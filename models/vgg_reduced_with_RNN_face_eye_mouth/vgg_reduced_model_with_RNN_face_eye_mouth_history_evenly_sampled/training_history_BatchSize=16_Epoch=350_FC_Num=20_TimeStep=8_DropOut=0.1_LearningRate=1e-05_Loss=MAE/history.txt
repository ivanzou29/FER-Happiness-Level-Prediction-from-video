Epoch: 1| Step: 0
Training loss: 5.373165130615234
Validation loss: 5.19682458139235

Epoch: 6| Step: 1
Training loss: 5.263878345489502
Validation loss: 5.1817055876537035

Epoch: 6| Step: 2
Training loss: 4.881619453430176
Validation loss: 5.166664200444376

Epoch: 6| Step: 3
Training loss: 4.205966949462891
Validation loss: 5.1515673668153825

Epoch: 6| Step: 4
Training loss: 4.801190376281738
Validation loss: 5.136356738305861

Epoch: 6| Step: 5
Training loss: 3.8221092224121094
Validation loss: 5.11961176062143

Epoch: 6| Step: 6
Training loss: 4.880278587341309
Validation loss: 5.101881298967587

Epoch: 6| Step: 7
Training loss: 6.983914375305176
Validation loss: 5.0819043138975735

Epoch: 6| Step: 8
Training loss: 4.365111351013184
Validation loss: 5.062079885954498

Epoch: 6| Step: 9
Training loss: 6.662703037261963
Validation loss: 5.0402134720997145

Epoch: 6| Step: 10
Training loss: 5.140484809875488
Validation loss: 5.016747177288097

Epoch: 6| Step: 11
Training loss: 3.666708469390869
Validation loss: 4.992414889797088

Epoch: 6| Step: 12
Training loss: 3.5212512016296387
Validation loss: 4.966132020437589

Epoch: 6| Step: 13
Training loss: 4.620092391967773
Validation loss: 4.940031820727933

Epoch: 2| Step: 0
Training loss: 4.386380195617676
Validation loss: 4.9112403008245655

Epoch: 6| Step: 1
Training loss: 4.66976261138916
Validation loss: 4.88247501209218

Epoch: 6| Step: 2
Training loss: 4.431092262268066
Validation loss: 4.853645104233936

Epoch: 6| Step: 3
Training loss: 5.65229606628418
Validation loss: 4.82366180676286

Epoch: 6| Step: 4
Training loss: 3.7814784049987793
Validation loss: 4.792503197987874

Epoch: 6| Step: 5
Training loss: 5.370270252227783
Validation loss: 4.761674593853694

Epoch: 6| Step: 6
Training loss: 4.418231964111328
Validation loss: 4.730306251074678

Epoch: 6| Step: 7
Training loss: 3.6992902755737305
Validation loss: 4.699140153905397

Epoch: 6| Step: 8
Training loss: 4.9559197425842285
Validation loss: 4.666954040527344

Epoch: 6| Step: 9
Training loss: 4.692859649658203
Validation loss: 4.634798716473323

Epoch: 6| Step: 10
Training loss: 5.15007209777832
Validation loss: 4.601445992787679

Epoch: 6| Step: 11
Training loss: 3.8907036781311035
Validation loss: 4.567276718795941

Epoch: 6| Step: 12
Training loss: 3.7924952507019043
Validation loss: 4.531952217061033

Epoch: 6| Step: 13
Training loss: 4.065128326416016
Validation loss: 4.494856214010587

Epoch: 3| Step: 0
Training loss: 3.3340673446655273
Validation loss: 4.457929759897212

Epoch: 6| Step: 1
Training loss: 4.675060272216797
Validation loss: 4.4200694637913855

Epoch: 6| Step: 2
Training loss: 4.953516483306885
Validation loss: 4.381554034448439

Epoch: 6| Step: 3
Training loss: 3.7245047092437744
Validation loss: 4.343605085085797

Epoch: 6| Step: 4
Training loss: 3.777865171432495
Validation loss: 4.307338986345517

Epoch: 6| Step: 5
Training loss: 4.77115535736084
Validation loss: 4.271213387930265

Epoch: 6| Step: 6
Training loss: 4.92586612701416
Validation loss: 4.237162318280948

Epoch: 6| Step: 7
Training loss: 4.144504547119141
Validation loss: 4.2043934022226646

Epoch: 6| Step: 8
Training loss: 2.8011586666107178
Validation loss: 4.171829505633283

Epoch: 6| Step: 9
Training loss: 4.785005569458008
Validation loss: 4.138219046336348

Epoch: 6| Step: 10
Training loss: 4.3322272300720215
Validation loss: 4.107436446733372

Epoch: 6| Step: 11
Training loss: 3.687835216522217
Validation loss: 4.079785023966143

Epoch: 6| Step: 12
Training loss: 3.3357834815979004
Validation loss: 4.050580634865709

Epoch: 6| Step: 13
Training loss: 3.0781664848327637
Validation loss: 4.025590537696757

Epoch: 4| Step: 0
Training loss: 4.1141862869262695
Validation loss: 4.001262572503859

Epoch: 6| Step: 1
Training loss: 2.698643207550049
Validation loss: 3.9762330978147444

Epoch: 6| Step: 2
Training loss: 4.240181922912598
Validation loss: 3.9517493196713027

Epoch: 6| Step: 3
Training loss: 3.4140143394470215
Validation loss: 3.9260168331925587

Epoch: 6| Step: 4
Training loss: 3.775303840637207
Validation loss: 3.900938239148868

Epoch: 6| Step: 5
Training loss: 4.673336505889893
Validation loss: 3.879491506084319

Epoch: 6| Step: 6
Training loss: 3.2929463386535645
Validation loss: 3.8597296437909527

Epoch: 6| Step: 7
Training loss: 3.743044376373291
Validation loss: 3.8405639381818872

Epoch: 6| Step: 8
Training loss: 3.8238024711608887
Validation loss: 3.8194341839000745

Epoch: 6| Step: 9
Training loss: 3.4226412773132324
Validation loss: 3.8034237841124177

Epoch: 6| Step: 10
Training loss: 3.860197067260742
Validation loss: 3.7825100524451143

Epoch: 6| Step: 11
Training loss: 3.5465755462646484
Validation loss: 3.76371919467885

Epoch: 6| Step: 12
Training loss: 3.7879140377044678
Validation loss: 3.7437472189626386

Epoch: 6| Step: 13
Training loss: 3.8740055561065674
Validation loss: 3.7226073818822063

Epoch: 5| Step: 0
Training loss: 3.4060497283935547
Validation loss: 3.7029888296640046

Epoch: 6| Step: 1
Training loss: 3.5930943489074707
Validation loss: 3.68627526170464

Epoch: 6| Step: 2
Training loss: 4.807910919189453
Validation loss: 3.667260641692787

Epoch: 6| Step: 3
Training loss: 3.5780272483825684
Validation loss: 3.64925968006093

Epoch: 6| Step: 4
Training loss: 3.4573843479156494
Validation loss: 3.632878811128678

Epoch: 6| Step: 5
Training loss: 3.470167636871338
Validation loss: 3.6203717595787457

Epoch: 6| Step: 6
Training loss: 3.286316394805908
Validation loss: 3.609553257624308

Epoch: 6| Step: 7
Training loss: 2.5863893032073975
Validation loss: 3.5943872569709696

Epoch: 6| Step: 8
Training loss: 2.884507179260254
Validation loss: 3.580033402289114

Epoch: 6| Step: 9
Training loss: 4.026113986968994
Validation loss: 3.5605000321583082

Epoch: 6| Step: 10
Training loss: 3.5006494522094727
Validation loss: 3.546692394441174

Epoch: 6| Step: 11
Training loss: 3.0407636165618896
Validation loss: 3.5379857811876523

Epoch: 6| Step: 12
Training loss: 3.870523691177368
Validation loss: 3.5299228801522204

Epoch: 6| Step: 13
Training loss: 4.078591346740723
Validation loss: 3.518980256972774

Epoch: 6| Step: 0
Training loss: 2.945010185241699
Validation loss: 3.504079318815662

Epoch: 6| Step: 1
Training loss: 2.556628942489624
Validation loss: 3.4926429538316626

Epoch: 6| Step: 2
Training loss: 3.8433804512023926
Validation loss: 3.481349378503779

Epoch: 6| Step: 3
Training loss: 4.305395126342773
Validation loss: 3.4711593376692904

Epoch: 6| Step: 4
Training loss: 3.1846582889556885
Validation loss: 3.4609434322644304

Epoch: 6| Step: 5
Training loss: 3.088632583618164
Validation loss: 3.4518128107952815

Epoch: 6| Step: 6
Training loss: 3.146744728088379
Validation loss: 3.443282655490342

Epoch: 6| Step: 7
Training loss: 3.254727840423584
Validation loss: 3.4376229675867225

Epoch: 6| Step: 8
Training loss: 4.410200119018555
Validation loss: 3.4296527883057952

Epoch: 6| Step: 9
Training loss: 3.8697903156280518
Validation loss: 3.420494189826391

Epoch: 6| Step: 10
Training loss: 4.225702285766602
Validation loss: 3.4101349512736

Epoch: 6| Step: 11
Training loss: 3.1858363151550293
Validation loss: 3.401427715055404

Epoch: 6| Step: 12
Training loss: 2.898800849914551
Validation loss: 3.3938877300549577

Epoch: 6| Step: 13
Training loss: 1.7530361413955688
Validation loss: 3.384761482156733

Epoch: 7| Step: 0
Training loss: 3.0685818195343018
Validation loss: 3.380305859350389

Epoch: 6| Step: 1
Training loss: 3.414832353591919
Validation loss: 3.3732971170897126

Epoch: 6| Step: 2
Training loss: 3.185753107070923
Validation loss: 3.3648154684292373

Epoch: 6| Step: 3
Training loss: 2.975515365600586
Validation loss: 3.356976862876646

Epoch: 6| Step: 4
Training loss: 4.278730392456055
Validation loss: 3.349565936673072

Epoch: 6| Step: 5
Training loss: 3.610870838165283
Validation loss: 3.343665302440684

Epoch: 6| Step: 6
Training loss: 3.0423059463500977
Validation loss: 3.331562831837644

Epoch: 6| Step: 7
Training loss: 2.4974944591522217
Validation loss: 3.3250245407063472

Epoch: 6| Step: 8
Training loss: 3.896329164505005
Validation loss: 3.321167527988393

Epoch: 6| Step: 9
Training loss: 3.0121188163757324
Validation loss: 3.310716049645537

Epoch: 6| Step: 10
Training loss: 3.6815476417541504
Validation loss: 3.3012932090349096

Epoch: 6| Step: 11
Training loss: 2.912477970123291
Validation loss: 3.294079908760645

Epoch: 6| Step: 12
Training loss: 2.7486777305603027
Validation loss: 3.289264596918578

Epoch: 6| Step: 13
Training loss: 4.259219169616699
Validation loss: 3.283110923664544

Epoch: 8| Step: 0
Training loss: 4.085488796234131
Validation loss: 3.2761825310286654

Epoch: 6| Step: 1
Training loss: 3.8067245483398438
Validation loss: 3.2705886851074877

Epoch: 6| Step: 2
Training loss: 2.871244430541992
Validation loss: 3.2592573319711993

Epoch: 6| Step: 3
Training loss: 3.7818918228149414
Validation loss: 3.253255751825148

Epoch: 6| Step: 4
Training loss: 1.7118782997131348
Validation loss: 3.2450250707646853

Epoch: 6| Step: 5
Training loss: 2.490238666534424
Validation loss: 3.2394048936905397

Epoch: 6| Step: 6
Training loss: 3.818970203399658
Validation loss: 3.2371692785652737

Epoch: 6| Step: 7
Training loss: 2.90228009223938
Validation loss: 3.235198102971559

Epoch: 6| Step: 8
Training loss: 3.6129910945892334
Validation loss: 3.2337134909886185

Epoch: 6| Step: 9
Training loss: 4.06814432144165
Validation loss: 3.2211924419608167

Epoch: 6| Step: 10
Training loss: 3.26509428024292
Validation loss: 3.215369245057465

Epoch: 6| Step: 11
Training loss: 3.378037452697754
Validation loss: 3.204412288563226

Epoch: 6| Step: 12
Training loss: 2.477354049682617
Validation loss: 3.1955801415187057

Epoch: 6| Step: 13
Training loss: 2.6252734661102295
Validation loss: 3.188117793811265

Epoch: 9| Step: 0
Training loss: 3.200108528137207
Validation loss: 3.1841467836851716

Epoch: 6| Step: 1
Training loss: 3.442685604095459
Validation loss: 3.178520312873266

Epoch: 6| Step: 2
Training loss: 3.7660439014434814
Validation loss: 3.1743382433409333

Epoch: 6| Step: 3
Training loss: 2.999293565750122
Validation loss: 3.166964707836028

Epoch: 6| Step: 4
Training loss: 2.0348949432373047
Validation loss: 3.162741235507432

Epoch: 6| Step: 5
Training loss: 2.7414064407348633
Validation loss: 3.1592442758621706

Epoch: 6| Step: 6
Training loss: 4.408069610595703
Validation loss: 3.148775657018026

Epoch: 6| Step: 7
Training loss: 3.1526989936828613
Validation loss: 3.1412672714520524

Epoch: 6| Step: 8
Training loss: 4.047024250030518
Validation loss: 3.1349589440130416

Epoch: 6| Step: 9
Training loss: 2.312500238418579
Validation loss: 3.1343455647909515

Epoch: 6| Step: 10
Training loss: 3.379889488220215
Validation loss: 3.1213458584200953

Epoch: 6| Step: 11
Training loss: 2.7190916538238525
Validation loss: 3.1153648617447063

Epoch: 6| Step: 12
Training loss: 2.8497371673583984
Validation loss: 3.107110410608271

Epoch: 6| Step: 13
Training loss: 3.2892580032348633
Validation loss: 3.1008918182824248

Epoch: 10| Step: 0
Training loss: 3.1505203247070312
Validation loss: 3.0919508139292398

Epoch: 6| Step: 1
Training loss: 2.5767440795898438
Validation loss: 3.1002870734019945

Epoch: 6| Step: 2
Training loss: 3.8284218311309814
Validation loss: 3.0829846910251084

Epoch: 6| Step: 3
Training loss: 3.0066466331481934
Validation loss: 3.074497507464501

Epoch: 6| Step: 4
Training loss: 2.7570979595184326
Validation loss: 3.071737955975276

Epoch: 6| Step: 5
Training loss: 3.4723660945892334
Validation loss: 3.0684783022890807

Epoch: 6| Step: 6
Training loss: 3.6701178550720215
Validation loss: 3.0674706684645785

Epoch: 6| Step: 7
Training loss: 3.3101019859313965
Validation loss: 3.062985702227521

Epoch: 6| Step: 8
Training loss: 2.644749164581299
Validation loss: 3.0560099155672136

Epoch: 6| Step: 9
Training loss: 3.2488744258880615
Validation loss: 3.0511195275091354

Epoch: 6| Step: 10
Training loss: 2.7452125549316406
Validation loss: 3.0445495472159436

Epoch: 6| Step: 11
Training loss: 3.8705153465270996
Validation loss: 3.040095172902589

Epoch: 6| Step: 12
Training loss: 2.344090461730957
Validation loss: 3.0260499600441224

Epoch: 6| Step: 13
Training loss: 2.6403515338897705
Validation loss: 3.0244196076546945

Epoch: 11| Step: 0
Training loss: 2.774089813232422
Validation loss: 3.0197922593803814

Epoch: 6| Step: 1
Training loss: 2.7940096855163574
Validation loss: 3.0211172949883247

Epoch: 6| Step: 2
Training loss: 3.290195941925049
Validation loss: 3.014173638436102

Epoch: 6| Step: 3
Training loss: 3.09018611907959
Validation loss: 3.0125325110650834

Epoch: 6| Step: 4
Training loss: 2.61238694190979
Validation loss: 3.010039298765121

Epoch: 6| Step: 5
Training loss: 3.446352958679199
Validation loss: 3.0565828097763883

Epoch: 6| Step: 6
Training loss: 3.6573009490966797
Validation loss: 3.056844639521773

Epoch: 6| Step: 7
Training loss: 3.130131721496582
Validation loss: 3.01321836697158

Epoch: 6| Step: 8
Training loss: 3.7225754261016846
Validation loss: 2.997157886464109

Epoch: 6| Step: 9
Training loss: 2.8771629333496094
Validation loss: 2.9935093208025862

Epoch: 6| Step: 10
Training loss: 2.7417311668395996
Validation loss: 3.002887484847858

Epoch: 6| Step: 11
Training loss: 1.9057750701904297
Validation loss: 2.997255894445604

Epoch: 6| Step: 12
Training loss: 3.83398175239563
Validation loss: 2.9842700189159763

Epoch: 6| Step: 13
Training loss: 3.1609904766082764
Validation loss: 2.980632100054013

Epoch: 12| Step: 0
Training loss: 3.003741979598999
Validation loss: 2.977529223247241

Epoch: 6| Step: 1
Training loss: 2.7103562355041504
Validation loss: 2.9726600211153746

Epoch: 6| Step: 2
Training loss: 3.8440427780151367
Validation loss: 2.9718327291550173

Epoch: 6| Step: 3
Training loss: 3.6079745292663574
Validation loss: 2.9669329376630884

Epoch: 6| Step: 4
Training loss: 2.947556495666504
Validation loss: 2.9628131287072295

Epoch: 6| Step: 5
Training loss: 2.998939037322998
Validation loss: 2.9547862314408824

Epoch: 6| Step: 6
Training loss: 3.291029930114746
Validation loss: 2.9497991095307055

Epoch: 6| Step: 7
Training loss: 3.0141773223876953
Validation loss: 2.948425882606096

Epoch: 6| Step: 8
Training loss: 2.4886345863342285
Validation loss: 2.944130551430487

Epoch: 6| Step: 9
Training loss: 2.37528657913208
Validation loss: 2.9405537010521017

Epoch: 6| Step: 10
Training loss: 3.1253345012664795
Validation loss: 2.9309470397169872

Epoch: 6| Step: 11
Training loss: 3.532562255859375
Validation loss: 2.9335983337894564

Epoch: 6| Step: 12
Training loss: 2.0271074771881104
Validation loss: 2.928592833139563

Epoch: 6| Step: 13
Training loss: 3.976653575897217
Validation loss: 2.9240731346991753

Epoch: 13| Step: 0
Training loss: 4.027016639709473
Validation loss: 2.917998513867778

Epoch: 6| Step: 1
Training loss: 3.6307597160339355
Validation loss: 2.9339439920199815

Epoch: 6| Step: 2
Training loss: 2.9822144508361816
Validation loss: 2.9160489446373394

Epoch: 6| Step: 3
Training loss: 3.694751501083374
Validation loss: 2.917461359372703

Epoch: 6| Step: 4
Training loss: 3.0167477130889893
Validation loss: 2.9086487318879817

Epoch: 6| Step: 5
Training loss: 2.6630287170410156
Validation loss: 2.9057886318493913

Epoch: 6| Step: 6
Training loss: 3.147203207015991
Validation loss: 2.9052778649073776

Epoch: 6| Step: 7
Training loss: 2.813861608505249
Validation loss: 2.9018461550435712

Epoch: 6| Step: 8
Training loss: 3.694007635116577
Validation loss: 2.906873610711867

Epoch: 6| Step: 9
Training loss: 2.5210301876068115
Validation loss: 2.90828094174785

Epoch: 6| Step: 10
Training loss: 1.7154533863067627
Validation loss: 2.9116355629377466

Epoch: 6| Step: 11
Training loss: 2.6560635566711426
Validation loss: 2.908524633735739

Epoch: 6| Step: 12
Training loss: 2.7243356704711914
Validation loss: 2.8961058944784184

Epoch: 6| Step: 13
Training loss: 2.520784616470337
Validation loss: 2.887420459460187

Epoch: 14| Step: 0
Training loss: 2.6271753311157227
Validation loss: 2.944859366263113

Epoch: 6| Step: 1
Training loss: 2.773271083831787
Validation loss: 2.9498295425086893

Epoch: 6| Step: 2
Training loss: 3.748034954071045
Validation loss: 2.9525511982620403

Epoch: 6| Step: 3
Training loss: 3.18892502784729
Validation loss: 2.9513363889468613

Epoch: 6| Step: 4
Training loss: 3.3256983757019043
Validation loss: 2.944940128634053

Epoch: 6| Step: 5
Training loss: 2.708357334136963
Validation loss: 2.9387748395243

Epoch: 6| Step: 6
Training loss: 2.362408399581909
Validation loss: 2.9296243370220227

Epoch: 6| Step: 7
Training loss: 2.7733049392700195
Validation loss: 2.9262659344621884

Epoch: 6| Step: 8
Training loss: 2.9570655822753906
Validation loss: 2.924036290055962

Epoch: 6| Step: 9
Training loss: 2.7164247035980225
Validation loss: 2.922022299099994

Epoch: 6| Step: 10
Training loss: 3.5438523292541504
Validation loss: 2.917194607437298

Epoch: 6| Step: 11
Training loss: 2.6012823581695557
Validation loss: 2.9179735798989572

Epoch: 6| Step: 12
Training loss: 3.9533886909484863
Validation loss: 2.9133970532366025

Epoch: 6| Step: 13
Training loss: 3.0333287715911865
Validation loss: 2.9085846511266564

Epoch: 15| Step: 0
Training loss: 3.0607986450195312
Validation loss: 2.903003454208374

Epoch: 6| Step: 1
Training loss: 2.8351082801818848
Validation loss: 2.902289516182356

Epoch: 6| Step: 2
Training loss: 3.5539345741271973
Validation loss: 2.894881251037762

Epoch: 6| Step: 3
Training loss: 2.905205249786377
Validation loss: 2.8885366403928368

Epoch: 6| Step: 4
Training loss: 2.459540843963623
Validation loss: 2.887200399111676

Epoch: 6| Step: 5
Training loss: 3.3334262371063232
Validation loss: 2.885402548697687

Epoch: 6| Step: 6
Training loss: 2.8739733695983887
Validation loss: 2.883639627887357

Epoch: 6| Step: 7
Training loss: 2.347236156463623
Validation loss: 2.880200537302161

Epoch: 6| Step: 8
Training loss: 2.5598220825195312
Validation loss: 2.8754490601119174

Epoch: 6| Step: 9
Training loss: 2.5827269554138184
Validation loss: 2.874534063441779

Epoch: 6| Step: 10
Training loss: 3.8120908737182617
Validation loss: 2.8662220021729827

Epoch: 6| Step: 11
Training loss: 2.9716994762420654
Validation loss: 2.8545358411727415

Epoch: 6| Step: 12
Training loss: 3.218174457550049
Validation loss: 2.8332527581081597

Epoch: 6| Step: 13
Training loss: 3.4807865619659424
Validation loss: 2.8225240322851364

Epoch: 16| Step: 0
Training loss: 2.8857545852661133
Validation loss: 2.8204429957174484

Epoch: 6| Step: 1
Training loss: 2.9029641151428223
Validation loss: 2.8229929170300885

Epoch: 6| Step: 2
Training loss: 3.3821017742156982
Validation loss: 2.828000973629695

Epoch: 6| Step: 3
Training loss: 2.494194507598877
Validation loss: 2.8296884823870916

Epoch: 6| Step: 4
Training loss: 2.6575393676757812
Validation loss: 2.819432904643397

Epoch: 6| Step: 5
Training loss: 3.0498056411743164
Validation loss: 2.8118376860054592

Epoch: 6| Step: 6
Training loss: 2.447338581085205
Validation loss: 2.8058034450777116

Epoch: 6| Step: 7
Training loss: 3.9590210914611816
Validation loss: 2.803314503803048

Epoch: 6| Step: 8
Training loss: 3.1955935955047607
Validation loss: 2.800865379712915

Epoch: 6| Step: 9
Training loss: 3.258948802947998
Validation loss: 2.8037268448901433

Epoch: 6| Step: 10
Training loss: 2.088942527770996
Validation loss: 2.800813995381837

Epoch: 6| Step: 11
Training loss: 3.3514389991760254
Validation loss: 2.799782406899237

Epoch: 6| Step: 12
Training loss: 2.1783385276794434
Validation loss: 2.7946593428170807

Epoch: 6| Step: 13
Training loss: 3.5622689723968506
Validation loss: 2.795851074239259

Epoch: 17| Step: 0
Training loss: 3.3122785091400146
Validation loss: 2.8005044203932568

Epoch: 6| Step: 1
Training loss: 2.651442050933838
Validation loss: 2.7889581341897287

Epoch: 6| Step: 2
Training loss: 1.9974876642227173
Validation loss: 2.794166282940936

Epoch: 6| Step: 3
Training loss: 2.8776392936706543
Validation loss: 2.787588006706648

Epoch: 6| Step: 4
Training loss: 3.692563533782959
Validation loss: 2.794199594887354

Epoch: 6| Step: 5
Training loss: 3.4298717975616455
Validation loss: 2.791464974803309

Epoch: 6| Step: 6
Training loss: 3.878586530685425
Validation loss: 2.7892624383331626

Epoch: 6| Step: 7
Training loss: 2.544022560119629
Validation loss: 2.7909653468798568

Epoch: 6| Step: 8
Training loss: 2.3468985557556152
Validation loss: 2.8240673772750364

Epoch: 6| Step: 9
Training loss: 2.9295811653137207
Validation loss: 2.850066984853437

Epoch: 6| Step: 10
Training loss: 2.4165287017822266
Validation loss: 2.831502796501242

Epoch: 6| Step: 11
Training loss: 3.145582914352417
Validation loss: 2.7889418345625683

Epoch: 6| Step: 12
Training loss: 3.1035618782043457
Validation loss: 2.7830835670553227

Epoch: 6| Step: 13
Training loss: 2.5385637283325195
Validation loss: 2.7923891185432352

Epoch: 18| Step: 0
Training loss: 3.5239391326904297
Validation loss: 2.8113360379331853

Epoch: 6| Step: 1
Training loss: 2.7731142044067383
Validation loss: 2.7956937692498647

Epoch: 6| Step: 2
Training loss: 3.348511219024658
Validation loss: 2.794639672002485

Epoch: 6| Step: 3
Training loss: 3.0687432289123535
Validation loss: 2.7914341342064644

Epoch: 6| Step: 4
Training loss: 2.3317365646362305
Validation loss: 2.7959702527651222

Epoch: 6| Step: 5
Training loss: 3.5466723442077637
Validation loss: 2.784602138303941

Epoch: 6| Step: 6
Training loss: 3.414311408996582
Validation loss: 2.7743356458602415

Epoch: 6| Step: 7
Training loss: 2.2612946033477783
Validation loss: 2.780242343102732

Epoch: 6| Step: 8
Training loss: 2.479252338409424
Validation loss: 2.7767989738013155

Epoch: 6| Step: 9
Training loss: 2.026754856109619
Validation loss: 2.7806481135788785

Epoch: 6| Step: 10
Training loss: 3.2661848068237305
Validation loss: 2.782338532068396

Epoch: 6| Step: 11
Training loss: 2.9549341201782227
Validation loss: 2.783112254194034

Epoch: 6| Step: 12
Training loss: 3.1417315006256104
Validation loss: 2.7917691302555863

Epoch: 6| Step: 13
Training loss: 2.769091844558716
Validation loss: 2.8120693955370175

Epoch: 19| Step: 0
Training loss: 2.871401309967041
Validation loss: 2.796049669224729

Epoch: 6| Step: 1
Training loss: 3.0480093955993652
Validation loss: 2.782961091687602

Epoch: 6| Step: 2
Training loss: 3.080443859100342
Validation loss: 2.771473164199501

Epoch: 6| Step: 3
Training loss: 2.5810389518737793
Validation loss: 2.7687120181258007

Epoch: 6| Step: 4
Training loss: 2.545586109161377
Validation loss: 2.7633760872707573

Epoch: 6| Step: 5
Training loss: 2.3350765705108643
Validation loss: 2.764514797477312

Epoch: 6| Step: 6
Training loss: 2.5005125999450684
Validation loss: 2.762893130702357

Epoch: 6| Step: 7
Training loss: 2.8765931129455566
Validation loss: 2.7606292693845687

Epoch: 6| Step: 8
Training loss: 3.5551528930664062
Validation loss: 2.7624638157506145

Epoch: 6| Step: 9
Training loss: 2.6346802711486816
Validation loss: 2.758466173243779

Epoch: 6| Step: 10
Training loss: 3.2242305278778076
Validation loss: 2.758656353078863

Epoch: 6| Step: 11
Training loss: 3.5784597396850586
Validation loss: 2.759403315923547

Epoch: 6| Step: 12
Training loss: 2.9437944889068604
Validation loss: 2.767846458701677

Epoch: 6| Step: 13
Training loss: 3.018857717514038
Validation loss: 2.768117053534395

Epoch: 20| Step: 0
Training loss: 3.227407217025757
Validation loss: 2.755383981171475

Epoch: 6| Step: 1
Training loss: 2.5426924228668213
Validation loss: 2.761653474582139

Epoch: 6| Step: 2
Training loss: 1.9271522760391235
Validation loss: 2.7533873204262025

Epoch: 6| Step: 3
Training loss: 3.338192939758301
Validation loss: 2.752303638765889

Epoch: 6| Step: 4
Training loss: 3.7721571922302246
Validation loss: 2.7518472927872852

Epoch: 6| Step: 5
Training loss: 2.577666759490967
Validation loss: 2.7522839423148864

Epoch: 6| Step: 6
Training loss: 3.0006699562072754
Validation loss: 2.756626416278142

Epoch: 6| Step: 7
Training loss: 2.599879026412964
Validation loss: 2.7498759659387733

Epoch: 6| Step: 8
Training loss: 2.649702310562134
Validation loss: 2.753454913375198

Epoch: 6| Step: 9
Training loss: 2.6365058422088623
Validation loss: 2.75014857322939

Epoch: 6| Step: 10
Training loss: 3.0453076362609863
Validation loss: 2.7509756524075746

Epoch: 6| Step: 11
Training loss: 3.7700490951538086
Validation loss: 2.745268178242509

Epoch: 6| Step: 12
Training loss: 2.783249616622925
Validation loss: 2.745941710728471

Epoch: 6| Step: 13
Training loss: 2.678731918334961
Validation loss: 2.7445407323939826

Epoch: 21| Step: 0
Training loss: 3.8116140365600586
Validation loss: 2.7414415908116165

Epoch: 6| Step: 1
Training loss: 2.329815626144409
Validation loss: 2.743074640150993

Epoch: 6| Step: 2
Training loss: 2.2055869102478027
Validation loss: 2.7445942919741393

Epoch: 6| Step: 3
Training loss: 2.617461681365967
Validation loss: 2.7446485616827525

Epoch: 6| Step: 4
Training loss: 2.369180679321289
Validation loss: 2.743290783256613

Epoch: 6| Step: 5
Training loss: 2.905451536178589
Validation loss: 2.741492881569811

Epoch: 6| Step: 6
Training loss: 3.3687021732330322
Validation loss: 2.737338004573699

Epoch: 6| Step: 7
Training loss: 2.730727195739746
Validation loss: 2.7335328132875505

Epoch: 6| Step: 8
Training loss: 3.180523157119751
Validation loss: 2.7328344878330024

Epoch: 6| Step: 9
Training loss: 3.525454044342041
Validation loss: 2.7327759419718096

Epoch: 6| Step: 10
Training loss: 3.533572196960449
Validation loss: 2.729339640627625

Epoch: 6| Step: 11
Training loss: 2.66145920753479
Validation loss: 2.726616044198313

Epoch: 6| Step: 12
Training loss: 2.4654414653778076
Validation loss: 2.7267777150677097

Epoch: 6| Step: 13
Training loss: 2.6846084594726562
Validation loss: 2.726214654984013

Epoch: 22| Step: 0
Training loss: 3.353013753890991
Validation loss: 2.724286589571225

Epoch: 6| Step: 1
Training loss: 2.4185690879821777
Validation loss: 2.7266691025867256

Epoch: 6| Step: 2
Training loss: 3.568117618560791
Validation loss: 2.7252554303856305

Epoch: 6| Step: 3
Training loss: 2.8781657218933105
Validation loss: 2.7292912775470364

Epoch: 6| Step: 4
Training loss: 2.9272496700286865
Validation loss: 2.721463723849225

Epoch: 6| Step: 5
Training loss: 2.2054543495178223
Validation loss: 2.7183700658941783

Epoch: 6| Step: 6
Training loss: 2.7498390674591064
Validation loss: 2.7181330009173323

Epoch: 6| Step: 7
Training loss: 2.923391819000244
Validation loss: 2.7186626695817515

Epoch: 6| Step: 8
Training loss: 3.465306282043457
Validation loss: 2.7151292729121383

Epoch: 6| Step: 9
Training loss: 2.7951855659484863
Validation loss: 2.7118249836788384

Epoch: 6| Step: 10
Training loss: 1.6801722049713135
Validation loss: 2.710801475791521

Epoch: 6| Step: 11
Training loss: 2.8508520126342773
Validation loss: 2.7112650845640447

Epoch: 6| Step: 12
Training loss: 3.6305034160614014
Validation loss: 2.7100409307787494

Epoch: 6| Step: 13
Training loss: 2.910590410232544
Validation loss: 2.7086998237076627

Epoch: 23| Step: 0
Training loss: 2.3810768127441406
Validation loss: 2.708592096964518

Epoch: 6| Step: 1
Training loss: 2.7139573097229004
Validation loss: 2.7065630728198635

Epoch: 6| Step: 2
Training loss: 3.724226951599121
Validation loss: 2.7081716829730618

Epoch: 6| Step: 3
Training loss: 2.243637800216675
Validation loss: 2.7048944170757006

Epoch: 6| Step: 4
Training loss: 2.1056010723114014
Validation loss: 2.7040111659675516

Epoch: 6| Step: 5
Training loss: 2.9755289554595947
Validation loss: 2.7018654782284974

Epoch: 6| Step: 6
Training loss: 4.045998573303223
Validation loss: 2.7002373690246255

Epoch: 6| Step: 7
Training loss: 2.6635632514953613
Validation loss: 2.699659983317057

Epoch: 6| Step: 8
Training loss: 2.826511859893799
Validation loss: 2.6979745305994505

Epoch: 6| Step: 9
Training loss: 3.8438689708709717
Validation loss: 2.697290605114352

Epoch: 6| Step: 10
Training loss: 3.023458242416382
Validation loss: 2.6926614751097975

Epoch: 6| Step: 11
Training loss: 2.95906400680542
Validation loss: 2.694090438145463

Epoch: 6| Step: 12
Training loss: 2.0778350830078125
Validation loss: 2.6912201245625815

Epoch: 6| Step: 13
Training loss: 2.390665292739868
Validation loss: 2.6928853963011052

Epoch: 24| Step: 0
Training loss: 3.117323398590088
Validation loss: 2.690723716571767

Epoch: 6| Step: 1
Training loss: 2.3420212268829346
Validation loss: 2.690818243129279

Epoch: 6| Step: 2
Training loss: 3.7202844619750977
Validation loss: 2.691533124575051

Epoch: 6| Step: 3
Training loss: 3.901604652404785
Validation loss: 2.685900342079901

Epoch: 6| Step: 4
Training loss: 1.8229362964630127
Validation loss: 2.6847421584590787

Epoch: 6| Step: 5
Training loss: 2.5662107467651367
Validation loss: 2.684686222384053

Epoch: 6| Step: 6
Training loss: 2.4117114543914795
Validation loss: 2.682581886168449

Epoch: 6| Step: 7
Training loss: 3.048644781112671
Validation loss: 2.6922100077393236

Epoch: 6| Step: 8
Training loss: 3.2727909088134766
Validation loss: 2.692373675684775

Epoch: 6| Step: 9
Training loss: 1.8790562152862549
Validation loss: 2.6916579687467186

Epoch: 6| Step: 10
Training loss: 3.5046520233154297
Validation loss: 2.6845069316125687

Epoch: 6| Step: 11
Training loss: 3.253448247909546
Validation loss: 2.684325272037137

Epoch: 6| Step: 12
Training loss: 2.311514139175415
Validation loss: 2.679072441593293

Epoch: 6| Step: 13
Training loss: 2.829312324523926
Validation loss: 2.68243157991799

Epoch: 25| Step: 0
Training loss: 3.194931745529175
Validation loss: 2.676389935196087

Epoch: 6| Step: 1
Training loss: 2.23734974861145
Validation loss: 2.676200282189154

Epoch: 6| Step: 2
Training loss: 2.643186092376709
Validation loss: 2.6749828374514015

Epoch: 6| Step: 3
Training loss: 3.246702194213867
Validation loss: 2.6764446791782173

Epoch: 6| Step: 4
Training loss: 3.2002463340759277
Validation loss: 2.675143731537686

Epoch: 6| Step: 5
Training loss: 2.778073787689209
Validation loss: 2.6741947589382047

Epoch: 6| Step: 6
Training loss: 2.6418142318725586
Validation loss: 2.672940126029394

Epoch: 6| Step: 7
Training loss: 2.5414180755615234
Validation loss: 2.672786548573484

Epoch: 6| Step: 8
Training loss: 2.618762254714966
Validation loss: 2.6703461959797847

Epoch: 6| Step: 9
Training loss: 3.431920051574707
Validation loss: 2.6682703289934384

Epoch: 6| Step: 10
Training loss: 2.7458336353302
Validation loss: 2.6678442903744277

Epoch: 6| Step: 11
Training loss: 3.018618583679199
Validation loss: 2.665316209998182

Epoch: 6| Step: 12
Training loss: 2.8654751777648926
Validation loss: 2.663602449560678

Epoch: 6| Step: 13
Training loss: 2.5111608505249023
Validation loss: 2.6633380638655795

Epoch: 26| Step: 0
Training loss: 2.8672873973846436
Validation loss: 2.6619547233786633

Epoch: 6| Step: 1
Training loss: 2.848383903503418
Validation loss: 2.663990689862159

Epoch: 6| Step: 2
Training loss: 3.252328395843506
Validation loss: 2.6600365202914

Epoch: 6| Step: 3
Training loss: 2.4501075744628906
Validation loss: 2.6614290924482447

Epoch: 6| Step: 4
Training loss: 2.4438774585723877
Validation loss: 2.6599485181993052

Epoch: 6| Step: 5
Training loss: 2.361454963684082
Validation loss: 2.660695122134301

Epoch: 6| Step: 6
Training loss: 1.841165542602539
Validation loss: 2.660371229212771

Epoch: 6| Step: 7
Training loss: 3.351935625076294
Validation loss: 2.661711339027651

Epoch: 6| Step: 8
Training loss: 3.5173230171203613
Validation loss: 2.6663799901162424

Epoch: 6| Step: 9
Training loss: 2.373084545135498
Validation loss: 2.6606317489377913

Epoch: 6| Step: 10
Training loss: 3.9014999866485596
Validation loss: 2.6632994016011557

Epoch: 6| Step: 11
Training loss: 3.4803690910339355
Validation loss: 2.661306570934993

Epoch: 6| Step: 12
Training loss: 2.30774188041687
Validation loss: 2.6576191225359516

Epoch: 6| Step: 13
Training loss: 2.66617751121521
Validation loss: 2.6564112709414576

Epoch: 27| Step: 0
Training loss: 2.2587876319885254
Validation loss: 2.6555622572539956

Epoch: 6| Step: 1
Training loss: 2.783396005630493
Validation loss: 2.6551172502579226

Epoch: 6| Step: 2
Training loss: 3.4105191230773926
Validation loss: 2.6605601695276078

Epoch: 6| Step: 3
Training loss: 3.5968363285064697
Validation loss: 2.655835872055382

Epoch: 6| Step: 4
Training loss: 1.7890276908874512
Validation loss: 2.6567936584513676

Epoch: 6| Step: 5
Training loss: 2.70497727394104
Validation loss: 2.6561968967478764

Epoch: 6| Step: 6
Training loss: 3.7429189682006836
Validation loss: 2.6542847259070284

Epoch: 6| Step: 7
Training loss: 2.7262489795684814
Validation loss: 2.655837171821184

Epoch: 6| Step: 8
Training loss: 2.842352867126465
Validation loss: 2.652798557794222

Epoch: 6| Step: 9
Training loss: 2.9123404026031494
Validation loss: 2.6538452333019626

Epoch: 6| Step: 10
Training loss: 2.8489365577697754
Validation loss: 2.6985740225802184

Epoch: 6| Step: 11
Training loss: 2.9722070693969727
Validation loss: 2.726660579763433

Epoch: 6| Step: 12
Training loss: 2.8344287872314453
Validation loss: 2.6834080578178487

Epoch: 6| Step: 13
Training loss: 1.898242712020874
Validation loss: 2.6595658768889723

Epoch: 28| Step: 0
Training loss: 2.824877977371216
Validation loss: 2.648600588562668

Epoch: 6| Step: 1
Training loss: 2.9780428409576416
Validation loss: 2.6492314620684554

Epoch: 6| Step: 2
Training loss: 2.606205701828003
Validation loss: 2.654272351213681

Epoch: 6| Step: 3
Training loss: 3.429459571838379
Validation loss: 2.656083009576285

Epoch: 6| Step: 4
Training loss: 2.4425318241119385
Validation loss: 2.6518396318599744

Epoch: 6| Step: 5
Training loss: 2.668699264526367
Validation loss: 2.6537820921149304

Epoch: 6| Step: 6
Training loss: 2.881901502609253
Validation loss: 2.6479821922958537

Epoch: 6| Step: 7
Training loss: 3.0850253105163574
Validation loss: 2.650397974957702

Epoch: 6| Step: 8
Training loss: 2.901235342025757
Validation loss: 2.64945884161098

Epoch: 6| Step: 9
Training loss: 2.4171249866485596
Validation loss: 2.64789475933198

Epoch: 6| Step: 10
Training loss: 3.3339152336120605
Validation loss: 2.647726233287524

Epoch: 6| Step: 11
Training loss: 2.3675966262817383
Validation loss: 2.6485094613926385

Epoch: 6| Step: 12
Training loss: 2.7437689304351807
Validation loss: 2.6485459496898036

Epoch: 6| Step: 13
Training loss: 3.0441958904266357
Validation loss: 2.6443726016629125

Epoch: 29| Step: 0
Training loss: 2.736757278442383
Validation loss: 2.6441322654806156

Epoch: 6| Step: 1
Training loss: 3.0320820808410645
Validation loss: 2.6408329984193206

Epoch: 6| Step: 2
Training loss: 2.3622610569000244
Validation loss: 2.6383310671775573

Epoch: 6| Step: 3
Training loss: 2.863727569580078
Validation loss: 2.641470727100167

Epoch: 6| Step: 4
Training loss: 3.1875710487365723
Validation loss: 2.640753061540665

Epoch: 6| Step: 5
Training loss: 3.4220752716064453
Validation loss: 2.639516835571617

Epoch: 6| Step: 6
Training loss: 2.8463332653045654
Validation loss: 2.6366734222699235

Epoch: 6| Step: 7
Training loss: 3.6982812881469727
Validation loss: 2.635966052291214

Epoch: 6| Step: 8
Training loss: 3.0934340953826904
Validation loss: 2.6396072756859565

Epoch: 6| Step: 9
Training loss: 2.4468889236450195
Validation loss: 2.6302313035534275

Epoch: 6| Step: 10
Training loss: 1.6331744194030762
Validation loss: 2.632721201066048

Epoch: 6| Step: 11
Training loss: 2.6432371139526367
Validation loss: 2.6375694556902816

Epoch: 6| Step: 12
Training loss: 2.870692729949951
Validation loss: 2.653731425603231

Epoch: 6| Step: 13
Training loss: 2.3497726917266846
Validation loss: 2.639459938131353

Epoch: 30| Step: 0
Training loss: 2.64497709274292
Validation loss: 2.635848376058763

Epoch: 6| Step: 1
Training loss: 2.6787490844726562
Validation loss: 2.644660213942169

Epoch: 6| Step: 2
Training loss: 2.899724006652832
Validation loss: 2.6480743551767

Epoch: 6| Step: 3
Training loss: 2.784719705581665
Validation loss: 2.634788238874046

Epoch: 6| Step: 4
Training loss: 2.4697532653808594
Validation loss: 2.636931352717902

Epoch: 6| Step: 5
Training loss: 3.3558311462402344
Validation loss: 2.6331667284811697

Epoch: 6| Step: 6
Training loss: 3.2485709190368652
Validation loss: 2.628812305388912

Epoch: 6| Step: 7
Training loss: 2.9177145957946777
Validation loss: 2.6288298201817337

Epoch: 6| Step: 8
Training loss: 3.1267380714416504
Validation loss: 2.6322454970370055

Epoch: 6| Step: 9
Training loss: 2.4357457160949707
Validation loss: 2.626848889935401

Epoch: 6| Step: 10
Training loss: 2.9646215438842773
Validation loss: 2.632401902188537

Epoch: 6| Step: 11
Training loss: 1.555192470550537
Validation loss: 2.6334346289275796

Epoch: 6| Step: 12
Training loss: 3.570993423461914
Validation loss: 2.6287956776157504

Epoch: 6| Step: 13
Training loss: 2.635745048522949
Validation loss: 2.6300722860520884

Epoch: 31| Step: 0
Training loss: 2.5171773433685303
Validation loss: 2.6269105698472712

Epoch: 6| Step: 1
Training loss: 2.548607587814331
Validation loss: 2.6272847293525614

Epoch: 6| Step: 2
Training loss: 2.889814853668213
Validation loss: 2.6251833169691023

Epoch: 6| Step: 3
Training loss: 2.5635008811950684
Validation loss: 2.6266897711702573

Epoch: 6| Step: 4
Training loss: 3.9467456340789795
Validation loss: 2.634371380652151

Epoch: 6| Step: 5
Training loss: 3.1676225662231445
Validation loss: 2.629192634295392

Epoch: 6| Step: 6
Training loss: 2.8394522666931152
Validation loss: 2.620881465173537

Epoch: 6| Step: 7
Training loss: 3.0178701877593994
Validation loss: 2.6228841120196926

Epoch: 6| Step: 8
Training loss: 3.4937968254089355
Validation loss: 2.6289847512398996

Epoch: 6| Step: 9
Training loss: 2.147571086883545
Validation loss: 2.626476880042784

Epoch: 6| Step: 10
Training loss: 2.2178173065185547
Validation loss: 2.6217636267344155

Epoch: 6| Step: 11
Training loss: 2.0973167419433594
Validation loss: 2.615333754529235

Epoch: 6| Step: 12
Training loss: 3.330490827560425
Validation loss: 2.6160867701294603

Epoch: 6| Step: 13
Training loss: 2.164283275604248
Validation loss: 2.612927475283223

Epoch: 32| Step: 0
Training loss: 2.5448122024536133
Validation loss: 2.613586510381391

Epoch: 6| Step: 1
Training loss: 2.5243980884552
Validation loss: 2.6126604874928794

Epoch: 6| Step: 2
Training loss: 2.9203262329101562
Validation loss: 2.61417342001392

Epoch: 6| Step: 3
Training loss: 2.9035446643829346
Validation loss: 2.6156169676011607

Epoch: 6| Step: 4
Training loss: 2.4409005641937256
Validation loss: 2.6211433026098434

Epoch: 6| Step: 5
Training loss: 3.0797152519226074
Validation loss: 2.6247910748245897

Epoch: 6| Step: 6
Training loss: 2.632122278213501
Validation loss: 2.6307396875914706

Epoch: 6| Step: 7
Training loss: 3.0108985900878906
Validation loss: 2.6404550921532417

Epoch: 6| Step: 8
Training loss: 2.664529323577881
Validation loss: 2.639120360856415

Epoch: 6| Step: 9
Training loss: 2.8191418647766113
Validation loss: 2.629777036687379

Epoch: 6| Step: 10
Training loss: 2.7434353828430176
Validation loss: 2.6158877829069733

Epoch: 6| Step: 11
Training loss: 3.3668441772460938
Validation loss: 2.612893207098848

Epoch: 6| Step: 12
Training loss: 3.1936933994293213
Validation loss: 2.6248749097188315

Epoch: 6| Step: 13
Training loss: 1.99102783203125
Validation loss: 2.63826092596977

Epoch: 33| Step: 0
Training loss: 2.3300771713256836
Validation loss: 2.6348217430935112

Epoch: 6| Step: 1
Training loss: 2.325310707092285
Validation loss: 2.6359205194698867

Epoch: 6| Step: 2
Training loss: 2.1641218662261963
Validation loss: 2.6364278331879647

Epoch: 6| Step: 3
Training loss: 3.683682441711426
Validation loss: 2.6263050904837986

Epoch: 6| Step: 4
Training loss: 3.1778717041015625
Validation loss: 2.634767875876478

Epoch: 6| Step: 5
Training loss: 2.8581576347351074
Validation loss: 2.6397043915205103

Epoch: 6| Step: 6
Training loss: 2.405259847640991
Validation loss: 2.6360375035193657

Epoch: 6| Step: 7
Training loss: 2.9535040855407715
Validation loss: 2.632697738626952

Epoch: 6| Step: 8
Training loss: 2.4629228115081787
Validation loss: 2.623820791962326

Epoch: 6| Step: 9
Training loss: 3.305285930633545
Validation loss: 2.632983253848168

Epoch: 6| Step: 10
Training loss: 2.3341476917266846
Validation loss: 2.6247332506282355

Epoch: 6| Step: 11
Training loss: 2.7059054374694824
Validation loss: 2.621050032236243

Epoch: 6| Step: 12
Training loss: 3.033945083618164
Validation loss: 2.6180643958430134

Epoch: 6| Step: 13
Training loss: 4.103382587432861
Validation loss: 2.6291016558165192

Epoch: 34| Step: 0
Training loss: 3.5504703521728516
Validation loss: 2.6258179936357724

Epoch: 6| Step: 1
Training loss: 2.205644130706787
Validation loss: 2.6175302920802945

Epoch: 6| Step: 2
Training loss: 2.8245577812194824
Validation loss: 2.6138675956315893

Epoch: 6| Step: 3
Training loss: 2.103332757949829
Validation loss: 2.6111604962297665

Epoch: 6| Step: 4
Training loss: 2.8805036544799805
Validation loss: 2.6089929662724978

Epoch: 6| Step: 5
Training loss: 2.3829495906829834
Validation loss: 2.6065851232056976

Epoch: 6| Step: 6
Training loss: 2.373432159423828
Validation loss: 2.6037251359672955

Epoch: 6| Step: 7
Training loss: 3.1731667518615723
Validation loss: 2.6026315714723323

Epoch: 6| Step: 8
Training loss: 2.9682884216308594
Validation loss: 2.6017738849886003

Epoch: 6| Step: 9
Training loss: 3.228668212890625
Validation loss: 2.6012766566327823

Epoch: 6| Step: 10
Training loss: 2.621138095855713
Validation loss: 2.599061043031754

Epoch: 6| Step: 11
Training loss: 3.5254604816436768
Validation loss: 2.5977416499968498

Epoch: 6| Step: 12
Training loss: 2.8507213592529297
Validation loss: 2.5983477561704573

Epoch: 6| Step: 13
Training loss: 2.0118813514709473
Validation loss: 2.6192522279677855

Epoch: 35| Step: 0
Training loss: 2.61361026763916
Validation loss: 2.6686243088014665

Epoch: 6| Step: 1
Training loss: 2.715181350708008
Validation loss: 2.6599610390201693

Epoch: 6| Step: 2
Training loss: 2.1053528785705566
Validation loss: 2.6514331140825824

Epoch: 6| Step: 3
Training loss: 3.2377326488494873
Validation loss: 2.6163199306816183

Epoch: 6| Step: 4
Training loss: 2.319439649581909
Validation loss: 2.5975673890882924

Epoch: 6| Step: 5
Training loss: 2.9913535118103027
Validation loss: 2.5903472618390153

Epoch: 6| Step: 6
Training loss: 2.838470458984375
Validation loss: 2.5879687506665467

Epoch: 6| Step: 7
Training loss: 2.9467337131500244
Validation loss: 2.589588890793503

Epoch: 6| Step: 8
Training loss: 3.0796217918395996
Validation loss: 2.590843003283265

Epoch: 6| Step: 9
Training loss: 3.2657814025878906
Validation loss: 2.591843156404393

Epoch: 6| Step: 10
Training loss: 2.8720409870147705
Validation loss: 2.5926382464747273

Epoch: 6| Step: 11
Training loss: 2.1230201721191406
Validation loss: 2.5921504497528076

Epoch: 6| Step: 12
Training loss: 2.5778942108154297
Validation loss: 2.5942415588645527

Epoch: 6| Step: 13
Training loss: 3.8263559341430664
Validation loss: 2.589457783647763

Epoch: 36| Step: 0
Training loss: 3.2083773612976074
Validation loss: 2.5875139441541446

Epoch: 6| Step: 1
Training loss: 2.925729513168335
Validation loss: 2.5890202189004548

Epoch: 6| Step: 2
Training loss: 3.3684840202331543
Validation loss: 2.594764406963061

Epoch: 6| Step: 3
Training loss: 3.0832953453063965
Validation loss: 2.6077837713303103

Epoch: 6| Step: 4
Training loss: 3.4928109645843506
Validation loss: 2.6306352589720037

Epoch: 6| Step: 5
Training loss: 2.6545324325561523
Validation loss: 2.6155940153265513

Epoch: 6| Step: 6
Training loss: 2.5831308364868164
Validation loss: 2.6019516914121565

Epoch: 6| Step: 7
Training loss: 2.9990270137786865
Validation loss: 2.5934275914263982

Epoch: 6| Step: 8
Training loss: 2.781627893447876
Validation loss: 2.5924235748988327

Epoch: 6| Step: 9
Training loss: 2.91629695892334
Validation loss: 2.6020818371926584

Epoch: 6| Step: 10
Training loss: 2.787843704223633
Validation loss: 2.606770366750738

Epoch: 6| Step: 11
Training loss: 1.3744693994522095
Validation loss: 2.6127683629271803

Epoch: 6| Step: 12
Training loss: 1.9088698625564575
Validation loss: 2.6263833045959473

Epoch: 6| Step: 13
Training loss: 2.9833550453186035
Validation loss: 2.6385217738407913

Epoch: 37| Step: 0
Training loss: 3.304978370666504
Validation loss: 2.6357639733181206

Epoch: 6| Step: 1
Training loss: 2.9040679931640625
Validation loss: 2.6235269038907942

Epoch: 6| Step: 2
Training loss: 2.373424768447876
Validation loss: 2.5981058023309194

Epoch: 6| Step: 3
Training loss: 2.0878429412841797
Validation loss: 2.588001781894315

Epoch: 6| Step: 4
Training loss: 2.6908795833587646
Validation loss: 2.5859851273157264

Epoch: 6| Step: 5
Training loss: 2.326988935470581
Validation loss: 2.582593543555147

Epoch: 6| Step: 6
Training loss: 3.0546836853027344
Validation loss: 2.5825533354154198

Epoch: 6| Step: 7
Training loss: 2.7885501384735107
Validation loss: 2.579910239865703

Epoch: 6| Step: 8
Training loss: 2.8231749534606934
Validation loss: 2.588863483039282

Epoch: 6| Step: 9
Training loss: 2.7555575370788574
Validation loss: 2.5956241110319733

Epoch: 6| Step: 10
Training loss: 3.3495290279388428
Validation loss: 2.600241932817685

Epoch: 6| Step: 11
Training loss: 2.6559643745422363
Validation loss: 2.604205467367685

Epoch: 6| Step: 12
Training loss: 2.904714822769165
Validation loss: 2.59356870958882

Epoch: 6| Step: 13
Training loss: 2.9475483894348145
Validation loss: 2.584524803264167

Epoch: 38| Step: 0
Training loss: 2.793898105621338
Validation loss: 2.579220074479298

Epoch: 6| Step: 1
Training loss: 3.793074131011963
Validation loss: 2.57792991463856

Epoch: 6| Step: 2
Training loss: 2.0519838333129883
Validation loss: 2.581147401563583

Epoch: 6| Step: 3
Training loss: 1.7071502208709717
Validation loss: 2.5728690431964014

Epoch: 6| Step: 4
Training loss: 2.176487922668457
Validation loss: 2.574088268382575

Epoch: 6| Step: 5
Training loss: 2.7367496490478516
Validation loss: 2.5745521104463966

Epoch: 6| Step: 6
Training loss: 2.5153284072875977
Validation loss: 2.5738423306454896

Epoch: 6| Step: 7
Training loss: 3.2834525108337402
Validation loss: 2.5758437238713747

Epoch: 6| Step: 8
Training loss: 2.275786876678467
Validation loss: 2.5773000691526677

Epoch: 6| Step: 9
Training loss: 3.014467716217041
Validation loss: 2.5867927971706597

Epoch: 6| Step: 10
Training loss: 2.574643611907959
Validation loss: 2.5924681950640935

Epoch: 6| Step: 11
Training loss: 3.4165914058685303
Validation loss: 2.602753008565595

Epoch: 6| Step: 12
Training loss: 3.106102466583252
Validation loss: 2.6047197875156196

Epoch: 6| Step: 13
Training loss: 3.7423832416534424
Validation loss: 2.579418341318766

Epoch: 39| Step: 0
Training loss: 3.1610093116760254
Validation loss: 2.5735586074090775

Epoch: 6| Step: 1
Training loss: 2.6795573234558105
Validation loss: 2.5657617763806413

Epoch: 6| Step: 2
Training loss: 2.331540584564209
Validation loss: 2.575931672127016

Epoch: 6| Step: 3
Training loss: 2.4850401878356934
Validation loss: 2.599941838172174

Epoch: 6| Step: 4
Training loss: 3.919621706008911
Validation loss: 2.5982344278725247

Epoch: 6| Step: 5
Training loss: 2.4066686630249023
Validation loss: 2.575232980071857

Epoch: 6| Step: 6
Training loss: 2.6142988204956055
Validation loss: 2.56332222107918

Epoch: 6| Step: 7
Training loss: 2.926804542541504
Validation loss: 2.5635268944565968

Epoch: 6| Step: 8
Training loss: 2.495696783065796
Validation loss: 2.573100548918529

Epoch: 6| Step: 9
Training loss: 3.010472536087036
Validation loss: 2.579111599153088

Epoch: 6| Step: 10
Training loss: 2.196568727493286
Validation loss: 2.585802567902432

Epoch: 6| Step: 11
Training loss: 3.2278101444244385
Validation loss: 2.5877220681918565

Epoch: 6| Step: 12
Training loss: 2.1769726276397705
Validation loss: 2.59130887575047

Epoch: 6| Step: 13
Training loss: 3.305419921875
Validation loss: 2.595251965266402

Epoch: 40| Step: 0
Training loss: 3.042188882827759
Validation loss: 2.602425349655972

Epoch: 6| Step: 1
Training loss: 2.8188576698303223
Validation loss: 2.6208357785337713

Epoch: 6| Step: 2
Training loss: 2.7599105834960938
Validation loss: 2.623777779199744

Epoch: 6| Step: 3
Training loss: 2.129974842071533
Validation loss: 2.6257292160423855

Epoch: 6| Step: 4
Training loss: 2.4648277759552
Validation loss: 2.6211142770705687

Epoch: 6| Step: 5
Training loss: 3.015655279159546
Validation loss: 2.623219874597365

Epoch: 6| Step: 6
Training loss: 2.198659658432007
Validation loss: 2.6200769819239134

Epoch: 6| Step: 7
Training loss: 3.0257742404937744
Validation loss: 2.6163370558010635

Epoch: 6| Step: 8
Training loss: 4.104818344116211
Validation loss: 2.614933847099222

Epoch: 6| Step: 9
Training loss: 3.0375125408172607
Validation loss: 2.6159315775799494

Epoch: 6| Step: 10
Training loss: 2.3412647247314453
Validation loss: 2.610149291253859

Epoch: 6| Step: 11
Training loss: 2.880403995513916
Validation loss: 2.6066898581802205

Epoch: 6| Step: 12
Training loss: 1.9844056367874146
Validation loss: 2.6035082083876415

Epoch: 6| Step: 13
Training loss: 3.578732490539551
Validation loss: 2.5898989708192888

Epoch: 41| Step: 0
Training loss: 3.0095067024230957
Validation loss: 2.574264621221891

Epoch: 6| Step: 1
Training loss: 2.914681911468506
Validation loss: 2.5637179984841296

Epoch: 6| Step: 2
Training loss: 3.1262412071228027
Validation loss: 2.5742071059442337

Epoch: 6| Step: 3
Training loss: 2.9186787605285645
Validation loss: 2.594885677419683

Epoch: 6| Step: 4
Training loss: 2.850248336791992
Validation loss: 2.659853078985727

Epoch: 6| Step: 5
Training loss: 2.786752939224243
Validation loss: 2.6504124518363708

Epoch: 6| Step: 6
Training loss: 3.0108320713043213
Validation loss: 2.6030547849593626

Epoch: 6| Step: 7
Training loss: 3.4639694690704346
Validation loss: 2.573043164386544

Epoch: 6| Step: 8
Training loss: 3.185854911804199
Validation loss: 2.5508390062598774

Epoch: 6| Step: 9
Training loss: 2.09908390045166
Validation loss: 2.551943345736432

Epoch: 6| Step: 10
Training loss: 2.481940746307373
Validation loss: 2.5616097450256348

Epoch: 6| Step: 11
Training loss: 2.0709235668182373
Validation loss: 2.57319147868823

Epoch: 6| Step: 12
Training loss: 2.607006549835205
Validation loss: 2.5814579456083235

Epoch: 6| Step: 13
Training loss: 2.194220781326294
Validation loss: 2.5955684133755264

Epoch: 42| Step: 0
Training loss: 2.8096165657043457
Validation loss: 2.595548729742727

Epoch: 6| Step: 1
Training loss: 3.022470474243164
Validation loss: 2.5976662046165875

Epoch: 6| Step: 2
Training loss: 2.4078502655029297
Validation loss: 2.5757525044102825

Epoch: 6| Step: 3
Training loss: 2.38732647895813
Validation loss: 2.5709774981262865

Epoch: 6| Step: 4
Training loss: 2.148695707321167
Validation loss: 2.565340362569337

Epoch: 6| Step: 5
Training loss: 3.1509511470794678
Validation loss: 2.5689641788441646

Epoch: 6| Step: 6
Training loss: 3.3961050510406494
Validation loss: 2.5597788877384637

Epoch: 6| Step: 7
Training loss: 3.00535249710083
Validation loss: 2.5560343778261574

Epoch: 6| Step: 8
Training loss: 2.975494623184204
Validation loss: 2.559720036804035

Epoch: 6| Step: 9
Training loss: 2.996192216873169
Validation loss: 2.567226004856889

Epoch: 6| Step: 10
Training loss: 3.412341594696045
Validation loss: 2.564208553683373

Epoch: 6| Step: 11
Training loss: 2.5228540897369385
Validation loss: 2.5639439526424614

Epoch: 6| Step: 12
Training loss: 1.941633701324463
Validation loss: 2.563198830491753

Epoch: 6| Step: 13
Training loss: 2.394819974899292
Validation loss: 2.554076281926965

Epoch: 43| Step: 0
Training loss: 1.954819917678833
Validation loss: 2.551164919330228

Epoch: 6| Step: 1
Training loss: 2.5244059562683105
Validation loss: 2.549886711182133

Epoch: 6| Step: 2
Training loss: 2.998096466064453
Validation loss: 2.546785699423923

Epoch: 6| Step: 3
Training loss: 2.853734016418457
Validation loss: 2.5414823588504585

Epoch: 6| Step: 4
Training loss: 3.6349308490753174
Validation loss: 2.5420558555151826

Epoch: 6| Step: 5
Training loss: 2.7650070190429688
Validation loss: 2.542349697441183

Epoch: 6| Step: 6
Training loss: 2.96142315864563
Validation loss: 2.5399316459573726

Epoch: 6| Step: 7
Training loss: 1.7770402431488037
Validation loss: 2.5373049218167543

Epoch: 6| Step: 8
Training loss: 3.5434584617614746
Validation loss: 2.5390350510997157

Epoch: 6| Step: 9
Training loss: 2.3166985511779785
Validation loss: 2.540588535288329

Epoch: 6| Step: 10
Training loss: 2.9278690814971924
Validation loss: 2.5338825538594234

Epoch: 6| Step: 11
Training loss: 2.3536322116851807
Validation loss: 2.5346711169007006

Epoch: 6| Step: 12
Training loss: 2.5576162338256836
Validation loss: 2.534448754402899

Epoch: 6| Step: 13
Training loss: 3.5095818042755127
Validation loss: 2.539197729479882

Epoch: 44| Step: 0
Training loss: 2.343841314315796
Validation loss: 2.545131814095282

Epoch: 6| Step: 1
Training loss: 2.9191818237304688
Validation loss: 2.5462496357579387

Epoch: 6| Step: 2
Training loss: 3.211592435836792
Validation loss: 2.546666376052364

Epoch: 6| Step: 3
Training loss: 3.277860403060913
Validation loss: 2.547031469242547

Epoch: 6| Step: 4
Training loss: 2.1439037322998047
Validation loss: 2.548072527813655

Epoch: 6| Step: 5
Training loss: 3.12847900390625
Validation loss: 2.547405929975612

Epoch: 6| Step: 6
Training loss: 3.300631046295166
Validation loss: 2.549505720856369

Epoch: 6| Step: 7
Training loss: 2.241854667663574
Validation loss: 2.539637247721354

Epoch: 6| Step: 8
Training loss: 2.4033203125
Validation loss: 2.532865108982209

Epoch: 6| Step: 9
Training loss: 2.6145212650299072
Validation loss: 2.5301781110866095

Epoch: 6| Step: 10
Training loss: 2.817084789276123
Validation loss: 2.5308704171129452

Epoch: 6| Step: 11
Training loss: 2.0804624557495117
Validation loss: 2.5268904906447216

Epoch: 6| Step: 12
Training loss: 2.5571796894073486
Validation loss: 2.5297515994759014

Epoch: 6| Step: 13
Training loss: 3.548072338104248
Validation loss: 2.528357057161229

Epoch: 45| Step: 0
Training loss: 2.651087522506714
Validation loss: 2.52731369644083

Epoch: 6| Step: 1
Training loss: 2.551506519317627
Validation loss: 2.530107751969368

Epoch: 6| Step: 2
Training loss: 2.1899325847625732
Validation loss: 2.5324032973217707

Epoch: 6| Step: 3
Training loss: 2.657005786895752
Validation loss: 2.5307439424658336

Epoch: 6| Step: 4
Training loss: 2.398005485534668
Validation loss: 2.5310387560116347

Epoch: 6| Step: 5
Training loss: 2.4554948806762695
Validation loss: 2.5305980431136263

Epoch: 6| Step: 6
Training loss: 3.174453020095825
Validation loss: 2.528996657299739

Epoch: 6| Step: 7
Training loss: 2.418415069580078
Validation loss: 2.527350305229105

Epoch: 6| Step: 8
Training loss: 3.2990684509277344
Validation loss: 2.525668539026732

Epoch: 6| Step: 9
Training loss: 3.3863070011138916
Validation loss: 2.540325241704141

Epoch: 6| Step: 10
Training loss: 2.5011954307556152
Validation loss: 2.5425658277285996

Epoch: 6| Step: 11
Training loss: 2.6164286136627197
Validation loss: 2.5621964675123974

Epoch: 6| Step: 12
Training loss: 3.105835199356079
Validation loss: 2.572565370990384

Epoch: 6| Step: 13
Training loss: 2.8792219161987305
Validation loss: 2.5760477050658195

Epoch: 46| Step: 0
Training loss: 3.1887922286987305
Validation loss: 2.56823738416036

Epoch: 6| Step: 1
Training loss: 2.010817766189575
Validation loss: 2.549073996082429

Epoch: 6| Step: 2
Training loss: 3.0948610305786133
Validation loss: 2.5339994071632304

Epoch: 6| Step: 3
Training loss: 2.070692777633667
Validation loss: 2.5242906052579164

Epoch: 6| Step: 4
Training loss: 1.9124655723571777
Validation loss: 2.524837896388064

Epoch: 6| Step: 5
Training loss: 3.2571370601654053
Validation loss: 2.5245176387089554

Epoch: 6| Step: 6
Training loss: 2.218940496444702
Validation loss: 2.5273458137307117

Epoch: 6| Step: 7
Training loss: 2.7893552780151367
Validation loss: 2.5289104036105576

Epoch: 6| Step: 8
Training loss: 2.5473520755767822
Validation loss: 2.5294208834248204

Epoch: 6| Step: 9
Training loss: 3.2831389904022217
Validation loss: 2.531081594446654

Epoch: 6| Step: 10
Training loss: 3.8033053874969482
Validation loss: 2.5240373611450195

Epoch: 6| Step: 11
Training loss: 2.5243709087371826
Validation loss: 2.523517903461251

Epoch: 6| Step: 12
Training loss: 3.0197486877441406
Validation loss: 2.51993207264972

Epoch: 6| Step: 13
Training loss: 2.2957422733306885
Validation loss: 2.522404193878174

Epoch: 47| Step: 0
Training loss: 2.7388076782226562
Validation loss: 2.518120563158425

Epoch: 6| Step: 1
Training loss: 3.0546023845672607
Validation loss: 2.5211901536551853

Epoch: 6| Step: 2
Training loss: 2.2136025428771973
Validation loss: 2.519316875806419

Epoch: 6| Step: 3
Training loss: 2.7648990154266357
Validation loss: 2.5171837819519864

Epoch: 6| Step: 4
Training loss: 1.9683856964111328
Validation loss: 2.5185731739126225

Epoch: 6| Step: 5
Training loss: 2.99550199508667
Validation loss: 2.5231120381304013

Epoch: 6| Step: 6
Training loss: 3.457122325897217
Validation loss: 2.5259690246274396

Epoch: 6| Step: 7
Training loss: 2.852989435195923
Validation loss: 2.521622488575597

Epoch: 6| Step: 8
Training loss: 2.4798574447631836
Validation loss: 2.5254625299925446

Epoch: 6| Step: 9
Training loss: 2.530683994293213
Validation loss: 2.53037751618252

Epoch: 6| Step: 10
Training loss: 2.8550004959106445
Validation loss: 2.5238671289977206

Epoch: 6| Step: 11
Training loss: 2.2790653705596924
Validation loss: 2.5202811007858603

Epoch: 6| Step: 12
Training loss: 2.636695623397827
Validation loss: 2.524319848706645

Epoch: 6| Step: 13
Training loss: 3.6746020317077637
Validation loss: 2.520866419679375

Epoch: 48| Step: 0
Training loss: 2.1464760303497314
Validation loss: 2.520381566016905

Epoch: 6| Step: 1
Training loss: 1.8411550521850586
Validation loss: 2.5134565445684616

Epoch: 6| Step: 2
Training loss: 2.096264362335205
Validation loss: 2.508515375916676

Epoch: 6| Step: 3
Training loss: 2.8697080612182617
Validation loss: 2.509788236310405

Epoch: 6| Step: 4
Training loss: 2.4118943214416504
Validation loss: 2.5065837137160765

Epoch: 6| Step: 5
Training loss: 2.676440715789795
Validation loss: 2.5168854908276628

Epoch: 6| Step: 6
Training loss: 3.629831314086914
Validation loss: 2.512703977605348

Epoch: 6| Step: 7
Training loss: 2.770543098449707
Validation loss: 2.5051498720722813

Epoch: 6| Step: 8
Training loss: 2.835005044937134
Validation loss: 2.494984203769315

Epoch: 6| Step: 9
Training loss: 2.341444730758667
Validation loss: 2.4923770350794636

Epoch: 6| Step: 10
Training loss: 2.515735626220703
Validation loss: 2.490475118801158

Epoch: 6| Step: 11
Training loss: 3.6177523136138916
Validation loss: 2.492007019699261

Epoch: 6| Step: 12
Training loss: 3.257838726043701
Validation loss: 2.495443223625101

Epoch: 6| Step: 13
Training loss: 2.931466817855835
Validation loss: 2.4976779107124574

Epoch: 49| Step: 0
Training loss: 2.7320308685302734
Validation loss: 2.4996574053200344

Epoch: 6| Step: 1
Training loss: 2.660700798034668
Validation loss: 2.499004371704594

Epoch: 6| Step: 2
Training loss: 1.853916049003601
Validation loss: 2.5000785191853843

Epoch: 6| Step: 3
Training loss: 2.7146196365356445
Validation loss: 2.4920699083676903

Epoch: 6| Step: 4
Training loss: 2.4565720558166504
Validation loss: 2.5005555511802755

Epoch: 6| Step: 5
Training loss: 2.2808332443237305
Validation loss: 2.4982124990032566

Epoch: 6| Step: 6
Training loss: 3.3297863006591797
Validation loss: 2.501602716343377

Epoch: 6| Step: 7
Training loss: 3.4174861907958984
Validation loss: 2.498559877436648

Epoch: 6| Step: 8
Training loss: 2.801673412322998
Validation loss: 2.4936082337492254

Epoch: 6| Step: 9
Training loss: 3.257094144821167
Validation loss: 2.4943671662320375

Epoch: 6| Step: 10
Training loss: 2.3142285346984863
Validation loss: 2.488782867308586

Epoch: 6| Step: 11
Training loss: 2.8996071815490723
Validation loss: 2.4816798984363513

Epoch: 6| Step: 12
Training loss: 2.471163749694824
Validation loss: 2.4859638393566175

Epoch: 6| Step: 13
Training loss: 2.504716157913208
Validation loss: 2.4809736820959274

Epoch: 50| Step: 0
Training loss: 1.9577491283416748
Validation loss: 2.48428056316991

Epoch: 6| Step: 1
Training loss: 2.4278781414031982
Validation loss: 2.4838838602906916

Epoch: 6| Step: 2
Training loss: 2.262821912765503
Validation loss: 2.4861147224262194

Epoch: 6| Step: 3
Training loss: 3.562553882598877
Validation loss: 2.4885068990850963

Epoch: 6| Step: 4
Training loss: 2.536881923675537
Validation loss: 2.4882895972139094

Epoch: 6| Step: 5
Training loss: 2.7141475677490234
Validation loss: 2.4890179813549085

Epoch: 6| Step: 6
Training loss: 3.027071475982666
Validation loss: 2.4846447231949016

Epoch: 6| Step: 7
Training loss: 2.362943172454834
Validation loss: 2.4823384361882366

Epoch: 6| Step: 8
Training loss: 2.720881462097168
Validation loss: 2.481447399303477

Epoch: 6| Step: 9
Training loss: 2.875850200653076
Validation loss: 2.482025343884704

Epoch: 6| Step: 10
Training loss: 2.628249406814575
Validation loss: 2.482347020538904

Epoch: 6| Step: 11
Training loss: 3.425886392593384
Validation loss: 2.4836573011131695

Epoch: 6| Step: 12
Training loss: 2.7414841651916504
Validation loss: 2.478573827333348

Epoch: 6| Step: 13
Training loss: 2.2608861923217773
Validation loss: 2.4819872046029694

Epoch: 51| Step: 0
Training loss: 2.198017120361328
Validation loss: 2.4788394897214827

Epoch: 6| Step: 1
Training loss: 2.783933639526367
Validation loss: 2.4771343123528267

Epoch: 6| Step: 2
Training loss: 2.8817458152770996
Validation loss: 2.478578144504178

Epoch: 6| Step: 3
Training loss: 2.9580750465393066
Validation loss: 2.478539715531052

Epoch: 6| Step: 4
Training loss: 2.1212968826293945
Validation loss: 2.4893452172638266

Epoch: 6| Step: 5
Training loss: 2.719296932220459
Validation loss: 2.4847865361039356

Epoch: 6| Step: 6
Training loss: 2.405449628829956
Validation loss: 2.48181406400537

Epoch: 6| Step: 7
Training loss: 3.415748357772827
Validation loss: 2.485075540440057

Epoch: 6| Step: 8
Training loss: 2.4733028411865234
Validation loss: 2.482609737303949

Epoch: 6| Step: 9
Training loss: 2.4459757804870605
Validation loss: 2.4946028852975495

Epoch: 6| Step: 10
Training loss: 2.7581522464752197
Validation loss: 2.5040681746698197

Epoch: 6| Step: 11
Training loss: 2.9632389545440674
Validation loss: 2.512032344777097

Epoch: 6| Step: 12
Training loss: 2.8702964782714844
Validation loss: 2.4906788718315864

Epoch: 6| Step: 13
Training loss: 2.7195169925689697
Validation loss: 2.474272402383948

Epoch: 52| Step: 0
Training loss: 2.5225751399993896
Validation loss: 2.475466525682839

Epoch: 6| Step: 1
Training loss: 2.643979072570801
Validation loss: 2.4708971772142636

Epoch: 6| Step: 2
Training loss: 2.823035955429077
Validation loss: 2.471813073722265

Epoch: 6| Step: 3
Training loss: 2.4513461589813232
Validation loss: 2.4706258414894022

Epoch: 6| Step: 4
Training loss: 2.369168281555176
Validation loss: 2.4697561853675434

Epoch: 6| Step: 5
Training loss: 2.304276466369629
Validation loss: 2.470318578904675

Epoch: 6| Step: 6
Training loss: 2.6827640533447266
Validation loss: 2.470850941955402

Epoch: 6| Step: 7
Training loss: 2.8191933631896973
Validation loss: 2.472357157737978

Epoch: 6| Step: 8
Training loss: 2.571282386779785
Validation loss: 2.4718769493923394

Epoch: 6| Step: 9
Training loss: 2.538109540939331
Validation loss: 2.4717388281258206

Epoch: 6| Step: 10
Training loss: 3.3470053672790527
Validation loss: 2.4735022821734027

Epoch: 6| Step: 11
Training loss: 2.7671751976013184
Validation loss: 2.477075133272397

Epoch: 6| Step: 12
Training loss: 2.765064239501953
Validation loss: 2.475516016765307

Epoch: 6| Step: 13
Training loss: 3.1541478633880615
Validation loss: 2.4758903211162937

Epoch: 53| Step: 0
Training loss: 1.7351521253585815
Validation loss: 2.4789839354894494

Epoch: 6| Step: 1
Training loss: 2.9705722332000732
Validation loss: 2.479400873184204

Epoch: 6| Step: 2
Training loss: 2.2881181240081787
Validation loss: 2.4785343370129986

Epoch: 6| Step: 3
Training loss: 2.073349952697754
Validation loss: 2.475739335501066

Epoch: 6| Step: 4
Training loss: 3.1903717517852783
Validation loss: 2.476109529054293

Epoch: 6| Step: 5
Training loss: 2.949838638305664
Validation loss: 2.4763439034902923

Epoch: 6| Step: 6
Training loss: 3.159785509109497
Validation loss: 2.4823487112599034

Epoch: 6| Step: 7
Training loss: 2.742969512939453
Validation loss: 2.478994672016431

Epoch: 6| Step: 8
Training loss: 2.3822107315063477
Validation loss: 2.477357256797052

Epoch: 6| Step: 9
Training loss: 2.4868922233581543
Validation loss: 2.4774282978427027

Epoch: 6| Step: 10
Training loss: 2.990668296813965
Validation loss: 2.4852279373394546

Epoch: 6| Step: 11
Training loss: 2.5666098594665527
Validation loss: 2.479329961602406

Epoch: 6| Step: 12
Training loss: 3.147198438644409
Validation loss: 2.480175725875362

Epoch: 6| Step: 13
Training loss: 3.052050828933716
Validation loss: 2.4816717050408803

Epoch: 54| Step: 0
Training loss: 2.4808332920074463
Validation loss: 2.474928814877746

Epoch: 6| Step: 1
Training loss: 2.1033592224121094
Validation loss: 2.4726910950035177

Epoch: 6| Step: 2
Training loss: 2.4196290969848633
Validation loss: 2.4708912423861924

Epoch: 6| Step: 3
Training loss: 2.6361207962036133
Validation loss: 2.4699962292948077

Epoch: 6| Step: 4
Training loss: 2.8160312175750732
Validation loss: 2.478495023583853

Epoch: 6| Step: 5
Training loss: 2.934600830078125
Validation loss: 2.481336050136115

Epoch: 6| Step: 6
Training loss: 3.758370876312256
Validation loss: 2.47558658353744

Epoch: 6| Step: 7
Training loss: 2.8278112411499023
Validation loss: 2.4693234018100205

Epoch: 6| Step: 8
Training loss: 2.0502731800079346
Validation loss: 2.465303736348306

Epoch: 6| Step: 9
Training loss: 2.571460247039795
Validation loss: 2.4613933204322733

Epoch: 6| Step: 10
Training loss: 2.5197336673736572
Validation loss: 2.4600794930611887

Epoch: 6| Step: 11
Training loss: 2.9220337867736816
Validation loss: 2.4624775404571206

Epoch: 6| Step: 12
Training loss: 2.874929904937744
Validation loss: 2.4667055260750557

Epoch: 6| Step: 13
Training loss: 2.4986751079559326
Validation loss: 2.4635013380358295

Epoch: 55| Step: 0
Training loss: 2.579860210418701
Validation loss: 2.4614869753519693

Epoch: 6| Step: 1
Training loss: 3.058558940887451
Validation loss: 2.462086331459784

Epoch: 6| Step: 2
Training loss: 2.1268467903137207
Validation loss: 2.4629555107444845

Epoch: 6| Step: 3
Training loss: 3.2227988243103027
Validation loss: 2.464343429893576

Epoch: 6| Step: 4
Training loss: 2.2892937660217285
Validation loss: 2.463346617196196

Epoch: 6| Step: 5
Training loss: 2.387446403503418
Validation loss: 2.466538731769849

Epoch: 6| Step: 6
Training loss: 2.4302210807800293
Validation loss: 2.4665557825437157

Epoch: 6| Step: 7
Training loss: 2.33271861076355
Validation loss: 2.470000651574904

Epoch: 6| Step: 8
Training loss: 3.2040562629699707
Validation loss: 2.4706406875323226

Epoch: 6| Step: 9
Training loss: 2.869626998901367
Validation loss: 2.46891196825171

Epoch: 6| Step: 10
Training loss: 2.6204185485839844
Validation loss: 2.472898103857553

Epoch: 6| Step: 11
Training loss: 3.3709354400634766
Validation loss: 2.472171788574547

Epoch: 6| Step: 12
Training loss: 2.222662925720215
Validation loss: 2.4679205186905397

Epoch: 6| Step: 13
Training loss: 2.706118106842041
Validation loss: 2.4703146975527526

Epoch: 56| Step: 0
Training loss: 2.3461532592773438
Validation loss: 2.4596005408994612

Epoch: 6| Step: 1
Training loss: 3.1729512214660645
Validation loss: 2.456424372170561

Epoch: 6| Step: 2
Training loss: 2.818359851837158
Validation loss: 2.4559236277816114

Epoch: 6| Step: 3
Training loss: 2.9445700645446777
Validation loss: 2.4560383673637145

Epoch: 6| Step: 4
Training loss: 2.7971255779266357
Validation loss: 2.4550541652146207

Epoch: 6| Step: 5
Training loss: 2.3742196559906006
Validation loss: 2.46106356446461

Epoch: 6| Step: 6
Training loss: 3.0345780849456787
Validation loss: 2.462094453073317

Epoch: 6| Step: 7
Training loss: 2.1368484497070312
Validation loss: 2.4595526905469995

Epoch: 6| Step: 8
Training loss: 2.426917791366577
Validation loss: 2.4576944484505603

Epoch: 6| Step: 9
Training loss: 2.0812554359436035
Validation loss: 2.455743476908694

Epoch: 6| Step: 10
Training loss: 2.8814921379089355
Validation loss: 2.457276180226316

Epoch: 6| Step: 11
Training loss: 2.804746150970459
Validation loss: 2.4580906668016986

Epoch: 6| Step: 12
Training loss: 3.217252731323242
Validation loss: 2.4625002696949947

Epoch: 6| Step: 13
Training loss: 2.1983187198638916
Validation loss: 2.4623857698132916

Epoch: 57| Step: 0
Training loss: 1.6637898683547974
Validation loss: 2.4679526654622888

Epoch: 6| Step: 1
Training loss: 3.153048276901245
Validation loss: 2.4771718940427228

Epoch: 6| Step: 2
Training loss: 2.283437728881836
Validation loss: 2.4818675415490263

Epoch: 6| Step: 3
Training loss: 2.3948915004730225
Validation loss: 2.4844998928808395

Epoch: 6| Step: 4
Training loss: 3.0973126888275146
Validation loss: 2.486160183465609

Epoch: 6| Step: 5
Training loss: 3.3714141845703125
Validation loss: 2.466336416941817

Epoch: 6| Step: 6
Training loss: 2.445645332336426
Validation loss: 2.457514170677431

Epoch: 6| Step: 7
Training loss: 2.724369525909424
Validation loss: 2.4569060520459245

Epoch: 6| Step: 8
Training loss: 3.480130195617676
Validation loss: 2.4520517113388225

Epoch: 6| Step: 9
Training loss: 2.3680365085601807
Validation loss: 2.4505638127685874

Epoch: 6| Step: 10
Training loss: 2.7764508724212646
Validation loss: 2.4552245140075684

Epoch: 6| Step: 11
Training loss: 2.1596570014953613
Validation loss: 2.45664958800039

Epoch: 6| Step: 12
Training loss: 2.9241738319396973
Validation loss: 2.4539491027914067

Epoch: 6| Step: 13
Training loss: 2.7445952892303467
Validation loss: 2.4531370311655025

Epoch: 58| Step: 0
Training loss: 2.96821928024292
Validation loss: 2.4508588993421165

Epoch: 6| Step: 1
Training loss: 2.3848624229431152
Validation loss: 2.453199135359897

Epoch: 6| Step: 2
Training loss: 2.8363656997680664
Validation loss: 2.461562733496389

Epoch: 6| Step: 3
Training loss: 2.640096426010132
Validation loss: 2.4692760026583107

Epoch: 6| Step: 4
Training loss: 2.1927671432495117
Validation loss: 2.4921930092637257

Epoch: 6| Step: 5
Training loss: 2.9013869762420654
Validation loss: 2.502728454528316

Epoch: 6| Step: 6
Training loss: 2.2179951667785645
Validation loss: 2.5142092602227324

Epoch: 6| Step: 7
Training loss: 2.8848977088928223
Validation loss: 2.512946605682373

Epoch: 6| Step: 8
Training loss: 2.6247739791870117
Validation loss: 2.5005499803891746

Epoch: 6| Step: 9
Training loss: 2.683720111846924
Validation loss: 2.4768885053614134

Epoch: 6| Step: 10
Training loss: 2.0904126167297363
Validation loss: 2.4603955822606243

Epoch: 6| Step: 11
Training loss: 2.483673572540283
Validation loss: 2.4495239719267814

Epoch: 6| Step: 12
Training loss: 3.560469627380371
Validation loss: 2.446731423818937

Epoch: 6| Step: 13
Training loss: 3.071251392364502
Validation loss: 2.447912508441556

Epoch: 59| Step: 0
Training loss: 3.091468095779419
Validation loss: 2.4490441019817064

Epoch: 6| Step: 1
Training loss: 2.4261975288391113
Validation loss: 2.4479930118847917

Epoch: 6| Step: 2
Training loss: 2.031251907348633
Validation loss: 2.4486562000807894

Epoch: 6| Step: 3
Training loss: 3.1991703510284424
Validation loss: 2.452739525866765

Epoch: 6| Step: 4
Training loss: 2.1234772205352783
Validation loss: 2.456385240759901

Epoch: 6| Step: 5
Training loss: 2.61478853225708
Validation loss: 2.4635508598819857

Epoch: 6| Step: 6
Training loss: 2.907384157180786
Validation loss: 2.4658359045623452

Epoch: 6| Step: 7
Training loss: 3.172424793243408
Validation loss: 2.4670897606880433

Epoch: 6| Step: 8
Training loss: 2.6572659015655518
Validation loss: 2.4689635833104453

Epoch: 6| Step: 9
Training loss: 1.9464551210403442
Validation loss: 2.463036291060909

Epoch: 6| Step: 10
Training loss: 2.4610326290130615
Validation loss: 2.461090095581547

Epoch: 6| Step: 11
Training loss: 3.310807704925537
Validation loss: 2.472506030913322

Epoch: 6| Step: 12
Training loss: 3.5498569011688232
Validation loss: 2.4769573288579143

Epoch: 6| Step: 13
Training loss: 1.3690156936645508
Validation loss: 2.474582682373703

Epoch: 60| Step: 0
Training loss: 2.1120922565460205
Validation loss: 2.4736725745662564

Epoch: 6| Step: 1
Training loss: 3.223576068878174
Validation loss: 2.4635587789679088

Epoch: 6| Step: 2
Training loss: 2.063603401184082
Validation loss: 2.4562366649668705

Epoch: 6| Step: 3
Training loss: 3.1500229835510254
Validation loss: 2.450920679235971

Epoch: 6| Step: 4
Training loss: 2.2861194610595703
Validation loss: 2.4468890492634108

Epoch: 6| Step: 5
Training loss: 2.5168352127075195
Validation loss: 2.44906106046451

Epoch: 6| Step: 6
Training loss: 3.5637736320495605
Validation loss: 2.4512033347160584

Epoch: 6| Step: 7
Training loss: 2.2466273307800293
Validation loss: 2.4413480451030116

Epoch: 6| Step: 8
Training loss: 2.181239604949951
Validation loss: 2.444804609462779

Epoch: 6| Step: 9
Training loss: 2.6774888038635254
Validation loss: 2.439427565502864

Epoch: 6| Step: 10
Training loss: 2.8370351791381836
Validation loss: 2.439309608551764

Epoch: 6| Step: 11
Training loss: 3.1099133491516113
Validation loss: 2.4380035682391097

Epoch: 6| Step: 12
Training loss: 2.968730926513672
Validation loss: 2.441575570773053

Epoch: 6| Step: 13
Training loss: 1.9919153451919556
Validation loss: 2.4405321100706696

Epoch: 61| Step: 0
Training loss: 2.577147960662842
Validation loss: 2.43941774675923

Epoch: 6| Step: 1
Training loss: 2.586618185043335
Validation loss: 2.4439677474319295

Epoch: 6| Step: 2
Training loss: 2.7807953357696533
Validation loss: 2.4429684864577426

Epoch: 6| Step: 3
Training loss: 2.130016803741455
Validation loss: 2.447528459692514

Epoch: 6| Step: 4
Training loss: 2.5830729007720947
Validation loss: 2.448695518637216

Epoch: 6| Step: 5
Training loss: 4.033397674560547
Validation loss: 2.447397626856322

Epoch: 6| Step: 6
Training loss: 2.131990909576416
Validation loss: 2.44707295971532

Epoch: 6| Step: 7
Training loss: 1.7787402868270874
Validation loss: 2.453466921724299

Epoch: 6| Step: 8
Training loss: 3.2250399589538574
Validation loss: 2.45255042916985

Epoch: 6| Step: 9
Training loss: 2.6521077156066895
Validation loss: 2.4610083385180404

Epoch: 6| Step: 10
Training loss: 2.680506706237793
Validation loss: 2.4519840517351703

Epoch: 6| Step: 11
Training loss: 1.7404630184173584
Validation loss: 2.4466340593112412

Epoch: 6| Step: 12
Training loss: 2.861647129058838
Validation loss: 2.4464991118318293

Epoch: 6| Step: 13
Training loss: 4.21960973739624
Validation loss: 2.440344077284618

Epoch: 62| Step: 0
Training loss: 3.048992395401001
Validation loss: 2.438013046018539

Epoch: 6| Step: 1
Training loss: 1.8456538915634155
Validation loss: 2.44036425570006

Epoch: 6| Step: 2
Training loss: 3.2821786403656006
Validation loss: 2.4345059907564552

Epoch: 6| Step: 3
Training loss: 2.0693376064300537
Validation loss: 2.431957403818766

Epoch: 6| Step: 4
Training loss: 2.327786684036255
Validation loss: 2.4326533591875465

Epoch: 6| Step: 5
Training loss: 2.77193546295166
Validation loss: 2.433968790115849

Epoch: 6| Step: 6
Training loss: 2.8363866806030273
Validation loss: 2.4338557079274166

Epoch: 6| Step: 7
Training loss: 2.001708984375
Validation loss: 2.4398161365139868

Epoch: 6| Step: 8
Training loss: 2.9059035778045654
Validation loss: 2.4501824020057597

Epoch: 6| Step: 9
Training loss: 2.5422682762145996
Validation loss: 2.4578600263082855

Epoch: 6| Step: 10
Training loss: 2.632568120956421
Validation loss: 2.4676011531583724

Epoch: 6| Step: 11
Training loss: 2.703748941421509
Validation loss: 2.477791775939285

Epoch: 6| Step: 12
Training loss: 3.2437026500701904
Validation loss: 2.4862872708228325

Epoch: 6| Step: 13
Training loss: 3.515997886657715
Validation loss: 2.489350744473037

Epoch: 63| Step: 0
Training loss: 3.0286502838134766
Validation loss: 2.4722945638882217

Epoch: 6| Step: 1
Training loss: 2.71441650390625
Validation loss: 2.4677501596430296

Epoch: 6| Step: 2
Training loss: 2.3855695724487305
Validation loss: 2.449285617438696

Epoch: 6| Step: 3
Training loss: 1.891216516494751
Validation loss: 2.4412397261588805

Epoch: 6| Step: 4
Training loss: 2.670396327972412
Validation loss: 2.436679588851108

Epoch: 6| Step: 5
Training loss: 2.7484660148620605
Validation loss: 2.429488084649527

Epoch: 6| Step: 6
Training loss: 2.5863800048828125
Validation loss: 2.43430588065937

Epoch: 6| Step: 7
Training loss: 2.879037857055664
Validation loss: 2.431476172580514

Epoch: 6| Step: 8
Training loss: 1.9079270362854004
Validation loss: 2.432258777720954

Epoch: 6| Step: 9
Training loss: 2.7282657623291016
Validation loss: 2.4274715787620953

Epoch: 6| Step: 10
Training loss: 2.4826459884643555
Validation loss: 2.4327303594158542

Epoch: 6| Step: 11
Training loss: 3.548677682876587
Validation loss: 2.433795311117685

Epoch: 6| Step: 12
Training loss: 2.959425449371338
Validation loss: 2.4369594948266142

Epoch: 6| Step: 13
Training loss: 2.5752906799316406
Validation loss: 2.4326643841240996

Epoch: 64| Step: 0
Training loss: 2.3576676845550537
Validation loss: 2.4327789429695375

Epoch: 6| Step: 1
Training loss: 2.2920751571655273
Validation loss: 2.4325763743410826

Epoch: 6| Step: 2
Training loss: 3.2790279388427734
Validation loss: 2.44119095289579

Epoch: 6| Step: 3
Training loss: 2.661555767059326
Validation loss: 2.4439838445314797

Epoch: 6| Step: 4
Training loss: 2.961454391479492
Validation loss: 2.447499362371301

Epoch: 6| Step: 5
Training loss: 2.168964147567749
Validation loss: 2.4431874495680614

Epoch: 6| Step: 6
Training loss: 2.9920318126678467
Validation loss: 2.4437762101491294

Epoch: 6| Step: 7
Training loss: 2.706716299057007
Validation loss: 2.436543458251543

Epoch: 6| Step: 8
Training loss: 2.5787487030029297
Validation loss: 2.4358995781149915

Epoch: 6| Step: 9
Training loss: 2.399949073791504
Validation loss: 2.4466198413602767

Epoch: 6| Step: 10
Training loss: 2.4726643562316895
Validation loss: 2.453332749746179

Epoch: 6| Step: 11
Training loss: 2.51232647895813
Validation loss: 2.45661336375821

Epoch: 6| Step: 12
Training loss: 2.9783568382263184
Validation loss: 2.4650771335888932

Epoch: 6| Step: 13
Training loss: 2.8253562450408936
Validation loss: 2.4927157125165387

Epoch: 65| Step: 0
Training loss: 2.7774500846862793
Validation loss: 2.475354089531847

Epoch: 6| Step: 1
Training loss: 1.8387243747711182
Validation loss: 2.447488095170708

Epoch: 6| Step: 2
Training loss: 2.7252089977264404
Validation loss: 2.4481365180784658

Epoch: 6| Step: 3
Training loss: 3.5272037982940674
Validation loss: 2.4600876326202066

Epoch: 6| Step: 4
Training loss: 2.895653247833252
Validation loss: 2.4771964293654247

Epoch: 6| Step: 5
Training loss: 3.6968746185302734
Validation loss: 2.478535380414737

Epoch: 6| Step: 6
Training loss: 2.7483749389648438
Validation loss: 2.470215948679114

Epoch: 6| Step: 7
Training loss: 1.9232838153839111
Validation loss: 2.4543895029252574

Epoch: 6| Step: 8
Training loss: 2.2884764671325684
Validation loss: 2.448072297598726

Epoch: 6| Step: 9
Training loss: 1.901955008506775
Validation loss: 2.43626590441632

Epoch: 6| Step: 10
Training loss: 2.945065498352051
Validation loss: 2.4308999507657942

Epoch: 6| Step: 11
Training loss: 2.346355676651001
Validation loss: 2.4333903430610575

Epoch: 6| Step: 12
Training loss: 2.960336446762085
Validation loss: 2.441277568058301

Epoch: 6| Step: 13
Training loss: 2.714982748031616
Validation loss: 2.4354007039018857

Epoch: 66| Step: 0
Training loss: 2.1339855194091797
Validation loss: 2.4337921193850938

Epoch: 6| Step: 1
Training loss: 2.3871233463287354
Validation loss: 2.436738419276412

Epoch: 6| Step: 2
Training loss: 3.5822832584381104
Validation loss: 2.4338783782015563

Epoch: 6| Step: 3
Training loss: 2.2913103103637695
Validation loss: 2.434403916840912

Epoch: 6| Step: 4
Training loss: 2.780441999435425
Validation loss: 2.439349756445936

Epoch: 6| Step: 5
Training loss: 2.36936354637146
Validation loss: 2.4452712151312057

Epoch: 6| Step: 6
Training loss: 2.6561837196350098
Validation loss: 2.4576417733264226

Epoch: 6| Step: 7
Training loss: 2.677797794342041
Validation loss: 2.465436581642397

Epoch: 6| Step: 8
Training loss: 2.655020236968994
Validation loss: 2.4500169651482695

Epoch: 6| Step: 9
Training loss: 2.677501678466797
Validation loss: 2.450094320440805

Epoch: 6| Step: 10
Training loss: 3.267364025115967
Validation loss: 2.448170651671707

Epoch: 6| Step: 11
Training loss: 2.325244188308716
Validation loss: 2.436614118596559

Epoch: 6| Step: 12
Training loss: 2.7039589881896973
Validation loss: 2.4288107656663462

Epoch: 6| Step: 13
Training loss: 2.840772867202759
Validation loss: 2.4298784861000637

Epoch: 67| Step: 0
Training loss: 3.1572370529174805
Validation loss: 2.427528635148079

Epoch: 6| Step: 1
Training loss: 2.589182138442993
Validation loss: 2.420253058915497

Epoch: 6| Step: 2
Training loss: 2.92807674407959
Validation loss: 2.421663030501335

Epoch: 6| Step: 3
Training loss: 2.243399143218994
Validation loss: 2.419478885589107

Epoch: 6| Step: 4
Training loss: 1.92439603805542
Validation loss: 2.418970287487071

Epoch: 6| Step: 5
Training loss: 2.7917351722717285
Validation loss: 2.416171504605201

Epoch: 6| Step: 6
Training loss: 3.1324141025543213
Validation loss: 2.416102606763122

Epoch: 6| Step: 7
Training loss: 3.0617122650146484
Validation loss: 2.4155176813884447

Epoch: 6| Step: 8
Training loss: 1.6565563678741455
Validation loss: 2.4159339909912436

Epoch: 6| Step: 9
Training loss: 2.7517690658569336
Validation loss: 2.4173133321987685

Epoch: 6| Step: 10
Training loss: 3.1801607608795166
Validation loss: 2.419274845430928

Epoch: 6| Step: 11
Training loss: 2.6948914527893066
Validation loss: 2.4184263419079524

Epoch: 6| Step: 12
Training loss: 2.4669840335845947
Validation loss: 2.422539734071301

Epoch: 6| Step: 13
Training loss: 2.3155672550201416
Validation loss: 2.430451113690612

Epoch: 68| Step: 0
Training loss: 3.187377452850342
Validation loss: 2.4417309376501266

Epoch: 6| Step: 1
Training loss: 3.024394989013672
Validation loss: 2.4582772152398222

Epoch: 6| Step: 2
Training loss: 2.490081310272217
Validation loss: 2.4544563370366252

Epoch: 6| Step: 3
Training loss: 2.8326730728149414
Validation loss: 2.451673392326601

Epoch: 6| Step: 4
Training loss: 2.7083888053894043
Validation loss: 2.444809159924907

Epoch: 6| Step: 5
Training loss: 2.3451294898986816
Validation loss: 2.4393770694732666

Epoch: 6| Step: 6
Training loss: 2.0487303733825684
Validation loss: 2.439857247055218

Epoch: 6| Step: 7
Training loss: 2.5253372192382812
Validation loss: 2.426570943606797

Epoch: 6| Step: 8
Training loss: 2.8241934776306152
Validation loss: 2.4294658758307017

Epoch: 6| Step: 9
Training loss: 2.749908924102783
Validation loss: 2.4300741046987553

Epoch: 6| Step: 10
Training loss: 2.328519105911255
Validation loss: 2.426173463944466

Epoch: 6| Step: 11
Training loss: 2.616321325302124
Validation loss: 2.4272614730301725

Epoch: 6| Step: 12
Training loss: 2.21195125579834
Validation loss: 2.426935221559258

Epoch: 6| Step: 13
Training loss: 3.578219413757324
Validation loss: 2.431622400078722

Epoch: 69| Step: 0
Training loss: 2.8580660820007324
Validation loss: 2.4160788751417592

Epoch: 6| Step: 1
Training loss: 1.8271183967590332
Validation loss: 2.419834401017876

Epoch: 6| Step: 2
Training loss: 2.9334006309509277
Validation loss: 2.4145360710800334

Epoch: 6| Step: 3
Training loss: 3.0203075408935547
Validation loss: 2.423301737795594

Epoch: 6| Step: 4
Training loss: 2.045433282852173
Validation loss: 2.41507060809802

Epoch: 6| Step: 5
Training loss: 2.8847460746765137
Validation loss: 2.4158138716092674

Epoch: 6| Step: 6
Training loss: 2.7890682220458984
Validation loss: 2.4142614538951586

Epoch: 6| Step: 7
Training loss: 2.7866528034210205
Validation loss: 2.4176779049699024

Epoch: 6| Step: 8
Training loss: 3.004450798034668
Validation loss: 2.4265226497445056

Epoch: 6| Step: 9
Training loss: 2.449759006500244
Validation loss: 2.418568108671455

Epoch: 6| Step: 10
Training loss: 2.5603890419006348
Validation loss: 2.424444839518557

Epoch: 6| Step: 11
Training loss: 2.4936869144439697
Validation loss: 2.4202266252169045

Epoch: 6| Step: 12
Training loss: 3.093158721923828
Validation loss: 2.4216495098606234

Epoch: 6| Step: 13
Training loss: 1.7181131839752197
Validation loss: 2.424227096701181

Epoch: 70| Step: 0
Training loss: 2.865044593811035
Validation loss: 2.4341771371902956

Epoch: 6| Step: 1
Training loss: 2.7342729568481445
Validation loss: 2.4234730658992643

Epoch: 6| Step: 2
Training loss: 2.3200840950012207
Validation loss: 2.4124308324629262

Epoch: 6| Step: 3
Training loss: 1.9811238050460815
Validation loss: 2.41554396255042

Epoch: 6| Step: 4
Training loss: 2.086984634399414
Validation loss: 2.4042182378871466

Epoch: 6| Step: 5
Training loss: 2.9011483192443848
Validation loss: 2.4047787766302786

Epoch: 6| Step: 6
Training loss: 3.1297667026519775
Validation loss: 2.4057274121110157

Epoch: 6| Step: 7
Training loss: 2.819016456604004
Validation loss: 2.405559257794452

Epoch: 6| Step: 8
Training loss: 2.737605094909668
Validation loss: 2.4041680097579956

Epoch: 6| Step: 9
Training loss: 2.993333339691162
Validation loss: 2.403460230878604

Epoch: 6| Step: 10
Training loss: 3.265338897705078
Validation loss: 2.40337973256265

Epoch: 6| Step: 11
Training loss: 2.3588037490844727
Validation loss: 2.4030388837219565

Epoch: 6| Step: 12
Training loss: 2.019132137298584
Validation loss: 2.4035636481418403

Epoch: 6| Step: 13
Training loss: 2.790618896484375
Validation loss: 2.4046100031945015

Epoch: 71| Step: 0
Training loss: 2.3458340167999268
Validation loss: 2.4069324257553264

Epoch: 6| Step: 1
Training loss: 2.4128317832946777
Validation loss: 2.412703060334729

Epoch: 6| Step: 2
Training loss: 2.578120231628418
Validation loss: 2.421162751413161

Epoch: 6| Step: 3
Training loss: 2.6428847312927246
Validation loss: 2.430166244506836

Epoch: 6| Step: 4
Training loss: 2.4978573322296143
Validation loss: 2.4334005694235525

Epoch: 6| Step: 5
Training loss: 2.9295217990875244
Validation loss: 2.434561098775556

Epoch: 6| Step: 6
Training loss: 2.891909122467041
Validation loss: 2.439185837263702

Epoch: 6| Step: 7
Training loss: 2.405311107635498
Validation loss: 2.4311791722492506

Epoch: 6| Step: 8
Training loss: 2.3832640647888184
Validation loss: 2.430871909664523

Epoch: 6| Step: 9
Training loss: 2.4451446533203125
Validation loss: 2.444771268034494

Epoch: 6| Step: 10
Training loss: 2.7168469429016113
Validation loss: 2.4323845627487346

Epoch: 6| Step: 11
Training loss: 2.6605396270751953
Validation loss: 2.434624436081097

Epoch: 6| Step: 12
Training loss: 2.366438388824463
Validation loss: 2.4330576389066634

Epoch: 6| Step: 13
Training loss: 4.17692232131958
Validation loss: 2.41825698268029

Epoch: 72| Step: 0
Training loss: 3.108079433441162
Validation loss: 2.4188903736811813

Epoch: 6| Step: 1
Training loss: 3.037505865097046
Validation loss: 2.4112817036208285

Epoch: 6| Step: 2
Training loss: 2.14927339553833
Validation loss: 2.4045090931718067

Epoch: 6| Step: 3
Training loss: 3.0369882583618164
Validation loss: 2.400768759430096

Epoch: 6| Step: 4
Training loss: 2.699878215789795
Validation loss: 2.4016687152206257

Epoch: 6| Step: 5
Training loss: 2.499474048614502
Validation loss: 2.397542074162473

Epoch: 6| Step: 6
Training loss: 2.5791263580322266
Validation loss: 2.399878212200698

Epoch: 6| Step: 7
Training loss: 2.437938690185547
Validation loss: 2.3969948214869343

Epoch: 6| Step: 8
Training loss: 2.1404178142547607
Validation loss: 2.39303780371143

Epoch: 6| Step: 9
Training loss: 2.113950490951538
Validation loss: 2.399478740589593

Epoch: 6| Step: 10
Training loss: 2.957381248474121
Validation loss: 2.395616505735664

Epoch: 6| Step: 11
Training loss: 2.877026081085205
Validation loss: 2.398814429518997

Epoch: 6| Step: 12
Training loss: 2.2071101665496826
Validation loss: 2.399688402811686

Epoch: 6| Step: 13
Training loss: 3.488154888153076
Validation loss: 2.399423596679523

Epoch: 73| Step: 0
Training loss: 2.3354697227478027
Validation loss: 2.411143474681403

Epoch: 6| Step: 1
Training loss: 2.2561562061309814
Validation loss: 2.4109962230087607

Epoch: 6| Step: 2
Training loss: 2.924788475036621
Validation loss: 2.4377835668543333

Epoch: 6| Step: 3
Training loss: 2.4678075313568115
Validation loss: 2.4439216275368967

Epoch: 6| Step: 4
Training loss: 3.456786632537842
Validation loss: 2.4569126149659515

Epoch: 6| Step: 5
Training loss: 3.6072590351104736
Validation loss: 2.4516125494433987

Epoch: 6| Step: 6
Training loss: 2.9304778575897217
Validation loss: 2.433093788803265

Epoch: 6| Step: 7
Training loss: 2.6006550788879395
Validation loss: 2.427749054406279

Epoch: 6| Step: 8
Training loss: 1.970497727394104
Validation loss: 2.418534614706552

Epoch: 6| Step: 9
Training loss: 2.611489772796631
Validation loss: 2.404284897670951

Epoch: 6| Step: 10
Training loss: 3.5344958305358887
Validation loss: 2.3999070044486754

Epoch: 6| Step: 11
Training loss: 2.219120502471924
Validation loss: 2.3972606248753046

Epoch: 6| Step: 12
Training loss: 1.6229662895202637
Validation loss: 2.3982140761549755

Epoch: 6| Step: 13
Training loss: 2.19451642036438
Validation loss: 2.393446468537854

Epoch: 74| Step: 0
Training loss: 3.139707088470459
Validation loss: 2.4014778508934924

Epoch: 6| Step: 1
Training loss: 2.342381477355957
Validation loss: 2.398926091450517

Epoch: 6| Step: 2
Training loss: 1.934192419052124
Validation loss: 2.3989650434063328

Epoch: 6| Step: 3
Training loss: 2.646127939224243
Validation loss: 2.406260654490481

Epoch: 6| Step: 4
Training loss: 2.5421013832092285
Validation loss: 2.4031270191233647

Epoch: 6| Step: 5
Training loss: 3.267948627471924
Validation loss: 2.3996781328673005

Epoch: 6| Step: 6
Training loss: 2.272609233856201
Validation loss: 2.401247485991447

Epoch: 6| Step: 7
Training loss: 2.8002796173095703
Validation loss: 2.4010039426947154

Epoch: 6| Step: 8
Training loss: 3.176468849182129
Validation loss: 2.403581380844116

Epoch: 6| Step: 9
Training loss: 2.2207040786743164
Validation loss: 2.397082749233451

Epoch: 6| Step: 10
Training loss: 2.4238343238830566
Validation loss: 2.400121100487248

Epoch: 6| Step: 11
Training loss: 3.1813604831695557
Validation loss: 2.3962447630461825

Epoch: 6| Step: 12
Training loss: 2.4961118698120117
Validation loss: 2.397036608829293

Epoch: 6| Step: 13
Training loss: 2.068744659423828
Validation loss: 2.4007806598499255

Epoch: 75| Step: 0
Training loss: 3.0545654296875
Validation loss: 2.4130216683110883

Epoch: 6| Step: 1
Training loss: 2.8132996559143066
Validation loss: 2.4297563311874226

Epoch: 6| Step: 2
Training loss: 2.9942164421081543
Validation loss: 2.4456904319024857

Epoch: 6| Step: 3
Training loss: 3.053601026535034
Validation loss: 2.4473371441646288

Epoch: 6| Step: 4
Training loss: 1.9521639347076416
Validation loss: 2.4466455854395384

Epoch: 6| Step: 5
Training loss: 2.862504005432129
Validation loss: 2.4445127159036617

Epoch: 6| Step: 6
Training loss: 1.9063485860824585
Validation loss: 2.4489291355174077

Epoch: 6| Step: 7
Training loss: 2.928797483444214
Validation loss: 2.4383598758328344

Epoch: 6| Step: 8
Training loss: 2.5317819118499756
Validation loss: 2.424154025252147

Epoch: 6| Step: 9
Training loss: 2.5242972373962402
Validation loss: 2.4140075022174465

Epoch: 6| Step: 10
Training loss: 2.205554962158203
Validation loss: 2.4014231287023073

Epoch: 6| Step: 11
Training loss: 3.262866258621216
Validation loss: 2.3940983818423365

Epoch: 6| Step: 12
Training loss: 2.350151538848877
Validation loss: 2.3892436027526855

Epoch: 6| Step: 13
Training loss: 2.4304590225219727
Validation loss: 2.386679616025699

Epoch: 76| Step: 0
Training loss: 1.8429220914840698
Validation loss: 2.3853530319788123

Epoch: 6| Step: 1
Training loss: 2.5018162727355957
Validation loss: 2.384608622520201

Epoch: 6| Step: 2
Training loss: 2.8367481231689453
Validation loss: 2.384890651190153

Epoch: 6| Step: 3
Training loss: 2.8691680431365967
Validation loss: 2.387530634480138

Epoch: 6| Step: 4
Training loss: 2.286114454269409
Validation loss: 2.390506080401841

Epoch: 6| Step: 5
Training loss: 2.9196670055389404
Validation loss: 2.382622916211364

Epoch: 6| Step: 6
Training loss: 3.0767312049865723
Validation loss: 2.3836834892149894

Epoch: 6| Step: 7
Training loss: 2.710272789001465
Validation loss: 2.382226418423396

Epoch: 6| Step: 8
Training loss: 2.4304423332214355
Validation loss: 2.383452579539309

Epoch: 6| Step: 9
Training loss: 2.9494686126708984
Validation loss: 2.385850485935006

Epoch: 6| Step: 10
Training loss: 2.3925018310546875
Validation loss: 2.390413071519585

Epoch: 6| Step: 11
Training loss: 2.467916488647461
Validation loss: 2.395919256312873

Epoch: 6| Step: 12
Training loss: 3.152158260345459
Validation loss: 2.3991076023347917

Epoch: 6| Step: 13
Training loss: 1.9993640184402466
Validation loss: 2.4003524703364216

Epoch: 77| Step: 0
Training loss: 2.4360997676849365
Validation loss: 2.4064417833923013

Epoch: 6| Step: 1
Training loss: 2.883065938949585
Validation loss: 2.4058507232255835

Epoch: 6| Step: 2
Training loss: 1.7559020519256592
Validation loss: 2.4064605030962216

Epoch: 6| Step: 3
Training loss: 2.414979934692383
Validation loss: 2.413379269261514

Epoch: 6| Step: 4
Training loss: 3.138145685195923
Validation loss: 2.4314171088639127

Epoch: 6| Step: 5
Training loss: 2.5356955528259277
Validation loss: 2.438539328113679

Epoch: 6| Step: 6
Training loss: 1.9751665592193604
Validation loss: 2.438141046031829

Epoch: 6| Step: 7
Training loss: 2.5915415287017822
Validation loss: 2.4332961164494997

Epoch: 6| Step: 8
Training loss: 3.3828039169311523
Validation loss: 2.4444990388808714

Epoch: 6| Step: 9
Training loss: 2.6626200675964355
Validation loss: 2.4363214661998134

Epoch: 6| Step: 10
Training loss: 2.633533000946045
Validation loss: 2.42666950789831

Epoch: 6| Step: 11
Training loss: 2.96761417388916
Validation loss: 2.410621722539266

Epoch: 6| Step: 12
Training loss: 2.658191680908203
Validation loss: 2.4039160872018464

Epoch: 6| Step: 13
Training loss: 2.808380603790283
Validation loss: 2.391380545913532

Epoch: 78| Step: 0
Training loss: 2.1123931407928467
Validation loss: 2.388415636554841

Epoch: 6| Step: 1
Training loss: 2.725198268890381
Validation loss: 2.3873567965722855

Epoch: 6| Step: 2
Training loss: 2.7216835021972656
Validation loss: 2.3886793326306086

Epoch: 6| Step: 3
Training loss: 3.075373411178589
Validation loss: 2.388857828673496

Epoch: 6| Step: 4
Training loss: 2.7483952045440674
Validation loss: 2.385578429827126

Epoch: 6| Step: 5
Training loss: 2.846545934677124
Validation loss: 2.385831432957803

Epoch: 6| Step: 6
Training loss: 2.7636685371398926
Validation loss: 2.387677418288364

Epoch: 6| Step: 7
Training loss: 2.402287483215332
Validation loss: 2.394804511018979

Epoch: 6| Step: 8
Training loss: 1.9484230279922485
Validation loss: 2.4013255616670013

Epoch: 6| Step: 9
Training loss: 3.12455415725708
Validation loss: 2.404242871910013

Epoch: 6| Step: 10
Training loss: 2.4386379718780518
Validation loss: 2.4094097665561143

Epoch: 6| Step: 11
Training loss: 3.301372766494751
Validation loss: 2.4103914383919007

Epoch: 6| Step: 12
Training loss: 2.1152584552764893
Validation loss: 2.4057690148712485

Epoch: 6| Step: 13
Training loss: 2.148695707321167
Validation loss: 2.4008893518037695

Epoch: 79| Step: 0
Training loss: 1.9145194292068481
Validation loss: 2.3937309890665035

Epoch: 6| Step: 1
Training loss: 2.818160057067871
Validation loss: 2.38885522145097

Epoch: 6| Step: 2
Training loss: 2.9302425384521484
Validation loss: 2.3845355767075733

Epoch: 6| Step: 3
Training loss: 2.2328784465789795
Validation loss: 2.3770270398868028

Epoch: 6| Step: 4
Training loss: 2.015529155731201
Validation loss: 2.37814506407707

Epoch: 6| Step: 5
Training loss: 2.545362710952759
Validation loss: 2.3809431035031556

Epoch: 6| Step: 6
Training loss: 2.998474597930908
Validation loss: 2.384098470851939

Epoch: 6| Step: 7
Training loss: 2.768303871154785
Validation loss: 2.3838648693535918

Epoch: 6| Step: 8
Training loss: 3.3624491691589355
Validation loss: 2.379097068181602

Epoch: 6| Step: 9
Training loss: 2.374852180480957
Validation loss: 2.3674651781717935

Epoch: 6| Step: 10
Training loss: 3.118868350982666
Validation loss: 2.371321839670981

Epoch: 6| Step: 11
Training loss: 2.4578299522399902
Validation loss: 2.3736232570422593

Epoch: 6| Step: 12
Training loss: 2.229459762573242
Validation loss: 2.377262653843049

Epoch: 6| Step: 13
Training loss: 3.118678569793701
Validation loss: 2.3851321153743292

Epoch: 80| Step: 0
Training loss: 2.7043724060058594
Validation loss: 2.4004457484009447

Epoch: 6| Step: 1
Training loss: 3.0777859687805176
Validation loss: 2.400037145101896

Epoch: 6| Step: 2
Training loss: 2.7308778762817383
Validation loss: 2.405757955325547

Epoch: 6| Step: 3
Training loss: 2.861372470855713
Validation loss: 2.418204225519652

Epoch: 6| Step: 4
Training loss: 2.3753581047058105
Validation loss: 2.4135125273017475

Epoch: 6| Step: 5
Training loss: 2.3656771183013916
Validation loss: 2.411124596031763

Epoch: 6| Step: 6
Training loss: 2.2706923484802246
Validation loss: 2.404871207411571

Epoch: 6| Step: 7
Training loss: 2.653298854827881
Validation loss: 2.396621219573482

Epoch: 6| Step: 8
Training loss: 2.1876091957092285
Validation loss: 2.397851356896021

Epoch: 6| Step: 9
Training loss: 2.730363368988037
Validation loss: 2.388291258965769

Epoch: 6| Step: 10
Training loss: 2.558414936065674
Validation loss: 2.3786734663030153

Epoch: 6| Step: 11
Training loss: 3.4859559535980225
Validation loss: 2.380067527935069

Epoch: 6| Step: 12
Training loss: 2.1288223266601562
Validation loss: 2.377570944447671

Epoch: 6| Step: 13
Training loss: 2.4559876918792725
Validation loss: 2.378598238832207

Epoch: 81| Step: 0
Training loss: 3.175792694091797
Validation loss: 2.37764980459726

Epoch: 6| Step: 1
Training loss: 2.2407665252685547
Validation loss: 2.377062310454666

Epoch: 6| Step: 2
Training loss: 2.8690595626831055
Validation loss: 2.379210364434027

Epoch: 6| Step: 3
Training loss: 2.791698455810547
Validation loss: 2.3741019387398996

Epoch: 6| Step: 4
Training loss: 2.548088550567627
Validation loss: 2.378623277910294

Epoch: 6| Step: 5
Training loss: 2.411249876022339
Validation loss: 2.370743397743471

Epoch: 6| Step: 6
Training loss: 2.0929293632507324
Validation loss: 2.372115550502654

Epoch: 6| Step: 7
Training loss: 2.7937049865722656
Validation loss: 2.3668602999820503

Epoch: 6| Step: 8
Training loss: 2.2719500064849854
Validation loss: 2.3679362061203166

Epoch: 6| Step: 9
Training loss: 2.316565990447998
Validation loss: 2.365587898479995

Epoch: 6| Step: 10
Training loss: 2.461676597595215
Validation loss: 2.364218592643738

Epoch: 6| Step: 11
Training loss: 2.70461368560791
Validation loss: 2.366765881097445

Epoch: 6| Step: 12
Training loss: 3.0372304916381836
Validation loss: 2.365844941908313

Epoch: 6| Step: 13
Training loss: 2.887127161026001
Validation loss: 2.372403142272785

Epoch: 82| Step: 0
Training loss: 2.721543073654175
Validation loss: 2.3793507955407582

Epoch: 6| Step: 1
Training loss: 2.4764554500579834
Validation loss: 2.3903018915525047

Epoch: 6| Step: 2
Training loss: 2.5291833877563477
Validation loss: 2.4103513661251275

Epoch: 6| Step: 3
Training loss: 1.8863344192504883
Validation loss: 2.421725503859981

Epoch: 6| Step: 4
Training loss: 2.7941908836364746
Validation loss: 2.423631794991032

Epoch: 6| Step: 5
Training loss: 2.506412982940674
Validation loss: 2.4142424944908387

Epoch: 6| Step: 6
Training loss: 2.6117405891418457
Validation loss: 2.4211907745689474

Epoch: 6| Step: 7
Training loss: 2.6979379653930664
Validation loss: 2.4210932203518447

Epoch: 6| Step: 8
Training loss: 2.6748409271240234
Validation loss: 2.4136967556450957

Epoch: 6| Step: 9
Training loss: 2.6583077907562256
Validation loss: 2.407491050740724

Epoch: 6| Step: 10
Training loss: 2.391289234161377
Validation loss: 2.387758101186445

Epoch: 6| Step: 11
Training loss: 2.9411468505859375
Validation loss: 2.37621110229082

Epoch: 6| Step: 12
Training loss: 2.9328269958496094
Validation loss: 2.3676295947003108

Epoch: 6| Step: 13
Training loss: 2.845857858657837
Validation loss: 2.3609035861107612

Epoch: 83| Step: 0
Training loss: 2.7870984077453613
Validation loss: 2.365314724624798

Epoch: 6| Step: 1
Training loss: 2.4219048023223877
Validation loss: 2.370437429797265

Epoch: 6| Step: 2
Training loss: 3.2475454807281494
Validation loss: 2.3706635403376755

Epoch: 6| Step: 3
Training loss: 2.495830774307251
Validation loss: 2.3671591410072903

Epoch: 6| Step: 4
Training loss: 2.708595037460327
Validation loss: 2.3614992787761073

Epoch: 6| Step: 5
Training loss: 2.2836434841156006
Validation loss: 2.366501014719727

Epoch: 6| Step: 6
Training loss: 2.4116158485412598
Validation loss: 2.365405333939419

Epoch: 6| Step: 7
Training loss: 2.245755434036255
Validation loss: 2.374143433827226

Epoch: 6| Step: 8
Training loss: 2.419170379638672
Validation loss: 2.387016023358991

Epoch: 6| Step: 9
Training loss: 2.9515247344970703
Validation loss: 2.41440002892607

Epoch: 6| Step: 10
Training loss: 2.913536548614502
Validation loss: 2.4170681020264984

Epoch: 6| Step: 11
Training loss: 3.1639490127563477
Validation loss: 2.4313241076725784

Epoch: 6| Step: 12
Training loss: 2.022860527038574
Validation loss: 2.413966889022499

Epoch: 6| Step: 13
Training loss: 2.471064329147339
Validation loss: 2.404546535143288

Epoch: 84| Step: 0
Training loss: 3.177811622619629
Validation loss: 2.389104499611803

Epoch: 6| Step: 1
Training loss: 2.485395669937134
Validation loss: 2.3821478197651524

Epoch: 6| Step: 2
Training loss: 2.8945441246032715
Validation loss: 2.366885223696309

Epoch: 6| Step: 3
Training loss: 2.5895867347717285
Validation loss: 2.3623748415259906

Epoch: 6| Step: 4
Training loss: 3.1562695503234863
Validation loss: 2.364566582505421

Epoch: 6| Step: 5
Training loss: 2.2623701095581055
Validation loss: 2.358959604335088

Epoch: 6| Step: 6
Training loss: 2.307040214538574
Validation loss: 2.3600917554670766

Epoch: 6| Step: 7
Training loss: 2.121664047241211
Validation loss: 2.3534717816178516

Epoch: 6| Step: 8
Training loss: 2.057483196258545
Validation loss: 2.3532550732294717

Epoch: 6| Step: 9
Training loss: 2.455625057220459
Validation loss: 2.3598228577644593

Epoch: 6| Step: 10
Training loss: 2.4156036376953125
Validation loss: 2.359455423970376

Epoch: 6| Step: 11
Training loss: 2.437556743621826
Validation loss: 2.366722429952314

Epoch: 6| Step: 12
Training loss: 2.876171112060547
Validation loss: 2.364229030506585

Epoch: 6| Step: 13
Training loss: 3.719843864440918
Validation loss: 2.372631444725939

Epoch: 85| Step: 0
Training loss: 2.578580379486084
Validation loss: 2.3753435739906887

Epoch: 6| Step: 1
Training loss: 2.5887606143951416
Validation loss: 2.38179458854019

Epoch: 6| Step: 2
Training loss: 2.5462000370025635
Validation loss: 2.3790381980198685

Epoch: 6| Step: 3
Training loss: 3.337691307067871
Validation loss: 2.377434886911864

Epoch: 6| Step: 4
Training loss: 2.6017141342163086
Validation loss: 2.381758077170259

Epoch: 6| Step: 5
Training loss: 2.6390349864959717
Validation loss: 2.37157537347527

Epoch: 6| Step: 6
Training loss: 2.298931360244751
Validation loss: 2.3659938202109387

Epoch: 6| Step: 7
Training loss: 1.8764280080795288
Validation loss: 2.358022177091209

Epoch: 6| Step: 8
Training loss: 3.0147624015808105
Validation loss: 2.3614918160182174

Epoch: 6| Step: 9
Training loss: 2.6832480430603027
Validation loss: 2.359736861721162

Epoch: 6| Step: 10
Training loss: 2.657322406768799
Validation loss: 2.361174932090185

Epoch: 6| Step: 11
Training loss: 2.262718915939331
Validation loss: 2.3625820144530265

Epoch: 6| Step: 12
Training loss: 2.798922538757324
Validation loss: 2.3580199082692466

Epoch: 6| Step: 13
Training loss: 2.3401730060577393
Validation loss: 2.355942380043768

Epoch: 86| Step: 0
Training loss: 2.1482126712799072
Validation loss: 2.362604818036479

Epoch: 6| Step: 1
Training loss: 2.9495301246643066
Validation loss: 2.357452082377608

Epoch: 6| Step: 2
Training loss: 2.3574023246765137
Validation loss: 2.357077749826575

Epoch: 6| Step: 3
Training loss: 1.943756103515625
Validation loss: 2.350756024801603

Epoch: 6| Step: 4
Training loss: 3.0340824127197266
Validation loss: 2.3484451822055283

Epoch: 6| Step: 5
Training loss: 2.9469571113586426
Validation loss: 2.3505205569728727

Epoch: 6| Step: 6
Training loss: 2.2938716411590576
Validation loss: 2.3545802639376734

Epoch: 6| Step: 7
Training loss: 2.4418134689331055
Validation loss: 2.354475764818089

Epoch: 6| Step: 8
Training loss: 2.5973613262176514
Validation loss: 2.3603818878050773

Epoch: 6| Step: 9
Training loss: 3.322509288787842
Validation loss: 2.362290297785113

Epoch: 6| Step: 10
Training loss: 2.7775521278381348
Validation loss: 2.3665966244154077

Epoch: 6| Step: 11
Training loss: 2.2078921794891357
Validation loss: 2.3757213469474547

Epoch: 6| Step: 12
Training loss: 2.734963893890381
Validation loss: 2.3951279322306314

Epoch: 6| Step: 13
Training loss: 2.815108299255371
Validation loss: 2.417667076151858

Epoch: 87| Step: 0
Training loss: 3.0832982063293457
Validation loss: 2.4177956094024

Epoch: 6| Step: 1
Training loss: 3.136683940887451
Validation loss: 2.412070007734401

Epoch: 6| Step: 2
Training loss: 2.42948842048645
Validation loss: 2.402264969323271

Epoch: 6| Step: 3
Training loss: 2.784153938293457
Validation loss: 2.386389442669448

Epoch: 6| Step: 4
Training loss: 2.5289230346679688
Validation loss: 2.3799695276444957

Epoch: 6| Step: 5
Training loss: 3.002795934677124
Validation loss: 2.366744790025937

Epoch: 6| Step: 6
Training loss: 2.3736541271209717
Validation loss: 2.349579479104729

Epoch: 6| Step: 7
Training loss: 2.830176591873169
Validation loss: 2.3497135485372236

Epoch: 6| Step: 8
Training loss: 2.5008797645568848
Validation loss: 2.3480293468762468

Epoch: 6| Step: 9
Training loss: 2.2412521839141846
Validation loss: 2.345090804561492

Epoch: 6| Step: 10
Training loss: 2.2117910385131836
Validation loss: 2.3442294366898073

Epoch: 6| Step: 11
Training loss: 2.7046308517456055
Validation loss: 2.345722662505283

Epoch: 6| Step: 12
Training loss: 1.8866655826568604
Validation loss: 2.34660291928117

Epoch: 6| Step: 13
Training loss: 2.7312562465667725
Validation loss: 2.3494131180547897

Epoch: 88| Step: 0
Training loss: 2.8692216873168945
Validation loss: 2.352529651375227

Epoch: 6| Step: 1
Training loss: 2.6494927406311035
Validation loss: 2.3527320495215793

Epoch: 6| Step: 2
Training loss: 2.8554506301879883
Validation loss: 2.36282350683725

Epoch: 6| Step: 3
Training loss: 1.876523494720459
Validation loss: 2.355286882769677

Epoch: 6| Step: 4
Training loss: 2.5690789222717285
Validation loss: 2.3609219494686333

Epoch: 6| Step: 5
Training loss: 2.969005584716797
Validation loss: 2.363539282993604

Epoch: 6| Step: 6
Training loss: 2.395552635192871
Validation loss: 2.3766329557664934

Epoch: 6| Step: 7
Training loss: 2.719059467315674
Validation loss: 2.377237271237117

Epoch: 6| Step: 8
Training loss: 2.7621965408325195
Validation loss: 2.379219844777097

Epoch: 6| Step: 9
Training loss: 2.970897674560547
Validation loss: 2.3792576969310804

Epoch: 6| Step: 10
Training loss: 2.0359463691711426
Validation loss: 2.3754491882939495

Epoch: 6| Step: 11
Training loss: 2.5674595832824707
Validation loss: 2.365494904979583

Epoch: 6| Step: 12
Training loss: 2.6483068466186523
Validation loss: 2.3592259268606863

Epoch: 6| Step: 13
Training loss: 2.188080072402954
Validation loss: 2.3631430902788715

Epoch: 89| Step: 0
Training loss: 2.3422293663024902
Validation loss: 2.359959361373737

Epoch: 6| Step: 1
Training loss: 3.3937220573425293
Validation loss: 2.361205426595544

Epoch: 6| Step: 2
Training loss: 1.9992985725402832
Validation loss: 2.3603266285311792

Epoch: 6| Step: 3
Training loss: 1.8441649675369263
Validation loss: 2.3705749204081874

Epoch: 6| Step: 4
Training loss: 2.767871618270874
Validation loss: 2.385555454479751

Epoch: 6| Step: 5
Training loss: 2.121591567993164
Validation loss: 2.3888014260158745

Epoch: 6| Step: 6
Training loss: 3.0469088554382324
Validation loss: 2.4196092620972665

Epoch: 6| Step: 7
Training loss: 2.693538188934326
Validation loss: 2.4047059012997534

Epoch: 6| Step: 8
Training loss: 2.423140525817871
Validation loss: 2.417344541959865

Epoch: 6| Step: 9
Training loss: 2.12612247467041
Validation loss: 2.4389259661397626

Epoch: 6| Step: 10
Training loss: 2.9616329669952393
Validation loss: 2.486214368574081

Epoch: 6| Step: 11
Training loss: 3.613337278366089
Validation loss: 2.4937613702589467

Epoch: 6| Step: 12
Training loss: 2.6640193462371826
Validation loss: 2.4772833560102727

Epoch: 6| Step: 13
Training loss: 2.3803563117980957
Validation loss: 2.450271124480873

Epoch: 90| Step: 0
Training loss: 2.5835375785827637
Validation loss: 2.3944985969092256

Epoch: 6| Step: 1
Training loss: 2.6539011001586914
Validation loss: 2.359047343654017

Epoch: 6| Step: 2
Training loss: 3.02120304107666
Validation loss: 2.3439729957170385

Epoch: 6| Step: 3
Training loss: 2.361989974975586
Validation loss: 2.3384011407052316

Epoch: 6| Step: 4
Training loss: 2.987694263458252
Validation loss: 2.3514596211012972

Epoch: 6| Step: 5
Training loss: 3.3346736431121826
Validation loss: 2.355333402592649

Epoch: 6| Step: 6
Training loss: 2.674008846282959
Validation loss: 2.3710685917126235

Epoch: 6| Step: 7
Training loss: 2.6667370796203613
Validation loss: 2.3710125056646203

Epoch: 6| Step: 8
Training loss: 2.7802584171295166
Validation loss: 2.359599208319059

Epoch: 6| Step: 9
Training loss: 2.4017529487609863
Validation loss: 2.35307575297612

Epoch: 6| Step: 10
Training loss: 2.287613868713379
Validation loss: 2.3398327519816737

Epoch: 6| Step: 11
Training loss: 2.1386559009552
Validation loss: 2.337422163255753

Epoch: 6| Step: 12
Training loss: 1.816704511642456
Validation loss: 2.3422095519240185

Epoch: 6| Step: 13
Training loss: 2.744574546813965
Validation loss: 2.351037617652647

Epoch: 91| Step: 0
Training loss: 2.3780174255371094
Validation loss: 2.3583510716756186

Epoch: 6| Step: 1
Training loss: 2.9804930686950684
Validation loss: 2.376231034596761

Epoch: 6| Step: 2
Training loss: 2.599780321121216
Validation loss: 2.4120400797936226

Epoch: 6| Step: 3
Training loss: 2.6175222396850586
Validation loss: 2.4270066830419723

Epoch: 6| Step: 4
Training loss: 2.7407450675964355
Validation loss: 2.461063454228063

Epoch: 6| Step: 5
Training loss: 2.4075751304626465
Validation loss: 2.4743715819492134

Epoch: 6| Step: 6
Training loss: 2.1704583168029785
Validation loss: 2.4536348850496355

Epoch: 6| Step: 7
Training loss: 2.219200611114502
Validation loss: 2.4236833536496727

Epoch: 6| Step: 8
Training loss: 2.1199212074279785
Validation loss: 2.4036780749597857

Epoch: 6| Step: 9
Training loss: 2.6664743423461914
Validation loss: 2.3816533985958306

Epoch: 6| Step: 10
Training loss: 3.647934913635254
Validation loss: 2.3558872771519486

Epoch: 6| Step: 11
Training loss: 2.561981439590454
Validation loss: 2.340497580907678

Epoch: 6| Step: 12
Training loss: 2.9604060649871826
Validation loss: 2.3361050364791707

Epoch: 6| Step: 13
Training loss: 2.1015260219573975
Validation loss: 2.3435719884851927

Epoch: 92| Step: 0
Training loss: 3.084428310394287
Validation loss: 2.341489771360992

Epoch: 6| Step: 1
Training loss: 2.4383957386016846
Validation loss: 2.3480612436930337

Epoch: 6| Step: 2
Training loss: 3.2173471450805664
Validation loss: 2.3501890038931244

Epoch: 6| Step: 3
Training loss: 2.3024635314941406
Validation loss: 2.3499862301734185

Epoch: 6| Step: 4
Training loss: 3.1533875465393066
Validation loss: 2.3534733762023268

Epoch: 6| Step: 5
Training loss: 2.473134994506836
Validation loss: 2.341655738892094

Epoch: 6| Step: 6
Training loss: 2.8650646209716797
Validation loss: 2.333082760533979

Epoch: 6| Step: 7
Training loss: 1.8281054496765137
Validation loss: 2.3324244137733214

Epoch: 6| Step: 8
Training loss: 2.28989839553833
Validation loss: 2.331654164098924

Epoch: 6| Step: 9
Training loss: 2.461599349975586
Validation loss: 2.3309131437732327

Epoch: 6| Step: 10
Training loss: 2.3569178581237793
Validation loss: 2.3327978144409838

Epoch: 6| Step: 11
Training loss: 2.52933406829834
Validation loss: 2.345219906940255

Epoch: 6| Step: 12
Training loss: 2.945448160171509
Validation loss: 2.346924243434783

Epoch: 6| Step: 13
Training loss: 2.17840838432312
Validation loss: 2.3572598426572737

Epoch: 93| Step: 0
Training loss: 3.2132058143615723
Validation loss: 2.363530910143288

Epoch: 6| Step: 1
Training loss: 2.6147735118865967
Validation loss: 2.3779273545870216

Epoch: 6| Step: 2
Training loss: 1.7421355247497559
Validation loss: 2.3669138441803637

Epoch: 6| Step: 3
Training loss: 2.9486565589904785
Validation loss: 2.3606836231805945

Epoch: 6| Step: 4
Training loss: 2.127777576446533
Validation loss: 2.3573069187902633

Epoch: 6| Step: 5
Training loss: 2.11543607711792
Validation loss: 2.3520951014693066

Epoch: 6| Step: 6
Training loss: 2.701004981994629
Validation loss: 2.3556306080151628

Epoch: 6| Step: 7
Training loss: 2.5226516723632812
Validation loss: 2.3431421223507134

Epoch: 6| Step: 8
Training loss: 2.6204311847686768
Validation loss: 2.3348023686357724

Epoch: 6| Step: 9
Training loss: 3.240844964981079
Validation loss: 2.339045468197074

Epoch: 6| Step: 10
Training loss: 3.158639669418335
Validation loss: 2.3282069339547107

Epoch: 6| Step: 11
Training loss: 2.7648565769195557
Validation loss: 2.3324784104542067

Epoch: 6| Step: 12
Training loss: 2.2500903606414795
Validation loss: 2.3240294020663024

Epoch: 6| Step: 13
Training loss: 1.5516304969787598
Validation loss: 2.3272804675563687

Epoch: 94| Step: 0
Training loss: 2.505486488342285
Validation loss: 2.326071887887934

Epoch: 6| Step: 1
Training loss: 2.9948112964630127
Validation loss: 2.321880122666718

Epoch: 6| Step: 2
Training loss: 2.4537148475646973
Validation loss: 2.3247379923379548

Epoch: 6| Step: 3
Training loss: 2.289191246032715
Validation loss: 2.3231322611531904

Epoch: 6| Step: 4
Training loss: 2.547738790512085
Validation loss: 2.3210876526371127

Epoch: 6| Step: 5
Training loss: 2.315721035003662
Validation loss: 2.321392165717258

Epoch: 6| Step: 6
Training loss: 2.41633939743042
Validation loss: 2.327801976152646

Epoch: 6| Step: 7
Training loss: 2.776756763458252
Validation loss: 2.32330152808979

Epoch: 6| Step: 8
Training loss: 2.4917502403259277
Validation loss: 2.3222559216201946

Epoch: 6| Step: 9
Training loss: 3.092478036880493
Validation loss: 2.329767350227602

Epoch: 6| Step: 10
Training loss: 2.0421910285949707
Validation loss: 2.3319113408365557

Epoch: 6| Step: 11
Training loss: 3.017385721206665
Validation loss: 2.345452639364427

Epoch: 6| Step: 12
Training loss: 2.759047269821167
Validation loss: 2.3357381718133086

Epoch: 6| Step: 13
Training loss: 2.212285041809082
Validation loss: 2.336835915042508

Epoch: 95| Step: 0
Training loss: 2.848210334777832
Validation loss: 2.334491406717608

Epoch: 6| Step: 1
Training loss: 2.6026103496551514
Validation loss: 2.334115659036944

Epoch: 6| Step: 2
Training loss: 2.6095316410064697
Validation loss: 2.329701877409412

Epoch: 6| Step: 3
Training loss: 2.7624502182006836
Validation loss: 2.3277112899288053

Epoch: 6| Step: 4
Training loss: 2.4004862308502197
Validation loss: 2.3271937498482327

Epoch: 6| Step: 5
Training loss: 2.3038883209228516
Validation loss: 2.3313751169430312

Epoch: 6| Step: 6
Training loss: 2.6703710556030273
Validation loss: 2.3199257081554783

Epoch: 6| Step: 7
Training loss: 2.853454828262329
Validation loss: 2.3277008059204265

Epoch: 6| Step: 8
Training loss: 1.607935905456543
Validation loss: 2.33610204983783

Epoch: 6| Step: 9
Training loss: 3.367436170578003
Validation loss: 2.3374192996691634

Epoch: 6| Step: 10
Training loss: 2.391340494155884
Validation loss: 2.337992557915308

Epoch: 6| Step: 11
Training loss: 2.6374757289886475
Validation loss: 2.336288321402765

Epoch: 6| Step: 12
Training loss: 2.4690937995910645
Validation loss: 2.3411436080932617

Epoch: 6| Step: 13
Training loss: 2.259678840637207
Validation loss: 2.3323078386245237

Epoch: 96| Step: 0
Training loss: 2.0851874351501465
Validation loss: 2.3297284751810055

Epoch: 6| Step: 1
Training loss: 2.9326534271240234
Validation loss: 2.3365120426301034

Epoch: 6| Step: 2
Training loss: 2.445033073425293
Validation loss: 2.351712919050647

Epoch: 6| Step: 3
Training loss: 2.4049129486083984
Validation loss: 2.346253215625722

Epoch: 6| Step: 4
Training loss: 2.6638708114624023
Validation loss: 2.339282621619522

Epoch: 6| Step: 5
Training loss: 2.530088186264038
Validation loss: 2.3283594116087882

Epoch: 6| Step: 6
Training loss: 2.8606793880462646
Validation loss: 2.3177120211303874

Epoch: 6| Step: 7
Training loss: 2.6914405822753906
Validation loss: 2.32403685456963

Epoch: 6| Step: 8
Training loss: 2.583315134048462
Validation loss: 2.3275076266257995

Epoch: 6| Step: 9
Training loss: 2.2980587482452393
Validation loss: 2.3412293669998006

Epoch: 6| Step: 10
Training loss: 2.6983420848846436
Validation loss: 2.342876534308157

Epoch: 6| Step: 11
Training loss: 2.590322971343994
Validation loss: 2.33589502047467

Epoch: 6| Step: 12
Training loss: 2.5420351028442383
Validation loss: 2.3403863009586128

Epoch: 6| Step: 13
Training loss: 2.567061185836792
Validation loss: 2.32268944350622

Epoch: 97| Step: 0
Training loss: 3.1819615364074707
Validation loss: 2.3123359654539373

Epoch: 6| Step: 1
Training loss: 1.9539151191711426
Validation loss: 2.3145429318951023

Epoch: 6| Step: 2
Training loss: 2.2415952682495117
Validation loss: 2.3078395551250828

Epoch: 6| Step: 3
Training loss: 2.260695457458496
Validation loss: 2.3094599939161733

Epoch: 6| Step: 4
Training loss: 3.100189208984375
Validation loss: 2.3101251176608506

Epoch: 6| Step: 5
Training loss: 2.2560880184173584
Validation loss: 2.314251187027142

Epoch: 6| Step: 6
Training loss: 2.1195669174194336
Validation loss: 2.3104213104453137

Epoch: 6| Step: 7
Training loss: 2.5684778690338135
Validation loss: 2.3101302244329966

Epoch: 6| Step: 8
Training loss: 2.8323545455932617
Validation loss: 2.317380464205178

Epoch: 6| Step: 9
Training loss: 1.922405481338501
Validation loss: 2.3195351682683474

Epoch: 6| Step: 10
Training loss: 2.9508891105651855
Validation loss: 2.333324199081749

Epoch: 6| Step: 11
Training loss: 2.61566162109375
Validation loss: 2.3428968383419897

Epoch: 6| Step: 12
Training loss: 3.1536450386047363
Validation loss: 2.3552180028730825

Epoch: 6| Step: 13
Training loss: 3.185426712036133
Validation loss: 2.3832805618163078

Epoch: 98| Step: 0
Training loss: 2.3201189041137695
Validation loss: 2.3841076204853673

Epoch: 6| Step: 1
Training loss: 2.442263603210449
Validation loss: 2.3782181432170253

Epoch: 6| Step: 2
Training loss: 2.0454533100128174
Validation loss: 2.3664459874553065

Epoch: 6| Step: 3
Training loss: 2.464524269104004
Validation loss: 2.3530452905162687

Epoch: 6| Step: 4
Training loss: 2.9979138374328613
Validation loss: 2.347498773246683

Epoch: 6| Step: 5
Training loss: 2.7269861698150635
Validation loss: 2.3284796309727493

Epoch: 6| Step: 6
Training loss: 2.831772565841675
Validation loss: 2.323638262287263

Epoch: 6| Step: 7
Training loss: 2.8026134967803955
Validation loss: 2.3195153461989535

Epoch: 6| Step: 8
Training loss: 2.358607292175293
Validation loss: 2.3113713354192753

Epoch: 6| Step: 9
Training loss: 2.633897066116333
Validation loss: 2.311155242304648

Epoch: 6| Step: 10
Training loss: 2.6149420738220215
Validation loss: 2.308201579637425

Epoch: 6| Step: 11
Training loss: 2.2304532527923584
Validation loss: 2.3085646603697088

Epoch: 6| Step: 12
Training loss: 2.8141770362854004
Validation loss: 2.309352800410281

Epoch: 6| Step: 13
Training loss: 2.722429037094116
Validation loss: 2.3131824334462485

Epoch: 99| Step: 0
Training loss: 3.712005615234375
Validation loss: 2.335794113015616

Epoch: 6| Step: 1
Training loss: 2.4968032836914062
Validation loss: 2.33984661358659

Epoch: 6| Step: 2
Training loss: 2.71243953704834
Validation loss: 2.3791194115915606

Epoch: 6| Step: 3
Training loss: 1.719839096069336
Validation loss: 2.3810423522867183

Epoch: 6| Step: 4
Training loss: 2.795118808746338
Validation loss: 2.4142838293506252

Epoch: 6| Step: 5
Training loss: 3.3639309406280518
Validation loss: 2.397069828484648

Epoch: 6| Step: 6
Training loss: 2.467339277267456
Validation loss: 2.3789035863773798

Epoch: 6| Step: 7
Training loss: 2.549589157104492
Validation loss: 2.3725234718732935

Epoch: 6| Step: 8
Training loss: 2.7585418224334717
Validation loss: 2.361298505977918

Epoch: 6| Step: 9
Training loss: 2.4844512939453125
Validation loss: 2.3511179775320072

Epoch: 6| Step: 10
Training loss: 2.218264579772949
Validation loss: 2.3570689488482732

Epoch: 6| Step: 11
Training loss: 1.8955237865447998
Validation loss: 2.3511725215501684

Epoch: 6| Step: 12
Training loss: 2.649031639099121
Validation loss: 2.354146900997367

Epoch: 6| Step: 13
Training loss: 2.5542619228363037
Validation loss: 2.356465388369817

Epoch: 100| Step: 0
Training loss: 2.7723238468170166
Validation loss: 2.3621374330212994

Epoch: 6| Step: 1
Training loss: 2.298478126525879
Validation loss: 2.3645448530873945

Epoch: 6| Step: 2
Training loss: 3.0716140270233154
Validation loss: 2.3692992887189313

Epoch: 6| Step: 3
Training loss: 2.211282253265381
Validation loss: 2.3664236594271917

Epoch: 6| Step: 4
Training loss: 3.0719308853149414
Validation loss: 2.3778114882848596

Epoch: 6| Step: 5
Training loss: 2.8883163928985596
Validation loss: 2.388247223310573

Epoch: 6| Step: 6
Training loss: 2.9980592727661133
Validation loss: 2.390340766599101

Epoch: 6| Step: 7
Training loss: 2.801501512527466
Validation loss: 2.3917314211527505

Epoch: 6| Step: 8
Training loss: 2.0619149208068848
Validation loss: 2.3872652617833947

Epoch: 6| Step: 9
Training loss: 2.6228270530700684
Validation loss: 2.3813291057463615

Epoch: 6| Step: 10
Training loss: 3.02406644821167
Validation loss: 2.3853138903135895

Epoch: 6| Step: 11
Training loss: 2.4786860942840576
Validation loss: 2.3833316321014077

Epoch: 6| Step: 12
Training loss: 1.8687125444412231
Validation loss: 2.362638804220384

Epoch: 6| Step: 13
Training loss: 1.8459362983703613
Validation loss: 2.357405685609387

Epoch: 101| Step: 0
Training loss: 2.144202709197998
Validation loss: 2.3553293033312728

Epoch: 6| Step: 1
Training loss: 2.9883310794830322
Validation loss: 2.353350559870402

Epoch: 6| Step: 2
Training loss: 2.895277500152588
Validation loss: 2.3434433937072754

Epoch: 6| Step: 3
Training loss: 2.0489649772644043
Validation loss: 2.346132614279306

Epoch: 6| Step: 4
Training loss: 2.334573268890381
Validation loss: 2.3412798989203667

Epoch: 6| Step: 5
Training loss: 3.1461572647094727
Validation loss: 2.3460686719545754

Epoch: 6| Step: 6
Training loss: 3.3256266117095947
Validation loss: 2.3382547978431947

Epoch: 6| Step: 7
Training loss: 2.1906919479370117
Validation loss: 2.3221305762567828

Epoch: 6| Step: 8
Training loss: 2.254476547241211
Validation loss: 2.3339220477688696

Epoch: 6| Step: 9
Training loss: 2.304109811782837
Validation loss: 2.3426651698286816

Epoch: 6| Step: 10
Training loss: 2.1929712295532227
Validation loss: 2.3431171319817983

Epoch: 6| Step: 11
Training loss: 2.8172993659973145
Validation loss: 2.372265100479126

Epoch: 6| Step: 12
Training loss: 2.675964117050171
Validation loss: 2.3697946071624756

Epoch: 6| Step: 13
Training loss: 3.016169309616089
Validation loss: 2.3300433287056546

Epoch: 102| Step: 0
Training loss: 3.385493278503418
Validation loss: 2.3182841629110356

Epoch: 6| Step: 1
Training loss: 2.637493133544922
Validation loss: 2.3019539258813344

Epoch: 6| Step: 2
Training loss: 1.6972200870513916
Validation loss: 2.2914186600715882

Epoch: 6| Step: 3
Training loss: 2.5838727951049805
Validation loss: 2.2952057930731002

Epoch: 6| Step: 4
Training loss: 2.255685329437256
Validation loss: 2.2901497758844847

Epoch: 6| Step: 5
Training loss: 2.586104393005371
Validation loss: 2.28597084424829

Epoch: 6| Step: 6
Training loss: 3.274651527404785
Validation loss: 2.285446295174219

Epoch: 6| Step: 7
Training loss: 2.1545071601867676
Validation loss: 2.2913063674844723

Epoch: 6| Step: 8
Training loss: 2.4376299381256104
Validation loss: 2.2863417569027153

Epoch: 6| Step: 9
Training loss: 2.7260520458221436
Validation loss: 2.2871430945652786

Epoch: 6| Step: 10
Training loss: 2.318509578704834
Validation loss: 2.2936269826786493

Epoch: 6| Step: 11
Training loss: 3.1628952026367188
Validation loss: 2.3022467167146745

Epoch: 6| Step: 12
Training loss: 2.4049596786499023
Validation loss: 2.311619302277924

Epoch: 6| Step: 13
Training loss: 1.9135115146636963
Validation loss: 2.3195114494651876

Epoch: 103| Step: 0
Training loss: 2.4804251194000244
Validation loss: 2.319532048317694

Epoch: 6| Step: 1
Training loss: 2.8775715827941895
Validation loss: 2.3236252902656473

Epoch: 6| Step: 2
Training loss: 2.011561632156372
Validation loss: 2.3251614493708455

Epoch: 6| Step: 3
Training loss: 2.9064555168151855
Validation loss: 2.3168863840000604

Epoch: 6| Step: 4
Training loss: 2.2113351821899414
Validation loss: 2.317043496716407

Epoch: 6| Step: 5
Training loss: 2.2295594215393066
Validation loss: 2.321302813868369

Epoch: 6| Step: 6
Training loss: 2.675078868865967
Validation loss: 2.3251822225509153

Epoch: 6| Step: 7
Training loss: 3.074556350708008
Validation loss: 2.3226518861709105

Epoch: 6| Step: 8
Training loss: 2.091836452484131
Validation loss: 2.3174652745646815

Epoch: 6| Step: 9
Training loss: 3.3922688961029053
Validation loss: 2.3174225566207722

Epoch: 6| Step: 10
Training loss: 2.688729763031006
Validation loss: 2.3170322192612516

Epoch: 6| Step: 11
Training loss: 1.813288927078247
Validation loss: 2.323622049823884

Epoch: 6| Step: 12
Training loss: 2.6938843727111816
Validation loss: 2.3203094569585656

Epoch: 6| Step: 13
Training loss: 2.660780429840088
Validation loss: 2.31102006922486

Epoch: 104| Step: 0
Training loss: 2.504262924194336
Validation loss: 2.3119711055550525

Epoch: 6| Step: 1
Training loss: 2.5870513916015625
Validation loss: 2.3238122245316863

Epoch: 6| Step: 2
Training loss: 1.9491459131240845
Validation loss: 2.3057020415541944

Epoch: 6| Step: 3
Training loss: 3.1570849418640137
Validation loss: 2.2991077028295046

Epoch: 6| Step: 4
Training loss: 2.9764180183410645
Validation loss: 2.302473965511527

Epoch: 6| Step: 5
Training loss: 2.0545363426208496
Validation loss: 2.2962499536493772

Epoch: 6| Step: 6
Training loss: 2.440549373626709
Validation loss: 2.301734624370452

Epoch: 6| Step: 7
Training loss: 2.2336559295654297
Validation loss: 2.297519886365501

Epoch: 6| Step: 8
Training loss: 1.9109175205230713
Validation loss: 2.3003730620107343

Epoch: 6| Step: 9
Training loss: 2.6909358501434326
Validation loss: 2.297902743021647

Epoch: 6| Step: 10
Training loss: 2.486501693725586
Validation loss: 2.2955710041907524

Epoch: 6| Step: 11
Training loss: 3.219982624053955
Validation loss: 2.3011857489103913

Epoch: 6| Step: 12
Training loss: 2.5528805255889893
Validation loss: 2.302763590248682

Epoch: 6| Step: 13
Training loss: 3.1813957691192627
Validation loss: 2.311576630479546

Epoch: 105| Step: 0
Training loss: 2.6502394676208496
Validation loss: 2.3133194728564193

Epoch: 6| Step: 1
Training loss: 2.4446370601654053
Validation loss: 2.3238400361871205

Epoch: 6| Step: 2
Training loss: 2.5673046112060547
Validation loss: 2.325955214038972

Epoch: 6| Step: 3
Training loss: 2.365208387374878
Validation loss: 2.3465243052410822

Epoch: 6| Step: 4
Training loss: 1.8806034326553345
Validation loss: 2.347197678781325

Epoch: 6| Step: 5
Training loss: 2.4842352867126465
Validation loss: 2.3246792542037142

Epoch: 6| Step: 6
Training loss: 2.5320115089416504
Validation loss: 2.3038762051572084

Epoch: 6| Step: 7
Training loss: 2.8559987545013428
Validation loss: 2.2956025292796474

Epoch: 6| Step: 8
Training loss: 2.3627431392669678
Validation loss: 2.291504257468767

Epoch: 6| Step: 9
Training loss: 2.9185733795166016
Validation loss: 2.284815808778168

Epoch: 6| Step: 10
Training loss: 3.1946473121643066
Validation loss: 2.288327378611411

Epoch: 6| Step: 11
Training loss: 2.432767629623413
Validation loss: 2.284494633315712

Epoch: 6| Step: 12
Training loss: 2.5814733505249023
Validation loss: 2.2855940634204495

Epoch: 6| Step: 13
Training loss: 2.39111065864563
Validation loss: 2.2887176390617125

Epoch: 106| Step: 0
Training loss: 1.991858959197998
Validation loss: 2.290347571014076

Epoch: 6| Step: 1
Training loss: 2.356905698776245
Validation loss: 2.2890634767470823

Epoch: 6| Step: 2
Training loss: 2.4032599925994873
Validation loss: 2.298894143873645

Epoch: 6| Step: 3
Training loss: 2.593712091445923
Validation loss: 2.298507090537779

Epoch: 6| Step: 4
Training loss: 2.432803153991699
Validation loss: 2.3078941145250873

Epoch: 6| Step: 5
Training loss: 1.7780535221099854
Validation loss: 2.317140112641037

Epoch: 6| Step: 6
Training loss: 2.2511634826660156
Validation loss: 2.3258766538353375

Epoch: 6| Step: 7
Training loss: 2.03955340385437
Validation loss: 2.3358032805945284

Epoch: 6| Step: 8
Training loss: 2.6007351875305176
Validation loss: 2.325845177455615

Epoch: 6| Step: 9
Training loss: 3.091552495956421
Validation loss: 2.3144012856227096

Epoch: 6| Step: 10
Training loss: 2.9889159202575684
Validation loss: 2.3075272626774286

Epoch: 6| Step: 11
Training loss: 3.490875244140625
Validation loss: 2.2994787590478056

Epoch: 6| Step: 12
Training loss: 2.7447590827941895
Validation loss: 2.28174731808324

Epoch: 6| Step: 13
Training loss: 2.9556479454040527
Validation loss: 2.2852150445343344

Epoch: 107| Step: 0
Training loss: 2.652639865875244
Validation loss: 2.2894147878052085

Epoch: 6| Step: 1
Training loss: 2.2196948528289795
Validation loss: 2.2875566713271605

Epoch: 6| Step: 2
Training loss: 2.227750062942505
Validation loss: 2.30178528447305

Epoch: 6| Step: 3
Training loss: 2.335689067840576
Validation loss: 2.311727059784756

Epoch: 6| Step: 4
Training loss: 2.490662097930908
Validation loss: 2.3341410518974386

Epoch: 6| Step: 5
Training loss: 3.3956992626190186
Validation loss: 2.345314912898566

Epoch: 6| Step: 6
Training loss: 2.839339256286621
Validation loss: 2.3711809124997867

Epoch: 6| Step: 7
Training loss: 1.330863118171692
Validation loss: 2.361702508823846

Epoch: 6| Step: 8
Training loss: 2.42262601852417
Validation loss: 2.369206666946411

Epoch: 6| Step: 9
Training loss: 2.6138687133789062
Validation loss: 2.3659831003476213

Epoch: 6| Step: 10
Training loss: 2.7735586166381836
Validation loss: 2.3624635486192602

Epoch: 6| Step: 11
Training loss: 3.415320873260498
Validation loss: 2.3333032438831944

Epoch: 6| Step: 12
Training loss: 2.556002140045166
Validation loss: 2.3098067891213203

Epoch: 6| Step: 13
Training loss: 2.365410566329956
Validation loss: 2.301238493252826

Epoch: 108| Step: 0
Training loss: 2.3541810512542725
Validation loss: 2.29574098894673

Epoch: 6| Step: 1
Training loss: 1.7935874462127686
Validation loss: 2.2863339326714955

Epoch: 6| Step: 2
Training loss: 2.784891128540039
Validation loss: 2.2935338174143145

Epoch: 6| Step: 3
Training loss: 2.959705352783203
Validation loss: 2.296996501184279

Epoch: 6| Step: 4
Training loss: 2.660679340362549
Validation loss: 2.302438692380023

Epoch: 6| Step: 5
Training loss: 2.46003794670105
Validation loss: 2.30189735017797

Epoch: 6| Step: 6
Training loss: 3.1424689292907715
Validation loss: 2.2947356239441903

Epoch: 6| Step: 7
Training loss: 2.198106050491333
Validation loss: 2.2955069798295216

Epoch: 6| Step: 8
Training loss: 2.453251600265503
Validation loss: 2.288190762201945

Epoch: 6| Step: 9
Training loss: 2.23146915435791
Validation loss: 2.2833682721660984

Epoch: 6| Step: 10
Training loss: 2.4022741317749023
Validation loss: 2.291286576178766

Epoch: 6| Step: 11
Training loss: 3.2375781536102295
Validation loss: 2.2919036803707

Epoch: 6| Step: 12
Training loss: 2.1496129035949707
Validation loss: 2.2852354921320432

Epoch: 6| Step: 13
Training loss: 3.273200273513794
Validation loss: 2.2880349595059633

Epoch: 109| Step: 0
Training loss: 2.436131715774536
Validation loss: 2.29181561675123

Epoch: 6| Step: 1
Training loss: 2.3131284713745117
Validation loss: 2.301854795025241

Epoch: 6| Step: 2
Training loss: 2.9118123054504395
Validation loss: 2.3084799602467525

Epoch: 6| Step: 3
Training loss: 3.0053677558898926
Validation loss: 2.317277749379476

Epoch: 6| Step: 4
Training loss: 1.775377631187439
Validation loss: 2.329172052362914

Epoch: 6| Step: 5
Training loss: 1.6072537899017334
Validation loss: 2.337589058824765

Epoch: 6| Step: 6
Training loss: 2.6922972202301025
Validation loss: 2.3443338383910475

Epoch: 6| Step: 7
Training loss: 2.1768312454223633
Validation loss: 2.3327651049501155

Epoch: 6| Step: 8
Training loss: 2.3933987617492676
Validation loss: 2.323935257491245

Epoch: 6| Step: 9
Training loss: 3.297308921813965
Validation loss: 2.299150997592557

Epoch: 6| Step: 10
Training loss: 3.402153253555298
Validation loss: 2.2880838609510854

Epoch: 6| Step: 11
Training loss: 2.951099395751953
Validation loss: 2.2796461095092115

Epoch: 6| Step: 12
Training loss: 2.5023748874664307
Validation loss: 2.2670610386838197

Epoch: 6| Step: 13
Training loss: 1.8587960004806519
Validation loss: 2.27289338778424

Epoch: 110| Step: 0
Training loss: 2.230318546295166
Validation loss: 2.2667965555703766

Epoch: 6| Step: 1
Training loss: 2.2370121479034424
Validation loss: 2.2681106457146267

Epoch: 6| Step: 2
Training loss: 2.1240851879119873
Validation loss: 2.2746660594017274

Epoch: 6| Step: 3
Training loss: 2.3679070472717285
Validation loss: 2.282788791964131

Epoch: 6| Step: 4
Training loss: 2.811161518096924
Validation loss: 2.3052266772075365

Epoch: 6| Step: 5
Training loss: 3.032252788543701
Validation loss: 2.319151891175137

Epoch: 6| Step: 6
Training loss: 2.4727160930633545
Validation loss: 2.3209374412413566

Epoch: 6| Step: 7
Training loss: 2.4494152069091797
Validation loss: 2.3258822169355167

Epoch: 6| Step: 8
Training loss: 2.71291184425354
Validation loss: 2.333676702232771

Epoch: 6| Step: 9
Training loss: 2.3745920658111572
Validation loss: 2.3200990051351567

Epoch: 6| Step: 10
Training loss: 3.2665107250213623
Validation loss: 2.3026115330316688

Epoch: 6| Step: 11
Training loss: 2.47243070602417
Validation loss: 2.2859675230518466

Epoch: 6| Step: 12
Training loss: 2.121347427368164
Validation loss: 2.2794871830171153

Epoch: 6| Step: 13
Training loss: 3.236243724822998
Validation loss: 2.2778437086330947

Epoch: 111| Step: 0
Training loss: 3.401585340499878
Validation loss: 2.2821388193356094

Epoch: 6| Step: 1
Training loss: 2.6468944549560547
Validation loss: 2.273496432970929

Epoch: 6| Step: 2
Training loss: 2.0679728984832764
Validation loss: 2.2727077340566986

Epoch: 6| Step: 3
Training loss: 2.322119951248169
Validation loss: 2.2729777136156635

Epoch: 6| Step: 4
Training loss: 1.906064748764038
Validation loss: 2.270939824401691

Epoch: 6| Step: 5
Training loss: 2.743654727935791
Validation loss: 2.2720307637286443

Epoch: 6| Step: 6
Training loss: 2.549318552017212
Validation loss: 2.26393082064967

Epoch: 6| Step: 7
Training loss: 2.364861488342285
Validation loss: 2.265883953340592

Epoch: 6| Step: 8
Training loss: 2.757871627807617
Validation loss: 2.2696253176658385

Epoch: 6| Step: 9
Training loss: 2.3817648887634277
Validation loss: 2.2731976842367523

Epoch: 6| Step: 10
Training loss: 2.442607879638672
Validation loss: 2.273932013460385

Epoch: 6| Step: 11
Training loss: 2.6528220176696777
Validation loss: 2.2755704438814552

Epoch: 6| Step: 12
Training loss: 2.049637794494629
Validation loss: 2.2723031146551973

Epoch: 6| Step: 13
Training loss: 3.555710792541504
Validation loss: 2.2932227888414936

Epoch: 112| Step: 0
Training loss: 2.9873764514923096
Validation loss: 2.2960522123562392

Epoch: 6| Step: 1
Training loss: 1.8641011714935303
Validation loss: 2.310246882900115

Epoch: 6| Step: 2
Training loss: 2.355304718017578
Validation loss: 2.3223894180790072

Epoch: 6| Step: 3
Training loss: 1.9790058135986328
Validation loss: 2.3517079660969396

Epoch: 6| Step: 4
Training loss: 2.5765132904052734
Validation loss: 2.3593748513088433

Epoch: 6| Step: 5
Training loss: 2.942194700241089
Validation loss: 2.3358434079795756

Epoch: 6| Step: 6
Training loss: 2.456130027770996
Validation loss: 2.3341497452028337

Epoch: 6| Step: 7
Training loss: 3.559391975402832
Validation loss: 2.3086986567384455

Epoch: 6| Step: 8
Training loss: 1.7047947645187378
Validation loss: 2.283034498973559

Epoch: 6| Step: 9
Training loss: 2.646657705307007
Validation loss: 2.2731961973251833

Epoch: 6| Step: 10
Training loss: 2.1709272861480713
Validation loss: 2.273989715883809

Epoch: 6| Step: 11
Training loss: 3.125826358795166
Validation loss: 2.2728092157712547

Epoch: 6| Step: 12
Training loss: 2.820167064666748
Validation loss: 2.275657687135922

Epoch: 6| Step: 13
Training loss: 2.0458755493164062
Validation loss: 2.272424764530633

Epoch: 113| Step: 0
Training loss: 2.7740557193756104
Validation loss: 2.275251588513774

Epoch: 6| Step: 1
Training loss: 2.7387757301330566
Validation loss: 2.2811814687585317

Epoch: 6| Step: 2
Training loss: 2.4445948600769043
Validation loss: 2.29451496114013

Epoch: 6| Step: 3
Training loss: 1.6754040718078613
Validation loss: 2.2868316417099326

Epoch: 6| Step: 4
Training loss: 2.4732038974761963
Validation loss: 2.2981808518850677

Epoch: 6| Step: 5
Training loss: 2.5662283897399902
Validation loss: 2.2942664725806123

Epoch: 6| Step: 6
Training loss: 2.280360221862793
Validation loss: 2.308452683110391

Epoch: 6| Step: 7
Training loss: 2.4904189109802246
Validation loss: 2.2990576938916276

Epoch: 6| Step: 8
Training loss: 2.446726083755493
Validation loss: 2.3052587278427614

Epoch: 6| Step: 9
Training loss: 2.776866912841797
Validation loss: 2.312013687626008

Epoch: 6| Step: 10
Training loss: 3.175691604614258
Validation loss: 2.3072703935766734

Epoch: 6| Step: 11
Training loss: 1.8428606986999512
Validation loss: 2.2938939935417584

Epoch: 6| Step: 12
Training loss: 3.010646104812622
Validation loss: 2.298571122589932

Epoch: 6| Step: 13
Training loss: 2.4815781116485596
Validation loss: 2.3012505808184223

Epoch: 114| Step: 0
Training loss: 3.106746196746826
Validation loss: 2.299649929487577

Epoch: 6| Step: 1
Training loss: 2.4012417793273926
Validation loss: 2.2906086316672702

Epoch: 6| Step: 2
Training loss: 2.452287435531616
Validation loss: 2.2761309146881104

Epoch: 6| Step: 3
Training loss: 2.4234187602996826
Validation loss: 2.273341296821512

Epoch: 6| Step: 4
Training loss: 2.881037473678589
Validation loss: 2.263911803563436

Epoch: 6| Step: 5
Training loss: 1.9568055868148804
Validation loss: 2.2636562803740143

Epoch: 6| Step: 6
Training loss: 2.942474365234375
Validation loss: 2.2650744069007134

Epoch: 6| Step: 7
Training loss: 2.2692995071411133
Validation loss: 2.2655340702302995

Epoch: 6| Step: 8
Training loss: 3.015644073486328
Validation loss: 2.2722818569470475

Epoch: 6| Step: 9
Training loss: 1.830815076828003
Validation loss: 2.271108450428132

Epoch: 6| Step: 10
Training loss: 2.3404014110565186
Validation loss: 2.2882140092952277

Epoch: 6| Step: 11
Training loss: 3.0147342681884766
Validation loss: 2.2878830407255437

Epoch: 6| Step: 12
Training loss: 1.9777076244354248
Validation loss: 2.2910059600748043

Epoch: 6| Step: 13
Training loss: 2.6745753288269043
Validation loss: 2.2916255176708265

Epoch: 115| Step: 0
Training loss: 2.6785407066345215
Validation loss: 2.302710161414198

Epoch: 6| Step: 1
Training loss: 2.5528504848480225
Validation loss: 2.307781542501142

Epoch: 6| Step: 2
Training loss: 2.5733752250671387
Validation loss: 2.303110853318245

Epoch: 6| Step: 3
Training loss: 2.84576416015625
Validation loss: 2.3016778551122195

Epoch: 6| Step: 4
Training loss: 2.512282609939575
Validation loss: 2.2855885131384737

Epoch: 6| Step: 5
Training loss: 2.0556721687316895
Validation loss: 2.2741732366623415

Epoch: 6| Step: 6
Training loss: 2.4435291290283203
Validation loss: 2.260536165647609

Epoch: 6| Step: 7
Training loss: 2.5317649841308594
Validation loss: 2.258455099598054

Epoch: 6| Step: 8
Training loss: 2.9878506660461426
Validation loss: 2.267218300091323

Epoch: 6| Step: 9
Training loss: 2.6532750129699707
Validation loss: 2.264667244367702

Epoch: 6| Step: 10
Training loss: 2.4493966102600098
Validation loss: 2.264003889535063

Epoch: 6| Step: 11
Training loss: 2.5009193420410156
Validation loss: 2.2603124905658025

Epoch: 6| Step: 12
Training loss: 1.8560292720794678
Validation loss: 2.2693474087663876

Epoch: 6| Step: 13
Training loss: 2.5759007930755615
Validation loss: 2.275019927691388

Epoch: 116| Step: 0
Training loss: 3.0836598873138428
Validation loss: 2.2808826738788235

Epoch: 6| Step: 1
Training loss: 2.971977949142456
Validation loss: 2.2946310658608713

Epoch: 6| Step: 2
Training loss: 1.9789353609085083
Validation loss: 2.312687494421518

Epoch: 6| Step: 3
Training loss: 2.1145389080047607
Validation loss: 2.3326750288727465

Epoch: 6| Step: 4
Training loss: 2.1043717861175537
Validation loss: 2.331274196665774

Epoch: 6| Step: 5
Training loss: 2.2198538780212402
Validation loss: 2.3299966473733225

Epoch: 6| Step: 6
Training loss: 2.9462273120880127
Validation loss: 2.3268397136401107

Epoch: 6| Step: 7
Training loss: 2.828850507736206
Validation loss: 2.3010773351115565

Epoch: 6| Step: 8
Training loss: 1.86429762840271
Validation loss: 2.2979291305747083

Epoch: 6| Step: 9
Training loss: 2.877870559692383
Validation loss: 2.294569392358103

Epoch: 6| Step: 10
Training loss: 2.9255149364471436
Validation loss: 2.2886461686062556

Epoch: 6| Step: 11
Training loss: 2.5202207565307617
Validation loss: 2.2761264975352953

Epoch: 6| Step: 12
Training loss: 2.459491014480591
Validation loss: 2.2799175272705736

Epoch: 6| Step: 13
Training loss: 1.9422463178634644
Validation loss: 2.2799214983499176

Epoch: 117| Step: 0
Training loss: 2.649559497833252
Validation loss: 2.278433204979025

Epoch: 6| Step: 1
Training loss: 2.1731793880462646
Validation loss: 2.2634137138243644

Epoch: 6| Step: 2
Training loss: 2.9831149578094482
Validation loss: 2.25718431831688

Epoch: 6| Step: 3
Training loss: 2.524474620819092
Validation loss: 2.25305143479378

Epoch: 6| Step: 4
Training loss: 2.599997043609619
Validation loss: 2.260953971134719

Epoch: 6| Step: 5
Training loss: 2.3054494857788086
Validation loss: 2.258110225841563

Epoch: 6| Step: 6
Training loss: 2.532886505126953
Validation loss: 2.259692351023356

Epoch: 6| Step: 7
Training loss: 2.8040637969970703
Validation loss: 2.2645034251674527

Epoch: 6| Step: 8
Training loss: 2.1312546730041504
Validation loss: 2.2671732261616695

Epoch: 6| Step: 9
Training loss: 2.5534021854400635
Validation loss: 2.2758512163674958

Epoch: 6| Step: 10
Training loss: 2.3160064220428467
Validation loss: 2.2870518866405694

Epoch: 6| Step: 11
Training loss: 1.816731572151184
Validation loss: 2.2763766934794765

Epoch: 6| Step: 12
Training loss: 2.7799296379089355
Validation loss: 2.2822997236764557

Epoch: 6| Step: 13
Training loss: 3.338716983795166
Validation loss: 2.284048200935446

Epoch: 118| Step: 0
Training loss: 3.289686441421509
Validation loss: 2.2775320622228805

Epoch: 6| Step: 1
Training loss: 2.443929672241211
Validation loss: 2.2693031628926597

Epoch: 6| Step: 2
Training loss: 2.776211977005005
Validation loss: 2.2604150797731135

Epoch: 6| Step: 3
Training loss: 1.826171636581421
Validation loss: 2.2604274198573124

Epoch: 6| Step: 4
Training loss: 2.2600605487823486
Validation loss: 2.2659128122432257

Epoch: 6| Step: 5
Training loss: 2.8746142387390137
Validation loss: 2.265316136421696

Epoch: 6| Step: 6
Training loss: 2.2923758029937744
Validation loss: 2.2661871320457867

Epoch: 6| Step: 7
Training loss: 1.5780541896820068
Validation loss: 2.2674410202169932

Epoch: 6| Step: 8
Training loss: 2.8849480152130127
Validation loss: 2.2683795344445015

Epoch: 6| Step: 9
Training loss: 2.4240410327911377
Validation loss: 2.266135072195402

Epoch: 6| Step: 10
Training loss: 3.1768298149108887
Validation loss: 2.2648644703690723

Epoch: 6| Step: 11
Training loss: 2.118143081665039
Validation loss: 2.2601296773520847

Epoch: 6| Step: 12
Training loss: 2.374068260192871
Validation loss: 2.258934041505219

Epoch: 6| Step: 13
Training loss: 2.931509256362915
Validation loss: 2.263851378553657

Epoch: 119| Step: 0
Training loss: 2.868431568145752
Validation loss: 2.2789951934609363

Epoch: 6| Step: 1
Training loss: 2.3134078979492188
Validation loss: 2.282803222697268

Epoch: 6| Step: 2
Training loss: 2.6680266857147217
Validation loss: 2.2950355237530125

Epoch: 6| Step: 3
Training loss: 2.22324800491333
Validation loss: 2.288681330219392

Epoch: 6| Step: 4
Training loss: 2.1730539798736572
Validation loss: 2.2931758998542704

Epoch: 6| Step: 5
Training loss: 3.016246795654297
Validation loss: 2.2989813358552995

Epoch: 6| Step: 6
Training loss: 2.9586000442504883
Validation loss: 2.2935715721499537

Epoch: 6| Step: 7
Training loss: 2.111466407775879
Validation loss: 2.2959676519516976

Epoch: 6| Step: 8
Training loss: 2.082176446914673
Validation loss: 2.285407543182373

Epoch: 6| Step: 9
Training loss: 1.7327497005462646
Validation loss: 2.2832561603156467

Epoch: 6| Step: 10
Training loss: 2.443510055541992
Validation loss: 2.271089671760477

Epoch: 6| Step: 11
Training loss: 3.028207778930664
Validation loss: 2.2717365500747517

Epoch: 6| Step: 12
Training loss: 3.242372989654541
Validation loss: 2.275623413824266

Epoch: 6| Step: 13
Training loss: 1.9922215938568115
Validation loss: 2.2820140866823095

Epoch: 120| Step: 0
Training loss: 2.453099250793457
Validation loss: 2.2641875179865028

Epoch: 6| Step: 1
Training loss: 1.7560744285583496
Validation loss: 2.26807665312162

Epoch: 6| Step: 2
Training loss: 2.088813304901123
Validation loss: 2.2643350298686693

Epoch: 6| Step: 3
Training loss: 2.463627576828003
Validation loss: 2.2758815749999015

Epoch: 6| Step: 4
Training loss: 1.845815896987915
Validation loss: 2.2785071685749996

Epoch: 6| Step: 5
Training loss: 2.5231728553771973
Validation loss: 2.279605298913935

Epoch: 6| Step: 6
Training loss: 3.475942611694336
Validation loss: 2.2940583126519316

Epoch: 6| Step: 7
Training loss: 2.0753772258758545
Validation loss: 2.289697806040446

Epoch: 6| Step: 8
Training loss: 2.383626699447632
Validation loss: 2.28466704071209

Epoch: 6| Step: 9
Training loss: 2.4884486198425293
Validation loss: 2.2838442992138606

Epoch: 6| Step: 10
Training loss: 3.0017147064208984
Validation loss: 2.2825745203161754

Epoch: 6| Step: 11
Training loss: 2.492784023284912
Validation loss: 2.2630526070953696

Epoch: 6| Step: 12
Training loss: 2.9470834732055664
Validation loss: 2.2629247660277994

Epoch: 6| Step: 13
Training loss: 3.374781370162964
Validation loss: 2.252578225187076

Epoch: 121| Step: 0
Training loss: 2.3964710235595703
Validation loss: 2.236499778686031

Epoch: 6| Step: 1
Training loss: 3.119013786315918
Validation loss: 2.234613723652337

Epoch: 6| Step: 2
Training loss: 2.0823516845703125
Validation loss: 2.231750370353781

Epoch: 6| Step: 3
Training loss: 2.4159088134765625
Validation loss: 2.233474046953263

Epoch: 6| Step: 4
Training loss: 2.699230670928955
Validation loss: 2.229716718837779

Epoch: 6| Step: 5
Training loss: 2.930514335632324
Validation loss: 2.2321243619406097

Epoch: 6| Step: 6
Training loss: 2.3864755630493164
Validation loss: 2.227320777472629

Epoch: 6| Step: 7
Training loss: 2.6319451332092285
Validation loss: 2.2324625933042137

Epoch: 6| Step: 8
Training loss: 3.197991371154785
Validation loss: 2.2297212231543755

Epoch: 6| Step: 9
Training loss: 2.630681276321411
Validation loss: 2.2376016647584978

Epoch: 6| Step: 10
Training loss: 2.415644645690918
Validation loss: 2.2280974080485683

Epoch: 6| Step: 11
Training loss: 1.43350350856781
Validation loss: 2.2375887875915854

Epoch: 6| Step: 12
Training loss: 2.134007215499878
Validation loss: 2.24353346004281

Epoch: 6| Step: 13
Training loss: 2.6385302543640137
Validation loss: 2.2763606784164265

Epoch: 122| Step: 0
Training loss: 2.6165456771850586
Validation loss: 2.31104770142545

Epoch: 6| Step: 1
Training loss: 2.4088351726531982
Validation loss: 2.3266249010639806

Epoch: 6| Step: 2
Training loss: 2.2376298904418945
Validation loss: 2.3039200113665674

Epoch: 6| Step: 3
Training loss: 2.7519755363464355
Validation loss: 2.2732770212234987

Epoch: 6| Step: 4
Training loss: 2.234419345855713
Validation loss: 2.247445874316718

Epoch: 6| Step: 5
Training loss: 2.4470114707946777
Validation loss: 2.233705489866195

Epoch: 6| Step: 6
Training loss: 3.0030031204223633
Validation loss: 2.219673382338657

Epoch: 6| Step: 7
Training loss: 2.5830228328704834
Validation loss: 2.2208877327621623

Epoch: 6| Step: 8
Training loss: 2.6764471530914307
Validation loss: 2.221710455033087

Epoch: 6| Step: 9
Training loss: 3.1044626235961914
Validation loss: 2.2199848390394643

Epoch: 6| Step: 10
Training loss: 2.2055814266204834
Validation loss: 2.2323832922084357

Epoch: 6| Step: 11
Training loss: 2.5435681343078613
Validation loss: 2.2390938753722818

Epoch: 6| Step: 12
Training loss: 2.113435983657837
Validation loss: 2.2343025694611254

Epoch: 6| Step: 13
Training loss: 2.102544069290161
Validation loss: 2.2316049093841226

Epoch: 123| Step: 0
Training loss: 2.3535547256469727
Validation loss: 2.233432076310599

Epoch: 6| Step: 1
Training loss: 2.6849093437194824
Validation loss: 2.2327507157479562

Epoch: 6| Step: 2
Training loss: 3.249244213104248
Validation loss: 2.251473157636581

Epoch: 6| Step: 3
Training loss: 2.9032304286956787
Validation loss: 2.264887691825949

Epoch: 6| Step: 4
Training loss: 2.1051249504089355
Validation loss: 2.273314352958433

Epoch: 6| Step: 5
Training loss: 2.3467767238616943
Validation loss: 2.2825272416555755

Epoch: 6| Step: 6
Training loss: 2.2744550704956055
Validation loss: 2.288917259503436

Epoch: 6| Step: 7
Training loss: 2.902445077896118
Validation loss: 2.295304500928489

Epoch: 6| Step: 8
Training loss: 2.815013885498047
Validation loss: 2.273065386279937

Epoch: 6| Step: 9
Training loss: 2.4963486194610596
Validation loss: 2.2633830924187937

Epoch: 6| Step: 10
Training loss: 2.0215377807617188
Validation loss: 2.2514133197005077

Epoch: 6| Step: 11
Training loss: 2.0212714672088623
Validation loss: 2.241695296379828

Epoch: 6| Step: 12
Training loss: 2.245560646057129
Validation loss: 2.2433668285287838

Epoch: 6| Step: 13
Training loss: 2.559356927871704
Validation loss: 2.2367016320587485

Epoch: 124| Step: 0
Training loss: 1.6402838230133057
Validation loss: 2.2427626040674027

Epoch: 6| Step: 1
Training loss: 2.469364643096924
Validation loss: 2.2535049787131687

Epoch: 6| Step: 2
Training loss: 2.834123134613037
Validation loss: 2.252943023558586

Epoch: 6| Step: 3
Training loss: 2.674198865890503
Validation loss: 2.2555532865626837

Epoch: 6| Step: 4
Training loss: 2.072134017944336
Validation loss: 2.264374493270792

Epoch: 6| Step: 5
Training loss: 2.5608744621276855
Validation loss: 2.2620179576258503

Epoch: 6| Step: 6
Training loss: 3.3267884254455566
Validation loss: 2.2655407100595455

Epoch: 6| Step: 7
Training loss: 3.2194979190826416
Validation loss: 2.2802955540277625

Epoch: 6| Step: 8
Training loss: 2.108511209487915
Validation loss: 2.2741816556581886

Epoch: 6| Step: 9
Training loss: 2.4323534965515137
Validation loss: 2.2712912585145686

Epoch: 6| Step: 10
Training loss: 2.3299460411071777
Validation loss: 2.2708038540296656

Epoch: 6| Step: 11
Training loss: 1.5303581953048706
Validation loss: 2.2799226801882506

Epoch: 6| Step: 12
Training loss: 2.6573915481567383
Validation loss: 2.3026739192265335

Epoch: 6| Step: 13
Training loss: 3.192690372467041
Validation loss: 2.3141409248434086

Epoch: 125| Step: 0
Training loss: 3.0528364181518555
Validation loss: 2.3240188731942126

Epoch: 6| Step: 1
Training loss: 2.353346586227417
Validation loss: 2.320285410009405

Epoch: 6| Step: 2
Training loss: 2.1343166828155518
Validation loss: 2.3034016842483194

Epoch: 6| Step: 3
Training loss: 2.651021957397461
Validation loss: 2.2855600798001854

Epoch: 6| Step: 4
Training loss: 2.2713418006896973
Validation loss: 2.2622679471969604

Epoch: 6| Step: 5
Training loss: 1.9167945384979248
Validation loss: 2.254447898557109

Epoch: 6| Step: 6
Training loss: 2.5995874404907227
Validation loss: 2.2319709101030902

Epoch: 6| Step: 7
Training loss: 3.569981098175049
Validation loss: 2.2186026137362242

Epoch: 6| Step: 8
Training loss: 2.577944278717041
Validation loss: 2.210151216035248

Epoch: 6| Step: 9
Training loss: 2.943704605102539
Validation loss: 2.210189160480294

Epoch: 6| Step: 10
Training loss: 1.7580307722091675
Validation loss: 2.2202447819453415

Epoch: 6| Step: 11
Training loss: 2.3940985202789307
Validation loss: 2.2194458079594437

Epoch: 6| Step: 12
Training loss: 2.432767152786255
Validation loss: 2.22561667683304

Epoch: 6| Step: 13
Training loss: 2.037196636199951
Validation loss: 2.222004598186862

Epoch: 126| Step: 0
Training loss: 2.77199125289917
Validation loss: 2.2255182112416914

Epoch: 6| Step: 1
Training loss: 2.0715138912200928
Validation loss: 2.2318966081065517

Epoch: 6| Step: 2
Training loss: 2.6656627655029297
Validation loss: 2.2438845083277714

Epoch: 6| Step: 3
Training loss: 2.497314691543579
Validation loss: 2.2546338701760895

Epoch: 6| Step: 4
Training loss: 1.8938068151474
Validation loss: 2.2690910472664783

Epoch: 6| Step: 5
Training loss: 2.5862202644348145
Validation loss: 2.258639052350034

Epoch: 6| Step: 6
Training loss: 2.5473227500915527
Validation loss: 2.2556700911573184

Epoch: 6| Step: 7
Training loss: 2.5105209350585938
Validation loss: 2.256093312335271

Epoch: 6| Step: 8
Training loss: 2.4125869274139404
Validation loss: 2.250558063548098

Epoch: 6| Step: 9
Training loss: 3.075531005859375
Validation loss: 2.250205675760905

Epoch: 6| Step: 10
Training loss: 2.4606876373291016
Validation loss: 2.238898754119873

Epoch: 6| Step: 11
Training loss: 2.379326820373535
Validation loss: 2.240445621552006

Epoch: 6| Step: 12
Training loss: 2.622990131378174
Validation loss: 2.2380060982960526

Epoch: 6| Step: 13
Training loss: 1.9707908630371094
Validation loss: 2.2442765543537755

Epoch: 127| Step: 0
Training loss: 2.1246089935302734
Validation loss: 2.244556015537631

Epoch: 6| Step: 1
Training loss: 1.9062083959579468
Validation loss: 2.2440740036708053

Epoch: 6| Step: 2
Training loss: 1.998462438583374
Validation loss: 2.248686736629855

Epoch: 6| Step: 3
Training loss: 2.1167244911193848
Validation loss: 2.260030872078352

Epoch: 6| Step: 4
Training loss: 2.3319344520568848
Validation loss: 2.2617286123255247

Epoch: 6| Step: 5
Training loss: 2.7190423011779785
Validation loss: 2.2839929570433912

Epoch: 6| Step: 6
Training loss: 2.5187997817993164
Validation loss: 2.2838417330095844

Epoch: 6| Step: 7
Training loss: 2.369616985321045
Validation loss: 2.2827329661256526

Epoch: 6| Step: 8
Training loss: 2.7632505893707275
Validation loss: 2.2805196290375083

Epoch: 6| Step: 9
Training loss: 3.3075404167175293
Validation loss: 2.2792556362767376

Epoch: 6| Step: 10
Training loss: 2.8283255100250244
Validation loss: 2.2809660332177275

Epoch: 6| Step: 11
Training loss: 2.2576770782470703
Validation loss: 2.290899715115947

Epoch: 6| Step: 12
Training loss: 2.754831314086914
Validation loss: 2.3110119347931235

Epoch: 6| Step: 13
Training loss: 2.7815146446228027
Validation loss: 2.301353136698405

Epoch: 128| Step: 0
Training loss: 2.2472565174102783
Validation loss: 2.296753739797941

Epoch: 6| Step: 1
Training loss: 2.058427333831787
Validation loss: 2.276273763307961

Epoch: 6| Step: 2
Training loss: 2.7069449424743652
Validation loss: 2.261185816539231

Epoch: 6| Step: 3
Training loss: 2.3127830028533936
Validation loss: 2.2619343521774455

Epoch: 6| Step: 4
Training loss: 2.331503391265869
Validation loss: 2.249558659010036

Epoch: 6| Step: 5
Training loss: 2.4901232719421387
Validation loss: 2.240565412787981

Epoch: 6| Step: 6
Training loss: 2.573188304901123
Validation loss: 2.2394483063810613

Epoch: 6| Step: 7
Training loss: 3.228038787841797
Validation loss: 2.238967498143514

Epoch: 6| Step: 8
Training loss: 3.2691617012023926
Validation loss: 2.242475237897647

Epoch: 6| Step: 9
Training loss: 2.2870078086853027
Validation loss: 2.2375569933204242

Epoch: 6| Step: 10
Training loss: 2.761462688446045
Validation loss: 2.2279208155088526

Epoch: 6| Step: 11
Training loss: 2.3203203678131104
Validation loss: 2.218511232765772

Epoch: 6| Step: 12
Training loss: 2.094191074371338
Validation loss: 2.2078131065573743

Epoch: 6| Step: 13
Training loss: 1.5506268739700317
Validation loss: 2.2185418657077256

Epoch: 129| Step: 0
Training loss: 1.8337409496307373
Validation loss: 2.230240386019471

Epoch: 6| Step: 1
Training loss: 3.050448417663574
Validation loss: 2.2329803487306

Epoch: 6| Step: 2
Training loss: 2.493316650390625
Validation loss: 2.2522595697833645

Epoch: 6| Step: 3
Training loss: 2.4412155151367188
Validation loss: 2.258740504582723

Epoch: 6| Step: 4
Training loss: 2.25124192237854
Validation loss: 2.274270587070014

Epoch: 6| Step: 5
Training loss: 2.1214795112609863
Validation loss: 2.288518480075303

Epoch: 6| Step: 6
Training loss: 1.9757500886917114
Validation loss: 2.2902150846296743

Epoch: 6| Step: 7
Training loss: 2.7703254222869873
Validation loss: 2.2917308243372108

Epoch: 6| Step: 8
Training loss: 2.6592893600463867
Validation loss: 2.27982065754552

Epoch: 6| Step: 9
Training loss: 2.509622097015381
Validation loss: 2.2834189681596655

Epoch: 6| Step: 10
Training loss: 2.679366111755371
Validation loss: 2.282510203699912

Epoch: 6| Step: 11
Training loss: 2.274019718170166
Validation loss: 2.263551576163179

Epoch: 6| Step: 12
Training loss: 2.708836078643799
Validation loss: 2.2494933041193153

Epoch: 6| Step: 13
Training loss: 2.86457896232605
Validation loss: 2.2484089789852018

Epoch: 130| Step: 0
Training loss: 1.9830071926116943
Validation loss: 2.245668608655212

Epoch: 6| Step: 1
Training loss: 2.5818614959716797
Validation loss: 2.2411040080490934

Epoch: 6| Step: 2
Training loss: 2.609480619430542
Validation loss: 2.249379955312257

Epoch: 6| Step: 3
Training loss: 2.4788713455200195
Validation loss: 2.252956362180812

Epoch: 6| Step: 4
Training loss: 1.6431514024734497
Validation loss: 2.2526272855779177

Epoch: 6| Step: 5
Training loss: 2.9474406242370605
Validation loss: 2.2715404623298237

Epoch: 6| Step: 6
Training loss: 3.1450765132904053
Validation loss: 2.293221632639567

Epoch: 6| Step: 7
Training loss: 2.1329236030578613
Validation loss: 2.305523864684566

Epoch: 6| Step: 8
Training loss: 2.683032512664795
Validation loss: 2.317421961856145

Epoch: 6| Step: 9
Training loss: 2.0601232051849365
Validation loss: 2.334545868699269

Epoch: 6| Step: 10
Training loss: 2.986218214035034
Validation loss: 2.3465420199978735

Epoch: 6| Step: 11
Training loss: 2.6872048377990723
Validation loss: 2.3392313398340696

Epoch: 6| Step: 12
Training loss: 2.690065860748291
Validation loss: 2.3560118072776386

Epoch: 6| Step: 13
Training loss: 1.7961660623550415
Validation loss: 2.3678361369717504

Epoch: 131| Step: 0
Training loss: 3.2363109588623047
Validation loss: 2.391867491506761

Epoch: 6| Step: 1
Training loss: 2.780024766921997
Validation loss: 2.3740590926139586

Epoch: 6| Step: 2
Training loss: 3.419154644012451
Validation loss: 2.3494106954143894

Epoch: 6| Step: 3
Training loss: 2.30526065826416
Validation loss: 2.3161213321070515

Epoch: 6| Step: 4
Training loss: 2.3263983726501465
Validation loss: 2.3115007685076807

Epoch: 6| Step: 5
Training loss: 2.447072744369507
Validation loss: 2.3037528940426406

Epoch: 6| Step: 6
Training loss: 2.9436049461364746
Validation loss: 2.308387476910827

Epoch: 6| Step: 7
Training loss: 2.1597037315368652
Validation loss: 2.2957315624401136

Epoch: 6| Step: 8
Training loss: 2.158292531967163
Validation loss: 2.2790296129001084

Epoch: 6| Step: 9
Training loss: 1.8792290687561035
Validation loss: 2.2635310798562984

Epoch: 6| Step: 10
Training loss: 2.3048858642578125
Validation loss: 2.236763443998111

Epoch: 6| Step: 11
Training loss: 2.1228270530700684
Validation loss: 2.230867765283072

Epoch: 6| Step: 12
Training loss: 2.512345790863037
Validation loss: 2.233747943755119

Epoch: 6| Step: 13
Training loss: 2.453911304473877
Validation loss: 2.2511470881841515

Epoch: 132| Step: 0
Training loss: 2.4581234455108643
Validation loss: 2.2646490245737056

Epoch: 6| Step: 1
Training loss: 1.7627980709075928
Validation loss: 2.297871282023768

Epoch: 6| Step: 2
Training loss: 2.5311431884765625
Validation loss: 2.2842792131567515

Epoch: 6| Step: 3
Training loss: 2.529583215713501
Validation loss: 2.2845775593993483

Epoch: 6| Step: 4
Training loss: 2.868821144104004
Validation loss: 2.2728095503263575

Epoch: 6| Step: 5
Training loss: 1.7329514026641846
Validation loss: 2.2746218865917576

Epoch: 6| Step: 6
Training loss: 2.4691247940063477
Validation loss: 2.264130437245933

Epoch: 6| Step: 7
Training loss: 2.9885048866271973
Validation loss: 2.263092730634956

Epoch: 6| Step: 8
Training loss: 2.866683006286621
Validation loss: 2.2596506534084195

Epoch: 6| Step: 9
Training loss: 2.3670921325683594
Validation loss: 2.265604475493072

Epoch: 6| Step: 10
Training loss: 2.880267381668091
Validation loss: 2.2722767809385895

Epoch: 6| Step: 11
Training loss: 2.7680344581604004
Validation loss: 2.2630729342019684

Epoch: 6| Step: 12
Training loss: 2.3359198570251465
Validation loss: 2.2771995093232844

Epoch: 6| Step: 13
Training loss: 1.4557952880859375
Validation loss: 2.263423381313201

Epoch: 133| Step: 0
Training loss: 2.2418317794799805
Validation loss: 2.2645790218025126

Epoch: 6| Step: 1
Training loss: 2.160935401916504
Validation loss: 2.2646755672270253

Epoch: 6| Step: 2
Training loss: 2.156081199645996
Validation loss: 2.2551334288812455

Epoch: 6| Step: 3
Training loss: 2.440596103668213
Validation loss: 2.252680008129407

Epoch: 6| Step: 4
Training loss: 3.2733874320983887
Validation loss: 2.2382610844027613

Epoch: 6| Step: 5
Training loss: 2.589514970779419
Validation loss: 2.2496535137135494

Epoch: 6| Step: 6
Training loss: 2.4959378242492676
Validation loss: 2.251491759413032

Epoch: 6| Step: 7
Training loss: 2.02333927154541
Validation loss: 2.2615229032372914

Epoch: 6| Step: 8
Training loss: 2.4299702644348145
Validation loss: 2.2611018739720827

Epoch: 6| Step: 9
Training loss: 2.4727845191955566
Validation loss: 2.25902574036711

Epoch: 6| Step: 10
Training loss: 2.9455084800720215
Validation loss: 2.276799614711474

Epoch: 6| Step: 11
Training loss: 2.125164747238159
Validation loss: 2.2511591090950915

Epoch: 6| Step: 12
Training loss: 2.561007499694824
Validation loss: 2.243635890304401

Epoch: 6| Step: 13
Training loss: 2.8075852394104004
Validation loss: 2.228387619859429

Epoch: 134| Step: 0
Training loss: 2.1433334350585938
Validation loss: 2.2370337645212808

Epoch: 6| Step: 1
Training loss: 2.969209909439087
Validation loss: 2.228962423980877

Epoch: 6| Step: 2
Training loss: 2.667356491088867
Validation loss: 2.2350150564665436

Epoch: 6| Step: 3
Training loss: 2.6491575241088867
Validation loss: 2.229029437547089

Epoch: 6| Step: 4
Training loss: 2.5957694053649902
Validation loss: 2.2251571327127437

Epoch: 6| Step: 5
Training loss: 2.0582833290100098
Validation loss: 2.234065294265747

Epoch: 6| Step: 6
Training loss: 2.708139419555664
Validation loss: 2.2275362373680196

Epoch: 6| Step: 7
Training loss: 2.0322160720825195
Validation loss: 2.2439775825828634

Epoch: 6| Step: 8
Training loss: 2.2258496284484863
Validation loss: 2.2425227062676543

Epoch: 6| Step: 9
Training loss: 1.5956230163574219
Validation loss: 2.2257576040042344

Epoch: 6| Step: 10
Training loss: 2.5130228996276855
Validation loss: 2.224479011310044

Epoch: 6| Step: 11
Training loss: 2.993391752243042
Validation loss: 2.2303547654100644

Epoch: 6| Step: 12
Training loss: 2.2458369731903076
Validation loss: 2.2409361921330935

Epoch: 6| Step: 13
Training loss: 3.028430938720703
Validation loss: 2.246832598922073

Epoch: 135| Step: 0
Training loss: 2.468961000442505
Validation loss: 2.2512144068235993

Epoch: 6| Step: 1
Training loss: 3.127507209777832
Validation loss: 2.243264541831068

Epoch: 6| Step: 2
Training loss: 2.556405544281006
Validation loss: 2.249567865043558

Epoch: 6| Step: 3
Training loss: 2.119033098220825
Validation loss: 2.2576981283003286

Epoch: 6| Step: 4
Training loss: 1.8852994441986084
Validation loss: 2.2713541292375132

Epoch: 6| Step: 5
Training loss: 2.0248870849609375
Validation loss: 2.2572124645274174

Epoch: 6| Step: 6
Training loss: 2.21783709526062
Validation loss: 2.2689952081249607

Epoch: 6| Step: 7
Training loss: 2.4598052501678467
Validation loss: 2.2426140257107314

Epoch: 6| Step: 8
Training loss: 2.780975341796875
Validation loss: 2.2287215007248746

Epoch: 6| Step: 9
Training loss: 2.059783697128296
Validation loss: 2.2397296531226045

Epoch: 6| Step: 10
Training loss: 2.156806468963623
Validation loss: 2.2387113007166053

Epoch: 6| Step: 11
Training loss: 2.896127223968506
Validation loss: 2.2342282713100476

Epoch: 6| Step: 12
Training loss: 3.251171112060547
Validation loss: 2.235957122618152

Epoch: 6| Step: 13
Training loss: 1.8430393934249878
Validation loss: 2.2322036117635746

Epoch: 136| Step: 0
Training loss: 3.0754356384277344
Validation loss: 2.247837774215206

Epoch: 6| Step: 1
Training loss: 1.5595673322677612
Validation loss: 2.2479903364694245

Epoch: 6| Step: 2
Training loss: 2.439283847808838
Validation loss: 2.239735964805849

Epoch: 6| Step: 3
Training loss: 1.9506607055664062
Validation loss: 2.2405489772878666

Epoch: 6| Step: 4
Training loss: 2.1822080612182617
Validation loss: 2.22924203770135

Epoch: 6| Step: 5
Training loss: 2.1396100521087646
Validation loss: 2.226263505156322

Epoch: 6| Step: 6
Training loss: 2.6835713386535645
Validation loss: 2.232972057916785

Epoch: 6| Step: 7
Training loss: 2.6937804222106934
Validation loss: 2.248393384359216

Epoch: 6| Step: 8
Training loss: 3.039487600326538
Validation loss: 2.24402831831286

Epoch: 6| Step: 9
Training loss: 2.818814516067505
Validation loss: 2.2609838567754275

Epoch: 6| Step: 10
Training loss: 2.416545867919922
Validation loss: 2.271321186455347

Epoch: 6| Step: 11
Training loss: 2.2346861362457275
Validation loss: 2.2695288478687243

Epoch: 6| Step: 12
Training loss: 2.608139991760254
Validation loss: 2.281252989204981

Epoch: 6| Step: 13
Training loss: 2.164750099182129
Validation loss: 2.2737336210025254

Epoch: 137| Step: 0
Training loss: 2.269270420074463
Validation loss: 2.2592465749350925

Epoch: 6| Step: 1
Training loss: 2.209911823272705
Validation loss: 2.2337927485025055

Epoch: 6| Step: 2
Training loss: 2.369055986404419
Validation loss: 2.215067045662993

Epoch: 6| Step: 3
Training loss: 2.907925605773926
Validation loss: 2.2173156917736097

Epoch: 6| Step: 4
Training loss: 2.6178510189056396
Validation loss: 2.203066449011526

Epoch: 6| Step: 5
Training loss: 1.7616028785705566
Validation loss: 2.1936059485199633

Epoch: 6| Step: 6
Training loss: 2.784477949142456
Validation loss: 2.1968253991937123

Epoch: 6| Step: 7
Training loss: 2.832420825958252
Validation loss: 2.1932849140577417

Epoch: 6| Step: 8
Training loss: 2.539628505706787
Validation loss: 2.1885535588828464

Epoch: 6| Step: 9
Training loss: 1.6191191673278809
Validation loss: 2.1949251364636164

Epoch: 6| Step: 10
Training loss: 2.789158821105957
Validation loss: 2.196066565411065

Epoch: 6| Step: 11
Training loss: 3.2787351608276367
Validation loss: 2.203419844309489

Epoch: 6| Step: 12
Training loss: 2.4803647994995117
Validation loss: 2.2158382861844954

Epoch: 6| Step: 13
Training loss: 1.1258769035339355
Validation loss: 2.234960953394572

Epoch: 138| Step: 0
Training loss: 1.94301176071167
Validation loss: 2.2898166282202608

Epoch: 6| Step: 1
Training loss: 2.123530864715576
Validation loss: 2.3284469676274124

Epoch: 6| Step: 2
Training loss: 2.954251766204834
Validation loss: 2.3263989648511334

Epoch: 6| Step: 3
Training loss: 2.7200374603271484
Validation loss: 2.313407510839483

Epoch: 6| Step: 4
Training loss: 2.2735626697540283
Validation loss: 2.313305729178972

Epoch: 6| Step: 5
Training loss: 1.9666011333465576
Validation loss: 2.302671827295775

Epoch: 6| Step: 6
Training loss: 1.5264230966567993
Validation loss: 2.3330632730196883

Epoch: 6| Step: 7
Training loss: 2.980226516723633
Validation loss: 2.323921218995125

Epoch: 6| Step: 8
Training loss: 2.8796370029449463
Validation loss: 2.2997044312056674

Epoch: 6| Step: 9
Training loss: 2.8960156440734863
Validation loss: 2.2781901949195453

Epoch: 6| Step: 10
Training loss: 3.079035758972168
Validation loss: 2.2580284841599

Epoch: 6| Step: 11
Training loss: 2.5250847339630127
Validation loss: 2.2461413824430077

Epoch: 6| Step: 12
Training loss: 2.1047580242156982
Validation loss: 2.235757718804062

Epoch: 6| Step: 13
Training loss: 2.071697950363159
Validation loss: 2.230259500524049

Epoch: 139| Step: 0
Training loss: 2.7751197814941406
Validation loss: 2.22210128589343

Epoch: 6| Step: 1
Training loss: 2.188044548034668
Validation loss: 2.217776749723701

Epoch: 6| Step: 2
Training loss: 2.2890896797180176
Validation loss: 2.2141875502883748

Epoch: 6| Step: 3
Training loss: 2.223442792892456
Validation loss: 2.216673363921463

Epoch: 6| Step: 4
Training loss: 1.6194618940353394
Validation loss: 2.2163372116704143

Epoch: 6| Step: 5
Training loss: 3.012997627258301
Validation loss: 2.2167305484894784

Epoch: 6| Step: 6
Training loss: 2.4489715099334717
Validation loss: 2.235878481659838

Epoch: 6| Step: 7
Training loss: 2.017263889312744
Validation loss: 2.2322282175863943

Epoch: 6| Step: 8
Training loss: 2.238003969192505
Validation loss: 2.2698869051471835

Epoch: 6| Step: 9
Training loss: 1.9055776596069336
Validation loss: 2.255934307652135

Epoch: 6| Step: 10
Training loss: 2.679490089416504
Validation loss: 2.2783794210803126

Epoch: 6| Step: 11
Training loss: 2.8057541847229004
Validation loss: 2.2672211611142723

Epoch: 6| Step: 12
Training loss: 2.820883274078369
Validation loss: 2.254961913631808

Epoch: 6| Step: 13
Training loss: 3.3340067863464355
Validation loss: 2.2453786596175163

Epoch: 140| Step: 0
Training loss: 2.378894329071045
Validation loss: 2.2371253172556558

Epoch: 6| Step: 1
Training loss: 2.461336135864258
Validation loss: 2.236617319045528

Epoch: 6| Step: 2
Training loss: 2.660398244857788
Validation loss: 2.227550450191703

Epoch: 6| Step: 3
Training loss: 2.614528179168701
Validation loss: 2.220348301754203

Epoch: 6| Step: 4
Training loss: 2.962766647338867
Validation loss: 2.2113125503704114

Epoch: 6| Step: 5
Training loss: 2.2565035820007324
Validation loss: 2.2218947641311155

Epoch: 6| Step: 6
Training loss: 2.454761266708374
Validation loss: 2.2078493641268824

Epoch: 6| Step: 7
Training loss: 2.0763776302337646
Validation loss: 2.202625702786189

Epoch: 6| Step: 8
Training loss: 2.3211069107055664
Validation loss: 2.1991328539386874

Epoch: 6| Step: 9
Training loss: 2.9102940559387207
Validation loss: 2.1999816561257965

Epoch: 6| Step: 10
Training loss: 2.7033660411834717
Validation loss: 2.208417530982725

Epoch: 6| Step: 11
Training loss: 2.719363212585449
Validation loss: 2.2119607669050976

Epoch: 6| Step: 12
Training loss: 1.3694138526916504
Validation loss: 2.225458114377914

Epoch: 6| Step: 13
Training loss: 1.4617434740066528
Validation loss: 2.2463740712852887

Epoch: 141| Step: 0
Training loss: 1.9160434007644653
Validation loss: 2.247660562556277

Epoch: 6| Step: 1
Training loss: 2.627729892730713
Validation loss: 2.279946570755333

Epoch: 6| Step: 2
Training loss: 1.9714980125427246
Validation loss: 2.286797128697877

Epoch: 6| Step: 3
Training loss: 2.0548675060272217
Validation loss: 2.3041348636791272

Epoch: 6| Step: 4
Training loss: 3.17330002784729
Validation loss: 2.3129116335222797

Epoch: 6| Step: 5
Training loss: 2.5343234539031982
Validation loss: 2.296042756367755

Epoch: 6| Step: 6
Training loss: 1.8022489547729492
Validation loss: 2.2798635318715084

Epoch: 6| Step: 7
Training loss: 2.290276527404785
Validation loss: 2.282800748784055

Epoch: 6| Step: 8
Training loss: 2.188750982284546
Validation loss: 2.280531347438853

Epoch: 6| Step: 9
Training loss: 2.4208037853240967
Validation loss: 2.275060743413946

Epoch: 6| Step: 10
Training loss: 2.6717257499694824
Validation loss: 2.2654187448563112

Epoch: 6| Step: 11
Training loss: 2.033254623413086
Validation loss: 2.2577682874536

Epoch: 6| Step: 12
Training loss: 3.3808584213256836
Validation loss: 2.24644822202703

Epoch: 6| Step: 13
Training loss: 3.0086681842803955
Validation loss: 2.234610131991807

Epoch: 142| Step: 0
Training loss: 3.184950828552246
Validation loss: 2.2315015741573867

Epoch: 6| Step: 1
Training loss: 2.805574655532837
Validation loss: 2.207404746804186

Epoch: 6| Step: 2
Training loss: 2.2176713943481445
Validation loss: 2.2034345416612524

Epoch: 6| Step: 3
Training loss: 2.7318127155303955
Validation loss: 2.20003140869961

Epoch: 6| Step: 4
Training loss: 2.244889259338379
Validation loss: 2.192630639640234

Epoch: 6| Step: 5
Training loss: 2.5224523544311523
Validation loss: 2.188275429510301

Epoch: 6| Step: 6
Training loss: 2.429612159729004
Validation loss: 2.1948231394572923

Epoch: 6| Step: 7
Training loss: 1.8372867107391357
Validation loss: 2.191966769515827

Epoch: 6| Step: 8
Training loss: 2.469470500946045
Validation loss: 2.195440697413619

Epoch: 6| Step: 9
Training loss: 2.145663261413574
Validation loss: 2.200473129108388

Epoch: 6| Step: 10
Training loss: 2.0451009273529053
Validation loss: 2.2073833198957544

Epoch: 6| Step: 11
Training loss: 2.3332676887512207
Validation loss: 2.2065983946605394

Epoch: 6| Step: 12
Training loss: 2.3634493350982666
Validation loss: 2.2155591467375397

Epoch: 6| Step: 13
Training loss: 2.3460049629211426
Validation loss: 2.2222194658812655

Epoch: 143| Step: 0
Training loss: 2.1280062198638916
Validation loss: 2.251748995114398

Epoch: 6| Step: 1
Training loss: 2.3101022243499756
Validation loss: 2.2611969030031593

Epoch: 6| Step: 2
Training loss: 2.588408946990967
Validation loss: 2.2791457176208496

Epoch: 6| Step: 3
Training loss: 2.036972761154175
Validation loss: 2.2844400995521137

Epoch: 6| Step: 4
Training loss: 2.5533382892608643
Validation loss: 2.2921115941898798

Epoch: 6| Step: 5
Training loss: 2.3672683238983154
Validation loss: 2.282814794971097

Epoch: 6| Step: 6
Training loss: 2.540292263031006
Validation loss: 2.27265336180246

Epoch: 6| Step: 7
Training loss: 2.3494062423706055
Validation loss: 2.253138134556432

Epoch: 6| Step: 8
Training loss: 2.4425911903381348
Validation loss: 2.241252637678577

Epoch: 6| Step: 9
Training loss: 2.0251176357269287
Validation loss: 2.238835209159441

Epoch: 6| Step: 10
Training loss: 3.1153793334960938
Validation loss: 2.2233590490074566

Epoch: 6| Step: 11
Training loss: 2.9048657417297363
Validation loss: 2.227003470543892

Epoch: 6| Step: 12
Training loss: 2.038339138031006
Validation loss: 2.211191438859509

Epoch: 6| Step: 13
Training loss: 2.057131767272949
Validation loss: 2.220221402824566

Epoch: 144| Step: 0
Training loss: 2.33864688873291
Validation loss: 2.2228109503305085

Epoch: 6| Step: 1
Training loss: 2.147739887237549
Validation loss: 2.2182156116731706

Epoch: 6| Step: 2
Training loss: 2.1464779376983643
Validation loss: 2.2458275774473786

Epoch: 6| Step: 3
Training loss: 2.681931972503662
Validation loss: 2.251339271504392

Epoch: 6| Step: 4
Training loss: 2.4926576614379883
Validation loss: 2.2584158682054087

Epoch: 6| Step: 5
Training loss: 3.0011074542999268
Validation loss: 2.2673355353775846

Epoch: 6| Step: 6
Training loss: 2.9821290969848633
Validation loss: 2.265168087456816

Epoch: 6| Step: 7
Training loss: 1.8215947151184082
Validation loss: 2.2431837474146197

Epoch: 6| Step: 8
Training loss: 2.233630895614624
Validation loss: 2.2236857093790525

Epoch: 6| Step: 9
Training loss: 2.3696229457855225
Validation loss: 2.216052727032733

Epoch: 6| Step: 10
Training loss: 2.280916690826416
Validation loss: 2.209233319887551

Epoch: 6| Step: 11
Training loss: 1.9512689113616943
Validation loss: 2.2108874628620763

Epoch: 6| Step: 12
Training loss: 2.7286500930786133
Validation loss: 2.21276629483828

Epoch: 6| Step: 13
Training loss: 2.550659656524658
Validation loss: 2.230804638196063

Epoch: 145| Step: 0
Training loss: 2.772204875946045
Validation loss: 2.244390146706694

Epoch: 6| Step: 1
Training loss: 1.9971810579299927
Validation loss: 2.2521832296925206

Epoch: 6| Step: 2
Training loss: 2.852717876434326
Validation loss: 2.2585483853534987

Epoch: 6| Step: 3
Training loss: 2.030874729156494
Validation loss: 2.2451313054689797

Epoch: 6| Step: 4
Training loss: 2.730475425720215
Validation loss: 2.2497044301802114

Epoch: 6| Step: 5
Training loss: 1.8011772632598877
Validation loss: 2.2522158725287325

Epoch: 6| Step: 6
Training loss: 2.681637763977051
Validation loss: 2.2576025685956402

Epoch: 6| Step: 7
Training loss: 2.699317693710327
Validation loss: 2.2450545885229625

Epoch: 6| Step: 8
Training loss: 2.357884407043457
Validation loss: 2.242620437375961

Epoch: 6| Step: 9
Training loss: 2.5663702487945557
Validation loss: 2.2342782815297446

Epoch: 6| Step: 10
Training loss: 1.549863576889038
Validation loss: 2.2227989781287407

Epoch: 6| Step: 11
Training loss: 2.337782859802246
Validation loss: 2.228533337193151

Epoch: 6| Step: 12
Training loss: 2.353806972503662
Validation loss: 2.224558650806386

Epoch: 6| Step: 13
Training loss: 2.871666669845581
Validation loss: 2.23635075681953

Epoch: 146| Step: 0
Training loss: 2.5093071460723877
Validation loss: 2.2442542327347623

Epoch: 6| Step: 1
Training loss: 2.2525014877319336
Validation loss: 2.241047061899657

Epoch: 6| Step: 2
Training loss: 3.110987424850464
Validation loss: 2.245045392744003

Epoch: 6| Step: 3
Training loss: 1.7327682971954346
Validation loss: 2.2379546883285686

Epoch: 6| Step: 4
Training loss: 2.276723623275757
Validation loss: 2.2326380334874636

Epoch: 6| Step: 5
Training loss: 2.4072892665863037
Validation loss: 2.242972994363436

Epoch: 6| Step: 6
Training loss: 2.1867995262145996
Validation loss: 2.2434603091209167

Epoch: 6| Step: 7
Training loss: 2.1065807342529297
Validation loss: 2.2498681327348113

Epoch: 6| Step: 8
Training loss: 2.6014792919158936
Validation loss: 2.2420551341067076

Epoch: 6| Step: 9
Training loss: 2.0428695678710938
Validation loss: 2.2523056332783034

Epoch: 6| Step: 10
Training loss: 3.0137274265289307
Validation loss: 2.238651511489704

Epoch: 6| Step: 11
Training loss: 2.212594985961914
Validation loss: 2.2479406813139557

Epoch: 6| Step: 12
Training loss: 1.8281782865524292
Validation loss: 2.2395226455503896

Epoch: 6| Step: 13
Training loss: 3.4765894412994385
Validation loss: 2.229902313601586

Epoch: 147| Step: 0
Training loss: 2.9485108852386475
Validation loss: 2.231011270194925

Epoch: 6| Step: 1
Training loss: 1.4126343727111816
Validation loss: 2.2305604257891254

Epoch: 6| Step: 2
Training loss: 3.1846091747283936
Validation loss: 2.246014110503658

Epoch: 6| Step: 3
Training loss: 2.106416702270508
Validation loss: 2.2695711530664915

Epoch: 6| Step: 4
Training loss: 1.6341662406921387
Validation loss: 2.2809566938748924

Epoch: 6| Step: 5
Training loss: 2.787222385406494
Validation loss: 2.2794849244497155

Epoch: 6| Step: 6
Training loss: 2.422637462615967
Validation loss: 2.2670766179279616

Epoch: 6| Step: 7
Training loss: 2.8640384674072266
Validation loss: 2.262601743462265

Epoch: 6| Step: 8
Training loss: 2.2091212272644043
Validation loss: 2.2250356879285587

Epoch: 6| Step: 9
Training loss: 2.401520013809204
Validation loss: 2.215477002564297

Epoch: 6| Step: 10
Training loss: 2.024643659591675
Validation loss: 2.2049302183171755

Epoch: 6| Step: 11
Training loss: 2.0664219856262207
Validation loss: 2.2318804494796263

Epoch: 6| Step: 12
Training loss: 2.523958921432495
Validation loss: 2.241577661165627

Epoch: 6| Step: 13
Training loss: 2.95538067817688
Validation loss: 2.256971425907586

Epoch: 148| Step: 0
Training loss: 2.2473723888397217
Validation loss: 2.257916706864552

Epoch: 6| Step: 1
Training loss: 1.910636067390442
Validation loss: 2.2490473203761603

Epoch: 6| Step: 2
Training loss: 2.2284295558929443
Validation loss: 2.2591929012729275

Epoch: 6| Step: 3
Training loss: 2.8482813835144043
Validation loss: 2.244212929920484

Epoch: 6| Step: 4
Training loss: 2.8894503116607666
Validation loss: 2.2140097477102794

Epoch: 6| Step: 5
Training loss: 2.560450315475464
Validation loss: 2.2297083793147916

Epoch: 6| Step: 6
Training loss: 2.176215887069702
Validation loss: 2.227491887666846

Epoch: 6| Step: 7
Training loss: 1.8478268384933472
Validation loss: 2.2436322601892615

Epoch: 6| Step: 8
Training loss: 3.373117685317993
Validation loss: 2.2584549175795687

Epoch: 6| Step: 9
Training loss: 1.9736753702163696
Validation loss: 2.2654163478523173

Epoch: 6| Step: 10
Training loss: 2.770188808441162
Validation loss: 2.239905516306559

Epoch: 6| Step: 11
Training loss: 2.1551759243011475
Validation loss: 2.232626950868996

Epoch: 6| Step: 12
Training loss: 2.184269428253174
Validation loss: 2.223446494789534

Epoch: 6| Step: 13
Training loss: 2.0132057666778564
Validation loss: 2.21263716554129

Epoch: 149| Step: 0
Training loss: 2.4100162982940674
Validation loss: 2.2246041169730564

Epoch: 6| Step: 1
Training loss: 2.5059967041015625
Validation loss: 2.211214937189574

Epoch: 6| Step: 2
Training loss: 2.1095223426818848
Validation loss: 2.2020978286702144

Epoch: 6| Step: 3
Training loss: 2.687974214553833
Validation loss: 2.195818962589387

Epoch: 6| Step: 4
Training loss: 2.346278667449951
Validation loss: 2.201137532470047

Epoch: 6| Step: 5
Training loss: 2.472423553466797
Validation loss: 2.2008859713872275

Epoch: 6| Step: 6
Training loss: 2.8200531005859375
Validation loss: 2.1995022604542394

Epoch: 6| Step: 7
Training loss: 1.239504098892212
Validation loss: 2.202884251071561

Epoch: 6| Step: 8
Training loss: 1.9208357334136963
Validation loss: 2.215815929956334

Epoch: 6| Step: 9
Training loss: 2.644822359085083
Validation loss: 2.2367226410937566

Epoch: 6| Step: 10
Training loss: 3.3425989151000977
Validation loss: 2.2433904986227713

Epoch: 6| Step: 11
Training loss: 2.3307461738586426
Validation loss: 2.2629405529268327

Epoch: 6| Step: 12
Training loss: 2.174699306488037
Validation loss: 2.2791679892488705

Epoch: 6| Step: 13
Training loss: 1.6518607139587402
Validation loss: 2.2919423810897337

Epoch: 150| Step: 0
Training loss: 1.5701119899749756
Validation loss: 2.3012846721115934

Epoch: 6| Step: 1
Training loss: 2.750497341156006
Validation loss: 2.320062034873552

Epoch: 6| Step: 2
Training loss: 1.9821820259094238
Validation loss: 2.3134448682108233

Epoch: 6| Step: 3
Training loss: 1.9646438360214233
Validation loss: 2.288820876870104

Epoch: 6| Step: 4
Training loss: 2.2153947353363037
Validation loss: 2.2785245680039927

Epoch: 6| Step: 5
Training loss: 2.520397186279297
Validation loss: 2.2618631829497633

Epoch: 6| Step: 6
Training loss: 2.3126351833343506
Validation loss: 2.2455785248869207

Epoch: 6| Step: 7
Training loss: 2.8292908668518066
Validation loss: 2.224451216318274

Epoch: 6| Step: 8
Training loss: 1.9648144245147705
Validation loss: 2.212392830079602

Epoch: 6| Step: 9
Training loss: 1.9956164360046387
Validation loss: 2.1999782387928297

Epoch: 6| Step: 10
Training loss: 2.86625337600708
Validation loss: 2.1995759497406664

Epoch: 6| Step: 11
Training loss: 2.827927589416504
Validation loss: 2.194936775392102

Epoch: 6| Step: 12
Training loss: 2.7351198196411133
Validation loss: 2.193981132199687

Epoch: 6| Step: 13
Training loss: 2.4262421131134033
Validation loss: 2.1947206938138573

Epoch: 151| Step: 0
Training loss: 2.684572219848633
Validation loss: 2.209223234525291

Epoch: 6| Step: 1
Training loss: 2.461320400238037
Validation loss: 2.2075371332066034

Epoch: 6| Step: 2
Training loss: 2.473304271697998
Validation loss: 2.2133799368335354

Epoch: 6| Step: 3
Training loss: 2.607959032058716
Validation loss: 2.2085520259795652

Epoch: 6| Step: 4
Training loss: 2.0766048431396484
Validation loss: 2.2163741486046904

Epoch: 6| Step: 5
Training loss: 2.4360954761505127
Validation loss: 2.208846015314902

Epoch: 6| Step: 6
Training loss: 2.7572855949401855
Validation loss: 2.2136976641993367

Epoch: 6| Step: 7
Training loss: 2.6208975315093994
Validation loss: 2.210363139388382

Epoch: 6| Step: 8
Training loss: 2.0555028915405273
Validation loss: 2.230125718219306

Epoch: 6| Step: 9
Training loss: 2.02301025390625
Validation loss: 2.239309718531947

Epoch: 6| Step: 10
Training loss: 2.374185562133789
Validation loss: 2.2510709044753865

Epoch: 6| Step: 11
Training loss: 1.848480224609375
Validation loss: 2.222018490555466

Epoch: 6| Step: 12
Training loss: 2.202448844909668
Validation loss: 2.2380613562881306

Epoch: 6| Step: 13
Training loss: 2.204188585281372
Validation loss: 2.238179411939395

Epoch: 152| Step: 0
Training loss: 2.868281364440918
Validation loss: 2.223688288401532

Epoch: 6| Step: 1
Training loss: 2.72428560256958
Validation loss: 2.224504474670656

Epoch: 6| Step: 2
Training loss: 2.0417206287384033
Validation loss: 2.231804560589534

Epoch: 6| Step: 3
Training loss: 2.0446081161499023
Validation loss: 2.2295957919090026

Epoch: 6| Step: 4
Training loss: 2.1426639556884766
Validation loss: 2.215902800201088

Epoch: 6| Step: 5
Training loss: 2.7688229084014893
Validation loss: 2.206584543310186

Epoch: 6| Step: 6
Training loss: 2.3309710025787354
Validation loss: 2.2014471292495728

Epoch: 6| Step: 7
Training loss: 2.2090702056884766
Validation loss: 2.191837783782713

Epoch: 6| Step: 8
Training loss: 2.7492737770080566
Validation loss: 2.189218818500478

Epoch: 6| Step: 9
Training loss: 1.9302297830581665
Validation loss: 2.2044526479577504

Epoch: 6| Step: 10
Training loss: 2.4734182357788086
Validation loss: 2.233101988351473

Epoch: 6| Step: 11
Training loss: 2.1247057914733887
Validation loss: 2.2827810113148024

Epoch: 6| Step: 12
Training loss: 2.479466438293457
Validation loss: 2.3001918305632887

Epoch: 6| Step: 13
Training loss: 1.881960153579712
Validation loss: 2.2782887387019333

Epoch: 153| Step: 0
Training loss: 1.9652764797210693
Validation loss: 2.2682523009597615

Epoch: 6| Step: 1
Training loss: 2.568828821182251
Validation loss: 2.2474896420714674

Epoch: 6| Step: 2
Training loss: 2.721731185913086
Validation loss: 2.2314092613035634

Epoch: 6| Step: 3
Training loss: 2.8145911693573
Validation loss: 2.2278273900349936

Epoch: 6| Step: 4
Training loss: 2.6326818466186523
Validation loss: 2.2151617388571463

Epoch: 6| Step: 5
Training loss: 2.480591297149658
Validation loss: 2.2144899214467695

Epoch: 6| Step: 6
Training loss: 2.3030805587768555
Validation loss: 2.2169524982411373

Epoch: 6| Step: 7
Training loss: 2.080827236175537
Validation loss: 2.2117014931094263

Epoch: 6| Step: 8
Training loss: 1.9097130298614502
Validation loss: 2.2072600318539526

Epoch: 6| Step: 9
Training loss: 3.000117778778076
Validation loss: 2.210615082453656

Epoch: 6| Step: 10
Training loss: 1.5328603982925415
Validation loss: 2.2262722484527098

Epoch: 6| Step: 11
Training loss: 2.4502360820770264
Validation loss: 2.220815089441115

Epoch: 6| Step: 12
Training loss: 2.142076253890991
Validation loss: 2.2394679848865797

Epoch: 6| Step: 13
Training loss: 1.7609442472457886
Validation loss: 2.2400688714878534

Epoch: 154| Step: 0
Training loss: 2.1931889057159424
Validation loss: 2.2536832773557274

Epoch: 6| Step: 1
Training loss: 2.0913643836975098
Validation loss: 2.2447080766001055

Epoch: 6| Step: 2
Training loss: 2.8439157009124756
Validation loss: 2.2330939526199014

Epoch: 6| Step: 3
Training loss: 2.930178165435791
Validation loss: 2.2438345468172463

Epoch: 6| Step: 4
Training loss: 2.3304429054260254
Validation loss: 2.2352956123249506

Epoch: 6| Step: 5
Training loss: 1.4939227104187012
Validation loss: 2.2176002533205095

Epoch: 6| Step: 6
Training loss: 2.2665929794311523
Validation loss: 2.2207837232979397

Epoch: 6| Step: 7
Training loss: 2.875835418701172
Validation loss: 2.2282577791521625

Epoch: 6| Step: 8
Training loss: 2.18179988861084
Validation loss: 2.2226844064651

Epoch: 6| Step: 9
Training loss: 2.011073589324951
Validation loss: 2.232340192282072

Epoch: 6| Step: 10
Training loss: 2.0680909156799316
Validation loss: 2.2474532588835685

Epoch: 6| Step: 11
Training loss: 1.9195507764816284
Validation loss: 2.2490180102727746

Epoch: 6| Step: 12
Training loss: 2.277902603149414
Validation loss: 2.256498590592415

Epoch: 6| Step: 13
Training loss: 3.5101356506347656
Validation loss: 2.2772154013315835

Epoch: 155| Step: 0
Training loss: 1.9093968868255615
Validation loss: 2.2476111099284184

Epoch: 6| Step: 1
Training loss: 2.497797966003418
Validation loss: 2.233100277121349

Epoch: 6| Step: 2
Training loss: 2.174379587173462
Validation loss: 2.2070378911110664

Epoch: 6| Step: 3
Training loss: 2.6425914764404297
Validation loss: 2.1962283939443608

Epoch: 6| Step: 4
Training loss: 2.1968421936035156
Validation loss: 2.179771884795158

Epoch: 6| Step: 5
Training loss: 2.266630172729492
Validation loss: 2.1819170444242415

Epoch: 6| Step: 6
Training loss: 2.214869976043701
Validation loss: 2.183029810587565

Epoch: 6| Step: 7
Training loss: 2.5881292819976807
Validation loss: 2.1927815816735707

Epoch: 6| Step: 8
Training loss: 2.185272693634033
Validation loss: 2.2036643822987876

Epoch: 6| Step: 9
Training loss: 2.928187370300293
Validation loss: 2.193400772668982

Epoch: 6| Step: 10
Training loss: 2.1116132736206055
Validation loss: 2.216531809940133

Epoch: 6| Step: 11
Training loss: 1.8158690929412842
Validation loss: 2.2102013249551096

Epoch: 6| Step: 12
Training loss: 1.96320641040802
Validation loss: 2.2132031763753583

Epoch: 6| Step: 13
Training loss: 3.263517379760742
Validation loss: 2.221269025597521

Epoch: 156| Step: 0
Training loss: 2.0809667110443115
Validation loss: 2.2339962041506203

Epoch: 6| Step: 1
Training loss: 2.3034355640411377
Validation loss: 2.2580969141375635

Epoch: 6| Step: 2
Training loss: 2.881094455718994
Validation loss: 2.2764321527173443

Epoch: 6| Step: 3
Training loss: 2.232598066329956
Validation loss: 2.2977776963223695

Epoch: 6| Step: 4
Training loss: 1.9079225063323975
Validation loss: 2.2674251679451234

Epoch: 6| Step: 5
Training loss: 2.733708381652832
Validation loss: 2.2293547225254837

Epoch: 6| Step: 6
Training loss: 1.7222520112991333
Validation loss: 2.1969505561295377

Epoch: 6| Step: 7
Training loss: 2.709155559539795
Validation loss: 2.203527932525963

Epoch: 6| Step: 8
Training loss: 2.5219764709472656
Validation loss: 2.1991708599111086

Epoch: 6| Step: 9
Training loss: 2.3297150135040283
Validation loss: 2.195377101180374

Epoch: 6| Step: 10
Training loss: 2.880603790283203
Validation loss: 2.1965368396492413

Epoch: 6| Step: 11
Training loss: 1.9599486589431763
Validation loss: 2.203310328145181

Epoch: 6| Step: 12
Training loss: 2.132011651992798
Validation loss: 2.202169518316946

Epoch: 6| Step: 13
Training loss: 1.7935131788253784
Validation loss: 2.222034236436249

Epoch: 157| Step: 0
Training loss: 2.11122465133667
Validation loss: 2.226434674314273

Epoch: 6| Step: 1
Training loss: 2.784273147583008
Validation loss: 2.2542093876869447

Epoch: 6| Step: 2
Training loss: 2.5292556285858154
Validation loss: 2.2713844186516217

Epoch: 6| Step: 3
Training loss: 2.4547083377838135
Validation loss: 2.2738127580253025

Epoch: 6| Step: 4
Training loss: 1.9397646188735962
Validation loss: 2.2583227234501995

Epoch: 6| Step: 5
Training loss: 2.500532627105713
Validation loss: 2.225344124660697

Epoch: 6| Step: 6
Training loss: 2.582953453063965
Validation loss: 2.1858410194355953

Epoch: 6| Step: 7
Training loss: 2.1789066791534424
Validation loss: 2.1664438773226995

Epoch: 6| Step: 8
Training loss: 1.7840794324874878
Validation loss: 2.1720071659293225

Epoch: 6| Step: 9
Training loss: 3.280313014984131
Validation loss: 2.1649507630255913

Epoch: 6| Step: 10
Training loss: 1.5345475673675537
Validation loss: 2.1676510354524017

Epoch: 6| Step: 11
Training loss: 2.2979025840759277
Validation loss: 2.1840768373140724

Epoch: 6| Step: 12
Training loss: 1.776505947113037
Validation loss: 2.1840044631752917

Epoch: 6| Step: 13
Training loss: 2.8195948600769043
Validation loss: 2.203858742149927

Epoch: 158| Step: 0
Training loss: 3.54893159866333
Validation loss: 2.255329555080783

Epoch: 6| Step: 1
Training loss: 1.743741750717163
Validation loss: 2.2629104173311623

Epoch: 6| Step: 2
Training loss: 2.141890048980713
Validation loss: 2.294387512309577

Epoch: 6| Step: 3
Training loss: 1.8586270809173584
Validation loss: 2.3079734412572717

Epoch: 6| Step: 4
Training loss: 1.8031222820281982
Validation loss: 2.320178561313178

Epoch: 6| Step: 5
Training loss: 2.6923160552978516
Validation loss: 2.3015229368722565

Epoch: 6| Step: 6
Training loss: 2.3200807571411133
Validation loss: 2.298435116326937

Epoch: 6| Step: 7
Training loss: 2.434668779373169
Validation loss: 2.281214955032513

Epoch: 6| Step: 8
Training loss: 1.9278106689453125
Validation loss: 2.251896696705972

Epoch: 6| Step: 9
Training loss: 2.8148086071014404
Validation loss: 2.2420952063734814

Epoch: 6| Step: 10
Training loss: 1.8203160762786865
Validation loss: 2.2261380380199802

Epoch: 6| Step: 11
Training loss: 2.4779043197631836
Validation loss: 2.2293994913819017

Epoch: 6| Step: 12
Training loss: 2.237806797027588
Validation loss: 2.20964567635649

Epoch: 6| Step: 13
Training loss: 2.2412703037261963
Validation loss: 2.207041468671573

Epoch: 159| Step: 0
Training loss: 2.3590035438537598
Validation loss: 2.1865030924479165

Epoch: 6| Step: 1
Training loss: 2.1539671421051025
Validation loss: 2.1843351241080993

Epoch: 6| Step: 2
Training loss: 1.678916335105896
Validation loss: 2.183027148246765

Epoch: 6| Step: 3
Training loss: 2.1974849700927734
Validation loss: 2.151976716133856

Epoch: 6| Step: 4
Training loss: 2.281123638153076
Validation loss: 2.1710250967292377

Epoch: 6| Step: 5
Training loss: 2.440960168838501
Validation loss: 2.1771005712529665

Epoch: 6| Step: 6
Training loss: 2.3685922622680664
Validation loss: 2.197658047881178

Epoch: 6| Step: 7
Training loss: 1.8358384370803833
Validation loss: 2.261479107282495

Epoch: 6| Step: 8
Training loss: 2.162137508392334
Validation loss: 2.2453980753498692

Epoch: 6| Step: 9
Training loss: 1.8809717893600464
Validation loss: 2.2646542569642425

Epoch: 6| Step: 10
Training loss: 2.188102960586548
Validation loss: 2.2930295134103424

Epoch: 6| Step: 11
Training loss: 3.0315494537353516
Validation loss: 2.288746521037112

Epoch: 6| Step: 12
Training loss: 3.001910924911499
Validation loss: 2.2608722781622284

Epoch: 6| Step: 13
Training loss: 3.1988918781280518
Validation loss: 2.2440376691920783

Epoch: 160| Step: 0
Training loss: 1.876418113708496
Validation loss: 2.222670042386619

Epoch: 6| Step: 1
Training loss: 2.5585403442382812
Validation loss: 2.2243346065603276

Epoch: 6| Step: 2
Training loss: 2.7624552249908447
Validation loss: 2.2330534188978133

Epoch: 6| Step: 3
Training loss: 1.706686019897461
Validation loss: 2.2504634139358357

Epoch: 6| Step: 4
Training loss: 2.016935110092163
Validation loss: 2.24860099182334

Epoch: 6| Step: 5
Training loss: 2.832557201385498
Validation loss: 2.2606321432257213

Epoch: 6| Step: 6
Training loss: 2.3697144985198975
Validation loss: 2.2515719667557748

Epoch: 6| Step: 7
Training loss: 1.7669532299041748
Validation loss: 2.2440789502154113

Epoch: 6| Step: 8
Training loss: 2.115464687347412
Validation loss: 2.247566209044508

Epoch: 6| Step: 9
Training loss: 3.306096076965332
Validation loss: 2.2390638397585962

Epoch: 6| Step: 10
Training loss: 2.555243968963623
Validation loss: 2.2213541948667137

Epoch: 6| Step: 11
Training loss: 1.720493197441101
Validation loss: 2.196543783269903

Epoch: 6| Step: 12
Training loss: 2.082761287689209
Validation loss: 2.2026218637343375

Epoch: 6| Step: 13
Training loss: 2.185438394546509
Validation loss: 2.191824548987932

Epoch: 161| Step: 0
Training loss: 2.494157552719116
Validation loss: 2.1796663730375228

Epoch: 6| Step: 1
Training loss: 1.6959812641143799
Validation loss: 2.1907992132248415

Epoch: 6| Step: 2
Training loss: 2.6090645790100098
Validation loss: 2.2069327523631435

Epoch: 6| Step: 3
Training loss: 2.135681629180908
Validation loss: 2.2118367994985273

Epoch: 6| Step: 4
Training loss: 2.539663553237915
Validation loss: 2.2247449326258835

Epoch: 6| Step: 5
Training loss: 2.2488231658935547
Validation loss: 2.2221039674615346

Epoch: 6| Step: 6
Training loss: 2.525724411010742
Validation loss: 2.219399598336989

Epoch: 6| Step: 7
Training loss: 2.898204803466797
Validation loss: 2.2182999836501254

Epoch: 6| Step: 8
Training loss: 2.087675094604492
Validation loss: 2.2132527289852018

Epoch: 6| Step: 9
Training loss: 2.404092788696289
Validation loss: 2.2080508047534573

Epoch: 6| Step: 10
Training loss: 2.5166187286376953
Validation loss: 2.199786163145496

Epoch: 6| Step: 11
Training loss: 2.359717607498169
Validation loss: 2.1948845104504655

Epoch: 6| Step: 12
Training loss: 1.6399707794189453
Validation loss: 2.1883849059381792

Epoch: 6| Step: 13
Training loss: 1.0270777940750122
Validation loss: 2.1852718681417485

Epoch: 162| Step: 0
Training loss: 2.5768816471099854
Validation loss: 2.185094020699942

Epoch: 6| Step: 1
Training loss: 2.351872682571411
Validation loss: 2.185751192031368

Epoch: 6| Step: 2
Training loss: 1.718890905380249
Validation loss: 2.1894317980735534

Epoch: 6| Step: 3
Training loss: 2.8547651767730713
Validation loss: 2.185487836919805

Epoch: 6| Step: 4
Training loss: 2.8043136596679688
Validation loss: 2.20197097973157

Epoch: 6| Step: 5
Training loss: 2.7994179725646973
Validation loss: 2.1901304234740553

Epoch: 6| Step: 6
Training loss: 2.463977813720703
Validation loss: 2.2003344130772415

Epoch: 6| Step: 7
Training loss: 1.9810634851455688
Validation loss: 2.2062280972798667

Epoch: 6| Step: 8
Training loss: 1.8264230489730835
Validation loss: 2.2156990138433312

Epoch: 6| Step: 9
Training loss: 2.4855446815490723
Validation loss: 2.2014480021692093

Epoch: 6| Step: 10
Training loss: 1.881584644317627
Validation loss: 2.211619520700106

Epoch: 6| Step: 11
Training loss: 2.0026819705963135
Validation loss: 2.2263643459607194

Epoch: 6| Step: 12
Training loss: 1.5651531219482422
Validation loss: 2.2348378396803334

Epoch: 6| Step: 13
Training loss: 2.1866960525512695
Validation loss: 2.258255825247816

Epoch: 163| Step: 0
Training loss: 2.073375701904297
Validation loss: 2.246776479546742

Epoch: 6| Step: 1
Training loss: 2.6826114654541016
Validation loss: 2.2329568042550036

Epoch: 6| Step: 2
Training loss: 1.4498460292816162
Validation loss: 2.2252343162413566

Epoch: 6| Step: 3
Training loss: 3.1942265033721924
Validation loss: 2.232619049728558

Epoch: 6| Step: 4
Training loss: 2.106492519378662
Validation loss: 2.2162756432769117

Epoch: 6| Step: 5
Training loss: 1.6133911609649658
Validation loss: 2.2260933178727345

Epoch: 6| Step: 6
Training loss: 2.473658561706543
Validation loss: 2.233387798391363

Epoch: 6| Step: 7
Training loss: 2.848621368408203
Validation loss: 2.2250797338383173

Epoch: 6| Step: 8
Training loss: 2.6800103187561035
Validation loss: 2.218406322181866

Epoch: 6| Step: 9
Training loss: 2.250392436981201
Validation loss: 2.217100510033228

Epoch: 6| Step: 10
Training loss: 1.9687273502349854
Validation loss: 2.228780431132163

Epoch: 6| Step: 11
Training loss: 2.4972550868988037
Validation loss: 2.257169331273725

Epoch: 6| Step: 12
Training loss: 1.656768798828125
Validation loss: 2.2417512247639317

Epoch: 6| Step: 13
Training loss: 2.2275710105895996
Validation loss: 2.239109639198549

Epoch: 164| Step: 0
Training loss: 2.391618013381958
Validation loss: 2.201777437681793

Epoch: 6| Step: 1
Training loss: 1.9732983112335205
Validation loss: 2.191669912748439

Epoch: 6| Step: 2
Training loss: 1.3406206369400024
Validation loss: 2.1684428427809026

Epoch: 6| Step: 3
Training loss: 2.502847671508789
Validation loss: 2.154023080743769

Epoch: 6| Step: 4
Training loss: 2.977834701538086
Validation loss: 2.1375822085206226

Epoch: 6| Step: 5
Training loss: 2.3769848346710205
Validation loss: 2.1482161168129212

Epoch: 6| Step: 6
Training loss: 1.8281629085540771
Validation loss: 2.132939361756848

Epoch: 6| Step: 7
Training loss: 2.6639344692230225
Validation loss: 2.133396182008969

Epoch: 6| Step: 8
Training loss: 2.182706356048584
Validation loss: 2.1311919753269484

Epoch: 6| Step: 9
Training loss: 1.974958896636963
Validation loss: 2.141993958462951

Epoch: 6| Step: 10
Training loss: 1.9791868925094604
Validation loss: 2.1482559493792954

Epoch: 6| Step: 11
Training loss: 2.5683932304382324
Validation loss: 2.1506547889401837

Epoch: 6| Step: 12
Training loss: 2.478757619857788
Validation loss: 2.1763454662856234

Epoch: 6| Step: 13
Training loss: 2.6567442417144775
Validation loss: 2.1867886179236957

Epoch: 165| Step: 0
Training loss: 2.1865005493164062
Validation loss: 2.2163322228257374

Epoch: 6| Step: 1
Training loss: 2.3113231658935547
Validation loss: 2.237480245610719

Epoch: 6| Step: 2
Training loss: 3.448671817779541
Validation loss: 2.2661592960357666

Epoch: 6| Step: 3
Training loss: 2.545323133468628
Validation loss: 2.2792889392504128

Epoch: 6| Step: 4
Training loss: 2.1691102981567383
Validation loss: 2.2745796583032094

Epoch: 6| Step: 5
Training loss: 1.8382298946380615
Validation loss: 2.2673276701281146

Epoch: 6| Step: 6
Training loss: 1.5552681684494019
Validation loss: 2.257902743995831

Epoch: 6| Step: 7
Training loss: 2.359436511993408
Validation loss: 2.241545437484659

Epoch: 6| Step: 8
Training loss: 2.436541795730591
Validation loss: 2.20026292339448

Epoch: 6| Step: 9
Training loss: 2.370086669921875
Validation loss: 2.18667576389928

Epoch: 6| Step: 10
Training loss: 2.3207874298095703
Validation loss: 2.1790261640343616

Epoch: 6| Step: 11
Training loss: 2.3232474327087402
Validation loss: 2.153544907928795

Epoch: 6| Step: 12
Training loss: 1.8215006589889526
Validation loss: 2.1543959622742026

Epoch: 6| Step: 13
Training loss: 1.560958743095398
Validation loss: 2.144629773273263

Epoch: 166| Step: 0
Training loss: 2.0411365032196045
Validation loss: 2.163007467023788

Epoch: 6| Step: 1
Training loss: 1.428332805633545
Validation loss: 2.1833564363500124

Epoch: 6| Step: 2
Training loss: 1.7864880561828613
Validation loss: 2.174772634301134

Epoch: 6| Step: 3
Training loss: 2.745481491088867
Validation loss: 2.2062484038773404

Epoch: 6| Step: 4
Training loss: 2.842754364013672
Validation loss: 2.1992447837706535

Epoch: 6| Step: 5
Training loss: 3.0710365772247314
Validation loss: 2.2205082408843504

Epoch: 6| Step: 6
Training loss: 1.5250215530395508
Validation loss: 2.219072021463866

Epoch: 6| Step: 7
Training loss: 1.9497824907302856
Validation loss: 2.217334311495545

Epoch: 6| Step: 8
Training loss: 2.29948091506958
Validation loss: 2.207709943094561

Epoch: 6| Step: 9
Training loss: 2.8331780433654785
Validation loss: 2.2002713910994993

Epoch: 6| Step: 10
Training loss: 1.9109199047088623
Validation loss: 2.2033391460295646

Epoch: 6| Step: 11
Training loss: 2.061495780944824
Validation loss: 2.2029612705271733

Epoch: 6| Step: 12
Training loss: 2.601867198944092
Validation loss: 2.1891728498602427

Epoch: 6| Step: 13
Training loss: 1.9540445804595947
Validation loss: 2.1931512522441086

Epoch: 167| Step: 0
Training loss: 2.1189582347869873
Validation loss: 2.198555415676486

Epoch: 6| Step: 1
Training loss: 2.167867422103882
Validation loss: 2.2038111686706543

Epoch: 6| Step: 2
Training loss: 2.240764617919922
Validation loss: 2.2242682223678916

Epoch: 6| Step: 3
Training loss: 2.46500563621521
Validation loss: 2.2410739032171105

Epoch: 6| Step: 4
Training loss: 2.100407123565674
Validation loss: 2.264494865171371

Epoch: 6| Step: 5
Training loss: 2.4449243545532227
Validation loss: 2.249257610690209

Epoch: 6| Step: 6
Training loss: 2.6405744552612305
Validation loss: 2.243634089346855

Epoch: 6| Step: 7
Training loss: 1.570455551147461
Validation loss: 2.2348469175318235

Epoch: 6| Step: 8
Training loss: 2.2058324813842773
Validation loss: 2.2123680191655315

Epoch: 6| Step: 9
Training loss: 2.6381757259368896
Validation loss: 2.2056591228772233

Epoch: 6| Step: 10
Training loss: 1.4943478107452393
Validation loss: 2.1916819913412935

Epoch: 6| Step: 11
Training loss: 2.5719213485717773
Validation loss: 2.179318097329909

Epoch: 6| Step: 12
Training loss: 2.156883716583252
Validation loss: 2.17279411644064

Epoch: 6| Step: 13
Training loss: 2.4936413764953613
Validation loss: 2.1877339091352237

Epoch: 168| Step: 0
Training loss: 2.6188697814941406
Validation loss: 2.197943074728853

Epoch: 6| Step: 1
Training loss: 2.300668954849243
Validation loss: 2.177555722575034

Epoch: 6| Step: 2
Training loss: 2.472900152206421
Validation loss: 2.1787459158128306

Epoch: 6| Step: 3
Training loss: 2.310899257659912
Validation loss: 2.173890644504178

Epoch: 6| Step: 4
Training loss: 1.6988531351089478
Validation loss: 2.149536073848765

Epoch: 6| Step: 5
Training loss: 2.3772614002227783
Validation loss: 2.154825564353697

Epoch: 6| Step: 6
Training loss: 2.2387120723724365
Validation loss: 2.17210893477163

Epoch: 6| Step: 7
Training loss: 1.7273458242416382
Validation loss: 2.2027046218995125

Epoch: 6| Step: 8
Training loss: 1.6237170696258545
Validation loss: 2.261353192790862

Epoch: 6| Step: 9
Training loss: 2.07110595703125
Validation loss: 2.3111498817320792

Epoch: 6| Step: 10
Training loss: 2.444720983505249
Validation loss: 2.3475535326106574

Epoch: 6| Step: 11
Training loss: 2.687014579772949
Validation loss: 2.331181223674487

Epoch: 6| Step: 12
Training loss: 2.7747974395751953
Validation loss: 2.300476058836906

Epoch: 6| Step: 13
Training loss: 2.5398104190826416
Validation loss: 2.279474460950462

Epoch: 169| Step: 0
Training loss: 1.5110867023468018
Validation loss: 2.257085795043617

Epoch: 6| Step: 1
Training loss: 2.492870807647705
Validation loss: 2.24004021767647

Epoch: 6| Step: 2
Training loss: 1.5847573280334473
Validation loss: 2.2167658677665134

Epoch: 6| Step: 3
Training loss: 1.9636170864105225
Validation loss: 2.2016778146066973

Epoch: 6| Step: 4
Training loss: 2.8517940044403076
Validation loss: 2.2081534606154247

Epoch: 6| Step: 5
Training loss: 2.7747905254364014
Validation loss: 2.207411530197308

Epoch: 6| Step: 6
Training loss: 2.3816912174224854
Validation loss: 2.187429610119071

Epoch: 6| Step: 7
Training loss: 2.4937825202941895
Validation loss: 2.1996102768887758

Epoch: 6| Step: 8
Training loss: 2.2684545516967773
Validation loss: 2.1852341441697973

Epoch: 6| Step: 9
Training loss: 1.877516269683838
Validation loss: 2.1937586543380574

Epoch: 6| Step: 10
Training loss: 2.9557018280029297
Validation loss: 2.1680591926779798

Epoch: 6| Step: 11
Training loss: 1.9016942977905273
Validation loss: 2.1851983557465258

Epoch: 6| Step: 12
Training loss: 1.9064428806304932
Validation loss: 2.189115224346038

Epoch: 6| Step: 13
Training loss: 2.2504522800445557
Validation loss: 2.2001616518984557

Epoch: 170| Step: 0
Training loss: 2.1141109466552734
Validation loss: 2.19533448578209

Epoch: 6| Step: 1
Training loss: 2.35561466217041
Validation loss: 2.222192641227476

Epoch: 6| Step: 2
Training loss: 2.793605327606201
Validation loss: 2.2413250028446154

Epoch: 6| Step: 3
Training loss: 3.4768013954162598
Validation loss: 2.2310017231971986

Epoch: 6| Step: 4
Training loss: 2.1132235527038574
Validation loss: 2.229672916473881

Epoch: 6| Step: 5
Training loss: 1.9322483539581299
Validation loss: 2.230908768151396

Epoch: 6| Step: 6
Training loss: 1.5506811141967773
Validation loss: 2.2011633201311995

Epoch: 6| Step: 7
Training loss: 1.9529814720153809
Validation loss: 2.1983977825410905

Epoch: 6| Step: 8
Training loss: 2.5231382846832275
Validation loss: 2.1766989564382904

Epoch: 6| Step: 9
Training loss: 2.531355619430542
Validation loss: 2.156316331637803

Epoch: 6| Step: 10
Training loss: 1.9449207782745361
Validation loss: 2.145844328788019

Epoch: 6| Step: 11
Training loss: 1.7890836000442505
Validation loss: 2.1503896918348087

Epoch: 6| Step: 12
Training loss: 1.8600326776504517
Validation loss: 2.141974615794356

Epoch: 6| Step: 13
Training loss: 2.0322558879852295
Validation loss: 2.145400657448717

Epoch: 171| Step: 0
Training loss: 2.1861960887908936
Validation loss: 2.153196116929413

Epoch: 6| Step: 1
Training loss: 2.1078498363494873
Validation loss: 2.1533597259111303

Epoch: 6| Step: 2
Training loss: 1.7596466541290283
Validation loss: 2.159949024518331

Epoch: 6| Step: 3
Training loss: 1.770850419998169
Validation loss: 2.1768241133741153

Epoch: 6| Step: 4
Training loss: 1.961303949356079
Validation loss: 2.1797493888485815

Epoch: 6| Step: 5
Training loss: 2.5620813369750977
Validation loss: 2.1965782129636375

Epoch: 6| Step: 6
Training loss: 2.0006322860717773
Validation loss: 2.2015181382497153

Epoch: 6| Step: 7
Training loss: 2.5888118743896484
Validation loss: 2.1931817326494443

Epoch: 6| Step: 8
Training loss: 2.4175145626068115
Validation loss: 2.2030062162747948

Epoch: 6| Step: 9
Training loss: 2.5717406272888184
Validation loss: 2.205242254400766

Epoch: 6| Step: 10
Training loss: 1.926462173461914
Validation loss: 2.202631486359463

Epoch: 6| Step: 11
Training loss: 2.758678436279297
Validation loss: 2.1916107541771344

Epoch: 6| Step: 12
Training loss: 2.185856580734253
Validation loss: 2.179564227340042

Epoch: 6| Step: 13
Training loss: 2.1005661487579346
Validation loss: 2.1730001306021087

Epoch: 172| Step: 0
Training loss: 2.686790943145752
Validation loss: 2.1711641383427445

Epoch: 6| Step: 1
Training loss: 2.0329017639160156
Validation loss: 2.173618734523814

Epoch: 6| Step: 2
Training loss: 2.3611583709716797
Validation loss: 2.175949555571361

Epoch: 6| Step: 3
Training loss: 1.497369408607483
Validation loss: 2.166529995138927

Epoch: 6| Step: 4
Training loss: 3.105754852294922
Validation loss: 2.1845395590669368

Epoch: 6| Step: 5
Training loss: 1.5035583972930908
Validation loss: 2.1774957705569524

Epoch: 6| Step: 6
Training loss: 2.4746499061584473
Validation loss: 2.1764860858199415

Epoch: 6| Step: 7
Training loss: 2.0075008869171143
Validation loss: 2.182362287275253

Epoch: 6| Step: 8
Training loss: 1.3892005681991577
Validation loss: 2.1828817680317867

Epoch: 6| Step: 9
Training loss: 1.6960079669952393
Validation loss: 2.1995940400708105

Epoch: 6| Step: 10
Training loss: 3.6659960746765137
Validation loss: 2.1966671841118925

Epoch: 6| Step: 11
Training loss: 2.4444918632507324
Validation loss: 2.2040437447127474

Epoch: 6| Step: 12
Training loss: 1.9334075450897217
Validation loss: 2.1810162733959895

Epoch: 6| Step: 13
Training loss: 1.613370656967163
Validation loss: 2.1884878348278742

Epoch: 173| Step: 0
Training loss: 2.040140151977539
Validation loss: 2.1878302456230245

Epoch: 6| Step: 1
Training loss: 2.3555808067321777
Validation loss: 2.174877856367378

Epoch: 6| Step: 2
Training loss: 2.5470757484436035
Validation loss: 2.165648232224167

Epoch: 6| Step: 3
Training loss: 1.8185456991195679
Validation loss: 2.173705203558809

Epoch: 6| Step: 4
Training loss: 2.5102405548095703
Validation loss: 2.157389251134729

Epoch: 6| Step: 5
Training loss: 1.6065549850463867
Validation loss: 2.172730871426162

Epoch: 6| Step: 6
Training loss: 2.092745780944824
Validation loss: 2.170378295324182

Epoch: 6| Step: 7
Training loss: 1.6823346614837646
Validation loss: 2.18204750040526

Epoch: 6| Step: 8
Training loss: 2.3266754150390625
Validation loss: 2.1893546247995026

Epoch: 6| Step: 9
Training loss: 2.391083240509033
Validation loss: 2.191790957604685

Epoch: 6| Step: 10
Training loss: 2.0396270751953125
Validation loss: 2.1969855985333844

Epoch: 6| Step: 11
Training loss: 2.6326658725738525
Validation loss: 2.194719388920774

Epoch: 6| Step: 12
Training loss: 2.3001151084899902
Validation loss: 2.1746130886898247

Epoch: 6| Step: 13
Training loss: 2.347792863845825
Validation loss: 2.1599104494176884

Epoch: 174| Step: 0
Training loss: 2.5416173934936523
Validation loss: 2.1491816864218762

Epoch: 6| Step: 1
Training loss: 2.4494802951812744
Validation loss: 2.149847222912696

Epoch: 6| Step: 2
Training loss: 2.8259572982788086
Validation loss: 2.1437858381579

Epoch: 6| Step: 3
Training loss: 1.5856389999389648
Validation loss: 2.1387155350818428

Epoch: 6| Step: 4
Training loss: 1.5471978187561035
Validation loss: 2.127300453442399

Epoch: 6| Step: 5
Training loss: 1.7838099002838135
Validation loss: 2.136956899396835

Epoch: 6| Step: 6
Training loss: 2.2309718132019043
Validation loss: 2.129335081705483

Epoch: 6| Step: 7
Training loss: 2.0712528228759766
Validation loss: 2.1372312653449272

Epoch: 6| Step: 8
Training loss: 2.086452007293701
Validation loss: 2.14957231860007

Epoch: 6| Step: 9
Training loss: 2.7261202335357666
Validation loss: 2.1599305393875285

Epoch: 6| Step: 10
Training loss: 2.5615463256835938
Validation loss: 2.181480920442971

Epoch: 6| Step: 11
Training loss: 2.6280670166015625
Validation loss: 2.18811362020431

Epoch: 6| Step: 12
Training loss: 1.7182081937789917
Validation loss: 2.2197816141190065

Epoch: 6| Step: 13
Training loss: 1.495972752571106
Validation loss: 2.2560802223861858

Epoch: 175| Step: 0
Training loss: 2.85892915725708
Validation loss: 2.2845615135726107

Epoch: 6| Step: 1
Training loss: 1.9306795597076416
Validation loss: 2.2951112639519478

Epoch: 6| Step: 2
Training loss: 2.841486930847168
Validation loss: 2.3087251340189288

Epoch: 6| Step: 3
Training loss: 1.9245537519454956
Validation loss: 2.293512052105319

Epoch: 6| Step: 4
Training loss: 2.0722804069519043
Validation loss: 2.271369937927492

Epoch: 6| Step: 5
Training loss: 1.6075427532196045
Validation loss: 2.2355309429989068

Epoch: 6| Step: 6
Training loss: 2.2002623081207275
Validation loss: 2.201964339902324

Epoch: 6| Step: 7
Training loss: 2.153747081756592
Validation loss: 2.198263855390651

Epoch: 6| Step: 8
Training loss: 2.3785858154296875
Validation loss: 2.1980493401968353

Epoch: 6| Step: 9
Training loss: 2.102792501449585
Validation loss: 2.192972380627868

Epoch: 6| Step: 10
Training loss: 1.722057819366455
Validation loss: 2.1700799401088426

Epoch: 6| Step: 11
Training loss: 2.4700915813446045
Validation loss: 2.1732151431422078

Epoch: 6| Step: 12
Training loss: 2.051494598388672
Validation loss: 2.174094456498341

Epoch: 6| Step: 13
Training loss: 2.8669965267181396
Validation loss: 2.1584297905686083

Epoch: 176| Step: 0
Training loss: 1.9621896743774414
Validation loss: 2.147777788100704

Epoch: 6| Step: 1
Training loss: 1.92230224609375
Validation loss: 2.1707954022192184

Epoch: 6| Step: 2
Training loss: 1.872502088546753
Validation loss: 2.192766261357133

Epoch: 6| Step: 3
Training loss: 2.7447710037231445
Validation loss: 2.223433176676432

Epoch: 6| Step: 4
Training loss: 1.6948410272598267
Validation loss: 2.2379735503145444

Epoch: 6| Step: 5
Training loss: 2.0189781188964844
Validation loss: 2.2356587738119145

Epoch: 6| Step: 6
Training loss: 1.2079581022262573
Validation loss: 2.2269194382493214

Epoch: 6| Step: 7
Training loss: 2.1617448329925537
Validation loss: 2.1956599989245014

Epoch: 6| Step: 8
Training loss: 2.5831711292266846
Validation loss: 2.1798165562332317

Epoch: 6| Step: 9
Training loss: 2.2783913612365723
Validation loss: 2.164787656517439

Epoch: 6| Step: 10
Training loss: 2.530571937561035
Validation loss: 2.1464285491615214

Epoch: 6| Step: 11
Training loss: 2.6564762592315674
Validation loss: 2.156559175060641

Epoch: 6| Step: 12
Training loss: 2.4613375663757324
Validation loss: 2.1688309049093597

Epoch: 6| Step: 13
Training loss: 2.77590274810791
Validation loss: 2.18433883882338

Epoch: 177| Step: 0
Training loss: 1.9995877742767334
Validation loss: 2.1840034300281155

Epoch: 6| Step: 1
Training loss: 1.8066112995147705
Validation loss: 2.1970639536457677

Epoch: 6| Step: 2
Training loss: 1.4189893007278442
Validation loss: 2.1701854505846576

Epoch: 6| Step: 3
Training loss: 2.200700283050537
Validation loss: 2.170356096759919

Epoch: 6| Step: 4
Training loss: 2.539832353591919
Validation loss: 2.155168805071103

Epoch: 6| Step: 5
Training loss: 2.666555881500244
Validation loss: 2.164607899163359

Epoch: 6| Step: 6
Training loss: 2.5817928314208984
Validation loss: 2.1663829152302077

Epoch: 6| Step: 7
Training loss: 2.277564525604248
Validation loss: 2.1780244509379068

Epoch: 6| Step: 8
Training loss: 1.6699820756912231
Validation loss: 2.1977799477115756

Epoch: 6| Step: 9
Training loss: 1.9481701850891113
Validation loss: 2.2039408683776855

Epoch: 6| Step: 10
Training loss: 2.4632201194763184
Validation loss: 2.1951475015250583

Epoch: 6| Step: 11
Training loss: 2.021827220916748
Validation loss: 2.2206831747485745

Epoch: 6| Step: 12
Training loss: 2.5167016983032227
Validation loss: 2.216543714205424

Epoch: 6| Step: 13
Training loss: 2.879868507385254
Validation loss: 2.2044053974971978

Epoch: 178| Step: 0
Training loss: 1.6634705066680908
Validation loss: 2.212387587434502

Epoch: 6| Step: 1
Training loss: 2.2806363105773926
Validation loss: 2.2278521996672436

Epoch: 6| Step: 2
Training loss: 2.171872138977051
Validation loss: 2.237625934744394

Epoch: 6| Step: 3
Training loss: 1.9840620756149292
Validation loss: 2.239209839092788

Epoch: 6| Step: 4
Training loss: 1.8557467460632324
Validation loss: 2.2196142981129308

Epoch: 6| Step: 5
Training loss: 2.7280452251434326
Validation loss: 2.2052673614153298

Epoch: 6| Step: 6
Training loss: 2.039670705795288
Validation loss: 2.1949063039595083

Epoch: 6| Step: 7
Training loss: 2.293081283569336
Validation loss: 2.20081502391446

Epoch: 6| Step: 8
Training loss: 1.9469107389450073
Validation loss: 2.194138467952769

Epoch: 6| Step: 9
Training loss: 2.1943931579589844
Validation loss: 2.186141788318593

Epoch: 6| Step: 10
Training loss: 1.9118874073028564
Validation loss: 2.1715807837824666

Epoch: 6| Step: 11
Training loss: 2.1344399452209473
Validation loss: 2.174006541570028

Epoch: 6| Step: 12
Training loss: 2.28140926361084
Validation loss: 2.1546079497183523

Epoch: 6| Step: 13
Training loss: 3.380997657775879
Validation loss: 2.1296535422725063

Epoch: 179| Step: 0
Training loss: 2.1462721824645996
Validation loss: 2.1287823595026487

Epoch: 6| Step: 1
Training loss: 1.4993228912353516
Validation loss: 2.1269346065418695

Epoch: 6| Step: 2
Training loss: 2.3793537616729736
Validation loss: 2.1356123083381244

Epoch: 6| Step: 3
Training loss: 2.2053356170654297
Validation loss: 2.1409243896443355

Epoch: 6| Step: 4
Training loss: 1.9057583808898926
Validation loss: 2.1543806765669133

Epoch: 6| Step: 5
Training loss: 1.4915820360183716
Validation loss: 2.170643792357496

Epoch: 6| Step: 6
Training loss: 2.5592498779296875
Validation loss: 2.171656944418466

Epoch: 6| Step: 7
Training loss: 2.101814031600952
Validation loss: 2.186041916570356

Epoch: 6| Step: 8
Training loss: 2.287554979324341
Validation loss: 2.189052733041907

Epoch: 6| Step: 9
Training loss: 2.754354476928711
Validation loss: 2.208139988683885

Epoch: 6| Step: 10
Training loss: 2.3117942810058594
Validation loss: 2.2209836103582896

Epoch: 6| Step: 11
Training loss: 2.208777904510498
Validation loss: 2.219826771366981

Epoch: 6| Step: 12
Training loss: 2.34688663482666
Validation loss: 2.1953085443024993

Epoch: 6| Step: 13
Training loss: 2.4161148071289062
Validation loss: 2.171164430597777

Epoch: 180| Step: 0
Training loss: 2.4277334213256836
Validation loss: 2.156892345797631

Epoch: 6| Step: 1
Training loss: 1.5327322483062744
Validation loss: 2.137180943642893

Epoch: 6| Step: 2
Training loss: 2.2898762226104736
Validation loss: 2.127174413332375

Epoch: 6| Step: 3
Training loss: 2.6284005641937256
Validation loss: 2.1211910401621172

Epoch: 6| Step: 4
Training loss: 1.9486775398254395
Validation loss: 2.1295524104948966

Epoch: 6| Step: 5
Training loss: 2.110929012298584
Validation loss: 2.131902276828725

Epoch: 6| Step: 6
Training loss: 1.7657721042633057
Validation loss: 2.1442537333375666

Epoch: 6| Step: 7
Training loss: 2.6563854217529297
Validation loss: 2.1665295400927143

Epoch: 6| Step: 8
Training loss: 2.389749050140381
Validation loss: 2.1662272253344135

Epoch: 6| Step: 9
Training loss: 2.0280141830444336
Validation loss: 2.1806995086772467

Epoch: 6| Step: 10
Training loss: 1.9309885501861572
Validation loss: 2.1860283446568314

Epoch: 6| Step: 11
Training loss: 2.1914353370666504
Validation loss: 2.2016151617932063

Epoch: 6| Step: 12
Training loss: 2.1795897483825684
Validation loss: 2.1932876263895342

Epoch: 6| Step: 13
Training loss: 2.3396143913269043
Validation loss: 2.1891509127873245

Epoch: 181| Step: 0
Training loss: 1.9142956733703613
Validation loss: 2.1834643066570325

Epoch: 6| Step: 1
Training loss: 2.706568717956543
Validation loss: 2.189296558339109

Epoch: 6| Step: 2
Training loss: 2.2108750343322754
Validation loss: 2.200135795019006

Epoch: 6| Step: 3
Training loss: 1.865215539932251
Validation loss: 2.1975185230214107

Epoch: 6| Step: 4
Training loss: 1.996072769165039
Validation loss: 2.1901605359969603

Epoch: 6| Step: 5
Training loss: 1.2812408208847046
Validation loss: 2.180360878667524

Epoch: 6| Step: 6
Training loss: 2.8441715240478516
Validation loss: 2.1583649086695846

Epoch: 6| Step: 7
Training loss: 2.4682979583740234
Validation loss: 2.14853342886894

Epoch: 6| Step: 8
Training loss: 2.868440628051758
Validation loss: 2.1577458638016895

Epoch: 6| Step: 9
Training loss: 2.1730241775512695
Validation loss: 2.14979737804782

Epoch: 6| Step: 10
Training loss: 1.5548195838928223
Validation loss: 2.1529674273665234

Epoch: 6| Step: 11
Training loss: 1.181352972984314
Validation loss: 2.1618810456286193

Epoch: 6| Step: 12
Training loss: 2.2207956314086914
Validation loss: 2.1607359199113745

Epoch: 6| Step: 13
Training loss: 3.2097392082214355
Validation loss: 2.1562358820310203

Epoch: 182| Step: 0
Training loss: 2.2240312099456787
Validation loss: 2.149978214694608

Epoch: 6| Step: 1
Training loss: 2.1521286964416504
Validation loss: 2.1593632185330955

Epoch: 6| Step: 2
Training loss: 1.8700934648513794
Validation loss: 2.1643817091500885

Epoch: 6| Step: 3
Training loss: 2.492791175842285
Validation loss: 2.174569781108569

Epoch: 6| Step: 4
Training loss: 1.814870834350586
Validation loss: 2.175808370754283

Epoch: 6| Step: 5
Training loss: 2.573033332824707
Validation loss: 2.1800124824688

Epoch: 6| Step: 6
Training loss: 1.9170751571655273
Validation loss: 2.187593037082303

Epoch: 6| Step: 7
Training loss: 2.249997854232788
Validation loss: 2.174945415989045

Epoch: 6| Step: 8
Training loss: 1.8957185745239258
Validation loss: 2.172017389728177

Epoch: 6| Step: 9
Training loss: 1.4006520509719849
Validation loss: 2.1854419990252425

Epoch: 6| Step: 10
Training loss: 2.397275924682617
Validation loss: 2.182220007783623

Epoch: 6| Step: 11
Training loss: 1.5825350284576416
Validation loss: 2.1860490922004945

Epoch: 6| Step: 12
Training loss: 3.0293502807617188
Validation loss: 2.1936258539076774

Epoch: 6| Step: 13
Training loss: 2.347919464111328
Validation loss: 2.2051359376599713

Epoch: 183| Step: 0
Training loss: 2.0108089447021484
Validation loss: 2.1807260961942774

Epoch: 6| Step: 1
Training loss: 2.1535444259643555
Validation loss: 2.1699862890346076

Epoch: 6| Step: 2
Training loss: 2.4063568115234375
Validation loss: 2.1476049987218713

Epoch: 6| Step: 3
Training loss: 1.8039603233337402
Validation loss: 2.1300153373390116

Epoch: 6| Step: 4
Training loss: 2.18583083152771
Validation loss: 2.126490457083589

Epoch: 6| Step: 5
Training loss: 1.9691178798675537
Validation loss: 2.099784187091294

Epoch: 6| Step: 6
Training loss: 2.985058307647705
Validation loss: 2.1008565066963114

Epoch: 6| Step: 7
Training loss: 1.6660206317901611
Validation loss: 2.111872499988925

Epoch: 6| Step: 8
Training loss: 2.108922004699707
Validation loss: 2.1083161894993117

Epoch: 6| Step: 9
Training loss: 2.69193696975708
Validation loss: 2.1245573771897184

Epoch: 6| Step: 10
Training loss: 2.0491158962249756
Validation loss: 2.1304820224802983

Epoch: 6| Step: 11
Training loss: 2.0000228881835938
Validation loss: 2.148796642980268

Epoch: 6| Step: 12
Training loss: 1.988606333732605
Validation loss: 2.1499504953302364

Epoch: 6| Step: 13
Training loss: 2.002706289291382
Validation loss: 2.1565137473485803

Epoch: 184| Step: 0
Training loss: 1.9987657070159912
Validation loss: 2.157785407958492

Epoch: 6| Step: 1
Training loss: 2.447923183441162
Validation loss: 2.1754422803078928

Epoch: 6| Step: 2
Training loss: 1.5999752283096313
Validation loss: 2.1865626265925746

Epoch: 6| Step: 3
Training loss: 2.105647563934326
Validation loss: 2.1914700897791053

Epoch: 6| Step: 4
Training loss: 2.1893422603607178
Validation loss: 2.196863987112558

Epoch: 6| Step: 5
Training loss: 2.5375237464904785
Validation loss: 2.199522938779605

Epoch: 6| Step: 6
Training loss: 2.1490230560302734
Validation loss: 2.203380689826063

Epoch: 6| Step: 7
Training loss: 1.9614393711090088
Validation loss: 2.179632984181886

Epoch: 6| Step: 8
Training loss: 2.255153179168701
Validation loss: 2.1759204274864605

Epoch: 6| Step: 9
Training loss: 2.179565191268921
Validation loss: 2.16421672092971

Epoch: 6| Step: 10
Training loss: 2.4835052490234375
Validation loss: 2.164986100248111

Epoch: 6| Step: 11
Training loss: 1.7164134979248047
Validation loss: 2.142579629857053

Epoch: 6| Step: 12
Training loss: 2.1020450592041016
Validation loss: 2.1342805201007473

Epoch: 6| Step: 13
Training loss: 2.1517703533172607
Validation loss: 2.1417288626393964

Epoch: 185| Step: 0
Training loss: 1.7038724422454834
Validation loss: 2.1534493661695913

Epoch: 6| Step: 1
Training loss: 2.439882278442383
Validation loss: 2.1510930817614318

Epoch: 6| Step: 2
Training loss: 1.6339226961135864
Validation loss: 2.1520844762043287

Epoch: 6| Step: 3
Training loss: 2.4589943885803223
Validation loss: 2.1542454073506017

Epoch: 6| Step: 4
Training loss: 1.9680120944976807
Validation loss: 2.1719031513378186

Epoch: 6| Step: 5
Training loss: 2.6662662029266357
Validation loss: 2.1849932773138887

Epoch: 6| Step: 6
Training loss: 2.0511410236358643
Validation loss: 2.190677409530968

Epoch: 6| Step: 7
Training loss: 2.1676926612854004
Validation loss: 2.218012156025056

Epoch: 6| Step: 8
Training loss: 2.0801594257354736
Validation loss: 2.1752861776659564

Epoch: 6| Step: 9
Training loss: 2.073373317718506
Validation loss: 2.172744310030373

Epoch: 6| Step: 10
Training loss: 2.209306240081787
Validation loss: 2.163666030412079

Epoch: 6| Step: 11
Training loss: 2.0340118408203125
Validation loss: 2.160157319038145

Epoch: 6| Step: 12
Training loss: 1.9962749481201172
Validation loss: 2.1572562110039497

Epoch: 6| Step: 13
Training loss: 2.0931291580200195
Validation loss: 2.1456937841189805

Epoch: 186| Step: 0
Training loss: 2.3885202407836914
Validation loss: 2.1453182107658795

Epoch: 6| Step: 1
Training loss: 1.7475762367248535
Validation loss: 2.155744739758071

Epoch: 6| Step: 2
Training loss: 1.6015821695327759
Validation loss: 2.1600892979611634

Epoch: 6| Step: 3
Training loss: 2.099545955657959
Validation loss: 2.1577757917424685

Epoch: 6| Step: 4
Training loss: 1.8997647762298584
Validation loss: 2.1691910195094284

Epoch: 6| Step: 5
Training loss: 2.3436126708984375
Validation loss: 2.1762564874464467

Epoch: 6| Step: 6
Training loss: 3.0384645462036133
Validation loss: 2.1732259155601583

Epoch: 6| Step: 7
Training loss: 1.9178063869476318
Validation loss: 2.171308837911134

Epoch: 6| Step: 8
Training loss: 2.2882611751556396
Validation loss: 2.195919047119797

Epoch: 6| Step: 9
Training loss: 2.0478765964508057
Validation loss: 2.194113769838887

Epoch: 6| Step: 10
Training loss: 1.653003454208374
Validation loss: 2.1688484376476658

Epoch: 6| Step: 11
Training loss: 2.657790184020996
Validation loss: 2.174047709793173

Epoch: 6| Step: 12
Training loss: 1.1845481395721436
Validation loss: 2.1560034239163963

Epoch: 6| Step: 13
Training loss: 2.8027846813201904
Validation loss: 2.136935423779231

Epoch: 187| Step: 0
Training loss: 2.0662121772766113
Validation loss: 2.1357969930095058

Epoch: 6| Step: 1
Training loss: 2.0667383670806885
Validation loss: 2.109769346893475

Epoch: 6| Step: 2
Training loss: 1.6548740863800049
Validation loss: 2.116160423524918

Epoch: 6| Step: 3
Training loss: 2.148085594177246
Validation loss: 2.1337295783463346

Epoch: 6| Step: 4
Training loss: 2.616952419281006
Validation loss: 2.136177303970501

Epoch: 6| Step: 5
Training loss: 2.0309247970581055
Validation loss: 2.1398412617303992

Epoch: 6| Step: 6
Training loss: 1.7750293016433716
Validation loss: 2.126597378843574

Epoch: 6| Step: 7
Training loss: 2.0900959968566895
Validation loss: 2.1282382575414514

Epoch: 6| Step: 8
Training loss: 2.256621837615967
Validation loss: 2.128110267782724

Epoch: 6| Step: 9
Training loss: 2.8990650177001953
Validation loss: 2.1570690601102767

Epoch: 6| Step: 10
Training loss: 2.5105419158935547
Validation loss: 2.1712730212878157

Epoch: 6| Step: 11
Training loss: 1.5402882099151611
Validation loss: 2.188558683600477

Epoch: 6| Step: 12
Training loss: 2.018035411834717
Validation loss: 2.180009462500131

Epoch: 6| Step: 13
Training loss: 1.6538764238357544
Validation loss: 2.1847615357368224

Epoch: 188| Step: 0
Training loss: 2.150754451751709
Validation loss: 2.184260610611208

Epoch: 6| Step: 1
Training loss: 1.5201674699783325
Validation loss: 2.1655540030489684

Epoch: 6| Step: 2
Training loss: 2.5675363540649414
Validation loss: 2.1320512038405224

Epoch: 6| Step: 3
Training loss: 1.8179298639297485
Validation loss: 2.133801560248098

Epoch: 6| Step: 4
Training loss: 2.3052821159362793
Validation loss: 2.1154120968234156

Epoch: 6| Step: 5
Training loss: 2.3531625270843506
Validation loss: 2.1128166003893782

Epoch: 6| Step: 6
Training loss: 2.125098466873169
Validation loss: 2.1143959286392375

Epoch: 6| Step: 7
Training loss: 2.5634279251098633
Validation loss: 2.1102240841875792

Epoch: 6| Step: 8
Training loss: 1.4887990951538086
Validation loss: 2.116874812751688

Epoch: 6| Step: 9
Training loss: 2.0250015258789062
Validation loss: 2.116049635794855

Epoch: 6| Step: 10
Training loss: 2.107478141784668
Validation loss: 2.122341380324415

Epoch: 6| Step: 11
Training loss: 2.0024242401123047
Validation loss: 2.1332963179516535

Epoch: 6| Step: 12
Training loss: 2.3671579360961914
Validation loss: 2.165626536133469

Epoch: 6| Step: 13
Training loss: 1.87349534034729
Validation loss: 2.1620079804492254

Epoch: 189| Step: 0
Training loss: 1.7677128314971924
Validation loss: 2.195544463331981

Epoch: 6| Step: 1
Training loss: 1.9290235042572021
Validation loss: 2.188122626273863

Epoch: 6| Step: 2
Training loss: 1.519363284111023
Validation loss: 2.1899755385614212

Epoch: 6| Step: 3
Training loss: 1.6832022666931152
Validation loss: 2.213948413889895

Epoch: 6| Step: 4
Training loss: 1.5616551637649536
Validation loss: 2.196344066691655

Epoch: 6| Step: 5
Training loss: 2.161766767501831
Validation loss: 2.1958172013682704

Epoch: 6| Step: 6
Training loss: 2.1051974296569824
Validation loss: 2.1731020506992134

Epoch: 6| Step: 7
Training loss: 2.111551523208618
Validation loss: 2.168439342129615

Epoch: 6| Step: 8
Training loss: 2.5081934928894043
Validation loss: 2.1692394620628765

Epoch: 6| Step: 9
Training loss: 2.1335930824279785
Validation loss: 2.16863840113404

Epoch: 6| Step: 10
Training loss: 2.8806729316711426
Validation loss: 2.162628414810345

Epoch: 6| Step: 11
Training loss: 2.0973072052001953
Validation loss: 2.164572413249682

Epoch: 6| Step: 12
Training loss: 2.2232749462127686
Validation loss: 2.1742564452591764

Epoch: 6| Step: 13
Training loss: 2.712881088256836
Validation loss: 2.1737313296205256

Epoch: 190| Step: 0
Training loss: 2.5576257705688477
Validation loss: 2.158079260139055

Epoch: 6| Step: 1
Training loss: 2.2137398719787598
Validation loss: 2.1385704176400298

Epoch: 6| Step: 2
Training loss: 2.355515956878662
Validation loss: 2.1403796313911356

Epoch: 6| Step: 3
Training loss: 2.1527397632598877
Validation loss: 2.1487178033398044

Epoch: 6| Step: 4
Training loss: 1.1875801086425781
Validation loss: 2.144181151543894

Epoch: 6| Step: 5
Training loss: 1.9751859903335571
Validation loss: 2.125649754719068

Epoch: 6| Step: 6
Training loss: 2.0949907302856445
Validation loss: 2.121242416802273

Epoch: 6| Step: 7
Training loss: 1.5656262636184692
Validation loss: 2.112607099676645

Epoch: 6| Step: 8
Training loss: 1.978102207183838
Validation loss: 2.1300622981081725

Epoch: 6| Step: 9
Training loss: 2.114307403564453
Validation loss: 2.1402004098379486

Epoch: 6| Step: 10
Training loss: 2.438061237335205
Validation loss: 2.149956621149535

Epoch: 6| Step: 11
Training loss: 2.326587200164795
Validation loss: 2.1572531974443825

Epoch: 6| Step: 12
Training loss: 1.8321871757507324
Validation loss: 2.1558866167581208

Epoch: 6| Step: 13
Training loss: 2.676517963409424
Validation loss: 2.1657696385537424

Epoch: 191| Step: 0
Training loss: 1.7881709337234497
Validation loss: 2.1814557993283836

Epoch: 6| Step: 1
Training loss: 1.7233457565307617
Validation loss: 2.194360351049772

Epoch: 6| Step: 2
Training loss: 2.135671854019165
Validation loss: 2.1973923931839647

Epoch: 6| Step: 3
Training loss: 1.467285394668579
Validation loss: 2.184028343487811

Epoch: 6| Step: 4
Training loss: 1.6049846410751343
Validation loss: 2.183266853773466

Epoch: 6| Step: 5
Training loss: 2.39369535446167
Validation loss: 2.1725626748095275

Epoch: 6| Step: 6
Training loss: 2.71834397315979
Validation loss: 2.1738870630982103

Epoch: 6| Step: 7
Training loss: 2.6587743759155273
Validation loss: 2.165739245312188

Epoch: 6| Step: 8
Training loss: 1.582045078277588
Validation loss: 2.150995598044447

Epoch: 6| Step: 9
Training loss: 2.324035167694092
Validation loss: 2.15152048295544

Epoch: 6| Step: 10
Training loss: 2.612035036087036
Validation loss: 2.1534798888749975

Epoch: 6| Step: 11
Training loss: 1.5059235095977783
Validation loss: 2.1582930498225714

Epoch: 6| Step: 12
Training loss: 2.498518705368042
Validation loss: 2.1447881037189114

Epoch: 6| Step: 13
Training loss: 2.1166486740112305
Validation loss: 2.147441594831405

Epoch: 192| Step: 0
Training loss: 1.283831000328064
Validation loss: 2.149579563448506

Epoch: 6| Step: 1
Training loss: 1.852751612663269
Validation loss: 2.122060311737881

Epoch: 6| Step: 2
Training loss: 2.4145052433013916
Validation loss: 2.1402986306016163

Epoch: 6| Step: 3
Training loss: 1.7638473510742188
Validation loss: 2.1345975681017806

Epoch: 6| Step: 4
Training loss: 2.0123891830444336
Validation loss: 2.1730123976225495

Epoch: 6| Step: 5
Training loss: 2.073030948638916
Validation loss: 2.1660638624621975

Epoch: 6| Step: 6
Training loss: 2.2663583755493164
Validation loss: 2.1521667024140716

Epoch: 6| Step: 7
Training loss: 1.9181849956512451
Validation loss: 2.1339155166379866

Epoch: 6| Step: 8
Training loss: 2.0651493072509766
Validation loss: 2.1161527710576213

Epoch: 6| Step: 9
Training loss: 2.7648611068725586
Validation loss: 2.099073738180181

Epoch: 6| Step: 10
Training loss: 1.832953691482544
Validation loss: 2.0893576939900718

Epoch: 6| Step: 11
Training loss: 2.434201240539551
Validation loss: 2.1062321739812053

Epoch: 6| Step: 12
Training loss: 2.3658523559570312
Validation loss: 2.103752500267439

Epoch: 6| Step: 13
Training loss: 2.3721399307250977
Validation loss: 2.1223631789607387

Epoch: 193| Step: 0
Training loss: 1.511189579963684
Validation loss: 2.13226249653806

Epoch: 6| Step: 1
Training loss: 1.9055180549621582
Validation loss: 2.138612408791819

Epoch: 6| Step: 2
Training loss: 1.9110254049301147
Validation loss: 2.1429354195953696

Epoch: 6| Step: 3
Training loss: 2.0291247367858887
Validation loss: 2.149215172695857

Epoch: 6| Step: 4
Training loss: 1.6083308458328247
Validation loss: 2.1504579923486196

Epoch: 6| Step: 5
Training loss: 2.0594193935394287
Validation loss: 2.1572714903021373

Epoch: 6| Step: 6
Training loss: 2.9506893157958984
Validation loss: 2.152333185236941

Epoch: 6| Step: 7
Training loss: 1.8690311908721924
Validation loss: 2.1518974906654766

Epoch: 6| Step: 8
Training loss: 2.1652941703796387
Validation loss: 2.152819659120293

Epoch: 6| Step: 9
Training loss: 2.521292209625244
Validation loss: 2.1501958677845616

Epoch: 6| Step: 10
Training loss: 2.157050609588623
Validation loss: 2.133124982157061

Epoch: 6| Step: 11
Training loss: 2.5925076007843018
Validation loss: 2.1392747535500476

Epoch: 6| Step: 12
Training loss: 1.5456470251083374
Validation loss: 2.145030972778156

Epoch: 6| Step: 13
Training loss: 2.242227792739868
Validation loss: 2.1481224119022326

Epoch: 194| Step: 0
Training loss: 2.0637423992156982
Validation loss: 2.1327679105984267

Epoch: 6| Step: 1
Training loss: 2.428813934326172
Validation loss: 2.117509034372145

Epoch: 6| Step: 2
Training loss: 2.35111141204834
Validation loss: 2.1229199081338863

Epoch: 6| Step: 3
Training loss: 2.7158498764038086
Validation loss: 2.1219433994703394

Epoch: 6| Step: 4
Training loss: 1.8588194847106934
Validation loss: 2.1116785490384666

Epoch: 6| Step: 5
Training loss: 2.1492536067962646
Validation loss: 2.1474113387446248

Epoch: 6| Step: 6
Training loss: 2.0345520973205566
Validation loss: 2.155032862899124

Epoch: 6| Step: 7
Training loss: 1.9113023281097412
Validation loss: 2.1561022548265356

Epoch: 6| Step: 8
Training loss: 1.1584349870681763
Validation loss: 2.167963671427901

Epoch: 6| Step: 9
Training loss: 1.4179000854492188
Validation loss: 2.1705848786138717

Epoch: 6| Step: 10
Training loss: 2.4407482147216797
Validation loss: 2.1831917224391812

Epoch: 6| Step: 11
Training loss: 1.9264135360717773
Validation loss: 2.1972344998390443

Epoch: 6| Step: 12
Training loss: 1.8173909187316895
Validation loss: 2.20823505104229

Epoch: 6| Step: 13
Training loss: 3.0753047466278076
Validation loss: 2.2105460218203965

Epoch: 195| Step: 0
Training loss: 1.839007019996643
Validation loss: 2.2355436855746853

Epoch: 6| Step: 1
Training loss: 2.0190205574035645
Validation loss: 2.2445784050931215

Epoch: 6| Step: 2
Training loss: 1.5914313793182373
Validation loss: 2.237397009326566

Epoch: 6| Step: 3
Training loss: 1.4910579919815063
Validation loss: 2.22296933204897

Epoch: 6| Step: 4
Training loss: 1.985586166381836
Validation loss: 2.176834544827861

Epoch: 6| Step: 5
Training loss: 2.1074061393737793
Validation loss: 2.164422640236475

Epoch: 6| Step: 6
Training loss: 2.6859827041625977
Validation loss: 2.1329269678361955

Epoch: 6| Step: 7
Training loss: 1.9343438148498535
Validation loss: 2.129341822798534

Epoch: 6| Step: 8
Training loss: 1.8507544994354248
Validation loss: 2.118708800244075

Epoch: 6| Step: 9
Training loss: 2.895906448364258
Validation loss: 2.121299248869701

Epoch: 6| Step: 10
Training loss: 2.313375473022461
Validation loss: 2.114303165866483

Epoch: 6| Step: 11
Training loss: 2.422549247741699
Validation loss: 2.1056166977010746

Epoch: 6| Step: 12
Training loss: 1.8403997421264648
Validation loss: 2.110678324135401

Epoch: 6| Step: 13
Training loss: 1.8941421508789062
Validation loss: 2.107233234631118

Epoch: 196| Step: 0
Training loss: 2.5841150283813477
Validation loss: 2.1354209966557

Epoch: 6| Step: 1
Training loss: 2.0300419330596924
Validation loss: 2.1364141536015335

Epoch: 6| Step: 2
Training loss: 1.9451050758361816
Validation loss: 2.150744286916589

Epoch: 6| Step: 3
Training loss: 2.030928611755371
Validation loss: 2.157672817989062

Epoch: 6| Step: 4
Training loss: 2.112527847290039
Validation loss: 2.1673574537359257

Epoch: 6| Step: 5
Training loss: 2.526660680770874
Validation loss: 2.1758709505040157

Epoch: 6| Step: 6
Training loss: 1.7212762832641602
Validation loss: 2.1879318478286907

Epoch: 6| Step: 7
Training loss: 1.2157843112945557
Validation loss: 2.1834404263445126

Epoch: 6| Step: 8
Training loss: 1.345390796661377
Validation loss: 2.1853486850697506

Epoch: 6| Step: 9
Training loss: 2.708299160003662
Validation loss: 2.179202998838117

Epoch: 6| Step: 10
Training loss: 2.349015474319458
Validation loss: 2.16398000460799

Epoch: 6| Step: 11
Training loss: 2.1502633094787598
Validation loss: 2.150504862108538

Epoch: 6| Step: 12
Training loss: 1.6137832403182983
Validation loss: 2.16098883716009

Epoch: 6| Step: 13
Training loss: 2.6130475997924805
Validation loss: 2.16031983078167

Epoch: 197| Step: 0
Training loss: 2.402315139770508
Validation loss: 2.144400255654448

Epoch: 6| Step: 1
Training loss: 1.5430556535720825
Validation loss: 2.1356158551349433

Epoch: 6| Step: 2
Training loss: 1.5322363376617432
Validation loss: 2.1324729201614216

Epoch: 6| Step: 3
Training loss: 1.9177719354629517
Validation loss: 2.137904069756949

Epoch: 6| Step: 4
Training loss: 1.6185531616210938
Validation loss: 2.138059675052602

Epoch: 6| Step: 5
Training loss: 1.3090370893478394
Validation loss: 2.1336230513870076

Epoch: 6| Step: 6
Training loss: 2.3902828693389893
Validation loss: 2.132422390804496

Epoch: 6| Step: 7
Training loss: 2.6457066535949707
Validation loss: 2.13881863317182

Epoch: 6| Step: 8
Training loss: 1.9045450687408447
Validation loss: 2.12935741742452

Epoch: 6| Step: 9
Training loss: 1.6784274578094482
Validation loss: 2.1400108798857658

Epoch: 6| Step: 10
Training loss: 2.779407262802124
Validation loss: 2.121371256407871

Epoch: 6| Step: 11
Training loss: 1.8390960693359375
Validation loss: 2.1051970143471994

Epoch: 6| Step: 12
Training loss: 2.188300848007202
Validation loss: 2.108449723130913

Epoch: 6| Step: 13
Training loss: 3.1179285049438477
Validation loss: 2.104854473503687

Epoch: 198| Step: 0
Training loss: 1.9569720029830933
Validation loss: 2.1086165738362137

Epoch: 6| Step: 1
Training loss: 2.2533674240112305
Validation loss: 2.106837659753779

Epoch: 6| Step: 2
Training loss: 0.9533286690711975
Validation loss: 2.107417751384038

Epoch: 6| Step: 3
Training loss: 1.568543791770935
Validation loss: 2.134080577922124

Epoch: 6| Step: 4
Training loss: 1.450943946838379
Validation loss: 2.1473997792889996

Epoch: 6| Step: 5
Training loss: 1.9077579975128174
Validation loss: 2.1456758155617663

Epoch: 6| Step: 6
Training loss: 1.4192075729370117
Validation loss: 2.1519816280693136

Epoch: 6| Step: 7
Training loss: 2.2526514530181885
Validation loss: 2.1608112345459642

Epoch: 6| Step: 8
Training loss: 2.3667190074920654
Validation loss: 2.127246597761749

Epoch: 6| Step: 9
Training loss: 2.277057409286499
Validation loss: 2.1204008504908574

Epoch: 6| Step: 10
Training loss: 2.0904622077941895
Validation loss: 2.102990572170545

Epoch: 6| Step: 11
Training loss: 2.9538583755493164
Validation loss: 2.112710242630333

Epoch: 6| Step: 12
Training loss: 2.497868537902832
Validation loss: 2.1373717067062215

Epoch: 6| Step: 13
Training loss: 2.8009443283081055
Validation loss: 2.1400688771278626

Epoch: 199| Step: 0
Training loss: 3.1813509464263916
Validation loss: 2.151427202327277

Epoch: 6| Step: 1
Training loss: 1.5721244812011719
Validation loss: 2.1583480296596402

Epoch: 6| Step: 2
Training loss: 2.271574020385742
Validation loss: 2.1752652122128393

Epoch: 6| Step: 3
Training loss: 2.403093099594116
Validation loss: 2.1728136924005326

Epoch: 6| Step: 4
Training loss: 1.8283050060272217
Validation loss: 2.171858028698993

Epoch: 6| Step: 5
Training loss: 1.0285508632659912
Validation loss: 2.2084496123816377

Epoch: 6| Step: 6
Training loss: 2.5868263244628906
Validation loss: 2.2075654960447744

Epoch: 6| Step: 7
Training loss: 1.347037434577942
Validation loss: 2.2187704014521774

Epoch: 6| Step: 8
Training loss: 2.6100571155548096
Validation loss: 2.1867126931426344

Epoch: 6| Step: 9
Training loss: 2.2217178344726562
Validation loss: 2.140901903952322

Epoch: 6| Step: 10
Training loss: 1.9029676914215088
Validation loss: 2.10891548279793

Epoch: 6| Step: 11
Training loss: 2.195495128631592
Validation loss: 2.1030947495532293

Epoch: 6| Step: 12
Training loss: 1.6264960765838623
Validation loss: 2.0995528031420965

Epoch: 6| Step: 13
Training loss: 1.927825689315796
Validation loss: 2.1053378069272606

Epoch: 200| Step: 0
Training loss: 2.384171724319458
Validation loss: 2.103187471307734

Epoch: 6| Step: 1
Training loss: 1.602352261543274
Validation loss: 2.1085259888761785

Epoch: 6| Step: 2
Training loss: 2.308051109313965
Validation loss: 2.109039150258546

Epoch: 6| Step: 3
Training loss: 2.4905500411987305
Validation loss: 2.1313417162946475

Epoch: 6| Step: 4
Training loss: 2.0373764038085938
Validation loss: 2.1365025197305987

Epoch: 6| Step: 5
Training loss: 1.8212611675262451
Validation loss: 2.148785324506862

Epoch: 6| Step: 6
Training loss: 1.9796264171600342
Validation loss: 2.1432286385566957

Epoch: 6| Step: 7
Training loss: 1.2499821186065674
Validation loss: 2.137910798031797

Epoch: 6| Step: 8
Training loss: 2.368882179260254
Validation loss: 2.1436026583435717

Epoch: 6| Step: 9
Training loss: 2.724290370941162
Validation loss: 2.1264304678927184

Epoch: 6| Step: 10
Training loss: 1.703713059425354
Validation loss: 2.1231169367349274

Epoch: 6| Step: 11
Training loss: 1.480055570602417
Validation loss: 2.1340833940813617

Epoch: 6| Step: 12
Training loss: 2.036564350128174
Validation loss: 2.12821614614097

Epoch: 6| Step: 13
Training loss: 1.9597746133804321
Validation loss: 2.1331968333131526

Epoch: 201| Step: 0
Training loss: 2.508821725845337
Validation loss: 2.1438241748399633

Epoch: 6| Step: 1
Training loss: 2.0351951122283936
Validation loss: 2.1526565449212187

Epoch: 6| Step: 2
Training loss: 1.4139845371246338
Validation loss: 2.153186775022937

Epoch: 6| Step: 3
Training loss: 2.2889785766601562
Validation loss: 2.1541543852898384

Epoch: 6| Step: 4
Training loss: 1.7669003009796143
Validation loss: 2.1570252039099254

Epoch: 6| Step: 5
Training loss: 1.8422000408172607
Validation loss: 2.1606151493646766

Epoch: 6| Step: 6
Training loss: 2.060701608657837
Validation loss: 2.1595665870174283

Epoch: 6| Step: 7
Training loss: 2.0109033584594727
Validation loss: 2.1464533164937007

Epoch: 6| Step: 8
Training loss: 1.724278450012207
Validation loss: 2.145255470788607

Epoch: 6| Step: 9
Training loss: 2.1295857429504395
Validation loss: 2.125642148397302

Epoch: 6| Step: 10
Training loss: 1.7532613277435303
Validation loss: 2.0918427000763598

Epoch: 6| Step: 11
Training loss: 2.4208595752716064
Validation loss: 2.1018076635176137

Epoch: 6| Step: 12
Training loss: 2.3744285106658936
Validation loss: 2.0960389670505317

Epoch: 6| Step: 13
Training loss: 1.5376814603805542
Validation loss: 2.0931907187226

Epoch: 202| Step: 0
Training loss: 2.3775625228881836
Validation loss: 2.0997296020548832

Epoch: 6| Step: 1
Training loss: 2.039687156677246
Validation loss: 2.094893237595917

Epoch: 6| Step: 2
Training loss: 1.6851627826690674
Validation loss: 2.0976519020654822

Epoch: 6| Step: 3
Training loss: 1.8115081787109375
Validation loss: 2.09479292233785

Epoch: 6| Step: 4
Training loss: 1.8754806518554688
Validation loss: 2.113056375134376

Epoch: 6| Step: 5
Training loss: 2.009875774383545
Validation loss: 2.1248102649565666

Epoch: 6| Step: 6
Training loss: 2.4426236152648926
Validation loss: 2.1186743782412623

Epoch: 6| Step: 7
Training loss: 1.535649061203003
Validation loss: 2.134942208566973

Epoch: 6| Step: 8
Training loss: 2.0542778968811035
Validation loss: 2.1443414970110823

Epoch: 6| Step: 9
Training loss: 2.212552785873413
Validation loss: 2.153369706164124

Epoch: 6| Step: 10
Training loss: 1.9665656089782715
Validation loss: 2.1497958501180015

Epoch: 6| Step: 11
Training loss: 1.9401192665100098
Validation loss: 2.159458411637173

Epoch: 6| Step: 12
Training loss: 1.980553150177002
Validation loss: 2.136134106625793

Epoch: 6| Step: 13
Training loss: 2.1252167224884033
Validation loss: 2.1442054548571186

Epoch: 203| Step: 0
Training loss: 2.1789355278015137
Validation loss: 2.116047846373691

Epoch: 6| Step: 1
Training loss: 2.3549787998199463
Validation loss: 2.1236048911207464

Epoch: 6| Step: 2
Training loss: 2.297372817993164
Validation loss: 2.1073255603031447

Epoch: 6| Step: 3
Training loss: 1.8635822534561157
Validation loss: 2.1032317633269937

Epoch: 6| Step: 4
Training loss: 2.5671234130859375
Validation loss: 2.093439189336633

Epoch: 6| Step: 5
Training loss: 2.7382686138153076
Validation loss: 2.1073693742034254

Epoch: 6| Step: 6
Training loss: 1.9714404344558716
Validation loss: 2.103559778582665

Epoch: 6| Step: 7
Training loss: 1.943359136581421
Validation loss: 2.1315126495976604

Epoch: 6| Step: 8
Training loss: 1.3476855754852295
Validation loss: 2.1352328664513043

Epoch: 6| Step: 9
Training loss: 1.6043312549591064
Validation loss: 2.131031784960019

Epoch: 6| Step: 10
Training loss: 1.6960680484771729
Validation loss: 2.1302060760477537

Epoch: 6| Step: 11
Training loss: 2.073786973953247
Validation loss: 2.1290974181185485

Epoch: 6| Step: 12
Training loss: 1.5036604404449463
Validation loss: 2.118667494866156

Epoch: 6| Step: 13
Training loss: 1.5474058389663696
Validation loss: 2.115051806613963

Epoch: 204| Step: 0
Training loss: 1.5036990642547607
Validation loss: 2.109039322022469

Epoch: 6| Step: 1
Training loss: 2.611372709274292
Validation loss: 2.104462492850519

Epoch: 6| Step: 2
Training loss: 2.1094565391540527
Validation loss: 2.1027156947761454

Epoch: 6| Step: 3
Training loss: 1.8800383806228638
Validation loss: 2.1104584176053285

Epoch: 6| Step: 4
Training loss: 2.2969305515289307
Validation loss: 2.1284773606126026

Epoch: 6| Step: 5
Training loss: 1.831087350845337
Validation loss: 2.096817708784534

Epoch: 6| Step: 6
Training loss: 1.8621717691421509
Validation loss: 2.137621202776509

Epoch: 6| Step: 7
Training loss: 2.0185964107513428
Validation loss: 2.15527960946483

Epoch: 6| Step: 8
Training loss: 1.9714961051940918
Validation loss: 2.16023152489816

Epoch: 6| Step: 9
Training loss: 1.483029842376709
Validation loss: 2.1713814966140257

Epoch: 6| Step: 10
Training loss: 2.0103588104248047
Validation loss: 2.159526430150514

Epoch: 6| Step: 11
Training loss: 2.1772069931030273
Validation loss: 2.120734099418886

Epoch: 6| Step: 12
Training loss: 1.9247591495513916
Validation loss: 2.0861016678553757

Epoch: 6| Step: 13
Training loss: 2.3763575553894043
Validation loss: 2.087310710260945

Epoch: 205| Step: 0
Training loss: 2.1621809005737305
Validation loss: 2.076680088555941

Epoch: 6| Step: 1
Training loss: 1.9469637870788574
Validation loss: 2.0869094376922934

Epoch: 6| Step: 2
Training loss: 1.4520983695983887
Validation loss: 2.0893160553388697

Epoch: 6| Step: 3
Training loss: 2.5393686294555664
Validation loss: 2.1012019393264607

Epoch: 6| Step: 4
Training loss: 1.863339900970459
Validation loss: 2.126360288230322

Epoch: 6| Step: 5
Training loss: 2.48861026763916
Validation loss: 2.1308918947814615

Epoch: 6| Step: 6
Training loss: 1.7671970129013062
Validation loss: 2.1165465488228747

Epoch: 6| Step: 7
Training loss: 1.3390507698059082
Validation loss: 2.1024615072434947

Epoch: 6| Step: 8
Training loss: 2.0572352409362793
Validation loss: 2.0913055801904328

Epoch: 6| Step: 9
Training loss: 1.8213807344436646
Validation loss: 2.1091699959129415

Epoch: 6| Step: 10
Training loss: 1.8980661630630493
Validation loss: 2.1165382221180904

Epoch: 6| Step: 11
Training loss: 2.396122455596924
Validation loss: 2.1223944464037494

Epoch: 6| Step: 12
Training loss: 2.3817081451416016
Validation loss: 2.1292136946032123

Epoch: 6| Step: 13
Training loss: 1.914162516593933
Validation loss: 2.1418078407164542

Epoch: 206| Step: 0
Training loss: 1.9991878271102905
Validation loss: 2.157708288520895

Epoch: 6| Step: 1
Training loss: 2.3539700508117676
Validation loss: 2.1505038956160187

Epoch: 6| Step: 2
Training loss: 1.641359806060791
Validation loss: 2.15171395322328

Epoch: 6| Step: 3
Training loss: 1.4468762874603271
Validation loss: 2.1496578185789046

Epoch: 6| Step: 4
Training loss: 1.9375337362289429
Validation loss: 2.147480913387832

Epoch: 6| Step: 5
Training loss: 1.6808393001556396
Validation loss: 2.1555819793414046

Epoch: 6| Step: 6
Training loss: 2.105372905731201
Validation loss: 2.1592938130901707

Epoch: 6| Step: 7
Training loss: 1.7397316694259644
Validation loss: 2.166944634529852

Epoch: 6| Step: 8
Training loss: 2.737740993499756
Validation loss: 2.146037709328436

Epoch: 6| Step: 9
Training loss: 2.120950937271118
Validation loss: 2.1475349882597565

Epoch: 6| Step: 10
Training loss: 2.057116985321045
Validation loss: 2.1132016694673927

Epoch: 6| Step: 11
Training loss: 1.961940050125122
Validation loss: 2.0847965555806316

Epoch: 6| Step: 12
Training loss: 1.7818224430084229
Validation loss: 2.071388029283093

Epoch: 6| Step: 13
Training loss: 2.501295804977417
Validation loss: 2.067535715718423

Epoch: 207| Step: 0
Training loss: 1.931017279624939
Validation loss: 2.0743461475577405

Epoch: 6| Step: 1
Training loss: 2.0897207260131836
Validation loss: 2.0737051540805447

Epoch: 6| Step: 2
Training loss: 2.0719432830810547
Validation loss: 2.082531677779331

Epoch: 6| Step: 3
Training loss: 1.9272878170013428
Validation loss: 2.0937177186371176

Epoch: 6| Step: 4
Training loss: 2.118778705596924
Validation loss: 2.0974821172734743

Epoch: 6| Step: 5
Training loss: 1.4640052318572998
Validation loss: 2.099120642549248

Epoch: 6| Step: 6
Training loss: 2.5752053260803223
Validation loss: 2.114428117711057

Epoch: 6| Step: 7
Training loss: 1.8006565570831299
Validation loss: 2.1241971344076176

Epoch: 6| Step: 8
Training loss: 2.0050134658813477
Validation loss: 2.141156640104068

Epoch: 6| Step: 9
Training loss: 2.038116455078125
Validation loss: 2.1515288186329666

Epoch: 6| Step: 10
Training loss: 1.9570071697235107
Validation loss: 2.146821343770591

Epoch: 6| Step: 11
Training loss: 1.8917869329452515
Validation loss: 2.1589544165518975

Epoch: 6| Step: 12
Training loss: 2.2775089740753174
Validation loss: 2.1425604461341776

Epoch: 6| Step: 13
Training loss: 1.3316283226013184
Validation loss: 2.136126264449089

Epoch: 208| Step: 0
Training loss: 1.6413253545761108
Validation loss: 2.1334869207874423

Epoch: 6| Step: 1
Training loss: 1.6782159805297852
Validation loss: 2.1075926506391136

Epoch: 6| Step: 2
Training loss: 1.7074453830718994
Validation loss: 2.1003855479660856

Epoch: 6| Step: 3
Training loss: 2.0192503929138184
Validation loss: 2.1041231386123167

Epoch: 6| Step: 4
Training loss: 1.5160224437713623
Validation loss: 2.086689277361798

Epoch: 6| Step: 5
Training loss: 2.5677828788757324
Validation loss: 2.098664886207991

Epoch: 6| Step: 6
Training loss: 2.1795473098754883
Validation loss: 2.0966607447593444

Epoch: 6| Step: 7
Training loss: 1.9623781442642212
Validation loss: 2.115522684589509

Epoch: 6| Step: 8
Training loss: 1.6590733528137207
Validation loss: 2.1243521449386433

Epoch: 6| Step: 9
Training loss: 2.0651650428771973
Validation loss: 2.126847569660474

Epoch: 6| Step: 10
Training loss: 2.320246696472168
Validation loss: 2.1533966141362346

Epoch: 6| Step: 11
Training loss: 2.5890891551971436
Validation loss: 2.1394308344010384

Epoch: 6| Step: 12
Training loss: 1.6976592540740967
Validation loss: 2.1487520689605386

Epoch: 6| Step: 13
Training loss: 2.078402280807495
Validation loss: 2.1366165709751908

Epoch: 209| Step: 0
Training loss: 2.3336527347564697
Validation loss: 2.135974963506063

Epoch: 6| Step: 1
Training loss: 2.495314836502075
Validation loss: 2.1326213857179046

Epoch: 6| Step: 2
Training loss: 1.9978166818618774
Validation loss: 2.1281888972046556

Epoch: 6| Step: 3
Training loss: 2.306391716003418
Validation loss: 2.119493713301997

Epoch: 6| Step: 4
Training loss: 2.8512370586395264
Validation loss: 2.1178978848200973

Epoch: 6| Step: 5
Training loss: 1.612586259841919
Validation loss: 2.121612710337485

Epoch: 6| Step: 6
Training loss: 1.7740343809127808
Validation loss: 2.1353722464653755

Epoch: 6| Step: 7
Training loss: 1.9469025135040283
Validation loss: 2.126988560922684

Epoch: 6| Step: 8
Training loss: 1.558253526687622
Validation loss: 2.121826834576104

Epoch: 6| Step: 9
Training loss: 1.1426814794540405
Validation loss: 2.116866368119435

Epoch: 6| Step: 10
Training loss: 1.965121865272522
Validation loss: 2.106136845004174

Epoch: 6| Step: 11
Training loss: 1.9505646228790283
Validation loss: 2.1251097699647308

Epoch: 6| Step: 12
Training loss: 1.5552728176116943
Validation loss: 2.101546770782881

Epoch: 6| Step: 13
Training loss: 2.0453648567199707
Validation loss: 2.1039308476191696

Epoch: 210| Step: 0
Training loss: 2.249739646911621
Validation loss: 2.10004005124492

Epoch: 6| Step: 1
Training loss: 1.3507890701293945
Validation loss: 2.108109143472487

Epoch: 6| Step: 2
Training loss: 2.1705806255340576
Validation loss: 2.08849641840945

Epoch: 6| Step: 3
Training loss: 2.000838279724121
Validation loss: 2.1000997148534304

Epoch: 6| Step: 4
Training loss: 1.9700584411621094
Validation loss: 2.1093389757217897

Epoch: 6| Step: 5
Training loss: 1.8652830123901367
Validation loss: 2.112070891164964

Epoch: 6| Step: 6
Training loss: 1.997706651687622
Validation loss: 2.1182489036231913

Epoch: 6| Step: 7
Training loss: 2.2355809211730957
Validation loss: 2.127974405083605

Epoch: 6| Step: 8
Training loss: 2.3312532901763916
Validation loss: 2.120125437295565

Epoch: 6| Step: 9
Training loss: 2.1756603717803955
Validation loss: 2.118974603632445

Epoch: 6| Step: 10
Training loss: 1.6045820713043213
Validation loss: 2.1026540494734243

Epoch: 6| Step: 11
Training loss: 1.9166321754455566
Validation loss: 2.0933780465074765

Epoch: 6| Step: 12
Training loss: 1.9456779956817627
Validation loss: 2.0999200344085693

Epoch: 6| Step: 13
Training loss: 1.4161088466644287
Validation loss: 2.089312714915122

Epoch: 211| Step: 0
Training loss: 1.6752386093139648
Validation loss: 2.1048339092603294

Epoch: 6| Step: 1
Training loss: 1.5486743450164795
Validation loss: 2.1048824607685046

Epoch: 6| Step: 2
Training loss: 2.285635232925415
Validation loss: 2.114776808728454

Epoch: 6| Step: 3
Training loss: 2.0665152072906494
Validation loss: 2.13951970941277

Epoch: 6| Step: 4
Training loss: 2.0770468711853027
Validation loss: 2.140979064408169

Epoch: 6| Step: 5
Training loss: 2.2107186317443848
Validation loss: 2.1182162723233624

Epoch: 6| Step: 6
Training loss: 2.464473247528076
Validation loss: 2.097435821769058

Epoch: 6| Step: 7
Training loss: 2.0613627433776855
Validation loss: 2.0950067299668507

Epoch: 6| Step: 8
Training loss: 2.0151970386505127
Validation loss: 2.0867475707043885

Epoch: 6| Step: 9
Training loss: 1.8657116889953613
Validation loss: 2.0594796890853555

Epoch: 6| Step: 10
Training loss: 1.8795925378799438
Validation loss: 2.0758829065548476

Epoch: 6| Step: 11
Training loss: 2.256300926208496
Validation loss: 2.0741589300094114

Epoch: 6| Step: 12
Training loss: 1.5041494369506836
Validation loss: 2.0895058147368895

Epoch: 6| Step: 13
Training loss: 1.386972427368164
Validation loss: 2.1027715513783116

Epoch: 212| Step: 0
Training loss: 1.7965562343597412
Validation loss: 2.1447848940408356

Epoch: 6| Step: 1
Training loss: 1.7945435047149658
Validation loss: 2.1644002109445553

Epoch: 6| Step: 2
Training loss: 1.972391128540039
Validation loss: 2.170564066979193

Epoch: 6| Step: 3
Training loss: 2.289978504180908
Validation loss: 2.1471922756523214

Epoch: 6| Step: 4
Training loss: 1.9937692880630493
Validation loss: 2.1409901444629957

Epoch: 6| Step: 5
Training loss: 2.6407299041748047
Validation loss: 2.1210914350325063

Epoch: 6| Step: 6
Training loss: 1.825514316558838
Validation loss: 2.107985104283979

Epoch: 6| Step: 7
Training loss: 1.7175135612487793
Validation loss: 2.0850393131215084

Epoch: 6| Step: 8
Training loss: 2.0348939895629883
Validation loss: 2.0897472417482765

Epoch: 6| Step: 9
Training loss: 1.645821452140808
Validation loss: 2.098048125543902

Epoch: 6| Step: 10
Training loss: 1.6458595991134644
Validation loss: 2.086985408618886

Epoch: 6| Step: 11
Training loss: 2.167819023132324
Validation loss: 2.121470010408791

Epoch: 6| Step: 12
Training loss: 1.7772293090820312
Validation loss: 2.0984356787896927

Epoch: 6| Step: 13
Training loss: 2.5844764709472656
Validation loss: 2.116255642265402

Epoch: 213| Step: 0
Training loss: 1.9276862144470215
Validation loss: 2.1031933215356644

Epoch: 6| Step: 1
Training loss: 1.0495518445968628
Validation loss: 2.081841814902521

Epoch: 6| Step: 2
Training loss: 1.4624128341674805
Validation loss: 2.0712822714159564

Epoch: 6| Step: 3
Training loss: 1.515891671180725
Validation loss: 2.07644413363549

Epoch: 6| Step: 4
Training loss: 1.831455111503601
Validation loss: 2.0764351019295315

Epoch: 6| Step: 5
Training loss: 1.997916340827942
Validation loss: 2.0697869459788003

Epoch: 6| Step: 6
Training loss: 2.4347872734069824
Validation loss: 2.0669948208716606

Epoch: 6| Step: 7
Training loss: 2.301509380340576
Validation loss: 2.0702013123419976

Epoch: 6| Step: 8
Training loss: 2.0932278633117676
Validation loss: 2.0821254240569247

Epoch: 6| Step: 9
Training loss: 1.4768266677856445
Validation loss: 2.088722439222438

Epoch: 6| Step: 10
Training loss: 2.991158962249756
Validation loss: 2.080876483712145

Epoch: 6| Step: 11
Training loss: 2.0215964317321777
Validation loss: 2.098346464095577

Epoch: 6| Step: 12
Training loss: 1.2497748136520386
Validation loss: 2.114400568828788

Epoch: 6| Step: 13
Training loss: 3.4375486373901367
Validation loss: 2.1168332766461115

Epoch: 214| Step: 0
Training loss: 1.8621771335601807
Validation loss: 2.140462234456052

Epoch: 6| Step: 1
Training loss: 2.0729548931121826
Validation loss: 2.1466536419365996

Epoch: 6| Step: 2
Training loss: 2.00688099861145
Validation loss: 2.1526056258909163

Epoch: 6| Step: 3
Training loss: 1.6924110651016235
Validation loss: 2.1494101144934215

Epoch: 6| Step: 4
Training loss: 1.258652687072754
Validation loss: 2.1474332860721055

Epoch: 6| Step: 5
Training loss: 2.317997932434082
Validation loss: 2.140055682069512

Epoch: 6| Step: 6
Training loss: 1.618335485458374
Validation loss: 2.1437463760375977

Epoch: 6| Step: 7
Training loss: 1.531232237815857
Validation loss: 2.1416235534093713

Epoch: 6| Step: 8
Training loss: 1.884657382965088
Validation loss: 2.1440875901970813

Epoch: 6| Step: 9
Training loss: 2.149233341217041
Validation loss: 2.1279919557673956

Epoch: 6| Step: 10
Training loss: 2.373816967010498
Validation loss: 2.1333252229998187

Epoch: 6| Step: 11
Training loss: 1.5594501495361328
Validation loss: 2.1169568313065397

Epoch: 6| Step: 12
Training loss: 2.4585225582122803
Validation loss: 2.1200329129413893

Epoch: 6| Step: 13
Training loss: 2.498945951461792
Validation loss: 2.092693962076659

Epoch: 215| Step: 0
Training loss: 1.8761177062988281
Validation loss: 2.08232484838014

Epoch: 6| Step: 1
Training loss: 1.8012769222259521
Validation loss: 2.0662070282043947

Epoch: 6| Step: 2
Training loss: 1.768659234046936
Validation loss: 2.055209631560951

Epoch: 6| Step: 3
Training loss: 2.1178879737854004
Validation loss: 2.043771292573662

Epoch: 6| Step: 4
Training loss: 1.8468210697174072
Validation loss: 2.044323387966361

Epoch: 6| Step: 5
Training loss: 2.0569937229156494
Validation loss: 2.0554282754980107

Epoch: 6| Step: 6
Training loss: 2.033229351043701
Validation loss: 2.053229440924942

Epoch: 6| Step: 7
Training loss: 1.8929972648620605
Validation loss: 2.057506395924476

Epoch: 6| Step: 8
Training loss: 2.0094175338745117
Validation loss: 2.0616297491135134

Epoch: 6| Step: 9
Training loss: 1.8759548664093018
Validation loss: 2.0816794518501527

Epoch: 6| Step: 10
Training loss: 1.9039183855056763
Validation loss: 2.0841082654973513

Epoch: 6| Step: 11
Training loss: 1.9129502773284912
Validation loss: 2.0955942266730854

Epoch: 6| Step: 12
Training loss: 1.6994272470474243
Validation loss: 2.09593113007084

Epoch: 6| Step: 13
Training loss: 2.535456657409668
Validation loss: 2.1339036341636413

Epoch: 216| Step: 0
Training loss: 1.6954982280731201
Validation loss: 2.1472077677326817

Epoch: 6| Step: 1
Training loss: 2.646015167236328
Validation loss: 2.1541086409681585

Epoch: 6| Step: 2
Training loss: 2.100369691848755
Validation loss: 2.141802623707761

Epoch: 6| Step: 3
Training loss: 1.847611665725708
Validation loss: 2.1367052498684136

Epoch: 6| Step: 4
Training loss: 1.6917707920074463
Validation loss: 2.116483570427023

Epoch: 6| Step: 5
Training loss: 2.0638909339904785
Validation loss: 2.1022814422525387

Epoch: 6| Step: 6
Training loss: 1.9729926586151123
Validation loss: 2.108828841999013

Epoch: 6| Step: 7
Training loss: 1.8955116271972656
Validation loss: 2.095354313491493

Epoch: 6| Step: 8
Training loss: 1.9554266929626465
Validation loss: 2.0930798015286847

Epoch: 6| Step: 9
Training loss: 2.105984687805176
Validation loss: 2.11031779678919

Epoch: 6| Step: 10
Training loss: 2.8616671562194824
Validation loss: 2.1269742981080086

Epoch: 6| Step: 11
Training loss: 1.2805123329162598
Validation loss: 2.122258875959663

Epoch: 6| Step: 12
Training loss: 1.7364437580108643
Validation loss: 2.1121567487716675

Epoch: 6| Step: 13
Training loss: 0.6608717441558838
Validation loss: 2.104270109566309

Epoch: 217| Step: 0
Training loss: 2.1662964820861816
Validation loss: 2.0906136497374503

Epoch: 6| Step: 1
Training loss: 1.5306541919708252
Validation loss: 2.099036447463497

Epoch: 6| Step: 2
Training loss: 1.9250973463058472
Validation loss: 2.0981213687568583

Epoch: 6| Step: 3
Training loss: 1.2356326580047607
Validation loss: 2.0962152327260664

Epoch: 6| Step: 4
Training loss: 2.2621684074401855
Validation loss: 2.1059868028087

Epoch: 6| Step: 5
Training loss: 1.5698349475860596
Validation loss: 2.1092857494149158

Epoch: 6| Step: 6
Training loss: 1.734076976776123
Validation loss: 2.109697340637125

Epoch: 6| Step: 7
Training loss: 2.119030475616455
Validation loss: 2.1044765416012017

Epoch: 6| Step: 8
Training loss: 2.278186798095703
Validation loss: 2.1057330562222387

Epoch: 6| Step: 9
Training loss: 1.7905426025390625
Validation loss: 2.08380530470161

Epoch: 6| Step: 10
Training loss: 2.2884955406188965
Validation loss: 2.0897767454065304

Epoch: 6| Step: 11
Training loss: 1.5312236547470093
Validation loss: 2.1009621107450096

Epoch: 6| Step: 12
Training loss: 2.0512452125549316
Validation loss: 2.106014601645931

Epoch: 6| Step: 13
Training loss: 2.3379533290863037
Validation loss: 2.0978908410636325

Epoch: 218| Step: 0
Training loss: 2.110071897506714
Validation loss: 2.09292939401442

Epoch: 6| Step: 1
Training loss: 1.6381499767303467
Validation loss: 2.1019828473368

Epoch: 6| Step: 2
Training loss: 2.248511791229248
Validation loss: 2.122302414268576

Epoch: 6| Step: 3
Training loss: 1.8201416730880737
Validation loss: 2.116271362509779

Epoch: 6| Step: 4
Training loss: 1.718869686126709
Validation loss: 2.1147969204892396

Epoch: 6| Step: 5
Training loss: 1.9776698350906372
Validation loss: 2.1297423173022527

Epoch: 6| Step: 6
Training loss: 1.6149758100509644
Validation loss: 2.1167024720099663

Epoch: 6| Step: 7
Training loss: 1.731685996055603
Validation loss: 2.114010312223947

Epoch: 6| Step: 8
Training loss: 1.452591896057129
Validation loss: 2.132830335247901

Epoch: 6| Step: 9
Training loss: 2.0196151733398438
Validation loss: 2.1414201644159134

Epoch: 6| Step: 10
Training loss: 2.175393581390381
Validation loss: 2.1169732270702237

Epoch: 6| Step: 11
Training loss: 1.321481466293335
Validation loss: 2.120736191349645

Epoch: 6| Step: 12
Training loss: 2.146533966064453
Validation loss: 2.097349597561744

Epoch: 6| Step: 13
Training loss: 3.281155586242676
Validation loss: 2.089322474695021

Epoch: 219| Step: 0
Training loss: 1.929593563079834
Validation loss: 2.095505599052675

Epoch: 6| Step: 1
Training loss: 1.7435864210128784
Validation loss: 2.0882959135117067

Epoch: 6| Step: 2
Training loss: 1.9239592552185059
Validation loss: 2.0979335269620343

Epoch: 6| Step: 3
Training loss: 2.027737617492676
Validation loss: 2.127204674546437

Epoch: 6| Step: 4
Training loss: 1.6916797161102295
Validation loss: 2.1265998681386313

Epoch: 6| Step: 5
Training loss: 1.4580259323120117
Validation loss: 2.128606927010321

Epoch: 6| Step: 6
Training loss: 2.012519121170044
Validation loss: 2.1124177030337754

Epoch: 6| Step: 7
Training loss: 1.181759238243103
Validation loss: 2.139395334387338

Epoch: 6| Step: 8
Training loss: 2.3666481971740723
Validation loss: 2.177317311686854

Epoch: 6| Step: 9
Training loss: 2.139362335205078
Validation loss: 2.1765858037497408

Epoch: 6| Step: 10
Training loss: 2.124727725982666
Validation loss: 2.151403104105303

Epoch: 6| Step: 11
Training loss: 2.097172498703003
Validation loss: 2.120211967857935

Epoch: 6| Step: 12
Training loss: 2.2159976959228516
Validation loss: 2.086815934027395

Epoch: 6| Step: 13
Training loss: 2.0047006607055664
Validation loss: 2.098578204390823

Epoch: 220| Step: 0
Training loss: 2.238222360610962
Validation loss: 2.0876403752193657

Epoch: 6| Step: 1
Training loss: 1.6837377548217773
Validation loss: 2.0840623878663584

Epoch: 6| Step: 2
Training loss: 1.7278203964233398
Validation loss: 2.059338346604378

Epoch: 6| Step: 3
Training loss: 2.3627994060516357
Validation loss: 2.0690692381192277

Epoch: 6| Step: 4
Training loss: 1.5638501644134521
Validation loss: 2.063112497329712

Epoch: 6| Step: 5
Training loss: 1.9664528369903564
Validation loss: 2.0746983738355738

Epoch: 6| Step: 6
Training loss: 1.7987496852874756
Validation loss: 2.0894897240464405

Epoch: 6| Step: 7
Training loss: 1.5953905582427979
Validation loss: 2.103142833196989

Epoch: 6| Step: 8
Training loss: 2.1825971603393555
Validation loss: 2.094522119850241

Epoch: 6| Step: 9
Training loss: 1.5314290523529053
Validation loss: 2.118624089866556

Epoch: 6| Step: 10
Training loss: 2.031125545501709
Validation loss: 2.1298282300272295

Epoch: 6| Step: 11
Training loss: 1.658475637435913
Validation loss: 2.1448561529959402

Epoch: 6| Step: 12
Training loss: 1.8156851530075073
Validation loss: 2.1229192441509617

Epoch: 6| Step: 13
Training loss: 2.5450167655944824
Validation loss: 2.1082694838123937

Epoch: 221| Step: 0
Training loss: 1.6336736679077148
Validation loss: 2.096549161018864

Epoch: 6| Step: 1
Training loss: 2.5817971229553223
Validation loss: 2.093898683465937

Epoch: 6| Step: 2
Training loss: 1.7063000202178955
Validation loss: 2.0978514814889557

Epoch: 6| Step: 3
Training loss: 2.1318373680114746
Validation loss: 2.0866463773994037

Epoch: 6| Step: 4
Training loss: 1.9290740489959717
Validation loss: 2.087270075275052

Epoch: 6| Step: 5
Training loss: 2.091550350189209
Validation loss: 2.0762022490142495

Epoch: 6| Step: 6
Training loss: 1.7686035633087158
Validation loss: 2.091343895081551

Epoch: 6| Step: 7
Training loss: 1.134940505027771
Validation loss: 2.0947511990865073

Epoch: 6| Step: 8
Training loss: 1.5795001983642578
Validation loss: 2.1082479466674147

Epoch: 6| Step: 9
Training loss: 2.3367910385131836
Validation loss: 2.1046288500549974

Epoch: 6| Step: 10
Training loss: 2.0033442974090576
Validation loss: 2.0787120147417952

Epoch: 6| Step: 11
Training loss: 1.8845016956329346
Validation loss: 2.0599222542137228

Epoch: 6| Step: 12
Training loss: 1.57967209815979
Validation loss: 2.0872750718106508

Epoch: 6| Step: 13
Training loss: 2.800466537475586
Validation loss: 2.0732841004607496

Epoch: 222| Step: 0
Training loss: 1.62054443359375
Validation loss: 2.0816991329193115

Epoch: 6| Step: 1
Training loss: 1.0017023086547852
Validation loss: 2.0999075058967835

Epoch: 6| Step: 2
Training loss: 1.9675017595291138
Validation loss: 2.090188689129327

Epoch: 6| Step: 3
Training loss: 2.1624388694763184
Validation loss: 2.0985160771236626

Epoch: 6| Step: 4
Training loss: 2.7928380966186523
Validation loss: 2.1050552821928457

Epoch: 6| Step: 5
Training loss: 2.0803475379943848
Validation loss: 2.120492871089648

Epoch: 6| Step: 6
Training loss: 1.7847559452056885
Validation loss: 2.116838038608592

Epoch: 6| Step: 7
Training loss: 2.1031880378723145
Validation loss: 2.1168533704614125

Epoch: 6| Step: 8
Training loss: 1.6077775955200195
Validation loss: 2.1158119324714906

Epoch: 6| Step: 9
Training loss: 2.0867674350738525
Validation loss: 2.1243296464284263

Epoch: 6| Step: 10
Training loss: 1.1901183128356934
Validation loss: 2.0876298668564006

Epoch: 6| Step: 11
Training loss: 1.5067980289459229
Validation loss: 2.1012329798872753

Epoch: 6| Step: 12
Training loss: 1.7209974527359009
Validation loss: 2.0879309074853056

Epoch: 6| Step: 13
Training loss: 2.9651880264282227
Validation loss: 2.0704758115994033

Epoch: 223| Step: 0
Training loss: 1.960054636001587
Validation loss: 2.082923464877631

Epoch: 6| Step: 1
Training loss: 1.680893898010254
Validation loss: 2.0840135120576426

Epoch: 6| Step: 2
Training loss: 2.121622323989868
Validation loss: 2.085874634404336

Epoch: 6| Step: 3
Training loss: 2.3110547065734863
Validation loss: 2.0844460943693757

Epoch: 6| Step: 4
Training loss: 1.9950082302093506
Validation loss: 2.0779278996170207

Epoch: 6| Step: 5
Training loss: 1.6509130001068115
Validation loss: 2.083777927583264

Epoch: 6| Step: 6
Training loss: 1.9822206497192383
Validation loss: 2.080096465285106

Epoch: 6| Step: 7
Training loss: 2.129328727722168
Validation loss: 2.0962267178361134

Epoch: 6| Step: 8
Training loss: 1.7025549411773682
Validation loss: 2.0959548924558904

Epoch: 6| Step: 9
Training loss: 2.226656436920166
Validation loss: 2.1031166545806395

Epoch: 6| Step: 10
Training loss: 1.5448554754257202
Validation loss: 2.1014667659677486

Epoch: 6| Step: 11
Training loss: 1.8334980010986328
Validation loss: 2.082794781654112

Epoch: 6| Step: 12
Training loss: 1.0058269500732422
Validation loss: 2.0882222421707644

Epoch: 6| Step: 13
Training loss: 1.9797990322113037
Validation loss: 2.0820539792378745

Epoch: 224| Step: 0
Training loss: 1.7339134216308594
Validation loss: 2.067537206475453

Epoch: 6| Step: 1
Training loss: 1.497133493423462
Validation loss: 2.0668301133699316

Epoch: 6| Step: 2
Training loss: 1.0530216693878174
Validation loss: 2.0691268097969795

Epoch: 6| Step: 3
Training loss: 1.9551780223846436
Validation loss: 2.0664374187428463

Epoch: 6| Step: 4
Training loss: 1.8502063751220703
Validation loss: 2.077342889642203

Epoch: 6| Step: 5
Training loss: 2.576416492462158
Validation loss: 2.0738504548226633

Epoch: 6| Step: 6
Training loss: 2.404374361038208
Validation loss: 2.077776126964118

Epoch: 6| Step: 7
Training loss: 1.960162878036499
Validation loss: 2.097831549183015

Epoch: 6| Step: 8
Training loss: 2.5002903938293457
Validation loss: 2.1090485716378815

Epoch: 6| Step: 9
Training loss: 0.8955528140068054
Validation loss: 2.1140483015327045

Epoch: 6| Step: 10
Training loss: 1.85317063331604
Validation loss: 2.0872653863763295

Epoch: 6| Step: 11
Training loss: 1.888575553894043
Validation loss: 2.0774826554841894

Epoch: 6| Step: 12
Training loss: 2.0434560775756836
Validation loss: 2.0988966829033306

Epoch: 6| Step: 13
Training loss: 1.7239712476730347
Validation loss: 2.0899733779250935

Epoch: 225| Step: 0
Training loss: 1.2741897106170654
Validation loss: 2.0840207838243052

Epoch: 6| Step: 1
Training loss: 2.2348031997680664
Validation loss: 2.0840569209027033

Epoch: 6| Step: 2
Training loss: 1.5736749172210693
Validation loss: 2.0779748591043616

Epoch: 6| Step: 3
Training loss: 2.629240036010742
Validation loss: 2.1110514492116947

Epoch: 6| Step: 4
Training loss: 2.080308437347412
Validation loss: 2.1001964435782483

Epoch: 6| Step: 5
Training loss: 1.5879756212234497
Validation loss: 2.1197776640615156

Epoch: 6| Step: 6
Training loss: 2.0515246391296387
Validation loss: 2.134682600216199

Epoch: 6| Step: 7
Training loss: 1.0045286417007446
Validation loss: 2.1345866675017984

Epoch: 6| Step: 8
Training loss: 2.389483690261841
Validation loss: 2.1416444598987536

Epoch: 6| Step: 9
Training loss: 1.9731992483139038
Validation loss: 2.110481664698611

Epoch: 6| Step: 10
Training loss: 2.00829815864563
Validation loss: 2.0879779708000923

Epoch: 6| Step: 11
Training loss: 2.4321770668029785
Validation loss: 2.0597964768768637

Epoch: 6| Step: 12
Training loss: 1.379155158996582
Validation loss: 2.06359254160235

Epoch: 6| Step: 13
Training loss: 1.1888576745986938
Validation loss: 2.0583263135725454

Epoch: 226| Step: 0
Training loss: 1.6965224742889404
Validation loss: 2.0789721140297512

Epoch: 6| Step: 1
Training loss: 2.2020583152770996
Validation loss: 2.0765022616232596

Epoch: 6| Step: 2
Training loss: 1.8599889278411865
Validation loss: 2.08393031807356

Epoch: 6| Step: 3
Training loss: 1.367701530456543
Validation loss: 2.092634436904743

Epoch: 6| Step: 4
Training loss: 1.8906325101852417
Validation loss: 2.090412562893283

Epoch: 6| Step: 5
Training loss: 2.3733909130096436
Validation loss: 2.0903739237016246

Epoch: 6| Step: 6
Training loss: 1.6196142435073853
Validation loss: 2.095130394863826

Epoch: 6| Step: 7
Training loss: 2.0610976219177246
Validation loss: 2.097528039768178

Epoch: 6| Step: 8
Training loss: 1.8522827625274658
Validation loss: 2.0921738711736535

Epoch: 6| Step: 9
Training loss: 2.0535428524017334
Validation loss: 2.06659883581182

Epoch: 6| Step: 10
Training loss: 1.9290953874588013
Validation loss: 2.0747216388743412

Epoch: 6| Step: 11
Training loss: 2.218318462371826
Validation loss: 2.0583509027317004

Epoch: 6| Step: 12
Training loss: 0.9628396034240723
Validation loss: 2.0474316714912333

Epoch: 6| Step: 13
Training loss: 2.079387903213501
Validation loss: 2.028586572216403

Epoch: 227| Step: 0
Training loss: 1.8166508674621582
Validation loss: 2.0325610599210187

Epoch: 6| Step: 1
Training loss: 1.869360327720642
Validation loss: 2.022717427181941

Epoch: 6| Step: 2
Training loss: 1.4309791326522827
Validation loss: 2.0219444562030096

Epoch: 6| Step: 3
Training loss: 0.764146625995636
Validation loss: 2.033942304631715

Epoch: 6| Step: 4
Training loss: 1.791519045829773
Validation loss: 2.0326192148270144

Epoch: 6| Step: 5
Training loss: 1.9991326332092285
Validation loss: 2.0351234430907876

Epoch: 6| Step: 6
Training loss: 2.0591509342193604
Validation loss: 2.0576592773519535

Epoch: 6| Step: 7
Training loss: 2.0062074661254883
Validation loss: 2.075301322885739

Epoch: 6| Step: 8
Training loss: 1.5992050170898438
Validation loss: 2.0761463424210906

Epoch: 6| Step: 9
Training loss: 2.511234760284424
Validation loss: 2.112532533625121

Epoch: 6| Step: 10
Training loss: 2.692093849182129
Validation loss: 2.1282969572210826

Epoch: 6| Step: 11
Training loss: 0.9992493391036987
Validation loss: 2.1438485294260006

Epoch: 6| Step: 12
Training loss: 2.039984703063965
Validation loss: 2.136700910906638

Epoch: 6| Step: 13
Training loss: 2.6841776371002197
Validation loss: 2.143777870362805

Epoch: 228| Step: 0
Training loss: 1.768283486366272
Validation loss: 2.1028919181516095

Epoch: 6| Step: 1
Training loss: 1.162832498550415
Validation loss: 2.0847266335641184

Epoch: 6| Step: 2
Training loss: 1.2877686023712158
Validation loss: 2.0679923065247072

Epoch: 6| Step: 3
Training loss: 2.4846301078796387
Validation loss: 2.0594340601275043

Epoch: 6| Step: 4
Training loss: 1.9858978986740112
Validation loss: 2.0570230740372852

Epoch: 6| Step: 5
Training loss: 1.8867002725601196
Validation loss: 2.0518939238722607

Epoch: 6| Step: 6
Training loss: 1.6802544593811035
Validation loss: 2.060534982271092

Epoch: 6| Step: 7
Training loss: 2.216916561126709
Validation loss: 2.0547634350356234

Epoch: 6| Step: 8
Training loss: 1.7545013427734375
Validation loss: 2.083454671726432

Epoch: 6| Step: 9
Training loss: 1.894497036933899
Validation loss: 2.076781911234702

Epoch: 6| Step: 10
Training loss: 2.030179738998413
Validation loss: 2.082471147660286

Epoch: 6| Step: 11
Training loss: 1.7751492261886597
Validation loss: 2.0998337102192703

Epoch: 6| Step: 12
Training loss: 2.1055819988250732
Validation loss: 2.1137678418108212

Epoch: 6| Step: 13
Training loss: 1.7364697456359863
Validation loss: 2.1232439125737836

Epoch: 229| Step: 0
Training loss: 1.6534922122955322
Validation loss: 2.1276552010607976

Epoch: 6| Step: 1
Training loss: 2.1743834018707275
Validation loss: 2.1325814903423352

Epoch: 6| Step: 2
Training loss: 2.7622008323669434
Validation loss: 2.1243270058785715

Epoch: 6| Step: 3
Training loss: 2.207498550415039
Validation loss: 2.1346035900936333

Epoch: 6| Step: 4
Training loss: 2.2277615070343018
Validation loss: 2.1102078499332553

Epoch: 6| Step: 5
Training loss: 1.3158708810806274
Validation loss: 2.090258267617995

Epoch: 6| Step: 6
Training loss: 1.9419348239898682
Validation loss: 2.0774236955950336

Epoch: 6| Step: 7
Training loss: 1.4837615489959717
Validation loss: 2.060053265222939

Epoch: 6| Step: 8
Training loss: 1.2875301837921143
Validation loss: 2.059303637473814

Epoch: 6| Step: 9
Training loss: 1.5304293632507324
Validation loss: 2.0634962999692528

Epoch: 6| Step: 10
Training loss: 1.494316577911377
Validation loss: 2.0626636474363265

Epoch: 6| Step: 11
Training loss: 2.470675230026245
Validation loss: 2.0620485198113228

Epoch: 6| Step: 12
Training loss: 1.791508436203003
Validation loss: 2.072000757340462

Epoch: 6| Step: 13
Training loss: 1.1466096639633179
Validation loss: 2.0582110189622447

Epoch: 230| Step: 0
Training loss: 1.6941847801208496
Validation loss: 2.0909787634367585

Epoch: 6| Step: 1
Training loss: 2.19281005859375
Validation loss: 2.112299398709369

Epoch: 6| Step: 2
Training loss: 2.100649833679199
Validation loss: 2.13775804222271

Epoch: 6| Step: 3
Training loss: 1.575270652770996
Validation loss: 2.1403316823385095

Epoch: 6| Step: 4
Training loss: 1.7870845794677734
Validation loss: 2.1387084735337125

Epoch: 6| Step: 5
Training loss: 1.902719259262085
Validation loss: 2.11667033421096

Epoch: 6| Step: 6
Training loss: 2.0251922607421875
Validation loss: 2.1151949077524166

Epoch: 6| Step: 7
Training loss: 2.3490209579467773
Validation loss: 2.1141602787920224

Epoch: 6| Step: 8
Training loss: 1.6837300062179565
Validation loss: 2.097932969370196

Epoch: 6| Step: 9
Training loss: 1.8811554908752441
Validation loss: 2.083942674821423

Epoch: 6| Step: 10
Training loss: 1.438315987586975
Validation loss: 2.0672722080702424

Epoch: 6| Step: 11
Training loss: 1.970313549041748
Validation loss: 2.0513009999388006

Epoch: 6| Step: 12
Training loss: 1.5507748126983643
Validation loss: 2.042808158423311

Epoch: 6| Step: 13
Training loss: 1.2962837219238281
Validation loss: 2.0405194682459675

Epoch: 231| Step: 0
Training loss: 1.831909418106079
Validation loss: 2.0510956933421474

Epoch: 6| Step: 1
Training loss: 1.7622038125991821
Validation loss: 2.050845420488747

Epoch: 6| Step: 2
Training loss: 1.6388636827468872
Validation loss: 2.0381132018181587

Epoch: 6| Step: 3
Training loss: 1.529517412185669
Validation loss: 2.0474617224867626

Epoch: 6| Step: 4
Training loss: 1.758545160293579
Validation loss: 2.0479718485186176

Epoch: 6| Step: 5
Training loss: 1.7670902013778687
Validation loss: 2.034419616063436

Epoch: 6| Step: 6
Training loss: 1.8597867488861084
Validation loss: 2.044292260241765

Epoch: 6| Step: 7
Training loss: 2.933223247528076
Validation loss: 2.0651086350922943

Epoch: 6| Step: 8
Training loss: 1.6293498277664185
Validation loss: 2.0765822651565715

Epoch: 6| Step: 9
Training loss: 2.353440999984741
Validation loss: 2.101508899401593

Epoch: 6| Step: 10
Training loss: 2.1535472869873047
Validation loss: 2.109396434599353

Epoch: 6| Step: 11
Training loss: 1.9969537258148193
Validation loss: 2.1365043834973405

Epoch: 6| Step: 12
Training loss: 1.1739858388900757
Validation loss: 2.1514804055613856

Epoch: 6| Step: 13
Training loss: 0.4732733964920044
Validation loss: 2.161498749127952

Epoch: 232| Step: 0
Training loss: 1.844943881034851
Validation loss: 2.1855806919836227

Epoch: 6| Step: 1
Training loss: 2.0188724994659424
Validation loss: 2.1879175170775382

Epoch: 6| Step: 2
Training loss: 1.6512670516967773
Validation loss: 2.200314280807331

Epoch: 6| Step: 3
Training loss: 2.448819637298584
Validation loss: 2.175769052197856

Epoch: 6| Step: 4
Training loss: 1.8256018161773682
Validation loss: 2.1528045490223873

Epoch: 6| Step: 5
Training loss: 1.6154019832611084
Validation loss: 2.112308338124265

Epoch: 6| Step: 6
Training loss: 1.997241497039795
Validation loss: 2.094150439385445

Epoch: 6| Step: 7
Training loss: 1.3643834590911865
Validation loss: 2.090717165700851

Epoch: 6| Step: 8
Training loss: 2.2557125091552734
Validation loss: 2.0996695769730436

Epoch: 6| Step: 9
Training loss: 1.5559585094451904
Validation loss: 2.083622524815221

Epoch: 6| Step: 10
Training loss: 1.472139835357666
Validation loss: 2.0570444304455995

Epoch: 6| Step: 11
Training loss: 1.642035961151123
Validation loss: 2.0591455531376663

Epoch: 6| Step: 12
Training loss: 2.5311131477355957
Validation loss: 2.034867284118488

Epoch: 6| Step: 13
Training loss: 1.341021180152893
Validation loss: 2.0498697437265867

Epoch: 233| Step: 0
Training loss: 2.661975145339966
Validation loss: 2.058942101335013

Epoch: 6| Step: 1
Training loss: 1.9469976425170898
Validation loss: 2.062448150368147

Epoch: 6| Step: 2
Training loss: 1.9609463214874268
Validation loss: 2.0321397037916284

Epoch: 6| Step: 3
Training loss: 1.5849090814590454
Validation loss: 2.019376362523725

Epoch: 6| Step: 4
Training loss: 1.2474374771118164
Validation loss: 2.0042679707209268

Epoch: 6| Step: 5
Training loss: 1.7430273294448853
Validation loss: 2.0225821336110434

Epoch: 6| Step: 6
Training loss: 1.5760548114776611
Validation loss: 2.029120235032933

Epoch: 6| Step: 7
Training loss: 2.180968999862671
Validation loss: 2.0563123841439523

Epoch: 6| Step: 8
Training loss: 1.4858570098876953
Validation loss: 2.0738976693922475

Epoch: 6| Step: 9
Training loss: 1.8315991163253784
Validation loss: 2.1160093174185803

Epoch: 6| Step: 10
Training loss: 1.7874562740325928
Validation loss: 2.130175264932776

Epoch: 6| Step: 11
Training loss: 1.9854968786239624
Validation loss: 2.1359444331097346

Epoch: 6| Step: 12
Training loss: 2.3794984817504883
Validation loss: 2.1471648754612094

Epoch: 6| Step: 13
Training loss: 0.5422417521476746
Validation loss: 2.146773289608699

Epoch: 234| Step: 0
Training loss: 1.250440001487732
Validation loss: 2.1391395394520094

Epoch: 6| Step: 1
Training loss: 2.177356481552124
Validation loss: 2.129493300632764

Epoch: 6| Step: 2
Training loss: 1.7640485763549805
Validation loss: 2.145047469805646

Epoch: 6| Step: 3
Training loss: 1.6259499788284302
Validation loss: 2.1239994879691833

Epoch: 6| Step: 4
Training loss: 1.7337833642959595
Validation loss: 2.1272046822373585

Epoch: 6| Step: 5
Training loss: 1.386134147644043
Validation loss: 2.1010003448814474

Epoch: 6| Step: 6
Training loss: 1.6800482273101807
Validation loss: 2.0965835535398094

Epoch: 6| Step: 7
Training loss: 1.8547420501708984
Validation loss: 2.1213111800532185

Epoch: 6| Step: 8
Training loss: 1.7610864639282227
Validation loss: 2.10978457748249

Epoch: 6| Step: 9
Training loss: 1.9046839475631714
Validation loss: 2.0893165667851767

Epoch: 6| Step: 10
Training loss: 2.1605730056762695
Validation loss: 2.0602003810226277

Epoch: 6| Step: 11
Training loss: 1.7219042778015137
Validation loss: 2.0465357713801886

Epoch: 6| Step: 12
Training loss: 2.0759899616241455
Validation loss: 2.037654274253435

Epoch: 6| Step: 13
Training loss: 2.191317081451416
Validation loss: 2.009161013428883

Epoch: 235| Step: 0
Training loss: 2.068498134613037
Validation loss: 2.0087250791570193

Epoch: 6| Step: 1
Training loss: 1.7570408582687378
Validation loss: 2.0132329592140774

Epoch: 6| Step: 2
Training loss: 2.283310890197754
Validation loss: 2.0275537403680945

Epoch: 6| Step: 3
Training loss: 2.018000364303589
Validation loss: 2.028309873355332

Epoch: 6| Step: 4
Training loss: 1.815877914428711
Validation loss: 2.0316273320105767

Epoch: 6| Step: 5
Training loss: 2.2549962997436523
Validation loss: 2.0421914874866443

Epoch: 6| Step: 6
Training loss: 1.3683836460113525
Validation loss: 2.067650123309064

Epoch: 6| Step: 7
Training loss: 1.7866507768630981
Validation loss: 2.0685924804338844

Epoch: 6| Step: 8
Training loss: 1.5600390434265137
Validation loss: 2.0682809147783505

Epoch: 6| Step: 9
Training loss: 2.0853798389434814
Validation loss: 2.0931597935256137

Epoch: 6| Step: 10
Training loss: 1.4631052017211914
Validation loss: 2.084684246329851

Epoch: 6| Step: 11
Training loss: 1.973428726196289
Validation loss: 2.086779773876231

Epoch: 6| Step: 12
Training loss: 1.4607219696044922
Validation loss: 2.0959646740267353

Epoch: 6| Step: 13
Training loss: 1.4336333274841309
Validation loss: 2.110301761217015

Epoch: 236| Step: 0
Training loss: 2.2863006591796875
Validation loss: 2.122442022446663

Epoch: 6| Step: 1
Training loss: 2.0357227325439453
Validation loss: 2.1099495785210722

Epoch: 6| Step: 2
Training loss: 1.8058300018310547
Validation loss: 2.1264846555648313

Epoch: 6| Step: 3
Training loss: 0.865282416343689
Validation loss: 2.1027867435127177

Epoch: 6| Step: 4
Training loss: 1.0249730348587036
Validation loss: 2.1107541591890397

Epoch: 6| Step: 5
Training loss: 1.5606436729431152
Validation loss: 2.1245711144580635

Epoch: 6| Step: 6
Training loss: 2.095122814178467
Validation loss: 2.104026391942014

Epoch: 6| Step: 7
Training loss: 2.397702217102051
Validation loss: 2.114985706985638

Epoch: 6| Step: 8
Training loss: 2.079404830932617
Validation loss: 2.1222265945967806

Epoch: 6| Step: 9
Training loss: 1.6741759777069092
Validation loss: 2.1027445062514274

Epoch: 6| Step: 10
Training loss: 1.9617056846618652
Validation loss: 2.0967668922998572

Epoch: 6| Step: 11
Training loss: 1.9427871704101562
Validation loss: 2.1140303304118495

Epoch: 6| Step: 12
Training loss: 1.5812535285949707
Validation loss: 2.0836332639058432

Epoch: 6| Step: 13
Training loss: 1.59165620803833
Validation loss: 2.084212041670276

Epoch: 237| Step: 0
Training loss: 1.279325246810913
Validation loss: 2.086724512038692

Epoch: 6| Step: 1
Training loss: 1.3698277473449707
Validation loss: 2.0983943426480858

Epoch: 6| Step: 2
Training loss: 2.0074386596679688
Validation loss: 2.090570772847822

Epoch: 6| Step: 3
Training loss: 1.8311336040496826
Validation loss: 2.069729058973251

Epoch: 6| Step: 4
Training loss: 2.6221375465393066
Validation loss: 2.0874968036528556

Epoch: 6| Step: 5
Training loss: 1.45139741897583
Validation loss: 2.0646439290815786

Epoch: 6| Step: 6
Training loss: 1.8955241441726685
Validation loss: 2.081441548562819

Epoch: 6| Step: 7
Training loss: 1.770902156829834
Validation loss: 2.0861203055227957

Epoch: 6| Step: 8
Training loss: 1.89002525806427
Validation loss: 2.0911898869340138

Epoch: 6| Step: 9
Training loss: 1.6579439640045166
Validation loss: 2.093656316880257

Epoch: 6| Step: 10
Training loss: 1.6002721786499023
Validation loss: 2.0975924089390743

Epoch: 6| Step: 11
Training loss: 2.068091630935669
Validation loss: 2.1041479674718713

Epoch: 6| Step: 12
Training loss: 1.5103347301483154
Validation loss: 2.1248606251132105

Epoch: 6| Step: 13
Training loss: 2.194790840148926
Validation loss: 2.104210622849003

Epoch: 238| Step: 0
Training loss: 2.4211173057556152
Validation loss: 2.119149551596693

Epoch: 6| Step: 1
Training loss: 1.9546058177947998
Validation loss: 2.121559352003118

Epoch: 6| Step: 2
Training loss: 1.5113935470581055
Validation loss: 2.1429168460189656

Epoch: 6| Step: 3
Training loss: 1.7907036542892456
Validation loss: 2.134121641036003

Epoch: 6| Step: 4
Training loss: 2.080061912536621
Validation loss: 2.146126752258629

Epoch: 6| Step: 5
Training loss: 1.6193132400512695
Validation loss: 2.125528274043914

Epoch: 6| Step: 6
Training loss: 1.7394585609436035
Validation loss: 2.1039345854072162

Epoch: 6| Step: 7
Training loss: 1.9441461563110352
Validation loss: 2.112890637049111

Epoch: 6| Step: 8
Training loss: 1.7114821672439575
Validation loss: 2.0769401455438263

Epoch: 6| Step: 9
Training loss: 1.1661864519119263
Validation loss: 2.080263385208704

Epoch: 6| Step: 10
Training loss: 1.407842993736267
Validation loss: 2.0546880588736585

Epoch: 6| Step: 11
Training loss: 2.085012435913086
Validation loss: 2.0441731868251676

Epoch: 6| Step: 12
Training loss: 1.523341178894043
Validation loss: 2.0529184956704416

Epoch: 6| Step: 13
Training loss: 2.1187219619750977
Validation loss: 2.0636931991064422

Epoch: 239| Step: 0
Training loss: 1.4258003234863281
Validation loss: 2.074998458226522

Epoch: 6| Step: 1
Training loss: 1.1901044845581055
Validation loss: 2.0984030513353247

Epoch: 6| Step: 2
Training loss: 2.407543182373047
Validation loss: 2.1010067796194427

Epoch: 6| Step: 3
Training loss: 1.5314528942108154
Validation loss: 2.132491450155935

Epoch: 6| Step: 4
Training loss: 1.5242352485656738
Validation loss: 2.1590558123844925

Epoch: 6| Step: 5
Training loss: 1.9213199615478516
Validation loss: 2.160441488348028

Epoch: 6| Step: 6
Training loss: 2.7378554344177246
Validation loss: 2.1712440675304783

Epoch: 6| Step: 7
Training loss: 2.0481185913085938
Validation loss: 2.158527079448905

Epoch: 6| Step: 8
Training loss: 1.787074327468872
Validation loss: 2.1763443075200564

Epoch: 6| Step: 9
Training loss: 1.657353162765503
Validation loss: 2.130399191251365

Epoch: 6| Step: 10
Training loss: 1.432429552078247
Validation loss: 2.1074553394830353

Epoch: 6| Step: 11
Training loss: 1.5339428186416626
Validation loss: 2.1123104146731797

Epoch: 6| Step: 12
Training loss: 1.806089997291565
Validation loss: 2.109982640512528

Epoch: 6| Step: 13
Training loss: 1.8589929342269897
Validation loss: 2.0904855292330504

Epoch: 240| Step: 0
Training loss: 1.4567508697509766
Validation loss: 2.088120952729256

Epoch: 6| Step: 1
Training loss: 1.2743654251098633
Validation loss: 2.071737092028382

Epoch: 6| Step: 2
Training loss: 1.4098948240280151
Validation loss: 2.1089056768724994

Epoch: 6| Step: 3
Training loss: 1.6232280731201172
Validation loss: 2.1100456304447626

Epoch: 6| Step: 4
Training loss: 1.980634331703186
Validation loss: 2.1180866020981983

Epoch: 6| Step: 5
Training loss: 1.9239240884780884
Validation loss: 2.116044516204506

Epoch: 6| Step: 6
Training loss: 2.306607961654663
Validation loss: 2.1110725018285934

Epoch: 6| Step: 7
Training loss: 1.7909374237060547
Validation loss: 2.119956909969289

Epoch: 6| Step: 8
Training loss: 1.3920583724975586
Validation loss: 2.091304212488154

Epoch: 6| Step: 9
Training loss: 1.437754511833191
Validation loss: 2.075696591408022

Epoch: 6| Step: 10
Training loss: 1.8057818412780762
Validation loss: 2.079989548652403

Epoch: 6| Step: 11
Training loss: 2.5489065647125244
Validation loss: 2.0833165235416864

Epoch: 6| Step: 12
Training loss: 2.0380654335021973
Validation loss: 2.07321818541455

Epoch: 6| Step: 13
Training loss: 2.0487301349639893
Validation loss: 2.084502811072975

Epoch: 241| Step: 0
Training loss: 1.2453433275222778
Validation loss: 2.079023366333336

Epoch: 6| Step: 1
Training loss: 1.5021452903747559
Validation loss: 2.05424746646676

Epoch: 6| Step: 2
Training loss: 1.7176649570465088
Validation loss: 2.0635650516838155

Epoch: 6| Step: 3
Training loss: 1.7688043117523193
Validation loss: 2.0602559299879175

Epoch: 6| Step: 4
Training loss: 1.487020492553711
Validation loss: 2.0408393644517466

Epoch: 6| Step: 5
Training loss: 1.5151869058609009
Validation loss: 2.075191310656968

Epoch: 6| Step: 6
Training loss: 2.0306012630462646
Validation loss: 2.0984290351149855

Epoch: 6| Step: 7
Training loss: 2.4456839561462402
Validation loss: 2.0992480272887857

Epoch: 6| Step: 8
Training loss: 1.8893346786499023
Validation loss: 2.0991465583924325

Epoch: 6| Step: 9
Training loss: 1.5849099159240723
Validation loss: 2.0915294154997794

Epoch: 6| Step: 10
Training loss: 2.000267267227173
Validation loss: 2.0949309743860716

Epoch: 6| Step: 11
Training loss: 1.7893061637878418
Validation loss: 2.0853777341945197

Epoch: 6| Step: 12
Training loss: 1.6986114978790283
Validation loss: 2.0825649371711155

Epoch: 6| Step: 13
Training loss: 2.080432415008545
Validation loss: 2.082733977225519

Epoch: 242| Step: 0
Training loss: 1.598609447479248
Validation loss: 2.081184500007219

Epoch: 6| Step: 1
Training loss: 2.2484755516052246
Validation loss: 2.078578410610076

Epoch: 6| Step: 2
Training loss: 2.129049301147461
Validation loss: 2.094955123880858

Epoch: 6| Step: 3
Training loss: 1.5964086055755615
Validation loss: 2.0973054721791256

Epoch: 6| Step: 4
Training loss: 1.4559056758880615
Validation loss: 2.0804194045323197

Epoch: 6| Step: 5
Training loss: 2.4270195960998535
Validation loss: 2.0688042589413222

Epoch: 6| Step: 6
Training loss: 1.1581730842590332
Validation loss: 2.0667673490380727

Epoch: 6| Step: 7
Training loss: 1.368640661239624
Validation loss: 2.073768020958029

Epoch: 6| Step: 8
Training loss: 2.604140281677246
Validation loss: 2.071641383632537

Epoch: 6| Step: 9
Training loss: 0.691832423210144
Validation loss: 2.0746244640760523

Epoch: 6| Step: 10
Training loss: 1.3353592157363892
Validation loss: 2.0631328013635453

Epoch: 6| Step: 11
Training loss: 2.005256175994873
Validation loss: 2.0544095680277836

Epoch: 6| Step: 12
Training loss: 1.7617037296295166
Validation loss: 2.050860643386841

Epoch: 6| Step: 13
Training loss: 2.2157089710235596
Validation loss: 2.0660011511977

Epoch: 243| Step: 0
Training loss: 1.798046350479126
Validation loss: 2.0695500745568225

Epoch: 6| Step: 1
Training loss: 1.5872236490249634
Validation loss: 2.066172247291893

Epoch: 6| Step: 2
Training loss: 1.7395644187927246
Validation loss: 2.0693399085793445

Epoch: 6| Step: 3
Training loss: 2.0448391437530518
Validation loss: 2.0689832061849613

Epoch: 6| Step: 4
Training loss: 1.9091947078704834
Validation loss: 2.0896640182823263

Epoch: 6| Step: 5
Training loss: 1.2528166770935059
Validation loss: 2.086727105161195

Epoch: 6| Step: 6
Training loss: 1.8963738679885864
Validation loss: 2.1076615369448097

Epoch: 6| Step: 7
Training loss: 1.6146743297576904
Validation loss: 2.122176049858011

Epoch: 6| Step: 8
Training loss: 2.0929436683654785
Validation loss: 2.093873252150833

Epoch: 6| Step: 9
Training loss: 0.934736430644989
Validation loss: 2.0898698209434428

Epoch: 6| Step: 10
Training loss: 2.1178712844848633
Validation loss: 2.089406969726727

Epoch: 6| Step: 11
Training loss: 1.6425379514694214
Validation loss: 2.1199806774816206

Epoch: 6| Step: 12
Training loss: 1.75714111328125
Validation loss: 2.0975852409998574

Epoch: 6| Step: 13
Training loss: 2.0611321926116943
Validation loss: 2.080482026582123

Epoch: 244| Step: 0
Training loss: 1.7293585538864136
Validation loss: 2.072988725477649

Epoch: 6| Step: 1
Training loss: 1.4078192710876465
Validation loss: 2.0719171903466664

Epoch: 6| Step: 2
Training loss: 1.8332358598709106
Validation loss: 2.061203484894127

Epoch: 6| Step: 3
Training loss: 2.092952251434326
Validation loss: 2.079539878394014

Epoch: 6| Step: 4
Training loss: 1.6306517124176025
Validation loss: 2.053022438480008

Epoch: 6| Step: 5
Training loss: 1.7367947101593018
Validation loss: 2.070388958018313

Epoch: 6| Step: 6
Training loss: 1.895779013633728
Validation loss: 2.0957450892335627

Epoch: 6| Step: 7
Training loss: 1.650166392326355
Validation loss: 2.094316920926494

Epoch: 6| Step: 8
Training loss: 0.6437243819236755
Validation loss: 2.108736579136182

Epoch: 6| Step: 9
Training loss: 1.5912325382232666
Validation loss: 2.1264526677388016

Epoch: 6| Step: 10
Training loss: 1.8383033275604248
Validation loss: 2.1419710882248415

Epoch: 6| Step: 11
Training loss: 2.556551456451416
Validation loss: 2.1270722471257693

Epoch: 6| Step: 12
Training loss: 1.134047269821167
Validation loss: 2.1402759346910702

Epoch: 6| Step: 13
Training loss: 2.9833688735961914
Validation loss: 2.142160084939772

Epoch: 245| Step: 0
Training loss: 2.1710562705993652
Validation loss: 2.1175979824476343

Epoch: 6| Step: 1
Training loss: 1.6698191165924072
Validation loss: 2.129944145038564

Epoch: 6| Step: 2
Training loss: 1.2903459072113037
Validation loss: 2.11234184234373

Epoch: 6| Step: 3
Training loss: 2.202674388885498
Validation loss: 2.09686799715924

Epoch: 6| Step: 4
Training loss: 1.6569305658340454
Validation loss: 2.075247985060497

Epoch: 6| Step: 5
Training loss: 1.1049968004226685
Validation loss: 2.0477712923480618

Epoch: 6| Step: 6
Training loss: 1.4967422485351562
Validation loss: 2.0571847705430883

Epoch: 6| Step: 7
Training loss: 1.4622383117675781
Validation loss: 2.0534749184885333

Epoch: 6| Step: 8
Training loss: 2.1104960441589355
Validation loss: 2.074129109741539

Epoch: 6| Step: 9
Training loss: 2.1970748901367188
Validation loss: 2.110349678224133

Epoch: 6| Step: 10
Training loss: 1.5838406085968018
Validation loss: 2.109256907175946

Epoch: 6| Step: 11
Training loss: 1.9066376686096191
Validation loss: 2.1457629434524046

Epoch: 6| Step: 12
Training loss: 1.3024225234985352
Validation loss: 2.1519361567753617

Epoch: 6| Step: 13
Training loss: 2.378751754760742
Validation loss: 2.132657625341928

Epoch: 246| Step: 0
Training loss: 1.5643038749694824
Validation loss: 2.125203340284286

Epoch: 6| Step: 1
Training loss: 2.0411276817321777
Validation loss: 2.1171454460390153

Epoch: 6| Step: 2
Training loss: 1.6620267629623413
Validation loss: 2.1282540239313597

Epoch: 6| Step: 3
Training loss: 1.9931637048721313
Validation loss: 2.0996816953023276

Epoch: 6| Step: 4
Training loss: 2.38992977142334
Validation loss: 2.09981781436551

Epoch: 6| Step: 5
Training loss: 1.9947227239608765
Validation loss: 2.075633846303468

Epoch: 6| Step: 6
Training loss: 1.8721715211868286
Validation loss: 2.0956229612391484

Epoch: 6| Step: 7
Training loss: 1.9950352907180786
Validation loss: 2.092448995959374

Epoch: 6| Step: 8
Training loss: 1.1786128282546997
Validation loss: 2.0949072120010213

Epoch: 6| Step: 9
Training loss: 1.238797664642334
Validation loss: 2.096776044496926

Epoch: 6| Step: 10
Training loss: 1.331444501876831
Validation loss: 2.0932787336328977

Epoch: 6| Step: 11
Training loss: 1.4972949028015137
Validation loss: 2.1080897264583136

Epoch: 6| Step: 12
Training loss: 1.5684443712234497
Validation loss: 2.095619104241812

Epoch: 6| Step: 13
Training loss: 1.5117911100387573
Validation loss: 2.114104287598723

Epoch: 247| Step: 0
Training loss: 1.8066811561584473
Validation loss: 2.1263013206502444

Epoch: 6| Step: 1
Training loss: 2.104799270629883
Validation loss: 2.1502591845809773

Epoch: 6| Step: 2
Training loss: 1.1663100719451904
Validation loss: 2.150125639412993

Epoch: 6| Step: 3
Training loss: 1.3027873039245605
Validation loss: 2.112995837324409

Epoch: 6| Step: 4
Training loss: 1.3091464042663574
Validation loss: 2.0902285281048028

Epoch: 6| Step: 5
Training loss: 1.593538761138916
Validation loss: 2.0843894558568157

Epoch: 6| Step: 6
Training loss: 1.7151105403900146
Validation loss: 2.0810640973429524

Epoch: 6| Step: 7
Training loss: 1.550567388534546
Validation loss: 2.0736558411711004

Epoch: 6| Step: 8
Training loss: 2.2602086067199707
Validation loss: 2.0720640536277526

Epoch: 6| Step: 9
Training loss: 1.4936699867248535
Validation loss: 2.095342113125709

Epoch: 6| Step: 10
Training loss: 2.0334558486938477
Validation loss: 2.0972383535036476

Epoch: 6| Step: 11
Training loss: 1.9371706247329712
Validation loss: 2.099420505185281

Epoch: 6| Step: 12
Training loss: 1.4723317623138428
Validation loss: 2.103057448581983

Epoch: 6| Step: 13
Training loss: 2.69599986076355
Validation loss: 2.143666828832319

Epoch: 248| Step: 0
Training loss: 1.1992809772491455
Validation loss: 2.123836976225658

Epoch: 6| Step: 1
Training loss: 2.2040841579437256
Validation loss: 2.1517440272915747

Epoch: 6| Step: 2
Training loss: 1.9955312013626099
Validation loss: 2.1506794242448706

Epoch: 6| Step: 3
Training loss: 1.5581588745117188
Validation loss: 2.146079135197465

Epoch: 6| Step: 4
Training loss: 1.3131129741668701
Validation loss: 2.146129633790703

Epoch: 6| Step: 5
Training loss: 1.272946834564209
Validation loss: 2.1450670380746164

Epoch: 6| Step: 6
Training loss: 2.1980676651000977
Validation loss: 2.1647363452501196

Epoch: 6| Step: 7
Training loss: 1.9077324867248535
Validation loss: 2.1612590282194075

Epoch: 6| Step: 8
Training loss: 2.269418478012085
Validation loss: 2.151628223798608

Epoch: 6| Step: 9
Training loss: 1.1875975131988525
Validation loss: 2.1405892961768695

Epoch: 6| Step: 10
Training loss: 2.0824320316314697
Validation loss: 2.1095365606328493

Epoch: 6| Step: 11
Training loss: 1.8326226472854614
Validation loss: 2.078054112772788

Epoch: 6| Step: 12
Training loss: 1.2631921768188477
Validation loss: 2.0798017337758052

Epoch: 6| Step: 13
Training loss: 1.3393884897232056
Validation loss: 2.090398616688226

Epoch: 249| Step: 0
Training loss: 1.6044785976409912
Validation loss: 2.0688271343067126

Epoch: 6| Step: 1
Training loss: 1.588993787765503
Validation loss: 2.090089190390802

Epoch: 6| Step: 2
Training loss: 1.4589529037475586
Validation loss: 2.1279902163372246

Epoch: 6| Step: 3
Training loss: 3.062321186065674
Validation loss: 2.1247570565951768

Epoch: 6| Step: 4
Training loss: 1.439732551574707
Validation loss: 2.1338344389392483

Epoch: 6| Step: 5
Training loss: 1.5542614459991455
Validation loss: 2.124613808047387

Epoch: 6| Step: 6
Training loss: 1.7120682001113892
Validation loss: 2.125432565648069

Epoch: 6| Step: 7
Training loss: 1.0122827291488647
Validation loss: 2.1702552328827562

Epoch: 6| Step: 8
Training loss: 1.6158729791641235
Validation loss: 2.1693927472637546

Epoch: 6| Step: 9
Training loss: 0.8623976111412048
Validation loss: 2.1645233502952

Epoch: 6| Step: 10
Training loss: 1.2887314558029175
Validation loss: 2.1534949348818873

Epoch: 6| Step: 11
Training loss: 2.1879773139953613
Validation loss: 2.117497208297894

Epoch: 6| Step: 12
Training loss: 2.392369031906128
Validation loss: 2.1188307910837154

Epoch: 6| Step: 13
Training loss: 2.1102447509765625
Validation loss: 2.1110962731863863

Epoch: 250| Step: 0
Training loss: 1.8165862560272217
Validation loss: 2.081361828311797

Epoch: 6| Step: 1
Training loss: 1.9078387022018433
Validation loss: 2.073214574526715

Epoch: 6| Step: 2
Training loss: 1.9049499034881592
Validation loss: 2.0522037500976236

Epoch: 6| Step: 3
Training loss: 1.4789671897888184
Validation loss: 2.032515388663097

Epoch: 6| Step: 4
Training loss: 1.471198558807373
Validation loss: 2.053487391882045

Epoch: 6| Step: 5
Training loss: 1.4525444507598877
Validation loss: 2.0337329654283423

Epoch: 6| Step: 6
Training loss: 0.8134142160415649
Validation loss: 2.0630022582187446

Epoch: 6| Step: 7
Training loss: 2.521261215209961
Validation loss: 2.066152480340773

Epoch: 6| Step: 8
Training loss: 1.562951922416687
Validation loss: 2.0660131246812883

Epoch: 6| Step: 9
Training loss: 1.7291704416275024
Validation loss: 2.065399703159127

Epoch: 6| Step: 10
Training loss: 1.6715812683105469
Validation loss: 2.079162900165845

Epoch: 6| Step: 11
Training loss: 1.2932413816452026
Validation loss: 2.0809374522137385

Epoch: 6| Step: 12
Training loss: 2.258577823638916
Validation loss: 2.0758031158037085

Epoch: 6| Step: 13
Training loss: 1.461519479751587
Validation loss: 2.0895375769625426

Epoch: 251| Step: 0
Training loss: 1.3111371994018555
Validation loss: 2.098207837791853

Epoch: 6| Step: 1
Training loss: 1.7531205415725708
Validation loss: 2.1176277822063816

Epoch: 6| Step: 2
Training loss: 2.0216622352600098
Validation loss: 2.1072343767330213

Epoch: 6| Step: 3
Training loss: 1.875844955444336
Validation loss: 2.098642594070845

Epoch: 6| Step: 4
Training loss: 2.2786312103271484
Validation loss: 2.07862324612115

Epoch: 6| Step: 5
Training loss: 1.5394587516784668
Validation loss: 2.0922593608979256

Epoch: 6| Step: 6
Training loss: 2.2122318744659424
Validation loss: 2.1124495998505624

Epoch: 6| Step: 7
Training loss: 1.491144061088562
Validation loss: 2.099838928509784

Epoch: 6| Step: 8
Training loss: 1.5922210216522217
Validation loss: 2.1159852832876225

Epoch: 6| Step: 9
Training loss: 1.2660194635391235
Validation loss: 2.097338696961762

Epoch: 6| Step: 10
Training loss: 1.558764934539795
Validation loss: 2.1225103485968804

Epoch: 6| Step: 11
Training loss: 1.253251314163208
Validation loss: 2.12005050464343

Epoch: 6| Step: 12
Training loss: 1.940916657447815
Validation loss: 2.0919683723039526

Epoch: 6| Step: 13
Training loss: 0.6158134341239929
Validation loss: 2.0829969913728776

Epoch: 252| Step: 0
Training loss: 1.3257144689559937
Validation loss: 2.0753990552758657

Epoch: 6| Step: 1
Training loss: 1.733757734298706
Validation loss: 2.080728538574711

Epoch: 6| Step: 2
Training loss: 2.1084704399108887
Validation loss: 2.0982338484897407

Epoch: 6| Step: 3
Training loss: 1.5543889999389648
Validation loss: 2.1061417402759677

Epoch: 6| Step: 4
Training loss: 1.2808678150177002
Validation loss: 2.1034117949906217

Epoch: 6| Step: 5
Training loss: 2.236640453338623
Validation loss: 2.116690371626167

Epoch: 6| Step: 6
Training loss: 1.9939539432525635
Validation loss: 2.139905696274132

Epoch: 6| Step: 7
Training loss: 1.1755677461624146
Validation loss: 2.173725019219101

Epoch: 6| Step: 8
Training loss: 1.4114006757736206
Validation loss: 2.1656092905229136

Epoch: 6| Step: 9
Training loss: 1.7337037324905396
Validation loss: 2.1802156561164447

Epoch: 6| Step: 10
Training loss: 1.8299298286437988
Validation loss: 2.1723118494915705

Epoch: 6| Step: 11
Training loss: 1.8517242670059204
Validation loss: 2.1473591250758015

Epoch: 6| Step: 12
Training loss: 1.079388976097107
Validation loss: 2.1356585666697514

Epoch: 6| Step: 13
Training loss: 2.0670650005340576
Validation loss: 2.1356927246175785

Epoch: 253| Step: 0
Training loss: 1.85420560836792
Validation loss: 2.1145734786987305

Epoch: 6| Step: 1
Training loss: 1.3530781269073486
Validation loss: 2.0883498422561155

Epoch: 6| Step: 2
Training loss: 1.6126041412353516
Validation loss: 2.094723624567832

Epoch: 6| Step: 3
Training loss: 2.30088472366333
Validation loss: 2.0915120814436223

Epoch: 6| Step: 4
Training loss: 1.8923841714859009
Validation loss: 2.100675718758696

Epoch: 6| Step: 5
Training loss: 1.8331583738327026
Validation loss: 2.1197044105939966

Epoch: 6| Step: 6
Training loss: 1.3943254947662354
Validation loss: 2.118154917993853

Epoch: 6| Step: 7
Training loss: 1.562487006187439
Validation loss: 2.122424215398809

Epoch: 6| Step: 8
Training loss: 1.332519292831421
Validation loss: 2.134533595013362

Epoch: 6| Step: 9
Training loss: 1.2848000526428223
Validation loss: 2.145845038916475

Epoch: 6| Step: 10
Training loss: 1.5761518478393555
Validation loss: 2.1312519555450766

Epoch: 6| Step: 11
Training loss: 1.0037317276000977
Validation loss: 2.110795021057129

Epoch: 6| Step: 12
Training loss: 1.978675127029419
Validation loss: 2.1010859140785794

Epoch: 6| Step: 13
Training loss: 2.367138385772705
Validation loss: 2.0930456922900293

Epoch: 254| Step: 0
Training loss: 2.2707529067993164
Validation loss: 2.072089286260707

Epoch: 6| Step: 1
Training loss: 1.3281649351119995
Validation loss: 2.065050217413133

Epoch: 6| Step: 2
Training loss: 1.6399672031402588
Validation loss: 2.0514721716603925

Epoch: 6| Step: 3
Training loss: 1.4127905368804932
Validation loss: 2.068291491077792

Epoch: 6| Step: 4
Training loss: 1.549456238746643
Validation loss: 2.08899349294683

Epoch: 6| Step: 5
Training loss: 1.2349387407302856
Validation loss: 2.1070898168830463

Epoch: 6| Step: 6
Training loss: 1.6993498802185059
Validation loss: 2.1108826706486363

Epoch: 6| Step: 7
Training loss: 2.2879867553710938
Validation loss: 2.140272194339383

Epoch: 6| Step: 8
Training loss: 1.350826382637024
Validation loss: 2.1387331357566257

Epoch: 6| Step: 9
Training loss: 1.6457006931304932
Validation loss: 2.1363825041760682

Epoch: 6| Step: 10
Training loss: 1.5883127450942993
Validation loss: 2.1413517446928125

Epoch: 6| Step: 11
Training loss: 2.195617437362671
Validation loss: 2.128829530490342

Epoch: 6| Step: 12
Training loss: 1.4637680053710938
Validation loss: 2.106661488932948

Epoch: 6| Step: 13
Training loss: 1.1998298168182373
Validation loss: 2.097663812739875

Epoch: 255| Step: 0
Training loss: 2.195209503173828
Validation loss: 2.0877986749013266

Epoch: 6| Step: 1
Training loss: 2.0471248626708984
Validation loss: 2.045980886746478

Epoch: 6| Step: 2
Training loss: 1.6063319444656372
Validation loss: 2.0351353383833364

Epoch: 6| Step: 3
Training loss: 1.6825344562530518
Validation loss: 2.0277876495033182

Epoch: 6| Step: 4
Training loss: 1.0480948686599731
Validation loss: 2.0336542180789414

Epoch: 6| Step: 5
Training loss: 1.6452821493148804
Validation loss: 2.0546343467568837

Epoch: 6| Step: 6
Training loss: 1.173651933670044
Validation loss: 2.0653115203303676

Epoch: 6| Step: 7
Training loss: 1.839524269104004
Validation loss: 2.1219780163098405

Epoch: 6| Step: 8
Training loss: 1.6287167072296143
Validation loss: 2.1211513268050326

Epoch: 6| Step: 9
Training loss: 1.9894882440567017
Validation loss: 2.154272989560199

Epoch: 6| Step: 10
Training loss: 1.3630859851837158
Validation loss: 2.1489557168817006

Epoch: 6| Step: 11
Training loss: 1.469961404800415
Validation loss: 2.170441360883815

Epoch: 6| Step: 12
Training loss: 1.829171061515808
Validation loss: 2.1557743164800827

Epoch: 6| Step: 13
Training loss: 1.3272016048431396
Validation loss: 2.179745375469167

Epoch: 256| Step: 0
Training loss: 1.261212706565857
Validation loss: 2.1446287042351178

Epoch: 6| Step: 1
Training loss: 1.1746914386749268
Validation loss: 2.1284566951054398

Epoch: 6| Step: 2
Training loss: 1.4759716987609863
Validation loss: 2.098796280481482

Epoch: 6| Step: 3
Training loss: 1.7426750659942627
Validation loss: 2.094297521857805

Epoch: 6| Step: 4
Training loss: 1.6692090034484863
Validation loss: 2.056039341034428

Epoch: 6| Step: 5
Training loss: 1.1801306009292603
Validation loss: 2.056979779274233

Epoch: 6| Step: 6
Training loss: 2.361438751220703
Validation loss: 2.0555728699571345

Epoch: 6| Step: 7
Training loss: 1.943065881729126
Validation loss: 2.05979916357225

Epoch: 6| Step: 8
Training loss: 2.0120930671691895
Validation loss: 2.0626573665167696

Epoch: 6| Step: 9
Training loss: 1.906714916229248
Validation loss: 2.092122754743022

Epoch: 6| Step: 10
Training loss: 1.2211204767227173
Validation loss: 2.0791368305042224

Epoch: 6| Step: 11
Training loss: 1.5236504077911377
Validation loss: 2.089874582905923

Epoch: 6| Step: 12
Training loss: 1.7407820224761963
Validation loss: 2.0984427211105183

Epoch: 6| Step: 13
Training loss: 1.0109316110610962
Validation loss: 2.1333139455446632

Epoch: 257| Step: 0
Training loss: 1.4594444036483765
Validation loss: 2.136217014763945

Epoch: 6| Step: 1
Training loss: 1.20167875289917
Validation loss: 2.1302026189783567

Epoch: 6| Step: 2
Training loss: 1.2724343538284302
Validation loss: 2.123656226742652

Epoch: 6| Step: 3
Training loss: 1.9882333278656006
Validation loss: 2.147772127582181

Epoch: 6| Step: 4
Training loss: 1.3552377223968506
Validation loss: 2.134860933467906

Epoch: 6| Step: 5
Training loss: 1.000319480895996
Validation loss: 2.11649997772709

Epoch: 6| Step: 6
Training loss: 1.2762501239776611
Validation loss: 2.1116548481807915

Epoch: 6| Step: 7
Training loss: 1.126446008682251
Validation loss: 2.1447831584561254

Epoch: 6| Step: 8
Training loss: 2.069304943084717
Validation loss: 2.123998483022054

Epoch: 6| Step: 9
Training loss: 1.9311577081680298
Validation loss: 2.165524591681778

Epoch: 6| Step: 10
Training loss: 2.1861090660095215
Validation loss: 2.1564381609680834

Epoch: 6| Step: 11
Training loss: 1.8263801336288452
Validation loss: 2.173598048507526

Epoch: 6| Step: 12
Training loss: 2.120911121368408
Validation loss: 2.1507270771970033

Epoch: 6| Step: 13
Training loss: 2.002115488052368
Validation loss: 2.132760073549004

Epoch: 258| Step: 0
Training loss: 1.8153854608535767
Validation loss: 2.087456243012541

Epoch: 6| Step: 1
Training loss: 1.5396416187286377
Validation loss: 2.081214459993506

Epoch: 6| Step: 2
Training loss: 1.3211445808410645
Validation loss: 2.050912512245999

Epoch: 6| Step: 3
Training loss: 1.4821857213974
Validation loss: 2.064008141076693

Epoch: 6| Step: 4
Training loss: 1.160646915435791
Validation loss: 2.0623081589257843

Epoch: 6| Step: 5
Training loss: 1.560126543045044
Validation loss: 2.0784315498926307

Epoch: 6| Step: 6
Training loss: 1.08359694480896
Validation loss: 2.0760418112559984

Epoch: 6| Step: 7
Training loss: 2.3433890342712402
Validation loss: 2.1147472012427544

Epoch: 6| Step: 8
Training loss: 2.2835774421691895
Validation loss: 2.098036899361559

Epoch: 6| Step: 9
Training loss: 1.9191792011260986
Validation loss: 2.1065170611104658

Epoch: 6| Step: 10
Training loss: 1.749737024307251
Validation loss: 2.110986696776523

Epoch: 6| Step: 11
Training loss: 0.8535479307174683
Validation loss: 2.110721917562587

Epoch: 6| Step: 12
Training loss: 1.742997169494629
Validation loss: 2.1003924505684965

Epoch: 6| Step: 13
Training loss: 1.8703645467758179
Validation loss: 2.082496799448485

Epoch: 259| Step: 0
Training loss: 1.6571999788284302
Validation loss: 2.079212724521596

Epoch: 6| Step: 1
Training loss: 1.4874887466430664
Validation loss: 2.0942159057945333

Epoch: 6| Step: 2
Training loss: 0.975045919418335
Validation loss: 2.095720006573585

Epoch: 6| Step: 3
Training loss: 1.8925247192382812
Validation loss: 2.1069460645798714

Epoch: 6| Step: 4
Training loss: 1.7555322647094727
Validation loss: 2.1139627284901117

Epoch: 6| Step: 5
Training loss: 1.833996295928955
Validation loss: 2.122758403901131

Epoch: 6| Step: 6
Training loss: 1.830739974975586
Validation loss: 2.0965552817108812

Epoch: 6| Step: 7
Training loss: 1.5224206447601318
Validation loss: 2.0822620468754924

Epoch: 6| Step: 8
Training loss: 1.9135410785675049
Validation loss: 2.0770993566000335

Epoch: 6| Step: 9
Training loss: 1.472082257270813
Validation loss: 2.0741759115649807

Epoch: 6| Step: 10
Training loss: 1.433762788772583
Validation loss: 2.072751893792101

Epoch: 6| Step: 11
Training loss: 1.6522045135498047
Validation loss: 2.117616207368912

Epoch: 6| Step: 12
Training loss: 1.097996473312378
Validation loss: 2.117987953206544

Epoch: 6| Step: 13
Training loss: 1.84873628616333
Validation loss: 2.122797296893212

Epoch: 260| Step: 0
Training loss: 2.3562262058258057
Validation loss: 2.1280612561010543

Epoch: 6| Step: 1
Training loss: 1.957247018814087
Validation loss: 2.1300611803608556

Epoch: 6| Step: 2
Training loss: 1.534123420715332
Validation loss: 2.1257649826747116

Epoch: 6| Step: 3
Training loss: 1.6506249904632568
Validation loss: 2.103860878175305

Epoch: 6| Step: 4
Training loss: 1.7974271774291992
Validation loss: 2.0869370070836877

Epoch: 6| Step: 5
Training loss: 1.2349978685379028
Validation loss: 2.0601763122825214

Epoch: 6| Step: 6
Training loss: 1.230044960975647
Validation loss: 2.064268744120034

Epoch: 6| Step: 7
Training loss: 1.0451176166534424
Validation loss: 2.0621174894353396

Epoch: 6| Step: 8
Training loss: 1.1942315101623535
Validation loss: 2.0430416868579004

Epoch: 6| Step: 9
Training loss: 1.1819792985916138
Validation loss: 2.047506240106398

Epoch: 6| Step: 10
Training loss: 2.020836353302002
Validation loss: 2.0452528961243166

Epoch: 6| Step: 11
Training loss: 1.8248039484024048
Validation loss: 2.067262787972727

Epoch: 6| Step: 12
Training loss: 1.324357032775879
Validation loss: 2.093882781203075

Epoch: 6| Step: 13
Training loss: 1.8520753383636475
Validation loss: 2.110200184647755

Epoch: 261| Step: 0
Training loss: 1.4970512390136719
Validation loss: 2.151457013622407

Epoch: 6| Step: 1
Training loss: 2.2328383922576904
Validation loss: 2.1738251268222766

Epoch: 6| Step: 2
Training loss: 1.1302164793014526
Validation loss: 2.180631355572772

Epoch: 6| Step: 3
Training loss: 1.5524152517318726
Validation loss: 2.1577396136458202

Epoch: 6| Step: 4
Training loss: 1.3743669986724854
Validation loss: 2.1244406495043027

Epoch: 6| Step: 5
Training loss: 0.9241091012954712
Validation loss: 2.1004522231317337

Epoch: 6| Step: 6
Training loss: 1.756800651550293
Validation loss: 2.0843897250390824

Epoch: 6| Step: 7
Training loss: 1.8429920673370361
Validation loss: 2.066334648798871

Epoch: 6| Step: 8
Training loss: 2.1290178298950195
Validation loss: 2.0643377868078088

Epoch: 6| Step: 9
Training loss: 1.8881759643554688
Validation loss: 2.051735439608174

Epoch: 6| Step: 10
Training loss: 1.598515272140503
Validation loss: 2.052065676258456

Epoch: 6| Step: 11
Training loss: 1.7888257503509521
Validation loss: 2.0387105223953084

Epoch: 6| Step: 12
Training loss: 1.408017635345459
Validation loss: 2.0877394881299747

Epoch: 6| Step: 13
Training loss: 1.328538417816162
Validation loss: 2.095525359594694

Epoch: 262| Step: 0
Training loss: 1.968920111656189
Validation loss: 2.122208636294129

Epoch: 6| Step: 1
Training loss: 1.988925814628601
Validation loss: 2.1311399885403213

Epoch: 6| Step: 2
Training loss: 1.8923070430755615
Validation loss: 2.1186876784088793

Epoch: 6| Step: 3
Training loss: 1.4838985204696655
Validation loss: 2.137403211285991

Epoch: 6| Step: 4
Training loss: 1.2577770948410034
Validation loss: 2.1120512100958053

Epoch: 6| Step: 5
Training loss: 1.7520418167114258
Validation loss: 2.091496936736568

Epoch: 6| Step: 6
Training loss: 1.5775984525680542
Validation loss: 2.100661959699405

Epoch: 6| Step: 7
Training loss: 1.0378843545913696
Validation loss: 2.0900769464431272

Epoch: 6| Step: 8
Training loss: 2.023327350616455
Validation loss: 2.1078813665656635

Epoch: 6| Step: 9
Training loss: 1.7804354429244995
Validation loss: 2.1128127741557297

Epoch: 6| Step: 10
Training loss: 1.0457563400268555
Validation loss: 2.1023101960459063

Epoch: 6| Step: 11
Training loss: 0.6752706170082092
Validation loss: 2.0963317373747468

Epoch: 6| Step: 12
Training loss: 1.697728157043457
Validation loss: 2.1217766192651566

Epoch: 6| Step: 13
Training loss: 2.098409652709961
Validation loss: 2.126617826441283

Epoch: 263| Step: 0
Training loss: 1.6324372291564941
Validation loss: 2.097557847217847

Epoch: 6| Step: 1
Training loss: 1.6706445217132568
Validation loss: 2.1081891931513304

Epoch: 6| Step: 2
Training loss: 1.5316205024719238
Validation loss: 2.0428548679556897

Epoch: 6| Step: 3
Training loss: 1.1784965991973877
Validation loss: 2.0340080722685783

Epoch: 6| Step: 4
Training loss: 1.5517759323120117
Validation loss: 2.0424334105624946

Epoch: 6| Step: 5
Training loss: 0.9750837683677673
Validation loss: 2.0483531900631484

Epoch: 6| Step: 6
Training loss: 1.573347568511963
Validation loss: 2.061427470176451

Epoch: 6| Step: 7
Training loss: 1.8986022472381592
Validation loss: 2.0532064399411603

Epoch: 6| Step: 8
Training loss: 1.4206352233886719
Validation loss: 2.0786827200202533

Epoch: 6| Step: 9
Training loss: 1.6123735904693604
Validation loss: 2.0854744821466427

Epoch: 6| Step: 10
Training loss: 1.6055148839950562
Validation loss: 2.138464717454808

Epoch: 6| Step: 11
Training loss: 1.6445786952972412
Validation loss: 2.1519291221454577

Epoch: 6| Step: 12
Training loss: 2.0707578659057617
Validation loss: 2.182019607995146

Epoch: 6| Step: 13
Training loss: 1.5862916707992554
Validation loss: 2.157997062129359

Epoch: 264| Step: 0
Training loss: 2.167372703552246
Validation loss: 2.150424047182965

Epoch: 6| Step: 1
Training loss: 0.8771535754203796
Validation loss: 2.169126861838884

Epoch: 6| Step: 2
Training loss: 1.6290287971496582
Validation loss: 2.1663749756351596

Epoch: 6| Step: 3
Training loss: 1.138530969619751
Validation loss: 2.1119076475020377

Epoch: 6| Step: 4
Training loss: 1.615016222000122
Validation loss: 2.0846817660075363

Epoch: 6| Step: 5
Training loss: 1.4399670362472534
Validation loss: 2.0569768592875493

Epoch: 6| Step: 6
Training loss: 1.898033857345581
Validation loss: 2.0492567721233574

Epoch: 6| Step: 7
Training loss: 1.9489786624908447
Validation loss: 2.0248165066524217

Epoch: 6| Step: 8
Training loss: 1.8608779907226562
Validation loss: 2.027899172998244

Epoch: 6| Step: 9
Training loss: 1.8515828847885132
Validation loss: 2.0297545438171714

Epoch: 6| Step: 10
Training loss: 1.3932218551635742
Validation loss: 2.032297888109761

Epoch: 6| Step: 11
Training loss: 1.2335044145584106
Validation loss: 2.0396382539503035

Epoch: 6| Step: 12
Training loss: 1.1098096370697021
Validation loss: 2.041795471663116

Epoch: 6| Step: 13
Training loss: 2.1269280910491943
Validation loss: 2.0561132930940196

Epoch: 265| Step: 0
Training loss: 1.621351957321167
Validation loss: 2.076996898138395

Epoch: 6| Step: 1
Training loss: 1.997509479522705
Validation loss: 2.056830859953357

Epoch: 6| Step: 2
Training loss: 1.7576384544372559
Validation loss: 2.070583099959999

Epoch: 6| Step: 3
Training loss: 0.9453574419021606
Validation loss: 2.078866486908287

Epoch: 6| Step: 4
Training loss: 1.485282301902771
Validation loss: 2.0770830954274824

Epoch: 6| Step: 5
Training loss: 1.8137794733047485
Validation loss: 2.10468985444756

Epoch: 6| Step: 6
Training loss: 1.2991042137145996
Validation loss: 2.1258426020222325

Epoch: 6| Step: 7
Training loss: 2.2368764877319336
Validation loss: 2.121887383922454

Epoch: 6| Step: 8
Training loss: 1.354057788848877
Validation loss: 2.1565055975350003

Epoch: 6| Step: 9
Training loss: 2.142658233642578
Validation loss: 2.172161207404188

Epoch: 6| Step: 10
Training loss: 1.2839083671569824
Validation loss: 2.1628298913278887

Epoch: 6| Step: 11
Training loss: 1.3199503421783447
Validation loss: 2.142874918958192

Epoch: 6| Step: 12
Training loss: 1.1477394104003906
Validation loss: 2.1306542324763473

Epoch: 6| Step: 13
Training loss: 1.567217469215393
Validation loss: 2.1154305242723033

Epoch: 266| Step: 0
Training loss: 1.5274758338928223
Validation loss: 2.080594713969897

Epoch: 6| Step: 1
Training loss: 2.2109909057617188
Validation loss: 2.088816809397872

Epoch: 6| Step: 2
Training loss: 1.06508469581604
Validation loss: 2.077347424722487

Epoch: 6| Step: 3
Training loss: 1.1474295854568481
Validation loss: 2.0762823768841323

Epoch: 6| Step: 4
Training loss: 1.6101644039154053
Validation loss: 2.082355965850174

Epoch: 6| Step: 5
Training loss: 1.2428280115127563
Validation loss: 2.074992988699226

Epoch: 6| Step: 6
Training loss: 1.4144195318222046
Validation loss: 2.068745033715361

Epoch: 6| Step: 7
Training loss: 1.4543774127960205
Validation loss: 2.0742851893107095

Epoch: 6| Step: 8
Training loss: 2.299849510192871
Validation loss: 2.0626578818085375

Epoch: 6| Step: 9
Training loss: 1.8556511402130127
Validation loss: 2.063124531058855

Epoch: 6| Step: 10
Training loss: 1.2987765073776245
Validation loss: 2.0509284311725247

Epoch: 6| Step: 11
Training loss: 1.2016382217407227
Validation loss: 2.061081099253829

Epoch: 6| Step: 12
Training loss: 1.6517119407653809
Validation loss: 2.06680344253458

Epoch: 6| Step: 13
Training loss: 1.608280062675476
Validation loss: 2.0769601060498144

Epoch: 267| Step: 0
Training loss: 1.7535150051116943
Validation loss: 2.0754645639850247

Epoch: 6| Step: 1
Training loss: 1.3784949779510498
Validation loss: 2.100654023949818

Epoch: 6| Step: 2
Training loss: 1.9066386222839355
Validation loss: 2.1145262077290523

Epoch: 6| Step: 3
Training loss: 2.028329372406006
Validation loss: 2.1211987669749925

Epoch: 6| Step: 4
Training loss: 1.749616026878357
Validation loss: 2.1342913027732604

Epoch: 6| Step: 5
Training loss: 1.5302534103393555
Validation loss: 2.1253864560075986

Epoch: 6| Step: 6
Training loss: 0.6818355321884155
Validation loss: 2.121167910996304

Epoch: 6| Step: 7
Training loss: 1.4616278409957886
Validation loss: 2.131224310526284

Epoch: 6| Step: 8
Training loss: 1.2907413244247437
Validation loss: 2.126051664352417

Epoch: 6| Step: 9
Training loss: 1.7861632108688354
Validation loss: 2.113299382630215

Epoch: 6| Step: 10
Training loss: 0.9958350658416748
Validation loss: 2.1045582166282077

Epoch: 6| Step: 11
Training loss: 1.677156686782837
Validation loss: 2.095571525635258

Epoch: 6| Step: 12
Training loss: 1.32706880569458
Validation loss: 2.09908204437584

Epoch: 6| Step: 13
Training loss: 2.501795768737793
Validation loss: 2.064807016362426

Epoch: 268| Step: 0
Training loss: 1.3842434883117676
Validation loss: 2.073049799088509

Epoch: 6| Step: 1
Training loss: 0.7987018823623657
Validation loss: 2.084546989010226

Epoch: 6| Step: 2
Training loss: 1.5775487422943115
Validation loss: 2.0936569962450253

Epoch: 6| Step: 3
Training loss: 1.525088906288147
Validation loss: 2.110491737242668

Epoch: 6| Step: 4
Training loss: 1.7478888034820557
Validation loss: 2.0969555377960205

Epoch: 6| Step: 5
Training loss: 1.7070538997650146
Validation loss: 2.084674685232101

Epoch: 6| Step: 6
Training loss: 1.2849795818328857
Validation loss: 2.0616987354011944

Epoch: 6| Step: 7
Training loss: 2.041594982147217
Validation loss: 2.0800855416123585

Epoch: 6| Step: 8
Training loss: 1.267041802406311
Validation loss: 2.0891237694730043

Epoch: 6| Step: 9
Training loss: 1.466722011566162
Validation loss: 2.0927628086459253

Epoch: 6| Step: 10
Training loss: 1.8807344436645508
Validation loss: 2.0955467788122033

Epoch: 6| Step: 11
Training loss: 1.6121318340301514
Validation loss: 2.10376125766385

Epoch: 6| Step: 12
Training loss: 1.837355375289917
Validation loss: 2.105759625793785

Epoch: 6| Step: 13
Training loss: 1.923484206199646
Validation loss: 2.1020978573829896

Epoch: 269| Step: 0
Training loss: 1.4695816040039062
Validation loss: 2.09631057195766

Epoch: 6| Step: 1
Training loss: 0.9853106141090393
Validation loss: 2.1251861651738486

Epoch: 6| Step: 2
Training loss: 2.1058554649353027
Validation loss: 2.131538000158084

Epoch: 6| Step: 3
Training loss: 1.4052526950836182
Validation loss: 2.1033146291650753

Epoch: 6| Step: 4
Training loss: 1.5900951623916626
Validation loss: 2.085109172328826

Epoch: 6| Step: 5
Training loss: 1.6382708549499512
Validation loss: 2.0838431901829217

Epoch: 6| Step: 6
Training loss: 1.7621829509735107
Validation loss: 2.079206682020618

Epoch: 6| Step: 7
Training loss: 1.4201457500457764
Validation loss: 2.0667938519549627

Epoch: 6| Step: 8
Training loss: 1.415563702583313
Validation loss: 2.0559849175073768

Epoch: 6| Step: 9
Training loss: 1.4084581136703491
Validation loss: 2.0612620538280857

Epoch: 6| Step: 10
Training loss: 1.2993065118789673
Validation loss: 2.0399771685241372

Epoch: 6| Step: 11
Training loss: 1.2880749702453613
Validation loss: 2.0566823149240143

Epoch: 6| Step: 12
Training loss: 2.1752679347991943
Validation loss: 2.0578315693845033

Epoch: 6| Step: 13
Training loss: 1.1529967784881592
Validation loss: 2.0486987970208608

Epoch: 270| Step: 0
Training loss: 1.4049921035766602
Validation loss: 2.0739501137887277

Epoch: 6| Step: 1
Training loss: 1.43791925907135
Validation loss: 2.0555501714829476

Epoch: 6| Step: 2
Training loss: 1.9093375205993652
Validation loss: 2.0626432024022585

Epoch: 6| Step: 3
Training loss: 1.2125791311264038
Validation loss: 2.0644487539927163

Epoch: 6| Step: 4
Training loss: 1.5038769245147705
Validation loss: 2.0613300236322547

Epoch: 6| Step: 5
Training loss: 1.6976332664489746
Validation loss: 2.0524508030183855

Epoch: 6| Step: 6
Training loss: 1.6708266735076904
Validation loss: 2.0440828723292195

Epoch: 6| Step: 7
Training loss: 1.5350931882858276
Validation loss: 2.0592340115577943

Epoch: 6| Step: 8
Training loss: 1.3004804849624634
Validation loss: 2.048397356464017

Epoch: 6| Step: 9
Training loss: 1.4438791275024414
Validation loss: 2.0747095461814635

Epoch: 6| Step: 10
Training loss: 1.1460161209106445
Validation loss: 2.068070614209739

Epoch: 6| Step: 11
Training loss: 1.125436544418335
Validation loss: 2.0984190869074997

Epoch: 6| Step: 12
Training loss: 2.060835838317871
Validation loss: 2.10117906396107

Epoch: 6| Step: 13
Training loss: 1.8565012216567993
Validation loss: 2.158147583725632

Epoch: 271| Step: 0
Training loss: 1.8008644580841064
Validation loss: 2.121563644819362

Epoch: 6| Step: 1
Training loss: 1.6067149639129639
Validation loss: 2.1092875593452045

Epoch: 6| Step: 2
Training loss: 0.8971409797668457
Validation loss: 2.0720356087530813

Epoch: 6| Step: 3
Training loss: 1.138637900352478
Validation loss: 2.0700945674732165

Epoch: 6| Step: 4
Training loss: 1.1092606782913208
Validation loss: 2.0546262725707023

Epoch: 6| Step: 5
Training loss: 1.458741545677185
Validation loss: 2.0301896449058288

Epoch: 6| Step: 6
Training loss: 1.399303913116455
Validation loss: 2.0320558112154723

Epoch: 6| Step: 7
Training loss: 1.8508260250091553
Validation loss: 2.0531183096670333

Epoch: 6| Step: 8
Training loss: 1.8384475708007812
Validation loss: 2.07364825535846

Epoch: 6| Step: 9
Training loss: 1.3684701919555664
Validation loss: 2.0917107584655925

Epoch: 6| Step: 10
Training loss: 1.5240089893341064
Validation loss: 2.096117386253931

Epoch: 6| Step: 11
Training loss: 1.8708072900772095
Validation loss: 2.10780031065787

Epoch: 6| Step: 12
Training loss: 1.4320610761642456
Validation loss: 2.1067943316633984

Epoch: 6| Step: 13
Training loss: 1.9975923299789429
Validation loss: 2.111058920942327

Epoch: 272| Step: 0
Training loss: 1.6246438026428223
Validation loss: 2.115706636059669

Epoch: 6| Step: 1
Training loss: 1.5681978464126587
Validation loss: 2.0982333921617076

Epoch: 6| Step: 2
Training loss: 1.8165743350982666
Validation loss: 2.084969389823175

Epoch: 6| Step: 3
Training loss: 1.0645259618759155
Validation loss: 2.0930849454736196

Epoch: 6| Step: 4
Training loss: 1.6124489307403564
Validation loss: 2.0665536234455724

Epoch: 6| Step: 5
Training loss: 1.969862461090088
Validation loss: 2.0723200715998167

Epoch: 6| Step: 6
Training loss: 1.3852739334106445
Validation loss: 2.069133189416701

Epoch: 6| Step: 7
Training loss: 1.6049596071243286
Validation loss: 2.0664249415038736

Epoch: 6| Step: 8
Training loss: 0.7663969993591309
Validation loss: 2.0657795667648315

Epoch: 6| Step: 9
Training loss: 1.1146105527877808
Validation loss: 2.057862966291366

Epoch: 6| Step: 10
Training loss: 1.8381447792053223
Validation loss: 2.075229352520358

Epoch: 6| Step: 11
Training loss: 1.2696781158447266
Validation loss: 2.053527278284873

Epoch: 6| Step: 12
Training loss: 1.7974838018417358
Validation loss: 2.049288590749105

Epoch: 6| Step: 13
Training loss: 1.5504597425460815
Validation loss: 2.053389956874232

Epoch: 273| Step: 0
Training loss: 1.3491339683532715
Validation loss: 2.041827699189545

Epoch: 6| Step: 1
Training loss: 1.4496372938156128
Validation loss: 2.050214849492555

Epoch: 6| Step: 2
Training loss: 1.44376802444458
Validation loss: 2.037292695814563

Epoch: 6| Step: 3
Training loss: 0.9474998116493225
Validation loss: 2.042935440617223

Epoch: 6| Step: 4
Training loss: 0.9562005996704102
Validation loss: 2.052312139541872

Epoch: 6| Step: 5
Training loss: 2.070737361907959
Validation loss: 2.0751851963740524

Epoch: 6| Step: 6
Training loss: 1.2116031646728516
Validation loss: 2.0865160598549792

Epoch: 6| Step: 7
Training loss: 1.9841053485870361
Validation loss: 2.088565816161453

Epoch: 6| Step: 8
Training loss: 1.8722178936004639
Validation loss: 2.1213882469361827

Epoch: 6| Step: 9
Training loss: 1.0204635858535767
Validation loss: 2.125645722112348

Epoch: 6| Step: 10
Training loss: 0.9479462504386902
Validation loss: 2.1050310775797856

Epoch: 6| Step: 11
Training loss: 1.7381644248962402
Validation loss: 2.105529354464623

Epoch: 6| Step: 12
Training loss: 2.1695611476898193
Validation loss: 2.0842023126540647

Epoch: 6| Step: 13
Training loss: 2.0980098247528076
Validation loss: 2.0862542352368756

Epoch: 274| Step: 0
Training loss: 1.5616142749786377
Validation loss: 2.0904606593552457

Epoch: 6| Step: 1
Training loss: 1.5028958320617676
Validation loss: 2.0598191830419723

Epoch: 6| Step: 2
Training loss: 1.2917044162750244
Validation loss: 2.0749537201337915

Epoch: 6| Step: 3
Training loss: 1.4719617366790771
Validation loss: 2.0689846943783503

Epoch: 6| Step: 4
Training loss: 1.4441730976104736
Validation loss: 2.069098631540934

Epoch: 6| Step: 5
Training loss: 1.4856672286987305
Validation loss: 2.07463139359669

Epoch: 6| Step: 6
Training loss: 2.5282249450683594
Validation loss: 2.113392053111907

Epoch: 6| Step: 7
Training loss: 1.2201921939849854
Validation loss: 2.1038141301883164

Epoch: 6| Step: 8
Training loss: 1.259520411491394
Validation loss: 2.109800156726632

Epoch: 6| Step: 9
Training loss: 1.2611083984375
Validation loss: 2.1189978789257746

Epoch: 6| Step: 10
Training loss: 1.6577943563461304
Validation loss: 2.1124358074639433

Epoch: 6| Step: 11
Training loss: 1.2964380979537964
Validation loss: 2.1339372345196304

Epoch: 6| Step: 12
Training loss: 1.0943530797958374
Validation loss: 2.125285925403718

Epoch: 6| Step: 13
Training loss: 1.7391817569732666
Validation loss: 2.1196707487106323

Epoch: 275| Step: 0
Training loss: 1.8146275281906128
Validation loss: 2.117105243026569

Epoch: 6| Step: 1
Training loss: 1.2129619121551514
Validation loss: 2.1069100826017317

Epoch: 6| Step: 2
Training loss: 1.492739200592041
Validation loss: 2.1004183728207826

Epoch: 6| Step: 3
Training loss: 1.194687843322754
Validation loss: 2.0863369126473703

Epoch: 6| Step: 4
Training loss: 1.3825621604919434
Validation loss: 2.0661227805640108

Epoch: 6| Step: 5
Training loss: 1.5852830410003662
Validation loss: 2.0622748174974994

Epoch: 6| Step: 6
Training loss: 1.8122057914733887
Validation loss: 2.042883029548071

Epoch: 6| Step: 7
Training loss: 1.5978965759277344
Validation loss: 2.0612137984204035

Epoch: 6| Step: 8
Training loss: 1.639094591140747
Validation loss: 2.0757428830669773

Epoch: 6| Step: 9
Training loss: 1.2343664169311523
Validation loss: 2.0769220654682448

Epoch: 6| Step: 10
Training loss: 1.2180523872375488
Validation loss: 2.086849831765698

Epoch: 6| Step: 11
Training loss: 1.592254400253296
Validation loss: 2.0791851628211235

Epoch: 6| Step: 12
Training loss: 1.0808379650115967
Validation loss: 2.0713431296810025

Epoch: 6| Step: 13
Training loss: 1.624216079711914
Validation loss: 2.05772997999704

Epoch: 276| Step: 0
Training loss: 2.0205929279327393
Validation loss: 2.078174629519063

Epoch: 6| Step: 1
Training loss: 1.304847240447998
Validation loss: 2.0591605735081497

Epoch: 6| Step: 2
Training loss: 1.2117125988006592
Validation loss: 2.0504174104300876

Epoch: 6| Step: 3
Training loss: 1.6470049619674683
Validation loss: 2.057435944516172

Epoch: 6| Step: 4
Training loss: 0.9657666683197021
Validation loss: 2.0530351720830446

Epoch: 6| Step: 5
Training loss: 1.5722267627716064
Validation loss: 2.053275749247561

Epoch: 6| Step: 6
Training loss: 1.6171529293060303
Validation loss: 2.0807191159135554

Epoch: 6| Step: 7
Training loss: 1.5451600551605225
Validation loss: 2.110551280360068

Epoch: 6| Step: 8
Training loss: 1.2341198921203613
Validation loss: 2.1455982910689486

Epoch: 6| Step: 9
Training loss: 1.0032191276550293
Validation loss: 2.1577348786015667

Epoch: 6| Step: 10
Training loss: 1.6034581661224365
Validation loss: 2.14563799032601

Epoch: 6| Step: 11
Training loss: 2.1641452312469482
Validation loss: 2.0934743112133396

Epoch: 6| Step: 12
Training loss: 1.5010840892791748
Validation loss: 2.0973556785173315

Epoch: 6| Step: 13
Training loss: 1.055328607559204
Validation loss: 2.06865297338014

Epoch: 277| Step: 0
Training loss: 1.7347177267074585
Validation loss: 2.0534412501960673

Epoch: 6| Step: 1
Training loss: 1.1119410991668701
Validation loss: 2.065909312617394

Epoch: 6| Step: 2
Training loss: 1.1236915588378906
Validation loss: 2.0495791127604823

Epoch: 6| Step: 3
Training loss: 2.680039405822754
Validation loss: 2.0747344160592682

Epoch: 6| Step: 4
Training loss: 1.4346952438354492
Validation loss: 2.0645060052153883

Epoch: 6| Step: 5
Training loss: 1.7675734758377075
Validation loss: 2.0733930705696024

Epoch: 6| Step: 6
Training loss: 1.0603679418563843
Validation loss: 2.0762095964083107

Epoch: 6| Step: 7
Training loss: 1.1702951192855835
Validation loss: 2.0650622190967685

Epoch: 6| Step: 8
Training loss: 1.6762502193450928
Validation loss: 2.071777202749765

Epoch: 6| Step: 9
Training loss: 1.0400747060775757
Validation loss: 2.077435314014394

Epoch: 6| Step: 10
Training loss: 1.08292818069458
Validation loss: 2.0744128586143575

Epoch: 6| Step: 11
Training loss: 1.4338229894638062
Validation loss: 2.07920681020265

Epoch: 6| Step: 12
Training loss: 1.8833379745483398
Validation loss: 2.0913201865329536

Epoch: 6| Step: 13
Training loss: 1.0493497848510742
Validation loss: 2.0953712822288595

Epoch: 278| Step: 0
Training loss: 0.844542384147644
Validation loss: 2.106813910186932

Epoch: 6| Step: 1
Training loss: 2.1896371841430664
Validation loss: 2.1313828883632535

Epoch: 6| Step: 2
Training loss: 1.8869469165802002
Validation loss: 2.124995582847185

Epoch: 6| Step: 3
Training loss: 0.6710078120231628
Validation loss: 2.0977832886480514

Epoch: 6| Step: 4
Training loss: 1.1999537944793701
Validation loss: 2.0897652410691783

Epoch: 6| Step: 5
Training loss: 1.0566784143447876
Validation loss: 2.0863045031024563

Epoch: 6| Step: 6
Training loss: 1.517016053199768
Validation loss: 2.0806429129774853

Epoch: 6| Step: 7
Training loss: 1.7072083950042725
Validation loss: 2.05317114117325

Epoch: 6| Step: 8
Training loss: 1.6091355085372925
Validation loss: 2.086630262354369

Epoch: 6| Step: 9
Training loss: 1.1460403203964233
Validation loss: 2.0483202024172713

Epoch: 6| Step: 10
Training loss: 1.7915287017822266
Validation loss: 2.0643503486469226

Epoch: 6| Step: 11
Training loss: 1.2077574729919434
Validation loss: 2.050648073996267

Epoch: 6| Step: 12
Training loss: 1.8427577018737793
Validation loss: 2.083409906715475

Epoch: 6| Step: 13
Training loss: 2.0490472316741943
Validation loss: 2.0829201423993675

Epoch: 279| Step: 0
Training loss: 0.877616286277771
Validation loss: 2.0952702183877268

Epoch: 6| Step: 1
Training loss: 1.0681335926055908
Validation loss: 2.096726517523489

Epoch: 6| Step: 2
Training loss: 1.3047709465026855
Validation loss: 2.060148463454298

Epoch: 6| Step: 3
Training loss: 1.415680170059204
Validation loss: 2.0453344032328618

Epoch: 6| Step: 4
Training loss: 1.2901383638381958
Validation loss: 2.043540677716655

Epoch: 6| Step: 5
Training loss: 1.8759862184524536
Validation loss: 2.0584415107645015

Epoch: 6| Step: 6
Training loss: 1.4195525646209717
Validation loss: 2.0442971901227067

Epoch: 6| Step: 7
Training loss: 1.3272377252578735
Validation loss: 2.054832125222811

Epoch: 6| Step: 8
Training loss: 1.8100274801254272
Validation loss: 2.0700043042500815

Epoch: 6| Step: 9
Training loss: 1.7726390361785889
Validation loss: 2.0809755825227305

Epoch: 6| Step: 10
Training loss: 1.7186534404754639
Validation loss: 2.0732479774823753

Epoch: 6| Step: 11
Training loss: 1.2480530738830566
Validation loss: 2.0619889510575162

Epoch: 6| Step: 12
Training loss: 1.5214157104492188
Validation loss: 2.024197531002824

Epoch: 6| Step: 13
Training loss: 1.8489117622375488
Validation loss: 2.0247822910226803

Epoch: 280| Step: 0
Training loss: 1.470799207687378
Validation loss: 2.0472488813502814

Epoch: 6| Step: 1
Training loss: 1.3688757419586182
Validation loss: 2.053306395007718

Epoch: 6| Step: 2
Training loss: 1.1253612041473389
Validation loss: 2.0723902717713387

Epoch: 6| Step: 3
Training loss: 1.7397418022155762
Validation loss: 2.0857019578256915

Epoch: 6| Step: 4
Training loss: 1.5500640869140625
Validation loss: 2.086207478277145

Epoch: 6| Step: 5
Training loss: 1.3383125066757202
Validation loss: 2.0398051174738074

Epoch: 6| Step: 6
Training loss: 1.561835527420044
Validation loss: 2.0381565760540705

Epoch: 6| Step: 7
Training loss: 1.2472608089447021
Validation loss: 2.014269972360262

Epoch: 6| Step: 8
Training loss: 1.1547456979751587
Validation loss: 2.0056317801116617

Epoch: 6| Step: 9
Training loss: 1.6301517486572266
Validation loss: 2.0205129590085757

Epoch: 6| Step: 10
Training loss: 1.393375039100647
Validation loss: 2.0136410228667723

Epoch: 6| Step: 11
Training loss: 1.6782619953155518
Validation loss: 2.006263954665071

Epoch: 6| Step: 12
Training loss: 1.2179864645004272
Validation loss: 2.0342709736157487

Epoch: 6| Step: 13
Training loss: 1.8765000104904175
Validation loss: 2.0566307524199128

Epoch: 281| Step: 0
Training loss: 1.3689634799957275
Validation loss: 2.0686655839284263

Epoch: 6| Step: 1
Training loss: 1.73443603515625
Validation loss: 2.098304151206888

Epoch: 6| Step: 2
Training loss: 1.0234769582748413
Validation loss: 2.1336770185860257

Epoch: 6| Step: 3
Training loss: 1.7857697010040283
Validation loss: 2.1015321823858444

Epoch: 6| Step: 4
Training loss: 0.5126216411590576
Validation loss: 2.1225948615740706

Epoch: 6| Step: 5
Training loss: 1.8384613990783691
Validation loss: 2.0756518917699016

Epoch: 6| Step: 6
Training loss: 1.4101433753967285
Validation loss: 2.100786870525729

Epoch: 6| Step: 7
Training loss: 1.0121705532073975
Validation loss: 2.085736051682503

Epoch: 6| Step: 8
Training loss: 2.2187888622283936
Validation loss: 2.080564263046429

Epoch: 6| Step: 9
Training loss: 1.1554049253463745
Validation loss: 2.081481874630015

Epoch: 6| Step: 10
Training loss: 1.4618077278137207
Validation loss: 2.0913753099338983

Epoch: 6| Step: 11
Training loss: 1.374186396598816
Validation loss: 2.0604872062642086

Epoch: 6| Step: 12
Training loss: 1.8288066387176514
Validation loss: 2.0537508559483353

Epoch: 6| Step: 13
Training loss: 1.404860019683838
Validation loss: 2.0672197572646605

Epoch: 282| Step: 0
Training loss: 1.7297229766845703
Validation loss: 2.0666534105936685

Epoch: 6| Step: 1
Training loss: 1.6094921827316284
Validation loss: 2.0608324876395603

Epoch: 6| Step: 2
Training loss: 1.7034778594970703
Validation loss: 2.0983576133687007

Epoch: 6| Step: 3
Training loss: 1.4097046852111816
Validation loss: 2.093406013263169

Epoch: 6| Step: 4
Training loss: 1.4744377136230469
Validation loss: 2.08659371765711

Epoch: 6| Step: 5
Training loss: 1.41696298122406
Validation loss: 2.0829571113791516

Epoch: 6| Step: 6
Training loss: 1.2034509181976318
Validation loss: 2.0844811829187537

Epoch: 6| Step: 7
Training loss: 1.20840585231781
Validation loss: 2.046472530211172

Epoch: 6| Step: 8
Training loss: 1.2793177366256714
Validation loss: 2.06043864065601

Epoch: 6| Step: 9
Training loss: 1.0206834077835083
Validation loss: 2.036236111835767

Epoch: 6| Step: 10
Training loss: 1.6199328899383545
Validation loss: 2.07101079469086

Epoch: 6| Step: 11
Training loss: 0.5901653170585632
Validation loss: 2.045401733408692

Epoch: 6| Step: 12
Training loss: 1.7792035341262817
Validation loss: 2.059063647383003

Epoch: 6| Step: 13
Training loss: 2.729318141937256
Validation loss: 2.0397000876806115

Epoch: 283| Step: 0
Training loss: 1.0547730922698975
Validation loss: 2.0557212880862656

Epoch: 6| Step: 1
Training loss: 1.526482343673706
Validation loss: 2.0531097176254436

Epoch: 6| Step: 2
Training loss: 1.247867226600647
Validation loss: 2.0518809621052077

Epoch: 6| Step: 3
Training loss: 1.4438822269439697
Validation loss: 2.058205525080363

Epoch: 6| Step: 4
Training loss: 1.286072015762329
Validation loss: 2.088935713614187

Epoch: 6| Step: 5
Training loss: 1.3299190998077393
Validation loss: 2.0840429593158025

Epoch: 6| Step: 6
Training loss: 1.5265390872955322
Validation loss: 2.0859483006179973

Epoch: 6| Step: 7
Training loss: 1.5270121097564697
Validation loss: 2.074564717149222

Epoch: 6| Step: 8
Training loss: 1.5075349807739258
Validation loss: 2.065433877770619

Epoch: 6| Step: 9
Training loss: 1.6515203714370728
Validation loss: 2.0763836573528986

Epoch: 6| Step: 10
Training loss: 1.7152003049850464
Validation loss: 2.0528584205976097

Epoch: 6| Step: 11
Training loss: 1.75636887550354
Validation loss: 2.045526815998939

Epoch: 6| Step: 12
Training loss: 1.3100810050964355
Validation loss: 2.0562606729486936

Epoch: 6| Step: 13
Training loss: 0.9014121294021606
Validation loss: 2.074274610447627

Epoch: 284| Step: 0
Training loss: 1.6448131799697876
Validation loss: 2.0764167103716122

Epoch: 6| Step: 1
Training loss: 0.9617476463317871
Validation loss: 2.084011116335469

Epoch: 6| Step: 2
Training loss: 1.483953595161438
Validation loss: 2.1054488593532192

Epoch: 6| Step: 3
Training loss: 1.758833408355713
Validation loss: 2.1118765261865433

Epoch: 6| Step: 4
Training loss: 1.4762701988220215
Validation loss: 2.0646341718653196

Epoch: 6| Step: 5
Training loss: 1.582471489906311
Validation loss: 2.0728141171957857

Epoch: 6| Step: 6
Training loss: 1.1511969566345215
Validation loss: 2.0778259410653064

Epoch: 6| Step: 7
Training loss: 1.3782501220703125
Validation loss: 2.0491486595522974

Epoch: 6| Step: 8
Training loss: 1.6071295738220215
Validation loss: 2.0347299191259567

Epoch: 6| Step: 9
Training loss: 1.733510136604309
Validation loss: 2.047823788017355

Epoch: 6| Step: 10
Training loss: 1.1352331638336182
Validation loss: 2.0717612876687

Epoch: 6| Step: 11
Training loss: 1.014857530593872
Validation loss: 2.0675885113336707

Epoch: 6| Step: 12
Training loss: 1.443408489227295
Validation loss: 2.076519312397126

Epoch: 6| Step: 13
Training loss: 1.5160373449325562
Validation loss: 2.0649960707592707

Epoch: 285| Step: 0
Training loss: 1.274256944656372
Validation loss: 2.068106464160386

Epoch: 6| Step: 1
Training loss: 1.1512668132781982
Validation loss: 2.055577672937865

Epoch: 6| Step: 2
Training loss: 1.6509733200073242
Validation loss: 2.065648280164247

Epoch: 6| Step: 3
Training loss: 1.6692755222320557
Validation loss: 2.0496032725098314

Epoch: 6| Step: 4
Training loss: 0.9653599262237549
Validation loss: 2.0505924814490863

Epoch: 6| Step: 5
Training loss: 0.8166354894638062
Validation loss: 2.0565656718387397

Epoch: 6| Step: 6
Training loss: 1.5946147441864014
Validation loss: 2.03885228659517

Epoch: 6| Step: 7
Training loss: 0.8395681381225586
Validation loss: 2.044625828343053

Epoch: 6| Step: 8
Training loss: 1.5817400217056274
Validation loss: 2.0698567231496177

Epoch: 6| Step: 9
Training loss: 1.3368496894836426
Validation loss: 2.082329583424394

Epoch: 6| Step: 10
Training loss: 1.780517339706421
Validation loss: 2.0880330685646302

Epoch: 6| Step: 11
Training loss: 1.652677297592163
Validation loss: 2.1000235285810245

Epoch: 6| Step: 12
Training loss: 1.6085748672485352
Validation loss: 2.070862639334894

Epoch: 6| Step: 13
Training loss: 2.020082712173462
Validation loss: 2.0541294390155422

Epoch: 286| Step: 0
Training loss: 1.6025536060333252
Validation loss: 2.030007613602505

Epoch: 6| Step: 1
Training loss: 1.7749625444412231
Validation loss: 2.0371234275961436

Epoch: 6| Step: 2
Training loss: 1.6608221530914307
Validation loss: 2.010587046223302

Epoch: 6| Step: 3
Training loss: 2.012718677520752
Validation loss: 2.014943520228068

Epoch: 6| Step: 4
Training loss: 1.1553139686584473
Validation loss: 2.0248754947416243

Epoch: 6| Step: 5
Training loss: 0.9561516046524048
Validation loss: 2.054545044898987

Epoch: 6| Step: 6
Training loss: 1.5480704307556152
Validation loss: 2.027843693251251

Epoch: 6| Step: 7
Training loss: 1.4923306703567505
Validation loss: 2.059349677895987

Epoch: 6| Step: 8
Training loss: 1.1945736408233643
Validation loss: 2.084805125831276

Epoch: 6| Step: 9
Training loss: 1.0075305700302124
Validation loss: 2.0851988766783025

Epoch: 6| Step: 10
Training loss: 1.0591740608215332
Validation loss: 2.053410945400115

Epoch: 6| Step: 11
Training loss: 1.1544907093048096
Validation loss: 2.0620993529596636

Epoch: 6| Step: 12
Training loss: 1.3811514377593994
Validation loss: 2.058188533270231

Epoch: 6| Step: 13
Training loss: 1.69612455368042
Validation loss: 2.0698349450224187

Epoch: 287| Step: 0
Training loss: 1.3971383571624756
Validation loss: 2.0671211429821548

Epoch: 6| Step: 1
Training loss: 1.2717998027801514
Validation loss: 2.063397815150599

Epoch: 6| Step: 2
Training loss: 1.3403091430664062
Validation loss: 2.059742384059455

Epoch: 6| Step: 3
Training loss: 1.5799577236175537
Validation loss: 2.074582948479601

Epoch: 6| Step: 4
Training loss: 1.6551425457000732
Validation loss: 2.098205843279439

Epoch: 6| Step: 5
Training loss: 1.4533058404922485
Validation loss: 2.0919955494583293

Epoch: 6| Step: 6
Training loss: 1.5504980087280273
Validation loss: 2.054961881329936

Epoch: 6| Step: 7
Training loss: 1.5748364925384521
Validation loss: 2.018758027784286

Epoch: 6| Step: 8
Training loss: 1.4080911874771118
Validation loss: 2.0130892389564106

Epoch: 6| Step: 9
Training loss: 1.1471936702728271
Validation loss: 2.002578050859513

Epoch: 6| Step: 10
Training loss: 0.8937811851501465
Validation loss: 2.0086224450859973

Epoch: 6| Step: 11
Training loss: 1.556749939918518
Validation loss: 2.0190128152088453

Epoch: 6| Step: 12
Training loss: 1.0762183666229248
Validation loss: 2.0132519199002172

Epoch: 6| Step: 13
Training loss: 1.8009874820709229
Validation loss: 2.018982183548712

Epoch: 288| Step: 0
Training loss: 0.6721073985099792
Validation loss: 2.0463273243237565

Epoch: 6| Step: 1
Training loss: 1.7485942840576172
Validation loss: 2.071999893393568

Epoch: 6| Step: 2
Training loss: 1.7429375648498535
Validation loss: 2.088970035635015

Epoch: 6| Step: 3
Training loss: 1.701425552368164
Validation loss: 2.063809812709849

Epoch: 6| Step: 4
Training loss: 1.490337610244751
Validation loss: 2.060270263302711

Epoch: 6| Step: 5
Training loss: 1.6661533117294312
Validation loss: 2.06010345233384

Epoch: 6| Step: 6
Training loss: 1.231757402420044
Validation loss: 2.0533355987200173

Epoch: 6| Step: 7
Training loss: 1.2191267013549805
Validation loss: 2.028374292517221

Epoch: 6| Step: 8
Training loss: 1.837010145187378
Validation loss: 2.0532952713710007

Epoch: 6| Step: 9
Training loss: 1.7607402801513672
Validation loss: 2.064363266832085

Epoch: 6| Step: 10
Training loss: 1.185692310333252
Validation loss: 2.0781995788697274

Epoch: 6| Step: 11
Training loss: 0.8455527424812317
Validation loss: 2.0597944285279963

Epoch: 6| Step: 12
Training loss: 0.8228562474250793
Validation loss: 2.076923344724922

Epoch: 6| Step: 13
Training loss: 1.672960877418518
Validation loss: 2.0663256004292476

Epoch: 289| Step: 0
Training loss: 1.418187141418457
Validation loss: 2.05624318891956

Epoch: 6| Step: 1
Training loss: 1.0021615028381348
Validation loss: 2.069902241870921

Epoch: 6| Step: 2
Training loss: 1.5916482210159302
Validation loss: 2.05998497111823

Epoch: 6| Step: 3
Training loss: 1.4439976215362549
Validation loss: 2.0423080280262935

Epoch: 6| Step: 4
Training loss: 1.9139137268066406
Validation loss: 2.0474958419799805

Epoch: 6| Step: 5
Training loss: 1.3427183628082275
Validation loss: 2.0374154121645036

Epoch: 6| Step: 6
Training loss: 1.2876895666122437
Validation loss: 2.034166487314368

Epoch: 6| Step: 7
Training loss: 0.9975193738937378
Validation loss: 2.0295757709010953

Epoch: 6| Step: 8
Training loss: 2.21612811088562
Validation loss: 2.0254652397606963

Epoch: 6| Step: 9
Training loss: 1.0018386840820312
Validation loss: 2.045684019724528

Epoch: 6| Step: 10
Training loss: 1.2950289249420166
Validation loss: 2.0638952332158245

Epoch: 6| Step: 11
Training loss: 0.7240463495254517
Validation loss: 2.0763859505294473

Epoch: 6| Step: 12
Training loss: 1.5738842487335205
Validation loss: 2.0935775938854424

Epoch: 6| Step: 13
Training loss: 1.7273668050765991
Validation loss: 2.102557956531484

Epoch: 290| Step: 0
Training loss: 1.6558369398117065
Validation loss: 2.1022673114653556

Epoch: 6| Step: 1
Training loss: 1.315969705581665
Validation loss: 2.1270844628733974

Epoch: 6| Step: 2
Training loss: 1.2364323139190674
Validation loss: 2.0906179822901243

Epoch: 6| Step: 3
Training loss: 1.4338970184326172
Validation loss: 2.0741664260946293

Epoch: 6| Step: 4
Training loss: 1.6455507278442383
Validation loss: 2.054452052680395

Epoch: 6| Step: 5
Training loss: 1.709348201751709
Validation loss: 2.035778009763328

Epoch: 6| Step: 6
Training loss: 1.2157344818115234
Validation loss: 2.02710610435855

Epoch: 6| Step: 7
Training loss: 1.2222084999084473
Validation loss: 2.007553300549907

Epoch: 6| Step: 8
Training loss: 1.5027793645858765
Validation loss: 2.0080292019792783

Epoch: 6| Step: 9
Training loss: 1.2017490863800049
Validation loss: 2.028052387699004

Epoch: 6| Step: 10
Training loss: 1.3350285291671753
Validation loss: 2.023889785171837

Epoch: 6| Step: 11
Training loss: 1.322355031967163
Validation loss: 2.04795866627847

Epoch: 6| Step: 12
Training loss: 0.9621393084526062
Validation loss: 2.0339711737889115

Epoch: 6| Step: 13
Training loss: 1.3779380321502686
Validation loss: 2.0332068832971717

Epoch: 291| Step: 0
Training loss: 1.5167453289031982
Validation loss: 2.0230690510042253

Epoch: 6| Step: 1
Training loss: 1.912742257118225
Validation loss: 2.0218274131897958

Epoch: 6| Step: 2
Training loss: 1.594733715057373
Validation loss: 2.0114494600603656

Epoch: 6| Step: 3
Training loss: 1.70184326171875
Validation loss: 2.0082678615405993

Epoch: 6| Step: 4
Training loss: 1.372826337814331
Validation loss: 2.0027669065742084

Epoch: 6| Step: 5
Training loss: 0.8947986364364624
Validation loss: 2.0238368485563543

Epoch: 6| Step: 6
Training loss: 1.508594036102295
Validation loss: 2.083895542288339

Epoch: 6| Step: 7
Training loss: 1.0039103031158447
Validation loss: 2.106281034408077

Epoch: 6| Step: 8
Training loss: 1.0714893341064453
Validation loss: 2.1082987093156382

Epoch: 6| Step: 9
Training loss: 1.2816098928451538
Validation loss: 2.1018423854663806

Epoch: 6| Step: 10
Training loss: 0.9563514590263367
Validation loss: 2.0985857543124946

Epoch: 6| Step: 11
Training loss: 1.7589802742004395
Validation loss: 2.117810795384069

Epoch: 6| Step: 12
Training loss: 1.180661916732788
Validation loss: 2.08038604387673

Epoch: 6| Step: 13
Training loss: 1.3626428842544556
Validation loss: 2.0361373578348467

Epoch: 292| Step: 0
Training loss: 1.2326139211654663
Validation loss: 2.054069661325024

Epoch: 6| Step: 1
Training loss: 1.3355982303619385
Validation loss: 2.0406990153815157

Epoch: 6| Step: 2
Training loss: 1.3288064002990723
Validation loss: 2.0440584100702757

Epoch: 6| Step: 3
Training loss: 0.8985023498535156
Validation loss: 2.0199696402395926

Epoch: 6| Step: 4
Training loss: 1.4756404161453247
Validation loss: 2.025158078439774

Epoch: 6| Step: 5
Training loss: 1.7185406684875488
Validation loss: 2.0321891615467687

Epoch: 6| Step: 6
Training loss: 1.9678477048873901
Validation loss: 2.015275947509273

Epoch: 6| Step: 7
Training loss: 0.868322491645813
Validation loss: 2.0355567650128434

Epoch: 6| Step: 8
Training loss: 2.0974063873291016
Validation loss: 2.081651167203021

Epoch: 6| Step: 9
Training loss: 0.8654347658157349
Validation loss: 2.094351589038808

Epoch: 6| Step: 10
Training loss: 1.7651798725128174
Validation loss: 2.0834068226557907

Epoch: 6| Step: 11
Training loss: 1.6127634048461914
Validation loss: 2.08100994940727

Epoch: 6| Step: 12
Training loss: 1.1003764867782593
Validation loss: 2.0690430236119095

Epoch: 6| Step: 13
Training loss: 0.6433486342430115
Validation loss: 2.052573924423546

Epoch: 293| Step: 0
Training loss: 1.199568748474121
Validation loss: 2.027322335909772

Epoch: 6| Step: 1
Training loss: 1.6758432388305664
Validation loss: 2.021503761250486

Epoch: 6| Step: 2
Training loss: 1.4714899063110352
Validation loss: 2.013357977713308

Epoch: 6| Step: 3
Training loss: 1.4530308246612549
Validation loss: 2.002386146976102

Epoch: 6| Step: 4
Training loss: 1.6491440534591675
Validation loss: 2.0428767473466936

Epoch: 6| Step: 5
Training loss: 1.5098984241485596
Validation loss: 2.0304823293480823

Epoch: 6| Step: 6
Training loss: 1.2496488094329834
Validation loss: 2.061600587701285

Epoch: 6| Step: 7
Training loss: 1.209215521812439
Validation loss: 2.054114680136404

Epoch: 6| Step: 8
Training loss: 1.66225004196167
Validation loss: 2.0679548017440306

Epoch: 6| Step: 9
Training loss: 1.6300328969955444
Validation loss: 2.064465674020911

Epoch: 6| Step: 10
Training loss: 1.1986751556396484
Validation loss: 2.0320716801510064

Epoch: 6| Step: 11
Training loss: 1.203416347503662
Validation loss: 2.023830718891595

Epoch: 6| Step: 12
Training loss: 1.0108519792556763
Validation loss: 2.0198335442491757

Epoch: 6| Step: 13
Training loss: 0.5053989887237549
Validation loss: 2.029944401915355

Epoch: 294| Step: 0
Training loss: 1.3726004362106323
Validation loss: 2.033874903955767

Epoch: 6| Step: 1
Training loss: 1.2330727577209473
Validation loss: 2.0436853619032007

Epoch: 6| Step: 2
Training loss: 1.0736479759216309
Validation loss: 2.061987666673558

Epoch: 6| Step: 3
Training loss: 1.2996759414672852
Validation loss: 2.0537923228356147

Epoch: 6| Step: 4
Training loss: 1.2274527549743652
Validation loss: 2.0816093388424126

Epoch: 6| Step: 5
Training loss: 0.8433786630630493
Validation loss: 2.1000403781091013

Epoch: 6| Step: 6
Training loss: 1.2239623069763184
Validation loss: 2.1251420500457927

Epoch: 6| Step: 7
Training loss: 1.484461784362793
Validation loss: 2.0857540612579673

Epoch: 6| Step: 8
Training loss: 1.9600186347961426
Validation loss: 2.0817579530900523

Epoch: 6| Step: 9
Training loss: 1.0325641632080078
Validation loss: 2.053754259181279

Epoch: 6| Step: 10
Training loss: 1.4010074138641357
Validation loss: 2.0348002051794403

Epoch: 6| Step: 11
Training loss: 1.9775773286819458
Validation loss: 2.018925389935893

Epoch: 6| Step: 12
Training loss: 1.6048991680145264
Validation loss: 2.0091366588428454

Epoch: 6| Step: 13
Training loss: 1.032195806503296
Validation loss: 2.0108064810434976

Epoch: 295| Step: 0
Training loss: 1.139648199081421
Validation loss: 2.0091880060011342

Epoch: 6| Step: 1
Training loss: 1.6345120668411255
Validation loss: 2.0077997074332288

Epoch: 6| Step: 2
Training loss: 1.320183277130127
Validation loss: 2.0267180576119372

Epoch: 6| Step: 3
Training loss: 0.7420476078987122
Validation loss: 2.044659977318138

Epoch: 6| Step: 4
Training loss: 1.6970068216323853
Validation loss: 2.0244204023832917

Epoch: 6| Step: 5
Training loss: 1.2397469282150269
Validation loss: 2.0522591747263426

Epoch: 6| Step: 6
Training loss: 1.752385139465332
Validation loss: 2.072299990602719

Epoch: 6| Step: 7
Training loss: 1.2622586488723755
Validation loss: 2.0834469538862987

Epoch: 6| Step: 8
Training loss: 1.3534760475158691
Validation loss: 2.067355889146046

Epoch: 6| Step: 9
Training loss: 1.1459262371063232
Validation loss: 2.090158975252541

Epoch: 6| Step: 10
Training loss: 1.1054410934448242
Validation loss: 2.1041714786201395

Epoch: 6| Step: 11
Training loss: 1.8157191276550293
Validation loss: 2.115799391141502

Epoch: 6| Step: 12
Training loss: 1.0059890747070312
Validation loss: 2.095991280771071

Epoch: 6| Step: 13
Training loss: 2.014361619949341
Validation loss: 2.08680526415507

Epoch: 296| Step: 0
Training loss: 1.4586827754974365
Validation loss: 2.0644573883343766

Epoch: 6| Step: 1
Training loss: 1.4990650415420532
Validation loss: 2.038710122467369

Epoch: 6| Step: 2
Training loss: 1.187033772468567
Validation loss: 2.0150951813626032

Epoch: 6| Step: 3
Training loss: 2.068427085876465
Validation loss: 1.9734908432088873

Epoch: 6| Step: 4
Training loss: 1.3420565128326416
Validation loss: 1.9809290939761746

Epoch: 6| Step: 5
Training loss: 1.6194818019866943
Validation loss: 1.9999175302443966

Epoch: 6| Step: 6
Training loss: 1.3996632099151611
Validation loss: 1.9933300915584768

Epoch: 6| Step: 7
Training loss: 1.0454397201538086
Validation loss: 1.9991879886196506

Epoch: 6| Step: 8
Training loss: 1.4167534112930298
Validation loss: 1.9862057957597958

Epoch: 6| Step: 9
Training loss: 1.0479739904403687
Validation loss: 1.9977920657844954

Epoch: 6| Step: 10
Training loss: 1.6277059316635132
Validation loss: 2.0051677252656672

Epoch: 6| Step: 11
Training loss: 0.7256252765655518
Validation loss: 2.0144056914955057

Epoch: 6| Step: 12
Training loss: 1.145686388015747
Validation loss: 2.0447988920314337

Epoch: 6| Step: 13
Training loss: 1.1461855173110962
Validation loss: 2.0658043815243627

Epoch: 297| Step: 0
Training loss: 1.6536715030670166
Validation loss: 2.0678634592281875

Epoch: 6| Step: 1
Training loss: 1.3518158197402954
Validation loss: 2.0794998830364597

Epoch: 6| Step: 2
Training loss: 1.2383356094360352
Validation loss: 2.0639419107026953

Epoch: 6| Step: 3
Training loss: 1.7781345844268799
Validation loss: 2.0428020210676294

Epoch: 6| Step: 4
Training loss: 0.8154369592666626
Validation loss: 2.040765006055114

Epoch: 6| Step: 5
Training loss: 1.3188178539276123
Validation loss: 2.0256697849560807

Epoch: 6| Step: 6
Training loss: 1.2876391410827637
Validation loss: 2.0189940570503153

Epoch: 6| Step: 7
Training loss: 1.228310465812683
Validation loss: 2.0338589350382485

Epoch: 6| Step: 8
Training loss: 1.5024358034133911
Validation loss: 2.009457629214051

Epoch: 6| Step: 9
Training loss: 1.2172938585281372
Validation loss: 2.0241804481834493

Epoch: 6| Step: 10
Training loss: 1.2934048175811768
Validation loss: 2.019446278131136

Epoch: 6| Step: 11
Training loss: 1.210790991783142
Validation loss: 2.042602672371813

Epoch: 6| Step: 12
Training loss: 1.4650523662567139
Validation loss: 2.0524525386030956

Epoch: 6| Step: 13
Training loss: 1.5707628726959229
Validation loss: 2.058172497698056

Epoch: 298| Step: 0
Training loss: 1.84071946144104
Validation loss: 2.0764586002595964

Epoch: 6| Step: 1
Training loss: 0.8702540993690491
Validation loss: 2.054995726513606

Epoch: 6| Step: 2
Training loss: 1.4293193817138672
Validation loss: 2.0671572428877636

Epoch: 6| Step: 3
Training loss: 0.8057361841201782
Validation loss: 2.0688481382144395

Epoch: 6| Step: 4
Training loss: 1.218968152999878
Validation loss: 2.069222906584381

Epoch: 6| Step: 5
Training loss: 1.4064689874649048
Validation loss: 2.048049126901934

Epoch: 6| Step: 6
Training loss: 1.678381085395813
Validation loss: 2.0731222373183056

Epoch: 6| Step: 7
Training loss: 1.6040269136428833
Validation loss: 2.041796225373463

Epoch: 6| Step: 8
Training loss: 1.4795572757720947
Validation loss: 2.0454409853104623

Epoch: 6| Step: 9
Training loss: 1.8069770336151123
Validation loss: 2.0696296332984843

Epoch: 6| Step: 10
Training loss: 1.4200400114059448
Validation loss: 2.1038471883343113

Epoch: 6| Step: 11
Training loss: 0.5018407702445984
Validation loss: 2.1280955178763277

Epoch: 6| Step: 12
Training loss: 1.2819284200668335
Validation loss: 2.0887545436941166

Epoch: 6| Step: 13
Training loss: 1.509824514389038
Validation loss: 2.0269107651966873

Epoch: 299| Step: 0
Training loss: 1.2623181343078613
Validation loss: 2.021632600856084

Epoch: 6| Step: 1
Training loss: 1.9463870525360107
Validation loss: 1.987993836402893

Epoch: 6| Step: 2
Training loss: 1.3122429847717285
Validation loss: 1.97707284778677

Epoch: 6| Step: 3
Training loss: 1.1717761754989624
Validation loss: 1.9840019749056907

Epoch: 6| Step: 4
Training loss: 1.7514550685882568
Validation loss: 1.9866227565273162

Epoch: 6| Step: 5
Training loss: 1.526346206665039
Validation loss: 1.9788296120141142

Epoch: 6| Step: 6
Training loss: 0.7745424509048462
Validation loss: 1.9916495123217184

Epoch: 6| Step: 7
Training loss: 1.0648736953735352
Validation loss: 2.026941824984807

Epoch: 6| Step: 8
Training loss: 1.2859331369400024
Validation loss: 2.0610500433111705

Epoch: 6| Step: 9
Training loss: 1.7560173273086548
Validation loss: 2.1437541720687703

Epoch: 6| Step: 10
Training loss: 1.7722620964050293
Validation loss: 2.1914695667964157

Epoch: 6| Step: 11
Training loss: 1.3321852684020996
Validation loss: 2.2237179125508955

Epoch: 6| Step: 12
Training loss: 0.9956751465797424
Validation loss: 2.206046845323296

Epoch: 6| Step: 13
Training loss: 1.6198232173919678
Validation loss: 2.1238715135922996

Epoch: 300| Step: 0
Training loss: 1.0760531425476074
Validation loss: 2.034148052174558

Epoch: 6| Step: 1
Training loss: 1.5125017166137695
Validation loss: 2.011717668143652

Epoch: 6| Step: 2
Training loss: 1.1995584964752197
Validation loss: 2.007324466141321

Epoch: 6| Step: 3
Training loss: 1.7139918804168701
Validation loss: 2.0202786973727647

Epoch: 6| Step: 4
Training loss: 1.708971381187439
Validation loss: 2.0332402516436834

Epoch: 6| Step: 5
Training loss: 1.4827864170074463
Validation loss: 1.9840201177904684

Epoch: 6| Step: 6
Training loss: 1.4123034477233887
Validation loss: 2.0026183243720763

Epoch: 6| Step: 7
Training loss: 1.6763039827346802
Validation loss: 1.996628793337012

Epoch: 6| Step: 8
Training loss: 1.953562617301941
Validation loss: 1.9847683470736268

Epoch: 6| Step: 9
Training loss: 1.235447645187378
Validation loss: 2.069514136160574

Epoch: 6| Step: 10
Training loss: 1.1853638887405396
Validation loss: 2.0878796744090256

Epoch: 6| Step: 11
Training loss: 0.9130903482437134
Validation loss: 2.1139517599536526

Epoch: 6| Step: 12
Training loss: 1.1486464738845825
Validation loss: 2.0892729656670683

Epoch: 6| Step: 13
Training loss: 1.15701162815094
Validation loss: 2.086078561762328

Epoch: 301| Step: 0
Training loss: 1.1271461248397827
Validation loss: 2.0462703627924763

Epoch: 6| Step: 1
Training loss: 1.0689351558685303
Validation loss: 2.0531953022044194

Epoch: 6| Step: 2
Training loss: 1.287276029586792
Validation loss: 2.0577958911977787

Epoch: 6| Step: 3
Training loss: 0.8202835321426392
Validation loss: 2.0759779958314795

Epoch: 6| Step: 4
Training loss: 1.3405059576034546
Validation loss: 2.0774016508492092

Epoch: 6| Step: 5
Training loss: 1.4826359748840332
Validation loss: 2.0758786457841114

Epoch: 6| Step: 6
Training loss: 1.7694488763809204
Validation loss: 2.0605013447423137

Epoch: 6| Step: 7
Training loss: 1.6770539283752441
Validation loss: 2.0466926661870812

Epoch: 6| Step: 8
Training loss: 1.7384893894195557
Validation loss: 2.0015276670455933

Epoch: 6| Step: 9
Training loss: 1.2635555267333984
Validation loss: 2.0253609354778

Epoch: 6| Step: 10
Training loss: 0.9829601049423218
Validation loss: 2.0281876517880346

Epoch: 6| Step: 11
Training loss: 1.3732866048812866
Validation loss: 2.0672753600664038

Epoch: 6| Step: 12
Training loss: 1.8004429340362549
Validation loss: 2.0744916469820085

Epoch: 6| Step: 13
Training loss: 0.6244044899940491
Validation loss: 2.0922087007953274

Epoch: 302| Step: 0
Training loss: 1.4392008781433105
Validation loss: 2.08522859696419

Epoch: 6| Step: 1
Training loss: 1.8406916856765747
Validation loss: 2.0602237229706137

Epoch: 6| Step: 2
Training loss: 1.3891125917434692
Validation loss: 2.042496713258887

Epoch: 6| Step: 3
Training loss: 1.2978034019470215
Validation loss: 2.0094671582662933

Epoch: 6| Step: 4
Training loss: 1.2417320013046265
Validation loss: 2.0095974117197017

Epoch: 6| Step: 5
Training loss: 0.8796979188919067
Validation loss: 1.9850808638398365

Epoch: 6| Step: 6
Training loss: 1.1640822887420654
Validation loss: 2.0256772502776115

Epoch: 6| Step: 7
Training loss: 1.1327513456344604
Validation loss: 2.0319541936279624

Epoch: 6| Step: 8
Training loss: 1.2647346258163452
Validation loss: 2.073915321339843

Epoch: 6| Step: 9
Training loss: 1.0633223056793213
Validation loss: 2.0838405393785044

Epoch: 6| Step: 10
Training loss: 1.3169622421264648
Validation loss: 2.096594665640144

Epoch: 6| Step: 11
Training loss: 1.5352959632873535
Validation loss: 2.084944304599557

Epoch: 6| Step: 12
Training loss: 1.477207899093628
Validation loss: 2.075579986777357

Epoch: 6| Step: 13
Training loss: 1.6475472450256348
Validation loss: 2.0878211452114965

Epoch: 303| Step: 0
Training loss: 0.8458880186080933
Validation loss: 2.0388666352918072

Epoch: 6| Step: 1
Training loss: 1.3364851474761963
Validation loss: 2.0116199703626734

Epoch: 6| Step: 2
Training loss: 1.6567764282226562
Validation loss: 2.0075990076987975

Epoch: 6| Step: 3
Training loss: 1.7613060474395752
Validation loss: 1.9984233340909403

Epoch: 6| Step: 4
Training loss: 1.863924264907837
Validation loss: 1.9910681145165556

Epoch: 6| Step: 5
Training loss: 1.2137014865875244
Validation loss: 1.9744167353517266

Epoch: 6| Step: 6
Training loss: 0.9604595899581909
Validation loss: 1.9662017053173435

Epoch: 6| Step: 7
Training loss: 1.236891508102417
Validation loss: 1.9856782651716662

Epoch: 6| Step: 8
Training loss: 0.9772981405258179
Validation loss: 2.017378373812604

Epoch: 6| Step: 9
Training loss: 1.2732257843017578
Validation loss: 1.9983070742699407

Epoch: 6| Step: 10
Training loss: 1.2835766077041626
Validation loss: 2.047260921488526

Epoch: 6| Step: 11
Training loss: 1.4350640773773193
Validation loss: 2.0621010744443504

Epoch: 6| Step: 12
Training loss: 1.2172566652297974
Validation loss: 2.0509795258122105

Epoch: 6| Step: 13
Training loss: 1.3624722957611084
Validation loss: 2.061893747698876

Epoch: 304| Step: 0
Training loss: 1.089683175086975
Validation loss: 2.067329029883108

Epoch: 6| Step: 1
Training loss: 1.936777114868164
Validation loss: 2.06601575369476

Epoch: 6| Step: 2
Training loss: 1.8456937074661255
Validation loss: 2.0726662489675705

Epoch: 6| Step: 3
Training loss: 1.0520660877227783
Validation loss: 2.059899244257199

Epoch: 6| Step: 4
Training loss: 0.9600266218185425
Validation loss: 2.0676757917609265

Epoch: 6| Step: 5
Training loss: 1.5286495685577393
Validation loss: 2.041755396832702

Epoch: 6| Step: 6
Training loss: 1.1471426486968994
Validation loss: 2.0806860500766384

Epoch: 6| Step: 7
Training loss: 0.9432145357131958
Validation loss: 2.0084943297088786

Epoch: 6| Step: 8
Training loss: 1.1525335311889648
Validation loss: 2.054931625243156

Epoch: 6| Step: 9
Training loss: 1.4953811168670654
Validation loss: 2.0371247517165316

Epoch: 6| Step: 10
Training loss: 1.321825623512268
Validation loss: 2.0327076168470484

Epoch: 6| Step: 11
Training loss: 1.3649928569793701
Validation loss: 2.0222325965922368

Epoch: 6| Step: 12
Training loss: 1.1922307014465332
Validation loss: 2.0113311326631935

Epoch: 6| Step: 13
Training loss: 1.3802604675292969
Validation loss: 2.004956579977466

Epoch: 305| Step: 0
Training loss: 1.462815284729004
Validation loss: 2.0613248873782415

Epoch: 6| Step: 1
Training loss: 0.4872502088546753
Validation loss: 2.0474456176962903

Epoch: 6| Step: 2
Training loss: 1.4190376996994019
Validation loss: 2.0707341368480394

Epoch: 6| Step: 3
Training loss: 0.8491830825805664
Validation loss: 2.0358021515671925

Epoch: 6| Step: 4
Training loss: 1.8428981304168701
Validation loss: 2.057032444143808

Epoch: 6| Step: 5
Training loss: 1.3344186544418335
Validation loss: 2.0234810216452486

Epoch: 6| Step: 6
Training loss: 1.3625268936157227
Validation loss: 2.010074516778351

Epoch: 6| Step: 7
Training loss: 1.929499626159668
Validation loss: 2.0044560035069785

Epoch: 6| Step: 8
Training loss: 0.9953442215919495
Validation loss: 2.0000976952173377

Epoch: 6| Step: 9
Training loss: 0.7361558675765991
Validation loss: 2.004612829095574

Epoch: 6| Step: 10
Training loss: 1.82112717628479
Validation loss: 1.9684543032799997

Epoch: 6| Step: 11
Training loss: 1.5698659420013428
Validation loss: 1.998388804415221

Epoch: 6| Step: 12
Training loss: 1.4797306060791016
Validation loss: 1.9996959137660202

Epoch: 6| Step: 13
Training loss: 0.8784210085868835
Validation loss: 2.020153005917867

Epoch: 306| Step: 0
Training loss: 1.4146947860717773
Validation loss: 2.006473982205955

Epoch: 6| Step: 1
Training loss: 1.148085355758667
Validation loss: 2.0052531919171734

Epoch: 6| Step: 2
Training loss: 1.1063659191131592
Validation loss: 2.0606718999083324

Epoch: 6| Step: 3
Training loss: 1.5962649583816528
Validation loss: 2.046255701331682

Epoch: 6| Step: 4
Training loss: 0.8959177732467651
Validation loss: 2.059572422376243

Epoch: 6| Step: 5
Training loss: 1.3033289909362793
Validation loss: 2.0572757362037577

Epoch: 6| Step: 6
Training loss: 1.0353463888168335
Validation loss: 2.0819684305498676

Epoch: 6| Step: 7
Training loss: 1.2336933612823486
Validation loss: 2.040075335451352

Epoch: 6| Step: 8
Training loss: 1.4484866857528687
Validation loss: 2.0413398204311246

Epoch: 6| Step: 9
Training loss: 1.6281812191009521
Validation loss: 2.0677716732025146

Epoch: 6| Step: 10
Training loss: 1.5230433940887451
Validation loss: 2.028208012221962

Epoch: 6| Step: 11
Training loss: 1.087245225906372
Validation loss: 2.000369450097443

Epoch: 6| Step: 12
Training loss: 1.228400468826294
Validation loss: 1.9754576862499278

Epoch: 6| Step: 13
Training loss: 1.3519667387008667
Validation loss: 1.972937249368237

Epoch: 307| Step: 0
Training loss: 1.0836254358291626
Validation loss: 1.957813214230281

Epoch: 6| Step: 1
Training loss: 0.9449170231819153
Validation loss: 1.9394796279168898

Epoch: 6| Step: 2
Training loss: 0.8081743717193604
Validation loss: 1.9508013148461618

Epoch: 6| Step: 3
Training loss: 1.271462321281433
Validation loss: 1.9444087871941187

Epoch: 6| Step: 4
Training loss: 1.4192852973937988
Validation loss: 1.942648762015886

Epoch: 6| Step: 5
Training loss: 1.8919219970703125
Validation loss: 1.9558193119623328

Epoch: 6| Step: 6
Training loss: 1.4902700185775757
Validation loss: 1.9622368786924629

Epoch: 6| Step: 7
Training loss: 1.434516429901123
Validation loss: 1.982009780022406

Epoch: 6| Step: 8
Training loss: 0.9974867701530457
Validation loss: 1.9983706346122168

Epoch: 6| Step: 9
Training loss: 1.445539951324463
Validation loss: 1.9850472263110581

Epoch: 6| Step: 10
Training loss: 1.19729483127594
Validation loss: 2.0116160197924544

Epoch: 6| Step: 11
Training loss: 1.467112421989441
Validation loss: 2.0129279987786406

Epoch: 6| Step: 12
Training loss: 0.9679015874862671
Validation loss: 2.009188873793489

Epoch: 6| Step: 13
Training loss: 1.4637116193771362
Validation loss: 2.0032261827940583

Epoch: 308| Step: 0
Training loss: 1.0422505140304565
Validation loss: 1.9916941055687525

Epoch: 6| Step: 1
Training loss: 1.4513211250305176
Validation loss: 1.9996518204289098

Epoch: 6| Step: 2
Training loss: 1.0455149412155151
Validation loss: 2.0084932234979447

Epoch: 6| Step: 3
Training loss: 1.0957398414611816
Validation loss: 1.9634183940067087

Epoch: 6| Step: 4
Training loss: 1.5024914741516113
Validation loss: 2.008077850905798

Epoch: 6| Step: 5
Training loss: 1.70291006565094
Validation loss: 2.0016824699217275

Epoch: 6| Step: 6
Training loss: 1.7905172109603882
Validation loss: 1.970955205220048

Epoch: 6| Step: 7
Training loss: 1.0848428010940552
Validation loss: 2.006371990326912

Epoch: 6| Step: 8
Training loss: 0.8214457035064697
Validation loss: 2.0222784524322837

Epoch: 6| Step: 9
Training loss: 1.7149572372436523
Validation loss: 2.015164457341676

Epoch: 6| Step: 10
Training loss: 1.323549747467041
Validation loss: 2.0424210691964753

Epoch: 6| Step: 11
Training loss: 0.7855284810066223
Validation loss: 2.039034999826903

Epoch: 6| Step: 12
Training loss: 0.9301548600196838
Validation loss: 2.055080707355212

Epoch: 6| Step: 13
Training loss: 1.249963402748108
Validation loss: 2.0408351088082917

Epoch: 309| Step: 0
Training loss: 2.0448436737060547
Validation loss: 2.042206504011667

Epoch: 6| Step: 1
Training loss: 1.5022547245025635
Validation loss: 2.0121213979618524

Epoch: 6| Step: 2
Training loss: 1.0421147346496582
Validation loss: 2.000262419382731

Epoch: 6| Step: 3
Training loss: 0.9595178365707397
Validation loss: 1.9365655504247195

Epoch: 6| Step: 4
Training loss: 1.342735767364502
Validation loss: 1.9433001702831638

Epoch: 6| Step: 5
Training loss: 0.8713569045066833
Validation loss: 1.9580898387457735

Epoch: 6| Step: 6
Training loss: 1.18010413646698
Validation loss: 1.944013198216756

Epoch: 6| Step: 7
Training loss: 1.692363977432251
Validation loss: 1.9653495537337435

Epoch: 6| Step: 8
Training loss: 0.7408356666564941
Validation loss: 1.9519050890399563

Epoch: 6| Step: 9
Training loss: 1.2479535341262817
Validation loss: 1.9668596957319526

Epoch: 6| Step: 10
Training loss: 1.509771466255188
Validation loss: 1.976718584696452

Epoch: 6| Step: 11
Training loss: 1.4972875118255615
Validation loss: 2.0202256377025316

Epoch: 6| Step: 12
Training loss: 0.9067573547363281
Validation loss: 2.0280808684646443

Epoch: 6| Step: 13
Training loss: 1.3521314859390259
Validation loss: 2.0815518492011615

Epoch: 310| Step: 0
Training loss: 1.121700406074524
Validation loss: 2.0857394600427277

Epoch: 6| Step: 1
Training loss: 1.1082806587219238
Validation loss: 2.0539874415243826

Epoch: 6| Step: 2
Training loss: 1.0167837142944336
Validation loss: 2.043357608138874

Epoch: 6| Step: 3
Training loss: 1.3921120166778564
Validation loss: 2.03164803981781

Epoch: 6| Step: 4
Training loss: 1.6376228332519531
Validation loss: 2.0241135448537846

Epoch: 6| Step: 5
Training loss: 0.8845940232276917
Validation loss: 1.9901643824833695

Epoch: 6| Step: 6
Training loss: 1.3977727890014648
Validation loss: 1.953605044272638

Epoch: 6| Step: 7
Training loss: 1.539600133895874
Validation loss: 1.9725148652189521

Epoch: 6| Step: 8
Training loss: 1.5275599956512451
Validation loss: 1.9428279963872765

Epoch: 6| Step: 9
Training loss: 0.9159799218177795
Validation loss: 1.919531089003368

Epoch: 6| Step: 10
Training loss: 1.2534422874450684
Validation loss: 1.938663867212111

Epoch: 6| Step: 11
Training loss: 1.315285086631775
Validation loss: 1.9497624622878207

Epoch: 6| Step: 12
Training loss: 1.2270084619522095
Validation loss: 1.9381782034391999

Epoch: 6| Step: 13
Training loss: 1.2814072370529175
Validation loss: 1.9577986091695807

Epoch: 311| Step: 0
Training loss: 1.2973887920379639
Validation loss: 1.9831890880420644

Epoch: 6| Step: 1
Training loss: 0.9904357194900513
Validation loss: 1.988818448076966

Epoch: 6| Step: 2
Training loss: 1.4136061668395996
Validation loss: 2.003586447367104

Epoch: 6| Step: 3
Training loss: 0.927893340587616
Validation loss: 1.9995688571724841

Epoch: 6| Step: 4
Training loss: 1.246781587600708
Validation loss: 1.9995644054105204

Epoch: 6| Step: 5
Training loss: 1.3297741413116455
Validation loss: 1.986407236386371

Epoch: 6| Step: 6
Training loss: 0.9920674562454224
Validation loss: 1.9986004291042205

Epoch: 6| Step: 7
Training loss: 1.984217882156372
Validation loss: 1.9683463958001906

Epoch: 6| Step: 8
Training loss: 1.3644462823867798
Validation loss: 1.9938690995657316

Epoch: 6| Step: 9
Training loss: 1.005359411239624
Validation loss: 1.997393633729668

Epoch: 6| Step: 10
Training loss: 1.7106531858444214
Validation loss: 2.0020524135199924

Epoch: 6| Step: 11
Training loss: 0.5994652509689331
Validation loss: 2.000223425126845

Epoch: 6| Step: 12
Training loss: 1.3999760150909424
Validation loss: 1.9884850491759598

Epoch: 6| Step: 13
Training loss: 0.7338131666183472
Validation loss: 1.9840259193092264

Epoch: 312| Step: 0
Training loss: 1.1040165424346924
Validation loss: 2.0037185684327157

Epoch: 6| Step: 1
Training loss: 1.6497846841812134
Validation loss: 2.032343849059074

Epoch: 6| Step: 2
Training loss: 0.5093904137611389
Validation loss: 1.9790198623493154

Epoch: 6| Step: 3
Training loss: 1.3834203481674194
Validation loss: 1.972688982563634

Epoch: 6| Step: 4
Training loss: 1.6050939559936523
Validation loss: 2.015703196166664

Epoch: 6| Step: 5
Training loss: 0.8169340491294861
Validation loss: 1.991153101767263

Epoch: 6| Step: 6
Training loss: 0.9531000852584839
Validation loss: 2.0092128694698377

Epoch: 6| Step: 7
Training loss: 1.7474335432052612
Validation loss: 1.987315554772654

Epoch: 6| Step: 8
Training loss: 1.3072268962860107
Validation loss: 2.018944227567283

Epoch: 6| Step: 9
Training loss: 1.1576297283172607
Validation loss: 1.9947026596274426

Epoch: 6| Step: 10
Training loss: 1.204478144645691
Validation loss: 1.9852246494703396

Epoch: 6| Step: 11
Training loss: 1.8500688076019287
Validation loss: 1.9455292891430598

Epoch: 6| Step: 12
Training loss: 1.3078948259353638
Validation loss: 1.9424402367684148

Epoch: 6| Step: 13
Training loss: 0.38979992270469666
Validation loss: 1.974972104513517

Epoch: 313| Step: 0
Training loss: 0.8453846573829651
Validation loss: 1.9729858008764123

Epoch: 6| Step: 1
Training loss: 0.9910519123077393
Validation loss: 1.9416221751961658

Epoch: 6| Step: 2
Training loss: 1.221397876739502
Validation loss: 1.999051050473285

Epoch: 6| Step: 3
Training loss: 1.701493501663208
Validation loss: 1.9866235563831944

Epoch: 6| Step: 4
Training loss: 1.4470051527023315
Validation loss: 2.0185433305719847

Epoch: 6| Step: 5
Training loss: 0.7856490015983582
Validation loss: 2.0450594655929075

Epoch: 6| Step: 6
Training loss: 1.2213060855865479
Validation loss: 2.064435593543514

Epoch: 6| Step: 7
Training loss: 1.3397488594055176
Validation loss: 2.0286711672300934

Epoch: 6| Step: 8
Training loss: 1.0383715629577637
Validation loss: 2.0200219987541117

Epoch: 6| Step: 9
Training loss: 1.6237616539001465
Validation loss: 2.0128718794033094

Epoch: 6| Step: 10
Training loss: 1.0567057132720947
Validation loss: 2.0042144662590435

Epoch: 6| Step: 11
Training loss: 1.147821068763733
Validation loss: 1.9842806452064103

Epoch: 6| Step: 12
Training loss: 1.7297825813293457
Validation loss: 1.9726649817600046

Epoch: 6| Step: 13
Training loss: 1.3577966690063477
Validation loss: 1.9800264860994072

Epoch: 314| Step: 0
Training loss: 1.5814080238342285
Validation loss: 1.996885061264038

Epoch: 6| Step: 1
Training loss: 0.584650993347168
Validation loss: 2.0410534617721394

Epoch: 6| Step: 2
Training loss: 0.978435754776001
Validation loss: 2.0429445466687604

Epoch: 6| Step: 3
Training loss: 1.7647494077682495
Validation loss: 2.0373873684995916

Epoch: 6| Step: 4
Training loss: 1.14072847366333
Validation loss: 2.0172414574571835

Epoch: 6| Step: 5
Training loss: 1.0521373748779297
Validation loss: 1.9942789949396604

Epoch: 6| Step: 6
Training loss: 1.0760197639465332
Validation loss: 2.0029802348024104

Epoch: 6| Step: 7
Training loss: 0.7179920673370361
Validation loss: 1.9642969728797994

Epoch: 6| Step: 8
Training loss: 1.586849331855774
Validation loss: 1.9546683090989307

Epoch: 6| Step: 9
Training loss: 1.780564546585083
Validation loss: 1.993771597903262

Epoch: 6| Step: 10
Training loss: 0.9838742017745972
Validation loss: 1.9553146336668281

Epoch: 6| Step: 11
Training loss: 1.3191903829574585
Validation loss: 1.9880598296401322

Epoch: 6| Step: 12
Training loss: 1.955571174621582
Validation loss: 2.003126882737683

Epoch: 6| Step: 13
Training loss: 0.7525421977043152
Validation loss: 2.0105800346661638

Epoch: 315| Step: 0
Training loss: 1.0752445459365845
Validation loss: 2.0081403845099994

Epoch: 6| Step: 1
Training loss: 1.5509246587753296
Validation loss: 2.0031142850076

Epoch: 6| Step: 2
Training loss: 1.1422168016433716
Validation loss: 2.0318455080832205

Epoch: 6| Step: 3
Training loss: 1.2539112567901611
Validation loss: 1.9994713311554284

Epoch: 6| Step: 4
Training loss: 1.2700345516204834
Validation loss: 2.005139729028107

Epoch: 6| Step: 5
Training loss: 1.1035795211791992
Validation loss: 1.9922491132572133

Epoch: 6| Step: 6
Training loss: 1.4921197891235352
Validation loss: 1.967073896879791

Epoch: 6| Step: 7
Training loss: 0.9047547578811646
Validation loss: 1.9802325258972824

Epoch: 6| Step: 8
Training loss: 0.9657089710235596
Validation loss: 1.9602832717280234

Epoch: 6| Step: 9
Training loss: 1.5268712043762207
Validation loss: 1.9797018163947648

Epoch: 6| Step: 10
Training loss: 1.6681581735610962
Validation loss: 1.966662222339261

Epoch: 6| Step: 11
Training loss: 1.0730369091033936
Validation loss: 1.9802300160931003

Epoch: 6| Step: 12
Training loss: 1.2357982397079468
Validation loss: 1.9850625761093632

Epoch: 6| Step: 13
Training loss: 0.8860849738121033
Validation loss: 1.9708154688599289

Epoch: 316| Step: 0
Training loss: 0.7069873809814453
Validation loss: 2.03023878476953

Epoch: 6| Step: 1
Training loss: 1.46919584274292
Validation loss: 2.0585311664048063

Epoch: 6| Step: 2
Training loss: 0.9890084862709045
Validation loss: 2.1038192895150956

Epoch: 6| Step: 3
Training loss: 0.7881698608398438
Validation loss: 2.0826466621891147

Epoch: 6| Step: 4
Training loss: 1.2826752662658691
Validation loss: 2.046515789083255

Epoch: 6| Step: 5
Training loss: 1.253657579421997
Validation loss: 2.021950879404622

Epoch: 6| Step: 6
Training loss: 1.378905177116394
Validation loss: 2.0125721090583393

Epoch: 6| Step: 7
Training loss: 1.3106153011322021
Validation loss: 2.016759059762442

Epoch: 6| Step: 8
Training loss: 0.9432003498077393
Validation loss: 1.988408173284223

Epoch: 6| Step: 9
Training loss: 1.5489516258239746
Validation loss: 1.9703978671822497

Epoch: 6| Step: 10
Training loss: 0.8169463872909546
Validation loss: 1.9915915791706373

Epoch: 6| Step: 11
Training loss: 1.3061524629592896
Validation loss: 1.9829885882716025

Epoch: 6| Step: 12
Training loss: 1.8205833435058594
Validation loss: 1.9869968839870986

Epoch: 6| Step: 13
Training loss: 1.4400640726089478
Validation loss: 2.038409940658077

Epoch: 317| Step: 0
Training loss: 1.2414798736572266
Validation loss: 2.000148509138374

Epoch: 6| Step: 1
Training loss: 0.9743523597717285
Validation loss: 2.019617155034055

Epoch: 6| Step: 2
Training loss: 1.292566180229187
Validation loss: 2.013190428415934

Epoch: 6| Step: 3
Training loss: 1.4637701511383057
Validation loss: 2.0209177873467885

Epoch: 6| Step: 4
Training loss: 1.2822771072387695
Validation loss: 2.0333432984608475

Epoch: 6| Step: 5
Training loss: 1.5992913246154785
Validation loss: 2.020886944186303

Epoch: 6| Step: 6
Training loss: 0.8752672672271729
Validation loss: 2.03777705084893

Epoch: 6| Step: 7
Training loss: 1.2122197151184082
Validation loss: 1.9949021390689317

Epoch: 6| Step: 8
Training loss: 1.15827476978302
Validation loss: 1.964411667598191

Epoch: 6| Step: 9
Training loss: 1.0993540287017822
Validation loss: 1.959156438868533

Epoch: 6| Step: 10
Training loss: 1.091423511505127
Validation loss: 1.942500824569374

Epoch: 6| Step: 11
Training loss: 1.4280798435211182
Validation loss: 1.9202372463800574

Epoch: 6| Step: 12
Training loss: 1.1045289039611816
Validation loss: 1.9647266480230516

Epoch: 6| Step: 13
Training loss: 1.752072811126709
Validation loss: 1.9451679670682518

Epoch: 318| Step: 0
Training loss: 1.4248778820037842
Validation loss: 1.9542904592329455

Epoch: 6| Step: 1
Training loss: 1.0023713111877441
Validation loss: 1.969642113613826

Epoch: 6| Step: 2
Training loss: 1.3695389032363892
Validation loss: 2.0250952448896182

Epoch: 6| Step: 3
Training loss: 0.8925058841705322
Validation loss: 2.0251315152773293

Epoch: 6| Step: 4
Training loss: 1.4717503786087036
Validation loss: 2.0165316520198697

Epoch: 6| Step: 5
Training loss: 1.333858847618103
Validation loss: 2.0376642186154603

Epoch: 6| Step: 6
Training loss: 1.2764852046966553
Validation loss: 2.0287070274353027

Epoch: 6| Step: 7
Training loss: 1.2823905944824219
Validation loss: 1.9953209200213033

Epoch: 6| Step: 8
Training loss: 1.4613547325134277
Validation loss: 1.9748901885042909

Epoch: 6| Step: 9
Training loss: 0.9159436225891113
Validation loss: 1.975082428224625

Epoch: 6| Step: 10
Training loss: 0.8245087265968323
Validation loss: 1.9591708465289044

Epoch: 6| Step: 11
Training loss: 1.4592609405517578
Validation loss: 1.9823217750877462

Epoch: 6| Step: 12
Training loss: 0.8977352380752563
Validation loss: 1.9473287123505787

Epoch: 6| Step: 13
Training loss: 1.4599639177322388
Validation loss: 1.9615349256864159

Epoch: 319| Step: 0
Training loss: 1.1825437545776367
Validation loss: 1.9734235950695571

Epoch: 6| Step: 1
Training loss: 0.9443512558937073
Validation loss: 1.9878626151751446

Epoch: 6| Step: 2
Training loss: 1.2880222797393799
Validation loss: 2.0056327568587435

Epoch: 6| Step: 3
Training loss: 1.0657423734664917
Validation loss: 2.0049437258833196

Epoch: 6| Step: 4
Training loss: 0.8658256530761719
Validation loss: 2.0110044146096833

Epoch: 6| Step: 5
Training loss: 1.3709337711334229
Validation loss: 1.995134829193033

Epoch: 6| Step: 6
Training loss: 0.782833993434906
Validation loss: 1.9616755631662184

Epoch: 6| Step: 7
Training loss: 1.4306087493896484
Validation loss: 1.9473592119832193

Epoch: 6| Step: 8
Training loss: 0.920814037322998
Validation loss: 1.9425795027004775

Epoch: 6| Step: 9
Training loss: 1.1791173219680786
Validation loss: 1.9191517919622443

Epoch: 6| Step: 10
Training loss: 1.4793891906738281
Validation loss: 1.9237093643475605

Epoch: 6| Step: 11
Training loss: 1.564713716506958
Validation loss: 1.922358888451771

Epoch: 6| Step: 12
Training loss: 1.3071074485778809
Validation loss: 1.9406829264856154

Epoch: 6| Step: 13
Training loss: 2.3336713314056396
Validation loss: 1.9636146189064108

Epoch: 320| Step: 0
Training loss: 1.1274943351745605
Validation loss: 1.989463931770735

Epoch: 6| Step: 1
Training loss: 1.1781065464019775
Validation loss: 2.0130262118513866

Epoch: 6| Step: 2
Training loss: 0.8566972017288208
Validation loss: 2.0324569209929435

Epoch: 6| Step: 3
Training loss: 1.2059389352798462
Validation loss: 2.0517194347996868

Epoch: 6| Step: 4
Training loss: 1.074613332748413
Validation loss: 2.056054974115023

Epoch: 6| Step: 5
Training loss: 1.1720751523971558
Validation loss: 2.0494693991958455

Epoch: 6| Step: 6
Training loss: 1.7277612686157227
Validation loss: 1.9978466187753985

Epoch: 6| Step: 7
Training loss: 0.8206732869148254
Validation loss: 2.011442989431402

Epoch: 6| Step: 8
Training loss: 1.056520700454712
Validation loss: 1.9931828129676081

Epoch: 6| Step: 9
Training loss: 1.5219664573669434
Validation loss: 1.9631329608219925

Epoch: 6| Step: 10
Training loss: 1.404369831085205
Validation loss: 1.9694624113780197

Epoch: 6| Step: 11
Training loss: 1.2278081178665161
Validation loss: 1.96594016398153

Epoch: 6| Step: 12
Training loss: 1.2464287281036377
Validation loss: 1.946763002744285

Epoch: 6| Step: 13
Training loss: 1.25106942653656
Validation loss: 1.9341532876414638

Epoch: 321| Step: 0
Training loss: 1.5784130096435547
Validation loss: 1.918714133642053

Epoch: 6| Step: 1
Training loss: 1.6253464221954346
Validation loss: 1.9264866280299362

Epoch: 6| Step: 2
Training loss: 0.8966364860534668
Validation loss: 1.9354820020737187

Epoch: 6| Step: 3
Training loss: 0.60503089427948
Validation loss: 1.9458507184059388

Epoch: 6| Step: 4
Training loss: 0.7539964914321899
Validation loss: 1.9560078779856365

Epoch: 6| Step: 5
Training loss: 1.0960347652435303
Validation loss: 1.9451722637299569

Epoch: 6| Step: 6
Training loss: 1.5178861618041992
Validation loss: 1.953117674396884

Epoch: 6| Step: 7
Training loss: 1.8476353883743286
Validation loss: 1.9562916499312206

Epoch: 6| Step: 8
Training loss: 1.6369855403900146
Validation loss: 1.9420429019517795

Epoch: 6| Step: 9
Training loss: 1.0477843284606934
Validation loss: 1.960228217545376

Epoch: 6| Step: 10
Training loss: 0.961268424987793
Validation loss: 1.9693502046728646

Epoch: 6| Step: 11
Training loss: 1.1991407871246338
Validation loss: 1.9764783587507022

Epoch: 6| Step: 12
Training loss: 1.091245412826538
Validation loss: 1.9885370474989696

Epoch: 6| Step: 13
Training loss: 0.9722809195518494
Validation loss: 2.0186065550773375

Epoch: 322| Step: 0
Training loss: 1.2768515348434448
Validation loss: 2.030428221148829

Epoch: 6| Step: 1
Training loss: 1.1718751192092896
Validation loss: 2.0138058072777203

Epoch: 6| Step: 2
Training loss: 1.1527166366577148
Validation loss: 2.0302028809824297

Epoch: 6| Step: 3
Training loss: 0.9640766382217407
Validation loss: 2.029036121983682

Epoch: 6| Step: 4
Training loss: 1.1865506172180176
Validation loss: 2.005226560818252

Epoch: 6| Step: 5
Training loss: 1.4853378534317017
Validation loss: 1.9916483202288229

Epoch: 6| Step: 6
Training loss: 0.8338563442230225
Validation loss: 1.9654173979195215

Epoch: 6| Step: 7
Training loss: 0.9697731137275696
Validation loss: 1.9351476289892708

Epoch: 6| Step: 8
Training loss: 1.67969810962677
Validation loss: 1.9430441779475058

Epoch: 6| Step: 9
Training loss: 1.257486343383789
Validation loss: 1.9563970399159256

Epoch: 6| Step: 10
Training loss: 1.4056546688079834
Validation loss: 1.9426678239658315

Epoch: 6| Step: 11
Training loss: 0.9657450318336487
Validation loss: 1.9401734798185286

Epoch: 6| Step: 12
Training loss: 1.1422473192214966
Validation loss: 1.9482315471095424

Epoch: 6| Step: 13
Training loss: 0.8875596523284912
Validation loss: 1.9597111389201174

Epoch: 323| Step: 0
Training loss: 0.9826768040657043
Validation loss: 1.9739909492513186

Epoch: 6| Step: 1
Training loss: 1.0632660388946533
Validation loss: 2.0050324778403006

Epoch: 6| Step: 2
Training loss: 1.23116135597229
Validation loss: 2.0244327822039203

Epoch: 6| Step: 3
Training loss: 1.2520251274108887
Validation loss: 1.9764372379549089

Epoch: 6| Step: 4
Training loss: 1.7981832027435303
Validation loss: 1.9708091020584106

Epoch: 6| Step: 5
Training loss: 0.6232728958129883
Validation loss: 1.9725283448414137

Epoch: 6| Step: 6
Training loss: 0.7885742783546448
Validation loss: 1.9473891283876152

Epoch: 6| Step: 7
Training loss: 1.2411242723464966
Validation loss: 1.9739626633223666

Epoch: 6| Step: 8
Training loss: 1.5530279874801636
Validation loss: 1.964595128131169

Epoch: 6| Step: 9
Training loss: 1.2957158088684082
Validation loss: 1.928136976816321

Epoch: 6| Step: 10
Training loss: 1.1440203189849854
Validation loss: 1.9256303900031633

Epoch: 6| Step: 11
Training loss: 1.7021832466125488
Validation loss: 1.9259391369358185

Epoch: 6| Step: 12
Training loss: 0.7961429953575134
Validation loss: 1.9218285417044034

Epoch: 6| Step: 13
Training loss: 0.6256751418113708
Validation loss: 1.929259248959121

Epoch: 324| Step: 0
Training loss: 1.1903278827667236
Validation loss: 1.9597663905030938

Epoch: 6| Step: 1
Training loss: 0.7994129657745361
Validation loss: 1.9581359727408296

Epoch: 6| Step: 2
Training loss: 1.7109864950180054
Validation loss: 1.9591266019369966

Epoch: 6| Step: 3
Training loss: 1.3058048486709595
Validation loss: 1.9736757124623945

Epoch: 6| Step: 4
Training loss: 1.3923979997634888
Validation loss: 1.9892978334939608

Epoch: 6| Step: 5
Training loss: 1.194129467010498
Validation loss: 1.9889915066380655

Epoch: 6| Step: 6
Training loss: 0.977354884147644
Validation loss: 1.992074534457217

Epoch: 6| Step: 7
Training loss: 1.0105820894241333
Validation loss: 1.951681766458737

Epoch: 6| Step: 8
Training loss: 1.207413911819458
Validation loss: 1.968667725081085

Epoch: 6| Step: 9
Training loss: 0.9466902017593384
Validation loss: 1.9137254684202132

Epoch: 6| Step: 10
Training loss: 1.7506794929504395
Validation loss: 1.9480768467790337

Epoch: 6| Step: 11
Training loss: 1.0949194431304932
Validation loss: 1.9519875203409502

Epoch: 6| Step: 12
Training loss: 0.8324145674705505
Validation loss: 1.975438738381991

Epoch: 6| Step: 13
Training loss: 0.6581445932388306
Validation loss: 1.99958295975962

Epoch: 325| Step: 0
Training loss: 1.204552412033081
Validation loss: 1.9978575398845058

Epoch: 6| Step: 1
Training loss: 1.0986278057098389
Validation loss: 2.0054792486211306

Epoch: 6| Step: 2
Training loss: 1.433074951171875
Validation loss: 2.022240464405347

Epoch: 6| Step: 3
Training loss: 0.841164231300354
Validation loss: 2.0214632788012104

Epoch: 6| Step: 4
Training loss: 0.96218341588974
Validation loss: 2.0447053255573397

Epoch: 6| Step: 5
Training loss: 1.2568787336349487
Validation loss: 2.0367624170036724

Epoch: 6| Step: 6
Training loss: 1.3395683765411377
Validation loss: 2.051800590689464

Epoch: 6| Step: 7
Training loss: 1.4537802934646606
Validation loss: 2.0493863987666305

Epoch: 6| Step: 8
Training loss: 1.4089510440826416
Validation loss: 2.0094648509897213

Epoch: 6| Step: 9
Training loss: 1.4929420948028564
Validation loss: 2.0068467099179506

Epoch: 6| Step: 10
Training loss: 0.6068993806838989
Validation loss: 1.9809333893560594

Epoch: 6| Step: 11
Training loss: 0.7734861373901367
Validation loss: 1.948933514215613

Epoch: 6| Step: 12
Training loss: 1.4018057584762573
Validation loss: 1.9515163475467312

Epoch: 6| Step: 13
Training loss: 1.1755605936050415
Validation loss: 1.9667171175761888

Epoch: 326| Step: 0
Training loss: 1.2165639400482178
Validation loss: 1.9673099235821796

Epoch: 6| Step: 1
Training loss: 1.3116347789764404
Validation loss: 1.9602530899868216

Epoch: 6| Step: 2
Training loss: 0.9377822279930115
Validation loss: 1.95790619491249

Epoch: 6| Step: 3
Training loss: 2.071897268295288
Validation loss: 1.9651026777041856

Epoch: 6| Step: 4
Training loss: 1.4600634574890137
Validation loss: 1.9857173709459202

Epoch: 6| Step: 5
Training loss: 0.531137228012085
Validation loss: 1.9545109066911923

Epoch: 6| Step: 6
Training loss: 0.7861553430557251
Validation loss: 1.944556910504577

Epoch: 6| Step: 7
Training loss: 0.9589742422103882
Validation loss: 1.976124289215252

Epoch: 6| Step: 8
Training loss: 1.1867845058441162
Validation loss: 1.9479314499003912

Epoch: 6| Step: 9
Training loss: 1.2896233797073364
Validation loss: 1.9295646964862783

Epoch: 6| Step: 10
Training loss: 1.1019790172576904
Validation loss: 1.9248344257313719

Epoch: 6| Step: 11
Training loss: 1.769510269165039
Validation loss: 1.9497244396517355

Epoch: 6| Step: 12
Training loss: 0.6431893110275269
Validation loss: 1.9599934713814848

Epoch: 6| Step: 13
Training loss: 0.7718784809112549
Validation loss: 2.007161917225007

Epoch: 327| Step: 0
Training loss: 1.150134801864624
Validation loss: 2.0271189699890795

Epoch: 6| Step: 1
Training loss: 0.9994401335716248
Validation loss: 2.0207728237234135

Epoch: 6| Step: 2
Training loss: 1.490114450454712
Validation loss: 2.0392987651209675

Epoch: 6| Step: 3
Training loss: 1.3026175498962402
Validation loss: 2.0362560979781614

Epoch: 6| Step: 4
Training loss: 1.4153797626495361
Validation loss: 2.0119560046862532

Epoch: 6| Step: 5
Training loss: 1.395009994506836
Validation loss: 2.010104553673857

Epoch: 6| Step: 6
Training loss: 0.8842142224311829
Validation loss: 1.99566932775641

Epoch: 6| Step: 7
Training loss: 0.8813211917877197
Validation loss: 1.9814650320237683

Epoch: 6| Step: 8
Training loss: 1.0932273864746094
Validation loss: 2.0017616800082627

Epoch: 6| Step: 9
Training loss: 0.7127747535705566
Validation loss: 1.9486943316716019

Epoch: 6| Step: 10
Training loss: 1.3786647319793701
Validation loss: 1.972848170547075

Epoch: 6| Step: 11
Training loss: 1.1757593154907227
Validation loss: 1.9670407733609598

Epoch: 6| Step: 12
Training loss: 1.2417411804199219
Validation loss: 1.9632701425142185

Epoch: 6| Step: 13
Training loss: 1.4955248832702637
Validation loss: 1.9207924540324877

Epoch: 328| Step: 0
Training loss: 0.7199112176895142
Validation loss: 1.946998942282892

Epoch: 6| Step: 1
Training loss: 1.4537421464920044
Validation loss: 1.9375964467243483

Epoch: 6| Step: 2
Training loss: 0.9162170886993408
Validation loss: 1.9563449070017824

Epoch: 6| Step: 3
Training loss: 0.8500786423683167
Validation loss: 1.9839856880967335

Epoch: 6| Step: 4
Training loss: 1.5346585512161255
Validation loss: 1.9920137236195226

Epoch: 6| Step: 5
Training loss: 0.9351010322570801
Validation loss: 1.990247090657552

Epoch: 6| Step: 6
Training loss: 1.3145594596862793
Validation loss: 1.9958258034080587

Epoch: 6| Step: 7
Training loss: 0.9546341896057129
Validation loss: 1.995488489827802

Epoch: 6| Step: 8
Training loss: 1.4755373001098633
Validation loss: 1.9754245768311203

Epoch: 6| Step: 9
Training loss: 1.1701648235321045
Validation loss: 2.0128614530768445

Epoch: 6| Step: 10
Training loss: 0.9378343224525452
Validation loss: 1.9954198868043962

Epoch: 6| Step: 11
Training loss: 1.4286305904388428
Validation loss: 1.976324999204246

Epoch: 6| Step: 12
Training loss: 1.4647152423858643
Validation loss: 1.979535912954679

Epoch: 6| Step: 13
Training loss: 1.0390985012054443
Validation loss: 1.9435188437020907

Epoch: 329| Step: 0
Training loss: 0.5420800447463989
Validation loss: 1.951322732433196

Epoch: 6| Step: 1
Training loss: 1.360205888748169
Validation loss: 1.985662373163367

Epoch: 6| Step: 2
Training loss: 1.1419892311096191
Validation loss: 1.9528951260351366

Epoch: 6| Step: 3
Training loss: 0.932864785194397
Validation loss: 1.9884563312735608

Epoch: 6| Step: 4
Training loss: 0.7782710194587708
Validation loss: 1.9693364186953473

Epoch: 6| Step: 5
Training loss: 1.2522227764129639
Validation loss: 1.998689805307696

Epoch: 6| Step: 6
Training loss: 1.2229540348052979
Validation loss: 2.0153718417690647

Epoch: 6| Step: 7
Training loss: 1.7185578346252441
Validation loss: 2.065360717875983

Epoch: 6| Step: 8
Training loss: 0.9396417737007141
Validation loss: 2.0609285908360637

Epoch: 6| Step: 9
Training loss: 1.177148461341858
Validation loss: 2.0750693505810154

Epoch: 6| Step: 10
Training loss: 1.0793633460998535
Validation loss: 2.0661041736602783

Epoch: 6| Step: 11
Training loss: 1.6471686363220215
Validation loss: 2.033858829928983

Epoch: 6| Step: 12
Training loss: 1.3609747886657715
Validation loss: 2.0243316978536625

Epoch: 6| Step: 13
Training loss: 1.2175400257110596
Validation loss: 1.9951396116646387

Epoch: 330| Step: 0
Training loss: 1.5170769691467285
Validation loss: 1.9782594737186228

Epoch: 6| Step: 1
Training loss: 1.393139362335205
Validation loss: 1.9875690655041767

Epoch: 6| Step: 2
Training loss: 0.9751731157302856
Validation loss: 1.9446451587061728

Epoch: 6| Step: 3
Training loss: 1.166356086730957
Validation loss: 1.9217395538924842

Epoch: 6| Step: 4
Training loss: 1.0187480449676514
Validation loss: 1.9376510663699078

Epoch: 6| Step: 5
Training loss: 1.405108094215393
Validation loss: 1.9362490587337042

Epoch: 6| Step: 6
Training loss: 1.4228525161743164
Validation loss: 1.9245518304968392

Epoch: 6| Step: 7
Training loss: 0.7484519481658936
Validation loss: 1.9573493401209514

Epoch: 6| Step: 8
Training loss: 1.3604987859725952
Validation loss: 1.9808710223884993

Epoch: 6| Step: 9
Training loss: 0.7161098122596741
Validation loss: 1.971259270944903

Epoch: 6| Step: 10
Training loss: 1.1174135208129883
Validation loss: 1.9865728885896745

Epoch: 6| Step: 11
Training loss: 1.3142597675323486
Validation loss: 2.0177292144426735

Epoch: 6| Step: 12
Training loss: 1.1043285131454468
Validation loss: 1.9962208796572942

Epoch: 6| Step: 13
Training loss: 0.9490788578987122
Validation loss: 1.9730953170407204

Epoch: 331| Step: 0
Training loss: 0.9274352788925171
Validation loss: 1.9397503188861314

Epoch: 6| Step: 1
Training loss: 1.2840197086334229
Validation loss: 1.9640080005891862

Epoch: 6| Step: 2
Training loss: 0.9339503645896912
Validation loss: 1.9720452831637474

Epoch: 6| Step: 3
Training loss: 1.2455157041549683
Validation loss: 1.9418990099301903

Epoch: 6| Step: 4
Training loss: 1.1170694828033447
Validation loss: 1.990428796378515

Epoch: 6| Step: 5
Training loss: 1.5184227228164673
Validation loss: 2.0150179914248887

Epoch: 6| Step: 6
Training loss: 1.546476125717163
Validation loss: 2.01110375952977

Epoch: 6| Step: 7
Training loss: 1.2501121759414673
Validation loss: 2.020935445703486

Epoch: 6| Step: 8
Training loss: 1.08925461769104
Validation loss: 2.011520661333556

Epoch: 6| Step: 9
Training loss: 0.9467552304267883
Validation loss: 2.040018363665509

Epoch: 6| Step: 10
Training loss: 1.3798167705535889
Validation loss: 1.9908200720305085

Epoch: 6| Step: 11
Training loss: 0.8194985389709473
Validation loss: 1.9937430915012155

Epoch: 6| Step: 12
Training loss: 0.7665187120437622
Validation loss: 1.9800881839567614

Epoch: 6| Step: 13
Training loss: 1.2497406005859375
Validation loss: 1.9657233915021342

Epoch: 332| Step: 0
Training loss: 1.3676180839538574
Validation loss: 1.9577215512593586

Epoch: 6| Step: 1
Training loss: 1.326648235321045
Validation loss: 1.9578732239302767

Epoch: 6| Step: 2
Training loss: 0.8485700488090515
Validation loss: 1.9666640553423154

Epoch: 6| Step: 3
Training loss: 1.1941707134246826
Validation loss: 1.95536018571546

Epoch: 6| Step: 4
Training loss: 0.7298769354820251
Validation loss: 1.9516745805740356

Epoch: 6| Step: 5
Training loss: 0.3220614492893219
Validation loss: 1.9482464277616112

Epoch: 6| Step: 6
Training loss: 1.9066963195800781
Validation loss: 1.979641201675579

Epoch: 6| Step: 7
Training loss: 0.8592432737350464
Validation loss: 1.9929791060827111

Epoch: 6| Step: 8
Training loss: 0.8401009440422058
Validation loss: 1.9654293829394924

Epoch: 6| Step: 9
Training loss: 1.3265187740325928
Validation loss: 1.951209011898246

Epoch: 6| Step: 10
Training loss: 1.0891830921173096
Validation loss: 1.9601191423272575

Epoch: 6| Step: 11
Training loss: 1.1642765998840332
Validation loss: 1.976694030146445

Epoch: 6| Step: 12
Training loss: 1.7567719221115112
Validation loss: 1.954502644077424

Epoch: 6| Step: 13
Training loss: 1.2349414825439453
Validation loss: 1.960230237694197

Epoch: 333| Step: 0
Training loss: 0.5424188375473022
Validation loss: 1.9703213937820927

Epoch: 6| Step: 1
Training loss: 0.810106098651886
Validation loss: 1.9644373052863664

Epoch: 6| Step: 2
Training loss: 0.6869488954544067
Validation loss: 1.9627509347854122

Epoch: 6| Step: 3
Training loss: 1.3825581073760986
Validation loss: 1.9865063275060346

Epoch: 6| Step: 4
Training loss: 1.0975555181503296
Validation loss: 1.9943169701483943

Epoch: 6| Step: 5
Training loss: 0.5667871832847595
Validation loss: 2.008863044041459

Epoch: 6| Step: 6
Training loss: 1.2670763731002808
Validation loss: 2.0148905631034606

Epoch: 6| Step: 7
Training loss: 0.824621319770813
Validation loss: 1.9813131209342711

Epoch: 6| Step: 8
Training loss: 1.0586873292922974
Validation loss: 1.9963681992664133

Epoch: 6| Step: 9
Training loss: 1.1917073726654053
Validation loss: 1.964305418793873

Epoch: 6| Step: 10
Training loss: 1.5719926357269287
Validation loss: 1.9547301902565906

Epoch: 6| Step: 11
Training loss: 1.4247336387634277
Validation loss: 1.9618875621467509

Epoch: 6| Step: 12
Training loss: 1.8400988578796387
Validation loss: 1.9596504883099628

Epoch: 6| Step: 13
Training loss: 1.8222249746322632
Validation loss: 1.9297000067208403

Epoch: 334| Step: 0
Training loss: 1.3546864986419678
Validation loss: 1.9430267580093876

Epoch: 6| Step: 1
Training loss: 1.2234828472137451
Validation loss: 1.9483095125485492

Epoch: 6| Step: 2
Training loss: 1.0094510316848755
Validation loss: 1.9949830783310758

Epoch: 6| Step: 3
Training loss: 1.0610121488571167
Validation loss: 1.9929277666153447

Epoch: 6| Step: 4
Training loss: 1.7719342708587646
Validation loss: 2.017279472402347

Epoch: 6| Step: 5
Training loss: 0.5288706421852112
Validation loss: 1.9940475417721657

Epoch: 6| Step: 6
Training loss: 0.4790555238723755
Validation loss: 1.9587959845860798

Epoch: 6| Step: 7
Training loss: 1.3203341960906982
Validation loss: 1.9891334925928423

Epoch: 6| Step: 8
Training loss: 1.1615879535675049
Validation loss: 1.9864799572575478

Epoch: 6| Step: 9
Training loss: 1.0096065998077393
Validation loss: 1.9526178016457507

Epoch: 6| Step: 10
Training loss: 1.4268940687179565
Validation loss: 1.935756657713203

Epoch: 6| Step: 11
Training loss: 0.7002890110015869
Validation loss: 1.951024519499912

Epoch: 6| Step: 12
Training loss: 1.1052320003509521
Validation loss: 1.9390278695732035

Epoch: 6| Step: 13
Training loss: 1.9321694374084473
Validation loss: 1.9606990993663829

Epoch: 335| Step: 0
Training loss: 0.7829107642173767
Validation loss: 1.9234777406979633

Epoch: 6| Step: 1
Training loss: 1.0148963928222656
Validation loss: 1.9261313138469573

Epoch: 6| Step: 2
Training loss: 1.0158592462539673
Validation loss: 1.9674204728936637

Epoch: 6| Step: 3
Training loss: 1.2697484493255615
Validation loss: 1.9891784485950266

Epoch: 6| Step: 4
Training loss: 1.4114418029785156
Validation loss: 1.964428473544377

Epoch: 6| Step: 5
Training loss: 1.1829497814178467
Validation loss: 2.0256531776920443

Epoch: 6| Step: 6
Training loss: 0.982132077217102
Validation loss: 2.0285729926119567

Epoch: 6| Step: 7
Training loss: 1.108830213546753
Validation loss: 2.0131332194933327

Epoch: 6| Step: 8
Training loss: 1.4082789421081543
Validation loss: 2.008292544272638

Epoch: 6| Step: 9
Training loss: 1.4194347858428955
Validation loss: 1.997040403786526

Epoch: 6| Step: 10
Training loss: 1.0260183811187744
Validation loss: 1.9669997256289247

Epoch: 6| Step: 11
Training loss: 0.6623222827911377
Validation loss: 1.975032994824071

Epoch: 6| Step: 12
Training loss: 0.821229100227356
Validation loss: 1.9682497568027948

Epoch: 6| Step: 13
Training loss: 1.8568795919418335
Validation loss: 1.998809806762203

Epoch: 336| Step: 0
Training loss: 0.6895924806594849
Validation loss: 1.9428966468380344

Epoch: 6| Step: 1
Training loss: 0.8754075765609741
Validation loss: 1.9579999933960617

Epoch: 6| Step: 2
Training loss: 0.9656544923782349
Validation loss: 1.9431542683673162

Epoch: 6| Step: 3
Training loss: 1.2330881357192993
Validation loss: 1.9921096729975876

Epoch: 6| Step: 4
Training loss: 1.0204638242721558
Validation loss: 1.9851236651020665

Epoch: 6| Step: 5
Training loss: 1.3388885259628296
Validation loss: 2.024362958887572

Epoch: 6| Step: 6
Training loss: 1.0813652276992798
Validation loss: 1.985326196557732

Epoch: 6| Step: 7
Training loss: 0.9386783242225647
Validation loss: 1.9938750036301152

Epoch: 6| Step: 8
Training loss: 1.8217337131500244
Validation loss: 1.9510072136438021

Epoch: 6| Step: 9
Training loss: 1.029329538345337
Validation loss: 1.9455438493400492

Epoch: 6| Step: 10
Training loss: 0.8228844404220581
Validation loss: 1.9337814418218469

Epoch: 6| Step: 11
Training loss: 0.8262673616409302
Validation loss: 1.9362935020077614

Epoch: 6| Step: 12
Training loss: 1.817633867263794
Validation loss: 1.9476872592843988

Epoch: 6| Step: 13
Training loss: 1.0501172542572021
Validation loss: 1.9217626587037118

Epoch: 337| Step: 0
Training loss: 1.2509806156158447
Validation loss: 1.9035637686329503

Epoch: 6| Step: 1
Training loss: 0.8324118256568909
Validation loss: 1.9158283049060452

Epoch: 6| Step: 2
Training loss: 1.2067044973373413
Validation loss: 1.9385847686439432

Epoch: 6| Step: 3
Training loss: 0.7089834213256836
Validation loss: 1.934890393287905

Epoch: 6| Step: 4
Training loss: 1.2056219577789307
Validation loss: 1.9635927625881728

Epoch: 6| Step: 5
Training loss: 1.133500337600708
Validation loss: 1.94360549219193

Epoch: 6| Step: 6
Training loss: 1.156118392944336
Validation loss: 2.0018250109047018

Epoch: 6| Step: 7
Training loss: 1.4575660228729248
Validation loss: 2.002906027660575

Epoch: 6| Step: 8
Training loss: 1.3033826351165771
Validation loss: 2.0089414722176007

Epoch: 6| Step: 9
Training loss: 0.8673554062843323
Validation loss: 2.022199192354756

Epoch: 6| Step: 10
Training loss: 1.0827553272247314
Validation loss: 1.986342466005715

Epoch: 6| Step: 11
Training loss: 1.2253397703170776
Validation loss: 1.9383576980201147

Epoch: 6| Step: 12
Training loss: 1.0620720386505127
Validation loss: 1.9200552907041324

Epoch: 6| Step: 13
Training loss: 1.33152174949646
Validation loss: 1.91605774048836

Epoch: 338| Step: 0
Training loss: 1.1680046319961548
Validation loss: 1.9002428182991602

Epoch: 6| Step: 1
Training loss: 1.052811861038208
Validation loss: 1.8653300757049232

Epoch: 6| Step: 2
Training loss: 1.2251832485198975
Validation loss: 1.9175594545179797

Epoch: 6| Step: 3
Training loss: 1.0195997953414917
Validation loss: 1.8963797323165401

Epoch: 6| Step: 4
Training loss: 1.437692403793335
Validation loss: 1.948882181157348

Epoch: 6| Step: 5
Training loss: 1.4149330854415894
Validation loss: 1.951031559257097

Epoch: 6| Step: 6
Training loss: 0.7898586392402649
Validation loss: 1.9932739837195284

Epoch: 6| Step: 7
Training loss: 0.6514188051223755
Validation loss: 1.9578281192369358

Epoch: 6| Step: 8
Training loss: 1.100830316543579
Validation loss: 1.9606655720741517

Epoch: 6| Step: 9
Training loss: 1.2402896881103516
Validation loss: 1.9715616087759695

Epoch: 6| Step: 10
Training loss: 1.3150116205215454
Validation loss: 1.9661394011589788

Epoch: 6| Step: 11
Training loss: 0.8525534272193909
Validation loss: 1.9682724193860126

Epoch: 6| Step: 12
Training loss: 0.9356424808502197
Validation loss: 1.9437440185136692

Epoch: 6| Step: 13
Training loss: 1.2091176509857178
Validation loss: 1.9661675550604378

Epoch: 339| Step: 0
Training loss: 0.6721132397651672
Validation loss: 1.9690553629270164

Epoch: 6| Step: 1
Training loss: 1.5285241603851318
Validation loss: 1.9943838670689573

Epoch: 6| Step: 2
Training loss: 1.3975794315338135
Validation loss: 1.9430658278926727

Epoch: 6| Step: 3
Training loss: 1.1676076650619507
Validation loss: 1.947385057326286

Epoch: 6| Step: 4
Training loss: 0.848647952079773
Validation loss: 1.94076826495509

Epoch: 6| Step: 5
Training loss: 1.0035344362258911
Validation loss: 1.9545215227270638

Epoch: 6| Step: 6
Training loss: 1.3064348697662354
Validation loss: 1.9139847652886504

Epoch: 6| Step: 7
Training loss: 1.090738296508789
Validation loss: 1.9446328288765364

Epoch: 6| Step: 8
Training loss: 1.1026053428649902
Validation loss: 1.957824158412154

Epoch: 6| Step: 9
Training loss: 1.497929573059082
Validation loss: 1.9167864796935872

Epoch: 6| Step: 10
Training loss: 0.961272656917572
Validation loss: 1.9186426029410413

Epoch: 6| Step: 11
Training loss: 0.997658371925354
Validation loss: 1.958349407360118

Epoch: 6| Step: 12
Training loss: 1.409975290298462
Validation loss: 1.9575175111011793

Epoch: 6| Step: 13
Training loss: 0.41797760128974915
Validation loss: 1.9751181115386307

Epoch: 340| Step: 0
Training loss: 0.6187914609909058
Validation loss: 2.001888382819391

Epoch: 6| Step: 1
Training loss: 1.2795746326446533
Validation loss: 2.0034816572743077

Epoch: 6| Step: 2
Training loss: 1.0505239963531494
Validation loss: 2.0168618079154723

Epoch: 6| Step: 3
Training loss: 0.9896185398101807
Validation loss: 2.036778529485067

Epoch: 6| Step: 4
Training loss: 1.0377098321914673
Validation loss: 2.0084578003934634

Epoch: 6| Step: 5
Training loss: 0.7692638635635376
Validation loss: 2.003277240260955

Epoch: 6| Step: 6
Training loss: 1.0108462572097778
Validation loss: 1.9639916727619786

Epoch: 6| Step: 7
Training loss: 1.1586235761642456
Validation loss: 1.9616533851110807

Epoch: 6| Step: 8
Training loss: 1.0830975770950317
Validation loss: 1.9033218353025374

Epoch: 6| Step: 9
Training loss: 0.9169701337814331
Validation loss: 1.885970204107223

Epoch: 6| Step: 10
Training loss: 0.9988653659820557
Validation loss: 1.8911737652235134

Epoch: 6| Step: 11
Training loss: 1.5201270580291748
Validation loss: 1.8872891010776642

Epoch: 6| Step: 12
Training loss: 1.819567322731018
Validation loss: 1.9032140931775492

Epoch: 6| Step: 13
Training loss: 1.388155221939087
Validation loss: 1.8681939007133566

Epoch: 341| Step: 0
Training loss: 0.718203067779541
Validation loss: 1.853540487186883

Epoch: 6| Step: 1
Training loss: 0.9110749363899231
Validation loss: 1.8956985858178907

Epoch: 6| Step: 2
Training loss: 0.9583843946456909
Validation loss: 1.9048844409245316

Epoch: 6| Step: 3
Training loss: 0.8031759858131409
Validation loss: 1.924885412698151

Epoch: 6| Step: 4
Training loss: 1.0261532068252563
Validation loss: 1.970142787502658

Epoch: 6| Step: 5
Training loss: 0.8338348269462585
Validation loss: 2.0143325610827376

Epoch: 6| Step: 6
Training loss: 1.4313099384307861
Validation loss: 1.9846692585176038

Epoch: 6| Step: 7
Training loss: 1.18892240524292
Validation loss: 2.033828878915438

Epoch: 6| Step: 8
Training loss: 1.3530336618423462
Validation loss: 2.019216496457336

Epoch: 6| Step: 9
Training loss: 1.0125572681427002
Validation loss: 2.030307956921157

Epoch: 6| Step: 10
Training loss: 1.3663597106933594
Validation loss: 2.0247044345384

Epoch: 6| Step: 11
Training loss: 1.4749010801315308
Validation loss: 2.008087282539696

Epoch: 6| Step: 12
Training loss: 1.075487732887268
Validation loss: 2.0027689523594354

Epoch: 6| Step: 13
Training loss: 0.6334501504898071
Validation loss: 1.9821605990009923

Epoch: 342| Step: 0
Training loss: 1.3678982257843018
Validation loss: 1.9643073081970215

Epoch: 6| Step: 1
Training loss: 1.1146562099456787
Validation loss: 1.9561513982793337

Epoch: 6| Step: 2
Training loss: 1.170048713684082
Validation loss: 1.9303318095463577

Epoch: 6| Step: 3
Training loss: 0.9088760614395142
Validation loss: 1.9568569801187004

Epoch: 6| Step: 4
Training loss: 0.9260656833648682
Validation loss: 1.9633787998589136

Epoch: 6| Step: 5
Training loss: 1.2223572731018066
Validation loss: 1.9318240099055792

Epoch: 6| Step: 6
Training loss: 1.2031292915344238
Validation loss: 1.960676916183964

Epoch: 6| Step: 7
Training loss: 1.259035587310791
Validation loss: 1.9672961042773338

Epoch: 6| Step: 8
Training loss: 1.127346396446228
Validation loss: 1.953239530645391

Epoch: 6| Step: 9
Training loss: 1.0456242561340332
Validation loss: 1.9315433348378828

Epoch: 6| Step: 10
Training loss: 1.3041435480117798
Validation loss: 1.9499066516917238

Epoch: 6| Step: 11
Training loss: 0.9290043711662292
Validation loss: 1.9294832432141868

Epoch: 6| Step: 12
Training loss: 0.731531023979187
Validation loss: 1.9708052117337462

Epoch: 6| Step: 13
Training loss: 0.43444278836250305
Validation loss: 1.9752731707788282

Epoch: 343| Step: 0
Training loss: 1.0125439167022705
Validation loss: 1.9640148608915267

Epoch: 6| Step: 1
Training loss: 1.1333317756652832
Validation loss: 1.9222276133875693

Epoch: 6| Step: 2
Training loss: 1.1022515296936035
Validation loss: 1.9180647775691042

Epoch: 6| Step: 3
Training loss: 1.5135844945907593
Validation loss: 1.9015560201419297

Epoch: 6| Step: 4
Training loss: 1.4858921766281128
Validation loss: 1.9071598655434066

Epoch: 6| Step: 5
Training loss: 1.3398151397705078
Validation loss: 1.9213411628559072

Epoch: 6| Step: 6
Training loss: 1.0827662944793701
Validation loss: 1.9440670782519924

Epoch: 6| Step: 7
Training loss: 0.40529513359069824
Validation loss: 1.9109901715350408

Epoch: 6| Step: 8
Training loss: 0.7837166786193848
Validation loss: 1.9676191217155867

Epoch: 6| Step: 9
Training loss: 1.3206396102905273
Validation loss: 1.9407065735068372

Epoch: 6| Step: 10
Training loss: 0.7333884835243225
Validation loss: 1.9714145301490702

Epoch: 6| Step: 11
Training loss: 1.09152352809906
Validation loss: 1.9788833997582878

Epoch: 6| Step: 12
Training loss: 0.7997527122497559
Validation loss: 1.9963401645742438

Epoch: 6| Step: 13
Training loss: 0.8471656441688538
Validation loss: 1.9976052571368474

Epoch: 344| Step: 0
Training loss: 0.7660342454910278
Validation loss: 1.968160178071709

Epoch: 6| Step: 1
Training loss: 1.5265161991119385
Validation loss: 1.954332451666555

Epoch: 6| Step: 2
Training loss: 1.321305751800537
Validation loss: 1.9396192924950713

Epoch: 6| Step: 3
Training loss: 0.9526183009147644
Validation loss: 1.971043909749677

Epoch: 6| Step: 4
Training loss: 0.8831931352615356
Validation loss: 1.9766974641430763

Epoch: 6| Step: 5
Training loss: 0.803270161151886
Validation loss: 1.925043708534651

Epoch: 6| Step: 6
Training loss: 1.1133065223693848
Validation loss: 1.912188144140346

Epoch: 6| Step: 7
Training loss: 0.9866915941238403
Validation loss: 1.9085220175404702

Epoch: 6| Step: 8
Training loss: 1.0937297344207764
Validation loss: 1.9269912396707842

Epoch: 6| Step: 9
Training loss: 1.4146167039871216
Validation loss: 1.9269835731034637

Epoch: 6| Step: 10
Training loss: 0.9751282930374146
Validation loss: 1.9540534301470684

Epoch: 6| Step: 11
Training loss: 1.152937412261963
Validation loss: 1.941997928004111

Epoch: 6| Step: 12
Training loss: 0.9390848278999329
Validation loss: 1.9429988232992028

Epoch: 6| Step: 13
Training loss: 0.7654903531074524
Validation loss: 1.9753559058712375

Epoch: 345| Step: 0
Training loss: 0.6209241151809692
Validation loss: 1.89812897610408

Epoch: 6| Step: 1
Training loss: 0.6392328143119812
Validation loss: 1.9115436102754326

Epoch: 6| Step: 2
Training loss: 1.1919431686401367
Validation loss: 1.893110736723869

Epoch: 6| Step: 3
Training loss: 1.3933179378509521
Validation loss: 1.8833132097798009

Epoch: 6| Step: 4
Training loss: 1.5583182573318481
Validation loss: 1.9082337451237503

Epoch: 6| Step: 5
Training loss: 1.0916457176208496
Validation loss: 1.9090921545541415

Epoch: 6| Step: 6
Training loss: 1.309187412261963
Validation loss: 1.9467323903114564

Epoch: 6| Step: 7
Training loss: 0.6676582098007202
Validation loss: 1.9486460890821231

Epoch: 6| Step: 8
Training loss: 1.3097279071807861
Validation loss: 1.9861974331640428

Epoch: 6| Step: 9
Training loss: 0.9423830509185791
Validation loss: 2.0117815899592575

Epoch: 6| Step: 10
Training loss: 0.37536704540252686
Validation loss: 1.991179048374135

Epoch: 6| Step: 11
Training loss: 1.5071923732757568
Validation loss: 2.0243236813493954

Epoch: 6| Step: 12
Training loss: 1.251720666885376
Validation loss: 1.9850714001604306

Epoch: 6| Step: 13
Training loss: 0.7644082903862
Validation loss: 1.9848060761728594

Epoch: 346| Step: 0
Training loss: 1.0571174621582031
Validation loss: 1.9740354194436023

Epoch: 6| Step: 1
Training loss: 1.1588525772094727
Validation loss: 1.9430966543894943

Epoch: 6| Step: 2
Training loss: 1.1168787479400635
Validation loss: 1.941089786509032

Epoch: 6| Step: 3
Training loss: 0.7492753863334656
Validation loss: 1.9388698788099392

Epoch: 6| Step: 4
Training loss: 0.6867512464523315
Validation loss: 1.9330246371607627

Epoch: 6| Step: 5
Training loss: 1.2151752710342407
Validation loss: 1.9486189990915277

Epoch: 6| Step: 6
Training loss: 1.106947422027588
Validation loss: 1.9441148427224928

Epoch: 6| Step: 7
Training loss: 1.005305528640747
Validation loss: 1.9551244974136353

Epoch: 6| Step: 8
Training loss: 1.881838321685791
Validation loss: 1.9721695530799128

Epoch: 6| Step: 9
Training loss: 1.6316654682159424
Validation loss: 1.9402892269114012

Epoch: 6| Step: 10
Training loss: 0.7934168577194214
Validation loss: 1.9746697551460677

Epoch: 6| Step: 11
Training loss: 0.4759814441204071
Validation loss: 1.9439489264642038

Epoch: 6| Step: 12
Training loss: 0.6852003335952759
Validation loss: 1.9777446228970763

Epoch: 6| Step: 13
Training loss: 0.8812597393989563
Validation loss: 1.9530490547098138

Epoch: 347| Step: 0
Training loss: 0.9747101664543152
Validation loss: 1.9830001015816965

Epoch: 6| Step: 1
Training loss: 0.7622077465057373
Validation loss: 2.013629300619966

Epoch: 6| Step: 2
Training loss: 1.2268245220184326
Validation loss: 2.0061589210264144

Epoch: 6| Step: 3
Training loss: 1.60579514503479
Validation loss: 1.9723319622778124

Epoch: 6| Step: 4
Training loss: 0.6868486404418945
Validation loss: 1.9734983136576991

Epoch: 6| Step: 5
Training loss: 0.9590862989425659
Validation loss: 1.9610264647391535

Epoch: 6| Step: 6
Training loss: 1.1058188676834106
Validation loss: 1.9345131612593127

Epoch: 6| Step: 7
Training loss: 1.4496028423309326
Validation loss: 1.9350168961350636

Epoch: 6| Step: 8
Training loss: 0.7089062929153442
Validation loss: 1.9513799682740243

Epoch: 6| Step: 9
Training loss: 0.8494035601615906
Validation loss: 1.949042402287965

Epoch: 6| Step: 10
Training loss: 1.1684930324554443
Validation loss: 1.9221510400054276

Epoch: 6| Step: 11
Training loss: 1.2745840549468994
Validation loss: 1.9392786128546602

Epoch: 6| Step: 12
Training loss: 0.6917942762374878
Validation loss: 1.9469302328683997

Epoch: 6| Step: 13
Training loss: 0.9007101058959961
Validation loss: 1.9094551455590032

Epoch: 348| Step: 0
Training loss: 0.8644648194313049
Validation loss: 1.9326342587829919

Epoch: 6| Step: 1
Training loss: 0.6688075065612793
Validation loss: 1.8935937214923162

Epoch: 6| Step: 2
Training loss: 1.0261763334274292
Validation loss: 1.9104418190576697

Epoch: 6| Step: 3
Training loss: 0.9632131457328796
Validation loss: 1.9047858791966592

Epoch: 6| Step: 4
Training loss: 0.7557253837585449
Validation loss: 1.9422794977823894

Epoch: 6| Step: 5
Training loss: 1.3987199068069458
Validation loss: 1.9188235459789154

Epoch: 6| Step: 6
Training loss: 1.22761869430542
Validation loss: 1.8924046229290705

Epoch: 6| Step: 7
Training loss: 1.043480396270752
Validation loss: 1.8923999827395204

Epoch: 6| Step: 8
Training loss: 1.2039552927017212
Validation loss: 1.916060104165026

Epoch: 6| Step: 9
Training loss: 0.9398052096366882
Validation loss: 1.952842677793195

Epoch: 6| Step: 10
Training loss: 1.325315237045288
Validation loss: 1.9207946843998407

Epoch: 6| Step: 11
Training loss: 0.9540907144546509
Validation loss: 1.9244930282715829

Epoch: 6| Step: 12
Training loss: 1.3139280080795288
Validation loss: 1.9490034195684618

Epoch: 6| Step: 13
Training loss: 0.8884485960006714
Validation loss: 1.9264044736021309

Epoch: 349| Step: 0
Training loss: 0.8359625339508057
Validation loss: 1.9672900169126448

Epoch: 6| Step: 1
Training loss: 0.7769473791122437
Validation loss: 1.9757523331590878

Epoch: 6| Step: 2
Training loss: 0.7754241228103638
Validation loss: 1.9874757105304348

Epoch: 6| Step: 3
Training loss: 1.216336727142334
Validation loss: 1.9862364389563119

Epoch: 6| Step: 4
Training loss: 1.3363430500030518
Validation loss: 1.9462086052022955

Epoch: 6| Step: 5
Training loss: 1.258530855178833
Validation loss: 1.9377097186221872

Epoch: 6| Step: 6
Training loss: 1.3638434410095215
Validation loss: 1.9353063721810617

Epoch: 6| Step: 7
Training loss: 1.1045751571655273
Validation loss: 1.924255540294032

Epoch: 6| Step: 8
Training loss: 1.0477535724639893
Validation loss: 1.9193773910563479

Epoch: 6| Step: 9
Training loss: 1.230583667755127
Validation loss: 1.9141598927077426

Epoch: 6| Step: 10
Training loss: 0.5630750060081482
Validation loss: 1.9173179147064046

Epoch: 6| Step: 11
Training loss: 1.1970773935317993
Validation loss: 1.8983735371661443

Epoch: 6| Step: 12
Training loss: 0.9318021535873413
Validation loss: 1.9600129870958225

Epoch: 6| Step: 13
Training loss: 0.7546856999397278
Validation loss: 1.9572012424468994

Epoch: 350| Step: 0
Training loss: 0.5281239748001099
Validation loss: 1.9601498547420706

Epoch: 6| Step: 1
Training loss: 0.7991160154342651
Validation loss: 1.9651315032794912

Epoch: 6| Step: 2
Training loss: 0.9462727308273315
Validation loss: 1.9633712307099374

Epoch: 6| Step: 3
Training loss: 1.2402383089065552
Validation loss: 1.9211644882796912

Epoch: 6| Step: 4
Training loss: 1.1519593000411987
Validation loss: 1.896055216430336

Epoch: 6| Step: 5
Training loss: 1.5234779119491577
Validation loss: 1.8794415740556614

Epoch: 6| Step: 6
Training loss: 1.0193250179290771
Validation loss: 1.8898651920339113

Epoch: 6| Step: 7
Training loss: 1.1031076908111572
Validation loss: 1.887792984644572

Epoch: 6| Step: 8
Training loss: 1.3368409872055054
Validation loss: 1.8811843433687765

Epoch: 6| Step: 9
Training loss: 1.006191372871399
Validation loss: 1.8846532170490553

Epoch: 6| Step: 10
Training loss: 1.1943681240081787
Validation loss: 1.9109144364633868

Epoch: 6| Step: 11
Training loss: 0.5640704035758972
Validation loss: 1.895021124552655

Epoch: 6| Step: 12
Training loss: 1.2642924785614014
Validation loss: 1.926327924574575

Epoch: 6| Step: 13
Training loss: 0.9354415535926819
Validation loss: 1.9469538837350824

Testing loss: 2.1416141271591185
