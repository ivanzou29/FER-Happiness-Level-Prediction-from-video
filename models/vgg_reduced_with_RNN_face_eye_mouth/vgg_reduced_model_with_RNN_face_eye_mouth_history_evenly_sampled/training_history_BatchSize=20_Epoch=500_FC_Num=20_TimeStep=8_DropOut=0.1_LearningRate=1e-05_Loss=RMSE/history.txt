Epoch: 1| Step: 0
Training loss: 5.9805478440230235
Validation loss: 5.792674925531111

Epoch: 5| Step: 1
Training loss: 5.871110643272436
Validation loss: 5.784194585741409

Epoch: 5| Step: 2
Training loss: 5.586104127759514
Validation loss: 5.775403014856429

Epoch: 5| Step: 3
Training loss: 5.961908543839583
Validation loss: 5.766450819425911

Epoch: 5| Step: 4
Training loss: 6.182880256827207
Validation loss: 5.757450461207975

Epoch: 5| Step: 5
Training loss: 5.573079538787716
Validation loss: 5.7482450962970955

Epoch: 5| Step: 6
Training loss: 6.887288710993189
Validation loss: 5.73809239205528

Epoch: 5| Step: 7
Training loss: 5.742412038552076
Validation loss: 5.727822076818016

Epoch: 5| Step: 8
Training loss: 6.092317226894479
Validation loss: 5.7162372069874285

Epoch: 5| Step: 9
Training loss: 5.125531983096117
Validation loss: 5.704029726556505

Epoch: 5| Step: 10
Training loss: 3.9094049759042617
Validation loss: 5.690594233192815

Epoch: 2| Step: 0
Training loss: 6.06794950035974
Validation loss: 5.677226978782845

Epoch: 5| Step: 1
Training loss: 4.517535481991779
Validation loss: 5.6620844254351885

Epoch: 5| Step: 2
Training loss: 6.201442230819175
Validation loss: 5.64754171656045

Epoch: 5| Step: 3
Training loss: 5.613365857595664
Validation loss: 5.62967957392512

Epoch: 5| Step: 4
Training loss: 4.854280702400234
Validation loss: 5.612593600198837

Epoch: 5| Step: 5
Training loss: 5.784754665121463
Validation loss: 5.59262192195296

Epoch: 5| Step: 6
Training loss: 5.4169553044027845
Validation loss: 5.573250107617521

Epoch: 5| Step: 7
Training loss: 6.015540976990317
Validation loss: 5.550965380035963

Epoch: 5| Step: 8
Training loss: 5.67466209178635
Validation loss: 5.527208946442631

Epoch: 5| Step: 9
Training loss: 5.742840497522151
Validation loss: 5.5027915120152935

Epoch: 5| Step: 10
Training loss: 5.787242526100682
Validation loss: 5.47644474815242

Epoch: 3| Step: 0
Training loss: 5.070924883569534
Validation loss: 5.447798565452441

Epoch: 5| Step: 1
Training loss: 5.448539664227127
Validation loss: 5.4193357449857835

Epoch: 5| Step: 2
Training loss: 5.983129625740045
Validation loss: 5.386970173929512

Epoch: 5| Step: 3
Training loss: 5.173475864813105
Validation loss: 5.3531823533305545

Epoch: 5| Step: 4
Training loss: 5.2257796586510885
Validation loss: 5.319355916113981

Epoch: 5| Step: 5
Training loss: 4.842760538744417
Validation loss: 5.282380683676211

Epoch: 5| Step: 6
Training loss: 5.27042412457298
Validation loss: 5.245154199745651

Epoch: 5| Step: 7
Training loss: 4.940810819795354
Validation loss: 5.205204854551144

Epoch: 5| Step: 8
Training loss: 4.58324284319703
Validation loss: 5.165005383405473

Epoch: 5| Step: 9
Training loss: 6.503070399556046
Validation loss: 5.123958232654751

Epoch: 5| Step: 10
Training loss: 5.182657578423961
Validation loss: 5.081433984136191

Epoch: 4| Step: 0
Training loss: 6.270876084833593
Validation loss: 5.037419727683033

Epoch: 5| Step: 1
Training loss: 4.450463071581841
Validation loss: 4.993908510402125

Epoch: 5| Step: 2
Training loss: 4.442341916476135
Validation loss: 4.951841167866848

Epoch: 5| Step: 3
Training loss: 4.133997035320309
Validation loss: 4.911187461000692

Epoch: 5| Step: 4
Training loss: 4.284162880886512
Validation loss: 4.875209386308178

Epoch: 5| Step: 5
Training loss: 5.626099034072056
Validation loss: 4.8378884693306725

Epoch: 5| Step: 6
Training loss: 5.747007503506614
Validation loss: 4.801236262543126

Epoch: 5| Step: 7
Training loss: 3.6872607654618963
Validation loss: 4.766627325757163

Epoch: 5| Step: 8
Training loss: 5.364573101540101
Validation loss: 4.734110225341595

Epoch: 5| Step: 9
Training loss: 4.489747978902881
Validation loss: 4.702332149874619

Epoch: 5| Step: 10
Training loss: 4.977723661385904
Validation loss: 4.671245922614242

Epoch: 5| Step: 0
Training loss: 3.9680082574189313
Validation loss: 4.641071111276438

Epoch: 5| Step: 1
Training loss: 4.187651901906137
Validation loss: 4.612898737604545

Epoch: 5| Step: 2
Training loss: 4.793150608433554
Validation loss: 4.583608639560077

Epoch: 5| Step: 3
Training loss: 4.441715655793259
Validation loss: 4.555114520070441

Epoch: 5| Step: 4
Training loss: 5.496949129976448
Validation loss: 4.532794948984951

Epoch: 5| Step: 5
Training loss: 5.010207438181417
Validation loss: 4.507260694127934

Epoch: 5| Step: 6
Training loss: 4.944149899133081
Validation loss: 4.482242422014557

Epoch: 5| Step: 7
Training loss: 5.071196257184476
Validation loss: 4.4577144419032235

Epoch: 5| Step: 8
Training loss: 4.001673586732303
Validation loss: 4.430976874045939

Epoch: 5| Step: 9
Training loss: 4.326147405757549
Validation loss: 4.410129392519542

Epoch: 5| Step: 10
Training loss: 4.195671875974661
Validation loss: 4.387848682032409

Epoch: 6| Step: 0
Training loss: 5.067693048384205
Validation loss: 4.365144383078058

Epoch: 5| Step: 1
Training loss: 3.7994986052753403
Validation loss: 4.34146570149935

Epoch: 5| Step: 2
Training loss: 4.596839333090514
Validation loss: 4.319342571934883

Epoch: 5| Step: 3
Training loss: 3.5052323059501718
Validation loss: 4.291888521081055

Epoch: 5| Step: 4
Training loss: 4.764216580750281
Validation loss: 4.2647124882330125

Epoch: 5| Step: 5
Training loss: 4.039262718683556
Validation loss: 4.239611662639296

Epoch: 5| Step: 6
Training loss: 4.867224532425832
Validation loss: 4.2192760119852535

Epoch: 5| Step: 7
Training loss: 4.205834178578051
Validation loss: 4.193880620027208

Epoch: 5| Step: 8
Training loss: 4.364841984601173
Validation loss: 4.169306075777979

Epoch: 5| Step: 9
Training loss: 3.7987838154147866
Validation loss: 4.142585719538495

Epoch: 5| Step: 10
Training loss: 4.774936671610997
Validation loss: 4.119964046327368

Epoch: 7| Step: 0
Training loss: 4.6375703873138185
Validation loss: 4.101179360085036

Epoch: 5| Step: 1
Training loss: 3.982378051576559
Validation loss: 4.08482252485046

Epoch: 5| Step: 2
Training loss: 4.0190336848107595
Validation loss: 4.074504715900838

Epoch: 5| Step: 3
Training loss: 3.353093293423166
Validation loss: 4.059466778392957

Epoch: 5| Step: 4
Training loss: 5.0467697463265075
Validation loss: 4.045667037181364

Epoch: 5| Step: 5
Training loss: 3.5516552410780315
Validation loss: 4.028166070584883

Epoch: 5| Step: 6
Training loss: 4.441965784208178
Validation loss: 4.012870611627968

Epoch: 5| Step: 7
Training loss: 4.101617838168356
Validation loss: 3.995204624979609

Epoch: 5| Step: 8
Training loss: 3.9120636669275
Validation loss: 3.9793315935523315

Epoch: 5| Step: 9
Training loss: 4.611086563187997
Validation loss: 3.960179023072807

Epoch: 5| Step: 10
Training loss: 3.9209255573859725
Validation loss: 3.9456780675995113

Epoch: 8| Step: 0
Training loss: 4.202986817765149
Validation loss: 3.935330802758889

Epoch: 5| Step: 1
Training loss: 3.682309393006013
Validation loss: 3.924804994498984

Epoch: 5| Step: 2
Training loss: 4.30407333839075
Validation loss: 3.9120469091330663

Epoch: 5| Step: 3
Training loss: 4.910273171962128
Validation loss: 3.8987207961021952

Epoch: 5| Step: 4
Training loss: 4.12743097978875
Validation loss: 3.884097872162501

Epoch: 5| Step: 5
Training loss: 2.799602010234749
Validation loss: 3.871860204639237

Epoch: 5| Step: 6
Training loss: 3.4022677880620407
Validation loss: 3.8648815185379912

Epoch: 5| Step: 7
Training loss: 4.117744306810408
Validation loss: 3.8565739229801785

Epoch: 5| Step: 8
Training loss: 3.812864817690362
Validation loss: 3.849753948318939

Epoch: 5| Step: 9
Training loss: 3.8579412723894664
Validation loss: 3.836244811457558

Epoch: 5| Step: 10
Training loss: 4.940652734050083
Validation loss: 3.826621504081895

Epoch: 9| Step: 0
Training loss: 4.14631969468082
Validation loss: 3.8175967701209506

Epoch: 5| Step: 1
Training loss: 3.8414134545498206
Validation loss: 3.8189457240309443

Epoch: 5| Step: 2
Training loss: 3.764323789301107
Validation loss: 3.8121773139256385

Epoch: 5| Step: 3
Training loss: 3.5303847341550165
Validation loss: 3.8025576662107485

Epoch: 5| Step: 4
Training loss: 3.625380660492313
Validation loss: 3.7913629008337146

Epoch: 5| Step: 5
Training loss: 3.6134919965989774
Validation loss: 3.7869064138826967

Epoch: 5| Step: 6
Training loss: 4.778188286132045
Validation loss: 3.7819127534499035

Epoch: 5| Step: 7
Training loss: 3.729311778621236
Validation loss: 3.7733367299770073

Epoch: 5| Step: 8
Training loss: 4.1932861435443
Validation loss: 3.769250218689008

Epoch: 5| Step: 9
Training loss: 3.5413040573890124
Validation loss: 3.758153377068433

Epoch: 5| Step: 10
Training loss: 4.678449718593669
Validation loss: 3.7532237754007656

Epoch: 10| Step: 0
Training loss: 4.309010738831279
Validation loss: 3.7475209399295046

Epoch: 5| Step: 1
Training loss: 3.2938208150761046
Validation loss: 3.7397594457851615

Epoch: 5| Step: 2
Training loss: 3.7811151906092153
Validation loss: 3.7389381604644445

Epoch: 5| Step: 3
Training loss: 4.38424294803755
Validation loss: 3.7342041260741716

Epoch: 5| Step: 4
Training loss: 3.8086295571233433
Validation loss: 3.723473693488052

Epoch: 5| Step: 5
Training loss: 3.940739585668617
Validation loss: 3.7211648503125123

Epoch: 5| Step: 6
Training loss: 3.6136777917963805
Validation loss: 3.7175989504102565

Epoch: 5| Step: 7
Training loss: 3.423074590406884
Validation loss: 3.714207728589414

Epoch: 5| Step: 8
Training loss: 3.52363413327604
Validation loss: 3.7089818300100235

Epoch: 5| Step: 9
Training loss: 4.225890044414368
Validation loss: 3.703910395780833

Epoch: 5| Step: 10
Training loss: 4.529342776152708
Validation loss: 3.7003758190560534

Epoch: 11| Step: 0
Training loss: 3.7161041592473545
Validation loss: 3.692841765546705

Epoch: 5| Step: 1
Training loss: 4.196173950633435
Validation loss: 3.6874848607584876

Epoch: 5| Step: 2
Training loss: 4.004324720890766
Validation loss: 3.683298874482592

Epoch: 5| Step: 3
Training loss: 2.916864842539598
Validation loss: 3.679532352643974

Epoch: 5| Step: 4
Training loss: 3.2393966244846673
Validation loss: 3.673400104174096

Epoch: 5| Step: 5
Training loss: 4.5257126220683555
Validation loss: 3.6701894479643604

Epoch: 5| Step: 6
Training loss: 3.4341294843892767
Validation loss: 3.6627548658272926

Epoch: 5| Step: 7
Training loss: 4.1314425009519224
Validation loss: 3.6600692289885655

Epoch: 5| Step: 8
Training loss: 4.518051182065632
Validation loss: 3.6541910641842947

Epoch: 5| Step: 9
Training loss: 3.3858776698087705
Validation loss: 3.6506732360806025

Epoch: 5| Step: 10
Training loss: 4.0588125072632035
Validation loss: 3.6519115291177826

Epoch: 12| Step: 0
Training loss: 3.9105589027665646
Validation loss: 3.6441791228334672

Epoch: 5| Step: 1
Training loss: 3.977422175386325
Validation loss: 3.639751998799021

Epoch: 5| Step: 2
Training loss: 3.3050958187277537
Validation loss: 3.633161159213007

Epoch: 5| Step: 3
Training loss: 3.216633665742402
Validation loss: 3.629811341120556

Epoch: 5| Step: 4
Training loss: 4.579689773980692
Validation loss: 3.630924447940107

Epoch: 5| Step: 5
Training loss: 3.6923151421166116
Validation loss: 3.621336492027669

Epoch: 5| Step: 6
Training loss: 4.491152649144752
Validation loss: 3.617648425754987

Epoch: 5| Step: 7
Training loss: 4.101719444541935
Validation loss: 3.614539774762611

Epoch: 5| Step: 8
Training loss: 3.1799002911272596
Validation loss: 3.611534039352726

Epoch: 5| Step: 9
Training loss: 3.6389935812478145
Validation loss: 3.6113296952732226

Epoch: 5| Step: 10
Training loss: 3.624528656932418
Validation loss: 3.606407856212119

Epoch: 13| Step: 0
Training loss: 4.061826209899166
Validation loss: 3.60398007621838

Epoch: 5| Step: 1
Training loss: 3.9801316347829747
Validation loss: 3.5984015124484654

Epoch: 5| Step: 2
Training loss: 4.024715598347665
Validation loss: 3.5975202289514723

Epoch: 5| Step: 3
Training loss: 3.80254164071642
Validation loss: 3.591582581238852

Epoch: 5| Step: 4
Training loss: 3.204658401781215
Validation loss: 3.5872259028944957

Epoch: 5| Step: 5
Training loss: 3.6788279831476007
Validation loss: 3.5840261943262033

Epoch: 5| Step: 6
Training loss: 3.657243381762059
Validation loss: 3.582696895833427

Epoch: 5| Step: 7
Training loss: 4.168929642634231
Validation loss: 3.5781661656074197

Epoch: 5| Step: 8
Training loss: 3.993926921621003
Validation loss: 3.5747224799413013

Epoch: 5| Step: 9
Training loss: 2.8076570989011045
Validation loss: 3.5717817374495473

Epoch: 5| Step: 10
Training loss: 4.091691526090125
Validation loss: 3.5702024279381774

Epoch: 14| Step: 0
Training loss: 3.97952142435579
Validation loss: 3.565489405078219

Epoch: 5| Step: 1
Training loss: 4.18519050337742
Validation loss: 3.5613876186364553

Epoch: 5| Step: 2
Training loss: 3.620793104807938
Validation loss: 3.559652898103226

Epoch: 5| Step: 3
Training loss: 3.2206126628915563
Validation loss: 3.5541915783812565

Epoch: 5| Step: 4
Training loss: 2.983767302790167
Validation loss: 3.5516656951199246

Epoch: 5| Step: 5
Training loss: 3.8923081277097213
Validation loss: 3.5522599758999935

Epoch: 5| Step: 6
Training loss: 3.3407092662778113
Validation loss: 3.55025722317617

Epoch: 5| Step: 7
Training loss: 3.5507329049926657
Validation loss: 3.545618164614448

Epoch: 5| Step: 8
Training loss: 4.368360222058511
Validation loss: 3.541669343709688

Epoch: 5| Step: 9
Training loss: 4.554669911790655
Validation loss: 3.5407854526921216

Epoch: 5| Step: 10
Training loss: 3.171805846113449
Validation loss: 3.53691528336455

Epoch: 15| Step: 0
Training loss: 4.363411077550389
Validation loss: 3.533075085878686

Epoch: 5| Step: 1
Training loss: 3.3515151227256736
Validation loss: 3.5302125388863885

Epoch: 5| Step: 2
Training loss: 3.0705266591479994
Validation loss: 3.524642491994947

Epoch: 5| Step: 3
Training loss: 4.188533370774991
Validation loss: 3.5270156556046195

Epoch: 5| Step: 4
Training loss: 4.0299361106029945
Validation loss: 3.5231283554423283

Epoch: 5| Step: 5
Training loss: 3.412076953194562
Validation loss: 3.5196498773328178

Epoch: 5| Step: 6
Training loss: 3.232353721430304
Validation loss: 3.516406483267254

Epoch: 5| Step: 7
Training loss: 3.6384598347201895
Validation loss: 3.5104769646805702

Epoch: 5| Step: 8
Training loss: 4.135421996349421
Validation loss: 3.510366944405509

Epoch: 5| Step: 9
Training loss: 3.9971847163645418
Validation loss: 3.5083556959736164

Epoch: 5| Step: 10
Training loss: 3.264544586620349
Validation loss: 3.5078945823135737

Epoch: 16| Step: 0
Training loss: 3.6076320386635334
Validation loss: 3.4994291112428977

Epoch: 5| Step: 1
Training loss: 3.277916804739923
Validation loss: 3.49616295255695

Epoch: 5| Step: 2
Training loss: 3.9155959972333463
Validation loss: 3.490925150380378

Epoch: 5| Step: 3
Training loss: 4.059213570783437
Validation loss: 3.486949230016173

Epoch: 5| Step: 4
Training loss: 3.795097657204906
Validation loss: 3.485939375506126

Epoch: 5| Step: 5
Training loss: 3.732636370202134
Validation loss: 3.4831565441925267

Epoch: 5| Step: 6
Training loss: 3.5846958379321783
Validation loss: 3.4784964056511765

Epoch: 5| Step: 7
Training loss: 3.958646273372753
Validation loss: 3.4744508268766467

Epoch: 5| Step: 8
Training loss: 3.6799201000910604
Validation loss: 3.4728159179656504

Epoch: 5| Step: 9
Training loss: 3.2056651394376883
Validation loss: 3.4673075649311396

Epoch: 5| Step: 10
Training loss: 3.797175768332669
Validation loss: 3.462193807465696

Epoch: 17| Step: 0
Training loss: 4.128931657177032
Validation loss: 3.462558974738217

Epoch: 5| Step: 1
Training loss: 3.6769000792114115
Validation loss: 3.464937440890794

Epoch: 5| Step: 2
Training loss: 2.918288207025676
Validation loss: 3.4601278698555054

Epoch: 5| Step: 3
Training loss: 4.144506858876154
Validation loss: 3.460857563303519

Epoch: 5| Step: 4
Training loss: 4.409216132705135
Validation loss: 3.4519097684307947

Epoch: 5| Step: 5
Training loss: 3.3660933626478653
Validation loss: 3.443892790754817

Epoch: 5| Step: 6
Training loss: 3.3795655064956667
Validation loss: 3.4519774119221385

Epoch: 5| Step: 7
Training loss: 3.0192117657733903
Validation loss: 3.4399973444178396

Epoch: 5| Step: 8
Training loss: 3.1683346387715656
Validation loss: 3.440646956324934

Epoch: 5| Step: 9
Training loss: 4.143796692091762
Validation loss: 3.4395761136367127

Epoch: 5| Step: 10
Training loss: 3.6798401495175
Validation loss: 3.426208974519889

Epoch: 18| Step: 0
Training loss: 3.8857418193562907
Validation loss: 3.420277027847931

Epoch: 5| Step: 1
Training loss: 2.898993837169085
Validation loss: 3.4145828998962844

Epoch: 5| Step: 2
Training loss: 3.6685939983103166
Validation loss: 3.411048917321539

Epoch: 5| Step: 3
Training loss: 2.761629483562192
Validation loss: 3.4191409265359076

Epoch: 5| Step: 4
Training loss: 3.824297801867444
Validation loss: 3.4196031758482355

Epoch: 5| Step: 5
Training loss: 3.075141041320094
Validation loss: 3.396763251799566

Epoch: 5| Step: 6
Training loss: 3.981810219243292
Validation loss: 3.3923949552670365

Epoch: 5| Step: 7
Training loss: 3.6529428245733673
Validation loss: 3.3894732856373793

Epoch: 5| Step: 8
Training loss: 3.9114666095075488
Validation loss: 3.3928834725548067

Epoch: 5| Step: 9
Training loss: 4.002042249038101
Validation loss: 3.3886196753638314

Epoch: 5| Step: 10
Training loss: 3.995150606756459
Validation loss: 3.379261304286941

Epoch: 19| Step: 0
Training loss: 3.5094724266272324
Validation loss: 3.3806038095570203

Epoch: 5| Step: 1
Training loss: 3.034406139712932
Validation loss: 3.3910244208890488

Epoch: 5| Step: 2
Training loss: 3.7351890538587744
Validation loss: 3.40890069990876

Epoch: 5| Step: 3
Training loss: 3.977153022252796
Validation loss: 3.399347757696086

Epoch: 5| Step: 4
Training loss: 3.816901246126321
Validation loss: 3.37840704728977

Epoch: 5| Step: 5
Training loss: 3.5812622709213855
Validation loss: 3.371849608702785

Epoch: 5| Step: 6
Training loss: 3.6661389289000073
Validation loss: 3.3673083408324196

Epoch: 5| Step: 7
Training loss: 3.4075296780475592
Validation loss: 3.3638375597200016

Epoch: 5| Step: 8
Training loss: 3.2935742673375037
Validation loss: 3.356927961948477

Epoch: 5| Step: 9
Training loss: 4.172689179828169
Validation loss: 3.3555736786779575

Epoch: 5| Step: 10
Training loss: 3.291153702824843
Validation loss: 3.351557379694613

Epoch: 20| Step: 0
Training loss: 3.660226729619251
Validation loss: 3.349306139827296

Epoch: 5| Step: 1
Training loss: 3.8600779522550255
Validation loss: 3.331560185236803

Epoch: 5| Step: 2
Training loss: 3.6359998932891933
Validation loss: 3.3310126214375133

Epoch: 5| Step: 3
Training loss: 4.1985360091776425
Validation loss: 3.3303770219919144

Epoch: 5| Step: 4
Training loss: 3.914858921670986
Validation loss: 3.324187741407849

Epoch: 5| Step: 5
Training loss: 2.7620362526892066
Validation loss: 3.3181696884424356

Epoch: 5| Step: 6
Training loss: 3.4654962899305577
Validation loss: 3.313972222602864

Epoch: 5| Step: 7
Training loss: 3.573496127429538
Validation loss: 3.312479012520154

Epoch: 5| Step: 8
Training loss: 3.7006048326759386
Validation loss: 3.3098955276489246

Epoch: 5| Step: 9
Training loss: 3.0946196287536663
Validation loss: 3.306679664258622

Epoch: 5| Step: 10
Training loss: 2.980662648304576
Validation loss: 3.3064029278836315

Epoch: 21| Step: 0
Training loss: 3.102549667268231
Validation loss: 3.3032603307855837

Epoch: 5| Step: 1
Training loss: 4.189494554719392
Validation loss: 3.301359188392317

Epoch: 5| Step: 2
Training loss: 3.955722483197565
Validation loss: 3.2953682944925617

Epoch: 5| Step: 3
Training loss: 3.410808767352507
Validation loss: 3.293666098910472

Epoch: 5| Step: 4
Training loss: 3.1669345207033963
Validation loss: 3.29360452891798

Epoch: 5| Step: 5
Training loss: 3.56048902003188
Validation loss: 3.287981861624555

Epoch: 5| Step: 6
Training loss: 2.3771257424033196
Validation loss: 3.2846416471108424

Epoch: 5| Step: 7
Training loss: 3.60008967605797
Validation loss: 3.282767094837559

Epoch: 5| Step: 8
Training loss: 3.2244234915287056
Validation loss: 3.2833729803767855

Epoch: 5| Step: 9
Training loss: 4.181430346330181
Validation loss: 3.2788020396195923

Epoch: 5| Step: 10
Training loss: 3.7458305067505036
Validation loss: 3.2799100031437582

Epoch: 22| Step: 0
Training loss: 3.433504175052796
Validation loss: 3.2779472749992036

Epoch: 5| Step: 1
Training loss: 3.8078484847755973
Validation loss: 3.278840157773801

Epoch: 5| Step: 2
Training loss: 3.5535101984558572
Validation loss: 3.27125788176906

Epoch: 5| Step: 3
Training loss: 3.6060535291442513
Validation loss: 3.2845171545171965

Epoch: 5| Step: 4
Training loss: 3.9641724868570236
Validation loss: 3.27242627350437

Epoch: 5| Step: 5
Training loss: 3.2252258044302864
Validation loss: 3.267884191447372

Epoch: 5| Step: 6
Training loss: 3.8553705483156007
Validation loss: 3.2712929452824646

Epoch: 5| Step: 7
Training loss: 3.1139927605046847
Validation loss: 3.27111093254787

Epoch: 5| Step: 8
Training loss: 3.171474187171868
Validation loss: 3.2717148534981244

Epoch: 5| Step: 9
Training loss: 3.867032011354866
Validation loss: 3.2721234289345973

Epoch: 5| Step: 10
Training loss: 2.842750122016634
Validation loss: 3.267917472717493

Epoch: 23| Step: 0
Training loss: 3.732709185901858
Validation loss: 3.266828573177072

Epoch: 5| Step: 1
Training loss: 3.4481449723888282
Validation loss: 3.2651164738406475

Epoch: 5| Step: 2
Training loss: 3.3242524590223166
Validation loss: 3.2603961988887344

Epoch: 5| Step: 3
Training loss: 3.581657431762018
Validation loss: 3.256189461727668

Epoch: 5| Step: 4
Training loss: 2.676019053786203
Validation loss: 3.255129387798584

Epoch: 5| Step: 5
Training loss: 3.466860969918063
Validation loss: 3.2546608392175864

Epoch: 5| Step: 6
Training loss: 4.279673265124989
Validation loss: 3.256172372264566

Epoch: 5| Step: 7
Training loss: 3.2529298340869826
Validation loss: 3.254296612388656

Epoch: 5| Step: 8
Training loss: 4.082402700653469
Validation loss: 3.2541603503542045

Epoch: 5| Step: 9
Training loss: 3.1465931831551277
Validation loss: 3.250296641490717

Epoch: 5| Step: 10
Training loss: 3.3005904103023127
Validation loss: 3.249251611584728

Epoch: 24| Step: 0
Training loss: 3.5487300374274793
Validation loss: 3.2494769152655865

Epoch: 5| Step: 1
Training loss: 3.2344731855001867
Validation loss: 3.2505557513505456

Epoch: 5| Step: 2
Training loss: 3.0111773804632915
Validation loss: 3.2460810829868003

Epoch: 5| Step: 3
Training loss: 4.119815226735467
Validation loss: 3.2433669063115116

Epoch: 5| Step: 4
Training loss: 2.423746284375778
Validation loss: 3.241178539964864

Epoch: 5| Step: 5
Training loss: 3.3123413623754603
Validation loss: 3.2409336844877963

Epoch: 5| Step: 6
Training loss: 3.341272024188396
Validation loss: 3.2385872275344547

Epoch: 5| Step: 7
Training loss: 4.146185829602159
Validation loss: 3.239973556671947

Epoch: 5| Step: 8
Training loss: 3.7826149738837302
Validation loss: 3.2365024650470318

Epoch: 5| Step: 9
Training loss: 3.7061519564804577
Validation loss: 3.237177557184331

Epoch: 5| Step: 10
Training loss: 3.454153468739904
Validation loss: 3.235306068248304

Epoch: 25| Step: 0
Training loss: 3.7415118473593885
Validation loss: 3.233794636787446

Epoch: 5| Step: 1
Training loss: 3.160750098714455
Validation loss: 3.233100299495321

Epoch: 5| Step: 2
Training loss: 3.750528552635388
Validation loss: 3.232141602767617

Epoch: 5| Step: 3
Training loss: 3.9022072585848946
Validation loss: 3.2292149667505026

Epoch: 5| Step: 4
Training loss: 3.793380447814692
Validation loss: 3.2283714805244617

Epoch: 5| Step: 5
Training loss: 3.119025508354354
Validation loss: 3.227314146471789

Epoch: 5| Step: 6
Training loss: 3.5920070236154378
Validation loss: 3.226669578699242

Epoch: 5| Step: 7
Training loss: 3.8845724189166067
Validation loss: 3.2255858309990857

Epoch: 5| Step: 8
Training loss: 3.0079624683595325
Validation loss: 3.224644599124357

Epoch: 5| Step: 9
Training loss: 3.380604223609592
Validation loss: 3.2222999393179412

Epoch: 5| Step: 10
Training loss: 2.623380252106727
Validation loss: 3.220533957214091

Epoch: 26| Step: 0
Training loss: 3.4741404122025252
Validation loss: 3.220456005859709

Epoch: 5| Step: 1
Training loss: 3.9657259255651063
Validation loss: 3.2184399253239837

Epoch: 5| Step: 2
Training loss: 3.386672146134437
Validation loss: 3.217314665648596

Epoch: 5| Step: 3
Training loss: 4.157169555818034
Validation loss: 3.2188126561611234

Epoch: 5| Step: 4
Training loss: 2.996057303752818
Validation loss: 3.2164850291348492

Epoch: 5| Step: 5
Training loss: 3.5931111970464844
Validation loss: 3.216790123194679

Epoch: 5| Step: 6
Training loss: 3.123672203264495
Validation loss: 3.2172211248605738

Epoch: 5| Step: 7
Training loss: 3.6228582698129186
Validation loss: 3.215940538642654

Epoch: 5| Step: 8
Training loss: 2.9243292471463147
Validation loss: 3.2131021259899657

Epoch: 5| Step: 9
Training loss: 3.8568085697173022
Validation loss: 3.2136642207450876

Epoch: 5| Step: 10
Training loss: 2.7335129605173196
Validation loss: 3.212545084837446

Epoch: 27| Step: 0
Training loss: 2.60246064316657
Validation loss: 3.2140914684134017

Epoch: 5| Step: 1
Training loss: 3.4248457602416655
Validation loss: 3.2139259680717633

Epoch: 5| Step: 2
Training loss: 3.4717314682759355
Validation loss: 3.2188853510079785

Epoch: 5| Step: 3
Training loss: 3.523058547387527
Validation loss: 3.239044449038655

Epoch: 5| Step: 4
Training loss: 2.6076425980429945
Validation loss: 3.2124791470519547

Epoch: 5| Step: 5
Training loss: 3.381426168143115
Validation loss: 3.210930898749567

Epoch: 5| Step: 6
Training loss: 3.540104929344129
Validation loss: 3.220124666871553

Epoch: 5| Step: 7
Training loss: 3.858594684249292
Validation loss: 3.2130228812743744

Epoch: 5| Step: 8
Training loss: 3.6342109203611
Validation loss: 3.2139934260080727

Epoch: 5| Step: 9
Training loss: 4.069927058210659
Validation loss: 3.2191039242348203

Epoch: 5| Step: 10
Training loss: 3.8109546718859613
Validation loss: 3.2139677192533074

Epoch: 28| Step: 0
Training loss: 3.539082575524255
Validation loss: 3.20955573836737

Epoch: 5| Step: 1
Training loss: 3.611210079956184
Validation loss: 3.2065039971405227

Epoch: 5| Step: 2
Training loss: 4.093852733458676
Validation loss: 3.208899475336283

Epoch: 5| Step: 3
Training loss: 3.573924301609542
Validation loss: 3.2098606420561544

Epoch: 5| Step: 4
Training loss: 2.708608544867385
Validation loss: 3.213771157243986

Epoch: 5| Step: 5
Training loss: 3.756343562377936
Validation loss: 3.2293529339013936

Epoch: 5| Step: 6
Training loss: 3.3635463632263556
Validation loss: 3.2115914627168713

Epoch: 5| Step: 7
Training loss: 3.8942073890150826
Validation loss: 3.2070551418176754

Epoch: 5| Step: 8
Training loss: 3.28778631319731
Validation loss: 3.2050694848101537

Epoch: 5| Step: 9
Training loss: 2.776734962753061
Validation loss: 3.205063055444365

Epoch: 5| Step: 10
Training loss: 3.2559191281259556
Validation loss: 3.2049578481351917

Epoch: 29| Step: 0
Training loss: 3.5954069878646884
Validation loss: 3.2031206300527084

Epoch: 5| Step: 1
Training loss: 2.8064714034319413
Validation loss: 3.20557403542302

Epoch: 5| Step: 2
Training loss: 3.0851145745614352
Validation loss: 3.2016884020043626

Epoch: 5| Step: 3
Training loss: 3.8355625691895536
Validation loss: 3.207342966357775

Epoch: 5| Step: 4
Training loss: 3.2285698287853806
Validation loss: 3.2052639098423734

Epoch: 5| Step: 5
Training loss: 3.0660537031115043
Validation loss: 3.2008954612245155

Epoch: 5| Step: 6
Training loss: 4.0702408035612105
Validation loss: 3.1979535077908228

Epoch: 5| Step: 7
Training loss: 3.344272038003542
Validation loss: 3.1972277691154996

Epoch: 5| Step: 8
Training loss: 3.1114651349894444
Validation loss: 3.1961535117664313

Epoch: 5| Step: 9
Training loss: 3.729392075075211
Validation loss: 3.1962210448200836

Epoch: 5| Step: 10
Training loss: 4.017072246119304
Validation loss: 3.195713881592579

Epoch: 30| Step: 0
Training loss: 2.832641704142593
Validation loss: 3.193265910425804

Epoch: 5| Step: 1
Training loss: 3.060482684194424
Validation loss: 3.192928210616151

Epoch: 5| Step: 2
Training loss: 3.5358842806112905
Validation loss: 3.1944249817010233

Epoch: 5| Step: 3
Training loss: 3.6093545227791015
Validation loss: 3.1929057378308183

Epoch: 5| Step: 4
Training loss: 3.0822899230010137
Validation loss: 3.1902066328289997

Epoch: 5| Step: 5
Training loss: 3.0768372606267866
Validation loss: 3.1921971774494025

Epoch: 5| Step: 6
Training loss: 3.698600999435779
Validation loss: 3.1921543576921723

Epoch: 5| Step: 7
Training loss: 3.5302206243888428
Validation loss: 3.191702880199838

Epoch: 5| Step: 8
Training loss: 3.575605146502657
Validation loss: 3.1928320484026456

Epoch: 5| Step: 9
Training loss: 4.1991642438323
Validation loss: 3.189051071173604

Epoch: 5| Step: 10
Training loss: 3.5665023807467953
Validation loss: 3.18989141917152

Epoch: 31| Step: 0
Training loss: 3.1921660733915935
Validation loss: 3.181048754908115

Epoch: 5| Step: 1
Training loss: 4.022774947343878
Validation loss: 3.184740888306072

Epoch: 5| Step: 2
Training loss: 2.9278851878059755
Validation loss: 3.183384517233925

Epoch: 5| Step: 3
Training loss: 2.606229062076323
Validation loss: 3.1792224403748492

Epoch: 5| Step: 4
Training loss: 3.4775567508238017
Validation loss: 3.1787659631260503

Epoch: 5| Step: 5
Training loss: 3.532451998957518
Validation loss: 3.1810580373718653

Epoch: 5| Step: 6
Training loss: 4.096946574850912
Validation loss: 3.179944062734525

Epoch: 5| Step: 7
Training loss: 2.784690785937446
Validation loss: 3.184837157175367

Epoch: 5| Step: 8
Training loss: 3.0991684444374865
Validation loss: 3.1873477044459353

Epoch: 5| Step: 9
Training loss: 4.063690011254348
Validation loss: 3.185700722869612

Epoch: 5| Step: 10
Training loss: 3.7394260100670027
Validation loss: 3.188310356489827

Epoch: 32| Step: 0
Training loss: 3.6338670082005717
Validation loss: 3.1802869106146487

Epoch: 5| Step: 1
Training loss: 2.6790672896856425
Validation loss: 3.1803168854346775

Epoch: 5| Step: 2
Training loss: 3.5242044836291266
Validation loss: 3.1735846131510437

Epoch: 5| Step: 3
Training loss: 2.904161420586626
Validation loss: 3.1711559182714835

Epoch: 5| Step: 4
Training loss: 3.4894755028912754
Validation loss: 3.1696839648714183

Epoch: 5| Step: 5
Training loss: 4.058183695223123
Validation loss: 3.168177303184727

Epoch: 5| Step: 6
Training loss: 3.0960672350933773
Validation loss: 3.1651862596426805

Epoch: 5| Step: 7
Training loss: 3.5335089286020973
Validation loss: 3.163596679881666

Epoch: 5| Step: 8
Training loss: 3.464141120758334
Validation loss: 3.1622298734287932

Epoch: 5| Step: 9
Training loss: 3.6049468384948513
Validation loss: 3.1610140491928904

Epoch: 5| Step: 10
Training loss: 3.5632977847213523
Validation loss: 3.1726865604613677

Epoch: 33| Step: 0
Training loss: 3.1025736431323545
Validation loss: 3.252381417001614

Epoch: 5| Step: 1
Training loss: 3.500943874062876
Validation loss: 3.2761334445309935

Epoch: 5| Step: 2
Training loss: 3.3416907128081674
Validation loss: 3.2820702702878504

Epoch: 5| Step: 3
Training loss: 3.527888766033846
Validation loss: 3.2525409013939663

Epoch: 5| Step: 4
Training loss: 4.04888182851504
Validation loss: 3.2324806814009266

Epoch: 5| Step: 5
Training loss: 3.20863932021526
Validation loss: 3.2088210735709812

Epoch: 5| Step: 6
Training loss: 2.9805175457281017
Validation loss: 3.1745665626690234

Epoch: 5| Step: 7
Training loss: 3.592359987210352
Validation loss: 3.1913453805453327

Epoch: 5| Step: 8
Training loss: 2.933483868406501
Validation loss: 3.2376205380086582

Epoch: 5| Step: 9
Training loss: 4.426597203510166
Validation loss: 3.2357669510411786

Epoch: 5| Step: 10
Training loss: 3.3674552793301613
Validation loss: 3.1739360216099497

Epoch: 34| Step: 0
Training loss: 2.730672978743445
Validation loss: 3.1619271029858784

Epoch: 5| Step: 1
Training loss: 3.1939843735667943
Validation loss: 3.163081815359462

Epoch: 5| Step: 2
Training loss: 3.8689800385102937
Validation loss: 3.2061113787933624

Epoch: 5| Step: 3
Training loss: 2.9435455121655485
Validation loss: 3.3009107412505587

Epoch: 5| Step: 4
Training loss: 2.9362046652615534
Validation loss: 3.1887576770584336

Epoch: 5| Step: 5
Training loss: 3.9412097711805725
Validation loss: 3.165126107370755

Epoch: 5| Step: 6
Training loss: 3.5680783416375528
Validation loss: 3.16304336232134

Epoch: 5| Step: 7
Training loss: 3.711997818296712
Validation loss: 3.1637893589245727

Epoch: 5| Step: 8
Training loss: 3.0469717157125924
Validation loss: 3.1655448039238827

Epoch: 5| Step: 9
Training loss: 4.354240648045736
Validation loss: 3.1704748977387838

Epoch: 5| Step: 10
Training loss: 3.1738952817414203
Validation loss: 3.161893254184614

Epoch: 35| Step: 0
Training loss: 3.6196459990174628
Validation loss: 3.153355867919795

Epoch: 5| Step: 1
Training loss: 3.7506225069251005
Validation loss: 3.1527120676933325

Epoch: 5| Step: 2
Training loss: 3.0742091332640245
Validation loss: 3.148164837136356

Epoch: 5| Step: 3
Training loss: 3.0393500890697376
Validation loss: 3.1482042406216153

Epoch: 5| Step: 4
Training loss: 3.22065826440293
Validation loss: 3.1461657113750863

Epoch: 5| Step: 5
Training loss: 3.6301023156745353
Validation loss: 3.1457130106506774

Epoch: 5| Step: 6
Training loss: 3.1859873754199732
Validation loss: 3.143912391347612

Epoch: 5| Step: 7
Training loss: 3.468582149259214
Validation loss: 3.1441085271426976

Epoch: 5| Step: 8
Training loss: 3.1599985656252154
Validation loss: 3.1440582325217936

Epoch: 5| Step: 9
Training loss: 3.5865313135958146
Validation loss: 3.1406632051045538

Epoch: 5| Step: 10
Training loss: 3.784044730456384
Validation loss: 3.1410602351057473

Epoch: 36| Step: 0
Training loss: 3.1085677896255945
Validation loss: 3.1415854540295656

Epoch: 5| Step: 1
Training loss: 2.800098628623122
Validation loss: 3.1389424590227146

Epoch: 5| Step: 2
Training loss: 4.0914437590025665
Validation loss: 3.1416656136616394

Epoch: 5| Step: 3
Training loss: 3.6061635448333402
Validation loss: 3.139517021206994

Epoch: 5| Step: 4
Training loss: 3.209534424385175
Validation loss: 3.1406926895868685

Epoch: 5| Step: 5
Training loss: 3.3433218708646866
Validation loss: 3.136777869664918

Epoch: 5| Step: 6
Training loss: 3.5480786940439213
Validation loss: 3.136637311523466

Epoch: 5| Step: 7
Training loss: 3.5420005341781997
Validation loss: 3.135984607612508

Epoch: 5| Step: 8
Training loss: 3.6341189424640565
Validation loss: 3.1339555603193032

Epoch: 5| Step: 9
Training loss: 3.142848504042209
Validation loss: 3.133976800973766

Epoch: 5| Step: 10
Training loss: 3.2905100629392092
Validation loss: 3.1329681600853756

Epoch: 37| Step: 0
Training loss: 3.4181697764544263
Validation loss: 3.1330609531350393

Epoch: 5| Step: 1
Training loss: 3.4969756820134252
Validation loss: 3.1311037107983037

Epoch: 5| Step: 2
Training loss: 4.017134683232866
Validation loss: 3.1306380899177473

Epoch: 5| Step: 3
Training loss: 2.634793857567419
Validation loss: 3.130865809357153

Epoch: 5| Step: 4
Training loss: 3.0487824558158665
Validation loss: 3.1285045636781907

Epoch: 5| Step: 5
Training loss: 3.680339261463238
Validation loss: 3.129357354734305

Epoch: 5| Step: 6
Training loss: 2.8755431284170005
Validation loss: 3.1282914562028292

Epoch: 5| Step: 7
Training loss: 3.5597583862351643
Validation loss: 3.12935304234295

Epoch: 5| Step: 8
Training loss: 3.716748380119128
Validation loss: 3.128764990814008

Epoch: 5| Step: 9
Training loss: 2.944409300236524
Validation loss: 3.1265681001566183

Epoch: 5| Step: 10
Training loss: 3.8216310811593783
Validation loss: 3.1266660289561288

Epoch: 38| Step: 0
Training loss: 3.8278559376107095
Validation loss: 3.125853376462704

Epoch: 5| Step: 1
Training loss: 3.2771915586869653
Validation loss: 3.126359620013957

Epoch: 5| Step: 2
Training loss: 3.6745630692226285
Validation loss: 3.124171401890404

Epoch: 5| Step: 3
Training loss: 3.31764598809815
Validation loss: 3.1238585325502553

Epoch: 5| Step: 4
Training loss: 3.844372830676374
Validation loss: 3.124560811344533

Epoch: 5| Step: 5
Training loss: 3.6861013572529964
Validation loss: 3.125352559864851

Epoch: 5| Step: 6
Training loss: 3.028064272874937
Validation loss: 3.1236060226711393

Epoch: 5| Step: 7
Training loss: 2.9734796694452936
Validation loss: 3.1259492347178006

Epoch: 5| Step: 8
Training loss: 3.272575319500188
Validation loss: 3.126916005133563

Epoch: 5| Step: 9
Training loss: 3.079106672956035
Validation loss: 3.1231702653094917

Epoch: 5| Step: 10
Training loss: 3.1923483084992967
Validation loss: 3.123410594735476

Epoch: 39| Step: 0
Training loss: 2.141658227312651
Validation loss: 3.1210907009923607

Epoch: 5| Step: 1
Training loss: 3.343206058360332
Validation loss: 3.122304809943685

Epoch: 5| Step: 2
Training loss: 3.58235351710249
Validation loss: 3.1230788201268966

Epoch: 5| Step: 3
Training loss: 3.2972693907968513
Validation loss: 3.12238878160738

Epoch: 5| Step: 4
Training loss: 3.1938877800114005
Validation loss: 3.1228897172261876

Epoch: 5| Step: 5
Training loss: 3.6088909138306864
Validation loss: 3.120911663495235

Epoch: 5| Step: 6
Training loss: 3.428387023871316
Validation loss: 3.1208662638375437

Epoch: 5| Step: 7
Training loss: 3.417031260940501
Validation loss: 3.119258923807886

Epoch: 5| Step: 8
Training loss: 3.3391725099869634
Validation loss: 3.1194899903106217

Epoch: 5| Step: 9
Training loss: 4.005414397747212
Validation loss: 3.117351830199033

Epoch: 5| Step: 10
Training loss: 3.6498396015196737
Validation loss: 3.117683638653701

Epoch: 40| Step: 0
Training loss: 3.8994550275286866
Validation loss: 3.1172861470223463

Epoch: 5| Step: 1
Training loss: 3.2858663873237814
Validation loss: 3.1149665766018955

Epoch: 5| Step: 2
Training loss: 3.457517014335424
Validation loss: 3.1162628530351086

Epoch: 5| Step: 3
Training loss: 2.772340111486342
Validation loss: 3.1141391780006815

Epoch: 5| Step: 4
Training loss: 3.3025694929459553
Validation loss: 3.1190687813623947

Epoch: 5| Step: 5
Training loss: 3.465119257384298
Validation loss: 3.1163267043539653

Epoch: 5| Step: 6
Training loss: 3.3511121754120414
Validation loss: 3.112640041853442

Epoch: 5| Step: 7
Training loss: 3.5799352073133965
Validation loss: 3.113105981340154

Epoch: 5| Step: 8
Training loss: 3.3890023985511215
Validation loss: 3.112011150714567

Epoch: 5| Step: 9
Training loss: 2.850730461071711
Validation loss: 3.1134381780616147

Epoch: 5| Step: 10
Training loss: 3.7672623363072395
Validation loss: 3.1118403325480855

Epoch: 41| Step: 0
Training loss: 2.6398987081631695
Validation loss: 3.111869146017459

Epoch: 5| Step: 1
Training loss: 3.5173399408792703
Validation loss: 3.113130918446459

Epoch: 5| Step: 2
Training loss: 3.3848890313986386
Validation loss: 3.112680156956539

Epoch: 5| Step: 3
Training loss: 3.2787383139456936
Validation loss: 3.110388889939712

Epoch: 5| Step: 4
Training loss: 2.9275390885607777
Validation loss: 3.1126811074046072

Epoch: 5| Step: 5
Training loss: 3.0117341077044393
Validation loss: 3.1100447991691778

Epoch: 5| Step: 6
Training loss: 3.7337828609628363
Validation loss: 3.1124340272604605

Epoch: 5| Step: 7
Training loss: 3.7917472215975416
Validation loss: 3.110463891287197

Epoch: 5| Step: 8
Training loss: 4.067370033931007
Validation loss: 3.109299909311883

Epoch: 5| Step: 9
Training loss: 3.46974923802575
Validation loss: 3.1078437839525703

Epoch: 5| Step: 10
Training loss: 3.021842910612002
Validation loss: 3.1071991039364386

Epoch: 42| Step: 0
Training loss: 3.7067705068748467
Validation loss: 3.106468061672088

Epoch: 5| Step: 1
Training loss: 3.072709019428721
Validation loss: 3.106697189676322

Epoch: 5| Step: 2
Training loss: 3.791449166791346
Validation loss: 3.1064386195935234

Epoch: 5| Step: 3
Training loss: 3.5579273257282216
Validation loss: 3.104152637842828

Epoch: 5| Step: 4
Training loss: 3.1209270638081024
Validation loss: 3.1034078565952696

Epoch: 5| Step: 5
Training loss: 2.9693323467694364
Validation loss: 3.1044109788184207

Epoch: 5| Step: 6
Training loss: 3.7200419001116676
Validation loss: 3.1020043811720215

Epoch: 5| Step: 7
Training loss: 3.176704075590692
Validation loss: 3.1038216493224398

Epoch: 5| Step: 8
Training loss: 3.3198388334015165
Validation loss: 3.103184452050597

Epoch: 5| Step: 9
Training loss: 3.1728294702889692
Validation loss: 3.101087585956004

Epoch: 5| Step: 10
Training loss: 3.372834111115024
Validation loss: 3.103103672617653

Epoch: 43| Step: 0
Training loss: 3.229469301542359
Validation loss: 3.106715088171673

Epoch: 5| Step: 1
Training loss: 3.794286025764597
Validation loss: 3.1045334904741915

Epoch: 5| Step: 2
Training loss: 3.5476158141465537
Validation loss: 3.1002585390259796

Epoch: 5| Step: 3
Training loss: 3.3846130512803043
Validation loss: 3.1004097246012448

Epoch: 5| Step: 4
Training loss: 2.726333302480568
Validation loss: 3.099304642030677

Epoch: 5| Step: 5
Training loss: 3.592339678474121
Validation loss: 3.10062401005724

Epoch: 5| Step: 6
Training loss: 3.318141811124918
Validation loss: 3.098619841346449

Epoch: 5| Step: 7
Training loss: 2.9275105844464333
Validation loss: 3.098733409489426

Epoch: 5| Step: 8
Training loss: 3.3245532431226636
Validation loss: 3.0974473004347787

Epoch: 5| Step: 9
Training loss: 3.728353841557811
Validation loss: 3.097704974125459

Epoch: 5| Step: 10
Training loss: 3.3790616214729536
Validation loss: 3.097310095801582

Epoch: 44| Step: 0
Training loss: 3.6521325034998546
Validation loss: 3.096569552665183

Epoch: 5| Step: 1
Training loss: 2.692182586718574
Validation loss: 3.0954972287930045

Epoch: 5| Step: 2
Training loss: 3.331818013674384
Validation loss: 3.0982233370053116

Epoch: 5| Step: 3
Training loss: 3.5134559552282156
Validation loss: 3.0981760906149796

Epoch: 5| Step: 4
Training loss: 3.912301343073055
Validation loss: 3.101190022830244

Epoch: 5| Step: 5
Training loss: 3.3760339071641114
Validation loss: 3.106624780999526

Epoch: 5| Step: 6
Training loss: 3.146346919764914
Validation loss: 3.1011911718923124

Epoch: 5| Step: 7
Training loss: 3.1581768537288584
Validation loss: 3.099798475616158

Epoch: 5| Step: 8
Training loss: 3.628648303239921
Validation loss: 3.1008008366414233

Epoch: 5| Step: 9
Training loss: 3.3076944581504204
Validation loss: 3.0933753671679187

Epoch: 5| Step: 10
Training loss: 3.07297887362
Validation loss: 3.091294118595262

Epoch: 45| Step: 0
Training loss: 3.478142197284529
Validation loss: 3.0917909779018644

Epoch: 5| Step: 1
Training loss: 3.3903615822844575
Validation loss: 3.09181955451108

Epoch: 5| Step: 2
Training loss: 2.7538813163764884
Validation loss: 3.0920384606193263

Epoch: 5| Step: 3
Training loss: 3.0173982930840344
Validation loss: 3.0907525019660778

Epoch: 5| Step: 4
Training loss: 3.1580491178822774
Validation loss: 3.0914386091893578

Epoch: 5| Step: 5
Training loss: 3.542726754500785
Validation loss: 3.088835946763738

Epoch: 5| Step: 6
Training loss: 3.843172107456831
Validation loss: 3.091319628890037

Epoch: 5| Step: 7
Training loss: 3.4059539106277996
Validation loss: 3.0902910333115385

Epoch: 5| Step: 8
Training loss: 2.682334726722532
Validation loss: 3.096509565979295

Epoch: 5| Step: 9
Training loss: 4.007877698817872
Validation loss: 3.1005297443393465

Epoch: 5| Step: 10
Training loss: 3.452501749953946
Validation loss: 3.0882053418658937

Epoch: 46| Step: 0
Training loss: 3.5457610006758173
Validation loss: 3.0892552016376116

Epoch: 5| Step: 1
Training loss: 2.9273389023678837
Validation loss: 3.0929451122576888

Epoch: 5| Step: 2
Training loss: 3.527569498503532
Validation loss: 3.1096681648441002

Epoch: 5| Step: 3
Training loss: 3.4544368685763374
Validation loss: 3.094682488522906

Epoch: 5| Step: 4
Training loss: 3.3085421543534532
Validation loss: 3.0854029935945797

Epoch: 5| Step: 5
Training loss: 3.4006221370337926
Validation loss: 3.084906422608229

Epoch: 5| Step: 6
Training loss: 3.6793582064292494
Validation loss: 3.0849213793965347

Epoch: 5| Step: 7
Training loss: 3.4103761931953738
Validation loss: 3.083735263261733

Epoch: 5| Step: 8
Training loss: 3.3316404017268217
Validation loss: 3.0874096471306514

Epoch: 5| Step: 9
Training loss: 2.5043544040915466
Validation loss: 3.084107320688754

Epoch: 5| Step: 10
Training loss: 3.8123065086417856
Validation loss: 3.0872505240974553

Epoch: 47| Step: 0
Training loss: 3.6042028583333865
Validation loss: 3.0868060840711267

Epoch: 5| Step: 1
Training loss: 3.86487635129708
Validation loss: 3.0917591705250604

Epoch: 5| Step: 2
Training loss: 3.371827365089776
Validation loss: 3.0892162030827484

Epoch: 5| Step: 3
Training loss: 3.2824783205941968
Validation loss: 3.0868626258864733

Epoch: 5| Step: 4
Training loss: 3.3531983835912897
Validation loss: 3.0872335391299597

Epoch: 5| Step: 5
Training loss: 2.899698892943674
Validation loss: 3.0861231552691444

Epoch: 5| Step: 6
Training loss: 2.8749795995900707
Validation loss: 3.0889481524964566

Epoch: 5| Step: 7
Training loss: 4.0939945992348905
Validation loss: 3.089503961230795

Epoch: 5| Step: 8
Training loss: 3.1919061463021996
Validation loss: 3.088945256005622

Epoch: 5| Step: 9
Training loss: 3.694514698581158
Validation loss: 3.083974210146505

Epoch: 5| Step: 10
Training loss: 2.156926587973778
Validation loss: 3.0834214270816185

Epoch: 48| Step: 0
Training loss: 2.9355697783225794
Validation loss: 3.0817020516554243

Epoch: 5| Step: 1
Training loss: 3.41548528638554
Validation loss: 3.0812516944443122

Epoch: 5| Step: 2
Training loss: 3.7322778918542396
Validation loss: 3.0793033266525005

Epoch: 5| Step: 3
Training loss: 4.060552981446827
Validation loss: 3.080565916501546

Epoch: 5| Step: 4
Training loss: 3.6618450425435243
Validation loss: 3.0789297919584286

Epoch: 5| Step: 5
Training loss: 3.046806452053431
Validation loss: 3.0786206054808556

Epoch: 5| Step: 6
Training loss: 3.264762801102239
Validation loss: 3.078700864019558

Epoch: 5| Step: 7
Training loss: 3.1852129042533974
Validation loss: 3.0759094053385803

Epoch: 5| Step: 8
Training loss: 3.2652005006411486
Validation loss: 3.0787631944706355

Epoch: 5| Step: 9
Training loss: 3.3798533264478774
Validation loss: 3.076892493386274

Epoch: 5| Step: 10
Training loss: 2.588349384455418
Validation loss: 3.078837827975782

Epoch: 49| Step: 0
Training loss: 4.0852124827299665
Validation loss: 3.0750412773885447

Epoch: 5| Step: 1
Training loss: 3.5465708866905916
Validation loss: 3.0767398289217116

Epoch: 5| Step: 2
Training loss: 2.964768962896929
Validation loss: 3.0770937900311526

Epoch: 5| Step: 3
Training loss: 3.256366363027783
Validation loss: 3.0764252332821074

Epoch: 5| Step: 4
Training loss: 3.5276341112841765
Validation loss: 3.0763478162290934

Epoch: 5| Step: 5
Training loss: 3.4086141518806974
Validation loss: 3.077085140390842

Epoch: 5| Step: 6
Training loss: 3.2394534429450887
Validation loss: 3.0763074023551344

Epoch: 5| Step: 7
Training loss: 3.3879929975597163
Validation loss: 3.0762336775012384

Epoch: 5| Step: 8
Training loss: 3.199223668580239
Validation loss: 3.0802965513759277

Epoch: 5| Step: 9
Training loss: 3.01978722359597
Validation loss: 3.0715903769409745

Epoch: 5| Step: 10
Training loss: 2.949395463714453
Validation loss: 3.0705248573925585

Epoch: 50| Step: 0
Training loss: 2.8344727824208626
Validation loss: 3.069474509499089

Epoch: 5| Step: 1
Training loss: 3.98539643004179
Validation loss: 3.069640488653482

Epoch: 5| Step: 2
Training loss: 3.0039648241302386
Validation loss: 3.0690964490216897

Epoch: 5| Step: 3
Training loss: 2.9468646829046268
Validation loss: 3.0700815500069685

Epoch: 5| Step: 4
Training loss: 2.946520974828202
Validation loss: 3.0684534885870245

Epoch: 5| Step: 5
Training loss: 3.1471118644661136
Validation loss: 3.0677713227908097

Epoch: 5| Step: 6
Training loss: 3.762864489975938
Validation loss: 3.0670938916733177

Epoch: 5| Step: 7
Training loss: 4.262465651924704
Validation loss: 3.066503772604776

Epoch: 5| Step: 8
Training loss: 2.758791136614265
Validation loss: 3.0677528360709565

Epoch: 5| Step: 9
Training loss: 3.0978700580866123
Validation loss: 3.0661442921894255

Epoch: 5| Step: 10
Training loss: 3.640248029453815
Validation loss: 3.06565674316119

Epoch: 51| Step: 0
Training loss: 3.3613098250427913
Validation loss: 3.065780576861947

Epoch: 5| Step: 1
Training loss: 3.590537849875921
Validation loss: 3.0662478178537316

Epoch: 5| Step: 2
Training loss: 3.2814290315741728
Validation loss: 3.0644738953793786

Epoch: 5| Step: 3
Training loss: 3.666583464863383
Validation loss: 3.065165127056272

Epoch: 5| Step: 4
Training loss: 3.1926007317503777
Validation loss: 3.0646140842293756

Epoch: 5| Step: 5
Training loss: 2.6900636732088645
Validation loss: 3.065626756935335

Epoch: 5| Step: 6
Training loss: 3.221563498444772
Validation loss: 3.0660426343112555

Epoch: 5| Step: 7
Training loss: 3.4180440839912265
Validation loss: 3.0654861561084124

Epoch: 5| Step: 8
Training loss: 3.180931054335589
Validation loss: 3.0632781194805263

Epoch: 5| Step: 9
Training loss: 3.5624445860719023
Validation loss: 3.0647433621453204

Epoch: 5| Step: 10
Training loss: 3.458111369045632
Validation loss: 3.0614891686078334

Epoch: 52| Step: 0
Training loss: 3.626849524806059
Validation loss: 3.0615237238819515

Epoch: 5| Step: 1
Training loss: 2.9646587892117022
Validation loss: 3.0610987823080036

Epoch: 5| Step: 2
Training loss: 3.0101952564871493
Validation loss: 3.060221658542051

Epoch: 5| Step: 3
Training loss: 3.0541621778454306
Validation loss: 3.058868803608342

Epoch: 5| Step: 4
Training loss: 3.8900011167549158
Validation loss: 3.0604146621831454

Epoch: 5| Step: 5
Training loss: 3.6137943047915373
Validation loss: 3.062009640299418

Epoch: 5| Step: 6
Training loss: 3.8496013236772098
Validation loss: 3.063428130821831

Epoch: 5| Step: 7
Training loss: 3.249984447735475
Validation loss: 3.060118148501881

Epoch: 5| Step: 8
Training loss: 2.9315340860159114
Validation loss: 3.0592496598717838

Epoch: 5| Step: 9
Training loss: 2.9605488786339538
Validation loss: 3.057525562649097

Epoch: 5| Step: 10
Training loss: 3.3004609624099617
Validation loss: 3.057813863356624

Epoch: 53| Step: 0
Training loss: 3.3065510719101106
Validation loss: 3.056792397878586

Epoch: 5| Step: 1
Training loss: 3.424995706374547
Validation loss: 3.0569099822085373

Epoch: 5| Step: 2
Training loss: 2.846939310630897
Validation loss: 3.0565311225001803

Epoch: 5| Step: 3
Training loss: 3.125657889733351
Validation loss: 3.056031529527967

Epoch: 5| Step: 4
Training loss: 3.4989090990511387
Validation loss: 3.0541992896778

Epoch: 5| Step: 5
Training loss: 3.3194889258929567
Validation loss: 3.0543469930381058

Epoch: 5| Step: 6
Training loss: 3.249569937788478
Validation loss: 3.053769494891575

Epoch: 5| Step: 7
Training loss: 3.305890380685126
Validation loss: 3.0541524341624715

Epoch: 5| Step: 8
Training loss: 3.779286907488471
Validation loss: 3.0530382260147313

Epoch: 5| Step: 9
Training loss: 3.7246191047657393
Validation loss: 3.053426872210062

Epoch: 5| Step: 10
Training loss: 2.8174511879701196
Validation loss: 3.0521760726480602

Epoch: 54| Step: 0
Training loss: 3.171974669144881
Validation loss: 3.0532139637534326

Epoch: 5| Step: 1
Training loss: 3.1336746361354573
Validation loss: 3.0539218234723453

Epoch: 5| Step: 2
Training loss: 3.530358396064497
Validation loss: 3.057122859678315

Epoch: 5| Step: 3
Training loss: 3.5689343353070937
Validation loss: 3.0553268444594743

Epoch: 5| Step: 4
Training loss: 2.8475891021640014
Validation loss: 3.0549099530685546

Epoch: 5| Step: 5
Training loss: 3.451034672702496
Validation loss: 3.05236955898124

Epoch: 5| Step: 6
Training loss: 3.1162283815321845
Validation loss: 3.0518726389687822

Epoch: 5| Step: 7
Training loss: 3.1255800853203195
Validation loss: 3.048947032197292

Epoch: 5| Step: 8
Training loss: 3.374237822195896
Validation loss: 3.048166251832749

Epoch: 5| Step: 9
Training loss: 3.6064703016244324
Validation loss: 3.050063708208364

Epoch: 5| Step: 10
Training loss: 3.5722939233091835
Validation loss: 3.048315791599201

Epoch: 55| Step: 0
Training loss: 3.232101747270948
Validation loss: 3.048975837153593

Epoch: 5| Step: 1
Training loss: 3.9329937777534263
Validation loss: 3.047863159984033

Epoch: 5| Step: 2
Training loss: 2.3390796158749825
Validation loss: 3.0462392896350097

Epoch: 5| Step: 3
Training loss: 3.464474078803332
Validation loss: 3.044265351409441

Epoch: 5| Step: 4
Training loss: 3.1730612054182123
Validation loss: 3.0451857704079717

Epoch: 5| Step: 5
Training loss: 3.803470362056729
Validation loss: 3.046962144234943

Epoch: 5| Step: 6
Training loss: 2.9336285341438124
Validation loss: 3.04477915108734

Epoch: 5| Step: 7
Training loss: 3.3015910041326038
Validation loss: 3.04577400418291

Epoch: 5| Step: 8
Training loss: 3.7920642406800464
Validation loss: 3.0454380480588736

Epoch: 5| Step: 9
Training loss: 2.898630634464093
Validation loss: 3.0477526742402095

Epoch: 5| Step: 10
Training loss: 3.311713647174796
Validation loss: 3.045705155371668

Epoch: 56| Step: 0
Training loss: 3.2167110466407403
Validation loss: 3.0518380701812173

Epoch: 5| Step: 1
Training loss: 4.106094501401953
Validation loss: 3.0541283501428556

Epoch: 5| Step: 2
Training loss: 3.5924465303417192
Validation loss: 3.045736548117686

Epoch: 5| Step: 3
Training loss: 3.708830867923253
Validation loss: 3.047573384614101

Epoch: 5| Step: 4
Training loss: 3.6581598494170153
Validation loss: 3.048264566558836

Epoch: 5| Step: 5
Training loss: 3.375474543235189
Validation loss: 3.045108633390398

Epoch: 5| Step: 6
Training loss: 2.7870076621408466
Validation loss: 3.0442666625919923

Epoch: 5| Step: 7
Training loss: 3.225611659752117
Validation loss: 3.0410189945538617

Epoch: 5| Step: 8
Training loss: 2.7957285657223236
Validation loss: 3.040096264988386

Epoch: 5| Step: 9
Training loss: 3.0139702719049435
Validation loss: 3.039902597924908

Epoch: 5| Step: 10
Training loss: 2.589712562518015
Validation loss: 3.04046809076559

Epoch: 57| Step: 0
Training loss: 3.3802644149916423
Validation loss: 3.039510626667901

Epoch: 5| Step: 1
Training loss: 3.4266695895596913
Validation loss: 3.0402647359300183

Epoch: 5| Step: 2
Training loss: 3.412261417977694
Validation loss: 3.0424951972087313

Epoch: 5| Step: 3
Training loss: 3.2675918423763175
Validation loss: 3.039260471036055

Epoch: 5| Step: 4
Training loss: 3.44948403190459
Validation loss: 3.040372064490825

Epoch: 5| Step: 5
Training loss: 2.988474322296314
Validation loss: 3.037820725308484

Epoch: 5| Step: 6
Training loss: 3.3190474669627217
Validation loss: 3.0373630079737675

Epoch: 5| Step: 7
Training loss: 2.760765936485886
Validation loss: 3.0362359953015905

Epoch: 5| Step: 8
Training loss: 3.591890069396596
Validation loss: 3.034750680056412

Epoch: 5| Step: 9
Training loss: 3.6958926110457826
Validation loss: 3.0368229531318605

Epoch: 5| Step: 10
Training loss: 3.0678199182152373
Validation loss: 3.034375079214646

Epoch: 58| Step: 0
Training loss: 3.491284008195109
Validation loss: 3.0333353862960593

Epoch: 5| Step: 1
Training loss: 3.1383128598828938
Validation loss: 3.03219259491844

Epoch: 5| Step: 2
Training loss: 2.9191777636721556
Validation loss: 3.03380277884932

Epoch: 5| Step: 3
Training loss: 3.8388047078593366
Validation loss: 3.035235997299476

Epoch: 5| Step: 4
Training loss: 2.76240446866246
Validation loss: 3.032489499933337

Epoch: 5| Step: 5
Training loss: 3.0428454235779956
Validation loss: 3.03352525133905

Epoch: 5| Step: 6
Training loss: 3.510407097838328
Validation loss: 3.034561062337993

Epoch: 5| Step: 7
Training loss: 3.2188202192924624
Validation loss: 3.032694019430763

Epoch: 5| Step: 8
Training loss: 4.125180558385563
Validation loss: 3.033804129199729

Epoch: 5| Step: 9
Training loss: 3.030130081154243
Validation loss: 3.031807421442442

Epoch: 5| Step: 10
Training loss: 3.0175533157859595
Validation loss: 3.0337805765687373

Epoch: 59| Step: 0
Training loss: 3.684872741986321
Validation loss: 3.036440229526385

Epoch: 5| Step: 1
Training loss: 3.5210582202365543
Validation loss: 3.035205860877775

Epoch: 5| Step: 2
Training loss: 3.0264465971551733
Validation loss: 3.0398780029533454

Epoch: 5| Step: 3
Training loss: 3.1402763818483446
Validation loss: 3.033543149295563

Epoch: 5| Step: 4
Training loss: 3.1475581983498753
Validation loss: 3.027230003567338

Epoch: 5| Step: 5
Training loss: 3.2566356408610804
Validation loss: 3.02865602418229

Epoch: 5| Step: 6
Training loss: 3.4733306607500314
Validation loss: 3.0271782828319247

Epoch: 5| Step: 7
Training loss: 3.233627896475377
Validation loss: 3.0251176206304873

Epoch: 5| Step: 8
Training loss: 3.235224368113614
Validation loss: 3.025515476363478

Epoch: 5| Step: 9
Training loss: 3.1617670468844867
Validation loss: 3.0262252285703766

Epoch: 5| Step: 10
Training loss: 3.4525520229080158
Validation loss: 3.0290936808582343

Epoch: 60| Step: 0
Training loss: 3.617410409868542
Validation loss: 3.030204508924075

Epoch: 5| Step: 1
Training loss: 3.3617224719651717
Validation loss: 3.0312475845738316

Epoch: 5| Step: 2
Training loss: 3.9419010331936497
Validation loss: 3.034475519458477

Epoch: 5| Step: 3
Training loss: 2.782621409876947
Validation loss: 3.03187993596394

Epoch: 5| Step: 4
Training loss: 2.7924256123442346
Validation loss: 3.034723336691942

Epoch: 5| Step: 5
Training loss: 2.7800343460595944
Validation loss: 3.018465151891284

Epoch: 5| Step: 6
Training loss: 3.3126995098563556
Validation loss: 3.0174183117538993

Epoch: 5| Step: 7
Training loss: 3.440502589349669
Validation loss: 3.0183281298011955

Epoch: 5| Step: 8
Training loss: 3.566621370711245
Validation loss: 3.0204247446932926

Epoch: 5| Step: 9
Training loss: 2.961967671528948
Validation loss: 3.0223458096032734

Epoch: 5| Step: 10
Training loss: 3.551353148345731
Validation loss: 3.0242558040432064

Epoch: 61| Step: 0
Training loss: 3.47935226463152
Validation loss: 3.021855963603436

Epoch: 5| Step: 1
Training loss: 3.2664805482536003
Validation loss: 3.0207944472161214

Epoch: 5| Step: 2
Training loss: 3.6826261218318432
Validation loss: 3.020797604245952

Epoch: 5| Step: 3
Training loss: 3.1792923215446107
Validation loss: 3.0146552491527405

Epoch: 5| Step: 4
Training loss: 3.0133444904300886
Validation loss: 3.0160669275750775

Epoch: 5| Step: 5
Training loss: 3.3486068960429014
Validation loss: 3.0144377823047996

Epoch: 5| Step: 6
Training loss: 3.197242060943251
Validation loss: 3.016157479541659

Epoch: 5| Step: 7
Training loss: 3.031834968675359
Validation loss: 3.016448309644136

Epoch: 5| Step: 8
Training loss: 3.201903170644698
Validation loss: 3.0135857502244026

Epoch: 5| Step: 9
Training loss: 3.142177368936847
Validation loss: 3.0122709924980087

Epoch: 5| Step: 10
Training loss: 3.695322177866225
Validation loss: 3.012177915106612

Epoch: 62| Step: 0
Training loss: 2.757406058903102
Validation loss: 3.0108676837532555

Epoch: 5| Step: 1
Training loss: 3.2205867526542535
Validation loss: 3.008770683711641

Epoch: 5| Step: 2
Training loss: 2.867921491008578
Validation loss: 3.0075920681564563

Epoch: 5| Step: 3
Training loss: 3.10887732428738
Validation loss: 3.007939811987857

Epoch: 5| Step: 4
Training loss: 3.342194382498611
Validation loss: 3.0151501098404525

Epoch: 5| Step: 5
Training loss: 2.948010087077509
Validation loss: 3.0127660091043826

Epoch: 5| Step: 6
Training loss: 3.3035852203670393
Validation loss: 3.0081497180206345

Epoch: 5| Step: 7
Training loss: 3.450490369362375
Validation loss: 3.0106125475603633

Epoch: 5| Step: 8
Training loss: 4.263731595650807
Validation loss: 3.004686143697017

Epoch: 5| Step: 9
Training loss: 3.3516114415861358
Validation loss: 3.004246969974372

Epoch: 5| Step: 10
Training loss: 3.3148324779684764
Validation loss: 3.0047657108324337

Epoch: 63| Step: 0
Training loss: 3.442294297399225
Validation loss: 3.0049075881141536

Epoch: 5| Step: 1
Training loss: 3.575959195657348
Validation loss: 3.0045447900957054

Epoch: 5| Step: 2
Training loss: 2.827711970902794
Validation loss: 3.0035992424192055

Epoch: 5| Step: 3
Training loss: 3.2221054808709164
Validation loss: 3.003628609436912

Epoch: 5| Step: 4
Training loss: 3.179960271959037
Validation loss: 3.0027109923698063

Epoch: 5| Step: 5
Training loss: 2.5929814314524933
Validation loss: 3.0026195379764387

Epoch: 5| Step: 6
Training loss: 3.2390218331948746
Validation loss: 3.001305205630235

Epoch: 5| Step: 7
Training loss: 3.7589769363527927
Validation loss: 3.0009233769619885

Epoch: 5| Step: 8
Training loss: 3.369726087039177
Validation loss: 3.00219630613736

Epoch: 5| Step: 9
Training loss: 3.231667827693212
Validation loss: 2.999683930896134

Epoch: 5| Step: 10
Training loss: 3.596071372583062
Validation loss: 2.998154245014312

Epoch: 64| Step: 0
Training loss: 2.8012557006941345
Validation loss: 3.0115638185412164

Epoch: 5| Step: 1
Training loss: 3.123464130633487
Validation loss: 3.000406213829864

Epoch: 5| Step: 2
Training loss: 3.6234945920301413
Validation loss: 2.999905007065043

Epoch: 5| Step: 3
Training loss: 2.8499664438514185
Validation loss: 2.9980400179164977

Epoch: 5| Step: 4
Training loss: 3.2299216751664366
Validation loss: 2.9982731320020295

Epoch: 5| Step: 5
Training loss: 3.369434147087255
Validation loss: 2.9987116041565667

Epoch: 5| Step: 6
Training loss: 3.5014838751596344
Validation loss: 3.000418692771364

Epoch: 5| Step: 7
Training loss: 3.4592082437436438
Validation loss: 3.001842346673109

Epoch: 5| Step: 8
Training loss: 3.2906217888420644
Validation loss: 2.9987015990809316

Epoch: 5| Step: 9
Training loss: 2.9180932688667895
Validation loss: 3.000813504639267

Epoch: 5| Step: 10
Training loss: 3.8831061208067412
Validation loss: 2.999134359268788

Epoch: 65| Step: 0
Training loss: 2.85901777193484
Validation loss: 3.0000899841458755

Epoch: 5| Step: 1
Training loss: 3.3857654254953182
Validation loss: 2.9988770964135116

Epoch: 5| Step: 2
Training loss: 3.727584346888932
Validation loss: 2.9970046457989077

Epoch: 5| Step: 3
Training loss: 3.540814435559343
Validation loss: 2.997180439225828

Epoch: 5| Step: 4
Training loss: 3.8032090841509825
Validation loss: 2.996459400414295

Epoch: 5| Step: 5
Training loss: 2.962644060068667
Validation loss: 2.997527304953671

Epoch: 5| Step: 6
Training loss: 3.169932555194192
Validation loss: 2.99531387348841

Epoch: 5| Step: 7
Training loss: 2.8646082281707077
Validation loss: 2.995551107381567

Epoch: 5| Step: 8
Training loss: 3.1753888890752884
Validation loss: 2.9952271155700543

Epoch: 5| Step: 9
Training loss: 3.493202147410851
Validation loss: 2.994705250025147

Epoch: 5| Step: 10
Training loss: 2.890655847333295
Validation loss: 2.9945461817102124

Epoch: 66| Step: 0
Training loss: 2.611364828007303
Validation loss: 2.994883848308003

Epoch: 5| Step: 1
Training loss: 3.327663192587739
Validation loss: 2.9929441621272646

Epoch: 5| Step: 2
Training loss: 3.452763465148554
Validation loss: 2.9932068905463547

Epoch: 5| Step: 3
Training loss: 3.149486887481665
Validation loss: 2.989218188580921

Epoch: 5| Step: 4
Training loss: 3.707684892402878
Validation loss: 2.9963604613593695

Epoch: 5| Step: 5
Training loss: 3.244664140198555
Validation loss: 2.9984575223453813

Epoch: 5| Step: 6
Training loss: 3.3881998838260396
Validation loss: 2.996366613008173

Epoch: 5| Step: 7
Training loss: 2.677785481995421
Validation loss: 3.0044699937496984

Epoch: 5| Step: 8
Training loss: 2.836748495867865
Validation loss: 3.0111434291463506

Epoch: 5| Step: 9
Training loss: 3.817377441277559
Validation loss: 3.011150443694509

Epoch: 5| Step: 10
Training loss: 3.631989022721494
Validation loss: 2.9902620274420357

Epoch: 67| Step: 0
Training loss: 3.9927760696271837
Validation loss: 2.9880004725166964

Epoch: 5| Step: 1
Training loss: 2.9946272741338493
Validation loss: 2.988876575372888

Epoch: 5| Step: 2
Training loss: 3.079122159134649
Validation loss: 2.990282994225215

Epoch: 5| Step: 3
Training loss: 3.3709329188803667
Validation loss: 2.990586567444246

Epoch: 5| Step: 4
Training loss: 2.8300205011602486
Validation loss: 2.99403360596435

Epoch: 5| Step: 5
Training loss: 3.7807580296802517
Validation loss: 2.995023219219747

Epoch: 5| Step: 6
Training loss: 3.272459334666498
Validation loss: 2.9911537917689226

Epoch: 5| Step: 7
Training loss: 2.760545538047336
Validation loss: 2.991697791552884

Epoch: 5| Step: 8
Training loss: 3.5353870295442102
Validation loss: 2.988574241276194

Epoch: 5| Step: 9
Training loss: 3.4150970078816485
Validation loss: 2.9873662457254224

Epoch: 5| Step: 10
Training loss: 2.6587507257070477
Validation loss: 2.9850528202642064

Epoch: 68| Step: 0
Training loss: 2.8939121011436244
Validation loss: 2.986420184737827

Epoch: 5| Step: 1
Training loss: 2.912745937720123
Validation loss: 2.9832940493694555

Epoch: 5| Step: 2
Training loss: 3.0555490512971333
Validation loss: 2.986820333485029

Epoch: 5| Step: 3
Training loss: 3.5057772230973665
Validation loss: 2.987154270768603

Epoch: 5| Step: 4
Training loss: 3.1666558081457454
Validation loss: 2.982319342117559

Epoch: 5| Step: 5
Training loss: 3.8530109769188092
Validation loss: 2.979915572668533

Epoch: 5| Step: 6
Training loss: 2.290295577984137
Validation loss: 2.983088510650988

Epoch: 5| Step: 7
Training loss: 3.301612090330954
Validation loss: 2.988239917902257

Epoch: 5| Step: 8
Training loss: 3.658614217508278
Validation loss: 2.982750534115038

Epoch: 5| Step: 9
Training loss: 3.5976581055743044
Validation loss: 2.982229220642609

Epoch: 5| Step: 10
Training loss: 3.4482699824973655
Validation loss: 2.98890803492433

Epoch: 69| Step: 0
Training loss: 2.9440500807026955
Validation loss: 2.986094386620002

Epoch: 5| Step: 1
Training loss: 3.246761615965324
Validation loss: 2.988753056677753

Epoch: 5| Step: 2
Training loss: 3.0213320791753113
Validation loss: 2.9844731827610236

Epoch: 5| Step: 3
Training loss: 2.5593128387764703
Validation loss: 2.9840282858783818

Epoch: 5| Step: 4
Training loss: 3.327420155565359
Validation loss: 2.9844676989466783

Epoch: 5| Step: 5
Training loss: 3.378443056673091
Validation loss: 2.9808607688052975

Epoch: 5| Step: 6
Training loss: 3.1632675867781916
Validation loss: 2.979408564701379

Epoch: 5| Step: 7
Training loss: 3.2118998104160843
Validation loss: 2.979877595057892

Epoch: 5| Step: 8
Training loss: 3.904465412664249
Validation loss: 2.97880628491285

Epoch: 5| Step: 9
Training loss: 2.9425707939661265
Validation loss: 2.9774555777151033

Epoch: 5| Step: 10
Training loss: 4.0631722700968975
Validation loss: 2.9776669430613896

Epoch: 70| Step: 0
Training loss: 3.166803976060174
Validation loss: 2.975821004385604

Epoch: 5| Step: 1
Training loss: 3.913471839788848
Validation loss: 2.976118427629212

Epoch: 5| Step: 2
Training loss: 3.072683724232782
Validation loss: 2.9767245773188487

Epoch: 5| Step: 3
Training loss: 3.3987743693043146
Validation loss: 2.975238419745388

Epoch: 5| Step: 4
Training loss: 2.795279276753288
Validation loss: 2.9765776084581277

Epoch: 5| Step: 5
Training loss: 3.099840123145466
Validation loss: 2.9757298745567784

Epoch: 5| Step: 6
Training loss: 3.3854141626593304
Validation loss: 2.9754278184043277

Epoch: 5| Step: 7
Training loss: 2.4436463355982316
Validation loss: 2.9730848476351444

Epoch: 5| Step: 8
Training loss: 2.9941600542626294
Validation loss: 2.9731280511505873

Epoch: 5| Step: 9
Training loss: 3.7493678513815025
Validation loss: 2.9727849701360123

Epoch: 5| Step: 10
Training loss: 3.652525871754429
Validation loss: 2.973881405088516

Epoch: 71| Step: 0
Training loss: 2.612671557182504
Validation loss: 2.9744927328613926

Epoch: 5| Step: 1
Training loss: 3.5134103538810124
Validation loss: 2.9750761046326217

Epoch: 5| Step: 2
Training loss: 2.082983089252014
Validation loss: 2.971830587263444

Epoch: 5| Step: 3
Training loss: 3.625390656566507
Validation loss: 2.9711219107471987

Epoch: 5| Step: 4
Training loss: 3.945662258243593
Validation loss: 2.974032730169923

Epoch: 5| Step: 5
Training loss: 3.5772002911799294
Validation loss: 2.972534732594123

Epoch: 5| Step: 6
Training loss: 2.8324774028957473
Validation loss: 2.9737725267804196

Epoch: 5| Step: 7
Training loss: 3.926517003892935
Validation loss: 2.9711194050218297

Epoch: 5| Step: 8
Training loss: 3.0270463563603855
Validation loss: 2.9700791712953736

Epoch: 5| Step: 9
Training loss: 3.0740248583829075
Validation loss: 2.9715684414430372

Epoch: 5| Step: 10
Training loss: 3.072658428828604
Validation loss: 2.970565944290954

Epoch: 72| Step: 0
Training loss: 3.2706951590021527
Validation loss: 2.968535935737343

Epoch: 5| Step: 1
Training loss: 3.5036997994764154
Validation loss: 2.967061018396013

Epoch: 5| Step: 2
Training loss: 3.0163135434289567
Validation loss: 2.9667539404899315

Epoch: 5| Step: 3
Training loss: 3.4705418263201073
Validation loss: 2.9673525489084525

Epoch: 5| Step: 4
Training loss: 3.357173890547237
Validation loss: 2.9673982955080485

Epoch: 5| Step: 5
Training loss: 3.229940424272272
Validation loss: 2.9665263269166244

Epoch: 5| Step: 6
Training loss: 3.107649894898506
Validation loss: 2.9671098894662524

Epoch: 5| Step: 7
Training loss: 3.3388716147327333
Validation loss: 2.9655564112983814

Epoch: 5| Step: 8
Training loss: 3.468466394876164
Validation loss: 2.964928449369098

Epoch: 5| Step: 9
Training loss: 2.6799709514922516
Validation loss: 2.964266406717153

Epoch: 5| Step: 10
Training loss: 3.2196805034903173
Validation loss: 2.9680475531944683

Epoch: 73| Step: 0
Training loss: 2.8808464644837826
Validation loss: 2.964335603283406

Epoch: 5| Step: 1
Training loss: 2.829327238205155
Validation loss: 2.9648362739686305

Epoch: 5| Step: 2
Training loss: 3.590261341666487
Validation loss: 2.967909074127828

Epoch: 5| Step: 3
Training loss: 3.642664522266269
Validation loss: 2.9617716733574326

Epoch: 5| Step: 4
Training loss: 4.012729892502802
Validation loss: 2.9610214037523708

Epoch: 5| Step: 5
Training loss: 2.585098729858346
Validation loss: 2.9625983949521277

Epoch: 5| Step: 6
Training loss: 2.828327066357993
Validation loss: 2.962445249164492

Epoch: 5| Step: 7
Training loss: 3.168331628752492
Validation loss: 2.9623106310668836

Epoch: 5| Step: 8
Training loss: 3.691529868341832
Validation loss: 2.9625896844753323

Epoch: 5| Step: 9
Training loss: 2.121718509617031
Validation loss: 2.9601826610538864

Epoch: 5| Step: 10
Training loss: 3.8837309888872285
Validation loss: 2.9597596051236517

Epoch: 74| Step: 0
Training loss: 3.3948607817070866
Validation loss: 2.9600578488711498

Epoch: 5| Step: 1
Training loss: 2.504880528142233
Validation loss: 2.9626003436863275

Epoch: 5| Step: 2
Training loss: 3.318124422643471
Validation loss: 2.959113251481316

Epoch: 5| Step: 3
Training loss: 3.603232834220539
Validation loss: 2.9586125568046784

Epoch: 5| Step: 4
Training loss: 3.273436771656766
Validation loss: 2.9598540407377203

Epoch: 5| Step: 5
Training loss: 2.739649453954684
Validation loss: 2.9574393574369067

Epoch: 5| Step: 6
Training loss: 3.5837958429209933
Validation loss: 2.958101847314169

Epoch: 5| Step: 7
Training loss: 3.648062905271156
Validation loss: 2.9581622487752366

Epoch: 5| Step: 8
Training loss: 3.190703782800534
Validation loss: 2.9583408234874207

Epoch: 5| Step: 9
Training loss: 2.800589455138709
Validation loss: 2.9595530010662485

Epoch: 5| Step: 10
Training loss: 3.4689891835822357
Validation loss: 2.957981659505583

Epoch: 75| Step: 0
Training loss: 3.237799117361923
Validation loss: 2.958007835900309

Epoch: 5| Step: 1
Training loss: 3.5295473568245805
Validation loss: 2.958055064280111

Epoch: 5| Step: 2
Training loss: 2.8542858757871072
Validation loss: 2.9561796322763065

Epoch: 5| Step: 3
Training loss: 2.7615124141117775
Validation loss: 2.956125447376039

Epoch: 5| Step: 4
Training loss: 3.0135804197683416
Validation loss: 2.957043103112652

Epoch: 5| Step: 5
Training loss: 3.202557471635889
Validation loss: 2.954799800706994

Epoch: 5| Step: 6
Training loss: 3.2342961251044597
Validation loss: 2.955071427604095

Epoch: 5| Step: 7
Training loss: 3.3628193076165585
Validation loss: 2.9584065199630607

Epoch: 5| Step: 8
Training loss: 3.7154955046524782
Validation loss: 2.9599307379535964

Epoch: 5| Step: 9
Training loss: 3.3824868695214994
Validation loss: 2.957332020177647

Epoch: 5| Step: 10
Training loss: 3.2184059922168466
Validation loss: 2.9561841443877834

Epoch: 76| Step: 0
Training loss: 3.6398319805058965
Validation loss: 2.9573081454448604

Epoch: 5| Step: 1
Training loss: 3.2133083825573876
Validation loss: 2.9553050649232966

Epoch: 5| Step: 2
Training loss: 2.8964628088901283
Validation loss: 2.9552791716761098

Epoch: 5| Step: 3
Training loss: 3.8426297423896005
Validation loss: 2.9595680750861124

Epoch: 5| Step: 4
Training loss: 3.9668848656230717
Validation loss: 2.9607679397683953

Epoch: 5| Step: 5
Training loss: 2.876850030506015
Validation loss: 2.950449693434724

Epoch: 5| Step: 6
Training loss: 2.6347433644931573
Validation loss: 2.948921151328731

Epoch: 5| Step: 7
Training loss: 3.1572546540275175
Validation loss: 2.950736165713818

Epoch: 5| Step: 8
Training loss: 3.3276490063625848
Validation loss: 2.950206723833878

Epoch: 5| Step: 9
Training loss: 3.2643586400129876
Validation loss: 2.948673073994106

Epoch: 5| Step: 10
Training loss: 2.290194599262306
Validation loss: 2.949643784490588

Epoch: 77| Step: 0
Training loss: 3.0349011013250857
Validation loss: 2.946008717415976

Epoch: 5| Step: 1
Training loss: 3.4816062429933115
Validation loss: 2.9459508480092476

Epoch: 5| Step: 2
Training loss: 3.1038428698813165
Validation loss: 2.9450893644525546

Epoch: 5| Step: 3
Training loss: 2.809020199717666
Validation loss: 2.9457143704867366

Epoch: 5| Step: 4
Training loss: 3.6470759136226603
Validation loss: 2.951785711305147

Epoch: 5| Step: 5
Training loss: 3.254678000419331
Validation loss: 2.9496784419410735

Epoch: 5| Step: 6
Training loss: 2.1421531179216244
Validation loss: 2.9453828285951125

Epoch: 5| Step: 7
Training loss: 3.480711238133178
Validation loss: 2.9444129344559267

Epoch: 5| Step: 8
Training loss: 3.352638196493459
Validation loss: 2.945528290305942

Epoch: 5| Step: 9
Training loss: 3.139089332264614
Validation loss: 2.9460038024765525

Epoch: 5| Step: 10
Training loss: 3.9768035156117816
Validation loss: 2.944164466806817

Epoch: 78| Step: 0
Training loss: 3.415000664416314
Validation loss: 2.947781586270731

Epoch: 5| Step: 1
Training loss: 2.9639576026159653
Validation loss: 2.9459812378565737

Epoch: 5| Step: 2
Training loss: 2.6916542769423475
Validation loss: 2.948359464700485

Epoch: 5| Step: 3
Training loss: 3.015744854220402
Validation loss: 2.953310469587929

Epoch: 5| Step: 4
Training loss: 3.0226841660800576
Validation loss: 2.957416443175311

Epoch: 5| Step: 5
Training loss: 3.3974998145142
Validation loss: 2.9639636900459094

Epoch: 5| Step: 6
Training loss: 3.5458610530596064
Validation loss: 2.9571407143588826

Epoch: 5| Step: 7
Training loss: 3.107461772017603
Validation loss: 2.9566189745160796

Epoch: 5| Step: 8
Training loss: 3.5800357697474054
Validation loss: 2.950443138458891

Epoch: 5| Step: 9
Training loss: 3.286052422865142
Validation loss: 2.9528074921259058

Epoch: 5| Step: 10
Training loss: 3.5130798621434516
Validation loss: 2.9477517802849458

Epoch: 79| Step: 0
Training loss: 3.074928133985379
Validation loss: 2.94757015659089

Epoch: 5| Step: 1
Training loss: 2.9068445397411016
Validation loss: 2.9450096909753394

Epoch: 5| Step: 2
Training loss: 3.4530288890046634
Validation loss: 2.9413020807566497

Epoch: 5| Step: 3
Training loss: 3.2924817359782708
Validation loss: 2.9418990369498523

Epoch: 5| Step: 4
Training loss: 3.1718392205686743
Validation loss: 2.939997743707968

Epoch: 5| Step: 5
Training loss: 2.885443585174997
Validation loss: 2.939638794391443

Epoch: 5| Step: 6
Training loss: 2.5269269407917436
Validation loss: 2.937263339599634

Epoch: 5| Step: 7
Training loss: 3.67236143096159
Validation loss: 2.9374809953977645

Epoch: 5| Step: 8
Training loss: 3.3039236786735118
Validation loss: 2.9394429557269257

Epoch: 5| Step: 9
Training loss: 3.456150852319565
Validation loss: 2.9362469882719404

Epoch: 5| Step: 10
Training loss: 3.7160891461966394
Validation loss: 2.937689990390719

Epoch: 80| Step: 0
Training loss: 3.2561956185103282
Validation loss: 2.93744263672614

Epoch: 5| Step: 1
Training loss: 3.281725458484192
Validation loss: 2.936799801345414

Epoch: 5| Step: 2
Training loss: 3.3451515183964795
Validation loss: 2.9378177433446706

Epoch: 5| Step: 3
Training loss: 3.4165818893955695
Validation loss: 2.94055977473164

Epoch: 5| Step: 4
Training loss: 3.2005843344281852
Validation loss: 2.9543870298703947

Epoch: 5| Step: 5
Training loss: 3.3981020005461464
Validation loss: 2.9517514850618616

Epoch: 5| Step: 6
Training loss: 2.552327877447202
Validation loss: 2.9340133527482974

Epoch: 5| Step: 7
Training loss: 3.6365494734788197
Validation loss: 2.9341582920668037

Epoch: 5| Step: 8
Training loss: 3.2604931384656286
Validation loss: 2.9342502569270406

Epoch: 5| Step: 9
Training loss: 2.67637567530627
Validation loss: 2.936003545354765

Epoch: 5| Step: 10
Training loss: 3.3478713261387205
Validation loss: 2.9319283439863733

Epoch: 81| Step: 0
Training loss: 4.03517468458398
Validation loss: 2.932673114497128

Epoch: 5| Step: 1
Training loss: 2.58476244456554
Validation loss: 2.9352193954069605

Epoch: 5| Step: 2
Training loss: 2.746518098214239
Validation loss: 2.932208472023769

Epoch: 5| Step: 3
Training loss: 3.3901153040718754
Validation loss: 2.9375575890587253

Epoch: 5| Step: 4
Training loss: 2.9401033917885844
Validation loss: 2.9482145844117453

Epoch: 5| Step: 5
Training loss: 3.033049531033517
Validation loss: 2.9581400221585534

Epoch: 5| Step: 6
Training loss: 3.4286865998406384
Validation loss: 2.9495441207575066

Epoch: 5| Step: 7
Training loss: 2.9436514544342494
Validation loss: 2.9370082844259513

Epoch: 5| Step: 8
Training loss: 3.2320790273239277
Validation loss: 2.9298097952745477

Epoch: 5| Step: 9
Training loss: 3.744650267299958
Validation loss: 2.929172007284648

Epoch: 5| Step: 10
Training loss: 3.167045336385276
Validation loss: 2.931648661396053

Epoch: 82| Step: 0
Training loss: 3.185435954489402
Validation loss: 2.932328898761542

Epoch: 5| Step: 1
Training loss: 3.290701197423968
Validation loss: 2.93639759523171

Epoch: 5| Step: 2
Training loss: 3.1360572506972635
Validation loss: 2.937522031081368

Epoch: 5| Step: 3
Training loss: 2.659909050612772
Validation loss: 2.9356112441824087

Epoch: 5| Step: 4
Training loss: 3.206159838027796
Validation loss: 2.9396736482838453

Epoch: 5| Step: 5
Training loss: 3.5796641408556926
Validation loss: 2.9267079259992514

Epoch: 5| Step: 6
Training loss: 3.4375532666327513
Validation loss: 2.925700042157078

Epoch: 5| Step: 7
Training loss: 3.2230826540819497
Validation loss: 2.9245715124479257

Epoch: 5| Step: 8
Training loss: 2.745213417692548
Validation loss: 2.9247432027017237

Epoch: 5| Step: 9
Training loss: 3.2305335484640096
Validation loss: 2.9289291194375155

Epoch: 5| Step: 10
Training loss: 3.747137121301402
Validation loss: 2.933014137090537

Epoch: 83| Step: 0
Training loss: 3.6652270583195916
Validation loss: 2.9335473984649454

Epoch: 5| Step: 1
Training loss: 3.1532950590793525
Validation loss: 2.9280372580129614

Epoch: 5| Step: 2
Training loss: 2.874524118595325
Validation loss: 2.9254297052144773

Epoch: 5| Step: 3
Training loss: 3.5478371814926675
Validation loss: 2.924606339908694

Epoch: 5| Step: 4
Training loss: 3.317248988828218
Validation loss: 2.9227784954337013

Epoch: 5| Step: 5
Training loss: 3.2855060404778746
Validation loss: 2.925300517358074

Epoch: 5| Step: 6
Training loss: 3.240606230310804
Validation loss: 2.92533282362062

Epoch: 5| Step: 7
Training loss: 3.275723408016189
Validation loss: 2.9242661261137877

Epoch: 5| Step: 8
Training loss: 2.555869665974907
Validation loss: 2.9200416820493773

Epoch: 5| Step: 9
Training loss: 3.1960531929182423
Validation loss: 2.924571938469055

Epoch: 5| Step: 10
Training loss: 3.127805137476973
Validation loss: 2.9221519105172735

Epoch: 84| Step: 0
Training loss: 3.166307797090796
Validation loss: 2.9232704892945844

Epoch: 5| Step: 1
Training loss: 3.0701730322768643
Validation loss: 2.919864294576582

Epoch: 5| Step: 2
Training loss: 3.915322228589433
Validation loss: 2.9239744415751923

Epoch: 5| Step: 3
Training loss: 3.1414226069542757
Validation loss: 2.921928739993987

Epoch: 5| Step: 4
Training loss: 3.274422071875456
Validation loss: 2.9238569210398304

Epoch: 5| Step: 5
Training loss: 3.751279739724691
Validation loss: 2.923402423104184

Epoch: 5| Step: 6
Training loss: 2.500257002018264
Validation loss: 2.9207209282685147

Epoch: 5| Step: 7
Training loss: 2.6340517472475242
Validation loss: 2.9211869600213296

Epoch: 5| Step: 8
Training loss: 3.414762865940039
Validation loss: 2.9234945079630985

Epoch: 5| Step: 9
Training loss: 3.3292091287348655
Validation loss: 2.9178325271333407

Epoch: 5| Step: 10
Training loss: 2.828376800961384
Validation loss: 2.919972139071926

Epoch: 85| Step: 0
Training loss: 3.0568643213872146
Validation loss: 2.9199431221019143

Epoch: 5| Step: 1
Training loss: 2.7684638329724156
Validation loss: 2.9212485688141028

Epoch: 5| Step: 2
Training loss: 3.244621374438681
Validation loss: 2.920628704172633

Epoch: 5| Step: 3
Training loss: 3.0970915656098197
Validation loss: 2.9223360359582524

Epoch: 5| Step: 4
Training loss: 3.1183224860906065
Validation loss: 2.9220666520368486

Epoch: 5| Step: 5
Training loss: 3.418914908105311
Validation loss: 2.929625291608245

Epoch: 5| Step: 6
Training loss: 3.475308515726335
Validation loss: 2.927959906598479

Epoch: 5| Step: 7
Training loss: 3.0608444410026134
Validation loss: 2.9248313716194554

Epoch: 5| Step: 8
Training loss: 3.837391129232325
Validation loss: 2.9218139729803947

Epoch: 5| Step: 9
Training loss: 3.172523018924059
Validation loss: 2.919644393848457

Epoch: 5| Step: 10
Training loss: 3.0436059874631254
Validation loss: 2.919050278688962

Epoch: 86| Step: 0
Training loss: 3.7843523146109264
Validation loss: 2.9170642851302375

Epoch: 5| Step: 1
Training loss: 2.714318006366435
Validation loss: 2.91696075386593

Epoch: 5| Step: 2
Training loss: 2.826156099456014
Validation loss: 2.917746542328568

Epoch: 5| Step: 3
Training loss: 3.883486407186806
Validation loss: 2.9196916509810977

Epoch: 5| Step: 4
Training loss: 3.048178525997941
Validation loss: 2.9162813210427205

Epoch: 5| Step: 5
Training loss: 2.9717055215254824
Validation loss: 2.9151114493998844

Epoch: 5| Step: 6
Training loss: 3.3541682146594027
Validation loss: 2.917133839427203

Epoch: 5| Step: 7
Training loss: 3.165917123795443
Validation loss: 2.915538557077978

Epoch: 5| Step: 8
Training loss: 2.9692528549762596
Validation loss: 2.915533190689268

Epoch: 5| Step: 9
Training loss: 3.5236177588659787
Validation loss: 2.917520317869221

Epoch: 5| Step: 10
Training loss: 2.8489846478815477
Validation loss: 2.9192151583399553

Epoch: 87| Step: 0
Training loss: 2.6329820165197493
Validation loss: 2.9189002530623402

Epoch: 5| Step: 1
Training loss: 3.179129886706086
Validation loss: 2.9194864105637293

Epoch: 5| Step: 2
Training loss: 3.0577676761014305
Validation loss: 2.9170443142404916

Epoch: 5| Step: 3
Training loss: 2.656148033428913
Validation loss: 2.917040457849799

Epoch: 5| Step: 4
Training loss: 2.9412786651135336
Validation loss: 2.9156060172723497

Epoch: 5| Step: 5
Training loss: 3.2525961850111402
Validation loss: 2.9151391311316277

Epoch: 5| Step: 6
Training loss: 3.7969591421843076
Validation loss: 2.9144068745982277

Epoch: 5| Step: 7
Training loss: 3.201141189698111
Validation loss: 2.91206670294228

Epoch: 5| Step: 8
Training loss: 3.066707756624125
Validation loss: 2.9139923304552595

Epoch: 5| Step: 9
Training loss: 3.6663029374710816
Validation loss: 2.912162656971931

Epoch: 5| Step: 10
Training loss: 3.6449522570503934
Validation loss: 2.9107378005085525

Epoch: 88| Step: 0
Training loss: 3.5700671489395
Validation loss: 2.9113900279733134

Epoch: 5| Step: 1
Training loss: 3.376184326346645
Validation loss: 2.9121043632312724

Epoch: 5| Step: 2
Training loss: 3.0453225900434915
Validation loss: 2.9125984242160645

Epoch: 5| Step: 3
Training loss: 3.667289955453564
Validation loss: 2.9126733564858154

Epoch: 5| Step: 4
Training loss: 3.0777019074411505
Validation loss: 2.9160904879227414

Epoch: 5| Step: 5
Training loss: 3.8160353981151656
Validation loss: 2.920923412913421

Epoch: 5| Step: 6
Training loss: 2.3087577438844225
Validation loss: 2.9237697797519355

Epoch: 5| Step: 7
Training loss: 2.958611614051478
Validation loss: 2.9213317757440964

Epoch: 5| Step: 8
Training loss: 2.5943826110772314
Validation loss: 2.9208888970042195

Epoch: 5| Step: 9
Training loss: 3.1454758262014626
Validation loss: 2.914587602418207

Epoch: 5| Step: 10
Training loss: 3.3549255713039683
Validation loss: 2.9138714705379085

Epoch: 89| Step: 0
Training loss: 3.0344480967335756
Validation loss: 2.917234367871469

Epoch: 5| Step: 1
Training loss: 3.4842488218991012
Validation loss: 2.9171460901765296

Epoch: 5| Step: 2
Training loss: 2.6659728776907166
Validation loss: 2.917179789138789

Epoch: 5| Step: 3
Training loss: 3.4922604137207767
Validation loss: 2.917509718906353

Epoch: 5| Step: 4
Training loss: 3.4237180997902055
Validation loss: 2.9165836090942285

Epoch: 5| Step: 5
Training loss: 2.912066474051029
Validation loss: 2.92203528878331

Epoch: 5| Step: 6
Training loss: 3.201981801045039
Validation loss: 2.909904364799699

Epoch: 5| Step: 7
Training loss: 3.464728834102297
Validation loss: 2.9111857574566993

Epoch: 5| Step: 8
Training loss: 3.197317077558277
Validation loss: 2.9062345823897195

Epoch: 5| Step: 9
Training loss: 3.0061874161072724
Validation loss: 2.903102449818111

Epoch: 5| Step: 10
Training loss: 3.181384634230506
Validation loss: 2.902102685614457

Epoch: 90| Step: 0
Training loss: 3.022781655792994
Validation loss: 2.903774951940987

Epoch: 5| Step: 1
Training loss: 3.3156126261200685
Validation loss: 2.900402181019596

Epoch: 5| Step: 2
Training loss: 3.19147303685281
Validation loss: 2.9003404325907876

Epoch: 5| Step: 3
Training loss: 3.112934471354837
Validation loss: 2.89849919344515

Epoch: 5| Step: 4
Training loss: 3.148094139591597
Validation loss: 2.8989111166184878

Epoch: 5| Step: 5
Training loss: 2.4884557258602475
Validation loss: 2.8972191934154803

Epoch: 5| Step: 6
Training loss: 3.762626498811125
Validation loss: 2.897707207962903

Epoch: 5| Step: 7
Training loss: 3.363194906475518
Validation loss: 2.896969340828601

Epoch: 5| Step: 8
Training loss: 3.2136437365346913
Validation loss: 2.8970516248114393

Epoch: 5| Step: 9
Training loss: 3.4557943254128514
Validation loss: 2.9022963658605856

Epoch: 5| Step: 10
Training loss: 2.868102049944612
Validation loss: 2.910599210747054

Epoch: 91| Step: 0
Training loss: 3.0896877244602208
Validation loss: 2.9062046114080613

Epoch: 5| Step: 1
Training loss: 3.05879610252167
Validation loss: 2.897805397109907

Epoch: 5| Step: 2
Training loss: 3.6498922515015155
Validation loss: 2.8953288864988598

Epoch: 5| Step: 3
Training loss: 3.4782384368960915
Validation loss: 2.8975387500803227

Epoch: 5| Step: 4
Training loss: 3.151193628771603
Validation loss: 2.894867400781214

Epoch: 5| Step: 5
Training loss: 2.8457334539071004
Validation loss: 2.8959121876324545

Epoch: 5| Step: 6
Training loss: 2.928527928072479
Validation loss: 2.8962252736669574

Epoch: 5| Step: 7
Training loss: 2.77323719429616
Validation loss: 2.891458909780753

Epoch: 5| Step: 8
Training loss: 3.6391108560850376
Validation loss: 2.895516900967905

Epoch: 5| Step: 9
Training loss: 3.59147837618086
Validation loss: 2.9004990786508458

Epoch: 5| Step: 10
Training loss: 2.6271405348170767
Validation loss: 2.9104771811164447

Epoch: 92| Step: 0
Training loss: 3.5197759240528357
Validation loss: 2.924546247355503

Epoch: 5| Step: 1
Training loss: 2.2297423026521637
Validation loss: 2.9343646581058382

Epoch: 5| Step: 2
Training loss: 3.4072595902490668
Validation loss: 2.928339166829135

Epoch: 5| Step: 3
Training loss: 3.680691916061032
Validation loss: 2.916083897910532

Epoch: 5| Step: 4
Training loss: 2.7241157987071007
Validation loss: 2.890095174801745

Epoch: 5| Step: 5
Training loss: 3.133401334985103
Validation loss: 2.8900747390173853

Epoch: 5| Step: 6
Training loss: 3.070430530094553
Validation loss: 2.892325562530376

Epoch: 5| Step: 7
Training loss: 3.3804721974195937
Validation loss: 2.8940225125642276

Epoch: 5| Step: 8
Training loss: 3.004046572023271
Validation loss: 2.89945199411704

Epoch: 5| Step: 9
Training loss: 3.7784003246568116
Validation loss: 2.892559245353996

Epoch: 5| Step: 10
Training loss: 2.952685126590221
Validation loss: 2.8911572747585836

Epoch: 93| Step: 0
Training loss: 2.96141801221415
Validation loss: 2.893294551159985

Epoch: 5| Step: 1
Training loss: 3.188723011627892
Validation loss: 2.8905997255523532

Epoch: 5| Step: 2
Training loss: 3.1262058220464106
Validation loss: 2.891117028130676

Epoch: 5| Step: 3
Training loss: 3.331870966250372
Validation loss: 2.8910896138513897

Epoch: 5| Step: 4
Training loss: 3.1287175763378436
Validation loss: 2.8895781683769006

Epoch: 5| Step: 5
Training loss: 2.723992565710647
Validation loss: 2.8901667361639998

Epoch: 5| Step: 6
Training loss: 3.719074908255785
Validation loss: 2.897082257706598

Epoch: 5| Step: 7
Training loss: 3.479188077636136
Validation loss: 2.892549005163971

Epoch: 5| Step: 8
Training loss: 3.3196657515794374
Validation loss: 2.8924070586054103

Epoch: 5| Step: 9
Training loss: 3.119118916741146
Validation loss: 2.890937977581331

Epoch: 5| Step: 10
Training loss: 2.8580445910232655
Validation loss: 2.8898666171881175

Epoch: 94| Step: 0
Training loss: 3.567200220313432
Validation loss: 2.8917312629276712

Epoch: 5| Step: 1
Training loss: 3.2223514297128215
Validation loss: 2.88959728042742

Epoch: 5| Step: 2
Training loss: 2.957199918303043
Validation loss: 2.8904373759911635

Epoch: 5| Step: 3
Training loss: 3.1284728017889503
Validation loss: 2.8904911949276384

Epoch: 5| Step: 4
Training loss: 3.2395763499357426
Validation loss: 2.8901131285098955

Epoch: 5| Step: 5
Training loss: 3.4594862674507287
Validation loss: 2.8901083030182693

Epoch: 5| Step: 6
Training loss: 2.896341311316431
Validation loss: 2.8930303249183438

Epoch: 5| Step: 7
Training loss: 3.7729079860262305
Validation loss: 2.891229974064036

Epoch: 5| Step: 8
Training loss: 3.0202950008889893
Validation loss: 2.8928965593184564

Epoch: 5| Step: 9
Training loss: 2.8249709946485235
Validation loss: 2.894539911978654

Epoch: 5| Step: 10
Training loss: 2.7209993900801686
Validation loss: 2.8934744074550336

Epoch: 95| Step: 0
Training loss: 2.678904694306152
Validation loss: 2.8922052313884

Epoch: 5| Step: 1
Training loss: 2.966129632268685
Validation loss: 2.8881449349520376

Epoch: 5| Step: 2
Training loss: 3.342976988808789
Validation loss: 2.8887028141876563

Epoch: 5| Step: 3
Training loss: 2.5768087090165945
Validation loss: 2.8869667981821645

Epoch: 5| Step: 4
Training loss: 3.0585957767094976
Validation loss: 2.887900694186661

Epoch: 5| Step: 5
Training loss: 3.2493024224131255
Validation loss: 2.8846962145094674

Epoch: 5| Step: 6
Training loss: 3.4806068470077887
Validation loss: 2.883874112066681

Epoch: 5| Step: 7
Training loss: 3.79105159815171
Validation loss: 2.881290285014228

Epoch: 5| Step: 8
Training loss: 3.0738430544933855
Validation loss: 2.8815956734601955

Epoch: 5| Step: 9
Training loss: 2.532540169159127
Validation loss: 2.8818830744925252

Epoch: 5| Step: 10
Training loss: 3.9961237006682464
Validation loss: 2.880745406638285

Epoch: 96| Step: 0
Training loss: 3.4454680600156333
Validation loss: 2.8811276564585517

Epoch: 5| Step: 1
Training loss: 3.0716538932756867
Validation loss: 2.879632731466432

Epoch: 5| Step: 2
Training loss: 2.612281140372846
Validation loss: 2.8805750953231857

Epoch: 5| Step: 3
Training loss: 3.0818341365001234
Validation loss: 2.8805043627791798

Epoch: 5| Step: 4
Training loss: 3.545184434147135
Validation loss: 2.880876289931206

Epoch: 5| Step: 5
Training loss: 3.033529152330993
Validation loss: 2.8837272472650275

Epoch: 5| Step: 6
Training loss: 3.646071914859222
Validation loss: 2.8810759974996976

Epoch: 5| Step: 7
Training loss: 3.0651548128095025
Validation loss: 2.8835033797533796

Epoch: 5| Step: 8
Training loss: 3.3425556081798273
Validation loss: 2.8855068491372053

Epoch: 5| Step: 9
Training loss: 2.672209780058927
Validation loss: 2.8808827753856443

Epoch: 5| Step: 10
Training loss: 3.2944274784685534
Validation loss: 2.8794475002160924

Epoch: 97| Step: 0
Training loss: 2.898495079764151
Validation loss: 2.880135164746535

Epoch: 5| Step: 1
Training loss: 3.0223091642022655
Validation loss: 2.8786249514638587

Epoch: 5| Step: 2
Training loss: 3.279319122402572
Validation loss: 2.877828902266104

Epoch: 5| Step: 3
Training loss: 3.7099806023679274
Validation loss: 2.876485570069718

Epoch: 5| Step: 4
Training loss: 3.281677508887622
Validation loss: 2.8745650612944593

Epoch: 5| Step: 5
Training loss: 2.9600020166338674
Validation loss: 2.8782630386982886

Epoch: 5| Step: 6
Training loss: 3.434698176776492
Validation loss: 2.8855982225380234

Epoch: 5| Step: 7
Training loss: 3.667324541779575
Validation loss: 2.8931879115382553

Epoch: 5| Step: 8
Training loss: 2.833622263219859
Validation loss: 2.899708963775456

Epoch: 5| Step: 9
Training loss: 2.606406802210587
Validation loss: 2.8859240619369144

Epoch: 5| Step: 10
Training loss: 3.0733352807039505
Validation loss: 2.8801067202118147

Epoch: 98| Step: 0
Training loss: 3.393700255421068
Validation loss: 2.8772306683272713

Epoch: 5| Step: 1
Training loss: 2.7160176545301096
Validation loss: 2.8772535832252815

Epoch: 5| Step: 2
Training loss: 2.897835805291796
Validation loss: 2.873503639340464

Epoch: 5| Step: 3
Training loss: 3.353929373045873
Validation loss: 2.874851546661372

Epoch: 5| Step: 4
Training loss: 3.703720366829016
Validation loss: 2.8708643404388106

Epoch: 5| Step: 5
Training loss: 3.0930421578179406
Validation loss: 2.87136450813386

Epoch: 5| Step: 6
Training loss: 3.570175068086251
Validation loss: 2.868974108745392

Epoch: 5| Step: 7
Training loss: 2.8559553198858993
Validation loss: 2.8705670054719135

Epoch: 5| Step: 8
Training loss: 3.2126086264921407
Validation loss: 2.8683927540512073

Epoch: 5| Step: 9
Training loss: 2.9440612563622683
Validation loss: 2.868681908574915

Epoch: 5| Step: 10
Training loss: 2.992862316560224
Validation loss: 2.86890451993355

Epoch: 99| Step: 0
Training loss: 3.584594342039956
Validation loss: 2.867172767369059

Epoch: 5| Step: 1
Training loss: 3.006561415437876
Validation loss: 2.8670271921732553

Epoch: 5| Step: 2
Training loss: 3.213956059096746
Validation loss: 2.868491454196898

Epoch: 5| Step: 3
Training loss: 3.5688970585601947
Validation loss: 2.8675186186432757

Epoch: 5| Step: 4
Training loss: 3.4314674850495304
Validation loss: 2.8683675348528554

Epoch: 5| Step: 5
Training loss: 2.6585505676798107
Validation loss: 2.866560658309399

Epoch: 5| Step: 6
Training loss: 3.520287842035604
Validation loss: 2.870174254637393

Epoch: 5| Step: 7
Training loss: 2.860649616918144
Validation loss: 2.8700442249448996

Epoch: 5| Step: 8
Training loss: 2.7198444662785133
Validation loss: 2.8687788436740402

Epoch: 5| Step: 9
Training loss: 2.8405143019590287
Validation loss: 2.865960131302012

Epoch: 5| Step: 10
Training loss: 3.3281560905329637
Validation loss: 2.8654503670070004

Epoch: 100| Step: 0
Training loss: 3.3802013583275414
Validation loss: 2.866945269735705

Epoch: 5| Step: 1
Training loss: 3.185238802833957
Validation loss: 2.866156963179723

Epoch: 5| Step: 2
Training loss: 3.2787399137096753
Validation loss: 2.862999163950745

Epoch: 5| Step: 3
Training loss: 3.017698375688548
Validation loss: 2.863508327877369

Epoch: 5| Step: 4
Training loss: 3.3362423759707784
Validation loss: 2.8638444399877874

Epoch: 5| Step: 5
Training loss: 3.0929134278192887
Validation loss: 2.8626188467125955

Epoch: 5| Step: 6
Training loss: 2.9939700561432674
Validation loss: 2.8627576162990227

Epoch: 5| Step: 7
Training loss: 2.9264821332252184
Validation loss: 2.8627131581420038

Epoch: 5| Step: 8
Training loss: 3.0513499727479583
Validation loss: 2.8632092664869084

Epoch: 5| Step: 9
Training loss: 2.9047076326670838
Validation loss: 2.8641655765916028

Epoch: 5| Step: 10
Training loss: 3.688380378759817
Validation loss: 2.861864112603775

Epoch: 101| Step: 0
Training loss: 3.606438437154968
Validation loss: 2.861300278372424

Epoch: 5| Step: 1
Training loss: 3.2513461626227467
Validation loss: 2.8605950922586225

Epoch: 5| Step: 2
Training loss: 2.688528884173491
Validation loss: 2.8657347622343483

Epoch: 5| Step: 3
Training loss: 2.9185200570015133
Validation loss: 2.862226264569408

Epoch: 5| Step: 4
Training loss: 3.173807542000565
Validation loss: 2.865900648206418

Epoch: 5| Step: 5
Training loss: 3.389865209999916
Validation loss: 2.867835764529583

Epoch: 5| Step: 6
Training loss: 3.2146761399768597
Validation loss: 2.8664208949513803

Epoch: 5| Step: 7
Training loss: 3.456420706591162
Validation loss: 2.8815024355754617

Epoch: 5| Step: 8
Training loss: 3.3057625827730144
Validation loss: 2.8770963035896404

Epoch: 5| Step: 9
Training loss: 2.786572624548358
Validation loss: 2.8797551859140613

Epoch: 5| Step: 10
Training loss: 2.90213328197806
Validation loss: 2.8651634650598266

Epoch: 102| Step: 0
Training loss: 2.918444082822727
Validation loss: 2.8595785293483402

Epoch: 5| Step: 1
Training loss: 3.1177375327307537
Validation loss: 2.857145097470907

Epoch: 5| Step: 2
Training loss: 3.398389794025793
Validation loss: 2.856593000185567

Epoch: 5| Step: 3
Training loss: 3.2154497430640863
Validation loss: 2.8575017522014985

Epoch: 5| Step: 4
Training loss: 3.0945895818631235
Validation loss: 2.8568115901519664

Epoch: 5| Step: 5
Training loss: 2.6619180679151206
Validation loss: 2.8551984481483874

Epoch: 5| Step: 6
Training loss: 3.027436522016015
Validation loss: 2.8583317536877946

Epoch: 5| Step: 7
Training loss: 3.363056808940148
Validation loss: 2.8575144846895233

Epoch: 5| Step: 8
Training loss: 3.1347616700714926
Validation loss: 2.8568719328188994

Epoch: 5| Step: 9
Training loss: 3.3385097047859835
Validation loss: 2.8560933235433708

Epoch: 5| Step: 10
Training loss: 3.448443108481931
Validation loss: 2.8547265695463317

Epoch: 103| Step: 0
Training loss: 3.3454582628033456
Validation loss: 2.85754740838687

Epoch: 5| Step: 1
Training loss: 2.9337949721892245
Validation loss: 2.855401395331019

Epoch: 5| Step: 2
Training loss: 2.98742759329546
Validation loss: 2.8542688320178207

Epoch: 5| Step: 3
Training loss: 2.999521694200916
Validation loss: 2.858880792724115

Epoch: 5| Step: 4
Training loss: 2.588875660114389
Validation loss: 2.858061074084663

Epoch: 5| Step: 5
Training loss: 2.974241778778311
Validation loss: 2.859074911769709

Epoch: 5| Step: 6
Training loss: 2.8247164423595383
Validation loss: 2.862155913365098

Epoch: 5| Step: 7
Training loss: 3.519539108013564
Validation loss: 2.859032823663043

Epoch: 5| Step: 8
Training loss: 3.4642822085827714
Validation loss: 2.8582953832235605

Epoch: 5| Step: 9
Training loss: 3.736437495336323
Validation loss: 2.855298187991746

Epoch: 5| Step: 10
Training loss: 3.177356662353511
Validation loss: 2.858150437604089

Epoch: 104| Step: 0
Training loss: 3.0017564717834047
Validation loss: 2.8560455302214187

Epoch: 5| Step: 1
Training loss: 3.021335077820039
Validation loss: 2.861718639130904

Epoch: 5| Step: 2
Training loss: 4.214076413367488
Validation loss: 2.859877490827375

Epoch: 5| Step: 3
Training loss: 2.7734861557681865
Validation loss: 2.8637461517171054

Epoch: 5| Step: 4
Training loss: 3.69191774730045
Validation loss: 2.8613566361536655

Epoch: 5| Step: 5
Training loss: 2.097138580720312
Validation loss: 2.855031307300158

Epoch: 5| Step: 6
Training loss: 3.1338601203867396
Validation loss: 2.858256508084079

Epoch: 5| Step: 7
Training loss: 3.0224872840632795
Validation loss: 2.860409057493303

Epoch: 5| Step: 8
Training loss: 3.215363433846748
Validation loss: 2.8548701705019464

Epoch: 5| Step: 9
Training loss: 2.9709976521793773
Validation loss: 2.8507106630777086

Epoch: 5| Step: 10
Training loss: 3.1444338955232354
Validation loss: 2.850837215888759

Epoch: 105| Step: 0
Training loss: 3.474705712460842
Validation loss: 2.853063691964046

Epoch: 5| Step: 1
Training loss: 3.0350497311786406
Validation loss: 2.850949511325469

Epoch: 5| Step: 2
Training loss: 3.1423644757238165
Validation loss: 2.8517722162414354

Epoch: 5| Step: 3
Training loss: 2.715245849690498
Validation loss: 2.855110490850211

Epoch: 5| Step: 4
Training loss: 3.130182165627849
Validation loss: 2.858275040280521

Epoch: 5| Step: 5
Training loss: 3.425392189682403
Validation loss: 2.8592160007725065

Epoch: 5| Step: 6
Training loss: 2.880600160478003
Validation loss: 2.861378335153484

Epoch: 5| Step: 7
Training loss: 3.59487990156178
Validation loss: 2.8583577385857297

Epoch: 5| Step: 8
Training loss: 3.4185698411186447
Validation loss: 2.852955832522374

Epoch: 5| Step: 9
Training loss: 3.0450769058312397
Validation loss: 2.849435741565637

Epoch: 5| Step: 10
Training loss: 2.5793190705151607
Validation loss: 2.8492842584539084

Epoch: 106| Step: 0
Training loss: 2.8367740458670103
Validation loss: 2.8458973519763355

Epoch: 5| Step: 1
Training loss: 2.573932174452948
Validation loss: 2.846102888207425

Epoch: 5| Step: 2
Training loss: 3.3839986012413075
Validation loss: 2.846780630850007

Epoch: 5| Step: 3
Training loss: 2.9095056817916563
Validation loss: 2.844971193668452

Epoch: 5| Step: 4
Training loss: 2.6438699681543154
Validation loss: 2.844508639974709

Epoch: 5| Step: 5
Training loss: 2.951688225220653
Validation loss: 2.8468164108916865

Epoch: 5| Step: 6
Training loss: 2.7552227363618593
Validation loss: 2.8468753463002705

Epoch: 5| Step: 7
Training loss: 3.6378464471540424
Validation loss: 2.846059639041266

Epoch: 5| Step: 8
Training loss: 3.4121229305773233
Validation loss: 2.8480456827104415

Epoch: 5| Step: 9
Training loss: 3.443500621925764
Validation loss: 2.84817386520245

Epoch: 5| Step: 10
Training loss: 3.9079451888114916
Validation loss: 2.8448811178843187

Epoch: 107| Step: 0
Training loss: 3.0901434327449144
Validation loss: 2.8424272351258075

Epoch: 5| Step: 1
Training loss: 3.427410647328733
Validation loss: 2.8420899603459557

Epoch: 5| Step: 2
Training loss: 2.9885095845669194
Validation loss: 2.8444338227300383

Epoch: 5| Step: 3
Training loss: 2.9296290684277184
Validation loss: 2.8405651327231087

Epoch: 5| Step: 4
Training loss: 3.4375973774382182
Validation loss: 2.8410677046363406

Epoch: 5| Step: 5
Training loss: 2.9303745939077683
Validation loss: 2.8400354692617764

Epoch: 5| Step: 6
Training loss: 3.2565129384434375
Validation loss: 2.840721021839004

Epoch: 5| Step: 7
Training loss: 2.951384500737138
Validation loss: 2.8400499075771344

Epoch: 5| Step: 8
Training loss: 3.0172627009498143
Validation loss: 2.8408294757564425

Epoch: 5| Step: 9
Training loss: 3.212228334569802
Validation loss: 2.8405270365853803

Epoch: 5| Step: 10
Training loss: 3.291866312531552
Validation loss: 2.8407539921668667

Epoch: 108| Step: 0
Training loss: 3.995908910031978
Validation loss: 2.8428229725729492

Epoch: 5| Step: 1
Training loss: 3.0907933142087045
Validation loss: 2.8466385238475156

Epoch: 5| Step: 2
Training loss: 3.0274688104208916
Validation loss: 2.8468892519467053

Epoch: 5| Step: 3
Training loss: 3.544948642934405
Validation loss: 2.85123586723891

Epoch: 5| Step: 4
Training loss: 1.8325854278677842
Validation loss: 2.8545552267604686

Epoch: 5| Step: 5
Training loss: 2.41389874640548
Validation loss: 2.8688710635168615

Epoch: 5| Step: 6
Training loss: 3.488613954335976
Validation loss: 2.874546594878716

Epoch: 5| Step: 7
Training loss: 3.012336796182129
Validation loss: 2.842750598176016

Epoch: 5| Step: 8
Training loss: 3.2697233191512196
Validation loss: 2.835770802355938

Epoch: 5| Step: 9
Training loss: 3.0940983123448222
Validation loss: 2.837574094833368

Epoch: 5| Step: 10
Training loss: 3.386718468407572
Validation loss: 2.8395327065265645

Epoch: 109| Step: 0
Training loss: 3.09072805450777
Validation loss: 2.8443001664902354

Epoch: 5| Step: 1
Training loss: 3.6128634154525994
Validation loss: 2.8428984309861325

Epoch: 5| Step: 2
Training loss: 3.419307076154828
Validation loss: 2.8454930182190132

Epoch: 5| Step: 3
Training loss: 2.8210842101771165
Validation loss: 2.842972313849101

Epoch: 5| Step: 4
Training loss: 2.923946034226996
Validation loss: 2.8419168994769834

Epoch: 5| Step: 5
Training loss: 3.0139060383751675
Validation loss: 2.840977940035545

Epoch: 5| Step: 6
Training loss: 2.8621789077511535
Validation loss: 2.8376574452151386

Epoch: 5| Step: 7
Training loss: 3.3194606271630405
Validation loss: 2.839742139375215

Epoch: 5| Step: 8
Training loss: 2.450743959317676
Validation loss: 2.8382789046899717

Epoch: 5| Step: 9
Training loss: 3.693545154758731
Validation loss: 2.836624104426678

Epoch: 5| Step: 10
Training loss: 3.278818155759047
Validation loss: 2.8350200542565283

Epoch: 110| Step: 0
Training loss: 3.3333680310032894
Validation loss: 2.8347214483993954

Epoch: 5| Step: 1
Training loss: 3.275972609204003
Validation loss: 2.836547803068573

Epoch: 5| Step: 2
Training loss: 3.4860422567497267
Validation loss: 2.8340802517146146

Epoch: 5| Step: 3
Training loss: 3.2717139320113975
Validation loss: 2.833963237886117

Epoch: 5| Step: 4
Training loss: 3.022223176987192
Validation loss: 2.834352226539838

Epoch: 5| Step: 5
Training loss: 2.5930128773620713
Validation loss: 2.8323967529973806

Epoch: 5| Step: 6
Training loss: 2.7703112538222485
Validation loss: 2.8326825155088393

Epoch: 5| Step: 7
Training loss: 3.359024810281464
Validation loss: 2.8330132944898043

Epoch: 5| Step: 8
Training loss: 3.0106010688525915
Validation loss: 2.8306709323786556

Epoch: 5| Step: 9
Training loss: 3.4310372375228684
Validation loss: 2.8327844626180267

Epoch: 5| Step: 10
Training loss: 2.794389611404159
Validation loss: 2.833047552613675

Epoch: 111| Step: 0
Training loss: 2.7490498028264985
Validation loss: 2.8300161674580067

Epoch: 5| Step: 1
Training loss: 3.43511533385308
Validation loss: 2.8343614405551114

Epoch: 5| Step: 2
Training loss: 3.0370057508447466
Validation loss: 2.8369186414038126

Epoch: 5| Step: 3
Training loss: 3.321093083796393
Validation loss: 2.8399023624998847

Epoch: 5| Step: 4
Training loss: 3.2096060338200365
Validation loss: 2.839942748162703

Epoch: 5| Step: 5
Training loss: 2.9072596939244146
Validation loss: 2.836772880071975

Epoch: 5| Step: 6
Training loss: 3.076247673917323
Validation loss: 2.837718196992305

Epoch: 5| Step: 7
Training loss: 3.252578446118823
Validation loss: 2.8347495045704547

Epoch: 5| Step: 8
Training loss: 3.0239232188170355
Validation loss: 2.839703666568869

Epoch: 5| Step: 9
Training loss: 3.040353064613931
Validation loss: 2.830685408496904

Epoch: 5| Step: 10
Training loss: 3.403267070512519
Validation loss: 2.834667216353071

Epoch: 112| Step: 0
Training loss: 2.8200830593457504
Validation loss: 2.832572535072921

Epoch: 5| Step: 1
Training loss: 2.7977136814301993
Validation loss: 2.8263262295753786

Epoch: 5| Step: 2
Training loss: 2.8081013509169295
Validation loss: 2.8346817109516547

Epoch: 5| Step: 3
Training loss: 3.2765943650282026
Validation loss: 2.834794062151722

Epoch: 5| Step: 4
Training loss: 3.5046387314007528
Validation loss: 2.8315759757787213

Epoch: 5| Step: 5
Training loss: 3.005192078403739
Validation loss: 2.8279099700788057

Epoch: 5| Step: 6
Training loss: 3.281901412970909
Validation loss: 2.8292163924670817

Epoch: 5| Step: 7
Training loss: 2.5379702991945168
Validation loss: 2.8252032560494156

Epoch: 5| Step: 8
Training loss: 3.258547034576959
Validation loss: 2.8264311243029363

Epoch: 5| Step: 9
Training loss: 3.561055342233768
Validation loss: 2.825251954945518

Epoch: 5| Step: 10
Training loss: 3.4592038326767995
Validation loss: 2.8237162334307615

Epoch: 113| Step: 0
Training loss: 3.2446954426139634
Validation loss: 2.825124262382633

Epoch: 5| Step: 1
Training loss: 2.8607037901409433
Validation loss: 2.8262174640220334

Epoch: 5| Step: 2
Training loss: 3.7475107196148123
Validation loss: 2.8246636264748486

Epoch: 5| Step: 3
Training loss: 3.279129214882809
Validation loss: 2.8251608901944394

Epoch: 5| Step: 4
Training loss: 3.1013288049552745
Validation loss: 2.8235658863923

Epoch: 5| Step: 5
Training loss: 3.453522258019094
Validation loss: 2.824125476930231

Epoch: 5| Step: 6
Training loss: 3.2750479075880814
Validation loss: 2.8242188934220382

Epoch: 5| Step: 7
Training loss: 2.7507637003864525
Validation loss: 2.8204758301700217

Epoch: 5| Step: 8
Training loss: 2.877701526680652
Validation loss: 2.8191499281624974

Epoch: 5| Step: 9
Training loss: 2.438851984141169
Validation loss: 2.8202367227074494

Epoch: 5| Step: 10
Training loss: 3.1751269878313497
Validation loss: 2.8199453198093027

Epoch: 114| Step: 0
Training loss: 2.8778436943697328
Validation loss: 2.8202823104062964

Epoch: 5| Step: 1
Training loss: 2.6507003254656274
Validation loss: 2.819197027499987

Epoch: 5| Step: 2
Training loss: 2.7255086091681866
Validation loss: 2.820376130518726

Epoch: 5| Step: 3
Training loss: 3.654751070993779
Validation loss: 2.8203420620729225

Epoch: 5| Step: 4
Training loss: 3.309137040787509
Validation loss: 2.8195529678898485

Epoch: 5| Step: 5
Training loss: 3.1838348859022947
Validation loss: 2.821022895709287

Epoch: 5| Step: 6
Training loss: 2.9190552513066046
Validation loss: 2.817869061757324

Epoch: 5| Step: 7
Training loss: 3.4350109452207893
Validation loss: 2.81838810752663

Epoch: 5| Step: 8
Training loss: 3.0708498108489475
Validation loss: 2.8199434124957694

Epoch: 5| Step: 9
Training loss: 3.12976169203046
Validation loss: 2.817290008325047

Epoch: 5| Step: 10
Training loss: 3.3525123228434066
Validation loss: 2.816982354469486

Epoch: 115| Step: 0
Training loss: 3.2158544163846052
Validation loss: 2.8206330195278584

Epoch: 5| Step: 1
Training loss: 3.578192431218464
Validation loss: 2.8173690951675554

Epoch: 5| Step: 2
Training loss: 3.04918641667739
Validation loss: 2.8196715862145423

Epoch: 5| Step: 3
Training loss: 3.1245235842899604
Validation loss: 2.8258651545528344

Epoch: 5| Step: 4
Training loss: 3.0451764972316453
Validation loss: 2.8405805286126733

Epoch: 5| Step: 5
Training loss: 3.196399904748187
Validation loss: 2.8216683978557997

Epoch: 5| Step: 6
Training loss: 2.470751566657033
Validation loss: 2.8184556131440894

Epoch: 5| Step: 7
Training loss: 2.5507687251439246
Validation loss: 2.816693101445668

Epoch: 5| Step: 8
Training loss: 3.535916915745984
Validation loss: 2.8177588761592736

Epoch: 5| Step: 9
Training loss: 3.2853655481967787
Validation loss: 2.8137308378497314

Epoch: 5| Step: 10
Training loss: 3.1508254468311834
Validation loss: 2.8149575857082016

Epoch: 116| Step: 0
Training loss: 3.1142706740679853
Validation loss: 2.8150043526580872

Epoch: 5| Step: 1
Training loss: 3.4901365534347066
Validation loss: 2.815447184468146

Epoch: 5| Step: 2
Training loss: 2.316667873281627
Validation loss: 2.815406287622134

Epoch: 5| Step: 3
Training loss: 2.961950445910728
Validation loss: 2.8152778133822394

Epoch: 5| Step: 4
Training loss: 3.3459711986243885
Validation loss: 2.8165956580593434

Epoch: 5| Step: 5
Training loss: 3.51251870146962
Validation loss: 2.815657099088017

Epoch: 5| Step: 6
Training loss: 3.315028107582942
Validation loss: 2.8138589490485533

Epoch: 5| Step: 7
Training loss: 2.1249514181530125
Validation loss: 2.814527071422552

Epoch: 5| Step: 8
Training loss: 3.227579986266649
Validation loss: 2.8132812836803005

Epoch: 5| Step: 9
Training loss: 3.6966911470126047
Validation loss: 2.8132750287604718

Epoch: 5| Step: 10
Training loss: 2.847647375189789
Validation loss: 2.8133216815250943

Epoch: 117| Step: 0
Training loss: 2.719491002618684
Validation loss: 2.8115382164549456

Epoch: 5| Step: 1
Training loss: 2.9643676536383774
Validation loss: 2.8135630176767625

Epoch: 5| Step: 2
Training loss: 3.3973669010053045
Validation loss: 2.814644477029324

Epoch: 5| Step: 3
Training loss: 3.1659684833685735
Validation loss: 2.814765397006965

Epoch: 5| Step: 4
Training loss: 2.772720115186205
Validation loss: 2.817974729801786

Epoch: 5| Step: 5
Training loss: 3.453164355023545
Validation loss: 2.8190415368613073

Epoch: 5| Step: 6
Training loss: 3.2682980635272028
Validation loss: 2.818160293637519

Epoch: 5| Step: 7
Training loss: 3.2073460005126346
Validation loss: 2.8255862140798635

Epoch: 5| Step: 8
Training loss: 3.291541535779656
Validation loss: 2.823088590562103

Epoch: 5| Step: 9
Training loss: 3.186229377760659
Validation loss: 2.8180028480842547

Epoch: 5| Step: 10
Training loss: 2.757750945444423
Validation loss: 2.8167225558808786

Epoch: 118| Step: 0
Training loss: 3.3110081894202126
Validation loss: 2.8144337394975665

Epoch: 5| Step: 1
Training loss: 3.1808628468738727
Validation loss: 2.810969825423826

Epoch: 5| Step: 2
Training loss: 3.1831076783361136
Validation loss: 2.817584056970865

Epoch: 5| Step: 3
Training loss: 3.109324392549061
Validation loss: 2.816205988255604

Epoch: 5| Step: 4
Training loss: 2.894119212776355
Validation loss: 2.825014396062352

Epoch: 5| Step: 5
Training loss: 3.0522996394004442
Validation loss: 2.829205685603107

Epoch: 5| Step: 6
Training loss: 3.5045380463964344
Validation loss: 2.8233435729189633

Epoch: 5| Step: 7
Training loss: 3.2689437429512425
Validation loss: 2.8234191042967858

Epoch: 5| Step: 8
Training loss: 3.0350641852792255
Validation loss: 2.813293930167155

Epoch: 5| Step: 9
Training loss: 2.6602460535158365
Validation loss: 2.8078051277165343

Epoch: 5| Step: 10
Training loss: 3.049165148682975
Validation loss: 2.8090969147678466

Epoch: 119| Step: 0
Training loss: 2.820123555202443
Validation loss: 2.8071400749500595

Epoch: 5| Step: 1
Training loss: 2.8791437555736583
Validation loss: 2.807391014002495

Epoch: 5| Step: 2
Training loss: 3.3697696706691715
Validation loss: 2.807572510893954

Epoch: 5| Step: 3
Training loss: 2.818537610631216
Validation loss: 2.8089073332755095

Epoch: 5| Step: 4
Training loss: 3.358268662075333
Validation loss: 2.8075223931373268

Epoch: 5| Step: 5
Training loss: 3.299184270665499
Validation loss: 2.8061317749099812

Epoch: 5| Step: 6
Training loss: 3.570536065979717
Validation loss: 2.8057421384607046

Epoch: 5| Step: 7
Training loss: 2.869776250909754
Validation loss: 2.8083068581554547

Epoch: 5| Step: 8
Training loss: 3.0484263065509993
Validation loss: 2.8065049706861585

Epoch: 5| Step: 9
Training loss: 3.1851506270358296
Validation loss: 2.8082121582802526

Epoch: 5| Step: 10
Training loss: 2.984571839876335
Validation loss: 2.8064010047074204

Epoch: 120| Step: 0
Training loss: 3.3784419275441286
Validation loss: 2.8036106526425906

Epoch: 5| Step: 1
Training loss: 2.7001169921112025
Validation loss: 2.803990866468095

Epoch: 5| Step: 2
Training loss: 3.357764989375664
Validation loss: 2.8049991244993127

Epoch: 5| Step: 3
Training loss: 3.288457311918397
Validation loss: 2.804271497017776

Epoch: 5| Step: 4
Training loss: 3.271425489208842
Validation loss: 2.803242592549095

Epoch: 5| Step: 5
Training loss: 2.7304526834738327
Validation loss: 2.805788113337456

Epoch: 5| Step: 6
Training loss: 3.062294933693568
Validation loss: 2.803775710097918

Epoch: 5| Step: 7
Training loss: 3.247508487822473
Validation loss: 2.809528966483954

Epoch: 5| Step: 8
Training loss: 3.026762481998963
Validation loss: 2.807660837084723

Epoch: 5| Step: 9
Training loss: 3.2608833019685965
Validation loss: 2.806490098542972

Epoch: 5| Step: 10
Training loss: 2.7524070609025566
Validation loss: 2.8104242921223443

Epoch: 121| Step: 0
Training loss: 2.992321519365248
Validation loss: 2.80893484230477

Epoch: 5| Step: 1
Training loss: 3.646388260525281
Validation loss: 2.808862407031653

Epoch: 5| Step: 2
Training loss: 3.185438948346073
Validation loss: 2.8103866476177064

Epoch: 5| Step: 3
Training loss: 2.806614290988583
Validation loss: 2.8112164329163676

Epoch: 5| Step: 4
Training loss: 3.2438610491550937
Validation loss: 2.8061201266737026

Epoch: 5| Step: 5
Training loss: 2.9510261302736067
Validation loss: 2.7986132770706607

Epoch: 5| Step: 6
Training loss: 2.6551130666562046
Validation loss: 2.7974138151632073

Epoch: 5| Step: 7
Training loss: 2.9917122485868735
Validation loss: 2.7997892743242905

Epoch: 5| Step: 8
Training loss: 3.527502181000444
Validation loss: 2.7980105048071584

Epoch: 5| Step: 9
Training loss: 2.928219358700932
Validation loss: 2.796577838843369

Epoch: 5| Step: 10
Training loss: 3.119476319404303
Validation loss: 2.796991396830945

Epoch: 122| Step: 0
Training loss: 3.020339364190377
Validation loss: 2.797848091595081

Epoch: 5| Step: 1
Training loss: 2.7453575829683494
Validation loss: 2.795838920832565

Epoch: 5| Step: 2
Training loss: 3.067629819080063
Validation loss: 2.7971740973369963

Epoch: 5| Step: 3
Training loss: 3.441336692773932
Validation loss: 2.7971225806996873

Epoch: 5| Step: 4
Training loss: 3.15575775235951
Validation loss: 2.7936028332500875

Epoch: 5| Step: 5
Training loss: 3.026667798780098
Validation loss: 2.796356620603607

Epoch: 5| Step: 6
Training loss: 3.1437503579596435
Validation loss: 2.796238316040164

Epoch: 5| Step: 7
Training loss: 3.2685097542287935
Validation loss: 2.7973069708523215

Epoch: 5| Step: 8
Training loss: 3.0927083737630423
Validation loss: 2.794953296121553

Epoch: 5| Step: 9
Training loss: 3.1331971044212663
Validation loss: 2.795439572191833

Epoch: 5| Step: 10
Training loss: 2.9754862604325614
Validation loss: 2.8098242333357466

Epoch: 123| Step: 0
Training loss: 3.6252354512536655
Validation loss: 2.8108292561026893

Epoch: 5| Step: 1
Training loss: 2.8609158059364885
Validation loss: 2.794052678982873

Epoch: 5| Step: 2
Training loss: 2.5821339273741177
Validation loss: 2.7939009457990287

Epoch: 5| Step: 3
Training loss: 3.5457597903474407
Validation loss: 2.791756775573687

Epoch: 5| Step: 4
Training loss: 3.032347333041775
Validation loss: 2.7937205859607808

Epoch: 5| Step: 5
Training loss: 3.373481974235695
Validation loss: 2.7947196490292097

Epoch: 5| Step: 6
Training loss: 2.8356666120301446
Validation loss: 2.794064879416802

Epoch: 5| Step: 7
Training loss: 2.459462041417311
Validation loss: 2.7941137475983693

Epoch: 5| Step: 8
Training loss: 3.1810640172048057
Validation loss: 2.7922385310663347

Epoch: 5| Step: 9
Training loss: 3.232401812626562
Validation loss: 2.7917083445710005

Epoch: 5| Step: 10
Training loss: 3.37344437528248
Validation loss: 2.790307143870065

Epoch: 124| Step: 0
Training loss: 3.4848242500025393
Validation loss: 2.792709679796467

Epoch: 5| Step: 1
Training loss: 3.1396151764859495
Validation loss: 2.791756725986059

Epoch: 5| Step: 2
Training loss: 3.1194558363544465
Validation loss: 2.7904085903816487

Epoch: 5| Step: 3
Training loss: 2.8331183931688972
Validation loss: 2.790923555220247

Epoch: 5| Step: 4
Training loss: 3.1093780670917663
Validation loss: 2.7892528843635667

Epoch: 5| Step: 5
Training loss: 3.5548012516140144
Validation loss: 2.7896330296345497

Epoch: 5| Step: 6
Training loss: 3.141028231265898
Validation loss: 2.7895332477561112

Epoch: 5| Step: 7
Training loss: 3.46163210130851
Validation loss: 2.790266574982426

Epoch: 5| Step: 8
Training loss: 2.704563177238663
Validation loss: 2.7891943325276545

Epoch: 5| Step: 9
Training loss: 2.7432106478555927
Validation loss: 2.7996145317087047

Epoch: 5| Step: 10
Training loss: 2.579243365386567
Validation loss: 2.8097017275088834

Epoch: 125| Step: 0
Training loss: 2.8018943032717245
Validation loss: 2.8016653252704966

Epoch: 5| Step: 1
Training loss: 3.076141182882601
Validation loss: 2.8126317712321005

Epoch: 5| Step: 2
Training loss: 3.166617861589151
Validation loss: 2.8108354754225275

Epoch: 5| Step: 3
Training loss: 2.8399816004734664
Validation loss: 2.8159385817286613

Epoch: 5| Step: 4
Training loss: 2.9845267851412536
Validation loss: 2.800760261391899

Epoch: 5| Step: 5
Training loss: 3.531074046924777
Validation loss: 2.8036808745475117

Epoch: 5| Step: 6
Training loss: 2.7344140622209863
Validation loss: 2.7960518520339788

Epoch: 5| Step: 7
Training loss: 2.8913032354656374
Validation loss: 2.792288783593948

Epoch: 5| Step: 8
Training loss: 2.8350791788229324
Validation loss: 2.7896440078494065

Epoch: 5| Step: 9
Training loss: 3.6005632913496535
Validation loss: 2.787424716275891

Epoch: 5| Step: 10
Training loss: 3.465145678519773
Validation loss: 2.7860062292309817

Epoch: 126| Step: 0
Training loss: 2.2022536698803488
Validation loss: 2.785430321728326

Epoch: 5| Step: 1
Training loss: 2.8080864078018752
Validation loss: 2.784492268440746

Epoch: 5| Step: 2
Training loss: 3.6648488451504098
Validation loss: 2.7823414179101524

Epoch: 5| Step: 3
Training loss: 3.5548476633732196
Validation loss: 2.783383780436067

Epoch: 5| Step: 4
Training loss: 3.478476008468608
Validation loss: 2.7826551846818823

Epoch: 5| Step: 5
Training loss: 3.211015612169564
Validation loss: 2.7827958901984675

Epoch: 5| Step: 6
Training loss: 2.390281802207351
Validation loss: 2.784753975622276

Epoch: 5| Step: 7
Training loss: 3.1417621432771132
Validation loss: 2.7837092569668584

Epoch: 5| Step: 8
Training loss: 3.4237838367964177
Validation loss: 2.7847725578431946

Epoch: 5| Step: 9
Training loss: 2.6367944325075814
Validation loss: 2.7802748538178914

Epoch: 5| Step: 10
Training loss: 3.1692193099477826
Validation loss: 2.780933371321397

Epoch: 127| Step: 0
Training loss: 2.9415609007526795
Validation loss: 2.784591754057652

Epoch: 5| Step: 1
Training loss: 2.9444337540758347
Validation loss: 2.7836748820553554

Epoch: 5| Step: 2
Training loss: 3.6995078661685885
Validation loss: 2.7861079105584055

Epoch: 5| Step: 3
Training loss: 3.338554838554278
Validation loss: 2.7845457643365354

Epoch: 5| Step: 4
Training loss: 3.0436025407543648
Validation loss: 2.786944786639138

Epoch: 5| Step: 5
Training loss: 3.802349899910914
Validation loss: 2.7905957043088

Epoch: 5| Step: 6
Training loss: 2.8527124045992602
Validation loss: 2.7825514396327264

Epoch: 5| Step: 7
Training loss: 2.928280586660689
Validation loss: 2.778817970256787

Epoch: 5| Step: 8
Training loss: 3.1643236594091606
Validation loss: 2.776974218250099

Epoch: 5| Step: 9
Training loss: 2.2366493227646753
Validation loss: 2.7796921643544708

Epoch: 5| Step: 10
Training loss: 2.7468302405207456
Validation loss: 2.779120680609101

Epoch: 128| Step: 0
Training loss: 2.9064252246823625
Validation loss: 2.7769276647786665

Epoch: 5| Step: 1
Training loss: 2.5766258736260412
Validation loss: 2.7771958763676667

Epoch: 5| Step: 2
Training loss: 3.3685509560971827
Validation loss: 2.778883645049064

Epoch: 5| Step: 3
Training loss: 3.491005511875877
Validation loss: 2.7773456847223046

Epoch: 5| Step: 4
Training loss: 3.191983977265645
Validation loss: 2.7771267516333205

Epoch: 5| Step: 5
Training loss: 3.483195699743964
Validation loss: 2.777574710875086

Epoch: 5| Step: 6
Training loss: 2.655313034856688
Validation loss: 2.7747082468301176

Epoch: 5| Step: 7
Training loss: 2.5782038821088116
Validation loss: 2.775226777165276

Epoch: 5| Step: 8
Training loss: 3.3622530651533804
Validation loss: 2.774757711839315

Epoch: 5| Step: 9
Training loss: 2.7690065906538526
Validation loss: 2.7746131763352895

Epoch: 5| Step: 10
Training loss: 3.4087594963587726
Validation loss: 2.7771750316779085

Epoch: 129| Step: 0
Training loss: 3.020105857509628
Validation loss: 2.77399478751452

Epoch: 5| Step: 1
Training loss: 3.471022677590097
Validation loss: 2.775059823955675

Epoch: 5| Step: 2
Training loss: 3.1700521408269493
Validation loss: 2.7749512172684048

Epoch: 5| Step: 3
Training loss: 3.0572700218114672
Validation loss: 2.7737782388175303

Epoch: 5| Step: 4
Training loss: 3.4644301725670936
Validation loss: 2.7749720223082655

Epoch: 5| Step: 5
Training loss: 2.740281445186649
Validation loss: 2.7747171202550347

Epoch: 5| Step: 6
Training loss: 3.1290275559740475
Validation loss: 2.77470278176931

Epoch: 5| Step: 7
Training loss: 3.4807958995026036
Validation loss: 2.7743586940956275

Epoch: 5| Step: 8
Training loss: 2.8856960854502693
Validation loss: 2.7741597061568433

Epoch: 5| Step: 9
Training loss: 2.4355114381318343
Validation loss: 2.7733180282490317

Epoch: 5| Step: 10
Training loss: 2.8736072981731113
Validation loss: 2.7729166196019994

Epoch: 130| Step: 0
Training loss: 3.3802522833758397
Validation loss: 2.7716486420089503

Epoch: 5| Step: 1
Training loss: 3.2021272919780626
Validation loss: 2.772238554011014

Epoch: 5| Step: 2
Training loss: 2.493826013615975
Validation loss: 2.7695151777417384

Epoch: 5| Step: 3
Training loss: 3.0170368585658385
Validation loss: 2.7687790696201784

Epoch: 5| Step: 4
Training loss: 2.7146325337969013
Validation loss: 2.767917803581678

Epoch: 5| Step: 5
Training loss: 3.385810915169908
Validation loss: 2.769031653794474

Epoch: 5| Step: 6
Training loss: 3.37999623969958
Validation loss: 2.769392914260969

Epoch: 5| Step: 7
Training loss: 3.0577291579625867
Validation loss: 2.76719519172417

Epoch: 5| Step: 8
Training loss: 2.6680359503798914
Validation loss: 2.7672704898994804

Epoch: 5| Step: 9
Training loss: 3.049805156550156
Validation loss: 2.76644674738686

Epoch: 5| Step: 10
Training loss: 3.4471632642380747
Validation loss: 2.7654260631379026

Epoch: 131| Step: 0
Training loss: 3.5175836828887936
Validation loss: 2.7681678412723887

Epoch: 5| Step: 1
Training loss: 2.7311174443461805
Validation loss: 2.7670056587465357

Epoch: 5| Step: 2
Training loss: 3.004991352748013
Validation loss: 2.7692915597521224

Epoch: 5| Step: 3
Training loss: 3.5568327414563368
Validation loss: 2.7737922854025023

Epoch: 5| Step: 4
Training loss: 2.6669671564872592
Validation loss: 2.7691969772555813

Epoch: 5| Step: 5
Training loss: 2.864907837029466
Validation loss: 2.7716915834757563

Epoch: 5| Step: 6
Training loss: 3.101228864198779
Validation loss: 2.7798295541128315

Epoch: 5| Step: 7
Training loss: 3.191486483701125
Validation loss: 2.784623877270318

Epoch: 5| Step: 8
Training loss: 2.9388869237702915
Validation loss: 2.7917182879633393

Epoch: 5| Step: 9
Training loss: 3.4430782486806897
Validation loss: 2.7856361744142846

Epoch: 5| Step: 10
Training loss: 2.6194942500194593
Validation loss: 2.7820314224678566

Epoch: 132| Step: 0
Training loss: 3.650997595128793
Validation loss: 2.7817708571962627

Epoch: 5| Step: 1
Training loss: 2.800988268151138
Validation loss: 2.783043313078856

Epoch: 5| Step: 2
Training loss: 2.9089470930746777
Validation loss: 2.7818008786146278

Epoch: 5| Step: 3
Training loss: 3.3416207923182006
Validation loss: 2.774209849069329

Epoch: 5| Step: 4
Training loss: 2.7803893740096832
Validation loss: 2.7738019445834627

Epoch: 5| Step: 5
Training loss: 3.2591100802703528
Validation loss: 2.767382628762319

Epoch: 5| Step: 6
Training loss: 3.2279013010603665
Validation loss: 2.7656199290272707

Epoch: 5| Step: 7
Training loss: 3.0914893319681456
Validation loss: 2.7623915891989044

Epoch: 5| Step: 8
Training loss: 2.93930679920264
Validation loss: 2.7617667452289303

Epoch: 5| Step: 9
Training loss: 3.091214614955638
Validation loss: 2.7632712137796607

Epoch: 5| Step: 10
Training loss: 2.531965460742083
Validation loss: 2.760283704276979

Epoch: 133| Step: 0
Training loss: 3.210953983904997
Validation loss: 2.75819089795825

Epoch: 5| Step: 1
Training loss: 3.054936937845668
Validation loss: 2.759542692227607

Epoch: 5| Step: 2
Training loss: 2.840059337801999
Validation loss: 2.761222581164964

Epoch: 5| Step: 3
Training loss: 3.304585773173876
Validation loss: 2.758002945459125

Epoch: 5| Step: 4
Training loss: 3.0045081280963237
Validation loss: 2.7592277234010347

Epoch: 5| Step: 5
Training loss: 3.1688226755449493
Validation loss: 2.759285628974063

Epoch: 5| Step: 6
Training loss: 2.880475510707502
Validation loss: 2.75885224236878

Epoch: 5| Step: 7
Training loss: 2.981047687823467
Validation loss: 2.7603785262410963

Epoch: 5| Step: 8
Training loss: 3.5007824704304946
Validation loss: 2.7564390966129957

Epoch: 5| Step: 9
Training loss: 2.7555086276286698
Validation loss: 2.761365702674479

Epoch: 5| Step: 10
Training loss: 3.017682890323351
Validation loss: 2.766586271062572

Epoch: 134| Step: 0
Training loss: 2.9432143774939683
Validation loss: 2.7762475140099916

Epoch: 5| Step: 1
Training loss: 3.3211645850589524
Validation loss: 2.7750930561374085

Epoch: 5| Step: 2
Training loss: 3.0862752608868047
Validation loss: 2.7778173678321667

Epoch: 5| Step: 3
Training loss: 3.5139766643619965
Validation loss: 2.766096901357958

Epoch: 5| Step: 4
Training loss: 2.9526932012152787
Validation loss: 2.7672507479273767

Epoch: 5| Step: 5
Training loss: 2.778232094381509
Validation loss: 2.7680477178987837

Epoch: 5| Step: 6
Training loss: 3.0394803032115276
Validation loss: 2.7679418610136657

Epoch: 5| Step: 7
Training loss: 2.8641560923699605
Validation loss: 2.763694417030975

Epoch: 5| Step: 8
Training loss: 3.0742230930321925
Validation loss: 2.76066856480972

Epoch: 5| Step: 9
Training loss: 2.8254442523944214
Validation loss: 2.7592555391140463

Epoch: 5| Step: 10
Training loss: 3.394485736713007
Validation loss: 2.7594233454049037

Epoch: 135| Step: 0
Training loss: 2.8662044492579883
Validation loss: 2.758390305508245

Epoch: 5| Step: 1
Training loss: 2.674044258293512
Validation loss: 2.7595670544581514

Epoch: 5| Step: 2
Training loss: 3.3503885413927588
Validation loss: 2.759233181018785

Epoch: 5| Step: 3
Training loss: 3.470272520505724
Validation loss: 2.7602906941146412

Epoch: 5| Step: 4
Training loss: 2.5293469280460066
Validation loss: 2.7544565763808357

Epoch: 5| Step: 5
Training loss: 3.1945892485449434
Validation loss: 2.7527400449398383

Epoch: 5| Step: 6
Training loss: 3.2197527758543933
Validation loss: 2.7551471135739005

Epoch: 5| Step: 7
Training loss: 3.680681811072556
Validation loss: 2.7557448401303968

Epoch: 5| Step: 8
Training loss: 3.301621044703215
Validation loss: 2.7536244768607734

Epoch: 5| Step: 9
Training loss: 2.1782437263432572
Validation loss: 2.753602874646131

Epoch: 5| Step: 10
Training loss: 2.9845255069828194
Validation loss: 2.7548909494851777

Epoch: 136| Step: 0
Training loss: 3.310369130091963
Validation loss: 2.752793594457904

Epoch: 5| Step: 1
Training loss: 2.9921106871464067
Validation loss: 2.751637504507429

Epoch: 5| Step: 2
Training loss: 3.180353118436187
Validation loss: 2.7541014382880906

Epoch: 5| Step: 3
Training loss: 2.2829205392785066
Validation loss: 2.7536346220133816

Epoch: 5| Step: 4
Training loss: 3.5153761033855817
Validation loss: 2.7585583075507443

Epoch: 5| Step: 5
Training loss: 3.5650771339493206
Validation loss: 2.7605640510564493

Epoch: 5| Step: 6
Training loss: 2.8126177445242617
Validation loss: 2.763539563365028

Epoch: 5| Step: 7
Training loss: 2.931370610275193
Validation loss: 2.7608607456019656

Epoch: 5| Step: 8
Training loss: 3.1760415959360815
Validation loss: 2.753360179531979

Epoch: 5| Step: 9
Training loss: 2.880096396581384
Validation loss: 2.75616300425735

Epoch: 5| Step: 10
Training loss: 2.838478484310916
Validation loss: 2.7585383824131897

Epoch: 137| Step: 0
Training loss: 3.236424335898281
Validation loss: 2.7599299411344176

Epoch: 5| Step: 1
Training loss: 2.9913827795072825
Validation loss: 2.7562229395787563

Epoch: 5| Step: 2
Training loss: 2.610708387128538
Validation loss: 2.751259085776762

Epoch: 5| Step: 3
Training loss: 3.0300043437158655
Validation loss: 2.7520193291150106

Epoch: 5| Step: 4
Training loss: 2.8638214392807355
Validation loss: 2.7515860642106644

Epoch: 5| Step: 5
Training loss: 2.971266793992755
Validation loss: 2.7473848723019065

Epoch: 5| Step: 6
Training loss: 3.133905462692945
Validation loss: 2.7536887788255218

Epoch: 5| Step: 7
Training loss: 2.959056568838773
Validation loss: 2.7498772687923134

Epoch: 5| Step: 8
Training loss: 3.334115524707008
Validation loss: 2.7517342361580623

Epoch: 5| Step: 9
Training loss: 3.314788028159698
Validation loss: 2.7574269024208697

Epoch: 5| Step: 10
Training loss: 3.1997449952086483
Validation loss: 2.7485322363378226

Epoch: 138| Step: 0
Training loss: 2.590537690277784
Validation loss: 2.7502489797620058

Epoch: 5| Step: 1
Training loss: 2.5796429413633075
Validation loss: 2.745715956547747

Epoch: 5| Step: 2
Training loss: 3.0725421914415554
Validation loss: 2.747307554730961

Epoch: 5| Step: 3
Training loss: 2.972267716991477
Validation loss: 2.749677522644363

Epoch: 5| Step: 4
Training loss: 3.274219792738366
Validation loss: 2.7480507371847644

Epoch: 5| Step: 5
Training loss: 3.5248595622338885
Validation loss: 2.7478696741776836

Epoch: 5| Step: 6
Training loss: 2.854799205179252
Validation loss: 2.7498005340667566

Epoch: 5| Step: 7
Training loss: 3.404050064113226
Validation loss: 2.7489600037563773

Epoch: 5| Step: 8
Training loss: 3.0446949520057083
Validation loss: 2.745972378108138

Epoch: 5| Step: 9
Training loss: 3.125589086322072
Validation loss: 2.748734643591239

Epoch: 5| Step: 10
Training loss: 3.204833528715235
Validation loss: 2.745441419093536

Epoch: 139| Step: 0
Training loss: 3.4931333485597587
Validation loss: 2.7474840182788203

Epoch: 5| Step: 1
Training loss: 3.1073159919696285
Validation loss: 2.7524637342914704

Epoch: 5| Step: 2
Training loss: 2.7887779966938475
Validation loss: 2.7548706656040096

Epoch: 5| Step: 3
Training loss: 2.948883563061392
Validation loss: 2.761024486810469

Epoch: 5| Step: 4
Training loss: 3.2063326521959765
Validation loss: 2.7629837188743984

Epoch: 5| Step: 5
Training loss: 3.1089236444647232
Validation loss: 2.766031911893298

Epoch: 5| Step: 6
Training loss: 3.4063374919329052
Validation loss: 2.766997803838076

Epoch: 5| Step: 7
Training loss: 2.5045393739949695
Validation loss: 2.7409816395445663

Epoch: 5| Step: 8
Training loss: 3.508478386085957
Validation loss: 2.7480151470399936

Epoch: 5| Step: 9
Training loss: 3.004614936162672
Validation loss: 2.754894481026046

Epoch: 5| Step: 10
Training loss: 2.500564225422952
Validation loss: 2.7727833086230365

Epoch: 140| Step: 0
Training loss: 2.7790699676512856
Validation loss: 2.7586886500870613

Epoch: 5| Step: 1
Training loss: 3.189302869575776
Validation loss: 2.755485706024867

Epoch: 5| Step: 2
Training loss: 3.3501564046303627
Validation loss: 2.7567332862191085

Epoch: 5| Step: 3
Training loss: 2.974443297029899
Validation loss: 2.7626905613965103

Epoch: 5| Step: 4
Training loss: 2.899357981153907
Validation loss: 2.761640923996884

Epoch: 5| Step: 5
Training loss: 2.6858673459356437
Validation loss: 2.7683912833313755

Epoch: 5| Step: 6
Training loss: 3.2383746052021474
Validation loss: 2.7688726099645224

Epoch: 5| Step: 7
Training loss: 3.0731787273496436
Validation loss: 2.7760613658230486

Epoch: 5| Step: 8
Training loss: 3.2547323545239415
Validation loss: 2.7797822046059886

Epoch: 5| Step: 9
Training loss: 3.2039397901385427
Validation loss: 2.776861961267128

Epoch: 5| Step: 10
Training loss: 3.278228094845369
Validation loss: 2.7653881676319156

Epoch: 141| Step: 0
Training loss: 3.4015567188976052
Validation loss: 2.754212046477068

Epoch: 5| Step: 1
Training loss: 3.1947101500942514
Validation loss: 2.7561613699861094

Epoch: 5| Step: 2
Training loss: 2.1623834920379372
Validation loss: 2.7510975784993033

Epoch: 5| Step: 3
Training loss: 3.443254543878926
Validation loss: 2.753374836794681

Epoch: 5| Step: 4
Training loss: 3.396579699415278
Validation loss: 2.749596212803487

Epoch: 5| Step: 5
Training loss: 2.8280249309223238
Validation loss: 2.746926651486915

Epoch: 5| Step: 6
Training loss: 2.826620133604745
Validation loss: 2.7512244298174138

Epoch: 5| Step: 7
Training loss: 2.4352181342017434
Validation loss: 2.7432188605826022

Epoch: 5| Step: 8
Training loss: 3.230928510540301
Validation loss: 2.7495858802612867

Epoch: 5| Step: 9
Training loss: 3.49081469014437
Validation loss: 2.7525588163294277

Epoch: 5| Step: 10
Training loss: 3.0284765080848772
Validation loss: 2.75191985466037

Epoch: 142| Step: 0
Training loss: 3.3603958353121004
Validation loss: 2.7419995808936184

Epoch: 5| Step: 1
Training loss: 2.563375370026538
Validation loss: 2.741451840088576

Epoch: 5| Step: 2
Training loss: 3.0561126740540296
Validation loss: 2.742256379878755

Epoch: 5| Step: 3
Training loss: 2.6280824637401055
Validation loss: 2.7395733114491496

Epoch: 5| Step: 4
Training loss: 3.241425426956935
Validation loss: 2.7387112569548946

Epoch: 5| Step: 5
Training loss: 2.8218967711494916
Validation loss: 2.7381297172523746

Epoch: 5| Step: 6
Training loss: 3.454992281384824
Validation loss: 2.738697199872343

Epoch: 5| Step: 7
Training loss: 2.9479253294764685
Validation loss: 2.7352112094134267

Epoch: 5| Step: 8
Training loss: 2.680098699488783
Validation loss: 2.7372971763061607

Epoch: 5| Step: 9
Training loss: 3.163092269019597
Validation loss: 2.7357390589621526

Epoch: 5| Step: 10
Training loss: 3.6371442011224
Validation loss: 2.7360441405370888

Epoch: 143| Step: 0
Training loss: 3.655633075540186
Validation loss: 2.735597441873612

Epoch: 5| Step: 1
Training loss: 2.621318324285066
Validation loss: 2.7333069996524446

Epoch: 5| Step: 2
Training loss: 2.6440766477685367
Validation loss: 2.7339946054470103

Epoch: 5| Step: 3
Training loss: 3.2907087324453363
Validation loss: 2.733129317800656

Epoch: 5| Step: 4
Training loss: 2.469027829532132
Validation loss: 2.7330009183907524

Epoch: 5| Step: 5
Training loss: 3.295432403394401
Validation loss: 2.7326545161547084

Epoch: 5| Step: 6
Training loss: 2.9144123266268838
Validation loss: 2.7333254607942883

Epoch: 5| Step: 7
Training loss: 3.5829058695296014
Validation loss: 2.738542468908008

Epoch: 5| Step: 8
Training loss: 2.6039285983303455
Validation loss: 2.739139936644487

Epoch: 5| Step: 9
Training loss: 3.1381442012780636
Validation loss: 2.738966258272189

Epoch: 5| Step: 10
Training loss: 3.2239762625660497
Validation loss: 2.741588986126623

Epoch: 144| Step: 0
Training loss: 2.6348766532562307
Validation loss: 2.733879487455166

Epoch: 5| Step: 1
Training loss: 3.2055046360313773
Validation loss: 2.7358063516861857

Epoch: 5| Step: 2
Training loss: 3.298721880921224
Validation loss: 2.7283602940664826

Epoch: 5| Step: 3
Training loss: 3.1208207222276716
Validation loss: 2.7280427512390197

Epoch: 5| Step: 4
Training loss: 2.856270861392977
Validation loss: 2.7283021530949645

Epoch: 5| Step: 5
Training loss: 2.9073100464058896
Validation loss: 2.729070322803086

Epoch: 5| Step: 6
Training loss: 2.887250425443916
Validation loss: 2.727586330153181

Epoch: 5| Step: 7
Training loss: 3.13035064390694
Validation loss: 2.7259850316396026

Epoch: 5| Step: 8
Training loss: 3.3377869100512063
Validation loss: 2.727996594763427

Epoch: 5| Step: 9
Training loss: 2.932467756297353
Validation loss: 2.729032232459625

Epoch: 5| Step: 10
Training loss: 3.256826127936876
Validation loss: 2.728807718029962

Epoch: 145| Step: 0
Training loss: 3.1025054036476853
Validation loss: 2.7285291614000413

Epoch: 5| Step: 1
Training loss: 3.0193161585543864
Validation loss: 2.7283383278509707

Epoch: 5| Step: 2
Training loss: 3.45800698513828
Validation loss: 2.727515481941551

Epoch: 5| Step: 3
Training loss: 3.155820156325424
Validation loss: 2.728624805939658

Epoch: 5| Step: 4
Training loss: 2.8811960211143153
Validation loss: 2.727066596137516

Epoch: 5| Step: 5
Training loss: 2.2261859776213684
Validation loss: 2.7282451290878185

Epoch: 5| Step: 6
Training loss: 3.0503671831580212
Validation loss: 2.7315786634624035

Epoch: 5| Step: 7
Training loss: 3.1484317448187165
Validation loss: 2.7272669995652676

Epoch: 5| Step: 8
Training loss: 3.1941038051450352
Validation loss: 2.730837270177281

Epoch: 5| Step: 9
Training loss: 2.976125129345616
Validation loss: 2.7314903003948934

Epoch: 5| Step: 10
Training loss: 3.235611241653839
Validation loss: 2.7320249457234396

Epoch: 146| Step: 0
Training loss: 2.50952508270929
Validation loss: 2.7278124666718844

Epoch: 5| Step: 1
Training loss: 3.124038090482203
Validation loss: 2.7305904664505323

Epoch: 5| Step: 2
Training loss: 3.2740518726301286
Validation loss: 2.731638886674981

Epoch: 5| Step: 3
Training loss: 2.193942147993578
Validation loss: 2.7286042422425534

Epoch: 5| Step: 4
Training loss: 3.7219509165057416
Validation loss: 2.7302113587351267

Epoch: 5| Step: 5
Training loss: 3.079951020631618
Validation loss: 2.7334956589011212

Epoch: 5| Step: 6
Training loss: 3.373923659885021
Validation loss: 2.7286930886667067

Epoch: 5| Step: 7
Training loss: 2.630512987880261
Validation loss: 2.732453673311837

Epoch: 5| Step: 8
Training loss: 3.3529432604796052
Validation loss: 2.7363276724817083

Epoch: 5| Step: 9
Training loss: 2.967758173650695
Validation loss: 2.725431054770806

Epoch: 5| Step: 10
Training loss: 3.03449319595527
Validation loss: 2.730005848386362

Epoch: 147| Step: 0
Training loss: 3.2302907320396064
Validation loss: 2.725932700041738

Epoch: 5| Step: 1
Training loss: 3.265076221551948
Validation loss: 2.7248580865558973

Epoch: 5| Step: 2
Training loss: 3.442984211650882
Validation loss: 2.7247155049942617

Epoch: 5| Step: 3
Training loss: 3.3704053898701014
Validation loss: 2.721518621565094

Epoch: 5| Step: 4
Training loss: 3.260280780987126
Validation loss: 2.7234164501527918

Epoch: 5| Step: 5
Training loss: 2.6141537519854823
Validation loss: 2.7216445701174417

Epoch: 5| Step: 6
Training loss: 2.3236481294674625
Validation loss: 2.7234825723159

Epoch: 5| Step: 7
Training loss: 2.80014486278728
Validation loss: 2.7226869872671506

Epoch: 5| Step: 8
Training loss: 2.4807788084387785
Validation loss: 2.722053245784166

Epoch: 5| Step: 9
Training loss: 3.128909145549144
Validation loss: 2.720877801426574

Epoch: 5| Step: 10
Training loss: 3.4424501323204644
Validation loss: 2.724289422566105

Epoch: 148| Step: 0
Training loss: 3.0908019536875773
Validation loss: 2.7220571335483026

Epoch: 5| Step: 1
Training loss: 2.9760059226807756
Validation loss: 2.723999121638663

Epoch: 5| Step: 2
Training loss: 2.8756573796247413
Validation loss: 2.7233626411682343

Epoch: 5| Step: 3
Training loss: 2.8564713540479594
Validation loss: 2.729662392639432

Epoch: 5| Step: 4
Training loss: 3.0930788487405825
Validation loss: 2.727029253847265

Epoch: 5| Step: 5
Training loss: 3.2652754163028153
Validation loss: 2.7320728836313015

Epoch: 5| Step: 6
Training loss: 3.5031461199515976
Validation loss: 2.740021370730388

Epoch: 5| Step: 7
Training loss: 2.815576269678589
Validation loss: 2.735342187419453

Epoch: 5| Step: 8
Training loss: 2.5005448701277033
Validation loss: 2.7324289548756773

Epoch: 5| Step: 9
Training loss: 3.3707856604400006
Validation loss: 2.7302172668525966

Epoch: 5| Step: 10
Training loss: 3.020448138353303
Validation loss: 2.7273212381702225

Epoch: 149| Step: 0
Training loss: 2.527926111119312
Validation loss: 2.7209043019204

Epoch: 5| Step: 1
Training loss: 3.095371938613273
Validation loss: 2.721285067976006

Epoch: 5| Step: 2
Training loss: 3.282253438924103
Validation loss: 2.720284573557597

Epoch: 5| Step: 3
Training loss: 2.7730786588389282
Validation loss: 2.7169047142331917

Epoch: 5| Step: 4
Training loss: 3.1210691525059358
Validation loss: 2.7168824643201206

Epoch: 5| Step: 5
Training loss: 3.5214915516167165
Validation loss: 2.7171893338052873

Epoch: 5| Step: 6
Training loss: 3.264010819847275
Validation loss: 2.714597488628452

Epoch: 5| Step: 7
Training loss: 3.151840604692391
Validation loss: 2.7166480327666465

Epoch: 5| Step: 8
Training loss: 3.0941029356963177
Validation loss: 2.717881271942442

Epoch: 5| Step: 9
Training loss: 2.302742243810771
Validation loss: 2.715271282549328

Epoch: 5| Step: 10
Training loss: 3.1658919708559816
Validation loss: 2.71448362577516

Epoch: 150| Step: 0
Training loss: 2.7552615030178544
Validation loss: 2.714782112621737

Epoch: 5| Step: 1
Training loss: 2.83016304220428
Validation loss: 2.7203707033931828

Epoch: 5| Step: 2
Training loss: 3.322842986785795
Validation loss: 2.7175385356535697

Epoch: 5| Step: 3
Training loss: 3.042846363823755
Validation loss: 2.7133365097152278

Epoch: 5| Step: 4
Training loss: 3.177614778356002
Validation loss: 2.716424962694854

Epoch: 5| Step: 5
Training loss: 2.928284657623261
Validation loss: 2.715525441321504

Epoch: 5| Step: 6
Training loss: 3.248736062396081
Validation loss: 2.7190056759475296

Epoch: 5| Step: 7
Training loss: 2.9804673101139216
Validation loss: 2.7212794739594437

Epoch: 5| Step: 8
Training loss: 3.364865664199739
Validation loss: 2.7285734307000165

Epoch: 5| Step: 9
Training loss: 3.2220560520631416
Validation loss: 2.7342714014072707

Epoch: 5| Step: 10
Training loss: 2.2966101876536262
Validation loss: 2.746490071358518

Epoch: 151| Step: 0
Training loss: 2.6935705775716854
Validation loss: 2.7650569459611565

Epoch: 5| Step: 1
Training loss: 3.2410777939002453
Validation loss: 2.7526059765915094

Epoch: 5| Step: 2
Training loss: 2.6203155499362656
Validation loss: 2.735204601628167

Epoch: 5| Step: 3
Training loss: 3.2207534628798187
Validation loss: 2.733392715396821

Epoch: 5| Step: 4
Training loss: 3.2891758697615545
Validation loss: 2.711497867225692

Epoch: 5| Step: 5
Training loss: 3.089980478070759
Validation loss: 2.7108071198246435

Epoch: 5| Step: 6
Training loss: 3.1157677651221563
Validation loss: 2.7169084093240974

Epoch: 5| Step: 7
Training loss: 3.0775288425708487
Validation loss: 2.7137824874325944

Epoch: 5| Step: 8
Training loss: 3.429703488671089
Validation loss: 2.7112079242092455

Epoch: 5| Step: 9
Training loss: 2.429391333876202
Validation loss: 2.7114819274954662

Epoch: 5| Step: 10
Training loss: 3.0842370092256446
Validation loss: 2.711685179217796

Epoch: 152| Step: 0
Training loss: 2.7736534356958975
Validation loss: 2.711452057858412

Epoch: 5| Step: 1
Training loss: 3.2584195749198264
Validation loss: 2.711103442231271

Epoch: 5| Step: 2
Training loss: 3.400640926537625
Validation loss: 2.7139878291896236

Epoch: 5| Step: 3
Training loss: 2.8650739399953755
Validation loss: 2.7144772711683234

Epoch: 5| Step: 4
Training loss: 3.3211915771032072
Validation loss: 2.719154099685122

Epoch: 5| Step: 5
Training loss: 3.0135340581842485
Validation loss: 2.726176845699752

Epoch: 5| Step: 6
Training loss: 2.336677459586663
Validation loss: 2.7234756254412584

Epoch: 5| Step: 7
Training loss: 2.703121736557595
Validation loss: 2.7178185064408575

Epoch: 5| Step: 8
Training loss: 3.2165685872622864
Validation loss: 2.719594912557971

Epoch: 5| Step: 9
Training loss: 3.077367699116634
Validation loss: 2.7140455022483847

Epoch: 5| Step: 10
Training loss: 3.3103780607769617
Validation loss: 2.7095233060492006

Epoch: 153| Step: 0
Training loss: 2.9785530863422895
Validation loss: 2.707757046696468

Epoch: 5| Step: 1
Training loss: 3.162807488853511
Validation loss: 2.709780261265511

Epoch: 5| Step: 2
Training loss: 2.8182138681686815
Validation loss: 2.710726067380828

Epoch: 5| Step: 3
Training loss: 3.4144525719757732
Validation loss: 2.7077309789746735

Epoch: 5| Step: 4
Training loss: 2.8346408370244647
Validation loss: 2.709710052533492

Epoch: 5| Step: 5
Training loss: 3.201872194502266
Validation loss: 2.7108882190205956

Epoch: 5| Step: 6
Training loss: 3.884770412068129
Validation loss: 2.7106152206655674

Epoch: 5| Step: 7
Training loss: 2.5354664852249527
Validation loss: 2.7085327573545577

Epoch: 5| Step: 8
Training loss: 2.96035156894298
Validation loss: 2.708134289062011

Epoch: 5| Step: 9
Training loss: 2.761006782841183
Validation loss: 2.707900332788919

Epoch: 5| Step: 10
Training loss: 2.6122883505622334
Validation loss: 2.705859048095126

Epoch: 154| Step: 0
Training loss: 2.858465831862657
Validation loss: 2.709853738654294

Epoch: 5| Step: 1
Training loss: 3.247645478899477
Validation loss: 2.7079867182982555

Epoch: 5| Step: 2
Training loss: 3.108924257972375
Validation loss: 2.710746122657849

Epoch: 5| Step: 3
Training loss: 2.7691416822881587
Validation loss: 2.7096285973395013

Epoch: 5| Step: 4
Training loss: 2.8715036112639583
Validation loss: 2.712105357427499

Epoch: 5| Step: 5
Training loss: 3.08747443061156
Validation loss: 2.717906864072224

Epoch: 5| Step: 6
Training loss: 3.097063544237654
Validation loss: 2.7131774921243665

Epoch: 5| Step: 7
Training loss: 3.142753525053831
Validation loss: 2.727281180421812

Epoch: 5| Step: 8
Training loss: 2.5580248950167372
Validation loss: 2.716276256754006

Epoch: 5| Step: 9
Training loss: 3.0544790991990514
Validation loss: 2.7161774024941363

Epoch: 5| Step: 10
Training loss: 3.56381723244843
Validation loss: 2.7084072875976317

Epoch: 155| Step: 0
Training loss: 3.1350838282814006
Validation loss: 2.7039867267372064

Epoch: 5| Step: 1
Training loss: 2.527185544187398
Validation loss: 2.70357491521643

Epoch: 5| Step: 2
Training loss: 2.639671921140452
Validation loss: 2.7071387017141726

Epoch: 5| Step: 3
Training loss: 3.0407928012757672
Validation loss: 2.7029086444931916

Epoch: 5| Step: 4
Training loss: 3.0535221462368
Validation loss: 2.7043115203870336

Epoch: 5| Step: 5
Training loss: 2.8024500686049567
Validation loss: 2.7046911380770107

Epoch: 5| Step: 6
Training loss: 3.055487876682017
Validation loss: 2.7013086801829345

Epoch: 5| Step: 7
Training loss: 2.8738361158904127
Validation loss: 2.703743840973201

Epoch: 5| Step: 8
Training loss: 3.688450836180801
Validation loss: 2.6996130871544297

Epoch: 5| Step: 9
Training loss: 3.2128722216418217
Validation loss: 2.701257207746914

Epoch: 5| Step: 10
Training loss: 3.1541765408548246
Validation loss: 2.6995619764936283

Epoch: 156| Step: 0
Training loss: 2.5203583535210967
Validation loss: 2.7011731619584145

Epoch: 5| Step: 1
Training loss: 3.389926539612581
Validation loss: 2.7003920799495162

Epoch: 5| Step: 2
Training loss: 3.1129248210432716
Validation loss: 2.699718439240329

Epoch: 5| Step: 3
Training loss: 2.7425604672577304
Validation loss: 2.7011049190986993

Epoch: 5| Step: 4
Training loss: 2.8407056673218527
Validation loss: 2.6977495154450533

Epoch: 5| Step: 5
Training loss: 3.2156015942076683
Validation loss: 2.7036054616800858

Epoch: 5| Step: 6
Training loss: 2.5297016070363103
Validation loss: 2.7046354077329364

Epoch: 5| Step: 7
Training loss: 2.9175781642246283
Validation loss: 2.7135727682420177

Epoch: 5| Step: 8
Training loss: 3.5040876496818445
Validation loss: 2.7061760635088183

Epoch: 5| Step: 9
Training loss: 3.4551135935237833
Validation loss: 2.697944961825811

Epoch: 5| Step: 10
Training loss: 2.7985609716357605
Validation loss: 2.7016985580146002

Epoch: 157| Step: 0
Training loss: 3.550531594676685
Validation loss: 2.695213530300099

Epoch: 5| Step: 1
Training loss: 2.5034854434142337
Validation loss: 2.699486348109878

Epoch: 5| Step: 2
Training loss: 3.351063511122792
Validation loss: 2.698979071207073

Epoch: 5| Step: 3
Training loss: 2.6889911329606258
Validation loss: 2.6943862186558873

Epoch: 5| Step: 4
Training loss: 2.761571640132478
Validation loss: 2.694828556290827

Epoch: 5| Step: 5
Training loss: 3.322272944904855
Validation loss: 2.6965609272047697

Epoch: 5| Step: 6
Training loss: 2.860005293621153
Validation loss: 2.697328418249875

Epoch: 5| Step: 7
Training loss: 3.211054964538995
Validation loss: 2.6951314115393394

Epoch: 5| Step: 8
Training loss: 2.8415705115493672
Validation loss: 2.6975424110987825

Epoch: 5| Step: 9
Training loss: 2.89923578255784
Validation loss: 2.697579625100368

Epoch: 5| Step: 10
Training loss: 3.132572003120811
Validation loss: 2.6932424106600226

Epoch: 158| Step: 0
Training loss: 3.4045012298371113
Validation loss: 2.6960669989412307

Epoch: 5| Step: 1
Training loss: 2.570189035343253
Validation loss: 2.695475160393658

Epoch: 5| Step: 2
Training loss: 3.6324040008902636
Validation loss: 2.697477346660442

Epoch: 5| Step: 3
Training loss: 3.1792771733094556
Validation loss: 2.697306443107291

Epoch: 5| Step: 4
Training loss: 3.390223747453889
Validation loss: 2.7002136705745396

Epoch: 5| Step: 5
Training loss: 2.9388797847203763
Validation loss: 2.7014093331228555

Epoch: 5| Step: 6
Training loss: 2.7268428275820096
Validation loss: 2.6974052333724825

Epoch: 5| Step: 7
Training loss: 2.761119469958965
Validation loss: 2.700636773655414

Epoch: 5| Step: 8
Training loss: 3.200948133673486
Validation loss: 2.700289520683464

Epoch: 5| Step: 9
Training loss: 2.4055593911488615
Validation loss: 2.6930780028288024

Epoch: 5| Step: 10
Training loss: 2.722989865063184
Validation loss: 2.6985279318364848

Epoch: 159| Step: 0
Training loss: 3.0101097152839587
Validation loss: 2.6958622758581603

Epoch: 5| Step: 1
Training loss: 3.4517334770933874
Validation loss: 2.6961549065165893

Epoch: 5| Step: 2
Training loss: 3.0441008629950015
Validation loss: 2.7000356140127466

Epoch: 5| Step: 3
Training loss: 2.490606494102506
Validation loss: 2.7019490862536095

Epoch: 5| Step: 4
Training loss: 2.7244466972324473
Validation loss: 2.698036367618202

Epoch: 5| Step: 5
Training loss: 3.074231313754902
Validation loss: 2.697869262456227

Epoch: 5| Step: 6
Training loss: 3.0985073926220976
Validation loss: 2.698060613445631

Epoch: 5| Step: 7
Training loss: 3.295190751570142
Validation loss: 2.697133556426399

Epoch: 5| Step: 8
Training loss: 3.4181648939256033
Validation loss: 2.696496538821455

Epoch: 5| Step: 9
Training loss: 2.561327689367004
Validation loss: 2.6920911983390194

Epoch: 5| Step: 10
Training loss: 2.8784454266740616
Validation loss: 2.692541033973071

Epoch: 160| Step: 0
Training loss: 2.9284279519001686
Validation loss: 2.6911645446143493

Epoch: 5| Step: 1
Training loss: 2.8423025618588555
Validation loss: 2.6920355156988434

Epoch: 5| Step: 2
Training loss: 2.674986784002153
Validation loss: 2.6945096173566

Epoch: 5| Step: 3
Training loss: 2.8270722848390055
Validation loss: 2.695691059737341

Epoch: 5| Step: 4
Training loss: 3.2253109626777445
Validation loss: 2.701507166729591

Epoch: 5| Step: 5
Training loss: 3.1752926308650635
Validation loss: 2.7007298377935647

Epoch: 5| Step: 6
Training loss: 3.104235210984694
Validation loss: 2.710401216671499

Epoch: 5| Step: 7
Training loss: 2.5937477939090767
Validation loss: 2.710912488917928

Epoch: 5| Step: 8
Training loss: 2.912468932153907
Validation loss: 2.7067119929397356

Epoch: 5| Step: 9
Training loss: 3.535757648042484
Validation loss: 2.7102630864809436

Epoch: 5| Step: 10
Training loss: 3.3406077799339853
Validation loss: 2.692839813846572

Epoch: 161| Step: 0
Training loss: 2.6624036529731447
Validation loss: 2.6878768397232897

Epoch: 5| Step: 1
Training loss: 2.7886648883082827
Validation loss: 2.6887344764616836

Epoch: 5| Step: 2
Training loss: 3.3250777213972786
Validation loss: 2.6895594069352664

Epoch: 5| Step: 3
Training loss: 2.448662166840929
Validation loss: 2.689275434147076

Epoch: 5| Step: 4
Training loss: 3.1761522440033323
Validation loss: 2.691901781999041

Epoch: 5| Step: 5
Training loss: 3.3660198408642508
Validation loss: 2.6924963388631284

Epoch: 5| Step: 6
Training loss: 3.546091135935504
Validation loss: 2.694482392014029

Epoch: 5| Step: 7
Training loss: 2.779955101748375
Validation loss: 2.694269823178846

Epoch: 5| Step: 8
Training loss: 3.182888210259479
Validation loss: 2.691804426909386

Epoch: 5| Step: 9
Training loss: 2.891901342743156
Validation loss: 2.6920483717944403

Epoch: 5| Step: 10
Training loss: 2.984523589744142
Validation loss: 2.69106521754497

Epoch: 162| Step: 0
Training loss: 2.6363290908547183
Validation loss: 2.6901376881760464

Epoch: 5| Step: 1
Training loss: 2.9501153050534064
Validation loss: 2.687787956537215

Epoch: 5| Step: 2
Training loss: 3.2335995836520977
Validation loss: 2.6887411364750906

Epoch: 5| Step: 3
Training loss: 3.0893268755715084
Validation loss: 2.687872599218261

Epoch: 5| Step: 4
Training loss: 3.449590747166541
Validation loss: 2.6838688110956395

Epoch: 5| Step: 5
Training loss: 2.8493220476609205
Validation loss: 2.687159536497078

Epoch: 5| Step: 6
Training loss: 3.147573953718708
Validation loss: 2.6838277972135227

Epoch: 5| Step: 7
Training loss: 2.6554956599210664
Validation loss: 2.6821669434365267

Epoch: 5| Step: 8
Training loss: 3.407258610617049
Validation loss: 2.686793132063972

Epoch: 5| Step: 9
Training loss: 2.6195357534550183
Validation loss: 2.6848678405192996

Epoch: 5| Step: 10
Training loss: 2.9884508670714167
Validation loss: 2.6849229824239216

Epoch: 163| Step: 0
Training loss: 2.829117911531549
Validation loss: 2.6868242719719664

Epoch: 5| Step: 1
Training loss: 3.466452722794603
Validation loss: 2.6966110109602544

Epoch: 5| Step: 2
Training loss: 3.3556213699466126
Validation loss: 2.6978004494834056

Epoch: 5| Step: 3
Training loss: 2.6868657095500708
Validation loss: 2.717146688671602

Epoch: 5| Step: 4
Training loss: 2.615343497565857
Validation loss: 2.7152752574446706

Epoch: 5| Step: 5
Training loss: 3.024902304340698
Validation loss: 2.7251312281837587

Epoch: 5| Step: 6
Training loss: 2.837061131353554
Validation loss: 2.7245457256937926

Epoch: 5| Step: 7
Training loss: 2.797775208927612
Validation loss: 2.7055868669434116

Epoch: 5| Step: 8
Training loss: 3.087207233587145
Validation loss: 2.6990911827206605

Epoch: 5| Step: 9
Training loss: 3.3019571049547913
Validation loss: 2.686979653154678

Epoch: 5| Step: 10
Training loss: 3.08487870607007
Validation loss: 2.680658054731722

Epoch: 164| Step: 0
Training loss: 2.6021000303939643
Validation loss: 2.6825078399041784

Epoch: 5| Step: 1
Training loss: 3.254292807452295
Validation loss: 2.6832057893779613

Epoch: 5| Step: 2
Training loss: 3.0907891487370476
Validation loss: 2.685751914750265

Epoch: 5| Step: 3
Training loss: 3.3443199456306023
Validation loss: 2.6873239830166145

Epoch: 5| Step: 4
Training loss: 2.886023906246578
Validation loss: 2.689859932362251

Epoch: 5| Step: 5
Training loss: 2.7543910255944053
Validation loss: 2.6902772233318237

Epoch: 5| Step: 6
Training loss: 3.3067199373056093
Validation loss: 2.6923486251112907

Epoch: 5| Step: 7
Training loss: 2.9655374914027033
Validation loss: 2.6888188557527646

Epoch: 5| Step: 8
Training loss: 3.060732428714262
Validation loss: 2.68916838023854

Epoch: 5| Step: 9
Training loss: 2.9121729065420645
Validation loss: 2.687089157466702

Epoch: 5| Step: 10
Training loss: 3.1435657606495715
Validation loss: 2.6877715824208197

Epoch: 165| Step: 0
Training loss: 2.7801019249213974
Validation loss: 2.686863825126889

Epoch: 5| Step: 1
Training loss: 3.2942265724958113
Validation loss: 2.6837400207956055

Epoch: 5| Step: 2
Training loss: 2.697238576699553
Validation loss: 2.6856011476523554

Epoch: 5| Step: 3
Training loss: 2.778959466930303
Validation loss: 2.6830758216251063

Epoch: 5| Step: 4
Training loss: 2.7620952948415165
Validation loss: 2.682550406867031

Epoch: 5| Step: 5
Training loss: 3.3008748599891806
Validation loss: 2.6832918711797573

Epoch: 5| Step: 6
Training loss: 3.1547857230522047
Validation loss: 2.685172706170796

Epoch: 5| Step: 7
Training loss: 3.4167467123439916
Validation loss: 2.683726113285775

Epoch: 5| Step: 8
Training loss: 2.531030245060282
Validation loss: 2.6857035948666215

Epoch: 5| Step: 9
Training loss: 2.9296630858357737
Validation loss: 2.685419166608519

Epoch: 5| Step: 10
Training loss: 3.462650331614609
Validation loss: 2.6832510610607265

Epoch: 166| Step: 0
Training loss: 2.946894779725506
Validation loss: 2.6880757305878253

Epoch: 5| Step: 1
Training loss: 2.9413422150753017
Validation loss: 2.703245884956122

Epoch: 5| Step: 2
Training loss: 3.3575056685842237
Validation loss: 2.7099871777009894

Epoch: 5| Step: 3
Training loss: 3.3465450405599046
Validation loss: 2.698631231584868

Epoch: 5| Step: 4
Training loss: 3.696866182653726
Validation loss: 2.6909529779076653

Epoch: 5| Step: 5
Training loss: 3.094533647643684
Validation loss: 2.6848774424534216

Epoch: 5| Step: 6
Training loss: 2.2797094917936094
Validation loss: 2.6814155212571453

Epoch: 5| Step: 7
Training loss: 2.758872285110889
Validation loss: 2.6804056723084764

Epoch: 5| Step: 8
Training loss: 2.7695035300865065
Validation loss: 2.677527103166062

Epoch: 5| Step: 9
Training loss: 3.09794440258123
Validation loss: 2.6774149183776963

Epoch: 5| Step: 10
Training loss: 2.535968479947379
Validation loss: 2.675197495545665

Epoch: 167| Step: 0
Training loss: 2.4464569826037637
Validation loss: 2.675536820364563

Epoch: 5| Step: 1
Training loss: 2.866847379296498
Validation loss: 2.6780695100511753

Epoch: 5| Step: 2
Training loss: 2.6152695645620754
Validation loss: 2.674706947805139

Epoch: 5| Step: 3
Training loss: 3.562227339098037
Validation loss: 2.6733826108710588

Epoch: 5| Step: 4
Training loss: 3.35630452202354
Validation loss: 2.6728154026521875

Epoch: 5| Step: 5
Training loss: 2.510365170363511
Validation loss: 2.673580863585146

Epoch: 5| Step: 6
Training loss: 3.1686583496322753
Validation loss: 2.6766005908708204

Epoch: 5| Step: 7
Training loss: 2.522428423014409
Validation loss: 2.674142549482374

Epoch: 5| Step: 8
Training loss: 3.2853845614499635
Validation loss: 2.679370275016432

Epoch: 5| Step: 9
Training loss: 3.3882567401515806
Validation loss: 2.6736051298267327

Epoch: 5| Step: 10
Training loss: 3.0753728500970836
Validation loss: 2.6761482673895185

Epoch: 168| Step: 0
Training loss: 2.7773750829203476
Validation loss: 2.67598381141043

Epoch: 5| Step: 1
Training loss: 3.0433106530282052
Validation loss: 2.669953021562998

Epoch: 5| Step: 2
Training loss: 3.355371973420695
Validation loss: 2.6810922204655174

Epoch: 5| Step: 3
Training loss: 2.802661387061395
Validation loss: 2.6717164729532605

Epoch: 5| Step: 4
Training loss: 2.9612025643023907
Validation loss: 2.675885620428994

Epoch: 5| Step: 5
Training loss: 3.4318923988102714
Validation loss: 2.6713587284871907

Epoch: 5| Step: 6
Training loss: 3.09341367184242
Validation loss: 2.670986754946346

Epoch: 5| Step: 7
Training loss: 3.0217695342065527
Validation loss: 2.6681691738572946

Epoch: 5| Step: 8
Training loss: 3.071887207006996
Validation loss: 2.669934084787892

Epoch: 5| Step: 9
Training loss: 2.9183550352999457
Validation loss: 2.6669969168354672

Epoch: 5| Step: 10
Training loss: 2.2704946866220057
Validation loss: 2.6699617688060187

Epoch: 169| Step: 0
Training loss: 2.853924334928498
Validation loss: 2.6694048147043627

Epoch: 5| Step: 1
Training loss: 3.0915260413200722
Validation loss: 2.669900059323015

Epoch: 5| Step: 2
Training loss: 3.031413123077439
Validation loss: 2.6664244284765695

Epoch: 5| Step: 3
Training loss: 2.890273119154677
Validation loss: 2.6703261932344726

Epoch: 5| Step: 4
Training loss: 2.815845957563388
Validation loss: 2.6698850254140494

Epoch: 5| Step: 5
Training loss: 2.620553747000425
Validation loss: 2.6651214947713204

Epoch: 5| Step: 6
Training loss: 2.78091754426493
Validation loss: 2.6709149083388173

Epoch: 5| Step: 7
Training loss: 3.061898620103226
Validation loss: 2.6720655990134916

Epoch: 5| Step: 8
Training loss: 3.374907315712305
Validation loss: 2.672205838000478

Epoch: 5| Step: 9
Training loss: 2.9946608716626146
Validation loss: 2.668117600176727

Epoch: 5| Step: 10
Training loss: 3.4515730878841113
Validation loss: 2.668863119365983

Epoch: 170| Step: 0
Training loss: 2.986689923002887
Validation loss: 2.6654020295466143

Epoch: 5| Step: 1
Training loss: 3.183419401859385
Validation loss: 2.6662983011831574

Epoch: 5| Step: 2
Training loss: 3.054049608208651
Validation loss: 2.662145343218203

Epoch: 5| Step: 3
Training loss: 2.7469123499287194
Validation loss: 2.664262024543237

Epoch: 5| Step: 4
Training loss: 2.9751559561234493
Validation loss: 2.6668130875453775

Epoch: 5| Step: 5
Training loss: 3.1902172997583933
Validation loss: 2.664547812600409

Epoch: 5| Step: 6
Training loss: 3.314773067572191
Validation loss: 2.6627395516340364

Epoch: 5| Step: 7
Training loss: 2.940608875258826
Validation loss: 2.6624214088741445

Epoch: 5| Step: 8
Training loss: 2.870098746059757
Validation loss: 2.664333667594497

Epoch: 5| Step: 9
Training loss: 2.8609006386616143
Validation loss: 2.6666980044256596

Epoch: 5| Step: 10
Training loss: 2.8433358027040136
Validation loss: 2.6641298932151907

Epoch: 171| Step: 0
Training loss: 2.872432391480769
Validation loss: 2.667546948631592

Epoch: 5| Step: 1
Training loss: 3.4482622386400172
Validation loss: 2.6735279377330134

Epoch: 5| Step: 2
Training loss: 3.133904549767076
Validation loss: 2.68242559404278

Epoch: 5| Step: 3
Training loss: 2.5900184722006006
Validation loss: 2.69717019341715

Epoch: 5| Step: 4
Training loss: 3.238655538061105
Validation loss: 2.700120602887641

Epoch: 5| Step: 5
Training loss: 3.4754035989768512
Validation loss: 2.687016757751217

Epoch: 5| Step: 6
Training loss: 2.731936866410573
Validation loss: 2.6851592614945092

Epoch: 5| Step: 7
Training loss: 2.6249086273275966
Validation loss: 2.678763104430276

Epoch: 5| Step: 8
Training loss: 2.8981054892180413
Validation loss: 2.6726896105281677

Epoch: 5| Step: 9
Training loss: 2.9933291017917325
Validation loss: 2.675964985332662

Epoch: 5| Step: 10
Training loss: 2.75440392292263
Validation loss: 2.668125307082838

Epoch: 172| Step: 0
Training loss: 2.840737392438853
Validation loss: 2.662470681842071

Epoch: 5| Step: 1
Training loss: 3.0078735345369934
Validation loss: 2.661693376632412

Epoch: 5| Step: 2
Training loss: 2.6512475873692463
Validation loss: 2.6610484551219553

Epoch: 5| Step: 3
Training loss: 3.2810584602763444
Validation loss: 2.662795343367305

Epoch: 5| Step: 4
Training loss: 2.794998135915827
Validation loss: 2.6646334840638777

Epoch: 5| Step: 5
Training loss: 3.2835476051807566
Validation loss: 2.66488449535911

Epoch: 5| Step: 6
Training loss: 3.4405445834401926
Validation loss: 2.6622649005869574

Epoch: 5| Step: 7
Training loss: 2.8277818671869146
Validation loss: 2.6615302197757953

Epoch: 5| Step: 8
Training loss: 3.6543447633069444
Validation loss: 2.661204514746877

Epoch: 5| Step: 9
Training loss: 2.269175096099958
Validation loss: 2.6589165483859665

Epoch: 5| Step: 10
Training loss: 2.5932115662368167
Validation loss: 2.6627945384973772

Epoch: 173| Step: 0
Training loss: 3.1375143104014094
Validation loss: 2.6651961610444768

Epoch: 5| Step: 1
Training loss: 2.820812064860265
Validation loss: 2.6669002295763082

Epoch: 5| Step: 2
Training loss: 3.034265178732031
Validation loss: 2.6699567249821197

Epoch: 5| Step: 3
Training loss: 2.5092896481412907
Validation loss: 2.6748651576909825

Epoch: 5| Step: 4
Training loss: 2.698642078413292
Validation loss: 2.681253490889851

Epoch: 5| Step: 5
Training loss: 3.2349690799326223
Validation loss: 2.685060804065128

Epoch: 5| Step: 6
Training loss: 3.728524577238467
Validation loss: 2.668283168370388

Epoch: 5| Step: 7
Training loss: 2.5348367592584036
Validation loss: 2.6640323902690377

Epoch: 5| Step: 8
Training loss: 2.739868487661661
Validation loss: 2.662182368307752

Epoch: 5| Step: 9
Training loss: 3.1141619615227487
Validation loss: 2.660011903282979

Epoch: 5| Step: 10
Training loss: 3.1655093805526304
Validation loss: 2.6585309498857574

Epoch: 174| Step: 0
Training loss: 2.974092194349927
Validation loss: 2.6590290884432046

Epoch: 5| Step: 1
Training loss: 3.1639657464952298
Validation loss: 2.65782981185405

Epoch: 5| Step: 2
Training loss: 3.343947502791906
Validation loss: 2.6573662609881556

Epoch: 5| Step: 3
Training loss: 2.5918425014823403
Validation loss: 2.659170925035306

Epoch: 5| Step: 4
Training loss: 2.978276437629729
Validation loss: 2.654526674462184

Epoch: 5| Step: 5
Training loss: 2.8360715051522285
Validation loss: 2.6554814591926195

Epoch: 5| Step: 6
Training loss: 3.0373151997679955
Validation loss: 2.65812091652503

Epoch: 5| Step: 7
Training loss: 2.9785508450786518
Validation loss: 2.665154820371933

Epoch: 5| Step: 8
Training loss: 2.8360388871662257
Validation loss: 2.6725614565792197

Epoch: 5| Step: 9
Training loss: 3.062654141030822
Validation loss: 2.686526108471141

Epoch: 5| Step: 10
Training loss: 3.093591859417038
Validation loss: 2.6802243504833294

Epoch: 175| Step: 0
Training loss: 2.9973045001571994
Validation loss: 2.6826715595587927

Epoch: 5| Step: 1
Training loss: 2.9182568347896294
Validation loss: 2.6842930521738166

Epoch: 5| Step: 2
Training loss: 3.149336996392368
Validation loss: 2.6814163377470743

Epoch: 5| Step: 3
Training loss: 3.1506682035378115
Validation loss: 2.6820954269049384

Epoch: 5| Step: 4
Training loss: 3.0053756552691824
Validation loss: 2.674242263518063

Epoch: 5| Step: 5
Training loss: 2.713604145953772
Validation loss: 2.669534213050151

Epoch: 5| Step: 6
Training loss: 2.639235904252342
Validation loss: 2.667288341146949

Epoch: 5| Step: 7
Training loss: 3.10831314434896
Validation loss: 2.660556132102559

Epoch: 5| Step: 8
Training loss: 3.1836184635256264
Validation loss: 2.6580376127448395

Epoch: 5| Step: 9
Training loss: 3.1573440619567785
Validation loss: 2.6576070003546257

Epoch: 5| Step: 10
Training loss: 2.7754966291442535
Validation loss: 2.654342545576389

Epoch: 176| Step: 0
Training loss: 3.1124919048648336
Validation loss: 2.6500125177342784

Epoch: 5| Step: 1
Training loss: 2.857189740068796
Validation loss: 2.6514404513977166

Epoch: 5| Step: 2
Training loss: 2.2921184672418424
Validation loss: 2.653168276422946

Epoch: 5| Step: 3
Training loss: 3.587787757524404
Validation loss: 2.6530139211808885

Epoch: 5| Step: 4
Training loss: 3.6593088249914296
Validation loss: 2.649671765410182

Epoch: 5| Step: 5
Training loss: 2.5239894015396485
Validation loss: 2.6522299983349265

Epoch: 5| Step: 6
Training loss: 3.194430427704803
Validation loss: 2.6548577208506083

Epoch: 5| Step: 7
Training loss: 3.1602072505348455
Validation loss: 2.6601542946153263

Epoch: 5| Step: 8
Training loss: 2.4505560963951813
Validation loss: 2.6513090512358684

Epoch: 5| Step: 9
Training loss: 2.9345850990164077
Validation loss: 2.6548535512075913

Epoch: 5| Step: 10
Training loss: 2.72488290377668
Validation loss: 2.652120780160073

Epoch: 177| Step: 0
Training loss: 2.791295544072962
Validation loss: 2.65226470671454

Epoch: 5| Step: 1
Training loss: 3.167354877040818
Validation loss: 2.6496042347279563

Epoch: 5| Step: 2
Training loss: 2.505487903584802
Validation loss: 2.6550782062616363

Epoch: 5| Step: 3
Training loss: 2.7818956804331725
Validation loss: 2.657854398416086

Epoch: 5| Step: 4
Training loss: 2.907763179502218
Validation loss: 2.65325220991748

Epoch: 5| Step: 5
Training loss: 2.862377487292817
Validation loss: 2.657132917315361

Epoch: 5| Step: 6
Training loss: 3.405854368419448
Validation loss: 2.6535350187877356

Epoch: 5| Step: 7
Training loss: 2.8853479003056703
Validation loss: 2.6518281095341893

Epoch: 5| Step: 8
Training loss: 2.826356282047408
Validation loss: 2.6530326530834545

Epoch: 5| Step: 9
Training loss: 3.283611791843873
Validation loss: 2.6492040349286063

Epoch: 5| Step: 10
Training loss: 3.3350790379893893
Validation loss: 2.647839510788453

Epoch: 178| Step: 0
Training loss: 2.9002686343242616
Validation loss: 2.6485006465408394

Epoch: 5| Step: 1
Training loss: 3.103564483469251
Validation loss: 2.6488721058193794

Epoch: 5| Step: 2
Training loss: 2.8146399939589544
Validation loss: 2.6470020753047074

Epoch: 5| Step: 3
Training loss: 3.48776107959356
Validation loss: 2.6466400632262297

Epoch: 5| Step: 4
Training loss: 2.5913501345861256
Validation loss: 2.6481109039286106

Epoch: 5| Step: 5
Training loss: 2.888241006469196
Validation loss: 2.6474810401488367

Epoch: 5| Step: 6
Training loss: 3.258241474258413
Validation loss: 2.6476277335425604

Epoch: 5| Step: 7
Training loss: 2.7896400516167366
Validation loss: 2.646075129068255

Epoch: 5| Step: 8
Training loss: 2.7827868555205693
Validation loss: 2.648961617333378

Epoch: 5| Step: 9
Training loss: 3.2542485564246912
Validation loss: 2.6518584226061552

Epoch: 5| Step: 10
Training loss: 2.8188583556196347
Validation loss: 2.649336465538696

Epoch: 179| Step: 0
Training loss: 3.282587269351449
Validation loss: 2.6437857581304884

Epoch: 5| Step: 1
Training loss: 2.733909523717731
Validation loss: 2.6454828476061665

Epoch: 5| Step: 2
Training loss: 2.945913238376927
Validation loss: 2.6457159048435943

Epoch: 5| Step: 3
Training loss: 3.1971012695424523
Validation loss: 2.644818427593755

Epoch: 5| Step: 4
Training loss: 2.7030132469053045
Validation loss: 2.6445235916331926

Epoch: 5| Step: 5
Training loss: 2.8645759351230224
Validation loss: 2.6425784742462755

Epoch: 5| Step: 6
Training loss: 3.110105802447401
Validation loss: 2.6433016216038996

Epoch: 5| Step: 7
Training loss: 2.8568200542112474
Validation loss: 2.643026260225033

Epoch: 5| Step: 8
Training loss: 2.7384795853078674
Validation loss: 2.6450962318577886

Epoch: 5| Step: 9
Training loss: 2.512205180620674
Validation loss: 2.642821047619515

Epoch: 5| Step: 10
Training loss: 3.767750879957486
Validation loss: 2.6448450698278183

Epoch: 180| Step: 0
Training loss: 3.316691499805614
Validation loss: 2.644978696657193

Epoch: 5| Step: 1
Training loss: 2.969221218256453
Validation loss: 2.64533192233424

Epoch: 5| Step: 2
Training loss: 3.2254211032569007
Validation loss: 2.6454366180321536

Epoch: 5| Step: 3
Training loss: 2.921702170742926
Validation loss: 2.6445436409966407

Epoch: 5| Step: 4
Training loss: 2.399473283508079
Validation loss: 2.6430994643431807

Epoch: 5| Step: 5
Training loss: 2.89485362287349
Validation loss: 2.6395208452295007

Epoch: 5| Step: 6
Training loss: 3.194454012501711
Validation loss: 2.639671425830093

Epoch: 5| Step: 7
Training loss: 3.013772820631954
Validation loss: 2.6535477213396743

Epoch: 5| Step: 8
Training loss: 2.7967478973661746
Validation loss: 2.65856972246842

Epoch: 5| Step: 9
Training loss: 3.3426025418264302
Validation loss: 2.666417981929255

Epoch: 5| Step: 10
Training loss: 2.46070933419587
Validation loss: 2.663696976092255

Epoch: 181| Step: 0
Training loss: 3.3058349925803836
Validation loss: 2.675774098802841

Epoch: 5| Step: 1
Training loss: 2.9885159668338726
Validation loss: 2.6643669866918476

Epoch: 5| Step: 2
Training loss: 2.9400949582185754
Validation loss: 2.6498513573402263

Epoch: 5| Step: 3
Training loss: 2.7926810589921325
Validation loss: 2.6424740407623295

Epoch: 5| Step: 4
Training loss: 3.5524805616884545
Validation loss: 2.6401501348926537

Epoch: 5| Step: 5
Training loss: 3.2957498519748114
Validation loss: 2.6390483178375406

Epoch: 5| Step: 6
Training loss: 2.981144139871541
Validation loss: 2.6385472125225835

Epoch: 5| Step: 7
Training loss: 2.4903894712731036
Validation loss: 2.645219888870934

Epoch: 5| Step: 8
Training loss: 2.262652953652388
Validation loss: 2.640106584251608

Epoch: 5| Step: 9
Training loss: 3.1462575024411907
Validation loss: 2.6411852818955395

Epoch: 5| Step: 10
Training loss: 2.7658226675310837
Validation loss: 2.6411879530960456

Epoch: 182| Step: 0
Training loss: 3.1069722308835406
Validation loss: 2.6404831303233114

Epoch: 5| Step: 1
Training loss: 2.956296801851879
Validation loss: 2.6414652569605703

Epoch: 5| Step: 2
Training loss: 3.1457918850692397
Validation loss: 2.6427461381726403

Epoch: 5| Step: 3
Training loss: 2.6953752151048316
Validation loss: 2.643033414185704

Epoch: 5| Step: 4
Training loss: 2.472893340448812
Validation loss: 2.6404640773459374

Epoch: 5| Step: 5
Training loss: 2.9241661839572193
Validation loss: 2.63765893505985

Epoch: 5| Step: 6
Training loss: 3.4974036804853483
Validation loss: 2.6371499656723407

Epoch: 5| Step: 7
Training loss: 3.323930846678152
Validation loss: 2.641688314871726

Epoch: 5| Step: 8
Training loss: 2.466844040275544
Validation loss: 2.6395770684826148

Epoch: 5| Step: 9
Training loss: 3.2625852610237205
Validation loss: 2.6386238705195737

Epoch: 5| Step: 10
Training loss: 2.588323224455905
Validation loss: 2.6419812936610194

Epoch: 183| Step: 0
Training loss: 2.9021081430908695
Validation loss: 2.6446488312592744

Epoch: 5| Step: 1
Training loss: 3.4047408654283475
Validation loss: 2.662880552299478

Epoch: 5| Step: 2
Training loss: 3.158325419420243
Validation loss: 2.6588255352114487

Epoch: 5| Step: 3
Training loss: 3.265673477324095
Validation loss: 2.6630751874778715

Epoch: 5| Step: 4
Training loss: 2.7911454658391794
Validation loss: 2.662266707089458

Epoch: 5| Step: 5
Training loss: 2.445815159623463
Validation loss: 2.6481994692304958

Epoch: 5| Step: 6
Training loss: 3.067683290509961
Validation loss: 2.6484732589608986

Epoch: 5| Step: 7
Training loss: 2.941225975966352
Validation loss: 2.639813852865136

Epoch: 5| Step: 8
Training loss: 3.1807651052802157
Validation loss: 2.637445677436128

Epoch: 5| Step: 9
Training loss: 2.6068026718243025
Validation loss: 2.641452593359144

Epoch: 5| Step: 10
Training loss: 2.7581784273043186
Validation loss: 2.6356785874418636

Epoch: 184| Step: 0
Training loss: 3.2324024026981464
Validation loss: 2.6339891039966905

Epoch: 5| Step: 1
Training loss: 3.219206990512743
Validation loss: 2.636578798579185

Epoch: 5| Step: 2
Training loss: 2.542792670135231
Validation loss: 2.635697791732002

Epoch: 5| Step: 3
Training loss: 3.0577820228145516
Validation loss: 2.63411143423285

Epoch: 5| Step: 4
Training loss: 3.382401439192221
Validation loss: 2.6370915315353978

Epoch: 5| Step: 5
Training loss: 2.629951258015508
Validation loss: 2.6325487849656803

Epoch: 5| Step: 6
Training loss: 2.892058146101937
Validation loss: 2.6330835823540033

Epoch: 5| Step: 7
Training loss: 2.8006850562608414
Validation loss: 2.6340778657621198

Epoch: 5| Step: 8
Training loss: 2.7021854068610796
Validation loss: 2.6320523729723697

Epoch: 5| Step: 9
Training loss: 3.060117923982538
Validation loss: 2.633270949183831

Epoch: 5| Step: 10
Training loss: 3.048332452650518
Validation loss: 2.6391513899713472

Epoch: 185| Step: 0
Training loss: 3.015834188370708
Validation loss: 2.6382856390487173

Epoch: 5| Step: 1
Training loss: 2.757984707132255
Validation loss: 2.640948874804265

Epoch: 5| Step: 2
Training loss: 2.9016077846430037
Validation loss: 2.6556133552073753

Epoch: 5| Step: 3
Training loss: 2.714465217821405
Validation loss: 2.672709584809093

Epoch: 5| Step: 4
Training loss: 3.1044888083891644
Validation loss: 2.6772384221965986

Epoch: 5| Step: 5
Training loss: 3.22223452496281
Validation loss: 2.683217807823755

Epoch: 5| Step: 6
Training loss: 3.115811993373759
Validation loss: 2.684336800859588

Epoch: 5| Step: 7
Training loss: 2.5623308451576636
Validation loss: 2.656839954507709

Epoch: 5| Step: 8
Training loss: 3.0538594326003334
Validation loss: 2.6451257992311077

Epoch: 5| Step: 9
Training loss: 3.2262873128147005
Validation loss: 2.6387570604240658

Epoch: 5| Step: 10
Training loss: 3.001548526379905
Validation loss: 2.6326385223423068

Epoch: 186| Step: 0
Training loss: 2.4745610088628798
Validation loss: 2.6335106086588693

Epoch: 5| Step: 1
Training loss: 2.743519864173975
Validation loss: 2.633887010495881

Epoch: 5| Step: 2
Training loss: 2.957551897743172
Validation loss: 2.6361526855129283

Epoch: 5| Step: 3
Training loss: 2.4040014486768677
Validation loss: 2.63656071014945

Epoch: 5| Step: 4
Training loss: 3.2095186760378787
Validation loss: 2.636226323616663

Epoch: 5| Step: 5
Training loss: 2.980633212410381
Validation loss: 2.6450849822708076

Epoch: 5| Step: 6
Training loss: 3.2275083323990916
Validation loss: 2.6435392923527816

Epoch: 5| Step: 7
Training loss: 3.355812774537129
Validation loss: 2.644031525125809

Epoch: 5| Step: 8
Training loss: 2.9755080550605104
Validation loss: 2.6478906438896224

Epoch: 5| Step: 9
Training loss: 3.4604074317645077
Validation loss: 2.6582525050896506

Epoch: 5| Step: 10
Training loss: 2.660537938814414
Validation loss: 2.6610266399173543

Epoch: 187| Step: 0
Training loss: 1.9852249848207244
Validation loss: 2.6653691581367283

Epoch: 5| Step: 1
Training loss: 3.1019240776328547
Validation loss: 2.6716712260360103

Epoch: 5| Step: 2
Training loss: 3.3211536733192215
Validation loss: 2.7030747647430395

Epoch: 5| Step: 3
Training loss: 3.1657716255838104
Validation loss: 2.717291750531958

Epoch: 5| Step: 4
Training loss: 3.011523526169011
Validation loss: 2.7143716678630714

Epoch: 5| Step: 5
Training loss: 3.223547905766105
Validation loss: 2.7507425575398465

Epoch: 5| Step: 6
Training loss: 3.341706409043614
Validation loss: 2.7124441225872573

Epoch: 5| Step: 7
Training loss: 2.8835828625378657
Validation loss: 2.687657296570541

Epoch: 5| Step: 8
Training loss: 3.102437777452413
Validation loss: 2.6653922064468465

Epoch: 5| Step: 9
Training loss: 2.666852547207086
Validation loss: 2.657900783350661

Epoch: 5| Step: 10
Training loss: 2.7993241993203273
Validation loss: 2.65674737644527

Epoch: 188| Step: 0
Training loss: 3.860078940498482
Validation loss: 2.6557272409335333

Epoch: 5| Step: 1
Training loss: 3.2928875135942706
Validation loss: 2.658794138732764

Epoch: 5| Step: 2
Training loss: 2.7131539993476275
Validation loss: 2.6587338526360234

Epoch: 5| Step: 3
Training loss: 2.9738114427053266
Validation loss: 2.661086864437901

Epoch: 5| Step: 4
Training loss: 2.821762937768751
Validation loss: 2.664773034762496

Epoch: 5| Step: 5
Training loss: 2.9812330713331274
Validation loss: 2.669584391875683

Epoch: 5| Step: 6
Training loss: 2.73351322217904
Validation loss: 2.681941188937314

Epoch: 5| Step: 7
Training loss: 3.0097312454943514
Validation loss: 2.6906547678990234

Epoch: 5| Step: 8
Training loss: 2.6326637112827993
Validation loss: 2.6938973055850606

Epoch: 5| Step: 9
Training loss: 2.955554749752435
Validation loss: 2.709952504785025

Epoch: 5| Step: 10
Training loss: 2.672846032089182
Validation loss: 2.7373863034404033

Epoch: 189| Step: 0
Training loss: 2.765933089687532
Validation loss: 2.7592428605056356

Epoch: 5| Step: 1
Training loss: 3.245234590347317
Validation loss: 2.7564993374929645

Epoch: 5| Step: 2
Training loss: 3.306714457607489
Validation loss: 2.7446710996285666

Epoch: 5| Step: 3
Training loss: 2.595507658178282
Validation loss: 2.7197534946109623

Epoch: 5| Step: 4
Training loss: 3.0049859575651223
Validation loss: 2.712066677173947

Epoch: 5| Step: 5
Training loss: 2.6973330677835006
Validation loss: 2.7032192805820827

Epoch: 5| Step: 6
Training loss: 3.035591869931374
Validation loss: 2.692554600794496

Epoch: 5| Step: 7
Training loss: 3.0995689153885055
Validation loss: 2.676158377670958

Epoch: 5| Step: 8
Training loss: 3.4476618984789016
Validation loss: 2.6555176064836687

Epoch: 5| Step: 9
Training loss: 2.8399703510509813
Validation loss: 2.661064221996949

Epoch: 5| Step: 10
Training loss: 3.0643952402515837
Validation loss: 2.657266041028857

Epoch: 190| Step: 0
Training loss: 3.002169778087982
Validation loss: 2.657316453447107

Epoch: 5| Step: 1
Training loss: 2.309641953500399
Validation loss: 2.643538697880102

Epoch: 5| Step: 2
Training loss: 3.1507341891670477
Validation loss: 2.6282898990786365

Epoch: 5| Step: 3
Training loss: 3.1563776575843017
Validation loss: 2.6255915317596834

Epoch: 5| Step: 4
Training loss: 2.6907754499349545
Validation loss: 2.6243412677715714

Epoch: 5| Step: 5
Training loss: 3.262167528538798
Validation loss: 2.6214803351876017

Epoch: 5| Step: 6
Training loss: 3.152724913061938
Validation loss: 2.6223669142891817

Epoch: 5| Step: 7
Training loss: 2.1959330811787914
Validation loss: 2.621442596356261

Epoch: 5| Step: 8
Training loss: 3.234882996696996
Validation loss: 2.6197364106682484

Epoch: 5| Step: 9
Training loss: 2.994662782411216
Validation loss: 2.618544446289742

Epoch: 5| Step: 10
Training loss: 3.334936487602541
Validation loss: 2.6231460323480236

Epoch: 191| Step: 0
Training loss: 3.0969223557748027
Validation loss: 2.628500472247808

Epoch: 5| Step: 1
Training loss: 3.258595324533979
Validation loss: 2.6294979647351937

Epoch: 5| Step: 2
Training loss: 2.8822227639823854
Validation loss: 2.6385084605178895

Epoch: 5| Step: 3
Training loss: 3.043617580909402
Validation loss: 2.639865140448875

Epoch: 5| Step: 4
Training loss: 2.3707883534469287
Validation loss: 2.647755916938353

Epoch: 5| Step: 5
Training loss: 2.7843201226200716
Validation loss: 2.6591670099231983

Epoch: 5| Step: 6
Training loss: 2.927163789306343
Validation loss: 2.6521495200843455

Epoch: 5| Step: 7
Training loss: 3.5758823879708483
Validation loss: 2.637896670071207

Epoch: 5| Step: 8
Training loss: 3.0660044024112993
Validation loss: 2.6252672212750965

Epoch: 5| Step: 9
Training loss: 2.6507588793425882
Validation loss: 2.6304036925110723

Epoch: 5| Step: 10
Training loss: 2.83218412841677
Validation loss: 2.622558834712162

Epoch: 192| Step: 0
Training loss: 3.1393246212288424
Validation loss: 2.6235672849241474

Epoch: 5| Step: 1
Training loss: 2.7630221084941735
Validation loss: 2.6185362850604488

Epoch: 5| Step: 2
Training loss: 2.768616518544562
Validation loss: 2.6202200259249566

Epoch: 5| Step: 3
Training loss: 2.8997885133645886
Validation loss: 2.6145048039397105

Epoch: 5| Step: 4
Training loss: 2.58363622509947
Validation loss: 2.612335003843783

Epoch: 5| Step: 5
Training loss: 3.4531296950088275
Validation loss: 2.614432300427641

Epoch: 5| Step: 6
Training loss: 3.008240508305569
Validation loss: 2.616774445216021

Epoch: 5| Step: 7
Training loss: 3.0150477988532978
Validation loss: 2.615114434028379

Epoch: 5| Step: 8
Training loss: 2.8600009587426345
Validation loss: 2.6148861386686177

Epoch: 5| Step: 9
Training loss: 2.8584588255920322
Validation loss: 2.61342608345118

Epoch: 5| Step: 10
Training loss: 3.037543458980917
Validation loss: 2.6120653613143543

Epoch: 193| Step: 0
Training loss: 3.0243084266747267
Validation loss: 2.616469776648524

Epoch: 5| Step: 1
Training loss: 3.277782242622855
Validation loss: 2.6218235165158457

Epoch: 5| Step: 2
Training loss: 2.8782761193446076
Validation loss: 2.6211151503135595

Epoch: 5| Step: 3
Training loss: 2.8311936396026955
Validation loss: 2.6197390137090255

Epoch: 5| Step: 4
Training loss: 3.3408234525708718
Validation loss: 2.619000976433766

Epoch: 5| Step: 5
Training loss: 2.6574592081924395
Validation loss: 2.6156311746262397

Epoch: 5| Step: 6
Training loss: 2.907488815272984
Validation loss: 2.6132850523706304

Epoch: 5| Step: 7
Training loss: 3.3205121148636176
Validation loss: 2.6096370183042055

Epoch: 5| Step: 8
Training loss: 3.0336501853815685
Validation loss: 2.6171776183787734

Epoch: 5| Step: 9
Training loss: 2.7060590046710873
Validation loss: 2.6146842719057424

Epoch: 5| Step: 10
Training loss: 2.126884074005401
Validation loss: 2.6164672663766617

Epoch: 194| Step: 0
Training loss: 2.8601166644010125
Validation loss: 2.6123054254910523

Epoch: 5| Step: 1
Training loss: 2.70281989520108
Validation loss: 2.6179851591679677

Epoch: 5| Step: 2
Training loss: 2.9979551021682593
Validation loss: 2.617652303494971

Epoch: 5| Step: 3
Training loss: 2.3216151424513547
Validation loss: 2.6222386336524193

Epoch: 5| Step: 4
Training loss: 3.1478529924726852
Validation loss: 2.6275374077830813

Epoch: 5| Step: 5
Training loss: 2.705106505097065
Validation loss: 2.622813992907882

Epoch: 5| Step: 6
Training loss: 3.0170164702828535
Validation loss: 2.627554087011866

Epoch: 5| Step: 7
Training loss: 3.4250885666582587
Validation loss: 2.61947996324328

Epoch: 5| Step: 8
Training loss: 3.4341246245514565
Validation loss: 2.6160287627236105

Epoch: 5| Step: 9
Training loss: 2.917146824868326
Validation loss: 2.6053693636516306

Epoch: 5| Step: 10
Training loss: 2.575574225684536
Validation loss: 2.6017601240893744

Epoch: 195| Step: 0
Training loss: 2.8448360171935536
Validation loss: 2.598389286913585

Epoch: 5| Step: 1
Training loss: 2.7549493640324076
Validation loss: 2.5967203935751693

Epoch: 5| Step: 2
Training loss: 3.261199288491179
Validation loss: 2.6013335543845217

Epoch: 5| Step: 3
Training loss: 2.883084746947452
Validation loss: 2.5963646985850217

Epoch: 5| Step: 4
Training loss: 3.2370802029068217
Validation loss: 2.597644723907813

Epoch: 5| Step: 5
Training loss: 2.6834888243395434
Validation loss: 2.5938283308259416

Epoch: 5| Step: 6
Training loss: 2.7085311719577003
Validation loss: 2.597006016646722

Epoch: 5| Step: 7
Training loss: 2.961351189613467
Validation loss: 2.601930351282113

Epoch: 5| Step: 8
Training loss: 2.922035580062697
Validation loss: 2.611125344005128

Epoch: 5| Step: 9
Training loss: 3.4085580548085854
Validation loss: 2.612514260730974

Epoch: 5| Step: 10
Training loss: 2.5064291302599937
Validation loss: 2.618132779632167

Epoch: 196| Step: 0
Training loss: 2.9185156456516683
Validation loss: 2.6285885893793313

Epoch: 5| Step: 1
Training loss: 3.626058095215173
Validation loss: 2.635540779132606

Epoch: 5| Step: 2
Training loss: 2.941026072864212
Validation loss: 2.6630945542366518

Epoch: 5| Step: 3
Training loss: 2.572947997444272
Validation loss: 2.6675742758912375

Epoch: 5| Step: 4
Training loss: 2.8704916394046665
Validation loss: 2.6943058511368405

Epoch: 5| Step: 5
Training loss: 2.9834310426818966
Validation loss: 2.7011802705893473

Epoch: 5| Step: 6
Training loss: 2.618629809696421
Validation loss: 2.6413559023150226

Epoch: 5| Step: 7
Training loss: 2.730913859966858
Validation loss: 2.612990014741353

Epoch: 5| Step: 8
Training loss: 2.6803837975359994
Validation loss: 2.595584225276891

Epoch: 5| Step: 9
Training loss: 3.2856275150143595
Validation loss: 2.5905351647734784

Epoch: 5| Step: 10
Training loss: 3.148892126082458
Validation loss: 2.5954193276385777

Epoch: 197| Step: 0
Training loss: 2.685330779658104
Validation loss: 2.6036861608057893

Epoch: 5| Step: 1
Training loss: 2.926138475355041
Validation loss: 2.591217933097317

Epoch: 5| Step: 2
Training loss: 2.7528962576122953
Validation loss: 2.5957903249401224

Epoch: 5| Step: 3
Training loss: 2.902745584880286
Validation loss: 2.5979681604478575

Epoch: 5| Step: 4
Training loss: 3.0424605252440755
Validation loss: 2.5997022798306024

Epoch: 5| Step: 5
Training loss: 3.0793902125446397
Validation loss: 2.604090648567059

Epoch: 5| Step: 6
Training loss: 3.270475590735942
Validation loss: 2.6087041961221034

Epoch: 5| Step: 7
Training loss: 2.453889375402124
Validation loss: 2.61067801359844

Epoch: 5| Step: 8
Training loss: 3.3582360044500255
Validation loss: 2.6302649148422805

Epoch: 5| Step: 9
Training loss: 2.7229660492796794
Validation loss: 2.631774623770847

Epoch: 5| Step: 10
Training loss: 3.169039055094595
Validation loss: 2.631599523440123

Epoch: 198| Step: 0
Training loss: 3.1933720673008468
Validation loss: 2.6274609795585766

Epoch: 5| Step: 1
Training loss: 2.718544173944889
Validation loss: 2.637354037047383

Epoch: 5| Step: 2
Training loss: 3.227864222227104
Validation loss: 2.6267010099179178

Epoch: 5| Step: 3
Training loss: 2.6122628866398605
Validation loss: 2.6173770371240046

Epoch: 5| Step: 4
Training loss: 2.700994809871293
Validation loss: 2.612996529329049

Epoch: 5| Step: 5
Training loss: 2.4967956033814014
Validation loss: 2.606039740191583

Epoch: 5| Step: 6
Training loss: 2.849991540728948
Validation loss: 2.6039896541034757

Epoch: 5| Step: 7
Training loss: 2.995478560690454
Validation loss: 2.6075529295323645

Epoch: 5| Step: 8
Training loss: 3.6121359829826596
Validation loss: 2.6039009073483594

Epoch: 5| Step: 9
Training loss: 3.0985961873426415
Validation loss: 2.6004174678254626

Epoch: 5| Step: 10
Training loss: 2.524928547065371
Validation loss: 2.604888370717008

Epoch: 199| Step: 0
Training loss: 3.2726633253496864
Validation loss: 2.601537097630869

Epoch: 5| Step: 1
Training loss: 3.132638065495222
Validation loss: 2.5975956947607988

Epoch: 5| Step: 2
Training loss: 3.1054813408746327
Validation loss: 2.597414082753437

Epoch: 5| Step: 3
Training loss: 2.946335996684507
Validation loss: 2.5953776894442915

Epoch: 5| Step: 4
Training loss: 2.4433837694250857
Validation loss: 2.600425461144452

Epoch: 5| Step: 5
Training loss: 2.8878828909528016
Validation loss: 2.597766500769177

Epoch: 5| Step: 6
Training loss: 2.9651187573173385
Validation loss: 2.599575179545654

Epoch: 5| Step: 7
Training loss: 2.674240225444646
Validation loss: 2.6024428761427125

Epoch: 5| Step: 8
Training loss: 3.2281945190625168
Validation loss: 2.6080820182380298

Epoch: 5| Step: 9
Training loss: 2.9408008616092323
Validation loss: 2.601732390320515

Epoch: 5| Step: 10
Training loss: 2.514125780028751
Validation loss: 2.610889284518867

Epoch: 200| Step: 0
Training loss: 2.7374041536178284
Validation loss: 2.6003818948919193

Epoch: 5| Step: 1
Training loss: 2.8997375369510814
Validation loss: 2.6068820904835577

Epoch: 5| Step: 2
Training loss: 3.085107928448498
Validation loss: 2.608446328931116

Epoch: 5| Step: 3
Training loss: 2.7630920880352305
Validation loss: 2.6144229614376746

Epoch: 5| Step: 4
Training loss: 3.0926496302086166
Validation loss: 2.616490263394701

Epoch: 5| Step: 5
Training loss: 3.219833339856303
Validation loss: 2.6019401440024734

Epoch: 5| Step: 6
Training loss: 2.754931536341326
Validation loss: 2.5986781285620664

Epoch: 5| Step: 7
Training loss: 2.2652307627768016
Validation loss: 2.6006295318792336

Epoch: 5| Step: 8
Training loss: 3.2841430988706724
Validation loss: 2.588630342147944

Epoch: 5| Step: 9
Training loss: 3.0502626024606023
Validation loss: 2.5831968276060766

Epoch: 5| Step: 10
Training loss: 2.941388255516422
Validation loss: 2.5889306680572424

Epoch: 201| Step: 0
Training loss: 2.869556248880778
Validation loss: 2.5864466521683287

Epoch: 5| Step: 1
Training loss: 2.542105860885179
Validation loss: 2.5830303173867035

Epoch: 5| Step: 2
Training loss: 2.777412853642111
Validation loss: 2.582163483991655

Epoch: 5| Step: 3
Training loss: 2.781794462595845
Validation loss: 2.588481200602991

Epoch: 5| Step: 4
Training loss: 3.279221552608007
Validation loss: 2.579552016307245

Epoch: 5| Step: 5
Training loss: 3.6014502253378344
Validation loss: 2.5828193850616854

Epoch: 5| Step: 6
Training loss: 2.866035250684559
Validation loss: 2.5809649395602414

Epoch: 5| Step: 7
Training loss: 3.0681191100831184
Validation loss: 2.5842004323749

Epoch: 5| Step: 8
Training loss: 2.4200569466124993
Validation loss: 2.5983494209632876

Epoch: 5| Step: 9
Training loss: 2.5914905312431586
Validation loss: 2.615449771065797

Epoch: 5| Step: 10
Training loss: 3.2929051801489306
Validation loss: 2.6262629469537324

Epoch: 202| Step: 0
Training loss: 3.2485412845298614
Validation loss: 2.635446713579585

Epoch: 5| Step: 1
Training loss: 2.887090388057408
Validation loss: 2.6535218640273235

Epoch: 5| Step: 2
Training loss: 2.706944848205143
Validation loss: 2.613599164406945

Epoch: 5| Step: 3
Training loss: 3.7076884934192353
Validation loss: 2.5885951885748737

Epoch: 5| Step: 4
Training loss: 2.769645828438021
Validation loss: 2.582265623973855

Epoch: 5| Step: 5
Training loss: 2.643124903735044
Validation loss: 2.582010484877252

Epoch: 5| Step: 6
Training loss: 2.7175371819192327
Validation loss: 2.5824530484735013

Epoch: 5| Step: 7
Training loss: 3.20862698552873
Validation loss: 2.575864305967045

Epoch: 5| Step: 8
Training loss: 2.8135958761797273
Validation loss: 2.578664660162569

Epoch: 5| Step: 9
Training loss: 2.59239317553422
Validation loss: 2.578965858319591

Epoch: 5| Step: 10
Training loss: 2.8360984063017014
Validation loss: 2.576136810159381

Epoch: 203| Step: 0
Training loss: 2.6691421006336933
Validation loss: 2.5803965008758154

Epoch: 5| Step: 1
Training loss: 2.9416187711135975
Validation loss: 2.579685377127042

Epoch: 5| Step: 2
Training loss: 3.3856479663573427
Validation loss: 2.579298431652995

Epoch: 5| Step: 3
Training loss: 2.4728994144479572
Validation loss: 2.582652566613004

Epoch: 5| Step: 4
Training loss: 3.2204031541438605
Validation loss: 2.5863463970722482

Epoch: 5| Step: 5
Training loss: 2.937641383887691
Validation loss: 2.583059183896997

Epoch: 5| Step: 6
Training loss: 2.227204561517418
Validation loss: 2.5933866131399737

Epoch: 5| Step: 7
Training loss: 3.316911171442232
Validation loss: 2.5893554662748275

Epoch: 5| Step: 8
Training loss: 2.975639941204645
Validation loss: 2.593449047947289

Epoch: 5| Step: 9
Training loss: 3.139383706519911
Validation loss: 2.5953173941714964

Epoch: 5| Step: 10
Training loss: 2.6954239531983806
Validation loss: 2.5914909655253338

Epoch: 204| Step: 0
Training loss: 2.3143511399603227
Validation loss: 2.5974764084164343

Epoch: 5| Step: 1
Training loss: 3.559858447057402
Validation loss: 2.610538199086169

Epoch: 5| Step: 2
Training loss: 2.4829172139925504
Validation loss: 2.6071365419702293

Epoch: 5| Step: 3
Training loss: 3.115104725211601
Validation loss: 2.624095983752762

Epoch: 5| Step: 4
Training loss: 2.7083015048773285
Validation loss: 2.6114272835866585

Epoch: 5| Step: 5
Training loss: 3.3235163770317784
Validation loss: 2.613157376608373

Epoch: 5| Step: 6
Training loss: 3.281461727032483
Validation loss: 2.6131107478197753

Epoch: 5| Step: 7
Training loss: 2.1584928706451016
Validation loss: 2.6097761659654144

Epoch: 5| Step: 8
Training loss: 3.2558473656609648
Validation loss: 2.5989953445191936

Epoch: 5| Step: 9
Training loss: 2.849204899487774
Validation loss: 2.5829493117797258

Epoch: 5| Step: 10
Training loss: 2.72119933544231
Validation loss: 2.581888739357879

Epoch: 205| Step: 0
Training loss: 3.4831024720075883
Validation loss: 2.577598894470955

Epoch: 5| Step: 1
Training loss: 2.6481825444206484
Validation loss: 2.5794905013651865

Epoch: 5| Step: 2
Training loss: 2.3999274282609444
Validation loss: 2.574376119829255

Epoch: 5| Step: 3
Training loss: 2.276781172974917
Validation loss: 2.5761581251731607

Epoch: 5| Step: 4
Training loss: 2.82378041096084
Validation loss: 2.5801083003448584

Epoch: 5| Step: 5
Training loss: 3.3145936791150428
Validation loss: 2.574639830950894

Epoch: 5| Step: 6
Training loss: 2.8495019444065584
Validation loss: 2.5882485295263518

Epoch: 5| Step: 7
Training loss: 2.9016753257463046
Validation loss: 2.5916890153441274

Epoch: 5| Step: 8
Training loss: 2.970330068826264
Validation loss: 2.610222783685595

Epoch: 5| Step: 9
Training loss: 3.162657776768087
Validation loss: 2.6111002261248304

Epoch: 5| Step: 10
Training loss: 3.1246067562633577
Validation loss: 2.5913043371852202

Epoch: 206| Step: 0
Training loss: 2.9066552320599572
Validation loss: 2.586339732094246

Epoch: 5| Step: 1
Training loss: 3.256012270517683
Validation loss: 2.5788338112846736

Epoch: 5| Step: 2
Training loss: 2.9960736966612145
Validation loss: 2.579776163327137

Epoch: 5| Step: 3
Training loss: 2.1070818834511664
Validation loss: 2.570784411418022

Epoch: 5| Step: 4
Training loss: 2.542753195819416
Validation loss: 2.5759214846960434

Epoch: 5| Step: 5
Training loss: 2.98041931351325
Validation loss: 2.5725870335208003

Epoch: 5| Step: 6
Training loss: 3.047654428801766
Validation loss: 2.573790250268226

Epoch: 5| Step: 7
Training loss: 2.9330569816228067
Validation loss: 2.5698549399653725

Epoch: 5| Step: 8
Training loss: 2.7522922845642013
Validation loss: 2.575893309511457

Epoch: 5| Step: 9
Training loss: 3.398688927480897
Validation loss: 2.5760761421607916

Epoch: 5| Step: 10
Training loss: 3.0123937817600672
Validation loss: 2.5795068502351626

Epoch: 207| Step: 0
Training loss: 2.6774148006044656
Validation loss: 2.5798574712863034

Epoch: 5| Step: 1
Training loss: 2.962109980280665
Validation loss: 2.588239779996478

Epoch: 5| Step: 2
Training loss: 2.55761373839377
Validation loss: 2.584029748537309

Epoch: 5| Step: 3
Training loss: 3.1594478911944175
Validation loss: 2.5876852900809117

Epoch: 5| Step: 4
Training loss: 2.7095049060270977
Validation loss: 2.5763339377046623

Epoch: 5| Step: 5
Training loss: 2.9882689631589723
Validation loss: 2.5735963844649627

Epoch: 5| Step: 6
Training loss: 3.0014554307975265
Validation loss: 2.578328165083253

Epoch: 5| Step: 7
Training loss: 3.067173253248322
Validation loss: 2.5835572349806113

Epoch: 5| Step: 8
Training loss: 2.9209905091431563
Validation loss: 2.5849845311766018

Epoch: 5| Step: 9
Training loss: 3.030561231247898
Validation loss: 2.589864900729955

Epoch: 5| Step: 10
Training loss: 2.96608606579152
Validation loss: 2.606784870470142

Epoch: 208| Step: 0
Training loss: 2.865048975234658
Validation loss: 2.6168999616988295

Epoch: 5| Step: 1
Training loss: 2.207530493520254
Validation loss: 2.6164695297366443

Epoch: 5| Step: 2
Training loss: 2.6014647136100937
Validation loss: 2.6144187969277195

Epoch: 5| Step: 3
Training loss: 2.8899467703593182
Validation loss: 2.623018876642083

Epoch: 5| Step: 4
Training loss: 2.9271952289810352
Validation loss: 2.6151624877365065

Epoch: 5| Step: 5
Training loss: 3.1093500030892995
Validation loss: 2.6058681847435814

Epoch: 5| Step: 6
Training loss: 3.083625796769834
Validation loss: 2.615812624409866

Epoch: 5| Step: 7
Training loss: 2.880465412681142
Validation loss: 2.5945020668367262

Epoch: 5| Step: 8
Training loss: 3.3173835311947264
Validation loss: 2.590443996575765

Epoch: 5| Step: 9
Training loss: 2.853219833552806
Validation loss: 2.5786485574805633

Epoch: 5| Step: 10
Training loss: 3.2363307770998486
Validation loss: 2.5747680297139492

Epoch: 209| Step: 0
Training loss: 2.8085504563009684
Validation loss: 2.5704499017304316

Epoch: 5| Step: 1
Training loss: 2.391348735487829
Validation loss: 2.5695669339188005

Epoch: 5| Step: 2
Training loss: 3.7333026447624276
Validation loss: 2.5685734091055874

Epoch: 5| Step: 3
Training loss: 2.920317862206236
Validation loss: 2.5694539226729285

Epoch: 5| Step: 4
Training loss: 2.551464042002041
Validation loss: 2.570404050106542

Epoch: 5| Step: 5
Training loss: 3.2586926339400466
Validation loss: 2.569640604557859

Epoch: 5| Step: 6
Training loss: 2.640259756978481
Validation loss: 2.5711203941606158

Epoch: 5| Step: 7
Training loss: 3.3010170034151503
Validation loss: 2.571226865306109

Epoch: 5| Step: 8
Training loss: 2.329235349767325
Validation loss: 2.5720442372670966

Epoch: 5| Step: 9
Training loss: 3.092612009078457
Validation loss: 2.5759623525969437

Epoch: 5| Step: 10
Training loss: 2.720970124276599
Validation loss: 2.580084831987525

Epoch: 210| Step: 0
Training loss: 2.756472080824862
Validation loss: 2.5796719262749455

Epoch: 5| Step: 1
Training loss: 3.2250120118383228
Validation loss: 2.5929512052127794

Epoch: 5| Step: 2
Training loss: 2.6301569464671335
Validation loss: 2.601933312551826

Epoch: 5| Step: 3
Training loss: 2.282883673151749
Validation loss: 2.626948023971556

Epoch: 5| Step: 4
Training loss: 3.444074412606428
Validation loss: 2.639476937462542

Epoch: 5| Step: 5
Training loss: 2.6222888024367204
Validation loss: 2.624233208078852

Epoch: 5| Step: 6
Training loss: 2.9430703449662774
Validation loss: 2.625604299200102

Epoch: 5| Step: 7
Training loss: 3.0404990755295254
Validation loss: 2.661267335232484

Epoch: 5| Step: 8
Training loss: 3.1542631637614207
Validation loss: 2.6429407885148253

Epoch: 5| Step: 9
Training loss: 2.6518781699998453
Validation loss: 2.6245077172582962

Epoch: 5| Step: 10
Training loss: 3.3119552452270122
Validation loss: 2.596910612047415

Epoch: 211| Step: 0
Training loss: 2.875170329480142
Validation loss: 2.5887823132683416

Epoch: 5| Step: 1
Training loss: 3.255398594700191
Validation loss: 2.5792067837671966

Epoch: 5| Step: 2
Training loss: 3.330415179515061
Validation loss: 2.577747017704939

Epoch: 5| Step: 3
Training loss: 2.5738356541094918
Validation loss: 2.578351795591179

Epoch: 5| Step: 4
Training loss: 3.016783180586068
Validation loss: 2.577407837599347

Epoch: 5| Step: 5
Training loss: 3.0453182057953057
Validation loss: 2.5729089688415145

Epoch: 5| Step: 6
Training loss: 3.376145627591626
Validation loss: 2.569479386804241

Epoch: 5| Step: 7
Training loss: 2.5943715832935204
Validation loss: 2.572327026687794

Epoch: 5| Step: 8
Training loss: 2.2156356660615755
Validation loss: 2.573035239226346

Epoch: 5| Step: 9
Training loss: 2.7347235757172053
Validation loss: 2.5733067508790772

Epoch: 5| Step: 10
Training loss: 2.8948788247583317
Validation loss: 2.5817292268124867

Epoch: 212| Step: 0
Training loss: 3.156697458709845
Validation loss: 2.583409758465104

Epoch: 5| Step: 1
Training loss: 3.0452585480766308
Validation loss: 2.5922015465887744

Epoch: 5| Step: 2
Training loss: 3.192459586297694
Validation loss: 2.606019481168036

Epoch: 5| Step: 3
Training loss: 3.076342381187286
Validation loss: 2.606312590107894

Epoch: 5| Step: 4
Training loss: 2.5174248932106282
Validation loss: 2.6123050241103063

Epoch: 5| Step: 5
Training loss: 2.743517952319559
Validation loss: 2.622391091342341

Epoch: 5| Step: 6
Training loss: 2.6504395606204554
Validation loss: 2.6252011008709193

Epoch: 5| Step: 7
Training loss: 3.1994700350603416
Validation loss: 2.6231065064893446

Epoch: 5| Step: 8
Training loss: 2.5831008519396805
Validation loss: 2.6154686563398877

Epoch: 5| Step: 9
Training loss: 3.1659684833685735
Validation loss: 2.601107650865353

Epoch: 5| Step: 10
Training loss: 2.635679772151413
Validation loss: 2.5896710760944366

Epoch: 213| Step: 0
Training loss: 2.366458793250753
Validation loss: 2.5851488974564254

Epoch: 5| Step: 1
Training loss: 3.4978797485027058
Validation loss: 2.5789820017646394

Epoch: 5| Step: 2
Training loss: 2.9588764032487314
Validation loss: 2.575989020284388

Epoch: 5| Step: 3
Training loss: 2.3254463095576416
Validation loss: 2.5710901173184975

Epoch: 5| Step: 4
Training loss: 2.94529469127988
Validation loss: 2.5717695559557576

Epoch: 5| Step: 5
Training loss: 3.3847680199158434
Validation loss: 2.5712409535779104

Epoch: 5| Step: 6
Training loss: 2.8504827257886567
Validation loss: 2.5707900058226922

Epoch: 5| Step: 7
Training loss: 2.5395137444575044
Validation loss: 2.566218695470133

Epoch: 5| Step: 8
Training loss: 2.708751137613956
Validation loss: 2.5675571740529004

Epoch: 5| Step: 9
Training loss: 3.0040316512145844
Validation loss: 2.569159909514809

Epoch: 5| Step: 10
Training loss: 3.2845937494518234
Validation loss: 2.5641974032913217

Epoch: 214| Step: 0
Training loss: 2.8689707685638806
Validation loss: 2.5711802059541147

Epoch: 5| Step: 1
Training loss: 2.6478163629398104
Validation loss: 2.566736262746562

Epoch: 5| Step: 2
Training loss: 2.8064675805376997
Validation loss: 2.5750815278179258

Epoch: 5| Step: 3
Training loss: 3.1535673921858884
Validation loss: 2.574678025792958

Epoch: 5| Step: 4
Training loss: 2.5125845785755847
Validation loss: 2.577573381255852

Epoch: 5| Step: 5
Training loss: 3.072025665593222
Validation loss: 2.5898533459017914

Epoch: 5| Step: 6
Training loss: 3.1007404919649018
Validation loss: 2.587095228425188

Epoch: 5| Step: 7
Training loss: 2.8851361924524506
Validation loss: 2.584424195085063

Epoch: 5| Step: 8
Training loss: 3.157319746875313
Validation loss: 2.575910716258488

Epoch: 5| Step: 9
Training loss: 3.2181843380950013
Validation loss: 2.568203340454948

Epoch: 5| Step: 10
Training loss: 2.3561155528760973
Validation loss: 2.5678518778875383

Epoch: 215| Step: 0
Training loss: 3.438038176976465
Validation loss: 2.5644186926813353

Epoch: 5| Step: 1
Training loss: 2.750794209322729
Validation loss: 2.56292029254778

Epoch: 5| Step: 2
Training loss: 2.5944358194749224
Validation loss: 2.564605641626436

Epoch: 5| Step: 3
Training loss: 2.4852367322134166
Validation loss: 2.5614005470647645

Epoch: 5| Step: 4
Training loss: 2.84546617975884
Validation loss: 2.5635173527860697

Epoch: 5| Step: 5
Training loss: 3.2545969803520376
Validation loss: 2.5601810654479413

Epoch: 5| Step: 6
Training loss: 3.052782952818468
Validation loss: 2.568621193716526

Epoch: 5| Step: 7
Training loss: 2.910876621463593
Validation loss: 2.558839660815678

Epoch: 5| Step: 8
Training loss: 3.302675180113375
Validation loss: 2.566510373558655

Epoch: 5| Step: 9
Training loss: 2.556309176555163
Validation loss: 2.5585481828898007

Epoch: 5| Step: 10
Training loss: 2.512673773378582
Validation loss: 2.5709570874280723

Epoch: 216| Step: 0
Training loss: 3.11634513161975
Validation loss: 2.577187452632699

Epoch: 5| Step: 1
Training loss: 2.7202956092305706
Validation loss: 2.606599482710217

Epoch: 5| Step: 2
Training loss: 2.469521317526886
Validation loss: 2.6315937553387445

Epoch: 5| Step: 3
Training loss: 2.284329152201614
Validation loss: 2.6483748475722364

Epoch: 5| Step: 4
Training loss: 2.9299353736285956
Validation loss: 2.6904684053527244

Epoch: 5| Step: 5
Training loss: 3.3966534020261907
Validation loss: 2.7284095469830416

Epoch: 5| Step: 6
Training loss: 2.9068781676323345
Validation loss: 2.696382705494439

Epoch: 5| Step: 7
Training loss: 3.146965951372318
Validation loss: 2.6499786989048983

Epoch: 5| Step: 8
Training loss: 2.7920926087003424
Validation loss: 2.577144241604705

Epoch: 5| Step: 9
Training loss: 2.9808701311171584
Validation loss: 2.5577711917176753

Epoch: 5| Step: 10
Training loss: 3.11076331654468
Validation loss: 2.565754690094075

Epoch: 217| Step: 0
Training loss: 3.278256022232285
Validation loss: 2.576480870986178

Epoch: 5| Step: 1
Training loss: 3.2527999554305254
Validation loss: 2.5783657972062684

Epoch: 5| Step: 2
Training loss: 3.01289014387232
Validation loss: 2.5828525130154305

Epoch: 5| Step: 3
Training loss: 2.9457049121049477
Validation loss: 2.5853346641924775

Epoch: 5| Step: 4
Training loss: 3.0715897793460325
Validation loss: 2.5858424756979503

Epoch: 5| Step: 5
Training loss: 2.5949976115133064
Validation loss: 2.5749238317263257

Epoch: 5| Step: 6
Training loss: 3.229452616838764
Validation loss: 2.5734604756563644

Epoch: 5| Step: 7
Training loss: 2.9112790802632973
Validation loss: 2.571767460598964

Epoch: 5| Step: 8
Training loss: 2.5253607917079686
Validation loss: 2.5691704707557097

Epoch: 5| Step: 9
Training loss: 2.759509204957667
Validation loss: 2.5690726947962714

Epoch: 5| Step: 10
Training loss: 2.7119027214101625
Validation loss: 2.564652992865177

Epoch: 218| Step: 0
Training loss: 3.0739590875686518
Validation loss: 2.561003829720824

Epoch: 5| Step: 1
Training loss: 2.9533989996172108
Validation loss: 2.5646148776331787

Epoch: 5| Step: 2
Training loss: 3.0591978058823095
Validation loss: 2.5722564657984166

Epoch: 5| Step: 3
Training loss: 2.932374581519273
Validation loss: 2.5826956348576044

Epoch: 5| Step: 4
Training loss: 2.472568407954154
Validation loss: 2.596146930082014

Epoch: 5| Step: 5
Training loss: 3.1895645038058076
Validation loss: 2.623215783387781

Epoch: 5| Step: 6
Training loss: 2.8934340566105208
Validation loss: 2.606974242480594

Epoch: 5| Step: 7
Training loss: 2.2181255912618743
Validation loss: 2.592718498232368

Epoch: 5| Step: 8
Training loss: 3.663745207560544
Validation loss: 2.5826384045992277

Epoch: 5| Step: 9
Training loss: 2.8859566597542625
Validation loss: 2.5661786204573223

Epoch: 5| Step: 10
Training loss: 2.3255100798206954
Validation loss: 2.5602869171068687

Epoch: 219| Step: 0
Training loss: 3.89354121595989
Validation loss: 2.5608341896266036

Epoch: 5| Step: 1
Training loss: 3.2376577331530734
Validation loss: 2.555797781067805

Epoch: 5| Step: 2
Training loss: 2.9034589265388524
Validation loss: 2.5583138777555

Epoch: 5| Step: 3
Training loss: 2.6042981127307883
Validation loss: 2.5526275422854305

Epoch: 5| Step: 4
Training loss: 2.9521258243220925
Validation loss: 2.5548007158898103

Epoch: 5| Step: 5
Training loss: 2.287667744640682
Validation loss: 2.553200591991553

Epoch: 5| Step: 6
Training loss: 2.967431347767112
Validation loss: 2.5590379549957647

Epoch: 5| Step: 7
Training loss: 2.617613982567131
Validation loss: 2.5571394465009067

Epoch: 5| Step: 8
Training loss: 2.609963173734356
Validation loss: 2.554622066648657

Epoch: 5| Step: 9
Training loss: 2.6475894436662823
Validation loss: 2.554510529849747

Epoch: 5| Step: 10
Training loss: 2.9003560998576443
Validation loss: 2.566265116367857

Epoch: 220| Step: 0
Training loss: 3.116096477743582
Validation loss: 2.574788151297939

Epoch: 5| Step: 1
Training loss: 2.430191625566819
Validation loss: 2.5959239911953604

Epoch: 5| Step: 2
Training loss: 3.1899089312334588
Validation loss: 2.6081955879615104

Epoch: 5| Step: 3
Training loss: 2.3807314931496086
Validation loss: 2.6120502232139344

Epoch: 5| Step: 4
Training loss: 2.702628382227996
Validation loss: 2.6214145094725003

Epoch: 5| Step: 5
Training loss: 2.903053905326921
Validation loss: 2.622920568734138

Epoch: 5| Step: 6
Training loss: 2.51728888981725
Validation loss: 2.6104948988270897

Epoch: 5| Step: 7
Training loss: 2.8121183348347505
Validation loss: 2.584038605084238

Epoch: 5| Step: 8
Training loss: 3.4306063800569855
Validation loss: 2.566300697695195

Epoch: 5| Step: 9
Training loss: 3.5696187420026857
Validation loss: 2.5560741757326366

Epoch: 5| Step: 10
Training loss: 2.569987360555835
Validation loss: 2.550947269388233

Epoch: 221| Step: 0
Training loss: 2.72617982293941
Validation loss: 2.5471506398043338

Epoch: 5| Step: 1
Training loss: 3.036817648268168
Validation loss: 2.5491692332026306

Epoch: 5| Step: 2
Training loss: 2.8798914223972685
Validation loss: 2.5456428559557134

Epoch: 5| Step: 3
Training loss: 2.8768281514565124
Validation loss: 2.545605277867135

Epoch: 5| Step: 4
Training loss: 3.093330586064971
Validation loss: 2.5466156437490466

Epoch: 5| Step: 5
Training loss: 2.9268379696856224
Validation loss: 2.541749187994505

Epoch: 5| Step: 6
Training loss: 3.1464446696943904
Validation loss: 2.543034701954457

Epoch: 5| Step: 7
Training loss: 2.7781611231031276
Validation loss: 2.5444575042784705

Epoch: 5| Step: 8
Training loss: 2.2934121738048523
Validation loss: 2.559907264338863

Epoch: 5| Step: 9
Training loss: 2.9897143150284173
Validation loss: 2.551823864810522

Epoch: 5| Step: 10
Training loss: 3.0279880551766514
Validation loss: 2.5527312055143896

Epoch: 222| Step: 0
Training loss: 2.8456287256489174
Validation loss: 2.5562276992529123

Epoch: 5| Step: 1
Training loss: 3.158572409513148
Validation loss: 2.5641474506532993

Epoch: 5| Step: 2
Training loss: 2.429245396467501
Validation loss: 2.5685403290424493

Epoch: 5| Step: 3
Training loss: 2.907754652133566
Validation loss: 2.558544667905175

Epoch: 5| Step: 4
Training loss: 3.1435929124539896
Validation loss: 2.565383573266348

Epoch: 5| Step: 5
Training loss: 2.51769451052862
Validation loss: 2.5636033254788395

Epoch: 5| Step: 6
Training loss: 2.8256195098006844
Validation loss: 2.5696548845969476

Epoch: 5| Step: 7
Training loss: 2.493594164269539
Validation loss: 2.5800873875935917

Epoch: 5| Step: 8
Training loss: 2.8554849480666595
Validation loss: 2.5687824294027255

Epoch: 5| Step: 9
Training loss: 3.3816065235408024
Validation loss: 2.5849721036136364

Epoch: 5| Step: 10
Training loss: 3.015280906534663
Validation loss: 2.564888072256461

Epoch: 223| Step: 0
Training loss: 2.7698640394756158
Validation loss: 2.5760099145570083

Epoch: 5| Step: 1
Training loss: 3.2551267242374338
Validation loss: 2.5613401400699374

Epoch: 5| Step: 2
Training loss: 2.707895468504493
Validation loss: 2.55006772360969

Epoch: 5| Step: 3
Training loss: 2.2840262463826986
Validation loss: 2.5429724377333414

Epoch: 5| Step: 4
Training loss: 2.7264319445988474
Validation loss: 2.537796651538727

Epoch: 5| Step: 5
Training loss: 3.374333351133998
Validation loss: 2.5346156276896816

Epoch: 5| Step: 6
Training loss: 2.766751162452829
Validation loss: 2.535719104033596

Epoch: 5| Step: 7
Training loss: 2.954755544862387
Validation loss: 2.531702558967318

Epoch: 5| Step: 8
Training loss: 2.8608766375348784
Validation loss: 2.5411724018155657

Epoch: 5| Step: 9
Training loss: 2.749766946800901
Validation loss: 2.5373013283496832

Epoch: 5| Step: 10
Training loss: 3.1453580349896457
Validation loss: 2.538350400055763

Epoch: 224| Step: 0
Training loss: 2.4281368888652293
Validation loss: 2.5522915167378764

Epoch: 5| Step: 1
Training loss: 2.8170346473022945
Validation loss: 2.5557010412899976

Epoch: 5| Step: 2
Training loss: 2.8363334442412422
Validation loss: 2.5589932062647396

Epoch: 5| Step: 3
Training loss: 3.04819839298448
Validation loss: 2.572265027011773

Epoch: 5| Step: 4
Training loss: 2.804592035310588
Validation loss: 2.5910869596441097

Epoch: 5| Step: 5
Training loss: 2.327749132371097
Validation loss: 2.5944812108192763

Epoch: 5| Step: 6
Training loss: 3.3685175488164774
Validation loss: 2.5879263151512877

Epoch: 5| Step: 7
Training loss: 3.1752252033293495
Validation loss: 2.5838862448326685

Epoch: 5| Step: 8
Training loss: 2.98324691462599
Validation loss: 2.5627489806879815

Epoch: 5| Step: 9
Training loss: 2.4911420297457396
Validation loss: 2.566182022087477

Epoch: 5| Step: 10
Training loss: 3.2103513010851934
Validation loss: 2.548547762759057

Epoch: 225| Step: 0
Training loss: 3.149467508025197
Validation loss: 2.5538727802537307

Epoch: 5| Step: 1
Training loss: 3.168666174868976
Validation loss: 2.553527678135108

Epoch: 5| Step: 2
Training loss: 2.994660712433509
Validation loss: 2.545321817032968

Epoch: 5| Step: 3
Training loss: 2.8239193832842635
Validation loss: 2.5488115129631583

Epoch: 5| Step: 4
Training loss: 2.8473265238526926
Validation loss: 2.553415587513575

Epoch: 5| Step: 5
Training loss: 2.629297099880673
Validation loss: 2.560974982387899

Epoch: 5| Step: 6
Training loss: 2.4869245965905757
Validation loss: 2.5610335651324214

Epoch: 5| Step: 7
Training loss: 2.8806630626968737
Validation loss: 2.5664340498592275

Epoch: 5| Step: 8
Training loss: 2.7449968081596454
Validation loss: 2.587106225787399

Epoch: 5| Step: 9
Training loss: 2.6167208582941996
Validation loss: 2.577139747274002

Epoch: 5| Step: 10
Training loss: 3.251904296508417
Validation loss: 2.5750955412411933

Epoch: 226| Step: 0
Training loss: 2.5244101902472718
Validation loss: 2.579256302615862

Epoch: 5| Step: 1
Training loss: 3.0468034784774685
Validation loss: 2.5653195814736742

Epoch: 5| Step: 2
Training loss: 2.8243475709188095
Validation loss: 2.560775141305721

Epoch: 5| Step: 3
Training loss: 3.1527671104246955
Validation loss: 2.550959375299707

Epoch: 5| Step: 4
Training loss: 2.9316266368961754
Validation loss: 2.5517375937033977

Epoch: 5| Step: 5
Training loss: 2.8183072641145674
Validation loss: 2.5469705269450493

Epoch: 5| Step: 6
Training loss: 2.54345529709638
Validation loss: 2.5443999711255865

Epoch: 5| Step: 7
Training loss: 3.034541122964942
Validation loss: 2.538360085584912

Epoch: 5| Step: 8
Training loss: 2.32341089393759
Validation loss: 2.5485280757806925

Epoch: 5| Step: 9
Training loss: 2.8311005003407748
Validation loss: 2.5460143873323453

Epoch: 5| Step: 10
Training loss: 3.513420532804468
Validation loss: 2.5509531163315637

Epoch: 227| Step: 0
Training loss: 2.5881520725834237
Validation loss: 2.5604915726655424

Epoch: 5| Step: 1
Training loss: 2.516486642306003
Validation loss: 2.5584438865926

Epoch: 5| Step: 2
Training loss: 2.770904157684675
Validation loss: 2.5500169432557946

Epoch: 5| Step: 3
Training loss: 3.097275853702447
Validation loss: 2.5517733424363285

Epoch: 5| Step: 4
Training loss: 3.0673015089411946
Validation loss: 2.542165393270479

Epoch: 5| Step: 5
Training loss: 2.6392915507734513
Validation loss: 2.5491380409367768

Epoch: 5| Step: 6
Training loss: 3.2720625363648423
Validation loss: 2.5498590060814967

Epoch: 5| Step: 7
Training loss: 2.954002936111882
Validation loss: 2.5614783078321675

Epoch: 5| Step: 8
Training loss: 3.128592448030197
Validation loss: 2.5584255473515785

Epoch: 5| Step: 9
Training loss: 2.3789301027001013
Validation loss: 2.569454309795065

Epoch: 5| Step: 10
Training loss: 2.9759615394096426
Validation loss: 2.601696743726225

Epoch: 228| Step: 0
Training loss: 2.8080403893003205
Validation loss: 2.6073662218274465

Epoch: 5| Step: 1
Training loss: 3.1264638905223636
Validation loss: 2.5893251650350964

Epoch: 5| Step: 2
Training loss: 3.0746666704339423
Validation loss: 2.5790129056430446

Epoch: 5| Step: 3
Training loss: 2.7846573948680318
Validation loss: 2.5804380579235837

Epoch: 5| Step: 4
Training loss: 2.888989785054529
Validation loss: 2.553151955465207

Epoch: 5| Step: 5
Training loss: 2.428556221826211
Validation loss: 2.5478660617577225

Epoch: 5| Step: 6
Training loss: 2.840395615383901
Validation loss: 2.5401057869147863

Epoch: 5| Step: 7
Training loss: 3.3398181936613596
Validation loss: 2.536046172388962

Epoch: 5| Step: 8
Training loss: 2.902524796149163
Validation loss: 2.5370166163574996

Epoch: 5| Step: 9
Training loss: 2.6819505394365284
Validation loss: 2.5390234503255567

Epoch: 5| Step: 10
Training loss: 2.558434587726028
Validation loss: 2.538149966954196

Epoch: 229| Step: 0
Training loss: 2.8343106061692764
Validation loss: 2.5424279008178536

Epoch: 5| Step: 1
Training loss: 2.7770037865508175
Validation loss: 2.551568988320353

Epoch: 5| Step: 2
Training loss: 2.48183786649262
Validation loss: 2.5563375319887696

Epoch: 5| Step: 3
Training loss: 2.8206592462896327
Validation loss: 2.5509192796497113

Epoch: 5| Step: 4
Training loss: 3.2199116804911863
Validation loss: 2.5484013113754975

Epoch: 5| Step: 5
Training loss: 3.0717945356104708
Validation loss: 2.552672813364848

Epoch: 5| Step: 6
Training loss: 2.777777572207973
Validation loss: 2.549441186919763

Epoch: 5| Step: 7
Training loss: 2.8702047411896694
Validation loss: 2.5560508598108083

Epoch: 5| Step: 8
Training loss: 2.980215319336738
Validation loss: 2.5750913051654045

Epoch: 5| Step: 9
Training loss: 3.064587407181809
Validation loss: 2.56383814714185

Epoch: 5| Step: 10
Training loss: 2.432861805871284
Validation loss: 2.550974308122659

Epoch: 230| Step: 0
Training loss: 2.89681393786356
Validation loss: 2.5625193905540686

Epoch: 5| Step: 1
Training loss: 3.0633162364406514
Validation loss: 2.563138410556644

Epoch: 5| Step: 2
Training loss: 2.424504089773689
Validation loss: 2.5595635777983876

Epoch: 5| Step: 3
Training loss: 2.773124053865503
Validation loss: 2.5528442350134255

Epoch: 5| Step: 4
Training loss: 2.535991983539414
Validation loss: 2.5453899560232096

Epoch: 5| Step: 5
Training loss: 2.81553249058973
Validation loss: 2.544574074899247

Epoch: 5| Step: 6
Training loss: 2.5479284810758984
Validation loss: 2.5543214615332097

Epoch: 5| Step: 7
Training loss: 2.8133319895712487
Validation loss: 2.558358239547044

Epoch: 5| Step: 8
Training loss: 3.448672777384957
Validation loss: 2.546714780191716

Epoch: 5| Step: 9
Training loss: 2.872007720171825
Validation loss: 2.536113173700777

Epoch: 5| Step: 10
Training loss: 3.2397882983427504
Validation loss: 2.5512117100760845

Epoch: 231| Step: 0
Training loss: 2.9746597095421254
Validation loss: 2.5392804593545297

Epoch: 5| Step: 1
Training loss: 2.73170585058045
Validation loss: 2.531166742723679

Epoch: 5| Step: 2
Training loss: 2.9509648894881315
Validation loss: 2.5326833369829527

Epoch: 5| Step: 3
Training loss: 2.5284511021055014
Validation loss: 2.5360754918090844

Epoch: 5| Step: 4
Training loss: 3.089531382361677
Validation loss: 2.55349508334916

Epoch: 5| Step: 5
Training loss: 2.9757790322870115
Validation loss: 2.5359341825084774

Epoch: 5| Step: 6
Training loss: 2.647066644893884
Validation loss: 2.5542240064185875

Epoch: 5| Step: 7
Training loss: 2.8609471402716813
Validation loss: 2.540651540979972

Epoch: 5| Step: 8
Training loss: 3.039399822117275
Validation loss: 2.540704167359631

Epoch: 5| Step: 9
Training loss: 2.3310377090788257
Validation loss: 2.549747281035029

Epoch: 5| Step: 10
Training loss: 3.286590009289287
Validation loss: 2.5566198943111185

Epoch: 232| Step: 0
Training loss: 2.772203713658719
Validation loss: 2.5743530403727446

Epoch: 5| Step: 1
Training loss: 2.8949568997931827
Validation loss: 2.5778726403907184

Epoch: 5| Step: 2
Training loss: 2.6414897337986054
Validation loss: 2.585950115249794

Epoch: 5| Step: 3
Training loss: 2.947596466323654
Validation loss: 2.558498486690876

Epoch: 5| Step: 4
Training loss: 3.0508850314454095
Validation loss: 2.556788009195383

Epoch: 5| Step: 5
Training loss: 3.4921027051628597
Validation loss: 2.5325209529684396

Epoch: 5| Step: 6
Training loss: 3.1530630810709908
Validation loss: 2.5256777854055743

Epoch: 5| Step: 7
Training loss: 2.5461604514314478
Validation loss: 2.525007504135575

Epoch: 5| Step: 8
Training loss: 2.363708961812419
Validation loss: 2.5349825198125906

Epoch: 5| Step: 9
Training loss: 3.0997095218048853
Validation loss: 2.529752285446915

Epoch: 5| Step: 10
Training loss: 2.319037501358859
Validation loss: 2.5469324852964568

Epoch: 233| Step: 0
Training loss: 2.6859563785797147
Validation loss: 2.545843540989739

Epoch: 5| Step: 1
Training loss: 2.766344741874374
Validation loss: 2.5539687892646783

Epoch: 5| Step: 2
Training loss: 3.3884623438012245
Validation loss: 2.555544023196484

Epoch: 5| Step: 3
Training loss: 3.3625236482036827
Validation loss: 2.5574545802863495

Epoch: 5| Step: 4
Training loss: 2.8424543845778354
Validation loss: 2.550284471997339

Epoch: 5| Step: 5
Training loss: 2.7406524100069323
Validation loss: 2.5619517374366643

Epoch: 5| Step: 6
Training loss: 2.7810550578516504
Validation loss: 2.5715192573961705

Epoch: 5| Step: 7
Training loss: 2.5597927400016465
Validation loss: 2.5617174633951474

Epoch: 5| Step: 8
Training loss: 2.7652203969740916
Validation loss: 2.5721543489567837

Epoch: 5| Step: 9
Training loss: 2.679306937461741
Validation loss: 2.5584782790788183

Epoch: 5| Step: 10
Training loss: 2.7161267658757913
Validation loss: 2.5542603426293247

Epoch: 234| Step: 0
Training loss: 2.65648317996501
Validation loss: 2.5623937765375433

Epoch: 5| Step: 1
Training loss: 2.9940351951635322
Validation loss: 2.560956084168025

Epoch: 5| Step: 2
Training loss: 3.128906707192148
Validation loss: 2.5742256764108316

Epoch: 5| Step: 3
Training loss: 2.736878213856603
Validation loss: 2.5730933416483706

Epoch: 5| Step: 4
Training loss: 1.9591028514265532
Validation loss: 2.55929149465565

Epoch: 5| Step: 5
Training loss: 3.140583398647822
Validation loss: 2.571761846390044

Epoch: 5| Step: 6
Training loss: 3.143252511979421
Validation loss: 2.5610232005713267

Epoch: 5| Step: 7
Training loss: 3.226516243000369
Validation loss: 2.544725493573432

Epoch: 5| Step: 8
Training loss: 2.7846451513755914
Validation loss: 2.544050000635373

Epoch: 5| Step: 9
Training loss: 2.6155180659704818
Validation loss: 2.5447287234018288

Epoch: 5| Step: 10
Training loss: 2.739895898275376
Validation loss: 2.5337642901660242

Epoch: 235| Step: 0
Training loss: 3.173513806551201
Validation loss: 2.5475104690660766

Epoch: 5| Step: 1
Training loss: 2.6962801315894738
Validation loss: 2.554530848130405

Epoch: 5| Step: 2
Training loss: 2.98188861908578
Validation loss: 2.556903463204875

Epoch: 5| Step: 3
Training loss: 3.044313890050963
Validation loss: 2.5710401804397907

Epoch: 5| Step: 4
Training loss: 2.8786405650385647
Validation loss: 2.580075837168045

Epoch: 5| Step: 5
Training loss: 2.8867355986272516
Validation loss: 2.549370122323439

Epoch: 5| Step: 6
Training loss: 2.8037928267331877
Validation loss: 2.5290001163021287

Epoch: 5| Step: 7
Training loss: 2.461352697799791
Validation loss: 2.5326364645453108

Epoch: 5| Step: 8
Training loss: 2.849698395413841
Validation loss: 2.5241983528252674

Epoch: 5| Step: 9
Training loss: 2.725212309379779
Validation loss: 2.5265622197060718

Epoch: 5| Step: 10
Training loss: 2.9629524239599916
Validation loss: 2.52111262909311

Epoch: 236| Step: 0
Training loss: 2.5235725106890277
Validation loss: 2.535387730508953

Epoch: 5| Step: 1
Training loss: 3.0595171668401298
Validation loss: 2.5359159716303936

Epoch: 5| Step: 2
Training loss: 3.079800377358877
Validation loss: 2.531517655757619

Epoch: 5| Step: 3
Training loss: 2.4136737399349486
Validation loss: 2.551645171921011

Epoch: 5| Step: 4
Training loss: 3.4320691296566546
Validation loss: 2.562155570616393

Epoch: 5| Step: 5
Training loss: 2.81248168939352
Validation loss: 2.5699250769927184

Epoch: 5| Step: 6
Training loss: 2.540971619256489
Validation loss: 2.592512048556516

Epoch: 5| Step: 7
Training loss: 2.7164594274784366
Validation loss: 2.582905540083111

Epoch: 5| Step: 8
Training loss: 2.7798646198214243
Validation loss: 2.5999665143386395

Epoch: 5| Step: 9
Training loss: 2.8372060077297614
Validation loss: 2.6477898435521263

Epoch: 5| Step: 10
Training loss: 3.098435985662924
Validation loss: 2.6166831291981434

Epoch: 237| Step: 0
Training loss: 3.5200994204439127
Validation loss: 2.584323186972879

Epoch: 5| Step: 1
Training loss: 2.6055662946156652
Validation loss: 2.5389783094660956

Epoch: 5| Step: 2
Training loss: 3.043875288685673
Validation loss: 2.5229615560441636

Epoch: 5| Step: 3
Training loss: 2.6841040158078413
Validation loss: 2.527298606444909

Epoch: 5| Step: 4
Training loss: 2.6024188674167763
Validation loss: 2.540514388414447

Epoch: 5| Step: 5
Training loss: 2.9248421846511214
Validation loss: 2.544246715327601

Epoch: 5| Step: 6
Training loss: 3.0899099543021964
Validation loss: 2.5779130467570734

Epoch: 5| Step: 7
Training loss: 2.7240508570131796
Validation loss: 2.576383187382661

Epoch: 5| Step: 8
Training loss: 3.4267624044836005
Validation loss: 2.620724733381353

Epoch: 5| Step: 9
Training loss: 2.831483480161114
Validation loss: 2.6340027631418015

Epoch: 5| Step: 10
Training loss: 3.0553105882262352
Validation loss: 2.634019008224948

Epoch: 238| Step: 0
Training loss: 2.6422388686516727
Validation loss: 2.6337769742403254

Epoch: 5| Step: 1
Training loss: 2.7824162813189597
Validation loss: 2.592920593024725

Epoch: 5| Step: 2
Training loss: 2.988700089366969
Validation loss: 2.5614799532194574

Epoch: 5| Step: 3
Training loss: 3.1782202182185495
Validation loss: 2.536078778142765

Epoch: 5| Step: 4
Training loss: 2.7975699983759097
Validation loss: 2.5423437637486135

Epoch: 5| Step: 5
Training loss: 2.773124569713808
Validation loss: 2.5513404339174337

Epoch: 5| Step: 6
Training loss: 2.91954445329375
Validation loss: 2.5914267107572835

Epoch: 5| Step: 7
Training loss: 3.2441088762745074
Validation loss: 2.648211092813203

Epoch: 5| Step: 8
Training loss: 3.119076875669378
Validation loss: 2.6571475110609395

Epoch: 5| Step: 9
Training loss: 2.9378872879875675
Validation loss: 2.61841166161329

Epoch: 5| Step: 10
Training loss: 2.7457877757837648
Validation loss: 2.5815387288543974

Epoch: 239| Step: 0
Training loss: 2.93811109963549
Validation loss: 2.563064204945585

Epoch: 5| Step: 1
Training loss: 2.8687073216141306
Validation loss: 2.5293670065567295

Epoch: 5| Step: 2
Training loss: 2.915889709166056
Validation loss: 2.5300169670668993

Epoch: 5| Step: 3
Training loss: 3.1997251750234286
Validation loss: 2.5398399315122053

Epoch: 5| Step: 4
Training loss: 2.475517846850817
Validation loss: 2.526431639778498

Epoch: 5| Step: 5
Training loss: 3.3357480998176423
Validation loss: 2.5306091955898857

Epoch: 5| Step: 6
Training loss: 3.0990048872498943
Validation loss: 2.528905730197217

Epoch: 5| Step: 7
Training loss: 2.6705168903090244
Validation loss: 2.528460577146103

Epoch: 5| Step: 8
Training loss: 2.8839158838626537
Validation loss: 2.5234453693961707

Epoch: 5| Step: 9
Training loss: 2.5820814811679793
Validation loss: 2.521795114945372

Epoch: 5| Step: 10
Training loss: 2.471986797519723
Validation loss: 2.5318767673527587

Epoch: 240| Step: 0
Training loss: 3.12489288146488
Validation loss: 2.5429499735273775

Epoch: 5| Step: 1
Training loss: 2.9693050467975666
Validation loss: 2.5435816619409777

Epoch: 5| Step: 2
Training loss: 2.6337604570656454
Validation loss: 2.5511619041253386

Epoch: 5| Step: 3
Training loss: 3.123857670852131
Validation loss: 2.559222644929595

Epoch: 5| Step: 4
Training loss: 3.2339412379921395
Validation loss: 2.590023027327893

Epoch: 5| Step: 5
Training loss: 2.748527566150805
Validation loss: 2.5826090827202983

Epoch: 5| Step: 6
Training loss: 2.908236573221015
Validation loss: 2.580926569565857

Epoch: 5| Step: 7
Training loss: 3.0068405364429753
Validation loss: 2.5908229366771725

Epoch: 5| Step: 8
Training loss: 2.49963481143171
Validation loss: 2.576944821266234

Epoch: 5| Step: 9
Training loss: 2.6682427239109288
Validation loss: 2.539317464719104

Epoch: 5| Step: 10
Training loss: 2.5164740415038063
Validation loss: 2.534488477468064

Epoch: 241| Step: 0
Training loss: 2.9888837219470936
Validation loss: 2.5272400466354368

Epoch: 5| Step: 1
Training loss: 2.9109452579740958
Validation loss: 2.5216986149899543

Epoch: 5| Step: 2
Training loss: 2.5638117340407387
Validation loss: 2.519672697814995

Epoch: 5| Step: 3
Training loss: 3.080648868876183
Validation loss: 2.5220519787869207

Epoch: 5| Step: 4
Training loss: 2.685679151571905
Validation loss: 2.5195785188609006

Epoch: 5| Step: 5
Training loss: 2.6010556572133146
Validation loss: 2.522656803203895

Epoch: 5| Step: 6
Training loss: 3.252994478302522
Validation loss: 2.5184048520113396

Epoch: 5| Step: 7
Training loss: 2.8497475897126825
Validation loss: 2.5240703705904943

Epoch: 5| Step: 8
Training loss: 2.6199862418650706
Validation loss: 2.5237556169886384

Epoch: 5| Step: 9
Training loss: 2.5676701190160487
Validation loss: 2.5482614280356293

Epoch: 5| Step: 10
Training loss: 3.239008142040038
Validation loss: 2.5488364440533267

Epoch: 242| Step: 0
Training loss: 3.123918880371668
Validation loss: 2.5555501615756575

Epoch: 5| Step: 1
Training loss: 2.5484466384171873
Validation loss: 2.5490050229992725

Epoch: 5| Step: 2
Training loss: 2.865675691345542
Validation loss: 2.5543789699388735

Epoch: 5| Step: 3
Training loss: 2.445629647745522
Validation loss: 2.546795096201834

Epoch: 5| Step: 4
Training loss: 2.6042039995696404
Validation loss: 2.5517968953564445

Epoch: 5| Step: 5
Training loss: 2.4305590081568824
Validation loss: 2.5682820661321357

Epoch: 5| Step: 6
Training loss: 2.834521568066898
Validation loss: 2.5615600124447337

Epoch: 5| Step: 7
Training loss: 3.2989103714676835
Validation loss: 2.5625794101018933

Epoch: 5| Step: 8
Training loss: 2.7879802409912653
Validation loss: 2.5409052323702657

Epoch: 5| Step: 9
Training loss: 3.217684671338234
Validation loss: 2.5375662697148633

Epoch: 5| Step: 10
Training loss: 3.2060307418482097
Validation loss: 2.5171858548289947

Epoch: 243| Step: 0
Training loss: 2.98754650383033
Validation loss: 2.5151542111453224

Epoch: 5| Step: 1
Training loss: 3.1914531652954605
Validation loss: 2.508066624446421

Epoch: 5| Step: 2
Training loss: 3.046197904032538
Validation loss: 2.516390054918855

Epoch: 5| Step: 3
Training loss: 3.0401355251420075
Validation loss: 2.5159456953969643

Epoch: 5| Step: 4
Training loss: 3.025680931943868
Validation loss: 2.516373181875476

Epoch: 5| Step: 5
Training loss: 2.7997456741633404
Validation loss: 2.5110921324183546

Epoch: 5| Step: 6
Training loss: 2.691620528905357
Validation loss: 2.510418267228914

Epoch: 5| Step: 7
Training loss: 2.6822040629972737
Validation loss: 2.509780470945145

Epoch: 5| Step: 8
Training loss: 2.1809041445873816
Validation loss: 2.5210797067356565

Epoch: 5| Step: 9
Training loss: 2.7684500538263292
Validation loss: 2.5215931880012783

Epoch: 5| Step: 10
Training loss: 2.768800625650401
Validation loss: 2.5435966703288146

Epoch: 244| Step: 0
Training loss: 2.8392398827102063
Validation loss: 2.5612961817468487

Epoch: 5| Step: 1
Training loss: 2.5886063647611874
Validation loss: 2.6165422638738645

Epoch: 5| Step: 2
Training loss: 2.7333996586389735
Validation loss: 2.6608725757817187

Epoch: 5| Step: 3
Training loss: 3.27191257692053
Validation loss: 2.6443136409867845

Epoch: 5| Step: 4
Training loss: 2.4171332424118175
Validation loss: 2.594215885945337

Epoch: 5| Step: 5
Training loss: 3.300141077204968
Validation loss: 2.571132239572702

Epoch: 5| Step: 6
Training loss: 2.8546654110008496
Validation loss: 2.5439144915307845

Epoch: 5| Step: 7
Training loss: 2.7666200044059712
Validation loss: 2.521790915393941

Epoch: 5| Step: 8
Training loss: 2.5369005594519
Validation loss: 2.5226099670260083

Epoch: 5| Step: 9
Training loss: 2.3867161527578955
Validation loss: 2.5220841520151884

Epoch: 5| Step: 10
Training loss: 3.5584813256201864
Validation loss: 2.520274864607314

Epoch: 245| Step: 0
Training loss: 2.8891937836712325
Validation loss: 2.512109942037859

Epoch: 5| Step: 1
Training loss: 2.5430302531925064
Validation loss: 2.512488852357671

Epoch: 5| Step: 2
Training loss: 2.909401610157493
Validation loss: 2.5120458468861493

Epoch: 5| Step: 3
Training loss: 2.8794698383535455
Validation loss: 2.5166137174976946

Epoch: 5| Step: 4
Training loss: 2.954466499927582
Validation loss: 2.522446131630926

Epoch: 5| Step: 5
Training loss: 2.95657841025671
Validation loss: 2.5261756251676433

Epoch: 5| Step: 6
Training loss: 2.3805437136928895
Validation loss: 2.539420566852711

Epoch: 5| Step: 7
Training loss: 2.6710824962288524
Validation loss: 2.533324522449454

Epoch: 5| Step: 8
Training loss: 2.986197828665045
Validation loss: 2.5384776269885396

Epoch: 5| Step: 9
Training loss: 3.348612449586308
Validation loss: 2.548073437392457

Epoch: 5| Step: 10
Training loss: 2.653128910848119
Validation loss: 2.5595157252500087

Epoch: 246| Step: 0
Training loss: 3.1601268262401057
Validation loss: 2.5457775600935233

Epoch: 5| Step: 1
Training loss: 2.6129285178029553
Validation loss: 2.5372412938413618

Epoch: 5| Step: 2
Training loss: 2.8643130828071732
Validation loss: 2.523566291479061

Epoch: 5| Step: 3
Training loss: 2.6569099952692086
Validation loss: 2.5152648553846455

Epoch: 5| Step: 4
Training loss: 2.97509473120907
Validation loss: 2.5220889746858974

Epoch: 5| Step: 5
Training loss: 2.767789952389909
Validation loss: 2.5202174650104805

Epoch: 5| Step: 6
Training loss: 3.0658535404546896
Validation loss: 2.516996874419717

Epoch: 5| Step: 7
Training loss: 2.9688646796312415
Validation loss: 2.530241587253611

Epoch: 5| Step: 8
Training loss: 2.4865432969785632
Validation loss: 2.53103524363905

Epoch: 5| Step: 9
Training loss: 2.975539624937015
Validation loss: 2.537795912084202

Epoch: 5| Step: 10
Training loss: 2.5540012756201085
Validation loss: 2.5402862865917344

Epoch: 247| Step: 0
Training loss: 2.881915855010574
Validation loss: 2.5390779167571793

Epoch: 5| Step: 1
Training loss: 2.8720943861091555
Validation loss: 2.5391524932032925

Epoch: 5| Step: 2
Training loss: 2.6399876654943677
Validation loss: 2.5507814590485927

Epoch: 5| Step: 3
Training loss: 2.5347000910752295
Validation loss: 2.5580300302605172

Epoch: 5| Step: 4
Training loss: 3.058645352723619
Validation loss: 2.5520564151739773

Epoch: 5| Step: 5
Training loss: 2.5772370630010446
Validation loss: 2.566060671512571

Epoch: 5| Step: 6
Training loss: 2.54014850572803
Validation loss: 2.538543778434097

Epoch: 5| Step: 7
Training loss: 3.0221031063422985
Validation loss: 2.545377358308528

Epoch: 5| Step: 8
Training loss: 2.834131932377113
Validation loss: 2.53542163392134

Epoch: 5| Step: 9
Training loss: 3.0027469138991156
Validation loss: 2.532774050794625

Epoch: 5| Step: 10
Training loss: 3.133074742326365
Validation loss: 2.5307583095241113

Epoch: 248| Step: 0
Training loss: 2.6155178836596877
Validation loss: 2.5359152387040074

Epoch: 5| Step: 1
Training loss: 3.063245254456887
Validation loss: 2.529606815374359

Epoch: 5| Step: 2
Training loss: 2.5056796407129833
Validation loss: 2.536185747950012

Epoch: 5| Step: 3
Training loss: 3.0810091864706766
Validation loss: 2.53892803735344

Epoch: 5| Step: 4
Training loss: 3.1233281050088357
Validation loss: 2.5362014161986624

Epoch: 5| Step: 5
Training loss: 2.224361147943268
Validation loss: 2.5230566522382447

Epoch: 5| Step: 6
Training loss: 2.842603347496574
Validation loss: 2.5223130781752836

Epoch: 5| Step: 7
Training loss: 2.797883432682795
Validation loss: 2.5388547306544336

Epoch: 5| Step: 8
Training loss: 2.990337387493264
Validation loss: 2.533939846061377

Epoch: 5| Step: 9
Training loss: 3.02919125203716
Validation loss: 2.546265710982809

Epoch: 5| Step: 10
Training loss: 2.7506559629979397
Validation loss: 2.56734892973517

Epoch: 249| Step: 0
Training loss: 2.936171535646915
Validation loss: 2.5718392579934832

Epoch: 5| Step: 1
Training loss: 2.470900456083428
Validation loss: 2.584078236445373

Epoch: 5| Step: 2
Training loss: 2.9029402395858814
Validation loss: 2.5718286379348467

Epoch: 5| Step: 3
Training loss: 2.5709617281794905
Validation loss: 2.5747946012434335

Epoch: 5| Step: 4
Training loss: 2.6566418527029034
Validation loss: 2.561710815399386

Epoch: 5| Step: 5
Training loss: 2.7586701440077865
Validation loss: 2.5366368765444958

Epoch: 5| Step: 6
Training loss: 3.289985581572224
Validation loss: 2.5331019275083175

Epoch: 5| Step: 7
Training loss: 2.9364922600814167
Validation loss: 2.5416280063356442

Epoch: 5| Step: 8
Training loss: 3.2897357025195264
Validation loss: 2.5414616949126545

Epoch: 5| Step: 9
Training loss: 2.814783652683377
Validation loss: 2.538523012056752

Epoch: 5| Step: 10
Training loss: 2.3165702054183637
Validation loss: 2.5469395885812283

Epoch: 250| Step: 0
Training loss: 2.084849556085232
Validation loss: 2.5426212130835286

Epoch: 5| Step: 1
Training loss: 2.8248564658371205
Validation loss: 2.537100584006443

Epoch: 5| Step: 2
Training loss: 3.0744814924054356
Validation loss: 2.557302767467588

Epoch: 5| Step: 3
Training loss: 2.9438268825590845
Validation loss: 2.5608436629796847

Epoch: 5| Step: 4
Training loss: 2.5998767053273992
Validation loss: 2.575713670783692

Epoch: 5| Step: 5
Training loss: 2.601098096482644
Validation loss: 2.5665795991329383

Epoch: 5| Step: 6
Training loss: 3.2935279380455427
Validation loss: 2.579298778534345

Epoch: 5| Step: 7
Training loss: 2.9609130214192643
Validation loss: 2.545567376951878

Epoch: 5| Step: 8
Training loss: 2.5584612397103257
Validation loss: 2.5399559499964437

Epoch: 5| Step: 9
Training loss: 2.9732570767852082
Validation loss: 2.532440269290676

Epoch: 5| Step: 10
Training loss: 2.993942821560628
Validation loss: 2.515917130811475

Epoch: 251| Step: 0
Training loss: 2.9289868953954774
Validation loss: 2.5164266450521953

Epoch: 5| Step: 1
Training loss: 2.820763971855535
Validation loss: 2.509383434768334

Epoch: 5| Step: 2
Training loss: 2.6966189549126858
Validation loss: 2.5095672300454015

Epoch: 5| Step: 3
Training loss: 2.974181176347327
Validation loss: 2.504154450200768

Epoch: 5| Step: 4
Training loss: 2.973356187102524
Validation loss: 2.5120966783965097

Epoch: 5| Step: 5
Training loss: 3.0010720562723043
Validation loss: 2.508011629692957

Epoch: 5| Step: 6
Training loss: 2.3884317147897236
Validation loss: 2.5151290358790614

Epoch: 5| Step: 7
Training loss: 3.432988344532187
Validation loss: 2.51923497626541

Epoch: 5| Step: 8
Training loss: 3.0612175260840897
Validation loss: 2.555589806382315

Epoch: 5| Step: 9
Training loss: 2.116160914556449
Validation loss: 2.597826183607218

Epoch: 5| Step: 10
Training loss: 2.5171566677750734
Validation loss: 2.6423083252523765

Epoch: 252| Step: 0
Training loss: 2.9931202522792986
Validation loss: 2.67326980526794

Epoch: 5| Step: 1
Training loss: 2.7564925798509665
Validation loss: 2.692920426940504

Epoch: 5| Step: 2
Training loss: 2.102095752549575
Validation loss: 2.7137247388767607

Epoch: 5| Step: 3
Training loss: 3.0906567763805812
Validation loss: 2.677285401079266

Epoch: 5| Step: 4
Training loss: 3.2326404877925152
Validation loss: 2.5851084286594372

Epoch: 5| Step: 5
Training loss: 2.2647848742051027
Validation loss: 2.5322010841696794

Epoch: 5| Step: 6
Training loss: 2.906405208914153
Validation loss: 2.513254975170507

Epoch: 5| Step: 7
Training loss: 3.267594760959594
Validation loss: 2.510494801983474

Epoch: 5| Step: 8
Training loss: 2.403332514540083
Validation loss: 2.5102559206992603

Epoch: 5| Step: 9
Training loss: 3.2436127620764434
Validation loss: 2.5195940293985823

Epoch: 5| Step: 10
Training loss: 3.0172287229451036
Validation loss: 2.517851850583022

Epoch: 253| Step: 0
Training loss: 3.206848808423985
Validation loss: 2.5175920430361485

Epoch: 5| Step: 1
Training loss: 3.0305392031680563
Validation loss: 2.514514695141434

Epoch: 5| Step: 2
Training loss: 2.8027029002479207
Validation loss: 2.524011089896685

Epoch: 5| Step: 3
Training loss: 2.8382175832170824
Validation loss: 2.5226705941365757

Epoch: 5| Step: 4
Training loss: 2.6921063358339876
Validation loss: 2.5311190643333727

Epoch: 5| Step: 5
Training loss: 2.420375532064609
Validation loss: 2.541888612779692

Epoch: 5| Step: 6
Training loss: 2.8305486757816474
Validation loss: 2.5483371632503475

Epoch: 5| Step: 7
Training loss: 3.1298628546068055
Validation loss: 2.573392326789876

Epoch: 5| Step: 8
Training loss: 2.816221530057581
Validation loss: 2.5696049457660397

Epoch: 5| Step: 9
Training loss: 2.59932046226308
Validation loss: 2.57370301415724

Epoch: 5| Step: 10
Training loss: 2.735904897760268
Validation loss: 2.56439945044908

Epoch: 254| Step: 0
Training loss: 2.7452540626450657
Validation loss: 2.566605361469491

Epoch: 5| Step: 1
Training loss: 2.454864468378136
Validation loss: 2.5458460081156296

Epoch: 5| Step: 2
Training loss: 2.880779262657285
Validation loss: 2.5383534865015975

Epoch: 5| Step: 3
Training loss: 2.2721068168231975
Validation loss: 2.5422944480955127

Epoch: 5| Step: 4
Training loss: 2.725905724589195
Validation loss: 2.5469268646586163

Epoch: 5| Step: 5
Training loss: 2.9090665889395306
Validation loss: 2.5579008693342327

Epoch: 5| Step: 6
Training loss: 2.9496856521970853
Validation loss: 2.559618864126251

Epoch: 5| Step: 7
Training loss: 2.967094200559719
Validation loss: 2.552807584402713

Epoch: 5| Step: 8
Training loss: 2.9671726252548103
Validation loss: 2.5453618376932803

Epoch: 5| Step: 9
Training loss: 3.149679918527018
Validation loss: 2.5396055346687176

Epoch: 5| Step: 10
Training loss: 3.093299447592028
Validation loss: 2.5234007026785528

Epoch: 255| Step: 0
Training loss: 2.7281071787947955
Validation loss: 2.515587936553293

Epoch: 5| Step: 1
Training loss: 2.7852156580598666
Validation loss: 2.5237566551399446

Epoch: 5| Step: 2
Training loss: 2.690781652340771
Validation loss: 2.5139377423210156

Epoch: 5| Step: 3
Training loss: 3.1047889205270995
Validation loss: 2.5206321850300166

Epoch: 5| Step: 4
Training loss: 3.055246599549309
Validation loss: 2.5275329497723624

Epoch: 5| Step: 5
Training loss: 3.042594837726117
Validation loss: 2.531785637116599

Epoch: 5| Step: 6
Training loss: 2.667610557717615
Validation loss: 2.5516941224970306

Epoch: 5| Step: 7
Training loss: 2.5060065591213307
Validation loss: 2.569042588411455

Epoch: 5| Step: 8
Training loss: 3.0107341101801315
Validation loss: 2.566338908762196

Epoch: 5| Step: 9
Training loss: 2.6227426359593045
Validation loss: 2.582970974529985

Epoch: 5| Step: 10
Training loss: 2.7070504500243526
Validation loss: 2.5743694049396875

Epoch: 256| Step: 0
Training loss: 2.8649407920910863
Validation loss: 2.61662889671094

Epoch: 5| Step: 1
Training loss: 2.880573343851297
Validation loss: 2.6011452826099055

Epoch: 5| Step: 2
Training loss: 2.8383644165320203
Validation loss: 2.5610411778628137

Epoch: 5| Step: 3
Training loss: 2.865042983659717
Validation loss: 2.5470573168283623

Epoch: 5| Step: 4
Training loss: 3.0028169440217627
Validation loss: 2.538254350732877

Epoch: 5| Step: 5
Training loss: 2.4656448150728156
Validation loss: 2.5189779773207324

Epoch: 5| Step: 6
Training loss: 2.8601916871823043
Validation loss: 2.514848239000671

Epoch: 5| Step: 7
Training loss: 2.7946745671780615
Validation loss: 2.5267656864089925

Epoch: 5| Step: 8
Training loss: 2.351073965229088
Validation loss: 2.5263995295252353

Epoch: 5| Step: 9
Training loss: 2.844667726766697
Validation loss: 2.52612694834305

Epoch: 5| Step: 10
Training loss: 3.3874710813744873
Validation loss: 2.533927809585797

Epoch: 257| Step: 0
Training loss: 2.8999493298543437
Validation loss: 2.536158638482292

Epoch: 5| Step: 1
Training loss: 2.986295870799493
Validation loss: 2.5258189519382377

Epoch: 5| Step: 2
Training loss: 2.907132414708341
Validation loss: 2.5223833622367016

Epoch: 5| Step: 3
Training loss: 2.747776433004539
Validation loss: 2.516882129136571

Epoch: 5| Step: 4
Training loss: 2.6471302328263824
Validation loss: 2.525864604042478

Epoch: 5| Step: 5
Training loss: 2.7043969133237304
Validation loss: 2.535758322880161

Epoch: 5| Step: 6
Training loss: 2.4061211885926146
Validation loss: 2.5257485777336295

Epoch: 5| Step: 7
Training loss: 2.9407611357323944
Validation loss: 2.531848678676227

Epoch: 5| Step: 8
Training loss: 2.8023408301119965
Validation loss: 2.540620651799406

Epoch: 5| Step: 9
Training loss: 3.133588965789635
Validation loss: 2.5299172751093555

Epoch: 5| Step: 10
Training loss: 2.7434725888375713
Validation loss: 2.5425561135021373

Epoch: 258| Step: 0
Training loss: 3.4022941366754367
Validation loss: 2.531915172915409

Epoch: 5| Step: 1
Training loss: 3.124128296390001
Validation loss: 2.5589331396708914

Epoch: 5| Step: 2
Training loss: 2.436847501620646
Validation loss: 2.5465497442673466

Epoch: 5| Step: 3
Training loss: 2.521355304325075
Validation loss: 2.565991709683906

Epoch: 5| Step: 4
Training loss: 2.765441802255802
Validation loss: 2.568540011149994

Epoch: 5| Step: 5
Training loss: 2.6601601039057527
Validation loss: 2.5605667869520965

Epoch: 5| Step: 6
Training loss: 2.5627324999028573
Validation loss: 2.5488548130625763

Epoch: 5| Step: 7
Training loss: 2.8301793851040036
Validation loss: 2.5321274592027927

Epoch: 5| Step: 8
Training loss: 3.0554460525157343
Validation loss: 2.5370144842137923

Epoch: 5| Step: 9
Training loss: 2.9201684547849784
Validation loss: 2.529015355168

Epoch: 5| Step: 10
Training loss: 2.487610922789159
Validation loss: 2.5210687254027606

Epoch: 259| Step: 0
Training loss: 2.8505031342354514
Validation loss: 2.5228393784555303

Epoch: 5| Step: 1
Training loss: 2.6946325356638705
Validation loss: 2.519986685662191

Epoch: 5| Step: 2
Training loss: 2.8679500885774303
Validation loss: 2.5183449116549657

Epoch: 5| Step: 3
Training loss: 2.5417768319024
Validation loss: 2.526671784013958

Epoch: 5| Step: 4
Training loss: 3.0199217549981383
Validation loss: 2.5406540040661754

Epoch: 5| Step: 5
Training loss: 3.0461346631605766
Validation loss: 2.560719334320371

Epoch: 5| Step: 6
Training loss: 2.709593161981073
Validation loss: 2.5725684981371653

Epoch: 5| Step: 7
Training loss: 2.9510342094380126
Validation loss: 2.5570407312663552

Epoch: 5| Step: 8
Training loss: 2.9202514054228317
Validation loss: 2.548599696984392

Epoch: 5| Step: 9
Training loss: 2.7298265392264645
Validation loss: 2.534269991670599

Epoch: 5| Step: 10
Training loss: 2.4187679911099607
Validation loss: 2.5372884479821023

Epoch: 260| Step: 0
Training loss: 2.9770353647527066
Validation loss: 2.531922061149148

Epoch: 5| Step: 1
Training loss: 2.5864624228248627
Validation loss: 2.540938613187545

Epoch: 5| Step: 2
Training loss: 2.934982519666356
Validation loss: 2.556659070298457

Epoch: 5| Step: 3
Training loss: 2.9526048636165076
Validation loss: 2.5556831638612727

Epoch: 5| Step: 4
Training loss: 2.725297169711686
Validation loss: 2.5586240133991103

Epoch: 5| Step: 5
Training loss: 2.817170905700659
Validation loss: 2.546014947181513

Epoch: 5| Step: 6
Training loss: 2.466631402803208
Validation loss: 2.535333896661438

Epoch: 5| Step: 7
Training loss: 3.1688735366004743
Validation loss: 2.5377399634409694

Epoch: 5| Step: 8
Training loss: 2.5017120221334452
Validation loss: 2.5215317373850104

Epoch: 5| Step: 9
Training loss: 2.9140968627539983
Validation loss: 2.5301998871464764

Epoch: 5| Step: 10
Training loss: 2.6943327519009803
Validation loss: 2.536832416783572

Epoch: 261| Step: 0
Training loss: 2.9769374981650114
Validation loss: 2.5350467024866696

Epoch: 5| Step: 1
Training loss: 2.5337702131853033
Validation loss: 2.5330772372733654

Epoch: 5| Step: 2
Training loss: 3.2160470224045827
Validation loss: 2.543130225974138

Epoch: 5| Step: 3
Training loss: 2.684151359718953
Validation loss: 2.5342563675480703

Epoch: 5| Step: 4
Training loss: 2.0335795029424344
Validation loss: 2.5422877745192056

Epoch: 5| Step: 5
Training loss: 2.9152714980091465
Validation loss: 2.5501298005174378

Epoch: 5| Step: 6
Training loss: 3.0526672082542157
Validation loss: 2.5571011952133125

Epoch: 5| Step: 7
Training loss: 2.731385956965922
Validation loss: 2.5848603619552035

Epoch: 5| Step: 8
Training loss: 2.772168538098917
Validation loss: 2.5765701054937202

Epoch: 5| Step: 9
Training loss: 2.8559671741917896
Validation loss: 2.5488087731133073

Epoch: 5| Step: 10
Training loss: 2.9048621032341884
Validation loss: 2.5373680348363226

Epoch: 262| Step: 0
Training loss: 2.7007001463541966
Validation loss: 2.5091792369690626

Epoch: 5| Step: 1
Training loss: 2.986494659710281
Validation loss: 2.5172920631912787

Epoch: 5| Step: 2
Training loss: 2.405213566297079
Validation loss: 2.507926972295553

Epoch: 5| Step: 3
Training loss: 2.7161865426387086
Validation loss: 2.51281679372779

Epoch: 5| Step: 4
Training loss: 3.1246508594023847
Validation loss: 2.5109141040816767

Epoch: 5| Step: 5
Training loss: 2.720469227175621
Validation loss: 2.4981782048651695

Epoch: 5| Step: 6
Training loss: 3.019385646453072
Validation loss: 2.5051694808183846

Epoch: 5| Step: 7
Training loss: 2.408338358872746
Validation loss: 2.5104280891170507

Epoch: 5| Step: 8
Training loss: 2.746224846566273
Validation loss: 2.537636266686924

Epoch: 5| Step: 9
Training loss: 2.8371328981861628
Validation loss: 2.575834227208831

Epoch: 5| Step: 10
Training loss: 3.1522026172228927
Validation loss: 2.639355679583221

Epoch: 263| Step: 0
Training loss: 3.116491560343284
Validation loss: 2.6829168546674618

Epoch: 5| Step: 1
Training loss: 2.9919787301720175
Validation loss: 2.6827302785391196

Epoch: 5| Step: 2
Training loss: 2.8819328971743805
Validation loss: 2.665456448844273

Epoch: 5| Step: 3
Training loss: 1.871447440148997
Validation loss: 2.63724726002681

Epoch: 5| Step: 4
Training loss: 2.5986490517918464
Validation loss: 2.599842897958582

Epoch: 5| Step: 5
Training loss: 3.2245031994368856
Validation loss: 2.549744040471119

Epoch: 5| Step: 6
Training loss: 3.0295627263361253
Validation loss: 2.5097052535813766

Epoch: 5| Step: 7
Training loss: 2.7672482484409953
Validation loss: 2.5015973802215306

Epoch: 5| Step: 8
Training loss: 3.1497303317458347
Validation loss: 2.496451173489498

Epoch: 5| Step: 9
Training loss: 2.898492118547038
Validation loss: 2.4967482081476517

Epoch: 5| Step: 10
Training loss: 2.315011593684585
Validation loss: 2.505087665480153

Epoch: 264| Step: 0
Training loss: 2.787949625881909
Validation loss: 2.4968190773400294

Epoch: 5| Step: 1
Training loss: 2.9835449981901707
Validation loss: 2.4936361614154987

Epoch: 5| Step: 2
Training loss: 2.8130612131314283
Validation loss: 2.509548928965877

Epoch: 5| Step: 3
Training loss: 2.408076596242649
Validation loss: 2.507268936243214

Epoch: 5| Step: 4
Training loss: 2.8179577748185656
Validation loss: 2.526592174776878

Epoch: 5| Step: 5
Training loss: 2.6596669378641065
Validation loss: 2.5532958350856134

Epoch: 5| Step: 6
Training loss: 3.013202385912576
Validation loss: 2.5431120333595554

Epoch: 5| Step: 7
Training loss: 2.7860439004225666
Validation loss: 2.555800233569483

Epoch: 5| Step: 8
Training loss: 2.8622383831027323
Validation loss: 2.5592058960110227

Epoch: 5| Step: 9
Training loss: 2.6434119150412005
Validation loss: 2.569692031681508

Epoch: 5| Step: 10
Training loss: 3.117296871857488
Validation loss: 2.585760482470879

Epoch: 265| Step: 0
Training loss: 2.2550015490541404
Validation loss: 2.5835751318794014

Epoch: 5| Step: 1
Training loss: 2.8162039209245764
Validation loss: 2.590791606677952

Epoch: 5| Step: 2
Training loss: 3.0509695857059658
Validation loss: 2.5962998663285255

Epoch: 5| Step: 3
Training loss: 2.6425595392107866
Validation loss: 2.550149995870941

Epoch: 5| Step: 4
Training loss: 2.979689509966712
Validation loss: 2.5160468992338347

Epoch: 5| Step: 5
Training loss: 2.552655639835165
Validation loss: 2.5083346629102614

Epoch: 5| Step: 6
Training loss: 3.3201486345134055
Validation loss: 2.5073016657202745

Epoch: 5| Step: 7
Training loss: 2.914267525095235
Validation loss: 2.506764318580192

Epoch: 5| Step: 8
Training loss: 2.2661462644557475
Validation loss: 2.519289152090185

Epoch: 5| Step: 9
Training loss: 3.286506293783657
Validation loss: 2.519432676065418

Epoch: 5| Step: 10
Training loss: 2.5024650818239786
Validation loss: 2.5317965117179373

Epoch: 266| Step: 0
Training loss: 2.958436740267906
Validation loss: 2.538251061155945

Epoch: 5| Step: 1
Training loss: 2.9633486147966766
Validation loss: 2.534292244516306

Epoch: 5| Step: 2
Training loss: 2.994205760309535
Validation loss: 2.542575938474885

Epoch: 5| Step: 3
Training loss: 2.0995163723951578
Validation loss: 2.555878458612284

Epoch: 5| Step: 4
Training loss: 2.5999373208340284
Validation loss: 2.553847311085867

Epoch: 5| Step: 5
Training loss: 2.8985317657030345
Validation loss: 2.5677969195773938

Epoch: 5| Step: 6
Training loss: 2.503229534809557
Validation loss: 2.5496058748003967

Epoch: 5| Step: 7
Training loss: 2.802561940062514
Validation loss: 2.555541327681964

Epoch: 5| Step: 8
Training loss: 2.569897464532476
Validation loss: 2.536713959326616

Epoch: 5| Step: 9
Training loss: 3.1848314371822193
Validation loss: 2.5229532977405817

Epoch: 5| Step: 10
Training loss: 2.920167801621
Validation loss: 2.5037697027291066

Epoch: 267| Step: 0
Training loss: 3.019061408556516
Validation loss: 2.492878537278501

Epoch: 5| Step: 1
Training loss: 2.9504896242534304
Validation loss: 2.499236221954291

Epoch: 5| Step: 2
Training loss: 2.665179602921052
Validation loss: 2.5056577404801197

Epoch: 5| Step: 3
Training loss: 3.1380808380003846
Validation loss: 2.502672397568262

Epoch: 5| Step: 4
Training loss: 2.5244955673193967
Validation loss: 2.513822830886295

Epoch: 5| Step: 5
Training loss: 2.7860885707526184
Validation loss: 2.541429530444961

Epoch: 5| Step: 6
Training loss: 2.726695934626681
Validation loss: 2.5443733411234866

Epoch: 5| Step: 7
Training loss: 2.9485675825524833
Validation loss: 2.558642778049764

Epoch: 5| Step: 8
Training loss: 2.6572567995167273
Validation loss: 2.581518482127258

Epoch: 5| Step: 9
Training loss: 2.758639549322444
Validation loss: 2.568859898854764

Epoch: 5| Step: 10
Training loss: 2.2929036587732
Validation loss: 2.5656057355990667

Epoch: 268| Step: 0
Training loss: 2.773763460158446
Validation loss: 2.577243743561572

Epoch: 5| Step: 1
Training loss: 2.8141013778720563
Validation loss: 2.586064694589531

Epoch: 5| Step: 2
Training loss: 3.0297276715059343
Validation loss: 2.559481598112128

Epoch: 5| Step: 3
Training loss: 2.876203533859952
Validation loss: 2.545884034782598

Epoch: 5| Step: 4
Training loss: 2.7815736732305645
Validation loss: 2.5260283932951864

Epoch: 5| Step: 5
Training loss: 2.5023017777356773
Validation loss: 2.521210465221074

Epoch: 5| Step: 6
Training loss: 3.2533434762431805
Validation loss: 2.50782945415276

Epoch: 5| Step: 7
Training loss: 2.4054456084656883
Validation loss: 2.4976369672577086

Epoch: 5| Step: 8
Training loss: 2.3458134024153363
Validation loss: 2.5003923272369373

Epoch: 5| Step: 9
Training loss: 2.7271402615831213
Validation loss: 2.5071965546275554

Epoch: 5| Step: 10
Training loss: 3.1615165357348833
Validation loss: 2.516125865009535

Epoch: 269| Step: 0
Training loss: 2.4969236519553113
Validation loss: 2.529613060271392

Epoch: 5| Step: 1
Training loss: 2.929397283802608
Validation loss: 2.5486209073382833

Epoch: 5| Step: 2
Training loss: 2.418797660574926
Validation loss: 2.552893035063288

Epoch: 5| Step: 3
Training loss: 2.763199599388725
Validation loss: 2.5832563657406107

Epoch: 5| Step: 4
Training loss: 2.6946134241171085
Validation loss: 2.5856944602796585

Epoch: 5| Step: 5
Training loss: 2.328023511479474
Validation loss: 2.5748014773175796

Epoch: 5| Step: 6
Training loss: 2.6223299888873015
Validation loss: 2.549783058678183

Epoch: 5| Step: 7
Training loss: 3.1720241267283695
Validation loss: 2.5348602925596397

Epoch: 5| Step: 8
Training loss: 3.226698754784211
Validation loss: 2.5242738908852353

Epoch: 5| Step: 9
Training loss: 2.522206197968759
Validation loss: 2.5189807165407974

Epoch: 5| Step: 10
Training loss: 3.307993864872512
Validation loss: 2.52353732247745

Epoch: 270| Step: 0
Training loss: 2.864874215818373
Validation loss: 2.5252802391453444

Epoch: 5| Step: 1
Training loss: 3.360512900033854
Validation loss: 2.5216652356758784

Epoch: 5| Step: 2
Training loss: 2.6816550280134877
Validation loss: 2.5224400854695324

Epoch: 5| Step: 3
Training loss: 2.247165802240954
Validation loss: 2.5327009577017714

Epoch: 5| Step: 4
Training loss: 2.915833454101188
Validation loss: 2.5402628530085054

Epoch: 5| Step: 5
Training loss: 2.933426162666933
Validation loss: 2.550111899111393

Epoch: 5| Step: 6
Training loss: 2.994169131825727
Validation loss: 2.583288104693125

Epoch: 5| Step: 7
Training loss: 2.30162978271425
Validation loss: 2.573461699966441

Epoch: 5| Step: 8
Training loss: 2.6006930161254203
Validation loss: 2.577302857213067

Epoch: 5| Step: 9
Training loss: 2.968958315316734
Validation loss: 2.549357025385843

Epoch: 5| Step: 10
Training loss: 2.4337666604716426
Validation loss: 2.5675930759532704

Epoch: 271| Step: 0
Training loss: 2.826162848362615
Validation loss: 2.5440508158650035

Epoch: 5| Step: 1
Training loss: 2.654684435666961
Validation loss: 2.54551449862273

Epoch: 5| Step: 2
Training loss: 2.8149053672210567
Validation loss: 2.51594381134465

Epoch: 5| Step: 3
Training loss: 2.5491425886593504
Validation loss: 2.5220335548382353

Epoch: 5| Step: 4
Training loss: 2.947987442155486
Validation loss: 2.5178401556754295

Epoch: 5| Step: 5
Training loss: 3.4742116459232797
Validation loss: 2.4951825553821294

Epoch: 5| Step: 6
Training loss: 2.615818770328495
Validation loss: 2.504128561862424

Epoch: 5| Step: 7
Training loss: 2.3204302517075472
Validation loss: 2.510353261863222

Epoch: 5| Step: 8
Training loss: 2.676554814476296
Validation loss: 2.523447579040179

Epoch: 5| Step: 9
Training loss: 2.6155513374775716
Validation loss: 2.5482151731365206

Epoch: 5| Step: 10
Training loss: 2.9657924978630685
Validation loss: 2.561445233722139

Epoch: 272| Step: 0
Training loss: 2.7987658539664175
Validation loss: 2.5765427652358412

Epoch: 5| Step: 1
Training loss: 3.317056077751659
Validation loss: 2.588737471638975

Epoch: 5| Step: 2
Training loss: 3.0284943000144025
Validation loss: 2.541768900245631

Epoch: 5| Step: 3
Training loss: 2.4854639893530153
Validation loss: 2.544056326467836

Epoch: 5| Step: 4
Training loss: 2.870708745976093
Validation loss: 2.519087026306546

Epoch: 5| Step: 5
Training loss: 3.058430517525253
Validation loss: 2.5173775136429994

Epoch: 5| Step: 6
Training loss: 2.626135171942735
Validation loss: 2.5167353070286587

Epoch: 5| Step: 7
Training loss: 2.577152230511845
Validation loss: 2.516551395518075

Epoch: 5| Step: 8
Training loss: 2.9261009948155157
Validation loss: 2.525624365801945

Epoch: 5| Step: 9
Training loss: 1.8063604354097011
Validation loss: 2.5270724444083776

Epoch: 5| Step: 10
Training loss: 2.6947441939360317
Validation loss: 2.539846277419418

Epoch: 273| Step: 0
Training loss: 2.1790776100220173
Validation loss: 2.5401062229173594

Epoch: 5| Step: 1
Training loss: 3.0010471106050303
Validation loss: 2.525682359130026

Epoch: 5| Step: 2
Training loss: 3.4924706807199506
Validation loss: 2.536011228017283

Epoch: 5| Step: 3
Training loss: 3.1015314441730775
Validation loss: 2.530009046167364

Epoch: 5| Step: 4
Training loss: 2.1239628224109497
Validation loss: 2.54457779355329

Epoch: 5| Step: 5
Training loss: 2.7793622414682324
Validation loss: 2.549205175841975

Epoch: 5| Step: 6
Training loss: 2.484322409403076
Validation loss: 2.5427854715852813

Epoch: 5| Step: 7
Training loss: 2.8806809399189466
Validation loss: 2.556857484963102

Epoch: 5| Step: 8
Training loss: 2.755064029676477
Validation loss: 2.5552686747910696

Epoch: 5| Step: 9
Training loss: 2.6136829198678884
Validation loss: 2.5311728500788844

Epoch: 5| Step: 10
Training loss: 2.767652210436595
Validation loss: 2.52172657934364

Epoch: 274| Step: 0
Training loss: 2.835250392937
Validation loss: 2.4989971723457263

Epoch: 5| Step: 1
Training loss: 2.913513131809444
Validation loss: 2.509642196677595

Epoch: 5| Step: 2
Training loss: 2.788065243191588
Validation loss: 2.5085274691097235

Epoch: 5| Step: 3
Training loss: 2.6739916532011017
Validation loss: 2.524998580646309

Epoch: 5| Step: 4
Training loss: 2.762825793909684
Validation loss: 2.539381269286632

Epoch: 5| Step: 5
Training loss: 2.8156403705207023
Validation loss: 2.553281541367768

Epoch: 5| Step: 6
Training loss: 2.596826406453444
Validation loss: 2.571011832604622

Epoch: 5| Step: 7
Training loss: 2.9240270838702966
Validation loss: 2.583310322323296

Epoch: 5| Step: 8
Training loss: 2.725097962464707
Validation loss: 2.5862017124384793

Epoch: 5| Step: 9
Training loss: 2.8760284574583665
Validation loss: 2.5780967594015753

Epoch: 5| Step: 10
Training loss: 2.44215047250551
Validation loss: 2.5886482663646495

Epoch: 275| Step: 0
Training loss: 2.3218867551934723
Validation loss: 2.579770772252835

Epoch: 5| Step: 1
Training loss: 3.3604315936960605
Validation loss: 2.563919648567184

Epoch: 5| Step: 2
Training loss: 2.8964758144259877
Validation loss: 2.5634026087002777

Epoch: 5| Step: 3
Training loss: 2.890247712128388
Validation loss: 2.5560082442914083

Epoch: 5| Step: 4
Training loss: 2.309631321042786
Validation loss: 2.5374084456543726

Epoch: 5| Step: 5
Training loss: 2.8712242875299308
Validation loss: 2.538041344604477

Epoch: 5| Step: 6
Training loss: 2.5654594265739172
Validation loss: 2.5146548459602287

Epoch: 5| Step: 7
Training loss: 2.392491029983654
Validation loss: 2.5075826881098804

Epoch: 5| Step: 8
Training loss: 3.033546600250458
Validation loss: 2.5089444223672457

Epoch: 5| Step: 9
Training loss: 2.9260830691703794
Validation loss: 2.5201087655449235

Epoch: 5| Step: 10
Training loss: 2.7415282932444653
Validation loss: 2.5372717088626136

Epoch: 276| Step: 0
Training loss: 2.8973577498372536
Validation loss: 2.5508718729688815

Epoch: 5| Step: 1
Training loss: 2.8360192153129047
Validation loss: 2.5468243824730057

Epoch: 5| Step: 2
Training loss: 2.6666574676672896
Validation loss: 2.5444959476531297

Epoch: 5| Step: 3
Training loss: 2.922337786086052
Validation loss: 2.5698933445843233

Epoch: 5| Step: 4
Training loss: 2.9042264394934887
Validation loss: 2.5805169229729095

Epoch: 5| Step: 5
Training loss: 2.685377302885034
Validation loss: 2.5634245046397477

Epoch: 5| Step: 6
Training loss: 2.1056804939763305
Validation loss: 2.5513159483200014

Epoch: 5| Step: 7
Training loss: 2.9355127633372367
Validation loss: 2.526943445095445

Epoch: 5| Step: 8
Training loss: 2.9572155591400864
Validation loss: 2.5165033363106692

Epoch: 5| Step: 9
Training loss: 2.6497205478943613
Validation loss: 2.494024945327105

Epoch: 5| Step: 10
Training loss: 2.78102976752148
Validation loss: 2.4988908491490798

Epoch: 277| Step: 0
Training loss: 3.0829727030686165
Validation loss: 2.497175030586717

Epoch: 5| Step: 1
Training loss: 2.598996107990188
Validation loss: 2.4930728400987627

Epoch: 5| Step: 2
Training loss: 3.185935590218668
Validation loss: 2.4964314566630277

Epoch: 5| Step: 3
Training loss: 2.3071863108764545
Validation loss: 2.5031231558269864

Epoch: 5| Step: 4
Training loss: 2.9183063439457926
Validation loss: 2.5103725854469348

Epoch: 5| Step: 5
Training loss: 2.819341011425985
Validation loss: 2.540464685570164

Epoch: 5| Step: 6
Training loss: 2.961357308372146
Validation loss: 2.543963001334507

Epoch: 5| Step: 7
Training loss: 2.5118486005995635
Validation loss: 2.5530814731303733

Epoch: 5| Step: 8
Training loss: 2.7553552156944376
Validation loss: 2.550335233956581

Epoch: 5| Step: 9
Training loss: 2.7674793126160955
Validation loss: 2.558189144549187

Epoch: 5| Step: 10
Training loss: 2.354856699412528
Validation loss: 2.558622054565247

Epoch: 278| Step: 0
Training loss: 3.2108853746624453
Validation loss: 2.5740106581846622

Epoch: 5| Step: 1
Training loss: 2.5144717019203657
Validation loss: 2.551306470739068

Epoch: 5| Step: 2
Training loss: 3.2144012702878624
Validation loss: 2.5357032927787793

Epoch: 5| Step: 3
Training loss: 2.735981147980017
Validation loss: 2.520788343030289

Epoch: 5| Step: 4
Training loss: 3.081921554953375
Validation loss: 2.5139870487818388

Epoch: 5| Step: 5
Training loss: 2.7409097243051934
Validation loss: 2.5011228008913693

Epoch: 5| Step: 6
Training loss: 2.805670690744433
Validation loss: 2.50172097334793

Epoch: 5| Step: 7
Training loss: 2.2061434149999424
Validation loss: 2.5098902775477714

Epoch: 5| Step: 8
Training loss: 2.475671553777156
Validation loss: 2.5120349424037816

Epoch: 5| Step: 9
Training loss: 2.6800485262107174
Validation loss: 2.5207098996167088

Epoch: 5| Step: 10
Training loss: 2.5774400205691204
Validation loss: 2.5206677148432552

Epoch: 279| Step: 0
Training loss: 2.960964071914493
Validation loss: 2.5440693766281455

Epoch: 5| Step: 1
Training loss: 2.8763519093987195
Validation loss: 2.541897291401524

Epoch: 5| Step: 2
Training loss: 2.9138343864930243
Validation loss: 2.5540732341763768

Epoch: 5| Step: 3
Training loss: 1.7996691002280258
Validation loss: 2.563905010118562

Epoch: 5| Step: 4
Training loss: 3.22652023324692
Validation loss: 2.562657208126122

Epoch: 5| Step: 5
Training loss: 1.7462330192990938
Validation loss: 2.5664053909266107

Epoch: 5| Step: 6
Training loss: 3.0438511637769943
Validation loss: 2.5520652179355507

Epoch: 5| Step: 7
Training loss: 3.174288728596552
Validation loss: 2.5410559889076096

Epoch: 5| Step: 8
Training loss: 2.7766069381841505
Validation loss: 2.544961461742182

Epoch: 5| Step: 9
Training loss: 2.787184224396787
Validation loss: 2.5794860608153134

Epoch: 5| Step: 10
Training loss: 2.5767630013851908
Validation loss: 2.5629527214546903

Epoch: 280| Step: 0
Training loss: 2.8497521075138774
Validation loss: 2.564107862174017

Epoch: 5| Step: 1
Training loss: 2.543157192578656
Validation loss: 2.5468916850622736

Epoch: 5| Step: 2
Training loss: 2.6758495015816464
Validation loss: 2.524472446170745

Epoch: 5| Step: 3
Training loss: 2.804013312021129
Validation loss: 2.509179934793389

Epoch: 5| Step: 4
Training loss: 3.2650255447019325
Validation loss: 2.5066920042110126

Epoch: 5| Step: 5
Training loss: 2.247091957196928
Validation loss: 2.494134240920367

Epoch: 5| Step: 6
Training loss: 3.067630440846232
Validation loss: 2.503088569137882

Epoch: 5| Step: 7
Training loss: 2.144619076568504
Validation loss: 2.5091207293795064

Epoch: 5| Step: 8
Training loss: 3.179190032059853
Validation loss: 2.5199448957178934

Epoch: 5| Step: 9
Training loss: 2.9973383858503517
Validation loss: 2.565393078786225

Epoch: 5| Step: 10
Training loss: 2.2764510798368547
Validation loss: 2.58133782857077

Epoch: 281| Step: 0
Training loss: 2.8741671143580576
Validation loss: 2.6125672234939232

Epoch: 5| Step: 1
Training loss: 2.5210857002311835
Validation loss: 2.5901716287656233

Epoch: 5| Step: 2
Training loss: 3.063222371756273
Validation loss: 2.556112872652645

Epoch: 5| Step: 3
Training loss: 2.4216322254200513
Validation loss: 2.5280593782227023

Epoch: 5| Step: 4
Training loss: 2.425301767037217
Validation loss: 2.51755200454462

Epoch: 5| Step: 5
Training loss: 2.428875164864963
Validation loss: 2.5088270632818706

Epoch: 5| Step: 6
Training loss: 3.106267401725181
Validation loss: 2.5023440631268734

Epoch: 5| Step: 7
Training loss: 2.672029457312522
Validation loss: 2.4975609037941355

Epoch: 5| Step: 8
Training loss: 3.134242009909983
Validation loss: 2.4904355751904554

Epoch: 5| Step: 9
Training loss: 2.9723270750317496
Validation loss: 2.4924965491095965

Epoch: 5| Step: 10
Training loss: 2.684522265479234
Validation loss: 2.5157402968565736

Epoch: 282| Step: 0
Training loss: 2.396680654432767
Validation loss: 2.5362656423206973

Epoch: 5| Step: 1
Training loss: 2.714635256438789
Validation loss: 2.5768449048421544

Epoch: 5| Step: 2
Training loss: 2.497056372480155
Validation loss: 2.591601149168065

Epoch: 5| Step: 3
Training loss: 2.9987370693727833
Validation loss: 2.6027784254428803

Epoch: 5| Step: 4
Training loss: 3.3216120790805843
Validation loss: 2.602954249202189

Epoch: 5| Step: 5
Training loss: 2.426607983145099
Validation loss: 2.5685590666621696

Epoch: 5| Step: 6
Training loss: 2.3176923658413866
Validation loss: 2.529043048046547

Epoch: 5| Step: 7
Training loss: 2.8237338038871234
Validation loss: 2.5250483533935784

Epoch: 5| Step: 8
Training loss: 2.9562690589080733
Validation loss: 2.497170056625702

Epoch: 5| Step: 9
Training loss: 3.0241439743080605
Validation loss: 2.5032100639122055

Epoch: 5| Step: 10
Training loss: 2.692808718750065
Validation loss: 2.4951066251578196

Epoch: 283| Step: 0
Training loss: 2.529146992723678
Validation loss: 2.4957153592226407

Epoch: 5| Step: 1
Training loss: 3.081125878238549
Validation loss: 2.504588285107827

Epoch: 5| Step: 2
Training loss: 3.0594902040262713
Validation loss: 2.4971158937067215

Epoch: 5| Step: 3
Training loss: 2.2595466896765752
Validation loss: 2.499754968550908

Epoch: 5| Step: 4
Training loss: 3.113427975977071
Validation loss: 2.5153380117989967

Epoch: 5| Step: 5
Training loss: 2.724073087902089
Validation loss: 2.5266071552230747

Epoch: 5| Step: 6
Training loss: 2.450010424221984
Validation loss: 2.533493990882593

Epoch: 5| Step: 7
Training loss: 2.7653797277968737
Validation loss: 2.530783243212769

Epoch: 5| Step: 8
Training loss: 2.980911881888327
Validation loss: 2.5550355107550615

Epoch: 5| Step: 9
Training loss: 2.363633008267615
Validation loss: 2.573056552035778

Epoch: 5| Step: 10
Training loss: 2.665189890439255
Validation loss: 2.5793000279031757

Epoch: 284| Step: 0
Training loss: 2.639882903247583
Validation loss: 2.6404634977153942

Epoch: 5| Step: 1
Training loss: 2.835130645056085
Validation loss: 2.6826348210787883

Epoch: 5| Step: 2
Training loss: 2.99346657448657
Validation loss: 2.6742867939799972

Epoch: 5| Step: 3
Training loss: 2.728004314816326
Validation loss: 2.6476053545985625

Epoch: 5| Step: 4
Training loss: 2.737232480847274
Validation loss: 2.5927641510133292

Epoch: 5| Step: 5
Training loss: 2.6017016124475925
Validation loss: 2.5448084966458726

Epoch: 5| Step: 6
Training loss: 2.94595710318127
Validation loss: 2.5136095453547314

Epoch: 5| Step: 7
Training loss: 2.9595267525810884
Validation loss: 2.5045820064745437

Epoch: 5| Step: 8
Training loss: 2.8184877869979394
Validation loss: 2.4996548440020008

Epoch: 5| Step: 9
Training loss: 2.1562703449561025
Validation loss: 2.4980135388383586

Epoch: 5| Step: 10
Training loss: 2.832194903676671
Validation loss: 2.497512160947879

Epoch: 285| Step: 0
Training loss: 2.158411904847814
Validation loss: 2.4921038326806038

Epoch: 5| Step: 1
Training loss: 3.4188070958476384
Validation loss: 2.49489450218148

Epoch: 5| Step: 2
Training loss: 2.771132421963074
Validation loss: 2.513434473742161

Epoch: 5| Step: 3
Training loss: 2.865085756572932
Validation loss: 2.527903327617133

Epoch: 5| Step: 4
Training loss: 2.879487888581628
Validation loss: 2.550029491911113

Epoch: 5| Step: 5
Training loss: 2.490224226388634
Validation loss: 2.564269182697497

Epoch: 5| Step: 6
Training loss: 3.0445596358356437
Validation loss: 2.56780451425333

Epoch: 5| Step: 7
Training loss: 2.4603838585440845
Validation loss: 2.5860949973534106

Epoch: 5| Step: 8
Training loss: 2.638713076797126
Validation loss: 2.5572303403892658

Epoch: 5| Step: 9
Training loss: 2.541228230500879
Validation loss: 2.54644673950145

Epoch: 5| Step: 10
Training loss: 2.783255207846013
Validation loss: 2.5266148077575625

Epoch: 286| Step: 0
Training loss: 2.701023409411869
Validation loss: 2.51337031750812

Epoch: 5| Step: 1
Training loss: 2.6133306068127222
Validation loss: 2.4976386516229385

Epoch: 5| Step: 2
Training loss: 2.7431334687017723
Validation loss: 2.503349453845903

Epoch: 5| Step: 3
Training loss: 2.984415902861061
Validation loss: 2.4969594174789713

Epoch: 5| Step: 4
Training loss: 2.6982308773061905
Validation loss: 2.499446635890194

Epoch: 5| Step: 5
Training loss: 2.3503363064307234
Validation loss: 2.506884361002112

Epoch: 5| Step: 6
Training loss: 2.160825105007328
Validation loss: 2.514547506175161

Epoch: 5| Step: 7
Training loss: 2.7025526907245636
Validation loss: 2.531768099641421

Epoch: 5| Step: 8
Training loss: 2.808923948611723
Validation loss: 2.583018170230976

Epoch: 5| Step: 9
Training loss: 2.8777144513062507
Validation loss: 2.6279169147730235

Epoch: 5| Step: 10
Training loss: 3.654347503490812
Validation loss: 2.632922422720847

Epoch: 287| Step: 0
Training loss: 3.2566164597617586
Validation loss: 2.5939364464498365

Epoch: 5| Step: 1
Training loss: 3.0676139640001816
Validation loss: 2.5397707906800218

Epoch: 5| Step: 2
Training loss: 2.4347194560150642
Validation loss: 2.523943580425635

Epoch: 5| Step: 3
Training loss: 2.4739395836906004
Validation loss: 2.5059978738500837

Epoch: 5| Step: 4
Training loss: 2.947669424375873
Validation loss: 2.51027945772122

Epoch: 5| Step: 5
Training loss: 2.4480053391865866
Validation loss: 2.5063946495388434

Epoch: 5| Step: 6
Training loss: 2.451187534966161
Validation loss: 2.5129689211198807

Epoch: 5| Step: 7
Training loss: 2.8527381459221277
Validation loss: 2.5077476264342855

Epoch: 5| Step: 8
Training loss: 2.848721863430684
Validation loss: 2.5255487818520703

Epoch: 5| Step: 9
Training loss: 2.417036773578661
Validation loss: 2.540125760196597

Epoch: 5| Step: 10
Training loss: 2.9055324201795365
Validation loss: 2.534699674371087

Epoch: 288| Step: 0
Training loss: 2.5441492390673495
Validation loss: 2.5437852226012354

Epoch: 5| Step: 1
Training loss: 2.660166019192093
Validation loss: 2.547768066903623

Epoch: 5| Step: 2
Training loss: 3.3773279991373837
Validation loss: 2.5661141125081124

Epoch: 5| Step: 3
Training loss: 2.821020993668127
Validation loss: 2.5476612614013576

Epoch: 5| Step: 4
Training loss: 2.893688166639507
Validation loss: 2.5316309063104385

Epoch: 5| Step: 5
Training loss: 2.407616660677469
Validation loss: 2.516607921164347

Epoch: 5| Step: 6
Training loss: 2.194422965876844
Validation loss: 2.5401548649937924

Epoch: 5| Step: 7
Training loss: 2.450959239718846
Validation loss: 2.5098306854218104

Epoch: 5| Step: 8
Training loss: 3.106314067832275
Validation loss: 2.528763814445009

Epoch: 5| Step: 9
Training loss: 2.7864208373402017
Validation loss: 2.5306563193264653

Epoch: 5| Step: 10
Training loss: 2.6085784061662673
Validation loss: 2.522695497501149

Epoch: 289| Step: 0
Training loss: 2.7552178904915077
Validation loss: 2.5465894385881294

Epoch: 5| Step: 1
Training loss: 2.944506466610182
Validation loss: 2.5661704435393693

Epoch: 5| Step: 2
Training loss: 2.277680622396204
Validation loss: 2.562627781669079

Epoch: 5| Step: 3
Training loss: 2.610106771046389
Validation loss: 2.5373822979675027

Epoch: 5| Step: 4
Training loss: 2.722256471024886
Validation loss: 2.529601836269005

Epoch: 5| Step: 5
Training loss: 3.2843584141915896
Validation loss: 2.5130130652723586

Epoch: 5| Step: 6
Training loss: 2.5818485997590246
Validation loss: 2.5320054495132247

Epoch: 5| Step: 7
Training loss: 1.9491378981462524
Validation loss: 2.528105690582457

Epoch: 5| Step: 8
Training loss: 2.8451801099567073
Validation loss: 2.54107849608805

Epoch: 5| Step: 9
Training loss: 3.3178967832085853
Validation loss: 2.5198390535151947

Epoch: 5| Step: 10
Training loss: 2.3883756140378063
Validation loss: 2.5444140457197526

Epoch: 290| Step: 0
Training loss: 2.508357669125068
Validation loss: 2.543746209144917

Epoch: 5| Step: 1
Training loss: 2.3253791540943665
Validation loss: 2.5469864061506247

Epoch: 5| Step: 2
Training loss: 2.8452119527749384
Validation loss: 2.526722224897977

Epoch: 5| Step: 3
Training loss: 2.69280455741406
Validation loss: 2.5472153482087814

Epoch: 5| Step: 4
Training loss: 2.2727387393315364
Validation loss: 2.5503725614158976

Epoch: 5| Step: 5
Training loss: 2.752167281189925
Validation loss: 2.568961728519466

Epoch: 5| Step: 6
Training loss: 2.645410749274893
Validation loss: 2.5980737375805663

Epoch: 5| Step: 7
Training loss: 2.8916985245268028
Validation loss: 2.593960329105424

Epoch: 5| Step: 8
Training loss: 3.065110942581366
Validation loss: 2.588822869214531

Epoch: 5| Step: 9
Training loss: 3.134543837072361
Validation loss: 2.556224781815289

Epoch: 5| Step: 10
Training loss: 2.722354735395145
Validation loss: 2.506989565969425

Epoch: 291| Step: 0
Training loss: 2.690199361312685
Validation loss: 2.496611370012804

Epoch: 5| Step: 1
Training loss: 2.874065413121519
Validation loss: 2.4903407558597963

Epoch: 5| Step: 2
Training loss: 2.8897078425162808
Validation loss: 2.4840273287182977

Epoch: 5| Step: 3
Training loss: 2.682798131638777
Validation loss: 2.484148027140462

Epoch: 5| Step: 4
Training loss: 2.7270988221065013
Validation loss: 2.484379304074799

Epoch: 5| Step: 5
Training loss: 2.962471999667831
Validation loss: 2.49296763502319

Epoch: 5| Step: 6
Training loss: 2.4851561463879754
Validation loss: 2.5090137357568154

Epoch: 5| Step: 7
Training loss: 2.766222011116012
Validation loss: 2.5535066249990077

Epoch: 5| Step: 8
Training loss: 3.0160168012763218
Validation loss: 2.5765523420205128

Epoch: 5| Step: 9
Training loss: 2.8552668509226993
Validation loss: 2.588991738872959

Epoch: 5| Step: 10
Training loss: 2.6396452762247535
Validation loss: 2.6204896589610702

Epoch: 292| Step: 0
Training loss: 3.0180072763202337
Validation loss: 2.6419873709420627

Epoch: 5| Step: 1
Training loss: 2.838261600408517
Validation loss: 2.6259618414068835

Epoch: 5| Step: 2
Training loss: 2.300174445295461
Validation loss: 2.5684881337680086

Epoch: 5| Step: 3
Training loss: 3.0031073689811536
Validation loss: 2.526566834445765

Epoch: 5| Step: 4
Training loss: 3.2258727142234833
Validation loss: 2.520341112378646

Epoch: 5| Step: 5
Training loss: 2.4550608389283055
Validation loss: 2.523318702255557

Epoch: 5| Step: 6
Training loss: 2.421998937573503
Validation loss: 2.5412703655163247

Epoch: 5| Step: 7
Training loss: 2.498194042222344
Validation loss: 2.5447868908416686

Epoch: 5| Step: 8
Training loss: 2.4810385702841358
Validation loss: 2.5485058627394626

Epoch: 5| Step: 9
Training loss: 3.0326104011786468
Validation loss: 2.540265063161893

Epoch: 5| Step: 10
Training loss: 2.56791821306182
Validation loss: 2.530704322495475

Epoch: 293| Step: 0
Training loss: 2.9696568760321025
Validation loss: 2.5100308081185663

Epoch: 5| Step: 1
Training loss: 2.1396337288403613
Validation loss: 2.5093621931195056

Epoch: 5| Step: 2
Training loss: 2.453758012289218
Validation loss: 2.525558321580371

Epoch: 5| Step: 3
Training loss: 2.54767413561502
Validation loss: 2.5400030133684335

Epoch: 5| Step: 4
Training loss: 2.8134391064519044
Validation loss: 2.5453273495603725

Epoch: 5| Step: 5
Training loss: 2.4544386535425784
Validation loss: 2.546217908055586

Epoch: 5| Step: 6
Training loss: 2.7945622093441633
Validation loss: 2.5287542310506606

Epoch: 5| Step: 7
Training loss: 2.7647310525562427
Validation loss: 2.5508745241723987

Epoch: 5| Step: 8
Training loss: 2.985094712638179
Validation loss: 2.5445906370232074

Epoch: 5| Step: 9
Training loss: 3.031462199855514
Validation loss: 2.542389400459188

Epoch: 5| Step: 10
Training loss: 2.7054073863240196
Validation loss: 2.549205605259924

Epoch: 294| Step: 0
Training loss: 3.0338694472467025
Validation loss: 2.5526457835829635

Epoch: 5| Step: 1
Training loss: 3.0777504010442316
Validation loss: 2.5332649017162954

Epoch: 5| Step: 2
Training loss: 2.8913992180026282
Validation loss: 2.534882469429155

Epoch: 5| Step: 3
Training loss: 2.480662420927189
Validation loss: 2.5415181386051726

Epoch: 5| Step: 4
Training loss: 2.4249913992188508
Validation loss: 2.5869925745440843

Epoch: 5| Step: 5
Training loss: 2.3937304901841916
Validation loss: 2.573583159788114

Epoch: 5| Step: 6
Training loss: 3.3220913777975047
Validation loss: 2.5781223519598475

Epoch: 5| Step: 7
Training loss: 2.4321336606401784
Validation loss: 2.565131605688769

Epoch: 5| Step: 8
Training loss: 2.692759490618575
Validation loss: 2.5412252625521274

Epoch: 5| Step: 9
Training loss: 2.546282272171806
Validation loss: 2.52834034035368

Epoch: 5| Step: 10
Training loss: 2.43493429279383
Validation loss: 2.5003091764517507

Epoch: 295| Step: 0
Training loss: 3.2056333071488923
Validation loss: 2.5053319615061125

Epoch: 5| Step: 1
Training loss: 2.380637455049133
Validation loss: 2.490509948860539

Epoch: 5| Step: 2
Training loss: 2.674107026405614
Validation loss: 2.4872333709593417

Epoch: 5| Step: 3
Training loss: 2.705584515158333
Validation loss: 2.494777462494306

Epoch: 5| Step: 4
Training loss: 2.823793075793604
Validation loss: 2.491994528278854

Epoch: 5| Step: 5
Training loss: 2.117915967778189
Validation loss: 2.513575317140699

Epoch: 5| Step: 6
Training loss: 2.4700091084609643
Validation loss: 2.513703990777999

Epoch: 5| Step: 7
Training loss: 2.9078263140498373
Validation loss: 2.5362138699638486

Epoch: 5| Step: 8
Training loss: 2.586851482851274
Validation loss: 2.587530897496102

Epoch: 5| Step: 9
Training loss: 2.8176532582502105
Validation loss: 2.5417957935451256

Epoch: 5| Step: 10
Training loss: 3.074222472599398
Validation loss: 2.540659707196387

Epoch: 296| Step: 0
Training loss: 2.978725978740055
Validation loss: 2.5621967171215254

Epoch: 5| Step: 1
Training loss: 2.614839964249295
Validation loss: 2.571632668351237

Epoch: 5| Step: 2
Training loss: 2.116376207602446
Validation loss: 2.5560842695040376

Epoch: 5| Step: 3
Training loss: 2.4388160087376614
Validation loss: 2.541967664298594

Epoch: 5| Step: 4
Training loss: 2.793677265491991
Validation loss: 2.5229752655457593

Epoch: 5| Step: 5
Training loss: 2.633625391767515
Validation loss: 2.5161483226431853

Epoch: 5| Step: 6
Training loss: 2.981242668094856
Validation loss: 2.518056004821117

Epoch: 5| Step: 7
Training loss: 2.438833605468724
Validation loss: 2.5169828013304545

Epoch: 5| Step: 8
Training loss: 3.274907549070058
Validation loss: 2.5171238199677344

Epoch: 5| Step: 9
Training loss: 2.4374231179657038
Validation loss: 2.5347902669710685

Epoch: 5| Step: 10
Training loss: 2.8655748535560903
Validation loss: 2.5347984647126487

Epoch: 297| Step: 0
Training loss: 2.9106091038173796
Validation loss: 2.5606496679881143

Epoch: 5| Step: 1
Training loss: 2.891587710516467
Validation loss: 2.6070027779818705

Epoch: 5| Step: 2
Training loss: 3.0009741790891122
Validation loss: 2.619842778006587

Epoch: 5| Step: 3
Training loss: 3.240120470138532
Validation loss: 2.6057464834829465

Epoch: 5| Step: 4
Training loss: 2.7219365179772192
Validation loss: 2.561957042926372

Epoch: 5| Step: 5
Training loss: 2.3697790683509274
Validation loss: 2.5186012041518255

Epoch: 5| Step: 6
Training loss: 2.606163652851278
Validation loss: 2.4918556070818627

Epoch: 5| Step: 7
Training loss: 2.3147282561613634
Validation loss: 2.4869366502641554

Epoch: 5| Step: 8
Training loss: 2.550500547611288
Validation loss: 2.464656321063103

Epoch: 5| Step: 9
Training loss: 2.5928412074770724
Validation loss: 2.4812746986082965

Epoch: 5| Step: 10
Training loss: 2.5679081857733004
Validation loss: 2.493184461195633

Epoch: 298| Step: 0
Training loss: 2.610533131779158
Validation loss: 2.5310111906103145

Epoch: 5| Step: 1
Training loss: 2.347916726690888
Validation loss: 2.5633858920936863

Epoch: 5| Step: 2
Training loss: 2.854065347994001
Validation loss: 2.6206232823644666

Epoch: 5| Step: 3
Training loss: 3.320828601892819
Validation loss: 2.6097067011205186

Epoch: 5| Step: 4
Training loss: 2.2974054671173256
Validation loss: 2.5490384646970443

Epoch: 5| Step: 5
Training loss: 2.5549010207979133
Validation loss: 2.4922817388695466

Epoch: 5| Step: 6
Training loss: 2.917616571420019
Validation loss: 2.4914632408278194

Epoch: 5| Step: 7
Training loss: 2.9736344160504706
Validation loss: 2.4782488230277027

Epoch: 5| Step: 8
Training loss: 2.530089029698256
Validation loss: 2.480765957023967

Epoch: 5| Step: 9
Training loss: 2.9426098472296145
Validation loss: 2.48214232843737

Epoch: 5| Step: 10
Training loss: 2.655245332895352
Validation loss: 2.5077539605235493

Epoch: 299| Step: 0
Training loss: 2.841988657349536
Validation loss: 2.522429918047617

Epoch: 5| Step: 1
Training loss: 3.024415639126163
Validation loss: 2.5463257663007934

Epoch: 5| Step: 2
Training loss: 2.650777587528324
Validation loss: 2.5781050973710053

Epoch: 5| Step: 3
Training loss: 2.576662978415998
Validation loss: 2.578180699696085

Epoch: 5| Step: 4
Training loss: 2.98329598458494
Validation loss: 2.580265398404737

Epoch: 5| Step: 5
Training loss: 2.192990959117534
Validation loss: 2.57029083628819

Epoch: 5| Step: 6
Training loss: 3.0449918747466223
Validation loss: 2.544502589242412

Epoch: 5| Step: 7
Training loss: 2.837392050416388
Validation loss: 2.5314374434246245

Epoch: 5| Step: 8
Training loss: 2.916936607584823
Validation loss: 2.5146322959782466

Epoch: 5| Step: 9
Training loss: 2.4402804044727344
Validation loss: 2.530528887597052

Epoch: 5| Step: 10
Training loss: 2.169543654805079
Validation loss: 2.526330997062224

Epoch: 300| Step: 0
Training loss: 1.8047417306389555
Validation loss: 2.5412197533763403

Epoch: 5| Step: 1
Training loss: 2.8968968988308945
Validation loss: 2.535957969474898

Epoch: 5| Step: 2
Training loss: 3.0539072118227253
Validation loss: 2.5176654362889077

Epoch: 5| Step: 3
Training loss: 2.9516001806484238
Validation loss: 2.53676786898893

Epoch: 5| Step: 4
Training loss: 2.5818099072759693
Validation loss: 2.5096116373179895

Epoch: 5| Step: 5
Training loss: 3.095358382322578
Validation loss: 2.5064445053317925

Epoch: 5| Step: 6
Training loss: 2.39545366900186
Validation loss: 2.49937837214551

Epoch: 5| Step: 7
Training loss: 2.121658727666481
Validation loss: 2.5001886860593934

Epoch: 5| Step: 8
Training loss: 3.4660336968071075
Validation loss: 2.4978124512752653

Epoch: 5| Step: 9
Training loss: 2.6371351125255393
Validation loss: 2.514326354125381

Epoch: 5| Step: 10
Training loss: 2.191796470346993
Validation loss: 2.534693726215406

Epoch: 301| Step: 0
Training loss: 3.046980792434191
Validation loss: 2.5525234731043818

Epoch: 5| Step: 1
Training loss: 2.7867950711334433
Validation loss: 2.605975611982261

Epoch: 5| Step: 2
Training loss: 2.7880771296106497
Validation loss: 2.6650235750218827

Epoch: 5| Step: 3
Training loss: 2.7906693817061066
Validation loss: 2.629393158459833

Epoch: 5| Step: 4
Training loss: 2.8445381497637583
Validation loss: 2.6327515517737208

Epoch: 5| Step: 5
Training loss: 2.5211460350438033
Validation loss: 2.55449138058035

Epoch: 5| Step: 6
Training loss: 2.824461867129239
Validation loss: 2.526327568157779

Epoch: 5| Step: 7
Training loss: 2.7287851799843454
Validation loss: 2.483964597857455

Epoch: 5| Step: 8
Training loss: 2.4477717796356475
Validation loss: 2.4833663096953145

Epoch: 5| Step: 9
Training loss: 2.3774526881375104
Validation loss: 2.484268891002145

Epoch: 5| Step: 10
Training loss: 2.664231460001352
Validation loss: 2.4867201004601203

Epoch: 302| Step: 0
Training loss: 2.2632701342845993
Validation loss: 2.4816062514657204

Epoch: 5| Step: 1
Training loss: 2.897113507934483
Validation loss: 2.4826284553539404

Epoch: 5| Step: 2
Training loss: 2.8215914967215467
Validation loss: 2.4849964669132065

Epoch: 5| Step: 3
Training loss: 3.0459394534750426
Validation loss: 2.4848565787831176

Epoch: 5| Step: 4
Training loss: 2.9548731882217347
Validation loss: 2.4925032120042134

Epoch: 5| Step: 5
Training loss: 2.4646482556375737
Validation loss: 2.4910467783083488

Epoch: 5| Step: 6
Training loss: 2.9311241594643858
Validation loss: 2.5103986876734967

Epoch: 5| Step: 7
Training loss: 2.9835408428063053
Validation loss: 2.5473493039657584

Epoch: 5| Step: 8
Training loss: 2.04506737483804
Validation loss: 2.5799933461809923

Epoch: 5| Step: 9
Training loss: 2.2155504394382053
Validation loss: 2.6204544123171223

Epoch: 5| Step: 10
Training loss: 3.194809405353572
Validation loss: 2.64380252975718

Epoch: 303| Step: 0
Training loss: 2.835969614735088
Validation loss: 2.678843062593836

Epoch: 5| Step: 1
Training loss: 2.409325059108463
Validation loss: 2.667977426877229

Epoch: 5| Step: 2
Training loss: 3.0542886380919914
Validation loss: 2.620745159476019

Epoch: 5| Step: 3
Training loss: 2.5642695945964755
Validation loss: 2.5329511600971024

Epoch: 5| Step: 4
Training loss: 2.7686629339784363
Validation loss: 2.503724049134443

Epoch: 5| Step: 5
Training loss: 2.1950937616921125
Validation loss: 2.4799282413637407

Epoch: 5| Step: 6
Training loss: 2.485244502851306
Validation loss: 2.4683105666451617

Epoch: 5| Step: 7
Training loss: 2.4623718925497906
Validation loss: 2.4677328171837383

Epoch: 5| Step: 8
Training loss: 3.1004589048780185
Validation loss: 2.4734398908834625

Epoch: 5| Step: 9
Training loss: 3.0617896054054
Validation loss: 2.4852434888427224

Epoch: 5| Step: 10
Training loss: 2.8739932412192153
Validation loss: 2.4959866519398317

Epoch: 304| Step: 0
Training loss: 2.9758924796462387
Validation loss: 2.512414097703858

Epoch: 5| Step: 1
Training loss: 2.804621363633096
Validation loss: 2.533443951971181

Epoch: 5| Step: 2
Training loss: 2.577166569896424
Validation loss: 2.549855722427112

Epoch: 5| Step: 3
Training loss: 2.3005222764175124
Validation loss: 2.582919871348374

Epoch: 5| Step: 4
Training loss: 3.100226510909374
Validation loss: 2.603934810694664

Epoch: 5| Step: 5
Training loss: 2.8928092333612523
Validation loss: 2.561869888208701

Epoch: 5| Step: 6
Training loss: 2.471058984994939
Validation loss: 2.527343611032447

Epoch: 5| Step: 7
Training loss: 2.5446425875326604
Validation loss: 2.5300654854552382

Epoch: 5| Step: 8
Training loss: 2.1244714865078476
Validation loss: 2.5153775433241803

Epoch: 5| Step: 9
Training loss: 2.8233624396086783
Validation loss: 2.503291153077305

Epoch: 5| Step: 10
Training loss: 2.790461598019796
Validation loss: 2.492701772077626

Epoch: 305| Step: 0
Training loss: 1.91970330330108
Validation loss: 2.4997431879525127

Epoch: 5| Step: 1
Training loss: 2.8913015862533085
Validation loss: 2.5032174991664977

Epoch: 5| Step: 2
Training loss: 2.5196268226180534
Validation loss: 2.519728870595657

Epoch: 5| Step: 3
Training loss: 3.202203236512656
Validation loss: 2.5478042285403606

Epoch: 5| Step: 4
Training loss: 3.2147672141178116
Validation loss: 2.575790407257686

Epoch: 5| Step: 5
Training loss: 2.5282488326970864
Validation loss: 2.579814500248302

Epoch: 5| Step: 6
Training loss: 2.5096123912061516
Validation loss: 2.6056708643543702

Epoch: 5| Step: 7
Training loss: 2.5105720144829116
Validation loss: 2.585240818614449

Epoch: 5| Step: 8
Training loss: 2.535857352014428
Validation loss: 2.559614907916802

Epoch: 5| Step: 9
Training loss: 2.5379214495865
Validation loss: 2.5367567271732274

Epoch: 5| Step: 10
Training loss: 2.8266000588084714
Validation loss: 2.549172687700473

Epoch: 306| Step: 0
Training loss: 2.680769454468525
Validation loss: 2.5156015975781805

Epoch: 5| Step: 1
Training loss: 2.4969784597033784
Validation loss: 2.5092356793978485

Epoch: 5| Step: 2
Training loss: 2.9591664676850606
Validation loss: 2.4871888218207228

Epoch: 5| Step: 3
Training loss: 2.2981215228027727
Validation loss: 2.4665975537161486

Epoch: 5| Step: 4
Training loss: 2.615472305562525
Validation loss: 2.472681607313353

Epoch: 5| Step: 5
Training loss: 2.0518261382007514
Validation loss: 2.482396869684036

Epoch: 5| Step: 6
Training loss: 2.6532006206901073
Validation loss: 2.4839941253807973

Epoch: 5| Step: 7
Training loss: 2.847022217546282
Validation loss: 2.4910923338875146

Epoch: 5| Step: 8
Training loss: 2.991392184304389
Validation loss: 2.5244528080576365

Epoch: 5| Step: 9
Training loss: 2.9734495209828276
Validation loss: 2.5301776363045523

Epoch: 5| Step: 10
Training loss: 2.8463681084843158
Validation loss: 2.525427535445217

Epoch: 307| Step: 0
Training loss: 2.567025816754533
Validation loss: 2.5547321716198175

Epoch: 5| Step: 1
Training loss: 2.8173932212491866
Validation loss: 2.636341603058105

Epoch: 5| Step: 2
Training loss: 2.4499450288171927
Validation loss: 2.6882647728051667

Epoch: 5| Step: 3
Training loss: 3.2031251488662313
Validation loss: 2.74707737048797

Epoch: 5| Step: 4
Training loss: 3.1902401683647805
Validation loss: 2.702741526609898

Epoch: 5| Step: 5
Training loss: 2.546867230175313
Validation loss: 2.6724865711268104

Epoch: 5| Step: 6
Training loss: 2.5144990095165802
Validation loss: 2.6301586151703575

Epoch: 5| Step: 7
Training loss: 2.4616499580981928
Validation loss: 2.6471679366556815

Epoch: 5| Step: 8
Training loss: 2.6615291419317675
Validation loss: 2.5905590461287664

Epoch: 5| Step: 9
Training loss: 2.5993735695844395
Validation loss: 2.5595366037586125

Epoch: 5| Step: 10
Training loss: 2.8075674248307383
Validation loss: 2.5169586618828643

Epoch: 308| Step: 0
Training loss: 2.4302922811669
Validation loss: 2.5121112319658505

Epoch: 5| Step: 1
Training loss: 2.9409785675336675
Validation loss: 2.5215799620421313

Epoch: 5| Step: 2
Training loss: 2.1142293950168742
Validation loss: 2.504902481225442

Epoch: 5| Step: 3
Training loss: 3.1056503914547227
Validation loss: 2.5124442561510367

Epoch: 5| Step: 4
Training loss: 2.550479608199611
Validation loss: 2.5015427515586843

Epoch: 5| Step: 5
Training loss: 3.0360970039501405
Validation loss: 2.510008438230825

Epoch: 5| Step: 6
Training loss: 2.6840242487555352
Validation loss: 2.4914778794248336

Epoch: 5| Step: 7
Training loss: 2.6168872262447254
Validation loss: 2.5068282133377355

Epoch: 5| Step: 8
Training loss: 2.619536208532904
Validation loss: 2.5100626824639756

Epoch: 5| Step: 9
Training loss: 2.864408471521412
Validation loss: 2.521177943760292

Epoch: 5| Step: 10
Training loss: 2.36330818602289
Validation loss: 2.5284166651795026

Epoch: 309| Step: 0
Training loss: 3.0034274549339095
Validation loss: 2.5418036928430587

Epoch: 5| Step: 1
Training loss: 2.6313564904199684
Validation loss: 2.581331274804021

Epoch: 5| Step: 2
Training loss: 2.254022816729547
Validation loss: 2.6159914587605906

Epoch: 5| Step: 3
Training loss: 2.9372245172415843
Validation loss: 2.6222028561805044

Epoch: 5| Step: 4
Training loss: 2.061898114785111
Validation loss: 2.630428656276075

Epoch: 5| Step: 5
Training loss: 2.571191144760161
Validation loss: 2.5995108839703045

Epoch: 5| Step: 6
Training loss: 2.7957173087940985
Validation loss: 2.57508092351471

Epoch: 5| Step: 7
Training loss: 2.336596341818503
Validation loss: 2.5412110250257753

Epoch: 5| Step: 8
Training loss: 2.45033056403557
Validation loss: 2.5328488381538214

Epoch: 5| Step: 9
Training loss: 3.205273461302632
Validation loss: 2.496450328339141

Epoch: 5| Step: 10
Training loss: 2.8909260361089215
Validation loss: 2.5144073702747423

Epoch: 310| Step: 0
Training loss: 3.0456073960723735
Validation loss: 2.486420709425592

Epoch: 5| Step: 1
Training loss: 2.018772358962444
Validation loss: 2.4996392512764443

Epoch: 5| Step: 2
Training loss: 2.4588790761931203
Validation loss: 2.5060157906416554

Epoch: 5| Step: 3
Training loss: 2.8410027616837215
Validation loss: 2.526747059413952

Epoch: 5| Step: 4
Training loss: 2.996012899210604
Validation loss: 2.5461498390489505

Epoch: 5| Step: 5
Training loss: 2.58645108473263
Validation loss: 2.555900057919557

Epoch: 5| Step: 6
Training loss: 2.6470310674097264
Validation loss: 2.596686209439865

Epoch: 5| Step: 7
Training loss: 2.355032556231838
Validation loss: 2.5978925408895854

Epoch: 5| Step: 8
Training loss: 2.0992597137986007
Validation loss: 2.581337669667697

Epoch: 5| Step: 9
Training loss: 2.8638324285105905
Validation loss: 2.575723156096655

Epoch: 5| Step: 10
Training loss: 3.1168602793185096
Validation loss: 2.5627899986262093

Epoch: 311| Step: 0
Training loss: 2.483810264651093
Validation loss: 2.553778734199141

Epoch: 5| Step: 1
Training loss: 2.2468964046472086
Validation loss: 2.5340368955814436

Epoch: 5| Step: 2
Training loss: 2.7368879705323397
Validation loss: 2.523326157503749

Epoch: 5| Step: 3
Training loss: 2.613510235845395
Validation loss: 2.516390602002114

Epoch: 5| Step: 4
Training loss: 2.8040035338277494
Validation loss: 2.503140136620546

Epoch: 5| Step: 5
Training loss: 2.5441885980118335
Validation loss: 2.5339546262531307

Epoch: 5| Step: 6
Training loss: 2.370175430468705
Validation loss: 2.5622813413877212

Epoch: 5| Step: 7
Training loss: 2.797960976263755
Validation loss: 2.5573094960933602

Epoch: 5| Step: 8
Training loss: 2.8387823626925637
Validation loss: 2.532982107381866

Epoch: 5| Step: 9
Training loss: 2.6772455149011094
Validation loss: 2.525212541778876

Epoch: 5| Step: 10
Training loss: 3.031859189198509
Validation loss: 2.482217244943472

Epoch: 312| Step: 0
Training loss: 2.8916683479179603
Validation loss: 2.4915249170336

Epoch: 5| Step: 1
Training loss: 2.759043821201833
Validation loss: 2.4814964082193076

Epoch: 5| Step: 2
Training loss: 2.765549653314641
Validation loss: 2.478774843165551

Epoch: 5| Step: 3
Training loss: 2.481330877950944
Validation loss: 2.4783863217591677

Epoch: 5| Step: 4
Training loss: 2.496833703531499
Validation loss: 2.486381288723761

Epoch: 5| Step: 5
Training loss: 2.463526354064021
Validation loss: 2.487545994389912

Epoch: 5| Step: 6
Training loss: 2.739326397314301
Validation loss: 2.49543744155449

Epoch: 5| Step: 7
Training loss: 2.9258428549296975
Validation loss: 2.5132807883718744

Epoch: 5| Step: 8
Training loss: 2.8558366071513275
Validation loss: 2.533002873641046

Epoch: 5| Step: 9
Training loss: 2.2191421806922245
Validation loss: 2.5369728625908285

Epoch: 5| Step: 10
Training loss: 2.5719262712450486
Validation loss: 2.576104382519135

Epoch: 313| Step: 0
Training loss: 2.646567795906169
Validation loss: 2.603129523368549

Epoch: 5| Step: 1
Training loss: 2.4187895778996076
Validation loss: 2.6121572421269583

Epoch: 5| Step: 2
Training loss: 2.416288762854731
Validation loss: 2.6872830547807114

Epoch: 5| Step: 3
Training loss: 2.5951144754374518
Validation loss: 2.6665911276049834

Epoch: 5| Step: 4
Training loss: 2.733668993677213
Validation loss: 2.688764509797472

Epoch: 5| Step: 5
Training loss: 1.9225958736012299
Validation loss: 2.7112088811273196

Epoch: 5| Step: 6
Training loss: 3.135992932934486
Validation loss: 2.705482183996725

Epoch: 5| Step: 7
Training loss: 2.9330737266391513
Validation loss: 2.6404976384170515

Epoch: 5| Step: 8
Training loss: 2.5556562261056777
Validation loss: 2.5579322624284004

Epoch: 5| Step: 9
Training loss: 2.7929580794977547
Validation loss: 2.492550760980502

Epoch: 5| Step: 10
Training loss: 3.055383003063635
Validation loss: 2.4790760546620656

Epoch: 314| Step: 0
Training loss: 2.694576970235393
Validation loss: 2.4796698747131742

Epoch: 5| Step: 1
Training loss: 3.3750772820560826
Validation loss: 2.4814383203071118

Epoch: 5| Step: 2
Training loss: 2.7033780370920906
Validation loss: 2.491326957756956

Epoch: 5| Step: 3
Training loss: 2.618369037895464
Validation loss: 2.4859022916441162

Epoch: 5| Step: 4
Training loss: 2.856502069414759
Validation loss: 2.4807328226775343

Epoch: 5| Step: 5
Training loss: 2.3645934946343194
Validation loss: 2.4850571435575386

Epoch: 5| Step: 6
Training loss: 2.706524866254521
Validation loss: 2.4727878636292866

Epoch: 5| Step: 7
Training loss: 2.197568989474728
Validation loss: 2.4940861259577867

Epoch: 5| Step: 8
Training loss: 2.964518211294654
Validation loss: 2.4993106383821138

Epoch: 5| Step: 9
Training loss: 2.6596301842798686
Validation loss: 2.509284202688063

Epoch: 5| Step: 10
Training loss: 2.9226254402174345
Validation loss: 2.545929009900239

Epoch: 315| Step: 0
Training loss: 2.5667168880685094
Validation loss: 2.5740836708061634

Epoch: 5| Step: 1
Training loss: 2.29382869575067
Validation loss: 2.589672609523993

Epoch: 5| Step: 2
Training loss: 2.066894473574444
Validation loss: 2.591542020378181

Epoch: 5| Step: 3
Training loss: 3.12124071980702
Validation loss: 2.607718526690107

Epoch: 5| Step: 4
Training loss: 2.623876603749052
Validation loss: 2.5800671155663824

Epoch: 5| Step: 5
Training loss: 2.9073236594677376
Validation loss: 2.5487592219577797

Epoch: 5| Step: 6
Training loss: 3.253509094253711
Validation loss: 2.555515615319977

Epoch: 5| Step: 7
Training loss: 2.6701171624984
Validation loss: 2.5520129041934094

Epoch: 5| Step: 8
Training loss: 2.2890577088393758
Validation loss: 2.5439118058642958

Epoch: 5| Step: 9
Training loss: 2.635268969914214
Validation loss: 2.5617691966820457

Epoch: 5| Step: 10
Training loss: 2.4486925451169803
Validation loss: 2.562021750604532

Epoch: 316| Step: 0
Training loss: 2.6801911261715716
Validation loss: 2.5747311405646305

Epoch: 5| Step: 1
Training loss: 2.58714068216869
Validation loss: 2.576293967297738

Epoch: 5| Step: 2
Training loss: 2.4520932111214355
Validation loss: 2.592001136476773

Epoch: 5| Step: 3
Training loss: 2.639929775835712
Validation loss: 2.5967311428501145

Epoch: 5| Step: 4
Training loss: 2.6307706527646055
Validation loss: 2.604390105147415

Epoch: 5| Step: 5
Training loss: 2.5272642238079692
Validation loss: 2.575914137879663

Epoch: 5| Step: 6
Training loss: 3.0211269016779947
Validation loss: 2.565105172425635

Epoch: 5| Step: 7
Training loss: 2.312049821904209
Validation loss: 2.5703719645540852

Epoch: 5| Step: 8
Training loss: 3.0229933459290397
Validation loss: 2.5476296401083296

Epoch: 5| Step: 9
Training loss: 2.2774474969333194
Validation loss: 2.525381850061211

Epoch: 5| Step: 10
Training loss: 2.617355751209119
Validation loss: 2.5168081854027835

Epoch: 317| Step: 0
Training loss: 2.597754087971898
Validation loss: 2.535876900798531

Epoch: 5| Step: 1
Training loss: 2.868736576223444
Validation loss: 2.554595538187573

Epoch: 5| Step: 2
Training loss: 2.723992390659812
Validation loss: 2.563260739602691

Epoch: 5| Step: 3
Training loss: 2.4980148062836034
Validation loss: 2.6229279138793284

Epoch: 5| Step: 4
Training loss: 2.327186548943067
Validation loss: 2.645124781576981

Epoch: 5| Step: 5
Training loss: 2.660747266365675
Validation loss: 2.6536004240109765

Epoch: 5| Step: 6
Training loss: 2.966146190577422
Validation loss: 2.604954239080774

Epoch: 5| Step: 7
Training loss: 2.710971447295105
Validation loss: 2.552093215196642

Epoch: 5| Step: 8
Training loss: 2.5952729499462865
Validation loss: 2.5119202970468613

Epoch: 5| Step: 9
Training loss: 2.789782690246907
Validation loss: 2.472384740674016

Epoch: 5| Step: 10
Training loss: 2.3409287829803973
Validation loss: 2.4683616470841527

Epoch: 318| Step: 0
Training loss: 2.404435104995205
Validation loss: 2.464906361125975

Epoch: 5| Step: 1
Training loss: 2.70163602006377
Validation loss: 2.464161631974132

Epoch: 5| Step: 2
Training loss: 2.7381981852036636
Validation loss: 2.4794180582231005

Epoch: 5| Step: 3
Training loss: 2.445434372274996
Validation loss: 2.4744882465348197

Epoch: 5| Step: 4
Training loss: 2.662103643152303
Validation loss: 2.481643892677073

Epoch: 5| Step: 5
Training loss: 2.961527501408954
Validation loss: 2.4940557845819256

Epoch: 5| Step: 6
Training loss: 2.7176811484959265
Validation loss: 2.5393683500007165

Epoch: 5| Step: 7
Training loss: 2.7622571363754815
Validation loss: 2.571170628104318

Epoch: 5| Step: 8
Training loss: 2.9100209044659304
Validation loss: 2.6080926076459954

Epoch: 5| Step: 9
Training loss: 2.6868812381009124
Validation loss: 2.6362890955537237

Epoch: 5| Step: 10
Training loss: 2.1875088282815716
Validation loss: 2.626745024861486

Epoch: 319| Step: 0
Training loss: 2.557990129626262
Validation loss: 2.593977243012049

Epoch: 5| Step: 1
Training loss: 2.3590707140612914
Validation loss: 2.5986020738796887

Epoch: 5| Step: 2
Training loss: 2.6001189754847807
Validation loss: 2.5821001369051717

Epoch: 5| Step: 3
Training loss: 2.366681639753804
Validation loss: 2.5688280045892466

Epoch: 5| Step: 4
Training loss: 2.5130141078615207
Validation loss: 2.56474148439344

Epoch: 5| Step: 5
Training loss: 3.0588642258979113
Validation loss: 2.569120696636504

Epoch: 5| Step: 6
Training loss: 2.546041153220828
Validation loss: 2.5776569039702126

Epoch: 5| Step: 7
Training loss: 2.6727577223662196
Validation loss: 2.570861867909614

Epoch: 5| Step: 8
Training loss: 2.221867265432982
Validation loss: 2.554683445838234

Epoch: 5| Step: 9
Training loss: 2.544033782650707
Validation loss: 2.5519597073602034

Epoch: 5| Step: 10
Training loss: 3.222857326823522
Validation loss: 2.5274718920760146

Epoch: 320| Step: 0
Training loss: 1.8162121740866783
Validation loss: 2.5343307196888567

Epoch: 5| Step: 1
Training loss: 2.667125294903597
Validation loss: 2.5289351861279896

Epoch: 5| Step: 2
Training loss: 2.4596958479450652
Validation loss: 2.5457660478520494

Epoch: 5| Step: 3
Training loss: 3.0000416434894532
Validation loss: 2.558748576121684

Epoch: 5| Step: 4
Training loss: 2.4479144698329294
Validation loss: 2.600778808726662

Epoch: 5| Step: 5
Training loss: 2.5190491680875695
Validation loss: 2.637002264570048

Epoch: 5| Step: 6
Training loss: 2.9874309452008676
Validation loss: 2.6307825560445384

Epoch: 5| Step: 7
Training loss: 2.7730636129748674
Validation loss: 2.5824397410907074

Epoch: 5| Step: 8
Training loss: 2.2583357788673286
Validation loss: 2.54395308520247

Epoch: 5| Step: 9
Training loss: 2.8195885233612645
Validation loss: 2.5120013418087583

Epoch: 5| Step: 10
Training loss: 2.710390942798691
Validation loss: 2.511757840407184

Epoch: 321| Step: 0
Training loss: 2.4738564132309078
Validation loss: 2.510976260706737

Epoch: 5| Step: 1
Training loss: 3.037634192748139
Validation loss: 2.5045123240013067

Epoch: 5| Step: 2
Training loss: 2.6815451363985057
Validation loss: 2.480471300752488

Epoch: 5| Step: 3
Training loss: 2.8418562735416044
Validation loss: 2.4854421121271058

Epoch: 5| Step: 4
Training loss: 2.7780411457670064
Validation loss: 2.5189720963583584

Epoch: 5| Step: 5
Training loss: 2.581785435597123
Validation loss: 2.568544115303258

Epoch: 5| Step: 6
Training loss: 2.29460166482811
Validation loss: 2.6429140717941095

Epoch: 5| Step: 7
Training loss: 2.673249365263981
Validation loss: 2.6967161827733768

Epoch: 5| Step: 8
Training loss: 2.5545775596923823
Validation loss: 2.646385318098159

Epoch: 5| Step: 9
Training loss: 2.121152423869073
Validation loss: 2.5655733841931707

Epoch: 5| Step: 10
Training loss: 2.56171098052368
Validation loss: 2.5282240788434462

Epoch: 322| Step: 0
Training loss: 2.638106279159887
Validation loss: 2.5054445569585613

Epoch: 5| Step: 1
Training loss: 2.9455161593422448
Validation loss: 2.495324771602893

Epoch: 5| Step: 2
Training loss: 2.502373903434075
Validation loss: 2.4818601370223994

Epoch: 5| Step: 3
Training loss: 2.5925962340869257
Validation loss: 2.4695458443670724

Epoch: 5| Step: 4
Training loss: 2.642060290431993
Validation loss: 2.4813921153433807

Epoch: 5| Step: 5
Training loss: 2.604122151312238
Validation loss: 2.4791729055691363

Epoch: 5| Step: 6
Training loss: 2.758690194577971
Validation loss: 2.5227707279388394

Epoch: 5| Step: 7
Training loss: 2.274665107810741
Validation loss: 2.537168305194572

Epoch: 5| Step: 8
Training loss: 2.0793384651755926
Validation loss: 2.5614818768399976

Epoch: 5| Step: 9
Training loss: 2.3194010064885604
Validation loss: 2.59707211700871

Epoch: 5| Step: 10
Training loss: 3.098281624047695
Validation loss: 2.631434342848337

Epoch: 323| Step: 0
Training loss: 2.9036458150866498
Validation loss: 2.6678199068934187

Epoch: 5| Step: 1
Training loss: 2.6978612376131896
Validation loss: 2.683482929893496

Epoch: 5| Step: 2
Training loss: 2.7447734931088394
Validation loss: 2.6587867895004016

Epoch: 5| Step: 3
Training loss: 2.430590593600146
Validation loss: 2.6353926814194577

Epoch: 5| Step: 4
Training loss: 2.502679056931914
Validation loss: 2.597764686913647

Epoch: 5| Step: 5
Training loss: 1.8729966587499174
Validation loss: 2.571746870786663

Epoch: 5| Step: 6
Training loss: 2.6442776309042393
Validation loss: 2.5306804304314094

Epoch: 5| Step: 7
Training loss: 2.73891364398711
Validation loss: 2.509999648328128

Epoch: 5| Step: 8
Training loss: 2.4232745648918543
Validation loss: 2.5071173168114873

Epoch: 5| Step: 9
Training loss: 2.976143554680931
Validation loss: 2.480200320831597

Epoch: 5| Step: 10
Training loss: 2.1061782915263896
Validation loss: 2.491232914309389

Epoch: 324| Step: 0
Training loss: 2.874438189471176
Validation loss: 2.4975824428897577

Epoch: 5| Step: 1
Training loss: 2.7972555061522746
Validation loss: 2.5247487852818438

Epoch: 5| Step: 2
Training loss: 2.437484056469542
Validation loss: 2.544561236383224

Epoch: 5| Step: 3
Training loss: 2.3870578656064585
Validation loss: 2.5420996517202057

Epoch: 5| Step: 4
Training loss: 2.4376062223324357
Validation loss: 2.5658727060581836

Epoch: 5| Step: 5
Training loss: 2.3895654262502557
Validation loss: 2.54154054990165

Epoch: 5| Step: 6
Training loss: 2.816362060538822
Validation loss: 2.5094558794732476

Epoch: 5| Step: 7
Training loss: 2.9417439098500973
Validation loss: 2.492427611069846

Epoch: 5| Step: 8
Training loss: 2.3771669641126505
Validation loss: 2.4875647830097103

Epoch: 5| Step: 9
Training loss: 2.103891549836374
Validation loss: 2.484337867629068

Epoch: 5| Step: 10
Training loss: 2.90966825554045
Validation loss: 2.502342669044014

Epoch: 325| Step: 0
Training loss: 2.3727416293521393
Validation loss: 2.5289231167090462

Epoch: 5| Step: 1
Training loss: 2.3066980934574755
Validation loss: 2.553443258730533

Epoch: 5| Step: 2
Training loss: 2.868771149468012
Validation loss: 2.559443617213729

Epoch: 5| Step: 3
Training loss: 2.5460203644207016
Validation loss: 2.607328845055126

Epoch: 5| Step: 4
Training loss: 2.2080960296190217
Validation loss: 2.6414053857752937

Epoch: 5| Step: 5
Training loss: 2.713287302543728
Validation loss: 2.632944007311479

Epoch: 5| Step: 6
Training loss: 2.816038999276604
Validation loss: 2.6009001766575532

Epoch: 5| Step: 7
Training loss: 2.455852765680724
Validation loss: 2.543192927853805

Epoch: 5| Step: 8
Training loss: 2.1976004519195147
Validation loss: 2.5348860688033485

Epoch: 5| Step: 9
Training loss: 2.6879127540337167
Validation loss: 2.527412902146666

Epoch: 5| Step: 10
Training loss: 2.9215492434134074
Validation loss: 2.5146846614991936

Epoch: 326| Step: 0
Training loss: 2.4827007674276693
Validation loss: 2.515450981825353

Epoch: 5| Step: 1
Training loss: 2.6080625968395013
Validation loss: 2.5486292783683844

Epoch: 5| Step: 2
Training loss: 2.3776540482891844
Validation loss: 2.583095581938066

Epoch: 5| Step: 3
Training loss: 2.788228057071765
Validation loss: 2.604459253097366

Epoch: 5| Step: 4
Training loss: 2.33705291144265
Validation loss: 2.6268465214977654

Epoch: 5| Step: 5
Training loss: 2.352878747139911
Validation loss: 2.6179441393846754

Epoch: 5| Step: 6
Training loss: 3.004874719429709
Validation loss: 2.613689096296515

Epoch: 5| Step: 7
Training loss: 2.3038552026018615
Validation loss: 2.574585938607336

Epoch: 5| Step: 8
Training loss: 2.6154733994461594
Validation loss: 2.5632123099686512

Epoch: 5| Step: 9
Training loss: 2.7316183090662176
Validation loss: 2.541976774298178

Epoch: 5| Step: 10
Training loss: 2.305561171630801
Validation loss: 2.5195715429542567

Epoch: 327| Step: 0
Training loss: 2.3382130641917835
Validation loss: 2.4878893880917503

Epoch: 5| Step: 1
Training loss: 3.2174976468022063
Validation loss: 2.4949576893178396

Epoch: 5| Step: 2
Training loss: 2.31554470154693
Validation loss: 2.497926189273054

Epoch: 5| Step: 3
Training loss: 1.9221261953551232
Validation loss: 2.5040132381566353

Epoch: 5| Step: 4
Training loss: 2.4500316384277316
Validation loss: 2.5217307393540525

Epoch: 5| Step: 5
Training loss: 2.569697436916915
Validation loss: 2.5586967577156714

Epoch: 5| Step: 6
Training loss: 1.9571597119959034
Validation loss: 2.5663341687467573

Epoch: 5| Step: 7
Training loss: 2.3608540326454435
Validation loss: 2.5481373989886285

Epoch: 5| Step: 8
Training loss: 2.540624331841375
Validation loss: 2.5192113448286357

Epoch: 5| Step: 9
Training loss: 2.9083505238313716
Validation loss: 2.5255123015499565

Epoch: 5| Step: 10
Training loss: 3.1173178279851137
Validation loss: 2.505745213398099

Epoch: 328| Step: 0
Training loss: 2.8710675089149453
Validation loss: 2.5035694092773504

Epoch: 5| Step: 1
Training loss: 2.509919704353557
Validation loss: 2.5261522108846983

Epoch: 5| Step: 2
Training loss: 2.362203355360761
Validation loss: 2.5392438098422794

Epoch: 5| Step: 3
Training loss: 2.5283050359836863
Validation loss: 2.5577699087800743

Epoch: 5| Step: 4
Training loss: 2.780519796804832
Validation loss: 2.5569231147733

Epoch: 5| Step: 5
Training loss: 2.410695613808957
Validation loss: 2.5350821142118463

Epoch: 5| Step: 6
Training loss: 1.882081962462776
Validation loss: 2.507566051265699

Epoch: 5| Step: 7
Training loss: 2.837653699568846
Validation loss: 2.5070689560950656

Epoch: 5| Step: 8
Training loss: 2.507800996462859
Validation loss: 2.4979830819870377

Epoch: 5| Step: 9
Training loss: 2.789610907655991
Validation loss: 2.5181393250006847

Epoch: 5| Step: 10
Training loss: 2.121948182497132
Validation loss: 2.513753924949463

Epoch: 329| Step: 0
Training loss: 2.5565013920440554
Validation loss: 2.527755078732143

Epoch: 5| Step: 1
Training loss: 2.8037892552900323
Validation loss: 2.525161463626044

Epoch: 5| Step: 2
Training loss: 2.2755350091663926
Validation loss: 2.575945049702071

Epoch: 5| Step: 3
Training loss: 2.738585799364511
Validation loss: 2.5873722896374693

Epoch: 5| Step: 4
Training loss: 2.3072438690768737
Validation loss: 2.619114103034091

Epoch: 5| Step: 5
Training loss: 2.5070522974354597
Validation loss: 2.60959821422637

Epoch: 5| Step: 6
Training loss: 2.4173573351070177
Validation loss: 2.589333230714213

Epoch: 5| Step: 7
Training loss: 2.567230788903178
Validation loss: 2.5325287455496723

Epoch: 5| Step: 8
Training loss: 3.112818818826488
Validation loss: 2.519268410166955

Epoch: 5| Step: 9
Training loss: 2.349313059297534
Validation loss: 2.502503681631518

Epoch: 5| Step: 10
Training loss: 1.8375373525131682
Validation loss: 2.5030140735012827

Epoch: 330| Step: 0
Training loss: 2.8037840681859194
Validation loss: 2.492045279110853

Epoch: 5| Step: 1
Training loss: 2.778100963441345
Validation loss: 2.5239957954244048

Epoch: 5| Step: 2
Training loss: 2.4429503905872427
Validation loss: 2.517133216448022

Epoch: 5| Step: 3
Training loss: 2.1291366032557626
Validation loss: 2.5867282506170204

Epoch: 5| Step: 4
Training loss: 2.636400986350073
Validation loss: 2.6431117815476646

Epoch: 5| Step: 5
Training loss: 2.336589505349626
Validation loss: 2.637081744913334

Epoch: 5| Step: 6
Training loss: 2.1996632968564422
Validation loss: 2.640177539869811

Epoch: 5| Step: 7
Training loss: 2.984902220487154
Validation loss: 2.618191256005176

Epoch: 5| Step: 8
Training loss: 2.328892523703679
Validation loss: 2.577280967773399

Epoch: 5| Step: 9
Training loss: 1.984571372100304
Validation loss: 2.566831246293192

Epoch: 5| Step: 10
Training loss: 2.9170675456348105
Validation loss: 2.53732015369557

Epoch: 331| Step: 0
Training loss: 1.8410751206893656
Validation loss: 2.528427229813949

Epoch: 5| Step: 1
Training loss: 2.7920641734719136
Validation loss: 2.5151322965789937

Epoch: 5| Step: 2
Training loss: 2.8690020149253135
Validation loss: 2.5009277375886128

Epoch: 5| Step: 3
Training loss: 2.559291226200209
Validation loss: 2.5081930489299724

Epoch: 5| Step: 4
Training loss: 2.1018585790650044
Validation loss: 2.5270339246670734

Epoch: 5| Step: 5
Training loss: 2.7959748423239956
Validation loss: 2.5780076145310518

Epoch: 5| Step: 6
Training loss: 2.2189503968768767
Validation loss: 2.587338613159863

Epoch: 5| Step: 7
Training loss: 2.1148225871317727
Validation loss: 2.5852146281507573

Epoch: 5| Step: 8
Training loss: 2.872636237968267
Validation loss: 2.5972723727271956

Epoch: 5| Step: 9
Training loss: 2.7841258236141355
Validation loss: 2.5820069382879978

Epoch: 5| Step: 10
Training loss: 2.280831912672915
Validation loss: 2.545716562344399

Epoch: 332| Step: 0
Training loss: 2.8701706836201906
Validation loss: 2.5600795404321355

Epoch: 5| Step: 1
Training loss: 2.8897789619156806
Validation loss: 2.535174124540129

Epoch: 5| Step: 2
Training loss: 2.51164233623922
Validation loss: 2.5267729437875577

Epoch: 5| Step: 3
Training loss: 2.4549821760536696
Validation loss: 2.5167163816937936

Epoch: 5| Step: 4
Training loss: 2.536408431066852
Validation loss: 2.5146408525371045

Epoch: 5| Step: 5
Training loss: 2.5203155952713674
Validation loss: 2.4991441071689935

Epoch: 5| Step: 6
Training loss: 2.38105784364281
Validation loss: 2.5231741871934337

Epoch: 5| Step: 7
Training loss: 2.0615127975210976
Validation loss: 2.5424437196613927

Epoch: 5| Step: 8
Training loss: 2.4384583765466226
Validation loss: 2.5320161515534814

Epoch: 5| Step: 9
Training loss: 2.399563702026476
Validation loss: 2.524203818916688

Epoch: 5| Step: 10
Training loss: 2.061825150566257
Validation loss: 2.55489735329253

Epoch: 333| Step: 0
Training loss: 2.4213391111062696
Validation loss: 2.5667601188290554

Epoch: 5| Step: 1
Training loss: 2.424537622475736
Validation loss: 2.5886339479965277

Epoch: 5| Step: 2
Training loss: 2.493944654779066
Validation loss: 2.578346969779011

Epoch: 5| Step: 3
Training loss: 2.5571480663456567
Validation loss: 2.5483223276473335

Epoch: 5| Step: 4
Training loss: 2.888398999060032
Validation loss: 2.5307962954662546

Epoch: 5| Step: 5
Training loss: 2.0848415510315683
Validation loss: 2.5356893063228467

Epoch: 5| Step: 6
Training loss: 2.5514917012266025
Validation loss: 2.5387252747747584

Epoch: 5| Step: 7
Training loss: 2.4775760153186277
Validation loss: 2.508186794651972

Epoch: 5| Step: 8
Training loss: 2.449150510381847
Validation loss: 2.5196183959307925

Epoch: 5| Step: 9
Training loss: 2.334102356294999
Validation loss: 2.52350941780979

Epoch: 5| Step: 10
Training loss: 2.4488551403800254
Validation loss: 2.5308297599818497

Epoch: 334| Step: 0
Training loss: 2.6480980939760945
Validation loss: 2.5387790013666405

Epoch: 5| Step: 1
Training loss: 2.2044861829345885
Validation loss: 2.54646260586532

Epoch: 5| Step: 2
Training loss: 2.3424653665268322
Validation loss: 2.5460681886776264

Epoch: 5| Step: 3
Training loss: 2.8096221611428485
Validation loss: 2.5830992580382546

Epoch: 5| Step: 4
Training loss: 2.0665671965544106
Validation loss: 2.6175417179640856

Epoch: 5| Step: 5
Training loss: 1.94874686299011
Validation loss: 2.5971224906104533

Epoch: 5| Step: 6
Training loss: 2.7305721323418424
Validation loss: 2.5847991717079086

Epoch: 5| Step: 7
Training loss: 2.2453538820492294
Validation loss: 2.5460576504216057

Epoch: 5| Step: 8
Training loss: 2.3111774683661146
Validation loss: 2.5232534430021234

Epoch: 5| Step: 9
Training loss: 3.035004011776832
Validation loss: 2.5015127107172366

Epoch: 5| Step: 10
Training loss: 2.6460931805547254
Validation loss: 2.4887937241904794

Epoch: 335| Step: 0
Training loss: 2.3085098896835166
Validation loss: 2.4812520983977366

Epoch: 5| Step: 1
Training loss: 2.3786199989416623
Validation loss: 2.469628569853937

Epoch: 5| Step: 2
Training loss: 2.5399768298136087
Validation loss: 2.4879893240835282

Epoch: 5| Step: 3
Training loss: 2.3324288136371525
Validation loss: 2.5096608837180923

Epoch: 5| Step: 4
Training loss: 2.8637626628354336
Validation loss: 2.5520987450990473

Epoch: 5| Step: 5
Training loss: 1.9308547840839425
Validation loss: 2.6017392114598072

Epoch: 5| Step: 6
Training loss: 2.6987207949861673
Validation loss: 2.6385100559255656

Epoch: 5| Step: 7
Training loss: 2.444178699247455
Validation loss: 2.611302508378876

Epoch: 5| Step: 8
Training loss: 2.683395178498776
Validation loss: 2.598598389127545

Epoch: 5| Step: 9
Training loss: 2.0191351319465447
Validation loss: 2.5470670024631406

Epoch: 5| Step: 10
Training loss: 3.0587847224962825
Validation loss: 2.534225437847446

Epoch: 336| Step: 0
Training loss: 2.2151879744495715
Validation loss: 2.5133914579632224

Epoch: 5| Step: 1
Training loss: 2.819290948290162
Validation loss: 2.4973687486519593

Epoch: 5| Step: 2
Training loss: 2.2401646650621507
Validation loss: 2.500379283395425

Epoch: 5| Step: 3
Training loss: 2.874492102831936
Validation loss: 2.5113634055157483

Epoch: 5| Step: 4
Training loss: 2.8808421609655195
Validation loss: 2.529148998713373

Epoch: 5| Step: 5
Training loss: 2.4111895703247743
Validation loss: 2.5739663052104387

Epoch: 5| Step: 6
Training loss: 2.7433616102606853
Validation loss: 2.5819222793990275

Epoch: 5| Step: 7
Training loss: 2.2553364729799763
Validation loss: 2.5919831068675188

Epoch: 5| Step: 8
Training loss: 2.1278871109210025
Validation loss: 2.589136386414408

Epoch: 5| Step: 9
Training loss: 2.3134851161658565
Validation loss: 2.5596638833559395

Epoch: 5| Step: 10
Training loss: 1.8688543692439983
Validation loss: 2.5532342367841703

Epoch: 337| Step: 0
Training loss: 2.176206591686485
Validation loss: 2.5195019985395097

Epoch: 5| Step: 1
Training loss: 2.7012204202411967
Validation loss: 2.4992049460423225

Epoch: 5| Step: 2
Training loss: 2.4582453458740594
Validation loss: 2.489685879936033

Epoch: 5| Step: 3
Training loss: 2.3288559758167553
Validation loss: 2.4626120302026977

Epoch: 5| Step: 4
Training loss: 2.6215742554800636
Validation loss: 2.463481862199214

Epoch: 5| Step: 5
Training loss: 2.1003280474248105
Validation loss: 2.4762551261305186

Epoch: 5| Step: 6
Training loss: 2.5898130941518502
Validation loss: 2.484746591365374

Epoch: 5| Step: 7
Training loss: 2.913815403502507
Validation loss: 2.502687647699967

Epoch: 5| Step: 8
Training loss: 2.4841107881752107
Validation loss: 2.5419603070903327

Epoch: 5| Step: 9
Training loss: 2.2223559882382147
Validation loss: 2.5923284358059244

Epoch: 5| Step: 10
Training loss: 2.376523382603572
Validation loss: 2.6685490383199872

Epoch: 338| Step: 0
Training loss: 2.9452302551928797
Validation loss: 2.706268722597112

Epoch: 5| Step: 1
Training loss: 2.844351233339271
Validation loss: 2.635624076609285

Epoch: 5| Step: 2
Training loss: 1.9528785244870168
Validation loss: 2.599079528175272

Epoch: 5| Step: 3
Training loss: 2.142382046847798
Validation loss: 2.579469887727395

Epoch: 5| Step: 4
Training loss: 2.7630113223406836
Validation loss: 2.569476568222078

Epoch: 5| Step: 5
Training loss: 2.6341076843100972
Validation loss: 2.539417034478066

Epoch: 5| Step: 6
Training loss: 2.4152597958163056
Validation loss: 2.5368918000721483

Epoch: 5| Step: 7
Training loss: 1.9775114533180713
Validation loss: 2.518429866269245

Epoch: 5| Step: 8
Training loss: 2.710001143423592
Validation loss: 2.5140475396793542

Epoch: 5| Step: 9
Training loss: 2.2096646692291237
Validation loss: 2.523192431104244

Epoch: 5| Step: 10
Training loss: 2.7819350181246794
Validation loss: 2.5291649188561234

Epoch: 339| Step: 0
Training loss: 2.5628864648195355
Validation loss: 2.5701695011656858

Epoch: 5| Step: 1
Training loss: 2.149566575653167
Validation loss: 2.592680110355985

Epoch: 5| Step: 2
Training loss: 2.3085965384064697
Validation loss: 2.590974496210275

Epoch: 5| Step: 3
Training loss: 2.257942169584182
Validation loss: 2.577503634363994

Epoch: 5| Step: 4
Training loss: 3.0204367717155
Validation loss: 2.626113503078708

Epoch: 5| Step: 5
Training loss: 2.451028985345872
Validation loss: 2.6076949932044884

Epoch: 5| Step: 6
Training loss: 2.4290664713257932
Validation loss: 2.603984698100974

Epoch: 5| Step: 7
Training loss: 2.2908341253766573
Validation loss: 2.5786727228988258

Epoch: 5| Step: 8
Training loss: 2.500614376870273
Validation loss: 2.593549063082806

Epoch: 5| Step: 9
Training loss: 2.493318211548724
Validation loss: 2.5822624609514335

Epoch: 5| Step: 10
Training loss: 2.210002364420597
Validation loss: 2.5472499365837313

Epoch: 340| Step: 0
Training loss: 2.5745812307031155
Validation loss: 2.5376785946929377

Epoch: 5| Step: 1
Training loss: 2.591579770249491
Validation loss: 2.5343963623360413

Epoch: 5| Step: 2
Training loss: 2.438339382311014
Validation loss: 2.544016119501201

Epoch: 5| Step: 3
Training loss: 2.720009873596671
Validation loss: 2.562705116056242

Epoch: 5| Step: 4
Training loss: 2.453692716764514
Validation loss: 2.5603044419727508

Epoch: 5| Step: 5
Training loss: 2.625078200129134
Validation loss: 2.5890193991987487

Epoch: 5| Step: 6
Training loss: 2.3278054651734554
Validation loss: 2.6255855278386235

Epoch: 5| Step: 7
Training loss: 2.2437312430870224
Validation loss: 2.639640456608124

Epoch: 5| Step: 8
Training loss: 1.9527245683265455
Validation loss: 2.6488901711509665

Epoch: 5| Step: 9
Training loss: 2.9405822815665412
Validation loss: 2.655503232582086

Epoch: 5| Step: 10
Training loss: 1.422653320577623
Validation loss: 2.59211207975637

Epoch: 341| Step: 0
Training loss: 2.02400935866714
Validation loss: 2.5553551206357255

Epoch: 5| Step: 1
Training loss: 3.057165677249013
Validation loss: 2.546156514585037

Epoch: 5| Step: 2
Training loss: 2.574456396406727
Validation loss: 2.5463660067697345

Epoch: 5| Step: 3
Training loss: 2.2500595508748007
Validation loss: 2.5715822460446214

Epoch: 5| Step: 4
Training loss: 2.556606586832954
Validation loss: 2.603239597485255

Epoch: 5| Step: 5
Training loss: 2.172892051062378
Validation loss: 2.602919995260017

Epoch: 5| Step: 6
Training loss: 2.3992901507292683
Validation loss: 2.586900796894454

Epoch: 5| Step: 7
Training loss: 2.1718689623412595
Validation loss: 2.588113353491355

Epoch: 5| Step: 8
Training loss: 2.4621272042119307
Validation loss: 2.5618919493517605

Epoch: 5| Step: 9
Training loss: 2.2365031744399078
Validation loss: 2.5429980289230496

Epoch: 5| Step: 10
Training loss: 2.5700792943099104
Validation loss: 2.5194251716466556

Epoch: 342| Step: 0
Training loss: 2.479737662160743
Validation loss: 2.5200768341351307

Epoch: 5| Step: 1
Training loss: 2.3600117411563857
Validation loss: 2.5234078874434394

Epoch: 5| Step: 2
Training loss: 1.7717518462586879
Validation loss: 2.507213761414354

Epoch: 5| Step: 3
Training loss: 2.7107061897557574
Validation loss: 2.517936973537608

Epoch: 5| Step: 4
Training loss: 1.9777303871568155
Validation loss: 2.5192448991232776

Epoch: 5| Step: 5
Training loss: 3.011607602217036
Validation loss: 2.5288122245793034

Epoch: 5| Step: 6
Training loss: 2.3264946061085543
Validation loss: 2.529528327196668

Epoch: 5| Step: 7
Training loss: 2.5702659347629444
Validation loss: 2.559720196090493

Epoch: 5| Step: 8
Training loss: 2.7583825924288674
Validation loss: 2.585936165605342

Epoch: 5| Step: 9
Training loss: 2.3705088665467913
Validation loss: 2.6403036449305444

Epoch: 5| Step: 10
Training loss: 1.8294857210330298
Validation loss: 2.664056019830321

Epoch: 343| Step: 0
Training loss: 2.7371774317938065
Validation loss: 2.7063850140852757

Epoch: 5| Step: 1
Training loss: 2.696381287895526
Validation loss: 2.7045432287247593

Epoch: 5| Step: 2
Training loss: 2.1642895520907794
Validation loss: 2.625989304638247

Epoch: 5| Step: 3
Training loss: 2.6762041857529395
Validation loss: 2.573051932996743

Epoch: 5| Step: 4
Training loss: 1.9859881714990109
Validation loss: 2.537437582629908

Epoch: 5| Step: 5
Training loss: 2.378713214728157
Validation loss: 2.5205320145817187

Epoch: 5| Step: 6
Training loss: 2.4374975546800135
Validation loss: 2.4910251693219716

Epoch: 5| Step: 7
Training loss: 2.5646879578194084
Validation loss: 2.491153818087651

Epoch: 5| Step: 8
Training loss: 2.429731264364191
Validation loss: 2.5065706531503187

Epoch: 5| Step: 9
Training loss: 1.99179982919992
Validation loss: 2.5201574955409205

Epoch: 5| Step: 10
Training loss: 2.298476303260573
Validation loss: 2.4886490822071017

Epoch: 344| Step: 0
Training loss: 1.9743984271981452
Validation loss: 2.5325219905634535

Epoch: 5| Step: 1
Training loss: 2.2708231257871274
Validation loss: 2.564752533624996

Epoch: 5| Step: 2
Training loss: 2.36798183093962
Validation loss: 2.6363947649170574

Epoch: 5| Step: 3
Training loss: 2.214287582080247
Validation loss: 2.6823219712565822

Epoch: 5| Step: 4
Training loss: 2.2835222189339945
Validation loss: 2.734183117862402

Epoch: 5| Step: 5
Training loss: 2.559191824630887
Validation loss: 2.7245398880807943

Epoch: 5| Step: 6
Training loss: 2.695821255200395
Validation loss: 2.6677287352364414

Epoch: 5| Step: 7
Training loss: 2.235243195139727
Validation loss: 2.5841727383251025

Epoch: 5| Step: 8
Training loss: 3.1165936126578906
Validation loss: 2.5274181898638575

Epoch: 5| Step: 9
Training loss: 2.29084848768269
Validation loss: 2.510751883551068

Epoch: 5| Step: 10
Training loss: 2.4768204900618525
Validation loss: 2.4965467752976025

Epoch: 345| Step: 0
Training loss: 2.658407614057797
Validation loss: 2.4822619349461568

Epoch: 5| Step: 1
Training loss: 2.424181031042164
Validation loss: 2.5143750218372474

Epoch: 5| Step: 2
Training loss: 2.4810897890731143
Validation loss: 2.5276362546927107

Epoch: 5| Step: 3
Training loss: 2.0625751366078355
Validation loss: 2.5787142271994674

Epoch: 5| Step: 4
Training loss: 1.917913432207294
Validation loss: 2.5908449848058854

Epoch: 5| Step: 5
Training loss: 2.412853543165055
Validation loss: 2.6050524898661576

Epoch: 5| Step: 6
Training loss: 2.7305264664690827
Validation loss: 2.6230268118372972

Epoch: 5| Step: 7
Training loss: 2.6635030119807115
Validation loss: 2.6271106293829964

Epoch: 5| Step: 8
Training loss: 2.540677070787892
Validation loss: 2.6198766629307424

Epoch: 5| Step: 9
Training loss: 2.000112530403563
Validation loss: 2.5959354123459137

Epoch: 5| Step: 10
Training loss: 2.3521913213636734
Validation loss: 2.592223425744932

Epoch: 346| Step: 0
Training loss: 2.230608880606586
Validation loss: 2.565907307698258

Epoch: 5| Step: 1
Training loss: 2.3836034243827147
Validation loss: 2.556370449049048

Epoch: 5| Step: 2
Training loss: 2.53167447899054
Validation loss: 2.5498969658648147

Epoch: 5| Step: 3
Training loss: 2.1907405284070443
Validation loss: 2.524819524458422

Epoch: 5| Step: 4
Training loss: 2.630708119462961
Validation loss: 2.481619353692686

Epoch: 5| Step: 5
Training loss: 2.2187306577887105
Validation loss: 2.513025742596747

Epoch: 5| Step: 6
Training loss: 2.0744385108983217
Validation loss: 2.521349587015971

Epoch: 5| Step: 7
Training loss: 2.6024958222252166
Validation loss: 2.5560610950923968

Epoch: 5| Step: 8
Training loss: 2.433089839388267
Validation loss: 2.6126464404300394

Epoch: 5| Step: 9
Training loss: 2.4017884147576187
Validation loss: 2.6356065448175148

Epoch: 5| Step: 10
Training loss: 2.2967391200972114
Validation loss: 2.657090074377608

Epoch: 347| Step: 0
Training loss: 2.1513288427841344
Validation loss: 2.670373987823598

Epoch: 5| Step: 1
Training loss: 2.0873549999199748
Validation loss: 2.648375491295619

Epoch: 5| Step: 2
Training loss: 2.0550776934265254
Validation loss: 2.618500697358627

Epoch: 5| Step: 3
Training loss: 2.2328966491944686
Validation loss: 2.6257357750337653

Epoch: 5| Step: 4
Training loss: 2.7275457057742227
Validation loss: 2.613572435149645

Epoch: 5| Step: 5
Training loss: 2.4569609954930143
Validation loss: 2.6184845699233894

Epoch: 5| Step: 6
Training loss: 2.488488013571487
Validation loss: 2.5987412382597066

Epoch: 5| Step: 7
Training loss: 2.6877137919710257
Validation loss: 2.6043484991437458

Epoch: 5| Step: 8
Training loss: 2.4387578408620167
Validation loss: 2.5864920945127956

Epoch: 5| Step: 9
Training loss: 2.0422308265625615
Validation loss: 2.5814528301185513

Epoch: 5| Step: 10
Training loss: 2.3400644443473624
Validation loss: 2.5612113357510125

Epoch: 348| Step: 0
Training loss: 2.017211526244526
Validation loss: 2.5386043900775612

Epoch: 5| Step: 1
Training loss: 1.4836854638170425
Validation loss: 2.526434996496113

Epoch: 5| Step: 2
Training loss: 2.4955764735983132
Validation loss: 2.5448072807135187

Epoch: 5| Step: 3
Training loss: 2.54009275221996
Validation loss: 2.576303084282927

Epoch: 5| Step: 4
Training loss: 2.2469299352135
Validation loss: 2.595767876361339

Epoch: 5| Step: 5
Training loss: 2.5742054129965584
Validation loss: 2.6162057577120783

Epoch: 5| Step: 6
Training loss: 2.811952410478379
Validation loss: 2.6254291837907866

Epoch: 5| Step: 7
Training loss: 2.582242694455509
Validation loss: 2.632002969838016

Epoch: 5| Step: 8
Training loss: 2.0810435745465248
Validation loss: 2.600273682473078

Epoch: 5| Step: 9
Training loss: 2.2962278116033614
Validation loss: 2.572962160984059

Epoch: 5| Step: 10
Training loss: 2.4159930265907046
Validation loss: 2.5685858900602474

Epoch: 349| Step: 0
Training loss: 2.503067233101279
Validation loss: 2.538398083003117

Epoch: 5| Step: 1
Training loss: 2.211877414155555
Validation loss: 2.5301823624907316

Epoch: 5| Step: 2
Training loss: 2.2747001156861293
Validation loss: 2.539246574147232

Epoch: 5| Step: 3
Training loss: 2.5749117160218127
Validation loss: 2.5566316294218274

Epoch: 5| Step: 4
Training loss: 2.387738448613419
Validation loss: 2.6047025546729943

Epoch: 5| Step: 5
Training loss: 2.479631417787453
Validation loss: 2.6429603222117435

Epoch: 5| Step: 6
Training loss: 2.2957159738147004
Validation loss: 2.6274123389761788

Epoch: 5| Step: 7
Training loss: 1.8178997503742853
Validation loss: 2.617944418472961

Epoch: 5| Step: 8
Training loss: 2.5115542439506253
Validation loss: 2.576509335262151

Epoch: 5| Step: 9
Training loss: 1.912024085974515
Validation loss: 2.558734914014606

Epoch: 5| Step: 10
Training loss: 2.513762359057622
Validation loss: 2.533939057930448

Epoch: 350| Step: 0
Training loss: 2.4863229468352404
Validation loss: 2.5216536753687944

Epoch: 5| Step: 1
Training loss: 2.2439103900676525
Validation loss: 2.5274417445670974

Epoch: 5| Step: 2
Training loss: 2.2726400228572126
Validation loss: 2.570464608625376

Epoch: 5| Step: 3
Training loss: 3.007799817343391
Validation loss: 2.559076633145537

Epoch: 5| Step: 4
Training loss: 1.8248696319837678
Validation loss: 2.5398576136108946

Epoch: 5| Step: 5
Training loss: 2.164189744644396
Validation loss: 2.555266352205258

Epoch: 5| Step: 6
Training loss: 2.478648176924903
Validation loss: 2.5703479455081677

Epoch: 5| Step: 7
Training loss: 2.316764302105946
Validation loss: 2.587413361109331

Epoch: 5| Step: 8
Training loss: 2.5049023246376976
Validation loss: 2.5893474922466417

Epoch: 5| Step: 9
Training loss: 2.3713183728678207
Validation loss: 2.5804882903001247

Epoch: 5| Step: 10
Training loss: 2.0466469208119995
Validation loss: 2.549760346810194

Epoch: 351| Step: 0
Training loss: 2.0277222737535627
Validation loss: 2.5277325391261583

Epoch: 5| Step: 1
Training loss: 1.8917453693480926
Validation loss: 2.5251833124750087

Epoch: 5| Step: 2
Training loss: 2.5286627839944753
Validation loss: 2.5148782846676614

Epoch: 5| Step: 3
Training loss: 2.6737715922050476
Validation loss: 2.505512247682251

Epoch: 5| Step: 4
Training loss: 2.499605624563769
Validation loss: 2.5298148385632704

Epoch: 5| Step: 5
Training loss: 2.5711647174584087
Validation loss: 2.5625917591840834

Epoch: 5| Step: 6
Training loss: 1.4530416485251318
Validation loss: 2.5698726110694405

Epoch: 5| Step: 7
Training loss: 2.0484244037037853
Validation loss: 2.5947894491838763

Epoch: 5| Step: 8
Training loss: 2.3474804499810458
Validation loss: 2.6203967661859804

Epoch: 5| Step: 9
Training loss: 2.7536656484269137
Validation loss: 2.6450999274340767

Epoch: 5| Step: 10
Training loss: 2.416303662189199
Validation loss: 2.6490783216207894

Epoch: 352| Step: 0
Training loss: 2.453553083449976
Validation loss: 2.6307107496531237

Epoch: 5| Step: 1
Training loss: 2.1695876117290727
Validation loss: 2.5992541877906565

Epoch: 5| Step: 2
Training loss: 2.7190825160343897
Validation loss: 2.578380511646535

Epoch: 5| Step: 3
Training loss: 2.372911136967951
Validation loss: 2.5507786308608926

Epoch: 5| Step: 4
Training loss: 2.6772079339822192
Validation loss: 2.5390372720100847

Epoch: 5| Step: 5
Training loss: 2.232727510451128
Validation loss: 2.5306322637091925

Epoch: 5| Step: 6
Training loss: 1.9574038822745565
Validation loss: 2.543829401385536

Epoch: 5| Step: 7
Training loss: 2.1737737246113147
Validation loss: 2.548572987137968

Epoch: 5| Step: 8
Training loss: 2.047734669708665
Validation loss: 2.5855511957159587

Epoch: 5| Step: 9
Training loss: 2.083908179766272
Validation loss: 2.6259842866720913

Epoch: 5| Step: 10
Training loss: 2.3434421591452343
Validation loss: 2.6450727672993612

Epoch: 353| Step: 0
Training loss: 2.6263920862035075
Validation loss: 2.6729906390744045

Epoch: 5| Step: 1
Training loss: 2.626319735153609
Validation loss: 2.6858038542432308

Epoch: 5| Step: 2
Training loss: 2.120085137475102
Validation loss: 2.6493505051912307

Epoch: 5| Step: 3
Training loss: 2.42646423651804
Validation loss: 2.598605589927465

Epoch: 5| Step: 4
Training loss: 2.4016091316773847
Validation loss: 2.602875985191783

Epoch: 5| Step: 5
Training loss: 2.3456105286222697
Validation loss: 2.569264844452289

Epoch: 5| Step: 6
Training loss: 1.2884154574303408
Validation loss: 2.5411486707219146

Epoch: 5| Step: 7
Training loss: 2.5530098822611986
Validation loss: 2.528274193687474

Epoch: 5| Step: 8
Training loss: 1.9504482389895137
Validation loss: 2.51955074535833

Epoch: 5| Step: 9
Training loss: 2.4070205445563824
Validation loss: 2.5224187444061332

Epoch: 5| Step: 10
Training loss: 2.2394411500257627
Validation loss: 2.5439525682323314

Epoch: 354| Step: 0
Training loss: 1.9860605005190053
Validation loss: 2.509824434203225

Epoch: 5| Step: 1
Training loss: 2.351770638921245
Validation loss: 2.5239569666719053

Epoch: 5| Step: 2
Training loss: 2.20445665736601
Validation loss: 2.5112947005782247

Epoch: 5| Step: 3
Training loss: 2.2855937832334874
Validation loss: 2.5296246115674013

Epoch: 5| Step: 4
Training loss: 2.3678884947595193
Validation loss: 2.548497594916002

Epoch: 5| Step: 5
Training loss: 2.4461619696276924
Validation loss: 2.5694773664049513

Epoch: 5| Step: 6
Training loss: 2.499643014215599
Validation loss: 2.6042360669804716

Epoch: 5| Step: 7
Training loss: 2.245184619848303
Validation loss: 2.63730630019992

Epoch: 5| Step: 8
Training loss: 2.4442272764126836
Validation loss: 2.65187564394256

Epoch: 5| Step: 9
Training loss: 2.4574713623613547
Validation loss: 2.661408937911452

Epoch: 5| Step: 10
Training loss: 1.5098695312117991
Validation loss: 2.611979509535048

Epoch: 355| Step: 0
Training loss: 2.0797982040965377
Validation loss: 2.6158291000651164

Epoch: 5| Step: 1
Training loss: 2.529397639914864
Validation loss: 2.5780598393245016

Epoch: 5| Step: 2
Training loss: 2.4840014674724475
Validation loss: 2.5654816966775225

Epoch: 5| Step: 3
Training loss: 2.3097655135202597
Validation loss: 2.5783555107693603

Epoch: 5| Step: 4
Training loss: 2.155849253690682
Validation loss: 2.6298439084505882

Epoch: 5| Step: 5
Training loss: 2.135761834757595
Validation loss: 2.6537050876601214

Epoch: 5| Step: 6
Training loss: 2.405770092952114
Validation loss: 2.682423860370977

Epoch: 5| Step: 7
Training loss: 2.229330811443606
Validation loss: 2.64089095864913

Epoch: 5| Step: 8
Training loss: 2.635744629809678
Validation loss: 2.6322867079434955

Epoch: 5| Step: 9
Training loss: 1.777358572761851
Validation loss: 2.6168249529002776

Epoch: 5| Step: 10
Training loss: 2.0776414810646067
Validation loss: 2.5942727827346164

Epoch: 356| Step: 0
Training loss: 2.5156413960366786
Validation loss: 2.5822426348877388

Epoch: 5| Step: 1
Training loss: 2.7460391390540217
Validation loss: 2.58433334797733

Epoch: 5| Step: 2
Training loss: 1.7428265413125994
Validation loss: 2.536678437989412

Epoch: 5| Step: 3
Training loss: 2.1895884762118913
Validation loss: 2.5410220739057

Epoch: 5| Step: 4
Training loss: 2.59254914946211
Validation loss: 2.5313984867743655

Epoch: 5| Step: 5
Training loss: 2.5699120299427154
Validation loss: 2.5676270902867175

Epoch: 5| Step: 6
Training loss: 2.0311718265456116
Validation loss: 2.5801421576373933

Epoch: 5| Step: 7
Training loss: 2.251130879505636
Validation loss: 2.5805125984374113

Epoch: 5| Step: 8
Training loss: 2.133498979137776
Validation loss: 2.579203186606245

Epoch: 5| Step: 9
Training loss: 1.9734049669787215
Validation loss: 2.551924046628233

Epoch: 5| Step: 10
Training loss: 1.6896546348393744
Validation loss: 2.567057702452498

Epoch: 357| Step: 0
Training loss: 2.4624129459077975
Validation loss: 2.6024572584179957

Epoch: 5| Step: 1
Training loss: 2.086512111428471
Validation loss: 2.617196339356763

Epoch: 5| Step: 2
Training loss: 2.7589448759926083
Validation loss: 2.6274925338389106

Epoch: 5| Step: 3
Training loss: 2.6837461114578964
Validation loss: 2.5954733800393486

Epoch: 5| Step: 4
Training loss: 2.1579620640967176
Validation loss: 2.585646609471645

Epoch: 5| Step: 5
Training loss: 1.917945877218503
Validation loss: 2.5751811263994346

Epoch: 5| Step: 6
Training loss: 1.6585109321664053
Validation loss: 2.5868761513870804

Epoch: 5| Step: 7
Training loss: 2.6252177011951243
Validation loss: 2.595626955491845

Epoch: 5| Step: 8
Training loss: 2.3468271019488527
Validation loss: 2.6212148384569356

Epoch: 5| Step: 9
Training loss: 1.794770775081336
Validation loss: 2.6260196953451116

Epoch: 5| Step: 10
Training loss: 1.9092594842259365
Validation loss: 2.6189965314174755

Epoch: 358| Step: 0
Training loss: 1.9691492917067448
Validation loss: 2.6297632422984494

Epoch: 5| Step: 1
Training loss: 2.2260226481982945
Validation loss: 2.629649838747152

Epoch: 5| Step: 2
Training loss: 2.1855706562183603
Validation loss: 2.626599861957769

Epoch: 5| Step: 3
Training loss: 2.2940999608631114
Validation loss: 2.6530436418893766

Epoch: 5| Step: 4
Training loss: 2.190336840256631
Validation loss: 2.6359076525110345

Epoch: 5| Step: 5
Training loss: 2.092194733952615
Validation loss: 2.6049096551720856

Epoch: 5| Step: 6
Training loss: 2.4110259182651155
Validation loss: 2.5917837362678706

Epoch: 5| Step: 7
Training loss: 2.5317171395724065
Validation loss: 2.5862284891526994

Epoch: 5| Step: 8
Training loss: 2.6282028458867472
Validation loss: 2.5718281524852764

Epoch: 5| Step: 9
Training loss: 1.6822390316818074
Validation loss: 2.5768677087868954

Epoch: 5| Step: 10
Training loss: 2.2705685055732134
Validation loss: 2.5452457211508492

Epoch: 359| Step: 0
Training loss: 2.3250460138177114
Validation loss: 2.5430644972689618

Epoch: 5| Step: 1
Training loss: 2.1250995163896036
Validation loss: 2.5629992855265744

Epoch: 5| Step: 2
Training loss: 2.3596317581020974
Validation loss: 2.5846163411468566

Epoch: 5| Step: 3
Training loss: 2.4977206329552804
Validation loss: 2.590259474152899

Epoch: 5| Step: 4
Training loss: 1.825970415232927
Validation loss: 2.5781017055061937

Epoch: 5| Step: 5
Training loss: 2.0905297410186483
Validation loss: 2.544964546214378

Epoch: 5| Step: 6
Training loss: 2.1345143218249167
Validation loss: 2.5342487335361987

Epoch: 5| Step: 7
Training loss: 2.2906068142823464
Validation loss: 2.5825521840834518

Epoch: 5| Step: 8
Training loss: 2.647345753932236
Validation loss: 2.6105621557271266

Epoch: 5| Step: 9
Training loss: 2.0841388162518624
Validation loss: 2.6392975332291506

Epoch: 5| Step: 10
Training loss: 1.8405027080123202
Validation loss: 2.6850227095306063

Epoch: 360| Step: 0
Training loss: 2.562600947927057
Validation loss: 2.730407481308829

Epoch: 5| Step: 1
Training loss: 1.9972685400741794
Validation loss: 2.7217442496660587

Epoch: 5| Step: 2
Training loss: 1.711617669899618
Validation loss: 2.7235030532559215

Epoch: 5| Step: 3
Training loss: 2.658994446185202
Validation loss: 2.668584402899162

Epoch: 5| Step: 4
Training loss: 2.018807906982586
Validation loss: 2.6670042304671058

Epoch: 5| Step: 5
Training loss: 2.603906806696235
Validation loss: 2.6300639867186693

Epoch: 5| Step: 6
Training loss: 2.2769090293165433
Validation loss: 2.576511373032352

Epoch: 5| Step: 7
Training loss: 2.5617888789744194
Validation loss: 2.5549530606770015

Epoch: 5| Step: 8
Training loss: 1.8975603879584693
Validation loss: 2.5603029920855302

Epoch: 5| Step: 9
Training loss: 2.001517554559469
Validation loss: 2.5571954308615092

Epoch: 5| Step: 10
Training loss: 2.0120767515570805
Validation loss: 2.5525363860686014

Epoch: 361| Step: 0
Training loss: 1.9944149355474872
Validation loss: 2.5620553315902774

Epoch: 5| Step: 1
Training loss: 2.094312222279001
Validation loss: 2.575907066723273

Epoch: 5| Step: 2
Training loss: 2.2943260945402635
Validation loss: 2.636371076078446

Epoch: 5| Step: 3
Training loss: 2.134861894201124
Validation loss: 2.6499721281846162

Epoch: 5| Step: 4
Training loss: 2.3605622594856936
Validation loss: 2.671403625622995

Epoch: 5| Step: 5
Training loss: 2.446543033535565
Validation loss: 2.6177643053544384

Epoch: 5| Step: 6
Training loss: 2.470620714102361
Validation loss: 2.606915955059114

Epoch: 5| Step: 7
Training loss: 1.7512424009758638
Validation loss: 2.568023484748727

Epoch: 5| Step: 8
Training loss: 2.0758203332658045
Validation loss: 2.603616086449401

Epoch: 5| Step: 9
Training loss: 1.7995724541147662
Validation loss: 2.6083768846931323

Epoch: 5| Step: 10
Training loss: 2.585714094301983
Validation loss: 2.623422811018115

Epoch: 362| Step: 0
Training loss: 1.5964597218035488
Validation loss: 2.6097902096946086

Epoch: 5| Step: 1
Training loss: 1.9741897514456748
Validation loss: 2.5750451150604365

Epoch: 5| Step: 2
Training loss: 1.8998529628276475
Validation loss: 2.5910783893829588

Epoch: 5| Step: 3
Training loss: 2.492219739364602
Validation loss: 2.586945841801883

Epoch: 5| Step: 4
Training loss: 2.4150289927888533
Validation loss: 2.565585422089444

Epoch: 5| Step: 5
Training loss: 2.272977487488684
Validation loss: 2.569918395363183

Epoch: 5| Step: 6
Training loss: 2.532836605194998
Validation loss: 2.5798116775549618

Epoch: 5| Step: 7
Training loss: 2.2913513197819544
Validation loss: 2.5737097407463194

Epoch: 5| Step: 8
Training loss: 1.9575173998140991
Validation loss: 2.5802670963930163

Epoch: 5| Step: 9
Training loss: 2.4272875938635647
Validation loss: 2.6024727409470105

Epoch: 5| Step: 10
Training loss: 2.028455719631648
Validation loss: 2.607217835419258

Epoch: 363| Step: 0
Training loss: 1.8757163904456544
Validation loss: 2.597540469615254

Epoch: 5| Step: 1
Training loss: 1.9062546901957862
Validation loss: 2.620940507695238

Epoch: 5| Step: 2
Training loss: 2.256943373720616
Validation loss: 2.6373675319863965

Epoch: 5| Step: 3
Training loss: 2.117405391052307
Validation loss: 2.6234885355293462

Epoch: 5| Step: 4
Training loss: 2.0375104236921224
Validation loss: 2.6459060018176976

Epoch: 5| Step: 5
Training loss: 2.4448208543172627
Validation loss: 2.6606230480485795

Epoch: 5| Step: 6
Training loss: 2.3320861503234647
Validation loss: 2.6478668981460807

Epoch: 5| Step: 7
Training loss: 1.6214535233538476
Validation loss: 2.6386527117868743

Epoch: 5| Step: 8
Training loss: 2.501752906429386
Validation loss: 2.609811299458847

Epoch: 5| Step: 9
Training loss: 2.3271642148935374
Validation loss: 2.5841620429615624

Epoch: 5| Step: 10
Training loss: 2.361280871503002
Validation loss: 2.571231038952214

Epoch: 364| Step: 0
Training loss: 2.002121991734669
Validation loss: 2.558006488630857

Epoch: 5| Step: 1
Training loss: 2.114107601476935
Validation loss: 2.581958335028252

Epoch: 5| Step: 2
Training loss: 2.0858817218080814
Validation loss: 2.5728093849331937

Epoch: 5| Step: 3
Training loss: 2.1895704008301835
Validation loss: 2.56015915478641

Epoch: 5| Step: 4
Training loss: 2.4329044351620355
Validation loss: 2.584076438775944

Epoch: 5| Step: 5
Training loss: 2.302767817260077
Validation loss: 2.5887215722373362

Epoch: 5| Step: 6
Training loss: 2.1919508204686133
Validation loss: 2.587374653751743

Epoch: 5| Step: 7
Training loss: 2.187837629148039
Validation loss: 2.6338199735015966

Epoch: 5| Step: 8
Training loss: 1.7427304366998357
Validation loss: 2.649442211544198

Epoch: 5| Step: 9
Training loss: 2.2290117679386277
Validation loss: 2.6478356699326397

Epoch: 5| Step: 10
Training loss: 2.342962921226911
Validation loss: 2.658622166963989

Epoch: 365| Step: 0
Training loss: 1.9347740193182401
Validation loss: 2.663843187439583

Epoch: 5| Step: 1
Training loss: 1.9528799895150972
Validation loss: 2.668659035686526

Epoch: 5| Step: 2
Training loss: 2.1765828873116995
Validation loss: 2.667617831706488

Epoch: 5| Step: 3
Training loss: 2.403189359877051
Validation loss: 2.6703104656860273

Epoch: 5| Step: 4
Training loss: 2.3045866346108586
Validation loss: 2.657081934093098

Epoch: 5| Step: 5
Training loss: 2.0314095067706064
Validation loss: 2.634157932636828

Epoch: 5| Step: 6
Training loss: 2.265272231426215
Validation loss: 2.603775302807203

Epoch: 5| Step: 7
Training loss: 1.911286127161915
Validation loss: 2.5832584368923293

Epoch: 5| Step: 8
Training loss: 2.3369277335188294
Validation loss: 2.5603204637726535

Epoch: 5| Step: 9
Training loss: 2.6050492482280174
Validation loss: 2.5559254203727098

Epoch: 5| Step: 10
Training loss: 2.085652421194311
Validation loss: 2.5566830705460135

Epoch: 366| Step: 0
Training loss: 2.2954701389638053
Validation loss: 2.5615678828201647

Epoch: 5| Step: 1
Training loss: 1.908115474753372
Validation loss: 2.5863972125043437

Epoch: 5| Step: 2
Training loss: 2.3829599803873
Validation loss: 2.6296331104174198

Epoch: 5| Step: 3
Training loss: 2.0457751398556887
Validation loss: 2.679067725082095

Epoch: 5| Step: 4
Training loss: 2.098017997024483
Validation loss: 2.7180940154675857

Epoch: 5| Step: 5
Training loss: 2.2930812515656176
Validation loss: 2.7085743029399785

Epoch: 5| Step: 6
Training loss: 1.5999739793807382
Validation loss: 2.664554359885096

Epoch: 5| Step: 7
Training loss: 2.558584990741209
Validation loss: 2.6240030056606445

Epoch: 5| Step: 8
Training loss: 2.3719726140337443
Validation loss: 2.612031451121279

Epoch: 5| Step: 9
Training loss: 2.1098608517075514
Validation loss: 2.5468327483354005

Epoch: 5| Step: 10
Training loss: 2.201594693751927
Validation loss: 2.5473258004990313

Epoch: 367| Step: 0
Training loss: 2.321975060998487
Validation loss: 2.5324443539997006

Epoch: 5| Step: 1
Training loss: 2.235430701485192
Validation loss: 2.5346967129377296

Epoch: 5| Step: 2
Training loss: 2.0893126196054594
Validation loss: 2.5470115010523062

Epoch: 5| Step: 3
Training loss: 2.371360499854414
Validation loss: 2.5484410311784846

Epoch: 5| Step: 4
Training loss: 1.9303433929090776
Validation loss: 2.580997562894096

Epoch: 5| Step: 5
Training loss: 1.8175818136027342
Validation loss: 2.6091718775790906

Epoch: 5| Step: 6
Training loss: 2.144305107825558
Validation loss: 2.6448463502689674

Epoch: 5| Step: 7
Training loss: 1.9993262348148673
Validation loss: 2.6275357013149208

Epoch: 5| Step: 8
Training loss: 1.5413204612001943
Validation loss: 2.66736507563186

Epoch: 5| Step: 9
Training loss: 2.4812405564443147
Validation loss: 2.668740173623002

Epoch: 5| Step: 10
Training loss: 2.562835671373956
Validation loss: 2.6426457925442315

Epoch: 368| Step: 0
Training loss: 2.1897181572557076
Validation loss: 2.637373862909643

Epoch: 5| Step: 1
Training loss: 2.0535322647625125
Validation loss: 2.6479112505997575

Epoch: 5| Step: 2
Training loss: 2.5149789300418974
Validation loss: 2.614690965621081

Epoch: 5| Step: 3
Training loss: 2.0322817016336394
Validation loss: 2.5784081182711898

Epoch: 5| Step: 4
Training loss: 2.5944712911338175
Validation loss: 2.54425156904131

Epoch: 5| Step: 5
Training loss: 2.358344250800897
Validation loss: 2.543900510917685

Epoch: 5| Step: 6
Training loss: 1.7606109722582062
Validation loss: 2.5670837446087345

Epoch: 5| Step: 7
Training loss: 2.3455975180809245
Validation loss: 2.611116149296464

Epoch: 5| Step: 8
Training loss: 1.9762635136817266
Validation loss: 2.65100366528222

Epoch: 5| Step: 9
Training loss: 1.79099292803145
Validation loss: 2.651695255189806

Epoch: 5| Step: 10
Training loss: 1.8318668771626807
Validation loss: 2.670596485797202

Epoch: 369| Step: 0
Training loss: 1.5700312879809937
Validation loss: 2.6867806916480763

Epoch: 5| Step: 1
Training loss: 2.6409702413919716
Validation loss: 2.676011507567229

Epoch: 5| Step: 2
Training loss: 2.1159736560126294
Validation loss: 2.66030496488753

Epoch: 5| Step: 3
Training loss: 2.104170758334673
Validation loss: 2.643184845570626

Epoch: 5| Step: 4
Training loss: 2.3854467620505884
Validation loss: 2.6121361806269294

Epoch: 5| Step: 5
Training loss: 2.7086676953622284
Validation loss: 2.595576456071321

Epoch: 5| Step: 6
Training loss: 2.1455223697659878
Validation loss: 2.5728745998653384

Epoch: 5| Step: 7
Training loss: 1.9968939742976295
Validation loss: 2.5509424143448363

Epoch: 5| Step: 8
Training loss: 1.7939395312619488
Validation loss: 2.568577903453945

Epoch: 5| Step: 9
Training loss: 2.0277195694231684
Validation loss: 2.5678449402744326

Epoch: 5| Step: 10
Training loss: 1.7038341060933826
Validation loss: 2.637499512990854

Epoch: 370| Step: 0
Training loss: 1.9712874394104645
Validation loss: 2.6386689088110873

Epoch: 5| Step: 1
Training loss: 1.767728514622625
Validation loss: 2.668665834180236

Epoch: 5| Step: 2
Training loss: 1.7330359711256937
Validation loss: 2.7150702576109347

Epoch: 5| Step: 3
Training loss: 2.0053524873779205
Validation loss: 2.6729459613759396

Epoch: 5| Step: 4
Training loss: 1.9480811948872072
Validation loss: 2.7053517844488737

Epoch: 5| Step: 5
Training loss: 2.188579837757305
Validation loss: 2.719791920385976

Epoch: 5| Step: 6
Training loss: 2.310670077085684
Validation loss: 2.6875865604686404

Epoch: 5| Step: 7
Training loss: 1.5631041312550116
Validation loss: 2.66989538314018

Epoch: 5| Step: 8
Training loss: 2.4098377975709915
Validation loss: 2.6185603212568274

Epoch: 5| Step: 9
Training loss: 2.662666290534688
Validation loss: 2.575175962639429

Epoch: 5| Step: 10
Training loss: 2.461731216558901
Validation loss: 2.55639332682568

Epoch: 371| Step: 0
Training loss: 1.877854463257899
Validation loss: 2.555425711809791

Epoch: 5| Step: 1
Training loss: 2.2813262926695708
Validation loss: 2.5633206727833913

Epoch: 5| Step: 2
Training loss: 1.4791709828201864
Validation loss: 2.5646951548691

Epoch: 5| Step: 3
Training loss: 1.8965645173068844
Validation loss: 2.597517787448407

Epoch: 5| Step: 4
Training loss: 1.8049217171217549
Validation loss: 2.63180621302719

Epoch: 5| Step: 5
Training loss: 2.8191542003632977
Validation loss: 2.6491907367312724

Epoch: 5| Step: 6
Training loss: 2.192368566386064
Validation loss: 2.616433454876783

Epoch: 5| Step: 7
Training loss: 2.477909528064425
Validation loss: 2.5925146611326655

Epoch: 5| Step: 8
Training loss: 2.2243763681886115
Validation loss: 2.6139766484566938

Epoch: 5| Step: 9
Training loss: 2.155147878967591
Validation loss: 2.615271873070198

Epoch: 5| Step: 10
Training loss: 1.9509151316553037
Validation loss: 2.623087057550596

Epoch: 372| Step: 0
Training loss: 1.7922196828518435
Validation loss: 2.596921378304322

Epoch: 5| Step: 1
Training loss: 2.3684248004013657
Validation loss: 2.5870814900796675

Epoch: 5| Step: 2
Training loss: 2.4091467327435487
Validation loss: 2.5876698785806664

Epoch: 5| Step: 3
Training loss: 2.088687298676571
Validation loss: 2.59270173926467

Epoch: 5| Step: 4
Training loss: 1.7533165294992676
Validation loss: 2.618700670772372

Epoch: 5| Step: 5
Training loss: 2.3253351687779897
Validation loss: 2.6045695161042923

Epoch: 5| Step: 6
Training loss: 2.0169618889645995
Validation loss: 2.624460923821566

Epoch: 5| Step: 7
Training loss: 1.6760290714009565
Validation loss: 2.6390007515257965

Epoch: 5| Step: 8
Training loss: 2.5698662924217075
Validation loss: 2.6600362046416555

Epoch: 5| Step: 9
Training loss: 2.0132657223311035
Validation loss: 2.651905736059857

Epoch: 5| Step: 10
Training loss: 2.024243050844943
Validation loss: 2.6211194479605804

Epoch: 373| Step: 0
Training loss: 2.072988371511435
Validation loss: 2.6019770168750336

Epoch: 5| Step: 1
Training loss: 2.062063922442575
Validation loss: 2.6103944379278468

Epoch: 5| Step: 2
Training loss: 2.216160297159824
Validation loss: 2.568717459886296

Epoch: 5| Step: 3
Training loss: 2.237228811868118
Validation loss: 2.5556739973924123

Epoch: 5| Step: 4
Training loss: 2.02198627525373
Validation loss: 2.5804584234044947

Epoch: 5| Step: 5
Training loss: 2.279040272315453
Validation loss: 2.5853487588817137

Epoch: 5| Step: 6
Training loss: 1.8771638464163762
Validation loss: 2.6142707215871765

Epoch: 5| Step: 7
Training loss: 1.4861101950685207
Validation loss: 2.6379016226156193

Epoch: 5| Step: 8
Training loss: 2.1802682410580374
Validation loss: 2.682954648967227

Epoch: 5| Step: 9
Training loss: 1.727375374258227
Validation loss: 2.6716550698011146

Epoch: 5| Step: 10
Training loss: 2.814605179331773
Validation loss: 2.6788965896858454

Epoch: 374| Step: 0
Training loss: 1.6815055057413946
Validation loss: 2.6582848463234385

Epoch: 5| Step: 1
Training loss: 2.2273185650951417
Validation loss: 2.650423726672312

Epoch: 5| Step: 2
Training loss: 2.173461115343375
Validation loss: 2.6466154286667445

Epoch: 5| Step: 3
Training loss: 2.6224558172149686
Validation loss: 2.651977060399774

Epoch: 5| Step: 4
Training loss: 2.3356221984568823
Validation loss: 2.635982599712725

Epoch: 5| Step: 5
Training loss: 1.9155809257378131
Validation loss: 2.608790815074704

Epoch: 5| Step: 6
Training loss: 1.9133607161730095
Validation loss: 2.5666310676127035

Epoch: 5| Step: 7
Training loss: 2.086798443802408
Validation loss: 2.594468663729951

Epoch: 5| Step: 8
Training loss: 1.9595178579425356
Validation loss: 2.582894595306098

Epoch: 5| Step: 9
Training loss: 2.1748003023923013
Validation loss: 2.6094408504082764

Epoch: 5| Step: 10
Training loss: 1.8954347953116715
Validation loss: 2.6168175406610685

Epoch: 375| Step: 0
Training loss: 2.037010241662985
Validation loss: 2.630199431302067

Epoch: 5| Step: 1
Training loss: 2.235959644861075
Validation loss: 2.6206975094274028

Epoch: 5| Step: 2
Training loss: 1.9620807248423113
Validation loss: 2.624275803956033

Epoch: 5| Step: 3
Training loss: 2.2839078704771865
Validation loss: 2.6290480310914477

Epoch: 5| Step: 4
Training loss: 2.0215470014076216
Validation loss: 2.6331356922897795

Epoch: 5| Step: 5
Training loss: 2.233311113085687
Validation loss: 2.62131390667031

Epoch: 5| Step: 6
Training loss: 2.008738263516658
Validation loss: 2.6323836103758107

Epoch: 5| Step: 7
Training loss: 1.9936262732115515
Validation loss: 2.6231215651464876

Epoch: 5| Step: 8
Training loss: 2.3820418315388436
Validation loss: 2.63136516526835

Epoch: 5| Step: 9
Training loss: 1.957827164457282
Validation loss: 2.6662942888487473

Epoch: 5| Step: 10
Training loss: 1.7283345100646519
Validation loss: 2.662114390356611

Epoch: 376| Step: 0
Training loss: 1.8360918994667323
Validation loss: 2.692301280612291

Epoch: 5| Step: 1
Training loss: 1.6259236278451719
Validation loss: 2.6678687976422895

Epoch: 5| Step: 2
Training loss: 2.2869494583423147
Validation loss: 2.671415813284002

Epoch: 5| Step: 3
Training loss: 2.6610683048374115
Validation loss: 2.6669342486148224

Epoch: 5| Step: 4
Training loss: 2.591739472800661
Validation loss: 2.6460711383864997

Epoch: 5| Step: 5
Training loss: 1.9285208074798708
Validation loss: 2.619397675258767

Epoch: 5| Step: 6
Training loss: 2.225966738586892
Validation loss: 2.5837464043682488

Epoch: 5| Step: 7
Training loss: 1.1521118965310166
Validation loss: 2.5975427830232816

Epoch: 5| Step: 8
Training loss: 2.5028694851080155
Validation loss: 2.6045194523896535

Epoch: 5| Step: 9
Training loss: 1.5839191992505928
Validation loss: 2.6240978038313254

Epoch: 5| Step: 10
Training loss: 1.5658770877936583
Validation loss: 2.6376704077896433

Epoch: 377| Step: 0
Training loss: 1.776945367118184
Validation loss: 2.664769819594802

Epoch: 5| Step: 1
Training loss: 2.2846297219929905
Validation loss: 2.681127132743706

Epoch: 5| Step: 2
Training loss: 1.999489540284508
Validation loss: 2.656085756883394

Epoch: 5| Step: 3
Training loss: 2.2376918049868317
Validation loss: 2.6654969403897337

Epoch: 5| Step: 4
Training loss: 1.8628938860073812
Validation loss: 2.6535080696219966

Epoch: 5| Step: 5
Training loss: 1.4809034207655583
Validation loss: 2.649621443624165

Epoch: 5| Step: 6
Training loss: 1.8293606095551171
Validation loss: 2.67491019819592

Epoch: 5| Step: 7
Training loss: 2.108692991416617
Validation loss: 2.653850190865438

Epoch: 5| Step: 8
Training loss: 2.498950547246874
Validation loss: 2.6686338147278374

Epoch: 5| Step: 9
Training loss: 1.642865640014093
Validation loss: 2.680133674448694

Epoch: 5| Step: 10
Training loss: 2.60305037923884
Validation loss: 2.670265500246505

Epoch: 378| Step: 0
Training loss: 1.8241155623795224
Validation loss: 2.6638498865876814

Epoch: 5| Step: 1
Training loss: 1.6508708909660126
Validation loss: 2.6522022152585034

Epoch: 5| Step: 2
Training loss: 1.9788568622316198
Validation loss: 2.63602543851035

Epoch: 5| Step: 3
Training loss: 1.9885626633103282
Validation loss: 2.630029690106745

Epoch: 5| Step: 4
Training loss: 2.1575420765403943
Validation loss: 2.641035617553139

Epoch: 5| Step: 5
Training loss: 2.4903695582180214
Validation loss: 2.6632711579848887

Epoch: 5| Step: 6
Training loss: 1.8916124019597795
Validation loss: 2.639883398518263

Epoch: 5| Step: 7
Training loss: 2.446373949843303
Validation loss: 2.6642288224893473

Epoch: 5| Step: 8
Training loss: 2.406239992591558
Validation loss: 2.6242566088855317

Epoch: 5| Step: 9
Training loss: 1.61406151327452
Validation loss: 2.6039157127958967

Epoch: 5| Step: 10
Training loss: 1.6464961041341566
Validation loss: 2.574874574047944

Epoch: 379| Step: 0
Training loss: 2.1401078093636925
Validation loss: 2.6038850700142437

Epoch: 5| Step: 1
Training loss: 2.3642541821533465
Validation loss: 2.647808389723573

Epoch: 5| Step: 2
Training loss: 2.154474052274719
Validation loss: 2.6969708620249664

Epoch: 5| Step: 3
Training loss: 2.0194424696394777
Validation loss: 2.743018288439473

Epoch: 5| Step: 4
Training loss: 1.9015468675132268
Validation loss: 2.7201987491747603

Epoch: 5| Step: 5
Training loss: 2.2275969662095445
Validation loss: 2.689622611716198

Epoch: 5| Step: 6
Training loss: 1.884209965047105
Validation loss: 2.666273784792991

Epoch: 5| Step: 7
Training loss: 2.3553054778288063
Validation loss: 2.651229444305559

Epoch: 5| Step: 8
Training loss: 1.8123295144765945
Validation loss: 2.671149394651409

Epoch: 5| Step: 9
Training loss: 1.8316293369107275
Validation loss: 2.6496567995922056

Epoch: 5| Step: 10
Training loss: 1.3907525507690803
Validation loss: 2.6344995685950297

Epoch: 380| Step: 0
Training loss: 1.6770927081428542
Validation loss: 2.6330383560289947

Epoch: 5| Step: 1
Training loss: 1.8795869668790006
Validation loss: 2.658669172020546

Epoch: 5| Step: 2
Training loss: 1.9027581674102045
Validation loss: 2.623716145887259

Epoch: 5| Step: 3
Training loss: 2.212246780129339
Validation loss: 2.632499295223786

Epoch: 5| Step: 4
Training loss: 2.1620273316073475
Validation loss: 2.6321893987253984

Epoch: 5| Step: 5
Training loss: 1.8744641491994216
Validation loss: 2.617406048845933

Epoch: 5| Step: 6
Training loss: 2.141627390262635
Validation loss: 2.569591051054434

Epoch: 5| Step: 7
Training loss: 2.0899954767497637
Validation loss: 2.5601657767706585

Epoch: 5| Step: 8
Training loss: 2.214642335590798
Validation loss: 2.560741917955239

Epoch: 5| Step: 9
Training loss: 2.0027498176564147
Validation loss: 2.5927244151138455

Epoch: 5| Step: 10
Training loss: 2.029594803382677
Validation loss: 2.6271397931867253

Epoch: 381| Step: 0
Training loss: 1.746272408649513
Validation loss: 2.6743117746961467

Epoch: 5| Step: 1
Training loss: 2.237707786928167
Validation loss: 2.6799123021523594

Epoch: 5| Step: 2
Training loss: 1.5475356107444562
Validation loss: 2.705132595266237

Epoch: 5| Step: 3
Training loss: 2.053202973950698
Validation loss: 2.683110236089091

Epoch: 5| Step: 4
Training loss: 2.1667953477451465
Validation loss: 2.699468750534011

Epoch: 5| Step: 5
Training loss: 2.2271046831649812
Validation loss: 2.692032197863909

Epoch: 5| Step: 6
Training loss: 2.3537632982037398
Validation loss: 2.685482070752509

Epoch: 5| Step: 7
Training loss: 2.1768705151468186
Validation loss: 2.67008061517006

Epoch: 5| Step: 8
Training loss: 1.4159033158586851
Validation loss: 2.667061396450698

Epoch: 5| Step: 9
Training loss: 1.7313029945608076
Validation loss: 2.6625495511642168

Epoch: 5| Step: 10
Training loss: 2.0205645693831786
Validation loss: 2.6287492852314402

Epoch: 382| Step: 0
Training loss: 2.07980531148158
Validation loss: 2.620345740333373

Epoch: 5| Step: 1
Training loss: 1.3886019532188976
Validation loss: 2.6171916042706496

Epoch: 5| Step: 2
Training loss: 2.1489245053499677
Validation loss: 2.579122479765815

Epoch: 5| Step: 3
Training loss: 2.0393559621050317
Validation loss: 2.608170813412621

Epoch: 5| Step: 4
Training loss: 1.682205512928141
Validation loss: 2.594983587014539

Epoch: 5| Step: 5
Training loss: 2.1628642707033436
Validation loss: 2.6325037636979443

Epoch: 5| Step: 6
Training loss: 2.342037134516258
Validation loss: 2.642575130211293

Epoch: 5| Step: 7
Training loss: 1.8683651199268447
Validation loss: 2.6480983069594872

Epoch: 5| Step: 8
Training loss: 2.07266642786914
Validation loss: 2.6673757285928366

Epoch: 5| Step: 9
Training loss: 1.878343652574456
Validation loss: 2.6834685108965894

Epoch: 5| Step: 10
Training loss: 1.9849545691261428
Validation loss: 2.681296007013267

Epoch: 383| Step: 0
Training loss: 1.9382048524548032
Validation loss: 2.696833553510713

Epoch: 5| Step: 1
Training loss: 2.1395589582570875
Validation loss: 2.671916135950927

Epoch: 5| Step: 2
Training loss: 1.5879969262158218
Validation loss: 2.6294700760164145

Epoch: 5| Step: 3
Training loss: 2.5482456754881473
Validation loss: 2.6154060992661123

Epoch: 5| Step: 4
Training loss: 1.8856100611968962
Validation loss: 2.6074968131293486

Epoch: 5| Step: 5
Training loss: 2.0313705408569542
Validation loss: 2.6259641493017294

Epoch: 5| Step: 6
Training loss: 1.9823863961187904
Validation loss: 2.6352301298156067

Epoch: 5| Step: 7
Training loss: 1.7427874844899967
Validation loss: 2.660614626135353

Epoch: 5| Step: 8
Training loss: 1.6656983980249795
Validation loss: 2.6932658248755383

Epoch: 5| Step: 9
Training loss: 1.9736799246758223
Validation loss: 2.7355416420526324

Epoch: 5| Step: 10
Training loss: 2.2043851670803245
Validation loss: 2.7304906554181607

Epoch: 384| Step: 0
Training loss: 1.9184337293181124
Validation loss: 2.756084021433733

Epoch: 5| Step: 1
Training loss: 1.8240475952104143
Validation loss: 2.725653291838412

Epoch: 5| Step: 2
Training loss: 1.9366575070600633
Validation loss: 2.7243625152227824

Epoch: 5| Step: 3
Training loss: 2.3620975777337905
Validation loss: 2.6967242566550347

Epoch: 5| Step: 4
Training loss: 2.4516786818876595
Validation loss: 2.5815934671140837

Epoch: 5| Step: 5
Training loss: 1.8364764132793463
Validation loss: 2.563812590983403

Epoch: 5| Step: 6
Training loss: 1.668585276956815
Validation loss: 2.559731473311344

Epoch: 5| Step: 7
Training loss: 1.905825020366509
Validation loss: 2.5689854262229797

Epoch: 5| Step: 8
Training loss: 1.949899680662684
Validation loss: 2.6058137202878418

Epoch: 5| Step: 9
Training loss: 1.8531987810805635
Validation loss: 2.6142065373763925

Epoch: 5| Step: 10
Training loss: 2.1065288415723096
Validation loss: 2.6655108583748643

Epoch: 385| Step: 0
Training loss: 1.7184904422710654
Validation loss: 2.694645629582939

Epoch: 5| Step: 1
Training loss: 1.9925811378682072
Validation loss: 2.7041859438862095

Epoch: 5| Step: 2
Training loss: 2.047231861484608
Validation loss: 2.684316754560685

Epoch: 5| Step: 3
Training loss: 1.9610117864025989
Validation loss: 2.666852170378153

Epoch: 5| Step: 4
Training loss: 1.9326828785931627
Validation loss: 2.651623602285832

Epoch: 5| Step: 5
Training loss: 1.9208193725387523
Validation loss: 2.6026692557561995

Epoch: 5| Step: 6
Training loss: 2.2352251689569713
Validation loss: 2.5954966628310276

Epoch: 5| Step: 7
Training loss: 1.7034900519033251
Validation loss: 2.6040027716140384

Epoch: 5| Step: 8
Training loss: 1.9706800174020005
Validation loss: 2.626561489052446

Epoch: 5| Step: 9
Training loss: 2.070180406494997
Validation loss: 2.659354906630555

Epoch: 5| Step: 10
Training loss: 1.9594470435226436
Validation loss: 2.685046887642505

Epoch: 386| Step: 0
Training loss: 1.8024382342841665
Validation loss: 2.673222845003388

Epoch: 5| Step: 1
Training loss: 2.1317400908581523
Validation loss: 2.6664296438709676

Epoch: 5| Step: 2
Training loss: 2.0233637380227054
Validation loss: 2.6326676025129494

Epoch: 5| Step: 3
Training loss: 1.6793941507784358
Validation loss: 2.6280555247594526

Epoch: 5| Step: 4
Training loss: 1.7208343351913873
Validation loss: 2.611372563002596

Epoch: 5| Step: 5
Training loss: 2.134539565169369
Validation loss: 2.6142566631919744

Epoch: 5| Step: 6
Training loss: 2.2854829994759434
Validation loss: 2.6566571767466156

Epoch: 5| Step: 7
Training loss: 1.884943725393517
Validation loss: 2.6297975053412164

Epoch: 5| Step: 8
Training loss: 1.7562453680554326
Validation loss: 2.667207140782678

Epoch: 5| Step: 9
Training loss: 1.8815801235780771
Validation loss: 2.6718681242769846

Epoch: 5| Step: 10
Training loss: 1.8502381815817022
Validation loss: 2.6915778348845465

Epoch: 387| Step: 0
Training loss: 2.0813185167919555
Validation loss: 2.692631421667094

Epoch: 5| Step: 1
Training loss: 1.3586503651576596
Validation loss: 2.6942414783219393

Epoch: 5| Step: 2
Training loss: 1.949569395400977
Validation loss: 2.7040937941151757

Epoch: 5| Step: 3
Training loss: 2.072611097756336
Validation loss: 2.736636686639613

Epoch: 5| Step: 4
Training loss: 1.8404521867489478
Validation loss: 2.696586077103082

Epoch: 5| Step: 5
Training loss: 2.1413810118921015
Validation loss: 2.6774509548279988

Epoch: 5| Step: 6
Training loss: 2.317269227225821
Validation loss: 2.689231332052619

Epoch: 5| Step: 7
Training loss: 1.0376107535938084
Validation loss: 2.66835137058902

Epoch: 5| Step: 8
Training loss: 1.8973749271832356
Validation loss: 2.6435366012233534

Epoch: 5| Step: 9
Training loss: 1.7410848232774083
Validation loss: 2.6588027047764395

Epoch: 5| Step: 10
Training loss: 2.547608533200075
Validation loss: 2.66689611961604

Epoch: 388| Step: 0
Training loss: 1.9998271986697211
Validation loss: 2.6402751741612254

Epoch: 5| Step: 1
Training loss: 2.0617498709876467
Validation loss: 2.64769408204918

Epoch: 5| Step: 2
Training loss: 1.5106014094880118
Validation loss: 2.6519824187589767

Epoch: 5| Step: 3
Training loss: 1.8625483000976197
Validation loss: 2.645046881414489

Epoch: 5| Step: 4
Training loss: 1.9653451935700548
Validation loss: 2.6734162813164257

Epoch: 5| Step: 5
Training loss: 2.3312210899380865
Validation loss: 2.691195140492272

Epoch: 5| Step: 6
Training loss: 1.687298515441889
Validation loss: 2.69387830682738

Epoch: 5| Step: 7
Training loss: 2.3307207217498602
Validation loss: 2.7337150374989765

Epoch: 5| Step: 8
Training loss: 1.4660661403573243
Validation loss: 2.7165111809293356

Epoch: 5| Step: 9
Training loss: 2.052514264966713
Validation loss: 2.7219342594334384

Epoch: 5| Step: 10
Training loss: 1.5943555242589356
Validation loss: 2.7013578151537407

Epoch: 389| Step: 0
Training loss: 1.914368585519135
Validation loss: 2.701373891492424

Epoch: 5| Step: 1
Training loss: 1.8583545609474894
Validation loss: 2.6884755498124036

Epoch: 5| Step: 2
Training loss: 2.184150092644108
Validation loss: 2.698265735049794

Epoch: 5| Step: 3
Training loss: 1.2015345576377034
Validation loss: 2.6800771512656634

Epoch: 5| Step: 4
Training loss: 2.308610170567395
Validation loss: 2.6850642990326996

Epoch: 5| Step: 5
Training loss: 1.827638936429993
Validation loss: 2.6596319896802245

Epoch: 5| Step: 6
Training loss: 1.8934097588699945
Validation loss: 2.6828136751331924

Epoch: 5| Step: 7
Training loss: 1.9631023235887728
Validation loss: 2.6952114405507723

Epoch: 5| Step: 8
Training loss: 1.9754513116242016
Validation loss: 2.673804582757814

Epoch: 5| Step: 9
Training loss: 1.9991382888278804
Validation loss: 2.636086297426748

Epoch: 5| Step: 10
Training loss: 1.585073150968402
Validation loss: 2.638519293142154

Epoch: 390| Step: 0
Training loss: 1.7479616282897599
Validation loss: 2.6016622544719126

Epoch: 5| Step: 1
Training loss: 1.7152056822595487
Validation loss: 2.6293284049469148

Epoch: 5| Step: 2
Training loss: 1.7784618172652966
Validation loss: 2.606379774932052

Epoch: 5| Step: 3
Training loss: 1.554555532710754
Validation loss: 2.595137379146096

Epoch: 5| Step: 4
Training loss: 2.1772335554310702
Validation loss: 2.6107909637147313

Epoch: 5| Step: 5
Training loss: 2.008448637294442
Validation loss: 2.6495930158916825

Epoch: 5| Step: 6
Training loss: 1.9246829230019835
Validation loss: 2.666405777192816

Epoch: 5| Step: 7
Training loss: 2.446879606863779
Validation loss: 2.6822265833744154

Epoch: 5| Step: 8
Training loss: 2.02251410310824
Validation loss: 2.6744122234055467

Epoch: 5| Step: 9
Training loss: 1.7891443891815904
Validation loss: 2.6830358877577094

Epoch: 5| Step: 10
Training loss: 1.6455697520566144
Validation loss: 2.729620761350032

Epoch: 391| Step: 0
Training loss: 2.083104184582049
Validation loss: 2.7139971627943247

Epoch: 5| Step: 1
Training loss: 1.885631303179267
Validation loss: 2.694871378607824

Epoch: 5| Step: 2
Training loss: 1.6778096902659991
Validation loss: 2.676008401703245

Epoch: 5| Step: 3
Training loss: 2.0726397407642065
Validation loss: 2.6671044165982916

Epoch: 5| Step: 4
Training loss: 1.9192245319083394
Validation loss: 2.6431639605038892

Epoch: 5| Step: 5
Training loss: 1.802807509900912
Validation loss: 2.6408578918398447

Epoch: 5| Step: 6
Training loss: 1.529394231939582
Validation loss: 2.623075178967022

Epoch: 5| Step: 7
Training loss: 1.8408072959378987
Validation loss: 2.6111067140091726

Epoch: 5| Step: 8
Training loss: 1.8494132400174075
Validation loss: 2.6192880550626954

Epoch: 5| Step: 9
Training loss: 2.075218864756054
Validation loss: 2.6411055377452834

Epoch: 5| Step: 10
Training loss: 2.12279070279889
Validation loss: 2.6509275132392434

Epoch: 392| Step: 0
Training loss: 1.5167417050058258
Validation loss: 2.6747047811707683

Epoch: 5| Step: 1
Training loss: 2.0097297984081997
Validation loss: 2.724137004226202

Epoch: 5| Step: 2
Training loss: 2.077957949700296
Validation loss: 2.7420482541129263

Epoch: 5| Step: 3
Training loss: 2.1066536762746444
Validation loss: 2.6899789946382846

Epoch: 5| Step: 4
Training loss: 1.275643199545983
Validation loss: 2.6496931380926334

Epoch: 5| Step: 5
Training loss: 1.721610445998454
Validation loss: 2.603731017722786

Epoch: 5| Step: 6
Training loss: 1.984774812085114
Validation loss: 2.570777768919235

Epoch: 5| Step: 7
Training loss: 2.4053392544537484
Validation loss: 2.564130015040916

Epoch: 5| Step: 8
Training loss: 1.8647404041588052
Validation loss: 2.573240492846392

Epoch: 5| Step: 9
Training loss: 2.3121569611024806
Validation loss: 2.5871285810669313

Epoch: 5| Step: 10
Training loss: 1.7883095968590392
Validation loss: 2.6085887419702765

Epoch: 393| Step: 0
Training loss: 1.9451108774388688
Validation loss: 2.624130929431388

Epoch: 5| Step: 1
Training loss: 2.05751591357616
Validation loss: 2.6472756363732373

Epoch: 5| Step: 2
Training loss: 1.9162451930275064
Validation loss: 2.653234409080573

Epoch: 5| Step: 3
Training loss: 1.8961999210391045
Validation loss: 2.648453547162034

Epoch: 5| Step: 4
Training loss: 1.9834562562735123
Validation loss: 2.6581009199015817

Epoch: 5| Step: 5
Training loss: 1.7909529913180877
Validation loss: 2.6799288075131042

Epoch: 5| Step: 6
Training loss: 1.1880300242486448
Validation loss: 2.6574009331538684

Epoch: 5| Step: 7
Training loss: 2.0054808856640025
Validation loss: 2.685900249004671

Epoch: 5| Step: 8
Training loss: 2.0415272048755733
Validation loss: 2.6710188431320105

Epoch: 5| Step: 9
Training loss: 1.676617607071391
Validation loss: 2.6259956688504023

Epoch: 5| Step: 10
Training loss: 2.207325387444803
Validation loss: 2.660828502965341

Epoch: 394| Step: 0
Training loss: 1.6498330523099556
Validation loss: 2.6352012695735016

Epoch: 5| Step: 1
Training loss: 2.352902255718112
Validation loss: 2.6645117661667035

Epoch: 5| Step: 2
Training loss: 2.065457160352158
Validation loss: 2.655280579221832

Epoch: 5| Step: 3
Training loss: 1.452526830796371
Validation loss: 2.6515492470451805

Epoch: 5| Step: 4
Training loss: 1.4767596400824394
Validation loss: 2.669701096347515

Epoch: 5| Step: 5
Training loss: 1.6599742834558067
Validation loss: 2.6899851350274084

Epoch: 5| Step: 6
Training loss: 2.103395704784471
Validation loss: 2.711756812551346

Epoch: 5| Step: 7
Training loss: 1.2371095233961715
Validation loss: 2.7441146842937045

Epoch: 5| Step: 8
Training loss: 2.2690204301555723
Validation loss: 2.720316745576417

Epoch: 5| Step: 9
Training loss: 2.2297424095786784
Validation loss: 2.713305864939091

Epoch: 5| Step: 10
Training loss: 1.8938661017252614
Validation loss: 2.6244149373995627

Epoch: 395| Step: 0
Training loss: 1.8822510701375457
Validation loss: 2.585711444119217

Epoch: 5| Step: 1
Training loss: 1.699441899522218
Validation loss: 2.542967393057955

Epoch: 5| Step: 2
Training loss: 1.681638923670742
Validation loss: 2.5143987313546226

Epoch: 5| Step: 3
Training loss: 1.8533678227012482
Validation loss: 2.548566716273659

Epoch: 5| Step: 4
Training loss: 1.663878094838574
Validation loss: 2.5950590206565347

Epoch: 5| Step: 5
Training loss: 2.1828357561493203
Validation loss: 2.569325838914804

Epoch: 5| Step: 6
Training loss: 2.3077998466377263
Validation loss: 2.587406332278282

Epoch: 5| Step: 7
Training loss: 1.9806239200876794
Validation loss: 2.599495333503985

Epoch: 5| Step: 8
Training loss: 1.892576928231852
Validation loss: 2.6131213659025523

Epoch: 5| Step: 9
Training loss: 2.1069808371188
Validation loss: 2.6306849007824535

Epoch: 5| Step: 10
Training loss: 1.6146146791758345
Validation loss: 2.6679230801416134

Epoch: 396| Step: 0
Training loss: 1.7356917735282038
Validation loss: 2.713448023771133

Epoch: 5| Step: 1
Training loss: 1.8949162986608838
Validation loss: 2.6755580477567285

Epoch: 5| Step: 2
Training loss: 1.8313422300268223
Validation loss: 2.6783867464792035

Epoch: 5| Step: 3
Training loss: 1.9952175061010822
Validation loss: 2.6762361922228353

Epoch: 5| Step: 4
Training loss: 1.9468424345816717
Validation loss: 2.64166789447071

Epoch: 5| Step: 5
Training loss: 1.8229064795799805
Validation loss: 2.6373367267198278

Epoch: 5| Step: 6
Training loss: 2.137239661173546
Validation loss: 2.6420895288850694

Epoch: 5| Step: 7
Training loss: 1.6314731196843806
Validation loss: 2.6263457509546906

Epoch: 5| Step: 8
Training loss: 1.9003488471368115
Validation loss: 2.633365446818835

Epoch: 5| Step: 9
Training loss: 2.124225587542726
Validation loss: 2.667415437504844

Epoch: 5| Step: 10
Training loss: 1.681076469116286
Validation loss: 2.6872725336835592

Epoch: 397| Step: 0
Training loss: 1.7858138928561993
Validation loss: 2.7194634994595703

Epoch: 5| Step: 1
Training loss: 1.74577222761163
Validation loss: 2.7691753465453486

Epoch: 5| Step: 2
Training loss: 1.6217391234648117
Validation loss: 2.7498978085888273

Epoch: 5| Step: 3
Training loss: 1.9981443618156116
Validation loss: 2.7063448908467973

Epoch: 5| Step: 4
Training loss: 1.8226877195909295
Validation loss: 2.647403461577434

Epoch: 5| Step: 5
Training loss: 1.9145481038579533
Validation loss: 2.6039649724480696

Epoch: 5| Step: 6
Training loss: 2.0388162398438645
Validation loss: 2.5747428867229436

Epoch: 5| Step: 7
Training loss: 1.7055972293369628
Validation loss: 2.5524745414465184

Epoch: 5| Step: 8
Training loss: 1.893018484308485
Validation loss: 2.5629650787407985

Epoch: 5| Step: 9
Training loss: 2.0541904558992736
Validation loss: 2.6175280316844547

Epoch: 5| Step: 10
Training loss: 1.9755503961946055
Validation loss: 2.6702819961108073

Epoch: 398| Step: 0
Training loss: 1.987117104265026
Validation loss: 2.716696428855251

Epoch: 5| Step: 1
Training loss: 2.2503571756635217
Validation loss: 2.769008705258056

Epoch: 5| Step: 2
Training loss: 1.5619956919309086
Validation loss: 2.785317908530057

Epoch: 5| Step: 3
Training loss: 1.7899512203325665
Validation loss: 2.781272151610393

Epoch: 5| Step: 4
Training loss: 2.1971510386788564
Validation loss: 2.7397658753090735

Epoch: 5| Step: 5
Training loss: 1.8591041688261782
Validation loss: 2.7311020640591934

Epoch: 5| Step: 6
Training loss: 1.7512527477779247
Validation loss: 2.7189698074456015

Epoch: 5| Step: 7
Training loss: 2.1787308538561896
Validation loss: 2.6870414054532574

Epoch: 5| Step: 8
Training loss: 1.3937970106467503
Validation loss: 2.6533232893634904

Epoch: 5| Step: 9
Training loss: 1.9312163562992228
Validation loss: 2.6336120470304

Epoch: 5| Step: 10
Training loss: 1.1427247564665093
Validation loss: 2.5844752149567944

Epoch: 399| Step: 0
Training loss: 1.7036583441571649
Validation loss: 2.568968628189225

Epoch: 5| Step: 1
Training loss: 1.7151093505385624
Validation loss: 2.5737540463461968

Epoch: 5| Step: 2
Training loss: 1.334734012094313
Validation loss: 2.564427426015919

Epoch: 5| Step: 3
Training loss: 1.8691979601765039
Validation loss: 2.584094657482621

Epoch: 5| Step: 4
Training loss: 1.9584236597643723
Validation loss: 2.586166952107824

Epoch: 5| Step: 5
Training loss: 2.433941125952321
Validation loss: 2.618173901231298

Epoch: 5| Step: 6
Training loss: 1.89625574652971
Validation loss: 2.666935307932809

Epoch: 5| Step: 7
Training loss: 2.052101741908297
Validation loss: 2.6883590738902905

Epoch: 5| Step: 8
Training loss: 1.7063080327152378
Validation loss: 2.736603337821518

Epoch: 5| Step: 9
Training loss: 1.7691188441153076
Validation loss: 2.7421282638650655

Epoch: 5| Step: 10
Training loss: 1.6750013408370843
Validation loss: 2.715156344186984

Epoch: 400| Step: 0
Training loss: 1.7094699366007715
Validation loss: 2.7056673987144926

Epoch: 5| Step: 1
Training loss: 2.0171252441254808
Validation loss: 2.69875885242834

Epoch: 5| Step: 2
Training loss: 1.8805062506200865
Validation loss: 2.657467831597227

Epoch: 5| Step: 3
Training loss: 1.5765360774235295
Validation loss: 2.6236465156340785

Epoch: 5| Step: 4
Training loss: 2.129936990656644
Validation loss: 2.599392723538272

Epoch: 5| Step: 5
Training loss: 2.1649217793207662
Validation loss: 2.584864296386174

Epoch: 5| Step: 6
Training loss: 1.9073066284437319
Validation loss: 2.593112039322059

Epoch: 5| Step: 7
Training loss: 1.5102538273167212
Validation loss: 2.6128555280458268

Epoch: 5| Step: 8
Training loss: 1.7681825057677172
Validation loss: 2.6159691511951726

Epoch: 5| Step: 9
Training loss: 1.6410401318633212
Validation loss: 2.6530455899529297

Epoch: 5| Step: 10
Training loss: 1.7519555065262171
Validation loss: 2.674243734074305

Epoch: 401| Step: 0
Training loss: 1.6750604106200722
Validation loss: 2.6688763003304454

Epoch: 5| Step: 1
Training loss: 1.6195183510089537
Validation loss: 2.6468015150414126

Epoch: 5| Step: 2
Training loss: 1.8392465193086713
Validation loss: 2.635984947461811

Epoch: 5| Step: 3
Training loss: 1.8804646649254873
Validation loss: 2.654815632069129

Epoch: 5| Step: 4
Training loss: 2.1410155670939943
Validation loss: 2.650731717228109

Epoch: 5| Step: 5
Training loss: 1.7975389663653487
Validation loss: 2.655462991229343

Epoch: 5| Step: 6
Training loss: 1.925367515953104
Validation loss: 2.664651835072898

Epoch: 5| Step: 7
Training loss: 1.972084854010404
Validation loss: 2.6416155394203953

Epoch: 5| Step: 8
Training loss: 1.939868463795892
Validation loss: 2.650312519780847

Epoch: 5| Step: 9
Training loss: 1.5308058736903267
Validation loss: 2.6216444209086798

Epoch: 5| Step: 10
Training loss: 1.6728547692476927
Validation loss: 2.6324746612665315

Epoch: 402| Step: 0
Training loss: 1.8589621975211719
Validation loss: 2.6608043215703474

Epoch: 5| Step: 1
Training loss: 1.6403195051325998
Validation loss: 2.6723430573549405

Epoch: 5| Step: 2
Training loss: 1.5083681970153489
Validation loss: 2.6409204265227277

Epoch: 5| Step: 3
Training loss: 1.6088828658432621
Validation loss: 2.6819435260872293

Epoch: 5| Step: 4
Training loss: 1.9861466316419873
Validation loss: 2.683802587936744

Epoch: 5| Step: 5
Training loss: 1.8038541512877482
Validation loss: 2.714685130448644

Epoch: 5| Step: 6
Training loss: 1.594809385766434
Validation loss: 2.7082895807056215

Epoch: 5| Step: 7
Training loss: 2.0036642363453208
Validation loss: 2.7141199853565854

Epoch: 5| Step: 8
Training loss: 2.0797382488980296
Validation loss: 2.714836376856237

Epoch: 5| Step: 9
Training loss: 1.850287598086561
Validation loss: 2.667332295692745

Epoch: 5| Step: 10
Training loss: 1.8978547508728814
Validation loss: 2.649695520134658

Epoch: 403| Step: 0
Training loss: 2.1039841324095465
Validation loss: 2.5671034221052658

Epoch: 5| Step: 1
Training loss: 1.668216088424648
Validation loss: 2.557536737214267

Epoch: 5| Step: 2
Training loss: 1.7680357282748274
Validation loss: 2.558715140099454

Epoch: 5| Step: 3
Training loss: 1.2577803708350415
Validation loss: 2.5665903887410013

Epoch: 5| Step: 4
Training loss: 1.64900060500301
Validation loss: 2.573804135259071

Epoch: 5| Step: 5
Training loss: 1.953103637578486
Validation loss: 2.630334506343309

Epoch: 5| Step: 6
Training loss: 1.4583761027286095
Validation loss: 2.6438748183620984

Epoch: 5| Step: 7
Training loss: 2.15874690459294
Validation loss: 2.682086676221398

Epoch: 5| Step: 8
Training loss: 2.0126180768174384
Validation loss: 2.6875788578598754

Epoch: 5| Step: 9
Training loss: 1.8235597911055894
Validation loss: 2.715402889090781

Epoch: 5| Step: 10
Training loss: 1.9640052174034663
Validation loss: 2.650832606856568

Epoch: 404| Step: 0
Training loss: 1.8828030661192274
Validation loss: 2.635650642537554

Epoch: 5| Step: 1
Training loss: 1.7645158913194843
Validation loss: 2.650697958833921

Epoch: 5| Step: 2
Training loss: 2.074089779050092
Validation loss: 2.6411378734609414

Epoch: 5| Step: 3
Training loss: 1.5106878190715924
Validation loss: 2.676477782644747

Epoch: 5| Step: 4
Training loss: 1.835833737302168
Validation loss: 2.685373586364495

Epoch: 5| Step: 5
Training loss: 1.9862591066625848
Validation loss: 2.7334817044226294

Epoch: 5| Step: 6
Training loss: 1.6379432922673092
Validation loss: 2.717634483984228

Epoch: 5| Step: 7
Training loss: 1.4088504060235545
Validation loss: 2.697317878833779

Epoch: 5| Step: 8
Training loss: 2.1517878262747465
Validation loss: 2.677085083231963

Epoch: 5| Step: 9
Training loss: 1.2672031124108076
Validation loss: 2.62488557612066

Epoch: 5| Step: 10
Training loss: 2.14976621288224
Validation loss: 2.596744080819039

Epoch: 405| Step: 0
Training loss: 1.4171669114203975
Validation loss: 2.5777595904925916

Epoch: 5| Step: 1
Training loss: 2.1916676737658527
Validation loss: 2.60264346624356

Epoch: 5| Step: 2
Training loss: 1.8458868671975295
Validation loss: 2.5871849509888265

Epoch: 5| Step: 3
Training loss: 1.5923372626881347
Validation loss: 2.6239669532808363

Epoch: 5| Step: 4
Training loss: 1.558088254101275
Validation loss: 2.635918352854423

Epoch: 5| Step: 5
Training loss: 1.9691150266333868
Validation loss: 2.684272778244008

Epoch: 5| Step: 6
Training loss: 1.612615415597419
Validation loss: 2.6822017815106096

Epoch: 5| Step: 7
Training loss: 2.19184922689661
Validation loss: 2.6807761036681432

Epoch: 5| Step: 8
Training loss: 1.8339146934978583
Validation loss: 2.7053962017929503

Epoch: 5| Step: 9
Training loss: 1.7671430695173809
Validation loss: 2.700642008414387

Epoch: 5| Step: 10
Training loss: 1.5262760420693395
Validation loss: 2.6545801665072357

Epoch: 406| Step: 0
Training loss: 1.6305132287268769
Validation loss: 2.6427929551281735

Epoch: 5| Step: 1
Training loss: 1.7185387915105774
Validation loss: 2.6190431650478385

Epoch: 5| Step: 2
Training loss: 2.1471454966354573
Validation loss: 2.5984217674530843

Epoch: 5| Step: 3
Training loss: 1.5202453818016624
Validation loss: 2.567258445024036

Epoch: 5| Step: 4
Training loss: 1.661958250533606
Validation loss: 2.54193803262169

Epoch: 5| Step: 5
Training loss: 1.7655973854268554
Validation loss: 2.5681696671646983

Epoch: 5| Step: 6
Training loss: 1.6180858973039958
Validation loss: 2.60284020750332

Epoch: 5| Step: 7
Training loss: 1.6840394883770053
Validation loss: 2.635084153051008

Epoch: 5| Step: 8
Training loss: 2.007777351042048
Validation loss: 2.691296667007761

Epoch: 5| Step: 9
Training loss: 1.8524226512539692
Validation loss: 2.681446625141048

Epoch: 5| Step: 10
Training loss: 1.9040390074805311
Validation loss: 2.716850396005672

Epoch: 407| Step: 0
Training loss: 1.6037149990719333
Validation loss: 2.717184683339694

Epoch: 5| Step: 1
Training loss: 1.778220427890546
Validation loss: 2.6891443745557972

Epoch: 5| Step: 2
Training loss: 1.9172963752703962
Validation loss: 2.698071881595301

Epoch: 5| Step: 3
Training loss: 1.7825888571186457
Validation loss: 2.654541339515616

Epoch: 5| Step: 4
Training loss: 1.8655486635983693
Validation loss: 2.672051277671107

Epoch: 5| Step: 5
Training loss: 1.1398828783437567
Validation loss: 2.5910228927435006

Epoch: 5| Step: 6
Training loss: 1.2989448666989807
Validation loss: 2.6055079530667804

Epoch: 5| Step: 7
Training loss: 1.8175740743493978
Validation loss: 2.5803543500257766

Epoch: 5| Step: 8
Training loss: 2.1078119208672295
Validation loss: 2.5819848593695776

Epoch: 5| Step: 9
Training loss: 1.9155882067981866
Validation loss: 2.5829760016198406

Epoch: 5| Step: 10
Training loss: 2.0581059900466423
Validation loss: 2.5906466428602593

Epoch: 408| Step: 0
Training loss: 1.9220798042155256
Validation loss: 2.5924125274198913

Epoch: 5| Step: 1
Training loss: 1.976064868147972
Validation loss: 2.599955023632125

Epoch: 5| Step: 2
Training loss: 1.701242649082108
Validation loss: 2.58126537272039

Epoch: 5| Step: 3
Training loss: 1.6927648994579951
Validation loss: 2.577501996221796

Epoch: 5| Step: 4
Training loss: 1.4082801152318591
Validation loss: 2.61224431284493

Epoch: 5| Step: 5
Training loss: 1.887031924080292
Validation loss: 2.621031569262984

Epoch: 5| Step: 6
Training loss: 1.7005157081172366
Validation loss: 2.6753844618849274

Epoch: 5| Step: 7
Training loss: 2.091984132279854
Validation loss: 2.698812771998057

Epoch: 5| Step: 8
Training loss: 2.2483798657864784
Validation loss: 2.705631804406916

Epoch: 5| Step: 9
Training loss: 1.2955663581822716
Validation loss: 2.6537276402552097

Epoch: 5| Step: 10
Training loss: 1.0912640795067061
Validation loss: 2.661104705231607

Epoch: 409| Step: 0
Training loss: 1.6988526399325548
Validation loss: 2.661257834995984

Epoch: 5| Step: 1
Training loss: 1.6722447351916587
Validation loss: 2.6484456349107965

Epoch: 5| Step: 2
Training loss: 1.8919764961008623
Validation loss: 2.6582340366075865

Epoch: 5| Step: 3
Training loss: 1.6062499139095536
Validation loss: 2.6362216752247813

Epoch: 5| Step: 4
Training loss: 1.588161919234863
Validation loss: 2.629249653571716

Epoch: 5| Step: 5
Training loss: 1.7480838366815072
Validation loss: 2.638989385610114

Epoch: 5| Step: 6
Training loss: 1.7940695713889254
Validation loss: 2.596921644844134

Epoch: 5| Step: 7
Training loss: 1.8762652260952275
Validation loss: 2.6578906971799663

Epoch: 5| Step: 8
Training loss: 2.1381863256255382
Validation loss: 2.6779269186939856

Epoch: 5| Step: 9
Training loss: 1.474910154677473
Validation loss: 2.671864077129488

Epoch: 5| Step: 10
Training loss: 1.8127463600838685
Validation loss: 2.66996105443291

Epoch: 410| Step: 0
Training loss: 1.5881847376661855
Validation loss: 2.6113025928091904

Epoch: 5| Step: 1
Training loss: 1.7057802692552728
Validation loss: 2.6098582308049534

Epoch: 5| Step: 2
Training loss: 1.4832069218094428
Validation loss: 2.597952654034121

Epoch: 5| Step: 3
Training loss: 1.7489421235591098
Validation loss: 2.590371886981446

Epoch: 5| Step: 4
Training loss: 1.7015082008238172
Validation loss: 2.5929728536112973

Epoch: 5| Step: 5
Training loss: 2.0206017377878958
Validation loss: 2.5900647169614497

Epoch: 5| Step: 6
Training loss: 2.156184762161318
Validation loss: 2.6037826556848547

Epoch: 5| Step: 7
Training loss: 1.2051291679070473
Validation loss: 2.597970582021487

Epoch: 5| Step: 8
Training loss: 1.895714207633932
Validation loss: 2.6335621338628945

Epoch: 5| Step: 9
Training loss: 1.8701966749385075
Validation loss: 2.6473313463131674

Epoch: 5| Step: 10
Training loss: 1.5812701619789058
Validation loss: 2.646747949085705

Epoch: 411| Step: 0
Training loss: 1.891385201451673
Validation loss: 2.6417269319203744

Epoch: 5| Step: 1
Training loss: 1.9511028350132216
Validation loss: 2.642909390544425

Epoch: 5| Step: 2
Training loss: 1.9222277805980563
Validation loss: 2.6234811313679622

Epoch: 5| Step: 3
Training loss: 1.6684665339162736
Validation loss: 2.6061493707088896

Epoch: 5| Step: 4
Training loss: 1.8868770809357962
Validation loss: 2.58288680281893

Epoch: 5| Step: 5
Training loss: 1.4505199749691224
Validation loss: 2.5973271554613717

Epoch: 5| Step: 6
Training loss: 1.2115901049877686
Validation loss: 2.6037027811329474

Epoch: 5| Step: 7
Training loss: 1.5627929412893282
Validation loss: 2.608338307584268

Epoch: 5| Step: 8
Training loss: 2.104679334776176
Validation loss: 2.6354761518614698

Epoch: 5| Step: 9
Training loss: 1.5208022580390392
Validation loss: 2.6313689239707294

Epoch: 5| Step: 10
Training loss: 1.8914845301907837
Validation loss: 2.6693632242023773

Epoch: 412| Step: 0
Training loss: 1.89053130114697
Validation loss: 2.643715058387234

Epoch: 5| Step: 1
Training loss: 1.903369540834956
Validation loss: 2.6409876463306596

Epoch: 5| Step: 2
Training loss: 1.4128239724297376
Validation loss: 2.6003320813197894

Epoch: 5| Step: 3
Training loss: 1.6541967080156503
Validation loss: 2.583329966526702

Epoch: 5| Step: 4
Training loss: 2.033497901677179
Validation loss: 2.5600560416828593

Epoch: 5| Step: 5
Training loss: 1.2487908236958847
Validation loss: 2.5538901594120227

Epoch: 5| Step: 6
Training loss: 1.8724774239863675
Validation loss: 2.6008963611092795

Epoch: 5| Step: 7
Training loss: 1.5510934664358151
Validation loss: 2.6019146147693313

Epoch: 5| Step: 8
Training loss: 1.7040072614488215
Validation loss: 2.6340173341811086

Epoch: 5| Step: 9
Training loss: 1.703205281736535
Validation loss: 2.6517150637393323

Epoch: 5| Step: 10
Training loss: 2.022452096077065
Validation loss: 2.6319193424904443

Epoch: 413| Step: 0
Training loss: 1.3915476363592074
Validation loss: 2.6319378261396547

Epoch: 5| Step: 1
Training loss: 1.9500708542691267
Validation loss: 2.650137157454664

Epoch: 5| Step: 2
Training loss: 1.8260406610196338
Validation loss: 2.6248682099370266

Epoch: 5| Step: 3
Training loss: 1.528837834203162
Validation loss: 2.6237852779374418

Epoch: 5| Step: 4
Training loss: 1.815264993454113
Validation loss: 2.6060508661591752

Epoch: 5| Step: 5
Training loss: 1.1444500578636678
Validation loss: 2.63452899021374

Epoch: 5| Step: 6
Training loss: 1.4126695969977117
Validation loss: 2.5835601007154785

Epoch: 5| Step: 7
Training loss: 2.2185803200757004
Validation loss: 2.6270214760689505

Epoch: 5| Step: 8
Training loss: 1.677768622549536
Validation loss: 2.6120881144287598

Epoch: 5| Step: 9
Training loss: 2.0138144234522932
Validation loss: 2.6335726617018618

Epoch: 5| Step: 10
Training loss: 1.6770838940858397
Validation loss: 2.6352044994147255

Epoch: 414| Step: 0
Training loss: 1.6308729707984935
Validation loss: 2.648532969406031

Epoch: 5| Step: 1
Training loss: 1.622067225830522
Validation loss: 2.651487250200575

Epoch: 5| Step: 2
Training loss: 1.311048522540104
Validation loss: 2.654531451116078

Epoch: 5| Step: 3
Training loss: 1.8255883248369567
Validation loss: 2.68523450384258

Epoch: 5| Step: 4
Training loss: 1.793675700918454
Validation loss: 2.67325628154818

Epoch: 5| Step: 5
Training loss: 1.867533057250909
Validation loss: 2.658294628179269

Epoch: 5| Step: 6
Training loss: 1.9042131141434584
Validation loss: 2.629488701677033

Epoch: 5| Step: 7
Training loss: 1.6027381861597463
Validation loss: 2.607130548648674

Epoch: 5| Step: 8
Training loss: 2.050387797078446
Validation loss: 2.5828734549910997

Epoch: 5| Step: 9
Training loss: 1.5479375099363568
Validation loss: 2.59794781677195

Epoch: 5| Step: 10
Training loss: 1.6375578047472248
Validation loss: 2.5972173351599914

Epoch: 415| Step: 0
Training loss: 2.017036476066427
Validation loss: 2.5879962417742113

Epoch: 5| Step: 1
Training loss: 1.3147554999216697
Validation loss: 2.5845531216294

Epoch: 5| Step: 2
Training loss: 1.699524459523689
Validation loss: 2.605706704513651

Epoch: 5| Step: 3
Training loss: 1.82286488777374
Validation loss: 2.5884601395885687

Epoch: 5| Step: 4
Training loss: 1.312310341347212
Validation loss: 2.6001160303891955

Epoch: 5| Step: 5
Training loss: 1.3957515474338553
Validation loss: 2.622652754015996

Epoch: 5| Step: 6
Training loss: 1.881226944386078
Validation loss: 2.628304590550588

Epoch: 5| Step: 7
Training loss: 1.7574850497959713
Validation loss: 2.6609236983322235

Epoch: 5| Step: 8
Training loss: 1.3977348224523398
Validation loss: 2.6568387449789745

Epoch: 5| Step: 9
Training loss: 1.8927146775750454
Validation loss: 2.676175130344298

Epoch: 5| Step: 10
Training loss: 2.227307111478243
Validation loss: 2.66519292907308

Epoch: 416| Step: 0
Training loss: 1.3829886114185304
Validation loss: 2.628381795997495

Epoch: 5| Step: 1
Training loss: 1.4107024595858286
Validation loss: 2.60990619465864

Epoch: 5| Step: 2
Training loss: 1.8668730403147866
Validation loss: 2.591660649532976

Epoch: 5| Step: 3
Training loss: 1.8040138077091181
Validation loss: 2.588314219142741

Epoch: 5| Step: 4
Training loss: 1.7078953003072301
Validation loss: 2.569262828873348

Epoch: 5| Step: 5
Training loss: 1.915985636034105
Validation loss: 2.555789039309551

Epoch: 5| Step: 6
Training loss: 1.7120988640537642
Validation loss: 2.542281896554213

Epoch: 5| Step: 7
Training loss: 1.972617755174371
Validation loss: 2.5894340854723024

Epoch: 5| Step: 8
Training loss: 1.527412744705238
Validation loss: 2.6056306326275025

Epoch: 5| Step: 9
Training loss: 1.5602411345425748
Validation loss: 2.597176498681232

Epoch: 5| Step: 10
Training loss: 1.6843323116519582
Validation loss: 2.6087104393709515

Epoch: 417| Step: 0
Training loss: 1.5378330180197217
Validation loss: 2.6464611232713757

Epoch: 5| Step: 1
Training loss: 1.9519926527111733
Validation loss: 2.6240123662433366

Epoch: 5| Step: 2
Training loss: 1.7865676475718981
Validation loss: 2.663838107970852

Epoch: 5| Step: 3
Training loss: 1.6194060215100634
Validation loss: 2.637731946022973

Epoch: 5| Step: 4
Training loss: 1.784819990746486
Validation loss: 2.656618145615536

Epoch: 5| Step: 5
Training loss: 1.9122889184092196
Validation loss: 2.642831950840272

Epoch: 5| Step: 6
Training loss: 1.0877448211981504
Validation loss: 2.6545951403010006

Epoch: 5| Step: 7
Training loss: 1.7219707483161961
Validation loss: 2.6433883637640916

Epoch: 5| Step: 8
Training loss: 1.657822204618965
Validation loss: 2.651339479504569

Epoch: 5| Step: 9
Training loss: 1.769518584822915
Validation loss: 2.6718348373141554

Epoch: 5| Step: 10
Training loss: 1.5718252761893727
Validation loss: 2.6836170582955376

Epoch: 418| Step: 0
Training loss: 1.9186151662166067
Validation loss: 2.6630458550126344

Epoch: 5| Step: 1
Training loss: 1.2232854522114465
Validation loss: 2.675364178898387

Epoch: 5| Step: 2
Training loss: 1.611341885594652
Validation loss: 2.6509426633628252

Epoch: 5| Step: 3
Training loss: 1.7262413451180134
Validation loss: 2.6524748833727387

Epoch: 5| Step: 4
Training loss: 1.5619365439133288
Validation loss: 2.6103332009909286

Epoch: 5| Step: 5
Training loss: 1.8785136679141201
Validation loss: 2.6323693818679437

Epoch: 5| Step: 6
Training loss: 1.5141533854855067
Validation loss: 2.620810975591857

Epoch: 5| Step: 7
Training loss: 1.7437792977226962
Validation loss: 2.6403331902385565

Epoch: 5| Step: 8
Training loss: 1.6668799104965077
Validation loss: 2.611002546564176

Epoch: 5| Step: 9
Training loss: 1.5144533957775583
Validation loss: 2.633669546021492

Epoch: 5| Step: 10
Training loss: 1.9535491482810858
Validation loss: 2.682137703153028

Epoch: 419| Step: 0
Training loss: 1.3218116149856092
Validation loss: 2.684747500241083

Epoch: 5| Step: 1
Training loss: 1.4772062159951078
Validation loss: 2.6604998019794524

Epoch: 5| Step: 2
Training loss: 1.5576464228741473
Validation loss: 2.630566271429585

Epoch: 5| Step: 3
Training loss: 2.090657925881065
Validation loss: 2.6120881134473075

Epoch: 5| Step: 4
Training loss: 1.5605515347484014
Validation loss: 2.597958029581628

Epoch: 5| Step: 5
Training loss: 1.3941885903856492
Validation loss: 2.593920928782828

Epoch: 5| Step: 6
Training loss: 1.614511902572407
Validation loss: 2.5953035403145623

Epoch: 5| Step: 7
Training loss: 1.782754496935569
Validation loss: 2.586878867765786

Epoch: 5| Step: 8
Training loss: 2.0178536802086136
Validation loss: 2.6410028544450364

Epoch: 5| Step: 9
Training loss: 1.2410252730126916
Validation loss: 2.648675674888286

Epoch: 5| Step: 10
Training loss: 2.067417063404575
Validation loss: 2.639948400532005

Epoch: 420| Step: 0
Training loss: 1.688650233712241
Validation loss: 2.6701600921285555

Epoch: 5| Step: 1
Training loss: 1.3482264984645975
Validation loss: 2.6397471290552263

Epoch: 5| Step: 2
Training loss: 1.7933560620017455
Validation loss: 2.623325212093958

Epoch: 5| Step: 3
Training loss: 2.0128070146935744
Validation loss: 2.596913996127842

Epoch: 5| Step: 4
Training loss: 1.4016457098136206
Validation loss: 2.557792439275814

Epoch: 5| Step: 5
Training loss: 1.3549453208419957
Validation loss: 2.563355774924103

Epoch: 5| Step: 6
Training loss: 2.0461968616257575
Validation loss: 2.555193112918643

Epoch: 5| Step: 7
Training loss: 1.9501783191626305
Validation loss: 2.5680531942845852

Epoch: 5| Step: 8
Training loss: 1.09680191405162
Validation loss: 2.5669357910490604

Epoch: 5| Step: 9
Training loss: 1.5498904497133565
Validation loss: 2.596868545624703

Epoch: 5| Step: 10
Training loss: 1.916516844104419
Validation loss: 2.6682579121527863

Epoch: 421| Step: 0
Training loss: 1.7887499673711427
Validation loss: 2.656721213502035

Epoch: 5| Step: 1
Training loss: 1.7976532950578032
Validation loss: 2.6821930082348477

Epoch: 5| Step: 2
Training loss: 1.63230150613779
Validation loss: 2.661902506419458

Epoch: 5| Step: 3
Training loss: 1.8505166234545531
Validation loss: 2.6796554677840088

Epoch: 5| Step: 4
Training loss: 1.9297573061529356
Validation loss: 2.641169377907823

Epoch: 5| Step: 5
Training loss: 1.625583983904494
Validation loss: 2.6105931630226866

Epoch: 5| Step: 6
Training loss: 1.6763279163250062
Validation loss: 2.6049527766477696

Epoch: 5| Step: 7
Training loss: 1.53859072197889
Validation loss: 2.600757032101199

Epoch: 5| Step: 8
Training loss: 1.6790699377983236
Validation loss: 2.6049617473228914

Epoch: 5| Step: 9
Training loss: 1.5425939949863412
Validation loss: 2.6326378513999775

Epoch: 5| Step: 10
Training loss: 1.1640904570428987
Validation loss: 2.6030023885301556

Epoch: 422| Step: 0
Training loss: 1.4871390858541271
Validation loss: 2.632052180118736

Epoch: 5| Step: 1
Training loss: 1.8340119348634785
Validation loss: 2.680828393936854

Epoch: 5| Step: 2
Training loss: 1.3797464377579667
Validation loss: 2.6906437354707347

Epoch: 5| Step: 3
Training loss: 1.9573146592015096
Validation loss: 2.6769118434646226

Epoch: 5| Step: 4
Training loss: 1.55683099403501
Validation loss: 2.6436980815952116

Epoch: 5| Step: 5
Training loss: 1.5830013362086062
Validation loss: 2.633759059296566

Epoch: 5| Step: 6
Training loss: 2.1916504858118295
Validation loss: 2.614672813033219

Epoch: 5| Step: 7
Training loss: 1.4827597412756728
Validation loss: 2.6000887641868307

Epoch: 5| Step: 8
Training loss: 1.6349869262685905
Validation loss: 2.5514059956405153

Epoch: 5| Step: 9
Training loss: 1.4253063508385995
Validation loss: 2.5904102590857874

Epoch: 5| Step: 10
Training loss: 1.5989242036471865
Validation loss: 2.581358676569163

Epoch: 423| Step: 0
Training loss: 1.5517426016501974
Validation loss: 2.5988518296894734

Epoch: 5| Step: 1
Training loss: 1.5789263362069323
Validation loss: 2.6027381499912257

Epoch: 5| Step: 2
Training loss: 1.753448426575134
Validation loss: 2.642998955109083

Epoch: 5| Step: 3
Training loss: 1.599815569619281
Validation loss: 2.6663639341557093

Epoch: 5| Step: 4
Training loss: 1.785703345673973
Validation loss: 2.663313305657429

Epoch: 5| Step: 5
Training loss: 1.4698243777147197
Validation loss: 2.6499456603611726

Epoch: 5| Step: 6
Training loss: 1.5332182087733341
Validation loss: 2.640513554217797

Epoch: 5| Step: 7
Training loss: 1.8203413146525722
Validation loss: 2.6287714872712353

Epoch: 5| Step: 8
Training loss: 1.7245898823484336
Validation loss: 2.638130740518175

Epoch: 5| Step: 9
Training loss: 1.4140855566010262
Validation loss: 2.6093751237916023

Epoch: 5| Step: 10
Training loss: 1.8447068527889303
Validation loss: 2.601967230205068

Epoch: 424| Step: 0
Training loss: 1.6425638277608674
Validation loss: 2.644470527266717

Epoch: 5| Step: 1
Training loss: 2.0159749754836054
Validation loss: 2.629341339494366

Epoch: 5| Step: 2
Training loss: 1.8565897877846365
Validation loss: 2.620505667910799

Epoch: 5| Step: 3
Training loss: 1.6125012005941963
Validation loss: 2.5853553232879287

Epoch: 5| Step: 4
Training loss: 1.2401471445240302
Validation loss: 2.5928909553524058

Epoch: 5| Step: 5
Training loss: 1.5596346713493359
Validation loss: 2.6364725055204197

Epoch: 5| Step: 6
Training loss: 1.6792403934596407
Validation loss: 2.627904711702604

Epoch: 5| Step: 7
Training loss: 1.521437285530725
Validation loss: 2.651462623934615

Epoch: 5| Step: 8
Training loss: 1.634864795005758
Validation loss: 2.662118180758103

Epoch: 5| Step: 9
Training loss: 1.5504185326857265
Validation loss: 2.68001071866873

Epoch: 5| Step: 10
Training loss: 1.5691533151559294
Validation loss: 2.6669582398531606

Epoch: 425| Step: 0
Training loss: 1.6510615142046476
Validation loss: 2.613077975021099

Epoch: 5| Step: 1
Training loss: 1.7997947522870787
Validation loss: 2.5459437174693895

Epoch: 5| Step: 2
Training loss: 1.355487130779778
Validation loss: 2.5754669279037326

Epoch: 5| Step: 3
Training loss: 1.751565641592647
Validation loss: 2.5424655969557883

Epoch: 5| Step: 4
Training loss: 1.9651752290903408
Validation loss: 2.5625503329004147

Epoch: 5| Step: 5
Training loss: 1.244008870237317
Validation loss: 2.5780432724513953

Epoch: 5| Step: 6
Training loss: 1.581800505211499
Validation loss: 2.582235234574375

Epoch: 5| Step: 7
Training loss: 1.360108407903015
Validation loss: 2.6262259972613613

Epoch: 5| Step: 8
Training loss: 2.059372814217827
Validation loss: 2.659153020171152

Epoch: 5| Step: 9
Training loss: 1.4718861476208775
Validation loss: 2.6882905715427117

Epoch: 5| Step: 10
Training loss: 1.50070015143567
Validation loss: 2.6917831562050205

Epoch: 426| Step: 0
Training loss: 1.1866329440850854
Validation loss: 2.674673788186931

Epoch: 5| Step: 1
Training loss: 1.7031119809834252
Validation loss: 2.666221628302696

Epoch: 5| Step: 2
Training loss: 1.643453212966849
Validation loss: 2.6802168696687523

Epoch: 5| Step: 3
Training loss: 1.7089056203952093
Validation loss: 2.640772821752702

Epoch: 5| Step: 4
Training loss: 1.763318538651781
Validation loss: 2.6379312473059455

Epoch: 5| Step: 5
Training loss: 2.1057112913263856
Validation loss: 2.6240596483506895

Epoch: 5| Step: 6
Training loss: 1.1798440185190915
Validation loss: 2.603298120843359

Epoch: 5| Step: 7
Training loss: 1.6977013839571333
Validation loss: 2.585281254598558

Epoch: 5| Step: 8
Training loss: 1.5640338235792886
Validation loss: 2.567325142033608

Epoch: 5| Step: 9
Training loss: 1.759334600333716
Validation loss: 2.5870605742400095

Epoch: 5| Step: 10
Training loss: 1.4192695641001587
Validation loss: 2.589544760552778

Epoch: 427| Step: 0
Training loss: 1.5527918774975569
Validation loss: 2.596925918362052

Epoch: 5| Step: 1
Training loss: 1.7918943955350035
Validation loss: 2.5733421192798125

Epoch: 5| Step: 2
Training loss: 1.3554219614358034
Validation loss: 2.580145502107682

Epoch: 5| Step: 3
Training loss: 1.7305857874986885
Validation loss: 2.6010339518993666

Epoch: 5| Step: 4
Training loss: 1.6478627726169157
Validation loss: 2.599848070903995

Epoch: 5| Step: 5
Training loss: 1.9495934869619094
Validation loss: 2.6111809033128557

Epoch: 5| Step: 6
Training loss: 1.6575899282142093
Validation loss: 2.6069539681013363

Epoch: 5| Step: 7
Training loss: 1.7173157690040497
Validation loss: 2.6285912265667664

Epoch: 5| Step: 8
Training loss: 1.1584976104955351
Validation loss: 2.6290054330615478

Epoch: 5| Step: 9
Training loss: 1.8071207923985302
Validation loss: 2.614011779433922

Epoch: 5| Step: 10
Training loss: 1.3873626503536094
Validation loss: 2.621643002011617

Epoch: 428| Step: 0
Training loss: 1.5179804166854967
Validation loss: 2.6224517954787046

Epoch: 5| Step: 1
Training loss: 1.502408160863696
Validation loss: 2.6386235149203743

Epoch: 5| Step: 2
Training loss: 1.513337050291922
Validation loss: 2.645093242827714

Epoch: 5| Step: 3
Training loss: 1.2443133702864044
Validation loss: 2.6567988755738092

Epoch: 5| Step: 4
Training loss: 1.6269453582028748
Validation loss: 2.6524155525926028

Epoch: 5| Step: 5
Training loss: 1.4715979540125028
Validation loss: 2.6818978800815567

Epoch: 5| Step: 6
Training loss: 1.5860960932768715
Validation loss: 2.677123830329459

Epoch: 5| Step: 7
Training loss: 1.845246176694644
Validation loss: 2.666519228899684

Epoch: 5| Step: 8
Training loss: 1.6010415323125435
Validation loss: 2.6176040535866822

Epoch: 5| Step: 9
Training loss: 1.7579812202014715
Validation loss: 2.5791555274774387

Epoch: 5| Step: 10
Training loss: 2.0261497436044307
Validation loss: 2.5685147712617167

Epoch: 429| Step: 0
Training loss: 1.3210273929039982
Validation loss: 2.551251144959182

Epoch: 5| Step: 1
Training loss: 1.7152158294418791
Validation loss: 2.5365603200035314

Epoch: 5| Step: 2
Training loss: 1.6824450191679945
Validation loss: 2.545517240004111

Epoch: 5| Step: 3
Training loss: 1.8852743934638567
Validation loss: 2.535554374613855

Epoch: 5| Step: 4
Training loss: 1.4220379746486285
Validation loss: 2.55128268619676

Epoch: 5| Step: 5
Training loss: 1.4831711555433318
Validation loss: 2.578729980525291

Epoch: 5| Step: 6
Training loss: 1.7870285933117016
Validation loss: 2.6057765396569543

Epoch: 5| Step: 7
Training loss: 1.8971144850254065
Validation loss: 2.6057713853674866

Epoch: 5| Step: 8
Training loss: 1.5261302917923636
Validation loss: 2.637340458442568

Epoch: 5| Step: 9
Training loss: 1.2266940878484551
Validation loss: 2.6617805499908154

Epoch: 5| Step: 10
Training loss: 1.580404618037377
Validation loss: 2.632799015793877

Epoch: 430| Step: 0
Training loss: 1.0892313668944864
Validation loss: 2.6424319604116477

Epoch: 5| Step: 1
Training loss: 1.4128960703986637
Validation loss: 2.6616178714036796

Epoch: 5| Step: 2
Training loss: 1.55280047581885
Validation loss: 2.606462829954162

Epoch: 5| Step: 3
Training loss: 1.9239100404911316
Validation loss: 2.6014524219326316

Epoch: 5| Step: 4
Training loss: 1.6605721704408989
Validation loss: 2.6327524573606453

Epoch: 5| Step: 5
Training loss: 1.963969223733058
Validation loss: 2.6447675918071223

Epoch: 5| Step: 6
Training loss: 1.72913414185357
Validation loss: 2.62356478535194

Epoch: 5| Step: 7
Training loss: 1.3145919205052117
Validation loss: 2.6317238078053324

Epoch: 5| Step: 8
Training loss: 1.471313430987422
Validation loss: 2.6078422681579045

Epoch: 5| Step: 9
Training loss: 1.810417820879265
Validation loss: 2.6172434468259396

Epoch: 5| Step: 10
Training loss: 1.3208792559144606
Validation loss: 2.628068139759713

Epoch: 431| Step: 0
Training loss: 1.4645684962744285
Validation loss: 2.6058387248295216

Epoch: 5| Step: 1
Training loss: 1.6335289218468498
Validation loss: 2.6223508942169382

Epoch: 5| Step: 2
Training loss: 1.7518703819646813
Validation loss: 2.64018690233836

Epoch: 5| Step: 3
Training loss: 1.3720046275425046
Validation loss: 2.6550568498919858

Epoch: 5| Step: 4
Training loss: 1.3800598592491482
Validation loss: 2.679223023133839

Epoch: 5| Step: 5
Training loss: 1.4571348260877253
Validation loss: 2.696057048897288

Epoch: 5| Step: 6
Training loss: 1.7781170514671585
Validation loss: 2.68365027649402

Epoch: 5| Step: 7
Training loss: 1.624551784616381
Validation loss: 2.6688875917986628

Epoch: 5| Step: 8
Training loss: 1.8155771639853289
Validation loss: 2.6465050130023595

Epoch: 5| Step: 9
Training loss: 1.517038374544325
Validation loss: 2.619883814053717

Epoch: 5| Step: 10
Training loss: 1.5439645378754394
Validation loss: 2.640549237962386

Epoch: 432| Step: 0
Training loss: 1.1956604095974472
Validation loss: 2.59918918793091

Epoch: 5| Step: 1
Training loss: 1.4581925823771718
Validation loss: 2.6399984366976925

Epoch: 5| Step: 2
Training loss: 1.6433458563899412
Validation loss: 2.6200788468510456

Epoch: 5| Step: 3
Training loss: 1.7678277108190634
Validation loss: 2.6372269082804056

Epoch: 5| Step: 4
Training loss: 1.7158765875891744
Validation loss: 2.5997170460775503

Epoch: 5| Step: 5
Training loss: 1.7418887305565451
Validation loss: 2.623671813377379

Epoch: 5| Step: 6
Training loss: 1.6153650749862178
Validation loss: 2.636846503137035

Epoch: 5| Step: 7
Training loss: 1.1423300971111596
Validation loss: 2.679266833555535

Epoch: 5| Step: 8
Training loss: 1.2575222177988552
Validation loss: 2.6657689670350755

Epoch: 5| Step: 9
Training loss: 1.7768508395317892
Validation loss: 2.6882764701453765

Epoch: 5| Step: 10
Training loss: 1.931644759834269
Validation loss: 2.683834723490343

Epoch: 433| Step: 0
Training loss: 1.7420677520242496
Validation loss: 2.6723592573963506

Epoch: 5| Step: 1
Training loss: 1.7261401043825746
Validation loss: 2.638942937364019

Epoch: 5| Step: 2
Training loss: 1.5144870851658105
Validation loss: 2.5881377930726694

Epoch: 5| Step: 3
Training loss: 1.5059820736227234
Validation loss: 2.5743671125323275

Epoch: 5| Step: 4
Training loss: 1.6271878699384121
Validation loss: 2.5568091034937805

Epoch: 5| Step: 5
Training loss: 1.2494663052879524
Validation loss: 2.583283528758517

Epoch: 5| Step: 6
Training loss: 2.092264815847016
Validation loss: 2.5456011528440445

Epoch: 5| Step: 7
Training loss: 1.5438450123819003
Validation loss: 2.5995540496364575

Epoch: 5| Step: 8
Training loss: 1.4096820911192924
Validation loss: 2.6371000582229978

Epoch: 5| Step: 9
Training loss: 1.4783772614212525
Validation loss: 2.624590642079609

Epoch: 5| Step: 10
Training loss: 1.602370416576503
Validation loss: 2.6343337241646796

Epoch: 434| Step: 0
Training loss: 1.5601973542064722
Validation loss: 2.634762368349606

Epoch: 5| Step: 1
Training loss: 1.2249348039210564
Validation loss: 2.6024648021851293

Epoch: 5| Step: 2
Training loss: 1.8610135079723276
Validation loss: 2.6057438841733127

Epoch: 5| Step: 3
Training loss: 1.8166102797247101
Validation loss: 2.575547362589855

Epoch: 5| Step: 4
Training loss: 1.4505086335560047
Validation loss: 2.574181852979263

Epoch: 5| Step: 5
Training loss: 1.7346784309063548
Validation loss: 2.5930641780841825

Epoch: 5| Step: 6
Training loss: 1.4693207139242341
Validation loss: 2.5893582097546357

Epoch: 5| Step: 7
Training loss: 1.8785500297798796
Validation loss: 2.6313410619015327

Epoch: 5| Step: 8
Training loss: 1.2790080669050254
Validation loss: 2.6765540415205993

Epoch: 5| Step: 9
Training loss: 1.5127905858120636
Validation loss: 2.694701175519735

Epoch: 5| Step: 10
Training loss: 1.6770976127190362
Validation loss: 2.729503253570413

Epoch: 435| Step: 0
Training loss: 1.7709636490686735
Validation loss: 2.678142428286681

Epoch: 5| Step: 1
Training loss: 1.5086604288814802
Validation loss: 2.67275656752006

Epoch: 5| Step: 2
Training loss: 1.3289223913864143
Validation loss: 2.6232479145075858

Epoch: 5| Step: 3
Training loss: 1.5254615054104563
Validation loss: 2.626399659809564

Epoch: 5| Step: 4
Training loss: 1.1995632409951251
Validation loss: 2.6139890695437473

Epoch: 5| Step: 5
Training loss: 1.3393773192912077
Validation loss: 2.578275143305655

Epoch: 5| Step: 6
Training loss: 1.8758408886104745
Validation loss: 2.598611077083429

Epoch: 5| Step: 7
Training loss: 1.5600308554605622
Validation loss: 2.576706494998573

Epoch: 5| Step: 8
Training loss: 1.7702142268998553
Validation loss: 2.5855130811844997

Epoch: 5| Step: 9
Training loss: 1.7784665763487648
Validation loss: 2.6187693958238203

Epoch: 5| Step: 10
Training loss: 1.5162389239404341
Validation loss: 2.5966048291479717

Epoch: 436| Step: 0
Training loss: 1.8880939408102397
Validation loss: 2.61106995533637

Epoch: 5| Step: 1
Training loss: 1.5081236523188652
Validation loss: 2.5767711934398836

Epoch: 5| Step: 2
Training loss: 1.6841535942907933
Validation loss: 2.5727497385619764

Epoch: 5| Step: 3
Training loss: 1.5948698559942764
Validation loss: 2.582371361603651

Epoch: 5| Step: 4
Training loss: 1.4180674452889848
Validation loss: 2.5844999775924973

Epoch: 5| Step: 5
Training loss: 1.262222803485838
Validation loss: 2.5944119579947937

Epoch: 5| Step: 6
Training loss: 1.4657841219872378
Validation loss: 2.6216587086019145

Epoch: 5| Step: 7
Training loss: 1.3829304273073395
Validation loss: 2.6378776324272404

Epoch: 5| Step: 8
Training loss: 1.6936068766465586
Validation loss: 2.6504748021807454

Epoch: 5| Step: 9
Training loss: 1.3699976786712138
Validation loss: 2.686442555151859

Epoch: 5| Step: 10
Training loss: 1.7569475546680744
Validation loss: 2.7059054855486875

Epoch: 437| Step: 0
Training loss: 1.5994557736606418
Validation loss: 2.68342429234736

Epoch: 5| Step: 1
Training loss: 1.6420899163460807
Validation loss: 2.6972831362014587

Epoch: 5| Step: 2
Training loss: 1.9094231881961352
Validation loss: 2.660917460050163

Epoch: 5| Step: 3
Training loss: 1.4454872644286307
Validation loss: 2.6422295551750894

Epoch: 5| Step: 4
Training loss: 1.806137295278956
Validation loss: 2.6266947684380995

Epoch: 5| Step: 5
Training loss: 1.537112709827029
Validation loss: 2.5972608854007184

Epoch: 5| Step: 6
Training loss: 1.4473124096267433
Validation loss: 2.5865067577673773

Epoch: 5| Step: 7
Training loss: 1.5119261291361425
Validation loss: 2.567995392122499

Epoch: 5| Step: 8
Training loss: 1.35205175111129
Validation loss: 2.593695859298291

Epoch: 5| Step: 9
Training loss: 1.193935523670867
Validation loss: 2.6036750335950045

Epoch: 5| Step: 10
Training loss: 1.558371850759981
Validation loss: 2.601549145507435

Epoch: 438| Step: 0
Training loss: 1.1798745316541785
Validation loss: 2.6132801120345457

Epoch: 5| Step: 1
Training loss: 1.9918027618494774
Validation loss: 2.6291080544831353

Epoch: 5| Step: 2
Training loss: 1.452102793814443
Validation loss: 2.6325442673897177

Epoch: 5| Step: 3
Training loss: 1.220503987663284
Validation loss: 2.6253463284216862

Epoch: 5| Step: 4
Training loss: 1.9115627859681947
Validation loss: 2.624116365043527

Epoch: 5| Step: 5
Training loss: 1.8654804167321568
Validation loss: 2.605500022569027

Epoch: 5| Step: 6
Training loss: 1.2949969930135214
Validation loss: 2.609512760700622

Epoch: 5| Step: 7
Training loss: 1.6913185008767808
Validation loss: 2.6108652076495704

Epoch: 5| Step: 8
Training loss: 1.2255120122127063
Validation loss: 2.607905592552882

Epoch: 5| Step: 9
Training loss: 1.458740622548327
Validation loss: 2.613734581904015

Epoch: 5| Step: 10
Training loss: 1.4128330006975727
Validation loss: 2.639844889488929

Epoch: 439| Step: 0
Training loss: 1.5915190097297924
Validation loss: 2.6775874266619275

Epoch: 5| Step: 1
Training loss: 1.6472228578620243
Validation loss: 2.7035140431471065

Epoch: 5| Step: 2
Training loss: 1.2967559575976753
Validation loss: 2.6797443461474777

Epoch: 5| Step: 3
Training loss: 1.4243913120140865
Validation loss: 2.6785935976719535

Epoch: 5| Step: 4
Training loss: 1.5325478483761137
Validation loss: 2.6855104789467656

Epoch: 5| Step: 5
Training loss: 1.3306997585841942
Validation loss: 2.6326684526232755

Epoch: 5| Step: 6
Training loss: 1.474523276537589
Validation loss: 2.6188246099007286

Epoch: 5| Step: 7
Training loss: 1.8442606461279607
Validation loss: 2.5818046386111257

Epoch: 5| Step: 8
Training loss: 1.4626064457425187
Validation loss: 2.5760048778535904

Epoch: 5| Step: 9
Training loss: 1.6986412733257004
Validation loss: 2.571620751473862

Epoch: 5| Step: 10
Training loss: 1.5903823277710074
Validation loss: 2.5657607321045326

Epoch: 440| Step: 0
Training loss: 1.5240899669494439
Validation loss: 2.5408183302138547

Epoch: 5| Step: 1
Training loss: 1.295117991974589
Validation loss: 2.5641622806786053

Epoch: 5| Step: 2
Training loss: 1.4756898269082424
Validation loss: 2.562010765143909

Epoch: 5| Step: 3
Training loss: 1.8340881773281692
Validation loss: 2.5584605783741243

Epoch: 5| Step: 4
Training loss: 1.2538902780816883
Validation loss: 2.6052861458485004

Epoch: 5| Step: 5
Training loss: 1.3115800176418162
Validation loss: 2.6356624216475093

Epoch: 5| Step: 6
Training loss: 1.7453833037164328
Validation loss: 2.6638971343029003

Epoch: 5| Step: 7
Training loss: 1.5382221851856495
Validation loss: 2.688796338150182

Epoch: 5| Step: 8
Training loss: 1.2166687238144576
Validation loss: 2.7204832653627213

Epoch: 5| Step: 9
Training loss: 1.79227888012356
Validation loss: 2.7055079322629356

Epoch: 5| Step: 10
Training loss: 1.8108080497599854
Validation loss: 2.699871391961522

Epoch: 441| Step: 0
Training loss: 1.1591562398902757
Validation loss: 2.647150313775289

Epoch: 5| Step: 1
Training loss: 1.3098603452977935
Validation loss: 2.6275223246736203

Epoch: 5| Step: 2
Training loss: 1.2343621555094677
Validation loss: 2.60623466892651

Epoch: 5| Step: 3
Training loss: 1.4977729477287263
Validation loss: 2.5932831574510886

Epoch: 5| Step: 4
Training loss: 1.7155450937809174
Validation loss: 2.5508841319982984

Epoch: 5| Step: 5
Training loss: 1.4638113223683906
Validation loss: 2.5549189618974895

Epoch: 5| Step: 6
Training loss: 1.5935395793757328
Validation loss: 2.618008621697603

Epoch: 5| Step: 7
Training loss: 1.55329618067099
Validation loss: 2.613280416146052

Epoch: 5| Step: 8
Training loss: 1.5739144535204994
Validation loss: 2.6210312792552255

Epoch: 5| Step: 9
Training loss: 1.999728363187119
Validation loss: 2.6376413798594274

Epoch: 5| Step: 10
Training loss: 1.4405229544752125
Validation loss: 2.6467119382218938

Epoch: 442| Step: 0
Training loss: 1.3716737221543716
Validation loss: 2.6488316756525276

Epoch: 5| Step: 1
Training loss: 1.724473613091408
Validation loss: 2.661044665123535

Epoch: 5| Step: 2
Training loss: 1.508335003228431
Validation loss: 2.6444167182642304

Epoch: 5| Step: 3
Training loss: 1.7983112731702433
Validation loss: 2.63149438146551

Epoch: 5| Step: 4
Training loss: 1.243143877103774
Validation loss: 2.6360274001231487

Epoch: 5| Step: 5
Training loss: 1.3293120520950275
Validation loss: 2.621612263290857

Epoch: 5| Step: 6
Training loss: 1.7874872193846592
Validation loss: 2.652233877290505

Epoch: 5| Step: 7
Training loss: 1.036722804437455
Validation loss: 2.639093447969291

Epoch: 5| Step: 8
Training loss: 1.562615962493739
Validation loss: 2.6134166211891734

Epoch: 5| Step: 9
Training loss: 1.6851343598268196
Validation loss: 2.633958040224681

Epoch: 5| Step: 10
Training loss: 1.4558684999483456
Validation loss: 2.5845828043257404

Epoch: 443| Step: 0
Training loss: 1.2942191816598885
Validation loss: 2.5779991579091246

Epoch: 5| Step: 1
Training loss: 1.456620800305896
Validation loss: 2.59546740522174

Epoch: 5| Step: 2
Training loss: 1.4844963425680855
Validation loss: 2.565348754701936

Epoch: 5| Step: 3
Training loss: 1.2397325356498192
Validation loss: 2.565865978906449

Epoch: 5| Step: 4
Training loss: 1.7534393164775375
Validation loss: 2.573720047245193

Epoch: 5| Step: 5
Training loss: 1.658702042898998
Validation loss: 2.5997689807099404

Epoch: 5| Step: 6
Training loss: 1.4201184835835958
Validation loss: 2.623553219669395

Epoch: 5| Step: 7
Training loss: 1.7853414159857244
Validation loss: 2.6221584423576725

Epoch: 5| Step: 8
Training loss: 1.6790231499816906
Validation loss: 2.6246514135310792

Epoch: 5| Step: 9
Training loss: 1.2631295645667666
Validation loss: 2.6441708358224463

Epoch: 5| Step: 10
Training loss: 1.4002733168156454
Validation loss: 2.635434546347774

Epoch: 444| Step: 0
Training loss: 1.0291682530338144
Validation loss: 2.633954200539491

Epoch: 5| Step: 1
Training loss: 1.6237304570032929
Validation loss: 2.621341173122072

Epoch: 5| Step: 2
Training loss: 1.3446453571386805
Validation loss: 2.618041994727353

Epoch: 5| Step: 3
Training loss: 1.341854710561006
Validation loss: 2.6068856071645623

Epoch: 5| Step: 4
Training loss: 1.5344776468845847
Validation loss: 2.5924658266849985

Epoch: 5| Step: 5
Training loss: 1.5447658455204698
Validation loss: 2.6065338890224785

Epoch: 5| Step: 6
Training loss: 1.713298127125606
Validation loss: 2.573536555110634

Epoch: 5| Step: 7
Training loss: 1.658166676043202
Validation loss: 2.6058689235736785

Epoch: 5| Step: 8
Training loss: 1.6421728189757656
Validation loss: 2.5997852474182266

Epoch: 5| Step: 9
Training loss: 1.6983510575322676
Validation loss: 2.618911833866271

Epoch: 5| Step: 10
Training loss: 1.2050922213677415
Validation loss: 2.6178194152794516

Epoch: 445| Step: 0
Training loss: 1.9473048046459664
Validation loss: 2.6213089335440607

Epoch: 5| Step: 1
Training loss: 1.2387093847797417
Validation loss: 2.634149815888938

Epoch: 5| Step: 2
Training loss: 1.115341635655089
Validation loss: 2.63693657161061

Epoch: 5| Step: 3
Training loss: 1.3400346269688426
Validation loss: 2.619539532067065

Epoch: 5| Step: 4
Training loss: 1.3355295997432877
Validation loss: 2.619674646406217

Epoch: 5| Step: 5
Training loss: 1.4933660356880463
Validation loss: 2.615799099613824

Epoch: 5| Step: 6
Training loss: 1.1698545204095805
Validation loss: 2.6364103330580417

Epoch: 5| Step: 7
Training loss: 1.6399182205046803
Validation loss: 2.6527333471601273

Epoch: 5| Step: 8
Training loss: 1.7480937930156057
Validation loss: 2.6317646546998943

Epoch: 5| Step: 9
Training loss: 1.4245682246271787
Validation loss: 2.6095743410815664

Epoch: 5| Step: 10
Training loss: 1.7557022652441243
Validation loss: 2.634695888794938

Epoch: 446| Step: 0
Training loss: 1.6231762849375426
Validation loss: 2.6362838910341404

Epoch: 5| Step: 1
Training loss: 1.780050509625566
Validation loss: 2.634348363440855

Epoch: 5| Step: 2
Training loss: 1.8860527426868028
Validation loss: 2.6059183292867165

Epoch: 5| Step: 3
Training loss: 1.6780953601798247
Validation loss: 2.5850508938076726

Epoch: 5| Step: 4
Training loss: 1.2191847001517475
Validation loss: 2.5750403333277467

Epoch: 5| Step: 5
Training loss: 1.2547411649445752
Validation loss: 2.5739448087025885

Epoch: 5| Step: 6
Training loss: 1.5347413723049568
Validation loss: 2.584638935182908

Epoch: 5| Step: 7
Training loss: 1.2697450428456796
Validation loss: 2.5892498415770495

Epoch: 5| Step: 8
Training loss: 0.9265096832712235
Validation loss: 2.5703724383101045

Epoch: 5| Step: 9
Training loss: 1.503894359987495
Validation loss: 2.5748540499031125

Epoch: 5| Step: 10
Training loss: 1.37008921458047
Validation loss: 2.6370249979271723

Epoch: 447| Step: 0
Training loss: 1.5224646959142192
Validation loss: 2.6445143327350493

Epoch: 5| Step: 1
Training loss: 1.2068649226774948
Validation loss: 2.682192128898512

Epoch: 5| Step: 2
Training loss: 1.35395336916596
Validation loss: 2.6804795273986337

Epoch: 5| Step: 3
Training loss: 1.4783950010652784
Validation loss: 2.655905151662855

Epoch: 5| Step: 4
Training loss: 1.1455555261169375
Validation loss: 2.665781794011814

Epoch: 5| Step: 5
Training loss: 1.5976368499548
Validation loss: 2.629389579744598

Epoch: 5| Step: 6
Training loss: 1.5221444927257166
Validation loss: 2.5972351744518587

Epoch: 5| Step: 7
Training loss: 1.7111867784033032
Validation loss: 2.576809775538212

Epoch: 5| Step: 8
Training loss: 1.7671508947168282
Validation loss: 2.567765621128725

Epoch: 5| Step: 9
Training loss: 1.4830641730912921
Validation loss: 2.550926631118798

Epoch: 5| Step: 10
Training loss: 1.4717327429833886
Validation loss: 2.6217085149445034

Epoch: 448| Step: 0
Training loss: 1.3304578152362325
Validation loss: 2.619702286130192

Epoch: 5| Step: 1
Training loss: 1.5528816968977182
Validation loss: 2.655602415649679

Epoch: 5| Step: 2
Training loss: 1.424494165019614
Validation loss: 2.6482603184640916

Epoch: 5| Step: 3
Training loss: 1.4714473548568547
Validation loss: 2.696947714766725

Epoch: 5| Step: 4
Training loss: 1.414531651012988
Validation loss: 2.6784075186523792

Epoch: 5| Step: 5
Training loss: 1.5248473857121356
Validation loss: 2.687836530810567

Epoch: 5| Step: 6
Training loss: 1.399662440340318
Validation loss: 2.651561721267077

Epoch: 5| Step: 7
Training loss: 1.5132785212187418
Validation loss: 2.6313224337642818

Epoch: 5| Step: 8
Training loss: 1.3861516088270462
Validation loss: 2.5753249439559665

Epoch: 5| Step: 9
Training loss: 1.8568458987805738
Validation loss: 2.54197819631443

Epoch: 5| Step: 10
Training loss: 1.3845022620957212
Validation loss: 2.551003595657983

Epoch: 449| Step: 0
Training loss: 1.2665431142246282
Validation loss: 2.5586316142614773

Epoch: 5| Step: 1
Training loss: 1.115535822277347
Validation loss: 2.5839572833423765

Epoch: 5| Step: 2
Training loss: 1.4879432755035835
Validation loss: 2.566033269233438

Epoch: 5| Step: 3
Training loss: 1.5814485960477906
Validation loss: 2.6357695916216

Epoch: 5| Step: 4
Training loss: 1.2895734756824269
Validation loss: 2.6372836431454103

Epoch: 5| Step: 5
Training loss: 1.7818206408453625
Validation loss: 2.659931028227341

Epoch: 5| Step: 6
Training loss: 1.4399488571144972
Validation loss: 2.6756601465345837

Epoch: 5| Step: 7
Training loss: 1.2246682184857078
Validation loss: 2.6604535847372164

Epoch: 5| Step: 8
Training loss: 1.8838903737053732
Validation loss: 2.6697206723916107

Epoch: 5| Step: 9
Training loss: 1.5173107878921288
Validation loss: 2.625060616460871

Epoch: 5| Step: 10
Training loss: 1.69303952620591
Validation loss: 2.6050718913895876

Epoch: 450| Step: 0
Training loss: 1.1581256190801161
Validation loss: 2.5650712625731282

Epoch: 5| Step: 1
Training loss: 1.4453618221630709
Validation loss: 2.576779177534195

Epoch: 5| Step: 2
Training loss: 1.542331844172196
Validation loss: 2.5769300598292073

Epoch: 5| Step: 3
Training loss: 1.7032775810558423
Validation loss: 2.534318878279543

Epoch: 5| Step: 4
Training loss: 1.4193036650147035
Validation loss: 2.581943474168844

Epoch: 5| Step: 5
Training loss: 1.9130362114278263
Validation loss: 2.581595955685742

Epoch: 5| Step: 6
Training loss: 1.6751405429237134
Validation loss: 2.5867273844176855

Epoch: 5| Step: 7
Training loss: 1.2938948250763564
Validation loss: 2.6186268912934585

Epoch: 5| Step: 8
Training loss: 1.2699014446735464
Validation loss: 2.6000739044101353

Epoch: 5| Step: 9
Training loss: 1.3740700264456298
Validation loss: 2.6172845598692764

Epoch: 5| Step: 10
Training loss: 1.254514410067674
Validation loss: 2.651157943200243

Epoch: 451| Step: 0
Training loss: 1.5215208859647644
Validation loss: 2.6088229921779047

Epoch: 5| Step: 1
Training loss: 1.5125517213663635
Validation loss: 2.641082687115343

Epoch: 5| Step: 2
Training loss: 1.594987501017707
Validation loss: 2.6429224982166466

Epoch: 5| Step: 3
Training loss: 1.4555127614810626
Validation loss: 2.625843826589409

Epoch: 5| Step: 4
Training loss: 1.332977987661426
Validation loss: 2.628873632182633

Epoch: 5| Step: 5
Training loss: 1.5571821890871909
Validation loss: 2.6175672446334177

Epoch: 5| Step: 6
Training loss: 1.024109015853258
Validation loss: 2.621701367820848

Epoch: 5| Step: 7
Training loss: 1.34755102659017
Validation loss: 2.5968027248966714

Epoch: 5| Step: 8
Training loss: 1.8356789914205716
Validation loss: 2.5995229836441123

Epoch: 5| Step: 9
Training loss: 1.2460805958020678
Validation loss: 2.5692265601559234

Epoch: 5| Step: 10
Training loss: 1.3731553969493557
Validation loss: 2.6009836136400715

Epoch: 452| Step: 0
Training loss: 1.197927867450041
Validation loss: 2.606222753863614

Epoch: 5| Step: 1
Training loss: 1.3955289119676357
Validation loss: 2.576993990627002

Epoch: 5| Step: 2
Training loss: 1.4840272194867217
Validation loss: 2.610576678873344

Epoch: 5| Step: 3
Training loss: 1.3893441720306052
Validation loss: 2.6244812544141825

Epoch: 5| Step: 4
Training loss: 1.2435798758700896
Validation loss: 2.6095664347304175

Epoch: 5| Step: 5
Training loss: 1.5138147299020794
Validation loss: 2.6262783877337235

Epoch: 5| Step: 6
Training loss: 1.9251697490210509
Validation loss: 2.65263440860501

Epoch: 5| Step: 7
Training loss: 1.0470185821909976
Validation loss: 2.6807448409063706

Epoch: 5| Step: 8
Training loss: 1.4749382814329062
Validation loss: 2.634673681216044

Epoch: 5| Step: 9
Training loss: 1.2529563752303132
Validation loss: 2.6512533523566146

Epoch: 5| Step: 10
Training loss: 1.8264035327873869
Validation loss: 2.6318879396650683

Epoch: 453| Step: 0
Training loss: 1.5036942766096255
Validation loss: 2.624947746135697

Epoch: 5| Step: 1
Training loss: 1.4677185332587082
Validation loss: 2.592888710959232

Epoch: 5| Step: 2
Training loss: 1.634673887388286
Validation loss: 2.648685493199623

Epoch: 5| Step: 3
Training loss: 1.2320011345684723
Validation loss: 2.6250933314625646

Epoch: 5| Step: 4
Training loss: 1.2194776563579934
Validation loss: 2.627239691837292

Epoch: 5| Step: 5
Training loss: 1.4524601881969499
Validation loss: 2.5988485665066903

Epoch: 5| Step: 6
Training loss: 1.4953769331137294
Validation loss: 2.616168874699428

Epoch: 5| Step: 7
Training loss: 1.1708944668992831
Validation loss: 2.649232318778215

Epoch: 5| Step: 8
Training loss: 1.4919356687856624
Validation loss: 2.6422017018723807

Epoch: 5| Step: 9
Training loss: 1.4999860921850767
Validation loss: 2.6293840261695043

Epoch: 5| Step: 10
Training loss: 1.6542369196632485
Validation loss: 2.6141551523919597

Epoch: 454| Step: 0
Training loss: 1.275707024530883
Validation loss: 2.64169130775442

Epoch: 5| Step: 1
Training loss: 1.3775199859609304
Validation loss: 2.652809198036634

Epoch: 5| Step: 2
Training loss: 1.3835856113808356
Validation loss: 2.6540043091099506

Epoch: 5| Step: 3
Training loss: 1.318088667591771
Validation loss: 2.662844444786572

Epoch: 5| Step: 4
Training loss: 1.847910696175559
Validation loss: 2.6495593726438567

Epoch: 5| Step: 5
Training loss: 1.241056395123064
Validation loss: 2.6565751476933865

Epoch: 5| Step: 6
Training loss: 1.3415087261392449
Validation loss: 2.636303466275856

Epoch: 5| Step: 7
Training loss: 1.3221270039187885
Validation loss: 2.6345785853569006

Epoch: 5| Step: 8
Training loss: 1.6372228315064823
Validation loss: 2.616846114796259

Epoch: 5| Step: 9
Training loss: 1.5035277051234714
Validation loss: 2.5784207042406297

Epoch: 5| Step: 10
Training loss: 1.4691516245942668
Validation loss: 2.5889482564889654

Epoch: 455| Step: 0
Training loss: 1.521575729115174
Validation loss: 2.5746986210403215

Epoch: 5| Step: 1
Training loss: 1.1515387357953841
Validation loss: 2.5746823312527973

Epoch: 5| Step: 2
Training loss: 1.4452971586495758
Validation loss: 2.5870930632334814

Epoch: 5| Step: 3
Training loss: 1.2354643638285003
Validation loss: 2.604858643835768

Epoch: 5| Step: 4
Training loss: 1.649510617363354
Validation loss: 2.6333708216313294

Epoch: 5| Step: 5
Training loss: 1.43373676802791
Validation loss: 2.657354786466183

Epoch: 5| Step: 6
Training loss: 1.3308871101465456
Validation loss: 2.6536997859127918

Epoch: 5| Step: 7
Training loss: 1.5340661602400107
Validation loss: 2.6728474727210587

Epoch: 5| Step: 8
Training loss: 1.4053108470144426
Validation loss: 2.6617080869576406

Epoch: 5| Step: 9
Training loss: 1.7143688891305742
Validation loss: 2.6480678346704827

Epoch: 5| Step: 10
Training loss: 1.1636760505429764
Validation loss: 2.610463551552499

Epoch: 456| Step: 0
Training loss: 1.1433629657883164
Validation loss: 2.60303962651331

Epoch: 5| Step: 1
Training loss: 1.6428800071878586
Validation loss: 2.6019298335152605

Epoch: 5| Step: 2
Training loss: 1.569019373529176
Validation loss: 2.601862094829972

Epoch: 5| Step: 3
Training loss: 1.4172938398443329
Validation loss: 2.600313243856913

Epoch: 5| Step: 4
Training loss: 1.8961813121770006
Validation loss: 2.615270154677721

Epoch: 5| Step: 5
Training loss: 1.3708299779802593
Validation loss: 2.628737663365042

Epoch: 5| Step: 6
Training loss: 1.246075908090699
Validation loss: 2.6423196827130093

Epoch: 5| Step: 7
Training loss: 1.7249001487912774
Validation loss: 2.700556152624148

Epoch: 5| Step: 8
Training loss: 1.2091957610030455
Validation loss: 2.6460802755758737

Epoch: 5| Step: 9
Training loss: 1.3126337800647279
Validation loss: 2.6142545371669224

Epoch: 5| Step: 10
Training loss: 0.9960193381845084
Validation loss: 2.55124642112562

Epoch: 457| Step: 0
Training loss: 1.238633211098446
Validation loss: 2.5333563587289767

Epoch: 5| Step: 1
Training loss: 1.5152522149723582
Validation loss: 2.5616658671698733

Epoch: 5| Step: 2
Training loss: 1.3954331929976762
Validation loss: 2.553323924277211

Epoch: 5| Step: 3
Training loss: 1.6049399143035792
Validation loss: 2.548729851298822

Epoch: 5| Step: 4
Training loss: 1.4270682600947042
Validation loss: 2.6026799341668556

Epoch: 5| Step: 5
Training loss: 1.2734829011090467
Validation loss: 2.636821949168641

Epoch: 5| Step: 6
Training loss: 0.90785633972731
Validation loss: 2.6609423899682567

Epoch: 5| Step: 7
Training loss: 1.890620964613462
Validation loss: 2.651827763439582

Epoch: 5| Step: 8
Training loss: 1.1833522537670964
Validation loss: 2.683524121005128

Epoch: 5| Step: 9
Training loss: 1.6152215332111186
Validation loss: 2.6728662258023244

Epoch: 5| Step: 10
Training loss: 1.4276305029118137
Validation loss: 2.653433609704373

Epoch: 458| Step: 0
Training loss: 1.4188402088407512
Validation loss: 2.6442548343479246

Epoch: 5| Step: 1
Training loss: 1.3616262626645597
Validation loss: 2.605591435342127

Epoch: 5| Step: 2
Training loss: 1.1244344349324749
Validation loss: 2.604766901224553

Epoch: 5| Step: 3
Training loss: 1.0143906942435603
Validation loss: 2.5859170458154814

Epoch: 5| Step: 4
Training loss: 1.7746129110856526
Validation loss: 2.57921925203093

Epoch: 5| Step: 5
Training loss: 1.0709995932342298
Validation loss: 2.562679408546207

Epoch: 5| Step: 6
Training loss: 1.577321518414947
Validation loss: 2.5778528432179275

Epoch: 5| Step: 7
Training loss: 1.3052550583269953
Validation loss: 2.577471355709023

Epoch: 5| Step: 8
Training loss: 1.7558075724291475
Validation loss: 2.6128126233398787

Epoch: 5| Step: 9
Training loss: 1.463589388068199
Validation loss: 2.624055475198723

Epoch: 5| Step: 10
Training loss: 1.523381393573203
Validation loss: 2.632642160424298

Epoch: 459| Step: 0
Training loss: 1.4583062124001105
Validation loss: 2.6865843872743245

Epoch: 5| Step: 1
Training loss: 1.6088734558207125
Validation loss: 2.6505242595132557

Epoch: 5| Step: 2
Training loss: 0.8968349261751499
Validation loss: 2.653593315928287

Epoch: 5| Step: 3
Training loss: 1.8479428865392487
Validation loss: 2.6207779498676476

Epoch: 5| Step: 4
Training loss: 1.2800319743633188
Validation loss: 2.5892700922056417

Epoch: 5| Step: 5
Training loss: 1.5158271261503704
Validation loss: 2.5815231326917867

Epoch: 5| Step: 6
Training loss: 1.4581745152051668
Validation loss: 2.551705875237622

Epoch: 5| Step: 7
Training loss: 1.2308504995923761
Validation loss: 2.5995513395992726

Epoch: 5| Step: 8
Training loss: 1.2519179412135157
Validation loss: 2.5973102604085527

Epoch: 5| Step: 9
Training loss: 0.9868870728269469
Validation loss: 2.6189289703523317

Epoch: 5| Step: 10
Training loss: 1.6917965903289633
Validation loss: 2.629582864344489

Epoch: 460| Step: 0
Training loss: 1.4933478352716743
Validation loss: 2.6362492241205264

Epoch: 5| Step: 1
Training loss: 1.2947254520997888
Validation loss: 2.6322039028606925

Epoch: 5| Step: 2
Training loss: 1.432422627328426
Validation loss: 2.636996781469631

Epoch: 5| Step: 3
Training loss: 0.8153060728019369
Validation loss: 2.634489548043133

Epoch: 5| Step: 4
Training loss: 1.0228913575334926
Validation loss: 2.639579817066586

Epoch: 5| Step: 5
Training loss: 1.6450591701080963
Validation loss: 2.6465017233320336

Epoch: 5| Step: 6
Training loss: 1.6204307579211896
Validation loss: 2.643357537498135

Epoch: 5| Step: 7
Training loss: 1.6817792775483689
Validation loss: 2.6178104565924905

Epoch: 5| Step: 8
Training loss: 1.3879293825560883
Validation loss: 2.616591030101737

Epoch: 5| Step: 9
Training loss: 1.279082255524286
Validation loss: 2.608394214229287

Epoch: 5| Step: 10
Training loss: 1.4515255565068865
Validation loss: 2.5807349792483225

Epoch: 461| Step: 0
Training loss: 1.2991593246953943
Validation loss: 2.5687951398783118

Epoch: 5| Step: 1
Training loss: 1.7643240803131732
Validation loss: 2.593464428070683

Epoch: 5| Step: 2
Training loss: 1.3826392544773005
Validation loss: 2.5928409395290597

Epoch: 5| Step: 3
Training loss: 1.257535204915985
Validation loss: 2.603159788010277

Epoch: 5| Step: 4
Training loss: 1.291515767091685
Validation loss: 2.595411500649386

Epoch: 5| Step: 5
Training loss: 1.7320704227297006
Validation loss: 2.6224627237554414

Epoch: 5| Step: 6
Training loss: 1.0109331770602545
Validation loss: 2.6393544518432304

Epoch: 5| Step: 7
Training loss: 1.4176458826635137
Validation loss: 2.6377859409566256

Epoch: 5| Step: 8
Training loss: 1.0385808186754035
Validation loss: 2.6727913834186885

Epoch: 5| Step: 9
Training loss: 1.475740395622142
Validation loss: 2.634397264242312

Epoch: 5| Step: 10
Training loss: 1.5765973997459275
Validation loss: 2.602963162500621

Epoch: 462| Step: 0
Training loss: 1.4070600507754962
Validation loss: 2.595346640630688

Epoch: 5| Step: 1
Training loss: 1.2197682943909236
Validation loss: 2.6112370475566755

Epoch: 5| Step: 2
Training loss: 1.4824230812278936
Validation loss: 2.590953878951195

Epoch: 5| Step: 3
Training loss: 1.164761685321175
Validation loss: 2.6080328068578824

Epoch: 5| Step: 4
Training loss: 0.9350877881783837
Validation loss: 2.6076874458886823

Epoch: 5| Step: 5
Training loss: 1.4456639867688414
Validation loss: 2.647005182274063

Epoch: 5| Step: 6
Training loss: 1.2736008428180245
Validation loss: 2.6406693226385136

Epoch: 5| Step: 7
Training loss: 1.4320757154022183
Validation loss: 2.62257251233333

Epoch: 5| Step: 8
Training loss: 1.8777718718220808
Validation loss: 2.6316830031391545

Epoch: 5| Step: 9
Training loss: 1.3838442816313665
Validation loss: 2.630612073329727

Epoch: 5| Step: 10
Training loss: 1.4439562233288572
Validation loss: 2.625506046112422

Epoch: 463| Step: 0
Training loss: 1.5130105031941712
Validation loss: 2.6346779129599023

Epoch: 5| Step: 1
Training loss: 1.4507922244542764
Validation loss: 2.603202513037426

Epoch: 5| Step: 2
Training loss: 1.0448225598064045
Validation loss: 2.6219287035938192

Epoch: 5| Step: 3
Training loss: 1.1115710591310304
Validation loss: 2.6177490915046193

Epoch: 5| Step: 4
Training loss: 1.5521098482397462
Validation loss: 2.6487904444539874

Epoch: 5| Step: 5
Training loss: 1.182398831836397
Validation loss: 2.6561020937233617

Epoch: 5| Step: 6
Training loss: 1.0643986959278098
Validation loss: 2.6658707185189408

Epoch: 5| Step: 7
Training loss: 1.3871794459209474
Validation loss: 2.6737140284301777

Epoch: 5| Step: 8
Training loss: 1.694240248558753
Validation loss: 2.6559394109542116

Epoch: 5| Step: 9
Training loss: 1.4475654157704136
Validation loss: 2.6397725798734895

Epoch: 5| Step: 10
Training loss: 1.5182632608222455
Validation loss: 2.6140250467201596

Epoch: 464| Step: 0
Training loss: 1.3097944530087098
Validation loss: 2.62494119870317

Epoch: 5| Step: 1
Training loss: 0.7739398750441863
Validation loss: 2.599538750906966

Epoch: 5| Step: 2
Training loss: 1.0618518647653676
Validation loss: 2.5862266632398936

Epoch: 5| Step: 3
Training loss: 0.972966952661484
Validation loss: 2.604170385214499

Epoch: 5| Step: 4
Training loss: 1.5010291383826238
Validation loss: 2.624566385656124

Epoch: 5| Step: 5
Training loss: 1.313314139948822
Validation loss: 2.6179617336395817

Epoch: 5| Step: 6
Training loss: 1.7869538786731471
Validation loss: 2.6230583227013446

Epoch: 5| Step: 7
Training loss: 1.9005316341891578
Validation loss: 2.614852888109954

Epoch: 5| Step: 8
Training loss: 1.45156891886069
Validation loss: 2.6391145551577595

Epoch: 5| Step: 9
Training loss: 1.474630151059146
Validation loss: 2.66285791837118

Epoch: 5| Step: 10
Training loss: 1.1428188494244362
Validation loss: 2.642815531969533

Epoch: 465| Step: 0
Training loss: 1.4305800689934378
Validation loss: 2.6899933863616967

Epoch: 5| Step: 1
Training loss: 1.0576818839139746
Validation loss: 2.6301306272123512

Epoch: 5| Step: 2
Training loss: 1.2177153376934486
Validation loss: 2.645708567731634

Epoch: 5| Step: 3
Training loss: 1.8091918088318908
Validation loss: 2.5877064985764786

Epoch: 5| Step: 4
Training loss: 1.1413321719717047
Validation loss: 2.598600882131776

Epoch: 5| Step: 5
Training loss: 1.3458770949548555
Validation loss: 2.6094935596990045

Epoch: 5| Step: 6
Training loss: 1.673677702546686
Validation loss: 2.591577012304713

Epoch: 5| Step: 7
Training loss: 1.1279324882439523
Validation loss: 2.593507092385701

Epoch: 5| Step: 8
Training loss: 1.2825472242647353
Validation loss: 2.60439141039989

Epoch: 5| Step: 9
Training loss: 1.4424316563274875
Validation loss: 2.608267639720943

Epoch: 5| Step: 10
Training loss: 1.3651929857258813
Validation loss: 2.6302295672179823

Epoch: 466| Step: 0
Training loss: 1.6294180891501966
Validation loss: 2.627056929313878

Epoch: 5| Step: 1
Training loss: 1.61155345843939
Validation loss: 2.6340858601014285

Epoch: 5| Step: 2
Training loss: 1.1847794639818037
Validation loss: 2.6094965271223605

Epoch: 5| Step: 3
Training loss: 1.4828775180594937
Validation loss: 2.657768801666628

Epoch: 5| Step: 4
Training loss: 1.2931739206403572
Validation loss: 2.6478876541412464

Epoch: 5| Step: 5
Training loss: 1.411173952552336
Validation loss: 2.602661292968552

Epoch: 5| Step: 6
Training loss: 1.111946242453275
Validation loss: 2.61048487402533

Epoch: 5| Step: 7
Training loss: 1.5400522989830265
Validation loss: 2.5917854306665626

Epoch: 5| Step: 8
Training loss: 1.3711826480400755
Validation loss: 2.630424817286636

Epoch: 5| Step: 9
Training loss: 0.992996966953774
Validation loss: 2.6129505560074913

Epoch: 5| Step: 10
Training loss: 1.17316528495024
Validation loss: 2.5969330714788694

Epoch: 467| Step: 0
Training loss: 1.3565840735979557
Validation loss: 2.585521619324656

Epoch: 5| Step: 1
Training loss: 1.4978977412627437
Validation loss: 2.6159139679897163

Epoch: 5| Step: 2
Training loss: 1.5622859808260523
Validation loss: 2.5670659274762007

Epoch: 5| Step: 3
Training loss: 1.3164335072579139
Validation loss: 2.5863045543254004

Epoch: 5| Step: 4
Training loss: 1.6626875664015133
Validation loss: 2.627472866609785

Epoch: 5| Step: 5
Training loss: 1.0155753490342507
Validation loss: 2.6506813662394104

Epoch: 5| Step: 6
Training loss: 0.997057818447522
Validation loss: 2.651909417313165

Epoch: 5| Step: 7
Training loss: 1.4596302078884629
Validation loss: 2.680790922535498

Epoch: 5| Step: 8
Training loss: 1.1136737867624604
Validation loss: 2.6791916499115467

Epoch: 5| Step: 9
Training loss: 1.531590248764092
Validation loss: 2.7014336559135126

Epoch: 5| Step: 10
Training loss: 1.2862870363588312
Validation loss: 2.656610414011845

Epoch: 468| Step: 0
Training loss: 1.784878030878728
Validation loss: 2.6273673575154426

Epoch: 5| Step: 1
Training loss: 0.7571122385013582
Validation loss: 2.6267155316710333

Epoch: 5| Step: 2
Training loss: 1.5370512082486272
Validation loss: 2.6032615818127622

Epoch: 5| Step: 3
Training loss: 1.1921015977221434
Validation loss: 2.638111735660027

Epoch: 5| Step: 4
Training loss: 0.9340460730978232
Validation loss: 2.572469408800177

Epoch: 5| Step: 5
Training loss: 1.2155739408228547
Validation loss: 2.5649816740022167

Epoch: 5| Step: 6
Training loss: 1.273944028502174
Validation loss: 2.624106589624906

Epoch: 5| Step: 7
Training loss: 1.691793983191003
Validation loss: 2.614886543574776

Epoch: 5| Step: 8
Training loss: 1.3361197453275155
Validation loss: 2.643012533257188

Epoch: 5| Step: 9
Training loss: 1.3389848452900588
Validation loss: 2.6420419736614775

Epoch: 5| Step: 10
Training loss: 1.472963255595534
Validation loss: 2.6508295720708563

Epoch: 469| Step: 0
Training loss: 1.312306980290591
Validation loss: 2.650305660665503

Epoch: 5| Step: 1
Training loss: 1.5571553182290812
Validation loss: 2.6421943297748194

Epoch: 5| Step: 2
Training loss: 1.6822126702656592
Validation loss: 2.6544916112802914

Epoch: 5| Step: 3
Training loss: 1.3236764793403724
Validation loss: 2.6215213534245594

Epoch: 5| Step: 4
Training loss: 1.4923499053933575
Validation loss: 2.6202924142960797

Epoch: 5| Step: 5
Training loss: 1.1454453187043827
Validation loss: 2.6038063288954794

Epoch: 5| Step: 6
Training loss: 1.3216940519246523
Validation loss: 2.616367333652469

Epoch: 5| Step: 7
Training loss: 1.263448374114322
Validation loss: 2.60490619782549

Epoch: 5| Step: 8
Training loss: 1.1221638002285839
Validation loss: 2.5937358669504316

Epoch: 5| Step: 9
Training loss: 1.4121950157862013
Validation loss: 2.5875485860971104

Epoch: 5| Step: 10
Training loss: 1.0353662817584623
Validation loss: 2.5396436840497483

Epoch: 470| Step: 0
Training loss: 1.25278172916448
Validation loss: 2.6075278499941037

Epoch: 5| Step: 1
Training loss: 1.2370176396326484
Validation loss: 2.594246835637133

Epoch: 5| Step: 2
Training loss: 1.3708544573948669
Validation loss: 2.6035907494105963

Epoch: 5| Step: 3
Training loss: 1.557324573930401
Validation loss: 2.630283750275021

Epoch: 5| Step: 4
Training loss: 1.4441690406552345
Validation loss: 2.6412941505402427

Epoch: 5| Step: 5
Training loss: 1.360291183238056
Validation loss: 2.6261804624833505

Epoch: 5| Step: 6
Training loss: 1.1003846168015499
Validation loss: 2.6212753047918103

Epoch: 5| Step: 7
Training loss: 0.9692862164921457
Validation loss: 2.634501742507254

Epoch: 5| Step: 8
Training loss: 1.5885876841732745
Validation loss: 2.647151391663247

Epoch: 5| Step: 9
Training loss: 1.414112659218075
Validation loss: 2.633459591580862

Epoch: 5| Step: 10
Training loss: 1.4391446863619
Validation loss: 2.650029913589691

Epoch: 471| Step: 0
Training loss: 1.0295328235368142
Validation loss: 2.6179756702972266

Epoch: 5| Step: 1
Training loss: 1.443247624305291
Validation loss: 2.6137934116857036

Epoch: 5| Step: 2
Training loss: 0.9978802088300851
Validation loss: 2.5730739909257045

Epoch: 5| Step: 3
Training loss: 1.1711700353531012
Validation loss: 2.60286871741154

Epoch: 5| Step: 4
Training loss: 1.461108682160641
Validation loss: 2.5932192238962615

Epoch: 5| Step: 5
Training loss: 1.5029633179310753
Validation loss: 2.5947402099784984

Epoch: 5| Step: 6
Training loss: 1.3690998762436475
Validation loss: 2.5756379771327773

Epoch: 5| Step: 7
Training loss: 1.572690463274298
Validation loss: 2.65962818995205

Epoch: 5| Step: 8
Training loss: 1.5033892647064968
Validation loss: 2.694654805658471

Epoch: 5| Step: 9
Training loss: 0.954220939047804
Validation loss: 2.6768122250426747

Epoch: 5| Step: 10
Training loss: 1.669814221219304
Validation loss: 2.697732075692124

Epoch: 472| Step: 0
Training loss: 1.4963419337380623
Validation loss: 2.6869754112337354

Epoch: 5| Step: 1
Training loss: 1.284149610508047
Validation loss: 2.6611186124707453

Epoch: 5| Step: 2
Training loss: 1.730939469564474
Validation loss: 2.6106785045897425

Epoch: 5| Step: 3
Training loss: 1.2006818066273808
Validation loss: 2.574178953898111

Epoch: 5| Step: 4
Training loss: 1.218616135899447
Validation loss: 2.5550226365089976

Epoch: 5| Step: 5
Training loss: 1.1785376294148773
Validation loss: 2.54287345481729

Epoch: 5| Step: 6
Training loss: 1.1417181968661523
Validation loss: 2.5558110757051433

Epoch: 5| Step: 7
Training loss: 1.3521715677132486
Validation loss: 2.6326620724071184

Epoch: 5| Step: 8
Training loss: 1.3462711458661787
Validation loss: 2.6700390063903123

Epoch: 5| Step: 9
Training loss: 1.3303289191012617
Validation loss: 2.657119541092064

Epoch: 5| Step: 10
Training loss: 1.4630055197809144
Validation loss: 2.6844282077928807

Epoch: 473| Step: 0
Training loss: 1.3994632560564728
Validation loss: 2.7037406455987294

Epoch: 5| Step: 1
Training loss: 1.3493050481943976
Validation loss: 2.6670065062102584

Epoch: 5| Step: 2
Training loss: 1.5072614226067391
Validation loss: 2.702890631948952

Epoch: 5| Step: 3
Training loss: 1.1784353115695732
Validation loss: 2.6759298169717116

Epoch: 5| Step: 4
Training loss: 1.565929844581955
Validation loss: 2.626386062638105

Epoch: 5| Step: 5
Training loss: 1.1702176390478172
Validation loss: 2.6042021370389716

Epoch: 5| Step: 6
Training loss: 1.7780813845362027
Validation loss: 2.5701447361156284

Epoch: 5| Step: 7
Training loss: 1.111384063546449
Validation loss: 2.536285362823753

Epoch: 5| Step: 8
Training loss: 1.2253473178749026
Validation loss: 2.5102293441367416

Epoch: 5| Step: 9
Training loss: 1.304477834701112
Validation loss: 2.546906517926435

Epoch: 5| Step: 10
Training loss: 0.9838329518206662
Validation loss: 2.550142584861292

Epoch: 474| Step: 0
Training loss: 1.2520865668298964
Validation loss: 2.5954501059285056

Epoch: 5| Step: 1
Training loss: 1.338688655555526
Validation loss: 2.6069919166701596

Epoch: 5| Step: 2
Training loss: 1.2902194293383917
Validation loss: 2.6735533191635703

Epoch: 5| Step: 3
Training loss: 0.9512203133721643
Validation loss: 2.7142150571170816

Epoch: 5| Step: 4
Training loss: 1.404581266635735
Validation loss: 2.719888011667629

Epoch: 5| Step: 5
Training loss: 1.2034889265279218
Validation loss: 2.7390624649578257

Epoch: 5| Step: 6
Training loss: 1.1308605345619596
Validation loss: 2.6900473143741004

Epoch: 5| Step: 7
Training loss: 1.2771517174703877
Validation loss: 2.6937070112364903

Epoch: 5| Step: 8
Training loss: 2.042816915030258
Validation loss: 2.6330787502399624

Epoch: 5| Step: 9
Training loss: 1.2174600474795312
Validation loss: 2.602241241080981

Epoch: 5| Step: 10
Training loss: 1.4549181959090034
Validation loss: 2.5443234103777983

Epoch: 475| Step: 0
Training loss: 1.2810999154366958
Validation loss: 2.5479511076508037

Epoch: 5| Step: 1
Training loss: 1.5842302275054803
Validation loss: 2.5407470163644885

Epoch: 5| Step: 2
Training loss: 1.0541342520473456
Validation loss: 2.5450456799890344

Epoch: 5| Step: 3
Training loss: 1.5968943973565046
Validation loss: 2.583802878836007

Epoch: 5| Step: 4
Training loss: 1.1532806208771231
Validation loss: 2.5897046281968596

Epoch: 5| Step: 5
Training loss: 1.162167741608069
Validation loss: 2.633791465739474

Epoch: 5| Step: 6
Training loss: 1.3001249106625083
Validation loss: 2.65386948294199

Epoch: 5| Step: 7
Training loss: 1.529703098486449
Validation loss: 2.6868500530542505

Epoch: 5| Step: 8
Training loss: 1.2124988949170927
Validation loss: 2.642961443518

Epoch: 5| Step: 9
Training loss: 1.2518100031845392
Validation loss: 2.5762148296749396

Epoch: 5| Step: 10
Training loss: 1.5357470746516255
Validation loss: 2.5642536744528637

Epoch: 476| Step: 0
Training loss: 1.2048196623626346
Validation loss: 2.512395348999639

Epoch: 5| Step: 1
Training loss: 1.6104372833366691
Validation loss: 2.5008785273130325

Epoch: 5| Step: 2
Training loss: 0.8775668640962795
Validation loss: 2.5192006168850756

Epoch: 5| Step: 3
Training loss: 1.6389420369612828
Validation loss: 2.483239205064369

Epoch: 5| Step: 4
Training loss: 1.4133707957580983
Validation loss: 2.5301310756289057

Epoch: 5| Step: 5
Training loss: 0.7797710916663682
Validation loss: 2.584129425847252

Epoch: 5| Step: 6
Training loss: 1.3836111144102214
Validation loss: 2.5954216597291024

Epoch: 5| Step: 7
Training loss: 1.21097451430325
Validation loss: 2.6352569779428525

Epoch: 5| Step: 8
Training loss: 1.5402490524687822
Validation loss: 2.652807162824583

Epoch: 5| Step: 9
Training loss: 1.4733032100641743
Validation loss: 2.688881858653889

Epoch: 5| Step: 10
Training loss: 1.2291322261489648
Validation loss: 2.722252940462987

Epoch: 477| Step: 0
Training loss: 1.4128063797981665
Validation loss: 2.687172738382373

Epoch: 5| Step: 1
Training loss: 1.2890964387992003
Validation loss: 2.68363713274791

Epoch: 5| Step: 2
Training loss: 1.6965154783316874
Validation loss: 2.6573155581608465

Epoch: 5| Step: 3
Training loss: 1.6312361413359684
Validation loss: 2.6138662742324694

Epoch: 5| Step: 4
Training loss: 1.0444831283543408
Validation loss: 2.6337938976909987

Epoch: 5| Step: 5
Training loss: 1.5117086562970516
Validation loss: 2.58329139150127

Epoch: 5| Step: 6
Training loss: 1.0509004773422639
Validation loss: 2.548927740132901

Epoch: 5| Step: 7
Training loss: 1.312624108032586
Validation loss: 2.5431649182953535

Epoch: 5| Step: 8
Training loss: 1.0238307750540985
Validation loss: 2.5555120791101262

Epoch: 5| Step: 9
Training loss: 1.0780247074968898
Validation loss: 2.5568357077501624

Epoch: 5| Step: 10
Training loss: 1.2919950939327427
Validation loss: 2.57704793010248

Epoch: 478| Step: 0
Training loss: 1.6458179939939435
Validation loss: 2.6153484026369203

Epoch: 5| Step: 1
Training loss: 1.4169590405215915
Validation loss: 2.639509704942355

Epoch: 5| Step: 2
Training loss: 1.2427717550273216
Validation loss: 2.613843031487999

Epoch: 5| Step: 3
Training loss: 1.4100585227346492
Validation loss: 2.650229904516887

Epoch: 5| Step: 4
Training loss: 0.9688568056357245
Validation loss: 2.64768028923368

Epoch: 5| Step: 5
Training loss: 1.120341776487918
Validation loss: 2.634601543971208

Epoch: 5| Step: 6
Training loss: 1.4997931973632823
Validation loss: 2.6549962694006584

Epoch: 5| Step: 7
Training loss: 1.238818223693198
Validation loss: 2.62786237853988

Epoch: 5| Step: 8
Training loss: 1.24140454454827
Validation loss: 2.6134535008632733

Epoch: 5| Step: 9
Training loss: 1.553259956130251
Validation loss: 2.5819510401412273

Epoch: 5| Step: 10
Training loss: 0.8969482684363216
Validation loss: 2.572122945055117

Epoch: 479| Step: 0
Training loss: 1.2933988288062428
Validation loss: 2.58354521433927

Epoch: 5| Step: 1
Training loss: 1.1324925990420736
Validation loss: 2.5585383924231824

Epoch: 5| Step: 2
Training loss: 1.32017814358917
Validation loss: 2.589303479208714

Epoch: 5| Step: 3
Training loss: 1.234575472620129
Validation loss: 2.5923035818080966

Epoch: 5| Step: 4
Training loss: 1.3004383631864846
Validation loss: 2.592459654081398

Epoch: 5| Step: 5
Training loss: 0.9043343126362233
Validation loss: 2.6176946333259776

Epoch: 5| Step: 6
Training loss: 1.7465763662500735
Validation loss: 2.648391836009085

Epoch: 5| Step: 7
Training loss: 0.9087913987018819
Validation loss: 2.633676039632515

Epoch: 5| Step: 8
Training loss: 1.4652631235620284
Validation loss: 2.643010720384214

Epoch: 5| Step: 9
Training loss: 1.4988594487356741
Validation loss: 2.6556998921622808

Epoch: 5| Step: 10
Training loss: 1.3237337557738837
Validation loss: 2.6528086713556025

Epoch: 480| Step: 0
Training loss: 1.3689923389797258
Validation loss: 2.6197583901348507

Epoch: 5| Step: 1
Training loss: 1.4304465691655697
Validation loss: 2.6311056946572644

Epoch: 5| Step: 2
Training loss: 1.1313855358725227
Validation loss: 2.5910085271423027

Epoch: 5| Step: 3
Training loss: 1.3375941929671753
Validation loss: 2.591417829996225

Epoch: 5| Step: 4
Training loss: 1.4102814848600267
Validation loss: 2.608995468600765

Epoch: 5| Step: 5
Training loss: 1.5044386676775716
Validation loss: 2.603076055401664

Epoch: 5| Step: 6
Training loss: 1.3305618818013671
Validation loss: 2.610246754025005

Epoch: 5| Step: 7
Training loss: 1.164954132028478
Validation loss: 2.6031144534528172

Epoch: 5| Step: 8
Training loss: 1.3747936440723525
Validation loss: 2.6456614826007225

Epoch: 5| Step: 9
Training loss: 0.8573943809324261
Validation loss: 2.638641798583762

Epoch: 5| Step: 10
Training loss: 1.1752563014410276
Validation loss: 2.6594731001176464

Epoch: 481| Step: 0
Training loss: 0.9919913390881328
Validation loss: 2.6441723594607995

Epoch: 5| Step: 1
Training loss: 0.9200497354145829
Validation loss: 2.66175165593473

Epoch: 5| Step: 2
Training loss: 1.708716148035564
Validation loss: 2.657333439710201

Epoch: 5| Step: 3
Training loss: 1.1844452165307284
Validation loss: 2.653049195219552

Epoch: 5| Step: 4
Training loss: 1.3313871823402563
Validation loss: 2.658608499307027

Epoch: 5| Step: 5
Training loss: 1.157393431402525
Validation loss: 2.640783934383205

Epoch: 5| Step: 6
Training loss: 1.348631044644931
Validation loss: 2.6479128287240203

Epoch: 5| Step: 7
Training loss: 1.2654045760743489
Validation loss: 2.6337659916788247

Epoch: 5| Step: 8
Training loss: 1.3188216691632824
Validation loss: 2.631638685991042

Epoch: 5| Step: 9
Training loss: 1.5381000433380951
Validation loss: 2.6146535425614132

Epoch: 5| Step: 10
Training loss: 1.1802533542073912
Validation loss: 2.599346351810954

Epoch: 482| Step: 0
Training loss: 1.33372533022831
Validation loss: 2.6234035373921567

Epoch: 5| Step: 1
Training loss: 1.36313118969519
Validation loss: 2.5876278491816245

Epoch: 5| Step: 2
Training loss: 1.5418898274884314
Validation loss: 2.570813246903621

Epoch: 5| Step: 3
Training loss: 1.619846535230722
Validation loss: 2.5766718105368875

Epoch: 5| Step: 4
Training loss: 1.0544396003149161
Validation loss: 2.6068921134052783

Epoch: 5| Step: 5
Training loss: 1.3502564928322125
Validation loss: 2.6295727124524038

Epoch: 5| Step: 6
Training loss: 1.1962719227088479
Validation loss: 2.652908754335812

Epoch: 5| Step: 7
Training loss: 1.0412380417484013
Validation loss: 2.6873355003354282

Epoch: 5| Step: 8
Training loss: 1.1310858886715367
Validation loss: 2.67340087689097

Epoch: 5| Step: 9
Training loss: 1.496757021656709
Validation loss: 2.737955747269121

Epoch: 5| Step: 10
Training loss: 0.7802693888495948
Validation loss: 2.693462646444352

Epoch: 483| Step: 0
Training loss: 0.7920280852925298
Validation loss: 2.6485927878806277

Epoch: 5| Step: 1
Training loss: 1.5307172510237765
Validation loss: 2.6358411191703204

Epoch: 5| Step: 2
Training loss: 1.013872424446327
Validation loss: 2.605882382345464

Epoch: 5| Step: 3
Training loss: 1.4535172456046965
Validation loss: 2.568521836818552

Epoch: 5| Step: 4
Training loss: 1.5860556572556328
Validation loss: 2.5498388496452082

Epoch: 5| Step: 5
Training loss: 1.4323721938181901
Validation loss: 2.570816865776104

Epoch: 5| Step: 6
Training loss: 1.0164780775371633
Validation loss: 2.5896283386811256

Epoch: 5| Step: 7
Training loss: 1.2525490995213444
Validation loss: 2.5888278770187765

Epoch: 5| Step: 8
Training loss: 1.2699235515413274
Validation loss: 2.6745364871199357

Epoch: 5| Step: 9
Training loss: 1.088025562403317
Validation loss: 2.635367632499766

Epoch: 5| Step: 10
Training loss: 1.4274112111285653
Validation loss: 2.6716159152110577

Epoch: 484| Step: 0
Training loss: 0.9591898028027356
Validation loss: 2.6786392827578274

Epoch: 5| Step: 1
Training loss: 1.1306680309906711
Validation loss: 2.683342455776664

Epoch: 5| Step: 2
Training loss: 1.3928261384901788
Validation loss: 2.647196261628615

Epoch: 5| Step: 3
Training loss: 1.4619426023746416
Validation loss: 2.658032919550776

Epoch: 5| Step: 4
Training loss: 1.409376610461074
Validation loss: 2.6457184629444064

Epoch: 5| Step: 5
Training loss: 1.097397471702643
Validation loss: 2.6085721272215

Epoch: 5| Step: 6
Training loss: 1.6061669383856128
Validation loss: 2.5617005356405285

Epoch: 5| Step: 7
Training loss: 1.5134049506333196
Validation loss: 2.554651629476555

Epoch: 5| Step: 8
Training loss: 1.197201352160041
Validation loss: 2.5693016155188637

Epoch: 5| Step: 9
Training loss: 0.9695020033415802
Validation loss: 2.555491796720354

Epoch: 5| Step: 10
Training loss: 1.0865342401094016
Validation loss: 2.5674685099740198

Epoch: 485| Step: 0
Training loss: 1.3293282836109033
Validation loss: 2.5835479758965425

Epoch: 5| Step: 1
Training loss: 1.0036817366402913
Validation loss: 2.578084383160141

Epoch: 5| Step: 2
Training loss: 1.4815819412626279
Validation loss: 2.6185648267341155

Epoch: 5| Step: 3
Training loss: 1.0529519954944166
Validation loss: 2.6262284845390185

Epoch: 5| Step: 4
Training loss: 1.1689418961579412
Validation loss: 2.653562748298948

Epoch: 5| Step: 5
Training loss: 1.3757094806968642
Validation loss: 2.666798670703525

Epoch: 5| Step: 6
Training loss: 0.9402421584082538
Validation loss: 2.6529283122386165

Epoch: 5| Step: 7
Training loss: 1.262053784746255
Validation loss: 2.683854415186466

Epoch: 5| Step: 8
Training loss: 1.4748248012395222
Validation loss: 2.6774196685603533

Epoch: 5| Step: 9
Training loss: 1.3886548348412804
Validation loss: 2.6759670249665373

Epoch: 5| Step: 10
Training loss: 1.4696193313768344
Validation loss: 2.591827032604305

Epoch: 486| Step: 0
Training loss: 1.1480177546932548
Validation loss: 2.5639517728696744

Epoch: 5| Step: 1
Training loss: 1.3632839170063678
Validation loss: 2.5494598110068867

Epoch: 5| Step: 2
Training loss: 1.0512339244434403
Validation loss: 2.604065901908993

Epoch: 5| Step: 3
Training loss: 0.8027201927398715
Validation loss: 2.5579403684650264

Epoch: 5| Step: 4
Training loss: 1.4431193439939476
Validation loss: 2.5656366407231674

Epoch: 5| Step: 5
Training loss: 1.5394771424021727
Validation loss: 2.6057128644298913

Epoch: 5| Step: 6
Training loss: 1.3559654710868958
Validation loss: 2.6154218854600213

Epoch: 5| Step: 7
Training loss: 1.0396018671945886
Validation loss: 2.636501146678104

Epoch: 5| Step: 8
Training loss: 1.286526352580978
Validation loss: 2.6220591801996567

Epoch: 5| Step: 9
Training loss: 1.4714503524083513
Validation loss: 2.6418029231659057

Epoch: 5| Step: 10
Training loss: 1.3386308613113715
Validation loss: 2.639691979189507

Epoch: 487| Step: 0
Training loss: 0.9719378411193881
Validation loss: 2.5978683785996215

Epoch: 5| Step: 1
Training loss: 1.5941507172305969
Validation loss: 2.626613233536674

Epoch: 5| Step: 2
Training loss: 0.8948200209495317
Validation loss: 2.6011654081060125

Epoch: 5| Step: 3
Training loss: 1.243443843406417
Validation loss: 2.6329717414201683

Epoch: 5| Step: 4
Training loss: 1.234100552723514
Validation loss: 2.598551107423919

Epoch: 5| Step: 5
Training loss: 1.3829662000507417
Validation loss: 2.6222902581344467

Epoch: 5| Step: 6
Training loss: 1.0807221132837257
Validation loss: 2.6047014749664634

Epoch: 5| Step: 7
Training loss: 1.3452887042308124
Validation loss: 2.6113599075998475

Epoch: 5| Step: 8
Training loss: 1.2464443180028018
Validation loss: 2.6158233589319044

Epoch: 5| Step: 9
Training loss: 1.1571126761108312
Validation loss: 2.636720332878607

Epoch: 5| Step: 10
Training loss: 1.609360630008282
Validation loss: 2.607085732523181

Epoch: 488| Step: 0
Training loss: 1.4207881924048362
Validation loss: 2.6774613943541854

Epoch: 5| Step: 1
Training loss: 0.7753178252437423
Validation loss: 2.6531233142025274

Epoch: 5| Step: 2
Training loss: 1.237991636084681
Validation loss: 2.6717477895431396

Epoch: 5| Step: 3
Training loss: 0.922764655971175
Validation loss: 2.700747128143767

Epoch: 5| Step: 4
Training loss: 1.481778815794921
Validation loss: 2.685412304561558

Epoch: 5| Step: 5
Training loss: 1.093751144408581
Validation loss: 2.672697320556906

Epoch: 5| Step: 6
Training loss: 1.0587483535987996
Validation loss: 2.664781550801328

Epoch: 5| Step: 7
Training loss: 1.3733663390801303
Validation loss: 2.6619255741517636

Epoch: 5| Step: 8
Training loss: 1.61728671594239
Validation loss: 2.6233383628940956

Epoch: 5| Step: 9
Training loss: 1.304568211018969
Validation loss: 2.609185529086725

Epoch: 5| Step: 10
Training loss: 1.2388041261767462
Validation loss: 2.611747354437288

Epoch: 489| Step: 0
Training loss: 1.7559830024826364
Validation loss: 2.6087360716178964

Epoch: 5| Step: 1
Training loss: 1.1182989713749882
Validation loss: 2.5799003705592023

Epoch: 5| Step: 2
Training loss: 1.3761440632695434
Validation loss: 2.5767439657511684

Epoch: 5| Step: 3
Training loss: 0.73218864287785
Validation loss: 2.6074637141398003

Epoch: 5| Step: 4
Training loss: 0.9302636613157943
Validation loss: 2.575494380117352

Epoch: 5| Step: 5
Training loss: 1.0533752755273043
Validation loss: 2.5589284660847396

Epoch: 5| Step: 6
Training loss: 1.3872578177576393
Validation loss: 2.616241698526397

Epoch: 5| Step: 7
Training loss: 1.4535888423793777
Validation loss: 2.6252913442760413

Epoch: 5| Step: 8
Training loss: 1.3596309552438843
Validation loss: 2.653039235549872

Epoch: 5| Step: 9
Training loss: 0.959566021518908
Validation loss: 2.676207530874194

Epoch: 5| Step: 10
Training loss: 1.2451267137350042
Validation loss: 2.700691693266349

Epoch: 490| Step: 0
Training loss: 1.3863214487800202
Validation loss: 2.6794829319058713

Epoch: 5| Step: 1
Training loss: 1.309258454446117
Validation loss: 2.6582763451545857

Epoch: 5| Step: 2
Training loss: 1.0017666708289976
Validation loss: 2.645844841672793

Epoch: 5| Step: 3
Training loss: 1.703777923019317
Validation loss: 2.6372192578651146

Epoch: 5| Step: 4
Training loss: 1.1661077363965608
Validation loss: 2.6199423315819796

Epoch: 5| Step: 5
Training loss: 1.3384012626108437
Validation loss: 2.64437127277378

Epoch: 5| Step: 6
Training loss: 1.314374901539812
Validation loss: 2.5898064410652313

Epoch: 5| Step: 7
Training loss: 1.0269321443860246
Validation loss: 2.61087442828065

Epoch: 5| Step: 8
Training loss: 1.0025933731621057
Validation loss: 2.6254389625848558

Epoch: 5| Step: 9
Training loss: 0.8077143065282792
Validation loss: 2.6282756962039207

Epoch: 5| Step: 10
Training loss: 1.3600114669737118
Validation loss: 2.640342466711577

Epoch: 491| Step: 0
Training loss: 1.554043583773027
Validation loss: 2.642327570618244

Epoch: 5| Step: 1
Training loss: 1.485733855820763
Validation loss: 2.6038677340975798

Epoch: 5| Step: 2
Training loss: 1.102242496633655
Validation loss: 2.636573273759915

Epoch: 5| Step: 3
Training loss: 0.8328491632289133
Validation loss: 2.6218649400568443

Epoch: 5| Step: 4
Training loss: 1.382115678812208
Validation loss: 2.6082708557356113

Epoch: 5| Step: 5
Training loss: 0.9916147696648843
Validation loss: 2.6352572688171447

Epoch: 5| Step: 6
Training loss: 1.169040048277093
Validation loss: 2.6596919643256345

Epoch: 5| Step: 7
Training loss: 1.1694016358661774
Validation loss: 2.661301749463749

Epoch: 5| Step: 8
Training loss: 1.1313125150488867
Validation loss: 2.6972899357330853

Epoch: 5| Step: 9
Training loss: 1.3104058316282665
Validation loss: 2.6787819854906307

Epoch: 5| Step: 10
Training loss: 1.360266250816154
Validation loss: 2.6707764647059085

Epoch: 492| Step: 0
Training loss: 1.360043985903704
Validation loss: 2.66711937775029

Epoch: 5| Step: 1
Training loss: 1.3807551710207044
Validation loss: 2.6278591416257484

Epoch: 5| Step: 2
Training loss: 1.058316578069102
Validation loss: 2.594740455994067

Epoch: 5| Step: 3
Training loss: 0.9455903015527685
Validation loss: 2.6077839500012505

Epoch: 5| Step: 4
Training loss: 1.0149148659166412
Validation loss: 2.619234944355032

Epoch: 5| Step: 5
Training loss: 1.2337272972793154
Validation loss: 2.607144109563786

Epoch: 5| Step: 6
Training loss: 1.1964420142974126
Validation loss: 2.6073700869016294

Epoch: 5| Step: 7
Training loss: 1.0274378512259095
Validation loss: 2.657323233687141

Epoch: 5| Step: 8
Training loss: 1.5502812038185478
Validation loss: 2.667755859790655

Epoch: 5| Step: 9
Training loss: 1.4006587879713426
Validation loss: 2.672826048277291

Epoch: 5| Step: 10
Training loss: 1.2558828680946796
Validation loss: 2.699400304084944

Epoch: 493| Step: 0
Training loss: 1.2370053526131137
Validation loss: 2.704753320092762

Epoch: 5| Step: 1
Training loss: 1.3520104873069905
Validation loss: 2.705455247217924

Epoch: 5| Step: 2
Training loss: 1.3457331550248293
Validation loss: 2.679675473374228

Epoch: 5| Step: 3
Training loss: 0.9539740173612296
Validation loss: 2.6894393433092425

Epoch: 5| Step: 4
Training loss: 1.2450933476578028
Validation loss: 2.68355181767652

Epoch: 5| Step: 5
Training loss: 1.2480974500554434
Validation loss: 2.622719412251917

Epoch: 5| Step: 6
Training loss: 1.3958780319496582
Validation loss: 2.650132884615508

Epoch: 5| Step: 7
Training loss: 0.957836077401491
Validation loss: 2.6478275050698965

Epoch: 5| Step: 8
Training loss: 1.1939606845140092
Validation loss: 2.651514421011978

Epoch: 5| Step: 9
Training loss: 1.1832573541686326
Validation loss: 2.657183900524208

Epoch: 5| Step: 10
Training loss: 1.2645019917772202
Validation loss: 2.6491039455322833

Epoch: 494| Step: 0
Training loss: 1.3521932993148031
Validation loss: 2.6196983560696774

Epoch: 5| Step: 1
Training loss: 1.5043483332072034
Validation loss: 2.6178753446835468

Epoch: 5| Step: 2
Training loss: 1.092859941455809
Validation loss: 2.6643846852481894

Epoch: 5| Step: 3
Training loss: 1.2629278194615081
Validation loss: 2.6347221566074364

Epoch: 5| Step: 4
Training loss: 1.004735285214368
Validation loss: 2.661547071266189

Epoch: 5| Step: 5
Training loss: 0.8523476856675792
Validation loss: 2.6236450997740297

Epoch: 5| Step: 6
Training loss: 1.3195886828682795
Validation loss: 2.644424166569608

Epoch: 5| Step: 7
Training loss: 1.1096993630327574
Validation loss: 2.6146883202966333

Epoch: 5| Step: 8
Training loss: 0.8029393957576967
Validation loss: 2.6114473681290833

Epoch: 5| Step: 9
Training loss: 1.3950837053459821
Validation loss: 2.6129720544098953

Epoch: 5| Step: 10
Training loss: 1.5461791043384563
Validation loss: 2.6055193184315875

Epoch: 495| Step: 0
Training loss: 1.2855494862857102
Validation loss: 2.632114928880651

Epoch: 5| Step: 1
Training loss: 0.9611224174906366
Validation loss: 2.6188470135502135

Epoch: 5| Step: 2
Training loss: 1.234691337901962
Validation loss: 2.6467073663627216

Epoch: 5| Step: 3
Training loss: 1.4218520277913331
Validation loss: 2.660419675072559

Epoch: 5| Step: 4
Training loss: 1.132723627221662
Validation loss: 2.677308937609892

Epoch: 5| Step: 5
Training loss: 0.9164292107426846
Validation loss: 2.683814650515914

Epoch: 5| Step: 6
Training loss: 1.383118891851191
Validation loss: 2.6573552379616783

Epoch: 5| Step: 7
Training loss: 0.7355307149302084
Validation loss: 2.6906122214841495

Epoch: 5| Step: 8
Training loss: 1.7551784871296534
Validation loss: 2.6545261259093875

Epoch: 5| Step: 9
Training loss: 1.001721807179764
Validation loss: 2.676647210287267

Epoch: 5| Step: 10
Training loss: 1.1714282901029216
Validation loss: 2.6751706256488093

Epoch: 496| Step: 0
Training loss: 1.1013443101731544
Validation loss: 2.65437986880446

Epoch: 5| Step: 1
Training loss: 1.2817042406194001
Validation loss: 2.6551761278157966

Epoch: 5| Step: 2
Training loss: 0.7880109824611007
Validation loss: 2.69703534459437

Epoch: 5| Step: 3
Training loss: 1.1182825017444769
Validation loss: 2.7003311817015456

Epoch: 5| Step: 4
Training loss: 1.6597379987845597
Validation loss: 2.6822251296201025

Epoch: 5| Step: 5
Training loss: 1.3665883086389012
Validation loss: 2.662456251115532

Epoch: 5| Step: 6
Training loss: 1.4071155003937539
Validation loss: 2.693893472346204

Epoch: 5| Step: 7
Training loss: 0.9160114605449047
Validation loss: 2.6339882766983242

Epoch: 5| Step: 8
Training loss: 0.9295421775269174
Validation loss: 2.644947335479022

Epoch: 5| Step: 9
Training loss: 1.418176556957596
Validation loss: 2.6512564427405225

Epoch: 5| Step: 10
Training loss: 0.8079935693626582
Validation loss: 2.639077255979176

Epoch: 497| Step: 0
Training loss: 1.1794988721395019
Validation loss: 2.6640984485849413

Epoch: 5| Step: 1
Training loss: 0.9159067573190637
Validation loss: 2.630093162611831

Epoch: 5| Step: 2
Training loss: 1.2394808184550223
Validation loss: 2.606736654949403

Epoch: 5| Step: 3
Training loss: 1.467534800284193
Validation loss: 2.607911000176745

Epoch: 5| Step: 4
Training loss: 0.9407083290677841
Validation loss: 2.623949826248443

Epoch: 5| Step: 5
Training loss: 0.908786315717057
Validation loss: 2.65614301259761

Epoch: 5| Step: 6
Training loss: 0.8561729772410802
Validation loss: 2.6513838724932444

Epoch: 5| Step: 7
Training loss: 1.089353936714521
Validation loss: 2.6699236350334226

Epoch: 5| Step: 8
Training loss: 1.2605679581483462
Validation loss: 2.7097538241685983

Epoch: 5| Step: 9
Training loss: 1.403959103684224
Validation loss: 2.6900877669405254

Epoch: 5| Step: 10
Training loss: 1.7128906945953877
Validation loss: 2.7130655814199653

Epoch: 498| Step: 0
Training loss: 0.9973948041281441
Validation loss: 2.7086610303956853

Epoch: 5| Step: 1
Training loss: 1.081830388234154
Validation loss: 2.6568879125778446

Epoch: 5| Step: 2
Training loss: 1.6271618621019626
Validation loss: 2.6255329350904217

Epoch: 5| Step: 3
Training loss: 1.2622213868260044
Validation loss: 2.6199748541279595

Epoch: 5| Step: 4
Training loss: 1.0432057200765004
Validation loss: 2.627337901559423

Epoch: 5| Step: 5
Training loss: 0.8595362078577963
Validation loss: 2.5886485426693557

Epoch: 5| Step: 6
Training loss: 0.912240159911811
Validation loss: 2.614739912464739

Epoch: 5| Step: 7
Training loss: 1.2453389527539878
Validation loss: 2.559206911767939

Epoch: 5| Step: 8
Training loss: 1.5302488206978204
Validation loss: 2.6016981380280537

Epoch: 5| Step: 9
Training loss: 1.3018257140574498
Validation loss: 2.6240033153683817

Epoch: 5| Step: 10
Training loss: 1.1071427681479
Validation loss: 2.615695011227491

Epoch: 499| Step: 0
Training loss: 1.178335665781895
Validation loss: 2.6292601128745674

Epoch: 5| Step: 1
Training loss: 0.9360759409823111
Validation loss: 2.5927393882046297

Epoch: 5| Step: 2
Training loss: 1.2105930946096433
Validation loss: 2.6217630941150913

Epoch: 5| Step: 3
Training loss: 1.4728441194458282
Validation loss: 2.6199033630967925

Epoch: 5| Step: 4
Training loss: 1.5398725517594731
Validation loss: 2.6442064042836524

Epoch: 5| Step: 5
Training loss: 0.5325104402584258
Validation loss: 2.645464911150663

Epoch: 5| Step: 6
Training loss: 1.5987300482035134
Validation loss: 2.6685293941178725

Epoch: 5| Step: 7
Training loss: 1.156672941643425
Validation loss: 2.686522723713765

Epoch: 5| Step: 8
Training loss: 1.2905955128845783
Validation loss: 2.6711314203578502

Epoch: 5| Step: 9
Training loss: 1.0680272006132123
Validation loss: 2.681308879225413

Epoch: 5| Step: 10
Training loss: 0.40285226482092296
Validation loss: 2.679009620560885

Epoch: 500| Step: 0
Training loss: 1.2405502277585772
Validation loss: 2.6675786341956678

Epoch: 5| Step: 1
Training loss: 0.7207978142456464
Validation loss: 2.6746259611641716

Epoch: 5| Step: 2
Training loss: 1.2873011259534113
Validation loss: 2.704655295851642

Epoch: 5| Step: 3
Training loss: 0.9991366116285572
Validation loss: 2.702711381101491

Epoch: 5| Step: 4
Training loss: 1.4329591432697995
Validation loss: 2.689527510404162

Epoch: 5| Step: 5
Training loss: 1.1627578592930858
Validation loss: 2.696939476154162

Epoch: 5| Step: 6
Training loss: 0.8426617562743463
Validation loss: 2.699298197204207

Epoch: 5| Step: 7
Training loss: 1.3964527046507138
Validation loss: 2.6846513983129414

Epoch: 5| Step: 8
Training loss: 1.4417493458378106
Validation loss: 2.6468434900866273

Epoch: 5| Step: 9
Training loss: 1.1869567331110982
Validation loss: 2.614710889789387

Epoch: 5| Step: 10
Training loss: 1.0534336690456787
Validation loss: 2.5759726341596862

Testing loss: 2.4089270668339733
