Epoch: 1| Step: 0
Training loss: 5.174981512506606
Validation loss: 5.794716426965992

Epoch: 6| Step: 1
Training loss: 5.801311265769468
Validation loss: 5.7882788006458

Epoch: 6| Step: 2
Training loss: 6.207567752340875
Validation loss: 5.782773414868502

Epoch: 6| Step: 3
Training loss: 6.291351849424869
Validation loss: 5.777777559145242

Epoch: 6| Step: 4
Training loss: 7.025554605224155
Validation loss: 5.7721246210750605

Epoch: 6| Step: 5
Training loss: 4.782017465467798
Validation loss: 5.767473076429675

Epoch: 6| Step: 6
Training loss: 6.082933107910402
Validation loss: 5.76220184964963

Epoch: 6| Step: 7
Training loss: 5.759547061595758
Validation loss: 5.756734716009864

Epoch: 6| Step: 8
Training loss: 5.709612774921849
Validation loss: 5.751625683688577

Epoch: 6| Step: 9
Training loss: 5.656289790735385
Validation loss: 5.746163188932775

Epoch: 6| Step: 10
Training loss: 5.417706824959333
Validation loss: 5.740601761714221

Epoch: 6| Step: 11
Training loss: 5.94599676016762
Validation loss: 5.734976632627003

Epoch: 6| Step: 12
Training loss: 5.730137561258653
Validation loss: 5.729450684906584

Epoch: 6| Step: 13
Training loss: 4.742964905517508
Validation loss: 5.723580447750627

Epoch: 2| Step: 0
Training loss: 5.4338349015277
Validation loss: 5.717794525787706

Epoch: 6| Step: 1
Training loss: 6.2899186019603714
Validation loss: 5.7115105587126695

Epoch: 6| Step: 2
Training loss: 5.841617297055985
Validation loss: 5.7052892094078045

Epoch: 6| Step: 3
Training loss: 5.506246314334394
Validation loss: 5.698561057983803

Epoch: 6| Step: 4
Training loss: 6.0528074828192135
Validation loss: 5.69189191959345

Epoch: 6| Step: 5
Training loss: 6.017497932867972
Validation loss: 5.684542902631245

Epoch: 6| Step: 6
Training loss: 5.904836657119791
Validation loss: 5.677114315650243

Epoch: 6| Step: 7
Training loss: 5.761878639201008
Validation loss: 5.668480278264696

Epoch: 6| Step: 8
Training loss: 4.942144020702179
Validation loss: 5.660293046957102

Epoch: 6| Step: 9
Training loss: 5.686407969509673
Validation loss: 5.651623272348989

Epoch: 6| Step: 10
Training loss: 5.713033518512085
Validation loss: 5.642720171243948

Epoch: 6| Step: 11
Training loss: 6.152392422922547
Validation loss: 5.63241656268719

Epoch: 6| Step: 12
Training loss: 5.129449726953445
Validation loss: 5.622726816057603

Epoch: 6| Step: 13
Training loss: 5.021751963467807
Validation loss: 5.61286516828486

Epoch: 3| Step: 0
Training loss: 6.226065621838675
Validation loss: 5.602152860754881

Epoch: 6| Step: 1
Training loss: 5.530018125093912
Validation loss: 5.590937076002556

Epoch: 6| Step: 2
Training loss: 5.588769496268554
Validation loss: 5.579052454686235

Epoch: 6| Step: 3
Training loss: 4.424981310099124
Validation loss: 5.56658270639127

Epoch: 6| Step: 4
Training loss: 5.839376026420091
Validation loss: 5.553995409428627

Epoch: 6| Step: 5
Training loss: 5.816806961305976
Validation loss: 5.54088641192814

Epoch: 6| Step: 6
Training loss: 4.602492958904726
Validation loss: 5.52705548975958

Epoch: 6| Step: 7
Training loss: 4.757722499854328
Validation loss: 5.513142683431916

Epoch: 6| Step: 8
Training loss: 5.738559121505643
Validation loss: 5.498458471016563

Epoch: 6| Step: 9
Training loss: 6.213141437781608
Validation loss: 5.484114294426474

Epoch: 6| Step: 10
Training loss: 5.178176222129443
Validation loss: 5.467181417169476

Epoch: 6| Step: 11
Training loss: 6.276330644172634
Validation loss: 5.45010907780033

Epoch: 6| Step: 12
Training loss: 5.706769891559922
Validation loss: 5.432871858220147

Epoch: 6| Step: 13
Training loss: 5.457106571319393
Validation loss: 5.417047356920827

Epoch: 4| Step: 0
Training loss: 6.20050869977507
Validation loss: 5.399549113811452

Epoch: 6| Step: 1
Training loss: 4.496984106970983
Validation loss: 5.381548237881259

Epoch: 6| Step: 2
Training loss: 5.518326484094485
Validation loss: 5.362454524125752

Epoch: 6| Step: 3
Training loss: 5.379836279778112
Validation loss: 5.344033781186553

Epoch: 6| Step: 4
Training loss: 6.28804036239599
Validation loss: 5.326908765578276

Epoch: 6| Step: 5
Training loss: 4.765584776661706
Validation loss: 5.3066966952779415

Epoch: 6| Step: 6
Training loss: 5.657262216274884
Validation loss: 5.288254669845312

Epoch: 6| Step: 7
Training loss: 4.919552984942359
Validation loss: 5.268385768003634

Epoch: 6| Step: 8
Training loss: 4.999106518069395
Validation loss: 5.2481904668925115

Epoch: 6| Step: 9
Training loss: 5.214835337657073
Validation loss: 5.229216402774371

Epoch: 6| Step: 10
Training loss: 5.0615913611772285
Validation loss: 5.210776533782657

Epoch: 6| Step: 11
Training loss: 5.178068664649514
Validation loss: 5.19054104578427

Epoch: 6| Step: 12
Training loss: 5.412010695825399
Validation loss: 5.171414924790894

Epoch: 6| Step: 13
Training loss: 5.1627540950728426
Validation loss: 5.1522664114524925

Epoch: 5| Step: 0
Training loss: 4.145514598971182
Validation loss: 5.131360926458385

Epoch: 6| Step: 1
Training loss: 5.147338194117339
Validation loss: 5.1126684481265405

Epoch: 6| Step: 2
Training loss: 4.733658638821215
Validation loss: 5.093665307430086

Epoch: 6| Step: 3
Training loss: 5.658009966607214
Validation loss: 5.074497685127924

Epoch: 6| Step: 4
Training loss: 4.790100283916869
Validation loss: 5.055225263637185

Epoch: 6| Step: 5
Training loss: 6.442850500422991
Validation loss: 5.036010351021225

Epoch: 6| Step: 6
Training loss: 4.700001030779786
Validation loss: 5.016918423609946

Epoch: 6| Step: 7
Training loss: 4.837483739702364
Validation loss: 4.997346473364623

Epoch: 6| Step: 8
Training loss: 4.873381125811125
Validation loss: 4.97678318024742

Epoch: 6| Step: 9
Training loss: 5.625010511600421
Validation loss: 4.955761499029842

Epoch: 6| Step: 10
Training loss: 5.2844744888947375
Validation loss: 4.9334612281593015

Epoch: 6| Step: 11
Training loss: 4.552563860894159
Validation loss: 4.912419239432312

Epoch: 6| Step: 12
Training loss: 4.912243723311863
Validation loss: 4.889525270636578

Epoch: 6| Step: 13
Training loss: 4.620440529632019
Validation loss: 4.866478214725457

Epoch: 6| Step: 0
Training loss: 5.148667001891101
Validation loss: 4.844250580970767

Epoch: 6| Step: 1
Training loss: 4.381984476080261
Validation loss: 4.819936909770531

Epoch: 6| Step: 2
Training loss: 4.9153352432554245
Validation loss: 4.7981170695513535

Epoch: 6| Step: 3
Training loss: 4.658082332684385
Validation loss: 4.774948446782263

Epoch: 6| Step: 4
Training loss: 5.390030891740419
Validation loss: 4.752954437478572

Epoch: 6| Step: 5
Training loss: 4.31535024023808
Validation loss: 4.726870652135941

Epoch: 6| Step: 6
Training loss: 4.200408397982137
Validation loss: 4.705363675551002

Epoch: 6| Step: 7
Training loss: 4.722018695010671
Validation loss: 4.681466302713254

Epoch: 6| Step: 8
Training loss: 4.532845472750421
Validation loss: 4.658460690338719

Epoch: 6| Step: 9
Training loss: 4.943466637516656
Validation loss: 4.6353085438791455

Epoch: 6| Step: 10
Training loss: 4.833442204444072
Validation loss: 4.612386914610606

Epoch: 6| Step: 11
Training loss: 4.628596788838123
Validation loss: 4.591459885304193

Epoch: 6| Step: 12
Training loss: 5.127664385187387
Validation loss: 4.565908900667857

Epoch: 6| Step: 13
Training loss: 5.074665663657104
Validation loss: 4.544745284741359

Epoch: 7| Step: 0
Training loss: 5.353875633473947
Validation loss: 4.522721665684527

Epoch: 6| Step: 1
Training loss: 3.7049797982142603
Validation loss: 4.497008579298022

Epoch: 6| Step: 2
Training loss: 5.056598567382552
Validation loss: 4.477786341345437

Epoch: 6| Step: 3
Training loss: 4.882115184583124
Validation loss: 4.456249412834929

Epoch: 6| Step: 4
Training loss: 4.578030842408444
Validation loss: 4.43436717730693

Epoch: 6| Step: 5
Training loss: 3.3313548574352185
Validation loss: 4.416245300909608

Epoch: 6| Step: 6
Training loss: 4.720691003811496
Validation loss: 4.396534219089189

Epoch: 6| Step: 7
Training loss: 2.851120671571497
Validation loss: 4.377921324197448

Epoch: 6| Step: 8
Training loss: 4.968754414490472
Validation loss: 4.360018826662578

Epoch: 6| Step: 9
Training loss: 5.042214902384286
Validation loss: 4.341962886837132

Epoch: 6| Step: 10
Training loss: 3.4267354090978257
Validation loss: 4.325265178509233

Epoch: 6| Step: 11
Training loss: 4.42627424438697
Validation loss: 4.306137541992014

Epoch: 6| Step: 12
Training loss: 5.2569762609278525
Validation loss: 4.2911478683398965

Epoch: 6| Step: 13
Training loss: 4.584680648215115
Validation loss: 4.274377919355494

Epoch: 8| Step: 0
Training loss: 3.4527101569605456
Validation loss: 4.257541350045254

Epoch: 6| Step: 1
Training loss: 3.6090308351454636
Validation loss: 4.244179436959066

Epoch: 6| Step: 2
Training loss: 3.5697509858294145
Validation loss: 4.229021453102099

Epoch: 6| Step: 3
Training loss: 5.5432154659020805
Validation loss: 4.214689516732726

Epoch: 6| Step: 4
Training loss: 3.931943333167982
Validation loss: 4.2008421416903845

Epoch: 6| Step: 5
Training loss: 3.344866129615478
Validation loss: 4.183550269050104

Epoch: 6| Step: 6
Training loss: 4.665457205492222
Validation loss: 4.169580906451765

Epoch: 6| Step: 7
Training loss: 4.113283104819145
Validation loss: 4.15511066032191

Epoch: 6| Step: 8
Training loss: 4.075982828330574
Validation loss: 4.141287217496537

Epoch: 6| Step: 9
Training loss: 4.223837716308587
Validation loss: 4.126195567154048

Epoch: 6| Step: 10
Training loss: 4.363826543463939
Validation loss: 4.113165514112918

Epoch: 6| Step: 11
Training loss: 5.413317696559728
Validation loss: 4.099989070022385

Epoch: 6| Step: 12
Training loss: 4.550575035563844
Validation loss: 4.087391862821488

Epoch: 6| Step: 13
Training loss: 4.690878705832939
Validation loss: 4.073716517860225

Epoch: 9| Step: 0
Training loss: 4.655736907748848
Validation loss: 4.060774542279584

Epoch: 6| Step: 1
Training loss: 4.19300616926253
Validation loss: 4.049171414798754

Epoch: 6| Step: 2
Training loss: 4.601930561468537
Validation loss: 4.0376863360484565

Epoch: 6| Step: 3
Training loss: 4.31306829716228
Validation loss: 4.025642626872309

Epoch: 6| Step: 4
Training loss: 3.433814830411037
Validation loss: 4.013617199595549

Epoch: 6| Step: 5
Training loss: 4.819244216927348
Validation loss: 4.003652407415258

Epoch: 6| Step: 6
Training loss: 3.298079862591156
Validation loss: 3.9929193102453167

Epoch: 6| Step: 7
Training loss: 3.5658455916697194
Validation loss: 3.9843654644518445

Epoch: 6| Step: 8
Training loss: 4.161221850395387
Validation loss: 3.974392829505427

Epoch: 6| Step: 9
Training loss: 3.505575779572549
Validation loss: 3.966819392440726

Epoch: 6| Step: 10
Training loss: 4.087669924315838
Validation loss: 3.9589197036456305

Epoch: 6| Step: 11
Training loss: 4.321412979332044
Validation loss: 3.950970937480797

Epoch: 6| Step: 12
Training loss: 4.324296600826422
Validation loss: 3.941742043857469

Epoch: 6| Step: 13
Training loss: 4.543727139044214
Validation loss: 3.9355292921977085

Epoch: 10| Step: 0
Training loss: 3.9882145352065765
Validation loss: 3.930276258116321

Epoch: 6| Step: 1
Training loss: 5.111109074762648
Validation loss: 3.9196207800787035

Epoch: 6| Step: 2
Training loss: 4.247457304633856
Validation loss: 3.9137684452476407

Epoch: 6| Step: 3
Training loss: 3.899408804271123
Validation loss: 3.905920704733764

Epoch: 6| Step: 4
Training loss: 3.94212263721473
Validation loss: 3.899026064008443

Epoch: 6| Step: 5
Training loss: 4.109661135846757
Validation loss: 3.892658599464071

Epoch: 6| Step: 6
Training loss: 2.976052708661499
Validation loss: 3.8854501409335995

Epoch: 6| Step: 7
Training loss: 3.4161085898049066
Validation loss: 3.878256059298395

Epoch: 6| Step: 8
Training loss: 4.5105638487356
Validation loss: 3.873377872963761

Epoch: 6| Step: 9
Training loss: 3.1139854103878517
Validation loss: 3.8654101789944084

Epoch: 6| Step: 10
Training loss: 4.441444685341058
Validation loss: 3.8612778481241787

Epoch: 6| Step: 11
Training loss: 4.093857625463832
Validation loss: 3.854057861672504

Epoch: 6| Step: 12
Training loss: 4.259553158029502
Validation loss: 3.8466125801826414

Epoch: 6| Step: 13
Training loss: 4.032870417950892
Validation loss: 3.8404313567769943

Epoch: 11| Step: 0
Training loss: 3.6218580902205155
Validation loss: 3.8348380052022266

Epoch: 6| Step: 1
Training loss: 5.1792374957707485
Validation loss: 3.827346196833709

Epoch: 6| Step: 2
Training loss: 3.9725093308009716
Validation loss: 3.8227982488326786

Epoch: 6| Step: 3
Training loss: 3.678735824593943
Validation loss: 3.816454290003542

Epoch: 6| Step: 4
Training loss: 3.9334268240944015
Validation loss: 3.813819557375966

Epoch: 6| Step: 5
Training loss: 4.418429808501687
Validation loss: 3.805521528768897

Epoch: 6| Step: 6
Training loss: 3.0266507838444445
Validation loss: 3.7989139730975827

Epoch: 6| Step: 7
Training loss: 4.361782052060572
Validation loss: 3.7962049572197722

Epoch: 6| Step: 8
Training loss: 4.008210101120159
Validation loss: 3.790067243211945

Epoch: 6| Step: 9
Training loss: 3.3921719024032524
Validation loss: 3.7826616253543515

Epoch: 6| Step: 10
Training loss: 3.27495588898982
Validation loss: 3.779575350974276

Epoch: 6| Step: 11
Training loss: 3.9744412923228096
Validation loss: 3.7738597561175915

Epoch: 6| Step: 12
Training loss: 3.967696402964036
Validation loss: 3.7690529167598643

Epoch: 6| Step: 13
Training loss: 4.540151127387885
Validation loss: 3.7628886883215213

Epoch: 12| Step: 0
Training loss: 3.863113877978297
Validation loss: 3.7593100277850415

Epoch: 6| Step: 1
Training loss: 3.4495731919034314
Validation loss: 3.7553262778949783

Epoch: 6| Step: 2
Training loss: 4.4612000182716915
Validation loss: 3.747798073591596

Epoch: 6| Step: 3
Training loss: 3.747875374691473
Validation loss: 3.7447793887832175

Epoch: 6| Step: 4
Training loss: 3.98480748839947
Validation loss: 3.7402343859667595

Epoch: 6| Step: 5
Training loss: 4.782528375999073
Validation loss: 3.7328409304942536

Epoch: 6| Step: 6
Training loss: 3.6521657971771764
Validation loss: 3.729254670627735

Epoch: 6| Step: 7
Training loss: 4.054526382802654
Validation loss: 3.7249963214594852

Epoch: 6| Step: 8
Training loss: 3.251152421131573
Validation loss: 3.719090746087309

Epoch: 6| Step: 9
Training loss: 4.337483228491643
Validation loss: 3.7138389035021917

Epoch: 6| Step: 10
Training loss: 4.034699612654636
Validation loss: 3.709353720099271

Epoch: 6| Step: 11
Training loss: 3.47936254319239
Validation loss: 3.704874861951004

Epoch: 6| Step: 12
Training loss: 3.857358336106445
Validation loss: 3.7011688093012065

Epoch: 6| Step: 13
Training loss: 3.042222133413864
Validation loss: 3.696268751897295

Epoch: 13| Step: 0
Training loss: 3.399167177637175
Validation loss: 3.6906335627390776

Epoch: 6| Step: 1
Training loss: 4.452273210407499
Validation loss: 3.6884817127465923

Epoch: 6| Step: 2
Training loss: 4.239075026474304
Validation loss: 3.680893794098579

Epoch: 6| Step: 3
Training loss: 3.8099427949310436
Validation loss: 3.678842020737472

Epoch: 6| Step: 4
Training loss: 3.8602233448539947
Validation loss: 3.6752281432343636

Epoch: 6| Step: 5
Training loss: 3.886825974102018
Validation loss: 3.671893415228144

Epoch: 6| Step: 6
Training loss: 3.8714122775895734
Validation loss: 3.667973977966647

Epoch: 6| Step: 7
Training loss: 3.876242776745288
Validation loss: 3.662236897141268

Epoch: 6| Step: 8
Training loss: 4.4440094390549145
Validation loss: 3.655160752021774

Epoch: 6| Step: 9
Training loss: 3.1707790341701068
Validation loss: 3.651180622385238

Epoch: 6| Step: 10
Training loss: 2.790790695619539
Validation loss: 3.6468162531256705

Epoch: 6| Step: 11
Training loss: 3.9353541021723655
Validation loss: 3.6433865560688887

Epoch: 6| Step: 12
Training loss: 4.618347951608239
Validation loss: 3.6421891120397505

Epoch: 6| Step: 13
Training loss: 2.3412718832660318
Validation loss: 3.6377317038416597

Epoch: 14| Step: 0
Training loss: 4.21036357188672
Validation loss: 3.6333839428408035

Epoch: 6| Step: 1
Training loss: 3.711749756911768
Validation loss: 3.631077808108954

Epoch: 6| Step: 2
Training loss: 4.007220665137677
Validation loss: 3.6288920150056065

Epoch: 6| Step: 3
Training loss: 4.487803779882052
Validation loss: 3.6262394953944455

Epoch: 6| Step: 4
Training loss: 3.7196341353130333
Validation loss: 3.623553715620296

Epoch: 6| Step: 5
Training loss: 3.0360992027329163
Validation loss: 3.6172803860966636

Epoch: 6| Step: 6
Training loss: 4.1277489028087295
Validation loss: 3.6141910953068734

Epoch: 6| Step: 7
Training loss: 4.629869732599906
Validation loss: 3.6096892564326493

Epoch: 6| Step: 8
Training loss: 3.7518571705341315
Validation loss: 3.6050274672357947

Epoch: 6| Step: 9
Training loss: 2.9889382830591407
Validation loss: 3.6029010328525364

Epoch: 6| Step: 10
Training loss: 3.289701494861345
Validation loss: 3.604336757986465

Epoch: 6| Step: 11
Training loss: 4.175027292128118
Validation loss: 3.6000652536337046

Epoch: 6| Step: 12
Training loss: 3.7280457301957366
Validation loss: 3.596172594457131

Epoch: 6| Step: 13
Training loss: 2.1971733921614307
Validation loss: 3.5945022929850228

Epoch: 15| Step: 0
Training loss: 2.8700588722703673
Validation loss: 3.594138553795767

Epoch: 6| Step: 1
Training loss: 3.56971785854283
Validation loss: 3.591974908083296

Epoch: 6| Step: 2
Training loss: 4.026479574703307
Validation loss: 3.595876812529718

Epoch: 6| Step: 3
Training loss: 3.658667783865837
Validation loss: 3.5911655001472975

Epoch: 6| Step: 4
Training loss: 4.150159000889727
Validation loss: 3.589149285896583

Epoch: 6| Step: 5
Training loss: 3.6168492202275107
Validation loss: 3.5871004981876444

Epoch: 6| Step: 6
Training loss: 3.3466624472947393
Validation loss: 3.5825605100421325

Epoch: 6| Step: 7
Training loss: 4.415762514860427
Validation loss: 3.5795366449390764

Epoch: 6| Step: 8
Training loss: 4.384949188807977
Validation loss: 3.5788129428284656

Epoch: 6| Step: 9
Training loss: 3.7801456572710985
Validation loss: 3.5737676201182245

Epoch: 6| Step: 10
Training loss: 3.6348945803880843
Validation loss: 3.5704698658760203

Epoch: 6| Step: 11
Training loss: 4.04987121188881
Validation loss: 3.5696395836217585

Epoch: 6| Step: 12
Training loss: 3.555999580778048
Validation loss: 3.5676110331242867

Epoch: 6| Step: 13
Training loss: 3.3827184791802
Validation loss: 3.563647767686679

Epoch: 16| Step: 0
Training loss: 3.6281523316608193
Validation loss: 3.5624741771188844

Epoch: 6| Step: 1
Training loss: 4.571523861232528
Validation loss: 3.5594491782008038

Epoch: 6| Step: 2
Training loss: 4.055165404157779
Validation loss: 3.558183329869731

Epoch: 6| Step: 3
Training loss: 3.641819573748713
Validation loss: 3.557133969559467

Epoch: 6| Step: 4
Training loss: 3.9652857040857543
Validation loss: 3.5547491144670613

Epoch: 6| Step: 5
Training loss: 3.939915960354764
Validation loss: 3.554265283000925

Epoch: 6| Step: 6
Training loss: 4.350386784337669
Validation loss: 3.5516946823143822

Epoch: 6| Step: 7
Training loss: 3.5478601641961514
Validation loss: 3.5500614550324956

Epoch: 6| Step: 8
Training loss: 2.9350895833213646
Validation loss: 3.545941679125273

Epoch: 6| Step: 9
Training loss: 3.967219741047234
Validation loss: 3.544946933333355

Epoch: 6| Step: 10
Training loss: 3.4402629498962303
Validation loss: 3.543916825442475

Epoch: 6| Step: 11
Training loss: 3.106970235730515
Validation loss: 3.541517999895908

Epoch: 6| Step: 12
Training loss: 3.3797068799468915
Validation loss: 3.5399719314292053

Epoch: 6| Step: 13
Training loss: 3.634336615349078
Validation loss: 3.537805276126667

Epoch: 17| Step: 0
Training loss: 3.540816994265228
Validation loss: 3.537132017182819

Epoch: 6| Step: 1
Training loss: 4.182959984967564
Validation loss: 3.5368189536848083

Epoch: 6| Step: 2
Training loss: 3.428760863929084
Validation loss: 3.5346007693948365

Epoch: 6| Step: 3
Training loss: 3.816583291577089
Validation loss: 3.5329761371786033

Epoch: 6| Step: 4
Training loss: 4.6030853290492875
Validation loss: 3.5318607488581066

Epoch: 6| Step: 5
Training loss: 4.19441631271214
Validation loss: 3.5298348438050287

Epoch: 6| Step: 6
Training loss: 4.083530628861572
Validation loss: 3.529227188958415

Epoch: 6| Step: 7
Training loss: 3.1247624116225787
Validation loss: 3.5259331596683645

Epoch: 6| Step: 8
Training loss: 4.041929780451122
Validation loss: 3.5258552796587437

Epoch: 6| Step: 9
Training loss: 3.997234938507554
Validation loss: 3.524478408715756

Epoch: 6| Step: 10
Training loss: 3.0722109916471014
Validation loss: 3.5248022212056487

Epoch: 6| Step: 11
Training loss: 2.347510411053566
Validation loss: 3.521091317510443

Epoch: 6| Step: 12
Training loss: 3.835484122464114
Validation loss: 3.5213494944003356

Epoch: 6| Step: 13
Training loss: 3.230308740936008
Validation loss: 3.5198815205962863

Epoch: 18| Step: 0
Training loss: 2.6741956481916445
Validation loss: 3.5192994336203216

Epoch: 6| Step: 1
Training loss: 3.50544315513277
Validation loss: 3.5181172386815156

Epoch: 6| Step: 2
Training loss: 3.599253015373712
Validation loss: 3.5160778152372307

Epoch: 6| Step: 3
Training loss: 4.148879550291518
Validation loss: 3.513661126241165

Epoch: 6| Step: 4
Training loss: 4.484963620994113
Validation loss: 3.5142683868645137

Epoch: 6| Step: 5
Training loss: 2.81859352371077
Validation loss: 3.512076618963752

Epoch: 6| Step: 6
Training loss: 3.1834210495239623
Validation loss: 3.5119788451682474

Epoch: 6| Step: 7
Training loss: 3.1364019288551286
Validation loss: 3.5102420526232536

Epoch: 6| Step: 8
Training loss: 4.191624446426221
Validation loss: 3.511086379444339

Epoch: 6| Step: 9
Training loss: 3.6993837410407373
Validation loss: 3.5089793100556905

Epoch: 6| Step: 10
Training loss: 2.8775030103944466
Validation loss: 3.507889419795046

Epoch: 6| Step: 11
Training loss: 4.488218355194659
Validation loss: 3.507762682844393

Epoch: 6| Step: 12
Training loss: 3.808022543303495
Validation loss: 3.506075790388662

Epoch: 6| Step: 13
Training loss: 5.367345815930634
Validation loss: 3.504681665755279

Epoch: 19| Step: 0
Training loss: 3.959968282784495
Validation loss: 3.502800738659627

Epoch: 6| Step: 1
Training loss: 3.485945959008254
Validation loss: 3.5028333709790505

Epoch: 6| Step: 2
Training loss: 3.636599431195802
Validation loss: 3.500197271714736

Epoch: 6| Step: 3
Training loss: 3.744802815399057
Validation loss: 3.5003754345572906

Epoch: 6| Step: 4
Training loss: 3.7572584477369695
Validation loss: 3.500042327648351

Epoch: 6| Step: 5
Training loss: 4.248756226694696
Validation loss: 3.4979564645697225

Epoch: 6| Step: 6
Training loss: 4.09185933723208
Validation loss: 3.49623678646591

Epoch: 6| Step: 7
Training loss: 3.845204148050601
Validation loss: 3.4958653807892954

Epoch: 6| Step: 8
Training loss: 3.518702808558298
Validation loss: 3.493195366222284

Epoch: 6| Step: 9
Training loss: 3.191372333098919
Validation loss: 3.4932300881173473

Epoch: 6| Step: 10
Training loss: 4.308386347215174
Validation loss: 3.4916570935617486

Epoch: 6| Step: 11
Training loss: 2.588106381041437
Validation loss: 3.4876030911293414

Epoch: 6| Step: 12
Training loss: 4.114010593131766
Validation loss: 3.488374183531263

Epoch: 6| Step: 13
Training loss: 2.376459075061701
Validation loss: 3.488883635829603

Epoch: 20| Step: 0
Training loss: 3.2983520959362553
Validation loss: 3.4902122203920416

Epoch: 6| Step: 1
Training loss: 3.5149435103368836
Validation loss: 3.4864697605995825

Epoch: 6| Step: 2
Training loss: 3.8350870156891768
Validation loss: 3.4855256857138546

Epoch: 6| Step: 3
Training loss: 5.036422061362191
Validation loss: 3.4876621742750453

Epoch: 6| Step: 4
Training loss: 3.8885070673890727
Validation loss: 3.4846513586059458

Epoch: 6| Step: 5
Training loss: 3.7944428617201993
Validation loss: 3.4816454822495833

Epoch: 6| Step: 6
Training loss: 3.8834396254982693
Validation loss: 3.4770252789450633

Epoch: 6| Step: 7
Training loss: 3.8423655427975016
Validation loss: 3.477243306058886

Epoch: 6| Step: 8
Training loss: 2.474363969709377
Validation loss: 3.474792364608096

Epoch: 6| Step: 9
Training loss: 3.8520002445208985
Validation loss: 3.474185047271986

Epoch: 6| Step: 10
Training loss: 4.2200545942924235
Validation loss: 3.4721955216451064

Epoch: 6| Step: 11
Training loss: 3.9164785515811418
Validation loss: 3.470885118089

Epoch: 6| Step: 12
Training loss: 2.4591893359899277
Validation loss: 3.4717052479025368

Epoch: 6| Step: 13
Training loss: 2.072503654191462
Validation loss: 3.4696143382622426

Epoch: 21| Step: 0
Training loss: 3.1828897083863827
Validation loss: 3.470051818353888

Epoch: 6| Step: 1
Training loss: 3.9210058214202292
Validation loss: 3.466485094548354

Epoch: 6| Step: 2
Training loss: 3.615981096488356
Validation loss: 3.4675305325686994

Epoch: 6| Step: 3
Training loss: 4.055368355272828
Validation loss: 3.4667047414708123

Epoch: 6| Step: 4
Training loss: 3.6828918111852684
Validation loss: 3.464772110584885

Epoch: 6| Step: 5
Training loss: 4.314917287729995
Validation loss: 3.464020556973782

Epoch: 6| Step: 6
Training loss: 3.3709955831050085
Validation loss: 3.46256047476604

Epoch: 6| Step: 7
Training loss: 3.2145101529434412
Validation loss: 3.4601131375852447

Epoch: 6| Step: 8
Training loss: 4.20743518473431
Validation loss: 3.4588669949428077

Epoch: 6| Step: 9
Training loss: 3.4937164577996307
Validation loss: 3.4580518632948345

Epoch: 6| Step: 10
Training loss: 3.6264279940083655
Validation loss: 3.4563277876474103

Epoch: 6| Step: 11
Training loss: 3.308922329094545
Validation loss: 3.4542011304144653

Epoch: 6| Step: 12
Training loss: 3.6506077195176365
Validation loss: 3.4548251023689107

Epoch: 6| Step: 13
Training loss: 3.6537534879601896
Validation loss: 3.4526661753780523

Epoch: 22| Step: 0
Training loss: 3.5666731100529256
Validation loss: 3.453450266457538

Epoch: 6| Step: 1
Training loss: 3.8621265317239284
Validation loss: 3.451967686051702

Epoch: 6| Step: 2
Training loss: 3.750611064715275
Validation loss: 3.450288598698083

Epoch: 6| Step: 3
Training loss: 4.119262867140614
Validation loss: 3.448052044557746

Epoch: 6| Step: 4
Training loss: 3.7119023725069145
Validation loss: 3.447150496445962

Epoch: 6| Step: 5
Training loss: 3.647730495394199
Validation loss: 3.4470325111228184

Epoch: 6| Step: 6
Training loss: 3.4195191796037254
Validation loss: 3.4474265856869732

Epoch: 6| Step: 7
Training loss: 3.3761209110013644
Validation loss: 3.4451559194566967

Epoch: 6| Step: 8
Training loss: 3.1603789563444886
Validation loss: 3.444739628509609

Epoch: 6| Step: 9
Training loss: 4.17704081652432
Validation loss: 3.442259222584564

Epoch: 6| Step: 10
Training loss: 3.0922038520739155
Validation loss: 3.442298412872354

Epoch: 6| Step: 11
Training loss: 3.385395006941929
Validation loss: 3.440531707631727

Epoch: 6| Step: 12
Training loss: 3.976081864064936
Validation loss: 3.440021923998838

Epoch: 6| Step: 13
Training loss: 4.067532752525921
Validation loss: 3.436927996911889

Epoch: 23| Step: 0
Training loss: 2.958499760490899
Validation loss: 3.433677097326117

Epoch: 6| Step: 1
Training loss: 3.2468136059240864
Validation loss: 3.433584542487112

Epoch: 6| Step: 2
Training loss: 3.920629904020439
Validation loss: 3.4312694835686846

Epoch: 6| Step: 3
Training loss: 3.3632380076252497
Validation loss: 3.4312723750014698

Epoch: 6| Step: 4
Training loss: 3.655352881809328
Validation loss: 3.429801235461677

Epoch: 6| Step: 5
Training loss: 3.9491342295913516
Validation loss: 3.4293259507579843

Epoch: 6| Step: 6
Training loss: 4.457913578036061
Validation loss: 3.425686917763827

Epoch: 6| Step: 7
Training loss: 3.0346236185038573
Validation loss: 3.423629184497616

Epoch: 6| Step: 8
Training loss: 3.4705797472970756
Validation loss: 3.423977326534936

Epoch: 6| Step: 9
Training loss: 3.4738627377253466
Validation loss: 3.421226402161558

Epoch: 6| Step: 10
Training loss: 4.335636602735123
Validation loss: 3.423520948592887

Epoch: 6| Step: 11
Training loss: 3.286107709088736
Validation loss: 3.417807485875016

Epoch: 6| Step: 12
Training loss: 3.9664475377781425
Validation loss: 3.4185945882610738

Epoch: 6| Step: 13
Training loss: 3.58058794702584
Validation loss: 3.416597138024293

Epoch: 24| Step: 0
Training loss: 4.297706329381233
Validation loss: 3.4143098290247447

Epoch: 6| Step: 1
Training loss: 3.4464109577036637
Validation loss: 3.414913810336937

Epoch: 6| Step: 2
Training loss: 4.476924222542165
Validation loss: 3.4118457751090023

Epoch: 6| Step: 3
Training loss: 3.506520872481781
Validation loss: 3.411170931710621

Epoch: 6| Step: 4
Training loss: 3.532062268305515
Validation loss: 3.4107107648924044

Epoch: 6| Step: 5
Training loss: 3.292955283140835
Validation loss: 3.4067827289638117

Epoch: 6| Step: 6
Training loss: 3.1764568440757053
Validation loss: 3.4015311890899467

Epoch: 6| Step: 7
Training loss: 3.3105284383704916
Validation loss: 3.4056722740553838

Epoch: 6| Step: 8
Training loss: 3.694297344622303
Validation loss: 3.4024873611403397

Epoch: 6| Step: 9
Training loss: 3.7943531342506143
Validation loss: 3.4030950558375173

Epoch: 6| Step: 10
Training loss: 3.6849511599571483
Validation loss: 3.4003749222068995

Epoch: 6| Step: 11
Training loss: 3.421587788272995
Validation loss: 3.398694378068689

Epoch: 6| Step: 12
Training loss: 4.094455337912499
Validation loss: 3.3979766718079425

Epoch: 6| Step: 13
Training loss: 1.8881560038269078
Validation loss: 3.394736925229558

Epoch: 25| Step: 0
Training loss: 3.1714841103815012
Validation loss: 3.3917051307130035

Epoch: 6| Step: 1
Training loss: 5.173869045350636
Validation loss: 3.3880106978693503

Epoch: 6| Step: 2
Training loss: 4.1032688043036
Validation loss: 3.3826813481864675

Epoch: 6| Step: 3
Training loss: 3.765664254771406
Validation loss: 3.3819312002684603

Epoch: 6| Step: 4
Training loss: 3.32529583525553
Validation loss: 3.3805595177723946

Epoch: 6| Step: 5
Training loss: 3.1256318025871566
Validation loss: 3.378021552711376

Epoch: 6| Step: 6
Training loss: 3.2323743741789306
Validation loss: 3.373133271866534

Epoch: 6| Step: 7
Training loss: 2.3643350568881876
Validation loss: 3.3741161734197895

Epoch: 6| Step: 8
Training loss: 3.0066007476933603
Validation loss: 3.372902358457238

Epoch: 6| Step: 9
Training loss: 3.0715061032214255
Validation loss: 3.3731341823674894

Epoch: 6| Step: 10
Training loss: 3.5323781599777635
Validation loss: 3.3740773688852976

Epoch: 6| Step: 11
Training loss: 4.301091902736575
Validation loss: 3.371031645800933

Epoch: 6| Step: 12
Training loss: 4.149999522013809
Validation loss: 3.371338204204146

Epoch: 6| Step: 13
Training loss: 3.118671570672785
Validation loss: 3.3694440092361604

Epoch: 26| Step: 0
Training loss: 3.4058123666148896
Validation loss: 3.3696582364120387

Epoch: 6| Step: 1
Training loss: 2.9270994428053325
Validation loss: 3.368963326379385

Epoch: 6| Step: 2
Training loss: 2.857888090490696
Validation loss: 3.367922338950718

Epoch: 6| Step: 3
Training loss: 4.398477394912322
Validation loss: 3.36725780093045

Epoch: 6| Step: 4
Training loss: 4.273811058998465
Validation loss: 3.36635097401099

Epoch: 6| Step: 5
Training loss: 3.5957529871610667
Validation loss: 3.366995698909743

Epoch: 6| Step: 6
Training loss: 3.133254479031522
Validation loss: 3.367139570547333

Epoch: 6| Step: 7
Training loss: 3.4038096794418906
Validation loss: 3.367067930915016

Epoch: 6| Step: 8
Training loss: 3.5205120113099095
Validation loss: 3.365486442632787

Epoch: 6| Step: 9
Training loss: 3.3618376465945743
Validation loss: 3.363905637494071

Epoch: 6| Step: 10
Training loss: 3.629390031413277
Validation loss: 3.3619335492335827

Epoch: 6| Step: 11
Training loss: 3.959512247237398
Validation loss: 3.359998451602206

Epoch: 6| Step: 12
Training loss: 4.062854457944014
Validation loss: 3.3598954221410873

Epoch: 6| Step: 13
Training loss: 3.3202507462088153
Validation loss: 3.3583374161022297

Epoch: 27| Step: 0
Training loss: 3.121359879435283
Validation loss: 3.3598531616908733

Epoch: 6| Step: 1
Training loss: 3.201109014502551
Validation loss: 3.365399556938718

Epoch: 6| Step: 2
Training loss: 4.219340417308007
Validation loss: 3.361392371597776

Epoch: 6| Step: 3
Training loss: 3.8394171632081355
Validation loss: 3.357224314222831

Epoch: 6| Step: 4
Training loss: 2.547175103041446
Validation loss: 3.3577783490046857

Epoch: 6| Step: 5
Training loss: 3.6278158629519552
Validation loss: 3.354262682646745

Epoch: 6| Step: 6
Training loss: 3.9541676469378904
Validation loss: 3.355194919134017

Epoch: 6| Step: 7
Training loss: 4.302324314464908
Validation loss: 3.355734917421686

Epoch: 6| Step: 8
Training loss: 4.408255046493072
Validation loss: 3.356074845484799

Epoch: 6| Step: 9
Training loss: 3.0178615992457556
Validation loss: 3.35302960268586

Epoch: 6| Step: 10
Training loss: 2.9803247579486696
Validation loss: 3.3519244155550965

Epoch: 6| Step: 11
Training loss: 3.70381615220781
Validation loss: 3.3501350852509857

Epoch: 6| Step: 12
Training loss: 3.3474212172270748
Validation loss: 3.3496167407694335

Epoch: 6| Step: 13
Training loss: 3.338256173069792
Validation loss: 3.3507414163733724

Epoch: 28| Step: 0
Training loss: 3.3864423557648897
Validation loss: 3.3485456701810516

Epoch: 6| Step: 1
Training loss: 3.5930938121631852
Validation loss: 3.3518140385655393

Epoch: 6| Step: 2
Training loss: 3.70735692803454
Validation loss: 3.3487529785771124

Epoch: 6| Step: 3
Training loss: 4.059560328387109
Validation loss: 3.3477305028348177

Epoch: 6| Step: 4
Training loss: 3.527091218984989
Validation loss: 3.348941374572358

Epoch: 6| Step: 5
Training loss: 4.618158796617584
Validation loss: 3.3462469120233487

Epoch: 6| Step: 6
Training loss: 3.9787850454922067
Validation loss: 3.346276626017325

Epoch: 6| Step: 7
Training loss: 4.275698661599038
Validation loss: 3.3448484094657926

Epoch: 6| Step: 8
Training loss: 1.8853225754782093
Validation loss: 3.3453751330287163

Epoch: 6| Step: 9
Training loss: 3.568067249519651
Validation loss: 3.345729155132977

Epoch: 6| Step: 10
Training loss: 2.1366337230997297
Validation loss: 3.3447789259523475

Epoch: 6| Step: 11
Training loss: 3.246809346890974
Validation loss: 3.344830853242216

Epoch: 6| Step: 12
Training loss: 3.5246924895217338
Validation loss: 3.344382677704926

Epoch: 6| Step: 13
Training loss: 3.733160739269689
Validation loss: 3.3460761462500077

Epoch: 29| Step: 0
Training loss: 3.5836368402685124
Validation loss: 3.3454461842857053

Epoch: 6| Step: 1
Training loss: 4.26855189476716
Validation loss: 3.344408570171943

Epoch: 6| Step: 2
Training loss: 2.6549472980333286
Validation loss: 3.342752100176746

Epoch: 6| Step: 3
Training loss: 3.776996963503796
Validation loss: 3.341153568669402

Epoch: 6| Step: 4
Training loss: 4.317576861556067
Validation loss: 3.341089997916695

Epoch: 6| Step: 5
Training loss: 3.313050854063198
Validation loss: 3.3412034453507946

Epoch: 6| Step: 6
Training loss: 3.751796292190025
Validation loss: 3.3396362155772406

Epoch: 6| Step: 7
Training loss: 4.001322527641935
Validation loss: 3.3397492042337418

Epoch: 6| Step: 8
Training loss: 3.3820220517116915
Validation loss: 3.33908003815231

Epoch: 6| Step: 9
Training loss: 3.527966618594068
Validation loss: 3.3389345566628643

Epoch: 6| Step: 10
Training loss: 2.520714297255818
Validation loss: 3.338195021547652

Epoch: 6| Step: 11
Training loss: 3.9612170239295077
Validation loss: 3.3385059558974923

Epoch: 6| Step: 12
Training loss: 3.4617153008438866
Validation loss: 3.3386335862120426

Epoch: 6| Step: 13
Training loss: 2.5777176968745574
Validation loss: 3.3372332267948273

Epoch: 30| Step: 0
Training loss: 3.8440578926641207
Validation loss: 3.3377389055811033

Epoch: 6| Step: 1
Training loss: 3.7401675703890387
Validation loss: 3.3369884898310973

Epoch: 6| Step: 2
Training loss: 3.049236614811233
Validation loss: 3.338350943889163

Epoch: 6| Step: 3
Training loss: 4.219265376506058
Validation loss: 3.336604484978218

Epoch: 6| Step: 4
Training loss: 3.470511324364043
Validation loss: 3.336835372602813

Epoch: 6| Step: 5
Training loss: 3.674454712149903
Validation loss: 3.3355650603952416

Epoch: 6| Step: 6
Training loss: 3.4645543197973763
Validation loss: 3.3355117683349196

Epoch: 6| Step: 7
Training loss: 3.6886850812700422
Validation loss: 3.3351763634367337

Epoch: 6| Step: 8
Training loss: 3.3596052223983417
Validation loss: 3.33458853797087

Epoch: 6| Step: 9
Training loss: 3.8617726650406388
Validation loss: 3.3344640111365242

Epoch: 6| Step: 10
Training loss: 3.707905576802016
Validation loss: 3.3350463024126102

Epoch: 6| Step: 11
Training loss: 2.8102152551220785
Validation loss: 3.3345834254290674

Epoch: 6| Step: 12
Training loss: 2.685456940965728
Validation loss: 3.3337942117563863

Epoch: 6| Step: 13
Training loss: 4.473712646464863
Validation loss: 3.3337749947441595

Epoch: 31| Step: 0
Training loss: 3.803768227063753
Validation loss: 3.3327900033541944

Epoch: 6| Step: 1
Training loss: 2.883544167397481
Validation loss: 3.3336539150225692

Epoch: 6| Step: 2
Training loss: 2.5873273819551317
Validation loss: 3.3321105857567366

Epoch: 6| Step: 3
Training loss: 3.3887526444805074
Validation loss: 3.3329670656129657

Epoch: 6| Step: 4
Training loss: 3.6195814478732324
Validation loss: 3.333164035179227

Epoch: 6| Step: 5
Training loss: 3.8061883930801645
Validation loss: 3.3318174935315676

Epoch: 6| Step: 6
Training loss: 3.097880986685256
Validation loss: 3.331769107583467

Epoch: 6| Step: 7
Training loss: 3.5003190576358927
Validation loss: 3.3316313787570007

Epoch: 6| Step: 8
Training loss: 4.150232533753804
Validation loss: 3.332373367536524

Epoch: 6| Step: 9
Training loss: 3.552185787986812
Validation loss: 3.3312985890798283

Epoch: 6| Step: 10
Training loss: 4.098078645039967
Validation loss: 3.3313564242365143

Epoch: 6| Step: 11
Training loss: 3.177911135699261
Validation loss: 3.3321115459358697

Epoch: 6| Step: 12
Training loss: 3.419268447088768
Validation loss: 3.33162835775721

Epoch: 6| Step: 13
Training loss: 5.037275035747661
Validation loss: 3.3315662535202843

Epoch: 32| Step: 0
Training loss: 3.8197098395109332
Validation loss: 3.331996523277957

Epoch: 6| Step: 1
Training loss: 4.025455539111478
Validation loss: 3.3295137799951076

Epoch: 6| Step: 2
Training loss: 3.783153086554409
Validation loss: 3.330377847190504

Epoch: 6| Step: 3
Training loss: 3.0870740897898856
Validation loss: 3.328122686030679

Epoch: 6| Step: 4
Training loss: 3.5644103165237606
Validation loss: 3.3277265699309284

Epoch: 6| Step: 5
Training loss: 3.497285744114823
Validation loss: 3.3272646918087028

Epoch: 6| Step: 6
Training loss: 3.033884064140955
Validation loss: 3.3262144662670283

Epoch: 6| Step: 7
Training loss: 4.178447446742097
Validation loss: 3.3267736877237204

Epoch: 6| Step: 8
Training loss: 3.4288634959206568
Validation loss: 3.3264732392676186

Epoch: 6| Step: 9
Training loss: 3.3502672800507005
Validation loss: 3.3263459176983545

Epoch: 6| Step: 10
Training loss: 3.786763860592402
Validation loss: 3.325540146866491

Epoch: 6| Step: 11
Training loss: 2.840789763285381
Validation loss: 3.32590087817925

Epoch: 6| Step: 12
Training loss: 3.455308042890626
Validation loss: 3.3250028285309745

Epoch: 6| Step: 13
Training loss: 4.025514529494689
Validation loss: 3.32458583063574

Epoch: 33| Step: 0
Training loss: 3.695060350392398
Validation loss: 3.3243046221158927

Epoch: 6| Step: 1
Training loss: 3.3137164491432074
Validation loss: 3.3248961008144127

Epoch: 6| Step: 2
Training loss: 3.158231811770612
Validation loss: 3.3245332771369207

Epoch: 6| Step: 3
Training loss: 3.663538002588636
Validation loss: 3.323615551354581

Epoch: 6| Step: 4
Training loss: 3.419295222516708
Validation loss: 3.323459263213342

Epoch: 6| Step: 5
Training loss: 3.5999906009975233
Validation loss: 3.323784416729622

Epoch: 6| Step: 6
Training loss: 3.584774585058814
Validation loss: 3.323177635357098

Epoch: 6| Step: 7
Training loss: 3.5713108261317306
Validation loss: 3.322469333952929

Epoch: 6| Step: 8
Training loss: 3.5182409429835446
Validation loss: 3.322161946993884

Epoch: 6| Step: 9
Training loss: 3.0709671992019416
Validation loss: 3.321971675745706

Epoch: 6| Step: 10
Training loss: 3.4747891478753616
Validation loss: 3.321832035007447

Epoch: 6| Step: 11
Training loss: 4.292210936369512
Validation loss: 3.3210499698629476

Epoch: 6| Step: 12
Training loss: 3.2673846163001627
Validation loss: 3.320893968581917

Epoch: 6| Step: 13
Training loss: 4.4236118962746165
Validation loss: 3.319622192816023

Epoch: 34| Step: 0
Training loss: 3.0955490892276867
Validation loss: 3.320066262463718

Epoch: 6| Step: 1
Training loss: 3.3291306386692265
Validation loss: 3.3203618944850395

Epoch: 6| Step: 2
Training loss: 3.1135607585574756
Validation loss: 3.3193809550802884

Epoch: 6| Step: 3
Training loss: 3.3311999805695955
Validation loss: 3.3194613145156513

Epoch: 6| Step: 4
Training loss: 3.2644572383155848
Validation loss: 3.31975531538647

Epoch: 6| Step: 5
Training loss: 4.8852482206129455
Validation loss: 3.3198398033076866

Epoch: 6| Step: 6
Training loss: 3.376120487286811
Validation loss: 3.3176383658924147

Epoch: 6| Step: 7
Training loss: 3.8976130101016535
Validation loss: 3.3176575079192454

Epoch: 6| Step: 8
Training loss: 2.6735035355849366
Validation loss: 3.3182580055015047

Epoch: 6| Step: 9
Training loss: 3.7933883670598147
Validation loss: 3.3168598829476803

Epoch: 6| Step: 10
Training loss: 3.7397006697385775
Validation loss: 3.3171904872865206

Epoch: 6| Step: 11
Training loss: 3.7927190696496598
Validation loss: 3.317261571880561

Epoch: 6| Step: 12
Training loss: 3.0742676087584226
Validation loss: 3.318704449994336

Epoch: 6| Step: 13
Training loss: 4.230345888898647
Validation loss: 3.317159930798829

Epoch: 35| Step: 0
Training loss: 3.311650725122974
Validation loss: 3.3158676170190255

Epoch: 6| Step: 1
Training loss: 3.6831686152800533
Validation loss: 3.3162653939128743

Epoch: 6| Step: 2
Training loss: 3.7243731643357276
Validation loss: 3.3159407045366636

Epoch: 6| Step: 3
Training loss: 3.428548636814838
Validation loss: 3.3143894396994957

Epoch: 6| Step: 4
Training loss: 3.159378314370248
Validation loss: 3.315069126778221

Epoch: 6| Step: 5
Training loss: 3.3344819156341092
Validation loss: 3.3140175953986355

Epoch: 6| Step: 6
Training loss: 4.100203690470112
Validation loss: 3.3147510411087215

Epoch: 6| Step: 7
Training loss: 3.425165971507519
Validation loss: 3.3141425973204863

Epoch: 6| Step: 8
Training loss: 2.8830023808993785
Validation loss: 3.314049485094462

Epoch: 6| Step: 9
Training loss: 3.191455257044166
Validation loss: 3.3143913301037586

Epoch: 6| Step: 10
Training loss: 4.513341412069809
Validation loss: 3.3132259543143543

Epoch: 6| Step: 11
Training loss: 2.9965931303388427
Validation loss: 3.313140336700157

Epoch: 6| Step: 12
Training loss: 4.052786614874156
Validation loss: 3.314631537259164

Epoch: 6| Step: 13
Training loss: 3.6632155881314703
Validation loss: 3.3158487244369717

Epoch: 36| Step: 0
Training loss: 3.7336814587498752
Validation loss: 3.315077011636073

Epoch: 6| Step: 1
Training loss: 3.308743632230839
Validation loss: 3.3126616807092524

Epoch: 6| Step: 2
Training loss: 2.438883266669387
Validation loss: 3.3129016487991394

Epoch: 6| Step: 3
Training loss: 3.910337461070111
Validation loss: 3.310997567858249

Epoch: 6| Step: 4
Training loss: 3.288876344754236
Validation loss: 3.3151080312086814

Epoch: 6| Step: 5
Training loss: 3.978160724344639
Validation loss: 3.3181912008378722

Epoch: 6| Step: 6
Training loss: 3.6243864395216305
Validation loss: 3.314009967941922

Epoch: 6| Step: 7
Training loss: 3.0150990398075868
Validation loss: 3.3109663704040044

Epoch: 6| Step: 8
Training loss: 3.907376790608894
Validation loss: 3.309000853799589

Epoch: 6| Step: 9
Training loss: 3.2953011611591463
Validation loss: 3.310592777177055

Epoch: 6| Step: 10
Training loss: 3.582180074181406
Validation loss: 3.3105023103435047

Epoch: 6| Step: 11
Training loss: 4.650148836440593
Validation loss: 3.3092971985502837

Epoch: 6| Step: 12
Training loss: 3.74832840856554
Validation loss: 3.3105589128060573

Epoch: 6| Step: 13
Training loss: 1.8056515847451173
Validation loss: 3.310855764651464

Epoch: 37| Step: 0
Training loss: 4.274269371730024
Validation loss: 3.309704696064966

Epoch: 6| Step: 1
Training loss: 3.1691200055373527
Validation loss: 3.3100796658937695

Epoch: 6| Step: 2
Training loss: 3.136775908180967
Validation loss: 3.3101519921073383

Epoch: 6| Step: 3
Training loss: 3.8096026057654595
Validation loss: 3.309988018614359

Epoch: 6| Step: 4
Training loss: 3.5004878385343736
Validation loss: 3.309348959048918

Epoch: 6| Step: 5
Training loss: 2.8972346439584973
Validation loss: 3.3091076874516845

Epoch: 6| Step: 6
Training loss: 3.244229549174475
Validation loss: 3.307605939639667

Epoch: 6| Step: 7
Training loss: 3.414394196692543
Validation loss: 3.307749395046435

Epoch: 6| Step: 8
Training loss: 3.8196119668616313
Validation loss: 3.307726222796351

Epoch: 6| Step: 9
Training loss: 3.9614677600947377
Validation loss: 3.306785832522772

Epoch: 6| Step: 10
Training loss: 2.950588529685017
Validation loss: 3.3071870815234368

Epoch: 6| Step: 11
Training loss: 3.2117540198421435
Validation loss: 3.306143534634384

Epoch: 6| Step: 12
Training loss: 4.537970248989397
Validation loss: 3.306429227867756

Epoch: 6| Step: 13
Training loss: 3.1989315216090275
Validation loss: 3.3058824335913672

Epoch: 38| Step: 0
Training loss: 2.6971112869380116
Validation loss: 3.30529577085176

Epoch: 6| Step: 1
Training loss: 2.806712320217716
Validation loss: 3.3061338496590946

Epoch: 6| Step: 2
Training loss: 3.3745475748370874
Validation loss: 3.3053723868739877

Epoch: 6| Step: 3
Training loss: 3.7961955149298148
Validation loss: 3.305580760255015

Epoch: 6| Step: 4
Training loss: 3.8374316380279776
Validation loss: 3.304922797906253

Epoch: 6| Step: 5
Training loss: 3.894991588265147
Validation loss: 3.304543910120009

Epoch: 6| Step: 6
Training loss: 3.9208158605485544
Validation loss: 3.303499925607458

Epoch: 6| Step: 7
Training loss: 3.7709035006294673
Validation loss: 3.303725855839065

Epoch: 6| Step: 8
Training loss: 3.4412471808087
Validation loss: 3.3032200070217375

Epoch: 6| Step: 9
Training loss: 3.515525036556248
Validation loss: 3.3032776485024637

Epoch: 6| Step: 10
Training loss: 4.057808617438338
Validation loss: 3.3035593881885323

Epoch: 6| Step: 11
Training loss: 3.5342306874946914
Validation loss: 3.3033434338893954

Epoch: 6| Step: 12
Training loss: 3.46682878506441
Validation loss: 3.301780060743345

Epoch: 6| Step: 13
Training loss: 3.0413182376931234
Validation loss: 3.3015749354831723

Epoch: 39| Step: 0
Training loss: 3.142087377682113
Validation loss: 3.301615104630675

Epoch: 6| Step: 1
Training loss: 3.813201464549273
Validation loss: 3.301598023562533

Epoch: 6| Step: 2
Training loss: 3.8534681082346642
Validation loss: 3.3006557164280035

Epoch: 6| Step: 3
Training loss: 3.9588532089689275
Validation loss: 3.3005497238084525

Epoch: 6| Step: 4
Training loss: 3.8759998139183542
Validation loss: 3.2997628127357497

Epoch: 6| Step: 5
Training loss: 2.334671545023953
Validation loss: 3.300459031403185

Epoch: 6| Step: 6
Training loss: 3.0166998810458834
Validation loss: 3.2999952945197135

Epoch: 6| Step: 7
Training loss: 3.703643633743868
Validation loss: 3.2991641868956614

Epoch: 6| Step: 8
Training loss: 3.637136859398692
Validation loss: 3.2993446769000263

Epoch: 6| Step: 9
Training loss: 2.8539722868356447
Validation loss: 3.2996141269640167

Epoch: 6| Step: 10
Training loss: 4.357854762646895
Validation loss: 3.2989123981892283

Epoch: 6| Step: 11
Training loss: 3.860439632462058
Validation loss: 3.2988352715420004

Epoch: 6| Step: 12
Training loss: 3.394116410344556
Validation loss: 3.298855051902065

Epoch: 6| Step: 13
Training loss: 3.125506093052375
Validation loss: 3.2991470232025426

Epoch: 40| Step: 0
Training loss: 3.762790610410764
Validation loss: 3.298817125387812

Epoch: 6| Step: 1
Training loss: 4.108688006976421
Validation loss: 3.2983065192986416

Epoch: 6| Step: 2
Training loss: 2.9501953125
Validation loss: 3.2977579864095508

Epoch: 6| Step: 3
Training loss: 3.446417875576858
Validation loss: 3.3013944509290156

Epoch: 6| Step: 4
Training loss: 3.198861312926964
Validation loss: 3.29867764612929

Epoch: 6| Step: 5
Training loss: 2.6992165417807086
Validation loss: 3.3041889279357153

Epoch: 6| Step: 6
Training loss: 4.085063775263935
Validation loss: 3.2995572613828488

Epoch: 6| Step: 7
Training loss: 3.062462631309003
Validation loss: 3.2991611548154767

Epoch: 6| Step: 8
Training loss: 3.7027677854641774
Validation loss: 3.2963093918491357

Epoch: 6| Step: 9
Training loss: 3.9861752500849295
Validation loss: 3.297268969389575

Epoch: 6| Step: 10
Training loss: 3.8238447900740766
Validation loss: 3.2970073599315715

Epoch: 6| Step: 11
Training loss: 3.4739520956018697
Validation loss: 3.2962452198960968

Epoch: 6| Step: 12
Training loss: 3.2396642218955165
Validation loss: 3.2959256800198298

Epoch: 6| Step: 13
Training loss: 3.8405527603146843
Validation loss: 3.2983975600217987

Epoch: 41| Step: 0
Training loss: 3.8566290472817584
Validation loss: 3.2965780129370863

Epoch: 6| Step: 1
Training loss: 3.9367159108164747
Validation loss: 3.295209256897915

Epoch: 6| Step: 2
Training loss: 4.1437824230738025
Validation loss: 3.295898056364474

Epoch: 6| Step: 3
Training loss: 3.1390395076777415
Validation loss: 3.2945092122727004

Epoch: 6| Step: 4
Training loss: 3.6410596858169124
Validation loss: 3.294304577464412

Epoch: 6| Step: 5
Training loss: 3.7168570436948687
Validation loss: 3.294209562068491

Epoch: 6| Step: 6
Training loss: 3.4715928808591783
Validation loss: 3.2946175001759954

Epoch: 6| Step: 7
Training loss: 4.003940548633582
Validation loss: 3.2928285060541747

Epoch: 6| Step: 8
Training loss: 2.9440416584384628
Validation loss: 3.2931442065106804

Epoch: 6| Step: 9
Training loss: 3.051157597225268
Validation loss: 3.2926777483229874

Epoch: 6| Step: 10
Training loss: 3.993685148425987
Validation loss: 3.291573675941589

Epoch: 6| Step: 11
Training loss: 3.3204785114748168
Validation loss: 3.2923201699789835

Epoch: 6| Step: 12
Training loss: 2.7146342025132206
Validation loss: 3.2922557949000875

Epoch: 6| Step: 13
Training loss: 3.033908582644144
Validation loss: 3.2927985269661346

Epoch: 42| Step: 0
Training loss: 3.5721099802922796
Validation loss: 3.292434173510737

Epoch: 6| Step: 1
Training loss: 3.7466111447393704
Validation loss: 3.290927488282988

Epoch: 6| Step: 2
Training loss: 3.2037062699053056
Validation loss: 3.292307083575498

Epoch: 6| Step: 3
Training loss: 3.2976857133212034
Validation loss: 3.291518531374702

Epoch: 6| Step: 4
Training loss: 3.0787385435584302
Validation loss: 3.2903498820479764

Epoch: 6| Step: 5
Training loss: 2.7387553850727775
Validation loss: 3.290086180382978

Epoch: 6| Step: 6
Training loss: 3.647631407077334
Validation loss: 3.289877367189917

Epoch: 6| Step: 7
Training loss: 3.0540427383600073
Validation loss: 3.2906654666038793

Epoch: 6| Step: 8
Training loss: 3.9468418292103737
Validation loss: 3.2890760404764876

Epoch: 6| Step: 9
Training loss: 4.261297804815247
Validation loss: 3.2889823082458998

Epoch: 6| Step: 10
Training loss: 3.6146807625398516
Validation loss: 3.2896409261100255

Epoch: 6| Step: 11
Training loss: 4.283225167735688
Validation loss: 3.288706369819859

Epoch: 6| Step: 12
Training loss: 3.322248114573931
Validation loss: 3.288593598942139

Epoch: 6| Step: 13
Training loss: 3.2538857339164147
Validation loss: 3.288525626472652

Epoch: 43| Step: 0
Training loss: 3.6533225313662734
Validation loss: 3.287501677723985

Epoch: 6| Step: 1
Training loss: 3.4363467969752457
Validation loss: 3.287645968265938

Epoch: 6| Step: 2
Training loss: 3.7829089348218883
Validation loss: 3.2864411682884023

Epoch: 6| Step: 3
Training loss: 3.7577472768345688
Validation loss: 3.2872071708024655

Epoch: 6| Step: 4
Training loss: 2.716988705541044
Validation loss: 3.2878343811130133

Epoch: 6| Step: 5
Training loss: 4.208025603169343
Validation loss: 3.286641564224563

Epoch: 6| Step: 6
Training loss: 3.291253816491568
Validation loss: 3.286676536939945

Epoch: 6| Step: 7
Training loss: 3.7914889087859374
Validation loss: 3.2858702742895267

Epoch: 6| Step: 8
Training loss: 3.047467452916752
Validation loss: 3.2860832865574534

Epoch: 6| Step: 9
Training loss: 3.7165737676485766
Validation loss: 3.285158890774369

Epoch: 6| Step: 10
Training loss: 3.2855234564578244
Validation loss: 3.2860290008731745

Epoch: 6| Step: 11
Training loss: 3.6877151685105103
Validation loss: 3.285615236054592

Epoch: 6| Step: 12
Training loss: 3.0710164202316665
Validation loss: 3.2862192765173583

Epoch: 6| Step: 13
Training loss: 3.8947982773066236
Validation loss: 3.2858445634315276

Epoch: 44| Step: 0
Training loss: 3.2814845410037634
Validation loss: 3.283584009943919

Epoch: 6| Step: 1
Training loss: 2.854502210361295
Validation loss: 3.2866369231122747

Epoch: 6| Step: 2
Training loss: 3.6416485702332717
Validation loss: 3.2831519143035233

Epoch: 6| Step: 3
Training loss: 3.1548806420916664
Validation loss: 3.2845190230883277

Epoch: 6| Step: 4
Training loss: 3.1823943892078987
Validation loss: 3.2839585758078846

Epoch: 6| Step: 5
Training loss: 3.7474404819029847
Validation loss: 3.284822824256236

Epoch: 6| Step: 6
Training loss: 3.1282499579929057
Validation loss: 3.2835515573515934

Epoch: 6| Step: 7
Training loss: 3.562879040279653
Validation loss: 3.282799905041967

Epoch: 6| Step: 8
Training loss: 3.8246349384901728
Validation loss: 3.282079901295128

Epoch: 6| Step: 9
Training loss: 4.871674797441969
Validation loss: 3.281441769169713

Epoch: 6| Step: 10
Training loss: 3.4205820088095678
Validation loss: 3.282272868543686

Epoch: 6| Step: 11
Training loss: 2.7173957521153413
Validation loss: 3.28307103938052

Epoch: 6| Step: 12
Training loss: 4.050107158608994
Validation loss: 3.281767261086419

Epoch: 6| Step: 13
Training loss: 3.3686456554438786
Validation loss: 3.2808664217822767

Epoch: 45| Step: 0
Training loss: 3.1553440115617866
Validation loss: 3.281711108051154

Epoch: 6| Step: 1
Training loss: 4.591891373376302
Validation loss: 3.280248837887574

Epoch: 6| Step: 2
Training loss: 4.086595646384748
Validation loss: 3.2808126186398585

Epoch: 6| Step: 3
Training loss: 4.236379901856249
Validation loss: 3.2804264501994425

Epoch: 6| Step: 4
Training loss: 2.9032285016912165
Validation loss: 3.2789416387876456

Epoch: 6| Step: 5
Training loss: 3.2938845120203943
Validation loss: 3.279213336055266

Epoch: 6| Step: 6
Training loss: 2.9144198528374874
Validation loss: 3.279235049287063

Epoch: 6| Step: 7
Training loss: 3.3267088550142576
Validation loss: 3.2786283318190295

Epoch: 6| Step: 8
Training loss: 3.1084809671340548
Validation loss: 3.2796753987848444

Epoch: 6| Step: 9
Training loss: 3.761918265655912
Validation loss: 3.2786625846356605

Epoch: 6| Step: 10
Training loss: 3.138185075231582
Validation loss: 3.280287287791536

Epoch: 6| Step: 11
Training loss: 3.126537707610349
Validation loss: 3.280784471559792

Epoch: 6| Step: 12
Training loss: 3.8022239902902704
Validation loss: 3.2830587469549366

Epoch: 6| Step: 13
Training loss: 3.377708055030377
Validation loss: 3.283848284494694

Epoch: 46| Step: 0
Training loss: 3.2485762191739056
Validation loss: 3.2819113842707384

Epoch: 6| Step: 1
Training loss: 3.789658709939113
Validation loss: 3.277633736883788

Epoch: 6| Step: 2
Training loss: 3.6153973955343717
Validation loss: 3.2781312636724174

Epoch: 6| Step: 3
Training loss: 3.0392736837172354
Validation loss: 3.275805297809311

Epoch: 6| Step: 4
Training loss: 3.327108165160216
Validation loss: 3.2768998318723286

Epoch: 6| Step: 5
Training loss: 3.8903674917527047
Validation loss: 3.277415833379669

Epoch: 6| Step: 6
Training loss: 3.598459889205207
Validation loss: 3.2756462002593087

Epoch: 6| Step: 7
Training loss: 2.9574227521131973
Validation loss: 3.2759745640348763

Epoch: 6| Step: 8
Training loss: 3.477186511325773
Validation loss: 3.274405657723751

Epoch: 6| Step: 9
Training loss: 3.9972499692400216
Validation loss: 3.2758146741097027

Epoch: 6| Step: 10
Training loss: 4.151522134362828
Validation loss: 3.2740783620124687

Epoch: 6| Step: 11
Training loss: 3.3989566099579664
Validation loss: 3.2754340644330533

Epoch: 6| Step: 12
Training loss: 2.8682333886220706
Validation loss: 3.2753105290019247

Epoch: 6| Step: 13
Training loss: 3.8351867314003725
Validation loss: 3.2756990121519736

Epoch: 47| Step: 0
Training loss: 3.479148742873265
Validation loss: 3.27619817396342

Epoch: 6| Step: 1
Training loss: 3.5614204778869483
Validation loss: 3.2758988146592056

Epoch: 6| Step: 2
Training loss: 3.9415401742221685
Validation loss: 3.2752766512773994

Epoch: 6| Step: 3
Training loss: 3.3121887636618674
Validation loss: 3.276839783812785

Epoch: 6| Step: 4
Training loss: 3.311607096545369
Validation loss: 3.27873190706296

Epoch: 6| Step: 5
Training loss: 3.586959792878239
Validation loss: 3.2782500554634555

Epoch: 6| Step: 6
Training loss: 3.3102000187025498
Validation loss: 3.279839511277005

Epoch: 6| Step: 7
Training loss: 4.022735830806334
Validation loss: 3.277918739641093

Epoch: 6| Step: 8
Training loss: 3.532666217756654
Validation loss: 3.274454152242055

Epoch: 6| Step: 9
Training loss: 2.97275730517703
Validation loss: 3.2744947863999543

Epoch: 6| Step: 10
Training loss: 3.2089418767156954
Validation loss: 3.275411389903566

Epoch: 6| Step: 11
Training loss: 4.0750908215471
Validation loss: 3.273221737284894

Epoch: 6| Step: 12
Training loss: 3.2664609870256744
Validation loss: 3.2734076738204068

Epoch: 6| Step: 13
Training loss: 3.5490103188303164
Validation loss: 3.2735378641479396

Epoch: 48| Step: 0
Training loss: 2.7639567198063
Validation loss: 3.271698034757342

Epoch: 6| Step: 1
Training loss: 2.7824830311603104
Validation loss: 3.2719536007106718

Epoch: 6| Step: 2
Training loss: 3.9716159354899974
Validation loss: 3.2695872358546842

Epoch: 6| Step: 3
Training loss: 3.469438914028294
Validation loss: 3.271789482091271

Epoch: 6| Step: 4
Training loss: 4.05421353842655
Validation loss: 3.271020267229728

Epoch: 6| Step: 5
Training loss: 3.795893538353862
Validation loss: 3.2724259194045273

Epoch: 6| Step: 6
Training loss: 2.5465654056282987
Validation loss: 3.2711065045172427

Epoch: 6| Step: 7
Training loss: 3.8949631859896754
Validation loss: 3.2701493982453607

Epoch: 6| Step: 8
Training loss: 3.4973704132875687
Validation loss: 3.2698423913099997

Epoch: 6| Step: 9
Training loss: 3.9835721272885904
Validation loss: 3.2697525328840142

Epoch: 6| Step: 10
Training loss: 3.8107171814918113
Validation loss: 3.2695515753863966

Epoch: 6| Step: 11
Training loss: 3.56450061505179
Validation loss: 3.27242879215591

Epoch: 6| Step: 12
Training loss: 3.5809914380748564
Validation loss: 3.2736452121782773

Epoch: 6| Step: 13
Training loss: 2.6526108889541717
Validation loss: 3.271996654843854

Epoch: 49| Step: 0
Training loss: 3.141419874729531
Validation loss: 3.2700170989409716

Epoch: 6| Step: 1
Training loss: 3.88374167056828
Validation loss: 3.268687651476894

Epoch: 6| Step: 2
Training loss: 3.4869142867707734
Validation loss: 3.268248232808879

Epoch: 6| Step: 3
Training loss: 3.5287186993985316
Validation loss: 3.272215137023329

Epoch: 6| Step: 4
Training loss: 3.1201910019144234
Validation loss: 3.270518706654747

Epoch: 6| Step: 5
Training loss: 4.0938331653795945
Validation loss: 3.269030318905481

Epoch: 6| Step: 6
Training loss: 3.3938324695212576
Validation loss: 3.268605654735636

Epoch: 6| Step: 7
Training loss: 3.611907202845579
Validation loss: 3.2684508195517687

Epoch: 6| Step: 8
Training loss: 3.864943097720923
Validation loss: 3.2694739301929125

Epoch: 6| Step: 9
Training loss: 3.355023497770658
Validation loss: 3.2686538243252854

Epoch: 6| Step: 10
Training loss: 3.6575815759349974
Validation loss: 3.267631302656875

Epoch: 6| Step: 11
Training loss: 3.3349047453629814
Validation loss: 3.267304452719713

Epoch: 6| Step: 12
Training loss: 2.9550234227938454
Validation loss: 3.2676547388378094

Epoch: 6| Step: 13
Training loss: 3.6326236142511297
Validation loss: 3.2676917631421314

Epoch: 50| Step: 0
Training loss: 3.8569162544414177
Validation loss: 3.2654922567492712

Epoch: 6| Step: 1
Training loss: 3.797318546462826
Validation loss: 3.2645840083465507

Epoch: 6| Step: 2
Training loss: 3.6913519961290837
Validation loss: 3.2644944284605795

Epoch: 6| Step: 3
Training loss: 3.8043700287449425
Validation loss: 3.2659432908201005

Epoch: 6| Step: 4
Training loss: 3.6713083682227676
Validation loss: 3.266596447146191

Epoch: 6| Step: 5
Training loss: 3.3372568563410447
Validation loss: 3.2629106854584093

Epoch: 6| Step: 6
Training loss: 3.595355131517402
Validation loss: 3.265575909617255

Epoch: 6| Step: 7
Training loss: 3.2272731192438373
Validation loss: 3.2655718571862176

Epoch: 6| Step: 8
Training loss: 3.6865524108960788
Validation loss: 3.2641424782382793

Epoch: 6| Step: 9
Training loss: 3.1191701296448158
Validation loss: 3.2635976122210066

Epoch: 6| Step: 10
Training loss: 2.826453120454409
Validation loss: 3.262697493722377

Epoch: 6| Step: 11
Training loss: 3.00687193593464
Validation loss: 3.2655716609234475

Epoch: 6| Step: 12
Training loss: 3.5629662994923708
Validation loss: 3.267943387377112

Epoch: 6| Step: 13
Training loss: 3.9754073408130925
Validation loss: 3.266613072409183

Epoch: 51| Step: 0
Training loss: 3.099389225257311
Validation loss: 3.2633727955897083

Epoch: 6| Step: 1
Training loss: 4.122976095585035
Validation loss: 3.262350048101272

Epoch: 6| Step: 2
Training loss: 3.6107148825254294
Validation loss: 3.262506448942638

Epoch: 6| Step: 3
Training loss: 3.5631690484606136
Validation loss: 3.262650779414824

Epoch: 6| Step: 4
Training loss: 3.408831676683872
Validation loss: 3.263007897598522

Epoch: 6| Step: 5
Training loss: 3.5789410189522086
Validation loss: 3.262522343837334

Epoch: 6| Step: 6
Training loss: 3.706864541167171
Validation loss: 3.2624675490279227

Epoch: 6| Step: 7
Training loss: 3.3749183362335033
Validation loss: 3.2621255942290617

Epoch: 6| Step: 8
Training loss: 3.6936893567885654
Validation loss: 3.2607430256038454

Epoch: 6| Step: 9
Training loss: 2.6997909712234316
Validation loss: 3.264562780355849

Epoch: 6| Step: 10
Training loss: 3.0297785068042464
Validation loss: 3.2636722441887778

Epoch: 6| Step: 11
Training loss: 3.84754644711662
Validation loss: 3.2676701238397543

Epoch: 6| Step: 12
Training loss: 3.7115264746425636
Validation loss: 3.264622286230109

Epoch: 6| Step: 13
Training loss: 3.360555042335405
Validation loss: 3.261482730996844

Epoch: 52| Step: 0
Training loss: 3.8011619949565234
Validation loss: 3.2602877816320417

Epoch: 6| Step: 1
Training loss: 3.8239279647171314
Validation loss: 3.258690332030664

Epoch: 6| Step: 2
Training loss: 3.031826947550367
Validation loss: 3.262297813805522

Epoch: 6| Step: 3
Training loss: 3.4701963966043565
Validation loss: 3.259765530626074

Epoch: 6| Step: 4
Training loss: 3.237691754292398
Validation loss: 3.2566883139120124

Epoch: 6| Step: 5
Training loss: 3.99466791006849
Validation loss: 3.2579683789990637

Epoch: 6| Step: 6
Training loss: 2.676610664963142
Validation loss: 3.2570327144643487

Epoch: 6| Step: 7
Training loss: 3.6088763796720555
Validation loss: 3.258138505003559

Epoch: 6| Step: 8
Training loss: 3.2142772523072285
Validation loss: 3.2588125182170278

Epoch: 6| Step: 9
Training loss: 4.041532665010718
Validation loss: 3.258950207801412

Epoch: 6| Step: 10
Training loss: 3.44738430434875
Validation loss: 3.259881526702502

Epoch: 6| Step: 11
Training loss: 2.6683640640970365
Validation loss: 3.263398371619887

Epoch: 6| Step: 12
Training loss: 4.079265332741574
Validation loss: 3.263142588155912

Epoch: 6| Step: 13
Training loss: 3.6797460725500155
Validation loss: 3.264237506488185

Epoch: 53| Step: 0
Training loss: 4.363629415174212
Validation loss: 3.2599369422027595

Epoch: 6| Step: 1
Training loss: 3.7619910215912533
Validation loss: 3.2580277692553503

Epoch: 6| Step: 2
Training loss: 3.105059058077703
Validation loss: 3.2593777581241787

Epoch: 6| Step: 3
Training loss: 3.6524288718356117
Validation loss: 3.257269746943733

Epoch: 6| Step: 4
Training loss: 3.848734531253803
Validation loss: 3.2555491888286

Epoch: 6| Step: 5
Training loss: 3.2117191300778174
Validation loss: 3.254929126340727

Epoch: 6| Step: 6
Training loss: 3.1841589677510105
Validation loss: 3.2548927822947165

Epoch: 6| Step: 7
Training loss: 3.250280221449273
Validation loss: 3.2561101397534986

Epoch: 6| Step: 8
Training loss: 3.4666887637192167
Validation loss: 3.2571598616137223

Epoch: 6| Step: 9
Training loss: 2.757202945593762
Validation loss: 3.2552669528072067

Epoch: 6| Step: 10
Training loss: 3.047532543731492
Validation loss: 3.25368501455993

Epoch: 6| Step: 11
Training loss: 3.66985301084605
Validation loss: 3.2546944061505814

Epoch: 6| Step: 12
Training loss: 3.7317454764690825
Validation loss: 3.253202551670468

Epoch: 6| Step: 13
Training loss: 3.792333704924238
Validation loss: 3.2527054284767796

Epoch: 54| Step: 0
Training loss: 2.854827433112475
Validation loss: 3.254118448363728

Epoch: 6| Step: 1
Training loss: 2.806746468243883
Validation loss: 3.2563483171671757

Epoch: 6| Step: 2
Training loss: 3.7909758780438256
Validation loss: 3.253214443111555

Epoch: 6| Step: 3
Training loss: 3.544009492176855
Validation loss: 3.2561217568206353

Epoch: 6| Step: 4
Training loss: 3.9925808050282683
Validation loss: 3.2536125803488973

Epoch: 6| Step: 5
Training loss: 3.505143473432742
Validation loss: 3.2549649611853697

Epoch: 6| Step: 6
Training loss: 3.7282608608613828
Validation loss: 3.2547175936375714

Epoch: 6| Step: 7
Training loss: 2.9232853224439137
Validation loss: 3.2531023087982414

Epoch: 6| Step: 8
Training loss: 3.402657390376554
Validation loss: 3.2528109798233356

Epoch: 6| Step: 9
Training loss: 3.173753154162612
Validation loss: 3.2530835812804324

Epoch: 6| Step: 10
Training loss: 4.2197664519854365
Validation loss: 3.2512816575276036

Epoch: 6| Step: 11
Training loss: 4.522004475351352
Validation loss: 3.253504152154023

Epoch: 6| Step: 12
Training loss: 2.7906879208638276
Validation loss: 3.25113548497791

Epoch: 6| Step: 13
Training loss: 2.882452882909343
Validation loss: 3.2521361547616983

Epoch: 55| Step: 0
Training loss: 2.9569604580466846
Validation loss: 3.251699476577701

Epoch: 6| Step: 1
Training loss: 3.185135207248218
Validation loss: 3.251483307392393

Epoch: 6| Step: 2
Training loss: 3.411938877573406
Validation loss: 3.251760072455252

Epoch: 6| Step: 3
Training loss: 4.099770814025957
Validation loss: 3.250001973608284

Epoch: 6| Step: 4
Training loss: 3.2275643259695825
Validation loss: 3.250367163592267

Epoch: 6| Step: 5
Training loss: 3.260219352691032
Validation loss: 3.2507905274730944

Epoch: 6| Step: 6
Training loss: 3.2676202984520644
Validation loss: 3.2485752058945896

Epoch: 6| Step: 7
Training loss: 3.5660422934325675
Validation loss: 3.2494988437645085

Epoch: 6| Step: 8
Training loss: 3.982394096273887
Validation loss: 3.24791116060784

Epoch: 6| Step: 9
Training loss: 3.535194556940243
Validation loss: 3.2477333851338708

Epoch: 6| Step: 10
Training loss: 3.921907827536291
Validation loss: 3.2460677604167474

Epoch: 6| Step: 11
Training loss: 3.5883719630686164
Validation loss: 3.245221740656494

Epoch: 6| Step: 12
Training loss: 3.3643038764535103
Validation loss: 3.244389271511685

Epoch: 6| Step: 13
Training loss: 3.251212700758554
Validation loss: 3.2420059313380047

Epoch: 56| Step: 0
Training loss: 3.381368773907432
Validation loss: 3.241097557365887

Epoch: 6| Step: 1
Training loss: 3.7010657141767016
Validation loss: 3.2378894286781907

Epoch: 6| Step: 2
Training loss: 4.098221528052524
Validation loss: 3.2343225881594178

Epoch: 6| Step: 3
Training loss: 2.8595976195677255
Validation loss: 3.2335293301201142

Epoch: 6| Step: 4
Training loss: 2.970722707549691
Validation loss: 3.2334569010725662

Epoch: 6| Step: 5
Training loss: 3.7122052727537236
Validation loss: 3.2316991671443147

Epoch: 6| Step: 6
Training loss: 3.283763249969179
Validation loss: 3.232366712690804

Epoch: 6| Step: 7
Training loss: 2.9345218901995023
Validation loss: 3.2324590173449996

Epoch: 6| Step: 8
Training loss: 3.6348669006242726
Validation loss: 3.230603606859126

Epoch: 6| Step: 9
Training loss: 3.1982655950956387
Validation loss: 3.23370660057227

Epoch: 6| Step: 10
Training loss: 3.2123185874687867
Validation loss: 3.2339568832637977

Epoch: 6| Step: 11
Training loss: 4.1735178252401965
Validation loss: 3.2340123926096846

Epoch: 6| Step: 12
Training loss: 3.2184371055442034
Validation loss: 3.230835192513077

Epoch: 6| Step: 13
Training loss: 4.383463275757765
Validation loss: 3.235054992876824

Epoch: 57| Step: 0
Training loss: 3.0809022409294426
Validation loss: 3.230538219388377

Epoch: 6| Step: 1
Training loss: 4.271471648857928
Validation loss: 3.225569115080682

Epoch: 6| Step: 2
Training loss: 2.885406898087217
Validation loss: 3.2275075523870362

Epoch: 6| Step: 3
Training loss: 3.9377260900104174
Validation loss: 3.226609582648605

Epoch: 6| Step: 4
Training loss: 2.711811111798349
Validation loss: 3.226719195842507

Epoch: 6| Step: 5
Training loss: 3.3866845363485916
Validation loss: 3.2279853785126846

Epoch: 6| Step: 6
Training loss: 3.3883262611937064
Validation loss: 3.2263855839333604

Epoch: 6| Step: 7
Training loss: 3.0375622966641727
Validation loss: 3.2255525135255794

Epoch: 6| Step: 8
Training loss: 3.4594387141617373
Validation loss: 3.2248354670227246

Epoch: 6| Step: 9
Training loss: 3.3799609704557536
Validation loss: 3.2253029601110965

Epoch: 6| Step: 10
Training loss: 3.166256593621305
Validation loss: 3.2264773223438956

Epoch: 6| Step: 11
Training loss: 4.297147541072577
Validation loss: 3.2242663135970684

Epoch: 6| Step: 12
Training loss: 4.119076724255417
Validation loss: 3.2244106797540177

Epoch: 6| Step: 13
Training loss: 2.5847620756053726
Validation loss: 3.223374388905276

Epoch: 58| Step: 0
Training loss: 3.9761259967328164
Validation loss: 3.2260550907663665

Epoch: 6| Step: 1
Training loss: 3.334154282247903
Validation loss: 3.2214089114063773

Epoch: 6| Step: 2
Training loss: 3.0641962141850314
Validation loss: 3.224809603433791

Epoch: 6| Step: 3
Training loss: 3.828578128076804
Validation loss: 3.2267679128582354

Epoch: 6| Step: 4
Training loss: 3.5104118520701793
Validation loss: 3.2238914125895453

Epoch: 6| Step: 5
Training loss: 3.724021957316339
Validation loss: 3.227211938073624

Epoch: 6| Step: 6
Training loss: 4.096048656144829
Validation loss: 3.2245453415713916

Epoch: 6| Step: 7
Training loss: 2.785080147622402
Validation loss: 3.223107909530623

Epoch: 6| Step: 8
Training loss: 2.542942966969188
Validation loss: 3.2237657509390485

Epoch: 6| Step: 9
Training loss: 4.39582207604484
Validation loss: 3.220744461977034

Epoch: 6| Step: 10
Training loss: 4.296066596539711
Validation loss: 3.2192675943645006

Epoch: 6| Step: 11
Training loss: 2.7345671667965443
Validation loss: 3.218896932779613

Epoch: 6| Step: 12
Training loss: 2.7979936120953557
Validation loss: 3.2191143966583007

Epoch: 6| Step: 13
Training loss: 1.948737931816704
Validation loss: 3.222905756992122

Epoch: 59| Step: 0
Training loss: 2.7654268872699292
Validation loss: 3.2338874199309915

Epoch: 6| Step: 1
Training loss: 4.294951185097806
Validation loss: 3.224413847321766

Epoch: 6| Step: 2
Training loss: 3.374703429578644
Validation loss: 3.226587842624104

Epoch: 6| Step: 3
Training loss: 3.2770926159927103
Validation loss: 3.221555621851297

Epoch: 6| Step: 4
Training loss: 2.3253126118827456
Validation loss: 3.2192372710797756

Epoch: 6| Step: 5
Training loss: 3.6520153856820348
Validation loss: 3.21921342587379

Epoch: 6| Step: 6
Training loss: 3.7653618558374315
Validation loss: 3.2166569666009837

Epoch: 6| Step: 7
Training loss: 3.6548112173941405
Validation loss: 3.2171734266972325

Epoch: 6| Step: 8
Training loss: 3.405505317689437
Validation loss: 3.2175958899795063

Epoch: 6| Step: 9
Training loss: 2.843941482972063
Validation loss: 3.2174415417835207

Epoch: 6| Step: 10
Training loss: 3.629613374239736
Validation loss: 3.217863332513595

Epoch: 6| Step: 11
Training loss: 4.202596070997297
Validation loss: 3.219973229666593

Epoch: 6| Step: 12
Training loss: 3.542926220286358
Validation loss: 3.220173198643345

Epoch: 6| Step: 13
Training loss: 3.2325376737660605
Validation loss: 3.217943384556691

Epoch: 60| Step: 0
Training loss: 2.315695230548993
Validation loss: 3.2173366850685956

Epoch: 6| Step: 1
Training loss: 3.269759631640536
Validation loss: 3.2166293970348705

Epoch: 6| Step: 2
Training loss: 4.075196833625106
Validation loss: 3.2164856412551615

Epoch: 6| Step: 3
Training loss: 2.7325599968161636
Validation loss: 3.2160553461326526

Epoch: 6| Step: 4
Training loss: 3.326843301470489
Validation loss: 3.2175831832807837

Epoch: 6| Step: 5
Training loss: 3.096942679919588
Validation loss: 3.2146609395691885

Epoch: 6| Step: 6
Training loss: 3.575459249382398
Validation loss: 3.2157845883328817

Epoch: 6| Step: 7
Training loss: 3.990987996893152
Validation loss: 3.2144380274890105

Epoch: 6| Step: 8
Training loss: 3.8293521082115904
Validation loss: 3.215915601577952

Epoch: 6| Step: 9
Training loss: 3.81580959563999
Validation loss: 3.2153640238559134

Epoch: 6| Step: 10
Training loss: 3.644262633078876
Validation loss: 3.2151946724295706

Epoch: 6| Step: 11
Training loss: 3.120511302622524
Validation loss: 3.2142868184577544

Epoch: 6| Step: 12
Training loss: 3.8250391141599476
Validation loss: 3.212649627931858

Epoch: 6| Step: 13
Training loss: 3.417845421882163
Validation loss: 3.214102043312083

Epoch: 61| Step: 0
Training loss: 3.539929551107852
Validation loss: 3.213220546198055

Epoch: 6| Step: 1
Training loss: 3.3419875018686835
Validation loss: 3.212471964015396

Epoch: 6| Step: 2
Training loss: 3.767989306756658
Validation loss: 3.212916372289348

Epoch: 6| Step: 3
Training loss: 3.1621244546814617
Validation loss: 3.2116396556705027

Epoch: 6| Step: 4
Training loss: 3.052380405242057
Validation loss: 3.212040392135545

Epoch: 6| Step: 5
Training loss: 3.3064603626846765
Validation loss: 3.2112898583739224

Epoch: 6| Step: 6
Training loss: 3.8972940545423054
Validation loss: 3.2116344240392456

Epoch: 6| Step: 7
Training loss: 3.326347628669158
Validation loss: 3.2119809824357395

Epoch: 6| Step: 8
Training loss: 3.3731184058896253
Validation loss: 3.212073369292461

Epoch: 6| Step: 9
Training loss: 3.577203357055208
Validation loss: 3.2100206856720295

Epoch: 6| Step: 10
Training loss: 2.9955522627329754
Validation loss: 3.2108311238432754

Epoch: 6| Step: 11
Training loss: 3.6664255814334283
Validation loss: 3.209347847512955

Epoch: 6| Step: 12
Training loss: 3.742057909543419
Validation loss: 3.209506950194512

Epoch: 6| Step: 13
Training loss: 3.6785537042071748
Validation loss: 3.2099733037985034

Epoch: 62| Step: 0
Training loss: 3.252329798239427
Validation loss: 3.2095876803204706

Epoch: 6| Step: 1
Training loss: 3.415606745246207
Validation loss: 3.2111693910483723

Epoch: 6| Step: 2
Training loss: 2.732232611470402
Validation loss: 3.212675537545971

Epoch: 6| Step: 3
Training loss: 3.571093985007376
Validation loss: 3.210497650438713

Epoch: 6| Step: 4
Training loss: 3.6327317751867754
Validation loss: 3.211349395017278

Epoch: 6| Step: 5
Training loss: 3.382778669721138
Validation loss: 3.2115998203435616

Epoch: 6| Step: 6
Training loss: 3.5015320830617758
Validation loss: 3.208393774487398

Epoch: 6| Step: 7
Training loss: 3.5655325313416597
Validation loss: 3.208417876692771

Epoch: 6| Step: 8
Training loss: 3.4961537617056093
Validation loss: 3.2072591950539895

Epoch: 6| Step: 9
Training loss: 4.263313086140752
Validation loss: 3.2076323667312403

Epoch: 6| Step: 10
Training loss: 3.902232553236177
Validation loss: 3.211445771500917

Epoch: 6| Step: 11
Training loss: 3.6312378454743603
Validation loss: 3.206794267871405

Epoch: 6| Step: 12
Training loss: 2.429161677238178
Validation loss: 3.2096586879246103

Epoch: 6| Step: 13
Training loss: 3.116144067805332
Validation loss: 3.2059528848588577

Epoch: 63| Step: 0
Training loss: 2.6187838568126223
Validation loss: 3.2046872806813487

Epoch: 6| Step: 1
Training loss: 3.8438821165128063
Validation loss: 3.2064343076591237

Epoch: 6| Step: 2
Training loss: 3.1105154428471224
Validation loss: 3.2056952728174815

Epoch: 6| Step: 3
Training loss: 3.4268948736037186
Validation loss: 3.2062660397428218

Epoch: 6| Step: 4
Training loss: 3.6060027515402995
Validation loss: 3.2056733797616177

Epoch: 6| Step: 5
Training loss: 4.083028249956325
Validation loss: 3.2107417657228723

Epoch: 6| Step: 6
Training loss: 3.4103194259982903
Validation loss: 3.208636435893923

Epoch: 6| Step: 7
Training loss: 3.7523510238891475
Validation loss: 3.215736078022253

Epoch: 6| Step: 8
Training loss: 2.8747674599188713
Validation loss: 3.2096388123436546

Epoch: 6| Step: 9
Training loss: 3.89665741117981
Validation loss: 3.2090263342735375

Epoch: 6| Step: 10
Training loss: 3.2375092730886443
Validation loss: 3.205651891217217

Epoch: 6| Step: 11
Training loss: 3.4438800212594627
Validation loss: 3.2051553225667715

Epoch: 6| Step: 12
Training loss: 3.4344975624048053
Validation loss: 3.2036708371715044

Epoch: 6| Step: 13
Training loss: 3.3089229055204252
Validation loss: 3.209266241434119

Epoch: 64| Step: 0
Training loss: 3.8095504107000657
Validation loss: 3.210857383471647

Epoch: 6| Step: 1
Training loss: 3.4821808753540706
Validation loss: 3.219504808187622

Epoch: 6| Step: 2
Training loss: 3.207359232143876
Validation loss: 3.2151655099596796

Epoch: 6| Step: 3
Training loss: 2.7194694356405362
Validation loss: 3.210980113986508

Epoch: 6| Step: 4
Training loss: 3.8606657888966676
Validation loss: 3.204276772672098

Epoch: 6| Step: 5
Training loss: 3.8354122633583256
Validation loss: 3.2032867030664174

Epoch: 6| Step: 6
Training loss: 3.4420525661623906
Validation loss: 3.2033468446259565

Epoch: 6| Step: 7
Training loss: 3.8404464791929986
Validation loss: 3.2026590147898433

Epoch: 6| Step: 8
Training loss: 3.680490717926572
Validation loss: 3.2054655450284733

Epoch: 6| Step: 9
Training loss: 3.1096501060969275
Validation loss: 3.205293106412195

Epoch: 6| Step: 10
Training loss: 3.426363574723413
Validation loss: 3.2086382056371003

Epoch: 6| Step: 11
Training loss: 3.3063928699452525
Validation loss: 3.2082068955483654

Epoch: 6| Step: 12
Training loss: 3.2209118740150124
Validation loss: 3.2051663044762524

Epoch: 6| Step: 13
Training loss: 3.0774540048814125
Validation loss: 3.204165125980282

Epoch: 65| Step: 0
Training loss: 3.90765526480767
Validation loss: 3.204280797013693

Epoch: 6| Step: 1
Training loss: 3.38913057504244
Validation loss: 3.2041992339036627

Epoch: 6| Step: 2
Training loss: 2.619984148865717
Validation loss: 3.2048721634736337

Epoch: 6| Step: 3
Training loss: 2.9809395554488765
Validation loss: 3.2044813708359228

Epoch: 6| Step: 4
Training loss: 4.378531638191121
Validation loss: 3.2046395911576586

Epoch: 6| Step: 5
Training loss: 3.5117980472832353
Validation loss: 3.207701937475166

Epoch: 6| Step: 6
Training loss: 3.0000804254559745
Validation loss: 3.2125891027251123

Epoch: 6| Step: 7
Training loss: 3.252344606222113
Validation loss: 3.2113131948131937

Epoch: 6| Step: 8
Training loss: 3.381324352638561
Validation loss: 3.210725783759072

Epoch: 6| Step: 9
Training loss: 3.3619894100932415
Validation loss: 3.20378217701078

Epoch: 6| Step: 10
Training loss: 4.017867000507191
Validation loss: 3.202848653930474

Epoch: 6| Step: 11
Training loss: 3.9625526159986957
Validation loss: 3.201549407636419

Epoch: 6| Step: 12
Training loss: 3.43254522950893
Validation loss: 3.1990994404601194

Epoch: 6| Step: 13
Training loss: 1.631400341837619
Validation loss: 3.19893014800007

Epoch: 66| Step: 0
Training loss: 4.177363639172074
Validation loss: 3.200045077585798

Epoch: 6| Step: 1
Training loss: 2.7877298371539694
Validation loss: 3.1999293591921294

Epoch: 6| Step: 2
Training loss: 3.0693252179756336
Validation loss: 3.2012998313642065

Epoch: 6| Step: 3
Training loss: 3.1863091432118953
Validation loss: 3.2007010079178233

Epoch: 6| Step: 4
Training loss: 3.800127559327856
Validation loss: 3.1978066364575284

Epoch: 6| Step: 5
Training loss: 2.86621376570346
Validation loss: 3.197176403322947

Epoch: 6| Step: 6
Training loss: 3.903986893256652
Validation loss: 3.198983777615386

Epoch: 6| Step: 7
Training loss: 3.3708549759731534
Validation loss: 3.1957379318235737

Epoch: 6| Step: 8
Training loss: 3.142182983820101
Validation loss: 3.199415724491657

Epoch: 6| Step: 9
Training loss: 3.5387579847951134
Validation loss: 3.1941298146316566

Epoch: 6| Step: 10
Training loss: 3.714105221795928
Validation loss: 3.196947301518697

Epoch: 6| Step: 11
Training loss: 3.546308833573102
Validation loss: 3.1969294013967757

Epoch: 6| Step: 12
Training loss: 3.5305062920266197
Validation loss: 3.194607213138648

Epoch: 6| Step: 13
Training loss: 3.309744786683486
Validation loss: 3.1958503381818164

Epoch: 67| Step: 0
Training loss: 3.1248658723657052
Validation loss: 3.195281158292753

Epoch: 6| Step: 1
Training loss: 3.1699110443437895
Validation loss: 3.194661519589036

Epoch: 6| Step: 2
Training loss: 3.628838052919811
Validation loss: 3.199069166417068

Epoch: 6| Step: 3
Training loss: 2.9292626645096935
Validation loss: 3.201857980990043

Epoch: 6| Step: 4
Training loss: 3.099476302426621
Validation loss: 3.199887170071473

Epoch: 6| Step: 5
Training loss: 2.897282701956043
Validation loss: 3.203715707578604

Epoch: 6| Step: 6
Training loss: 3.360752550726452
Validation loss: 3.200807247387527

Epoch: 6| Step: 7
Training loss: 3.512741466109775
Validation loss: 3.198735224183617

Epoch: 6| Step: 8
Training loss: 4.235016383620168
Validation loss: 3.1988451818466297

Epoch: 6| Step: 9
Training loss: 3.6549534251197953
Validation loss: 3.1981075660511435

Epoch: 6| Step: 10
Training loss: 3.553580646270167
Validation loss: 3.1943975645503992

Epoch: 6| Step: 11
Training loss: 4.168462493453212
Validation loss: 3.1927044143148176

Epoch: 6| Step: 12
Training loss: 3.366047464844115
Validation loss: 3.193258299615158

Epoch: 6| Step: 13
Training loss: 3.0863148132662865
Validation loss: 3.1909557191255957

Epoch: 68| Step: 0
Training loss: 3.4961736744530407
Validation loss: 3.1934650270324463

Epoch: 6| Step: 1
Training loss: 3.571734456178351
Validation loss: 3.193667438458485

Epoch: 6| Step: 2
Training loss: 3.010679627299674
Validation loss: 3.1920830008620067

Epoch: 6| Step: 3
Training loss: 3.9201520197449176
Validation loss: 3.1911949635721553

Epoch: 6| Step: 4
Training loss: 3.3641945975555827
Validation loss: 3.1946883422517782

Epoch: 6| Step: 5
Training loss: 2.6328719044670654
Validation loss: 3.1914899618790713

Epoch: 6| Step: 6
Training loss: 3.247857487995602
Validation loss: 3.1917452883449973

Epoch: 6| Step: 7
Training loss: 3.7582220857540616
Validation loss: 3.191777188460286

Epoch: 6| Step: 8
Training loss: 3.6680208797630147
Validation loss: 3.1918095990878426

Epoch: 6| Step: 9
Training loss: 3.387193199988429
Validation loss: 3.192712425520119

Epoch: 6| Step: 10
Training loss: 3.233600320968348
Validation loss: 3.1896425333661353

Epoch: 6| Step: 11
Training loss: 3.58902967850687
Validation loss: 3.1899531602141833

Epoch: 6| Step: 12
Training loss: 3.40906849015696
Validation loss: 3.188792017314912

Epoch: 6| Step: 13
Training loss: 3.9334668287694745
Validation loss: 3.190084014420418

Epoch: 69| Step: 0
Training loss: 3.025453038615405
Validation loss: 3.190893684949652

Epoch: 6| Step: 1
Training loss: 3.8599714675402215
Validation loss: 3.192094328112382

Epoch: 6| Step: 2
Training loss: 3.0010154912765503
Validation loss: 3.1927518260327172

Epoch: 6| Step: 3
Training loss: 3.5945084808033063
Validation loss: 3.1954377177396744

Epoch: 6| Step: 4
Training loss: 3.147567439489234
Validation loss: 3.192438271402795

Epoch: 6| Step: 5
Training loss: 3.6346099016631848
Validation loss: 3.1933568172664737

Epoch: 6| Step: 6
Training loss: 4.127580933450321
Validation loss: 3.193386798655717

Epoch: 6| Step: 7
Training loss: 3.5194114808630803
Validation loss: 3.195752135654171

Epoch: 6| Step: 8
Training loss: 2.8491103406636196
Validation loss: 3.1961510990431647

Epoch: 6| Step: 9
Training loss: 3.9692320042871545
Validation loss: 3.1987229186280546

Epoch: 6| Step: 10
Training loss: 2.8109379987308043
Validation loss: 3.194235418708824

Epoch: 6| Step: 11
Training loss: 2.5140191870467805
Validation loss: 3.1933516793147176

Epoch: 6| Step: 12
Training loss: 3.8931906945954835
Validation loss: 3.1903907187441525

Epoch: 6| Step: 13
Training loss: 3.896485843514761
Validation loss: 3.186938948036703

Epoch: 70| Step: 0
Training loss: 3.600177490309465
Validation loss: 3.1886222628299237

Epoch: 6| Step: 1
Training loss: 3.886267493040825
Validation loss: 3.1884462864905783

Epoch: 6| Step: 2
Training loss: 3.2367026389179343
Validation loss: 3.1871281406328276

Epoch: 6| Step: 3
Training loss: 3.99988150421103
Validation loss: 3.1898647402162714

Epoch: 6| Step: 4
Training loss: 3.086113338048089
Validation loss: 3.1898855571500526

Epoch: 6| Step: 5
Training loss: 3.3644127266129398
Validation loss: 3.1918938537742614

Epoch: 6| Step: 6
Training loss: 2.4950525921188444
Validation loss: 3.1909214857099495

Epoch: 6| Step: 7
Training loss: 3.4991429505737264
Validation loss: 3.1881614688791386

Epoch: 6| Step: 8
Training loss: 3.696778859349924
Validation loss: 3.1866451969505576

Epoch: 6| Step: 9
Training loss: 4.151310100355839
Validation loss: 3.1849176127087606

Epoch: 6| Step: 10
Training loss: 3.713799266610378
Validation loss: 3.1851262811547763

Epoch: 6| Step: 11
Training loss: 2.9454878291958564
Validation loss: 3.1842748422111473

Epoch: 6| Step: 12
Training loss: 2.9553233849808134
Validation loss: 3.1853840894999745

Epoch: 6| Step: 13
Training loss: 2.8395725629737067
Validation loss: 3.18361431321283

Epoch: 71| Step: 0
Training loss: 3.761444810694929
Validation loss: 3.1835668483563593

Epoch: 6| Step: 1
Training loss: 3.8035694022528244
Validation loss: 3.1855462488869057

Epoch: 6| Step: 2
Training loss: 2.9544978104597943
Validation loss: 3.1848094594659218

Epoch: 6| Step: 3
Training loss: 4.049529041175315
Validation loss: 3.192454006840783

Epoch: 6| Step: 4
Training loss: 3.2789358061811957
Validation loss: 3.190192738605768

Epoch: 6| Step: 5
Training loss: 2.5818323471398745
Validation loss: 3.1914919282930088

Epoch: 6| Step: 6
Training loss: 3.767427131945493
Validation loss: 3.1898479464083525

Epoch: 6| Step: 7
Training loss: 3.42398786416978
Validation loss: 3.1931663719533496

Epoch: 6| Step: 8
Training loss: 3.765183798874451
Validation loss: 3.1914641863216096

Epoch: 6| Step: 9
Training loss: 3.3632849362095074
Validation loss: 3.1836591852638914

Epoch: 6| Step: 10
Training loss: 2.723169264767428
Validation loss: 3.183096140309123

Epoch: 6| Step: 11
Training loss: 3.6649001085269646
Validation loss: 3.182455368642201

Epoch: 6| Step: 12
Training loss: 3.190993843840157
Validation loss: 3.1819378449192444

Epoch: 6| Step: 13
Training loss: 3.50301013659536
Validation loss: 3.18228182817912

Epoch: 72| Step: 0
Training loss: 3.4360373419618777
Validation loss: 3.183353145065039

Epoch: 6| Step: 1
Training loss: 3.4882550041005906
Validation loss: 3.1829758946010944

Epoch: 6| Step: 2
Training loss: 3.150922149829651
Validation loss: 3.1806897466467845

Epoch: 6| Step: 3
Training loss: 4.484095548103484
Validation loss: 3.181835643705479

Epoch: 6| Step: 4
Training loss: 3.299318104430616
Validation loss: 3.1797206740170476

Epoch: 6| Step: 5
Training loss: 3.208996262531238
Validation loss: 3.1819944276967216

Epoch: 6| Step: 6
Training loss: 2.8241630327102487
Validation loss: 3.178483621275967

Epoch: 6| Step: 7
Training loss: 3.703377888088444
Validation loss: 3.179218756858698

Epoch: 6| Step: 8
Training loss: 3.2291187569950637
Validation loss: 3.1816251446898347

Epoch: 6| Step: 9
Training loss: 3.73249035128185
Validation loss: 3.17884705781351

Epoch: 6| Step: 10
Training loss: 3.269704652333108
Validation loss: 3.1793198455725435

Epoch: 6| Step: 11
Training loss: 2.555314479965669
Validation loss: 3.1814085945535635

Epoch: 6| Step: 12
Training loss: 3.916183171291087
Validation loss: 3.178709826138356

Epoch: 6| Step: 13
Training loss: 3.2634001093089244
Validation loss: 3.179852184715162

Epoch: 73| Step: 0
Training loss: 3.2865789827588365
Validation loss: 3.1780018565842756

Epoch: 6| Step: 1
Training loss: 3.503430728689742
Validation loss: 3.1788244895134623

Epoch: 6| Step: 2
Training loss: 2.6146314294857014
Validation loss: 3.1844100387799728

Epoch: 6| Step: 3
Training loss: 3.9733930446524517
Validation loss: 3.176291765396861

Epoch: 6| Step: 4
Training loss: 2.4873672794993062
Validation loss: 3.1792128251630363

Epoch: 6| Step: 5
Training loss: 3.4335104245435484
Validation loss: 3.18018331978203

Epoch: 6| Step: 6
Training loss: 3.5435925053444146
Validation loss: 3.177242860196548

Epoch: 6| Step: 7
Training loss: 2.965311086459149
Validation loss: 3.1771856965604472

Epoch: 6| Step: 8
Training loss: 3.162732709080379
Validation loss: 3.177600622537276

Epoch: 6| Step: 9
Training loss: 3.043975076049546
Validation loss: 3.1764377679808664

Epoch: 6| Step: 10
Training loss: 4.116427443705524
Validation loss: 3.1769725089645484

Epoch: 6| Step: 11
Training loss: 2.9833805364642982
Validation loss: 3.1766433634426914

Epoch: 6| Step: 12
Training loss: 4.23048295206238
Validation loss: 3.1763148408020645

Epoch: 6| Step: 13
Training loss: 4.492720331850694
Validation loss: 3.176880885545825

Epoch: 74| Step: 0
Training loss: 3.9446953319105242
Validation loss: 3.1757923044244074

Epoch: 6| Step: 1
Training loss: 3.3953672373924166
Validation loss: 3.1763882903392386

Epoch: 6| Step: 2
Training loss: 3.5170260879985107
Validation loss: 3.1765856265096652

Epoch: 6| Step: 3
Training loss: 2.9767371098924964
Validation loss: 3.176252311634707

Epoch: 6| Step: 4
Training loss: 3.270497169146984
Validation loss: 3.1726955223608773

Epoch: 6| Step: 5
Training loss: 3.6161250949759256
Validation loss: 3.1753613971768555

Epoch: 6| Step: 6
Training loss: 3.7437935649903538
Validation loss: 3.173439355001856

Epoch: 6| Step: 7
Training loss: 3.4560217121466557
Validation loss: 3.173672930965789

Epoch: 6| Step: 8
Training loss: 2.7732985770664134
Validation loss: 3.174160935236209

Epoch: 6| Step: 9
Training loss: 2.703766674990297
Validation loss: 3.174885621746674

Epoch: 6| Step: 10
Training loss: 3.6610852734726995
Validation loss: 3.17405507194958

Epoch: 6| Step: 11
Training loss: 2.9561892158437026
Validation loss: 3.1723628137542925

Epoch: 6| Step: 12
Training loss: 3.523988803269853
Validation loss: 3.1735068915701783

Epoch: 6| Step: 13
Training loss: 4.5354817591516845
Validation loss: 3.1730923367800083

Epoch: 75| Step: 0
Training loss: 2.956740331008079
Validation loss: 3.174355644617047

Epoch: 6| Step: 1
Training loss: 3.0605819300900046
Validation loss: 3.1716608766984864

Epoch: 6| Step: 2
Training loss: 2.864347043551266
Validation loss: 3.1716205618735573

Epoch: 6| Step: 3
Training loss: 3.0279250638953927
Validation loss: 3.1721810185632116

Epoch: 6| Step: 4
Training loss: 3.5288128840281967
Validation loss: 3.173358765180761

Epoch: 6| Step: 5
Training loss: 3.9563689058824627
Validation loss: 3.1720307248939394

Epoch: 6| Step: 6
Training loss: 3.4959355323835752
Validation loss: 3.1737195130751608

Epoch: 6| Step: 7
Training loss: 3.1559636958733237
Validation loss: 3.169580414932505

Epoch: 6| Step: 8
Training loss: 2.8715452916078776
Validation loss: 3.1686929319839408

Epoch: 6| Step: 9
Training loss: 3.7448364311729603
Validation loss: 3.170057662667675

Epoch: 6| Step: 10
Training loss: 3.227431653611793
Validation loss: 3.169417558385686

Epoch: 6| Step: 11
Training loss: 3.928471705174226
Validation loss: 3.1673211728517288

Epoch: 6| Step: 12
Training loss: 4.346114359053689
Validation loss: 3.1686834037520146

Epoch: 6| Step: 13
Training loss: 3.256290510222159
Validation loss: 3.1684079447994598

Epoch: 76| Step: 0
Training loss: 3.3349359156729697
Validation loss: 3.1685602315626005

Epoch: 6| Step: 1
Training loss: 3.3241497530203676
Validation loss: 3.166874992586115

Epoch: 6| Step: 2
Training loss: 3.010897236165334
Validation loss: 3.1671719606703124

Epoch: 6| Step: 3
Training loss: 2.9452161697298194
Validation loss: 3.1688609597538604

Epoch: 6| Step: 4
Training loss: 3.740589541312592
Validation loss: 3.1703883312565995

Epoch: 6| Step: 5
Training loss: 3.5740023521411333
Validation loss: 3.171126265116423

Epoch: 6| Step: 6
Training loss: 3.9334927709776584
Validation loss: 3.177154503638267

Epoch: 6| Step: 7
Training loss: 3.74769546904966
Validation loss: 3.1742677803035946

Epoch: 6| Step: 8
Training loss: 3.377059590661947
Validation loss: 3.171099145333321

Epoch: 6| Step: 9
Training loss: 3.308265570676061
Validation loss: 3.171172380988466

Epoch: 6| Step: 10
Training loss: 3.416448322545652
Validation loss: 3.1694370892537136

Epoch: 6| Step: 11
Training loss: 3.147967660837188
Validation loss: 3.1688641278359686

Epoch: 6| Step: 12
Training loss: 3.633115300510596
Validation loss: 3.1675519650231467

Epoch: 6| Step: 13
Training loss: 3.1086497012019083
Validation loss: 3.1637802688876895

Epoch: 77| Step: 0
Training loss: 3.1410831857357606
Validation loss: 3.1659632815350562

Epoch: 6| Step: 1
Training loss: 3.3920891057402573
Validation loss: 3.1654297890922347

Epoch: 6| Step: 2
Training loss: 3.0530875228096614
Validation loss: 3.1723819491013794

Epoch: 6| Step: 3
Training loss: 3.101360170313319
Validation loss: 3.1703770331924384

Epoch: 6| Step: 4
Training loss: 3.503687959163251
Validation loss: 3.1801854656989104

Epoch: 6| Step: 5
Training loss: 3.9637385890463213
Validation loss: 3.1788439996827513

Epoch: 6| Step: 6
Training loss: 3.633049807437315
Validation loss: 3.1699160488361895

Epoch: 6| Step: 7
Training loss: 3.398583419999473
Validation loss: 3.167353747934841

Epoch: 6| Step: 8
Training loss: 3.2540491262806035
Validation loss: 3.1661346508924493

Epoch: 6| Step: 9
Training loss: 3.6182930824246764
Validation loss: 3.164283184668977

Epoch: 6| Step: 10
Training loss: 3.718153961884492
Validation loss: 3.1625337059919034

Epoch: 6| Step: 11
Training loss: 3.2450182954481117
Validation loss: 3.16403130004846

Epoch: 6| Step: 12
Training loss: 3.244848129409845
Validation loss: 3.1656961497406133

Epoch: 6| Step: 13
Training loss: 3.630222636139477
Validation loss: 3.168364413531997

Epoch: 78| Step: 0
Training loss: 3.950771913070463
Validation loss: 3.171384723298338

Epoch: 6| Step: 1
Training loss: 2.7634270333792124
Validation loss: 3.165542651321551

Epoch: 6| Step: 2
Training loss: 3.406483353487207
Validation loss: 3.164986212024076

Epoch: 6| Step: 3
Training loss: 3.8535829394145997
Validation loss: 3.1649351653765057

Epoch: 6| Step: 4
Training loss: 2.9440274053210254
Validation loss: 3.1637546062874735

Epoch: 6| Step: 5
Training loss: 2.8801404359803775
Validation loss: 3.159527237381216

Epoch: 6| Step: 6
Training loss: 2.9911913296676143
Validation loss: 3.162804371443811

Epoch: 6| Step: 7
Training loss: 2.730336634941963
Validation loss: 3.161774855122244

Epoch: 6| Step: 8
Training loss: 3.3014988587542278
Validation loss: 3.160986210051845

Epoch: 6| Step: 9
Training loss: 2.8887294843499003
Validation loss: 3.160651156010469

Epoch: 6| Step: 10
Training loss: 3.9267695914629974
Validation loss: 3.1611770418516767

Epoch: 6| Step: 11
Training loss: 3.839121194653955
Validation loss: 3.16182437657663

Epoch: 6| Step: 12
Training loss: 3.7337109601815306
Validation loss: 3.1610836986879023

Epoch: 6| Step: 13
Training loss: 4.571718700602806
Validation loss: 3.15983514546044

Epoch: 79| Step: 0
Training loss: 3.606789459657831
Validation loss: 3.1614289600752365

Epoch: 6| Step: 1
Training loss: 3.9625151913709686
Validation loss: 3.1623947271299357

Epoch: 6| Step: 2
Training loss: 2.8608768042100636
Validation loss: 3.1588119916434794

Epoch: 6| Step: 3
Training loss: 3.763678083033606
Validation loss: 3.15997894721432

Epoch: 6| Step: 4
Training loss: 3.2115017657333764
Validation loss: 3.1587094804536657

Epoch: 6| Step: 5
Training loss: 3.1205597421862032
Validation loss: 3.1597033379343635

Epoch: 6| Step: 6
Training loss: 2.967016416642479
Validation loss: 3.161424652507834

Epoch: 6| Step: 7
Training loss: 3.436521356164118
Validation loss: 3.1646444462311183

Epoch: 6| Step: 8
Training loss: 3.6411180939961656
Validation loss: 3.1599405391696522

Epoch: 6| Step: 9
Training loss: 3.6367548071101212
Validation loss: 3.1583244015372043

Epoch: 6| Step: 10
Training loss: 3.4237732521094837
Validation loss: 3.1589707967461793

Epoch: 6| Step: 11
Training loss: 3.0572191757281555
Validation loss: 3.158460777084434

Epoch: 6| Step: 12
Training loss: 3.3063426821433217
Validation loss: 3.1585177008956125

Epoch: 6| Step: 13
Training loss: 3.6833384679237815
Validation loss: 3.15611083378662

Epoch: 80| Step: 0
Training loss: 2.880361285066046
Validation loss: 3.1583468890458617

Epoch: 6| Step: 1
Training loss: 3.579762712851547
Validation loss: 3.1551893253783247

Epoch: 6| Step: 2
Training loss: 2.416799826625602
Validation loss: 3.156677827904253

Epoch: 6| Step: 3
Training loss: 3.3288970195120355
Validation loss: 3.1549256302875057

Epoch: 6| Step: 4
Training loss: 3.878606041299941
Validation loss: 3.153450426768018

Epoch: 6| Step: 5
Training loss: 3.3741270278507955
Validation loss: 3.1555469419904965

Epoch: 6| Step: 6
Training loss: 3.141335326378173
Validation loss: 3.1548479430943073

Epoch: 6| Step: 7
Training loss: 3.660494175052164
Validation loss: 3.154836951799555

Epoch: 6| Step: 8
Training loss: 3.0538533430378894
Validation loss: 3.1544584836800347

Epoch: 6| Step: 9
Training loss: 3.9569614777057613
Validation loss: 3.152372142023812

Epoch: 6| Step: 10
Training loss: 3.667640094434661
Validation loss: 3.154860873215484

Epoch: 6| Step: 11
Training loss: 3.294101651437375
Validation loss: 3.1533993689842794

Epoch: 6| Step: 12
Training loss: 3.546208928286872
Validation loss: 3.1525797183990996

Epoch: 6| Step: 13
Training loss: 3.789435236579647
Validation loss: 3.1528767441670555

Epoch: 81| Step: 0
Training loss: 3.3754003781792608
Validation loss: 3.153669106413242

Epoch: 6| Step: 1
Training loss: 2.6837580157206014
Validation loss: 3.154544378808616

Epoch: 6| Step: 2
Training loss: 3.897023282751669
Validation loss: 3.1534694630678826

Epoch: 6| Step: 3
Training loss: 3.1970739755767394
Validation loss: 3.152812084870074

Epoch: 6| Step: 4
Training loss: 2.9772041810594336
Validation loss: 3.154160271465244

Epoch: 6| Step: 5
Training loss: 3.0840807000374135
Validation loss: 3.157887756279313

Epoch: 6| Step: 6
Training loss: 3.7877582625663493
Validation loss: 3.158830794360966

Epoch: 6| Step: 7
Training loss: 3.5755606045031048
Validation loss: 3.1631290437780013

Epoch: 6| Step: 8
Training loss: 3.6377830054446827
Validation loss: 3.160495129987412

Epoch: 6| Step: 9
Training loss: 3.906070186291067
Validation loss: 3.152950829146433

Epoch: 6| Step: 10
Training loss: 2.6169116429946984
Validation loss: 3.151526981094448

Epoch: 6| Step: 11
Training loss: 3.929357192489249
Validation loss: 3.150839332397178

Epoch: 6| Step: 12
Training loss: 3.2909907037261164
Validation loss: 3.150531319796654

Epoch: 6| Step: 13
Training loss: 3.396822982151162
Validation loss: 3.152373953925909

Epoch: 82| Step: 0
Training loss: 3.2486092452776494
Validation loss: 3.153302034643615

Epoch: 6| Step: 1
Training loss: 3.046970620244364
Validation loss: 3.1540961700501438

Epoch: 6| Step: 2
Training loss: 3.6596291080012304
Validation loss: 3.1568823763366867

Epoch: 6| Step: 3
Training loss: 2.961504637823252
Validation loss: 3.154190332016683

Epoch: 6| Step: 4
Training loss: 3.060946323446318
Validation loss: 3.158201560776126

Epoch: 6| Step: 5
Training loss: 3.524736727358851
Validation loss: 3.1601054530774757

Epoch: 6| Step: 6
Training loss: 3.966775117454794
Validation loss: 3.1535146307333117

Epoch: 6| Step: 7
Training loss: 3.2141478887406225
Validation loss: 3.152835972048765

Epoch: 6| Step: 8
Training loss: 3.3022293074600153
Validation loss: 3.150938086899304

Epoch: 6| Step: 9
Training loss: 3.503317622964068
Validation loss: 3.1516890734415086

Epoch: 6| Step: 10
Training loss: 3.3081930699309936
Validation loss: 3.151264956414084

Epoch: 6| Step: 11
Training loss: 3.406509249559435
Validation loss: 3.149743797273212

Epoch: 6| Step: 12
Training loss: 3.866763066591898
Validation loss: 3.1494395082117843

Epoch: 6| Step: 13
Training loss: 3.5865770488542643
Validation loss: 3.1492779724780258

Epoch: 83| Step: 0
Training loss: 2.2199499619489464
Validation loss: 3.149654561035487

Epoch: 6| Step: 1
Training loss: 2.8378919692013334
Validation loss: 3.1481342589492676

Epoch: 6| Step: 2
Training loss: 2.8325967579246734
Validation loss: 3.1501618503087396

Epoch: 6| Step: 3
Training loss: 3.0021265757877003
Validation loss: 3.1499412156112006

Epoch: 6| Step: 4
Training loss: 3.6338301351061615
Validation loss: 3.149671645661739

Epoch: 6| Step: 5
Training loss: 3.909748799286592
Validation loss: 3.1498158186354615

Epoch: 6| Step: 6
Training loss: 4.207909339218239
Validation loss: 3.149287513021287

Epoch: 6| Step: 7
Training loss: 3.6960734900397223
Validation loss: 3.1488262711964046

Epoch: 6| Step: 8
Training loss: 2.9645687171716912
Validation loss: 3.1458605522201166

Epoch: 6| Step: 9
Training loss: 2.9744434573412906
Validation loss: 3.147137477048167

Epoch: 6| Step: 10
Training loss: 3.41830829786646
Validation loss: 3.1474221909871445

Epoch: 6| Step: 11
Training loss: 3.4549442521937457
Validation loss: 3.1448414023812954

Epoch: 6| Step: 12
Training loss: 4.278233711639214
Validation loss: 3.1470940922647817

Epoch: 6| Step: 13
Training loss: 3.690298279489283
Validation loss: 3.1454153377433265

Epoch: 84| Step: 0
Training loss: 3.1761564476530846
Validation loss: 3.1447210129411243

Epoch: 6| Step: 1
Training loss: 3.7421579379703958
Validation loss: 3.1466654542373496

Epoch: 6| Step: 2
Training loss: 3.998984923311179
Validation loss: 3.145904191969933

Epoch: 6| Step: 3
Training loss: 2.7254232305430097
Validation loss: 3.1455952861851237

Epoch: 6| Step: 4
Training loss: 3.8549022625557474
Validation loss: 3.1449366932901857

Epoch: 6| Step: 5
Training loss: 3.19403901406803
Validation loss: 3.1474926201780455

Epoch: 6| Step: 6
Training loss: 3.219881766144785
Validation loss: 3.1455613276554235

Epoch: 6| Step: 7
Training loss: 3.4660449778813156
Validation loss: 3.1431369000091833

Epoch: 6| Step: 8
Training loss: 3.5203072119079235
Validation loss: 3.142422454718077

Epoch: 6| Step: 9
Training loss: 2.923110292800207
Validation loss: 3.143374942759081

Epoch: 6| Step: 10
Training loss: 3.9468609179126997
Validation loss: 3.1429699896950543

Epoch: 6| Step: 11
Training loss: 2.4806478120346496
Validation loss: 3.1438324390455357

Epoch: 6| Step: 12
Training loss: 3.713467733209866
Validation loss: 3.1421146923865857

Epoch: 6| Step: 13
Training loss: 3.079476771313366
Validation loss: 3.142313864379255

Epoch: 85| Step: 0
Training loss: 2.8593388122603343
Validation loss: 3.1417993627235035

Epoch: 6| Step: 1
Training loss: 4.223809493233784
Validation loss: 3.141755688804326

Epoch: 6| Step: 2
Training loss: 3.361967993416553
Validation loss: 3.1420538977123837

Epoch: 6| Step: 3
Training loss: 3.3351974202392
Validation loss: 3.1411114330626195

Epoch: 6| Step: 4
Training loss: 3.442586014614243
Validation loss: 3.1400137416506775

Epoch: 6| Step: 5
Training loss: 3.3768678370881138
Validation loss: 3.1408996445618595

Epoch: 6| Step: 6
Training loss: 3.9786981569796205
Validation loss: 3.140338017495966

Epoch: 6| Step: 7
Training loss: 3.4563644197091046
Validation loss: 3.142097496503185

Epoch: 6| Step: 8
Training loss: 3.2252833160626477
Validation loss: 3.1404460198262676

Epoch: 6| Step: 9
Training loss: 3.037938711877918
Validation loss: 3.139173745109409

Epoch: 6| Step: 10
Training loss: 2.646666077854786
Validation loss: 3.137793894058064

Epoch: 6| Step: 11
Training loss: 3.251336043178839
Validation loss: 3.139411570637756

Epoch: 6| Step: 12
Training loss: 3.3001134795126563
Validation loss: 3.1366820056056337

Epoch: 6| Step: 13
Training loss: 3.967235726855535
Validation loss: 3.13773320848736

Epoch: 86| Step: 0
Training loss: 3.465374928456572
Validation loss: 3.1384632513391946

Epoch: 6| Step: 1
Training loss: 2.970384810208154
Validation loss: 3.1384160609836744

Epoch: 6| Step: 2
Training loss: 4.062041975757683
Validation loss: 3.1392488688519666

Epoch: 6| Step: 3
Training loss: 3.650856408803309
Validation loss: 3.142772865154263

Epoch: 6| Step: 4
Training loss: 3.8204098554504657
Validation loss: 3.141828058107297

Epoch: 6| Step: 5
Training loss: 3.146906250814602
Validation loss: 3.1409360621070537

Epoch: 6| Step: 6
Training loss: 3.3727262396461497
Validation loss: 3.1362273800991476

Epoch: 6| Step: 7
Training loss: 2.2208633029578397
Validation loss: 3.138533466621735

Epoch: 6| Step: 8
Training loss: 3.62972004843416
Validation loss: 3.1394055335148705

Epoch: 6| Step: 9
Training loss: 3.1306961026516458
Validation loss: 3.1371059065140527

Epoch: 6| Step: 10
Training loss: 2.7974651715630703
Validation loss: 3.1375114473066166

Epoch: 6| Step: 11
Training loss: 3.297434971698172
Validation loss: 3.140392257497891

Epoch: 6| Step: 12
Training loss: 3.8365204595375477
Validation loss: 3.1448807268607286

Epoch: 6| Step: 13
Training loss: 3.8426369396818534
Validation loss: 3.1478004430907798

Epoch: 87| Step: 0
Training loss: 2.216572942640595
Validation loss: 3.142262263399454

Epoch: 6| Step: 1
Training loss: 3.1950984967112555
Validation loss: 3.1372710295375152

Epoch: 6| Step: 2
Training loss: 3.5293284901911304
Validation loss: 3.1394396321235134

Epoch: 6| Step: 3
Training loss: 2.9230279126865564
Validation loss: 3.1363384388297013

Epoch: 6| Step: 4
Training loss: 3.4178685811214833
Validation loss: 3.136024154330024

Epoch: 6| Step: 5
Training loss: 3.9699944174700867
Validation loss: 3.134822833513191

Epoch: 6| Step: 6
Training loss: 3.6371887755553574
Validation loss: 3.136649316316452

Epoch: 6| Step: 7
Training loss: 3.87569827279493
Validation loss: 3.1343891876530705

Epoch: 6| Step: 8
Training loss: 3.394507931540305
Validation loss: 3.1326576063482965

Epoch: 6| Step: 9
Training loss: 3.461277241101976
Validation loss: 3.1336532298129214

Epoch: 6| Step: 10
Training loss: 3.5011044530772604
Validation loss: 3.132718139828008

Epoch: 6| Step: 11
Training loss: 3.1110369204197568
Validation loss: 3.1338386155289393

Epoch: 6| Step: 12
Training loss: 3.6514848484569593
Validation loss: 3.1331820017030783

Epoch: 6| Step: 13
Training loss: 3.079352584271057
Validation loss: 3.134062969509523

Epoch: 88| Step: 0
Training loss: 2.388738748233471
Validation loss: 3.13612398353926

Epoch: 6| Step: 1
Training loss: 3.6584781476137564
Validation loss: 3.134510513713459

Epoch: 6| Step: 2
Training loss: 3.3240190708242223
Validation loss: 3.1350599113300768

Epoch: 6| Step: 3
Training loss: 2.077578365165396
Validation loss: 3.1347256387746563

Epoch: 6| Step: 4
Training loss: 3.4337597005100937
Validation loss: 3.1339350066628797

Epoch: 6| Step: 5
Training loss: 3.848315001507813
Validation loss: 3.1350773134488525

Epoch: 6| Step: 6
Training loss: 3.4170057237067555
Validation loss: 3.131975087140523

Epoch: 6| Step: 7
Training loss: 4.0665267941126775
Validation loss: 3.1312428553167755

Epoch: 6| Step: 8
Training loss: 3.349744752867417
Validation loss: 3.1311950296914093

Epoch: 6| Step: 9
Training loss: 2.999996821083928
Validation loss: 3.130073668272061

Epoch: 6| Step: 10
Training loss: 3.5507887702753145
Validation loss: 3.1306659057673425

Epoch: 6| Step: 11
Training loss: 3.9675317531533727
Validation loss: 3.1295547697131076

Epoch: 6| Step: 12
Training loss: 3.799823008983072
Validation loss: 3.129962269306844

Epoch: 6| Step: 13
Training loss: 2.5505088672405276
Validation loss: 3.1300140976341804

Epoch: 89| Step: 0
Training loss: 3.9316438996120864
Validation loss: 3.132008090418946

Epoch: 6| Step: 1
Training loss: 3.7051566301151864
Validation loss: 3.131199604817925

Epoch: 6| Step: 2
Training loss: 3.96359831693904
Validation loss: 3.1342501836334495

Epoch: 6| Step: 3
Training loss: 3.8949587787214712
Validation loss: 3.132426518424116

Epoch: 6| Step: 4
Training loss: 4.001925481846939
Validation loss: 3.1361984005014643

Epoch: 6| Step: 5
Training loss: 3.089192588278229
Validation loss: 3.131868639375426

Epoch: 6| Step: 6
Training loss: 2.6851136902052013
Validation loss: 3.131117402170082

Epoch: 6| Step: 7
Training loss: 3.2898957200611925
Validation loss: 3.134181705444913

Epoch: 6| Step: 8
Training loss: 3.477833993259018
Validation loss: 3.130711338554472

Epoch: 6| Step: 9
Training loss: 3.365078365099285
Validation loss: 3.1278806932688514

Epoch: 6| Step: 10
Training loss: 2.9123890344003343
Validation loss: 3.1297765376696023

Epoch: 6| Step: 11
Training loss: 2.8251484755936582
Validation loss: 3.131269801223386

Epoch: 6| Step: 12
Training loss: 2.9899621561774885
Validation loss: 3.130764962512332

Epoch: 6| Step: 13
Training loss: 2.317943661061876
Validation loss: 3.1309065637998583

Epoch: 90| Step: 0
Training loss: 3.542936045233907
Validation loss: 3.1350738945260415

Epoch: 6| Step: 1
Training loss: 2.7131782527566615
Validation loss: 3.131836852666014

Epoch: 6| Step: 2
Training loss: 3.489373833739646
Validation loss: 3.137123259692412

Epoch: 6| Step: 3
Training loss: 2.8408678141976513
Validation loss: 3.1393214511017695

Epoch: 6| Step: 4
Training loss: 3.721596533978227
Validation loss: 3.1504210950296474

Epoch: 6| Step: 5
Training loss: 3.1427944907842305
Validation loss: 3.1445204117876777

Epoch: 6| Step: 6
Training loss: 3.0937076141844737
Validation loss: 3.130577804471761

Epoch: 6| Step: 7
Training loss: 3.895603166332656
Validation loss: 3.133831763524075

Epoch: 6| Step: 8
Training loss: 3.568118834257186
Validation loss: 3.1270409365388296

Epoch: 6| Step: 9
Training loss: 3.661220725513245
Validation loss: 3.123768527307278

Epoch: 6| Step: 10
Training loss: 4.279796269995909
Validation loss: 3.1260725268689025

Epoch: 6| Step: 11
Training loss: 3.052254959506101
Validation loss: 3.1275271478572786

Epoch: 6| Step: 12
Training loss: 3.2402602752882874
Validation loss: 3.129214839505237

Epoch: 6| Step: 13
Training loss: 2.0896717036366006
Validation loss: 3.1347764936674083

Epoch: 91| Step: 0
Training loss: 3.1350146233371223
Validation loss: 3.1402955649508275

Epoch: 6| Step: 1
Training loss: 3.8433075937124386
Validation loss: 3.147982399444635

Epoch: 6| Step: 2
Training loss: 3.6406566962307187
Validation loss: 3.1372962468780985

Epoch: 6| Step: 3
Training loss: 3.8521277455887883
Validation loss: 3.1312061657898536

Epoch: 6| Step: 4
Training loss: 3.1070480457491723
Validation loss: 3.127466308974143

Epoch: 6| Step: 5
Training loss: 2.9422241532792244
Validation loss: 3.124817063094085

Epoch: 6| Step: 6
Training loss: 3.5707636241421903
Validation loss: 3.122394054392869

Epoch: 6| Step: 7
Training loss: 3.6348910384395468
Validation loss: 3.1222861895913394

Epoch: 6| Step: 8
Training loss: 2.793519463297381
Validation loss: 3.1224364613208047

Epoch: 6| Step: 9
Training loss: 3.022951703139122
Validation loss: 3.1218200846285784

Epoch: 6| Step: 10
Training loss: 3.1370042264822935
Validation loss: 3.1200403878603544

Epoch: 6| Step: 11
Training loss: 3.6736057828701507
Validation loss: 3.12232035035646

Epoch: 6| Step: 12
Training loss: 3.3672012364224595
Validation loss: 3.1210292503683044

Epoch: 6| Step: 13
Training loss: 3.611494226591821
Validation loss: 3.1253419110696217

Epoch: 92| Step: 0
Training loss: 2.4488239852376177
Validation loss: 3.129478362239955

Epoch: 6| Step: 1
Training loss: 2.7701052997557003
Validation loss: 3.1303578949949102

Epoch: 6| Step: 2
Training loss: 3.1153871313449013
Validation loss: 3.1275916266008297

Epoch: 6| Step: 3
Training loss: 3.3468636249879644
Validation loss: 3.1372893010980993

Epoch: 6| Step: 4
Training loss: 3.6496485919839876
Validation loss: 3.1269015697842333

Epoch: 6| Step: 5
Training loss: 3.39069405059117
Validation loss: 3.1205539503780835

Epoch: 6| Step: 6
Training loss: 3.9811079206521023
Validation loss: 3.12397060544447

Epoch: 6| Step: 7
Training loss: 3.3785158846940297
Validation loss: 3.119951486110429

Epoch: 6| Step: 8
Training loss: 2.5925377460259074
Validation loss: 3.119805045572278

Epoch: 6| Step: 9
Training loss: 3.6457424624789625
Validation loss: 3.1215495201426555

Epoch: 6| Step: 10
Training loss: 3.95791998595656
Validation loss: 3.1205430091713677

Epoch: 6| Step: 11
Training loss: 4.036779116117727
Validation loss: 3.119364255983047

Epoch: 6| Step: 12
Training loss: 3.2421983833589922
Validation loss: 3.1187186742625643

Epoch: 6| Step: 13
Training loss: 3.209088389405257
Validation loss: 3.120255357837741

Epoch: 93| Step: 0
Training loss: 3.1183364012917356
Validation loss: 3.118289929900677

Epoch: 6| Step: 1
Training loss: 3.4145035447920478
Validation loss: 3.1193234115557913

Epoch: 6| Step: 2
Training loss: 3.355844176920393
Validation loss: 3.117815624945599

Epoch: 6| Step: 3
Training loss: 2.816390335101532
Validation loss: 3.120712497450202

Epoch: 6| Step: 4
Training loss: 3.9053757566616065
Validation loss: 3.1236208310874396

Epoch: 6| Step: 5
Training loss: 2.7354178047807296
Validation loss: 3.124113336927314

Epoch: 6| Step: 6
Training loss: 3.33057295627059
Validation loss: 3.130282426021742

Epoch: 6| Step: 7
Training loss: 3.5539968637120927
Validation loss: 3.1300872986268335

Epoch: 6| Step: 8
Training loss: 3.6537054613957065
Validation loss: 3.1216329027562297

Epoch: 6| Step: 9
Training loss: 3.6448575412451554
Validation loss: 3.119895483157673

Epoch: 6| Step: 10
Training loss: 3.412771439149423
Validation loss: 3.1165215507214925

Epoch: 6| Step: 11
Training loss: 3.2275965329130685
Validation loss: 3.118190055912431

Epoch: 6| Step: 12
Training loss: 3.869983255907056
Validation loss: 3.1165353703169885

Epoch: 6| Step: 13
Training loss: 2.678975981179984
Validation loss: 3.118783537327427

Epoch: 94| Step: 0
Training loss: 3.435331597016148
Validation loss: 3.1172759879599825

Epoch: 6| Step: 1
Training loss: 3.2396421437378575
Validation loss: 3.113822666057891

Epoch: 6| Step: 2
Training loss: 2.521748358325002
Validation loss: 3.115697874417318

Epoch: 6| Step: 3
Training loss: 3.3144608937556272
Validation loss: 3.1150206789944628

Epoch: 6| Step: 4
Training loss: 3.0869443385694972
Validation loss: 3.114822828453442

Epoch: 6| Step: 5
Training loss: 3.8652454778927194
Validation loss: 3.1161866404099694

Epoch: 6| Step: 6
Training loss: 3.3201772146152373
Validation loss: 3.1147409113125866

Epoch: 6| Step: 7
Training loss: 3.8519407013144518
Validation loss: 3.114914120958689

Epoch: 6| Step: 8
Training loss: 3.6693128371784436
Validation loss: 3.112874506841757

Epoch: 6| Step: 9
Training loss: 4.056831983480151
Validation loss: 3.1137937768072175

Epoch: 6| Step: 10
Training loss: 2.4347907439756424
Validation loss: 3.114478597026492

Epoch: 6| Step: 11
Training loss: 3.406482933549279
Validation loss: 3.1154702674518053

Epoch: 6| Step: 12
Training loss: 3.491491056288499
Validation loss: 3.1126845682191235

Epoch: 6| Step: 13
Training loss: 2.9124962737096434
Validation loss: 3.1129201935279074

Epoch: 95| Step: 0
Training loss: 2.387629208888127
Validation loss: 3.1121785533228277

Epoch: 6| Step: 1
Training loss: 3.358681540662847
Validation loss: 3.1142485383743037

Epoch: 6| Step: 2
Training loss: 2.823790373967381
Validation loss: 3.1128888482921084

Epoch: 6| Step: 3
Training loss: 2.8800147729070917
Validation loss: 3.112450744566

Epoch: 6| Step: 4
Training loss: 4.055001483733521
Validation loss: 3.1128125003505143

Epoch: 6| Step: 5
Training loss: 3.356452273732598
Validation loss: 3.1108243799020725

Epoch: 6| Step: 6
Training loss: 3.424428187620586
Validation loss: 3.112124913899718

Epoch: 6| Step: 7
Training loss: 3.175263497539786
Validation loss: 3.110857935559242

Epoch: 6| Step: 8
Training loss: 3.5558766147246317
Validation loss: 3.1140626450230764

Epoch: 6| Step: 9
Training loss: 3.8590408983675513
Validation loss: 3.1092744818134226

Epoch: 6| Step: 10
Training loss: 3.571620843343873
Validation loss: 3.1115546985772506

Epoch: 6| Step: 11
Training loss: 3.6297040212306957
Validation loss: 3.109578666462287

Epoch: 6| Step: 12
Training loss: 3.0232632214689183
Validation loss: 3.1104292796898303

Epoch: 6| Step: 13
Training loss: 3.9420226024442266
Validation loss: 3.1079869838427316

Epoch: 96| Step: 0
Training loss: 3.100424608253657
Validation loss: 3.108882776666246

Epoch: 6| Step: 1
Training loss: 3.2109568054658384
Validation loss: 3.1088858986683503

Epoch: 6| Step: 2
Training loss: 3.42949841093212
Validation loss: 3.1087799888096677

Epoch: 6| Step: 3
Training loss: 3.1762220538943007
Validation loss: 3.1091208545519287

Epoch: 6| Step: 4
Training loss: 2.88241731576369
Validation loss: 3.1071378373199585

Epoch: 6| Step: 5
Training loss: 3.596220013516987
Validation loss: 3.108302173251026

Epoch: 6| Step: 6
Training loss: 3.907867951058812
Validation loss: 3.107021764396044

Epoch: 6| Step: 7
Training loss: 3.4345354648413413
Validation loss: 3.107741787477299

Epoch: 6| Step: 8
Training loss: 3.361138595034322
Validation loss: 3.107442937323124

Epoch: 6| Step: 9
Training loss: 2.655695599313095
Validation loss: 3.107375896269391

Epoch: 6| Step: 10
Training loss: 3.4945817970596043
Validation loss: 3.1079421542643493

Epoch: 6| Step: 11
Training loss: 2.1907625119832437
Validation loss: 3.1087284340354047

Epoch: 6| Step: 12
Training loss: 4.439469880770183
Validation loss: 3.107084148830386

Epoch: 6| Step: 13
Training loss: 3.936906557927126
Validation loss: 3.1066961268209803

Epoch: 97| Step: 0
Training loss: 3.1307894674529235
Validation loss: 3.107226702231738

Epoch: 6| Step: 1
Training loss: 3.525888339173869
Validation loss: 3.1063958902862057

Epoch: 6| Step: 2
Training loss: 3.0404052905911554
Validation loss: 3.1059393665139683

Epoch: 6| Step: 3
Training loss: 3.8439230531023103
Validation loss: 3.1072784692070954

Epoch: 6| Step: 4
Training loss: 3.0962732987341575
Validation loss: 3.1075398535198153

Epoch: 6| Step: 5
Training loss: 3.2151470574284953
Validation loss: 3.1050624927109722

Epoch: 6| Step: 6
Training loss: 3.3996641554172533
Validation loss: 3.1099068511496726

Epoch: 6| Step: 7
Training loss: 3.6829060532506546
Validation loss: 3.105031447120967

Epoch: 6| Step: 8
Training loss: 3.234847766767041
Validation loss: 3.1055767382885175

Epoch: 6| Step: 9
Training loss: 3.1667288389293202
Validation loss: 3.107008369500564

Epoch: 6| Step: 10
Training loss: 2.9400025117305484
Validation loss: 3.1032946160648325

Epoch: 6| Step: 11
Training loss: 3.7184979008726016
Validation loss: 3.1075021692885074

Epoch: 6| Step: 12
Training loss: 3.8560839995973484
Validation loss: 3.103880183088868

Epoch: 6| Step: 13
Training loss: 2.864041548848458
Validation loss: 3.1029205890743756

Epoch: 98| Step: 0
Training loss: 3.536761548504021
Validation loss: 3.102445582965599

Epoch: 6| Step: 1
Training loss: 3.2035571295304734
Validation loss: 3.102683540054186

Epoch: 6| Step: 2
Training loss: 3.427350127590516
Validation loss: 3.102746362869523

Epoch: 6| Step: 3
Training loss: 3.053102672421078
Validation loss: 3.1024533405321866

Epoch: 6| Step: 4
Training loss: 3.784256677644227
Validation loss: 3.1036862628380373

Epoch: 6| Step: 5
Training loss: 2.8917084184283643
Validation loss: 3.1038636145471163

Epoch: 6| Step: 6
Training loss: 3.0272832655248108
Validation loss: 3.101068848951991

Epoch: 6| Step: 7
Training loss: 3.2383788753284164
Validation loss: 3.1006217321826823

Epoch: 6| Step: 8
Training loss: 3.6790623224884227
Validation loss: 3.101583447546672

Epoch: 6| Step: 9
Training loss: 3.3431955038193344
Validation loss: 3.1020221695552874

Epoch: 6| Step: 10
Training loss: 3.4854236615633885
Validation loss: 3.1022994548160425

Epoch: 6| Step: 11
Training loss: 3.1390987502378955
Validation loss: 3.1025414703491077

Epoch: 6| Step: 12
Training loss: 3.63679374838752
Validation loss: 3.101021302831164

Epoch: 6| Step: 13
Training loss: 3.6186415054844607
Validation loss: 3.1007167582310022

Epoch: 99| Step: 0
Training loss: 3.571832846512117
Validation loss: 3.099528418856179

Epoch: 6| Step: 1
Training loss: 4.071196652262881
Validation loss: 3.1004000336513786

Epoch: 6| Step: 2
Training loss: 3.3994373473060624
Validation loss: 3.0999295884298914

Epoch: 6| Step: 3
Training loss: 2.6826187872560756
Validation loss: 3.099165709704015

Epoch: 6| Step: 4
Training loss: 4.006251218798567
Validation loss: 3.1001329881059436

Epoch: 6| Step: 5
Training loss: 3.0723991001282287
Validation loss: 3.0994633066808306

Epoch: 6| Step: 6
Training loss: 3.6939867799002917
Validation loss: 3.098609801447686

Epoch: 6| Step: 7
Training loss: 3.1649888931248267
Validation loss: 3.100002286634287

Epoch: 6| Step: 8
Training loss: 3.727456679319508
Validation loss: 3.099917415798377

Epoch: 6| Step: 9
Training loss: 2.9840640560157676
Validation loss: 3.098084232891628

Epoch: 6| Step: 10
Training loss: 2.778952174414505
Validation loss: 3.097881393838118

Epoch: 6| Step: 11
Training loss: 3.004499081770677
Validation loss: 3.0977181717315796

Epoch: 6| Step: 12
Training loss: 2.860545101370985
Validation loss: 3.0985751310733147

Epoch: 6| Step: 13
Training loss: 3.842472391320979
Validation loss: 3.097954183965444

Epoch: 100| Step: 0
Training loss: 3.4874667148984253
Validation loss: 3.098576964505046

Epoch: 6| Step: 1
Training loss: 3.1584582771273855
Validation loss: 3.0990258595296543

Epoch: 6| Step: 2
Training loss: 3.055154515930567
Validation loss: 3.097555430983309

Epoch: 6| Step: 3
Training loss: 3.1874853395611082
Validation loss: 3.100485858692517

Epoch: 6| Step: 4
Training loss: 3.9056841631196266
Validation loss: 3.0999479039366813

Epoch: 6| Step: 5
Training loss: 3.942111508925605
Validation loss: 3.0974713042064037

Epoch: 6| Step: 6
Training loss: 3.445907852738583
Validation loss: 3.096014995812831

Epoch: 6| Step: 7
Training loss: 2.811881527186184
Validation loss: 3.096552786049796

Epoch: 6| Step: 8
Training loss: 3.743454625063222
Validation loss: 3.097366309300404

Epoch: 6| Step: 9
Training loss: 3.071935481953624
Validation loss: 3.0952453463209255

Epoch: 6| Step: 10
Training loss: 3.5670039834443297
Validation loss: 3.0966323049659663

Epoch: 6| Step: 11
Training loss: 2.542710720396087
Validation loss: 3.094886618226213

Epoch: 6| Step: 12
Training loss: 3.4629233972469264
Validation loss: 3.0945984924078815

Epoch: 6| Step: 13
Training loss: 3.3212300547444897
Validation loss: 3.0938797989082985

Epoch: 101| Step: 0
Training loss: 3.900114077342377
Validation loss: 3.094015173694587

Epoch: 6| Step: 1
Training loss: 2.87986045976193
Validation loss: 3.093971777315213

Epoch: 6| Step: 2
Training loss: 3.620903989558287
Validation loss: 3.094231641063288

Epoch: 6| Step: 3
Training loss: 2.9694452375175606
Validation loss: 3.093592964894474

Epoch: 6| Step: 4
Training loss: 3.574037841220839
Validation loss: 3.094151404243878

Epoch: 6| Step: 5
Training loss: 2.9757014753885986
Validation loss: 3.0955103289765185

Epoch: 6| Step: 6
Training loss: 3.656663920129969
Validation loss: 3.093835941569905

Epoch: 6| Step: 7
Training loss: 3.3384531438857876
Validation loss: 3.0936985220820863

Epoch: 6| Step: 8
Training loss: 3.5289199028232408
Validation loss: 3.0928386656473603

Epoch: 6| Step: 9
Training loss: 2.377106184407984
Validation loss: 3.094469273742275

Epoch: 6| Step: 10
Training loss: 4.074375109355824
Validation loss: 3.094737189069083

Epoch: 6| Step: 11
Training loss: 2.689112689510197
Validation loss: 3.097028070995533

Epoch: 6| Step: 12
Training loss: 3.3872251561001487
Validation loss: 3.09602457462593

Epoch: 6| Step: 13
Training loss: 3.7497545797784335
Validation loss: 3.0952721542110386

Epoch: 102| Step: 0
Training loss: 3.2623971564792664
Validation loss: 3.0926632796091624

Epoch: 6| Step: 1
Training loss: 3.2209173516438767
Validation loss: 3.094463111658782

Epoch: 6| Step: 2
Training loss: 2.961619437003382
Validation loss: 3.0915443460780136

Epoch: 6| Step: 3
Training loss: 3.037843749136061
Validation loss: 3.0953734940049995

Epoch: 6| Step: 4
Training loss: 3.1851465849628013
Validation loss: 3.091925551988633

Epoch: 6| Step: 5
Training loss: 3.943403269281148
Validation loss: 3.0911816919915007

Epoch: 6| Step: 6
Training loss: 3.711446562534324
Validation loss: 3.08993380091129

Epoch: 6| Step: 7
Training loss: 3.9552317196256173
Validation loss: 3.0905565900587058

Epoch: 6| Step: 8
Training loss: 2.6709627077504936
Validation loss: 3.092765379624573

Epoch: 6| Step: 9
Training loss: 3.1617976618770025
Validation loss: 3.0905183826956852

Epoch: 6| Step: 10
Training loss: 3.4898764112390364
Validation loss: 3.0908055318978493

Epoch: 6| Step: 11
Training loss: 3.08649866337626
Validation loss: 3.0905303775027244

Epoch: 6| Step: 12
Training loss: 3.5821750158581422
Validation loss: 3.0900704785377755

Epoch: 6| Step: 13
Training loss: 3.4793245808898843
Validation loss: 3.091693765370968

Epoch: 103| Step: 0
Training loss: 3.8551783428178314
Validation loss: 3.092519227566308

Epoch: 6| Step: 1
Training loss: 3.8303432966116056
Validation loss: 3.089085931029468

Epoch: 6| Step: 2
Training loss: 4.145532082710167
Validation loss: 3.0905352185472066

Epoch: 6| Step: 3
Training loss: 3.6151241077524747
Validation loss: 3.0927611480089183

Epoch: 6| Step: 4
Training loss: 3.035146038180617
Validation loss: 3.0915903040263166

Epoch: 6| Step: 5
Training loss: 2.0803428803778874
Validation loss: 3.092278478707422

Epoch: 6| Step: 6
Training loss: 3.0488773906473647
Validation loss: 3.088091814908699

Epoch: 6| Step: 7
Training loss: 2.936075067875346
Validation loss: 3.091381289440883

Epoch: 6| Step: 8
Training loss: 3.4209645074621746
Validation loss: 3.0893231620445167

Epoch: 6| Step: 9
Training loss: 2.702324544767239
Validation loss: 3.092913149317057

Epoch: 6| Step: 10
Training loss: 3.5356233235558023
Validation loss: 3.0873143975007435

Epoch: 6| Step: 11
Training loss: 3.522472308600304
Validation loss: 3.0882154695488047

Epoch: 6| Step: 12
Training loss: 3.3354030064802074
Validation loss: 3.08621646964413

Epoch: 6| Step: 13
Training loss: 3.2477833451139126
Validation loss: 3.085347489423759

Epoch: 104| Step: 0
Training loss: 3.413105077512499
Validation loss: 3.0866333834852484

Epoch: 6| Step: 1
Training loss: 2.8746810404442353
Validation loss: 3.087292533547722

Epoch: 6| Step: 2
Training loss: 3.555092589383826
Validation loss: 3.0860985049968748

Epoch: 6| Step: 3
Training loss: 2.9606893229085465
Validation loss: 3.0859083372363014

Epoch: 6| Step: 4
Training loss: 3.5342766947950035
Validation loss: 3.0864506112276198

Epoch: 6| Step: 5
Training loss: 3.2478310610239793
Validation loss: 3.08515786950687

Epoch: 6| Step: 6
Training loss: 4.164250296246031
Validation loss: 3.085299983541533

Epoch: 6| Step: 7
Training loss: 3.3005576153901277
Validation loss: 3.0885667799709395

Epoch: 6| Step: 8
Training loss: 2.6158848495571396
Validation loss: 3.0893196568028762

Epoch: 6| Step: 9
Training loss: 3.4468794047101845
Validation loss: 3.084974596819742

Epoch: 6| Step: 10
Training loss: 3.51709306370679
Validation loss: 3.08733096517547

Epoch: 6| Step: 11
Training loss: 2.899222295990741
Validation loss: 3.08603092632147

Epoch: 6| Step: 12
Training loss: 3.8211576622964607
Validation loss: 3.0867781944004595

Epoch: 6| Step: 13
Training loss: 3.106321743111701
Validation loss: 3.085904726763305

Epoch: 105| Step: 0
Training loss: 2.813107742768541
Validation loss: 3.0836952970363476

Epoch: 6| Step: 1
Training loss: 3.2347243852846077
Validation loss: 3.087179112532966

Epoch: 6| Step: 2
Training loss: 3.16377780716702
Validation loss: 3.0830327211443134

Epoch: 6| Step: 3
Training loss: 3.4858502057754133
Validation loss: 3.0854628414267227

Epoch: 6| Step: 4
Training loss: 3.247311727397759
Validation loss: 3.083830008265015

Epoch: 6| Step: 5
Training loss: 3.464038295084864
Validation loss: 3.0834253954813873

Epoch: 6| Step: 6
Training loss: 3.069992242859226
Validation loss: 3.082037235643429

Epoch: 6| Step: 7
Training loss: 2.4220882198858216
Validation loss: 3.082523737420808

Epoch: 6| Step: 8
Training loss: 3.5864787971000665
Validation loss: 3.080919533730707

Epoch: 6| Step: 9
Training loss: 3.5978296095243203
Validation loss: 3.081375352351072

Epoch: 6| Step: 10
Training loss: 3.874107750335044
Validation loss: 3.0823531972315514

Epoch: 6| Step: 11
Training loss: 3.5201304409393734
Validation loss: 3.081781439668217

Epoch: 6| Step: 12
Training loss: 3.528787750355715
Validation loss: 3.0808535040309883

Epoch: 6| Step: 13
Training loss: 3.771550877763625
Validation loss: 3.079643015534173

Epoch: 106| Step: 0
Training loss: 3.242801029111144
Validation loss: 3.0802460412839388

Epoch: 6| Step: 1
Training loss: 2.7391141966028454
Validation loss: 3.0808653251088005

Epoch: 6| Step: 2
Training loss: 2.9118264135666023
Validation loss: 3.0800963895897358

Epoch: 6| Step: 3
Training loss: 3.85080796718326
Validation loss: 3.079813381159303

Epoch: 6| Step: 4
Training loss: 3.2122033958216174
Validation loss: 3.0787336506569605

Epoch: 6| Step: 5
Training loss: 3.929220304530924
Validation loss: 3.078939825256169

Epoch: 6| Step: 6
Training loss: 3.145559656899666
Validation loss: 3.079657653253407

Epoch: 6| Step: 7
Training loss: 3.271214716031919
Validation loss: 3.0776264492155505

Epoch: 6| Step: 8
Training loss: 3.546041113342406
Validation loss: 3.0786551216886884

Epoch: 6| Step: 9
Training loss: 2.9056484461228367
Validation loss: 3.0827846609854155

Epoch: 6| Step: 10
Training loss: 3.0069881746334244
Validation loss: 3.0773871677333204

Epoch: 6| Step: 11
Training loss: 3.104763272363449
Validation loss: 3.0772850848332727

Epoch: 6| Step: 12
Training loss: 3.465265947184544
Validation loss: 3.0791863027231243

Epoch: 6| Step: 13
Training loss: 4.690673770943257
Validation loss: 3.077287102564946

Epoch: 107| Step: 0
Training loss: 3.633360593734341
Validation loss: 3.0792402678250244

Epoch: 6| Step: 1
Training loss: 3.3780995017755893
Validation loss: 3.0819305952891094

Epoch: 6| Step: 2
Training loss: 2.845702119616329
Validation loss: 3.082689005658217

Epoch: 6| Step: 3
Training loss: 3.518559430722934
Validation loss: 3.087782172606258

Epoch: 6| Step: 4
Training loss: 3.1693781905326515
Validation loss: 3.086679546610875

Epoch: 6| Step: 5
Training loss: 3.4742124694259626
Validation loss: 3.0892513195632456

Epoch: 6| Step: 6
Training loss: 3.2055195115691144
Validation loss: 3.0865493045409997

Epoch: 6| Step: 7
Training loss: 3.230927182273429
Validation loss: 3.0831635541215667

Epoch: 6| Step: 8
Training loss: 3.9042498541362525
Validation loss: 3.0776404867779954

Epoch: 6| Step: 9
Training loss: 3.4039220291693026
Validation loss: 3.081125076561444

Epoch: 6| Step: 10
Training loss: 2.9300185359850235
Validation loss: 3.078472851752212

Epoch: 6| Step: 11
Training loss: 2.882868406999389
Validation loss: 3.082900475602411

Epoch: 6| Step: 12
Training loss: 3.4057518831063174
Validation loss: 3.078167315551872

Epoch: 6| Step: 13
Training loss: 3.863650775821345
Validation loss: 3.0770730723440605

Epoch: 108| Step: 0
Training loss: 3.151560103378179
Validation loss: 3.0744980475170105

Epoch: 6| Step: 1
Training loss: 3.071019836172909
Validation loss: 3.079225085292381

Epoch: 6| Step: 2
Training loss: 3.4754202005474872
Validation loss: 3.0773270453821415

Epoch: 6| Step: 3
Training loss: 3.4213805516414557
Validation loss: 3.078336623576201

Epoch: 6| Step: 4
Training loss: 3.3518783313820735
Validation loss: 3.073846617416493

Epoch: 6| Step: 5
Training loss: 2.8825430395216696
Validation loss: 3.074214140108118

Epoch: 6| Step: 6
Training loss: 3.6828595721247264
Validation loss: 3.0761606792631007

Epoch: 6| Step: 7
Training loss: 3.303437702314995
Validation loss: 3.0738243507473624

Epoch: 6| Step: 8
Training loss: 2.957102685264536
Validation loss: 3.0728771982357546

Epoch: 6| Step: 9
Training loss: 3.900710916524945
Validation loss: 3.0750701472107114

Epoch: 6| Step: 10
Training loss: 3.4813545033300537
Validation loss: 3.074972881281261

Epoch: 6| Step: 11
Training loss: 3.504570837370874
Validation loss: 3.075350002615829

Epoch: 6| Step: 12
Training loss: 3.281164404343013
Validation loss: 3.072320409247904

Epoch: 6| Step: 13
Training loss: 3.0244262025002557
Validation loss: 3.074177824459071

Epoch: 109| Step: 0
Training loss: 3.935439524357849
Validation loss: 3.072996524685958

Epoch: 6| Step: 1
Training loss: 3.5630613185971143
Validation loss: 3.074489917562508

Epoch: 6| Step: 2
Training loss: 2.6504646577664626
Validation loss: 3.0715024674724334

Epoch: 6| Step: 3
Training loss: 3.1174411144675775
Validation loss: 3.0730463288769103

Epoch: 6| Step: 4
Training loss: 3.331261388247493
Validation loss: 3.075065593618485

Epoch: 6| Step: 5
Training loss: 3.7605862284267735
Validation loss: 3.072699518110988

Epoch: 6| Step: 6
Training loss: 2.756240093879458
Validation loss: 3.073262412989083

Epoch: 6| Step: 7
Training loss: 3.3825722976931467
Validation loss: 3.073306810832568

Epoch: 6| Step: 8
Training loss: 2.904134657330847
Validation loss: 3.0713278880303823

Epoch: 6| Step: 9
Training loss: 3.575793443675271
Validation loss: 3.0723272574188116

Epoch: 6| Step: 10
Training loss: 3.525549279021786
Validation loss: 3.072995710459983

Epoch: 6| Step: 11
Training loss: 3.1405776290737157
Validation loss: 3.073641492407178

Epoch: 6| Step: 12
Training loss: 3.746171013728434
Validation loss: 3.074810885178089

Epoch: 6| Step: 13
Training loss: 2.7847889876084637
Validation loss: 3.0746535748272033

Epoch: 110| Step: 0
Training loss: 2.7498781003810997
Validation loss: 3.075439405089656

Epoch: 6| Step: 1
Training loss: 3.7250948081016277
Validation loss: 3.073255048877724

Epoch: 6| Step: 2
Training loss: 3.3046098704497666
Validation loss: 3.0719871142597395

Epoch: 6| Step: 3
Training loss: 2.6997586495647456
Validation loss: 3.0740564122621796

Epoch: 6| Step: 4
Training loss: 3.094945195071804
Validation loss: 3.070120514392205

Epoch: 6| Step: 5
Training loss: 3.6049956469039985
Validation loss: 3.0708151134066717

Epoch: 6| Step: 6
Training loss: 2.3141865122018226
Validation loss: 3.0732810834515103

Epoch: 6| Step: 7
Training loss: 4.391440970733693
Validation loss: 3.072896992304275

Epoch: 6| Step: 8
Training loss: 3.2858064531940347
Validation loss: 3.0716091810911483

Epoch: 6| Step: 9
Training loss: 3.44613741386735
Validation loss: 3.0738737378648437

Epoch: 6| Step: 10
Training loss: 3.0122855082402626
Validation loss: 3.071566184268455

Epoch: 6| Step: 11
Training loss: 3.450526161429652
Validation loss: 3.067682003542881

Epoch: 6| Step: 12
Training loss: 3.660161200553616
Validation loss: 3.068439845119784

Epoch: 6| Step: 13
Training loss: 3.53025993038564
Validation loss: 3.067803674700322

Epoch: 111| Step: 0
Training loss: 3.6544728973256317
Validation loss: 3.0670471754750595

Epoch: 6| Step: 1
Training loss: 2.445077220578832
Validation loss: 3.0684827704544584

Epoch: 6| Step: 2
Training loss: 3.358864111088785
Validation loss: 3.066462411360316

Epoch: 6| Step: 3
Training loss: 3.8934946775535964
Validation loss: 3.0689544016191266

Epoch: 6| Step: 4
Training loss: 3.470540177572579
Validation loss: 3.069300277438234

Epoch: 6| Step: 5
Training loss: 3.774064100852198
Validation loss: 3.0676681092781948

Epoch: 6| Step: 6
Training loss: 3.3440343432875976
Validation loss: 3.069649493334288

Epoch: 6| Step: 7
Training loss: 2.7721558094245125
Validation loss: 3.0674979199039893

Epoch: 6| Step: 8
Training loss: 3.478664628467521
Validation loss: 3.0698602706507927

Epoch: 6| Step: 9
Training loss: 3.185110206074714
Validation loss: 3.0735554699436323

Epoch: 6| Step: 10
Training loss: 3.450450569253148
Validation loss: 3.0687962572436636

Epoch: 6| Step: 11
Training loss: 2.753801925522863
Validation loss: 3.0686719838336267

Epoch: 6| Step: 12
Training loss: 3.4662084117640966
Validation loss: 3.066493306525402

Epoch: 6| Step: 13
Training loss: 3.2868750902934987
Validation loss: 3.0666629255101667

Epoch: 112| Step: 0
Training loss: 3.0232905073683143
Validation loss: 3.0632163460002255

Epoch: 6| Step: 1
Training loss: 3.1430560519699924
Validation loss: 3.064608621685705

Epoch: 6| Step: 2
Training loss: 3.432492162996974
Validation loss: 3.0639260466588203

Epoch: 6| Step: 3
Training loss: 3.598112824965899
Validation loss: 3.062656860653849

Epoch: 6| Step: 4
Training loss: 2.9164811393223427
Validation loss: 3.062166846719067

Epoch: 6| Step: 5
Training loss: 4.158368710741348
Validation loss: 3.066136071523301

Epoch: 6| Step: 6
Training loss: 3.498902557525097
Validation loss: 3.0624230831181665

Epoch: 6| Step: 7
Training loss: 2.590056213593673
Validation loss: 3.062692208837004

Epoch: 6| Step: 8
Training loss: 3.395425097182409
Validation loss: 3.0639196390692716

Epoch: 6| Step: 9
Training loss: 3.150120439194842
Validation loss: 3.062498772800678

Epoch: 6| Step: 10
Training loss: 3.2672205773261345
Validation loss: 3.063204349688939

Epoch: 6| Step: 11
Training loss: 2.4624675535591414
Validation loss: 3.0612862479410143

Epoch: 6| Step: 12
Training loss: 3.707333647892301
Validation loss: 3.062592144020027

Epoch: 6| Step: 13
Training loss: 4.232294789277988
Validation loss: 3.05998303346959

Epoch: 113| Step: 0
Training loss: 2.915132464217629
Validation loss: 3.0617298148052767

Epoch: 6| Step: 1
Training loss: 3.1417371005014076
Validation loss: 3.0607897310994723

Epoch: 6| Step: 2
Training loss: 3.467738373476275
Validation loss: 3.0650729014699247

Epoch: 6| Step: 3
Training loss: 3.05731104119491
Validation loss: 3.062441666470059

Epoch: 6| Step: 4
Training loss: 3.1572116104560117
Validation loss: 3.0619227351037464

Epoch: 6| Step: 5
Training loss: 3.2762695297945728
Validation loss: 3.0627846802121135

Epoch: 6| Step: 6
Training loss: 3.951318863507272
Validation loss: 3.062174511259185

Epoch: 6| Step: 7
Training loss: 2.004697884988385
Validation loss: 3.0618499106054853

Epoch: 6| Step: 8
Training loss: 3.7292500207774033
Validation loss: 3.063096037626027

Epoch: 6| Step: 9
Training loss: 3.914488991897664
Validation loss: 3.066371490572031

Epoch: 6| Step: 10
Training loss: 3.2054842564326074
Validation loss: 3.0633729055229604

Epoch: 6| Step: 11
Training loss: 3.1309933981763405
Validation loss: 3.0602265735022103

Epoch: 6| Step: 12
Training loss: 3.587895143658695
Validation loss: 3.062452503009306

Epoch: 6| Step: 13
Training loss: 3.7448715746139496
Validation loss: 3.0600636752701367

Epoch: 114| Step: 0
Training loss: 3.211493450958117
Validation loss: 3.0649640749540756

Epoch: 6| Step: 1
Training loss: 3.3753450005415244
Validation loss: 3.0591414223236986

Epoch: 6| Step: 2
Training loss: 3.6960823918444032
Validation loss: 3.061831743144257

Epoch: 6| Step: 3
Training loss: 2.771760245337879
Validation loss: 3.0603108336411124

Epoch: 6| Step: 4
Training loss: 3.4502800316427837
Validation loss: 3.0584939500785757

Epoch: 6| Step: 5
Training loss: 3.5109709048411544
Validation loss: 3.060080599926089

Epoch: 6| Step: 6
Training loss: 3.045499050793447
Validation loss: 3.05835373048993

Epoch: 6| Step: 7
Training loss: 3.2376020614266814
Validation loss: 3.0565389261445954

Epoch: 6| Step: 8
Training loss: 3.2637948926733173
Validation loss: 3.0583025335912675

Epoch: 6| Step: 9
Training loss: 2.8658103026004222
Validation loss: 3.057580391327357

Epoch: 6| Step: 10
Training loss: 3.5139914553369582
Validation loss: 3.0565664207480427

Epoch: 6| Step: 11
Training loss: 4.1570704517978685
Validation loss: 3.0575917397817443

Epoch: 6| Step: 12
Training loss: 3.171020994176452
Validation loss: 3.0548452393189063

Epoch: 6| Step: 13
Training loss: 2.8755056517055784
Validation loss: 3.0553667018198687

Epoch: 115| Step: 0
Training loss: 3.1910183506231475
Validation loss: 3.0552602180227866

Epoch: 6| Step: 1
Training loss: 3.7891560021887907
Validation loss: 3.056120433468784

Epoch: 6| Step: 2
Training loss: 3.6077007687772737
Validation loss: 3.0537545979210887

Epoch: 6| Step: 3
Training loss: 4.404585720156998
Validation loss: 3.0567449220682654

Epoch: 6| Step: 4
Training loss: 2.8913085129387674
Validation loss: 3.053397652499872

Epoch: 6| Step: 5
Training loss: 2.940240596087065
Validation loss: 3.054583248502376

Epoch: 6| Step: 6
Training loss: 3.3807406170469476
Validation loss: 3.053983902476437

Epoch: 6| Step: 7
Training loss: 3.2675790005789325
Validation loss: 3.054037372748999

Epoch: 6| Step: 8
Training loss: 3.2038909740590777
Validation loss: 3.053814394399542

Epoch: 6| Step: 9
Training loss: 2.9892557387795
Validation loss: 3.0536171385629345

Epoch: 6| Step: 10
Training loss: 3.480409700896748
Validation loss: 3.0527130813364582

Epoch: 6| Step: 11
Training loss: 3.073319920519552
Validation loss: 3.053657600034119

Epoch: 6| Step: 12
Training loss: 2.799867105736259
Validation loss: 3.053599550101921

Epoch: 6| Step: 13
Training loss: 3.0652282395878125
Validation loss: 3.0528191820328363

Epoch: 116| Step: 0
Training loss: 2.835538978003365
Validation loss: 3.0534929862086617

Epoch: 6| Step: 1
Training loss: 3.3303653537235562
Validation loss: 3.056751170251775

Epoch: 6| Step: 2
Training loss: 3.4492661677003253
Validation loss: 3.057169226904365

Epoch: 6| Step: 3
Training loss: 2.8161232392101008
Validation loss: 3.057161950651526

Epoch: 6| Step: 4
Training loss: 2.7656128446667463
Validation loss: 3.076992338101477

Epoch: 6| Step: 5
Training loss: 3.187596039166684
Validation loss: 3.061529898672248

Epoch: 6| Step: 6
Training loss: 3.876128493849253
Validation loss: 3.0624411441052053

Epoch: 6| Step: 7
Training loss: 3.491673374093714
Validation loss: 3.059106786505128

Epoch: 6| Step: 8
Training loss: 2.8994188318312912
Validation loss: 3.0566250819529497

Epoch: 6| Step: 9
Training loss: 3.3934599806928567
Validation loss: 3.0520453644768963

Epoch: 6| Step: 10
Training loss: 3.9673334432157583
Validation loss: 3.0511814845584

Epoch: 6| Step: 11
Training loss: 3.7229249743152066
Validation loss: 3.0505809609209575

Epoch: 6| Step: 12
Training loss: 3.3587685680834447
Validation loss: 3.051906489993909

Epoch: 6| Step: 13
Training loss: 3.015007311557489
Validation loss: 3.050211281521455

Epoch: 117| Step: 0
Training loss: 3.609738022024103
Validation loss: 3.0525728918242336

Epoch: 6| Step: 1
Training loss: 3.084178413534345
Validation loss: 3.054275366139467

Epoch: 6| Step: 2
Training loss: 3.123041073028538
Validation loss: 3.055336893174825

Epoch: 6| Step: 3
Training loss: 4.218987352264102
Validation loss: 3.0551991248915127

Epoch: 6| Step: 4
Training loss: 2.9178940688129793
Validation loss: 3.053991069619016

Epoch: 6| Step: 5
Training loss: 2.968261196652878
Validation loss: 3.054895956236971

Epoch: 6| Step: 6
Training loss: 3.0582385873973745
Validation loss: 3.0522491640737357

Epoch: 6| Step: 7
Training loss: 3.7031633721146155
Validation loss: 3.054493436179315

Epoch: 6| Step: 8
Training loss: 3.1876537809488132
Validation loss: 3.0536402359622543

Epoch: 6| Step: 9
Training loss: 2.618954008254264
Validation loss: 3.0532300376106547

Epoch: 6| Step: 10
Training loss: 3.409754359103997
Validation loss: 3.0506297932055815

Epoch: 6| Step: 11
Training loss: 3.7210732263435164
Validation loss: 3.0484617919916066

Epoch: 6| Step: 12
Training loss: 3.536659620771182
Validation loss: 3.050241350374673

Epoch: 6| Step: 13
Training loss: 2.7958573349340785
Validation loss: 3.049048326769183

Epoch: 118| Step: 0
Training loss: 3.736347778715298
Validation loss: 3.050790063291398

Epoch: 6| Step: 1
Training loss: 3.267979115600343
Validation loss: 3.049993955988471

Epoch: 6| Step: 2
Training loss: 3.146064867673794
Validation loss: 3.0497300235463336

Epoch: 6| Step: 3
Training loss: 3.6177419151082426
Validation loss: 3.051030164427429

Epoch: 6| Step: 4
Training loss: 3.9636603933724266
Validation loss: 3.049652711451162

Epoch: 6| Step: 5
Training loss: 3.7054901939574267
Validation loss: 3.049555050115844

Epoch: 6| Step: 6
Training loss: 3.28035425947991
Validation loss: 3.0483441929560495

Epoch: 6| Step: 7
Training loss: 2.854850482933778
Validation loss: 3.0495517866698303

Epoch: 6| Step: 8
Training loss: 3.4799024675667067
Validation loss: 3.0476714635879043

Epoch: 6| Step: 9
Training loss: 3.146101546485094
Validation loss: 3.0483613063046597

Epoch: 6| Step: 10
Training loss: 3.225166221888955
Validation loss: 3.0461414734165655

Epoch: 6| Step: 11
Training loss: 2.5507160079113347
Validation loss: 3.048245051550731

Epoch: 6| Step: 12
Training loss: 3.1154901381587385
Validation loss: 3.0464961091653686

Epoch: 6| Step: 13
Training loss: 2.9090315111013436
Validation loss: 3.04592894703467

Epoch: 119| Step: 0
Training loss: 3.1077735649113367
Validation loss: 3.0450764225824134

Epoch: 6| Step: 1
Training loss: 3.5918826351745077
Validation loss: 3.0481620869821304

Epoch: 6| Step: 2
Training loss: 3.447464666482885
Validation loss: 3.044391824451034

Epoch: 6| Step: 3
Training loss: 2.5470214052772366
Validation loss: 3.0443306033196547

Epoch: 6| Step: 4
Training loss: 2.6771055188478114
Validation loss: 3.046493226169081

Epoch: 6| Step: 5
Training loss: 3.1200632392147467
Validation loss: 3.044854495503514

Epoch: 6| Step: 6
Training loss: 4.219600111468859
Validation loss: 3.0441195135634773

Epoch: 6| Step: 7
Training loss: 3.435030518330985
Validation loss: 3.0451502021720986

Epoch: 6| Step: 8
Training loss: 3.371788050650322
Validation loss: 3.0441576447187044

Epoch: 6| Step: 9
Training loss: 3.4800337360106113
Validation loss: 3.046018226636065

Epoch: 6| Step: 10
Training loss: 3.0026333695265617
Validation loss: 3.0465799403879936

Epoch: 6| Step: 11
Training loss: 3.1699697099556223
Validation loss: 3.0446001612613567

Epoch: 6| Step: 12
Training loss: 3.774431622897378
Validation loss: 3.0462726966365543

Epoch: 6| Step: 13
Training loss: 2.978743427507879
Validation loss: 3.044666864358136

Epoch: 120| Step: 0
Training loss: 3.5037690713113676
Validation loss: 3.0451137133387856

Epoch: 6| Step: 1
Training loss: 3.4279248133084543
Validation loss: 3.044469948004777

Epoch: 6| Step: 2
Training loss: 4.288061139724187
Validation loss: 3.0447897776879547

Epoch: 6| Step: 3
Training loss: 2.361266432745859
Validation loss: 3.044368776461864

Epoch: 6| Step: 4
Training loss: 3.395733198003984
Validation loss: 3.043789979779471

Epoch: 6| Step: 5
Training loss: 3.3893357036211125
Validation loss: 3.0445495296562104

Epoch: 6| Step: 6
Training loss: 3.9621966465497613
Validation loss: 3.04361687000769

Epoch: 6| Step: 7
Training loss: 3.206213973588412
Validation loss: 3.041978790264763

Epoch: 6| Step: 8
Training loss: 3.2188150343759894
Validation loss: 3.045465493884835

Epoch: 6| Step: 9
Training loss: 3.6005466046214125
Validation loss: 3.0419985148646633

Epoch: 6| Step: 10
Training loss: 2.7240193483558968
Validation loss: 3.0420161164654345

Epoch: 6| Step: 11
Training loss: 3.2081227088918554
Validation loss: 3.040527592902759

Epoch: 6| Step: 12
Training loss: 2.9500579246394514
Validation loss: 3.0428378881211966

Epoch: 6| Step: 13
Training loss: 1.990426875005679
Validation loss: 3.0389335215439646

Epoch: 121| Step: 0
Training loss: 3.2343270855731596
Validation loss: 3.045481851492939

Epoch: 6| Step: 1
Training loss: 3.461184249589573
Validation loss: 3.0444704069299977

Epoch: 6| Step: 2
Training loss: 3.985137268152818
Validation loss: 3.047937989106545

Epoch: 6| Step: 3
Training loss: 3.3234387568591153
Validation loss: 3.0486330423724772

Epoch: 6| Step: 4
Training loss: 2.984425649163219
Validation loss: 3.0454820072231414

Epoch: 6| Step: 5
Training loss: 3.0897650437391992
Validation loss: 3.0479419961355605

Epoch: 6| Step: 6
Training loss: 2.646745979920733
Validation loss: 3.045441664416671

Epoch: 6| Step: 7
Training loss: 3.112720166121678
Validation loss: 3.0474733701680434

Epoch: 6| Step: 8
Training loss: 3.9390480994536703
Validation loss: 3.041071719113167

Epoch: 6| Step: 9
Training loss: 3.833209091052819
Validation loss: 3.0407250225509226

Epoch: 6| Step: 10
Training loss: 3.1104890754040606
Validation loss: 3.039443304338906

Epoch: 6| Step: 11
Training loss: 3.6969867808709527
Validation loss: 3.0413331458459734

Epoch: 6| Step: 12
Training loss: 2.3360384405774903
Validation loss: 3.041227677903004

Epoch: 6| Step: 13
Training loss: 3.0115466433577995
Validation loss: 3.036890298094284

Epoch: 122| Step: 0
Training loss: 2.75853791030464
Validation loss: 3.0375024207847527

Epoch: 6| Step: 1
Training loss: 3.4450576930205026
Validation loss: 3.0403767096741032

Epoch: 6| Step: 2
Training loss: 3.026539239119522
Validation loss: 3.0368407603197842

Epoch: 6| Step: 3
Training loss: 3.3443304966229173
Validation loss: 3.0385212631277665

Epoch: 6| Step: 4
Training loss: 3.4454309698310737
Validation loss: 3.037263673560336

Epoch: 6| Step: 5
Training loss: 3.203431798617088
Validation loss: 3.0393495441795637

Epoch: 6| Step: 6
Training loss: 3.8414331912728477
Validation loss: 3.03996307925422

Epoch: 6| Step: 7
Training loss: 3.475033678948194
Validation loss: 3.0378420106986503

Epoch: 6| Step: 8
Training loss: 3.437281237490326
Validation loss: 3.0347637104750773

Epoch: 6| Step: 9
Training loss: 2.9132766277576296
Validation loss: 3.0369723389823746

Epoch: 6| Step: 10
Training loss: 2.880104674715295
Validation loss: 3.034182164805911

Epoch: 6| Step: 11
Training loss: 4.101591796770369
Validation loss: 3.0355212041197124

Epoch: 6| Step: 12
Training loss: 3.3195664947786234
Validation loss: 3.034658381697312

Epoch: 6| Step: 13
Training loss: 2.4507894878838776
Validation loss: 3.0375351946701046

Epoch: 123| Step: 0
Training loss: 4.398572794322395
Validation loss: 3.037611883437303

Epoch: 6| Step: 1
Training loss: 3.256742672249675
Validation loss: 3.0378951633946283

Epoch: 6| Step: 2
Training loss: 2.7636881797498276
Validation loss: 3.03422039380706

Epoch: 6| Step: 3
Training loss: 3.1801262630131615
Validation loss: 3.035480235707887

Epoch: 6| Step: 4
Training loss: 2.9297501620902877
Validation loss: 3.03733993365775

Epoch: 6| Step: 5
Training loss: 3.3721022705189942
Validation loss: 3.0369710449100245

Epoch: 6| Step: 6
Training loss: 2.9843225923899745
Validation loss: 3.037914975268214

Epoch: 6| Step: 7
Training loss: 3.3938719500976564
Validation loss: 3.0351456293692665

Epoch: 6| Step: 8
Training loss: 3.1019010190931264
Validation loss: 3.0360193531348476

Epoch: 6| Step: 9
Training loss: 3.0904919972744285
Validation loss: 3.0324436514733084

Epoch: 6| Step: 10
Training loss: 3.2294409522602736
Validation loss: 3.0345947567252045

Epoch: 6| Step: 11
Training loss: 3.4683569608143556
Validation loss: 3.03282195640577

Epoch: 6| Step: 12
Training loss: 3.771478306248354
Validation loss: 3.0331547762209463

Epoch: 6| Step: 13
Training loss: 2.817452880411206
Validation loss: 3.036187838359977

Epoch: 124| Step: 0
Training loss: 3.4952313771423977
Validation loss: 3.030366748392084

Epoch: 6| Step: 1
Training loss: 2.829112180953925
Validation loss: 3.028850099729133

Epoch: 6| Step: 2
Training loss: 3.000540048945714
Validation loss: 3.034203737221958

Epoch: 6| Step: 3
Training loss: 3.612507175319634
Validation loss: 3.0351813140006145

Epoch: 6| Step: 4
Training loss: 2.899307983965945
Validation loss: 3.0317956779821387

Epoch: 6| Step: 5
Training loss: 3.6425255002063226
Validation loss: 3.0314429843010062

Epoch: 6| Step: 6
Training loss: 3.238025613778909
Validation loss: 3.0314206192785753

Epoch: 6| Step: 7
Training loss: 3.5516238246310676
Validation loss: 3.0301922008704105

Epoch: 6| Step: 8
Training loss: 2.978106080962828
Validation loss: 3.032502402269898

Epoch: 6| Step: 9
Training loss: 3.294009586072452
Validation loss: 3.0316832748349003

Epoch: 6| Step: 10
Training loss: 3.521699937939185
Validation loss: 3.035283709873188

Epoch: 6| Step: 11
Training loss: 3.3780554609878397
Validation loss: 3.031162610415487

Epoch: 6| Step: 12
Training loss: 3.507093598034004
Validation loss: 3.0326956593790912

Epoch: 6| Step: 13
Training loss: 3.0582763195353784
Validation loss: 3.0346404316052507

Epoch: 125| Step: 0
Training loss: 3.2084357175137495
Validation loss: 3.030859941243172

Epoch: 6| Step: 1
Training loss: 3.137362327442788
Validation loss: 3.033064091022445

Epoch: 6| Step: 2
Training loss: 3.744900860562845
Validation loss: 3.038811114581777

Epoch: 6| Step: 3
Training loss: 3.4878149457802805
Validation loss: 3.040759541470582

Epoch: 6| Step: 4
Training loss: 2.707862627255518
Validation loss: 3.0410761516336344

Epoch: 6| Step: 5
Training loss: 4.398230214087626
Validation loss: 3.0384085687909113

Epoch: 6| Step: 6
Training loss: 3.5344798752987123
Validation loss: 3.0354639838251605

Epoch: 6| Step: 7
Training loss: 3.1893332202469074
Validation loss: 3.0297711926932145

Epoch: 6| Step: 8
Training loss: 3.1024374700572506
Validation loss: 3.0274204547438712

Epoch: 6| Step: 9
Training loss: 3.2805317410487467
Validation loss: 3.0296426411787265

Epoch: 6| Step: 10
Training loss: 3.0252705224506435
Validation loss: 3.02665813429483

Epoch: 6| Step: 11
Training loss: 2.9929284356174537
Validation loss: 3.027366439834867

Epoch: 6| Step: 12
Training loss: 2.4880077744758053
Validation loss: 3.0250365218192905

Epoch: 6| Step: 13
Training loss: 3.7989581637447407
Validation loss: 3.0260971507895897

Epoch: 126| Step: 0
Training loss: 3.3451664856675665
Validation loss: 3.02652809187502

Epoch: 6| Step: 1
Training loss: 3.5931488861229615
Validation loss: 3.028597107351417

Epoch: 6| Step: 2
Training loss: 3.320874981078573
Validation loss: 3.025940318121834

Epoch: 6| Step: 3
Training loss: 3.2863520601544276
Validation loss: 3.026041694906426

Epoch: 6| Step: 4
Training loss: 3.8111935237454753
Validation loss: 3.026562104395151

Epoch: 6| Step: 5
Training loss: 3.9122992710869973
Validation loss: 3.0271469999665315

Epoch: 6| Step: 6
Training loss: 3.134893701141405
Validation loss: 3.028078651951882

Epoch: 6| Step: 7
Training loss: 2.679442992329844
Validation loss: 3.0244514011945607

Epoch: 6| Step: 8
Training loss: 3.7338379030764304
Validation loss: 3.0275709861766367

Epoch: 6| Step: 9
Training loss: 3.046853715871172
Validation loss: 3.0258118004164216

Epoch: 6| Step: 10
Training loss: 2.613179705233546
Validation loss: 3.0250025531646494

Epoch: 6| Step: 11
Training loss: 3.5891883094004573
Validation loss: 3.0256934040826113

Epoch: 6| Step: 12
Training loss: 2.992213953762794
Validation loss: 3.029081265883489

Epoch: 6| Step: 13
Training loss: 2.4071891240116066
Validation loss: 3.0292969630133686

Epoch: 127| Step: 0
Training loss: 2.8514019646592272
Validation loss: 3.0245815820629582

Epoch: 6| Step: 1
Training loss: 3.5152036965442335
Validation loss: 3.0291803447496215

Epoch: 6| Step: 2
Training loss: 3.2062529387283987
Validation loss: 3.0248614912833247

Epoch: 6| Step: 3
Training loss: 3.373353627210445
Validation loss: 3.0286788074535678

Epoch: 6| Step: 4
Training loss: 3.292591946765538
Validation loss: 3.0259631133682285

Epoch: 6| Step: 5
Training loss: 3.381440410787832
Validation loss: 3.02738745788503

Epoch: 6| Step: 6
Training loss: 3.837135392055872
Validation loss: 3.025515135732732

Epoch: 6| Step: 7
Training loss: 3.1963652949299792
Validation loss: 3.0276211667382125

Epoch: 6| Step: 8
Training loss: 3.0135041522106163
Validation loss: 3.028014379048052

Epoch: 6| Step: 9
Training loss: 3.309639037120253
Validation loss: 3.0242142159360776

Epoch: 6| Step: 10
Training loss: 3.3739483925717217
Validation loss: 3.0240743583790684

Epoch: 6| Step: 11
Training loss: 2.749292022431097
Validation loss: 3.0252891899598473

Epoch: 6| Step: 12
Training loss: 3.1479228240347794
Validation loss: 3.022059435703398

Epoch: 6| Step: 13
Training loss: 4.069624302650268
Validation loss: 3.020544977113539

Epoch: 128| Step: 0
Training loss: 3.407005996103164
Validation loss: 3.0236135057783433

Epoch: 6| Step: 1
Training loss: 2.8752491055251617
Validation loss: 3.0229074375406366

Epoch: 6| Step: 2
Training loss: 3.6426590243194674
Validation loss: 3.0249534156552818

Epoch: 6| Step: 3
Training loss: 3.611671938913602
Validation loss: 3.027320766990239

Epoch: 6| Step: 4
Training loss: 3.0129743400466085
Validation loss: 3.0308170328656017

Epoch: 6| Step: 5
Training loss: 2.715450433139977
Validation loss: 3.0292094663073352

Epoch: 6| Step: 6
Training loss: 3.1828912065125814
Validation loss: 3.0282715191986136

Epoch: 6| Step: 7
Training loss: 3.6044122836409027
Validation loss: 3.026643909403846

Epoch: 6| Step: 8
Training loss: 3.2276316942550562
Validation loss: 3.0270719558486987

Epoch: 6| Step: 9
Training loss: 3.8473619067697022
Validation loss: 3.0228180351004843

Epoch: 6| Step: 10
Training loss: 3.109858029673007
Validation loss: 3.017832932249295

Epoch: 6| Step: 11
Training loss: 3.667120139661827
Validation loss: 3.0205990953333735

Epoch: 6| Step: 12
Training loss: 2.4293850529577785
Validation loss: 3.022838729426207

Epoch: 6| Step: 13
Training loss: 3.6284568352299513
Validation loss: 3.024575262337724

Epoch: 129| Step: 0
Training loss: 3.3305829781350837
Validation loss: 3.028215820375559

Epoch: 6| Step: 1
Training loss: 3.8700825653337163
Validation loss: 3.0199813580523367

Epoch: 6| Step: 2
Training loss: 2.889716093116401
Validation loss: 3.021593747667483

Epoch: 6| Step: 3
Training loss: 3.405316146088285
Validation loss: 3.0225949834943893

Epoch: 6| Step: 4
Training loss: 3.2066397387298538
Validation loss: 3.0183632998053853

Epoch: 6| Step: 5
Training loss: 2.9485080696397894
Validation loss: 3.0170678511432096

Epoch: 6| Step: 6
Training loss: 3.671247193254561
Validation loss: 3.017882421002081

Epoch: 6| Step: 7
Training loss: 3.1190858954379754
Validation loss: 3.018009946983971

Epoch: 6| Step: 8
Training loss: 3.3383814415692616
Validation loss: 3.0186892339165325

Epoch: 6| Step: 9
Training loss: 3.135151054478781
Validation loss: 3.021972733872514

Epoch: 6| Step: 10
Training loss: 2.4458529816530934
Validation loss: 3.02093474515281

Epoch: 6| Step: 11
Training loss: 3.4923366028362395
Validation loss: 3.0239784015706843

Epoch: 6| Step: 12
Training loss: 4.045888419648773
Validation loss: 3.020140256430186

Epoch: 6| Step: 13
Training loss: 2.4128411916492527
Validation loss: 3.022769795849055

Epoch: 130| Step: 0
Training loss: 3.414019202475019
Validation loss: 3.0204867109303057

Epoch: 6| Step: 1
Training loss: 2.779194189923834
Validation loss: 3.016399990623403

Epoch: 6| Step: 2
Training loss: 3.7470060476718023
Validation loss: 3.0153703164939465

Epoch: 6| Step: 3
Training loss: 3.5996907101330478
Validation loss: 3.0174332411329745

Epoch: 6| Step: 4
Training loss: 3.498883205438949
Validation loss: 3.0162929547727027

Epoch: 6| Step: 5
Training loss: 3.672163931659234
Validation loss: 3.019393838176222

Epoch: 6| Step: 6
Training loss: 3.3351815503988824
Validation loss: 3.021831712108277

Epoch: 6| Step: 7
Training loss: 2.6943439014810715
Validation loss: 3.019177714602263

Epoch: 6| Step: 8
Training loss: 3.0583502232832713
Validation loss: 3.016952576926704

Epoch: 6| Step: 9
Training loss: 3.7290153827917707
Validation loss: 3.0207276056703374

Epoch: 6| Step: 10
Training loss: 3.0765141178664597
Validation loss: 3.01983006457574

Epoch: 6| Step: 11
Training loss: 3.379081800894834
Validation loss: 3.0171368640130884

Epoch: 6| Step: 12
Training loss: 2.979995469979549
Validation loss: 3.0151113414522626

Epoch: 6| Step: 13
Training loss: 2.4208036945080345
Validation loss: 3.01626210722228

Epoch: 131| Step: 0
Training loss: 3.336688133676268
Validation loss: 3.018703322195241

Epoch: 6| Step: 1
Training loss: 3.617264221564192
Validation loss: 3.014121017475313

Epoch: 6| Step: 2
Training loss: 3.197770868181556
Validation loss: 3.016001387178475

Epoch: 6| Step: 3
Training loss: 2.64428078664144
Validation loss: 3.0152377645562622

Epoch: 6| Step: 4
Training loss: 3.324662534180954
Validation loss: 3.012116710754292

Epoch: 6| Step: 5
Training loss: 2.620317824647756
Validation loss: 3.011352842001276

Epoch: 6| Step: 6
Training loss: 3.1241754588480553
Validation loss: 3.0104706632314304

Epoch: 6| Step: 7
Training loss: 3.123247494435723
Validation loss: 3.013591411590568

Epoch: 6| Step: 8
Training loss: 2.9978480568237207
Validation loss: 3.013167502801185

Epoch: 6| Step: 9
Training loss: 3.4357815695400817
Validation loss: 3.01226173629282

Epoch: 6| Step: 10
Training loss: 4.029029648721677
Validation loss: 3.01923585490669

Epoch: 6| Step: 11
Training loss: 3.5741728566042688
Validation loss: 3.0138891538377894

Epoch: 6| Step: 12
Training loss: 2.9521327698165947
Validation loss: 3.019348049826677

Epoch: 6| Step: 13
Training loss: 4.122249726794653
Validation loss: 3.0165346127491186

Epoch: 132| Step: 0
Training loss: 2.8639549722168716
Validation loss: 3.0158962548780766

Epoch: 6| Step: 1
Training loss: 3.403996553376691
Validation loss: 3.01465162222595

Epoch: 6| Step: 2
Training loss: 3.4764279457370977
Validation loss: 3.0096545141184436

Epoch: 6| Step: 3
Training loss: 3.6591416360278
Validation loss: 3.0118737058338385

Epoch: 6| Step: 4
Training loss: 3.685620362277426
Validation loss: 3.010807488165419

Epoch: 6| Step: 5
Training loss: 3.6710714556692294
Validation loss: 3.0106434461849014

Epoch: 6| Step: 6
Training loss: 2.7837064374950473
Validation loss: 3.011472045605247

Epoch: 6| Step: 7
Training loss: 2.8241163475286677
Validation loss: 3.0104085146687205

Epoch: 6| Step: 8
Training loss: 3.2838248186768886
Validation loss: 3.0116045955892012

Epoch: 6| Step: 9
Training loss: 3.650893371153386
Validation loss: 3.010717538238028

Epoch: 6| Step: 10
Training loss: 3.3295554368937355
Validation loss: 3.01154585593254

Epoch: 6| Step: 11
Training loss: 3.249584171395981
Validation loss: 3.0085085466854973

Epoch: 6| Step: 12
Training loss: 2.952068159934394
Validation loss: 3.0096446050473302

Epoch: 6| Step: 13
Training loss: 2.7114653059793676
Validation loss: 3.0091731969367594

Epoch: 133| Step: 0
Training loss: 1.994741620132356
Validation loss: 3.015111202008963

Epoch: 6| Step: 1
Training loss: 3.7577871214709555
Validation loss: 3.01852270631259

Epoch: 6| Step: 2
Training loss: 3.7724911468583993
Validation loss: 3.027671578473961

Epoch: 6| Step: 3
Training loss: 3.240762935340407
Validation loss: 3.0311992891782933

Epoch: 6| Step: 4
Training loss: 3.3407014158267767
Validation loss: 3.0317550558115536

Epoch: 6| Step: 5
Training loss: 3.3077493826457824
Validation loss: 3.025620629444586

Epoch: 6| Step: 6
Training loss: 2.628954950706272
Validation loss: 3.030231867683649

Epoch: 6| Step: 7
Training loss: 2.5489697413363963
Validation loss: 3.027066946404877

Epoch: 6| Step: 8
Training loss: 3.2496509364547554
Validation loss: 3.0214403746916783

Epoch: 6| Step: 9
Training loss: 4.431380014166699
Validation loss: 3.0197011153272606

Epoch: 6| Step: 10
Training loss: 3.0683301587962966
Validation loss: 3.0067607539308856

Epoch: 6| Step: 11
Training loss: 4.022639341720753
Validation loss: 3.007693510201625

Epoch: 6| Step: 12
Training loss: 3.113998119953938
Validation loss: 3.0095270591516656

Epoch: 6| Step: 13
Training loss: 2.4253854228999314
Validation loss: 3.0101449813106584

Epoch: 134| Step: 0
Training loss: 2.5830804536985568
Validation loss: 3.0205347481484055

Epoch: 6| Step: 1
Training loss: 3.3427722963224755
Validation loss: 3.022393868166212

Epoch: 6| Step: 2
Training loss: 3.9531838635069083
Validation loss: 3.016854783277924

Epoch: 6| Step: 3
Training loss: 2.6482099137096955
Validation loss: 3.011402737759341

Epoch: 6| Step: 4
Training loss: 4.059558449021936
Validation loss: 3.007781401826236

Epoch: 6| Step: 5
Training loss: 3.693476085543593
Validation loss: 3.0074833865003443

Epoch: 6| Step: 6
Training loss: 3.361878070251912
Validation loss: 3.0082718556880494

Epoch: 6| Step: 7
Training loss: 3.550685902271125
Validation loss: 3.006685998215695

Epoch: 6| Step: 8
Training loss: 3.199787168577675
Validation loss: 3.0084236162377875

Epoch: 6| Step: 9
Training loss: 3.5325547230147407
Validation loss: 3.0075741483134664

Epoch: 6| Step: 10
Training loss: 2.5495105984353983
Validation loss: 3.0053605312154703

Epoch: 6| Step: 11
Training loss: 2.354883529309887
Validation loss: 3.008305156810899

Epoch: 6| Step: 12
Training loss: 3.481554061239815
Validation loss: 3.010049758342868

Epoch: 6| Step: 13
Training loss: 3.0701579668986785
Validation loss: 3.0149868636339217

Epoch: 135| Step: 0
Training loss: 3.531961960040115
Validation loss: 3.01781037801427

Epoch: 6| Step: 1
Training loss: 2.6934576313998324
Validation loss: 3.007361982315558

Epoch: 6| Step: 2
Training loss: 2.831969119738739
Validation loss: 3.0159906837947497

Epoch: 6| Step: 3
Training loss: 3.41851195460315
Validation loss: 3.014270149760807

Epoch: 6| Step: 4
Training loss: 4.033010645376808
Validation loss: 3.018789092058574

Epoch: 6| Step: 5
Training loss: 3.330201839710754
Validation loss: 3.0110738310703153

Epoch: 6| Step: 6
Training loss: 3.2081204793761833
Validation loss: 3.0116483071678974

Epoch: 6| Step: 7
Training loss: 3.135959633148958
Validation loss: 3.003682424752427

Epoch: 6| Step: 8
Training loss: 2.273790260029813
Validation loss: 3.004124547489511

Epoch: 6| Step: 9
Training loss: 3.3973196010681357
Validation loss: 3.0028596582991933

Epoch: 6| Step: 10
Training loss: 3.8910345758153357
Validation loss: 3.0042416203883984

Epoch: 6| Step: 11
Training loss: 3.1351525754167975
Validation loss: 3.0012695470182624

Epoch: 6| Step: 12
Training loss: 3.3861642491384782
Validation loss: 3.0003251357592986

Epoch: 6| Step: 13
Training loss: 3.3323985855456693
Validation loss: 3.0018693592803998

Epoch: 136| Step: 0
Training loss: 3.7410874312767715
Validation loss: 3.002270990909937

Epoch: 6| Step: 1
Training loss: 3.764802961728171
Validation loss: 3.0030761614730124

Epoch: 6| Step: 2
Training loss: 3.8647012752553658
Validation loss: 3.001051311797266

Epoch: 6| Step: 3
Training loss: 3.012278068250245
Validation loss: 3.0037688522549875

Epoch: 6| Step: 4
Training loss: 3.400077616983717
Validation loss: 3.002473435348908

Epoch: 6| Step: 5
Training loss: 3.4500975995839993
Validation loss: 2.9996833736728106

Epoch: 6| Step: 6
Training loss: 3.2806044170528277
Validation loss: 3.0057168261909575

Epoch: 6| Step: 7
Training loss: 3.3866310328263456
Validation loss: 3.004618891754458

Epoch: 6| Step: 8
Training loss: 3.0840105052031865
Validation loss: 3.0033933187010637

Epoch: 6| Step: 9
Training loss: 2.142182945730765
Validation loss: 3.0031892921622374

Epoch: 6| Step: 10
Training loss: 4.072800708625775
Validation loss: 3.0031025748078086

Epoch: 6| Step: 11
Training loss: 2.239215755608377
Validation loss: 3.002188303172327

Epoch: 6| Step: 12
Training loss: 2.7953208995712084
Validation loss: 3.0059678612233403

Epoch: 6| Step: 13
Training loss: 2.8054228007399997
Validation loss: 3.003606564782953

Epoch: 137| Step: 0
Training loss: 2.5585582468612644
Validation loss: 3.0020426424068694

Epoch: 6| Step: 1
Training loss: 3.1959684486789244
Validation loss: 3.008855844635693

Epoch: 6| Step: 2
Training loss: 4.005608917694496
Validation loss: 3.004681748787885

Epoch: 6| Step: 3
Training loss: 3.2694573069315562
Validation loss: 3.0112248885068773

Epoch: 6| Step: 4
Training loss: 3.1813200337733387
Validation loss: 3.012725922569352

Epoch: 6| Step: 5
Training loss: 3.469361672297659
Validation loss: 3.0048991248419323

Epoch: 6| Step: 6
Training loss: 2.8624970948316997
Validation loss: 2.999469564913545

Epoch: 6| Step: 7
Training loss: 2.768267559791281
Validation loss: 3.002488215333188

Epoch: 6| Step: 8
Training loss: 3.076405311083298
Validation loss: 3.0004389195684937

Epoch: 6| Step: 9
Training loss: 3.4114153133718
Validation loss: 2.9982965548505036

Epoch: 6| Step: 10
Training loss: 3.378631192516636
Validation loss: 2.999111459262785

Epoch: 6| Step: 11
Training loss: 3.7130082627011105
Validation loss: 2.996947290616072

Epoch: 6| Step: 12
Training loss: 3.3865435949876614
Validation loss: 2.998739124567965

Epoch: 6| Step: 13
Training loss: 3.3916770603729876
Validation loss: 2.9967620801988257

Epoch: 138| Step: 0
Training loss: 3.032359284031761
Validation loss: 2.9999133442767967

Epoch: 6| Step: 1
Training loss: 3.002177084297893
Validation loss: 3.001186859878087

Epoch: 6| Step: 2
Training loss: 2.9862910805419838
Validation loss: 2.999717934142544

Epoch: 6| Step: 3
Training loss: 4.117121252580165
Validation loss: 2.9955894374243774

Epoch: 6| Step: 4
Training loss: 3.4315414110408864
Validation loss: 2.99484877494017

Epoch: 6| Step: 5
Training loss: 4.157651736575165
Validation loss: 2.994512252435091

Epoch: 6| Step: 6
Training loss: 2.5814551837643225
Validation loss: 2.9967562732615285

Epoch: 6| Step: 7
Training loss: 3.3639917631105147
Validation loss: 2.9965785574025547

Epoch: 6| Step: 8
Training loss: 3.231893425931175
Validation loss: 2.9953707849413664

Epoch: 6| Step: 9
Training loss: 2.582279810866058
Validation loss: 2.9961698224329245

Epoch: 6| Step: 10
Training loss: 3.920742403300935
Validation loss: 2.9930121971745702

Epoch: 6| Step: 11
Training loss: 2.2194733850817365
Validation loss: 2.9946015368329384

Epoch: 6| Step: 12
Training loss: 3.438101143725604
Validation loss: 2.992968209137223

Epoch: 6| Step: 13
Training loss: 3.12851502143091
Validation loss: 2.993477322437621

Epoch: 139| Step: 0
Training loss: 2.994478230314285
Validation loss: 2.994029470275026

Epoch: 6| Step: 1
Training loss: 3.6853173472015897
Validation loss: 2.9950696533502867

Epoch: 6| Step: 2
Training loss: 3.8050757490079583
Validation loss: 2.9902451019899527

Epoch: 6| Step: 3
Training loss: 2.8723583524488743
Validation loss: 2.993820369911678

Epoch: 6| Step: 4
Training loss: 3.5070783700749626
Validation loss: 2.9933479231065863

Epoch: 6| Step: 5
Training loss: 3.6674021647899027
Validation loss: 2.993200961942452

Epoch: 6| Step: 6
Training loss: 2.708232046336314
Validation loss: 2.993641250028908

Epoch: 6| Step: 7
Training loss: 3.3020297426193146
Validation loss: 2.9976798694404896

Epoch: 6| Step: 8
Training loss: 3.062410781494981
Validation loss: 2.9932366224634195

Epoch: 6| Step: 9
Training loss: 2.947057556128781
Validation loss: 2.9944949948610735

Epoch: 6| Step: 10
Training loss: 3.629316325264383
Validation loss: 2.9962155440254525

Epoch: 6| Step: 11
Training loss: 3.1120918711067938
Validation loss: 2.9969843145600525

Epoch: 6| Step: 12
Training loss: 2.870482669078321
Validation loss: 2.9993647292436902

Epoch: 6| Step: 13
Training loss: 3.47097459546076
Validation loss: 3.0079958905215634

Epoch: 140| Step: 0
Training loss: 2.9110487830144387
Validation loss: 2.9997282118720316

Epoch: 6| Step: 1
Training loss: 3.49486096347075
Validation loss: 2.9973254193877454

Epoch: 6| Step: 2
Training loss: 3.983148363572523
Validation loss: 2.994590336620575

Epoch: 6| Step: 3
Training loss: 2.6054404741894754
Validation loss: 3.001508175578453

Epoch: 6| Step: 4
Training loss: 3.076985879403866
Validation loss: 2.999469517050457

Epoch: 6| Step: 5
Training loss: 3.3628695033240166
Validation loss: 2.995908533880183

Epoch: 6| Step: 6
Training loss: 2.508639665656854
Validation loss: 2.992917543504815

Epoch: 6| Step: 7
Training loss: 3.679333323545111
Validation loss: 2.99049648422346

Epoch: 6| Step: 8
Training loss: 3.570524847948735
Validation loss: 2.9906952236542224

Epoch: 6| Step: 9
Training loss: 3.334896738263842
Validation loss: 2.992773994502248

Epoch: 6| Step: 10
Training loss: 3.689090191916131
Validation loss: 2.988453977631543

Epoch: 6| Step: 11
Training loss: 3.0904585158015996
Validation loss: 2.9893212395225315

Epoch: 6| Step: 12
Training loss: 2.8176001188942115
Validation loss: 2.9901049244946396

Epoch: 6| Step: 13
Training loss: 3.2975830474876786
Validation loss: 2.9899168791387396

Epoch: 141| Step: 0
Training loss: 3.732237519362874
Validation loss: 2.9882372326430358

Epoch: 6| Step: 1
Training loss: 3.4324634067171274
Validation loss: 2.989104998258746

Epoch: 6| Step: 2
Training loss: 2.276444272209425
Validation loss: 2.990980477781123

Epoch: 6| Step: 3
Training loss: 3.388058442540624
Validation loss: 2.991404466030175

Epoch: 6| Step: 4
Training loss: 2.5371029848601205
Validation loss: 2.989292655591915

Epoch: 6| Step: 5
Training loss: 3.3285464884035894
Validation loss: 2.9920161437630073

Epoch: 6| Step: 6
Training loss: 2.9724347186158866
Validation loss: 2.990338285952078

Epoch: 6| Step: 7
Training loss: 3.4956147105466076
Validation loss: 2.9884867009396503

Epoch: 6| Step: 8
Training loss: 3.1354409319338936
Validation loss: 2.987758840512906

Epoch: 6| Step: 9
Training loss: 3.581283840798472
Validation loss: 2.9880225344984606

Epoch: 6| Step: 10
Training loss: 2.712531684655276
Validation loss: 2.987141375101407

Epoch: 6| Step: 11
Training loss: 3.308583517407804
Validation loss: 2.987113237190545

Epoch: 6| Step: 12
Training loss: 4.148696115482329
Validation loss: 2.9870495281223017

Epoch: 6| Step: 13
Training loss: 3.3756481537274694
Validation loss: 2.9878006614819825

Epoch: 142| Step: 0
Training loss: 4.046410964814003
Validation loss: 2.985641166228013

Epoch: 6| Step: 1
Training loss: 3.0343846109790023
Validation loss: 2.985313265887791

Epoch: 6| Step: 2
Training loss: 3.5623084568932577
Validation loss: 2.9864285424265504

Epoch: 6| Step: 3
Training loss: 3.450394323177077
Validation loss: 2.988118649876011

Epoch: 6| Step: 4
Training loss: 2.030672666225642
Validation loss: 2.986535533541

Epoch: 6| Step: 5
Training loss: 3.5596626091857853
Validation loss: 2.989090057755985

Epoch: 6| Step: 6
Training loss: 3.6106365690859827
Validation loss: 2.9871278511547605

Epoch: 6| Step: 7
Training loss: 3.2085367774038565
Validation loss: 2.986875309941744

Epoch: 6| Step: 8
Training loss: 3.6275090709233724
Validation loss: 2.986228706910538

Epoch: 6| Step: 9
Training loss: 2.978325429378269
Validation loss: 2.986503329651394

Epoch: 6| Step: 10
Training loss: 2.6025166179555166
Validation loss: 2.988456902893352

Epoch: 6| Step: 11
Training loss: 3.0735898762152463
Validation loss: 2.987140183884299

Epoch: 6| Step: 12
Training loss: 3.251100647226412
Validation loss: 2.988683664592215

Epoch: 6| Step: 13
Training loss: 3.203665338856972
Validation loss: 2.991946934463971

Epoch: 143| Step: 0
Training loss: 2.695187065412328
Validation loss: 2.9915836127206226

Epoch: 6| Step: 1
Training loss: 2.923969354575903
Validation loss: 2.990391666609314

Epoch: 6| Step: 2
Training loss: 3.5356753816432174
Validation loss: 2.9910328111613884

Epoch: 6| Step: 3
Training loss: 2.8585310560817745
Validation loss: 2.9912501716342037

Epoch: 6| Step: 4
Training loss: 3.567851013152144
Validation loss: 2.988700209455861

Epoch: 6| Step: 5
Training loss: 2.93106868484072
Validation loss: 2.987859805320555

Epoch: 6| Step: 6
Training loss: 3.458169971575592
Validation loss: 2.9839085443797386

Epoch: 6| Step: 7
Training loss: 3.434840196337734
Validation loss: 2.984491128782263

Epoch: 6| Step: 8
Training loss: 3.4216116189841
Validation loss: 2.9851633576974783

Epoch: 6| Step: 9
Training loss: 3.343901443617025
Validation loss: 2.9829271598474723

Epoch: 6| Step: 10
Training loss: 2.534389291668917
Validation loss: 2.9837223561956727

Epoch: 6| Step: 11
Training loss: 4.193311615500034
Validation loss: 2.9827941133160887

Epoch: 6| Step: 12
Training loss: 3.555167029597541
Validation loss: 2.981364267397372

Epoch: 6| Step: 13
Training loss: 2.5383709244460793
Validation loss: 2.983931103992521

Epoch: 144| Step: 0
Training loss: 3.3900995506590816
Validation loss: 2.984436147920574

Epoch: 6| Step: 1
Training loss: 2.8634264650249825
Validation loss: 2.9828025224196564

Epoch: 6| Step: 2
Training loss: 3.355408495893817
Validation loss: 2.9827684973765747

Epoch: 6| Step: 3
Training loss: 2.503895014173796
Validation loss: 2.9822096637905435

Epoch: 6| Step: 4
Training loss: 3.030402782850186
Validation loss: 2.982969412093398

Epoch: 6| Step: 5
Training loss: 3.1761427857710474
Validation loss: 2.9815215076082833

Epoch: 6| Step: 6
Training loss: 3.227244307408745
Validation loss: 2.9824387313848106

Epoch: 6| Step: 7
Training loss: 3.766749677052835
Validation loss: 2.98241561550638

Epoch: 6| Step: 8
Training loss: 2.460911148172404
Validation loss: 2.9818878900285273

Epoch: 6| Step: 9
Training loss: 3.9035502144891865
Validation loss: 2.9809008994264095

Epoch: 6| Step: 10
Training loss: 3.251755753676371
Validation loss: 2.9814458490557456

Epoch: 6| Step: 11
Training loss: 3.5642317193651443
Validation loss: 2.98256933978052

Epoch: 6| Step: 12
Training loss: 3.9029248542872166
Validation loss: 2.9801351294155394

Epoch: 6| Step: 13
Training loss: 2.5786062080504437
Validation loss: 2.9769890471813696

Epoch: 145| Step: 0
Training loss: 3.365225023111643
Validation loss: 2.9793349202118566

Epoch: 6| Step: 1
Training loss: 3.502755578986088
Validation loss: 2.98162636964673

Epoch: 6| Step: 2
Training loss: 3.0957658153648415
Validation loss: 2.980817685967144

Epoch: 6| Step: 3
Training loss: 3.1823537834002944
Validation loss: 2.9864376915622666

Epoch: 6| Step: 4
Training loss: 2.943238193217076
Validation loss: 2.9858486113260536

Epoch: 6| Step: 5
Training loss: 3.7525024965037783
Validation loss: 2.98537053028764

Epoch: 6| Step: 6
Training loss: 4.2311084718010346
Validation loss: 2.9827908352719508

Epoch: 6| Step: 7
Training loss: 2.73848437373516
Validation loss: 2.977811524220565

Epoch: 6| Step: 8
Training loss: 3.264537137274148
Validation loss: 2.9777439545921762

Epoch: 6| Step: 9
Training loss: 2.697097320056772
Validation loss: 2.9748170180252704

Epoch: 6| Step: 10
Training loss: 2.7593528185046843
Validation loss: 2.974879379288286

Epoch: 6| Step: 11
Training loss: 2.7797396555784517
Validation loss: 2.9759155178361616

Epoch: 6| Step: 12
Training loss: 3.2609638733978574
Validation loss: 2.978986811413228

Epoch: 6| Step: 13
Training loss: 3.988485930717476
Validation loss: 2.9755561145114635

Epoch: 146| Step: 0
Training loss: 2.2286718181733525
Validation loss: 2.9764345160016177

Epoch: 6| Step: 1
Training loss: 2.226929430257594
Validation loss: 2.9801188010968236

Epoch: 6| Step: 2
Training loss: 3.2092186998381886
Validation loss: 2.9752840511269816

Epoch: 6| Step: 3
Training loss: 3.5226126845172847
Validation loss: 2.9824114671448148

Epoch: 6| Step: 4
Training loss: 3.3214146837919807
Validation loss: 2.985945392527659

Epoch: 6| Step: 5
Training loss: 3.566475507182821
Validation loss: 2.985232848788444

Epoch: 6| Step: 6
Training loss: 3.399329338124749
Validation loss: 2.980882532737973

Epoch: 6| Step: 7
Training loss: 3.5890788362336368
Validation loss: 2.9823020707220813

Epoch: 6| Step: 8
Training loss: 3.0784761644846776
Validation loss: 2.975412752357903

Epoch: 6| Step: 9
Training loss: 3.0084817513357325
Validation loss: 2.9758787322840488

Epoch: 6| Step: 10
Training loss: 2.9326414144749364
Validation loss: 2.975952974866205

Epoch: 6| Step: 11
Training loss: 3.525987603107888
Validation loss: 2.9748472715534597

Epoch: 6| Step: 12
Training loss: 3.452864969396748
Validation loss: 2.974565243236922

Epoch: 6| Step: 13
Training loss: 4.5743765734542015
Validation loss: 2.973608922944078

Epoch: 147| Step: 0
Training loss: 3.2181338118571245
Validation loss: 2.973600868904737

Epoch: 6| Step: 1
Training loss: 2.8489861542193555
Validation loss: 2.9758792543369377

Epoch: 6| Step: 2
Training loss: 3.184813919739918
Validation loss: 2.9734266680238877

Epoch: 6| Step: 3
Training loss: 3.621987505161887
Validation loss: 2.973740362265976

Epoch: 6| Step: 4
Training loss: 3.8614834728645486
Validation loss: 2.973022602220148

Epoch: 6| Step: 5
Training loss: 3.043520915283412
Validation loss: 2.9730726842457247

Epoch: 6| Step: 6
Training loss: 2.7517519485440394
Validation loss: 2.9745945874935362

Epoch: 6| Step: 7
Training loss: 2.6780450975924155
Validation loss: 2.972758843659066

Epoch: 6| Step: 8
Training loss: 3.214079792753218
Validation loss: 2.9722104520056423

Epoch: 6| Step: 9
Training loss: 3.301975445032808
Validation loss: 2.97060935445178

Epoch: 6| Step: 10
Training loss: 2.8144964973236806
Validation loss: 2.971604047536081

Epoch: 6| Step: 11
Training loss: 3.8689131152349887
Validation loss: 2.9743495073511497

Epoch: 6| Step: 12
Training loss: 3.396170164538141
Validation loss: 2.971388244189038

Epoch: 6| Step: 13
Training loss: 3.702548726628602
Validation loss: 2.970666582988846

Epoch: 148| Step: 0
Training loss: 3.533072887274537
Validation loss: 2.972527793372723

Epoch: 6| Step: 1
Training loss: 3.2601772297619047
Validation loss: 2.9688451349098064

Epoch: 6| Step: 2
Training loss: 3.009278730237085
Validation loss: 2.9711956776994315

Epoch: 6| Step: 3
Training loss: 3.1136345752591956
Validation loss: 2.973629005357354

Epoch: 6| Step: 4
Training loss: 3.096638573668651
Validation loss: 2.97125495879549

Epoch: 6| Step: 5
Training loss: 3.0353563947242117
Validation loss: 2.968963906354304

Epoch: 6| Step: 6
Training loss: 3.0515485865778245
Validation loss: 2.9679277007675964

Epoch: 6| Step: 7
Training loss: 3.7564802762502207
Validation loss: 2.972910183625991

Epoch: 6| Step: 8
Training loss: 2.789804739186613
Validation loss: 2.9715255983067492

Epoch: 6| Step: 9
Training loss: 3.1817826999816226
Validation loss: 2.970768311642195

Epoch: 6| Step: 10
Training loss: 3.983952997336358
Validation loss: 2.968061297096684

Epoch: 6| Step: 11
Training loss: 3.123868966464681
Validation loss: 2.96601933020815

Epoch: 6| Step: 12
Training loss: 3.314380903474347
Validation loss: 2.968830610561446

Epoch: 6| Step: 13
Training loss: 2.9367158533048032
Validation loss: 2.96835291332794

Epoch: 149| Step: 0
Training loss: 3.4784389960765836
Validation loss: 2.9693483864650743

Epoch: 6| Step: 1
Training loss: 3.092090354191463
Validation loss: 2.972477176066372

Epoch: 6| Step: 2
Training loss: 3.311709039650927
Validation loss: 2.984094186585606

Epoch: 6| Step: 3
Training loss: 3.972392175650331
Validation loss: 2.9772593772754377

Epoch: 6| Step: 4
Training loss: 3.034990028729469
Validation loss: 2.9747021317884124

Epoch: 6| Step: 5
Training loss: 3.0511952606504424
Validation loss: 2.970071873305336

Epoch: 6| Step: 6
Training loss: 3.1968691888273493
Validation loss: 2.967292782921329

Epoch: 6| Step: 7
Training loss: 3.593780119396542
Validation loss: 2.9673937166465345

Epoch: 6| Step: 8
Training loss: 2.7061829662170047
Validation loss: 2.965476828662414

Epoch: 6| Step: 9
Training loss: 2.4428312247677275
Validation loss: 2.9645983506214804

Epoch: 6| Step: 10
Training loss: 3.420800724098693
Validation loss: 2.9656806091262937

Epoch: 6| Step: 11
Training loss: 3.1917110376950686
Validation loss: 2.9662933271163676

Epoch: 6| Step: 12
Training loss: 3.3053391988634777
Validation loss: 2.965569388724428

Epoch: 6| Step: 13
Training loss: 3.7485007785991193
Validation loss: 2.9659214199393666

Epoch: 150| Step: 0
Training loss: 3.431201644028643
Validation loss: 2.964992689091755

Epoch: 6| Step: 1
Training loss: 3.3529163818308687
Validation loss: 2.9667621410068916

Epoch: 6| Step: 2
Training loss: 3.0996701403444322
Validation loss: 2.964528920646401

Epoch: 6| Step: 3
Training loss: 3.4989066459803064
Validation loss: 2.963565972439353

Epoch: 6| Step: 4
Training loss: 3.0171114563804515
Validation loss: 2.964808579803365

Epoch: 6| Step: 5
Training loss: 3.370477825667368
Validation loss: 2.9634409601773166

Epoch: 6| Step: 6
Training loss: 3.8486925307787536
Validation loss: 2.9650919597947385

Epoch: 6| Step: 7
Training loss: 2.8965222387739256
Validation loss: 2.9632814542066424

Epoch: 6| Step: 8
Training loss: 3.9586906004178233
Validation loss: 2.96699657115234

Epoch: 6| Step: 9
Training loss: 2.709929265017618
Validation loss: 2.9622505019927754

Epoch: 6| Step: 10
Training loss: 3.1553769556583577
Validation loss: 2.966037639405064

Epoch: 6| Step: 11
Training loss: 2.837601438885376
Validation loss: 2.9627276645554175

Epoch: 6| Step: 12
Training loss: 3.1351513586664437
Validation loss: 2.9626558457288064

Epoch: 6| Step: 13
Training loss: 2.680480928540672
Validation loss: 2.9623156868418095

Epoch: 151| Step: 0
Training loss: 3.0900582529644756
Validation loss: 2.96148033965965

Epoch: 6| Step: 1
Training loss: 2.5669197486188793
Validation loss: 2.9628142293763395

Epoch: 6| Step: 2
Training loss: 2.719225524006594
Validation loss: 2.9632090717425754

Epoch: 6| Step: 3
Training loss: 4.053776927273951
Validation loss: 2.9715610064863567

Epoch: 6| Step: 4
Training loss: 3.2085005151035775
Validation loss: 2.9680738861166813

Epoch: 6| Step: 5
Training loss: 3.276231106292842
Validation loss: 2.962883623390032

Epoch: 6| Step: 6
Training loss: 2.693356984934808
Validation loss: 2.9763163475925025

Epoch: 6| Step: 7
Training loss: 3.251657210166342
Validation loss: 2.968961748517268

Epoch: 6| Step: 8
Training loss: 3.8986078809914964
Validation loss: 2.9789183458862842

Epoch: 6| Step: 9
Training loss: 3.146975648817914
Validation loss: 2.9592191354155015

Epoch: 6| Step: 10
Training loss: 3.269428137608298
Validation loss: 2.961610531478863

Epoch: 6| Step: 11
Training loss: 3.4776749449108864
Validation loss: 2.960562170694659

Epoch: 6| Step: 12
Training loss: 3.66774033230307
Validation loss: 2.9614831608503702

Epoch: 6| Step: 13
Training loss: 2.2301365058755636
Validation loss: 2.9671648630580987

Epoch: 152| Step: 0
Training loss: 3.217987710999234
Validation loss: 2.9716821875767976

Epoch: 6| Step: 1
Training loss: 3.538528637903705
Validation loss: 2.9966726420219065

Epoch: 6| Step: 2
Training loss: 2.6489984599044547
Validation loss: 2.9840885818003122

Epoch: 6| Step: 3
Training loss: 2.9391153642117396
Validation loss: 2.9824917050269244

Epoch: 6| Step: 4
Training loss: 3.7397356064307354
Validation loss: 2.974681067250353

Epoch: 6| Step: 5
Training loss: 4.099166431823794
Validation loss: 2.9736629746222434

Epoch: 6| Step: 6
Training loss: 3.20289692880871
Validation loss: 2.968595828687693

Epoch: 6| Step: 7
Training loss: 3.1991870026183475
Validation loss: 2.9674776348250504

Epoch: 6| Step: 8
Training loss: 3.184784873512143
Validation loss: 2.9623862210120024

Epoch: 6| Step: 9
Training loss: 3.282602086103108
Validation loss: 2.9664393259646027

Epoch: 6| Step: 10
Training loss: 2.805788636885881
Validation loss: 2.9588223682414063

Epoch: 6| Step: 11
Training loss: 3.198180611287003
Validation loss: 2.962269841846116

Epoch: 6| Step: 12
Training loss: 3.25096937541448
Validation loss: 2.9594619021805455

Epoch: 6| Step: 13
Training loss: 2.864438602374801
Validation loss: 2.9582811397493196

Epoch: 153| Step: 0
Training loss: 4.049794914798614
Validation loss: 2.960567414764212

Epoch: 6| Step: 1
Training loss: 2.6966263816694505
Validation loss: 2.959205489924951

Epoch: 6| Step: 2
Training loss: 3.790459255485102
Validation loss: 2.9617957743778005

Epoch: 6| Step: 3
Training loss: 4.158393708569888
Validation loss: 2.960425027530935

Epoch: 6| Step: 4
Training loss: 3.491821542975569
Validation loss: 2.964018253203287

Epoch: 6| Step: 5
Training loss: 2.2324207002197807
Validation loss: 2.961976094752276

Epoch: 6| Step: 6
Training loss: 3.0428469906541005
Validation loss: 2.964791384958465

Epoch: 6| Step: 7
Training loss: 3.4852499098635814
Validation loss: 2.9652691264046056

Epoch: 6| Step: 8
Training loss: 3.018371912181158
Validation loss: 2.965369114055862

Epoch: 6| Step: 9
Training loss: 2.8759795468999796
Validation loss: 2.964939606858083

Epoch: 6| Step: 10
Training loss: 3.1076106140631095
Validation loss: 2.963189577964241

Epoch: 6| Step: 11
Training loss: 3.058203973208466
Validation loss: 2.9622594687700294

Epoch: 6| Step: 12
Training loss: 2.7814939584784732
Validation loss: 2.9705033207304012

Epoch: 6| Step: 13
Training loss: 2.7724872519335033
Validation loss: 2.9687107396619656

Epoch: 154| Step: 0
Training loss: 3.851931416947755
Validation loss: 2.9722998077409177

Epoch: 6| Step: 1
Training loss: 2.5242291321890713
Validation loss: 2.9751058074867567

Epoch: 6| Step: 2
Training loss: 3.2449083792002966
Validation loss: 2.973414848321151

Epoch: 6| Step: 3
Training loss: 3.3309039481889218
Validation loss: 2.9753012615879237

Epoch: 6| Step: 4
Training loss: 3.86380158749379
Validation loss: 2.9715378629293676

Epoch: 6| Step: 5
Training loss: 3.322851740442965
Validation loss: 2.9700768606267838

Epoch: 6| Step: 6
Training loss: 2.8498038107286536
Validation loss: 2.9731920076530884

Epoch: 6| Step: 7
Training loss: 3.311142841360601
Validation loss: 2.977355281291638

Epoch: 6| Step: 8
Training loss: 3.008468120510654
Validation loss: 2.974374732951614

Epoch: 6| Step: 9
Training loss: 2.6831562512966087
Validation loss: 2.977601352978396

Epoch: 6| Step: 10
Training loss: 2.7735525187967736
Validation loss: 2.966784022191056

Epoch: 6| Step: 11
Training loss: 3.0582937821854683
Validation loss: 2.967961541800915

Epoch: 6| Step: 12
Training loss: 3.7945015478670103
Validation loss: 2.96118777217914

Epoch: 6| Step: 13
Training loss: 3.5275974794973357
Validation loss: 2.9583240915027296

Epoch: 155| Step: 0
Training loss: 3.021992340492221
Validation loss: 2.9570829448975875

Epoch: 6| Step: 1
Training loss: 3.029122776166529
Validation loss: 2.956197005125163

Epoch: 6| Step: 2
Training loss: 3.716023832304284
Validation loss: 2.9521071778724335

Epoch: 6| Step: 3
Training loss: 3.5908961367181402
Validation loss: 2.9501101988240377

Epoch: 6| Step: 4
Training loss: 3.134488920079332
Validation loss: 2.952598974175632

Epoch: 6| Step: 5
Training loss: 3.119613430088099
Validation loss: 2.9556749477764956

Epoch: 6| Step: 6
Training loss: 3.5495753826815495
Validation loss: 2.951646192233944

Epoch: 6| Step: 7
Training loss: 2.6851835691756527
Validation loss: 2.9564524686538984

Epoch: 6| Step: 8
Training loss: 3.264739724222889
Validation loss: 2.9561053171650236

Epoch: 6| Step: 9
Training loss: 3.832502330323946
Validation loss: 2.9624072033573423

Epoch: 6| Step: 10
Training loss: 3.1418644371484996
Validation loss: 2.9561068773219836

Epoch: 6| Step: 11
Training loss: 3.086189201809843
Validation loss: 2.9570823631746306

Epoch: 6| Step: 12
Training loss: 2.7876243837257615
Validation loss: 2.9465808376087543

Epoch: 6| Step: 13
Training loss: 3.057060237272325
Validation loss: 2.953803297114899

Epoch: 156| Step: 0
Training loss: 3.4615659810463955
Validation loss: 2.9516478537620663

Epoch: 6| Step: 1
Training loss: 3.2749417656533084
Validation loss: 2.945180201094885

Epoch: 6| Step: 2
Training loss: 3.830401681697607
Validation loss: 2.9513329718301606

Epoch: 6| Step: 3
Training loss: 2.7239747104675187
Validation loss: 2.950373342355807

Epoch: 6| Step: 4
Training loss: 3.164388004090157
Validation loss: 2.9485519201863446

Epoch: 6| Step: 5
Training loss: 3.674240064873455
Validation loss: 2.9477779040232805

Epoch: 6| Step: 6
Training loss: 3.6367137675348524
Validation loss: 2.9485789341076947

Epoch: 6| Step: 7
Training loss: 3.0076035464148574
Validation loss: 2.949367072609179

Epoch: 6| Step: 8
Training loss: 2.9171989681792856
Validation loss: 2.9488735193312596

Epoch: 6| Step: 9
Training loss: 2.993853312005883
Validation loss: 2.9496525888218144

Epoch: 6| Step: 10
Training loss: 3.1174346902303443
Validation loss: 2.947180184893872

Epoch: 6| Step: 11
Training loss: 2.9874172183263155
Validation loss: 2.950953864204774

Epoch: 6| Step: 12
Training loss: 2.973869968221648
Validation loss: 2.9544963978312464

Epoch: 6| Step: 13
Training loss: 3.3719931029388377
Validation loss: 2.949247113847776

Epoch: 157| Step: 0
Training loss: 3.020193483836685
Validation loss: 2.9540008480565607

Epoch: 6| Step: 1
Training loss: 2.819860194913901
Validation loss: 2.9613314161021536

Epoch: 6| Step: 2
Training loss: 3.628341450177636
Validation loss: 2.96952400070123

Epoch: 6| Step: 3
Training loss: 3.0199269656009027
Validation loss: 2.9666469506146314

Epoch: 6| Step: 4
Training loss: 3.385234432695414
Validation loss: 2.9695337009155156

Epoch: 6| Step: 5
Training loss: 3.624573386509355
Validation loss: 2.971858933707512

Epoch: 6| Step: 6
Training loss: 3.105123248763992
Validation loss: 2.9608992538603314

Epoch: 6| Step: 7
Training loss: 3.22606028788662
Validation loss: 2.9568623986728477

Epoch: 6| Step: 8
Training loss: 2.7310693432312996
Validation loss: 2.9499127106208083

Epoch: 6| Step: 9
Training loss: 3.0401998318696415
Validation loss: 2.9492277311902613

Epoch: 6| Step: 10
Training loss: 2.6758088716069772
Validation loss: 2.9467147527290294

Epoch: 6| Step: 11
Training loss: 3.7755841138015485
Validation loss: 2.946080287681641

Epoch: 6| Step: 12
Training loss: 3.603411350964224
Validation loss: 2.943387875441859

Epoch: 6| Step: 13
Training loss: 3.514143839463387
Validation loss: 2.946829881006133

Epoch: 158| Step: 0
Training loss: 3.3663647702012693
Validation loss: 2.9446944587680846

Epoch: 6| Step: 1
Training loss: 3.7957744494720242
Validation loss: 2.9473678690843665

Epoch: 6| Step: 2
Training loss: 3.5166147152888576
Validation loss: 2.9456392456600584

Epoch: 6| Step: 3
Training loss: 3.6534962513602793
Validation loss: 2.9437267135947227

Epoch: 6| Step: 4
Training loss: 3.0983024009841804
Validation loss: 2.9450087882632854

Epoch: 6| Step: 5
Training loss: 3.3176945676572904
Validation loss: 2.944892396155236

Epoch: 6| Step: 6
Training loss: 2.70172718047001
Validation loss: 2.941391808054208

Epoch: 6| Step: 7
Training loss: 2.18300395500045
Validation loss: 2.9488417917689556

Epoch: 6| Step: 8
Training loss: 2.918354381730101
Validation loss: 2.943004041328978

Epoch: 6| Step: 9
Training loss: 3.266154999137909
Validation loss: 2.9407308941905566

Epoch: 6| Step: 10
Training loss: 3.1687970942321413
Validation loss: 2.9447423272559634

Epoch: 6| Step: 11
Training loss: 3.177216640656573
Validation loss: 2.9488618828886026

Epoch: 6| Step: 12
Training loss: 3.4466397935814554
Validation loss: 2.9478548423840967

Epoch: 6| Step: 13
Training loss: 3.3715600744329404
Validation loss: 2.948860147633302

Epoch: 159| Step: 0
Training loss: 4.022309317327882
Validation loss: 2.9507363759667773

Epoch: 6| Step: 1
Training loss: 2.5123068208588277
Validation loss: 2.9538401779272316

Epoch: 6| Step: 2
Training loss: 3.0036055832338886
Validation loss: 2.959877143999736

Epoch: 6| Step: 3
Training loss: 3.0883784044589513
Validation loss: 2.9516811744558207

Epoch: 6| Step: 4
Training loss: 3.137342569117388
Validation loss: 2.958051567287711

Epoch: 6| Step: 5
Training loss: 3.0363713683319076
Validation loss: 2.9605582584187546

Epoch: 6| Step: 6
Training loss: 2.752219344962248
Validation loss: 2.9563585868941753

Epoch: 6| Step: 7
Training loss: 3.8147717570851842
Validation loss: 2.9478906496758697

Epoch: 6| Step: 8
Training loss: 3.3290389690965876
Validation loss: 2.948942849321975

Epoch: 6| Step: 9
Training loss: 3.89732341863063
Validation loss: 2.947345247931926

Epoch: 6| Step: 10
Training loss: 2.6031038684147543
Validation loss: 2.950272740471183

Epoch: 6| Step: 11
Training loss: 3.155380582510357
Validation loss: 2.9478905331424246

Epoch: 6| Step: 12
Training loss: 3.434271944007986
Validation loss: 2.940618472084267

Epoch: 6| Step: 13
Training loss: 2.7501214607465325
Validation loss: 2.94537649038637

Epoch: 160| Step: 0
Training loss: 3.2150395311740287
Validation loss: 2.9452015114455894

Epoch: 6| Step: 1
Training loss: 3.086747075373073
Validation loss: 2.949384376065538

Epoch: 6| Step: 2
Training loss: 3.421517549422101
Validation loss: 2.944328791635984

Epoch: 6| Step: 3
Training loss: 3.469119490456116
Validation loss: 2.949160009976901

Epoch: 6| Step: 4
Training loss: 2.9824636040486894
Validation loss: 2.960375243336316

Epoch: 6| Step: 5
Training loss: 2.9510046395886156
Validation loss: 2.9481490538677884

Epoch: 6| Step: 6
Training loss: 3.0546503479398335
Validation loss: 2.956567297519088

Epoch: 6| Step: 7
Training loss: 2.85670955642083
Validation loss: 2.946277599447083

Epoch: 6| Step: 8
Training loss: 3.833871444305983
Validation loss: 2.946276219422675

Epoch: 6| Step: 9
Training loss: 2.775234961657702
Validation loss: 2.942117509581303

Epoch: 6| Step: 10
Training loss: 3.552779605822921
Validation loss: 2.941773745334901

Epoch: 6| Step: 11
Training loss: 3.4291609444614903
Validation loss: 2.940883528418718

Epoch: 6| Step: 12
Training loss: 3.1502123201052914
Validation loss: 2.9344852785380526

Epoch: 6| Step: 13
Training loss: 3.2161769026312212
Validation loss: 2.9407523893420695

Epoch: 161| Step: 0
Training loss: 4.087342117480154
Validation loss: 2.9385997482606037

Epoch: 6| Step: 1
Training loss: 2.7129700706059965
Validation loss: 2.9397006147235323

Epoch: 6| Step: 2
Training loss: 3.4464026562375003
Validation loss: 2.9341080525828116

Epoch: 6| Step: 3
Training loss: 2.9741670676676732
Validation loss: 2.940322938610936

Epoch: 6| Step: 4
Training loss: 3.148169418545675
Validation loss: 2.9401079712976483

Epoch: 6| Step: 5
Training loss: 3.6220456942999326
Validation loss: 2.9456367452375503

Epoch: 6| Step: 6
Training loss: 2.949096030404132
Validation loss: 2.949128871396526

Epoch: 6| Step: 7
Training loss: 3.3808497842512724
Validation loss: 2.9584793665428855

Epoch: 6| Step: 8
Training loss: 2.484872636198371
Validation loss: 2.9627776956304177

Epoch: 6| Step: 9
Training loss: 3.377904701636777
Validation loss: 2.9662320770019086

Epoch: 6| Step: 10
Training loss: 2.525384866069178
Validation loss: 2.954021768464342

Epoch: 6| Step: 11
Training loss: 3.5741392366497116
Validation loss: 2.9468120405675005

Epoch: 6| Step: 12
Training loss: 3.6827398060748258
Validation loss: 2.9424335676338678

Epoch: 6| Step: 13
Training loss: 2.275740148852161
Validation loss: 2.9334539066585106

Epoch: 162| Step: 0
Training loss: 3.987816614478154
Validation loss: 2.933141693397555

Epoch: 6| Step: 1
Training loss: 2.6424342170546424
Validation loss: 2.9317977443532155

Epoch: 6| Step: 2
Training loss: 3.489383399511877
Validation loss: 2.932015262032703

Epoch: 6| Step: 3
Training loss: 3.6000878217369574
Validation loss: 2.933881506384851

Epoch: 6| Step: 4
Training loss: 2.9393301599072585
Validation loss: 2.934653547927906

Epoch: 6| Step: 5
Training loss: 2.8635846610858313
Validation loss: 2.9363993474553287

Epoch: 6| Step: 6
Training loss: 3.340627477946491
Validation loss: 2.93394502259034

Epoch: 6| Step: 7
Training loss: 3.023735406279779
Validation loss: 2.936753697699114

Epoch: 6| Step: 8
Training loss: 3.5389018917061112
Validation loss: 2.9370030174944457

Epoch: 6| Step: 9
Training loss: 2.6919693267854594
Validation loss: 2.9366094190055163

Epoch: 6| Step: 10
Training loss: 3.3589468749723803
Validation loss: 2.9378332055117786

Epoch: 6| Step: 11
Training loss: 3.4128605802300056
Validation loss: 2.9356687663733845

Epoch: 6| Step: 12
Training loss: 3.085944607883428
Validation loss: 2.936900051188796

Epoch: 6| Step: 13
Training loss: 2.5253429482098064
Validation loss: 2.938461200559435

Epoch: 163| Step: 0
Training loss: 2.6735344802861722
Validation loss: 2.9330158082994946

Epoch: 6| Step: 1
Training loss: 3.3875848175353624
Validation loss: 2.9349939884010254

Epoch: 6| Step: 2
Training loss: 3.403506372693797
Validation loss: 2.931547534119911

Epoch: 6| Step: 3
Training loss: 2.6889810251663797
Validation loss: 2.9325098185231546

Epoch: 6| Step: 4
Training loss: 3.2025737008898556
Validation loss: 2.9339068343902746

Epoch: 6| Step: 5
Training loss: 3.515249817220082
Validation loss: 2.9305749698891304

Epoch: 6| Step: 6
Training loss: 3.1062087610834594
Validation loss: 2.9323675542560275

Epoch: 6| Step: 7
Training loss: 2.778610091022731
Validation loss: 2.932992395554174

Epoch: 6| Step: 8
Training loss: 3.5015346704727843
Validation loss: 2.934526452210451

Epoch: 6| Step: 9
Training loss: 3.0206558876976244
Validation loss: 2.933828953527598

Epoch: 6| Step: 10
Training loss: 2.815803198726996
Validation loss: 2.9313456574064976

Epoch: 6| Step: 11
Training loss: 3.742716136697388
Validation loss: 2.9315210173870203

Epoch: 6| Step: 12
Training loss: 3.650229036643933
Validation loss: 2.932800417279202

Epoch: 6| Step: 13
Training loss: 3.421070439759519
Validation loss: 2.93495381880858

Epoch: 164| Step: 0
Training loss: 3.9838592793917313
Validation loss: 2.9310645967534126

Epoch: 6| Step: 1
Training loss: 3.189042410070004
Validation loss: 2.9338577702469824

Epoch: 6| Step: 2
Training loss: 2.9174657181243218
Validation loss: 2.9324413265666966

Epoch: 6| Step: 3
Training loss: 3.510857906211794
Validation loss: 2.9287935831704854

Epoch: 6| Step: 4
Training loss: 3.1456813817662495
Validation loss: 2.92980484266012

Epoch: 6| Step: 5
Training loss: 3.557031550282768
Validation loss: 2.928045527563338

Epoch: 6| Step: 6
Training loss: 2.45643363440911
Validation loss: 2.9281957605207203

Epoch: 6| Step: 7
Training loss: 3.8301553129970705
Validation loss: 2.9257747992295724

Epoch: 6| Step: 8
Training loss: 3.2595916939349068
Validation loss: 2.9294941421197436

Epoch: 6| Step: 9
Training loss: 2.5085588812149617
Validation loss: 2.92773945020367

Epoch: 6| Step: 10
Training loss: 2.904528035941858
Validation loss: 2.9291780506034706

Epoch: 6| Step: 11
Training loss: 2.789743206826424
Validation loss: 2.926789142665779

Epoch: 6| Step: 12
Training loss: 3.078990833869713
Validation loss: 2.928730406920746

Epoch: 6| Step: 13
Training loss: 3.7135961385033815
Validation loss: 2.9289818346070584

Epoch: 165| Step: 0
Training loss: 3.2042145155437227
Validation loss: 2.9295448107683013

Epoch: 6| Step: 1
Training loss: 2.782208566818337
Validation loss: 2.925733327147963

Epoch: 6| Step: 2
Training loss: 2.951758658987588
Validation loss: 2.9259155545785633

Epoch: 6| Step: 3
Training loss: 3.3527946430306406
Validation loss: 2.9248914885536386

Epoch: 6| Step: 4
Training loss: 3.047819802932493
Validation loss: 2.9289979307197713

Epoch: 6| Step: 5
Training loss: 2.922756775996056
Validation loss: 2.9331807445969407

Epoch: 6| Step: 6
Training loss: 4.332506736754536
Validation loss: 2.9347188128808672

Epoch: 6| Step: 7
Training loss: 3.0579700832862047
Validation loss: 2.945353374348269

Epoch: 6| Step: 8
Training loss: 2.9211935788909993
Validation loss: 2.9424291729677776

Epoch: 6| Step: 9
Training loss: 2.9193969663015316
Validation loss: 2.9440685012739687

Epoch: 6| Step: 10
Training loss: 3.738373343709535
Validation loss: 2.9391088240809555

Epoch: 6| Step: 11
Training loss: 2.819530262343101
Validation loss: 2.9428765535891386

Epoch: 6| Step: 12
Training loss: 3.588421129805417
Validation loss: 2.944158897464072

Epoch: 6| Step: 13
Training loss: 2.882198113201991
Validation loss: 2.943639529979462

Epoch: 166| Step: 0
Training loss: 3.347371929473705
Validation loss: 2.935182467534355

Epoch: 6| Step: 1
Training loss: 3.083561931761987
Validation loss: 2.9448383326396974

Epoch: 6| Step: 2
Training loss: 3.034631317973066
Validation loss: 2.9368790402419642

Epoch: 6| Step: 3
Training loss: 2.5727216103525463
Validation loss: 2.9432486054582667

Epoch: 6| Step: 4
Training loss: 4.139387759212486
Validation loss: 2.9369618654480276

Epoch: 6| Step: 5
Training loss: 2.9167029968905496
Validation loss: 2.9310045998739853

Epoch: 6| Step: 6
Training loss: 3.3637941614014255
Validation loss: 2.9345961377496703

Epoch: 6| Step: 7
Training loss: 2.468588908287509
Validation loss: 2.9313518143095822

Epoch: 6| Step: 8
Training loss: 3.423281445900866
Validation loss: 2.930123334727038

Epoch: 6| Step: 9
Training loss: 3.746191888663341
Validation loss: 2.931948327163499

Epoch: 6| Step: 10
Training loss: 3.3228652296400143
Validation loss: 2.926388615436471

Epoch: 6| Step: 11
Training loss: 2.8849438074414424
Validation loss: 2.923677322131213

Epoch: 6| Step: 12
Training loss: 2.825188476891791
Validation loss: 2.922530134095465

Epoch: 6| Step: 13
Training loss: 3.6095127888590466
Validation loss: 2.9228421529284154

Epoch: 167| Step: 0
Training loss: 2.3313872759698677
Validation loss: 2.9245377794420913

Epoch: 6| Step: 1
Training loss: 2.9657130719724987
Validation loss: 2.9245543453226404

Epoch: 6| Step: 2
Training loss: 3.3235341677217147
Validation loss: 2.9232744988301333

Epoch: 6| Step: 3
Training loss: 3.163209249101468
Validation loss: 2.9201131706091616

Epoch: 6| Step: 4
Training loss: 3.1255205865211604
Validation loss: 2.9235355680936452

Epoch: 6| Step: 5
Training loss: 3.2615623208185074
Validation loss: 2.9239355813055226

Epoch: 6| Step: 6
Training loss: 3.6198196227094175
Validation loss: 2.9312391776689237

Epoch: 6| Step: 7
Training loss: 2.724438383691355
Validation loss: 2.928047919555979

Epoch: 6| Step: 8
Training loss: 3.534296797503605
Validation loss: 2.929322127334088

Epoch: 6| Step: 9
Training loss: 3.6849995556938495
Validation loss: 2.9269718272565757

Epoch: 6| Step: 10
Training loss: 3.1533851841325755
Validation loss: 2.92511377396417

Epoch: 6| Step: 11
Training loss: 3.8628856429381235
Validation loss: 2.9204357112555774

Epoch: 6| Step: 12
Training loss: 2.96074681938791
Validation loss: 2.922121932592602

Epoch: 6| Step: 13
Training loss: 2.730249835449303
Validation loss: 2.9207049357579646

Epoch: 168| Step: 0
Training loss: 3.530105405319855
Validation loss: 2.9187623811261445

Epoch: 6| Step: 1
Training loss: 3.465036001967957
Validation loss: 2.920501795165604

Epoch: 6| Step: 2
Training loss: 3.376829146166187
Validation loss: 2.917110946031053

Epoch: 6| Step: 3
Training loss: 3.0370548942561273
Validation loss: 2.9179940052721114

Epoch: 6| Step: 4
Training loss: 2.9833442545713997
Validation loss: 2.9217834739087865

Epoch: 6| Step: 5
Training loss: 3.1049200760879567
Validation loss: 2.9172532635841435

Epoch: 6| Step: 6
Training loss: 3.6891924320203295
Validation loss: 2.9188423152152416

Epoch: 6| Step: 7
Training loss: 2.6840935343037344
Validation loss: 2.92096212719074

Epoch: 6| Step: 8
Training loss: 3.0796164370408197
Validation loss: 2.919957136324765

Epoch: 6| Step: 9
Training loss: 3.5207547211006256
Validation loss: 2.9235648721029173

Epoch: 6| Step: 10
Training loss: 3.115250293846475
Validation loss: 2.921313355725174

Epoch: 6| Step: 11
Training loss: 2.5267270970561992
Validation loss: 2.9308404700555855

Epoch: 6| Step: 12
Training loss: 3.732781105979327
Validation loss: 2.9301270916562094

Epoch: 6| Step: 13
Training loss: 2.4939027820718636
Validation loss: 2.9345336874648997

Epoch: 169| Step: 0
Training loss: 3.283852262846808
Validation loss: 2.93471557635485

Epoch: 6| Step: 1
Training loss: 3.5875167527289458
Validation loss: 2.9226939201112008

Epoch: 6| Step: 2
Training loss: 3.084351105293082
Validation loss: 2.916957285827511

Epoch: 6| Step: 3
Training loss: 2.9026401209297132
Validation loss: 2.9169394938291315

Epoch: 6| Step: 4
Training loss: 3.193564834751248
Validation loss: 2.9172013637928793

Epoch: 6| Step: 5
Training loss: 3.521467584367902
Validation loss: 2.9185305504006944

Epoch: 6| Step: 6
Training loss: 2.2941699025659803
Validation loss: 2.9184114833291996

Epoch: 6| Step: 7
Training loss: 3.2603106171704823
Validation loss: 2.916221567696824

Epoch: 6| Step: 8
Training loss: 3.4769480287904315
Validation loss: 2.917073168458664

Epoch: 6| Step: 9
Training loss: 2.8430523697856414
Validation loss: 2.9181240806063062

Epoch: 6| Step: 10
Training loss: 3.32708752718864
Validation loss: 2.917101774560984

Epoch: 6| Step: 11
Training loss: 3.4087885924876486
Validation loss: 2.9180011233782683

Epoch: 6| Step: 12
Training loss: 3.865058945061991
Validation loss: 2.917215429854137

Epoch: 6| Step: 13
Training loss: 1.8035929609791208
Validation loss: 2.9178835581887297

Epoch: 170| Step: 0
Training loss: 3.044636534998722
Validation loss: 2.919021849767378

Epoch: 6| Step: 1
Training loss: 3.110072992087691
Validation loss: 2.915946186457287

Epoch: 6| Step: 2
Training loss: 3.5551011735600504
Validation loss: 2.917117080248487

Epoch: 6| Step: 3
Training loss: 2.778006559063478
Validation loss: 2.916557817727957

Epoch: 6| Step: 4
Training loss: 3.3955708657774473
Validation loss: 2.915870148732071

Epoch: 6| Step: 5
Training loss: 2.7877531851838473
Validation loss: 2.9136296775910875

Epoch: 6| Step: 6
Training loss: 3.8735684857797312
Validation loss: 2.915173526044831

Epoch: 6| Step: 7
Training loss: 3.1140498764463627
Validation loss: 2.915934878426315

Epoch: 6| Step: 8
Training loss: 3.1258729859734347
Validation loss: 2.915418111237042

Epoch: 6| Step: 9
Training loss: 2.7179564271512113
Validation loss: 2.91599163353833

Epoch: 6| Step: 10
Training loss: 2.8387615340354215
Validation loss: 2.9165965222715102

Epoch: 6| Step: 11
Training loss: 3.3688646286409902
Validation loss: 2.9195360850258023

Epoch: 6| Step: 12
Training loss: 3.4308548941284926
Validation loss: 2.9169259643145327

Epoch: 6| Step: 13
Training loss: 3.7317816376335586
Validation loss: 2.9192765637345977

Epoch: 171| Step: 0
Training loss: 3.774025059797237
Validation loss: 2.922400898766302

Epoch: 6| Step: 1
Training loss: 3.3362090739501657
Validation loss: 2.922509888271436

Epoch: 6| Step: 2
Training loss: 2.7572752345486253
Validation loss: 2.9211762593958825

Epoch: 6| Step: 3
Training loss: 2.992958706505597
Validation loss: 2.923786681422648

Epoch: 6| Step: 4
Training loss: 3.0169077304465777
Validation loss: 2.9198089870814115

Epoch: 6| Step: 5
Training loss: 3.189987259364022
Validation loss: 2.9177096797508604

Epoch: 6| Step: 6
Training loss: 2.659377467224913
Validation loss: 2.9196619454580777

Epoch: 6| Step: 7
Training loss: 3.623117023621775
Validation loss: 2.917093814974138

Epoch: 6| Step: 8
Training loss: 3.556227935025326
Validation loss: 2.914942609505258

Epoch: 6| Step: 9
Training loss: 3.0048818603752148
Validation loss: 2.917718388899763

Epoch: 6| Step: 10
Training loss: 3.1395611076015477
Validation loss: 2.9157072824511574

Epoch: 6| Step: 11
Training loss: 3.870758196071045
Validation loss: 2.9168677024878606

Epoch: 6| Step: 12
Training loss: 2.8363023423416713
Validation loss: 2.9137332233937685

Epoch: 6| Step: 13
Training loss: 2.4078518378468514
Validation loss: 2.9157369271513582

Epoch: 172| Step: 0
Training loss: 2.4083654839328723
Validation loss: 2.9136087240848516

Epoch: 6| Step: 1
Training loss: 3.0448745811954163
Validation loss: 2.913970814740826

Epoch: 6| Step: 2
Training loss: 3.2759545602220506
Validation loss: 2.9155176357561374

Epoch: 6| Step: 3
Training loss: 3.0545663638864875
Validation loss: 2.9178582061928653

Epoch: 6| Step: 4
Training loss: 3.715135629059802
Validation loss: 2.9146630772563085

Epoch: 6| Step: 5
Training loss: 3.906511954107271
Validation loss: 2.9197191716303137

Epoch: 6| Step: 6
Training loss: 2.7041657489447855
Validation loss: 2.9167965465990924

Epoch: 6| Step: 7
Training loss: 3.202297941291123
Validation loss: 2.922722288755099

Epoch: 6| Step: 8
Training loss: 3.2123988926038805
Validation loss: 2.926332360706256

Epoch: 6| Step: 9
Training loss: 3.3890019764470933
Validation loss: 2.9245186064527133

Epoch: 6| Step: 10
Training loss: 2.8987572999955247
Validation loss: 2.9228525027538104

Epoch: 6| Step: 11
Training loss: 2.835628440136806
Validation loss: 2.914324172810814

Epoch: 6| Step: 12
Training loss: 3.707113315329116
Validation loss: 2.9118139097640716

Epoch: 6| Step: 13
Training loss: 3.1532205073822968
Validation loss: 2.911766425288049

Epoch: 173| Step: 0
Training loss: 3.120588316591984
Validation loss: 2.9126271314784797

Epoch: 6| Step: 1
Training loss: 3.8985579783566013
Validation loss: 2.9101178861760895

Epoch: 6| Step: 2
Training loss: 3.0066519740127013
Validation loss: 2.915907236778963

Epoch: 6| Step: 3
Training loss: 2.9365063873902257
Validation loss: 2.9115975428644236

Epoch: 6| Step: 4
Training loss: 4.021967410053714
Validation loss: 2.913174459671666

Epoch: 6| Step: 5
Training loss: 3.2762520646223763
Validation loss: 2.9108642650640837

Epoch: 6| Step: 6
Training loss: 3.3436364840909576
Validation loss: 2.9059229250032694

Epoch: 6| Step: 7
Training loss: 3.143158000318441
Validation loss: 2.9081185198405826

Epoch: 6| Step: 8
Training loss: 2.6042347606657255
Validation loss: 2.9058610186320837

Epoch: 6| Step: 9
Training loss: 2.60749008718126
Validation loss: 2.905490595635709

Epoch: 6| Step: 10
Training loss: 3.206191367641286
Validation loss: 2.9062018027153442

Epoch: 6| Step: 11
Training loss: 3.4139545345038895
Validation loss: 2.9084113943879513

Epoch: 6| Step: 12
Training loss: 2.7809560384667216
Validation loss: 2.903800626418164

Epoch: 6| Step: 13
Training loss: 2.9825604899332454
Validation loss: 2.905867615065689

Epoch: 174| Step: 0
Training loss: 2.9527888030975467
Validation loss: 2.9061563304493716

Epoch: 6| Step: 1
Training loss: 3.29048354378263
Validation loss: 2.904585137508297

Epoch: 6| Step: 2
Training loss: 3.117529828770908
Validation loss: 2.9055051683838076

Epoch: 6| Step: 3
Training loss: 3.366468596218621
Validation loss: 2.9121849422361885

Epoch: 6| Step: 4
Training loss: 3.430502827213814
Validation loss: 2.9049059542708

Epoch: 6| Step: 5
Training loss: 3.2035605529901887
Validation loss: 2.906998245926684

Epoch: 6| Step: 6
Training loss: 3.094621015526187
Validation loss: 2.9036160540045803

Epoch: 6| Step: 7
Training loss: 3.2103187725993974
Validation loss: 2.902952546701156

Epoch: 6| Step: 8
Training loss: 3.6042612022982032
Validation loss: 2.904241978987378

Epoch: 6| Step: 9
Training loss: 2.5033977307579907
Validation loss: 2.904969330945706

Epoch: 6| Step: 10
Training loss: 3.210187764127985
Validation loss: 2.901296192227429

Epoch: 6| Step: 11
Training loss: 3.2828711001991016
Validation loss: 2.90653744697467

Epoch: 6| Step: 12
Training loss: 2.959672723152651
Validation loss: 2.9060193377277828

Epoch: 6| Step: 13
Training loss: 3.5397204867429264
Validation loss: 2.9047818462152937

Epoch: 175| Step: 0
Training loss: 3.6960264004263994
Validation loss: 2.9044861439760012

Epoch: 6| Step: 1
Training loss: 3.3071161819319106
Validation loss: 2.907284334140374

Epoch: 6| Step: 2
Training loss: 3.1865954144012396
Validation loss: 2.911747567045811

Epoch: 6| Step: 3
Training loss: 2.304703017360367
Validation loss: 2.9245345237595397

Epoch: 6| Step: 4
Training loss: 2.9500503277122503
Validation loss: 2.9324474217215335

Epoch: 6| Step: 5
Training loss: 3.220199999077327
Validation loss: 2.951089379114959

Epoch: 6| Step: 6
Training loss: 3.1417173696890464
Validation loss: 2.939795791493659

Epoch: 6| Step: 7
Training loss: 3.621065306320326
Validation loss: 2.9203673223761033

Epoch: 6| Step: 8
Training loss: 3.4013830289162397
Validation loss: 2.916486750091504

Epoch: 6| Step: 9
Training loss: 3.516768206054005
Validation loss: 2.906331204415499

Epoch: 6| Step: 10
Training loss: 3.2659697282256053
Validation loss: 2.902402082554931

Epoch: 6| Step: 11
Training loss: 3.132464686846966
Validation loss: 2.90189026007905

Epoch: 6| Step: 12
Training loss: 2.596301375107154
Validation loss: 2.90053474225938

Epoch: 6| Step: 13
Training loss: 3.1579336076151097
Validation loss: 2.9012245148141362

Epoch: 176| Step: 0
Training loss: 3.354040976750025
Validation loss: 2.902087293673603

Epoch: 6| Step: 1
Training loss: 3.2913077114448015
Validation loss: 2.898814517888479

Epoch: 6| Step: 2
Training loss: 2.6036247808606596
Validation loss: 2.901634792084416

Epoch: 6| Step: 3
Training loss: 2.8500979490346987
Validation loss: 2.9050427762287634

Epoch: 6| Step: 4
Training loss: 2.9522259670806985
Validation loss: 2.9009616745265414

Epoch: 6| Step: 5
Training loss: 2.0707355570848462
Validation loss: 2.9026699220468566

Epoch: 6| Step: 6
Training loss: 3.057578667465362
Validation loss: 2.899860622329646

Epoch: 6| Step: 7
Training loss: 4.010028189467285
Validation loss: 2.9091764252047922

Epoch: 6| Step: 8
Training loss: 3.3584146235797796
Validation loss: 2.8979274737847485

Epoch: 6| Step: 9
Training loss: 2.294465338565909
Validation loss: 2.900177354520228

Epoch: 6| Step: 10
Training loss: 3.2657672175783103
Validation loss: 2.902790253906423

Epoch: 6| Step: 11
Training loss: 4.046113284974081
Validation loss: 2.89972101583894

Epoch: 6| Step: 12
Training loss: 3.973722211723208
Validation loss: 2.9020473806055254

Epoch: 6| Step: 13
Training loss: 2.569992091838381
Validation loss: 2.9020603770151734

Epoch: 177| Step: 0
Training loss: 2.810823067779147
Validation loss: 2.9036644443022395

Epoch: 6| Step: 1
Training loss: 2.757872410628687
Validation loss: 2.9024863606034317

Epoch: 6| Step: 2
Training loss: 3.0135962426713325
Validation loss: 2.906213371794952

Epoch: 6| Step: 3
Training loss: 2.6365147490527443
Validation loss: 2.907315226043231

Epoch: 6| Step: 4
Training loss: 3.3882957227739525
Validation loss: 2.908901793275773

Epoch: 6| Step: 5
Training loss: 3.1736194342446806
Validation loss: 2.9093728419898466

Epoch: 6| Step: 6
Training loss: 3.143479904797426
Validation loss: 2.906734144391503

Epoch: 6| Step: 7
Training loss: 3.3435472088221023
Validation loss: 2.917455651470374

Epoch: 6| Step: 8
Training loss: 3.678008326103573
Validation loss: 2.9079517450425847

Epoch: 6| Step: 9
Training loss: 3.309379115115625
Validation loss: 2.9069598730560684

Epoch: 6| Step: 10
Training loss: 2.9814713817747434
Validation loss: 2.90310640596586

Epoch: 6| Step: 11
Training loss: 3.685740940339795
Validation loss: 2.9028745277504022

Epoch: 6| Step: 12
Training loss: 3.4363713579058994
Validation loss: 2.899893444509613

Epoch: 6| Step: 13
Training loss: 3.1823061345963484
Validation loss: 2.900550214914339

Epoch: 178| Step: 0
Training loss: 3.1457539899980067
Validation loss: 2.9023951911775767

Epoch: 6| Step: 1
Training loss: 3.4465089134943345
Validation loss: 2.900722034853114

Epoch: 6| Step: 2
Training loss: 3.4554534932471803
Validation loss: 2.8987766531027184

Epoch: 6| Step: 3
Training loss: 3.244346102293916
Validation loss: 2.8996435076063314

Epoch: 6| Step: 4
Training loss: 3.38261754837532
Validation loss: 2.8997981038321337

Epoch: 6| Step: 5
Training loss: 2.5319613175473097
Validation loss: 2.9029907411691305

Epoch: 6| Step: 6
Training loss: 3.077623665352395
Validation loss: 2.9021330099018745

Epoch: 6| Step: 7
Training loss: 2.617693587379399
Validation loss: 2.90371544271354

Epoch: 6| Step: 8
Training loss: 4.023454566104582
Validation loss: 2.9010800818814597

Epoch: 6| Step: 9
Training loss: 3.0640955291477394
Validation loss: 2.900728438817133

Epoch: 6| Step: 10
Training loss: 4.059336442889082
Validation loss: 2.8973941926972415

Epoch: 6| Step: 11
Training loss: 2.3456356346972815
Validation loss: 2.8960987965925264

Epoch: 6| Step: 12
Training loss: 2.613616237638281
Validation loss: 2.8965899630682093

Epoch: 6| Step: 13
Training loss: 3.0321243440902785
Validation loss: 2.9027973722017113

Epoch: 179| Step: 0
Training loss: 2.5544293474427238
Validation loss: 2.902048983958558

Epoch: 6| Step: 1
Training loss: 3.9012476514853827
Validation loss: 2.909410486923173

Epoch: 6| Step: 2
Training loss: 3.1614391613315576
Validation loss: 2.9210263201419626

Epoch: 6| Step: 3
Training loss: 2.7132999559016326
Validation loss: 2.928789600447739

Epoch: 6| Step: 4
Training loss: 3.9260241684794015
Validation loss: 2.945090851231582

Epoch: 6| Step: 5
Training loss: 3.499098797986603
Validation loss: 2.927662859751436

Epoch: 6| Step: 6
Training loss: 3.1087986397552263
Validation loss: 2.9224882449093825

Epoch: 6| Step: 7
Training loss: 2.9916271352325587
Validation loss: 2.907534845110024

Epoch: 6| Step: 8
Training loss: 3.5724906704502533
Validation loss: 2.899114128835847

Epoch: 6| Step: 9
Training loss: 3.0808790250538243
Validation loss: 2.894805241157576

Epoch: 6| Step: 10
Training loss: 3.0799966921107376
Validation loss: 2.895861720184079

Epoch: 6| Step: 11
Training loss: 3.295585633304477
Validation loss: 2.8933397187440897

Epoch: 6| Step: 12
Training loss: 2.525663639897327
Validation loss: 2.9016638260404837

Epoch: 6| Step: 13
Training loss: 2.8080665401280327
Validation loss: 2.9014286808125607

Epoch: 180| Step: 0
Training loss: 3.1524065240709946
Validation loss: 2.907662270703532

Epoch: 6| Step: 1
Training loss: 3.0780388679652955
Validation loss: 2.9039984370285925

Epoch: 6| Step: 2
Training loss: 3.08730932720321
Validation loss: 2.900540374152711

Epoch: 6| Step: 3
Training loss: 3.4584814445921044
Validation loss: 2.899236176931989

Epoch: 6| Step: 4
Training loss: 2.9648239677885
Validation loss: 2.8994978765635055

Epoch: 6| Step: 5
Training loss: 3.9662342658634
Validation loss: 2.898900155128302

Epoch: 6| Step: 6
Training loss: 2.916500922443748
Validation loss: 2.8957551635923697

Epoch: 6| Step: 7
Training loss: 3.0754579714757875
Validation loss: 2.8947103413216

Epoch: 6| Step: 8
Training loss: 2.9064683729597225
Validation loss: 2.895942909597394

Epoch: 6| Step: 9
Training loss: 3.2293519161780666
Validation loss: 2.894108117980963

Epoch: 6| Step: 10
Training loss: 3.426083002317593
Validation loss: 2.8940044838942693

Epoch: 6| Step: 11
Training loss: 3.2083111716822015
Validation loss: 2.892789461473358

Epoch: 6| Step: 12
Training loss: 2.78154161617478
Validation loss: 2.892756697383845

Epoch: 6| Step: 13
Training loss: 3.470475875808018
Validation loss: 2.894779987266847

Epoch: 181| Step: 0
Training loss: 2.8465803544525965
Validation loss: 2.8915700549927252

Epoch: 6| Step: 1
Training loss: 3.2758429163253484
Validation loss: 2.894638626591115

Epoch: 6| Step: 2
Training loss: 2.8559299414881445
Validation loss: 2.895442202920271

Epoch: 6| Step: 3
Training loss: 3.069874661897176
Validation loss: 2.892960252255574

Epoch: 6| Step: 4
Training loss: 3.2780551433847616
Validation loss: 2.894178421503406

Epoch: 6| Step: 5
Training loss: 3.974203492981391
Validation loss: 2.8955943664929293

Epoch: 6| Step: 6
Training loss: 2.0636296502089313
Validation loss: 2.8951037864494085

Epoch: 6| Step: 7
Training loss: 3.518081688301732
Validation loss: 2.895169290355651

Epoch: 6| Step: 8
Training loss: 2.883659259110939
Validation loss: 2.893442919455673

Epoch: 6| Step: 9
Training loss: 2.9623744567795907
Validation loss: 2.8944651028043364

Epoch: 6| Step: 10
Training loss: 3.1448326961489665
Validation loss: 2.900770834010341

Epoch: 6| Step: 11
Training loss: 3.000610289486957
Validation loss: 2.8969788043489046

Epoch: 6| Step: 12
Training loss: 4.11597773750001
Validation loss: 2.8997953154564735

Epoch: 6| Step: 13
Training loss: 3.0846061828610676
Validation loss: 2.896399883363658

Epoch: 182| Step: 0
Training loss: 2.6882284197484343
Validation loss: 2.9038319182321644

Epoch: 6| Step: 1
Training loss: 3.591584324316944
Validation loss: 2.8967583761211135

Epoch: 6| Step: 2
Training loss: 3.6168957586435972
Validation loss: 2.894988899995329

Epoch: 6| Step: 3
Training loss: 2.850079210753336
Validation loss: 2.895587299548484

Epoch: 6| Step: 4
Training loss: 3.3080885680495404
Validation loss: 2.8940737703507193

Epoch: 6| Step: 5
Training loss: 2.5188255090493747
Validation loss: 2.8979095463732985

Epoch: 6| Step: 6
Training loss: 3.202704723047347
Validation loss: 2.8983629117195155

Epoch: 6| Step: 7
Training loss: 3.7239567825563133
Validation loss: 2.9000090277492045

Epoch: 6| Step: 8
Training loss: 3.0870716183890177
Validation loss: 2.8954666931345883

Epoch: 6| Step: 9
Training loss: 3.517258870550102
Validation loss: 2.8893041997141555

Epoch: 6| Step: 10
Training loss: 3.18603167654264
Validation loss: 2.8878813871493123

Epoch: 6| Step: 11
Training loss: 2.561623400105825
Validation loss: 2.887732860059695

Epoch: 6| Step: 12
Training loss: 3.4135641262389247
Validation loss: 2.8844791795322746

Epoch: 6| Step: 13
Training loss: 2.873208358448292
Validation loss: 2.8864140527993674

Epoch: 183| Step: 0
Training loss: 2.889138494206966
Validation loss: 2.887214141348753

Epoch: 6| Step: 1
Training loss: 3.0256680089915293
Validation loss: 2.889581016295145

Epoch: 6| Step: 2
Training loss: 3.324406655511033
Validation loss: 2.8869375693532313

Epoch: 6| Step: 3
Training loss: 2.916910942384217
Validation loss: 2.890807478005417

Epoch: 6| Step: 4
Training loss: 3.7509426203798206
Validation loss: 2.8937331774719253

Epoch: 6| Step: 5
Training loss: 3.859518318758447
Validation loss: 2.8905413605823833

Epoch: 6| Step: 6
Training loss: 3.521662973623751
Validation loss: 2.892095278901961

Epoch: 6| Step: 7
Training loss: 3.050424239874331
Validation loss: 2.8915101137119446

Epoch: 6| Step: 8
Training loss: 3.128053622808133
Validation loss: 2.896592530610831

Epoch: 6| Step: 9
Training loss: 3.2089350412747675
Validation loss: 2.9025626305871968

Epoch: 6| Step: 10
Training loss: 3.067508727716467
Validation loss: 2.896017885970656

Epoch: 6| Step: 11
Training loss: 2.3731442278448998
Validation loss: 2.8994751330439343

Epoch: 6| Step: 12
Training loss: 3.1436943883508515
Validation loss: 2.912377785619158

Epoch: 6| Step: 13
Training loss: 2.802061418828155
Validation loss: 2.8929061531379827

Epoch: 184| Step: 0
Training loss: 2.595995379227815
Validation loss: 2.8878981961479013

Epoch: 6| Step: 1
Training loss: 3.5855416139638248
Validation loss: 2.8876427012390353

Epoch: 6| Step: 2
Training loss: 3.347372499278469
Validation loss: 2.883178180852243

Epoch: 6| Step: 3
Training loss: 3.488719746025552
Validation loss: 2.883865974541056

Epoch: 6| Step: 4
Training loss: 2.7902739642593843
Validation loss: 2.8792723592952933

Epoch: 6| Step: 5
Training loss: 3.449658755688841
Validation loss: 2.881338649876599

Epoch: 6| Step: 6
Training loss: 3.4239105719537024
Validation loss: 2.883050429825147

Epoch: 6| Step: 7
Training loss: 3.0612042858469115
Validation loss: 2.8840611905958227

Epoch: 6| Step: 8
Training loss: 3.1064664953301664
Validation loss: 2.8803622881424684

Epoch: 6| Step: 9
Training loss: 3.5116315752354246
Validation loss: 2.8814977397937986

Epoch: 6| Step: 10
Training loss: 3.490572767285246
Validation loss: 2.8825453074083787

Epoch: 6| Step: 11
Training loss: 2.4706290132165263
Validation loss: 2.8799960743884196

Epoch: 6| Step: 12
Training loss: 2.8976964285937816
Validation loss: 2.8845271292028154

Epoch: 6| Step: 13
Training loss: 2.9292800823482694
Validation loss: 2.883916114988167

Epoch: 185| Step: 0
Training loss: 3.227617511574968
Validation loss: 2.880906692597387

Epoch: 6| Step: 1
Training loss: 2.35090430290396
Validation loss: 2.8823103146206046

Epoch: 6| Step: 2
Training loss: 3.0626653509849917
Validation loss: 2.877642468919678

Epoch: 6| Step: 3
Training loss: 4.4007414886612475
Validation loss: 2.882616461225363

Epoch: 6| Step: 4
Training loss: 3.016837869356003
Validation loss: 2.8804226794637966

Epoch: 6| Step: 5
Training loss: 3.5748286492958194
Validation loss: 2.87915340234314

Epoch: 6| Step: 6
Training loss: 2.5897709302604204
Validation loss: 2.8832028588198306

Epoch: 6| Step: 7
Training loss: 3.347279762276497
Validation loss: 2.88293171502265

Epoch: 6| Step: 8
Training loss: 3.6478596460463524
Validation loss: 2.8811440225880354

Epoch: 6| Step: 9
Training loss: 3.1391576878806013
Validation loss: 2.880696992658525

Epoch: 6| Step: 10
Training loss: 3.4175284314594934
Validation loss: 2.8830874341103594

Epoch: 6| Step: 11
Training loss: 2.932244164379661
Validation loss: 2.881613596496415

Epoch: 6| Step: 12
Training loss: 2.404093382813183
Validation loss: 2.8805715621191457

Epoch: 6| Step: 13
Training loss: 2.465782506671815
Validation loss: 2.8784124837245217

Epoch: 186| Step: 0
Training loss: 2.2826765642679443
Validation loss: 2.8802739226228904

Epoch: 6| Step: 1
Training loss: 3.721589615111487
Validation loss: 2.880687254944591

Epoch: 6| Step: 2
Training loss: 3.4753791766874778
Validation loss: 2.879109959570518

Epoch: 6| Step: 3
Training loss: 3.37630070241166
Validation loss: 2.883336366394238

Epoch: 6| Step: 4
Training loss: 3.089995138170683
Validation loss: 2.880934083643223

Epoch: 6| Step: 5
Training loss: 3.2523383018416863
Validation loss: 2.8816311475478464

Epoch: 6| Step: 6
Training loss: 2.8876804510101177
Validation loss: 2.8840340150313724

Epoch: 6| Step: 7
Training loss: 3.3369119190346495
Validation loss: 2.887536347409981

Epoch: 6| Step: 8
Training loss: 2.7058569713046023
Validation loss: 2.8837842957670143

Epoch: 6| Step: 9
Training loss: 3.066414336175644
Validation loss: 2.8848797437906035

Epoch: 6| Step: 10
Training loss: 2.2546066174503
Validation loss: 2.886709616958549

Epoch: 6| Step: 11
Training loss: 4.17893105194839
Validation loss: 2.8831384683893213

Epoch: 6| Step: 12
Training loss: 2.880374032209999
Validation loss: 2.877909876187644

Epoch: 6| Step: 13
Training loss: 3.5573803437752227
Validation loss: 2.879111768029579

Epoch: 187| Step: 0
Training loss: 2.2786788037049237
Validation loss: 2.8772685653962324

Epoch: 6| Step: 1
Training loss: 2.8951260551456315
Validation loss: 2.881895489323634

Epoch: 6| Step: 2
Training loss: 2.5617121904340956
Validation loss: 2.881991772724919

Epoch: 6| Step: 3
Training loss: 3.741473358756829
Validation loss: 2.8809807059306816

Epoch: 6| Step: 4
Training loss: 3.4549735114356057
Validation loss: 2.885541635462675

Epoch: 6| Step: 5
Training loss: 3.211575558420485
Validation loss: 2.884582306199195

Epoch: 6| Step: 6
Training loss: 3.2457261961923733
Validation loss: 2.889033876120861

Epoch: 6| Step: 7
Training loss: 3.2729305339076715
Validation loss: 2.892395839359487

Epoch: 6| Step: 8
Training loss: 3.5433243107314505
Validation loss: 2.8886426483366194

Epoch: 6| Step: 9
Training loss: 2.865025674595058
Validation loss: 2.8931427593063304

Epoch: 6| Step: 10
Training loss: 3.7907882064064298
Validation loss: 2.90180352458967

Epoch: 6| Step: 11
Training loss: 2.8890181740743404
Validation loss: 2.8881774899505404

Epoch: 6| Step: 12
Training loss: 3.1942926472150677
Validation loss: 2.8830152533060183

Epoch: 6| Step: 13
Training loss: 3.400782826005048
Validation loss: 2.879569384745099

Epoch: 188| Step: 0
Training loss: 3.576763577056391
Validation loss: 2.877676662559552

Epoch: 6| Step: 1
Training loss: 3.1712552672550305
Validation loss: 2.8753830225233616

Epoch: 6| Step: 2
Training loss: 3.616667015907751
Validation loss: 2.8769824846721925

Epoch: 6| Step: 3
Training loss: 3.5241215416151133
Validation loss: 2.8764882749835725

Epoch: 6| Step: 4
Training loss: 2.3700365100736382
Validation loss: 2.8740188811395417

Epoch: 6| Step: 5
Training loss: 2.7969228218295106
Validation loss: 2.876550706540436

Epoch: 6| Step: 6
Training loss: 2.6406952436686217
Validation loss: 2.876947395248772

Epoch: 6| Step: 7
Training loss: 3.429873103027086
Validation loss: 2.878827766380185

Epoch: 6| Step: 8
Training loss: 3.5542855842495684
Validation loss: 2.880092918867922

Epoch: 6| Step: 9
Training loss: 2.851007778610702
Validation loss: 2.8786404261091154

Epoch: 6| Step: 10
Training loss: 3.0198418579632498
Validation loss: 2.884364180974048

Epoch: 6| Step: 11
Training loss: 3.259307737744518
Validation loss: 2.8840725667095657

Epoch: 6| Step: 12
Training loss: 3.0398698141431115
Validation loss: 2.8778735340115915

Epoch: 6| Step: 13
Training loss: 3.3226311699525914
Validation loss: 2.880948275610405

Epoch: 189| Step: 0
Training loss: 3.3216367706112093
Validation loss: 2.8805170007107987

Epoch: 6| Step: 1
Training loss: 2.6883593227819587
Validation loss: 2.878135009825178

Epoch: 6| Step: 2
Training loss: 3.589038447231794
Validation loss: 2.880411784679295

Epoch: 6| Step: 3
Training loss: 2.937595609367015
Validation loss: 2.8772678178487845

Epoch: 6| Step: 4
Training loss: 3.0598703110083654
Validation loss: 2.880461843742154

Epoch: 6| Step: 5
Training loss: 2.5658425651236367
Validation loss: 2.8841841618906985

Epoch: 6| Step: 6
Training loss: 3.531737572421901
Validation loss: 2.881917100396038

Epoch: 6| Step: 7
Training loss: 2.365528393968696
Validation loss: 2.8767536373944047

Epoch: 6| Step: 8
Training loss: 3.5300139567934075
Validation loss: 2.8815592807951824

Epoch: 6| Step: 9
Training loss: 3.1821059418886155
Validation loss: 2.881511707897909

Epoch: 6| Step: 10
Training loss: 3.2291747226409506
Validation loss: 2.878505025486131

Epoch: 6| Step: 11
Training loss: 3.2604720788376462
Validation loss: 2.8782859988182743

Epoch: 6| Step: 12
Training loss: 3.3525878476005526
Validation loss: 2.8788738252524064

Epoch: 6| Step: 13
Training loss: 3.677368210661955
Validation loss: 2.877154102839015

Epoch: 190| Step: 0
Training loss: 3.314111137842569
Validation loss: 2.8724343406960977

Epoch: 6| Step: 1
Training loss: 2.3934420275467914
Validation loss: 2.8744111869255193

Epoch: 6| Step: 2
Training loss: 3.5266745303185907
Validation loss: 2.874137617106337

Epoch: 6| Step: 3
Training loss: 3.760609686099003
Validation loss: 2.8721990080097277

Epoch: 6| Step: 4
Training loss: 3.5447053028713262
Validation loss: 2.8703453259877483

Epoch: 6| Step: 5
Training loss: 3.607980962614259
Validation loss: 2.8732408846054973

Epoch: 6| Step: 6
Training loss: 2.2381442628919417
Validation loss: 2.875677626347428

Epoch: 6| Step: 7
Training loss: 3.1094587305191492
Validation loss: 2.8814811701537075

Epoch: 6| Step: 8
Training loss: 3.207545361216688
Validation loss: 2.8752324214115457

Epoch: 6| Step: 9
Training loss: 2.7658047375221293
Validation loss: 2.8820829693664036

Epoch: 6| Step: 10
Training loss: 2.8151670737682264
Validation loss: 2.882990452797323

Epoch: 6| Step: 11
Training loss: 3.6752049706836876
Validation loss: 2.8843781458625393

Epoch: 6| Step: 12
Training loss: 3.0028971352402305
Validation loss: 2.884241458231117

Epoch: 6| Step: 13
Training loss: 2.8076125169798107
Validation loss: 2.8866401120033753

Epoch: 191| Step: 0
Training loss: 3.4867025906211637
Validation loss: 2.877408648261113

Epoch: 6| Step: 1
Training loss: 3.6906758226582435
Validation loss: 2.877331258007907

Epoch: 6| Step: 2
Training loss: 3.3948588152870838
Validation loss: 2.8762305079915937

Epoch: 6| Step: 3
Training loss: 3.545835502316043
Validation loss: 2.8712217464102734

Epoch: 6| Step: 4
Training loss: 3.058395749597692
Validation loss: 2.8673521297884075

Epoch: 6| Step: 5
Training loss: 3.553431563626964
Validation loss: 2.8735478529351344

Epoch: 6| Step: 6
Training loss: 2.4728617168471416
Validation loss: 2.8689917746487428

Epoch: 6| Step: 7
Training loss: 2.9053106943514475
Validation loss: 2.8727738606166695

Epoch: 6| Step: 8
Training loss: 2.8555846392993063
Validation loss: 2.869385530749804

Epoch: 6| Step: 9
Training loss: 3.185005558314481
Validation loss: 2.8658769599992655

Epoch: 6| Step: 10
Training loss: 2.965949735558967
Validation loss: 2.869592454285366

Epoch: 6| Step: 11
Training loss: 3.23122174898116
Validation loss: 2.870142492257365

Epoch: 6| Step: 12
Training loss: 2.571737062780829
Validation loss: 2.8656457721033703

Epoch: 6| Step: 13
Training loss: 3.1589125176827166
Validation loss: 2.866411514784278

Epoch: 192| Step: 0
Training loss: 2.9251977315728297
Validation loss: 2.8658864510494686

Epoch: 6| Step: 1
Training loss: 3.151553597388036
Validation loss: 2.8653651159420095

Epoch: 6| Step: 2
Training loss: 2.733792488176124
Validation loss: 2.866055417791156

Epoch: 6| Step: 3
Training loss: 3.40840794513494
Validation loss: 2.863718382315116

Epoch: 6| Step: 4
Training loss: 3.6054585664384216
Validation loss: 2.8651055670820282

Epoch: 6| Step: 5
Training loss: 2.9582320361636874
Validation loss: 2.867126973859451

Epoch: 6| Step: 6
Training loss: 3.15658552444833
Validation loss: 2.864426136047861

Epoch: 6| Step: 7
Training loss: 2.803357332227435
Validation loss: 2.863406241799462

Epoch: 6| Step: 8
Training loss: 2.9546088471981204
Validation loss: 2.8647633449938907

Epoch: 6| Step: 9
Training loss: 3.8227182002439783
Validation loss: 2.8637705101487994

Epoch: 6| Step: 10
Training loss: 3.153409075912738
Validation loss: 2.8652036458746992

Epoch: 6| Step: 11
Training loss: 3.6576298123397084
Validation loss: 2.872362549080347

Epoch: 6| Step: 12
Training loss: 2.6926807768621153
Validation loss: 2.8653087359005616

Epoch: 6| Step: 13
Training loss: 2.9196759276644055
Validation loss: 2.871268609438004

Epoch: 193| Step: 0
Training loss: 3.1586337011293595
Validation loss: 2.867016748122622

Epoch: 6| Step: 1
Training loss: 3.537829455882679
Validation loss: 2.870747553401125

Epoch: 6| Step: 2
Training loss: 3.670194200579951
Validation loss: 2.867216407102844

Epoch: 6| Step: 3
Training loss: 2.752973163067934
Validation loss: 2.8700906918490516

Epoch: 6| Step: 4
Training loss: 2.714036912199023
Validation loss: 2.8631034171007106

Epoch: 6| Step: 5
Training loss: 3.6505869511060065
Validation loss: 2.8654004277228986

Epoch: 6| Step: 6
Training loss: 3.062974231358758
Validation loss: 2.8624258689955626

Epoch: 6| Step: 7
Training loss: 2.9372526024061663
Validation loss: 2.867993198927157

Epoch: 6| Step: 8
Training loss: 3.1839430166924974
Validation loss: 2.862284934632351

Epoch: 6| Step: 9
Training loss: 2.777211203544267
Validation loss: 2.8596297805705055

Epoch: 6| Step: 10
Training loss: 3.57451984408867
Validation loss: 2.860434837998497

Epoch: 6| Step: 11
Training loss: 2.6494124426943997
Validation loss: 2.85980962324476

Epoch: 6| Step: 12
Training loss: 3.3387782131589754
Validation loss: 2.862350582341611

Epoch: 6| Step: 13
Training loss: 2.8300767770873256
Validation loss: 2.8625822933920686

Epoch: 194| Step: 0
Training loss: 2.7738425375452915
Validation loss: 2.860917403666127

Epoch: 6| Step: 1
Training loss: 3.1011579811869927
Validation loss: 2.8599902685240646

Epoch: 6| Step: 2
Training loss: 2.992594320265618
Validation loss: 2.862712686198553

Epoch: 6| Step: 3
Training loss: 3.449934784646015
Validation loss: 2.861797554337301

Epoch: 6| Step: 4
Training loss: 2.9568485420251194
Validation loss: 2.8618094650662433

Epoch: 6| Step: 5
Training loss: 2.953958867937947
Validation loss: 2.8656867745544727

Epoch: 6| Step: 6
Training loss: 2.804565597052668
Validation loss: 2.8620583607270436

Epoch: 6| Step: 7
Training loss: 3.100037322281158
Validation loss: 2.861552852059836

Epoch: 6| Step: 8
Training loss: 3.741249173894269
Validation loss: 2.8602679798370754

Epoch: 6| Step: 9
Training loss: 3.3010460380572604
Validation loss: 2.8636040271927454

Epoch: 6| Step: 10
Training loss: 3.1697117235773185
Validation loss: 2.862545630343929

Epoch: 6| Step: 11
Training loss: 3.1660123115536334
Validation loss: 2.864448121460485

Epoch: 6| Step: 12
Training loss: 3.812291624284384
Validation loss: 2.861971396254354

Epoch: 6| Step: 13
Training loss: 2.1929672583672453
Validation loss: 2.861331748267138

Epoch: 195| Step: 0
Training loss: 3.3949576967101036
Validation loss: 2.8612180145545527

Epoch: 6| Step: 1
Training loss: 3.1721415290286132
Validation loss: 2.863934962187551

Epoch: 6| Step: 2
Training loss: 3.244493073776878
Validation loss: 2.868894433007978

Epoch: 6| Step: 3
Training loss: 2.509578475208532
Validation loss: 2.86027575876093

Epoch: 6| Step: 4
Training loss: 3.184746544063869
Validation loss: 2.869959251474979

Epoch: 6| Step: 5
Training loss: 3.961679964622312
Validation loss: 2.8725163261367794

Epoch: 6| Step: 6
Training loss: 2.310739620421087
Validation loss: 2.8745532337409587

Epoch: 6| Step: 7
Training loss: 3.390512490932879
Validation loss: 2.8749162680482807

Epoch: 6| Step: 8
Training loss: 3.16067813670967
Validation loss: 2.885338494596224

Epoch: 6| Step: 9
Training loss: 1.9287474037296328
Validation loss: 2.8777650142927262

Epoch: 6| Step: 10
Training loss: 3.4216810197586454
Validation loss: 2.865967884041868

Epoch: 6| Step: 11
Training loss: 2.9196530629817494
Validation loss: 2.8655105537012946

Epoch: 6| Step: 12
Training loss: 3.722121817782972
Validation loss: 2.8629615615408204

Epoch: 6| Step: 13
Training loss: 3.3279794294014997
Validation loss: 2.856349531302719

Epoch: 196| Step: 0
Training loss: 2.8100373400722094
Validation loss: 2.8567231252326346

Epoch: 6| Step: 1
Training loss: 3.2867081069139243
Validation loss: 2.856602865802699

Epoch: 6| Step: 2
Training loss: 2.4996599919851112
Validation loss: 2.8543884254667815

Epoch: 6| Step: 3
Training loss: 3.433248213913443
Validation loss: 2.8593152337676018

Epoch: 6| Step: 4
Training loss: 3.143549378441851
Validation loss: 2.8573453313966377

Epoch: 6| Step: 5
Training loss: 2.254289353205589
Validation loss: 2.858498790341829

Epoch: 6| Step: 6
Training loss: 3.243965121212249
Validation loss: 2.85707912646835

Epoch: 6| Step: 7
Training loss: 3.7451534741967634
Validation loss: 2.8576428731221553

Epoch: 6| Step: 8
Training loss: 3.47613673656951
Validation loss: 2.859423561609536

Epoch: 6| Step: 9
Training loss: 2.5077969084162905
Validation loss: 2.858970835428093

Epoch: 6| Step: 10
Training loss: 3.503250383894691
Validation loss: 2.8607552219393853

Epoch: 6| Step: 11
Training loss: 3.291418685907702
Validation loss: 2.856739619508343

Epoch: 6| Step: 12
Training loss: 3.443174637433063
Validation loss: 2.8572081356238317

Epoch: 6| Step: 13
Training loss: 3.129109846294275
Validation loss: 2.8561530216602664

Epoch: 197| Step: 0
Training loss: 3.2488683050674547
Validation loss: 2.855620063045247

Epoch: 6| Step: 1
Training loss: 2.7126992077785412
Validation loss: 2.8570335570171035

Epoch: 6| Step: 2
Training loss: 2.7852082963229607
Validation loss: 2.8592375322113353

Epoch: 6| Step: 3
Training loss: 2.8838636347981725
Validation loss: 2.8633187989679922

Epoch: 6| Step: 4
Training loss: 2.8444303599975824
Validation loss: 2.8734248671898337

Epoch: 6| Step: 5
Training loss: 2.645418590169033
Validation loss: 2.87210961030896

Epoch: 6| Step: 6
Training loss: 3.042667241762036
Validation loss: 2.8721286761489346

Epoch: 6| Step: 7
Training loss: 3.1161792625603444
Validation loss: 2.880194701890691

Epoch: 6| Step: 8
Training loss: 3.3669171501369366
Validation loss: 2.877692407782504

Epoch: 6| Step: 9
Training loss: 3.347360533358067
Validation loss: 2.8880442185974675

Epoch: 6| Step: 10
Training loss: 3.1002661929129482
Validation loss: 2.8864445578947473

Epoch: 6| Step: 11
Training loss: 3.8455048563748857
Validation loss: 2.8882297674898965

Epoch: 6| Step: 12
Training loss: 3.8570945272495814
Validation loss: 2.874125547853262

Epoch: 6| Step: 13
Training loss: 3.1287410468637504
Validation loss: 2.8657796369031505

Epoch: 198| Step: 0
Training loss: 2.9243106584019527
Validation loss: 2.8522920730168946

Epoch: 6| Step: 1
Training loss: 2.624537654304991
Validation loss: 2.854455515741956

Epoch: 6| Step: 2
Training loss: 2.431922007753216
Validation loss: 2.8574530269435416

Epoch: 6| Step: 3
Training loss: 3.1394083124056915
Validation loss: 2.8585227988780013

Epoch: 6| Step: 4
Training loss: 2.77980964310805
Validation loss: 2.8569966872682326

Epoch: 6| Step: 5
Training loss: 3.138484396139253
Validation loss: 2.8548657344352173

Epoch: 6| Step: 6
Training loss: 3.454748264090642
Validation loss: 2.857290409016633

Epoch: 6| Step: 7
Training loss: 3.612640093030644
Validation loss: 2.856870263730089

Epoch: 6| Step: 8
Training loss: 2.8850178540502096
Validation loss: 2.857138861413145

Epoch: 6| Step: 9
Training loss: 3.0124506079712425
Validation loss: 2.8583382113677684

Epoch: 6| Step: 10
Training loss: 3.023915019016958
Validation loss: 2.858743129887172

Epoch: 6| Step: 11
Training loss: 3.1613581650443963
Validation loss: 2.858416096117461

Epoch: 6| Step: 12
Training loss: 3.5885700876174447
Validation loss: 2.8568476806831624

Epoch: 6| Step: 13
Training loss: 4.681877120708433
Validation loss: 2.8593312854183353

Epoch: 199| Step: 0
Training loss: 2.9478837585409687
Validation loss: 2.8582571045388896

Epoch: 6| Step: 1
Training loss: 2.9823459298307804
Validation loss: 2.8572753579791916

Epoch: 6| Step: 2
Training loss: 3.399264951798317
Validation loss: 2.8570618310695783

Epoch: 6| Step: 3
Training loss: 3.242512073126723
Validation loss: 2.856355901916938

Epoch: 6| Step: 4
Training loss: 3.6822957961056155
Validation loss: 2.8569957477739036

Epoch: 6| Step: 5
Training loss: 2.973791078762419
Validation loss: 2.854747105706891

Epoch: 6| Step: 6
Training loss: 2.861442277213146
Validation loss: 2.8546664868680565

Epoch: 6| Step: 7
Training loss: 2.790691679940698
Validation loss: 2.8542722558691875

Epoch: 6| Step: 8
Training loss: 3.200942472904465
Validation loss: 2.8554439795829114

Epoch: 6| Step: 9
Training loss: 2.8074605085358773
Validation loss: 2.8545539433930083

Epoch: 6| Step: 10
Training loss: 3.264078020247927
Validation loss: 2.852322582625913

Epoch: 6| Step: 11
Training loss: 3.1660624647117346
Validation loss: 2.85148322421829

Epoch: 6| Step: 12
Training loss: 3.543661535595269
Validation loss: 2.8521479386766875

Epoch: 6| Step: 13
Training loss: 3.2877472991178087
Validation loss: 2.854098404446107

Epoch: 200| Step: 0
Training loss: 3.6130699632059433
Validation loss: 2.8521948778055495

Epoch: 6| Step: 1
Training loss: 2.6294983966399617
Validation loss: 2.8555450072395008

Epoch: 6| Step: 2
Training loss: 3.0189475300927517
Validation loss: 2.8538572627084364

Epoch: 6| Step: 3
Training loss: 2.7989110089186378
Validation loss: 2.8536078152426705

Epoch: 6| Step: 4
Training loss: 3.199583449670255
Validation loss: 2.856294973024782

Epoch: 6| Step: 5
Training loss: 3.1495503240871576
Validation loss: 2.855925624660566

Epoch: 6| Step: 6
Training loss: 3.075657199008132
Validation loss: 2.8555337975825976

Epoch: 6| Step: 7
Training loss: 2.779286924064231
Validation loss: 2.858475825992781

Epoch: 6| Step: 8
Training loss: 4.186023053145413
Validation loss: 2.858018685802148

Epoch: 6| Step: 9
Training loss: 2.9757972995268167
Validation loss: 2.855715097565212

Epoch: 6| Step: 10
Training loss: 3.5373246597670662
Validation loss: 2.856578673306753

Epoch: 6| Step: 11
Training loss: 2.9654517875872464
Validation loss: 2.853972213177419

Epoch: 6| Step: 12
Training loss: 3.280822435405661
Validation loss: 2.8531638604525194

Epoch: 6| Step: 13
Training loss: 1.8310996739265402
Validation loss: 2.85377972157084

Epoch: 201| Step: 0
Training loss: 3.4973102861149914
Validation loss: 2.8529688270182505

Epoch: 6| Step: 1
Training loss: 2.944119563463292
Validation loss: 2.857889281759894

Epoch: 6| Step: 2
Training loss: 2.6413603892910418
Validation loss: 2.86204756891335

Epoch: 6| Step: 3
Training loss: 3.448829983222401
Validation loss: 2.854078819791882

Epoch: 6| Step: 4
Training loss: 3.450808062804409
Validation loss: 2.8568534435677804

Epoch: 6| Step: 5
Training loss: 3.346602889538667
Validation loss: 2.8539416619169895

Epoch: 6| Step: 6
Training loss: 3.12259520508492
Validation loss: 2.8524954130185045

Epoch: 6| Step: 7
Training loss: 3.172992077384457
Validation loss: 2.85351310225016

Epoch: 6| Step: 8
Training loss: 2.9626595112153087
Validation loss: 2.850586200106723

Epoch: 6| Step: 9
Training loss: 3.429034125237522
Validation loss: 2.8494317109016

Epoch: 6| Step: 10
Training loss: 3.055422487154961
Validation loss: 2.8490320701450536

Epoch: 6| Step: 11
Training loss: 2.9422212360735136
Validation loss: 2.852183658577299

Epoch: 6| Step: 12
Training loss: 2.5447669168695684
Validation loss: 2.847682109047864

Epoch: 6| Step: 13
Training loss: 3.425922525726861
Validation loss: 2.8459811215783626

Epoch: 202| Step: 0
Training loss: 3.7010824630525905
Validation loss: 2.84572807930167

Epoch: 6| Step: 1
Training loss: 2.3958497641179677
Validation loss: 2.8423578189434915

Epoch: 6| Step: 2
Training loss: 3.165019627611188
Validation loss: 2.8496743089334733

Epoch: 6| Step: 3
Training loss: 3.2257121815289045
Validation loss: 2.851474091601603

Epoch: 6| Step: 4
Training loss: 3.4656777738194013
Validation loss: 2.8418546353261958

Epoch: 6| Step: 5
Training loss: 2.5171955963326593
Validation loss: 2.8458991193842014

Epoch: 6| Step: 6
Training loss: 3.296463493229498
Validation loss: 2.8526559991603473

Epoch: 6| Step: 7
Training loss: 3.3898306061049626
Validation loss: 2.852564897055945

Epoch: 6| Step: 8
Training loss: 2.6483970796544494
Validation loss: 2.852864001327176

Epoch: 6| Step: 9
Training loss: 3.658360320551456
Validation loss: 2.857892006965726

Epoch: 6| Step: 10
Training loss: 3.3818679442338264
Validation loss: 2.869502299961422

Epoch: 6| Step: 11
Training loss: 3.0948638452214636
Validation loss: 2.8638257397305464

Epoch: 6| Step: 12
Training loss: 2.3929364368176214
Validation loss: 2.85244151170969

Epoch: 6| Step: 13
Training loss: 3.4308828299874987
Validation loss: 2.842993087309772

Epoch: 203| Step: 0
Training loss: 3.091165407028294
Validation loss: 2.843582393589077

Epoch: 6| Step: 1
Training loss: 3.5267129293867554
Validation loss: 2.846810036940538

Epoch: 6| Step: 2
Training loss: 2.8899627751787644
Validation loss: 2.8434946602965057

Epoch: 6| Step: 3
Training loss: 3.091082415081515
Validation loss: 2.8399345425300164

Epoch: 6| Step: 4
Training loss: 2.868364388805539
Validation loss: 2.8427635924265546

Epoch: 6| Step: 5
Training loss: 3.5981549674265976
Validation loss: 2.842926764459639

Epoch: 6| Step: 6
Training loss: 2.427290049469352
Validation loss: 2.8427352023155867

Epoch: 6| Step: 7
Training loss: 2.783487684192139
Validation loss: 2.840922191377118

Epoch: 6| Step: 8
Training loss: 3.0647299296889363
Validation loss: 2.8418931547887682

Epoch: 6| Step: 9
Training loss: 3.5489818348660203
Validation loss: 2.8445953172933067

Epoch: 6| Step: 10
Training loss: 3.5016481061392386
Validation loss: 2.8429313490091404

Epoch: 6| Step: 11
Training loss: 2.9876331698691923
Validation loss: 2.845544136636293

Epoch: 6| Step: 12
Training loss: 3.3349133243764397
Validation loss: 2.8418105998143193

Epoch: 6| Step: 13
Training loss: 3.0540773997113653
Validation loss: 2.843645618807892

Epoch: 204| Step: 0
Training loss: 2.896187044858068
Validation loss: 2.8463982501736464

Epoch: 6| Step: 1
Training loss: 3.5105880257790383
Validation loss: 2.8438373747425554

Epoch: 6| Step: 2
Training loss: 2.6981502024392743
Validation loss: 2.840786061476513

Epoch: 6| Step: 3
Training loss: 3.211553584115485
Validation loss: 2.841106759026893

Epoch: 6| Step: 4
Training loss: 3.200167746915533
Validation loss: 2.8457337151598714

Epoch: 6| Step: 5
Training loss: 2.8876923402081425
Validation loss: 2.845054550809976

Epoch: 6| Step: 6
Training loss: 2.650291041820456
Validation loss: 2.848323126636091

Epoch: 6| Step: 7
Training loss: 2.9681293039457373
Validation loss: 2.845892247926867

Epoch: 6| Step: 8
Training loss: 2.943286796135681
Validation loss: 2.853244542413786

Epoch: 6| Step: 9
Training loss: 3.248690121118319
Validation loss: 2.862501332788318

Epoch: 6| Step: 10
Training loss: 3.450484979791125
Validation loss: 2.8690608850837385

Epoch: 6| Step: 11
Training loss: 3.1847522336205025
Validation loss: 2.8741336094884216

Epoch: 6| Step: 12
Training loss: 3.6989405687543506
Validation loss: 2.866639534122397

Epoch: 6| Step: 13
Training loss: 3.3935694412898707
Validation loss: 2.8496545530816113

Epoch: 205| Step: 0
Training loss: 3.4188048642514097
Validation loss: 2.844758372545438

Epoch: 6| Step: 1
Training loss: 3.172021721514185
Validation loss: 2.847608934464545

Epoch: 6| Step: 2
Training loss: 3.5086701497993187
Validation loss: 2.840746970188725

Epoch: 6| Step: 3
Training loss: 3.126335163992688
Validation loss: 2.8347686073513523

Epoch: 6| Step: 4
Training loss: 3.278813792868644
Validation loss: 2.839486224387278

Epoch: 6| Step: 5
Training loss: 3.0744880063946978
Validation loss: 2.837713734112689

Epoch: 6| Step: 6
Training loss: 3.0756480518788036
Validation loss: 2.8358854517698333

Epoch: 6| Step: 7
Training loss: 3.153168032818498
Validation loss: 2.8379911592044857

Epoch: 6| Step: 8
Training loss: 3.3853688085058757
Validation loss: 2.8332062921387458

Epoch: 6| Step: 9
Training loss: 3.3050753318523243
Validation loss: 2.834342717630198

Epoch: 6| Step: 10
Training loss: 2.0211359433258833
Validation loss: 2.835364825598249

Epoch: 6| Step: 11
Training loss: 3.1041356710298853
Validation loss: 2.8378561570393233

Epoch: 6| Step: 12
Training loss: 2.9686921766572723
Validation loss: 2.833875235744848

Epoch: 6| Step: 13
Training loss: 3.040454065393373
Validation loss: 2.8348127341655323

Epoch: 206| Step: 0
Training loss: 3.9039456093548206
Validation loss: 2.8344557379978816

Epoch: 6| Step: 1
Training loss: 2.7607072977102027
Validation loss: 2.8374795820896486

Epoch: 6| Step: 2
Training loss: 2.5788589819892858
Validation loss: 2.8384626687828147

Epoch: 6| Step: 3
Training loss: 3.3865299370215616
Validation loss: 2.833760094277014

Epoch: 6| Step: 4
Training loss: 3.1220185362359056
Validation loss: 2.8349615126314798

Epoch: 6| Step: 5
Training loss: 3.097624539264706
Validation loss: 2.8346953291324235

Epoch: 6| Step: 6
Training loss: 2.8212346394889325
Validation loss: 2.8332959292679627

Epoch: 6| Step: 7
Training loss: 3.302806273703653
Validation loss: 2.835601919671358

Epoch: 6| Step: 8
Training loss: 3.289274159052146
Validation loss: 2.8311552643305333

Epoch: 6| Step: 9
Training loss: 3.607037204128587
Validation loss: 2.833713568110875

Epoch: 6| Step: 10
Training loss: 3.2754425972788543
Validation loss: 2.833446949798664

Epoch: 6| Step: 11
Training loss: 2.717431987623764
Validation loss: 2.835548849064901

Epoch: 6| Step: 12
Training loss: 3.125786033956599
Validation loss: 2.8314511189738214

Epoch: 6| Step: 13
Training loss: 2.2457431154643483
Validation loss: 2.833472773856384

Epoch: 207| Step: 0
Training loss: 3.3443212288611757
Validation loss: 2.833522949231722

Epoch: 6| Step: 1
Training loss: 3.222424382046886
Validation loss: 2.8340571894587394

Epoch: 6| Step: 2
Training loss: 2.3822602179191357
Validation loss: 2.8492465785165333

Epoch: 6| Step: 3
Training loss: 3.2621067204702707
Validation loss: 2.853220696120285

Epoch: 6| Step: 4
Training loss: 2.548204227251607
Validation loss: 2.856084707430103

Epoch: 6| Step: 5
Training loss: 3.0152097426000264
Validation loss: 2.8696470197181014

Epoch: 6| Step: 6
Training loss: 2.9512368276480645
Validation loss: 2.8498437556190885

Epoch: 6| Step: 7
Training loss: 2.9151646879337503
Validation loss: 2.850589036617522

Epoch: 6| Step: 8
Training loss: 3.158080976833525
Validation loss: 2.8533312903855883

Epoch: 6| Step: 9
Training loss: 3.3518618292179
Validation loss: 2.841644643654264

Epoch: 6| Step: 10
Training loss: 3.545963926558903
Validation loss: 2.8359672372844753

Epoch: 6| Step: 11
Training loss: 3.0752615220424877
Validation loss: 2.831127973019988

Epoch: 6| Step: 12
Training loss: 3.665169034341113
Validation loss: 2.8315604286211578

Epoch: 6| Step: 13
Training loss: 3.300328764288882
Validation loss: 2.8305809078094044

Epoch: 208| Step: 0
Training loss: 2.9782850832909724
Validation loss: 2.828956677063332

Epoch: 6| Step: 1
Training loss: 3.7964108030285084
Validation loss: 2.8277638377609398

Epoch: 6| Step: 2
Training loss: 2.5688382358664708
Validation loss: 2.8295987031685352

Epoch: 6| Step: 3
Training loss: 3.2679820338377517
Validation loss: 2.8265703426966913

Epoch: 6| Step: 4
Training loss: 2.790050171431769
Validation loss: 2.8304308484211607

Epoch: 6| Step: 5
Training loss: 4.0066953890549035
Validation loss: 2.8263925555686984

Epoch: 6| Step: 6
Training loss: 3.2232903613829422
Validation loss: 2.8273426016791756

Epoch: 6| Step: 7
Training loss: 2.5162039143965385
Validation loss: 2.8265140187244007

Epoch: 6| Step: 8
Training loss: 3.50452103850877
Validation loss: 2.8290704073745783

Epoch: 6| Step: 9
Training loss: 3.3538361064650015
Validation loss: 2.8283352993216693

Epoch: 6| Step: 10
Training loss: 2.5773284606387588
Validation loss: 2.82877257003844

Epoch: 6| Step: 11
Training loss: 2.887911290853708
Validation loss: 2.8351600851732788

Epoch: 6| Step: 12
Training loss: 2.8414626092070057
Validation loss: 2.8305260412303213

Epoch: 6| Step: 13
Training loss: 3.1524844226860695
Validation loss: 2.8255701921095877

Epoch: 209| Step: 0
Training loss: 4.030029585282464
Validation loss: 2.8283392685025754

Epoch: 6| Step: 1
Training loss: 3.271502448644105
Validation loss: 2.830756546348315

Epoch: 6| Step: 2
Training loss: 3.6139105501404574
Validation loss: 2.824177048371786

Epoch: 6| Step: 3
Training loss: 3.449493293593125
Validation loss: 2.826424282613234

Epoch: 6| Step: 4
Training loss: 2.7051697863531685
Validation loss: 2.821739038023222

Epoch: 6| Step: 5
Training loss: 2.9395413711836733
Validation loss: 2.825166420077993

Epoch: 6| Step: 6
Training loss: 3.0232365662195786
Validation loss: 2.826990392527427

Epoch: 6| Step: 7
Training loss: 2.930047178441929
Validation loss: 2.829575763844919

Epoch: 6| Step: 8
Training loss: 2.6623778624123178
Validation loss: 2.8263425547505903

Epoch: 6| Step: 9
Training loss: 3.0719024191299193
Validation loss: 2.8306444976944225

Epoch: 6| Step: 10
Training loss: 2.9436671672594987
Validation loss: 2.8361440834351552

Epoch: 6| Step: 11
Training loss: 2.9669624166907917
Validation loss: 2.834845963118646

Epoch: 6| Step: 12
Training loss: 2.3243990788106252
Validation loss: 2.84615053683297

Epoch: 6| Step: 13
Training loss: 3.7316490023900393
Validation loss: 2.8336089854874653

Epoch: 210| Step: 0
Training loss: 3.394392460662431
Validation loss: 2.837317136772231

Epoch: 6| Step: 1
Training loss: 3.8288659449154525
Validation loss: 2.834470751024066

Epoch: 6| Step: 2
Training loss: 3.251871157234615
Validation loss: 2.8250505951592153

Epoch: 6| Step: 3
Training loss: 3.114116637988622
Validation loss: 2.825826452897788

Epoch: 6| Step: 4
Training loss: 2.8215255030835324
Validation loss: 2.8286344016968665

Epoch: 6| Step: 5
Training loss: 3.7662653081856923
Validation loss: 2.82510176676882

Epoch: 6| Step: 6
Training loss: 3.174813398749968
Validation loss: 2.825718660641919

Epoch: 6| Step: 7
Training loss: 2.8128078716042078
Validation loss: 2.825063924912855

Epoch: 6| Step: 8
Training loss: 3.2946534106786682
Validation loss: 2.8270205784985087

Epoch: 6| Step: 9
Training loss: 2.309717721247179
Validation loss: 2.824766797774706

Epoch: 6| Step: 10
Training loss: 2.6121163045392795
Validation loss: 2.8245231568642333

Epoch: 6| Step: 11
Training loss: 2.6343393850577614
Validation loss: 2.821283372358546

Epoch: 6| Step: 12
Training loss: 3.0534838868661276
Validation loss: 2.8259207448423527

Epoch: 6| Step: 13
Training loss: 3.522350608847096
Validation loss: 2.81987611568478

Epoch: 211| Step: 0
Training loss: 2.972265150130564
Validation loss: 2.8244162906152357

Epoch: 6| Step: 1
Training loss: 2.77745792030851
Validation loss: 2.820861792003156

Epoch: 6| Step: 2
Training loss: 3.285572801233013
Validation loss: 2.824137492074582

Epoch: 6| Step: 3
Training loss: 2.9832622590647078
Validation loss: 2.8202581526809953

Epoch: 6| Step: 4
Training loss: 3.397764783903294
Validation loss: 2.819087978704565

Epoch: 6| Step: 5
Training loss: 3.1195467861829034
Validation loss: 2.8196089262985176

Epoch: 6| Step: 6
Training loss: 3.047128676589142
Validation loss: 2.8186258433351847

Epoch: 6| Step: 7
Training loss: 3.1950023845729376
Validation loss: 2.8167457891895595

Epoch: 6| Step: 8
Training loss: 3.00504006763728
Validation loss: 2.8174373026355073

Epoch: 6| Step: 9
Training loss: 3.651025413807144
Validation loss: 2.818540614010286

Epoch: 6| Step: 10
Training loss: 3.1463913243728707
Validation loss: 2.822035071329819

Epoch: 6| Step: 11
Training loss: 2.8589664021372836
Validation loss: 2.8172789576654256

Epoch: 6| Step: 12
Training loss: 2.260814004832556
Validation loss: 2.822923501721643

Epoch: 6| Step: 13
Training loss: 4.226778881576976
Validation loss: 2.8231466328547157

Epoch: 212| Step: 0
Training loss: 2.5523921442362623
Validation loss: 2.8222389181038503

Epoch: 6| Step: 1
Training loss: 2.5450882524278966
Validation loss: 2.822262886285331

Epoch: 6| Step: 2
Training loss: 3.426213270934792
Validation loss: 2.82841538342557

Epoch: 6| Step: 3
Training loss: 3.1558325463122676
Validation loss: 2.8278896406310854

Epoch: 6| Step: 4
Training loss: 2.1507629016851526
Validation loss: 2.8282749351796537

Epoch: 6| Step: 5
Training loss: 3.3098940405351818
Validation loss: 2.83323071225792

Epoch: 6| Step: 6
Training loss: 2.72160198537383
Validation loss: 2.821702838236028

Epoch: 6| Step: 7
Training loss: 3.2030124551493393
Validation loss: 2.831661747981258

Epoch: 6| Step: 8
Training loss: 2.69110539807526
Validation loss: 2.822374290329879

Epoch: 6| Step: 9
Training loss: 4.511677742643727
Validation loss: 2.814866442930405

Epoch: 6| Step: 10
Training loss: 2.6318347598269627
Validation loss: 2.8160283752253537

Epoch: 6| Step: 11
Training loss: 3.370011775961204
Validation loss: 2.8149394495542737

Epoch: 6| Step: 12
Training loss: 3.537829725447476
Validation loss: 2.8133948740312715

Epoch: 6| Step: 13
Training loss: 3.293263559052747
Validation loss: 2.816417709599665

Epoch: 213| Step: 0
Training loss: 3.024996254658548
Validation loss: 2.8149180956633453

Epoch: 6| Step: 1
Training loss: 2.740766020988552
Validation loss: 2.8113204724989918

Epoch: 6| Step: 2
Training loss: 1.8508234923386078
Validation loss: 2.814620218086679

Epoch: 6| Step: 3
Training loss: 3.3777878161610237
Validation loss: 2.814120506942362

Epoch: 6| Step: 4
Training loss: 3.199729347704204
Validation loss: 2.8150691030918487

Epoch: 6| Step: 5
Training loss: 3.1027162649564324
Validation loss: 2.8160745435830923

Epoch: 6| Step: 6
Training loss: 3.1719593356341287
Validation loss: 2.812042011266148

Epoch: 6| Step: 7
Training loss: 3.2079543017797385
Validation loss: 2.815748886375389

Epoch: 6| Step: 8
Training loss: 2.7210183163005026
Validation loss: 2.815639402659006

Epoch: 6| Step: 9
Training loss: 3.284879003703139
Validation loss: 2.8163321908885064

Epoch: 6| Step: 10
Training loss: 3.4419180481911344
Validation loss: 2.8161858674435516

Epoch: 6| Step: 11
Training loss: 3.1679470752957664
Validation loss: 2.819082105880235

Epoch: 6| Step: 12
Training loss: 2.9380661439143307
Validation loss: 2.8164712503760136

Epoch: 6| Step: 13
Training loss: 4.593925213229542
Validation loss: 2.8209266042870342

Epoch: 214| Step: 0
Training loss: 2.7976479767498885
Validation loss: 2.820726127700052

Epoch: 6| Step: 1
Training loss: 3.768395255681064
Validation loss: 2.8273270919941025

Epoch: 6| Step: 2
Training loss: 2.8655492275457912
Validation loss: 2.8227144757785214

Epoch: 6| Step: 3
Training loss: 2.9493189914669684
Validation loss: 2.8189524441155593

Epoch: 6| Step: 4
Training loss: 2.9462285324822974
Validation loss: 2.8176125321788046

Epoch: 6| Step: 5
Training loss: 2.513493553066845
Validation loss: 2.816811042025205

Epoch: 6| Step: 6
Training loss: 2.8421206994409
Validation loss: 2.8164532213645037

Epoch: 6| Step: 7
Training loss: 3.659459979131783
Validation loss: 2.817755869217518

Epoch: 6| Step: 8
Training loss: 3.077858075801714
Validation loss: 2.811362187926162

Epoch: 6| Step: 9
Training loss: 3.8500649285724564
Validation loss: 2.8146697494990605

Epoch: 6| Step: 10
Training loss: 3.4180181358039294
Validation loss: 2.8082876684882843

Epoch: 6| Step: 11
Training loss: 3.340883541540286
Validation loss: 2.811910515083814

Epoch: 6| Step: 12
Training loss: 2.4514413875425203
Validation loss: 2.809608382196803

Epoch: 6| Step: 13
Training loss: 2.558542219036179
Validation loss: 2.8149120857255645

Epoch: 215| Step: 0
Training loss: 3.5156277126725644
Validation loss: 2.8101333979545675

Epoch: 6| Step: 1
Training loss: 3.392104287622642
Validation loss: 2.808808048090455

Epoch: 6| Step: 2
Training loss: 2.40714336506837
Validation loss: 2.810892463780271

Epoch: 6| Step: 3
Training loss: 2.8705138989822863
Validation loss: 2.809987521730126

Epoch: 6| Step: 4
Training loss: 2.74760731731334
Validation loss: 2.813299142566291

Epoch: 6| Step: 5
Training loss: 3.0414787826688525
Validation loss: 2.813511156917198

Epoch: 6| Step: 6
Training loss: 2.979244435680251
Validation loss: 2.8112889935654923

Epoch: 6| Step: 7
Training loss: 2.892392664494667
Validation loss: 2.8098855905367914

Epoch: 6| Step: 8
Training loss: 3.2002350959248997
Validation loss: 2.810006171552432

Epoch: 6| Step: 9
Training loss: 3.147107167472943
Validation loss: 2.8072597273467146

Epoch: 6| Step: 10
Training loss: 3.799851996902545
Validation loss: 2.8081389813234305

Epoch: 6| Step: 11
Training loss: 2.7494963271384814
Validation loss: 2.809148706440733

Epoch: 6| Step: 12
Training loss: 3.1108131341681213
Validation loss: 2.8084600257236034

Epoch: 6| Step: 13
Training loss: 3.8493122080967703
Validation loss: 2.810616695574912

Epoch: 216| Step: 0
Training loss: 2.611274530378633
Validation loss: 2.8123988544684777

Epoch: 6| Step: 1
Training loss: 2.784467058126299
Validation loss: 2.8123854373400845

Epoch: 6| Step: 2
Training loss: 3.508810126615385
Validation loss: 2.8177861368285377

Epoch: 6| Step: 3
Training loss: 2.8806099269652194
Validation loss: 2.8218004087025848

Epoch: 6| Step: 4
Training loss: 3.0075531290360624
Validation loss: 2.822733960624345

Epoch: 6| Step: 5
Training loss: 3.4341149048551847
Validation loss: 2.819853714574386

Epoch: 6| Step: 6
Training loss: 2.8553109392844696
Validation loss: 2.8273341844780093

Epoch: 6| Step: 7
Training loss: 2.900590205149291
Validation loss: 2.8347068373395077

Epoch: 6| Step: 8
Training loss: 3.4885115766361885
Validation loss: 2.82934545610232

Epoch: 6| Step: 9
Training loss: 3.4911961865947116
Validation loss: 2.830994001006372

Epoch: 6| Step: 10
Training loss: 3.6549295502642756
Validation loss: 2.8278760767060205

Epoch: 6| Step: 11
Training loss: 2.841675389370624
Validation loss: 2.825578205374326

Epoch: 6| Step: 12
Training loss: 2.978251140921201
Validation loss: 2.812925522128751

Epoch: 6| Step: 13
Training loss: 2.8593324751896754
Validation loss: 2.811956917890772

Epoch: 217| Step: 0
Training loss: 3.124472916975139
Validation loss: 2.806053513364263

Epoch: 6| Step: 1
Training loss: 2.5661069094477207
Validation loss: 2.808906888799085

Epoch: 6| Step: 2
Training loss: 3.3254931435543735
Validation loss: 2.805617890961166

Epoch: 6| Step: 3
Training loss: 3.1192274565246296
Validation loss: 2.8044981058316485

Epoch: 6| Step: 4
Training loss: 4.008567218473395
Validation loss: 2.8023123424368697

Epoch: 6| Step: 5
Training loss: 2.9882922602431967
Validation loss: 2.8043242124500383

Epoch: 6| Step: 6
Training loss: 2.8145136088768914
Validation loss: 2.8078302563129425

Epoch: 6| Step: 7
Training loss: 2.992294110423293
Validation loss: 2.8079373319987084

Epoch: 6| Step: 8
Training loss: 2.516900349392962
Validation loss: 2.8029452878801404

Epoch: 6| Step: 9
Training loss: 3.051002093929246
Validation loss: 2.8032328692826964

Epoch: 6| Step: 10
Training loss: 2.919680663897712
Validation loss: 2.803302729361064

Epoch: 6| Step: 11
Training loss: 3.364890605174266
Validation loss: 2.805303662172422

Epoch: 6| Step: 12
Training loss: 3.6200313058837783
Validation loss: 2.8049710897291265

Epoch: 6| Step: 13
Training loss: 2.633492582873837
Validation loss: 2.80565836077183

Epoch: 218| Step: 0
Training loss: 3.170109600494972
Validation loss: 2.805142428851912

Epoch: 6| Step: 1
Training loss: 2.4721009895040957
Validation loss: 2.8023746984156146

Epoch: 6| Step: 2
Training loss: 3.6331601868649295
Validation loss: 2.802845845466328

Epoch: 6| Step: 3
Training loss: 2.6262296793685787
Validation loss: 2.8022569983080143

Epoch: 6| Step: 4
Training loss: 3.6058550428303113
Validation loss: 2.802969513417602

Epoch: 6| Step: 5
Training loss: 2.5664866999495763
Validation loss: 2.8031299388673387

Epoch: 6| Step: 6
Training loss: 2.9195405334700713
Validation loss: 2.8014385294078807

Epoch: 6| Step: 7
Training loss: 3.467852777139066
Validation loss: 2.807008926338772

Epoch: 6| Step: 8
Training loss: 4.052302075964743
Validation loss: 2.8034447670268454

Epoch: 6| Step: 9
Training loss: 3.187055968229756
Validation loss: 2.8056321856703854

Epoch: 6| Step: 10
Training loss: 2.5640905142769967
Validation loss: 2.8074225329904134

Epoch: 6| Step: 11
Training loss: 2.9477549981492306
Validation loss: 2.807178360253596

Epoch: 6| Step: 12
Training loss: 3.2130181098852653
Validation loss: 2.805761245943779

Epoch: 6| Step: 13
Training loss: 2.193269586805898
Validation loss: 2.8081145201102142

Epoch: 219| Step: 0
Training loss: 3.2236974525384556
Validation loss: 2.808523714828889

Epoch: 6| Step: 1
Training loss: 3.7058136913161315
Validation loss: 2.820815833778707

Epoch: 6| Step: 2
Training loss: 2.9305500032473772
Validation loss: 2.8237552100443573

Epoch: 6| Step: 3
Training loss: 3.1570430552434874
Validation loss: 2.813698585912166

Epoch: 6| Step: 4
Training loss: 2.6985657449982807
Validation loss: 2.8147294627428248

Epoch: 6| Step: 5
Training loss: 2.962969160956505
Validation loss: 2.814266567929094

Epoch: 6| Step: 6
Training loss: 2.46306767383181
Validation loss: 2.8176292144626056

Epoch: 6| Step: 7
Training loss: 3.312784146771502
Validation loss: 2.8161361797190234

Epoch: 6| Step: 8
Training loss: 3.1793331164328444
Validation loss: 2.8084612890771172

Epoch: 6| Step: 9
Training loss: 3.1988371643616937
Validation loss: 2.805300258060671

Epoch: 6| Step: 10
Training loss: 3.5306225784733742
Validation loss: 2.8069546228351707

Epoch: 6| Step: 11
Training loss: 3.0326396470335486
Validation loss: 2.81101353330043

Epoch: 6| Step: 12
Training loss: 2.7592363437191256
Validation loss: 2.8076845900482255

Epoch: 6| Step: 13
Training loss: 3.2033012527727744
Validation loss: 2.8040478714215533

Epoch: 220| Step: 0
Training loss: 3.3401466990707873
Validation loss: 2.7999188355725426

Epoch: 6| Step: 1
Training loss: 3.271341968682273
Validation loss: 2.81374912301619

Epoch: 6| Step: 2
Training loss: 3.355681904427351
Validation loss: 2.802939095869776

Epoch: 6| Step: 3
Training loss: 3.500154628062755
Validation loss: 2.8034065971688715

Epoch: 6| Step: 4
Training loss: 3.3761861624079414
Validation loss: 2.804067334210689

Epoch: 6| Step: 5
Training loss: 3.1980819079589953
Validation loss: 2.80038653531555

Epoch: 6| Step: 6
Training loss: 2.809449300324487
Validation loss: 2.80404104825939

Epoch: 6| Step: 7
Training loss: 2.7085941091338634
Validation loss: 2.8016897220063974

Epoch: 6| Step: 8
Training loss: 3.108337535974629
Validation loss: 2.8014425284610325

Epoch: 6| Step: 9
Training loss: 2.8228954206467165
Validation loss: 2.801683161206772

Epoch: 6| Step: 10
Training loss: 3.014743023702419
Validation loss: 2.8001649368141055

Epoch: 6| Step: 11
Training loss: 2.984329782512894
Validation loss: 2.8012907992856957

Epoch: 6| Step: 12
Training loss: 2.2668670406785543
Validation loss: 2.804473135688432

Epoch: 6| Step: 13
Training loss: 3.795325697039247
Validation loss: 2.8016203707406104

Epoch: 221| Step: 0
Training loss: 3.0125420975019073
Validation loss: 2.802167295976031

Epoch: 6| Step: 1
Training loss: 3.6931462138133666
Validation loss: 2.8014546866456915

Epoch: 6| Step: 2
Training loss: 3.129274115683838
Validation loss: 2.807977690776871

Epoch: 6| Step: 3
Training loss: 2.5257123489964264
Validation loss: 2.808779588586545

Epoch: 6| Step: 4
Training loss: 2.991513965786407
Validation loss: 2.8101794697596154

Epoch: 6| Step: 5
Training loss: 2.1251943162821623
Validation loss: 2.796893629098102

Epoch: 6| Step: 6
Training loss: 4.18807045766009
Validation loss: 2.802292416444196

Epoch: 6| Step: 7
Training loss: 3.6012912077103585
Validation loss: 2.8074831327203547

Epoch: 6| Step: 8
Training loss: 2.7906150450320673
Validation loss: 2.7966175218625784

Epoch: 6| Step: 9
Training loss: 2.4515516739187446
Validation loss: 2.800000611391601

Epoch: 6| Step: 10
Training loss: 2.859111169202143
Validation loss: 2.8010077631829913

Epoch: 6| Step: 11
Training loss: 2.6538635304370106
Validation loss: 2.795478386399825

Epoch: 6| Step: 12
Training loss: 3.238694554586418
Validation loss: 2.7976151362020034

Epoch: 6| Step: 13
Training loss: 3.934207690304575
Validation loss: 2.799358946653032

Epoch: 222| Step: 0
Training loss: 3.618347904615847
Validation loss: 2.7965825103749764

Epoch: 6| Step: 1
Training loss: 2.739813752631534
Validation loss: 2.8022110908338194

Epoch: 6| Step: 2
Training loss: 3.4913473804194446
Validation loss: 2.7971098290191887

Epoch: 6| Step: 3
Training loss: 2.94244001847601
Validation loss: 2.793257771551088

Epoch: 6| Step: 4
Training loss: 3.892613037075313
Validation loss: 2.801048394786518

Epoch: 6| Step: 5
Training loss: 2.177895414274147
Validation loss: 2.800153488062904

Epoch: 6| Step: 6
Training loss: 3.622621216151091
Validation loss: 2.800018775638206

Epoch: 6| Step: 7
Training loss: 2.5235913114646364
Validation loss: 2.7988240764127705

Epoch: 6| Step: 8
Training loss: 3.1376106637838665
Validation loss: 2.7945727287778475

Epoch: 6| Step: 9
Training loss: 2.846201081389564
Validation loss: 2.800065864427036

Epoch: 6| Step: 10
Training loss: 2.511488077775232
Validation loss: 2.8014447164989105

Epoch: 6| Step: 11
Training loss: 3.19104196063851
Validation loss: 2.7992732424404716

Epoch: 6| Step: 12
Training loss: 3.0095273368520457
Validation loss: 2.79788187409251

Epoch: 6| Step: 13
Training loss: 3.371612685697448
Validation loss: 2.8020937388359144

Epoch: 223| Step: 0
Training loss: 2.8726707642795213
Validation loss: 2.803836441678506

Epoch: 6| Step: 1
Training loss: 3.103549426538709
Validation loss: 2.809927135672071

Epoch: 6| Step: 2
Training loss: 3.426524169818818
Validation loss: 2.80309166960642

Epoch: 6| Step: 3
Training loss: 2.117516523744861
Validation loss: 2.802288192638834

Epoch: 6| Step: 4
Training loss: 3.2509058643559348
Validation loss: 2.8016344753843723

Epoch: 6| Step: 5
Training loss: 3.5539182396512694
Validation loss: 2.8075334913308

Epoch: 6| Step: 6
Training loss: 3.264848242558302
Validation loss: 2.8012578092577334

Epoch: 6| Step: 7
Training loss: 3.1778230566816705
Validation loss: 2.8001416098768357

Epoch: 6| Step: 8
Training loss: 2.6908208157730713
Validation loss: 2.8022621470706905

Epoch: 6| Step: 9
Training loss: 3.4057336818402426
Validation loss: 2.804924467159729

Epoch: 6| Step: 10
Training loss: 3.194136050905524
Validation loss: 2.802457967766457

Epoch: 6| Step: 11
Training loss: 3.045601759707817
Validation loss: 2.8019709956653656

Epoch: 6| Step: 12
Training loss: 3.109728922421899
Validation loss: 2.8007046028324827

Epoch: 6| Step: 13
Training loss: 2.9020807036647853
Validation loss: 2.796367229548453

Epoch: 224| Step: 0
Training loss: 3.093753236711138
Validation loss: 2.7951332682449843

Epoch: 6| Step: 1
Training loss: 2.8961422615937997
Validation loss: 2.793703362649455

Epoch: 6| Step: 2
Training loss: 2.67323393590159
Validation loss: 2.791352906561246

Epoch: 6| Step: 3
Training loss: 3.6489006581686483
Validation loss: 2.796746009981954

Epoch: 6| Step: 4
Training loss: 3.1943371317064413
Validation loss: 2.7919046419622027

Epoch: 6| Step: 5
Training loss: 2.894954923236001
Validation loss: 2.791114122174376

Epoch: 6| Step: 6
Training loss: 2.9565293807104145
Validation loss: 2.785468729635694

Epoch: 6| Step: 7
Training loss: 2.6448002598129485
Validation loss: 2.7908081004173027

Epoch: 6| Step: 8
Training loss: 2.976842191276302
Validation loss: 2.790440946135127

Epoch: 6| Step: 9
Training loss: 3.2520481405038115
Validation loss: 2.788517994724101

Epoch: 6| Step: 10
Training loss: 3.15882556941125
Validation loss: 2.7899216983901645

Epoch: 6| Step: 11
Training loss: 3.22558312873591
Validation loss: 2.790277361896111

Epoch: 6| Step: 12
Training loss: 3.468854747943347
Validation loss: 2.7892825090801403

Epoch: 6| Step: 13
Training loss: 3.2103296154646177
Validation loss: 2.7918036042668337

Epoch: 225| Step: 0
Training loss: 2.7902002231302774
Validation loss: 2.794003275718533

Epoch: 6| Step: 1
Training loss: 3.4419654279321397
Validation loss: 2.7964735863050567

Epoch: 6| Step: 2
Training loss: 3.2355259123807834
Validation loss: 2.7957867523881097

Epoch: 6| Step: 3
Training loss: 2.807589164262322
Validation loss: 2.792122919459027

Epoch: 6| Step: 4
Training loss: 3.3337269232759015
Validation loss: 2.8063226227766336

Epoch: 6| Step: 5
Training loss: 3.2088825862108763
Validation loss: 2.806144933247673

Epoch: 6| Step: 6
Training loss: 2.6790792147382976
Validation loss: 2.803788948983252

Epoch: 6| Step: 7
Training loss: 3.099654910661112
Validation loss: 2.807713634972681

Epoch: 6| Step: 8
Training loss: 2.6767583469194105
Validation loss: 2.8122028991484647

Epoch: 6| Step: 9
Training loss: 3.152392154213259
Validation loss: 2.8016792155692505

Epoch: 6| Step: 10
Training loss: 3.4844963839475644
Validation loss: 2.7996149785761273

Epoch: 6| Step: 11
Training loss: 2.771137412076512
Validation loss: 2.8199399442364435

Epoch: 6| Step: 12
Training loss: 3.333518372803919
Validation loss: 2.8094742317153645

Epoch: 6| Step: 13
Training loss: 3.2569524787057245
Validation loss: 2.804987318928507

Epoch: 226| Step: 0
Training loss: 2.7692375942089065
Validation loss: 2.805348982614832

Epoch: 6| Step: 1
Training loss: 2.9385207005865857
Validation loss: 2.7927709214389997

Epoch: 6| Step: 2
Training loss: 2.966508681844779
Validation loss: 2.791835800603826

Epoch: 6| Step: 3
Training loss: 2.9993961044303523
Validation loss: 2.7873261903593587

Epoch: 6| Step: 4
Training loss: 2.901784111274025
Validation loss: 2.790303885922272

Epoch: 6| Step: 5
Training loss: 3.6223284644035694
Validation loss: 2.7882087853004744

Epoch: 6| Step: 6
Training loss: 2.8271098132616346
Validation loss: 2.789776428588264

Epoch: 6| Step: 7
Training loss: 2.2883518404766754
Validation loss: 2.792598946738606

Epoch: 6| Step: 8
Training loss: 3.808998876690167
Validation loss: 2.7933864564264437

Epoch: 6| Step: 9
Training loss: 2.94453982632573
Validation loss: 2.7937992315236935

Epoch: 6| Step: 10
Training loss: 3.216845495230622
Validation loss: 2.7942202571055685

Epoch: 6| Step: 11
Training loss: 3.165918178105907
Validation loss: 2.7924647475343525

Epoch: 6| Step: 12
Training loss: 3.645707932994995
Validation loss: 2.794735480938653

Epoch: 6| Step: 13
Training loss: 2.8764687808308866
Validation loss: 2.792799386648424

Epoch: 227| Step: 0
Training loss: 2.605150103207433
Validation loss: 2.7893499557906307

Epoch: 6| Step: 1
Training loss: 3.3847842207726337
Validation loss: 2.7897375198849863

Epoch: 6| Step: 2
Training loss: 2.6804393903458035
Validation loss: 2.7926157692663094

Epoch: 6| Step: 3
Training loss: 3.222446134248758
Validation loss: 2.7905159092021123

Epoch: 6| Step: 4
Training loss: 2.226098584482932
Validation loss: 2.791030685230433

Epoch: 6| Step: 5
Training loss: 4.25410375495645
Validation loss: 2.7909481909858003

Epoch: 6| Step: 6
Training loss: 3.0671808710089787
Validation loss: 2.788668137139208

Epoch: 6| Step: 7
Training loss: 3.1811034403018694
Validation loss: 2.7888213096136862

Epoch: 6| Step: 8
Training loss: 3.103527762867627
Validation loss: 2.7929837850126846

Epoch: 6| Step: 9
Training loss: 3.976823899346816
Validation loss: 2.7948506496703582

Epoch: 6| Step: 10
Training loss: 2.9620835796260763
Validation loss: 2.797773685096989

Epoch: 6| Step: 11
Training loss: 2.6147368387295358
Validation loss: 2.7913968839461534

Epoch: 6| Step: 12
Training loss: 2.095239024399473
Validation loss: 2.797268991269134

Epoch: 6| Step: 13
Training loss: 3.467850852108652
Validation loss: 2.8033299504513387

Epoch: 228| Step: 0
Training loss: 4.207411158275972
Validation loss: 2.8041904308457535

Epoch: 6| Step: 1
Training loss: 3.179218379475454
Validation loss: 2.802076357477406

Epoch: 6| Step: 2
Training loss: 2.4411327971857846
Validation loss: 2.8127356117212416

Epoch: 6| Step: 3
Training loss: 2.997023377310479
Validation loss: 2.8136976201159167

Epoch: 6| Step: 4
Training loss: 2.7887049854566266
Validation loss: 2.811716464155361

Epoch: 6| Step: 5
Training loss: 3.0581704500844977
Validation loss: 2.8287732977756876

Epoch: 6| Step: 6
Training loss: 3.201500606357482
Validation loss: 2.8164793587058625

Epoch: 6| Step: 7
Training loss: 2.7408724074005892
Validation loss: 2.80541694134479

Epoch: 6| Step: 8
Training loss: 2.4326649174550234
Validation loss: 2.806481033265753

Epoch: 6| Step: 9
Training loss: 3.140126962220984
Validation loss: 2.800310994235332

Epoch: 6| Step: 10
Training loss: 3.1905583687605175
Validation loss: 2.7977991172907437

Epoch: 6| Step: 11
Training loss: 2.7936308389464677
Validation loss: 2.795420883881051

Epoch: 6| Step: 12
Training loss: 4.024912028802569
Validation loss: 2.790904250622015

Epoch: 6| Step: 13
Training loss: 2.2205017052179845
Validation loss: 2.790718389267034

Epoch: 229| Step: 0
Training loss: 2.375287389934939
Validation loss: 2.786097062874375

Epoch: 6| Step: 1
Training loss: 2.8264355750658035
Validation loss: 2.78816333980322

Epoch: 6| Step: 2
Training loss: 2.7964339094941
Validation loss: 2.7907096962476268

Epoch: 6| Step: 3
Training loss: 2.6968805589320244
Validation loss: 2.7877078141058145

Epoch: 6| Step: 4
Training loss: 3.524736727358851
Validation loss: 2.787366322400806

Epoch: 6| Step: 5
Training loss: 2.6064767789174037
Validation loss: 2.785722946974794

Epoch: 6| Step: 6
Training loss: 2.6345294368632
Validation loss: 2.783735502368765

Epoch: 6| Step: 7
Training loss: 3.129265887181174
Validation loss: 2.785358241621861

Epoch: 6| Step: 8
Training loss: 3.464039946927034
Validation loss: 2.7825170131034573

Epoch: 6| Step: 9
Training loss: 3.6945023082003687
Validation loss: 2.7799662482097762

Epoch: 6| Step: 10
Training loss: 3.499221987764326
Validation loss: 2.782250571303987

Epoch: 6| Step: 11
Training loss: 3.2284298127869078
Validation loss: 2.7821878195787297

Epoch: 6| Step: 12
Training loss: 3.4180818898685223
Validation loss: 2.7824467214427413

Epoch: 6| Step: 13
Training loss: 3.2013577680162353
Validation loss: 2.783459554336067

Epoch: 230| Step: 0
Training loss: 3.1757962647630915
Validation loss: 2.78338979489781

Epoch: 6| Step: 1
Training loss: 3.115576918373507
Validation loss: 2.785806680006748

Epoch: 6| Step: 2
Training loss: 2.3763889467571446
Validation loss: 2.7939138534325547

Epoch: 6| Step: 3
Training loss: 2.9285710763432626
Validation loss: 2.7984007349840683

Epoch: 6| Step: 4
Training loss: 3.7414267130985346
Validation loss: 2.826811715847017

Epoch: 6| Step: 5
Training loss: 3.4651189821630766
Validation loss: 2.824765329344948

Epoch: 6| Step: 6
Training loss: 3.3042685962427027
Validation loss: 2.8267134567705887

Epoch: 6| Step: 7
Training loss: 3.0724312264153686
Validation loss: 2.8143159616389486

Epoch: 6| Step: 8
Training loss: 3.7160518057818295
Validation loss: 2.805933362756724

Epoch: 6| Step: 9
Training loss: 2.6796286885116523
Validation loss: 2.7888719261457706

Epoch: 6| Step: 10
Training loss: 2.9369090683043426
Validation loss: 2.788154971667787

Epoch: 6| Step: 11
Training loss: 2.831362730901929
Validation loss: 2.7878004324125905

Epoch: 6| Step: 12
Training loss: 2.756685021080653
Validation loss: 2.792953573550414

Epoch: 6| Step: 13
Training loss: 3.0984858475922548
Validation loss: 2.783198002693775

Epoch: 231| Step: 0
Training loss: 3.836219668450243
Validation loss: 2.7830098294698877

Epoch: 6| Step: 1
Training loss: 3.085516869572583
Validation loss: 2.779172366746274

Epoch: 6| Step: 2
Training loss: 2.9578761074281883
Validation loss: 2.7770585741763623

Epoch: 6| Step: 3
Training loss: 3.599420734001699
Validation loss: 2.780743320386973

Epoch: 6| Step: 4
Training loss: 2.4862339574297225
Validation loss: 2.779362912964063

Epoch: 6| Step: 5
Training loss: 3.067228131795153
Validation loss: 2.7795945656543117

Epoch: 6| Step: 6
Training loss: 2.011190459873816
Validation loss: 2.7817563854961547

Epoch: 6| Step: 7
Training loss: 3.2841782355780316
Validation loss: 2.7819186793239346

Epoch: 6| Step: 8
Training loss: 3.2317107648695043
Validation loss: 2.7860727081102064

Epoch: 6| Step: 9
Training loss: 3.5894698154760096
Validation loss: 2.7832286571748495

Epoch: 6| Step: 10
Training loss: 2.8884044469262675
Validation loss: 2.7803101305967584

Epoch: 6| Step: 11
Training loss: 2.952691101814888
Validation loss: 2.7798957066874426

Epoch: 6| Step: 12
Training loss: 2.7288774429316645
Validation loss: 2.781146637619447

Epoch: 6| Step: 13
Training loss: 3.2770411064077205
Validation loss: 2.778351489540098

Epoch: 232| Step: 0
Training loss: 2.956878698488195
Validation loss: 2.791597828010961

Epoch: 6| Step: 1
Training loss: 3.088746156832914
Validation loss: 2.7883081217640324

Epoch: 6| Step: 2
Training loss: 3.546648060264636
Validation loss: 2.7867276472225875

Epoch: 6| Step: 3
Training loss: 2.6049031754729133
Validation loss: 2.7843442754209384

Epoch: 6| Step: 4
Training loss: 3.3381726105106484
Validation loss: 2.778105671579606

Epoch: 6| Step: 5
Training loss: 2.5619770539899256
Validation loss: 2.7750318442434216

Epoch: 6| Step: 6
Training loss: 3.455132086695273
Validation loss: 2.77661034423503

Epoch: 6| Step: 7
Training loss: 2.835855446040902
Validation loss: 2.7821365276397882

Epoch: 6| Step: 8
Training loss: 2.8173753655664147
Validation loss: 2.7824667683646025

Epoch: 6| Step: 9
Training loss: 3.2439127916121544
Validation loss: 2.783614416987621

Epoch: 6| Step: 10
Training loss: 3.394135376351823
Validation loss: 2.7884702319342645

Epoch: 6| Step: 11
Training loss: 3.065713247726401
Validation loss: 2.7857270256456435

Epoch: 6| Step: 12
Training loss: 3.0174769906191523
Validation loss: 2.7835532506497875

Epoch: 6| Step: 13
Training loss: 3.426114734872969
Validation loss: 2.783601130963579

Epoch: 233| Step: 0
Training loss: 2.9153616210777065
Validation loss: 2.7832501418224993

Epoch: 6| Step: 1
Training loss: 3.297451167811521
Validation loss: 2.781145424540005

Epoch: 6| Step: 2
Training loss: 2.166339653964237
Validation loss: 2.780208279642303

Epoch: 6| Step: 3
Training loss: 2.073684307435217
Validation loss: 2.78174636133675

Epoch: 6| Step: 4
Training loss: 3.4196954343937813
Validation loss: 2.7798233133792487

Epoch: 6| Step: 5
Training loss: 3.4353664365990038
Validation loss: 2.783066157864102

Epoch: 6| Step: 6
Training loss: 3.6414851535513852
Validation loss: 2.7788141083963587

Epoch: 6| Step: 7
Training loss: 2.7034836018571027
Validation loss: 2.7779020756082757

Epoch: 6| Step: 8
Training loss: 2.871711508795076
Validation loss: 2.7810427920471943

Epoch: 6| Step: 9
Training loss: 3.1339328503453343
Validation loss: 2.781218990029998

Epoch: 6| Step: 10
Training loss: 2.995075316333914
Validation loss: 2.7790070453982487

Epoch: 6| Step: 11
Training loss: 3.005076722293885
Validation loss: 2.7796202997562465

Epoch: 6| Step: 12
Training loss: 4.173337758542316
Validation loss: 2.7824174772596435

Epoch: 6| Step: 13
Training loss: 2.7722589272069733
Validation loss: 2.7790925572864755

Epoch: 234| Step: 0
Training loss: 2.3846261548397787
Validation loss: 2.78905910731757

Epoch: 6| Step: 1
Training loss: 3.007795378400944
Validation loss: 2.7844406451467814

Epoch: 6| Step: 2
Training loss: 2.772117193020894
Validation loss: 2.7922343278596484

Epoch: 6| Step: 3
Training loss: 3.705661854386168
Validation loss: 2.800667548992776

Epoch: 6| Step: 4
Training loss: 3.4974513992739347
Validation loss: 2.789954873920234

Epoch: 6| Step: 5
Training loss: 2.9427871198431674
Validation loss: 2.7939867588332867

Epoch: 6| Step: 6
Training loss: 3.5255989161112975
Validation loss: 2.784873197954786

Epoch: 6| Step: 7
Training loss: 3.281520287416873
Validation loss: 2.778370605465688

Epoch: 6| Step: 8
Training loss: 2.9291469227834006
Validation loss: 2.7796678530787338

Epoch: 6| Step: 9
Training loss: 3.083365534708767
Validation loss: 2.77827939740971

Epoch: 6| Step: 10
Training loss: 2.894142279184893
Validation loss: 2.7749498998569884

Epoch: 6| Step: 11
Training loss: 2.459420357156251
Validation loss: 2.772776117284767

Epoch: 6| Step: 12
Training loss: 3.1465671180344934
Validation loss: 2.7742139465150166

Epoch: 6| Step: 13
Training loss: 3.637083631458606
Validation loss: 2.7760735188097696

Epoch: 235| Step: 0
Training loss: 2.9757421769881627
Validation loss: 2.7753904162427894

Epoch: 6| Step: 1
Training loss: 2.4333942754072884
Validation loss: 2.771413445530739

Epoch: 6| Step: 2
Training loss: 3.1623283249166763
Validation loss: 2.771851617038607

Epoch: 6| Step: 3
Training loss: 3.079152821538527
Validation loss: 2.76877125863116

Epoch: 6| Step: 4
Training loss: 2.9820111084903203
Validation loss: 2.7744215471294282

Epoch: 6| Step: 5
Training loss: 3.610413240994991
Validation loss: 2.771679655460038

Epoch: 6| Step: 6
Training loss: 2.3364372611884896
Validation loss: 2.7725417478520997

Epoch: 6| Step: 7
Training loss: 3.1920459717807814
Validation loss: 2.7713330167035455

Epoch: 6| Step: 8
Training loss: 3.2334931134206197
Validation loss: 2.7742587241603283

Epoch: 6| Step: 9
Training loss: 3.338621109817194
Validation loss: 2.769998042549178

Epoch: 6| Step: 10
Training loss: 2.8037708877962304
Validation loss: 2.7732254763019624

Epoch: 6| Step: 11
Training loss: 2.92446670235174
Validation loss: 2.772041236702061

Epoch: 6| Step: 12
Training loss: 3.592415205154547
Validation loss: 2.771376616140801

Epoch: 6| Step: 13
Training loss: 3.4463084331950653
Validation loss: 2.7792073374338866

Epoch: 236| Step: 0
Training loss: 2.743542458716161
Validation loss: 2.7800925688825333

Epoch: 6| Step: 1
Training loss: 3.5681872563853565
Validation loss: 2.779006282488669

Epoch: 6| Step: 2
Training loss: 2.499915216915637
Validation loss: 2.771253250677213

Epoch: 6| Step: 3
Training loss: 2.505596001358057
Validation loss: 2.776915791566008

Epoch: 6| Step: 4
Training loss: 3.3854410649912086
Validation loss: 2.77489695067129

Epoch: 6| Step: 5
Training loss: 3.51687369317274
Validation loss: 2.770992543410372

Epoch: 6| Step: 6
Training loss: 3.0187267105120315
Validation loss: 2.7762107662943167

Epoch: 6| Step: 7
Training loss: 3.1404289829707213
Validation loss: 2.7753817407965027

Epoch: 6| Step: 8
Training loss: 3.1110044264288286
Validation loss: 2.777476205213368

Epoch: 6| Step: 9
Training loss: 2.821766570955708
Validation loss: 2.777365687235073

Epoch: 6| Step: 10
Training loss: 2.6694424805075463
Validation loss: 2.7721642942891633

Epoch: 6| Step: 11
Training loss: 3.247360771783249
Validation loss: 2.7781069450456597

Epoch: 6| Step: 12
Training loss: 3.0568130005808367
Validation loss: 2.7759579977181543

Epoch: 6| Step: 13
Training loss: 3.957420939982986
Validation loss: 2.773100725034085

Epoch: 237| Step: 0
Training loss: 2.9947492425097457
Validation loss: 2.7817137284249296

Epoch: 6| Step: 1
Training loss: 2.830587926930545
Validation loss: 2.7810475698729933

Epoch: 6| Step: 2
Training loss: 3.1024967967592434
Validation loss: 2.7803141858577773

Epoch: 6| Step: 3
Training loss: 3.2935755703394176
Validation loss: 2.779492497554258

Epoch: 6| Step: 4
Training loss: 3.6806393179968846
Validation loss: 2.7771171520192484

Epoch: 6| Step: 5
Training loss: 2.907471266889089
Validation loss: 2.7765105984881933

Epoch: 6| Step: 6
Training loss: 2.977934273439605
Validation loss: 2.777295279043487

Epoch: 6| Step: 7
Training loss: 3.150732978434003
Validation loss: 2.769719132899881

Epoch: 6| Step: 8
Training loss: 3.0644086223067206
Validation loss: 2.77418059475768

Epoch: 6| Step: 9
Training loss: 2.9312225796000595
Validation loss: 2.7700414269989575

Epoch: 6| Step: 10
Training loss: 3.258457915777278
Validation loss: 2.768545829511512

Epoch: 6| Step: 11
Training loss: 2.2946696171199457
Validation loss: 2.7705478050775567

Epoch: 6| Step: 12
Training loss: 3.558288896150682
Validation loss: 2.770309986952027

Epoch: 6| Step: 13
Training loss: 2.726692174762649
Validation loss: 2.766007052354322

Epoch: 238| Step: 0
Training loss: 3.370055921865972
Validation loss: 2.7649420902047894

Epoch: 6| Step: 1
Training loss: 3.0827966858834754
Validation loss: 2.7639936276588517

Epoch: 6| Step: 2
Training loss: 3.4613589338062205
Validation loss: 2.7635390809788647

Epoch: 6| Step: 3
Training loss: 3.43576436007711
Validation loss: 2.7680643673332583

Epoch: 6| Step: 4
Training loss: 2.9468596667379288
Validation loss: 2.7642071533601658

Epoch: 6| Step: 5
Training loss: 3.663963332796488
Validation loss: 2.764833596982739

Epoch: 6| Step: 6
Training loss: 2.8444311981919266
Validation loss: 2.764145972144725

Epoch: 6| Step: 7
Training loss: 3.427129604100671
Validation loss: 2.7696780037413

Epoch: 6| Step: 8
Training loss: 2.462116842910696
Validation loss: 2.764840328674793

Epoch: 6| Step: 9
Training loss: 2.4863090424505825
Validation loss: 2.7659163986909094

Epoch: 6| Step: 10
Training loss: 3.1554283356728896
Validation loss: 2.7674944814739684

Epoch: 6| Step: 11
Training loss: 2.275001433655004
Validation loss: 2.771657734267518

Epoch: 6| Step: 12
Training loss: 2.3919557345769458
Validation loss: 2.7708274334840017

Epoch: 6| Step: 13
Training loss: 3.992212343978469
Validation loss: 2.766699886406747

Epoch: 239| Step: 0
Training loss: 2.1481360761563897
Validation loss: 2.769018189478761

Epoch: 6| Step: 1
Training loss: 3.2342004406397535
Validation loss: 2.7751650361238225

Epoch: 6| Step: 2
Training loss: 3.501391679102857
Validation loss: 2.7717196829252697

Epoch: 6| Step: 3
Training loss: 2.9240851381694877
Validation loss: 2.7821291706557965

Epoch: 6| Step: 4
Training loss: 3.0780831735935226
Validation loss: 2.7709470533272675

Epoch: 6| Step: 5
Training loss: 3.181407266562982
Validation loss: 2.7763630636839456

Epoch: 6| Step: 6
Training loss: 3.4715553830154793
Validation loss: 2.7750383701275094

Epoch: 6| Step: 7
Training loss: 2.5638760849382827
Validation loss: 2.7705647032023344

Epoch: 6| Step: 8
Training loss: 3.2297170518649807
Validation loss: 2.770293686009942

Epoch: 6| Step: 9
Training loss: 2.5591897750733703
Validation loss: 2.774858744739116

Epoch: 6| Step: 10
Training loss: 2.996381166441361
Validation loss: 2.7671550487827554

Epoch: 6| Step: 11
Training loss: 3.6435792912429816
Validation loss: 2.7686716119587307

Epoch: 6| Step: 12
Training loss: 3.0062056571878286
Validation loss: 2.7664316450663415

Epoch: 6| Step: 13
Training loss: 3.2914295513524383
Validation loss: 2.76392631720473

Epoch: 240| Step: 0
Training loss: 3.178184810289435
Validation loss: 2.759434480968683

Epoch: 6| Step: 1
Training loss: 2.8220679402003146
Validation loss: 2.7646346578836605

Epoch: 6| Step: 2
Training loss: 3.179550430380222
Validation loss: 2.761792749412947

Epoch: 6| Step: 3
Training loss: 2.543268751505199
Validation loss: 2.760952580152514

Epoch: 6| Step: 4
Training loss: 3.4542369864514706
Validation loss: 2.7626293122596732

Epoch: 6| Step: 5
Training loss: 2.521205611890224
Validation loss: 2.77074189227582

Epoch: 6| Step: 6
Training loss: 3.742380921655164
Validation loss: 2.773753960738633

Epoch: 6| Step: 7
Training loss: 2.656838295808012
Validation loss: 2.774861537631459

Epoch: 6| Step: 8
Training loss: 2.5232533485135638
Validation loss: 2.774436263145645

Epoch: 6| Step: 9
Training loss: 3.0925282850028197
Validation loss: 2.765249565295129

Epoch: 6| Step: 10
Training loss: 3.822535330370239
Validation loss: 2.7790538786048518

Epoch: 6| Step: 11
Training loss: 3.304067855710836
Validation loss: 2.7785425875184493

Epoch: 6| Step: 12
Training loss: 2.726316861780534
Validation loss: 2.76534453311043

Epoch: 6| Step: 13
Training loss: 3.154734634871066
Validation loss: 2.767704257095022

Epoch: 241| Step: 0
Training loss: 3.904963655388145
Validation loss: 2.758011935838143

Epoch: 6| Step: 1
Training loss: 2.9077043073512923
Validation loss: 2.7573225186893704

Epoch: 6| Step: 2
Training loss: 2.807902668909891
Validation loss: 2.7617047292651047

Epoch: 6| Step: 3
Training loss: 3.676202958631936
Validation loss: 2.760104340065265

Epoch: 6| Step: 4
Training loss: 2.5904556863304564
Validation loss: 2.7578029103115145

Epoch: 6| Step: 5
Training loss: 3.187671881136694
Validation loss: 2.760858104759806

Epoch: 6| Step: 6
Training loss: 2.826940298901313
Validation loss: 2.7617491917557544

Epoch: 6| Step: 7
Training loss: 2.470253305612682
Validation loss: 2.759939078500845

Epoch: 6| Step: 8
Training loss: 2.579554028815707
Validation loss: 2.7613484604517327

Epoch: 6| Step: 9
Training loss: 2.761438941000113
Validation loss: 2.7645577698874226

Epoch: 6| Step: 10
Training loss: 3.2822941163365744
Validation loss: 2.7583151422618335

Epoch: 6| Step: 11
Training loss: 3.07767138551642
Validation loss: 2.755881291623813

Epoch: 6| Step: 12
Training loss: 3.2420032127124414
Validation loss: 2.7662733414307543

Epoch: 6| Step: 13
Training loss: 3.711436027369178
Validation loss: 2.761826205281841

Epoch: 242| Step: 0
Training loss: 2.4332814023821228
Validation loss: 2.7647090660687126

Epoch: 6| Step: 1
Training loss: 2.3503031352520645
Validation loss: 2.764569694320399

Epoch: 6| Step: 2
Training loss: 3.0896451285817355
Validation loss: 2.763440817161851

Epoch: 6| Step: 3
Training loss: 3.4492900836692217
Validation loss: 2.7683729708328695

Epoch: 6| Step: 4
Training loss: 2.8414434783485336
Validation loss: 2.7625583382492005

Epoch: 6| Step: 5
Training loss: 2.550977527024452
Validation loss: 2.7638354617237697

Epoch: 6| Step: 6
Training loss: 3.5787992550108223
Validation loss: 2.7682155218716034

Epoch: 6| Step: 7
Training loss: 3.483609923799777
Validation loss: 2.7601887035137573

Epoch: 6| Step: 8
Training loss: 2.7595362476830436
Validation loss: 2.7565854192508374

Epoch: 6| Step: 9
Training loss: 3.2742519776559034
Validation loss: 2.7573433098428777

Epoch: 6| Step: 10
Training loss: 2.397534626063325
Validation loss: 2.7577200728298363

Epoch: 6| Step: 11
Training loss: 4.062699533110699
Validation loss: 2.76248874887523

Epoch: 6| Step: 12
Training loss: 2.85972584724248
Validation loss: 2.760781597240069

Epoch: 6| Step: 13
Training loss: 3.5769072880171655
Validation loss: 2.7560987590880694

Epoch: 243| Step: 0
Training loss: 3.1198167157746393
Validation loss: 2.7579679187670685

Epoch: 6| Step: 1
Training loss: 2.900855523557609
Validation loss: 2.760389541861098

Epoch: 6| Step: 2
Training loss: 3.1676610757266674
Validation loss: 2.7580456169654837

Epoch: 6| Step: 3
Training loss: 3.0952446920024177
Validation loss: 2.767071642617912

Epoch: 6| Step: 4
Training loss: 2.4168193593512246
Validation loss: 2.7574554289354505

Epoch: 6| Step: 5
Training loss: 2.900838263804355
Validation loss: 2.754512104715248

Epoch: 6| Step: 6
Training loss: 3.458009880903434
Validation loss: 2.760674652903629

Epoch: 6| Step: 7
Training loss: 2.526911184092884
Validation loss: 2.755752725253367

Epoch: 6| Step: 8
Training loss: 3.140610576235924
Validation loss: 2.7537401081588055

Epoch: 6| Step: 9
Training loss: 2.9047641031999927
Validation loss: 2.7543431885164193

Epoch: 6| Step: 10
Training loss: 3.424210818066332
Validation loss: 2.757857690818719

Epoch: 6| Step: 11
Training loss: 3.7158946126359393
Validation loss: 2.7520975184944656

Epoch: 6| Step: 12
Training loss: 3.0584259961579274
Validation loss: 2.7550010849004924

Epoch: 6| Step: 13
Training loss: 2.8725300005615217
Validation loss: 2.75704613635105

Epoch: 244| Step: 0
Training loss: 3.108234905767444
Validation loss: 2.7530983705624763

Epoch: 6| Step: 1
Training loss: 2.8709514141482613
Validation loss: 2.7553583298121054

Epoch: 6| Step: 2
Training loss: 3.3892408789213495
Validation loss: 2.752126662883182

Epoch: 6| Step: 3
Training loss: 3.3282805930288717
Validation loss: 2.752638223478346

Epoch: 6| Step: 4
Training loss: 2.976217094665656
Validation loss: 2.753926333392962

Epoch: 6| Step: 5
Training loss: 2.90344710190273
Validation loss: 2.750725851724245

Epoch: 6| Step: 6
Training loss: 3.00214325321994
Validation loss: 2.755387382955421

Epoch: 6| Step: 7
Training loss: 2.9721316703082676
Validation loss: 2.7561332681824275

Epoch: 6| Step: 8
Training loss: 2.4789022951187722
Validation loss: 2.7519454413889353

Epoch: 6| Step: 9
Training loss: 3.829990352887387
Validation loss: 2.7525534274384986

Epoch: 6| Step: 10
Training loss: 2.780485841163183
Validation loss: 2.752149644134337

Epoch: 6| Step: 11
Training loss: 3.081940430824845
Validation loss: 2.7536936804527636

Epoch: 6| Step: 12
Training loss: 3.3736007050211123
Validation loss: 2.7561082282033365

Epoch: 6| Step: 13
Training loss: 2.2902593510785274
Validation loss: 2.755553730632878

Epoch: 245| Step: 0
Training loss: 3.1716067947720963
Validation loss: 2.757223694878557

Epoch: 6| Step: 1
Training loss: 3.373325921705143
Validation loss: 2.7621470053446426

Epoch: 6| Step: 2
Training loss: 2.837951449472917
Validation loss: 2.757884274729044

Epoch: 6| Step: 3
Training loss: 3.0646224160536506
Validation loss: 2.7572542095069497

Epoch: 6| Step: 4
Training loss: 2.883860658557142
Validation loss: 2.758014024479694

Epoch: 6| Step: 5
Training loss: 2.9116076236088926
Validation loss: 2.7571609556151633

Epoch: 6| Step: 6
Training loss: 3.335327092591549
Validation loss: 2.758346075133826

Epoch: 6| Step: 7
Training loss: 2.766773739623378
Validation loss: 2.755072037715131

Epoch: 6| Step: 8
Training loss: 3.163844725096199
Validation loss: 2.757384553255577

Epoch: 6| Step: 9
Training loss: 2.4274499531702984
Validation loss: 2.759468878669945

Epoch: 6| Step: 10
Training loss: 3.755375125194901
Validation loss: 2.756176943426171

Epoch: 6| Step: 11
Training loss: 3.066539824668327
Validation loss: 2.7543620419865325

Epoch: 6| Step: 12
Training loss: 3.1308281528679482
Validation loss: 2.756318644386716

Epoch: 6| Step: 13
Training loss: 2.7142986820742947
Validation loss: 2.7563562311654395

Epoch: 246| Step: 0
Training loss: 3.0724928396590054
Validation loss: 2.7622633852408196

Epoch: 6| Step: 1
Training loss: 2.4544365165117688
Validation loss: 2.760446930849239

Epoch: 6| Step: 2
Training loss: 2.3154609900087806
Validation loss: 2.7571174028891092

Epoch: 6| Step: 3
Training loss: 3.0306603556258342
Validation loss: 2.765553745978469

Epoch: 6| Step: 4
Training loss: 2.795553907671215
Validation loss: 2.7640826415244675

Epoch: 6| Step: 5
Training loss: 3.670036862263584
Validation loss: 2.7576816605305408

Epoch: 6| Step: 6
Training loss: 3.3672730331001315
Validation loss: 2.7632324555854764

Epoch: 6| Step: 7
Training loss: 3.1726760228641577
Validation loss: 2.7607666580061307

Epoch: 6| Step: 8
Training loss: 2.9400673867631837
Validation loss: 2.769217205265275

Epoch: 6| Step: 9
Training loss: 3.2357502100744844
Validation loss: 2.7689380354958253

Epoch: 6| Step: 10
Training loss: 3.6221860289634447
Validation loss: 2.7647965195305653

Epoch: 6| Step: 11
Training loss: 2.3921597609353724
Validation loss: 2.7648602640303297

Epoch: 6| Step: 12
Training loss: 3.2599759682547713
Validation loss: 2.758692680444497

Epoch: 6| Step: 13
Training loss: 3.336759157858306
Validation loss: 2.755629665086024

Epoch: 247| Step: 0
Training loss: 2.745751827653049
Validation loss: 2.7604283399716247

Epoch: 6| Step: 1
Training loss: 3.196367234283152
Validation loss: 2.753258779527888

Epoch: 6| Step: 2
Training loss: 3.335903766113102
Validation loss: 2.762314298163415

Epoch: 6| Step: 3
Training loss: 3.109993417861695
Validation loss: 2.7586050511355547

Epoch: 6| Step: 4
Training loss: 3.3237987212605287
Validation loss: 2.7635488622695332

Epoch: 6| Step: 5
Training loss: 3.3761594688031344
Validation loss: 2.756039141981763

Epoch: 6| Step: 6
Training loss: 2.7926547640925277
Validation loss: 2.753887270528427

Epoch: 6| Step: 7
Training loss: 2.950514835756721
Validation loss: 2.7552933057092215

Epoch: 6| Step: 8
Training loss: 3.3843649458097427
Validation loss: 2.7506514548587604

Epoch: 6| Step: 9
Training loss: 2.525284318685275
Validation loss: 2.7499966616717497

Epoch: 6| Step: 10
Training loss: 3.2254174073252986
Validation loss: 2.7505054289077058

Epoch: 6| Step: 11
Training loss: 2.9952435934770207
Validation loss: 2.754046045957463

Epoch: 6| Step: 12
Training loss: 2.8503957373275384
Validation loss: 2.7461140044221612

Epoch: 6| Step: 13
Training loss: 2.876628083036247
Validation loss: 2.7465131641791856

Epoch: 248| Step: 0
Training loss: 3.108523151509681
Validation loss: 2.7428647564579314

Epoch: 6| Step: 1
Training loss: 2.6961603130479435
Validation loss: 2.7432278115672646

Epoch: 6| Step: 2
Training loss: 2.5713658363016183
Validation loss: 2.7472852515041377

Epoch: 6| Step: 3
Training loss: 2.8062274073857396
Validation loss: 2.7483741637713304

Epoch: 6| Step: 4
Training loss: 3.4739864106118383
Validation loss: 2.747366167841536

Epoch: 6| Step: 5
Training loss: 3.089531382361677
Validation loss: 2.7488517228350116

Epoch: 6| Step: 6
Training loss: 3.874902539411979
Validation loss: 2.748572837809091

Epoch: 6| Step: 7
Training loss: 2.8404406060695737
Validation loss: 2.7506280127887317

Epoch: 6| Step: 8
Training loss: 3.369542831517744
Validation loss: 2.7547314335784896

Epoch: 6| Step: 9
Training loss: 2.8581458613211823
Validation loss: 2.754792159425131

Epoch: 6| Step: 10
Training loss: 3.6345988813933086
Validation loss: 2.75362382422556

Epoch: 6| Step: 11
Training loss: 2.0800644851738825
Validation loss: 2.747957366881029

Epoch: 6| Step: 12
Training loss: 2.7386739887256053
Validation loss: 2.7472913645901778

Epoch: 6| Step: 13
Training loss: 3.4372067413082847
Validation loss: 2.749020141816408

Epoch: 249| Step: 0
Training loss: 2.94688539472832
Validation loss: 2.7502442118179706

Epoch: 6| Step: 1
Training loss: 3.0517507812419
Validation loss: 2.7446612828198176

Epoch: 6| Step: 2
Training loss: 3.5342162510629347
Validation loss: 2.7467337141695496

Epoch: 6| Step: 3
Training loss: 3.218308205515512
Validation loss: 2.7438041026693694

Epoch: 6| Step: 4
Training loss: 2.8409193434096784
Validation loss: 2.7517854938807718

Epoch: 6| Step: 5
Training loss: 2.6658084998524822
Validation loss: 2.743676796153674

Epoch: 6| Step: 6
Training loss: 2.991048969761973
Validation loss: 2.741562526607767

Epoch: 6| Step: 7
Training loss: 2.765474821851649
Validation loss: 2.7398824208397707

Epoch: 6| Step: 8
Training loss: 3.620971545942254
Validation loss: 2.7431992548523203

Epoch: 6| Step: 9
Training loss: 3.119914991247727
Validation loss: 2.744004555711851

Epoch: 6| Step: 10
Training loss: 2.59810768736503
Validation loss: 2.740649129513187

Epoch: 6| Step: 11
Training loss: 3.3703659173643374
Validation loss: 2.742244764151432

Epoch: 6| Step: 12
Training loss: 3.029938718975529
Validation loss: 2.740572735085597

Epoch: 6| Step: 13
Training loss: 2.891734142414
Validation loss: 2.7453247967255883

Epoch: 250| Step: 0
Training loss: 3.387435045358573
Validation loss: 2.741848028309556

Epoch: 6| Step: 1
Training loss: 2.54753132419963
Validation loss: 2.738502249520259

Epoch: 6| Step: 2
Training loss: 3.0762937103849026
Validation loss: 2.744892457008644

Epoch: 6| Step: 3
Training loss: 3.125663686847382
Validation loss: 2.744497505062432

Epoch: 6| Step: 4
Training loss: 2.977940838494486
Validation loss: 2.7459921078123957

Epoch: 6| Step: 5
Training loss: 2.637960319665996
Validation loss: 2.7474284692033217

Epoch: 6| Step: 6
Training loss: 3.019548462970424
Validation loss: 2.7512718850387583

Epoch: 6| Step: 7
Training loss: 2.494434264723244
Validation loss: 2.7589815777060767

Epoch: 6| Step: 8
Training loss: 3.4242427072246144
Validation loss: 2.751263733622817

Epoch: 6| Step: 9
Training loss: 3.1783966518496802
Validation loss: 2.75678871289889

Epoch: 6| Step: 10
Training loss: 4.022638393413587
Validation loss: 2.7584420482909096

Epoch: 6| Step: 11
Training loss: 3.556752973496689
Validation loss: 2.7590804268243003

Epoch: 6| Step: 12
Training loss: 2.2736231148051496
Validation loss: 2.748854633547918

Epoch: 6| Step: 13
Training loss: 2.3192626427563576
Validation loss: 2.7478587501778486

Epoch: 251| Step: 0
Training loss: 3.661433791851134
Validation loss: 2.7458649363500958

Epoch: 6| Step: 1
Training loss: 2.955125242312736
Validation loss: 2.745128829362337

Epoch: 6| Step: 2
Training loss: 3.151240386161378
Validation loss: 2.7438492682000417

Epoch: 6| Step: 3
Training loss: 3.0173815419381267
Validation loss: 2.7433675507994075

Epoch: 6| Step: 4
Training loss: 3.5042796536682514
Validation loss: 2.739249097489874

Epoch: 6| Step: 5
Training loss: 2.8350112285088898
Validation loss: 2.7375637155473944

Epoch: 6| Step: 6
Training loss: 2.8106015897916423
Validation loss: 2.7348998135395837

Epoch: 6| Step: 7
Training loss: 2.6385495307846334
Validation loss: 2.741633531724471

Epoch: 6| Step: 8
Training loss: 2.7197585591980054
Validation loss: 2.7404648168911057

Epoch: 6| Step: 9
Training loss: 2.543721311815156
Validation loss: 2.7389854085278293

Epoch: 6| Step: 10
Training loss: 3.0657381338228777
Validation loss: 2.7402333159512606

Epoch: 6| Step: 11
Training loss: 3.272151721813028
Validation loss: 2.7358038825069912

Epoch: 6| Step: 12
Training loss: 3.3764635374297005
Validation loss: 2.739352369326148

Epoch: 6| Step: 13
Training loss: 3.0249858509079606
Validation loss: 2.738750918188602

Epoch: 252| Step: 0
Training loss: 2.8259800316603907
Validation loss: 2.739078563345473

Epoch: 6| Step: 1
Training loss: 2.7649624995470314
Validation loss: 2.738855682114946

Epoch: 6| Step: 2
Training loss: 3.072805542741587
Validation loss: 2.740264524972938

Epoch: 6| Step: 3
Training loss: 3.6096517613639505
Validation loss: 2.746426786327155

Epoch: 6| Step: 4
Training loss: 3.1669471683413715
Validation loss: 2.7449890042119187

Epoch: 6| Step: 5
Training loss: 3.0578044784043033
Validation loss: 2.7452231270012595

Epoch: 6| Step: 6
Training loss: 3.09709618449298
Validation loss: 2.7500960556064515

Epoch: 6| Step: 7
Training loss: 2.903545967517277
Validation loss: 2.7495359036624394

Epoch: 6| Step: 8
Training loss: 2.7554693452960444
Validation loss: 2.7507176110831653

Epoch: 6| Step: 9
Training loss: 3.308478018978362
Validation loss: 2.7489341262481273

Epoch: 6| Step: 10
Training loss: 3.0020735250538255
Validation loss: 2.7521116515168567

Epoch: 6| Step: 11
Training loss: 2.555745596891497
Validation loss: 2.7589698939435365

Epoch: 6| Step: 12
Training loss: 3.2818800548368516
Validation loss: 2.7750831566416103

Epoch: 6| Step: 13
Training loss: 3.3661879894779156
Validation loss: 2.7561780233228013

Epoch: 253| Step: 0
Training loss: 2.972186859807818
Validation loss: 2.7637596664593227

Epoch: 6| Step: 1
Training loss: 3.7109375
Validation loss: 2.765772120439283

Epoch: 6| Step: 2
Training loss: 2.556260397593797
Validation loss: 2.7501755534394956

Epoch: 6| Step: 3
Training loss: 2.9728432795754625
Validation loss: 2.7469157862665825

Epoch: 6| Step: 4
Training loss: 3.005064821480367
Validation loss: 2.7444197044714964

Epoch: 6| Step: 5
Training loss: 3.121796148180707
Validation loss: 2.7392490769002555

Epoch: 6| Step: 6
Training loss: 3.201027085461082
Validation loss: 2.7353913952216216

Epoch: 6| Step: 7
Training loss: 3.1053290185741402
Validation loss: 2.7394674229760065

Epoch: 6| Step: 8
Training loss: 2.6599612171529516
Validation loss: 2.735862928545174

Epoch: 6| Step: 9
Training loss: 3.1774474555472465
Validation loss: 2.73590357747661

Epoch: 6| Step: 10
Training loss: 2.7865259085093657
Validation loss: 2.737624201343009

Epoch: 6| Step: 11
Training loss: 3.005723896902239
Validation loss: 2.7394470679412435

Epoch: 6| Step: 12
Training loss: 2.9235394474850134
Validation loss: 2.738774701548385

Epoch: 6| Step: 13
Training loss: 3.6109348906206766
Validation loss: 2.739117797621333

Epoch: 254| Step: 0
Training loss: 2.3618359394381687
Validation loss: 2.7372557032810136

Epoch: 6| Step: 1
Training loss: 3.4244756701007972
Validation loss: 2.7358545953459283

Epoch: 6| Step: 2
Training loss: 3.404384697258985
Validation loss: 2.736168881722177

Epoch: 6| Step: 3
Training loss: 3.0407299184389345
Validation loss: 2.737547501493578

Epoch: 6| Step: 4
Training loss: 2.963599465359086
Validation loss: 2.7356093575960023

Epoch: 6| Step: 5
Training loss: 1.9782103654180494
Validation loss: 2.738302973085501

Epoch: 6| Step: 6
Training loss: 3.685845472635082
Validation loss: 2.738463535824028

Epoch: 6| Step: 7
Training loss: 2.8968188760828797
Validation loss: 2.7360069699690674

Epoch: 6| Step: 8
Training loss: 2.593015359917638
Validation loss: 2.7421820234153977

Epoch: 6| Step: 9
Training loss: 2.9934396539113473
Validation loss: 2.7460367444264273

Epoch: 6| Step: 10
Training loss: 3.2491085590555193
Validation loss: 2.7389815560238167

Epoch: 6| Step: 11
Training loss: 3.3055043755281495
Validation loss: 2.738095362321936

Epoch: 6| Step: 12
Training loss: 3.7183477360474817
Validation loss: 2.737740423216207

Epoch: 6| Step: 13
Training loss: 2.29880686371726
Validation loss: 2.7383924868945173

Epoch: 255| Step: 0
Training loss: 3.068261779359722
Validation loss: 2.7380874038784975

Epoch: 6| Step: 1
Training loss: 2.8329401491402604
Validation loss: 2.739804850378011

Epoch: 6| Step: 2
Training loss: 3.3767698380530127
Validation loss: 2.7373973422810685

Epoch: 6| Step: 3
Training loss: 2.3420530152090504
Validation loss: 2.743274970569101

Epoch: 6| Step: 4
Training loss: 3.020478764914482
Validation loss: 2.742276234478461

Epoch: 6| Step: 5
Training loss: 2.9814245208904904
Validation loss: 2.75257119416028

Epoch: 6| Step: 6
Training loss: 3.448839523187714
Validation loss: 2.7578985658685866

Epoch: 6| Step: 7
Training loss: 3.1551155090950984
Validation loss: 2.758793877936729

Epoch: 6| Step: 8
Training loss: 3.5337869089126666
Validation loss: 2.7554202867170865

Epoch: 6| Step: 9
Training loss: 2.456180491932088
Validation loss: 2.738339178157119

Epoch: 6| Step: 10
Training loss: 3.5621637553763845
Validation loss: 2.738545059187459

Epoch: 6| Step: 11
Training loss: 2.8377491442494485
Validation loss: 2.735344148100757

Epoch: 6| Step: 12
Training loss: 2.86592028312266
Validation loss: 2.736693364365211

Epoch: 6| Step: 13
Training loss: 3.0303818550839545
Validation loss: 2.734486032976933

Epoch: 256| Step: 0
Training loss: 2.8813265974409434
Validation loss: 2.7327726736296243

Epoch: 6| Step: 1
Training loss: 3.1709794908508133
Validation loss: 2.7307348235398705

Epoch: 6| Step: 2
Training loss: 3.92698342814299
Validation loss: 2.7299185772827332

Epoch: 6| Step: 3
Training loss: 3.230091594188645
Validation loss: 2.7290646132308733

Epoch: 6| Step: 4
Training loss: 2.9202176049552415
Validation loss: 2.732479319414677

Epoch: 6| Step: 5
Training loss: 3.058937959558789
Validation loss: 2.731864534771103

Epoch: 6| Step: 6
Training loss: 2.4613957054209203
Validation loss: 2.7378630898491907

Epoch: 6| Step: 7
Training loss: 2.3365813423755126
Validation loss: 2.7347062423874333

Epoch: 6| Step: 8
Training loss: 2.7316205783731924
Validation loss: 2.735195856832494

Epoch: 6| Step: 9
Training loss: 3.841731091756953
Validation loss: 2.7292912612976807

Epoch: 6| Step: 10
Training loss: 2.905672733852676
Validation loss: 2.736580920187645

Epoch: 6| Step: 11
Training loss: 2.5623084206026525
Validation loss: 2.734661993619965

Epoch: 6| Step: 12
Training loss: 3.3399845205165306
Validation loss: 2.737236192516276

Epoch: 6| Step: 13
Training loss: 2.754831751066582
Validation loss: 2.7461996014183923

Epoch: 257| Step: 0
Training loss: 2.3594920148316247
Validation loss: 2.752399865691472

Epoch: 6| Step: 1
Training loss: 3.5756022126155655
Validation loss: 2.7536635760379857

Epoch: 6| Step: 2
Training loss: 3.180989966416567
Validation loss: 2.753840440347656

Epoch: 6| Step: 3
Training loss: 3.598749282587741
Validation loss: 2.7629066030706295

Epoch: 6| Step: 4
Training loss: 2.9311220446152846
Validation loss: 2.756034930077262

Epoch: 6| Step: 5
Training loss: 3.265898916629628
Validation loss: 2.748819138681184

Epoch: 6| Step: 6
Training loss: 3.40614668663205
Validation loss: 2.746589960879384

Epoch: 6| Step: 7
Training loss: 2.759791974092412
Validation loss: 2.736835357508778

Epoch: 6| Step: 8
Training loss: 2.954639349292432
Validation loss: 2.755185943635985

Epoch: 6| Step: 9
Training loss: 2.6221893340363382
Validation loss: 2.745733237181404

Epoch: 6| Step: 10
Training loss: 3.189177427038642
Validation loss: 2.7400678925650497

Epoch: 6| Step: 11
Training loss: 2.5627950172865295
Validation loss: 2.75193243472296

Epoch: 6| Step: 12
Training loss: 3.070839562446422
Validation loss: 2.7425558532698266

Epoch: 6| Step: 13
Training loss: 2.8815822715895956
Validation loss: 2.736821601782757

Epoch: 258| Step: 0
Training loss: 3.265924613386271
Validation loss: 2.740098654382134

Epoch: 6| Step: 1
Training loss: 3.8864912877065536
Validation loss: 2.731951766233299

Epoch: 6| Step: 2
Training loss: 2.996430976122348
Validation loss: 2.7299848368269926

Epoch: 6| Step: 3
Training loss: 2.838149372022226
Validation loss: 2.7266600826689493

Epoch: 6| Step: 4
Training loss: 2.738658492676306
Validation loss: 2.727288360122072

Epoch: 6| Step: 5
Training loss: 2.9778426814083523
Validation loss: 2.7276773197243003

Epoch: 6| Step: 6
Training loss: 3.205372538227918
Validation loss: 2.7263687609830125

Epoch: 6| Step: 7
Training loss: 3.153556051742917
Validation loss: 2.7287696719346353

Epoch: 6| Step: 8
Training loss: 2.9049358062742487
Validation loss: 2.7281791655792595

Epoch: 6| Step: 9
Training loss: 3.0019213563706137
Validation loss: 2.7294714415495944

Epoch: 6| Step: 10
Training loss: 3.387859570327808
Validation loss: 2.731726976534103

Epoch: 6| Step: 11
Training loss: 2.3578633903941997
Validation loss: 2.7280652005056703

Epoch: 6| Step: 12
Training loss: 2.901002802608468
Validation loss: 2.7356209958751445

Epoch: 6| Step: 13
Training loss: 2.6324162850106196
Validation loss: 2.7312981545881927

Epoch: 259| Step: 0
Training loss: 3.3067437306263425
Validation loss: 2.7376717190730675

Epoch: 6| Step: 1
Training loss: 3.1728387881110187
Validation loss: 2.7313911360785914

Epoch: 6| Step: 2
Training loss: 3.0453975910259663
Validation loss: 2.735512981670565

Epoch: 6| Step: 3
Training loss: 2.750970235809862
Validation loss: 2.7442495299424863

Epoch: 6| Step: 4
Training loss: 2.9233120734885465
Validation loss: 2.748608653908869

Epoch: 6| Step: 5
Training loss: 2.8030809141708986
Validation loss: 2.736622352852346

Epoch: 6| Step: 6
Training loss: 3.4032503971925445
Validation loss: 2.7387133649962134

Epoch: 6| Step: 7
Training loss: 2.569743177443294
Validation loss: 2.736572402750152

Epoch: 6| Step: 8
Training loss: 3.060666060667893
Validation loss: 2.732202029445097

Epoch: 6| Step: 9
Training loss: 3.105263757237726
Validation loss: 2.7330829039181426

Epoch: 6| Step: 10
Training loss: 2.788521081000348
Validation loss: 2.730895655699916

Epoch: 6| Step: 11
Training loss: 3.306069087539532
Validation loss: 2.7335264871762144

Epoch: 6| Step: 12
Training loss: 3.58465433537204
Validation loss: 2.7326003280565034

Epoch: 6| Step: 13
Training loss: 2.235484881277202
Validation loss: 2.7316522133296868

Epoch: 260| Step: 0
Training loss: 2.8225649981790166
Validation loss: 2.733571948189084

Epoch: 6| Step: 1
Training loss: 3.630935676351651
Validation loss: 2.7344557002240286

Epoch: 6| Step: 2
Training loss: 3.247232579357148
Validation loss: 2.729731128380905

Epoch: 6| Step: 3
Training loss: 3.8111238341000173
Validation loss: 2.726223431698806

Epoch: 6| Step: 4
Training loss: 3.1747243326016035
Validation loss: 2.724966795938139

Epoch: 6| Step: 5
Training loss: 2.521466787736399
Validation loss: 2.722696898370535

Epoch: 6| Step: 6
Training loss: 2.6088119173401814
Validation loss: 2.722259585336422

Epoch: 6| Step: 7
Training loss: 3.6806097798381763
Validation loss: 2.723922559537406

Epoch: 6| Step: 8
Training loss: 2.702872733103159
Validation loss: 2.7215156976296324

Epoch: 6| Step: 9
Training loss: 2.7455396025272356
Validation loss: 2.7247674187033915

Epoch: 6| Step: 10
Training loss: 2.522450918546208
Validation loss: 2.724012538372393

Epoch: 6| Step: 11
Training loss: 2.716543771347244
Validation loss: 2.72217869118642

Epoch: 6| Step: 12
Training loss: 3.1677977566367974
Validation loss: 2.7262973300925153

Epoch: 6| Step: 13
Training loss: 2.885608010311235
Validation loss: 2.7285760746022008

Epoch: 261| Step: 0
Training loss: 3.3551207107681957
Validation loss: 2.73548370338666

Epoch: 6| Step: 1
Training loss: 2.9364432199302803
Validation loss: 2.72926785274354

Epoch: 6| Step: 2
Training loss: 3.0328811504095845
Validation loss: 2.7273144298514813

Epoch: 6| Step: 3
Training loss: 3.0233162158227733
Validation loss: 2.7249038784704114

Epoch: 6| Step: 4
Training loss: 2.4139786492757005
Validation loss: 2.72063425728373

Epoch: 6| Step: 5
Training loss: 2.576853675652278
Validation loss: 2.726161847546924

Epoch: 6| Step: 6
Training loss: 3.5083207269896652
Validation loss: 2.7236958101561433

Epoch: 6| Step: 7
Training loss: 2.7890937012708976
Validation loss: 2.7255340130445025

Epoch: 6| Step: 8
Training loss: 3.347924879373013
Validation loss: 2.72381793185223

Epoch: 6| Step: 9
Training loss: 2.8306605316984466
Validation loss: 2.725029527561219

Epoch: 6| Step: 10
Training loss: 3.227630216895455
Validation loss: 2.7236333734895926

Epoch: 6| Step: 11
Training loss: 3.286577241724331
Validation loss: 2.7314205962014038

Epoch: 6| Step: 12
Training loss: 3.1014201326149378
Validation loss: 2.722568767789533

Epoch: 6| Step: 13
Training loss: 2.889569228911866
Validation loss: 2.7321888255759084

Epoch: 262| Step: 0
Training loss: 2.791326805797106
Validation loss: 2.7287140519234425

Epoch: 6| Step: 1
Training loss: 2.88951493677126
Validation loss: 2.7241170607097285

Epoch: 6| Step: 2
Training loss: 3.096426682496009
Validation loss: 2.7285595271523415

Epoch: 6| Step: 3
Training loss: 3.0794148332649227
Validation loss: 2.731589603765695

Epoch: 6| Step: 4
Training loss: 3.044099139921273
Validation loss: 2.728581986260503

Epoch: 6| Step: 5
Training loss: 3.610795439265929
Validation loss: 2.7348806365504523

Epoch: 6| Step: 6
Training loss: 2.457073556993673
Validation loss: 2.7207450802511133

Epoch: 6| Step: 7
Training loss: 3.1029781310638254
Validation loss: 2.7334904903409103

Epoch: 6| Step: 8
Training loss: 3.0424490841168335
Validation loss: 2.7241793300729946

Epoch: 6| Step: 9
Training loss: 2.923510088852786
Validation loss: 2.7228860771489036

Epoch: 6| Step: 10
Training loss: 3.297268089254647
Validation loss: 2.721054477188078

Epoch: 6| Step: 11
Training loss: 2.6165116533500665
Validation loss: 2.724603137631304

Epoch: 6| Step: 12
Training loss: 3.2403959540974396
Validation loss: 2.7223171961612156

Epoch: 6| Step: 13
Training loss: 3.382650675437979
Validation loss: 2.718674693221522

Epoch: 263| Step: 0
Training loss: 3.0591190905202352
Validation loss: 2.7194165252116935

Epoch: 6| Step: 1
Training loss: 3.5060444817514824
Validation loss: 2.7191431074627297

Epoch: 6| Step: 2
Training loss: 2.808003879620516
Validation loss: 2.720412469642398

Epoch: 6| Step: 3
Training loss: 2.862654675964819
Validation loss: 2.7240396822103063

Epoch: 6| Step: 4
Training loss: 2.5566040689231437
Validation loss: 2.720266079516446

Epoch: 6| Step: 5
Training loss: 3.3981170152405844
Validation loss: 2.7196963564044676

Epoch: 6| Step: 6
Training loss: 2.7884260033688233
Validation loss: 2.7247487085806994

Epoch: 6| Step: 7
Training loss: 3.147091864317534
Validation loss: 2.722668452107611

Epoch: 6| Step: 8
Training loss: 3.5293703731278883
Validation loss: 2.725846707390903

Epoch: 6| Step: 9
Training loss: 2.1517124808014247
Validation loss: 2.7236174040661902

Epoch: 6| Step: 10
Training loss: 2.892555046118262
Validation loss: 2.722245966907026

Epoch: 6| Step: 11
Training loss: 3.087740832368542
Validation loss: 2.727459898390004

Epoch: 6| Step: 12
Training loss: 3.381119725226168
Validation loss: 2.722899281877898

Epoch: 6| Step: 13
Training loss: 3.129139561711411
Validation loss: 2.719115143516282

Epoch: 264| Step: 0
Training loss: 2.6842058086255385
Validation loss: 2.7265004467909937

Epoch: 6| Step: 1
Training loss: 3.0484330326362383
Validation loss: 2.724284365461141

Epoch: 6| Step: 2
Training loss: 2.490824359491782
Validation loss: 2.7241360979625524

Epoch: 6| Step: 3
Training loss: 3.8737525162468636
Validation loss: 2.72797749517409

Epoch: 6| Step: 4
Training loss: 2.9532564325704183
Validation loss: 2.723661804027271

Epoch: 6| Step: 5
Training loss: 3.5313562697902645
Validation loss: 2.7206227452387632

Epoch: 6| Step: 6
Training loss: 2.487967526766699
Validation loss: 2.7171385867847775

Epoch: 6| Step: 7
Training loss: 2.6825240445014864
Validation loss: 2.716490320742719

Epoch: 6| Step: 8
Training loss: 3.0086936551734795
Validation loss: 2.7191907709034915

Epoch: 6| Step: 9
Training loss: 2.9445697849714643
Validation loss: 2.7176471463449268

Epoch: 6| Step: 10
Training loss: 3.3048293351562466
Validation loss: 2.7184041696392764

Epoch: 6| Step: 11
Training loss: 3.170414931521219
Validation loss: 2.718684785857783

Epoch: 6| Step: 12
Training loss: 3.285542323665258
Validation loss: 2.716551345585978

Epoch: 6| Step: 13
Training loss: 2.5611564091142545
Validation loss: 2.713681191893085

Epoch: 265| Step: 0
Training loss: 2.690872028632186
Validation loss: 2.7157577325312023

Epoch: 6| Step: 1
Training loss: 3.372796504939619
Validation loss: 2.7136782462869973

Epoch: 6| Step: 2
Training loss: 2.33607099783144
Validation loss: 2.71381258553431

Epoch: 6| Step: 3
Training loss: 2.9538479681957
Validation loss: 2.728040447004788

Epoch: 6| Step: 4
Training loss: 3.4686306769665403
Validation loss: 2.7200377765070485

Epoch: 6| Step: 5
Training loss: 3.153865404410236
Validation loss: 2.718831397848796

Epoch: 6| Step: 6
Training loss: 2.866157866576385
Validation loss: 2.7203663024446514

Epoch: 6| Step: 7
Training loss: 2.6277607523622226
Validation loss: 2.719547318416634

Epoch: 6| Step: 8
Training loss: 2.853033318775298
Validation loss: 2.7261631819523537

Epoch: 6| Step: 9
Training loss: 2.5694941461470076
Validation loss: 2.7245564072511517

Epoch: 6| Step: 10
Training loss: 3.6680657289662357
Validation loss: 2.7201110258220176

Epoch: 6| Step: 11
Training loss: 3.1670128147936794
Validation loss: 2.7159604858690005

Epoch: 6| Step: 12
Training loss: 3.3244950104617335
Validation loss: 2.7136687953855825

Epoch: 6| Step: 13
Training loss: 3.3379070533807975
Validation loss: 2.717533349951202

Epoch: 266| Step: 0
Training loss: 3.2209670940093313
Validation loss: 2.71855396812956

Epoch: 6| Step: 1
Training loss: 2.9550331046739964
Validation loss: 2.7172119802984764

Epoch: 6| Step: 2
Training loss: 2.297891612419254
Validation loss: 2.713178465355712

Epoch: 6| Step: 3
Training loss: 3.0342021606123812
Validation loss: 2.7177096507341876

Epoch: 6| Step: 4
Training loss: 2.4916897937462594
Validation loss: 2.712819684057139

Epoch: 6| Step: 5
Training loss: 3.2694592029285605
Validation loss: 2.713029347124361

Epoch: 6| Step: 6
Training loss: 2.9844497751185357
Validation loss: 2.7122848938840396

Epoch: 6| Step: 7
Training loss: 3.1955740898519176
Validation loss: 2.7140701718046354

Epoch: 6| Step: 8
Training loss: 2.515596756865427
Validation loss: 2.713167011440027

Epoch: 6| Step: 9
Training loss: 3.276662762608212
Validation loss: 2.71411591998084

Epoch: 6| Step: 10
Training loss: 3.523640628888703
Validation loss: 2.7166328999061373

Epoch: 6| Step: 11
Training loss: 3.0495301244285757
Validation loss: 2.7156076825587814

Epoch: 6| Step: 12
Training loss: 3.054335473891621
Validation loss: 2.7114081453394774

Epoch: 6| Step: 13
Training loss: 3.6857809165305313
Validation loss: 2.7142563575214442

Epoch: 267| Step: 0
Training loss: 2.8166930413751254
Validation loss: 2.718877730659386

Epoch: 6| Step: 1
Training loss: 3.353887716189255
Validation loss: 2.7198643949384245

Epoch: 6| Step: 2
Training loss: 3.074324842316437
Validation loss: 2.719120210235127

Epoch: 6| Step: 3
Training loss: 2.4201094560066356
Validation loss: 2.718815939573564

Epoch: 6| Step: 4
Training loss: 3.355128527480443
Validation loss: 2.7143558271782044

Epoch: 6| Step: 5
Training loss: 2.957842736913346
Validation loss: 2.718168121670315

Epoch: 6| Step: 6
Training loss: 3.133658354384989
Validation loss: 2.712519794201163

Epoch: 6| Step: 7
Training loss: 3.5190236935458823
Validation loss: 2.7168748532605322

Epoch: 6| Step: 8
Training loss: 2.782639317207969
Validation loss: 2.712196269920801

Epoch: 6| Step: 9
Training loss: 3.287256175235069
Validation loss: 2.7119760581069974

Epoch: 6| Step: 10
Training loss: 2.835720926217303
Validation loss: 2.705737858258055

Epoch: 6| Step: 11
Training loss: 2.82365021318651
Validation loss: 2.7121453264432946

Epoch: 6| Step: 12
Training loss: 3.078647317478883
Validation loss: 2.7121648154257607

Epoch: 6| Step: 13
Training loss: 2.789990866314557
Validation loss: 2.7116037748467035

Epoch: 268| Step: 0
Training loss: 2.962007273972239
Validation loss: 2.713175318888063

Epoch: 6| Step: 1
Training loss: 2.588495286082116
Validation loss: 2.710065375550095

Epoch: 6| Step: 2
Training loss: 3.1494396498476083
Validation loss: 2.711881203743179

Epoch: 6| Step: 3
Training loss: 3.245935980202512
Validation loss: 2.7108481926963117

Epoch: 6| Step: 4
Training loss: 3.0384053203727017
Validation loss: 2.7112187301775137

Epoch: 6| Step: 5
Training loss: 2.6548951227770856
Validation loss: 2.7102393537202802

Epoch: 6| Step: 6
Training loss: 3.014906723578672
Validation loss: 2.7124384337809744

Epoch: 6| Step: 7
Training loss: 3.715581746407068
Validation loss: 2.7086373612084342

Epoch: 6| Step: 8
Training loss: 3.1342147770983937
Validation loss: 2.7102054464430703

Epoch: 6| Step: 9
Training loss: 2.6999563708135867
Validation loss: 2.7101219978869064

Epoch: 6| Step: 10
Training loss: 2.2075072728833227
Validation loss: 2.7181742766611388

Epoch: 6| Step: 11
Training loss: 3.3206901784280327
Validation loss: 2.713295732453158

Epoch: 6| Step: 12
Training loss: 3.484396074855688
Validation loss: 2.71060189272718

Epoch: 6| Step: 13
Training loss: 2.892305782461082
Validation loss: 2.712576817059492

Epoch: 269| Step: 0
Training loss: 2.9436172746999754
Validation loss: 2.7118695732416924

Epoch: 6| Step: 1
Training loss: 2.7638626086733766
Validation loss: 2.707686958768264

Epoch: 6| Step: 2
Training loss: 2.873154586961623
Validation loss: 2.709703030614142

Epoch: 6| Step: 3
Training loss: 2.993766029649479
Validation loss: 2.7154548198695028

Epoch: 6| Step: 4
Training loss: 2.9066663874471454
Validation loss: 2.713074374867958

Epoch: 6| Step: 5
Training loss: 3.715815564426993
Validation loss: 2.7111010356582828

Epoch: 6| Step: 6
Training loss: 2.8900820660406352
Validation loss: 2.712248541405059

Epoch: 6| Step: 7
Training loss: 2.641463107219512
Validation loss: 2.714210457282429

Epoch: 6| Step: 8
Training loss: 2.891076624875813
Validation loss: 2.7139875420303423

Epoch: 6| Step: 9
Training loss: 3.417388622642872
Validation loss: 2.7133108064491833

Epoch: 6| Step: 10
Training loss: 2.9714813517242575
Validation loss: 2.709162314664932

Epoch: 6| Step: 11
Training loss: 3.2574711536175407
Validation loss: 2.7121503437968166

Epoch: 6| Step: 12
Training loss: 3.058514863186864
Validation loss: 2.7101194769282646

Epoch: 6| Step: 13
Training loss: 2.912849562464111
Validation loss: 2.7083580978308888

Epoch: 270| Step: 0
Training loss: 1.7666579069364252
Validation loss: 2.7076214980516045

Epoch: 6| Step: 1
Training loss: 3.0220969527904677
Validation loss: 2.708527127535126

Epoch: 6| Step: 2
Training loss: 3.058623994602221
Validation loss: 2.706254264909461

Epoch: 6| Step: 3
Training loss: 2.63373348077012
Validation loss: 2.7090140418858493

Epoch: 6| Step: 4
Training loss: 3.5119658691902775
Validation loss: 2.7089584714519326

Epoch: 6| Step: 5
Training loss: 3.3270383681712614
Validation loss: 2.7059814565427156

Epoch: 6| Step: 6
Training loss: 3.213410327933385
Validation loss: 2.7083741193655175

Epoch: 6| Step: 7
Training loss: 3.459732431418545
Validation loss: 2.705582130207396

Epoch: 6| Step: 8
Training loss: 2.7717353002874607
Validation loss: 2.7081797257271996

Epoch: 6| Step: 9
Training loss: 2.882975255822289
Validation loss: 2.7083621794219086

Epoch: 6| Step: 10
Training loss: 3.347890981414643
Validation loss: 2.7105345256730824

Epoch: 6| Step: 11
Training loss: 3.0828737139726807
Validation loss: 2.7104657003663175

Epoch: 6| Step: 12
Training loss: 2.470286410324852
Validation loss: 2.719392817657103

Epoch: 6| Step: 13
Training loss: 3.628504144669103
Validation loss: 2.717156187860184

Epoch: 271| Step: 0
Training loss: 2.8952395335769903
Validation loss: 2.721038163817273

Epoch: 6| Step: 1
Training loss: 2.811057759416573
Validation loss: 2.719341117162916

Epoch: 6| Step: 2
Training loss: 2.8567796612547816
Validation loss: 2.7290663755153775

Epoch: 6| Step: 3
Training loss: 3.512020450315262
Validation loss: 2.7300165987297094

Epoch: 6| Step: 4
Training loss: 2.185298574897763
Validation loss: 2.7242796508833016

Epoch: 6| Step: 5
Training loss: 3.1141149536553847
Validation loss: 2.7274943769432767

Epoch: 6| Step: 6
Training loss: 3.7734386373008766
Validation loss: 2.7113788885268133

Epoch: 6| Step: 7
Training loss: 2.517882098660767
Validation loss: 2.7029989207104688

Epoch: 6| Step: 8
Training loss: 3.184310214625571
Validation loss: 2.7044959886920745

Epoch: 6| Step: 9
Training loss: 3.2410368934421774
Validation loss: 2.6999262540279725

Epoch: 6| Step: 10
Training loss: 3.1921805629570823
Validation loss: 2.702124486412128

Epoch: 6| Step: 11
Training loss: 2.9695857427665864
Validation loss: 2.7020382009647483

Epoch: 6| Step: 12
Training loss: 3.262953400073658
Validation loss: 2.7014594959103078

Epoch: 6| Step: 13
Training loss: 2.2935255891957906
Validation loss: 2.703657730474013

Epoch: 272| Step: 0
Training loss: 3.041403998612463
Validation loss: 2.7017744138801705

Epoch: 6| Step: 1
Training loss: 3.352393556365764
Validation loss: 2.705018583259713

Epoch: 6| Step: 2
Training loss: 2.385166593767235
Validation loss: 2.7041647497169348

Epoch: 6| Step: 3
Training loss: 3.5356405864262106
Validation loss: 2.706306960923537

Epoch: 6| Step: 4
Training loss: 2.1755819178005664
Validation loss: 2.701301423839826

Epoch: 6| Step: 5
Training loss: 3.233322045873492
Validation loss: 2.7030850436612335

Epoch: 6| Step: 6
Training loss: 3.2915018418648954
Validation loss: 2.703069000261568

Epoch: 6| Step: 7
Training loss: 2.8234852198340077
Validation loss: 2.703810222364414

Epoch: 6| Step: 8
Training loss: 2.848971425548833
Validation loss: 2.6999580267617884

Epoch: 6| Step: 9
Training loss: 2.8223123407952437
Validation loss: 2.7034284478374806

Epoch: 6| Step: 10
Training loss: 3.1989844379624874
Validation loss: 2.705595910210746

Epoch: 6| Step: 11
Training loss: 3.1258276796980513
Validation loss: 2.7079141170896914

Epoch: 6| Step: 12
Training loss: 3.0112754010577687
Validation loss: 2.7153683448085157

Epoch: 6| Step: 13
Training loss: 3.521266225954154
Validation loss: 2.724397354794778

Epoch: 273| Step: 0
Training loss: 3.2644747665909417
Validation loss: 2.7313874540101906

Epoch: 6| Step: 1
Training loss: 2.8289913304810623
Validation loss: 2.7117533808198013

Epoch: 6| Step: 2
Training loss: 2.572132706738083
Validation loss: 2.71784252202617

Epoch: 6| Step: 3
Training loss: 3.202936232052052
Validation loss: 2.720676426552271

Epoch: 6| Step: 4
Training loss: 2.6857221178618906
Validation loss: 2.7148270999624806

Epoch: 6| Step: 5
Training loss: 2.6460302885344675
Validation loss: 2.7121635714925634

Epoch: 6| Step: 6
Training loss: 3.3874006981740785
Validation loss: 2.7203235007284734

Epoch: 6| Step: 7
Training loss: 2.9678769082612457
Validation loss: 2.7095544666799314

Epoch: 6| Step: 8
Training loss: 2.9042930987807494
Validation loss: 2.7056554316660497

Epoch: 6| Step: 9
Training loss: 3.210908838594329
Validation loss: 2.710788866591452

Epoch: 6| Step: 10
Training loss: 2.8545070547316387
Validation loss: 2.703899723252539

Epoch: 6| Step: 11
Training loss: 3.1985041340724747
Validation loss: 2.7070620841841557

Epoch: 6| Step: 12
Training loss: 3.3368127465322237
Validation loss: 2.705523324441065

Epoch: 6| Step: 13
Training loss: 3.305834271374983
Validation loss: 2.7011233991198584

Epoch: 274| Step: 0
Training loss: 3.276562494178812
Validation loss: 2.7052729054537674

Epoch: 6| Step: 1
Training loss: 2.9744141202126695
Validation loss: 2.698041291485727

Epoch: 6| Step: 2
Training loss: 2.181595380923533
Validation loss: 2.699264099301454

Epoch: 6| Step: 3
Training loss: 3.2914369398343712
Validation loss: 2.6985245830333313

Epoch: 6| Step: 4
Training loss: 2.9852859145443924
Validation loss: 2.701803861042563

Epoch: 6| Step: 5
Training loss: 3.7294397662589764
Validation loss: 2.70101568152923

Epoch: 6| Step: 6
Training loss: 3.46528548700821
Validation loss: 2.701210549920685

Epoch: 6| Step: 7
Training loss: 3.3625446359160547
Validation loss: 2.7016868599552137

Epoch: 6| Step: 8
Training loss: 3.5442207252534943
Validation loss: 2.70387564924987

Epoch: 6| Step: 9
Training loss: 2.2770363549507895
Validation loss: 2.704053771505543

Epoch: 6| Step: 10
Training loss: 3.040287192732692
Validation loss: 2.7018528864305718

Epoch: 6| Step: 11
Training loss: 2.31296627395787
Validation loss: 2.7096402242141986

Epoch: 6| Step: 12
Training loss: 2.310323773767701
Validation loss: 2.7122361279521625

Epoch: 6| Step: 13
Training loss: 3.001998553555907
Validation loss: 2.7098363077391294

Epoch: 275| Step: 0
Training loss: 3.392669483243863
Validation loss: 2.7124835970356984

Epoch: 6| Step: 1
Training loss: 2.3582009937731074
Validation loss: 2.720058169343124

Epoch: 6| Step: 2
Training loss: 3.0198713853745662
Validation loss: 2.717852929971583

Epoch: 6| Step: 3
Training loss: 2.910905124650124
Validation loss: 2.7158381845397015

Epoch: 6| Step: 4
Training loss: 3.377339858883009
Validation loss: 2.706691633098531

Epoch: 6| Step: 5
Training loss: 3.104773408788776
Validation loss: 2.704152381634621

Epoch: 6| Step: 6
Training loss: 3.0880048949049663
Validation loss: 2.704098764784288

Epoch: 6| Step: 7
Training loss: 2.842794236762626
Validation loss: 2.6998477140843464

Epoch: 6| Step: 8
Training loss: 3.1112907297266212
Validation loss: 2.699323995910518

Epoch: 6| Step: 9
Training loss: 3.095123910719097
Validation loss: 2.702412233610644

Epoch: 6| Step: 10
Training loss: 2.8065852383409347
Validation loss: 2.7009569690207855

Epoch: 6| Step: 11
Training loss: 2.732355211056873
Validation loss: 2.7008867501916476

Epoch: 6| Step: 12
Training loss: 3.5078328903047407
Validation loss: 2.697319683720024

Epoch: 6| Step: 13
Training loss: 2.6784454225238954
Validation loss: 2.700464516943264

Epoch: 276| Step: 0
Training loss: 2.950624406326063
Validation loss: 2.701510804116921

Epoch: 6| Step: 1
Training loss: 3.4873749686631212
Validation loss: 2.6990423318046948

Epoch: 6| Step: 2
Training loss: 3.432994594961968
Validation loss: 2.705036358917917

Epoch: 6| Step: 3
Training loss: 2.8052245239591387
Validation loss: 2.701131378205522

Epoch: 6| Step: 4
Training loss: 3.4193742924785213
Validation loss: 2.7050524636240496

Epoch: 6| Step: 5
Training loss: 2.6808028944297564
Validation loss: 2.7061844393103445

Epoch: 6| Step: 6
Training loss: 3.5118268328403413
Validation loss: 2.702657858976939

Epoch: 6| Step: 7
Training loss: 3.1640724464542735
Validation loss: 2.7041865468311608

Epoch: 6| Step: 8
Training loss: 3.041603105133494
Validation loss: 2.6974838073664755

Epoch: 6| Step: 9
Training loss: 2.8772048788249136
Validation loss: 2.696787119548048

Epoch: 6| Step: 10
Training loss: 2.7943958397900674
Validation loss: 2.696577751822502

Epoch: 6| Step: 11
Training loss: 3.313302716574898
Validation loss: 2.6968756586113782

Epoch: 6| Step: 12
Training loss: 2.1064783623392427
Validation loss: 2.7057390994605064

Epoch: 6| Step: 13
Training loss: 1.7057919400921382
Validation loss: 2.695862172204188

Epoch: 277| Step: 0
Training loss: 3.7196382375392454
Validation loss: 2.69959013443655

Epoch: 6| Step: 1
Training loss: 2.9579484895215127
Validation loss: 2.7084989498669265

Epoch: 6| Step: 2
Training loss: 3.242809557700644
Validation loss: 2.708706049361051

Epoch: 6| Step: 3
Training loss: 3.0564495185366294
Validation loss: 2.7104907969117913

Epoch: 6| Step: 4
Training loss: 2.3948081324739827
Validation loss: 2.699567232804551

Epoch: 6| Step: 5
Training loss: 3.010769111743057
Validation loss: 2.7299125990259854

Epoch: 6| Step: 6
Training loss: 2.301206177103076
Validation loss: 2.728045596758868

Epoch: 6| Step: 7
Training loss: 2.5465960203561058
Validation loss: 2.7322490550436003

Epoch: 6| Step: 8
Training loss: 3.1614480602384485
Validation loss: 2.755524970447345

Epoch: 6| Step: 9
Training loss: 3.191858042531321
Validation loss: 2.757004465717343

Epoch: 6| Step: 10
Training loss: 3.172952703787693
Validation loss: 2.7417865061838658

Epoch: 6| Step: 11
Training loss: 3.2408991816304877
Validation loss: 2.744609836003107

Epoch: 6| Step: 12
Training loss: 3.065012932356517
Validation loss: 2.7309724991861337

Epoch: 6| Step: 13
Training loss: 3.027088415391458
Validation loss: 2.7153116392686347

Epoch: 278| Step: 0
Training loss: 3.3747020166033472
Validation loss: 2.696294398403042

Epoch: 6| Step: 1
Training loss: 2.640152928517951
Validation loss: 2.693575481049858

Epoch: 6| Step: 2
Training loss: 2.8014116202988117
Validation loss: 2.6994351191866053

Epoch: 6| Step: 3
Training loss: 3.529484940686559
Validation loss: 2.7065622892166714

Epoch: 6| Step: 4
Training loss: 3.0992519891339714
Validation loss: 2.7105951057813433

Epoch: 6| Step: 5
Training loss: 3.0700546816451033
Validation loss: 2.708020251962111

Epoch: 6| Step: 6
Training loss: 3.5439661676587386
Validation loss: 2.704862558842579

Epoch: 6| Step: 7
Training loss: 2.9568424139361995
Validation loss: 2.701536843605604

Epoch: 6| Step: 8
Training loss: 2.265370321758045
Validation loss: 2.697730201710221

Epoch: 6| Step: 9
Training loss: 3.575439511472025
Validation loss: 2.693877684445454

Epoch: 6| Step: 10
Training loss: 3.0548251772242745
Validation loss: 2.6984171056204462

Epoch: 6| Step: 11
Training loss: 3.0818152599776094
Validation loss: 2.6944824785951456

Epoch: 6| Step: 12
Training loss: 2.9813223200249426
Validation loss: 2.6964093640115308

Epoch: 6| Step: 13
Training loss: 1.5542308961143063
Validation loss: 2.695219180319751

Epoch: 279| Step: 0
Training loss: 2.7021217027781623
Validation loss: 2.696826992383065

Epoch: 6| Step: 1
Training loss: 2.8220141236068734
Validation loss: 2.696730674484849

Epoch: 6| Step: 2
Training loss: 3.3589570960995467
Validation loss: 2.7006843735638526

Epoch: 6| Step: 3
Training loss: 2.7668545678303955
Validation loss: 2.698291899914227

Epoch: 6| Step: 4
Training loss: 2.841056134666675
Validation loss: 2.7040192490994643

Epoch: 6| Step: 5
Training loss: 3.0178693414797886
Validation loss: 2.7155846280748377

Epoch: 6| Step: 6
Training loss: 2.885428546830565
Validation loss: 2.7121786810832385

Epoch: 6| Step: 7
Training loss: 3.1161457510417963
Validation loss: 2.7187960192583684

Epoch: 6| Step: 8
Training loss: 2.8541024379510906
Validation loss: 2.7036651616010463

Epoch: 6| Step: 9
Training loss: 3.122650331248691
Validation loss: 2.7059350497627506

Epoch: 6| Step: 10
Training loss: 3.859834342524741
Validation loss: 2.7107625443067773

Epoch: 6| Step: 11
Training loss: 2.5209206705227936
Validation loss: 2.7216788472953977

Epoch: 6| Step: 12
Training loss: 3.341937991294676
Validation loss: 2.705803539825173

Epoch: 6| Step: 13
Training loss: 2.8116099326743713
Validation loss: 2.705446782454869

Epoch: 280| Step: 0
Training loss: 3.134718469758258
Validation loss: 2.694769082998498

Epoch: 6| Step: 1
Training loss: 2.767240494275031
Validation loss: 2.7103835897010176

Epoch: 6| Step: 2
Training loss: 3.487497068561156
Validation loss: 2.698261362654737

Epoch: 6| Step: 3
Training loss: 2.6472363294038974
Validation loss: 2.700987220482655

Epoch: 6| Step: 4
Training loss: 3.238354579707283
Validation loss: 2.692812210801947

Epoch: 6| Step: 5
Training loss: 3.182278563893383
Validation loss: 2.692446655600558

Epoch: 6| Step: 6
Training loss: 3.14814397234006
Validation loss: 2.696008405928167

Epoch: 6| Step: 7
Training loss: 2.6233513514066784
Validation loss: 2.693727189416577

Epoch: 6| Step: 8
Training loss: 2.650006215070238
Validation loss: 2.693878641809642

Epoch: 6| Step: 9
Training loss: 3.180204082394127
Validation loss: 2.692598878866868

Epoch: 6| Step: 10
Training loss: 2.8816534260551716
Validation loss: 2.6966306302746905

Epoch: 6| Step: 11
Training loss: 2.46333840131776
Validation loss: 2.696222681347962

Epoch: 6| Step: 12
Training loss: 3.4664703301315902
Validation loss: 2.6920035485129348

Epoch: 6| Step: 13
Training loss: 3.301538865762618
Validation loss: 2.700318894796586

Epoch: 281| Step: 0
Training loss: 3.370517862754472
Validation loss: 2.7036920337210066

Epoch: 6| Step: 1
Training loss: 2.6722800856802498
Validation loss: 2.7070860427249706

Epoch: 6| Step: 2
Training loss: 3.0857888487733356
Validation loss: 2.7022490250073488

Epoch: 6| Step: 3
Training loss: 3.0025798513194957
Validation loss: 2.7052780189459287

Epoch: 6| Step: 4
Training loss: 3.3511837476294817
Validation loss: 2.705645387074079

Epoch: 6| Step: 5
Training loss: 3.3237889658640496
Validation loss: 2.7043629517533527

Epoch: 6| Step: 6
Training loss: 3.013535165807202
Validation loss: 2.708207760937475

Epoch: 6| Step: 7
Training loss: 3.417617169417783
Validation loss: 2.707552689593813

Epoch: 6| Step: 8
Training loss: 3.1408805173867265
Validation loss: 2.7061184979409183

Epoch: 6| Step: 9
Training loss: 2.688765737859049
Validation loss: 2.7080919140793336

Epoch: 6| Step: 10
Training loss: 2.777464444184389
Validation loss: 2.7134835098802434

Epoch: 6| Step: 11
Training loss: 2.3553452593820623
Validation loss: 2.7103099933069354

Epoch: 6| Step: 12
Training loss: 2.875758195498121
Validation loss: 2.70686647212889

Epoch: 6| Step: 13
Training loss: 2.9523907106797873
Validation loss: 2.7029925495365354

Epoch: 282| Step: 0
Training loss: 3.3179144603149124
Validation loss: 2.6968694036789755

Epoch: 6| Step: 1
Training loss: 2.838842496183902
Validation loss: 2.6932449045815976

Epoch: 6| Step: 2
Training loss: 3.3324065986473643
Validation loss: 2.6886426152208243

Epoch: 6| Step: 3
Training loss: 3.2693247302607507
Validation loss: 2.6934705720802214

Epoch: 6| Step: 4
Training loss: 2.2877201662266216
Validation loss: 2.685105802916677

Epoch: 6| Step: 5
Training loss: 3.180498999065499
Validation loss: 2.6893872609777127

Epoch: 6| Step: 6
Training loss: 2.795862963121964
Validation loss: 2.698198557862045

Epoch: 6| Step: 7
Training loss: 3.2809974209892463
Validation loss: 2.68770218851989

Epoch: 6| Step: 8
Training loss: 3.300265625175693
Validation loss: 2.6861995107908787

Epoch: 6| Step: 9
Training loss: 3.0985909551419653
Validation loss: 2.6908522349024317

Epoch: 6| Step: 10
Training loss: 2.703839951710632
Validation loss: 2.688358167008959

Epoch: 6| Step: 11
Training loss: 2.858360902821974
Validation loss: 2.69085198909952

Epoch: 6| Step: 12
Training loss: 2.9878926741335796
Validation loss: 2.6838184561203913

Epoch: 6| Step: 13
Training loss: 2.618889280999025
Validation loss: 2.688277532497086

Epoch: 283| Step: 0
Training loss: 3.2797585140280305
Validation loss: 2.694103403613447

Epoch: 6| Step: 1
Training loss: 2.5564845119807704
Validation loss: 2.693413431216666

Epoch: 6| Step: 2
Training loss: 3.57079260204562
Validation loss: 2.6914452386062115

Epoch: 6| Step: 3
Training loss: 3.1995256251152364
Validation loss: 2.6897981122907297

Epoch: 6| Step: 4
Training loss: 3.524441662662088
Validation loss: 2.6981769717617903

Epoch: 6| Step: 5
Training loss: 2.901964206445897
Validation loss: 2.7034432003820057

Epoch: 6| Step: 6
Training loss: 3.1896373090572663
Validation loss: 2.6972945511168858

Epoch: 6| Step: 7
Training loss: 2.1131654943892224
Validation loss: 2.69890578409609

Epoch: 6| Step: 8
Training loss: 2.8709150401439274
Validation loss: 2.7066223151015687

Epoch: 6| Step: 9
Training loss: 2.872805877681234
Validation loss: 2.7078572488228136

Epoch: 6| Step: 10
Training loss: 2.4348106219771135
Validation loss: 2.7008771605606428

Epoch: 6| Step: 11
Training loss: 2.9567296870875572
Validation loss: 2.7059112610411127

Epoch: 6| Step: 12
Training loss: 3.314509519997536
Validation loss: 2.7073106360400137

Epoch: 6| Step: 13
Training loss: 3.0585600752456568
Validation loss: 2.708929685971338

Epoch: 284| Step: 0
Training loss: 2.776927718323869
Validation loss: 2.703345532620468

Epoch: 6| Step: 1
Training loss: 2.5080024433397865
Validation loss: 2.7070588785211824

Epoch: 6| Step: 2
Training loss: 3.0893349017535914
Validation loss: 2.713101845468812

Epoch: 6| Step: 3
Training loss: 2.586526210189747
Validation loss: 2.7058910031819408

Epoch: 6| Step: 4
Training loss: 2.733839582066518
Validation loss: 2.711521932173824

Epoch: 6| Step: 5
Training loss: 2.821050151191199
Validation loss: 2.709334561986403

Epoch: 6| Step: 6
Training loss: 2.05974487317384
Validation loss: 2.7167039922881293

Epoch: 6| Step: 7
Training loss: 3.1159889001024257
Validation loss: 2.718756874084269

Epoch: 6| Step: 8
Training loss: 3.1678043797910007
Validation loss: 2.699506418513204

Epoch: 6| Step: 9
Training loss: 3.784458911069422
Validation loss: 2.6916745657541266

Epoch: 6| Step: 10
Training loss: 3.2786295281636773
Validation loss: 2.6932053137798677

Epoch: 6| Step: 11
Training loss: 3.125025482073841
Validation loss: 2.6928119404251363

Epoch: 6| Step: 12
Training loss: 3.7063406973382915
Validation loss: 2.6802694874446793

Epoch: 6| Step: 13
Training loss: 2.963069420023503
Validation loss: 2.6864786537262435

Epoch: 285| Step: 0
Training loss: 3.3131858547503303
Validation loss: 2.684351582879672

Epoch: 6| Step: 1
Training loss: 2.642990587613929
Validation loss: 2.684638264242881

Epoch: 6| Step: 2
Training loss: 3.5506321841131827
Validation loss: 2.690545243866047

Epoch: 6| Step: 3
Training loss: 2.7778824553369685
Validation loss: 2.684767968246937

Epoch: 6| Step: 4
Training loss: 2.613587776305423
Validation loss: 2.683451195196313

Epoch: 6| Step: 5
Training loss: 3.0213537009153955
Validation loss: 2.6857312633348887

Epoch: 6| Step: 6
Training loss: 3.1752178447811112
Validation loss: 2.6862546673513537

Epoch: 6| Step: 7
Training loss: 2.67672405479101
Validation loss: 2.6850053160119005

Epoch: 6| Step: 8
Training loss: 2.6392480996130385
Validation loss: 2.687152562502007

Epoch: 6| Step: 9
Training loss: 3.034413054018431
Validation loss: 2.695040545506249

Epoch: 6| Step: 10
Training loss: 2.874376312275467
Validation loss: 2.693812931196404

Epoch: 6| Step: 11
Training loss: 2.514725233960827
Validation loss: 2.6934334554990795

Epoch: 6| Step: 12
Training loss: 3.5517951348740184
Validation loss: 2.711081995760922

Epoch: 6| Step: 13
Training loss: 3.8502355924581604
Validation loss: 2.7104973902258713

Epoch: 286| Step: 0
Training loss: 2.879295126169595
Validation loss: 2.706172219716315

Epoch: 6| Step: 1
Training loss: 3.261661734625184
Validation loss: 2.705107387409476

Epoch: 6| Step: 2
Training loss: 2.513966837237124
Validation loss: 2.716224330826132

Epoch: 6| Step: 3
Training loss: 2.9930208405273517
Validation loss: 2.7020777173756034

Epoch: 6| Step: 4
Training loss: 2.9405331474658154
Validation loss: 2.7022975499494684

Epoch: 6| Step: 5
Training loss: 3.4185490578800843
Validation loss: 2.700808825741811

Epoch: 6| Step: 6
Training loss: 3.099900422496589
Validation loss: 2.6958594229950728

Epoch: 6| Step: 7
Training loss: 2.9676720519351383
Validation loss: 2.6952165008422106

Epoch: 6| Step: 8
Training loss: 3.253702841969114
Validation loss: 2.6879111078325573

Epoch: 6| Step: 9
Training loss: 2.65132069696234
Validation loss: 2.685354549259424

Epoch: 6| Step: 10
Training loss: 2.9160097381471055
Validation loss: 2.683603089009395

Epoch: 6| Step: 11
Training loss: 3.1757599289144376
Validation loss: 2.6869438685346374

Epoch: 6| Step: 12
Training loss: 2.977560842102208
Validation loss: 2.6835808629543316

Epoch: 6| Step: 13
Training loss: 3.0710853594012986
Validation loss: 2.677820696830249

Epoch: 287| Step: 0
Training loss: 2.8203799591027616
Validation loss: 2.6844598067910783

Epoch: 6| Step: 1
Training loss: 3.2891168657825007
Validation loss: 2.679906089896246

Epoch: 6| Step: 2
Training loss: 2.4333318627583838
Validation loss: 2.6790555349115928

Epoch: 6| Step: 3
Training loss: 3.2491217673728863
Validation loss: 2.682225823522654

Epoch: 6| Step: 4
Training loss: 3.0025207737339805
Validation loss: 2.680621588953427

Epoch: 6| Step: 5
Training loss: 3.05453514246005
Validation loss: 2.6829523757630724

Epoch: 6| Step: 6
Training loss: 2.713025435084156
Validation loss: 2.6831883449079688

Epoch: 6| Step: 7
Training loss: 3.107396708925435
Validation loss: 2.6823990545968637

Epoch: 6| Step: 8
Training loss: 3.517283273186897
Validation loss: 2.681725022919039

Epoch: 6| Step: 9
Training loss: 3.2539188526729235
Validation loss: 2.6846374878849764

Epoch: 6| Step: 10
Training loss: 3.3043250207528674
Validation loss: 2.684176866574691

Epoch: 6| Step: 11
Training loss: 3.076494123746188
Validation loss: 2.6793191972935104

Epoch: 6| Step: 12
Training loss: 2.7280172494975004
Validation loss: 2.680104324936367

Epoch: 6| Step: 13
Training loss: 1.6355333792797258
Validation loss: 2.689024443031561

Epoch: 288| Step: 0
Training loss: 2.3192342699756616
Validation loss: 2.6851010243218134

Epoch: 6| Step: 1
Training loss: 3.2527696105727086
Validation loss: 2.6873275022290994

Epoch: 6| Step: 2
Training loss: 2.5575235006645425
Validation loss: 2.688353596360538

Epoch: 6| Step: 3
Training loss: 3.183733940548302
Validation loss: 2.6882527721547502

Epoch: 6| Step: 4
Training loss: 2.841690155856991
Validation loss: 2.6966653765602526

Epoch: 6| Step: 5
Training loss: 2.7011787596509333
Validation loss: 2.705131294080689

Epoch: 6| Step: 6
Training loss: 3.044516251947758
Validation loss: 2.719964473380459

Epoch: 6| Step: 7
Training loss: 3.029618758336074
Validation loss: 2.709771202634276

Epoch: 6| Step: 8
Training loss: 2.810169356323256
Validation loss: 2.6976307067966587

Epoch: 6| Step: 9
Training loss: 3.3164039494986133
Validation loss: 2.685575163661492

Epoch: 6| Step: 10
Training loss: 2.9479256529833955
Validation loss: 2.688602870831528

Epoch: 6| Step: 11
Training loss: 3.397553988961788
Validation loss: 2.679263124825275

Epoch: 6| Step: 12
Training loss: 3.2294716639712995
Validation loss: 2.6789128754595812

Epoch: 6| Step: 13
Training loss: 3.547797129407986
Validation loss: 2.6803880891028764

Epoch: 289| Step: 0
Training loss: 2.6951636231811595
Validation loss: 2.6824728003293643

Epoch: 6| Step: 1
Training loss: 3.064902939371979
Validation loss: 2.6826537484731934

Epoch: 6| Step: 2
Training loss: 2.6174595022484386
Validation loss: 2.6795610000790715

Epoch: 6| Step: 3
Training loss: 2.8520303420797535
Validation loss: 2.6773141255772988

Epoch: 6| Step: 4
Training loss: 3.251357455298329
Validation loss: 2.6814596352590976

Epoch: 6| Step: 5
Training loss: 3.18696649611942
Validation loss: 2.6803885491523167

Epoch: 6| Step: 6
Training loss: 3.1702350454706467
Validation loss: 2.688753370452439

Epoch: 6| Step: 7
Training loss: 3.1562249210985387
Validation loss: 2.684428792732986

Epoch: 6| Step: 8
Training loss: 3.3929820503819155
Validation loss: 2.68630472566897

Epoch: 6| Step: 9
Training loss: 2.6611091598719496
Validation loss: 2.690200252326054

Epoch: 6| Step: 10
Training loss: 2.7441943180356527
Validation loss: 2.686531210887015

Epoch: 6| Step: 11
Training loss: 3.1994199584735217
Validation loss: 2.6857892644385872

Epoch: 6| Step: 12
Training loss: 3.1666752329927994
Validation loss: 2.6880461244522524

Epoch: 6| Step: 13
Training loss: 2.717441814119036
Validation loss: 2.691370724269843

Epoch: 290| Step: 0
Training loss: 3.0623623564013935
Validation loss: 2.692650981433611

Epoch: 6| Step: 1
Training loss: 2.9955942864119933
Validation loss: 2.6986000607226326

Epoch: 6| Step: 2
Training loss: 2.7731646336389972
Validation loss: 2.6933478158597777

Epoch: 6| Step: 3
Training loss: 3.2119009980921596
Validation loss: 2.696170606916748

Epoch: 6| Step: 4
Training loss: 3.499971117172958
Validation loss: 2.6937628886837626

Epoch: 6| Step: 5
Training loss: 2.9612175398883616
Validation loss: 2.6860682553058477

Epoch: 6| Step: 6
Training loss: 2.9883517786815887
Validation loss: 2.6996632652754733

Epoch: 6| Step: 7
Training loss: 2.8497686727236493
Validation loss: 2.685594815867609

Epoch: 6| Step: 8
Training loss: 3.1982933261655835
Validation loss: 2.687108243342076

Epoch: 6| Step: 9
Training loss: 2.492199171272142
Validation loss: 2.6739907529518585

Epoch: 6| Step: 10
Training loss: 2.7989268528415265
Validation loss: 2.676614094819921

Epoch: 6| Step: 11
Training loss: 3.0611080198124276
Validation loss: 2.6764733176643656

Epoch: 6| Step: 12
Training loss: 2.9678921714998996
Validation loss: 2.674336544285183

Epoch: 6| Step: 13
Training loss: 3.271202179993248
Validation loss: 2.669655644341046

Epoch: 291| Step: 0
Training loss: 3.2208535440920367
Validation loss: 2.6731190687924236

Epoch: 6| Step: 1
Training loss: 2.702994547435865
Validation loss: 2.6724691727600387

Epoch: 6| Step: 2
Training loss: 2.688210504338752
Validation loss: 2.670969986047714

Epoch: 6| Step: 3
Training loss: 2.8810507086886123
Validation loss: 2.6721678369879185

Epoch: 6| Step: 4
Training loss: 2.8575755643156535
Validation loss: 2.6758385911029148

Epoch: 6| Step: 5
Training loss: 3.673012155613984
Validation loss: 2.675773917244197

Epoch: 6| Step: 6
Training loss: 2.9735446158923926
Validation loss: 2.6744923058942427

Epoch: 6| Step: 7
Training loss: 3.303021094240699
Validation loss: 2.6746035406947994

Epoch: 6| Step: 8
Training loss: 3.104594634250594
Validation loss: 2.677057062052622

Epoch: 6| Step: 9
Training loss: 3.0402605298988186
Validation loss: 2.6807552637800964

Epoch: 6| Step: 10
Training loss: 2.796271232350432
Validation loss: 2.6849575765877374

Epoch: 6| Step: 11
Training loss: 3.231256280594114
Validation loss: 2.68791747994164

Epoch: 6| Step: 12
Training loss: 2.9155528166933817
Validation loss: 2.6866174141991688

Epoch: 6| Step: 13
Training loss: 2.304852599356571
Validation loss: 2.683966172257876

Epoch: 292| Step: 0
Training loss: 2.835297315235863
Validation loss: 2.6839670901748955

Epoch: 6| Step: 1
Training loss: 2.9352614618715553
Validation loss: 2.6768986465208666

Epoch: 6| Step: 2
Training loss: 3.0742739680952647
Validation loss: 2.6773138488476556

Epoch: 6| Step: 3
Training loss: 3.2689361577607516
Validation loss: 2.6755504456216466

Epoch: 6| Step: 4
Training loss: 2.7050506259883855
Validation loss: 2.677034939660141

Epoch: 6| Step: 5
Training loss: 2.5301025992536834
Validation loss: 2.6750464948942048

Epoch: 6| Step: 6
Training loss: 2.8697559795249217
Validation loss: 2.702231946342824

Epoch: 6| Step: 7
Training loss: 3.006776943538679
Validation loss: 2.6895579714422198

Epoch: 6| Step: 8
Training loss: 3.353580178743128
Validation loss: 2.6924512507219225

Epoch: 6| Step: 9
Training loss: 2.6941173612749765
Validation loss: 2.699143099651874

Epoch: 6| Step: 10
Training loss: 4.09070036769879
Validation loss: 2.694651422549138

Epoch: 6| Step: 11
Training loss: 2.769538050805957
Validation loss: 2.680210222907788

Epoch: 6| Step: 12
Training loss: 2.88503669596429
Validation loss: 2.6735047840812576

Epoch: 6| Step: 13
Training loss: 2.594299442052081
Validation loss: 2.672052336879336

Epoch: 293| Step: 0
Training loss: 3.179320668048179
Validation loss: 2.6700472463935228

Epoch: 6| Step: 1
Training loss: 2.9945982939721216
Validation loss: 2.670064373459364

Epoch: 6| Step: 2
Training loss: 3.5840688586347023
Validation loss: 2.6694284178375396

Epoch: 6| Step: 3
Training loss: 2.9816880837942334
Validation loss: 2.670567902155877

Epoch: 6| Step: 4
Training loss: 2.7893219300900705
Validation loss: 2.6704412524776573

Epoch: 6| Step: 5
Training loss: 2.436063294163135
Validation loss: 2.6725363386365317

Epoch: 6| Step: 6
Training loss: 2.393566839715683
Validation loss: 2.6720923024946095

Epoch: 6| Step: 7
Training loss: 2.9958827057556023
Validation loss: 2.672840657048347

Epoch: 6| Step: 8
Training loss: 3.078057147987089
Validation loss: 2.6694997772229674

Epoch: 6| Step: 9
Training loss: 3.5298348350896953
Validation loss: 2.667515631737933

Epoch: 6| Step: 10
Training loss: 3.1121621986522836
Validation loss: 2.6743157711672856

Epoch: 6| Step: 11
Training loss: 3.3058364349907134
Validation loss: 2.6724837681335436

Epoch: 6| Step: 12
Training loss: 2.905334492530726
Validation loss: 2.679498757740781

Epoch: 6| Step: 13
Training loss: 2.0422560431514394
Validation loss: 2.672281000895971

Epoch: 294| Step: 0
Training loss: 2.4100283398683313
Validation loss: 2.6839102837967865

Epoch: 6| Step: 1
Training loss: 2.9070428566622804
Validation loss: 2.6779095815210128

Epoch: 6| Step: 2
Training loss: 3.071089862131061
Validation loss: 2.6757335491223566

Epoch: 6| Step: 3
Training loss: 3.6985950689429075
Validation loss: 2.6870757214252396

Epoch: 6| Step: 4
Training loss: 3.3072052871757807
Validation loss: 2.6839026632909335

Epoch: 6| Step: 5
Training loss: 2.323454813068587
Validation loss: 2.675782271324294

Epoch: 6| Step: 6
Training loss: 1.9959175644251224
Validation loss: 2.675068018472771

Epoch: 6| Step: 7
Training loss: 2.746660372146628
Validation loss: 2.668506874390775

Epoch: 6| Step: 8
Training loss: 3.125876952148101
Validation loss: 2.6778393384953754

Epoch: 6| Step: 9
Training loss: 3.4492824803444884
Validation loss: 2.683777417587844

Epoch: 6| Step: 10
Training loss: 2.6541328519845964
Validation loss: 2.6901609073721464

Epoch: 6| Step: 11
Training loss: 3.671133542783841
Validation loss: 2.6857209246812985

Epoch: 6| Step: 12
Training loss: 2.8438977213628402
Validation loss: 2.6914969634569883

Epoch: 6| Step: 13
Training loss: 3.4414807938329814
Validation loss: 2.6817713591953747

Epoch: 295| Step: 0
Training loss: 2.932787747652107
Validation loss: 2.678791890601112

Epoch: 6| Step: 1
Training loss: 3.1815653886323876
Validation loss: 2.693374153189527

Epoch: 6| Step: 2
Training loss: 2.916235392338107
Validation loss: 2.6789228853524727

Epoch: 6| Step: 3
Training loss: 2.978614080083845
Validation loss: 2.679251023573988

Epoch: 6| Step: 4
Training loss: 3.8626583819956144
Validation loss: 2.666742964647751

Epoch: 6| Step: 5
Training loss: 2.317833703468567
Validation loss: 2.667214930096472

Epoch: 6| Step: 6
Training loss: 3.3271193440080356
Validation loss: 2.6666938407984917

Epoch: 6| Step: 7
Training loss: 3.075240434380383
Validation loss: 2.6658347284396924

Epoch: 6| Step: 8
Training loss: 2.340820108794839
Validation loss: 2.665335730855841

Epoch: 6| Step: 9
Training loss: 3.0241389286482234
Validation loss: 2.6676985909669995

Epoch: 6| Step: 10
Training loss: 3.1735740583405287
Validation loss: 2.67103780676905

Epoch: 6| Step: 11
Training loss: 3.294676856952111
Validation loss: 2.670278432352222

Epoch: 6| Step: 12
Training loss: 2.495516093815748
Validation loss: 2.675760055516736

Epoch: 6| Step: 13
Training loss: 2.517899048136693
Validation loss: 2.6724744228828685

Epoch: 296| Step: 0
Training loss: 3.1595382934992857
Validation loss: 2.668039353785808

Epoch: 6| Step: 1
Training loss: 2.4363529734332885
Validation loss: 2.673043224544676

Epoch: 6| Step: 2
Training loss: 3.642998441525675
Validation loss: 2.6736856938569815

Epoch: 6| Step: 3
Training loss: 3.4106766521058143
Validation loss: 2.6703233802931035

Epoch: 6| Step: 4
Training loss: 2.806486185240679
Validation loss: 2.6726327399861605

Epoch: 6| Step: 5
Training loss: 3.2699686029075976
Validation loss: 2.66413819575967

Epoch: 6| Step: 6
Training loss: 2.7181097570269523
Validation loss: 2.6646642614262417

Epoch: 6| Step: 7
Training loss: 3.0570610171671593
Validation loss: 2.6693879580769004

Epoch: 6| Step: 8
Training loss: 3.4551596882596485
Validation loss: 2.6700868522065084

Epoch: 6| Step: 9
Training loss: 2.7848821347291337
Validation loss: 2.673666225469545

Epoch: 6| Step: 10
Training loss: 3.2474105496087127
Validation loss: 2.671902026812331

Epoch: 6| Step: 11
Training loss: 2.078193032434623
Validation loss: 2.669105689790036

Epoch: 6| Step: 12
Training loss: 2.7336519865824798
Validation loss: 2.67287916546678

Epoch: 6| Step: 13
Training loss: 2.5856681752628545
Validation loss: 2.6697604923840754

Epoch: 297| Step: 0
Training loss: 3.043152555073391
Validation loss: 2.6695477575462725

Epoch: 6| Step: 1
Training loss: 3.612902746222504
Validation loss: 2.6676440876717473

Epoch: 6| Step: 2
Training loss: 2.950368412095317
Validation loss: 2.6745721549809085

Epoch: 6| Step: 3
Training loss: 2.1077428083725818
Validation loss: 2.6737784246808958

Epoch: 6| Step: 4
Training loss: 2.9210837205631512
Validation loss: 2.668749819173872

Epoch: 6| Step: 5
Training loss: 3.2720212945594933
Validation loss: 2.674659423300436

Epoch: 6| Step: 6
Training loss: 2.7483884250755226
Validation loss: 2.6666278842700293

Epoch: 6| Step: 7
Training loss: 3.230857226113117
Validation loss: 2.6640598786799194

Epoch: 6| Step: 8
Training loss: 3.274175519755696
Validation loss: 2.665844923033574

Epoch: 6| Step: 9
Training loss: 2.8612369666046433
Validation loss: 2.6630408722158423

Epoch: 6| Step: 10
Training loss: 2.583863778158278
Validation loss: 2.665794318959383

Epoch: 6| Step: 11
Training loss: 2.585745628591496
Validation loss: 2.670609271348322

Epoch: 6| Step: 12
Training loss: 3.492547820957824
Validation loss: 2.672852525477058

Epoch: 6| Step: 13
Training loss: 2.816482098493227
Validation loss: 2.675421815447764

Epoch: 298| Step: 0
Training loss: 3.2992767697435057
Validation loss: 2.6901280240140606

Epoch: 6| Step: 1
Training loss: 2.643685728333474
Validation loss: 2.706647660395661

Epoch: 6| Step: 2
Training loss: 3.1404251870128363
Validation loss: 2.7146051589589195

Epoch: 6| Step: 3
Training loss: 2.6492067193332147
Validation loss: 2.705520363320273

Epoch: 6| Step: 4
Training loss: 3.2190886384172934
Validation loss: 2.7047714225970765

Epoch: 6| Step: 5
Training loss: 2.9956468151817552
Validation loss: 2.700920434651592

Epoch: 6| Step: 6
Training loss: 2.8605681051205902
Validation loss: 2.6986378130252873

Epoch: 6| Step: 7
Training loss: 2.8806630626968737
Validation loss: 2.6796787481500806

Epoch: 6| Step: 8
Training loss: 3.2190969335745425
Validation loss: 2.6601085821499537

Epoch: 6| Step: 9
Training loss: 3.1883775587615646
Validation loss: 2.6624021652851737

Epoch: 6| Step: 10
Training loss: 3.1127377829054206
Validation loss: 2.6653751368854017

Epoch: 6| Step: 11
Training loss: 2.6497954991444863
Validation loss: 2.6659459455915386

Epoch: 6| Step: 12
Training loss: 2.3934409318006065
Validation loss: 2.6611721849120746

Epoch: 6| Step: 13
Training loss: 3.849597855409895
Validation loss: 2.6631318655109237

Epoch: 299| Step: 0
Training loss: 2.2580558883264845
Validation loss: 2.6606248898718254

Epoch: 6| Step: 1
Training loss: 3.046986582742464
Validation loss: 2.659607163149094

Epoch: 6| Step: 2
Training loss: 3.4677330107119757
Validation loss: 2.66312595488698

Epoch: 6| Step: 3
Training loss: 2.77142828574762
Validation loss: 2.662985024014168

Epoch: 6| Step: 4
Training loss: 3.3029050235888757
Validation loss: 2.6595611945126287

Epoch: 6| Step: 5
Training loss: 3.7851022061012203
Validation loss: 2.65756732624214

Epoch: 6| Step: 6
Training loss: 3.3664096721597248
Validation loss: 2.6611492040949125

Epoch: 6| Step: 7
Training loss: 2.153853923395836
Validation loss: 2.6637128418196236

Epoch: 6| Step: 8
Training loss: 2.3121731501357106
Validation loss: 2.660912620674716

Epoch: 6| Step: 9
Training loss: 2.924257174338037
Validation loss: 2.6721196542656354

Epoch: 6| Step: 10
Training loss: 2.5455235365088758
Validation loss: 2.677775399876992

Epoch: 6| Step: 11
Training loss: 3.3699294253240732
Validation loss: 2.6786267240786894

Epoch: 6| Step: 12
Training loss: 2.920060027563679
Validation loss: 2.667257148089039

Epoch: 6| Step: 13
Training loss: 3.3175241048895843
Validation loss: 2.679865699357556

Epoch: 300| Step: 0
Training loss: 2.908846935694674
Validation loss: 2.702344119754775

Epoch: 6| Step: 1
Training loss: 3.1050544510396105
Validation loss: 2.7007799211270203

Epoch: 6| Step: 2
Training loss: 2.4196909254705834
Validation loss: 2.68774067286858

Epoch: 6| Step: 3
Training loss: 2.528589239511885
Validation loss: 2.6868066382180387

Epoch: 6| Step: 4
Training loss: 3.009610993350939
Validation loss: 2.691113021048082

Epoch: 6| Step: 5
Training loss: 2.9206710211640043
Validation loss: 2.6762020543375877

Epoch: 6| Step: 6
Training loss: 3.3260388350521994
Validation loss: 2.670490342912611

Epoch: 6| Step: 7
Training loss: 3.767375871401857
Validation loss: 2.660738455107001

Epoch: 6| Step: 8
Training loss: 2.833047366203112
Validation loss: 2.6649143203312606

Epoch: 6| Step: 9
Training loss: 3.6613676332153045
Validation loss: 2.6606676691460986

Epoch: 6| Step: 10
Training loss: 3.102613909871879
Validation loss: 2.6608035801698136

Epoch: 6| Step: 11
Training loss: 2.474147256698184
Validation loss: 2.6646301725178048

Epoch: 6| Step: 12
Training loss: 2.700696350299266
Validation loss: 2.6569956775775103

Epoch: 6| Step: 13
Training loss: 2.6754362231933317
Validation loss: 2.6597465862372487

Epoch: 301| Step: 0
Training loss: 3.542074441809257
Validation loss: 2.658097298339634

Epoch: 6| Step: 1
Training loss: 3.177012975361869
Validation loss: 2.661036897247676

Epoch: 6| Step: 2
Training loss: 3.183900633454722
Validation loss: 2.657845242866091

Epoch: 6| Step: 3
Training loss: 2.309653721406128
Validation loss: 2.669270401461146

Epoch: 6| Step: 4
Training loss: 2.971866136732232
Validation loss: 2.6722902863845084

Epoch: 6| Step: 5
Training loss: 3.1689451620281166
Validation loss: 2.6733856123833193

Epoch: 6| Step: 6
Training loss: 2.429966754136463
Validation loss: 2.6713704365168467

Epoch: 6| Step: 7
Training loss: 2.8365726652905674
Validation loss: 2.689544438117523

Epoch: 6| Step: 8
Training loss: 3.3481984717585993
Validation loss: 2.716342348868861

Epoch: 6| Step: 9
Training loss: 2.8947727447546576
Validation loss: 2.6980317325992265

Epoch: 6| Step: 10
Training loss: 2.874414467272089
Validation loss: 2.6916983002886745

Epoch: 6| Step: 11
Training loss: 3.1258674943386655
Validation loss: 2.6710434349832255

Epoch: 6| Step: 12
Training loss: 3.4259786168381474
Validation loss: 2.67079442267065

Epoch: 6| Step: 13
Training loss: 1.6046682622215116
Validation loss: 2.665790266437486

Epoch: 302| Step: 0
Training loss: 3.2874676604910373
Validation loss: 2.664622948580313

Epoch: 6| Step: 1
Training loss: 2.9571296141375965
Validation loss: 2.662395079257079

Epoch: 6| Step: 2
Training loss: 3.176613861584431
Validation loss: 2.6613395212796

Epoch: 6| Step: 3
Training loss: 2.4662729705189377
Validation loss: 2.658114357251761

Epoch: 6| Step: 4
Training loss: 3.501874694116141
Validation loss: 2.659489279267397

Epoch: 6| Step: 5
Training loss: 2.6307667558051793
Validation loss: 2.655715776705795

Epoch: 6| Step: 6
Training loss: 2.8919420695642954
Validation loss: 2.6532324505270926

Epoch: 6| Step: 7
Training loss: 2.7813562951510136
Validation loss: 2.6575647573595966

Epoch: 6| Step: 8
Training loss: 2.7363248140259233
Validation loss: 2.651549492624135

Epoch: 6| Step: 9
Training loss: 3.119090481750988
Validation loss: 2.6632282376350807

Epoch: 6| Step: 10
Training loss: 3.2265864410620564
Validation loss: 2.6614311420278263

Epoch: 6| Step: 11
Training loss: 2.322807434889435
Validation loss: 2.6676920023883794

Epoch: 6| Step: 12
Training loss: 3.3076637519327154
Validation loss: 2.6642156291166574

Epoch: 6| Step: 13
Training loss: 3.344038763679441
Validation loss: 2.6644593221365884

Epoch: 303| Step: 0
Training loss: 3.119487630881654
Validation loss: 2.66720044333871

Epoch: 6| Step: 1
Training loss: 3.312730025455986
Validation loss: 2.672014269401144

Epoch: 6| Step: 2
Training loss: 2.6362841438697835
Validation loss: 2.6673027120910007

Epoch: 6| Step: 3
Training loss: 2.6319230838424392
Validation loss: 2.672601120097444

Epoch: 6| Step: 4
Training loss: 3.350907979869155
Validation loss: 2.6623757420750787

Epoch: 6| Step: 5
Training loss: 3.2169200547055405
Validation loss: 2.6693643382592764

Epoch: 6| Step: 6
Training loss: 2.6719073912681606
Validation loss: 2.6667900947749654

Epoch: 6| Step: 7
Training loss: 2.896345591805372
Validation loss: 2.6729720009985987

Epoch: 6| Step: 8
Training loss: 3.3922385318665427
Validation loss: 2.673765792353232

Epoch: 6| Step: 9
Training loss: 2.478090121972647
Validation loss: 2.668364335990318

Epoch: 6| Step: 10
Training loss: 3.4101586270842947
Validation loss: 2.666114810272184

Epoch: 6| Step: 11
Training loss: 2.8958677843272125
Validation loss: 2.6697070481100433

Epoch: 6| Step: 12
Training loss: 2.590238469166196
Validation loss: 2.657412094909511

Epoch: 6| Step: 13
Training loss: 3.0520757646868257
Validation loss: 2.6611191269100347

Epoch: 304| Step: 0
Training loss: 2.5506604853925903
Validation loss: 2.6593591993567753

Epoch: 6| Step: 1
Training loss: 3.645450651884108
Validation loss: 2.6579768204835372

Epoch: 6| Step: 2
Training loss: 3.383674775983062
Validation loss: 2.664389076673453

Epoch: 6| Step: 3
Training loss: 3.1227217952977555
Validation loss: 2.656920452304171

Epoch: 6| Step: 4
Training loss: 2.9144285243169117
Validation loss: 2.6619231895707975

Epoch: 6| Step: 5
Training loss: 1.924542196753228
Validation loss: 2.666087964225276

Epoch: 6| Step: 6
Training loss: 2.4765954241083374
Validation loss: 2.6644154000564226

Epoch: 6| Step: 7
Training loss: 3.2796379852555457
Validation loss: 2.6599988547640407

Epoch: 6| Step: 8
Training loss: 3.3468839985417516
Validation loss: 2.6785536285644946

Epoch: 6| Step: 9
Training loss: 2.446682969471236
Validation loss: 2.6618769354042584

Epoch: 6| Step: 10
Training loss: 3.345121868747454
Validation loss: 2.659816010707524

Epoch: 6| Step: 11
Training loss: 3.0165647317373647
Validation loss: 2.6599015541064697

Epoch: 6| Step: 12
Training loss: 3.045306462242283
Validation loss: 2.6543822698201596

Epoch: 6| Step: 13
Training loss: 2.6956776247254255
Validation loss: 2.6693210443215647

Epoch: 305| Step: 0
Training loss: 2.676248284116192
Validation loss: 2.6685039125440055

Epoch: 6| Step: 1
Training loss: 3.216970155330267
Validation loss: 2.6550489969075484

Epoch: 6| Step: 2
Training loss: 2.8328965542290616
Validation loss: 2.668112517315357

Epoch: 6| Step: 3
Training loss: 3.432888752815766
Validation loss: 2.666434045869343

Epoch: 6| Step: 4
Training loss: 2.5985636338147224
Validation loss: 2.6686165516732467

Epoch: 6| Step: 5
Training loss: 2.8266231701161373
Validation loss: 2.664806070337743

Epoch: 6| Step: 6
Training loss: 2.963101766125493
Validation loss: 2.6565415783939548

Epoch: 6| Step: 7
Training loss: 3.4355624200188393
Validation loss: 2.6566257372719044

Epoch: 6| Step: 8
Training loss: 2.688697725476848
Validation loss: 2.6520459197595736

Epoch: 6| Step: 9
Training loss: 2.918399804485883
Validation loss: 2.6539792502661834

Epoch: 6| Step: 10
Training loss: 3.0101632580253552
Validation loss: 2.6548547138414578

Epoch: 6| Step: 11
Training loss: 3.150195669727257
Validation loss: 2.65257584104022

Epoch: 6| Step: 12
Training loss: 3.3385934017336716
Validation loss: 2.650299113971094

Epoch: 6| Step: 13
Training loss: 2.0769726993197293
Validation loss: 2.653855015105232

Epoch: 306| Step: 0
Training loss: 2.8160356973585414
Validation loss: 2.653853132358306

Epoch: 6| Step: 1
Training loss: 3.2262203598582304
Validation loss: 2.6546430616677865

Epoch: 6| Step: 2
Training loss: 2.373672716792033
Validation loss: 2.6617296972054807

Epoch: 6| Step: 3
Training loss: 2.5301466998062154
Validation loss: 2.6658766672932637

Epoch: 6| Step: 4
Training loss: 3.428158082341655
Validation loss: 2.6681522594602476

Epoch: 6| Step: 5
Training loss: 3.1721092100067994
Validation loss: 2.6632848142272656

Epoch: 6| Step: 6
Training loss: 3.3134133861038095
Validation loss: 2.665458865850936

Epoch: 6| Step: 7
Training loss: 3.2433779817378476
Validation loss: 2.6696204447200014

Epoch: 6| Step: 8
Training loss: 2.9200629669089144
Validation loss: 2.6694823507465877

Epoch: 6| Step: 9
Training loss: 2.8740474947493815
Validation loss: 2.668629414917071

Epoch: 6| Step: 10
Training loss: 3.2168469775431827
Validation loss: 2.6726115056664024

Epoch: 6| Step: 11
Training loss: 2.8256596731831602
Validation loss: 2.6705524995396077

Epoch: 6| Step: 12
Training loss: 2.7101287954770212
Validation loss: 2.663260494381323

Epoch: 6| Step: 13
Training loss: 2.8786089263550743
Validation loss: 2.6585449294110215

Epoch: 307| Step: 0
Training loss: 2.9504796042371706
Validation loss: 2.651597552181086

Epoch: 6| Step: 1
Training loss: 2.3457190825136336
Validation loss: 2.655158637261183

Epoch: 6| Step: 2
Training loss: 3.1505769413190636
Validation loss: 2.647085280389731

Epoch: 6| Step: 3
Training loss: 2.72753871285354
Validation loss: 2.648536137496018

Epoch: 6| Step: 4
Training loss: 3.161215926318938
Validation loss: 2.6498222325889067

Epoch: 6| Step: 5
Training loss: 3.0198650693750286
Validation loss: 2.6546607941504723

Epoch: 6| Step: 6
Training loss: 2.947186994167297
Validation loss: 2.652815421562374

Epoch: 6| Step: 7
Training loss: 3.165324997690351
Validation loss: 2.6585458040329426

Epoch: 6| Step: 8
Training loss: 3.0087299483502354
Validation loss: 2.657878366478052

Epoch: 6| Step: 9
Training loss: 3.640257984702517
Validation loss: 2.660217466594594

Epoch: 6| Step: 10
Training loss: 2.7426687834414243
Validation loss: 2.6569153793809313

Epoch: 6| Step: 11
Training loss: 3.1094723786867635
Validation loss: 2.664388476268673

Epoch: 6| Step: 12
Training loss: 2.3202053263666653
Validation loss: 2.6597329985764775

Epoch: 6| Step: 13
Training loss: 3.350858031887612
Validation loss: 2.667942283908802

Epoch: 308| Step: 0
Training loss: 2.6839629562027407
Validation loss: 2.6649019595980588

Epoch: 6| Step: 1
Training loss: 2.861890009890481
Validation loss: 2.657671221617115

Epoch: 6| Step: 2
Training loss: 2.5966510405292698
Validation loss: 2.65560483776354

Epoch: 6| Step: 3
Training loss: 2.7247112296149916
Validation loss: 2.6584628207064833

Epoch: 6| Step: 4
Training loss: 2.77071950195842
Validation loss: 2.663158242713677

Epoch: 6| Step: 5
Training loss: 3.3493941257369944
Validation loss: 2.655021032833241

Epoch: 6| Step: 6
Training loss: 3.178709587413308
Validation loss: 2.654938362273895

Epoch: 6| Step: 7
Training loss: 3.329195522013014
Validation loss: 2.653631897879606

Epoch: 6| Step: 8
Training loss: 3.053967949689704
Validation loss: 2.6551412344553413

Epoch: 6| Step: 9
Training loss: 2.685445310579473
Validation loss: 2.6567002563287185

Epoch: 6| Step: 10
Training loss: 3.4567294403919244
Validation loss: 2.6552093590693886

Epoch: 6| Step: 11
Training loss: 3.1711636953071474
Validation loss: 2.655396445833511

Epoch: 6| Step: 12
Training loss: 3.2041933836565115
Validation loss: 2.6589145795554217

Epoch: 6| Step: 13
Training loss: 1.8468854074459233
Validation loss: 2.6576979665139393

Epoch: 309| Step: 0
Training loss: 2.18070987255258
Validation loss: 2.6520418094957403

Epoch: 6| Step: 1
Training loss: 3.6069717663410055
Validation loss: 2.654636997907966

Epoch: 6| Step: 2
Training loss: 3.0783626251672116
Validation loss: 2.651256288028022

Epoch: 6| Step: 3
Training loss: 2.880456307872928
Validation loss: 2.6608321121386855

Epoch: 6| Step: 4
Training loss: 2.9975792336829117
Validation loss: 2.6584816964730584

Epoch: 6| Step: 5
Training loss: 2.9717177163911592
Validation loss: 2.6566192158020425

Epoch: 6| Step: 6
Training loss: 3.334125106871589
Validation loss: 2.6444446248227678

Epoch: 6| Step: 7
Training loss: 2.608901294950975
Validation loss: 2.653968554157705

Epoch: 6| Step: 8
Training loss: 2.1498421810689776
Validation loss: 2.6514681099941906

Epoch: 6| Step: 9
Training loss: 3.1571809509928332
Validation loss: 2.65818301856735

Epoch: 6| Step: 10
Training loss: 3.4277268629725377
Validation loss: 2.6507729308039876

Epoch: 6| Step: 11
Training loss: 2.859202728918702
Validation loss: 2.6551518041824105

Epoch: 6| Step: 12
Training loss: 3.2773654286846328
Validation loss: 2.6478483126883363

Epoch: 6| Step: 13
Training loss: 2.6515026978204403
Validation loss: 2.650368195871996

Epoch: 310| Step: 0
Training loss: 2.97123245047914
Validation loss: 2.6551028009239195

Epoch: 6| Step: 1
Training loss: 2.3931438664678715
Validation loss: 2.6529903169593343

Epoch: 6| Step: 2
Training loss: 2.3105007499160326
Validation loss: 2.6543518513211457

Epoch: 6| Step: 3
Training loss: 3.0354352550334522
Validation loss: 2.644468031941456

Epoch: 6| Step: 4
Training loss: 2.5864571685931783
Validation loss: 2.652334693348212

Epoch: 6| Step: 5
Training loss: 3.365390802734053
Validation loss: 2.6467842887791426

Epoch: 6| Step: 6
Training loss: 2.7142665331743587
Validation loss: 2.657479474451633

Epoch: 6| Step: 7
Training loss: 3.400719308497181
Validation loss: 2.6514883911056644

Epoch: 6| Step: 8
Training loss: 3.481463802764713
Validation loss: 2.6468299679125846

Epoch: 6| Step: 9
Training loss: 3.3963283965855853
Validation loss: 2.651216116621767

Epoch: 6| Step: 10
Training loss: 3.12978865888024
Validation loss: 2.6523197908841833

Epoch: 6| Step: 11
Training loss: 3.015616303268305
Validation loss: 2.647812038913195

Epoch: 6| Step: 12
Training loss: 3.1001199206875922
Validation loss: 2.644864595276371

Epoch: 6| Step: 13
Training loss: 2.0699007596538714
Validation loss: 2.652034247250977

Epoch: 311| Step: 0
Training loss: 3.3069770403013936
Validation loss: 2.6544643222122697

Epoch: 6| Step: 1
Training loss: 2.8747876959655647
Validation loss: 2.648992446613239

Epoch: 6| Step: 2
Training loss: 2.607362439338974
Validation loss: 2.658405443300613

Epoch: 6| Step: 3
Training loss: 3.568824775299907
Validation loss: 2.6562311025836425

Epoch: 6| Step: 4
Training loss: 3.1062136734310095
Validation loss: 2.655090554795765

Epoch: 6| Step: 5
Training loss: 2.7258955787479815
Validation loss: 2.649246505103372

Epoch: 6| Step: 6
Training loss: 3.022891761752558
Validation loss: 2.6565470858108386

Epoch: 6| Step: 7
Training loss: 2.605920389313429
Validation loss: 2.651668322131273

Epoch: 6| Step: 8
Training loss: 3.201861620846581
Validation loss: 2.6614352493500344

Epoch: 6| Step: 9
Training loss: 3.3619827439899557
Validation loss: 2.654825060724894

Epoch: 6| Step: 10
Training loss: 2.953307938333808
Validation loss: 2.6506758882231733

Epoch: 6| Step: 11
Training loss: 2.9546835687006996
Validation loss: 2.654162136135896

Epoch: 6| Step: 12
Training loss: 2.797904736078484
Validation loss: 2.6537370099833804

Epoch: 6| Step: 13
Training loss: 1.7357450005955037
Validation loss: 2.6485286146070406

Epoch: 312| Step: 0
Training loss: 3.494482596195366
Validation loss: 2.6583020896771594

Epoch: 6| Step: 1
Training loss: 3.0717468793817
Validation loss: 2.6707832942852616

Epoch: 6| Step: 2
Training loss: 3.2530989910628754
Validation loss: 2.6675261803036636

Epoch: 6| Step: 3
Training loss: 2.814771624934625
Validation loss: 2.6614759138096695

Epoch: 6| Step: 4
Training loss: 2.45820800547992
Validation loss: 2.666698681218748

Epoch: 6| Step: 5
Training loss: 3.074728238882415
Validation loss: 2.6745487122655245

Epoch: 6| Step: 6
Training loss: 2.4251231408069556
Validation loss: 2.6776672897240203

Epoch: 6| Step: 7
Training loss: 2.9267882790060087
Validation loss: 2.6706566442622943

Epoch: 6| Step: 8
Training loss: 2.796926316797466
Validation loss: 2.6761654559947834

Epoch: 6| Step: 9
Training loss: 3.1985989483747326
Validation loss: 2.6622708670479116

Epoch: 6| Step: 10
Training loss: 3.0342521351887455
Validation loss: 2.6425653008388257

Epoch: 6| Step: 11
Training loss: 2.7198273727389393
Validation loss: 2.6463928325489228

Epoch: 6| Step: 12
Training loss: 3.0258788668534167
Validation loss: 2.6401719215959356

Epoch: 6| Step: 13
Training loss: 3.5077151686454964
Validation loss: 2.640932451021436

Epoch: 313| Step: 0
Training loss: 2.1787988088440304
Validation loss: 2.6427903549085494

Epoch: 6| Step: 1
Training loss: 3.159308132290337
Validation loss: 2.6407102670705376

Epoch: 6| Step: 2
Training loss: 3.3410038589596835
Validation loss: 2.644267799134794

Epoch: 6| Step: 3
Training loss: 2.758694342953608
Validation loss: 2.6460370695973654

Epoch: 6| Step: 4
Training loss: 3.300494047231497
Validation loss: 2.6507140155229827

Epoch: 6| Step: 5
Training loss: 2.837712008584478
Validation loss: 2.653594821114087

Epoch: 6| Step: 6
Training loss: 2.8998559324061146
Validation loss: 2.6543216913177163

Epoch: 6| Step: 7
Training loss: 2.9696278127592817
Validation loss: 2.6651583861720907

Epoch: 6| Step: 8
Training loss: 2.894807171765771
Validation loss: 2.6643484634112045

Epoch: 6| Step: 9
Training loss: 3.2969201252095446
Validation loss: 2.6576049466299696

Epoch: 6| Step: 10
Training loss: 3.5063204236361525
Validation loss: 2.652661283532603

Epoch: 6| Step: 11
Training loss: 2.7712404817203495
Validation loss: 2.6428200135572752

Epoch: 6| Step: 12
Training loss: 2.9257964068887277
Validation loss: 2.6508345700844798

Epoch: 6| Step: 13
Training loss: 2.134071286041366
Validation loss: 2.6493004085755074

Epoch: 314| Step: 0
Training loss: 3.028101908592781
Validation loss: 2.650124477249887

Epoch: 6| Step: 1
Training loss: 3.299245262536292
Validation loss: 2.6560646006904

Epoch: 6| Step: 2
Training loss: 2.8243083174604746
Validation loss: 2.664125246357897

Epoch: 6| Step: 3
Training loss: 2.846622567233528
Validation loss: 2.6634889372017856

Epoch: 6| Step: 4
Training loss: 3.014392976653873
Validation loss: 2.6656065155062776

Epoch: 6| Step: 5
Training loss: 3.6111358706937806
Validation loss: 2.662151217499509

Epoch: 6| Step: 6
Training loss: 2.5758175783427317
Validation loss: 2.6593467790627856

Epoch: 6| Step: 7
Training loss: 3.1128502215935794
Validation loss: 2.6564094008235712

Epoch: 6| Step: 8
Training loss: 2.7170028334214282
Validation loss: 2.646616499023359

Epoch: 6| Step: 9
Training loss: 3.0776295529451123
Validation loss: 2.665317627423118

Epoch: 6| Step: 10
Training loss: 2.284541120633738
Validation loss: 2.654563800020237

Epoch: 6| Step: 11
Training loss: 2.8409391491773657
Validation loss: 2.656924983914429

Epoch: 6| Step: 12
Training loss: 2.9527259839661992
Validation loss: 2.651160609187645

Epoch: 6| Step: 13
Training loss: 3.407621894833612
Validation loss: 2.6492517538308893

Epoch: 315| Step: 0
Training loss: 2.7682332816082913
Validation loss: 2.648407576593965

Epoch: 6| Step: 1
Training loss: 2.9798548154859006
Validation loss: 2.654824318137387

Epoch: 6| Step: 2
Training loss: 2.90684142299002
Validation loss: 2.647035174800695

Epoch: 6| Step: 3
Training loss: 3.002268569247203
Validation loss: 2.641976643750452

Epoch: 6| Step: 4
Training loss: 3.458218921162952
Validation loss: 2.6399053981539278

Epoch: 6| Step: 5
Training loss: 2.3906251994612866
Validation loss: 2.639848301077151

Epoch: 6| Step: 6
Training loss: 2.855328140241004
Validation loss: 2.639569824056237

Epoch: 6| Step: 7
Training loss: 2.8276115499360133
Validation loss: 2.6428874324045233

Epoch: 6| Step: 8
Training loss: 2.9724863733183016
Validation loss: 2.648528288408206

Epoch: 6| Step: 9
Training loss: 2.4498759335614833
Validation loss: 2.6505255778340766

Epoch: 6| Step: 10
Training loss: 3.373240542084235
Validation loss: 2.64092892337487

Epoch: 6| Step: 11
Training loss: 2.8737617811680813
Validation loss: 2.638559320707021

Epoch: 6| Step: 12
Training loss: 3.4780873587080423
Validation loss: 2.6576508564989525

Epoch: 6| Step: 13
Training loss: 3.0366047234468896
Validation loss: 2.646598868596495

Epoch: 316| Step: 0
Training loss: 2.217138430460358
Validation loss: 2.661792929071603

Epoch: 6| Step: 1
Training loss: 2.664287121384131
Validation loss: 2.676290685298038

Epoch: 6| Step: 2
Training loss: 3.435709677824279
Validation loss: 2.68675500818049

Epoch: 6| Step: 3
Training loss: 3.489500099821645
Validation loss: 2.673347047009524

Epoch: 6| Step: 4
Training loss: 2.890709953090754
Validation loss: 2.6766573972218053

Epoch: 6| Step: 5
Training loss: 3.0716085634688697
Validation loss: 2.67951129128411

Epoch: 6| Step: 6
Training loss: 2.8534778589860537
Validation loss: 2.659836496112537

Epoch: 6| Step: 7
Training loss: 2.4171634251209984
Validation loss: 2.665100698885188

Epoch: 6| Step: 8
Training loss: 2.961738095714647
Validation loss: 2.655671064200187

Epoch: 6| Step: 9
Training loss: 3.159138934242552
Validation loss: 2.649051981320786

Epoch: 6| Step: 10
Training loss: 2.818519677608298
Validation loss: 2.6595871866165797

Epoch: 6| Step: 11
Training loss: 2.8306665960495456
Validation loss: 2.6436404865286947

Epoch: 6| Step: 12
Training loss: 3.145304671238472
Validation loss: 2.644618736057564

Epoch: 6| Step: 13
Training loss: 3.6562445224818747
Validation loss: 2.64396503574402

Epoch: 317| Step: 0
Training loss: 2.395401017257399
Validation loss: 2.643083699905985

Epoch: 6| Step: 1
Training loss: 3.0458779293053575
Validation loss: 2.645130503695668

Epoch: 6| Step: 2
Training loss: 3.191616915189728
Validation loss: 2.637001235031318

Epoch: 6| Step: 3
Training loss: 2.9624138928224895
Validation loss: 2.6386795629808315

Epoch: 6| Step: 4
Training loss: 2.7467120194934496
Validation loss: 2.6368288414143306

Epoch: 6| Step: 5
Training loss: 3.0302643107339193
Validation loss: 2.6371244025372267

Epoch: 6| Step: 6
Training loss: 3.2916562687834356
Validation loss: 2.638964815636037

Epoch: 6| Step: 7
Training loss: 3.2313434934094984
Validation loss: 2.6376943561261417

Epoch: 6| Step: 8
Training loss: 3.2627594709439394
Validation loss: 2.63290658955943

Epoch: 6| Step: 9
Training loss: 3.04951089157859
Validation loss: 2.634564324914869

Epoch: 6| Step: 10
Training loss: 3.3512853405578418
Validation loss: 2.646214943488704

Epoch: 6| Step: 11
Training loss: 2.488955515677409
Validation loss: 2.653445846088832

Epoch: 6| Step: 12
Training loss: 2.8854306951702826
Validation loss: 2.6633584163849724

Epoch: 6| Step: 13
Training loss: 2.153341570898466
Validation loss: 2.6637716967312235

Epoch: 318| Step: 0
Training loss: 3.4954920757140036
Validation loss: 2.666229540685996

Epoch: 6| Step: 1
Training loss: 2.8283429983854704
Validation loss: 2.6675331844667567

Epoch: 6| Step: 2
Training loss: 2.9430246548852925
Validation loss: 2.6696992641468924

Epoch: 6| Step: 3
Training loss: 3.3422508800858397
Validation loss: 2.6648365003397054

Epoch: 6| Step: 4
Training loss: 3.0219459501692993
Validation loss: 2.6543003269294956

Epoch: 6| Step: 5
Training loss: 2.4571967865167936
Validation loss: 2.6498129215790884

Epoch: 6| Step: 6
Training loss: 3.0123640227594066
Validation loss: 2.6490912003818163

Epoch: 6| Step: 7
Training loss: 2.5707321056383843
Validation loss: 2.6430638528570105

Epoch: 6| Step: 8
Training loss: 3.6504559375845225
Validation loss: 2.649545710001947

Epoch: 6| Step: 9
Training loss: 2.7839479540640664
Validation loss: 2.6486905804333754

Epoch: 6| Step: 10
Training loss: 2.51879200107588
Validation loss: 2.6395801191192785

Epoch: 6| Step: 11
Training loss: 2.8505191932384015
Validation loss: 2.6497301668969975

Epoch: 6| Step: 12
Training loss: 3.083063337172239
Validation loss: 2.6535276308365336

Epoch: 6| Step: 13
Training loss: 2.653325614039376
Validation loss: 2.660245776456231

Epoch: 319| Step: 0
Training loss: 3.1194460533578026
Validation loss: 2.652564134137419

Epoch: 6| Step: 1
Training loss: 3.1385444088246626
Validation loss: 2.6529289625878656

Epoch: 6| Step: 2
Training loss: 3.28167009843292
Validation loss: 2.6565835143790903

Epoch: 6| Step: 3
Training loss: 2.8920926054272016
Validation loss: 2.6552450403486914

Epoch: 6| Step: 4
Training loss: 2.7937335907797687
Validation loss: 2.6528377739498046

Epoch: 6| Step: 5
Training loss: 2.7454947934883753
Validation loss: 2.6568894834403944

Epoch: 6| Step: 6
Training loss: 3.2211377814644524
Validation loss: 2.6666965450899784

Epoch: 6| Step: 7
Training loss: 2.9737833821177637
Validation loss: 2.6621747944230623

Epoch: 6| Step: 8
Training loss: 2.6086618511110986
Validation loss: 2.6624892672932368

Epoch: 6| Step: 9
Training loss: 3.588386846043825
Validation loss: 2.6738418193676696

Epoch: 6| Step: 10
Training loss: 2.950586913609837
Validation loss: 2.67095410775881

Epoch: 6| Step: 11
Training loss: 2.342973911219932
Validation loss: 2.690873989323906

Epoch: 6| Step: 12
Training loss: 2.75770080167299
Validation loss: 2.679457208146947

Epoch: 6| Step: 13
Training loss: 2.950810731594598
Validation loss: 2.663151252072854

Epoch: 320| Step: 0
Training loss: 3.174731842491349
Validation loss: 2.656843163832979

Epoch: 6| Step: 1
Training loss: 3.133497967013437
Validation loss: 2.6577618036022046

Epoch: 6| Step: 2
Training loss: 2.7043709942739755
Validation loss: 2.6528738185897724

Epoch: 6| Step: 3
Training loss: 2.948680944859107
Validation loss: 2.6414781815745627

Epoch: 6| Step: 4
Training loss: 3.163901242514958
Validation loss: 2.631055695941602

Epoch: 6| Step: 5
Training loss: 2.473675510235274
Validation loss: 2.6391448583487094

Epoch: 6| Step: 6
Training loss: 3.29682698147051
Validation loss: 2.639421882479638

Epoch: 6| Step: 7
Training loss: 2.9141466062133667
Validation loss: 2.641313478031347

Epoch: 6| Step: 8
Training loss: 2.725221320447637
Validation loss: 2.6362957587241116

Epoch: 6| Step: 9
Training loss: 3.0151336744038275
Validation loss: 2.643868533065141

Epoch: 6| Step: 10
Training loss: 2.8250859407839157
Validation loss: 2.637129893149358

Epoch: 6| Step: 11
Training loss: 3.485224462037022
Validation loss: 2.6507269211541304

Epoch: 6| Step: 12
Training loss: 2.8624327939069225
Validation loss: 2.6357194703127873

Epoch: 6| Step: 13
Training loss: 2.497443990604405
Validation loss: 2.6462556170785554

Epoch: 321| Step: 0
Training loss: 2.541024257167313
Validation loss: 2.63462731451958

Epoch: 6| Step: 1
Training loss: 3.2204388382222042
Validation loss: 2.6426140330962977

Epoch: 6| Step: 2
Training loss: 3.476111770729264
Validation loss: 2.6399987513264835

Epoch: 6| Step: 3
Training loss: 3.183194412741943
Validation loss: 2.6460024888046285

Epoch: 6| Step: 4
Training loss: 2.9368308096429003
Validation loss: 2.6408517896320345

Epoch: 6| Step: 5
Training loss: 2.833936757923966
Validation loss: 2.6394180439439245

Epoch: 6| Step: 6
Training loss: 1.923658086552795
Validation loss: 2.638124203453254

Epoch: 6| Step: 7
Training loss: 3.5525361310395294
Validation loss: 2.6332010565646273

Epoch: 6| Step: 8
Training loss: 3.2127846558322233
Validation loss: 2.6384127090287355

Epoch: 6| Step: 9
Training loss: 3.0966649050616897
Validation loss: 2.6423619695656333

Epoch: 6| Step: 10
Training loss: 2.80787829967876
Validation loss: 2.639524751603275

Epoch: 6| Step: 11
Training loss: 2.7668569805764003
Validation loss: 2.639639638365032

Epoch: 6| Step: 12
Training loss: 3.0064925827526143
Validation loss: 2.6433739520324617

Epoch: 6| Step: 13
Training loss: 2.4707222315837307
Validation loss: 2.6477251647596676

Epoch: 322| Step: 0
Training loss: 2.979944905533431
Validation loss: 2.6452340036758164

Epoch: 6| Step: 1
Training loss: 3.237265065038444
Validation loss: 2.6585181014250803

Epoch: 6| Step: 2
Training loss: 2.6214848552050296
Validation loss: 2.6652100257725384

Epoch: 6| Step: 3
Training loss: 3.2343863519294294
Validation loss: 2.6689391746138393

Epoch: 6| Step: 4
Training loss: 2.8715607347689507
Validation loss: 2.67278175245304

Epoch: 6| Step: 5
Training loss: 2.6687235846541064
Validation loss: 2.6974779796164383

Epoch: 6| Step: 6
Training loss: 2.5980674016724072
Validation loss: 2.683971248975024

Epoch: 6| Step: 7
Training loss: 2.915251052279193
Validation loss: 2.688606545700868

Epoch: 6| Step: 8
Training loss: 2.616346719542414
Validation loss: 2.679050865140085

Epoch: 6| Step: 9
Training loss: 3.377673608933209
Validation loss: 2.6754387279637415

Epoch: 6| Step: 10
Training loss: 2.6885505219916843
Validation loss: 2.668870379374722

Epoch: 6| Step: 11
Training loss: 3.417361553209078
Validation loss: 2.6595144317503565

Epoch: 6| Step: 12
Training loss: 3.1475342621578433
Validation loss: 2.6529494200006973

Epoch: 6| Step: 13
Training loss: 3.0502769844731863
Validation loss: 2.6503935587251917

Epoch: 323| Step: 0
Training loss: 2.872566852107052
Validation loss: 2.642219849680605

Epoch: 6| Step: 1
Training loss: 3.3236515264998063
Validation loss: 2.6370100108882273

Epoch: 6| Step: 2
Training loss: 2.8397371253732526
Validation loss: 2.635339221126895

Epoch: 6| Step: 3
Training loss: 3.365057393189669
Validation loss: 2.6348853418121454

Epoch: 6| Step: 4
Training loss: 2.525812029805882
Validation loss: 2.6294907481127514

Epoch: 6| Step: 5
Training loss: 3.1855745671025817
Validation loss: 2.6352619831164104

Epoch: 6| Step: 6
Training loss: 2.700505481309701
Validation loss: 2.635007629467546

Epoch: 6| Step: 7
Training loss: 2.373976637560613
Validation loss: 2.625760061660963

Epoch: 6| Step: 8
Training loss: 3.3694744796092153
Validation loss: 2.6377782843875597

Epoch: 6| Step: 9
Training loss: 3.291453744947201
Validation loss: 2.6386001978070737

Epoch: 6| Step: 10
Training loss: 2.5891543199997633
Validation loss: 2.6423371166014635

Epoch: 6| Step: 11
Training loss: 2.6522641963573412
Validation loss: 2.6457529331116403

Epoch: 6| Step: 12
Training loss: 2.8922464308049385
Validation loss: 2.634251418446071

Epoch: 6| Step: 13
Training loss: 3.5234893321350405
Validation loss: 2.6412969225729643

Epoch: 324| Step: 0
Training loss: 2.745868700771215
Validation loss: 2.645465195088153

Epoch: 6| Step: 1
Training loss: 2.1606089443573566
Validation loss: 2.636393738058305

Epoch: 6| Step: 2
Training loss: 2.605266237181041
Validation loss: 2.637320486519805

Epoch: 6| Step: 3
Training loss: 3.0200324388997606
Validation loss: 2.6377051969534047

Epoch: 6| Step: 4
Training loss: 3.135888470778205
Validation loss: 2.6420347175576047

Epoch: 6| Step: 5
Training loss: 3.2506739577831505
Validation loss: 2.6524031452110455

Epoch: 6| Step: 6
Training loss: 2.650181558975201
Validation loss: 2.6469635361846398

Epoch: 6| Step: 7
Training loss: 3.0902816905783888
Validation loss: 2.644883311714175

Epoch: 6| Step: 8
Training loss: 2.457010290302096
Validation loss: 2.6587461398369774

Epoch: 6| Step: 9
Training loss: 3.051058044771669
Validation loss: 2.6524530256834487

Epoch: 6| Step: 10
Training loss: 3.5735316215366097
Validation loss: 2.6692330093565206

Epoch: 6| Step: 11
Training loss: 3.312122827325553
Validation loss: 2.674919651861527

Epoch: 6| Step: 12
Training loss: 3.3999840736016145
Validation loss: 2.692447887695618

Epoch: 6| Step: 13
Training loss: 2.568832017466296
Validation loss: 2.6583960167356375

Epoch: 325| Step: 0
Training loss: 2.762752096833802
Validation loss: 2.6602353180373393

Epoch: 6| Step: 1
Training loss: 3.2513213772622027
Validation loss: 2.65422639631973

Epoch: 6| Step: 2
Training loss: 3.0077906223839097
Validation loss: 2.6681746169189746

Epoch: 6| Step: 3
Training loss: 2.394244676277939
Validation loss: 2.6520592983729068

Epoch: 6| Step: 4
Training loss: 3.0434792400145287
Validation loss: 2.6514181723170487

Epoch: 6| Step: 5
Training loss: 2.8910629353120383
Validation loss: 2.6475305640579276

Epoch: 6| Step: 6
Training loss: 3.272939858130822
Validation loss: 2.6563225298925577

Epoch: 6| Step: 7
Training loss: 3.0100669437707603
Validation loss: 2.6599179407594855

Epoch: 6| Step: 8
Training loss: 3.7828687245327903
Validation loss: 2.649903799273931

Epoch: 6| Step: 9
Training loss: 2.7148676370352005
Validation loss: 2.6358165101232536

Epoch: 6| Step: 10
Training loss: 2.946373219816468
Validation loss: 2.630777961375122

Epoch: 6| Step: 11
Training loss: 2.3850567364292043
Validation loss: 2.630642380421248

Epoch: 6| Step: 12
Training loss: 3.0340061831829357
Validation loss: 2.6281789876175843

Epoch: 6| Step: 13
Training loss: 2.5526773085924863
Validation loss: 2.6250910218255328

Epoch: 326| Step: 0
Training loss: 2.459699240496433
Validation loss: 2.625913959941394

Epoch: 6| Step: 1
Training loss: 2.695645342192212
Validation loss: 2.6306140925789396

Epoch: 6| Step: 2
Training loss: 3.2311854461183485
Validation loss: 2.6236343796660107

Epoch: 6| Step: 3
Training loss: 2.947379199166059
Validation loss: 2.6193814559635653

Epoch: 6| Step: 4
Training loss: 3.2154234946297344
Validation loss: 2.6257426709942058

Epoch: 6| Step: 5
Training loss: 2.999644576317087
Validation loss: 2.6223422286534586

Epoch: 6| Step: 6
Training loss: 3.143154359362936
Validation loss: 2.622565024450646

Epoch: 6| Step: 7
Training loss: 2.2718720699747914
Validation loss: 2.6207735440586286

Epoch: 6| Step: 8
Training loss: 3.188537279284073
Validation loss: 2.6261090359338146

Epoch: 6| Step: 9
Training loss: 3.3744975528411425
Validation loss: 2.6236735506951026

Epoch: 6| Step: 10
Training loss: 2.7309682495607017
Validation loss: 2.6275625909873814

Epoch: 6| Step: 11
Training loss: 3.091528663399959
Validation loss: 2.6220223658366453

Epoch: 6| Step: 12
Training loss: 3.175100105689952
Validation loss: 2.6291803619551755

Epoch: 6| Step: 13
Training loss: 2.6616312606580954
Validation loss: 2.6250954535923885

Epoch: 327| Step: 0
Training loss: 2.601485150994471
Validation loss: 2.6322730632678284

Epoch: 6| Step: 1
Training loss: 3.0670639596196003
Validation loss: 2.63752147321927

Epoch: 6| Step: 2
Training loss: 2.8723907240092723
Validation loss: 2.6374318358852835

Epoch: 6| Step: 3
Training loss: 2.9461849954172394
Validation loss: 2.632833733979213

Epoch: 6| Step: 4
Training loss: 3.172753123232478
Validation loss: 2.634510387537041

Epoch: 6| Step: 5
Training loss: 2.8499162494333374
Validation loss: 2.6328313814726867

Epoch: 6| Step: 6
Training loss: 2.4278333648362502
Validation loss: 2.6374172423990587

Epoch: 6| Step: 7
Training loss: 2.631687818333102
Validation loss: 2.6359957077896063

Epoch: 6| Step: 8
Training loss: 3.366895764805387
Validation loss: 2.6414525176568686

Epoch: 6| Step: 9
Training loss: 3.3060318757705347
Validation loss: 2.636978869928816

Epoch: 6| Step: 10
Training loss: 2.9424567100951022
Validation loss: 2.629556877645336

Epoch: 6| Step: 11
Training loss: 3.570853361402243
Validation loss: 2.6344091540552212

Epoch: 6| Step: 12
Training loss: 2.3209402346232166
Validation loss: 2.6305417124415493

Epoch: 6| Step: 13
Training loss: 3.218508220591587
Validation loss: 2.6305150890700397

Epoch: 328| Step: 0
Training loss: 2.941260669849398
Validation loss: 2.635295336105047

Epoch: 6| Step: 1
Training loss: 3.377766358484519
Validation loss: 2.6284608971871917

Epoch: 6| Step: 2
Training loss: 3.151243261188594
Validation loss: 2.6311633804425556

Epoch: 6| Step: 3
Training loss: 2.8521087541322734
Validation loss: 2.633287049828251

Epoch: 6| Step: 4
Training loss: 2.8398286380916695
Validation loss: 2.628742011940519

Epoch: 6| Step: 5
Training loss: 2.133880124451363
Validation loss: 2.6239911595565037

Epoch: 6| Step: 6
Training loss: 3.1248397786075004
Validation loss: 2.6305370773941195

Epoch: 6| Step: 7
Training loss: 2.5899671982562276
Validation loss: 2.6279201662490896

Epoch: 6| Step: 8
Training loss: 3.3887693891318844
Validation loss: 2.624519860909632

Epoch: 6| Step: 9
Training loss: 2.891017412922954
Validation loss: 2.6248583660209324

Epoch: 6| Step: 10
Training loss: 3.2323593271894073
Validation loss: 2.6325418776190865

Epoch: 6| Step: 11
Training loss: 2.955056825146303
Validation loss: 2.6235222238577913

Epoch: 6| Step: 12
Training loss: 3.0797441745383702
Validation loss: 2.62431120149001

Epoch: 6| Step: 13
Training loss: 2.3993998532152014
Validation loss: 2.627193354948751

Epoch: 329| Step: 0
Training loss: 2.967717041202801
Validation loss: 2.6311479405611604

Epoch: 6| Step: 1
Training loss: 2.2140988235886074
Validation loss: 2.6287117034193286

Epoch: 6| Step: 2
Training loss: 3.1535100847297426
Validation loss: 2.634080610351761

Epoch: 6| Step: 3
Training loss: 2.918438691031653
Validation loss: 2.656174212634683

Epoch: 6| Step: 4
Training loss: 2.9757399336074077
Validation loss: 2.653574914528119

Epoch: 6| Step: 5
Training loss: 2.747053388373258
Validation loss: 2.665767745689793

Epoch: 6| Step: 6
Training loss: 2.667372451206811
Validation loss: 2.6837675595348713

Epoch: 6| Step: 7
Training loss: 2.822434575392855
Validation loss: 2.69732756665822

Epoch: 6| Step: 8
Training loss: 3.150223218486897
Validation loss: 2.7016142365328824

Epoch: 6| Step: 9
Training loss: 3.208912157301344
Validation loss: 2.701692718480255

Epoch: 6| Step: 10
Training loss: 3.2708615020381306
Validation loss: 2.658566043687417

Epoch: 6| Step: 11
Training loss: 3.2504342595992557
Validation loss: 2.6379465663367365

Epoch: 6| Step: 12
Training loss: 2.7183154405589325
Validation loss: 2.6245555306069037

Epoch: 6| Step: 13
Training loss: 3.518060544159325
Validation loss: 2.619460204536697

Epoch: 330| Step: 0
Training loss: 2.8121311369715065
Validation loss: 2.6151169946146293

Epoch: 6| Step: 1
Training loss: 2.6248609415187674
Validation loss: 2.616965791252569

Epoch: 6| Step: 2
Training loss: 3.353947144584934
Validation loss: 2.617419627044074

Epoch: 6| Step: 3
Training loss: 3.0260047757148247
Validation loss: 2.624032728643872

Epoch: 6| Step: 4
Training loss: 2.9754790489396346
Validation loss: 2.6222219812284044

Epoch: 6| Step: 5
Training loss: 2.907330711992787
Validation loss: 2.616954418781097

Epoch: 6| Step: 6
Training loss: 2.5888137725534452
Validation loss: 2.615493577400391

Epoch: 6| Step: 7
Training loss: 2.9961590019988575
Validation loss: 2.614174682492343

Epoch: 6| Step: 8
Training loss: 2.656671109197804
Validation loss: 2.6157218207241137

Epoch: 6| Step: 9
Training loss: 3.20818870185407
Validation loss: 2.6224213771103706

Epoch: 6| Step: 10
Training loss: 3.3887751582783205
Validation loss: 2.622372397673376

Epoch: 6| Step: 11
Training loss: 2.6435095927997163
Validation loss: 2.616820943083286

Epoch: 6| Step: 12
Training loss: 3.136697467432469
Validation loss: 2.618031097937913

Epoch: 6| Step: 13
Training loss: 3.178712437595652
Validation loss: 2.621268222992015

Epoch: 331| Step: 0
Training loss: 3.071860197541904
Validation loss: 2.6210316480003293

Epoch: 6| Step: 1
Training loss: 2.5523817757213405
Validation loss: 2.6260212475754368

Epoch: 6| Step: 2
Training loss: 2.6916710179375434
Validation loss: 2.627108380069957

Epoch: 6| Step: 3
Training loss: 2.8279414670624976
Validation loss: 2.6287250076919126

Epoch: 6| Step: 4
Training loss: 3.5434012858734323
Validation loss: 2.6382268549785874

Epoch: 6| Step: 5
Training loss: 3.019733061961426
Validation loss: 2.6365450796937537

Epoch: 6| Step: 6
Training loss: 2.6389505167228724
Validation loss: 2.6456405463475026

Epoch: 6| Step: 7
Training loss: 2.6682023355263196
Validation loss: 2.6576205969557476

Epoch: 6| Step: 8
Training loss: 3.337906624815369
Validation loss: 2.664967344138198

Epoch: 6| Step: 9
Training loss: 2.359650955735626
Validation loss: 2.6651093129554932

Epoch: 6| Step: 10
Training loss: 3.3914147085819417
Validation loss: 2.6574583254953263

Epoch: 6| Step: 11
Training loss: 2.9028998313281664
Validation loss: 2.6278263108183926

Epoch: 6| Step: 12
Training loss: 3.388876468517563
Validation loss: 2.617187829125521

Epoch: 6| Step: 13
Training loss: 2.786820052487036
Validation loss: 2.615299583830952

Epoch: 332| Step: 0
Training loss: 2.14582293856674
Validation loss: 2.613481494774243

Epoch: 6| Step: 1
Training loss: 3.1969063288401833
Validation loss: 2.6189852695663918

Epoch: 6| Step: 2
Training loss: 3.873774673171616
Validation loss: 2.622341907995777

Epoch: 6| Step: 3
Training loss: 2.9009922829242303
Validation loss: 2.6138717116984336

Epoch: 6| Step: 4
Training loss: 3.0961504014420247
Validation loss: 2.616646169636147

Epoch: 6| Step: 5
Training loss: 3.0542432066801357
Validation loss: 2.621511891044432

Epoch: 6| Step: 6
Training loss: 2.8974777236621945
Validation loss: 2.623160694967826

Epoch: 6| Step: 7
Training loss: 2.5977613384816944
Validation loss: 2.6182865328785767

Epoch: 6| Step: 8
Training loss: 2.764274569193585
Validation loss: 2.616681291225686

Epoch: 6| Step: 9
Training loss: 3.1331474905159924
Validation loss: 2.6101236549687172

Epoch: 6| Step: 10
Training loss: 2.384988960224568
Validation loss: 2.6153764164546054

Epoch: 6| Step: 11
Training loss: 2.9192826301728823
Validation loss: 2.6172041070736

Epoch: 6| Step: 12
Training loss: 3.1023867494383772
Validation loss: 2.617756530485942

Epoch: 6| Step: 13
Training loss: 3.314410252650685
Validation loss: 2.6216822751559516

Epoch: 333| Step: 0
Training loss: 2.920460731005924
Validation loss: 2.61911455720642

Epoch: 6| Step: 1
Training loss: 3.045064065193508
Validation loss: 2.6480448001522063

Epoch: 6| Step: 2
Training loss: 2.1760624099504846
Validation loss: 2.6403912108667202

Epoch: 6| Step: 3
Training loss: 3.2650551914848824
Validation loss: 2.6620314489346297

Epoch: 6| Step: 4
Training loss: 3.213435405703438
Validation loss: 2.6829162975862224

Epoch: 6| Step: 5
Training loss: 3.658359929526126
Validation loss: 2.683701072135407

Epoch: 6| Step: 6
Training loss: 2.830610837220827
Validation loss: 2.6540620753057067

Epoch: 6| Step: 7
Training loss: 3.0437479258066116
Validation loss: 2.645052071599295

Epoch: 6| Step: 8
Training loss: 2.769453168664181
Validation loss: 2.64360152504761

Epoch: 6| Step: 9
Training loss: 2.998124808127958
Validation loss: 2.6519207007867425

Epoch: 6| Step: 10
Training loss: 2.4858982047110842
Validation loss: 2.6409298436309503

Epoch: 6| Step: 11
Training loss: 3.0757207630538037
Validation loss: 2.6420383320274565

Epoch: 6| Step: 12
Training loss: 3.1016521296774586
Validation loss: 2.633598395593206

Epoch: 6| Step: 13
Training loss: 2.3550350871782824
Validation loss: 2.6262486452627063

Epoch: 334| Step: 0
Training loss: 2.5412222260000212
Validation loss: 2.6241876074603847

Epoch: 6| Step: 1
Training loss: 2.9082160780331923
Validation loss: 2.6215639454473374

Epoch: 6| Step: 2
Training loss: 3.1230306905263876
Validation loss: 2.6199145573975544

Epoch: 6| Step: 3
Training loss: 2.72233625635923
Validation loss: 2.622099367131493

Epoch: 6| Step: 4
Training loss: 2.481906071941274
Validation loss: 2.6209977535552063

Epoch: 6| Step: 5
Training loss: 2.968297020334679
Validation loss: 2.620235639291379

Epoch: 6| Step: 6
Training loss: 2.976496818398522
Validation loss: 2.6198251631135827

Epoch: 6| Step: 7
Training loss: 2.8205060813174176
Validation loss: 2.617474520915467

Epoch: 6| Step: 8
Training loss: 3.8026825872420598
Validation loss: 2.615778151722849

Epoch: 6| Step: 9
Training loss: 2.7783445977354697
Validation loss: 2.61158469655249

Epoch: 6| Step: 10
Training loss: 2.7991369892927107
Validation loss: 2.609307720360104

Epoch: 6| Step: 11
Training loss: 3.4323392101616763
Validation loss: 2.6154000729435505

Epoch: 6| Step: 12
Training loss: 3.229527623501535
Validation loss: 2.611789075207513

Epoch: 6| Step: 13
Training loss: 2.0581985470685944
Validation loss: 2.610481457452533

Epoch: 335| Step: 0
Training loss: 2.598945378110063
Validation loss: 2.6118117983374565

Epoch: 6| Step: 1
Training loss: 2.4632850712275607
Validation loss: 2.6157735022758093

Epoch: 6| Step: 2
Training loss: 2.839082177639309
Validation loss: 2.613302459230971

Epoch: 6| Step: 3
Training loss: 3.2186985937661525
Validation loss: 2.6202397485715005

Epoch: 6| Step: 4
Training loss: 3.5626228712877346
Validation loss: 2.6218558074562774

Epoch: 6| Step: 5
Training loss: 2.961330095901105
Validation loss: 2.618715478695648

Epoch: 6| Step: 6
Training loss: 2.7004074813513115
Validation loss: 2.621589879361132

Epoch: 6| Step: 7
Training loss: 3.1482327302361983
Validation loss: 2.6246827495886866

Epoch: 6| Step: 8
Training loss: 3.323754247897254
Validation loss: 2.6323981407096744

Epoch: 6| Step: 9
Training loss: 2.7307973944967134
Validation loss: 2.6358192762452934

Epoch: 6| Step: 10
Training loss: 2.5766365147052377
Validation loss: 2.6338620347355928

Epoch: 6| Step: 11
Training loss: 2.8331796567042984
Validation loss: 2.6344109796593265

Epoch: 6| Step: 12
Training loss: 3.3843177459467046
Validation loss: 2.63010653300103

Epoch: 6| Step: 13
Training loss: 2.460257978325804
Validation loss: 2.64159892374385

Epoch: 336| Step: 0
Training loss: 2.7696012372426795
Validation loss: 2.6412080006025747

Epoch: 6| Step: 1
Training loss: 2.6604462632156296
Validation loss: 2.631458717170341

Epoch: 6| Step: 2
Training loss: 3.0225791008303435
Validation loss: 2.623106864192094

Epoch: 6| Step: 3
Training loss: 3.594961211057609
Validation loss: 2.618944378019115

Epoch: 6| Step: 4
Training loss: 2.8643353904001416
Validation loss: 2.625576336901485

Epoch: 6| Step: 5
Training loss: 3.245614393993012
Validation loss: 2.612088975162536

Epoch: 6| Step: 6
Training loss: 2.8150805185026373
Validation loss: 2.6155956194376175

Epoch: 6| Step: 7
Training loss: 3.053954053471953
Validation loss: 2.6168357665417616

Epoch: 6| Step: 8
Training loss: 3.0183592738934886
Validation loss: 2.6134710713984624

Epoch: 6| Step: 9
Training loss: 2.5684022617022984
Validation loss: 2.614237871149571

Epoch: 6| Step: 10
Training loss: 2.5295741809253585
Validation loss: 2.611943665150329

Epoch: 6| Step: 11
Training loss: 3.4830703003300143
Validation loss: 2.620519731913533

Epoch: 6| Step: 12
Training loss: 2.293591078572108
Validation loss: 2.6122201076336222

Epoch: 6| Step: 13
Training loss: 3.2083926174747086
Validation loss: 2.615808061269105

Epoch: 337| Step: 0
Training loss: 3.0223347232330595
Validation loss: 2.61171862243238

Epoch: 6| Step: 1
Training loss: 2.439039771043151
Validation loss: 2.6188159845522607

Epoch: 6| Step: 2
Training loss: 2.8307408832961483
Validation loss: 2.612767980229716

Epoch: 6| Step: 3
Training loss: 3.335276196436894
Validation loss: 2.61556221813401

Epoch: 6| Step: 4
Training loss: 3.0034430137982957
Validation loss: 2.6208653132615085

Epoch: 6| Step: 5
Training loss: 3.0849244591662544
Validation loss: 2.620406197372727

Epoch: 6| Step: 6
Training loss: 2.4502087406841087
Validation loss: 2.6152868650899195

Epoch: 6| Step: 7
Training loss: 3.540444346412459
Validation loss: 2.623621346629094

Epoch: 6| Step: 8
Training loss: 2.855160802264403
Validation loss: 2.6307628325288674

Epoch: 6| Step: 9
Training loss: 3.179693348572247
Validation loss: 2.6293373312149817

Epoch: 6| Step: 10
Training loss: 2.856823893181523
Validation loss: 2.6301270636340197

Epoch: 6| Step: 11
Training loss: 2.663812888525022
Validation loss: 2.6307422025867155

Epoch: 6| Step: 12
Training loss: 3.077051585521591
Validation loss: 2.6305695849262896

Epoch: 6| Step: 13
Training loss: 2.489062607280875
Validation loss: 2.6342199198243716

Epoch: 338| Step: 0
Training loss: 2.196384480440342
Validation loss: 2.628348405022437

Epoch: 6| Step: 1
Training loss: 2.6310877371657644
Validation loss: 2.6362326456109617

Epoch: 6| Step: 2
Training loss: 2.9075370317824887
Validation loss: 2.6453594693898776

Epoch: 6| Step: 3
Training loss: 3.09151215968362
Validation loss: 2.6404669046207325

Epoch: 6| Step: 4
Training loss: 3.3405595335866303
Validation loss: 2.659839130269335

Epoch: 6| Step: 5
Training loss: 3.2305109650922184
Validation loss: 2.6751503151664178

Epoch: 6| Step: 6
Training loss: 2.3513319339702967
Validation loss: 2.672253344742054

Epoch: 6| Step: 7
Training loss: 2.865591826501688
Validation loss: 2.6644878972228483

Epoch: 6| Step: 8
Training loss: 3.2084033182280858
Validation loss: 2.630874137874453

Epoch: 6| Step: 9
Training loss: 3.1303943614722733
Validation loss: 2.625951730187154

Epoch: 6| Step: 10
Training loss: 2.9153922066764877
Validation loss: 2.620723506695441

Epoch: 6| Step: 11
Training loss: 2.965505011073683
Validation loss: 2.608976865648736

Epoch: 6| Step: 12
Training loss: 2.9857356779279955
Validation loss: 2.607736818131414

Epoch: 6| Step: 13
Training loss: 3.259138464094032
Validation loss: 2.6073760570583766

Epoch: 339| Step: 0
Training loss: 2.7104860309127576
Validation loss: 2.617074366527084

Epoch: 6| Step: 1
Training loss: 2.774974816010442
Validation loss: 2.614943722949694

Epoch: 6| Step: 2
Training loss: 3.5166355969350676
Validation loss: 2.6095683396052323

Epoch: 6| Step: 3
Training loss: 2.380052112040884
Validation loss: 2.615865715418711

Epoch: 6| Step: 4
Training loss: 3.0975925203288233
Validation loss: 2.609486506344629

Epoch: 6| Step: 5
Training loss: 2.6028146107647108
Validation loss: 2.613983205699583

Epoch: 6| Step: 6
Training loss: 3.383589939352218
Validation loss: 2.6162462746293254

Epoch: 6| Step: 7
Training loss: 3.6081844860032004
Validation loss: 2.615548392115981

Epoch: 6| Step: 8
Training loss: 2.9309186866124723
Validation loss: 2.614317515022922

Epoch: 6| Step: 9
Training loss: 2.975093128445697
Validation loss: 2.614944939601992

Epoch: 6| Step: 10
Training loss: 2.639600205060174
Validation loss: 2.617766180760123

Epoch: 6| Step: 11
Training loss: 2.540892519596722
Validation loss: 2.625911660789011

Epoch: 6| Step: 12
Training loss: 3.3468801517963382
Validation loss: 2.6223838062823

Epoch: 6| Step: 13
Training loss: 2.430493874145648
Validation loss: 2.624584846364932

Epoch: 340| Step: 0
Training loss: 3.147842237365585
Validation loss: 2.625133174090511

Epoch: 6| Step: 1
Training loss: 2.9792388338182394
Validation loss: 2.6391237344031273

Epoch: 6| Step: 2
Training loss: 3.340462325072242
Validation loss: 2.6361050786220503

Epoch: 6| Step: 3
Training loss: 3.2132007947736754
Validation loss: 2.63320216255505

Epoch: 6| Step: 4
Training loss: 3.3277521775297076
Validation loss: 2.635503380739224

Epoch: 6| Step: 5
Training loss: 2.447132542333687
Validation loss: 2.6415898923650425

Epoch: 6| Step: 6
Training loss: 2.734957213407091
Validation loss: 2.664446589820766

Epoch: 6| Step: 7
Training loss: 3.0200586487588876
Validation loss: 2.6676095159662303

Epoch: 6| Step: 8
Training loss: 3.504530562936031
Validation loss: 2.6625268190989635

Epoch: 6| Step: 9
Training loss: 2.894031393981514
Validation loss: 2.6464653962265365

Epoch: 6| Step: 10
Training loss: 2.23502879147685
Validation loss: 2.6427877139441973

Epoch: 6| Step: 11
Training loss: 2.80876649370431
Validation loss: 2.623768233748318

Epoch: 6| Step: 12
Training loss: 2.739550939641589
Validation loss: 2.63427286660609

Epoch: 6| Step: 13
Training loss: 2.4424815991117543
Validation loss: 2.6125360698656306

Epoch: 341| Step: 0
Training loss: 3.174335746665143
Validation loss: 2.6087956980719618

Epoch: 6| Step: 1
Training loss: 3.2798400756181483
Validation loss: 2.6103082404846454

Epoch: 6| Step: 2
Training loss: 2.9851383211685163
Validation loss: 2.6104615952815307

Epoch: 6| Step: 3
Training loss: 2.892545814514007
Validation loss: 2.6166323787380508

Epoch: 6| Step: 4
Training loss: 3.0645505307376375
Validation loss: 2.6120739078639406

Epoch: 6| Step: 5
Training loss: 3.490212242427727
Validation loss: 2.617557405090955

Epoch: 6| Step: 6
Training loss: 2.5825613057780075
Validation loss: 2.616085429116702

Epoch: 6| Step: 7
Training loss: 3.104515687578168
Validation loss: 2.616783719971409

Epoch: 6| Step: 8
Training loss: 2.7425532518222524
Validation loss: 2.6170245386018083

Epoch: 6| Step: 9
Training loss: 3.204545761983969
Validation loss: 2.630536453669704

Epoch: 6| Step: 10
Training loss: 2.736937624503855
Validation loss: 2.6350603045499263

Epoch: 6| Step: 11
Training loss: 2.452279109048217
Validation loss: 2.6301388518859232

Epoch: 6| Step: 12
Training loss: 2.483674052459107
Validation loss: 2.634806006352071

Epoch: 6| Step: 13
Training loss: 2.568497129742053
Validation loss: 2.645743188217841

Epoch: 342| Step: 0
Training loss: 2.651527874821113
Validation loss: 2.6426714458437055

Epoch: 6| Step: 1
Training loss: 2.8865598394817975
Validation loss: 2.669653342527602

Epoch: 6| Step: 2
Training loss: 2.916147421983869
Validation loss: 2.679927978134067

Epoch: 6| Step: 3
Training loss: 3.0101003689681525
Validation loss: 2.695984076031744

Epoch: 6| Step: 4
Training loss: 2.789761324829011
Validation loss: 2.6720266298538164

Epoch: 6| Step: 5
Training loss: 2.946299744138741
Validation loss: 2.643994438813701

Epoch: 6| Step: 6
Training loss: 2.93472938550765
Validation loss: 2.6451449165180114

Epoch: 6| Step: 7
Training loss: 3.186071487161151
Validation loss: 2.622380369040825

Epoch: 6| Step: 8
Training loss: 3.2884854424380463
Validation loss: 2.6132983429663037

Epoch: 6| Step: 9
Training loss: 3.484068989680531
Validation loss: 2.6082118129273604

Epoch: 6| Step: 10
Training loss: 3.223724373179028
Validation loss: 2.6077504909147398

Epoch: 6| Step: 11
Training loss: 2.6045147981009076
Validation loss: 2.600382943858262

Epoch: 6| Step: 12
Training loss: 2.4521604937975225
Validation loss: 2.6025055054455892

Epoch: 6| Step: 13
Training loss: 2.7033622505281394
Validation loss: 2.604070386193754

Epoch: 343| Step: 0
Training loss: 2.939188857254811
Validation loss: 2.602921813402322

Epoch: 6| Step: 1
Training loss: 3.505509127917177
Validation loss: 2.60673166532255

Epoch: 6| Step: 2
Training loss: 2.9843948123933326
Validation loss: 2.607247464606078

Epoch: 6| Step: 3
Training loss: 2.5545622535358072
Validation loss: 2.602611860887718

Epoch: 6| Step: 4
Training loss: 3.092389048233544
Validation loss: 2.6058022302781154

Epoch: 6| Step: 5
Training loss: 3.2408479795928495
Validation loss: 2.6061082718557262

Epoch: 6| Step: 6
Training loss: 2.5680983262058956
Validation loss: 2.614014050314015

Epoch: 6| Step: 7
Training loss: 3.145022222443442
Validation loss: 2.6108969904840857

Epoch: 6| Step: 8
Training loss: 2.879771709401042
Validation loss: 2.6199998272395786

Epoch: 6| Step: 9
Training loss: 3.0844118620458265
Validation loss: 2.6271073808083623

Epoch: 6| Step: 10
Training loss: 2.700865048892503
Validation loss: 2.623683640403974

Epoch: 6| Step: 11
Training loss: 2.8844874202026136
Validation loss: 2.61941895045281

Epoch: 6| Step: 12
Training loss: 2.6614040859439587
Validation loss: 2.636005415290954

Epoch: 6| Step: 13
Training loss: 2.7801119586986367
Validation loss: 2.622310657370294

Epoch: 344| Step: 0
Training loss: 2.741867785821471
Validation loss: 2.6326359466629112

Epoch: 6| Step: 1
Training loss: 2.818565017483539
Validation loss: 2.6249218585820544

Epoch: 6| Step: 2
Training loss: 2.9038009989837836
Validation loss: 2.62737040281391

Epoch: 6| Step: 3
Training loss: 2.84314847180499
Validation loss: 2.6346601257727937

Epoch: 6| Step: 4
Training loss: 2.4220304377727797
Validation loss: 2.634540037710738

Epoch: 6| Step: 5
Training loss: 2.483038968896205
Validation loss: 2.626051534431837

Epoch: 6| Step: 6
Training loss: 2.705635624805437
Validation loss: 2.6183693140011663

Epoch: 6| Step: 7
Training loss: 3.3210016231102153
Validation loss: 2.6157766492780716

Epoch: 6| Step: 8
Training loss: 3.056315346859791
Validation loss: 2.6163036349596096

Epoch: 6| Step: 9
Training loss: 3.369639059597893
Validation loss: 2.6123124599484915

Epoch: 6| Step: 10
Training loss: 3.082631641308857
Validation loss: 2.616096580957512

Epoch: 6| Step: 11
Training loss: 3.2932366276904417
Validation loss: 2.6181567803658536

Epoch: 6| Step: 12
Training loss: 3.2563974065236367
Validation loss: 2.6117675071916233

Epoch: 6| Step: 13
Training loss: 2.415582567165516
Validation loss: 2.620516119068616

Epoch: 345| Step: 0
Training loss: 3.307874509061702
Validation loss: 2.6092556719887594

Epoch: 6| Step: 1
Training loss: 2.8317044194492507
Validation loss: 2.609497654948661

Epoch: 6| Step: 2
Training loss: 3.0027899484763183
Validation loss: 2.61964128341085

Epoch: 6| Step: 3
Training loss: 2.789415866040462
Validation loss: 2.6241132339045086

Epoch: 6| Step: 4
Training loss: 2.62735624375607
Validation loss: 2.6110732493917013

Epoch: 6| Step: 5
Training loss: 2.883615273452422
Validation loss: 2.622616886886007

Epoch: 6| Step: 6
Training loss: 3.1138956763127092
Validation loss: 2.635868958959862

Epoch: 6| Step: 7
Training loss: 3.3664776613669103
Validation loss: 2.624396002211898

Epoch: 6| Step: 8
Training loss: 2.9391440802552555
Validation loss: 2.627899797875289

Epoch: 6| Step: 9
Training loss: 2.4107297341795335
Validation loss: 2.62067821184543

Epoch: 6| Step: 10
Training loss: 2.3556754304665177
Validation loss: 2.6261684895346065

Epoch: 6| Step: 11
Training loss: 3.5092903541418243
Validation loss: 2.6386152457681007

Epoch: 6| Step: 12
Training loss: 2.9433460906095372
Validation loss: 2.6313744879705383

Epoch: 6| Step: 13
Training loss: 2.6169159250131915
Validation loss: 2.6333267237013205

Epoch: 346| Step: 0
Training loss: 2.6373980968007658
Validation loss: 2.63847193105362

Epoch: 6| Step: 1
Training loss: 2.6219576507744806
Validation loss: 2.619134216724089

Epoch: 6| Step: 2
Training loss: 3.2400524785065694
Validation loss: 2.6296770684850457

Epoch: 6| Step: 3
Training loss: 2.65723517604723
Validation loss: 2.614629274350421

Epoch: 6| Step: 4
Training loss: 3.1316140943509465
Validation loss: 2.623715152173429

Epoch: 6| Step: 5
Training loss: 2.69920011257246
Validation loss: 2.6151808354345407

Epoch: 6| Step: 6
Training loss: 3.4978342167352174
Validation loss: 2.608124362833649

Epoch: 6| Step: 7
Training loss: 3.0165059280425783
Validation loss: 2.6185948356388753

Epoch: 6| Step: 8
Training loss: 2.9641379419678957
Validation loss: 2.6239351397047086

Epoch: 6| Step: 9
Training loss: 2.6914138683106077
Validation loss: 2.604378196410987

Epoch: 6| Step: 10
Training loss: 2.9059159281699456
Validation loss: 2.6001015779769063

Epoch: 6| Step: 11
Training loss: 3.21300801813459
Validation loss: 2.61600803814761

Epoch: 6| Step: 12
Training loss: 2.8276008415284593
Validation loss: 2.616723095962268

Epoch: 6| Step: 13
Training loss: 2.6016490108551524
Validation loss: 2.6155944687571586

Epoch: 347| Step: 0
Training loss: 2.3505934432654367
Validation loss: 2.614174519701248

Epoch: 6| Step: 1
Training loss: 2.9708583372400525
Validation loss: 2.6133401056825147

Epoch: 6| Step: 2
Training loss: 3.5554565939111846
Validation loss: 2.6210107448637596

Epoch: 6| Step: 3
Training loss: 2.8302678373051178
Validation loss: 2.6243869126090322

Epoch: 6| Step: 4
Training loss: 2.815744181999124
Validation loss: 2.6238460533863033

Epoch: 6| Step: 5
Training loss: 2.5687966558298627
Validation loss: 2.619863251097664

Epoch: 6| Step: 6
Training loss: 3.4820195605907953
Validation loss: 2.6338622079899285

Epoch: 6| Step: 7
Training loss: 2.922396363443179
Validation loss: 2.6217485801327385

Epoch: 6| Step: 8
Training loss: 2.9899433375574525
Validation loss: 2.6268842510089487

Epoch: 6| Step: 9
Training loss: 3.088158689344861
Validation loss: 2.6101661383236414

Epoch: 6| Step: 10
Training loss: 2.7744191326456225
Validation loss: 2.616216121197282

Epoch: 6| Step: 11
Training loss: 3.081774721481108
Validation loss: 2.615527524550685

Epoch: 6| Step: 12
Training loss: 2.4921555472212025
Validation loss: 2.6280210087869293

Epoch: 6| Step: 13
Training loss: 2.8398783391763884
Validation loss: 2.629235960958259

Epoch: 348| Step: 0
Training loss: 2.945201436587181
Validation loss: 2.6326907209366497

Epoch: 6| Step: 1
Training loss: 3.1439943980781018
Validation loss: 2.633162730204602

Epoch: 6| Step: 2
Training loss: 2.4665263337949495
Validation loss: 2.6292996593302664

Epoch: 6| Step: 3
Training loss: 2.918226932813225
Validation loss: 2.6215135481369285

Epoch: 6| Step: 4
Training loss: 2.9770408105894415
Validation loss: 2.629405218611437

Epoch: 6| Step: 5
Training loss: 2.823107404470346
Validation loss: 2.6225781634222805

Epoch: 6| Step: 6
Training loss: 2.9581917384115
Validation loss: 2.6258215646479424

Epoch: 6| Step: 7
Training loss: 2.663629580585863
Validation loss: 2.618284946688893

Epoch: 6| Step: 8
Training loss: 3.017027533709322
Validation loss: 2.6294243331973592

Epoch: 6| Step: 9
Training loss: 2.5666866991161346
Validation loss: 2.6216456657433063

Epoch: 6| Step: 10
Training loss: 3.5167046139614726
Validation loss: 2.610449962706265

Epoch: 6| Step: 11
Training loss: 2.9929144153128897
Validation loss: 2.619411098284052

Epoch: 6| Step: 12
Training loss: 3.174140609616899
Validation loss: 2.605674101283703

Epoch: 6| Step: 13
Training loss: 2.5668871471116685
Validation loss: 2.607051477796872

Epoch: 349| Step: 0
Training loss: 2.7640039898171453
Validation loss: 2.607077231571658

Epoch: 6| Step: 1
Training loss: 3.1064508384696214
Validation loss: 2.624696060609226

Epoch: 6| Step: 2
Training loss: 3.1202215663781017
Validation loss: 2.6187595054874313

Epoch: 6| Step: 3
Training loss: 3.1252159044068804
Validation loss: 2.620694819298023

Epoch: 6| Step: 4
Training loss: 2.926625352827134
Validation loss: 2.6267168150938374

Epoch: 6| Step: 5
Training loss: 2.9369115037064066
Validation loss: 2.637516898065263

Epoch: 6| Step: 6
Training loss: 3.0260852979095962
Validation loss: 2.616178451946574

Epoch: 6| Step: 7
Training loss: 2.0187644461950462
Validation loss: 2.6223625707838103

Epoch: 6| Step: 8
Training loss: 3.508702358551629
Validation loss: 2.620890487213866

Epoch: 6| Step: 9
Training loss: 2.6752038931460094
Validation loss: 2.644409382394864

Epoch: 6| Step: 10
Training loss: 2.867970040200779
Validation loss: 2.6287518832484196

Epoch: 6| Step: 11
Training loss: 3.1762845061738654
Validation loss: 2.6085474437166174

Epoch: 6| Step: 12
Training loss: 2.7307325243936824
Validation loss: 2.610710434537837

Epoch: 6| Step: 13
Training loss: 2.7437357213511224
Validation loss: 2.614858995107003

Epoch: 350| Step: 0
Training loss: 3.233109821053135
Validation loss: 2.61254237559095

Epoch: 6| Step: 1
Training loss: 2.6391330996387135
Validation loss: 2.5974654061049534

Epoch: 6| Step: 2
Training loss: 3.1238976632426034
Validation loss: 2.602858285023672

Epoch: 6| Step: 3
Training loss: 3.1857142214436007
Validation loss: 2.6164407075136307

Epoch: 6| Step: 4
Training loss: 3.1173193576239493
Validation loss: 2.6032850628075503

Epoch: 6| Step: 5
Training loss: 3.1094397149947324
Validation loss: 2.6183403893229067

Epoch: 6| Step: 6
Training loss: 2.9513909632856272
Validation loss: 2.6196651264677575

Epoch: 6| Step: 7
Training loss: 3.1566312956179425
Validation loss: 2.617760448771843

Epoch: 6| Step: 8
Training loss: 2.4244564941744726
Validation loss: 2.6175236390140575

Epoch: 6| Step: 9
Training loss: 2.446369564231824
Validation loss: 2.624673229256907

Epoch: 6| Step: 10
Training loss: 2.724376687672655
Validation loss: 2.608302939982683

Epoch: 6| Step: 11
Training loss: 2.874425416003687
Validation loss: 2.6199432562740785

Epoch: 6| Step: 12
Training loss: 3.0659400148141316
Validation loss: 2.614102830813482

Epoch: 6| Step: 13
Training loss: 2.7924426883837232
Validation loss: 2.622121756488909

Epoch: 351| Step: 0
Training loss: 2.569910452800369
Validation loss: 2.6164314795536723

Epoch: 6| Step: 1
Training loss: 3.07602414699844
Validation loss: 2.6229148802642483

Epoch: 6| Step: 2
Training loss: 3.1144854850240966
Validation loss: 2.6391157475532023

Epoch: 6| Step: 3
Training loss: 2.8403251061593635
Validation loss: 2.6362535301593333

Epoch: 6| Step: 4
Training loss: 3.4857615632953816
Validation loss: 2.645359561455194

Epoch: 6| Step: 5
Training loss: 2.757241511468206
Validation loss: 2.6675551838391143

Epoch: 6| Step: 6
Training loss: 3.196170010958841
Validation loss: 2.670181180805732

Epoch: 6| Step: 7
Training loss: 2.693150457588107
Validation loss: 2.678880030116194

Epoch: 6| Step: 8
Training loss: 3.0047887093751338
Validation loss: 2.6579914973654217

Epoch: 6| Step: 9
Training loss: 2.8014778324402814
Validation loss: 2.664612479440433

Epoch: 6| Step: 10
Training loss: 2.8731515996273007
Validation loss: 2.658161480752154

Epoch: 6| Step: 11
Training loss: 3.365701086234469
Validation loss: 2.6449191385972695

Epoch: 6| Step: 12
Training loss: 2.489822844365776
Validation loss: 2.607520230422963

Epoch: 6| Step: 13
Training loss: 2.431974849175605
Validation loss: 2.5991079885902373

Epoch: 352| Step: 0
Training loss: 2.699095793599654
Validation loss: 2.6003311309219375

Epoch: 6| Step: 1
Training loss: 2.581961995868241
Validation loss: 2.593696562553477

Epoch: 6| Step: 2
Training loss: 3.1899189465787665
Validation loss: 2.594605992658008

Epoch: 6| Step: 3
Training loss: 3.0676354149710443
Validation loss: 2.5909980084123823

Epoch: 6| Step: 4
Training loss: 3.1130992879305457
Validation loss: 2.5902144047224382

Epoch: 6| Step: 5
Training loss: 3.243418558640436
Validation loss: 2.592483874692379

Epoch: 6| Step: 6
Training loss: 2.583874943060231
Validation loss: 2.597705659929195

Epoch: 6| Step: 7
Training loss: 2.9556257367067635
Validation loss: 2.5981895524173124

Epoch: 6| Step: 8
Training loss: 3.0110156949336413
Validation loss: 2.5942925494717963

Epoch: 6| Step: 9
Training loss: 3.0895937349466327
Validation loss: 2.589458742275272

Epoch: 6| Step: 10
Training loss: 3.0782356048696005
Validation loss: 2.6005031798071956

Epoch: 6| Step: 11
Training loss: 2.7769842974857935
Validation loss: 2.587517648923738

Epoch: 6| Step: 12
Training loss: 2.7525267696897857
Validation loss: 2.5916830426830937

Epoch: 6| Step: 13
Training loss: 2.8674446011474073
Validation loss: 2.5874747709186003

Epoch: 353| Step: 0
Training loss: 3.1595995663787586
Validation loss: 2.592162981938318

Epoch: 6| Step: 1
Training loss: 2.8163955836418166
Validation loss: 2.5926607525571255

Epoch: 6| Step: 2
Training loss: 2.59529306862646
Validation loss: 2.593238076312888

Epoch: 6| Step: 3
Training loss: 3.155068355732678
Validation loss: 2.6045134879887337

Epoch: 6| Step: 4
Training loss: 3.152989884989127
Validation loss: 2.612834542818931

Epoch: 6| Step: 5
Training loss: 3.5577150300503813
Validation loss: 2.6220280288663433

Epoch: 6| Step: 6
Training loss: 3.0054337247865694
Validation loss: 2.6304843156331015

Epoch: 6| Step: 7
Training loss: 2.975602122689408
Validation loss: 2.629243507846532

Epoch: 6| Step: 8
Training loss: 2.992033234845156
Validation loss: 2.62841545184519

Epoch: 6| Step: 9
Training loss: 2.0767510253198367
Validation loss: 2.6224135554385777

Epoch: 6| Step: 10
Training loss: 2.8693890759408034
Validation loss: 2.628118179704771

Epoch: 6| Step: 11
Training loss: 2.7648842029571
Validation loss: 2.609898913058029

Epoch: 6| Step: 12
Training loss: 2.4419718094931757
Validation loss: 2.61633501808683

Epoch: 6| Step: 13
Training loss: 3.2868475262889483
Validation loss: 2.613913332850306

Epoch: 354| Step: 0
Training loss: 2.1145769191199926
Validation loss: 2.598040219553123

Epoch: 6| Step: 1
Training loss: 2.8224783318957467
Validation loss: 2.602611594930655

Epoch: 6| Step: 2
Training loss: 2.906709368097529
Validation loss: 2.6064276464069196

Epoch: 6| Step: 3
Training loss: 2.9295413374998
Validation loss: 2.5947525897691266

Epoch: 6| Step: 4
Training loss: 2.6862891374792772
Validation loss: 2.5929786453379826

Epoch: 6| Step: 5
Training loss: 2.6710603598655203
Validation loss: 2.589399643767822

Epoch: 6| Step: 6
Training loss: 3.4666986671829227
Validation loss: 2.593389864413317

Epoch: 6| Step: 7
Training loss: 3.4793996828059233
Validation loss: 2.5929412767079554

Epoch: 6| Step: 8
Training loss: 3.1295671277030177
Validation loss: 2.5922098124870403

Epoch: 6| Step: 9
Training loss: 2.6320686534693443
Validation loss: 2.593016441524139

Epoch: 6| Step: 10
Training loss: 2.502509478875957
Validation loss: 2.5892518713005463

Epoch: 6| Step: 11
Training loss: 3.1343418108170864
Validation loss: 2.5910684121464356

Epoch: 6| Step: 12
Training loss: 3.1847681044352854
Validation loss: 2.6078290628071565

Epoch: 6| Step: 13
Training loss: 3.1115245960605304
Validation loss: 2.6064138161950345

Epoch: 355| Step: 0
Training loss: 2.6631390265896875
Validation loss: 2.5919954434500627

Epoch: 6| Step: 1
Training loss: 2.4145546815723047
Validation loss: 2.5920008377811032

Epoch: 6| Step: 2
Training loss: 3.2428344081180156
Validation loss: 2.6051061396708803

Epoch: 6| Step: 3
Training loss: 2.5191226125136192
Validation loss: 2.6171656816283564

Epoch: 6| Step: 4
Training loss: 2.131542009054653
Validation loss: 2.6138136232058975

Epoch: 6| Step: 5
Training loss: 2.3550148395305666
Validation loss: 2.6101106959050924

Epoch: 6| Step: 6
Training loss: 3.170365599238819
Validation loss: 2.6090551284304007

Epoch: 6| Step: 7
Training loss: 3.2773978736964127
Validation loss: 2.6179769423366936

Epoch: 6| Step: 8
Training loss: 3.186373043924523
Validation loss: 2.6131666485048455

Epoch: 6| Step: 9
Training loss: 3.348002074283153
Validation loss: 2.61336638508776

Epoch: 6| Step: 10
Training loss: 3.4703120932821405
Validation loss: 2.614218351327781

Epoch: 6| Step: 11
Training loss: 2.930390215202489
Validation loss: 2.611694403514563

Epoch: 6| Step: 12
Training loss: 3.187961918889412
Validation loss: 2.6089653767954997

Epoch: 6| Step: 13
Training loss: 2.4329514735125812
Validation loss: 2.6114529362880896

Epoch: 356| Step: 0
Training loss: 2.967784041812249
Validation loss: 2.610154853105376

Epoch: 6| Step: 1
Training loss: 2.3473639536345345
Validation loss: 2.6091930082039942

Epoch: 6| Step: 2
Training loss: 3.877948254685153
Validation loss: 2.611408640037437

Epoch: 6| Step: 3
Training loss: 2.6910579993136836
Validation loss: 2.6148210440413098

Epoch: 6| Step: 4
Training loss: 3.1460247023692425
Validation loss: 2.619056731822015

Epoch: 6| Step: 5
Training loss: 2.5517462267723974
Validation loss: 2.6126868408294794

Epoch: 6| Step: 6
Training loss: 2.499224256322816
Validation loss: 2.6143464538108208

Epoch: 6| Step: 7
Training loss: 2.9272913378097534
Validation loss: 2.60433607932703

Epoch: 6| Step: 8
Training loss: 2.9669913453585632
Validation loss: 2.614722442619565

Epoch: 6| Step: 9
Training loss: 2.5097497605590524
Validation loss: 2.6133632489166985

Epoch: 6| Step: 10
Training loss: 3.0451755577053508
Validation loss: 2.612277358131337

Epoch: 6| Step: 11
Training loss: 3.2873957164164884
Validation loss: 2.633795657532847

Epoch: 6| Step: 12
Training loss: 3.226241199669111
Validation loss: 2.6036075259214333

Epoch: 6| Step: 13
Training loss: 2.142492551668233
Validation loss: 2.595263622024911

Epoch: 357| Step: 0
Training loss: 3.0572960684038977
Validation loss: 2.60428437063363

Epoch: 6| Step: 1
Training loss: 3.2733699090575508
Validation loss: 2.591568924426775

Epoch: 6| Step: 2
Training loss: 2.2824780020014126
Validation loss: 2.5851156353012645

Epoch: 6| Step: 3
Training loss: 2.8736137697004636
Validation loss: 2.5842714825843145

Epoch: 6| Step: 4
Training loss: 3.0044790845331195
Validation loss: 2.578803488808658

Epoch: 6| Step: 5
Training loss: 2.9878647457901675
Validation loss: 2.5825986300386665

Epoch: 6| Step: 6
Training loss: 2.6917895305767514
Validation loss: 2.5780845959611947

Epoch: 6| Step: 7
Training loss: 2.6320549755210356
Validation loss: 2.5871283402730616

Epoch: 6| Step: 8
Training loss: 3.241380117609395
Validation loss: 2.582846598333132

Epoch: 6| Step: 9
Training loss: 3.1205177205259083
Validation loss: 2.5895152931348586

Epoch: 6| Step: 10
Training loss: 2.8805601009805937
Validation loss: 2.5860012200132356

Epoch: 6| Step: 11
Training loss: 3.3139530090057763
Validation loss: 2.593902807754266

Epoch: 6| Step: 12
Training loss: 2.8591408555516753
Validation loss: 2.597738314811204

Epoch: 6| Step: 13
Training loss: 2.4339436728010293
Validation loss: 2.612679667064096

Epoch: 358| Step: 0
Training loss: 2.0662054818879434
Validation loss: 2.6003051545606786

Epoch: 6| Step: 1
Training loss: 2.50903670713561
Validation loss: 2.599691424504878

Epoch: 6| Step: 2
Training loss: 1.9839898283797677
Validation loss: 2.601924041515009

Epoch: 6| Step: 3
Training loss: 3.202697129864085
Validation loss: 2.617005386346745

Epoch: 6| Step: 4
Training loss: 2.5129625909937716
Validation loss: 2.613220593788549

Epoch: 6| Step: 5
Training loss: 2.2808848049538226
Validation loss: 2.6080788462237665

Epoch: 6| Step: 6
Training loss: 3.357046908598866
Validation loss: 2.62095847406634

Epoch: 6| Step: 7
Training loss: 3.2062261688358076
Validation loss: 2.619981045078652

Epoch: 6| Step: 8
Training loss: 2.9727694957280906
Validation loss: 2.6126816255991794

Epoch: 6| Step: 9
Training loss: 3.432034395539049
Validation loss: 2.6206414426472437

Epoch: 6| Step: 10
Training loss: 3.5134129325444103
Validation loss: 2.6259303497642645

Epoch: 6| Step: 11
Training loss: 3.459367038404061
Validation loss: 2.629691563079982

Epoch: 6| Step: 12
Training loss: 2.639730448689002
Validation loss: 2.6104946032295477

Epoch: 6| Step: 13
Training loss: 3.4216942587023493
Validation loss: 2.611386826395571

Epoch: 359| Step: 0
Training loss: 3.162416081577891
Validation loss: 2.601527433963721

Epoch: 6| Step: 1
Training loss: 3.278998483483562
Validation loss: 2.5939159930758944

Epoch: 6| Step: 2
Training loss: 2.85789259542326
Validation loss: 2.6048052379352717

Epoch: 6| Step: 3
Training loss: 2.4834700561708933
Validation loss: 2.6039095023550844

Epoch: 6| Step: 4
Training loss: 2.4176792347373293
Validation loss: 2.615816441721892

Epoch: 6| Step: 5
Training loss: 3.658517900357177
Validation loss: 2.6114644112525185

Epoch: 6| Step: 6
Training loss: 2.3030294370041213
Validation loss: 2.6101632934514174

Epoch: 6| Step: 7
Training loss: 3.2005804608312665
Validation loss: 2.6308796610196543

Epoch: 6| Step: 8
Training loss: 1.99486412799855
Validation loss: 2.6254694929475955

Epoch: 6| Step: 9
Training loss: 2.920600164215202
Validation loss: 2.617673634986969

Epoch: 6| Step: 10
Training loss: 3.200412699789608
Validation loss: 2.6012303053640697

Epoch: 6| Step: 11
Training loss: 3.2551106105123253
Validation loss: 2.590384149589092

Epoch: 6| Step: 12
Training loss: 3.0845931976035588
Validation loss: 2.590759855253887

Epoch: 6| Step: 13
Training loss: 2.3137119313575214
Validation loss: 2.6000534529748505

Epoch: 360| Step: 0
Training loss: 3.0306631877032797
Validation loss: 2.592891901556347

Epoch: 6| Step: 1
Training loss: 2.2034247444723913
Validation loss: 2.591160483444352

Epoch: 6| Step: 2
Training loss: 3.0190293461225286
Validation loss: 2.5951646845283016

Epoch: 6| Step: 3
Training loss: 3.0112845853764765
Validation loss: 2.599009249717384

Epoch: 6| Step: 4
Training loss: 2.884394018042327
Validation loss: 2.5932327280534024

Epoch: 6| Step: 5
Training loss: 3.6354563946816687
Validation loss: 2.5938912788201898

Epoch: 6| Step: 6
Training loss: 3.4690432037979715
Validation loss: 2.600768779002613

Epoch: 6| Step: 7
Training loss: 3.1498920119409886
Validation loss: 2.59734504927228

Epoch: 6| Step: 8
Training loss: 2.6873029592272677
Validation loss: 2.5916515509621574

Epoch: 6| Step: 9
Training loss: 2.985670677252495
Validation loss: 2.594970490103314

Epoch: 6| Step: 10
Training loss: 2.687169431715934
Validation loss: 2.6030196061161113

Epoch: 6| Step: 11
Training loss: 2.95314389177365
Validation loss: 2.6125462212320194

Epoch: 6| Step: 12
Training loss: 2.4141363731364858
Validation loss: 2.5861026463461623

Epoch: 6| Step: 13
Training loss: 1.8980609536065898
Validation loss: 2.602622022397225

Epoch: 361| Step: 0
Training loss: 2.478609701044088
Validation loss: 2.5999757405893362

Epoch: 6| Step: 1
Training loss: 2.9604382257573607
Validation loss: 2.611936231206763

Epoch: 6| Step: 2
Training loss: 2.8611669709844008
Validation loss: 2.6202202000813304

Epoch: 6| Step: 3
Training loss: 2.7655491360534135
Validation loss: 2.6100600317723814

Epoch: 6| Step: 4
Training loss: 2.9055542471959526
Validation loss: 2.6243688974213146

Epoch: 6| Step: 5
Training loss: 2.8224181876476697
Validation loss: 2.612313535527926

Epoch: 6| Step: 6
Training loss: 3.3677527712151534
Validation loss: 2.602995768169628

Epoch: 6| Step: 7
Training loss: 3.8268410534173114
Validation loss: 2.607497693567549

Epoch: 6| Step: 8
Training loss: 2.454673327059657
Validation loss: 2.5960547393784608

Epoch: 6| Step: 9
Training loss: 2.943680126227521
Validation loss: 2.589773556490825

Epoch: 6| Step: 10
Training loss: 3.1037231913655905
Validation loss: 2.577222364911144

Epoch: 6| Step: 11
Training loss: 2.760451483356984
Validation loss: 2.582510215336356

Epoch: 6| Step: 12
Training loss: 1.8763168161428403
Validation loss: 2.5801824539433196

Epoch: 6| Step: 13
Training loss: 3.629098876833878
Validation loss: 2.591638756722973

Epoch: 362| Step: 0
Training loss: 3.1026160615150076
Validation loss: 2.5932772784216054

Epoch: 6| Step: 1
Training loss: 2.7787926780179206
Validation loss: 2.5926557986302217

Epoch: 6| Step: 2
Training loss: 2.8532896898918905
Validation loss: 2.6004262429267984

Epoch: 6| Step: 3
Training loss: 3.0112693837303235
Validation loss: 2.5976731398418345

Epoch: 6| Step: 4
Training loss: 2.5223036542379527
Validation loss: 2.608550501158169

Epoch: 6| Step: 5
Training loss: 3.225159272984918
Validation loss: 2.603081646391688

Epoch: 6| Step: 6
Training loss: 3.052201686469571
Validation loss: 2.6201991212055895

Epoch: 6| Step: 7
Training loss: 3.501591456853996
Validation loss: 2.620669969219583

Epoch: 6| Step: 8
Training loss: 2.7806149732872383
Validation loss: 2.63338477506454

Epoch: 6| Step: 9
Training loss: 3.072999666461622
Validation loss: 2.625244487660811

Epoch: 6| Step: 10
Training loss: 2.697951376751838
Validation loss: 2.611436208214711

Epoch: 6| Step: 11
Training loss: 2.6176201761634013
Validation loss: 2.6086176214657257

Epoch: 6| Step: 12
Training loss: 2.2653823196401492
Validation loss: 2.6020845584552377

Epoch: 6| Step: 13
Training loss: 3.171718198912537
Validation loss: 2.607166265494923

Epoch: 363| Step: 0
Training loss: 2.8807989599067656
Validation loss: 2.5923440292636837

Epoch: 6| Step: 1
Training loss: 3.596366659479267
Validation loss: 2.5939586005481616

Epoch: 6| Step: 2
Training loss: 3.1705669844282713
Validation loss: 2.590338757708518

Epoch: 6| Step: 3
Training loss: 2.961250550321155
Validation loss: 2.5890578245192697

Epoch: 6| Step: 4
Training loss: 3.0679826511255603
Validation loss: 2.587328300468368

Epoch: 6| Step: 5
Training loss: 2.618527106584207
Validation loss: 2.5882753529134845

Epoch: 6| Step: 6
Training loss: 2.6206960362150737
Validation loss: 2.583057097698266

Epoch: 6| Step: 7
Training loss: 3.219043310930514
Validation loss: 2.595464484480139

Epoch: 6| Step: 8
Training loss: 2.7566584693144107
Validation loss: 2.586256269731659

Epoch: 6| Step: 9
Training loss: 2.7986217989742466
Validation loss: 2.6087635304591426

Epoch: 6| Step: 10
Training loss: 2.835401920576428
Validation loss: 2.6111875549558583

Epoch: 6| Step: 11
Training loss: 2.2367251114616575
Validation loss: 2.6165142164881323

Epoch: 6| Step: 12
Training loss: 2.8585345591307147
Validation loss: 2.61342387238867

Epoch: 6| Step: 13
Training loss: 3.063233579630993
Validation loss: 2.621370184980348

Epoch: 364| Step: 0
Training loss: 3.5595594617890174
Validation loss: 2.6156150103854965

Epoch: 6| Step: 1
Training loss: 2.6993771187768894
Validation loss: 2.642265189548542

Epoch: 6| Step: 2
Training loss: 2.5280925696783805
Validation loss: 2.6404760456687653

Epoch: 6| Step: 3
Training loss: 2.232880953145875
Validation loss: 2.648035688135984

Epoch: 6| Step: 4
Training loss: 2.906669012237909
Validation loss: 2.642029852327827

Epoch: 6| Step: 5
Training loss: 2.492956921660869
Validation loss: 2.6471714269347197

Epoch: 6| Step: 6
Training loss: 3.1263296731697694
Validation loss: 2.631826742090236

Epoch: 6| Step: 7
Training loss: 3.3669545387346353
Validation loss: 2.6250205617823035

Epoch: 6| Step: 8
Training loss: 2.4680086785323083
Validation loss: 2.621639935392047

Epoch: 6| Step: 9
Training loss: 3.01619466036047
Validation loss: 2.6079001161057986

Epoch: 6| Step: 10
Training loss: 2.694915388403331
Validation loss: 2.609379480073298

Epoch: 6| Step: 11
Training loss: 3.2137159962823008
Validation loss: 2.597129415164512

Epoch: 6| Step: 12
Training loss: 2.9534592212285515
Validation loss: 2.6023474920635805

Epoch: 6| Step: 13
Training loss: 3.3027658489223266
Validation loss: 2.5952153984185533

Epoch: 365| Step: 0
Training loss: 2.31858643317339
Validation loss: 2.5829932822286295

Epoch: 6| Step: 1
Training loss: 2.719255246975827
Validation loss: 2.597613333083027

Epoch: 6| Step: 2
Training loss: 2.9281460788745695
Validation loss: 2.5872931361404543

Epoch: 6| Step: 3
Training loss: 3.068982794918833
Validation loss: 2.598813510708175

Epoch: 6| Step: 4
Training loss: 2.8691783510432414
Validation loss: 2.5853139137031995

Epoch: 6| Step: 5
Training loss: 2.526893257190268
Validation loss: 2.585672136226056

Epoch: 6| Step: 6
Training loss: 3.2153165708270106
Validation loss: 2.5855836788876014

Epoch: 6| Step: 7
Training loss: 3.280535520240643
Validation loss: 2.593452599647872

Epoch: 6| Step: 8
Training loss: 2.7526553079166414
Validation loss: 2.602856108321158

Epoch: 6| Step: 9
Training loss: 2.6649886056967773
Validation loss: 2.613812931738506

Epoch: 6| Step: 10
Training loss: 3.4285888302452254
Validation loss: 2.619954279165867

Epoch: 6| Step: 11
Training loss: 3.3572170689969183
Validation loss: 2.61457710639602

Epoch: 6| Step: 12
Training loss: 2.891344465468126
Validation loss: 2.622691812144361

Epoch: 6| Step: 13
Training loss: 2.093228631083988
Validation loss: 2.615093142440943

Epoch: 366| Step: 0
Training loss: 2.882241293289252
Validation loss: 2.611102122026114

Epoch: 6| Step: 1
Training loss: 3.2711899354439815
Validation loss: 2.626223367460523

Epoch: 6| Step: 2
Training loss: 2.734364885583972
Validation loss: 2.626857179700425

Epoch: 6| Step: 3
Training loss: 2.1334885863594915
Validation loss: 2.6315387575473257

Epoch: 6| Step: 4
Training loss: 3.350916517911147
Validation loss: 2.6303317198336686

Epoch: 6| Step: 5
Training loss: 3.4827061235997756
Validation loss: 2.628145211686999

Epoch: 6| Step: 6
Training loss: 2.639511866958167
Validation loss: 2.611374155354412

Epoch: 6| Step: 7
Training loss: 2.569833357191499
Validation loss: 2.6239281500847076

Epoch: 6| Step: 8
Training loss: 2.6770777325008797
Validation loss: 2.594052833405612

Epoch: 6| Step: 9
Training loss: 3.261436587252755
Validation loss: 2.600261144601861

Epoch: 6| Step: 10
Training loss: 3.407886217134179
Validation loss: 2.6071169424301224

Epoch: 6| Step: 11
Training loss: 2.7800376907373336
Validation loss: 2.607134357039832

Epoch: 6| Step: 12
Training loss: 2.649695533679976
Validation loss: 2.60758156881357

Epoch: 6| Step: 13
Training loss: 2.454975766375051
Validation loss: 2.6076597574637153

Epoch: 367| Step: 0
Training loss: 3.0957025088721783
Validation loss: 2.6045172204778795

Epoch: 6| Step: 1
Training loss: 2.7745533592330136
Validation loss: 2.6147398614809627

Epoch: 6| Step: 2
Training loss: 3.498403457537307
Validation loss: 2.608009844374924

Epoch: 6| Step: 3
Training loss: 2.7006206929287933
Validation loss: 2.6224100918411786

Epoch: 6| Step: 4
Training loss: 2.8631876556795475
Validation loss: 2.6272675847161895

Epoch: 6| Step: 5
Training loss: 3.084551149727961
Validation loss: 2.6423924707876707

Epoch: 6| Step: 6
Training loss: 2.46696359247713
Validation loss: 2.6323926090638783

Epoch: 6| Step: 7
Training loss: 2.679546118918625
Validation loss: 2.6209203839026745

Epoch: 6| Step: 8
Training loss: 2.726034468535756
Validation loss: 2.6216229926454173

Epoch: 6| Step: 9
Training loss: 3.0859370364418166
Validation loss: 2.6196286571893137

Epoch: 6| Step: 10
Training loss: 2.868402956247462
Validation loss: 2.6016159222117694

Epoch: 6| Step: 11
Training loss: 2.815065697128646
Validation loss: 2.609085441264081

Epoch: 6| Step: 12
Training loss: 2.884046337046435
Validation loss: 2.610809776639494

Epoch: 6| Step: 13
Training loss: 3.289140351522592
Validation loss: 2.6150974970400345

Epoch: 368| Step: 0
Training loss: 2.344581253143937
Validation loss: 2.6300215625678325

Epoch: 6| Step: 1
Training loss: 2.878660939504072
Validation loss: 2.617393386375653

Epoch: 6| Step: 2
Training loss: 2.831523391963817
Validation loss: 2.6130429521639242

Epoch: 6| Step: 3
Training loss: 3.656365417223779
Validation loss: 2.6007174370526576

Epoch: 6| Step: 4
Training loss: 3.175616833699415
Validation loss: 2.6145846436291396

Epoch: 6| Step: 5
Training loss: 2.3348728164898724
Validation loss: 2.6038449948079143

Epoch: 6| Step: 6
Training loss: 2.909121827481432
Validation loss: 2.604603791661113

Epoch: 6| Step: 7
Training loss: 3.228907732682865
Validation loss: 2.595856507119097

Epoch: 6| Step: 8
Training loss: 2.418069717197286
Validation loss: 2.593393932206242

Epoch: 6| Step: 9
Training loss: 2.846370621354733
Validation loss: 2.600145829238953

Epoch: 6| Step: 10
Training loss: 2.7653656746356576
Validation loss: 2.590480839115121

Epoch: 6| Step: 11
Training loss: 3.0144110098943484
Validation loss: 2.5858067171277175

Epoch: 6| Step: 12
Training loss: 3.320508093963211
Validation loss: 2.5872688550461778

Epoch: 6| Step: 13
Training loss: 2.980412273946823
Validation loss: 2.590142445614543

Epoch: 369| Step: 0
Training loss: 2.7814967871055445
Validation loss: 2.5907587880430496

Epoch: 6| Step: 1
Training loss: 3.152926971296374
Validation loss: 2.5961746662446665

Epoch: 6| Step: 2
Training loss: 3.238124130357877
Validation loss: 2.586310621679648

Epoch: 6| Step: 3
Training loss: 2.289076248492202
Validation loss: 2.5905900662278287

Epoch: 6| Step: 4
Training loss: 2.4175596122137666
Validation loss: 2.593475475527671

Epoch: 6| Step: 5
Training loss: 3.0618170151804045
Validation loss: 2.608951226923834

Epoch: 6| Step: 6
Training loss: 2.571142369949173
Validation loss: 2.6060886704846085

Epoch: 6| Step: 7
Training loss: 3.118476161516437
Validation loss: 2.599717545055714

Epoch: 6| Step: 8
Training loss: 2.952196893726537
Validation loss: 2.596648931682707

Epoch: 6| Step: 9
Training loss: 3.0791103896460057
Validation loss: 2.5965733072735357

Epoch: 6| Step: 10
Training loss: 2.9388288373606812
Validation loss: 2.585665854205002

Epoch: 6| Step: 11
Training loss: 3.0131759581641426
Validation loss: 2.5911773285621513

Epoch: 6| Step: 12
Training loss: 2.774818184197441
Validation loss: 2.5939444992729896

Epoch: 6| Step: 13
Training loss: 3.2605857114671486
Validation loss: 2.5888571175696264

Epoch: 370| Step: 0
Training loss: 3.276240857754512
Validation loss: 2.590342578911117

Epoch: 6| Step: 1
Training loss: 2.6138448292821326
Validation loss: 2.5967600189654716

Epoch: 6| Step: 2
Training loss: 2.6780965547597813
Validation loss: 2.598446996543711

Epoch: 6| Step: 3
Training loss: 3.073980959622963
Validation loss: 2.6036109702228196

Epoch: 6| Step: 4
Training loss: 2.747605581849521
Validation loss: 2.587659833712475

Epoch: 6| Step: 5
Training loss: 2.9252280513186797
Validation loss: 2.597721913898928

Epoch: 6| Step: 6
Training loss: 3.2822984746008683
Validation loss: 2.608135341313971

Epoch: 6| Step: 7
Training loss: 1.89795769801698
Validation loss: 2.584357123956598

Epoch: 6| Step: 8
Training loss: 2.924812676063798
Validation loss: 2.5941389068801355

Epoch: 6| Step: 9
Training loss: 3.0482439144890026
Validation loss: 2.6033658384119676

Epoch: 6| Step: 10
Training loss: 3.0284221869453427
Validation loss: 2.5975646527203167

Epoch: 6| Step: 11
Training loss: 2.7027018662399853
Validation loss: 2.5889904417

Epoch: 6| Step: 12
Training loss: 2.818336957285886
Validation loss: 2.6016612020798324

Epoch: 6| Step: 13
Training loss: 3.584384823081434
Validation loss: 2.6094563475011876

Epoch: 371| Step: 0
Training loss: 2.3423616493431316
Validation loss: 2.5905580456338395

Epoch: 6| Step: 1
Training loss: 2.878488166089007
Validation loss: 2.5856823742219808

Epoch: 6| Step: 2
Training loss: 2.6336512828371648
Validation loss: 2.5843106738934667

Epoch: 6| Step: 3
Training loss: 3.006949323180844
Validation loss: 2.5709894727979257

Epoch: 6| Step: 4
Training loss: 2.697389725489581
Validation loss: 2.5698220594573735

Epoch: 6| Step: 5
Training loss: 2.96213847340605
Validation loss: 2.576729274797764

Epoch: 6| Step: 6
Training loss: 3.107272103163111
Validation loss: 2.575347698148173

Epoch: 6| Step: 7
Training loss: 3.1397807186849502
Validation loss: 2.5723046185155383

Epoch: 6| Step: 8
Training loss: 2.702681312089762
Validation loss: 2.5722089241346344

Epoch: 6| Step: 9
Training loss: 3.0078318409483686
Validation loss: 2.572001574759611

Epoch: 6| Step: 10
Training loss: 3.388934720533735
Validation loss: 2.5761793325362388

Epoch: 6| Step: 11
Training loss: 2.620295350411604
Validation loss: 2.5751743424291957

Epoch: 6| Step: 12
Training loss: 2.969952470289929
Validation loss: 2.572920013886556

Epoch: 6| Step: 13
Training loss: 3.1541326993845944
Validation loss: 2.575280686287181

Epoch: 372| Step: 0
Training loss: 3.9340349724615797
Validation loss: 2.5813048361103417

Epoch: 6| Step: 1
Training loss: 2.5822578365381705
Validation loss: 2.5920271377040436

Epoch: 6| Step: 2
Training loss: 3.172770106102741
Validation loss: 2.5971316475025583

Epoch: 6| Step: 3
Training loss: 3.008765448675999
Validation loss: 2.5894742104505326

Epoch: 6| Step: 4
Training loss: 2.24834572059305
Validation loss: 2.6044672891339578

Epoch: 6| Step: 5
Training loss: 2.9114517093553522
Validation loss: 2.6099708735936873

Epoch: 6| Step: 6
Training loss: 2.9929712927321326
Validation loss: 2.6187048881902264

Epoch: 6| Step: 7
Training loss: 2.4337391327711844
Validation loss: 2.62294602204229

Epoch: 6| Step: 8
Training loss: 2.8533421645815125
Validation loss: 2.6316245693813847

Epoch: 6| Step: 9
Training loss: 2.635824862947059
Validation loss: 2.617931269954982

Epoch: 6| Step: 10
Training loss: 3.2835115903949252
Validation loss: 2.636375193270473

Epoch: 6| Step: 11
Training loss: 2.655262931979723
Validation loss: 2.6235245387846216

Epoch: 6| Step: 12
Training loss: 2.810142037273796
Validation loss: 2.6258779289168235

Epoch: 6| Step: 13
Training loss: 2.8231860286863104
Validation loss: 2.613582228388894

Epoch: 373| Step: 0
Training loss: 3.5084937438778594
Validation loss: 2.6167488069641673

Epoch: 6| Step: 1
Training loss: 3.0396822025429
Validation loss: 2.5870093615777585

Epoch: 6| Step: 2
Training loss: 2.618561068254141
Validation loss: 2.584627544456903

Epoch: 6| Step: 3
Training loss: 3.1076328630347527
Validation loss: 2.587018567148355

Epoch: 6| Step: 4
Training loss: 2.1658996055633315
Validation loss: 2.5728218264066145

Epoch: 6| Step: 5
Training loss: 2.5649543731379114
Validation loss: 2.5784596514040494

Epoch: 6| Step: 6
Training loss: 2.904860461719803
Validation loss: 2.5720219163378255

Epoch: 6| Step: 7
Training loss: 3.2878795680245054
Validation loss: 2.5754937460490743

Epoch: 6| Step: 8
Training loss: 2.1796603730950874
Validation loss: 2.570866605061684

Epoch: 6| Step: 9
Training loss: 3.3147028669905763
Validation loss: 2.573022114289808

Epoch: 6| Step: 10
Training loss: 2.679146670380084
Validation loss: 2.581204496514584

Epoch: 6| Step: 11
Training loss: 2.564303531045948
Validation loss: 2.5789835534783876

Epoch: 6| Step: 12
Training loss: 3.177260913993117
Validation loss: 2.5921931422062268

Epoch: 6| Step: 13
Training loss: 3.3678191758587244
Validation loss: 2.5982516853298474

Epoch: 374| Step: 0
Training loss: 2.9045354235947105
Validation loss: 2.5848693832682588

Epoch: 6| Step: 1
Training loss: 3.056354818906459
Validation loss: 2.6087814411487398

Epoch: 6| Step: 2
Training loss: 2.5510683701346704
Validation loss: 2.601984554152392

Epoch: 6| Step: 3
Training loss: 3.146718353342681
Validation loss: 2.606212472614732

Epoch: 6| Step: 4
Training loss: 3.1535690554474285
Validation loss: 2.6484994791817558

Epoch: 6| Step: 5
Training loss: 2.9138162217374073
Validation loss: 2.660249422558326

Epoch: 6| Step: 6
Training loss: 3.407652120126372
Validation loss: 2.6824857538628626

Epoch: 6| Step: 7
Training loss: 2.3876096370748576
Validation loss: 2.6616355997984638

Epoch: 6| Step: 8
Training loss: 2.751363589599319
Validation loss: 2.6299285444202583

Epoch: 6| Step: 9
Training loss: 3.0452269180509153
Validation loss: 2.6056882310726674

Epoch: 6| Step: 10
Training loss: 2.513414537229347
Validation loss: 2.605048519990601

Epoch: 6| Step: 11
Training loss: 2.5847506378140572
Validation loss: 2.6067360968315687

Epoch: 6| Step: 12
Training loss: 3.0902404916254564
Validation loss: 2.588579001093189

Epoch: 6| Step: 13
Training loss: 2.9742028202144324
Validation loss: 2.587783879504642

Epoch: 375| Step: 0
Training loss: 3.532115188880387
Validation loss: 2.584059445182342

Epoch: 6| Step: 1
Training loss: 2.8942337192098244
Validation loss: 2.572540798451504

Epoch: 6| Step: 2
Training loss: 3.014766748872931
Validation loss: 2.5786213694987623

Epoch: 6| Step: 3
Training loss: 3.4205040820102566
Validation loss: 2.574195340485645

Epoch: 6| Step: 4
Training loss: 1.6695550526844245
Validation loss: 2.576925845671136

Epoch: 6| Step: 5
Training loss: 2.5675926775674425
Validation loss: 2.573785346677162

Epoch: 6| Step: 6
Training loss: 2.8881749672974513
Validation loss: 2.574754887722627

Epoch: 6| Step: 7
Training loss: 2.660481034000316
Validation loss: 2.5752715009760596

Epoch: 6| Step: 8
Training loss: 2.721924255135657
Validation loss: 2.574510921789377

Epoch: 6| Step: 9
Training loss: 3.3826303763402015
Validation loss: 2.593012800245612

Epoch: 6| Step: 10
Training loss: 2.6680059248874195
Validation loss: 2.5944555098726205

Epoch: 6| Step: 11
Training loss: 2.642971283057
Validation loss: 2.595069543671412

Epoch: 6| Step: 12
Training loss: 2.9423366255605825
Validation loss: 2.607791855858152

Epoch: 6| Step: 13
Training loss: 3.35311490899067
Validation loss: 2.611493955937022

Epoch: 376| Step: 0
Training loss: 3.1110824420909866
Validation loss: 2.613822908467315

Epoch: 6| Step: 1
Training loss: 2.167613287300401
Validation loss: 2.5999878242955377

Epoch: 6| Step: 2
Training loss: 2.32746847227646
Validation loss: 2.6098910538572357

Epoch: 6| Step: 3
Training loss: 3.051385446032472
Validation loss: 2.611212397097247

Epoch: 6| Step: 4
Training loss: 3.5050505573800272
Validation loss: 2.602379906453427

Epoch: 6| Step: 5
Training loss: 3.320067632285038
Validation loss: 2.6038320871993195

Epoch: 6| Step: 6
Training loss: 2.5860739496194594
Validation loss: 2.5911779864950484

Epoch: 6| Step: 7
Training loss: 2.6494723748420683
Validation loss: 2.589217038054359

Epoch: 6| Step: 8
Training loss: 3.591733416462937
Validation loss: 2.589948005281065

Epoch: 6| Step: 9
Training loss: 2.4584254446930576
Validation loss: 2.581402707878283

Epoch: 6| Step: 10
Training loss: 2.731253798981912
Validation loss: 2.579237007076382

Epoch: 6| Step: 11
Training loss: 3.2977999433793332
Validation loss: 2.581855130367805

Epoch: 6| Step: 12
Training loss: 2.8212002442805892
Validation loss: 2.586674507057026

Epoch: 6| Step: 13
Training loss: 2.1201829728753268
Validation loss: 2.5951576075413714

Epoch: 377| Step: 0
Training loss: 3.408528816816481
Validation loss: 2.589463031079667

Epoch: 6| Step: 1
Training loss: 3.1595879457515466
Validation loss: 2.603865121097859

Epoch: 6| Step: 2
Training loss: 2.696679164101492
Validation loss: 2.6041889457159817

Epoch: 6| Step: 3
Training loss: 3.0175936109028205
Validation loss: 2.600901299340415

Epoch: 6| Step: 4
Training loss: 2.5250901989830954
Validation loss: 2.6062775402749017

Epoch: 6| Step: 5
Training loss: 3.360509778360864
Validation loss: 2.6134050851485098

Epoch: 6| Step: 6
Training loss: 2.649571538871825
Validation loss: 2.6235860472742165

Epoch: 6| Step: 7
Training loss: 1.9432918364323974
Validation loss: 2.618388961490673

Epoch: 6| Step: 8
Training loss: 2.8549266462372564
Validation loss: 2.6200710710230832

Epoch: 6| Step: 9
Training loss: 2.6400884500771857
Validation loss: 2.609475599372032

Epoch: 6| Step: 10
Training loss: 3.1132754298290957
Validation loss: 2.608262516892323

Epoch: 6| Step: 11
Training loss: 3.0463437913333284
Validation loss: 2.612233668624998

Epoch: 6| Step: 12
Training loss: 2.974706676993204
Validation loss: 2.612350501922927

Epoch: 6| Step: 13
Training loss: 2.8734747116226655
Validation loss: 2.6115085416365615

Epoch: 378| Step: 0
Training loss: 2.5133867435531
Validation loss: 2.5870320328190526

Epoch: 6| Step: 1
Training loss: 2.5628024597306203
Validation loss: 2.5826092633835596

Epoch: 6| Step: 2
Training loss: 2.1668605962185996
Validation loss: 2.5770148538707525

Epoch: 6| Step: 3
Training loss: 2.9405793627320094
Validation loss: 2.569613278366701

Epoch: 6| Step: 4
Training loss: 3.1412958595823475
Validation loss: 2.5662806464222054

Epoch: 6| Step: 5
Training loss: 3.0057311944729412
Validation loss: 2.578434985863503

Epoch: 6| Step: 6
Training loss: 2.6274495276222978
Validation loss: 2.5796217117909026

Epoch: 6| Step: 7
Training loss: 3.1130150426298373
Validation loss: 2.5757371670244167

Epoch: 6| Step: 8
Training loss: 3.063704428985609
Validation loss: 2.5785143864262663

Epoch: 6| Step: 9
Training loss: 3.0535235516739414
Validation loss: 2.5869390544940614

Epoch: 6| Step: 10
Training loss: 2.8906005858343993
Validation loss: 2.588489383303119

Epoch: 6| Step: 11
Training loss: 3.128377843617053
Validation loss: 2.598258788422982

Epoch: 6| Step: 12
Training loss: 3.161491046130864
Validation loss: 2.5965109219202294

Epoch: 6| Step: 13
Training loss: 3.054154059230983
Validation loss: 2.600351826643888

Epoch: 379| Step: 0
Training loss: 2.9914734787757604
Validation loss: 2.6088155149479015

Epoch: 6| Step: 1
Training loss: 2.810834942781508
Validation loss: 2.594221629439146

Epoch: 6| Step: 2
Training loss: 2.884953724508196
Validation loss: 2.5795297384790508

Epoch: 6| Step: 3
Training loss: 3.3157006401616624
Validation loss: 2.6026005113921395

Epoch: 6| Step: 4
Training loss: 2.4938312718047797
Validation loss: 2.594284765527929

Epoch: 6| Step: 5
Training loss: 2.760267078497117
Validation loss: 2.6014683607967313

Epoch: 6| Step: 6
Training loss: 3.4813823078976367
Validation loss: 2.6011395672165833

Epoch: 6| Step: 7
Training loss: 3.47764313436838
Validation loss: 2.584768157490444

Epoch: 6| Step: 8
Training loss: 2.751225025249095
Validation loss: 2.589596786334061

Epoch: 6| Step: 9
Training loss: 2.566521164456619
Validation loss: 2.5889277448922763

Epoch: 6| Step: 10
Training loss: 2.550470353672706
Validation loss: 2.585441928258966

Epoch: 6| Step: 11
Training loss: 2.8085617466828854
Validation loss: 2.58923334630172

Epoch: 6| Step: 12
Training loss: 2.5876767858290766
Validation loss: 2.585202939488565

Epoch: 6| Step: 13
Training loss: 2.6097452049558476
Validation loss: 2.5884087297893927

Epoch: 380| Step: 0
Training loss: 3.006028317468477
Validation loss: 2.596995300592097

Epoch: 6| Step: 1
Training loss: 2.903832691606437
Validation loss: 2.600343838027976

Epoch: 6| Step: 2
Training loss: 2.8855248900314847
Validation loss: 2.6082920604958946

Epoch: 6| Step: 3
Training loss: 2.9549073991289063
Validation loss: 2.615414301629487

Epoch: 6| Step: 4
Training loss: 2.5868143398696164
Validation loss: 2.6097889115627013

Epoch: 6| Step: 5
Training loss: 3.1173167572374827
Validation loss: 2.626415682516737

Epoch: 6| Step: 6
Training loss: 2.695779511171409
Validation loss: 2.6283756423908438

Epoch: 6| Step: 7
Training loss: 2.969356755943513
Validation loss: 2.618965911403073

Epoch: 6| Step: 8
Training loss: 3.4903488610035516
Validation loss: 2.620076278394003

Epoch: 6| Step: 9
Training loss: 2.5932677406639035
Validation loss: 2.6371131286648333

Epoch: 6| Step: 10
Training loss: 3.358978106096604
Validation loss: 2.648231001964428

Epoch: 6| Step: 11
Training loss: 2.6012458494007555
Validation loss: 2.6362396327536124

Epoch: 6| Step: 12
Training loss: 2.463862445961302
Validation loss: 2.62213269885116

Epoch: 6| Step: 13
Training loss: 2.489825429810081
Validation loss: 2.588276721759507

Epoch: 381| Step: 0
Training loss: 2.7497716288676215
Validation loss: 2.6001806974921706

Epoch: 6| Step: 1
Training loss: 3.0615643998954245
Validation loss: 2.5972780087830443

Epoch: 6| Step: 2
Training loss: 3.150606756961541
Validation loss: 2.6005771313920225

Epoch: 6| Step: 3
Training loss: 2.5754738788290994
Validation loss: 2.5947219484444823

Epoch: 6| Step: 4
Training loss: 2.483156877260759
Validation loss: 2.609474369362894

Epoch: 6| Step: 5
Training loss: 2.989890549101333
Validation loss: 2.6130713527172937

Epoch: 6| Step: 6
Training loss: 2.8642090339031783
Validation loss: 2.6019891917839635

Epoch: 6| Step: 7
Training loss: 2.5892658308045586
Validation loss: 2.591251863876532

Epoch: 6| Step: 8
Training loss: 2.981527997696786
Validation loss: 2.5787198073832527

Epoch: 6| Step: 9
Training loss: 2.8589849153849913
Validation loss: 2.5716306645970666

Epoch: 6| Step: 10
Training loss: 2.946547676750666
Validation loss: 2.5785836913953486

Epoch: 6| Step: 11
Training loss: 2.822041412211871
Validation loss: 2.5702690686619922

Epoch: 6| Step: 12
Training loss: 3.3099559875512496
Validation loss: 2.5739000014072935

Epoch: 6| Step: 13
Training loss: 3.1913145091809407
Validation loss: 2.5754529403911595

Epoch: 382| Step: 0
Training loss: 3.1086836003052225
Validation loss: 2.580487013689398

Epoch: 6| Step: 1
Training loss: 2.6907626906551747
Validation loss: 2.5724186605667843

Epoch: 6| Step: 2
Training loss: 2.849702411306804
Validation loss: 2.5699894184603194

Epoch: 6| Step: 3
Training loss: 3.102651870785155
Validation loss: 2.583865466836672

Epoch: 6| Step: 4
Training loss: 3.2940673443615953
Validation loss: 2.5821190208616414

Epoch: 6| Step: 5
Training loss: 2.716733513538187
Validation loss: 2.583031945075426

Epoch: 6| Step: 6
Training loss: 2.632352794505556
Validation loss: 2.5912529096133987

Epoch: 6| Step: 7
Training loss: 2.4811057406751393
Validation loss: 2.6064323636717086

Epoch: 6| Step: 8
Training loss: 2.47194918245099
Validation loss: 2.601295576487945

Epoch: 6| Step: 9
Training loss: 3.1616091412056884
Validation loss: 2.600563531303695

Epoch: 6| Step: 10
Training loss: 2.5503162000994117
Validation loss: 2.5827155755649858

Epoch: 6| Step: 11
Training loss: 2.6186742402910514
Validation loss: 2.5810259386214263

Epoch: 6| Step: 12
Training loss: 3.2808016516141123
Validation loss: 2.5857900710015658

Epoch: 6| Step: 13
Training loss: 3.5673817431732586
Validation loss: 2.592332908748639

Epoch: 383| Step: 0
Training loss: 3.100758330591316
Validation loss: 2.5921804663520134

Epoch: 6| Step: 1
Training loss: 2.2572464282812104
Validation loss: 2.582732300070627

Epoch: 6| Step: 2
Training loss: 2.9423578554368066
Validation loss: 2.5943967821057403

Epoch: 6| Step: 3
Training loss: 2.4128056189304665
Validation loss: 2.590084400997626

Epoch: 6| Step: 4
Training loss: 2.903937619634841
Validation loss: 2.605714143439583

Epoch: 6| Step: 5
Training loss: 3.4764134064326004
Validation loss: 2.603008934023282

Epoch: 6| Step: 6
Training loss: 3.139390237730617
Validation loss: 2.6107773569337396

Epoch: 6| Step: 7
Training loss: 2.3796779339323177
Validation loss: 2.6109016162124767

Epoch: 6| Step: 8
Training loss: 2.9078381208780253
Validation loss: 2.614693468774033

Epoch: 6| Step: 9
Training loss: 3.401453683538096
Validation loss: 2.626359490848298

Epoch: 6| Step: 10
Training loss: 2.462295593453104
Validation loss: 2.6203693553838803

Epoch: 6| Step: 11
Training loss: 2.551048743810737
Validation loss: 2.6007776258619555

Epoch: 6| Step: 12
Training loss: 3.3789646738988046
Validation loss: 2.584652230251024

Epoch: 6| Step: 13
Training loss: 2.576100149595005
Validation loss: 2.59026572424917

Epoch: 384| Step: 0
Training loss: 2.745645890810949
Validation loss: 2.583950838905922

Epoch: 6| Step: 1
Training loss: 3.251372121052228
Validation loss: 2.5870882036844907

Epoch: 6| Step: 2
Training loss: 2.8530090843294054
Validation loss: 2.581219455981535

Epoch: 6| Step: 3
Training loss: 2.212431170583689
Validation loss: 2.5846006147718086

Epoch: 6| Step: 4
Training loss: 2.8058302737488328
Validation loss: 2.580896584571194

Epoch: 6| Step: 5
Training loss: 3.175051897480855
Validation loss: 2.5903105641651045

Epoch: 6| Step: 6
Training loss: 2.6513385918692753
Validation loss: 2.6028938024449415

Epoch: 6| Step: 7
Training loss: 2.4495527170570055
Validation loss: 2.596894395449118

Epoch: 6| Step: 8
Training loss: 2.9983617760109853
Validation loss: 2.6072613572582055

Epoch: 6| Step: 9
Training loss: 3.1494364703660214
Validation loss: 2.6047428450244627

Epoch: 6| Step: 10
Training loss: 3.3285956251479982
Validation loss: 2.5976143772458404

Epoch: 6| Step: 11
Training loss: 2.989976190325498
Validation loss: 2.5872798516703805

Epoch: 6| Step: 12
Training loss: 2.976104941455962
Validation loss: 2.593727814467931

Epoch: 6| Step: 13
Training loss: 2.2864250116954294
Validation loss: 2.5987254168331386

Epoch: 385| Step: 0
Training loss: 3.2700839469936764
Validation loss: 2.598275569761052

Epoch: 6| Step: 1
Training loss: 2.6341073222617317
Validation loss: 2.595720356435011

Epoch: 6| Step: 2
Training loss: 2.823092540784919
Validation loss: 2.629241013670608

Epoch: 6| Step: 3
Training loss: 2.685913948634884
Validation loss: 2.5994981727925435

Epoch: 6| Step: 4
Training loss: 3.2378530184660104
Validation loss: 2.6037362508809703

Epoch: 6| Step: 5
Training loss: 2.9437692175883794
Validation loss: 2.5796950366539537

Epoch: 6| Step: 6
Training loss: 3.24292836744235
Validation loss: 2.5671237076247464

Epoch: 6| Step: 7
Training loss: 2.5040413616225576
Validation loss: 2.5592454411135166

Epoch: 6| Step: 8
Training loss: 3.00813842592903
Validation loss: 2.561794499027709

Epoch: 6| Step: 9
Training loss: 2.431956712638701
Validation loss: 2.5570607216521943

Epoch: 6| Step: 10
Training loss: 2.299649593363802
Validation loss: 2.5634339274168294

Epoch: 6| Step: 11
Training loss: 2.9685310684590682
Validation loss: 2.567205836725079

Epoch: 6| Step: 12
Training loss: 2.966619751234237
Validation loss: 2.5718990102072397

Epoch: 6| Step: 13
Training loss: 3.454173899705505
Validation loss: 2.5672790848140803

Epoch: 386| Step: 0
Training loss: 3.0368311518463154
Validation loss: 2.578449800328845

Epoch: 6| Step: 1
Training loss: 2.811915018916539
Validation loss: 2.566926829551988

Epoch: 6| Step: 2
Training loss: 3.16524018399288
Validation loss: 2.5754275542354548

Epoch: 6| Step: 3
Training loss: 3.1105525408478476
Validation loss: 2.5929517331764207

Epoch: 6| Step: 4
Training loss: 2.268722836670744
Validation loss: 2.588088888915417

Epoch: 6| Step: 5
Training loss: 3.1673342519748227
Validation loss: 2.59426416271803

Epoch: 6| Step: 6
Training loss: 3.147869200804108
Validation loss: 2.608877359417203

Epoch: 6| Step: 7
Training loss: 2.7070441968203656
Validation loss: 2.608354988691013

Epoch: 6| Step: 8
Training loss: 2.3142777903654963
Validation loss: 2.617483096815806

Epoch: 6| Step: 9
Training loss: 3.098385507336877
Validation loss: 2.62444021503699

Epoch: 6| Step: 10
Training loss: 2.041523934909077
Validation loss: 2.629287300822058

Epoch: 6| Step: 11
Training loss: 2.544537085531428
Validation loss: 2.6237014609667906

Epoch: 6| Step: 12
Training loss: 3.705802882791193
Validation loss: 2.646789156892513

Epoch: 6| Step: 13
Training loss: 2.772483726157884
Validation loss: 2.6421663674294353

Epoch: 387| Step: 0
Training loss: 3.272750017539856
Validation loss: 2.5885336330194493

Epoch: 6| Step: 1
Training loss: 3.4448730465289517
Validation loss: 2.5739874838210897

Epoch: 6| Step: 2
Training loss: 2.338380690530354
Validation loss: 2.5631716868596075

Epoch: 6| Step: 3
Training loss: 2.988246463747692
Validation loss: 2.5571856803293223

Epoch: 6| Step: 4
Training loss: 2.960834591972011
Validation loss: 2.5523074632828995

Epoch: 6| Step: 5
Training loss: 2.336497160041466
Validation loss: 2.5548373469389176

Epoch: 6| Step: 6
Training loss: 2.9322609140376925
Validation loss: 2.5527916510243

Epoch: 6| Step: 7
Training loss: 2.6902079579117157
Validation loss: 2.5610841991241546

Epoch: 6| Step: 8
Training loss: 2.9426349641998986
Validation loss: 2.5666065131373843

Epoch: 6| Step: 9
Training loss: 2.0553714208638443
Validation loss: 2.5610232436152733

Epoch: 6| Step: 10
Training loss: 2.931637697262862
Validation loss: 2.56320754016729

Epoch: 6| Step: 11
Training loss: 3.142166897911544
Validation loss: 2.566413187506542

Epoch: 6| Step: 12
Training loss: 2.780960496558113
Validation loss: 2.5552723517962557

Epoch: 6| Step: 13
Training loss: 4.031103796858241
Validation loss: 2.5550224278074127

Epoch: 388| Step: 0
Training loss: 2.7082159359259053
Validation loss: 2.5521544964938845

Epoch: 6| Step: 1
Training loss: 2.8901333777461047
Validation loss: 2.56941393503665

Epoch: 6| Step: 2
Training loss: 2.5092563928908644
Validation loss: 2.571972108689553

Epoch: 6| Step: 3
Training loss: 3.1103051102791057
Validation loss: 2.600219755493451

Epoch: 6| Step: 4
Training loss: 2.2773780885597263
Validation loss: 2.614806701338279

Epoch: 6| Step: 5
Training loss: 3.279667063772531
Validation loss: 2.66261917888193

Epoch: 6| Step: 6
Training loss: 2.699610194571935
Validation loss: 2.6409696686675557

Epoch: 6| Step: 7
Training loss: 3.254081364163651
Validation loss: 2.6335260682728534

Epoch: 6| Step: 8
Training loss: 2.8565417985841037
Validation loss: 2.601544515960289

Epoch: 6| Step: 9
Training loss: 3.0307673433797695
Validation loss: 2.5727548972270675

Epoch: 6| Step: 10
Training loss: 2.9429953286084953
Validation loss: 2.565654209983849

Epoch: 6| Step: 11
Training loss: 3.0240001697035646
Validation loss: 2.559458992338734

Epoch: 6| Step: 12
Training loss: 2.906449505921056
Validation loss: 2.561236476451007

Epoch: 6| Step: 13
Training loss: 3.0131229437184275
Validation loss: 2.55766541836801

Epoch: 389| Step: 0
Training loss: 3.0701273699752414
Validation loss: 2.5556016966949495

Epoch: 6| Step: 1
Training loss: 3.120465460071622
Validation loss: 2.5597869072403303

Epoch: 6| Step: 2
Training loss: 3.027940339401457
Validation loss: 2.559642470049916

Epoch: 6| Step: 3
Training loss: 3.1462500761423873
Validation loss: 2.567177882448097

Epoch: 6| Step: 4
Training loss: 3.299477801765495
Validation loss: 2.561409590951287

Epoch: 6| Step: 5
Training loss: 2.604909582344451
Validation loss: 2.567428098994769

Epoch: 6| Step: 6
Training loss: 2.2195117341324555
Validation loss: 2.568332845693636

Epoch: 6| Step: 7
Training loss: 3.232715567992718
Validation loss: 2.5618354702046005

Epoch: 6| Step: 8
Training loss: 2.9233575823251905
Validation loss: 2.5620876238557853

Epoch: 6| Step: 9
Training loss: 3.4325339772542502
Validation loss: 2.5559245467433946

Epoch: 6| Step: 10
Training loss: 2.949365715760793
Validation loss: 2.5529923585349565

Epoch: 6| Step: 11
Training loss: 2.420780352889798
Validation loss: 2.55335188163194

Epoch: 6| Step: 12
Training loss: 2.2245808667373295
Validation loss: 2.5604150365094376

Epoch: 6| Step: 13
Training loss: 2.6804597592626926
Validation loss: 2.563396098087518

Epoch: 390| Step: 0
Training loss: 2.11557294367386
Validation loss: 2.572941280820346

Epoch: 6| Step: 1
Training loss: 2.986640429835655
Validation loss: 2.589218708389558

Epoch: 6| Step: 2
Training loss: 2.845639449999689
Validation loss: 2.5786821863915033

Epoch: 6| Step: 3
Training loss: 2.870267538965533
Validation loss: 2.5855900830641487

Epoch: 6| Step: 4
Training loss: 2.8661982937327597
Validation loss: 2.6000065526966476

Epoch: 6| Step: 5
Training loss: 2.7559140508839124
Validation loss: 2.6136519207828424

Epoch: 6| Step: 6
Training loss: 3.038184345531331
Validation loss: 2.6252500988194742

Epoch: 6| Step: 7
Training loss: 2.5787253865608126
Validation loss: 2.6101896063140777

Epoch: 6| Step: 8
Training loss: 3.0004380224253953
Validation loss: 2.593593498299214

Epoch: 6| Step: 9
Training loss: 3.5296548937287398
Validation loss: 2.6000120497141146

Epoch: 6| Step: 10
Training loss: 2.955052306975782
Validation loss: 2.593944446892164

Epoch: 6| Step: 11
Training loss: 2.578777068934934
Validation loss: 2.588563293840746

Epoch: 6| Step: 12
Training loss: 3.0391409503450895
Validation loss: 2.5776748657045667

Epoch: 6| Step: 13
Training loss: 3.077242342267575
Validation loss: 2.5633443476288833

Epoch: 391| Step: 0
Training loss: 2.6342324070107233
Validation loss: 2.5604362931666564

Epoch: 6| Step: 1
Training loss: 2.835404443165603
Validation loss: 2.5696879213804547

Epoch: 6| Step: 2
Training loss: 3.2940352082956266
Validation loss: 2.568749038156784

Epoch: 6| Step: 3
Training loss: 2.9127627995014747
Validation loss: 2.57719918162739

Epoch: 6| Step: 4
Training loss: 2.6863956400219613
Validation loss: 2.5628605630689205

Epoch: 6| Step: 5
Training loss: 3.012554918477142
Validation loss: 2.5570151593056853

Epoch: 6| Step: 6
Training loss: 2.8595240819870478
Validation loss: 2.56694278904469

Epoch: 6| Step: 7
Training loss: 2.3985817334672594
Validation loss: 2.563946545498767

Epoch: 6| Step: 8
Training loss: 3.079980281419923
Validation loss: 2.5597704544553004

Epoch: 6| Step: 9
Training loss: 3.1184186679154102
Validation loss: 2.5851558332575197

Epoch: 6| Step: 10
Training loss: 1.995565086872747
Validation loss: 2.587228901969022

Epoch: 6| Step: 11
Training loss: 3.113499651706542
Validation loss: 2.578594460600734

Epoch: 6| Step: 12
Training loss: 3.2689816686396918
Validation loss: 2.5765788314702633

Epoch: 6| Step: 13
Training loss: 3.0086881081428296
Validation loss: 2.577258846378998

Epoch: 392| Step: 0
Training loss: 1.6683590720392343
Validation loss: 2.574394333493138

Epoch: 6| Step: 1
Training loss: 2.784220619931046
Validation loss: 2.567112695562555

Epoch: 6| Step: 2
Training loss: 2.9982972080951695
Validation loss: 2.5674831820246085

Epoch: 6| Step: 3
Training loss: 3.1732325162286457
Validation loss: 2.567791615171636

Epoch: 6| Step: 4
Training loss: 3.499084216608602
Validation loss: 2.554047889465678

Epoch: 6| Step: 5
Training loss: 3.0446838325009344
Validation loss: 2.566870514121192

Epoch: 6| Step: 6
Training loss: 2.219761040516715
Validation loss: 2.573519938697866

Epoch: 6| Step: 7
Training loss: 2.8548237584860825
Validation loss: 2.5649670266224063

Epoch: 6| Step: 8
Training loss: 2.713768440089047
Validation loss: 2.566483759212593

Epoch: 6| Step: 9
Training loss: 2.4184602351930877
Validation loss: 2.564807427228929

Epoch: 6| Step: 10
Training loss: 2.8807868767360776
Validation loss: 2.582634470747877

Epoch: 6| Step: 11
Training loss: 3.3740753037348528
Validation loss: 2.591530104041941

Epoch: 6| Step: 12
Training loss: 3.2606820840428834
Validation loss: 2.5876695645243264

Epoch: 6| Step: 13
Training loss: 2.9948713651363024
Validation loss: 2.578156145839303

Epoch: 393| Step: 0
Training loss: 3.214451410170508
Validation loss: 2.576141169904592

Epoch: 6| Step: 1
Training loss: 3.0622418353199015
Validation loss: 2.5670381444466863

Epoch: 6| Step: 2
Training loss: 3.35281782494196
Validation loss: 2.5650656506986653

Epoch: 6| Step: 3
Training loss: 2.521742780166627
Validation loss: 2.5649446930801814

Epoch: 6| Step: 4
Training loss: 2.7176589530493174
Validation loss: 2.5553238393458457

Epoch: 6| Step: 5
Training loss: 2.86744327079977
Validation loss: 2.5588510536258786

Epoch: 6| Step: 6
Training loss: 2.6474048322912043
Validation loss: 2.564989224041679

Epoch: 6| Step: 7
Training loss: 2.896824143507542
Validation loss: 2.560085258368414

Epoch: 6| Step: 8
Training loss: 2.945793132876384
Validation loss: 2.556665703353682

Epoch: 6| Step: 9
Training loss: 2.6936736943529684
Validation loss: 2.559078614672447

Epoch: 6| Step: 10
Training loss: 3.1334135092629793
Validation loss: 2.567275416018397

Epoch: 6| Step: 11
Training loss: 2.605232742807359
Validation loss: 2.5655801755641074

Epoch: 6| Step: 12
Training loss: 2.6423924416817677
Validation loss: 2.5603150467513447

Epoch: 6| Step: 13
Training loss: 2.791310491662341
Validation loss: 2.5802518075033394

Epoch: 394| Step: 0
Training loss: 2.9689247481464145
Validation loss: 2.5883268158754027

Epoch: 6| Step: 1
Training loss: 2.6117062690749306
Validation loss: 2.59549704113022

Epoch: 6| Step: 2
Training loss: 3.6130293144854972
Validation loss: 2.600931762400856

Epoch: 6| Step: 3
Training loss: 2.4187233383720117
Validation loss: 2.59593238251165

Epoch: 6| Step: 4
Training loss: 2.8911472158142937
Validation loss: 2.614723237775565

Epoch: 6| Step: 5
Training loss: 2.7990995968907946
Validation loss: 2.5808106604890706

Epoch: 6| Step: 6
Training loss: 2.964005544031804
Validation loss: 2.5907852856151874

Epoch: 6| Step: 7
Training loss: 2.5941119573428213
Validation loss: 2.6154937616732283

Epoch: 6| Step: 8
Training loss: 3.010918299361862
Validation loss: 2.5951451605326126

Epoch: 6| Step: 9
Training loss: 2.6681512236853466
Validation loss: 2.6054187601423284

Epoch: 6| Step: 10
Training loss: 3.103983589935184
Validation loss: 2.600270758256888

Epoch: 6| Step: 11
Training loss: 2.978410922852354
Validation loss: 2.613330864812017

Epoch: 6| Step: 12
Training loss: 2.8366819303156454
Validation loss: 2.6306083856621063

Epoch: 6| Step: 13
Training loss: 2.3207107356328245
Validation loss: 2.621547446181321

Epoch: 395| Step: 0
Training loss: 3.1646752035045806
Validation loss: 2.5915300674401265

Epoch: 6| Step: 1
Training loss: 3.027184345601678
Validation loss: 2.595752215572654

Epoch: 6| Step: 2
Training loss: 2.9503852204786325
Validation loss: 2.5916158191272265

Epoch: 6| Step: 3
Training loss: 3.4815561156543486
Validation loss: 2.592889705611248

Epoch: 6| Step: 4
Training loss: 3.124297406369513
Validation loss: 2.5926923912159165

Epoch: 6| Step: 5
Training loss: 2.939405918692788
Validation loss: 2.5776567418565364

Epoch: 6| Step: 6
Training loss: 2.920754937078053
Validation loss: 2.5781026452053353

Epoch: 6| Step: 7
Training loss: 2.033045518026869
Validation loss: 2.571337782684087

Epoch: 6| Step: 8
Training loss: 2.8996048296327874
Validation loss: 2.5736463559167113

Epoch: 6| Step: 9
Training loss: 2.624611780432649
Validation loss: 2.5664526485261363

Epoch: 6| Step: 10
Training loss: 2.9297003580447005
Validation loss: 2.5748414181236434

Epoch: 6| Step: 11
Training loss: 3.130864705576794
Validation loss: 2.5734671301581393

Epoch: 6| Step: 12
Training loss: 1.9828027218456568
Validation loss: 2.5878334293867193

Epoch: 6| Step: 13
Training loss: 2.4364387940896384
Validation loss: 2.5833302572935315

Epoch: 396| Step: 0
Training loss: 2.512389003142784
Validation loss: 2.5851931716256327

Epoch: 6| Step: 1
Training loss: 2.3948412845400022
Validation loss: 2.582623316365653

Epoch: 6| Step: 2
Training loss: 2.5922733377750227
Validation loss: 2.591012542275996

Epoch: 6| Step: 3
Training loss: 2.5931214639598674
Validation loss: 2.580997662221605

Epoch: 6| Step: 4
Training loss: 3.386804353012724
Validation loss: 2.5865292198210548

Epoch: 6| Step: 5
Training loss: 2.6193640014155384
Validation loss: 2.596031677859468

Epoch: 6| Step: 6
Training loss: 3.076180710552787
Validation loss: 2.599937546637041

Epoch: 6| Step: 7
Training loss: 2.3097148309700124
Validation loss: 2.5926670403720724

Epoch: 6| Step: 8
Training loss: 3.2710237548861207
Validation loss: 2.614086190307897

Epoch: 6| Step: 9
Training loss: 3.077557971448621
Validation loss: 2.5866027477973583

Epoch: 6| Step: 10
Training loss: 2.408095704689312
Validation loss: 2.604556606180522

Epoch: 6| Step: 11
Training loss: 3.159479736040985
Validation loss: 2.590435294542446

Epoch: 6| Step: 12
Training loss: 3.3207243540522455
Validation loss: 2.5984324712119267

Epoch: 6| Step: 13
Training loss: 3.3090105210866447
Validation loss: 2.5788884548622764

Epoch: 397| Step: 0
Training loss: 2.0815612376961905
Validation loss: 2.5600722482924185

Epoch: 6| Step: 1
Training loss: 2.4290937575254525
Validation loss: 2.5742924438645924

Epoch: 6| Step: 2
Training loss: 2.618591933840189
Validation loss: 2.562144840378128

Epoch: 6| Step: 3
Training loss: 3.0274152587320606
Validation loss: 2.558497304319003

Epoch: 6| Step: 4
Training loss: 2.684190531066651
Validation loss: 2.5558163738807127

Epoch: 6| Step: 5
Training loss: 2.7828713309630477
Validation loss: 2.5594986877800228

Epoch: 6| Step: 6
Training loss: 2.9326986478758656
Validation loss: 2.552912329880716

Epoch: 6| Step: 7
Training loss: 3.5780471726661482
Validation loss: 2.5519387085957934

Epoch: 6| Step: 8
Training loss: 2.6339278306567464
Validation loss: 2.552063312330605

Epoch: 6| Step: 9
Training loss: 3.0942681389226365
Validation loss: 2.5577816736946857

Epoch: 6| Step: 10
Training loss: 3.54914185266239
Validation loss: 2.558813368943609

Epoch: 6| Step: 11
Training loss: 3.1497957314759977
Validation loss: 2.554969900688528

Epoch: 6| Step: 12
Training loss: 2.4957773787181208
Validation loss: 2.567607578553163

Epoch: 6| Step: 13
Training loss: 2.716283183344992
Validation loss: 2.575404035261385

Epoch: 398| Step: 0
Training loss: 3.153883244938702
Validation loss: 2.5852861363849824

Epoch: 6| Step: 1
Training loss: 3.3043398843381757
Validation loss: 2.5799376259981406

Epoch: 6| Step: 2
Training loss: 2.672003045834159
Validation loss: 2.59259071145752

Epoch: 6| Step: 3
Training loss: 2.8300506611525424
Validation loss: 2.6069460400356768

Epoch: 6| Step: 4
Training loss: 2.521913712025957
Validation loss: 2.6200945442273142

Epoch: 6| Step: 5
Training loss: 2.3535278826509116
Validation loss: 2.622063474343945

Epoch: 6| Step: 6
Training loss: 2.3475774412209063
Validation loss: 2.6007454487784116

Epoch: 6| Step: 7
Training loss: 3.011543951639466
Validation loss: 2.6016602088105123

Epoch: 6| Step: 8
Training loss: 2.9578859411795837
Validation loss: 2.6076061955910435

Epoch: 6| Step: 9
Training loss: 3.1177451798878413
Validation loss: 2.588023403582335

Epoch: 6| Step: 10
Training loss: 3.2921742558948424
Validation loss: 2.5845497352510005

Epoch: 6| Step: 11
Training loss: 3.32152709287441
Validation loss: 2.576556921949732

Epoch: 6| Step: 12
Training loss: 1.8703982786873892
Validation loss: 2.5735139413025485

Epoch: 6| Step: 13
Training loss: 3.154979487864803
Validation loss: 2.5703306407246536

Epoch: 399| Step: 0
Training loss: 2.944075347350829
Validation loss: 2.5646840504127204

Epoch: 6| Step: 1
Training loss: 2.8827984403768774
Validation loss: 2.57101457671306

Epoch: 6| Step: 2
Training loss: 2.5784658495683312
Validation loss: 2.562831826163705

Epoch: 6| Step: 3
Training loss: 2.717580609569261
Validation loss: 2.5626325475475715

Epoch: 6| Step: 4
Training loss: 3.6698207871754924
Validation loss: 2.5632567050016446

Epoch: 6| Step: 5
Training loss: 2.2843787280677192
Validation loss: 2.560216201622565

Epoch: 6| Step: 6
Training loss: 3.3042042336046067
Validation loss: 2.563875145024434

Epoch: 6| Step: 7
Training loss: 2.287653153925926
Validation loss: 2.5787830535928955

Epoch: 6| Step: 8
Training loss: 2.8724719003177794
Validation loss: 2.584955464013944

Epoch: 6| Step: 9
Training loss: 3.235885783269886
Validation loss: 2.588919429400717

Epoch: 6| Step: 10
Training loss: 2.6730436033780487
Validation loss: 2.5930686359166524

Epoch: 6| Step: 11
Training loss: 2.625339667732859
Validation loss: 2.58922109359071

Epoch: 6| Step: 12
Training loss: 3.0048905881744536
Validation loss: 2.6092396225080496

Epoch: 6| Step: 13
Training loss: 2.6589757958121476
Validation loss: 2.610165499909637

Epoch: 400| Step: 0
Training loss: 3.5830595813836417
Validation loss: 2.59623682466605

Epoch: 6| Step: 1
Training loss: 2.3303461935854095
Validation loss: 2.5948165942218124

Epoch: 6| Step: 2
Training loss: 3.26529673701514
Validation loss: 2.6022050793118425

Epoch: 6| Step: 3
Training loss: 2.2859542627039406
Validation loss: 2.5962297506016347

Epoch: 6| Step: 4
Training loss: 2.4865799242219135
Validation loss: 2.589159742033248

Epoch: 6| Step: 5
Training loss: 2.8241248741745895
Validation loss: 2.6096515249868504

Epoch: 6| Step: 6
Training loss: 2.8588396415450337
Validation loss: 2.5987581970094724

Epoch: 6| Step: 7
Training loss: 2.9065449882843546
Validation loss: 2.5911675100068607

Epoch: 6| Step: 8
Training loss: 2.5678634338786925
Validation loss: 2.5960631905102938

Epoch: 6| Step: 9
Training loss: 2.765663965672711
Validation loss: 2.5858685586793975

Epoch: 6| Step: 10
Training loss: 3.312561322490316
Validation loss: 2.5833108899679456

Epoch: 6| Step: 11
Training loss: 2.6676890281049226
Validation loss: 2.586001798963451

Epoch: 6| Step: 12
Training loss: 2.5469854600039787
Validation loss: 2.580188563514207

Epoch: 6| Step: 13
Training loss: 3.7113329867383427
Validation loss: 2.5894027634202077

Epoch: 401| Step: 0
Training loss: 3.210017979889424
Validation loss: 2.580313687801615

Epoch: 6| Step: 1
Training loss: 2.849336941869245
Validation loss: 2.5716716714641144

Epoch: 6| Step: 2
Training loss: 2.7580606062594586
Validation loss: 2.563283346853091

Epoch: 6| Step: 3
Training loss: 2.5222125313227712
Validation loss: 2.5623158454502777

Epoch: 6| Step: 4
Training loss: 2.696697200072599
Validation loss: 2.563867423719114

Epoch: 6| Step: 5
Training loss: 2.667308451988963
Validation loss: 2.5769878217516897

Epoch: 6| Step: 6
Training loss: 2.59327242947268
Validation loss: 2.569466599894836

Epoch: 6| Step: 7
Training loss: 2.9712427214780894
Validation loss: 2.561142052662326

Epoch: 6| Step: 8
Training loss: 2.9456187931337774
Validation loss: 2.5574181842043826

Epoch: 6| Step: 9
Training loss: 3.012571538178644
Validation loss: 2.5582381332538677

Epoch: 6| Step: 10
Training loss: 2.842429388908829
Validation loss: 2.556075654095526

Epoch: 6| Step: 11
Training loss: 3.036790012851287
Validation loss: 2.564867175339482

Epoch: 6| Step: 12
Training loss: 2.9545341238058005
Validation loss: 2.556076218761723

Epoch: 6| Step: 13
Training loss: 3.0529049406524527
Validation loss: 2.5699992471011295

Epoch: 402| Step: 0
Training loss: 3.173793719765442
Validation loss: 2.586143133289473

Epoch: 6| Step: 1
Training loss: 2.696891521168978
Validation loss: 2.576428473886524

Epoch: 6| Step: 2
Training loss: 2.8302797992001167
Validation loss: 2.5763591656698166

Epoch: 6| Step: 3
Training loss: 2.235590464106869
Validation loss: 2.571866669184882

Epoch: 6| Step: 4
Training loss: 3.115927534805751
Validation loss: 2.5916103962969737

Epoch: 6| Step: 5
Training loss: 3.423334098030854
Validation loss: 2.5894780052082935

Epoch: 6| Step: 6
Training loss: 2.80733796165856
Validation loss: 2.6065575397047596

Epoch: 6| Step: 7
Training loss: 2.6733237460274464
Validation loss: 2.6003898873343885

Epoch: 6| Step: 8
Training loss: 2.9912732672354334
Validation loss: 2.589935131357378

Epoch: 6| Step: 9
Training loss: 2.370595059435823
Validation loss: 2.5881864783923163

Epoch: 6| Step: 10
Training loss: 3.3698450916581404
Validation loss: 2.579100275262809

Epoch: 6| Step: 11
Training loss: 3.1286238448846424
Validation loss: 2.568890771815242

Epoch: 6| Step: 12
Training loss: 2.6150275127940197
Validation loss: 2.5631456619669617

Epoch: 6| Step: 13
Training loss: 1.8332795727679128
Validation loss: 2.5683212349184488

Epoch: 403| Step: 0
Training loss: 2.524468840072999
Validation loss: 2.564776178760623

Epoch: 6| Step: 1
Training loss: 3.0068085022802444
Validation loss: 2.5596572170063454

Epoch: 6| Step: 2
Training loss: 2.400023392722249
Validation loss: 2.5598917476953726

Epoch: 6| Step: 3
Training loss: 2.5981668759170002
Validation loss: 2.5595726071422042

Epoch: 6| Step: 4
Training loss: 2.540570934888734
Validation loss: 2.555249027554727

Epoch: 6| Step: 5
Training loss: 3.350401919722713
Validation loss: 2.553311296428587

Epoch: 6| Step: 6
Training loss: 3.0746818688053486
Validation loss: 2.554015730429843

Epoch: 6| Step: 7
Training loss: 3.3625345675028186
Validation loss: 2.547595262173416

Epoch: 6| Step: 8
Training loss: 2.9267710092607886
Validation loss: 2.5544134944330574

Epoch: 6| Step: 9
Training loss: 2.9802389993770975
Validation loss: 2.556570209764437

Epoch: 6| Step: 10
Training loss: 2.4126974153536533
Validation loss: 2.5687175906273843

Epoch: 6| Step: 11
Training loss: 2.786464731559657
Validation loss: 2.574825922777413

Epoch: 6| Step: 12
Training loss: 2.6463205885087935
Validation loss: 2.5817250641799006

Epoch: 6| Step: 13
Training loss: 3.456603494678177
Validation loss: 2.5888187873072073

Epoch: 404| Step: 0
Training loss: 2.9625724365134696
Validation loss: 2.6069394641087924

Epoch: 6| Step: 1
Training loss: 3.1176150227169814
Validation loss: 2.663098771623794

Epoch: 6| Step: 2
Training loss: 2.2724993366034854
Validation loss: 2.6924954076674426

Epoch: 6| Step: 3
Training loss: 3.129115637013085
Validation loss: 2.6700398090764317

Epoch: 6| Step: 4
Training loss: 2.6764920146900693
Validation loss: 2.6388737866095995

Epoch: 6| Step: 5
Training loss: 3.5564164536712175
Validation loss: 2.6347986738871136

Epoch: 6| Step: 6
Training loss: 2.867647804501812
Validation loss: 2.5943702917749243

Epoch: 6| Step: 7
Training loss: 2.718558469142513
Validation loss: 2.594423730660711

Epoch: 6| Step: 8
Training loss: 3.000735987346984
Validation loss: 2.5725768091805366

Epoch: 6| Step: 9
Training loss: 2.7338343494520916
Validation loss: 2.5576344850834927

Epoch: 6| Step: 10
Training loss: 2.9194309396025107
Validation loss: 2.5473974776455117

Epoch: 6| Step: 11
Training loss: 3.153521727753679
Validation loss: 2.5402507829131573

Epoch: 6| Step: 12
Training loss: 2.194284870553422
Validation loss: 2.5413049076979086

Epoch: 6| Step: 13
Training loss: 2.653470099373238
Validation loss: 2.5371928252733373

Epoch: 405| Step: 0
Training loss: 2.964694173907286
Validation loss: 2.5419081524961538

Epoch: 6| Step: 1
Training loss: 2.7604305818794805
Validation loss: 2.5399586146126265

Epoch: 6| Step: 2
Training loss: 2.8352873926639295
Validation loss: 2.5374762748119535

Epoch: 6| Step: 3
Training loss: 2.8068064386475253
Validation loss: 2.5374066821084633

Epoch: 6| Step: 4
Training loss: 3.3012273182319065
Validation loss: 2.532348380324347

Epoch: 6| Step: 5
Training loss: 2.898154519963011
Validation loss: 2.537924486047357

Epoch: 6| Step: 6
Training loss: 2.9789660904239086
Validation loss: 2.539534334148168

Epoch: 6| Step: 7
Training loss: 3.174502332236196
Validation loss: 2.5434593903219445

Epoch: 6| Step: 8
Training loss: 3.0125112319673586
Validation loss: 2.548328042790179

Epoch: 6| Step: 9
Training loss: 2.767013804553979
Validation loss: 2.551270057790821

Epoch: 6| Step: 10
Training loss: 2.6904383719800853
Validation loss: 2.5741767390018944

Epoch: 6| Step: 11
Training loss: 3.0691182772111794
Validation loss: 2.5829442657799215

Epoch: 6| Step: 12
Training loss: 2.5429532802128825
Validation loss: 2.5729114090183787

Epoch: 6| Step: 13
Training loss: 1.7984516690091281
Validation loss: 2.5854160501963372

Epoch: 406| Step: 0
Training loss: 3.2007345071870685
Validation loss: 2.5825421322147015

Epoch: 6| Step: 1
Training loss: 3.127832578544494
Validation loss: 2.5924106405951437

Epoch: 6| Step: 2
Training loss: 2.861691063266115
Validation loss: 2.6193609693194717

Epoch: 6| Step: 3
Training loss: 2.8208855973947022
Validation loss: 2.595962133592896

Epoch: 6| Step: 4
Training loss: 2.6422302964510194
Validation loss: 2.5985780740628783

Epoch: 6| Step: 5
Training loss: 3.1799748171403
Validation loss: 2.5766350998770444

Epoch: 6| Step: 6
Training loss: 3.010200008704941
Validation loss: 2.586018731217219

Epoch: 6| Step: 7
Training loss: 2.992808304969259
Validation loss: 2.5786928169969165

Epoch: 6| Step: 8
Training loss: 2.254898566863814
Validation loss: 2.58299400477411

Epoch: 6| Step: 9
Training loss: 2.2287140740340847
Validation loss: 2.5744997909618754

Epoch: 6| Step: 10
Training loss: 3.4063656288609643
Validation loss: 2.5693911692040508

Epoch: 6| Step: 11
Training loss: 1.9986120414716995
Validation loss: 2.5649459849227294

Epoch: 6| Step: 12
Training loss: 3.1526796901716483
Validation loss: 2.5843977880323226

Epoch: 6| Step: 13
Training loss: 2.9142428181266795
Validation loss: 2.5903914375518005

Epoch: 407| Step: 0
Training loss: 3.365711853550142
Validation loss: 2.5860132282469053

Epoch: 6| Step: 1
Training loss: 2.959880871824173
Validation loss: 2.5713423230479497

Epoch: 6| Step: 2
Training loss: 2.7389364506235263
Validation loss: 2.59185762111111

Epoch: 6| Step: 3
Training loss: 2.8605652713353393
Validation loss: 2.5905558279181884

Epoch: 6| Step: 4
Training loss: 2.886293372170753
Validation loss: 2.5862395957699

Epoch: 6| Step: 5
Training loss: 2.4806046576325422
Validation loss: 2.564540517813189

Epoch: 6| Step: 6
Training loss: 3.2806852308788246
Validation loss: 2.554249892370807

Epoch: 6| Step: 7
Training loss: 2.776553700207197
Validation loss: 2.557607784389508

Epoch: 6| Step: 8
Training loss: 2.9847729802025427
Validation loss: 2.5683003280042627

Epoch: 6| Step: 9
Training loss: 2.528490045360049
Validation loss: 2.557661959303446

Epoch: 6| Step: 10
Training loss: 2.6128097131570773
Validation loss: 2.5633604094348805

Epoch: 6| Step: 11
Training loss: 3.3623190111425223
Validation loss: 2.5592813484227865

Epoch: 6| Step: 12
Training loss: 2.6147240731303136
Validation loss: 2.5571749131962966

Epoch: 6| Step: 13
Training loss: 1.9999164921492794
Validation loss: 2.571885348180956

Epoch: 408| Step: 0
Training loss: 2.6016345314845046
Validation loss: 2.5775831610862654

Epoch: 6| Step: 1
Training loss: 3.075171278238487
Validation loss: 2.5821813925360644

Epoch: 6| Step: 2
Training loss: 2.1775734333046226
Validation loss: 2.5964573986223267

Epoch: 6| Step: 3
Training loss: 3.205618580889657
Validation loss: 2.5931188104725234

Epoch: 6| Step: 4
Training loss: 3.275261345838668
Validation loss: 2.599905051508372

Epoch: 6| Step: 5
Training loss: 2.5361974896691315
Validation loss: 2.5990819822498095

Epoch: 6| Step: 6
Training loss: 2.7363682048947267
Validation loss: 2.5851578463618736

Epoch: 6| Step: 7
Training loss: 3.2304067548086994
Validation loss: 2.5801414799990945

Epoch: 6| Step: 8
Training loss: 2.72539182523242
Validation loss: 2.5771685613884094

Epoch: 6| Step: 9
Training loss: 2.7197589975063234
Validation loss: 2.559736239073978

Epoch: 6| Step: 10
Training loss: 2.934026246882434
Validation loss: 2.5535196524631636

Epoch: 6| Step: 11
Training loss: 2.9246180097458345
Validation loss: 2.563856257682582

Epoch: 6| Step: 12
Training loss: 2.9917948094146807
Validation loss: 2.560686990259868

Epoch: 6| Step: 13
Training loss: 2.533545406984874
Validation loss: 2.563082909082949

Epoch: 409| Step: 0
Training loss: 2.448103606749245
Validation loss: 2.562404514737713

Epoch: 6| Step: 1
Training loss: 2.9786861183273596
Validation loss: 2.5614249863030834

Epoch: 6| Step: 2
Training loss: 2.9928975271315514
Validation loss: 2.5611293407414806

Epoch: 6| Step: 3
Training loss: 2.666878652094076
Validation loss: 2.5593640326880567

Epoch: 6| Step: 4
Training loss: 3.2755578941803853
Validation loss: 2.5652538152008946

Epoch: 6| Step: 5
Training loss: 2.5674597031087756
Validation loss: 2.564982127764814

Epoch: 6| Step: 6
Training loss: 2.905137043804669
Validation loss: 2.571972300067594

Epoch: 6| Step: 7
Training loss: 2.4341254717318477
Validation loss: 2.5690723804622895

Epoch: 6| Step: 8
Training loss: 3.012158867606616
Validation loss: 2.561517901922434

Epoch: 6| Step: 9
Training loss: 3.2955545248811835
Validation loss: 2.5664132814049903

Epoch: 6| Step: 10
Training loss: 2.629919800496482
Validation loss: 2.5842328095133884

Epoch: 6| Step: 11
Training loss: 3.095183531661011
Validation loss: 2.577426485389605

Epoch: 6| Step: 12
Training loss: 2.838454125597262
Validation loss: 2.5837169888951252

Epoch: 6| Step: 13
Training loss: 2.5687708535937386
Validation loss: 2.5778870692485687

Epoch: 410| Step: 0
Training loss: 2.8336448124233273
Validation loss: 2.574283059837616

Epoch: 6| Step: 1
Training loss: 3.0924474883497513
Validation loss: 2.5802968671423163

Epoch: 6| Step: 2
Training loss: 2.527763697360254
Validation loss: 2.583051357169369

Epoch: 6| Step: 3
Training loss: 2.982810364248351
Validation loss: 2.5886551511957134

Epoch: 6| Step: 4
Training loss: 3.442136654541065
Validation loss: 2.6088455092318363

Epoch: 6| Step: 5
Training loss: 2.621923551234953
Validation loss: 2.5887939392259685

Epoch: 6| Step: 6
Training loss: 2.540217585818345
Validation loss: 2.584067400805286

Epoch: 6| Step: 7
Training loss: 2.952598888217319
Validation loss: 2.567799523354716

Epoch: 6| Step: 8
Training loss: 2.5550650687992937
Validation loss: 2.5693460969100497

Epoch: 6| Step: 9
Training loss: 2.2298668685654484
Validation loss: 2.5748727102146316

Epoch: 6| Step: 10
Training loss: 3.4158021872196223
Validation loss: 2.558146173813311

Epoch: 6| Step: 11
Training loss: 2.8454184196654086
Validation loss: 2.5597025290122937

Epoch: 6| Step: 12
Training loss: 2.464544843393038
Validation loss: 2.5599892694494484

Epoch: 6| Step: 13
Training loss: 3.341127597266501
Validation loss: 2.5549222962389693

Epoch: 411| Step: 0
Training loss: 3.1405545506712964
Validation loss: 2.556912253289891

Epoch: 6| Step: 1
Training loss: 2.6276723791719516
Validation loss: 2.561308765223577

Epoch: 6| Step: 2
Training loss: 2.7302778665730583
Validation loss: 2.553010297985064

Epoch: 6| Step: 3
Training loss: 3.107149947836416
Validation loss: 2.5504286299845953

Epoch: 6| Step: 4
Training loss: 2.7823676960243997
Validation loss: 2.55153161004137

Epoch: 6| Step: 5
Training loss: 2.5854557199369395
Validation loss: 2.55654432023134

Epoch: 6| Step: 6
Training loss: 2.8166712875629267
Validation loss: 2.5509741272289004

Epoch: 6| Step: 7
Training loss: 3.009085566624124
Validation loss: 2.5600748509137428

Epoch: 6| Step: 8
Training loss: 2.7289386003631524
Validation loss: 2.5637293052169077

Epoch: 6| Step: 9
Training loss: 2.668075268966215
Validation loss: 2.571807458492304

Epoch: 6| Step: 10
Training loss: 3.2337162249924307
Validation loss: 2.5643591030740462

Epoch: 6| Step: 11
Training loss: 2.659111994324074
Validation loss: 2.5827984853286523

Epoch: 6| Step: 12
Training loss: 3.061094779101599
Validation loss: 2.59376856588081

Epoch: 6| Step: 13
Training loss: 2.635762449556242
Validation loss: 2.6237205868161477

Epoch: 412| Step: 0
Training loss: 3.086006260359342
Validation loss: 2.624575127391058

Epoch: 6| Step: 1
Training loss: 2.4662923047651804
Validation loss: 2.606420520330805

Epoch: 6| Step: 2
Training loss: 2.4013002688037646
Validation loss: 2.65481773720001

Epoch: 6| Step: 3
Training loss: 3.2738564161765304
Validation loss: 2.6016558051148806

Epoch: 6| Step: 4
Training loss: 2.428525984362958
Validation loss: 2.5660866029026024

Epoch: 6| Step: 5
Training loss: 2.9269163326169143
Validation loss: 2.545970579760167

Epoch: 6| Step: 6
Training loss: 2.512933558923459
Validation loss: 2.543868984469054

Epoch: 6| Step: 7
Training loss: 2.821711227717059
Validation loss: 2.5401394093565512

Epoch: 6| Step: 8
Training loss: 2.797908485459339
Validation loss: 2.5382869614509818

Epoch: 6| Step: 9
Training loss: 2.8639736197125103
Validation loss: 2.537032231981923

Epoch: 6| Step: 10
Training loss: 2.1328782291554464
Validation loss: 2.542087185946265

Epoch: 6| Step: 11
Training loss: 3.3969611106984514
Validation loss: 2.5384867818300902

Epoch: 6| Step: 12
Training loss: 3.4211420815854785
Validation loss: 2.534563564209084

Epoch: 6| Step: 13
Training loss: 3.777726099807721
Validation loss: 2.543314244610983

Epoch: 413| Step: 0
Training loss: 2.7348532994065518
Validation loss: 2.530368028914389

Epoch: 6| Step: 1
Training loss: 3.012556501309807
Validation loss: 2.5457855618360146

Epoch: 6| Step: 2
Training loss: 3.006786934532897
Validation loss: 2.5554085467486467

Epoch: 6| Step: 3
Training loss: 2.8573582942665703
Validation loss: 2.5657299583692983

Epoch: 6| Step: 4
Training loss: 2.9927490344910757
Validation loss: 2.5689999010044553

Epoch: 6| Step: 5
Training loss: 3.102365231349546
Validation loss: 2.5702570467172006

Epoch: 6| Step: 6
Training loss: 2.3944846517437783
Validation loss: 2.5755935825066376

Epoch: 6| Step: 7
Training loss: 2.6958286841547485
Validation loss: 2.5858827248134717

Epoch: 6| Step: 8
Training loss: 2.5427802934560773
Validation loss: 2.583405183738329

Epoch: 6| Step: 9
Training loss: 3.2003386497118327
Validation loss: 2.5890392109952916

Epoch: 6| Step: 10
Training loss: 3.19128567153831
Validation loss: 2.580149124782135

Epoch: 6| Step: 11
Training loss: 2.79323968173458
Validation loss: 2.574527190754487

Epoch: 6| Step: 12
Training loss: 2.8295139674495666
Validation loss: 2.5630162697192764

Epoch: 6| Step: 13
Training loss: 2.170100303476417
Validation loss: 2.569518655069109

Epoch: 414| Step: 0
Training loss: 2.340387602762532
Validation loss: 2.5727581028285007

Epoch: 6| Step: 1
Training loss: 2.549599623570147
Validation loss: 2.5871063199257276

Epoch: 6| Step: 2
Training loss: 2.1037804907018844
Validation loss: 2.592169203709092

Epoch: 6| Step: 3
Training loss: 2.927043891903467
Validation loss: 2.5697671382944263

Epoch: 6| Step: 4
Training loss: 3.4258660161352275
Validation loss: 2.564824665325386

Epoch: 6| Step: 5
Training loss: 3.2873519109870064
Validation loss: 2.566820969063246

Epoch: 6| Step: 6
Training loss: 2.5800402376452682
Validation loss: 2.5701736775262782

Epoch: 6| Step: 7
Training loss: 2.7897261997263634
Validation loss: 2.567652328417257

Epoch: 6| Step: 8
Training loss: 2.797273064102575
Validation loss: 2.588301184560052

Epoch: 6| Step: 9
Training loss: 2.544978646898906
Validation loss: 2.5891463196082154

Epoch: 6| Step: 10
Training loss: 3.5585492630657813
Validation loss: 2.588707367170804

Epoch: 6| Step: 11
Training loss: 2.7660185108296362
Validation loss: 2.5838934251183865

Epoch: 6| Step: 12
Training loss: 2.8705300121509234
Validation loss: 2.575223535141368

Epoch: 6| Step: 13
Training loss: 3.2800699200969934
Validation loss: 2.574029379388333

Epoch: 415| Step: 0
Training loss: 3.0622505553506096
Validation loss: 2.5450044375116065

Epoch: 6| Step: 1
Training loss: 2.9922354671926286
Validation loss: 2.544933408185131

Epoch: 6| Step: 2
Training loss: 2.595598779881638
Validation loss: 2.534656686722743

Epoch: 6| Step: 3
Training loss: 2.689672789402141
Validation loss: 2.5390568922310646

Epoch: 6| Step: 4
Training loss: 2.869924792590306
Validation loss: 2.532220579175174

Epoch: 6| Step: 5
Training loss: 3.0930708322736344
Validation loss: 2.5255790006804206

Epoch: 6| Step: 6
Training loss: 3.226318350137746
Validation loss: 2.5333073078215467

Epoch: 6| Step: 7
Training loss: 2.3644685647366788
Validation loss: 2.531195289165382

Epoch: 6| Step: 8
Training loss: 2.365305035620045
Validation loss: 2.5367919482814276

Epoch: 6| Step: 9
Training loss: 3.024858165600012
Validation loss: 2.5409284602593623

Epoch: 6| Step: 10
Training loss: 2.6164914244590176
Validation loss: 2.5366579706495913

Epoch: 6| Step: 11
Training loss: 2.7108233425059076
Validation loss: 2.5359881138016926

Epoch: 6| Step: 12
Training loss: 3.08776770292181
Validation loss: 2.5402782584440455

Epoch: 6| Step: 13
Training loss: 3.5965493619053905
Validation loss: 2.5435530851854753

Epoch: 416| Step: 0
Training loss: 2.9525220144357163
Validation loss: 2.557657776545408

Epoch: 6| Step: 1
Training loss: 2.6860979548222716
Validation loss: 2.5704627405970677

Epoch: 6| Step: 2
Training loss: 3.3144200356517115
Validation loss: 2.589589620872361

Epoch: 6| Step: 3
Training loss: 2.784874515274686
Validation loss: 2.6063939220427472

Epoch: 6| Step: 4
Training loss: 3.448239006963628
Validation loss: 2.603042863760044

Epoch: 6| Step: 5
Training loss: 2.815219750914866
Validation loss: 2.5912511109853007

Epoch: 6| Step: 6
Training loss: 2.638170173437201
Validation loss: 2.596713882581059

Epoch: 6| Step: 7
Training loss: 2.0881776817547433
Validation loss: 2.5935275984081794

Epoch: 6| Step: 8
Training loss: 2.9938611163262228
Validation loss: 2.5999210856446195

Epoch: 6| Step: 9
Training loss: 2.8804952100340833
Validation loss: 2.5990864869698282

Epoch: 6| Step: 10
Training loss: 3.018259745528786
Validation loss: 2.6041850454030566

Epoch: 6| Step: 11
Training loss: 2.8571803941985663
Validation loss: 2.60324031736561

Epoch: 6| Step: 12
Training loss: 2.633256642717765
Validation loss: 2.607931381145881

Epoch: 6| Step: 13
Training loss: 2.693372476060414
Validation loss: 2.6175849672734643

Epoch: 417| Step: 0
Training loss: 2.9277689030235496
Validation loss: 2.627022235298422

Epoch: 6| Step: 1
Training loss: 2.894980783085794
Validation loss: 2.6134957594095414

Epoch: 6| Step: 2
Training loss: 2.9445714043490367
Validation loss: 2.604222801998091

Epoch: 6| Step: 3
Training loss: 2.297370909010318
Validation loss: 2.582385591595576

Epoch: 6| Step: 4
Training loss: 3.0418054906091867
Validation loss: 2.5770983141097448

Epoch: 6| Step: 5
Training loss: 2.6927582510496912
Validation loss: 2.5622663183782

Epoch: 6| Step: 6
Training loss: 2.7841021882573607
Validation loss: 2.5663082528447543

Epoch: 6| Step: 7
Training loss: 3.1763118286600487
Validation loss: 2.5668341346967662

Epoch: 6| Step: 8
Training loss: 3.072341830696252
Validation loss: 2.56152132125141

Epoch: 6| Step: 9
Training loss: 2.6179532425437366
Validation loss: 2.5650561609560323

Epoch: 6| Step: 10
Training loss: 3.0750293947381087
Validation loss: 2.559320557795672

Epoch: 6| Step: 11
Training loss: 3.112716183182839
Validation loss: 2.560468548780632

Epoch: 6| Step: 12
Training loss: 2.54728994909243
Validation loss: 2.5816573747807032

Epoch: 6| Step: 13
Training loss: 2.7454650072303806
Validation loss: 2.57555657578299

Epoch: 418| Step: 0
Training loss: 2.5664859567745157
Validation loss: 2.5779233135786215

Epoch: 6| Step: 1
Training loss: 1.8903723934180585
Validation loss: 2.601360424180137

Epoch: 6| Step: 2
Training loss: 2.44337293833041
Validation loss: 2.5896550715498403

Epoch: 6| Step: 3
Training loss: 3.0796837901998364
Validation loss: 2.6020722549273447

Epoch: 6| Step: 4
Training loss: 3.2509860963644375
Validation loss: 2.5978548491980074

Epoch: 6| Step: 5
Training loss: 3.3350177006058743
Validation loss: 2.591919947353018

Epoch: 6| Step: 6
Training loss: 2.9566169559409814
Validation loss: 2.603516800220298

Epoch: 6| Step: 7
Training loss: 2.648536612757587
Validation loss: 2.5988942743672454

Epoch: 6| Step: 8
Training loss: 2.8203658418551085
Validation loss: 2.610667162667094

Epoch: 6| Step: 9
Training loss: 3.0400439249178106
Validation loss: 2.601010757114066

Epoch: 6| Step: 10
Training loss: 2.7326595483882477
Validation loss: 2.6110691885228934

Epoch: 6| Step: 11
Training loss: 2.191962023754135
Validation loss: 2.5956811615939777

Epoch: 6| Step: 12
Training loss: 3.424837267274463
Validation loss: 2.56979255842023

Epoch: 6| Step: 13
Training loss: 3.162304802098772
Validation loss: 2.5580042216476757

Epoch: 419| Step: 0
Training loss: 2.892782200241184
Validation loss: 2.5562196489623257

Epoch: 6| Step: 1
Training loss: 3.261991240489058
Validation loss: 2.55517610431671

Epoch: 6| Step: 2
Training loss: 2.48066616924759
Validation loss: 2.538512053666993

Epoch: 6| Step: 3
Training loss: 2.870486157541898
Validation loss: 2.5361464851710815

Epoch: 6| Step: 4
Training loss: 2.6221758773267902
Validation loss: 2.546567320380869

Epoch: 6| Step: 5
Training loss: 3.1449465649163577
Validation loss: 2.540013412228301

Epoch: 6| Step: 6
Training loss: 2.769042925699281
Validation loss: 2.558320961464313

Epoch: 6| Step: 7
Training loss: 2.3550539173344305
Validation loss: 2.560909308759792

Epoch: 6| Step: 8
Training loss: 2.977971902216444
Validation loss: 2.558831818617462

Epoch: 6| Step: 9
Training loss: 2.6335781353827374
Validation loss: 2.5659012190743544

Epoch: 6| Step: 10
Training loss: 2.612699480973818
Validation loss: 2.579069604037432

Epoch: 6| Step: 11
Training loss: 3.559045153733096
Validation loss: 2.5701030056485323

Epoch: 6| Step: 12
Training loss: 2.6337605475896617
Validation loss: 2.5957272481868756

Epoch: 6| Step: 13
Training loss: 2.757228886824302
Validation loss: 2.5884196987911396

Epoch: 420| Step: 0
Training loss: 2.414783061612297
Validation loss: 2.5976519342596815

Epoch: 6| Step: 1
Training loss: 2.1982293893313583
Validation loss: 2.586071219508034

Epoch: 6| Step: 2
Training loss: 3.3601084773400083
Validation loss: 2.5939575895047002

Epoch: 6| Step: 3
Training loss: 2.564672712002438
Validation loss: 2.576614772829268

Epoch: 6| Step: 4
Training loss: 2.904183586286591
Validation loss: 2.5795559598285234

Epoch: 6| Step: 5
Training loss: 3.424528582352984
Validation loss: 2.563727726271033

Epoch: 6| Step: 6
Training loss: 3.1891756328306875
Validation loss: 2.5650078781609182

Epoch: 6| Step: 7
Training loss: 2.439462996158221
Validation loss: 2.590360215157758

Epoch: 6| Step: 8
Training loss: 2.0578109150317787
Validation loss: 2.562453061185896

Epoch: 6| Step: 9
Training loss: 2.846203091804048
Validation loss: 2.5774278530347963

Epoch: 6| Step: 10
Training loss: 3.0218501692563398
Validation loss: 2.5749220545474993

Epoch: 6| Step: 11
Training loss: 3.04859038751192
Validation loss: 2.578117583889703

Epoch: 6| Step: 12
Training loss: 2.6437873639291394
Validation loss: 2.5993719639636494

Epoch: 6| Step: 13
Training loss: 3.5348418206593797
Validation loss: 2.5807692663925206

Epoch: 421| Step: 0
Training loss: 2.6899521751832225
Validation loss: 2.5985072552080477

Epoch: 6| Step: 1
Training loss: 2.494536915768797
Validation loss: 2.588049475480124

Epoch: 6| Step: 2
Training loss: 3.1122853829413852
Validation loss: 2.6059174566770116

Epoch: 6| Step: 3
Training loss: 3.236555313672534
Validation loss: 2.605859239078391

Epoch: 6| Step: 4
Training loss: 3.094658612233267
Validation loss: 2.6113373513595293

Epoch: 6| Step: 5
Training loss: 2.997541691964994
Validation loss: 2.6139932151235814

Epoch: 6| Step: 6
Training loss: 2.7821311840607885
Validation loss: 2.5888476615633564

Epoch: 6| Step: 7
Training loss: 2.0582059607175855
Validation loss: 2.572559093870218

Epoch: 6| Step: 8
Training loss: 2.57136008761809
Validation loss: 2.5636610526690333

Epoch: 6| Step: 9
Training loss: 2.898026511777259
Validation loss: 2.5638470574398857

Epoch: 6| Step: 10
Training loss: 3.018035715709612
Validation loss: 2.555820843518203

Epoch: 6| Step: 11
Training loss: 3.202576232050492
Validation loss: 2.5457608284553

Epoch: 6| Step: 12
Training loss: 2.635957554332195
Validation loss: 2.5463439651515225

Epoch: 6| Step: 13
Training loss: 2.752923192087273
Validation loss: 2.5531090736632955

Epoch: 422| Step: 0
Training loss: 3.164565058227033
Validation loss: 2.5399448443709387

Epoch: 6| Step: 1
Training loss: 2.725652067228933
Validation loss: 2.551107776081215

Epoch: 6| Step: 2
Training loss: 2.479223320150728
Validation loss: 2.539175815877636

Epoch: 6| Step: 3
Training loss: 3.155321343405671
Validation loss: 2.5471837344640806

Epoch: 6| Step: 4
Training loss: 2.7161825926729413
Validation loss: 2.546617176930358

Epoch: 6| Step: 5
Training loss: 2.87979638095122
Validation loss: 2.5566815163274876

Epoch: 6| Step: 6
Training loss: 2.6840733706171673
Validation loss: 2.5527643724398468

Epoch: 6| Step: 7
Training loss: 2.7617796981539375
Validation loss: 2.5574946466532498

Epoch: 6| Step: 8
Training loss: 2.54226829620809
Validation loss: 2.549405773528084

Epoch: 6| Step: 9
Training loss: 2.958067617885437
Validation loss: 2.5573219969348258

Epoch: 6| Step: 10
Training loss: 2.0491502070480148
Validation loss: 2.5654169873314308

Epoch: 6| Step: 11
Training loss: 2.9546238562045137
Validation loss: 2.5770189773556895

Epoch: 6| Step: 12
Training loss: 3.341038112236889
Validation loss: 2.580621855063973

Epoch: 6| Step: 13
Training loss: 3.3020025939376687
Validation loss: 2.599511675889711

Epoch: 423| Step: 0
Training loss: 3.1295880016674182
Validation loss: 2.611179835121227

Epoch: 6| Step: 1
Training loss: 3.1506185620618052
Validation loss: 2.607902261073519

Epoch: 6| Step: 2
Training loss: 2.476900480776065
Validation loss: 2.626640608948067

Epoch: 6| Step: 3
Training loss: 2.869661100894037
Validation loss: 2.631333240438208

Epoch: 6| Step: 4
Training loss: 3.111029563319458
Validation loss: 2.6254153628637975

Epoch: 6| Step: 5
Training loss: 2.506231171877337
Validation loss: 2.6365213406707695

Epoch: 6| Step: 6
Training loss: 3.086737497669117
Validation loss: 2.608612201548036

Epoch: 6| Step: 7
Training loss: 2.247455111385242
Validation loss: 2.610545201970424

Epoch: 6| Step: 8
Training loss: 2.913313454910072
Validation loss: 2.577198431594046

Epoch: 6| Step: 9
Training loss: 2.377866320382595
Validation loss: 2.553197818696222

Epoch: 6| Step: 10
Training loss: 3.055079286236354
Validation loss: 2.538688540500661

Epoch: 6| Step: 11
Training loss: 2.956869828972158
Validation loss: 2.5626511167822104

Epoch: 6| Step: 12
Training loss: 2.7954643570755264
Validation loss: 2.548501299797504

Epoch: 6| Step: 13
Training loss: 3.062168336931537
Validation loss: 2.5403854258170204

Epoch: 424| Step: 0
Training loss: 2.6048643677999417
Validation loss: 2.538239862220383

Epoch: 6| Step: 1
Training loss: 2.859349985482284
Validation loss: 2.548391315939066

Epoch: 6| Step: 2
Training loss: 2.7371202039933133
Validation loss: 2.5398159164451117

Epoch: 6| Step: 3
Training loss: 2.8694523900986697
Validation loss: 2.5484366612659257

Epoch: 6| Step: 4
Training loss: 3.0706980999414264
Validation loss: 2.553033154660173

Epoch: 6| Step: 5
Training loss: 2.8800755355784
Validation loss: 2.5505365900957577

Epoch: 6| Step: 6
Training loss: 2.2698505853221924
Validation loss: 2.556064599450824

Epoch: 6| Step: 7
Training loss: 2.93073483883422
Validation loss: 2.543729631444645

Epoch: 6| Step: 8
Training loss: 2.822303217337223
Validation loss: 2.5610692621856765

Epoch: 6| Step: 9
Training loss: 2.2857406521025774
Validation loss: 2.551743691006062

Epoch: 6| Step: 10
Training loss: 3.1901853133280555
Validation loss: 2.5622423003901225

Epoch: 6| Step: 11
Training loss: 3.3684970229924045
Validation loss: 2.55874715040066

Epoch: 6| Step: 12
Training loss: 2.8531733731266913
Validation loss: 2.5647951377927733

Epoch: 6| Step: 13
Training loss: 2.934658055572609
Validation loss: 2.5851797345559118

Epoch: 425| Step: 0
Training loss: 2.1563799169350677
Validation loss: 2.57650235329998

Epoch: 6| Step: 1
Training loss: 2.7487316674648548
Validation loss: 2.5774637328228014

Epoch: 6| Step: 2
Training loss: 2.9096459677412256
Validation loss: 2.5642950352286835

Epoch: 6| Step: 3
Training loss: 2.782114130428334
Validation loss: 2.5551294493485797

Epoch: 6| Step: 4
Training loss: 2.887590289665284
Validation loss: 2.5642056264922304

Epoch: 6| Step: 5
Training loss: 3.427781672572543
Validation loss: 2.552605136936828

Epoch: 6| Step: 6
Training loss: 3.747831862237491
Validation loss: 2.545103309346582

Epoch: 6| Step: 7
Training loss: 2.217024763720062
Validation loss: 2.5513038240037527

Epoch: 6| Step: 8
Training loss: 2.5190933675025935
Validation loss: 2.536393249758862

Epoch: 6| Step: 9
Training loss: 2.4111624770350133
Validation loss: 2.5306877890288355

Epoch: 6| Step: 10
Training loss: 3.018576645069362
Validation loss: 2.5275277424239944

Epoch: 6| Step: 11
Training loss: 3.0818655455395345
Validation loss: 2.5379414855144415

Epoch: 6| Step: 12
Training loss: 2.9236947171259513
Validation loss: 2.5351162694680753

Epoch: 6| Step: 13
Training loss: 2.327917819437352
Validation loss: 2.5380724227475953

Epoch: 426| Step: 0
Training loss: 2.6994404460218515
Validation loss: 2.53927418977216

Epoch: 6| Step: 1
Training loss: 3.083138038705119
Validation loss: 2.540646428630585

Epoch: 6| Step: 2
Training loss: 2.8235345330846378
Validation loss: 2.557469984410163

Epoch: 6| Step: 3
Training loss: 3.195066409905825
Validation loss: 2.56447698332761

Epoch: 6| Step: 4
Training loss: 3.4033829408243985
Validation loss: 2.57243344938652

Epoch: 6| Step: 5
Training loss: 2.8975193595074913
Validation loss: 2.5882044492653433

Epoch: 6| Step: 6
Training loss: 3.206651040142895
Validation loss: 2.5899216604886606

Epoch: 6| Step: 7
Training loss: 2.7254447504076125
Validation loss: 2.5964381993177317

Epoch: 6| Step: 8
Training loss: 2.1569935719018902
Validation loss: 2.584142917981692

Epoch: 6| Step: 9
Training loss: 2.855950644934837
Validation loss: 2.585186951907282

Epoch: 6| Step: 10
Training loss: 2.7088567570314135
Validation loss: 2.578565899042419

Epoch: 6| Step: 11
Training loss: 2.880899595852705
Validation loss: 2.601939941034702

Epoch: 6| Step: 12
Training loss: 2.46601967789347
Validation loss: 2.5981816844381034

Epoch: 6| Step: 13
Training loss: 1.784884242196502
Validation loss: 2.597404239410909

Epoch: 427| Step: 0
Training loss: 3.3320082096855077
Validation loss: 2.602784687830563

Epoch: 6| Step: 1
Training loss: 2.221051379217954
Validation loss: 2.5940177463989564

Epoch: 6| Step: 2
Training loss: 3.5070163698447967
Validation loss: 2.6114323334514435

Epoch: 6| Step: 3
Training loss: 2.7409016346697044
Validation loss: 2.5674881805276635

Epoch: 6| Step: 4
Training loss: 3.3868347640884817
Validation loss: 2.5710925971114627

Epoch: 6| Step: 5
Training loss: 2.158883076571231
Validation loss: 2.551708185994065

Epoch: 6| Step: 6
Training loss: 2.6079316858811037
Validation loss: 2.544669106919367

Epoch: 6| Step: 7
Training loss: 2.56762629152866
Validation loss: 2.547574443790309

Epoch: 6| Step: 8
Training loss: 3.1125593126153177
Validation loss: 2.532676308095837

Epoch: 6| Step: 9
Training loss: 2.6559017177460036
Validation loss: 2.5319429408982503

Epoch: 6| Step: 10
Training loss: 2.6344376707032398
Validation loss: 2.547664435181817

Epoch: 6| Step: 11
Training loss: 2.7145593727520128
Validation loss: 2.5528785613439755

Epoch: 6| Step: 12
Training loss: 2.8818849141255036
Validation loss: 2.549698666111113

Epoch: 6| Step: 13
Training loss: 2.9943669203153784
Validation loss: 2.5608345049717958

Epoch: 428| Step: 0
Training loss: 3.4442206142534535
Validation loss: 2.5560106303941286

Epoch: 6| Step: 1
Training loss: 2.6408621777441548
Validation loss: 2.5653291117145396

Epoch: 6| Step: 2
Training loss: 1.6820732029964236
Validation loss: 2.554019672727733

Epoch: 6| Step: 3
Training loss: 2.753900016615286
Validation loss: 2.563169776509449

Epoch: 6| Step: 4
Training loss: 2.8333131191056165
Validation loss: 2.5783784465193325

Epoch: 6| Step: 5
Training loss: 2.5967107213616556
Validation loss: 2.5710062207342057

Epoch: 6| Step: 6
Training loss: 2.8748402758472165
Validation loss: 2.565186126900397

Epoch: 6| Step: 7
Training loss: 2.73962813269437
Validation loss: 2.56036539256625

Epoch: 6| Step: 8
Training loss: 2.888928549649165
Validation loss: 2.565169269007755

Epoch: 6| Step: 9
Training loss: 2.8340932350624697
Validation loss: 2.5639995876207173

Epoch: 6| Step: 10
Training loss: 2.611191899377749
Validation loss: 2.566590319820301

Epoch: 6| Step: 11
Training loss: 3.489009494951164
Validation loss: 2.5466067808758894

Epoch: 6| Step: 12
Training loss: 3.039510110483424
Validation loss: 2.5672571009204828

Epoch: 6| Step: 13
Training loss: 2.9901967410678796
Validation loss: 2.587376848432591

Epoch: 429| Step: 0
Training loss: 2.7633385123590486
Validation loss: 2.5765688836556495

Epoch: 6| Step: 1
Training loss: 2.6268028244642347
Validation loss: 2.5956604967806993

Epoch: 6| Step: 2
Training loss: 3.223051141762189
Validation loss: 2.6006243871042676

Epoch: 6| Step: 3
Training loss: 2.9223467604091287
Validation loss: 2.5909653319048784

Epoch: 6| Step: 4
Training loss: 3.3284920503470685
Validation loss: 2.584179885077069

Epoch: 6| Step: 5
Training loss: 2.140740161777366
Validation loss: 2.580719645448172

Epoch: 6| Step: 6
Training loss: 2.6782525226941134
Validation loss: 2.573265966331339

Epoch: 6| Step: 7
Training loss: 2.661463389730907
Validation loss: 2.564284161981151

Epoch: 6| Step: 8
Training loss: 3.247826656507803
Validation loss: 2.5473447998391396

Epoch: 6| Step: 9
Training loss: 2.892836101394908
Validation loss: 2.5454073175620415

Epoch: 6| Step: 10
Training loss: 2.744668300300478
Validation loss: 2.5313772992171826

Epoch: 6| Step: 11
Training loss: 2.6720604190848203
Validation loss: 2.539917502503607

Epoch: 6| Step: 12
Training loss: 2.4744465449955726
Validation loss: 2.5331392478050834

Epoch: 6| Step: 13
Training loss: 3.2799585616587796
Validation loss: 2.5308859525492284

Epoch: 430| Step: 0
Training loss: 2.767368435235079
Validation loss: 2.5382237060931683

Epoch: 6| Step: 1
Training loss: 2.9683795898648757
Validation loss: 2.534003739495849

Epoch: 6| Step: 2
Training loss: 2.649499640820924
Validation loss: 2.5387637887932484

Epoch: 6| Step: 3
Training loss: 2.66924106984486
Validation loss: 2.5507162199804756

Epoch: 6| Step: 4
Training loss: 3.014850734476232
Validation loss: 2.576295181305486

Epoch: 6| Step: 5
Training loss: 2.877110908775761
Validation loss: 2.58533190751851

Epoch: 6| Step: 6
Training loss: 3.4761045004233933
Validation loss: 2.6092104148526634

Epoch: 6| Step: 7
Training loss: 2.805499456073475
Validation loss: 2.5851122942859677

Epoch: 6| Step: 8
Training loss: 3.0128432968618384
Validation loss: 2.598814223922847

Epoch: 6| Step: 9
Training loss: 2.0666333021526597
Validation loss: 2.581517521823866

Epoch: 6| Step: 10
Training loss: 3.391462934468909
Validation loss: 2.5756316845730156

Epoch: 6| Step: 11
Training loss: 2.5914323862371877
Validation loss: 2.563262468358286

Epoch: 6| Step: 12
Training loss: 2.585552820826182
Validation loss: 2.572395873489527

Epoch: 6| Step: 13
Training loss: 2.4446700839700246
Validation loss: 2.5613147336454656

Epoch: 431| Step: 0
Training loss: 3.254586724503505
Validation loss: 2.548824641872401

Epoch: 6| Step: 1
Training loss: 2.726058432430671
Validation loss: 2.569574726892151

Epoch: 6| Step: 2
Training loss: 3.089290294439069
Validation loss: 2.5544385324283794

Epoch: 6| Step: 3
Training loss: 3.1520371222948356
Validation loss: 2.5775394673451553

Epoch: 6| Step: 4
Training loss: 3.122655981243734
Validation loss: 2.5695057765651192

Epoch: 6| Step: 5
Training loss: 2.6696879933966406
Validation loss: 2.584613492453282

Epoch: 6| Step: 6
Training loss: 2.6119833147821674
Validation loss: 2.5758622597229057

Epoch: 6| Step: 7
Training loss: 2.7371224687387503
Validation loss: 2.574935707431

Epoch: 6| Step: 8
Training loss: 2.778046037648131
Validation loss: 2.5597344899094225

Epoch: 6| Step: 9
Training loss: 2.3281732336590664
Validation loss: 2.5673420816317734

Epoch: 6| Step: 10
Training loss: 2.4327487121334004
Validation loss: 2.5589701233154964

Epoch: 6| Step: 11
Training loss: 3.053298985844729
Validation loss: 2.561259150614362

Epoch: 6| Step: 12
Training loss: 2.548149959918215
Validation loss: 2.55572094134322

Epoch: 6| Step: 13
Training loss: 2.863103051774946
Validation loss: 2.5623355385512703

Epoch: 432| Step: 0
Training loss: 2.3393972031245176
Validation loss: 2.5679877870296943

Epoch: 6| Step: 1
Training loss: 2.8362421549944528
Validation loss: 2.5686967418309234

Epoch: 6| Step: 2
Training loss: 2.831165849727732
Validation loss: 2.567733710275776

Epoch: 6| Step: 3
Training loss: 2.998515397531485
Validation loss: 2.569715987023725

Epoch: 6| Step: 4
Training loss: 2.8774826277300414
Validation loss: 2.575773200746157

Epoch: 6| Step: 5
Training loss: 2.9764035800751842
Validation loss: 2.5876376890936457

Epoch: 6| Step: 6
Training loss: 2.7880764455015745
Validation loss: 2.5825329737230946

Epoch: 6| Step: 7
Training loss: 2.9979212234458905
Validation loss: 2.5800577475745015

Epoch: 6| Step: 8
Training loss: 3.2741817820889367
Validation loss: 2.5824761895560213

Epoch: 6| Step: 9
Training loss: 2.9308213951540902
Validation loss: 2.582455034896039

Epoch: 6| Step: 10
Training loss: 2.633685864218487
Validation loss: 2.587244619304358

Epoch: 6| Step: 11
Training loss: 2.599383200329602
Validation loss: 2.5866599904451943

Epoch: 6| Step: 12
Training loss: 2.988499851583573
Validation loss: 2.589436643731718

Epoch: 6| Step: 13
Training loss: 1.8985623291168252
Validation loss: 2.5831148417072556

Epoch: 433| Step: 0
Training loss: 2.1386153540262463
Validation loss: 2.5529515587452574

Epoch: 6| Step: 1
Training loss: 2.9550403660632925
Validation loss: 2.540201327217885

Epoch: 6| Step: 2
Training loss: 3.0149555945724393
Validation loss: 2.5398410256700754

Epoch: 6| Step: 3
Training loss: 2.5278499986534286
Validation loss: 2.544389579110254

Epoch: 6| Step: 4
Training loss: 2.4982098846100733
Validation loss: 2.550889532866969

Epoch: 6| Step: 5
Training loss: 3.536000120490922
Validation loss: 2.5552692657207725

Epoch: 6| Step: 6
Training loss: 3.009473624351359
Validation loss: 2.568440324722665

Epoch: 6| Step: 7
Training loss: 2.4414882798719213
Validation loss: 2.5558977880650233

Epoch: 6| Step: 8
Training loss: 3.0366964274126484
Validation loss: 2.5617786825891384

Epoch: 6| Step: 9
Training loss: 3.0917937904675075
Validation loss: 2.5559641335868997

Epoch: 6| Step: 10
Training loss: 3.5618372518209576
Validation loss: 2.558091479006518

Epoch: 6| Step: 11
Training loss: 2.2580969608190986
Validation loss: 2.5449580700272576

Epoch: 6| Step: 12
Training loss: 2.618599672941885
Validation loss: 2.5562298905883667

Epoch: 6| Step: 13
Training loss: 1.9257999442471825
Validation loss: 2.5375592775895757

Epoch: 434| Step: 0
Training loss: 2.408379541325595
Validation loss: 2.533516063344492

Epoch: 6| Step: 1
Training loss: 3.113368551257932
Validation loss: 2.5332249029723113

Epoch: 6| Step: 2
Training loss: 2.9067633390828425
Validation loss: 2.53052303398566

Epoch: 6| Step: 3
Training loss: 2.268065933211065
Validation loss: 2.5305056716367123

Epoch: 6| Step: 4
Training loss: 3.1269377232112103
Validation loss: 2.541107322623124

Epoch: 6| Step: 5
Training loss: 3.5437137447164364
Validation loss: 2.5258445200195667

Epoch: 6| Step: 6
Training loss: 2.39022295195245
Validation loss: 2.5407389644472547

Epoch: 6| Step: 7
Training loss: 2.591966130494544
Validation loss: 2.5423741051232547

Epoch: 6| Step: 8
Training loss: 2.2096260413782276
Validation loss: 2.539760501861037

Epoch: 6| Step: 9
Training loss: 3.1110933242773804
Validation loss: 2.5477474189805673

Epoch: 6| Step: 10
Training loss: 2.9763465462589758
Validation loss: 2.5492612379057054

Epoch: 6| Step: 11
Training loss: 3.0760633661417853
Validation loss: 2.575166330959927

Epoch: 6| Step: 12
Training loss: 2.4624538049382934
Validation loss: 2.558038679174338

Epoch: 6| Step: 13
Training loss: 3.284000079880968
Validation loss: 2.5732911237529685

Epoch: 435| Step: 0
Training loss: 3.344816804211458
Validation loss: 2.53837330490911

Epoch: 6| Step: 1
Training loss: 3.1590023315266516
Validation loss: 2.5639534946601303

Epoch: 6| Step: 2
Training loss: 2.6307482678259877
Validation loss: 2.553570999662277

Epoch: 6| Step: 3
Training loss: 2.9052673647520564
Validation loss: 2.549426558856364

Epoch: 6| Step: 4
Training loss: 2.316246503239569
Validation loss: 2.54670427984405

Epoch: 6| Step: 5
Training loss: 2.8587472362029573
Validation loss: 2.5626719747481554

Epoch: 6| Step: 6
Training loss: 3.5032442588141155
Validation loss: 2.5435778501128405

Epoch: 6| Step: 7
Training loss: 2.5560918558536825
Validation loss: 2.553536053158921

Epoch: 6| Step: 8
Training loss: 2.3827671734610547
Validation loss: 2.54609129294144

Epoch: 6| Step: 9
Training loss: 2.4684014376101886
Validation loss: 2.5539012696442813

Epoch: 6| Step: 10
Training loss: 2.730139716628886
Validation loss: 2.5530563284407277

Epoch: 6| Step: 11
Training loss: 2.7781546866822886
Validation loss: 2.552651575416232

Epoch: 6| Step: 12
Training loss: 2.997121383515258
Validation loss: 2.5562349853106756

Epoch: 6| Step: 13
Training loss: 2.658156036475607
Validation loss: 2.5696723241248502

Epoch: 436| Step: 0
Training loss: 2.4739246459808957
Validation loss: 2.5676715577542626

Epoch: 6| Step: 1
Training loss: 2.264951197959502
Validation loss: 2.561373188012659

Epoch: 6| Step: 2
Training loss: 2.4881875396281607
Validation loss: 2.5776246202725575

Epoch: 6| Step: 3
Training loss: 3.0514960825265374
Validation loss: 2.569186500129847

Epoch: 6| Step: 4
Training loss: 3.1883150442436046
Validation loss: 2.5695943952900135

Epoch: 6| Step: 5
Training loss: 2.882330960216261
Validation loss: 2.5680631740878432

Epoch: 6| Step: 6
Training loss: 3.131096196156771
Validation loss: 2.568088169845785

Epoch: 6| Step: 7
Training loss: 3.274640501835242
Validation loss: 2.571046398983402

Epoch: 6| Step: 8
Training loss: 2.741223635914211
Validation loss: 2.550471173886287

Epoch: 6| Step: 9
Training loss: 2.799241583153718
Validation loss: 2.555532969261588

Epoch: 6| Step: 10
Training loss: 2.607953809563149
Validation loss: 2.5527424874994242

Epoch: 6| Step: 11
Training loss: 2.7014149455099834
Validation loss: 2.5585543671668782

Epoch: 6| Step: 12
Training loss: 2.8385801166881697
Validation loss: 2.5420441396794096

Epoch: 6| Step: 13
Training loss: 2.768257827586494
Validation loss: 2.5463013653804687

Epoch: 437| Step: 0
Training loss: 2.8317837311015555
Validation loss: 2.5525628656264017

Epoch: 6| Step: 1
Training loss: 2.8906612909461753
Validation loss: 2.536151884066666

Epoch: 6| Step: 2
Training loss: 2.6878077308657713
Validation loss: 2.545366149432422

Epoch: 6| Step: 3
Training loss: 2.67873915192601
Validation loss: 2.541861540937112

Epoch: 6| Step: 4
Training loss: 2.5786792506147926
Validation loss: 2.5451099543873283

Epoch: 6| Step: 5
Training loss: 2.7126756532110368
Validation loss: 2.5513982386093623

Epoch: 6| Step: 6
Training loss: 3.193467183291044
Validation loss: 2.5380357891240837

Epoch: 6| Step: 7
Training loss: 2.945119188678526
Validation loss: 2.5340403251826022

Epoch: 6| Step: 8
Training loss: 2.4129593683608923
Validation loss: 2.5327258145700737

Epoch: 6| Step: 9
Training loss: 2.8882552046939005
Validation loss: 2.540418780162848

Epoch: 6| Step: 10
Training loss: 3.061694136489241
Validation loss: 2.545480394262122

Epoch: 6| Step: 11
Training loss: 2.7051534814357168
Validation loss: 2.5648464601666885

Epoch: 6| Step: 12
Training loss: 2.714217518544907
Validation loss: 2.5561124489083458

Epoch: 6| Step: 13
Training loss: 3.187235952174163
Validation loss: 2.559795797589108

Epoch: 438| Step: 0
Training loss: 3.100987455547489
Validation loss: 2.571761931121626

Epoch: 6| Step: 1
Training loss: 3.0527904502907224
Validation loss: 2.582734545348853

Epoch: 6| Step: 2
Training loss: 2.799619553468835
Validation loss: 2.579074503545639

Epoch: 6| Step: 3
Training loss: 2.4450360711680195
Validation loss: 2.6086761371872553

Epoch: 6| Step: 4
Training loss: 2.880285628777939
Validation loss: 2.5996805642031413

Epoch: 6| Step: 5
Training loss: 2.726461676452255
Validation loss: 2.611739081662565

Epoch: 6| Step: 6
Training loss: 2.5732053113463023
Validation loss: 2.5945424701382738

Epoch: 6| Step: 7
Training loss: 2.9009626961077912
Validation loss: 2.5740293206264555

Epoch: 6| Step: 8
Training loss: 2.522670948296449
Validation loss: 2.596177204037404

Epoch: 6| Step: 9
Training loss: 2.916271037562587
Validation loss: 2.5901590410048487

Epoch: 6| Step: 10
Training loss: 2.6882154709989425
Validation loss: 2.592198178113939

Epoch: 6| Step: 11
Training loss: 2.3725850727356783
Validation loss: 2.55428451696861

Epoch: 6| Step: 12
Training loss: 3.26493163710524
Validation loss: 2.561595016614765

Epoch: 6| Step: 13
Training loss: 3.1594964884143697
Validation loss: 2.552123461255706

Epoch: 439| Step: 0
Training loss: 2.5620088804449925
Validation loss: 2.5419441383023034

Epoch: 6| Step: 1
Training loss: 3.593607360662801
Validation loss: 2.5335812201546206

Epoch: 6| Step: 2
Training loss: 2.705649547610944
Validation loss: 2.540794975194012

Epoch: 6| Step: 3
Training loss: 2.720469490091921
Validation loss: 2.5393305720445696

Epoch: 6| Step: 4
Training loss: 2.769576703170738
Validation loss: 2.553299281992251

Epoch: 6| Step: 5
Training loss: 2.9526232742298713
Validation loss: 2.5466180235520786

Epoch: 6| Step: 6
Training loss: 2.988044440167518
Validation loss: 2.5620685587355556

Epoch: 6| Step: 7
Training loss: 2.7016978823980127
Validation loss: 2.5708174341849315

Epoch: 6| Step: 8
Training loss: 2.557574119948104
Validation loss: 2.580322121934988

Epoch: 6| Step: 9
Training loss: 2.8256680264199874
Validation loss: 2.581607065847907

Epoch: 6| Step: 10
Training loss: 2.922239882589464
Validation loss: 2.6317083775437706

Epoch: 6| Step: 11
Training loss: 2.1874012516076395
Validation loss: 2.619736669993855

Epoch: 6| Step: 12
Training loss: 3.2073828705402265
Validation loss: 2.61121724513095

Epoch: 6| Step: 13
Training loss: 2.77041383784928
Validation loss: 2.617570877708502

Epoch: 440| Step: 0
Training loss: 3.1984227346462433
Validation loss: 2.599175474056754

Epoch: 6| Step: 1
Training loss: 2.826185541442855
Validation loss: 2.5915260669576075

Epoch: 6| Step: 2
Training loss: 2.365044961868881
Validation loss: 2.577435708774719

Epoch: 6| Step: 3
Training loss: 2.542500489421486
Validation loss: 2.575300857621138

Epoch: 6| Step: 4
Training loss: 2.498431572063158
Validation loss: 2.562184998494464

Epoch: 6| Step: 5
Training loss: 3.2229863408125023
Validation loss: 2.561215792970789

Epoch: 6| Step: 6
Training loss: 2.5217586637037828
Validation loss: 2.5731440252657283

Epoch: 6| Step: 7
Training loss: 2.4244152897916416
Validation loss: 2.5636906672621285

Epoch: 6| Step: 8
Training loss: 2.370897866316658
Validation loss: 2.5585985133729414

Epoch: 6| Step: 9
Training loss: 2.990291303395473
Validation loss: 2.5542816525130543

Epoch: 6| Step: 10
Training loss: 3.1032547261915
Validation loss: 2.5906953008237976

Epoch: 6| Step: 11
Training loss: 3.1292201728834708
Validation loss: 2.56059522489194

Epoch: 6| Step: 12
Training loss: 2.780011190487959
Validation loss: 2.5541191681887088

Epoch: 6| Step: 13
Training loss: 3.3711486316868067
Validation loss: 2.557762649145261

Epoch: 441| Step: 0
Training loss: 2.5554690784068117
Validation loss: 2.551262132033664

Epoch: 6| Step: 1
Training loss: 3.2784167455376805
Validation loss: 2.527265811333443

Epoch: 6| Step: 2
Training loss: 2.187252030623149
Validation loss: 2.5268640473279462

Epoch: 6| Step: 3
Training loss: 2.946708206844821
Validation loss: 2.5283746049341174

Epoch: 6| Step: 4
Training loss: 2.462389708242046
Validation loss: 2.5244439222131607

Epoch: 6| Step: 5
Training loss: 2.8292830820154267
Validation loss: 2.520286014185974

Epoch: 6| Step: 6
Training loss: 3.1358603399085125
Validation loss: 2.530641519870976

Epoch: 6| Step: 7
Training loss: 2.939352384849727
Validation loss: 2.533384295594845

Epoch: 6| Step: 8
Training loss: 2.7320333863169015
Validation loss: 2.5329825866129365

Epoch: 6| Step: 9
Training loss: 2.605761006905634
Validation loss: 2.548958649839318

Epoch: 6| Step: 10
Training loss: 3.104256408896155
Validation loss: 2.5424168846413036

Epoch: 6| Step: 11
Training loss: 3.133073068184963
Validation loss: 2.551911393769738

Epoch: 6| Step: 12
Training loss: 2.472265516990241
Validation loss: 2.5458595621605276

Epoch: 6| Step: 13
Training loss: 2.8505825919601815
Validation loss: 2.541315041972782

Epoch: 442| Step: 0
Training loss: 2.8543095982164766
Validation loss: 2.5470981878835115

Epoch: 6| Step: 1
Training loss: 3.129234649149999
Validation loss: 2.5483368906229025

Epoch: 6| Step: 2
Training loss: 2.730291489071343
Validation loss: 2.538632677170281

Epoch: 6| Step: 3
Training loss: 2.8567067188079904
Validation loss: 2.5588272690795084

Epoch: 6| Step: 4
Training loss: 3.242173528066657
Validation loss: 2.539618882777538

Epoch: 6| Step: 5
Training loss: 2.737203649914627
Validation loss: 2.557921494429041

Epoch: 6| Step: 6
Training loss: 2.3993454994401273
Validation loss: 2.5610257021241503

Epoch: 6| Step: 7
Training loss: 2.987847829066635
Validation loss: 2.5516542011535552

Epoch: 6| Step: 8
Training loss: 2.6997812571043895
Validation loss: 2.5687413863925457

Epoch: 6| Step: 9
Training loss: 2.7277019928735378
Validation loss: 2.5565829057480514

Epoch: 6| Step: 10
Training loss: 2.974999525567025
Validation loss: 2.550258346755833

Epoch: 6| Step: 11
Training loss: 2.5334594879193766
Validation loss: 2.5461278509376943

Epoch: 6| Step: 12
Training loss: 2.7408810190390542
Validation loss: 2.567159444821569

Epoch: 6| Step: 13
Training loss: 2.367211873649787
Validation loss: 2.5535051541844913

Epoch: 443| Step: 0
Training loss: 3.0926311280706473
Validation loss: 2.555237163693098

Epoch: 6| Step: 1
Training loss: 2.7380884731201256
Validation loss: 2.5469675938710172

Epoch: 6| Step: 2
Training loss: 2.0984613731088624
Validation loss: 2.5526897969682065

Epoch: 6| Step: 3
Training loss: 2.707348737497976
Validation loss: 2.554521333302213

Epoch: 6| Step: 4
Training loss: 3.2779114223612997
Validation loss: 2.5511051110513088

Epoch: 6| Step: 5
Training loss: 2.817032869975294
Validation loss: 2.572495288045523

Epoch: 6| Step: 6
Training loss: 2.2097914458383494
Validation loss: 2.5802611400161086

Epoch: 6| Step: 7
Training loss: 2.577683659549025
Validation loss: 2.578431596421179

Epoch: 6| Step: 8
Training loss: 3.117437137560375
Validation loss: 2.5740914301864484

Epoch: 6| Step: 9
Training loss: 3.109923041271574
Validation loss: 2.569107511786652

Epoch: 6| Step: 10
Training loss: 2.3752525596849776
Validation loss: 2.5654314412755173

Epoch: 6| Step: 11
Training loss: 2.7714071229433386
Validation loss: 2.578473619623298

Epoch: 6| Step: 12
Training loss: 2.9034362626106467
Validation loss: 2.5712080728471753

Epoch: 6| Step: 13
Training loss: 3.282236005593006
Validation loss: 2.58429731556377

Epoch: 444| Step: 0
Training loss: 2.2492198651262325
Validation loss: 2.5941710492973673

Epoch: 6| Step: 1
Training loss: 2.670300292940848
Validation loss: 2.5696517664102543

Epoch: 6| Step: 2
Training loss: 2.606802854744608
Validation loss: 2.575740085253101

Epoch: 6| Step: 3
Training loss: 3.299001288287422
Validation loss: 2.5853132552695794

Epoch: 6| Step: 4
Training loss: 2.843617027443585
Validation loss: 2.5555107679524927

Epoch: 6| Step: 5
Training loss: 3.0399112251771445
Validation loss: 2.575463935705253

Epoch: 6| Step: 6
Training loss: 3.228559194871991
Validation loss: 2.5432672475536573

Epoch: 6| Step: 7
Training loss: 3.1446264785658196
Validation loss: 2.5368789388468205

Epoch: 6| Step: 8
Training loss: 2.7134913307446493
Validation loss: 2.53984798426085

Epoch: 6| Step: 9
Training loss: 3.1053686353752377
Validation loss: 2.541619840204379

Epoch: 6| Step: 10
Training loss: 2.9558554646176396
Validation loss: 2.5512652139126213

Epoch: 6| Step: 11
Training loss: 2.555429706607599
Validation loss: 2.5477175989386414

Epoch: 6| Step: 12
Training loss: 2.0961658717034624
Validation loss: 2.5603037751048356

Epoch: 6| Step: 13
Training loss: 2.051337815101413
Validation loss: 2.572037927941273

Epoch: 445| Step: 0
Training loss: 2.6640820991936223
Validation loss: 2.5789403387463845

Epoch: 6| Step: 1
Training loss: 2.844139826957466
Validation loss: 2.592965445363002

Epoch: 6| Step: 2
Training loss: 2.927681279225847
Validation loss: 2.618808574032704

Epoch: 6| Step: 3
Training loss: 3.2663652229059106
Validation loss: 2.6093730203160375

Epoch: 6| Step: 4
Training loss: 2.936724621319616
Validation loss: 2.6167776076693174

Epoch: 6| Step: 5
Training loss: 3.060286831595722
Validation loss: 2.601975681838663

Epoch: 6| Step: 6
Training loss: 2.5360519637190215
Validation loss: 2.587980638959678

Epoch: 6| Step: 7
Training loss: 3.1064427030109285
Validation loss: 2.5553266996233766

Epoch: 6| Step: 8
Training loss: 2.5961762995170083
Validation loss: 2.5532313842033107

Epoch: 6| Step: 9
Training loss: 2.761469331995471
Validation loss: 2.5352655420041965

Epoch: 6| Step: 10
Training loss: 2.7201878921743052
Validation loss: 2.5323782467047455

Epoch: 6| Step: 11
Training loss: 1.888780434929394
Validation loss: 2.526676488855574

Epoch: 6| Step: 12
Training loss: 3.1414365716214148
Validation loss: 2.532515098900021

Epoch: 6| Step: 13
Training loss: 2.5404953889525292
Validation loss: 2.526053817173455

Epoch: 446| Step: 0
Training loss: 2.628305352335601
Validation loss: 2.524692812533169

Epoch: 6| Step: 1
Training loss: 2.7813424084345573
Validation loss: 2.538127745910679

Epoch: 6| Step: 2
Training loss: 2.711348093033777
Validation loss: 2.5183449483024725

Epoch: 6| Step: 3
Training loss: 3.2664923725211374
Validation loss: 2.5283530330961916

Epoch: 6| Step: 4
Training loss: 2.8465252423797986
Validation loss: 2.5423980183827655

Epoch: 6| Step: 5
Training loss: 2.8634429511276793
Validation loss: 2.5362274603224546

Epoch: 6| Step: 6
Training loss: 3.055942755547477
Validation loss: 2.5464494597442062

Epoch: 6| Step: 7
Training loss: 2.522666789836491
Validation loss: 2.550535232154282

Epoch: 6| Step: 8
Training loss: 2.778310272252289
Validation loss: 2.569355998853845

Epoch: 6| Step: 9
Training loss: 3.1061513474454694
Validation loss: 2.5783266785991397

Epoch: 6| Step: 10
Training loss: 2.72716316667762
Validation loss: 2.603197253201359

Epoch: 6| Step: 11
Training loss: 2.6303773026280677
Validation loss: 2.6047969874015386

Epoch: 6| Step: 12
Training loss: 2.7201453826422517
Validation loss: 2.585550832817502

Epoch: 6| Step: 13
Training loss: 2.56313278944929
Validation loss: 2.589262762472624

Epoch: 447| Step: 0
Training loss: 2.871589960308833
Validation loss: 2.586327598499327

Epoch: 6| Step: 1
Training loss: 2.766153920776596
Validation loss: 2.5793938888575028

Epoch: 6| Step: 2
Training loss: 2.8207801156445056
Validation loss: 2.586665233362805

Epoch: 6| Step: 3
Training loss: 2.5620743933067947
Validation loss: 2.572497582120905

Epoch: 6| Step: 4
Training loss: 2.9887064712271068
Validation loss: 2.5917043248001197

Epoch: 6| Step: 5
Training loss: 2.6066803867274952
Validation loss: 2.5744174245292255

Epoch: 6| Step: 6
Training loss: 2.91557882094534
Validation loss: 2.5893770516696866

Epoch: 6| Step: 7
Training loss: 3.4896818384339987
Validation loss: 2.6267812284492433

Epoch: 6| Step: 8
Training loss: 2.723197193672805
Validation loss: 2.6372900588404597

Epoch: 6| Step: 9
Training loss: 3.1108692355212706
Validation loss: 2.6003143963700754

Epoch: 6| Step: 10
Training loss: 2.756809906088355
Validation loss: 2.5873042426462476

Epoch: 6| Step: 11
Training loss: 2.2964113766650054
Validation loss: 2.5590096555315927

Epoch: 6| Step: 12
Training loss: 2.8250668678134305
Validation loss: 2.541203441162395

Epoch: 6| Step: 13
Training loss: 1.9600986343010816
Validation loss: 2.5354555823806164

Epoch: 448| Step: 0
Training loss: 2.751899410072828
Validation loss: 2.527682294878652

Epoch: 6| Step: 1
Training loss: 2.9116873790380575
Validation loss: 2.531535003064489

Epoch: 6| Step: 2
Training loss: 2.4959526678818245
Validation loss: 2.5276860840234567

Epoch: 6| Step: 3
Training loss: 2.946926170705812
Validation loss: 2.534176127334678

Epoch: 6| Step: 4
Training loss: 2.6333570511470112
Validation loss: 2.5254498611300713

Epoch: 6| Step: 5
Training loss: 2.409937918247254
Validation loss: 2.5267116952411395

Epoch: 6| Step: 6
Training loss: 2.7482963833735723
Validation loss: 2.527177164007141

Epoch: 6| Step: 7
Training loss: 3.1963773785728806
Validation loss: 2.5239927533795865

Epoch: 6| Step: 8
Training loss: 2.6109691022128088
Validation loss: 2.5253573300162424

Epoch: 6| Step: 9
Training loss: 2.852711401685876
Validation loss: 2.5435169961538215

Epoch: 6| Step: 10
Training loss: 3.4298198561448485
Validation loss: 2.551449314005772

Epoch: 6| Step: 11
Training loss: 2.6020527512336558
Validation loss: 2.5649668367206515

Epoch: 6| Step: 12
Training loss: 2.9523866729563712
Validation loss: 2.5893323351889372

Epoch: 6| Step: 13
Training loss: 2.3575137040679452
Validation loss: 2.5970512786690354

Epoch: 449| Step: 0
Training loss: 3.13604919204277
Validation loss: 2.6255379695420054

Epoch: 6| Step: 1
Training loss: 1.6558358016409265
Validation loss: 2.647326348464361

Epoch: 6| Step: 2
Training loss: 2.590479984066961
Validation loss: 2.6362861480776205

Epoch: 6| Step: 3
Training loss: 2.8086344964012318
Validation loss: 2.6600035300328932

Epoch: 6| Step: 4
Training loss: 2.7729252731759066
Validation loss: 2.669702408079474

Epoch: 6| Step: 5
Training loss: 2.192368675135376
Validation loss: 2.6479264857527394

Epoch: 6| Step: 6
Training loss: 3.2794156714727807
Validation loss: 2.645623641020933

Epoch: 6| Step: 7
Training loss: 3.115778477905075
Validation loss: 2.623864906562509

Epoch: 6| Step: 8
Training loss: 2.7666512002474337
Validation loss: 2.5741922631534107

Epoch: 6| Step: 9
Training loss: 3.163209701335658
Validation loss: 2.575669519327373

Epoch: 6| Step: 10
Training loss: 2.097624879740989
Validation loss: 2.56061251437223

Epoch: 6| Step: 11
Training loss: 2.4916917074554874
Validation loss: 2.5532117724981154

Epoch: 6| Step: 12
Training loss: 3.497839533349409
Validation loss: 2.5408459842493007

Epoch: 6| Step: 13
Training loss: 3.2435902697681724
Validation loss: 2.5735642052291894

Epoch: 450| Step: 0
Training loss: 2.721837625345483
Validation loss: 2.52995513890834

Epoch: 6| Step: 1
Training loss: 2.82443417984546
Validation loss: 2.5174260582123

Epoch: 6| Step: 2
Training loss: 2.0936374918757297
Validation loss: 2.518790757317115

Epoch: 6| Step: 3
Training loss: 2.941407871119241
Validation loss: 2.5252277974101647

Epoch: 6| Step: 4
Training loss: 2.643237655450629
Validation loss: 2.5230894705621183

Epoch: 6| Step: 5
Training loss: 2.5938715159435217
Validation loss: 2.531490567188792

Epoch: 6| Step: 6
Training loss: 2.944302575474339
Validation loss: 2.5339743880108005

Epoch: 6| Step: 7
Training loss: 2.9572418420098465
Validation loss: 2.5574590671091095

Epoch: 6| Step: 8
Training loss: 3.330811611623579
Validation loss: 2.539548093492443

Epoch: 6| Step: 9
Training loss: 2.812844403690645
Validation loss: 2.544589606364341

Epoch: 6| Step: 10
Training loss: 2.911773846521837
Validation loss: 2.537115557980556

Epoch: 6| Step: 11
Training loss: 3.1307155983050747
Validation loss: 2.5352069447638277

Epoch: 6| Step: 12
Training loss: 2.4643197205371052
Validation loss: 2.530614014677287

Epoch: 6| Step: 13
Training loss: 2.8546649098872705
Validation loss: 2.514572809095403

Testing loss: 2.7282896909056475
