Epoch: 1| Step: 0
Training loss: 4.942923741793666
Validation loss: 5.786310115181663

Epoch: 5| Step: 1
Training loss: 5.307616019577838
Validation loss: 5.781998535936986

Epoch: 5| Step: 2
Training loss: 4.867762744397285
Validation loss: 5.777388304910959

Epoch: 5| Step: 3
Training loss: 6.072003967203445
Validation loss: 5.772680279421288

Epoch: 5| Step: 4
Training loss: 6.067693314649689
Validation loss: 5.768018651017237

Epoch: 5| Step: 5
Training loss: 7.376230945339522
Validation loss: 5.763077355426413

Epoch: 5| Step: 6
Training loss: 6.2320188118842905
Validation loss: 5.758110862026773

Epoch: 5| Step: 7
Training loss: 4.896066581634869
Validation loss: 5.752655459416307

Epoch: 5| Step: 8
Training loss: 5.014790022800389
Validation loss: 5.747342387661609

Epoch: 5| Step: 9
Training loss: 5.957077996742811
Validation loss: 5.741533867397001

Epoch: 5| Step: 10
Training loss: 6.580419579668337
Validation loss: 5.735739501205271

Epoch: 2| Step: 0
Training loss: 5.5264533845603685
Validation loss: 5.729732889812711

Epoch: 5| Step: 1
Training loss: 6.611751913577764
Validation loss: 5.72298719079257

Epoch: 5| Step: 2
Training loss: 5.267739977699758
Validation loss: 5.716190046014749

Epoch: 5| Step: 3
Training loss: 7.012465685320176
Validation loss: 5.708907079759095

Epoch: 5| Step: 4
Training loss: 5.142464444895715
Validation loss: 5.701297834907474

Epoch: 5| Step: 5
Training loss: 6.443123740576224
Validation loss: 5.693683874342562

Epoch: 5| Step: 6
Training loss: 5.448462649156899
Validation loss: 5.6849970583333995

Epoch: 5| Step: 7
Training loss: 5.3415169316499895
Validation loss: 5.67675420599761

Epoch: 5| Step: 8
Training loss: 4.962746694279985
Validation loss: 5.667236836296797

Epoch: 5| Step: 9
Training loss: 5.901901339619921
Validation loss: 5.6584543924923665

Epoch: 5| Step: 10
Training loss: 4.785419516035978
Validation loss: 5.6479026466204365

Epoch: 3| Step: 0
Training loss: 4.1281448860469165
Validation loss: 5.637772484544669

Epoch: 5| Step: 1
Training loss: 6.217228535614764
Validation loss: 5.626920983229475

Epoch: 5| Step: 2
Training loss: 4.409528662304129
Validation loss: 5.616055580729363

Epoch: 5| Step: 3
Training loss: 5.4399133347171444
Validation loss: 5.603421659850575

Epoch: 5| Step: 4
Training loss: 4.904709106281057
Validation loss: 5.591770896504419

Epoch: 5| Step: 5
Training loss: 6.729924902305658
Validation loss: 5.579719304360132

Epoch: 5| Step: 6
Training loss: 6.456453734854937
Validation loss: 5.565911697959577

Epoch: 5| Step: 7
Training loss: 6.578190529105024
Validation loss: 5.552061543287899

Epoch: 5| Step: 8
Training loss: 5.459354897141633
Validation loss: 5.53750436396973

Epoch: 5| Step: 9
Training loss: 4.263946538335947
Validation loss: 5.522813653187332

Epoch: 5| Step: 10
Training loss: 6.420614374063411
Validation loss: 5.507740342781647

Epoch: 4| Step: 0
Training loss: 4.237583872997498
Validation loss: 5.490769001650583

Epoch: 5| Step: 1
Training loss: 5.583164535172382
Validation loss: 5.474742431845297

Epoch: 5| Step: 2
Training loss: 4.736052263229267
Validation loss: 5.457012920771811

Epoch: 5| Step: 3
Training loss: 5.614437783170613
Validation loss: 5.4408876123184005

Epoch: 5| Step: 4
Training loss: 4.9824637931277636
Validation loss: 5.422423630465416

Epoch: 5| Step: 5
Training loss: 6.051016402184985
Validation loss: 5.403890304955706

Epoch: 5| Step: 6
Training loss: 5.335495311907665
Validation loss: 5.384652769206204

Epoch: 5| Step: 7
Training loss: 6.479994873233227
Validation loss: 5.3658854612582125

Epoch: 5| Step: 8
Training loss: 6.126728358963002
Validation loss: 5.344796358992542

Epoch: 5| Step: 9
Training loss: 4.865486447830621
Validation loss: 5.3237190162827215

Epoch: 5| Step: 10
Training loss: 5.4402793708759765
Validation loss: 5.30358792778669

Epoch: 5| Step: 0
Training loss: 5.843012635736547
Validation loss: 5.280761121381637

Epoch: 5| Step: 1
Training loss: 4.857766624275783
Validation loss: 5.258975371541527

Epoch: 5| Step: 2
Training loss: 4.887607411328716
Validation loss: 5.23798525736999

Epoch: 5| Step: 3
Training loss: 5.843310987332245
Validation loss: 5.21556630742484

Epoch: 5| Step: 4
Training loss: 4.859652692213758
Validation loss: 5.191859252456901

Epoch: 5| Step: 5
Training loss: 5.750356580209661
Validation loss: 5.16995781399045

Epoch: 5| Step: 6
Training loss: 4.9306341794808946
Validation loss: 5.147351051804455

Epoch: 5| Step: 7
Training loss: 5.1374177058327755
Validation loss: 5.1247822224797135

Epoch: 5| Step: 8
Training loss: 5.423591979521242
Validation loss: 5.103396005150358

Epoch: 5| Step: 9
Training loss: 4.754243661634251
Validation loss: 5.0796689254690595

Epoch: 5| Step: 10
Training loss: 5.005802030677693
Validation loss: 5.055969419596005

Epoch: 6| Step: 0
Training loss: 5.177506161570509
Validation loss: 5.033498679475907

Epoch: 5| Step: 1
Training loss: 5.30929360958805
Validation loss: 5.0101015288046735

Epoch: 5| Step: 2
Training loss: 5.42621801388445
Validation loss: 4.98688388312437

Epoch: 5| Step: 3
Training loss: 4.182121124527567
Validation loss: 4.965171759174616

Epoch: 5| Step: 4
Training loss: 5.508588154602888
Validation loss: 4.9429023879460745

Epoch: 5| Step: 5
Training loss: 4.912188198298983
Validation loss: 4.918504863908458

Epoch: 5| Step: 6
Training loss: 4.736665983439393
Validation loss: 4.896659660205061

Epoch: 5| Step: 7
Training loss: 5.4158303813434205
Validation loss: 4.875441935837793

Epoch: 5| Step: 8
Training loss: 3.9897631545747236
Validation loss: 4.855495326849427

Epoch: 5| Step: 9
Training loss: 5.515184249774432
Validation loss: 4.833892657653988

Epoch: 5| Step: 10
Training loss: 4.356226067497813
Validation loss: 4.815306515448009

Epoch: 7| Step: 0
Training loss: 5.0899496118715755
Validation loss: 4.794609265577148

Epoch: 5| Step: 1
Training loss: 5.382690605477606
Validation loss: 4.775333167296081

Epoch: 5| Step: 2
Training loss: 4.0864616918473065
Validation loss: 4.755679467270149

Epoch: 5| Step: 3
Training loss: 5.1172689416825445
Validation loss: 4.736734931710614

Epoch: 5| Step: 4
Training loss: 5.441902044949108
Validation loss: 4.718217754112383

Epoch: 5| Step: 5
Training loss: 4.3749884469015985
Validation loss: 4.698933431619611

Epoch: 5| Step: 6
Training loss: 4.5403691576128855
Validation loss: 4.682214118444647

Epoch: 5| Step: 7
Training loss: 4.656678250479757
Validation loss: 4.6632150390016465

Epoch: 5| Step: 8
Training loss: 4.922130565971577
Validation loss: 4.645358857074613

Epoch: 5| Step: 9
Training loss: 4.642271834987369
Validation loss: 4.631222290533634

Epoch: 5| Step: 10
Training loss: 4.132194025674534
Validation loss: 4.615110358308355

Epoch: 8| Step: 0
Training loss: 4.72573133995022
Validation loss: 4.600113573584979

Epoch: 5| Step: 1
Training loss: 4.1366184643916935
Validation loss: 4.582174577903317

Epoch: 5| Step: 2
Training loss: 3.89580769793938
Validation loss: 4.567563474594768

Epoch: 5| Step: 3
Training loss: 4.443644178715948
Validation loss: 4.550471091040273

Epoch: 5| Step: 4
Training loss: 4.500827713183406
Validation loss: 4.537919472695858

Epoch: 5| Step: 5
Training loss: 4.656219482321866
Validation loss: 4.521416172280496

Epoch: 5| Step: 6
Training loss: 4.24339049759023
Validation loss: 4.506980697690214

Epoch: 5| Step: 7
Training loss: 5.134415142624476
Validation loss: 4.494501425656123

Epoch: 5| Step: 8
Training loss: 4.296130972515598
Validation loss: 4.482664500301877

Epoch: 5| Step: 9
Training loss: 5.372868492301974
Validation loss: 4.4706098887029215

Epoch: 5| Step: 10
Training loss: 5.290971825503928
Validation loss: 4.4619312889467855

Epoch: 9| Step: 0
Training loss: 4.454547641449287
Validation loss: 4.45193272166007

Epoch: 5| Step: 1
Training loss: 4.160956449963303
Validation loss: 4.439694564595525

Epoch: 5| Step: 2
Training loss: 4.028493012396538
Validation loss: 4.4301520701876145

Epoch: 5| Step: 3
Training loss: 5.4525331542184645
Validation loss: 4.421247533369331

Epoch: 5| Step: 4
Training loss: 4.255134622347086
Validation loss: 4.410287156512797

Epoch: 5| Step: 5
Training loss: 4.131701256926649
Validation loss: 4.3998129161185515

Epoch: 5| Step: 6
Training loss: 4.352911200821953
Validation loss: 4.3909354560135565

Epoch: 5| Step: 7
Training loss: 3.983152433833938
Validation loss: 4.381604251960854

Epoch: 5| Step: 8
Training loss: 5.3616404735971654
Validation loss: 4.372119031171902

Epoch: 5| Step: 9
Training loss: 4.829177889784815
Validation loss: 4.36130844031018

Epoch: 5| Step: 10
Training loss: 4.303719468840818
Validation loss: 4.352070276605841

Epoch: 10| Step: 0
Training loss: 4.365463544389927
Validation loss: 4.342654054764682

Epoch: 5| Step: 1
Training loss: 5.076617301722616
Validation loss: 4.3325305333912

Epoch: 5| Step: 2
Training loss: 4.3287925893928465
Validation loss: 4.32135447347941

Epoch: 5| Step: 3
Training loss: 4.980964474410244
Validation loss: 4.313886803796643

Epoch: 5| Step: 4
Training loss: 3.468980386317325
Validation loss: 4.302692858297891

Epoch: 5| Step: 5
Training loss: 4.621601196184841
Validation loss: 4.2942829530276105

Epoch: 5| Step: 6
Training loss: 4.223493381910986
Validation loss: 4.286873335400505

Epoch: 5| Step: 7
Training loss: 3.842879778349139
Validation loss: 4.2772748333903445

Epoch: 5| Step: 8
Training loss: 4.130082207478121
Validation loss: 4.266620242070719

Epoch: 5| Step: 9
Training loss: 4.345894702589009
Validation loss: 4.256369769099697

Epoch: 5| Step: 10
Training loss: 5.017763816690935
Validation loss: 4.2489959452470565

Epoch: 11| Step: 0
Training loss: 4.07283512954203
Validation loss: 4.239564148439553

Epoch: 5| Step: 1
Training loss: 3.0564306412497744
Validation loss: 4.229086856926526

Epoch: 5| Step: 2
Training loss: 4.047179457357752
Validation loss: 4.222088947326393

Epoch: 5| Step: 3
Training loss: 4.728589643098393
Validation loss: 4.21261567075373

Epoch: 5| Step: 4
Training loss: 4.2939916195692165
Validation loss: 4.203838189834001

Epoch: 5| Step: 5
Training loss: 4.108343074598751
Validation loss: 4.195398411043307

Epoch: 5| Step: 6
Training loss: 4.9035571051977715
Validation loss: 4.18705285760937

Epoch: 5| Step: 7
Training loss: 4.122194434246807
Validation loss: 4.179266014157817

Epoch: 5| Step: 8
Training loss: 4.515242510901378
Validation loss: 4.17151011518581

Epoch: 5| Step: 9
Training loss: 4.564373520045567
Validation loss: 4.160762328798035

Epoch: 5| Step: 10
Training loss: 4.94008385374739
Validation loss: 4.15729403684869

Epoch: 12| Step: 0
Training loss: 3.9850633213655424
Validation loss: 4.147145909083151

Epoch: 5| Step: 1
Training loss: 4.085814027397661
Validation loss: 4.1395876314987365

Epoch: 5| Step: 2
Training loss: 4.732113540435216
Validation loss: 4.132179143333113

Epoch: 5| Step: 3
Training loss: 4.565756275919002
Validation loss: 4.123730210168425

Epoch: 5| Step: 4
Training loss: 4.072213166628546
Validation loss: 4.115823520453311

Epoch: 5| Step: 5
Training loss: 4.453626316696812
Validation loss: 4.10889601991407

Epoch: 5| Step: 6
Training loss: 4.0165743763136
Validation loss: 4.101141403934852

Epoch: 5| Step: 7
Training loss: 4.850454108618537
Validation loss: 4.092785016785898

Epoch: 5| Step: 8
Training loss: 4.7439838256302895
Validation loss: 4.084008381846084

Epoch: 5| Step: 9
Training loss: 2.7084617193065017
Validation loss: 4.076210984406913

Epoch: 5| Step: 10
Training loss: 4.0810585432725865
Validation loss: 4.068152475496793

Epoch: 13| Step: 0
Training loss: 4.04140028452585
Validation loss: 4.061355793171666

Epoch: 5| Step: 1
Training loss: 3.4980566896847236
Validation loss: 4.052930995946982

Epoch: 5| Step: 2
Training loss: 3.9590671193791995
Validation loss: 4.046711117527897

Epoch: 5| Step: 3
Training loss: 4.696928384138674
Validation loss: 4.039591195561718

Epoch: 5| Step: 4
Training loss: 4.118358004125732
Validation loss: 4.031644440177934

Epoch: 5| Step: 5
Training loss: 4.272094069070267
Validation loss: 4.024493374790134

Epoch: 5| Step: 6
Training loss: 4.215917243753339
Validation loss: 4.016738333148054

Epoch: 5| Step: 7
Training loss: 4.150909664236192
Validation loss: 4.010067706140657

Epoch: 5| Step: 8
Training loss: 4.534289373303121
Validation loss: 4.002100528864308

Epoch: 5| Step: 9
Training loss: 4.523425061039136
Validation loss: 3.992768830926535

Epoch: 5| Step: 10
Training loss: 3.61787424509818
Validation loss: 3.9872035590621007

Epoch: 14| Step: 0
Training loss: 4.894777332887555
Validation loss: 3.984015438706377

Epoch: 5| Step: 1
Training loss: 3.8544871154086846
Validation loss: 3.974622429868127

Epoch: 5| Step: 2
Training loss: 4.195742338242531
Validation loss: 3.967637770271134

Epoch: 5| Step: 3
Training loss: 4.14958379106123
Validation loss: 3.960951419320523

Epoch: 5| Step: 4
Training loss: 4.159180490028391
Validation loss: 3.952978044928784

Epoch: 5| Step: 5
Training loss: 3.4932570217135437
Validation loss: 3.94543137933222

Epoch: 5| Step: 6
Training loss: 3.349314827382945
Validation loss: 3.939471679440768

Epoch: 5| Step: 7
Training loss: 4.231785056065843
Validation loss: 3.9336061537037756

Epoch: 5| Step: 8
Training loss: 4.06324690775119
Validation loss: 3.926359867527609

Epoch: 5| Step: 9
Training loss: 4.485065260872701
Validation loss: 3.919939948985025

Epoch: 5| Step: 10
Training loss: 4.03836449027916
Validation loss: 3.9147764792691016

Epoch: 15| Step: 0
Training loss: 4.6073854452247796
Validation loss: 3.9073399043385013

Epoch: 5| Step: 1
Training loss: 4.053425910503173
Validation loss: 3.902223103401743

Epoch: 5| Step: 2
Training loss: 3.9799773237646296
Validation loss: 3.899467952691564

Epoch: 5| Step: 3
Training loss: 3.855807489512307
Validation loss: 3.8913860990822826

Epoch: 5| Step: 4
Training loss: 3.562585796193099
Validation loss: 3.8870964524300415

Epoch: 5| Step: 5
Training loss: 3.792885650761623
Validation loss: 3.8818373917437423

Epoch: 5| Step: 6
Training loss: 4.3859523467168335
Validation loss: 3.877122777234222

Epoch: 5| Step: 7
Training loss: 4.251723444933509
Validation loss: 3.8722039282669853

Epoch: 5| Step: 8
Training loss: 3.6299454727491205
Validation loss: 3.8661069836929984

Epoch: 5| Step: 9
Training loss: 3.769002958446869
Validation loss: 3.8620710464540937

Epoch: 5| Step: 10
Training loss: 4.551162009620992
Validation loss: 3.8587231380512894

Epoch: 16| Step: 0
Training loss: 4.155538856645058
Validation loss: 3.855420419476281

Epoch: 5| Step: 1
Training loss: 3.5190285716391525
Validation loss: 3.850029562751534

Epoch: 5| Step: 2
Training loss: 4.100057852732319
Validation loss: 3.8446865479833323

Epoch: 5| Step: 3
Training loss: 4.123657470479076
Validation loss: 3.8412026802585384

Epoch: 5| Step: 4
Training loss: 4.073099715988637
Validation loss: 3.834901148448101

Epoch: 5| Step: 5
Training loss: 3.6853051846759204
Validation loss: 3.8341800072112435

Epoch: 5| Step: 6
Training loss: 3.488470706728681
Validation loss: 3.8265306766999156

Epoch: 5| Step: 7
Training loss: 5.094124809470503
Validation loss: 3.822751983898232

Epoch: 5| Step: 8
Training loss: 4.370975059827362
Validation loss: 3.8212278425280517

Epoch: 5| Step: 9
Training loss: 3.5751424961101446
Validation loss: 3.817103293395511

Epoch: 5| Step: 10
Training loss: 3.4559332704194805
Validation loss: 3.8117701670579867

Epoch: 17| Step: 0
Training loss: 3.7659734667604536
Validation loss: 3.8045081380407653

Epoch: 5| Step: 1
Training loss: 4.112021170802852
Validation loss: 3.803541631625843

Epoch: 5| Step: 2
Training loss: 4.165094587664767
Validation loss: 3.7986301376325096

Epoch: 5| Step: 3
Training loss: 2.8057459797038846
Validation loss: 3.7978501746505744

Epoch: 5| Step: 4
Training loss: 4.886939271727923
Validation loss: 3.796772322673126

Epoch: 5| Step: 5
Training loss: 3.6646733212044236
Validation loss: 3.7893408441890513

Epoch: 5| Step: 6
Training loss: 3.7637321811787596
Validation loss: 3.784105785080918

Epoch: 5| Step: 7
Training loss: 4.151822593044675
Validation loss: 3.780702664383424

Epoch: 5| Step: 8
Training loss: 3.5409954257731933
Validation loss: 3.777984505409302

Epoch: 5| Step: 9
Training loss: 3.9661183680858505
Validation loss: 3.772514060251452

Epoch: 5| Step: 10
Training loss: 4.493643403679103
Validation loss: 3.7739458678585955

Epoch: 18| Step: 0
Training loss: 3.67473604461036
Validation loss: 3.7650399764402094

Epoch: 5| Step: 1
Training loss: 4.026507996681351
Validation loss: 3.7656245833498674

Epoch: 5| Step: 2
Training loss: 4.134299921001377
Validation loss: 3.760106018195456

Epoch: 5| Step: 3
Training loss: 3.981250929420638
Validation loss: 3.7569425272261747

Epoch: 5| Step: 4
Training loss: 3.150636269629266
Validation loss: 3.754068575297747

Epoch: 5| Step: 5
Training loss: 3.98639487136367
Validation loss: 3.7488911483068317

Epoch: 5| Step: 6
Training loss: 4.3803560441459926
Validation loss: 3.746511125725089

Epoch: 5| Step: 7
Training loss: 3.945913620279346
Validation loss: 3.742739788566299

Epoch: 5| Step: 8
Training loss: 3.8044167800246087
Validation loss: 3.738425429840706

Epoch: 5| Step: 9
Training loss: 4.420260832327168
Validation loss: 3.73664437368908

Epoch: 5| Step: 10
Training loss: 3.491570403259887
Validation loss: 3.7313101396629897

Epoch: 19| Step: 0
Training loss: 3.950235026646778
Validation loss: 3.73052887823277

Epoch: 5| Step: 1
Training loss: 3.56532215968711
Validation loss: 3.724520696402164

Epoch: 5| Step: 2
Training loss: 3.6341009664832824
Validation loss: 3.7247814014395044

Epoch: 5| Step: 3
Training loss: 3.600326226606178
Validation loss: 3.723240396331585

Epoch: 5| Step: 4
Training loss: 4.337329098195649
Validation loss: 3.7192444321407376

Epoch: 5| Step: 5
Training loss: 3.9399011950037024
Validation loss: 3.7154572323006536

Epoch: 5| Step: 6
Training loss: 3.1285482480409064
Validation loss: 3.71028813965656

Epoch: 5| Step: 7
Training loss: 3.4635307292717736
Validation loss: 3.7074436730410385

Epoch: 5| Step: 8
Training loss: 5.17245065303253
Validation loss: 3.7041960105913496

Epoch: 5| Step: 9
Training loss: 3.814774882022882
Validation loss: 3.702817981073798

Epoch: 5| Step: 10
Training loss: 3.913478419415827
Validation loss: 3.6987973491088857

Epoch: 20| Step: 0
Training loss: 3.9756901651699055
Validation loss: 3.697550837879434

Epoch: 5| Step: 1
Training loss: 3.8662372076573397
Validation loss: 3.6910521367418454

Epoch: 5| Step: 2
Training loss: 3.6077643429667527
Validation loss: 3.6906580735233474

Epoch: 5| Step: 3
Training loss: 3.7281130078259554
Validation loss: 3.684490312541257

Epoch: 5| Step: 4
Training loss: 4.442683456488394
Validation loss: 3.684009253358498

Epoch: 5| Step: 5
Training loss: 3.4989509372721974
Validation loss: 3.6815084213935956

Epoch: 5| Step: 6
Training loss: 2.404601684387475
Validation loss: 3.67484339021166

Epoch: 5| Step: 7
Training loss: 4.343978766036431
Validation loss: 3.674696376620186

Epoch: 5| Step: 8
Training loss: 3.7921328974102546
Validation loss: 3.670230637095021

Epoch: 5| Step: 9
Training loss: 4.245515589231561
Validation loss: 3.6642140975178243

Epoch: 5| Step: 10
Training loss: 4.283802468897147
Validation loss: 3.665000615793004

Epoch: 21| Step: 0
Training loss: 4.2896630261086335
Validation loss: 3.659354558604772

Epoch: 5| Step: 1
Training loss: 3.8022573492212532
Validation loss: 3.658872181721012

Epoch: 5| Step: 2
Training loss: 3.607316656390544
Validation loss: 3.6532091415044365

Epoch: 5| Step: 3
Training loss: 4.010984596894313
Validation loss: 3.650902513726419

Epoch: 5| Step: 4
Training loss: 3.375867096458938
Validation loss: 3.6452763986694094

Epoch: 5| Step: 5
Training loss: 4.719789908307832
Validation loss: 3.6415630091446882

Epoch: 5| Step: 6
Training loss: 3.5844823340631
Validation loss: 3.64168870380038

Epoch: 5| Step: 7
Training loss: 3.203589875517017
Validation loss: 3.6373269034891105

Epoch: 5| Step: 8
Training loss: 3.7420588015284686
Validation loss: 3.6350527500506447

Epoch: 5| Step: 9
Training loss: 3.768406517356336
Validation loss: 3.6314062146385657

Epoch: 5| Step: 10
Training loss: 3.8934563441853496
Validation loss: 3.627521366452705

Epoch: 22| Step: 0
Training loss: 3.2001617867579415
Validation loss: 3.626390937819291

Epoch: 5| Step: 1
Training loss: 3.7890711833421764
Validation loss: 3.6257136077096526

Epoch: 5| Step: 2
Training loss: 4.1873524198574374
Validation loss: 3.6218357950893254

Epoch: 5| Step: 3
Training loss: 3.420391161673258
Validation loss: 3.6175210964108953

Epoch: 5| Step: 4
Training loss: 3.8242556576998377
Validation loss: 3.61516525484266

Epoch: 5| Step: 5
Training loss: 3.6967164290174304
Validation loss: 3.6150588021664154

Epoch: 5| Step: 6
Training loss: 3.75724233001448
Validation loss: 3.611104579842853

Epoch: 5| Step: 7
Training loss: 4.868906173845612
Validation loss: 3.607355688037239

Epoch: 5| Step: 8
Training loss: 4.056935886883499
Validation loss: 3.607358148377062

Epoch: 5| Step: 9
Training loss: 3.3116806744408995
Validation loss: 3.601990741374363

Epoch: 5| Step: 10
Training loss: 3.465124486583351
Validation loss: 3.601878004611266

Epoch: 23| Step: 0
Training loss: 3.678485001647911
Validation loss: 3.60364562254019

Epoch: 5| Step: 1
Training loss: 3.6379579917743072
Validation loss: 3.6028918453201038

Epoch: 5| Step: 2
Training loss: 3.393747886811612
Validation loss: 3.6005361123635424

Epoch: 5| Step: 3
Training loss: 3.65603167542273
Validation loss: 3.597198706282234

Epoch: 5| Step: 4
Training loss: 3.5234768816656543
Validation loss: 3.5935317720030686

Epoch: 5| Step: 5
Training loss: 3.952714137261044
Validation loss: 3.5862246326985967

Epoch: 5| Step: 6
Training loss: 4.962730936591165
Validation loss: 3.584779362237303

Epoch: 5| Step: 7
Training loss: 3.5525916995213933
Validation loss: 3.5809590777049403

Epoch: 5| Step: 8
Training loss: 3.5556041164525856
Validation loss: 3.5813722836672333

Epoch: 5| Step: 9
Training loss: 3.7970964029696197
Validation loss: 3.5766475306927195

Epoch: 5| Step: 10
Training loss: 3.736965797037096
Validation loss: 3.5734609285433114

Epoch: 24| Step: 0
Training loss: 3.816822665717605
Validation loss: 3.5728359241391696

Epoch: 5| Step: 1
Training loss: 3.4359529655354817
Validation loss: 3.5724477573554654

Epoch: 5| Step: 2
Training loss: 4.045869326734217
Validation loss: 3.573722798401844

Epoch: 5| Step: 3
Training loss: 4.00479339447696
Validation loss: 3.570853312582662

Epoch: 5| Step: 4
Training loss: 4.450379070466876
Validation loss: 3.56701129990235

Epoch: 5| Step: 5
Training loss: 3.138722161185145
Validation loss: 3.5665138630129536

Epoch: 5| Step: 6
Training loss: 3.7412593702000754
Validation loss: 3.563015136146259

Epoch: 5| Step: 7
Training loss: 4.096624166228356
Validation loss: 3.559540517978753

Epoch: 5| Step: 8
Training loss: 3.200321217150606
Validation loss: 3.5606844711778156

Epoch: 5| Step: 9
Training loss: 3.5803503587506977
Validation loss: 3.554284580225501

Epoch: 5| Step: 10
Training loss: 3.7217524613227324
Validation loss: 3.554450941412539

Epoch: 25| Step: 0
Training loss: 3.1049259119209376
Validation loss: 3.5550727153210198

Epoch: 5| Step: 1
Training loss: 3.985130088913224
Validation loss: 3.5541706101100017

Epoch: 5| Step: 2
Training loss: 4.072981707873948
Validation loss: 3.5511296929111267

Epoch: 5| Step: 3
Training loss: 3.5351067471067887
Validation loss: 3.5471665074353234

Epoch: 5| Step: 4
Training loss: 4.082986907795982
Validation loss: 3.541517089252412

Epoch: 5| Step: 5
Training loss: 3.0599108280328524
Validation loss: 3.5403849362922086

Epoch: 5| Step: 6
Training loss: 4.03204219634062
Validation loss: 3.539339990532025

Epoch: 5| Step: 7
Training loss: 3.5527402805407213
Validation loss: 3.537355587186161

Epoch: 5| Step: 8
Training loss: 4.2166749725461035
Validation loss: 3.5356824801502684

Epoch: 5| Step: 9
Training loss: 3.580638019673266
Validation loss: 3.530278740117543

Epoch: 5| Step: 10
Training loss: 3.7993203910646915
Validation loss: 3.530381611645591

Epoch: 26| Step: 0
Training loss: 3.823382495629458
Validation loss: 3.5322128785039957

Epoch: 5| Step: 1
Training loss: 4.262488025637277
Validation loss: 3.5346084459458225

Epoch: 5| Step: 2
Training loss: 4.280619999552215
Validation loss: 3.5301308694804705

Epoch: 5| Step: 3
Training loss: 3.284700305337799
Validation loss: 3.523445660712392

Epoch: 5| Step: 4
Training loss: 4.20439701614978
Validation loss: 3.5202087461917437

Epoch: 5| Step: 5
Training loss: 3.64391391182637
Validation loss: 3.522475669559815

Epoch: 5| Step: 6
Training loss: 3.1883160911475374
Validation loss: 3.520688246123271

Epoch: 5| Step: 7
Training loss: 2.686975294833651
Validation loss: 3.518177634008032

Epoch: 5| Step: 8
Training loss: 3.5127703796798966
Validation loss: 3.516173751462384

Epoch: 5| Step: 9
Training loss: 3.8496051635409483
Validation loss: 3.5128504983202657

Epoch: 5| Step: 10
Training loss: 4.039313244000061
Validation loss: 3.5145402780384134

Epoch: 27| Step: 0
Training loss: 3.728740191803225
Validation loss: 3.5143332996333645

Epoch: 5| Step: 1
Training loss: 3.934353615821615
Validation loss: 3.5113296502196545

Epoch: 5| Step: 2
Training loss: 3.767465608537287
Validation loss: 3.5131382176376906

Epoch: 5| Step: 3
Training loss: 3.1456866872261604
Validation loss: 3.5088004340693604

Epoch: 5| Step: 4
Training loss: 3.4910440301011647
Validation loss: 3.504663922681701

Epoch: 5| Step: 5
Training loss: 3.903891866343324
Validation loss: 3.503913742110282

Epoch: 5| Step: 6
Training loss: 4.4881813828369435
Validation loss: 3.503248680289126

Epoch: 5| Step: 7
Training loss: 4.338623754389555
Validation loss: 3.502224325247231

Epoch: 5| Step: 8
Training loss: 2.985039122818711
Validation loss: 3.4991910720391144

Epoch: 5| Step: 9
Training loss: 2.5684178566892224
Validation loss: 3.4985324372856765

Epoch: 5| Step: 10
Training loss: 4.141429664590242
Validation loss: 3.4965732795792346

Epoch: 28| Step: 0
Training loss: 3.7266089478483124
Validation loss: 3.495828907446672

Epoch: 5| Step: 1
Training loss: 3.947703265995936
Validation loss: 3.4951661609534117

Epoch: 5| Step: 2
Training loss: 3.9736598124773908
Validation loss: 3.4945271342998994

Epoch: 5| Step: 3
Training loss: 4.2477168514046495
Validation loss: 3.493260344732492

Epoch: 5| Step: 4
Training loss: 2.9523309518093037
Validation loss: 3.494918066611794

Epoch: 5| Step: 5
Training loss: 2.9953970565362704
Validation loss: 3.4946119348662315

Epoch: 5| Step: 6
Training loss: 3.9263570638424676
Validation loss: 3.4910537014487932

Epoch: 5| Step: 7
Training loss: 3.2928628961059507
Validation loss: 3.488061065535634

Epoch: 5| Step: 8
Training loss: 3.3738409807305434
Validation loss: 3.484770083045046

Epoch: 5| Step: 9
Training loss: 3.555589766801383
Validation loss: 3.483649894055263

Epoch: 5| Step: 10
Training loss: 4.5619813807206615
Validation loss: 3.482624403104905

Epoch: 29| Step: 0
Training loss: 4.412930665869064
Validation loss: 3.4812112589382123

Epoch: 5| Step: 1
Training loss: 2.7273623979160986
Validation loss: 3.482988965235383

Epoch: 5| Step: 2
Training loss: 4.38404586763821
Validation loss: 3.477813692442677

Epoch: 5| Step: 3
Training loss: 3.317973383322495
Validation loss: 3.477834914680333

Epoch: 5| Step: 4
Training loss: 3.1508493580209316
Validation loss: 3.477015142411675

Epoch: 5| Step: 5
Training loss: 3.96515486675749
Validation loss: 3.4769109131274916

Epoch: 5| Step: 6
Training loss: 3.61394142512113
Validation loss: 3.475643711369246

Epoch: 5| Step: 7
Training loss: 3.99926870336855
Validation loss: 3.473437734233944

Epoch: 5| Step: 8
Training loss: 2.495157702092793
Validation loss: 3.46919492857403

Epoch: 5| Step: 9
Training loss: 3.9884598679854197
Validation loss: 3.4679963397022964

Epoch: 5| Step: 10
Training loss: 4.052960507621901
Validation loss: 3.4669576291670814

Epoch: 30| Step: 0
Training loss: 3.8790163944583376
Validation loss: 3.466418407163097

Epoch: 5| Step: 1
Training loss: 3.1861261137040318
Validation loss: 3.466724515740672

Epoch: 5| Step: 2
Training loss: 4.210164015014759
Validation loss: 3.4734126412350697

Epoch: 5| Step: 3
Training loss: 3.2527313492615324
Validation loss: 3.4655161509896364

Epoch: 5| Step: 4
Training loss: 3.426683783309084
Validation loss: 3.4606397972918153

Epoch: 5| Step: 5
Training loss: 3.856339098428123
Validation loss: 3.4626542333595856

Epoch: 5| Step: 6
Training loss: 3.476646302316871
Validation loss: 3.4638705342730507

Epoch: 5| Step: 7
Training loss: 3.9275681713265627
Validation loss: 3.4611897824878124

Epoch: 5| Step: 8
Training loss: 3.8623008602620104
Validation loss: 3.458828423756713

Epoch: 5| Step: 9
Training loss: 3.311796869471114
Validation loss: 3.45846200271952

Epoch: 5| Step: 10
Training loss: 3.977369545092583
Validation loss: 3.454539171142406

Epoch: 31| Step: 0
Training loss: 3.6626450129108314
Validation loss: 3.455519662215242

Epoch: 5| Step: 1
Training loss: 3.436818558166522
Validation loss: 3.453245908548558

Epoch: 5| Step: 2
Training loss: 3.251426530421232
Validation loss: 3.4549000348889494

Epoch: 5| Step: 3
Training loss: 3.8910164387202992
Validation loss: 3.4536741702845752

Epoch: 5| Step: 4
Training loss: 3.2077435203155606
Validation loss: 3.451973418644656

Epoch: 5| Step: 5
Training loss: 4.178518884163098
Validation loss: 3.44933000642332

Epoch: 5| Step: 6
Training loss: 3.93057004448894
Validation loss: 3.4489503020026313

Epoch: 5| Step: 7
Training loss: 3.348665421383587
Validation loss: 3.4496180348628047

Epoch: 5| Step: 8
Training loss: 3.756264095946409
Validation loss: 3.447676263085433

Epoch: 5| Step: 9
Training loss: 4.186640637027305
Validation loss: 3.447074967086779

Epoch: 5| Step: 10
Training loss: 3.2953314037694215
Validation loss: 3.4462129905549648

Epoch: 32| Step: 0
Training loss: 3.579269026394309
Validation loss: 3.4450985704409858

Epoch: 5| Step: 1
Training loss: 3.6518243593762008
Validation loss: 3.442479774786904

Epoch: 5| Step: 2
Training loss: 3.4975416541737805
Validation loss: 3.4432961500101698

Epoch: 5| Step: 3
Training loss: 4.1965632501110495
Validation loss: 3.442649794766217

Epoch: 5| Step: 4
Training loss: 2.8862433138803363
Validation loss: 3.441071545660605

Epoch: 5| Step: 5
Training loss: 3.4342472292151696
Validation loss: 3.4410244456604944

Epoch: 5| Step: 6
Training loss: 4.206228705659787
Validation loss: 3.4390369368991283

Epoch: 5| Step: 7
Training loss: 3.9184247528362897
Validation loss: 3.437668096137043

Epoch: 5| Step: 8
Training loss: 3.9955285829570237
Validation loss: 3.436746894025154

Epoch: 5| Step: 9
Training loss: 3.434502699389572
Validation loss: 3.4380928818475542

Epoch: 5| Step: 10
Training loss: 3.1935077971050734
Validation loss: 3.436019681638736

Epoch: 33| Step: 0
Training loss: 3.741686697880085
Validation loss: 3.4353494519174044

Epoch: 5| Step: 1
Training loss: 4.5409106170654505
Validation loss: 3.435411569474931

Epoch: 5| Step: 2
Training loss: 3.787917005288347
Validation loss: 3.434164370507055

Epoch: 5| Step: 3
Training loss: 3.7393594460512167
Validation loss: 3.432774550578942

Epoch: 5| Step: 4
Training loss: 3.5091548806485293
Validation loss: 3.4315492150439333

Epoch: 5| Step: 5
Training loss: 3.6273245100061167
Validation loss: 3.4294371879726624

Epoch: 5| Step: 6
Training loss: 3.3629792506507705
Validation loss: 3.430225303332419

Epoch: 5| Step: 7
Training loss: 3.034279636569911
Validation loss: 3.4282833112653655

Epoch: 5| Step: 8
Training loss: 3.9220098343122363
Validation loss: 3.4274363089907607

Epoch: 5| Step: 9
Training loss: 3.0623309030365062
Validation loss: 3.427202694612067

Epoch: 5| Step: 10
Training loss: 3.6344693907192553
Validation loss: 3.4274664717445074

Epoch: 34| Step: 0
Training loss: 3.635327590390325
Validation loss: 3.424026503633768

Epoch: 5| Step: 1
Training loss: 4.068924738681306
Validation loss: 3.425166749918253

Epoch: 5| Step: 2
Training loss: 3.3515972144545434
Validation loss: 3.421886055056105

Epoch: 5| Step: 3
Training loss: 3.8185259614396334
Validation loss: 3.4239335958273798

Epoch: 5| Step: 4
Training loss: 2.7356560894056026
Validation loss: 3.4213260800910392

Epoch: 5| Step: 5
Training loss: 3.9849066884448865
Validation loss: 3.4203418146302598

Epoch: 5| Step: 6
Training loss: 3.7736828963134554
Validation loss: 3.4209812323336886

Epoch: 5| Step: 7
Training loss: 3.5309660130639315
Validation loss: 3.418495502625113

Epoch: 5| Step: 8
Training loss: 3.229943524507633
Validation loss: 3.417499808820742

Epoch: 5| Step: 9
Training loss: 4.178499027877901
Validation loss: 3.41578175565072

Epoch: 5| Step: 10
Training loss: 3.5380813552275048
Validation loss: 3.417043755644185

Epoch: 35| Step: 0
Training loss: 3.8042094656858048
Validation loss: 3.415364534793246

Epoch: 5| Step: 1
Training loss: 3.3541258499473683
Validation loss: 3.414933744870727

Epoch: 5| Step: 2
Training loss: 3.9737584508354225
Validation loss: 3.412254949256781

Epoch: 5| Step: 3
Training loss: 4.0188540526782655
Validation loss: 3.411551747956647

Epoch: 5| Step: 4
Training loss: 3.8404831067808693
Validation loss: 3.4106289940534458

Epoch: 5| Step: 5
Training loss: 3.066015600116257
Validation loss: 3.409531767441136

Epoch: 5| Step: 6
Training loss: 3.954411474487462
Validation loss: 3.4096194947138265

Epoch: 5| Step: 7
Training loss: 3.3269585369657753
Validation loss: 3.4091866538510756

Epoch: 5| Step: 8
Training loss: 2.8808012772213796
Validation loss: 3.4065564234037247

Epoch: 5| Step: 9
Training loss: 3.877886650636285
Validation loss: 3.407165774533385

Epoch: 5| Step: 10
Training loss: 3.7186492136913514
Validation loss: 3.407260822688947

Epoch: 36| Step: 0
Training loss: 3.75173426897807
Validation loss: 3.4068020368299896

Epoch: 5| Step: 1
Training loss: 3.550525282560947
Validation loss: 3.4043280696246265

Epoch: 5| Step: 2
Training loss: 3.6208016649155574
Validation loss: 3.404281301678532

Epoch: 5| Step: 3
Training loss: 3.8597256273386793
Validation loss: 3.404129914437441

Epoch: 5| Step: 4
Training loss: 4.1219901461421005
Validation loss: 3.4044402087163474

Epoch: 5| Step: 5
Training loss: 3.0381691215307534
Validation loss: 3.4023039080951567

Epoch: 5| Step: 6
Training loss: 3.0095865937789696
Validation loss: 3.401551099552715

Epoch: 5| Step: 7
Training loss: 3.4844818783093294
Validation loss: 3.40266135187284

Epoch: 5| Step: 8
Training loss: 4.225783073494014
Validation loss: 3.3997764310012957

Epoch: 5| Step: 9
Training loss: 3.9023144236886043
Validation loss: 3.3996535710435243

Epoch: 5| Step: 10
Training loss: 3.0434634157967886
Validation loss: 3.3993079108430546

Epoch: 37| Step: 0
Training loss: 3.0411289906915986
Validation loss: 3.397610555954358

Epoch: 5| Step: 1
Training loss: 4.149994925989933
Validation loss: 3.3981048025095344

Epoch: 5| Step: 2
Training loss: 2.862868212876184
Validation loss: 3.3973078291809133

Epoch: 5| Step: 3
Training loss: 3.9218707445585106
Validation loss: 3.397182788091822

Epoch: 5| Step: 4
Training loss: 3.8249987234474996
Validation loss: 3.3957803433801748

Epoch: 5| Step: 5
Training loss: 3.2968337793168803
Validation loss: 3.3952397584488354

Epoch: 5| Step: 6
Training loss: 3.734742342067696
Validation loss: 3.394535143946634

Epoch: 5| Step: 7
Training loss: 4.0579197813239425
Validation loss: 3.394376378924684

Epoch: 5| Step: 8
Training loss: 3.8642079598597507
Validation loss: 3.393890530721987

Epoch: 5| Step: 9
Training loss: 4.288255737251034
Validation loss: 3.392493736209377

Epoch: 5| Step: 10
Training loss: 1.9835348678689775
Validation loss: 3.3920035574952028

Epoch: 38| Step: 0
Training loss: 3.8343861972238074
Validation loss: 3.391325130038116

Epoch: 5| Step: 1
Training loss: 4.1435559533715365
Validation loss: 3.390305181687178

Epoch: 5| Step: 2
Training loss: 3.551877699164111
Validation loss: 3.38932591145459

Epoch: 5| Step: 3
Training loss: 2.827271980920028
Validation loss: 3.3894514405596348

Epoch: 5| Step: 4
Training loss: 3.649213622572867
Validation loss: 3.386602218694741

Epoch: 5| Step: 5
Training loss: 3.7297746102396694
Validation loss: 3.3846163234186624

Epoch: 5| Step: 6
Training loss: 2.7442005734666246
Validation loss: 3.385219937927684

Epoch: 5| Step: 7
Training loss: 4.124462208225465
Validation loss: 3.3851186394276205

Epoch: 5| Step: 8
Training loss: 3.2265620566453235
Validation loss: 3.3851931640958184

Epoch: 5| Step: 9
Training loss: 4.409954488783263
Validation loss: 3.3844231876093964

Epoch: 5| Step: 10
Training loss: 3.0511844773936385
Validation loss: 3.3840007194268678

Epoch: 39| Step: 0
Training loss: 3.260441805384109
Validation loss: 3.384797494207841

Epoch: 5| Step: 1
Training loss: 3.5977120493518195
Validation loss: 3.3849376834998157

Epoch: 5| Step: 2
Training loss: 2.9341120560459313
Validation loss: 3.3828035119705633

Epoch: 5| Step: 3
Training loss: 3.155230215774845
Validation loss: 3.383181449365981

Epoch: 5| Step: 4
Training loss: 3.3932040904775813
Validation loss: 3.383821617457227

Epoch: 5| Step: 5
Training loss: 4.346662683738646
Validation loss: 3.383917169789158

Epoch: 5| Step: 6
Training loss: 4.00267011215431
Validation loss: 3.384515903687007

Epoch: 5| Step: 7
Training loss: 3.594803630787209
Validation loss: 3.3833500528965588

Epoch: 5| Step: 8
Training loss: 3.7032506736322635
Validation loss: 3.3819819082459044

Epoch: 5| Step: 9
Training loss: 3.8733569938169
Validation loss: 3.382062379655695

Epoch: 5| Step: 10
Training loss: 3.681427691952433
Validation loss: 3.3798196834842074

Epoch: 40| Step: 0
Training loss: 3.6284766789864764
Validation loss: 3.3793299574171476

Epoch: 5| Step: 1
Training loss: 3.292325754616593
Validation loss: 3.3787216000448788

Epoch: 5| Step: 2
Training loss: 4.382749397245151
Validation loss: 3.3772339106499247

Epoch: 5| Step: 3
Training loss: 3.688933142494909
Validation loss: 3.378477324950519

Epoch: 5| Step: 4
Training loss: 3.201812028446225
Validation loss: 3.3768808675782287

Epoch: 5| Step: 5
Training loss: 3.240262629849684
Validation loss: 3.376098516323456

Epoch: 5| Step: 6
Training loss: 3.036526835711982
Validation loss: 3.377874805180917

Epoch: 5| Step: 7
Training loss: 3.9663696359503935
Validation loss: 3.3751615366377323

Epoch: 5| Step: 8
Training loss: 3.565835294949559
Validation loss: 3.3751203119792748

Epoch: 5| Step: 9
Training loss: 3.9422698421701026
Validation loss: 3.374322214739773

Epoch: 5| Step: 10
Training loss: 3.519447384934843
Validation loss: 3.372809917522513

Epoch: 41| Step: 0
Training loss: 3.8220403153605287
Validation loss: 3.373037892870047

Epoch: 5| Step: 1
Training loss: 3.401709233537413
Validation loss: 3.3728508952703646

Epoch: 5| Step: 2
Training loss: 3.4572563486037504
Validation loss: 3.3731201387369327

Epoch: 5| Step: 3
Training loss: 3.8168120466193707
Validation loss: 3.3724589168482684

Epoch: 5| Step: 4
Training loss: 4.524002909530392
Validation loss: 3.3715838876861866

Epoch: 5| Step: 5
Training loss: 3.219945296776546
Validation loss: 3.3708055714994307

Epoch: 5| Step: 6
Training loss: 3.1020339876498237
Validation loss: 3.370046557493154

Epoch: 5| Step: 7
Training loss: 3.786663625295071
Validation loss: 3.370031238205549

Epoch: 5| Step: 8
Training loss: 3.0935627273752777
Validation loss: 3.3698448330000046

Epoch: 5| Step: 9
Training loss: 3.5776228239993078
Validation loss: 3.36852939696233

Epoch: 5| Step: 10
Training loss: 3.6157147105436835
Validation loss: 3.369296032883834

Epoch: 42| Step: 0
Training loss: 3.4859054693907465
Validation loss: 3.367055661907882

Epoch: 5| Step: 1
Training loss: 3.951158237858016
Validation loss: 3.3674362346183035

Epoch: 5| Step: 2
Training loss: 3.625981954236161
Validation loss: 3.3674302812204977

Epoch: 5| Step: 3
Training loss: 3.705459567047972
Validation loss: 3.366712903481261

Epoch: 5| Step: 4
Training loss: 4.24387254495896
Validation loss: 3.3657247550888796

Epoch: 5| Step: 5
Training loss: 3.3376869063601062
Validation loss: 3.36500793559464

Epoch: 5| Step: 6
Training loss: 3.9005429501270887
Validation loss: 3.3644371421296615

Epoch: 5| Step: 7
Training loss: 3.549172888024323
Validation loss: 3.364763946445127

Epoch: 5| Step: 8
Training loss: 3.3477999679714014
Validation loss: 3.3637272444013893

Epoch: 5| Step: 9
Training loss: 1.9993572990585515
Validation loss: 3.363161898780562

Epoch: 5| Step: 10
Training loss: 4.04269865304007
Validation loss: 3.363012133595792

Epoch: 43| Step: 0
Training loss: 3.6364275265629624
Validation loss: 3.3627330193193705

Epoch: 5| Step: 1
Training loss: 3.440892989889557
Validation loss: 3.362904395318204

Epoch: 5| Step: 2
Training loss: 3.0344418110745446
Validation loss: 3.3619471790151243

Epoch: 5| Step: 3
Training loss: 3.508160478285771
Validation loss: 3.3619926371474165

Epoch: 5| Step: 4
Training loss: 3.7219003107986315
Validation loss: 3.360526511165532

Epoch: 5| Step: 5
Training loss: 4.165065050658957
Validation loss: 3.3600401585911643

Epoch: 5| Step: 6
Training loss: 3.6339361606463756
Validation loss: 3.360630573242444

Epoch: 5| Step: 7
Training loss: 3.2947240384534466
Validation loss: 3.360752010651666

Epoch: 5| Step: 8
Training loss: 3.8253581110046677
Validation loss: 3.3580794663475864

Epoch: 5| Step: 9
Training loss: 3.9151841191713728
Validation loss: 3.358718277503627

Epoch: 5| Step: 10
Training loss: 3.169130237044635
Validation loss: 3.3577018766639375

Epoch: 44| Step: 0
Training loss: 3.656527256030875
Validation loss: 3.357368987909003

Epoch: 5| Step: 1
Training loss: 3.516818373844372
Validation loss: 3.3560056532261044

Epoch: 5| Step: 2
Training loss: 3.834620232112161
Validation loss: 3.3546196069904632

Epoch: 5| Step: 3
Training loss: 3.4439223895394186
Validation loss: 3.354758898552425

Epoch: 5| Step: 4
Training loss: 3.739669557956954
Validation loss: 3.355797932672057

Epoch: 5| Step: 5
Training loss: 3.3279013401867985
Validation loss: 3.353586607752106

Epoch: 5| Step: 6
Training loss: 3.329036534089149
Validation loss: 3.353676789166347

Epoch: 5| Step: 7
Training loss: 3.583120931200199
Validation loss: 3.3527713401469756

Epoch: 5| Step: 8
Training loss: 4.201164383928119
Validation loss: 3.352538273343663

Epoch: 5| Step: 9
Training loss: 3.4358787181175057
Validation loss: 3.350737147132007

Epoch: 5| Step: 10
Training loss: 3.28445307296746
Validation loss: 3.349776256523566

Epoch: 45| Step: 0
Training loss: 3.2257367201928444
Validation loss: 3.3488538399116643

Epoch: 5| Step: 1
Training loss: 3.7429454569449114
Validation loss: 3.3492993275432266

Epoch: 5| Step: 2
Training loss: 3.6147372224939263
Validation loss: 3.350619417980295

Epoch: 5| Step: 3
Training loss: 4.510964704642269
Validation loss: 3.3481688598113966

Epoch: 5| Step: 4
Training loss: 3.444841625188571
Validation loss: 3.34797461229753

Epoch: 5| Step: 5
Training loss: 3.354754299712274
Validation loss: 3.347497178499504

Epoch: 5| Step: 6
Training loss: 3.5662979493927276
Validation loss: 3.3470197976178633

Epoch: 5| Step: 7
Training loss: 3.2962491132889076
Validation loss: 3.3463242437034237

Epoch: 5| Step: 8
Training loss: 3.7796877321303928
Validation loss: 3.3446992660066113

Epoch: 5| Step: 9
Training loss: 2.9620771404063353
Validation loss: 3.3448462910125496

Epoch: 5| Step: 10
Training loss: 3.741442516610744
Validation loss: 3.344687694458156

Epoch: 46| Step: 0
Training loss: 3.6243098687248216
Validation loss: 3.3426326249088585

Epoch: 5| Step: 1
Training loss: 3.5734244709586345
Validation loss: 3.343222451419624

Epoch: 5| Step: 2
Training loss: 3.937171195697611
Validation loss: 3.3429877464936584

Epoch: 5| Step: 3
Training loss: 3.8549300941234477
Validation loss: 3.3411219837093706

Epoch: 5| Step: 4
Training loss: 3.905186012321631
Validation loss: 3.3431771920257325

Epoch: 5| Step: 5
Training loss: 3.2120770662119345
Validation loss: 3.3398056894525348

Epoch: 5| Step: 6
Training loss: 2.947006588341138
Validation loss: 3.344838014929459

Epoch: 5| Step: 7
Training loss: 2.8709319815183507
Validation loss: 3.3409157288197138

Epoch: 5| Step: 8
Training loss: 3.4151993523828317
Validation loss: 3.339462900842367

Epoch: 5| Step: 9
Training loss: 4.1504209557715255
Validation loss: 3.3398847745227487

Epoch: 5| Step: 10
Training loss: 3.655832120050131
Validation loss: 3.3384622313525516

Epoch: 47| Step: 0
Training loss: 3.44364103224479
Validation loss: 3.3375710519476627

Epoch: 5| Step: 1
Training loss: 4.7302014175338725
Validation loss: 3.3365144675671488

Epoch: 5| Step: 2
Training loss: 3.6887484231374765
Validation loss: 3.3363047251151197

Epoch: 5| Step: 3
Training loss: 3.73820369564276
Validation loss: 3.3347311585830144

Epoch: 5| Step: 4
Training loss: 3.360256345597741
Validation loss: 3.333141628003077

Epoch: 5| Step: 5
Training loss: 3.3960190860674753
Validation loss: 3.3319737535542595

Epoch: 5| Step: 6
Training loss: 3.263158715641456
Validation loss: 3.3305738784065397

Epoch: 5| Step: 7
Training loss: 3.0267325491883827
Validation loss: 3.329947128849281

Epoch: 5| Step: 8
Training loss: 4.038406997703619
Validation loss: 3.3292820542719195

Epoch: 5| Step: 9
Training loss: 2.7557850590451523
Validation loss: 3.3277340812055063

Epoch: 5| Step: 10
Training loss: 3.442394309599595
Validation loss: 3.326973171520226

Epoch: 48| Step: 0
Training loss: 3.4992669564035457
Validation loss: 3.325523703645983

Epoch: 5| Step: 1
Training loss: 3.626450215663661
Validation loss: 3.3243769874129794

Epoch: 5| Step: 2
Training loss: 3.6711556237221035
Validation loss: 3.3248627838434426

Epoch: 5| Step: 3
Training loss: 3.5736320973041313
Validation loss: 3.323289025166098

Epoch: 5| Step: 4
Training loss: 3.576434006555562
Validation loss: 3.322976469451435

Epoch: 5| Step: 5
Training loss: 3.489356888593037
Validation loss: 3.322235257176936

Epoch: 5| Step: 6
Training loss: 3.472580178353377
Validation loss: 3.3217814167518176

Epoch: 5| Step: 7
Training loss: 3.4983404857410325
Validation loss: 3.3217501631361985

Epoch: 5| Step: 8
Training loss: 3.7214256085780706
Validation loss: 3.320685016695474

Epoch: 5| Step: 9
Training loss: 3.4424407131655395
Validation loss: 3.32102665111469

Epoch: 5| Step: 10
Training loss: 3.6320214507524025
Validation loss: 3.3206696395331865

Epoch: 49| Step: 0
Training loss: 3.7772435172036283
Validation loss: 3.3197368928297193

Epoch: 5| Step: 1
Training loss: 3.4737245098769733
Validation loss: 3.320676473493206

Epoch: 5| Step: 2
Training loss: 3.3996527943319856
Validation loss: 3.3207895359700195

Epoch: 5| Step: 3
Training loss: 2.6945495410186666
Validation loss: 3.320260306617072

Epoch: 5| Step: 4
Training loss: 3.785359065209465
Validation loss: 3.3194355904402486

Epoch: 5| Step: 5
Training loss: 4.101589006610778
Validation loss: 3.3187651619173693

Epoch: 5| Step: 6
Training loss: 3.3107418936843565
Validation loss: 3.3181053698439

Epoch: 5| Step: 7
Training loss: 3.486745122339277
Validation loss: 3.3176519860137494

Epoch: 5| Step: 8
Training loss: 3.4262818826488393
Validation loss: 3.3169311910375474

Epoch: 5| Step: 9
Training loss: 3.6122912231095374
Validation loss: 3.3167764932021955

Epoch: 5| Step: 10
Training loss: 3.96083420838878
Validation loss: 3.316339254973838

Epoch: 50| Step: 0
Training loss: 3.385347258027466
Validation loss: 3.3156625638136017

Epoch: 5| Step: 1
Training loss: 3.3959573048310476
Validation loss: 3.3153070005740535

Epoch: 5| Step: 2
Training loss: 4.359623946324859
Validation loss: 3.3150473126288897

Epoch: 5| Step: 3
Training loss: 3.5865363657751113
Validation loss: 3.3148735490805388

Epoch: 5| Step: 4
Training loss: 3.3319432380027085
Validation loss: 3.3145772713099495

Epoch: 5| Step: 5
Training loss: 3.094543047128643
Validation loss: 3.314391698283842

Epoch: 5| Step: 6
Training loss: 2.944231477469107
Validation loss: 3.31338948748076

Epoch: 5| Step: 7
Training loss: 3.9901195328478036
Validation loss: 3.31264219561238

Epoch: 5| Step: 8
Training loss: 3.5171148915466715
Validation loss: 3.312435450576037

Epoch: 5| Step: 9
Training loss: 3.5713890672951214
Validation loss: 3.311855052928513

Epoch: 5| Step: 10
Training loss: 3.756100080040373
Validation loss: 3.312480416436408

Testing loss: 3.5002443591601136
