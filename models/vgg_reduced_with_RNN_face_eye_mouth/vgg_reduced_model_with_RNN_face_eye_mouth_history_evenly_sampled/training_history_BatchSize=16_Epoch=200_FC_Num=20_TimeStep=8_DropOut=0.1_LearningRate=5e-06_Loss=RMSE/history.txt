Epoch: 1| Step: 0
Training loss: 5.1081929837352495
Validation loss: 5.781373871127811

Epoch: 6| Step: 1
Training loss: 5.562819396718083
Validation loss: 5.776801997484664

Epoch: 6| Step: 2
Training loss: 6.110750087516268
Validation loss: 5.772603348554223

Epoch: 6| Step: 3
Training loss: 6.15002622521244
Validation loss: 5.768233933448326

Epoch: 6| Step: 4
Training loss: 5.368235745297504
Validation loss: 5.763953397155706

Epoch: 6| Step: 5
Training loss: 5.181230180101943
Validation loss: 5.759974253088766

Epoch: 6| Step: 6
Training loss: 6.375136430065879
Validation loss: 5.755795843267453

Epoch: 6| Step: 7
Training loss: 5.47825485397651
Validation loss: 5.751909713738687

Epoch: 6| Step: 8
Training loss: 6.60514649383934
Validation loss: 5.747714015823495

Epoch: 6| Step: 9
Training loss: 6.5052175855201755
Validation loss: 5.743779431228766

Epoch: 6| Step: 10
Training loss: 5.440404006878224
Validation loss: 5.739179069426679

Epoch: 6| Step: 11
Training loss: 5.5831875948128475
Validation loss: 5.734836917975977

Epoch: 6| Step: 12
Training loss: 5.439609688332553
Validation loss: 5.730478073186237

Epoch: 6| Step: 13
Training loss: 5.943927698858543
Validation loss: 5.726094882256979

Epoch: 2| Step: 0
Training loss: 5.200566026252162
Validation loss: 5.721202892496762

Epoch: 6| Step: 1
Training loss: 6.547384237727713
Validation loss: 5.716419062542013

Epoch: 6| Step: 2
Training loss: 5.270557843674663
Validation loss: 5.711271877719896

Epoch: 6| Step: 3
Training loss: 6.31731812565912
Validation loss: 5.705992322009161

Epoch: 6| Step: 4
Training loss: 4.8146183256393265
Validation loss: 5.700279920807693

Epoch: 6| Step: 5
Training loss: 5.934918936840269
Validation loss: 5.694617004074335

Epoch: 6| Step: 6
Training loss: 6.108457686688072
Validation loss: 5.688710765929871

Epoch: 6| Step: 7
Training loss: 4.794970006759443
Validation loss: 5.682246467758942

Epoch: 6| Step: 8
Training loss: 6.116967052321718
Validation loss: 5.675887749880885

Epoch: 6| Step: 9
Training loss: 6.173933472982082
Validation loss: 5.668520417317308

Epoch: 6| Step: 10
Training loss: 5.7668042308003615
Validation loss: 5.661467441113367

Epoch: 6| Step: 11
Training loss: 4.936344059704636
Validation loss: 5.653925109970665

Epoch: 6| Step: 12
Training loss: 6.569272860579628
Validation loss: 5.64536993704696

Epoch: 6| Step: 13
Training loss: 4.487189390010875
Validation loss: 5.637422662223653

Epoch: 3| Step: 0
Training loss: 5.935767633789563
Validation loss: 5.628704660449153

Epoch: 6| Step: 1
Training loss: 5.604220005996406
Validation loss: 5.619008310229611

Epoch: 6| Step: 2
Training loss: 5.5586508817008635
Validation loss: 5.609608238403738

Epoch: 6| Step: 3
Training loss: 5.598236501132068
Validation loss: 5.5982758029946345

Epoch: 6| Step: 4
Training loss: 5.654273093376154
Validation loss: 5.587160140082254

Epoch: 6| Step: 5
Training loss: 5.993822096151378
Validation loss: 5.5764406048130555

Epoch: 6| Step: 6
Training loss: 5.465345620048382
Validation loss: 5.5635399338883955

Epoch: 6| Step: 7
Training loss: 5.886935507891374
Validation loss: 5.5504479452632385

Epoch: 6| Step: 8
Training loss: 5.291992457816241
Validation loss: 5.536233090323997

Epoch: 6| Step: 9
Training loss: 6.214480674203503
Validation loss: 5.5220977016447526

Epoch: 6| Step: 10
Training loss: 5.098814897659622
Validation loss: 5.508442973416735

Epoch: 6| Step: 11
Training loss: 5.869080503539822
Validation loss: 5.493225821972115

Epoch: 6| Step: 12
Training loss: 3.4628701077631754
Validation loss: 5.476549396613612

Epoch: 6| Step: 13
Training loss: 6.631468871564674
Validation loss: 5.461928773371624

Epoch: 4| Step: 0
Training loss: 6.201057762237461
Validation loss: 5.444413469578188

Epoch: 6| Step: 1
Training loss: 5.6461546784150265
Validation loss: 5.426390870861258

Epoch: 6| Step: 2
Training loss: 5.681260931258392
Validation loss: 5.409082318909902

Epoch: 6| Step: 3
Training loss: 5.5758689784743245
Validation loss: 5.390366897955102

Epoch: 6| Step: 4
Training loss: 5.969041747307814
Validation loss: 5.3711835624516935

Epoch: 6| Step: 5
Training loss: 3.3703816215349076
Validation loss: 5.350738367561142

Epoch: 6| Step: 6
Training loss: 5.563424880042331
Validation loss: 5.331726702581398

Epoch: 6| Step: 7
Training loss: 5.556140993849083
Validation loss: 5.31108024103243

Epoch: 6| Step: 8
Training loss: 4.953361240854281
Validation loss: 5.290072468953806

Epoch: 6| Step: 9
Training loss: 5.527577015837556
Validation loss: 5.26812898629229

Epoch: 6| Step: 10
Training loss: 5.459153130777103
Validation loss: 5.245430844398158

Epoch: 6| Step: 11
Training loss: 5.052272308066294
Validation loss: 5.2238450860744265

Epoch: 6| Step: 12
Training loss: 5.209038201001428
Validation loss: 5.201914822362571

Epoch: 6| Step: 13
Training loss: 4.491776051130094
Validation loss: 5.177052768786984

Epoch: 5| Step: 0
Training loss: 4.404693328539621
Validation loss: 5.155391060990546

Epoch: 6| Step: 1
Training loss: 4.679232618230024
Validation loss: 5.131579833606112

Epoch: 6| Step: 2
Training loss: 3.9918378762710454
Validation loss: 5.108352218074038

Epoch: 6| Step: 3
Training loss: 4.681061047966587
Validation loss: 5.085408309570256

Epoch: 6| Step: 4
Training loss: 5.696292327194547
Validation loss: 5.063047714917588

Epoch: 6| Step: 5
Training loss: 4.9407380507948675
Validation loss: 5.039555677779873

Epoch: 6| Step: 6
Training loss: 5.275799709645349
Validation loss: 5.0148077006167115

Epoch: 6| Step: 7
Training loss: 5.990322573833083
Validation loss: 4.992586996379854

Epoch: 6| Step: 8
Training loss: 5.66913666841659
Validation loss: 4.968814898187232

Epoch: 6| Step: 9
Training loss: 5.647195386637803
Validation loss: 4.945955723863848

Epoch: 6| Step: 10
Training loss: 4.294130870912464
Validation loss: 4.921519411273105

Epoch: 6| Step: 11
Training loss: 5.023435221859903
Validation loss: 4.89795330004579

Epoch: 6| Step: 12
Training loss: 5.1994502290459685
Validation loss: 4.876036978319603

Epoch: 6| Step: 13
Training loss: 4.872412165891865
Validation loss: 4.854266533987743

Epoch: 6| Step: 0
Training loss: 5.513896033567748
Validation loss: 4.831098730900317

Epoch: 6| Step: 1
Training loss: 4.098183597054433
Validation loss: 4.808524070584036

Epoch: 6| Step: 2
Training loss: 4.0444710561787405
Validation loss: 4.786432014451979

Epoch: 6| Step: 3
Training loss: 3.46659302877809
Validation loss: 4.765941199604069

Epoch: 6| Step: 4
Training loss: 5.17065894821349
Validation loss: 4.744614960176413

Epoch: 6| Step: 5
Training loss: 5.0438773402668335
Validation loss: 4.723119490180085

Epoch: 6| Step: 6
Training loss: 4.314768098012224
Validation loss: 4.705089096424125

Epoch: 6| Step: 7
Training loss: 5.600403818829492
Validation loss: 4.684700376085543

Epoch: 6| Step: 8
Training loss: 4.028636943048664
Validation loss: 4.664754013411377

Epoch: 6| Step: 9
Training loss: 5.430258829260239
Validation loss: 4.6443197568807655

Epoch: 6| Step: 10
Training loss: 5.876687639400616
Validation loss: 4.626843606880531

Epoch: 6| Step: 11
Training loss: 3.6809529519819444
Validation loss: 4.6062175522569975

Epoch: 6| Step: 12
Training loss: 5.574016864117371
Validation loss: 4.586709111496157

Epoch: 6| Step: 13
Training loss: 3.5957773875411077
Validation loss: 4.567998869876094

Epoch: 7| Step: 0
Training loss: 5.58087962118799
Validation loss: 4.550950864239693

Epoch: 6| Step: 1
Training loss: 4.331193517891888
Validation loss: 4.534883978439596

Epoch: 6| Step: 2
Training loss: 4.15104521492392
Validation loss: 4.517434930200479

Epoch: 6| Step: 3
Training loss: 4.341067796481352
Validation loss: 4.502993277490333

Epoch: 6| Step: 4
Training loss: 4.273108767849248
Validation loss: 4.487967676549909

Epoch: 6| Step: 5
Training loss: 4.077892077579631
Validation loss: 4.471532094323405

Epoch: 6| Step: 6
Training loss: 4.47388062355963
Validation loss: 4.457167614003348

Epoch: 6| Step: 7
Training loss: 5.185359283330018
Validation loss: 4.442458875356149

Epoch: 6| Step: 8
Training loss: 3.9113400674643533
Validation loss: 4.429127169442521

Epoch: 6| Step: 9
Training loss: 4.915012965141574
Validation loss: 4.41492496928465

Epoch: 6| Step: 10
Training loss: 4.701085050610781
Validation loss: 4.400600118441099

Epoch: 6| Step: 11
Training loss: 4.731694737523895
Validation loss: 4.386449487861013

Epoch: 6| Step: 12
Training loss: 4.400703564660278
Validation loss: 4.373114303427142

Epoch: 6| Step: 13
Training loss: 4.379657555000421
Validation loss: 4.362297850421744

Epoch: 8| Step: 0
Training loss: 4.471008157052466
Validation loss: 4.348856873336093

Epoch: 6| Step: 1
Training loss: 4.761731968424024
Validation loss: 4.334416125607459

Epoch: 6| Step: 2
Training loss: 4.6588107242623575
Validation loss: 4.3232630002230765

Epoch: 6| Step: 3
Training loss: 4.339605536047729
Validation loss: 4.309890540166547

Epoch: 6| Step: 4
Training loss: 5.127623468081477
Validation loss: 4.297057108818899

Epoch: 6| Step: 5
Training loss: 3.889454983577378
Validation loss: 4.284532728430494

Epoch: 6| Step: 6
Training loss: 3.9438851068873855
Validation loss: 4.273587879407735

Epoch: 6| Step: 7
Training loss: 4.238163565834452
Validation loss: 4.26304765863329

Epoch: 6| Step: 8
Training loss: 4.571497158830284
Validation loss: 4.252993270944815

Epoch: 6| Step: 9
Training loss: 4.47418479953179
Validation loss: 4.24416911033309

Epoch: 6| Step: 10
Training loss: 4.264413067590328
Validation loss: 4.232600421424453

Epoch: 6| Step: 11
Training loss: 4.881769810545587
Validation loss: 4.2212832168967385

Epoch: 6| Step: 12
Training loss: 3.535587314015777
Validation loss: 4.210963637143614

Epoch: 6| Step: 13
Training loss: 3.89747733177459
Validation loss: 4.200090740276445

Epoch: 9| Step: 0
Training loss: 4.787483490200808
Validation loss: 4.190809739043498

Epoch: 6| Step: 1
Training loss: 3.691275522652144
Validation loss: 4.177319777929925

Epoch: 6| Step: 2
Training loss: 4.810977447234889
Validation loss: 4.16607131314264

Epoch: 6| Step: 3
Training loss: 4.74897554292243
Validation loss: 4.155494629318223

Epoch: 6| Step: 4
Training loss: 3.2259093725028993
Validation loss: 4.141441973227301

Epoch: 6| Step: 5
Training loss: 3.8113216392662865
Validation loss: 4.131731850231765

Epoch: 6| Step: 6
Training loss: 4.7123863307691485
Validation loss: 4.119638712113624

Epoch: 6| Step: 7
Training loss: 4.075589498930669
Validation loss: 4.1084724544655575

Epoch: 6| Step: 8
Training loss: 4.2472285041460465
Validation loss: 4.097891327177455

Epoch: 6| Step: 9
Training loss: 3.509892244342343
Validation loss: 4.085814838061912

Epoch: 6| Step: 10
Training loss: 4.944472014008619
Validation loss: 4.077107967583337

Epoch: 6| Step: 11
Training loss: 4.71381124775825
Validation loss: 4.067564243174595

Epoch: 6| Step: 12
Training loss: 3.9367021024714983
Validation loss: 4.058259411355241

Epoch: 6| Step: 13
Training loss: 3.5624791194906167
Validation loss: 4.0482417899568075

Epoch: 10| Step: 0
Training loss: 4.589719080753676
Validation loss: 4.038938564272212

Epoch: 6| Step: 1
Training loss: 4.041444175862303
Validation loss: 4.033534243617294

Epoch: 6| Step: 2
Training loss: 4.0842781271387745
Validation loss: 4.023270098728806

Epoch: 6| Step: 3
Training loss: 3.76561790877185
Validation loss: 4.014736358912035

Epoch: 6| Step: 4
Training loss: 3.943343171477977
Validation loss: 4.006225535284291

Epoch: 6| Step: 5
Training loss: 3.6773543361546293
Validation loss: 3.999412747313302

Epoch: 6| Step: 6
Training loss: 4.634047859771238
Validation loss: 3.9933730881988136

Epoch: 6| Step: 7
Training loss: 4.469954108358939
Validation loss: 3.987404522360463

Epoch: 6| Step: 8
Training loss: 3.586287338046509
Validation loss: 3.977286614259411

Epoch: 6| Step: 9
Training loss: 3.925231348496696
Validation loss: 3.9697999012026193

Epoch: 6| Step: 10
Training loss: 2.8274896234647406
Validation loss: 3.9623110997526845

Epoch: 6| Step: 11
Training loss: 3.7142274427558952
Validation loss: 3.957775942423387

Epoch: 6| Step: 12
Training loss: 4.920491341968474
Validation loss: 3.950569387394906

Epoch: 6| Step: 13
Training loss: 5.896842124374276
Validation loss: 3.9456618203211935

Epoch: 11| Step: 0
Training loss: 4.366044824793875
Validation loss: 3.9385802595022867

Epoch: 6| Step: 1
Training loss: 2.9472212942946694
Validation loss: 3.9333145911463867

Epoch: 6| Step: 2
Training loss: 3.2854967519174862
Validation loss: 3.9293789523602762

Epoch: 6| Step: 3
Training loss: 4.3919369512455235
Validation loss: 3.922983657789199

Epoch: 6| Step: 4
Training loss: 3.489599032390448
Validation loss: 3.9173697000144863

Epoch: 6| Step: 5
Training loss: 5.1185399721535045
Validation loss: 3.9147211403702893

Epoch: 6| Step: 6
Training loss: 4.428866732547726
Validation loss: 3.9068578339882456

Epoch: 6| Step: 7
Training loss: 4.361629436384071
Validation loss: 3.9029369639760265

Epoch: 6| Step: 8
Training loss: 2.969163404090524
Validation loss: 3.897398530225067

Epoch: 6| Step: 9
Training loss: 2.6454492325209538
Validation loss: 3.894406185198515

Epoch: 6| Step: 10
Training loss: 3.5893695173532207
Validation loss: 3.8922441097398734

Epoch: 6| Step: 11
Training loss: 4.247753671634316
Validation loss: 3.885904036722118

Epoch: 6| Step: 12
Training loss: 5.331174453253747
Validation loss: 3.881239197217804

Epoch: 6| Step: 13
Training loss: 5.009643220056768
Validation loss: 3.8758403926631826

Epoch: 12| Step: 0
Training loss: 3.4453825305559835
Validation loss: 3.874696296913409

Epoch: 6| Step: 1
Training loss: 2.520464016261547
Validation loss: 3.8678769482009727

Epoch: 6| Step: 2
Training loss: 3.847019696710039
Validation loss: 3.8627200351135165

Epoch: 6| Step: 3
Training loss: 5.097559341152613
Validation loss: 3.8551188473678586

Epoch: 6| Step: 4
Training loss: 3.2921087877507547
Validation loss: 3.853058339637077

Epoch: 6| Step: 5
Training loss: 3.6241890888188593
Validation loss: 3.849459206067721

Epoch: 6| Step: 6
Training loss: 4.7543981167584946
Validation loss: 3.850646614821104

Epoch: 6| Step: 7
Training loss: 4.331864156845671
Validation loss: 3.839268031263717

Epoch: 6| Step: 8
Training loss: 3.832235192832135
Validation loss: 3.8348154829192724

Epoch: 6| Step: 9
Training loss: 4.8753705006194705
Validation loss: 3.8317661095623534

Epoch: 6| Step: 10
Training loss: 3.6118260107960882
Validation loss: 3.8289925759708763

Epoch: 6| Step: 11
Training loss: 4.287622762540733
Validation loss: 3.8239189850911273

Epoch: 6| Step: 12
Training loss: 4.156729763707428
Validation loss: 3.8192408570404366

Epoch: 6| Step: 13
Training loss: 3.4741877642605745
Validation loss: 3.813730168826126

Epoch: 13| Step: 0
Training loss: 3.7071940925936335
Validation loss: 3.8097256511769166

Epoch: 6| Step: 1
Training loss: 3.3691983690703764
Validation loss: 3.8047294135142424

Epoch: 6| Step: 2
Training loss: 3.9848328570417566
Validation loss: 3.802156311404623

Epoch: 6| Step: 3
Training loss: 4.544223707186096
Validation loss: 3.797365989455663

Epoch: 6| Step: 4
Training loss: 4.081414193418417
Validation loss: 3.7931949524413984

Epoch: 6| Step: 5
Training loss: 4.82334411352746
Validation loss: 3.7876619494768518

Epoch: 6| Step: 6
Training loss: 3.4525993948294604
Validation loss: 3.783731238874186

Epoch: 6| Step: 7
Training loss: 4.281415059047291
Validation loss: 3.781962314824128

Epoch: 6| Step: 8
Training loss: 3.1619594790560464
Validation loss: 3.775558330534201

Epoch: 6| Step: 9
Training loss: 4.2128421814263906
Validation loss: 3.769276696681608

Epoch: 6| Step: 10
Training loss: 3.614960942987314
Validation loss: 3.7667591087619994

Epoch: 6| Step: 11
Training loss: 3.187029635561806
Validation loss: 3.7643427261450655

Epoch: 6| Step: 12
Training loss: 4.912562688762405
Validation loss: 3.7574457799729575

Epoch: 6| Step: 13
Training loss: 3.203301848204894
Validation loss: 3.7517527268126436

Epoch: 14| Step: 0
Training loss: 3.463226870043826
Validation loss: 3.745718987836364

Epoch: 6| Step: 1
Training loss: 4.0742304537523655
Validation loss: 3.7431165680946252

Epoch: 6| Step: 2
Training loss: 3.9051172674059846
Validation loss: 3.739893224684772

Epoch: 6| Step: 3
Training loss: 3.15906587893922
Validation loss: 3.734650415551642

Epoch: 6| Step: 4
Training loss: 4.784361979680499
Validation loss: 3.731773443386938

Epoch: 6| Step: 5
Training loss: 3.751974730302838
Validation loss: 3.724931999269129

Epoch: 6| Step: 6
Training loss: 3.002327810617899
Validation loss: 3.7208020780487345

Epoch: 6| Step: 7
Training loss: 3.5813164616620767
Validation loss: 3.716043215349898

Epoch: 6| Step: 8
Training loss: 3.9728158864343164
Validation loss: 3.7129959450811207

Epoch: 6| Step: 9
Training loss: 3.648324315277939
Validation loss: 3.708544199857812

Epoch: 6| Step: 10
Training loss: 4.463582499023171
Validation loss: 3.7055884006579936

Epoch: 6| Step: 11
Training loss: 4.103422429852596
Validation loss: 3.7011872491710154

Epoch: 6| Step: 12
Training loss: 3.8647904798955417
Validation loss: 3.6952841017335465

Epoch: 6| Step: 13
Training loss: 4.8196490803470775
Validation loss: 3.6913332765529034

Epoch: 15| Step: 0
Training loss: 3.1772409535482664
Validation loss: 3.690969271170816

Epoch: 6| Step: 1
Training loss: 4.130285402647645
Validation loss: 3.6910525048562524

Epoch: 6| Step: 2
Training loss: 3.6858677241766222
Validation loss: 3.684492139691845

Epoch: 6| Step: 3
Training loss: 3.9946488110771807
Validation loss: 3.6794710301373366

Epoch: 6| Step: 4
Training loss: 3.9486261030650445
Validation loss: 3.67651550813241

Epoch: 6| Step: 5
Training loss: 4.210009527490124
Validation loss: 3.6733547226961805

Epoch: 6| Step: 6
Training loss: 3.0209026109490633
Validation loss: 3.671556187431875

Epoch: 6| Step: 7
Training loss: 3.2445740522192543
Validation loss: 3.6686807220788964

Epoch: 6| Step: 8
Training loss: 4.316313895363791
Validation loss: 3.6673728639427856

Epoch: 6| Step: 9
Training loss: 3.472260494445107
Validation loss: 3.661870797560174

Epoch: 6| Step: 10
Training loss: 5.093389018554928
Validation loss: 3.658803314193087

Epoch: 6| Step: 11
Training loss: 3.531291860146664
Validation loss: 3.656334531676503

Epoch: 6| Step: 12
Training loss: 2.8882918556024855
Validation loss: 3.652417830928434

Epoch: 6| Step: 13
Training loss: 5.129448239582276
Validation loss: 3.6484377262591203

Epoch: 16| Step: 0
Training loss: 3.917760020027251
Validation loss: 3.6455608147701954

Epoch: 6| Step: 1
Training loss: 3.8777638085036865
Validation loss: 3.642100085023166

Epoch: 6| Step: 2
Training loss: 3.6861141639536488
Validation loss: 3.6385780131124155

Epoch: 6| Step: 3
Training loss: 3.9668500061834475
Validation loss: 3.6348051560630203

Epoch: 6| Step: 4
Training loss: 3.8167824379188504
Validation loss: 3.6315521202660284

Epoch: 6| Step: 5
Training loss: 3.307717956143265
Validation loss: 3.6280207256297636

Epoch: 6| Step: 6
Training loss: 3.2390977959704075
Validation loss: 3.62855244261793

Epoch: 6| Step: 7
Training loss: 3.903704737175806
Validation loss: 3.623606712861977

Epoch: 6| Step: 8
Training loss: 3.8947834633414935
Validation loss: 3.6224309001994066

Epoch: 6| Step: 9
Training loss: 3.766815377284617
Validation loss: 3.617278790057825

Epoch: 6| Step: 10
Training loss: 3.9334814970483936
Validation loss: 3.6153126838638676

Epoch: 6| Step: 11
Training loss: 3.9910727062326923
Validation loss: 3.612316442896642

Epoch: 6| Step: 12
Training loss: 4.02627374622504
Validation loss: 3.60993422684574

Epoch: 6| Step: 13
Training loss: 4.217083184901491
Validation loss: 3.607793809585308

Epoch: 17| Step: 0
Training loss: 2.891548957590984
Validation loss: 3.6043660278683194

Epoch: 6| Step: 1
Training loss: 3.5027984603068205
Validation loss: 3.601733181703251

Epoch: 6| Step: 2
Training loss: 4.416474728042435
Validation loss: 3.599497234565217

Epoch: 6| Step: 3
Training loss: 3.4618519420995684
Validation loss: 3.59529838858189

Epoch: 6| Step: 4
Training loss: 3.9769390055367664
Validation loss: 3.5953310149166193

Epoch: 6| Step: 5
Training loss: 4.07327086850817
Validation loss: 3.5907268590152257

Epoch: 6| Step: 6
Training loss: 4.3119161459389925
Validation loss: 3.5883005450758914

Epoch: 6| Step: 7
Training loss: 4.1779370787079335
Validation loss: 3.585389452153245

Epoch: 6| Step: 8
Training loss: 3.271997977407712
Validation loss: 3.581421076921898

Epoch: 6| Step: 9
Training loss: 4.31235249584979
Validation loss: 3.5802760110831287

Epoch: 6| Step: 10
Training loss: 3.177242604416883
Validation loss: 3.5772672955074922

Epoch: 6| Step: 11
Training loss: 3.4354952428254886
Validation loss: 3.5753889343718983

Epoch: 6| Step: 12
Training loss: 4.5154047189594175
Validation loss: 3.5734446461432556

Epoch: 6| Step: 13
Training loss: 2.0319638685107937
Validation loss: 3.5710693815119496

Epoch: 18| Step: 0
Training loss: 3.150833165019859
Validation loss: 3.568686185548954

Epoch: 6| Step: 1
Training loss: 2.8506456547252084
Validation loss: 3.567620120370034

Epoch: 6| Step: 2
Training loss: 3.810903746583303
Validation loss: 3.5634373897995753

Epoch: 6| Step: 3
Training loss: 3.400108189824943
Validation loss: 3.55934746224981

Epoch: 6| Step: 4
Training loss: 4.7787022004367445
Validation loss: 3.559492299862248

Epoch: 6| Step: 5
Training loss: 3.028351961651369
Validation loss: 3.5572745170330613

Epoch: 6| Step: 6
Training loss: 3.9790546874156347
Validation loss: 3.558859309982939

Epoch: 6| Step: 7
Training loss: 4.097689763923959
Validation loss: 3.5587624397015607

Epoch: 6| Step: 8
Training loss: 3.555189964916855
Validation loss: 3.5587063177868314

Epoch: 6| Step: 9
Training loss: 3.65917434468018
Validation loss: 3.555535195490608

Epoch: 6| Step: 10
Training loss: 4.49048498648179
Validation loss: 3.5498724443535123

Epoch: 6| Step: 11
Training loss: 4.228042428055506
Validation loss: 3.549489231561958

Epoch: 6| Step: 12
Training loss: 4.057127701560253
Validation loss: 3.543734096284441

Epoch: 6| Step: 13
Training loss: 2.0885135588494625
Validation loss: 3.5428645955794607

Epoch: 19| Step: 0
Training loss: 3.8082469293209726
Validation loss: 3.53767325846915

Epoch: 6| Step: 1
Training loss: 4.173088211644701
Validation loss: 3.538465212285273

Epoch: 6| Step: 2
Training loss: 2.824383109600853
Validation loss: 3.5358603601684173

Epoch: 6| Step: 3
Training loss: 3.4911172408755586
Validation loss: 3.5345084181062827

Epoch: 6| Step: 4
Training loss: 4.607380270517436
Validation loss: 3.535281849729976

Epoch: 6| Step: 5
Training loss: 3.8298870157653258
Validation loss: 3.529921227680443

Epoch: 6| Step: 6
Training loss: 3.352309777241705
Validation loss: 3.526864849633485

Epoch: 6| Step: 7
Training loss: 4.078573501887974
Validation loss: 3.523893033245426

Epoch: 6| Step: 8
Training loss: 3.489773933936889
Validation loss: 3.5212114226605333

Epoch: 6| Step: 9
Training loss: 3.019641948215444
Validation loss: 3.519856085711272

Epoch: 6| Step: 10
Training loss: 4.133013714974107
Validation loss: 3.518807998715753

Epoch: 6| Step: 11
Training loss: 3.916774883533805
Validation loss: 3.515519781691602

Epoch: 6| Step: 12
Training loss: 3.908391868841614
Validation loss: 3.5123873946027153

Epoch: 6| Step: 13
Training loss: 2.747213772832642
Validation loss: 3.5096690621912168

Epoch: 20| Step: 0
Training loss: 4.4896969998420415
Validation loss: 3.505165504411252

Epoch: 6| Step: 1
Training loss: 4.054901764193646
Validation loss: 3.5063423989641813

Epoch: 6| Step: 2
Training loss: 3.558173513880796
Validation loss: 3.502414092026088

Epoch: 6| Step: 3
Training loss: 3.8424479442438297
Validation loss: 3.4999878395326376

Epoch: 6| Step: 4
Training loss: 3.2329127742801096
Validation loss: 3.4962730370451545

Epoch: 6| Step: 5
Training loss: 3.462491549815529
Validation loss: 3.4928369734159

Epoch: 6| Step: 6
Training loss: 4.090977319475971
Validation loss: 3.4934197563952747

Epoch: 6| Step: 7
Training loss: 3.7369502297941426
Validation loss: 3.4887660419241686

Epoch: 6| Step: 8
Training loss: 3.323262131928471
Validation loss: 3.4846690122988213

Epoch: 6| Step: 9
Training loss: 3.431613390081169
Validation loss: 3.481740787105347

Epoch: 6| Step: 10
Training loss: 4.63412812000458
Validation loss: 3.4769260402153512

Epoch: 6| Step: 11
Training loss: 2.7099324322825136
Validation loss: 3.475512799357903

Epoch: 6| Step: 12
Training loss: 3.010885041615784
Validation loss: 3.471788172073029

Epoch: 6| Step: 13
Training loss: 3.859545869944363
Validation loss: 3.467301404452915

Epoch: 21| Step: 0
Training loss: 4.11458359086563
Validation loss: 3.4664426396548476

Epoch: 6| Step: 1
Training loss: 3.3949560112554296
Validation loss: 3.46333461564808

Epoch: 6| Step: 2
Training loss: 2.416072860200184
Validation loss: 3.4615014977624945

Epoch: 6| Step: 3
Training loss: 3.3867576095305214
Validation loss: 3.4592018198292402

Epoch: 6| Step: 4
Training loss: 2.719870500847758
Validation loss: 3.4583907603835518

Epoch: 6| Step: 5
Training loss: 3.957914684977994
Validation loss: 3.4541834353022582

Epoch: 6| Step: 6
Training loss: 4.363192510428189
Validation loss: 3.452989804170518

Epoch: 6| Step: 7
Training loss: 4.153781473302863
Validation loss: 3.4498351768272086

Epoch: 6| Step: 8
Training loss: 4.098643632156019
Validation loss: 3.4474376710947583

Epoch: 6| Step: 9
Training loss: 3.284446394677014
Validation loss: 3.444851328014759

Epoch: 6| Step: 10
Training loss: 3.0160737173243892
Validation loss: 3.443852908443046

Epoch: 6| Step: 11
Training loss: 4.146697345714192
Validation loss: 3.4423614342569033

Epoch: 6| Step: 12
Training loss: 3.645920336457241
Validation loss: 3.4422899584966027

Epoch: 6| Step: 13
Training loss: 4.331780057457502
Validation loss: 3.4398927253414406

Epoch: 22| Step: 0
Training loss: 3.266240112196288
Validation loss: 3.436977663748701

Epoch: 6| Step: 1
Training loss: 4.405991999871276
Validation loss: 3.435131862956377

Epoch: 6| Step: 2
Training loss: 3.259364501702142
Validation loss: 3.4339091678162057

Epoch: 6| Step: 3
Training loss: 4.118075019971975
Validation loss: 3.4325931269853385

Epoch: 6| Step: 4
Training loss: 4.205422153034044
Validation loss: 3.4310284221504372

Epoch: 6| Step: 5
Training loss: 4.25153928818372
Validation loss: 3.4289768549880204

Epoch: 6| Step: 6
Training loss: 4.201121253254409
Validation loss: 3.4262949676381544

Epoch: 6| Step: 7
Training loss: 3.172094177791435
Validation loss: 3.4219565830159633

Epoch: 6| Step: 8
Training loss: 3.8673364475735066
Validation loss: 3.4240946687635905

Epoch: 6| Step: 9
Training loss: 2.710756147403531
Validation loss: 3.423927814041855

Epoch: 6| Step: 10
Training loss: 3.6470217847662454
Validation loss: 3.4201975230240524

Epoch: 6| Step: 11
Training loss: 3.0880668150734545
Validation loss: 3.4170537189634866

Epoch: 6| Step: 12
Training loss: 3.0116275521211637
Validation loss: 3.416409138884216

Epoch: 6| Step: 13
Training loss: 3.0952285162110273
Validation loss: 3.4160872017298742

Epoch: 23| Step: 0
Training loss: 3.32137706968632
Validation loss: 3.413740068187225

Epoch: 6| Step: 1
Training loss: 2.9112969332720424
Validation loss: 3.4117843526004

Epoch: 6| Step: 2
Training loss: 4.1295143625176145
Validation loss: 3.4111668816445695

Epoch: 6| Step: 3
Training loss: 3.305617181397624
Validation loss: 3.4124995665587705

Epoch: 6| Step: 4
Training loss: 2.4449979439631204
Validation loss: 3.4079904331182957

Epoch: 6| Step: 5
Training loss: 3.3168069442400303
Validation loss: 3.4064282147428044

Epoch: 6| Step: 6
Training loss: 3.794334409343003
Validation loss: 3.4024626867186494

Epoch: 6| Step: 7
Training loss: 3.267318359556551
Validation loss: 3.40007549674985

Epoch: 6| Step: 8
Training loss: 3.890126882018519
Validation loss: 3.4025885328370604

Epoch: 6| Step: 9
Training loss: 4.087717518282953
Validation loss: 3.403329424118293

Epoch: 6| Step: 10
Training loss: 3.735670942228563
Validation loss: 3.399795790722034

Epoch: 6| Step: 11
Training loss: 4.215151686286428
Validation loss: 3.396983583678223

Epoch: 6| Step: 12
Training loss: 4.056324652174415
Validation loss: 3.3941400593002657

Epoch: 6| Step: 13
Training loss: 4.036385274246417
Validation loss: 3.3925685734253404

Epoch: 24| Step: 0
Training loss: 4.412956598880564
Validation loss: 3.3913023270107465

Epoch: 6| Step: 1
Training loss: 3.4194207295403634
Validation loss: 3.3869573472639947

Epoch: 6| Step: 2
Training loss: 3.397761135100755
Validation loss: 3.3836181517912083

Epoch: 6| Step: 3
Training loss: 3.8892379800848986
Validation loss: 3.3837116642371505

Epoch: 6| Step: 4
Training loss: 3.685732401679752
Validation loss: 3.380455467788626

Epoch: 6| Step: 5
Training loss: 3.606864287156077
Validation loss: 3.378593181935108

Epoch: 6| Step: 6
Training loss: 3.266633676505073
Validation loss: 3.377253153647799

Epoch: 6| Step: 7
Training loss: 3.849090092132622
Validation loss: 3.3724225493799125

Epoch: 6| Step: 8
Training loss: 3.3737185835956782
Validation loss: 3.371369381372879

Epoch: 6| Step: 9
Training loss: 3.433518757180191
Validation loss: 3.3686370694916983

Epoch: 6| Step: 10
Training loss: 3.2854031391788543
Validation loss: 3.3656698344693012

Epoch: 6| Step: 11
Training loss: 3.873392817773117
Validation loss: 3.362810058790465

Epoch: 6| Step: 12
Training loss: 2.9803333976679327
Validation loss: 3.363777473812382

Epoch: 6| Step: 13
Training loss: 3.9497761771612336
Validation loss: 3.361107010244075

Epoch: 25| Step: 0
Training loss: 4.532198681670599
Validation loss: 3.3597586692895254

Epoch: 6| Step: 1
Training loss: 2.751562021700608
Validation loss: 3.362649378104302

Epoch: 6| Step: 2
Training loss: 3.0558617717777894
Validation loss: 3.3575703502423035

Epoch: 6| Step: 3
Training loss: 3.767275626545303
Validation loss: 3.3566516625409273

Epoch: 6| Step: 4
Training loss: 3.565370173128668
Validation loss: 3.354280871250383

Epoch: 6| Step: 5
Training loss: 3.05988651788254
Validation loss: 3.3536828548880386

Epoch: 6| Step: 6
Training loss: 3.080963839538204
Validation loss: 3.353538178129362

Epoch: 6| Step: 7
Training loss: 2.935632964576798
Validation loss: 3.351137628025741

Epoch: 6| Step: 8
Training loss: 4.314129507725032
Validation loss: 3.3494012592973883

Epoch: 6| Step: 9
Training loss: 4.80273874351672
Validation loss: 3.345694806593884

Epoch: 6| Step: 10
Training loss: 3.6928999850635837
Validation loss: 3.3456768778144292

Epoch: 6| Step: 11
Training loss: 3.3162705176876592
Validation loss: 3.3449875683642913

Epoch: 6| Step: 12
Training loss: 3.3878446509224975
Validation loss: 3.342390751533702

Epoch: 6| Step: 13
Training loss: 2.926296866073002
Validation loss: 3.3438848422867946

Epoch: 26| Step: 0
Training loss: 3.175170539420952
Validation loss: 3.3425796556778398

Epoch: 6| Step: 1
Training loss: 3.256352305498349
Validation loss: 3.3406488948371758

Epoch: 6| Step: 2
Training loss: 3.6212127896425934
Validation loss: 3.3388037344593835

Epoch: 6| Step: 3
Training loss: 3.881323300466497
Validation loss: 3.342059801852869

Epoch: 6| Step: 4
Training loss: 3.6824229575370344
Validation loss: 3.3337597933092384

Epoch: 6| Step: 5
Training loss: 3.403283743750808
Validation loss: 3.336803530109886

Epoch: 6| Step: 6
Training loss: 3.8277498022446537
Validation loss: 3.335171024270175

Epoch: 6| Step: 7
Training loss: 2.948711669983234
Validation loss: 3.335279991999693

Epoch: 6| Step: 8
Training loss: 3.8859256414425007
Validation loss: 3.3364511265304095

Epoch: 6| Step: 9
Training loss: 3.1185877817046075
Validation loss: 3.3340858661106942

Epoch: 6| Step: 10
Training loss: 3.8089528075940393
Validation loss: 3.335576167860425

Epoch: 6| Step: 11
Training loss: 4.032332873727195
Validation loss: 3.3330934566406922

Epoch: 6| Step: 12
Training loss: 3.802210571389624
Validation loss: 3.330804005691861

Epoch: 6| Step: 13
Training loss: 3.240400074406232
Validation loss: 3.3294261149367412

Epoch: 27| Step: 0
Training loss: 4.573651207719391
Validation loss: 3.3273699043123446

Epoch: 6| Step: 1
Training loss: 3.3849755258957317
Validation loss: 3.3255400420248367

Epoch: 6| Step: 2
Training loss: 3.151668736298956
Validation loss: 3.323608901617965

Epoch: 6| Step: 3
Training loss: 2.235217275789764
Validation loss: 3.3218649239576794

Epoch: 6| Step: 4
Training loss: 3.1588592319599913
Validation loss: 3.3218363120711594

Epoch: 6| Step: 5
Training loss: 3.418098769848445
Validation loss: 3.320812525970749

Epoch: 6| Step: 6
Training loss: 4.336579696248423
Validation loss: 3.319710614871066

Epoch: 6| Step: 7
Training loss: 2.953620021444719
Validation loss: 3.318708724908946

Epoch: 6| Step: 8
Training loss: 4.623557200788679
Validation loss: 3.3165721006593785

Epoch: 6| Step: 9
Training loss: 3.3931504086976343
Validation loss: 3.313206639669065

Epoch: 6| Step: 10
Training loss: 3.312415499779016
Validation loss: 3.3142545421847784

Epoch: 6| Step: 11
Training loss: 3.515944809672513
Validation loss: 3.3152818644348074

Epoch: 6| Step: 12
Training loss: 3.484217892513292
Validation loss: 3.3115204709272126

Epoch: 6| Step: 13
Training loss: 3.4823167135692175
Validation loss: 3.312551239137458

Epoch: 28| Step: 0
Training loss: 2.3787091052919602
Validation loss: 3.3104820025134756

Epoch: 6| Step: 1
Training loss: 3.7528829301179125
Validation loss: 3.309574063180527

Epoch: 6| Step: 2
Training loss: 4.010596069022337
Validation loss: 3.3096914057450197

Epoch: 6| Step: 3
Training loss: 3.8176819651665856
Validation loss: 3.308009141311824

Epoch: 6| Step: 4
Training loss: 3.269132637691506
Validation loss: 3.305929439659822

Epoch: 6| Step: 5
Training loss: 4.577452105652338
Validation loss: 3.3052559225584863

Epoch: 6| Step: 6
Training loss: 3.43926928677135
Validation loss: 3.305135595264215

Epoch: 6| Step: 7
Training loss: 3.9908232326755453
Validation loss: 3.303210331325131

Epoch: 6| Step: 8
Training loss: 2.1612264730961157
Validation loss: 3.301464571084122

Epoch: 6| Step: 9
Training loss: 4.181217776232799
Validation loss: 3.3010110894374556

Epoch: 6| Step: 10
Training loss: 3.3307666592529586
Validation loss: 3.2997390910547306

Epoch: 6| Step: 11
Training loss: 3.7021872061327383
Validation loss: 3.2997459800169056

Epoch: 6| Step: 12
Training loss: 2.49918180428254
Validation loss: 3.29922576969055

Epoch: 6| Step: 13
Training loss: 3.6951429396715483
Validation loss: 3.2975994520014438

Epoch: 29| Step: 0
Training loss: 3.099679062750404
Validation loss: 3.2986406338717504

Epoch: 6| Step: 1
Training loss: 3.892653583689078
Validation loss: 3.2987367557645433

Epoch: 6| Step: 2
Training loss: 3.175331374770137
Validation loss: 3.295466159488018

Epoch: 6| Step: 3
Training loss: 4.221933251804252
Validation loss: 3.2945582808401004

Epoch: 6| Step: 4
Training loss: 4.071545200063744
Validation loss: 3.2945974920591747

Epoch: 6| Step: 5
Training loss: 3.842580353710152
Validation loss: 3.29329022552401

Epoch: 6| Step: 6
Training loss: 4.191825340913038
Validation loss: 3.293291816662305

Epoch: 6| Step: 7
Training loss: 2.986463844303989
Validation loss: 3.292758908154119

Epoch: 6| Step: 8
Training loss: 2.7722010475561274
Validation loss: 3.292070422962827

Epoch: 6| Step: 9
Training loss: 3.0792398515468866
Validation loss: 3.290116982859877

Epoch: 6| Step: 10
Training loss: 3.3045856288782813
Validation loss: 3.2919539693175204

Epoch: 6| Step: 11
Training loss: 3.3046087160932522
Validation loss: 3.2941421047190587

Epoch: 6| Step: 12
Training loss: 3.60152410457774
Validation loss: 3.3003234875949516

Epoch: 6| Step: 13
Training loss: 3.6307147788834953
Validation loss: 3.2893609901946923

Epoch: 30| Step: 0
Training loss: 3.8938532538523614
Validation loss: 3.2876565373873263

Epoch: 6| Step: 1
Training loss: 4.1277766274926515
Validation loss: 3.287995715311335

Epoch: 6| Step: 2
Training loss: 3.58034849420637
Validation loss: 3.2896328322161947

Epoch: 6| Step: 3
Training loss: 2.779064562826915
Validation loss: 3.2900882172155046

Epoch: 6| Step: 4
Training loss: 3.2922489922732185
Validation loss: 3.289791936780002

Epoch: 6| Step: 5
Training loss: 3.6559333338095437
Validation loss: 3.2951193480074297

Epoch: 6| Step: 6
Training loss: 4.304848780440602
Validation loss: 3.2895020054459945

Epoch: 6| Step: 7
Training loss: 3.7472538111506544
Validation loss: 3.2876237772112655

Epoch: 6| Step: 8
Training loss: 3.8183763586578814
Validation loss: 3.2873671991263707

Epoch: 6| Step: 9
Training loss: 3.1506521609512275
Validation loss: 3.2863587532943743

Epoch: 6| Step: 10
Training loss: 2.828591661257031
Validation loss: 3.2875033309297668

Epoch: 6| Step: 11
Training loss: 3.806181502704615
Validation loss: 3.2879064450221844

Epoch: 6| Step: 12
Training loss: 3.15885983576925
Validation loss: 3.2854456830931973

Epoch: 6| Step: 13
Training loss: 2.282839600116938
Validation loss: 3.2845507144860084

Epoch: 31| Step: 0
Training loss: 3.5580459323810865
Validation loss: 3.2838500987987285

Epoch: 6| Step: 1
Training loss: 2.9456440463260747
Validation loss: 3.2825745455726874

Epoch: 6| Step: 2
Training loss: 2.9115150914719043
Validation loss: 3.282009434943802

Epoch: 6| Step: 3
Training loss: 4.570559137976472
Validation loss: 3.2817089004068385

Epoch: 6| Step: 4
Training loss: 3.9143875200320193
Validation loss: 3.2812193557081777

Epoch: 6| Step: 5
Training loss: 3.597943057412772
Validation loss: 3.278430142309671

Epoch: 6| Step: 6
Training loss: 3.510355344212201
Validation loss: 3.277930456952718

Epoch: 6| Step: 7
Training loss: 3.4428561011077083
Validation loss: 3.2747039330445533

Epoch: 6| Step: 8
Training loss: 3.2300626598693296
Validation loss: 3.2758530821486294

Epoch: 6| Step: 9
Training loss: 3.397643108259176
Validation loss: 3.2741218830620604

Epoch: 6| Step: 10
Training loss: 3.6803107574114122
Validation loss: 3.2731425061645214

Epoch: 6| Step: 11
Training loss: 3.756657603359262
Validation loss: 3.2720311964636712

Epoch: 6| Step: 12
Training loss: 2.6923136517175807
Validation loss: 3.2731267818955883

Epoch: 6| Step: 13
Training loss: 3.939976594535902
Validation loss: 3.2708894750791715

Epoch: 32| Step: 0
Training loss: 3.4683502241826574
Validation loss: 3.268651491784007

Epoch: 6| Step: 1
Training loss: 3.2116710261216506
Validation loss: 3.2686007119321268

Epoch: 6| Step: 2
Training loss: 3.783016958466408
Validation loss: 3.268352726858005

Epoch: 6| Step: 3
Training loss: 3.555027268488908
Validation loss: 3.2669579961360142

Epoch: 6| Step: 4
Training loss: 2.9349732590453077
Validation loss: 3.2678136629665437

Epoch: 6| Step: 5
Training loss: 3.2444254677216096
Validation loss: 3.2678721949192644

Epoch: 6| Step: 6
Training loss: 3.3447877218404765
Validation loss: 3.2668997240295607

Epoch: 6| Step: 7
Training loss: 3.726207660279665
Validation loss: 3.2636532395530535

Epoch: 6| Step: 8
Training loss: 2.8716135397889833
Validation loss: 3.263345068423278

Epoch: 6| Step: 9
Training loss: 3.70251112086901
Validation loss: 3.261538888021076

Epoch: 6| Step: 10
Training loss: 3.57277616144881
Validation loss: 3.264823796055191

Epoch: 6| Step: 11
Training loss: 4.1851841230463
Validation loss: 3.258717601606622

Epoch: 6| Step: 12
Training loss: 3.635944156943909
Validation loss: 3.258859787865231

Epoch: 6| Step: 13
Training loss: 3.885785628212819
Validation loss: 3.257208496407901

Epoch: 33| Step: 0
Training loss: 2.8907424490497733
Validation loss: 3.256144351523534

Epoch: 6| Step: 1
Training loss: 3.6782497180675966
Validation loss: 3.2563952431246634

Epoch: 6| Step: 2
Training loss: 3.6734600136219924
Validation loss: 3.2560771401282307

Epoch: 6| Step: 3
Training loss: 3.099108130844266
Validation loss: 3.2548053773926813

Epoch: 6| Step: 4
Training loss: 4.426621117491564
Validation loss: 3.2554951129555816

Epoch: 6| Step: 5
Training loss: 4.031885377950089
Validation loss: 3.2549183517092133

Epoch: 6| Step: 6
Training loss: 3.270905090970348
Validation loss: 3.256143370517667

Epoch: 6| Step: 7
Training loss: 2.8585667536175703
Validation loss: 3.253279823984115

Epoch: 6| Step: 8
Training loss: 3.637960220010374
Validation loss: 3.252046163407412

Epoch: 6| Step: 9
Training loss: 2.165250926992819
Validation loss: 3.2532147725093705

Epoch: 6| Step: 10
Training loss: 3.5516567179127168
Validation loss: 3.251624807910821

Epoch: 6| Step: 11
Training loss: 3.853278530307523
Validation loss: 3.2517293047754303

Epoch: 6| Step: 12
Training loss: 3.5518366186352823
Validation loss: 3.2501333712590723

Epoch: 6| Step: 13
Training loss: 3.994070904036959
Validation loss: 3.250417363871473

Epoch: 34| Step: 0
Training loss: 3.758338938932334
Validation loss: 3.249969397086042

Epoch: 6| Step: 1
Training loss: 3.8535455701605126
Validation loss: 3.249528369491247

Epoch: 6| Step: 2
Training loss: 3.801933780324258
Validation loss: 3.249125161759752

Epoch: 6| Step: 3
Training loss: 3.970180584045779
Validation loss: 3.2487271942602183

Epoch: 6| Step: 4
Training loss: 3.776473378024365
Validation loss: 3.2497802010067964

Epoch: 6| Step: 5
Training loss: 2.724376775185728
Validation loss: 3.2447597404845956

Epoch: 6| Step: 6
Training loss: 3.156900168956537
Validation loss: 3.245282926721972

Epoch: 6| Step: 7
Training loss: 3.284060918161656
Validation loss: 3.245311044402784

Epoch: 6| Step: 8
Training loss: 2.4910660375955733
Validation loss: 3.2449948806478353

Epoch: 6| Step: 9
Training loss: 4.209440003978525
Validation loss: 3.2451299380652885

Epoch: 6| Step: 10
Training loss: 2.3287897377084206
Validation loss: 3.243412316741892

Epoch: 6| Step: 11
Training loss: 3.4764081942142946
Validation loss: 3.244488343927351

Epoch: 6| Step: 12
Training loss: 3.453271646967412
Validation loss: 3.241707242129754

Epoch: 6| Step: 13
Training loss: 4.437537824442669
Validation loss: 3.241921867977081

Epoch: 35| Step: 0
Training loss: 3.063741938169122
Validation loss: 3.240768792349541

Epoch: 6| Step: 1
Training loss: 3.1839058752284832
Validation loss: 3.2398273312954737

Epoch: 6| Step: 2
Training loss: 4.268957157051384
Validation loss: 3.2397705288878704

Epoch: 6| Step: 3
Training loss: 3.3085778966746813
Validation loss: 3.238701553605814

Epoch: 6| Step: 4
Training loss: 4.541707776551447
Validation loss: 3.238740526832826

Epoch: 6| Step: 5
Training loss: 3.100829684070742
Validation loss: 3.2367482767007316

Epoch: 6| Step: 6
Training loss: 3.7745921893608436
Validation loss: 3.2370680716285163

Epoch: 6| Step: 7
Training loss: 2.9721388899231562
Validation loss: 3.237292085085207

Epoch: 6| Step: 8
Training loss: 3.8189028145889483
Validation loss: 3.2375251560941876

Epoch: 6| Step: 9
Training loss: 2.925620223581139
Validation loss: 3.2382904546999645

Epoch: 6| Step: 10
Training loss: 4.2167036957051
Validation loss: 3.238241055229964

Epoch: 6| Step: 11
Training loss: 2.7183945522123536
Validation loss: 3.2387956993161087

Epoch: 6| Step: 12
Training loss: 3.1899784400713616
Validation loss: 3.2444605098953496

Epoch: 6| Step: 13
Training loss: 2.945937356007011
Validation loss: 3.2355914224918734

Epoch: 36| Step: 0
Training loss: 3.1503639858607135
Validation loss: 3.2353832893976073

Epoch: 6| Step: 1
Training loss: 2.8671899946238297
Validation loss: 3.2339388788282735

Epoch: 6| Step: 2
Training loss: 3.4627507198190606
Validation loss: 3.236230913901275

Epoch: 6| Step: 3
Training loss: 3.7495972735001746
Validation loss: 3.233547476373397

Epoch: 6| Step: 4
Training loss: 3.6471611584053782
Validation loss: 3.2317571077581446

Epoch: 6| Step: 5
Training loss: 3.172166632413693
Validation loss: 3.2343544567268783

Epoch: 6| Step: 6
Training loss: 3.4102019736249534
Validation loss: 3.2310495519227276

Epoch: 6| Step: 7
Training loss: 3.5366050154201862
Validation loss: 3.232148270155251

Epoch: 6| Step: 8
Training loss: 3.9270051633034946
Validation loss: 3.230828504958822

Epoch: 6| Step: 9
Training loss: 3.065385665650377
Validation loss: 3.232602373657723

Epoch: 6| Step: 10
Training loss: 3.3969028559492758
Validation loss: 3.2306787391571348

Epoch: 6| Step: 11
Training loss: 3.6744113684260973
Validation loss: 3.231718399354806

Epoch: 6| Step: 12
Training loss: 3.9862824306083917
Validation loss: 3.2292722993709093

Epoch: 6| Step: 13
Training loss: 3.641947231934828
Validation loss: 3.2298479571544285

Epoch: 37| Step: 0
Training loss: 3.356911967259883
Validation loss: 3.2313098449617357

Epoch: 6| Step: 1
Training loss: 3.830569362700022
Validation loss: 3.2316305866122903

Epoch: 6| Step: 2
Training loss: 3.4821989509060804
Validation loss: 3.2363501180347014

Epoch: 6| Step: 3
Training loss: 3.7950063117858104
Validation loss: 3.2277448595793157

Epoch: 6| Step: 4
Training loss: 2.733855977526866
Validation loss: 3.2235986318519294

Epoch: 6| Step: 5
Training loss: 3.7068939987516445
Validation loss: 3.2241710423231176

Epoch: 6| Step: 6
Training loss: 4.055850646781035
Validation loss: 3.224106322723115

Epoch: 6| Step: 7
Training loss: 3.51969816127525
Validation loss: 3.2237401920917197

Epoch: 6| Step: 8
Training loss: 3.6575914840051764
Validation loss: 3.2239437093331333

Epoch: 6| Step: 9
Training loss: 3.2106435970742817
Validation loss: 3.2242519427791523

Epoch: 6| Step: 10
Training loss: 3.8234217809830255
Validation loss: 3.221153777030324

Epoch: 6| Step: 11
Training loss: 3.190579292052161
Validation loss: 3.2208839206113375

Epoch: 6| Step: 12
Training loss: 3.229230982642433
Validation loss: 3.218469204687907

Epoch: 6| Step: 13
Training loss: 2.3074475329748325
Validation loss: 3.220362484670655

Epoch: 38| Step: 0
Training loss: 3.8570292521705887
Validation loss: 3.220557180500426

Epoch: 6| Step: 1
Training loss: 2.7304436896706292
Validation loss: 3.222065771753383

Epoch: 6| Step: 2
Training loss: 3.1363408109213795
Validation loss: 3.223775522731052

Epoch: 6| Step: 3
Training loss: 3.554745851813303
Validation loss: 3.220415948427208

Epoch: 6| Step: 4
Training loss: 3.9522279467925685
Validation loss: 3.2189841650706534

Epoch: 6| Step: 5
Training loss: 3.0696941655810983
Validation loss: 3.2189327450550484

Epoch: 6| Step: 6
Training loss: 4.530678969609211
Validation loss: 3.218271065545365

Epoch: 6| Step: 7
Training loss: 3.7930031960491752
Validation loss: 3.2174153717492326

Epoch: 6| Step: 8
Training loss: 3.08140211368235
Validation loss: 3.217267614310791

Epoch: 6| Step: 9
Training loss: 3.6359327472808163
Validation loss: 3.217242923398167

Epoch: 6| Step: 10
Training loss: 3.2926550882087886
Validation loss: 3.218043563518791

Epoch: 6| Step: 11
Training loss: 2.8669440142697296
Validation loss: 3.217981901752566

Epoch: 6| Step: 12
Training loss: 3.158447558133272
Validation loss: 3.214601707096289

Epoch: 6| Step: 13
Training loss: 3.6072130209912188
Validation loss: 3.2149580512281783

Epoch: 39| Step: 0
Training loss: 3.5566738740895065
Validation loss: 3.2145968997706187

Epoch: 6| Step: 1
Training loss: 3.1388844083980962
Validation loss: 3.212867157986883

Epoch: 6| Step: 2
Training loss: 3.526337844527946
Validation loss: 3.21346527315679

Epoch: 6| Step: 3
Training loss: 3.205919191423651
Validation loss: 3.2126652005375083

Epoch: 6| Step: 4
Training loss: 3.524524326560341
Validation loss: 3.2121190529260417

Epoch: 6| Step: 5
Training loss: 3.4717798146162377
Validation loss: 3.210708252692499

Epoch: 6| Step: 6
Training loss: 3.9515511617803307
Validation loss: 3.211924109798034

Epoch: 6| Step: 7
Training loss: 3.0251450559027626
Validation loss: 3.213153562718442

Epoch: 6| Step: 8
Training loss: 3.5128062158872324
Validation loss: 3.211981658468195

Epoch: 6| Step: 9
Training loss: 2.867912180110672
Validation loss: 3.2108930746323163

Epoch: 6| Step: 10
Training loss: 3.9718217151348076
Validation loss: 3.209946306168219

Epoch: 6| Step: 11
Training loss: 4.115477233875657
Validation loss: 3.2101388434086355

Epoch: 6| Step: 12
Training loss: 3.577345717413537
Validation loss: 3.209612847064771

Epoch: 6| Step: 13
Training loss: 2.1894860107783387
Validation loss: 3.209476571434286

Epoch: 40| Step: 0
Training loss: 4.3575711363666905
Validation loss: 3.2089556450198984

Epoch: 6| Step: 1
Training loss: 2.758020236482577
Validation loss: 3.2183745440319287

Epoch: 6| Step: 2
Training loss: 3.6144687660082524
Validation loss: 3.223042239543653

Epoch: 6| Step: 3
Training loss: 2.920358845856827
Validation loss: 3.2597848064437995

Epoch: 6| Step: 4
Training loss: 3.056307389982321
Validation loss: 3.230239172963192

Epoch: 6| Step: 5
Training loss: 4.1810708867185715
Validation loss: 3.211575368436946

Epoch: 6| Step: 6
Training loss: 4.376348669077893
Validation loss: 3.207406449615071

Epoch: 6| Step: 7
Training loss: 2.8160125838236976
Validation loss: 3.206571820683724

Epoch: 6| Step: 8
Training loss: 2.5985188593603032
Validation loss: 3.2072775922523604

Epoch: 6| Step: 9
Training loss: 2.3587883226185498
Validation loss: 3.208493991936969

Epoch: 6| Step: 10
Training loss: 3.3635863410548077
Validation loss: 3.2083958743684784

Epoch: 6| Step: 11
Training loss: 3.90602489585775
Validation loss: 3.2082979040236577

Epoch: 6| Step: 12
Training loss: 3.7172440757470793
Validation loss: 3.210915816741618

Epoch: 6| Step: 13
Training loss: 3.8737756579208855
Validation loss: 3.2078604384959277

Epoch: 41| Step: 0
Training loss: 3.0376790876929594
Validation loss: 3.206082774995469

Epoch: 6| Step: 1
Training loss: 3.601326957497384
Validation loss: 3.2052803925320563

Epoch: 6| Step: 2
Training loss: 3.9825812397230083
Validation loss: 3.203740573161955

Epoch: 6| Step: 3
Training loss: 2.9604475677903404
Validation loss: 3.20386146864805

Epoch: 6| Step: 4
Training loss: 2.1353515491016304
Validation loss: 3.202943501306306

Epoch: 6| Step: 5
Training loss: 3.9549127087321923
Validation loss: 3.202544213761685

Epoch: 6| Step: 6
Training loss: 3.254568849947386
Validation loss: 3.2037846824107254

Epoch: 6| Step: 7
Training loss: 3.2456371661067833
Validation loss: 3.2033491879054696

Epoch: 6| Step: 8
Training loss: 3.903804654518416
Validation loss: 3.202692051722623

Epoch: 6| Step: 9
Training loss: 3.448042084563201
Validation loss: 3.2046074038879064

Epoch: 6| Step: 10
Training loss: 3.7326372644386403
Validation loss: 3.20239854323686

Epoch: 6| Step: 11
Training loss: 3.3056388189121075
Validation loss: 3.2021512956413893

Epoch: 6| Step: 12
Training loss: 3.915692688523581
Validation loss: 3.201737959487265

Epoch: 6| Step: 13
Training loss: 3.554346759939522
Validation loss: 3.2024492456887033

Epoch: 42| Step: 0
Training loss: 3.0501495762403135
Validation loss: 3.202003120465269

Epoch: 6| Step: 1
Training loss: 3.3714091660631533
Validation loss: 3.1999778447486587

Epoch: 6| Step: 2
Training loss: 3.0181433089746252
Validation loss: 3.1983960835705907

Epoch: 6| Step: 3
Training loss: 3.4888945549785935
Validation loss: 3.1985883382508726

Epoch: 6| Step: 4
Training loss: 3.9800046401260394
Validation loss: 3.198415419849816

Epoch: 6| Step: 5
Training loss: 3.235439549201636
Validation loss: 3.197891812984344

Epoch: 6| Step: 6
Training loss: 3.2421174926553236
Validation loss: 3.1978352693892296

Epoch: 6| Step: 7
Training loss: 3.357401139315694
Validation loss: 3.1986578596497637

Epoch: 6| Step: 8
Training loss: 3.319168001277297
Validation loss: 3.1991233899117293

Epoch: 6| Step: 9
Training loss: 3.118553684454495
Validation loss: 3.196342948170931

Epoch: 6| Step: 10
Training loss: 4.25832852377623
Validation loss: 3.195397922723825

Epoch: 6| Step: 11
Training loss: 4.109211385392442
Validation loss: 3.1959527281380153

Epoch: 6| Step: 12
Training loss: 3.5914765174137333
Validation loss: 3.1955235655230307

Epoch: 6| Step: 13
Training loss: 2.4853993349411634
Validation loss: 3.19529429225777

Epoch: 43| Step: 0
Training loss: 3.451872585557559
Validation loss: 3.1970065712007822

Epoch: 6| Step: 1
Training loss: 3.611450127232048
Validation loss: 3.1958079091046514

Epoch: 6| Step: 2
Training loss: 3.5342993609280255
Validation loss: 3.19335816196342

Epoch: 6| Step: 3
Training loss: 2.721916371851193
Validation loss: 3.1943478843596553

Epoch: 6| Step: 4
Training loss: 3.412857087284784
Validation loss: 3.192881203782321

Epoch: 6| Step: 5
Training loss: 3.6316148321879727
Validation loss: 3.1934435221667306

Epoch: 6| Step: 6
Training loss: 3.2006366275277434
Validation loss: 3.1923349744975225

Epoch: 6| Step: 7
Training loss: 3.9272806672857277
Validation loss: 3.191326505910558

Epoch: 6| Step: 8
Training loss: 2.6604462632156296
Validation loss: 3.191890429849033

Epoch: 6| Step: 9
Training loss: 3.8902482306115593
Validation loss: 3.190394388558003

Epoch: 6| Step: 10
Training loss: 3.4957159253767487
Validation loss: 3.19037320450543

Epoch: 6| Step: 11
Training loss: 3.96711817557248
Validation loss: 3.1895589353597686

Epoch: 6| Step: 12
Training loss: 3.074126769341488
Validation loss: 3.1906686291069883

Epoch: 6| Step: 13
Training loss: 3.4868895348483386
Validation loss: 3.1910169398653716

Epoch: 44| Step: 0
Training loss: 3.313100796323088
Validation loss: 3.1881359768012927

Epoch: 6| Step: 1
Training loss: 3.5356925093955915
Validation loss: 3.1909360194907674

Epoch: 6| Step: 2
Training loss: 2.810930365086354
Validation loss: 3.193019917114196

Epoch: 6| Step: 3
Training loss: 2.9979485809415958
Validation loss: 3.191614399434909

Epoch: 6| Step: 4
Training loss: 3.172414047964678
Validation loss: 3.191324426930512

Epoch: 6| Step: 5
Training loss: 3.33148768509248
Validation loss: 3.189168628014521

Epoch: 6| Step: 6
Training loss: 3.680806825965699
Validation loss: 3.188292846100566

Epoch: 6| Step: 7
Training loss: 3.472620548712715
Validation loss: 3.188808200858636

Epoch: 6| Step: 8
Training loss: 3.2358997823523867
Validation loss: 3.188506763447573

Epoch: 6| Step: 9
Training loss: 3.191238753780477
Validation loss: 3.188441389074815

Epoch: 6| Step: 10
Training loss: 3.5371471215545283
Validation loss: 3.188066295914104

Epoch: 6| Step: 11
Training loss: 3.8882063736009354
Validation loss: 3.1890909646816072

Epoch: 6| Step: 12
Training loss: 4.021753288271018
Validation loss: 3.189047233408863

Epoch: 6| Step: 13
Training loss: 4.244789070487448
Validation loss: 3.188590221806717

Epoch: 45| Step: 0
Training loss: 3.4236185169634226
Validation loss: 3.189222963570006

Epoch: 6| Step: 1
Training loss: 3.795385374623602
Validation loss: 3.1877613125391693

Epoch: 6| Step: 2
Training loss: 3.133456575391349
Validation loss: 3.1873270848869764

Epoch: 6| Step: 3
Training loss: 3.6593962606045367
Validation loss: 3.186800449471448

Epoch: 6| Step: 4
Training loss: 3.9248953203954384
Validation loss: 3.1854920952720494

Epoch: 6| Step: 5
Training loss: 3.1259199695654285
Validation loss: 3.1840701517487977

Epoch: 6| Step: 6
Training loss: 3.2884774673151633
Validation loss: 3.1846594800219394

Epoch: 6| Step: 7
Training loss: 3.2653655172682807
Validation loss: 3.18532512669572

Epoch: 6| Step: 8
Training loss: 3.800607110765383
Validation loss: 3.1853901787143246

Epoch: 6| Step: 9
Training loss: 3.4046216799924354
Validation loss: 3.1844303713063735

Epoch: 6| Step: 10
Training loss: 2.631885218114682
Validation loss: 3.1844072371704977

Epoch: 6| Step: 11
Training loss: 3.4597543455028115
Validation loss: 3.184218419112105

Epoch: 6| Step: 12
Training loss: 3.827083523825923
Validation loss: 3.1865536424772225

Epoch: 6| Step: 13
Training loss: 3.1755982143306265
Validation loss: 3.185499113001508

Epoch: 46| Step: 0
Training loss: 3.8178116115254603
Validation loss: 3.184421478659747

Epoch: 6| Step: 1
Training loss: 3.944609505747309
Validation loss: 3.1840213369964583

Epoch: 6| Step: 2
Training loss: 3.6593648569958437
Validation loss: 3.1806799343696612

Epoch: 6| Step: 3
Training loss: 3.7893094011857937
Validation loss: 3.181628113124916

Epoch: 6| Step: 4
Training loss: 3.0371040368723183
Validation loss: 3.1801680903408363

Epoch: 6| Step: 5
Training loss: 3.2106948352456737
Validation loss: 3.1793571164067638

Epoch: 6| Step: 6
Training loss: 4.142348136075038
Validation loss: 3.1804712482613393

Epoch: 6| Step: 7
Training loss: 3.508050651367308
Validation loss: 3.1791471758096232

Epoch: 6| Step: 8
Training loss: 3.0152051564221862
Validation loss: 3.179615018414108

Epoch: 6| Step: 9
Training loss: 3.610658491737694
Validation loss: 3.1778333521349444

Epoch: 6| Step: 10
Training loss: 3.273303190767168
Validation loss: 3.1804134147686542

Epoch: 6| Step: 11
Training loss: 2.879482423845619
Validation loss: 3.178571248071371

Epoch: 6| Step: 12
Training loss: 3.2126216880223484
Validation loss: 3.1781834599792447

Epoch: 6| Step: 13
Training loss: 2.1745551608087346
Validation loss: 3.1787917658389753

Epoch: 47| Step: 0
Training loss: 3.224591630023858
Validation loss: 3.179503078211526

Epoch: 6| Step: 1
Training loss: 3.778386063939066
Validation loss: 3.178915302074801

Epoch: 6| Step: 2
Training loss: 3.9881188848102163
Validation loss: 3.1768321741739936

Epoch: 6| Step: 3
Training loss: 4.026280378376888
Validation loss: 3.17994232297499

Epoch: 6| Step: 4
Training loss: 3.8167088524320794
Validation loss: 3.1780872993178346

Epoch: 6| Step: 5
Training loss: 2.6906639814045223
Validation loss: 3.1775681896132757

Epoch: 6| Step: 6
Training loss: 3.1338222331915393
Validation loss: 3.177307266797285

Epoch: 6| Step: 7
Training loss: 3.1561206753362834
Validation loss: 3.1782601637871415

Epoch: 6| Step: 8
Training loss: 3.3425039661415323
Validation loss: 3.176110029623805

Epoch: 6| Step: 9
Training loss: 3.0649648595292125
Validation loss: 3.1785440934113467

Epoch: 6| Step: 10
Training loss: 3.897157753335413
Validation loss: 3.1785371409809895

Epoch: 6| Step: 11
Training loss: 3.157384989403965
Validation loss: 3.1742131160600993

Epoch: 6| Step: 12
Training loss: 3.083449043645888
Validation loss: 3.175843988635453

Epoch: 6| Step: 13
Training loss: 3.4857192931708787
Validation loss: 3.1742445220284257

Epoch: 48| Step: 0
Training loss: 2.979343186775394
Validation loss: 3.1746196719601367

Epoch: 6| Step: 1
Training loss: 3.1949710430331466
Validation loss: 3.1743343704891687

Epoch: 6| Step: 2
Training loss: 3.8758985646599053
Validation loss: 3.173724158566498

Epoch: 6| Step: 3
Training loss: 3.9539089707126087
Validation loss: 3.1731703488599945

Epoch: 6| Step: 4
Training loss: 3.5901343691870866
Validation loss: 3.1738121994792756

Epoch: 6| Step: 5
Training loss: 3.8824280945750815
Validation loss: 3.1721966653764424

Epoch: 6| Step: 6
Training loss: 3.663749892964617
Validation loss: 3.174965604363736

Epoch: 6| Step: 7
Training loss: 3.1339228082339154
Validation loss: 3.172658523151624

Epoch: 6| Step: 8
Training loss: 3.052868079285688
Validation loss: 3.172636006987569

Epoch: 6| Step: 9
Training loss: 2.2249473737000756
Validation loss: 3.1717491721022477

Epoch: 6| Step: 10
Training loss: 3.01690583378675
Validation loss: 3.172263829178981

Epoch: 6| Step: 11
Training loss: 4.021872799508916
Validation loss: 3.172398947696491

Epoch: 6| Step: 12
Training loss: 3.607922546638032
Validation loss: 3.1724116786027228

Epoch: 6| Step: 13
Training loss: 3.476162525271166
Validation loss: 3.172158518405861

Epoch: 49| Step: 0
Training loss: 4.526163337339298
Validation loss: 3.173848375077562

Epoch: 6| Step: 1
Training loss: 3.180508594268044
Validation loss: 3.1722717796731157

Epoch: 6| Step: 2
Training loss: 2.844163131048503
Validation loss: 3.1725743943825297

Epoch: 6| Step: 3
Training loss: 2.4347828123139954
Validation loss: 3.17334880743996

Epoch: 6| Step: 4
Training loss: 3.3147713413462108
Validation loss: 3.171729534229792

Epoch: 6| Step: 5
Training loss: 2.539585658242651
Validation loss: 3.1705376686039894

Epoch: 6| Step: 6
Training loss: 2.8724377036249287
Validation loss: 3.1697481805206653

Epoch: 6| Step: 7
Training loss: 3.329796313222301
Validation loss: 3.170832937790172

Epoch: 6| Step: 8
Training loss: 3.6491429302462532
Validation loss: 3.1701145909261883

Epoch: 6| Step: 9
Training loss: 3.5172271468691556
Validation loss: 3.169765045233342

Epoch: 6| Step: 10
Training loss: 3.618851808160128
Validation loss: 3.1681965924711473

Epoch: 6| Step: 11
Training loss: 3.1494793173956745
Validation loss: 3.1681743868816863

Epoch: 6| Step: 12
Training loss: 4.1021707138330665
Validation loss: 3.167855386678343

Epoch: 6| Step: 13
Training loss: 4.810315515713889
Validation loss: 3.1682105621201457

Epoch: 50| Step: 0
Training loss: 2.7519788558114415
Validation loss: 3.1677112610503886

Epoch: 6| Step: 1
Training loss: 4.01425111772206
Validation loss: 3.1665857225920084

Epoch: 6| Step: 2
Training loss: 3.7321788762636645
Validation loss: 3.167051082026021

Epoch: 6| Step: 3
Training loss: 3.638250141203298
Validation loss: 3.165305041349554

Epoch: 6| Step: 4
Training loss: 3.0960901830682994
Validation loss: 3.164654141350001

Epoch: 6| Step: 5
Training loss: 3.253381290655569
Validation loss: 3.166389869893764

Epoch: 6| Step: 6
Training loss: 3.036537356954171
Validation loss: 3.1645730491258885

Epoch: 6| Step: 7
Training loss: 3.951749660393225
Validation loss: 3.164583144654778

Epoch: 6| Step: 8
Training loss: 3.1477590733953997
Validation loss: 3.1647728126096992

Epoch: 6| Step: 9
Training loss: 2.6786733771405142
Validation loss: 3.1643427404794626

Epoch: 6| Step: 10
Training loss: 3.134398708082695
Validation loss: 3.166013163397947

Epoch: 6| Step: 11
Training loss: 3.744881761056933
Validation loss: 3.165947941582714

Epoch: 6| Step: 12
Training loss: 3.786329530451805
Validation loss: 3.166078183868468

Epoch: 6| Step: 13
Training loss: 3.8905530562892046
Validation loss: 3.168999155087927

Epoch: 51| Step: 0
Training loss: 2.9530878619729934
Validation loss: 3.166342646391643

Epoch: 6| Step: 1
Training loss: 3.5345708035602934
Validation loss: 3.168493801593837

Epoch: 6| Step: 2
Training loss: 2.695327714517747
Validation loss: 3.1669639152128597

Epoch: 6| Step: 3
Training loss: 3.749184964936533
Validation loss: 3.1673237556570353

Epoch: 6| Step: 4
Training loss: 3.805159208598663
Validation loss: 3.1653808990722276

Epoch: 6| Step: 5
Training loss: 3.1481642687349485
Validation loss: 3.1694453347931923

Epoch: 6| Step: 6
Training loss: 3.3984407271446604
Validation loss: 3.1649524639804048

Epoch: 6| Step: 7
Training loss: 3.5336653289528503
Validation loss: 3.1730189046697865

Epoch: 6| Step: 8
Training loss: 3.788682678691808
Validation loss: 3.16566525985704

Epoch: 6| Step: 9
Training loss: 3.4697937640814893
Validation loss: 3.1638903815254946

Epoch: 6| Step: 10
Training loss: 3.665292626911739
Validation loss: 3.1637192179739246

Epoch: 6| Step: 11
Training loss: 3.818760219129509
Validation loss: 3.160431398787078

Epoch: 6| Step: 12
Training loss: 3.2592244919052837
Validation loss: 3.1629987684015237

Epoch: 6| Step: 13
Training loss: 2.4296217538456997
Validation loss: 3.1619509521140987

Epoch: 52| Step: 0
Training loss: 3.3122811874958717
Validation loss: 3.1620321918484464

Epoch: 6| Step: 1
Training loss: 4.1476889184529995
Validation loss: 3.1609558288880777

Epoch: 6| Step: 2
Training loss: 3.193048472537433
Validation loss: 3.160883736932426

Epoch: 6| Step: 3
Training loss: 4.074522100403885
Validation loss: 3.1612053788693153

Epoch: 6| Step: 4
Training loss: 3.135441996492153
Validation loss: 3.161282454077593

Epoch: 6| Step: 5
Training loss: 3.4147347982040173
Validation loss: 3.1606460865592605

Epoch: 6| Step: 6
Training loss: 4.049892876232649
Validation loss: 3.1594805442075065

Epoch: 6| Step: 7
Training loss: 3.5487458928626285
Validation loss: 3.1582848434585316

Epoch: 6| Step: 8
Training loss: 2.631261895304633
Validation loss: 3.1577194628569965

Epoch: 6| Step: 9
Training loss: 3.15523218041156
Validation loss: 3.1592147955796714

Epoch: 6| Step: 10
Training loss: 3.646027056678909
Validation loss: 3.157873300955642

Epoch: 6| Step: 11
Training loss: 3.0425898226641546
Validation loss: 3.157853469631166

Epoch: 6| Step: 12
Training loss: 2.711253035153651
Validation loss: 3.160275112873519

Epoch: 6| Step: 13
Training loss: 3.5518972995104363
Validation loss: 3.1600943810961106

Epoch: 53| Step: 0
Training loss: 3.1920719643035884
Validation loss: 3.1630220088663186

Epoch: 6| Step: 1
Training loss: 2.4892110719179845
Validation loss: 3.1643341851224966

Epoch: 6| Step: 2
Training loss: 2.821730069888116
Validation loss: 3.163171395735936

Epoch: 6| Step: 3
Training loss: 3.636221518773815
Validation loss: 3.164012329724704

Epoch: 6| Step: 4
Training loss: 3.7217195339066724
Validation loss: 3.164015736013399

Epoch: 6| Step: 5
Training loss: 3.027640799438534
Validation loss: 3.1689988622390155

Epoch: 6| Step: 6
Training loss: 2.857685194313713
Validation loss: 3.174109918218152

Epoch: 6| Step: 7
Training loss: 3.684192790799009
Validation loss: 3.1741006267424954

Epoch: 6| Step: 8
Training loss: 2.8019981134967864
Validation loss: 3.1869485359162546

Epoch: 6| Step: 9
Training loss: 4.014589168674337
Validation loss: 3.205969340816613

Epoch: 6| Step: 10
Training loss: 4.259683012653187
Validation loss: 3.1756159311501504

Epoch: 6| Step: 11
Training loss: 3.671382919778341
Validation loss: 3.1626504554482815

Epoch: 6| Step: 12
Training loss: 3.5771288422118905
Validation loss: 3.1562994115781917

Epoch: 6| Step: 13
Training loss: 3.9320909192040827
Validation loss: 3.1558171262464945

Epoch: 54| Step: 0
Training loss: 3.5512082689808175
Validation loss: 3.158387621678887

Epoch: 6| Step: 1
Training loss: 3.0155130474280796
Validation loss: 3.1548512008202536

Epoch: 6| Step: 2
Training loss: 3.403074972102006
Validation loss: 3.156794824791649

Epoch: 6| Step: 3
Training loss: 3.2382394307085605
Validation loss: 3.1577388144022067

Epoch: 6| Step: 4
Training loss: 3.15664202077953
Validation loss: 3.157591968314495

Epoch: 6| Step: 5
Training loss: 4.034223775592724
Validation loss: 3.1565136981574615

Epoch: 6| Step: 6
Training loss: 3.215888668182943
Validation loss: 3.1572519761027604

Epoch: 6| Step: 7
Training loss: 3.700088608170484
Validation loss: 3.156758660040672

Epoch: 6| Step: 8
Training loss: 3.2035316767370072
Validation loss: 3.1539467394289145

Epoch: 6| Step: 9
Training loss: 3.0789075137573527
Validation loss: 3.1558587006251675

Epoch: 6| Step: 10
Training loss: 4.199254632840875
Validation loss: 3.1545440244793546

Epoch: 6| Step: 11
Training loss: 3.4297258726853928
Validation loss: 3.1515649547979456

Epoch: 6| Step: 12
Training loss: 2.923937717134488
Validation loss: 3.1534147488425206

Epoch: 6| Step: 13
Training loss: 3.5197183472484728
Validation loss: 3.157288822134317

Epoch: 55| Step: 0
Training loss: 3.0121227740510563
Validation loss: 3.155632979720756

Epoch: 6| Step: 1
Training loss: 3.1641581956497005
Validation loss: 3.1603323836434463

Epoch: 6| Step: 2
Training loss: 3.0842181474095742
Validation loss: 3.158664093265479

Epoch: 6| Step: 3
Training loss: 4.533567270151968
Validation loss: 3.156939362715267

Epoch: 6| Step: 4
Training loss: 3.93689420369272
Validation loss: 3.1590898235155027

Epoch: 6| Step: 5
Training loss: 3.094578025289078
Validation loss: 3.162727378716869

Epoch: 6| Step: 6
Training loss: 3.4804875194587193
Validation loss: 3.1626642858546123

Epoch: 6| Step: 7
Training loss: 2.5714852576592553
Validation loss: 3.1640137265952024

Epoch: 6| Step: 8
Training loss: 3.428944848365503
Validation loss: 3.15757049680347

Epoch: 6| Step: 9
Training loss: 3.352788669751446
Validation loss: 3.15923115498058

Epoch: 6| Step: 10
Training loss: 3.5412644700206815
Validation loss: 3.158248157593516

Epoch: 6| Step: 11
Training loss: 3.074540117811956
Validation loss: 3.152640432072075

Epoch: 6| Step: 12
Training loss: 3.3094814150147642
Validation loss: 3.1544888136428657

Epoch: 6| Step: 13
Training loss: 4.058951838449857
Validation loss: 3.153651318325557

Epoch: 56| Step: 0
Training loss: 3.640616879433674
Validation loss: 3.156202251146653

Epoch: 6| Step: 1
Training loss: 3.1292928583035793
Validation loss: 3.1573102111160285

Epoch: 6| Step: 2
Training loss: 3.060765612197788
Validation loss: 3.1563888140773946

Epoch: 6| Step: 3
Training loss: 3.1620487539548936
Validation loss: 3.158451694438809

Epoch: 6| Step: 4
Training loss: 3.736530527793375
Validation loss: 3.156773479420152

Epoch: 6| Step: 5
Training loss: 3.41875283975152
Validation loss: 3.1539698840288874

Epoch: 6| Step: 6
Training loss: 2.7232709105989894
Validation loss: 3.1543709932691106

Epoch: 6| Step: 7
Training loss: 4.1344394762428
Validation loss: 3.154404017421472

Epoch: 6| Step: 8
Training loss: 2.917894885904142
Validation loss: 3.1508078347097803

Epoch: 6| Step: 9
Training loss: 3.7813960275747895
Validation loss: 3.153209985221736

Epoch: 6| Step: 10
Training loss: 3.3474066873867776
Validation loss: 3.154058259333829

Epoch: 6| Step: 11
Training loss: 3.713680755164846
Validation loss: 3.161183648060225

Epoch: 6| Step: 12
Training loss: 2.929900708387699
Validation loss: 3.160850919170632

Epoch: 6| Step: 13
Training loss: 3.946113610845449
Validation loss: 3.16580862511189

Epoch: 57| Step: 0
Training loss: 3.7971988743924134
Validation loss: 3.165720886372683

Epoch: 6| Step: 1
Training loss: 3.555906920820765
Validation loss: 3.1664710427001848

Epoch: 6| Step: 2
Training loss: 2.3984406809832324
Validation loss: 3.164870374962783

Epoch: 6| Step: 3
Training loss: 2.86213125993919
Validation loss: 3.1573672433617883

Epoch: 6| Step: 4
Training loss: 3.583512028223276
Validation loss: 3.154406000452545

Epoch: 6| Step: 5
Training loss: 3.0628400341361335
Validation loss: 3.1456909967851665

Epoch: 6| Step: 6
Training loss: 3.477315962506224
Validation loss: 3.145418408814127

Epoch: 6| Step: 7
Training loss: 3.872637120596541
Validation loss: 3.145602282084069

Epoch: 6| Step: 8
Training loss: 3.2098005003448673
Validation loss: 3.1461971170139753

Epoch: 6| Step: 9
Training loss: 4.068394067902966
Validation loss: 3.1462145414592673

Epoch: 6| Step: 10
Training loss: 3.5146203534148173
Validation loss: 3.149337178734076

Epoch: 6| Step: 11
Training loss: 3.8316561858531766
Validation loss: 3.152632085658051

Epoch: 6| Step: 12
Training loss: 2.687668462396995
Validation loss: 3.1453417631841902

Epoch: 6| Step: 13
Training loss: 3.361831831221421
Validation loss: 3.1397330361758655

Epoch: 58| Step: 0
Training loss: 3.7421798546699043
Validation loss: 3.141290799700868

Epoch: 6| Step: 1
Training loss: 3.5092177942652536
Validation loss: 3.1414645791117444

Epoch: 6| Step: 2
Training loss: 3.812490869730038
Validation loss: 3.141127898174327

Epoch: 6| Step: 3
Training loss: 3.2065633044433772
Validation loss: 3.1436987593559667

Epoch: 6| Step: 4
Training loss: 3.3239401712920618
Validation loss: 3.138451503440407

Epoch: 6| Step: 5
Training loss: 2.7723384775041624
Validation loss: 3.1363961483194407

Epoch: 6| Step: 6
Training loss: 3.376862471220309
Validation loss: 3.1388733383356393

Epoch: 6| Step: 7
Training loss: 2.825817536745174
Validation loss: 3.13750619175595

Epoch: 6| Step: 8
Training loss: 3.863973372341995
Validation loss: 3.1362176036428915

Epoch: 6| Step: 9
Training loss: 3.2909896894842294
Validation loss: 3.1367694385443743

Epoch: 6| Step: 10
Training loss: 3.0297684342432376
Validation loss: 3.1350400248283465

Epoch: 6| Step: 11
Training loss: 3.8667322372489252
Validation loss: 3.133484983101654

Epoch: 6| Step: 12
Training loss: 3.7574118799167273
Validation loss: 3.1329200220251607

Epoch: 6| Step: 13
Training loss: 2.5690706261785996
Validation loss: 3.133816719492357

Epoch: 59| Step: 0
Training loss: 3.7297475067668318
Validation loss: 3.133503306191796

Epoch: 6| Step: 1
Training loss: 4.035374623507808
Validation loss: 3.1307788289618745

Epoch: 6| Step: 2
Training loss: 2.747142954875167
Validation loss: 3.1322501856818636

Epoch: 6| Step: 3
Training loss: 3.862129494880964
Validation loss: 3.1315358665028583

Epoch: 6| Step: 4
Training loss: 3.0819458460125326
Validation loss: 3.1319087717635448

Epoch: 6| Step: 5
Training loss: 3.108866127584648
Validation loss: 3.133073472401004

Epoch: 6| Step: 6
Training loss: 3.483221846869544
Validation loss: 3.128313577757551

Epoch: 6| Step: 7
Training loss: 3.8149006273918853
Validation loss: 3.1296280486197463

Epoch: 6| Step: 8
Training loss: 3.567510193754735
Validation loss: 3.131670563101996

Epoch: 6| Step: 9
Training loss: 2.976117118294682
Validation loss: 3.128495087589982

Epoch: 6| Step: 10
Training loss: 3.0442856961494718
Validation loss: 3.129652700078718

Epoch: 6| Step: 11
Training loss: 2.32587062572987
Validation loss: 3.129226607334145

Epoch: 6| Step: 12
Training loss: 3.1720705770695967
Validation loss: 3.1307644482717323

Epoch: 6| Step: 13
Training loss: 4.404894248221255
Validation loss: 3.132633926203472

Epoch: 60| Step: 0
Training loss: 3.571370107989676
Validation loss: 3.1442017064793717

Epoch: 6| Step: 1
Training loss: 3.5161438961680123
Validation loss: 3.1339743403831015

Epoch: 6| Step: 2
Training loss: 2.658029296931689
Validation loss: 3.1271255040950736

Epoch: 6| Step: 3
Training loss: 3.3657350881665984
Validation loss: 3.1260866650772234

Epoch: 6| Step: 4
Training loss: 3.6366088719471077
Validation loss: 3.124771259098909

Epoch: 6| Step: 5
Training loss: 3.4600365975269085
Validation loss: 3.128227650777101

Epoch: 6| Step: 6
Training loss: 4.305061227183628
Validation loss: 3.1311287665690726

Epoch: 6| Step: 7
Training loss: 3.551834873373536
Validation loss: 3.1232529726191287

Epoch: 6| Step: 8
Training loss: 2.43281721581386
Validation loss: 3.1249305684569872

Epoch: 6| Step: 9
Training loss: 2.737215060380474
Validation loss: 3.1280861167191225

Epoch: 6| Step: 10
Training loss: 3.646031764852037
Validation loss: 3.131940565928505

Epoch: 6| Step: 11
Training loss: 3.64537086096727
Validation loss: 3.136040405813198

Epoch: 6| Step: 12
Training loss: 2.6382894627130096
Validation loss: 3.135815081461273

Epoch: 6| Step: 13
Training loss: 3.99074293901803
Validation loss: 3.1321093646030485

Epoch: 61| Step: 0
Training loss: 4.006923643895987
Validation loss: 3.124938383417871

Epoch: 6| Step: 1
Training loss: 2.9193528657538397
Validation loss: 3.12174224533478

Epoch: 6| Step: 2
Training loss: 3.342964008681859
Validation loss: 3.121493535183624

Epoch: 6| Step: 3
Training loss: 2.9460050138079934
Validation loss: 3.1204489204397263

Epoch: 6| Step: 4
Training loss: 3.370875204523332
Validation loss: 3.1218700477177896

Epoch: 6| Step: 5
Training loss: 3.666528713636696
Validation loss: 3.122322658380735

Epoch: 6| Step: 6
Training loss: 3.18051893906336
Validation loss: 3.1226266326838354

Epoch: 6| Step: 7
Training loss: 2.5798465414022322
Validation loss: 3.1238030255749143

Epoch: 6| Step: 8
Training loss: 3.944560426848544
Validation loss: 3.126512402675235

Epoch: 6| Step: 9
Training loss: 3.1262552410632423
Validation loss: 3.1275622997654753

Epoch: 6| Step: 10
Training loss: 4.045342939666762
Validation loss: 3.127997126462227

Epoch: 6| Step: 11
Training loss: 3.0774338619212456
Validation loss: 3.123608873068981

Epoch: 6| Step: 12
Training loss: 3.432429926880066
Validation loss: 3.1264326244947886

Epoch: 6| Step: 13
Training loss: 3.396668282740255
Validation loss: 3.124131179955649

Epoch: 62| Step: 0
Training loss: 3.4045257403884865
Validation loss: 3.123831847700709

Epoch: 6| Step: 1
Training loss: 3.1442584375542904
Validation loss: 3.121825455276111

Epoch: 6| Step: 2
Training loss: 3.1580930559727185
Validation loss: 3.1178856457819926

Epoch: 6| Step: 3
Training loss: 2.9173227026511497
Validation loss: 3.1226831654419747

Epoch: 6| Step: 4
Training loss: 3.226455206391767
Validation loss: 3.1169831068630036

Epoch: 6| Step: 5
Training loss: 3.2384280549975197
Validation loss: 3.119364989070622

Epoch: 6| Step: 6
Training loss: 3.578046239794003
Validation loss: 3.119249022665177

Epoch: 6| Step: 7
Training loss: 2.7517545478168404
Validation loss: 3.1193447682824624

Epoch: 6| Step: 8
Training loss: 3.1393390509012677
Validation loss: 3.1155688100364776

Epoch: 6| Step: 9
Training loss: 3.1088538571791777
Validation loss: 3.12111438164961

Epoch: 6| Step: 10
Training loss: 4.309611804588669
Validation loss: 3.1197855704859143

Epoch: 6| Step: 11
Training loss: 3.7867316244043057
Validation loss: 3.1226199137065125

Epoch: 6| Step: 12
Training loss: 4.156310575803865
Validation loss: 3.1228386293545496

Epoch: 6| Step: 13
Training loss: 2.6561413013432507
Validation loss: 3.120469571962329

Epoch: 63| Step: 0
Training loss: 3.906270629828337
Validation loss: 3.116694046140652

Epoch: 6| Step: 1
Training loss: 3.5102269756256725
Validation loss: 3.1156701224144197

Epoch: 6| Step: 2
Training loss: 3.220275221252114
Validation loss: 3.1159450190937155

Epoch: 6| Step: 3
Training loss: 2.462043634717494
Validation loss: 3.115932086275411

Epoch: 6| Step: 4
Training loss: 3.6786449599621704
Validation loss: 3.1172062215366987

Epoch: 6| Step: 5
Training loss: 3.301475605360507
Validation loss: 3.113935366893324

Epoch: 6| Step: 6
Training loss: 2.862807917795802
Validation loss: 3.114518879414114

Epoch: 6| Step: 7
Training loss: 3.3960245620773875
Validation loss: 3.114525130224657

Epoch: 6| Step: 8
Training loss: 3.268287412978021
Validation loss: 3.1151364374120343

Epoch: 6| Step: 9
Training loss: 2.878790471351101
Validation loss: 3.1149606904471976

Epoch: 6| Step: 10
Training loss: 2.9589972668861075
Validation loss: 3.115310943379524

Epoch: 6| Step: 11
Training loss: 3.851554328956216
Validation loss: 3.113880718735522

Epoch: 6| Step: 12
Training loss: 3.975540719352585
Validation loss: 3.1162607058785055

Epoch: 6| Step: 13
Training loss: 3.7616888344150543
Validation loss: 3.1142206861961412

Epoch: 64| Step: 0
Training loss: 3.62858667188088
Validation loss: 3.1123543873737325

Epoch: 6| Step: 1
Training loss: 2.92219680401183
Validation loss: 3.1122137896272837

Epoch: 6| Step: 2
Training loss: 2.8697747554846176
Validation loss: 3.114994988334808

Epoch: 6| Step: 3
Training loss: 3.2134477219330453
Validation loss: 3.1125602663948615

Epoch: 6| Step: 4
Training loss: 3.409103178522399
Validation loss: 3.113696627953626

Epoch: 6| Step: 5
Training loss: 3.2965596848252625
Validation loss: 3.1118665180094367

Epoch: 6| Step: 6
Training loss: 3.6509961584776764
Validation loss: 3.113593224223344

Epoch: 6| Step: 7
Training loss: 3.22860601336719
Validation loss: 3.111908925055308

Epoch: 6| Step: 8
Training loss: 3.484279751010355
Validation loss: 3.1128149859047674

Epoch: 6| Step: 9
Training loss: 3.587640229252479
Validation loss: 3.11233444145846

Epoch: 6| Step: 10
Training loss: 3.863068947970945
Validation loss: 3.109324720700386

Epoch: 6| Step: 11
Training loss: 3.795790277956425
Validation loss: 3.1104714261035853

Epoch: 6| Step: 12
Training loss: 2.972321941410229
Validation loss: 3.1112767121511116

Epoch: 6| Step: 13
Training loss: 2.8042501039453125
Validation loss: 3.1117911764418547

Epoch: 65| Step: 0
Training loss: 3.6218018729304746
Validation loss: 3.1168926168515827

Epoch: 6| Step: 1
Training loss: 3.4494753231299993
Validation loss: 3.1133258001328556

Epoch: 6| Step: 2
Training loss: 3.1805595682961934
Validation loss: 3.1146620818907325

Epoch: 6| Step: 3
Training loss: 3.1993095189447134
Validation loss: 3.112423083867263

Epoch: 6| Step: 4
Training loss: 3.2775075732855807
Validation loss: 3.112389057460603

Epoch: 6| Step: 5
Training loss: 3.4501893696435513
Validation loss: 3.1110599854097347

Epoch: 6| Step: 6
Training loss: 3.09164619199103
Validation loss: 3.1153294342573754

Epoch: 6| Step: 7
Training loss: 3.873178238403556
Validation loss: 3.111306914295267

Epoch: 6| Step: 8
Training loss: 3.3224125941184126
Validation loss: 3.109844932223606

Epoch: 6| Step: 9
Training loss: 3.263447742995841
Validation loss: 3.110238392209369

Epoch: 6| Step: 10
Training loss: 4.155797718650985
Validation loss: 3.1109088806585254

Epoch: 6| Step: 11
Training loss: 2.946553340763717
Validation loss: 3.1029703021045862

Epoch: 6| Step: 12
Training loss: 2.5724251363851014
Validation loss: 3.1062896190523386

Epoch: 6| Step: 13
Training loss: 3.516333343353498
Validation loss: 3.1075425990332017

Epoch: 66| Step: 0
Training loss: 3.0166168953458663
Validation loss: 3.105319116771587

Epoch: 6| Step: 1
Training loss: 2.432056706997147
Validation loss: 3.1059502683707314

Epoch: 6| Step: 2
Training loss: 3.8070561048673697
Validation loss: 3.105976929390261

Epoch: 6| Step: 3
Training loss: 3.167088246307624
Validation loss: 3.1065629039367755

Epoch: 6| Step: 4
Training loss: 3.812951608394282
Validation loss: 3.1064126565917363

Epoch: 6| Step: 5
Training loss: 4.082101337616009
Validation loss: 3.1047447846142417

Epoch: 6| Step: 6
Training loss: 3.0278071091968406
Validation loss: 3.102227664101843

Epoch: 6| Step: 7
Training loss: 3.395778694571377
Validation loss: 3.10460043105906

Epoch: 6| Step: 8
Training loss: 3.6449960819008784
Validation loss: 3.102723858247794

Epoch: 6| Step: 9
Training loss: 3.454692087985632
Validation loss: 3.102898143550861

Epoch: 6| Step: 10
Training loss: 3.2295651261796596
Validation loss: 3.103905812119566

Epoch: 6| Step: 11
Training loss: 2.8488100746720084
Validation loss: 3.103513554932905

Epoch: 6| Step: 12
Training loss: 3.245905130463119
Validation loss: 3.104585534395529

Epoch: 6| Step: 13
Training loss: 3.7901912934835797
Validation loss: 3.104291363496656

Epoch: 67| Step: 0
Training loss: 3.8891201556029094
Validation loss: 3.1040145667181176

Epoch: 6| Step: 1
Training loss: 3.8537014792199957
Validation loss: 3.104583159510635

Epoch: 6| Step: 2
Training loss: 3.816155354150525
Validation loss: 3.103724066913609

Epoch: 6| Step: 3
Training loss: 2.5906450921948725
Validation loss: 3.1025282048456027

Epoch: 6| Step: 4
Training loss: 3.967544733094568
Validation loss: 3.1018611464237624

Epoch: 6| Step: 5
Training loss: 3.3762829073022895
Validation loss: 3.103182081876376

Epoch: 6| Step: 6
Training loss: 3.559940556447803
Validation loss: 3.102664995293938

Epoch: 6| Step: 7
Training loss: 3.2027135072957202
Validation loss: 3.103540718464894

Epoch: 6| Step: 8
Training loss: 3.000160054069886
Validation loss: 3.1026702801157167

Epoch: 6| Step: 9
Training loss: 3.0989161042400233
Validation loss: 3.100524717150774

Epoch: 6| Step: 10
Training loss: 3.1436030753595716
Validation loss: 3.1031952454491756

Epoch: 6| Step: 11
Training loss: 3.5734945261833144
Validation loss: 3.1004191707675925

Epoch: 6| Step: 12
Training loss: 2.2095240735557318
Validation loss: 3.1001683861275624

Epoch: 6| Step: 13
Training loss: 3.2129737356271804
Validation loss: 3.098986788700314

Epoch: 68| Step: 0
Training loss: 3.2399426881407214
Validation loss: 3.0964734439228487

Epoch: 6| Step: 1
Training loss: 3.2390097614269613
Validation loss: 3.0969048046525818

Epoch: 6| Step: 2
Training loss: 4.0834411814454015
Validation loss: 3.0977244092712604

Epoch: 6| Step: 3
Training loss: 3.7274097303260736
Validation loss: 3.0980059221745564

Epoch: 6| Step: 4
Training loss: 3.1810524749888693
Validation loss: 3.095932720967644

Epoch: 6| Step: 5
Training loss: 3.6410537925629325
Validation loss: 3.095097848663251

Epoch: 6| Step: 6
Training loss: 3.789859271091439
Validation loss: 3.0965905695870415

Epoch: 6| Step: 7
Training loss: 2.430234203590625
Validation loss: 3.0957750918608964

Epoch: 6| Step: 8
Training loss: 2.346412468855172
Validation loss: 3.092645459776697

Epoch: 6| Step: 9
Training loss: 3.7190382388950076
Validation loss: 3.0940334902408737

Epoch: 6| Step: 10
Training loss: 3.607404162534345
Validation loss: 3.0939514783988584

Epoch: 6| Step: 11
Training loss: 2.9145369974360986
Validation loss: 3.0936166770417555

Epoch: 6| Step: 12
Training loss: 3.4351478158388757
Validation loss: 3.092450282909306

Epoch: 6| Step: 13
Training loss: 3.0169624169587856
Validation loss: 3.0910673388179735

Epoch: 69| Step: 0
Training loss: 3.2799007002988367
Validation loss: 3.0926906843332587

Epoch: 6| Step: 1
Training loss: 3.1524183224315347
Validation loss: 3.091003365477571

Epoch: 6| Step: 2
Training loss: 3.7612092652528557
Validation loss: 3.0917686895553493

Epoch: 6| Step: 3
Training loss: 3.38702398242462
Validation loss: 3.0903058943545356

Epoch: 6| Step: 4
Training loss: 3.1184096462169064
Validation loss: 3.090959097413473

Epoch: 6| Step: 5
Training loss: 3.393437497976549
Validation loss: 3.0914444729596062

Epoch: 6| Step: 6
Training loss: 3.545466878731713
Validation loss: 3.090606170998082

Epoch: 6| Step: 7
Training loss: 3.293178420445318
Validation loss: 3.091432313356904

Epoch: 6| Step: 8
Training loss: 3.094568009556663
Validation loss: 3.0904323322772473

Epoch: 6| Step: 9
Training loss: 2.664226269652366
Validation loss: 3.088454755449677

Epoch: 6| Step: 10
Training loss: 3.721386399695662
Validation loss: 3.0900490820934703

Epoch: 6| Step: 11
Training loss: 3.0923119487652864
Validation loss: 3.0893886032794646

Epoch: 6| Step: 12
Training loss: 3.186558603133037
Validation loss: 3.092944330635857

Epoch: 6| Step: 13
Training loss: 4.5227830377158265
Validation loss: 3.089576940431903

Epoch: 70| Step: 0
Training loss: 3.12104745766084
Validation loss: 3.0897863243309778

Epoch: 6| Step: 1
Training loss: 3.8586617864838457
Validation loss: 3.0876421190207752

Epoch: 6| Step: 2
Training loss: 3.6408631079089235
Validation loss: 3.0861765505028904

Epoch: 6| Step: 3
Training loss: 2.634738116053576
Validation loss: 3.0861958140284282

Epoch: 6| Step: 4
Training loss: 2.626202081009817
Validation loss: 3.0847167780718574

Epoch: 6| Step: 5
Training loss: 3.6940162110935932
Validation loss: 3.085062638438959

Epoch: 6| Step: 6
Training loss: 3.387420968685734
Validation loss: 3.084099130446945

Epoch: 6| Step: 7
Training loss: 3.543683872581462
Validation loss: 3.081004829706043

Epoch: 6| Step: 8
Training loss: 3.87882462307114
Validation loss: 3.0825044027101987

Epoch: 6| Step: 9
Training loss: 3.5071580442000427
Validation loss: 3.0837610879815758

Epoch: 6| Step: 10
Training loss: 2.7207042642058363
Validation loss: 3.0809106327181386

Epoch: 6| Step: 11
Training loss: 3.341621077710929
Validation loss: 3.079898885065439

Epoch: 6| Step: 12
Training loss: 3.1912460753868346
Validation loss: 3.0821259325997112

Epoch: 6| Step: 13
Training loss: 3.357034835121064
Validation loss: 3.081044940664273

Epoch: 71| Step: 0
Training loss: 3.3233889699530312
Validation loss: 3.0816936695088897

Epoch: 6| Step: 1
Training loss: 3.8409969736339087
Validation loss: 3.0795598329428002

Epoch: 6| Step: 2
Training loss: 2.924571705297004
Validation loss: 3.078951618710565

Epoch: 6| Step: 3
Training loss: 3.527524079606282
Validation loss: 3.0791128857538217

Epoch: 6| Step: 4
Training loss: 3.749906157273071
Validation loss: 3.0783767093400414

Epoch: 6| Step: 5
Training loss: 3.020662044185126
Validation loss: 3.079314762389304

Epoch: 6| Step: 6
Training loss: 3.213292801101442
Validation loss: 3.0771032627840644

Epoch: 6| Step: 7
Training loss: 2.985888352081945
Validation loss: 3.076585576993482

Epoch: 6| Step: 8
Training loss: 3.068558908017354
Validation loss: 3.0784307419317796

Epoch: 6| Step: 9
Training loss: 3.3474323282388654
Validation loss: 3.0771177384605255

Epoch: 6| Step: 10
Training loss: 3.5305288473046628
Validation loss: 3.07782172818338

Epoch: 6| Step: 11
Training loss: 3.490002659138101
Validation loss: 3.082813244573665

Epoch: 6| Step: 12
Training loss: 2.8457329512206666
Validation loss: 3.0754365350546253

Epoch: 6| Step: 13
Training loss: 4.007618562939904
Validation loss: 3.0766458004929484

Epoch: 72| Step: 0
Training loss: 3.46243343358142
Validation loss: 3.078552622825036

Epoch: 6| Step: 1
Training loss: 3.1332920687237644
Validation loss: 3.075844024881352

Epoch: 6| Step: 2
Training loss: 3.842159903769656
Validation loss: 3.0763969636711437

Epoch: 6| Step: 3
Training loss: 3.0855247511253463
Validation loss: 3.0807582863660863

Epoch: 6| Step: 4
Training loss: 2.4459099085538125
Validation loss: 3.076921316677612

Epoch: 6| Step: 5
Training loss: 3.829966448644387
Validation loss: 3.0746179397529607

Epoch: 6| Step: 6
Training loss: 3.1920933258161823
Validation loss: 3.0783975539974424

Epoch: 6| Step: 7
Training loss: 4.096469587319548
Validation loss: 3.0770124372950747

Epoch: 6| Step: 8
Training loss: 3.6815421903286567
Validation loss: 3.0760990194745528

Epoch: 6| Step: 9
Training loss: 3.022504795723795
Validation loss: 3.0806565398607586

Epoch: 6| Step: 10
Training loss: 2.968042871684838
Validation loss: 3.080307610569432

Epoch: 6| Step: 11
Training loss: 3.3888708402503944
Validation loss: 3.0806708898266137

Epoch: 6| Step: 12
Training loss: 3.036282481384546
Validation loss: 3.080615243807813

Epoch: 6| Step: 13
Training loss: 3.1588234560554156
Validation loss: 3.0766813170895344

Epoch: 73| Step: 0
Training loss: 3.446966972057829
Validation loss: 3.08273712808343

Epoch: 6| Step: 1
Training loss: 3.216710305453226
Validation loss: 3.079912603459709

Epoch: 6| Step: 2
Training loss: 3.360637480797914
Validation loss: 3.083023578435451

Epoch: 6| Step: 3
Training loss: 3.5512361979929676
Validation loss: 3.077156130540657

Epoch: 6| Step: 4
Training loss: 3.664494665886558
Validation loss: 3.0774531951669464

Epoch: 6| Step: 5
Training loss: 3.424524265857775
Validation loss: 3.078328008241775

Epoch: 6| Step: 6
Training loss: 3.035542545749953
Validation loss: 3.0773601990428623

Epoch: 6| Step: 7
Training loss: 3.6679948799738202
Validation loss: 3.0781023794970954

Epoch: 6| Step: 8
Training loss: 3.81926252606193
Validation loss: 3.0755913314011583

Epoch: 6| Step: 9
Training loss: 2.680073346088009
Validation loss: 3.0762909186488607

Epoch: 6| Step: 10
Training loss: 3.2031644493092837
Validation loss: 3.0733829440002194

Epoch: 6| Step: 11
Training loss: 3.2444550088016606
Validation loss: 3.0783956760686513

Epoch: 6| Step: 12
Training loss: 3.125087126470983
Validation loss: 3.075746740082539

Epoch: 6| Step: 13
Training loss: 2.922853030769344
Validation loss: 3.0759690836707816

Epoch: 74| Step: 0
Training loss: 3.1761827203379895
Validation loss: 3.075968043535472

Epoch: 6| Step: 1
Training loss: 3.154467542064427
Validation loss: 3.074327589140183

Epoch: 6| Step: 2
Training loss: 3.7674189049916493
Validation loss: 3.076959079663137

Epoch: 6| Step: 3
Training loss: 3.3114986705613205
Validation loss: 3.0764544434405754

Epoch: 6| Step: 4
Training loss: 4.183712513268181
Validation loss: 3.0725444409054172

Epoch: 6| Step: 5
Training loss: 2.8366668015632044
Validation loss: 3.0706951661989343

Epoch: 6| Step: 6
Training loss: 3.5247867817343863
Validation loss: 3.069829527956679

Epoch: 6| Step: 7
Training loss: 2.97506011132811
Validation loss: 3.06737115592954

Epoch: 6| Step: 8
Training loss: 3.2755175698417185
Validation loss: 3.068761806416455

Epoch: 6| Step: 9
Training loss: 2.7156492067581666
Validation loss: 3.0678153438335345

Epoch: 6| Step: 10
Training loss: 3.440091352802277
Validation loss: 3.065074589333654

Epoch: 6| Step: 11
Training loss: 3.369782406039045
Validation loss: 3.0659130616594443

Epoch: 6| Step: 12
Training loss: 2.733690448630405
Validation loss: 3.0639128549418353

Epoch: 6| Step: 13
Training loss: 4.179371017880865
Validation loss: 3.0639773504013963

Epoch: 75| Step: 0
Training loss: 3.7857723462981245
Validation loss: 3.0623035346962375

Epoch: 6| Step: 1
Training loss: 3.289267345582498
Validation loss: 3.064041986739984

Epoch: 6| Step: 2
Training loss: 2.9397210997036725
Validation loss: 3.0625647796884947

Epoch: 6| Step: 3
Training loss: 3.9108503184886847
Validation loss: 3.061570854282335

Epoch: 6| Step: 4
Training loss: 3.214510597960351
Validation loss: 3.0621285630795176

Epoch: 6| Step: 5
Training loss: 3.5660497815245824
Validation loss: 3.062794734592027

Epoch: 6| Step: 6
Training loss: 3.46411510491251
Validation loss: 3.062564768806332

Epoch: 6| Step: 7
Training loss: 3.4113642944109808
Validation loss: 3.0615939946715653

Epoch: 6| Step: 8
Training loss: 2.8364491066915116
Validation loss: 3.0626209261109034

Epoch: 6| Step: 9
Training loss: 2.2328004424274788
Validation loss: 3.0636214646651667

Epoch: 6| Step: 10
Training loss: 3.3361141685142206
Validation loss: 3.064825909646215

Epoch: 6| Step: 11
Training loss: 3.142544136314022
Validation loss: 3.0670291708673005

Epoch: 6| Step: 12
Training loss: 3.698927806462223
Validation loss: 3.0674720468558005

Epoch: 6| Step: 13
Training loss: 3.528060147523142
Validation loss: 3.0688447971754726

Epoch: 76| Step: 0
Training loss: 3.754067059267007
Validation loss: 3.066737936251975

Epoch: 6| Step: 1
Training loss: 3.3936950566742605
Validation loss: 3.061768198883707

Epoch: 6| Step: 2
Training loss: 3.7666021954805666
Validation loss: 3.058282769125994

Epoch: 6| Step: 3
Training loss: 3.3413048476181872
Validation loss: 3.0615010812028864

Epoch: 6| Step: 4
Training loss: 2.776496253567694
Validation loss: 3.0592955079950226

Epoch: 6| Step: 5
Training loss: 3.7944344420058407
Validation loss: 3.0597411807776127

Epoch: 6| Step: 6
Training loss: 3.125301499127599
Validation loss: 3.0594050020507386

Epoch: 6| Step: 7
Training loss: 3.429442933558407
Validation loss: 3.0589627264557846

Epoch: 6| Step: 8
Training loss: 2.0708193752296844
Validation loss: 3.0595186633707274

Epoch: 6| Step: 9
Training loss: 3.1821924039069978
Validation loss: 3.058013011391253

Epoch: 6| Step: 10
Training loss: 3.614828242525698
Validation loss: 3.0575729693231755

Epoch: 6| Step: 11
Training loss: 3.668911131353621
Validation loss: 3.0571355674860246

Epoch: 6| Step: 12
Training loss: 3.1808872818030087
Validation loss: 3.057847241158054

Epoch: 6| Step: 13
Training loss: 2.805389656432804
Validation loss: 3.0561825634408764

Epoch: 77| Step: 0
Training loss: 3.7734362363319573
Validation loss: 3.056585375197942

Epoch: 6| Step: 1
Training loss: 3.598266682316005
Validation loss: 3.0567419917077343

Epoch: 6| Step: 2
Training loss: 2.4088261673133444
Validation loss: 3.0559315091883827

Epoch: 6| Step: 3
Training loss: 2.9886849323945257
Validation loss: 3.057279520768313

Epoch: 6| Step: 4
Training loss: 3.0693326750400254
Validation loss: 3.055198767431678

Epoch: 6| Step: 5
Training loss: 3.2370433765200257
Validation loss: 3.058115543124774

Epoch: 6| Step: 6
Training loss: 3.8583806413313964
Validation loss: 3.0568186548518623

Epoch: 6| Step: 7
Training loss: 3.6908631586273812
Validation loss: 3.057617898500388

Epoch: 6| Step: 8
Training loss: 3.4260515478279108
Validation loss: 3.0560528889901053

Epoch: 6| Step: 9
Training loss: 3.5990684628600778
Validation loss: 3.0537743404838937

Epoch: 6| Step: 10
Training loss: 3.1376819390665824
Validation loss: 3.055258858695444

Epoch: 6| Step: 11
Training loss: 3.7151397362532266
Validation loss: 3.05775049382849

Epoch: 6| Step: 12
Training loss: 2.290583707221283
Validation loss: 3.052438880655414

Epoch: 6| Step: 13
Training loss: 3.2831602802919058
Validation loss: 3.05279065435473

Epoch: 78| Step: 0
Training loss: 3.114637665715916
Validation loss: 3.051853185673683

Epoch: 6| Step: 1
Training loss: 3.7510341489900685
Validation loss: 3.0501987280909573

Epoch: 6| Step: 2
Training loss: 3.5179514329430273
Validation loss: 3.049780024438563

Epoch: 6| Step: 3
Training loss: 3.069787055716381
Validation loss: 3.049281123703742

Epoch: 6| Step: 4
Training loss: 2.7996581311648936
Validation loss: 3.0488512233638967

Epoch: 6| Step: 5
Training loss: 3.078792286689714
Validation loss: 3.048829209710484

Epoch: 6| Step: 6
Training loss: 3.2399435711879954
Validation loss: 3.047284678726852

Epoch: 6| Step: 7
Training loss: 2.9743440626202338
Validation loss: 3.047310144374459

Epoch: 6| Step: 8
Training loss: 2.9987084469573757
Validation loss: 3.0462140927575585

Epoch: 6| Step: 9
Training loss: 3.2321867243583196
Validation loss: 3.0463483314745172

Epoch: 6| Step: 10
Training loss: 3.7829333885191074
Validation loss: 3.0442365498832866

Epoch: 6| Step: 11
Training loss: 3.5837937140617804
Validation loss: 3.044551043648567

Epoch: 6| Step: 12
Training loss: 4.004260655046657
Validation loss: 3.0444296877837997

Epoch: 6| Step: 13
Training loss: 2.7713549034625724
Validation loss: 3.0425540917935896

Epoch: 79| Step: 0
Training loss: 3.856500705872744
Validation loss: 3.0491323114692075

Epoch: 6| Step: 1
Training loss: 3.7705074331050703
Validation loss: 3.056399692178065

Epoch: 6| Step: 2
Training loss: 3.0544367928808254
Validation loss: 3.0498655961694228

Epoch: 6| Step: 3
Training loss: 3.2622303818413845
Validation loss: 3.05195278611038

Epoch: 6| Step: 4
Training loss: 3.7358336851851766
Validation loss: 3.0444025997682105

Epoch: 6| Step: 5
Training loss: 2.64042599622264
Validation loss: 3.0521571974884605

Epoch: 6| Step: 6
Training loss: 3.1020395214777743
Validation loss: 3.0478346977886135

Epoch: 6| Step: 7
Training loss: 3.12174879702993
Validation loss: 3.0424763816416744

Epoch: 6| Step: 8
Training loss: 3.583140227563088
Validation loss: 3.0436770838048686

Epoch: 6| Step: 9
Training loss: 3.3349301963718596
Validation loss: 3.042375370475802

Epoch: 6| Step: 10
Training loss: 2.5919244615532673
Validation loss: 3.0383834166621146

Epoch: 6| Step: 11
Training loss: 3.033594542215162
Validation loss: 3.0373877178414252

Epoch: 6| Step: 12
Training loss: 3.4428598406181328
Validation loss: 3.0369816034437918

Epoch: 6| Step: 13
Training loss: 3.6740786169421686
Validation loss: 3.0374492367398047

Epoch: 80| Step: 0
Training loss: 3.266582147971081
Validation loss: 3.039337242793972

Epoch: 6| Step: 1
Training loss: 3.4739176429908643
Validation loss: 3.041775909790553

Epoch: 6| Step: 2
Training loss: 3.1086204034890272
Validation loss: 3.0401697480261807

Epoch: 6| Step: 3
Training loss: 3.5925973121667414
Validation loss: 3.0429277293671433

Epoch: 6| Step: 4
Training loss: 3.756305225747052
Validation loss: 3.040957236791289

Epoch: 6| Step: 5
Training loss: 3.6614055313202765
Validation loss: 3.0505819004632366

Epoch: 6| Step: 6
Training loss: 2.8251797002841617
Validation loss: 3.0499962674714367

Epoch: 6| Step: 7
Training loss: 3.405186758423275
Validation loss: 3.046453537147782

Epoch: 6| Step: 8
Training loss: 2.8625037580573722
Validation loss: 3.0479937859227673

Epoch: 6| Step: 9
Training loss: 2.5887289510374965
Validation loss: 3.0441697413527233

Epoch: 6| Step: 10
Training loss: 3.228439413233873
Validation loss: 3.0425183310122375

Epoch: 6| Step: 11
Training loss: 3.21159129668166
Validation loss: 3.042501540379496

Epoch: 6| Step: 12
Training loss: 3.689798446981312
Validation loss: 3.0376562098872273

Epoch: 6| Step: 13
Training loss: 3.5672615755387813
Validation loss: 3.0348996391149967

Epoch: 81| Step: 0
Training loss: 2.8571927440920204
Validation loss: 3.0383560300517534

Epoch: 6| Step: 1
Training loss: 2.9217997658575334
Validation loss: 3.035716367613817

Epoch: 6| Step: 2
Training loss: 3.378479188600637
Validation loss: 3.037172783540964

Epoch: 6| Step: 3
Training loss: 2.9755832132515425
Validation loss: 3.0388458661477284

Epoch: 6| Step: 4
Training loss: 2.9699426764919132
Validation loss: 3.0366344390634405

Epoch: 6| Step: 5
Training loss: 2.365474471388876
Validation loss: 3.0368025541750128

Epoch: 6| Step: 6
Training loss: 3.763663766532521
Validation loss: 3.035293615480435

Epoch: 6| Step: 7
Training loss: 2.885105947205253
Validation loss: 3.0379865136470476

Epoch: 6| Step: 8
Training loss: 3.424024908108891
Validation loss: 3.0342143628394087

Epoch: 6| Step: 9
Training loss: 4.0870922200191915
Validation loss: 3.035162934542072

Epoch: 6| Step: 10
Training loss: 3.938969776797844
Validation loss: 3.0334891212896657

Epoch: 6| Step: 11
Training loss: 3.1062268753265556
Validation loss: 3.0352580808225613

Epoch: 6| Step: 12
Training loss: 4.048982873987339
Validation loss: 3.0342260935589698

Epoch: 6| Step: 13
Training loss: 2.782761495252374
Validation loss: 3.0337875945485533

Epoch: 82| Step: 0
Training loss: 3.124570282954922
Validation loss: 3.0323030118397165

Epoch: 6| Step: 1
Training loss: 4.03683061749266
Validation loss: 3.031686801898218

Epoch: 6| Step: 2
Training loss: 2.801370428408325
Validation loss: 3.0325056308043146

Epoch: 6| Step: 3
Training loss: 3.0892378144208728
Validation loss: 3.032695806467197

Epoch: 6| Step: 4
Training loss: 3.2269603123785107
Validation loss: 3.0309515077602014

Epoch: 6| Step: 5
Training loss: 2.8194399511576043
Validation loss: 3.0348351398286684

Epoch: 6| Step: 6
Training loss: 3.60950340934325
Validation loss: 3.0312445094696647

Epoch: 6| Step: 7
Training loss: 3.331815151349004
Validation loss: 3.030504384263676

Epoch: 6| Step: 8
Training loss: 4.098519611590482
Validation loss: 3.0299229188044725

Epoch: 6| Step: 9
Training loss: 3.0344656965095944
Validation loss: 3.0326084686902672

Epoch: 6| Step: 10
Training loss: 3.6515308148597234
Validation loss: 3.0294024925876903

Epoch: 6| Step: 11
Training loss: 3.4445721096731003
Validation loss: 3.0302040909857615

Epoch: 6| Step: 12
Training loss: 2.5787510891947663
Validation loss: 3.0311764047541607

Epoch: 6| Step: 13
Training loss: 2.743837648004112
Validation loss: 3.0331413940447245

Epoch: 83| Step: 0
Training loss: 3.873287068439231
Validation loss: 3.0329422163664623

Epoch: 6| Step: 1
Training loss: 3.174684980488898
Validation loss: 3.035512282311017

Epoch: 6| Step: 2
Training loss: 3.125717538471776
Validation loss: 3.0364727936744083

Epoch: 6| Step: 3
Training loss: 3.865418678889824
Validation loss: 3.033911915306562

Epoch: 6| Step: 4
Training loss: 3.0671404500219963
Validation loss: 3.0330712763250216

Epoch: 6| Step: 5
Training loss: 3.1957109198237963
Validation loss: 3.0340598432985266

Epoch: 6| Step: 6
Training loss: 2.9315755634852443
Validation loss: 3.0358668981024364

Epoch: 6| Step: 7
Training loss: 1.9348560875104435
Validation loss: 3.043556870652479

Epoch: 6| Step: 8
Training loss: 3.4495613040367346
Validation loss: 3.044851558751409

Epoch: 6| Step: 9
Training loss: 3.6219094354606933
Validation loss: 3.0414625586245343

Epoch: 6| Step: 10
Training loss: 3.110264329869755
Validation loss: 3.036752040756991

Epoch: 6| Step: 11
Training loss: 4.396189791191434
Validation loss: 3.034122007608519

Epoch: 6| Step: 12
Training loss: 2.511960221188232
Validation loss: 3.032905136044171

Epoch: 6| Step: 13
Training loss: 3.2943001043454183
Validation loss: 3.0314497396114923

Epoch: 84| Step: 0
Training loss: 3.1679564074782687
Validation loss: 3.027806843333407

Epoch: 6| Step: 1
Training loss: 3.0314189431214915
Validation loss: 3.0267788170236547

Epoch: 6| Step: 2
Training loss: 3.105715491131315
Validation loss: 3.028599002614928

Epoch: 6| Step: 3
Training loss: 3.3067337807130452
Validation loss: 3.0276228653198345

Epoch: 6| Step: 4
Training loss: 3.6782100489400458
Validation loss: 3.0244872594697156

Epoch: 6| Step: 5
Training loss: 3.9305820546569326
Validation loss: 3.024885474402987

Epoch: 6| Step: 6
Training loss: 2.761005832968536
Validation loss: 3.0263766352099464

Epoch: 6| Step: 7
Training loss: 3.605579973780454
Validation loss: 3.0277374877411583

Epoch: 6| Step: 8
Training loss: 3.2378064809536515
Validation loss: 3.0250795494772107

Epoch: 6| Step: 9
Training loss: 3.8972261492406615
Validation loss: 3.026703617244799

Epoch: 6| Step: 10
Training loss: 2.527622213455776
Validation loss: 3.0242933082944012

Epoch: 6| Step: 11
Training loss: 3.1032946767833938
Validation loss: 3.02270432615347

Epoch: 6| Step: 12
Training loss: 3.4239949666102123
Validation loss: 3.0225388959266613

Epoch: 6| Step: 13
Training loss: 2.8677816580919773
Validation loss: 3.0207773839219794

Epoch: 85| Step: 0
Training loss: 3.8761673676344346
Validation loss: 3.0236771422261666

Epoch: 6| Step: 1
Training loss: 3.140484707104405
Validation loss: 3.0239135930362213

Epoch: 6| Step: 2
Training loss: 3.7973579758887492
Validation loss: 3.0231004320235586

Epoch: 6| Step: 3
Training loss: 3.1463570737749014
Validation loss: 3.0276356038048777

Epoch: 6| Step: 4
Training loss: 3.790096558722281
Validation loss: 3.0195123185058845

Epoch: 6| Step: 5
Training loss: 2.7851064284310554
Validation loss: 3.0236276287680224

Epoch: 6| Step: 6
Training loss: 3.609829300202313
Validation loss: 3.023018020605751

Epoch: 6| Step: 7
Training loss: 2.4517728152484994
Validation loss: 3.0263349042839627

Epoch: 6| Step: 8
Training loss: 3.012313368465171
Validation loss: 3.028467011902338

Epoch: 6| Step: 9
Training loss: 2.6379924947127207
Validation loss: 3.0175122724941215

Epoch: 6| Step: 10
Training loss: 3.1657104721656246
Validation loss: 3.0191538576654806

Epoch: 6| Step: 11
Training loss: 2.312769796768156
Validation loss: 3.021595597265854

Epoch: 6| Step: 12
Training loss: 4.040210553338479
Validation loss: 3.0204246750942954

Epoch: 6| Step: 13
Training loss: 4.027393477657348
Validation loss: 3.0181646528697006

Epoch: 86| Step: 0
Training loss: 3.2918752934137245
Validation loss: 3.017809988941618

Epoch: 6| Step: 1
Training loss: 2.930144007401986
Validation loss: 3.0167762258737505

Epoch: 6| Step: 2
Training loss: 3.326378449114135
Validation loss: 3.0191789288419395

Epoch: 6| Step: 3
Training loss: 3.590895605555806
Validation loss: 3.0177151369691573

Epoch: 6| Step: 4
Training loss: 3.17753509478093
Validation loss: 3.015516720077021

Epoch: 6| Step: 5
Training loss: 3.1604110935659104
Validation loss: 3.019435103813439

Epoch: 6| Step: 6
Training loss: 2.4905106694150527
Validation loss: 3.016053295330695

Epoch: 6| Step: 7
Training loss: 3.5740501155573665
Validation loss: 3.014879143267912

Epoch: 6| Step: 8
Training loss: 3.0212078695393996
Validation loss: 3.016918473064552

Epoch: 6| Step: 9
Training loss: 4.003618034596127
Validation loss: 3.0150733208074305

Epoch: 6| Step: 10
Training loss: 3.5963528702402323
Validation loss: 3.0151108899620436

Epoch: 6| Step: 11
Training loss: 3.2012037516526073
Validation loss: 3.014050203804993

Epoch: 6| Step: 12
Training loss: 3.414495445052916
Validation loss: 3.014672166816448

Epoch: 6| Step: 13
Training loss: 2.843142601792245
Validation loss: 3.0146006483484484

Epoch: 87| Step: 0
Training loss: 3.7067452934442624
Validation loss: 3.012800533523213

Epoch: 6| Step: 1
Training loss: 3.842823195953262
Validation loss: 3.0150748393977054

Epoch: 6| Step: 2
Training loss: 3.07568045429918
Validation loss: 3.014374245068154

Epoch: 6| Step: 3
Training loss: 3.1882342820469196
Validation loss: 3.0143827880464302

Epoch: 6| Step: 4
Training loss: 2.321514190939377
Validation loss: 3.01466049436998

Epoch: 6| Step: 5
Training loss: 3.317124359780548
Validation loss: 3.0136353929401327

Epoch: 6| Step: 6
Training loss: 3.1164885002522613
Validation loss: 3.014499800173502

Epoch: 6| Step: 7
Training loss: 3.556861296610425
Validation loss: 3.0133135990836437

Epoch: 6| Step: 8
Training loss: 3.291250629127984
Validation loss: 3.014105729770084

Epoch: 6| Step: 9
Training loss: 3.5177405201790495
Validation loss: 3.0143799882995217

Epoch: 6| Step: 10
Training loss: 2.6915668500534933
Validation loss: 3.0156259555338005

Epoch: 6| Step: 11
Training loss: 3.0837159477861866
Validation loss: 3.016566813879784

Epoch: 6| Step: 12
Training loss: 3.8170481584172813
Validation loss: 3.013601467613848

Epoch: 6| Step: 13
Training loss: 3.0647201275890135
Validation loss: 3.012391109521393

Epoch: 88| Step: 0
Training loss: 3.4155934827071164
Validation loss: 3.015093488406158

Epoch: 6| Step: 1
Training loss: 3.428563379096618
Validation loss: 3.013467589853284

Epoch: 6| Step: 2
Training loss: 3.7752064730534367
Validation loss: 3.0115861829076227

Epoch: 6| Step: 3
Training loss: 3.1057498828624146
Validation loss: 3.0115785743427157

Epoch: 6| Step: 4
Training loss: 3.1204778376267357
Validation loss: 3.014094883566555

Epoch: 6| Step: 5
Training loss: 3.252659223267184
Validation loss: 3.0118088283479723

Epoch: 6| Step: 6
Training loss: 3.0543529590727054
Validation loss: 3.0117402041176655

Epoch: 6| Step: 7
Training loss: 2.9455590587594975
Validation loss: 3.011910784621614

Epoch: 6| Step: 8
Training loss: 2.7997048835542575
Validation loss: 3.01031551083974

Epoch: 6| Step: 9
Training loss: 3.861909227344556
Validation loss: 3.0120080987345075

Epoch: 6| Step: 10
Training loss: 2.6394844074775086
Validation loss: 3.0112700477823293

Epoch: 6| Step: 11
Training loss: 3.4622050906851
Validation loss: 3.0143608356476506

Epoch: 6| Step: 12
Training loss: 3.493875321817351
Validation loss: 3.0125590508600277

Epoch: 6| Step: 13
Training loss: 3.564657795921842
Validation loss: 3.0133830790706417

Epoch: 89| Step: 0
Training loss: 3.034836210956292
Validation loss: 3.011990022168505

Epoch: 6| Step: 1
Training loss: 3.5712656964900775
Validation loss: 3.010865518483584

Epoch: 6| Step: 2
Training loss: 2.707374187727032
Validation loss: 3.009054859884422

Epoch: 6| Step: 3
Training loss: 3.0928869103157397
Validation loss: 3.0106488465568217

Epoch: 6| Step: 4
Training loss: 2.9280732857647336
Validation loss: 3.010602398102817

Epoch: 6| Step: 5
Training loss: 3.524011806195473
Validation loss: 3.0086940624665712

Epoch: 6| Step: 6
Training loss: 3.610772989207414
Validation loss: 3.00821365858325

Epoch: 6| Step: 7
Training loss: 3.3238363079616335
Validation loss: 3.0091297544034266

Epoch: 6| Step: 8
Training loss: 3.339649288472536
Validation loss: 3.008873968147932

Epoch: 6| Step: 9
Training loss: 3.4087457875196714
Validation loss: 3.0076865131620716

Epoch: 6| Step: 10
Training loss: 3.6200448732071266
Validation loss: 3.0102078745457175

Epoch: 6| Step: 11
Training loss: 3.124564941639704
Validation loss: 3.0024684173099714

Epoch: 6| Step: 12
Training loss: 3.1611480476830116
Validation loss: 3.0075148917987677

Epoch: 6| Step: 13
Training loss: 3.5569205511752786
Validation loss: 3.005900580814794

Epoch: 90| Step: 0
Training loss: 4.023213737709802
Validation loss: 3.0056362172007915

Epoch: 6| Step: 1
Training loss: 2.7842733687873884
Validation loss: 3.006959330653691

Epoch: 6| Step: 2
Training loss: 3.6397578307698426
Validation loss: 3.005749156861115

Epoch: 6| Step: 3
Training loss: 3.5493472721543617
Validation loss: 3.0049181688772064

Epoch: 6| Step: 4
Training loss: 2.821166862780606
Validation loss: 3.0036297582672384

Epoch: 6| Step: 5
Training loss: 2.4599007496544725
Validation loss: 3.0048829029347757

Epoch: 6| Step: 6
Training loss: 2.824708423927379
Validation loss: 3.003059700079693

Epoch: 6| Step: 7
Training loss: 3.0215328239792925
Validation loss: 3.004229700053216

Epoch: 6| Step: 8
Training loss: 3.4455616140806105
Validation loss: 3.0009250872379423

Epoch: 6| Step: 9
Training loss: 2.3536523802980582
Validation loss: 3.003681825595908

Epoch: 6| Step: 10
Training loss: 3.5135125489342647
Validation loss: 3.0016761202729745

Epoch: 6| Step: 11
Training loss: 3.539934804499227
Validation loss: 3.003231318241979

Epoch: 6| Step: 12
Training loss: 3.6912544663321825
Validation loss: 3.0044409446981515

Epoch: 6| Step: 13
Training loss: 4.030805696354958
Validation loss: 3.0062355300227277

Epoch: 91| Step: 0
Training loss: 2.690077499351022
Validation loss: 3.0074747753356434

Epoch: 6| Step: 1
Training loss: 3.457765249144088
Validation loss: 3.002992503058369

Epoch: 6| Step: 2
Training loss: 3.060105613930376
Validation loss: 3.002804853257507

Epoch: 6| Step: 3
Training loss: 2.876933898654358
Validation loss: 3.00501485973006

Epoch: 6| Step: 4
Training loss: 3.838181843276911
Validation loss: 3.003881187904618

Epoch: 6| Step: 5
Training loss: 3.5814193818678035
Validation loss: 2.9988983038754924

Epoch: 6| Step: 6
Training loss: 2.941834842820317
Validation loss: 3.0010878767852858

Epoch: 6| Step: 7
Training loss: 2.3693223649248547
Validation loss: 3.0007023143083127

Epoch: 6| Step: 8
Training loss: 3.028968345590034
Validation loss: 3.000513861683727

Epoch: 6| Step: 9
Training loss: 3.2501985049147533
Validation loss: 2.998737881534109

Epoch: 6| Step: 10
Training loss: 4.236201606714956
Validation loss: 2.99903408689271

Epoch: 6| Step: 11
Training loss: 3.5971111998901284
Validation loss: 2.999360630820739

Epoch: 6| Step: 12
Training loss: 2.9429382954544003
Validation loss: 3.001349682206145

Epoch: 6| Step: 13
Training loss: 3.6668027216782515
Validation loss: 2.997658643095909

Epoch: 92| Step: 0
Training loss: 3.8742966782735855
Validation loss: 2.9997588867453393

Epoch: 6| Step: 1
Training loss: 3.4490415153891565
Validation loss: 3.0010616336522795

Epoch: 6| Step: 2
Training loss: 3.1999490018595536
Validation loss: 2.99859277388082

Epoch: 6| Step: 3
Training loss: 3.492961072476046
Validation loss: 2.99863159168463

Epoch: 6| Step: 4
Training loss: 1.9133071966191533
Validation loss: 2.996988498351584

Epoch: 6| Step: 5
Training loss: 2.6503348516838026
Validation loss: 2.9942924373744044

Epoch: 6| Step: 6
Training loss: 3.7275536456683556
Validation loss: 2.9961975433065757

Epoch: 6| Step: 7
Training loss: 3.652127542063132
Validation loss: 2.9987530646358747

Epoch: 6| Step: 8
Training loss: 3.4430655074367924
Validation loss: 2.997626823822578

Epoch: 6| Step: 9
Training loss: 3.0872711776388844
Validation loss: 2.995390232756423

Epoch: 6| Step: 10
Training loss: 2.6049494876467216
Validation loss: 2.996326314773177

Epoch: 6| Step: 11
Training loss: 2.785609739388887
Validation loss: 2.9949510500719203

Epoch: 6| Step: 12
Training loss: 3.8410343408298346
Validation loss: 2.9926432121136686

Epoch: 6| Step: 13
Training loss: 3.6294963180369866
Validation loss: 2.992658630874162

Epoch: 93| Step: 0
Training loss: 3.3775444329400575
Validation loss: 2.993595136292275

Epoch: 6| Step: 1
Training loss: 3.476359363579038
Validation loss: 2.9954618084950697

Epoch: 6| Step: 2
Training loss: 2.73382580282699
Validation loss: 2.9961027002009053

Epoch: 6| Step: 3
Training loss: 3.698725279750898
Validation loss: 2.9965913448713577

Epoch: 6| Step: 4
Training loss: 3.1208214861887287
Validation loss: 2.9983379364220024

Epoch: 6| Step: 5
Training loss: 3.5622804808326216
Validation loss: 2.9948953983841142

Epoch: 6| Step: 6
Training loss: 2.9834628483738412
Validation loss: 2.998671627254931

Epoch: 6| Step: 7
Training loss: 3.4282635141797737
Validation loss: 2.993923365199813

Epoch: 6| Step: 8
Training loss: 3.413445388573892
Validation loss: 2.99085379733942

Epoch: 6| Step: 9
Training loss: 3.1657416515190557
Validation loss: 2.993186591752685

Epoch: 6| Step: 10
Training loss: 2.749751946792725
Validation loss: 2.9934972116119547

Epoch: 6| Step: 11
Training loss: 3.6030626461989366
Validation loss: 2.9935802490287693

Epoch: 6| Step: 12
Training loss: 2.924737843560042
Validation loss: 2.991991325661965

Epoch: 6| Step: 13
Training loss: 3.3826347462951514
Validation loss: 2.9953426438843467

Epoch: 94| Step: 0
Training loss: 2.778569161746543
Validation loss: 2.995076946066033

Epoch: 6| Step: 1
Training loss: 3.1078854160567726
Validation loss: 2.996111012055699

Epoch: 6| Step: 2
Training loss: 3.3026864416613324
Validation loss: 2.9943847762198486

Epoch: 6| Step: 3
Training loss: 2.5905576616653576
Validation loss: 2.997055899275059

Epoch: 6| Step: 4
Training loss: 2.1236687024179157
Validation loss: 2.996036124098737

Epoch: 6| Step: 5
Training loss: 2.9418447301931048
Validation loss: 2.9949047639026403

Epoch: 6| Step: 6
Training loss: 3.4091960520858313
Validation loss: 2.993924406437711

Epoch: 6| Step: 7
Training loss: 3.612783960711925
Validation loss: 2.9918876169314594

Epoch: 6| Step: 8
Training loss: 3.0677605426449563
Validation loss: 2.993255699588535

Epoch: 6| Step: 9
Training loss: 2.8711784506001066
Validation loss: 2.989671396647288

Epoch: 6| Step: 10
Training loss: 4.352123505130139
Validation loss: 2.991107499978039

Epoch: 6| Step: 11
Training loss: 3.781416455853237
Validation loss: 2.991901894821357

Epoch: 6| Step: 12
Training loss: 3.875899917948114
Validation loss: 2.990949626306957

Epoch: 6| Step: 13
Training loss: 3.4219675269311214
Validation loss: 2.9935228059690164

Epoch: 95| Step: 0
Training loss: 3.555962570722915
Validation loss: 2.992287407222986

Epoch: 6| Step: 1
Training loss: 3.129115179851463
Validation loss: 2.9917854830036315

Epoch: 6| Step: 2
Training loss: 3.472064659782272
Validation loss: 2.9935385053773524

Epoch: 6| Step: 3
Training loss: 3.6128030986414443
Validation loss: 2.987861047731883

Epoch: 6| Step: 4
Training loss: 3.4174237846800155
Validation loss: 2.9904120512431884

Epoch: 6| Step: 5
Training loss: 3.1261202520865012
Validation loss: 2.9905173482065686

Epoch: 6| Step: 6
Training loss: 3.1079587538546294
Validation loss: 2.9894744114590344

Epoch: 6| Step: 7
Training loss: 3.8707735947405557
Validation loss: 2.9902573001219857

Epoch: 6| Step: 8
Training loss: 3.3564328106582706
Validation loss: 2.992139304131777

Epoch: 6| Step: 9
Training loss: 2.5759410508915876
Validation loss: 2.988382837127892

Epoch: 6| Step: 10
Training loss: 3.0074513404315417
Validation loss: 2.9873164119115665

Epoch: 6| Step: 11
Training loss: 3.582156779212341
Validation loss: 2.991463520621701

Epoch: 6| Step: 12
Training loss: 3.229404334069253
Validation loss: 2.9936098513511813

Epoch: 6| Step: 13
Training loss: 1.354030494690259
Validation loss: 2.9991679507566746

Epoch: 96| Step: 0
Training loss: 4.17081303599497
Validation loss: 3.000964908542454

Epoch: 6| Step: 1
Training loss: 3.0883797940339632
Validation loss: 3.005246322959575

Epoch: 6| Step: 2
Training loss: 3.553601042329033
Validation loss: 3.0123666805544516

Epoch: 6| Step: 3
Training loss: 2.344333830278462
Validation loss: 2.9978434765816697

Epoch: 6| Step: 4
Training loss: 3.629325390807278
Validation loss: 2.9891391964625567

Epoch: 6| Step: 5
Training loss: 3.115478659113335
Validation loss: 2.9877270685409205

Epoch: 6| Step: 6
Training loss: 3.2059916252745526
Validation loss: 2.986381661465125

Epoch: 6| Step: 7
Training loss: 3.236401056953949
Validation loss: 2.9865701671851723

Epoch: 6| Step: 8
Training loss: 3.1256278361014145
Validation loss: 2.9877686977525997

Epoch: 6| Step: 9
Training loss: 2.9020401191278085
Validation loss: 2.986151375053558

Epoch: 6| Step: 10
Training loss: 3.4916175189386895
Validation loss: 2.9863320927954495

Epoch: 6| Step: 11
Training loss: 2.7859149343589755
Validation loss: 2.987853533194707

Epoch: 6| Step: 12
Training loss: 3.260499134584829
Validation loss: 2.985742959097003

Epoch: 6| Step: 13
Training loss: 3.4739857243149603
Validation loss: 2.9894662269368237

Epoch: 97| Step: 0
Training loss: 3.086123381219372
Validation loss: 2.9886003470137155

Epoch: 6| Step: 1
Training loss: 3.099531378242439
Validation loss: 2.9855095321207408

Epoch: 6| Step: 2
Training loss: 2.9964347953608335
Validation loss: 2.9845808933462346

Epoch: 6| Step: 3
Training loss: 3.785923111495048
Validation loss: 2.986540934585827

Epoch: 6| Step: 4
Training loss: 3.490388206161589
Validation loss: 2.986501621417463

Epoch: 6| Step: 5
Training loss: 3.469145056420292
Validation loss: 2.9833207435454545

Epoch: 6| Step: 6
Training loss: 3.105510054019738
Validation loss: 2.986107922973864

Epoch: 6| Step: 7
Training loss: 3.538924662956329
Validation loss: 2.9867882837317015

Epoch: 6| Step: 8
Training loss: 2.8549979639797667
Validation loss: 2.9864101616612206

Epoch: 6| Step: 9
Training loss: 3.18732825919841
Validation loss: 2.985573778093789

Epoch: 6| Step: 10
Training loss: 3.333530388411641
Validation loss: 2.985957388431903

Epoch: 6| Step: 11
Training loss: 3.323338464894314
Validation loss: 2.988090231179777

Epoch: 6| Step: 12
Training loss: 3.0745717564558
Validation loss: 2.9853243317321634

Epoch: 6| Step: 13
Training loss: 3.2062538310543025
Validation loss: 2.9864572739492043

Epoch: 98| Step: 0
Training loss: 3.1360272967259943
Validation loss: 2.9877490415881502

Epoch: 6| Step: 1
Training loss: 2.961363427118182
Validation loss: 2.9888703465517157

Epoch: 6| Step: 2
Training loss: 3.230834792593278
Validation loss: 2.9873736224666323

Epoch: 6| Step: 3
Training loss: 2.793696979471888
Validation loss: 2.9887810350477517

Epoch: 6| Step: 4
Training loss: 3.0250785376071487
Validation loss: 2.999790526155927

Epoch: 6| Step: 5
Training loss: 3.375653239010053
Validation loss: 2.9994635529617946

Epoch: 6| Step: 6
Training loss: 3.5967971488422075
Validation loss: 2.9867635758322577

Epoch: 6| Step: 7
Training loss: 3.5912873164414734
Validation loss: 2.9829201201833775

Epoch: 6| Step: 8
Training loss: 3.2733629168114327
Validation loss: 2.984341329625065

Epoch: 6| Step: 9
Training loss: 3.390645110602442
Validation loss: 2.98206089341215

Epoch: 6| Step: 10
Training loss: 3.3045463802426505
Validation loss: 2.9813588879305084

Epoch: 6| Step: 11
Training loss: 2.939587277617716
Validation loss: 2.9820714314435683

Epoch: 6| Step: 12
Training loss: 3.2120332727668512
Validation loss: 2.9797638296711395

Epoch: 6| Step: 13
Training loss: 4.046114463480602
Validation loss: 2.979800433048846

Epoch: 99| Step: 0
Training loss: 3.570182280388181
Validation loss: 2.97848897727371

Epoch: 6| Step: 1
Training loss: 2.839869440059608
Validation loss: 2.9785687648121897

Epoch: 6| Step: 2
Training loss: 3.1105326122247727
Validation loss: 2.9781730664934765

Epoch: 6| Step: 3
Training loss: 3.795373690454645
Validation loss: 2.9796175734175345

Epoch: 6| Step: 4
Training loss: 3.0235472666605476
Validation loss: 2.9800241448078837

Epoch: 6| Step: 5
Training loss: 3.5020318264476336
Validation loss: 2.9780386342323015

Epoch: 6| Step: 6
Training loss: 3.0080333281862095
Validation loss: 2.978650667466825

Epoch: 6| Step: 7
Training loss: 3.5518797129033075
Validation loss: 2.976879620283846

Epoch: 6| Step: 8
Training loss: 2.5388968545727058
Validation loss: 2.9757022817757077

Epoch: 6| Step: 9
Training loss: 2.858626470928472
Validation loss: 2.9751118290213814

Epoch: 6| Step: 10
Training loss: 3.148467941704957
Validation loss: 2.9765545943408234

Epoch: 6| Step: 11
Training loss: 3.9359281520876364
Validation loss: 2.9782960246130252

Epoch: 6| Step: 12
Training loss: 3.1766387795194584
Validation loss: 2.977797621282474

Epoch: 6| Step: 13
Training loss: 3.33469869942617
Validation loss: 2.9798477195250412

Epoch: 100| Step: 0
Training loss: 3.100097310169397
Validation loss: 2.9760968562693964

Epoch: 6| Step: 1
Training loss: 3.7070366524756473
Validation loss: 2.977083130015993

Epoch: 6| Step: 2
Training loss: 2.574629014336318
Validation loss: 2.9800250756254205

Epoch: 6| Step: 3
Training loss: 4.0043351999647525
Validation loss: 2.9757074405803747

Epoch: 6| Step: 4
Training loss: 3.4209721737253753
Validation loss: 2.9729810631617677

Epoch: 6| Step: 5
Training loss: 3.6286881199579315
Validation loss: 2.9751211379038867

Epoch: 6| Step: 6
Training loss: 3.2681133518241214
Validation loss: 2.976804506020098

Epoch: 6| Step: 7
Training loss: 3.488803939703047
Validation loss: 2.971608302432211

Epoch: 6| Step: 8
Training loss: 3.3200086028205913
Validation loss: 2.9764612467190013

Epoch: 6| Step: 9
Training loss: 3.415541828116625
Validation loss: 2.975760784749746

Epoch: 6| Step: 10
Training loss: 2.823452963097962
Validation loss: 2.9753266505842046

Epoch: 6| Step: 11
Training loss: 2.998263651313961
Validation loss: 2.973999737484622

Epoch: 6| Step: 12
Training loss: 2.4048508378561957
Validation loss: 2.973495345352429

Epoch: 6| Step: 13
Training loss: 2.8088882992169744
Validation loss: 2.9760601763292325

Epoch: 101| Step: 0
Training loss: 4.391675721556698
Validation loss: 2.9752603799028257

Epoch: 6| Step: 1
Training loss: 3.2550643197310154
Validation loss: 2.97364714786567

Epoch: 6| Step: 2
Training loss: 2.865587167271731
Validation loss: 2.971181929313655

Epoch: 6| Step: 3
Training loss: 3.2652853465149168
Validation loss: 2.975681768804939

Epoch: 6| Step: 4
Training loss: 3.649532047739884
Validation loss: 2.976617405812725

Epoch: 6| Step: 5
Training loss: 3.21561093637785
Validation loss: 2.9731125043726774

Epoch: 6| Step: 6
Training loss: 3.3842147493332173
Validation loss: 2.9734379143295624

Epoch: 6| Step: 7
Training loss: 2.9038579797722566
Validation loss: 2.9763308569443994

Epoch: 6| Step: 8
Training loss: 2.783685881925868
Validation loss: 2.9695622384928546

Epoch: 6| Step: 9
Training loss: 2.426155884542177
Validation loss: 2.9679743990120575

Epoch: 6| Step: 10
Training loss: 3.116132744190938
Validation loss: 2.9676903068791955

Epoch: 6| Step: 11
Training loss: 3.433855239927399
Validation loss: 2.9668059464192376

Epoch: 6| Step: 12
Training loss: 3.2607056283515052
Validation loss: 2.9686282069768626

Epoch: 6| Step: 13
Training loss: 3.079913244387988
Validation loss: 2.971136227165111

Epoch: 102| Step: 0
Training loss: 2.8004413222881244
Validation loss: 2.9732955355812063

Epoch: 6| Step: 1
Training loss: 3.815430562331932
Validation loss: 2.9745248961351303

Epoch: 6| Step: 2
Training loss: 3.718802828373448
Validation loss: 2.9707490452368672

Epoch: 6| Step: 3
Training loss: 2.7621068614311146
Validation loss: 2.9737667439177597

Epoch: 6| Step: 4
Training loss: 3.1777769905332405
Validation loss: 2.974231859468509

Epoch: 6| Step: 5
Training loss: 3.782398018076744
Validation loss: 2.9793287824435364

Epoch: 6| Step: 6
Training loss: 3.4246396954215537
Validation loss: 2.984609470864705

Epoch: 6| Step: 7
Training loss: 3.0045238400708687
Validation loss: 2.9814297420229385

Epoch: 6| Step: 8
Training loss: 3.150347033563884
Validation loss: 2.981375616183255

Epoch: 6| Step: 9
Training loss: 3.513365023383796
Validation loss: 2.977800920319791

Epoch: 6| Step: 10
Training loss: 3.189099228538575
Validation loss: 2.9808367135664042

Epoch: 6| Step: 11
Training loss: 2.2255923650631186
Validation loss: 2.9761198317175745

Epoch: 6| Step: 12
Training loss: 3.5151270534945778
Validation loss: 2.9757623587237783

Epoch: 6| Step: 13
Training loss: 2.770083180084122
Validation loss: 2.970530033189404

Epoch: 103| Step: 0
Training loss: 2.923033948536081
Validation loss: 2.9696824721263435

Epoch: 6| Step: 1
Training loss: 2.9749793300391443
Validation loss: 2.967934902967864

Epoch: 6| Step: 2
Training loss: 3.2398944145235262
Validation loss: 2.9699434291981417

Epoch: 6| Step: 3
Training loss: 3.3723099902604083
Validation loss: 2.9788153550452923

Epoch: 6| Step: 4
Training loss: 3.143924934267606
Validation loss: 2.9651795449663276

Epoch: 6| Step: 5
Training loss: 2.967692939894228
Validation loss: 2.9670200724216604

Epoch: 6| Step: 6
Training loss: 4.111232091366532
Validation loss: 2.9659014884645645

Epoch: 6| Step: 7
Training loss: 3.081645830275503
Validation loss: 2.9646097973139374

Epoch: 6| Step: 8
Training loss: 2.662931230035969
Validation loss: 2.967145837209448

Epoch: 6| Step: 9
Training loss: 3.5145061153543726
Validation loss: 2.9628446798773305

Epoch: 6| Step: 10
Training loss: 2.825170670476702
Validation loss: 2.9643466246318284

Epoch: 6| Step: 11
Training loss: 3.618635312175292
Validation loss: 2.9641168127339754

Epoch: 6| Step: 12
Training loss: 3.321107441603158
Validation loss: 2.962003628450806

Epoch: 6| Step: 13
Training loss: 3.54848413474557
Validation loss: 2.969030574888299

Epoch: 104| Step: 0
Training loss: 3.3111768275089486
Validation loss: 2.9646541369402533

Epoch: 6| Step: 1
Training loss: 3.705042604106218
Validation loss: 2.9637191710362956

Epoch: 6| Step: 2
Training loss: 2.069536977942184
Validation loss: 2.963736303334175

Epoch: 6| Step: 3
Training loss: 2.7785446210528346
Validation loss: 2.9631041402009184

Epoch: 6| Step: 4
Training loss: 2.799720212036559
Validation loss: 2.9661570582677603

Epoch: 6| Step: 5
Training loss: 3.1227512661066528
Validation loss: 2.966292417917558

Epoch: 6| Step: 6
Training loss: 3.09076060739135
Validation loss: 2.965105399222679

Epoch: 6| Step: 7
Training loss: 3.1994759965065653
Validation loss: 2.9699127648968657

Epoch: 6| Step: 8
Training loss: 3.210769983084641
Validation loss: 2.9680285524385153

Epoch: 6| Step: 9
Training loss: 2.717060660439388
Validation loss: 2.968534073805716

Epoch: 6| Step: 10
Training loss: 3.507474003625458
Validation loss: 2.975081467885316

Epoch: 6| Step: 11
Training loss: 4.095004755746318
Validation loss: 2.9683420415858124

Epoch: 6| Step: 12
Training loss: 3.197137362844226
Validation loss: 2.9697842085927357

Epoch: 6| Step: 13
Training loss: 4.532335033076304
Validation loss: 2.9705366215122586

Epoch: 105| Step: 0
Training loss: 2.9071798170263548
Validation loss: 2.965883659884997

Epoch: 6| Step: 1
Training loss: 3.7595516629459773
Validation loss: 2.9720957332713596

Epoch: 6| Step: 2
Training loss: 3.433987018860602
Validation loss: 2.9513273821378863

Epoch: 6| Step: 3
Training loss: 3.172304472011943
Validation loss: 2.949464884869787

Epoch: 6| Step: 4
Training loss: 3.608674216668884
Validation loss: 2.9448113375086056

Epoch: 6| Step: 5
Training loss: 3.385644586177943
Validation loss: 2.9435053451803013

Epoch: 6| Step: 6
Training loss: 2.643372680576458
Validation loss: 2.94339742139944

Epoch: 6| Step: 7
Training loss: 3.6411420594129766
Validation loss: 2.9429092740817726

Epoch: 6| Step: 8
Training loss: 2.7228574746860352
Validation loss: 2.943595700312878

Epoch: 6| Step: 9
Training loss: 2.19064192608921
Validation loss: 2.946914231663802

Epoch: 6| Step: 10
Training loss: 3.250767397146268
Validation loss: 2.946913524401926

Epoch: 6| Step: 11
Training loss: 3.440073887674672
Validation loss: 2.945086061850555

Epoch: 6| Step: 12
Training loss: 3.498755097380397
Validation loss: 2.943773787911192

Epoch: 6| Step: 13
Training loss: 3.163693102713463
Validation loss: 2.9442104073873057

Epoch: 106| Step: 0
Training loss: 3.1076324027128153
Validation loss: 2.940931068409446

Epoch: 6| Step: 1
Training loss: 3.127599016874056
Validation loss: 2.944082054087361

Epoch: 6| Step: 2
Training loss: 3.748572268494236
Validation loss: 2.939995586410646

Epoch: 6| Step: 3
Training loss: 2.7355209129285742
Validation loss: 2.9413433028177973

Epoch: 6| Step: 4
Training loss: 3.483536555249951
Validation loss: 2.941020504551835

Epoch: 6| Step: 5
Training loss: 3.139729082605409
Validation loss: 2.939507564026533

Epoch: 6| Step: 6
Training loss: 2.6328092399599625
Validation loss: 2.9387758251387424

Epoch: 6| Step: 7
Training loss: 3.104281446822505
Validation loss: 2.9402304138430604

Epoch: 6| Step: 8
Training loss: 3.255914441645904
Validation loss: 2.943597085948579

Epoch: 6| Step: 9
Training loss: 3.428831510670137
Validation loss: 2.9403994704490506

Epoch: 6| Step: 10
Training loss: 3.2027815471831746
Validation loss: 2.943593355791401

Epoch: 6| Step: 11
Training loss: 3.360030567166388
Validation loss: 2.942414012887671

Epoch: 6| Step: 12
Training loss: 3.2570817525767986
Validation loss: 2.9378703522524674

Epoch: 6| Step: 13
Training loss: 3.6211693353593226
Validation loss: 2.9356936362133474

Epoch: 107| Step: 0
Training loss: 3.0070489087556322
Validation loss: 2.937646140026487

Epoch: 6| Step: 1
Training loss: 3.489277901259342
Validation loss: 2.9370194205420437

Epoch: 6| Step: 2
Training loss: 2.717920461797533
Validation loss: 2.9376715001521614

Epoch: 6| Step: 3
Training loss: 3.442895296515146
Validation loss: 2.936277262025307

Epoch: 6| Step: 4
Training loss: 3.50493478298053
Validation loss: 2.9363611859360432

Epoch: 6| Step: 5
Training loss: 3.4266974203854743
Validation loss: 2.9363729618428085

Epoch: 6| Step: 6
Training loss: 3.286255859973394
Validation loss: 2.9381128150627998

Epoch: 6| Step: 7
Training loss: 2.4650455156499795
Validation loss: 2.9377513787538443

Epoch: 6| Step: 8
Training loss: 3.4657508325048143
Validation loss: 2.9348210677940667

Epoch: 6| Step: 9
Training loss: 3.320937584772645
Validation loss: 2.9348226899302157

Epoch: 6| Step: 10
Training loss: 3.19837949967639
Validation loss: 2.9346639286039538

Epoch: 6| Step: 11
Training loss: 3.5594013859521882
Validation loss: 2.931943602877814

Epoch: 6| Step: 12
Training loss: 3.071163457536924
Validation loss: 2.9300766001903105

Epoch: 6| Step: 13
Training loss: 2.7801593828138085
Validation loss: 2.9286790589108262

Epoch: 108| Step: 0
Training loss: 2.700460366455301
Validation loss: 2.932116919634044

Epoch: 6| Step: 1
Training loss: 3.1969279563597137
Validation loss: 2.933074352455844

Epoch: 6| Step: 2
Training loss: 3.42168589727018
Validation loss: 2.933810262442078

Epoch: 6| Step: 3
Training loss: 2.83452543723737
Validation loss: 2.929518471056379

Epoch: 6| Step: 4
Training loss: 3.342945322916131
Validation loss: 2.933287828568848

Epoch: 6| Step: 5
Training loss: 3.025979405264349
Validation loss: 2.92860099438048

Epoch: 6| Step: 6
Training loss: 3.3782920323240355
Validation loss: 2.930670284692682

Epoch: 6| Step: 7
Training loss: 3.1335739009573764
Validation loss: 2.9289347518755005

Epoch: 6| Step: 8
Training loss: 3.5474460495011186
Validation loss: 2.931800583613573

Epoch: 6| Step: 9
Training loss: 3.3146899199996174
Validation loss: 2.9288410961974845

Epoch: 6| Step: 10
Training loss: 3.411932448815234
Validation loss: 2.9293793783283335

Epoch: 6| Step: 11
Training loss: 3.37515286699882
Validation loss: 2.931182144918583

Epoch: 6| Step: 12
Training loss: 3.2535501310415054
Validation loss: 2.9295013941785015

Epoch: 6| Step: 13
Training loss: 2.9472628745741805
Validation loss: 2.9307617921752773

Epoch: 109| Step: 0
Training loss: 2.0148236951536207
Validation loss: 2.928582784655632

Epoch: 6| Step: 1
Training loss: 3.743964615467154
Validation loss: 2.9254976585275436

Epoch: 6| Step: 2
Training loss: 3.1073454554360294
Validation loss: 2.926200037720162

Epoch: 6| Step: 3
Training loss: 3.9620612542367666
Validation loss: 2.9278895657760025

Epoch: 6| Step: 4
Training loss: 3.089030046538552
Validation loss: 2.927131962181562

Epoch: 6| Step: 5
Training loss: 3.127578587021142
Validation loss: 2.927479642062344

Epoch: 6| Step: 6
Training loss: 2.8109213743229695
Validation loss: 2.927709384134492

Epoch: 6| Step: 7
Training loss: 3.5082306134793244
Validation loss: 2.923912530736829

Epoch: 6| Step: 8
Training loss: 3.471300991344566
Validation loss: 2.9239265241809576

Epoch: 6| Step: 9
Training loss: 3.175200274301038
Validation loss: 2.9245637949680017

Epoch: 6| Step: 10
Training loss: 3.1453597025922817
Validation loss: 2.926443554170579

Epoch: 6| Step: 11
Training loss: 3.17488143579373
Validation loss: 2.926181558983808

Epoch: 6| Step: 12
Training loss: 2.438701431361716
Validation loss: 2.9258470887533177

Epoch: 6| Step: 13
Training loss: 4.039668556063316
Validation loss: 2.9263153686110313

Epoch: 110| Step: 0
Training loss: 2.6556212634794036
Validation loss: 2.9240979559713547

Epoch: 6| Step: 1
Training loss: 3.476552213160694
Validation loss: 2.9312973340138293

Epoch: 6| Step: 2
Training loss: 3.283027676008161
Validation loss: 2.9328134172702027

Epoch: 6| Step: 3
Training loss: 3.621326821736627
Validation loss: 2.934717756751717

Epoch: 6| Step: 4
Training loss: 3.4586667432508067
Validation loss: 2.940421839013128

Epoch: 6| Step: 5
Training loss: 2.9661315613967902
Validation loss: 2.9357935527041565

Epoch: 6| Step: 6
Training loss: 3.2606227106836174
Validation loss: 2.9386542135647047

Epoch: 6| Step: 7
Training loss: 3.360357664236323
Validation loss: 2.928134648106921

Epoch: 6| Step: 8
Training loss: 3.6341974059229756
Validation loss: 2.9310335571916437

Epoch: 6| Step: 9
Training loss: 2.779100337421325
Validation loss: 2.926764481838158

Epoch: 6| Step: 10
Training loss: 3.6396504026775616
Validation loss: 2.9277814148658368

Epoch: 6| Step: 11
Training loss: 2.766233388072597
Validation loss: 2.9246619748013813

Epoch: 6| Step: 12
Training loss: 2.5421297766680047
Validation loss: 2.9271789407879147

Epoch: 6| Step: 13
Training loss: 3.2763718447247077
Validation loss: 2.924166015629229

Epoch: 111| Step: 0
Training loss: 3.8220449314720146
Validation loss: 2.9205614425064166

Epoch: 6| Step: 1
Training loss: 2.479918795917415
Validation loss: 2.9232684687391526

Epoch: 6| Step: 2
Training loss: 2.2988436819115705
Validation loss: 2.9270178861588625

Epoch: 6| Step: 3
Training loss: 3.162863572523095
Validation loss: 2.9341731890006173

Epoch: 6| Step: 4
Training loss: 3.2365115567830034
Validation loss: 2.9405308109644777

Epoch: 6| Step: 5
Training loss: 3.397567742958654
Validation loss: 2.9364971787183363

Epoch: 6| Step: 6
Training loss: 3.411606243314698
Validation loss: 2.9247334196749746

Epoch: 6| Step: 7
Training loss: 2.737093810860246
Validation loss: 2.9214126495732864

Epoch: 6| Step: 8
Training loss: 2.8228676335391913
Validation loss: 2.9195529497393737

Epoch: 6| Step: 9
Training loss: 3.20426823753089
Validation loss: 2.919441554421736

Epoch: 6| Step: 10
Training loss: 3.4109401785000792
Validation loss: 2.9214297333666255

Epoch: 6| Step: 11
Training loss: 2.9802873188757752
Validation loss: 2.9216700770422657

Epoch: 6| Step: 12
Training loss: 4.000078677357338
Validation loss: 2.9237375561777035

Epoch: 6| Step: 13
Training loss: 3.6909302096738577
Validation loss: 2.9240206292299504

Epoch: 112| Step: 0
Training loss: 3.736556050696298
Validation loss: 2.924015174951308

Epoch: 6| Step: 1
Training loss: 3.616904327975045
Validation loss: 2.922331671599901

Epoch: 6| Step: 2
Training loss: 3.511184532937684
Validation loss: 2.9241026236712933

Epoch: 6| Step: 3
Training loss: 2.4645258823985206
Validation loss: 2.9207671480627933

Epoch: 6| Step: 4
Training loss: 3.557762878098728
Validation loss: 2.9219213498163676

Epoch: 6| Step: 5
Training loss: 2.5989195999796153
Validation loss: 2.920601781083133

Epoch: 6| Step: 6
Training loss: 3.259996738549222
Validation loss: 2.9180890158864297

Epoch: 6| Step: 7
Training loss: 3.0191187410256175
Validation loss: 2.9201460820796923

Epoch: 6| Step: 8
Training loss: 2.2843102609042645
Validation loss: 2.9172238909009254

Epoch: 6| Step: 9
Training loss: 3.391150367924002
Validation loss: 2.919317291529112

Epoch: 6| Step: 10
Training loss: 3.1466084887358132
Validation loss: 2.9189770708000573

Epoch: 6| Step: 11
Training loss: 3.1341161892988114
Validation loss: 2.917871768286047

Epoch: 6| Step: 12
Training loss: 3.7686130176151127
Validation loss: 2.915993227465812

Epoch: 6| Step: 13
Training loss: 3.019107527322544
Validation loss: 2.918005297416397

Epoch: 113| Step: 0
Training loss: 2.889361461068857
Validation loss: 2.917641058269363

Epoch: 6| Step: 1
Training loss: 3.1317033207324916
Validation loss: 2.9186964370166857

Epoch: 6| Step: 2
Training loss: 2.830858458672406
Validation loss: 2.9190968595415674

Epoch: 6| Step: 3
Training loss: 3.584756893709741
Validation loss: 2.926971743173257

Epoch: 6| Step: 4
Training loss: 2.8668641783811726
Validation loss: 2.9408833680213804

Epoch: 6| Step: 5
Training loss: 3.0002047151018765
Validation loss: 2.9383027117345537

Epoch: 6| Step: 6
Training loss: 3.14327693587916
Validation loss: 2.9350901458201792

Epoch: 6| Step: 7
Training loss: 3.2026107747486474
Validation loss: 2.9358681496886794

Epoch: 6| Step: 8
Training loss: 3.5048751937260465
Validation loss: 2.936863069377669

Epoch: 6| Step: 9
Training loss: 3.457256624450891
Validation loss: 2.9239269467889426

Epoch: 6| Step: 10
Training loss: 2.7857862190768405
Validation loss: 2.922026710943275

Epoch: 6| Step: 11
Training loss: 4.032212962975068
Validation loss: 2.9219510148220755

Epoch: 6| Step: 12
Training loss: 3.0799140184959914
Validation loss: 2.920124195571704

Epoch: 6| Step: 13
Training loss: 3.1730098103715134
Validation loss: 2.9188319248208927

Epoch: 114| Step: 0
Training loss: 3.419509697284717
Validation loss: 2.9202115044655543

Epoch: 6| Step: 1
Training loss: 3.5588199279796604
Validation loss: 2.9187114848913436

Epoch: 6| Step: 2
Training loss: 2.6136993393077192
Validation loss: 2.9200779111685846

Epoch: 6| Step: 3
Training loss: 3.559715923162027
Validation loss: 2.9238553094791713

Epoch: 6| Step: 4
Training loss: 3.555565761180642
Validation loss: 2.924612720500699

Epoch: 6| Step: 5
Training loss: 3.5055517035085475
Validation loss: 2.921304982871126

Epoch: 6| Step: 6
Training loss: 2.823270139816442
Validation loss: 2.916571059762201

Epoch: 6| Step: 7
Training loss: 3.564407105867317
Validation loss: 2.9178306767773523

Epoch: 6| Step: 8
Training loss: 2.4125173617514037
Validation loss: 2.9183735688634522

Epoch: 6| Step: 9
Training loss: 2.6806484089934584
Validation loss: 2.9185464757703663

Epoch: 6| Step: 10
Training loss: 3.3757485866401007
Validation loss: 2.9180445573308695

Epoch: 6| Step: 11
Training loss: 3.606345486492432
Validation loss: 2.9158339517360834

Epoch: 6| Step: 12
Training loss: 2.686850890792153
Validation loss: 2.9229265731040095

Epoch: 6| Step: 13
Training loss: 3.153081682283827
Validation loss: 2.9177822727699336

Epoch: 115| Step: 0
Training loss: 3.9984491441265706
Validation loss: 2.9206145053285058

Epoch: 6| Step: 1
Training loss: 3.961678038824051
Validation loss: 2.9178240370999786

Epoch: 6| Step: 2
Training loss: 2.2417667007343205
Validation loss: 2.9180732979909556

Epoch: 6| Step: 3
Training loss: 3.1157333309275885
Validation loss: 2.9182992423965817

Epoch: 6| Step: 4
Training loss: 3.33968812457229
Validation loss: 2.9190600096247747

Epoch: 6| Step: 5
Training loss: 3.53590720615061
Validation loss: 2.9181609537624733

Epoch: 6| Step: 6
Training loss: 3.008620592035707
Validation loss: 2.921958719023354

Epoch: 6| Step: 7
Training loss: 3.277727834317452
Validation loss: 2.9184908815344928

Epoch: 6| Step: 8
Training loss: 2.7904662118057866
Validation loss: 2.9158690690710705

Epoch: 6| Step: 9
Training loss: 3.323427852586124
Validation loss: 2.9228756721961795

Epoch: 6| Step: 10
Training loss: 2.875409967797663
Validation loss: 2.9150949142832103

Epoch: 6| Step: 11
Training loss: 2.758535230994157
Validation loss: 2.9129457679328086

Epoch: 6| Step: 12
Training loss: 3.0787496949481077
Validation loss: 2.917900457054025

Epoch: 6| Step: 13
Training loss: 3.0262271126122333
Validation loss: 2.912861407898767

Epoch: 116| Step: 0
Training loss: 3.1920017541292576
Validation loss: 2.912515407892777

Epoch: 6| Step: 1
Training loss: 3.2149888071959922
Validation loss: 2.9104651295518345

Epoch: 6| Step: 2
Training loss: 3.067766915470641
Validation loss: 2.9107147158846143

Epoch: 6| Step: 3
Training loss: 2.4518251316076083
Validation loss: 2.910732077370857

Epoch: 6| Step: 4
Training loss: 2.893496185442604
Validation loss: 2.909019820157165

Epoch: 6| Step: 5
Training loss: 3.4529266990926177
Validation loss: 2.9137921461791603

Epoch: 6| Step: 6
Training loss: 3.890605022578291
Validation loss: 2.907172894646518

Epoch: 6| Step: 7
Training loss: 3.365531496468744
Validation loss: 2.9099521192902187

Epoch: 6| Step: 8
Training loss: 3.236349341737937
Validation loss: 2.908979579190928

Epoch: 6| Step: 9
Training loss: 2.614112983941218
Validation loss: 2.9112985852466013

Epoch: 6| Step: 10
Training loss: 2.857572393826955
Validation loss: 2.9093760635312176

Epoch: 6| Step: 11
Training loss: 3.597001437592292
Validation loss: 2.9071230142237874

Epoch: 6| Step: 12
Training loss: 3.408085879519854
Validation loss: 2.91095568884881

Epoch: 6| Step: 13
Training loss: 3.3718252438187712
Validation loss: 2.911486647088472

Epoch: 117| Step: 0
Training loss: 3.149988743595417
Validation loss: 2.9142942379607835

Epoch: 6| Step: 1
Training loss: 2.9267043731566065
Validation loss: 2.9131990331396027

Epoch: 6| Step: 2
Training loss: 2.513481316683135
Validation loss: 2.9213494804408113

Epoch: 6| Step: 3
Training loss: 3.581403804225843
Validation loss: 2.9175666270296663

Epoch: 6| Step: 4
Training loss: 3.4774794151634807
Validation loss: 2.919264146289765

Epoch: 6| Step: 5
Training loss: 2.9100367988802827
Validation loss: 2.921543268553673

Epoch: 6| Step: 6
Training loss: 3.234482178317424
Validation loss: 2.919402570588657

Epoch: 6| Step: 7
Training loss: 3.0587911140226023
Validation loss: 2.920337427963722

Epoch: 6| Step: 8
Training loss: 3.6039146967370663
Validation loss: 2.9140561068643227

Epoch: 6| Step: 9
Training loss: 2.9113165878339595
Validation loss: 2.908923899940734

Epoch: 6| Step: 10
Training loss: 3.3164531223682645
Validation loss: 2.906939227762355

Epoch: 6| Step: 11
Training loss: 3.611243750915719
Validation loss: 2.9056659790467094

Epoch: 6| Step: 12
Training loss: 3.179305070003414
Validation loss: 2.9035855792162875

Epoch: 6| Step: 13
Training loss: 3.113614666362615
Validation loss: 2.9068220591950684

Epoch: 118| Step: 0
Training loss: 2.9550119658613547
Validation loss: 2.9040578248129725

Epoch: 6| Step: 1
Training loss: 3.6755071329030224
Validation loss: 2.906170744603098

Epoch: 6| Step: 2
Training loss: 3.3985750017082643
Validation loss: 2.9060084568632325

Epoch: 6| Step: 3
Training loss: 2.6424727436489737
Validation loss: 2.905483071000908

Epoch: 6| Step: 4
Training loss: 3.0197954346044553
Validation loss: 2.9053747575119684

Epoch: 6| Step: 5
Training loss: 3.3330281276849383
Validation loss: 2.906271242083279

Epoch: 6| Step: 6
Training loss: 3.8312148722645323
Validation loss: 2.9048214975441904

Epoch: 6| Step: 7
Training loss: 3.5381205738971886
Validation loss: 2.9029866576967076

Epoch: 6| Step: 8
Training loss: 3.138814983416842
Validation loss: 2.9026024517809277

Epoch: 6| Step: 9
Training loss: 2.529984145887555
Validation loss: 2.9055333519206723

Epoch: 6| Step: 10
Training loss: 2.9247409412397976
Validation loss: 2.9021178159964927

Epoch: 6| Step: 11
Training loss: 3.3769710577802483
Validation loss: 2.904127184796526

Epoch: 6| Step: 12
Training loss: 3.0484827739222
Validation loss: 2.9057611748359586

Epoch: 6| Step: 13
Training loss: 3.038662214811824
Validation loss: 2.9025249463008165

Epoch: 119| Step: 0
Training loss: 2.6752581676789458
Validation loss: 2.9027773155210337

Epoch: 6| Step: 1
Training loss: 3.1346661418209614
Validation loss: 2.9036660882585585

Epoch: 6| Step: 2
Training loss: 2.8008848461107956
Validation loss: 2.902186656118745

Epoch: 6| Step: 3
Training loss: 3.1582712179096437
Validation loss: 2.9024036830621722

Epoch: 6| Step: 4
Training loss: 3.1114735638186426
Validation loss: 2.9023713503481834

Epoch: 6| Step: 5
Training loss: 3.2334019768366313
Validation loss: 2.9005690496182823

Epoch: 6| Step: 6
Training loss: 3.6821107437744107
Validation loss: 2.9023557902392096

Epoch: 6| Step: 7
Training loss: 2.6428208109298827
Validation loss: 2.903644815639099

Epoch: 6| Step: 8
Training loss: 3.1867555235068727
Validation loss: 2.917396586506283

Epoch: 6| Step: 9
Training loss: 3.5923287940061397
Validation loss: 2.9287564858678614

Epoch: 6| Step: 10
Training loss: 3.417402157279362
Validation loss: 2.943880751294522

Epoch: 6| Step: 11
Training loss: 3.581848339540051
Validation loss: 2.941425382636371

Epoch: 6| Step: 12
Training loss: 3.4570180084492166
Validation loss: 2.928163014819602

Epoch: 6| Step: 13
Training loss: 2.699254081262978
Validation loss: 2.9276449857014173

Epoch: 120| Step: 0
Training loss: 3.5705045485649842
Validation loss: 2.9178067142977238

Epoch: 6| Step: 1
Training loss: 3.01817016719437
Validation loss: 2.906473922791824

Epoch: 6| Step: 2
Training loss: 2.89812424604395
Validation loss: 2.901076228129091

Epoch: 6| Step: 3
Training loss: 1.9852838912816837
Validation loss: 2.902762840358038

Epoch: 6| Step: 4
Training loss: 3.405012833491268
Validation loss: 2.896295995810206

Epoch: 6| Step: 5
Training loss: 3.4212948381345036
Validation loss: 2.9025620900482267

Epoch: 6| Step: 6
Training loss: 3.4017912353653905
Validation loss: 2.8996622500627915

Epoch: 6| Step: 7
Training loss: 2.894774391989396
Validation loss: 2.898010763800349

Epoch: 6| Step: 8
Training loss: 3.2746898649876797
Validation loss: 2.8985972717419033

Epoch: 6| Step: 9
Training loss: 3.6821657813036364
Validation loss: 2.9011262558169215

Epoch: 6| Step: 10
Training loss: 3.0609925900419137
Validation loss: 2.8985207488258626

Epoch: 6| Step: 11
Training loss: 3.1897479339791444
Validation loss: 2.898346114762675

Epoch: 6| Step: 12
Training loss: 3.556839846750844
Validation loss: 2.8983787710001634

Epoch: 6| Step: 13
Training loss: 2.82848225228681
Validation loss: 2.897293777516077

Epoch: 121| Step: 0
Training loss: 3.812690855158183
Validation loss: 2.895542274154782

Epoch: 6| Step: 1
Training loss: 3.3546427197392585
Validation loss: 2.8955464416117365

Epoch: 6| Step: 2
Training loss: 3.190878778988971
Validation loss: 2.894039755386664

Epoch: 6| Step: 3
Training loss: 3.8898781668601314
Validation loss: 2.895814168008939

Epoch: 6| Step: 4
Training loss: 3.551965497132857
Validation loss: 2.8939067017383544

Epoch: 6| Step: 5
Training loss: 3.1698373347283444
Validation loss: 2.893901771837788

Epoch: 6| Step: 6
Training loss: 2.735946378143389
Validation loss: 2.8939563803161508

Epoch: 6| Step: 7
Training loss: 3.3792258756430775
Validation loss: 2.8944484373413397

Epoch: 6| Step: 8
Training loss: 3.408901337641345
Validation loss: 2.893686334510332

Epoch: 6| Step: 9
Training loss: 3.1652091503491677
Validation loss: 2.892175054748042

Epoch: 6| Step: 10
Training loss: 2.663556540314271
Validation loss: 2.8943668339983555

Epoch: 6| Step: 11
Training loss: 3.1346661418209614
Validation loss: 2.891307348738954

Epoch: 6| Step: 12
Training loss: 2.204117788002418
Validation loss: 2.893299555638281

Epoch: 6| Step: 13
Training loss: 1.9808417275646368
Validation loss: 2.891165333238774

Epoch: 122| Step: 0
Training loss: 1.9332991558649466
Validation loss: 2.893421250048137

Epoch: 6| Step: 1
Training loss: 2.9110276524112626
Validation loss: 2.8949159231489237

Epoch: 6| Step: 2
Training loss: 3.670316844432561
Validation loss: 2.8991327411886165

Epoch: 6| Step: 3
Training loss: 3.5672769475976795
Validation loss: 2.895238904894967

Epoch: 6| Step: 4
Training loss: 2.740608217020528
Validation loss: 2.8919789379149843

Epoch: 6| Step: 5
Training loss: 3.4916687309119436
Validation loss: 2.894591335964811

Epoch: 6| Step: 6
Training loss: 3.584890042245401
Validation loss: 2.894745271220738

Epoch: 6| Step: 7
Training loss: 3.587164907722436
Validation loss: 2.8937219757705432

Epoch: 6| Step: 8
Training loss: 2.7851038602847904
Validation loss: 2.8928188106324275

Epoch: 6| Step: 9
Training loss: 3.3923596985492
Validation loss: 2.8878133068193246

Epoch: 6| Step: 10
Training loss: 3.4491309633240435
Validation loss: 2.887437878310557

Epoch: 6| Step: 11
Training loss: 3.2524686387563753
Validation loss: 2.8869546822180143

Epoch: 6| Step: 12
Training loss: 3.085474525199373
Validation loss: 2.8906152753325483

Epoch: 6| Step: 13
Training loss: 2.259183051897566
Validation loss: 2.8898600126181253

Epoch: 123| Step: 0
Training loss: 3.1975993807740766
Validation loss: 2.8901962037619473

Epoch: 6| Step: 1
Training loss: 3.236263000532893
Validation loss: 2.8927153040582416

Epoch: 6| Step: 2
Training loss: 3.173672922887954
Validation loss: 2.89320211384122

Epoch: 6| Step: 3
Training loss: 3.390092517861878
Validation loss: 2.8905919422054205

Epoch: 6| Step: 4
Training loss: 3.4279757248988223
Validation loss: 2.8967625657235643

Epoch: 6| Step: 5
Training loss: 3.686378696454931
Validation loss: 2.901534367272541

Epoch: 6| Step: 6
Training loss: 2.996006373756464
Validation loss: 2.8971057544759993

Epoch: 6| Step: 7
Training loss: 3.524025878499473
Validation loss: 2.895886614074666

Epoch: 6| Step: 8
Training loss: 3.6391365381147756
Validation loss: 2.8921465672993394

Epoch: 6| Step: 9
Training loss: 2.7586385986346955
Validation loss: 2.8946524382911187

Epoch: 6| Step: 10
Training loss: 2.592946031361145
Validation loss: 2.8922637808311165

Epoch: 6| Step: 11
Training loss: 3.114407401501033
Validation loss: 2.8931332318437084

Epoch: 6| Step: 12
Training loss: 3.0005489482907737
Validation loss: 2.8967750760846815

Epoch: 6| Step: 13
Training loss: 1.8955436597025728
Validation loss: 2.892335305379096

Epoch: 124| Step: 0
Training loss: 3.371930457252184
Validation loss: 2.8919379261670124

Epoch: 6| Step: 1
Training loss: 2.9675026933614435
Validation loss: 2.895621601779495

Epoch: 6| Step: 2
Training loss: 3.3569727625555794
Validation loss: 2.888776494659275

Epoch: 6| Step: 3
Training loss: 3.790040572258782
Validation loss: 2.891280580880657

Epoch: 6| Step: 4
Training loss: 2.8143584151417875
Validation loss: 2.890630733680526

Epoch: 6| Step: 5
Training loss: 3.3660919460583436
Validation loss: 2.889931966576446

Epoch: 6| Step: 6
Training loss: 3.2939107142694537
Validation loss: 2.886115982773642

Epoch: 6| Step: 7
Training loss: 2.8253522737680394
Validation loss: 2.887350944852178

Epoch: 6| Step: 8
Training loss: 3.523416793999234
Validation loss: 2.8879442452898836

Epoch: 6| Step: 9
Training loss: 2.556681656708555
Validation loss: 2.8877364439822135

Epoch: 6| Step: 10
Training loss: 2.9972906594117745
Validation loss: 2.8889772356558434

Epoch: 6| Step: 11
Training loss: 2.8447342730757157
Validation loss: 2.891579343794064

Epoch: 6| Step: 12
Training loss: 3.4878738695140155
Validation loss: 2.8917945205392925

Epoch: 6| Step: 13
Training loss: 3.09733543322138
Validation loss: 2.8895123522930084

Epoch: 125| Step: 0
Training loss: 3.1526650190611925
Validation loss: 2.8885840379213588

Epoch: 6| Step: 1
Training loss: 3.5724063134372233
Validation loss: 2.8930140924922605

Epoch: 6| Step: 2
Training loss: 2.75189178593368
Validation loss: 2.8839330413258772

Epoch: 6| Step: 3
Training loss: 2.8036282805213952
Validation loss: 2.885377732532483

Epoch: 6| Step: 4
Training loss: 2.689833936138792
Validation loss: 2.883893587275105

Epoch: 6| Step: 5
Training loss: 3.78942114322333
Validation loss: 2.886413816544823

Epoch: 6| Step: 6
Training loss: 2.886574376358424
Validation loss: 2.8829542164607336

Epoch: 6| Step: 7
Training loss: 2.328145071877611
Validation loss: 2.88455138058435

Epoch: 6| Step: 8
Training loss: 2.9314239645539057
Validation loss: 2.884174803940276

Epoch: 6| Step: 9
Training loss: 3.6153681156887023
Validation loss: 2.884266702178309

Epoch: 6| Step: 10
Training loss: 3.056678376863513
Validation loss: 2.8852264518111106

Epoch: 6| Step: 11
Training loss: 3.8207576936967453
Validation loss: 2.8839074975497745

Epoch: 6| Step: 12
Training loss: 3.1586385319450976
Validation loss: 2.8869379876077392

Epoch: 6| Step: 13
Training loss: 3.756788847955141
Validation loss: 2.8892240162943335

Epoch: 126| Step: 0
Training loss: 2.835957340559901
Validation loss: 2.8907814540056713

Epoch: 6| Step: 1
Training loss: 3.470880627319465
Validation loss: 2.9133724917800214

Epoch: 6| Step: 2
Training loss: 2.9415330188278515
Validation loss: 2.918615118126031

Epoch: 6| Step: 3
Training loss: 3.377975847337472
Validation loss: 2.935217321065032

Epoch: 6| Step: 4
Training loss: 3.5380604653806373
Validation loss: 2.8961474913007104

Epoch: 6| Step: 5
Training loss: 2.9135558477953802
Validation loss: 2.8831168718071094

Epoch: 6| Step: 6
Training loss: 3.7537971345760375
Validation loss: 2.8806967238973504

Epoch: 6| Step: 7
Training loss: 2.8727119297236814
Validation loss: 2.8826128398101085

Epoch: 6| Step: 8
Training loss: 3.0112619412297446
Validation loss: 2.88109883376385

Epoch: 6| Step: 9
Training loss: 2.9852677053666525
Validation loss: 2.8825759219256057

Epoch: 6| Step: 10
Training loss: 2.9274454311428824
Validation loss: 2.8835269462749626

Epoch: 6| Step: 11
Training loss: 3.64117833463452
Validation loss: 2.884230706754386

Epoch: 6| Step: 12
Training loss: 2.970143202081196
Validation loss: 2.882589891920018

Epoch: 6| Step: 13
Training loss: 3.087804919796146
Validation loss: 2.883357510550406

Epoch: 127| Step: 0
Training loss: 2.744501859842547
Validation loss: 2.8829414878392186

Epoch: 6| Step: 1
Training loss: 2.9977120575967984
Validation loss: 2.8825905722751597

Epoch: 6| Step: 2
Training loss: 3.226778258713822
Validation loss: 2.8832980778369333

Epoch: 6| Step: 3
Training loss: 2.6894650040019976
Validation loss: 2.88034543160596

Epoch: 6| Step: 4
Training loss: 3.2462033323298005
Validation loss: 2.880887457931625

Epoch: 6| Step: 5
Training loss: 3.113773474556955
Validation loss: 2.879851888940839

Epoch: 6| Step: 6
Training loss: 3.6914275638025553
Validation loss: 2.880391624635666

Epoch: 6| Step: 7
Training loss: 3.4280733728824595
Validation loss: 2.877772283573248

Epoch: 6| Step: 8
Training loss: 3.3044268999087905
Validation loss: 2.8790019014120274

Epoch: 6| Step: 9
Training loss: 3.070534423883633
Validation loss: 2.877835074782788

Epoch: 6| Step: 10
Training loss: 3.193821640853475
Validation loss: 2.878881553011567

Epoch: 6| Step: 11
Training loss: 3.2575027721097545
Validation loss: 2.880178261829314

Epoch: 6| Step: 12
Training loss: 3.299153774307266
Validation loss: 2.8830495023777507

Epoch: 6| Step: 13
Training loss: 3.097311108905058
Validation loss: 2.884177500753951

Epoch: 128| Step: 0
Training loss: 3.510517394359218
Validation loss: 2.886424948020825

Epoch: 6| Step: 1
Training loss: 2.776561600100533
Validation loss: 2.890587080263623

Epoch: 6| Step: 2
Training loss: 3.3720424550416794
Validation loss: 2.891084281000783

Epoch: 6| Step: 3
Training loss: 3.217693859268258
Validation loss: 2.8886169855700787

Epoch: 6| Step: 4
Training loss: 3.47504520524076
Validation loss: 2.8928046463272037

Epoch: 6| Step: 5
Training loss: 2.1492303668380384
Validation loss: 2.8905927621362437

Epoch: 6| Step: 6
Training loss: 3.432556203894629
Validation loss: 2.8947994068163614

Epoch: 6| Step: 7
Training loss: 2.6476100653084025
Validation loss: 2.909859419976556

Epoch: 6| Step: 8
Training loss: 2.7153938888695697
Validation loss: 2.9107411086144057

Epoch: 6| Step: 9
Training loss: 3.2849045519846407
Validation loss: 2.913329982538348

Epoch: 6| Step: 10
Training loss: 3.6080036943674734
Validation loss: 2.9087944655148505

Epoch: 6| Step: 11
Training loss: 3.361724883297115
Validation loss: 2.896093171995591

Epoch: 6| Step: 12
Training loss: 2.8323775717664144
Validation loss: 2.8908672768903494

Epoch: 6| Step: 13
Training loss: 4.009401240749817
Validation loss: 2.8902917600566376

Epoch: 129| Step: 0
Training loss: 2.64390964612218
Validation loss: 2.8839770603616777

Epoch: 6| Step: 1
Training loss: 2.7333037103427844
Validation loss: 2.8848580073954158

Epoch: 6| Step: 2
Training loss: 2.4292467704987817
Validation loss: 2.882352600042978

Epoch: 6| Step: 3
Training loss: 3.166997908952587
Validation loss: 2.8833257689179104

Epoch: 6| Step: 4
Training loss: 3.340353408207526
Validation loss: 2.88316793935365

Epoch: 6| Step: 5
Training loss: 3.2186865939219027
Validation loss: 2.8802603561692677

Epoch: 6| Step: 6
Training loss: 3.1534996513341103
Validation loss: 2.8797265480055088

Epoch: 6| Step: 7
Training loss: 3.0005470412904827
Validation loss: 2.8783082310727455

Epoch: 6| Step: 8
Training loss: 3.291134288244598
Validation loss: 2.881235667814043

Epoch: 6| Step: 9
Training loss: 3.8996665714245538
Validation loss: 2.8802614278164

Epoch: 6| Step: 10
Training loss: 3.6593264165270734
Validation loss: 2.883268796701296

Epoch: 6| Step: 11
Training loss: 3.232673824206664
Validation loss: 2.880041926757015

Epoch: 6| Step: 12
Training loss: 3.08109260451114
Validation loss: 2.8790358861235847

Epoch: 6| Step: 13
Training loss: 3.3021940740233076
Validation loss: 2.8857037265334813

Epoch: 130| Step: 0
Training loss: 3.330988122548412
Validation loss: 2.880652785557818

Epoch: 6| Step: 1
Training loss: 2.8766357081026697
Validation loss: 2.884383112483008

Epoch: 6| Step: 2
Training loss: 2.7465460501115397
Validation loss: 2.87978946307486

Epoch: 6| Step: 3
Training loss: 3.7224431011906094
Validation loss: 2.8782716659104817

Epoch: 6| Step: 4
Training loss: 3.5051523159741165
Validation loss: 2.8811355641411605

Epoch: 6| Step: 5
Training loss: 2.8065286612692697
Validation loss: 2.881387681220454

Epoch: 6| Step: 6
Training loss: 3.3742553454580966
Validation loss: 2.890667506124106

Epoch: 6| Step: 7
Training loss: 2.390812885156648
Validation loss: 2.885065507753416

Epoch: 6| Step: 8
Training loss: 3.325536446570794
Validation loss: 2.888065140100987

Epoch: 6| Step: 9
Training loss: 3.2503214457076774
Validation loss: 2.8865418920932457

Epoch: 6| Step: 10
Training loss: 3.1391560169832915
Validation loss: 2.8852505613690713

Epoch: 6| Step: 11
Training loss: 3.0595924432649975
Validation loss: 2.890887223765924

Epoch: 6| Step: 12
Training loss: 3.4309346705559767
Validation loss: 2.8886466686622225

Epoch: 6| Step: 13
Training loss: 3.137256998933297
Validation loss: 2.886960500444612

Epoch: 131| Step: 0
Training loss: 3.0140568109738464
Validation loss: 2.883426856355154

Epoch: 6| Step: 1
Training loss: 3.017806613012179
Validation loss: 2.8841151694035134

Epoch: 6| Step: 2
Training loss: 3.2770255369670345
Validation loss: 2.8772153179700086

Epoch: 6| Step: 3
Training loss: 3.880879156852263
Validation loss: 2.8727101975527938

Epoch: 6| Step: 4
Training loss: 2.647698673506114
Validation loss: 2.8728264032893387

Epoch: 6| Step: 5
Training loss: 3.252760081935765
Validation loss: 2.884948755315568

Epoch: 6| Step: 6
Training loss: 3.699370851380667
Validation loss: 2.8826975968096877

Epoch: 6| Step: 7
Training loss: 3.3932868599347965
Validation loss: 2.8869199448879352

Epoch: 6| Step: 8
Training loss: 2.7171525317898446
Validation loss: 2.889287419302977

Epoch: 6| Step: 9
Training loss: 2.787979727891644
Validation loss: 2.8900429576172444

Epoch: 6| Step: 10
Training loss: 3.391270448627963
Validation loss: 2.886007545582705

Epoch: 6| Step: 11
Training loss: 2.5245644146473296
Validation loss: 2.880038601191906

Epoch: 6| Step: 12
Training loss: 3.409961882794917
Validation loss: 2.8755363081840066

Epoch: 6| Step: 13
Training loss: 3.198144231562877
Validation loss: 2.8727677976984927

Epoch: 132| Step: 0
Training loss: 2.8456918981955104
Validation loss: 2.8697676446112985

Epoch: 6| Step: 1
Training loss: 2.848502076673027
Validation loss: 2.8709521570896857

Epoch: 6| Step: 2
Training loss: 3.250504968000675
Validation loss: 2.8705181304616683

Epoch: 6| Step: 3
Training loss: 3.073432560089129
Validation loss: 2.8687538459186017

Epoch: 6| Step: 4
Training loss: 2.953856846785448
Validation loss: 2.868127282426863

Epoch: 6| Step: 5
Training loss: 2.6501232622377606
Validation loss: 2.8691016010492136

Epoch: 6| Step: 6
Training loss: 3.1200228920121225
Validation loss: 2.8666563353193757

Epoch: 6| Step: 7
Training loss: 3.0034298363979683
Validation loss: 2.8690287601035354

Epoch: 6| Step: 8
Training loss: 3.4584461484838664
Validation loss: 2.8695322576126356

Epoch: 6| Step: 9
Training loss: 3.3891004659619917
Validation loss: 2.868049703182183

Epoch: 6| Step: 10
Training loss: 3.797266810416696
Validation loss: 2.8652519718032474

Epoch: 6| Step: 11
Training loss: 2.7651991004380636
Validation loss: 2.8687734818601727

Epoch: 6| Step: 12
Training loss: 3.0583224706084406
Validation loss: 2.8722240195165556

Epoch: 6| Step: 13
Training loss: 4.294330079098144
Validation loss: 2.8712220982027983

Epoch: 133| Step: 0
Training loss: 2.945173912936451
Validation loss: 2.8730648103202987

Epoch: 6| Step: 1
Training loss: 2.949960456195173
Validation loss: 2.872612547295555

Epoch: 6| Step: 2
Training loss: 3.3515250819680635
Validation loss: 2.8849958254537853

Epoch: 6| Step: 3
Training loss: 2.955053920608904
Validation loss: 2.8980895895196506

Epoch: 6| Step: 4
Training loss: 4.139312420936022
Validation loss: 2.8924051618486093

Epoch: 6| Step: 5
Training loss: 2.9672173006912526
Validation loss: 2.8901376833959658

Epoch: 6| Step: 6
Training loss: 3.0128645047203353
Validation loss: 2.9014023102858695

Epoch: 6| Step: 7
Training loss: 3.29082421897952
Validation loss: 2.892406782955317

Epoch: 6| Step: 8
Training loss: 3.4884280593581662
Validation loss: 2.874623829119465

Epoch: 6| Step: 9
Training loss: 3.171426374908433
Validation loss: 2.8655650716114596

Epoch: 6| Step: 10
Training loss: 3.1526957224410888
Validation loss: 2.8640944155206722

Epoch: 6| Step: 11
Training loss: 2.699407678553382
Validation loss: 2.862606745910031

Epoch: 6| Step: 12
Training loss: 2.9514483177833872
Validation loss: 2.8631168786063195

Epoch: 6| Step: 13
Training loss: 2.9116353007917897
Validation loss: 2.863380536394621

Epoch: 134| Step: 0
Training loss: 2.1830872850848904
Validation loss: 2.863200078153131

Epoch: 6| Step: 1
Training loss: 3.3194577541820465
Validation loss: 2.864040002092889

Epoch: 6| Step: 2
Training loss: 2.908061621651905
Validation loss: 2.8647124970402817

Epoch: 6| Step: 3
Training loss: 3.1503978901807113
Validation loss: 2.8640463162159797

Epoch: 6| Step: 4
Training loss: 4.006285973445404
Validation loss: 2.863672138770109

Epoch: 6| Step: 5
Training loss: 3.270769803023459
Validation loss: 2.8639045503274563

Epoch: 6| Step: 6
Training loss: 3.1733994602344517
Validation loss: 2.862992183996519

Epoch: 6| Step: 7
Training loss: 3.2574301662264067
Validation loss: 2.86101535452761

Epoch: 6| Step: 8
Training loss: 3.419399951473534
Validation loss: 2.865225822164803

Epoch: 6| Step: 9
Training loss: 3.2086477909966185
Validation loss: 2.863470033826309

Epoch: 6| Step: 10
Training loss: 3.2805041237450387
Validation loss: 2.8637187216011815

Epoch: 6| Step: 11
Training loss: 2.7914969454363754
Validation loss: 2.8626254881615334

Epoch: 6| Step: 12
Training loss: 3.241941585176886
Validation loss: 2.862229635909329

Epoch: 6| Step: 13
Training loss: 2.546240698339058
Validation loss: 2.8616570333760802

Epoch: 135| Step: 0
Training loss: 3.457390683556765
Validation loss: 2.863046800005023

Epoch: 6| Step: 1
Training loss: 2.873851214895943
Validation loss: 2.862970623486506

Epoch: 6| Step: 2
Training loss: 3.491601540649298
Validation loss: 2.861132571971592

Epoch: 6| Step: 3
Training loss: 2.3351971017449045
Validation loss: 2.861111111243856

Epoch: 6| Step: 4
Training loss: 3.357566737167148
Validation loss: 2.8602096618823882

Epoch: 6| Step: 5
Training loss: 3.1410277758380976
Validation loss: 2.8582354894752267

Epoch: 6| Step: 6
Training loss: 3.305833261687157
Validation loss: 2.859059011114005

Epoch: 6| Step: 7
Training loss: 2.791410168683184
Validation loss: 2.8596537419588985

Epoch: 6| Step: 8
Training loss: 3.661282979674062
Validation loss: 2.8580284541073553

Epoch: 6| Step: 9
Training loss: 3.499732143506692
Validation loss: 2.858715536978046

Epoch: 6| Step: 10
Training loss: 2.9623253621966765
Validation loss: 2.8566719259634694

Epoch: 6| Step: 11
Training loss: 2.8621765753592414
Validation loss: 2.8591771838787365

Epoch: 6| Step: 12
Training loss: 3.2835763586374735
Validation loss: 2.865490373813381

Epoch: 6| Step: 13
Training loss: 2.8766746619309775
Validation loss: 2.8580548346435655

Epoch: 136| Step: 0
Training loss: 2.635207086203381
Validation loss: 2.8622625376138817

Epoch: 6| Step: 1
Training loss: 3.5792671612866838
Validation loss: 2.8606626920711347

Epoch: 6| Step: 2
Training loss: 3.3727953739203302
Validation loss: 2.856833463663499

Epoch: 6| Step: 3
Training loss: 3.3024115334154156
Validation loss: 2.8560409936515616

Epoch: 6| Step: 4
Training loss: 3.222895794837668
Validation loss: 2.8556483097966474

Epoch: 6| Step: 5
Training loss: 2.749707986759898
Validation loss: 2.8576535209866245

Epoch: 6| Step: 6
Training loss: 3.506543582042184
Validation loss: 2.855878254926175

Epoch: 6| Step: 7
Training loss: 3.4284162315937756
Validation loss: 2.856046453871185

Epoch: 6| Step: 8
Training loss: 3.2495882800545925
Validation loss: 2.8539363899028527

Epoch: 6| Step: 9
Training loss: 3.1013626303279858
Validation loss: 2.857143661832916

Epoch: 6| Step: 10
Training loss: 3.3511426258066868
Validation loss: 2.8534860975468037

Epoch: 6| Step: 11
Training loss: 2.091151432649013
Validation loss: 2.8525686752480226

Epoch: 6| Step: 12
Training loss: 3.7051241986954753
Validation loss: 2.8534649216125523

Epoch: 6| Step: 13
Training loss: 1.76163653332007
Validation loss: 2.8553249879072617

Epoch: 137| Step: 0
Training loss: 4.063289624282373
Validation loss: 2.8533708813161134

Epoch: 6| Step: 1
Training loss: 2.9196987921680044
Validation loss: 2.8542702152111548

Epoch: 6| Step: 2
Training loss: 2.8908793569467575
Validation loss: 2.852685924332463

Epoch: 6| Step: 3
Training loss: 3.762164666830345
Validation loss: 2.8556012407000058

Epoch: 6| Step: 4
Training loss: 3.127036079864668
Validation loss: 2.853697576044497

Epoch: 6| Step: 5
Training loss: 3.761141565394603
Validation loss: 2.8533885827272627

Epoch: 6| Step: 6
Training loss: 2.269762877628498
Validation loss: 2.8551015655817045

Epoch: 6| Step: 7
Training loss: 2.80817963116346
Validation loss: 2.85424126142176

Epoch: 6| Step: 8
Training loss: 2.812097647815091
Validation loss: 2.855395583726826

Epoch: 6| Step: 9
Training loss: 2.810819674912115
Validation loss: 2.8537990625856446

Epoch: 6| Step: 10
Training loss: 2.7477271484391035
Validation loss: 2.853815301570555

Epoch: 6| Step: 11
Training loss: 3.231651449444733
Validation loss: 2.8543059579518997

Epoch: 6| Step: 12
Training loss: 3.8440072818651405
Validation loss: 2.8585591825916787

Epoch: 6| Step: 13
Training loss: 1.7816745854348373
Validation loss: 2.8591556143264545

Epoch: 138| Step: 0
Training loss: 3.2361208124702068
Validation loss: 2.868193581857361

Epoch: 6| Step: 1
Training loss: 3.651242731773406
Validation loss: 2.8770686737357383

Epoch: 6| Step: 2
Training loss: 3.438666821898267
Validation loss: 2.891352494166886

Epoch: 6| Step: 3
Training loss: 2.918814131953189
Validation loss: 2.894347733956018

Epoch: 6| Step: 4
Training loss: 2.7074066826544514
Validation loss: 2.910266695241296

Epoch: 6| Step: 5
Training loss: 2.8271543407213846
Validation loss: 2.9308803750092753

Epoch: 6| Step: 6
Training loss: 3.0816376293321097
Validation loss: 2.9204440664118203

Epoch: 6| Step: 7
Training loss: 3.748555222984667
Validation loss: 2.9231551733300565

Epoch: 6| Step: 8
Training loss: 3.4045650969618255
Validation loss: 2.895388809816275

Epoch: 6| Step: 9
Training loss: 2.8636081399668964
Validation loss: 2.8750303265941435

Epoch: 6| Step: 10
Training loss: 2.969483295024357
Validation loss: 2.861143583177243

Epoch: 6| Step: 11
Training loss: 3.6869856912176444
Validation loss: 2.8547768949107377

Epoch: 6| Step: 12
Training loss: 2.9536339053901575
Validation loss: 2.8548447510277812

Epoch: 6| Step: 13
Training loss: 1.9297899844488207
Validation loss: 2.851057162525181

Epoch: 139| Step: 0
Training loss: 2.909841963419181
Validation loss: 2.8496923013934135

Epoch: 6| Step: 1
Training loss: 3.5948245888308503
Validation loss: 2.8530484649748056

Epoch: 6| Step: 2
Training loss: 3.449685157010001
Validation loss: 2.8525678987598595

Epoch: 6| Step: 3
Training loss: 2.917659227329554
Validation loss: 2.851345050481173

Epoch: 6| Step: 4
Training loss: 2.811040881271854
Validation loss: 2.852223009273544

Epoch: 6| Step: 5
Training loss: 3.2924902807047367
Validation loss: 2.850282767084388

Epoch: 6| Step: 6
Training loss: 2.769650993394948
Validation loss: 2.8520873747157394

Epoch: 6| Step: 7
Training loss: 2.9277105960300185
Validation loss: 2.8532477491590016

Epoch: 6| Step: 8
Training loss: 2.796514647728003
Validation loss: 2.853263737906317

Epoch: 6| Step: 9
Training loss: 3.641165631800224
Validation loss: 2.8564796333365146

Epoch: 6| Step: 10
Training loss: 3.723811319646006
Validation loss: 2.8568181374163037

Epoch: 6| Step: 11
Training loss: 2.889256333759677
Validation loss: 2.8646350564323657

Epoch: 6| Step: 12
Training loss: 3.2756369400898584
Validation loss: 2.857053288763958

Epoch: 6| Step: 13
Training loss: 2.648760120467924
Validation loss: 2.8541880649392963

Epoch: 140| Step: 0
Training loss: 3.006509711770886
Validation loss: 2.8563709290787225

Epoch: 6| Step: 1
Training loss: 3.3433385578037362
Validation loss: 2.8534815182755695

Epoch: 6| Step: 2
Training loss: 3.349269126760595
Validation loss: 2.854461604982049

Epoch: 6| Step: 3
Training loss: 2.570267418926942
Validation loss: 2.8574157651526773

Epoch: 6| Step: 4
Training loss: 2.957214914158751
Validation loss: 2.860619193431614

Epoch: 6| Step: 5
Training loss: 3.150173872735725
Validation loss: 2.857664173296971

Epoch: 6| Step: 6
Training loss: 2.260463755127392
Validation loss: 2.859776851990713

Epoch: 6| Step: 7
Training loss: 2.912475481052909
Validation loss: 2.8580745037267956

Epoch: 6| Step: 8
Training loss: 3.741361459179974
Validation loss: 2.8569329086308692

Epoch: 6| Step: 9
Training loss: 3.2770671523160115
Validation loss: 2.8503569226369647

Epoch: 6| Step: 10
Training loss: 3.1186795213338465
Validation loss: 2.8525010804427935

Epoch: 6| Step: 11
Training loss: 3.303268236069955
Validation loss: 2.852583067202169

Epoch: 6| Step: 12
Training loss: 3.010392625618123
Validation loss: 2.8507425655235927

Epoch: 6| Step: 13
Training loss: 4.083562623936761
Validation loss: 2.850700366088024

Epoch: 141| Step: 0
Training loss: 3.3070965726886277
Validation loss: 2.8519869221209695

Epoch: 6| Step: 1
Training loss: 3.5420001303071267
Validation loss: 2.849324270010586

Epoch: 6| Step: 2
Training loss: 2.718721937714369
Validation loss: 2.849719989768091

Epoch: 6| Step: 3
Training loss: 2.738677470971809
Validation loss: 2.850010889461074

Epoch: 6| Step: 4
Training loss: 2.965473012777921
Validation loss: 2.8488134672882897

Epoch: 6| Step: 5
Training loss: 3.424954913879798
Validation loss: 2.8484751216636033

Epoch: 6| Step: 6
Training loss: 3.033007869097736
Validation loss: 2.8501048463319

Epoch: 6| Step: 7
Training loss: 3.351028506547919
Validation loss: 2.8493253263008724

Epoch: 6| Step: 8
Training loss: 2.7302082685179245
Validation loss: 2.852597883271942

Epoch: 6| Step: 9
Training loss: 3.688892554149824
Validation loss: 2.8486495048118283

Epoch: 6| Step: 10
Training loss: 2.5609125942580873
Validation loss: 2.84967752959215

Epoch: 6| Step: 11
Training loss: 3.199533523891852
Validation loss: 2.8467904863458067

Epoch: 6| Step: 12
Training loss: 2.8677030094724087
Validation loss: 2.8483669282591264

Epoch: 6| Step: 13
Training loss: 3.937272201488086
Validation loss: 2.8464750467220004

Epoch: 142| Step: 0
Training loss: 2.9387060084066277
Validation loss: 2.846464350737356

Epoch: 6| Step: 1
Training loss: 3.226988683453161
Validation loss: 2.847293210055479

Epoch: 6| Step: 2
Training loss: 3.03338264872388
Validation loss: 2.8448155572774314

Epoch: 6| Step: 3
Training loss: 2.761725570044399
Validation loss: 2.843895224336444

Epoch: 6| Step: 4
Training loss: 3.248378349084926
Validation loss: 2.845084386533151

Epoch: 6| Step: 5
Training loss: 3.326510185378625
Validation loss: 2.8452740173139546

Epoch: 6| Step: 6
Training loss: 2.9221530720789004
Validation loss: 2.842250328025969

Epoch: 6| Step: 7
Training loss: 3.826278801865396
Validation loss: 2.8467964388902476

Epoch: 6| Step: 8
Training loss: 4.053672707638629
Validation loss: 2.8461568807352475

Epoch: 6| Step: 9
Training loss: 2.744049570330972
Validation loss: 2.847046888348418

Epoch: 6| Step: 10
Training loss: 2.9611082002658464
Validation loss: 2.8472706176769322

Epoch: 6| Step: 11
Training loss: 2.967217943498379
Validation loss: 2.8427120704917757

Epoch: 6| Step: 12
Training loss: 2.3203001696326417
Validation loss: 2.8447424792825933

Epoch: 6| Step: 13
Training loss: 3.3261573956947768
Validation loss: 2.8462707641212517

Epoch: 143| Step: 0
Training loss: 2.733424430197511
Validation loss: 2.8422039372348706

Epoch: 6| Step: 1
Training loss: 3.098472612713929
Validation loss: 2.843047720507258

Epoch: 6| Step: 2
Training loss: 3.1259782404419894
Validation loss: 2.8430904329867457

Epoch: 6| Step: 3
Training loss: 2.6108353234689456
Validation loss: 2.847716309537658

Epoch: 6| Step: 4
Training loss: 2.220907747072872
Validation loss: 2.845028030805578

Epoch: 6| Step: 5
Training loss: 3.3272268310125424
Validation loss: 2.84740110662929

Epoch: 6| Step: 6
Training loss: 3.618859977566339
Validation loss: 2.84697109955457

Epoch: 6| Step: 7
Training loss: 3.3126050824465896
Validation loss: 2.847139232222035

Epoch: 6| Step: 8
Training loss: 3.628706122753009
Validation loss: 2.8493057047901362

Epoch: 6| Step: 9
Training loss: 3.186578205934482
Validation loss: 2.8452660631235926

Epoch: 6| Step: 10
Training loss: 3.234121708926461
Validation loss: 2.8482910476807346

Epoch: 6| Step: 11
Training loss: 3.2609757176688063
Validation loss: 2.844158011267659

Epoch: 6| Step: 12
Training loss: 2.8908222852862164
Validation loss: 2.8440636037414504

Epoch: 6| Step: 13
Training loss: 3.546574382394019
Validation loss: 2.8437617654522094

Epoch: 144| Step: 0
Training loss: 3.276547504585381
Validation loss: 2.8425303046209716

Epoch: 6| Step: 1
Training loss: 2.5293707759474087
Validation loss: 2.841417008548989

Epoch: 6| Step: 2
Training loss: 3.600227820287376
Validation loss: 2.839410185933649

Epoch: 6| Step: 3
Training loss: 3.0655102629582314
Validation loss: 2.8364764652038184

Epoch: 6| Step: 4
Training loss: 3.5229283406887415
Validation loss: 2.8370674847369646

Epoch: 6| Step: 5
Training loss: 2.980661528466094
Validation loss: 2.839843182176464

Epoch: 6| Step: 6
Training loss: 2.529721210483676
Validation loss: 2.841965541098901

Epoch: 6| Step: 7
Training loss: 3.0063189080285575
Validation loss: 2.8359304642878884

Epoch: 6| Step: 8
Training loss: 3.2694535149342494
Validation loss: 2.842612171316848

Epoch: 6| Step: 9
Training loss: 3.3517588311158204
Validation loss: 2.836787281673792

Epoch: 6| Step: 10
Training loss: 2.8358591452459
Validation loss: 2.8381786110118052

Epoch: 6| Step: 11
Training loss: 3.7532847958865583
Validation loss: 2.8384364087241245

Epoch: 6| Step: 12
Training loss: 2.5786382915581987
Validation loss: 2.8363780311704723

Epoch: 6| Step: 13
Training loss: 3.4554987554866696
Validation loss: 2.8395779961768537

Epoch: 145| Step: 0
Training loss: 3.5780313138065973
Validation loss: 2.8378063112283236

Epoch: 6| Step: 1
Training loss: 3.0548951061365544
Validation loss: 2.8416847826258422

Epoch: 6| Step: 2
Training loss: 3.4903961297855957
Validation loss: 2.8560966330072

Epoch: 6| Step: 3
Training loss: 3.1647485813360983
Validation loss: 2.8747803228270246

Epoch: 6| Step: 4
Training loss: 2.888856914131385
Validation loss: 2.90528772543812

Epoch: 6| Step: 5
Training loss: 3.029805261881819
Validation loss: 2.918223097312208

Epoch: 6| Step: 6
Training loss: 3.2087579091193428
Validation loss: 2.8983487948523625

Epoch: 6| Step: 7
Training loss: 3.0515979645636646
Validation loss: 2.880038356403102

Epoch: 6| Step: 8
Training loss: 2.7231922908135924
Validation loss: 2.8565900206601853

Epoch: 6| Step: 9
Training loss: 3.539944907153035
Validation loss: 2.839135566862137

Epoch: 6| Step: 10
Training loss: 3.2413193608993267
Validation loss: 2.838500565028746

Epoch: 6| Step: 11
Training loss: 3.1742329970126217
Validation loss: 2.8451847206098106

Epoch: 6| Step: 12
Training loss: 2.66456702145099
Validation loss: 2.852682777167056

Epoch: 6| Step: 13
Training loss: 3.106890428558883
Validation loss: 2.854313242967229

Epoch: 146| Step: 0
Training loss: 3.775929640938813
Validation loss: 2.8469796216848664

Epoch: 6| Step: 1
Training loss: 3.0982514587659935
Validation loss: 2.845466161739714

Epoch: 6| Step: 2
Training loss: 3.56149706191392
Validation loss: 2.842871318238784

Epoch: 6| Step: 3
Training loss: 2.464020847120898
Validation loss: 2.8429806964731936

Epoch: 6| Step: 4
Training loss: 3.3799676011016837
Validation loss: 2.8407944036250328

Epoch: 6| Step: 5
Training loss: 3.4363351408789353
Validation loss: 2.8402756457640006

Epoch: 6| Step: 6
Training loss: 2.8025989459875955
Validation loss: 2.838514143212103

Epoch: 6| Step: 7
Training loss: 2.214522188717582
Validation loss: 2.839578086459304

Epoch: 6| Step: 8
Training loss: 2.9698522830282
Validation loss: 2.838305042463464

Epoch: 6| Step: 9
Training loss: 3.188542513435465
Validation loss: 2.8382196914187428

Epoch: 6| Step: 10
Training loss: 3.63980748243864
Validation loss: 2.83804507390307

Epoch: 6| Step: 11
Training loss: 3.350104310418712
Validation loss: 2.8372405911133476

Epoch: 6| Step: 12
Training loss: 3.037129942404233
Validation loss: 2.8388795014708834

Epoch: 6| Step: 13
Training loss: 2.07357082556346
Validation loss: 2.841508177555827

Epoch: 147| Step: 0
Training loss: 3.1756348523394604
Validation loss: 2.8392676441227276

Epoch: 6| Step: 1
Training loss: 3.0762713897593867
Validation loss: 2.8416843694387417

Epoch: 6| Step: 2
Training loss: 2.972013105679312
Validation loss: 2.8535000877723555

Epoch: 6| Step: 3
Training loss: 3.4896837514216847
Validation loss: 2.849503808543437

Epoch: 6| Step: 4
Training loss: 2.8813694596091897
Validation loss: 2.8517368489793764

Epoch: 6| Step: 5
Training loss: 3.701058499252961
Validation loss: 2.85652506264464

Epoch: 6| Step: 6
Training loss: 2.9006993601464632
Validation loss: 2.8568297727725604

Epoch: 6| Step: 7
Training loss: 2.82489773725566
Validation loss: 2.851617496739477

Epoch: 6| Step: 8
Training loss: 3.016258528974405
Validation loss: 2.8447521886384566

Epoch: 6| Step: 9
Training loss: 3.3965840514233987
Validation loss: 2.836569905141883

Epoch: 6| Step: 10
Training loss: 3.7187079419234066
Validation loss: 2.8334326162683765

Epoch: 6| Step: 11
Training loss: 1.8802285092047115
Validation loss: 2.832450483647592

Epoch: 6| Step: 12
Training loss: 3.4589077269528627
Validation loss: 2.835443012280039

Epoch: 6| Step: 13
Training loss: 2.908841362187621
Validation loss: 2.8336470036419272

Epoch: 148| Step: 0
Training loss: 2.948754361203192
Validation loss: 2.8359610504796997

Epoch: 6| Step: 1
Training loss: 2.6559988464100184
Validation loss: 2.8349914618090444

Epoch: 6| Step: 2
Training loss: 2.830678556259468
Validation loss: 2.833707631509639

Epoch: 6| Step: 3
Training loss: 2.192387597433531
Validation loss: 2.8354244845595686

Epoch: 6| Step: 4
Training loss: 3.2119983860358605
Validation loss: 2.836334915720514

Epoch: 6| Step: 5
Training loss: 3.022318157219228
Validation loss: 2.8347491319731546

Epoch: 6| Step: 6
Training loss: 2.121756378139071
Validation loss: 2.8335071567102577

Epoch: 6| Step: 7
Training loss: 3.8106310906970786
Validation loss: 2.8354043215569646

Epoch: 6| Step: 8
Training loss: 3.3841273899675115
Validation loss: 2.8358451041518653

Epoch: 6| Step: 9
Training loss: 3.8282271391029625
Validation loss: 2.8363685082638708

Epoch: 6| Step: 10
Training loss: 2.811260713291406
Validation loss: 2.8331797173301467

Epoch: 6| Step: 11
Training loss: 3.5846664403350497
Validation loss: 2.833603189804719

Epoch: 6| Step: 12
Training loss: 3.04458485145752
Validation loss: 2.8307119913260603

Epoch: 6| Step: 13
Training loss: 4.261284153052532
Validation loss: 2.842557539668883

Epoch: 149| Step: 0
Training loss: 2.421326507478215
Validation loss: 2.8475932011568665

Epoch: 6| Step: 1
Training loss: 3.408803839879088
Validation loss: 2.87590018113048

Epoch: 6| Step: 2
Training loss: 3.066178584303244
Validation loss: 2.865533709938628

Epoch: 6| Step: 3
Training loss: 3.1693852617371867
Validation loss: 2.862361732163827

Epoch: 6| Step: 4
Training loss: 3.486112289800018
Validation loss: 2.8538003759373085

Epoch: 6| Step: 5
Training loss: 3.455910504241983
Validation loss: 2.85492504425698

Epoch: 6| Step: 6
Training loss: 3.2683971265616583
Validation loss: 2.8399492882787074

Epoch: 6| Step: 7
Training loss: 2.8761421920154446
Validation loss: 2.835080121962989

Epoch: 6| Step: 8
Training loss: 3.067412504084647
Validation loss: 2.8334001778155744

Epoch: 6| Step: 9
Training loss: 3.1741739595235456
Validation loss: 2.8340256446564287

Epoch: 6| Step: 10
Training loss: 3.0131362369804955
Validation loss: 2.8293398301860866

Epoch: 6| Step: 11
Training loss: 2.5910422657471615
Validation loss: 2.8288559096899157

Epoch: 6| Step: 12
Training loss: 3.258910069721056
Validation loss: 2.8315431982654555

Epoch: 6| Step: 13
Training loss: 3.57708005347719
Validation loss: 2.828271231493578

Epoch: 150| Step: 0
Training loss: 3.291210931704721
Validation loss: 2.8294174856883108

Epoch: 6| Step: 1
Training loss: 2.9578593416127186
Validation loss: 2.831241018492064

Epoch: 6| Step: 2
Training loss: 3.1845474031777163
Validation loss: 2.8301587503884518

Epoch: 6| Step: 3
Training loss: 3.133206083541023
Validation loss: 2.822191287256508

Epoch: 6| Step: 4
Training loss: 2.9838478461636035
Validation loss: 2.826094588416447

Epoch: 6| Step: 5
Training loss: 3.1731976537255564
Validation loss: 2.826964239918468

Epoch: 6| Step: 6
Training loss: 3.8099041215341893
Validation loss: 2.826772359662504

Epoch: 6| Step: 7
Training loss: 2.7948803315450683
Validation loss: 2.827898058898604

Epoch: 6| Step: 8
Training loss: 2.968504564278878
Validation loss: 2.8248567081474922

Epoch: 6| Step: 9
Training loss: 2.617895412072416
Validation loss: 2.8271642192950046

Epoch: 6| Step: 10
Training loss: 3.568389575080879
Validation loss: 2.8275007629669133

Epoch: 6| Step: 11
Training loss: 3.3303957074553927
Validation loss: 2.826099098672799

Epoch: 6| Step: 12
Training loss: 2.6109961310788625
Validation loss: 2.8285599956832748

Epoch: 6| Step: 13
Training loss: 3.0841453273488133
Validation loss: 2.830865895493975

Epoch: 151| Step: 0
Training loss: 3.2133580943165314
Validation loss: 2.8274004777592965

Epoch: 6| Step: 1
Training loss: 3.448167928124568
Validation loss: 2.831376238284561

Epoch: 6| Step: 2
Training loss: 2.679356501742113
Validation loss: 2.830840790256406

Epoch: 6| Step: 3
Training loss: 2.7585730868170377
Validation loss: 2.8296784235503964

Epoch: 6| Step: 4
Training loss: 3.8124480947494472
Validation loss: 2.82577962917421

Epoch: 6| Step: 5
Training loss: 2.8502547100086106
Validation loss: 2.8306659131767287

Epoch: 6| Step: 6
Training loss: 4.133444494372886
Validation loss: 2.8279796856029034

Epoch: 6| Step: 7
Training loss: 2.266381499172741
Validation loss: 2.8282670129475336

Epoch: 6| Step: 8
Training loss: 3.4160142291127795
Validation loss: 2.82641298285931

Epoch: 6| Step: 9
Training loss: 3.156652896962518
Validation loss: 2.8282540400179075

Epoch: 6| Step: 10
Training loss: 2.7320399313950485
Validation loss: 2.83297610850969

Epoch: 6| Step: 11
Training loss: 2.7468731182556305
Validation loss: 2.829742320000204

Epoch: 6| Step: 12
Training loss: 3.0053774005442557
Validation loss: 2.832601154652343

Epoch: 6| Step: 13
Training loss: 2.974706196101558
Validation loss: 2.8393136187941588

Epoch: 152| Step: 0
Training loss: 3.4507370368831767
Validation loss: 2.8416258748908887

Epoch: 6| Step: 1
Training loss: 3.1260810508056336
Validation loss: 2.84735491410328

Epoch: 6| Step: 2
Training loss: 2.5798348969852944
Validation loss: 2.8536150418486

Epoch: 6| Step: 3
Training loss: 3.3656199052324047
Validation loss: 2.846123610895277

Epoch: 6| Step: 4
Training loss: 3.2314882526328788
Validation loss: 2.853816538557542

Epoch: 6| Step: 5
Training loss: 3.4898908944550393
Validation loss: 2.845104377761385

Epoch: 6| Step: 6
Training loss: 3.1988219596159597
Validation loss: 2.843579537467295

Epoch: 6| Step: 7
Training loss: 2.9732153789006026
Validation loss: 2.830887294811883

Epoch: 6| Step: 8
Training loss: 3.2746946702105633
Validation loss: 2.8311252139017506

Epoch: 6| Step: 9
Training loss: 3.228708804905608
Validation loss: 2.824241578521258

Epoch: 6| Step: 10
Training loss: 2.723610840630495
Validation loss: 2.8228642624141664

Epoch: 6| Step: 11
Training loss: 3.247745318702094
Validation loss: 2.820993127209532

Epoch: 6| Step: 12
Training loss: 2.436700151720464
Validation loss: 2.8248777418790896

Epoch: 6| Step: 13
Training loss: 3.246756622535635
Validation loss: 2.8221555847137045

Epoch: 153| Step: 0
Training loss: 3.8972677490253056
Validation loss: 2.8243608141292293

Epoch: 6| Step: 1
Training loss: 3.134442521315967
Validation loss: 2.8234675397815687

Epoch: 6| Step: 2
Training loss: 3.516355311514871
Validation loss: 2.822450393536861

Epoch: 6| Step: 3
Training loss: 2.996483171960308
Validation loss: 2.8227708292465397

Epoch: 6| Step: 4
Training loss: 3.007146905353308
Validation loss: 2.823306646398044

Epoch: 6| Step: 5
Training loss: 2.107030625390967
Validation loss: 2.8229100873922164

Epoch: 6| Step: 6
Training loss: 2.8432402101437235
Validation loss: 2.822435198492252

Epoch: 6| Step: 7
Training loss: 2.822091933452802
Validation loss: 2.820221881162251

Epoch: 6| Step: 8
Training loss: 3.4655850379779376
Validation loss: 2.820408344273578

Epoch: 6| Step: 9
Training loss: 3.2327225006541083
Validation loss: 2.824730573259283

Epoch: 6| Step: 10
Training loss: 2.9970594936062467
Validation loss: 2.8220895879151557

Epoch: 6| Step: 11
Training loss: 3.1348258609866892
Validation loss: 2.823014888379791

Epoch: 6| Step: 12
Training loss: 3.0199503342542413
Validation loss: 2.822001651557295

Epoch: 6| Step: 13
Training loss: 3.368488387953177
Validation loss: 2.820723966888378

Epoch: 154| Step: 0
Training loss: 3.150512163214731
Validation loss: 2.82432628543679

Epoch: 6| Step: 1
Training loss: 3.2929710668734438
Validation loss: 2.820426243472929

Epoch: 6| Step: 2
Training loss: 3.8884342260852014
Validation loss: 2.8244656103013805

Epoch: 6| Step: 3
Training loss: 2.4824330159319237
Validation loss: 2.8298174604444073

Epoch: 6| Step: 4
Training loss: 3.3189427321626086
Validation loss: 2.8279596213641955

Epoch: 6| Step: 5
Training loss: 2.724812117932803
Validation loss: 2.825219849955897

Epoch: 6| Step: 6
Training loss: 3.1753918924046403
Validation loss: 2.8320435719686983

Epoch: 6| Step: 7
Training loss: 2.90780696386664
Validation loss: 2.8331269352514212

Epoch: 6| Step: 8
Training loss: 3.4566343952562097
Validation loss: 2.83054695675401

Epoch: 6| Step: 9
Training loss: 3.493138262808345
Validation loss: 2.824275858627384

Epoch: 6| Step: 10
Training loss: 2.3772526147218054
Validation loss: 2.8243199224534505

Epoch: 6| Step: 11
Training loss: 2.965159604181786
Validation loss: 2.8193017864670518

Epoch: 6| Step: 12
Training loss: 3.2522730581173014
Validation loss: 2.8165327613234603

Epoch: 6| Step: 13
Training loss: 2.7200529988118274
Validation loss: 2.8216323943212713

Epoch: 155| Step: 0
Training loss: 2.908789396916737
Validation loss: 2.8214825531916907

Epoch: 6| Step: 1
Training loss: 3.0005073118421106
Validation loss: 2.825379320531379

Epoch: 6| Step: 2
Training loss: 3.160482307277137
Validation loss: 2.8270945779700405

Epoch: 6| Step: 3
Training loss: 3.0139585644177895
Validation loss: 2.8303491112542414

Epoch: 6| Step: 4
Training loss: 2.3897132880324836
Validation loss: 2.833054789134629

Epoch: 6| Step: 5
Training loss: 3.5982861624931863
Validation loss: 2.826346129441612

Epoch: 6| Step: 6
Training loss: 3.3836902774631765
Validation loss: 2.8220801112691527

Epoch: 6| Step: 7
Training loss: 3.2675725796613135
Validation loss: 2.8224868580403144

Epoch: 6| Step: 8
Training loss: 3.891691865914314
Validation loss: 2.8216726825974323

Epoch: 6| Step: 9
Training loss: 2.6202407563225463
Validation loss: 2.8229440113279978

Epoch: 6| Step: 10
Training loss: 2.53999391344798
Validation loss: 2.8204345585813337

Epoch: 6| Step: 11
Training loss: 2.826475642500339
Validation loss: 2.82126681799801

Epoch: 6| Step: 12
Training loss: 3.575628617512727
Validation loss: 2.8188477512889927

Epoch: 6| Step: 13
Training loss: 3.1215005736013652
Validation loss: 2.8176676702307106

Epoch: 156| Step: 0
Training loss: 3.0567682306630988
Validation loss: 2.822462938084044

Epoch: 6| Step: 1
Training loss: 2.7149709109158318
Validation loss: 2.817091292756462

Epoch: 6| Step: 2
Training loss: 2.551840966581888
Validation loss: 2.8195484189756796

Epoch: 6| Step: 3
Training loss: 3.3940635859434405
Validation loss: 2.8159196489116503

Epoch: 6| Step: 4
Training loss: 2.733239510329308
Validation loss: 2.8151518813014897

Epoch: 6| Step: 5
Training loss: 3.2914060819468713
Validation loss: 2.8153061826101613

Epoch: 6| Step: 6
Training loss: 3.0367451047624705
Validation loss: 2.8136601679217286

Epoch: 6| Step: 7
Training loss: 3.159897311509839
Validation loss: 2.8114469993007924

Epoch: 6| Step: 8
Training loss: 3.0933458468852755
Validation loss: 2.813217705927887

Epoch: 6| Step: 9
Training loss: 2.6624147571654504
Validation loss: 2.810874472861848

Epoch: 6| Step: 10
Training loss: 3.5353056986711406
Validation loss: 2.8104157594851285

Epoch: 6| Step: 11
Training loss: 3.4937445734353823
Validation loss: 2.8133141928589667

Epoch: 6| Step: 12
Training loss: 3.1180476863755175
Validation loss: 2.8135709913341045

Epoch: 6| Step: 13
Training loss: 3.777646956952445
Validation loss: 2.811434805908235

Epoch: 157| Step: 0
Training loss: 3.8930404089989397
Validation loss: 2.8195922120850514

Epoch: 6| Step: 1
Training loss: 3.0729743736581447
Validation loss: 2.8240323206086675

Epoch: 6| Step: 2
Training loss: 2.118878129443811
Validation loss: 2.814143038411731

Epoch: 6| Step: 3
Training loss: 3.44526378225193
Validation loss: 2.8145311939727087

Epoch: 6| Step: 4
Training loss: 3.505892697656748
Validation loss: 2.816091017403131

Epoch: 6| Step: 5
Training loss: 2.581734090490627
Validation loss: 2.8120993024540715

Epoch: 6| Step: 6
Training loss: 3.081028222697354
Validation loss: 2.8152642597219617

Epoch: 6| Step: 7
Training loss: 3.015507987326656
Validation loss: 2.814697204031804

Epoch: 6| Step: 8
Training loss: 2.6273731222107433
Validation loss: 2.8121716288265324

Epoch: 6| Step: 9
Training loss: 2.853719318908368
Validation loss: 2.813102374178791

Epoch: 6| Step: 10
Training loss: 3.090844687897564
Validation loss: 2.8108000563990507

Epoch: 6| Step: 11
Training loss: 3.7563089070961384
Validation loss: 2.8161352402482707

Epoch: 6| Step: 12
Training loss: 3.270206723459567
Validation loss: 2.81702084545958

Epoch: 6| Step: 13
Training loss: 2.4943633431908037
Validation loss: 2.81469184302774

Epoch: 158| Step: 0
Training loss: 2.49062956423084
Validation loss: 2.8078387611989837

Epoch: 6| Step: 1
Training loss: 3.223462996795748
Validation loss: 2.8095855926334603

Epoch: 6| Step: 2
Training loss: 3.264530564307501
Validation loss: 2.8128024541369268

Epoch: 6| Step: 3
Training loss: 2.985504096579564
Validation loss: 2.807795212989

Epoch: 6| Step: 4
Training loss: 3.094353511013738
Validation loss: 2.8098165182001456

Epoch: 6| Step: 5
Training loss: 3.0763915162162574
Validation loss: 2.8061092978817364

Epoch: 6| Step: 6
Training loss: 3.290687866190051
Validation loss: 2.809523557293838

Epoch: 6| Step: 7
Training loss: 2.8269901422383388
Validation loss: 2.8082359604416456

Epoch: 6| Step: 8
Training loss: 2.8174263089688303
Validation loss: 2.809928425736493

Epoch: 6| Step: 9
Training loss: 3.8789455876655854
Validation loss: 2.808903623218598

Epoch: 6| Step: 10
Training loss: 3.44672958053436
Validation loss: 2.808862789451721

Epoch: 6| Step: 11
Training loss: 3.5063612214806006
Validation loss: 2.8105137747019677

Epoch: 6| Step: 12
Training loss: 2.9287071927597768
Validation loss: 2.8114753214697985

Epoch: 6| Step: 13
Training loss: 1.957806157789134
Validation loss: 2.809540982002607

Epoch: 159| Step: 0
Training loss: 3.5528544971360456
Validation loss: 2.811818091925919

Epoch: 6| Step: 1
Training loss: 2.3353684156358003
Validation loss: 2.811963543153923

Epoch: 6| Step: 2
Training loss: 2.720634421243092
Validation loss: 2.814914174041511

Epoch: 6| Step: 3
Training loss: 3.673756478567729
Validation loss: 2.8134396458896007

Epoch: 6| Step: 4
Training loss: 3.2239239043254955
Validation loss: 2.8103879155783558

Epoch: 6| Step: 5
Training loss: 3.2023388898169998
Validation loss: 2.8125967758829393

Epoch: 6| Step: 6
Training loss: 2.8605235976986316
Validation loss: 2.8097344495974395

Epoch: 6| Step: 7
Training loss: 3.0636046616607078
Validation loss: 2.809170394393521

Epoch: 6| Step: 8
Training loss: 3.3933853656049666
Validation loss: 2.8095097769517134

Epoch: 6| Step: 9
Training loss: 2.2266616531513597
Validation loss: 2.814738802926827

Epoch: 6| Step: 10
Training loss: 3.749671413012933
Validation loss: 2.8136409655634003

Epoch: 6| Step: 11
Training loss: 2.9198725565442
Validation loss: 2.821929865114664

Epoch: 6| Step: 12
Training loss: 3.247145940143713
Validation loss: 2.817089245185785

Epoch: 6| Step: 13
Training loss: 2.822068954003843
Validation loss: 2.8144069591928047

Epoch: 160| Step: 0
Training loss: 2.5669364671799118
Validation loss: 2.8190739195537495

Epoch: 6| Step: 1
Training loss: 2.656080442514525
Validation loss: 2.814870605056488

Epoch: 6| Step: 2
Training loss: 3.77978853088315
Validation loss: 2.8188481250786843

Epoch: 6| Step: 3
Training loss: 2.752847930787588
Validation loss: 2.818482142137675

Epoch: 6| Step: 4
Training loss: 3.32400271725687
Validation loss: 2.817316397241354

Epoch: 6| Step: 5
Training loss: 2.8112136442243054
Validation loss: 2.811232316006083

Epoch: 6| Step: 6
Training loss: 3.085512233355671
Validation loss: 2.8085145830909317

Epoch: 6| Step: 7
Training loss: 2.433739230735083
Validation loss: 2.8003009861435286

Epoch: 6| Step: 8
Training loss: 3.3430068001183018
Validation loss: 2.8033872633065378

Epoch: 6| Step: 9
Training loss: 3.212029412976958
Validation loss: 2.7983550216781343

Epoch: 6| Step: 10
Training loss: 2.814821514345677
Validation loss: 2.801635214746119

Epoch: 6| Step: 11
Training loss: 3.2850890453236676
Validation loss: 2.8004273800770303

Epoch: 6| Step: 12
Training loss: 3.609177092703962
Validation loss: 2.80110697706384

Epoch: 6| Step: 13
Training loss: 3.757165928530993
Validation loss: 2.799804982339224

Epoch: 161| Step: 0
Training loss: 2.7054458092849574
Validation loss: 2.8019229635493326

Epoch: 6| Step: 1
Training loss: 3.653699588538797
Validation loss: 2.8017957632601953

Epoch: 6| Step: 2
Training loss: 3.6528108512306194
Validation loss: 2.802068500240901

Epoch: 6| Step: 3
Training loss: 3.0216317711098855
Validation loss: 2.8016954830529257

Epoch: 6| Step: 4
Training loss: 3.05721480854046
Validation loss: 2.800258939316542

Epoch: 6| Step: 5
Training loss: 3.1123771551317705
Validation loss: 2.8031431634259407

Epoch: 6| Step: 6
Training loss: 3.310455555064237
Validation loss: 2.8017875923062103

Epoch: 6| Step: 7
Training loss: 2.9884752796485223
Validation loss: 2.8016173098752986

Epoch: 6| Step: 8
Training loss: 3.3523645397244834
Validation loss: 2.8009450857148104

Epoch: 6| Step: 9
Training loss: 2.444913301393439
Validation loss: 2.797349824539509

Epoch: 6| Step: 10
Training loss: 3.1388711919445087
Validation loss: 2.800292402519284

Epoch: 6| Step: 11
Training loss: 3.0868559810456473
Validation loss: 2.800579721745549

Epoch: 6| Step: 12
Training loss: 2.689296388179734
Validation loss: 2.8114890675581274

Epoch: 6| Step: 13
Training loss: 2.98734730605632
Validation loss: 2.7990341299055714

Epoch: 162| Step: 0
Training loss: 2.9390016329443758
Validation loss: 2.800254526596909

Epoch: 6| Step: 1
Training loss: 2.6690475047898095
Validation loss: 2.797986856631318

Epoch: 6| Step: 2
Training loss: 2.729153776259714
Validation loss: 2.7994615798172653

Epoch: 6| Step: 3
Training loss: 2.8027571727078033
Validation loss: 2.7986775044514327

Epoch: 6| Step: 4
Training loss: 3.2138238635601626
Validation loss: 2.7961799682394846

Epoch: 6| Step: 5
Training loss: 2.8108983883726317
Validation loss: 2.798645474761957

Epoch: 6| Step: 6
Training loss: 3.3155319445294618
Validation loss: 2.796729110549048

Epoch: 6| Step: 7
Training loss: 3.138593785490149
Validation loss: 2.794079984685834

Epoch: 6| Step: 8
Training loss: 3.6201033570092562
Validation loss: 2.7940762980645046

Epoch: 6| Step: 9
Training loss: 3.306597651356164
Validation loss: 2.7977596572029215

Epoch: 6| Step: 10
Training loss: 3.116511909872157
Validation loss: 2.7995124535991454

Epoch: 6| Step: 11
Training loss: 3.337843625098814
Validation loss: 2.799005492254836

Epoch: 6| Step: 12
Training loss: 3.1072665786540288
Validation loss: 2.797688129335269

Epoch: 6| Step: 13
Training loss: 3.175664582872019
Validation loss: 2.7964682912068297

Epoch: 163| Step: 0
Training loss: 3.245058557954797
Validation loss: 2.7982598530824117

Epoch: 6| Step: 1
Training loss: 2.9339519744250113
Validation loss: 2.7941690309864766

Epoch: 6| Step: 2
Training loss: 3.2091647635505187
Validation loss: 2.795715093348993

Epoch: 6| Step: 3
Training loss: 2.84714615469531
Validation loss: 2.7942512448139016

Epoch: 6| Step: 4
Training loss: 3.2896498928056657
Validation loss: 2.7954892953475836

Epoch: 6| Step: 5
Training loss: 3.145151397020605
Validation loss: 2.7957896820920762

Epoch: 6| Step: 6
Training loss: 2.5648958124784773
Validation loss: 2.795589481342149

Epoch: 6| Step: 7
Training loss: 3.544954292422368
Validation loss: 2.796819176125091

Epoch: 6| Step: 8
Training loss: 3.105033872852678
Validation loss: 2.804537771849311

Epoch: 6| Step: 9
Training loss: 2.7649062779910314
Validation loss: 2.799368567985182

Epoch: 6| Step: 10
Training loss: 3.1173043671309966
Validation loss: 2.798254641986131

Epoch: 6| Step: 11
Training loss: 3.025213621809304
Validation loss: 2.793546760446779

Epoch: 6| Step: 12
Training loss: 2.9350691131824673
Validation loss: 2.793655756420446

Epoch: 6| Step: 13
Training loss: 3.778444116081974
Validation loss: 2.792363311456628

Epoch: 164| Step: 0
Training loss: 2.8163373412274826
Validation loss: 2.7970036742698334

Epoch: 6| Step: 1
Training loss: 2.623364256790069
Validation loss: 2.7964660186018664

Epoch: 6| Step: 2
Training loss: 3.3284744294169837
Validation loss: 2.798201121413477

Epoch: 6| Step: 3
Training loss: 2.800132857304219
Validation loss: 2.79479902920508

Epoch: 6| Step: 4
Training loss: 3.323360704432358
Validation loss: 2.792525847203532

Epoch: 6| Step: 5
Training loss: 3.378459146719801
Validation loss: 2.7923631223300958

Epoch: 6| Step: 6
Training loss: 2.957110102822904
Validation loss: 2.794287328661179

Epoch: 6| Step: 7
Training loss: 2.5513414407479513
Validation loss: 2.7948097701893233

Epoch: 6| Step: 8
Training loss: 3.2535574589848597
Validation loss: 2.7963121262211947

Epoch: 6| Step: 9
Training loss: 2.8668867987753175
Validation loss: 2.7978609086322814

Epoch: 6| Step: 10
Training loss: 3.0034274549339095
Validation loss: 2.795330090001037

Epoch: 6| Step: 11
Training loss: 3.5416018910187765
Validation loss: 2.7974293834733706

Epoch: 6| Step: 12
Training loss: 3.116582596676876
Validation loss: 2.7959070767926244

Epoch: 6| Step: 13
Training loss: 3.9069154706587965
Validation loss: 2.803299760868999

Epoch: 165| Step: 0
Training loss: 2.588332067302223
Validation loss: 2.795332071886994

Epoch: 6| Step: 1
Training loss: 3.049294161810878
Validation loss: 2.797875432643148

Epoch: 6| Step: 2
Training loss: 2.948062169738051
Validation loss: 2.799045536524404

Epoch: 6| Step: 3
Training loss: 2.7792999632142013
Validation loss: 2.808215899376628

Epoch: 6| Step: 4
Training loss: 3.364758245844494
Validation loss: 2.7958436183563906

Epoch: 6| Step: 5
Training loss: 3.7536868726952477
Validation loss: 2.7938510360886846

Epoch: 6| Step: 6
Training loss: 3.310730947592787
Validation loss: 2.788882602170393

Epoch: 6| Step: 7
Training loss: 2.7385238997060943
Validation loss: 2.789906487906249

Epoch: 6| Step: 8
Training loss: 3.1957792580085953
Validation loss: 2.7868728882873235

Epoch: 6| Step: 9
Training loss: 2.8308075885502277
Validation loss: 2.7883519412227433

Epoch: 6| Step: 10
Training loss: 3.3981525170112112
Validation loss: 2.7904802782018145

Epoch: 6| Step: 11
Training loss: 3.0841578506663936
Validation loss: 2.787962467735473

Epoch: 6| Step: 12
Training loss: 3.0415952665405523
Validation loss: 2.789514733090376

Epoch: 6| Step: 13
Training loss: 2.988032152352724
Validation loss: 2.7904885024768

Epoch: 166| Step: 0
Training loss: 2.7443992628616125
Validation loss: 2.7928304130703627

Epoch: 6| Step: 1
Training loss: 2.983909051281282
Validation loss: 2.792073101002407

Epoch: 6| Step: 2
Training loss: 3.05443960291275
Validation loss: 2.790425963569816

Epoch: 6| Step: 3
Training loss: 3.0034928651270576
Validation loss: 2.7888078957983264

Epoch: 6| Step: 4
Training loss: 3.24910107431851
Validation loss: 2.7920367755170337

Epoch: 6| Step: 5
Training loss: 3.0460185094259726
Validation loss: 2.7890767435222763

Epoch: 6| Step: 6
Training loss: 4.150145213332667
Validation loss: 2.7906071233717094

Epoch: 6| Step: 7
Training loss: 2.8125932466096164
Validation loss: 2.791327513907197

Epoch: 6| Step: 8
Training loss: 2.3033953649041163
Validation loss: 2.790171146581003

Epoch: 6| Step: 9
Training loss: 2.930697417077353
Validation loss: 2.7881540126545077

Epoch: 6| Step: 10
Training loss: 3.216117893772028
Validation loss: 2.787505916407265

Epoch: 6| Step: 11
Training loss: 3.290508758723391
Validation loss: 2.788829963475952

Epoch: 6| Step: 12
Training loss: 3.517862786059594
Validation loss: 2.790023184644801

Epoch: 6| Step: 13
Training loss: 2.3219538063034713
Validation loss: 2.788449823646443

Epoch: 167| Step: 0
Training loss: 2.746929274924414
Validation loss: 2.7852617462510874

Epoch: 6| Step: 1
Training loss: 3.2395208583748465
Validation loss: 2.785545351511251

Epoch: 6| Step: 2
Training loss: 2.6027328104183067
Validation loss: 2.7842566938188105

Epoch: 6| Step: 3
Training loss: 2.5758420141594827
Validation loss: 2.7891039591467326

Epoch: 6| Step: 4
Training loss: 3.252210598853782
Validation loss: 2.7859783640549662

Epoch: 6| Step: 5
Training loss: 3.385181187974292
Validation loss: 2.787209312636973

Epoch: 6| Step: 6
Training loss: 2.875157227570686
Validation loss: 2.7865202403022367

Epoch: 6| Step: 7
Training loss: 2.7761243243672036
Validation loss: 2.7876727468153777

Epoch: 6| Step: 8
Training loss: 3.490149122839625
Validation loss: 2.789230500177854

Epoch: 6| Step: 9
Training loss: 3.4615626750001365
Validation loss: 2.78858118685929

Epoch: 6| Step: 10
Training loss: 3.274450031723481
Validation loss: 2.7860322004062383

Epoch: 6| Step: 11
Training loss: 3.108885146617417
Validation loss: 2.787656051716746

Epoch: 6| Step: 12
Training loss: 2.6751836624554683
Validation loss: 2.7836668485491165

Epoch: 6| Step: 13
Training loss: 3.938096258642491
Validation loss: 2.7885346405334137

Epoch: 168| Step: 0
Training loss: 2.52440376796136
Validation loss: 2.7881178862093146

Epoch: 6| Step: 1
Training loss: 3.7933554329476995
Validation loss: 2.78454359984653

Epoch: 6| Step: 2
Training loss: 2.9738657993188595
Validation loss: 2.7866744204436515

Epoch: 6| Step: 3
Training loss: 2.9337075283777945
Validation loss: 2.7877040197381238

Epoch: 6| Step: 4
Training loss: 2.6891414154194315
Validation loss: 2.7955676889459755

Epoch: 6| Step: 5
Training loss: 3.0026926036999613
Validation loss: 2.791953269732795

Epoch: 6| Step: 6
Training loss: 2.868059820788283
Validation loss: 2.7927845195461014

Epoch: 6| Step: 7
Training loss: 3.667289305331531
Validation loss: 2.7943814408123466

Epoch: 6| Step: 8
Training loss: 2.98036955622124
Validation loss: 2.8002065593365724

Epoch: 6| Step: 9
Training loss: 2.3500955765138576
Validation loss: 2.8053556326219824

Epoch: 6| Step: 10
Training loss: 3.1973834426788104
Validation loss: 2.8001330532303066

Epoch: 6| Step: 11
Training loss: 3.7745439317081764
Validation loss: 2.799139993338888

Epoch: 6| Step: 12
Training loss: 3.24623226967348
Validation loss: 2.7938454203646335

Epoch: 6| Step: 13
Training loss: 2.676753537140876
Validation loss: 2.7900205851887185

Epoch: 169| Step: 0
Training loss: 3.5694392031488062
Validation loss: 2.7881287140776956

Epoch: 6| Step: 1
Training loss: 3.8014212811412875
Validation loss: 2.7819739875740654

Epoch: 6| Step: 2
Training loss: 2.7396015896690504
Validation loss: 2.78302390960269

Epoch: 6| Step: 3
Training loss: 3.195447401262972
Validation loss: 2.781188355800038

Epoch: 6| Step: 4
Training loss: 3.016215212289757
Validation loss: 2.781374836473182

Epoch: 6| Step: 5
Training loss: 3.123953987534924
Validation loss: 2.779579969179082

Epoch: 6| Step: 6
Training loss: 2.534043360224004
Validation loss: 2.7790038037229667

Epoch: 6| Step: 7
Training loss: 2.779555243722505
Validation loss: 2.781059370136501

Epoch: 6| Step: 8
Training loss: 2.693255095368433
Validation loss: 2.779964240614295

Epoch: 6| Step: 9
Training loss: 2.9627956709611634
Validation loss: 2.7803228809518474

Epoch: 6| Step: 10
Training loss: 3.52905907645195
Validation loss: 2.7789331150734893

Epoch: 6| Step: 11
Training loss: 3.0912863429764093
Validation loss: 2.7830272562145524

Epoch: 6| Step: 12
Training loss: 3.239167279739917
Validation loss: 2.777314647774024

Epoch: 6| Step: 13
Training loss: 2.3226640390008253
Validation loss: 2.7795573152534576

Epoch: 170| Step: 0
Training loss: 2.472680933921027
Validation loss: 2.7796618969682068

Epoch: 6| Step: 1
Training loss: 3.0576009685971948
Validation loss: 2.7792098114058827

Epoch: 6| Step: 2
Training loss: 3.578153251969524
Validation loss: 2.7780838786091895

Epoch: 6| Step: 3
Training loss: 3.0319942858398057
Validation loss: 2.779881670654046

Epoch: 6| Step: 4
Training loss: 3.1251502954580697
Validation loss: 2.780883786152817

Epoch: 6| Step: 5
Training loss: 2.937819605545753
Validation loss: 2.781428496479328

Epoch: 6| Step: 6
Training loss: 2.9470442884086077
Validation loss: 2.780854533830494

Epoch: 6| Step: 7
Training loss: 2.540314820371026
Validation loss: 2.784215582366672

Epoch: 6| Step: 8
Training loss: 3.6676523155406144
Validation loss: 2.779413698978053

Epoch: 6| Step: 9
Training loss: 2.9258751236609215
Validation loss: 2.7805164803670652

Epoch: 6| Step: 10
Training loss: 3.3161274463656474
Validation loss: 2.779074619721602

Epoch: 6| Step: 11
Training loss: 3.2505557245355057
Validation loss: 2.7813155473131315

Epoch: 6| Step: 12
Training loss: 2.8526146188855224
Validation loss: 2.779390743002968

Epoch: 6| Step: 13
Training loss: 3.4123385548391587
Validation loss: 2.7764150403084997

Epoch: 171| Step: 0
Training loss: 3.6411357734172705
Validation loss: 2.776787705168044

Epoch: 6| Step: 1
Training loss: 3.398002228321335
Validation loss: 2.7753602913042177

Epoch: 6| Step: 2
Training loss: 2.515109560269431
Validation loss: 2.7763272556649543

Epoch: 6| Step: 3
Training loss: 3.1332549355891937
Validation loss: 2.7755427540277493

Epoch: 6| Step: 4
Training loss: 3.664693749553315
Validation loss: 2.7761922514298236

Epoch: 6| Step: 5
Training loss: 2.9731913221627018
Validation loss: 2.7796487838883133

Epoch: 6| Step: 6
Training loss: 2.7460641438826796
Validation loss: 2.778105498092881

Epoch: 6| Step: 7
Training loss: 3.5121928776498668
Validation loss: 2.7863069956480833

Epoch: 6| Step: 8
Training loss: 3.749402316464971
Validation loss: 2.788146535465835

Epoch: 6| Step: 9
Training loss: 2.6397890652572062
Validation loss: 2.778025638603788

Epoch: 6| Step: 10
Training loss: 2.561236558527977
Validation loss: 2.7927756741517964

Epoch: 6| Step: 11
Training loss: 2.7212269341083086
Validation loss: 2.790716894653874

Epoch: 6| Step: 12
Training loss: 2.7296546519180396
Validation loss: 2.778589618617551

Epoch: 6| Step: 13
Training loss: 2.705793089321136
Validation loss: 2.7826432133753918

Epoch: 172| Step: 0
Training loss: 2.957334717028162
Validation loss: 2.779475220203922

Epoch: 6| Step: 1
Training loss: 2.7375065772966076
Validation loss: 2.777501739267778

Epoch: 6| Step: 2
Training loss: 3.5804262715166475
Validation loss: 2.77575528509762

Epoch: 6| Step: 3
Training loss: 3.1284520728031255
Validation loss: 2.7750504924892416

Epoch: 6| Step: 4
Training loss: 3.8262935071912385
Validation loss: 2.7769352903437263

Epoch: 6| Step: 5
Training loss: 3.2126381632858507
Validation loss: 2.7750897673950545

Epoch: 6| Step: 6
Training loss: 2.6538008225650938
Validation loss: 2.7758657138835767

Epoch: 6| Step: 7
Training loss: 3.459983952655954
Validation loss: 2.776123067537434

Epoch: 6| Step: 8
Training loss: 2.786653391823186
Validation loss: 2.7743805200238154

Epoch: 6| Step: 9
Training loss: 2.9917348813184725
Validation loss: 2.773345083302714

Epoch: 6| Step: 10
Training loss: 3.0948532141171334
Validation loss: 2.7760410011397063

Epoch: 6| Step: 11
Training loss: 3.016705413344717
Validation loss: 2.773886542081139

Epoch: 6| Step: 12
Training loss: 2.7631071019105318
Validation loss: 2.77745161609584

Epoch: 6| Step: 13
Training loss: 2.318156258379262
Validation loss: 2.775008866801199

Epoch: 173| Step: 0
Training loss: 3.1682697722273234
Validation loss: 2.7746160960576547

Epoch: 6| Step: 1
Training loss: 3.408686894838817
Validation loss: 2.7783835326546225

Epoch: 6| Step: 2
Training loss: 3.349333192877959
Validation loss: 2.7774535304366026

Epoch: 6| Step: 3
Training loss: 3.4079679304145287
Validation loss: 2.773665978187443

Epoch: 6| Step: 4
Training loss: 2.956752587596367
Validation loss: 2.7755890998179606

Epoch: 6| Step: 5
Training loss: 2.3693015349763646
Validation loss: 2.773426789478706

Epoch: 6| Step: 6
Training loss: 2.3504893747043707
Validation loss: 2.7713553595119684

Epoch: 6| Step: 7
Training loss: 2.5274478943959893
Validation loss: 2.774200808607876

Epoch: 6| Step: 8
Training loss: 3.71009293432103
Validation loss: 2.7750341242397765

Epoch: 6| Step: 9
Training loss: 2.870103397965768
Validation loss: 2.771679781252035

Epoch: 6| Step: 10
Training loss: 3.1371623066486114
Validation loss: 2.775809769499954

Epoch: 6| Step: 11
Training loss: 3.180955039029497
Validation loss: 2.77454329426598

Epoch: 6| Step: 12
Training loss: 2.9976337955957124
Validation loss: 2.7777950243944307

Epoch: 6| Step: 13
Training loss: 3.5589803073270714
Validation loss: 2.7805788991745763

Epoch: 174| Step: 0
Training loss: 3.126862543093847
Validation loss: 2.77908313143113

Epoch: 6| Step: 1
Training loss: 2.1145234749375597
Validation loss: 2.789890327193108

Epoch: 6| Step: 2
Training loss: 2.887211614302235
Validation loss: 2.7763747998304296

Epoch: 6| Step: 3
Training loss: 2.4870121233023044
Validation loss: 2.7868028260848967

Epoch: 6| Step: 4
Training loss: 3.3700358298912754
Validation loss: 2.789583651946173

Epoch: 6| Step: 5
Training loss: 3.6857581469734226
Validation loss: 2.7800330218353686

Epoch: 6| Step: 6
Training loss: 3.3613113855081442
Validation loss: 2.7760552819218707

Epoch: 6| Step: 7
Training loss: 2.7351024422995653
Validation loss: 2.775613853216319

Epoch: 6| Step: 8
Training loss: 2.842330913899521
Validation loss: 2.7723062863792904

Epoch: 6| Step: 9
Training loss: 3.0947909674980187
Validation loss: 2.7706890606812773

Epoch: 6| Step: 10
Training loss: 3.2680853377631287
Validation loss: 2.772485068782645

Epoch: 6| Step: 11
Training loss: 2.987036352211602
Validation loss: 2.771269615355876

Epoch: 6| Step: 12
Training loss: 3.5149315722385737
Validation loss: 2.772115429435913

Epoch: 6| Step: 13
Training loss: 3.5094409043059023
Validation loss: 2.766389323471319

Epoch: 175| Step: 0
Training loss: 2.5424892366044562
Validation loss: 2.767744719039252

Epoch: 6| Step: 1
Training loss: 2.522248735115792
Validation loss: 2.7723780895105024

Epoch: 6| Step: 2
Training loss: 3.501107040804299
Validation loss: 2.7671336781960525

Epoch: 6| Step: 3
Training loss: 3.250813602432288
Validation loss: 2.7683963154273212

Epoch: 6| Step: 4
Training loss: 3.1851175417687196
Validation loss: 2.769760603913092

Epoch: 6| Step: 5
Training loss: 2.902711416294114
Validation loss: 2.7688403299355335

Epoch: 6| Step: 6
Training loss: 3.480382984615988
Validation loss: 2.770240595078347

Epoch: 6| Step: 7
Training loss: 3.0328028525936523
Validation loss: 2.767873580503491

Epoch: 6| Step: 8
Training loss: 3.4495718095954553
Validation loss: 2.7678731044299414

Epoch: 6| Step: 9
Training loss: 3.5624511447702005
Validation loss: 2.7687661698099593

Epoch: 6| Step: 10
Training loss: 3.3367452961145503
Validation loss: 2.7717299782776794

Epoch: 6| Step: 11
Training loss: 2.7074095886858722
Validation loss: 2.768871572979997

Epoch: 6| Step: 12
Training loss: 2.8151874841622693
Validation loss: 2.7705035383863605

Epoch: 6| Step: 13
Training loss: 1.8164468083929535
Validation loss: 2.7730374620981793

Epoch: 176| Step: 0
Training loss: 3.5818290362173824
Validation loss: 2.767945754714542

Epoch: 6| Step: 1
Training loss: 2.682540575842244
Validation loss: 2.773308090987627

Epoch: 6| Step: 2
Training loss: 3.015920673956243
Validation loss: 2.778145462503931

Epoch: 6| Step: 3
Training loss: 3.504805943753397
Validation loss: 2.7810382050317197

Epoch: 6| Step: 4
Training loss: 2.8228077509702976
Validation loss: 2.771874070351494

Epoch: 6| Step: 5
Training loss: 3.6987778784605942
Validation loss: 2.777128490804009

Epoch: 6| Step: 6
Training loss: 2.835600525563531
Validation loss: 2.7713703082700896

Epoch: 6| Step: 7
Training loss: 3.202587994476611
Validation loss: 2.7668068091101143

Epoch: 6| Step: 8
Training loss: 2.9190088586153355
Validation loss: 2.768928856534411

Epoch: 6| Step: 9
Training loss: 3.1816328316740035
Validation loss: 2.7663485998275648

Epoch: 6| Step: 10
Training loss: 3.0116934175328898
Validation loss: 2.769929000113675

Epoch: 6| Step: 11
Training loss: 3.058312180226805
Validation loss: 2.7638397285254603

Epoch: 6| Step: 12
Training loss: 2.687714146798335
Validation loss: 2.7683997797339175

Epoch: 6| Step: 13
Training loss: 2.286027165269018
Validation loss: 2.7694230957795924

Epoch: 177| Step: 0
Training loss: 3.761153355906987
Validation loss: 2.765925144607743

Epoch: 6| Step: 1
Training loss: 3.204161387928226
Validation loss: 2.7673714533863776

Epoch: 6| Step: 2
Training loss: 2.7485179375376667
Validation loss: 2.7647132795949436

Epoch: 6| Step: 3
Training loss: 3.709053283983358
Validation loss: 2.763274781925802

Epoch: 6| Step: 4
Training loss: 2.9041126554511894
Validation loss: 2.764868640545671

Epoch: 6| Step: 5
Training loss: 3.3592756389739016
Validation loss: 2.76034616174045

Epoch: 6| Step: 6
Training loss: 3.2940295627381473
Validation loss: 2.7628142897161

Epoch: 6| Step: 7
Training loss: 2.988598775511897
Validation loss: 2.7621381695014238

Epoch: 6| Step: 8
Training loss: 2.5303780266520794
Validation loss: 2.7637629269423627

Epoch: 6| Step: 9
Training loss: 2.947373698523823
Validation loss: 2.7630154883524845

Epoch: 6| Step: 10
Training loss: 3.1602415019113383
Validation loss: 2.772952322816442

Epoch: 6| Step: 11
Training loss: 2.399788938619531
Validation loss: 2.765109983442457

Epoch: 6| Step: 12
Training loss: 2.610106405668852
Validation loss: 2.774854080057545

Epoch: 6| Step: 13
Training loss: 3.132369849689551
Validation loss: 2.7706104743767193

Epoch: 178| Step: 0
Training loss: 3.3973909016117783
Validation loss: 2.76897518248081

Epoch: 6| Step: 1
Training loss: 2.2245929774349027
Validation loss: 2.7677151638994344

Epoch: 6| Step: 2
Training loss: 3.2208212697213203
Validation loss: 2.7656703356867034

Epoch: 6| Step: 3
Training loss: 3.451207245503523
Validation loss: 2.7775884705985523

Epoch: 6| Step: 4
Training loss: 3.2921533989283054
Validation loss: 2.7675259314621248

Epoch: 6| Step: 5
Training loss: 2.8164807440737603
Validation loss: 2.7659161762424733

Epoch: 6| Step: 6
Training loss: 3.0717513811417723
Validation loss: 2.768798803472818

Epoch: 6| Step: 7
Training loss: 3.5543754692204774
Validation loss: 2.764188825199001

Epoch: 6| Step: 8
Training loss: 2.8521527241266664
Validation loss: 2.762245588049046

Epoch: 6| Step: 9
Training loss: 2.2499782773134873
Validation loss: 2.7625852536883215

Epoch: 6| Step: 10
Training loss: 2.839045059410864
Validation loss: 2.7701729311222834

Epoch: 6| Step: 11
Training loss: 3.4791338037701474
Validation loss: 2.76524808287469

Epoch: 6| Step: 12
Training loss: 3.258140638918712
Validation loss: 2.761801146371024

Epoch: 6| Step: 13
Training loss: 2.7752468171200664
Validation loss: 2.7585121375161075

Epoch: 179| Step: 0
Training loss: 2.934422930731248
Validation loss: 2.7613849816767297

Epoch: 6| Step: 1
Training loss: 2.75849106521086
Validation loss: 2.7619250110681257

Epoch: 6| Step: 2
Training loss: 3.0594423561357678
Validation loss: 2.7595132945029

Epoch: 6| Step: 3
Training loss: 3.3093612483299917
Validation loss: 2.7621362547556223

Epoch: 6| Step: 4
Training loss: 2.7374857619102566
Validation loss: 2.7624705243880223

Epoch: 6| Step: 5
Training loss: 3.2875884823803574
Validation loss: 2.7618748446879513

Epoch: 6| Step: 6
Training loss: 2.587347378122645
Validation loss: 2.7603033994877584

Epoch: 6| Step: 7
Training loss: 3.0337077136839388
Validation loss: 2.761083997202098

Epoch: 6| Step: 8
Training loss: 3.480980284291197
Validation loss: 2.763323657456543

Epoch: 6| Step: 9
Training loss: 3.5845487145098662
Validation loss: 2.763304210605963

Epoch: 6| Step: 10
Training loss: 2.758734789289155
Validation loss: 2.7592923481865674

Epoch: 6| Step: 11
Training loss: 3.4695516124008416
Validation loss: 2.7591412585784325

Epoch: 6| Step: 12
Training loss: 2.8074512518899204
Validation loss: 2.7615689015674105

Epoch: 6| Step: 13
Training loss: 2.8641514308044367
Validation loss: 2.7604951933644215

Epoch: 180| Step: 0
Training loss: 3.4023601474651506
Validation loss: 2.7617031066277895

Epoch: 6| Step: 1
Training loss: 3.077253654034638
Validation loss: 2.7589202899015985

Epoch: 6| Step: 2
Training loss: 2.882917035282878
Validation loss: 2.758115381648417

Epoch: 6| Step: 3
Training loss: 3.442292358075763
Validation loss: 2.7601431050324616

Epoch: 6| Step: 4
Training loss: 2.5427028440806643
Validation loss: 2.7590991717329274

Epoch: 6| Step: 5
Training loss: 3.2499187165879566
Validation loss: 2.7609124198004857

Epoch: 6| Step: 6
Training loss: 2.9942925521019554
Validation loss: 2.7581971885670864

Epoch: 6| Step: 7
Training loss: 2.9180547045363956
Validation loss: 2.758942758320994

Epoch: 6| Step: 8
Training loss: 3.0964257585201915
Validation loss: 2.7610558749345113

Epoch: 6| Step: 9
Training loss: 2.274741097274885
Validation loss: 2.758861350781199

Epoch: 6| Step: 10
Training loss: 3.6199497691510523
Validation loss: 2.763214306514194

Epoch: 6| Step: 11
Training loss: 2.7145138766541335
Validation loss: 2.7681888037968445

Epoch: 6| Step: 12
Training loss: 3.4817925021919836
Validation loss: 2.7680064499863057

Epoch: 6| Step: 13
Training loss: 2.8939941566898644
Validation loss: 2.777079171414846

Epoch: 181| Step: 0
Training loss: 2.850913279584274
Validation loss: 2.773957866707955

Epoch: 6| Step: 1
Training loss: 2.4867775294397596
Validation loss: 2.779605896177621

Epoch: 6| Step: 2
Training loss: 2.721969802554405
Validation loss: 2.7869820643212933

Epoch: 6| Step: 3
Training loss: 3.2452722053799614
Validation loss: 2.7735270352710257

Epoch: 6| Step: 4
Training loss: 3.29476195683905
Validation loss: 2.774213012253576

Epoch: 6| Step: 5
Training loss: 3.011120055147458
Validation loss: 2.767163143195637

Epoch: 6| Step: 6
Training loss: 3.1884734219452375
Validation loss: 2.7710152442266405

Epoch: 6| Step: 7
Training loss: 3.5032235695738816
Validation loss: 2.7592187258340046

Epoch: 6| Step: 8
Training loss: 3.1255137212022186
Validation loss: 2.7595806661476705

Epoch: 6| Step: 9
Training loss: 2.8651208731566373
Validation loss: 2.7572016197020894

Epoch: 6| Step: 10
Training loss: 3.0754223107113585
Validation loss: 2.7561927204785497

Epoch: 6| Step: 11
Training loss: 2.8260321697933715
Validation loss: 2.7572408113403295

Epoch: 6| Step: 12
Training loss: 3.410737607501005
Validation loss: 2.759971575029598

Epoch: 6| Step: 13
Training loss: 3.2389857649742098
Validation loss: 2.7548654962008614

Epoch: 182| Step: 0
Training loss: 3.4365377293056754
Validation loss: 2.756764572550983

Epoch: 6| Step: 1
Training loss: 3.3303730853607547
Validation loss: 2.7546254744586043

Epoch: 6| Step: 2
Training loss: 2.391813792932522
Validation loss: 2.751449350323498

Epoch: 6| Step: 3
Training loss: 3.6430887554706675
Validation loss: 2.753449768061198

Epoch: 6| Step: 4
Training loss: 2.2508918266317806
Validation loss: 2.752069172120192

Epoch: 6| Step: 5
Training loss: 3.5140662234410853
Validation loss: 2.7559570533333737

Epoch: 6| Step: 6
Training loss: 3.6752733453313144
Validation loss: 2.7542615249554503

Epoch: 6| Step: 7
Training loss: 3.2291391350997882
Validation loss: 2.7543520461079427

Epoch: 6| Step: 8
Training loss: 2.914327900845658
Validation loss: 2.755735519543603

Epoch: 6| Step: 9
Training loss: 2.5148251606591026
Validation loss: 2.758677007831727

Epoch: 6| Step: 10
Training loss: 2.5911077806499723
Validation loss: 2.761028698531556

Epoch: 6| Step: 11
Training loss: 3.3353722694264847
Validation loss: 2.7610750846061025

Epoch: 6| Step: 12
Training loss: 2.866683541477423
Validation loss: 2.770836685725135

Epoch: 6| Step: 13
Training loss: 2.3820131055341665
Validation loss: 2.7830693303267084

Epoch: 183| Step: 0
Training loss: 3.394582662423522
Validation loss: 2.775587871378636

Epoch: 6| Step: 1
Training loss: 3.1597930359968944
Validation loss: 2.7674272506108166

Epoch: 6| Step: 2
Training loss: 3.3552784627087058
Validation loss: 2.759341251519631

Epoch: 6| Step: 3
Training loss: 2.440901412648268
Validation loss: 2.7575503165443696

Epoch: 6| Step: 4
Training loss: 2.6248244272280754
Validation loss: 2.751770034400991

Epoch: 6| Step: 5
Training loss: 3.086124617299732
Validation loss: 2.749464572081217

Epoch: 6| Step: 6
Training loss: 2.687167834669001
Validation loss: 2.751439583787606

Epoch: 6| Step: 7
Training loss: 3.43475648463827
Validation loss: 2.7502515590158714

Epoch: 6| Step: 8
Training loss: 2.685651809029469
Validation loss: 2.7509400946022033

Epoch: 6| Step: 9
Training loss: 3.2308353829510588
Validation loss: 2.7500118262818805

Epoch: 6| Step: 10
Training loss: 3.1469453442012063
Validation loss: 2.748527378671592

Epoch: 6| Step: 11
Training loss: 2.6670069378082126
Validation loss: 2.750693506926492

Epoch: 6| Step: 12
Training loss: 3.384064405283813
Validation loss: 2.7541129732910448

Epoch: 6| Step: 13
Training loss: 3.5468747311226494
Validation loss: 2.7519170953113448

Epoch: 184| Step: 0
Training loss: 3.5760866714402817
Validation loss: 2.7438499268974605

Epoch: 6| Step: 1
Training loss: 2.919080080894794
Validation loss: 2.7453080159195165

Epoch: 6| Step: 2
Training loss: 2.917711524911697
Validation loss: 2.7469181567959002

Epoch: 6| Step: 3
Training loss: 2.9170608435802166
Validation loss: 2.7505142061182837

Epoch: 6| Step: 4
Training loss: 1.911443109131211
Validation loss: 2.7482268927521205

Epoch: 6| Step: 5
Training loss: 2.776167179059144
Validation loss: 2.749301985887264

Epoch: 6| Step: 6
Training loss: 2.9605052300310186
Validation loss: 2.7482684436815172

Epoch: 6| Step: 7
Training loss: 3.2056339021478433
Validation loss: 2.746547392348031

Epoch: 6| Step: 8
Training loss: 2.796687199771451
Validation loss: 2.749104828626782

Epoch: 6| Step: 9
Training loss: 2.8345986140322124
Validation loss: 2.748922476253908

Epoch: 6| Step: 10
Training loss: 3.409984955740489
Validation loss: 2.74801342769315

Epoch: 6| Step: 11
Training loss: 3.484838891047564
Validation loss: 2.7493075695098033

Epoch: 6| Step: 12
Training loss: 3.5487835156456033
Validation loss: 2.7465189774908376

Epoch: 6| Step: 13
Training loss: 3.3480671615974034
Validation loss: 2.7492931889545975

Epoch: 185| Step: 0
Training loss: 2.676107612253674
Validation loss: 2.747751407371055

Epoch: 6| Step: 1
Training loss: 3.1469241307958717
Validation loss: 2.7495539015337016

Epoch: 6| Step: 2
Training loss: 3.442318954416564
Validation loss: 2.7512638463711903

Epoch: 6| Step: 3
Training loss: 2.7766925461453402
Validation loss: 2.746409576332436

Epoch: 6| Step: 4
Training loss: 3.262809159988054
Validation loss: 2.747868693641083

Epoch: 6| Step: 5
Training loss: 3.5463554909324033
Validation loss: 2.750103086252861

Epoch: 6| Step: 6
Training loss: 3.3107104955878737
Validation loss: 2.7567560077402025

Epoch: 6| Step: 7
Training loss: 3.1006965100854758
Validation loss: 2.7535007080168263

Epoch: 6| Step: 8
Training loss: 2.529861823066832
Validation loss: 2.753721843460449

Epoch: 6| Step: 9
Training loss: 3.1436136932855323
Validation loss: 2.754779338363802

Epoch: 6| Step: 10
Training loss: 2.618360933886415
Validation loss: 2.7501374710938493

Epoch: 6| Step: 11
Training loss: 3.6342920059345003
Validation loss: 2.7532959099309755

Epoch: 6| Step: 12
Training loss: 2.8119285850735456
Validation loss: 2.7467175094461793

Epoch: 6| Step: 13
Training loss: 2.0014994484040383
Validation loss: 2.747971032812285

Epoch: 186| Step: 0
Training loss: 3.45898561569183
Validation loss: 2.745555067209146

Epoch: 6| Step: 1
Training loss: 3.0789121599196325
Validation loss: 2.7443085315881217

Epoch: 6| Step: 2
Training loss: 2.747516203980915
Validation loss: 2.7519763592224855

Epoch: 6| Step: 3
Training loss: 2.4152761821901203
Validation loss: 2.7470136146318076

Epoch: 6| Step: 4
Training loss: 2.8172809232009386
Validation loss: 2.748545767430041

Epoch: 6| Step: 5
Training loss: 2.9049456550911934
Validation loss: 2.7458828733222935

Epoch: 6| Step: 6
Training loss: 3.385768946389786
Validation loss: 2.7423872541737335

Epoch: 6| Step: 7
Training loss: 3.4621852580219126
Validation loss: 2.745129348603563

Epoch: 6| Step: 8
Training loss: 2.8532833393862824
Validation loss: 2.7457984578021337

Epoch: 6| Step: 9
Training loss: 3.1306910764088114
Validation loss: 2.7455789036766194

Epoch: 6| Step: 10
Training loss: 2.6038935301910953
Validation loss: 2.7407602085698053

Epoch: 6| Step: 11
Training loss: 3.1525267745234005
Validation loss: 2.7417885707196636

Epoch: 6| Step: 12
Training loss: 3.1867148236369536
Validation loss: 2.743998591326854

Epoch: 6| Step: 13
Training loss: 3.560091777432868
Validation loss: 2.7436411922528317

Epoch: 187| Step: 0
Training loss: 3.7652043151130457
Validation loss: 2.7448710961524223

Epoch: 6| Step: 1
Training loss: 2.756908581999845
Validation loss: 2.7442722670114956

Epoch: 6| Step: 2
Training loss: 2.964817373688668
Validation loss: 2.7454827806049384

Epoch: 6| Step: 3
Training loss: 3.1426758404245705
Validation loss: 2.7441377345109954

Epoch: 6| Step: 4
Training loss: 2.815193158394906
Validation loss: 2.7514106920806394

Epoch: 6| Step: 5
Training loss: 3.3180334549700943
Validation loss: 2.743627884587609

Epoch: 6| Step: 6
Training loss: 2.011608528154629
Validation loss: 2.74859932031554

Epoch: 6| Step: 7
Training loss: 3.325416860047898
Validation loss: 2.7484373386693175

Epoch: 6| Step: 8
Training loss: 3.083005956504826
Validation loss: 2.748856204081894

Epoch: 6| Step: 9
Training loss: 3.002203926525124
Validation loss: 2.7473688841719213

Epoch: 6| Step: 10
Training loss: 3.2321914452421114
Validation loss: 2.749508395213495

Epoch: 6| Step: 11
Training loss: 2.5483102323467612
Validation loss: 2.746769518783796

Epoch: 6| Step: 12
Training loss: 3.4052811390882938
Validation loss: 2.743927041987353

Epoch: 6| Step: 13
Training loss: 3.0674445271469906
Validation loss: 2.745374880798628

Epoch: 188| Step: 0
Training loss: 2.7354036848501533
Validation loss: 2.7455438314662337

Epoch: 6| Step: 1
Training loss: 2.7917826234638694
Validation loss: 2.7440480297448837

Epoch: 6| Step: 2
Training loss: 2.3583480924362408
Validation loss: 2.7412838857118262

Epoch: 6| Step: 3
Training loss: 3.322556542919322
Validation loss: 2.7431558140956933

Epoch: 6| Step: 4
Training loss: 3.911484529870595
Validation loss: 2.741792336062426

Epoch: 6| Step: 5
Training loss: 3.5169211477855473
Validation loss: 2.7453147123792467

Epoch: 6| Step: 6
Training loss: 2.658060511477913
Validation loss: 2.7422973687463332

Epoch: 6| Step: 7
Training loss: 3.155953572771819
Validation loss: 2.7432716642413975

Epoch: 6| Step: 8
Training loss: 2.915783739419554
Validation loss: 2.7496157197764983

Epoch: 6| Step: 9
Training loss: 2.511785099938915
Validation loss: 2.746775062754596

Epoch: 6| Step: 10
Training loss: 3.0499962103147884
Validation loss: 2.7500723580380524

Epoch: 6| Step: 11
Training loss: 3.0755858816857966
Validation loss: 2.751798784454862

Epoch: 6| Step: 12
Training loss: 3.3458795629009837
Validation loss: 2.750335918952232

Epoch: 6| Step: 13
Training loss: 3.012363389585986
Validation loss: 2.7489541098087886

Epoch: 189| Step: 0
Training loss: 2.0613974890099516
Validation loss: 2.7432493786663463

Epoch: 6| Step: 1
Training loss: 3.17646404963799
Validation loss: 2.7423609182758173

Epoch: 6| Step: 2
Training loss: 3.698507399678096
Validation loss: 2.74452032507966

Epoch: 6| Step: 3
Training loss: 3.4713871184738463
Validation loss: 2.738684541228505

Epoch: 6| Step: 4
Training loss: 3.26983604696747
Validation loss: 2.7412577945248326

Epoch: 6| Step: 5
Training loss: 3.464248348028947
Validation loss: 2.7356096040630113

Epoch: 6| Step: 6
Training loss: 2.9745478182238707
Validation loss: 2.7448782008900925

Epoch: 6| Step: 7
Training loss: 2.5085098390376763
Validation loss: 2.7413794022700517

Epoch: 6| Step: 8
Training loss: 3.165287788408388
Validation loss: 2.7397379534245547

Epoch: 6| Step: 9
Training loss: 2.8293665062987743
Validation loss: 2.740171699566422

Epoch: 6| Step: 10
Training loss: 2.870682169159973
Validation loss: 2.7509265468635293

Epoch: 6| Step: 11
Training loss: 3.0147181911572973
Validation loss: 2.7415727285517395

Epoch: 6| Step: 12
Training loss: 3.268956141782415
Validation loss: 2.7411184967334488

Epoch: 6| Step: 13
Training loss: 2.1475167815826155
Validation loss: 2.742816914633547

Epoch: 190| Step: 0
Training loss: 2.807780311157965
Validation loss: 2.7414775815600945

Epoch: 6| Step: 1
Training loss: 2.8062332696564636
Validation loss: 2.7420467432553393

Epoch: 6| Step: 2
Training loss: 2.3942048439976835
Validation loss: 2.748309233745549

Epoch: 6| Step: 3
Training loss: 3.033081759685601
Validation loss: 2.743155595408906

Epoch: 6| Step: 4
Training loss: 2.7696274066798723
Validation loss: 2.7407515862625793

Epoch: 6| Step: 5
Training loss: 3.3970150129981995
Validation loss: 2.748345549527113

Epoch: 6| Step: 6
Training loss: 3.232841533606108
Validation loss: 2.7546530248733245

Epoch: 6| Step: 7
Training loss: 3.8694933249611565
Validation loss: 2.754382725181928

Epoch: 6| Step: 8
Training loss: 3.275562989278105
Validation loss: 2.751754467230104

Epoch: 6| Step: 9
Training loss: 2.7704754552877833
Validation loss: 2.7590822693576436

Epoch: 6| Step: 10
Training loss: 3.0551554523881164
Validation loss: 2.7450781365639783

Epoch: 6| Step: 11
Training loss: 2.8605907753015347
Validation loss: 2.749486881406253

Epoch: 6| Step: 12
Training loss: 3.2489684008244315
Validation loss: 2.743609161054936

Epoch: 6| Step: 13
Training loss: 2.872199975556187
Validation loss: 2.7414810574397683

Epoch: 191| Step: 0
Training loss: 3.5417039457864923
Validation loss: 2.7436339441524846

Epoch: 6| Step: 1
Training loss: 3.04216163126601
Validation loss: 2.7388206632794367

Epoch: 6| Step: 2
Training loss: 2.9570093191888205
Validation loss: 2.734911706054939

Epoch: 6| Step: 3
Training loss: 3.3068993203035415
Validation loss: 2.7314310181083585

Epoch: 6| Step: 4
Training loss: 3.369259508772094
Validation loss: 2.7395177245584086

Epoch: 6| Step: 5
Training loss: 2.5696820352582734
Validation loss: 2.7386716475678052

Epoch: 6| Step: 6
Training loss: 2.5317216598568417
Validation loss: 2.738640880018945

Epoch: 6| Step: 7
Training loss: 3.0996696788399762
Validation loss: 2.741083879042244

Epoch: 6| Step: 8
Training loss: 2.394897034727339
Validation loss: 2.7434339938719265

Epoch: 6| Step: 9
Training loss: 2.870230990162577
Validation loss: 2.742254006254451

Epoch: 6| Step: 10
Training loss: 3.0618606211349393
Validation loss: 2.737959913951566

Epoch: 6| Step: 11
Training loss: 3.400134414933006
Validation loss: 2.7357693512475594

Epoch: 6| Step: 12
Training loss: 3.267175333811339
Validation loss: 2.7380104979070206

Epoch: 6| Step: 13
Training loss: 3.0787537218288983
Validation loss: 2.7383398138387043

Epoch: 192| Step: 0
Training loss: 2.532768076860681
Validation loss: 2.7414205772527622

Epoch: 6| Step: 1
Training loss: 2.6831573175864976
Validation loss: 2.7449006581659363

Epoch: 6| Step: 2
Training loss: 2.9168805361855203
Validation loss: 2.742786944136554

Epoch: 6| Step: 3
Training loss: 3.1554756347702035
Validation loss: 2.741786074201994

Epoch: 6| Step: 4
Training loss: 3.2264315599376836
Validation loss: 2.7414591079852126

Epoch: 6| Step: 5
Training loss: 2.8263541731601673
Validation loss: 2.7425163994302717

Epoch: 6| Step: 6
Training loss: 2.2506272183497122
Validation loss: 2.7395321030873885

Epoch: 6| Step: 7
Training loss: 3.423011068635475
Validation loss: 2.7371366397460215

Epoch: 6| Step: 8
Training loss: 4.0924659637173
Validation loss: 2.739073673938206

Epoch: 6| Step: 9
Training loss: 2.921736606849544
Validation loss: 2.7417959405761683

Epoch: 6| Step: 10
Training loss: 3.2833914898467627
Validation loss: 2.74078376497146

Epoch: 6| Step: 11
Training loss: 3.256437967626516
Validation loss: 2.738037390617907

Epoch: 6| Step: 12
Training loss: 2.8939261067730118
Validation loss: 2.7407298807140688

Epoch: 6| Step: 13
Training loss: 2.8482409218457896
Validation loss: 2.7357751330383375

Epoch: 193| Step: 0
Training loss: 2.4965170440183697
Validation loss: 2.7327803323467297

Epoch: 6| Step: 1
Training loss: 3.4221244268219366
Validation loss: 2.735430824368045

Epoch: 6| Step: 2
Training loss: 2.8981959815564173
Validation loss: 2.738151986447356

Epoch: 6| Step: 3
Training loss: 2.54399526477469
Validation loss: 2.736143852987302

Epoch: 6| Step: 4
Training loss: 3.747088510062992
Validation loss: 2.7342528603928615

Epoch: 6| Step: 5
Training loss: 3.2680199706869284
Validation loss: 2.7352228596966386

Epoch: 6| Step: 6
Training loss: 2.898311478581949
Validation loss: 2.743618828386443

Epoch: 6| Step: 7
Training loss: 3.289876298057201
Validation loss: 2.738466193581613

Epoch: 6| Step: 8
Training loss: 2.9158821867493128
Validation loss: 2.742916689306398

Epoch: 6| Step: 9
Training loss: 2.915322857050286
Validation loss: 2.749386712503183

Epoch: 6| Step: 10
Training loss: 2.696520283203119
Validation loss: 2.744000710254588

Epoch: 6| Step: 11
Training loss: 3.905164155721227
Validation loss: 2.7406188041699386

Epoch: 6| Step: 12
Training loss: 2.0922727924992053
Validation loss: 2.7347916405499744

Epoch: 6| Step: 13
Training loss: 3.1018327648109096
Validation loss: 2.7319066432997534

Epoch: 194| Step: 0
Training loss: 2.57585719386831
Validation loss: 2.7331352092926435

Epoch: 6| Step: 1
Training loss: 2.7843914506728096
Validation loss: 2.732552493220276

Epoch: 6| Step: 2
Training loss: 2.907766295265295
Validation loss: 2.7315291223074816

Epoch: 6| Step: 3
Training loss: 3.5983041848761164
Validation loss: 2.735455339486706

Epoch: 6| Step: 4
Training loss: 3.3510354790330528
Validation loss: 2.7347848067702794

Epoch: 6| Step: 5
Training loss: 2.6885960140496965
Validation loss: 2.731719540096926

Epoch: 6| Step: 6
Training loss: 3.3735566055028965
Validation loss: 2.741611591906398

Epoch: 6| Step: 7
Training loss: 3.0719086281380354
Validation loss: 2.7368618636658164

Epoch: 6| Step: 8
Training loss: 3.2225494182103116
Validation loss: 2.7394638883922964

Epoch: 6| Step: 9
Training loss: 3.1419682453282176
Validation loss: 2.7473742179134995

Epoch: 6| Step: 10
Training loss: 2.8603090522084336
Validation loss: 2.7558994443355256

Epoch: 6| Step: 11
Training loss: 3.1440661352932997
Validation loss: 2.757365640493992

Epoch: 6| Step: 12
Training loss: 2.5364870125926666
Validation loss: 2.753773309027894

Epoch: 6| Step: 13
Training loss: 3.347281329282509
Validation loss: 2.7504959367754567

Epoch: 195| Step: 0
Training loss: 3.6848367675073246
Validation loss: 2.754668198284069

Epoch: 6| Step: 1
Training loss: 2.783014145174036
Validation loss: 2.752873255587403

Epoch: 6| Step: 2
Training loss: 3.010494948340617
Validation loss: 2.7437936829114045

Epoch: 6| Step: 3
Training loss: 3.447167967366728
Validation loss: 2.733400758789056

Epoch: 6| Step: 4
Training loss: 2.9994875152272105
Validation loss: 2.732993533259684

Epoch: 6| Step: 5
Training loss: 3.2807878441273566
Validation loss: 2.7301896069496094

Epoch: 6| Step: 6
Training loss: 2.1086071736211287
Validation loss: 2.7335152066807322

Epoch: 6| Step: 7
Training loss: 2.8476435238484497
Validation loss: 2.7318050109801755

Epoch: 6| Step: 8
Training loss: 3.62021241887319
Validation loss: 2.7295127257228695

Epoch: 6| Step: 9
Training loss: 2.629701219274735
Validation loss: 2.730693548454723

Epoch: 6| Step: 10
Training loss: 3.024167468050818
Validation loss: 2.7284367579502034

Epoch: 6| Step: 11
Training loss: 3.362184990517539
Validation loss: 2.7314062341027237

Epoch: 6| Step: 12
Training loss: 2.8213161045995454
Validation loss: 2.736407978784938

Epoch: 6| Step: 13
Training loss: 2.325619674467383
Validation loss: 2.7264093728092527

Epoch: 196| Step: 0
Training loss: 2.6586728882648263
Validation loss: 2.728829599203287

Epoch: 6| Step: 1
Training loss: 3.750796424216858
Validation loss: 2.731295702921635

Epoch: 6| Step: 2
Training loss: 3.0123621232387445
Validation loss: 2.7270228415165905

Epoch: 6| Step: 3
Training loss: 2.87384391428779
Validation loss: 2.7283231372086343

Epoch: 6| Step: 4
Training loss: 3.095065058947261
Validation loss: 2.7284574347212134

Epoch: 6| Step: 5
Training loss: 3.1732736895536564
Validation loss: 2.7277353847289785

Epoch: 6| Step: 6
Training loss: 2.2248297122555596
Validation loss: 2.726905034231839

Epoch: 6| Step: 7
Training loss: 3.1831261039775414
Validation loss: 2.7246895468278858

Epoch: 6| Step: 8
Training loss: 3.4174309007625623
Validation loss: 2.730393557993656

Epoch: 6| Step: 9
Training loss: 3.020086910942464
Validation loss: 2.7267679492662924

Epoch: 6| Step: 10
Training loss: 3.1522833949554436
Validation loss: 2.731943143339122

Epoch: 6| Step: 11
Training loss: 3.139818989584195
Validation loss: 2.7340774322653307

Epoch: 6| Step: 12
Training loss: 3.1244999294711366
Validation loss: 2.7297223003096382

Epoch: 6| Step: 13
Training loss: 1.90713630458794
Validation loss: 2.7331666869598927

Epoch: 197| Step: 0
Training loss: 3.2591699201046933
Validation loss: 2.731972467073942

Epoch: 6| Step: 1
Training loss: 2.9468957505855777
Validation loss: 2.7268406652366997

Epoch: 6| Step: 2
Training loss: 3.078657075236191
Validation loss: 2.729425863397624

Epoch: 6| Step: 3
Training loss: 2.8783536507471648
Validation loss: 2.730391651031953

Epoch: 6| Step: 4
Training loss: 2.487565013860171
Validation loss: 2.7308145047986114

Epoch: 6| Step: 5
Training loss: 3.251785081525325
Validation loss: 2.7391230645995615

Epoch: 6| Step: 6
Training loss: 2.786973357807955
Validation loss: 2.733173175859727

Epoch: 6| Step: 7
Training loss: 3.194805375500846
Validation loss: 2.735122111692734

Epoch: 6| Step: 8
Training loss: 2.9973511127722934
Validation loss: 2.737533326057809

Epoch: 6| Step: 9
Training loss: 2.9962309367019433
Validation loss: 2.731950988306538

Epoch: 6| Step: 10
Training loss: 3.618398640759432
Validation loss: 2.7377442681026576

Epoch: 6| Step: 11
Training loss: 2.7025413985703026
Validation loss: 2.7372486696064153

Epoch: 6| Step: 12
Training loss: 3.3303195362458804
Validation loss: 2.7230169946171694

Epoch: 6| Step: 13
Training loss: 2.7455062563353705
Validation loss: 2.7221121239080754

Epoch: 198| Step: 0
Training loss: 2.8100550726927334
Validation loss: 2.7225553721898215

Epoch: 6| Step: 1
Training loss: 2.887853665181791
Validation loss: 2.725727076836197

Epoch: 6| Step: 2
Training loss: 2.730455303022593
Validation loss: 2.718936957584947

Epoch: 6| Step: 3
Training loss: 2.4893938149390773
Validation loss: 2.7253455740054116

Epoch: 6| Step: 4
Training loss: 3.3063821978902244
Validation loss: 2.7259650903581094

Epoch: 6| Step: 5
Training loss: 2.8844907264183495
Validation loss: 2.7216412224413626

Epoch: 6| Step: 6
Training loss: 1.9243106449934373
Validation loss: 2.7217784615395466

Epoch: 6| Step: 7
Training loss: 3.066828102202579
Validation loss: 2.7227173965194775

Epoch: 6| Step: 8
Training loss: 3.1994625832369414
Validation loss: 2.72453541859108

Epoch: 6| Step: 9
Training loss: 3.6182470891283587
Validation loss: 2.7222812564010788

Epoch: 6| Step: 10
Training loss: 3.336903916751843
Validation loss: 2.724656388624789

Epoch: 6| Step: 11
Training loss: 3.074430930971845
Validation loss: 2.7220140240740096

Epoch: 6| Step: 12
Training loss: 3.9019110423495906
Validation loss: 2.723210986211928

Epoch: 6| Step: 13
Training loss: 2.746648914116213
Validation loss: 2.7195374703062405

Epoch: 199| Step: 0
Training loss: 3.315691580000547
Validation loss: 2.7238621723089995

Epoch: 6| Step: 1
Training loss: 3.1687254654575954
Validation loss: 2.7223928730241274

Epoch: 6| Step: 2
Training loss: 3.3809054948381587
Validation loss: 2.7235610632377045

Epoch: 6| Step: 3
Training loss: 3.2881191468381603
Validation loss: 2.724440081217822

Epoch: 6| Step: 4
Training loss: 3.282284237582751
Validation loss: 2.722020463273124

Epoch: 6| Step: 5
Training loss: 2.4566483191637936
Validation loss: 2.719925875673179

Epoch: 6| Step: 6
Training loss: 2.276688705642988
Validation loss: 2.7157693322215857

Epoch: 6| Step: 7
Training loss: 3.19773642231869
Validation loss: 2.716689507092548

Epoch: 6| Step: 8
Training loss: 1.9119682220946572
Validation loss: 2.719737201714859

Epoch: 6| Step: 9
Training loss: 2.6337767513384867
Validation loss: 2.7191245839731097

Epoch: 6| Step: 10
Training loss: 3.3213268211706213
Validation loss: 2.716441810563405

Epoch: 6| Step: 11
Training loss: 3.4574157845811233
Validation loss: 2.721289090611323

Epoch: 6| Step: 12
Training loss: 3.1733662524506028
Validation loss: 2.716353176881906

Epoch: 6| Step: 13
Training loss: 3.2617341001229367
Validation loss: 2.7225090219269528

Epoch: 200| Step: 0
Training loss: 3.291037068735776
Validation loss: 2.7205616656613025

Epoch: 6| Step: 1
Training loss: 3.0913927750369705
Validation loss: 2.7300937158016296

Epoch: 6| Step: 2
Training loss: 3.0231425612158236
Validation loss: 2.728921434145977

Epoch: 6| Step: 3
Training loss: 3.3675838511561773
Validation loss: 2.7239060261702726

Epoch: 6| Step: 4
Training loss: 3.5737189605314943
Validation loss: 2.720588577255227

Epoch: 6| Step: 5
Training loss: 2.9801170771597385
Validation loss: 2.7169216553722118

Epoch: 6| Step: 6
Training loss: 2.692657047179303
Validation loss: 2.715706560389005

Epoch: 6| Step: 7
Training loss: 3.164388004090157
Validation loss: 2.715217686040742

Epoch: 6| Step: 8
Training loss: 3.2908156699270625
Validation loss: 2.7152695943972414

Epoch: 6| Step: 9
Training loss: 2.7936613917966833
Validation loss: 2.7176996393747435

Epoch: 6| Step: 10
Training loss: 2.5729661594423465
Validation loss: 2.7167231706626223

Epoch: 6| Step: 11
Training loss: 2.417074256813733
Validation loss: 2.718652857618645

Epoch: 6| Step: 12
Training loss: 3.2180251999858767
Validation loss: 2.714103030508093

Epoch: 6| Step: 13
Training loss: 2.7488985456754316
Validation loss: 2.7194729830138926

Testing loss: 2.935388687393918
