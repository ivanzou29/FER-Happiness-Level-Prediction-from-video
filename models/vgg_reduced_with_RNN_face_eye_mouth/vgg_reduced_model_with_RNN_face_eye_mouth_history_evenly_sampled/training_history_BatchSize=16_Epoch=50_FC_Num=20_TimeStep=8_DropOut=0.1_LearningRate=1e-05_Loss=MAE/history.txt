Epoch: 1| Step: 0
Training loss: 5.307380676269531
Validation loss: 5.244499350106844

Epoch: 6| Step: 1
Training loss: 3.397057056427002
Validation loss: 5.2351180661109185

Epoch: 6| Step: 2
Training loss: 4.675471305847168
Validation loss: 5.226333269508936

Epoch: 6| Step: 3
Training loss: 4.063422203063965
Validation loss: 5.218046844646495

Epoch: 6| Step: 4
Training loss: 6.097362518310547
Validation loss: 5.2093140181674755

Epoch: 6| Step: 5
Training loss: 4.85835075378418
Validation loss: 5.200239719883088

Epoch: 6| Step: 6
Training loss: 5.95429801940918
Validation loss: 5.1907922785769225

Epoch: 6| Step: 7
Training loss: 4.997666358947754
Validation loss: 5.180698938267206

Epoch: 6| Step: 8
Training loss: 4.720003604888916
Validation loss: 5.169580828758978

Epoch: 6| Step: 9
Training loss: 5.6109771728515625
Validation loss: 5.157782831499653

Epoch: 6| Step: 10
Training loss: 6.196576118469238
Validation loss: 5.144934628599433

Epoch: 6| Step: 11
Training loss: 4.1793413162231445
Validation loss: 5.13088160176431

Epoch: 6| Step: 12
Training loss: 5.490627765655518
Validation loss: 5.115906074482908

Epoch: 6| Step: 13
Training loss: 3.469571113586426
Validation loss: 5.099898112717495

Epoch: 2| Step: 0
Training loss: 6.008950233459473
Validation loss: 5.082719587510632

Epoch: 6| Step: 1
Training loss: 4.85734748840332
Validation loss: 5.0632960924538235

Epoch: 6| Step: 2
Training loss: 4.636938095092773
Validation loss: 5.043041895794612

Epoch: 6| Step: 3
Training loss: 5.961071968078613
Validation loss: 5.022583771777409

Epoch: 6| Step: 4
Training loss: 3.7799582481384277
Validation loss: 5.000066136801115

Epoch: 6| Step: 5
Training loss: 4.832531929016113
Validation loss: 4.975111684491558

Epoch: 6| Step: 6
Training loss: 4.545792579650879
Validation loss: 4.95086242306617

Epoch: 6| Step: 7
Training loss: 4.261305332183838
Validation loss: 4.9246401889349825

Epoch: 6| Step: 8
Training loss: 4.1014227867126465
Validation loss: 4.8972060244570494

Epoch: 6| Step: 9
Training loss: 4.838234901428223
Validation loss: 4.869063013343401

Epoch: 6| Step: 10
Training loss: 4.601973056793213
Validation loss: 4.838604809135519

Epoch: 6| Step: 11
Training loss: 4.394639015197754
Validation loss: 4.807171406284455

Epoch: 6| Step: 12
Training loss: 4.735353469848633
Validation loss: 4.773729683250509

Epoch: 6| Step: 13
Training loss: 4.518800735473633
Validation loss: 4.740163651845789

Epoch: 3| Step: 0
Training loss: 3.9161462783813477
Validation loss: 4.706204647658973

Epoch: 6| Step: 1
Training loss: 3.776719570159912
Validation loss: 4.669210803124212

Epoch: 6| Step: 2
Training loss: 4.486246109008789
Validation loss: 4.6332319269898115

Epoch: 6| Step: 3
Training loss: 4.784670352935791
Validation loss: 4.595345825277349

Epoch: 6| Step: 4
Training loss: 4.198151588439941
Validation loss: 4.5548061914341424

Epoch: 6| Step: 5
Training loss: 4.089592933654785
Validation loss: 4.515825809970979

Epoch: 6| Step: 6
Training loss: 5.078144550323486
Validation loss: 4.474710469604821

Epoch: 6| Step: 7
Training loss: 3.38464617729187
Validation loss: 4.431395602482621

Epoch: 6| Step: 8
Training loss: 3.8106327056884766
Validation loss: 4.3904566303376225

Epoch: 6| Step: 9
Training loss: 5.059206962585449
Validation loss: 4.348531482040241

Epoch: 6| Step: 10
Training loss: 4.516836643218994
Validation loss: 4.308089935651389

Epoch: 6| Step: 11
Training loss: 3.414226531982422
Validation loss: 4.268341177253313

Epoch: 6| Step: 12
Training loss: 5.058259963989258
Validation loss: 4.22766984406338

Epoch: 6| Step: 13
Training loss: 3.7077713012695312
Validation loss: 4.188212651078419

Epoch: 4| Step: 0
Training loss: 3.766371726989746
Validation loss: 4.148266238550986

Epoch: 6| Step: 1
Training loss: 3.2686166763305664
Validation loss: 4.109572638747513

Epoch: 6| Step: 2
Training loss: 4.10942268371582
Validation loss: 4.072916300066056

Epoch: 6| Step: 3
Training loss: 3.8624420166015625
Validation loss: 4.034317919003066

Epoch: 6| Step: 4
Training loss: 3.7596781253814697
Validation loss: 3.9972662156628025

Epoch: 6| Step: 5
Training loss: 3.560892105102539
Validation loss: 3.961536443361672

Epoch: 6| Step: 6
Training loss: 3.706916332244873
Validation loss: 3.9254302055604997

Epoch: 6| Step: 7
Training loss: 3.794726848602295
Validation loss: 3.893877065309914

Epoch: 6| Step: 8
Training loss: 5.402698993682861
Validation loss: 3.864915842651039

Epoch: 6| Step: 9
Training loss: 3.7866709232330322
Validation loss: 3.8345766477687384

Epoch: 6| Step: 10
Training loss: 3.5306339263916016
Validation loss: 3.805084797643846

Epoch: 6| Step: 11
Training loss: 3.368985176086426
Validation loss: 3.7717871614681777

Epoch: 6| Step: 12
Training loss: 4.035309791564941
Validation loss: 3.729211712396273

Epoch: 6| Step: 13
Training loss: 2.7307019233703613
Validation loss: 3.7028735427446264

Epoch: 5| Step: 0
Training loss: 3.6492764949798584
Validation loss: 3.689693384273078

Epoch: 6| Step: 1
Training loss: 3.515639305114746
Validation loss: 3.6746302779002855

Epoch: 6| Step: 2
Training loss: 2.061830759048462
Validation loss: 3.656035997534311

Epoch: 6| Step: 3
Training loss: 3.179011821746826
Validation loss: 3.6434474811759046

Epoch: 6| Step: 4
Training loss: 3.0567526817321777
Validation loss: 3.624649770798222

Epoch: 6| Step: 5
Training loss: 4.742386817932129
Validation loss: 3.609999769477434

Epoch: 6| Step: 6
Training loss: 4.038717746734619
Validation loss: 3.593795845585485

Epoch: 6| Step: 7
Training loss: 2.6009371280670166
Validation loss: 3.5782316577049995

Epoch: 6| Step: 8
Training loss: 3.7977046966552734
Validation loss: 3.56386068303098

Epoch: 6| Step: 9
Training loss: 3.3762407302856445
Validation loss: 3.547962188720703

Epoch: 6| Step: 10
Training loss: 4.094175338745117
Validation loss: 3.53272605711414

Epoch: 6| Step: 11
Training loss: 3.6475229263305664
Validation loss: 3.516241496609103

Epoch: 6| Step: 12
Training loss: 4.340681552886963
Validation loss: 3.5024404320665585

Epoch: 6| Step: 13
Training loss: 2.6007673740386963
Validation loss: 3.4870498949481594

Epoch: 6| Step: 0
Training loss: 3.4574241638183594
Validation loss: 3.4752049035923456

Epoch: 6| Step: 1
Training loss: 2.39420485496521
Validation loss: 3.469526788239838

Epoch: 6| Step: 2
Training loss: 3.8492062091827393
Validation loss: 3.4717532409134733

Epoch: 6| Step: 3
Training loss: 4.526186466217041
Validation loss: 3.4524127437222387

Epoch: 6| Step: 4
Training loss: 2.1509714126586914
Validation loss: 3.4344300993027224

Epoch: 6| Step: 5
Training loss: 3.10331392288208
Validation loss: 3.42245884864561

Epoch: 6| Step: 6
Training loss: 3.985968828201294
Validation loss: 3.412751859234225

Epoch: 6| Step: 7
Training loss: 4.191411972045898
Validation loss: 3.4065258144050516

Epoch: 6| Step: 8
Training loss: 2.237018585205078
Validation loss: 3.3988696990474576

Epoch: 6| Step: 9
Training loss: 3.4055514335632324
Validation loss: 3.3927941271053847

Epoch: 6| Step: 10
Training loss: 3.7717032432556152
Validation loss: 3.3825215831879647

Epoch: 6| Step: 11
Training loss: 2.9721803665161133
Validation loss: 3.372549662026026

Epoch: 6| Step: 12
Training loss: 3.3863730430603027
Validation loss: 3.3666382733211724

Epoch: 6| Step: 13
Training loss: 4.018032073974609
Validation loss: 3.3597787323818413

Epoch: 7| Step: 0
Training loss: 3.051778554916382
Validation loss: 3.3485876257701586

Epoch: 6| Step: 1
Training loss: 3.729705810546875
Validation loss: 3.3412899022461264

Epoch: 6| Step: 2
Training loss: 4.096972942352295
Validation loss: 3.3341707465469197

Epoch: 6| Step: 3
Training loss: 3.088183641433716
Validation loss: 3.317132995974633

Epoch: 6| Step: 4
Training loss: 2.9284393787384033
Validation loss: 3.311837157895488

Epoch: 6| Step: 5
Training loss: 3.6221210956573486
Validation loss: 3.299235959206858

Epoch: 6| Step: 6
Training loss: 2.9340415000915527
Validation loss: 3.2877304348894345

Epoch: 6| Step: 7
Training loss: 3.1857762336730957
Validation loss: 3.279356207898868

Epoch: 6| Step: 8
Training loss: 3.456984043121338
Validation loss: 3.2721064193274385

Epoch: 6| Step: 9
Training loss: 4.2268195152282715
Validation loss: 3.2643874409378215

Epoch: 6| Step: 10
Training loss: 2.4076380729675293
Validation loss: 3.2607325456475698

Epoch: 6| Step: 11
Training loss: 2.552192211151123
Validation loss: 3.255054425167781

Epoch: 6| Step: 12
Training loss: 2.8112025260925293
Validation loss: 3.255633351623371

Epoch: 6| Step: 13
Training loss: 3.9314732551574707
Validation loss: 3.2489108859851794

Epoch: 8| Step: 0
Training loss: 2.546077251434326
Validation loss: 3.234029616079023

Epoch: 6| Step: 1
Training loss: 3.2407994270324707
Validation loss: 3.226306087227278

Epoch: 6| Step: 2
Training loss: 2.9175868034362793
Validation loss: 3.217894602847356

Epoch: 6| Step: 3
Training loss: 2.9235358238220215
Validation loss: 3.2151858550246044

Epoch: 6| Step: 4
Training loss: 2.9078619480133057
Validation loss: 3.2109184982956096

Epoch: 6| Step: 5
Training loss: 2.8805558681488037
Validation loss: 3.2014829830456804

Epoch: 6| Step: 6
Training loss: 3.7447738647460938
Validation loss: 3.195977698090256

Epoch: 6| Step: 7
Training loss: 2.5859336853027344
Validation loss: 3.1904318281399306

Epoch: 6| Step: 8
Training loss: 3.6182007789611816
Validation loss: 3.182570929168373

Epoch: 6| Step: 9
Training loss: 3.416531562805176
Validation loss: 3.1764393673148206

Epoch: 6| Step: 10
Training loss: 3.902691125869751
Validation loss: 3.1709397838961695

Epoch: 6| Step: 11
Training loss: 2.98429012298584
Validation loss: 3.1648326022650606

Epoch: 6| Step: 12
Training loss: 3.1445417404174805
Validation loss: 3.159499068414011

Epoch: 6| Step: 13
Training loss: 4.402061462402344
Validation loss: 3.152695045676283

Epoch: 9| Step: 0
Training loss: 3.0416951179504395
Validation loss: 3.1424625509528705

Epoch: 6| Step: 1
Training loss: 3.30295991897583
Validation loss: 3.1344899131405737

Epoch: 6| Step: 2
Training loss: 3.5966005325317383
Validation loss: 3.1195213281980125

Epoch: 6| Step: 3
Training loss: 2.766974449157715
Validation loss: 3.1144222828649704

Epoch: 6| Step: 4
Training loss: 3.073798894882202
Validation loss: 3.1059987006648893

Epoch: 6| Step: 5
Training loss: 3.354632616043091
Validation loss: 3.1015985576055383

Epoch: 6| Step: 6
Training loss: 3.346803903579712
Validation loss: 3.1042342288519746

Epoch: 6| Step: 7
Training loss: 3.8110947608947754
Validation loss: 3.0944872210102696

Epoch: 6| Step: 8
Training loss: 3.803117036819458
Validation loss: 3.086740965484291

Epoch: 6| Step: 9
Training loss: 3.3948211669921875
Validation loss: 3.0797943940726658

Epoch: 6| Step: 10
Training loss: 2.121299982070923
Validation loss: 3.0755741006584576

Epoch: 6| Step: 11
Training loss: 2.627163887023926
Validation loss: 3.077873270998719

Epoch: 6| Step: 12
Training loss: 2.887343168258667
Validation loss: 3.0637096281974547

Epoch: 6| Step: 13
Training loss: 2.318537950515747
Validation loss: 3.059843276136665

Epoch: 10| Step: 0
Training loss: 2.967256546020508
Validation loss: 3.0603257430497037

Epoch: 6| Step: 1
Training loss: 2.78768253326416
Validation loss: 3.058622693502775

Epoch: 6| Step: 2
Training loss: 2.447514772415161
Validation loss: 3.0542550522794008

Epoch: 6| Step: 3
Training loss: 2.9071297645568848
Validation loss: 3.048147670684322

Epoch: 6| Step: 4
Training loss: 3.1298763751983643
Validation loss: 3.046496980933733

Epoch: 6| Step: 5
Training loss: 2.916327953338623
Validation loss: 3.0330548440256426

Epoch: 6| Step: 6
Training loss: 2.620636463165283
Validation loss: 3.036204440619356

Epoch: 6| Step: 7
Training loss: 3.8079676628112793
Validation loss: 3.0302593605492705

Epoch: 6| Step: 8
Training loss: 2.3502750396728516
Validation loss: 3.0275052593600367

Epoch: 6| Step: 9
Training loss: 3.4672043323516846
Validation loss: 3.019857547616446

Epoch: 6| Step: 10
Training loss: 3.4045047760009766
Validation loss: 3.015573852805681

Epoch: 6| Step: 11
Training loss: 2.901890516281128
Validation loss: 3.0164576345874416

Epoch: 6| Step: 12
Training loss: 3.599595069885254
Validation loss: 3.0012213594170025

Epoch: 6| Step: 13
Training loss: 4.37865686416626
Validation loss: 3.003862129744663

Epoch: 11| Step: 0
Training loss: 3.4567699432373047
Validation loss: 2.999638536924957

Epoch: 6| Step: 1
Training loss: 2.5212061405181885
Validation loss: 3.0055599981738674

Epoch: 6| Step: 2
Training loss: 3.9997403621673584
Validation loss: 3.0166770694076375

Epoch: 6| Step: 3
Training loss: 3.0439813137054443
Validation loss: 3.0243209382539153

Epoch: 6| Step: 4
Training loss: 3.6674585342407227
Validation loss: 3.048236839232906

Epoch: 6| Step: 5
Training loss: 2.393785238265991
Validation loss: 3.001953399309548

Epoch: 6| Step: 6
Training loss: 2.8985509872436523
Validation loss: 2.9726918589684272

Epoch: 6| Step: 7
Training loss: 2.939850330352783
Validation loss: 2.9697154388632825

Epoch: 6| Step: 8
Training loss: 2.503539562225342
Validation loss: 2.9768692011474283

Epoch: 6| Step: 9
Training loss: 3.516493797302246
Validation loss: 2.984063304880614

Epoch: 6| Step: 10
Training loss: 2.760899782180786
Validation loss: 2.9686676020263345

Epoch: 6| Step: 11
Training loss: 2.7943692207336426
Validation loss: 2.956211159306188

Epoch: 6| Step: 12
Training loss: 3.7146730422973633
Validation loss: 2.945657666011523

Epoch: 6| Step: 13
Training loss: 2.1980435848236084
Validation loss: 2.939609025114326

Epoch: 12| Step: 0
Training loss: 2.852139472961426
Validation loss: 2.935150900194722

Epoch: 6| Step: 1
Training loss: 3.4106059074401855
Validation loss: 2.927461924091462

Epoch: 6| Step: 2
Training loss: 3.150008201599121
Validation loss: 2.929979549941196

Epoch: 6| Step: 3
Training loss: 2.895695686340332
Validation loss: 2.9198193678291897

Epoch: 6| Step: 4
Training loss: 2.3634350299835205
Validation loss: 2.911019963602866

Epoch: 6| Step: 5
Training loss: 3.3202521800994873
Validation loss: 2.9114442512553227

Epoch: 6| Step: 6
Training loss: 3.5370941162109375
Validation loss: 2.9052683896915887

Epoch: 6| Step: 7
Training loss: 2.490541934967041
Validation loss: 2.915533922051871

Epoch: 6| Step: 8
Training loss: 2.7717161178588867
Validation loss: 2.905029514784454

Epoch: 6| Step: 9
Training loss: 2.746232509613037
Validation loss: 2.905603883086994

Epoch: 6| Step: 10
Training loss: 2.4312222003936768
Validation loss: 2.905172481331774

Epoch: 6| Step: 11
Training loss: 3.8201904296875
Validation loss: 2.9058623442085842

Epoch: 6| Step: 12
Training loss: 3.4535679817199707
Validation loss: 2.9003655884855535

Epoch: 6| Step: 13
Training loss: 2.63751220703125
Validation loss: 2.8861623271819083

Epoch: 13| Step: 0
Training loss: 2.792293071746826
Validation loss: 2.8815136468538673

Epoch: 6| Step: 1
Training loss: 2.4174091815948486
Validation loss: 2.8833384898401078

Epoch: 6| Step: 2
Training loss: 2.724249839782715
Validation loss: 2.8819991362992154

Epoch: 6| Step: 3
Training loss: 2.334414005279541
Validation loss: 2.8777969652606594

Epoch: 6| Step: 4
Training loss: 4.025569915771484
Validation loss: 2.875182233830934

Epoch: 6| Step: 5
Training loss: 3.181386947631836
Validation loss: 2.8672816855933076

Epoch: 6| Step: 6
Training loss: 3.365555763244629
Validation loss: 2.8617759520007717

Epoch: 6| Step: 7
Training loss: 2.901477575302124
Validation loss: 2.8573925418238484

Epoch: 6| Step: 8
Training loss: 2.434467315673828
Validation loss: 2.8458065858451267

Epoch: 6| Step: 9
Training loss: 3.4118316173553467
Validation loss: 2.843759144506147

Epoch: 6| Step: 10
Training loss: 2.9552416801452637
Validation loss: 2.836075739193988

Epoch: 6| Step: 11
Training loss: 2.565791368484497
Validation loss: 2.8385709818973335

Epoch: 6| Step: 12
Training loss: 3.1628403663635254
Validation loss: 2.8383113748283795

Epoch: 6| Step: 13
Training loss: 3.4461793899536133
Validation loss: 2.8373659861985074

Epoch: 14| Step: 0
Training loss: 2.1316442489624023
Validation loss: 2.830801845878683

Epoch: 6| Step: 1
Training loss: 3.151733636856079
Validation loss: 2.8368994497483775

Epoch: 6| Step: 2
Training loss: 2.576479196548462
Validation loss: 2.8295913511706936

Epoch: 6| Step: 3
Training loss: 2.2048733234405518
Validation loss: 2.8172076645717827

Epoch: 6| Step: 4
Training loss: 3.479555606842041
Validation loss: 2.8170438428078928

Epoch: 6| Step: 5
Training loss: 2.9560155868530273
Validation loss: 2.8143489719719015

Epoch: 6| Step: 6
Training loss: 2.1974565982818604
Validation loss: 2.8135560558688257

Epoch: 6| Step: 7
Training loss: 3.2424774169921875
Validation loss: 2.814318985067388

Epoch: 6| Step: 8
Training loss: 3.7287635803222656
Validation loss: 2.8113309824338524

Epoch: 6| Step: 9
Training loss: 2.647660970687866
Validation loss: 2.814800893106768

Epoch: 6| Step: 10
Training loss: 3.2724804878234863
Validation loss: 2.804764709165019

Epoch: 6| Step: 11
Training loss: 3.6442766189575195
Validation loss: 2.8065811536645375

Epoch: 6| Step: 12
Training loss: 2.8407108783721924
Validation loss: 2.8028994426932385

Epoch: 6| Step: 13
Training loss: 3.2377407550811768
Validation loss: 2.8053410668526926

Epoch: 15| Step: 0
Training loss: 2.5758094787597656
Validation loss: 2.803901513417562

Epoch: 6| Step: 1
Training loss: 3.547420024871826
Validation loss: 2.800368701258013

Epoch: 6| Step: 2
Training loss: 2.8449320793151855
Validation loss: 2.7975121877526723

Epoch: 6| Step: 3
Training loss: 3.01151180267334
Validation loss: 2.794650247020106

Epoch: 6| Step: 4
Training loss: 2.702016830444336
Validation loss: 2.788510166188722

Epoch: 6| Step: 5
Training loss: 2.9998011589050293
Validation loss: 2.7850386583676903

Epoch: 6| Step: 6
Training loss: 3.073782444000244
Validation loss: 2.782288151402627

Epoch: 6| Step: 7
Training loss: 2.3378190994262695
Validation loss: 2.7774544864572506

Epoch: 6| Step: 8
Training loss: 2.72450590133667
Validation loss: 2.7749645658718642

Epoch: 6| Step: 9
Training loss: 2.9418978691101074
Validation loss: 2.7699269992049023

Epoch: 6| Step: 10
Training loss: 3.3479065895080566
Validation loss: 2.773550271987915

Epoch: 6| Step: 11
Training loss: 2.411555290222168
Validation loss: 2.7689757270197712

Epoch: 6| Step: 12
Training loss: 2.799502372741699
Validation loss: 2.7683595226657007

Epoch: 6| Step: 13
Training loss: 3.9868180751800537
Validation loss: 2.7680711284760506

Epoch: 16| Step: 0
Training loss: 3.6966159343719482
Validation loss: 2.7768529820185837

Epoch: 6| Step: 1
Training loss: 3.2976274490356445
Validation loss: 2.7693880565704836

Epoch: 6| Step: 2
Training loss: 2.735677480697632
Validation loss: 2.7668857753917737

Epoch: 6| Step: 3
Training loss: 2.5517451763153076
Validation loss: 2.7704530146814164

Epoch: 6| Step: 4
Training loss: 2.9378461837768555
Validation loss: 2.7664324519454793

Epoch: 6| Step: 5
Training loss: 3.281968832015991
Validation loss: 2.7562994751878964

Epoch: 6| Step: 6
Training loss: 2.4776611328125
Validation loss: 2.7482585368617887

Epoch: 6| Step: 7
Training loss: 3.0113773345947266
Validation loss: 2.7463338426364365

Epoch: 6| Step: 8
Training loss: 3.0209405422210693
Validation loss: 2.7448680067575104

Epoch: 6| Step: 9
Training loss: 2.696615219116211
Validation loss: 2.7457174434456775

Epoch: 6| Step: 10
Training loss: 2.446005344390869
Validation loss: 2.743194298077655

Epoch: 6| Step: 11
Training loss: 2.821542263031006
Validation loss: 2.7456374117123183

Epoch: 6| Step: 12
Training loss: 3.22468900680542
Validation loss: 2.744512757947368

Epoch: 6| Step: 13
Training loss: 1.9847406148910522
Validation loss: 2.749849837313416

Epoch: 17| Step: 0
Training loss: 2.489558696746826
Validation loss: 2.766825799019106

Epoch: 6| Step: 1
Training loss: 3.0239338874816895
Validation loss: 2.758138064415224

Epoch: 6| Step: 2
Training loss: 2.5801305770874023
Validation loss: 2.742246838026149

Epoch: 6| Step: 3
Training loss: 2.5618631839752197
Validation loss: 2.7355860715271323

Epoch: 6| Step: 4
Training loss: 3.147322177886963
Validation loss: 2.731010378047984

Epoch: 6| Step: 5
Training loss: 2.6779446601867676
Validation loss: 2.728645581071095

Epoch: 6| Step: 6
Training loss: 3.366939067840576
Validation loss: 2.7268412497735794

Epoch: 6| Step: 7
Training loss: 2.6766109466552734
Validation loss: 2.726464912455569

Epoch: 6| Step: 8
Training loss: 2.1705727577209473
Validation loss: 2.7230322976266184

Epoch: 6| Step: 9
Training loss: 3.982234239578247
Validation loss: 2.7187922462340324

Epoch: 6| Step: 10
Training loss: 2.7876765727996826
Validation loss: 2.720139480406238

Epoch: 6| Step: 11
Training loss: 3.909578561782837
Validation loss: 2.721776267533661

Epoch: 6| Step: 12
Training loss: 2.1162314414978027
Validation loss: 2.719889807444747

Epoch: 6| Step: 13
Training loss: 2.8057541847229004
Validation loss: 2.7149033520811345

Epoch: 18| Step: 0
Training loss: 2.9217233657836914
Validation loss: 2.7161559674047653

Epoch: 6| Step: 1
Training loss: 3.1053662300109863
Validation loss: 2.7146307345359557

Epoch: 6| Step: 2
Training loss: 3.7244718074798584
Validation loss: 2.71048911668921

Epoch: 6| Step: 3
Training loss: 2.773155927658081
Validation loss: 2.7133100263534056

Epoch: 6| Step: 4
Training loss: 2.97426438331604
Validation loss: 2.708741867414085

Epoch: 6| Step: 5
Training loss: 2.585407257080078
Validation loss: 2.7096678082660963

Epoch: 6| Step: 6
Training loss: 2.47859263420105
Validation loss: 2.70531290577304

Epoch: 6| Step: 7
Training loss: 3.485661029815674
Validation loss: 2.705780675334315

Epoch: 6| Step: 8
Training loss: 2.586568832397461
Validation loss: 2.7234152260647027

Epoch: 6| Step: 9
Training loss: 2.4962854385375977
Validation loss: 2.7349344325321976

Epoch: 6| Step: 10
Training loss: 2.3419437408447266
Validation loss: 2.7406208489530828

Epoch: 6| Step: 11
Training loss: 3.104071855545044
Validation loss: 2.7488349663314

Epoch: 6| Step: 12
Training loss: 2.7563400268554688
Validation loss: 2.7481183851918867

Epoch: 6| Step: 13
Training loss: 2.8986387252807617
Validation loss: 2.7470784674408617

Epoch: 19| Step: 0
Training loss: 2.9664230346679688
Validation loss: 2.7191536554726223

Epoch: 6| Step: 1
Training loss: 2.4760217666625977
Validation loss: 2.7037964123551563

Epoch: 6| Step: 2
Training loss: 3.283618211746216
Validation loss: 2.692950133354433

Epoch: 6| Step: 3
Training loss: 2.828401565551758
Validation loss: 2.6914357369945896

Epoch: 6| Step: 4
Training loss: 2.7134995460510254
Validation loss: 2.6920680384482107

Epoch: 6| Step: 5
Training loss: 2.6932578086853027
Validation loss: 2.6950228444991575

Epoch: 6| Step: 6
Training loss: 1.9986222982406616
Validation loss: 2.6906433797651723

Epoch: 6| Step: 7
Training loss: 2.843100070953369
Validation loss: 2.688460866610209

Epoch: 6| Step: 8
Training loss: 3.1992359161376953
Validation loss: 2.6871719411624375

Epoch: 6| Step: 9
Training loss: 3.1264312267303467
Validation loss: 2.68632008183387

Epoch: 6| Step: 10
Training loss: 3.409451961517334
Validation loss: 2.690273984786003

Epoch: 6| Step: 11
Training loss: 2.1466219425201416
Validation loss: 2.688665202868882

Epoch: 6| Step: 12
Training loss: 2.8151721954345703
Validation loss: 2.691703586168187

Epoch: 6| Step: 13
Training loss: 4.054689407348633
Validation loss: 2.6897290957871305

Epoch: 20| Step: 0
Training loss: 3.459319829940796
Validation loss: 2.689409699491275

Epoch: 6| Step: 1
Training loss: 2.595836877822876
Validation loss: 2.6869005874920915

Epoch: 6| Step: 2
Training loss: 3.3003740310668945
Validation loss: 2.689875215612432

Epoch: 6| Step: 3
Training loss: 2.2808337211608887
Validation loss: 2.681369919930735

Epoch: 6| Step: 4
Training loss: 2.5911569595336914
Validation loss: 2.684037031665925

Epoch: 6| Step: 5
Training loss: 3.0278029441833496
Validation loss: 2.6891257121998775

Epoch: 6| Step: 6
Training loss: 2.566826105117798
Validation loss: 2.6811343649382233

Epoch: 6| Step: 7
Training loss: 3.3877158164978027
Validation loss: 2.679495590989308

Epoch: 6| Step: 8
Training loss: 2.436206817626953
Validation loss: 2.6741550378901984

Epoch: 6| Step: 9
Training loss: 2.304969072341919
Validation loss: 2.674833356693227

Epoch: 6| Step: 10
Training loss: 3.1897900104522705
Validation loss: 2.6718089298535417

Epoch: 6| Step: 11
Training loss: 2.971538543701172
Validation loss: 2.6710723471897904

Epoch: 6| Step: 12
Training loss: 2.9054970741271973
Validation loss: 2.673086525291525

Epoch: 6| Step: 13
Training loss: 2.89795184135437
Validation loss: 2.67245541849444

Epoch: 21| Step: 0
Training loss: 2.393810510635376
Validation loss: 2.6667376692577074

Epoch: 6| Step: 1
Training loss: 2.1168713569641113
Validation loss: 2.671275543910201

Epoch: 6| Step: 2
Training loss: 2.108644962310791
Validation loss: 2.6684263547261557

Epoch: 6| Step: 3
Training loss: 2.702305555343628
Validation loss: 2.6703554686679634

Epoch: 6| Step: 4
Training loss: 4.105141639709473
Validation loss: 2.6632242997487388

Epoch: 6| Step: 5
Training loss: 2.98175311088562
Validation loss: 2.661947445202899

Epoch: 6| Step: 6
Training loss: 2.5720536708831787
Validation loss: 2.66205422852629

Epoch: 6| Step: 7
Training loss: 2.5106406211853027
Validation loss: 2.661256949106852

Epoch: 6| Step: 8
Training loss: 3.7442786693573
Validation loss: 2.6658848178002144

Epoch: 6| Step: 9
Training loss: 2.8110029697418213
Validation loss: 2.663382617376184

Epoch: 6| Step: 10
Training loss: 2.902080535888672
Validation loss: 2.669793321240333

Epoch: 6| Step: 11
Training loss: 3.030035972595215
Validation loss: 2.6790351970221407

Epoch: 6| Step: 12
Training loss: 2.37016224861145
Validation loss: 2.7075898467853503

Epoch: 6| Step: 13
Training loss: 3.9372715950012207
Validation loss: 2.6968744698391167

Epoch: 22| Step: 0
Training loss: 3.728126049041748
Validation loss: 2.6585380390126216

Epoch: 6| Step: 1
Training loss: 2.58561372756958
Validation loss: 2.6538241319758917

Epoch: 6| Step: 2
Training loss: 2.367889404296875
Validation loss: 2.6636786460876465

Epoch: 6| Step: 3
Training loss: 2.6377992630004883
Validation loss: 2.6617948547486336

Epoch: 6| Step: 4
Training loss: 3.7794010639190674
Validation loss: 2.659751720325921

Epoch: 6| Step: 5
Training loss: 1.9950052499771118
Validation loss: 2.666638607619911

Epoch: 6| Step: 6
Training loss: 2.729776382446289
Validation loss: 2.664513857133927

Epoch: 6| Step: 7
Training loss: 2.45271635055542
Validation loss: 2.6636199464080152

Epoch: 6| Step: 8
Training loss: 3.76389741897583
Validation loss: 2.663533297918176

Epoch: 6| Step: 9
Training loss: 2.3340795040130615
Validation loss: 2.659484906863141

Epoch: 6| Step: 10
Training loss: 3.418334484100342
Validation loss: 2.6540018025264946

Epoch: 6| Step: 11
Training loss: 3.6722586154937744
Validation loss: 2.654277960459391

Epoch: 6| Step: 12
Training loss: 1.877633810043335
Validation loss: 2.6538007900279057

Epoch: 6| Step: 13
Training loss: 2.1160542964935303
Validation loss: 2.6548941109770086

Epoch: 23| Step: 0
Training loss: 2.4566245079040527
Validation loss: 2.6593869193907707

Epoch: 6| Step: 1
Training loss: 2.900801181793213
Validation loss: 2.658640097546321

Epoch: 6| Step: 2
Training loss: 4.1485514640808105
Validation loss: 2.654205088974327

Epoch: 6| Step: 3
Training loss: 2.4206862449645996
Validation loss: 2.6556619546746694

Epoch: 6| Step: 4
Training loss: 3.182429790496826
Validation loss: 2.6505171201562368

Epoch: 6| Step: 5
Training loss: 2.4656200408935547
Validation loss: 2.643021434865972

Epoch: 6| Step: 6
Training loss: 2.549558639526367
Validation loss: 2.6437948185910463

Epoch: 6| Step: 7
Training loss: 3.45671010017395
Validation loss: 2.6422295801101194

Epoch: 6| Step: 8
Training loss: 3.3677566051483154
Validation loss: 2.646455792970555

Epoch: 6| Step: 9
Training loss: 2.3196375370025635
Validation loss: 2.639318320059007

Epoch: 6| Step: 10
Training loss: 3.1017675399780273
Validation loss: 2.6440504468897337

Epoch: 6| Step: 11
Training loss: 2.362086534500122
Validation loss: 2.6375746906444593

Epoch: 6| Step: 12
Training loss: 2.207314968109131
Validation loss: 2.6381645779455862

Epoch: 6| Step: 13
Training loss: 2.567960023880005
Validation loss: 2.6380100711699455

Epoch: 24| Step: 0
Training loss: 3.3846476078033447
Validation loss: 2.6365743170502367

Epoch: 6| Step: 1
Training loss: 2.2391035556793213
Validation loss: 2.639973004659017

Epoch: 6| Step: 2
Training loss: 3.5915489196777344
Validation loss: 2.6409732090529574

Epoch: 6| Step: 3
Training loss: 3.4647374153137207
Validation loss: 2.6447828918374996

Epoch: 6| Step: 4
Training loss: 2.4535293579101562
Validation loss: 2.6429543495178223

Epoch: 6| Step: 5
Training loss: 2.9344146251678467
Validation loss: 2.641235366944344

Epoch: 6| Step: 6
Training loss: 2.3787436485290527
Validation loss: 2.6589609525536977

Epoch: 6| Step: 7
Training loss: 2.675095319747925
Validation loss: 2.6720520732223347

Epoch: 6| Step: 8
Training loss: 3.57523512840271
Validation loss: 2.686619912424395

Epoch: 6| Step: 9
Training loss: 2.923447370529175
Validation loss: 2.6516368901857765

Epoch: 6| Step: 10
Training loss: 2.706528663635254
Validation loss: 2.6311497893384708

Epoch: 6| Step: 11
Training loss: 2.608248710632324
Validation loss: 2.624773863823183

Epoch: 6| Step: 12
Training loss: 2.2576606273651123
Validation loss: 2.626599327210457

Epoch: 6| Step: 13
Training loss: 2.020350933074951
Validation loss: 2.628931119877805

Epoch: 25| Step: 0
Training loss: 1.8435641527175903
Validation loss: 2.635965049907725

Epoch: 6| Step: 1
Training loss: 2.9454002380371094
Validation loss: 2.6370553047426286

Epoch: 6| Step: 2
Training loss: 3.383284091949463
Validation loss: 2.637192808171754

Epoch: 6| Step: 3
Training loss: 3.545408248901367
Validation loss: 2.6392021845745783

Epoch: 6| Step: 4
Training loss: 2.8751049041748047
Validation loss: 2.627787192662557

Epoch: 6| Step: 5
Training loss: 2.922011137008667
Validation loss: 2.628263158182944

Epoch: 6| Step: 6
Training loss: 2.562438726425171
Validation loss: 2.6230579371093423

Epoch: 6| Step: 7
Training loss: 2.9189624786376953
Validation loss: 2.6232543478729906

Epoch: 6| Step: 8
Training loss: 2.0499768257141113
Validation loss: 2.697198921634305

Epoch: 6| Step: 9
Training loss: 3.6078951358795166
Validation loss: 2.741842016097038

Epoch: 6| Step: 10
Training loss: 2.3312244415283203
Validation loss: 2.744959500528151

Epoch: 6| Step: 11
Training loss: 2.734952926635742
Validation loss: 2.7267894283417733

Epoch: 6| Step: 12
Training loss: 2.986751079559326
Validation loss: 2.7182120456490466

Epoch: 6| Step: 13
Training loss: 3.1433706283569336
Validation loss: 2.710669307298558

Epoch: 26| Step: 0
Training loss: 2.5741653442382812
Validation loss: 2.6864612076872136

Epoch: 6| Step: 1
Training loss: 2.8207993507385254
Validation loss: 2.689008092367521

Epoch: 6| Step: 2
Training loss: 3.169445037841797
Validation loss: 2.688118037357125

Epoch: 6| Step: 3
Training loss: 2.7304646968841553
Validation loss: 2.70004330911944

Epoch: 6| Step: 4
Training loss: 3.4067459106445312
Validation loss: 2.6954231723662345

Epoch: 6| Step: 5
Training loss: 3.409384250640869
Validation loss: 2.7063961259780394

Epoch: 6| Step: 6
Training loss: 1.8611968755722046
Validation loss: 2.6974426495131625

Epoch: 6| Step: 7
Training loss: 3.080796241760254
Validation loss: 2.679217800017326

Epoch: 6| Step: 8
Training loss: 2.948826789855957
Validation loss: 2.6738102051519577

Epoch: 6| Step: 9
Training loss: 3.3057708740234375
Validation loss: 2.6679033156364196

Epoch: 6| Step: 10
Training loss: 2.4853219985961914
Validation loss: 2.6678020261949107

Epoch: 6| Step: 11
Training loss: 2.9250426292419434
Validation loss: 2.670384204515847

Epoch: 6| Step: 12
Training loss: 2.5741448402404785
Validation loss: 2.66838175507002

Epoch: 6| Step: 13
Training loss: 2.196892499923706
Validation loss: 2.666018716750606

Epoch: 27| Step: 0
Training loss: 3.5237863063812256
Validation loss: 2.669672163583899

Epoch: 6| Step: 1
Training loss: 3.023982286453247
Validation loss: 2.6727248878889185

Epoch: 6| Step: 2
Training loss: 3.1799497604370117
Validation loss: 2.6761735357264036

Epoch: 6| Step: 3
Training loss: 3.3146324157714844
Validation loss: 2.6850503106271066

Epoch: 6| Step: 4
Training loss: 2.630760431289673
Validation loss: 2.677187740161855

Epoch: 6| Step: 5
Training loss: 2.558673143386841
Validation loss: 2.6700735527981996

Epoch: 6| Step: 6
Training loss: 2.490234613418579
Validation loss: 2.6720354608310166

Epoch: 6| Step: 7
Training loss: 3.1675970554351807
Validation loss: 2.664056290862381

Epoch: 6| Step: 8
Training loss: 2.141960859298706
Validation loss: 2.6526262734525945

Epoch: 6| Step: 9
Training loss: 3.1029810905456543
Validation loss: 2.6592244025199645

Epoch: 6| Step: 10
Training loss: 2.920501947402954
Validation loss: 2.655887988305861

Epoch: 6| Step: 11
Training loss: 2.494206666946411
Validation loss: 2.6482361465372066

Epoch: 6| Step: 12
Training loss: 1.8402695655822754
Validation loss: 2.6164543218510126

Epoch: 6| Step: 13
Training loss: 3.4297566413879395
Validation loss: 2.595866257144559

Epoch: 28| Step: 0
Training loss: 2.360858917236328
Validation loss: 2.6024325252861105

Epoch: 6| Step: 1
Training loss: 2.809386730194092
Validation loss: 2.6140731996105564

Epoch: 6| Step: 2
Training loss: 2.525632381439209
Validation loss: 2.606484715656568

Epoch: 6| Step: 3
Training loss: 3.142416000366211
Validation loss: 2.5997451838626655

Epoch: 6| Step: 4
Training loss: 2.8297839164733887
Validation loss: 2.5889903447961293

Epoch: 6| Step: 5
Training loss: 2.8241567611694336
Validation loss: 2.5957389698233655

Epoch: 6| Step: 6
Training loss: 3.044281244277954
Validation loss: 2.5837920250431186

Epoch: 6| Step: 7
Training loss: 3.2089366912841797
Validation loss: 2.5852656928441857

Epoch: 6| Step: 8
Training loss: 3.417009115219116
Validation loss: 2.5873378579334547

Epoch: 6| Step: 9
Training loss: 2.409005880355835
Validation loss: 2.5870791327568794

Epoch: 6| Step: 10
Training loss: 2.0484988689422607
Validation loss: 2.5836327332322315

Epoch: 6| Step: 11
Training loss: 2.85976243019104
Validation loss: 2.584524710973104

Epoch: 6| Step: 12
Training loss: 2.8853073120117188
Validation loss: 2.5881073295429187

Epoch: 6| Step: 13
Training loss: 2.5195558071136475
Validation loss: 2.6013336156004216

Epoch: 29| Step: 0
Training loss: 2.385362148284912
Validation loss: 2.6219259564594557

Epoch: 6| Step: 1
Training loss: 2.72208571434021
Validation loss: 2.6414769080377396

Epoch: 6| Step: 2
Training loss: 3.1128501892089844
Validation loss: 2.672586615367602

Epoch: 6| Step: 3
Training loss: 3.1772875785827637
Validation loss: 2.6601875853794876

Epoch: 6| Step: 4
Training loss: 2.2333850860595703
Validation loss: 2.619157801392258

Epoch: 6| Step: 5
Training loss: 2.7234580516815186
Validation loss: 2.594332433515979

Epoch: 6| Step: 6
Training loss: 3.43365740776062
Validation loss: 2.5825268709531395

Epoch: 6| Step: 7
Training loss: 2.724414348602295
Validation loss: 2.5847834207678355

Epoch: 6| Step: 8
Training loss: 2.92587947845459
Validation loss: 2.595180167946764

Epoch: 6| Step: 9
Training loss: 2.213716983795166
Validation loss: 2.6059414417512956

Epoch: 6| Step: 10
Training loss: 2.324923276901245
Validation loss: 2.6084351616521038

Epoch: 6| Step: 11
Training loss: 2.857306480407715
Validation loss: 2.600396666475522

Epoch: 6| Step: 12
Training loss: 2.8377785682678223
Validation loss: 2.5918683851918867

Epoch: 6| Step: 13
Training loss: 3.8782010078430176
Validation loss: 2.586757572748328

Epoch: 30| Step: 0
Training loss: 2.733132839202881
Validation loss: 2.5793084918811755

Epoch: 6| Step: 1
Training loss: 3.281019449234009
Validation loss: 2.5717085048716557

Epoch: 6| Step: 2
Training loss: 3.009627342224121
Validation loss: 2.5712105458782566

Epoch: 6| Step: 3
Training loss: 2.4130196571350098
Validation loss: 2.572748368786227

Epoch: 6| Step: 4
Training loss: 2.7254886627197266
Validation loss: 2.5727446463800248

Epoch: 6| Step: 5
Training loss: 2.471660614013672
Validation loss: 2.5883551848832

Epoch: 6| Step: 6
Training loss: 2.2523012161254883
Validation loss: 2.581559658050537

Epoch: 6| Step: 7
Training loss: 3.1396007537841797
Validation loss: 2.58837305602207

Epoch: 6| Step: 8
Training loss: 2.1038577556610107
Validation loss: 2.5913957472770446

Epoch: 6| Step: 9
Training loss: 3.65816068649292
Validation loss: 2.585815980870237

Epoch: 6| Step: 10
Training loss: 2.7768006324768066
Validation loss: 2.588603465787826

Epoch: 6| Step: 11
Training loss: 3.1144275665283203
Validation loss: 2.5753087151435112

Epoch: 6| Step: 12
Training loss: 2.525266170501709
Validation loss: 2.571026994336036

Epoch: 6| Step: 13
Training loss: 2.3014817237854004
Validation loss: 2.568520710032473

Epoch: 31| Step: 0
Training loss: 2.9037861824035645
Validation loss: 2.5697795396210044

Epoch: 6| Step: 1
Training loss: 2.143906354904175
Validation loss: 2.56664708352858

Epoch: 6| Step: 2
Training loss: 2.8043084144592285
Validation loss: 2.5672859273931032

Epoch: 6| Step: 3
Training loss: 2.8621888160705566
Validation loss: 2.567894507479924

Epoch: 6| Step: 4
Training loss: 2.879725217819214
Validation loss: 2.5682107299886723

Epoch: 6| Step: 5
Training loss: 2.6705827713012695
Validation loss: 2.5679926987617248

Epoch: 6| Step: 6
Training loss: 3.0966055393218994
Validation loss: 2.569626215965517

Epoch: 6| Step: 7
Training loss: 2.2539148330688477
Validation loss: 2.566942640530166

Epoch: 6| Step: 8
Training loss: 2.627007007598877
Validation loss: 2.561862322591966

Epoch: 6| Step: 9
Training loss: 2.7949466705322266
Validation loss: 2.563893997541038

Epoch: 6| Step: 10
Training loss: 2.810941696166992
Validation loss: 2.560065864234842

Epoch: 6| Step: 11
Training loss: 3.2216150760650635
Validation loss: 2.5668965103805705

Epoch: 6| Step: 12
Training loss: 2.8793818950653076
Validation loss: 2.561576692006921

Epoch: 6| Step: 13
Training loss: 2.5357210636138916
Validation loss: 2.563657873420305

Epoch: 32| Step: 0
Training loss: 2.992722749710083
Validation loss: 2.560811763168663

Epoch: 6| Step: 1
Training loss: 2.530630588531494
Validation loss: 2.561718386988486

Epoch: 6| Step: 2
Training loss: 2.7912843227386475
Validation loss: 2.5631451324750016

Epoch: 6| Step: 3
Training loss: 3.37019681930542
Validation loss: 2.5628746606970347

Epoch: 6| Step: 4
Training loss: 2.049105644226074
Validation loss: 2.5628178965660835

Epoch: 6| Step: 5
Training loss: 2.2411112785339355
Validation loss: 2.5627842641645864

Epoch: 6| Step: 6
Training loss: 3.4216442108154297
Validation loss: 2.5602183803435294

Epoch: 6| Step: 7
Training loss: 2.376011610031128
Validation loss: 2.5548436872420774

Epoch: 6| Step: 8
Training loss: 2.757038116455078
Validation loss: 2.552403288502847

Epoch: 6| Step: 9
Training loss: 2.3170623779296875
Validation loss: 2.554398872519052

Epoch: 6| Step: 10
Training loss: 3.2033963203430176
Validation loss: 2.557603397677022

Epoch: 6| Step: 11
Training loss: 2.838304281234741
Validation loss: 2.5570516560667302

Epoch: 6| Step: 12
Training loss: 2.9727673530578613
Validation loss: 2.5517256516282276

Epoch: 6| Step: 13
Training loss: 2.645508050918579
Validation loss: 2.557415844291769

Epoch: 33| Step: 0
Training loss: 2.2332658767700195
Validation loss: 2.554995165076307

Epoch: 6| Step: 1
Training loss: 2.041684150695801
Validation loss: 2.5491572938939577

Epoch: 6| Step: 2
Training loss: 2.8704681396484375
Validation loss: 2.5593593248756985

Epoch: 6| Step: 3
Training loss: 2.824162483215332
Validation loss: 2.5598132020683697

Epoch: 6| Step: 4
Training loss: 2.589158058166504
Validation loss: 2.563729411812239

Epoch: 6| Step: 5
Training loss: 3.648256778717041
Validation loss: 2.5621623685283046

Epoch: 6| Step: 6
Training loss: 3.381206750869751
Validation loss: 2.55339490982794

Epoch: 6| Step: 7
Training loss: 2.459611415863037
Validation loss: 2.5512910735222603

Epoch: 6| Step: 8
Training loss: 2.351271152496338
Validation loss: 2.550923639728177

Epoch: 6| Step: 9
Training loss: 2.8305232524871826
Validation loss: 2.5519813978543846

Epoch: 6| Step: 10
Training loss: 2.583211898803711
Validation loss: 2.5500127628285396

Epoch: 6| Step: 11
Training loss: 3.2449584007263184
Validation loss: 2.550534879007647

Epoch: 6| Step: 12
Training loss: 2.5211713314056396
Validation loss: 2.5563486263316166

Epoch: 6| Step: 13
Training loss: 2.8777174949645996
Validation loss: 2.5571103634372836

Epoch: 34| Step: 0
Training loss: 2.9555389881134033
Validation loss: 2.554832919951408

Epoch: 6| Step: 1
Training loss: 2.492351531982422
Validation loss: 2.5675362899739254

Epoch: 6| Step: 2
Training loss: 2.5003461837768555
Validation loss: 2.560477913066905

Epoch: 6| Step: 3
Training loss: 2.7238731384277344
Validation loss: 2.555102568800731

Epoch: 6| Step: 4
Training loss: 2.9973907470703125
Validation loss: 2.5503697908052834

Epoch: 6| Step: 5
Training loss: 2.8468270301818848
Validation loss: 2.5478727227898053

Epoch: 6| Step: 6
Training loss: 2.4094018936157227
Validation loss: 2.545648656865602

Epoch: 6| Step: 7
Training loss: 3.1928248405456543
Validation loss: 2.5466534450489986

Epoch: 6| Step: 8
Training loss: 3.1588826179504395
Validation loss: 2.5511418927100395

Epoch: 6| Step: 9
Training loss: 2.961026668548584
Validation loss: 2.5666202960475797

Epoch: 6| Step: 10
Training loss: 2.9634368419647217
Validation loss: 2.5729911493998703

Epoch: 6| Step: 11
Training loss: 2.392119884490967
Validation loss: 2.5632608885406167

Epoch: 6| Step: 12
Training loss: 1.9697332382202148
Validation loss: 2.5577226813121507

Epoch: 6| Step: 13
Training loss: 2.991368293762207
Validation loss: 2.5458593496712307

Epoch: 35| Step: 0
Training loss: 2.2947568893432617
Validation loss: 2.5345961406666744

Epoch: 6| Step: 1
Training loss: 2.457289934158325
Validation loss: 2.537510315577189

Epoch: 6| Step: 2
Training loss: 2.2244932651519775
Validation loss: 2.5375602117148777

Epoch: 6| Step: 3
Training loss: 2.4686083793640137
Validation loss: 2.535944607950026

Epoch: 6| Step: 4
Training loss: 3.0859174728393555
Validation loss: 2.535988125749814

Epoch: 6| Step: 5
Training loss: 2.3067057132720947
Validation loss: 2.5324762713524605

Epoch: 6| Step: 6
Training loss: 3.176523208618164
Validation loss: 2.533492188299856

Epoch: 6| Step: 7
Training loss: 3.1631717681884766
Validation loss: 2.5341932107043523

Epoch: 6| Step: 8
Training loss: 2.6873228549957275
Validation loss: 2.534595053683045

Epoch: 6| Step: 9
Training loss: 3.2896580696105957
Validation loss: 2.5290590486218854

Epoch: 6| Step: 10
Training loss: 2.5680198669433594
Validation loss: 2.537904723998039

Epoch: 6| Step: 11
Training loss: 3.2880988121032715
Validation loss: 2.541686108035426

Epoch: 6| Step: 12
Training loss: 1.9634783267974854
Validation loss: 2.544025287833265

Epoch: 6| Step: 13
Training loss: 3.750270366668701
Validation loss: 2.55020506663989

Epoch: 36| Step: 0
Training loss: 2.7721190452575684
Validation loss: 2.558836998478059

Epoch: 6| Step: 1
Training loss: 1.7989988327026367
Validation loss: 2.5509997439640824

Epoch: 6| Step: 2
Training loss: 2.1075234413146973
Validation loss: 2.536103904888194

Epoch: 6| Step: 3
Training loss: 2.7352800369262695
Validation loss: 2.5318332128627326

Epoch: 6| Step: 4
Training loss: 2.6125059127807617
Validation loss: 2.5352029338959725

Epoch: 6| Step: 5
Training loss: 3.73435115814209
Validation loss: 2.5376799644962436

Epoch: 6| Step: 6
Training loss: 2.560974359512329
Validation loss: 2.535723706727387

Epoch: 6| Step: 7
Training loss: 2.7088422775268555
Validation loss: 2.5350006421407065

Epoch: 6| Step: 8
Training loss: 1.893244743347168
Validation loss: 2.5277270758023827

Epoch: 6| Step: 9
Training loss: 2.2724952697753906
Validation loss: 2.5291557337648127

Epoch: 6| Step: 10
Training loss: 3.0968384742736816
Validation loss: 2.5273683660773822

Epoch: 6| Step: 11
Training loss: 3.7364249229431152
Validation loss: 2.525681523866551

Epoch: 6| Step: 12
Training loss: 2.9345366954803467
Validation loss: 2.532322983587942

Epoch: 6| Step: 13
Training loss: 3.9068729877471924
Validation loss: 2.542406851245511

Epoch: 37| Step: 0
Training loss: 2.3822782039642334
Validation loss: 2.5418827790085987

Epoch: 6| Step: 1
Training loss: 2.1417670249938965
Validation loss: 2.5483640470812396

Epoch: 6| Step: 2
Training loss: 2.3617842197418213
Validation loss: 2.5506992673361175

Epoch: 6| Step: 3
Training loss: 3.16752290725708
Validation loss: 2.538910150527954

Epoch: 6| Step: 4
Training loss: 3.3064253330230713
Validation loss: 2.530685491459344

Epoch: 6| Step: 5
Training loss: 2.302863359451294
Validation loss: 2.5234822073290424

Epoch: 6| Step: 6
Training loss: 2.920931339263916
Validation loss: 2.5257929832704606

Epoch: 6| Step: 7
Training loss: 1.69060480594635
Validation loss: 2.5210648967373754

Epoch: 6| Step: 8
Training loss: 3.401160717010498
Validation loss: 2.524112016923966

Epoch: 6| Step: 9
Training loss: 2.847414493560791
Validation loss: 2.520027542626986

Epoch: 6| Step: 10
Training loss: 2.957371234893799
Validation loss: 2.5203262388065295

Epoch: 6| Step: 11
Training loss: 2.6601755619049072
Validation loss: 2.52077668200257

Epoch: 6| Step: 12
Training loss: 3.0128445625305176
Validation loss: 2.522914509619436

Epoch: 6| Step: 13
Training loss: 3.220050096511841
Validation loss: 2.520310068643221

Epoch: 38| Step: 0
Training loss: 3.0677661895751953
Validation loss: 2.523139376794138

Epoch: 6| Step: 1
Training loss: 2.929212808609009
Validation loss: 2.5188831462655017

Epoch: 6| Step: 2
Training loss: 2.2593154907226562
Validation loss: 2.5225196423069125

Epoch: 6| Step: 3
Training loss: 2.926875352859497
Validation loss: 2.5159843275623937

Epoch: 6| Step: 4
Training loss: 2.948345899581909
Validation loss: 2.5173661862650225

Epoch: 6| Step: 5
Training loss: 3.063678741455078
Validation loss: 2.515975862421015

Epoch: 6| Step: 6
Training loss: 2.6807332038879395
Validation loss: 2.5244408833083285

Epoch: 6| Step: 7
Training loss: 2.5680112838745117
Validation loss: 2.521729359062769

Epoch: 6| Step: 8
Training loss: 2.735215663909912
Validation loss: 2.5187780472540084

Epoch: 6| Step: 9
Training loss: 2.431939125061035
Validation loss: 2.519188037482641

Epoch: 6| Step: 10
Training loss: 2.966482162475586
Validation loss: 2.5251926606701267

Epoch: 6| Step: 11
Training loss: 2.5202410221099854
Validation loss: 2.5373755347344185

Epoch: 6| Step: 12
Training loss: 1.9219727516174316
Validation loss: 2.5371373597011773

Epoch: 6| Step: 13
Training loss: 3.3624463081359863
Validation loss: 2.5295847590251634

Epoch: 39| Step: 0
Training loss: 3.483849048614502
Validation loss: 2.524034530885758

Epoch: 6| Step: 1
Training loss: 2.3194446563720703
Validation loss: 2.520091349078763

Epoch: 6| Step: 2
Training loss: 2.5592637062072754
Validation loss: 2.5181598048056326

Epoch: 6| Step: 3
Training loss: 2.5890824794769287
Validation loss: 2.5190367057759273

Epoch: 6| Step: 4
Training loss: 3.201751232147217
Validation loss: 2.521886794797836

Epoch: 6| Step: 5
Training loss: 2.203979969024658
Validation loss: 2.553104385252922

Epoch: 6| Step: 6
Training loss: 2.277944326400757
Validation loss: 2.5557020735997025

Epoch: 6| Step: 7
Training loss: 3.087615728378296
Validation loss: 2.577087028052217

Epoch: 6| Step: 8
Training loss: 3.646648645401001
Validation loss: 2.5307213080826627

Epoch: 6| Step: 9
Training loss: 2.960970401763916
Validation loss: 2.518138513770155

Epoch: 6| Step: 10
Training loss: 2.586894989013672
Validation loss: 2.5170607272014824

Epoch: 6| Step: 11
Training loss: 2.5297298431396484
Validation loss: 2.520773195451306

Epoch: 6| Step: 12
Training loss: 2.308094024658203
Validation loss: 2.5339582607310307

Epoch: 6| Step: 13
Training loss: 2.1332645416259766
Validation loss: 2.539398875287784

Epoch: 40| Step: 0
Training loss: 2.9886980056762695
Validation loss: 2.535843785091113

Epoch: 6| Step: 1
Training loss: 2.7244322299957275
Validation loss: 2.5526857581189883

Epoch: 6| Step: 2
Training loss: 4.283464431762695
Validation loss: 2.547539536670972

Epoch: 6| Step: 3
Training loss: 2.776076078414917
Validation loss: 2.524937152862549

Epoch: 6| Step: 4
Training loss: 3.0892717838287354
Validation loss: 2.514892247415358

Epoch: 6| Step: 5
Training loss: 2.1443982124328613
Validation loss: 2.5155698201989614

Epoch: 6| Step: 6
Training loss: 2.5311594009399414
Validation loss: 2.5218422259053876

Epoch: 6| Step: 7
Training loss: 2.21689510345459
Validation loss: 2.515034919144005

Epoch: 6| Step: 8
Training loss: 2.240729808807373
Validation loss: 2.5188297558856267

Epoch: 6| Step: 9
Training loss: 2.9080216884613037
Validation loss: 2.5174095681918565

Epoch: 6| Step: 10
Training loss: 2.55958890914917
Validation loss: 2.525620037509549

Epoch: 6| Step: 11
Training loss: 2.9556312561035156
Validation loss: 2.539916806323554

Epoch: 6| Step: 12
Training loss: 1.9377715587615967
Validation loss: 2.5227043423601376

Epoch: 6| Step: 13
Training loss: 3.0191047191619873
Validation loss: 2.517313970032559

Epoch: 41| Step: 0
Training loss: 2.118647575378418
Validation loss: 2.515403921886157

Epoch: 6| Step: 1
Training loss: 2.782771348953247
Validation loss: 2.510232217850224

Epoch: 6| Step: 2
Training loss: 2.0356879234313965
Validation loss: 2.5078572868019022

Epoch: 6| Step: 3
Training loss: 2.9185736179351807
Validation loss: 2.5119813924194663

Epoch: 6| Step: 4
Training loss: 3.1272783279418945
Validation loss: 2.5174842701163342

Epoch: 6| Step: 5
Training loss: 2.6565403938293457
Validation loss: 2.5175723004084762

Epoch: 6| Step: 6
Training loss: 3.0916435718536377
Validation loss: 2.5216647912097234

Epoch: 6| Step: 7
Training loss: 2.975423812866211
Validation loss: 2.5154568738834833

Epoch: 6| Step: 8
Training loss: 2.093453884124756
Validation loss: 2.5088441423190537

Epoch: 6| Step: 9
Training loss: 3.7000045776367188
Validation loss: 2.50902811942562

Epoch: 6| Step: 10
Training loss: 2.1532936096191406
Validation loss: 2.5036173225730978

Epoch: 6| Step: 11
Training loss: 2.338437795639038
Validation loss: 2.5058193514423985

Epoch: 6| Step: 12
Training loss: 3.2386131286621094
Validation loss: 2.5059424779748403

Epoch: 6| Step: 13
Training loss: 2.8249897956848145
Validation loss: 2.501881471244238

Epoch: 42| Step: 0
Training loss: 2.588560104370117
Validation loss: 2.5114013071983092

Epoch: 6| Step: 1
Training loss: 1.757948637008667
Validation loss: 2.509023940691384

Epoch: 6| Step: 2
Training loss: 3.1553292274475098
Validation loss: 2.5041691423744283

Epoch: 6| Step: 3
Training loss: 2.416390895843506
Validation loss: 2.5052493362016577

Epoch: 6| Step: 4
Training loss: 1.9747436046600342
Validation loss: 2.5025404935242026

Epoch: 6| Step: 5
Training loss: 3.270298480987549
Validation loss: 2.5033358104767336

Epoch: 6| Step: 6
Training loss: 3.261746406555176
Validation loss: 2.5079845407957673

Epoch: 6| Step: 7
Training loss: 3.253702163696289
Validation loss: 2.511656161277525

Epoch: 6| Step: 8
Training loss: 2.792130947113037
Validation loss: 2.5057547092437744

Epoch: 6| Step: 9
Training loss: 2.8381996154785156
Validation loss: 2.512582673821398

Epoch: 6| Step: 10
Training loss: 2.599541664123535
Validation loss: 2.5171369634648806

Epoch: 6| Step: 11
Training loss: 2.055349826812744
Validation loss: 2.5151075265740834

Epoch: 6| Step: 12
Training loss: 3.478771924972534
Validation loss: 2.5047171551694154

Epoch: 6| Step: 13
Training loss: 2.1972670555114746
Validation loss: 2.5060982037616033

Epoch: 43| Step: 0
Training loss: 2.4669013023376465
Validation loss: 2.5006861968707015

Epoch: 6| Step: 1
Training loss: 3.5587687492370605
Validation loss: 2.5066281544264926

Epoch: 6| Step: 2
Training loss: 2.8099985122680664
Validation loss: 2.5073981003094743

Epoch: 6| Step: 3
Training loss: 2.79426646232605
Validation loss: 2.5101578927809194

Epoch: 6| Step: 4
Training loss: 2.4801061153411865
Validation loss: 2.4995012847326135

Epoch: 6| Step: 5
Training loss: 2.6403403282165527
Validation loss: 2.5009368722156813

Epoch: 6| Step: 6
Training loss: 3.4021482467651367
Validation loss: 2.500201250917168

Epoch: 6| Step: 7
Training loss: 2.5970687866210938
Validation loss: 2.501884598885813

Epoch: 6| Step: 8
Training loss: 1.8958532810211182
Validation loss: 2.498646218289611

Epoch: 6| Step: 9
Training loss: 2.4158267974853516
Validation loss: 2.5143963803527174

Epoch: 6| Step: 10
Training loss: 2.3943867683410645
Validation loss: 2.517205487015427

Epoch: 6| Step: 11
Training loss: 2.815488338470459
Validation loss: 2.5173697445982244

Epoch: 6| Step: 12
Training loss: 3.13909649848938
Validation loss: 2.525748129813902

Epoch: 6| Step: 13
Training loss: 2.20354962348938
Validation loss: 2.517787988467883

Epoch: 44| Step: 0
Training loss: 2.5772454738616943
Validation loss: 2.5066345763462845

Epoch: 6| Step: 1
Training loss: 2.184887409210205
Validation loss: 2.505885160097512

Epoch: 6| Step: 2
Training loss: 2.9242842197418213
Validation loss: 2.4980780437428463

Epoch: 6| Step: 3
Training loss: 2.1135878562927246
Validation loss: 2.4960462380481023

Epoch: 6| Step: 4
Training loss: 2.469270706176758
Validation loss: 2.494034920969317

Epoch: 6| Step: 5
Training loss: 2.8949532508850098
Validation loss: 2.4939638799236667

Epoch: 6| Step: 6
Training loss: 2.4508790969848633
Validation loss: 2.4981564424371205

Epoch: 6| Step: 7
Training loss: 2.7185206413269043
Validation loss: 2.4946694348448064

Epoch: 6| Step: 8
Training loss: 3.3902435302734375
Validation loss: 2.494503467313705

Epoch: 6| Step: 9
Training loss: 2.5115575790405273
Validation loss: 2.495627974951139

Epoch: 6| Step: 10
Training loss: 2.454850196838379
Validation loss: 2.4963281744269916

Epoch: 6| Step: 11
Training loss: 2.9784605503082275
Validation loss: 2.497816801071167

Epoch: 6| Step: 12
Training loss: 2.741694927215576
Validation loss: 2.4977426887840353

Epoch: 6| Step: 13
Training loss: 3.903512716293335
Validation loss: 2.495374543692476

Epoch: 45| Step: 0
Training loss: 2.744502305984497
Validation loss: 2.493850541371171

Epoch: 6| Step: 1
Training loss: 2.505924701690674
Validation loss: 2.4952833396132275

Epoch: 6| Step: 2
Training loss: 2.4043593406677246
Validation loss: 2.4928829798134426

Epoch: 6| Step: 3
Training loss: 2.3027000427246094
Validation loss: 2.490856780800768

Epoch: 6| Step: 4
Training loss: 2.269235134124756
Validation loss: 2.493882497151693

Epoch: 6| Step: 5
Training loss: 2.5819811820983887
Validation loss: 2.494037328227874

Epoch: 6| Step: 6
Training loss: 2.5311026573181152
Validation loss: 2.491135181919221

Epoch: 6| Step: 7
Training loss: 3.312220573425293
Validation loss: 2.48942929954939

Epoch: 6| Step: 8
Training loss: 2.433495044708252
Validation loss: 2.488641885019118

Epoch: 6| Step: 9
Training loss: 3.191157579421997
Validation loss: 2.4939830328828547

Epoch: 6| Step: 10
Training loss: 2.7420506477355957
Validation loss: 2.4907926282575055

Epoch: 6| Step: 11
Training loss: 3.246394157409668
Validation loss: 2.491290074522777

Epoch: 6| Step: 12
Training loss: 2.32198166847229
Validation loss: 2.4956440284687984

Epoch: 6| Step: 13
Training loss: 3.5583958625793457
Validation loss: 2.5059805095836682

Epoch: 46| Step: 0
Training loss: 3.432487726211548
Validation loss: 2.519886193736907

Epoch: 6| Step: 1
Training loss: 2.556328296661377
Validation loss: 2.516173344786449

Epoch: 6| Step: 2
Training loss: 3.0567429065704346
Validation loss: 2.523955093917026

Epoch: 6| Step: 3
Training loss: 3.3010830879211426
Validation loss: 2.5093243173373643

Epoch: 6| Step: 4
Training loss: 2.9343795776367188
Validation loss: 2.4943766568296697

Epoch: 6| Step: 5
Training loss: 2.5646800994873047
Validation loss: 2.4908043312770065

Epoch: 6| Step: 6
Training loss: 2.040715217590332
Validation loss: 2.4851307971503145

Epoch: 6| Step: 7
Training loss: 1.9737207889556885
Validation loss: 2.4899827587989067

Epoch: 6| Step: 8
Training loss: 2.9308810234069824
Validation loss: 2.4931419818632063

Epoch: 6| Step: 9
Training loss: 2.7239415645599365
Validation loss: 2.489163524361067

Epoch: 6| Step: 10
Training loss: 2.4200973510742188
Validation loss: 2.493938430663078

Epoch: 6| Step: 11
Training loss: 2.9493067264556885
Validation loss: 2.496062760711998

Epoch: 6| Step: 12
Training loss: 2.3022637367248535
Validation loss: 2.491743774824245

Epoch: 6| Step: 13
Training loss: 2.529029369354248
Validation loss: 2.4929991845161683

Epoch: 47| Step: 0
Training loss: 2.861879348754883
Validation loss: 2.494898893499887

Epoch: 6| Step: 1
Training loss: 2.775167465209961
Validation loss: 2.4946446726399083

Epoch: 6| Step: 2
Training loss: 2.877774715423584
Validation loss: 2.5016969685913413

Epoch: 6| Step: 3
Training loss: 2.65755558013916
Validation loss: 2.4960709925620788

Epoch: 6| Step: 4
Training loss: 2.162886619567871
Validation loss: 2.492628656407838

Epoch: 6| Step: 5
Training loss: 2.287147045135498
Validation loss: 2.4896081186109975

Epoch: 6| Step: 6
Training loss: 2.359030246734619
Validation loss: 2.4886910505192255

Epoch: 6| Step: 7
Training loss: 2.1937923431396484
Validation loss: 2.486223766880651

Epoch: 6| Step: 8
Training loss: 3.146024227142334
Validation loss: 2.4904290347970943

Epoch: 6| Step: 9
Training loss: 2.8379015922546387
Validation loss: 2.481432545569635

Epoch: 6| Step: 10
Training loss: 3.5064077377319336
Validation loss: 2.485071941088605

Epoch: 6| Step: 11
Training loss: 2.328765869140625
Validation loss: 2.48011637503101

Epoch: 6| Step: 12
Training loss: 2.3945508003234863
Validation loss: 2.482242363755421

Epoch: 6| Step: 13
Training loss: 3.6919336318969727
Validation loss: 2.4792792079269246

Epoch: 48| Step: 0
Training loss: 2.4916720390319824
Validation loss: 2.483759774956652

Epoch: 6| Step: 1
Training loss: 1.621751308441162
Validation loss: 2.475848742710647

Epoch: 6| Step: 2
Training loss: 2.2186779975891113
Validation loss: 2.4819983102942027

Epoch: 6| Step: 3
Training loss: 2.8246262073516846
Validation loss: 2.478166203345022

Epoch: 6| Step: 4
Training loss: 3.0072593688964844
Validation loss: 2.4869542762797368

Epoch: 6| Step: 5
Training loss: 2.6276988983154297
Validation loss: 2.4871718652786745

Epoch: 6| Step: 6
Training loss: 3.008331298828125
Validation loss: 2.493850597771265

Epoch: 6| Step: 7
Training loss: 2.7055397033691406
Validation loss: 2.501135218528009

Epoch: 6| Step: 8
Training loss: 2.6215288639068604
Validation loss: 2.499292794094291

Epoch: 6| Step: 9
Training loss: 3.371265411376953
Validation loss: 2.4914402628457673

Epoch: 6| Step: 10
Training loss: 3.0335845947265625
Validation loss: 2.487522412371892

Epoch: 6| Step: 11
Training loss: 3.117339849472046
Validation loss: 2.4915725313207155

Epoch: 6| Step: 12
Training loss: 2.4518206119537354
Validation loss: 2.4861482292093258

Epoch: 6| Step: 13
Training loss: 2.4196271896362305
Validation loss: 2.4853329325235016

Epoch: 49| Step: 0
Training loss: 3.260897159576416
Validation loss: 2.481922980277769

Epoch: 6| Step: 1
Training loss: 2.8949222564697266
Validation loss: 2.481617268695626

Epoch: 6| Step: 2
Training loss: 2.8562991619110107
Validation loss: 2.4890299381748324

Epoch: 6| Step: 3
Training loss: 1.7937943935394287
Validation loss: 2.498880724753103

Epoch: 6| Step: 4
Training loss: 2.536691188812256
Validation loss: 2.4985600312550864

Epoch: 6| Step: 5
Training loss: 2.2524468898773193
Validation loss: 2.503765598420174

Epoch: 6| Step: 6
Training loss: 2.3610596656799316
Validation loss: 2.5098765434757357

Epoch: 6| Step: 7
Training loss: 2.4641456604003906
Validation loss: 2.507824444001721

Epoch: 6| Step: 8
Training loss: 2.5386757850646973
Validation loss: 2.5000045248257217

Epoch: 6| Step: 9
Training loss: 2.761972427368164
Validation loss: 2.4956284440973753

Epoch: 6| Step: 10
Training loss: 2.54408597946167
Validation loss: 2.4942415875773274

Epoch: 6| Step: 11
Training loss: 3.0259218215942383
Validation loss: 2.489339813109367

Epoch: 6| Step: 12
Training loss: 2.9954833984375
Validation loss: 2.4830995452019478

Epoch: 6| Step: 13
Training loss: 3.7569422721862793
Validation loss: 2.4815224165557535

Epoch: 50| Step: 0
Training loss: 2.9043922424316406
Validation loss: 2.4809063480746363

Epoch: 6| Step: 1
Training loss: 2.7219436168670654
Validation loss: 2.4786411536637174

Epoch: 6| Step: 2
Training loss: 3.1221742630004883
Validation loss: 2.4759358693194646

Epoch: 6| Step: 3
Training loss: 2.83596134185791
Validation loss: 2.4767831833131853

Epoch: 6| Step: 4
Training loss: 2.7963409423828125
Validation loss: 2.4779394467671714

Epoch: 6| Step: 5
Training loss: 3.164616107940674
Validation loss: 2.475125676842146

Epoch: 6| Step: 6
Training loss: 3.0841822624206543
Validation loss: 2.4719700992748304

Epoch: 6| Step: 7
Training loss: 1.878954291343689
Validation loss: 2.470043264409547

Epoch: 6| Step: 8
Training loss: 1.843709945678711
Validation loss: 2.470726383629666

Epoch: 6| Step: 9
Training loss: 2.076019048690796
Validation loss: 2.4675982639353764

Epoch: 6| Step: 10
Training loss: 2.4360570907592773
Validation loss: 2.4672544387079056

Epoch: 6| Step: 11
Training loss: 2.618983745574951
Validation loss: 2.4694884233577277

Epoch: 6| Step: 12
Training loss: 2.608407497406006
Validation loss: 2.479494138430524

Epoch: 6| Step: 13
Training loss: 3.9833459854125977
Validation loss: 2.5024900820947464

Testing loss: 2.595038832558526
