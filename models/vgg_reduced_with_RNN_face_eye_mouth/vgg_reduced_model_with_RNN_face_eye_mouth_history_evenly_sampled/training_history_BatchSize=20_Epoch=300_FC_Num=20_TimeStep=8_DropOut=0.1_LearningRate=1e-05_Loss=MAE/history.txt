Epoch: 1| Step: 0
Training loss: 6.280969142913818
Validation loss: 5.218229016950054

Epoch: 5| Step: 1
Training loss: 5.125075817108154
Validation loss: 5.204607004760414

Epoch: 5| Step: 2
Training loss: 4.770022869110107
Validation loss: 5.191171564081664

Epoch: 5| Step: 3
Training loss: 5.02298641204834
Validation loss: 5.1779751367466424

Epoch: 5| Step: 4
Training loss: 3.901038646697998
Validation loss: 5.165071020844162

Epoch: 5| Step: 5
Training loss: 4.294987678527832
Validation loss: 5.151420659916376

Epoch: 5| Step: 6
Training loss: 5.10745906829834
Validation loss: 5.1380181312561035

Epoch: 5| Step: 7
Training loss: 4.789128303527832
Validation loss: 5.123658651946693

Epoch: 5| Step: 8
Training loss: 4.4437994956970215
Validation loss: 5.108360787873627

Epoch: 5| Step: 9
Training loss: 5.2439985275268555
Validation loss: 5.09270086596089

Epoch: 5| Step: 10
Training loss: 5.521983623504639
Validation loss: 5.075545177664808

Epoch: 2| Step: 0
Training loss: 5.01602029800415
Validation loss: 5.057044906000937

Epoch: 5| Step: 1
Training loss: 4.894745826721191
Validation loss: 5.037181223592451

Epoch: 5| Step: 2
Training loss: 4.63034725189209
Validation loss: 5.016474990434544

Epoch: 5| Step: 3
Training loss: 4.741152763366699
Validation loss: 4.993223113398398

Epoch: 5| Step: 4
Training loss: 5.003214359283447
Validation loss: 4.969217141469319

Epoch: 5| Step: 5
Training loss: 5.020274639129639
Validation loss: 4.944454639188705

Epoch: 5| Step: 6
Training loss: 5.089662075042725
Validation loss: 4.917264963990899

Epoch: 5| Step: 7
Training loss: 4.012472152709961
Validation loss: 4.888582655178603

Epoch: 5| Step: 8
Training loss: 4.774146556854248
Validation loss: 4.857565049202211

Epoch: 5| Step: 9
Training loss: 4.744874000549316
Validation loss: 4.826165363352786

Epoch: 5| Step: 10
Training loss: 4.030141830444336
Validation loss: 4.793236983719693

Epoch: 3| Step: 0
Training loss: 4.835230827331543
Validation loss: 4.7592861472919425

Epoch: 5| Step: 1
Training loss: 2.83990740776062
Validation loss: 4.724308711226269

Epoch: 5| Step: 2
Training loss: 4.548550605773926
Validation loss: 4.689236835766864

Epoch: 5| Step: 3
Training loss: 4.486976623535156
Validation loss: 4.65216855079897

Epoch: 5| Step: 4
Training loss: 5.361061096191406
Validation loss: 4.616730741275254

Epoch: 5| Step: 5
Training loss: 3.509908676147461
Validation loss: 4.579368396471906

Epoch: 5| Step: 6
Training loss: 4.7928466796875
Validation loss: 4.543172656848866

Epoch: 5| Step: 7
Training loss: 4.68705940246582
Validation loss: 4.504871809354392

Epoch: 5| Step: 8
Training loss: 3.662930965423584
Validation loss: 4.468140232947565

Epoch: 5| Step: 9
Training loss: 4.554210186004639
Validation loss: 4.430809333760251

Epoch: 5| Step: 10
Training loss: 4.805703639984131
Validation loss: 4.395650099682552

Epoch: 4| Step: 0
Training loss: 5.249081611633301
Validation loss: 4.359582824091757

Epoch: 5| Step: 1
Training loss: 5.303179740905762
Validation loss: 4.326195811712614

Epoch: 5| Step: 2
Training loss: 3.884559154510498
Validation loss: 4.29055546176049

Epoch: 5| Step: 3
Training loss: 4.04602575302124
Validation loss: 4.257639838803199

Epoch: 5| Step: 4
Training loss: 4.021241188049316
Validation loss: 4.225192844226796

Epoch: 5| Step: 5
Training loss: 4.0452985763549805
Validation loss: 4.19429301702848

Epoch: 5| Step: 6
Training loss: 3.370063066482544
Validation loss: 4.16469862640545

Epoch: 5| Step: 7
Training loss: 3.810622453689575
Validation loss: 4.13405369686824

Epoch: 5| Step: 8
Training loss: 3.709226131439209
Validation loss: 4.104555350477978

Epoch: 5| Step: 9
Training loss: 3.109731674194336
Validation loss: 4.074578997909382

Epoch: 5| Step: 10
Training loss: 3.673478126525879
Validation loss: 4.0476283258007415

Epoch: 5| Step: 0
Training loss: 4.114013671875
Validation loss: 4.024462197416572

Epoch: 5| Step: 1
Training loss: 3.745964527130127
Validation loss: 4.005077351805984

Epoch: 5| Step: 2
Training loss: 4.513157844543457
Validation loss: 3.9896504443178893

Epoch: 5| Step: 3
Training loss: 3.373579502105713
Validation loss: 3.9702852361945697

Epoch: 5| Step: 4
Training loss: 2.466876268386841
Validation loss: 3.95019345642418

Epoch: 5| Step: 5
Training loss: 4.466667652130127
Validation loss: 3.9323857445870676

Epoch: 5| Step: 6
Training loss: 3.190232515335083
Validation loss: 3.9093243434864986

Epoch: 5| Step: 7
Training loss: 3.700697422027588
Validation loss: 3.889334617122527

Epoch: 5| Step: 8
Training loss: 4.1710686683654785
Validation loss: 3.872930916406775

Epoch: 5| Step: 9
Training loss: 4.319594383239746
Validation loss: 3.8572510391153316

Epoch: 5| Step: 10
Training loss: 3.7453670501708984
Validation loss: 3.8386897656225387

Epoch: 6| Step: 0
Training loss: 3.873816967010498
Validation loss: 3.815993719203498

Epoch: 5| Step: 1
Training loss: 3.197861433029175
Validation loss: 3.7938857847644436

Epoch: 5| Step: 2
Training loss: 4.052125930786133
Validation loss: 3.772199579464492

Epoch: 5| Step: 3
Training loss: 2.988192319869995
Validation loss: 3.7581314297132593

Epoch: 5| Step: 4
Training loss: 3.2594077587127686
Validation loss: 3.7384114470533145

Epoch: 5| Step: 5
Training loss: 3.4910519123077393
Validation loss: 3.7249700177100395

Epoch: 5| Step: 6
Training loss: 3.540271759033203
Validation loss: 3.7086793274007817

Epoch: 5| Step: 7
Training loss: 4.205327033996582
Validation loss: 3.69909091149607

Epoch: 5| Step: 8
Training loss: 4.024456977844238
Validation loss: 3.6816754648762364

Epoch: 5| Step: 9
Training loss: 3.329720973968506
Validation loss: 3.6670435218400854

Epoch: 5| Step: 10
Training loss: 3.93772029876709
Validation loss: 3.653529069756949

Epoch: 7| Step: 0
Training loss: 3.3633549213409424
Validation loss: 3.6386248937217136

Epoch: 5| Step: 1
Training loss: 3.60084867477417
Validation loss: 3.627769572760469

Epoch: 5| Step: 2
Training loss: 3.4443588256835938
Validation loss: 3.6178603787576

Epoch: 5| Step: 3
Training loss: 3.5390350818634033
Validation loss: 3.603521729028353

Epoch: 5| Step: 4
Training loss: 3.453700304031372
Validation loss: 3.587119020441527

Epoch: 5| Step: 5
Training loss: 2.752026319503784
Validation loss: 3.5729246575345277

Epoch: 5| Step: 6
Training loss: 3.388416290283203
Validation loss: 3.5589825876297487

Epoch: 5| Step: 7
Training loss: 4.222683906555176
Validation loss: 3.5471183766600904

Epoch: 5| Step: 8
Training loss: 3.5688483715057373
Validation loss: 3.537293429015785

Epoch: 5| Step: 9
Training loss: 3.466179609298706
Validation loss: 3.525311326467863

Epoch: 5| Step: 10
Training loss: 3.7211923599243164
Validation loss: 3.5134656480563584

Epoch: 8| Step: 0
Training loss: 3.156125783920288
Validation loss: 3.4970196908520115

Epoch: 5| Step: 1
Training loss: 3.7075607776641846
Validation loss: 3.481840051630492

Epoch: 5| Step: 2
Training loss: 4.050646781921387
Validation loss: 3.4709152354989

Epoch: 5| Step: 3
Training loss: 3.421221971511841
Validation loss: 3.462072846710041

Epoch: 5| Step: 4
Training loss: 2.6155893802642822
Validation loss: 3.448178942485522

Epoch: 5| Step: 5
Training loss: 3.905653715133667
Validation loss: 3.43991453929614

Epoch: 5| Step: 6
Training loss: 3.1252150535583496
Validation loss: 3.420658255136141

Epoch: 5| Step: 7
Training loss: 3.84114146232605
Validation loss: 3.409737099883377

Epoch: 5| Step: 8
Training loss: 2.5696468353271484
Validation loss: 3.4067585493928645

Epoch: 5| Step: 9
Training loss: 3.756500720977783
Validation loss: 3.402857626638105

Epoch: 5| Step: 10
Training loss: 3.034886121749878
Validation loss: 3.393723128944315

Epoch: 9| Step: 0
Training loss: 3.887495517730713
Validation loss: 3.3740781173911145

Epoch: 5| Step: 1
Training loss: 3.1152865886688232
Validation loss: 3.366153952895954

Epoch: 5| Step: 2
Training loss: 3.841254472732544
Validation loss: 3.3529118876303396

Epoch: 5| Step: 3
Training loss: 3.4156253337860107
Validation loss: 3.341671436063705

Epoch: 5| Step: 4
Training loss: 3.390882968902588
Validation loss: 3.331553997532014

Epoch: 5| Step: 5
Training loss: 2.938615322113037
Validation loss: 3.32326421430034

Epoch: 5| Step: 6
Training loss: 4.348499298095703
Validation loss: 3.313208508235152

Epoch: 5| Step: 7
Training loss: 3.9469566345214844
Validation loss: 3.299842280726279

Epoch: 5| Step: 8
Training loss: 1.9140291213989258
Validation loss: 3.287014192150485

Epoch: 5| Step: 9
Training loss: 2.989144802093506
Validation loss: 3.27685950392036

Epoch: 5| Step: 10
Training loss: 2.201542854309082
Validation loss: 3.2678117598256757

Epoch: 10| Step: 0
Training loss: 3.6083998680114746
Validation loss: 3.257791147437147

Epoch: 5| Step: 1
Training loss: 4.061997890472412
Validation loss: 3.2472896652836956

Epoch: 5| Step: 2
Training loss: 2.9109222888946533
Validation loss: 3.2387345093552784

Epoch: 5| Step: 3
Training loss: 3.8211841583251953
Validation loss: 3.2369638822411977

Epoch: 5| Step: 4
Training loss: 2.958505630493164
Validation loss: 3.220911128546602

Epoch: 5| Step: 5
Training loss: 3.1134743690490723
Validation loss: 3.2161647735103482

Epoch: 5| Step: 6
Training loss: 3.312565565109253
Validation loss: 3.2096784858293432

Epoch: 5| Step: 7
Training loss: 2.994032621383667
Validation loss: 3.2033949616134807

Epoch: 5| Step: 8
Training loss: 3.369856595993042
Validation loss: 3.198199451610606

Epoch: 5| Step: 9
Training loss: 2.3093361854553223
Validation loss: 3.187088556187127

Epoch: 5| Step: 10
Training loss: 2.776444435119629
Validation loss: 3.180008357571017

Epoch: 11| Step: 0
Training loss: 4.196234703063965
Validation loss: 3.1811609986007854

Epoch: 5| Step: 1
Training loss: 2.2912192344665527
Validation loss: 3.1854489182913177

Epoch: 5| Step: 2
Training loss: 3.819148540496826
Validation loss: 3.187078132424303

Epoch: 5| Step: 3
Training loss: 2.805319309234619
Validation loss: 3.1547917268609487

Epoch: 5| Step: 4
Training loss: 3.070941925048828
Validation loss: 3.1693516854316957

Epoch: 5| Step: 5
Training loss: 2.881016969680786
Validation loss: 3.170782332779259

Epoch: 5| Step: 6
Training loss: 3.1573264598846436
Validation loss: 3.153894744893556

Epoch: 5| Step: 7
Training loss: 3.350358247756958
Validation loss: 3.1444851224140455

Epoch: 5| Step: 8
Training loss: 3.3453986644744873
Validation loss: 3.149296465740409

Epoch: 5| Step: 9
Training loss: 2.8309404850006104
Validation loss: 3.140090088690481

Epoch: 5| Step: 10
Training loss: 3.075834274291992
Validation loss: 3.1303159344580864

Epoch: 12| Step: 0
Training loss: 3.046703338623047
Validation loss: 3.12008269627889

Epoch: 5| Step: 1
Training loss: 2.786060333251953
Validation loss: 3.1119235074648293

Epoch: 5| Step: 2
Training loss: 3.2335047721862793
Validation loss: 3.105496432191582

Epoch: 5| Step: 3
Training loss: 2.8543434143066406
Validation loss: 3.0945055715499388

Epoch: 5| Step: 4
Training loss: 3.2913074493408203
Validation loss: 3.089952253526257

Epoch: 5| Step: 5
Training loss: 3.0622074604034424
Validation loss: 3.08443973910424

Epoch: 5| Step: 6
Training loss: 2.437760829925537
Validation loss: 3.0979233377723285

Epoch: 5| Step: 7
Training loss: 2.686500072479248
Validation loss: 3.0883116722106934

Epoch: 5| Step: 8
Training loss: 3.5224227905273438
Validation loss: 3.0787348131979666

Epoch: 5| Step: 9
Training loss: 3.8525662422180176
Validation loss: 3.0833715443970053

Epoch: 5| Step: 10
Training loss: 3.6587369441986084
Validation loss: 3.076095078581123

Epoch: 13| Step: 0
Training loss: 2.592104196548462
Validation loss: 3.070901047798895

Epoch: 5| Step: 1
Training loss: 3.5044071674346924
Validation loss: 3.061754975267636

Epoch: 5| Step: 2
Training loss: 3.9242515563964844
Validation loss: 3.0586917272178074

Epoch: 5| Step: 3
Training loss: 2.859220266342163
Validation loss: 3.0548087320020123

Epoch: 5| Step: 4
Training loss: 3.401202440261841
Validation loss: 3.0513797524154826

Epoch: 5| Step: 5
Training loss: 2.632660388946533
Validation loss: 3.048500822436425

Epoch: 5| Step: 6
Training loss: 2.9138731956481934
Validation loss: 3.0437524241785847

Epoch: 5| Step: 7
Training loss: 2.4478070735931396
Validation loss: 3.0384453419716126

Epoch: 5| Step: 8
Training loss: 3.0676968097686768
Validation loss: 3.0322024694053074

Epoch: 5| Step: 9
Training loss: 3.558032989501953
Validation loss: 3.026010808124337

Epoch: 5| Step: 10
Training loss: 3.103206157684326
Validation loss: 3.022492031897268

Epoch: 14| Step: 0
Training loss: 2.969799518585205
Validation loss: 3.028540708685434

Epoch: 5| Step: 1
Training loss: 2.622741937637329
Validation loss: 3.0290435847415718

Epoch: 5| Step: 2
Training loss: 3.420423984527588
Validation loss: 3.019454945800125

Epoch: 5| Step: 3
Training loss: 2.908295154571533
Validation loss: 2.9986555627597276

Epoch: 5| Step: 4
Training loss: 3.8893446922302246
Validation loss: 3.0004245388892388

Epoch: 5| Step: 5
Training loss: 3.0918984413146973
Validation loss: 2.990628755220803

Epoch: 5| Step: 6
Training loss: 3.059067726135254
Validation loss: 2.986060596281482

Epoch: 5| Step: 7
Training loss: 2.855283260345459
Validation loss: 2.98310266002532

Epoch: 5| Step: 8
Training loss: 2.7497875690460205
Validation loss: 2.977540777575585

Epoch: 5| Step: 9
Training loss: 3.528189182281494
Validation loss: 2.9836755311617287

Epoch: 5| Step: 10
Training loss: 2.4623665809631348
Validation loss: 2.979226940421648

Epoch: 15| Step: 0
Training loss: 3.1703040599823
Validation loss: 2.964529924495246

Epoch: 5| Step: 1
Training loss: 3.149010419845581
Validation loss: 2.958001980217554

Epoch: 5| Step: 2
Training loss: 2.4634456634521484
Validation loss: 2.957224012703024

Epoch: 5| Step: 3
Training loss: 3.672321319580078
Validation loss: 2.9489910987115677

Epoch: 5| Step: 4
Training loss: 3.951889753341675
Validation loss: 2.9452546642672632

Epoch: 5| Step: 5
Training loss: 2.8962981700897217
Validation loss: 2.9418832819948912

Epoch: 5| Step: 6
Training loss: 3.330713987350464
Validation loss: 2.9350858093589864

Epoch: 5| Step: 7
Training loss: 3.1694493293762207
Validation loss: 2.93213471545968

Epoch: 5| Step: 8
Training loss: 2.2918429374694824
Validation loss: 2.923629278777748

Epoch: 5| Step: 9
Training loss: 2.4238946437835693
Validation loss: 2.916737271893409

Epoch: 5| Step: 10
Training loss: 2.642063856124878
Validation loss: 2.9146210532034598

Epoch: 16| Step: 0
Training loss: 2.4708874225616455
Validation loss: 2.907857915406586

Epoch: 5| Step: 1
Training loss: 2.555844306945801
Validation loss: 2.904862291069441

Epoch: 5| Step: 2
Training loss: 3.184164524078369
Validation loss: 2.9015082364441245

Epoch: 5| Step: 3
Training loss: 2.8533987998962402
Validation loss: 2.896964242381434

Epoch: 5| Step: 4
Training loss: 3.1125946044921875
Validation loss: 2.895233287606188

Epoch: 5| Step: 5
Training loss: 3.51788592338562
Validation loss: 2.88885824911056

Epoch: 5| Step: 6
Training loss: 2.998041868209839
Validation loss: 2.8902978410003004

Epoch: 5| Step: 7
Training loss: 2.380862236022949
Validation loss: 2.8814339945393224

Epoch: 5| Step: 8
Training loss: 3.0237717628479004
Validation loss: 2.8783270030893306

Epoch: 5| Step: 9
Training loss: 3.028184413909912
Validation loss: 2.871109095952844

Epoch: 5| Step: 10
Training loss: 3.835671901702881
Validation loss: 2.866328949569374

Epoch: 17| Step: 0
Training loss: 3.452981472015381
Validation loss: 2.8559292260036675

Epoch: 5| Step: 1
Training loss: 2.492657423019409
Validation loss: 2.8534322425883305

Epoch: 5| Step: 2
Training loss: 2.781907558441162
Validation loss: 2.851306551246233

Epoch: 5| Step: 3
Training loss: 3.9766945838928223
Validation loss: 2.848308563232422

Epoch: 5| Step: 4
Training loss: 2.5472376346588135
Validation loss: 2.841892578268564

Epoch: 5| Step: 5
Training loss: 2.8487846851348877
Validation loss: 2.841018312720842

Epoch: 5| Step: 6
Training loss: 3.191279172897339
Validation loss: 2.8424308582018782

Epoch: 5| Step: 7
Training loss: 2.4381766319274902
Validation loss: 2.8468641440073648

Epoch: 5| Step: 8
Training loss: 3.244921922683716
Validation loss: 2.832927352638655

Epoch: 5| Step: 9
Training loss: 2.657195568084717
Validation loss: 2.825422825351838

Epoch: 5| Step: 10
Training loss: 2.810007095336914
Validation loss: 2.8271159741186325

Epoch: 18| Step: 0
Training loss: 2.4089856147766113
Validation loss: 2.823872399586503

Epoch: 5| Step: 1
Training loss: 2.920419454574585
Validation loss: 2.820953728050314

Epoch: 5| Step: 2
Training loss: 3.188934803009033
Validation loss: 2.807005477207963

Epoch: 5| Step: 3
Training loss: 3.028489828109741
Validation loss: 2.8126962159269597

Epoch: 5| Step: 4
Training loss: 3.4449679851531982
Validation loss: 2.805796648866387

Epoch: 5| Step: 5
Training loss: 2.171412944793701
Validation loss: 2.8093383004588466

Epoch: 5| Step: 6
Training loss: 3.263477325439453
Validation loss: 2.8099267175120692

Epoch: 5| Step: 7
Training loss: 3.4701926708221436
Validation loss: 2.8020424894107285

Epoch: 5| Step: 8
Training loss: 3.0494911670684814
Validation loss: 2.790790509152156

Epoch: 5| Step: 9
Training loss: 2.686919689178467
Validation loss: 2.7810539430187595

Epoch: 5| Step: 10
Training loss: 2.5996177196502686
Validation loss: 2.776017506917318

Epoch: 19| Step: 0
Training loss: 2.930861711502075
Validation loss: 2.772638172231695

Epoch: 5| Step: 1
Training loss: 3.170161724090576
Validation loss: 2.7703766028086343

Epoch: 5| Step: 2
Training loss: 2.8408148288726807
Validation loss: 2.767435025143367

Epoch: 5| Step: 3
Training loss: 3.5204989910125732
Validation loss: 2.767364025115967

Epoch: 5| Step: 4
Training loss: 2.300429344177246
Validation loss: 2.761185299965643

Epoch: 5| Step: 5
Training loss: 2.7990219593048096
Validation loss: 2.754287883799563

Epoch: 5| Step: 6
Training loss: 2.7280752658843994
Validation loss: 2.755639571015553

Epoch: 5| Step: 7
Training loss: 2.6521852016448975
Validation loss: 2.749374012793264

Epoch: 5| Step: 8
Training loss: 2.617856502532959
Validation loss: 2.745458367050335

Epoch: 5| Step: 9
Training loss: 2.997692346572876
Validation loss: 2.738438178134221

Epoch: 5| Step: 10
Training loss: 3.374969959259033
Validation loss: 2.736553607448455

Epoch: 20| Step: 0
Training loss: 3.573593854904175
Validation loss: 2.7446569858058805

Epoch: 5| Step: 1
Training loss: 2.956540584564209
Validation loss: 2.7298851449002504

Epoch: 5| Step: 2
Training loss: 3.3395919799804688
Validation loss: 2.7305928430249615

Epoch: 5| Step: 3
Training loss: 3.4750640392303467
Validation loss: 2.7290164834709576

Epoch: 5| Step: 4
Training loss: 2.4240126609802246
Validation loss: 2.72304517222989

Epoch: 5| Step: 5
Training loss: 2.4947361946105957
Validation loss: 2.7194647558273806

Epoch: 5| Step: 6
Training loss: 2.357142925262451
Validation loss: 2.719387072388844

Epoch: 5| Step: 7
Training loss: 2.3354597091674805
Validation loss: 2.716228174906905

Epoch: 5| Step: 8
Training loss: 2.834714412689209
Validation loss: 2.7162793810649584

Epoch: 5| Step: 9
Training loss: 3.189481019973755
Validation loss: 2.7138801543943343

Epoch: 5| Step: 10
Training loss: 2.636831283569336
Validation loss: 2.7088590668093775

Epoch: 21| Step: 0
Training loss: 2.391768217086792
Validation loss: 2.7168462968641713

Epoch: 5| Step: 1
Training loss: 2.6923129558563232
Validation loss: 2.6981767941546697

Epoch: 5| Step: 2
Training loss: 2.565314531326294
Validation loss: 2.695407316248904

Epoch: 5| Step: 3
Training loss: 3.0229127407073975
Validation loss: 2.6924289118859077

Epoch: 5| Step: 4
Training loss: 3.791475772857666
Validation loss: 2.6959711813157603

Epoch: 5| Step: 5
Training loss: 2.666776418685913
Validation loss: 2.6868756560869116

Epoch: 5| Step: 6
Training loss: 2.7324984073638916
Validation loss: 2.6880898757647445

Epoch: 5| Step: 7
Training loss: 2.7210025787353516
Validation loss: 2.7229922920145015

Epoch: 5| Step: 8
Training loss: 3.4065468311309814
Validation loss: 2.707444529379568

Epoch: 5| Step: 9
Training loss: 2.4372518062591553
Validation loss: 2.6872092549518873

Epoch: 5| Step: 10
Training loss: 3.12141489982605
Validation loss: 2.6835676726474555

Epoch: 22| Step: 0
Training loss: 2.631507635116577
Validation loss: 2.679171772413356

Epoch: 5| Step: 1
Training loss: 3.4928176403045654
Validation loss: 2.6841379288704164

Epoch: 5| Step: 2
Training loss: 3.031188488006592
Validation loss: 2.68286104612453

Epoch: 5| Step: 3
Training loss: 2.15484619140625
Validation loss: 2.6783247993838404

Epoch: 5| Step: 4
Training loss: 3.223180055618286
Validation loss: 2.684906498078377

Epoch: 5| Step: 5
Training loss: 3.334836959838867
Validation loss: 2.683472292397612

Epoch: 5| Step: 6
Training loss: 2.6147475242614746
Validation loss: 2.6705224232007096

Epoch: 5| Step: 7
Training loss: 2.5554213523864746
Validation loss: 2.688748598098755

Epoch: 5| Step: 8
Training loss: 2.515822649002075
Validation loss: 2.6931171250599686

Epoch: 5| Step: 9
Training loss: 2.76214599609375
Validation loss: 2.69356785538376

Epoch: 5| Step: 10
Training loss: 3.0947182178497314
Validation loss: 2.6866454539760465

Epoch: 23| Step: 0
Training loss: 2.518939971923828
Validation loss: 2.6642865134823706

Epoch: 5| Step: 1
Training loss: 3.568366527557373
Validation loss: 2.650464483486709

Epoch: 5| Step: 2
Training loss: 3.078896999359131
Validation loss: 2.654666651961624

Epoch: 5| Step: 3
Training loss: 2.4731221199035645
Validation loss: 2.674274285634359

Epoch: 5| Step: 4
Training loss: 2.534902572631836
Validation loss: 2.6781466084141887

Epoch: 5| Step: 5
Training loss: 3.051427125930786
Validation loss: 2.667110002169045

Epoch: 5| Step: 6
Training loss: 3.2727577686309814
Validation loss: 2.6567267269216557

Epoch: 5| Step: 7
Training loss: 2.1993205547332764
Validation loss: 2.6472306200253066

Epoch: 5| Step: 8
Training loss: 2.683406352996826
Validation loss: 2.6476523260916434

Epoch: 5| Step: 9
Training loss: 3.2266831398010254
Validation loss: 2.6462750742512364

Epoch: 5| Step: 10
Training loss: 2.498671531677246
Validation loss: 2.637375254784861

Epoch: 24| Step: 0
Training loss: 2.9380860328674316
Validation loss: 2.6552266202947146

Epoch: 5| Step: 1
Training loss: 2.684361696243286
Validation loss: 2.6632856092145367

Epoch: 5| Step: 2
Training loss: 2.4409518241882324
Validation loss: 2.6428201378032727

Epoch: 5| Step: 3
Training loss: 2.6933674812316895
Validation loss: 2.6286471479682514

Epoch: 5| Step: 4
Training loss: 2.71152925491333
Validation loss: 2.6269256273905435

Epoch: 5| Step: 5
Training loss: 2.990208148956299
Validation loss: 2.6249213269961778

Epoch: 5| Step: 6
Training loss: 2.4745185375213623
Validation loss: 2.62360232363465

Epoch: 5| Step: 7
Training loss: 3.34559965133667
Validation loss: 2.624104904872115

Epoch: 5| Step: 8
Training loss: 3.723090410232544
Validation loss: 2.6208876486747497

Epoch: 5| Step: 9
Training loss: 2.3856682777404785
Validation loss: 2.617829789397537

Epoch: 5| Step: 10
Training loss: 2.5744266510009766
Validation loss: 2.619496827484459

Epoch: 25| Step: 0
Training loss: 2.556185245513916
Validation loss: 2.613370559548819

Epoch: 5| Step: 1
Training loss: 2.775737762451172
Validation loss: 2.6108292918051443

Epoch: 5| Step: 2
Training loss: 3.179029941558838
Validation loss: 2.609926874919604

Epoch: 5| Step: 3
Training loss: 2.5081143379211426
Validation loss: 2.606623647033527

Epoch: 5| Step: 4
Training loss: 3.0974903106689453
Validation loss: 2.601876271668301

Epoch: 5| Step: 5
Training loss: 2.5806021690368652
Validation loss: 2.600618172717351

Epoch: 5| Step: 6
Training loss: 2.956634044647217
Validation loss: 2.597090346838838

Epoch: 5| Step: 7
Training loss: 2.6733298301696777
Validation loss: 2.595241303084999

Epoch: 5| Step: 8
Training loss: 2.5269100666046143
Validation loss: 2.594449761093304

Epoch: 5| Step: 9
Training loss: 2.754488945007324
Validation loss: 2.593269812163486

Epoch: 5| Step: 10
Training loss: 3.3211264610290527
Validation loss: 2.59254212533274

Epoch: 26| Step: 0
Training loss: 3.2235305309295654
Validation loss: 2.595353844345257

Epoch: 5| Step: 1
Training loss: 2.90571928024292
Validation loss: 2.598786028482581

Epoch: 5| Step: 2
Training loss: 2.5991930961608887
Validation loss: 2.6028338632275982

Epoch: 5| Step: 3
Training loss: 2.6314585208892822
Validation loss: 2.5886590967896166

Epoch: 5| Step: 4
Training loss: 2.495093584060669
Validation loss: 2.588013546441191

Epoch: 5| Step: 5
Training loss: 2.9747486114501953
Validation loss: 2.5854853737738823

Epoch: 5| Step: 6
Training loss: 3.133747100830078
Validation loss: 2.5866676735621628

Epoch: 5| Step: 7
Training loss: 1.7656896114349365
Validation loss: 2.5853986714475896

Epoch: 5| Step: 8
Training loss: 3.4180099964141846
Validation loss: 2.5867251503852104

Epoch: 5| Step: 9
Training loss: 2.6952602863311768
Validation loss: 2.5864859986048874

Epoch: 5| Step: 10
Training loss: 2.903407573699951
Validation loss: 2.582606815522717

Epoch: 27| Step: 0
Training loss: 3.2647438049316406
Validation loss: 2.5802661424042075

Epoch: 5| Step: 1
Training loss: 3.018984317779541
Validation loss: 2.577491319307717

Epoch: 5| Step: 2
Training loss: 2.943237781524658
Validation loss: 2.5725224838461926

Epoch: 5| Step: 3
Training loss: 3.181422233581543
Validation loss: 2.5719191746045182

Epoch: 5| Step: 4
Training loss: 2.3439154624938965
Validation loss: 2.5697882765082904

Epoch: 5| Step: 5
Training loss: 2.5921263694763184
Validation loss: 2.57109333110112

Epoch: 5| Step: 6
Training loss: 2.588372230529785
Validation loss: 2.56802426615069

Epoch: 5| Step: 7
Training loss: 3.0091323852539062
Validation loss: 2.5702967131009666

Epoch: 5| Step: 8
Training loss: 2.7945103645324707
Validation loss: 2.5698353270048737

Epoch: 5| Step: 9
Training loss: 2.3534624576568604
Validation loss: 2.5810759862264

Epoch: 5| Step: 10
Training loss: 2.429511070251465
Validation loss: 2.575247058304407

Epoch: 28| Step: 0
Training loss: 2.724801540374756
Validation loss: 2.572962873725481

Epoch: 5| Step: 1
Training loss: 2.0117533206939697
Validation loss: 2.565509219323435

Epoch: 5| Step: 2
Training loss: 2.851208209991455
Validation loss: 2.5597290915827595

Epoch: 5| Step: 3
Training loss: 3.259599208831787
Validation loss: 2.5568863909731627

Epoch: 5| Step: 4
Training loss: 2.724544048309326
Validation loss: 2.560932551660845

Epoch: 5| Step: 5
Training loss: 2.079038143157959
Validation loss: 2.5585019537197646

Epoch: 5| Step: 6
Training loss: 3.306594133377075
Validation loss: 2.5578401037441787

Epoch: 5| Step: 7
Training loss: 3.159031629562378
Validation loss: 2.5573718983639955

Epoch: 5| Step: 8
Training loss: 2.2307772636413574
Validation loss: 2.56211083678789

Epoch: 5| Step: 9
Training loss: 2.990662097930908
Validation loss: 2.5571034082802395

Epoch: 5| Step: 10
Training loss: 3.1103339195251465
Validation loss: 2.551916132691086

Epoch: 29| Step: 0
Training loss: 2.526071310043335
Validation loss: 2.549514901253485

Epoch: 5| Step: 1
Training loss: 2.5411155223846436
Validation loss: 2.5485317296879266

Epoch: 5| Step: 2
Training loss: 3.120805263519287
Validation loss: 2.5560121536254883

Epoch: 5| Step: 3
Training loss: 3.16455078125
Validation loss: 2.565091686864053

Epoch: 5| Step: 4
Training loss: 2.347766637802124
Validation loss: 2.5525285890025478

Epoch: 5| Step: 5
Training loss: 2.984945297241211
Validation loss: 2.543501228414556

Epoch: 5| Step: 6
Training loss: 2.994716167449951
Validation loss: 2.5425891517311014

Epoch: 5| Step: 7
Training loss: 2.7830326557159424
Validation loss: 2.5543885307927288

Epoch: 5| Step: 8
Training loss: 2.0741894245147705
Validation loss: 2.571275290622506

Epoch: 5| Step: 9
Training loss: 2.709766387939453
Validation loss: 2.5906656660059446

Epoch: 5| Step: 10
Training loss: 3.331449508666992
Validation loss: 2.6221489085946033

Epoch: 30| Step: 0
Training loss: 2.3178951740264893
Validation loss: 2.6080659076731694

Epoch: 5| Step: 1
Training loss: 2.8939480781555176
Validation loss: 2.568883293418474

Epoch: 5| Step: 2
Training loss: 2.0386509895324707
Validation loss: 2.5492071515770367

Epoch: 5| Step: 3
Training loss: 3.318124294281006
Validation loss: 2.549215991009948

Epoch: 5| Step: 4
Training loss: 2.834808826446533
Validation loss: 2.560034489118925

Epoch: 5| Step: 5
Training loss: 2.818112850189209
Validation loss: 2.5679775104727796

Epoch: 5| Step: 6
Training loss: 2.609853744506836
Validation loss: 2.5557025042913293

Epoch: 5| Step: 7
Training loss: 2.165008068084717
Validation loss: 2.5539045103134645

Epoch: 5| Step: 8
Training loss: 3.4493308067321777
Validation loss: 2.5606930691708802

Epoch: 5| Step: 9
Training loss: 3.167492151260376
Validation loss: 2.5628406975858953

Epoch: 5| Step: 10
Training loss: 2.927142858505249
Validation loss: 2.549797365742345

Epoch: 31| Step: 0
Training loss: 3.1349518299102783
Validation loss: 2.5400981518530075

Epoch: 5| Step: 1
Training loss: 2.6676576137542725
Validation loss: 2.5372740427652993

Epoch: 5| Step: 2
Training loss: 2.6555137634277344
Validation loss: 2.530209042692697

Epoch: 5| Step: 3
Training loss: 2.40828013420105
Validation loss: 2.5403994257732103

Epoch: 5| Step: 4
Training loss: 2.8876588344573975
Validation loss: 2.561258275021789

Epoch: 5| Step: 5
Training loss: 3.212345838546753
Validation loss: 2.5758517198665167

Epoch: 5| Step: 6
Training loss: 2.7112560272216797
Validation loss: 2.5838922480101227

Epoch: 5| Step: 7
Training loss: 2.7052204608917236
Validation loss: 2.579485780449324

Epoch: 5| Step: 8
Training loss: 2.3956644535064697
Validation loss: 2.5377709788660847

Epoch: 5| Step: 9
Training loss: 2.85396146774292
Validation loss: 2.522571045865295

Epoch: 5| Step: 10
Training loss: 2.6636435985565186
Validation loss: 2.5230200059952272

Epoch: 32| Step: 0
Training loss: 2.980440616607666
Validation loss: 2.5219263466455604

Epoch: 5| Step: 1
Training loss: 2.5458920001983643
Validation loss: 2.5226496804145073

Epoch: 5| Step: 2
Training loss: 2.992176055908203
Validation loss: 2.5268389307042605

Epoch: 5| Step: 3
Training loss: 2.729565143585205
Validation loss: 2.5292625657973753

Epoch: 5| Step: 4
Training loss: 3.3051514625549316
Validation loss: 2.530823051288564

Epoch: 5| Step: 5
Training loss: 3.16503643989563
Validation loss: 2.5241795098909767

Epoch: 5| Step: 6
Training loss: 2.4744904041290283
Validation loss: 2.5184389134889007

Epoch: 5| Step: 7
Training loss: 2.221238136291504
Validation loss: 2.5162699786565637

Epoch: 5| Step: 8
Training loss: 2.842864751815796
Validation loss: 2.517920360770277

Epoch: 5| Step: 9
Training loss: 2.9185030460357666
Validation loss: 2.5146030328607045

Epoch: 5| Step: 10
Training loss: 1.9825401306152344
Validation loss: 2.513925849750478

Epoch: 33| Step: 0
Training loss: 2.869784116744995
Validation loss: 2.519421628726426

Epoch: 5| Step: 1
Training loss: 3.2162537574768066
Validation loss: 2.54234210137398

Epoch: 5| Step: 2
Training loss: 2.830648422241211
Validation loss: 2.5532515741163686

Epoch: 5| Step: 3
Training loss: 2.5631041526794434
Validation loss: 2.5817673437057005

Epoch: 5| Step: 4
Training loss: 2.0446808338165283
Validation loss: 2.6427588565375215

Epoch: 5| Step: 5
Training loss: 2.7313692569732666
Validation loss: 2.6602866418900026

Epoch: 5| Step: 6
Training loss: 2.4698147773742676
Validation loss: 2.680170246349868

Epoch: 5| Step: 7
Training loss: 3.3956451416015625
Validation loss: 2.644770781199137

Epoch: 5| Step: 8
Training loss: 2.8580002784729004
Validation loss: 2.553899318941178

Epoch: 5| Step: 9
Training loss: 2.1144773960113525
Validation loss: 2.5099127677179154

Epoch: 5| Step: 10
Training loss: 3.500063180923462
Validation loss: 2.5558128792752504

Epoch: 34| Step: 0
Training loss: 2.7004008293151855
Validation loss: 2.571445295887609

Epoch: 5| Step: 1
Training loss: 2.8356406688690186
Validation loss: 2.5927146916748374

Epoch: 5| Step: 2
Training loss: 2.940901279449463
Validation loss: 2.5712702017958446

Epoch: 5| Step: 3
Training loss: 2.7055017948150635
Validation loss: 2.5234229026302213

Epoch: 5| Step: 4
Training loss: 2.5546457767486572
Validation loss: 2.520332577408001

Epoch: 5| Step: 5
Training loss: 2.1476387977600098
Validation loss: 2.530972603828676

Epoch: 5| Step: 6
Training loss: 2.998354911804199
Validation loss: 2.531240617075274

Epoch: 5| Step: 7
Training loss: 2.8721375465393066
Validation loss: 2.521086167263728

Epoch: 5| Step: 8
Training loss: 3.061434268951416
Validation loss: 2.502287592939151

Epoch: 5| Step: 9
Training loss: 2.6745901107788086
Validation loss: 2.5007141687536754

Epoch: 5| Step: 10
Training loss: 2.8672473430633545
Validation loss: 2.509516328893682

Epoch: 35| Step: 0
Training loss: 2.865821123123169
Validation loss: 2.5340965229977845

Epoch: 5| Step: 1
Training loss: 2.5582261085510254
Validation loss: 2.567067128355785

Epoch: 5| Step: 2
Training loss: 2.3127517700195312
Validation loss: 2.564047162250806

Epoch: 5| Step: 3
Training loss: 2.851759910583496
Validation loss: 2.5476110955720306

Epoch: 5| Step: 4
Training loss: 3.076108932495117
Validation loss: 2.5483063677305817

Epoch: 5| Step: 5
Training loss: 2.745474338531494
Validation loss: 2.535294040556877

Epoch: 5| Step: 6
Training loss: 2.6524431705474854
Validation loss: 2.531277579645957

Epoch: 5| Step: 7
Training loss: 2.384587526321411
Validation loss: 2.5249863465627036

Epoch: 5| Step: 8
Training loss: 3.384108066558838
Validation loss: 2.5051735549844723

Epoch: 5| Step: 9
Training loss: 2.660060167312622
Validation loss: 2.494253748206682

Epoch: 5| Step: 10
Training loss: 2.5623998641967773
Validation loss: 2.48866093543268

Epoch: 36| Step: 0
Training loss: 2.8197600841522217
Validation loss: 2.483396666024321

Epoch: 5| Step: 1
Training loss: 2.5615742206573486
Validation loss: 2.49308358212953

Epoch: 5| Step: 2
Training loss: 2.6520209312438965
Validation loss: 2.505812286048807

Epoch: 5| Step: 3
Training loss: 2.4195573329925537
Validation loss: 2.5049496901932584

Epoch: 5| Step: 4
Training loss: 3.033128261566162
Validation loss: 2.497954163500058

Epoch: 5| Step: 5
Training loss: 2.5375444889068604
Validation loss: 2.4939806486970637

Epoch: 5| Step: 6
Training loss: 2.806457281112671
Validation loss: 2.4853912502206783

Epoch: 5| Step: 7
Training loss: 2.6107735633850098
Validation loss: 2.4901883602142334

Epoch: 5| Step: 8
Training loss: 2.5544941425323486
Validation loss: 2.490523984355311

Epoch: 5| Step: 9
Training loss: 2.613518238067627
Validation loss: 2.493408556907408

Epoch: 5| Step: 10
Training loss: 3.4301939010620117
Validation loss: 2.486081538661834

Epoch: 37| Step: 0
Training loss: 2.9466421604156494
Validation loss: 2.47987868965313

Epoch: 5| Step: 1
Training loss: 2.4436893463134766
Validation loss: 2.481471597507436

Epoch: 5| Step: 2
Training loss: 2.2906901836395264
Validation loss: 2.4947792330095844

Epoch: 5| Step: 3
Training loss: 2.8754067420959473
Validation loss: 2.5027954527126846

Epoch: 5| Step: 4
Training loss: 2.383347511291504
Validation loss: 2.517606194301318

Epoch: 5| Step: 5
Training loss: 2.6979732513427734
Validation loss: 2.5035205964119203

Epoch: 5| Step: 6
Training loss: 3.182832956314087
Validation loss: 2.5133991472182737

Epoch: 5| Step: 7
Training loss: 2.8960940837860107
Validation loss: 2.4854010817825154

Epoch: 5| Step: 8
Training loss: 3.1682233810424805
Validation loss: 2.4732466923293246

Epoch: 5| Step: 9
Training loss: 2.456613063812256
Validation loss: 2.4787689203857095

Epoch: 5| Step: 10
Training loss: 2.428983449935913
Validation loss: 2.486647739205309

Epoch: 38| Step: 0
Training loss: 3.4470267295837402
Validation loss: 2.493115714801255

Epoch: 5| Step: 1
Training loss: 2.238903045654297
Validation loss: 2.500503101656514

Epoch: 5| Step: 2
Training loss: 2.642200469970703
Validation loss: 2.501692671929636

Epoch: 5| Step: 3
Training loss: 3.3337390422821045
Validation loss: 2.4961943728949434

Epoch: 5| Step: 4
Training loss: 2.458371639251709
Validation loss: 2.488044346532514

Epoch: 5| Step: 5
Training loss: 2.708935022354126
Validation loss: 2.4809094218797583

Epoch: 5| Step: 6
Training loss: 2.219092607498169
Validation loss: 2.4789405791990218

Epoch: 5| Step: 7
Training loss: 2.5239832401275635
Validation loss: 2.4770114062934794

Epoch: 5| Step: 8
Training loss: 2.1984171867370605
Validation loss: 2.4772494787810952

Epoch: 5| Step: 9
Training loss: 3.7145633697509766
Validation loss: 2.484276238308158

Epoch: 5| Step: 10
Training loss: 2.364351511001587
Validation loss: 2.493456655933011

Epoch: 39| Step: 0
Training loss: 2.611179828643799
Validation loss: 2.509581555602371

Epoch: 5| Step: 1
Training loss: 2.811908721923828
Validation loss: 2.5210188204242336

Epoch: 5| Step: 2
Training loss: 2.6786632537841797
Validation loss: 2.5153596093577724

Epoch: 5| Step: 3
Training loss: 2.3269519805908203
Validation loss: 2.5287529678754908

Epoch: 5| Step: 4
Training loss: 3.0836544036865234
Validation loss: 2.4900124355029036

Epoch: 5| Step: 5
Training loss: 3.171358585357666
Validation loss: 2.475163718705536

Epoch: 5| Step: 6
Training loss: 2.5484681129455566
Validation loss: 2.4684521998128583

Epoch: 5| Step: 7
Training loss: 2.228309154510498
Validation loss: 2.4664216733747915

Epoch: 5| Step: 8
Training loss: 2.8631575107574463
Validation loss: 2.470145476761685

Epoch: 5| Step: 9
Training loss: 2.963408946990967
Validation loss: 2.4612713552290395

Epoch: 5| Step: 10
Training loss: 2.5838489532470703
Validation loss: 2.4648790256951445

Epoch: 40| Step: 0
Training loss: 2.215841054916382
Validation loss: 2.465422104763728

Epoch: 5| Step: 1
Training loss: 2.3072292804718018
Validation loss: 2.4698850416368052

Epoch: 5| Step: 2
Training loss: 2.5978665351867676
Validation loss: 2.46887303680502

Epoch: 5| Step: 3
Training loss: 1.8501970767974854
Validation loss: 2.4687940228369927

Epoch: 5| Step: 4
Training loss: 2.9290127754211426
Validation loss: 2.459430048542638

Epoch: 5| Step: 5
Training loss: 3.441415786743164
Validation loss: 2.4608590807966007

Epoch: 5| Step: 6
Training loss: 2.4078402519226074
Validation loss: 2.4602913241232596

Epoch: 5| Step: 7
Training loss: 2.7208685874938965
Validation loss: 2.4647189058283323

Epoch: 5| Step: 8
Training loss: 3.3742594718933105
Validation loss: 2.468323507616597

Epoch: 5| Step: 9
Training loss: 3.100181818008423
Validation loss: 2.469372041763798

Epoch: 5| Step: 10
Training loss: 2.755624771118164
Validation loss: 2.4711422766408613

Epoch: 41| Step: 0
Training loss: 2.485867977142334
Validation loss: 2.4782078599417083

Epoch: 5| Step: 1
Training loss: 2.235325336456299
Validation loss: 2.493981533153083

Epoch: 5| Step: 2
Training loss: 2.2975239753723145
Validation loss: 2.508630601308679

Epoch: 5| Step: 3
Training loss: 3.0984435081481934
Validation loss: 2.514927153946251

Epoch: 5| Step: 4
Training loss: 1.9777214527130127
Validation loss: 2.4848743228502173

Epoch: 5| Step: 5
Training loss: 2.4929654598236084
Validation loss: 2.480810139768867

Epoch: 5| Step: 6
Training loss: 3.259730815887451
Validation loss: 2.482112879394203

Epoch: 5| Step: 7
Training loss: 3.0498046875
Validation loss: 2.4766088275499243

Epoch: 5| Step: 8
Training loss: 3.679267168045044
Validation loss: 2.470375548126877

Epoch: 5| Step: 9
Training loss: 2.3000757694244385
Validation loss: 2.459086238697011

Epoch: 5| Step: 10
Training loss: 2.7645909786224365
Validation loss: 2.4617922793152514

Epoch: 42| Step: 0
Training loss: 2.5340137481689453
Validation loss: 2.461119464648667

Epoch: 5| Step: 1
Training loss: 2.6611971855163574
Validation loss: 2.4565647263680734

Epoch: 5| Step: 2
Training loss: 2.4501798152923584
Validation loss: 2.4609234268947313

Epoch: 5| Step: 3
Training loss: 3.071928024291992
Validation loss: 2.4666132670576855

Epoch: 5| Step: 4
Training loss: 2.6824588775634766
Validation loss: 2.471617829415106

Epoch: 5| Step: 5
Training loss: 2.3516674041748047
Validation loss: 2.4748954721676406

Epoch: 5| Step: 6
Training loss: 3.0137548446655273
Validation loss: 2.4856109183321715

Epoch: 5| Step: 7
Training loss: 2.3562557697296143
Validation loss: 2.4798157804755756

Epoch: 5| Step: 8
Training loss: 3.216353178024292
Validation loss: 2.463070754081972

Epoch: 5| Step: 9
Training loss: 3.3310904502868652
Validation loss: 2.457968799016809

Epoch: 5| Step: 10
Training loss: 1.6779435873031616
Validation loss: 2.4522108467676307

Epoch: 43| Step: 0
Training loss: 2.304849863052368
Validation loss: 2.4558223037309546

Epoch: 5| Step: 1
Training loss: 2.946551561355591
Validation loss: 2.4635615092451855

Epoch: 5| Step: 2
Training loss: 3.022590160369873
Validation loss: 2.4654102171621015

Epoch: 5| Step: 3
Training loss: 2.7787435054779053
Validation loss: 2.468148026415097

Epoch: 5| Step: 4
Training loss: 2.8169853687286377
Validation loss: 2.4686956636367308

Epoch: 5| Step: 5
Training loss: 2.202272415161133
Validation loss: 2.4643385128308366

Epoch: 5| Step: 6
Training loss: 2.114461660385132
Validation loss: 2.465000201297063

Epoch: 5| Step: 7
Training loss: 2.7053942680358887
Validation loss: 2.4528806722292336

Epoch: 5| Step: 8
Training loss: 3.2971503734588623
Validation loss: 2.4561994998685774

Epoch: 5| Step: 9
Training loss: 2.407783031463623
Validation loss: 2.4572407161035845

Epoch: 5| Step: 10
Training loss: 2.8488080501556396
Validation loss: 2.4571198519840034

Epoch: 44| Step: 0
Training loss: 2.7919981479644775
Validation loss: 2.4553019077547136

Epoch: 5| Step: 1
Training loss: 2.744051694869995
Validation loss: 2.456723310614145

Epoch: 5| Step: 2
Training loss: 3.0166897773742676
Validation loss: 2.4657751770429712

Epoch: 5| Step: 3
Training loss: 2.3890609741210938
Validation loss: 2.471749198052191

Epoch: 5| Step: 4
Training loss: 2.1475982666015625
Validation loss: 2.475289470405989

Epoch: 5| Step: 5
Training loss: 3.0951409339904785
Validation loss: 2.4730944633483887

Epoch: 5| Step: 6
Training loss: 2.6157073974609375
Validation loss: 2.4686680891180552

Epoch: 5| Step: 7
Training loss: 2.7045907974243164
Validation loss: 2.4667589587550007

Epoch: 5| Step: 8
Training loss: 2.69376277923584
Validation loss: 2.466417010112475

Epoch: 5| Step: 9
Training loss: 2.3170104026794434
Validation loss: 2.4593857052505657

Epoch: 5| Step: 10
Training loss: 2.9483957290649414
Validation loss: 2.4569036909328994

Epoch: 45| Step: 0
Training loss: 2.513490676879883
Validation loss: 2.4557254878423547

Epoch: 5| Step: 1
Training loss: 2.8491578102111816
Validation loss: 2.455842823110601

Epoch: 5| Step: 2
Training loss: 2.664729595184326
Validation loss: 2.4600444250209357

Epoch: 5| Step: 3
Training loss: 3.2193570137023926
Validation loss: 2.464076858694835

Epoch: 5| Step: 4
Training loss: 3.2447052001953125
Validation loss: 2.4558515189796366

Epoch: 5| Step: 5
Training loss: 2.0599002838134766
Validation loss: 2.4551569069585493

Epoch: 5| Step: 6
Training loss: 2.2983741760253906
Validation loss: 2.455886220419279

Epoch: 5| Step: 7
Training loss: 2.0617668628692627
Validation loss: 2.46024917018029

Epoch: 5| Step: 8
Training loss: 3.168092966079712
Validation loss: 2.4744377469503753

Epoch: 5| Step: 9
Training loss: 2.538461446762085
Validation loss: 2.495405356089274

Epoch: 5| Step: 10
Training loss: 2.8915321826934814
Validation loss: 2.491338106893724

Epoch: 46| Step: 0
Training loss: 3.0832552909851074
Validation loss: 2.4796001603526454

Epoch: 5| Step: 1
Training loss: 2.797936201095581
Validation loss: 2.4726460095374816

Epoch: 5| Step: 2
Training loss: 2.7774386405944824
Validation loss: 2.461315998467066

Epoch: 5| Step: 3
Training loss: 2.951463222503662
Validation loss: 2.4506206320178126

Epoch: 5| Step: 4
Training loss: 2.7065982818603516
Validation loss: 2.446396025278235

Epoch: 5| Step: 5
Training loss: 2.947049856185913
Validation loss: 2.4416785727265062

Epoch: 5| Step: 6
Training loss: 2.0664162635803223
Validation loss: 2.439353989016625

Epoch: 5| Step: 7
Training loss: 2.7926013469696045
Validation loss: 2.437097749402446

Epoch: 5| Step: 8
Training loss: 2.6255531311035156
Validation loss: 2.436897849523893

Epoch: 5| Step: 9
Training loss: 2.4093122482299805
Validation loss: 2.439266643216533

Epoch: 5| Step: 10
Training loss: 2.0484542846679688
Validation loss: 2.4368584925128567

Epoch: 47| Step: 0
Training loss: 2.246344804763794
Validation loss: 2.434647857501943

Epoch: 5| Step: 1
Training loss: 3.350855588912964
Validation loss: 2.4341792547574608

Epoch: 5| Step: 2
Training loss: 3.1565489768981934
Validation loss: 2.4316612046252013

Epoch: 5| Step: 3
Training loss: 2.3805770874023438
Validation loss: 2.4356172341172413

Epoch: 5| Step: 4
Training loss: 3.181370496749878
Validation loss: 2.4368714363344255

Epoch: 5| Step: 5
Training loss: 1.6523746252059937
Validation loss: 2.4364335690775225

Epoch: 5| Step: 6
Training loss: 3.051858425140381
Validation loss: 2.4414515469663884

Epoch: 5| Step: 7
Training loss: 2.5931453704833984
Validation loss: 2.4462760622783373

Epoch: 5| Step: 8
Training loss: 2.7714829444885254
Validation loss: 2.4441240808015228

Epoch: 5| Step: 9
Training loss: 2.2159857749938965
Validation loss: 2.451005079412973

Epoch: 5| Step: 10
Training loss: 2.5936782360076904
Validation loss: 2.4534108561854207

Epoch: 48| Step: 0
Training loss: 2.484109401702881
Validation loss: 2.449612925129552

Epoch: 5| Step: 1
Training loss: 2.4131035804748535
Validation loss: 2.4536575860874628

Epoch: 5| Step: 2
Training loss: 2.7337517738342285
Validation loss: 2.446613311767578

Epoch: 5| Step: 3
Training loss: 2.6588776111602783
Validation loss: 2.443197291384461

Epoch: 5| Step: 4
Training loss: 2.0487842559814453
Validation loss: 2.440488766598445

Epoch: 5| Step: 5
Training loss: 2.388080358505249
Validation loss: 2.4449907272092757

Epoch: 5| Step: 6
Training loss: 2.382127046585083
Validation loss: 2.444172454136674

Epoch: 5| Step: 7
Training loss: 3.067619800567627
Validation loss: 2.441848119099935

Epoch: 5| Step: 8
Training loss: 2.7864954471588135
Validation loss: 2.4386816486235587

Epoch: 5| Step: 9
Training loss: 3.2230308055877686
Validation loss: 2.438004434749644

Epoch: 5| Step: 10
Training loss: 3.0696845054626465
Validation loss: 2.4461597140117357

Epoch: 49| Step: 0
Training loss: 3.4533348083496094
Validation loss: 2.4434323285215642

Epoch: 5| Step: 1
Training loss: 2.369328022003174
Validation loss: 2.4339219947015085

Epoch: 5| Step: 2
Training loss: 2.82307767868042
Validation loss: 2.4310947041357718

Epoch: 5| Step: 3
Training loss: 1.8031879663467407
Validation loss: 2.432306017926944

Epoch: 5| Step: 4
Training loss: 2.7021384239196777
Validation loss: 2.429324701268186

Epoch: 5| Step: 5
Training loss: 2.5530343055725098
Validation loss: 2.4289875620154926

Epoch: 5| Step: 6
Training loss: 2.75606107711792
Validation loss: 2.430341728271977

Epoch: 5| Step: 7
Training loss: 2.7933967113494873
Validation loss: 2.4362675989827802

Epoch: 5| Step: 8
Training loss: 2.9067013263702393
Validation loss: 2.43876600521867

Epoch: 5| Step: 9
Training loss: 2.1735613346099854
Validation loss: 2.4367429210293676

Epoch: 5| Step: 10
Training loss: 2.891772508621216
Validation loss: 2.438098079414778

Epoch: 50| Step: 0
Training loss: 2.382775068283081
Validation loss: 2.4438847111117457

Epoch: 5| Step: 1
Training loss: 1.8978246450424194
Validation loss: 2.45678101816485

Epoch: 5| Step: 2
Training loss: 3.2722244262695312
Validation loss: 2.4619269601760374

Epoch: 5| Step: 3
Training loss: 2.8354291915893555
Validation loss: 2.4669729509661273

Epoch: 5| Step: 4
Training loss: 2.5213699340820312
Validation loss: 2.4875053744162283

Epoch: 5| Step: 5
Training loss: 2.100231647491455
Validation loss: 2.47290777391003

Epoch: 5| Step: 6
Training loss: 3.5566649436950684
Validation loss: 2.4603179116402902

Epoch: 5| Step: 7
Training loss: 2.290003538131714
Validation loss: 2.44909337259108

Epoch: 5| Step: 8
Training loss: 2.489245653152466
Validation loss: 2.436147553946382

Epoch: 5| Step: 9
Training loss: 3.356440305709839
Validation loss: 2.4275571530865085

Epoch: 5| Step: 10
Training loss: 2.4392833709716797
Validation loss: 2.4264844514990367

Epoch: 51| Step: 0
Training loss: 2.9390931129455566
Validation loss: 2.42359479524756

Epoch: 5| Step: 1
Training loss: 2.998206615447998
Validation loss: 2.426295203547324

Epoch: 5| Step: 2
Training loss: 2.122530460357666
Validation loss: 2.426736436864381

Epoch: 5| Step: 3
Training loss: 2.732339859008789
Validation loss: 2.434428632900279

Epoch: 5| Step: 4
Training loss: 2.2834560871124268
Validation loss: 2.446292802851687

Epoch: 5| Step: 5
Training loss: 2.730583667755127
Validation loss: 2.445791357307024

Epoch: 5| Step: 6
Training loss: 2.4973533153533936
Validation loss: 2.455499777229883

Epoch: 5| Step: 7
Training loss: 2.722226619720459
Validation loss: 2.4547939685083207

Epoch: 5| Step: 8
Training loss: 2.0223822593688965
Validation loss: 2.4589034536833405

Epoch: 5| Step: 9
Training loss: 2.780688762664795
Validation loss: 2.473146976963166

Epoch: 5| Step: 10
Training loss: 3.4174611568450928
Validation loss: 2.4875174081453713

Epoch: 52| Step: 0
Training loss: 2.985797166824341
Validation loss: 2.5011700327678392

Epoch: 5| Step: 1
Training loss: 2.35990571975708
Validation loss: 2.5035977927587365

Epoch: 5| Step: 2
Training loss: 2.9872848987579346
Validation loss: 2.501830444541029

Epoch: 5| Step: 3
Training loss: 1.8771865367889404
Validation loss: 2.4988670990031254

Epoch: 5| Step: 4
Training loss: 2.9749436378479004
Validation loss: 2.4911889247996832

Epoch: 5| Step: 5
Training loss: 2.3612852096557617
Validation loss: 2.4864211800277873

Epoch: 5| Step: 6
Training loss: 2.904487371444702
Validation loss: 2.4826149222671345

Epoch: 5| Step: 7
Training loss: 3.005150318145752
Validation loss: 2.4762779076894126

Epoch: 5| Step: 8
Training loss: 2.9186244010925293
Validation loss: 2.4572804102333645

Epoch: 5| Step: 9
Training loss: 2.4956722259521484
Validation loss: 2.4450527775672173

Epoch: 5| Step: 10
Training loss: 2.491814374923706
Validation loss: 2.440794519198838

Epoch: 53| Step: 0
Training loss: 1.9371038675308228
Validation loss: 2.436299713709021

Epoch: 5| Step: 1
Training loss: 2.8971035480499268
Validation loss: 2.4316605547423005

Epoch: 5| Step: 2
Training loss: 3.0100953578948975
Validation loss: 2.4217138572405745

Epoch: 5| Step: 3
Training loss: 2.6382741928100586
Validation loss: 2.422740485078545

Epoch: 5| Step: 4
Training loss: 2.243307590484619
Validation loss: 2.423957460670061

Epoch: 5| Step: 5
Training loss: 2.733278274536133
Validation loss: 2.4344651058156

Epoch: 5| Step: 6
Training loss: 2.9607033729553223
Validation loss: 2.435467376503893

Epoch: 5| Step: 7
Training loss: 3.086927890777588
Validation loss: 2.454565466091197

Epoch: 5| Step: 8
Training loss: 2.2262344360351562
Validation loss: 2.450096986627066

Epoch: 5| Step: 9
Training loss: 2.6185266971588135
Validation loss: 2.4363134266227804

Epoch: 5| Step: 10
Training loss: 2.8289732933044434
Validation loss: 2.4306365802723873

Epoch: 54| Step: 0
Training loss: 2.217470645904541
Validation loss: 2.422994162446709

Epoch: 5| Step: 1
Training loss: 3.261383533477783
Validation loss: 2.416716880695794

Epoch: 5| Step: 2
Training loss: 3.047354221343994
Validation loss: 2.414577499512703

Epoch: 5| Step: 3
Training loss: 2.2060368061065674
Validation loss: 2.412560885952365

Epoch: 5| Step: 4
Training loss: 3.2694478034973145
Validation loss: 2.412932998390608

Epoch: 5| Step: 5
Training loss: 2.2969298362731934
Validation loss: 2.417392369239561

Epoch: 5| Step: 6
Training loss: 2.4228107929229736
Validation loss: 2.4212607747764996

Epoch: 5| Step: 7
Training loss: 2.474379777908325
Validation loss: 2.4275508721669516

Epoch: 5| Step: 8
Training loss: 2.7651848793029785
Validation loss: 2.4470166647306053

Epoch: 5| Step: 9
Training loss: 2.7120180130004883
Validation loss: 2.4482807190187517

Epoch: 5| Step: 10
Training loss: 2.435744047164917
Validation loss: 2.4368626430470455

Epoch: 55| Step: 0
Training loss: 3.106933116912842
Validation loss: 2.440450822153399

Epoch: 5| Step: 1
Training loss: 2.202096462249756
Validation loss: 2.4447446407810336

Epoch: 5| Step: 2
Training loss: 1.8878370523452759
Validation loss: 2.439551317563621

Epoch: 5| Step: 3
Training loss: 2.6336469650268555
Validation loss: 2.4360320362993466

Epoch: 5| Step: 4
Training loss: 3.436011552810669
Validation loss: 2.439969931879351

Epoch: 5| Step: 5
Training loss: 2.882403612136841
Validation loss: 2.4252703958942043

Epoch: 5| Step: 6
Training loss: 2.4722237586975098
Validation loss: 2.421611116778466

Epoch: 5| Step: 7
Training loss: 2.5375585556030273
Validation loss: 2.4153721794005363

Epoch: 5| Step: 8
Training loss: 2.7661736011505127
Validation loss: 2.40758539015247

Epoch: 5| Step: 9
Training loss: 2.8769941329956055
Validation loss: 2.405338805208924

Epoch: 5| Step: 10
Training loss: 2.155752420425415
Validation loss: 2.4086983921707317

Epoch: 56| Step: 0
Training loss: 3.2910587787628174
Validation loss: 2.4086439314708916

Epoch: 5| Step: 1
Training loss: 2.8388671875
Validation loss: 2.4040703414588847

Epoch: 5| Step: 2
Training loss: 2.530409336090088
Validation loss: 2.4012138869172786

Epoch: 5| Step: 3
Training loss: 2.3921151161193848
Validation loss: 2.402027940237394

Epoch: 5| Step: 4
Training loss: 2.6563589572906494
Validation loss: 2.4008941163298902

Epoch: 5| Step: 5
Training loss: 2.441072463989258
Validation loss: 2.398146745979145

Epoch: 5| Step: 6
Training loss: 2.4809699058532715
Validation loss: 2.402722353576332

Epoch: 5| Step: 7
Training loss: 2.7881557941436768
Validation loss: 2.415716871138542

Epoch: 5| Step: 8
Training loss: 3.0707263946533203
Validation loss: 2.4240968586296163

Epoch: 5| Step: 9
Training loss: 2.295175790786743
Validation loss: 2.424648748931064

Epoch: 5| Step: 10
Training loss: 2.230454206466675
Validation loss: 2.425274887392598

Epoch: 57| Step: 0
Training loss: 2.854523181915283
Validation loss: 2.4166551341292677

Epoch: 5| Step: 1
Training loss: 2.3810112476348877
Validation loss: 2.408480259679979

Epoch: 5| Step: 2
Training loss: 2.5496256351470947
Validation loss: 2.407692796440535

Epoch: 5| Step: 3
Training loss: 2.4112231731414795
Validation loss: 2.4043360269197853

Epoch: 5| Step: 4
Training loss: 2.836009979248047
Validation loss: 2.4054409098881546

Epoch: 5| Step: 5
Training loss: 2.7399542331695557
Validation loss: 2.3982156015211538

Epoch: 5| Step: 6
Training loss: 2.801194667816162
Validation loss: 2.4066454005497757

Epoch: 5| Step: 7
Training loss: 2.1098098754882812
Validation loss: 2.4058390894243793

Epoch: 5| Step: 8
Training loss: 2.978314161300659
Validation loss: 2.4357556066205426

Epoch: 5| Step: 9
Training loss: 2.288289785385132
Validation loss: 2.4124376696925007

Epoch: 5| Step: 10
Training loss: 3.1134731769561768
Validation loss: 2.4058357810461395

Epoch: 58| Step: 0
Training loss: 2.8865036964416504
Validation loss: 2.3983347031377975

Epoch: 5| Step: 1
Training loss: 2.58683180809021
Validation loss: 2.407322668260144

Epoch: 5| Step: 2
Training loss: 2.2220637798309326
Validation loss: 2.4283719831897366

Epoch: 5| Step: 3
Training loss: 2.2342922687530518
Validation loss: 2.4651678762128277

Epoch: 5| Step: 4
Training loss: 2.66618013381958
Validation loss: 2.477563606795444

Epoch: 5| Step: 5
Training loss: 2.444540023803711
Validation loss: 2.480101672551965

Epoch: 5| Step: 6
Training loss: 2.355924129486084
Validation loss: 2.453304262571437

Epoch: 5| Step: 7
Training loss: 3.0988409519195557
Validation loss: 2.432580171092864

Epoch: 5| Step: 8
Training loss: 3.0367839336395264
Validation loss: 2.409991479689075

Epoch: 5| Step: 9
Training loss: 2.292802333831787
Validation loss: 2.3955627500369983

Epoch: 5| Step: 10
Training loss: 3.385284662246704
Validation loss: 2.392444787486907

Epoch: 59| Step: 0
Training loss: 2.281890392303467
Validation loss: 2.39110908457028

Epoch: 5| Step: 1
Training loss: 2.5490386486053467
Validation loss: 2.389786656184863

Epoch: 5| Step: 2
Training loss: 2.8955140113830566
Validation loss: 2.3912490080761653

Epoch: 5| Step: 3
Training loss: 2.931561231613159
Validation loss: 2.3911381562550864

Epoch: 5| Step: 4
Training loss: 2.153937816619873
Validation loss: 2.3907864529599427

Epoch: 5| Step: 5
Training loss: 2.7532026767730713
Validation loss: 2.3901102465967976

Epoch: 5| Step: 6
Training loss: 2.0169079303741455
Validation loss: 2.389605504210277

Epoch: 5| Step: 7
Training loss: 2.7472243309020996
Validation loss: 2.3873058647237797

Epoch: 5| Step: 8
Training loss: 2.5883939266204834
Validation loss: 2.3859713282636417

Epoch: 5| Step: 9
Training loss: 3.1292052268981934
Validation loss: 2.388664601951517

Epoch: 5| Step: 10
Training loss: 3.0332136154174805
Validation loss: 2.3900886761244906

Epoch: 60| Step: 0
Training loss: 2.400555372238159
Validation loss: 2.411181926727295

Epoch: 5| Step: 1
Training loss: 3.425034284591675
Validation loss: 2.4262138348753735

Epoch: 5| Step: 2
Training loss: 2.3817522525787354
Validation loss: 2.4470666300865913

Epoch: 5| Step: 3
Training loss: 2.9048497676849365
Validation loss: 2.4438062893447055

Epoch: 5| Step: 4
Training loss: 2.618387460708618
Validation loss: 2.4550633020298456

Epoch: 5| Step: 5
Training loss: 2.077738046646118
Validation loss: 2.4509750437992874

Epoch: 5| Step: 6
Training loss: 2.743589401245117
Validation loss: 2.4436425150081678

Epoch: 5| Step: 7
Training loss: 2.714843273162842
Validation loss: 2.4413861023482455

Epoch: 5| Step: 8
Training loss: 2.3621058464050293
Validation loss: 2.4321699180910663

Epoch: 5| Step: 9
Training loss: 3.2445149421691895
Validation loss: 2.4300300536617154

Epoch: 5| Step: 10
Training loss: 1.9987541437149048
Validation loss: 2.425906199280934

Epoch: 61| Step: 0
Training loss: 2.061143398284912
Validation loss: 2.4240630493369153

Epoch: 5| Step: 1
Training loss: 2.600796699523926
Validation loss: 2.4236296889602498

Epoch: 5| Step: 2
Training loss: 3.076521396636963
Validation loss: 2.419060214873283

Epoch: 5| Step: 3
Training loss: 2.8145394325256348
Validation loss: 2.4185607766592376

Epoch: 5| Step: 4
Training loss: 2.042266845703125
Validation loss: 2.421989053808233

Epoch: 5| Step: 5
Training loss: 2.648902177810669
Validation loss: 2.4272512620495212

Epoch: 5| Step: 6
Training loss: 2.830535411834717
Validation loss: 2.426723454588203

Epoch: 5| Step: 7
Training loss: 2.708289623260498
Validation loss: 2.4343842972991285

Epoch: 5| Step: 8
Training loss: 3.0485470294952393
Validation loss: 2.432344921173588

Epoch: 5| Step: 9
Training loss: 1.9725828170776367
Validation loss: 2.435376141660957

Epoch: 5| Step: 10
Training loss: 3.2072551250457764
Validation loss: 2.436763859564258

Epoch: 62| Step: 0
Training loss: 2.841621160507202
Validation loss: 2.4329235271740983

Epoch: 5| Step: 1
Training loss: 2.334021806716919
Validation loss: 2.4320710166808097

Epoch: 5| Step: 2
Training loss: 1.9433012008666992
Validation loss: 2.4284116016921176

Epoch: 5| Step: 3
Training loss: 3.251746416091919
Validation loss: 2.4163597040278937

Epoch: 5| Step: 4
Training loss: 2.4435267448425293
Validation loss: 2.4122493446514173

Epoch: 5| Step: 5
Training loss: 2.3636550903320312
Validation loss: 2.4075985159925235

Epoch: 5| Step: 6
Training loss: 2.978227138519287
Validation loss: 2.4124676565970145

Epoch: 5| Step: 7
Training loss: 2.273075819015503
Validation loss: 2.4166127225404144

Epoch: 5| Step: 8
Training loss: 2.25614595413208
Validation loss: 2.4158748144744546

Epoch: 5| Step: 9
Training loss: 2.9980664253234863
Validation loss: 2.422583482598746

Epoch: 5| Step: 10
Training loss: 3.413822650909424
Validation loss: 2.4212293496695896

Epoch: 63| Step: 0
Training loss: 2.57558012008667
Validation loss: 2.427638187203356

Epoch: 5| Step: 1
Training loss: 2.6032607555389404
Validation loss: 2.4302885814379622

Epoch: 5| Step: 2
Training loss: 2.592874526977539
Validation loss: 2.4352111636951403

Epoch: 5| Step: 3
Training loss: 1.9410321712493896
Validation loss: 2.428294433060513

Epoch: 5| Step: 4
Training loss: 3.0219826698303223
Validation loss: 2.4348717197295158

Epoch: 5| Step: 5
Training loss: 2.550191879272461
Validation loss: 2.4268973565870717

Epoch: 5| Step: 6
Training loss: 2.65124773979187
Validation loss: 2.4124379696384555

Epoch: 5| Step: 7
Training loss: 2.950180768966675
Validation loss: 2.4142657210749965

Epoch: 5| Step: 8
Training loss: 3.1514275074005127
Validation loss: 2.4064431857037287

Epoch: 5| Step: 9
Training loss: 1.7065880298614502
Validation loss: 2.4113576155836864

Epoch: 5| Step: 10
Training loss: 3.157277822494507
Validation loss: 2.426387361300889

Epoch: 64| Step: 0
Training loss: 1.811476707458496
Validation loss: 2.419494769906485

Epoch: 5| Step: 1
Training loss: 2.598768711090088
Validation loss: 2.420304493237567

Epoch: 5| Step: 2
Training loss: 2.7006278038024902
Validation loss: 2.404809387781287

Epoch: 5| Step: 3
Training loss: 3.5328750610351562
Validation loss: 2.410919056143812

Epoch: 5| Step: 4
Training loss: 2.8996801376342773
Validation loss: 2.406499952398321

Epoch: 5| Step: 5
Training loss: 2.2950756549835205
Validation loss: 2.40302098694668

Epoch: 5| Step: 6
Training loss: 2.5639071464538574
Validation loss: 2.401146529823221

Epoch: 5| Step: 7
Training loss: 2.556013584136963
Validation loss: 2.4085334359958606

Epoch: 5| Step: 8
Training loss: 2.7400760650634766
Validation loss: 2.411033473989015

Epoch: 5| Step: 9
Training loss: 2.62968373298645
Validation loss: 2.4260894239589734

Epoch: 5| Step: 10
Training loss: 2.5303139686584473
Validation loss: 2.4375794933688257

Epoch: 65| Step: 0
Training loss: 2.0334277153015137
Validation loss: 2.424534856632192

Epoch: 5| Step: 1
Training loss: 3.0072073936462402
Validation loss: 2.423609595144949

Epoch: 5| Step: 2
Training loss: 2.311028480529785
Validation loss: 2.412925115195654

Epoch: 5| Step: 3
Training loss: 2.235565423965454
Validation loss: 2.416372404303602

Epoch: 5| Step: 4
Training loss: 2.5193543434143066
Validation loss: 2.43146683836496

Epoch: 5| Step: 5
Training loss: 3.253476619720459
Validation loss: 2.450101980599024

Epoch: 5| Step: 6
Training loss: 2.826442241668701
Validation loss: 2.4517158154518373

Epoch: 5| Step: 7
Training loss: 2.5024526119232178
Validation loss: 2.420757842320268

Epoch: 5| Step: 8
Training loss: 3.1524739265441895
Validation loss: 2.4283471235664944

Epoch: 5| Step: 9
Training loss: 2.5417137145996094
Validation loss: 2.4155583356016423

Epoch: 5| Step: 10
Training loss: 2.457270860671997
Validation loss: 2.4205725859570246

Epoch: 66| Step: 0
Training loss: 2.195920944213867
Validation loss: 2.4113220271243843

Epoch: 5| Step: 1
Training loss: 2.7289111614227295
Validation loss: 2.4086583250312397

Epoch: 5| Step: 2
Training loss: 2.9549431800842285
Validation loss: 2.397680769684494

Epoch: 5| Step: 3
Training loss: 2.510716676712036
Validation loss: 2.3899431305546917

Epoch: 5| Step: 4
Training loss: 1.7278801202774048
Validation loss: 2.390326282029511

Epoch: 5| Step: 5
Training loss: 2.7251648902893066
Validation loss: 2.3823358192238757

Epoch: 5| Step: 6
Training loss: 2.477079153060913
Validation loss: 2.3729499911749237

Epoch: 5| Step: 7
Training loss: 2.954080581665039
Validation loss: 2.375437444256198

Epoch: 5| Step: 8
Training loss: 2.789130687713623
Validation loss: 2.370973945945822

Epoch: 5| Step: 9
Training loss: 3.052274227142334
Validation loss: 2.381820499256093

Epoch: 5| Step: 10
Training loss: 2.6628081798553467
Validation loss: 2.380977717779016

Epoch: 67| Step: 0
Training loss: 2.643842935562134
Validation loss: 2.379433875442833

Epoch: 5| Step: 1
Training loss: 2.854565382003784
Validation loss: 2.386851285093574

Epoch: 5| Step: 2
Training loss: 3.0504698753356934
Validation loss: 2.3876206310846473

Epoch: 5| Step: 3
Training loss: 2.3875625133514404
Validation loss: 2.386359848001952

Epoch: 5| Step: 4
Training loss: 2.495687961578369
Validation loss: 2.3752404797461724

Epoch: 5| Step: 5
Training loss: 2.2306573390960693
Validation loss: 2.369520943651917

Epoch: 5| Step: 6
Training loss: 2.5251712799072266
Validation loss: 2.3771788074124243

Epoch: 5| Step: 7
Training loss: 3.077685594558716
Validation loss: 2.37497615814209

Epoch: 5| Step: 8
Training loss: 2.2551944255828857
Validation loss: 2.374961642808812

Epoch: 5| Step: 9
Training loss: 2.6451802253723145
Validation loss: 2.376513111975885

Epoch: 5| Step: 10
Training loss: 2.546125888824463
Validation loss: 2.3820658063375824

Epoch: 68| Step: 0
Training loss: 3.0797736644744873
Validation loss: 2.3900325477764173

Epoch: 5| Step: 1
Training loss: 2.8642971515655518
Validation loss: 2.4049944339259977

Epoch: 5| Step: 2
Training loss: 1.8676382303237915
Validation loss: 2.404741394904352

Epoch: 5| Step: 3
Training loss: 2.0661680698394775
Validation loss: 2.3920724366300847

Epoch: 5| Step: 4
Training loss: 2.5966439247131348
Validation loss: 2.3794462629543838

Epoch: 5| Step: 5
Training loss: 2.9728341102600098
Validation loss: 2.3744175703294816

Epoch: 5| Step: 6
Training loss: 2.7819790840148926
Validation loss: 2.3683607116822274

Epoch: 5| Step: 7
Training loss: 1.9812548160552979
Validation loss: 2.3706346763077604

Epoch: 5| Step: 8
Training loss: 3.2102901935577393
Validation loss: 2.36194787486907

Epoch: 5| Step: 9
Training loss: 2.6694602966308594
Validation loss: 2.3609385977509203

Epoch: 5| Step: 10
Training loss: 2.615518569946289
Validation loss: 2.358621281962241

Epoch: 69| Step: 0
Training loss: 3.349343776702881
Validation loss: 2.3590660351578907

Epoch: 5| Step: 1
Training loss: 2.677481174468994
Validation loss: 2.3573586915128972

Epoch: 5| Step: 2
Training loss: 3.0497682094573975
Validation loss: 2.353196741432272

Epoch: 5| Step: 3
Training loss: 3.051689624786377
Validation loss: 2.352757259081769

Epoch: 5| Step: 4
Training loss: 2.968613386154175
Validation loss: 2.3726869014001664

Epoch: 5| Step: 5
Training loss: 2.0380070209503174
Validation loss: 2.3992437316525366

Epoch: 5| Step: 6
Training loss: 2.1814346313476562
Validation loss: 2.420898101663077

Epoch: 5| Step: 7
Training loss: 1.9504083395004272
Validation loss: 2.4400220814571587

Epoch: 5| Step: 8
Training loss: 3.0000619888305664
Validation loss: 2.4465750737856795

Epoch: 5| Step: 9
Training loss: 2.3451123237609863
Validation loss: 2.4450929369977725

Epoch: 5| Step: 10
Training loss: 2.154618263244629
Validation loss: 2.438632013977215

Epoch: 70| Step: 0
Training loss: 2.3115522861480713
Validation loss: 2.4162732734475085

Epoch: 5| Step: 1
Training loss: 3.3597493171691895
Validation loss: 2.3974335270543254

Epoch: 5| Step: 2
Training loss: 1.8083629608154297
Validation loss: 2.3993625948506017

Epoch: 5| Step: 3
Training loss: 2.659339427947998
Validation loss: 2.3835355697139615

Epoch: 5| Step: 4
Training loss: 3.244213581085205
Validation loss: 2.383424330783147

Epoch: 5| Step: 5
Training loss: 2.4455173015594482
Validation loss: 2.3850660631733556

Epoch: 5| Step: 6
Training loss: 2.501575469970703
Validation loss: 2.3905841663319576

Epoch: 5| Step: 7
Training loss: 2.482121706008911
Validation loss: 2.399018718350318

Epoch: 5| Step: 8
Training loss: 2.6167330741882324
Validation loss: 2.417388213578091

Epoch: 5| Step: 9
Training loss: 2.9931282997131348
Validation loss: 2.4153045710696968

Epoch: 5| Step: 10
Training loss: 2.2818753719329834
Validation loss: 2.4148448333945325

Epoch: 71| Step: 0
Training loss: 2.3440730571746826
Validation loss: 2.4055238718627603

Epoch: 5| Step: 1
Training loss: 2.4834301471710205
Validation loss: 2.4017299990500174

Epoch: 5| Step: 2
Training loss: 2.108591079711914
Validation loss: 2.3960610153854534

Epoch: 5| Step: 3
Training loss: 2.2941012382507324
Validation loss: 2.385658106496257

Epoch: 5| Step: 4
Training loss: 2.3072075843811035
Validation loss: 2.3780629942494054

Epoch: 5| Step: 5
Training loss: 3.012160062789917
Validation loss: 2.374141041950513

Epoch: 5| Step: 6
Training loss: 3.0828938484191895
Validation loss: 2.3767456316178843

Epoch: 5| Step: 7
Training loss: 2.8049888610839844
Validation loss: 2.377567906533518

Epoch: 5| Step: 8
Training loss: 3.160114049911499
Validation loss: 2.3702655338471934

Epoch: 5| Step: 9
Training loss: 2.5898427963256836
Validation loss: 2.380401522882523

Epoch: 5| Step: 10
Training loss: 2.5203566551208496
Validation loss: 2.3776265177675473

Epoch: 72| Step: 0
Training loss: 2.3672165870666504
Validation loss: 2.365702317607018

Epoch: 5| Step: 1
Training loss: 2.384852886199951
Validation loss: 2.364944757953767

Epoch: 5| Step: 2
Training loss: 2.636618137359619
Validation loss: 2.365508679420717

Epoch: 5| Step: 3
Training loss: 3.016296148300171
Validation loss: 2.360456359001898

Epoch: 5| Step: 4
Training loss: 1.9387600421905518
Validation loss: 2.3603310200475875

Epoch: 5| Step: 5
Training loss: 2.2807981967926025
Validation loss: 2.3567807494953112

Epoch: 5| Step: 6
Training loss: 3.059204578399658
Validation loss: 2.3602822647299817

Epoch: 5| Step: 7
Training loss: 2.866014003753662
Validation loss: 2.3606472169199297

Epoch: 5| Step: 8
Training loss: 3.3073387145996094
Validation loss: 2.360881177327966

Epoch: 5| Step: 9
Training loss: 2.8665261268615723
Validation loss: 2.352714325792046

Epoch: 5| Step: 10
Training loss: 1.7002185583114624
Validation loss: 2.356310870057793

Epoch: 73| Step: 0
Training loss: 2.393622875213623
Validation loss: 2.3573970358858825

Epoch: 5| Step: 1
Training loss: 2.6851892471313477
Validation loss: 2.3649481496503277

Epoch: 5| Step: 2
Training loss: 3.1321444511413574
Validation loss: 2.3623207499904018

Epoch: 5| Step: 3
Training loss: 2.389147996902466
Validation loss: 2.365054826582632

Epoch: 5| Step: 4
Training loss: 2.028747320175171
Validation loss: 2.358902700485722

Epoch: 5| Step: 5
Training loss: 2.9369723796844482
Validation loss: 2.3731650511423745

Epoch: 5| Step: 6
Training loss: 2.637136936187744
Validation loss: 2.3742311616097727

Epoch: 5| Step: 7
Training loss: 2.504301071166992
Validation loss: 2.396561171418877

Epoch: 5| Step: 8
Training loss: 2.3800177574157715
Validation loss: 2.408005937453239

Epoch: 5| Step: 9
Training loss: 2.798337697982788
Validation loss: 2.4019230488807923

Epoch: 5| Step: 10
Training loss: 2.7770934104919434
Validation loss: 2.4007248801569783

Epoch: 74| Step: 0
Training loss: 2.757272720336914
Validation loss: 2.380369694002213

Epoch: 5| Step: 1
Training loss: 3.0589797496795654
Validation loss: 2.369289432802508

Epoch: 5| Step: 2
Training loss: 2.7312867641448975
Validation loss: 2.3537742258400045

Epoch: 5| Step: 3
Training loss: 2.3569235801696777
Validation loss: 2.3455160843428744

Epoch: 5| Step: 4
Training loss: 1.4874403476715088
Validation loss: 2.3446362018585205

Epoch: 5| Step: 5
Training loss: 2.9025590419769287
Validation loss: 2.3419259517423567

Epoch: 5| Step: 6
Training loss: 2.6066572666168213
Validation loss: 2.34520387136808

Epoch: 5| Step: 7
Training loss: 2.3690807819366455
Validation loss: 2.3494745864663074

Epoch: 5| Step: 8
Training loss: 3.218877077102661
Validation loss: 2.3482127728000766

Epoch: 5| Step: 9
Training loss: 2.1748881340026855
Validation loss: 2.351381327516289

Epoch: 5| Step: 10
Training loss: 2.8081586360931396
Validation loss: 2.346765616888641

Epoch: 75| Step: 0
Training loss: 3.1146774291992188
Validation loss: 2.3575268945386334

Epoch: 5| Step: 1
Training loss: 2.4611783027648926
Validation loss: 2.360263878299344

Epoch: 5| Step: 2
Training loss: 2.8373522758483887
Validation loss: 2.36431364346576

Epoch: 5| Step: 3
Training loss: 2.8230512142181396
Validation loss: 2.3617299064513175

Epoch: 5| Step: 4
Training loss: 2.291018486022949
Validation loss: 2.3733927729309245

Epoch: 5| Step: 5
Training loss: 2.277357339859009
Validation loss: 2.378678878148397

Epoch: 5| Step: 6
Training loss: 2.683361053466797
Validation loss: 2.3698271295075775

Epoch: 5| Step: 7
Training loss: 2.7414934635162354
Validation loss: 2.356407583400767

Epoch: 5| Step: 8
Training loss: 2.3386759757995605
Validation loss: 2.3562501348474973

Epoch: 5| Step: 9
Training loss: 2.4806385040283203
Validation loss: 2.348538839688865

Epoch: 5| Step: 10
Training loss: 2.397909164428711
Validation loss: 2.344896824129166

Epoch: 76| Step: 0
Training loss: 2.501411199569702
Validation loss: 2.3404413653958227

Epoch: 5| Step: 1
Training loss: 2.170775890350342
Validation loss: 2.3431067569281465

Epoch: 5| Step: 2
Training loss: 2.4959025382995605
Validation loss: 2.3412484148497223

Epoch: 5| Step: 3
Training loss: 2.9336869716644287
Validation loss: 2.3425571944123957

Epoch: 5| Step: 4
Training loss: 2.4953861236572266
Validation loss: 2.3416114596910376

Epoch: 5| Step: 5
Training loss: 2.445099115371704
Validation loss: 2.3376483096871326

Epoch: 5| Step: 6
Training loss: 2.524040937423706
Validation loss: 2.3429727733776136

Epoch: 5| Step: 7
Training loss: 2.8286068439483643
Validation loss: 2.348780911455872

Epoch: 5| Step: 8
Training loss: 2.662529468536377
Validation loss: 2.3511166470025175

Epoch: 5| Step: 9
Training loss: 2.3884477615356445
Validation loss: 2.36303420477016

Epoch: 5| Step: 10
Training loss: 3.1785778999328613
Validation loss: 2.365341983815675

Epoch: 77| Step: 0
Training loss: 3.3102760314941406
Validation loss: 2.3841937613743607

Epoch: 5| Step: 1
Training loss: 3.177391529083252
Validation loss: 2.373369134882445

Epoch: 5| Step: 2
Training loss: 2.7418181896209717
Validation loss: 2.3619914823962795

Epoch: 5| Step: 3
Training loss: 2.013256549835205
Validation loss: 2.350461229201286

Epoch: 5| Step: 4
Training loss: 2.327974319458008
Validation loss: 2.346249072782455

Epoch: 5| Step: 5
Training loss: 2.5908010005950928
Validation loss: 2.3402316211372294

Epoch: 5| Step: 6
Training loss: 2.2826733589172363
Validation loss: 2.343497040451214

Epoch: 5| Step: 7
Training loss: 2.7913577556610107
Validation loss: 2.3472061772500314

Epoch: 5| Step: 8
Training loss: 2.641012668609619
Validation loss: 2.3494648343773297

Epoch: 5| Step: 9
Training loss: 2.116605281829834
Validation loss: 2.361277408497308

Epoch: 5| Step: 10
Training loss: 2.551215648651123
Validation loss: 2.3818272262491207

Epoch: 78| Step: 0
Training loss: 2.7395825386047363
Validation loss: 2.397047427392775

Epoch: 5| Step: 1
Training loss: 2.2961201667785645
Validation loss: 2.40458986836095

Epoch: 5| Step: 2
Training loss: 3.2940597534179688
Validation loss: 2.4270196576272287

Epoch: 5| Step: 3
Training loss: 2.86216402053833
Validation loss: 2.4151396853949434

Epoch: 5| Step: 4
Training loss: 2.960932493209839
Validation loss: 2.384093338443387

Epoch: 5| Step: 5
Training loss: 2.4269518852233887
Validation loss: 2.36289708845077

Epoch: 5| Step: 6
Training loss: 2.061297655105591
Validation loss: 2.3471402814311366

Epoch: 5| Step: 7
Training loss: 2.7732605934143066
Validation loss: 2.3425231954102874

Epoch: 5| Step: 8
Training loss: 2.4222867488861084
Validation loss: 2.34183753946776

Epoch: 5| Step: 9
Training loss: 2.5627574920654297
Validation loss: 2.3434391085819533

Epoch: 5| Step: 10
Training loss: 1.974981427192688
Validation loss: 2.337893855187201

Epoch: 79| Step: 0
Training loss: 2.5465426445007324
Validation loss: 2.334018007401497

Epoch: 5| Step: 1
Training loss: 2.0931925773620605
Validation loss: 2.3324522741379274

Epoch: 5| Step: 2
Training loss: 2.3801026344299316
Validation loss: 2.3338174358490975

Epoch: 5| Step: 3
Training loss: 2.2068424224853516
Validation loss: 2.330517038222282

Epoch: 5| Step: 4
Training loss: 3.388026475906372
Validation loss: 2.346665323421519

Epoch: 5| Step: 5
Training loss: 2.175239086151123
Validation loss: 2.351763984208466

Epoch: 5| Step: 6
Training loss: 3.111919641494751
Validation loss: 2.361870861822559

Epoch: 5| Step: 7
Training loss: 2.3028626441955566
Validation loss: 2.3643489422336703

Epoch: 5| Step: 8
Training loss: 2.6346523761749268
Validation loss: 2.3552130371011715

Epoch: 5| Step: 9
Training loss: 2.660649061203003
Validation loss: 2.3436286423795964

Epoch: 5| Step: 10
Training loss: 3.0811808109283447
Validation loss: 2.327996494949505

Epoch: 80| Step: 0
Training loss: 2.562074661254883
Validation loss: 2.324065564781107

Epoch: 5| Step: 1
Training loss: 2.5966057777404785
Validation loss: 2.3171050753644717

Epoch: 5| Step: 2
Training loss: 2.5363197326660156
Validation loss: 2.3253191324972335

Epoch: 5| Step: 3
Training loss: 2.961822986602783
Validation loss: 2.3313122359655236

Epoch: 5| Step: 4
Training loss: 2.4098904132843018
Validation loss: 2.3581548711305023

Epoch: 5| Step: 5
Training loss: 2.739635467529297
Validation loss: 2.3562841646132933

Epoch: 5| Step: 6
Training loss: 2.2981507778167725
Validation loss: 2.363570074881277

Epoch: 5| Step: 7
Training loss: 2.3177928924560547
Validation loss: 2.3539601692589383

Epoch: 5| Step: 8
Training loss: 2.645211696624756
Validation loss: 2.3499257461999052

Epoch: 5| Step: 9
Training loss: 3.201369524002075
Validation loss: 2.340734948394119

Epoch: 5| Step: 10
Training loss: 2.1374175548553467
Validation loss: 2.3264659143263295

Epoch: 81| Step: 0
Training loss: 2.8077540397644043
Validation loss: 2.320861554914905

Epoch: 5| Step: 1
Training loss: 2.3983898162841797
Validation loss: 2.3149298262852493

Epoch: 5| Step: 2
Training loss: 2.5844943523406982
Validation loss: 2.312618322269891

Epoch: 5| Step: 3
Training loss: 2.337130069732666
Validation loss: 2.3148939917164464

Epoch: 5| Step: 4
Training loss: 2.8502211570739746
Validation loss: 2.318843041696856

Epoch: 5| Step: 5
Training loss: 2.7252659797668457
Validation loss: 2.317009531041627

Epoch: 5| Step: 6
Training loss: 3.28550386428833
Validation loss: 2.3246781005654285

Epoch: 5| Step: 7
Training loss: 2.4995601177215576
Validation loss: 2.328438303803885

Epoch: 5| Step: 8
Training loss: 2.057816743850708
Validation loss: 2.348453703747001

Epoch: 5| Step: 9
Training loss: 2.2685914039611816
Validation loss: 2.3636850387819353

Epoch: 5| Step: 10
Training loss: 2.6426331996917725
Validation loss: 2.364971068597609

Epoch: 82| Step: 0
Training loss: 2.6243748664855957
Validation loss: 2.367012787890691

Epoch: 5| Step: 1
Training loss: 2.587193727493286
Validation loss: 2.3681290816235285

Epoch: 5| Step: 2
Training loss: 2.2262680530548096
Validation loss: 2.3738648327448035

Epoch: 5| Step: 3
Training loss: 2.4039013385772705
Validation loss: 2.381062671702395

Epoch: 5| Step: 4
Training loss: 2.512007713317871
Validation loss: 2.3708113649839997

Epoch: 5| Step: 5
Training loss: 2.508748769760132
Validation loss: 2.344833209950437

Epoch: 5| Step: 6
Training loss: 2.3661320209503174
Validation loss: 2.332966399449174

Epoch: 5| Step: 7
Training loss: 2.659592866897583
Validation loss: 2.3398826417102607

Epoch: 5| Step: 8
Training loss: 2.6877593994140625
Validation loss: 2.341942830752301

Epoch: 5| Step: 9
Training loss: 2.5925345420837402
Validation loss: 2.3447943656675276

Epoch: 5| Step: 10
Training loss: 3.4375951290130615
Validation loss: 2.349730650583903

Epoch: 83| Step: 0
Training loss: 2.157892942428589
Validation loss: 2.3343852489225325

Epoch: 5| Step: 1
Training loss: 2.587299108505249
Validation loss: 2.3168612193035822

Epoch: 5| Step: 2
Training loss: 2.4435362815856934
Validation loss: 2.3185316183233775

Epoch: 5| Step: 3
Training loss: 2.6931581497192383
Validation loss: 2.326438516698858

Epoch: 5| Step: 4
Training loss: 2.3350670337677
Validation loss: 2.3275221240135933

Epoch: 5| Step: 5
Training loss: 1.8685433864593506
Validation loss: 2.334144451284921

Epoch: 5| Step: 6
Training loss: 2.4222843647003174
Validation loss: 2.339138715497909

Epoch: 5| Step: 7
Training loss: 2.5870227813720703
Validation loss: 2.345712028523927

Epoch: 5| Step: 8
Training loss: 2.699218988418579
Validation loss: 2.3400377970869823

Epoch: 5| Step: 9
Training loss: 3.3715713024139404
Validation loss: 2.3375924864122943

Epoch: 5| Step: 10
Training loss: 3.4186832904815674
Validation loss: 2.332685479553797

Epoch: 84| Step: 0
Training loss: 1.7086127996444702
Validation loss: 2.3185835499917307

Epoch: 5| Step: 1
Training loss: 2.5912511348724365
Validation loss: 2.3201586918164323

Epoch: 5| Step: 2
Training loss: 2.665977954864502
Validation loss: 2.334993359863117

Epoch: 5| Step: 3
Training loss: 2.400150775909424
Validation loss: 2.3422380365351194

Epoch: 5| Step: 4
Training loss: 2.5733251571655273
Validation loss: 2.361654950726417

Epoch: 5| Step: 5
Training loss: 2.9396839141845703
Validation loss: 2.3594509427265455

Epoch: 5| Step: 6
Training loss: 2.4717440605163574
Validation loss: 2.3564499373077066

Epoch: 5| Step: 7
Training loss: 2.302950382232666
Validation loss: 2.341971151290401

Epoch: 5| Step: 8
Training loss: 2.654794454574585
Validation loss: 2.3356856863985778

Epoch: 5| Step: 9
Training loss: 3.2621757984161377
Validation loss: 2.3277228647662747

Epoch: 5| Step: 10
Training loss: 2.773954153060913
Validation loss: 2.3245074492628857

Epoch: 85| Step: 0
Training loss: 2.578295946121216
Validation loss: 2.324262983055525

Epoch: 5| Step: 1
Training loss: 2.971848726272583
Validation loss: 2.3227420032665296

Epoch: 5| Step: 2
Training loss: 2.48508620262146
Validation loss: 2.322533089627502

Epoch: 5| Step: 3
Training loss: 2.4966228008270264
Validation loss: 2.33923605949648

Epoch: 5| Step: 4
Training loss: 2.3761022090911865
Validation loss: 2.3560626891351517

Epoch: 5| Step: 5
Training loss: 2.1569740772247314
Validation loss: 2.3659066948839413

Epoch: 5| Step: 6
Training loss: 2.9990735054016113
Validation loss: 2.361932959607852

Epoch: 5| Step: 7
Training loss: 2.807832717895508
Validation loss: 2.3667680909556728

Epoch: 5| Step: 8
Training loss: 2.140718936920166
Validation loss: 2.3570483807594544

Epoch: 5| Step: 9
Training loss: 2.892392158508301
Validation loss: 2.331688186173798

Epoch: 5| Step: 10
Training loss: 2.223428249359131
Validation loss: 2.3228060404459634

Epoch: 86| Step: 0
Training loss: 2.8402512073516846
Validation loss: 2.3255284947733723

Epoch: 5| Step: 1
Training loss: 1.9697325229644775
Validation loss: 2.3265950295232956

Epoch: 5| Step: 2
Training loss: 2.489776134490967
Validation loss: 2.3260490163680045

Epoch: 5| Step: 3
Training loss: 2.2831308841705322
Validation loss: 2.3264597051887104

Epoch: 5| Step: 4
Training loss: 2.281740665435791
Validation loss: 2.326693001613822

Epoch: 5| Step: 5
Training loss: 3.264164447784424
Validation loss: 2.3331750285240913

Epoch: 5| Step: 6
Training loss: 2.421952724456787
Validation loss: 2.335172589107226

Epoch: 5| Step: 7
Training loss: 2.49635648727417
Validation loss: 2.347755511601766

Epoch: 5| Step: 8
Training loss: 2.79019832611084
Validation loss: 2.3653551327284945

Epoch: 5| Step: 9
Training loss: 2.583730936050415
Validation loss: 2.3798739141033542

Epoch: 5| Step: 10
Training loss: 2.954253911972046
Validation loss: 2.388647738323417

Epoch: 87| Step: 0
Training loss: 3.456723690032959
Validation loss: 2.3874096639694704

Epoch: 5| Step: 1
Training loss: 2.562404155731201
Validation loss: 2.386183969436153

Epoch: 5| Step: 2
Training loss: 2.4108150005340576
Validation loss: 2.375908059458579

Epoch: 5| Step: 3
Training loss: 2.0709891319274902
Validation loss: 2.3498017659751316

Epoch: 5| Step: 4
Training loss: 2.2295262813568115
Validation loss: 2.3343919810428413

Epoch: 5| Step: 5
Training loss: 2.347520589828491
Validation loss: 2.314653096660491

Epoch: 5| Step: 6
Training loss: 2.804042100906372
Validation loss: 2.3088571999662664

Epoch: 5| Step: 7
Training loss: 2.7359306812286377
Validation loss: 2.311053963117702

Epoch: 5| Step: 8
Training loss: 2.224046468734741
Validation loss: 2.3234337106827767

Epoch: 5| Step: 9
Training loss: 2.851716995239258
Validation loss: 2.32501329657852

Epoch: 5| Step: 10
Training loss: 2.8144149780273438
Validation loss: 2.320590023071535

Epoch: 88| Step: 0
Training loss: 2.4150962829589844
Validation loss: 2.3125645524712017

Epoch: 5| Step: 1
Training loss: 2.9391930103302
Validation loss: 2.3089473888438237

Epoch: 5| Step: 2
Training loss: 3.033674955368042
Validation loss: 2.3004795735882175

Epoch: 5| Step: 3
Training loss: 2.2701611518859863
Validation loss: 2.290110365036995

Epoch: 5| Step: 4
Training loss: 2.5481059551239014
Validation loss: 2.297067606320945

Epoch: 5| Step: 5
Training loss: 2.8363823890686035
Validation loss: 2.306465361707954

Epoch: 5| Step: 6
Training loss: 2.2542152404785156
Validation loss: 2.3142967429212344

Epoch: 5| Step: 7
Training loss: 2.3070740699768066
Validation loss: 2.3262943977950723

Epoch: 5| Step: 8
Training loss: 2.8401541709899902
Validation loss: 2.3497112643334175

Epoch: 5| Step: 9
Training loss: 2.225886344909668
Validation loss: 2.3677866151255946

Epoch: 5| Step: 10
Training loss: 2.553290605545044
Validation loss: 2.398714970516902

Epoch: 89| Step: 0
Training loss: 2.088068723678589
Validation loss: 2.381644336126184

Epoch: 5| Step: 1
Training loss: 2.4706196784973145
Validation loss: 2.3297065919445408

Epoch: 5| Step: 2
Training loss: 3.3719725608825684
Validation loss: 2.305026092836934

Epoch: 5| Step: 3
Training loss: 3.0126547813415527
Validation loss: 2.2881772236157487

Epoch: 5| Step: 4
Training loss: 2.264331102371216
Validation loss: 2.3010959291970856

Epoch: 5| Step: 5
Training loss: 2.7403640747070312
Validation loss: 2.319100700398927

Epoch: 5| Step: 6
Training loss: 2.760221004486084
Validation loss: 2.329705253724129

Epoch: 5| Step: 7
Training loss: 2.657886505126953
Validation loss: 2.348778660579394

Epoch: 5| Step: 8
Training loss: 2.356086254119873
Validation loss: 2.3800046777212494

Epoch: 5| Step: 9
Training loss: 2.1850745677948
Validation loss: 2.420427781279369

Epoch: 5| Step: 10
Training loss: 2.5041611194610596
Validation loss: 2.4391404531335317

Epoch: 90| Step: 0
Training loss: 2.5392239093780518
Validation loss: 2.319346115153323

Epoch: 5| Step: 1
Training loss: 2.0714869499206543
Validation loss: 2.297171083829736

Epoch: 5| Step: 2
Training loss: 2.4520416259765625
Validation loss: 2.285979534990044

Epoch: 5| Step: 3
Training loss: 2.559342622756958
Validation loss: 2.281999321394069

Epoch: 5| Step: 4
Training loss: 2.2928576469421387
Validation loss: 2.2984386233873266

Epoch: 5| Step: 5
Training loss: 2.808598756790161
Validation loss: 2.3340217323713404

Epoch: 5| Step: 6
Training loss: 2.174659252166748
Validation loss: 2.363132888270963

Epoch: 5| Step: 7
Training loss: 2.6202473640441895
Validation loss: 2.3964210402581

Epoch: 5| Step: 8
Training loss: 2.981921672821045
Validation loss: 2.3969127337137857

Epoch: 5| Step: 9
Training loss: 2.5516726970672607
Validation loss: 2.3854362349356375

Epoch: 5| Step: 10
Training loss: 3.405256986618042
Validation loss: 2.3840015729268393

Epoch: 91| Step: 0
Training loss: 2.43169903755188
Validation loss: 2.3846585032760457

Epoch: 5| Step: 1
Training loss: 2.562772750854492
Validation loss: 2.3694324493408203

Epoch: 5| Step: 2
Training loss: 2.959681987762451
Validation loss: 2.3326919886373703

Epoch: 5| Step: 3
Training loss: 2.330209255218506
Validation loss: 2.3047319625013616

Epoch: 5| Step: 4
Training loss: 2.4290096759796143
Validation loss: 2.2963047771043676

Epoch: 5| Step: 5
Training loss: 2.300894260406494
Validation loss: 2.2990824330237603

Epoch: 5| Step: 6
Training loss: 2.183323860168457
Validation loss: 2.303211699249924

Epoch: 5| Step: 7
Training loss: 2.7175722122192383
Validation loss: 2.3013501782571115

Epoch: 5| Step: 8
Training loss: 2.971325397491455
Validation loss: 2.301464965266566

Epoch: 5| Step: 9
Training loss: 2.0960583686828613
Validation loss: 2.304251706728371

Epoch: 5| Step: 10
Training loss: 3.3946492671966553
Validation loss: 2.294530519875147

Epoch: 92| Step: 0
Training loss: 2.772996187210083
Validation loss: 2.284138387249362

Epoch: 5| Step: 1
Training loss: 2.9018664360046387
Validation loss: 2.284180215609971

Epoch: 5| Step: 2
Training loss: 2.8637821674346924
Validation loss: 2.278732984296737

Epoch: 5| Step: 3
Training loss: 2.2284045219421387
Validation loss: 2.28440978962888

Epoch: 5| Step: 4
Training loss: 2.391407012939453
Validation loss: 2.2861837520394275

Epoch: 5| Step: 5
Training loss: 2.8625075817108154
Validation loss: 2.283409536525767

Epoch: 5| Step: 6
Training loss: 2.0556697845458984
Validation loss: 2.2854460131737495

Epoch: 5| Step: 7
Training loss: 2.1571450233459473
Validation loss: 2.2997169084446405

Epoch: 5| Step: 8
Training loss: 2.6013665199279785
Validation loss: 2.3094320117786364

Epoch: 5| Step: 9
Training loss: 3.0901832580566406
Validation loss: 2.3154769225787093

Epoch: 5| Step: 10
Training loss: 1.9986821413040161
Validation loss: 2.3167698960150442

Epoch: 93| Step: 0
Training loss: 2.5047054290771484
Validation loss: 2.3079157695975354

Epoch: 5| Step: 1
Training loss: 2.772543430328369
Validation loss: 2.3153943477138395

Epoch: 5| Step: 2
Training loss: 2.6897449493408203
Validation loss: 2.3245575876646143

Epoch: 5| Step: 3
Training loss: 2.2263238430023193
Validation loss: 2.320003673594485

Epoch: 5| Step: 4
Training loss: 2.755795955657959
Validation loss: 2.322343146929177

Epoch: 5| Step: 5
Training loss: 2.4029388427734375
Validation loss: 2.3112596491331696

Epoch: 5| Step: 6
Training loss: 2.1084206104278564
Validation loss: 2.3089884199121946

Epoch: 5| Step: 7
Training loss: 2.812404155731201
Validation loss: 2.30432875182039

Epoch: 5| Step: 8
Training loss: 2.9149329662323
Validation loss: 2.2942283384261595

Epoch: 5| Step: 9
Training loss: 2.604861259460449
Validation loss: 2.2834675491497083

Epoch: 5| Step: 10
Training loss: 2.2941648960113525
Validation loss: 2.2749176102299846

Epoch: 94| Step: 0
Training loss: 2.1612696647644043
Validation loss: 2.2687604734974522

Epoch: 5| Step: 1
Training loss: 2.946479082107544
Validation loss: 2.27041890287912

Epoch: 5| Step: 2
Training loss: 2.3603572845458984
Validation loss: 2.275637795848231

Epoch: 5| Step: 3
Training loss: 2.7860496044158936
Validation loss: 2.274946649869283

Epoch: 5| Step: 4
Training loss: 2.2100613117218018
Validation loss: 2.283106565475464

Epoch: 5| Step: 5
Training loss: 2.8255412578582764
Validation loss: 2.281384998752225

Epoch: 5| Step: 6
Training loss: 2.2296431064605713
Validation loss: 2.293440188131025

Epoch: 5| Step: 7
Training loss: 2.4335968494415283
Validation loss: 2.2980186221420125

Epoch: 5| Step: 8
Training loss: 2.798931837081909
Validation loss: 2.3102570374806723

Epoch: 5| Step: 9
Training loss: 2.8777990341186523
Validation loss: 2.3180803868078415

Epoch: 5| Step: 10
Training loss: 2.343047618865967
Validation loss: 2.341068867714174

Epoch: 95| Step: 0
Training loss: 2.928734302520752
Validation loss: 2.3508922002648793

Epoch: 5| Step: 1
Training loss: 2.5318636894226074
Validation loss: 2.3477580521696355

Epoch: 5| Step: 2
Training loss: 2.8282864093780518
Validation loss: 2.3486621790034796

Epoch: 5| Step: 3
Training loss: 1.8893159627914429
Validation loss: 2.3562327405457855

Epoch: 5| Step: 4
Training loss: 2.8945837020874023
Validation loss: 2.3510545992082164

Epoch: 5| Step: 5
Training loss: 2.3268802165985107
Validation loss: 2.3409949553910123

Epoch: 5| Step: 6
Training loss: 2.5425429344177246
Validation loss: 2.341033581764467

Epoch: 5| Step: 7
Training loss: 2.620277166366577
Validation loss: 2.3214962777271064

Epoch: 5| Step: 8
Training loss: 2.4376745223999023
Validation loss: 2.3023547203310075

Epoch: 5| Step: 9
Training loss: 2.4285407066345215
Validation loss: 2.293044838854062

Epoch: 5| Step: 10
Training loss: 2.6660659313201904
Validation loss: 2.2946844664953088

Epoch: 96| Step: 0
Training loss: 2.3857579231262207
Validation loss: 2.289952980574741

Epoch: 5| Step: 1
Training loss: 1.8715234994888306
Validation loss: 2.2947326603756157

Epoch: 5| Step: 2
Training loss: 2.35040020942688
Validation loss: 2.2984234645802486

Epoch: 5| Step: 3
Training loss: 2.3593039512634277
Validation loss: 2.305902260606007

Epoch: 5| Step: 4
Training loss: 3.2855277061462402
Validation loss: 2.320535188080162

Epoch: 5| Step: 5
Training loss: 2.9917023181915283
Validation loss: 2.322984592888945

Epoch: 5| Step: 6
Training loss: 2.3267264366149902
Validation loss: 2.3111036234004523

Epoch: 5| Step: 7
Training loss: 2.575115203857422
Validation loss: 2.3102426580203477

Epoch: 5| Step: 8
Training loss: 2.67812442779541
Validation loss: 2.3134808078888924

Epoch: 5| Step: 9
Training loss: 2.7472329139709473
Validation loss: 2.3028043803348335

Epoch: 5| Step: 10
Training loss: 2.507578134536743
Validation loss: 2.3031829685293217

Epoch: 97| Step: 0
Training loss: 3.0107269287109375
Validation loss: 2.302473538665361

Epoch: 5| Step: 1
Training loss: 2.431241273880005
Validation loss: 2.314676279662758

Epoch: 5| Step: 2
Training loss: 2.8550381660461426
Validation loss: 2.3200293843464186

Epoch: 5| Step: 3
Training loss: 3.053062915802002
Validation loss: 2.343479371839954

Epoch: 5| Step: 4
Training loss: 1.4964298009872437
Validation loss: 2.3488163589149393

Epoch: 5| Step: 5
Training loss: 3.0304951667785645
Validation loss: 2.365674002196199

Epoch: 5| Step: 6
Training loss: 2.323204755783081
Validation loss: 2.351868465382566

Epoch: 5| Step: 7
Training loss: 2.7943196296691895
Validation loss: 2.330932955588064

Epoch: 5| Step: 8
Training loss: 2.8261730670928955
Validation loss: 2.3105857167192685

Epoch: 5| Step: 9
Training loss: 2.106961727142334
Validation loss: 2.30852835793649

Epoch: 5| Step: 10
Training loss: 1.8685812950134277
Validation loss: 2.302383634351915

Epoch: 98| Step: 0
Training loss: 2.302201747894287
Validation loss: 2.3079251294494956

Epoch: 5| Step: 1
Training loss: 2.2537853717803955
Validation loss: 2.317021559643489

Epoch: 5| Step: 2
Training loss: 2.0835366249084473
Validation loss: 2.3326792127342633

Epoch: 5| Step: 3
Training loss: 3.0476138591766357
Validation loss: 2.3567184479005876

Epoch: 5| Step: 4
Training loss: 2.683018445968628
Validation loss: 2.369755716734035

Epoch: 5| Step: 5
Training loss: 2.5822460651397705
Validation loss: 2.3591184616088867

Epoch: 5| Step: 6
Training loss: 2.3971142768859863
Validation loss: 2.347639815781706

Epoch: 5| Step: 7
Training loss: 2.3664135932922363
Validation loss: 2.3132860763098604

Epoch: 5| Step: 8
Training loss: 2.588352918624878
Validation loss: 2.3037099876711444

Epoch: 5| Step: 9
Training loss: 2.549647569656372
Validation loss: 2.297485900181596

Epoch: 5| Step: 10
Training loss: 3.2406036853790283
Validation loss: 2.295461650817625

Epoch: 99| Step: 0
Training loss: 2.576770544052124
Validation loss: 2.3090842872537594

Epoch: 5| Step: 1
Training loss: 3.036193370819092
Validation loss: 2.308549136243841

Epoch: 5| Step: 2
Training loss: 2.252236843109131
Validation loss: 2.3072198001287316

Epoch: 5| Step: 3
Training loss: 2.6676523685455322
Validation loss: 2.3067440960996892

Epoch: 5| Step: 4
Training loss: 2.5671448707580566
Validation loss: 2.3092665108301307

Epoch: 5| Step: 5
Training loss: 2.1964640617370605
Validation loss: 2.304362307312668

Epoch: 5| Step: 6
Training loss: 2.598672389984131
Validation loss: 2.3101667640029744

Epoch: 5| Step: 7
Training loss: 2.7133991718292236
Validation loss: 2.3145210589132

Epoch: 5| Step: 8
Training loss: 2.550262928009033
Validation loss: 2.2958211027165896

Epoch: 5| Step: 9
Training loss: 2.274028778076172
Validation loss: 2.288663396271326

Epoch: 5| Step: 10
Training loss: 2.458434581756592
Validation loss: 2.2787515412094774

Epoch: 100| Step: 0
Training loss: 2.196526288986206
Validation loss: 2.2881591140582995

Epoch: 5| Step: 1
Training loss: 2.4402384757995605
Validation loss: 2.294263655139554

Epoch: 5| Step: 2
Training loss: 2.4663116931915283
Validation loss: 2.3220304212262555

Epoch: 5| Step: 3
Training loss: 2.950352430343628
Validation loss: 2.3376085681300007

Epoch: 5| Step: 4
Training loss: 2.91835618019104
Validation loss: 2.352435824691608

Epoch: 5| Step: 5
Training loss: 2.721785306930542
Validation loss: 2.334263111955376

Epoch: 5| Step: 6
Training loss: 2.6094741821289062
Validation loss: 2.318296492740672

Epoch: 5| Step: 7
Training loss: 2.384070873260498
Validation loss: 2.298677111184725

Epoch: 5| Step: 8
Training loss: 2.610985279083252
Validation loss: 2.273157004387148

Epoch: 5| Step: 9
Training loss: 2.688549518585205
Validation loss: 2.2681172842620523

Epoch: 5| Step: 10
Training loss: 1.8356529474258423
Validation loss: 2.2590786462189048

Epoch: 101| Step: 0
Training loss: 2.775578260421753
Validation loss: 2.2751855029854724

Epoch: 5| Step: 1
Training loss: 2.6620559692382812
Validation loss: 2.270014229641166

Epoch: 5| Step: 2
Training loss: 2.5969510078430176
Validation loss: 2.2694923108623875

Epoch: 5| Step: 3
Training loss: 2.454397678375244
Validation loss: 2.2767118997471307

Epoch: 5| Step: 4
Training loss: 2.0426554679870605
Validation loss: 2.276261865451772

Epoch: 5| Step: 5
Training loss: 2.20314359664917
Validation loss: 2.284558629476896

Epoch: 5| Step: 6
Training loss: 2.954937696456909
Validation loss: 2.2881963073566394

Epoch: 5| Step: 7
Training loss: 2.3731400966644287
Validation loss: 2.2835692692828435

Epoch: 5| Step: 8
Training loss: 2.8826889991760254
Validation loss: 2.2913809386632775

Epoch: 5| Step: 9
Training loss: 2.1313962936401367
Validation loss: 2.2953266379653767

Epoch: 5| Step: 10
Training loss: 2.8043394088745117
Validation loss: 2.2964170850733274

Epoch: 102| Step: 0
Training loss: 2.378201961517334
Validation loss: 2.281169605511491

Epoch: 5| Step: 1
Training loss: 2.9301538467407227
Validation loss: 2.2740545311281757

Epoch: 5| Step: 2
Training loss: 2.3932127952575684
Validation loss: 2.2820210379938923

Epoch: 5| Step: 3
Training loss: 1.888010025024414
Validation loss: 2.277064620807607

Epoch: 5| Step: 4
Training loss: 2.5238747596740723
Validation loss: 2.278563863487654

Epoch: 5| Step: 5
Training loss: 2.670867919921875
Validation loss: 2.277314632169662

Epoch: 5| Step: 6
Training loss: 2.452767848968506
Validation loss: 2.2787496735972743

Epoch: 5| Step: 7
Training loss: 2.3454601764678955
Validation loss: 2.2748262856596257

Epoch: 5| Step: 8
Training loss: 2.5432236194610596
Validation loss: 2.2699301909374934

Epoch: 5| Step: 9
Training loss: 2.5631535053253174
Validation loss: 2.2595761027387393

Epoch: 5| Step: 10
Training loss: 3.113475799560547
Validation loss: 2.25234019243589

Epoch: 103| Step: 0
Training loss: 1.9005496501922607
Validation loss: 2.249840792789254

Epoch: 5| Step: 1
Training loss: 1.8007453680038452
Validation loss: 2.243967174201883

Epoch: 5| Step: 2
Training loss: 2.766104221343994
Validation loss: 2.2532419440566853

Epoch: 5| Step: 3
Training loss: 1.984155297279358
Validation loss: 2.259732897563647

Epoch: 5| Step: 4
Training loss: 3.097529888153076
Validation loss: 2.2590752186313754

Epoch: 5| Step: 5
Training loss: 2.9479713439941406
Validation loss: 2.250107883125223

Epoch: 5| Step: 6
Training loss: 2.966481924057007
Validation loss: 2.265523438812584

Epoch: 5| Step: 7
Training loss: 2.140061378479004
Validation loss: 2.2690889578993603

Epoch: 5| Step: 8
Training loss: 2.5146565437316895
Validation loss: 2.275750498617849

Epoch: 5| Step: 9
Training loss: 2.718137502670288
Validation loss: 2.2908007175691667

Epoch: 5| Step: 10
Training loss: 2.907921552658081
Validation loss: 2.2857456745639926

Epoch: 104| Step: 0
Training loss: 1.9976752996444702
Validation loss: 2.2956564298240085

Epoch: 5| Step: 1
Training loss: 2.2367663383483887
Validation loss: 2.2977255928900933

Epoch: 5| Step: 2
Training loss: 2.9112071990966797
Validation loss: 2.291769940366027

Epoch: 5| Step: 3
Training loss: 2.824681282043457
Validation loss: 2.2951188356645646

Epoch: 5| Step: 4
Training loss: 2.486377477645874
Validation loss: 2.293533132922265

Epoch: 5| Step: 5
Training loss: 2.2747721672058105
Validation loss: 2.291591316141108

Epoch: 5| Step: 6
Training loss: 2.7023167610168457
Validation loss: 2.279482841491699

Epoch: 5| Step: 7
Training loss: 3.2060959339141846
Validation loss: 2.2812577729584067

Epoch: 5| Step: 8
Training loss: 2.338838577270508
Validation loss: 2.2847083460900093

Epoch: 5| Step: 9
Training loss: 2.2765936851501465
Validation loss: 2.276221065111058

Epoch: 5| Step: 10
Training loss: 2.348879098892212
Validation loss: 2.2752602382372786

Epoch: 105| Step: 0
Training loss: 1.956639051437378
Validation loss: 2.262318003562189

Epoch: 5| Step: 1
Training loss: 3.0692648887634277
Validation loss: 2.2657673589644896

Epoch: 5| Step: 2
Training loss: 2.622335433959961
Validation loss: 2.2632735416453373

Epoch: 5| Step: 3
Training loss: 3.0904860496520996
Validation loss: 2.2674383553125526

Epoch: 5| Step: 4
Training loss: 2.7581748962402344
Validation loss: 2.2852928741003877

Epoch: 5| Step: 5
Training loss: 2.0663795471191406
Validation loss: 2.2920621159256145

Epoch: 5| Step: 6
Training loss: 2.5466325283050537
Validation loss: 2.289833020138484

Epoch: 5| Step: 7
Training loss: 2.5329413414001465
Validation loss: 2.2904591227090485

Epoch: 5| Step: 8
Training loss: 2.232356309890747
Validation loss: 2.2801296736604426

Epoch: 5| Step: 9
Training loss: 2.3277969360351562
Validation loss: 2.273874003400085

Epoch: 5| Step: 10
Training loss: 2.4218170642852783
Validation loss: 2.273154777865256

Epoch: 106| Step: 0
Training loss: 2.3264212608337402
Validation loss: 2.2688613322473343

Epoch: 5| Step: 1
Training loss: 2.217288017272949
Validation loss: 2.271065911939067

Epoch: 5| Step: 2
Training loss: 2.6031556129455566
Validation loss: 2.2828844413962415

Epoch: 5| Step: 3
Training loss: 2.522374391555786
Validation loss: 2.278883928893715

Epoch: 5| Step: 4
Training loss: 3.0212697982788086
Validation loss: 2.281040158323062

Epoch: 5| Step: 5
Training loss: 2.763899564743042
Validation loss: 2.2768223157493015

Epoch: 5| Step: 6
Training loss: 2.967339277267456
Validation loss: 2.2895603308113675

Epoch: 5| Step: 7
Training loss: 2.098266363143921
Validation loss: 2.28565239778129

Epoch: 5| Step: 8
Training loss: 2.055471897125244
Validation loss: 2.290115894809846

Epoch: 5| Step: 9
Training loss: 2.5826828479766846
Validation loss: 2.292344916251398

Epoch: 5| Step: 10
Training loss: 2.4840142726898193
Validation loss: 2.2925537683630504

Epoch: 107| Step: 0
Training loss: 2.396533966064453
Validation loss: 2.2953424351189726

Epoch: 5| Step: 1
Training loss: 2.65330171585083
Validation loss: 2.285811931856217

Epoch: 5| Step: 2
Training loss: 2.3559415340423584
Validation loss: 2.296766855383432

Epoch: 5| Step: 3
Training loss: 3.230189561843872
Validation loss: 2.300776143227854

Epoch: 5| Step: 4
Training loss: 2.1662540435791016
Validation loss: 2.308253494642114

Epoch: 5| Step: 5
Training loss: 2.8018264770507812
Validation loss: 2.3098356903240247

Epoch: 5| Step: 6
Training loss: 2.2122631072998047
Validation loss: 2.30625343579118

Epoch: 5| Step: 7
Training loss: 2.6278538703918457
Validation loss: 2.303957470001713

Epoch: 5| Step: 8
Training loss: 2.7803502082824707
Validation loss: 2.303670885742352

Epoch: 5| Step: 9
Training loss: 1.7533960342407227
Validation loss: 2.289312429325555

Epoch: 5| Step: 10
Training loss: 2.43135142326355
Validation loss: 2.2987698739574802

Epoch: 108| Step: 0
Training loss: 1.886911153793335
Validation loss: 2.290379806231427

Epoch: 5| Step: 1
Training loss: 2.7883057594299316
Validation loss: 2.2923050054939846

Epoch: 5| Step: 2
Training loss: 2.589622974395752
Validation loss: 2.2751643221865416

Epoch: 5| Step: 3
Training loss: 2.5748190879821777
Validation loss: 2.280216593896189

Epoch: 5| Step: 4
Training loss: 2.765789270401001
Validation loss: 2.2815882262363227

Epoch: 5| Step: 5
Training loss: 3.192841053009033
Validation loss: 2.2789254637174707

Epoch: 5| Step: 6
Training loss: 2.1244685649871826
Validation loss: 2.268606396131618

Epoch: 5| Step: 7
Training loss: 2.2731027603149414
Validation loss: 2.2596683476560857

Epoch: 5| Step: 8
Training loss: 2.4097092151641846
Validation loss: 2.257486343383789

Epoch: 5| Step: 9
Training loss: 2.2932002544403076
Validation loss: 2.263004082505421

Epoch: 5| Step: 10
Training loss: 2.745755195617676
Validation loss: 2.2575511958009455

Epoch: 109| Step: 0
Training loss: 2.8997914791107178
Validation loss: 2.262137274588308

Epoch: 5| Step: 1
Training loss: 2.184022903442383
Validation loss: 2.259093810153264

Epoch: 5| Step: 2
Training loss: 2.258702278137207
Validation loss: 2.2592402760700514

Epoch: 5| Step: 3
Training loss: 2.675365924835205
Validation loss: 2.2603178485747306

Epoch: 5| Step: 4
Training loss: 2.5425593852996826
Validation loss: 2.265299286893619

Epoch: 5| Step: 5
Training loss: 2.878082275390625
Validation loss: 2.2590208976499495

Epoch: 5| Step: 6
Training loss: 2.531557559967041
Validation loss: 2.276429881331741

Epoch: 5| Step: 7
Training loss: 2.5699462890625
Validation loss: 2.284801524172547

Epoch: 5| Step: 8
Training loss: 2.626941680908203
Validation loss: 2.283331307031775

Epoch: 5| Step: 9
Training loss: 2.2043392658233643
Validation loss: 2.2740802713619765

Epoch: 5| Step: 10
Training loss: 2.0128536224365234
Validation loss: 2.27108794899397

Epoch: 110| Step: 0
Training loss: 2.626652240753174
Validation loss: 2.2680940205051052

Epoch: 5| Step: 1
Training loss: 2.6554596424102783
Validation loss: 2.2780709702481508

Epoch: 5| Step: 2
Training loss: 3.276144504547119
Validation loss: 2.252523596568774

Epoch: 5| Step: 3
Training loss: 1.8198436498641968
Validation loss: 2.247382915148171

Epoch: 5| Step: 4
Training loss: 2.464953899383545
Validation loss: 2.2401429043021253

Epoch: 5| Step: 5
Training loss: 2.450638771057129
Validation loss: 2.24343123743611

Epoch: 5| Step: 6
Training loss: 2.123323917388916
Validation loss: 2.244742283257105

Epoch: 5| Step: 7
Training loss: 2.15283465385437
Validation loss: 2.2573149332436184

Epoch: 5| Step: 8
Training loss: 3.2589099407196045
Validation loss: 2.273121853028574

Epoch: 5| Step: 9
Training loss: 2.2071619033813477
Validation loss: 2.272981741095102

Epoch: 5| Step: 10
Training loss: 2.649125814437866
Validation loss: 2.261981600074358

Epoch: 111| Step: 0
Training loss: 2.2072360515594482
Validation loss: 2.26169938682228

Epoch: 5| Step: 1
Training loss: 2.5294439792633057
Validation loss: 2.255613560317665

Epoch: 5| Step: 2
Training loss: 2.8113467693328857
Validation loss: 2.2653620781437045

Epoch: 5| Step: 3
Training loss: 2.4746921062469482
Validation loss: 2.272793085344376

Epoch: 5| Step: 4
Training loss: 2.7034780979156494
Validation loss: 2.2773647051985546

Epoch: 5| Step: 5
Training loss: 2.545325517654419
Validation loss: 2.2620795362739154

Epoch: 5| Step: 6
Training loss: 2.4844589233398438
Validation loss: 2.2658625187412387

Epoch: 5| Step: 7
Training loss: 2.4686646461486816
Validation loss: 2.2587524152571157

Epoch: 5| Step: 8
Training loss: 2.986100196838379
Validation loss: 2.265165367434102

Epoch: 5| Step: 9
Training loss: 2.007744550704956
Validation loss: 2.256097642324304

Epoch: 5| Step: 10
Training loss: 2.275477886199951
Validation loss: 2.2624460830483386

Epoch: 112| Step: 0
Training loss: 2.3380796909332275
Validation loss: 2.2761326746274064

Epoch: 5| Step: 1
Training loss: 2.580488681793213
Validation loss: 2.2965676387151084

Epoch: 5| Step: 2
Training loss: 2.8970720767974854
Validation loss: 2.2930263626960015

Epoch: 5| Step: 3
Training loss: 2.1795897483825684
Validation loss: 2.299132457343481

Epoch: 5| Step: 4
Training loss: 1.9566618204116821
Validation loss: 2.3115098758410384

Epoch: 5| Step: 5
Training loss: 2.597139835357666
Validation loss: 2.3174109330741306

Epoch: 5| Step: 6
Training loss: 2.407776355743408
Validation loss: 2.297455285185127

Epoch: 5| Step: 7
Training loss: 2.441310405731201
Validation loss: 2.2927928714342016

Epoch: 5| Step: 8
Training loss: 2.7547194957733154
Validation loss: 2.3053729277785107

Epoch: 5| Step: 9
Training loss: 2.459874391555786
Validation loss: 2.3099511413164038

Epoch: 5| Step: 10
Training loss: 2.8233001232147217
Validation loss: 2.311971346537272

Epoch: 113| Step: 0
Training loss: 3.0722384452819824
Validation loss: 2.3209278275889735

Epoch: 5| Step: 1
Training loss: 2.3693811893463135
Validation loss: 2.3169871145679104

Epoch: 5| Step: 2
Training loss: 2.5998311042785645
Validation loss: 2.3015880789808048

Epoch: 5| Step: 3
Training loss: 2.3581221103668213
Validation loss: 2.2858828498471166

Epoch: 5| Step: 4
Training loss: 1.8936767578125
Validation loss: 2.2776426115343646

Epoch: 5| Step: 5
Training loss: 2.2455899715423584
Validation loss: 2.277311522473571

Epoch: 5| Step: 6
Training loss: 3.0357184410095215
Validation loss: 2.265655679087485

Epoch: 5| Step: 7
Training loss: 2.213871479034424
Validation loss: 2.2802607987516668

Epoch: 5| Step: 8
Training loss: 2.4574368000030518
Validation loss: 2.2636443799541843

Epoch: 5| Step: 9
Training loss: 2.2782177925109863
Validation loss: 2.280093954455468

Epoch: 5| Step: 10
Training loss: 2.8608250617980957
Validation loss: 2.268198913143527

Epoch: 114| Step: 0
Training loss: 3.2429890632629395
Validation loss: 2.277810714578116

Epoch: 5| Step: 1
Training loss: 1.8146533966064453
Validation loss: 2.270087247253746

Epoch: 5| Step: 2
Training loss: 1.6437448263168335
Validation loss: 2.2573907516335927

Epoch: 5| Step: 3
Training loss: 2.5180585384368896
Validation loss: 2.267111659049988

Epoch: 5| Step: 4
Training loss: 2.80372953414917
Validation loss: 2.2645520625575895

Epoch: 5| Step: 5
Training loss: 2.8376593589782715
Validation loss: 2.2727620088925926

Epoch: 5| Step: 6
Training loss: 2.8295609951019287
Validation loss: 2.295334698051535

Epoch: 5| Step: 7
Training loss: 2.1991686820983887
Validation loss: 2.28327666559527

Epoch: 5| Step: 8
Training loss: 2.6126277446746826
Validation loss: 2.280786145117975

Epoch: 5| Step: 9
Training loss: 2.645975351333618
Validation loss: 2.29147312718053

Epoch: 5| Step: 10
Training loss: 2.180856704711914
Validation loss: 2.2628128836231847

Epoch: 115| Step: 0
Training loss: 2.3378965854644775
Validation loss: 2.2457215068160847

Epoch: 5| Step: 1
Training loss: 2.92075777053833
Validation loss: 2.2484384172706195

Epoch: 5| Step: 2
Training loss: 1.4915835857391357
Validation loss: 2.2457753894149617

Epoch: 5| Step: 3
Training loss: 2.5692338943481445
Validation loss: 2.2395640214284263

Epoch: 5| Step: 4
Training loss: 2.6055731773376465
Validation loss: 2.2604071940145185

Epoch: 5| Step: 5
Training loss: 2.6551413536071777
Validation loss: 2.2417510337727045

Epoch: 5| Step: 6
Training loss: 2.586246967315674
Validation loss: 2.2377101682847544

Epoch: 5| Step: 7
Training loss: 2.9191603660583496
Validation loss: 2.243603002640509

Epoch: 5| Step: 8
Training loss: 2.7223517894744873
Validation loss: 2.237578268974058

Epoch: 5| Step: 9
Training loss: 2.5403342247009277
Validation loss: 2.2539251427496634

Epoch: 5| Step: 10
Training loss: 1.9773638248443604
Validation loss: 2.2605272108508694

Epoch: 116| Step: 0
Training loss: 2.6218209266662598
Validation loss: 2.2708235914989183

Epoch: 5| Step: 1
Training loss: 2.260380268096924
Validation loss: 2.2672429289869083

Epoch: 5| Step: 2
Training loss: 2.034963369369507
Validation loss: 2.271861360919091

Epoch: 5| Step: 3
Training loss: 2.5310254096984863
Validation loss: 2.2871353882615284

Epoch: 5| Step: 4
Training loss: 2.0951695442199707
Validation loss: 2.2969980034776913

Epoch: 5| Step: 5
Training loss: 2.2451586723327637
Validation loss: 2.3049417157326975

Epoch: 5| Step: 6
Training loss: 3.0723109245300293
Validation loss: 2.305144376652215

Epoch: 5| Step: 7
Training loss: 2.880275011062622
Validation loss: 2.3096797261186826

Epoch: 5| Step: 8
Training loss: 2.7153682708740234
Validation loss: 2.2800468578133533

Epoch: 5| Step: 9
Training loss: 2.502042770385742
Validation loss: 2.2424799549964165

Epoch: 5| Step: 10
Training loss: 2.386625289916992
Validation loss: 2.23139468572473

Epoch: 117| Step: 0
Training loss: 2.434138774871826
Validation loss: 2.2250573532555693

Epoch: 5| Step: 1
Training loss: 2.2729380130767822
Validation loss: 2.221696587019069

Epoch: 5| Step: 2
Training loss: 2.5343270301818848
Validation loss: 2.2023681953389156

Epoch: 5| Step: 3
Training loss: 2.6750025749206543
Validation loss: 2.2152264861650366

Epoch: 5| Step: 4
Training loss: 2.7730801105499268
Validation loss: 2.2110251406187653

Epoch: 5| Step: 5
Training loss: 2.7618556022644043
Validation loss: 2.218924614690965

Epoch: 5| Step: 6
Training loss: 2.1843361854553223
Validation loss: 2.2090140183766684

Epoch: 5| Step: 7
Training loss: 2.734591007232666
Validation loss: 2.20588324146886

Epoch: 5| Step: 8
Training loss: 2.4770853519439697
Validation loss: 2.2082834897502774

Epoch: 5| Step: 9
Training loss: 2.3420650959014893
Validation loss: 2.208733194617815

Epoch: 5| Step: 10
Training loss: 2.3270339965820312
Validation loss: 2.227346674088509

Epoch: 118| Step: 0
Training loss: 3.0834743976593018
Validation loss: 2.252356211344401

Epoch: 5| Step: 1
Training loss: 2.9148125648498535
Validation loss: 2.2807651271102247

Epoch: 5| Step: 2
Training loss: 2.6560592651367188
Validation loss: 2.298962334150909

Epoch: 5| Step: 3
Training loss: 2.156054735183716
Validation loss: 2.30718659329158

Epoch: 5| Step: 4
Training loss: 2.031440258026123
Validation loss: 2.312517527611025

Epoch: 5| Step: 5
Training loss: 1.8754371404647827
Validation loss: 2.326665593731788

Epoch: 5| Step: 6
Training loss: 2.8226451873779297
Validation loss: 2.3222625409403155

Epoch: 5| Step: 7
Training loss: 2.205246686935425
Validation loss: 2.3013068194030435

Epoch: 5| Step: 8
Training loss: 2.370776414871216
Validation loss: 2.274713311144101

Epoch: 5| Step: 9
Training loss: 2.677624464035034
Validation loss: 2.2500111364549205

Epoch: 5| Step: 10
Training loss: 2.716797351837158
Validation loss: 2.2382744627614177

Epoch: 119| Step: 0
Training loss: 2.89843487739563
Validation loss: 2.226325155586325

Epoch: 5| Step: 1
Training loss: 1.1525030136108398
Validation loss: 2.216660850791521

Epoch: 5| Step: 2
Training loss: 3.0856564044952393
Validation loss: 2.2249288405141523

Epoch: 5| Step: 3
Training loss: 2.397042751312256
Validation loss: 2.2174716611062326

Epoch: 5| Step: 4
Training loss: 2.6454992294311523
Validation loss: 2.222771918901833

Epoch: 5| Step: 5
Training loss: 2.0561468601226807
Validation loss: 2.220800543344149

Epoch: 5| Step: 6
Training loss: 3.059786319732666
Validation loss: 2.227079237661054

Epoch: 5| Step: 7
Training loss: 2.5434720516204834
Validation loss: 2.2391377648999615

Epoch: 5| Step: 8
Training loss: 2.4158613681793213
Validation loss: 2.2489125036424205

Epoch: 5| Step: 9
Training loss: 2.569084644317627
Validation loss: 2.2555179237037577

Epoch: 5| Step: 10
Training loss: 2.5197317600250244
Validation loss: 2.268347668391402

Epoch: 120| Step: 0
Training loss: 2.6285462379455566
Validation loss: 2.250727617612449

Epoch: 5| Step: 1
Training loss: 2.423870325088501
Validation loss: 2.2488842318134923

Epoch: 5| Step: 2
Training loss: 2.050990581512451
Validation loss: 2.2555963505980787

Epoch: 5| Step: 3
Training loss: 2.886110305786133
Validation loss: 2.2682643577616703

Epoch: 5| Step: 4
Training loss: 2.6866631507873535
Validation loss: 2.302706046770978

Epoch: 5| Step: 5
Training loss: 2.5690064430236816
Validation loss: 2.3061691432870846

Epoch: 5| Step: 6
Training loss: 2.782068967819214
Validation loss: 2.3171773110666583

Epoch: 5| Step: 7
Training loss: 2.2470321655273438
Validation loss: 2.3035062513043805

Epoch: 5| Step: 8
Training loss: 2.4110653400421143
Validation loss: 2.296973961655812

Epoch: 5| Step: 9
Training loss: 2.9859325885772705
Validation loss: 2.2592893338972524

Epoch: 5| Step: 10
Training loss: 1.5843095779418945
Validation loss: 2.24660062789917

Epoch: 121| Step: 0
Training loss: 2.931425094604492
Validation loss: 2.2311440719071256

Epoch: 5| Step: 1
Training loss: 2.8295998573303223
Validation loss: 2.2330993260106733

Epoch: 5| Step: 2
Training loss: 1.9439334869384766
Validation loss: 2.2217337008445495

Epoch: 5| Step: 3
Training loss: 2.6325931549072266
Validation loss: 2.219764341590225

Epoch: 5| Step: 4
Training loss: 2.156637191772461
Validation loss: 2.2457805410508187

Epoch: 5| Step: 5
Training loss: 2.539416551589966
Validation loss: 2.321559108713622

Epoch: 5| Step: 6
Training loss: 2.369492292404175
Validation loss: 2.3648736297443347

Epoch: 5| Step: 7
Training loss: 2.998436212539673
Validation loss: 2.3308824877585135

Epoch: 5| Step: 8
Training loss: 2.2368578910827637
Validation loss: 2.2763164543336436

Epoch: 5| Step: 9
Training loss: 2.629542589187622
Validation loss: 2.2161945527599705

Epoch: 5| Step: 10
Training loss: 2.635308265686035
Validation loss: 2.209058766723961

Epoch: 122| Step: 0
Training loss: 2.4496243000030518
Validation loss: 2.24559356833017

Epoch: 5| Step: 1
Training loss: 2.609186887741089
Validation loss: 2.301289648138067

Epoch: 5| Step: 2
Training loss: 2.7043213844299316
Validation loss: 2.3551669530971076

Epoch: 5| Step: 3
Training loss: 2.5679569244384766
Validation loss: 2.3728805203591623

Epoch: 5| Step: 4
Training loss: 2.725156307220459
Validation loss: 2.36613549981066

Epoch: 5| Step: 5
Training loss: 2.2624504566192627
Validation loss: 2.338108629308721

Epoch: 5| Step: 6
Training loss: 1.9874582290649414
Validation loss: 2.2760915679316365

Epoch: 5| Step: 7
Training loss: 2.7469639778137207
Validation loss: 2.275096829219531

Epoch: 5| Step: 8
Training loss: 2.0103416442871094
Validation loss: 2.259050464117399

Epoch: 5| Step: 9
Training loss: 3.215132236480713
Validation loss: 2.255166874136976

Epoch: 5| Step: 10
Training loss: 2.304121255874634
Validation loss: 2.243062775622132

Epoch: 123| Step: 0
Training loss: 2.859571933746338
Validation loss: 2.2498363935819237

Epoch: 5| Step: 1
Training loss: 2.106715440750122
Validation loss: 2.2555842758506857

Epoch: 5| Step: 2
Training loss: 2.6359035968780518
Validation loss: 2.2961668327290523

Epoch: 5| Step: 3
Training loss: 1.8154408931732178
Validation loss: 2.310298063421762

Epoch: 5| Step: 4
Training loss: 2.729526996612549
Validation loss: 2.3053637268722698

Epoch: 5| Step: 5
Training loss: 2.6138527393341064
Validation loss: 2.303487659782492

Epoch: 5| Step: 6
Training loss: 2.470534086227417
Validation loss: 2.301695264795775

Epoch: 5| Step: 7
Training loss: 2.5021398067474365
Validation loss: 2.259503113326206

Epoch: 5| Step: 8
Training loss: 2.217109203338623
Validation loss: 2.2540423972632295

Epoch: 5| Step: 9
Training loss: 2.5132839679718018
Validation loss: 2.259859851611558

Epoch: 5| Step: 10
Training loss: 2.9527652263641357
Validation loss: 2.2477941795061995

Epoch: 124| Step: 0
Training loss: 2.7000253200531006
Validation loss: 2.2477261994474675

Epoch: 5| Step: 1
Training loss: 3.336392641067505
Validation loss: 2.235921388031334

Epoch: 5| Step: 2
Training loss: 2.1286227703094482
Validation loss: 2.2477927079764743

Epoch: 5| Step: 3
Training loss: 2.002382278442383
Validation loss: 2.230187180221722

Epoch: 5| Step: 4
Training loss: 2.04384183883667
Validation loss: 2.2250949516091296

Epoch: 5| Step: 5
Training loss: 2.3597559928894043
Validation loss: 2.2128419081370034

Epoch: 5| Step: 6
Training loss: 2.0489275455474854
Validation loss: 2.2096531134779736

Epoch: 5| Step: 7
Training loss: 2.6475982666015625
Validation loss: 2.2039985528556247

Epoch: 5| Step: 8
Training loss: 2.574824571609497
Validation loss: 2.2145905366507908

Epoch: 5| Step: 9
Training loss: 2.819228172302246
Validation loss: 2.217748652222336

Epoch: 5| Step: 10
Training loss: 2.448084592819214
Validation loss: 2.22078634590231

Epoch: 125| Step: 0
Training loss: 1.963585615158081
Validation loss: 2.2284913716777677

Epoch: 5| Step: 1
Training loss: 2.223773956298828
Validation loss: 2.267132002820251

Epoch: 5| Step: 2
Training loss: 1.7376525402069092
Validation loss: 2.2948520824473393

Epoch: 5| Step: 3
Training loss: 3.0098235607147217
Validation loss: 2.320783627930508

Epoch: 5| Step: 4
Training loss: 2.9863734245300293
Validation loss: 2.306743578244281

Epoch: 5| Step: 5
Training loss: 2.7470202445983887
Validation loss: 2.2761367674796813

Epoch: 5| Step: 6
Training loss: 2.4734809398651123
Validation loss: 2.2483652227668354

Epoch: 5| Step: 7
Training loss: 2.4256463050842285
Validation loss: 2.242083039335025

Epoch: 5| Step: 8
Training loss: 2.4932143688201904
Validation loss: 2.236135398187945

Epoch: 5| Step: 9
Training loss: 2.352482318878174
Validation loss: 2.221823324439346

Epoch: 5| Step: 10
Training loss: 2.9137606620788574
Validation loss: 2.2291539061454033

Epoch: 126| Step: 0
Training loss: 1.6841399669647217
Validation loss: 2.253979258639838

Epoch: 5| Step: 1
Training loss: 2.7579705715179443
Validation loss: 2.2780387222125964

Epoch: 5| Step: 2
Training loss: 2.2804272174835205
Validation loss: 2.2996684018001763

Epoch: 5| Step: 3
Training loss: 2.7848379611968994
Validation loss: 2.322403056647188

Epoch: 5| Step: 4
Training loss: 2.3002376556396484
Validation loss: 2.309631350219891

Epoch: 5| Step: 5
Training loss: 2.170985460281372
Validation loss: 2.3066911082113943

Epoch: 5| Step: 6
Training loss: 2.7548696994781494
Validation loss: 2.278423173453218

Epoch: 5| Step: 7
Training loss: 2.3424432277679443
Validation loss: 2.2584919211685017

Epoch: 5| Step: 8
Training loss: 2.580383777618408
Validation loss: 2.2462759581945275

Epoch: 5| Step: 9
Training loss: 2.5871405601501465
Validation loss: 2.233685371696308

Epoch: 5| Step: 10
Training loss: 2.884592294692993
Validation loss: 2.2323887617357316

Epoch: 127| Step: 0
Training loss: 2.5681569576263428
Validation loss: 2.2265205549937424

Epoch: 5| Step: 1
Training loss: 2.2037837505340576
Validation loss: 2.2308300054201515

Epoch: 5| Step: 2
Training loss: 2.6520586013793945
Validation loss: 2.227086426109396

Epoch: 5| Step: 3
Training loss: 2.5792996883392334
Validation loss: 2.2189327209226546

Epoch: 5| Step: 4
Training loss: 2.0113844871520996
Validation loss: 2.221426909969699

Epoch: 5| Step: 5
Training loss: 2.190638780593872
Validation loss: 2.2208834489186606

Epoch: 5| Step: 6
Training loss: 2.419879198074341
Validation loss: 2.2196549113078783

Epoch: 5| Step: 7
Training loss: 2.1854474544525146
Validation loss: 2.22823901073907

Epoch: 5| Step: 8
Training loss: 2.7491888999938965
Validation loss: 2.244434525889735

Epoch: 5| Step: 9
Training loss: 2.804396390914917
Validation loss: 2.2387864487145537

Epoch: 5| Step: 10
Training loss: 2.5840213298797607
Validation loss: 2.2370099777816446

Epoch: 128| Step: 0
Training loss: 2.3424923419952393
Validation loss: 2.2372088278493574

Epoch: 5| Step: 1
Training loss: 2.7703614234924316
Validation loss: 2.2274999233984176

Epoch: 5| Step: 2
Training loss: 1.948733925819397
Validation loss: 2.2251816590627036

Epoch: 5| Step: 3
Training loss: 2.8035573959350586
Validation loss: 2.237058795908446

Epoch: 5| Step: 4
Training loss: 2.1252541542053223
Validation loss: 2.2381781249917965

Epoch: 5| Step: 5
Training loss: 1.505446195602417
Validation loss: 2.2439721271555912

Epoch: 5| Step: 6
Training loss: 2.7240238189697266
Validation loss: 2.2471969819838002

Epoch: 5| Step: 7
Training loss: 2.6153056621551514
Validation loss: 2.2534994861131072

Epoch: 5| Step: 8
Training loss: 3.2437634468078613
Validation loss: 2.2421999054570354

Epoch: 5| Step: 9
Training loss: 2.619318723678589
Validation loss: 2.2448937431458504

Epoch: 5| Step: 10
Training loss: 2.312566041946411
Validation loss: 2.222734940949307

Epoch: 129| Step: 0
Training loss: 2.0127007961273193
Validation loss: 2.222613278255668

Epoch: 5| Step: 1
Training loss: 2.624253511428833
Validation loss: 2.215432910509007

Epoch: 5| Step: 2
Training loss: 2.389708995819092
Validation loss: 2.215143424208446

Epoch: 5| Step: 3
Training loss: 2.5792837142944336
Validation loss: 2.204202357158866

Epoch: 5| Step: 4
Training loss: 2.2127504348754883
Validation loss: 2.195581324638859

Epoch: 5| Step: 5
Training loss: 2.5509185791015625
Validation loss: 2.192008954222484

Epoch: 5| Step: 6
Training loss: 3.0805203914642334
Validation loss: 2.185338633034819

Epoch: 5| Step: 7
Training loss: 2.4785709381103516
Validation loss: 2.183027099537593

Epoch: 5| Step: 8
Training loss: 1.959012746810913
Validation loss: 2.1805108670265443

Epoch: 5| Step: 9
Training loss: 2.532349109649658
Validation loss: 2.184543965965189

Epoch: 5| Step: 10
Training loss: 2.516777276992798
Validation loss: 2.192386770761141

Epoch: 130| Step: 0
Training loss: 2.0800998210906982
Validation loss: 2.1987666647921325

Epoch: 5| Step: 1
Training loss: 1.9444230794906616
Validation loss: 2.2103787827235397

Epoch: 5| Step: 2
Training loss: 2.3574609756469727
Validation loss: 2.2093706900073635

Epoch: 5| Step: 3
Training loss: 2.372765064239502
Validation loss: 2.2204968544744674

Epoch: 5| Step: 4
Training loss: 2.000819683074951
Validation loss: 2.2265498381789013

Epoch: 5| Step: 5
Training loss: 2.9420554637908936
Validation loss: 2.2213042679653374

Epoch: 5| Step: 6
Training loss: 2.8072876930236816
Validation loss: 2.226561507871074

Epoch: 5| Step: 7
Training loss: 2.747138500213623
Validation loss: 2.2217392536901657

Epoch: 5| Step: 8
Training loss: 2.801988124847412
Validation loss: 2.236915517878789

Epoch: 5| Step: 9
Training loss: 2.3666625022888184
Validation loss: 2.2275799218044487

Epoch: 5| Step: 10
Training loss: 2.446349620819092
Validation loss: 2.240794453569638

Epoch: 131| Step: 0
Training loss: 2.555276393890381
Validation loss: 2.237851649202326

Epoch: 5| Step: 1
Training loss: 2.5175747871398926
Validation loss: 2.2296865576057026

Epoch: 5| Step: 2
Training loss: 2.5566399097442627
Validation loss: 2.229576356949345

Epoch: 5| Step: 3
Training loss: 2.046285390853882
Validation loss: 2.2248488869718326

Epoch: 5| Step: 4
Training loss: 2.1889054775238037
Validation loss: 2.2161159899926957

Epoch: 5| Step: 5
Training loss: 2.6305320262908936
Validation loss: 2.218656616826211

Epoch: 5| Step: 6
Training loss: 1.9857486486434937
Validation loss: 2.209199790031679

Epoch: 5| Step: 7
Training loss: 2.4939255714416504
Validation loss: 2.2132981746427474

Epoch: 5| Step: 8
Training loss: 2.6911914348602295
Validation loss: 2.2113318263843493

Epoch: 5| Step: 9
Training loss: 2.5623764991760254
Validation loss: 2.210275944843087

Epoch: 5| Step: 10
Training loss: 2.604710817337036
Validation loss: 2.2057372293164654

Epoch: 132| Step: 0
Training loss: 2.501674175262451
Validation loss: 2.203656429885536

Epoch: 5| Step: 1
Training loss: 3.003173828125
Validation loss: 2.194281170445104

Epoch: 5| Step: 2
Training loss: 2.0776526927948
Validation loss: 2.201230982298492

Epoch: 5| Step: 3
Training loss: 2.737349033355713
Validation loss: 2.204399129395844

Epoch: 5| Step: 4
Training loss: 2.2542479038238525
Validation loss: 2.2167858769816737

Epoch: 5| Step: 5
Training loss: 1.8932701349258423
Validation loss: 2.225020818812873

Epoch: 5| Step: 6
Training loss: 2.894960641860962
Validation loss: 2.2282807121994677

Epoch: 5| Step: 7
Training loss: 3.220508575439453
Validation loss: 2.2370893852685088

Epoch: 5| Step: 8
Training loss: 1.8067859411239624
Validation loss: 2.242869289972449

Epoch: 5| Step: 9
Training loss: 2.3642091751098633
Validation loss: 2.245737030941953

Epoch: 5| Step: 10
Training loss: 2.0284764766693115
Validation loss: 2.239756917440763

Epoch: 133| Step: 0
Training loss: 2.633106231689453
Validation loss: 2.2171767911603375

Epoch: 5| Step: 1
Training loss: 2.4949727058410645
Validation loss: 2.21153578963331

Epoch: 5| Step: 2
Training loss: 2.043428897857666
Validation loss: 2.2039484311175603

Epoch: 5| Step: 3
Training loss: 2.0575549602508545
Validation loss: 2.199110428492228

Epoch: 5| Step: 4
Training loss: 2.7282843589782715
Validation loss: 2.2150126657178326

Epoch: 5| Step: 5
Training loss: 2.5909554958343506
Validation loss: 2.2343340971136607

Epoch: 5| Step: 6
Training loss: 2.727163314819336
Validation loss: 2.266229857680618

Epoch: 5| Step: 7
Training loss: 2.330284833908081
Validation loss: 2.2708266114675872

Epoch: 5| Step: 8
Training loss: 2.7726619243621826
Validation loss: 2.2525442595122964

Epoch: 5| Step: 9
Training loss: 2.0264639854431152
Validation loss: 2.2221616852668022

Epoch: 5| Step: 10
Training loss: 2.4588088989257812
Validation loss: 2.2102678616841636

Epoch: 134| Step: 0
Training loss: 2.4013755321502686
Validation loss: 2.2106405996507212

Epoch: 5| Step: 1
Training loss: 2.336686134338379
Validation loss: 2.2152786921429377

Epoch: 5| Step: 2
Training loss: 3.0305023193359375
Validation loss: 2.2171145177656606

Epoch: 5| Step: 3
Training loss: 2.5605251789093018
Validation loss: 2.226154399174516

Epoch: 5| Step: 4
Training loss: 1.8043632507324219
Validation loss: 2.2425361602537093

Epoch: 5| Step: 5
Training loss: 2.6400651931762695
Validation loss: 2.2357471796774093

Epoch: 5| Step: 6
Training loss: 2.3102290630340576
Validation loss: 2.221755912227015

Epoch: 5| Step: 7
Training loss: 2.6189870834350586
Validation loss: 2.214407854182746

Epoch: 5| Step: 8
Training loss: 2.5473973751068115
Validation loss: 2.193772869725381

Epoch: 5| Step: 9
Training loss: 2.2184510231018066
Validation loss: 2.1801163124781784

Epoch: 5| Step: 10
Training loss: 2.281919240951538
Validation loss: 2.1757000466828704

Epoch: 135| Step: 0
Training loss: 2.7289743423461914
Validation loss: 2.187167993155859

Epoch: 5| Step: 1
Training loss: 2.2415900230407715
Validation loss: 2.201358018382903

Epoch: 5| Step: 2
Training loss: 2.0776820182800293
Validation loss: 2.2168859743302867

Epoch: 5| Step: 3
Training loss: 2.4239628314971924
Validation loss: 2.221315127547069

Epoch: 5| Step: 4
Training loss: 2.3734843730926514
Validation loss: 2.228758627368558

Epoch: 5| Step: 5
Training loss: 2.654465913772583
Validation loss: 2.2218814793453423

Epoch: 5| Step: 6
Training loss: 3.2356231212615967
Validation loss: 2.212711258601117

Epoch: 5| Step: 7
Training loss: 2.233853578567505
Validation loss: 2.192224484617992

Epoch: 5| Step: 8
Training loss: 1.8290735483169556
Validation loss: 2.198384290100426

Epoch: 5| Step: 9
Training loss: 2.302053928375244
Validation loss: 2.2125574183720413

Epoch: 5| Step: 10
Training loss: 2.6134510040283203
Validation loss: 2.2231655813032583

Epoch: 136| Step: 0
Training loss: 2.4461355209350586
Validation loss: 2.2383986749956684

Epoch: 5| Step: 1
Training loss: 2.4846370220184326
Validation loss: 2.2396820668251283

Epoch: 5| Step: 2
Training loss: 2.7623074054718018
Validation loss: 2.234232343653197

Epoch: 5| Step: 3
Training loss: 1.8807077407836914
Validation loss: 2.2291133583232923

Epoch: 5| Step: 4
Training loss: 2.6562252044677734
Validation loss: 2.2079259746818134

Epoch: 5| Step: 5
Training loss: 1.7763404846191406
Validation loss: 2.2007129397443546

Epoch: 5| Step: 6
Training loss: 2.5251049995422363
Validation loss: 2.2085860518999

Epoch: 5| Step: 7
Training loss: 2.7464382648468018
Validation loss: 2.2101010071334017

Epoch: 5| Step: 8
Training loss: 2.260058879852295
Validation loss: 2.2108951409657798

Epoch: 5| Step: 9
Training loss: 2.823791027069092
Validation loss: 2.2170229086311917

Epoch: 5| Step: 10
Training loss: 2.2405033111572266
Validation loss: 2.2349681085155857

Epoch: 137| Step: 0
Training loss: 2.6043708324432373
Validation loss: 2.2294039572438886

Epoch: 5| Step: 1
Training loss: 2.934039831161499
Validation loss: 2.232437510644236

Epoch: 5| Step: 2
Training loss: 2.4865527153015137
Validation loss: 2.223781693366266

Epoch: 5| Step: 3
Training loss: 2.6798033714294434
Validation loss: 2.1960400842851207

Epoch: 5| Step: 4
Training loss: 2.323026418685913
Validation loss: 2.1930465236786874

Epoch: 5| Step: 5
Training loss: 2.6744332313537598
Validation loss: 2.1905739307403564

Epoch: 5| Step: 6
Training loss: 2.007429838180542
Validation loss: 2.200116660005303

Epoch: 5| Step: 7
Training loss: 2.4791011810302734
Validation loss: 2.193578294528428

Epoch: 5| Step: 8
Training loss: 2.3112616539001465
Validation loss: 2.1928004885232575

Epoch: 5| Step: 9
Training loss: 1.6431818008422852
Validation loss: 2.1816889265532136

Epoch: 5| Step: 10
Training loss: 2.533031463623047
Validation loss: 2.1837007230327976

Epoch: 138| Step: 0
Training loss: 2.2967441082000732
Validation loss: 2.1979478456640757

Epoch: 5| Step: 1
Training loss: 2.1649413108825684
Validation loss: 2.227054465201593

Epoch: 5| Step: 2
Training loss: 3.3472495079040527
Validation loss: 2.2782651608990085

Epoch: 5| Step: 3
Training loss: 2.255488157272339
Validation loss: 2.3222505431021414

Epoch: 5| Step: 4
Training loss: 2.2647759914398193
Validation loss: 2.336280007516184

Epoch: 5| Step: 5
Training loss: 2.455332040786743
Validation loss: 2.284793310267951

Epoch: 5| Step: 6
Training loss: 2.0381245613098145
Validation loss: 2.254916050100839

Epoch: 5| Step: 7
Training loss: 2.2343311309814453
Validation loss: 2.2332165625787552

Epoch: 5| Step: 8
Training loss: 2.619915008544922
Validation loss: 2.226473703179308

Epoch: 5| Step: 9
Training loss: 2.86550235748291
Validation loss: 2.230928961948682

Epoch: 5| Step: 10
Training loss: 2.376516819000244
Validation loss: 2.224061974915125

Epoch: 139| Step: 0
Training loss: 2.062042236328125
Validation loss: 2.2158435877933296

Epoch: 5| Step: 1
Training loss: 2.6374056339263916
Validation loss: 2.2048439620643534

Epoch: 5| Step: 2
Training loss: 2.1793723106384277
Validation loss: 2.199811038150582

Epoch: 5| Step: 3
Training loss: 2.1388726234436035
Validation loss: 2.190056759824035

Epoch: 5| Step: 4
Training loss: 2.69722318649292
Validation loss: 2.184119286075715

Epoch: 5| Step: 5
Training loss: 2.291268825531006
Validation loss: 2.189927788190944

Epoch: 5| Step: 6
Training loss: 2.9796626567840576
Validation loss: 2.1948314584711546

Epoch: 5| Step: 7
Training loss: 2.457742691040039
Validation loss: 2.2080456864449287

Epoch: 5| Step: 8
Training loss: 2.6848061084747314
Validation loss: 2.201041447219028

Epoch: 5| Step: 9
Training loss: 1.9542608261108398
Validation loss: 2.203618108585317

Epoch: 5| Step: 10
Training loss: 2.459475040435791
Validation loss: 2.2230383593549012

Epoch: 140| Step: 0
Training loss: 2.4886727333068848
Validation loss: 2.2279276911930372

Epoch: 5| Step: 1
Training loss: 2.604067325592041
Validation loss: 2.2338286676714496

Epoch: 5| Step: 2
Training loss: 2.9485085010528564
Validation loss: 2.2362465473913375

Epoch: 5| Step: 3
Training loss: 2.1244330406188965
Validation loss: 2.228738525862335

Epoch: 5| Step: 4
Training loss: 2.4257071018218994
Validation loss: 2.2143135737347346

Epoch: 5| Step: 5
Training loss: 1.6111419200897217
Validation loss: 2.218727106689125

Epoch: 5| Step: 6
Training loss: 2.385011911392212
Validation loss: 2.2385887971488376

Epoch: 5| Step: 7
Training loss: 2.139202833175659
Validation loss: 2.2542354881122546

Epoch: 5| Step: 8
Training loss: 3.0366358757019043
Validation loss: 2.2952120022107194

Epoch: 5| Step: 9
Training loss: 2.617368221282959
Validation loss: 2.276017165953113

Epoch: 5| Step: 10
Training loss: 2.3732776641845703
Validation loss: 2.2412129550851803

Epoch: 141| Step: 0
Training loss: 2.2691614627838135
Validation loss: 2.2242553926283315

Epoch: 5| Step: 1
Training loss: 1.9395062923431396
Validation loss: 2.217450023979269

Epoch: 5| Step: 2
Training loss: 2.6215620040893555
Validation loss: 2.2229398937635523

Epoch: 5| Step: 3
Training loss: 2.9644980430603027
Validation loss: 2.218571691102879

Epoch: 5| Step: 4
Training loss: 2.4109349250793457
Validation loss: 2.2335340643441803

Epoch: 5| Step: 5
Training loss: 2.339920997619629
Validation loss: 2.2230229275200957

Epoch: 5| Step: 6
Training loss: 2.472583532333374
Validation loss: 2.2565980072944396

Epoch: 5| Step: 7
Training loss: 2.7661385536193848
Validation loss: 2.2548124277463524

Epoch: 5| Step: 8
Training loss: 2.1383395195007324
Validation loss: 2.259097999142062

Epoch: 5| Step: 9
Training loss: 1.7653043270111084
Validation loss: 2.2255100857826973

Epoch: 5| Step: 10
Training loss: 2.830256700515747
Validation loss: 2.2302365431221585

Epoch: 142| Step: 0
Training loss: 2.3248815536499023
Validation loss: 2.227583171218954

Epoch: 5| Step: 1
Training loss: 2.6574339866638184
Validation loss: 2.2265970373666413

Epoch: 5| Step: 2
Training loss: 2.2611193656921387
Validation loss: 2.232550308268557

Epoch: 5| Step: 3
Training loss: 2.2162678241729736
Validation loss: 2.23471857911797

Epoch: 5| Step: 4
Training loss: 2.6063663959503174
Validation loss: 2.26913555078609

Epoch: 5| Step: 5
Training loss: 2.5790069103240967
Validation loss: 2.304126811283891

Epoch: 5| Step: 6
Training loss: 2.239708423614502
Validation loss: 2.3468962407881215

Epoch: 5| Step: 7
Training loss: 2.518195629119873
Validation loss: 2.322382519322057

Epoch: 5| Step: 8
Training loss: 1.873379111289978
Validation loss: 2.323779539395404

Epoch: 5| Step: 9
Training loss: 2.8460652828216553
Validation loss: 2.2666986808981946

Epoch: 5| Step: 10
Training loss: 2.6355340480804443
Validation loss: 2.2379831165395756

Epoch: 143| Step: 0
Training loss: 2.1596901416778564
Validation loss: 2.20761138649397

Epoch: 5| Step: 1
Training loss: 2.526475429534912
Validation loss: 2.194424747138895

Epoch: 5| Step: 2
Training loss: 2.4131920337677
Validation loss: 2.1962044418499036

Epoch: 5| Step: 3
Training loss: 2.2152397632598877
Validation loss: 2.200274239304245

Epoch: 5| Step: 4
Training loss: 2.3552613258361816
Validation loss: 2.2196238143469698

Epoch: 5| Step: 5
Training loss: 2.1050491333007812
Validation loss: 2.2185777682130055

Epoch: 5| Step: 6
Training loss: 2.908069372177124
Validation loss: 2.225609407630018

Epoch: 5| Step: 7
Training loss: 2.1313607692718506
Validation loss: 2.1887405572399015

Epoch: 5| Step: 8
Training loss: 2.2141001224517822
Validation loss: 2.17740293728408

Epoch: 5| Step: 9
Training loss: 2.700568675994873
Validation loss: 2.185862801408255

Epoch: 5| Step: 10
Training loss: 2.7835190296173096
Validation loss: 2.1823273589534145

Epoch: 144| Step: 0
Training loss: 3.0820021629333496
Validation loss: 2.203152184845299

Epoch: 5| Step: 1
Training loss: 1.8759241104125977
Validation loss: 2.2123379938064085

Epoch: 5| Step: 2
Training loss: 2.3605265617370605
Validation loss: 2.251126863623178

Epoch: 5| Step: 3
Training loss: 2.266812801361084
Validation loss: 2.297721985847719

Epoch: 5| Step: 4
Training loss: 2.6516621112823486
Validation loss: 2.273178546659408

Epoch: 5| Step: 5
Training loss: 2.024099588394165
Validation loss: 2.247984799005652

Epoch: 5| Step: 6
Training loss: 2.0664141178131104
Validation loss: 2.2448492383444183

Epoch: 5| Step: 7
Training loss: 2.4670822620391846
Validation loss: 2.234512029155608

Epoch: 5| Step: 8
Training loss: 2.418975353240967
Validation loss: 2.2399929851614018

Epoch: 5| Step: 9
Training loss: 2.8567543029785156
Validation loss: 2.2301952069805515

Epoch: 5| Step: 10
Training loss: 2.356693744659424
Validation loss: 2.21054095350286

Epoch: 145| Step: 0
Training loss: 2.0933837890625
Validation loss: 2.1932604620533604

Epoch: 5| Step: 1
Training loss: 2.1899266242980957
Validation loss: 2.190228008454846

Epoch: 5| Step: 2
Training loss: 3.017864942550659
Validation loss: 2.1838896056657195

Epoch: 5| Step: 3
Training loss: 2.428795337677002
Validation loss: 2.188586978502171

Epoch: 5| Step: 4
Training loss: 1.8269157409667969
Validation loss: 2.1805141279774327

Epoch: 5| Step: 5
Training loss: 2.4360549449920654
Validation loss: 2.1897538579920286

Epoch: 5| Step: 6
Training loss: 3.123568534851074
Validation loss: 2.1820548913812123

Epoch: 5| Step: 7
Training loss: 2.2440578937530518
Validation loss: 2.1818855782990814

Epoch: 5| Step: 8
Training loss: 1.5578336715698242
Validation loss: 2.184909664174562

Epoch: 5| Step: 9
Training loss: 2.9157707691192627
Validation loss: 2.18691284425797

Epoch: 5| Step: 10
Training loss: 2.5596039295196533
Validation loss: 2.213588547962968

Epoch: 146| Step: 0
Training loss: 2.2825698852539062
Validation loss: 2.2023888095732658

Epoch: 5| Step: 1
Training loss: 2.2475802898406982
Validation loss: 2.2107550790232997

Epoch: 5| Step: 2
Training loss: 2.0136780738830566
Validation loss: 2.2195914227475404

Epoch: 5| Step: 3
Training loss: 2.0796802043914795
Validation loss: 2.2152414962809575

Epoch: 5| Step: 4
Training loss: 2.3316969871520996
Validation loss: 2.2218978097361903

Epoch: 5| Step: 5
Training loss: 2.0113272666931152
Validation loss: 2.259277512950282

Epoch: 5| Step: 6
Training loss: 3.081986665725708
Validation loss: 2.2977441664664977

Epoch: 5| Step: 7
Training loss: 2.7905120849609375
Validation loss: 2.2615466707496235

Epoch: 5| Step: 8
Training loss: 2.8512182235717773
Validation loss: 2.221557956869884

Epoch: 5| Step: 9
Training loss: 1.482590913772583
Validation loss: 2.203986983145437

Epoch: 5| Step: 10
Training loss: 3.3016300201416016
Validation loss: 2.187863273005332

Epoch: 147| Step: 0
Training loss: 2.7358994483947754
Validation loss: 2.1896333925185667

Epoch: 5| Step: 1
Training loss: 2.4851489067077637
Validation loss: 2.199490738171403

Epoch: 5| Step: 2
Training loss: 2.9613280296325684
Validation loss: 2.188988680480629

Epoch: 5| Step: 3
Training loss: 1.8146721124649048
Validation loss: 2.2046606181770243

Epoch: 5| Step: 4
Training loss: 2.236215591430664
Validation loss: 2.2088130879145798

Epoch: 5| Step: 5
Training loss: 2.828946590423584
Validation loss: 2.2076194235073623

Epoch: 5| Step: 6
Training loss: 2.648322343826294
Validation loss: 2.202162896433184

Epoch: 5| Step: 7
Training loss: 1.8053430318832397
Validation loss: 2.189385567941973

Epoch: 5| Step: 8
Training loss: 2.254279613494873
Validation loss: 2.1738639288051154

Epoch: 5| Step: 9
Training loss: 1.587886095046997
Validation loss: 2.1821083150884157

Epoch: 5| Step: 10
Training loss: 2.948248863220215
Validation loss: 2.187790661729792

Epoch: 148| Step: 0
Training loss: 2.458824634552002
Validation loss: 2.182554970505417

Epoch: 5| Step: 1
Training loss: 1.7279996871948242
Validation loss: 2.177239482120801

Epoch: 5| Step: 2
Training loss: 1.8626381158828735
Validation loss: 2.199096246432233

Epoch: 5| Step: 3
Training loss: 2.3424856662750244
Validation loss: 2.2095812418127574

Epoch: 5| Step: 4
Training loss: 2.397136688232422
Validation loss: 2.193975769063478

Epoch: 5| Step: 5
Training loss: 3.086369514465332
Validation loss: 2.1969618156392086

Epoch: 5| Step: 6
Training loss: 2.109862804412842
Validation loss: 2.1969547117910078

Epoch: 5| Step: 7
Training loss: 2.956275701522827
Validation loss: 2.2071617803265973

Epoch: 5| Step: 8
Training loss: 2.4860100746154785
Validation loss: 2.193465935286655

Epoch: 5| Step: 9
Training loss: 2.3662796020507812
Validation loss: 2.192083881747338

Epoch: 5| Step: 10
Training loss: 2.0905544757843018
Validation loss: 2.1925901289909118

Epoch: 149| Step: 0
Training loss: 2.288922071456909
Validation loss: 2.1981094934607066

Epoch: 5| Step: 1
Training loss: 2.6115059852600098
Validation loss: 2.210784404508529

Epoch: 5| Step: 2
Training loss: 1.9725532531738281
Validation loss: 2.2197282698846634

Epoch: 5| Step: 3
Training loss: 2.5402257442474365
Validation loss: 2.233330588186941

Epoch: 5| Step: 4
Training loss: 2.408994674682617
Validation loss: 2.218098735296598

Epoch: 5| Step: 5
Training loss: 2.993072509765625
Validation loss: 2.221420613668298

Epoch: 5| Step: 6
Training loss: 2.026566982269287
Validation loss: 2.2036448012116137

Epoch: 5| Step: 7
Training loss: 2.463712215423584
Validation loss: 2.21791354046073

Epoch: 5| Step: 8
Training loss: 1.8304812908172607
Validation loss: 2.216014644151093

Epoch: 5| Step: 9
Training loss: 2.1851720809936523
Validation loss: 2.227738936742147

Epoch: 5| Step: 10
Training loss: 2.623347043991089
Validation loss: 2.2189163700226815

Epoch: 150| Step: 0
Training loss: 2.591538429260254
Validation loss: 2.2357023044299056

Epoch: 5| Step: 1
Training loss: 2.3829541206359863
Validation loss: 2.236824345845048

Epoch: 5| Step: 2
Training loss: 2.542977809906006
Validation loss: 2.220815873915149

Epoch: 5| Step: 3
Training loss: 2.1519370079040527
Validation loss: 2.2188477926356818

Epoch: 5| Step: 4
Training loss: 1.8827784061431885
Validation loss: 2.202419883461409

Epoch: 5| Step: 5
Training loss: 2.263594150543213
Validation loss: 2.202421010181468

Epoch: 5| Step: 6
Training loss: 2.583935260772705
Validation loss: 2.1835087858220583

Epoch: 5| Step: 7
Training loss: 2.792018413543701
Validation loss: 2.1863925354455107

Epoch: 5| Step: 8
Training loss: 2.2451555728912354
Validation loss: 2.1967752261828353

Epoch: 5| Step: 9
Training loss: 2.33666729927063
Validation loss: 2.193208658567039

Epoch: 5| Step: 10
Training loss: 2.085184097290039
Validation loss: 2.199799141576213

Epoch: 151| Step: 0
Training loss: 2.5941309928894043
Validation loss: 2.2100238184775076

Epoch: 5| Step: 1
Training loss: 2.400113821029663
Validation loss: 2.1962212977870816

Epoch: 5| Step: 2
Training loss: 2.22890043258667
Validation loss: 2.1967406401070217

Epoch: 5| Step: 3
Training loss: 2.5120410919189453
Validation loss: 2.184274552970804

Epoch: 5| Step: 4
Training loss: 2.431063413619995
Validation loss: 2.183505622289514

Epoch: 5| Step: 5
Training loss: 2.762382984161377
Validation loss: 2.1772927327822615

Epoch: 5| Step: 6
Training loss: 2.2545080184936523
Validation loss: 2.184389614289807

Epoch: 5| Step: 7
Training loss: 2.5254900455474854
Validation loss: 2.194229789959487

Epoch: 5| Step: 8
Training loss: 2.1848814487457275
Validation loss: 2.1839948290137836

Epoch: 5| Step: 9
Training loss: 1.8709074258804321
Validation loss: 2.1885849839897564

Epoch: 5| Step: 10
Training loss: 2.1595211029052734
Validation loss: 2.18520519041246

Epoch: 152| Step: 0
Training loss: 2.4694676399230957
Validation loss: 2.1768660391530683

Epoch: 5| Step: 1
Training loss: 2.349926710128784
Validation loss: 2.170350768232858

Epoch: 5| Step: 2
Training loss: 2.456040143966675
Validation loss: 2.1893954328311387

Epoch: 5| Step: 3
Training loss: 2.094891309738159
Validation loss: 2.1956241002646824

Epoch: 5| Step: 4
Training loss: 2.3303780555725098
Validation loss: 2.2015314473900744

Epoch: 5| Step: 5
Training loss: 1.645254373550415
Validation loss: 2.2094863255818686

Epoch: 5| Step: 6
Training loss: 2.5741353034973145
Validation loss: 2.221158919795867

Epoch: 5| Step: 7
Training loss: 2.6915974617004395
Validation loss: 2.236969365868517

Epoch: 5| Step: 8
Training loss: 1.7190444469451904
Validation loss: 2.2597345459845757

Epoch: 5| Step: 9
Training loss: 2.9519031047821045
Validation loss: 2.27877321550923

Epoch: 5| Step: 10
Training loss: 2.4261622428894043
Validation loss: 2.244342662954843

Epoch: 153| Step: 0
Training loss: 1.9466972351074219
Validation loss: 2.2392631551270843

Epoch: 5| Step: 1
Training loss: 2.5342280864715576
Validation loss: 2.230024496714274

Epoch: 5| Step: 2
Training loss: 3.0032989978790283
Validation loss: 2.2230948145671556

Epoch: 5| Step: 3
Training loss: 2.5751607418060303
Validation loss: 2.2070841173971854

Epoch: 5| Step: 4
Training loss: 1.7364778518676758
Validation loss: 2.1966429679624495

Epoch: 5| Step: 5
Training loss: 1.8953759670257568
Validation loss: 2.2128254726368892

Epoch: 5| Step: 6
Training loss: 2.524077892303467
Validation loss: 2.200392084736978

Epoch: 5| Step: 7
Training loss: 2.166537046432495
Validation loss: 2.2130930885191886

Epoch: 5| Step: 8
Training loss: 2.5336570739746094
Validation loss: 2.2105153299147084

Epoch: 5| Step: 9
Training loss: 2.821892023086548
Validation loss: 2.231174025484311

Epoch: 5| Step: 10
Training loss: 1.849465250968933
Validation loss: 2.1993847047128985

Epoch: 154| Step: 0
Training loss: 2.9222519397735596
Validation loss: 2.195460847629014

Epoch: 5| Step: 1
Training loss: 2.2315378189086914
Validation loss: 2.202514789437735

Epoch: 5| Step: 2
Training loss: 2.2669997215270996
Validation loss: 2.2030511107496036

Epoch: 5| Step: 3
Training loss: 2.8806653022766113
Validation loss: 2.2343288288321546

Epoch: 5| Step: 4
Training loss: 2.807404041290283
Validation loss: 2.240109899992584

Epoch: 5| Step: 5
Training loss: 2.4142563343048096
Validation loss: 2.2487750925043577

Epoch: 5| Step: 6
Training loss: 2.253328323364258
Validation loss: 2.255434505401119

Epoch: 5| Step: 7
Training loss: 2.09861421585083
Validation loss: 2.2415504763203282

Epoch: 5| Step: 8
Training loss: 1.9597667455673218
Validation loss: 2.240702695744012

Epoch: 5| Step: 9
Training loss: 1.2154827117919922
Validation loss: 2.2219573913082

Epoch: 5| Step: 10
Training loss: 2.6962952613830566
Validation loss: 2.227861655655728

Epoch: 155| Step: 0
Training loss: 2.099834680557251
Validation loss: 2.196890720757105

Epoch: 5| Step: 1
Training loss: 1.6787086725234985
Validation loss: 2.1864717468138664

Epoch: 5| Step: 2
Training loss: 2.026623249053955
Validation loss: 2.202558832783853

Epoch: 5| Step: 3
Training loss: 2.148283004760742
Validation loss: 2.23342550698147

Epoch: 5| Step: 4
Training loss: 2.964594602584839
Validation loss: 2.268469766903949

Epoch: 5| Step: 5
Training loss: 2.7548000812530518
Validation loss: 2.2610941292137228

Epoch: 5| Step: 6
Training loss: 2.0740890502929688
Validation loss: 2.2112993040392475

Epoch: 5| Step: 7
Training loss: 1.9063432216644287
Validation loss: 2.1947592150780464

Epoch: 5| Step: 8
Training loss: 2.316896915435791
Validation loss: 2.1817872524261475

Epoch: 5| Step: 9
Training loss: 2.423480272293091
Validation loss: 2.172050663219985

Epoch: 5| Step: 10
Training loss: 3.330157995223999
Validation loss: 2.174266797240062

Epoch: 156| Step: 0
Training loss: 2.4314827919006348
Validation loss: 2.1826159748979794

Epoch: 5| Step: 1
Training loss: 2.1360483169555664
Validation loss: 2.186795401316817

Epoch: 5| Step: 2
Training loss: 2.687751531600952
Validation loss: 2.182327416635329

Epoch: 5| Step: 3
Training loss: 2.22654390335083
Validation loss: 2.1767876891679663

Epoch: 5| Step: 4
Training loss: 2.2532339096069336
Validation loss: 2.171357233037231

Epoch: 5| Step: 5
Training loss: 2.702373504638672
Validation loss: 2.1618458327426704

Epoch: 5| Step: 6
Training loss: 1.8252452611923218
Validation loss: 2.1631243357094387

Epoch: 5| Step: 7
Training loss: 2.5301032066345215
Validation loss: 2.1651881330756733

Epoch: 5| Step: 8
Training loss: 2.441223382949829
Validation loss: 2.1863262666169034

Epoch: 5| Step: 9
Training loss: 2.309945583343506
Validation loss: 2.2321308479514173

Epoch: 5| Step: 10
Training loss: 2.0028469562530518
Validation loss: 2.2972185098996727

Epoch: 157| Step: 0
Training loss: 2.438171625137329
Validation loss: 2.2805622444357923

Epoch: 5| Step: 1
Training loss: 1.9074962139129639
Validation loss: 2.2357313504783054

Epoch: 5| Step: 2
Training loss: 2.235704183578491
Validation loss: 2.202833867842151

Epoch: 5| Step: 3
Training loss: 2.2264819145202637
Validation loss: 2.1770656813857374

Epoch: 5| Step: 4
Training loss: 2.7302560806274414
Validation loss: 2.209177024902836

Epoch: 5| Step: 5
Training loss: 2.501753568649292
Validation loss: 2.2336837963391374

Epoch: 5| Step: 6
Training loss: 2.154568910598755
Validation loss: 2.271289940803282

Epoch: 5| Step: 7
Training loss: 2.386671543121338
Validation loss: 2.3019754912263606

Epoch: 5| Step: 8
Training loss: 2.329573154449463
Validation loss: 2.3118429312141995

Epoch: 5| Step: 9
Training loss: 2.413137912750244
Validation loss: 2.299546282778504

Epoch: 5| Step: 10
Training loss: 2.8404786586761475
Validation loss: 2.265915466893104

Epoch: 158| Step: 0
Training loss: 2.7546229362487793
Validation loss: 2.242249796467443

Epoch: 5| Step: 1
Training loss: 2.1092476844787598
Validation loss: 2.2284043835055445

Epoch: 5| Step: 2
Training loss: 2.8595499992370605
Validation loss: 2.23991027955086

Epoch: 5| Step: 3
Training loss: 1.5797622203826904
Validation loss: 2.2565612921150784

Epoch: 5| Step: 4
Training loss: 2.18458890914917
Validation loss: 2.2713673422413487

Epoch: 5| Step: 5
Training loss: 2.3055830001831055
Validation loss: 2.265476644680064

Epoch: 5| Step: 6
Training loss: 2.520662307739258
Validation loss: 2.257688109592725

Epoch: 5| Step: 7
Training loss: 2.1879425048828125
Validation loss: 2.2322237286516415

Epoch: 5| Step: 8
Training loss: 2.2381110191345215
Validation loss: 2.1692373098865634

Epoch: 5| Step: 9
Training loss: 3.0582761764526367
Validation loss: 2.155618167692615

Epoch: 5| Step: 10
Training loss: 1.5534132719039917
Validation loss: 2.128190677653077

Epoch: 159| Step: 0
Training loss: 2.388054609298706
Validation loss: 2.1511194270144225

Epoch: 5| Step: 1
Training loss: 2.4137649536132812
Validation loss: 2.1623895578486945

Epoch: 5| Step: 2
Training loss: 1.7100509405136108
Validation loss: 2.1634585447208856

Epoch: 5| Step: 3
Training loss: 2.0911777019500732
Validation loss: 2.141180661416823

Epoch: 5| Step: 4
Training loss: 2.3715767860412598
Validation loss: 2.142050527757214

Epoch: 5| Step: 5
Training loss: 2.2487308979034424
Validation loss: 2.1402758898273593

Epoch: 5| Step: 6
Training loss: 2.0220940113067627
Validation loss: 2.1368239733480636

Epoch: 5| Step: 7
Training loss: 2.5452980995178223
Validation loss: 2.1521365796366045

Epoch: 5| Step: 8
Training loss: 2.865011692047119
Validation loss: 2.1673864600478963

Epoch: 5| Step: 9
Training loss: 2.548305034637451
Validation loss: 2.1736274380837717

Epoch: 5| Step: 10
Training loss: 2.5137314796447754
Validation loss: 2.1765519008841565

Epoch: 160| Step: 0
Training loss: 2.0993950366973877
Validation loss: 2.200655489839533

Epoch: 5| Step: 1
Training loss: 2.1320714950561523
Validation loss: 2.1911847745218584

Epoch: 5| Step: 2
Training loss: 2.428330421447754
Validation loss: 2.2015882307483303

Epoch: 5| Step: 3
Training loss: 2.3955001831054688
Validation loss: 2.206438374775712

Epoch: 5| Step: 4
Training loss: 2.7379536628723145
Validation loss: 2.205165514381983

Epoch: 5| Step: 5
Training loss: 2.751178741455078
Validation loss: 2.1959856569126086

Epoch: 5| Step: 6
Training loss: 1.750482201576233
Validation loss: 2.1977579824386106

Epoch: 5| Step: 7
Training loss: 1.7077640295028687
Validation loss: 2.2289119638422483

Epoch: 5| Step: 8
Training loss: 2.3423221111297607
Validation loss: 2.258285927516158

Epoch: 5| Step: 9
Training loss: 2.329193353652954
Validation loss: 2.224218894076604

Epoch: 5| Step: 10
Training loss: 2.8884756565093994
Validation loss: 2.2166324379623576

Epoch: 161| Step: 0
Training loss: 1.866930365562439
Validation loss: 2.2177883924976474

Epoch: 5| Step: 1
Training loss: 1.4764392375946045
Validation loss: 2.216888230334046

Epoch: 5| Step: 2
Training loss: 1.5552754402160645
Validation loss: 2.2247248747015513

Epoch: 5| Step: 3
Training loss: 2.028982400894165
Validation loss: 2.238460544616945

Epoch: 5| Step: 4
Training loss: 3.1547458171844482
Validation loss: 2.2421326996177755

Epoch: 5| Step: 5
Training loss: 2.373107433319092
Validation loss: 2.2141352315102854

Epoch: 5| Step: 6
Training loss: 2.9703457355499268
Validation loss: 2.2035774082265873

Epoch: 5| Step: 7
Training loss: 2.572866439819336
Validation loss: 2.2013521463640275

Epoch: 5| Step: 8
Training loss: 2.4590542316436768
Validation loss: 2.1961537843109458

Epoch: 5| Step: 9
Training loss: 2.086378335952759
Validation loss: 2.181477459528113

Epoch: 5| Step: 10
Training loss: 2.950533151626587
Validation loss: 2.169244873908258

Epoch: 162| Step: 0
Training loss: 3.0287413597106934
Validation loss: 2.1733396848042807

Epoch: 5| Step: 1
Training loss: 2.305072784423828
Validation loss: 2.17384071247552

Epoch: 5| Step: 2
Training loss: 2.106889247894287
Validation loss: 2.1794937361953077

Epoch: 5| Step: 3
Training loss: 2.6598596572875977
Validation loss: 2.1861585006918958

Epoch: 5| Step: 4
Training loss: 1.7440258264541626
Validation loss: 2.1990935033367527

Epoch: 5| Step: 5
Training loss: 2.5036494731903076
Validation loss: 2.191858983808948

Epoch: 5| Step: 6
Training loss: 1.9830610752105713
Validation loss: 2.167870972746162

Epoch: 5| Step: 7
Training loss: 2.321842670440674
Validation loss: 2.155293039096299

Epoch: 5| Step: 8
Training loss: 1.8429358005523682
Validation loss: 2.141946948984618

Epoch: 5| Step: 9
Training loss: 2.2925362586975098
Validation loss: 2.134431598007038

Epoch: 5| Step: 10
Training loss: 2.571629524230957
Validation loss: 2.1542595342923234

Epoch: 163| Step: 0
Training loss: 1.8412984609603882
Validation loss: 2.180889173220563

Epoch: 5| Step: 1
Training loss: 1.8847243785858154
Validation loss: 2.1896465645041516

Epoch: 5| Step: 2
Training loss: 2.5996603965759277
Validation loss: 2.1918246515335573

Epoch: 5| Step: 3
Training loss: 2.3716413974761963
Validation loss: 2.2096045914516655

Epoch: 5| Step: 4
Training loss: 2.524437665939331
Validation loss: 2.202728186884234

Epoch: 5| Step: 5
Training loss: 1.8981940746307373
Validation loss: 2.1966620568306214

Epoch: 5| Step: 6
Training loss: 2.358710765838623
Validation loss: 2.1829561918012557

Epoch: 5| Step: 7
Training loss: 2.535372495651245
Validation loss: 2.176982782220328

Epoch: 5| Step: 8
Training loss: 2.2777554988861084
Validation loss: 2.1628938772345103

Epoch: 5| Step: 9
Training loss: 2.4720675945281982
Validation loss: 2.159237951360723

Epoch: 5| Step: 10
Training loss: 2.4644620418548584
Validation loss: 2.1569989112115677

Epoch: 164| Step: 0
Training loss: 1.4808440208435059
Validation loss: 2.165126023753997

Epoch: 5| Step: 1
Training loss: 2.3108716011047363
Validation loss: 2.1663490854283816

Epoch: 5| Step: 2
Training loss: 2.719099760055542
Validation loss: 2.1798795218108804

Epoch: 5| Step: 3
Training loss: 2.5481388568878174
Validation loss: 2.1819787153633694

Epoch: 5| Step: 4
Training loss: 2.191964626312256
Validation loss: 2.1877451506994103

Epoch: 5| Step: 5
Training loss: 2.2261288166046143
Validation loss: 2.1865953835107947

Epoch: 5| Step: 6
Training loss: 2.7710611820220947
Validation loss: 2.183068747161537

Epoch: 5| Step: 7
Training loss: 2.214261531829834
Validation loss: 2.190559120588405

Epoch: 5| Step: 8
Training loss: 2.2056782245635986
Validation loss: 2.1983522625379663

Epoch: 5| Step: 9
Training loss: 2.093195676803589
Validation loss: 2.209096189468138

Epoch: 5| Step: 10
Training loss: 2.322615146636963
Validation loss: 2.1981549929547053

Epoch: 165| Step: 0
Training loss: 2.284331798553467
Validation loss: 2.188946639337847

Epoch: 5| Step: 1
Training loss: 1.8775691986083984
Validation loss: 2.1956621908372447

Epoch: 5| Step: 2
Training loss: 1.9995272159576416
Validation loss: 2.213024236822641

Epoch: 5| Step: 3
Training loss: 1.8040622472763062
Validation loss: 2.220869243785899

Epoch: 5| Step: 4
Training loss: 3.212406635284424
Validation loss: 2.1826516146300943

Epoch: 5| Step: 5
Training loss: 2.72743558883667
Validation loss: 2.1742622570324968

Epoch: 5| Step: 6
Training loss: 2.320791006088257
Validation loss: 2.1511852254149733

Epoch: 5| Step: 7
Training loss: 1.6690711975097656
Validation loss: 2.160846362831772

Epoch: 5| Step: 8
Training loss: 2.1347570419311523
Validation loss: 2.1513068086357525

Epoch: 5| Step: 9
Training loss: 2.417375087738037
Validation loss: 2.1617944189297256

Epoch: 5| Step: 10
Training loss: 2.6452057361602783
Validation loss: 2.177947190500075

Epoch: 166| Step: 0
Training loss: 2.5427653789520264
Validation loss: 2.2033464754781416

Epoch: 5| Step: 1
Training loss: 2.763007164001465
Validation loss: 2.2281490320800454

Epoch: 5| Step: 2
Training loss: 2.2280428409576416
Validation loss: 2.2400127867216706

Epoch: 5| Step: 3
Training loss: 2.1221861839294434
Validation loss: 2.2304474512736

Epoch: 5| Step: 4
Training loss: 2.7204222679138184
Validation loss: 2.2088964267443587

Epoch: 5| Step: 5
Training loss: 1.4965112209320068
Validation loss: 2.1947637911765807

Epoch: 5| Step: 6
Training loss: 1.62393057346344
Validation loss: 2.172819132445961

Epoch: 5| Step: 7
Training loss: 2.7703280448913574
Validation loss: 2.192105777802006

Epoch: 5| Step: 8
Training loss: 2.027045488357544
Validation loss: 2.1953152738591677

Epoch: 5| Step: 9
Training loss: 2.2846758365631104
Validation loss: 2.1908018819747435

Epoch: 5| Step: 10
Training loss: 2.5833733081817627
Validation loss: 2.2257913081876692

Epoch: 167| Step: 0
Training loss: 2.5426783561706543
Validation loss: 2.2063292918666715

Epoch: 5| Step: 1
Training loss: 2.195456027984619
Validation loss: 2.211385921765399

Epoch: 5| Step: 2
Training loss: 1.937913179397583
Validation loss: 2.1912220575476207

Epoch: 5| Step: 3
Training loss: 2.1123573780059814
Validation loss: 2.1604676246643066

Epoch: 5| Step: 4
Training loss: 1.5547467470169067
Validation loss: 2.1413628491022254

Epoch: 5| Step: 5
Training loss: 2.4451406002044678
Validation loss: 2.1333604089675413

Epoch: 5| Step: 6
Training loss: 2.9301810264587402
Validation loss: 2.1521332584401613

Epoch: 5| Step: 7
Training loss: 2.225564479827881
Validation loss: 2.1582465812724125

Epoch: 5| Step: 8
Training loss: 2.2711501121520996
Validation loss: 2.17797024532031

Epoch: 5| Step: 9
Training loss: 2.2192981243133545
Validation loss: 2.1952083751719487

Epoch: 5| Step: 10
Training loss: 2.6375293731689453
Validation loss: 2.1961787131524857

Epoch: 168| Step: 0
Training loss: 3.062732458114624
Validation loss: 2.191449680636006

Epoch: 5| Step: 1
Training loss: 2.47296142578125
Validation loss: 2.2030254140976937

Epoch: 5| Step: 2
Training loss: 1.9751548767089844
Validation loss: 2.201262625314856

Epoch: 5| Step: 3
Training loss: 1.5372756719589233
Validation loss: 2.1868775070354505

Epoch: 5| Step: 4
Training loss: 2.4798507690429688
Validation loss: 2.171500987904046

Epoch: 5| Step: 5
Training loss: 2.294827938079834
Validation loss: 2.1768177529816986

Epoch: 5| Step: 6
Training loss: 2.6304268836975098
Validation loss: 2.179202392537107

Epoch: 5| Step: 7
Training loss: 2.133911609649658
Validation loss: 2.175079543103454

Epoch: 5| Step: 8
Training loss: 2.5384979248046875
Validation loss: 2.1700465756077922

Epoch: 5| Step: 9
Training loss: 1.6917121410369873
Validation loss: 2.19347482983784

Epoch: 5| Step: 10
Training loss: 2.184809923171997
Validation loss: 2.212217115586804

Epoch: 169| Step: 0
Training loss: 2.3716533184051514
Validation loss: 2.2562205291563466

Epoch: 5| Step: 1
Training loss: 2.54880428314209
Validation loss: 2.286249440203431

Epoch: 5| Step: 2
Training loss: 2.3191921710968018
Validation loss: 2.2633803224050872

Epoch: 5| Step: 3
Training loss: 1.8517729043960571
Validation loss: 2.241711014060564

Epoch: 5| Step: 4
Training loss: 2.3414626121520996
Validation loss: 2.2286592927030338

Epoch: 5| Step: 5
Training loss: 2.3484065532684326
Validation loss: 2.21445966792363

Epoch: 5| Step: 6
Training loss: 1.706483244895935
Validation loss: 2.1895000344963482

Epoch: 5| Step: 7
Training loss: 2.924509048461914
Validation loss: 2.1753356764393468

Epoch: 5| Step: 8
Training loss: 2.1904425621032715
Validation loss: 2.1744670355191795

Epoch: 5| Step: 9
Training loss: 2.155357837677002
Validation loss: 2.1601087021571335

Epoch: 5| Step: 10
Training loss: 2.048064708709717
Validation loss: 2.1543547671328307

Epoch: 170| Step: 0
Training loss: 2.591869354248047
Validation loss: 2.1561459674630115

Epoch: 5| Step: 1
Training loss: 2.095982789993286
Validation loss: 2.1596733036861626

Epoch: 5| Step: 2
Training loss: 1.4567558765411377
Validation loss: 2.142986636007986

Epoch: 5| Step: 3
Training loss: 2.864687919616699
Validation loss: 2.1511667005477415

Epoch: 5| Step: 4
Training loss: 2.061724901199341
Validation loss: 2.1419464388201312

Epoch: 5| Step: 5
Training loss: 3.032590866088867
Validation loss: 2.1394374037301667

Epoch: 5| Step: 6
Training loss: 1.931950330734253
Validation loss: 2.1374038214324624

Epoch: 5| Step: 7
Training loss: 1.8335109949111938
Validation loss: 2.152037412889542

Epoch: 5| Step: 8
Training loss: 2.337631940841675
Validation loss: 2.1666933182747132

Epoch: 5| Step: 9
Training loss: 2.578174114227295
Validation loss: 2.177647977746943

Epoch: 5| Step: 10
Training loss: 2.145024538040161
Validation loss: 2.181467197274649

Epoch: 171| Step: 0
Training loss: 2.8025996685028076
Validation loss: 2.202079398657686

Epoch: 5| Step: 1
Training loss: 1.8101675510406494
Validation loss: 2.1869141222328268

Epoch: 5| Step: 2
Training loss: 2.0313613414764404
Validation loss: 2.1933804788897113

Epoch: 5| Step: 3
Training loss: 2.8170883655548096
Validation loss: 2.190385277553271

Epoch: 5| Step: 4
Training loss: 1.7336479425430298
Validation loss: 2.1932551809536514

Epoch: 5| Step: 5
Training loss: 2.5916757583618164
Validation loss: 2.2151884622471307

Epoch: 5| Step: 6
Training loss: 2.3712432384490967
Validation loss: 2.251829961294769

Epoch: 5| Step: 7
Training loss: 2.3243606090545654
Validation loss: 2.183121540213144

Epoch: 5| Step: 8
Training loss: 2.0877277851104736
Validation loss: 2.1545557591222946

Epoch: 5| Step: 9
Training loss: 2.16090726852417
Validation loss: 2.138703925635225

Epoch: 5| Step: 10
Training loss: 2.038628578186035
Validation loss: 2.1430339210776874

Epoch: 172| Step: 0
Training loss: 2.4007840156555176
Validation loss: 2.1221602578316965

Epoch: 5| Step: 1
Training loss: 2.0107693672180176
Validation loss: 2.1246824097889725

Epoch: 5| Step: 2
Training loss: 1.9928497076034546
Validation loss: 2.1381302418247348

Epoch: 5| Step: 3
Training loss: 2.285029888153076
Validation loss: 2.1513590120500132

Epoch: 5| Step: 4
Training loss: 2.778687000274658
Validation loss: 2.14058639413567

Epoch: 5| Step: 5
Training loss: 2.6419334411621094
Validation loss: 2.1386323846796507

Epoch: 5| Step: 6
Training loss: 2.0570640563964844
Validation loss: 2.125560946361993

Epoch: 5| Step: 7
Training loss: 2.191162586212158
Validation loss: 2.17384583462951

Epoch: 5| Step: 8
Training loss: 2.46073579788208
Validation loss: 2.1706331032578663

Epoch: 5| Step: 9
Training loss: 2.009946823120117
Validation loss: 2.184327188358512

Epoch: 5| Step: 10
Training loss: 1.768803358078003
Validation loss: 2.1981156154345443

Epoch: 173| Step: 0
Training loss: 1.8526954650878906
Validation loss: 2.207385447717482

Epoch: 5| Step: 1
Training loss: 2.3408217430114746
Validation loss: 2.1971497971524476

Epoch: 5| Step: 2
Training loss: 2.5656771659851074
Validation loss: 2.218589016186294

Epoch: 5| Step: 3
Training loss: 2.158343553543091
Validation loss: 2.2137312581462245

Epoch: 5| Step: 4
Training loss: 2.3983054161071777
Validation loss: 2.21246446845352

Epoch: 5| Step: 5
Training loss: 1.8946422338485718
Validation loss: 2.2048807015983005

Epoch: 5| Step: 6
Training loss: 2.2113850116729736
Validation loss: 2.194044614350924

Epoch: 5| Step: 7
Training loss: 2.1492438316345215
Validation loss: 2.1964739407262495

Epoch: 5| Step: 8
Training loss: 1.8068320751190186
Validation loss: 2.207442509230747

Epoch: 5| Step: 9
Training loss: 2.8931453227996826
Validation loss: 2.201401120872908

Epoch: 5| Step: 10
Training loss: 2.3200457096099854
Validation loss: 2.1851786285318355

Epoch: 174| Step: 0
Training loss: 2.3439114093780518
Validation loss: 2.2137566715158443

Epoch: 5| Step: 1
Training loss: 2.013482093811035
Validation loss: 2.253093329809045

Epoch: 5| Step: 2
Training loss: 2.2970974445343018
Validation loss: 2.2813919769820346

Epoch: 5| Step: 3
Training loss: 2.16929292678833
Validation loss: 2.2744308274279357

Epoch: 5| Step: 4
Training loss: 1.6418002843856812
Validation loss: 2.286099306998714

Epoch: 5| Step: 5
Training loss: 2.8690590858459473
Validation loss: 2.2194973627726235

Epoch: 5| Step: 6
Training loss: 2.130566358566284
Validation loss: 2.1904948475540325

Epoch: 5| Step: 7
Training loss: 1.979517936706543
Validation loss: 2.1772573532596713

Epoch: 5| Step: 8
Training loss: 2.3846774101257324
Validation loss: 2.1643786955905218

Epoch: 5| Step: 9
Training loss: 2.558872938156128
Validation loss: 2.15150700846026

Epoch: 5| Step: 10
Training loss: 2.277498960494995
Validation loss: 2.1451248199709

Epoch: 175| Step: 0
Training loss: 1.9609918594360352
Validation loss: 2.1338920695807344

Epoch: 5| Step: 1
Training loss: 2.0025875568389893
Validation loss: 2.1216927600163284

Epoch: 5| Step: 2
Training loss: 2.3556456565856934
Validation loss: 2.124479273314117

Epoch: 5| Step: 3
Training loss: 2.658545970916748
Validation loss: 2.125215402213476

Epoch: 5| Step: 4
Training loss: 2.5581119060516357
Validation loss: 2.113813123395366

Epoch: 5| Step: 5
Training loss: 2.432142972946167
Validation loss: 2.1020256473172094

Epoch: 5| Step: 6
Training loss: 1.720085859298706
Validation loss: 2.100770834953554

Epoch: 5| Step: 7
Training loss: 2.4556188583374023
Validation loss: 2.10083322499388

Epoch: 5| Step: 8
Training loss: 2.7002456188201904
Validation loss: 2.103711046198363

Epoch: 5| Step: 9
Training loss: 2.1824588775634766
Validation loss: 2.135280539912562

Epoch: 5| Step: 10
Training loss: 1.5811022520065308
Validation loss: 2.183879183184716

Epoch: 176| Step: 0
Training loss: 2.1413559913635254
Validation loss: 2.2337960043261127

Epoch: 5| Step: 1
Training loss: 2.5968575477600098
Validation loss: 2.2420502119166876

Epoch: 5| Step: 2
Training loss: 2.0717079639434814
Validation loss: 2.2294895161864576

Epoch: 5| Step: 3
Training loss: 2.154923677444458
Validation loss: 2.180667765678898

Epoch: 5| Step: 4
Training loss: 2.4228625297546387
Validation loss: 2.155533177878267

Epoch: 5| Step: 5
Training loss: 2.405477285385132
Validation loss: 2.133225985752639

Epoch: 5| Step: 6
Training loss: 2.565591335296631
Validation loss: 2.1292778317646315

Epoch: 5| Step: 7
Training loss: 2.557033061981201
Validation loss: 2.133093362213463

Epoch: 5| Step: 8
Training loss: 2.1399970054626465
Validation loss: 2.13087736662998

Epoch: 5| Step: 9
Training loss: 1.6934913396835327
Validation loss: 2.151269207718552

Epoch: 5| Step: 10
Training loss: 1.8299790620803833
Validation loss: 2.152135525980303

Epoch: 177| Step: 0
Training loss: 2.3458104133605957
Validation loss: 2.1597625414530435

Epoch: 5| Step: 1
Training loss: 2.265617609024048
Validation loss: 2.1569824270022813

Epoch: 5| Step: 2
Training loss: 2.4609546661376953
Validation loss: 2.170389062614851

Epoch: 5| Step: 3
Training loss: 1.5660995244979858
Validation loss: 2.180843150743874

Epoch: 5| Step: 4
Training loss: 2.615421772003174
Validation loss: 2.1886654925602738

Epoch: 5| Step: 5
Training loss: 2.8240604400634766
Validation loss: 2.1624858943364953

Epoch: 5| Step: 6
Training loss: 2.9918148517608643
Validation loss: 2.145426737364902

Epoch: 5| Step: 7
Training loss: 1.83309805393219
Validation loss: 2.124785138714698

Epoch: 5| Step: 8
Training loss: 1.5399497747421265
Validation loss: 2.127750245473718

Epoch: 5| Step: 9
Training loss: 1.610632300376892
Validation loss: 2.1394593715667725

Epoch: 5| Step: 10
Training loss: 2.1354825496673584
Validation loss: 2.1551886117586525

Epoch: 178| Step: 0
Training loss: 2.344128131866455
Validation loss: 2.167399965306764

Epoch: 5| Step: 1
Training loss: 2.626469135284424
Validation loss: 2.1996775237462853

Epoch: 5| Step: 2
Training loss: 2.0676090717315674
Validation loss: 2.187872217547509

Epoch: 5| Step: 3
Training loss: 1.9004876613616943
Validation loss: 2.1715758846652125

Epoch: 5| Step: 4
Training loss: 2.211282730102539
Validation loss: 2.170008050498142

Epoch: 5| Step: 5
Training loss: 1.8471524715423584
Validation loss: 2.1754451323581

Epoch: 5| Step: 6
Training loss: 2.046882152557373
Validation loss: 2.2054957715413903

Epoch: 5| Step: 7
Training loss: 2.55953311920166
Validation loss: 2.2089998798985637

Epoch: 5| Step: 8
Training loss: 1.5251314640045166
Validation loss: 2.2021852283067602

Epoch: 5| Step: 9
Training loss: 2.513298511505127
Validation loss: 2.1779250098812963

Epoch: 5| Step: 10
Training loss: 2.6048409938812256
Validation loss: 2.169739987260552

Epoch: 179| Step: 0
Training loss: 2.118877410888672
Validation loss: 2.157518494513727

Epoch: 5| Step: 1
Training loss: 2.6021230220794678
Validation loss: 2.1662821679986934

Epoch: 5| Step: 2
Training loss: 2.741734027862549
Validation loss: 2.1517954487954416

Epoch: 5| Step: 3
Training loss: 2.1897237300872803
Validation loss: 2.1713958350561

Epoch: 5| Step: 4
Training loss: 2.16129207611084
Validation loss: 2.181418365047824

Epoch: 5| Step: 5
Training loss: 2.9275271892547607
Validation loss: 2.1709766887849375

Epoch: 5| Step: 6
Training loss: 1.7372525930404663
Validation loss: 2.1736670027496996

Epoch: 5| Step: 7
Training loss: 1.698075532913208
Validation loss: 2.1886096359581075

Epoch: 5| Step: 8
Training loss: 1.4917981624603271
Validation loss: 2.1901376965225383

Epoch: 5| Step: 9
Training loss: 2.313361406326294
Validation loss: 2.222745439057709

Epoch: 5| Step: 10
Training loss: 2.0510640144348145
Validation loss: 2.2246832488685526

Epoch: 180| Step: 0
Training loss: 2.411506175994873
Validation loss: 2.248866317092731

Epoch: 5| Step: 1
Training loss: 2.049623489379883
Validation loss: 2.2384930067164923

Epoch: 5| Step: 2
Training loss: 1.6093889474868774
Validation loss: 2.2182305987163256

Epoch: 5| Step: 3
Training loss: 2.341700792312622
Validation loss: 2.2372458365655716

Epoch: 5| Step: 4
Training loss: 2.2276418209075928
Validation loss: 2.189609166114561

Epoch: 5| Step: 5
Training loss: 2.107001304626465
Validation loss: 2.189163120844031

Epoch: 5| Step: 6
Training loss: 2.1699461936950684
Validation loss: 2.1715119141404347

Epoch: 5| Step: 7
Training loss: 2.2495105266571045
Validation loss: 2.1598736675836707

Epoch: 5| Step: 8
Training loss: 1.4467483758926392
Validation loss: 2.1527237994696504

Epoch: 5| Step: 9
Training loss: 2.832407236099243
Validation loss: 2.141938299261114

Epoch: 5| Step: 10
Training loss: 2.6345157623291016
Validation loss: 2.1411416581881944

Epoch: 181| Step: 0
Training loss: 1.9133403301239014
Validation loss: 2.1407731656105287

Epoch: 5| Step: 1
Training loss: 1.5943505764007568
Validation loss: 2.154394534326369

Epoch: 5| Step: 2
Training loss: 1.9690685272216797
Validation loss: 2.17436537947706

Epoch: 5| Step: 3
Training loss: 3.1339364051818848
Validation loss: 2.203975933854298

Epoch: 5| Step: 4
Training loss: 1.7783094644546509
Validation loss: 2.2518824864459295

Epoch: 5| Step: 5
Training loss: 1.9105799198150635
Validation loss: 2.3023106205847954

Epoch: 5| Step: 6
Training loss: 1.5816397666931152
Validation loss: 2.2811159062129196

Epoch: 5| Step: 7
Training loss: 2.666999101638794
Validation loss: 2.270688082582207

Epoch: 5| Step: 8
Training loss: 2.501652479171753
Validation loss: 2.2283891067709973

Epoch: 5| Step: 9
Training loss: 2.863943576812744
Validation loss: 2.1767561435699463

Epoch: 5| Step: 10
Training loss: 2.3550875186920166
Validation loss: 2.1520176984930552

Epoch: 182| Step: 0
Training loss: 1.541678547859192
Validation loss: 2.1555248409189205

Epoch: 5| Step: 1
Training loss: 1.9694395065307617
Validation loss: 2.15370855023784

Epoch: 5| Step: 2
Training loss: 2.2790322303771973
Validation loss: 2.1601493666248937

Epoch: 5| Step: 3
Training loss: 2.567429304122925
Validation loss: 2.158238455813418

Epoch: 5| Step: 4
Training loss: 2.774721145629883
Validation loss: 2.1819667123979136

Epoch: 5| Step: 5
Training loss: 2.0170819759368896
Validation loss: 2.193880424704603

Epoch: 5| Step: 6
Training loss: 1.9892761707305908
Validation loss: 2.228149587108243

Epoch: 5| Step: 7
Training loss: 1.8122144937515259
Validation loss: 2.2588040187794673

Epoch: 5| Step: 8
Training loss: 2.6710572242736816
Validation loss: 2.224078537315451

Epoch: 5| Step: 9
Training loss: 1.995994210243225
Validation loss: 2.2015471766071935

Epoch: 5| Step: 10
Training loss: 2.377554178237915
Validation loss: 2.173445486253308

Epoch: 183| Step: 0
Training loss: 1.9670658111572266
Validation loss: 2.1409502388328634

Epoch: 5| Step: 1
Training loss: 2.1868999004364014
Validation loss: 2.1361410130736647

Epoch: 5| Step: 2
Training loss: 2.509831190109253
Validation loss: 2.1280231809103363

Epoch: 5| Step: 3
Training loss: 2.2586829662323
Validation loss: 2.121867423416466

Epoch: 5| Step: 4
Training loss: 1.7443262338638306
Validation loss: 2.1339894443429928

Epoch: 5| Step: 5
Training loss: 2.4940598011016846
Validation loss: 2.122616598683019

Epoch: 5| Step: 6
Training loss: 2.3399784564971924
Validation loss: 2.1309603606500933

Epoch: 5| Step: 7
Training loss: 2.3856308460235596
Validation loss: 2.126208936014483

Epoch: 5| Step: 8
Training loss: 1.9314641952514648
Validation loss: 2.1374171216000795

Epoch: 5| Step: 9
Training loss: 2.0536742210388184
Validation loss: 2.1542555311674714

Epoch: 5| Step: 10
Training loss: 1.9097083806991577
Validation loss: 2.163752737865653

Epoch: 184| Step: 0
Training loss: 1.914284348487854
Validation loss: 2.152512458062941

Epoch: 5| Step: 1
Training loss: 2.024298906326294
Validation loss: 2.13806317698571

Epoch: 5| Step: 2
Training loss: 1.9818843603134155
Validation loss: 2.13492392211832

Epoch: 5| Step: 3
Training loss: 2.7491579055786133
Validation loss: 2.1386344381558

Epoch: 5| Step: 4
Training loss: 1.8402760028839111
Validation loss: 2.1321711014675837

Epoch: 5| Step: 5
Training loss: 2.4848785400390625
Validation loss: 2.1551266203644457

Epoch: 5| Step: 6
Training loss: 2.563654661178589
Validation loss: 2.1527301201256375

Epoch: 5| Step: 7
Training loss: 1.8212382793426514
Validation loss: 2.1433829005046556

Epoch: 5| Step: 8
Training loss: 2.115910291671753
Validation loss: 2.152788982596449

Epoch: 5| Step: 9
Training loss: 1.9544681310653687
Validation loss: 2.1742591011908745

Epoch: 5| Step: 10
Training loss: 2.165437698364258
Validation loss: 2.204374031354022

Epoch: 185| Step: 0
Training loss: 1.8516117334365845
Validation loss: 2.236294005506782

Epoch: 5| Step: 1
Training loss: 2.8434207439422607
Validation loss: 2.215745838739539

Epoch: 5| Step: 2
Training loss: 1.7751712799072266
Validation loss: 2.1981677086122575

Epoch: 5| Step: 3
Training loss: 1.52629554271698
Validation loss: 2.1756520860938617

Epoch: 5| Step: 4
Training loss: 2.1666533946990967
Validation loss: 2.1458083878281298

Epoch: 5| Step: 5
Training loss: 2.315232753753662
Validation loss: 2.113977978306432

Epoch: 5| Step: 6
Training loss: 1.8245041370391846
Validation loss: 2.1254974719016784

Epoch: 5| Step: 7
Training loss: 2.711515426635742
Validation loss: 2.1288490679956253

Epoch: 5| Step: 8
Training loss: 1.9077131748199463
Validation loss: 2.143509111096782

Epoch: 5| Step: 9
Training loss: 2.7573277950286865
Validation loss: 2.156229595984182

Epoch: 5| Step: 10
Training loss: 2.331873655319214
Validation loss: 2.1618348962517193

Epoch: 186| Step: 0
Training loss: 2.1967170238494873
Validation loss: 2.194834340003229

Epoch: 5| Step: 1
Training loss: 1.9921373128890991
Validation loss: 2.202666715909076

Epoch: 5| Step: 2
Training loss: 2.608610153198242
Validation loss: 2.216750478231779

Epoch: 5| Step: 3
Training loss: 2.105201482772827
Validation loss: 2.2561365250618226

Epoch: 5| Step: 4
Training loss: 1.9157981872558594
Validation loss: 2.2726458951991093

Epoch: 5| Step: 5
Training loss: 1.9125455617904663
Validation loss: 2.2861117727013043

Epoch: 5| Step: 6
Training loss: 2.537330150604248
Validation loss: 2.252397378285726

Epoch: 5| Step: 7
Training loss: 1.283968210220337
Validation loss: 2.2025282306055867

Epoch: 5| Step: 8
Training loss: 2.8862013816833496
Validation loss: 2.173959178309287

Epoch: 5| Step: 9
Training loss: 1.983353853225708
Validation loss: 2.145227591196696

Epoch: 5| Step: 10
Training loss: 2.124049663543701
Validation loss: 2.1232607621018604

Epoch: 187| Step: 0
Training loss: 1.9856294393539429
Validation loss: 2.1136944242703017

Epoch: 5| Step: 1
Training loss: 1.8110382556915283
Validation loss: 2.1052211740965485

Epoch: 5| Step: 2
Training loss: 2.1789348125457764
Validation loss: 2.113346792036487

Epoch: 5| Step: 3
Training loss: 1.941266655921936
Validation loss: 2.1238729018037037

Epoch: 5| Step: 4
Training loss: 2.530667304992676
Validation loss: 2.122344755357312

Epoch: 5| Step: 5
Training loss: 1.6335150003433228
Validation loss: 2.1180563255022933

Epoch: 5| Step: 6
Training loss: 2.133850336074829
Validation loss: 2.138780014489287

Epoch: 5| Step: 7
Training loss: 2.487513303756714
Validation loss: 2.145749666357553

Epoch: 5| Step: 8
Training loss: 2.4007630348205566
Validation loss: 2.156217331527382

Epoch: 5| Step: 9
Training loss: 2.207101583480835
Validation loss: 2.1986672006627566

Epoch: 5| Step: 10
Training loss: 2.131978988647461
Validation loss: 2.2074973096129713

Epoch: 188| Step: 0
Training loss: 2.228048801422119
Validation loss: 2.2311069875635128

Epoch: 5| Step: 1
Training loss: 2.576421022415161
Validation loss: 2.243085333096084

Epoch: 5| Step: 2
Training loss: 2.6558837890625
Validation loss: 2.192225048618932

Epoch: 5| Step: 3
Training loss: 2.038135528564453
Validation loss: 2.175408640215474

Epoch: 5| Step: 4
Training loss: 1.8747704029083252
Validation loss: 2.1395686570034234

Epoch: 5| Step: 5
Training loss: 1.2514915466308594
Validation loss: 2.1148585606646795

Epoch: 5| Step: 6
Training loss: 2.6004061698913574
Validation loss: 2.1085477708488383

Epoch: 5| Step: 7
Training loss: 1.7913258075714111
Validation loss: 2.1227037406736806

Epoch: 5| Step: 8
Training loss: 2.7270870208740234
Validation loss: 2.142856133881436

Epoch: 5| Step: 9
Training loss: 1.8610597848892212
Validation loss: 2.1572468793520363

Epoch: 5| Step: 10
Training loss: 2.1640639305114746
Validation loss: 2.155000591790804

Epoch: 189| Step: 0
Training loss: 2.7003772258758545
Validation loss: 2.1700968127096854

Epoch: 5| Step: 1
Training loss: 2.100098133087158
Validation loss: 2.1371405714301654

Epoch: 5| Step: 2
Training loss: 2.176098346710205
Validation loss: 2.1603733493435766

Epoch: 5| Step: 3
Training loss: 2.23949933052063
Validation loss: 2.167100647444366

Epoch: 5| Step: 4
Training loss: 1.6604359149932861
Validation loss: 2.170510474071708

Epoch: 5| Step: 5
Training loss: 1.856278419494629
Validation loss: 2.2259706579228884

Epoch: 5| Step: 6
Training loss: 2.088566541671753
Validation loss: 2.2348850260498705

Epoch: 5| Step: 7
Training loss: 2.2325239181518555
Validation loss: 2.2089902854734853

Epoch: 5| Step: 8
Training loss: 2.662262439727783
Validation loss: 2.1779613879419144

Epoch: 5| Step: 9
Training loss: 1.5847752094268799
Validation loss: 2.151000092106481

Epoch: 5| Step: 10
Training loss: 2.121365785598755
Validation loss: 2.120352755310715

Epoch: 190| Step: 0
Training loss: 2.261218547821045
Validation loss: 2.108124788089465

Epoch: 5| Step: 1
Training loss: 1.9930146932601929
Validation loss: 2.118340862694607

Epoch: 5| Step: 2
Training loss: 2.371408700942993
Validation loss: 2.114201652106418

Epoch: 5| Step: 3
Training loss: 1.9655663967132568
Validation loss: 2.117113208258024

Epoch: 5| Step: 4
Training loss: 1.7051509618759155
Validation loss: 2.115059191180814

Epoch: 5| Step: 5
Training loss: 2.4264755249023438
Validation loss: 2.117992284477398

Epoch: 5| Step: 6
Training loss: 2.247025728225708
Validation loss: 2.1640407270000828

Epoch: 5| Step: 7
Training loss: 1.9083220958709717
Validation loss: 2.2408537762139433

Epoch: 5| Step: 8
Training loss: 2.0070996284484863
Validation loss: 2.290873994109451

Epoch: 5| Step: 9
Training loss: 2.385528802871704
Validation loss: 2.3367245274205364

Epoch: 5| Step: 10
Training loss: 2.3392932415008545
Validation loss: 2.3664617076996834

Epoch: 191| Step: 0
Training loss: 2.1823320388793945
Validation loss: 2.3355480624783422

Epoch: 5| Step: 1
Training loss: 2.049170970916748
Validation loss: 2.2675151671132734

Epoch: 5| Step: 2
Training loss: 2.2779059410095215
Validation loss: 2.2151366408153246

Epoch: 5| Step: 3
Training loss: 2.0950698852539062
Validation loss: 2.1707006705704557

Epoch: 5| Step: 4
Training loss: 1.9959983825683594
Validation loss: 2.1793266957806003

Epoch: 5| Step: 5
Training loss: 1.8281666040420532
Validation loss: 2.1742979352192213

Epoch: 5| Step: 6
Training loss: 1.9221973419189453
Validation loss: 2.1554339419129076

Epoch: 5| Step: 7
Training loss: 1.7029008865356445
Validation loss: 2.140556013712319

Epoch: 5| Step: 8
Training loss: 3.0756702423095703
Validation loss: 2.1502623788772093

Epoch: 5| Step: 9
Training loss: 2.1830809116363525
Validation loss: 2.156082982658058

Epoch: 5| Step: 10
Training loss: 2.379812002182007
Validation loss: 2.156665853274766

Epoch: 192| Step: 0
Training loss: 2.3654778003692627
Validation loss: 2.1547170903093074

Epoch: 5| Step: 1
Training loss: 2.5653514862060547
Validation loss: 2.1612171178222983

Epoch: 5| Step: 2
Training loss: 1.2578771114349365
Validation loss: 2.154045602326752

Epoch: 5| Step: 3
Training loss: 2.168185234069824
Validation loss: 2.157825877589564

Epoch: 5| Step: 4
Training loss: 1.8449325561523438
Validation loss: 2.1682449540784283

Epoch: 5| Step: 5
Training loss: 2.2495341300964355
Validation loss: 2.176326081316958

Epoch: 5| Step: 6
Training loss: 2.1691133975982666
Validation loss: 2.196901862339307

Epoch: 5| Step: 7
Training loss: 2.5619266033172607
Validation loss: 2.1934357458545315

Epoch: 5| Step: 8
Training loss: 2.2615628242492676
Validation loss: 2.176340313367946

Epoch: 5| Step: 9
Training loss: 2.1605257987976074
Validation loss: 2.1617444971556306

Epoch: 5| Step: 10
Training loss: 1.4932363033294678
Validation loss: 2.134707934112959

Epoch: 193| Step: 0
Training loss: 1.9865859746932983
Validation loss: 2.1189136594854374

Epoch: 5| Step: 1
Training loss: 1.5976355075836182
Validation loss: 2.1210619608561196

Epoch: 5| Step: 2
Training loss: 1.894409418106079
Validation loss: 2.1247591126349663

Epoch: 5| Step: 3
Training loss: 2.265415668487549
Validation loss: 2.110629099671559

Epoch: 5| Step: 4
Training loss: 1.4065377712249756
Validation loss: 2.108675520907166

Epoch: 5| Step: 5
Training loss: 2.2194623947143555
Validation loss: 2.1386608513452674

Epoch: 5| Step: 6
Training loss: 2.560514211654663
Validation loss: 2.1622047373043594

Epoch: 5| Step: 7
Training loss: 2.36403751373291
Validation loss: 2.1932093315227057

Epoch: 5| Step: 8
Training loss: 2.3178064823150635
Validation loss: 2.279228723177346

Epoch: 5| Step: 9
Training loss: 2.65393328666687
Validation loss: 2.2261879597940752

Epoch: 5| Step: 10
Training loss: 1.8598744869232178
Validation loss: 2.1695133332283265

Epoch: 194| Step: 0
Training loss: 1.90716552734375
Validation loss: 2.145854519259545

Epoch: 5| Step: 1
Training loss: 2.424558639526367
Validation loss: 2.1274630305587605

Epoch: 5| Step: 2
Training loss: 1.7023588418960571
Validation loss: 2.132299279653898

Epoch: 5| Step: 3
Training loss: 1.5691992044448853
Validation loss: 2.1312751462382655

Epoch: 5| Step: 4
Training loss: 2.02097749710083
Validation loss: 2.115385683633948

Epoch: 5| Step: 5
Training loss: 1.8798173666000366
Validation loss: 2.0959205832532657

Epoch: 5| Step: 6
Training loss: 2.3604772090911865
Validation loss: 2.105561384590723

Epoch: 5| Step: 7
Training loss: 2.3931033611297607
Validation loss: 2.0936488400223436

Epoch: 5| Step: 8
Training loss: 2.3718650341033936
Validation loss: 2.115821538432952

Epoch: 5| Step: 9
Training loss: 2.512434482574463
Validation loss: 2.126569764588469

Epoch: 5| Step: 10
Training loss: 2.0065486431121826
Validation loss: 2.1431363756938646

Epoch: 195| Step: 0
Training loss: 2.2741928100585938
Validation loss: 2.152548607959542

Epoch: 5| Step: 1
Training loss: 2.6183547973632812
Validation loss: 2.132991196006857

Epoch: 5| Step: 2
Training loss: 2.9885098934173584
Validation loss: 2.1333672359425533

Epoch: 5| Step: 3
Training loss: 1.7893445491790771
Validation loss: 2.153746904865388

Epoch: 5| Step: 4
Training loss: 1.4890449047088623
Validation loss: 2.1335768340736307

Epoch: 5| Step: 5
Training loss: 1.9675064086914062
Validation loss: 2.1208789912603234

Epoch: 5| Step: 6
Training loss: 1.936682105064392
Validation loss: 2.1119643180601058

Epoch: 5| Step: 7
Training loss: 1.921655297279358
Validation loss: 2.128005975036211

Epoch: 5| Step: 8
Training loss: 1.7771505117416382
Validation loss: 2.1239999827518257

Epoch: 5| Step: 9
Training loss: 2.3504114151000977
Validation loss: 2.1146991919445735

Epoch: 5| Step: 10
Training loss: 1.888049840927124
Validation loss: 2.120084024244739

Epoch: 196| Step: 0
Training loss: 2.3247838020324707
Validation loss: 2.1471620580201507

Epoch: 5| Step: 1
Training loss: 1.8053785562515259
Validation loss: 2.187749921634633

Epoch: 5| Step: 2
Training loss: 1.6461658477783203
Validation loss: 2.2140274483670472

Epoch: 5| Step: 3
Training loss: 2.266899347305298
Validation loss: 2.2423104034957064

Epoch: 5| Step: 4
Training loss: 1.905752420425415
Validation loss: 2.2714418288200133

Epoch: 5| Step: 5
Training loss: 2.30374813079834
Validation loss: 2.2513167550486903

Epoch: 5| Step: 6
Training loss: 2.2512669563293457
Validation loss: 2.2236487198901433

Epoch: 5| Step: 7
Training loss: 2.1902871131896973
Validation loss: 2.158782066837434

Epoch: 5| Step: 8
Training loss: 2.004702091217041
Validation loss: 2.121816696659211

Epoch: 5| Step: 9
Training loss: 1.9710029363632202
Validation loss: 2.0849375032609507

Epoch: 5| Step: 10
Training loss: 2.206056594848633
Validation loss: 2.076594706504576

Epoch: 197| Step: 0
Training loss: 2.1083741188049316
Validation loss: 2.0960900040083033

Epoch: 5| Step: 1
Training loss: 3.1804115772247314
Validation loss: 2.110637075157576

Epoch: 5| Step: 2
Training loss: 2.2264885902404785
Validation loss: 2.130257852615849

Epoch: 5| Step: 3
Training loss: 1.4736154079437256
Validation loss: 2.1217010226300967

Epoch: 5| Step: 4
Training loss: 2.9019505977630615
Validation loss: 2.1110480575151342

Epoch: 5| Step: 5
Training loss: 1.8679616451263428
Validation loss: 2.1165446632651874

Epoch: 5| Step: 6
Training loss: 1.3365981578826904
Validation loss: 2.1336996273327897

Epoch: 5| Step: 7
Training loss: 1.9193681478500366
Validation loss: 2.2027160095912155

Epoch: 5| Step: 8
Training loss: 2.257113456726074
Validation loss: 2.2856488766208773

Epoch: 5| Step: 9
Training loss: 1.9945943355560303
Validation loss: 2.281654821929111

Epoch: 5| Step: 10
Training loss: 2.040684223175049
Validation loss: 2.2016797296462522

Epoch: 198| Step: 0
Training loss: 1.6249014139175415
Validation loss: 2.1661719660605154

Epoch: 5| Step: 1
Training loss: 2.6014275550842285
Validation loss: 2.1136820341951106

Epoch: 5| Step: 2
Training loss: 1.821470856666565
Validation loss: 2.09996041687586

Epoch: 5| Step: 3
Training loss: 2.3137834072113037
Validation loss: 2.080531615082936

Epoch: 5| Step: 4
Training loss: 2.7288174629211426
Validation loss: 2.087353684568918

Epoch: 5| Step: 5
Training loss: 1.9086660146713257
Validation loss: 2.0755190746758574

Epoch: 5| Step: 6
Training loss: 1.7668488025665283
Validation loss: 2.084991665296657

Epoch: 5| Step: 7
Training loss: 2.2128617763519287
Validation loss: 2.096576665037422

Epoch: 5| Step: 8
Training loss: 1.7441221475601196
Validation loss: 2.1068249825508363

Epoch: 5| Step: 9
Training loss: 2.0444252490997314
Validation loss: 2.108041686396445

Epoch: 5| Step: 10
Training loss: 1.9848322868347168
Validation loss: 2.1093512119785434

Epoch: 199| Step: 0
Training loss: 1.6612437963485718
Validation loss: 2.1487832274488223

Epoch: 5| Step: 1
Training loss: 2.4048397541046143
Validation loss: 2.186219246156754

Epoch: 5| Step: 2
Training loss: 2.3524136543273926
Validation loss: 2.189219419674207

Epoch: 5| Step: 3
Training loss: 2.583568572998047
Validation loss: 2.2327933849826938

Epoch: 5| Step: 4
Training loss: 1.762084722518921
Validation loss: 2.288794320116761

Epoch: 5| Step: 5
Training loss: 2.5818123817443848
Validation loss: 2.300210047793645

Epoch: 5| Step: 6
Training loss: 1.6430317163467407
Validation loss: 2.247627042954968

Epoch: 5| Step: 7
Training loss: 1.3133876323699951
Validation loss: 2.155702572996898

Epoch: 5| Step: 8
Training loss: 2.5544357299804688
Validation loss: 2.1030815468039563

Epoch: 5| Step: 9
Training loss: 1.9236280918121338
Validation loss: 2.087652962694886

Epoch: 5| Step: 10
Training loss: 2.1213419437408447
Validation loss: 2.0896361309994935

Epoch: 200| Step: 0
Training loss: 2.39469575881958
Validation loss: 2.109913813170566

Epoch: 5| Step: 1
Training loss: 2.3525149822235107
Validation loss: 2.118808182336951

Epoch: 5| Step: 2
Training loss: 2.0283024311065674
Validation loss: 2.1140727368734216

Epoch: 5| Step: 3
Training loss: 1.8730236291885376
Validation loss: 2.124757561632382

Epoch: 5| Step: 4
Training loss: 1.6156387329101562
Validation loss: 2.110546596588627

Epoch: 5| Step: 5
Training loss: 2.1243655681610107
Validation loss: 2.131735360750588

Epoch: 5| Step: 6
Training loss: 2.029127359390259
Validation loss: 2.1537512874090545

Epoch: 5| Step: 7
Training loss: 1.9642471075057983
Validation loss: 2.186310483563331

Epoch: 5| Step: 8
Training loss: 1.8821884393692017
Validation loss: 2.2095372394848893

Epoch: 5| Step: 9
Training loss: 2.1389479637145996
Validation loss: 2.207057276079732

Epoch: 5| Step: 10
Training loss: 2.195427417755127
Validation loss: 2.2332827544981435

Epoch: 201| Step: 0
Training loss: 2.231220245361328
Validation loss: 2.259573817253113

Epoch: 5| Step: 1
Training loss: 1.9724773168563843
Validation loss: 2.2596015212356404

Epoch: 5| Step: 2
Training loss: 1.9206123352050781
Validation loss: 2.2929109040127007

Epoch: 5| Step: 3
Training loss: 2.369344711303711
Validation loss: 2.2368060414509108

Epoch: 5| Step: 4
Training loss: 2.677011251449585
Validation loss: 2.2186240560264996

Epoch: 5| Step: 5
Training loss: 2.575282573699951
Validation loss: 2.198387021659523

Epoch: 5| Step: 6
Training loss: 1.8200222253799438
Validation loss: 2.129859285969888

Epoch: 5| Step: 7
Training loss: 1.8442277908325195
Validation loss: 2.095738080240065

Epoch: 5| Step: 8
Training loss: 1.481534719467163
Validation loss: 2.0888248079566547

Epoch: 5| Step: 9
Training loss: 1.5582163333892822
Validation loss: 2.0814510904332644

Epoch: 5| Step: 10
Training loss: 2.2338855266571045
Validation loss: 2.0896511821336645

Epoch: 202| Step: 0
Training loss: 2.171637773513794
Validation loss: 2.08760489443297

Epoch: 5| Step: 1
Training loss: 2.374476909637451
Validation loss: 2.0634586939247708

Epoch: 5| Step: 2
Training loss: 2.3505096435546875
Validation loss: 2.0623254852910198

Epoch: 5| Step: 3
Training loss: 2.209836483001709
Validation loss: 2.0651193024009786

Epoch: 5| Step: 4
Training loss: 2.2831578254699707
Validation loss: 2.0643509844298005

Epoch: 5| Step: 5
Training loss: 2.1236064434051514
Validation loss: 2.082251784622028

Epoch: 5| Step: 6
Training loss: 1.7101421356201172
Validation loss: 2.0996841076881654

Epoch: 5| Step: 7
Training loss: 1.9206756353378296
Validation loss: 2.1208922145187215

Epoch: 5| Step: 8
Training loss: 1.7484031915664673
Validation loss: 2.1446230949894076

Epoch: 5| Step: 9
Training loss: 1.9306821823120117
Validation loss: 2.1489384148710515

Epoch: 5| Step: 10
Training loss: 1.7963221073150635
Validation loss: 2.1814080271669614

Epoch: 203| Step: 0
Training loss: 2.22529935836792
Validation loss: 2.2184814509525093

Epoch: 5| Step: 1
Training loss: 2.4414680004119873
Validation loss: 2.2265617565442155

Epoch: 5| Step: 2
Training loss: 1.7343454360961914
Validation loss: 2.2052357927445443

Epoch: 5| Step: 3
Training loss: 1.9795891046524048
Validation loss: 2.1772236183125484

Epoch: 5| Step: 4
Training loss: 2.0133323669433594
Validation loss: 2.147641151182113

Epoch: 5| Step: 5
Training loss: 1.8429133892059326
Validation loss: 2.113104571578323

Epoch: 5| Step: 6
Training loss: 1.5109293460845947
Validation loss: 2.091414982272733

Epoch: 5| Step: 7
Training loss: 1.8741271495819092
Validation loss: 2.103936661956131

Epoch: 5| Step: 8
Training loss: 2.356957197189331
Validation loss: 2.0849879723723217

Epoch: 5| Step: 9
Training loss: 1.533246636390686
Validation loss: 2.0945911612561954

Epoch: 5| Step: 10
Training loss: 3.1648383140563965
Validation loss: 2.076750583546136

Epoch: 204| Step: 0
Training loss: 2.1958465576171875
Validation loss: 2.0695380036548903

Epoch: 5| Step: 1
Training loss: 2.078495740890503
Validation loss: 2.0712720501807427

Epoch: 5| Step: 2
Training loss: 2.400848388671875
Validation loss: 2.0932078182056384

Epoch: 5| Step: 3
Training loss: 2.39947772026062
Validation loss: 2.0835124049135434

Epoch: 5| Step: 4
Training loss: 1.8093750476837158
Validation loss: 2.096288682312094

Epoch: 5| Step: 5
Training loss: 1.7031011581420898
Validation loss: 2.1358499655159573

Epoch: 5| Step: 6
Training loss: 2.009857654571533
Validation loss: 2.146101810598886

Epoch: 5| Step: 7
Training loss: 1.9229522943496704
Validation loss: 2.1723373679704565

Epoch: 5| Step: 8
Training loss: 1.601003646850586
Validation loss: 2.1749323234763196

Epoch: 5| Step: 9
Training loss: 2.1524240970611572
Validation loss: 2.1802426076704458

Epoch: 5| Step: 10
Training loss: 1.9709795713424683
Validation loss: 2.2184885266006633

Epoch: 205| Step: 0
Training loss: 1.987622618675232
Validation loss: 2.194533117355839

Epoch: 5| Step: 1
Training loss: 2.2467200756073
Validation loss: 2.1991582455173617

Epoch: 5| Step: 2
Training loss: 2.249540328979492
Validation loss: 2.2016398547798075

Epoch: 5| Step: 3
Training loss: 2.171635150909424
Validation loss: 2.1964628004258677

Epoch: 5| Step: 4
Training loss: 1.5746105909347534
Validation loss: 2.1468678456480785

Epoch: 5| Step: 5
Training loss: 1.9711151123046875
Validation loss: 2.144790550713898

Epoch: 5| Step: 6
Training loss: 2.132333993911743
Validation loss: 2.1276859045028687

Epoch: 5| Step: 7
Training loss: 2.078634262084961
Validation loss: 2.1040531666048112

Epoch: 5| Step: 8
Training loss: 1.878371000289917
Validation loss: 2.1318601485221618

Epoch: 5| Step: 9
Training loss: 2.3674979209899902
Validation loss: 2.154425485159761

Epoch: 5| Step: 10
Training loss: 1.888623595237732
Validation loss: 2.1770549410132953

Epoch: 206| Step: 0
Training loss: 1.5734202861785889
Validation loss: 2.2026065626452045

Epoch: 5| Step: 1
Training loss: 1.8659073114395142
Validation loss: 2.266986717459976

Epoch: 5| Step: 2
Training loss: 1.9602006673812866
Validation loss: 2.2967952400125484

Epoch: 5| Step: 3
Training loss: 2.717744827270508
Validation loss: 2.29073953500358

Epoch: 5| Step: 4
Training loss: 1.4579246044158936
Validation loss: 2.2199902970303773

Epoch: 5| Step: 5
Training loss: 2.3613336086273193
Validation loss: 2.1231354205839095

Epoch: 5| Step: 6
Training loss: 1.5696327686309814
Validation loss: 2.072516634900083

Epoch: 5| Step: 7
Training loss: 2.197225570678711
Validation loss: 2.0657772889701267

Epoch: 5| Step: 8
Training loss: 2.4174964427948
Validation loss: 2.1013621707116403

Epoch: 5| Step: 9
Training loss: 2.4629244804382324
Validation loss: 2.098447493327561

Epoch: 5| Step: 10
Training loss: 2.127251386642456
Validation loss: 2.101186498518913

Epoch: 207| Step: 0
Training loss: 2.390079975128174
Validation loss: 2.0930963126561974

Epoch: 5| Step: 1
Training loss: 1.7505813837051392
Validation loss: 2.0737854191052016

Epoch: 5| Step: 2
Training loss: 2.2964935302734375
Validation loss: 2.0876098371321157

Epoch: 5| Step: 3
Training loss: 1.3459097146987915
Validation loss: 2.117555797740977

Epoch: 5| Step: 4
Training loss: 1.9597437381744385
Validation loss: 2.1533505660231396

Epoch: 5| Step: 5
Training loss: 2.5000698566436768
Validation loss: 2.204198875734883

Epoch: 5| Step: 6
Training loss: 2.1220333576202393
Validation loss: 2.237701310906359

Epoch: 5| Step: 7
Training loss: 0.9943219423294067
Validation loss: 2.23159949369328

Epoch: 5| Step: 8
Training loss: 1.633905053138733
Validation loss: 2.233728931796166

Epoch: 5| Step: 9
Training loss: 2.1781516075134277
Validation loss: 2.212067650210473

Epoch: 5| Step: 10
Training loss: 3.3814566135406494
Validation loss: 2.176943923837395

Epoch: 208| Step: 0
Training loss: 1.9227691888809204
Validation loss: 2.1225422889955583

Epoch: 5| Step: 1
Training loss: 1.442030429840088
Validation loss: 2.0993839117788498

Epoch: 5| Step: 2
Training loss: 1.2579526901245117
Validation loss: 2.080359928069576

Epoch: 5| Step: 3
Training loss: 1.8581174612045288
Validation loss: 2.0815427662223898

Epoch: 5| Step: 4
Training loss: 2.997814416885376
Validation loss: 2.0849910577138266

Epoch: 5| Step: 5
Training loss: 2.2074313163757324
Validation loss: 2.072357408462032

Epoch: 5| Step: 6
Training loss: 2.071563959121704
Validation loss: 2.066081900750437

Epoch: 5| Step: 7
Training loss: 2.2624101638793945
Validation loss: 2.041539119135949

Epoch: 5| Step: 8
Training loss: 1.996840476989746
Validation loss: 2.0587141078005553

Epoch: 5| Step: 9
Training loss: 2.29844331741333
Validation loss: 2.08333283726887

Epoch: 5| Step: 10
Training loss: 2.1401495933532715
Validation loss: 2.0738951647153465

Epoch: 209| Step: 0
Training loss: 2.429841995239258
Validation loss: 2.0959950467591644

Epoch: 5| Step: 1
Training loss: 1.200085163116455
Validation loss: 2.171326498831472

Epoch: 5| Step: 2
Training loss: 2.6653695106506348
Validation loss: 2.224066492049925

Epoch: 5| Step: 3
Training loss: 1.81890869140625
Validation loss: 2.301251962620725

Epoch: 5| Step: 4
Training loss: 2.1645379066467285
Validation loss: 2.3160515190452657

Epoch: 5| Step: 5
Training loss: 1.8772811889648438
Validation loss: 2.3286013667301466

Epoch: 5| Step: 6
Training loss: 1.7139323949813843
Validation loss: 2.278469458703072

Epoch: 5| Step: 7
Training loss: 2.422070026397705
Validation loss: 2.200153159838851

Epoch: 5| Step: 8
Training loss: 1.735171914100647
Validation loss: 2.150260458710373

Epoch: 5| Step: 9
Training loss: 2.1637721061706543
Validation loss: 2.1110652928711264

Epoch: 5| Step: 10
Training loss: 1.9726845026016235
Validation loss: 2.1052158160876204

Epoch: 210| Step: 0
Training loss: 2.3939759731292725
Validation loss: 2.1104145383322113

Epoch: 5| Step: 1
Training loss: 2.0183346271514893
Validation loss: 2.1124178094248616

Epoch: 5| Step: 2
Training loss: 2.4396533966064453
Validation loss: 2.108776396320712

Epoch: 5| Step: 3
Training loss: 1.707251787185669
Validation loss: 2.0766643426751576

Epoch: 5| Step: 4
Training loss: 1.7625036239624023
Validation loss: 2.0501182361315657

Epoch: 5| Step: 5
Training loss: 2.409367084503174
Validation loss: 2.0327372756055606

Epoch: 5| Step: 6
Training loss: 1.8330284357070923
Validation loss: 2.027432185347362

Epoch: 5| Step: 7
Training loss: 2.243156671524048
Validation loss: 2.0370252824598745

Epoch: 5| Step: 8
Training loss: 2.1929898262023926
Validation loss: 2.0638040470820602

Epoch: 5| Step: 9
Training loss: 1.6314926147460938
Validation loss: 2.1111759396009546

Epoch: 5| Step: 10
Training loss: 1.858384132385254
Validation loss: 2.133720105694186

Epoch: 211| Step: 0
Training loss: 2.591115713119507
Validation loss: 2.2079989282033776

Epoch: 5| Step: 1
Training loss: 1.887250542640686
Validation loss: 2.1780746495851906

Epoch: 5| Step: 2
Training loss: 1.4425996541976929
Validation loss: 2.1949284153599895

Epoch: 5| Step: 3
Training loss: 2.3205721378326416
Validation loss: 2.173778557008313

Epoch: 5| Step: 4
Training loss: 2.1040849685668945
Validation loss: 2.142532435796594

Epoch: 5| Step: 5
Training loss: 2.5438027381896973
Validation loss: 2.143278077084531

Epoch: 5| Step: 6
Training loss: 1.4573032855987549
Validation loss: 2.1343490192967076

Epoch: 5| Step: 7
Training loss: 2.0670952796936035
Validation loss: 2.1226799436794814

Epoch: 5| Step: 8
Training loss: 1.6227340698242188
Validation loss: 2.096754894461683

Epoch: 5| Step: 9
Training loss: 1.962000846862793
Validation loss: 2.0971605444467194

Epoch: 5| Step: 10
Training loss: 2.107489585876465
Validation loss: 2.093328681043399

Epoch: 212| Step: 0
Training loss: 1.8692913055419922
Validation loss: 2.091550624498757

Epoch: 5| Step: 1
Training loss: 2.171997308731079
Validation loss: 2.0936352822088424

Epoch: 5| Step: 2
Training loss: 0.9029864072799683
Validation loss: 2.0952585551046554

Epoch: 5| Step: 3
Training loss: 2.2846012115478516
Validation loss: 2.0821690508114394

Epoch: 5| Step: 4
Training loss: 2.3595130443573
Validation loss: 2.099881479817052

Epoch: 5| Step: 5
Training loss: 1.6778528690338135
Validation loss: 2.1128666336818407

Epoch: 5| Step: 6
Training loss: 2.3717727661132812
Validation loss: 2.1195004063267864

Epoch: 5| Step: 7
Training loss: 1.5447185039520264
Validation loss: 2.1873742290722427

Epoch: 5| Step: 8
Training loss: 2.393516778945923
Validation loss: 2.2013570980359147

Epoch: 5| Step: 9
Training loss: 2.2160212993621826
Validation loss: 2.2302983089159896

Epoch: 5| Step: 10
Training loss: 2.3099255561828613
Validation loss: 2.2246435816569994

Epoch: 213| Step: 0
Training loss: 2.2191615104675293
Validation loss: 2.1862025312198106

Epoch: 5| Step: 1
Training loss: 2.1918857097625732
Validation loss: 2.1502792271234656

Epoch: 5| Step: 2
Training loss: 1.5059846639633179
Validation loss: 2.1318026716991136

Epoch: 5| Step: 3
Training loss: 2.1922237873077393
Validation loss: 2.121113682305941

Epoch: 5| Step: 4
Training loss: 1.6645729541778564
Validation loss: 2.0989018101846018

Epoch: 5| Step: 5
Training loss: 2.3480515480041504
Validation loss: 2.1127415523734143

Epoch: 5| Step: 6
Training loss: 1.3739650249481201
Validation loss: 2.0882118901898785

Epoch: 5| Step: 7
Training loss: 1.9425203800201416
Validation loss: 2.0741388413213913

Epoch: 5| Step: 8
Training loss: 2.3824591636657715
Validation loss: 2.044526876941804

Epoch: 5| Step: 9
Training loss: 2.21783709526062
Validation loss: 2.046669634439612

Epoch: 5| Step: 10
Training loss: 2.02276349067688
Validation loss: 2.069456861865136

Epoch: 214| Step: 0
Training loss: 2.0082428455352783
Validation loss: 2.094405040946058

Epoch: 5| Step: 1
Training loss: 2.129286050796509
Validation loss: 2.1369535205184773

Epoch: 5| Step: 2
Training loss: 2.165180206298828
Validation loss: 2.172660126481005

Epoch: 5| Step: 3
Training loss: 2.355473279953003
Validation loss: 2.230004331117035

Epoch: 5| Step: 4
Training loss: 1.9501760005950928
Validation loss: 2.264164650312034

Epoch: 5| Step: 5
Training loss: 2.5272529125213623
Validation loss: 2.2563737694935133

Epoch: 5| Step: 6
Training loss: 1.7514909505844116
Validation loss: 2.2088936785215973

Epoch: 5| Step: 7
Training loss: 2.0396153926849365
Validation loss: 2.1645663297304543

Epoch: 5| Step: 8
Training loss: 1.8093239068984985
Validation loss: 2.1295380053981656

Epoch: 5| Step: 9
Training loss: 2.0374488830566406
Validation loss: 2.123445451900523

Epoch: 5| Step: 10
Training loss: 1.0238395929336548
Validation loss: 2.1126587134535595

Epoch: 215| Step: 0
Training loss: 1.9087154865264893
Validation loss: 2.0965274251917356

Epoch: 5| Step: 1
Training loss: 1.4124400615692139
Validation loss: 2.1002219389843684

Epoch: 5| Step: 2
Training loss: 2.12321400642395
Validation loss: 2.0905725148416336

Epoch: 5| Step: 3
Training loss: 1.5318019390106201
Validation loss: 2.0790812341115807

Epoch: 5| Step: 4
Training loss: 2.2899351119995117
Validation loss: 2.0714288757693384

Epoch: 5| Step: 5
Training loss: 2.4249370098114014
Validation loss: 2.068411431004924

Epoch: 5| Step: 6
Training loss: 2.312037229537964
Validation loss: 2.0894189573103383

Epoch: 5| Step: 7
Training loss: 2.1440305709838867
Validation loss: 2.1277393756374234

Epoch: 5| Step: 8
Training loss: 1.965881586074829
Validation loss: 2.1744120556821107

Epoch: 5| Step: 9
Training loss: 1.7470436096191406
Validation loss: 2.217537333888392

Epoch: 5| Step: 10
Training loss: 2.248324155807495
Validation loss: 2.2464193515880133

Epoch: 216| Step: 0
Training loss: 2.147026777267456
Validation loss: 2.2612302123859362

Epoch: 5| Step: 1
Training loss: 2.46246337890625
Validation loss: 2.240082469037784

Epoch: 5| Step: 2
Training loss: 1.8197473287582397
Validation loss: 2.21481579349887

Epoch: 5| Step: 3
Training loss: 1.7791274785995483
Validation loss: 2.1785857331368232

Epoch: 5| Step: 4
Training loss: 1.984890341758728
Validation loss: 2.1606903511990785

Epoch: 5| Step: 5
Training loss: 2.2709133625030518
Validation loss: 2.153416710515176

Epoch: 5| Step: 6
Training loss: 1.9361196756362915
Validation loss: 2.1342986347854778

Epoch: 5| Step: 7
Training loss: 1.592756986618042
Validation loss: 2.131578390316297

Epoch: 5| Step: 8
Training loss: 2.226409435272217
Validation loss: 2.1431097215221775

Epoch: 5| Step: 9
Training loss: 1.7639795541763306
Validation loss: 2.1381469131797872

Epoch: 5| Step: 10
Training loss: 1.8671826124191284
Validation loss: 2.1273688001017415

Epoch: 217| Step: 0
Training loss: 2.0803062915802
Validation loss: 2.1176559361078406

Epoch: 5| Step: 1
Training loss: 1.7187515497207642
Validation loss: 2.1017671092864005

Epoch: 5| Step: 2
Training loss: 2.0752336978912354
Validation loss: 2.1162769640645673

Epoch: 5| Step: 3
Training loss: 2.385680913925171
Validation loss: 2.134034464436193

Epoch: 5| Step: 4
Training loss: 1.385223627090454
Validation loss: 2.1696650187174478

Epoch: 5| Step: 5
Training loss: 2.207655668258667
Validation loss: 2.1680253218579035

Epoch: 5| Step: 6
Training loss: 1.650719404220581
Validation loss: 2.1639203179267144

Epoch: 5| Step: 7
Training loss: 2.1935973167419434
Validation loss: 2.1512752681650142

Epoch: 5| Step: 8
Training loss: 1.9988479614257812
Validation loss: 2.139376494192308

Epoch: 5| Step: 9
Training loss: 1.913764238357544
Validation loss: 2.1287708218379686

Epoch: 5| Step: 10
Training loss: 1.8933343887329102
Validation loss: 2.127383306462278

Epoch: 218| Step: 0
Training loss: 2.4506068229675293
Validation loss: 2.1196137115519535

Epoch: 5| Step: 1
Training loss: 2.458228588104248
Validation loss: 2.135292478787002

Epoch: 5| Step: 2
Training loss: 1.891114592552185
Validation loss: 2.137464520751789

Epoch: 5| Step: 3
Training loss: 2.142437696456909
Validation loss: 2.126147198420699

Epoch: 5| Step: 4
Training loss: 2.030484676361084
Validation loss: 2.1088033568474556

Epoch: 5| Step: 5
Training loss: 2.2730746269226074
Validation loss: 2.1103768592239707

Epoch: 5| Step: 6
Training loss: 1.8913323879241943
Validation loss: 2.095115823130454

Epoch: 5| Step: 7
Training loss: 1.4784126281738281
Validation loss: 2.089433482898179

Epoch: 5| Step: 8
Training loss: 1.3446753025054932
Validation loss: 2.08032129656884

Epoch: 5| Step: 9
Training loss: 1.5302867889404297
Validation loss: 2.07818676066655

Epoch: 5| Step: 10
Training loss: 1.9982681274414062
Validation loss: 2.0881650960573586

Epoch: 219| Step: 0
Training loss: 1.5168030261993408
Validation loss: 2.1212735945178616

Epoch: 5| Step: 1
Training loss: 2.1905970573425293
Validation loss: 2.160325454127404

Epoch: 5| Step: 2
Training loss: 2.882429838180542
Validation loss: 2.163949660075608

Epoch: 5| Step: 3
Training loss: 1.9451725482940674
Validation loss: 2.1948056323553926

Epoch: 5| Step: 4
Training loss: 1.390342354774475
Validation loss: 2.2171960364105883

Epoch: 5| Step: 5
Training loss: 2.323765993118286
Validation loss: 2.2625578834164526

Epoch: 5| Step: 6
Training loss: 1.37992525100708
Validation loss: 2.292699506205897

Epoch: 5| Step: 7
Training loss: 2.0455715656280518
Validation loss: 2.3307311381063154

Epoch: 5| Step: 8
Training loss: 1.963382363319397
Validation loss: 2.296798870127688

Epoch: 5| Step: 9
Training loss: 3.0280988216400146
Validation loss: 2.2368592498123006

Epoch: 5| Step: 10
Training loss: 1.0465047359466553
Validation loss: 2.2031499108960553

Epoch: 220| Step: 0
Training loss: 1.9542372226715088
Validation loss: 2.1365871890898673

Epoch: 5| Step: 1
Training loss: 2.3933792114257812
Validation loss: 2.10736761810959

Epoch: 5| Step: 2
Training loss: 1.950609803199768
Validation loss: 2.0998784880484305

Epoch: 5| Step: 3
Training loss: 2.0442168712615967
Validation loss: 2.084300116826129

Epoch: 5| Step: 4
Training loss: 2.263788938522339
Validation loss: 2.083812020158255

Epoch: 5| Step: 5
Training loss: 1.6872485876083374
Validation loss: 2.08798974047425

Epoch: 5| Step: 6
Training loss: 1.7479976415634155
Validation loss: 2.098260200151833

Epoch: 5| Step: 7
Training loss: 1.8870494365692139
Validation loss: 2.1311208201992895

Epoch: 5| Step: 8
Training loss: 1.847288727760315
Validation loss: 2.1563792331244356

Epoch: 5| Step: 9
Training loss: 2.2751991748809814
Validation loss: 2.1654517996695732

Epoch: 5| Step: 10
Training loss: 1.447590947151184
Validation loss: 2.1466681688062605

Epoch: 221| Step: 0
Training loss: 2.7666287422180176
Validation loss: 2.1472400337137203

Epoch: 5| Step: 1
Training loss: 1.4171339273452759
Validation loss: 2.135794767769434

Epoch: 5| Step: 2
Training loss: 1.4679726362228394
Validation loss: 2.1276603719239593

Epoch: 5| Step: 3
Training loss: 2.656071901321411
Validation loss: 2.1402553666022515

Epoch: 5| Step: 4
Training loss: 1.9132044315338135
Validation loss: 2.1188350518544516

Epoch: 5| Step: 5
Training loss: 1.8050782680511475
Validation loss: 2.0891999659999723

Epoch: 5| Step: 6
Training loss: 2.014749526977539
Validation loss: 2.063839422759189

Epoch: 5| Step: 7
Training loss: 1.7022727727890015
Validation loss: 2.0767840467473513

Epoch: 5| Step: 8
Training loss: 1.7323455810546875
Validation loss: 2.079289021030549

Epoch: 5| Step: 9
Training loss: 2.2201571464538574
Validation loss: 2.069423044881513

Epoch: 5| Step: 10
Training loss: 2.0673282146453857
Validation loss: 2.0763491738227104

Epoch: 222| Step: 0
Training loss: 1.584174394607544
Validation loss: 2.043247643337455

Epoch: 5| Step: 1
Training loss: 1.8270084857940674
Validation loss: 2.036358420566846

Epoch: 5| Step: 2
Training loss: 1.752716302871704
Validation loss: 2.0584370936116865

Epoch: 5| Step: 3
Training loss: 1.2515513896942139
Validation loss: 2.072502536158408

Epoch: 5| Step: 4
Training loss: 2.2656054496765137
Validation loss: 2.1026014999676774

Epoch: 5| Step: 5
Training loss: 2.2693302631378174
Validation loss: 2.1487152012445594

Epoch: 5| Step: 6
Training loss: 1.8699766397476196
Validation loss: 2.1724186558877268

Epoch: 5| Step: 7
Training loss: 2.1666007041931152
Validation loss: 2.1899158211164576

Epoch: 5| Step: 8
Training loss: 1.7380691766738892
Validation loss: 2.2103167631292857

Epoch: 5| Step: 9
Training loss: 2.336373805999756
Validation loss: 2.1861822630769465

Epoch: 5| Step: 10
Training loss: 2.335221290588379
Validation loss: 2.1592787158104683

Epoch: 223| Step: 0
Training loss: 2.1687726974487305
Validation loss: 2.1462550727269982

Epoch: 5| Step: 1
Training loss: 1.7278234958648682
Validation loss: 2.103555949785376

Epoch: 5| Step: 2
Training loss: 1.6105852127075195
Validation loss: 2.0984730053973455

Epoch: 5| Step: 3
Training loss: 1.6499912738800049
Validation loss: 2.066175022432881

Epoch: 5| Step: 4
Training loss: 1.9743340015411377
Validation loss: 2.0772918219207437

Epoch: 5| Step: 5
Training loss: 2.125293016433716
Validation loss: 2.081043215208156

Epoch: 5| Step: 6
Training loss: 2.2512946128845215
Validation loss: 2.0691845468295518

Epoch: 5| Step: 7
Training loss: 2.1826443672180176
Validation loss: 2.0999981305932485

Epoch: 5| Step: 8
Training loss: 2.0871758460998535
Validation loss: 2.0846006665178525

Epoch: 5| Step: 9
Training loss: 1.741098403930664
Validation loss: 2.096237535117775

Epoch: 5| Step: 10
Training loss: 1.5053174495697021
Validation loss: 2.1033433752675212

Epoch: 224| Step: 0
Training loss: 2.5739848613739014
Validation loss: 2.0996051321747484

Epoch: 5| Step: 1
Training loss: 1.6330254077911377
Validation loss: 2.0783109639280584

Epoch: 5| Step: 2
Training loss: 2.2464935779571533
Validation loss: 2.0750599471471642

Epoch: 5| Step: 3
Training loss: 1.7627226114273071
Validation loss: 2.076598528892763

Epoch: 5| Step: 4
Training loss: 1.965707778930664
Validation loss: 2.0653344290230864

Epoch: 5| Step: 5
Training loss: 1.6881272792816162
Validation loss: 2.091609844597437

Epoch: 5| Step: 6
Training loss: 1.4508644342422485
Validation loss: 2.102075781873477

Epoch: 5| Step: 7
Training loss: 1.731711745262146
Validation loss: 2.0910565648027646

Epoch: 5| Step: 8
Training loss: 1.4503798484802246
Validation loss: 2.0958418487220682

Epoch: 5| Step: 9
Training loss: 2.1697418689727783
Validation loss: 2.108823514753772

Epoch: 5| Step: 10
Training loss: 2.3202626705169678
Validation loss: 2.1322028201113463

Epoch: 225| Step: 0
Training loss: 2.1903867721557617
Validation loss: 2.136259021297578

Epoch: 5| Step: 1
Training loss: 0.9846234321594238
Validation loss: 2.115540668528567

Epoch: 5| Step: 2
Training loss: 1.496891736984253
Validation loss: 2.1050987602562032

Epoch: 5| Step: 3
Training loss: 1.5118616819381714
Validation loss: 2.0837357172402005

Epoch: 5| Step: 4
Training loss: 1.9342750310897827
Validation loss: 2.0834327449080763

Epoch: 5| Step: 5
Training loss: 2.2540009021759033
Validation loss: 2.064820912576491

Epoch: 5| Step: 6
Training loss: 1.785460114479065
Validation loss: 2.0622000066182946

Epoch: 5| Step: 7
Training loss: 1.8371556997299194
Validation loss: 2.0785576656300533

Epoch: 5| Step: 8
Training loss: 2.3567795753479004
Validation loss: 2.081200579161285

Epoch: 5| Step: 9
Training loss: 2.0791711807250977
Validation loss: 2.064722611058143

Epoch: 5| Step: 10
Training loss: 2.514708995819092
Validation loss: 2.0861960816127

Epoch: 226| Step: 0
Training loss: 1.8921808004379272
Validation loss: 2.086156665637929

Epoch: 5| Step: 1
Training loss: 1.632312536239624
Validation loss: 2.0799139045899913

Epoch: 5| Step: 2
Training loss: 1.9016368389129639
Validation loss: 2.078958098606397

Epoch: 5| Step: 3
Training loss: 1.991102933883667
Validation loss: 2.081602778486026

Epoch: 5| Step: 4
Training loss: 2.0544962882995605
Validation loss: 2.105054199054677

Epoch: 5| Step: 5
Training loss: 1.986617088317871
Validation loss: 2.10600221285256

Epoch: 5| Step: 6
Training loss: 2.016091823577881
Validation loss: 2.1398623861292356

Epoch: 5| Step: 7
Training loss: 1.7904094457626343
Validation loss: 2.132362655414048

Epoch: 5| Step: 8
Training loss: 1.3311927318572998
Validation loss: 2.1362150894698275

Epoch: 5| Step: 9
Training loss: 2.5353474617004395
Validation loss: 2.145368481195101

Epoch: 5| Step: 10
Training loss: 1.5071805715560913
Validation loss: 2.1138289615672123

Epoch: 227| Step: 0
Training loss: 2.142686367034912
Validation loss: 2.0850245273241432

Epoch: 5| Step: 1
Training loss: 1.5102651119232178
Validation loss: 2.0788665894539125

Epoch: 5| Step: 2
Training loss: 1.5348032712936401
Validation loss: 2.0807911042244203

Epoch: 5| Step: 3
Training loss: 1.9159759283065796
Validation loss: 2.087613626192975

Epoch: 5| Step: 4
Training loss: 2.339470148086548
Validation loss: 2.0812104389231694

Epoch: 5| Step: 5
Training loss: 1.6000229120254517
Validation loss: 2.11821468927527

Epoch: 5| Step: 6
Training loss: 2.027967929840088
Validation loss: 2.1355683547194286

Epoch: 5| Step: 7
Training loss: 2.032085657119751
Validation loss: 2.1234645997324297

Epoch: 5| Step: 8
Training loss: 1.9912354946136475
Validation loss: 2.1171616033841203

Epoch: 5| Step: 9
Training loss: 1.7219440937042236
Validation loss: 2.090343383050734

Epoch: 5| Step: 10
Training loss: 1.999633550643921
Validation loss: 2.1095777891015493

Epoch: 228| Step: 0
Training loss: 2.221572160720825
Validation loss: 2.124317338389735

Epoch: 5| Step: 1
Training loss: 1.8746753931045532
Validation loss: 2.150029836162444

Epoch: 5| Step: 2
Training loss: 1.5440645217895508
Validation loss: 2.143357091052558

Epoch: 5| Step: 3
Training loss: 1.8513381481170654
Validation loss: 2.1297714453871532

Epoch: 5| Step: 4
Training loss: 1.867537260055542
Validation loss: 2.0790390891413533

Epoch: 5| Step: 5
Training loss: 1.8502037525177002
Validation loss: 2.0694646014962146

Epoch: 5| Step: 6
Training loss: 2.0621113777160645
Validation loss: 2.0521045090049825

Epoch: 5| Step: 7
Training loss: 1.8610461950302124
Validation loss: 2.046565019956199

Epoch: 5| Step: 8
Training loss: 1.7877002954483032
Validation loss: 2.055840847312763

Epoch: 5| Step: 9
Training loss: 2.0172247886657715
Validation loss: 2.057079161367109

Epoch: 5| Step: 10
Training loss: 1.7657058238983154
Validation loss: 2.066686725103727

Epoch: 229| Step: 0
Training loss: 1.7585119009017944
Validation loss: 2.0929532897087837

Epoch: 5| Step: 1
Training loss: 1.8324015140533447
Validation loss: 2.1680623869742117

Epoch: 5| Step: 2
Training loss: 1.5817186832427979
Validation loss: 2.2174353266275055

Epoch: 5| Step: 3
Training loss: 1.703494668006897
Validation loss: 2.2462534801934355

Epoch: 5| Step: 4
Training loss: 1.9111086130142212
Validation loss: 2.257461751660993

Epoch: 5| Step: 5
Training loss: 2.3124160766601562
Validation loss: 2.2337575984257523

Epoch: 5| Step: 6
Training loss: 2.0709493160247803
Validation loss: 2.176288561154437

Epoch: 5| Step: 7
Training loss: 1.8732173442840576
Validation loss: 2.1350358147774973

Epoch: 5| Step: 8
Training loss: 1.8767973184585571
Validation loss: 2.1160505253781556

Epoch: 5| Step: 9
Training loss: 2.3548696041107178
Validation loss: 2.087436427352249

Epoch: 5| Step: 10
Training loss: 1.3705610036849976
Validation loss: 2.0641477492547806

Epoch: 230| Step: 0
Training loss: 1.8191986083984375
Validation loss: 2.0551003127969723

Epoch: 5| Step: 1
Training loss: 2.007624626159668
Validation loss: 2.04446848746269

Epoch: 5| Step: 2
Training loss: 2.1684489250183105
Validation loss: 2.065831338205645

Epoch: 5| Step: 3
Training loss: 1.6668545007705688
Validation loss: 2.0794988934711744

Epoch: 5| Step: 4
Training loss: 2.048647403717041
Validation loss: 2.150574594415644

Epoch: 5| Step: 5
Training loss: 1.9319181442260742
Validation loss: 2.1767686387544036

Epoch: 5| Step: 6
Training loss: 2.7347970008850098
Validation loss: 2.185299773370066

Epoch: 5| Step: 7
Training loss: 2.043334484100342
Validation loss: 2.1562465057578137

Epoch: 5| Step: 8
Training loss: 1.3266569375991821
Validation loss: 2.109073236424436

Epoch: 5| Step: 9
Training loss: 1.3203452825546265
Validation loss: 2.070294148178511

Epoch: 5| Step: 10
Training loss: 1.9608428478240967
Validation loss: 2.071733287585679

Epoch: 231| Step: 0
Training loss: 1.603618860244751
Validation loss: 2.05280319593286

Epoch: 5| Step: 1
Training loss: 2.290025234222412
Validation loss: 2.053860038839361

Epoch: 5| Step: 2
Training loss: 2.84773588180542
Validation loss: 2.0557418369477793

Epoch: 5| Step: 3
Training loss: 2.2000625133514404
Validation loss: 2.03698746619686

Epoch: 5| Step: 4
Training loss: 0.9008714556694031
Validation loss: 2.032773126838028

Epoch: 5| Step: 5
Training loss: 1.718875527381897
Validation loss: 2.025387594776769

Epoch: 5| Step: 6
Training loss: 2.163224458694458
Validation loss: 2.031864861006378

Epoch: 5| Step: 7
Training loss: 2.388638734817505
Validation loss: 2.0554318966404086

Epoch: 5| Step: 8
Training loss: 1.909703016281128
Validation loss: 2.0651797556108042

Epoch: 5| Step: 9
Training loss: 1.4677894115447998
Validation loss: 2.093974668492553

Epoch: 5| Step: 10
Training loss: 1.0341804027557373
Validation loss: 2.1187268431468675

Epoch: 232| Step: 0
Training loss: 1.6912078857421875
Validation loss: 2.1468631503402547

Epoch: 5| Step: 1
Training loss: 2.204699993133545
Validation loss: 2.142426016510174

Epoch: 5| Step: 2
Training loss: 2.2629380226135254
Validation loss: 2.14242386305204

Epoch: 5| Step: 3
Training loss: 1.3555577993392944
Validation loss: 2.131304212795791

Epoch: 5| Step: 4
Training loss: 1.2001222372055054
Validation loss: 2.119379369161462

Epoch: 5| Step: 5
Training loss: 2.426588535308838
Validation loss: 2.130882742584393

Epoch: 5| Step: 6
Training loss: 1.9971473217010498
Validation loss: 2.0979479538497103

Epoch: 5| Step: 7
Training loss: 1.6380119323730469
Validation loss: 2.0715488926056893

Epoch: 5| Step: 8
Training loss: 1.9149463176727295
Validation loss: 2.0644843270701747

Epoch: 5| Step: 9
Training loss: 2.1538827419281006
Validation loss: 2.076257457015335

Epoch: 5| Step: 10
Training loss: 1.5323792695999146
Validation loss: 2.0733944421173423

Epoch: 233| Step: 0
Training loss: 2.572165012359619
Validation loss: 2.058879167802872

Epoch: 5| Step: 1
Training loss: 1.8649795055389404
Validation loss: 2.079272472730247

Epoch: 5| Step: 2
Training loss: 1.5353209972381592
Validation loss: 2.077797575663495

Epoch: 5| Step: 3
Training loss: 1.9366705417633057
Validation loss: 2.098705591694001

Epoch: 5| Step: 4
Training loss: 2.088902711868286
Validation loss: 2.098544498925568

Epoch: 5| Step: 5
Training loss: 2.0019543170928955
Validation loss: 2.0941167134110645

Epoch: 5| Step: 6
Training loss: 1.5962566137313843
Validation loss: 2.1148322628390406

Epoch: 5| Step: 7
Training loss: 1.1842643022537231
Validation loss: 2.09375625271951

Epoch: 5| Step: 8
Training loss: 2.162040948867798
Validation loss: 2.110396067301432

Epoch: 5| Step: 9
Training loss: 1.4811443090438843
Validation loss: 2.103586285345016

Epoch: 5| Step: 10
Training loss: 1.9117377996444702
Validation loss: 2.0889047140716226

Epoch: 234| Step: 0
Training loss: 1.476897120475769
Validation loss: 2.093487178125689

Epoch: 5| Step: 1
Training loss: 1.2916767597198486
Validation loss: 2.111380507869105

Epoch: 5| Step: 2
Training loss: 2.032484769821167
Validation loss: 2.1279006158151934

Epoch: 5| Step: 3
Training loss: 2.423985004425049
Validation loss: 2.134993940271357

Epoch: 5| Step: 4
Training loss: 1.5703717470169067
Validation loss: 2.1367432917318037

Epoch: 5| Step: 5
Training loss: 2.4039998054504395
Validation loss: 2.1271601774359263

Epoch: 5| Step: 6
Training loss: 1.675824522972107
Validation loss: 2.1132188202232443

Epoch: 5| Step: 7
Training loss: 2.249356985092163
Validation loss: 2.1049092943950365

Epoch: 5| Step: 8
Training loss: 1.3723409175872803
Validation loss: 2.0800026411651285

Epoch: 5| Step: 9
Training loss: 1.740544080734253
Validation loss: 2.065982170002435

Epoch: 5| Step: 10
Training loss: 1.9748064279556274
Validation loss: 2.064862456372989

Epoch: 235| Step: 0
Training loss: 1.8635848760604858
Validation loss: 2.0738999689778974

Epoch: 5| Step: 1
Training loss: 1.510244607925415
Validation loss: 2.080553675210604

Epoch: 5| Step: 2
Training loss: 1.5247578620910645
Validation loss: 2.1007458420209986

Epoch: 5| Step: 3
Training loss: 1.4911125898361206
Validation loss: 2.122117941097547

Epoch: 5| Step: 4
Training loss: 2.6236462593078613
Validation loss: 2.149161156787667

Epoch: 5| Step: 5
Training loss: 1.5270335674285889
Validation loss: 2.150967688970668

Epoch: 5| Step: 6
Training loss: 1.5809427499771118
Validation loss: 2.114455971666562

Epoch: 5| Step: 7
Training loss: 2.27943754196167
Validation loss: 2.1148328114581365

Epoch: 5| Step: 8
Training loss: 2.261120557785034
Validation loss: 2.080034937909854

Epoch: 5| Step: 9
Training loss: 1.3082075119018555
Validation loss: 2.059302577408411

Epoch: 5| Step: 10
Training loss: 2.2606313228607178
Validation loss: 2.0454863976406794

Epoch: 236| Step: 0
Training loss: 1.3943208456039429
Validation loss: 2.0416641401988205

Epoch: 5| Step: 1
Training loss: 2.1524670124053955
Validation loss: 2.0455403917579242

Epoch: 5| Step: 2
Training loss: 2.151885986328125
Validation loss: 2.0464875005906626

Epoch: 5| Step: 3
Training loss: 2.1688947677612305
Validation loss: 2.0482643727333314

Epoch: 5| Step: 4
Training loss: 1.225346326828003
Validation loss: 2.0745915674394175

Epoch: 5| Step: 5
Training loss: 1.5478261709213257
Validation loss: 2.0855186575202533

Epoch: 5| Step: 6
Training loss: 1.9820064306259155
Validation loss: 2.102689794314805

Epoch: 5| Step: 7
Training loss: 2.1161911487579346
Validation loss: 2.127692655850482

Epoch: 5| Step: 8
Training loss: 1.6349376440048218
Validation loss: 2.1281192738522767

Epoch: 5| Step: 9
Training loss: 1.3660743236541748
Validation loss: 2.105743036475233

Epoch: 5| Step: 10
Training loss: 2.349302291870117
Validation loss: 2.125864318622056

Epoch: 237| Step: 0
Training loss: 1.9562031030654907
Validation loss: 2.100069720257995

Epoch: 5| Step: 1
Training loss: 1.7078863382339478
Validation loss: 2.108369263269568

Epoch: 5| Step: 2
Training loss: 1.8672029972076416
Validation loss: 2.061718479279549

Epoch: 5| Step: 3
Training loss: 1.7056776285171509
Validation loss: 2.048833061290044

Epoch: 5| Step: 4
Training loss: 1.5120084285736084
Validation loss: 2.0509978391790904

Epoch: 5| Step: 5
Training loss: 1.6648117303848267
Validation loss: 2.051985509933964

Epoch: 5| Step: 6
Training loss: 2.061513662338257
Validation loss: 2.0430543473971787

Epoch: 5| Step: 7
Training loss: 1.61380934715271
Validation loss: 2.0675402956624187

Epoch: 5| Step: 8
Training loss: 2.4372708797454834
Validation loss: 2.088093420510651

Epoch: 5| Step: 9
Training loss: 1.651937484741211
Validation loss: 2.0974737059685493

Epoch: 5| Step: 10
Training loss: 1.5670232772827148
Validation loss: 2.104893763860067

Epoch: 238| Step: 0
Training loss: 2.281313419342041
Validation loss: 2.1211810188908733

Epoch: 5| Step: 1
Training loss: 1.1786288022994995
Validation loss: 2.081948023970409

Epoch: 5| Step: 2
Training loss: 1.4908106327056885
Validation loss: 2.053889920634608

Epoch: 5| Step: 3
Training loss: 1.8773057460784912
Validation loss: 2.061874960058479

Epoch: 5| Step: 4
Training loss: 2.058955430984497
Validation loss: 2.035013112970578

Epoch: 5| Step: 5
Training loss: 1.8403215408325195
Validation loss: 2.0340025309593446

Epoch: 5| Step: 6
Training loss: 1.782639741897583
Validation loss: 2.023753022634855

Epoch: 5| Step: 7
Training loss: 1.9498980045318604
Validation loss: 2.0238216961583784

Epoch: 5| Step: 8
Training loss: 1.5841165781021118
Validation loss: 2.018418963237475

Epoch: 5| Step: 9
Training loss: 1.8391215801239014
Validation loss: 2.0148646703330417

Epoch: 5| Step: 10
Training loss: 1.9270657300949097
Validation loss: 2.0320313207564817

Epoch: 239| Step: 0
Training loss: 1.6984360218048096
Validation loss: 2.046647369220693

Epoch: 5| Step: 1
Training loss: 1.9296786785125732
Validation loss: 2.0595226146841563

Epoch: 5| Step: 2
Training loss: 1.845999002456665
Validation loss: 2.1054671220881964

Epoch: 5| Step: 3
Training loss: 2.068521499633789
Validation loss: 2.1252061013252503

Epoch: 5| Step: 4
Training loss: 2.1722683906555176
Validation loss: 2.1186611011464107

Epoch: 5| Step: 5
Training loss: 2.0357306003570557
Validation loss: 2.081621172607586

Epoch: 5| Step: 6
Training loss: 1.7929538488388062
Validation loss: 2.0440348989220074

Epoch: 5| Step: 7
Training loss: 1.2241952419281006
Validation loss: 2.0335585686468307

Epoch: 5| Step: 8
Training loss: 1.6410140991210938
Validation loss: 2.0369934574250252

Epoch: 5| Step: 9
Training loss: 1.9142202138900757
Validation loss: 2.0405129565987536

Epoch: 5| Step: 10
Training loss: 1.3382648229599
Validation loss: 2.0373031388046923

Epoch: 240| Step: 0
Training loss: 1.8745319843292236
Validation loss: 2.0444029120988745

Epoch: 5| Step: 1
Training loss: 2.2051937580108643
Validation loss: 2.0522753346350884

Epoch: 5| Step: 2
Training loss: 2.127833366394043
Validation loss: 2.062337016546598

Epoch: 5| Step: 3
Training loss: 1.238743543624878
Validation loss: 2.066134650220153

Epoch: 5| Step: 4
Training loss: 1.6680400371551514
Validation loss: 2.0802296899980113

Epoch: 5| Step: 5
Training loss: 1.8091773986816406
Validation loss: 2.106298085181944

Epoch: 5| Step: 6
Training loss: 1.4497957229614258
Validation loss: 2.1197442623876754

Epoch: 5| Step: 7
Training loss: 1.9834206104278564
Validation loss: 2.1069014187782042

Epoch: 5| Step: 8
Training loss: 1.7001686096191406
Validation loss: 2.117650067934426

Epoch: 5| Step: 9
Training loss: 1.947037696838379
Validation loss: 2.068600323892409

Epoch: 5| Step: 10
Training loss: 1.690798282623291
Validation loss: 2.0605843208169423

Epoch: 241| Step: 0
Training loss: 2.113198757171631
Validation loss: 2.030596184474166

Epoch: 5| Step: 1
Training loss: 2.0838913917541504
Validation loss: 2.02742136550206

Epoch: 5| Step: 2
Training loss: 1.4159507751464844
Validation loss: 2.0410881375753753

Epoch: 5| Step: 3
Training loss: 1.3855736255645752
Validation loss: 2.03784256340355

Epoch: 5| Step: 4
Training loss: 2.696268320083618
Validation loss: 2.044793518640662

Epoch: 5| Step: 5
Training loss: 1.6365522146224976
Validation loss: 2.050151990305993

Epoch: 5| Step: 6
Training loss: 1.471708059310913
Validation loss: 2.0952676393652476

Epoch: 5| Step: 7
Training loss: 2.0038342475891113
Validation loss: 2.0905382863936888

Epoch: 5| Step: 8
Training loss: 1.5424301624298096
Validation loss: 2.1081458727518716

Epoch: 5| Step: 9
Training loss: 1.692856788635254
Validation loss: 2.084728393503415

Epoch: 5| Step: 10
Training loss: 1.4655565023422241
Validation loss: 2.1018541551405385

Epoch: 242| Step: 0
Training loss: 1.5075485706329346
Validation loss: 2.074325015467982

Epoch: 5| Step: 1
Training loss: 2.575354814529419
Validation loss: 2.0599973329933743

Epoch: 5| Step: 2
Training loss: 1.8783700466156006
Validation loss: 2.050395627175608

Epoch: 5| Step: 3
Training loss: 1.4946380853652954
Validation loss: 2.0452814999447075

Epoch: 5| Step: 4
Training loss: 1.8145453929901123
Validation loss: 2.0525808565078245

Epoch: 5| Step: 5
Training loss: 1.6787025928497314
Validation loss: 2.053368418447433

Epoch: 5| Step: 6
Training loss: 1.7475230693817139
Validation loss: 2.0485474294231785

Epoch: 5| Step: 7
Training loss: 2.0091748237609863
Validation loss: 2.0554188143822456

Epoch: 5| Step: 8
Training loss: 1.6583274602890015
Validation loss: 2.076228403276013

Epoch: 5| Step: 9
Training loss: 1.8515132665634155
Validation loss: 2.0913195122954664

Epoch: 5| Step: 10
Training loss: 1.1076748371124268
Validation loss: 2.0834039231782318

Epoch: 243| Step: 0
Training loss: 1.9854099750518799
Validation loss: 2.056303484465486

Epoch: 5| Step: 1
Training loss: 1.7310693264007568
Validation loss: 2.056223089976977

Epoch: 5| Step: 2
Training loss: 1.4511942863464355
Validation loss: 2.0447745015544276

Epoch: 5| Step: 3
Training loss: 1.9404869079589844
Validation loss: 2.047585642465981

Epoch: 5| Step: 4
Training loss: 1.421584963798523
Validation loss: 2.051838449252549

Epoch: 5| Step: 5
Training loss: 1.9885154962539673
Validation loss: 2.042186201259654

Epoch: 5| Step: 6
Training loss: 1.5276306867599487
Validation loss: 2.0635365529726912

Epoch: 5| Step: 7
Training loss: 2.442934513092041
Validation loss: 2.057617184936359

Epoch: 5| Step: 8
Training loss: 1.5306886434555054
Validation loss: 2.035748335622972

Epoch: 5| Step: 9
Training loss: 1.5027658939361572
Validation loss: 2.0230744987405758

Epoch: 5| Step: 10
Training loss: 2.0051066875457764
Validation loss: 2.0263748168945312

Epoch: 244| Step: 0
Training loss: 2.1943328380584717
Validation loss: 2.03265025795147

Epoch: 5| Step: 1
Training loss: 1.6748641729354858
Validation loss: 2.0130708050984207

Epoch: 5| Step: 2
Training loss: 1.6541160345077515
Validation loss: 2.0004434765026136

Epoch: 5| Step: 3
Training loss: 1.379138708114624
Validation loss: 2.020099460437734

Epoch: 5| Step: 4
Training loss: 2.2921876907348633
Validation loss: 2.033816486276606

Epoch: 5| Step: 5
Training loss: 1.2898706197738647
Validation loss: 2.0579447541185605

Epoch: 5| Step: 6
Training loss: 2.2219574451446533
Validation loss: 2.070375911651119

Epoch: 5| Step: 7
Training loss: 1.8423798084259033
Validation loss: 2.0940536478514313

Epoch: 5| Step: 8
Training loss: 1.6659252643585205
Validation loss: 2.1011289217138804

Epoch: 5| Step: 9
Training loss: 1.6520378589630127
Validation loss: 2.09519334249599

Epoch: 5| Step: 10
Training loss: 1.2096258401870728
Validation loss: 2.0913027460857103

Epoch: 245| Step: 0
Training loss: 2.276270627975464
Validation loss: 2.0649656454722085

Epoch: 5| Step: 1
Training loss: 1.6756709814071655
Validation loss: 2.0645491051417526

Epoch: 5| Step: 2
Training loss: 1.2593257427215576
Validation loss: 2.040581016130345

Epoch: 5| Step: 3
Training loss: 2.342298984527588
Validation loss: 2.0372905064654607

Epoch: 5| Step: 4
Training loss: 1.3330461978912354
Validation loss: 2.0288258778151644

Epoch: 5| Step: 5
Training loss: 1.2908488512039185
Validation loss: 2.0466308414295153

Epoch: 5| Step: 6
Training loss: 1.3635157346725464
Validation loss: 2.0769538930667344

Epoch: 5| Step: 7
Training loss: 1.8061752319335938
Validation loss: 2.100572960351103

Epoch: 5| Step: 8
Training loss: 2.0286736488342285
Validation loss: 2.125721426420314

Epoch: 5| Step: 9
Training loss: 1.856102705001831
Validation loss: 2.118381589971563

Epoch: 5| Step: 10
Training loss: 2.057363748550415
Validation loss: 2.0976720368990334

Epoch: 246| Step: 0
Training loss: 2.09824800491333
Validation loss: 2.0449315963252896

Epoch: 5| Step: 1
Training loss: 1.476976990699768
Validation loss: 2.0179328969729844

Epoch: 5| Step: 2
Training loss: 2.5259010791778564
Validation loss: 2.017657332522895

Epoch: 5| Step: 3
Training loss: 2.005882978439331
Validation loss: 2.0289417082263577

Epoch: 5| Step: 4
Training loss: 1.3541710376739502
Validation loss: 2.0156324409669444

Epoch: 5| Step: 5
Training loss: 1.7778291702270508
Validation loss: 2.0259436176669214

Epoch: 5| Step: 6
Training loss: 2.29292631149292
Validation loss: 2.032984795108918

Epoch: 5| Step: 7
Training loss: 1.1764699220657349
Validation loss: 2.0432988776955554

Epoch: 5| Step: 8
Training loss: 1.1315969228744507
Validation loss: 2.03655308036394

Epoch: 5| Step: 9
Training loss: 2.1183319091796875
Validation loss: 2.0667069906829507

Epoch: 5| Step: 10
Training loss: 1.5439411401748657
Validation loss: 2.117933657861525

Epoch: 247| Step: 0
Training loss: 1.371537685394287
Validation loss: 2.2135570562014015

Epoch: 5| Step: 1
Training loss: 1.712182641029358
Validation loss: 2.2809225256725023

Epoch: 5| Step: 2
Training loss: 1.6298344135284424
Validation loss: 2.225560293402723

Epoch: 5| Step: 3
Training loss: 1.6466541290283203
Validation loss: 2.1422372223228536

Epoch: 5| Step: 4
Training loss: 1.2857451438903809
Validation loss: 2.0632809926104803

Epoch: 5| Step: 5
Training loss: 1.831080675125122
Validation loss: 2.0432495224860405

Epoch: 5| Step: 6
Training loss: 1.9263461828231812
Validation loss: 2.043077741899798

Epoch: 5| Step: 7
Training loss: 2.0442521572113037
Validation loss: 2.0553725432324153

Epoch: 5| Step: 8
Training loss: 2.1404290199279785
Validation loss: 2.0458962327690533

Epoch: 5| Step: 9
Training loss: 2.2307395935058594
Validation loss: 2.0406481424967446

Epoch: 5| Step: 10
Training loss: 2.177044630050659
Validation loss: 2.0079155237443986

Epoch: 248| Step: 0
Training loss: 2.0431761741638184
Validation loss: 2.010325759969732

Epoch: 5| Step: 1
Training loss: 1.504638910293579
Validation loss: 2.0282283418922016

Epoch: 5| Step: 2
Training loss: 1.3377940654754639
Validation loss: 2.057429849460561

Epoch: 5| Step: 3
Training loss: 1.6576839685440063
Validation loss: 2.0970891534641223

Epoch: 5| Step: 4
Training loss: 2.091393232345581
Validation loss: 2.1584529363980858

Epoch: 5| Step: 5
Training loss: 1.8874664306640625
Validation loss: 2.2125909892461633

Epoch: 5| Step: 6
Training loss: 1.7127964496612549
Validation loss: 2.198926494967553

Epoch: 5| Step: 7
Training loss: 1.4654381275177002
Validation loss: 2.1717578211138324

Epoch: 5| Step: 8
Training loss: 1.7442941665649414
Validation loss: 2.1049349705378213

Epoch: 5| Step: 9
Training loss: 2.3162825107574463
Validation loss: 2.0718361728934833

Epoch: 5| Step: 10
Training loss: 1.502087950706482
Validation loss: 2.0618193905840636

Epoch: 249| Step: 0
Training loss: 2.577296018600464
Validation loss: 2.0559868607469785

Epoch: 5| Step: 1
Training loss: 1.8779945373535156
Validation loss: 2.0347520074536725

Epoch: 5| Step: 2
Training loss: 1.472558856010437
Validation loss: 2.057752832289665

Epoch: 5| Step: 3
Training loss: 1.864841103553772
Validation loss: 2.0392621717145367

Epoch: 5| Step: 4
Training loss: 1.5729663372039795
Validation loss: 2.044664175279679

Epoch: 5| Step: 5
Training loss: 2.367809772491455
Validation loss: 2.056368074109477

Epoch: 5| Step: 6
Training loss: 1.2269760370254517
Validation loss: 2.104491574789888

Epoch: 5| Step: 7
Training loss: 1.4949204921722412
Validation loss: 2.1841482167602866

Epoch: 5| Step: 8
Training loss: 0.9009518623352051
Validation loss: 2.1942341327667236

Epoch: 5| Step: 9
Training loss: 2.160125494003296
Validation loss: 2.163969953854879

Epoch: 5| Step: 10
Training loss: 1.7969080209732056
Validation loss: 2.1147132022406465

Epoch: 250| Step: 0
Training loss: 2.524200916290283
Validation loss: 2.0788333454439716

Epoch: 5| Step: 1
Training loss: 1.4100291728973389
Validation loss: 2.0654194739557084

Epoch: 5| Step: 2
Training loss: 1.844294786453247
Validation loss: 2.049871375483851

Epoch: 5| Step: 3
Training loss: 1.692051887512207
Validation loss: 2.062883015601866

Epoch: 5| Step: 4
Training loss: 1.8802133798599243
Validation loss: 2.0713995874568982

Epoch: 5| Step: 5
Training loss: 2.012995481491089
Validation loss: 2.0556483268737793

Epoch: 5| Step: 6
Training loss: 1.3407142162322998
Validation loss: 2.0521827692626626

Epoch: 5| Step: 7
Training loss: 2.0483596324920654
Validation loss: 2.0336145636855916

Epoch: 5| Step: 8
Training loss: 2.099473714828491
Validation loss: 2.0288405418395996

Epoch: 5| Step: 9
Training loss: 1.3102458715438843
Validation loss: 2.033001007572297

Epoch: 5| Step: 10
Training loss: 1.0659149885177612
Validation loss: 2.0273403467670565

Epoch: 251| Step: 0
Training loss: 1.3272254467010498
Validation loss: 2.035080176527782

Epoch: 5| Step: 1
Training loss: 1.705447793006897
Validation loss: 2.0867145651130268

Epoch: 5| Step: 2
Training loss: 2.028109550476074
Validation loss: 2.1133105754852295

Epoch: 5| Step: 3
Training loss: 1.2051409482955933
Validation loss: 2.1205356531245734

Epoch: 5| Step: 4
Training loss: 1.2471745014190674
Validation loss: 2.0656871423926404

Epoch: 5| Step: 5
Training loss: 2.4898667335510254
Validation loss: 2.051176009639617

Epoch: 5| Step: 6
Training loss: 1.3798105716705322
Validation loss: 2.0462148189544678

Epoch: 5| Step: 7
Training loss: 1.2409875392913818
Validation loss: 2.0097479333159742

Epoch: 5| Step: 8
Training loss: 2.282829523086548
Validation loss: 2.009233920804916

Epoch: 5| Step: 9
Training loss: 2.143425703048706
Validation loss: 2.011578793166786

Epoch: 5| Step: 10
Training loss: 1.878373146057129
Validation loss: 2.0200623158485658

Epoch: 252| Step: 0
Training loss: 2.393110752105713
Validation loss: 2.019410293589356

Epoch: 5| Step: 1
Training loss: 1.5509719848632812
Validation loss: 2.031512503982872

Epoch: 5| Step: 2
Training loss: 1.7106502056121826
Validation loss: 2.027849528097337

Epoch: 5| Step: 3
Training loss: 1.5083730220794678
Validation loss: 2.020020519533465

Epoch: 5| Step: 4
Training loss: 1.454228162765503
Validation loss: 2.0415297092929965

Epoch: 5| Step: 5
Training loss: 2.0075623989105225
Validation loss: 2.070445286330356

Epoch: 5| Step: 6
Training loss: 1.6267671585083008
Validation loss: 2.0964387078439035

Epoch: 5| Step: 7
Training loss: 1.2516556978225708
Validation loss: 2.1422599925789783

Epoch: 5| Step: 8
Training loss: 1.7467743158340454
Validation loss: 2.1777019577641643

Epoch: 5| Step: 9
Training loss: 1.8650245666503906
Validation loss: 2.1466194327159593

Epoch: 5| Step: 10
Training loss: 1.731017827987671
Validation loss: 2.086704961715206

Epoch: 253| Step: 0
Training loss: 1.464136004447937
Validation loss: 2.0575886105978363

Epoch: 5| Step: 1
Training loss: 1.5741287469863892
Validation loss: 2.037571043096563

Epoch: 5| Step: 2
Training loss: 2.0702223777770996
Validation loss: 2.036662286327731

Epoch: 5| Step: 3
Training loss: 1.685428261756897
Validation loss: 2.0252530497889363

Epoch: 5| Step: 4
Training loss: 1.640582799911499
Validation loss: 2.0219294383961666

Epoch: 5| Step: 5
Training loss: 1.5992517471313477
Validation loss: 2.033933360089538

Epoch: 5| Step: 6
Training loss: 1.72481369972229
Validation loss: 2.0375466231376893

Epoch: 5| Step: 7
Training loss: 1.3665587902069092
Validation loss: 2.044650646948045

Epoch: 5| Step: 8
Training loss: 1.367370367050171
Validation loss: 2.065692235064763

Epoch: 5| Step: 9
Training loss: 1.9575989246368408
Validation loss: 2.0747619880143033

Epoch: 5| Step: 10
Training loss: 2.1731204986572266
Validation loss: 2.0697475864041235

Epoch: 254| Step: 0
Training loss: 1.64617919921875
Validation loss: 2.0574490793289675

Epoch: 5| Step: 1
Training loss: 1.9584705829620361
Validation loss: 2.0483878453572593

Epoch: 5| Step: 2
Training loss: 2.0619826316833496
Validation loss: 2.0472307269291212

Epoch: 5| Step: 3
Training loss: 1.4739506244659424
Validation loss: 2.0300360956499652

Epoch: 5| Step: 4
Training loss: 1.9329957962036133
Validation loss: 2.0346570591772757

Epoch: 5| Step: 5
Training loss: 1.6939802169799805
Validation loss: 2.0339560252363964

Epoch: 5| Step: 6
Training loss: 1.8144540786743164
Validation loss: 2.0215586795601794

Epoch: 5| Step: 7
Training loss: 1.3813350200653076
Validation loss: 2.0134421702354186

Epoch: 5| Step: 8
Training loss: 1.3880406618118286
Validation loss: 2.0295650779560046

Epoch: 5| Step: 9
Training loss: 1.3227636814117432
Validation loss: 2.0252691161247993

Epoch: 5| Step: 10
Training loss: 1.6780600547790527
Validation loss: 2.0231671025676112

Epoch: 255| Step: 0
Training loss: 1.8956273794174194
Validation loss: 2.0083136532896306

Epoch: 5| Step: 1
Training loss: 1.9282341003417969
Validation loss: 2.0331503345120336

Epoch: 5| Step: 2
Training loss: 2.2949509620666504
Validation loss: 2.0448253744391987

Epoch: 5| Step: 3
Training loss: 1.0143935680389404
Validation loss: 2.041145501598235

Epoch: 5| Step: 4
Training loss: 1.6188138723373413
Validation loss: 2.0308615751163934

Epoch: 5| Step: 5
Training loss: 1.754194974899292
Validation loss: 2.0463876660152147

Epoch: 5| Step: 6
Training loss: 1.3622983694076538
Validation loss: 2.0410567470776138

Epoch: 5| Step: 7
Training loss: 1.3066039085388184
Validation loss: 2.039728436418759

Epoch: 5| Step: 8
Training loss: 1.6739442348480225
Validation loss: 2.0377384475482407

Epoch: 5| Step: 9
Training loss: 1.8291213512420654
Validation loss: 2.0118865556614374

Epoch: 5| Step: 10
Training loss: 1.5481741428375244
Validation loss: 1.9990140802116805

Epoch: 256| Step: 0
Training loss: 1.4913957118988037
Validation loss: 1.989662903611378

Epoch: 5| Step: 1
Training loss: 2.2475903034210205
Validation loss: 1.9893637049582698

Epoch: 5| Step: 2
Training loss: 1.7598129510879517
Validation loss: 2.018824387622136

Epoch: 5| Step: 3
Training loss: 1.3586872816085815
Validation loss: 2.035209301979311

Epoch: 5| Step: 4
Training loss: 1.5368905067443848
Validation loss: 2.0441198425908245

Epoch: 5| Step: 5
Training loss: 1.801370620727539
Validation loss: 2.0457098022583993

Epoch: 5| Step: 6
Training loss: 1.66567862033844
Validation loss: 2.0556681463795323

Epoch: 5| Step: 7
Training loss: 0.875357449054718
Validation loss: 2.0399081348091044

Epoch: 5| Step: 8
Training loss: 1.7642548084259033
Validation loss: 2.03610852713226

Epoch: 5| Step: 9
Training loss: 1.8696197271347046
Validation loss: 2.036438816337175

Epoch: 5| Step: 10
Training loss: 1.8672688007354736
Validation loss: 2.050265565995247

Epoch: 257| Step: 0
Training loss: 1.635290503501892
Validation loss: 2.0530788565194733

Epoch: 5| Step: 1
Training loss: 1.7253618240356445
Validation loss: 2.056784816967544

Epoch: 5| Step: 2
Training loss: 1.4234665632247925
Validation loss: 2.0760674630441973

Epoch: 5| Step: 3
Training loss: 2.2451858520507812
Validation loss: 2.0579074992928454

Epoch: 5| Step: 4
Training loss: 1.3781946897506714
Validation loss: 2.0620941321055093

Epoch: 5| Step: 5
Training loss: 1.6163580417633057
Validation loss: 2.076878333604464

Epoch: 5| Step: 6
Training loss: 1.3012031316757202
Validation loss: 2.057462748660836

Epoch: 5| Step: 7
Training loss: 1.4082481861114502
Validation loss: 2.042765323833753

Epoch: 5| Step: 8
Training loss: 1.8496849536895752
Validation loss: 2.0547767326396

Epoch: 5| Step: 9
Training loss: 2.1566872596740723
Validation loss: 2.022835927624856

Epoch: 5| Step: 10
Training loss: 1.398575782775879
Validation loss: 2.0187645445587816

Epoch: 258| Step: 0
Training loss: 1.5025330781936646
Validation loss: 2.0214130237538326

Epoch: 5| Step: 1
Training loss: 1.530408263206482
Validation loss: 2.0220584074656167

Epoch: 5| Step: 2
Training loss: 1.714154839515686
Validation loss: 2.008645637061006

Epoch: 5| Step: 3
Training loss: 1.5200575590133667
Validation loss: 2.0429891514521774

Epoch: 5| Step: 4
Training loss: 1.601034164428711
Validation loss: 2.0630202331850604

Epoch: 5| Step: 5
Training loss: 1.5919570922851562
Validation loss: 2.0778704932940903

Epoch: 5| Step: 6
Training loss: 1.5528206825256348
Validation loss: 2.066844314657232

Epoch: 5| Step: 7
Training loss: 2.03155779838562
Validation loss: 2.054828320780108

Epoch: 5| Step: 8
Training loss: 1.3126590251922607
Validation loss: 2.048899035299978

Epoch: 5| Step: 9
Training loss: 1.8353372812271118
Validation loss: 2.038724225054505

Epoch: 5| Step: 10
Training loss: 2.043367862701416
Validation loss: 2.0261334693560036

Epoch: 259| Step: 0
Training loss: 1.242591142654419
Validation loss: 2.023473648614781

Epoch: 5| Step: 1
Training loss: 1.2357532978057861
Validation loss: 2.0015099548524424

Epoch: 5| Step: 2
Training loss: 2.2486557960510254
Validation loss: 2.0036576845312632

Epoch: 5| Step: 3
Training loss: 1.4665496349334717
Validation loss: 1.9993133109102967

Epoch: 5| Step: 4
Training loss: 1.284850835800171
Validation loss: 2.0083211314293647

Epoch: 5| Step: 5
Training loss: 1.206283450126648
Validation loss: 2.0290334442610383

Epoch: 5| Step: 6
Training loss: 1.8899965286254883
Validation loss: 2.045543632199687

Epoch: 5| Step: 7
Training loss: 1.7361996173858643
Validation loss: 2.046621081649616

Epoch: 5| Step: 8
Training loss: 2.0930542945861816
Validation loss: 2.049750998455991

Epoch: 5| Step: 9
Training loss: 1.2928857803344727
Validation loss: 2.054358251633183

Epoch: 5| Step: 10
Training loss: 2.4794206619262695
Validation loss: 2.022721318788426

Epoch: 260| Step: 0
Training loss: 1.8237804174423218
Validation loss: 2.010742272100141

Epoch: 5| Step: 1
Training loss: 1.4646906852722168
Validation loss: 2.002131651806575

Epoch: 5| Step: 2
Training loss: 1.1186445951461792
Validation loss: 2.01831833265161

Epoch: 5| Step: 3
Training loss: 2.333538770675659
Validation loss: 2.019067325899678

Epoch: 5| Step: 4
Training loss: 1.6617568731307983
Validation loss: 2.02085082761703

Epoch: 5| Step: 5
Training loss: 1.4756526947021484
Validation loss: 2.027802598091864

Epoch: 5| Step: 6
Training loss: 1.570467472076416
Validation loss: 2.012121151852351

Epoch: 5| Step: 7
Training loss: 1.224050760269165
Validation loss: 2.0245743208034064

Epoch: 5| Step: 8
Training loss: 1.9876420497894287
Validation loss: 2.0180433052842335

Epoch: 5| Step: 9
Training loss: 1.8724607229232788
Validation loss: 2.030807113134733

Epoch: 5| Step: 10
Training loss: 1.3670707941055298
Validation loss: 2.0195417429811213

Epoch: 261| Step: 0
Training loss: 1.3636759519577026
Validation loss: 2.0499850755096762

Epoch: 5| Step: 1
Training loss: 1.3906476497650146
Validation loss: 2.0402270517041607

Epoch: 5| Step: 2
Training loss: 0.9480697512626648
Validation loss: 2.047759399619154

Epoch: 5| Step: 3
Training loss: 1.573045015335083
Validation loss: 2.067283873916954

Epoch: 5| Step: 4
Training loss: 1.996861219406128
Validation loss: 2.0610629781599967

Epoch: 5| Step: 5
Training loss: 2.519392490386963
Validation loss: 2.0965903023237824

Epoch: 5| Step: 6
Training loss: 1.7955129146575928
Validation loss: 2.105889710046912

Epoch: 5| Step: 7
Training loss: 1.1897462606430054
Validation loss: 2.090981537295926

Epoch: 5| Step: 8
Training loss: 1.6387035846710205
Validation loss: 2.071138487067274

Epoch: 5| Step: 9
Training loss: 2.0295803546905518
Validation loss: 2.0149502279937908

Epoch: 5| Step: 10
Training loss: 1.6044102907180786
Validation loss: 1.9952106450193672

Epoch: 262| Step: 0
Training loss: 1.3510806560516357
Validation loss: 1.9592419260291642

Epoch: 5| Step: 1
Training loss: 1.686191201210022
Validation loss: 1.9618900334963234

Epoch: 5| Step: 2
Training loss: 1.7635300159454346
Validation loss: 1.9742831722382577

Epoch: 5| Step: 3
Training loss: 2.159316062927246
Validation loss: 1.9637591121017293

Epoch: 5| Step: 4
Training loss: 1.4050452709197998
Validation loss: 1.9798618619159987

Epoch: 5| Step: 5
Training loss: 2.4758524894714355
Validation loss: 2.0112548361542406

Epoch: 5| Step: 6
Training loss: 0.9017524719238281
Validation loss: 2.0542573518650507

Epoch: 5| Step: 7
Training loss: 1.8325891494750977
Validation loss: 2.094758361898443

Epoch: 5| Step: 8
Training loss: 2.0140175819396973
Validation loss: 2.125754884494248

Epoch: 5| Step: 9
Training loss: 1.0341846942901611
Validation loss: 2.0584529753654235

Epoch: 5| Step: 10
Training loss: 1.780705213546753
Validation loss: 2.0164255903613184

Epoch: 263| Step: 0
Training loss: 1.939004898071289
Validation loss: 2.013240506572108

Epoch: 5| Step: 1
Training loss: 1.8126277923583984
Validation loss: 2.0250570953533216

Epoch: 5| Step: 2
Training loss: 1.3666973114013672
Validation loss: 2.006257591709014

Epoch: 5| Step: 3
Training loss: 1.5334193706512451
Validation loss: 1.9905656460792787

Epoch: 5| Step: 4
Training loss: 1.4775407314300537
Validation loss: 2.024505240942842

Epoch: 5| Step: 5
Training loss: 1.731705665588379
Validation loss: 2.0109081511856406

Epoch: 5| Step: 6
Training loss: 0.8800989389419556
Validation loss: 2.0149846487147833

Epoch: 5| Step: 7
Training loss: 1.5265252590179443
Validation loss: 2.0409974616060973

Epoch: 5| Step: 8
Training loss: 1.7789911031723022
Validation loss: 2.0493306318918862

Epoch: 5| Step: 9
Training loss: 1.9649912118911743
Validation loss: 2.0557665260889197

Epoch: 5| Step: 10
Training loss: 1.8156442642211914
Validation loss: 2.0744308246079313

Epoch: 264| Step: 0
Training loss: 1.4456496238708496
Validation loss: 2.064640639930643

Epoch: 5| Step: 1
Training loss: 1.6535625457763672
Validation loss: 2.030896887984327

Epoch: 5| Step: 2
Training loss: 1.751721739768982
Validation loss: 2.019131382306417

Epoch: 5| Step: 3
Training loss: 1.5888707637786865
Validation loss: 2.0299222994876165

Epoch: 5| Step: 4
Training loss: 1.709005355834961
Validation loss: 2.027286139867639

Epoch: 5| Step: 5
Training loss: 1.4331731796264648
Validation loss: 2.029379023018704

Epoch: 5| Step: 6
Training loss: 1.8433263301849365
Validation loss: 2.009116934191796

Epoch: 5| Step: 7
Training loss: 1.6402771472930908
Validation loss: 2.0116615474865003

Epoch: 5| Step: 8
Training loss: 1.6923004388809204
Validation loss: 2.0013915518278718

Epoch: 5| Step: 9
Training loss: 1.6514495611190796
Validation loss: 1.9952117127756919

Epoch: 5| Step: 10
Training loss: 1.2140846252441406
Validation loss: 1.9795348259710497

Epoch: 265| Step: 0
Training loss: 2.0858798027038574
Validation loss: 1.9960373306787142

Epoch: 5| Step: 1
Training loss: 1.3614864349365234
Validation loss: 2.0034316714091966

Epoch: 5| Step: 2
Training loss: 1.066906452178955
Validation loss: 2.0192529155362036

Epoch: 5| Step: 3
Training loss: 1.4450576305389404
Validation loss: 2.050553475656817

Epoch: 5| Step: 4
Training loss: 1.9198544025421143
Validation loss: 2.070549531649518

Epoch: 5| Step: 5
Training loss: 1.8923957347869873
Validation loss: 2.0250606613774456

Epoch: 5| Step: 6
Training loss: 2.2431068420410156
Validation loss: 2.011984904607137

Epoch: 5| Step: 7
Training loss: 1.4102634191513062
Validation loss: 2.015241438342679

Epoch: 5| Step: 8
Training loss: 1.1959562301635742
Validation loss: 2.00002577740659

Epoch: 5| Step: 9
Training loss: 1.3564096689224243
Validation loss: 1.9941018691626928

Epoch: 5| Step: 10
Training loss: 1.7549095153808594
Validation loss: 2.008075257783295

Epoch: 266| Step: 0
Training loss: 0.9259563684463501
Validation loss: 2.036654790242513

Epoch: 5| Step: 1
Training loss: 1.5142419338226318
Validation loss: 2.0376600924358574

Epoch: 5| Step: 2
Training loss: 1.5798723697662354
Validation loss: 2.061629723477107

Epoch: 5| Step: 3
Training loss: 1.7242963314056396
Validation loss: 2.081300457318624

Epoch: 5| Step: 4
Training loss: 1.858919382095337
Validation loss: 2.089146514092722

Epoch: 5| Step: 5
Training loss: 1.680579423904419
Validation loss: 2.076168267957626

Epoch: 5| Step: 6
Training loss: 1.7924871444702148
Validation loss: 2.055929212160008

Epoch: 5| Step: 7
Training loss: 1.2096617221832275
Validation loss: 2.011818608930034

Epoch: 5| Step: 8
Training loss: 1.4693235158920288
Validation loss: 1.9990259819133307

Epoch: 5| Step: 9
Training loss: 1.5129096508026123
Validation loss: 1.9827593103531869

Epoch: 5| Step: 10
Training loss: 2.3530983924865723
Validation loss: 1.9804339895966232

Epoch: 267| Step: 0
Training loss: 1.6932868957519531
Validation loss: 1.976752346561801

Epoch: 5| Step: 1
Training loss: 1.0087661743164062
Validation loss: 1.9693531349141111

Epoch: 5| Step: 2
Training loss: 1.9622795581817627
Validation loss: 1.9941627389641219

Epoch: 5| Step: 3
Training loss: 1.5701336860656738
Validation loss: 1.991930361716978

Epoch: 5| Step: 4
Training loss: 1.2906758785247803
Validation loss: 1.9939319907978017

Epoch: 5| Step: 5
Training loss: 1.5081478357315063
Validation loss: 2.003475002063218

Epoch: 5| Step: 6
Training loss: 1.382017970085144
Validation loss: 2.0552110082359722

Epoch: 5| Step: 7
Training loss: 1.6723343133926392
Validation loss: 2.1297451808888423

Epoch: 5| Step: 8
Training loss: 2.3256735801696777
Validation loss: 2.1431766222882014

Epoch: 5| Step: 9
Training loss: 1.4963539838790894
Validation loss: 2.131922060443509

Epoch: 5| Step: 10
Training loss: 1.6789112091064453
Validation loss: 2.08825058321799

Epoch: 268| Step: 0
Training loss: 1.5447121858596802
Validation loss: 2.0335471835187686

Epoch: 5| Step: 1
Training loss: 1.677337646484375
Validation loss: 2.0398949371871127

Epoch: 5| Step: 2
Training loss: 1.5129224061965942
Validation loss: 2.019091089566549

Epoch: 5| Step: 3
Training loss: 1.9342800378799438
Validation loss: 2.048236108595325

Epoch: 5| Step: 4
Training loss: 1.3184359073638916
Validation loss: 2.0171526555092103

Epoch: 5| Step: 5
Training loss: 1.596893072128296
Validation loss: 2.0163541763059554

Epoch: 5| Step: 6
Training loss: 1.9668165445327759
Validation loss: 1.9918031256685975

Epoch: 5| Step: 7
Training loss: 1.3875155448913574
Validation loss: 2.026649171306241

Epoch: 5| Step: 8
Training loss: 1.6542829275131226
Validation loss: 2.0564655078354703

Epoch: 5| Step: 9
Training loss: 1.7370336055755615
Validation loss: 2.153625790790845

Epoch: 5| Step: 10
Training loss: 1.678850531578064
Validation loss: 2.1407560815093336

Epoch: 269| Step: 0
Training loss: 1.4140650033950806
Validation loss: 2.1115478828389156

Epoch: 5| Step: 1
Training loss: 1.3909231424331665
Validation loss: 2.0722391169558287

Epoch: 5| Step: 2
Training loss: 1.8088462352752686
Validation loss: 2.0377802207905757

Epoch: 5| Step: 3
Training loss: 1.4949605464935303
Validation loss: 2.0018140423682427

Epoch: 5| Step: 4
Training loss: 1.7730880975723267
Validation loss: 1.9912540322990828

Epoch: 5| Step: 5
Training loss: 1.5753545761108398
Validation loss: 1.9804848817086989

Epoch: 5| Step: 6
Training loss: 1.6741869449615479
Validation loss: 1.9809273801824099

Epoch: 5| Step: 7
Training loss: 1.8252155780792236
Validation loss: 1.9853749826390257

Epoch: 5| Step: 8
Training loss: 1.4035980701446533
Validation loss: 1.9985731160768898

Epoch: 5| Step: 9
Training loss: 1.638074517250061
Validation loss: 1.981848568044683

Epoch: 5| Step: 10
Training loss: 1.6956218481063843
Validation loss: 2.0063467910212855

Epoch: 270| Step: 0
Training loss: 1.1953940391540527
Validation loss: 2.0042965386503484

Epoch: 5| Step: 1
Training loss: 1.7118288278579712
Validation loss: 1.9874024955175256

Epoch: 5| Step: 2
Training loss: 1.6751960515975952
Validation loss: 1.9925954341888428

Epoch: 5| Step: 3
Training loss: 1.3495018482208252
Validation loss: 2.015235024113809

Epoch: 5| Step: 4
Training loss: 1.8332288265228271
Validation loss: 2.0738071831323768

Epoch: 5| Step: 5
Training loss: 1.8173227310180664
Validation loss: 2.094458951744982

Epoch: 5| Step: 6
Training loss: 1.5605655908584595
Validation loss: 2.1115914083296254

Epoch: 5| Step: 7
Training loss: 1.5833998918533325
Validation loss: 2.0874439811193817

Epoch: 5| Step: 8
Training loss: 1.6047214269638062
Validation loss: 2.028406987908066

Epoch: 5| Step: 9
Training loss: 1.3042898178100586
Validation loss: 2.005964917521323

Epoch: 5| Step: 10
Training loss: 1.814945936203003
Validation loss: 2.00809060629978

Epoch: 271| Step: 0
Training loss: 0.9915518760681152
Validation loss: 1.97949892474759

Epoch: 5| Step: 1
Training loss: 1.6414600610733032
Validation loss: 1.9847158693498181

Epoch: 5| Step: 2
Training loss: 1.891510009765625
Validation loss: 1.980568321802283

Epoch: 5| Step: 3
Training loss: 1.3786349296569824
Validation loss: 1.9829032831294562

Epoch: 5| Step: 4
Training loss: 0.6869252324104309
Validation loss: 1.9873683862788702

Epoch: 5| Step: 5
Training loss: 1.9910377264022827
Validation loss: 1.980385415015682

Epoch: 5| Step: 6
Training loss: 1.7333297729492188
Validation loss: 1.98152659913545

Epoch: 5| Step: 7
Training loss: 1.9870754480361938
Validation loss: 1.9890585560952463

Epoch: 5| Step: 8
Training loss: 1.687967300415039
Validation loss: 1.975018391045191

Epoch: 5| Step: 9
Training loss: 1.8358666896820068
Validation loss: 1.9914990035436486

Epoch: 5| Step: 10
Training loss: 1.4006584882736206
Validation loss: 2.020057947404923

Epoch: 272| Step: 0
Training loss: 1.6720187664031982
Validation loss: 2.055246432622274

Epoch: 5| Step: 1
Training loss: 1.4121522903442383
Validation loss: 2.0413214442550496

Epoch: 5| Step: 2
Training loss: 2.001575231552124
Validation loss: 2.040349145089426

Epoch: 5| Step: 3
Training loss: 1.0688798427581787
Validation loss: 2.045456963200723

Epoch: 5| Step: 4
Training loss: 1.7128196954727173
Validation loss: 2.011949118747506

Epoch: 5| Step: 5
Training loss: 1.9836666584014893
Validation loss: 1.9842770945641302

Epoch: 5| Step: 6
Training loss: 1.231818437576294
Validation loss: 2.009536161217638

Epoch: 5| Step: 7
Training loss: 1.1885417699813843
Validation loss: 1.9984695937043877

Epoch: 5| Step: 8
Training loss: 1.645085096359253
Validation loss: 1.9804800556552025

Epoch: 5| Step: 9
Training loss: 1.993600845336914
Validation loss: 1.9643293631974088

Epoch: 5| Step: 10
Training loss: 1.3021836280822754
Validation loss: 1.9768638444203201

Epoch: 273| Step: 0
Training loss: 1.6280879974365234
Validation loss: 1.977855420881702

Epoch: 5| Step: 1
Training loss: 1.5830376148223877
Validation loss: 1.9852779219227452

Epoch: 5| Step: 2
Training loss: 1.7542616128921509
Validation loss: 1.9959347324986612

Epoch: 5| Step: 3
Training loss: 1.6156225204467773
Validation loss: 2.0115844126670592

Epoch: 5| Step: 4
Training loss: 1.8216403722763062
Validation loss: 2.014463537482805

Epoch: 5| Step: 5
Training loss: 1.5704244375228882
Validation loss: 2.0173553382196734

Epoch: 5| Step: 6
Training loss: 1.0112568140029907
Validation loss: 2.0191928725088797

Epoch: 5| Step: 7
Training loss: 1.6119625568389893
Validation loss: 2.0303646236337642

Epoch: 5| Step: 8
Training loss: 1.4166781902313232
Validation loss: 2.027068554714162

Epoch: 5| Step: 9
Training loss: 1.2516225576400757
Validation loss: 2.05855232028551

Epoch: 5| Step: 10
Training loss: 1.8706142902374268
Validation loss: 2.107807654206471

Epoch: 274| Step: 0
Training loss: 1.8822782039642334
Validation loss: 2.1008445255218016

Epoch: 5| Step: 1
Training loss: 1.597619891166687
Validation loss: 2.1094053304323586

Epoch: 5| Step: 2
Training loss: 2.0320117473602295
Validation loss: 2.0554599864508516

Epoch: 5| Step: 3
Training loss: 1.2362463474273682
Validation loss: 2.0170663954109274

Epoch: 5| Step: 4
Training loss: 1.5430667400360107
Validation loss: 2.0015652769355365

Epoch: 5| Step: 5
Training loss: 1.1193748712539673
Validation loss: 1.9884298027202647

Epoch: 5| Step: 6
Training loss: 1.597762942314148
Validation loss: 1.972901132798964

Epoch: 5| Step: 7
Training loss: 1.3166728019714355
Validation loss: 1.9775355631305325

Epoch: 5| Step: 8
Training loss: 1.4644159078598022
Validation loss: 1.9812569156769784

Epoch: 5| Step: 9
Training loss: 1.4784003496170044
Validation loss: 1.988579224514705

Epoch: 5| Step: 10
Training loss: 2.1796627044677734
Validation loss: 1.9838591288494807

Epoch: 275| Step: 0
Training loss: 2.278655529022217
Validation loss: 2.0121557122917584

Epoch: 5| Step: 1
Training loss: 1.371053695678711
Validation loss: 2.0394094528690463

Epoch: 5| Step: 2
Training loss: 1.4394731521606445
Validation loss: 2.048747206246981

Epoch: 5| Step: 3
Training loss: 1.754319429397583
Validation loss: 2.0366012357896373

Epoch: 5| Step: 4
Training loss: 1.3516230583190918
Validation loss: 2.0713544199543614

Epoch: 5| Step: 5
Training loss: 1.1990169286727905
Validation loss: 2.0682926626615625

Epoch: 5| Step: 6
Training loss: 1.442926287651062
Validation loss: 2.084383286455626

Epoch: 5| Step: 7
Training loss: 1.9893262386322021
Validation loss: 2.045233645746785

Epoch: 5| Step: 8
Training loss: 1.6105865240097046
Validation loss: 2.0619138876597085

Epoch: 5| Step: 9
Training loss: 1.2801692485809326
Validation loss: 2.0251563338823217

Epoch: 5| Step: 10
Training loss: 1.259870171546936
Validation loss: 2.0110027277341453

Epoch: 276| Step: 0
Training loss: 1.3108454942703247
Validation loss: 2.006228152141776

Epoch: 5| Step: 1
Training loss: 1.5021865367889404
Validation loss: 1.9968488626582648

Epoch: 5| Step: 2
Training loss: 1.532135009765625
Validation loss: 1.998010955831056

Epoch: 5| Step: 3
Training loss: 1.4528892040252686
Validation loss: 2.020911044971917

Epoch: 5| Step: 4
Training loss: 1.4362022876739502
Validation loss: 2.0427099594505886

Epoch: 5| Step: 5
Training loss: 1.5048353672027588
Validation loss: 2.0590978412217993

Epoch: 5| Step: 6
Training loss: 2.5551161766052246
Validation loss: 2.068824383520311

Epoch: 5| Step: 7
Training loss: 1.3068207502365112
Validation loss: 2.0325322125547673

Epoch: 5| Step: 8
Training loss: 2.168600559234619
Validation loss: 2.0062893180436987

Epoch: 5| Step: 9
Training loss: 0.9636300802230835
Validation loss: 2.0152869045093493

Epoch: 5| Step: 10
Training loss: 1.1273410320281982
Validation loss: 2.00602751393472

Epoch: 277| Step: 0
Training loss: 1.5738263130187988
Validation loss: 2.031139653216126

Epoch: 5| Step: 1
Training loss: 1.1034622192382812
Validation loss: 2.040948124342067

Epoch: 5| Step: 2
Training loss: 2.066532611846924
Validation loss: 2.034026550990279

Epoch: 5| Step: 3
Training loss: 1.9332507848739624
Validation loss: 2.0349447111929617

Epoch: 5| Step: 4
Training loss: 1.2787576913833618
Validation loss: 2.0641250661624375

Epoch: 5| Step: 5
Training loss: 1.784050703048706
Validation loss: 2.093694713807875

Epoch: 5| Step: 6
Training loss: 1.325812578201294
Validation loss: 2.1326776755753385

Epoch: 5| Step: 7
Training loss: 1.9748386144638062
Validation loss: 2.1371595244253836

Epoch: 5| Step: 8
Training loss: 1.4126060009002686
Validation loss: 2.111501678343742

Epoch: 5| Step: 9
Training loss: 1.4143692255020142
Validation loss: 2.0728076606668453

Epoch: 5| Step: 10
Training loss: 1.009167194366455
Validation loss: 2.0121265662613737

Epoch: 278| Step: 0
Training loss: 1.5099961757659912
Validation loss: 1.9768889693803684

Epoch: 5| Step: 1
Training loss: 1.8998740911483765
Validation loss: 1.9602704894158147

Epoch: 5| Step: 2
Training loss: 1.5804580450057983
Validation loss: 1.958988243533719

Epoch: 5| Step: 3
Training loss: 1.7496623992919922
Validation loss: 1.9644759470416653

Epoch: 5| Step: 4
Training loss: 1.7634906768798828
Validation loss: 1.9467986899037515

Epoch: 5| Step: 5
Training loss: 1.6689493656158447
Validation loss: 1.9609210298907371

Epoch: 5| Step: 6
Training loss: 1.9785597324371338
Validation loss: 1.9964336349118141

Epoch: 5| Step: 7
Training loss: 0.8323949575424194
Validation loss: 2.037350849438739

Epoch: 5| Step: 8
Training loss: 1.1248124837875366
Validation loss: 2.076168898613222

Epoch: 5| Step: 9
Training loss: 1.635824203491211
Validation loss: 2.0877174408205095

Epoch: 5| Step: 10
Training loss: 1.2853212356567383
Validation loss: 2.0886036324244674

Epoch: 279| Step: 0
Training loss: 1.5219377279281616
Validation loss: 2.095111635423476

Epoch: 5| Step: 1
Training loss: 1.531777262687683
Validation loss: 2.0508170332959903

Epoch: 5| Step: 2
Training loss: 2.077413558959961
Validation loss: 2.039569495826639

Epoch: 5| Step: 3
Training loss: 1.7222487926483154
Validation loss: 2.027176854430988

Epoch: 5| Step: 4
Training loss: 1.539320707321167
Validation loss: 2.028464936440991

Epoch: 5| Step: 5
Training loss: 1.923396348953247
Validation loss: 1.9998811752565446

Epoch: 5| Step: 6
Training loss: 1.6183027029037476
Validation loss: 2.0005165069333968

Epoch: 5| Step: 7
Training loss: 1.23538339138031
Validation loss: 1.9838145599570325

Epoch: 5| Step: 8
Training loss: 1.1262049674987793
Validation loss: 1.9824979856450071

Epoch: 5| Step: 9
Training loss: 1.0186179876327515
Validation loss: 2.038494457480728

Epoch: 5| Step: 10
Training loss: 2.130876064300537
Validation loss: 2.0901640717701246

Epoch: 280| Step: 0
Training loss: 1.7919042110443115
Validation loss: 2.1327378365301315

Epoch: 5| Step: 1
Training loss: 1.913378119468689
Validation loss: 2.0829975374283327

Epoch: 5| Step: 2
Training loss: 1.3394192457199097
Validation loss: 2.0420055594495548

Epoch: 5| Step: 3
Training loss: 1.3086813688278198
Validation loss: 1.9903815523270638

Epoch: 5| Step: 4
Training loss: 1.0092304944992065
Validation loss: 1.9604105334128104

Epoch: 5| Step: 5
Training loss: 1.345564603805542
Validation loss: 1.9705691722131544

Epoch: 5| Step: 6
Training loss: 1.5930784940719604
Validation loss: 1.9799733956654866

Epoch: 5| Step: 7
Training loss: 1.9683116674423218
Validation loss: 1.9903640080523748

Epoch: 5| Step: 8
Training loss: 1.6145694255828857
Validation loss: 2.0004447967775407

Epoch: 5| Step: 9
Training loss: 1.2963409423828125
Validation loss: 2.011194489335501

Epoch: 5| Step: 10
Training loss: 2.0242884159088135
Validation loss: 2.0071046121658815

Epoch: 281| Step: 0
Training loss: 1.1072700023651123
Validation loss: 2.007778731725549

Epoch: 5| Step: 1
Training loss: 1.7013626098632812
Validation loss: 2.023028951819225

Epoch: 5| Step: 2
Training loss: 1.7266002893447876
Validation loss: 2.0000200297242854

Epoch: 5| Step: 3
Training loss: 1.2262852191925049
Validation loss: 2.0433975958055064

Epoch: 5| Step: 4
Training loss: 1.7398580312728882
Validation loss: 2.0762055163742392

Epoch: 5| Step: 5
Training loss: 1.8600313663482666
Validation loss: 2.129897509851763

Epoch: 5| Step: 6
Training loss: 1.6460882425308228
Validation loss: 2.0954052863582486

Epoch: 5| Step: 7
Training loss: 1.556708574295044
Validation loss: 2.0604123377030894

Epoch: 5| Step: 8
Training loss: 1.067147970199585
Validation loss: 2.0425110440100394

Epoch: 5| Step: 9
Training loss: 1.7485997676849365
Validation loss: 2.0205167993422477

Epoch: 5| Step: 10
Training loss: 1.3088829517364502
Validation loss: 2.012470419688891

Epoch: 282| Step: 0
Training loss: 1.4208035469055176
Validation loss: 2.0106802025148944

Epoch: 5| Step: 1
Training loss: 1.224064588546753
Validation loss: 2.0060634869401173

Epoch: 5| Step: 2
Training loss: 1.8579299449920654
Validation loss: 1.996104053271714

Epoch: 5| Step: 3
Training loss: 1.5450201034545898
Validation loss: 1.983913206285046

Epoch: 5| Step: 4
Training loss: 1.5932420492172241
Validation loss: 1.9788632521065332

Epoch: 5| Step: 5
Training loss: 1.6398032903671265
Validation loss: 2.0116873505294963

Epoch: 5| Step: 6
Training loss: 1.3103500604629517
Validation loss: 2.0215262110515306

Epoch: 5| Step: 7
Training loss: 1.6909974813461304
Validation loss: 2.04661165770664

Epoch: 5| Step: 8
Training loss: 1.3372503519058228
Validation loss: 2.065690294388802

Epoch: 5| Step: 9
Training loss: 1.3399810791015625
Validation loss: 2.061160582368092

Epoch: 5| Step: 10
Training loss: 1.506420612335205
Validation loss: 2.1039232233519196

Epoch: 283| Step: 0
Training loss: 1.7500852346420288
Validation loss: 2.0753556361762424

Epoch: 5| Step: 1
Training loss: 1.7954292297363281
Validation loss: 2.070763535397027

Epoch: 5| Step: 2
Training loss: 1.356544852256775
Validation loss: 2.0598191394600818

Epoch: 5| Step: 3
Training loss: 1.1926164627075195
Validation loss: 2.070785664742993

Epoch: 5| Step: 4
Training loss: 1.856467843055725
Validation loss: 2.0663553335333384

Epoch: 5| Step: 5
Training loss: 1.0621155500411987
Validation loss: 2.05649080071398

Epoch: 5| Step: 6
Training loss: 1.4514806270599365
Validation loss: 2.0212049112525037

Epoch: 5| Step: 7
Training loss: 1.265267252922058
Validation loss: 2.0343981622367777

Epoch: 5| Step: 8
Training loss: 1.8703111410140991
Validation loss: 2.013529400671682

Epoch: 5| Step: 9
Training loss: 1.2132426500320435
Validation loss: 1.981359480529703

Epoch: 5| Step: 10
Training loss: 1.439661979675293
Validation loss: 1.982802539743403

Epoch: 284| Step: 0
Training loss: 0.901731014251709
Validation loss: 1.9867872935469433

Epoch: 5| Step: 1
Training loss: 0.9408038258552551
Validation loss: 2.0032612739070768

Epoch: 5| Step: 2
Training loss: 1.8215386867523193
Validation loss: 2.008088768169444

Epoch: 5| Step: 3
Training loss: 1.901672124862671
Validation loss: 2.0488857992233767

Epoch: 5| Step: 4
Training loss: 1.2560627460479736
Validation loss: 2.0573327772078978

Epoch: 5| Step: 5
Training loss: 1.024903655052185
Validation loss: 2.047435111896966

Epoch: 5| Step: 6
Training loss: 2.120867967605591
Validation loss: 2.043885354072817

Epoch: 5| Step: 7
Training loss: 0.8626317977905273
Validation loss: 2.0343711812009095

Epoch: 5| Step: 8
Training loss: 1.6998265981674194
Validation loss: 2.0102354941829557

Epoch: 5| Step: 9
Training loss: 2.042938709259033
Validation loss: 2.0174503941689768

Epoch: 5| Step: 10
Training loss: 1.7929892539978027
Validation loss: 1.9951875389263194

Epoch: 285| Step: 0
Training loss: 1.13767409324646
Validation loss: 1.979000481226111

Epoch: 5| Step: 1
Training loss: 1.1537666320800781
Validation loss: 2.005473686802772

Epoch: 5| Step: 2
Training loss: 1.3829189538955688
Validation loss: 1.9918050407081522

Epoch: 5| Step: 3
Training loss: 1.6332823038101196
Validation loss: 1.9969746425587644

Epoch: 5| Step: 4
Training loss: 1.5686737298965454
Validation loss: 2.022173358548072

Epoch: 5| Step: 5
Training loss: 1.5168060064315796
Validation loss: 2.0364094088154454

Epoch: 5| Step: 6
Training loss: 1.7207973003387451
Validation loss: 2.0514364293826524

Epoch: 5| Step: 7
Training loss: 2.0932259559631348
Validation loss: 2.070300514980029

Epoch: 5| Step: 8
Training loss: 1.0102643966674805
Validation loss: 2.064010113798162

Epoch: 5| Step: 9
Training loss: 1.5240191221237183
Validation loss: 2.0289815266927085

Epoch: 5| Step: 10
Training loss: 1.4694706201553345
Validation loss: 2.0010869990112963

Epoch: 286| Step: 0
Training loss: 1.9080286026000977
Validation loss: 1.9816208154924455

Epoch: 5| Step: 1
Training loss: 1.365232229232788
Validation loss: 1.9789460410353958

Epoch: 5| Step: 2
Training loss: 1.3106173276901245
Validation loss: 1.9591337942307996

Epoch: 5| Step: 3
Training loss: 1.5256975889205933
Validation loss: 1.9601276356686828

Epoch: 5| Step: 4
Training loss: 1.5634211301803589
Validation loss: 1.9702933308898762

Epoch: 5| Step: 5
Training loss: 1.2808191776275635
Validation loss: 1.9726286677904026

Epoch: 5| Step: 6
Training loss: 1.2949881553649902
Validation loss: 2.0002644574770363

Epoch: 5| Step: 7
Training loss: 1.5798367261886597
Validation loss: 2.0602327777493383

Epoch: 5| Step: 8
Training loss: 1.850006103515625
Validation loss: 2.0724087479293987

Epoch: 5| Step: 9
Training loss: 1.5103671550750732
Validation loss: 2.047177839022811

Epoch: 5| Step: 10
Training loss: 1.0767422914505005
Validation loss: 2.00853939594761

Epoch: 287| Step: 0
Training loss: 1.366607666015625
Validation loss: 1.9932075021087483

Epoch: 5| Step: 1
Training loss: 1.6053955554962158
Validation loss: 2.00641788974885

Epoch: 5| Step: 2
Training loss: 1.2849503755569458
Validation loss: 2.0075348897646834

Epoch: 5| Step: 3
Training loss: 1.9908396005630493
Validation loss: 1.999981636642128

Epoch: 5| Step: 4
Training loss: 1.382955551147461
Validation loss: 1.9987421292130665

Epoch: 5| Step: 5
Training loss: 1.3116496801376343
Validation loss: 2.0237364358799432

Epoch: 5| Step: 6
Training loss: 1.0483405590057373
Validation loss: 2.004021413864628

Epoch: 5| Step: 7
Training loss: 1.9603592157363892
Validation loss: 2.0013379832749725

Epoch: 5| Step: 8
Training loss: 1.8468650579452515
Validation loss: 1.9912478462342293

Epoch: 5| Step: 9
Training loss: 0.9942226409912109
Validation loss: 1.9848704273982714

Epoch: 5| Step: 10
Training loss: 1.28408944606781
Validation loss: 1.9981056285160843

Epoch: 288| Step: 0
Training loss: 1.749084711074829
Validation loss: 1.9782658392383206

Epoch: 5| Step: 1
Training loss: 1.2178891897201538
Validation loss: 1.9821881927469724

Epoch: 5| Step: 2
Training loss: 1.7297859191894531
Validation loss: 1.9981958212391022

Epoch: 5| Step: 3
Training loss: 1.7407306432724
Validation loss: 1.9874131474443661

Epoch: 5| Step: 4
Training loss: 1.3627040386199951
Validation loss: 2.0057880519538798

Epoch: 5| Step: 5
Training loss: 1.3636025190353394
Validation loss: 2.049673512417783

Epoch: 5| Step: 6
Training loss: 1.0989508628845215
Validation loss: 2.044005304254511

Epoch: 5| Step: 7
Training loss: 1.4551260471343994
Validation loss: 2.0665930201930385

Epoch: 5| Step: 8
Training loss: 1.2931406497955322
Validation loss: 2.0888599323970016

Epoch: 5| Step: 9
Training loss: 1.2353546619415283
Validation loss: 2.06289263438153

Epoch: 5| Step: 10
Training loss: 1.7402369976043701
Validation loss: 2.0608330695859847

Epoch: 289| Step: 0
Training loss: 1.6758434772491455
Validation loss: 2.056891720782044

Epoch: 5| Step: 1
Training loss: 1.677079439163208
Validation loss: 2.046402203139438

Epoch: 5| Step: 2
Training loss: 1.0932778120040894
Validation loss: 2.051760288976854

Epoch: 5| Step: 3
Training loss: 1.7362487316131592
Validation loss: 2.0481779857348372

Epoch: 5| Step: 4
Training loss: 1.1726969480514526
Validation loss: 2.0427989523897887

Epoch: 5| Step: 5
Training loss: 1.6908187866210938
Validation loss: 2.0461339924925115

Epoch: 5| Step: 6
Training loss: 1.464081883430481
Validation loss: 2.034309438479844

Epoch: 5| Step: 7
Training loss: 1.0316919088363647
Validation loss: 2.012599998904813

Epoch: 5| Step: 8
Training loss: 1.5625927448272705
Validation loss: 2.0309169369359172

Epoch: 5| Step: 9
Training loss: 1.4099491834640503
Validation loss: 2.035892350699312

Epoch: 5| Step: 10
Training loss: 1.1796449422836304
Validation loss: 2.0309501386457876

Epoch: 290| Step: 0
Training loss: 1.229241132736206
Validation loss: 2.0241719625329457

Epoch: 5| Step: 1
Training loss: 1.2393708229064941
Validation loss: 2.02555416476342

Epoch: 5| Step: 2
Training loss: 1.6132781505584717
Validation loss: 1.988469095640285

Epoch: 5| Step: 3
Training loss: 1.4543240070343018
Validation loss: 1.9717475188675748

Epoch: 5| Step: 4
Training loss: 1.6973899602890015
Validation loss: 1.9732363916212512

Epoch: 5| Step: 5
Training loss: 1.9215404987335205
Validation loss: 1.9730671849302066

Epoch: 5| Step: 6
Training loss: 1.2355859279632568
Validation loss: 1.970499559115338

Epoch: 5| Step: 7
Training loss: 1.7587177753448486
Validation loss: 1.9721478928801834

Epoch: 5| Step: 8
Training loss: 0.8515008091926575
Validation loss: 1.9868181905438822

Epoch: 5| Step: 9
Training loss: 1.1849807500839233
Validation loss: 1.9845464280856553

Epoch: 5| Step: 10
Training loss: 1.6633810997009277
Validation loss: 1.9756612213709022

Epoch: 291| Step: 0
Training loss: 1.1108033657073975
Validation loss: 2.009951533809785

Epoch: 5| Step: 1
Training loss: 1.9245681762695312
Validation loss: 2.028941700535436

Epoch: 5| Step: 2
Training loss: 1.5629003047943115
Validation loss: 2.025137375118912

Epoch: 5| Step: 3
Training loss: 1.92617928981781
Validation loss: 2.0356039924006306

Epoch: 5| Step: 4
Training loss: 1.568105936050415
Validation loss: 2.0144612314880534

Epoch: 5| Step: 5
Training loss: 1.502544641494751
Validation loss: 2.019631476812465

Epoch: 5| Step: 6
Training loss: 1.62026846408844
Validation loss: 2.023192459537137

Epoch: 5| Step: 7
Training loss: 0.5802367925643921
Validation loss: 2.0195437259571527

Epoch: 5| Step: 8
Training loss: 1.100706934928894
Validation loss: 1.9986358855360298

Epoch: 5| Step: 9
Training loss: 2.0443339347839355
Validation loss: 2.010655815883349

Epoch: 5| Step: 10
Training loss: 0.8183456063270569
Validation loss: 1.9976386844470937

Epoch: 292| Step: 0
Training loss: 0.8813353776931763
Validation loss: 2.0030068889740975

Epoch: 5| Step: 1
Training loss: 1.889451026916504
Validation loss: 2.0085714529919367

Epoch: 5| Step: 2
Training loss: 0.7831367254257202
Validation loss: 1.9971725786885908

Epoch: 5| Step: 3
Training loss: 1.4502689838409424
Validation loss: 1.9791515334959953

Epoch: 5| Step: 4
Training loss: 1.5079134702682495
Validation loss: 2.015656227706581

Epoch: 5| Step: 5
Training loss: 1.5395290851593018
Validation loss: 2.033909461831534

Epoch: 5| Step: 6
Training loss: 1.1976890563964844
Validation loss: 2.0166394197812645

Epoch: 5| Step: 7
Training loss: 2.079930305480957
Validation loss: 2.016363746376448

Epoch: 5| Step: 8
Training loss: 1.6590206623077393
Validation loss: 2.00506805604504

Epoch: 5| Step: 9
Training loss: 1.2438703775405884
Validation loss: 2.0049358349974438

Epoch: 5| Step: 10
Training loss: 1.3699309825897217
Validation loss: 1.9889676417073896

Epoch: 293| Step: 0
Training loss: 1.299916386604309
Validation loss: 1.9893081957294094

Epoch: 5| Step: 1
Training loss: 1.6100469827651978
Validation loss: 1.9822653083391086

Epoch: 5| Step: 2
Training loss: 1.5195244550704956
Validation loss: 2.0005678310189197

Epoch: 5| Step: 3
Training loss: 0.9580578804016113
Validation loss: 1.9882378937095724

Epoch: 5| Step: 4
Training loss: 1.092409372329712
Validation loss: 1.9963274617348947

Epoch: 5| Step: 5
Training loss: 1.7080252170562744
Validation loss: 1.9974518014538674

Epoch: 5| Step: 6
Training loss: 1.2808359861373901
Validation loss: 2.0048783492016535

Epoch: 5| Step: 7
Training loss: 1.8347641229629517
Validation loss: 1.9873817383602101

Epoch: 5| Step: 8
Training loss: 1.5122466087341309
Validation loss: 1.991788366789459

Epoch: 5| Step: 9
Training loss: 1.614416480064392
Validation loss: 1.9935933364334928

Epoch: 5| Step: 10
Training loss: 0.8803763389587402
Validation loss: 1.9983911129736132

Epoch: 294| Step: 0
Training loss: 1.4371919631958008
Validation loss: 2.008616844813029

Epoch: 5| Step: 1
Training loss: 1.387296438217163
Validation loss: 1.991425298875378

Epoch: 5| Step: 2
Training loss: 1.362532377243042
Validation loss: 2.046085911412393

Epoch: 5| Step: 3
Training loss: 1.2061522006988525
Validation loss: 2.0027739950405654

Epoch: 5| Step: 4
Training loss: 1.5026088953018188
Validation loss: 2.000265929006761

Epoch: 5| Step: 5
Training loss: 1.1807633638381958
Validation loss: 2.0040249029795327

Epoch: 5| Step: 6
Training loss: 1.278980016708374
Validation loss: 2.000188624987038

Epoch: 5| Step: 7
Training loss: 0.8735203742980957
Validation loss: 1.9842771291732788

Epoch: 5| Step: 8
Training loss: 1.9592773914337158
Validation loss: 1.9795354796994118

Epoch: 5| Step: 9
Training loss: 2.063936233520508
Validation loss: 1.9855679696606052

Epoch: 5| Step: 10
Training loss: 1.0694594383239746
Validation loss: 1.9866212003974504

Epoch: 295| Step: 0
Training loss: 1.2569549083709717
Validation loss: 1.9836296009761032

Epoch: 5| Step: 1
Training loss: 1.8892736434936523
Validation loss: 2.000906567419729

Epoch: 5| Step: 2
Training loss: 1.4486603736877441
Validation loss: 1.9753873476418116

Epoch: 5| Step: 3
Training loss: 0.9632027745246887
Validation loss: 1.9965476541108982

Epoch: 5| Step: 4
Training loss: 1.4991556406021118
Validation loss: 1.9922513218336209

Epoch: 5| Step: 5
Training loss: 1.2796094417572021
Validation loss: 2.0013707068658646

Epoch: 5| Step: 6
Training loss: 1.3930766582489014
Validation loss: 2.021907955087641

Epoch: 5| Step: 7
Training loss: 1.193910837173462
Validation loss: 2.0148029353028987

Epoch: 5| Step: 8
Training loss: 1.4122769832611084
Validation loss: 2.0050632005096762

Epoch: 5| Step: 9
Training loss: 1.5758681297302246
Validation loss: 1.9871126682527605

Epoch: 5| Step: 10
Training loss: 1.2976659536361694
Validation loss: 2.023080331023021

Epoch: 296| Step: 0
Training loss: 1.0131268501281738
Validation loss: 2.026274096581244

Epoch: 5| Step: 1
Training loss: 1.1703308820724487
Validation loss: 2.0533479234223724

Epoch: 5| Step: 2
Training loss: 1.231614589691162
Validation loss: 2.033434734549574

Epoch: 5| Step: 3
Training loss: 1.2267367839813232
Validation loss: 2.0001848513080227

Epoch: 5| Step: 4
Training loss: 1.8617017269134521
Validation loss: 1.9712285739119335

Epoch: 5| Step: 5
Training loss: 1.3868837356567383
Validation loss: 1.9738564375908143

Epoch: 5| Step: 6
Training loss: 1.3521093130111694
Validation loss: 1.9700686444518387

Epoch: 5| Step: 7
Training loss: 1.4568541049957275
Validation loss: 1.9618018827130717

Epoch: 5| Step: 8
Training loss: 1.6516786813735962
Validation loss: 1.9805088299576954

Epoch: 5| Step: 9
Training loss: 1.143555998802185
Validation loss: 2.003192436310553

Epoch: 5| Step: 10
Training loss: 1.9964624643325806
Validation loss: 2.0314548989777923

Epoch: 297| Step: 0
Training loss: 1.7451753616333008
Validation loss: 2.052562085531091

Epoch: 5| Step: 1
Training loss: 1.2656221389770508
Validation loss: 2.03099109408676

Epoch: 5| Step: 2
Training loss: 1.119468092918396
Validation loss: 2.0335309223462175

Epoch: 5| Step: 3
Training loss: 0.8291042447090149
Validation loss: 2.0382135914218042

Epoch: 5| Step: 4
Training loss: 1.5523040294647217
Validation loss: 2.0281509622450797

Epoch: 5| Step: 5
Training loss: 1.319040298461914
Validation loss: 1.9976684047329811

Epoch: 5| Step: 6
Training loss: 1.4580646753311157
Validation loss: 2.0114269000227734

Epoch: 5| Step: 7
Training loss: 1.373357892036438
Validation loss: 2.0029384961692234

Epoch: 5| Step: 8
Training loss: 1.6585614681243896
Validation loss: 2.0154176117271505

Epoch: 5| Step: 9
Training loss: 1.8920122385025024
Validation loss: 2.0016932282396542

Epoch: 5| Step: 10
Training loss: 1.0705748796463013
Validation loss: 2.0024387221182547

Epoch: 298| Step: 0
Training loss: 1.8160327672958374
Validation loss: 2.0145991002359698

Epoch: 5| Step: 1
Training loss: 1.6268800497055054
Validation loss: 2.038889194047579

Epoch: 5| Step: 2
Training loss: 1.7244364023208618
Validation loss: 2.090446774677564

Epoch: 5| Step: 3
Training loss: 1.0519180297851562
Validation loss: 2.0726186588246334

Epoch: 5| Step: 4
Training loss: 1.2328948974609375
Validation loss: 2.067396161376789

Epoch: 5| Step: 5
Training loss: 1.222292184829712
Validation loss: 2.0032463971004693

Epoch: 5| Step: 6
Training loss: 1.0459667444229126
Validation loss: 1.979254025284962

Epoch: 5| Step: 7
Training loss: 1.413257360458374
Validation loss: 1.9673653648745628

Epoch: 5| Step: 8
Training loss: 1.5553982257843018
Validation loss: 1.9452988460499754

Epoch: 5| Step: 9
Training loss: 1.414548635482788
Validation loss: 1.9596461544754684

Epoch: 5| Step: 10
Training loss: 1.2608320713043213
Validation loss: 1.9834078781066402

Epoch: 299| Step: 0
Training loss: 1.2322255373001099
Validation loss: 1.9834290448055472

Epoch: 5| Step: 1
Training loss: 1.9339736700057983
Validation loss: 1.9901061904045843

Epoch: 5| Step: 2
Training loss: 1.4667478799819946
Validation loss: 1.9902058570615706

Epoch: 5| Step: 3
Training loss: 1.5219168663024902
Validation loss: 2.005374075264059

Epoch: 5| Step: 4
Training loss: 1.2304636240005493
Validation loss: 2.0132967272112445

Epoch: 5| Step: 5
Training loss: 0.9902414083480835
Validation loss: 2.026191588371031

Epoch: 5| Step: 6
Training loss: 1.4290046691894531
Validation loss: 2.071181519057161

Epoch: 5| Step: 7
Training loss: 1.2496129274368286
Validation loss: 2.0516704333725797

Epoch: 5| Step: 8
Training loss: 1.277836561203003
Validation loss: 2.0270101562623055

Epoch: 5| Step: 9
Training loss: 1.7579567432403564
Validation loss: 2.0050389177055767

Epoch: 5| Step: 10
Training loss: 1.0670955181121826
Validation loss: 1.9830767518730574

Epoch: 300| Step: 0
Training loss: 1.6888248920440674
Validation loss: 1.9784282330543763

Epoch: 5| Step: 1
Training loss: 0.9821251034736633
Validation loss: 1.9662972034946564

Epoch: 5| Step: 2
Training loss: 1.3558437824249268
Validation loss: 1.9751535333612913

Epoch: 5| Step: 3
Training loss: 1.1580569744110107
Validation loss: 1.9887813368151266

Epoch: 5| Step: 4
Training loss: 1.1623084545135498
Validation loss: 2.001863997469666

Epoch: 5| Step: 5
Training loss: 1.0350984334945679
Validation loss: 1.9931068933138283

Epoch: 5| Step: 6
Training loss: 1.6502670049667358
Validation loss: 2.017489251270089

Epoch: 5| Step: 7
Training loss: 1.610489845275879
Validation loss: 2.0246250578152236

Epoch: 5| Step: 8
Training loss: 1.1292845010757446
Validation loss: 2.022674496455859

Epoch: 5| Step: 9
Training loss: 1.9134441614151
Validation loss: 2.062413643765193

Epoch: 5| Step: 10
Training loss: 1.4695310592651367
Validation loss: 2.033032965916459

Testing loss: 2.239403353797065
