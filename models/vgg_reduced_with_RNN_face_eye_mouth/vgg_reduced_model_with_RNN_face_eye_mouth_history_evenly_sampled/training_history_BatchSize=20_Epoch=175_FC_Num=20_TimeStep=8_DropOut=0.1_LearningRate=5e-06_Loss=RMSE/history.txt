Epoch: 1| Step: 0
Training loss: 6.110113621231235
Validation loss: 5.839900860733707

Epoch: 5| Step: 1
Training loss: 7.280405937027836
Validation loss: 5.834216439806697

Epoch: 5| Step: 2
Training loss: 4.5563865358593265
Validation loss: 5.828235563919509

Epoch: 5| Step: 3
Training loss: 6.113005747086781
Validation loss: 5.823007986810773

Epoch: 5| Step: 4
Training loss: 5.436125658358342
Validation loss: 5.817654264491878

Epoch: 5| Step: 5
Training loss: 5.464635729153751
Validation loss: 5.812016924312699

Epoch: 5| Step: 6
Training loss: 6.07085888538032
Validation loss: 5.806626804220112

Epoch: 5| Step: 7
Training loss: 6.71985734197782
Validation loss: 5.800516733100896

Epoch: 5| Step: 8
Training loss: 5.921110964482167
Validation loss: 5.794744189013337

Epoch: 5| Step: 9
Training loss: 4.828958680109419
Validation loss: 5.7888427823760535

Epoch: 5| Step: 10
Training loss: 5.1587257683797
Validation loss: 5.782117920047332

Epoch: 2| Step: 0
Training loss: 7.053465609593124
Validation loss: 5.775790652305173

Epoch: 5| Step: 1
Training loss: 6.308122684618556
Validation loss: 5.768299984139012

Epoch: 5| Step: 2
Training loss: 5.556210165664119
Validation loss: 5.761473756993485

Epoch: 5| Step: 3
Training loss: 5.077037518774213
Validation loss: 5.754220256437215

Epoch: 5| Step: 4
Training loss: 5.866576629005552
Validation loss: 5.746819553300589

Epoch: 5| Step: 5
Training loss: 5.663069349890563
Validation loss: 5.738814741008238

Epoch: 5| Step: 6
Training loss: 6.249318810534723
Validation loss: 5.729920247951826

Epoch: 5| Step: 7
Training loss: 5.665132576720196
Validation loss: 5.7217042544317325

Epoch: 5| Step: 8
Training loss: 5.705689572142209
Validation loss: 5.712623287789585

Epoch: 5| Step: 9
Training loss: 4.863533620146158
Validation loss: 5.703040753061328

Epoch: 5| Step: 10
Training loss: 5.062698737117153
Validation loss: 5.693326631901202

Epoch: 3| Step: 0
Training loss: 6.5847641882821595
Validation loss: 5.682721217909334

Epoch: 5| Step: 1
Training loss: 5.276185988033616
Validation loss: 5.6722587496987105

Epoch: 5| Step: 2
Training loss: 4.765801498396586
Validation loss: 5.6602447658425

Epoch: 5| Step: 3
Training loss: 6.723339411830976
Validation loss: 5.6486935007283625

Epoch: 5| Step: 4
Training loss: 5.182502085441026
Validation loss: 5.636570694401337

Epoch: 5| Step: 5
Training loss: 6.412778328549435
Validation loss: 5.622894339636493

Epoch: 5| Step: 6
Training loss: 5.2495215061661735
Validation loss: 5.6088031266254985

Epoch: 5| Step: 7
Training loss: 5.048031889885771
Validation loss: 5.595249210000901

Epoch: 5| Step: 8
Training loss: 5.7402795645124955
Validation loss: 5.58057991841831

Epoch: 5| Step: 9
Training loss: 5.109138506627827
Validation loss: 5.564561733470938

Epoch: 5| Step: 10
Training loss: 5.777373792919689
Validation loss: 5.548549770742564

Epoch: 4| Step: 0
Training loss: 6.12616734182546
Validation loss: 5.5325203205009394

Epoch: 5| Step: 1
Training loss: 6.711916833191811
Validation loss: 5.5163063749302435

Epoch: 5| Step: 2
Training loss: 5.33456952947652
Validation loss: 5.497689439529282

Epoch: 5| Step: 3
Training loss: 5.338555382191477
Validation loss: 5.478367771296369

Epoch: 5| Step: 4
Training loss: 5.399907090129537
Validation loss: 5.459447921481083

Epoch: 5| Step: 5
Training loss: 4.371962882761265
Validation loss: 5.441392873499323

Epoch: 5| Step: 6
Training loss: 5.729538044307924
Validation loss: 5.420794730312155

Epoch: 5| Step: 7
Training loss: 5.803924140692072
Validation loss: 5.400479245767424

Epoch: 5| Step: 8
Training loss: 5.671668519184095
Validation loss: 5.38030121722739

Epoch: 5| Step: 9
Training loss: 5.246452949821193
Validation loss: 5.360174719197873

Epoch: 5| Step: 10
Training loss: 3.9126656299181723
Validation loss: 5.337495753619986

Epoch: 5| Step: 0
Training loss: 5.953770880317154
Validation loss: 5.316261362283496

Epoch: 5| Step: 1
Training loss: 5.122291965979801
Validation loss: 5.294818027331759

Epoch: 5| Step: 2
Training loss: 4.489294882209088
Validation loss: 5.273319163876618

Epoch: 5| Step: 3
Training loss: 5.227073017270838
Validation loss: 5.250822726475217

Epoch: 5| Step: 4
Training loss: 5.5115457206185585
Validation loss: 5.229793612810656

Epoch: 5| Step: 5
Training loss: 5.915350145180579
Validation loss: 5.205451511959175

Epoch: 5| Step: 6
Training loss: 5.1922859267514925
Validation loss: 5.18082926878985

Epoch: 5| Step: 7
Training loss: 4.082428864456747
Validation loss: 5.156408959427866

Epoch: 5| Step: 8
Training loss: 5.1774492447896625
Validation loss: 5.130831058682521

Epoch: 5| Step: 9
Training loss: 5.373741179922869
Validation loss: 5.109179611913144

Epoch: 5| Step: 10
Training loss: 5.538366879363418
Validation loss: 5.0841111620752155

Epoch: 6| Step: 0
Training loss: 5.053700275502038
Validation loss: 5.058804407744758

Epoch: 5| Step: 1
Training loss: 4.841953658211888
Validation loss: 5.034524430786413

Epoch: 5| Step: 2
Training loss: 4.643756259590541
Validation loss: 5.008677651566865

Epoch: 5| Step: 3
Training loss: 5.9870765106221056
Validation loss: 4.985098481652197

Epoch: 5| Step: 4
Training loss: 5.40607447697591
Validation loss: 4.959867926392916

Epoch: 5| Step: 5
Training loss: 4.589700795646126
Validation loss: 4.935188613307553

Epoch: 5| Step: 6
Training loss: 5.443701353852142
Validation loss: 4.911997605243209

Epoch: 5| Step: 7
Training loss: 4.567284152939403
Validation loss: 4.887562203916919

Epoch: 5| Step: 8
Training loss: 5.946779729227342
Validation loss: 4.864307552881405

Epoch: 5| Step: 9
Training loss: 4.066672192762612
Validation loss: 4.842566080255942

Epoch: 5| Step: 10
Training loss: 3.9714512080442304
Validation loss: 4.819784627245421

Epoch: 7| Step: 0
Training loss: 4.879059495191383
Validation loss: 4.797134341631673

Epoch: 5| Step: 1
Training loss: 4.9637368301604985
Validation loss: 4.775900860613005

Epoch: 5| Step: 2
Training loss: 4.7224341151749245
Validation loss: 4.75294157220919

Epoch: 5| Step: 3
Training loss: 5.216612235243351
Validation loss: 4.730096891499531

Epoch: 5| Step: 4
Training loss: 4.657302020744066
Validation loss: 4.705170705668176

Epoch: 5| Step: 5
Training loss: 4.5675455700167555
Validation loss: 4.679077568860902

Epoch: 5| Step: 6
Training loss: 4.589744638225117
Validation loss: 4.6490001166677954

Epoch: 5| Step: 7
Training loss: 3.9127715336477196
Validation loss: 4.616023708742066

Epoch: 5| Step: 8
Training loss: 4.098321357038348
Validation loss: 4.578649380877282

Epoch: 5| Step: 9
Training loss: 4.8309981306384735
Validation loss: 4.547550055595418

Epoch: 5| Step: 10
Training loss: 5.75886449429676
Validation loss: 4.517247677693898

Epoch: 8| Step: 0
Training loss: 3.9783483066498135
Validation loss: 4.495349064326458

Epoch: 5| Step: 1
Training loss: 4.723264038252449
Validation loss: 4.4768459519031385

Epoch: 5| Step: 2
Training loss: 4.210491772560169
Validation loss: 4.456791241981449

Epoch: 5| Step: 3
Training loss: 2.952175734605439
Validation loss: 4.439328688213441

Epoch: 5| Step: 4
Training loss: 4.131744188999963
Validation loss: 4.423552397271149

Epoch: 5| Step: 5
Training loss: 5.005171961921809
Validation loss: 4.408928153762468

Epoch: 5| Step: 6
Training loss: 6.154116188140171
Validation loss: 4.39297100018345

Epoch: 5| Step: 7
Training loss: 4.380018135625491
Validation loss: 4.379954196587238

Epoch: 5| Step: 8
Training loss: 4.439869637508661
Validation loss: 4.366500447940725

Epoch: 5| Step: 9
Training loss: 3.9188936003394184
Validation loss: 4.354974418114695

Epoch: 5| Step: 10
Training loss: 5.170988346863531
Validation loss: 4.344228225224988

Epoch: 9| Step: 0
Training loss: 3.776544590924515
Validation loss: 4.332174872005043

Epoch: 5| Step: 1
Training loss: 4.092266949803268
Validation loss: 4.322540837761051

Epoch: 5| Step: 2
Training loss: 3.7868144809277187
Validation loss: 4.3129156743702906

Epoch: 5| Step: 3
Training loss: 4.919602029723479
Validation loss: 4.304589221830686

Epoch: 5| Step: 4
Training loss: 4.252518300460558
Validation loss: 4.296548553923626

Epoch: 5| Step: 5
Training loss: 5.018720675676121
Validation loss: 4.287706859875422

Epoch: 5| Step: 6
Training loss: 4.4323102664519896
Validation loss: 4.278414849861596

Epoch: 5| Step: 7
Training loss: 3.8643186466575545
Validation loss: 4.271483695601184

Epoch: 5| Step: 8
Training loss: 5.052561482353182
Validation loss: 4.262874749932629

Epoch: 5| Step: 9
Training loss: 5.015916287053689
Validation loss: 4.254896823414945

Epoch: 5| Step: 10
Training loss: 3.8587285168305847
Validation loss: 4.246364558719447

Epoch: 10| Step: 0
Training loss: 4.379759461229854
Validation loss: 4.238159907432643

Epoch: 5| Step: 1
Training loss: 3.490033400629886
Validation loss: 4.231923834244288

Epoch: 5| Step: 2
Training loss: 4.451430684391194
Validation loss: 4.225328175390613

Epoch: 5| Step: 3
Training loss: 4.209332388454746
Validation loss: 4.217867586315967

Epoch: 5| Step: 4
Training loss: 4.117214600909976
Validation loss: 4.209525230841401

Epoch: 5| Step: 5
Training loss: 3.916558419754093
Validation loss: 4.202959230545818

Epoch: 5| Step: 6
Training loss: 4.197867469720187
Validation loss: 4.196050845414963

Epoch: 5| Step: 7
Training loss: 5.498070985460012
Validation loss: 4.188301064903433

Epoch: 5| Step: 8
Training loss: 4.576019115234678
Validation loss: 4.180124862002402

Epoch: 5| Step: 9
Training loss: 3.801747025896591
Validation loss: 4.1742200489740044

Epoch: 5| Step: 10
Training loss: 4.752843908943183
Validation loss: 4.1656215407045885

Epoch: 11| Step: 0
Training loss: 4.0696510172821725
Validation loss: 4.158189112571846

Epoch: 5| Step: 1
Training loss: 4.089225773363108
Validation loss: 4.150855376018983

Epoch: 5| Step: 2
Training loss: 4.289156775489393
Validation loss: 4.14505071370031

Epoch: 5| Step: 3
Training loss: 4.246472409375102
Validation loss: 4.136017209180815

Epoch: 5| Step: 4
Training loss: 4.269445252664909
Validation loss: 4.13042825895591

Epoch: 5| Step: 5
Training loss: 3.714824881039421
Validation loss: 4.120778887015649

Epoch: 5| Step: 6
Training loss: 4.161675833825793
Validation loss: 4.1137628790533025

Epoch: 5| Step: 7
Training loss: 4.634450175935387
Validation loss: 4.1053729090177775

Epoch: 5| Step: 8
Training loss: 4.483817142252919
Validation loss: 4.09797534939501

Epoch: 5| Step: 9
Training loss: 5.007838018533851
Validation loss: 4.091414522403829

Epoch: 5| Step: 10
Training loss: 3.610631022369872
Validation loss: 4.083007548790218

Epoch: 12| Step: 0
Training loss: 3.9999443288743706
Validation loss: 4.075849775416856

Epoch: 5| Step: 1
Training loss: 3.8393304739842797
Validation loss: 4.067171907399962

Epoch: 5| Step: 2
Training loss: 3.950538361958304
Validation loss: 4.061681383825909

Epoch: 5| Step: 3
Training loss: 4.201112627066531
Validation loss: 4.051369504400259

Epoch: 5| Step: 4
Training loss: 4.684292318824503
Validation loss: 4.045236730796969

Epoch: 5| Step: 5
Training loss: 4.040777731337405
Validation loss: 4.038186680478136

Epoch: 5| Step: 6
Training loss: 4.596047793399658
Validation loss: 4.03204207426377

Epoch: 5| Step: 7
Training loss: 4.672655123385376
Validation loss: 4.025209382428242

Epoch: 5| Step: 8
Training loss: 3.587611121606617
Validation loss: 4.018402820415303

Epoch: 5| Step: 9
Training loss: 4.421524303534704
Validation loss: 4.010002420182411

Epoch: 5| Step: 10
Training loss: 3.8106569932192405
Validation loss: 4.005520479761357

Epoch: 13| Step: 0
Training loss: 4.2376705169128135
Validation loss: 3.9981652866627484

Epoch: 5| Step: 1
Training loss: 3.9144860683753104
Validation loss: 3.9918922514370028

Epoch: 5| Step: 2
Training loss: 4.100916522791496
Validation loss: 3.9869771099130147

Epoch: 5| Step: 3
Training loss: 4.735703687896411
Validation loss: 3.981059653614665

Epoch: 5| Step: 4
Training loss: 4.244896910441223
Validation loss: 3.9750787995599284

Epoch: 5| Step: 5
Training loss: 3.9756581415391126
Validation loss: 3.969666080493158

Epoch: 5| Step: 6
Training loss: 3.0856380269048174
Validation loss: 3.9628831104656173

Epoch: 5| Step: 7
Training loss: 4.111776484236861
Validation loss: 3.958343504982764

Epoch: 5| Step: 8
Training loss: 4.475679799876272
Validation loss: 3.952316043820548

Epoch: 5| Step: 9
Training loss: 3.4112572220012614
Validation loss: 3.946535555544418

Epoch: 5| Step: 10
Training loss: 4.845575001140196
Validation loss: 3.9393253968570106

Epoch: 14| Step: 0
Training loss: 4.106693451740388
Validation loss: 3.9318283767584834

Epoch: 5| Step: 1
Training loss: 3.6500449713457885
Validation loss: 3.9237161088279855

Epoch: 5| Step: 2
Training loss: 4.417739497947849
Validation loss: 3.9170404337461475

Epoch: 5| Step: 3
Training loss: 3.8633276586570457
Validation loss: 3.9090453576467823

Epoch: 5| Step: 4
Training loss: 4.888611790481742
Validation loss: 3.8987924418045723

Epoch: 5| Step: 5
Training loss: 4.672797989014994
Validation loss: 3.8905268198497467

Epoch: 5| Step: 6
Training loss: 3.9798981292185758
Validation loss: 3.8784685664429417

Epoch: 5| Step: 7
Training loss: 4.171331363075364
Validation loss: 3.8705347303071735

Epoch: 5| Step: 8
Training loss: 3.744509301219772
Validation loss: 3.860164567379758

Epoch: 5| Step: 9
Training loss: 3.397616302543099
Validation loss: 3.851709623746109

Epoch: 5| Step: 10
Training loss: 3.3003391669559297
Validation loss: 3.8488038049915736

Epoch: 15| Step: 0
Training loss: 4.495563863622037
Validation loss: 3.8402386705959826

Epoch: 5| Step: 1
Training loss: 2.7280323690132926
Validation loss: 3.8394492788825563

Epoch: 5| Step: 2
Training loss: 4.011343369198198
Validation loss: 3.8338244370140444

Epoch: 5| Step: 3
Training loss: 4.492070947876584
Validation loss: 3.824338162443134

Epoch: 5| Step: 4
Training loss: 3.5896399837605855
Validation loss: 3.8218737224573736

Epoch: 5| Step: 5
Training loss: 3.553407275043082
Validation loss: 3.813508345387584

Epoch: 5| Step: 6
Training loss: 4.189687584494107
Validation loss: 3.8087672481138712

Epoch: 5| Step: 7
Training loss: 3.6073280243781363
Validation loss: 3.8065566725751334

Epoch: 5| Step: 8
Training loss: 3.902383584553319
Validation loss: 3.798246629399929

Epoch: 5| Step: 9
Training loss: 4.222073750367234
Validation loss: 3.7962172074450944

Epoch: 5| Step: 10
Training loss: 4.759284933218595
Validation loss: 3.7916574857795142

Epoch: 16| Step: 0
Training loss: 4.400471245932565
Validation loss: 3.781940342609169

Epoch: 5| Step: 1
Training loss: 3.4021130559167574
Validation loss: 3.779556972037729

Epoch: 5| Step: 2
Training loss: 4.090466296189674
Validation loss: 3.7757453889917785

Epoch: 5| Step: 3
Training loss: 3.418678916178205
Validation loss: 3.7697791012380577

Epoch: 5| Step: 4
Training loss: 2.957327300033171
Validation loss: 3.767025460061139

Epoch: 5| Step: 5
Training loss: 4.026992323719151
Validation loss: 3.762972060302377

Epoch: 5| Step: 6
Training loss: 4.806758477704936
Validation loss: 3.7597146186623585

Epoch: 5| Step: 7
Training loss: 3.893645313012905
Validation loss: 3.7546686609583406

Epoch: 5| Step: 8
Training loss: 3.3838365515697206
Validation loss: 3.752416446062708

Epoch: 5| Step: 9
Training loss: 4.215951401026857
Validation loss: 3.74667093317096

Epoch: 5| Step: 10
Training loss: 4.422546120117948
Validation loss: 3.7425608032898

Epoch: 17| Step: 0
Training loss: 4.693408141912683
Validation loss: 3.739643093818416

Epoch: 5| Step: 1
Training loss: 3.725782012779396
Validation loss: 3.732403659504048

Epoch: 5| Step: 2
Training loss: 3.3454240547833756
Validation loss: 3.7288962961834238

Epoch: 5| Step: 3
Training loss: 4.860785472801454
Validation loss: 3.729020251554504

Epoch: 5| Step: 4
Training loss: 3.754246278540352
Validation loss: 3.721312491661506

Epoch: 5| Step: 5
Training loss: 3.8163455267207254
Validation loss: 3.715372795479821

Epoch: 5| Step: 6
Training loss: 3.6909415785166457
Validation loss: 3.712839115559692

Epoch: 5| Step: 7
Training loss: 3.766781071526205
Validation loss: 3.7098621831557894

Epoch: 5| Step: 8
Training loss: 3.4787867599447644
Validation loss: 3.7059443457916617

Epoch: 5| Step: 9
Training loss: 4.337275668012919
Validation loss: 3.705648642037588

Epoch: 5| Step: 10
Training loss: 2.8822464219156396
Validation loss: 3.69935901087163

Epoch: 18| Step: 0
Training loss: 4.161572941366458
Validation loss: 3.6983176074543773

Epoch: 5| Step: 1
Training loss: 3.845024827894356
Validation loss: 3.695898541713189

Epoch: 5| Step: 2
Training loss: 3.664488029578061
Validation loss: 3.6900001922455306

Epoch: 5| Step: 3
Training loss: 4.275942666150249
Validation loss: 3.6884082268740013

Epoch: 5| Step: 4
Training loss: 4.402086820780066
Validation loss: 3.6819157949940617

Epoch: 5| Step: 5
Training loss: 4.03175078837416
Validation loss: 3.678841256978003

Epoch: 5| Step: 6
Training loss: 3.5968420907113363
Validation loss: 3.6748672612616713

Epoch: 5| Step: 7
Training loss: 3.3719140532232164
Validation loss: 3.6741775027580537

Epoch: 5| Step: 8
Training loss: 3.0263950756519984
Validation loss: 3.6665764764468323

Epoch: 5| Step: 9
Training loss: 3.7187692337179867
Validation loss: 3.66926511767298

Epoch: 5| Step: 10
Training loss: 4.288381164576595
Validation loss: 3.6616934757674935

Epoch: 19| Step: 0
Training loss: 4.426288464564099
Validation loss: 3.6567575687701654

Epoch: 5| Step: 1
Training loss: 4.335787933794265
Validation loss: 3.654458307340737

Epoch: 5| Step: 2
Training loss: 2.8088108026623275
Validation loss: 3.653698980904556

Epoch: 5| Step: 3
Training loss: 4.102766285401467
Validation loss: 3.648408360237645

Epoch: 5| Step: 4
Training loss: 2.9919439869089763
Validation loss: 3.646033228772012

Epoch: 5| Step: 5
Training loss: 4.054842260564107
Validation loss: 3.639255779371405

Epoch: 5| Step: 6
Training loss: 4.067124302446722
Validation loss: 3.6367621651134243

Epoch: 5| Step: 7
Training loss: 4.0951484446465924
Validation loss: 3.634966043505322

Epoch: 5| Step: 8
Training loss: 3.2168420859091404
Validation loss: 3.630943507906324

Epoch: 5| Step: 9
Training loss: 3.2215310831709236
Validation loss: 3.6303656050791764

Epoch: 5| Step: 10
Training loss: 4.495596956833543
Validation loss: 3.6259803408168705

Epoch: 20| Step: 0
Training loss: 4.136166111500929
Validation loss: 3.62172340424695

Epoch: 5| Step: 1
Training loss: 3.3194831799774676
Validation loss: 3.6184404208479455

Epoch: 5| Step: 2
Training loss: 3.7915634867843644
Validation loss: 3.6154541846549724

Epoch: 5| Step: 3
Training loss: 4.036664771266737
Validation loss: 3.621188438883635

Epoch: 5| Step: 4
Training loss: 2.757318641598862
Validation loss: 3.616535722057514

Epoch: 5| Step: 5
Training loss: 3.21781152173024
Validation loss: 3.6117003600351496

Epoch: 5| Step: 6
Training loss: 3.975699640277131
Validation loss: 3.6031640345341813

Epoch: 5| Step: 7
Training loss: 5.317060958607568
Validation loss: 3.603697686118092

Epoch: 5| Step: 8
Training loss: 3.722856834427501
Validation loss: 3.5994243080052044

Epoch: 5| Step: 9
Training loss: 2.9766863299066015
Validation loss: 3.5958642034693584

Epoch: 5| Step: 10
Training loss: 3.981690822851123
Validation loss: 3.5918877069486563

Epoch: 21| Step: 0
Training loss: 3.6495577870915814
Validation loss: 3.5925033254578977

Epoch: 5| Step: 1
Training loss: 3.824582075836466
Validation loss: 3.586333975680095

Epoch: 5| Step: 2
Training loss: 4.497592493943526
Validation loss: 3.5831082500633067

Epoch: 5| Step: 3
Training loss: 4.098844430480767
Validation loss: 3.5842140848608914

Epoch: 5| Step: 4
Training loss: 4.128696057356754
Validation loss: 3.583046364841722

Epoch: 5| Step: 5
Training loss: 4.057992400484221
Validation loss: 3.57749700670871

Epoch: 5| Step: 6
Training loss: 2.3310880303045822
Validation loss: 3.573495955252559

Epoch: 5| Step: 7
Training loss: 4.187555568952656
Validation loss: 3.575545054393582

Epoch: 5| Step: 8
Training loss: 3.1341317079544018
Validation loss: 3.577795272589814

Epoch: 5| Step: 9
Training loss: 3.4470755635459893
Validation loss: 3.5716162710776618

Epoch: 5| Step: 10
Training loss: 3.761570817647106
Validation loss: 3.570831363805851

Epoch: 22| Step: 0
Training loss: 3.297733863942046
Validation loss: 3.562738564229861

Epoch: 5| Step: 1
Training loss: 3.5375265868572874
Validation loss: 3.560450328565363

Epoch: 5| Step: 2
Training loss: 3.4109667397126975
Validation loss: 3.560517217534092

Epoch: 5| Step: 3
Training loss: 3.437275827207454
Validation loss: 3.560035424433579

Epoch: 5| Step: 4
Training loss: 4.422585797553141
Validation loss: 3.559862648424075

Epoch: 5| Step: 5
Training loss: 4.053045921760138
Validation loss: 3.55537507967389

Epoch: 5| Step: 6
Training loss: 3.359171448684225
Validation loss: 3.5578922005108833

Epoch: 5| Step: 7
Training loss: 4.232293662614451
Validation loss: 3.551211023775279

Epoch: 5| Step: 8
Training loss: 3.3687986692405576
Validation loss: 3.550050217075288

Epoch: 5| Step: 9
Training loss: 4.329670654175998
Validation loss: 3.548173530925302

Epoch: 5| Step: 10
Training loss: 3.6335371053640184
Validation loss: 3.54491091436422

Epoch: 23| Step: 0
Training loss: 3.47424952684465
Validation loss: 3.545420717284093

Epoch: 5| Step: 1
Training loss: 3.927299365401237
Validation loss: 3.538997672823584

Epoch: 5| Step: 2
Training loss: 4.242104545330153
Validation loss: 3.5368783939859636

Epoch: 5| Step: 3
Training loss: 3.1606822100744414
Validation loss: 3.5320613407077226

Epoch: 5| Step: 4
Training loss: 3.703825164145524
Validation loss: 3.5293749754265304

Epoch: 5| Step: 5
Training loss: 4.010896147101297
Validation loss: 3.536573288403415

Epoch: 5| Step: 6
Training loss: 3.3664000402443306
Validation loss: 3.5326046491981056

Epoch: 5| Step: 7
Training loss: 3.3671741883618833
Validation loss: 3.523515829253327

Epoch: 5| Step: 8
Training loss: 3.897289527559005
Validation loss: 3.5221541877810325

Epoch: 5| Step: 9
Training loss: 4.58123819263805
Validation loss: 3.5253178351025016

Epoch: 5| Step: 10
Training loss: 2.9596488785622865
Validation loss: 3.528731910186363

Epoch: 24| Step: 0
Training loss: 3.251068086444477
Validation loss: 3.5278706847750567

Epoch: 5| Step: 1
Training loss: 3.789948979137494
Validation loss: 3.514351268172292

Epoch: 5| Step: 2
Training loss: 3.508505567972724
Validation loss: 3.5119407419661157

Epoch: 5| Step: 3
Training loss: 3.7087181120280444
Validation loss: 3.512172588570249

Epoch: 5| Step: 4
Training loss: 3.5848823274802037
Validation loss: 3.5101121519836505

Epoch: 5| Step: 5
Training loss: 3.35920480696245
Validation loss: 3.511561157540639

Epoch: 5| Step: 6
Training loss: 3.7987336056284287
Validation loss: 3.5083440927838327

Epoch: 5| Step: 7
Training loss: 4.0740272718367905
Validation loss: 3.5060128978988083

Epoch: 5| Step: 8
Training loss: 4.474254925466532
Validation loss: 3.5049893865567556

Epoch: 5| Step: 9
Training loss: 3.391508910113304
Validation loss: 3.502802154853124

Epoch: 5| Step: 10
Training loss: 3.8426150995809913
Validation loss: 3.5002604503381916

Epoch: 25| Step: 0
Training loss: 3.350532569115558
Validation loss: 3.4994015079415006

Epoch: 5| Step: 1
Training loss: 2.877866559845904
Validation loss: 3.4961906232237645

Epoch: 5| Step: 2
Training loss: 4.026500891205648
Validation loss: 3.4947068597024575

Epoch: 5| Step: 3
Training loss: 3.437373072274886
Validation loss: 3.490509981785849

Epoch: 5| Step: 4
Training loss: 3.917219582887725
Validation loss: 3.4890289488277832

Epoch: 5| Step: 5
Training loss: 3.212822057114074
Validation loss: 3.4855017359396467

Epoch: 5| Step: 6
Training loss: 4.046841536571347
Validation loss: 3.485896892791601

Epoch: 5| Step: 7
Training loss: 4.459365915290545
Validation loss: 3.48278705014566

Epoch: 5| Step: 8
Training loss: 3.678048515983074
Validation loss: 3.4837399899242265

Epoch: 5| Step: 9
Training loss: 3.610977939856308
Validation loss: 3.4783210667511213

Epoch: 5| Step: 10
Training loss: 3.862334070684691
Validation loss: 3.477845177085865

Epoch: 26| Step: 0
Training loss: 3.6719855109284216
Validation loss: 3.479266748775117

Epoch: 5| Step: 1
Training loss: 3.5800626747143425
Validation loss: 3.4736817095079378

Epoch: 5| Step: 2
Training loss: 3.918482799029372
Validation loss: 3.4734133150979

Epoch: 5| Step: 3
Training loss: 3.6995772094423827
Validation loss: 3.47031748899761

Epoch: 5| Step: 4
Training loss: 3.53185800365003
Validation loss: 3.471357829197524

Epoch: 5| Step: 5
Training loss: 3.656136926712083
Validation loss: 3.4674605500798674

Epoch: 5| Step: 6
Training loss: 3.696556478726524
Validation loss: 3.4657926523353573

Epoch: 5| Step: 7
Training loss: 4.276201599079117
Validation loss: 3.4626078859720018

Epoch: 5| Step: 8
Training loss: 2.986703653220085
Validation loss: 3.461780417023049

Epoch: 5| Step: 9
Training loss: 4.113052637135782
Validation loss: 3.4596344869401214

Epoch: 5| Step: 10
Training loss: 3.1501631255524423
Validation loss: 3.4599406903786467

Epoch: 27| Step: 0
Training loss: 3.882812131578516
Validation loss: 3.4577823476253022

Epoch: 5| Step: 1
Training loss: 3.735563208873301
Validation loss: 3.45219274648708

Epoch: 5| Step: 2
Training loss: 2.988157102711201
Validation loss: 3.451973964499299

Epoch: 5| Step: 3
Training loss: 4.1602853101313055
Validation loss: 3.4577036873870473

Epoch: 5| Step: 4
Training loss: 3.386556689686942
Validation loss: 3.455386799212436

Epoch: 5| Step: 5
Training loss: 2.943489137660921
Validation loss: 3.4479461887752447

Epoch: 5| Step: 6
Training loss: 3.381667156893145
Validation loss: 3.4443439328280525

Epoch: 5| Step: 7
Training loss: 4.5473936643745665
Validation loss: 3.4422597051859336

Epoch: 5| Step: 8
Training loss: 3.4990547811183363
Validation loss: 3.43955252888206

Epoch: 5| Step: 9
Training loss: 4.068609016659666
Validation loss: 3.4403731792326604

Epoch: 5| Step: 10
Training loss: 3.3897666020350092
Validation loss: 3.4393777158122774

Epoch: 28| Step: 0
Training loss: 3.421772715812194
Validation loss: 3.4399301942118163

Epoch: 5| Step: 1
Training loss: 3.8124005664303504
Validation loss: 3.43863294768024

Epoch: 5| Step: 2
Training loss: 2.639362642917346
Validation loss: 3.44420637219209

Epoch: 5| Step: 3
Training loss: 4.001164743599034
Validation loss: 3.443915661685514

Epoch: 5| Step: 4
Training loss: 3.8485130014575364
Validation loss: 3.4348884767846974

Epoch: 5| Step: 5
Training loss: 2.8287984983945114
Validation loss: 3.434505452248924

Epoch: 5| Step: 6
Training loss: 3.7471054349898103
Validation loss: 3.441213621043764

Epoch: 5| Step: 7
Training loss: 3.8738118472829077
Validation loss: 3.4401514501684107

Epoch: 5| Step: 8
Training loss: 3.9460011098466676
Validation loss: 3.4445394218304966

Epoch: 5| Step: 9
Training loss: 3.619548776651258
Validation loss: 3.4321026413977087

Epoch: 5| Step: 10
Training loss: 4.288334908117565
Validation loss: 3.4315801768738594

Epoch: 29| Step: 0
Training loss: 4.023197855803077
Validation loss: 3.423125319501673

Epoch: 5| Step: 1
Training loss: 3.726919992761622
Validation loss: 3.4224848986397625

Epoch: 5| Step: 2
Training loss: 4.026630919426227
Validation loss: 3.42384577782415

Epoch: 5| Step: 3
Training loss: 3.227347733313476
Validation loss: 3.4193012513076826

Epoch: 5| Step: 4
Training loss: 3.5450290800335744
Validation loss: 3.4166603723603584

Epoch: 5| Step: 5
Training loss: 3.0587876844247743
Validation loss: 3.4190221373549052

Epoch: 5| Step: 6
Training loss: 3.4194122230987376
Validation loss: 3.4181563468583565

Epoch: 5| Step: 7
Training loss: 4.1049964698469665
Validation loss: 3.4193082982543346

Epoch: 5| Step: 8
Training loss: 3.0936071189484764
Validation loss: 3.414993372860463

Epoch: 5| Step: 9
Training loss: 3.756554152985031
Validation loss: 3.409796595045134

Epoch: 5| Step: 10
Training loss: 3.916645591083935
Validation loss: 3.408771732586738

Epoch: 30| Step: 0
Training loss: 4.179738153168537
Validation loss: 3.4077174403294346

Epoch: 5| Step: 1
Training loss: 3.608361964886715
Validation loss: 3.4081848841705966

Epoch: 5| Step: 2
Training loss: 3.713752401756247
Validation loss: 3.405432049062129

Epoch: 5| Step: 3
Training loss: 3.4600804217038372
Validation loss: 3.401105358555866

Epoch: 5| Step: 4
Training loss: 2.2747859560703856
Validation loss: 3.4024748868215076

Epoch: 5| Step: 5
Training loss: 3.186040806089339
Validation loss: 3.401859227331375

Epoch: 5| Step: 6
Training loss: 3.512167081972943
Validation loss: 3.399228165959611

Epoch: 5| Step: 7
Training loss: 3.5973580202632247
Validation loss: 3.399617861735592

Epoch: 5| Step: 8
Training loss: 4.013356558858217
Validation loss: 3.3970779567971126

Epoch: 5| Step: 9
Training loss: 4.098178012092548
Validation loss: 3.3947350886290053

Epoch: 5| Step: 10
Training loss: 3.9278586892932696
Validation loss: 3.394387482756071

Epoch: 31| Step: 0
Training loss: 3.6396307508541956
Validation loss: 3.394866987551992

Epoch: 5| Step: 1
Training loss: 3.287124896678668
Validation loss: 3.3945252157333

Epoch: 5| Step: 2
Training loss: 3.5959841210732884
Validation loss: 3.393203823022752

Epoch: 5| Step: 3
Training loss: 3.7789019395552477
Validation loss: 3.392114420932052

Epoch: 5| Step: 4
Training loss: 3.5054768898250717
Validation loss: 3.3902007305782007

Epoch: 5| Step: 5
Training loss: 4.529814183548326
Validation loss: 3.3885553185619206

Epoch: 5| Step: 6
Training loss: 3.6116663937875892
Validation loss: 3.3877824391091482

Epoch: 5| Step: 7
Training loss: 3.1857986397483535
Validation loss: 3.387146376345732

Epoch: 5| Step: 8
Training loss: 3.590549270986657
Validation loss: 3.3855454327474717

Epoch: 5| Step: 9
Training loss: 3.6760886830953146
Validation loss: 3.386180635615794

Epoch: 5| Step: 10
Training loss: 3.139919676269648
Validation loss: 3.3834664173786417

Epoch: 32| Step: 0
Training loss: 2.8935817134031505
Validation loss: 3.381818661227467

Epoch: 5| Step: 1
Training loss: 3.431868639488349
Validation loss: 3.3829059756061657

Epoch: 5| Step: 2
Training loss: 4.2039637526411315
Validation loss: 3.3792887365748783

Epoch: 5| Step: 3
Training loss: 3.5748661309633794
Validation loss: 3.379856970311023

Epoch: 5| Step: 4
Training loss: 3.868972150744286
Validation loss: 3.3800287128667468

Epoch: 5| Step: 5
Training loss: 4.1313187724750415
Validation loss: 3.376801277859946

Epoch: 5| Step: 6
Training loss: 3.211068477882918
Validation loss: 3.3771959587340143

Epoch: 5| Step: 7
Training loss: 3.8294359103501776
Validation loss: 3.3738564833213234

Epoch: 5| Step: 8
Training loss: 4.001557285435029
Validation loss: 3.3728753272327268

Epoch: 5| Step: 9
Training loss: 3.213291762335026
Validation loss: 3.3722435265655406

Epoch: 5| Step: 10
Training loss: 2.961358274490782
Validation loss: 3.37148451235672

Epoch: 33| Step: 0
Training loss: 3.732520500888211
Validation loss: 3.3730069256953947

Epoch: 5| Step: 1
Training loss: 3.8665657545492396
Validation loss: 3.372686907560245

Epoch: 5| Step: 2
Training loss: 3.6971237550369604
Validation loss: 3.3726267945984674

Epoch: 5| Step: 3
Training loss: 3.8672985947189717
Validation loss: 3.3718384169661535

Epoch: 5| Step: 4
Training loss: 3.3987377516430066
Validation loss: 3.3687720129846412

Epoch: 5| Step: 5
Training loss: 3.343119053716786
Validation loss: 3.366461610006535

Epoch: 5| Step: 6
Training loss: 3.9750530023460016
Validation loss: 3.3666919493682825

Epoch: 5| Step: 7
Training loss: 3.6876737909258255
Validation loss: 3.3658248503983454

Epoch: 5| Step: 8
Training loss: 2.9929056525891844
Validation loss: 3.3657286732226286

Epoch: 5| Step: 9
Training loss: 3.717113487401569
Validation loss: 3.3637061809937676

Epoch: 5| Step: 10
Training loss: 3.1201045028595833
Validation loss: 3.363031457969542

Epoch: 34| Step: 0
Training loss: 3.5730300010448692
Validation loss: 3.362617420970785

Epoch: 5| Step: 1
Training loss: 2.5783774512407787
Validation loss: 3.360698948643571

Epoch: 5| Step: 2
Training loss: 3.783698936195969
Validation loss: 3.3627205454281532

Epoch: 5| Step: 3
Training loss: 3.027686945012564
Validation loss: 3.3604043797634153

Epoch: 5| Step: 4
Training loss: 3.6447769523789484
Validation loss: 3.362281261434668

Epoch: 5| Step: 5
Training loss: 3.431158423808563
Validation loss: 3.3595369536998074

Epoch: 5| Step: 6
Training loss: 3.907156511025371
Validation loss: 3.359228074375275

Epoch: 5| Step: 7
Training loss: 4.536523736014381
Validation loss: 3.359492472688292

Epoch: 5| Step: 8
Training loss: 4.1920933369153595
Validation loss: 3.3565872060566497

Epoch: 5| Step: 9
Training loss: 2.802970509434199
Validation loss: 3.357047424068963

Epoch: 5| Step: 10
Training loss: 3.599593478668101
Validation loss: 3.3582529088948823

Epoch: 35| Step: 0
Training loss: 3.360744179557511
Validation loss: 3.3589647710831922

Epoch: 5| Step: 1
Training loss: 3.7507648959495583
Validation loss: 3.358668027388496

Epoch: 5| Step: 2
Training loss: 4.383789388818489
Validation loss: 3.3548277474335504

Epoch: 5| Step: 3
Training loss: 3.1788136924155945
Validation loss: 3.3547653375293875

Epoch: 5| Step: 4
Training loss: 3.653244217623376
Validation loss: 3.3553773660153787

Epoch: 5| Step: 5
Training loss: 4.051068934908521
Validation loss: 3.35805511606672

Epoch: 5| Step: 6
Training loss: 3.811568349602484
Validation loss: 3.355060526822676

Epoch: 5| Step: 7
Training loss: 3.2061779824658867
Validation loss: 3.3594253997952186

Epoch: 5| Step: 8
Training loss: 3.0919208706579404
Validation loss: 3.353841441906816

Epoch: 5| Step: 9
Training loss: 3.125247030031108
Validation loss: 3.3536028384604855

Epoch: 5| Step: 10
Training loss: 3.6661290439301295
Validation loss: 3.3519985356018447

Epoch: 36| Step: 0
Training loss: 4.175843826267567
Validation loss: 3.3517803971599345

Epoch: 5| Step: 1
Training loss: 3.402464556821247
Validation loss: 3.3518211057877143

Epoch: 5| Step: 2
Training loss: 3.0279023867133423
Validation loss: 3.3510580840452877

Epoch: 5| Step: 3
Training loss: 3.194888359590836
Validation loss: 3.349012770424278

Epoch: 5| Step: 4
Training loss: 4.332054585289946
Validation loss: 3.3513001855784625

Epoch: 5| Step: 5
Training loss: 3.3192639658735317
Validation loss: 3.3488614523112266

Epoch: 5| Step: 6
Training loss: 3.4324952192057903
Validation loss: 3.345286210696678

Epoch: 5| Step: 7
Training loss: 3.7460098654988285
Validation loss: 3.344780731732592

Epoch: 5| Step: 8
Training loss: 3.78391884181633
Validation loss: 3.3454136344482905

Epoch: 5| Step: 9
Training loss: 3.63769072461959
Validation loss: 3.344887894920002

Epoch: 5| Step: 10
Training loss: 3.036502181315098
Validation loss: 3.3458405994505003

Epoch: 37| Step: 0
Training loss: 3.3740153819097034
Validation loss: 3.3454196638092446

Epoch: 5| Step: 1
Training loss: 4.053320740713669
Validation loss: 3.345357656202134

Epoch: 5| Step: 2
Training loss: 3.033194950286795
Validation loss: 3.345928764604126

Epoch: 5| Step: 3
Training loss: 3.347295717212514
Validation loss: 3.34089632256549

Epoch: 5| Step: 4
Training loss: 3.9595022516794565
Validation loss: 3.343129916768223

Epoch: 5| Step: 5
Training loss: 3.6673215512454718
Validation loss: 3.337494304019642

Epoch: 5| Step: 6
Training loss: 3.491412117236763
Validation loss: 3.3378916357432944

Epoch: 5| Step: 7
Training loss: 3.574222752303087
Validation loss: 3.337028771996338

Epoch: 5| Step: 8
Training loss: 3.01325065156149
Validation loss: 3.3381305857627925

Epoch: 5| Step: 9
Training loss: 3.9099741768533036
Validation loss: 3.336850835071327

Epoch: 5| Step: 10
Training loss: 3.8028007074418215
Validation loss: 3.337051922075114

Epoch: 38| Step: 0
Training loss: 3.475445720162579
Validation loss: 3.3361158375896136

Epoch: 5| Step: 1
Training loss: 3.5546944754395846
Validation loss: 3.335858318275489

Epoch: 5| Step: 2
Training loss: 3.4579325217728405
Validation loss: 3.3333272308375785

Epoch: 5| Step: 3
Training loss: 3.712566459908601
Validation loss: 3.334510114561564

Epoch: 5| Step: 4
Training loss: 3.2146185869091464
Validation loss: 3.3319752069618978

Epoch: 5| Step: 5
Training loss: 3.5972961179261276
Validation loss: 3.3310278431056366

Epoch: 5| Step: 6
Training loss: 3.8506832705489358
Validation loss: 3.3316961795432714

Epoch: 5| Step: 7
Training loss: 3.455762865390437
Validation loss: 3.331232538462052

Epoch: 5| Step: 8
Training loss: 4.077050780080436
Validation loss: 3.330920796622887

Epoch: 5| Step: 9
Training loss: 3.589675451075651
Validation loss: 3.3305339954085746

Epoch: 5| Step: 10
Training loss: 3.142540191174874
Validation loss: 3.333158427438534

Epoch: 39| Step: 0
Training loss: 3.3176508748315436
Validation loss: 3.330238807580334

Epoch: 5| Step: 1
Training loss: 3.9453720843659648
Validation loss: 3.3279343340086998

Epoch: 5| Step: 2
Training loss: 3.398333387862862
Validation loss: 3.32727120864859

Epoch: 5| Step: 3
Training loss: 3.7891901053738497
Validation loss: 3.3284530281566718

Epoch: 5| Step: 4
Training loss: 3.4133137944774887
Validation loss: 3.3277998299423013

Epoch: 5| Step: 5
Training loss: 3.333761537386737
Validation loss: 3.3254810033139104

Epoch: 5| Step: 6
Training loss: 3.459448362708015
Validation loss: 3.3261216757977805

Epoch: 5| Step: 7
Training loss: 3.7859281494931993
Validation loss: 3.3246891030275294

Epoch: 5| Step: 8
Training loss: 3.8111732550751607
Validation loss: 3.323591590334259

Epoch: 5| Step: 9
Training loss: 2.9448829560264063
Validation loss: 3.325351056485714

Epoch: 5| Step: 10
Training loss: 3.952926811708401
Validation loss: 3.327704650779203

Epoch: 40| Step: 0
Training loss: 3.517337229527226
Validation loss: 3.3254237613442226

Epoch: 5| Step: 1
Training loss: 3.7525445570260483
Validation loss: 3.323200270947366

Epoch: 5| Step: 2
Training loss: 3.1770605534638423
Validation loss: 3.325365818380352

Epoch: 5| Step: 3
Training loss: 4.538783893800094
Validation loss: 3.3212987604014215

Epoch: 5| Step: 4
Training loss: 3.8131503191515166
Validation loss: 3.322257534966216

Epoch: 5| Step: 5
Training loss: 3.0400661978290238
Validation loss: 3.321700864930028

Epoch: 5| Step: 6
Training loss: 3.7950164893072293
Validation loss: 3.3213393316555573

Epoch: 5| Step: 7
Training loss: 3.821662274333317
Validation loss: 3.3215806772270713

Epoch: 5| Step: 8
Training loss: 3.246404860147793
Validation loss: 3.3214191636180885

Epoch: 5| Step: 9
Training loss: 2.9935288572562775
Validation loss: 3.3199474804360576

Epoch: 5| Step: 10
Training loss: 3.1272901154492403
Validation loss: 3.3211927442216553

Epoch: 41| Step: 0
Training loss: 3.6864484160412854
Validation loss: 3.319613937252324

Epoch: 5| Step: 1
Training loss: 3.496519947180029
Validation loss: 3.320090636550515

Epoch: 5| Step: 2
Training loss: 3.0103796370361713
Validation loss: 3.3205380282455184

Epoch: 5| Step: 3
Training loss: 4.0934730028394695
Validation loss: 3.3185086508402026

Epoch: 5| Step: 4
Training loss: 3.588891103236641
Validation loss: 3.319120112169754

Epoch: 5| Step: 5
Training loss: 3.451561897661149
Validation loss: 3.319302689839366

Epoch: 5| Step: 6
Training loss: 4.079330090894645
Validation loss: 3.318610718751434

Epoch: 5| Step: 7
Training loss: 3.4063022154559364
Validation loss: 3.3170385429162175

Epoch: 5| Step: 8
Training loss: 3.295662751989881
Validation loss: 3.3161404233058294

Epoch: 5| Step: 9
Training loss: 2.99146742161681
Validation loss: 3.3163766618436354

Epoch: 5| Step: 10
Training loss: 3.9125525327818083
Validation loss: 3.315092066744111

Epoch: 42| Step: 0
Training loss: 3.7336897600420906
Validation loss: 3.3150343205829214

Epoch: 5| Step: 1
Training loss: 3.3874568640858707
Validation loss: 3.3156566705461437

Epoch: 5| Step: 2
Training loss: 3.170915731060403
Validation loss: 3.317546524045695

Epoch: 5| Step: 3
Training loss: 2.802039211072351
Validation loss: 3.3151887988995994

Epoch: 5| Step: 4
Training loss: 3.220134696512567
Validation loss: 3.31530392139564

Epoch: 5| Step: 5
Training loss: 3.9468290228140295
Validation loss: 3.312266658304407

Epoch: 5| Step: 6
Training loss: 3.6057339092383063
Validation loss: 3.311705972609475

Epoch: 5| Step: 7
Training loss: 3.885718258086346
Validation loss: 3.3137927203927844

Epoch: 5| Step: 8
Training loss: 3.3893705939409
Validation loss: 3.312997938062511

Epoch: 5| Step: 9
Training loss: 3.2906913439084535
Validation loss: 3.31507480610495

Epoch: 5| Step: 10
Training loss: 4.541797227761877
Validation loss: 3.313043498306825

Epoch: 43| Step: 0
Training loss: 3.535469167780724
Validation loss: 3.314663136428294

Epoch: 5| Step: 1
Training loss: 4.194615481989743
Validation loss: 3.312471432600397

Epoch: 5| Step: 2
Training loss: 2.352087222136354
Validation loss: 3.313899657174052

Epoch: 5| Step: 3
Training loss: 3.1422160659015113
Validation loss: 3.313544345764663

Epoch: 5| Step: 4
Training loss: 3.547400481835654
Validation loss: 3.3139286067955696

Epoch: 5| Step: 5
Training loss: 3.2849189228056663
Validation loss: 3.312942080679224

Epoch: 5| Step: 6
Training loss: 3.7770912693541376
Validation loss: 3.310374661048

Epoch: 5| Step: 7
Training loss: 4.244911064231771
Validation loss: 3.3095581215970062

Epoch: 5| Step: 8
Training loss: 3.2197315978501724
Validation loss: 3.3082613396110148

Epoch: 5| Step: 9
Training loss: 3.9447568596586193
Validation loss: 3.3078744214854066

Epoch: 5| Step: 10
Training loss: 3.40701831236974
Validation loss: 3.3079216526725523

Epoch: 44| Step: 0
Training loss: 3.7900476177918128
Validation loss: 3.3077579987628245

Epoch: 5| Step: 1
Training loss: 3.718828601166765
Validation loss: 3.3093490860941652

Epoch: 5| Step: 2
Training loss: 3.0257498008931574
Validation loss: 3.3080405665980175

Epoch: 5| Step: 3
Training loss: 3.53471461113937
Validation loss: 3.305875392239405

Epoch: 5| Step: 4
Training loss: 3.2079094115425977
Validation loss: 3.3099731757451347

Epoch: 5| Step: 5
Training loss: 3.4391768093774515
Validation loss: 3.305722811454313

Epoch: 5| Step: 6
Training loss: 3.3606722433988216
Validation loss: 3.304752805839306

Epoch: 5| Step: 7
Training loss: 3.4552241370539587
Validation loss: 3.304709543890483

Epoch: 5| Step: 8
Training loss: 3.5968569386390854
Validation loss: 3.3036262295443755

Epoch: 5| Step: 9
Training loss: 4.0715102997801464
Validation loss: 3.3054234890884144

Epoch: 5| Step: 10
Training loss: 3.7545876733000365
Validation loss: 3.3022791975621097

Epoch: 45| Step: 0
Training loss: 3.348765951576416
Validation loss: 3.3037212395030067

Epoch: 5| Step: 1
Training loss: 3.6056647448928856
Validation loss: 3.303856371555444

Epoch: 5| Step: 2
Training loss: 3.855645481994514
Validation loss: 3.3031857721424847

Epoch: 5| Step: 3
Training loss: 3.021328133585609
Validation loss: 3.3018818181078404

Epoch: 5| Step: 4
Training loss: 3.688022641143478
Validation loss: 3.3015452408107855

Epoch: 5| Step: 5
Training loss: 3.646220609894984
Validation loss: 3.29985220433038

Epoch: 5| Step: 6
Training loss: 4.227825434434673
Validation loss: 3.3015849646155724

Epoch: 5| Step: 7
Training loss: 3.329762087505233
Validation loss: 3.302408752730898

Epoch: 5| Step: 8
Training loss: 3.5589114402220323
Validation loss: 3.3006086756424122

Epoch: 5| Step: 9
Training loss: 3.351062941945637
Validation loss: 3.3004404856023726

Epoch: 5| Step: 10
Training loss: 3.163184677613291
Validation loss: 3.2998804148425718

Epoch: 46| Step: 0
Training loss: 3.9374273384292637
Validation loss: 3.298837862509363

Epoch: 5| Step: 1
Training loss: 3.493416179616151
Validation loss: 3.298565625731857

Epoch: 5| Step: 2
Training loss: 3.3636321306787798
Validation loss: 3.3005017432071417

Epoch: 5| Step: 3
Training loss: 3.2246102622462436
Validation loss: 3.3013434416571634

Epoch: 5| Step: 4
Training loss: 4.297689242809302
Validation loss: 3.303031968863897

Epoch: 5| Step: 5
Training loss: 3.1588829313867492
Validation loss: 3.301999943342343

Epoch: 5| Step: 6
Training loss: 3.8243181256639383
Validation loss: 3.298929191643081

Epoch: 5| Step: 7
Training loss: 3.101064800619949
Validation loss: 3.297965432346645

Epoch: 5| Step: 8
Training loss: 2.3897566870212628
Validation loss: 3.296985276984848

Epoch: 5| Step: 9
Training loss: 4.311703373404137
Validation loss: 3.2971962089616036

Epoch: 5| Step: 10
Training loss: 3.4066243097268694
Validation loss: 3.2966660545772672

Epoch: 47| Step: 0
Training loss: 3.6241681690144243
Validation loss: 3.2956028451056225

Epoch: 5| Step: 1
Training loss: 3.608635368363193
Validation loss: 3.2966988446541667

Epoch: 5| Step: 2
Training loss: 3.919121737089129
Validation loss: 3.294140026811537

Epoch: 5| Step: 3
Training loss: 3.576747312557965
Validation loss: 3.295643931830386

Epoch: 5| Step: 4
Training loss: 2.9923860568707528
Validation loss: 3.294425833406493

Epoch: 5| Step: 5
Training loss: 4.021109905844147
Validation loss: 3.2973357563282164

Epoch: 5| Step: 6
Training loss: 3.511005672918532
Validation loss: 3.2954200310522577

Epoch: 5| Step: 7
Training loss: 3.3043755278091775
Validation loss: 3.2954487167046085

Epoch: 5| Step: 8
Training loss: 3.2254926556580625
Validation loss: 3.2931074154302937

Epoch: 5| Step: 9
Training loss: 3.729985294671001
Validation loss: 3.2921212379495843

Epoch: 5| Step: 10
Training loss: 3.265436924533296
Validation loss: 3.29303890710129

Epoch: 48| Step: 0
Training loss: 3.0518367177299264
Validation loss: 3.291356900957847

Epoch: 5| Step: 1
Training loss: 3.7595794393835007
Validation loss: 3.2912926597057175

Epoch: 5| Step: 2
Training loss: 4.057281663888036
Validation loss: 3.291450426925604

Epoch: 5| Step: 3
Training loss: 3.5546899145767896
Validation loss: 3.2913004722242976

Epoch: 5| Step: 4
Training loss: 3.287951211460613
Validation loss: 3.291400119544679

Epoch: 5| Step: 5
Training loss: 3.352383599703433
Validation loss: 3.2909095322271136

Epoch: 5| Step: 6
Training loss: 3.4956819600798688
Validation loss: 3.290463190313542

Epoch: 5| Step: 7
Training loss: 3.419645515050997
Validation loss: 3.2904292114886142

Epoch: 5| Step: 8
Training loss: 3.3818683672282805
Validation loss: 3.2900452416519075

Epoch: 5| Step: 9
Training loss: 3.6219728919056955
Validation loss: 3.2903386265835755

Epoch: 5| Step: 10
Training loss: 3.872732175660296
Validation loss: 3.2884526468627224

Epoch: 49| Step: 0
Training loss: 2.9809194001642982
Validation loss: 3.28773525810383

Epoch: 5| Step: 1
Training loss: 4.257915082623193
Validation loss: 3.2876826161630097

Epoch: 5| Step: 2
Training loss: 3.525932291532992
Validation loss: 3.286870777095818

Epoch: 5| Step: 3
Training loss: 3.592629299398694
Validation loss: 3.286793280526468

Epoch: 5| Step: 4
Training loss: 4.138907828632575
Validation loss: 3.286093293537038

Epoch: 5| Step: 5
Training loss: 2.969358040631327
Validation loss: 3.2848753512566313

Epoch: 5| Step: 6
Training loss: 3.210008027253854
Validation loss: 3.28442838289469

Epoch: 5| Step: 7
Training loss: 3.904005825077464
Validation loss: 3.2877014101578093

Epoch: 5| Step: 8
Training loss: 3.385930058603599
Validation loss: 3.286624569141439

Epoch: 5| Step: 9
Training loss: 3.527852542381982
Validation loss: 3.28456771327512

Epoch: 5| Step: 10
Training loss: 3.0203838847131927
Validation loss: 3.28832838352784

Epoch: 50| Step: 0
Training loss: 4.316712464392798
Validation loss: 3.2841161692167007

Epoch: 5| Step: 1
Training loss: 3.591172596050491
Validation loss: 3.286381768074716

Epoch: 5| Step: 2
Training loss: 3.4652100791935165
Validation loss: 3.2845249363206257

Epoch: 5| Step: 3
Training loss: 2.9040184067071855
Validation loss: 3.2848765265956303

Epoch: 5| Step: 4
Training loss: 3.792996910297112
Validation loss: 3.2837062535421273

Epoch: 5| Step: 5
Training loss: 3.5643783436076752
Validation loss: 3.2825352625860833

Epoch: 5| Step: 6
Training loss: 3.80883875914645
Validation loss: 3.2823485895380853

Epoch: 5| Step: 7
Training loss: 3.645837286084167
Validation loss: 3.2811653278635777

Epoch: 5| Step: 8
Training loss: 3.1501484427216506
Validation loss: 3.282623430167648

Epoch: 5| Step: 9
Training loss: 3.2354619507937628
Validation loss: 3.2827630933040224

Epoch: 5| Step: 10
Training loss: 3.067710958500221
Validation loss: 3.281494836223161

Epoch: 51| Step: 0
Training loss: 2.4156018136356403
Validation loss: 3.2814716473248073

Epoch: 5| Step: 1
Training loss: 3.4237601604777472
Validation loss: 3.281057522661474

Epoch: 5| Step: 2
Training loss: 3.6879748022579877
Validation loss: 3.281753118630121

Epoch: 5| Step: 3
Training loss: 4.276113059609108
Validation loss: 3.2782454869287876

Epoch: 5| Step: 4
Training loss: 3.142769607959804
Validation loss: 3.2793437571323

Epoch: 5| Step: 5
Training loss: 3.341629496785456
Validation loss: 3.2794034200673132

Epoch: 5| Step: 6
Training loss: 3.5487562391677083
Validation loss: 3.2776766804261963

Epoch: 5| Step: 7
Training loss: 3.7326864471165795
Validation loss: 3.2780763058999227

Epoch: 5| Step: 8
Training loss: 3.8893034502105674
Validation loss: 3.278455648573747

Epoch: 5| Step: 9
Training loss: 3.2672239340780727
Validation loss: 3.2785631577434184

Epoch: 5| Step: 10
Training loss: 3.799180700420263
Validation loss: 3.278140731075099

Epoch: 52| Step: 0
Training loss: 3.232121221384136
Validation loss: 3.277703572258228

Epoch: 5| Step: 1
Training loss: 2.4890392352667456
Validation loss: 3.2768754705837386

Epoch: 5| Step: 2
Training loss: 3.68115179322726
Validation loss: 3.276648098950771

Epoch: 5| Step: 3
Training loss: 3.0242469354654826
Validation loss: 3.278997458495775

Epoch: 5| Step: 4
Training loss: 3.5824834274047097
Validation loss: 3.2756000838551147

Epoch: 5| Step: 5
Training loss: 4.037991822701611
Validation loss: 3.275910972741386

Epoch: 5| Step: 6
Training loss: 4.174267257988315
Validation loss: 3.2754632945424342

Epoch: 5| Step: 7
Training loss: 3.647038520343879
Validation loss: 3.276906656974944

Epoch: 5| Step: 8
Training loss: 3.523951321710566
Validation loss: 3.2743573793629026

Epoch: 5| Step: 9
Training loss: 3.704393901799254
Validation loss: 3.2751221627830924

Epoch: 5| Step: 10
Training loss: 3.345772247580254
Validation loss: 3.2748050897533094

Epoch: 53| Step: 0
Training loss: 3.219099303615545
Validation loss: 3.2742205240393285

Epoch: 5| Step: 1
Training loss: 3.33107701866965
Validation loss: 3.2738136950326315

Epoch: 5| Step: 2
Training loss: 3.651005823210662
Validation loss: 3.272248667254437

Epoch: 5| Step: 3
Training loss: 2.695424837729141
Validation loss: 3.273976864937402

Epoch: 5| Step: 4
Training loss: 3.8920156911864954
Validation loss: 3.273366279795469

Epoch: 5| Step: 5
Training loss: 3.262798929952596
Validation loss: 3.273316849691134

Epoch: 5| Step: 6
Training loss: 3.9050111560930816
Validation loss: 3.2713915438238965

Epoch: 5| Step: 7
Training loss: 4.069210672155568
Validation loss: 3.2708481918341294

Epoch: 5| Step: 8
Training loss: 3.397255036292714
Validation loss: 3.2695822851260266

Epoch: 5| Step: 9
Training loss: 3.719124783134717
Validation loss: 3.268427056508259

Epoch: 5| Step: 10
Training loss: 3.3364301759927333
Validation loss: 3.2692618894527303

Epoch: 54| Step: 0
Training loss: 3.130919686139312
Validation loss: 3.26843254862919

Epoch: 5| Step: 1
Training loss: 3.8896830081002
Validation loss: 3.2684075320299097

Epoch: 5| Step: 2
Training loss: 3.6359871723632815
Validation loss: 3.2677770425028037

Epoch: 5| Step: 3
Training loss: 4.10423926791089
Validation loss: 3.2700043356587822

Epoch: 5| Step: 4
Training loss: 3.536490813355694
Validation loss: 3.2697259080975005

Epoch: 5| Step: 5
Training loss: 3.168835165169705
Validation loss: 3.266493863697464

Epoch: 5| Step: 6
Training loss: 3.7409275936409485
Validation loss: 3.2674715011123

Epoch: 5| Step: 7
Training loss: 3.7423271519479737
Validation loss: 3.2672891130742037

Epoch: 5| Step: 8
Training loss: 3.0571658332226157
Validation loss: 3.2657205707319013

Epoch: 5| Step: 9
Training loss: 3.1034205177863483
Validation loss: 3.2654298430724866

Epoch: 5| Step: 10
Training loss: 3.359047097459948
Validation loss: 3.266431408725963

Epoch: 55| Step: 0
Training loss: 4.153943102811063
Validation loss: 3.2680338870302954

Epoch: 5| Step: 1
Training loss: 2.954369983931113
Validation loss: 3.2692074067853034

Epoch: 5| Step: 2
Training loss: 3.2302805466357167
Validation loss: 3.2712077536617845

Epoch: 5| Step: 3
Training loss: 3.948799148741558
Validation loss: 3.269247137708125

Epoch: 5| Step: 4
Training loss: 3.995211238122365
Validation loss: 3.2674768198750552

Epoch: 5| Step: 5
Training loss: 3.877682280495559
Validation loss: 3.263090336692212

Epoch: 5| Step: 6
Training loss: 3.8401032803474635
Validation loss: 3.2628843026225844

Epoch: 5| Step: 7
Training loss: 2.8729678725966736
Validation loss: 3.2663211385708464

Epoch: 5| Step: 8
Training loss: 3.5874254385081605
Validation loss: 3.2635964716371184

Epoch: 5| Step: 9
Training loss: 2.5609297244295472
Validation loss: 3.26179353499183

Epoch: 5| Step: 10
Training loss: 3.172570964960431
Validation loss: 3.261887108525993

Epoch: 56| Step: 0
Training loss: 3.022702149855848
Validation loss: 3.263325942472297

Epoch: 5| Step: 1
Training loss: 3.688030010862567
Validation loss: 3.2610137395632997

Epoch: 5| Step: 2
Training loss: 3.688188133042011
Validation loss: 3.260777474158623

Epoch: 5| Step: 3
Training loss: 3.6292187050126197
Validation loss: 3.260044605977429

Epoch: 5| Step: 4
Training loss: 3.446925747896411
Validation loss: 3.2614047019088908

Epoch: 5| Step: 5
Training loss: 4.068549479100826
Validation loss: 3.259148013412683

Epoch: 5| Step: 6
Training loss: 3.365184497961778
Validation loss: 3.260967956712374

Epoch: 5| Step: 7
Training loss: 3.110126500393466
Validation loss: 3.2588084101746775

Epoch: 5| Step: 8
Training loss: 3.2261483801852138
Validation loss: 3.2588092818164207

Epoch: 5| Step: 9
Training loss: 3.6920066062727623
Validation loss: 3.2593416257133234

Epoch: 5| Step: 10
Training loss: 3.559885638468203
Validation loss: 3.260029977665286

Epoch: 57| Step: 0
Training loss: 3.9008628624282817
Validation loss: 3.258419840849514

Epoch: 5| Step: 1
Training loss: 3.7672853726900843
Validation loss: 3.259044630717559

Epoch: 5| Step: 2
Training loss: 4.114613722033086
Validation loss: 3.25666813023361

Epoch: 5| Step: 3
Training loss: 3.5709095795784163
Validation loss: 3.256482272350777

Epoch: 5| Step: 4
Training loss: 2.6928885797398054
Validation loss: 3.2583843303896622

Epoch: 5| Step: 5
Training loss: 3.5737779355900328
Validation loss: 3.2592192485591243

Epoch: 5| Step: 6
Training loss: 3.7382012720431703
Validation loss: 3.261416734803315

Epoch: 5| Step: 7
Training loss: 3.4581905166980422
Validation loss: 3.258482824661907

Epoch: 5| Step: 8
Training loss: 3.342842620659702
Validation loss: 3.257989317894153

Epoch: 5| Step: 9
Training loss: 2.8707502717587148
Validation loss: 3.2598715611551277

Epoch: 5| Step: 10
Training loss: 3.262476375099672
Validation loss: 3.2593948040386733

Epoch: 58| Step: 0
Training loss: 3.7041368349559707
Validation loss: 3.2581783960815747

Epoch: 5| Step: 1
Training loss: 2.968227621598965
Validation loss: 3.254048607887793

Epoch: 5| Step: 2
Training loss: 3.6376249206696065
Validation loss: 3.2557483097588413

Epoch: 5| Step: 3
Training loss: 3.145046026138689
Validation loss: 3.254672236181277

Epoch: 5| Step: 4
Training loss: 3.6925841374713033
Validation loss: 3.259586602186002

Epoch: 5| Step: 5
Training loss: 2.654000979471493
Validation loss: 3.257134449896781

Epoch: 5| Step: 6
Training loss: 2.9504351602064602
Validation loss: 3.2611995526219917

Epoch: 5| Step: 7
Training loss: 3.7500891357000836
Validation loss: 3.2545171823812398

Epoch: 5| Step: 8
Training loss: 4.193549497902394
Validation loss: 3.2535773499341336

Epoch: 5| Step: 9
Training loss: 3.823460941219455
Validation loss: 3.2545911466529107

Epoch: 5| Step: 10
Training loss: 3.778193602085053
Validation loss: 3.252849326891236

Epoch: 59| Step: 0
Training loss: 2.738900238470979
Validation loss: 3.2525104989450058

Epoch: 5| Step: 1
Training loss: 3.337612615964166
Validation loss: 3.2542964091437203

Epoch: 5| Step: 2
Training loss: 3.1034212860307684
Validation loss: 3.2542655945438006

Epoch: 5| Step: 3
Training loss: 3.7785571889997898
Validation loss: 3.2539890536156766

Epoch: 5| Step: 4
Training loss: 3.491859505972175
Validation loss: 3.25106084120821

Epoch: 5| Step: 5
Training loss: 3.411196695248862
Validation loss: 3.25234310067601

Epoch: 5| Step: 6
Training loss: 4.14624287229471
Validation loss: 3.251218452994293

Epoch: 5| Step: 7
Training loss: 4.047682751493536
Validation loss: 3.2499771732636185

Epoch: 5| Step: 8
Training loss: 3.340620483737958
Validation loss: 3.2509320778602153

Epoch: 5| Step: 9
Training loss: 3.3284886121241333
Validation loss: 3.25045721326145

Epoch: 5| Step: 10
Training loss: 3.612259541992832
Validation loss: 3.2554561969855813

Epoch: 60| Step: 0
Training loss: 3.179607118532517
Validation loss: 3.2516159161166174

Epoch: 5| Step: 1
Training loss: 3.262144287127199
Validation loss: 3.252096334615886

Epoch: 5| Step: 2
Training loss: 2.7870108273572676
Validation loss: 3.2504391543119415

Epoch: 5| Step: 3
Training loss: 4.044782296300123
Validation loss: 3.2514714372160554

Epoch: 5| Step: 4
Training loss: 3.010034310281573
Validation loss: 3.253024010917388

Epoch: 5| Step: 5
Training loss: 3.5469642661536773
Validation loss: 3.255213254994599

Epoch: 5| Step: 6
Training loss: 3.7250178752700696
Validation loss: 3.257212789067345

Epoch: 5| Step: 7
Training loss: 4.333684662490598
Validation loss: 3.25796077455079

Epoch: 5| Step: 8
Training loss: 3.4928281055684414
Validation loss: 3.251685028322873

Epoch: 5| Step: 9
Training loss: 3.4299478975125672
Validation loss: 3.2509732236694004

Epoch: 5| Step: 10
Training loss: 3.452235871196517
Validation loss: 3.2493544569274353

Epoch: 61| Step: 0
Training loss: 3.596270929248465
Validation loss: 3.249388401361646

Epoch: 5| Step: 1
Training loss: 2.991663954227957
Validation loss: 3.2482274745925195

Epoch: 5| Step: 2
Training loss: 3.0898898925422356
Validation loss: 3.2485176749436255

Epoch: 5| Step: 3
Training loss: 3.3369755079212537
Validation loss: 3.249361298861266

Epoch: 5| Step: 4
Training loss: 4.2388583726452485
Validation loss: 3.248290594473442

Epoch: 5| Step: 5
Training loss: 3.488597688920871
Validation loss: 3.2493032287524755

Epoch: 5| Step: 6
Training loss: 3.6395762492421904
Validation loss: 3.2463573096436504

Epoch: 5| Step: 7
Training loss: 3.8479695303933914
Validation loss: 3.2482060323692714

Epoch: 5| Step: 8
Training loss: 2.2160282903235697
Validation loss: 3.246271452583252

Epoch: 5| Step: 9
Training loss: 4.07064191250397
Validation loss: 3.2467113417899096

Epoch: 5| Step: 10
Training loss: 3.5413575130991077
Validation loss: 3.2459179158438394

Epoch: 62| Step: 0
Training loss: 3.2377083965377027
Validation loss: 3.2462059021267207

Epoch: 5| Step: 1
Training loss: 2.9778609359890122
Validation loss: 3.243825929377294

Epoch: 5| Step: 2
Training loss: 3.4878849432368466
Validation loss: 3.245296327559721

Epoch: 5| Step: 3
Training loss: 3.9891427031663818
Validation loss: 3.2442423553823927

Epoch: 5| Step: 4
Training loss: 3.5211824022114437
Validation loss: 3.2473306839884506

Epoch: 5| Step: 5
Training loss: 3.7058198676019427
Validation loss: 3.2464334545537867

Epoch: 5| Step: 6
Training loss: 3.9196232262370243
Validation loss: 3.2478885417804695

Epoch: 5| Step: 7
Training loss: 3.9495013972558954
Validation loss: 3.244950981589638

Epoch: 5| Step: 8
Training loss: 3.3631573342989802
Validation loss: 3.24450900002873

Epoch: 5| Step: 9
Training loss: 3.245741475037456
Validation loss: 3.248579197455673

Epoch: 5| Step: 10
Training loss: 2.7077184027926577
Validation loss: 3.2486248861969598

Epoch: 63| Step: 0
Training loss: 3.329767958887553
Validation loss: 3.2591013064377927

Epoch: 5| Step: 1
Training loss: 4.078459861132286
Validation loss: 3.248357894371821

Epoch: 5| Step: 2
Training loss: 3.7014884068556024
Validation loss: 3.2481899237743757

Epoch: 5| Step: 3
Training loss: 3.050019192244384
Validation loss: 3.246753088281897

Epoch: 5| Step: 4
Training loss: 3.2070505789802715
Validation loss: 3.243420550480928

Epoch: 5| Step: 5
Training loss: 4.204266134445826
Validation loss: 3.2423814529976114

Epoch: 5| Step: 6
Training loss: 2.8974044892019912
Validation loss: 3.2421408317677436

Epoch: 5| Step: 7
Training loss: 3.9873966502605165
Validation loss: 3.240689663293251

Epoch: 5| Step: 8
Training loss: 3.43506105771278
Validation loss: 3.2386129193514677

Epoch: 5| Step: 9
Training loss: 2.988953119680526
Validation loss: 3.2388583325839084

Epoch: 5| Step: 10
Training loss: 3.2560581084837468
Validation loss: 3.239326243425423

Epoch: 64| Step: 0
Training loss: 3.230747418452259
Validation loss: 3.238124819141576

Epoch: 5| Step: 1
Training loss: 4.476674556161874
Validation loss: 3.238465014463334

Epoch: 5| Step: 2
Training loss: 2.88522527360613
Validation loss: 3.238505850826064

Epoch: 5| Step: 3
Training loss: 3.1632072894192316
Validation loss: 3.24089010299424

Epoch: 5| Step: 4
Training loss: 3.4018820658520514
Validation loss: 3.2536437793393755

Epoch: 5| Step: 5
Training loss: 3.859337439721074
Validation loss: 3.2433769075527787

Epoch: 5| Step: 6
Training loss: 3.6437967915744935
Validation loss: 3.2439792482261045

Epoch: 5| Step: 7
Training loss: 3.2385686693919564
Validation loss: 3.240892145432529

Epoch: 5| Step: 8
Training loss: 3.6290225368629336
Validation loss: 3.2369294750016313

Epoch: 5| Step: 9
Training loss: 3.538221920473687
Validation loss: 3.237657514610875

Epoch: 5| Step: 10
Training loss: 2.9825721607927504
Validation loss: 3.2405115043036603

Epoch: 65| Step: 0
Training loss: 3.4438472062530723
Validation loss: 3.237654559538828

Epoch: 5| Step: 1
Training loss: 3.3078066127113854
Validation loss: 3.2368374673234803

Epoch: 5| Step: 2
Training loss: 3.8034129426354735
Validation loss: 3.238586758911793

Epoch: 5| Step: 3
Training loss: 3.7474623677080063
Validation loss: 3.2362633221501556

Epoch: 5| Step: 4
Training loss: 3.884934028055528
Validation loss: 3.2347675545185184

Epoch: 5| Step: 5
Training loss: 3.506493947183674
Validation loss: 3.2350780659605043

Epoch: 5| Step: 6
Training loss: 2.8993954784790916
Validation loss: 3.2344499828700086

Epoch: 5| Step: 7
Training loss: 3.7467267055610756
Validation loss: 3.2356022804982576

Epoch: 5| Step: 8
Training loss: 3.1360076820415683
Validation loss: 3.235107459417022

Epoch: 5| Step: 9
Training loss: 3.519224773785109
Validation loss: 3.235375506669456

Epoch: 5| Step: 10
Training loss: 3.2149665595847257
Validation loss: 3.232634541509519

Epoch: 66| Step: 0
Training loss: 4.486214396754513
Validation loss: 3.234556118839616

Epoch: 5| Step: 1
Training loss: 3.389828918101051
Validation loss: 3.2328793610309496

Epoch: 5| Step: 2
Training loss: 3.630638210215466
Validation loss: 3.2329216509049616

Epoch: 5| Step: 3
Training loss: 3.86947138998218
Validation loss: 3.2340221572221353

Epoch: 5| Step: 4
Training loss: 3.381601447210821
Validation loss: 3.2307977521877658

Epoch: 5| Step: 5
Training loss: 2.7047676872297783
Validation loss: 3.229382138137408

Epoch: 5| Step: 6
Training loss: 3.0408884559653835
Validation loss: 3.2309433261538434

Epoch: 5| Step: 7
Training loss: 3.530718873177752
Validation loss: 3.2317214522712754

Epoch: 5| Step: 8
Training loss: 3.5451084392625245
Validation loss: 3.2296781824816763

Epoch: 5| Step: 9
Training loss: 2.6588827213219894
Validation loss: 3.2292802015994293

Epoch: 5| Step: 10
Training loss: 3.755136913338186
Validation loss: 3.228973456459934

Epoch: 67| Step: 0
Training loss: 3.4383506415987477
Validation loss: 3.2274037630323487

Epoch: 5| Step: 1
Training loss: 3.6414188943777197
Validation loss: 3.2265613955859083

Epoch: 5| Step: 2
Training loss: 3.22099433355061
Validation loss: 3.226593320151573

Epoch: 5| Step: 3
Training loss: 3.84484326701685
Validation loss: 3.2241797792185136

Epoch: 5| Step: 4
Training loss: 3.3109979642898075
Validation loss: 3.224904444058614

Epoch: 5| Step: 5
Training loss: 3.193697719556653
Validation loss: 3.2224504604866024

Epoch: 5| Step: 6
Training loss: 3.7531196333745975
Validation loss: 3.222771184170024

Epoch: 5| Step: 7
Training loss: 3.22662944585702
Validation loss: 3.2281910454892526

Epoch: 5| Step: 8
Training loss: 3.6399661274266655
Validation loss: 3.228185267310175

Epoch: 5| Step: 9
Training loss: 3.2438531113187756
Validation loss: 3.2175662281895385

Epoch: 5| Step: 10
Training loss: 3.712630164950344
Validation loss: 3.2154650031269854

Epoch: 68| Step: 0
Training loss: 3.214531958699583
Validation loss: 3.2192854562844078

Epoch: 5| Step: 1
Training loss: 3.352503219932927
Validation loss: 3.2162732492374375

Epoch: 5| Step: 2
Training loss: 2.886858987047374
Validation loss: 3.2155284982433057

Epoch: 5| Step: 3
Training loss: 3.682532763468115
Validation loss: 3.2131286271621082

Epoch: 5| Step: 4
Training loss: 3.6171284417424965
Validation loss: 3.2157427810188532

Epoch: 5| Step: 5
Training loss: 4.250445623035867
Validation loss: 3.215248858393407

Epoch: 5| Step: 6
Training loss: 3.879804647384669
Validation loss: 3.214191192360928

Epoch: 5| Step: 7
Training loss: 2.870799437508721
Validation loss: 3.2095703970395784

Epoch: 5| Step: 8
Training loss: 3.295545409334077
Validation loss: 3.212823143908765

Epoch: 5| Step: 9
Training loss: 3.3324206215289665
Validation loss: 3.2125842748317828

Epoch: 5| Step: 10
Training loss: 3.5834517496340825
Validation loss: 3.2117156131430025

Epoch: 69| Step: 0
Training loss: 4.00035618149902
Validation loss: 3.211664969173935

Epoch: 5| Step: 1
Training loss: 2.737461723861306
Validation loss: 3.2077258338879178

Epoch: 5| Step: 2
Training loss: 2.839150198472653
Validation loss: 3.2091312052925827

Epoch: 5| Step: 3
Training loss: 4.049780550062202
Validation loss: 3.206503063309565

Epoch: 5| Step: 4
Training loss: 4.256005475922697
Validation loss: 3.2064593752273134

Epoch: 5| Step: 5
Training loss: 2.9530479784412704
Validation loss: 3.2077463798652865

Epoch: 5| Step: 6
Training loss: 3.93237819281701
Validation loss: 3.203292172419232

Epoch: 5| Step: 7
Training loss: 3.290404129948008
Validation loss: 3.2043571641380098

Epoch: 5| Step: 8
Training loss: 3.5157904691962254
Validation loss: 3.202363226522721

Epoch: 5| Step: 9
Training loss: 3.4255187261334332
Validation loss: 3.205129831274234

Epoch: 5| Step: 10
Training loss: 2.41651845894095
Validation loss: 3.2030311040474477

Epoch: 70| Step: 0
Training loss: 3.0236377896150337
Validation loss: 3.2030591508253026

Epoch: 5| Step: 1
Training loss: 3.3516908278717548
Validation loss: 3.205954358613705

Epoch: 5| Step: 2
Training loss: 3.4129078044985093
Validation loss: 3.211736428934902

Epoch: 5| Step: 3
Training loss: 3.5629312354643417
Validation loss: 3.2271573269933187

Epoch: 5| Step: 4
Training loss: 3.4438977440020744
Validation loss: 3.2096855218403424

Epoch: 5| Step: 5
Training loss: 4.216562792035096
Validation loss: 3.2036067877437016

Epoch: 5| Step: 6
Training loss: 3.0241452357217042
Validation loss: 3.1998485648562647

Epoch: 5| Step: 7
Training loss: 3.591713900745995
Validation loss: 3.2028343438975555

Epoch: 5| Step: 8
Training loss: 2.917016871181552
Validation loss: 3.2005921408811804

Epoch: 5| Step: 9
Training loss: 3.4496876450822054
Validation loss: 3.199868815306981

Epoch: 5| Step: 10
Training loss: 3.9294426236917803
Validation loss: 3.199279891149341

Epoch: 71| Step: 0
Training loss: 3.006576640888135
Validation loss: 3.201714085642767

Epoch: 5| Step: 1
Training loss: 3.6847666292038546
Validation loss: 3.1995554269099067

Epoch: 5| Step: 2
Training loss: 3.8648117011665177
Validation loss: 3.1987900015245336

Epoch: 5| Step: 3
Training loss: 3.543483372906172
Validation loss: 3.1990893208293447

Epoch: 5| Step: 4
Training loss: 3.4462485220500887
Validation loss: 3.1981359686329105

Epoch: 5| Step: 5
Training loss: 3.3523490356318297
Validation loss: 3.197094885094354

Epoch: 5| Step: 6
Training loss: 3.7001618066409887
Validation loss: 3.1984811049360964

Epoch: 5| Step: 7
Training loss: 3.7929780529784214
Validation loss: 3.1988626657284938

Epoch: 5| Step: 8
Training loss: 2.6928133227738966
Validation loss: 3.1959735294821736

Epoch: 5| Step: 9
Training loss: 3.0909602370084897
Validation loss: 3.1972462577122243

Epoch: 5| Step: 10
Training loss: 3.717562574053649
Validation loss: 3.1980411887021103

Epoch: 72| Step: 0
Training loss: 3.749793237708117
Validation loss: 3.197209124855483

Epoch: 5| Step: 1
Training loss: 3.770877577941865
Validation loss: 3.1942665941100823

Epoch: 5| Step: 2
Training loss: 3.6160293603565967
Validation loss: 3.1941374410230843

Epoch: 5| Step: 3
Training loss: 3.4866255945834217
Validation loss: 3.195144396570977

Epoch: 5| Step: 4
Training loss: 3.036797235768611
Validation loss: 3.1942413530056952

Epoch: 5| Step: 5
Training loss: 2.9153992396832384
Validation loss: 3.192539584744224

Epoch: 5| Step: 6
Training loss: 3.3333896314317237
Validation loss: 3.193095956222199

Epoch: 5| Step: 7
Training loss: 4.043929394099012
Validation loss: 3.1928552403294557

Epoch: 5| Step: 8
Training loss: 3.1493809046219643
Validation loss: 3.1927267512105884

Epoch: 5| Step: 9
Training loss: 3.5690800983465034
Validation loss: 3.1945297558559695

Epoch: 5| Step: 10
Training loss: 3.1051513509673807
Validation loss: 3.19271265436552

Epoch: 73| Step: 0
Training loss: 3.69957579165612
Validation loss: 3.1923459314469285

Epoch: 5| Step: 1
Training loss: 2.955855303298124
Validation loss: 3.194488052372504

Epoch: 5| Step: 2
Training loss: 3.1422262332602293
Validation loss: 3.191775680047271

Epoch: 5| Step: 3
Training loss: 3.25573576456265
Validation loss: 3.191729567886893

Epoch: 5| Step: 4
Training loss: 3.311216861592153
Validation loss: 3.1922000380759066

Epoch: 5| Step: 5
Training loss: 3.5883623954090997
Validation loss: 3.194319096573449

Epoch: 5| Step: 6
Training loss: 3.7112754266368317
Validation loss: 3.1939887905278725

Epoch: 5| Step: 7
Training loss: 3.9948738152696084
Validation loss: 3.191282431725584

Epoch: 5| Step: 8
Training loss: 3.3928980086310663
Validation loss: 3.190821964891547

Epoch: 5| Step: 9
Training loss: 3.572027616669626
Validation loss: 3.191812924307087

Epoch: 5| Step: 10
Training loss: 3.166217889272795
Validation loss: 3.1921026596873645

Epoch: 74| Step: 0
Training loss: 3.1998557177441427
Validation loss: 3.1904536489986577

Epoch: 5| Step: 1
Training loss: 3.9318079905696095
Validation loss: 3.190164364951413

Epoch: 5| Step: 2
Training loss: 3.4672279111442017
Validation loss: 3.1920041113593176

Epoch: 5| Step: 3
Training loss: 3.495292495035929
Validation loss: 3.190558756051571

Epoch: 5| Step: 4
Training loss: 3.6911989184086558
Validation loss: 3.189601433095249

Epoch: 5| Step: 5
Training loss: 2.882694397034541
Validation loss: 3.189633116744145

Epoch: 5| Step: 6
Training loss: 3.2040569159301806
Validation loss: 3.188991553948886

Epoch: 5| Step: 7
Training loss: 3.2805228744660537
Validation loss: 3.1905507177438053

Epoch: 5| Step: 8
Training loss: 3.405592268690062
Validation loss: 3.190040246935469

Epoch: 5| Step: 9
Training loss: 3.565484118875461
Validation loss: 3.1877503430483562

Epoch: 5| Step: 10
Training loss: 3.7391741572158312
Validation loss: 3.190685842830882

Epoch: 75| Step: 0
Training loss: 3.8386937822543827
Validation loss: 3.193628132726562

Epoch: 5| Step: 1
Training loss: 4.055519562536857
Validation loss: 3.1922211690477558

Epoch: 5| Step: 2
Training loss: 3.0819071658917316
Validation loss: 3.1895265516955544

Epoch: 5| Step: 3
Training loss: 3.255528369684453
Validation loss: 3.189384349036283

Epoch: 5| Step: 4
Training loss: 3.2759631480565097
Validation loss: 3.187181304435314

Epoch: 5| Step: 5
Training loss: 3.581712814703563
Validation loss: 3.1883799082183146

Epoch: 5| Step: 6
Training loss: 3.5402456836252547
Validation loss: 3.185588660125538

Epoch: 5| Step: 7
Training loss: 2.7893710780474086
Validation loss: 3.186264355146398

Epoch: 5| Step: 8
Training loss: 3.5687746705172887
Validation loss: 3.1871144903894644

Epoch: 5| Step: 9
Training loss: 3.218134997232496
Validation loss: 3.186142697007426

Epoch: 5| Step: 10
Training loss: 3.5388380236307957
Validation loss: 3.1870788257358025

Epoch: 76| Step: 0
Training loss: 3.1775073326140286
Validation loss: 3.1857672028339308

Epoch: 5| Step: 1
Training loss: 3.921332454769067
Validation loss: 3.1880488798771123

Epoch: 5| Step: 2
Training loss: 3.7501118961170263
Validation loss: 3.183549701630797

Epoch: 5| Step: 3
Training loss: 2.7564194054130438
Validation loss: 3.1834690214760313

Epoch: 5| Step: 4
Training loss: 3.634357214217484
Validation loss: 3.185628363615129

Epoch: 5| Step: 5
Training loss: 3.030909410986244
Validation loss: 3.1854098096311625

Epoch: 5| Step: 6
Training loss: 3.352088157851069
Validation loss: 3.1838364367272707

Epoch: 5| Step: 7
Training loss: 3.3722271301412574
Validation loss: 3.183922106153088

Epoch: 5| Step: 8
Training loss: 3.998107104646779
Validation loss: 3.1819854146424698

Epoch: 5| Step: 9
Training loss: 3.8286239610252304
Validation loss: 3.1830908086086427

Epoch: 5| Step: 10
Training loss: 2.6622707572713136
Validation loss: 3.185532075198693

Epoch: 77| Step: 0
Training loss: 2.982378546519333
Validation loss: 3.1870250762300216

Epoch: 5| Step: 1
Training loss: 4.024444276344057
Validation loss: 3.189062362567757

Epoch: 5| Step: 2
Training loss: 2.9168262619677714
Validation loss: 3.1888449604319313

Epoch: 5| Step: 3
Training loss: 2.642808541841532
Validation loss: 3.1906207461193823

Epoch: 5| Step: 4
Training loss: 3.2531964648749248
Validation loss: 3.186186901026401

Epoch: 5| Step: 5
Training loss: 3.9224349758187667
Validation loss: 3.1791430857839185

Epoch: 5| Step: 6
Training loss: 3.7358746570006636
Validation loss: 3.178818266750749

Epoch: 5| Step: 7
Training loss: 3.6068193379616806
Validation loss: 3.179212120390413

Epoch: 5| Step: 8
Training loss: 3.4853926057929416
Validation loss: 3.1819404416419963

Epoch: 5| Step: 9
Training loss: 3.810094230668032
Validation loss: 3.1822999299200574

Epoch: 5| Step: 10
Training loss: 3.1641697994923614
Validation loss: 3.1799744591951677

Epoch: 78| Step: 0
Training loss: 3.1946489535855904
Validation loss: 3.179838643519756

Epoch: 5| Step: 1
Training loss: 4.019687364102705
Validation loss: 3.1793674697866954

Epoch: 5| Step: 2
Training loss: 2.9090003668718314
Validation loss: 3.1783473563421447

Epoch: 5| Step: 3
Training loss: 3.69166071584895
Validation loss: 3.1807193541672603

Epoch: 5| Step: 4
Training loss: 3.6078739099905675
Validation loss: 3.182044347486034

Epoch: 5| Step: 5
Training loss: 3.08203078585429
Validation loss: 3.1811048876919403

Epoch: 5| Step: 6
Training loss: 3.867386506479916
Validation loss: 3.1825109288490103

Epoch: 5| Step: 7
Training loss: 2.8194928867164446
Validation loss: 3.1801746377519216

Epoch: 5| Step: 8
Training loss: 3.023830496704922
Validation loss: 3.1801228288366223

Epoch: 5| Step: 9
Training loss: 3.709199582767124
Validation loss: 3.1772903033373256

Epoch: 5| Step: 10
Training loss: 3.7294657212582125
Validation loss: 3.1803972513817147

Epoch: 79| Step: 0
Training loss: 4.000038623623341
Validation loss: 3.1795432189116988

Epoch: 5| Step: 1
Training loss: 3.2801346109261886
Validation loss: 3.1770250131844535

Epoch: 5| Step: 2
Training loss: 3.5484860160329568
Validation loss: 3.179353107285168

Epoch: 5| Step: 3
Training loss: 3.2919465601906976
Validation loss: 3.178087036346178

Epoch: 5| Step: 4
Training loss: 3.0002695598296873
Validation loss: 3.1779355255611015

Epoch: 5| Step: 5
Training loss: 3.079692615677036
Validation loss: 3.1768179511162837

Epoch: 5| Step: 6
Training loss: 3.4351121411626844
Validation loss: 3.1776095810656972

Epoch: 5| Step: 7
Training loss: 4.270862089230873
Validation loss: 3.181317516322586

Epoch: 5| Step: 8
Training loss: 3.6248171530023683
Validation loss: 3.174296793547492

Epoch: 5| Step: 9
Training loss: 3.142352032633688
Validation loss: 3.1766079234105615

Epoch: 5| Step: 10
Training loss: 2.799958303686034
Validation loss: 3.1753547558761395

Epoch: 80| Step: 0
Training loss: 3.6107875157318032
Validation loss: 3.174704428885298

Epoch: 5| Step: 1
Training loss: 2.9224099062305036
Validation loss: 3.1761702006841257

Epoch: 5| Step: 2
Training loss: 2.8380636856858565
Validation loss: 3.173346390303941

Epoch: 5| Step: 3
Training loss: 3.965579110339231
Validation loss: 3.1732617409100494

Epoch: 5| Step: 4
Training loss: 3.5670871314466823
Validation loss: 3.174391818060196

Epoch: 5| Step: 5
Training loss: 2.9009459301111957
Validation loss: 3.1727757129024954

Epoch: 5| Step: 6
Training loss: 3.650446140771339
Validation loss: 3.173919586151151

Epoch: 5| Step: 7
Training loss: 3.3209233698172325
Validation loss: 3.1730014076562667

Epoch: 5| Step: 8
Training loss: 3.889499240995314
Validation loss: 3.1741718135808346

Epoch: 5| Step: 9
Training loss: 3.7292973301904118
Validation loss: 3.1739813842623494

Epoch: 5| Step: 10
Training loss: 3.0721445611477733
Validation loss: 3.176823973630706

Epoch: 81| Step: 0
Training loss: 4.031755519191153
Validation loss: 3.1793861977074522

Epoch: 5| Step: 1
Training loss: 3.7238553688735783
Validation loss: 3.189206475060657

Epoch: 5| Step: 2
Training loss: 3.9274292784211293
Validation loss: 3.1755109931145484

Epoch: 5| Step: 3
Training loss: 3.489622262006898
Validation loss: 3.1714782256535656

Epoch: 5| Step: 4
Training loss: 3.0077975978729863
Validation loss: 3.170611881844531

Epoch: 5| Step: 5
Training loss: 3.3767801464427127
Validation loss: 3.1695517936687287

Epoch: 5| Step: 6
Training loss: 3.1592257229547718
Validation loss: 3.1706022639686293

Epoch: 5| Step: 7
Training loss: 3.3364107390379667
Validation loss: 3.167716749743737

Epoch: 5| Step: 8
Training loss: 2.9287560368213965
Validation loss: 3.1690200265704833

Epoch: 5| Step: 9
Training loss: 3.2169153114106956
Validation loss: 3.167774819892876

Epoch: 5| Step: 10
Training loss: 3.373872073983607
Validation loss: 3.169483477211696

Epoch: 82| Step: 0
Training loss: 3.197789507563025
Validation loss: 3.168809138994904

Epoch: 5| Step: 1
Training loss: 3.9383691706394366
Validation loss: 3.1698455258486034

Epoch: 5| Step: 2
Training loss: 3.520699056438693
Validation loss: 3.1693795332700265

Epoch: 5| Step: 3
Training loss: 3.2306100060278653
Validation loss: 3.1675089577852527

Epoch: 5| Step: 4
Training loss: 3.630658567394572
Validation loss: 3.166444100836132

Epoch: 5| Step: 5
Training loss: 3.213424276539699
Validation loss: 3.168695616420776

Epoch: 5| Step: 6
Training loss: 3.155885883139227
Validation loss: 3.167165709346919

Epoch: 5| Step: 7
Training loss: 3.1728674928424336
Validation loss: 3.1673620158950997

Epoch: 5| Step: 8
Training loss: 3.7039096178105075
Validation loss: 3.1697303629658573

Epoch: 5| Step: 9
Training loss: 3.8217307736498403
Validation loss: 3.1674787055528046

Epoch: 5| Step: 10
Training loss: 2.928051300912668
Validation loss: 3.1691566844642534

Epoch: 83| Step: 0
Training loss: 4.019093006736938
Validation loss: 3.1656119744233773

Epoch: 5| Step: 1
Training loss: 2.8701598847942646
Validation loss: 3.167730462533212

Epoch: 5| Step: 2
Training loss: 2.7678518866563806
Validation loss: 3.1666837124023033

Epoch: 5| Step: 3
Training loss: 3.3864798104058766
Validation loss: 3.166674258272131

Epoch: 5| Step: 4
Training loss: 3.231976195436571
Validation loss: 3.16311225715153

Epoch: 5| Step: 5
Training loss: 3.655117152850509
Validation loss: 3.164676744276694

Epoch: 5| Step: 6
Training loss: 3.5168068488747686
Validation loss: 3.1684867882736243

Epoch: 5| Step: 7
Training loss: 3.4753385639611105
Validation loss: 3.167422846051072

Epoch: 5| Step: 8
Training loss: 3.3946177797515684
Validation loss: 3.1625381004071165

Epoch: 5| Step: 9
Training loss: 3.75933692766985
Validation loss: 3.1607494384902584

Epoch: 5| Step: 10
Training loss: 3.417268901565323
Validation loss: 3.164833157095614

Epoch: 84| Step: 0
Training loss: 3.457527909459292
Validation loss: 3.1665526587057484

Epoch: 5| Step: 1
Training loss: 3.583444963239345
Validation loss: 3.1647718948170382

Epoch: 5| Step: 2
Training loss: 3.3039474921314533
Validation loss: 3.1686631821551132

Epoch: 5| Step: 3
Training loss: 3.0222832894077127
Validation loss: 3.1790241566313786

Epoch: 5| Step: 4
Training loss: 3.8734101756533583
Validation loss: 3.191755060178715

Epoch: 5| Step: 5
Training loss: 2.9604562655186832
Validation loss: 3.159196522612964

Epoch: 5| Step: 6
Training loss: 2.8122519489681395
Validation loss: 3.1634843884310766

Epoch: 5| Step: 7
Training loss: 3.7873754147223715
Validation loss: 3.1579121725232167

Epoch: 5| Step: 8
Training loss: 3.1170455403138764
Validation loss: 3.1587410081037226

Epoch: 5| Step: 9
Training loss: 3.852338175014345
Validation loss: 3.158944038437073

Epoch: 5| Step: 10
Training loss: 3.7728905449224
Validation loss: 3.157985054813947

Epoch: 85| Step: 0
Training loss: 3.192207749387026
Validation loss: 3.159762435657791

Epoch: 5| Step: 1
Training loss: 3.3292685679729823
Validation loss: 3.160044000170523

Epoch: 5| Step: 2
Training loss: 4.003207589577266
Validation loss: 3.1605409191627145

Epoch: 5| Step: 3
Training loss: 2.824969813092744
Validation loss: 3.1589073464310884

Epoch: 5| Step: 4
Training loss: 2.870526357625761
Validation loss: 3.157535537694983

Epoch: 5| Step: 5
Training loss: 3.5264936164074507
Validation loss: 3.1579060254536575

Epoch: 5| Step: 6
Training loss: 3.1348705808948414
Validation loss: 3.1556323996661066

Epoch: 5| Step: 7
Training loss: 3.895097605274386
Validation loss: 3.1582337469412285

Epoch: 5| Step: 8
Training loss: 3.410278178304223
Validation loss: 3.156909640988566

Epoch: 5| Step: 9
Training loss: 3.695268497648629
Validation loss: 3.158423930114548

Epoch: 5| Step: 10
Training loss: 3.557737278802766
Validation loss: 3.1536278283362664

Epoch: 86| Step: 0
Training loss: 2.789967793377898
Validation loss: 3.1543973921381245

Epoch: 5| Step: 1
Training loss: 3.464966643862335
Validation loss: 3.1532420686771854

Epoch: 5| Step: 2
Training loss: 3.5829955688500266
Validation loss: 3.1535913102251634

Epoch: 5| Step: 3
Training loss: 2.505999899393066
Validation loss: 3.15386833882157

Epoch: 5| Step: 4
Training loss: 3.4516235125128216
Validation loss: 3.1517398384502995

Epoch: 5| Step: 5
Training loss: 3.4195774673988586
Validation loss: 3.153498665224416

Epoch: 5| Step: 6
Training loss: 3.555449351737898
Validation loss: 3.151879127708303

Epoch: 5| Step: 7
Training loss: 3.885840848756891
Validation loss: 3.152036629417916

Epoch: 5| Step: 8
Training loss: 3.3230055714416173
Validation loss: 3.1529182418572796

Epoch: 5| Step: 9
Training loss: 3.9249597097868034
Validation loss: 3.152416489410951

Epoch: 5| Step: 10
Training loss: 3.443922804912132
Validation loss: 3.151568368032461

Epoch: 87| Step: 0
Training loss: 2.9787706409784516
Validation loss: 3.1515008005941962

Epoch: 5| Step: 1
Training loss: 3.2292557898907557
Validation loss: 3.1502194660689917

Epoch: 5| Step: 2
Training loss: 3.134984811505724
Validation loss: 3.1513367363801543

Epoch: 5| Step: 3
Training loss: 3.761248566109665
Validation loss: 3.1507135529398

Epoch: 5| Step: 4
Training loss: 3.225045722814733
Validation loss: 3.148910831719213

Epoch: 5| Step: 5
Training loss: 3.5847578248355534
Validation loss: 3.148959140531144

Epoch: 5| Step: 6
Training loss: 3.2158762130257568
Validation loss: 3.1508412639717083

Epoch: 5| Step: 7
Training loss: 2.809343134579476
Validation loss: 3.1514026315430783

Epoch: 5| Step: 8
Training loss: 3.6923975345183893
Validation loss: 3.1499461574220673

Epoch: 5| Step: 9
Training loss: 3.7974235232640385
Validation loss: 3.1495268116513513

Epoch: 5| Step: 10
Training loss: 4.03792285889717
Validation loss: 3.1507918058525375

Epoch: 88| Step: 0
Training loss: 3.4096542286012177
Validation loss: 3.1487905490177663

Epoch: 5| Step: 1
Training loss: 3.3904065883624668
Validation loss: 3.1493414181758013

Epoch: 5| Step: 2
Training loss: 3.492263144542166
Validation loss: 3.149286695726733

Epoch: 5| Step: 3
Training loss: 2.547491081005053
Validation loss: 3.147691525179844

Epoch: 5| Step: 4
Training loss: 4.010242699487035
Validation loss: 3.148874838575454

Epoch: 5| Step: 5
Training loss: 3.580711529312623
Validation loss: 3.1490139451985986

Epoch: 5| Step: 6
Training loss: 3.0720227164282923
Validation loss: 3.147645985634983

Epoch: 5| Step: 7
Training loss: 3.422838745963879
Validation loss: 3.1474363994547705

Epoch: 5| Step: 8
Training loss: 3.314182358102642
Validation loss: 3.1479191755601046

Epoch: 5| Step: 9
Training loss: 3.3959929695910325
Validation loss: 3.147460448793537

Epoch: 5| Step: 10
Training loss: 3.771313561196904
Validation loss: 3.146367926030363

Epoch: 89| Step: 0
Training loss: 3.6961172247870704
Validation loss: 3.1463593437970463

Epoch: 5| Step: 1
Training loss: 2.688689656096995
Validation loss: 3.1444069173022395

Epoch: 5| Step: 2
Training loss: 3.9477649884372124
Validation loss: 3.1438547284983227

Epoch: 5| Step: 3
Training loss: 2.8102676857346918
Validation loss: 3.144815117312026

Epoch: 5| Step: 4
Training loss: 3.0098899899780425
Validation loss: 3.1426981935511513

Epoch: 5| Step: 5
Training loss: 3.3326079215040703
Validation loss: 3.1443655649227726

Epoch: 5| Step: 6
Training loss: 3.9019530810062943
Validation loss: 3.1419873609861155

Epoch: 5| Step: 7
Training loss: 3.353737576604206
Validation loss: 3.1436852320540174

Epoch: 5| Step: 8
Training loss: 3.8485372861067244
Validation loss: 3.143638717849967

Epoch: 5| Step: 9
Training loss: 3.2825067928851137
Validation loss: 3.1426085745172334

Epoch: 5| Step: 10
Training loss: 3.339604455060474
Validation loss: 3.1423824468136994

Epoch: 90| Step: 0
Training loss: 3.7573066735802993
Validation loss: 3.142633150258682

Epoch: 5| Step: 1
Training loss: 3.728030509422772
Validation loss: 3.14180059077086

Epoch: 5| Step: 2
Training loss: 3.506278537355319
Validation loss: 3.1435087732289957

Epoch: 5| Step: 3
Training loss: 3.388680036463515
Validation loss: 3.143974138366285

Epoch: 5| Step: 4
Training loss: 3.112802121616445
Validation loss: 3.141012797286974

Epoch: 5| Step: 5
Training loss: 2.962073115886889
Validation loss: 3.1413684337081613

Epoch: 5| Step: 6
Training loss: 3.0465929732254744
Validation loss: 3.1404002070465027

Epoch: 5| Step: 7
Training loss: 3.6866195403450446
Validation loss: 3.1401341482804415

Epoch: 5| Step: 8
Training loss: 3.731327361514154
Validation loss: 3.1424884650151297

Epoch: 5| Step: 9
Training loss: 2.5148232645537774
Validation loss: 3.1417504517773445

Epoch: 5| Step: 10
Training loss: 3.839240677781688
Validation loss: 3.140134538524963

Epoch: 91| Step: 0
Training loss: 2.6247189689245816
Validation loss: 3.141414497593307

Epoch: 5| Step: 1
Training loss: 3.8111629955836643
Validation loss: 3.142095091225979

Epoch: 5| Step: 2
Training loss: 2.50798618749073
Validation loss: 3.1388735678393225

Epoch: 5| Step: 3
Training loss: 3.9114694133792938
Validation loss: 3.1409147607755856

Epoch: 5| Step: 4
Training loss: 3.1902170008212765
Validation loss: 3.1408108598240303

Epoch: 5| Step: 5
Training loss: 3.2229895956858012
Validation loss: 3.1407993696589585

Epoch: 5| Step: 6
Training loss: 3.7929192175415363
Validation loss: 3.141371815584977

Epoch: 5| Step: 7
Training loss: 3.6421432276407546
Validation loss: 3.1409605219756735

Epoch: 5| Step: 8
Training loss: 3.7704473617596483
Validation loss: 3.139487590193162

Epoch: 5| Step: 9
Training loss: 3.2106655776073767
Validation loss: 3.1396922934219615

Epoch: 5| Step: 10
Training loss: 3.4368794661411557
Validation loss: 3.1402115904575187

Epoch: 92| Step: 0
Training loss: 3.6192914804720657
Validation loss: 3.137684104246315

Epoch: 5| Step: 1
Training loss: 2.4997486941867044
Validation loss: 3.140040119163829

Epoch: 5| Step: 2
Training loss: 3.6329118612503897
Validation loss: 3.139323102312097

Epoch: 5| Step: 3
Training loss: 2.7162493902101286
Validation loss: 3.138215990533263

Epoch: 5| Step: 4
Training loss: 2.662815462148161
Validation loss: 3.1390019737440538

Epoch: 5| Step: 5
Training loss: 3.1546167359107637
Validation loss: 3.140688222159914

Epoch: 5| Step: 6
Training loss: 3.625324760885183
Validation loss: 3.13950456601471

Epoch: 5| Step: 7
Training loss: 3.668871751159018
Validation loss: 3.139871269204089

Epoch: 5| Step: 8
Training loss: 3.747413251711314
Validation loss: 3.1407071905187496

Epoch: 5| Step: 9
Training loss: 3.678209530386526
Validation loss: 3.1387453094179603

Epoch: 5| Step: 10
Training loss: 4.1188095343169815
Validation loss: 3.13728087462059

Epoch: 93| Step: 0
Training loss: 4.062249748151561
Validation loss: 3.136727099526994

Epoch: 5| Step: 1
Training loss: 2.3089914253706754
Validation loss: 3.137528464052527

Epoch: 5| Step: 2
Training loss: 3.336434606459223
Validation loss: 3.136122427104308

Epoch: 5| Step: 3
Training loss: 3.558220015663816
Validation loss: 3.1348078874666565

Epoch: 5| Step: 4
Training loss: 3.648628180869337
Validation loss: 3.136656392649617

Epoch: 5| Step: 5
Training loss: 3.157738665020033
Validation loss: 3.136396017537967

Epoch: 5| Step: 6
Training loss: 3.6413565625129936
Validation loss: 3.134669211973187

Epoch: 5| Step: 7
Training loss: 3.2996256413673577
Validation loss: 3.1344123965122748

Epoch: 5| Step: 8
Training loss: 3.870933737272191
Validation loss: 3.133857826585901

Epoch: 5| Step: 9
Training loss: 3.229782898873009
Validation loss: 3.1319923287775753

Epoch: 5| Step: 10
Training loss: 2.923225131698423
Validation loss: 3.1305164188751924

Epoch: 94| Step: 0
Training loss: 3.203695404623459
Validation loss: 3.135104878122268

Epoch: 5| Step: 1
Training loss: 3.271265734298351
Validation loss: 3.134838046088167

Epoch: 5| Step: 2
Training loss: 3.2820295588564585
Validation loss: 3.137613104364429

Epoch: 5| Step: 3
Training loss: 2.883761118060086
Validation loss: 3.137479619713886

Epoch: 5| Step: 4
Training loss: 3.881315560639486
Validation loss: 3.1467829830617333

Epoch: 5| Step: 5
Training loss: 3.7454464286504137
Validation loss: 3.135165576953598

Epoch: 5| Step: 6
Training loss: 3.8203667946918247
Validation loss: 3.1368458130773282

Epoch: 5| Step: 7
Training loss: 3.2594982149529166
Validation loss: 3.1347589762029404

Epoch: 5| Step: 8
Training loss: 2.641131741809559
Validation loss: 3.1349126325971954

Epoch: 5| Step: 9
Training loss: 3.744590035830089
Validation loss: 3.136098655407265

Epoch: 5| Step: 10
Training loss: 3.411201168394336
Validation loss: 3.132394901880005

Epoch: 95| Step: 0
Training loss: 3.4004993016001497
Validation loss: 3.1313057789525627

Epoch: 5| Step: 1
Training loss: 3.1062112172582057
Validation loss: 3.1318896895434305

Epoch: 5| Step: 2
Training loss: 3.1256081561554057
Validation loss: 3.1310814501145945

Epoch: 5| Step: 3
Training loss: 3.2713221449981016
Validation loss: 3.131296412862247

Epoch: 5| Step: 4
Training loss: 3.0695765732011178
Validation loss: 3.13137226428912

Epoch: 5| Step: 5
Training loss: 4.175642848063047
Validation loss: 3.132144356225576

Epoch: 5| Step: 6
Training loss: 3.8229034312726795
Validation loss: 3.1336378478654003

Epoch: 5| Step: 7
Training loss: 3.813418043325009
Validation loss: 3.1326082555982118

Epoch: 5| Step: 8
Training loss: 2.706609431618446
Validation loss: 3.1327632498898215

Epoch: 5| Step: 9
Training loss: 3.4989022849612463
Validation loss: 3.131461225762057

Epoch: 5| Step: 10
Training loss: 3.0698369169875157
Validation loss: 3.128728161203017

Epoch: 96| Step: 0
Training loss: 3.103526226431311
Validation loss: 3.1306732380129603

Epoch: 5| Step: 1
Training loss: 3.40170825230699
Validation loss: 3.13111031413752

Epoch: 5| Step: 2
Training loss: 3.388446441979146
Validation loss: 3.1328520131119664

Epoch: 5| Step: 3
Training loss: 3.446654043438913
Validation loss: 3.129975940280714

Epoch: 5| Step: 4
Training loss: 3.822405594732151
Validation loss: 3.128796111448193

Epoch: 5| Step: 5
Training loss: 2.295231341335292
Validation loss: 3.1299382952003456

Epoch: 5| Step: 6
Training loss: 4.412719954500918
Validation loss: 3.1287002625742364

Epoch: 5| Step: 7
Training loss: 3.2881219021830264
Validation loss: 3.1259718534321865

Epoch: 5| Step: 8
Training loss: 3.036178671955844
Validation loss: 3.125424367331707

Epoch: 5| Step: 9
Training loss: 3.472703622295347
Validation loss: 3.1276937019751254

Epoch: 5| Step: 10
Training loss: 3.255939338493908
Validation loss: 3.1263573371101963

Epoch: 97| Step: 0
Training loss: 3.1826053512648116
Validation loss: 3.1236702204195175

Epoch: 5| Step: 1
Training loss: 2.9076331344129263
Validation loss: 3.1251987197204545

Epoch: 5| Step: 2
Training loss: 3.139236067155057
Validation loss: 3.122339304678181

Epoch: 5| Step: 3
Training loss: 3.334644361804472
Validation loss: 3.1251451585752528

Epoch: 5| Step: 4
Training loss: 3.789020844849962
Validation loss: 3.121997868682533

Epoch: 5| Step: 5
Training loss: 2.947314808651907
Validation loss: 3.123278199718496

Epoch: 5| Step: 6
Training loss: 2.9793899203503647
Validation loss: 3.1211923598065483

Epoch: 5| Step: 7
Training loss: 4.005869135851711
Validation loss: 3.119328569531802

Epoch: 5| Step: 8
Training loss: 3.7566875590093494
Validation loss: 3.1194452561868653

Epoch: 5| Step: 9
Training loss: 3.564071576325576
Validation loss: 3.1223311334378065

Epoch: 5| Step: 10
Training loss: 3.4829458547452905
Validation loss: 3.11852270905094

Epoch: 98| Step: 0
Training loss: 3.1723620411942512
Validation loss: 3.1184582861315193

Epoch: 5| Step: 1
Training loss: 4.0805004699280465
Validation loss: 3.119491851718841

Epoch: 5| Step: 2
Training loss: 3.172191284646422
Validation loss: 3.1164521030359946

Epoch: 5| Step: 3
Training loss: 3.6780014548866666
Validation loss: 3.1181695298823886

Epoch: 5| Step: 4
Training loss: 3.375774577230662
Validation loss: 3.1188783914179994

Epoch: 5| Step: 5
Training loss: 3.733817597611577
Validation loss: 3.1161293168232236

Epoch: 5| Step: 6
Training loss: 2.611233352162499
Validation loss: 3.11493217470137

Epoch: 5| Step: 7
Training loss: 2.935579037061839
Validation loss: 3.1145157268409607

Epoch: 5| Step: 8
Training loss: 3.0550296523532814
Validation loss: 3.1153460932346553

Epoch: 5| Step: 9
Training loss: 2.9238467168121325
Validation loss: 3.114603164702453

Epoch: 5| Step: 10
Training loss: 4.214072792456494
Validation loss: 3.1169090355306555

Epoch: 99| Step: 0
Training loss: 3.569317635255744
Validation loss: 3.114492566442655

Epoch: 5| Step: 1
Training loss: 3.378101477951323
Validation loss: 3.114211202865297

Epoch: 5| Step: 2
Training loss: 3.016726435987758
Validation loss: 3.1126267156115

Epoch: 5| Step: 3
Training loss: 3.627170044755186
Validation loss: 3.1128775078949484

Epoch: 5| Step: 4
Training loss: 3.560112270127942
Validation loss: 3.113213210632909

Epoch: 5| Step: 5
Training loss: 3.1987451894529424
Validation loss: 3.1140617493309435

Epoch: 5| Step: 6
Training loss: 3.866278277545654
Validation loss: 3.1103981005698604

Epoch: 5| Step: 7
Training loss: 2.8834408124468722
Validation loss: 3.112906467415441

Epoch: 5| Step: 8
Training loss: 2.886918779806375
Validation loss: 3.109617861429851

Epoch: 5| Step: 9
Training loss: 3.786408491825436
Validation loss: 3.111984173154603

Epoch: 5| Step: 10
Training loss: 3.184264841317518
Validation loss: 3.1105946855914985

Epoch: 100| Step: 0
Training loss: 2.9436422210854425
Validation loss: 3.111967303410958

Epoch: 5| Step: 1
Training loss: 3.5801809476164443
Validation loss: 3.1127067290361023

Epoch: 5| Step: 2
Training loss: 3.3979898793752925
Validation loss: 3.114762661606696

Epoch: 5| Step: 3
Training loss: 3.053872392397936
Validation loss: 3.1161651797698937

Epoch: 5| Step: 4
Training loss: 3.558571506602409
Validation loss: 3.114401484655862

Epoch: 5| Step: 5
Training loss: 3.2765964024235577
Validation loss: 3.114943693619272

Epoch: 5| Step: 6
Training loss: 3.734431820999789
Validation loss: 3.1113753084529545

Epoch: 5| Step: 7
Training loss: 3.538387141514114
Validation loss: 3.11018438302219

Epoch: 5| Step: 8
Training loss: 3.762312956054676
Validation loss: 3.107162025302686

Epoch: 5| Step: 9
Training loss: 3.1878199697226934
Validation loss: 3.1103460896174484

Epoch: 5| Step: 10
Training loss: 2.8865618217874665
Validation loss: 3.1085297376637575

Epoch: 101| Step: 0
Training loss: 3.96567422221533
Validation loss: 3.1075464203086125

Epoch: 5| Step: 1
Training loss: 2.938964965434974
Validation loss: 3.1065564225439375

Epoch: 5| Step: 2
Training loss: 3.3179595868096627
Validation loss: 3.1081363187214603

Epoch: 5| Step: 3
Training loss: 3.1158211756310314
Validation loss: 3.10718027920073

Epoch: 5| Step: 4
Training loss: 3.2413058265618364
Validation loss: 3.1084253686545322

Epoch: 5| Step: 5
Training loss: 2.9324123070915076
Validation loss: 3.110372762410924

Epoch: 5| Step: 6
Training loss: 2.9013800067034206
Validation loss: 3.1113668150887284

Epoch: 5| Step: 7
Training loss: 4.142992717422541
Validation loss: 3.1259630159148206

Epoch: 5| Step: 8
Training loss: 3.4298355661464623
Validation loss: 3.1292545799183036

Epoch: 5| Step: 9
Training loss: 3.3371729829859857
Validation loss: 3.1306784853812344

Epoch: 5| Step: 10
Training loss: 3.6247273046592197
Validation loss: 3.134688694366163

Epoch: 102| Step: 0
Training loss: 3.1045918696150516
Validation loss: 3.1275509371617485

Epoch: 5| Step: 1
Training loss: 3.292233349915806
Validation loss: 3.1182712296688013

Epoch: 5| Step: 2
Training loss: 3.7710704131794235
Validation loss: 3.1065469620297868

Epoch: 5| Step: 3
Training loss: 2.797368863793195
Validation loss: 3.1052349642100436

Epoch: 5| Step: 4
Training loss: 3.5085742012996377
Validation loss: 3.1046300169090615

Epoch: 5| Step: 5
Training loss: 4.115219775202507
Validation loss: 3.109204291785294

Epoch: 5| Step: 6
Training loss: 3.399926010897537
Validation loss: 3.1128581772403754

Epoch: 5| Step: 7
Training loss: 3.150344611799748
Validation loss: 3.1210188250314426

Epoch: 5| Step: 8
Training loss: 2.8122597485818503
Validation loss: 3.1218733308236577

Epoch: 5| Step: 9
Training loss: 3.8372493450798735
Validation loss: 3.1157598382973215

Epoch: 5| Step: 10
Training loss: 3.153155783587111
Validation loss: 3.1074359842147694

Epoch: 103| Step: 0
Training loss: 3.142430939200033
Validation loss: 3.1092130582046904

Epoch: 5| Step: 1
Training loss: 2.922224054549513
Validation loss: 3.108564967495652

Epoch: 5| Step: 2
Training loss: 3.447719433877816
Validation loss: 3.1087726271928497

Epoch: 5| Step: 3
Training loss: 2.9968717477599824
Validation loss: 3.10929542769894

Epoch: 5| Step: 4
Training loss: 3.740455433659956
Validation loss: 3.110119312591886

Epoch: 5| Step: 5
Training loss: 3.4648985229429146
Validation loss: 3.1114768043389818

Epoch: 5| Step: 6
Training loss: 3.0353513677027637
Validation loss: 3.108812073116651

Epoch: 5| Step: 7
Training loss: 3.832890498801872
Validation loss: 3.106411596940138

Epoch: 5| Step: 8
Training loss: 2.9529722466900497
Validation loss: 3.1030810408801814

Epoch: 5| Step: 9
Training loss: 3.9389626344689015
Validation loss: 3.105163028357907

Epoch: 5| Step: 10
Training loss: 3.4665191625122946
Validation loss: 3.1023189735640555

Epoch: 104| Step: 0
Training loss: 2.911958400156699
Validation loss: 3.1028120018631595

Epoch: 5| Step: 1
Training loss: 2.9610544146401567
Validation loss: 3.1039818868886675

Epoch: 5| Step: 2
Training loss: 3.5686985099004134
Validation loss: 3.100277164333352

Epoch: 5| Step: 3
Training loss: 2.1818983016331064
Validation loss: 3.1029813978060674

Epoch: 5| Step: 4
Training loss: 3.257772248749019
Validation loss: 3.100420012520165

Epoch: 5| Step: 5
Training loss: 3.909238480853158
Validation loss: 3.1029677442216848

Epoch: 5| Step: 6
Training loss: 3.6555352449738594
Validation loss: 3.102071585419784

Epoch: 5| Step: 7
Training loss: 3.0795614695780418
Validation loss: 3.09821821505414

Epoch: 5| Step: 8
Training loss: 3.15484905311056
Validation loss: 3.099688124077457

Epoch: 5| Step: 9
Training loss: 3.602717216555896
Validation loss: 3.101317971169189

Epoch: 5| Step: 10
Training loss: 4.436568901270739
Validation loss: 3.101479348176439

Epoch: 105| Step: 0
Training loss: 3.4253494529933834
Validation loss: 3.0999233230743317

Epoch: 5| Step: 1
Training loss: 3.2264847642156655
Validation loss: 3.0984197719236155

Epoch: 5| Step: 2
Training loss: 2.8374628005761275
Validation loss: 3.0989394828048646

Epoch: 5| Step: 3
Training loss: 2.7300434790981103
Validation loss: 3.099434581356672

Epoch: 5| Step: 4
Training loss: 3.998051764965561
Validation loss: 3.097626614922514

Epoch: 5| Step: 5
Training loss: 3.069770279779527
Validation loss: 3.0971788158109983

Epoch: 5| Step: 6
Training loss: 3.6078967745831316
Validation loss: 3.09558117733302

Epoch: 5| Step: 7
Training loss: 4.070719693073951
Validation loss: 3.095374037315237

Epoch: 5| Step: 8
Training loss: 3.2119263845632444
Validation loss: 3.095125665023443

Epoch: 5| Step: 9
Training loss: 2.916540651778082
Validation loss: 3.0969456219096188

Epoch: 5| Step: 10
Training loss: 3.6801957024491503
Validation loss: 3.0955249744820845

Epoch: 106| Step: 0
Training loss: 2.845946249855726
Validation loss: 3.093050868926216

Epoch: 5| Step: 1
Training loss: 3.7377059318430295
Validation loss: 3.096241972923708

Epoch: 5| Step: 2
Training loss: 3.2993416620800593
Validation loss: 3.0929358521398997

Epoch: 5| Step: 3
Training loss: 3.682254746111245
Validation loss: 3.0935353336911917

Epoch: 5| Step: 4
Training loss: 3.1931153743745906
Validation loss: 3.093016970890363

Epoch: 5| Step: 5
Training loss: 3.726982556866481
Validation loss: 3.0926726715156425

Epoch: 5| Step: 6
Training loss: 3.7838281086678376
Validation loss: 3.0939808901579333

Epoch: 5| Step: 7
Training loss: 3.919404364895452
Validation loss: 3.094893640117382

Epoch: 5| Step: 8
Training loss: 2.743945826882648
Validation loss: 3.0954207434184497

Epoch: 5| Step: 9
Training loss: 2.196463395218141
Validation loss: 3.0956772475259124

Epoch: 5| Step: 10
Training loss: 3.4349408420316117
Validation loss: 3.0950696013380217

Epoch: 107| Step: 0
Training loss: 3.4112928665839357
Validation loss: 3.1004548020036893

Epoch: 5| Step: 1
Training loss: 3.5962959890703403
Validation loss: 3.105022731644493

Epoch: 5| Step: 2
Training loss: 3.50351946853187
Validation loss: 3.1030963941948646

Epoch: 5| Step: 3
Training loss: 2.6957344941106567
Validation loss: 3.103006379926018

Epoch: 5| Step: 4
Training loss: 3.4774219607846226
Validation loss: 3.098209899933148

Epoch: 5| Step: 5
Training loss: 2.8799554990933127
Validation loss: 3.096467539172566

Epoch: 5| Step: 6
Training loss: 4.28862600415798
Validation loss: 3.0932681496797567

Epoch: 5| Step: 7
Training loss: 3.570374068849945
Validation loss: 3.0936654498729106

Epoch: 5| Step: 8
Training loss: 3.008222596586362
Validation loss: 3.09032771873762

Epoch: 5| Step: 9
Training loss: 2.6788643776688046
Validation loss: 3.090940261688253

Epoch: 5| Step: 10
Training loss: 3.542925412755211
Validation loss: 3.088314551401539

Epoch: 108| Step: 0
Training loss: 3.4354150171007984
Validation loss: 3.0881537565786554

Epoch: 5| Step: 1
Training loss: 2.5561287923491203
Validation loss: 3.0880300679202803

Epoch: 5| Step: 2
Training loss: 3.0122263044067523
Validation loss: 3.089458624471487

Epoch: 5| Step: 3
Training loss: 3.1014295112290653
Validation loss: 3.087554038863015

Epoch: 5| Step: 4
Training loss: 3.5241256008129414
Validation loss: 3.0900096629673617

Epoch: 5| Step: 5
Training loss: 3.4076974575628443
Validation loss: 3.0898041199971615

Epoch: 5| Step: 6
Training loss: 3.889995110319933
Validation loss: 3.089608881462799

Epoch: 5| Step: 7
Training loss: 3.1849780109790276
Validation loss: 3.0885503351319237

Epoch: 5| Step: 8
Training loss: 3.401245500532859
Validation loss: 3.089297817829714

Epoch: 5| Step: 9
Training loss: 3.9612341173454864
Validation loss: 3.087367883401103

Epoch: 5| Step: 10
Training loss: 3.2209397061948213
Validation loss: 3.0907679223286366

Epoch: 109| Step: 0
Training loss: 2.4010268160566928
Validation loss: 3.089133483256064

Epoch: 5| Step: 1
Training loss: 3.888495417777255
Validation loss: 3.0871316190582774

Epoch: 5| Step: 2
Training loss: 3.5639867524522693
Validation loss: 3.086709920492899

Epoch: 5| Step: 3
Training loss: 3.834076159831681
Validation loss: 3.089511708143978

Epoch: 5| Step: 4
Training loss: 2.8855113393811616
Validation loss: 3.0875360791099142

Epoch: 5| Step: 5
Training loss: 3.403009255422717
Validation loss: 3.0869791686376464

Epoch: 5| Step: 6
Training loss: 2.5085643936478164
Validation loss: 3.090726485165781

Epoch: 5| Step: 7
Training loss: 2.9205457958516083
Validation loss: 3.0886775836312292

Epoch: 5| Step: 8
Training loss: 3.5662091671825253
Validation loss: 3.0894193297517814

Epoch: 5| Step: 9
Training loss: 3.5902798027723164
Validation loss: 3.088749793864279

Epoch: 5| Step: 10
Training loss: 3.98041364427631
Validation loss: 3.092725102366418

Epoch: 110| Step: 0
Training loss: 3.5292409397372935
Validation loss: 3.0888544317964075

Epoch: 5| Step: 1
Training loss: 3.345878850327204
Validation loss: 3.087735508709978

Epoch: 5| Step: 2
Training loss: 3.0653814656528904
Validation loss: 3.090767065505604

Epoch: 5| Step: 3
Training loss: 3.406065069655603
Validation loss: 3.0882861498891394

Epoch: 5| Step: 4
Training loss: 2.563475167410335
Validation loss: 3.0872201812767375

Epoch: 5| Step: 5
Training loss: 3.4970617222300944
Validation loss: 3.0877381240455724

Epoch: 5| Step: 6
Training loss: 4.18136215173593
Validation loss: 3.087273494427491

Epoch: 5| Step: 7
Training loss: 2.830110643198704
Validation loss: 3.084745124354298

Epoch: 5| Step: 8
Training loss: 3.6425249765727146
Validation loss: 3.0884184155021743

Epoch: 5| Step: 9
Training loss: 3.422984043664766
Validation loss: 3.086463367729011

Epoch: 5| Step: 10
Training loss: 3.096363235515963
Validation loss: 3.0834102206689

Epoch: 111| Step: 0
Training loss: 3.632814993908754
Validation loss: 3.085705158900039

Epoch: 5| Step: 1
Training loss: 3.144146970405294
Validation loss: 3.0832587631928443

Epoch: 5| Step: 2
Training loss: 3.6791325695377433
Validation loss: 3.0831258904123717

Epoch: 5| Step: 3
Training loss: 2.9757354468408246
Validation loss: 3.0840452071407047

Epoch: 5| Step: 4
Training loss: 2.8350756467922804
Validation loss: 3.0818402789149157

Epoch: 5| Step: 5
Training loss: 3.39176394411343
Validation loss: 3.083444605523718

Epoch: 5| Step: 6
Training loss: 3.969693770044446
Validation loss: 3.0836200677789662

Epoch: 5| Step: 7
Training loss: 3.426214105974054
Validation loss: 3.0828680027104536

Epoch: 5| Step: 8
Training loss: 3.3554862291726786
Validation loss: 3.0817004236440315

Epoch: 5| Step: 9
Training loss: 3.3762180814678384
Validation loss: 3.0796230467226478

Epoch: 5| Step: 10
Training loss: 2.828126433145571
Validation loss: 3.0792660153510147

Epoch: 112| Step: 0
Training loss: 3.0826676827245354
Validation loss: 3.0808179473268638

Epoch: 5| Step: 1
Training loss: 3.8824460261536275
Validation loss: 3.080484757824148

Epoch: 5| Step: 2
Training loss: 3.0159867618179192
Validation loss: 3.084736994812073

Epoch: 5| Step: 3
Training loss: 3.4288885276477243
Validation loss: 3.0792245091605825

Epoch: 5| Step: 4
Training loss: 3.6773508351024535
Validation loss: 3.082409956295013

Epoch: 5| Step: 5
Training loss: 3.440331697218983
Validation loss: 3.0877056771221576

Epoch: 5| Step: 6
Training loss: 3.817569926182936
Validation loss: 3.089048095535427

Epoch: 5| Step: 7
Training loss: 3.27922242507805
Validation loss: 3.0821940227544156

Epoch: 5| Step: 8
Training loss: 3.188917854464039
Validation loss: 3.0786478803952333

Epoch: 5| Step: 9
Training loss: 2.8334745110138946
Validation loss: 3.080983603287551

Epoch: 5| Step: 10
Training loss: 2.9147058344399626
Validation loss: 3.0800620210420253

Epoch: 113| Step: 0
Training loss: 3.0586807413994057
Validation loss: 3.077433098852007

Epoch: 5| Step: 1
Training loss: 4.300420678430728
Validation loss: 3.0790231678073794

Epoch: 5| Step: 2
Training loss: 3.659851256928259
Validation loss: 3.0772430437349705

Epoch: 5| Step: 3
Training loss: 3.346945545867084
Validation loss: 3.0791441710215954

Epoch: 5| Step: 4
Training loss: 3.4480019796060426
Validation loss: 3.0785664854529657

Epoch: 5| Step: 5
Training loss: 3.2722974444387494
Validation loss: 3.083656919860907

Epoch: 5| Step: 6
Training loss: 2.9183810145827183
Validation loss: 3.0775943188500223

Epoch: 5| Step: 7
Training loss: 2.9737211668421435
Validation loss: 3.077104033433304

Epoch: 5| Step: 8
Training loss: 2.785033834584031
Validation loss: 3.079045719932573

Epoch: 5| Step: 9
Training loss: 3.467441346346964
Validation loss: 3.077323764735641

Epoch: 5| Step: 10
Training loss: 3.3626736791065173
Validation loss: 3.079081255472116

Epoch: 114| Step: 0
Training loss: 3.1345240609807394
Validation loss: 3.082540438960247

Epoch: 5| Step: 1
Training loss: 3.4643361645537745
Validation loss: 3.0816848930209844

Epoch: 5| Step: 2
Training loss: 3.6898678434943455
Validation loss: 3.084283086032656

Epoch: 5| Step: 3
Training loss: 3.586171925846009
Validation loss: 3.0820742938040566

Epoch: 5| Step: 4
Training loss: 2.7034481494884743
Validation loss: 3.083350084808617

Epoch: 5| Step: 5
Training loss: 3.9248650691657194
Validation loss: 3.0785678802895275

Epoch: 5| Step: 6
Training loss: 3.6197313628445076
Validation loss: 3.079338108277507

Epoch: 5| Step: 7
Training loss: 3.1095436855546903
Validation loss: 3.0790399149783805

Epoch: 5| Step: 8
Training loss: 3.383307511054156
Validation loss: 3.0788211613071508

Epoch: 5| Step: 9
Training loss: 2.6666817863353613
Validation loss: 3.0788216101160066

Epoch: 5| Step: 10
Training loss: 3.2752406723463836
Validation loss: 3.0750670825821924

Epoch: 115| Step: 0
Training loss: 2.923489700740277
Validation loss: 3.074679957756852

Epoch: 5| Step: 1
Training loss: 4.429598368398907
Validation loss: 3.0744717147248846

Epoch: 5| Step: 2
Training loss: 2.5136030138805054
Validation loss: 3.07541569700286

Epoch: 5| Step: 3
Training loss: 3.29414768315494
Validation loss: 3.07385850130315

Epoch: 5| Step: 4
Training loss: 3.235231442787876
Validation loss: 3.07248533853251

Epoch: 5| Step: 5
Training loss: 3.4936641839531193
Validation loss: 3.074877027961843

Epoch: 5| Step: 6
Training loss: 3.3539272404548575
Validation loss: 3.073612849381148

Epoch: 5| Step: 7
Training loss: 3.0518781226284935
Validation loss: 3.0756848236070016

Epoch: 5| Step: 8
Training loss: 3.658585022861548
Validation loss: 3.0741573648200258

Epoch: 5| Step: 9
Training loss: 3.6651236292868132
Validation loss: 3.07300815574698

Epoch: 5| Step: 10
Training loss: 2.6299299539731424
Validation loss: 3.0723422712729302

Epoch: 116| Step: 0
Training loss: 4.034805976901521
Validation loss: 3.070903171113556

Epoch: 5| Step: 1
Training loss: 2.733154460435039
Validation loss: 3.07199911299271

Epoch: 5| Step: 2
Training loss: 3.812428333046629
Validation loss: 3.0730585320319372

Epoch: 5| Step: 3
Training loss: 2.1551490958695285
Validation loss: 3.0716381457672814

Epoch: 5| Step: 4
Training loss: 4.253942568285047
Validation loss: 3.0699312825669303

Epoch: 5| Step: 5
Training loss: 2.1451070599636872
Validation loss: 3.0727104769956757

Epoch: 5| Step: 6
Training loss: 3.749468702190492
Validation loss: 3.071875857953123

Epoch: 5| Step: 7
Training loss: 3.365397603774945
Validation loss: 3.075121498458829

Epoch: 5| Step: 8
Training loss: 3.2025116123819766
Validation loss: 3.0720380079929797

Epoch: 5| Step: 9
Training loss: 3.2558579104488308
Validation loss: 3.0719184289984254

Epoch: 5| Step: 10
Training loss: 3.283548476501326
Validation loss: 3.0691914337590602

Epoch: 117| Step: 0
Training loss: 2.3193203124473682
Validation loss: 3.070397568793654

Epoch: 5| Step: 1
Training loss: 3.223325421765101
Validation loss: 3.0706063310820455

Epoch: 5| Step: 2
Training loss: 3.5737284339662367
Validation loss: 3.0699771348404314

Epoch: 5| Step: 3
Training loss: 3.5715359317446556
Validation loss: 3.073819736093867

Epoch: 5| Step: 4
Training loss: 3.070372913338921
Validation loss: 3.074848263879635

Epoch: 5| Step: 5
Training loss: 3.8825065753239985
Validation loss: 3.0759508962541275

Epoch: 5| Step: 6
Training loss: 3.062135324369414
Validation loss: 3.070825806024391

Epoch: 5| Step: 7
Training loss: 3.543868349174633
Validation loss: 3.0686853597698533

Epoch: 5| Step: 8
Training loss: 3.6614573638321457
Validation loss: 3.0685359747120073

Epoch: 5| Step: 9
Training loss: 3.0427186444473597
Validation loss: 3.0692388740740046

Epoch: 5| Step: 10
Training loss: 3.5297124435401295
Validation loss: 3.0665299832093167

Epoch: 118| Step: 0
Training loss: 3.7881137564636544
Validation loss: 3.066639025012079

Epoch: 5| Step: 1
Training loss: 2.894476556711682
Validation loss: 3.0664439568788713

Epoch: 5| Step: 2
Training loss: 3.751489597741853
Validation loss: 3.0679091181308054

Epoch: 5| Step: 3
Training loss: 3.334299583261453
Validation loss: 3.068155898515756

Epoch: 5| Step: 4
Training loss: 2.729087644020231
Validation loss: 3.0659556795436242

Epoch: 5| Step: 5
Training loss: 3.208248451067856
Validation loss: 3.0670603319786105

Epoch: 5| Step: 6
Training loss: 3.99121440218072
Validation loss: 3.069882760649349

Epoch: 5| Step: 7
Training loss: 2.9067431615977215
Validation loss: 3.0653529704164244

Epoch: 5| Step: 8
Training loss: 3.4292406212459516
Validation loss: 3.0648260016581186

Epoch: 5| Step: 9
Training loss: 3.3770113002869304
Validation loss: 3.0650106137971225

Epoch: 5| Step: 10
Training loss: 3.005104966702641
Validation loss: 3.065606671736655

Epoch: 119| Step: 0
Training loss: 4.003018670676319
Validation loss: 3.063829730590008

Epoch: 5| Step: 1
Training loss: 2.8670429744207344
Validation loss: 3.0652841013741705

Epoch: 5| Step: 2
Training loss: 3.4174768061154293
Validation loss: 3.0649911502080776

Epoch: 5| Step: 3
Training loss: 3.4859856274341885
Validation loss: 3.069099421045905

Epoch: 5| Step: 4
Training loss: 3.150179321997747
Validation loss: 3.0697064171381085

Epoch: 5| Step: 5
Training loss: 3.005410401918507
Validation loss: 3.0823275919347632

Epoch: 5| Step: 6
Training loss: 3.5373028218343046
Validation loss: 3.081541813609304

Epoch: 5| Step: 7
Training loss: 3.5129203734892815
Validation loss: 3.0666905475326867

Epoch: 5| Step: 8
Training loss: 2.8425961343819357
Validation loss: 3.0643664463816624

Epoch: 5| Step: 9
Training loss: 3.582047224269179
Validation loss: 3.062592020131895

Epoch: 5| Step: 10
Training loss: 3.0962053824125695
Validation loss: 3.062977021840603

Epoch: 120| Step: 0
Training loss: 3.859717350034295
Validation loss: 3.064130153755105

Epoch: 5| Step: 1
Training loss: 3.5518045325322865
Validation loss: 3.064215272870565

Epoch: 5| Step: 2
Training loss: 2.3467985544567296
Validation loss: 3.0652799815269263

Epoch: 5| Step: 3
Training loss: 3.6097237554721984
Validation loss: 3.065384312903906

Epoch: 5| Step: 4
Training loss: 4.022366694202784
Validation loss: 3.0671178429569013

Epoch: 5| Step: 5
Training loss: 2.516180889243661
Validation loss: 3.067811155518986

Epoch: 5| Step: 6
Training loss: 3.3191365392264043
Validation loss: 3.0700691713503185

Epoch: 5| Step: 7
Training loss: 2.917253398917148
Validation loss: 3.0676454150100625

Epoch: 5| Step: 8
Training loss: 3.1759893482904036
Validation loss: 3.0620669623190926

Epoch: 5| Step: 9
Training loss: 3.1684411916044395
Validation loss: 3.062236142506119

Epoch: 5| Step: 10
Training loss: 3.848987887229899
Validation loss: 3.0613156896439837

Epoch: 121| Step: 0
Training loss: 3.282133873468098
Validation loss: 3.0611687186517376

Epoch: 5| Step: 1
Training loss: 2.742000127841048
Validation loss: 3.0597105835828535

Epoch: 5| Step: 2
Training loss: 2.9235242788951745
Validation loss: 3.059876490810877

Epoch: 5| Step: 3
Training loss: 2.9302933943781517
Validation loss: 3.063332984119375

Epoch: 5| Step: 4
Training loss: 3.5005964043512967
Validation loss: 3.0658214305333815

Epoch: 5| Step: 5
Training loss: 3.3744182791763317
Validation loss: 3.0665413244597657

Epoch: 5| Step: 6
Training loss: 3.7740493183643333
Validation loss: 3.0650932829059667

Epoch: 5| Step: 7
Training loss: 3.2948742621689555
Validation loss: 3.0615863228166518

Epoch: 5| Step: 8
Training loss: 3.8599778912953715
Validation loss: 3.059273480668741

Epoch: 5| Step: 9
Training loss: 3.3550897279841423
Validation loss: 3.060240199134531

Epoch: 5| Step: 10
Training loss: 3.448823208448401
Validation loss: 3.057797006640357

Epoch: 122| Step: 0
Training loss: 3.7332515542973495
Validation loss: 3.0588328689839455

Epoch: 5| Step: 1
Training loss: 3.5865983208687853
Validation loss: 3.0573780958594217

Epoch: 5| Step: 2
Training loss: 3.306444931773857
Validation loss: 3.059785949088474

Epoch: 5| Step: 3
Training loss: 4.041183652560312
Validation loss: 3.057554808310623

Epoch: 5| Step: 4
Training loss: 3.402062037616023
Validation loss: 3.0574980842170394

Epoch: 5| Step: 5
Training loss: 3.3584448657829573
Validation loss: 3.0592750946370875

Epoch: 5| Step: 6
Training loss: 3.502817926891873
Validation loss: 3.058073919206608

Epoch: 5| Step: 7
Training loss: 2.985313547558093
Validation loss: 3.05630945008246

Epoch: 5| Step: 8
Training loss: 2.7349327172575975
Validation loss: 3.0581749927869115

Epoch: 5| Step: 9
Training loss: 2.590167317380317
Validation loss: 3.057689380025703

Epoch: 5| Step: 10
Training loss: 3.075559834947102
Validation loss: 3.0558042813442667

Epoch: 123| Step: 0
Training loss: 3.5304817106613036
Validation loss: 3.0561624178523368

Epoch: 5| Step: 1
Training loss: 3.015715760757737
Validation loss: 3.0567134863826424

Epoch: 5| Step: 2
Training loss: 2.72095531601055
Validation loss: 3.057115116225174

Epoch: 5| Step: 3
Training loss: 3.591753064832736
Validation loss: 3.05462465645694

Epoch: 5| Step: 4
Training loss: 3.2923021467657163
Validation loss: 3.056846666066978

Epoch: 5| Step: 5
Training loss: 3.572125064510125
Validation loss: 3.0547053893598024

Epoch: 5| Step: 6
Training loss: 3.344336912750617
Validation loss: 3.0558370552521423

Epoch: 5| Step: 7
Training loss: 3.3872312094265546
Validation loss: 3.052998456655178

Epoch: 5| Step: 8
Training loss: 3.591525907184853
Validation loss: 3.0554544949218494

Epoch: 5| Step: 9
Training loss: 3.3054497022447378
Validation loss: 3.0528259085166676

Epoch: 5| Step: 10
Training loss: 3.125758269820707
Validation loss: 3.0561980902841315

Epoch: 124| Step: 0
Training loss: 4.07323902672348
Validation loss: 3.054728829331619

Epoch: 5| Step: 1
Training loss: 3.727046015499131
Validation loss: 3.053329988175877

Epoch: 5| Step: 2
Training loss: 2.953064610100948
Validation loss: 3.053280665908458

Epoch: 5| Step: 3
Training loss: 3.6261742104174854
Validation loss: 3.0537780544254005

Epoch: 5| Step: 4
Training loss: 2.9826439435681897
Validation loss: 3.053689693461758

Epoch: 5| Step: 5
Training loss: 2.872891191715843
Validation loss: 3.0511727127279333

Epoch: 5| Step: 6
Training loss: 3.631327664042133
Validation loss: 3.053301669300201

Epoch: 5| Step: 7
Training loss: 2.6383253388114034
Validation loss: 3.054141197159387

Epoch: 5| Step: 8
Training loss: 3.4025213149255875
Validation loss: 3.051059547131919

Epoch: 5| Step: 9
Training loss: 3.6552453902460558
Validation loss: 3.051438146900303

Epoch: 5| Step: 10
Training loss: 2.5117233062750275
Validation loss: 3.0507829592158253

Epoch: 125| Step: 0
Training loss: 3.1042309099415153
Validation loss: 3.051140441585159

Epoch: 5| Step: 1
Training loss: 2.797364602310846
Validation loss: 3.053279543316553

Epoch: 5| Step: 2
Training loss: 2.8666050290718803
Validation loss: 3.0513695804800944

Epoch: 5| Step: 3
Training loss: 3.1787775410649
Validation loss: 3.053465452176626

Epoch: 5| Step: 4
Training loss: 3.3545318467906684
Validation loss: 3.0556207741880446

Epoch: 5| Step: 5
Training loss: 4.056553405793842
Validation loss: 3.052776431984493

Epoch: 5| Step: 6
Training loss: 3.2632881820199597
Validation loss: 3.0582535907812614

Epoch: 5| Step: 7
Training loss: 3.383128937684253
Validation loss: 3.0525208001178386

Epoch: 5| Step: 8
Training loss: 3.170572549035314
Validation loss: 3.051195740409541

Epoch: 5| Step: 9
Training loss: 3.6577009924668484
Validation loss: 3.0504015803587667

Epoch: 5| Step: 10
Training loss: 3.5446038726167317
Validation loss: 3.051817926155251

Epoch: 126| Step: 0
Training loss: 3.4087048005596494
Validation loss: 3.051194479256303

Epoch: 5| Step: 1
Training loss: 3.5454499326911564
Validation loss: 3.050547653203853

Epoch: 5| Step: 2
Training loss: 3.491666819011773
Validation loss: 3.0490985540816027

Epoch: 5| Step: 3
Training loss: 3.388931625041158
Validation loss: 3.0503437987566775

Epoch: 5| Step: 4
Training loss: 3.4554842661147656
Validation loss: 3.0474062052418773

Epoch: 5| Step: 5
Training loss: 3.4143225529354133
Validation loss: 3.0480855686139297

Epoch: 5| Step: 6
Training loss: 2.9622408532220263
Validation loss: 3.0476158484570863

Epoch: 5| Step: 7
Training loss: 3.2790575241157267
Validation loss: 3.04854161338112

Epoch: 5| Step: 8
Training loss: 2.636902753272958
Validation loss: 3.0489842369363527

Epoch: 5| Step: 9
Training loss: 3.757594239048707
Validation loss: 3.0467481849179725

Epoch: 5| Step: 10
Training loss: 2.9892653097851913
Validation loss: 3.047060088075199

Epoch: 127| Step: 0
Training loss: 3.552264584627561
Validation loss: 3.0472560445518972

Epoch: 5| Step: 1
Training loss: 3.2547068624154014
Validation loss: 3.0475482828882496

Epoch: 5| Step: 2
Training loss: 3.2463644674549714
Validation loss: 3.0473742374474457

Epoch: 5| Step: 3
Training loss: 2.587485227680884
Validation loss: 3.0477584883166995

Epoch: 5| Step: 4
Training loss: 3.3686571211033853
Validation loss: 3.046042341956096

Epoch: 5| Step: 5
Training loss: 3.512196679102028
Validation loss: 3.0466601510309324

Epoch: 5| Step: 6
Training loss: 3.4954671117004508
Validation loss: 3.0454436055976464

Epoch: 5| Step: 7
Training loss: 3.519237781275546
Validation loss: 3.04556390757954

Epoch: 5| Step: 8
Training loss: 3.1130102941904707
Validation loss: 3.044538333836195

Epoch: 5| Step: 9
Training loss: 2.9444593413194053
Validation loss: 3.0460519424144485

Epoch: 5| Step: 10
Training loss: 3.815367948854218
Validation loss: 3.0433896525957893

Epoch: 128| Step: 0
Training loss: 3.258212058175471
Validation loss: 3.0439298309597085

Epoch: 5| Step: 1
Training loss: 3.7094219767191743
Validation loss: 3.044760475089998

Epoch: 5| Step: 2
Training loss: 3.589669207790922
Validation loss: 3.044365988291753

Epoch: 5| Step: 3
Training loss: 2.743241762260654
Validation loss: 3.043994993209683

Epoch: 5| Step: 4
Training loss: 3.3972366491430592
Validation loss: 3.0436288946688017

Epoch: 5| Step: 5
Training loss: 2.8380352910154794
Validation loss: 3.043400455047304

Epoch: 5| Step: 6
Training loss: 3.2972501568430865
Validation loss: 3.043771853602973

Epoch: 5| Step: 7
Training loss: 3.4695797864220017
Validation loss: 3.0423890179142505

Epoch: 5| Step: 8
Training loss: 3.2686515545289185
Validation loss: 3.0430694533506806

Epoch: 5| Step: 9
Training loss: 3.33021644461635
Validation loss: 3.044986907412485

Epoch: 5| Step: 10
Training loss: 3.480627396689419
Validation loss: 3.043519685485363

Epoch: 129| Step: 0
Training loss: 3.0661764070906643
Validation loss: 3.041325254295256

Epoch: 5| Step: 1
Training loss: 3.59606540560196
Validation loss: 3.040586641109294

Epoch: 5| Step: 2
Training loss: 3.471411431487221
Validation loss: 3.0427958546907568

Epoch: 5| Step: 3
Training loss: 3.418396457614398
Validation loss: 3.0441582527517204

Epoch: 5| Step: 4
Training loss: 3.0003315424506045
Validation loss: 3.0462893276256313

Epoch: 5| Step: 5
Training loss: 3.029232966464003
Validation loss: 3.0476348005320197

Epoch: 5| Step: 6
Training loss: 3.0690067222722957
Validation loss: 3.044929524854581

Epoch: 5| Step: 7
Training loss: 3.29013790572062
Validation loss: 3.043549065730279

Epoch: 5| Step: 8
Training loss: 3.1910204426568787
Validation loss: 3.045548350932224

Epoch: 5| Step: 9
Training loss: 3.621987241860495
Validation loss: 3.043532542746708

Epoch: 5| Step: 10
Training loss: 3.6787933753538486
Validation loss: 3.0428290315765594

Epoch: 130| Step: 0
Training loss: 3.9747770906721582
Validation loss: 3.0411216769035394

Epoch: 5| Step: 1
Training loss: 2.8790953947999705
Validation loss: 3.0416240989773233

Epoch: 5| Step: 2
Training loss: 3.7239820075005063
Validation loss: 3.0384629594520134

Epoch: 5| Step: 3
Training loss: 3.3450437520676872
Validation loss: 3.0395880145494774

Epoch: 5| Step: 4
Training loss: 3.3114875829764228
Validation loss: 3.0395305317540555

Epoch: 5| Step: 5
Training loss: 3.5684307323017146
Validation loss: 3.0392256643210844

Epoch: 5| Step: 6
Training loss: 2.8721438608931162
Validation loss: 3.0356099191181958

Epoch: 5| Step: 7
Training loss: 2.8220175875001483
Validation loss: 3.0387274520556558

Epoch: 5| Step: 8
Training loss: 3.188339122947093
Validation loss: 3.03768058485485

Epoch: 5| Step: 9
Training loss: 3.0380722825452535
Validation loss: 3.039185148208962

Epoch: 5| Step: 10
Training loss: 3.5227116346711327
Validation loss: 3.0406150792499678

Epoch: 131| Step: 0
Training loss: 3.546960367528219
Validation loss: 3.0421823684461433

Epoch: 5| Step: 1
Training loss: 2.399113463535893
Validation loss: 3.0427213026894178

Epoch: 5| Step: 2
Training loss: 2.7793829147950166
Validation loss: 3.0468794610995524

Epoch: 5| Step: 3
Training loss: 3.2316603025623265
Validation loss: 3.0505714343829

Epoch: 5| Step: 4
Training loss: 3.315241417012669
Validation loss: 3.057702565055541

Epoch: 5| Step: 5
Training loss: 3.2137557607070173
Validation loss: 3.054484227350407

Epoch: 5| Step: 6
Training loss: 4.034935973840017
Validation loss: 3.0455164570735636

Epoch: 5| Step: 7
Training loss: 3.3269436311065665
Validation loss: 3.0384999331383478

Epoch: 5| Step: 8
Training loss: 3.7355593794314528
Validation loss: 3.036842168411919

Epoch: 5| Step: 9
Training loss: 3.7319504276920634
Validation loss: 3.037193185075702

Epoch: 5| Step: 10
Training loss: 2.6863141659563525
Validation loss: 3.0346041576999934

Epoch: 132| Step: 0
Training loss: 3.672885317496444
Validation loss: 3.037663255203

Epoch: 5| Step: 1
Training loss: 3.4408038821306923
Validation loss: 3.035654799241404

Epoch: 5| Step: 2
Training loss: 3.1554526653290687
Validation loss: 3.0359710711600703

Epoch: 5| Step: 3
Training loss: 3.2142778457060883
Validation loss: 3.036292118612951

Epoch: 5| Step: 4
Training loss: 3.513525849001479
Validation loss: 3.0339066966124717

Epoch: 5| Step: 5
Training loss: 3.4432765628336015
Validation loss: 3.0349159531498606

Epoch: 5| Step: 6
Training loss: 3.0090064911498176
Validation loss: 3.0357038994964154

Epoch: 5| Step: 7
Training loss: 3.317844038762485
Validation loss: 3.0344316441624697

Epoch: 5| Step: 8
Training loss: 3.3064452202027574
Validation loss: 3.034500706513236

Epoch: 5| Step: 9
Training loss: 3.036710716651083
Validation loss: 3.0357535791167822

Epoch: 5| Step: 10
Training loss: 3.2476723478540923
Validation loss: 3.035672475627377

Epoch: 133| Step: 0
Training loss: 3.06366411777435
Validation loss: 3.0362668315884784

Epoch: 5| Step: 1
Training loss: 2.69429682516238
Validation loss: 3.033928162828416

Epoch: 5| Step: 2
Training loss: 3.154841495891161
Validation loss: 3.0359274724969176

Epoch: 5| Step: 3
Training loss: 3.5045927432035997
Validation loss: 3.0332780351796598

Epoch: 5| Step: 4
Training loss: 3.6186284599910943
Validation loss: 3.0348021340451625

Epoch: 5| Step: 5
Training loss: 3.492070070208234
Validation loss: 3.0329210711374657

Epoch: 5| Step: 6
Training loss: 3.3592373132212745
Validation loss: 3.0320542045418293

Epoch: 5| Step: 7
Training loss: 3.393555109037744
Validation loss: 3.032624163571214

Epoch: 5| Step: 8
Training loss: 3.444890072069438
Validation loss: 3.0332230528841055

Epoch: 5| Step: 9
Training loss: 3.1767271915792894
Validation loss: 3.030533978666028

Epoch: 5| Step: 10
Training loss: 3.3715849658862136
Validation loss: 3.031122917722655

Epoch: 134| Step: 0
Training loss: 2.6404964257714343
Validation loss: 3.0318212686554533

Epoch: 5| Step: 1
Training loss: 2.9615901338488153
Validation loss: 3.03168833246146

Epoch: 5| Step: 2
Training loss: 3.6880544471941774
Validation loss: 3.032605589398648

Epoch: 5| Step: 3
Training loss: 3.0725848692307083
Validation loss: 3.0307578526832866

Epoch: 5| Step: 4
Training loss: 3.3344967877956972
Validation loss: 3.0376360789973305

Epoch: 5| Step: 5
Training loss: 3.2855582881407703
Validation loss: 3.0377211277858214

Epoch: 5| Step: 6
Training loss: 3.138232786161919
Validation loss: 3.0426783163977134

Epoch: 5| Step: 7
Training loss: 3.410636527202938
Validation loss: 3.0453459540737886

Epoch: 5| Step: 8
Training loss: 3.6358767476106664
Validation loss: 3.0314722016717264

Epoch: 5| Step: 9
Training loss: 3.553370237987842
Validation loss: 3.0286660428836982

Epoch: 5| Step: 10
Training loss: 3.5325350153457156
Validation loss: 3.03124638870036

Epoch: 135| Step: 0
Training loss: 3.5519645574107366
Validation loss: 3.02970993420472

Epoch: 5| Step: 1
Training loss: 3.6022572540309707
Validation loss: 3.030778864131822

Epoch: 5| Step: 2
Training loss: 2.6062823945371814
Validation loss: 3.0289619613827767

Epoch: 5| Step: 3
Training loss: 2.809296118251544
Validation loss: 3.0302361510863487

Epoch: 5| Step: 4
Training loss: 3.3674756699032193
Validation loss: 3.029281631723025

Epoch: 5| Step: 5
Training loss: 3.3027192154349754
Validation loss: 3.0318476082882455

Epoch: 5| Step: 6
Training loss: 2.883585508340464
Validation loss: 3.030945148875717

Epoch: 5| Step: 7
Training loss: 2.917360786313467
Validation loss: 3.0300471324606044

Epoch: 5| Step: 8
Training loss: 4.242503567156306
Validation loss: 3.0291833305473213

Epoch: 5| Step: 9
Training loss: 3.1944262481023773
Validation loss: 3.030049590301258

Epoch: 5| Step: 10
Training loss: 3.6314143289752168
Validation loss: 3.0264149619617235

Epoch: 136| Step: 0
Training loss: 2.7080955009693817
Validation loss: 3.0287062206245112

Epoch: 5| Step: 1
Training loss: 3.8319145285963483
Validation loss: 3.0285626123325065

Epoch: 5| Step: 2
Training loss: 2.6410846197343645
Validation loss: 3.0294958878489977

Epoch: 5| Step: 3
Training loss: 2.6937228172683194
Validation loss: 3.0288551189198727

Epoch: 5| Step: 4
Training loss: 3.7236156528256594
Validation loss: 3.030622909019663

Epoch: 5| Step: 5
Training loss: 3.374181860200782
Validation loss: 3.0331210692181165

Epoch: 5| Step: 6
Training loss: 3.432452432034733
Validation loss: 3.035642107919579

Epoch: 5| Step: 7
Training loss: 2.9849335312591396
Validation loss: 3.047699889455002

Epoch: 5| Step: 8
Training loss: 4.2184599600095884
Validation loss: 3.0436700481981376

Epoch: 5| Step: 9
Training loss: 2.7054179615053098
Validation loss: 3.026975580825427

Epoch: 5| Step: 10
Training loss: 3.68964944037491
Validation loss: 3.025862314312389

Epoch: 137| Step: 0
Training loss: 3.3182584984115198
Validation loss: 3.0267593904801693

Epoch: 5| Step: 1
Training loss: 3.4058232871339045
Validation loss: 3.0284508493616613

Epoch: 5| Step: 2
Training loss: 3.7144414481327397
Validation loss: 3.0295153569266136

Epoch: 5| Step: 3
Training loss: 3.876554730986837
Validation loss: 3.0302559538136906

Epoch: 5| Step: 4
Training loss: 3.1232290208863547
Validation loss: 3.0310184807716762

Epoch: 5| Step: 5
Training loss: 3.3571893723578596
Validation loss: 3.0261868579051656

Epoch: 5| Step: 6
Training loss: 3.3910422354081313
Validation loss: 3.0245244243466174

Epoch: 5| Step: 7
Training loss: 2.9197273725457102
Validation loss: 3.0252788287395607

Epoch: 5| Step: 8
Training loss: 3.348677952223827
Validation loss: 3.026290737304748

Epoch: 5| Step: 9
Training loss: 2.8863614368362076
Validation loss: 3.025713183162444

Epoch: 5| Step: 10
Training loss: 2.8375274992967268
Validation loss: 3.024919360469175

Epoch: 138| Step: 0
Training loss: 3.569375079940985
Validation loss: 3.028036733670257

Epoch: 5| Step: 1
Training loss: 3.0603630239530255
Validation loss: 3.025709490693254

Epoch: 5| Step: 2
Training loss: 3.0409375366298748
Validation loss: 3.0231804278032177

Epoch: 5| Step: 3
Training loss: 3.0769445024257913
Validation loss: 3.0253755399911437

Epoch: 5| Step: 4
Training loss: 3.722852223412603
Validation loss: 3.0317131714499315

Epoch: 5| Step: 5
Training loss: 2.746860619551824
Validation loss: 3.0285518145176917

Epoch: 5| Step: 6
Training loss: 3.4205212288465257
Validation loss: 3.030485054354223

Epoch: 5| Step: 7
Training loss: 3.34785423450064
Validation loss: 3.0272790092772905

Epoch: 5| Step: 8
Training loss: 3.19926212267417
Validation loss: 3.0269310395289994

Epoch: 5| Step: 9
Training loss: 3.227234260144223
Validation loss: 3.0271457042346053

Epoch: 5| Step: 10
Training loss: 3.8308392302958922
Validation loss: 3.0301533575840924

Epoch: 139| Step: 0
Training loss: 2.839313105942037
Validation loss: 3.0240143052993482

Epoch: 5| Step: 1
Training loss: 2.847836921726991
Validation loss: 3.023078809208119

Epoch: 5| Step: 2
Training loss: 3.036479725225265
Validation loss: 3.0224354813209615

Epoch: 5| Step: 3
Training loss: 3.0586576686528337
Validation loss: 3.022791263127653

Epoch: 5| Step: 4
Training loss: 3.120273525279249
Validation loss: 3.0223714141281364

Epoch: 5| Step: 5
Training loss: 2.7482437247648233
Validation loss: 3.0217369931644376

Epoch: 5| Step: 6
Training loss: 4.061129764410256
Validation loss: 3.019546576459464

Epoch: 5| Step: 7
Training loss: 3.8156737578304947
Validation loss: 3.019871534785148

Epoch: 5| Step: 8
Training loss: 3.122108953223109
Validation loss: 3.0199533801116045

Epoch: 5| Step: 9
Training loss: 3.6425490636407734
Validation loss: 3.0200340653505466

Epoch: 5| Step: 10
Training loss: 3.747797764405884
Validation loss: 3.0204998224048367

Epoch: 140| Step: 0
Training loss: 1.744318390231449
Validation loss: 3.017265122473428

Epoch: 5| Step: 1
Training loss: 3.5674139565007215
Validation loss: 3.0180666317740514

Epoch: 5| Step: 2
Training loss: 3.3056731501444507
Validation loss: 3.017517662272256

Epoch: 5| Step: 3
Training loss: 3.707770672806179
Validation loss: 3.0187148346370005

Epoch: 5| Step: 4
Training loss: 2.9926657033119795
Validation loss: 3.0223889943173323

Epoch: 5| Step: 5
Training loss: 3.2308392202740053
Validation loss: 3.02115604995077

Epoch: 5| Step: 6
Training loss: 3.8821033467249837
Validation loss: 3.023682392141514

Epoch: 5| Step: 7
Training loss: 3.3647970755665506
Validation loss: 3.0257618101380217

Epoch: 5| Step: 8
Training loss: 3.0113449161530013
Validation loss: 3.0195162053386033

Epoch: 5| Step: 9
Training loss: 2.9720719874867956
Validation loss: 3.0157855033295475

Epoch: 5| Step: 10
Training loss: 4.020878661432217
Validation loss: 3.016957597216512

Epoch: 141| Step: 0
Training loss: 2.8792921452062292
Validation loss: 3.0153863910119036

Epoch: 5| Step: 1
Training loss: 2.577342151503748
Validation loss: 3.014041973742791

Epoch: 5| Step: 2
Training loss: 4.067155254176101
Validation loss: 3.01513065428695

Epoch: 5| Step: 3
Training loss: 3.6965510609341985
Validation loss: 3.0145338157403976

Epoch: 5| Step: 4
Training loss: 3.0187020686986368
Validation loss: 3.0152235299995933

Epoch: 5| Step: 5
Training loss: 3.7065527137786036
Validation loss: 3.0147309391002475

Epoch: 5| Step: 6
Training loss: 3.850008451774535
Validation loss: 3.012298138819536

Epoch: 5| Step: 7
Training loss: 2.7797570668564773
Validation loss: 3.0132251379916815

Epoch: 5| Step: 8
Training loss: 3.528498700254508
Validation loss: 3.0119166849090893

Epoch: 5| Step: 9
Training loss: 2.713550023354655
Validation loss: 3.012227419319203

Epoch: 5| Step: 10
Training loss: 2.9406497382685193
Validation loss: 3.0118671823985865

Epoch: 142| Step: 0
Training loss: 3.0263317360883404
Validation loss: 3.014520501427513

Epoch: 5| Step: 1
Training loss: 3.2820837505657194
Validation loss: 3.01440751959816

Epoch: 5| Step: 2
Training loss: 3.4390419016129776
Validation loss: 3.013758591065114

Epoch: 5| Step: 3
Training loss: 3.3707886311349418
Validation loss: 3.013338039941549

Epoch: 5| Step: 4
Training loss: 3.780515489094212
Validation loss: 3.0143676224360796

Epoch: 5| Step: 5
Training loss: 2.9050062245812756
Validation loss: 3.0123380914756077

Epoch: 5| Step: 6
Training loss: 3.0424512783089543
Validation loss: 3.0101268356424757

Epoch: 5| Step: 7
Training loss: 3.35210366315033
Validation loss: 3.010516217023486

Epoch: 5| Step: 8
Training loss: 3.1781307974343322
Validation loss: 3.0117505429661726

Epoch: 5| Step: 9
Training loss: 3.4657070800307395
Validation loss: 3.016791020764282

Epoch: 5| Step: 10
Training loss: 3.276682699506412
Validation loss: 3.018078209502148

Epoch: 143| Step: 0
Training loss: 3.6984893498656093
Validation loss: 3.022802619215666

Epoch: 5| Step: 1
Training loss: 3.8736534240048113
Validation loss: 3.015269335070153

Epoch: 5| Step: 2
Training loss: 2.9319838005961096
Validation loss: 3.014095026459076

Epoch: 5| Step: 3
Training loss: 3.710021474112907
Validation loss: 3.0137921284339058

Epoch: 5| Step: 4
Training loss: 3.2008118255324325
Validation loss: 3.0169727447092334

Epoch: 5| Step: 5
Training loss: 2.3912078545820097
Validation loss: 3.0141305588556904

Epoch: 5| Step: 6
Training loss: 3.6042750935791945
Validation loss: 3.0160262083083564

Epoch: 5| Step: 7
Training loss: 2.761222654512042
Validation loss: 3.0174020161146866

Epoch: 5| Step: 8
Training loss: 3.8769493122226213
Validation loss: 3.0141192993772243

Epoch: 5| Step: 9
Training loss: 2.8962568526831087
Validation loss: 3.010143281383185

Epoch: 5| Step: 10
Training loss: 2.7753320375039805
Validation loss: 3.008397903228922

Epoch: 144| Step: 0
Training loss: 2.5132205442354807
Validation loss: 3.008362932877391

Epoch: 5| Step: 1
Training loss: 3.564168974119243
Validation loss: 3.010031668312771

Epoch: 5| Step: 2
Training loss: 3.694318512672031
Validation loss: 3.0091631636006495

Epoch: 5| Step: 3
Training loss: 3.195322349178739
Validation loss: 3.010457368417943

Epoch: 5| Step: 4
Training loss: 3.0009710012049835
Validation loss: 3.0097487393813664

Epoch: 5| Step: 5
Training loss: 2.9814070878138397
Validation loss: 3.0127052277049677

Epoch: 5| Step: 6
Training loss: 2.9420940106773568
Validation loss: 3.015030875644722

Epoch: 5| Step: 7
Training loss: 3.460112669328593
Validation loss: 3.0129863176784837

Epoch: 5| Step: 8
Training loss: 3.7693616127228045
Validation loss: 3.019308518523859

Epoch: 5| Step: 9
Training loss: 3.424263595158588
Validation loss: 3.0163372749446635

Epoch: 5| Step: 10
Training loss: 3.4280889517906563
Validation loss: 3.0089189752640637

Epoch: 145| Step: 0
Training loss: 2.6087474867950746
Validation loss: 3.0083935086292586

Epoch: 5| Step: 1
Training loss: 3.925874775394039
Validation loss: 3.0088556831756765

Epoch: 5| Step: 2
Training loss: 3.280608632211666
Validation loss: 3.006497673376062

Epoch: 5| Step: 3
Training loss: 2.7179334444678975
Validation loss: 3.0082238254744915

Epoch: 5| Step: 4
Training loss: 4.062676998097331
Validation loss: 3.0069799286528003

Epoch: 5| Step: 5
Training loss: 3.261167852055049
Validation loss: 3.0073724095265404

Epoch: 5| Step: 6
Training loss: 2.6358302901285917
Validation loss: 3.0035943995265564

Epoch: 5| Step: 7
Training loss: 3.5692869086492447
Validation loss: 3.0056328719509207

Epoch: 5| Step: 8
Training loss: 3.1452062794486473
Validation loss: 3.0051438607674985

Epoch: 5| Step: 9
Training loss: 3.262943755038901
Validation loss: 3.0036048321352578

Epoch: 5| Step: 10
Training loss: 3.3475106740700165
Validation loss: 3.00549632935495

Epoch: 146| Step: 0
Training loss: 4.144852233019813
Validation loss: 3.006353434001751

Epoch: 5| Step: 1
Training loss: 2.9410756851206514
Validation loss: 3.004597992587417

Epoch: 5| Step: 2
Training loss: 2.906584361541367
Validation loss: 3.0060699951361873

Epoch: 5| Step: 3
Training loss: 3.139037988623036
Validation loss: 3.00649453629104

Epoch: 5| Step: 4
Training loss: 2.825295903735492
Validation loss: 3.00399486006154

Epoch: 5| Step: 5
Training loss: 3.451476104746452
Validation loss: 3.002920813992157

Epoch: 5| Step: 6
Training loss: 3.411052153578657
Validation loss: 3.0035212183199906

Epoch: 5| Step: 7
Training loss: 3.184863627102766
Validation loss: 3.0025448140594952

Epoch: 5| Step: 8
Training loss: 3.7693642692938165
Validation loss: 3.0063289585318302

Epoch: 5| Step: 9
Training loss: 2.904184899804242
Validation loss: 3.008981537990533

Epoch: 5| Step: 10
Training loss: 3.191690570021346
Validation loss: 3.0076053091496058

Epoch: 147| Step: 0
Training loss: 3.4619445024666673
Validation loss: 3.0111635506987664

Epoch: 5| Step: 1
Training loss: 3.494999446841566
Validation loss: 3.014392343906634

Epoch: 5| Step: 2
Training loss: 3.519151605755568
Validation loss: 3.012980286750662

Epoch: 5| Step: 3
Training loss: 2.9444117294349446
Validation loss: 3.0094574807694388

Epoch: 5| Step: 4
Training loss: 2.5851811804078
Validation loss: 3.005521193739137

Epoch: 5| Step: 5
Training loss: 3.444348258723
Validation loss: 3.0063751489712134

Epoch: 5| Step: 6
Training loss: 3.930863858470314
Validation loss: 3.005386909972451

Epoch: 5| Step: 7
Training loss: 3.5161353524967773
Validation loss: 3.004267003743608

Epoch: 5| Step: 8
Training loss: 2.913284484255881
Validation loss: 3.0025403297798237

Epoch: 5| Step: 9
Training loss: 3.133610878143634
Validation loss: 3.002572132843292

Epoch: 5| Step: 10
Training loss: 2.889520217510572
Validation loss: 2.99985234946598

Epoch: 148| Step: 0
Training loss: 3.437788517721549
Validation loss: 2.9993323229160467

Epoch: 5| Step: 1
Training loss: 3.5913834450582516
Validation loss: 2.998739661449003

Epoch: 5| Step: 2
Training loss: 3.189576164717605
Validation loss: 3.001339972070048

Epoch: 5| Step: 3
Training loss: 3.491960283435903
Validation loss: 2.9998553422349503

Epoch: 5| Step: 4
Training loss: 3.6173844417734977
Validation loss: 2.998152297157468

Epoch: 5| Step: 5
Training loss: 2.3140470124318195
Validation loss: 3.0011466665158584

Epoch: 5| Step: 6
Training loss: 3.6404223733596517
Validation loss: 3.009246590833675

Epoch: 5| Step: 7
Training loss: 3.4557137430283316
Validation loss: 3.0016450798031573

Epoch: 5| Step: 8
Training loss: 2.7775891674434803
Validation loss: 3.000967889096378

Epoch: 5| Step: 9
Training loss: 3.4216291783492347
Validation loss: 3.004474245618505

Epoch: 5| Step: 10
Training loss: 2.777416630686037
Validation loss: 3.001065458102828

Epoch: 149| Step: 0
Training loss: 3.081515695750112
Validation loss: 2.9975341691967916

Epoch: 5| Step: 1
Training loss: 3.6050611205613974
Validation loss: 2.997628303358713

Epoch: 5| Step: 2
Training loss: 2.8900606171477743
Validation loss: 2.9960367042480116

Epoch: 5| Step: 3
Training loss: 3.302087793838585
Validation loss: 2.9983030565096622

Epoch: 5| Step: 4
Training loss: 2.83137148834357
Validation loss: 2.9984237724192204

Epoch: 5| Step: 5
Training loss: 3.8052633425480735
Validation loss: 2.996623786829273

Epoch: 5| Step: 6
Training loss: 3.1650750694592538
Validation loss: 3.0013553316322366

Epoch: 5| Step: 7
Training loss: 3.3682730710469624
Validation loss: 3.0031883634024523

Epoch: 5| Step: 8
Training loss: 3.4096918478081384
Validation loss: 3.004911585978206

Epoch: 5| Step: 9
Training loss: 3.0489433897273672
Validation loss: 3.0094590439346853

Epoch: 5| Step: 10
Training loss: 3.459565797142864
Validation loss: 3.001182166850521

Epoch: 150| Step: 0
Training loss: 3.4072812820287206
Validation loss: 3.0116905778317626

Epoch: 5| Step: 1
Training loss: 3.730673899177519
Validation loss: 2.9974296370274973

Epoch: 5| Step: 2
Training loss: 2.7372659278327474
Validation loss: 2.9993478312260398

Epoch: 5| Step: 3
Training loss: 3.7856366902750764
Validation loss: 2.9965168547673726

Epoch: 5| Step: 4
Training loss: 2.4883184265521456
Validation loss: 2.9991505250803936

Epoch: 5| Step: 5
Training loss: 2.8981237524448233
Validation loss: 2.996067200432224

Epoch: 5| Step: 6
Training loss: 3.470081245724473
Validation loss: 2.997638979943486

Epoch: 5| Step: 7
Training loss: 3.543466282811834
Validation loss: 3.00027200703106

Epoch: 5| Step: 8
Training loss: 3.7224264484258693
Validation loss: 2.9972331660057074

Epoch: 5| Step: 9
Training loss: 2.8679020378481983
Validation loss: 2.996220562269139

Epoch: 5| Step: 10
Training loss: 3.0620747485066224
Validation loss: 2.997741729437713

Epoch: 151| Step: 0
Training loss: 3.51132821191178
Validation loss: 2.9969190497354337

Epoch: 5| Step: 1
Training loss: 3.5395159904505693
Validation loss: 2.997318180040158

Epoch: 5| Step: 2
Training loss: 3.1764626985963065
Validation loss: 2.998359562379492

Epoch: 5| Step: 3
Training loss: 3.0438674559440773
Validation loss: 2.995747012667947

Epoch: 5| Step: 4
Training loss: 3.8923067801263658
Validation loss: 2.992515218514786

Epoch: 5| Step: 5
Training loss: 3.4697266999278753
Validation loss: 2.9933300781460686

Epoch: 5| Step: 6
Training loss: 2.8643422158229805
Validation loss: 2.993733569568165

Epoch: 5| Step: 7
Training loss: 3.3513305868371903
Validation loss: 2.993680577339495

Epoch: 5| Step: 8
Training loss: 2.6896103845521786
Validation loss: 2.9925323915578517

Epoch: 5| Step: 9
Training loss: 3.4544323133804564
Validation loss: 2.994743606303018

Epoch: 5| Step: 10
Training loss: 2.73067236756435
Validation loss: 2.998626002957259

Epoch: 152| Step: 0
Training loss: 3.3558474450248457
Validation loss: 2.9961312405530487

Epoch: 5| Step: 1
Training loss: 3.131395737840839
Validation loss: 2.997482005344322

Epoch: 5| Step: 2
Training loss: 3.0876368998088224
Validation loss: 2.9977630578161287

Epoch: 5| Step: 3
Training loss: 2.1715576159523455
Validation loss: 2.999426093803601

Epoch: 5| Step: 4
Training loss: 3.6624715966695405
Validation loss: 2.994127901555928

Epoch: 5| Step: 5
Training loss: 3.6495847021585868
Validation loss: 2.991904812427754

Epoch: 5| Step: 6
Training loss: 3.125305923746409
Validation loss: 2.992498079640735

Epoch: 5| Step: 7
Training loss: 3.6741777706922965
Validation loss: 2.990814381428186

Epoch: 5| Step: 8
Training loss: 3.48200586629392
Validation loss: 2.991420250257681

Epoch: 5| Step: 9
Training loss: 2.5875045776326697
Validation loss: 2.991554142029802

Epoch: 5| Step: 10
Training loss: 3.7726306882029035
Validation loss: 2.994516728190104

Epoch: 153| Step: 0
Training loss: 2.7899643751488314
Validation loss: 2.992358771888921

Epoch: 5| Step: 1
Training loss: 3.7316829922176855
Validation loss: 2.992761105917901

Epoch: 5| Step: 2
Training loss: 3.523115934259114
Validation loss: 2.9950449868060045

Epoch: 5| Step: 3
Training loss: 2.959317934479008
Validation loss: 2.9952394098158974

Epoch: 5| Step: 4
Training loss: 2.972637642640515
Validation loss: 3.00265513701298

Epoch: 5| Step: 5
Training loss: 3.467649543029325
Validation loss: 2.994394425007687

Epoch: 5| Step: 6
Training loss: 3.4889549638548116
Validation loss: 3.002541631007136

Epoch: 5| Step: 7
Training loss: 2.955869499381779
Validation loss: 2.995808580548372

Epoch: 5| Step: 8
Training loss: 3.088448036837453
Validation loss: 2.9927528618547816

Epoch: 5| Step: 9
Training loss: 3.189409020907937
Validation loss: 2.9919446158351986

Epoch: 5| Step: 10
Training loss: 3.7536285647002154
Validation loss: 2.9951292279839192

Epoch: 154| Step: 0
Training loss: 3.129922575556701
Validation loss: 2.9910631822300573

Epoch: 5| Step: 1
Training loss: 3.4167136367422555
Validation loss: 2.9878738407632297

Epoch: 5| Step: 2
Training loss: 3.360877973879751
Validation loss: 2.989663261541929

Epoch: 5| Step: 3
Training loss: 3.4965008546579157
Validation loss: 2.9882440410144344

Epoch: 5| Step: 4
Training loss: 3.638210035941438
Validation loss: 2.9888866313492692

Epoch: 5| Step: 5
Training loss: 3.3760735958809738
Validation loss: 2.9898426111693857

Epoch: 5| Step: 6
Training loss: 3.294136247662513
Validation loss: 2.9892922113510525

Epoch: 5| Step: 7
Training loss: 3.0986158849600662
Validation loss: 2.9885367906006866

Epoch: 5| Step: 8
Training loss: 3.0278118337724393
Validation loss: 2.985750250551757

Epoch: 5| Step: 9
Training loss: 3.5297236561875907
Validation loss: 2.9892166105428797

Epoch: 5| Step: 10
Training loss: 2.2612409597609417
Validation loss: 2.9867728681413546

Epoch: 155| Step: 0
Training loss: 3.3114425122816185
Validation loss: 2.9898505134184155

Epoch: 5| Step: 1
Training loss: 3.941709417927199
Validation loss: 2.987572370556981

Epoch: 5| Step: 2
Training loss: 3.174929496402858
Validation loss: 2.991072142341372

Epoch: 5| Step: 3
Training loss: 3.3983154274950667
Validation loss: 2.9893979516781464

Epoch: 5| Step: 4
Training loss: 3.1586515147257845
Validation loss: 2.9850940419044987

Epoch: 5| Step: 5
Training loss: 3.073708400995544
Validation loss: 2.986712859880761

Epoch: 5| Step: 6
Training loss: 3.2684029622874164
Validation loss: 2.9865053031324935

Epoch: 5| Step: 7
Training loss: 2.9643827740902897
Validation loss: 2.988719378154475

Epoch: 5| Step: 8
Training loss: 3.0107613512506384
Validation loss: 2.9850719333731273

Epoch: 5| Step: 9
Training loss: 3.2411903410576386
Validation loss: 2.9888281820143914

Epoch: 5| Step: 10
Training loss: 3.3036803385924083
Validation loss: 2.9865965101860334

Epoch: 156| Step: 0
Training loss: 2.792142305611438
Validation loss: 2.9859159056827407

Epoch: 5| Step: 1
Training loss: 2.8547118471440527
Validation loss: 2.984922132444685

Epoch: 5| Step: 2
Training loss: 3.7881975897521376
Validation loss: 2.983829594701939

Epoch: 5| Step: 3
Training loss: 3.905608345737315
Validation loss: 2.984741600750928

Epoch: 5| Step: 4
Training loss: 3.199700436875644
Validation loss: 2.9828889532912224

Epoch: 5| Step: 5
Training loss: 3.181722004167586
Validation loss: 2.9846221558624646

Epoch: 5| Step: 6
Training loss: 2.785954386456158
Validation loss: 2.9836935055416367

Epoch: 5| Step: 7
Training loss: 3.5858300552394553
Validation loss: 2.9833247204966353

Epoch: 5| Step: 8
Training loss: 3.471395772277786
Validation loss: 2.9818256615839207

Epoch: 5| Step: 9
Training loss: 2.9533481412678517
Validation loss: 2.9843052157585475

Epoch: 5| Step: 10
Training loss: 3.149932884833434
Validation loss: 2.983852038923475

Epoch: 157| Step: 0
Training loss: 3.468496364908897
Validation loss: 2.983057660058696

Epoch: 5| Step: 1
Training loss: 2.7940661428564533
Validation loss: 2.980876048984401

Epoch: 5| Step: 2
Training loss: 2.8164541634599
Validation loss: 2.9808786884130445

Epoch: 5| Step: 3
Training loss: 3.761844113995221
Validation loss: 2.984446990241106

Epoch: 5| Step: 4
Training loss: 3.396787747242517
Validation loss: 2.9821333624730224

Epoch: 5| Step: 5
Training loss: 3.682474494219034
Validation loss: 2.9834593648361762

Epoch: 5| Step: 6
Training loss: 3.0648529978312875
Validation loss: 2.9807830732107576

Epoch: 5| Step: 7
Training loss: 3.1445630942681064
Validation loss: 2.9816660841372977

Epoch: 5| Step: 8
Training loss: 3.704310746424914
Validation loss: 2.983677764641895

Epoch: 5| Step: 9
Training loss: 2.7514639339090112
Validation loss: 2.980728561497261

Epoch: 5| Step: 10
Training loss: 3.074425657645611
Validation loss: 2.981676295980887

Epoch: 158| Step: 0
Training loss: 3.669793500781605
Validation loss: 2.9822774305290345

Epoch: 5| Step: 1
Training loss: 3.432563705353273
Validation loss: 2.980159376988714

Epoch: 5| Step: 2
Training loss: 2.8845894152132554
Validation loss: 2.9785991721671508

Epoch: 5| Step: 3
Training loss: 3.3871965786224227
Validation loss: 2.9801408938988723

Epoch: 5| Step: 4
Training loss: 3.679616745189571
Validation loss: 2.9827423672414133

Epoch: 5| Step: 5
Training loss: 3.474890557630874
Validation loss: 2.9811720168026854

Epoch: 5| Step: 6
Training loss: 3.3724016147794718
Validation loss: 2.9839277670569655

Epoch: 5| Step: 7
Training loss: 3.222661576700143
Validation loss: 2.9802826428294966

Epoch: 5| Step: 8
Training loss: 2.6999490415214775
Validation loss: 2.980052312663087

Epoch: 5| Step: 9
Training loss: 3.0867761172614547
Validation loss: 2.9862390636882767

Epoch: 5| Step: 10
Training loss: 2.762541091406201
Validation loss: 2.980673736575037

Epoch: 159| Step: 0
Training loss: 3.1180781189220843
Validation loss: 2.9781898969996137

Epoch: 5| Step: 1
Training loss: 3.466578310671922
Validation loss: 2.980942586125896

Epoch: 5| Step: 2
Training loss: 3.253246593126767
Validation loss: 2.9811054572631774

Epoch: 5| Step: 3
Training loss: 2.72175659903214
Validation loss: 2.980015425906765

Epoch: 5| Step: 4
Training loss: 3.5302212997533076
Validation loss: 2.9786202580555137

Epoch: 5| Step: 5
Training loss: 2.748212233220135
Validation loss: 2.9780500042999978

Epoch: 5| Step: 6
Training loss: 3.4844256341787623
Validation loss: 2.98129916969306

Epoch: 5| Step: 7
Training loss: 3.350764537510782
Validation loss: 2.978806331386699

Epoch: 5| Step: 8
Training loss: 3.802451226537981
Validation loss: 2.9817288120072782

Epoch: 5| Step: 9
Training loss: 2.959029174062686
Validation loss: 2.978528533912953

Epoch: 5| Step: 10
Training loss: 3.2510402188495973
Validation loss: 2.9805073376556117

Epoch: 160| Step: 0
Training loss: 3.5799015082764445
Validation loss: 2.9790308613239254

Epoch: 5| Step: 1
Training loss: 3.1561859426513266
Validation loss: 2.9794015597463703

Epoch: 5| Step: 2
Training loss: 3.1951714743386224
Validation loss: 2.979703788661826

Epoch: 5| Step: 3
Training loss: 3.1787086873551944
Validation loss: 2.980289641412591

Epoch: 5| Step: 4
Training loss: 2.8605024272586346
Validation loss: 2.98364718478543

Epoch: 5| Step: 5
Training loss: 3.142264777873618
Validation loss: 2.9821874522089025

Epoch: 5| Step: 6
Training loss: 3.7214348341374253
Validation loss: 2.9758776054765113

Epoch: 5| Step: 7
Training loss: 2.973810480632422
Validation loss: 2.97722943327657

Epoch: 5| Step: 8
Training loss: 3.3282996476604536
Validation loss: 2.9755305293110226

Epoch: 5| Step: 9
Training loss: 3.043269131565776
Validation loss: 2.9740610590728727

Epoch: 5| Step: 10
Training loss: 3.618879742182504
Validation loss: 2.977261856306446

Epoch: 161| Step: 0
Training loss: 2.867393714910562
Validation loss: 2.980078884471435

Epoch: 5| Step: 1
Training loss: 3.744363490612136
Validation loss: 2.9725214837211067

Epoch: 5| Step: 2
Training loss: 2.946989922492353
Validation loss: 2.977080947924507

Epoch: 5| Step: 3
Training loss: 3.6936879367423074
Validation loss: 2.971324889054343

Epoch: 5| Step: 4
Training loss: 3.0607832164350115
Validation loss: 2.9758495816013397

Epoch: 5| Step: 5
Training loss: 3.754194202950129
Validation loss: 2.9752896768062773

Epoch: 5| Step: 6
Training loss: 2.3625580997488127
Validation loss: 2.9779006283822897

Epoch: 5| Step: 7
Training loss: 2.9694964624869744
Validation loss: 2.9785908940711496

Epoch: 5| Step: 8
Training loss: 3.001023912537287
Validation loss: 2.9782032704354475

Epoch: 5| Step: 9
Training loss: 3.4776907129598693
Validation loss: 2.9854619463267142

Epoch: 5| Step: 10
Training loss: 3.6962028866275416
Validation loss: 2.98077819926891

Epoch: 162| Step: 0
Training loss: 3.5737038830413117
Validation loss: 2.9757001141790944

Epoch: 5| Step: 1
Training loss: 2.69853208339661
Validation loss: 2.9773995180757633

Epoch: 5| Step: 2
Training loss: 3.752581661385427
Validation loss: 2.9757569915292117

Epoch: 5| Step: 3
Training loss: 3.883664442580419
Validation loss: 2.9771504106722735

Epoch: 5| Step: 4
Training loss: 3.138087068019651
Validation loss: 2.972928704771485

Epoch: 5| Step: 5
Training loss: 3.3369413558384102
Validation loss: 2.973590543977181

Epoch: 5| Step: 6
Training loss: 2.8706203771114187
Validation loss: 2.9736664911888675

Epoch: 5| Step: 7
Training loss: 3.104664363688485
Validation loss: 2.972949764479289

Epoch: 5| Step: 8
Training loss: 2.4871447975700147
Validation loss: 2.979218112860765

Epoch: 5| Step: 9
Training loss: 3.0167485649274286
Validation loss: 2.9749269654541846

Epoch: 5| Step: 10
Training loss: 3.6891147504803796
Validation loss: 2.9716371470509895

Epoch: 163| Step: 0
Training loss: 3.2896955519692086
Validation loss: 2.973793363268928

Epoch: 5| Step: 1
Training loss: 3.472286723915324
Validation loss: 2.971183332283513

Epoch: 5| Step: 2
Training loss: 2.946601079869679
Validation loss: 2.9715257760302576

Epoch: 5| Step: 3
Training loss: 2.29112052189526
Validation loss: 2.973320112253721

Epoch: 5| Step: 4
Training loss: 3.9066960194584053
Validation loss: 2.969286376994866

Epoch: 5| Step: 5
Training loss: 3.1576072871570378
Validation loss: 2.9718017798910847

Epoch: 5| Step: 6
Training loss: 3.1546099339132314
Validation loss: 2.968931234685835

Epoch: 5| Step: 7
Training loss: 3.3538105145716517
Validation loss: 2.9715824416799657

Epoch: 5| Step: 8
Training loss: 3.4072951367060362
Validation loss: 2.9704193024742023

Epoch: 5| Step: 9
Training loss: 3.6460002461327132
Validation loss: 2.9735132731365623

Epoch: 5| Step: 10
Training loss: 2.802459682069093
Validation loss: 2.971340923170706

Epoch: 164| Step: 0
Training loss: 3.6088144106479745
Validation loss: 2.969813518946107

Epoch: 5| Step: 1
Training loss: 2.7334350714318947
Validation loss: 2.9680373868809515

Epoch: 5| Step: 2
Training loss: 3.210290699805596
Validation loss: 2.9689896111759575

Epoch: 5| Step: 3
Training loss: 2.8726364039611405
Validation loss: 2.9666290159026616

Epoch: 5| Step: 4
Training loss: 2.9105199804152666
Validation loss: 2.9691666643697365

Epoch: 5| Step: 5
Training loss: 2.976662621603934
Validation loss: 2.96718791630821

Epoch: 5| Step: 6
Training loss: 3.4827024268738254
Validation loss: 2.969890673697444

Epoch: 5| Step: 7
Training loss: 3.4653000730019423
Validation loss: 2.9667798485158285

Epoch: 5| Step: 8
Training loss: 3.503118896479058
Validation loss: 2.968831135580746

Epoch: 5| Step: 9
Training loss: 3.722420171595212
Validation loss: 2.967783768844113

Epoch: 5| Step: 10
Training loss: 3.0620309898756712
Validation loss: 2.9681020257302992

Epoch: 165| Step: 0
Training loss: 3.0470951881075496
Validation loss: 2.967203017204504

Epoch: 5| Step: 1
Training loss: 2.824150031851138
Validation loss: 2.9687288319168195

Epoch: 5| Step: 2
Training loss: 3.7054925102680136
Validation loss: 2.966739781799022

Epoch: 5| Step: 3
Training loss: 3.4189513096651916
Validation loss: 2.970272914073788

Epoch: 5| Step: 4
Training loss: 2.995014657826927
Validation loss: 2.9687849499340437

Epoch: 5| Step: 5
Training loss: 3.714438752280861
Validation loss: 2.9686152843744713

Epoch: 5| Step: 6
Training loss: 3.078241181480474
Validation loss: 2.9675481966206596

Epoch: 5| Step: 7
Training loss: 3.0176405421841577
Validation loss: 2.975787168304102

Epoch: 5| Step: 8
Training loss: 2.96654388373672
Validation loss: 2.9744877650103034

Epoch: 5| Step: 9
Training loss: 3.165691794531468
Validation loss: 2.9700736220624773

Epoch: 5| Step: 10
Training loss: 3.683414070544865
Validation loss: 2.964791512500992

Epoch: 166| Step: 0
Training loss: 3.1910135688266115
Validation loss: 2.9643730328059266

Epoch: 5| Step: 1
Training loss: 2.6766005994909956
Validation loss: 2.963062105633723

Epoch: 5| Step: 2
Training loss: 3.055524394329199
Validation loss: 2.9620808221877235

Epoch: 5| Step: 3
Training loss: 3.0718934160458593
Validation loss: 2.9657515144936264

Epoch: 5| Step: 4
Training loss: 3.5277108881124914
Validation loss: 2.9658058753373946

Epoch: 5| Step: 5
Training loss: 3.334017270176763
Validation loss: 2.9607370895194296

Epoch: 5| Step: 6
Training loss: 3.401216620267789
Validation loss: 2.966150889773685

Epoch: 5| Step: 7
Training loss: 3.7394961432844998
Validation loss: 2.9636124236731933

Epoch: 5| Step: 8
Training loss: 3.568999936091796
Validation loss: 2.9648830771079036

Epoch: 5| Step: 9
Training loss: 3.0705845836027046
Validation loss: 2.9638672220985898

Epoch: 5| Step: 10
Training loss: 2.8876451133825785
Validation loss: 2.964440902878847

Epoch: 167| Step: 0
Training loss: 3.601424406966532
Validation loss: 2.9658412480761647

Epoch: 5| Step: 1
Training loss: 2.4160691103492646
Validation loss: 2.9651957177916897

Epoch: 5| Step: 2
Training loss: 2.825745735651906
Validation loss: 2.964707082471153

Epoch: 5| Step: 3
Training loss: 2.7954186425225993
Validation loss: 2.966786018294524

Epoch: 5| Step: 4
Training loss: 3.311392401012584
Validation loss: 2.9660549069753914

Epoch: 5| Step: 5
Training loss: 3.1330531306140483
Validation loss: 2.966183305122813

Epoch: 5| Step: 6
Training loss: 3.877546150724834
Validation loss: 2.961786036702837

Epoch: 5| Step: 7
Training loss: 3.4034521528893036
Validation loss: 2.964474590003393

Epoch: 5| Step: 8
Training loss: 3.6797430921109138
Validation loss: 2.959716176150353

Epoch: 5| Step: 9
Training loss: 3.441879257274327
Validation loss: 2.9611037900267605

Epoch: 5| Step: 10
Training loss: 2.8296265383324966
Validation loss: 2.960887098423191

Epoch: 168| Step: 0
Training loss: 2.7494238336574703
Validation loss: 2.964866338810231

Epoch: 5| Step: 1
Training loss: 3.4581389468304966
Validation loss: 2.9594925950723523

Epoch: 5| Step: 2
Training loss: 2.7631033915926158
Validation loss: 2.959371176455569

Epoch: 5| Step: 3
Training loss: 3.5579207586906807
Validation loss: 2.9600347270996004

Epoch: 5| Step: 4
Training loss: 3.417047169284717
Validation loss: 2.9609206043289182

Epoch: 5| Step: 5
Training loss: 3.7525443028853354
Validation loss: 2.9618900723659993

Epoch: 5| Step: 6
Training loss: 2.9966892411594923
Validation loss: 2.9602243415993117

Epoch: 5| Step: 7
Training loss: 3.1885547762707946
Validation loss: 2.9609094645967637

Epoch: 5| Step: 8
Training loss: 3.1007304961379947
Validation loss: 2.9599804023076173

Epoch: 5| Step: 9
Training loss: 3.5627615313986785
Validation loss: 2.9595409960210217

Epoch: 5| Step: 10
Training loss: 2.922607003791033
Validation loss: 2.9629631978066784

Epoch: 169| Step: 0
Training loss: 3.1963277010821463
Validation loss: 2.9598301005998775

Epoch: 5| Step: 1
Training loss: 3.512767257568763
Validation loss: 2.9618487502310287

Epoch: 5| Step: 2
Training loss: 2.7996489338816426
Validation loss: 2.9645443178660607

Epoch: 5| Step: 3
Training loss: 3.6888942345678775
Validation loss: 2.966146850902673

Epoch: 5| Step: 4
Training loss: 2.912680290437692
Validation loss: 2.9784942534735874

Epoch: 5| Step: 5
Training loss: 3.1407455497114416
Validation loss: 2.9855663840253484

Epoch: 5| Step: 6
Training loss: 3.079956594136537
Validation loss: 2.9841786857814907

Epoch: 5| Step: 7
Training loss: 3.4224617511626607
Validation loss: 2.9899994398113727

Epoch: 5| Step: 8
Training loss: 3.0347562352031656
Validation loss: 2.9681686790746897

Epoch: 5| Step: 9
Training loss: 3.3388861817151305
Validation loss: 2.9576959774107388

Epoch: 5| Step: 10
Training loss: 3.5650150723560046
Validation loss: 2.9574071695843083

Epoch: 170| Step: 0
Training loss: 3.2598209182136437
Validation loss: 2.9590824420275563

Epoch: 5| Step: 1
Training loss: 3.1569167839733465
Validation loss: 2.960740313185902

Epoch: 5| Step: 2
Training loss: 3.5172743255730636
Validation loss: 2.963141614694916

Epoch: 5| Step: 3
Training loss: 2.8091621089126186
Validation loss: 2.959896656129147

Epoch: 5| Step: 4
Training loss: 3.238465454605219
Validation loss: 2.9587058982822123

Epoch: 5| Step: 5
Training loss: 3.8778648860976452
Validation loss: 2.9555083522989736

Epoch: 5| Step: 6
Training loss: 3.112903988522655
Validation loss: 2.958147841835346

Epoch: 5| Step: 7
Training loss: 2.9016690811360446
Validation loss: 2.9537786535254194

Epoch: 5| Step: 8
Training loss: 3.6821225283498835
Validation loss: 2.9530624823163274

Epoch: 5| Step: 9
Training loss: 3.1202778042090182
Validation loss: 2.955361495957781

Epoch: 5| Step: 10
Training loss: 2.758996811868029
Validation loss: 2.951479912226295

Epoch: 171| Step: 0
Training loss: 3.0302106510877787
Validation loss: 2.9517941861647254

Epoch: 5| Step: 1
Training loss: 3.629178499946325
Validation loss: 2.955102304901998

Epoch: 5| Step: 2
Training loss: 3.5778243425812826
Validation loss: 2.9546748895530537

Epoch: 5| Step: 3
Training loss: 3.3162617466585886
Validation loss: 2.9570044606806545

Epoch: 5| Step: 4
Training loss: 2.635424848903172
Validation loss: 2.955133450808828

Epoch: 5| Step: 5
Training loss: 3.7721446727059305
Validation loss: 2.956396133885762

Epoch: 5| Step: 6
Training loss: 3.2585837642760866
Validation loss: 2.948559480109776

Epoch: 5| Step: 7
Training loss: 2.559413632950182
Validation loss: 2.9495733732310563

Epoch: 5| Step: 8
Training loss: 3.1144467497171515
Validation loss: 2.9492570137486886

Epoch: 5| Step: 9
Training loss: 3.4642153130233333
Validation loss: 2.946108147455472

Epoch: 5| Step: 10
Training loss: 2.9912719919597435
Validation loss: 2.9456866636432206

Epoch: 172| Step: 0
Training loss: 3.205937485959356
Validation loss: 2.94676927161918

Epoch: 5| Step: 1
Training loss: 2.939090866122334
Validation loss: 2.9448833181713385

Epoch: 5| Step: 2
Training loss: 2.65680733611838
Validation loss: 2.9415256979485687

Epoch: 5| Step: 3
Training loss: 3.413633411250577
Validation loss: 2.9433927538132827

Epoch: 5| Step: 4
Training loss: 3.054787090268341
Validation loss: 2.9421115372805056

Epoch: 5| Step: 5
Training loss: 3.253748419369619
Validation loss: 2.9418667740521447

Epoch: 5| Step: 6
Training loss: 2.9368350311176825
Validation loss: 2.944224450642319

Epoch: 5| Step: 7
Training loss: 3.3302651271724213
Validation loss: 2.949797452366091

Epoch: 5| Step: 8
Training loss: 3.807822813600043
Validation loss: 2.9564021154844426

Epoch: 5| Step: 9
Training loss: 3.4546466771495505
Validation loss: 2.9388438885748567

Epoch: 5| Step: 10
Training loss: 3.385712329962811
Validation loss: 2.938567402901774

Epoch: 173| Step: 0
Training loss: 3.7283255766945786
Validation loss: 2.9360721043950173

Epoch: 5| Step: 1
Training loss: 3.1370115226653152
Validation loss: 2.949131234988081

Epoch: 5| Step: 2
Training loss: 2.7975519309452417
Validation loss: 2.951728855815078

Epoch: 5| Step: 3
Training loss: 3.217131568900503
Validation loss: 2.9521137777842514

Epoch: 5| Step: 4
Training loss: 2.5834858039242965
Validation loss: 2.954015669225271

Epoch: 5| Step: 5
Training loss: 3.6457193120656126
Validation loss: 2.9531886301229733

Epoch: 5| Step: 6
Training loss: 3.813753766133347
Validation loss: 2.9449524261004307

Epoch: 5| Step: 7
Training loss: 2.927421324053049
Validation loss: 2.93826772902744

Epoch: 5| Step: 8
Training loss: 3.1059837058303748
Validation loss: 2.9359203324826755

Epoch: 5| Step: 9
Training loss: 3.3324219093416656
Validation loss: 2.933724856909412

Epoch: 5| Step: 10
Training loss: 2.9522120765138733
Validation loss: 2.9317777190513974

Epoch: 174| Step: 0
Training loss: 2.681242733392005
Validation loss: 2.9342672292827

Epoch: 5| Step: 1
Training loss: 3.0202929484784926
Validation loss: 2.935659827536075

Epoch: 5| Step: 2
Training loss: 3.319391818584857
Validation loss: 2.933997444924328

Epoch: 5| Step: 3
Training loss: 2.9234092886382648
Validation loss: 2.934795582580979

Epoch: 5| Step: 4
Training loss: 3.460923446730074
Validation loss: 2.935984207116489

Epoch: 5| Step: 5
Training loss: 2.7739083763453483
Validation loss: 2.9333035567059715

Epoch: 5| Step: 6
Training loss: 3.374383658185867
Validation loss: 2.932186471837926

Epoch: 5| Step: 7
Training loss: 3.1588236070094506
Validation loss: 2.928051342938827

Epoch: 5| Step: 8
Training loss: 3.585687765762663
Validation loss: 2.9309876112495488

Epoch: 5| Step: 9
Training loss: 2.956969811067068
Validation loss: 2.930011706936595

Epoch: 5| Step: 10
Training loss: 4.152566065897161
Validation loss: 2.9309664372137267

Epoch: 175| Step: 0
Training loss: 2.9912064739396995
Validation loss: 2.928215751660397

Epoch: 5| Step: 1
Training loss: 2.7535387159167546
Validation loss: 2.9284289901627805

Epoch: 5| Step: 2
Training loss: 3.138680686534769
Validation loss: 2.9331452244584497

Epoch: 5| Step: 3
Training loss: 3.7176926335781486
Validation loss: 2.9328788184486623

Epoch: 5| Step: 4
Training loss: 3.1845167074221914
Validation loss: 2.932983622500558

Epoch: 5| Step: 5
Training loss: 2.9935353881110287
Validation loss: 2.9327456369638285

Epoch: 5| Step: 6
Training loss: 3.2215417402832465
Validation loss: 2.9313794213891797

Epoch: 5| Step: 7
Training loss: 3.6457197044467247
Validation loss: 2.937861701097844

Epoch: 5| Step: 8
Training loss: 3.4558583484336385
Validation loss: 2.9306077507492785

Epoch: 5| Step: 9
Training loss: 2.8078479864375505
Validation loss: 2.9316662784283203

Epoch: 5| Step: 10
Training loss: 3.434977212577652
Validation loss: 2.9329248886037793

Testing loss: 3.1349885464502485
