Epoch: 1| Step: 0
Training loss: 5.88381815669674
Validation loss: 5.729593380188617

Epoch: 6| Step: 1
Training loss: 5.38406671935597
Validation loss: 5.71702200181885

Epoch: 6| Step: 2
Training loss: 6.419875527479491
Validation loss: 5.7045216089719135

Epoch: 6| Step: 3
Training loss: 4.903452859472431
Validation loss: 5.692449495610311

Epoch: 6| Step: 4
Training loss: 4.3398430907543375
Validation loss: 5.680002733487308

Epoch: 6| Step: 5
Training loss: 6.147777323197792
Validation loss: 5.667611788278551

Epoch: 6| Step: 6
Training loss: 5.327542180825653
Validation loss: 5.653996721917303

Epoch: 6| Step: 7
Training loss: 6.320294996692389
Validation loss: 5.639230714387454

Epoch: 6| Step: 8
Training loss: 6.285184775999591
Validation loss: 5.623127290825539

Epoch: 6| Step: 9
Training loss: 5.347873814283214
Validation loss: 5.608090103658572

Epoch: 6| Step: 10
Training loss: 5.11070024294779
Validation loss: 5.589744040423273

Epoch: 6| Step: 11
Training loss: 5.822171604302076
Validation loss: 5.570906150295891

Epoch: 6| Step: 12
Training loss: 6.234461886534269
Validation loss: 5.550250700543439

Epoch: 6| Step: 13
Training loss: 5.480641890473798
Validation loss: 5.5296075986252715

Epoch: 2| Step: 0
Training loss: 6.607886324849188
Validation loss: 5.5055718561868

Epoch: 6| Step: 1
Training loss: 5.676956296660161
Validation loss: 5.481537506427923

Epoch: 6| Step: 2
Training loss: 6.40295146597145
Validation loss: 5.455129690086542

Epoch: 6| Step: 3
Training loss: 4.8674586727227656
Validation loss: 5.427354484118863

Epoch: 6| Step: 4
Training loss: 4.811006785008767
Validation loss: 5.398476379699968

Epoch: 6| Step: 5
Training loss: 3.578843090513485
Validation loss: 5.369163635517585

Epoch: 6| Step: 6
Training loss: 6.251871667990902
Validation loss: 5.339176095581061

Epoch: 6| Step: 7
Training loss: 4.8634267517139715
Validation loss: 5.307120716270171

Epoch: 6| Step: 8
Training loss: 6.978981342037659
Validation loss: 5.275471661496583

Epoch: 6| Step: 9
Training loss: 4.544128427396485
Validation loss: 5.240802358953735

Epoch: 6| Step: 10
Training loss: 5.078840469429613
Validation loss: 5.2063621475925395

Epoch: 6| Step: 11
Training loss: 3.908264617207391
Validation loss: 5.1719629760869426

Epoch: 6| Step: 12
Training loss: 5.388696651809657
Validation loss: 5.136921137483116

Epoch: 6| Step: 13
Training loss: 4.86784522448245
Validation loss: 5.100747766513439

Epoch: 3| Step: 0
Training loss: 5.3324025454515604
Validation loss: 5.066086337776063

Epoch: 6| Step: 1
Training loss: 4.411197995457351
Validation loss: 5.02948333901127

Epoch: 6| Step: 2
Training loss: 3.9656227586768438
Validation loss: 4.994950420084264

Epoch: 6| Step: 3
Training loss: 5.621551134536012
Validation loss: 4.959561005793564

Epoch: 6| Step: 4
Training loss: 5.390208175687289
Validation loss: 4.92351637096238

Epoch: 6| Step: 5
Training loss: 3.4785748433336643
Validation loss: 4.8866407707660935

Epoch: 6| Step: 6
Training loss: 5.25884265075412
Validation loss: 4.851907906550343

Epoch: 6| Step: 7
Training loss: 5.057884089941678
Validation loss: 4.816447630816118

Epoch: 6| Step: 8
Training loss: 5.471762911674103
Validation loss: 4.779038406434619

Epoch: 6| Step: 9
Training loss: 4.388341561056311
Validation loss: 4.740539256772665

Epoch: 6| Step: 10
Training loss: 4.929451478848759
Validation loss: 4.703546403440837

Epoch: 6| Step: 11
Training loss: 5.329605031221203
Validation loss: 4.662514321747479

Epoch: 6| Step: 12
Training loss: 4.509886372016592
Validation loss: 4.6198739776768285

Epoch: 6| Step: 13
Training loss: 5.112959884441421
Validation loss: 4.573827190889391

Epoch: 4| Step: 0
Training loss: 4.36945885840936
Validation loss: 4.52972953047444

Epoch: 6| Step: 1
Training loss: 3.7502927030135083
Validation loss: 4.487668930632179

Epoch: 6| Step: 2
Training loss: 4.216230756419985
Validation loss: 4.446793669226817

Epoch: 6| Step: 3
Training loss: 2.9703193130695964
Validation loss: 4.41003664860693

Epoch: 6| Step: 4
Training loss: 4.692519488611739
Validation loss: 4.374985426777418

Epoch: 6| Step: 5
Training loss: 5.543307508422617
Validation loss: 4.344172709387044

Epoch: 6| Step: 6
Training loss: 4.435762091941329
Validation loss: 4.3126524710575325

Epoch: 6| Step: 7
Training loss: 4.9373267421020826
Validation loss: 4.284160415480142

Epoch: 6| Step: 8
Training loss: 4.262926302984002
Validation loss: 4.2544972779342975

Epoch: 6| Step: 9
Training loss: 4.661561330442364
Validation loss: 4.225738255168833

Epoch: 6| Step: 10
Training loss: 4.155097973858532
Validation loss: 4.19610698540076

Epoch: 6| Step: 11
Training loss: 4.680207136085958
Validation loss: 4.167393390079228

Epoch: 6| Step: 12
Training loss: 3.988100830540535
Validation loss: 4.138107555485887

Epoch: 6| Step: 13
Training loss: 4.717389851766526
Validation loss: 4.114103613235743

Epoch: 5| Step: 0
Training loss: 5.018751839415331
Validation loss: 4.0893086044523175

Epoch: 6| Step: 1
Training loss: 3.011230429161768
Validation loss: 4.069683375970439

Epoch: 6| Step: 2
Training loss: 3.633662298749704
Validation loss: 4.05544310747402

Epoch: 6| Step: 3
Training loss: 4.349119312101423
Validation loss: 4.042895410764335

Epoch: 6| Step: 4
Training loss: 3.94629957485144
Validation loss: 4.030129361735093

Epoch: 6| Step: 5
Training loss: 5.635894059451902
Validation loss: 4.019059962618472

Epoch: 6| Step: 6
Training loss: 4.015910453892323
Validation loss: 4.005390876068645

Epoch: 6| Step: 7
Training loss: 4.520627534228257
Validation loss: 3.9962873456774726

Epoch: 6| Step: 8
Training loss: 4.55767839225965
Validation loss: 3.984538355451845

Epoch: 6| Step: 9
Training loss: 3.746274241692635
Validation loss: 3.973037504447735

Epoch: 6| Step: 10
Training loss: 4.844708747731054
Validation loss: 3.9637327163396097

Epoch: 6| Step: 11
Training loss: 2.8838735555794246
Validation loss: 3.952541365465813

Epoch: 6| Step: 12
Training loss: 3.105504987013422
Validation loss: 3.940397260198296

Epoch: 6| Step: 13
Training loss: 3.972283179846154
Validation loss: 3.935170165554796

Epoch: 6| Step: 0
Training loss: 5.383098090890815
Validation loss: 3.9257965072901038

Epoch: 6| Step: 1
Training loss: 3.6181693340886025
Validation loss: 3.9159447487502446

Epoch: 6| Step: 2
Training loss: 3.6875636208428557
Validation loss: 3.906117582968567

Epoch: 6| Step: 3
Training loss: 4.17942441308401
Validation loss: 3.895381511507017

Epoch: 6| Step: 4
Training loss: 3.5795668982541935
Validation loss: 3.8864969539117182

Epoch: 6| Step: 5
Training loss: 4.038887300509969
Validation loss: 3.8789453206572375

Epoch: 6| Step: 6
Training loss: 4.073236217142292
Validation loss: 3.8674845303308145

Epoch: 6| Step: 7
Training loss: 3.5114115919097055
Validation loss: 3.8607969042353436

Epoch: 6| Step: 8
Training loss: 3.628818079736535
Validation loss: 3.85210090136767

Epoch: 6| Step: 9
Training loss: 3.843329305809361
Validation loss: 3.842686062109095

Epoch: 6| Step: 10
Training loss: 3.695068609403382
Validation loss: 3.8358653152203783

Epoch: 6| Step: 11
Training loss: 4.034688976075726
Validation loss: 3.827715990367663

Epoch: 6| Step: 12
Training loss: 4.784071943475721
Validation loss: 3.821610434492302

Epoch: 6| Step: 13
Training loss: 4.00830479622964
Validation loss: 3.812126452030705

Epoch: 7| Step: 0
Training loss: 3.6657375256632414
Validation loss: 3.804444332673225

Epoch: 6| Step: 1
Training loss: 4.115053148447877
Validation loss: 3.7986253931840457

Epoch: 6| Step: 2
Training loss: 3.5630048427586347
Validation loss: 3.7900610445826097

Epoch: 6| Step: 3
Training loss: 4.203741205701383
Validation loss: 3.7829069871395067

Epoch: 6| Step: 4
Training loss: 1.8447642365420798
Validation loss: 3.7703995460524062

Epoch: 6| Step: 5
Training loss: 4.720544941042853
Validation loss: 3.7621735499024136

Epoch: 6| Step: 6
Training loss: 2.8200670806535766
Validation loss: 3.7557596418639894

Epoch: 6| Step: 7
Training loss: 4.113396710897297
Validation loss: 3.7458888444210774

Epoch: 6| Step: 8
Training loss: 4.695948603698109
Validation loss: 3.73263362705133

Epoch: 6| Step: 9
Training loss: 3.766485472065344
Validation loss: 3.7229047773506383

Epoch: 6| Step: 10
Training loss: 4.598871606834914
Validation loss: 3.7131859508702307

Epoch: 6| Step: 11
Training loss: 3.768501544309798
Validation loss: 3.7025988435060095

Epoch: 6| Step: 12
Training loss: 3.6726666834783863
Validation loss: 3.690655528399323

Epoch: 6| Step: 13
Training loss: 4.75280518267814
Validation loss: 3.684781499926993

Epoch: 8| Step: 0
Training loss: 3.4831075373084706
Validation loss: 3.6756682488685013

Epoch: 6| Step: 1
Training loss: 4.020875103722005
Validation loss: 3.6665765708377394

Epoch: 6| Step: 2
Training loss: 5.149821765370904
Validation loss: 3.6582782127243125

Epoch: 6| Step: 3
Training loss: 3.8569877129087793
Validation loss: 3.6473409593743744

Epoch: 6| Step: 4
Training loss: 3.465309980434369
Validation loss: 3.6393848024804645

Epoch: 6| Step: 5
Training loss: 3.588537798447132
Validation loss: 3.631119344878802

Epoch: 6| Step: 6
Training loss: 3.5727237096941247
Validation loss: 3.622212405690254

Epoch: 6| Step: 7
Training loss: 4.263850139782866
Validation loss: 3.6150630443351113

Epoch: 6| Step: 8
Training loss: 3.4414636128696836
Validation loss: 3.6045477572767433

Epoch: 6| Step: 9
Training loss: 4.17585547357152
Validation loss: 3.5979165027646705

Epoch: 6| Step: 10
Training loss: 3.8845159528082864
Validation loss: 3.592262859915596

Epoch: 6| Step: 11
Training loss: 3.2584260138739722
Validation loss: 3.58011414962843

Epoch: 6| Step: 12
Training loss: 3.38922427729152
Validation loss: 3.57068813632466

Epoch: 6| Step: 13
Training loss: 3.2773808510172793
Validation loss: 3.563678511262015

Epoch: 9| Step: 0
Training loss: 4.916865630353663
Validation loss: 3.5597068243805845

Epoch: 6| Step: 1
Training loss: 4.239147466925147
Validation loss: 3.549499003675011

Epoch: 6| Step: 2
Training loss: 3.6111187046329833
Validation loss: 3.5406915213757753

Epoch: 6| Step: 3
Training loss: 3.688179212183714
Validation loss: 3.533683760716489

Epoch: 6| Step: 4
Training loss: 4.364675929044008
Validation loss: 3.523586106986927

Epoch: 6| Step: 5
Training loss: 3.692995018136295
Validation loss: 3.5155470593562237

Epoch: 6| Step: 6
Training loss: 3.664657186631817
Validation loss: 3.510285134618966

Epoch: 6| Step: 7
Training loss: 3.1490797424298624
Validation loss: 3.5030413157399547

Epoch: 6| Step: 8
Training loss: 3.201456668234631
Validation loss: 3.4990738333292226

Epoch: 6| Step: 9
Training loss: 2.9882333789057776
Validation loss: 3.491793805381678

Epoch: 6| Step: 10
Training loss: 3.4012240506506783
Validation loss: 3.4885659882657483

Epoch: 6| Step: 11
Training loss: 3.4409417695204416
Validation loss: 3.4822711918076403

Epoch: 6| Step: 12
Training loss: 3.8944435836735414
Validation loss: 3.4784234554713707

Epoch: 6| Step: 13
Training loss: 3.3456838844400782
Validation loss: 3.4761057187796274

Epoch: 10| Step: 0
Training loss: 3.2819236427179197
Validation loss: 3.4655903123381457

Epoch: 6| Step: 1
Training loss: 3.4929713109910794
Validation loss: 3.4576450517451827

Epoch: 6| Step: 2
Training loss: 4.616990241728036
Validation loss: 3.4553192462074818

Epoch: 6| Step: 3
Training loss: 2.9671760000414817
Validation loss: 3.449198728204666

Epoch: 6| Step: 4
Training loss: 4.0774933190586315
Validation loss: 3.442935776671579

Epoch: 6| Step: 5
Training loss: 2.2250416698197095
Validation loss: 3.439109659549723

Epoch: 6| Step: 6
Training loss: 3.191064375048414
Validation loss: 3.4354490558774953

Epoch: 6| Step: 7
Training loss: 3.565866719911495
Validation loss: 3.4304669547696274

Epoch: 6| Step: 8
Training loss: 3.514167449591657
Validation loss: 3.428496769141286

Epoch: 6| Step: 9
Training loss: 3.7197341257881233
Validation loss: 3.4201315836626014

Epoch: 6| Step: 10
Training loss: 3.499189282936461
Validation loss: 3.415120987478351

Epoch: 6| Step: 11
Training loss: 3.6805203865978124
Validation loss: 3.410364736996206

Epoch: 6| Step: 12
Training loss: 4.587808724391369
Validation loss: 3.4070035701666197

Epoch: 6| Step: 13
Training loss: 4.330752680246913
Validation loss: 3.401503773387317

Epoch: 11| Step: 0
Training loss: 3.885763048919874
Validation loss: 3.3969471142540923

Epoch: 6| Step: 1
Training loss: 3.5816145626471605
Validation loss: 3.391452484753424

Epoch: 6| Step: 2
Training loss: 3.4973713676787987
Validation loss: 3.3905164197398245

Epoch: 6| Step: 3
Training loss: 3.137144067035951
Validation loss: 3.3829026487658678

Epoch: 6| Step: 4
Training loss: 3.521765741584558
Validation loss: 3.3757618401651763

Epoch: 6| Step: 5
Training loss: 2.908032106760129
Validation loss: 3.37006929058513

Epoch: 6| Step: 6
Training loss: 4.243351841536855
Validation loss: 3.3633828799689143

Epoch: 6| Step: 7
Training loss: 3.1584449916081567
Validation loss: 3.3575751620705074

Epoch: 6| Step: 8
Training loss: 4.3594955372980575
Validation loss: 3.3555078721098726

Epoch: 6| Step: 9
Training loss: 3.691504163301309
Validation loss: 3.3532423548223083

Epoch: 6| Step: 10
Training loss: 3.422005707495794
Validation loss: 3.3443338679661037

Epoch: 6| Step: 11
Training loss: 3.335173400992077
Validation loss: 3.3381466727460958

Epoch: 6| Step: 12
Training loss: 3.9653839494988827
Validation loss: 3.3307939306149077

Epoch: 6| Step: 13
Training loss: 3.17197406783213
Validation loss: 3.3298754404645132

Epoch: 12| Step: 0
Training loss: 2.861519764806786
Validation loss: 3.320069296300593

Epoch: 6| Step: 1
Training loss: 3.874455936753852
Validation loss: 3.317458500245731

Epoch: 6| Step: 2
Training loss: 3.0017550421086505
Validation loss: 3.3068833805554454

Epoch: 6| Step: 3
Training loss: 4.0047364802347545
Validation loss: 3.298388279007203

Epoch: 6| Step: 4
Training loss: 3.932547103299022
Validation loss: 3.296827556900739

Epoch: 6| Step: 5
Training loss: 3.6739769945499026
Validation loss: 3.2899376572969277

Epoch: 6| Step: 6
Training loss: 3.793204334615459
Validation loss: 3.283182243838136

Epoch: 6| Step: 7
Training loss: 3.4236013856396754
Validation loss: 3.2756153172731217

Epoch: 6| Step: 8
Training loss: 3.687214209909799
Validation loss: 3.267741256368563

Epoch: 6| Step: 9
Training loss: 3.6016437910260537
Validation loss: 3.2631805969796948

Epoch: 6| Step: 10
Training loss: 4.10195589631251
Validation loss: 3.256910929067326

Epoch: 6| Step: 11
Training loss: 2.2038128367535426
Validation loss: 3.249978864489064

Epoch: 6| Step: 12
Training loss: 3.2633670867743323
Validation loss: 3.2431799747259618

Epoch: 6| Step: 13
Training loss: 3.468087072861102
Validation loss: 3.2354928541504013

Epoch: 13| Step: 0
Training loss: 3.018410774584198
Validation loss: 3.2378966289617495

Epoch: 6| Step: 1
Training loss: 3.367794964509216
Validation loss: 3.2349580866642347

Epoch: 6| Step: 2
Training loss: 3.3101245351914725
Validation loss: 3.2263005454303397

Epoch: 6| Step: 3
Training loss: 3.3141964580938463
Validation loss: 3.222019314933707

Epoch: 6| Step: 4
Training loss: 3.3838754441986465
Validation loss: 3.2175424160153336

Epoch: 6| Step: 5
Training loss: 3.1398627271835693
Validation loss: 3.2162247383263174

Epoch: 6| Step: 6
Training loss: 2.9645146726340714
Validation loss: 3.210052456085191

Epoch: 6| Step: 7
Training loss: 3.9286151734926245
Validation loss: 3.207018325577977

Epoch: 6| Step: 8
Training loss: 4.600164178323345
Validation loss: 3.206370905897073

Epoch: 6| Step: 9
Training loss: 3.4818709745916223
Validation loss: 3.202205745549719

Epoch: 6| Step: 10
Training loss: 2.9524735635450856
Validation loss: 3.2135303841682994

Epoch: 6| Step: 11
Training loss: 4.02770414321648
Validation loss: 3.2226298287689215

Epoch: 6| Step: 12
Training loss: 3.8475024507253277
Validation loss: 3.2096778876636707

Epoch: 6| Step: 13
Training loss: 2.206056092469949
Validation loss: 3.213964548569143

Epoch: 14| Step: 0
Training loss: 3.8214052349849923
Validation loss: 3.227692104975113

Epoch: 6| Step: 1
Training loss: 3.0597175881705736
Validation loss: 3.1910453557488516

Epoch: 6| Step: 2
Training loss: 3.3608026354203018
Validation loss: 3.1913743204712137

Epoch: 6| Step: 3
Training loss: 3.5213612869763202
Validation loss: 3.1851482929042803

Epoch: 6| Step: 4
Training loss: 3.4871447036951704
Validation loss: 3.1815192896448137

Epoch: 6| Step: 5
Training loss: 2.7685795750920623
Validation loss: 3.180132168820762

Epoch: 6| Step: 6
Training loss: 3.5354680888014807
Validation loss: 3.1746907801352693

Epoch: 6| Step: 7
Training loss: 3.742583506741251
Validation loss: 3.1642207272353273

Epoch: 6| Step: 8
Training loss: 3.1768373654733226
Validation loss: 3.156617032704621

Epoch: 6| Step: 9
Training loss: 3.432371996266132
Validation loss: 3.1530069450382405

Epoch: 6| Step: 10
Training loss: 2.9413303806201343
Validation loss: 3.152112559208055

Epoch: 6| Step: 11
Training loss: 4.1386377712139
Validation loss: 3.155425294655791

Epoch: 6| Step: 12
Training loss: 3.901189593306114
Validation loss: 3.1506210161631167

Epoch: 6| Step: 13
Training loss: 2.4333958430513296
Validation loss: 3.143809898274084

Epoch: 15| Step: 0
Training loss: 3.3038633504785353
Validation loss: 3.1359722422123046

Epoch: 6| Step: 1
Training loss: 3.3611309341672797
Validation loss: 3.13307926561303

Epoch: 6| Step: 2
Training loss: 3.1446922877048853
Validation loss: 3.1299730350706656

Epoch: 6| Step: 3
Training loss: 3.0017531358745857
Validation loss: 3.1295454901298085

Epoch: 6| Step: 4
Training loss: 3.656698737361714
Validation loss: 3.136962469237391

Epoch: 6| Step: 5
Training loss: 3.789417368208273
Validation loss: 3.119677302812979

Epoch: 6| Step: 6
Training loss: 3.9533624992345446
Validation loss: 3.1172608155076977

Epoch: 6| Step: 7
Training loss: 2.7685040504628486
Validation loss: 3.1164047957263414

Epoch: 6| Step: 8
Training loss: 3.874811598596967
Validation loss: 3.1170273014205634

Epoch: 6| Step: 9
Training loss: 2.7589343331497704
Validation loss: 3.113009190667277

Epoch: 6| Step: 10
Training loss: 3.089240284088778
Validation loss: 3.114157993599472

Epoch: 6| Step: 11
Training loss: 3.6107970239706675
Validation loss: 3.109863068153453

Epoch: 6| Step: 12
Training loss: 3.0189284183068734
Validation loss: 3.104328198939948

Epoch: 6| Step: 13
Training loss: 4.166634114456175
Validation loss: 3.1036052478339577

Epoch: 16| Step: 0
Training loss: 3.867830843346081
Validation loss: 3.1006745916702956

Epoch: 6| Step: 1
Training loss: 3.7504058618258864
Validation loss: 3.0980244865489133

Epoch: 6| Step: 2
Training loss: 3.1461230685637247
Validation loss: 3.0961985580754234

Epoch: 6| Step: 3
Training loss: 3.4675112050156636
Validation loss: 3.0958412504748436

Epoch: 6| Step: 4
Training loss: 2.0768184139637382
Validation loss: 3.0886090421083168

Epoch: 6| Step: 5
Training loss: 3.2411557681637233
Validation loss: 3.0890500873255684

Epoch: 6| Step: 6
Training loss: 3.3201447567921925
Validation loss: 3.085957647267965

Epoch: 6| Step: 7
Training loss: 3.2889502861833213
Validation loss: 3.0808869717262817

Epoch: 6| Step: 8
Training loss: 3.6314415098236155
Validation loss: 3.0830684211047465

Epoch: 6| Step: 9
Training loss: 3.4166720475565397
Validation loss: 3.0789525445997348

Epoch: 6| Step: 10
Training loss: 3.4524634922978423
Validation loss: 3.074694502373556

Epoch: 6| Step: 11
Training loss: 2.9479607532740726
Validation loss: 3.0693538016202737

Epoch: 6| Step: 12
Training loss: 3.4413517959564546
Validation loss: 3.0649135731530497

Epoch: 6| Step: 13
Training loss: 3.9148426001856724
Validation loss: 3.064374770513297

Epoch: 17| Step: 0
Training loss: 3.816570547856431
Validation loss: 3.0673911334606068

Epoch: 6| Step: 1
Training loss: 2.4954009669225052
Validation loss: 3.0626657611453205

Epoch: 6| Step: 2
Training loss: 2.4582190621752167
Validation loss: 3.060731780419088

Epoch: 6| Step: 3
Training loss: 3.17378064868337
Validation loss: 3.0681182502773257

Epoch: 6| Step: 4
Training loss: 3.624707703480233
Validation loss: 3.0897135127034154

Epoch: 6| Step: 5
Training loss: 2.9005048838500156
Validation loss: 3.077044795354559

Epoch: 6| Step: 6
Training loss: 3.4432607756728375
Validation loss: 3.072896872168696

Epoch: 6| Step: 7
Training loss: 3.885128811697739
Validation loss: 3.0651436052688017

Epoch: 6| Step: 8
Training loss: 3.411804430151953
Validation loss: 3.048640395322594

Epoch: 6| Step: 9
Training loss: 4.162727528445048
Validation loss: 3.052800861736551

Epoch: 6| Step: 10
Training loss: 3.0422124155334034
Validation loss: 3.0543183730325394

Epoch: 6| Step: 11
Training loss: 3.1714029195722646
Validation loss: 3.055927182105881

Epoch: 6| Step: 12
Training loss: 2.7328760888895274
Validation loss: 3.0499953277487553

Epoch: 6| Step: 13
Training loss: 4.27832510503184
Validation loss: 3.047897753667595

Epoch: 18| Step: 0
Training loss: 2.642095573897062
Validation loss: 3.0417026012510155

Epoch: 6| Step: 1
Training loss: 3.3548840689491595
Validation loss: 3.042610056433774

Epoch: 6| Step: 2
Training loss: 3.510109198412185
Validation loss: 3.050018382811359

Epoch: 6| Step: 3
Training loss: 2.5241469575807893
Validation loss: 3.058003751124135

Epoch: 6| Step: 4
Training loss: 3.6428056333944623
Validation loss: 3.0829562857672954

Epoch: 6| Step: 5
Training loss: 3.590335451142887
Validation loss: 3.061806724821379

Epoch: 6| Step: 6
Training loss: 3.3529084177454185
Validation loss: 3.049753404247824

Epoch: 6| Step: 7
Training loss: 2.661283503474265
Validation loss: 3.0365409197481905

Epoch: 6| Step: 8
Training loss: 3.3225674500518485
Validation loss: 3.045182631085258

Epoch: 6| Step: 9
Training loss: 3.7461585396264416
Validation loss: 3.0520585461700924

Epoch: 6| Step: 10
Training loss: 2.561472803183308
Validation loss: 3.0458931602259742

Epoch: 6| Step: 11
Training loss: 3.7200348501726466
Validation loss: 3.0371128257012

Epoch: 6| Step: 12
Training loss: 3.6075241826146383
Validation loss: 3.0341778016368455

Epoch: 6| Step: 13
Training loss: 4.415891663314319
Validation loss: 3.036799452616602

Epoch: 19| Step: 0
Training loss: 3.5798223875516526
Validation loss: 3.031142288390047

Epoch: 6| Step: 1
Training loss: 3.0281574952199786
Validation loss: 3.0263138518159804

Epoch: 6| Step: 2
Training loss: 2.7460888011990883
Validation loss: 3.0274212185636302

Epoch: 6| Step: 3
Training loss: 2.8785209656747512
Validation loss: 3.0341487632519075

Epoch: 6| Step: 4
Training loss: 2.887884046768174
Validation loss: 3.0476146909719044

Epoch: 6| Step: 5
Training loss: 3.2082674754595817
Validation loss: 3.068346516495754

Epoch: 6| Step: 6
Training loss: 3.976284294664076
Validation loss: 3.075398424936784

Epoch: 6| Step: 7
Training loss: 2.9747622996023972
Validation loss: 3.0249800947607848

Epoch: 6| Step: 8
Training loss: 3.7777673746102898
Validation loss: 3.0202620619936305

Epoch: 6| Step: 9
Training loss: 4.01184878189641
Validation loss: 3.0200259195057706

Epoch: 6| Step: 10
Training loss: 2.886767148243216
Validation loss: 3.022668188893136

Epoch: 6| Step: 11
Training loss: 3.657722763401268
Validation loss: 3.021310573527653

Epoch: 6| Step: 12
Training loss: 3.3261642769566038
Validation loss: 3.0205851491462625

Epoch: 6| Step: 13
Training loss: 2.9431950979579242
Validation loss: 3.020481789868922

Epoch: 20| Step: 0
Training loss: 2.4372553580343883
Validation loss: 3.018761986273218

Epoch: 6| Step: 1
Training loss: 2.6933348546008102
Validation loss: 3.021911644761407

Epoch: 6| Step: 2
Training loss: 3.6841982267647704
Validation loss: 3.0244688302816476

Epoch: 6| Step: 3
Training loss: 3.2655633801939103
Validation loss: 3.0210218128192783

Epoch: 6| Step: 4
Training loss: 3.302529787193492
Validation loss: 3.0100239399871076

Epoch: 6| Step: 5
Training loss: 3.803325934262201
Validation loss: 3.0062671046810476

Epoch: 6| Step: 6
Training loss: 3.115866933476356
Validation loss: 3.0071153996096203

Epoch: 6| Step: 7
Training loss: 3.054875126610672
Validation loss: 3.0061512414743015

Epoch: 6| Step: 8
Training loss: 3.0052772835810835
Validation loss: 3.0070946576082376

Epoch: 6| Step: 9
Training loss: 2.9794763435235074
Validation loss: 3.010840906844512

Epoch: 6| Step: 10
Training loss: 3.816830286464011
Validation loss: 3.0122006323695807

Epoch: 6| Step: 11
Training loss: 3.6121363790118797
Validation loss: 3.009662058551382

Epoch: 6| Step: 12
Training loss: 4.010356133074333
Validation loss: 3.002704025554849

Epoch: 6| Step: 13
Training loss: 2.871964884317517
Validation loss: 3.001826979354527

Epoch: 21| Step: 0
Training loss: 2.749733305050031
Validation loss: 3.006137948877981

Epoch: 6| Step: 1
Training loss: 3.118232570986368
Validation loss: 3.014150148444823

Epoch: 6| Step: 2
Training loss: 2.9657285071298976
Validation loss: 2.9982554352064126

Epoch: 6| Step: 3
Training loss: 4.247255673445529
Validation loss: 2.986598984900266

Epoch: 6| Step: 4
Training loss: 2.3375655914732527
Validation loss: 2.985938937797717

Epoch: 6| Step: 5
Training loss: 3.6715126670464078
Validation loss: 2.9892602884414923

Epoch: 6| Step: 6
Training loss: 2.8021288068028833
Validation loss: 2.993659011780648

Epoch: 6| Step: 7
Training loss: 3.2112814169149124
Validation loss: 3.000110658361699

Epoch: 6| Step: 8
Training loss: 3.6673469056964314
Validation loss: 3.0040881927000136

Epoch: 6| Step: 9
Training loss: 3.6714544826524103
Validation loss: 3.0021746984243816

Epoch: 6| Step: 10
Training loss: 3.6005421018402246
Validation loss: 2.999600799210997

Epoch: 6| Step: 11
Training loss: 3.2088937311262167
Validation loss: 2.9942651183932854

Epoch: 6| Step: 12
Training loss: 3.058177934348688
Validation loss: 2.9974980534887403

Epoch: 6| Step: 13
Training loss: 3.3862156477798404
Validation loss: 2.989640340439825

Epoch: 22| Step: 0
Training loss: 3.142896144179076
Validation loss: 2.988908101826344

Epoch: 6| Step: 1
Training loss: 3.533977164384155
Validation loss: 2.987902740285397

Epoch: 6| Step: 2
Training loss: 3.6377379139703434
Validation loss: 2.98616501502832

Epoch: 6| Step: 3
Training loss: 3.0653473987939717
Validation loss: 2.9829488648725118

Epoch: 6| Step: 4
Training loss: 3.3869538715060705
Validation loss: 2.980677053071126

Epoch: 6| Step: 5
Training loss: 2.659412072681979
Validation loss: 2.9815445513137706

Epoch: 6| Step: 6
Training loss: 2.7711236462245408
Validation loss: 2.978435004568945

Epoch: 6| Step: 7
Training loss: 3.3591494462343037
Validation loss: 2.9750324847601375

Epoch: 6| Step: 8
Training loss: 3.3674248348419815
Validation loss: 2.974619084055141

Epoch: 6| Step: 9
Training loss: 3.144402201593063
Validation loss: 2.9693785610263914

Epoch: 6| Step: 10
Training loss: 3.025555797621568
Validation loss: 2.9714056730634697

Epoch: 6| Step: 11
Training loss: 3.202989082243978
Validation loss: 2.9738850886347508

Epoch: 6| Step: 12
Training loss: 3.7632711184291816
Validation loss: 2.9742824176072684

Epoch: 6| Step: 13
Training loss: 3.8067739041573043
Validation loss: 2.9772007074205002

Epoch: 23| Step: 0
Training loss: 3.535236640142586
Validation loss: 2.982826193953284

Epoch: 6| Step: 1
Training loss: 2.804603681666674
Validation loss: 2.9842597893229836

Epoch: 6| Step: 2
Training loss: 3.2766263810944602
Validation loss: 2.975319540377398

Epoch: 6| Step: 3
Training loss: 3.8796551952330667
Validation loss: 2.9727606425781943

Epoch: 6| Step: 4
Training loss: 4.042958371061557
Validation loss: 2.970583151881541

Epoch: 6| Step: 5
Training loss: 3.211333684309748
Validation loss: 2.9685242079667

Epoch: 6| Step: 6
Training loss: 2.766610955822608
Validation loss: 2.9685269611470626

Epoch: 6| Step: 7
Training loss: 3.1696971313005293
Validation loss: 2.9684904856181116

Epoch: 6| Step: 8
Training loss: 3.6226430662769595
Validation loss: 2.9678563550245776

Epoch: 6| Step: 9
Training loss: 3.000771264434782
Validation loss: 2.9658026787869196

Epoch: 6| Step: 10
Training loss: 2.9332107720635436
Validation loss: 2.967157215753836

Epoch: 6| Step: 11
Training loss: 3.438311394384019
Validation loss: 2.974613978951629

Epoch: 6| Step: 12
Training loss: 3.09996410472146
Validation loss: 2.9791789569137976

Epoch: 6| Step: 13
Training loss: 1.8718046299311892
Validation loss: 2.9881524612863584

Epoch: 24| Step: 0
Training loss: 3.570626209592022
Validation loss: 2.9994728640460075

Epoch: 6| Step: 1
Training loss: 3.2617058850794196
Validation loss: 2.972690171737643

Epoch: 6| Step: 2
Training loss: 3.441752352506125
Validation loss: 2.979485329875246

Epoch: 6| Step: 3
Training loss: 3.155153896247977
Validation loss: 2.992104336537575

Epoch: 6| Step: 4
Training loss: 2.610368276900051
Validation loss: 2.989649493466657

Epoch: 6| Step: 5
Training loss: 3.0791347028822322
Validation loss: 2.97880837021095

Epoch: 6| Step: 6
Training loss: 3.1251504480386183
Validation loss: 2.973427961299474

Epoch: 6| Step: 7
Training loss: 3.433832049644539
Validation loss: 2.974584902059264

Epoch: 6| Step: 8
Training loss: 3.7838337795533596
Validation loss: 2.9678937073211515

Epoch: 6| Step: 9
Training loss: 3.0065680765818517
Validation loss: 2.9601811783906964

Epoch: 6| Step: 10
Training loss: 3.678109188904725
Validation loss: 2.9555400039591024

Epoch: 6| Step: 11
Training loss: 3.214118662534952
Validation loss: 2.9537003071734733

Epoch: 6| Step: 12
Training loss: 3.153253776105862
Validation loss: 2.9542748671033383

Epoch: 6| Step: 13
Training loss: 2.9409895927299536
Validation loss: 2.956191408153007

Epoch: 25| Step: 0
Training loss: 2.685253179963284
Validation loss: 2.9603341442676214

Epoch: 6| Step: 1
Training loss: 3.7223185879456926
Validation loss: 2.9654102410326084

Epoch: 6| Step: 2
Training loss: 2.2268599462094016
Validation loss: 2.9676984840763803

Epoch: 6| Step: 3
Training loss: 3.434612379122893
Validation loss: 2.9647075987087725

Epoch: 6| Step: 4
Training loss: 3.1808701923630998
Validation loss: 2.9554400186004495

Epoch: 6| Step: 5
Training loss: 3.21813425637294
Validation loss: 2.956343151377441

Epoch: 6| Step: 6
Training loss: 3.1394825845579515
Validation loss: 2.9571570559865306

Epoch: 6| Step: 7
Training loss: 3.8296316490629856
Validation loss: 2.9545528798863736

Epoch: 6| Step: 8
Training loss: 3.0664409271028883
Validation loss: 2.951493747174712

Epoch: 6| Step: 9
Training loss: 4.030904119276323
Validation loss: 2.9516449615039373

Epoch: 6| Step: 10
Training loss: 3.176399499226526
Validation loss: 2.9501007093477543

Epoch: 6| Step: 11
Training loss: 3.569965103577243
Validation loss: 2.9478212975474247

Epoch: 6| Step: 12
Training loss: 3.091426246391371
Validation loss: 2.9440581215391797

Epoch: 6| Step: 13
Training loss: 2.183587417183907
Validation loss: 2.9463970839645968

Epoch: 26| Step: 0
Training loss: 3.366379643156052
Validation loss: 2.9453401250635265

Epoch: 6| Step: 1
Training loss: 2.998877315259419
Validation loss: 2.9461036503683817

Epoch: 6| Step: 2
Training loss: 3.0205673276043394
Validation loss: 2.9470564374392336

Epoch: 6| Step: 3
Training loss: 3.354233324482416
Validation loss: 2.9569689163411472

Epoch: 6| Step: 4
Training loss: 2.8451427360891235
Validation loss: 2.9532491338079874

Epoch: 6| Step: 5
Training loss: 3.2491634466000887
Validation loss: 2.963421681602794

Epoch: 6| Step: 6
Training loss: 3.1009880706252573
Validation loss: 2.952124901207502

Epoch: 6| Step: 7
Training loss: 2.9575726959503554
Validation loss: 2.944689779308278

Epoch: 6| Step: 8
Training loss: 3.4062497200222075
Validation loss: 2.943828653002814

Epoch: 6| Step: 9
Training loss: 2.5914667029886713
Validation loss: 2.9397898947047008

Epoch: 6| Step: 10
Training loss: 3.8686646385820818
Validation loss: 2.9406632493000364

Epoch: 6| Step: 11
Training loss: 2.811760529687077
Validation loss: 2.9409442416697558

Epoch: 6| Step: 12
Training loss: 4.023065109056041
Validation loss: 2.939268499246657

Epoch: 6| Step: 13
Training loss: 3.664688544889249
Validation loss: 2.9386178488039394

Epoch: 27| Step: 0
Training loss: 3.902158990558644
Validation loss: 2.93408234710894

Epoch: 6| Step: 1
Training loss: 3.411417549801941
Validation loss: 2.9371427477169827

Epoch: 6| Step: 2
Training loss: 2.8617882055986628
Validation loss: 2.933879376047233

Epoch: 6| Step: 3
Training loss: 2.8982542242215006
Validation loss: 2.9379527612075846

Epoch: 6| Step: 4
Training loss: 2.8186452909589597
Validation loss: 2.936623443610967

Epoch: 6| Step: 5
Training loss: 3.8003772548330956
Validation loss: 2.9369866597450627

Epoch: 6| Step: 6
Training loss: 2.8443069750958845
Validation loss: 2.939045852117054

Epoch: 6| Step: 7
Training loss: 2.979019552657751
Validation loss: 2.9406965131288243

Epoch: 6| Step: 8
Training loss: 3.064485801391273
Validation loss: 2.946836543195193

Epoch: 6| Step: 9
Training loss: 2.9862799032445806
Validation loss: 2.955635876321956

Epoch: 6| Step: 10
Training loss: 3.274945405694318
Validation loss: 2.9460934727248826

Epoch: 6| Step: 11
Training loss: 3.097055230155383
Validation loss: 2.9355203245280155

Epoch: 6| Step: 12
Training loss: 3.76646458300315
Validation loss: 2.9350080425623726

Epoch: 6| Step: 13
Training loss: 3.290527742258193
Validation loss: 2.930782758629378

Epoch: 28| Step: 0
Training loss: 2.549423347046508
Validation loss: 2.9295858062267413

Epoch: 6| Step: 1
Training loss: 2.561024124514491
Validation loss: 2.9304054488591276

Epoch: 6| Step: 2
Training loss: 3.3674389951032797
Validation loss: 2.9323246244633188

Epoch: 6| Step: 3
Training loss: 2.9278540812648433
Validation loss: 2.9348406163530365

Epoch: 6| Step: 4
Training loss: 3.844799115671476
Validation loss: 2.934245505768195

Epoch: 6| Step: 5
Training loss: 3.199887458491201
Validation loss: 2.9388196193916944

Epoch: 6| Step: 6
Training loss: 3.455128084450134
Validation loss: 2.930940307081097

Epoch: 6| Step: 7
Training loss: 3.3316020443176675
Validation loss: 2.928802134189223

Epoch: 6| Step: 8
Training loss: 2.612217525561068
Validation loss: 2.9291275935412227

Epoch: 6| Step: 9
Training loss: 3.477337765779576
Validation loss: 2.927792147390306

Epoch: 6| Step: 10
Training loss: 2.8621290941107076
Validation loss: 2.9278481814393986

Epoch: 6| Step: 11
Training loss: 4.0266910767815345
Validation loss: 2.927531244046021

Epoch: 6| Step: 12
Training loss: 3.0352869582537516
Validation loss: 2.927850505296076

Epoch: 6| Step: 13
Training loss: 3.7770836946740096
Validation loss: 2.925783128624302

Epoch: 29| Step: 0
Training loss: 3.050914414707358
Validation loss: 2.9272062990852903

Epoch: 6| Step: 1
Training loss: 3.286373824510643
Validation loss: 2.9253989160883833

Epoch: 6| Step: 2
Training loss: 2.8064737821190633
Validation loss: 2.9246749127929887

Epoch: 6| Step: 3
Training loss: 3.2844995302643354
Validation loss: 2.9226263717722905

Epoch: 6| Step: 4
Training loss: 3.3661551253713733
Validation loss: 2.921499438209611

Epoch: 6| Step: 5
Training loss: 2.4158180544596934
Validation loss: 2.921715760620162

Epoch: 6| Step: 6
Training loss: 2.2020481805753467
Validation loss: 2.9229462915515714

Epoch: 6| Step: 7
Training loss: 3.834081383292605
Validation loss: 2.9214402698437656

Epoch: 6| Step: 8
Training loss: 3.844579219538229
Validation loss: 2.9249086493177057

Epoch: 6| Step: 9
Training loss: 3.066545267051822
Validation loss: 2.925310565779721

Epoch: 6| Step: 10
Training loss: 3.6291745582491846
Validation loss: 2.929330317118102

Epoch: 6| Step: 11
Training loss: 3.153628629873253
Validation loss: 2.942435461764294

Epoch: 6| Step: 12
Training loss: 3.471057845811522
Validation loss: 2.937453287696206

Epoch: 6| Step: 13
Training loss: 3.2953664211819476
Validation loss: 2.9258795011338115

Epoch: 30| Step: 0
Training loss: 3.7696337117713243
Validation loss: 2.917255245245366

Epoch: 6| Step: 1
Training loss: 3.148191380879201
Validation loss: 2.915396115370131

Epoch: 6| Step: 2
Training loss: 2.8332843402291785
Validation loss: 2.916341201507172

Epoch: 6| Step: 3
Training loss: 3.5817277253492
Validation loss: 2.91764686626541

Epoch: 6| Step: 4
Training loss: 3.5050508294657687
Validation loss: 2.9157205740690735

Epoch: 6| Step: 5
Training loss: 2.678738261885565
Validation loss: 2.9149869350797073

Epoch: 6| Step: 6
Training loss: 3.059382973836886
Validation loss: 2.9144499821152148

Epoch: 6| Step: 7
Training loss: 3.109970879127095
Validation loss: 2.914602187734708

Epoch: 6| Step: 8
Training loss: 4.101039308148902
Validation loss: 2.9143265426381406

Epoch: 6| Step: 9
Training loss: 2.9675687347139013
Validation loss: 2.913694413065958

Epoch: 6| Step: 10
Training loss: 2.805761785030215
Validation loss: 2.912868201465717

Epoch: 6| Step: 11
Training loss: 3.2499358831096545
Validation loss: 2.9155819134082392

Epoch: 6| Step: 12
Training loss: 3.102895762417223
Validation loss: 2.9152325428340617

Epoch: 6| Step: 13
Training loss: 2.364346451734463
Validation loss: 2.9215733761415215

Epoch: 31| Step: 0
Training loss: 3.1742384049719896
Validation loss: 2.9325562896136383

Epoch: 6| Step: 1
Training loss: 3.2833300582430494
Validation loss: 2.927132922080095

Epoch: 6| Step: 2
Training loss: 3.404101753005044
Validation loss: 2.9183865575728096

Epoch: 6| Step: 3
Training loss: 3.5046888007043813
Validation loss: 2.9116266421251327

Epoch: 6| Step: 4
Training loss: 3.251563503076416
Validation loss: 2.915791040525221

Epoch: 6| Step: 5
Training loss: 4.0009111320391275
Validation loss: 2.917637283505067

Epoch: 6| Step: 6
Training loss: 3.565015473619776
Validation loss: 2.9132279676835635

Epoch: 6| Step: 7
Training loss: 3.1085679430200766
Validation loss: 2.910587642365225

Epoch: 6| Step: 8
Training loss: 2.636562676225715
Validation loss: 2.9088443516475073

Epoch: 6| Step: 9
Training loss: 2.957364062347689
Validation loss: 2.91030727252556

Epoch: 6| Step: 10
Training loss: 2.620558659928167
Validation loss: 2.907745937828185

Epoch: 6| Step: 11
Training loss: 2.976297842359791
Validation loss: 2.905311051722656

Epoch: 6| Step: 12
Training loss: 3.191562382626996
Validation loss: 2.9073615372696864

Epoch: 6| Step: 13
Training loss: 2.8460506313428424
Validation loss: 2.906528757244791

Epoch: 32| Step: 0
Training loss: 3.132724675115208
Validation loss: 2.9046709161704114

Epoch: 6| Step: 1
Training loss: 3.0753427702122695
Validation loss: 2.905864379930201

Epoch: 6| Step: 2
Training loss: 2.472097999747426
Validation loss: 2.905710063224729

Epoch: 6| Step: 3
Training loss: 3.749705493806574
Validation loss: 2.904490899682777

Epoch: 6| Step: 4
Training loss: 3.6865289993749433
Validation loss: 2.9037024395854565

Epoch: 6| Step: 5
Training loss: 3.0450571750728903
Validation loss: 2.9044952670176274

Epoch: 6| Step: 6
Training loss: 2.7344371679595785
Validation loss: 2.908496589520028

Epoch: 6| Step: 7
Training loss: 3.092412023503322
Validation loss: 2.909318972284554

Epoch: 6| Step: 8
Training loss: 3.556206883603205
Validation loss: 2.914093196005296

Epoch: 6| Step: 9
Training loss: 3.135832512908052
Validation loss: 2.9061084844735894

Epoch: 6| Step: 10
Training loss: 3.737165485836863
Validation loss: 2.9026621763647866

Epoch: 6| Step: 11
Training loss: 3.719117731457214
Validation loss: 2.902908660857803

Epoch: 6| Step: 12
Training loss: 2.4133665198824548
Validation loss: 2.9018414249726945

Epoch: 6| Step: 13
Training loss: 2.6894447032876947
Validation loss: 2.899827049205613

Epoch: 33| Step: 0
Training loss: 3.2057781861330525
Validation loss: 2.900913247097449

Epoch: 6| Step: 1
Training loss: 3.522365635406783
Validation loss: 2.901293680097333

Epoch: 6| Step: 2
Training loss: 2.736978392354394
Validation loss: 2.9003858307498116

Epoch: 6| Step: 3
Training loss: 3.1705520952965367
Validation loss: 2.9024286330187214

Epoch: 6| Step: 4
Training loss: 2.067761962605121
Validation loss: 2.900764798676592

Epoch: 6| Step: 5
Training loss: 3.0487452317967336
Validation loss: 2.9060203575310637

Epoch: 6| Step: 6
Training loss: 3.047768016918074
Validation loss: 2.9040190458476305

Epoch: 6| Step: 7
Training loss: 3.366061772559953
Validation loss: 2.899816069960029

Epoch: 6| Step: 8
Training loss: 4.031066180629177
Validation loss: 2.901789616173437

Epoch: 6| Step: 9
Training loss: 3.2993906556712056
Validation loss: 2.9000886071190077

Epoch: 6| Step: 10
Training loss: 3.577745709035301
Validation loss: 2.897273849972052

Epoch: 6| Step: 11
Training loss: 3.4436102920135605
Validation loss: 2.8979815180887303

Epoch: 6| Step: 12
Training loss: 2.6939029269609764
Validation loss: 2.8975865853855405

Epoch: 6| Step: 13
Training loss: 3.1027854218858866
Validation loss: 2.8978710363438345

Epoch: 34| Step: 0
Training loss: 3.1789633936326855
Validation loss: 2.89876334658409

Epoch: 6| Step: 1
Training loss: 2.501935495735851
Validation loss: 2.8998235792415965

Epoch: 6| Step: 2
Training loss: 2.6549263741724762
Validation loss: 2.8979050841866383

Epoch: 6| Step: 3
Training loss: 2.9466344158714937
Validation loss: 2.897195485197358

Epoch: 6| Step: 4
Training loss: 3.5709102472473995
Validation loss: 2.891736802922065

Epoch: 6| Step: 5
Training loss: 3.251025111579892
Validation loss: 2.8912665819430905

Epoch: 6| Step: 6
Training loss: 3.06564605425683
Validation loss: 2.8883779548272526

Epoch: 6| Step: 7
Training loss: 3.37544756147009
Validation loss: 2.8922755643238287

Epoch: 6| Step: 8
Training loss: 3.1342216233582096
Validation loss: 2.901416642911128

Epoch: 6| Step: 9
Training loss: 2.790277980232474
Validation loss: 2.916651910020851

Epoch: 6| Step: 10
Training loss: 4.3166645231695755
Validation loss: 2.9234015277510608

Epoch: 6| Step: 11
Training loss: 2.9953548708979882
Validation loss: 2.896831163185601

Epoch: 6| Step: 12
Training loss: 3.3618383557857343
Validation loss: 2.890032043214101

Epoch: 6| Step: 13
Training loss: 3.32498751759875
Validation loss: 2.8908450693902354

Epoch: 35| Step: 0
Training loss: 3.111727184271773
Validation loss: 2.895091066969315

Epoch: 6| Step: 1
Training loss: 3.455361448998512
Validation loss: 2.894639949753944

Epoch: 6| Step: 2
Training loss: 3.226462448083666
Validation loss: 2.891891561199715

Epoch: 6| Step: 3
Training loss: 2.7317050650758468
Validation loss: 2.8921028986460384

Epoch: 6| Step: 4
Training loss: 3.1368382337338114
Validation loss: 2.889998802996376

Epoch: 6| Step: 5
Training loss: 3.3875104953279527
Validation loss: 2.8888312710168966

Epoch: 6| Step: 6
Training loss: 3.021504733134793
Validation loss: 2.8894262611408355

Epoch: 6| Step: 7
Training loss: 3.5816457160300277
Validation loss: 2.8830637030496735

Epoch: 6| Step: 8
Training loss: 2.605867232429645
Validation loss: 2.8762155560663842

Epoch: 6| Step: 9
Training loss: 3.407663034749539
Validation loss: 2.873202262541133

Epoch: 6| Step: 10
Training loss: 3.3616074352376453
Validation loss: 2.8773165888985033

Epoch: 6| Step: 11
Training loss: 3.0021832786793246
Validation loss: 2.8763097300608624

Epoch: 6| Step: 12
Training loss: 3.633748251878799
Validation loss: 2.876565799318105

Epoch: 6| Step: 13
Training loss: 2.40767449163547
Validation loss: 2.8734214161972407

Epoch: 36| Step: 0
Training loss: 3.9513372065168637
Validation loss: 2.8736303927339075

Epoch: 6| Step: 1
Training loss: 3.2150255895756064
Validation loss: 2.8696042754842153

Epoch: 6| Step: 2
Training loss: 2.9733754314413154
Validation loss: 2.8657404204729353

Epoch: 6| Step: 3
Training loss: 3.815719870747726
Validation loss: 2.86391595906481

Epoch: 6| Step: 4
Training loss: 2.3632850836100103
Validation loss: 2.8619510991475337

Epoch: 6| Step: 5
Training loss: 3.074555626991777
Validation loss: 2.8601219115780596

Epoch: 6| Step: 6
Training loss: 2.785779714689303
Validation loss: 2.8597227562337046

Epoch: 6| Step: 7
Training loss: 3.5514134346810713
Validation loss: 2.8600344830663014

Epoch: 6| Step: 8
Training loss: 3.049041916501238
Validation loss: 2.855539197723144

Epoch: 6| Step: 9
Training loss: 3.13530557801068
Validation loss: 2.8566724204430263

Epoch: 6| Step: 10
Training loss: 3.1463369172752746
Validation loss: 2.8564126821483717

Epoch: 6| Step: 11
Training loss: 3.2208316330866174
Validation loss: 2.8576470474055395

Epoch: 6| Step: 12
Training loss: 2.9809435544970753
Validation loss: 2.8615731663255795

Epoch: 6| Step: 13
Training loss: 2.649757528908186
Validation loss: 2.8676919528293743

Epoch: 37| Step: 0
Training loss: 3.5281804339748013
Validation loss: 2.8776636183868876

Epoch: 6| Step: 1
Training loss: 4.003150176327203
Validation loss: 2.8778393436017073

Epoch: 6| Step: 2
Training loss: 3.401600034872003
Validation loss: 2.862822942432784

Epoch: 6| Step: 3
Training loss: 2.1521855623301045
Validation loss: 2.8546313548345066

Epoch: 6| Step: 4
Training loss: 3.285803695907525
Validation loss: 2.8486511463192037

Epoch: 6| Step: 5
Training loss: 2.696390218471005
Validation loss: 2.8489458148658247

Epoch: 6| Step: 6
Training loss: 2.800721065454522
Validation loss: 2.851112289501467

Epoch: 6| Step: 7
Training loss: 2.801110837476469
Validation loss: 2.853568381225503

Epoch: 6| Step: 8
Training loss: 3.205980172803351
Validation loss: 2.856132452524123

Epoch: 6| Step: 9
Training loss: 2.794691032297384
Validation loss: 2.8558825036024205

Epoch: 6| Step: 10
Training loss: 3.400344629212179
Validation loss: 2.8549611604325618

Epoch: 6| Step: 11
Training loss: 3.6509355574066134
Validation loss: 2.8518219285188326

Epoch: 6| Step: 12
Training loss: 2.847444084228025
Validation loss: 2.847836021520585

Epoch: 6| Step: 13
Training loss: 3.397301916056018
Validation loss: 2.8459778120619714

Epoch: 38| Step: 0
Training loss: 2.806154340375247
Validation loss: 2.845122864070997

Epoch: 6| Step: 1
Training loss: 3.6696929291778635
Validation loss: 2.8474007897081677

Epoch: 6| Step: 2
Training loss: 2.84873994109925
Validation loss: 2.8488360996250894

Epoch: 6| Step: 3
Training loss: 3.067148845193891
Validation loss: 2.854878160792604

Epoch: 6| Step: 4
Training loss: 3.465461065269304
Validation loss: 2.853619754764488

Epoch: 6| Step: 5
Training loss: 3.7453016730555073
Validation loss: 2.8605996843395176

Epoch: 6| Step: 6
Training loss: 2.7473853425945047
Validation loss: 2.8615376827861803

Epoch: 6| Step: 7
Training loss: 2.624259026716025
Validation loss: 2.857696874583089

Epoch: 6| Step: 8
Training loss: 3.4442919129948013
Validation loss: 2.860222403827352

Epoch: 6| Step: 9
Training loss: 3.0939713215895135
Validation loss: 2.8614629801970817

Epoch: 6| Step: 10
Training loss: 2.580409846613802
Validation loss: 2.85301325910254

Epoch: 6| Step: 11
Training loss: 3.0284667460968357
Validation loss: 2.846037543106226

Epoch: 6| Step: 12
Training loss: 3.175969079575774
Validation loss: 2.841972497823779

Epoch: 6| Step: 13
Training loss: 3.8812809155103656
Validation loss: 2.8393617334819514

Epoch: 39| Step: 0
Training loss: 3.222255982481557
Validation loss: 2.838790683636961

Epoch: 6| Step: 1
Training loss: 2.2711039623953395
Validation loss: 2.840372724447356

Epoch: 6| Step: 2
Training loss: 2.7700206932093674
Validation loss: 2.840853527133537

Epoch: 6| Step: 3
Training loss: 3.442027076033958
Validation loss: 2.8397185191416683

Epoch: 6| Step: 4
Training loss: 2.6255154784746484
Validation loss: 2.839344296753341

Epoch: 6| Step: 5
Training loss: 3.807338785627047
Validation loss: 2.8397517863839767

Epoch: 6| Step: 6
Training loss: 3.552229549199015
Validation loss: 2.8389049212173467

Epoch: 6| Step: 7
Training loss: 3.403958450978262
Validation loss: 2.839065840838568

Epoch: 6| Step: 8
Training loss: 3.5463369356296
Validation loss: 2.8368222795388442

Epoch: 6| Step: 9
Training loss: 3.604026894624641
Validation loss: 2.836426430650241

Epoch: 6| Step: 10
Training loss: 2.9985181009453283
Validation loss: 2.8363428949572294

Epoch: 6| Step: 11
Training loss: 2.8422012303604234
Validation loss: 2.833368651033028

Epoch: 6| Step: 12
Training loss: 2.4783064902039875
Validation loss: 2.834811317965376

Epoch: 6| Step: 13
Training loss: 2.9778164202363775
Validation loss: 2.8357054903826486

Epoch: 40| Step: 0
Training loss: 3.7584470344029857
Validation loss: 2.8349180157233174

Epoch: 6| Step: 1
Training loss: 3.5959000499867386
Validation loss: 2.835743537384611

Epoch: 6| Step: 2
Training loss: 2.7521378270389283
Validation loss: 2.83800046890123

Epoch: 6| Step: 3
Training loss: 3.0764564600504163
Validation loss: 2.8383417404378153

Epoch: 6| Step: 4
Training loss: 3.8631418972512956
Validation loss: 2.839888328758331

Epoch: 6| Step: 5
Training loss: 2.5374574253663598
Validation loss: 2.8372583335248582

Epoch: 6| Step: 6
Training loss: 3.055706976018973
Validation loss: 2.849703667171811

Epoch: 6| Step: 7
Training loss: 3.6461977240705936
Validation loss: 2.863598163301231

Epoch: 6| Step: 8
Training loss: 2.863814113104072
Validation loss: 2.855204006052812

Epoch: 6| Step: 9
Training loss: 2.6584937100080457
Validation loss: 2.8351347846671757

Epoch: 6| Step: 10
Training loss: 3.652715947571086
Validation loss: 2.8330939449348542

Epoch: 6| Step: 11
Training loss: 2.228390234613257
Validation loss: 2.830507983997977

Epoch: 6| Step: 12
Training loss: 2.7590923851504
Validation loss: 2.8270633934724514

Epoch: 6| Step: 13
Training loss: 3.0679691292354776
Validation loss: 2.8316211871738863

Epoch: 41| Step: 0
Training loss: 3.0493573371577387
Validation loss: 2.832879740136682

Epoch: 6| Step: 1
Training loss: 3.3529384251830288
Validation loss: 2.8333816819767836

Epoch: 6| Step: 2
Training loss: 2.478034030548244
Validation loss: 2.8309596754700492

Epoch: 6| Step: 3
Training loss: 2.4597383998935016
Validation loss: 2.830674512471597

Epoch: 6| Step: 4
Training loss: 3.459578477618025
Validation loss: 2.8282776445054316

Epoch: 6| Step: 5
Training loss: 3.4912744476303716
Validation loss: 2.83007940044366

Epoch: 6| Step: 6
Training loss: 3.7527149544994916
Validation loss: 2.832234937608136

Epoch: 6| Step: 7
Training loss: 2.9608302436667193
Validation loss: 2.8277600218939383

Epoch: 6| Step: 8
Training loss: 3.186544985848839
Validation loss: 2.8245261584169223

Epoch: 6| Step: 9
Training loss: 2.275963916512645
Validation loss: 2.825312235771499

Epoch: 6| Step: 10
Training loss: 3.373460771869995
Validation loss: 2.826649463737718

Epoch: 6| Step: 11
Training loss: 3.1525205730399195
Validation loss: 2.827431986765543

Epoch: 6| Step: 12
Training loss: 3.2966686021460343
Validation loss: 2.830763948117834

Epoch: 6| Step: 13
Training loss: 3.382017116997353
Validation loss: 2.835094751896903

Epoch: 42| Step: 0
Training loss: 3.713157359279036
Validation loss: 2.8383600142804717

Epoch: 6| Step: 1
Training loss: 3.5970462443454854
Validation loss: 2.833931599766443

Epoch: 6| Step: 2
Training loss: 3.08542275300457
Validation loss: 2.828522896173107

Epoch: 6| Step: 3
Training loss: 3.1129822629330763
Validation loss: 2.827647558030262

Epoch: 6| Step: 4
Training loss: 3.3310293500300654
Validation loss: 2.82416754968234

Epoch: 6| Step: 5
Training loss: 2.8745287633396694
Validation loss: 2.820467216141444

Epoch: 6| Step: 6
Training loss: 2.816997577106922
Validation loss: 2.8208376410581946

Epoch: 6| Step: 7
Training loss: 3.2408163457457793
Validation loss: 2.816260904423445

Epoch: 6| Step: 8
Training loss: 2.9407908085809136
Validation loss: 2.817050770601027

Epoch: 6| Step: 9
Training loss: 2.853827092002058
Validation loss: 2.8166439432896326

Epoch: 6| Step: 10
Training loss: 3.5526339793057726
Validation loss: 2.819087796827253

Epoch: 6| Step: 11
Training loss: 2.770156682124328
Validation loss: 2.8166699487072755

Epoch: 6| Step: 12
Training loss: 2.514201264851942
Validation loss: 2.817987858312642

Epoch: 6| Step: 13
Training loss: 3.38290933730297
Validation loss: 2.8179385089502795

Epoch: 43| Step: 0
Training loss: 3.022323679233928
Validation loss: 2.830679077921268

Epoch: 6| Step: 1
Training loss: 3.2956142817322416
Validation loss: 2.831353576847438

Epoch: 6| Step: 2
Training loss: 3.2743485305103626
Validation loss: 2.8348603012590647

Epoch: 6| Step: 3
Training loss: 3.3330485858094256
Validation loss: 2.8287449485104346

Epoch: 6| Step: 4
Training loss: 3.100644376909901
Validation loss: 2.834844959310451

Epoch: 6| Step: 5
Training loss: 3.266288142428668
Validation loss: 2.8203506973902766

Epoch: 6| Step: 6
Training loss: 3.0132011199179365
Validation loss: 2.8187211737907174

Epoch: 6| Step: 7
Training loss: 3.6871856296824568
Validation loss: 2.816986315985192

Epoch: 6| Step: 8
Training loss: 2.849792767402337
Validation loss: 2.8120938936498714

Epoch: 6| Step: 9
Training loss: 2.84208513089164
Validation loss: 2.8117466253677215

Epoch: 6| Step: 10
Training loss: 2.9927801038397335
Validation loss: 2.812813897886307

Epoch: 6| Step: 11
Training loss: 3.2232979060543436
Validation loss: 2.8139509398455838

Epoch: 6| Step: 12
Training loss: 2.7063106221727953
Validation loss: 2.816112487117675

Epoch: 6| Step: 13
Training loss: 3.089481375913948
Validation loss: 2.8104428770177834

Epoch: 44| Step: 0
Training loss: 2.6235696437833034
Validation loss: 2.8119906767576515

Epoch: 6| Step: 1
Training loss: 2.2109055803239137
Validation loss: 2.812387461900348

Epoch: 6| Step: 2
Training loss: 2.9037185637028227
Validation loss: 2.8185572817054423

Epoch: 6| Step: 3
Training loss: 3.7143357949496223
Validation loss: 2.821038710863778

Epoch: 6| Step: 4
Training loss: 2.4666296629664686
Validation loss: 2.817879424131341

Epoch: 6| Step: 5
Training loss: 2.9231036046003465
Validation loss: 2.8233446525495696

Epoch: 6| Step: 6
Training loss: 2.737728482121865
Validation loss: 2.825480171970709

Epoch: 6| Step: 7
Training loss: 2.961330095901105
Validation loss: 2.8284211770491856

Epoch: 6| Step: 8
Training loss: 2.987371568034021
Validation loss: 2.8189498813399405

Epoch: 6| Step: 9
Training loss: 4.035697435423424
Validation loss: 2.814840717758092

Epoch: 6| Step: 10
Training loss: 3.346694790416753
Validation loss: 2.8099961797444273

Epoch: 6| Step: 11
Training loss: 3.0836141991064094
Validation loss: 2.8070090213219476

Epoch: 6| Step: 12
Training loss: 3.858687737311371
Validation loss: 2.8074979064627956

Epoch: 6| Step: 13
Training loss: 3.4673383434982887
Validation loss: 2.8080695054069067

Epoch: 45| Step: 0
Training loss: 3.1264147798413364
Validation loss: 2.809210759183965

Epoch: 6| Step: 1
Training loss: 2.343710733720553
Validation loss: 2.8135163547904893

Epoch: 6| Step: 2
Training loss: 2.6345824679203793
Validation loss: 2.8125429412225293

Epoch: 6| Step: 3
Training loss: 3.2095347215230605
Validation loss: 2.8148419996506515

Epoch: 6| Step: 4
Training loss: 3.048958716323528
Validation loss: 2.8139295638763566

Epoch: 6| Step: 5
Training loss: 3.162418644880187
Validation loss: 2.810239095052644

Epoch: 6| Step: 6
Training loss: 2.2023311835204846
Validation loss: 2.804160631760218

Epoch: 6| Step: 7
Training loss: 3.404970401181538
Validation loss: 2.8048976627844113

Epoch: 6| Step: 8
Training loss: 3.6228715633124247
Validation loss: 2.802798254579884

Epoch: 6| Step: 9
Training loss: 3.1484371970959844
Validation loss: 2.8037499078528563

Epoch: 6| Step: 10
Training loss: 3.3233221079778024
Validation loss: 2.803530881402018

Epoch: 6| Step: 11
Training loss: 3.499080264635874
Validation loss: 2.805645712762308

Epoch: 6| Step: 12
Training loss: 3.3502422302124115
Validation loss: 2.809599380815848

Epoch: 6| Step: 13
Training loss: 3.52717273927062
Validation loss: 2.819758346037511

Epoch: 46| Step: 0
Training loss: 2.9461765792561088
Validation loss: 2.8261400716453626

Epoch: 6| Step: 1
Training loss: 2.9041292389729687
Validation loss: 2.8462764349328857

Epoch: 6| Step: 2
Training loss: 3.016319076436381
Validation loss: 2.8610047747308602

Epoch: 6| Step: 3
Training loss: 3.0670350420193455
Validation loss: 2.862694146013154

Epoch: 6| Step: 4
Training loss: 3.852522972083002
Validation loss: 2.8466766345585492

Epoch: 6| Step: 5
Training loss: 3.1130136640514126
Validation loss: 2.8179819240622783

Epoch: 6| Step: 6
Training loss: 2.965039635018636
Validation loss: 2.7993550783297008

Epoch: 6| Step: 7
Training loss: 3.5253110924200497
Validation loss: 2.7980933368995746

Epoch: 6| Step: 8
Training loss: 3.0714970989756956
Validation loss: 2.800499456806941

Epoch: 6| Step: 9
Training loss: 2.5684820921847082
Validation loss: 2.800512043840099

Epoch: 6| Step: 10
Training loss: 2.7853140980208657
Validation loss: 2.8027203179675397

Epoch: 6| Step: 11
Training loss: 3.121111166741924
Validation loss: 2.8049762408215595

Epoch: 6| Step: 12
Training loss: 3.526244134691858
Validation loss: 2.805015961312428

Epoch: 6| Step: 13
Training loss: 2.838132066951002
Validation loss: 2.806838002560776

Epoch: 47| Step: 0
Training loss: 3.137795003571144
Validation loss: 2.8059743908175663

Epoch: 6| Step: 1
Training loss: 3.600674269368419
Validation loss: 2.8048077469358104

Epoch: 6| Step: 2
Training loss: 3.2118126634857065
Validation loss: 2.7980665669525484

Epoch: 6| Step: 3
Training loss: 3.1932031809086983
Validation loss: 2.7977695882517963

Epoch: 6| Step: 4
Training loss: 3.234238478870723
Validation loss: 2.796400315776259

Epoch: 6| Step: 5
Training loss: 2.9582233318956956
Validation loss: 2.7967824768795992

Epoch: 6| Step: 6
Training loss: 3.0747333566072683
Validation loss: 2.7950268779134944

Epoch: 6| Step: 7
Training loss: 2.5869743366067084
Validation loss: 2.7955613870566047

Epoch: 6| Step: 8
Training loss: 3.4022064006074033
Validation loss: 2.795669590139031

Epoch: 6| Step: 9
Training loss: 2.7389824115122994
Validation loss: 2.7959515455290274

Epoch: 6| Step: 10
Training loss: 3.0703587807620365
Validation loss: 2.7995657522209627

Epoch: 6| Step: 11
Training loss: 2.9579257594780812
Validation loss: 2.793973835020477

Epoch: 6| Step: 12
Training loss: 3.011706242120995
Validation loss: 2.7923357998382747

Epoch: 6| Step: 13
Training loss: 3.5542131379917885
Validation loss: 2.7950827871131136

Epoch: 48| Step: 0
Training loss: 3.344896066644713
Validation loss: 2.793927476715775

Epoch: 6| Step: 1
Training loss: 3.171330297142929
Validation loss: 2.793545637180538

Epoch: 6| Step: 2
Training loss: 2.9686269634249487
Validation loss: 2.791250079948297

Epoch: 6| Step: 3
Training loss: 2.9640311231948253
Validation loss: 2.7889351810413454

Epoch: 6| Step: 4
Training loss: 3.221323410458892
Validation loss: 2.7905892671704415

Epoch: 6| Step: 5
Training loss: 3.071670814162249
Validation loss: 2.7888638745172503

Epoch: 6| Step: 6
Training loss: 2.98411295274594
Validation loss: 2.7900147237693163

Epoch: 6| Step: 7
Training loss: 2.8956291803716385
Validation loss: 2.789316111318986

Epoch: 6| Step: 8
Training loss: 2.9474715760650563
Validation loss: 2.790114510480816

Epoch: 6| Step: 9
Training loss: 3.477451168021855
Validation loss: 2.7894940686814325

Epoch: 6| Step: 10
Training loss: 3.7988155727620385
Validation loss: 2.792156912622014

Epoch: 6| Step: 11
Training loss: 2.125508191545415
Validation loss: 2.7905113882869133

Epoch: 6| Step: 12
Training loss: 3.189735376748617
Validation loss: 2.7893279712685617

Epoch: 6| Step: 13
Training loss: 3.0416385353215825
Validation loss: 2.790332624822906

Epoch: 49| Step: 0
Training loss: 3.4449028065650396
Validation loss: 2.795899641427648

Epoch: 6| Step: 1
Training loss: 3.0751872494138497
Validation loss: 2.786752664138248

Epoch: 6| Step: 2
Training loss: 2.1949901412012545
Validation loss: 2.795754517189063

Epoch: 6| Step: 3
Training loss: 2.964951343619611
Validation loss: 2.808195811693799

Epoch: 6| Step: 4
Training loss: 3.2536947815906903
Validation loss: 2.796056558368841

Epoch: 6| Step: 5
Training loss: 3.262367047052619
Validation loss: 2.7868007764984015

Epoch: 6| Step: 6
Training loss: 2.965295649128964
Validation loss: 2.784394858249781

Epoch: 6| Step: 7
Training loss: 3.3225064557589006
Validation loss: 2.789182141120513

Epoch: 6| Step: 8
Training loss: 3.4093026297744116
Validation loss: 2.784788976561419

Epoch: 6| Step: 9
Training loss: 2.8920973868322406
Validation loss: 2.784640336452545

Epoch: 6| Step: 10
Training loss: 3.010433491766528
Validation loss: 2.7856066139947018

Epoch: 6| Step: 11
Training loss: 3.107209491485022
Validation loss: 2.7845946596346054

Epoch: 6| Step: 12
Training loss: 3.005191443719238
Validation loss: 2.7834365368620304

Epoch: 6| Step: 13
Training loss: 3.505691396785323
Validation loss: 2.7817476193122164

Epoch: 50| Step: 0
Training loss: 3.1083798757005483
Validation loss: 2.7877719184591587

Epoch: 6| Step: 1
Training loss: 2.909357030302907
Validation loss: 2.787381979019609

Epoch: 6| Step: 2
Training loss: 2.9558848246228315
Validation loss: 2.7962995505371926

Epoch: 6| Step: 3
Training loss: 3.2790722113985105
Validation loss: 2.7973459231948508

Epoch: 6| Step: 4
Training loss: 3.2224609315810806
Validation loss: 2.80576751213192

Epoch: 6| Step: 5
Training loss: 2.629219478634961
Validation loss: 2.8013235052276193

Epoch: 6| Step: 6
Training loss: 3.596021382235392
Validation loss: 2.7936848866323065

Epoch: 6| Step: 7
Training loss: 3.037136065497672
Validation loss: 2.790018825569671

Epoch: 6| Step: 8
Training loss: 3.4123589566884656
Validation loss: 2.7933201607865845

Epoch: 6| Step: 9
Training loss: 2.284710493382962
Validation loss: 2.782979753846549

Epoch: 6| Step: 10
Training loss: 3.498133297805255
Validation loss: 2.779278869572889

Epoch: 6| Step: 11
Training loss: 3.6044716825395495
Validation loss: 2.779832899959204

Epoch: 6| Step: 12
Training loss: 2.70861312203512
Validation loss: 2.775725876209165

Epoch: 6| Step: 13
Training loss: 2.6858864309483366
Validation loss: 2.776518621306947

Epoch: 51| Step: 0
Training loss: 3.36372952015914
Validation loss: 2.779413176918046

Epoch: 6| Step: 1
Training loss: 2.3942921754058584
Validation loss: 2.778491330703998

Epoch: 6| Step: 2
Training loss: 3.308844366568983
Validation loss: 2.776048287450701

Epoch: 6| Step: 3
Training loss: 2.6109449038352066
Validation loss: 2.7837462165108704

Epoch: 6| Step: 4
Training loss: 2.951509548538223
Validation loss: 2.7795243882430016

Epoch: 6| Step: 5
Training loss: 3.748820310049685
Validation loss: 2.779216180812838

Epoch: 6| Step: 6
Training loss: 2.8197682032450357
Validation loss: 2.783350785401941

Epoch: 6| Step: 7
Training loss: 3.417848212160275
Validation loss: 2.7804121299562277

Epoch: 6| Step: 8
Training loss: 2.7309512256469892
Validation loss: 2.7920883850740177

Epoch: 6| Step: 9
Training loss: 3.4374704533087415
Validation loss: 2.784356409748799

Epoch: 6| Step: 10
Training loss: 3.0807531919641606
Validation loss: 2.7780849638322898

Epoch: 6| Step: 11
Training loss: 3.0929969873028256
Validation loss: 2.77558899637046

Epoch: 6| Step: 12
Training loss: 3.326353076024395
Validation loss: 2.773262364335925

Epoch: 6| Step: 13
Training loss: 2.5705840828215423
Validation loss: 2.770717773569026

Epoch: 52| Step: 0
Training loss: 2.872357522404067
Validation loss: 2.76964502407379

Epoch: 6| Step: 1
Training loss: 2.316831089835451
Validation loss: 2.780453388003971

Epoch: 6| Step: 2
Training loss: 3.2904954267098203
Validation loss: 2.7831130848863337

Epoch: 6| Step: 3
Training loss: 2.8048490089943945
Validation loss: 2.7700212133375763

Epoch: 6| Step: 4
Training loss: 3.768304528372765
Validation loss: 2.771048283448915

Epoch: 6| Step: 5
Training loss: 3.4494418701723677
Validation loss: 2.764449970085603

Epoch: 6| Step: 6
Training loss: 3.016916581510009
Validation loss: 2.764433757001211

Epoch: 6| Step: 7
Training loss: 3.5674727684644423
Validation loss: 2.761747402984667

Epoch: 6| Step: 8
Training loss: 3.349369923565878
Validation loss: 2.764964225970943

Epoch: 6| Step: 9
Training loss: 3.2668805058872437
Validation loss: 2.7667049512303503

Epoch: 6| Step: 10
Training loss: 2.8741062267743693
Validation loss: 2.7676272024235518

Epoch: 6| Step: 11
Training loss: 2.6064594907292813
Validation loss: 2.7680747633386527

Epoch: 6| Step: 12
Training loss: 3.0731708141338707
Validation loss: 2.76175548354231

Epoch: 6| Step: 13
Training loss: 2.5149762756563447
Validation loss: 2.7630051651678644

Epoch: 53| Step: 0
Training loss: 3.12805972035953
Validation loss: 2.758268870101173

Epoch: 6| Step: 1
Training loss: 2.6781882493374436
Validation loss: 2.7580573613435555

Epoch: 6| Step: 2
Training loss: 3.096830433545056
Validation loss: 2.7557195677685162

Epoch: 6| Step: 3
Training loss: 2.4069419955724003
Validation loss: 2.756370676249834

Epoch: 6| Step: 4
Training loss: 2.681027802906202
Validation loss: 2.7552158974294536

Epoch: 6| Step: 5
Training loss: 3.434430225542673
Validation loss: 2.75741792500999

Epoch: 6| Step: 6
Training loss: 3.342624367887442
Validation loss: 2.757542128836439

Epoch: 6| Step: 7
Training loss: 3.012667930639342
Validation loss: 2.7547515621398624

Epoch: 6| Step: 8
Training loss: 3.6238496204695556
Validation loss: 2.754064384836029

Epoch: 6| Step: 9
Training loss: 3.15419891488754
Validation loss: 2.751710179104517

Epoch: 6| Step: 10
Training loss: 3.3925174055447127
Validation loss: 2.755159954325

Epoch: 6| Step: 11
Training loss: 2.940023758461381
Validation loss: 2.754001345534766

Epoch: 6| Step: 12
Training loss: 3.096091877207357
Validation loss: 2.754379610891987

Epoch: 6| Step: 13
Training loss: 2.867613383997321
Validation loss: 2.7538338614370748

Epoch: 54| Step: 0
Training loss: 2.6898486498262626
Validation loss: 2.750642447878388

Epoch: 6| Step: 1
Training loss: 3.483297275435678
Validation loss: 2.750634559290226

Epoch: 6| Step: 2
Training loss: 3.4346851267861536
Validation loss: 2.74899612069594

Epoch: 6| Step: 3
Training loss: 2.7372219414781074
Validation loss: 2.7484346989487825

Epoch: 6| Step: 4
Training loss: 3.3625043620822224
Validation loss: 2.7476404999171433

Epoch: 6| Step: 5
Training loss: 3.1613791307628465
Validation loss: 2.7488774211245643

Epoch: 6| Step: 6
Training loss: 2.7234901234920588
Validation loss: 2.7443951648063414

Epoch: 6| Step: 7
Training loss: 3.259635872427009
Validation loss: 2.7461720838214987

Epoch: 6| Step: 8
Training loss: 2.906487896114276
Validation loss: 2.743591107366973

Epoch: 6| Step: 9
Training loss: 3.178570075363924
Validation loss: 2.7491760520455437

Epoch: 6| Step: 10
Training loss: 3.022710983952135
Validation loss: 2.746426707917704

Epoch: 6| Step: 11
Training loss: 2.6038893183201486
Validation loss: 2.748076048354043

Epoch: 6| Step: 12
Training loss: 2.9876154538115367
Validation loss: 2.7473135781855

Epoch: 6| Step: 13
Training loss: 3.4687099969980086
Validation loss: 2.7481423906471876

Epoch: 55| Step: 0
Training loss: 2.676649946664898
Validation loss: 2.744481627150539

Epoch: 6| Step: 1
Training loss: 3.142627286556112
Validation loss: 2.7458590478962934

Epoch: 6| Step: 2
Training loss: 3.0737411341281407
Validation loss: 2.745559072026532

Epoch: 6| Step: 3
Training loss: 2.9998757018724245
Validation loss: 2.745019551179946

Epoch: 6| Step: 4
Training loss: 3.1413359335557747
Validation loss: 2.7481219571378346

Epoch: 6| Step: 5
Training loss: 3.595210964289381
Validation loss: 2.742779552641015

Epoch: 6| Step: 6
Training loss: 3.04338131655428
Validation loss: 2.741924821035462

Epoch: 6| Step: 7
Training loss: 2.3671274712634216
Validation loss: 2.736937326638913

Epoch: 6| Step: 8
Training loss: 3.3374458851516855
Validation loss: 2.739159837231561

Epoch: 6| Step: 9
Training loss: 3.155259987446186
Validation loss: 2.7355475105432427

Epoch: 6| Step: 10
Training loss: 2.3681064748152716
Validation loss: 2.734179906492148

Epoch: 6| Step: 11
Training loss: 3.052917904501924
Validation loss: 2.7363930863629196

Epoch: 6| Step: 12
Training loss: 3.2697885063442107
Validation loss: 2.736219718029236

Epoch: 6| Step: 13
Training loss: 3.7678251684816986
Validation loss: 2.73717041103051

Epoch: 56| Step: 0
Training loss: 3.521158974540459
Validation loss: 2.733056677221548

Epoch: 6| Step: 1
Training loss: 2.986717383374164
Validation loss: 2.7355316622159136

Epoch: 6| Step: 2
Training loss: 3.6264682295683164
Validation loss: 2.7381318042071174

Epoch: 6| Step: 3
Training loss: 3.4418049991569366
Validation loss: 2.7376189356950986

Epoch: 6| Step: 4
Training loss: 3.256999767477972
Validation loss: 2.737677496846173

Epoch: 6| Step: 5
Training loss: 3.021028253690244
Validation loss: 2.7363647628061942

Epoch: 6| Step: 6
Training loss: 3.0388068947277356
Validation loss: 2.7410699042725133

Epoch: 6| Step: 7
Training loss: 2.8398716228644183
Validation loss: 2.7412050680407645

Epoch: 6| Step: 8
Training loss: 2.534080712180882
Validation loss: 2.7385207065320976

Epoch: 6| Step: 9
Training loss: 2.4908668582515383
Validation loss: 2.736411637234287

Epoch: 6| Step: 10
Training loss: 2.6730340596379194
Validation loss: 2.7343758138019623

Epoch: 6| Step: 11
Training loss: 3.4157198237513096
Validation loss: 2.7316450873314944

Epoch: 6| Step: 12
Training loss: 3.09952937829977
Validation loss: 2.73343268358227

Epoch: 6| Step: 13
Training loss: 2.2598119416102067
Validation loss: 2.7292216944428818

Epoch: 57| Step: 0
Training loss: 2.2472345523419994
Validation loss: 2.7285477882862175

Epoch: 6| Step: 1
Training loss: 3.3695833042510035
Validation loss: 2.736640701697862

Epoch: 6| Step: 2
Training loss: 3.088396932074371
Validation loss: 2.733140005207249

Epoch: 6| Step: 3
Training loss: 2.4387096435711597
Validation loss: 2.729612425999678

Epoch: 6| Step: 4
Training loss: 2.801395960643212
Validation loss: 2.7350591194584264

Epoch: 6| Step: 5
Training loss: 3.261421966756105
Validation loss: 2.7374416760719384

Epoch: 6| Step: 6
Training loss: 2.766953661024315
Validation loss: 2.7359642274081106

Epoch: 6| Step: 7
Training loss: 3.7287968429093743
Validation loss: 2.7321718777645643

Epoch: 6| Step: 8
Training loss: 3.628693376257697
Validation loss: 2.7282683650628425

Epoch: 6| Step: 9
Training loss: 3.1752885762430214
Validation loss: 2.727754183386496

Epoch: 6| Step: 10
Training loss: 2.8623663258886944
Validation loss: 2.7300548490621472

Epoch: 6| Step: 11
Training loss: 2.7909619784688555
Validation loss: 2.7277928789653916

Epoch: 6| Step: 12
Training loss: 3.1050329514381327
Validation loss: 2.725340254532505

Epoch: 6| Step: 13
Training loss: 3.289243135905963
Validation loss: 2.7245767907305303

Epoch: 58| Step: 0
Training loss: 2.99871115019718
Validation loss: 2.724874654601978

Epoch: 6| Step: 1
Training loss: 3.0858457141215445
Validation loss: 2.726809335481205

Epoch: 6| Step: 2
Training loss: 2.4617112653855195
Validation loss: 2.7233204268887463

Epoch: 6| Step: 3
Training loss: 3.0388509877793832
Validation loss: 2.726222675646557

Epoch: 6| Step: 4
Training loss: 2.985149183267447
Validation loss: 2.7234507069126197

Epoch: 6| Step: 5
Training loss: 3.622719935551921
Validation loss: 2.723493177090633

Epoch: 6| Step: 6
Training loss: 3.025691333304439
Validation loss: 2.721737952984262

Epoch: 6| Step: 7
Training loss: 3.0136715585506963
Validation loss: 2.7223886702740026

Epoch: 6| Step: 8
Training loss: 3.008581603171078
Validation loss: 2.725090475011364

Epoch: 6| Step: 9
Training loss: 2.807539995542112
Validation loss: 2.7212724734149396

Epoch: 6| Step: 10
Training loss: 3.445391111277204
Validation loss: 2.7219423800103812

Epoch: 6| Step: 11
Training loss: 3.1439567846769165
Validation loss: 2.720490131298027

Epoch: 6| Step: 12
Training loss: 3.1048101146581404
Validation loss: 2.7223270182067987

Epoch: 6| Step: 13
Training loss: 2.6785893539555525
Validation loss: 2.719715462305537

Epoch: 59| Step: 0
Training loss: 2.228527179390511
Validation loss: 2.7195713724672306

Epoch: 6| Step: 1
Training loss: 3.3567334102244244
Validation loss: 2.7206432486497896

Epoch: 6| Step: 2
Training loss: 2.412233517807427
Validation loss: 2.7251842016931573

Epoch: 6| Step: 3
Training loss: 3.05302083238928
Validation loss: 2.7314349037875543

Epoch: 6| Step: 4
Training loss: 3.260081573589084
Validation loss: 2.7425116900208355

Epoch: 6| Step: 5
Training loss: 2.8618608519118407
Validation loss: 2.752008312595426

Epoch: 6| Step: 6
Training loss: 3.060972182976522
Validation loss: 2.75276582054833

Epoch: 6| Step: 7
Training loss: 2.894251842114977
Validation loss: 2.7575617404341486

Epoch: 6| Step: 8
Training loss: 3.0660412613692034
Validation loss: 2.7382112983029847

Epoch: 6| Step: 9
Training loss: 3.273350388999784
Validation loss: 2.7212888042224948

Epoch: 6| Step: 10
Training loss: 3.0186929069474884
Validation loss: 2.7141217743466775

Epoch: 6| Step: 11
Training loss: 3.105262835891394
Validation loss: 2.7173855263861264

Epoch: 6| Step: 12
Training loss: 3.615456482068408
Validation loss: 2.7203647258290236

Epoch: 6| Step: 13
Training loss: 3.693042791990984
Validation loss: 2.7235279072976297

Epoch: 60| Step: 0
Training loss: 2.9858195219182724
Validation loss: 2.721817801554216

Epoch: 6| Step: 1
Training loss: 2.9018728456934917
Validation loss: 2.7190388314036222

Epoch: 6| Step: 2
Training loss: 3.070382231485897
Validation loss: 2.7153246060883207

Epoch: 6| Step: 3
Training loss: 3.4098441384233156
Validation loss: 2.717650088592534

Epoch: 6| Step: 4
Training loss: 3.4294473829046885
Validation loss: 2.7137134714829463

Epoch: 6| Step: 5
Training loss: 2.5125820165504207
Validation loss: 2.7120543366201826

Epoch: 6| Step: 6
Training loss: 2.7987636391024977
Validation loss: 2.712699858918992

Epoch: 6| Step: 7
Training loss: 3.13963249048244
Validation loss: 2.714793554057255

Epoch: 6| Step: 8
Training loss: 3.114573364922297
Validation loss: 2.7211079945328525

Epoch: 6| Step: 9
Training loss: 3.2484153405516736
Validation loss: 2.7240583350896173

Epoch: 6| Step: 10
Training loss: 2.4544127176338266
Validation loss: 2.7288569215349447

Epoch: 6| Step: 11
Training loss: 3.3037500517286222
Validation loss: 2.7336042723718865

Epoch: 6| Step: 12
Training loss: 3.3723334622107997
Validation loss: 2.7316365610732225

Epoch: 6| Step: 13
Training loss: 2.6337426237737183
Validation loss: 2.7288131547536567

Epoch: 61| Step: 0
Training loss: 2.8560623407799395
Validation loss: 2.728792574625833

Epoch: 6| Step: 1
Training loss: 3.3560860080541786
Validation loss: 2.724120028907489

Epoch: 6| Step: 2
Training loss: 2.8392642346826658
Validation loss: 2.7211792121217817

Epoch: 6| Step: 3
Training loss: 2.9482387910401933
Validation loss: 2.7177595390722704

Epoch: 6| Step: 4
Training loss: 3.3529331632347135
Validation loss: 2.7125334208216647

Epoch: 6| Step: 5
Training loss: 3.0404194055661407
Validation loss: 2.713664204072136

Epoch: 6| Step: 6
Training loss: 3.0082043677360764
Validation loss: 2.709552805242824

Epoch: 6| Step: 7
Training loss: 3.4304391649882175
Validation loss: 2.706228235761567

Epoch: 6| Step: 8
Training loss: 3.066975184829964
Validation loss: 2.705531659149582

Epoch: 6| Step: 9
Training loss: 2.9417469896223483
Validation loss: 2.710405328290591

Epoch: 6| Step: 10
Training loss: 2.939151705372212
Validation loss: 2.7073669571099557

Epoch: 6| Step: 11
Training loss: 2.6269073822690308
Validation loss: 2.7081258288862218

Epoch: 6| Step: 12
Training loss: 3.3018599152820647
Validation loss: 2.7077675095029305

Epoch: 6| Step: 13
Training loss: 2.548565075626312
Validation loss: 2.711193307527355

Epoch: 62| Step: 0
Training loss: 2.926083232131284
Validation loss: 2.7190656355005536

Epoch: 6| Step: 1
Training loss: 2.879488219777416
Validation loss: 2.713292225190726

Epoch: 6| Step: 2
Training loss: 3.504272850021451
Validation loss: 2.717014803329248

Epoch: 6| Step: 3
Training loss: 2.9021239165357344
Validation loss: 2.723383227499379

Epoch: 6| Step: 4
Training loss: 3.131771380785377
Validation loss: 2.711153189257043

Epoch: 6| Step: 5
Training loss: 2.875035161342393
Validation loss: 2.709256502487212

Epoch: 6| Step: 6
Training loss: 3.2639189283643457
Validation loss: 2.710052560463745

Epoch: 6| Step: 7
Training loss: 3.8065607053725707
Validation loss: 2.70959292544734

Epoch: 6| Step: 8
Training loss: 1.899205809799795
Validation loss: 2.7130018776793148

Epoch: 6| Step: 9
Training loss: 3.104292660061471
Validation loss: 2.7167279422336197

Epoch: 6| Step: 10
Training loss: 2.7243079015279976
Validation loss: 2.719550464110697

Epoch: 6| Step: 11
Training loss: 2.3415144367444993
Validation loss: 2.7115131752917105

Epoch: 6| Step: 12
Training loss: 3.1790797897074197
Validation loss: 2.7094421073349535

Epoch: 6| Step: 13
Training loss: 3.800460315731529
Validation loss: 2.7059888888675445

Epoch: 63| Step: 0
Training loss: 3.644173133321544
Validation loss: 2.7012067953931447

Epoch: 6| Step: 1
Training loss: 2.737511628705413
Validation loss: 2.6999305183300013

Epoch: 6| Step: 2
Training loss: 3.1413837484233595
Validation loss: 2.707641733495504

Epoch: 6| Step: 3
Training loss: 2.6803963393746106
Validation loss: 2.7112007681155497

Epoch: 6| Step: 4
Training loss: 2.5818600504065388
Validation loss: 2.7127751945305385

Epoch: 6| Step: 5
Training loss: 3.5520025488354583
Validation loss: 2.7049480973981175

Epoch: 6| Step: 6
Training loss: 3.4445304415505684
Validation loss: 2.706748375261221

Epoch: 6| Step: 7
Training loss: 2.8759671118796337
Validation loss: 2.7044304763324205

Epoch: 6| Step: 8
Training loss: 3.182782141082354
Validation loss: 2.7038025460623287

Epoch: 6| Step: 9
Training loss: 3.3716182013469878
Validation loss: 2.703367762132876

Epoch: 6| Step: 10
Training loss: 3.1105422699580534
Validation loss: 2.704459151396828

Epoch: 6| Step: 11
Training loss: 2.7000503252778834
Validation loss: 2.699283705980579

Epoch: 6| Step: 12
Training loss: 2.648333432113745
Validation loss: 2.702026525249057

Epoch: 6| Step: 13
Training loss: 2.070822598936734
Validation loss: 2.702866835402291

Epoch: 64| Step: 0
Training loss: 3.1301660180471433
Validation loss: 2.6972300433787586

Epoch: 6| Step: 1
Training loss: 2.759026711279666
Validation loss: 2.7035381924370414

Epoch: 6| Step: 2
Training loss: 2.784637103176412
Validation loss: 2.7017109572570006

Epoch: 6| Step: 3
Training loss: 3.0841074478688317
Validation loss: 2.7045712675063567

Epoch: 6| Step: 4
Training loss: 3.071132094309563
Validation loss: 2.702474037385609

Epoch: 6| Step: 5
Training loss: 3.387544700637309
Validation loss: 2.7033661860350775

Epoch: 6| Step: 6
Training loss: 2.912957766990539
Validation loss: 2.7020172964073654

Epoch: 6| Step: 7
Training loss: 3.1491951232039006
Validation loss: 2.703812255215466

Epoch: 6| Step: 8
Training loss: 3.256282016940876
Validation loss: 2.703493553964424

Epoch: 6| Step: 9
Training loss: 3.18780037455725
Validation loss: 2.699707289066271

Epoch: 6| Step: 10
Training loss: 2.7023586002591387
Validation loss: 2.7016836773303567

Epoch: 6| Step: 11
Training loss: 3.092531831372437
Validation loss: 2.7005682163142137

Epoch: 6| Step: 12
Training loss: 2.8489105016027754
Validation loss: 2.704178766366093

Epoch: 6| Step: 13
Training loss: 2.9344736295949376
Validation loss: 2.7050266333083486

Epoch: 65| Step: 0
Training loss: 2.8331087995832207
Validation loss: 2.7229627126431533

Epoch: 6| Step: 1
Training loss: 3.1065599743554895
Validation loss: 2.741051354063217

Epoch: 6| Step: 2
Training loss: 3.7725497952986404
Validation loss: 2.7847205006144686

Epoch: 6| Step: 3
Training loss: 3.744512612137074
Validation loss: 2.786960963512676

Epoch: 6| Step: 4
Training loss: 2.9940108279208877
Validation loss: 2.749618095437021

Epoch: 6| Step: 5
Training loss: 2.4916157320700214
Validation loss: 2.702416735894999

Epoch: 6| Step: 6
Training loss: 2.7204974467134613
Validation loss: 2.6945444813775308

Epoch: 6| Step: 7
Training loss: 2.713077634843048
Validation loss: 2.697643215017199

Epoch: 6| Step: 8
Training loss: 3.1196869507263427
Validation loss: 2.7122133888695785

Epoch: 6| Step: 9
Training loss: 3.0838783057479886
Validation loss: 2.7308673267578856

Epoch: 6| Step: 10
Training loss: 2.409718181546867
Validation loss: 2.7583192856250025

Epoch: 6| Step: 11
Training loss: 3.2451143956409148
Validation loss: 2.7491418873780953

Epoch: 6| Step: 12
Training loss: 2.8493921669059867
Validation loss: 2.708419087253722

Epoch: 6| Step: 13
Training loss: 3.662744996921788
Validation loss: 2.6999098329365037

Epoch: 66| Step: 0
Training loss: 2.8075001673982865
Validation loss: 2.69849134368041

Epoch: 6| Step: 1
Training loss: 3.6710921081941956
Validation loss: 2.7013684859053946

Epoch: 6| Step: 2
Training loss: 3.0536530052767525
Validation loss: 2.7059125125856647

Epoch: 6| Step: 3
Training loss: 3.426578163706076
Validation loss: 2.7168212157280704

Epoch: 6| Step: 4
Training loss: 3.1777007623452787
Validation loss: 2.7321194577682175

Epoch: 6| Step: 5
Training loss: 3.044183412748263
Validation loss: 2.737454490303935

Epoch: 6| Step: 6
Training loss: 3.5384407760495797
Validation loss: 2.735510233886815

Epoch: 6| Step: 7
Training loss: 2.8543379980486705
Validation loss: 2.7273171896524837

Epoch: 6| Step: 8
Training loss: 2.6647491912482684
Validation loss: 2.7154467936549205

Epoch: 6| Step: 9
Training loss: 2.1963287933406126
Validation loss: 2.7074660118539953

Epoch: 6| Step: 10
Training loss: 2.7249403010837163
Validation loss: 2.7051871203485676

Epoch: 6| Step: 11
Training loss: 2.6196929326547735
Validation loss: 2.694994171020297

Epoch: 6| Step: 12
Training loss: 3.5933129086264888
Validation loss: 2.698517252702478

Epoch: 6| Step: 13
Training loss: 2.6404503758944298
Validation loss: 2.6926347349552966

Epoch: 67| Step: 0
Training loss: 2.155915386386784
Validation loss: 2.6935354039910466

Epoch: 6| Step: 1
Training loss: 3.5198677740404563
Validation loss: 2.69381726132467

Epoch: 6| Step: 2
Training loss: 2.8511674999324224
Validation loss: 2.694467804483326

Epoch: 6| Step: 3
Training loss: 3.2836576801822868
Validation loss: 2.696037939841413

Epoch: 6| Step: 4
Training loss: 3.0882849927050113
Validation loss: 2.706881349892712

Epoch: 6| Step: 5
Training loss: 2.5911707175639807
Validation loss: 2.7204833803291155

Epoch: 6| Step: 6
Training loss: 2.874161307695908
Validation loss: 2.735979569118364

Epoch: 6| Step: 7
Training loss: 3.200348930408556
Validation loss: 2.7493537542493973

Epoch: 6| Step: 8
Training loss: 2.7671929349151263
Validation loss: 2.739409934188573

Epoch: 6| Step: 9
Training loss: 3.0276856850744895
Validation loss: 2.71679307784563

Epoch: 6| Step: 10
Training loss: 3.9592712629618876
Validation loss: 2.7030210421064655

Epoch: 6| Step: 11
Training loss: 2.6205513815134127
Validation loss: 2.6926352309960815

Epoch: 6| Step: 12
Training loss: 3.383453801708529
Validation loss: 2.688176895219259

Epoch: 6| Step: 13
Training loss: 2.4839573155174186
Validation loss: 2.6896015639551587

Epoch: 68| Step: 0
Training loss: 2.7556570128850133
Validation loss: 2.690790829207453

Epoch: 6| Step: 1
Training loss: 3.4097982701567644
Validation loss: 2.691785616240005

Epoch: 6| Step: 2
Training loss: 2.8431877167216886
Validation loss: 2.688649017061901

Epoch: 6| Step: 3
Training loss: 3.2035234901230267
Validation loss: 2.6924111388374437

Epoch: 6| Step: 4
Training loss: 3.7105332325026867
Validation loss: 2.6922016821928554

Epoch: 6| Step: 5
Training loss: 2.7324315603328615
Validation loss: 2.6864183447491947

Epoch: 6| Step: 6
Training loss: 3.4052499125406213
Validation loss: 2.687785529088149

Epoch: 6| Step: 7
Training loss: 2.934249703004173
Validation loss: 2.6851206465815896

Epoch: 6| Step: 8
Training loss: 3.056508333798565
Validation loss: 2.691225968454844

Epoch: 6| Step: 9
Training loss: 2.870945600982162
Validation loss: 2.693446279699285

Epoch: 6| Step: 10
Training loss: 3.123323830257956
Validation loss: 2.69834829806796

Epoch: 6| Step: 11
Training loss: 2.360676791567538
Validation loss: 2.709741577150908

Epoch: 6| Step: 12
Training loss: 3.253387739581253
Validation loss: 2.701448504760417

Epoch: 6| Step: 13
Training loss: 1.9438301168041912
Validation loss: 2.6965140816376425

Epoch: 69| Step: 0
Training loss: 2.17481016887219
Validation loss: 2.71558804363622

Epoch: 6| Step: 1
Training loss: 2.106514693927199
Validation loss: 2.727136100930929

Epoch: 6| Step: 2
Training loss: 3.0439429627336936
Validation loss: 2.74088529257915

Epoch: 6| Step: 3
Training loss: 2.8665945494991547
Validation loss: 2.747703532138385

Epoch: 6| Step: 4
Training loss: 3.2849019391013363
Validation loss: 2.7500684474209076

Epoch: 6| Step: 5
Training loss: 3.30727737704016
Validation loss: 2.733631867713945

Epoch: 6| Step: 6
Training loss: 3.296536541239094
Validation loss: 2.707016379689278

Epoch: 6| Step: 7
Training loss: 3.1352517389831513
Validation loss: 2.693219089525891

Epoch: 6| Step: 8
Training loss: 3.3950349458179656
Validation loss: 2.6887602277864517

Epoch: 6| Step: 9
Training loss: 2.50259436460885
Validation loss: 2.683783972408837

Epoch: 6| Step: 10
Training loss: 3.705207078426057
Validation loss: 2.6840582709148824

Epoch: 6| Step: 11
Training loss: 3.590429613127617
Validation loss: 2.689498701877165

Epoch: 6| Step: 12
Training loss: 2.892862804346751
Validation loss: 2.6878849907067455

Epoch: 6| Step: 13
Training loss: 2.2671105085848784
Validation loss: 2.6876876061585984

Epoch: 70| Step: 0
Training loss: 2.6037848434277855
Validation loss: 2.6918471306695477

Epoch: 6| Step: 1
Training loss: 2.4907116959821827
Validation loss: 2.6880668496397324

Epoch: 6| Step: 2
Training loss: 3.137892715983369
Validation loss: 2.6881800270782366

Epoch: 6| Step: 3
Training loss: 2.783001637443584
Validation loss: 2.690028388491941

Epoch: 6| Step: 4
Training loss: 2.8665697643254937
Validation loss: 2.693844245004507

Epoch: 6| Step: 5
Training loss: 2.686886739623109
Validation loss: 2.69750231884774

Epoch: 6| Step: 6
Training loss: 2.7067322228703126
Validation loss: 2.6954894000819976

Epoch: 6| Step: 7
Training loss: 3.1674864527676827
Validation loss: 2.708780516503712

Epoch: 6| Step: 8
Training loss: 2.537217253167436
Validation loss: 2.7226882292171957

Epoch: 6| Step: 9
Training loss: 3.389562202923887
Validation loss: 2.7154473638884395

Epoch: 6| Step: 10
Training loss: 3.523305547912039
Validation loss: 2.71309665884564

Epoch: 6| Step: 11
Training loss: 3.4195894595014185
Validation loss: 2.6900772734902962

Epoch: 6| Step: 12
Training loss: 3.438566007916076
Validation loss: 2.680130478664636

Epoch: 6| Step: 13
Training loss: 3.5715311253673505
Validation loss: 2.6781404180697117

Epoch: 71| Step: 0
Training loss: 2.944146125204246
Validation loss: 2.6806257625074528

Epoch: 6| Step: 1
Training loss: 3.608765125355274
Validation loss: 2.6865660582102766

Epoch: 6| Step: 2
Training loss: 2.9058310914384227
Validation loss: 2.6994344325568727

Epoch: 6| Step: 3
Training loss: 2.918630501957726
Validation loss: 2.702751529824724

Epoch: 6| Step: 4
Training loss: 2.9595464090819332
Validation loss: 2.6975512836597892

Epoch: 6| Step: 5
Training loss: 3.0650560261271473
Validation loss: 2.69164045032761

Epoch: 6| Step: 6
Training loss: 3.2336576836572672
Validation loss: 2.6900860038988923

Epoch: 6| Step: 7
Training loss: 3.0689806196956315
Validation loss: 2.690060894248638

Epoch: 6| Step: 8
Training loss: 3.1277888251727433
Validation loss: 2.6912127921684625

Epoch: 6| Step: 9
Training loss: 2.895615841682059
Validation loss: 2.6928664417483446

Epoch: 6| Step: 10
Training loss: 2.641542173835645
Validation loss: 2.6913979391777003

Epoch: 6| Step: 11
Training loss: 2.899711555079424
Validation loss: 2.697308123493012

Epoch: 6| Step: 12
Training loss: 2.6769435168218694
Validation loss: 2.69155947886669

Epoch: 6| Step: 13
Training loss: 3.51394735362218
Validation loss: 2.696711545485311

Epoch: 72| Step: 0
Training loss: 2.9909022984950657
Validation loss: 2.6943332790284376

Epoch: 6| Step: 1
Training loss: 3.1863342846287925
Validation loss: 2.695231713999518

Epoch: 6| Step: 2
Training loss: 3.0398933432089255
Validation loss: 2.690650295478671

Epoch: 6| Step: 3
Training loss: 2.779284264756398
Validation loss: 2.6927042483250805

Epoch: 6| Step: 4
Training loss: 3.012854533880084
Validation loss: 2.7015944047887475

Epoch: 6| Step: 5
Training loss: 3.037632152053063
Validation loss: 2.6997819018646934

Epoch: 6| Step: 6
Training loss: 2.9662069571708165
Validation loss: 2.681781600273382

Epoch: 6| Step: 7
Training loss: 2.6040584287402173
Validation loss: 2.675191854988393

Epoch: 6| Step: 8
Training loss: 3.2145728997196974
Validation loss: 2.672009482744601

Epoch: 6| Step: 9
Training loss: 3.052316667579655
Validation loss: 2.6687646029950516

Epoch: 6| Step: 10
Training loss: 3.2391973103993283
Validation loss: 2.6730199679090805

Epoch: 6| Step: 11
Training loss: 3.3141990478816283
Validation loss: 2.6699179631703327

Epoch: 6| Step: 12
Training loss: 2.823559442704041
Validation loss: 2.668191573450188

Epoch: 6| Step: 13
Training loss: 2.7531917429702513
Validation loss: 2.6677561336678695

Epoch: 73| Step: 0
Training loss: 3.278155075240746
Validation loss: 2.6661727486953404

Epoch: 6| Step: 1
Training loss: 2.9184963663407633
Validation loss: 2.667497444590238

Epoch: 6| Step: 2
Training loss: 3.279579536656469
Validation loss: 2.6675823341839173

Epoch: 6| Step: 3
Training loss: 3.2569618486717977
Validation loss: 2.6653110502721944

Epoch: 6| Step: 4
Training loss: 3.1899784400713616
Validation loss: 2.671081547970084

Epoch: 6| Step: 5
Training loss: 2.369560638456786
Validation loss: 2.6628085389632696

Epoch: 6| Step: 6
Training loss: 2.66111561060954
Validation loss: 2.6654780152373165

Epoch: 6| Step: 7
Training loss: 2.7797676164940452
Validation loss: 2.66799838194786

Epoch: 6| Step: 8
Training loss: 2.813824998490728
Validation loss: 2.661477651012833

Epoch: 6| Step: 9
Training loss: 2.8504094549150207
Validation loss: 2.668329023258177

Epoch: 6| Step: 10
Training loss: 2.687999678889891
Validation loss: 2.662408897909153

Epoch: 6| Step: 11
Training loss: 3.403637365298061
Validation loss: 2.6703347683671463

Epoch: 6| Step: 12
Training loss: 3.422945316788399
Validation loss: 2.6709584807044697

Epoch: 6| Step: 13
Training loss: 2.8766955475961598
Validation loss: 2.683447028902732

Epoch: 74| Step: 0
Training loss: 3.193178989553541
Validation loss: 2.6768375882611584

Epoch: 6| Step: 1
Training loss: 3.047335545872522
Validation loss: 2.6695280150565877

Epoch: 6| Step: 2
Training loss: 3.173176014737886
Validation loss: 2.664316482521182

Epoch: 6| Step: 3
Training loss: 3.1878050115920127
Validation loss: 2.6633355401004173

Epoch: 6| Step: 4
Training loss: 2.4919661181428947
Validation loss: 2.664563668450985

Epoch: 6| Step: 5
Training loss: 2.9303270786244537
Validation loss: 2.6641692386557185

Epoch: 6| Step: 6
Training loss: 2.5166193732392634
Validation loss: 2.664054076931113

Epoch: 6| Step: 7
Training loss: 2.2283203681372705
Validation loss: 2.6629429385354273

Epoch: 6| Step: 8
Training loss: 2.790212271350615
Validation loss: 2.6614953056910626

Epoch: 6| Step: 9
Training loss: 3.1786471827803817
Validation loss: 2.662981273354341

Epoch: 6| Step: 10
Training loss: 3.499070180271445
Validation loss: 2.664158574797744

Epoch: 6| Step: 11
Training loss: 3.2017837321378866
Validation loss: 2.674919112282769

Epoch: 6| Step: 12
Training loss: 3.1692524107264646
Validation loss: 2.6704990960755146

Epoch: 6| Step: 13
Training loss: 3.2307072727843784
Validation loss: 2.6730683348471356

Epoch: 75| Step: 0
Training loss: 2.811623500303427
Validation loss: 2.672550883762304

Epoch: 6| Step: 1
Training loss: 2.215825584812205
Validation loss: 2.671801058663555

Epoch: 6| Step: 2
Training loss: 3.034312009304912
Validation loss: 2.669490569419687

Epoch: 6| Step: 3
Training loss: 3.3995600808466575
Validation loss: 2.6670376368358752

Epoch: 6| Step: 4
Training loss: 3.609512392541971
Validation loss: 2.663390299048603

Epoch: 6| Step: 5
Training loss: 3.269749860849734
Validation loss: 2.6551174463809244

Epoch: 6| Step: 6
Training loss: 3.1794724450270873
Validation loss: 2.6574875652841254

Epoch: 6| Step: 7
Training loss: 2.8964275784110294
Validation loss: 2.65592960015377

Epoch: 6| Step: 8
Training loss: 3.2680867968347336
Validation loss: 2.658046154221033

Epoch: 6| Step: 9
Training loss: 2.810473920287504
Validation loss: 2.6567054662059664

Epoch: 6| Step: 10
Training loss: 2.932916189646114
Validation loss: 2.659074185081821

Epoch: 6| Step: 11
Training loss: 2.2252990350260986
Validation loss: 2.6597369957482737

Epoch: 6| Step: 12
Training loss: 3.283443480707932
Validation loss: 2.6633923723758888

Epoch: 6| Step: 13
Training loss: 2.5367654122354057
Validation loss: 2.668091591005843

Epoch: 76| Step: 0
Training loss: 2.236998824779626
Validation loss: 2.686673188139659

Epoch: 6| Step: 1
Training loss: 3.6382209142097546
Validation loss: 2.7073959163916035

Epoch: 6| Step: 2
Training loss: 3.232329085478998
Validation loss: 2.7413116347385977

Epoch: 6| Step: 3
Training loss: 3.118621725681957
Validation loss: 2.7388066544966096

Epoch: 6| Step: 4
Training loss: 3.0084491006515197
Validation loss: 2.702238105375938

Epoch: 6| Step: 5
Training loss: 2.4728429160386116
Validation loss: 2.6767337501076067

Epoch: 6| Step: 6
Training loss: 3.0152891298144118
Validation loss: 2.6537689802245246

Epoch: 6| Step: 7
Training loss: 3.4260483466910894
Validation loss: 2.656396589390404

Epoch: 6| Step: 8
Training loss: 3.073095404820108
Validation loss: 2.654317395273717

Epoch: 6| Step: 9
Training loss: 2.8253145532270407
Validation loss: 2.659073610472059

Epoch: 6| Step: 10
Training loss: 3.1255799327607443
Validation loss: 2.665213766562697

Epoch: 6| Step: 11
Training loss: 3.3979295372889737
Validation loss: 2.663812768225624

Epoch: 6| Step: 12
Training loss: 2.4746425177831872
Validation loss: 2.6607318647096507

Epoch: 6| Step: 13
Training loss: 2.778735535069619
Validation loss: 2.6604837937504806

Epoch: 77| Step: 0
Training loss: 3.331376614052113
Validation loss: 2.6593891373867535

Epoch: 6| Step: 1
Training loss: 3.1356868352908127
Validation loss: 2.655334616050882

Epoch: 6| Step: 2
Training loss: 3.3544523855899255
Validation loss: 2.6539309334196246

Epoch: 6| Step: 3
Training loss: 2.6921499080324884
Validation loss: 2.655962867346223

Epoch: 6| Step: 4
Training loss: 3.7218071688757495
Validation loss: 2.679116072786465

Epoch: 6| Step: 5
Training loss: 3.029360782187758
Validation loss: 2.6882426921010434

Epoch: 6| Step: 6
Training loss: 3.0328607114156485
Validation loss: 2.686291578686992

Epoch: 6| Step: 7
Training loss: 3.1892300566895746
Validation loss: 2.6783069757020623

Epoch: 6| Step: 8
Training loss: 3.225187512054925
Validation loss: 2.6827855198033066

Epoch: 6| Step: 9
Training loss: 1.9782776157510578
Validation loss: 2.666360040181589

Epoch: 6| Step: 10
Training loss: 2.775332123410305
Validation loss: 2.6656193548056497

Epoch: 6| Step: 11
Training loss: 2.8102704005617825
Validation loss: 2.6695804286547453

Epoch: 6| Step: 12
Training loss: 2.856141810799316
Validation loss: 2.663631711474534

Epoch: 6| Step: 13
Training loss: 2.0426046072460937
Validation loss: 2.6588929290724446

Epoch: 78| Step: 0
Training loss: 2.526802394143692
Validation loss: 2.6557322548282913

Epoch: 6| Step: 1
Training loss: 3.356074641528659
Validation loss: 2.6568345277865273

Epoch: 6| Step: 2
Training loss: 3.66390932328242
Validation loss: 2.6571844379155753

Epoch: 6| Step: 3
Training loss: 3.346561996398654
Validation loss: 2.657985334184437

Epoch: 6| Step: 4
Training loss: 3.0244230492581208
Validation loss: 2.653893698545156

Epoch: 6| Step: 5
Training loss: 2.921293639419009
Validation loss: 2.6486859945674626

Epoch: 6| Step: 6
Training loss: 2.50796422766768
Validation loss: 2.6549091842124137

Epoch: 6| Step: 7
Training loss: 2.8747667964395185
Validation loss: 2.6498734648096245

Epoch: 6| Step: 8
Training loss: 3.249755703474214
Validation loss: 2.650019248943572

Epoch: 6| Step: 9
Training loss: 3.5040453284654336
Validation loss: 2.650433678276237

Epoch: 6| Step: 10
Training loss: 2.794024160019899
Validation loss: 2.655699632487094

Epoch: 6| Step: 11
Training loss: 2.682403344850989
Validation loss: 2.6517356765005955

Epoch: 6| Step: 12
Training loss: 2.6442566226148845
Validation loss: 2.6498585214149926

Epoch: 6| Step: 13
Training loss: 1.9941859973374922
Validation loss: 2.65039840231482

Epoch: 79| Step: 0
Training loss: 3.240803103578579
Validation loss: 2.6473613399864955

Epoch: 6| Step: 1
Training loss: 2.4528730712596887
Validation loss: 2.6486131442446794

Epoch: 6| Step: 2
Training loss: 3.6274948742631152
Validation loss: 2.6471070903970255

Epoch: 6| Step: 3
Training loss: 2.9907436622349035
Validation loss: 2.650534943406182

Epoch: 6| Step: 4
Training loss: 2.276653204729634
Validation loss: 2.6505495599388023

Epoch: 6| Step: 5
Training loss: 3.526025063021554
Validation loss: 2.650927511305097

Epoch: 6| Step: 6
Training loss: 2.8693694665481964
Validation loss: 2.6507268989097663

Epoch: 6| Step: 7
Training loss: 3.2846399144153695
Validation loss: 2.649650686687236

Epoch: 6| Step: 8
Training loss: 2.664105546441309
Validation loss: 2.6532983931744623

Epoch: 6| Step: 9
Training loss: 3.2029055636535113
Validation loss: 2.651447853866551

Epoch: 6| Step: 10
Training loss: 2.6721516962277025
Validation loss: 2.6517461341213604

Epoch: 6| Step: 11
Training loss: 2.767440717108712
Validation loss: 2.6591773954178715

Epoch: 6| Step: 12
Training loss: 3.249160071189613
Validation loss: 2.661678362828311

Epoch: 6| Step: 13
Training loss: 2.408368651803183
Validation loss: 2.6638211169909454

Epoch: 80| Step: 0
Training loss: 2.1097151870504205
Validation loss: 2.6553880966474206

Epoch: 6| Step: 1
Training loss: 2.8172585815331486
Validation loss: 2.6521999147297866

Epoch: 6| Step: 2
Training loss: 3.3813302755081276
Validation loss: 2.649350574861938

Epoch: 6| Step: 3
Training loss: 3.178557473974074
Validation loss: 2.6468238203903764

Epoch: 6| Step: 4
Training loss: 2.717368114538343
Validation loss: 2.6468685438454616

Epoch: 6| Step: 5
Training loss: 2.715092797142434
Validation loss: 2.643900265807864

Epoch: 6| Step: 6
Training loss: 2.987799153054251
Validation loss: 2.642620254439194

Epoch: 6| Step: 7
Training loss: 3.283938804864774
Validation loss: 2.6452542802501124

Epoch: 6| Step: 8
Training loss: 3.093079619553617
Validation loss: 2.643009337206887

Epoch: 6| Step: 9
Training loss: 2.5360062736168887
Validation loss: 2.647411615643499

Epoch: 6| Step: 10
Training loss: 3.619817778495448
Validation loss: 2.646448682161328

Epoch: 6| Step: 11
Training loss: 3.0938005539588005
Validation loss: 2.640337641085446

Epoch: 6| Step: 12
Training loss: 2.941765144003781
Validation loss: 2.643697016845041

Epoch: 6| Step: 13
Training loss: 3.0252744628986474
Validation loss: 2.6421796088045877

Epoch: 81| Step: 0
Training loss: 3.431688841392556
Validation loss: 2.6411266875786965

Epoch: 6| Step: 1
Training loss: 3.167786918718231
Validation loss: 2.644678707043602

Epoch: 6| Step: 2
Training loss: 2.6227085466258795
Validation loss: 2.6454237825318203

Epoch: 6| Step: 3
Training loss: 3.1455528353169506
Validation loss: 2.6497536114974443

Epoch: 6| Step: 4
Training loss: 2.6152207913377157
Validation loss: 2.652802793781473

Epoch: 6| Step: 5
Training loss: 2.8981150321797258
Validation loss: 2.660798203444103

Epoch: 6| Step: 6
Training loss: 2.7252998816993386
Validation loss: 2.660979279575443

Epoch: 6| Step: 7
Training loss: 3.30332626552448
Validation loss: 2.669155256208753

Epoch: 6| Step: 8
Training loss: 2.783050982683716
Validation loss: 2.663356474901988

Epoch: 6| Step: 9
Training loss: 2.7878621400711756
Validation loss: 2.656764874874589

Epoch: 6| Step: 10
Training loss: 2.720371069981508
Validation loss: 2.642958779929869

Epoch: 6| Step: 11
Training loss: 2.834108209303416
Validation loss: 2.638340957748535

Epoch: 6| Step: 12
Training loss: 3.2897197583163273
Validation loss: 2.6428239654965244

Epoch: 6| Step: 13
Training loss: 3.511821265840625
Validation loss: 2.6363916648914993

Epoch: 82| Step: 0
Training loss: 2.9209570437220624
Validation loss: 2.638601412295748

Epoch: 6| Step: 1
Training loss: 3.376113849085197
Validation loss: 2.6357577556048866

Epoch: 6| Step: 2
Training loss: 2.5495177055981486
Validation loss: 2.63705913453744

Epoch: 6| Step: 3
Training loss: 3.0014999136885807
Validation loss: 2.6377884532938793

Epoch: 6| Step: 4
Training loss: 2.9147768346773444
Validation loss: 2.636046024187807

Epoch: 6| Step: 5
Training loss: 2.7207840950576996
Validation loss: 2.643243818102548

Epoch: 6| Step: 6
Training loss: 3.511040304840831
Validation loss: 2.6361765289940706

Epoch: 6| Step: 7
Training loss: 2.8709532411408905
Validation loss: 2.640892901115936

Epoch: 6| Step: 8
Training loss: 2.8125895168045876
Validation loss: 2.6476696548222067

Epoch: 6| Step: 9
Training loss: 3.1961744866609094
Validation loss: 2.6618095024835444

Epoch: 6| Step: 10
Training loss: 3.385722329450345
Validation loss: 2.668249339953529

Epoch: 6| Step: 11
Training loss: 2.746028112546822
Validation loss: 2.6547841534037633

Epoch: 6| Step: 12
Training loss: 2.847033271619254
Validation loss: 2.6608643401246392

Epoch: 6| Step: 13
Training loss: 2.5705246301556928
Validation loss: 2.6520008147753837

Epoch: 83| Step: 0
Training loss: 3.3495268074736133
Validation loss: 2.653028095981752

Epoch: 6| Step: 1
Training loss: 3.6967627359146236
Validation loss: 2.6412503256363555

Epoch: 6| Step: 2
Training loss: 3.091188854163474
Validation loss: 2.6438626647058974

Epoch: 6| Step: 3
Training loss: 3.0360751730919047
Validation loss: 2.6421294276492193

Epoch: 6| Step: 4
Training loss: 2.6804940035994336
Validation loss: 2.633214117152519

Epoch: 6| Step: 5
Training loss: 2.833790704799131
Validation loss: 2.6322873478098474

Epoch: 6| Step: 6
Training loss: 3.6009052198162075
Validation loss: 2.6315125339462986

Epoch: 6| Step: 7
Training loss: 2.69201192698451
Validation loss: 2.6330305318183416

Epoch: 6| Step: 8
Training loss: 2.804061182162716
Validation loss: 2.6336609196467236

Epoch: 6| Step: 9
Training loss: 2.592340385062808
Validation loss: 2.632233760168292

Epoch: 6| Step: 10
Training loss: 2.2801844577460035
Validation loss: 2.632866356289918

Epoch: 6| Step: 11
Training loss: 2.988285558360865
Validation loss: 2.637520345712327

Epoch: 6| Step: 12
Training loss: 3.357802621889917
Validation loss: 2.63810064384184

Epoch: 6| Step: 13
Training loss: 1.6791358219213455
Validation loss: 2.643351183082058

Epoch: 84| Step: 0
Training loss: 3.6130343296121015
Validation loss: 2.6556509598345945

Epoch: 6| Step: 1
Training loss: 2.6856129253241185
Validation loss: 2.643223439785322

Epoch: 6| Step: 2
Training loss: 3.253313429594388
Validation loss: 2.6363322541616108

Epoch: 6| Step: 3
Training loss: 3.0292716895310234
Validation loss: 2.635223816117434

Epoch: 6| Step: 4
Training loss: 3.0511421253930706
Validation loss: 2.633502183272193

Epoch: 6| Step: 5
Training loss: 2.705491898493004
Validation loss: 2.6297905020571952

Epoch: 6| Step: 6
Training loss: 2.8017196041040138
Validation loss: 2.63404202427331

Epoch: 6| Step: 7
Training loss: 2.6347218277262345
Validation loss: 2.628256472796541

Epoch: 6| Step: 8
Training loss: 3.476347430145342
Validation loss: 2.6317001538787768

Epoch: 6| Step: 9
Training loss: 2.615638023717763
Validation loss: 2.633425952497036

Epoch: 6| Step: 10
Training loss: 2.7216832790891714
Validation loss: 2.6315928873460392

Epoch: 6| Step: 11
Training loss: 3.3938636606197075
Validation loss: 2.6302423043475183

Epoch: 6| Step: 12
Training loss: 2.8077053314968126
Validation loss: 2.6331920353261005

Epoch: 6| Step: 13
Training loss: 2.4363718601085425
Validation loss: 2.6384450077879356

Epoch: 85| Step: 0
Training loss: 2.4094811085888357
Validation loss: 2.639042903102439

Epoch: 6| Step: 1
Training loss: 2.6276106794948917
Validation loss: 2.6494786168495015

Epoch: 6| Step: 2
Training loss: 3.104069770137008
Validation loss: 2.6624681802778114

Epoch: 6| Step: 3
Training loss: 3.2678101452106425
Validation loss: 2.6671055364047356

Epoch: 6| Step: 4
Training loss: 2.8257035484947512
Validation loss: 2.6522858980506134

Epoch: 6| Step: 5
Training loss: 3.184965135512273
Validation loss: 2.647845839910266

Epoch: 6| Step: 6
Training loss: 3.2986864654678745
Validation loss: 2.6378329295281993

Epoch: 6| Step: 7
Training loss: 2.3069746662232125
Validation loss: 2.630137405405732

Epoch: 6| Step: 8
Training loss: 2.690386796391325
Validation loss: 2.6295848785344944

Epoch: 6| Step: 9
Training loss: 3.2948040717863574
Validation loss: 2.629129089234622

Epoch: 6| Step: 10
Training loss: 3.4012515289067675
Validation loss: 2.6287929187030756

Epoch: 6| Step: 11
Training loss: 2.32775220510456
Validation loss: 2.6255621281356043

Epoch: 6| Step: 12
Training loss: 3.05534305026214
Validation loss: 2.629604647932249

Epoch: 6| Step: 13
Training loss: 3.8944141978711095
Validation loss: 2.6291101275427926

Epoch: 86| Step: 0
Training loss: 3.0778339074070376
Validation loss: 2.624972420941635

Epoch: 6| Step: 1
Training loss: 3.013166779610456
Validation loss: 2.6253853967662732

Epoch: 6| Step: 2
Training loss: 2.8394849044148662
Validation loss: 2.6299773441441365

Epoch: 6| Step: 3
Training loss: 2.8562398096482946
Validation loss: 2.625139687840744

Epoch: 6| Step: 4
Training loss: 3.3406911388448126
Validation loss: 2.628463900254506

Epoch: 6| Step: 5
Training loss: 3.056087085461699
Validation loss: 2.626109488896405

Epoch: 6| Step: 6
Training loss: 3.298563158902531
Validation loss: 2.6273637428655006

Epoch: 6| Step: 7
Training loss: 2.6320597763984055
Validation loss: 2.6276540684512275

Epoch: 6| Step: 8
Training loss: 3.132422063760672
Validation loss: 2.6241966889612813

Epoch: 6| Step: 9
Training loss: 2.9964242924432845
Validation loss: 2.6224348090982383

Epoch: 6| Step: 10
Training loss: 2.199875728391818
Validation loss: 2.6380994718807553

Epoch: 6| Step: 11
Training loss: 2.79022004712477
Validation loss: 2.653084549957324

Epoch: 6| Step: 12
Training loss: 3.236263295216691
Validation loss: 2.6592264735017737

Epoch: 6| Step: 13
Training loss: 3.056510673904939
Validation loss: 2.6584095302244823

Epoch: 87| Step: 0
Training loss: 3.413782872111934
Validation loss: 2.6574384893327125

Epoch: 6| Step: 1
Training loss: 2.3309592589848322
Validation loss: 2.657170382731818

Epoch: 6| Step: 2
Training loss: 2.755666703072792
Validation loss: 2.6646615281337644

Epoch: 6| Step: 3
Training loss: 2.944274557558803
Validation loss: 2.6633443908952645

Epoch: 6| Step: 4
Training loss: 2.8587522401788403
Validation loss: 2.6608517139303114

Epoch: 6| Step: 5
Training loss: 2.8978642721990777
Validation loss: 2.6663642024070504

Epoch: 6| Step: 6
Training loss: 2.235451392348147
Validation loss: 2.659707285254179

Epoch: 6| Step: 7
Training loss: 3.4418598616519787
Validation loss: 2.656171983107596

Epoch: 6| Step: 8
Training loss: 2.9053458171131026
Validation loss: 2.6530951153163866

Epoch: 6| Step: 9
Training loss: 3.2554292080013205
Validation loss: 2.671279022312349

Epoch: 6| Step: 10
Training loss: 2.962518355558163
Validation loss: 2.67177288131568

Epoch: 6| Step: 11
Training loss: 3.3962626897626067
Validation loss: 2.6772488462729136

Epoch: 6| Step: 12
Training loss: 3.485581261912916
Validation loss: 2.6796299580719958

Epoch: 6| Step: 13
Training loss: 2.494711623105664
Validation loss: 2.678364935619702

Epoch: 88| Step: 0
Training loss: 3.2964104058385546
Validation loss: 2.6621159042066345

Epoch: 6| Step: 1
Training loss: 3.267364768606029
Validation loss: 2.6485028612306225

Epoch: 6| Step: 2
Training loss: 2.791161524681141
Validation loss: 2.6484506742064027

Epoch: 6| Step: 3
Training loss: 3.0608070520992765
Validation loss: 2.647501099070422

Epoch: 6| Step: 4
Training loss: 3.657019118574329
Validation loss: 2.647806922881541

Epoch: 6| Step: 5
Training loss: 3.4481448341008
Validation loss: 2.6468135312252286

Epoch: 6| Step: 6
Training loss: 2.3997699627304776
Validation loss: 2.647029410311495

Epoch: 6| Step: 7
Training loss: 3.0458525678355204
Validation loss: 2.6481885348650542

Epoch: 6| Step: 8
Training loss: 3.104325224306661
Validation loss: 2.6498152890012494

Epoch: 6| Step: 9
Training loss: 2.6856835902700635
Validation loss: 2.6470594451770055

Epoch: 6| Step: 10
Training loss: 2.0820051409889677
Validation loss: 2.647927890565749

Epoch: 6| Step: 11
Training loss: 3.260570355937824
Validation loss: 2.6448943552178608

Epoch: 6| Step: 12
Training loss: 2.894166828232034
Validation loss: 2.643156675472905

Epoch: 6| Step: 13
Training loss: 2.0715873967434226
Validation loss: 2.647158712186293

Epoch: 89| Step: 0
Training loss: 2.010334019782223
Validation loss: 2.6487518766700333

Epoch: 6| Step: 1
Training loss: 3.41808621449942
Validation loss: 2.6488403348872707

Epoch: 6| Step: 2
Training loss: 2.1986752205993247
Validation loss: 2.649005451118603

Epoch: 6| Step: 3
Training loss: 3.238614018072645
Validation loss: 2.6503900968710843

Epoch: 6| Step: 4
Training loss: 3.108688968907587
Validation loss: 2.6618048496491764

Epoch: 6| Step: 5
Training loss: 3.642054723203857
Validation loss: 2.671121846751336

Epoch: 6| Step: 6
Training loss: 2.8926790105212428
Validation loss: 2.666802179510645

Epoch: 6| Step: 7
Training loss: 2.702290665302812
Validation loss: 2.66771239848388

Epoch: 6| Step: 8
Training loss: 2.4504418733681197
Validation loss: 2.659824621652142

Epoch: 6| Step: 9
Training loss: 2.5083265876890537
Validation loss: 2.6595722093600926

Epoch: 6| Step: 10
Training loss: 3.1562790066736417
Validation loss: 2.6495455382569473

Epoch: 6| Step: 11
Training loss: 3.3305361614523417
Validation loss: 2.6496315090253715

Epoch: 6| Step: 12
Training loss: 3.363911249611629
Validation loss: 2.6486536406610024

Epoch: 6| Step: 13
Training loss: 3.5045127386296206
Validation loss: 2.6428227927198824

Epoch: 90| Step: 0
Training loss: 2.572351452808332
Validation loss: 2.643375316592115

Epoch: 6| Step: 1
Training loss: 2.8467850470961302
Validation loss: 2.6435662112545177

Epoch: 6| Step: 2
Training loss: 2.5129063291932145
Validation loss: 2.6475952853676565

Epoch: 6| Step: 3
Training loss: 2.63459206045494
Validation loss: 2.6463914821386916

Epoch: 6| Step: 4
Training loss: 3.0534429722331766
Validation loss: 2.649317817815691

Epoch: 6| Step: 5
Training loss: 3.2448247639461614
Validation loss: 2.648705723994128

Epoch: 6| Step: 6
Training loss: 2.604602034733594
Validation loss: 2.6464834799241137

Epoch: 6| Step: 7
Training loss: 3.2223094036833904
Validation loss: 2.6434139409998507

Epoch: 6| Step: 8
Training loss: 3.3248597366462818
Validation loss: 2.6444980096190394

Epoch: 6| Step: 9
Training loss: 2.9104990098063914
Validation loss: 2.642540169415797

Epoch: 6| Step: 10
Training loss: 3.6385880039314036
Validation loss: 2.6417396854277486

Epoch: 6| Step: 11
Training loss: 2.9293274518340144
Validation loss: 2.639253765506964

Epoch: 6| Step: 12
Training loss: 3.2620365559057474
Validation loss: 2.637143768365222

Epoch: 6| Step: 13
Training loss: 2.8390460671519815
Validation loss: 2.6392258050328516

Epoch: 91| Step: 0
Training loss: 2.903708874940412
Validation loss: 2.6375992117167466

Epoch: 6| Step: 1
Training loss: 3.053514025920651
Validation loss: 2.6444953747224758

Epoch: 6| Step: 2
Training loss: 2.9035098376165753
Validation loss: 2.677353022564549

Epoch: 6| Step: 3
Training loss: 3.141760018443288
Validation loss: 2.684385440447072

Epoch: 6| Step: 4
Training loss: 3.049264450180369
Validation loss: 2.6881131433576693

Epoch: 6| Step: 5
Training loss: 3.4688629956785677
Validation loss: 2.6920693261463726

Epoch: 6| Step: 6
Training loss: 2.8657081383944965
Validation loss: 2.6598220857925696

Epoch: 6| Step: 7
Training loss: 2.751658979605788
Validation loss: 2.639481316908284

Epoch: 6| Step: 8
Training loss: 2.7435389826448597
Validation loss: 2.6225591856468724

Epoch: 6| Step: 9
Training loss: 3.167965589114869
Validation loss: 2.6182605221838324

Epoch: 6| Step: 10
Training loss: 3.0403149531994935
Validation loss: 2.6150014294879806

Epoch: 6| Step: 11
Training loss: 2.97654551904195
Validation loss: 2.618715868325184

Epoch: 6| Step: 12
Training loss: 2.7521671945605313
Validation loss: 2.624534945645377

Epoch: 6| Step: 13
Training loss: 2.9157372946748166
Validation loss: 2.6249148154317274

Epoch: 92| Step: 0
Training loss: 2.6596299153493317
Validation loss: 2.627024073842916

Epoch: 6| Step: 1
Training loss: 2.76784551240086
Validation loss: 2.626822324943268

Epoch: 6| Step: 2
Training loss: 2.7894068059319514
Validation loss: 2.631975057986689

Epoch: 6| Step: 3
Training loss: 2.9408052395301776
Validation loss: 2.6247230018378866

Epoch: 6| Step: 4
Training loss: 3.2968446269150378
Validation loss: 2.622354903399017

Epoch: 6| Step: 5
Training loss: 3.6184090514645666
Validation loss: 2.616236377694299

Epoch: 6| Step: 6
Training loss: 2.5456285293371064
Validation loss: 2.616888850508397

Epoch: 6| Step: 7
Training loss: 2.385953540161016
Validation loss: 2.6087353365479573

Epoch: 6| Step: 8
Training loss: 3.4512924924539847
Validation loss: 2.614672089437119

Epoch: 6| Step: 9
Training loss: 2.6477451375953214
Validation loss: 2.6154717596007195

Epoch: 6| Step: 10
Training loss: 2.8080497289096034
Validation loss: 2.6214896314330645

Epoch: 6| Step: 11
Training loss: 3.5086471821961953
Validation loss: 2.6334963833196348

Epoch: 6| Step: 12
Training loss: 2.796459742572275
Validation loss: 2.637091927199199

Epoch: 6| Step: 13
Training loss: 3.2548363719778
Validation loss: 2.6457104572433945

Epoch: 93| Step: 0
Training loss: 2.465028783076925
Validation loss: 2.631783589473306

Epoch: 6| Step: 1
Training loss: 2.48889123934491
Validation loss: 2.625207124225585

Epoch: 6| Step: 2
Training loss: 3.1622937945661937
Validation loss: 2.622435439637463

Epoch: 6| Step: 3
Training loss: 3.0530181772370026
Validation loss: 2.621787295315048

Epoch: 6| Step: 4
Training loss: 2.792709829426561
Validation loss: 2.6319931029310966

Epoch: 6| Step: 5
Training loss: 2.8971722661221584
Validation loss: 2.627661682323531

Epoch: 6| Step: 6
Training loss: 2.5621620513623657
Validation loss: 2.6208901008420846

Epoch: 6| Step: 7
Training loss: 3.260181763853331
Validation loss: 2.6233318358759465

Epoch: 6| Step: 8
Training loss: 2.9601714821708254
Validation loss: 2.618447674951604

Epoch: 6| Step: 9
Training loss: 2.9492045219027654
Validation loss: 2.6152285433562703

Epoch: 6| Step: 10
Training loss: 2.8888328151477567
Validation loss: 2.6166485513901727

Epoch: 6| Step: 11
Training loss: 3.0950545825982934
Validation loss: 2.612892096765553

Epoch: 6| Step: 12
Training loss: 3.386853348500352
Validation loss: 2.6254671074782787

Epoch: 6| Step: 13
Training loss: 3.4286540566433237
Validation loss: 2.632403232150849

Epoch: 94| Step: 0
Training loss: 3.665380179968852
Validation loss: 2.608738784888967

Epoch: 6| Step: 1
Training loss: 3.612475892088811
Validation loss: 2.606497721893451

Epoch: 6| Step: 2
Training loss: 2.6141618690369683
Validation loss: 2.6043110574049826

Epoch: 6| Step: 3
Training loss: 3.538282295777749
Validation loss: 2.6061464678408446

Epoch: 6| Step: 4
Training loss: 2.675857876982187
Validation loss: 2.603729097746779

Epoch: 6| Step: 5
Training loss: 3.09067698744509
Validation loss: 2.604066217925801

Epoch: 6| Step: 6
Training loss: 3.044221945642843
Validation loss: 2.6038622550653847

Epoch: 6| Step: 7
Training loss: 2.769804818613639
Validation loss: 2.6018647916219337

Epoch: 6| Step: 8
Training loss: 2.5487096064698256
Validation loss: 2.6029946936644195

Epoch: 6| Step: 9
Training loss: 2.7883227139225326
Validation loss: 2.606554680075105

Epoch: 6| Step: 10
Training loss: 2.8268864907253195
Validation loss: 2.611479969963263

Epoch: 6| Step: 11
Training loss: 2.3755873907414573
Validation loss: 2.635306925160482

Epoch: 6| Step: 12
Training loss: 2.226410977745886
Validation loss: 2.6594765356888965

Epoch: 6| Step: 13
Training loss: 3.3686145139495123
Validation loss: 2.683880298347243

Epoch: 95| Step: 0
Training loss: 3.3749660914095214
Validation loss: 2.7211604952274886

Epoch: 6| Step: 1
Training loss: 2.5947706673189836
Validation loss: 2.6855588390572334

Epoch: 6| Step: 2
Training loss: 2.8125376380945095
Validation loss: 2.6475324338714006

Epoch: 6| Step: 3
Training loss: 3.1651964957663408
Validation loss: 2.617941951723187

Epoch: 6| Step: 4
Training loss: 2.6082547461357652
Validation loss: 2.6024589833006044

Epoch: 6| Step: 5
Training loss: 2.708217696631161
Validation loss: 2.597738687849583

Epoch: 6| Step: 6
Training loss: 2.3326484719601006
Validation loss: 2.6006028704193085

Epoch: 6| Step: 7
Training loss: 3.286977220169109
Validation loss: 2.603897967514805

Epoch: 6| Step: 8
Training loss: 3.0719567475254257
Validation loss: 2.607613862101547

Epoch: 6| Step: 9
Training loss: 2.8244572244633988
Validation loss: 2.602360479934685

Epoch: 6| Step: 10
Training loss: 2.460367191171486
Validation loss: 2.605185066851347

Epoch: 6| Step: 11
Training loss: 3.8370526279780224
Validation loss: 2.601353010253253

Epoch: 6| Step: 12
Training loss: 3.4230205412551196
Validation loss: 2.6057718212049177

Epoch: 6| Step: 13
Training loss: 2.409369490205276
Validation loss: 2.602975875470589

Epoch: 96| Step: 0
Training loss: 2.4651644780684845
Validation loss: 2.6031266712986536

Epoch: 6| Step: 1
Training loss: 3.2091375721857665
Validation loss: 2.600636275077685

Epoch: 6| Step: 2
Training loss: 3.053395654245009
Validation loss: 2.600207043837278

Epoch: 6| Step: 3
Training loss: 2.732673246261122
Validation loss: 2.599841921743939

Epoch: 6| Step: 4
Training loss: 2.478833141384948
Validation loss: 2.6023442756246253

Epoch: 6| Step: 5
Training loss: 2.9347690305533947
Validation loss: 2.610805576908087

Epoch: 6| Step: 6
Training loss: 3.075537664037395
Validation loss: 2.6228726483652345

Epoch: 6| Step: 7
Training loss: 3.484088834635161
Validation loss: 2.6481172449870733

Epoch: 6| Step: 8
Training loss: 3.62091412968072
Validation loss: 2.625227521303377

Epoch: 6| Step: 9
Training loss: 2.9413559948603596
Validation loss: 2.6244842757106417

Epoch: 6| Step: 10
Training loss: 2.4338746130751336
Validation loss: 2.6229838799848206

Epoch: 6| Step: 11
Training loss: 3.0862638276826724
Validation loss: 2.6171449180571025

Epoch: 6| Step: 12
Training loss: 2.6175828321989836
Validation loss: 2.625919116674154

Epoch: 6| Step: 13
Training loss: 2.8179466066899703
Validation loss: 2.635255426288478

Epoch: 97| Step: 0
Training loss: 2.9948794852386826
Validation loss: 2.6480831163600738

Epoch: 6| Step: 1
Training loss: 3.20766785560778
Validation loss: 2.6661622688139395

Epoch: 6| Step: 2
Training loss: 2.328583537779874
Validation loss: 2.672348495752505

Epoch: 6| Step: 3
Training loss: 3.4625748664116087
Validation loss: 2.6738792203677617

Epoch: 6| Step: 4
Training loss: 2.883546647870774
Validation loss: 2.6255246940355743

Epoch: 6| Step: 5
Training loss: 2.8258864674531448
Validation loss: 2.604269613548695

Epoch: 6| Step: 6
Training loss: 2.575883295353603
Validation loss: 2.5970444237466377

Epoch: 6| Step: 7
Training loss: 2.7402199318601013
Validation loss: 2.59383641363551

Epoch: 6| Step: 8
Training loss: 3.0975090848159876
Validation loss: 2.5972983537571444

Epoch: 6| Step: 9
Training loss: 3.1977578951079297
Validation loss: 2.594310099575655

Epoch: 6| Step: 10
Training loss: 3.2376304865282823
Validation loss: 2.5983020419831138

Epoch: 6| Step: 11
Training loss: 3.3969459505225403
Validation loss: 2.5969670954051307

Epoch: 6| Step: 12
Training loss: 2.375736925338226
Validation loss: 2.5971032221889514

Epoch: 6| Step: 13
Training loss: 2.7282321485034826
Validation loss: 2.598256965044349

Epoch: 98| Step: 0
Training loss: 3.1098163234036216
Validation loss: 2.5941854260442785

Epoch: 6| Step: 1
Training loss: 3.2660895934281724
Validation loss: 2.596129226003975

Epoch: 6| Step: 2
Training loss: 3.299825929616816
Validation loss: 2.5987386181323697

Epoch: 6| Step: 3
Training loss: 2.8268070416712714
Validation loss: 2.5934901408157343

Epoch: 6| Step: 4
Training loss: 2.904351875897747
Validation loss: 2.597269036492227

Epoch: 6| Step: 5
Training loss: 2.755686862014974
Validation loss: 2.595176328322841

Epoch: 6| Step: 6
Training loss: 2.4402577376647963
Validation loss: 2.593703700360437

Epoch: 6| Step: 7
Training loss: 2.568399105562471
Validation loss: 2.590223358891135

Epoch: 6| Step: 8
Training loss: 3.228616647126376
Validation loss: 2.5961696518749138

Epoch: 6| Step: 9
Training loss: 3.3303159567288905
Validation loss: 2.6033434000107256

Epoch: 6| Step: 10
Training loss: 2.8705070882343273
Validation loss: 2.6118078691641564

Epoch: 6| Step: 11
Training loss: 2.888383480839283
Validation loss: 2.6103914170191893

Epoch: 6| Step: 12
Training loss: 2.1798026762034763
Validation loss: 2.613828232250787

Epoch: 6| Step: 13
Training loss: 3.482448849490664
Validation loss: 2.6295239617660107

Epoch: 99| Step: 0
Training loss: 3.363599666892035
Validation loss: 2.629200480542557

Epoch: 6| Step: 1
Training loss: 2.3335821722948378
Validation loss: 2.6274330145779943

Epoch: 6| Step: 2
Training loss: 3.153238200338073
Validation loss: 2.6544745430905032

Epoch: 6| Step: 3
Training loss: 2.765521290014539
Validation loss: 2.6595988156145216

Epoch: 6| Step: 4
Training loss: 3.053951555268798
Validation loss: 2.6324904765750206

Epoch: 6| Step: 5
Training loss: 2.5803087638207933
Validation loss: 2.6132454352427215

Epoch: 6| Step: 6
Training loss: 3.8285162278163107
Validation loss: 2.6142545881601635

Epoch: 6| Step: 7
Training loss: 2.5040743052819523
Validation loss: 2.5992644225905557

Epoch: 6| Step: 8
Training loss: 2.7819696416891886
Validation loss: 2.593252164623479

Epoch: 6| Step: 9
Training loss: 2.612365744759587
Validation loss: 2.590484937206608

Epoch: 6| Step: 10
Training loss: 3.2916714792980954
Validation loss: 2.594769821588465

Epoch: 6| Step: 11
Training loss: 3.1554281845564267
Validation loss: 2.5907969540396087

Epoch: 6| Step: 12
Training loss: 3.143188493155226
Validation loss: 2.5930376988561346

Epoch: 6| Step: 13
Training loss: 2.3724670957769747
Validation loss: 2.5941221363355456

Epoch: 100| Step: 0
Training loss: 2.8579194580218736
Validation loss: 2.5934309473458796

Epoch: 6| Step: 1
Training loss: 3.309883379768976
Validation loss: 2.5900399134969376

Epoch: 6| Step: 2
Training loss: 3.038019231678888
Validation loss: 2.593826424275479

Epoch: 6| Step: 3
Training loss: 2.9356979361706346
Validation loss: 2.590146313625795

Epoch: 6| Step: 4
Training loss: 2.595403488925124
Validation loss: 2.5887089219678585

Epoch: 6| Step: 5
Training loss: 3.0487258375898754
Validation loss: 2.591050834148954

Epoch: 6| Step: 6
Training loss: 2.797019656399016
Validation loss: 2.5911082793072513

Epoch: 6| Step: 7
Training loss: 3.169881560703289
Validation loss: 2.5991552414231514

Epoch: 6| Step: 8
Training loss: 2.861138638936999
Validation loss: 2.602065480474436

Epoch: 6| Step: 9
Training loss: 2.863150017243287
Validation loss: 2.6048632448567925

Epoch: 6| Step: 10
Training loss: 2.8307767628327127
Validation loss: 2.624348538605991

Epoch: 6| Step: 11
Training loss: 3.0928821309740586
Validation loss: 2.635224849269079

Epoch: 6| Step: 12
Training loss: 2.9466143495854875
Validation loss: 2.623000387807995

Epoch: 6| Step: 13
Training loss: 2.8665226885398227
Validation loss: 2.6151768088823903

Epoch: 101| Step: 0
Training loss: 3.155543030981123
Validation loss: 2.6037949511307117

Epoch: 6| Step: 1
Training loss: 3.3626029186735495
Validation loss: 2.5873759933494846

Epoch: 6| Step: 2
Training loss: 2.582209455426088
Validation loss: 2.588630150020743

Epoch: 6| Step: 3
Training loss: 2.594358074194592
Validation loss: 2.5834006209116667

Epoch: 6| Step: 4
Training loss: 2.450713120043415
Validation loss: 2.5876671402458715

Epoch: 6| Step: 5
Training loss: 3.246140609384627
Validation loss: 2.587087619031774

Epoch: 6| Step: 6
Training loss: 2.4983112353398824
Validation loss: 2.589181333020357

Epoch: 6| Step: 7
Training loss: 2.855845122575057
Validation loss: 2.586399690506751

Epoch: 6| Step: 8
Training loss: 2.4418136378853905
Validation loss: 2.5883985114910466

Epoch: 6| Step: 9
Training loss: 2.6048171388141923
Validation loss: 2.5848221757451113

Epoch: 6| Step: 10
Training loss: 2.729723478013562
Validation loss: 2.584712442048134

Epoch: 6| Step: 11
Training loss: 2.7524214400913447
Validation loss: 2.5865136383871814

Epoch: 6| Step: 12
Training loss: 3.962885330670441
Validation loss: 2.5916417609117612

Epoch: 6| Step: 13
Training loss: 3.7138924809732297
Validation loss: 2.5876645723113327

Epoch: 102| Step: 0
Training loss: 3.050795473268301
Validation loss: 2.5855942622790278

Epoch: 6| Step: 1
Training loss: 3.2209074326874725
Validation loss: 2.580117446577294

Epoch: 6| Step: 2
Training loss: 3.0724056185324944
Validation loss: 2.5851780150026133

Epoch: 6| Step: 3
Training loss: 3.4450152002893413
Validation loss: 2.587466271919601

Epoch: 6| Step: 4
Training loss: 2.6425960791091394
Validation loss: 2.582689740661146

Epoch: 6| Step: 5
Training loss: 3.3622702254169856
Validation loss: 2.5845652576034186

Epoch: 6| Step: 6
Training loss: 3.280186653408792
Validation loss: 2.5844128520187604

Epoch: 6| Step: 7
Training loss: 2.7449403513835793
Validation loss: 2.584091576065871

Epoch: 6| Step: 8
Training loss: 2.8986689637089356
Validation loss: 2.585638502051913

Epoch: 6| Step: 9
Training loss: 2.132950551242722
Validation loss: 2.588003970338129

Epoch: 6| Step: 10
Training loss: 2.07702630620615
Validation loss: 2.5834238239625846

Epoch: 6| Step: 11
Training loss: 2.7553660318185162
Validation loss: 2.5815244038247718

Epoch: 6| Step: 12
Training loss: 2.8548160751610685
Validation loss: 2.5828877784940025

Epoch: 6| Step: 13
Training loss: 3.3237421969479612
Validation loss: 2.5834352656435033

Epoch: 103| Step: 0
Training loss: 2.794969047825396
Validation loss: 2.5828343848038324

Epoch: 6| Step: 1
Training loss: 2.8010738970083358
Validation loss: 2.5871872835655267

Epoch: 6| Step: 2
Training loss: 2.9561843768007963
Validation loss: 2.586327665902838

Epoch: 6| Step: 3
Training loss: 3.4069554709527226
Validation loss: 2.586716468695485

Epoch: 6| Step: 4
Training loss: 2.842034629498049
Validation loss: 2.5932819879731057

Epoch: 6| Step: 5
Training loss: 2.50669203591529
Validation loss: 2.5924518013454496

Epoch: 6| Step: 6
Training loss: 2.7324818188061566
Validation loss: 2.599108347623079

Epoch: 6| Step: 7
Training loss: 2.302395162276964
Validation loss: 2.6125745231706063

Epoch: 6| Step: 8
Training loss: 3.002644168336959
Validation loss: 2.6362967632549057

Epoch: 6| Step: 9
Training loss: 2.8832883364597013
Validation loss: 2.6551521343951845

Epoch: 6| Step: 10
Training loss: 2.328487803205444
Validation loss: 2.674358139720948

Epoch: 6| Step: 11
Training loss: 3.656058281982781
Validation loss: 2.6519466626474713

Epoch: 6| Step: 12
Training loss: 3.1372486393763173
Validation loss: 2.5993291098938847

Epoch: 6| Step: 13
Training loss: 3.8994056248734785
Validation loss: 2.57745674349956

Epoch: 104| Step: 0
Training loss: 2.5894272413239094
Validation loss: 2.5815246481205705

Epoch: 6| Step: 1
Training loss: 3.1711581317374216
Validation loss: 2.588892909265498

Epoch: 6| Step: 2
Training loss: 3.3373561585250706
Validation loss: 2.5928853868808384

Epoch: 6| Step: 3
Training loss: 3.5332599422342215
Validation loss: 2.597356192743839

Epoch: 6| Step: 4
Training loss: 2.673763031930004
Validation loss: 2.6063163780544936

Epoch: 6| Step: 5
Training loss: 2.9363694957778836
Validation loss: 2.6142397539882753

Epoch: 6| Step: 6
Training loss: 2.944519745765534
Validation loss: 2.6213355643539633

Epoch: 6| Step: 7
Training loss: 2.991204401570153
Validation loss: 2.621081011448862

Epoch: 6| Step: 8
Training loss: 2.8903519785021596
Validation loss: 2.6202356480969864

Epoch: 6| Step: 9
Training loss: 2.926312509135524
Validation loss: 2.6099010445957216

Epoch: 6| Step: 10
Training loss: 3.266384784707334
Validation loss: 2.600904689070892

Epoch: 6| Step: 11
Training loss: 2.088851208155337
Validation loss: 2.5916611104947265

Epoch: 6| Step: 12
Training loss: 2.7541374812885837
Validation loss: 2.583303450042076

Epoch: 6| Step: 13
Training loss: 3.254874462044869
Validation loss: 2.5815571412419334

Epoch: 105| Step: 0
Training loss: 2.8867486479866638
Validation loss: 2.584354679707135

Epoch: 6| Step: 1
Training loss: 2.7451640871127068
Validation loss: 2.6033737685177902

Epoch: 6| Step: 2
Training loss: 2.7127747040624697
Validation loss: 2.6526717036790477

Epoch: 6| Step: 3
Training loss: 2.9321137414392395
Validation loss: 2.709153404427332

Epoch: 6| Step: 4
Training loss: 2.7742228510919507
Validation loss: 2.674494453050436

Epoch: 6| Step: 5
Training loss: 2.775737743428617
Validation loss: 2.6551111876980147

Epoch: 6| Step: 6
Training loss: 2.8039440136542964
Validation loss: 2.626917486882641

Epoch: 6| Step: 7
Training loss: 2.796526583488779
Validation loss: 2.5922253077610846

Epoch: 6| Step: 8
Training loss: 3.1752992383861867
Validation loss: 2.585298877774375

Epoch: 6| Step: 9
Training loss: 3.061847227943554
Validation loss: 2.588916743384786

Epoch: 6| Step: 10
Training loss: 2.6642404983435553
Validation loss: 2.5996473656962737

Epoch: 6| Step: 11
Training loss: 3.2273042948371957
Validation loss: 2.59705165378037

Epoch: 6| Step: 12
Training loss: 3.4662738932113815
Validation loss: 2.5891377755984095

Epoch: 6| Step: 13
Training loss: 3.216046281064034
Validation loss: 2.589653833116492

Epoch: 106| Step: 0
Training loss: 2.737278034843933
Validation loss: 2.5776029354657584

Epoch: 6| Step: 1
Training loss: 2.365752839800354
Validation loss: 2.577336597183098

Epoch: 6| Step: 2
Training loss: 2.859074644562669
Validation loss: 2.5775081449687334

Epoch: 6| Step: 3
Training loss: 2.8806468406771293
Validation loss: 2.572855739728197

Epoch: 6| Step: 4
Training loss: 2.4702740564316734
Validation loss: 2.576809047279096

Epoch: 6| Step: 5
Training loss: 3.3695049055782396
Validation loss: 2.5775305586284722

Epoch: 6| Step: 6
Training loss: 3.1186172915797687
Validation loss: 2.582356553255111

Epoch: 6| Step: 7
Training loss: 3.063709253844079
Validation loss: 2.5773390500776117

Epoch: 6| Step: 8
Training loss: 3.1681162544652053
Validation loss: 2.581206833502488

Epoch: 6| Step: 9
Training loss: 2.8782956680575382
Validation loss: 2.584373119647338

Epoch: 6| Step: 10
Training loss: 3.1727961062501224
Validation loss: 2.586130765815827

Epoch: 6| Step: 11
Training loss: 2.836038382761435
Validation loss: 2.5850738430442832

Epoch: 6| Step: 12
Training loss: 3.0327984502467906
Validation loss: 2.5905794409010694

Epoch: 6| Step: 13
Training loss: 3.0375089229248604
Validation loss: 2.601528207038705

Epoch: 107| Step: 0
Training loss: 3.363273594013499
Validation loss: 2.608697897825542

Epoch: 6| Step: 1
Training loss: 2.7071649427551905
Validation loss: 2.6215178759353774

Epoch: 6| Step: 2
Training loss: 2.4613509542317327
Validation loss: 2.645015679030005

Epoch: 6| Step: 3
Training loss: 2.806029102492639
Validation loss: 2.668442348042067

Epoch: 6| Step: 4
Training loss: 3.3331424340579527
Validation loss: 2.676927736214382

Epoch: 6| Step: 5
Training loss: 2.593965452506804
Validation loss: 2.65174134713293

Epoch: 6| Step: 6
Training loss: 2.8216793731775884
Validation loss: 2.620120158057422

Epoch: 6| Step: 7
Training loss: 3.4233938530385983
Validation loss: 2.6103191675489548

Epoch: 6| Step: 8
Training loss: 2.7336408228935434
Validation loss: 2.609838997473422

Epoch: 6| Step: 9
Training loss: 3.4212342102110114
Validation loss: 2.607506272294051

Epoch: 6| Step: 10
Training loss: 3.066183405268454
Validation loss: 2.5989563983233768

Epoch: 6| Step: 11
Training loss: 2.546734203355164
Validation loss: 2.596645940197988

Epoch: 6| Step: 12
Training loss: 3.144619503322892
Validation loss: 2.6018295064842842

Epoch: 6| Step: 13
Training loss: 2.6390071630463807
Validation loss: 2.6030841291931663

Epoch: 108| Step: 0
Training loss: 3.072910287279307
Validation loss: 2.6079936132376105

Epoch: 6| Step: 1
Training loss: 3.13117051318733
Validation loss: 2.6143504958606094

Epoch: 6| Step: 2
Training loss: 2.3667260655036784
Validation loss: 2.6126385870410975

Epoch: 6| Step: 3
Training loss: 3.328286037220455
Validation loss: 2.6342011076705116

Epoch: 6| Step: 4
Training loss: 3.066954817571877
Validation loss: 2.630781393491614

Epoch: 6| Step: 5
Training loss: 2.8149191730610488
Validation loss: 2.626272824651179

Epoch: 6| Step: 6
Training loss: 2.5058578526885475
Validation loss: 2.623602517108445

Epoch: 6| Step: 7
Training loss: 2.8547312231531206
Validation loss: 2.6096020701004297

Epoch: 6| Step: 8
Training loss: 3.2585480589168094
Validation loss: 2.5856869102182567

Epoch: 6| Step: 9
Training loss: 2.938356964425974
Validation loss: 2.5814901326687614

Epoch: 6| Step: 10
Training loss: 2.9433151474675645
Validation loss: 2.583274940547935

Epoch: 6| Step: 11
Training loss: 3.000541479199379
Validation loss: 2.579802871089635

Epoch: 6| Step: 12
Training loss: 2.8043136134951943
Validation loss: 2.574876815226065

Epoch: 6| Step: 13
Training loss: 3.0497790459817056
Validation loss: 2.5751953821859153

Epoch: 109| Step: 0
Training loss: 2.415620961253749
Validation loss: 2.5681845089017212

Epoch: 6| Step: 1
Training loss: 2.967993067566212
Validation loss: 2.5665399702572818

Epoch: 6| Step: 2
Training loss: 2.981946986074499
Validation loss: 2.564107512237769

Epoch: 6| Step: 3
Training loss: 2.569784649387196
Validation loss: 2.5624669110642664

Epoch: 6| Step: 4
Training loss: 3.0333648854665256
Validation loss: 2.5639096956310885

Epoch: 6| Step: 5
Training loss: 2.9454659743253195
Validation loss: 2.5647673181700354

Epoch: 6| Step: 6
Training loss: 3.0896130269519246
Validation loss: 2.5699840497501554

Epoch: 6| Step: 7
Training loss: 3.280410513891278
Validation loss: 2.569221878352844

Epoch: 6| Step: 8
Training loss: 3.3227708041106885
Validation loss: 2.5683916473950084

Epoch: 6| Step: 9
Training loss: 2.641249272517453
Validation loss: 2.5687173351333437

Epoch: 6| Step: 10
Training loss: 2.6216047218152183
Validation loss: 2.574023822899096

Epoch: 6| Step: 11
Training loss: 3.2125807221360576
Validation loss: 2.5779991976863386

Epoch: 6| Step: 12
Training loss: 3.013062965056735
Validation loss: 2.5854422544847098

Epoch: 6| Step: 13
Training loss: 2.59077853310405
Validation loss: 2.591956938044829

Epoch: 110| Step: 0
Training loss: 3.2299525299363285
Validation loss: 2.6107425722706132

Epoch: 6| Step: 1
Training loss: 2.8124923705951206
Validation loss: 2.629282588485643

Epoch: 6| Step: 2
Training loss: 2.792484353481845
Validation loss: 2.6186959922500503

Epoch: 6| Step: 3
Training loss: 3.2291728029910614
Validation loss: 2.5968824266718182

Epoch: 6| Step: 4
Training loss: 3.0317756747598312
Validation loss: 2.5761515860931907

Epoch: 6| Step: 5
Training loss: 2.6462204016758704
Validation loss: 2.5656473613538586

Epoch: 6| Step: 6
Training loss: 3.433222936194831
Validation loss: 2.5615851377130086

Epoch: 6| Step: 7
Training loss: 2.6571251717724547
Validation loss: 2.5638571221097313

Epoch: 6| Step: 8
Training loss: 2.648796034768886
Validation loss: 2.5670878980271024

Epoch: 6| Step: 9
Training loss: 2.808289661313159
Validation loss: 2.567213984381357

Epoch: 6| Step: 10
Training loss: 3.2797723258481546
Validation loss: 2.5725040936165153

Epoch: 6| Step: 11
Training loss: 2.597599803339954
Validation loss: 2.5662486092136145

Epoch: 6| Step: 12
Training loss: 2.9197348850557017
Validation loss: 2.565884233995301

Epoch: 6| Step: 13
Training loss: 2.9936766740901897
Validation loss: 2.56390066656281

Epoch: 111| Step: 0
Training loss: 3.170042814814006
Validation loss: 2.5653429425678937

Epoch: 6| Step: 1
Training loss: 2.6070924929477797
Validation loss: 2.5664524217748457

Epoch: 6| Step: 2
Training loss: 2.8318965485206973
Validation loss: 2.576819961195377

Epoch: 6| Step: 3
Training loss: 2.9729701514312703
Validation loss: 2.5984704593830923

Epoch: 6| Step: 4
Training loss: 2.8408686534431196
Validation loss: 2.618800125819043

Epoch: 6| Step: 5
Training loss: 2.87193466639256
Validation loss: 2.634755237176082

Epoch: 6| Step: 6
Training loss: 3.3851413243147612
Validation loss: 2.670849570534281

Epoch: 6| Step: 7
Training loss: 2.8515330691974383
Validation loss: 2.600886621628335

Epoch: 6| Step: 8
Training loss: 2.989713517565564
Validation loss: 2.568693895443094

Epoch: 6| Step: 9
Training loss: 2.4018082680962602
Validation loss: 2.562464442933081

Epoch: 6| Step: 10
Training loss: 2.8903920672618506
Validation loss: 2.563409608340619

Epoch: 6| Step: 11
Training loss: 2.852859327600752
Validation loss: 2.563446664412181

Epoch: 6| Step: 12
Training loss: 3.184535723851949
Validation loss: 2.5680769952077616

Epoch: 6| Step: 13
Training loss: 3.370251034179239
Validation loss: 2.5683801347048036

Epoch: 112| Step: 0
Training loss: 3.213989886037109
Validation loss: 2.5786376761583

Epoch: 6| Step: 1
Training loss: 2.701551916786764
Validation loss: 2.5728520569633906

Epoch: 6| Step: 2
Training loss: 3.0488709783383277
Validation loss: 2.574094427964122

Epoch: 6| Step: 3
Training loss: 3.3479855530129745
Validation loss: 2.5672576990766087

Epoch: 6| Step: 4
Training loss: 2.589713022836587
Validation loss: 2.5657017551992602

Epoch: 6| Step: 5
Training loss: 3.3935891129099205
Validation loss: 2.5682431283327

Epoch: 6| Step: 6
Training loss: 3.115317948036508
Validation loss: 2.5714118731621136

Epoch: 6| Step: 7
Training loss: 2.543086504810103
Validation loss: 2.5659871538579337

Epoch: 6| Step: 8
Training loss: 2.787910116500887
Validation loss: 2.5876400569283473

Epoch: 6| Step: 9
Training loss: 2.496646061834747
Validation loss: 2.6117609414411427

Epoch: 6| Step: 10
Training loss: 2.281315214714249
Validation loss: 2.6299067917846246

Epoch: 6| Step: 11
Training loss: 2.9105897721347254
Validation loss: 2.645312234614573

Epoch: 6| Step: 12
Training loss: 3.0966843069975005
Validation loss: 2.61174009858313

Epoch: 6| Step: 13
Training loss: 3.7133412496549734
Validation loss: 2.5889063963797696

Epoch: 113| Step: 0
Training loss: 3.230046716358133
Validation loss: 2.563773577303378

Epoch: 6| Step: 1
Training loss: 2.9427916568448578
Validation loss: 2.5675702121011903

Epoch: 6| Step: 2
Training loss: 3.1084183798056486
Validation loss: 2.5587617562387215

Epoch: 6| Step: 3
Training loss: 2.6871636645975348
Validation loss: 2.5566909318691136

Epoch: 6| Step: 4
Training loss: 2.5397316388415456
Validation loss: 2.558622674779303

Epoch: 6| Step: 5
Training loss: 2.9555686246093815
Validation loss: 2.5578184344443926

Epoch: 6| Step: 6
Training loss: 3.030823353109499
Validation loss: 2.5619276674666382

Epoch: 6| Step: 7
Training loss: 2.4592769772918213
Validation loss: 2.56682756287479

Epoch: 6| Step: 8
Training loss: 3.0664504126994983
Validation loss: 2.564137215656261

Epoch: 6| Step: 9
Training loss: 2.6589094424627877
Validation loss: 2.5614761620213646

Epoch: 6| Step: 10
Training loss: 2.9026010227283314
Validation loss: 2.5625602551010718

Epoch: 6| Step: 11
Training loss: 3.1328806881606583
Validation loss: 2.557888233512598

Epoch: 6| Step: 12
Training loss: 3.0964426980330426
Validation loss: 2.5598239927199056

Epoch: 6| Step: 13
Training loss: 3.0288719995907365
Validation loss: 2.554757746362614

Epoch: 114| Step: 0
Training loss: 3.4773806862893126
Validation loss: 2.5570102496123663

Epoch: 6| Step: 1
Training loss: 2.875210298227454
Validation loss: 2.5558995955233703

Epoch: 6| Step: 2
Training loss: 2.81789161147172
Validation loss: 2.5593144064224043

Epoch: 6| Step: 3
Training loss: 3.5830752849074288
Validation loss: 2.556352576301716

Epoch: 6| Step: 4
Training loss: 3.6820782388707505
Validation loss: 2.5582338667592968

Epoch: 6| Step: 5
Training loss: 2.2784108300506176
Validation loss: 2.5574252002240176

Epoch: 6| Step: 6
Training loss: 2.915804999091093
Validation loss: 2.557954689267399

Epoch: 6| Step: 7
Training loss: 2.363887891857606
Validation loss: 2.562064145025179

Epoch: 6| Step: 8
Training loss: 2.8812686745789367
Validation loss: 2.565189026150944

Epoch: 6| Step: 9
Training loss: 2.266761547328053
Validation loss: 2.577254782960895

Epoch: 6| Step: 10
Training loss: 2.596035146037447
Validation loss: 2.5822890824395

Epoch: 6| Step: 11
Training loss: 2.8916182177732934
Validation loss: 2.592655510886871

Epoch: 6| Step: 12
Training loss: 3.0684005569423687
Validation loss: 2.601035186885535

Epoch: 6| Step: 13
Training loss: 2.291173072601566
Validation loss: 2.6055152430030377

Epoch: 115| Step: 0
Training loss: 2.747605581849521
Validation loss: 2.6081057507193917

Epoch: 6| Step: 1
Training loss: 2.5361700396767186
Validation loss: 2.623951363093964

Epoch: 6| Step: 2
Training loss: 3.2558321342404217
Validation loss: 2.6294242688485654

Epoch: 6| Step: 3
Training loss: 3.32946177397274
Validation loss: 2.615284003732258

Epoch: 6| Step: 4
Training loss: 3.02290248819326
Validation loss: 2.628073238614039

Epoch: 6| Step: 5
Training loss: 3.0465619831200197
Validation loss: 2.6231098743663015

Epoch: 6| Step: 6
Training loss: 2.8855652111023957
Validation loss: 2.6162144338020545

Epoch: 6| Step: 7
Training loss: 3.26578123458133
Validation loss: 2.5977932870638636

Epoch: 6| Step: 8
Training loss: 2.8089460170579295
Validation loss: 2.5915333774291542

Epoch: 6| Step: 9
Training loss: 2.289460756204224
Validation loss: 2.571069436330338

Epoch: 6| Step: 10
Training loss: 2.91507750314897
Validation loss: 2.5760986394340724

Epoch: 6| Step: 11
Training loss: 2.738987982476713
Validation loss: 2.5638433137385914

Epoch: 6| Step: 12
Training loss: 2.904228081366233
Validation loss: 2.5678283454358315

Epoch: 6| Step: 13
Training loss: 2.7484838467713675
Validation loss: 2.5512199590551368

Epoch: 116| Step: 0
Training loss: 2.4380229486788907
Validation loss: 2.553807864091519

Epoch: 6| Step: 1
Training loss: 2.297884557043717
Validation loss: 2.5496754286323062

Epoch: 6| Step: 2
Training loss: 2.944425494854807
Validation loss: 2.5517806181056466

Epoch: 6| Step: 3
Training loss: 3.37128880224928
Validation loss: 2.5529275354678584

Epoch: 6| Step: 4
Training loss: 3.141808737486153
Validation loss: 2.5528716011157315

Epoch: 6| Step: 5
Training loss: 2.854118142562445
Validation loss: 2.5519535231752304

Epoch: 6| Step: 6
Training loss: 3.1260924909189405
Validation loss: 2.554221307503655

Epoch: 6| Step: 7
Training loss: 2.9254172981137283
Validation loss: 2.5532056736809374

Epoch: 6| Step: 8
Training loss: 3.3202747297943636
Validation loss: 2.5503691557878714

Epoch: 6| Step: 9
Training loss: 2.9228703236638944
Validation loss: 2.5555177069481814

Epoch: 6| Step: 10
Training loss: 2.499079344028321
Validation loss: 2.559103819400579

Epoch: 6| Step: 11
Training loss: 2.9410187768735603
Validation loss: 2.560082837009216

Epoch: 6| Step: 12
Training loss: 3.0628495308846517
Validation loss: 2.564798556251036

Epoch: 6| Step: 13
Training loss: 2.535771981394616
Validation loss: 2.5749395723995305

Epoch: 117| Step: 0
Training loss: 2.5899612146956814
Validation loss: 2.578682559204087

Epoch: 6| Step: 1
Training loss: 2.2109607924457686
Validation loss: 2.581247690224552

Epoch: 6| Step: 2
Training loss: 3.0357167476355564
Validation loss: 2.5997706610293316

Epoch: 6| Step: 3
Training loss: 2.571534582253766
Validation loss: 2.624543402749329

Epoch: 6| Step: 4
Training loss: 2.0273638597494323
Validation loss: 2.5933289999793447

Epoch: 6| Step: 5
Training loss: 3.071902108679184
Validation loss: 2.595790692332758

Epoch: 6| Step: 6
Training loss: 3.131126197301497
Validation loss: 2.586182362651426

Epoch: 6| Step: 7
Training loss: 3.0918766090970298
Validation loss: 2.5744343612761904

Epoch: 6| Step: 8
Training loss: 2.3738400487708597
Validation loss: 2.5512982903686923

Epoch: 6| Step: 9
Training loss: 3.3864248955651184
Validation loss: 2.5509235056164163

Epoch: 6| Step: 10
Training loss: 3.0935548663011345
Validation loss: 2.5485219607253913

Epoch: 6| Step: 11
Training loss: 3.37042632850271
Validation loss: 2.5480860137289123

Epoch: 6| Step: 12
Training loss: 3.3073125563234638
Validation loss: 2.549481972497786

Epoch: 6| Step: 13
Training loss: 3.3911225265915186
Validation loss: 2.5508384824427477

Epoch: 118| Step: 0
Training loss: 2.832249452800834
Validation loss: 2.550292444520531

Epoch: 6| Step: 1
Training loss: 3.0310064788215487
Validation loss: 2.551090030265901

Epoch: 6| Step: 2
Training loss: 2.909828362138725
Validation loss: 2.5498115465088405

Epoch: 6| Step: 3
Training loss: 2.7883465700202077
Validation loss: 2.545942589683992

Epoch: 6| Step: 4
Training loss: 2.971116899294348
Validation loss: 2.5469560135302878

Epoch: 6| Step: 5
Training loss: 2.5682436144599117
Validation loss: 2.545751129794799

Epoch: 6| Step: 6
Training loss: 2.7348172075463117
Validation loss: 2.5469584020742375

Epoch: 6| Step: 7
Training loss: 2.8624766053155795
Validation loss: 2.5450899346007807

Epoch: 6| Step: 8
Training loss: 2.7769958020605405
Validation loss: 2.5495254442180233

Epoch: 6| Step: 9
Training loss: 2.8763154379087235
Validation loss: 2.553203179527601

Epoch: 6| Step: 10
Training loss: 3.2014912230123933
Validation loss: 2.552135554556424

Epoch: 6| Step: 11
Training loss: 2.5794219482822647
Validation loss: 2.552999764284606

Epoch: 6| Step: 12
Training loss: 3.1950226817870617
Validation loss: 2.5585137803212126

Epoch: 6| Step: 13
Training loss: 3.60700693103705
Validation loss: 2.5510489849953575

Epoch: 119| Step: 0
Training loss: 2.668070175454747
Validation loss: 2.5484591042685723

Epoch: 6| Step: 1
Training loss: 2.3987698899359398
Validation loss: 2.560381514112042

Epoch: 6| Step: 2
Training loss: 2.0750666320397486
Validation loss: 2.5676833052562453

Epoch: 6| Step: 3
Training loss: 2.5267270970561992
Validation loss: 2.559020292223728

Epoch: 6| Step: 4
Training loss: 3.3692467714257286
Validation loss: 2.562922933288427

Epoch: 6| Step: 5
Training loss: 2.832144394291574
Validation loss: 2.5557218782373368

Epoch: 6| Step: 6
Training loss: 3.270039326375896
Validation loss: 2.55988898365194

Epoch: 6| Step: 7
Training loss: 3.2928450845143553
Validation loss: 2.5621778524269616

Epoch: 6| Step: 8
Training loss: 3.3038816799748503
Validation loss: 2.5561334845937913

Epoch: 6| Step: 9
Training loss: 2.831048792411506
Validation loss: 2.5574181380924594

Epoch: 6| Step: 10
Training loss: 3.1378945395142397
Validation loss: 2.5485941444012457

Epoch: 6| Step: 11
Training loss: 3.1408595666543015
Validation loss: 2.549492607209898

Epoch: 6| Step: 12
Training loss: 2.6559198510934263
Validation loss: 2.5471257254275934

Epoch: 6| Step: 13
Training loss: 2.8122597485818503
Validation loss: 2.5445308006908083

Epoch: 120| Step: 0
Training loss: 2.8287393313690083
Validation loss: 2.5472567622144813

Epoch: 6| Step: 1
Training loss: 2.8672955983752204
Validation loss: 2.5552947457973643

Epoch: 6| Step: 2
Training loss: 3.2370287931550505
Validation loss: 2.561616063322279

Epoch: 6| Step: 3
Training loss: 3.020822108456157
Validation loss: 2.559273300725623

Epoch: 6| Step: 4
Training loss: 3.2613447694471365
Validation loss: 2.566830277498734

Epoch: 6| Step: 5
Training loss: 3.2684700723847397
Validation loss: 2.5634057829930366

Epoch: 6| Step: 6
Training loss: 2.77586254427071
Validation loss: 2.5634910303851197

Epoch: 6| Step: 7
Training loss: 2.913676136574759
Validation loss: 2.5690357118920306

Epoch: 6| Step: 8
Training loss: 2.70034452995249
Validation loss: 2.566949580288085

Epoch: 6| Step: 9
Training loss: 2.3016728744404706
Validation loss: 2.593369937572706

Epoch: 6| Step: 10
Training loss: 2.950817518589575
Validation loss: 2.582980117573391

Epoch: 6| Step: 11
Training loss: 2.8782280753334497
Validation loss: 2.5918500543839373

Epoch: 6| Step: 12
Training loss: 2.7673710198399846
Validation loss: 2.5880923885387417

Epoch: 6| Step: 13
Training loss: 2.6348320434433314
Validation loss: 2.5941569353417098

Epoch: 121| Step: 0
Training loss: 2.92176304567019
Validation loss: 2.586939710531892

Epoch: 6| Step: 1
Training loss: 2.7258090751716875
Validation loss: 2.567340601768009

Epoch: 6| Step: 2
Training loss: 2.4597717430471198
Validation loss: 2.5569246387661737

Epoch: 6| Step: 3
Training loss: 2.999365898511193
Validation loss: 2.551492205616827

Epoch: 6| Step: 4
Training loss: 3.0753111395005757
Validation loss: 2.5507222141928714

Epoch: 6| Step: 5
Training loss: 2.610370377609427
Validation loss: 2.5485174823107206

Epoch: 6| Step: 6
Training loss: 2.948782659966688
Validation loss: 2.54917882734229

Epoch: 6| Step: 7
Training loss: 2.9147859958723212
Validation loss: 2.546894782295456

Epoch: 6| Step: 8
Training loss: 2.4547981339259684
Validation loss: 2.5446807933751834

Epoch: 6| Step: 9
Training loss: 3.3691886035985954
Validation loss: 2.5437842440219463

Epoch: 6| Step: 10
Training loss: 3.4061625058197453
Validation loss: 2.544524406015784

Epoch: 6| Step: 11
Training loss: 2.8092641229358537
Validation loss: 2.5443232612541355

Epoch: 6| Step: 12
Training loss: 2.707595568209242
Validation loss: 2.543008585906856

Epoch: 6| Step: 13
Training loss: 3.2533499252438225
Validation loss: 2.548004051119118

Epoch: 122| Step: 0
Training loss: 2.9340049567203477
Validation loss: 2.558467624601952

Epoch: 6| Step: 1
Training loss: 3.1788306429073288
Validation loss: 2.556022203813257

Epoch: 6| Step: 2
Training loss: 2.254781410973843
Validation loss: 2.560072188709483

Epoch: 6| Step: 3
Training loss: 3.1698902854826176
Validation loss: 2.5621203459694764

Epoch: 6| Step: 4
Training loss: 3.3424098100955613
Validation loss: 2.5675299235393667

Epoch: 6| Step: 5
Training loss: 2.951647353479782
Validation loss: 2.5725385353074373

Epoch: 6| Step: 6
Training loss: 2.2280586436102743
Validation loss: 2.578123784865127

Epoch: 6| Step: 7
Training loss: 2.8952354161499887
Validation loss: 2.586617555127745

Epoch: 6| Step: 8
Training loss: 3.2361215492120214
Validation loss: 2.608235113716484

Epoch: 6| Step: 9
Training loss: 2.781762408084439
Validation loss: 2.6209921587239764

Epoch: 6| Step: 10
Training loss: 2.958046017157952
Validation loss: 2.6419351415776546

Epoch: 6| Step: 11
Training loss: 2.735037151272639
Validation loss: 2.685220931542907

Epoch: 6| Step: 12
Training loss: 2.9755808095008325
Validation loss: 2.6873788942264025

Epoch: 6| Step: 13
Training loss: 2.3196672255174646
Validation loss: 2.71316325361538

Epoch: 123| Step: 0
Training loss: 3.5748997440818977
Validation loss: 2.6419547710125117

Epoch: 6| Step: 1
Training loss: 2.559273619268262
Validation loss: 2.5745504608319902

Epoch: 6| Step: 2
Training loss: 3.3162065317789806
Validation loss: 2.551649038007801

Epoch: 6| Step: 3
Training loss: 2.448682029602535
Validation loss: 2.540826517082769

Epoch: 6| Step: 4
Training loss: 2.5301094782366222
Validation loss: 2.5436147899339088

Epoch: 6| Step: 5
Training loss: 3.404272642941224
Validation loss: 2.5388071481737926

Epoch: 6| Step: 6
Training loss: 2.583170444726555
Validation loss: 2.543154597845471

Epoch: 6| Step: 7
Training loss: 2.9895811357833457
Validation loss: 2.546144325425556

Epoch: 6| Step: 8
Training loss: 3.343412578349759
Validation loss: 2.546435624933867

Epoch: 6| Step: 9
Training loss: 2.7628744639686222
Validation loss: 2.5520105153574146

Epoch: 6| Step: 10
Training loss: 2.331680143625041
Validation loss: 2.5515534028844225

Epoch: 6| Step: 11
Training loss: 2.362134620628744
Validation loss: 2.5556082201425574

Epoch: 6| Step: 12
Training loss: 3.0779220591611005
Validation loss: 2.5669361465920413

Epoch: 6| Step: 13
Training loss: 3.1441621362360483
Validation loss: 2.577276656707611

Epoch: 124| Step: 0
Training loss: 2.7277518140597845
Validation loss: 2.5743652353857716

Epoch: 6| Step: 1
Training loss: 3.23906158138102
Validation loss: 2.5671566886032258

Epoch: 6| Step: 2
Training loss: 3.0676508036186085
Validation loss: 2.558517402562534

Epoch: 6| Step: 3
Training loss: 3.3138754526146412
Validation loss: 2.558693831070083

Epoch: 6| Step: 4
Training loss: 2.7366759292253735
Validation loss: 2.5494532054596726

Epoch: 6| Step: 5
Training loss: 2.7919372788027155
Validation loss: 2.5497968944290132

Epoch: 6| Step: 6
Training loss: 3.1848441634687648
Validation loss: 2.551214400116404

Epoch: 6| Step: 7
Training loss: 3.185804926128364
Validation loss: 2.5596877692968416

Epoch: 6| Step: 8
Training loss: 2.2962414133641276
Validation loss: 2.556893749659561

Epoch: 6| Step: 9
Training loss: 2.75527032927848
Validation loss: 2.5576134893081792

Epoch: 6| Step: 10
Training loss: 3.22168190763223
Validation loss: 2.5662453165610923

Epoch: 6| Step: 11
Training loss: 2.8719662125706598
Validation loss: 2.558114075819109

Epoch: 6| Step: 12
Training loss: 2.236030338900426
Validation loss: 2.547975483716888

Epoch: 6| Step: 13
Training loss: 2.466311445519659
Validation loss: 2.5424595878147245

Epoch: 125| Step: 0
Training loss: 2.9050658079693843
Validation loss: 2.539003766234843

Epoch: 6| Step: 1
Training loss: 2.7494231399307156
Validation loss: 2.535317917172232

Epoch: 6| Step: 2
Training loss: 3.002247763019268
Validation loss: 2.5316073318503056

Epoch: 6| Step: 3
Training loss: 2.9702873666373213
Validation loss: 2.5362248913509893

Epoch: 6| Step: 4
Training loss: 3.1717309778147773
Validation loss: 2.5309930729487484

Epoch: 6| Step: 5
Training loss: 2.420058325860686
Validation loss: 2.5360615943410707

Epoch: 6| Step: 6
Training loss: 3.083300272446451
Validation loss: 2.540643408036016

Epoch: 6| Step: 7
Training loss: 2.1298132967721997
Validation loss: 2.5435628002903172

Epoch: 6| Step: 8
Training loss: 3.4195373074933495
Validation loss: 2.5608079557738876

Epoch: 6| Step: 9
Training loss: 2.95497678796007
Validation loss: 2.565881365504088

Epoch: 6| Step: 10
Training loss: 3.220121961617738
Validation loss: 2.563072587816755

Epoch: 6| Step: 11
Training loss: 3.183719861861825
Validation loss: 2.5622091781096388

Epoch: 6| Step: 12
Training loss: 2.0740347168167843
Validation loss: 2.5608332485962744

Epoch: 6| Step: 13
Training loss: 2.7794399586543777
Validation loss: 2.5664443675959707

Epoch: 126| Step: 0
Training loss: 2.7513901924627886
Validation loss: 2.556937501430364

Epoch: 6| Step: 1
Training loss: 3.167657462935384
Validation loss: 2.5626944531429747

Epoch: 6| Step: 2
Training loss: 2.27797254515356
Validation loss: 2.566464108430352

Epoch: 6| Step: 3
Training loss: 3.4583391549547824
Validation loss: 2.576883460965324

Epoch: 6| Step: 4
Training loss: 2.8904963284284246
Validation loss: 2.561470744441595

Epoch: 6| Step: 5
Training loss: 2.912102661534431
Validation loss: 2.5620643141291626

Epoch: 6| Step: 6
Training loss: 3.0907616873389583
Validation loss: 2.564801616866819

Epoch: 6| Step: 7
Training loss: 1.85667293624002
Validation loss: 2.558140998716685

Epoch: 6| Step: 8
Training loss: 2.9209705931826484
Validation loss: 2.55828150428518

Epoch: 6| Step: 9
Training loss: 2.08685134129396
Validation loss: 2.5661091742679174

Epoch: 6| Step: 10
Training loss: 2.9488918097963155
Validation loss: 2.54662113017824

Epoch: 6| Step: 11
Training loss: 3.401556017987336
Validation loss: 2.555532268043849

Epoch: 6| Step: 12
Training loss: 3.1706230812360214
Validation loss: 2.549014751520135

Epoch: 6| Step: 13
Training loss: 3.0205644860610286
Validation loss: 2.5485457529258158

Epoch: 127| Step: 0
Training loss: 2.947577377222582
Validation loss: 2.5604498100259976

Epoch: 6| Step: 1
Training loss: 3.6003761571821307
Validation loss: 2.550859691266355

Epoch: 6| Step: 2
Training loss: 2.489993094928773
Validation loss: 2.5571884924082746

Epoch: 6| Step: 3
Training loss: 3.1735074958237934
Validation loss: 2.558518805365541

Epoch: 6| Step: 4
Training loss: 2.969497104800731
Validation loss: 2.555929211780056

Epoch: 6| Step: 5
Training loss: 3.119705139556602
Validation loss: 2.5534256626784435

Epoch: 6| Step: 6
Training loss: 3.0883679054275417
Validation loss: 2.564268292915497

Epoch: 6| Step: 7
Training loss: 2.9864196164553496
Validation loss: 2.5532894633665397

Epoch: 6| Step: 8
Training loss: 2.9332783982883783
Validation loss: 2.5484438559246048

Epoch: 6| Step: 9
Training loss: 2.671010730900376
Validation loss: 2.547928790975204

Epoch: 6| Step: 10
Training loss: 2.7704888801344665
Validation loss: 2.563486253101883

Epoch: 6| Step: 11
Training loss: 2.1911168306820707
Validation loss: 2.5565852772757953

Epoch: 6| Step: 12
Training loss: 2.4566992700691612
Validation loss: 2.564858370536903

Epoch: 6| Step: 13
Training loss: 2.7272833715577915
Validation loss: 2.5836165058277403

Epoch: 128| Step: 0
Training loss: 2.9882834839656685
Validation loss: 2.5862851101483177

Epoch: 6| Step: 1
Training loss: 3.0206974042805976
Validation loss: 2.573271271407647

Epoch: 6| Step: 2
Training loss: 3.340699132055739
Validation loss: 2.5873789361024424

Epoch: 6| Step: 3
Training loss: 3.1394128690300427
Validation loss: 2.5778837317930052

Epoch: 6| Step: 4
Training loss: 2.6790294673391215
Validation loss: 2.572005923572904

Epoch: 6| Step: 5
Training loss: 2.9459214934268987
Validation loss: 2.5633294423629054

Epoch: 6| Step: 6
Training loss: 2.7804060952227476
Validation loss: 2.5639510169613042

Epoch: 6| Step: 7
Training loss: 3.0570413637566696
Validation loss: 2.5654015824592142

Epoch: 6| Step: 8
Training loss: 2.788554169307739
Validation loss: 2.557086013442071

Epoch: 6| Step: 9
Training loss: 3.268257503715964
Validation loss: 2.5502134077790144

Epoch: 6| Step: 10
Training loss: 2.4511853951009104
Validation loss: 2.5484287432952355

Epoch: 6| Step: 11
Training loss: 2.561011370465688
Validation loss: 2.5428976255018396

Epoch: 6| Step: 12
Training loss: 2.567620813040135
Validation loss: 2.547349931956414

Epoch: 6| Step: 13
Training loss: 2.6491196015640956
Validation loss: 2.5443408708845703

Epoch: 129| Step: 0
Training loss: 3.2343844353727107
Validation loss: 2.5520581228899966

Epoch: 6| Step: 1
Training loss: 3.4649513683787094
Validation loss: 2.552890659101396

Epoch: 6| Step: 2
Training loss: 2.9227476397850602
Validation loss: 2.5746227910034625

Epoch: 6| Step: 3
Training loss: 2.757184267756645
Validation loss: 2.5850575660755095

Epoch: 6| Step: 4
Training loss: 3.1722922966724463
Validation loss: 2.5983375772858834

Epoch: 6| Step: 5
Training loss: 3.549180680410236
Validation loss: 2.6149261711332143

Epoch: 6| Step: 6
Training loss: 2.909039870811451
Validation loss: 2.600713840564553

Epoch: 6| Step: 7
Training loss: 2.6012178943124713
Validation loss: 2.582614874857573

Epoch: 6| Step: 8
Training loss: 2.7365565725368852
Validation loss: 2.56386349306382

Epoch: 6| Step: 9
Training loss: 2.879019870871008
Validation loss: 2.5692686461092555

Epoch: 6| Step: 10
Training loss: 1.9169507714498966
Validation loss: 2.5647540959469124

Epoch: 6| Step: 11
Training loss: 2.008321497184519
Validation loss: 2.568477549759092

Epoch: 6| Step: 12
Training loss: 3.183140035489276
Validation loss: 2.560681543979264

Epoch: 6| Step: 13
Training loss: 2.341607806007868
Validation loss: 2.5589307753282675

Epoch: 130| Step: 0
Training loss: 2.2390429414053297
Validation loss: 2.558332056462945

Epoch: 6| Step: 1
Training loss: 2.761861449443848
Validation loss: 2.554112452236588

Epoch: 6| Step: 2
Training loss: 2.9341560972746197
Validation loss: 2.5600750662131952

Epoch: 6| Step: 3
Training loss: 2.745788123106404
Validation loss: 2.5479585250345984

Epoch: 6| Step: 4
Training loss: 3.2184225860288675
Validation loss: 2.554291469833968

Epoch: 6| Step: 5
Training loss: 3.48841589382677
Validation loss: 2.563015531039267

Epoch: 6| Step: 6
Training loss: 2.6414222191026355
Validation loss: 2.5624213097808313

Epoch: 6| Step: 7
Training loss: 2.401719720939652
Validation loss: 2.5597933429065054

Epoch: 6| Step: 8
Training loss: 2.9632567328503137
Validation loss: 2.5578765638010603

Epoch: 6| Step: 9
Training loss: 2.587506789046517
Validation loss: 2.553030489631799

Epoch: 6| Step: 10
Training loss: 2.9268860303600475
Validation loss: 2.555502638158239

Epoch: 6| Step: 11
Training loss: 2.9812770562373707
Validation loss: 2.5588346729700002

Epoch: 6| Step: 12
Training loss: 3.2580750723210605
Validation loss: 2.5661691807851477

Epoch: 6| Step: 13
Training loss: 2.9717647303391623
Validation loss: 2.5753811083601574

Epoch: 131| Step: 0
Training loss: 2.579068098100295
Validation loss: 2.569751847789565

Epoch: 6| Step: 1
Training loss: 2.5523956938082693
Validation loss: 2.5641788472541394

Epoch: 6| Step: 2
Training loss: 2.35789766859333
Validation loss: 2.581487520852355

Epoch: 6| Step: 3
Training loss: 2.925229029369765
Validation loss: 2.5784664341874852

Epoch: 6| Step: 4
Training loss: 3.0793934643491676
Validation loss: 2.5634601003935704

Epoch: 6| Step: 5
Training loss: 2.3578205166649457
Validation loss: 2.5579601233139124

Epoch: 6| Step: 6
Training loss: 3.2280921542923777
Validation loss: 2.5416429153077678

Epoch: 6| Step: 7
Training loss: 2.977830992012842
Validation loss: 2.5444414359928413

Epoch: 6| Step: 8
Training loss: 3.1260630516092793
Validation loss: 2.540147486387013

Epoch: 6| Step: 9
Training loss: 2.988720830362592
Validation loss: 2.528778838798464

Epoch: 6| Step: 10
Training loss: 2.9227518816008597
Validation loss: 2.5261404904688596

Epoch: 6| Step: 11
Training loss: 2.936069058835216
Validation loss: 2.5246738950618086

Epoch: 6| Step: 12
Training loss: 3.570642368428652
Validation loss: 2.5363230446297256

Epoch: 6| Step: 13
Training loss: 2.1826558564108116
Validation loss: 2.535011609835575

Epoch: 132| Step: 0
Training loss: 2.9282473673945852
Validation loss: 2.543902980935722

Epoch: 6| Step: 1
Training loss: 3.231443394198962
Validation loss: 2.541800632775756

Epoch: 6| Step: 2
Training loss: 2.7932925163358076
Validation loss: 2.5540312903004354

Epoch: 6| Step: 3
Training loss: 2.6858936210807394
Validation loss: 2.5416339281765272

Epoch: 6| Step: 4
Training loss: 3.0045787519829923
Validation loss: 2.5390073799605988

Epoch: 6| Step: 5
Training loss: 3.048003941240541
Validation loss: 2.5492564158544027

Epoch: 6| Step: 6
Training loss: 2.597404203878872
Validation loss: 2.5445521457115423

Epoch: 6| Step: 7
Training loss: 2.7327713105558464
Validation loss: 2.5532951422899512

Epoch: 6| Step: 8
Training loss: 2.7239428508214
Validation loss: 2.565745745454487

Epoch: 6| Step: 9
Training loss: 2.684107746502816
Validation loss: 2.573974995194741

Epoch: 6| Step: 10
Training loss: 2.7439675490348368
Validation loss: 2.5890291001458565

Epoch: 6| Step: 11
Training loss: 2.858339716363866
Validation loss: 2.5583416623360113

Epoch: 6| Step: 12
Training loss: 3.2079847732715305
Validation loss: 2.542140755767335

Epoch: 6| Step: 13
Training loss: 3.254321233291687
Validation loss: 2.5259074297344895

Epoch: 133| Step: 0
Training loss: 2.7534574968206966
Validation loss: 2.5215640234949244

Epoch: 6| Step: 1
Training loss: 3.311961004202703
Validation loss: 2.5236641665756556

Epoch: 6| Step: 2
Training loss: 2.9479440928195446
Validation loss: 2.5227441155422676

Epoch: 6| Step: 3
Training loss: 2.71816808677376
Validation loss: 2.525990666004753

Epoch: 6| Step: 4
Training loss: 2.9298356082354142
Validation loss: 2.51950338236469

Epoch: 6| Step: 5
Training loss: 2.5982728613504067
Validation loss: 2.522109280727168

Epoch: 6| Step: 6
Training loss: 3.1484892961581528
Validation loss: 2.526625594524637

Epoch: 6| Step: 7
Training loss: 2.468982926981389
Validation loss: 2.5422136238371857

Epoch: 6| Step: 8
Training loss: 2.965285518337354
Validation loss: 2.554776291553715

Epoch: 6| Step: 9
Training loss: 2.8984955733000426
Validation loss: 2.54535175125699

Epoch: 6| Step: 10
Training loss: 3.012523578219127
Validation loss: 2.574486869661791

Epoch: 6| Step: 11
Training loss: 2.9930112815310386
Validation loss: 2.5873429064694435

Epoch: 6| Step: 12
Training loss: 2.957294407048601
Validation loss: 2.5870561060548716

Epoch: 6| Step: 13
Training loss: 2.3396860110906257
Validation loss: 2.598433722233679

Epoch: 134| Step: 0
Training loss: 2.875689714048081
Validation loss: 2.6112002396657314

Epoch: 6| Step: 1
Training loss: 2.806394264913895
Validation loss: 2.639410885526125

Epoch: 6| Step: 2
Training loss: 2.5642171549256014
Validation loss: 2.662355459163395

Epoch: 6| Step: 3
Training loss: 2.677315064925804
Validation loss: 2.6918315660040966

Epoch: 6| Step: 4
Training loss: 3.5343503591958525
Validation loss: 2.61938877384169

Epoch: 6| Step: 5
Training loss: 2.811689641557527
Validation loss: 2.567754237420228

Epoch: 6| Step: 6
Training loss: 2.946140648451629
Validation loss: 2.5364560787604207

Epoch: 6| Step: 7
Training loss: 2.552415496593087
Validation loss: 2.524568634972037

Epoch: 6| Step: 8
Training loss: 3.3176382268009066
Validation loss: 2.521838034143018

Epoch: 6| Step: 9
Training loss: 2.881516245292955
Validation loss: 2.5206878258747096

Epoch: 6| Step: 10
Training loss: 3.129513037585399
Validation loss: 2.52078327023138

Epoch: 6| Step: 11
Training loss: 2.0858956664958934
Validation loss: 2.5219522459308545

Epoch: 6| Step: 12
Training loss: 3.190150187672936
Validation loss: 2.5236382482843394

Epoch: 6| Step: 13
Training loss: 2.601742758248101
Validation loss: 2.5200963039099893

Epoch: 135| Step: 0
Training loss: 2.5694048824071207
Validation loss: 2.518389741336926

Epoch: 6| Step: 1
Training loss: 3.5981714002020433
Validation loss: 2.5196628661778093

Epoch: 6| Step: 2
Training loss: 2.868836305604077
Validation loss: 2.5178968040965746

Epoch: 6| Step: 3
Training loss: 2.093648196350229
Validation loss: 2.5319238350966518

Epoch: 6| Step: 4
Training loss: 3.0973599112962287
Validation loss: 2.5299252956022253

Epoch: 6| Step: 5
Training loss: 2.8370144063041254
Validation loss: 2.5493936969432367

Epoch: 6| Step: 6
Training loss: 3.2475325681302865
Validation loss: 2.5533095513969672

Epoch: 6| Step: 7
Training loss: 2.9020069281129275
Validation loss: 2.5495164798452623

Epoch: 6| Step: 8
Training loss: 2.4993991129676187
Validation loss: 2.5364266384092065

Epoch: 6| Step: 9
Training loss: 3.1196557696277454
Validation loss: 2.536732169529085

Epoch: 6| Step: 10
Training loss: 2.744473192147628
Validation loss: 2.52794621207036

Epoch: 6| Step: 11
Training loss: 2.966167089281736
Validation loss: 2.548706737760425

Epoch: 6| Step: 12
Training loss: 2.7139220944258953
Validation loss: 2.5338114392013793

Epoch: 6| Step: 13
Training loss: 2.608646862292487
Validation loss: 2.536023559893313

Epoch: 136| Step: 0
Training loss: 2.8038231838163328
Validation loss: 2.539635351035043

Epoch: 6| Step: 1
Training loss: 2.953304709158735
Validation loss: 2.5366984524059406

Epoch: 6| Step: 2
Training loss: 3.3617516915180996
Validation loss: 2.535951989899361

Epoch: 6| Step: 3
Training loss: 2.980379795731853
Validation loss: 2.5358505280511006

Epoch: 6| Step: 4
Training loss: 2.4508835581181945
Validation loss: 2.544910132231734

Epoch: 6| Step: 5
Training loss: 2.421496454003538
Validation loss: 2.5355960943396605

Epoch: 6| Step: 6
Training loss: 2.8299857914975695
Validation loss: 2.5375658363067037

Epoch: 6| Step: 7
Training loss: 2.745280464172164
Validation loss: 2.545288263049148

Epoch: 6| Step: 8
Training loss: 3.0991085924323447
Validation loss: 2.541909692551038

Epoch: 6| Step: 9
Training loss: 3.0574894613113996
Validation loss: 2.5448806536857296

Epoch: 6| Step: 10
Training loss: 3.2737014409178453
Validation loss: 2.538198675811033

Epoch: 6| Step: 11
Training loss: 2.9365765357790834
Validation loss: 2.5387094837573083

Epoch: 6| Step: 12
Training loss: 1.9509165981577812
Validation loss: 2.536845082195629

Epoch: 6| Step: 13
Training loss: 3.1656502213372435
Validation loss: 2.5390355918853085

Epoch: 137| Step: 0
Training loss: 3.69945566451946
Validation loss: 2.532452422166444

Epoch: 6| Step: 1
Training loss: 2.853327959744869
Validation loss: 2.5334846156188187

Epoch: 6| Step: 2
Training loss: 2.723211464444917
Validation loss: 2.53317087793527

Epoch: 6| Step: 3
Training loss: 3.245496564116633
Validation loss: 2.53714921297591

Epoch: 6| Step: 4
Training loss: 2.374301004444169
Validation loss: 2.533856629615365

Epoch: 6| Step: 5
Training loss: 2.3918435973893777
Validation loss: 2.544102004507169

Epoch: 6| Step: 6
Training loss: 2.9112453394156823
Validation loss: 2.555296565721451

Epoch: 6| Step: 7
Training loss: 2.2923025693919885
Validation loss: 2.54358339147296

Epoch: 6| Step: 8
Training loss: 2.806748676808386
Validation loss: 2.5366687874753273

Epoch: 6| Step: 9
Training loss: 2.774189591852101
Validation loss: 2.521593881373501

Epoch: 6| Step: 10
Training loss: 2.844451817695015
Validation loss: 2.514411433299612

Epoch: 6| Step: 11
Training loss: 2.751655773724307
Validation loss: 2.517359225553307

Epoch: 6| Step: 12
Training loss: 3.223414920167522
Validation loss: 2.519195518500892

Epoch: 6| Step: 13
Training loss: 3.2428101458784035
Validation loss: 2.5186230976960178

Epoch: 138| Step: 0
Training loss: 2.429631174299392
Validation loss: 2.5208932006230254

Epoch: 6| Step: 1
Training loss: 2.7605033045194305
Validation loss: 2.5270849020763313

Epoch: 6| Step: 2
Training loss: 2.6229443448408913
Validation loss: 2.52366012860586

Epoch: 6| Step: 3
Training loss: 2.98390122093156
Validation loss: 2.522836358388302

Epoch: 6| Step: 4
Training loss: 3.2342007355114815
Validation loss: 2.527051647676018

Epoch: 6| Step: 5
Training loss: 3.1714361479139717
Validation loss: 2.523403726134143

Epoch: 6| Step: 6
Training loss: 2.648435969619534
Validation loss: 2.5287174269507924

Epoch: 6| Step: 7
Training loss: 2.533454970735639
Validation loss: 2.5337027765561584

Epoch: 6| Step: 8
Training loss: 2.666309471844181
Validation loss: 2.5510895438847188

Epoch: 6| Step: 9
Training loss: 2.8237180147221252
Validation loss: 2.5625692928938864

Epoch: 6| Step: 10
Training loss: 2.8487642118627576
Validation loss: 2.5954166053820154

Epoch: 6| Step: 11
Training loss: 3.3526874068276022
Validation loss: 2.610490079895547

Epoch: 6| Step: 12
Training loss: 2.7992875759597053
Validation loss: 2.691879267328512

Epoch: 6| Step: 13
Training loss: 3.36246593131919
Validation loss: 2.708068290091251

Epoch: 139| Step: 0
Training loss: 2.834724944696568
Validation loss: 2.685934247401121

Epoch: 6| Step: 1
Training loss: 3.2205876410086978
Validation loss: 2.58098335107471

Epoch: 6| Step: 2
Training loss: 3.2070288710405306
Validation loss: 2.5113015871837714

Epoch: 6| Step: 3
Training loss: 3.4745198967891366
Validation loss: 2.5201387749435256

Epoch: 6| Step: 4
Training loss: 3.1148385205977234
Validation loss: 2.538448324204235

Epoch: 6| Step: 5
Training loss: 2.91777820296945
Validation loss: 2.5661928353452805

Epoch: 6| Step: 6
Training loss: 3.0786535128839327
Validation loss: 2.5741990183409946

Epoch: 6| Step: 7
Training loss: 2.4715651866566883
Validation loss: 2.579747953722891

Epoch: 6| Step: 8
Training loss: 2.877421810304159
Validation loss: 2.5807259822246467

Epoch: 6| Step: 9
Training loss: 2.6591755631968566
Validation loss: 2.559703576621352

Epoch: 6| Step: 10
Training loss: 2.834055714987674
Validation loss: 2.544853008235247

Epoch: 6| Step: 11
Training loss: 3.2212674564337105
Validation loss: 2.539778572120558

Epoch: 6| Step: 12
Training loss: 2.7341584038098494
Validation loss: 2.5334011717129097

Epoch: 6| Step: 13
Training loss: 2.064655911131942
Validation loss: 2.5299462516164906

Epoch: 140| Step: 0
Training loss: 3.00313356777402
Validation loss: 2.5270669226390057

Epoch: 6| Step: 1
Training loss: 3.1326647031552897
Validation loss: 2.5275491123639977

Epoch: 6| Step: 2
Training loss: 3.1707394827054936
Validation loss: 2.5289921501492074

Epoch: 6| Step: 3
Training loss: 2.552145623724964
Validation loss: 2.524429938369426

Epoch: 6| Step: 4
Training loss: 2.2935650909481544
Validation loss: 2.52307919602085

Epoch: 6| Step: 5
Training loss: 2.961544246458335
Validation loss: 2.5289722445407805

Epoch: 6| Step: 6
Training loss: 2.421283280474261
Validation loss: 2.521673495910327

Epoch: 6| Step: 7
Training loss: 3.5326967229688155
Validation loss: 2.525852896501537

Epoch: 6| Step: 8
Training loss: 3.0080564721974885
Validation loss: 2.5325191642548663

Epoch: 6| Step: 9
Training loss: 2.968910775097615
Validation loss: 2.5309355244314573

Epoch: 6| Step: 10
Training loss: 2.9043279054852893
Validation loss: 2.5448797269036385

Epoch: 6| Step: 11
Training loss: 2.996515634766796
Validation loss: 2.569495867216745

Epoch: 6| Step: 12
Training loss: 2.573108578421761
Validation loss: 2.5687927856107655

Epoch: 6| Step: 13
Training loss: 2.8826909233446605
Validation loss: 2.5806197023225463

Epoch: 141| Step: 0
Training loss: 2.4805323795357506
Validation loss: 2.590319138946063

Epoch: 6| Step: 1
Training loss: 2.6944672516931387
Validation loss: 2.5874079027193537

Epoch: 6| Step: 2
Training loss: 2.873180643023736
Validation loss: 2.6458496940739344

Epoch: 6| Step: 3
Training loss: 3.3162161656913702
Validation loss: 2.6593017689891965

Epoch: 6| Step: 4
Training loss: 3.1959829210056587
Validation loss: 2.626892152081622

Epoch: 6| Step: 5
Training loss: 3.4380276361744984
Validation loss: 2.6222825230812576

Epoch: 6| Step: 6
Training loss: 3.1935606540159696
Validation loss: 2.582579970953764

Epoch: 6| Step: 7
Training loss: 2.9578085599571784
Validation loss: 2.5605222902135916

Epoch: 6| Step: 8
Training loss: 3.3205422714614703
Validation loss: 2.5281421517155205

Epoch: 6| Step: 9
Training loss: 1.970982451439651
Validation loss: 2.515981120208811

Epoch: 6| Step: 10
Training loss: 2.559525042224135
Validation loss: 2.512377872089517

Epoch: 6| Step: 11
Training loss: 2.8332592636599188
Validation loss: 2.505339507115983

Epoch: 6| Step: 12
Training loss: 2.426763805481785
Validation loss: 2.5091143221107117

Epoch: 6| Step: 13
Training loss: 2.1586377841076754
Validation loss: 2.507984474298212

Epoch: 142| Step: 0
Training loss: 3.0115993688847444
Validation loss: 2.5098318253482272

Epoch: 6| Step: 1
Training loss: 2.5901499203332317
Validation loss: 2.509530747275617

Epoch: 6| Step: 2
Training loss: 2.70172012072268
Validation loss: 2.5068876733314167

Epoch: 6| Step: 3
Training loss: 2.9039021514297145
Validation loss: 2.5172652421479644

Epoch: 6| Step: 4
Training loss: 3.0578776138694317
Validation loss: 2.523472243615617

Epoch: 6| Step: 5
Training loss: 3.578400047425394
Validation loss: 2.5505902397645954

Epoch: 6| Step: 6
Training loss: 3.0230405088506265
Validation loss: 2.564916660186521

Epoch: 6| Step: 7
Training loss: 2.2638958876904023
Validation loss: 2.537462107178802

Epoch: 6| Step: 8
Training loss: 1.9517903154503662
Validation loss: 2.528751532831471

Epoch: 6| Step: 9
Training loss: 2.977490217959897
Validation loss: 2.5380238064165184

Epoch: 6| Step: 10
Training loss: 3.2915357410774138
Validation loss: 2.541514202637393

Epoch: 6| Step: 11
Training loss: 3.11219330161326
Validation loss: 2.545109490030793

Epoch: 6| Step: 12
Training loss: 2.7712617318296933
Validation loss: 2.5438402512075435

Epoch: 6| Step: 13
Training loss: 2.6749748407054192
Validation loss: 2.5401727840898145

Epoch: 143| Step: 0
Training loss: 2.844085170570406
Validation loss: 2.5501657869195027

Epoch: 6| Step: 1
Training loss: 2.9263343441038048
Validation loss: 2.5482337181550863

Epoch: 6| Step: 2
Training loss: 3.158404681793036
Validation loss: 2.5771441381496376

Epoch: 6| Step: 3
Training loss: 3.132242127054145
Validation loss: 2.5977225218171345

Epoch: 6| Step: 4
Training loss: 3.292166434547876
Validation loss: 2.589590709849581

Epoch: 6| Step: 5
Training loss: 2.2533699865388575
Validation loss: 2.5989653174413987

Epoch: 6| Step: 6
Training loss: 2.614656140857592
Validation loss: 2.6088512264139467

Epoch: 6| Step: 7
Training loss: 2.7023243683127953
Validation loss: 2.6366332264729135

Epoch: 6| Step: 8
Training loss: 2.8058895839683133
Validation loss: 2.6235422851862373

Epoch: 6| Step: 9
Training loss: 3.2074359447954404
Validation loss: 2.581246747201053

Epoch: 6| Step: 10
Training loss: 2.3645510454256087
Validation loss: 2.5641185771987978

Epoch: 6| Step: 11
Training loss: 2.481852852639197
Validation loss: 2.5455652318281996

Epoch: 6| Step: 12
Training loss: 3.071312040355222
Validation loss: 2.5346211931951395

Epoch: 6| Step: 13
Training loss: 3.3164838909860426
Validation loss: 2.527589219690441

Epoch: 144| Step: 0
Training loss: 2.9082631347695433
Validation loss: 2.517417885877138

Epoch: 6| Step: 1
Training loss: 2.760033596497765
Validation loss: 2.5112955192951416

Epoch: 6| Step: 2
Training loss: 2.751803413688538
Validation loss: 2.5230848255845664

Epoch: 6| Step: 3
Training loss: 2.7452637895530105
Validation loss: 2.5204059211706777

Epoch: 6| Step: 4
Training loss: 2.624329254195027
Validation loss: 2.5201518355325523

Epoch: 6| Step: 5
Training loss: 2.5781794686776913
Validation loss: 2.528353003691446

Epoch: 6| Step: 6
Training loss: 3.234205011148518
Validation loss: 2.5399028640016708

Epoch: 6| Step: 7
Training loss: 3.2956300527301314
Validation loss: 2.535050624225344

Epoch: 6| Step: 8
Training loss: 2.444348910179569
Validation loss: 2.553557909211324

Epoch: 6| Step: 9
Training loss: 3.1784281568246437
Validation loss: 2.5401108978291367

Epoch: 6| Step: 10
Training loss: 2.3539564550840018
Validation loss: 2.544426686490846

Epoch: 6| Step: 11
Training loss: 2.6615606737460897
Validation loss: 2.543842049092955

Epoch: 6| Step: 12
Training loss: 3.135909910893213
Validation loss: 2.540669089281894

Epoch: 6| Step: 13
Training loss: 3.403037419869237
Validation loss: 2.546445865640466

Epoch: 145| Step: 0
Training loss: 3.543048424545151
Validation loss: 2.5956069549587295

Epoch: 6| Step: 1
Training loss: 2.5490344669231155
Validation loss: 2.574384343379183

Epoch: 6| Step: 2
Training loss: 2.481011182692948
Validation loss: 2.5652104231382733

Epoch: 6| Step: 3
Training loss: 3.1307226045258716
Validation loss: 2.5444290491977504

Epoch: 6| Step: 4
Training loss: 3.011499300431435
Validation loss: 2.5297210898880778

Epoch: 6| Step: 5
Training loss: 2.6495624504900106
Validation loss: 2.535209249322974

Epoch: 6| Step: 6
Training loss: 2.451509757899938
Validation loss: 2.5248451869358832

Epoch: 6| Step: 7
Training loss: 2.692264325976878
Validation loss: 2.5307441569583244

Epoch: 6| Step: 8
Training loss: 3.2357711358731787
Validation loss: 2.5282806406173286

Epoch: 6| Step: 9
Training loss: 2.2000146648611794
Validation loss: 2.526308534051056

Epoch: 6| Step: 10
Training loss: 3.258308208267892
Validation loss: 2.5337242047016764

Epoch: 6| Step: 11
Training loss: 2.7046501840257346
Validation loss: 2.531857606880206

Epoch: 6| Step: 12
Training loss: 2.693560663990723
Validation loss: 2.5417690525449705

Epoch: 6| Step: 13
Training loss: 3.2230820623041354
Validation loss: 2.5650398748967214

Epoch: 146| Step: 0
Training loss: 2.1858091086255875
Validation loss: 2.5894201644970303

Epoch: 6| Step: 1
Training loss: 2.866146220787688
Validation loss: 2.5993451248987722

Epoch: 6| Step: 2
Training loss: 3.342719088487846
Validation loss: 2.5980376993683665

Epoch: 6| Step: 3
Training loss: 3.0881132929876696
Validation loss: 2.5755631223458533

Epoch: 6| Step: 4
Training loss: 2.7032067611765576
Validation loss: 2.566665209559504

Epoch: 6| Step: 5
Training loss: 2.9134334263603803
Validation loss: 2.5687812807063635

Epoch: 6| Step: 6
Training loss: 2.5590767673845165
Validation loss: 2.5657613935574344

Epoch: 6| Step: 7
Training loss: 2.4788909459595936
Validation loss: 2.556680584798641

Epoch: 6| Step: 8
Training loss: 2.346556140760481
Validation loss: 2.5533222113835397

Epoch: 6| Step: 9
Training loss: 2.6708403251504853
Validation loss: 2.548987510964703

Epoch: 6| Step: 10
Training loss: 2.893594731888367
Validation loss: 2.5344024366201574

Epoch: 6| Step: 11
Training loss: 3.293477698983057
Validation loss: 2.532974136040356

Epoch: 6| Step: 12
Training loss: 2.977060031110056
Validation loss: 2.5614318372148905

Epoch: 6| Step: 13
Training loss: 3.761592748003305
Validation loss: 2.5766298455047814

Epoch: 147| Step: 0
Training loss: 2.6739005280326857
Validation loss: 2.561617223238031

Epoch: 6| Step: 1
Training loss: 2.582888739280489
Validation loss: 2.5682594270199273

Epoch: 6| Step: 2
Training loss: 3.1097899500328308
Validation loss: 2.5580969378166336

Epoch: 6| Step: 3
Training loss: 2.9384776984149514
Validation loss: 2.5486449098506254

Epoch: 6| Step: 4
Training loss: 2.4738325120485536
Validation loss: 2.525115827236765

Epoch: 6| Step: 5
Training loss: 3.102887771312766
Validation loss: 2.520402606264037

Epoch: 6| Step: 6
Training loss: 2.593407665779303
Validation loss: 2.5255435419902295

Epoch: 6| Step: 7
Training loss: 2.839237531474222
Validation loss: 2.51076898632999

Epoch: 6| Step: 8
Training loss: 3.1697588095381217
Validation loss: 2.5204032333401445

Epoch: 6| Step: 9
Training loss: 2.263746653680208
Validation loss: 2.5232188193121337

Epoch: 6| Step: 10
Training loss: 2.458823225272042
Validation loss: 2.5337832510638227

Epoch: 6| Step: 11
Training loss: 3.665444054653931
Validation loss: 2.5367891752381935

Epoch: 6| Step: 12
Training loss: 3.223585330089944
Validation loss: 2.5424754427607996

Epoch: 6| Step: 13
Training loss: 2.5649759379963
Validation loss: 2.5363103968263143

Epoch: 148| Step: 0
Training loss: 2.7522585004283178
Validation loss: 2.5514798811849078

Epoch: 6| Step: 1
Training loss: 2.49923751647524
Validation loss: 2.5629455295147547

Epoch: 6| Step: 2
Training loss: 2.7677889187047193
Validation loss: 2.567607629474368

Epoch: 6| Step: 3
Training loss: 3.217525953115556
Validation loss: 2.5794964177797626

Epoch: 6| Step: 4
Training loss: 3.1655907225188726
Validation loss: 2.573840293654871

Epoch: 6| Step: 5
Training loss: 2.7456797563114947
Validation loss: 2.5727911331449502

Epoch: 6| Step: 6
Training loss: 2.9652959707408293
Validation loss: 2.555253707870611

Epoch: 6| Step: 7
Training loss: 3.1528344132932964
Validation loss: 2.55229137711979

Epoch: 6| Step: 8
Training loss: 2.7064486670750303
Validation loss: 2.546298933934146

Epoch: 6| Step: 9
Training loss: 2.9884787899373277
Validation loss: 2.5535204355546064

Epoch: 6| Step: 10
Training loss: 2.323250397342577
Validation loss: 2.55719307593996

Epoch: 6| Step: 11
Training loss: 3.0842196934644117
Validation loss: 2.5675652706707073

Epoch: 6| Step: 12
Training loss: 2.2821018248565665
Validation loss: 2.567377187704411

Epoch: 6| Step: 13
Training loss: 3.3186900045428227
Validation loss: 2.5720673194997357

Epoch: 149| Step: 0
Training loss: 2.6142503341436742
Validation loss: 2.5717954547038877

Epoch: 6| Step: 1
Training loss: 3.0602793524890823
Validation loss: 2.586034488621936

Epoch: 6| Step: 2
Training loss: 2.5109397902415953
Validation loss: 2.583592415426792

Epoch: 6| Step: 3
Training loss: 2.8475922837680248
Validation loss: 2.5811505177623006

Epoch: 6| Step: 4
Training loss: 3.010390724853533
Validation loss: 2.5886154423440844

Epoch: 6| Step: 5
Training loss: 2.7538846062425186
Validation loss: 2.5776807077167727

Epoch: 6| Step: 6
Training loss: 2.960192745222376
Validation loss: 2.5808196770844196

Epoch: 6| Step: 7
Training loss: 2.914619944744468
Validation loss: 2.5930442111716587

Epoch: 6| Step: 8
Training loss: 2.385599476390656
Validation loss: 2.5977851543938573

Epoch: 6| Step: 9
Training loss: 3.1581789675173795
Validation loss: 2.596937340042091

Epoch: 6| Step: 10
Training loss: 2.474119985552717
Validation loss: 2.5822546318089645

Epoch: 6| Step: 11
Training loss: 2.9506373347384365
Validation loss: 2.587527058270514

Epoch: 6| Step: 12
Training loss: 3.423097157068218
Validation loss: 2.582485074262998

Epoch: 6| Step: 13
Training loss: 3.30626653367868
Validation loss: 2.5804251862288683

Epoch: 150| Step: 0
Training loss: 2.417696788080391
Validation loss: 2.5794471410761513

Epoch: 6| Step: 1
Training loss: 2.9198282998697396
Validation loss: 2.5759849518776083

Epoch: 6| Step: 2
Training loss: 3.1193167314875048
Validation loss: 2.5829630825250587

Epoch: 6| Step: 3
Training loss: 2.778681994664363
Validation loss: 2.5809921952298263

Epoch: 6| Step: 4
Training loss: 2.56801254193342
Validation loss: 2.5910311089727527

Epoch: 6| Step: 5
Training loss: 3.0927990309171545
Validation loss: 2.5880991460770972

Epoch: 6| Step: 6
Training loss: 2.2779676260050215
Validation loss: 2.595467331141422

Epoch: 6| Step: 7
Training loss: 2.729971953726548
Validation loss: 2.5980555724974277

Epoch: 6| Step: 8
Training loss: 3.166455228338738
Validation loss: 2.605157998360049

Epoch: 6| Step: 9
Training loss: 3.0267550775944283
Validation loss: 2.6131075063674487

Epoch: 6| Step: 10
Training loss: 3.093040153679378
Validation loss: 2.6050891799294495

Epoch: 6| Step: 11
Training loss: 3.3520873043462744
Validation loss: 2.5782554536282993

Epoch: 6| Step: 12
Training loss: 2.8406845170470136
Validation loss: 2.5625980687577896

Epoch: 6| Step: 13
Training loss: 2.1985664552175384
Validation loss: 2.525737499974148

Epoch: 151| Step: 0
Training loss: 2.401631964707038
Validation loss: 2.518011853374818

Epoch: 6| Step: 1
Training loss: 3.035501860551259
Validation loss: 2.5269211934784828

Epoch: 6| Step: 2
Training loss: 2.5867922197264144
Validation loss: 2.544641903463222

Epoch: 6| Step: 3
Training loss: 3.6434713214548116
Validation loss: 2.5572474681594493

Epoch: 6| Step: 4
Training loss: 2.5576724657841208
Validation loss: 2.52783287452867

Epoch: 6| Step: 5
Training loss: 2.6657124441278044
Validation loss: 2.509853367408706

Epoch: 6| Step: 6
Training loss: 2.5337587334021756
Validation loss: 2.5066502784773323

Epoch: 6| Step: 7
Training loss: 2.9311537671915793
Validation loss: 2.5028181968047662

Epoch: 6| Step: 8
Training loss: 2.9648903904640083
Validation loss: 2.5019460845804917

Epoch: 6| Step: 9
Training loss: 3.2734141929361193
Validation loss: 2.499353747773065

Epoch: 6| Step: 10
Training loss: 2.6040703310631867
Validation loss: 2.500104684586306

Epoch: 6| Step: 11
Training loss: 3.2499923705965137
Validation loss: 2.496256633484786

Epoch: 6| Step: 12
Training loss: 2.7521342751935394
Validation loss: 2.5047148544533955

Epoch: 6| Step: 13
Training loss: 2.5541845170642414
Validation loss: 2.511465777010151

Epoch: 152| Step: 0
Training loss: 2.8633308770639574
Validation loss: 2.5590346600780545

Epoch: 6| Step: 1
Training loss: 3.10317251854785
Validation loss: 2.589600954132866

Epoch: 6| Step: 2
Training loss: 2.981018255731323
Validation loss: 2.603089395166885

Epoch: 6| Step: 3
Training loss: 2.947025842942292
Validation loss: 2.601316545409142

Epoch: 6| Step: 4
Training loss: 2.9768772709733917
Validation loss: 2.5831708049821036

Epoch: 6| Step: 5
Training loss: 2.829026895103292
Validation loss: 2.54019466832715

Epoch: 6| Step: 6
Training loss: 2.32843957606269
Validation loss: 2.525068817370513

Epoch: 6| Step: 7
Training loss: 2.806435722883174
Validation loss: 2.519070714775936

Epoch: 6| Step: 8
Training loss: 2.9400670623915817
Validation loss: 2.512446212213215

Epoch: 6| Step: 9
Training loss: 3.006368235842446
Validation loss: 2.50514828018977

Epoch: 6| Step: 10
Training loss: 2.7011954416169623
Validation loss: 2.517061433211749

Epoch: 6| Step: 11
Training loss: 2.373030197022154
Validation loss: 2.501587759366969

Epoch: 6| Step: 12
Training loss: 2.8316227480165788
Validation loss: 2.504850816973102

Epoch: 6| Step: 13
Training loss: 3.373926345156922
Validation loss: 2.5141017589668633

Epoch: 153| Step: 0
Training loss: 2.823387604078868
Validation loss: 2.5210783054718378

Epoch: 6| Step: 1
Training loss: 3.060591122247159
Validation loss: 2.53124677322893

Epoch: 6| Step: 2
Training loss: 2.64537551002694
Validation loss: 2.54657730485596

Epoch: 6| Step: 3
Training loss: 2.485180802090582
Validation loss: 2.547076717249678

Epoch: 6| Step: 4
Training loss: 3.4571451804143134
Validation loss: 2.592626006641432

Epoch: 6| Step: 5
Training loss: 3.3227543008931617
Validation loss: 2.615735263592664

Epoch: 6| Step: 6
Training loss: 2.2343809754618524
Validation loss: 2.572529517590326

Epoch: 6| Step: 7
Training loss: 2.420783603002027
Validation loss: 2.5461044086914524

Epoch: 6| Step: 8
Training loss: 3.081600956922008
Validation loss: 2.5376139613348534

Epoch: 6| Step: 9
Training loss: 3.4684035669487274
Validation loss: 2.5366846210097185

Epoch: 6| Step: 10
Training loss: 2.216525614942624
Validation loss: 2.53235030278958

Epoch: 6| Step: 11
Training loss: 2.1410550987141783
Validation loss: 2.520158114031359

Epoch: 6| Step: 12
Training loss: 3.085037138729268
Validation loss: 2.529058840119678

Epoch: 6| Step: 13
Training loss: 3.069766862447817
Validation loss: 2.5330823967791467

Epoch: 154| Step: 0
Training loss: 3.13491180174175
Validation loss: 2.5441637725242345

Epoch: 6| Step: 1
Training loss: 3.2981559109174516
Validation loss: 2.5506624674272036

Epoch: 6| Step: 2
Training loss: 2.1349496718467065
Validation loss: 2.5450407582855243

Epoch: 6| Step: 3
Training loss: 2.9765876508636406
Validation loss: 2.5370607008059674

Epoch: 6| Step: 4
Training loss: 2.727545181305793
Validation loss: 2.529788270879961

Epoch: 6| Step: 5
Training loss: 2.435942910551139
Validation loss: 2.5348473997883776

Epoch: 6| Step: 6
Training loss: 2.382338780075016
Validation loss: 2.5355332147067244

Epoch: 6| Step: 7
Training loss: 2.5473892535245115
Validation loss: 2.535210059305748

Epoch: 6| Step: 8
Training loss: 2.577691428978136
Validation loss: 2.5343321996082397

Epoch: 6| Step: 9
Training loss: 2.68592247018387
Validation loss: 2.528438282101055

Epoch: 6| Step: 10
Training loss: 3.43357986256435
Validation loss: 2.5100185058284796

Epoch: 6| Step: 11
Training loss: 2.6395034665552677
Validation loss: 2.50581264432295

Epoch: 6| Step: 12
Training loss: 2.8123686018025422
Validation loss: 2.5185719754800195

Epoch: 6| Step: 13
Training loss: 4.014483931689473
Validation loss: 2.5172494219165067

Epoch: 155| Step: 0
Training loss: 3.0678722983270954
Validation loss: 2.520565215655788

Epoch: 6| Step: 1
Training loss: 2.982374869165426
Validation loss: 2.5145614384369157

Epoch: 6| Step: 2
Training loss: 2.852345816267483
Validation loss: 2.528212561708987

Epoch: 6| Step: 3
Training loss: 2.808390603391822
Validation loss: 2.5268543638964394

Epoch: 6| Step: 4
Training loss: 2.955930638553856
Validation loss: 2.531158646150794

Epoch: 6| Step: 5
Training loss: 3.0262661892734823
Validation loss: 2.537716975084647

Epoch: 6| Step: 6
Training loss: 2.3620563958498733
Validation loss: 2.5288523250517576

Epoch: 6| Step: 7
Training loss: 2.902578187820885
Validation loss: 2.5242010025912416

Epoch: 6| Step: 8
Training loss: 3.0251015512113972
Validation loss: 2.5271578634160776

Epoch: 6| Step: 9
Training loss: 2.130216031111136
Validation loss: 2.5217295427926207

Epoch: 6| Step: 10
Training loss: 2.6921938337626816
Validation loss: 2.499396533323779

Epoch: 6| Step: 11
Training loss: 3.0899554785820365
Validation loss: 2.498794623987485

Epoch: 6| Step: 12
Training loss: 2.6112426652526834
Validation loss: 2.508006307193334

Epoch: 6| Step: 13
Training loss: 2.9985185780181065
Validation loss: 2.515896569978416

Epoch: 156| Step: 0
Training loss: 2.6312196707166824
Validation loss: 2.5189914413499745

Epoch: 6| Step: 1
Training loss: 2.965438119770416
Validation loss: 2.5163456419567622

Epoch: 6| Step: 2
Training loss: 2.5844467798894706
Validation loss: 2.5090157139071314

Epoch: 6| Step: 3
Training loss: 2.225414314699695
Validation loss: 2.5077098137557985

Epoch: 6| Step: 4
Training loss: 2.817176237417041
Validation loss: 2.5014319605246094

Epoch: 6| Step: 5
Training loss: 2.593463744028313
Validation loss: 2.5065945229111866

Epoch: 6| Step: 6
Training loss: 3.191959477896409
Validation loss: 2.510246759920763

Epoch: 6| Step: 7
Training loss: 3.2855458068301675
Validation loss: 2.503151044005587

Epoch: 6| Step: 8
Training loss: 2.702035849886123
Validation loss: 2.5066128036283937

Epoch: 6| Step: 9
Training loss: 2.877915935399362
Validation loss: 2.5182608917715488

Epoch: 6| Step: 10
Training loss: 3.277537543622272
Validation loss: 2.513409313889885

Epoch: 6| Step: 11
Training loss: 2.4702408550376163
Validation loss: 2.537469645141366

Epoch: 6| Step: 12
Training loss: 2.652480828362445
Validation loss: 2.5592457606613404

Epoch: 6| Step: 13
Training loss: 3.0491978325249742
Validation loss: 2.5670944542027962

Epoch: 157| Step: 0
Training loss: 2.808680590055036
Validation loss: 2.629216721170406

Epoch: 6| Step: 1
Training loss: 2.6749320583093406
Validation loss: 2.653914583697525

Epoch: 6| Step: 2
Training loss: 3.1403629326488494
Validation loss: 2.73037786847594

Epoch: 6| Step: 3
Training loss: 3.0563841495833306
Validation loss: 2.67453214878057

Epoch: 6| Step: 4
Training loss: 3.0294711212277674
Validation loss: 2.5870526169211248

Epoch: 6| Step: 5
Training loss: 2.809119333211506
Validation loss: 2.535677374199344

Epoch: 6| Step: 6
Training loss: 2.5058622293314805
Validation loss: 2.5200301758489023

Epoch: 6| Step: 7
Training loss: 3.088613542532038
Validation loss: 2.4938851863612856

Epoch: 6| Step: 8
Training loss: 3.0372002787340335
Validation loss: 2.4945709740951973

Epoch: 6| Step: 9
Training loss: 3.045985478377214
Validation loss: 2.4958060371888986

Epoch: 6| Step: 10
Training loss: 3.063910490367001
Validation loss: 2.496282574191957

Epoch: 6| Step: 11
Training loss: 2.6587588859520808
Validation loss: 2.4990619396675586

Epoch: 6| Step: 12
Training loss: 2.7929318725712267
Validation loss: 2.495813381511054

Epoch: 6| Step: 13
Training loss: 2.5441617965110184
Validation loss: 2.494032477862112

Epoch: 158| Step: 0
Training loss: 3.0417721002847666
Validation loss: 2.4991448344663674

Epoch: 6| Step: 1
Training loss: 2.6989143520134897
Validation loss: 2.4946437544109408

Epoch: 6| Step: 2
Training loss: 2.8109714168858195
Validation loss: 2.493995972403317

Epoch: 6| Step: 3
Training loss: 2.5538939197110766
Validation loss: 2.4948463869812705

Epoch: 6| Step: 4
Training loss: 2.5251114433547452
Validation loss: 2.493531619081527

Epoch: 6| Step: 5
Training loss: 3.2813034779868255
Validation loss: 2.5027824637890372

Epoch: 6| Step: 6
Training loss: 2.4882525048624187
Validation loss: 2.4957273139426164

Epoch: 6| Step: 7
Training loss: 2.9490035426964862
Validation loss: 2.5161113081703004

Epoch: 6| Step: 8
Training loss: 2.760522823571732
Validation loss: 2.524587772573457

Epoch: 6| Step: 9
Training loss: 2.9170614974398794
Validation loss: 2.536076229743502

Epoch: 6| Step: 10
Training loss: 2.808438823390202
Validation loss: 2.5415745023669802

Epoch: 6| Step: 11
Training loss: 2.849089252781053
Validation loss: 2.55889788869879

Epoch: 6| Step: 12
Training loss: 2.766448679536418
Validation loss: 2.574870278865943

Epoch: 6| Step: 13
Training loss: 3.3126435158787397
Validation loss: 2.6007734069734547

Epoch: 159| Step: 0
Training loss: 2.8298066761317435
Validation loss: 2.5995240724048916

Epoch: 6| Step: 1
Training loss: 2.588828415726032
Validation loss: 2.585841885806506

Epoch: 6| Step: 2
Training loss: 2.4974724390229412
Validation loss: 2.564647126175164

Epoch: 6| Step: 3
Training loss: 2.947833128555379
Validation loss: 2.5889428013350804

Epoch: 6| Step: 4
Training loss: 2.3557215819038873
Validation loss: 2.554421920747482

Epoch: 6| Step: 5
Training loss: 3.4474724121317735
Validation loss: 2.5547928226603056

Epoch: 6| Step: 6
Training loss: 2.397044022430792
Validation loss: 2.5291036907320756

Epoch: 6| Step: 7
Training loss: 2.1718699503229293
Validation loss: 2.5316012488343476

Epoch: 6| Step: 8
Training loss: 3.3725500751507624
Validation loss: 2.52391059342149

Epoch: 6| Step: 9
Training loss: 2.8126168120815898
Validation loss: 2.5168380681245863

Epoch: 6| Step: 10
Training loss: 3.014729895694495
Validation loss: 2.511674142161139

Epoch: 6| Step: 11
Training loss: 3.1066990364691334
Validation loss: 2.499975468915132

Epoch: 6| Step: 12
Training loss: 2.7141576984160922
Validation loss: 2.4979801734958462

Epoch: 6| Step: 13
Training loss: 3.1132259579370944
Validation loss: 2.4910071375049103

Epoch: 160| Step: 0
Training loss: 2.5659547173421036
Validation loss: 2.492691972904592

Epoch: 6| Step: 1
Training loss: 2.469096002596465
Validation loss: 2.485197959121504

Epoch: 6| Step: 2
Training loss: 2.835766495522236
Validation loss: 2.49661029798316

Epoch: 6| Step: 3
Training loss: 2.9031596827411428
Validation loss: 2.5019891239711973

Epoch: 6| Step: 4
Training loss: 3.175541304454084
Validation loss: 2.511007211332639

Epoch: 6| Step: 5
Training loss: 2.7216644450932175
Validation loss: 2.5083191573587627

Epoch: 6| Step: 6
Training loss: 3.0853672707926867
Validation loss: 2.518917711181281

Epoch: 6| Step: 7
Training loss: 2.957440649035229
Validation loss: 2.5154334746775673

Epoch: 6| Step: 8
Training loss: 2.6244506261058116
Validation loss: 2.517641283784791

Epoch: 6| Step: 9
Training loss: 2.571779151511729
Validation loss: 2.509634149669336

Epoch: 6| Step: 10
Training loss: 3.173040767721563
Validation loss: 2.5028043338687787

Epoch: 6| Step: 11
Training loss: 2.7371024343871615
Validation loss: 2.515808382090902

Epoch: 6| Step: 12
Training loss: 2.9206582866317157
Validation loss: 2.510408488192942

Epoch: 6| Step: 13
Training loss: 2.4839362950717665
Validation loss: 2.5250660385598

Epoch: 161| Step: 0
Training loss: 3.033204539851972
Validation loss: 2.5339069396160183

Epoch: 6| Step: 1
Training loss: 3.1184090345753854
Validation loss: 2.574902504503826

Epoch: 6| Step: 2
Training loss: 2.6562885954801723
Validation loss: 2.602538031148611

Epoch: 6| Step: 3
Training loss: 2.4293524704328404
Validation loss: 2.604772349811798

Epoch: 6| Step: 4
Training loss: 2.6202791542838546
Validation loss: 2.6152193120993945

Epoch: 6| Step: 5
Training loss: 2.811417519686683
Validation loss: 2.601888492135192

Epoch: 6| Step: 6
Training loss: 3.499493698557012
Validation loss: 2.5788402690054637

Epoch: 6| Step: 7
Training loss: 2.5121015432025424
Validation loss: 2.562099206346104

Epoch: 6| Step: 8
Training loss: 3.037027103990199
Validation loss: 2.5339872943292128

Epoch: 6| Step: 9
Training loss: 2.5426258611893755
Validation loss: 2.5184047685384474

Epoch: 6| Step: 10
Training loss: 3.0109748366871294
Validation loss: 2.5261455068419103

Epoch: 6| Step: 11
Training loss: 2.699551728794614
Validation loss: 2.516097270883697

Epoch: 6| Step: 12
Training loss: 2.5845674417751194
Validation loss: 2.519784991253852

Epoch: 6| Step: 13
Training loss: 2.501287033668584
Validation loss: 2.5189774384323917

Epoch: 162| Step: 0
Training loss: 2.832629583884393
Validation loss: 2.5085049958815877

Epoch: 6| Step: 1
Training loss: 2.9400083505421075
Validation loss: 2.5108420092906014

Epoch: 6| Step: 2
Training loss: 2.953975171624703
Validation loss: 2.511759666360051

Epoch: 6| Step: 3
Training loss: 2.9531128898251198
Validation loss: 2.5071862763075563

Epoch: 6| Step: 4
Training loss: 2.845642968918479
Validation loss: 2.5183418088307916

Epoch: 6| Step: 5
Training loss: 2.453781720353328
Validation loss: 2.5332905889471453

Epoch: 6| Step: 6
Training loss: 2.347260554475302
Validation loss: 2.530328694099647

Epoch: 6| Step: 7
Training loss: 3.0042606933383125
Validation loss: 2.545820555317456

Epoch: 6| Step: 8
Training loss: 2.754166481221972
Validation loss: 2.544255285143866

Epoch: 6| Step: 9
Training loss: 3.141615526371671
Validation loss: 2.581807442741661

Epoch: 6| Step: 10
Training loss: 2.8878548210088613
Validation loss: 2.5813872489382654

Epoch: 6| Step: 11
Training loss: 2.58369103898245
Validation loss: 2.5797774631457626

Epoch: 6| Step: 12
Training loss: 2.820748250590043
Validation loss: 2.585806274950886

Epoch: 6| Step: 13
Training loss: 2.6259781967617637
Validation loss: 2.56745494718928

Epoch: 163| Step: 0
Training loss: 3.005004840662861
Validation loss: 2.5497373049513854

Epoch: 6| Step: 1
Training loss: 2.6755881580934195
Validation loss: 2.5528006038960234

Epoch: 6| Step: 2
Training loss: 2.970977429448346
Validation loss: 2.5222137215565197

Epoch: 6| Step: 3
Training loss: 2.9100187742800903
Validation loss: 2.5292332974969

Epoch: 6| Step: 4
Training loss: 2.8112063505686122
Validation loss: 2.5157355175532343

Epoch: 6| Step: 5
Training loss: 2.9998938223804923
Validation loss: 2.508001470220177

Epoch: 6| Step: 6
Training loss: 2.907213277020786
Validation loss: 2.5209827746607694

Epoch: 6| Step: 7
Training loss: 2.4224764169464317
Validation loss: 2.5523882682265566

Epoch: 6| Step: 8
Training loss: 3.0548295478281893
Validation loss: 2.5828085997247516

Epoch: 6| Step: 9
Training loss: 2.11210895959516
Validation loss: 2.6025413084213813

Epoch: 6| Step: 10
Training loss: 2.71987716285237
Validation loss: 2.6682352210335893

Epoch: 6| Step: 11
Training loss: 2.8546009336645493
Validation loss: 2.593027011386225

Epoch: 6| Step: 12
Training loss: 2.7702247601431558
Validation loss: 2.570534839720215

Epoch: 6| Step: 13
Training loss: 3.1446652970264206
Validation loss: 2.528490698819682

Epoch: 164| Step: 0
Training loss: 2.2040390391137583
Validation loss: 2.5103756542086977

Epoch: 6| Step: 1
Training loss: 3.0778445972973203
Validation loss: 2.509773524496055

Epoch: 6| Step: 2
Training loss: 2.525174986564011
Validation loss: 2.4997904710231196

Epoch: 6| Step: 3
Training loss: 2.7452733427326246
Validation loss: 2.5037869822137284

Epoch: 6| Step: 4
Training loss: 2.7790853241584066
Validation loss: 2.5008778538248535

Epoch: 6| Step: 5
Training loss: 2.6169854385035
Validation loss: 2.4963839713334797

Epoch: 6| Step: 6
Training loss: 3.059262802981313
Validation loss: 2.49791909337222

Epoch: 6| Step: 7
Training loss: 3.3258708071686374
Validation loss: 2.497618342680407

Epoch: 6| Step: 8
Training loss: 2.814710299557411
Validation loss: 2.5012134006887123

Epoch: 6| Step: 9
Training loss: 3.260614959894377
Validation loss: 2.5032734912474712

Epoch: 6| Step: 10
Training loss: 3.202100934336199
Validation loss: 2.5023719389862995

Epoch: 6| Step: 11
Training loss: 3.200777710346316
Validation loss: 2.500203548881854

Epoch: 6| Step: 12
Training loss: 2.75859529878178
Validation loss: 2.4984977330890366

Epoch: 6| Step: 13
Training loss: 1.7284904521251394
Validation loss: 2.5195249760441443

Epoch: 165| Step: 0
Training loss: 2.597824756635159
Validation loss: 2.5165916327849565

Epoch: 6| Step: 1
Training loss: 3.232153382920225
Validation loss: 2.5283071207174896

Epoch: 6| Step: 2
Training loss: 2.7543205652988583
Validation loss: 2.5541635486353766

Epoch: 6| Step: 3
Training loss: 3.11043327379914
Validation loss: 2.5714006013060353

Epoch: 6| Step: 4
Training loss: 2.7461323850689467
Validation loss: 2.6289928927690145

Epoch: 6| Step: 5
Training loss: 3.177901982797466
Validation loss: 2.6430625065656206

Epoch: 6| Step: 6
Training loss: 2.923915538105472
Validation loss: 2.628240076995637

Epoch: 6| Step: 7
Training loss: 2.3575729663030307
Validation loss: 2.5804584323458384

Epoch: 6| Step: 8
Training loss: 2.5326848613905164
Validation loss: 2.543061506260969

Epoch: 6| Step: 9
Training loss: 2.401634247998064
Validation loss: 2.5126972500018

Epoch: 6| Step: 10
Training loss: 2.9162277073014238
Validation loss: 2.492768430732088

Epoch: 6| Step: 11
Training loss: 2.7092876415842797
Validation loss: 2.485833864795042

Epoch: 6| Step: 12
Training loss: 3.2301772146357015
Validation loss: 2.4833115401312766

Epoch: 6| Step: 13
Training loss: 3.221036820853488
Validation loss: 2.483130087576835

Epoch: 166| Step: 0
Training loss: 2.8774019242184594
Validation loss: 2.4903498786843117

Epoch: 6| Step: 1
Training loss: 2.9750940901038243
Validation loss: 2.489871382005191

Epoch: 6| Step: 2
Training loss: 2.4693558347938773
Validation loss: 2.4870376790490947

Epoch: 6| Step: 3
Training loss: 3.054965657791931
Validation loss: 2.491172059806486

Epoch: 6| Step: 4
Training loss: 2.2375052340142605
Validation loss: 2.491056977083784

Epoch: 6| Step: 5
Training loss: 2.479278519188195
Validation loss: 2.50135859316031

Epoch: 6| Step: 6
Training loss: 3.168035579404538
Validation loss: 2.517355070539466

Epoch: 6| Step: 7
Training loss: 2.5493113092657578
Validation loss: 2.538016170100298

Epoch: 6| Step: 8
Training loss: 2.347260554475302
Validation loss: 2.5568890633219636

Epoch: 6| Step: 9
Training loss: 2.4631495630820073
Validation loss: 2.5508333327212087

Epoch: 6| Step: 10
Training loss: 3.4409775223334576
Validation loss: 2.555776362453127

Epoch: 6| Step: 11
Training loss: 3.31875480464724
Validation loss: 2.5553556563671176

Epoch: 6| Step: 12
Training loss: 2.5658350385771937
Validation loss: 2.5700223058048026

Epoch: 6| Step: 13
Training loss: 3.3035439390710466
Validation loss: 2.5645985707782946

Epoch: 167| Step: 0
Training loss: 2.6557860025290534
Validation loss: 2.548507535614946

Epoch: 6| Step: 1
Training loss: 3.114504469741698
Validation loss: 2.524071248135411

Epoch: 6| Step: 2
Training loss: 3.1199999672327285
Validation loss: 2.5213823299500566

Epoch: 6| Step: 3
Training loss: 2.7651942720508114
Validation loss: 2.51455708305227

Epoch: 6| Step: 4
Training loss: 2.2573543730579755
Validation loss: 2.514507891762183

Epoch: 6| Step: 5
Training loss: 2.6760329524920814
Validation loss: 2.507935776107013

Epoch: 6| Step: 6
Training loss: 2.8822149882556283
Validation loss: 2.502499449706307

Epoch: 6| Step: 7
Training loss: 1.8495204303950608
Validation loss: 2.5083477021759943

Epoch: 6| Step: 8
Training loss: 2.880207983825184
Validation loss: 2.505852658612203

Epoch: 6| Step: 9
Training loss: 2.929720377419689
Validation loss: 2.502133216110322

Epoch: 6| Step: 10
Training loss: 2.888238364931318
Validation loss: 2.505919224228312

Epoch: 6| Step: 11
Training loss: 2.6680924259859355
Validation loss: 2.500192479958313

Epoch: 6| Step: 12
Training loss: 2.994622815665684
Validation loss: 2.502956813747698

Epoch: 6| Step: 13
Training loss: 3.299266219198451
Validation loss: 2.5127678264910442

Epoch: 168| Step: 0
Training loss: 2.7650553660859583
Validation loss: 2.5194488570425326

Epoch: 6| Step: 1
Training loss: 3.1506162918536513
Validation loss: 2.549150706555286

Epoch: 6| Step: 2
Training loss: 2.651738992548254
Validation loss: 2.539975520729714

Epoch: 6| Step: 3
Training loss: 3.1091138260385645
Validation loss: 2.565653682398179

Epoch: 6| Step: 4
Training loss: 2.7570905307742897
Validation loss: 2.557652578409063

Epoch: 6| Step: 5
Training loss: 2.495554404575033
Validation loss: 2.5703493737709744

Epoch: 6| Step: 6
Training loss: 2.324834969518922
Validation loss: 2.5572860941934685

Epoch: 6| Step: 7
Training loss: 2.1814716652764043
Validation loss: 2.557923163151195

Epoch: 6| Step: 8
Training loss: 3.234237299397414
Validation loss: 2.5591647755485947

Epoch: 6| Step: 9
Training loss: 2.6355410057761275
Validation loss: 2.554026342750662

Epoch: 6| Step: 10
Training loss: 2.7154708906371927
Validation loss: 2.541198246190307

Epoch: 6| Step: 11
Training loss: 2.9250741672079004
Validation loss: 2.5434291228747834

Epoch: 6| Step: 12
Training loss: 3.0048688479729138
Validation loss: 2.553043442205929

Epoch: 6| Step: 13
Training loss: 3.1361866424838527
Validation loss: 2.522664584589792

Epoch: 169| Step: 0
Training loss: 3.3531498917849385
Validation loss: 2.5352518099774963

Epoch: 6| Step: 1
Training loss: 2.1358058171677174
Validation loss: 2.5276944290471772

Epoch: 6| Step: 2
Training loss: 2.8926138969027955
Validation loss: 2.5324795267667457

Epoch: 6| Step: 3
Training loss: 3.2976614208492685
Validation loss: 2.5138871428176683

Epoch: 6| Step: 4
Training loss: 2.7617470660235077
Validation loss: 2.529475104451852

Epoch: 6| Step: 5
Training loss: 2.4981029942631046
Validation loss: 2.5360519485558424

Epoch: 6| Step: 6
Training loss: 2.5432333156706273
Validation loss: 2.5504602678385533

Epoch: 6| Step: 7
Training loss: 2.6985846518554832
Validation loss: 2.568036867334672

Epoch: 6| Step: 8
Training loss: 3.119810449270898
Validation loss: 2.551754136458412

Epoch: 6| Step: 9
Training loss: 2.6355994441363126
Validation loss: 2.538359708870027

Epoch: 6| Step: 10
Training loss: 2.5295368566774337
Validation loss: 2.527600945559664

Epoch: 6| Step: 11
Training loss: 2.8600853209673467
Validation loss: 2.5160739299132358

Epoch: 6| Step: 12
Training loss: 2.967222121741306
Validation loss: 2.508925759622819

Epoch: 6| Step: 13
Training loss: 2.082184118559827
Validation loss: 2.508378345921113

Epoch: 170| Step: 0
Training loss: 2.7072979243872664
Validation loss: 2.5127572740673427

Epoch: 6| Step: 1
Training loss: 2.9222325396949924
Validation loss: 2.504465821281677

Epoch: 6| Step: 2
Training loss: 2.874813571358734
Validation loss: 2.4971945680454377

Epoch: 6| Step: 3
Training loss: 2.9654439085005286
Validation loss: 2.495045490100495

Epoch: 6| Step: 4
Training loss: 3.447580157835659
Validation loss: 2.491326018255886

Epoch: 6| Step: 5
Training loss: 2.73662104321952
Validation loss: 2.4931385294484265

Epoch: 6| Step: 6
Training loss: 2.44994512613308
Validation loss: 2.492667562737892

Epoch: 6| Step: 7
Training loss: 3.1965165609440613
Validation loss: 2.4921028692978235

Epoch: 6| Step: 8
Training loss: 2.9720652490284296
Validation loss: 2.499410672611295

Epoch: 6| Step: 9
Training loss: 1.9714610492013447
Validation loss: 2.5032584295387186

Epoch: 6| Step: 10
Training loss: 2.9004577012445782
Validation loss: 2.510984618893734

Epoch: 6| Step: 11
Training loss: 2.659579445570488
Validation loss: 2.511864736535564

Epoch: 6| Step: 12
Training loss: 2.3624247866975012
Validation loss: 2.52798847313695

Epoch: 6| Step: 13
Training loss: 2.09858225694545
Validation loss: 2.529300031281114

Epoch: 171| Step: 0
Training loss: 2.4750388479555547
Validation loss: 2.517387482520673

Epoch: 6| Step: 1
Training loss: 2.8390262481776736
Validation loss: 2.5292332255310246

Epoch: 6| Step: 2
Training loss: 2.3883712217524953
Validation loss: 2.5453090104902096

Epoch: 6| Step: 3
Training loss: 2.49184412967494
Validation loss: 2.5205962550047034

Epoch: 6| Step: 4
Training loss: 3.04221664751742
Validation loss: 2.539125800089128

Epoch: 6| Step: 5
Training loss: 2.665953739551882
Validation loss: 2.5310944124889914

Epoch: 6| Step: 6
Training loss: 3.0126332676957945
Validation loss: 2.530626490367543

Epoch: 6| Step: 7
Training loss: 2.8226638249037754
Validation loss: 2.5394255034869517

Epoch: 6| Step: 8
Training loss: 2.6489410371824507
Validation loss: 2.545110046049888

Epoch: 6| Step: 9
Training loss: 2.959465526577887
Validation loss: 2.5724099992090457

Epoch: 6| Step: 10
Training loss: 3.094203877148663
Validation loss: 2.560651147714065

Epoch: 6| Step: 11
Training loss: 2.35369279756489
Validation loss: 2.5608952677619303

Epoch: 6| Step: 12
Training loss: 3.337686620630982
Validation loss: 2.5237516553505706

Epoch: 6| Step: 13
Training loss: 2.2988883815183225
Validation loss: 2.5216686363541374

Epoch: 172| Step: 0
Training loss: 3.132544603570614
Validation loss: 2.5124711204962416

Epoch: 6| Step: 1
Training loss: 2.7754060877692055
Validation loss: 2.521459732665381

Epoch: 6| Step: 2
Training loss: 2.78553698747544
Validation loss: 2.5527765279809964

Epoch: 6| Step: 3
Training loss: 2.9155704799841287
Validation loss: 2.5713002969582317

Epoch: 6| Step: 4
Training loss: 2.5416077987440784
Validation loss: 2.6090707260731496

Epoch: 6| Step: 5
Training loss: 3.165309481322297
Validation loss: 2.610443235037451

Epoch: 6| Step: 6
Training loss: 2.1958266772676622
Validation loss: 2.607165995085927

Epoch: 6| Step: 7
Training loss: 2.598344708756885
Validation loss: 2.5893535326693042

Epoch: 6| Step: 8
Training loss: 3.0831456170203757
Validation loss: 2.577435399439249

Epoch: 6| Step: 9
Training loss: 3.0921662255201543
Validation loss: 2.5732074673017507

Epoch: 6| Step: 10
Training loss: 2.866817606419453
Validation loss: 2.548688601045014

Epoch: 6| Step: 11
Training loss: 2.3226192837110973
Validation loss: 2.539836071674773

Epoch: 6| Step: 12
Training loss: 2.548504173767851
Validation loss: 2.5168099455565747

Epoch: 6| Step: 13
Training loss: 2.723937511668424
Validation loss: 2.504067062996832

Epoch: 173| Step: 0
Training loss: 2.445386404072405
Validation loss: 2.4865420319340883

Epoch: 6| Step: 1
Training loss: 2.3311848853787027
Validation loss: 2.4940594325973455

Epoch: 6| Step: 2
Training loss: 2.62697009680275
Validation loss: 2.479179648736509

Epoch: 6| Step: 3
Training loss: 3.1882751120798245
Validation loss: 2.4842190163705777

Epoch: 6| Step: 4
Training loss: 3.031206425619073
Validation loss: 2.4811592611774054

Epoch: 6| Step: 5
Training loss: 2.8162012118174182
Validation loss: 2.4895650370670337

Epoch: 6| Step: 6
Training loss: 3.4489429402485525
Validation loss: 2.5046786571968362

Epoch: 6| Step: 7
Training loss: 2.3501578663496496
Validation loss: 2.5366982977809283

Epoch: 6| Step: 8
Training loss: 3.037563709485707
Validation loss: 2.58058977138132

Epoch: 6| Step: 9
Training loss: 2.5594768834591317
Validation loss: 2.624781877368979

Epoch: 6| Step: 10
Training loss: 2.6251404134344094
Validation loss: 2.617822929019312

Epoch: 6| Step: 11
Training loss: 2.456325605553805
Validation loss: 2.6519467419169875

Epoch: 6| Step: 12
Training loss: 2.920058394592826
Validation loss: 2.6157040536072484

Epoch: 6| Step: 13
Training loss: 3.0521024805364543
Validation loss: 2.557099317422679

Epoch: 174| Step: 0
Training loss: 3.3384195782520423
Validation loss: 2.5200760894811594

Epoch: 6| Step: 1
Training loss: 2.6418477675237115
Validation loss: 2.502617799542233

Epoch: 6| Step: 2
Training loss: 2.1149313754588803
Validation loss: 2.5060329697311854

Epoch: 6| Step: 3
Training loss: 3.1667890692360934
Validation loss: 2.4888264391120334

Epoch: 6| Step: 4
Training loss: 2.760377809263041
Validation loss: 2.4911745594652133

Epoch: 6| Step: 5
Training loss: 2.7734333736765078
Validation loss: 2.4985796492964973

Epoch: 6| Step: 6
Training loss: 2.6413381843631467
Validation loss: 2.5015173158142012

Epoch: 6| Step: 7
Training loss: 3.0412019000030286
Validation loss: 2.5031226826572652

Epoch: 6| Step: 8
Training loss: 2.45080359378512
Validation loss: 2.5053997217829

Epoch: 6| Step: 9
Training loss: 2.9938300581960893
Validation loss: 2.5183439231900677

Epoch: 6| Step: 10
Training loss: 2.656286172059546
Validation loss: 2.5284284105316646

Epoch: 6| Step: 11
Training loss: 2.5770566634142438
Validation loss: 2.527841224138609

Epoch: 6| Step: 12
Training loss: 2.915568517401552
Validation loss: 2.537681801162919

Epoch: 6| Step: 13
Training loss: 2.4786826123317565
Validation loss: 2.557550938988635

Epoch: 175| Step: 0
Training loss: 2.578951431521156
Validation loss: 2.546052378256514

Epoch: 6| Step: 1
Training loss: 2.148658657828774
Validation loss: 2.563982888904429

Epoch: 6| Step: 2
Training loss: 3.0142553510021215
Validation loss: 2.581415510642918

Epoch: 6| Step: 3
Training loss: 2.654441038010391
Validation loss: 2.553758427000278

Epoch: 6| Step: 4
Training loss: 3.173002596965007
Validation loss: 2.5349323464496987

Epoch: 6| Step: 5
Training loss: 2.533482826573716
Validation loss: 2.5230910485214846

Epoch: 6| Step: 6
Training loss: 3.142184956614538
Validation loss: 2.5078187664563085

Epoch: 6| Step: 7
Training loss: 2.684634433062455
Validation loss: 2.5041441378954343

Epoch: 6| Step: 8
Training loss: 2.8557057001871784
Validation loss: 2.499170667747166

Epoch: 6| Step: 9
Training loss: 2.825971848079686
Validation loss: 2.497480323511407

Epoch: 6| Step: 10
Training loss: 2.4471192921259517
Validation loss: 2.4991546924536188

Epoch: 6| Step: 11
Training loss: 2.5690554063701616
Validation loss: 2.4908527095756297

Epoch: 6| Step: 12
Training loss: 3.033885635845821
Validation loss: 2.5023448591598756

Epoch: 6| Step: 13
Training loss: 3.1508893104900477
Validation loss: 2.5037936969753525

Epoch: 176| Step: 0
Training loss: 3.0687806479483295
Validation loss: 2.5042992950589555

Epoch: 6| Step: 1
Training loss: 3.047584803139072
Validation loss: 2.5349424101255047

Epoch: 6| Step: 2
Training loss: 2.1925515838435685
Validation loss: 2.533104360489423

Epoch: 6| Step: 3
Training loss: 2.6479326965503116
Validation loss: 2.532347863009862

Epoch: 6| Step: 4
Training loss: 2.7749156183008856
Validation loss: 2.5262240057442344

Epoch: 6| Step: 5
Training loss: 2.6677292455181014
Validation loss: 2.532569824750476

Epoch: 6| Step: 6
Training loss: 2.8674748663894163
Validation loss: 2.525753736985091

Epoch: 6| Step: 7
Training loss: 2.273386636800815
Validation loss: 2.52299788626375

Epoch: 6| Step: 8
Training loss: 2.862401475834986
Validation loss: 2.526284663331086

Epoch: 6| Step: 9
Training loss: 2.7813939260896907
Validation loss: 2.5418374370521994

Epoch: 6| Step: 10
Training loss: 2.539340523390215
Validation loss: 2.5403388408134635

Epoch: 6| Step: 11
Training loss: 3.061272511397521
Validation loss: 2.5279432843044267

Epoch: 6| Step: 12
Training loss: 2.884616194504844
Validation loss: 2.5331540984503635

Epoch: 6| Step: 13
Training loss: 2.8256654107626265
Validation loss: 2.5351277552388574

Epoch: 177| Step: 0
Training loss: 3.05429316558398
Validation loss: 2.529400406872102

Epoch: 6| Step: 1
Training loss: 2.5985554680393674
Validation loss: 2.523365371868516

Epoch: 6| Step: 2
Training loss: 2.9882546018521787
Validation loss: 2.537825368876501

Epoch: 6| Step: 3
Training loss: 2.8219254971840972
Validation loss: 2.531796706132844

Epoch: 6| Step: 4
Training loss: 2.9982949815905138
Validation loss: 2.5661296364831157

Epoch: 6| Step: 5
Training loss: 2.1814775670655777
Validation loss: 2.561882099614229

Epoch: 6| Step: 6
Training loss: 2.593214416359802
Validation loss: 2.567494447115029

Epoch: 6| Step: 7
Training loss: 2.6670007695074296
Validation loss: 2.5613766145410097

Epoch: 6| Step: 8
Training loss: 2.255099028889072
Validation loss: 2.5317108755627578

Epoch: 6| Step: 9
Training loss: 2.4618728071340037
Validation loss: 2.533409245939867

Epoch: 6| Step: 10
Training loss: 3.086153819554239
Validation loss: 2.520269073642562

Epoch: 6| Step: 11
Training loss: 3.187492221000005
Validation loss: 2.4958384814676573

Epoch: 6| Step: 12
Training loss: 2.7345281939508252
Validation loss: 2.484703966772367

Epoch: 6| Step: 13
Training loss: 2.469777533207717
Validation loss: 2.4837709862419612

Epoch: 178| Step: 0
Training loss: 2.638146676428841
Validation loss: 2.4848542677613294

Epoch: 6| Step: 1
Training loss: 3.0245435007718973
Validation loss: 2.4941977150697228

Epoch: 6| Step: 2
Training loss: 2.845309992898573
Validation loss: 2.5023957811823916

Epoch: 6| Step: 3
Training loss: 3.101909320187175
Validation loss: 2.5275627482975453

Epoch: 6| Step: 4
Training loss: 2.603979505806948
Validation loss: 2.5371173111190566

Epoch: 6| Step: 5
Training loss: 2.1772456009790035
Validation loss: 2.545038794033615

Epoch: 6| Step: 6
Training loss: 3.1517014162221333
Validation loss: 2.5935004379019135

Epoch: 6| Step: 7
Training loss: 2.633041598259797
Validation loss: 2.5916732032924785

Epoch: 6| Step: 8
Training loss: 3.0983225621745367
Validation loss: 2.5768240442019477

Epoch: 6| Step: 9
Training loss: 2.9982558584532146
Validation loss: 2.514023547442241

Epoch: 6| Step: 10
Training loss: 2.5553618774644393
Validation loss: 2.4964464424922626

Epoch: 6| Step: 11
Training loss: 2.7585557146888444
Validation loss: 2.490050269794526

Epoch: 6| Step: 12
Training loss: 2.4141276822965816
Validation loss: 2.47808267132852

Epoch: 6| Step: 13
Training loss: 2.6438959392551484
Validation loss: 2.4739357433140476

Epoch: 179| Step: 0
Training loss: 2.730751732390973
Validation loss: 2.4806195726857365

Epoch: 6| Step: 1
Training loss: 2.6116395363760763
Validation loss: 2.4787843229636852

Epoch: 6| Step: 2
Training loss: 2.4921079042931957
Validation loss: 2.4955183672269095

Epoch: 6| Step: 3
Training loss: 2.722289839270268
Validation loss: 2.491600556675841

Epoch: 6| Step: 4
Training loss: 2.4705149462058045
Validation loss: 2.504710399040999

Epoch: 6| Step: 5
Training loss: 3.3535041075715877
Validation loss: 2.51708123593414

Epoch: 6| Step: 6
Training loss: 2.487476548127465
Validation loss: 2.5563502737548744

Epoch: 6| Step: 7
Training loss: 2.5953988958283074
Validation loss: 2.581188808944327

Epoch: 6| Step: 8
Training loss: 3.3247323810464224
Validation loss: 2.5908354727266936

Epoch: 6| Step: 9
Training loss: 2.8192537386268075
Validation loss: 2.5695398104758436

Epoch: 6| Step: 10
Training loss: 2.8047114719227118
Validation loss: 2.5720694076351864

Epoch: 6| Step: 11
Training loss: 2.3946794025334515
Validation loss: 2.5474767225140877

Epoch: 6| Step: 12
Training loss: 3.269000923051584
Validation loss: 2.546792960668474

Epoch: 6| Step: 13
Training loss: 2.574653368831426
Validation loss: 2.5174350197455944

Epoch: 180| Step: 0
Training loss: 2.719507922933027
Validation loss: 2.4938854289623342

Epoch: 6| Step: 1
Training loss: 3.0545516898558085
Validation loss: 2.473606015535238

Epoch: 6| Step: 2
Training loss: 2.2913273878082365
Validation loss: 2.470955923009822

Epoch: 6| Step: 3
Training loss: 3.100032707780136
Validation loss: 2.4688470462340235

Epoch: 6| Step: 4
Training loss: 2.6466175228844393
Validation loss: 2.4683592063727278

Epoch: 6| Step: 5
Training loss: 2.658805784457167
Validation loss: 2.470133420686899

Epoch: 6| Step: 6
Training loss: 3.1239350602437495
Validation loss: 2.473179439777774

Epoch: 6| Step: 7
Training loss: 2.695114349600379
Validation loss: 2.4904043411072605

Epoch: 6| Step: 8
Training loss: 2.9670562731192756
Validation loss: 2.4838411894458097

Epoch: 6| Step: 9
Training loss: 3.0647297741002935
Validation loss: 2.506440918300792

Epoch: 6| Step: 10
Training loss: 2.2444678218282963
Validation loss: 2.5316529909652807

Epoch: 6| Step: 11
Training loss: 3.0860215573994902
Validation loss: 2.573461144095868

Epoch: 6| Step: 12
Training loss: 2.267764639925662
Validation loss: 2.5438876972197293

Epoch: 6| Step: 13
Training loss: 2.411315737985558
Validation loss: 2.5692198727184796

Epoch: 181| Step: 0
Training loss: 3.2189930944401266
Validation loss: 2.579562741716946

Epoch: 6| Step: 1
Training loss: 2.9189405750735227
Validation loss: 2.575632824242129

Epoch: 6| Step: 2
Training loss: 2.6935963350088112
Validation loss: 2.5551536555980974

Epoch: 6| Step: 3
Training loss: 2.91765661242584
Validation loss: 2.5252938116989316

Epoch: 6| Step: 4
Training loss: 2.157896657044287
Validation loss: 2.509112720035523

Epoch: 6| Step: 5
Training loss: 2.36998721702766
Validation loss: 2.5042446628900286

Epoch: 6| Step: 6
Training loss: 2.8720030713503255
Validation loss: 2.499749272602109

Epoch: 6| Step: 7
Training loss: 3.340322145699175
Validation loss: 2.5081531373944377

Epoch: 6| Step: 8
Training loss: 2.690265917769652
Validation loss: 2.50064387695027

Epoch: 6| Step: 9
Training loss: 2.547142623227114
Validation loss: 2.5055635841800092

Epoch: 6| Step: 10
Training loss: 2.7987944766655386
Validation loss: 2.515080091235638

Epoch: 6| Step: 11
Training loss: 2.6041577656911685
Validation loss: 2.5250021616202467

Epoch: 6| Step: 12
Training loss: 1.9705866768858444
Validation loss: 2.528687106734177

Epoch: 6| Step: 13
Training loss: 3.2239670925401422
Validation loss: 2.5403723340257813

Epoch: 182| Step: 0
Training loss: 2.7135851680224317
Validation loss: 2.5298292770300637

Epoch: 6| Step: 1
Training loss: 2.5823387159149704
Validation loss: 2.556373768460363

Epoch: 6| Step: 2
Training loss: 2.966948273683891
Validation loss: 2.581742360609116

Epoch: 6| Step: 3
Training loss: 2.6905048339097077
Validation loss: 2.605474825859657

Epoch: 6| Step: 4
Training loss: 2.630257382580763
Validation loss: 2.6060785864336333

Epoch: 6| Step: 5
Training loss: 2.810542972819129
Validation loss: 2.565958829626833

Epoch: 6| Step: 6
Training loss: 2.6050609629814057
Validation loss: 2.581627176827851

Epoch: 6| Step: 7
Training loss: 2.36463019594873
Validation loss: 2.5858329065515577

Epoch: 6| Step: 8
Training loss: 2.792064771212428
Validation loss: 2.6030999004916464

Epoch: 6| Step: 9
Training loss: 2.953249328256697
Validation loss: 2.6059684718812033

Epoch: 6| Step: 10
Training loss: 2.7130187562546544
Validation loss: 2.586644237842037

Epoch: 6| Step: 11
Training loss: 2.9141570784124067
Validation loss: 2.5304593160736117

Epoch: 6| Step: 12
Training loss: 3.0144072134316344
Validation loss: 2.4928543536431143

Epoch: 6| Step: 13
Training loss: 2.5477691204262043
Validation loss: 2.4841932438066765

Epoch: 183| Step: 0
Training loss: 3.008353841047754
Validation loss: 2.47958085124864

Epoch: 6| Step: 1
Training loss: 2.9588784982604914
Validation loss: 2.473509572664057

Epoch: 6| Step: 2
Training loss: 2.8083425523585865
Validation loss: 2.473640991651871

Epoch: 6| Step: 3
Training loss: 3.1418023630749032
Validation loss: 2.466157247728703

Epoch: 6| Step: 4
Training loss: 2.619959487747424
Validation loss: 2.463403891790756

Epoch: 6| Step: 5
Training loss: 2.1617858148393707
Validation loss: 2.4662768997489937

Epoch: 6| Step: 6
Training loss: 3.0619500114003255
Validation loss: 2.4632106842150154

Epoch: 6| Step: 7
Training loss: 3.1213501024063275
Validation loss: 2.4774485220397073

Epoch: 6| Step: 8
Training loss: 2.4117289996137883
Validation loss: 2.5092858823000377

Epoch: 6| Step: 9
Training loss: 2.8216980465719277
Validation loss: 2.5328992218151027

Epoch: 6| Step: 10
Training loss: 2.945303109960993
Validation loss: 2.535211115013245

Epoch: 6| Step: 11
Training loss: 2.791134019586915
Validation loss: 2.543132567708114

Epoch: 6| Step: 12
Training loss: 2.5243896955424567
Validation loss: 2.551235046106551

Epoch: 6| Step: 13
Training loss: 2.576829249429013
Validation loss: 2.5552242663839917

Epoch: 184| Step: 0
Training loss: 2.653833883633523
Validation loss: 2.5488642394118077

Epoch: 6| Step: 1
Training loss: 2.567702246317635
Validation loss: 2.5245925269948652

Epoch: 6| Step: 2
Training loss: 2.756904085014959
Validation loss: 2.5105865105169567

Epoch: 6| Step: 3
Training loss: 2.66171214665791
Validation loss: 2.4914420403566675

Epoch: 6| Step: 4
Training loss: 3.010316594098385
Validation loss: 2.511597540251238

Epoch: 6| Step: 5
Training loss: 2.3821685421151906
Validation loss: 2.4971479739670763

Epoch: 6| Step: 6
Training loss: 2.9571320328866473
Validation loss: 2.522649027891492

Epoch: 6| Step: 7
Training loss: 1.9414547582203796
Validation loss: 2.5199585204064543

Epoch: 6| Step: 8
Training loss: 3.0149263353347653
Validation loss: 2.5216753065501023

Epoch: 6| Step: 9
Training loss: 2.9788060181185183
Validation loss: 2.521746225471298

Epoch: 6| Step: 10
Training loss: 3.039770205747066
Validation loss: 2.4954417953801378

Epoch: 6| Step: 11
Training loss: 2.447412338791094
Validation loss: 2.4977834206742187

Epoch: 6| Step: 12
Training loss: 3.0230185837043533
Validation loss: 2.485635122748858

Epoch: 6| Step: 13
Training loss: 2.9652207126134336
Validation loss: 2.4985639139099556

Epoch: 185| Step: 0
Training loss: 2.7184321776786473
Validation loss: 2.4952596062491317

Epoch: 6| Step: 1
Training loss: 2.3718833551272267
Validation loss: 2.481202861069171

Epoch: 6| Step: 2
Training loss: 2.6864918436891814
Validation loss: 2.4946368192512227

Epoch: 6| Step: 3
Training loss: 3.071049492594008
Validation loss: 2.496909762452943

Epoch: 6| Step: 4
Training loss: 2.825184172981841
Validation loss: 2.5007916253379077

Epoch: 6| Step: 5
Training loss: 2.4242126995850817
Validation loss: 2.5114268346651776

Epoch: 6| Step: 6
Training loss: 2.7560904424247314
Validation loss: 2.5372200318052833

Epoch: 6| Step: 7
Training loss: 3.0085142431697047
Validation loss: 2.5464027521082113

Epoch: 6| Step: 8
Training loss: 2.312715262626666
Validation loss: 2.55699035407902

Epoch: 6| Step: 9
Training loss: 2.717333369757016
Validation loss: 2.5576988039642554

Epoch: 6| Step: 10
Training loss: 3.2199479623700586
Validation loss: 2.5692076053864574

Epoch: 6| Step: 11
Training loss: 2.56401780000599
Validation loss: 2.5856238209839186

Epoch: 6| Step: 12
Training loss: 2.8226578278250765
Validation loss: 2.566817412972301

Epoch: 6| Step: 13
Training loss: 2.717270547256888
Validation loss: 2.551309680178284

Epoch: 186| Step: 0
Training loss: 2.9901112656319957
Validation loss: 2.5264526892060646

Epoch: 6| Step: 1
Training loss: 3.1344854211801367
Validation loss: 2.5017040126395043

Epoch: 6| Step: 2
Training loss: 2.5551057525666754
Validation loss: 2.509816608922198

Epoch: 6| Step: 3
Training loss: 2.7613476796657834
Validation loss: 2.520969868881757

Epoch: 6| Step: 4
Training loss: 2.6736728798692977
Validation loss: 2.5146878157313215

Epoch: 6| Step: 5
Training loss: 2.30962182404897
Validation loss: 2.5144258215547155

Epoch: 6| Step: 6
Training loss: 2.9449469139612354
Validation loss: 2.514703614358046

Epoch: 6| Step: 7
Training loss: 2.451275462359239
Validation loss: 2.5136154424332156

Epoch: 6| Step: 8
Training loss: 2.646849029305515
Validation loss: 2.5022045423936756

Epoch: 6| Step: 9
Training loss: 3.2328961073479863
Validation loss: 2.51232910701539

Epoch: 6| Step: 10
Training loss: 2.279951170013622
Validation loss: 2.509977901204412

Epoch: 6| Step: 11
Training loss: 2.5044371329269186
Validation loss: 2.516125394285037

Epoch: 6| Step: 12
Training loss: 2.935710930316852
Validation loss: 2.51634624813978

Epoch: 6| Step: 13
Training loss: 2.300670679411497
Validation loss: 2.531408451073033

Epoch: 187| Step: 0
Training loss: 2.8834601607754697
Validation loss: 2.5366358689307353

Epoch: 6| Step: 1
Training loss: 3.1370601634517965
Validation loss: 2.538720457956825

Epoch: 6| Step: 2
Training loss: 2.805909382086267
Validation loss: 2.5397410960235676

Epoch: 6| Step: 3
Training loss: 2.187962619364548
Validation loss: 2.5447792566865473

Epoch: 6| Step: 4
Training loss: 3.1534955686916404
Validation loss: 2.5276322372678903

Epoch: 6| Step: 5
Training loss: 2.189568440840067
Validation loss: 2.5201575809902663

Epoch: 6| Step: 6
Training loss: 3.004017523997632
Validation loss: 2.506495464244661

Epoch: 6| Step: 7
Training loss: 1.90928720625154
Validation loss: 2.519577586841819

Epoch: 6| Step: 8
Training loss: 2.8434803593834124
Validation loss: 2.519823251477701

Epoch: 6| Step: 9
Training loss: 3.1015225270960043
Validation loss: 2.529816846050145

Epoch: 6| Step: 10
Training loss: 3.121908566100675
Validation loss: 2.5073272958437802

Epoch: 6| Step: 11
Training loss: 2.9357953908653727
Validation loss: 2.5239525980443647

Epoch: 6| Step: 12
Training loss: 1.9239156170619092
Validation loss: 2.5281993871095696

Epoch: 6| Step: 13
Training loss: 2.259003427429436
Validation loss: 2.5159216794833337

Epoch: 188| Step: 0
Training loss: 3.0123334719901393
Validation loss: 2.56381311694807

Epoch: 6| Step: 1
Training loss: 2.5853975314268043
Validation loss: 2.558447763448432

Epoch: 6| Step: 2
Training loss: 3.200706499310201
Validation loss: 2.548643477471687

Epoch: 6| Step: 3
Training loss: 2.6405070803344546
Validation loss: 2.522671142398396

Epoch: 6| Step: 4
Training loss: 2.6943798275919586
Validation loss: 2.5088716052532734

Epoch: 6| Step: 5
Training loss: 3.0377994844966008
Validation loss: 2.503116418783004

Epoch: 6| Step: 6
Training loss: 3.12769155938715
Validation loss: 2.5161604161509974

Epoch: 6| Step: 7
Training loss: 1.5508496632127058
Validation loss: 2.515455815684545

Epoch: 6| Step: 8
Training loss: 2.9701502659863968
Validation loss: 2.506641141851632

Epoch: 6| Step: 9
Training loss: 2.849597159575857
Validation loss: 2.5090369840333424

Epoch: 6| Step: 10
Training loss: 2.2747195060439336
Validation loss: 2.5229271610439024

Epoch: 6| Step: 11
Training loss: 2.8304147460907023
Validation loss: 2.5398730891313597

Epoch: 6| Step: 12
Training loss: 2.4578173036522313
Validation loss: 2.5107005990213405

Epoch: 6| Step: 13
Training loss: 1.4783625051006355
Validation loss: 2.5324575616866123

Epoch: 189| Step: 0
Training loss: 2.7478920920784047
Validation loss: 2.560510039282608

Epoch: 6| Step: 1
Training loss: 2.644973515051655
Validation loss: 2.5972534607586537

Epoch: 6| Step: 2
Training loss: 3.081495579340195
Validation loss: 2.6053582908610404

Epoch: 6| Step: 3
Training loss: 2.3307997936153764
Validation loss: 2.587137676221453

Epoch: 6| Step: 4
Training loss: 2.9584829982096905
Validation loss: 2.5941690412108964

Epoch: 6| Step: 5
Training loss: 2.578241056662186
Validation loss: 2.5464903536429877

Epoch: 6| Step: 6
Training loss: 2.5588516687750715
Validation loss: 2.5432469219443887

Epoch: 6| Step: 7
Training loss: 2.5583028147447973
Validation loss: 2.5362231310253454

Epoch: 6| Step: 8
Training loss: 3.217010917097214
Validation loss: 2.5133845541339688

Epoch: 6| Step: 9
Training loss: 2.5256435329604052
Validation loss: 2.5301265322378375

Epoch: 6| Step: 10
Training loss: 2.8605160963795475
Validation loss: 2.5100029024137513

Epoch: 6| Step: 11
Training loss: 2.355843433546939
Validation loss: 2.5052264617993294

Epoch: 6| Step: 12
Training loss: 2.663758649306305
Validation loss: 2.495137120202929

Epoch: 6| Step: 13
Training loss: 2.5273048834192684
Validation loss: 2.5024878500353482

Epoch: 190| Step: 0
Training loss: 2.666385387447454
Validation loss: 2.5329491834335984

Epoch: 6| Step: 1
Training loss: 2.2120243272392135
Validation loss: 2.551936215213353

Epoch: 6| Step: 2
Training loss: 2.512718749131615
Validation loss: 2.5922447192489058

Epoch: 6| Step: 3
Training loss: 2.802001517045606
Validation loss: 2.6005951191641716

Epoch: 6| Step: 4
Training loss: 2.4127673776728265
Validation loss: 2.5325949116762425

Epoch: 6| Step: 5
Training loss: 2.8953314330238022
Validation loss: 2.4973727736990563

Epoch: 6| Step: 6
Training loss: 3.105974801535492
Validation loss: 2.4941099337807704

Epoch: 6| Step: 7
Training loss: 3.2495687638799216
Validation loss: 2.492252077062006

Epoch: 6| Step: 8
Training loss: 2.9261484157654114
Validation loss: 2.4738867961253352

Epoch: 6| Step: 9
Training loss: 2.3035277471276765
Validation loss: 2.471448140154814

Epoch: 6| Step: 10
Training loss: 2.7086539641124787
Validation loss: 2.4805000575147793

Epoch: 6| Step: 11
Training loss: 2.3225972136979838
Validation loss: 2.5264492939525667

Epoch: 6| Step: 12
Training loss: 2.5849241362900295
Validation loss: 2.5721894302137764

Epoch: 6| Step: 13
Training loss: 3.5433977870396185
Validation loss: 2.577733055493711

Epoch: 191| Step: 0
Training loss: 3.0158903173238794
Validation loss: 2.6240478660059186

Epoch: 6| Step: 1
Training loss: 3.0523427564406016
Validation loss: 2.6737032549802473

Epoch: 6| Step: 2
Training loss: 2.752248451733524
Validation loss: 2.6731253716266634

Epoch: 6| Step: 3
Training loss: 2.5224937351175476
Validation loss: 2.623450689755302

Epoch: 6| Step: 4
Training loss: 2.9923302837995256
Validation loss: 2.60104370758418

Epoch: 6| Step: 5
Training loss: 2.4282420479978
Validation loss: 2.547927512137241

Epoch: 6| Step: 6
Training loss: 2.78505831809768
Validation loss: 2.5445311583568904

Epoch: 6| Step: 7
Training loss: 2.2931875095284777
Validation loss: 2.513441429962871

Epoch: 6| Step: 8
Training loss: 3.209480939117659
Validation loss: 2.497948907514807

Epoch: 6| Step: 9
Training loss: 2.6454414818419436
Validation loss: 2.483388807047834

Epoch: 6| Step: 10
Training loss: 2.373768436948861
Validation loss: 2.4741121260935075

Epoch: 6| Step: 11
Training loss: 3.114125365882625
Validation loss: 2.483380962470335

Epoch: 6| Step: 12
Training loss: 2.7001262635271814
Validation loss: 2.482619676937047

Epoch: 6| Step: 13
Training loss: 2.43624258620581
Validation loss: 2.506332294392765

Epoch: 192| Step: 0
Training loss: 2.8610643076437734
Validation loss: 2.511459516591332

Epoch: 6| Step: 1
Training loss: 2.7094122473808455
Validation loss: 2.5107268632519486

Epoch: 6| Step: 2
Training loss: 2.6489267263103153
Validation loss: 2.526082439662306

Epoch: 6| Step: 3
Training loss: 2.452449243858305
Validation loss: 2.526441393324105

Epoch: 6| Step: 4
Training loss: 2.4660242219216437
Validation loss: 2.55201238785142

Epoch: 6| Step: 5
Training loss: 2.862207729294351
Validation loss: 2.548790835271732

Epoch: 6| Step: 6
Training loss: 2.500921461041285
Validation loss: 2.5395525453259493

Epoch: 6| Step: 7
Training loss: 2.387206681692933
Validation loss: 2.5418607875365793

Epoch: 6| Step: 8
Training loss: 2.6362909266630843
Validation loss: 2.532690048013363

Epoch: 6| Step: 9
Training loss: 2.9409461402462136
Validation loss: 2.5138677983190663

Epoch: 6| Step: 10
Training loss: 3.0457061873241145
Validation loss: 2.4988568327729195

Epoch: 6| Step: 11
Training loss: 2.851370190968262
Validation loss: 2.502844756803829

Epoch: 6| Step: 12
Training loss: 2.788977699166007
Validation loss: 2.5089894113284803

Epoch: 6| Step: 13
Training loss: 2.718590041091786
Validation loss: 2.520516490491054

Epoch: 193| Step: 0
Training loss: 3.0858617845735106
Validation loss: 2.523210834398784

Epoch: 6| Step: 1
Training loss: 2.424921494619139
Validation loss: 2.5271087135001005

Epoch: 6| Step: 2
Training loss: 2.3407265043977037
Validation loss: 2.549182608670433

Epoch: 6| Step: 3
Training loss: 2.861200469102025
Validation loss: 2.5536166084015712

Epoch: 6| Step: 4
Training loss: 2.3296516072855455
Validation loss: 2.5904507865760014

Epoch: 6| Step: 5
Training loss: 2.7669243642756247
Validation loss: 2.680510317923891

Epoch: 6| Step: 6
Training loss: 3.487073460681669
Validation loss: 2.7201375714847194

Epoch: 6| Step: 7
Training loss: 3.1195924893813753
Validation loss: 2.678963464271253

Epoch: 6| Step: 8
Training loss: 2.758418721685801
Validation loss: 2.5817894481938377

Epoch: 6| Step: 9
Training loss: 2.8289116034237183
Validation loss: 2.512502321060489

Epoch: 6| Step: 10
Training loss: 2.665622824771973
Validation loss: 2.493937642121038

Epoch: 6| Step: 11
Training loss: 2.393713458307698
Validation loss: 2.4811487468735516

Epoch: 6| Step: 12
Training loss: 2.4089736386476335
Validation loss: 2.4669134718980246

Epoch: 6| Step: 13
Training loss: 3.256496831577563
Validation loss: 2.483251449549206

Epoch: 194| Step: 0
Training loss: 2.809193681036116
Validation loss: 2.480380805312606

Epoch: 6| Step: 1
Training loss: 2.8272777995554974
Validation loss: 2.486056416606652

Epoch: 6| Step: 2
Training loss: 2.82521809774125
Validation loss: 2.5031040241314604

Epoch: 6| Step: 3
Training loss: 2.7356501630462904
Validation loss: 2.531187564389247

Epoch: 6| Step: 4
Training loss: 2.4000767377665175
Validation loss: 2.5593320851949666

Epoch: 6| Step: 5
Training loss: 2.7974300579637768
Validation loss: 2.5982214888271886

Epoch: 6| Step: 6
Training loss: 3.3801518432097537
Validation loss: 2.6218845955738384

Epoch: 6| Step: 7
Training loss: 1.780308591795842
Validation loss: 2.6039595349701607

Epoch: 6| Step: 8
Training loss: 2.806614121090933
Validation loss: 2.552556880758149

Epoch: 6| Step: 9
Training loss: 2.6924354124690497
Validation loss: 2.5650960940957597

Epoch: 6| Step: 10
Training loss: 3.1902489869339057
Validation loss: 2.5778771921178465

Epoch: 6| Step: 11
Training loss: 2.485984904414507
Validation loss: 2.5414391215230827

Epoch: 6| Step: 12
Training loss: 2.9583819389827632
Validation loss: 2.5376942067490096

Epoch: 6| Step: 13
Training loss: 2.683701958619428
Validation loss: 2.535314275941878

Epoch: 195| Step: 0
Training loss: 3.0968555315100565
Validation loss: 2.5554490254098265

Epoch: 6| Step: 1
Training loss: 2.1540977683445934
Validation loss: 2.571599726833277

Epoch: 6| Step: 2
Training loss: 2.2935527207357125
Validation loss: 2.604532820689093

Epoch: 6| Step: 3
Training loss: 2.8065643406364877
Validation loss: 2.623519859092943

Epoch: 6| Step: 4
Training loss: 2.2488666435045306
Validation loss: 2.614170080207663

Epoch: 6| Step: 5
Training loss: 2.1748638855885676
Validation loss: 2.597148406017094

Epoch: 6| Step: 6
Training loss: 2.819706056439298
Validation loss: 2.5640940951461095

Epoch: 6| Step: 7
Training loss: 3.0525744219931217
Validation loss: 2.521948344484907

Epoch: 6| Step: 8
Training loss: 2.606448148152026
Validation loss: 2.501297150718405

Epoch: 6| Step: 9
Training loss: 3.0406944776636373
Validation loss: 2.4703260940904475

Epoch: 6| Step: 10
Training loss: 2.8221025782811844
Validation loss: 2.462596649531123

Epoch: 6| Step: 11
Training loss: 3.2123545097921604
Validation loss: 2.452248975923726

Epoch: 6| Step: 12
Training loss: 2.7408270871199587
Validation loss: 2.453764007237344

Epoch: 6| Step: 13
Training loss: 2.716736234074528
Validation loss: 2.4509967355225477

Epoch: 196| Step: 0
Training loss: 2.9441265278453796
Validation loss: 2.460263850107491

Epoch: 6| Step: 1
Training loss: 2.688546974820308
Validation loss: 2.467073194311551

Epoch: 6| Step: 2
Training loss: 2.860102993371118
Validation loss: 2.5026330863720347

Epoch: 6| Step: 3
Training loss: 2.4867751325758345
Validation loss: 2.539858031487523

Epoch: 6| Step: 4
Training loss: 2.8566287668118435
Validation loss: 2.5655157220166585

Epoch: 6| Step: 5
Training loss: 2.712681893433537
Validation loss: 2.588451883505312

Epoch: 6| Step: 6
Training loss: 2.4989590384983362
Validation loss: 2.5810021339421

Epoch: 6| Step: 7
Training loss: 3.2302398046989973
Validation loss: 2.614577176012817

Epoch: 6| Step: 8
Training loss: 2.3064870242174136
Validation loss: 2.6415227791112126

Epoch: 6| Step: 9
Training loss: 2.3067067756179243
Validation loss: 2.63720859974003

Epoch: 6| Step: 10
Training loss: 2.3236989185285917
Validation loss: 2.6031196553509854

Epoch: 6| Step: 11
Training loss: 2.5006235298775965
Validation loss: 2.583895897584683

Epoch: 6| Step: 12
Training loss: 2.894676215162069
Validation loss: 2.5838459189772696

Epoch: 6| Step: 13
Training loss: 2.9624230676633156
Validation loss: 2.5559578036248034

Epoch: 197| Step: 0
Training loss: 2.559885691832552
Validation loss: 2.54221135487208

Epoch: 6| Step: 1
Training loss: 2.486004756686631
Validation loss: 2.512312107716327

Epoch: 6| Step: 2
Training loss: 2.4598259247077836
Validation loss: 2.5085756351307444

Epoch: 6| Step: 3
Training loss: 2.898331221202617
Validation loss: 2.5086954994199866

Epoch: 6| Step: 4
Training loss: 2.62644473690656
Validation loss: 2.5103780356877867

Epoch: 6| Step: 5
Training loss: 3.316531049808776
Validation loss: 2.5125445613012323

Epoch: 6| Step: 6
Training loss: 2.759619879738105
Validation loss: 2.521116190164941

Epoch: 6| Step: 7
Training loss: 2.354797672562302
Validation loss: 2.5444430097784974

Epoch: 6| Step: 8
Training loss: 2.922445476144107
Validation loss: 2.5425442559529507

Epoch: 6| Step: 9
Training loss: 2.384950672815158
Validation loss: 2.5634507857206965

Epoch: 6| Step: 10
Training loss: 2.7247966305499656
Validation loss: 2.5929898421781745

Epoch: 6| Step: 11
Training loss: 2.9114574416448677
Validation loss: 2.599556212338778

Epoch: 6| Step: 12
Training loss: 2.412726863017723
Validation loss: 2.6148776395464353

Epoch: 6| Step: 13
Training loss: 2.3366882750763205
Validation loss: 2.6247995566676914

Epoch: 198| Step: 0
Training loss: 2.843731219889911
Validation loss: 2.6311727744989057

Epoch: 6| Step: 1
Training loss: 2.4164803751032777
Validation loss: 2.623814993127929

Epoch: 6| Step: 2
Training loss: 2.435572130795777
Validation loss: 2.6083555007595947

Epoch: 6| Step: 3
Training loss: 3.4798550562434896
Validation loss: 2.591487838494198

Epoch: 6| Step: 4
Training loss: 2.9173112611104184
Validation loss: 2.5532348603151482

Epoch: 6| Step: 5
Training loss: 2.6282151831577094
Validation loss: 2.5086509313285625

Epoch: 6| Step: 6
Training loss: 2.7774001490021205
Validation loss: 2.506895778753548

Epoch: 6| Step: 7
Training loss: 2.8443458687403873
Validation loss: 2.49765411775831

Epoch: 6| Step: 8
Training loss: 2.244245481904896
Validation loss: 2.484559574237468

Epoch: 6| Step: 9
Training loss: 2.3846186562129974
Validation loss: 2.479219743369531

Epoch: 6| Step: 10
Training loss: 2.8928082443491165
Validation loss: 2.47293708348379

Epoch: 6| Step: 11
Training loss: 2.3712326084558937
Validation loss: 2.4908229288563812

Epoch: 6| Step: 12
Training loss: 2.638370702851994
Validation loss: 2.501262259996537

Epoch: 6| Step: 13
Training loss: 2.4259935369067414
Validation loss: 2.5241623019191533

Epoch: 199| Step: 0
Training loss: 2.8092647170166534
Validation loss: 2.5483986907963683

Epoch: 6| Step: 1
Training loss: 3.0604683501413303
Validation loss: 2.5832535393651024

Epoch: 6| Step: 2
Training loss: 2.6336871315903285
Validation loss: 2.6035899833483

Epoch: 6| Step: 3
Training loss: 2.839972197974148
Validation loss: 2.6044640379085187

Epoch: 6| Step: 4
Training loss: 3.199370179184808
Validation loss: 2.592175809193782

Epoch: 6| Step: 5
Training loss: 2.7049360437641576
Validation loss: 2.5506421655707485

Epoch: 6| Step: 6
Training loss: 2.5035113471070973
Validation loss: 2.5267545126634823

Epoch: 6| Step: 7
Training loss: 2.223399488884175
Validation loss: 2.508900889712482

Epoch: 6| Step: 8
Training loss: 2.3052473002600924
Validation loss: 2.5073477613097874

Epoch: 6| Step: 9
Training loss: 2.7607050523125896
Validation loss: 2.5038616360803485

Epoch: 6| Step: 10
Training loss: 2.7446151377439962
Validation loss: 2.512301538071943

Epoch: 6| Step: 11
Training loss: 2.585844470422307
Validation loss: 2.532991622151149

Epoch: 6| Step: 12
Training loss: 2.4451354331359547
Validation loss: 2.5204575330638814

Epoch: 6| Step: 13
Training loss: 2.316693910488876
Validation loss: 2.5145877632732625

Epoch: 200| Step: 0
Training loss: 2.658201331166735
Validation loss: 2.4894449019864298

Epoch: 6| Step: 1
Training loss: 2.445238203681126
Validation loss: 2.4754830370599477

Epoch: 6| Step: 2
Training loss: 2.9035126294885663
Validation loss: 2.4748547269518584

Epoch: 6| Step: 3
Training loss: 2.7717933616958907
Validation loss: 2.4735721717229544

Epoch: 6| Step: 4
Training loss: 2.334987485472248
Validation loss: 2.473643077890917

Epoch: 6| Step: 5
Training loss: 2.16988990135225
Validation loss: 2.4828971516963385

Epoch: 6| Step: 6
Training loss: 2.911036989208324
Validation loss: 2.474106588708705

Epoch: 6| Step: 7
Training loss: 3.1089377551100834
Validation loss: 2.4716770727026645

Epoch: 6| Step: 8
Training loss: 2.6426802542857133
Validation loss: 2.4727636742692733

Epoch: 6| Step: 9
Training loss: 3.0132188437944802
Validation loss: 2.4949132400853125

Epoch: 6| Step: 10
Training loss: 2.4385812757540504
Validation loss: 2.5212213778093475

Epoch: 6| Step: 11
Training loss: 2.6762411571572184
Validation loss: 2.560944838367165

Epoch: 6| Step: 12
Training loss: 3.0256131646283957
Validation loss: 2.604471146698325

Epoch: 6| Step: 13
Training loss: 2.513028054235227
Validation loss: 2.610665639605157

Epoch: 201| Step: 0
Training loss: 2.8621879041021523
Validation loss: 2.638891169430651

Epoch: 6| Step: 1
Training loss: 3.3412968558562826
Validation loss: 2.6340454735487504

Epoch: 6| Step: 2
Training loss: 2.5057291188805326
Validation loss: 2.6008697004132433

Epoch: 6| Step: 3
Training loss: 2.209079784218305
Validation loss: 2.5702002785995433

Epoch: 6| Step: 4
Training loss: 2.3984846178825574
Validation loss: 2.5407253699681798

Epoch: 6| Step: 5
Training loss: 3.200440263264282
Validation loss: 2.5321527529982832

Epoch: 6| Step: 6
Training loss: 2.4221685416235514
Validation loss: 2.5375492263125783

Epoch: 6| Step: 7
Training loss: 3.1208046790022634
Validation loss: 2.5307148345270014

Epoch: 6| Step: 8
Training loss: 2.6216793855753475
Validation loss: 2.520896438104375

Epoch: 6| Step: 9
Training loss: 2.604379040005697
Validation loss: 2.514705681822793

Epoch: 6| Step: 10
Training loss: 2.7422090621926483
Validation loss: 2.512817645616226

Epoch: 6| Step: 11
Training loss: 2.4583809303805304
Validation loss: 2.515549734206567

Epoch: 6| Step: 12
Training loss: 2.4918952220424395
Validation loss: 2.5080024234071936

Epoch: 6| Step: 13
Training loss: 2.3737551789832403
Validation loss: 2.510715694707871

Epoch: 202| Step: 0
Training loss: 2.9953026553983695
Validation loss: 2.5031581762831197

Epoch: 6| Step: 1
Training loss: 2.868987389011263
Validation loss: 2.512259278948535

Epoch: 6| Step: 2
Training loss: 2.8001795166234222
Validation loss: 2.506356225237888

Epoch: 6| Step: 3
Training loss: 3.0471012911760127
Validation loss: 2.518621263486639

Epoch: 6| Step: 4
Training loss: 2.6696247641528528
Validation loss: 2.5224704736613957

Epoch: 6| Step: 5
Training loss: 2.5998276433303062
Validation loss: 2.5170911550605464

Epoch: 6| Step: 6
Training loss: 2.682883533743786
Validation loss: 2.520000637192392

Epoch: 6| Step: 7
Training loss: 2.2661017606870213
Validation loss: 2.5189058502387125

Epoch: 6| Step: 8
Training loss: 2.1760357856823194
Validation loss: 2.540448537537065

Epoch: 6| Step: 9
Training loss: 2.7117876374361907
Validation loss: 2.550134864198925

Epoch: 6| Step: 10
Training loss: 2.1162466513555973
Validation loss: 2.5764818152565367

Epoch: 6| Step: 11
Training loss: 2.694299479863889
Validation loss: 2.602694210722714

Epoch: 6| Step: 12
Training loss: 2.417535450309554
Validation loss: 2.615266240502851

Epoch: 6| Step: 13
Training loss: 3.3877738532261903
Validation loss: 2.6131610261155136

Epoch: 203| Step: 0
Training loss: 2.5916121531290313
Validation loss: 2.58244534796949

Epoch: 6| Step: 1
Training loss: 2.305076023263107
Validation loss: 2.543772297463379

Epoch: 6| Step: 2
Training loss: 2.6524947605207148
Validation loss: 2.519248776262538

Epoch: 6| Step: 3
Training loss: 2.6209794998851783
Validation loss: 2.492142105370607

Epoch: 6| Step: 4
Training loss: 2.734569782403884
Validation loss: 2.499789701866346

Epoch: 6| Step: 5
Training loss: 2.1819099936169137
Validation loss: 2.494513882804715

Epoch: 6| Step: 6
Training loss: 3.1622211137318255
Validation loss: 2.480495044949024

Epoch: 6| Step: 7
Training loss: 2.5888078784228616
Validation loss: 2.481144782299888

Epoch: 6| Step: 8
Training loss: 2.8703476124434415
Validation loss: 2.473937024131067

Epoch: 6| Step: 9
Training loss: 2.7640535879557517
Validation loss: 2.4757487940456886

Epoch: 6| Step: 10
Training loss: 2.781610358391895
Validation loss: 2.4781425313760463

Epoch: 6| Step: 11
Training loss: 2.913292340732945
Validation loss: 2.482889185276529

Epoch: 6| Step: 12
Training loss: 2.143430889612759
Validation loss: 2.4897374542087523

Epoch: 6| Step: 13
Training loss: 3.0421754246076795
Validation loss: 2.4923481660072717

Epoch: 204| Step: 0
Training loss: 2.852864509047428
Validation loss: 2.507583786119311

Epoch: 6| Step: 1
Training loss: 2.7642049645971825
Validation loss: 2.5284604737269105

Epoch: 6| Step: 2
Training loss: 2.9174114547930357
Validation loss: 2.5868333450046626

Epoch: 6| Step: 3
Training loss: 2.3802664740631094
Validation loss: 2.6072639707872924

Epoch: 6| Step: 4
Training loss: 2.476886619754308
Validation loss: 2.598053223036093

Epoch: 6| Step: 5
Training loss: 2.819822823660369
Validation loss: 2.591400543240935

Epoch: 6| Step: 6
Training loss: 2.4811585916357997
Validation loss: 2.585435174186942

Epoch: 6| Step: 7
Training loss: 2.801262850036154
Validation loss: 2.572474274538725

Epoch: 6| Step: 8
Training loss: 2.6878232539742064
Validation loss: 2.5645517268541167

Epoch: 6| Step: 9
Training loss: 2.7367153070783723
Validation loss: 2.5445489730866826

Epoch: 6| Step: 10
Training loss: 2.953747880428811
Validation loss: 2.533838182229939

Epoch: 6| Step: 11
Training loss: 2.333244889717551
Validation loss: 2.5196107170595043

Epoch: 6| Step: 12
Training loss: 2.329384072882053
Validation loss: 2.515833569920176

Epoch: 6| Step: 13
Training loss: 2.695800913911086
Validation loss: 2.5003532272929117

Epoch: 205| Step: 0
Training loss: 2.9424743739384
Validation loss: 2.4907647959900214

Epoch: 6| Step: 1
Training loss: 3.0328445173457284
Validation loss: 2.500878038342181

Epoch: 6| Step: 2
Training loss: 2.0469267161584566
Validation loss: 2.514818899428449

Epoch: 6| Step: 3
Training loss: 3.162388186683274
Validation loss: 2.529454538284916

Epoch: 6| Step: 4
Training loss: 3.138636932463397
Validation loss: 2.538726977320798

Epoch: 6| Step: 5
Training loss: 2.488271859958244
Validation loss: 2.5403049788066245

Epoch: 6| Step: 6
Training loss: 2.5756290260066868
Validation loss: 2.5506723333534604

Epoch: 6| Step: 7
Training loss: 3.020591007027976
Validation loss: 2.550864942440529

Epoch: 6| Step: 8
Training loss: 2.197764700265789
Validation loss: 2.538551924164088

Epoch: 6| Step: 9
Training loss: 2.3892767601163087
Validation loss: 2.5318047105461288

Epoch: 6| Step: 10
Training loss: 2.097335023632367
Validation loss: 2.523523172082205

Epoch: 6| Step: 11
Training loss: 2.754223960784538
Validation loss: 2.5230778547999546

Epoch: 6| Step: 12
Training loss: 2.393682183084405
Validation loss: 2.505719548675949

Epoch: 6| Step: 13
Training loss: 2.2013451711951357
Validation loss: 2.4989637708940546

Epoch: 206| Step: 0
Training loss: 2.3275530835909186
Validation loss: 2.4955104149016374

Epoch: 6| Step: 1
Training loss: 2.299141420910412
Validation loss: 2.4826798623214805

Epoch: 6| Step: 2
Training loss: 1.9714331734941208
Validation loss: 2.5051048273969925

Epoch: 6| Step: 3
Training loss: 2.7271311694312033
Validation loss: 2.515986645929091

Epoch: 6| Step: 4
Training loss: 2.3072867526195084
Validation loss: 2.5132547691208087

Epoch: 6| Step: 5
Training loss: 2.386597875353143
Validation loss: 2.5160904524245793

Epoch: 6| Step: 6
Training loss: 2.4648340772145785
Validation loss: 2.513818910704584

Epoch: 6| Step: 7
Training loss: 2.975908182471033
Validation loss: 2.5325342878034953

Epoch: 6| Step: 8
Training loss: 3.2711753585398564
Validation loss: 2.526075087946663

Epoch: 6| Step: 9
Training loss: 2.6199648567929454
Validation loss: 2.53534551289715

Epoch: 6| Step: 10
Training loss: 2.905781041528028
Validation loss: 2.5155459869089047

Epoch: 6| Step: 11
Training loss: 2.805378778215861
Validation loss: 2.5471349347371985

Epoch: 6| Step: 12
Training loss: 3.0547413540749093
Validation loss: 2.572352256078829

Epoch: 6| Step: 13
Training loss: 2.145247765305523
Validation loss: 2.569395425902265

Epoch: 207| Step: 0
Training loss: 2.926531666167071
Validation loss: 2.5722138446842804

Epoch: 6| Step: 1
Training loss: 2.9661949004060446
Validation loss: 2.554413757379449

Epoch: 6| Step: 2
Training loss: 2.3630630266305572
Validation loss: 2.5578167536265908

Epoch: 6| Step: 3
Training loss: 2.2065392409966575
Validation loss: 2.5444191328668904

Epoch: 6| Step: 4
Training loss: 2.39018454888621
Validation loss: 2.5626896073499212

Epoch: 6| Step: 5
Training loss: 3.0898613428900226
Validation loss: 2.563299033491309

Epoch: 6| Step: 6
Training loss: 2.01733550600606
Validation loss: 2.56190759297471

Epoch: 6| Step: 7
Training loss: 2.6843383289181566
Validation loss: 2.5498626174931944

Epoch: 6| Step: 8
Training loss: 2.0483380396110946
Validation loss: 2.523505797129116

Epoch: 6| Step: 9
Training loss: 2.606892758521369
Validation loss: 2.5131885742707354

Epoch: 6| Step: 10
Training loss: 2.8048462039175366
Validation loss: 2.5271568043443735

Epoch: 6| Step: 11
Training loss: 3.19360320767297
Validation loss: 2.515455536435922

Epoch: 6| Step: 12
Training loss: 2.1828124912619677
Validation loss: 2.5309623272223645

Epoch: 6| Step: 13
Training loss: 3.0984836930810307
Validation loss: 2.534312417374504

Epoch: 208| Step: 0
Training loss: 2.7295665205385937
Validation loss: 2.550008846213728

Epoch: 6| Step: 1
Training loss: 2.8901198487031925
Validation loss: 2.534389373603799

Epoch: 6| Step: 2
Training loss: 2.7078530301397294
Validation loss: 2.5104537562518443

Epoch: 6| Step: 3
Training loss: 2.990279981588034
Validation loss: 2.4944697247333116

Epoch: 6| Step: 4
Training loss: 2.772306399658971
Validation loss: 2.4971329902946144

Epoch: 6| Step: 5
Training loss: 2.2129699207990443
Validation loss: 2.4791235354290824

Epoch: 6| Step: 6
Training loss: 2.868629695721767
Validation loss: 2.503375623668933

Epoch: 6| Step: 7
Training loss: 2.498664308407762
Validation loss: 2.499994912706347

Epoch: 6| Step: 8
Training loss: 2.286754499181398
Validation loss: 2.507868043973628

Epoch: 6| Step: 9
Training loss: 2.0233329834327627
Validation loss: 2.5284609624332517

Epoch: 6| Step: 10
Training loss: 2.9127348056168043
Validation loss: 2.5222661156791024

Epoch: 6| Step: 11
Training loss: 2.783867279583291
Validation loss: 2.5475125813555164

Epoch: 6| Step: 12
Training loss: 2.687848800380344
Validation loss: 2.5546073488309577

Epoch: 6| Step: 13
Training loss: 1.8738722906738792
Validation loss: 2.6117330743631215

Epoch: 209| Step: 0
Training loss: 2.4736684743160704
Validation loss: 2.5945519221869224

Epoch: 6| Step: 1
Training loss: 2.7454426890352046
Validation loss: 2.579662679084004

Epoch: 6| Step: 2
Training loss: 2.158125683530008
Validation loss: 2.533389235896007

Epoch: 6| Step: 3
Training loss: 3.2013087636133744
Validation loss: 2.5246505135618316

Epoch: 6| Step: 4
Training loss: 2.690960275493614
Validation loss: 2.512694419759068

Epoch: 6| Step: 5
Training loss: 2.5358134447969047
Validation loss: 2.5163824884497425

Epoch: 6| Step: 6
Training loss: 2.358032855334798
Validation loss: 2.5267931056559134

Epoch: 6| Step: 7
Training loss: 2.2149944489626936
Validation loss: 2.5115989182243617

Epoch: 6| Step: 8
Training loss: 3.0274447122781414
Validation loss: 2.505674303028459

Epoch: 6| Step: 9
Training loss: 3.1085507627910203
Validation loss: 2.5118908242770916

Epoch: 6| Step: 10
Training loss: 2.919897379182367
Validation loss: 2.518881323130461

Epoch: 6| Step: 11
Training loss: 2.163516640246733
Validation loss: 2.5206575555280217

Epoch: 6| Step: 12
Training loss: 2.2740468260641795
Validation loss: 2.5194283942248816

Epoch: 6| Step: 13
Training loss: 2.1839087298329294
Validation loss: 2.532354018134262

Epoch: 210| Step: 0
Training loss: 2.864132118523585
Validation loss: 2.5566344621649963

Epoch: 6| Step: 1
Training loss: 2.543704909316317
Validation loss: 2.549832425049277

Epoch: 6| Step: 2
Training loss: 3.001886410489973
Validation loss: 2.5645352596535016

Epoch: 6| Step: 3
Training loss: 2.4772778750406697
Validation loss: 2.560192280557925

Epoch: 6| Step: 4
Training loss: 2.7955548458051296
Validation loss: 2.5657469984253156

Epoch: 6| Step: 5
Training loss: 2.9125768233878793
Validation loss: 2.573185969435988

Epoch: 6| Step: 6
Training loss: 2.088603855136293
Validation loss: 2.563699970063697

Epoch: 6| Step: 7
Training loss: 2.653470908037668
Validation loss: 2.549040537502643

Epoch: 6| Step: 8
Training loss: 3.0413060083339403
Validation loss: 2.5495779920031962

Epoch: 6| Step: 9
Training loss: 2.4452281608296604
Validation loss: 2.563599006412344

Epoch: 6| Step: 10
Training loss: 2.150278973777491
Validation loss: 2.5364474361000546

Epoch: 6| Step: 11
Training loss: 2.058897166177455
Validation loss: 2.5362144147925676

Epoch: 6| Step: 12
Training loss: 2.5758093404583216
Validation loss: 2.51675942417149

Epoch: 6| Step: 13
Training loss: 2.1066082929821186
Validation loss: 2.505839758800291

Epoch: 211| Step: 0
Training loss: 2.245728358526589
Validation loss: 2.527442387647382

Epoch: 6| Step: 1
Training loss: 2.143675920190751
Validation loss: 2.511918436510675

Epoch: 6| Step: 2
Training loss: 2.8892817495036955
Validation loss: 2.512738777886826

Epoch: 6| Step: 3
Training loss: 2.3888924497632047
Validation loss: 2.5110849593781466

Epoch: 6| Step: 4
Training loss: 2.074410467393434
Validation loss: 2.502412493378901

Epoch: 6| Step: 5
Training loss: 2.7608732793535524
Validation loss: 2.501266130162295

Epoch: 6| Step: 6
Training loss: 2.2335189566643603
Validation loss: 2.4883731940896707

Epoch: 6| Step: 7
Training loss: 2.6138734702415527
Validation loss: 2.5017344108694313

Epoch: 6| Step: 8
Training loss: 2.54372412366148
Validation loss: 2.513504665410041

Epoch: 6| Step: 9
Training loss: 2.4915920012481165
Validation loss: 2.513821737641646

Epoch: 6| Step: 10
Training loss: 2.647355210160633
Validation loss: 2.519777146035398

Epoch: 6| Step: 11
Training loss: 3.171855757330793
Validation loss: 2.5555699930842857

Epoch: 6| Step: 12
Training loss: 2.5870137812863367
Validation loss: 2.5747461197199004

Epoch: 6| Step: 13
Training loss: 3.048197610822104
Validation loss: 2.6933734926177992

Epoch: 212| Step: 0
Training loss: 2.279556900268133
Validation loss: 2.8346370910096645

Epoch: 6| Step: 1
Training loss: 3.186965897635309
Validation loss: 2.8993293998166294

Epoch: 6| Step: 2
Training loss: 2.2513052015722392
Validation loss: 2.780660666614368

Epoch: 6| Step: 3
Training loss: 3.0494502213057486
Validation loss: 2.6486500236038495

Epoch: 6| Step: 4
Training loss: 2.7659418818945842
Validation loss: 2.559881199248364

Epoch: 6| Step: 5
Training loss: 2.4400535314972633
Validation loss: 2.5008186784157216

Epoch: 6| Step: 6
Training loss: 2.9366677911289356
Validation loss: 2.5011852879613086

Epoch: 6| Step: 7
Training loss: 2.9424703226075652
Validation loss: 2.4936233598145163

Epoch: 6| Step: 8
Training loss: 2.541020504054693
Validation loss: 2.502531572615855

Epoch: 6| Step: 9
Training loss: 2.7793791404231776
Validation loss: 2.5189294631687447

Epoch: 6| Step: 10
Training loss: 2.5452180867162943
Validation loss: 2.5173230471695907

Epoch: 6| Step: 11
Training loss: 3.0818428010946923
Validation loss: 2.496741616135468

Epoch: 6| Step: 12
Training loss: 2.7261810473118193
Validation loss: 2.525707552022158

Epoch: 6| Step: 13
Training loss: 2.0470494785637174
Validation loss: 2.584061386717723

Epoch: 213| Step: 0
Training loss: 2.6463380667583305
Validation loss: 2.637537963925219

Epoch: 6| Step: 1
Training loss: 2.8889557838845916
Validation loss: 2.7290728206197503

Epoch: 6| Step: 2
Training loss: 2.310992393847584
Validation loss: 2.7158719072753246

Epoch: 6| Step: 3
Training loss: 2.623908951493931
Validation loss: 2.6799349374484813

Epoch: 6| Step: 4
Training loss: 2.9250971525311096
Validation loss: 2.643253593548161

Epoch: 6| Step: 5
Training loss: 2.6331810396154185
Validation loss: 2.6086400636378726

Epoch: 6| Step: 6
Training loss: 3.1880150173221247
Validation loss: 2.5840876295454267

Epoch: 6| Step: 7
Training loss: 2.7552245535610442
Validation loss: 2.5357900022309874

Epoch: 6| Step: 8
Training loss: 2.3243601010720276
Validation loss: 2.5042532313960244

Epoch: 6| Step: 9
Training loss: 2.86159708366896
Validation loss: 2.4872011339585582

Epoch: 6| Step: 10
Training loss: 2.0924895178966425
Validation loss: 2.4924575279282872

Epoch: 6| Step: 11
Training loss: 3.105406716165007
Validation loss: 2.4967448166519683

Epoch: 6| Step: 12
Training loss: 2.132793943443198
Validation loss: 2.5263899889143837

Epoch: 6| Step: 13
Training loss: 2.7509815891749425
Validation loss: 2.549886201132517

Epoch: 214| Step: 0
Training loss: 2.985260517502759
Validation loss: 2.528946669559967

Epoch: 6| Step: 1
Training loss: 2.2167523484652656
Validation loss: 2.526889363373103

Epoch: 6| Step: 2
Training loss: 3.095330499310757
Validation loss: 2.516364791156791

Epoch: 6| Step: 3
Training loss: 3.09585992554393
Validation loss: 2.5153059382879475

Epoch: 6| Step: 4
Training loss: 2.334565030576044
Validation loss: 2.52247530219958

Epoch: 6| Step: 5
Training loss: 2.5827039341572293
Validation loss: 2.5188493741248372

Epoch: 6| Step: 6
Training loss: 2.7971366035400425
Validation loss: 2.521458715936413

Epoch: 6| Step: 7
Training loss: 2.8536641776120795
Validation loss: 2.51061084295737

Epoch: 6| Step: 8
Training loss: 1.8150657383386881
Validation loss: 2.498637221744142

Epoch: 6| Step: 9
Training loss: 2.9124275100265873
Validation loss: 2.514321081699388

Epoch: 6| Step: 10
Training loss: 2.4588455270072567
Validation loss: 2.521337163033884

Epoch: 6| Step: 11
Training loss: 2.3763201206863953
Validation loss: 2.50923955054752

Epoch: 6| Step: 12
Training loss: 2.426841516413582
Validation loss: 2.527519531750654

Epoch: 6| Step: 13
Training loss: 2.5639523368011705
Validation loss: 2.530261648026385

Epoch: 215| Step: 0
Training loss: 2.181701058256808
Validation loss: 2.5348173046010865

Epoch: 6| Step: 1
Training loss: 2.7347867819124754
Validation loss: 2.526036991427558

Epoch: 6| Step: 2
Training loss: 2.7986360259060605
Validation loss: 2.5351008336751444

Epoch: 6| Step: 3
Training loss: 2.873273413963447
Validation loss: 2.572280177997288

Epoch: 6| Step: 4
Training loss: 2.694208776080218
Validation loss: 2.53392216617191

Epoch: 6| Step: 5
Training loss: 2.0911305681544774
Validation loss: 2.541225290799107

Epoch: 6| Step: 6
Training loss: 2.7803124551343235
Validation loss: 2.5270074819501316

Epoch: 6| Step: 7
Training loss: 2.8108135677411363
Validation loss: 2.516760580313561

Epoch: 6| Step: 8
Training loss: 2.541166589872
Validation loss: 2.5054051705627574

Epoch: 6| Step: 9
Training loss: 2.5621054741070317
Validation loss: 2.5051394425334306

Epoch: 6| Step: 10
Training loss: 2.6312296379551916
Validation loss: 2.519572111731499

Epoch: 6| Step: 11
Training loss: 2.047720930874661
Validation loss: 2.5392421369214215

Epoch: 6| Step: 12
Training loss: 2.6187943265891627
Validation loss: 2.563886762935358

Epoch: 6| Step: 13
Training loss: 2.6555992675741167
Validation loss: 2.5678836704653567

Epoch: 216| Step: 0
Training loss: 2.6014488584883
Validation loss: 2.543820913781202

Epoch: 6| Step: 1
Training loss: 3.1597448960679624
Validation loss: 2.5477485369109005

Epoch: 6| Step: 2
Training loss: 2.8171170801891874
Validation loss: 2.560932759637318

Epoch: 6| Step: 3
Training loss: 2.2777467766903206
Validation loss: 2.565231033435174

Epoch: 6| Step: 4
Training loss: 2.598377374353699
Validation loss: 2.5646573261503414

Epoch: 6| Step: 5
Training loss: 2.9804586707828427
Validation loss: 2.5860838261749546

Epoch: 6| Step: 6
Training loss: 2.886747822079589
Validation loss: 2.5866908115124425

Epoch: 6| Step: 7
Training loss: 2.2975833345560583
Validation loss: 2.5790399871123224

Epoch: 6| Step: 8
Training loss: 2.705297578248545
Validation loss: 2.571595011468286

Epoch: 6| Step: 9
Training loss: 2.1704729343599434
Validation loss: 2.5777837513157946

Epoch: 6| Step: 10
Training loss: 1.7309055853382715
Validation loss: 2.5362950168183187

Epoch: 6| Step: 11
Training loss: 2.009777132081064
Validation loss: 2.5445677216402913

Epoch: 6| Step: 12
Training loss: 2.5581733649458567
Validation loss: 2.529913518692897

Epoch: 6| Step: 13
Training loss: 3.012874000727992
Validation loss: 2.528232761783083

Epoch: 217| Step: 0
Training loss: 2.6743835808530947
Validation loss: 2.537353124994514

Epoch: 6| Step: 1
Training loss: 2.4689220899647517
Validation loss: 2.541582284337253

Epoch: 6| Step: 2
Training loss: 2.200897280904988
Validation loss: 2.5359229844615356

Epoch: 6| Step: 3
Training loss: 2.8594955669061215
Validation loss: 2.5344538049589653

Epoch: 6| Step: 4
Training loss: 2.552028567187142
Validation loss: 2.5368737597775843

Epoch: 6| Step: 5
Training loss: 2.943395015751369
Validation loss: 2.5196351485480966

Epoch: 6| Step: 6
Training loss: 2.7152246880334503
Validation loss: 2.516512183976181

Epoch: 6| Step: 7
Training loss: 2.0902573791161956
Validation loss: 2.508589199445762

Epoch: 6| Step: 8
Training loss: 2.6518969601943048
Validation loss: 2.4925808779485283

Epoch: 6| Step: 9
Training loss: 2.4552142728383846
Validation loss: 2.4795623888132505

Epoch: 6| Step: 10
Training loss: 2.559021333099444
Validation loss: 2.4823761618531335

Epoch: 6| Step: 11
Training loss: 3.029158981992129
Validation loss: 2.4960285739097956

Epoch: 6| Step: 12
Training loss: 2.125467361217545
Validation loss: 2.5159137620989243

Epoch: 6| Step: 13
Training loss: 2.269818128618594
Validation loss: 2.5402007398475037

Epoch: 218| Step: 0
Training loss: 2.7452448567897307
Validation loss: 2.5555696269315678

Epoch: 6| Step: 1
Training loss: 2.163682374035165
Validation loss: 2.5816825566837887

Epoch: 6| Step: 2
Training loss: 1.9248465538794113
Validation loss: 2.618818342796424

Epoch: 6| Step: 3
Training loss: 2.816333362413947
Validation loss: 2.584159972534066

Epoch: 6| Step: 4
Training loss: 2.520688570347964
Validation loss: 2.602237278738704

Epoch: 6| Step: 5
Training loss: 3.01029220024558
Validation loss: 2.569729763339404

Epoch: 6| Step: 6
Training loss: 3.1110228192955662
Validation loss: 2.5426250132383785

Epoch: 6| Step: 7
Training loss: 1.9797557623338953
Validation loss: 2.506853794101239

Epoch: 6| Step: 8
Training loss: 2.6209067265150425
Validation loss: 2.494131969331175

Epoch: 6| Step: 9
Training loss: 1.8184336514980448
Validation loss: 2.480697939316745

Epoch: 6| Step: 10
Training loss: 2.5091321093678474
Validation loss: 2.470145194087404

Epoch: 6| Step: 11
Training loss: 2.7296676661224466
Validation loss: 2.4654797137147253

Epoch: 6| Step: 12
Training loss: 3.1216149879600206
Validation loss: 2.4646005864990066

Epoch: 6| Step: 13
Training loss: 2.4959313663680973
Validation loss: 2.472725065354243

Epoch: 219| Step: 0
Training loss: 2.5268435329579213
Validation loss: 2.4825117146375537

Epoch: 6| Step: 1
Training loss: 2.583964998687273
Validation loss: 2.4801328018630158

Epoch: 6| Step: 2
Training loss: 1.7516579948208217
Validation loss: 2.489458452112264

Epoch: 6| Step: 3
Training loss: 3.3610917783519216
Validation loss: 2.505273040706039

Epoch: 6| Step: 4
Training loss: 2.5717962093034314
Validation loss: 2.5160357094725976

Epoch: 6| Step: 5
Training loss: 2.76070349780548
Validation loss: 2.5319035662548552

Epoch: 6| Step: 6
Training loss: 2.3942203786658096
Validation loss: 2.5444914430095134

Epoch: 6| Step: 7
Training loss: 2.6511788822979074
Validation loss: 2.557677263949787

Epoch: 6| Step: 8
Training loss: 2.707595920431068
Validation loss: 2.583841014626126

Epoch: 6| Step: 9
Training loss: 2.4948331846686123
Validation loss: 2.5802559923838877

Epoch: 6| Step: 10
Training loss: 2.5365589181955333
Validation loss: 2.5815055592141274

Epoch: 6| Step: 11
Training loss: 1.9889075711093303
Validation loss: 2.572732043375273

Epoch: 6| Step: 12
Training loss: 2.4122868893436005
Validation loss: 2.5394895158229005

Epoch: 6| Step: 13
Training loss: 2.8108112775485985
Validation loss: 2.5303242199587648

Epoch: 220| Step: 0
Training loss: 3.0117949044461434
Validation loss: 2.5210935037532085

Epoch: 6| Step: 1
Training loss: 2.274819914009528
Validation loss: 2.5115212759154373

Epoch: 6| Step: 2
Training loss: 2.8556467566994086
Validation loss: 2.505734600706719

Epoch: 6| Step: 3
Training loss: 2.6067618802755583
Validation loss: 2.520833171972278

Epoch: 6| Step: 4
Training loss: 2.2503962697648783
Validation loss: 2.501489365865828

Epoch: 6| Step: 5
Training loss: 1.8483053281065287
Validation loss: 2.5090193973905213

Epoch: 6| Step: 6
Training loss: 2.3597302706184964
Validation loss: 2.531207563479286

Epoch: 6| Step: 7
Training loss: 2.183256774996667
Validation loss: 2.543412914034501

Epoch: 6| Step: 8
Training loss: 2.60227466263648
Validation loss: 2.5158208486611104

Epoch: 6| Step: 9
Training loss: 2.462690231798431
Validation loss: 2.5289974948795053

Epoch: 6| Step: 10
Training loss: 2.3001844995553355
Validation loss: 2.5592461553379082

Epoch: 6| Step: 11
Training loss: 3.0431934513675416
Validation loss: 2.565813245139121

Epoch: 6| Step: 12
Training loss: 3.0453429453988154
Validation loss: 2.5797917452075882

Epoch: 6| Step: 13
Training loss: 1.8253414775192072
Validation loss: 2.5836574246619066

Epoch: 221| Step: 0
Training loss: 2.639299590514728
Validation loss: 2.5811165892722427

Epoch: 6| Step: 1
Training loss: 2.9140425366901646
Validation loss: 2.5776128166311403

Epoch: 6| Step: 2
Training loss: 2.777830615070939
Validation loss: 2.574208605836857

Epoch: 6| Step: 3
Training loss: 2.9161493841768396
Validation loss: 2.587680652572396

Epoch: 6| Step: 4
Training loss: 2.416830704043636
Validation loss: 2.5590745664654313

Epoch: 6| Step: 5
Training loss: 2.2485739109207716
Validation loss: 2.5457480412404987

Epoch: 6| Step: 6
Training loss: 2.5138892588840536
Validation loss: 2.5491450143762555

Epoch: 6| Step: 7
Training loss: 2.5206392912361415
Validation loss: 2.5422645277890883

Epoch: 6| Step: 8
Training loss: 2.554113667753966
Validation loss: 2.5249117026520667

Epoch: 6| Step: 9
Training loss: 1.8651262341851826
Validation loss: 2.5092919192902423

Epoch: 6| Step: 10
Training loss: 2.5085187731491465
Validation loss: 2.5194609789704434

Epoch: 6| Step: 11
Training loss: 2.734244207251374
Validation loss: 2.505115758975272

Epoch: 6| Step: 12
Training loss: 1.6335591338552393
Validation loss: 2.517894972921702

Epoch: 6| Step: 13
Training loss: 2.32946431595949
Validation loss: 2.5333033165937158

Epoch: 222| Step: 0
Training loss: 2.778303321290311
Validation loss: 2.532646676020568

Epoch: 6| Step: 1
Training loss: 2.8197019132702144
Validation loss: 2.585995734850054

Epoch: 6| Step: 2
Training loss: 2.3586114317315547
Validation loss: 2.694616185062796

Epoch: 6| Step: 3
Training loss: 2.4340876633742514
Validation loss: 2.740699027297574

Epoch: 6| Step: 4
Training loss: 2.283564608293679
Validation loss: 2.7338662119802364

Epoch: 6| Step: 5
Training loss: 2.7729931112672275
Validation loss: 2.729193999087767

Epoch: 6| Step: 6
Training loss: 2.9682934861790153
Validation loss: 2.677972561543957

Epoch: 6| Step: 7
Training loss: 2.258480408818957
Validation loss: 2.62976591925183

Epoch: 6| Step: 8
Training loss: 2.174165464756454
Validation loss: 2.527426661548832

Epoch: 6| Step: 9
Training loss: 2.7366666945141116
Validation loss: 2.4858684801408373

Epoch: 6| Step: 10
Training loss: 2.0677752223754338
Validation loss: 2.462124864567076

Epoch: 6| Step: 11
Training loss: 2.9465245350985114
Validation loss: 2.439169554116861

Epoch: 6| Step: 12
Training loss: 2.1303270550936113
Validation loss: 2.430601533336728

Epoch: 6| Step: 13
Training loss: 2.2868608426023074
Validation loss: 2.4320967937137907

Epoch: 223| Step: 0
Training loss: 2.6836502535672713
Validation loss: 2.436670441421802

Epoch: 6| Step: 1
Training loss: 2.7028748501261273
Validation loss: 2.4264905641322954

Epoch: 6| Step: 2
Training loss: 2.636935122053848
Validation loss: 2.4331050509778924

Epoch: 6| Step: 3
Training loss: 2.6522054959249943
Validation loss: 2.4343983900419346

Epoch: 6| Step: 4
Training loss: 2.5479224923650268
Validation loss: 2.447627969830887

Epoch: 6| Step: 5
Training loss: 2.489468900426146
Validation loss: 2.461682234983481

Epoch: 6| Step: 6
Training loss: 3.008496650073897
Validation loss: 2.476940354586615

Epoch: 6| Step: 7
Training loss: 2.869751825534942
Validation loss: 2.5220537525613604

Epoch: 6| Step: 8
Training loss: 2.4730039234616155
Validation loss: 2.5692788456976094

Epoch: 6| Step: 9
Training loss: 2.5931629297843424
Validation loss: 2.6297467779028967

Epoch: 6| Step: 10
Training loss: 2.5138133853184197
Validation loss: 2.703344545417627

Epoch: 6| Step: 11
Training loss: 2.3224136651851603
Validation loss: 2.6538239529912153

Epoch: 6| Step: 12
Training loss: 2.090453100051083
Validation loss: 2.617691708983651

Epoch: 6| Step: 13
Training loss: 2.963414266001039
Validation loss: 2.6016610621550105

Epoch: 224| Step: 0
Training loss: 2.8251159002784476
Validation loss: 2.5604326626262055

Epoch: 6| Step: 1
Training loss: 2.4118484170580112
Validation loss: 2.5143097302948956

Epoch: 6| Step: 2
Training loss: 2.060277839923403
Validation loss: 2.4950888242221807

Epoch: 6| Step: 3
Training loss: 2.4322157091673446
Validation loss: 2.471251452413279

Epoch: 6| Step: 4
Training loss: 2.245549038059584
Validation loss: 2.4835620194105505

Epoch: 6| Step: 5
Training loss: 2.8813237840716943
Validation loss: 2.4615564649039787

Epoch: 6| Step: 6
Training loss: 2.4108120166808837
Validation loss: 2.464118660143581

Epoch: 6| Step: 7
Training loss: 2.652423301256621
Validation loss: 2.4652898581813183

Epoch: 6| Step: 8
Training loss: 2.0464192822249574
Validation loss: 2.4806120903670457

Epoch: 6| Step: 9
Training loss: 2.6161527951149366
Validation loss: 2.498310243053192

Epoch: 6| Step: 10
Training loss: 3.1759792890185703
Validation loss: 2.482900537842932

Epoch: 6| Step: 11
Training loss: 2.4924804132700156
Validation loss: 2.5012943957199347

Epoch: 6| Step: 12
Training loss: 2.746270685478305
Validation loss: 2.5261117559887056

Epoch: 6| Step: 13
Training loss: 1.7916716494232205
Validation loss: 2.5448621119355037

Epoch: 225| Step: 0
Training loss: 2.2282126218198095
Validation loss: 2.5693553433152143

Epoch: 6| Step: 1
Training loss: 1.6937456757324874
Validation loss: 2.554946997121869

Epoch: 6| Step: 2
Training loss: 2.6446443023633535
Validation loss: 2.574757333119834

Epoch: 6| Step: 3
Training loss: 2.6837227469678706
Validation loss: 2.5966961315240464

Epoch: 6| Step: 4
Training loss: 2.8095183780392907
Validation loss: 2.6159888676706333

Epoch: 6| Step: 5
Training loss: 2.99252532565842
Validation loss: 2.606818763844882

Epoch: 6| Step: 6
Training loss: 1.6756504959278273
Validation loss: 2.593835472717912

Epoch: 6| Step: 7
Training loss: 2.2482094527780974
Validation loss: 2.587565038116395

Epoch: 6| Step: 8
Training loss: 2.516845407096482
Validation loss: 2.5624395553939316

Epoch: 6| Step: 9
Training loss: 2.4231466584889456
Validation loss: 2.546478238566741

Epoch: 6| Step: 10
Training loss: 2.275079822187929
Validation loss: 2.5482133873910424

Epoch: 6| Step: 11
Training loss: 3.043886881106245
Validation loss: 2.529887885333665

Epoch: 6| Step: 12
Training loss: 2.7151563725128733
Validation loss: 2.5350584515040957

Epoch: 6| Step: 13
Training loss: 2.008764968749832
Validation loss: 2.520148788847731

Epoch: 226| Step: 0
Training loss: 2.670723382488854
Validation loss: 2.508668800558569

Epoch: 6| Step: 1
Training loss: 2.062456650711882
Validation loss: 2.4961738769348547

Epoch: 6| Step: 2
Training loss: 2.5580575162671306
Validation loss: 2.481593887809102

Epoch: 6| Step: 3
Training loss: 2.479281788779038
Validation loss: 2.477356380494699

Epoch: 6| Step: 4
Training loss: 2.4683294783138625
Validation loss: 2.4686521067070477

Epoch: 6| Step: 5
Training loss: 2.3716203836878553
Validation loss: 2.4784023388606173

Epoch: 6| Step: 6
Training loss: 2.2514664851199018
Validation loss: 2.4882956729279733

Epoch: 6| Step: 7
Training loss: 2.8596142944930603
Validation loss: 2.5051283329943854

Epoch: 6| Step: 8
Training loss: 2.541921467334062
Validation loss: 2.5155194366813833

Epoch: 6| Step: 9
Training loss: 2.7053281592759384
Validation loss: 2.5404727978947634

Epoch: 6| Step: 10
Training loss: 2.467157357184552
Validation loss: 2.559688344183192

Epoch: 6| Step: 11
Training loss: 1.7698399019843591
Validation loss: 2.594381338338995

Epoch: 6| Step: 12
Training loss: 2.736301898490259
Validation loss: 2.6193805516262647

Epoch: 6| Step: 13
Training loss: 2.9487590507313444
Validation loss: 2.654917196937677

Epoch: 227| Step: 0
Training loss: 2.6332183434533714
Validation loss: 2.5792116432562997

Epoch: 6| Step: 1
Training loss: 2.1181504428086217
Validation loss: 2.5314232004720987

Epoch: 6| Step: 2
Training loss: 2.6695198253089045
Validation loss: 2.4938373338710567

Epoch: 6| Step: 3
Training loss: 2.6501554695444467
Validation loss: 2.4681061486241096

Epoch: 6| Step: 4
Training loss: 2.605201810462307
Validation loss: 2.477122314881073

Epoch: 6| Step: 5
Training loss: 2.661657058453242
Validation loss: 2.467289956151773

Epoch: 6| Step: 6
Training loss: 2.723409759152588
Validation loss: 2.4592088531083607

Epoch: 6| Step: 7
Training loss: 3.0270646292696477
Validation loss: 2.442949534273855

Epoch: 6| Step: 8
Training loss: 2.63564150809821
Validation loss: 2.454937904235406

Epoch: 6| Step: 9
Training loss: 2.2700583392473477
Validation loss: 2.4671977843527246

Epoch: 6| Step: 10
Training loss: 2.6421246305145005
Validation loss: 2.467474873323808

Epoch: 6| Step: 11
Training loss: 2.2901818985305367
Validation loss: 2.495877585374084

Epoch: 6| Step: 12
Training loss: 2.015940205376045
Validation loss: 2.529242891239248

Epoch: 6| Step: 13
Training loss: 2.305110879577114
Validation loss: 2.569861589837356

Epoch: 228| Step: 0
Training loss: 2.3072561658850645
Validation loss: 2.582347792696801

Epoch: 6| Step: 1
Training loss: 2.7965999020445307
Validation loss: 2.6106311942076115

Epoch: 6| Step: 2
Training loss: 2.411787720519801
Validation loss: 2.61439390092327

Epoch: 6| Step: 3
Training loss: 2.578407410846112
Validation loss: 2.588505017714879

Epoch: 6| Step: 4
Training loss: 2.4755283446826355
Validation loss: 2.570788884948293

Epoch: 6| Step: 5
Training loss: 2.303519363490851
Validation loss: 2.5738633159553546

Epoch: 6| Step: 6
Training loss: 2.4456513873849977
Validation loss: 2.579314768819396

Epoch: 6| Step: 7
Training loss: 2.951260255491218
Validation loss: 2.5797393716296977

Epoch: 6| Step: 8
Training loss: 2.3026989650187746
Validation loss: 2.572279106607678

Epoch: 6| Step: 9
Training loss: 2.657837965280939
Validation loss: 2.5663841277696595

Epoch: 6| Step: 10
Training loss: 1.9580040986365963
Validation loss: 2.551289948192698

Epoch: 6| Step: 11
Training loss: 2.29292424693291
Validation loss: 2.530318633350552

Epoch: 6| Step: 12
Training loss: 2.2756368479306333
Validation loss: 2.5354805719984608

Epoch: 6| Step: 13
Training loss: 3.2513527622431098
Validation loss: 2.5088522987202344

Epoch: 229| Step: 0
Training loss: 2.6322138527369936
Validation loss: 2.500284705819323

Epoch: 6| Step: 1
Training loss: 2.420092117195726
Validation loss: 2.5018677994367624

Epoch: 6| Step: 2
Training loss: 2.425222728765062
Validation loss: 2.484751287893054

Epoch: 6| Step: 3
Training loss: 2.2481691540986577
Validation loss: 2.4883619375783868

Epoch: 6| Step: 4
Training loss: 2.5537703147972697
Validation loss: 2.4961810959047095

Epoch: 6| Step: 5
Training loss: 2.926458832900128
Validation loss: 2.5070727043037864

Epoch: 6| Step: 6
Training loss: 2.7107174478975904
Validation loss: 2.5516535882879974

Epoch: 6| Step: 7
Training loss: 2.316421688858225
Validation loss: 2.5610382008424724

Epoch: 6| Step: 8
Training loss: 2.5919887583806718
Validation loss: 2.568893532160783

Epoch: 6| Step: 9
Training loss: 2.6665567037639435
Validation loss: 2.535197190560056

Epoch: 6| Step: 10
Training loss: 1.9009495821733
Validation loss: 2.4907325552906476

Epoch: 6| Step: 11
Training loss: 2.5481031768066416
Validation loss: 2.4734143283476806

Epoch: 6| Step: 12
Training loss: 2.5727416273697545
Validation loss: 2.4529891208011314

Epoch: 6| Step: 13
Training loss: 1.3743630581241986
Validation loss: 2.450432487932605

Epoch: 230| Step: 0
Training loss: 2.4643187530545827
Validation loss: 2.459691971780033

Epoch: 6| Step: 1
Training loss: 2.8900084791752065
Validation loss: 2.45387714842758

Epoch: 6| Step: 2
Training loss: 2.352782683784607
Validation loss: 2.4784433211501398

Epoch: 6| Step: 3
Training loss: 2.9904250888316968
Validation loss: 2.4580922680335897

Epoch: 6| Step: 4
Training loss: 1.620153462358553
Validation loss: 2.466733269456067

Epoch: 6| Step: 5
Training loss: 2.546410079366119
Validation loss: 2.476314986874255

Epoch: 6| Step: 6
Training loss: 2.7085191124996477
Validation loss: 2.4973751829756097

Epoch: 6| Step: 7
Training loss: 2.4111634658465615
Validation loss: 2.525281821319321

Epoch: 6| Step: 8
Training loss: 2.1629620449847087
Validation loss: 2.549348628085594

Epoch: 6| Step: 9
Training loss: 2.5398311449229176
Validation loss: 2.581874262364859

Epoch: 6| Step: 10
Training loss: 1.7821699744869024
Validation loss: 2.576507303460376

Epoch: 6| Step: 11
Training loss: 2.529232115634522
Validation loss: 2.6066819563749455

Epoch: 6| Step: 12
Training loss: 2.3885436128879296
Validation loss: 2.5959061162285213

Epoch: 6| Step: 13
Training loss: 3.0078002929439793
Validation loss: 2.558447554024217

Epoch: 231| Step: 0
Training loss: 2.576541206082178
Validation loss: 2.509068109800228

Epoch: 6| Step: 1
Training loss: 2.3868552011296513
Validation loss: 2.471008232655594

Epoch: 6| Step: 2
Training loss: 2.8085167546654537
Validation loss: 2.4776918162864514

Epoch: 6| Step: 3
Training loss: 3.1021323653411645
Validation loss: 2.4638258483006186

Epoch: 6| Step: 4
Training loss: 3.0681405575222414
Validation loss: 2.4586314584933477

Epoch: 6| Step: 5
Training loss: 2.010908419169825
Validation loss: 2.4395029102042898

Epoch: 6| Step: 6
Training loss: 2.716598711938615
Validation loss: 2.456107197605516

Epoch: 6| Step: 7
Training loss: 2.183126819346642
Validation loss: 2.435753256670166

Epoch: 6| Step: 8
Training loss: 2.0533092212912663
Validation loss: 2.4337779872615326

Epoch: 6| Step: 9
Training loss: 1.911648843887822
Validation loss: 2.4676290199459157

Epoch: 6| Step: 10
Training loss: 2.1953437775796782
Validation loss: 2.4957182826798165

Epoch: 6| Step: 11
Training loss: 2.2920308835144185
Validation loss: 2.5245630417201577

Epoch: 6| Step: 12
Training loss: 2.852516662655975
Validation loss: 2.554916403191326

Epoch: 6| Step: 13
Training loss: 2.325501672908597
Validation loss: 2.5810862260738054

Epoch: 232| Step: 0
Training loss: 2.5443552107991336
Validation loss: 2.6037429166194377

Epoch: 6| Step: 1
Training loss: 2.130076907206694
Validation loss: 2.614653442551471

Epoch: 6| Step: 2
Training loss: 3.4183364757546335
Validation loss: 2.606085449809609

Epoch: 6| Step: 3
Training loss: 2.5171958804805015
Validation loss: 2.5776415090928584

Epoch: 6| Step: 4
Training loss: 2.542035425252954
Validation loss: 2.5443426936058504

Epoch: 6| Step: 5
Training loss: 3.035862196195999
Validation loss: 2.5301755596979283

Epoch: 6| Step: 6
Training loss: 2.450324920595573
Validation loss: 2.5273792950118033

Epoch: 6| Step: 7
Training loss: 2.5635252971557967
Validation loss: 2.5037590601618733

Epoch: 6| Step: 8
Training loss: 1.924161713622558
Validation loss: 2.5023028401554055

Epoch: 6| Step: 9
Training loss: 2.3522723067680724
Validation loss: 2.4836328581717546

Epoch: 6| Step: 10
Training loss: 2.276514546891421
Validation loss: 2.4812757276703126

Epoch: 6| Step: 11
Training loss: 1.9504805095122228
Validation loss: 2.498187074331181

Epoch: 6| Step: 12
Training loss: 2.0301249983314076
Validation loss: 2.486192264203585

Epoch: 6| Step: 13
Training loss: 1.7159670407168839
Validation loss: 2.4871493473249893

Epoch: 233| Step: 0
Training loss: 2.784886928981921
Validation loss: 2.486156151988116

Epoch: 6| Step: 1
Training loss: 2.1497796322754086
Validation loss: 2.4895262490046064

Epoch: 6| Step: 2
Training loss: 2.36685349528433
Validation loss: 2.498137679737842

Epoch: 6| Step: 3
Training loss: 2.3091319533122436
Validation loss: 2.531022827698155

Epoch: 6| Step: 4
Training loss: 3.1350515835304025
Validation loss: 2.5198275692732164

Epoch: 6| Step: 5
Training loss: 2.4287528543264094
Validation loss: 2.5312411435872573

Epoch: 6| Step: 6
Training loss: 1.8296602763456276
Validation loss: 2.549523822287295

Epoch: 6| Step: 7
Training loss: 2.127557225606395
Validation loss: 2.5526012200732264

Epoch: 6| Step: 8
Training loss: 2.4884245874629665
Validation loss: 2.538876213263545

Epoch: 6| Step: 9
Training loss: 1.986182883624917
Validation loss: 2.514956678579538

Epoch: 6| Step: 10
Training loss: 2.1475637427785177
Validation loss: 2.497097541411372

Epoch: 6| Step: 11
Training loss: 2.915036118088965
Validation loss: 2.4922956798794313

Epoch: 6| Step: 12
Training loss: 2.4865236407747244
Validation loss: 2.4799457562293634

Epoch: 6| Step: 13
Training loss: 2.486031417942769
Validation loss: 2.475104093574115

Epoch: 234| Step: 0
Training loss: 2.8781072990875507
Validation loss: 2.472779884857451

Epoch: 6| Step: 1
Training loss: 2.1808695988839926
Validation loss: 2.4954921340113105

Epoch: 6| Step: 2
Training loss: 2.4188893280511747
Validation loss: 2.549667169628808

Epoch: 6| Step: 3
Training loss: 2.2608270814581637
Validation loss: 2.5728907396806133

Epoch: 6| Step: 4
Training loss: 2.1005475738157613
Validation loss: 2.624921540681133

Epoch: 6| Step: 5
Training loss: 2.6005804367666197
Validation loss: 2.63906916553252

Epoch: 6| Step: 6
Training loss: 2.3925032872543155
Validation loss: 2.62613122905647

Epoch: 6| Step: 7
Training loss: 2.0257004268248258
Validation loss: 2.5836109163746275

Epoch: 6| Step: 8
Training loss: 2.329698683611445
Validation loss: 2.568072109657512

Epoch: 6| Step: 9
Training loss: 2.49787946412988
Validation loss: 2.551066496947752

Epoch: 6| Step: 10
Training loss: 2.3231246809488386
Validation loss: 2.5249338085100748

Epoch: 6| Step: 11
Training loss: 2.4810597113758375
Validation loss: 2.52483200136538

Epoch: 6| Step: 12
Training loss: 2.533255547868569
Validation loss: 2.503059207459794

Epoch: 6| Step: 13
Training loss: 3.0023154224386532
Validation loss: 2.485080768630014

Epoch: 235| Step: 0
Training loss: 2.75299931736171
Validation loss: 2.4512799526669

Epoch: 6| Step: 1
Training loss: 2.1692908852067565
Validation loss: 2.4326373614794665

Epoch: 6| Step: 2
Training loss: 2.385935653356051
Validation loss: 2.4250820989214628

Epoch: 6| Step: 3
Training loss: 2.594273433953323
Validation loss: 2.427777737404055

Epoch: 6| Step: 4
Training loss: 2.607270082777367
Validation loss: 2.447562731777166

Epoch: 6| Step: 5
Training loss: 2.505041760612407
Validation loss: 2.4426445490340916

Epoch: 6| Step: 6
Training loss: 2.197473297477683
Validation loss: 2.4470263773239336

Epoch: 6| Step: 7
Training loss: 2.5156668902398276
Validation loss: 2.441046494621331

Epoch: 6| Step: 8
Training loss: 1.9071301163890242
Validation loss: 2.449313631028949

Epoch: 6| Step: 9
Training loss: 2.749779345589819
Validation loss: 2.484789752244494

Epoch: 6| Step: 10
Training loss: 2.7580811799227276
Validation loss: 2.4765799279073812

Epoch: 6| Step: 11
Training loss: 2.2547695681624487
Validation loss: 2.4760830964714575

Epoch: 6| Step: 12
Training loss: 2.4338805885331105
Validation loss: 2.508388472184636

Epoch: 6| Step: 13
Training loss: 1.174706255942414
Validation loss: 2.5076178834689724

Epoch: 236| Step: 0
Training loss: 2.6608495047014444
Validation loss: 2.5447952090023005

Epoch: 6| Step: 1
Training loss: 2.408609496741676
Validation loss: 2.5926556839284087

Epoch: 6| Step: 2
Training loss: 2.6314123035671826
Validation loss: 2.607873272403199

Epoch: 6| Step: 3
Training loss: 2.759817977376318
Validation loss: 2.6051842500870843

Epoch: 6| Step: 4
Training loss: 2.2307851269709604
Validation loss: 2.5795971537617146

Epoch: 6| Step: 5
Training loss: 2.3791311373844173
Validation loss: 2.591747530471724

Epoch: 6| Step: 6
Training loss: 1.584461822237614
Validation loss: 2.6150579019781106

Epoch: 6| Step: 7
Training loss: 1.8055884684309802
Validation loss: 2.6033186039048313

Epoch: 6| Step: 8
Training loss: 2.708831672792656
Validation loss: 2.570749184338878

Epoch: 6| Step: 9
Training loss: 2.5115469344300965
Validation loss: 2.5251627448564555

Epoch: 6| Step: 10
Training loss: 2.737896379314291
Validation loss: 2.50356844621059

Epoch: 6| Step: 11
Training loss: 2.3968398150033723
Validation loss: 2.4828335306208826

Epoch: 6| Step: 12
Training loss: 2.2793399705383894
Validation loss: 2.4564812533064813

Epoch: 6| Step: 13
Training loss: 2.4462350683287744
Validation loss: 2.4589770749786752

Epoch: 237| Step: 0
Training loss: 2.48967901282757
Validation loss: 2.460913609813409

Epoch: 6| Step: 1
Training loss: 2.3753636734243813
Validation loss: 2.4633944766472506

Epoch: 6| Step: 2
Training loss: 2.2498007792119235
Validation loss: 2.465514187991167

Epoch: 6| Step: 3
Training loss: 2.563358070178114
Validation loss: 2.470920287408622

Epoch: 6| Step: 4
Training loss: 2.37316060362765
Validation loss: 2.4721947735248198

Epoch: 6| Step: 5
Training loss: 2.661936428976169
Validation loss: 2.4601206725888667

Epoch: 6| Step: 6
Training loss: 1.4090589232324282
Validation loss: 2.4853833108418972

Epoch: 6| Step: 7
Training loss: 2.2252596071501114
Validation loss: 2.4967156873853487

Epoch: 6| Step: 8
Training loss: 2.67167564674561
Validation loss: 2.496405105702853

Epoch: 6| Step: 9
Training loss: 2.4136731472651
Validation loss: 2.5297226069600174

Epoch: 6| Step: 10
Training loss: 2.491467602112845
Validation loss: 2.527146210559602

Epoch: 6| Step: 11
Training loss: 2.6779036297996957
Validation loss: 2.5163952567894987

Epoch: 6| Step: 12
Training loss: 2.75910344585903
Validation loss: 2.4793715669361425

Epoch: 6| Step: 13
Training loss: 1.921445100665597
Validation loss: 2.4551716957329504

Epoch: 238| Step: 0
Training loss: 2.4845551239549803
Validation loss: 2.4467742502303627

Epoch: 6| Step: 1
Training loss: 2.355006942900772
Validation loss: 2.424874044652199

Epoch: 6| Step: 2
Training loss: 2.7445133268366693
Validation loss: 2.438640687274778

Epoch: 6| Step: 3
Training loss: 1.8925898406903248
Validation loss: 2.4389761879181147

Epoch: 6| Step: 4
Training loss: 2.495149389010651
Validation loss: 2.450717893299302

Epoch: 6| Step: 5
Training loss: 1.9388686852494026
Validation loss: 2.4853399333395303

Epoch: 6| Step: 6
Training loss: 2.447790188599416
Validation loss: 2.524164846096503

Epoch: 6| Step: 7
Training loss: 2.7002942030942036
Validation loss: 2.541472320819019

Epoch: 6| Step: 8
Training loss: 2.3302694595452595
Validation loss: 2.5707669041435697

Epoch: 6| Step: 9
Training loss: 2.521405136789914
Validation loss: 2.5809037662212133

Epoch: 6| Step: 10
Training loss: 2.271516388054991
Validation loss: 2.5580158371591963

Epoch: 6| Step: 11
Training loss: 2.833217693287721
Validation loss: 2.53207333228419

Epoch: 6| Step: 12
Training loss: 2.209056795722395
Validation loss: 2.526095405584632

Epoch: 6| Step: 13
Training loss: 2.2375052340142605
Validation loss: 2.511436140684461

Epoch: 239| Step: 0
Training loss: 2.1758146711484447
Validation loss: 2.4953716349895068

Epoch: 6| Step: 1
Training loss: 2.347191686889343
Validation loss: 2.516987197333206

Epoch: 6| Step: 2
Training loss: 1.9141220394917016
Validation loss: 2.5024884626484774

Epoch: 6| Step: 3
Training loss: 2.5241514914220082
Validation loss: 2.5037166512221356

Epoch: 6| Step: 4
Training loss: 2.096891295686668
Validation loss: 2.506745576709021

Epoch: 6| Step: 5
Training loss: 2.711022015664071
Validation loss: 2.5162423299366035

Epoch: 6| Step: 6
Training loss: 2.5044422736389325
Validation loss: 2.533149226509136

Epoch: 6| Step: 7
Training loss: 2.1675391519039793
Validation loss: 2.5594929765463026

Epoch: 6| Step: 8
Training loss: 1.386570753339922
Validation loss: 2.579624319533579

Epoch: 6| Step: 9
Training loss: 2.3839210808127556
Validation loss: 2.575831156810903

Epoch: 6| Step: 10
Training loss: 2.3674766439476125
Validation loss: 2.5663248165557397

Epoch: 6| Step: 11
Training loss: 2.593285392605766
Validation loss: 2.5544546020594225

Epoch: 6| Step: 12
Training loss: 3.1821889574590196
Validation loss: 2.506824084843524

Epoch: 6| Step: 13
Training loss: 2.46556059121058
Validation loss: 2.48448773313612

Epoch: 240| Step: 0
Training loss: 1.6622420548266215
Validation loss: 2.4806918472086075

Epoch: 6| Step: 1
Training loss: 2.000609781766891
Validation loss: 2.445021782055036

Epoch: 6| Step: 2
Training loss: 2.026783889760084
Validation loss: 2.449798633092839

Epoch: 6| Step: 3
Training loss: 2.1408028633124188
Validation loss: 2.4567591815556447

Epoch: 6| Step: 4
Training loss: 2.4000981946566564
Validation loss: 2.4651535596397642

Epoch: 6| Step: 5
Training loss: 2.002060305819894
Validation loss: 2.486491380653523

Epoch: 6| Step: 6
Training loss: 2.067089177083472
Validation loss: 2.514388648668548

Epoch: 6| Step: 7
Training loss: 2.87970282663871
Validation loss: 2.563836073300787

Epoch: 6| Step: 8
Training loss: 2.7619588226906147
Validation loss: 2.5518806112478583

Epoch: 6| Step: 9
Training loss: 2.0999271879743118
Validation loss: 2.5931442705914005

Epoch: 6| Step: 10
Training loss: 2.209822194813517
Validation loss: 2.57969750916902

Epoch: 6| Step: 11
Training loss: 2.851069159486113
Validation loss: 2.5643621552168576

Epoch: 6| Step: 12
Training loss: 3.0180323977946597
Validation loss: 2.574620144339906

Epoch: 6| Step: 13
Training loss: 2.8736713490585353
Validation loss: 2.5184250941059036

Epoch: 241| Step: 0
Training loss: 1.968217384105933
Validation loss: 2.473869424894396

Epoch: 6| Step: 1
Training loss: 2.058922641836832
Validation loss: 2.4766495234117043

Epoch: 6| Step: 2
Training loss: 2.413247375151739
Validation loss: 2.451758315491592

Epoch: 6| Step: 3
Training loss: 2.8111574147381027
Validation loss: 2.4595143953896685

Epoch: 6| Step: 4
Training loss: 2.135657121719855
Validation loss: 2.433352581815603

Epoch: 6| Step: 5
Training loss: 2.9679249470313325
Validation loss: 2.461180833752228

Epoch: 6| Step: 6
Training loss: 2.2090749275137487
Validation loss: 2.4569500917366516

Epoch: 6| Step: 7
Training loss: 2.1664489367709514
Validation loss: 2.4626408580976658

Epoch: 6| Step: 8
Training loss: 2.8639769496096696
Validation loss: 2.4745226683461996

Epoch: 6| Step: 9
Training loss: 2.811621719555846
Validation loss: 2.4848678243495352

Epoch: 6| Step: 10
Training loss: 2.2353907057175153
Validation loss: 2.5198162762485796

Epoch: 6| Step: 11
Training loss: 2.2531999509410827
Validation loss: 2.545712526121371

Epoch: 6| Step: 12
Training loss: 2.491738401505191
Validation loss: 2.534732046617262

Epoch: 6| Step: 13
Training loss: 1.7341819861983583
Validation loss: 2.5528077360434898

Epoch: 242| Step: 0
Training loss: 2.3622556368279843
Validation loss: 2.5626635995699494

Epoch: 6| Step: 1
Training loss: 2.7114121079336266
Validation loss: 2.6419262772811303

Epoch: 6| Step: 2
Training loss: 2.5175148635622464
Validation loss: 2.6587794580857413

Epoch: 6| Step: 3
Training loss: 2.500307827117829
Validation loss: 2.6210188093803066

Epoch: 6| Step: 4
Training loss: 2.4068967272130206
Validation loss: 2.534341089221999

Epoch: 6| Step: 5
Training loss: 2.0493803343800896
Validation loss: 2.4748824737494273

Epoch: 6| Step: 6
Training loss: 1.9341381192952867
Validation loss: 2.441335715966997

Epoch: 6| Step: 7
Training loss: 3.1098065100824788
Validation loss: 2.448619700905488

Epoch: 6| Step: 8
Training loss: 1.822853770306308
Validation loss: 2.4236718928531396

Epoch: 6| Step: 9
Training loss: 1.671144058304905
Validation loss: 2.4200450089853223

Epoch: 6| Step: 10
Training loss: 2.390039708912943
Validation loss: 2.435012024077012

Epoch: 6| Step: 11
Training loss: 2.641171551183444
Validation loss: 2.435523153638976

Epoch: 6| Step: 12
Training loss: 2.4518931995487505
Validation loss: 2.436396081431822

Epoch: 6| Step: 13
Training loss: 2.4300675171628403
Validation loss: 2.4586703356439057

Epoch: 243| Step: 0
Training loss: 1.9076017996045433
Validation loss: 2.470721877759449

Epoch: 6| Step: 1
Training loss: 2.2077154938700274
Validation loss: 2.5331185231458546

Epoch: 6| Step: 2
Training loss: 2.342826763148839
Validation loss: 2.553218686113307

Epoch: 6| Step: 3
Training loss: 2.1418686198842756
Validation loss: 2.5807357679888825

Epoch: 6| Step: 4
Training loss: 2.31076912927515
Validation loss: 2.667333689324111

Epoch: 6| Step: 5
Training loss: 2.5692319134859467
Validation loss: 2.7340462304450908

Epoch: 6| Step: 6
Training loss: 2.1505430688968823
Validation loss: 2.7410084694343717

Epoch: 6| Step: 7
Training loss: 2.3843666886451023
Validation loss: 2.7312523121893353

Epoch: 6| Step: 8
Training loss: 2.342473101873682
Validation loss: 2.6786637127708084

Epoch: 6| Step: 9
Training loss: 2.6299998487175147
Validation loss: 2.59983070806824

Epoch: 6| Step: 10
Training loss: 2.641428808179702
Validation loss: 2.5080595919887787

Epoch: 6| Step: 11
Training loss: 2.4478015845552257
Validation loss: 2.472916967692917

Epoch: 6| Step: 12
Training loss: 2.363595282757826
Validation loss: 2.449419606892104

Epoch: 6| Step: 13
Training loss: 2.9980261985239776
Validation loss: 2.4451100250103823

Epoch: 244| Step: 0
Training loss: 2.5153472936657204
Validation loss: 2.440721272776718

Epoch: 6| Step: 1
Training loss: 2.8493026348680335
Validation loss: 2.4315471398103905

Epoch: 6| Step: 2
Training loss: 2.5802850171058105
Validation loss: 2.420764038721923

Epoch: 6| Step: 3
Training loss: 2.2623332346791636
Validation loss: 2.419518666240946

Epoch: 6| Step: 4
Training loss: 2.492606100963517
Validation loss: 2.425516427005682

Epoch: 6| Step: 5
Training loss: 2.1683251440239073
Validation loss: 2.4427157389966303

Epoch: 6| Step: 6
Training loss: 1.8087374339692048
Validation loss: 2.45766946534046

Epoch: 6| Step: 7
Training loss: 2.4682688183781427
Validation loss: 2.513138835945495

Epoch: 6| Step: 8
Training loss: 2.6462960827274213
Validation loss: 2.567939481486043

Epoch: 6| Step: 9
Training loss: 2.3848307082834266
Validation loss: 2.600528320190785

Epoch: 6| Step: 10
Training loss: 2.247915149743597
Validation loss: 2.6114605345677204

Epoch: 6| Step: 11
Training loss: 2.3113062071167985
Validation loss: 2.6363028750337243

Epoch: 6| Step: 12
Training loss: 2.3476337044596503
Validation loss: 2.5929964999496766

Epoch: 6| Step: 13
Training loss: 2.6542933718761375
Validation loss: 2.5648946610419707

Epoch: 245| Step: 0
Training loss: 2.333003520362837
Validation loss: 2.544835486769398

Epoch: 6| Step: 1
Training loss: 2.269736407095884
Validation loss: 2.5286832988128842

Epoch: 6| Step: 2
Training loss: 1.8318621917349724
Validation loss: 2.514955717324976

Epoch: 6| Step: 3
Training loss: 2.557567687719018
Validation loss: 2.501701207875904

Epoch: 6| Step: 4
Training loss: 2.3177734251561577
Validation loss: 2.4938022205585444

Epoch: 6| Step: 5
Training loss: 2.6887775312261812
Validation loss: 2.497216277636496

Epoch: 6| Step: 6
Training loss: 2.1543314041317148
Validation loss: 2.4836701228824336

Epoch: 6| Step: 7
Training loss: 2.612128352693417
Validation loss: 2.5095607130784625

Epoch: 6| Step: 8
Training loss: 2.5947748939914383
Validation loss: 2.5053840947188637

Epoch: 6| Step: 9
Training loss: 2.203110931568003
Validation loss: 2.517943305412168

Epoch: 6| Step: 10
Training loss: 1.7806127646478762
Validation loss: 2.541965526222446

Epoch: 6| Step: 11
Training loss: 2.4909766433582528
Validation loss: 2.5571407798819084

Epoch: 6| Step: 12
Training loss: 2.378759520567275
Validation loss: 2.5615937846314267

Epoch: 6| Step: 13
Training loss: 2.4499603073641647
Validation loss: 2.5714690173025576

Epoch: 246| Step: 0
Training loss: 2.3127748480696884
Validation loss: 2.565828203418782

Epoch: 6| Step: 1
Training loss: 2.4265410727533108
Validation loss: 2.522158708995879

Epoch: 6| Step: 2
Training loss: 1.873371879694669
Validation loss: 2.5101463527375873

Epoch: 6| Step: 3
Training loss: 2.2182086767782083
Validation loss: 2.508826749574427

Epoch: 6| Step: 4
Training loss: 2.7410924741168725
Validation loss: 2.49970028731689

Epoch: 6| Step: 5
Training loss: 2.488834050213954
Validation loss: 2.498218246000792

Epoch: 6| Step: 6
Training loss: 2.4034761566636424
Validation loss: 2.4952671206734136

Epoch: 6| Step: 7
Training loss: 1.9167285646588625
Validation loss: 2.48928239050129

Epoch: 6| Step: 8
Training loss: 1.984378724582811
Validation loss: 2.4984790543894495

Epoch: 6| Step: 9
Training loss: 2.2166852343171213
Validation loss: 2.4954523891780647

Epoch: 6| Step: 10
Training loss: 2.5838481841235628
Validation loss: 2.507241864829009

Epoch: 6| Step: 11
Training loss: 1.5147789235480345
Validation loss: 2.5209142729062837

Epoch: 6| Step: 12
Training loss: 3.0634659781256426
Validation loss: 2.5553621533553583

Epoch: 6| Step: 13
Training loss: 2.193458072551203
Validation loss: 2.534849055382458

Epoch: 247| Step: 0
Training loss: 2.2488614486549814
Validation loss: 2.530356956181297

Epoch: 6| Step: 1
Training loss: 2.835795249208689
Validation loss: 2.514137138381925

Epoch: 6| Step: 2
Training loss: 2.00947009583884
Validation loss: 2.5029028733597425

Epoch: 6| Step: 3
Training loss: 2.4819061680039645
Validation loss: 2.519365870180206

Epoch: 6| Step: 4
Training loss: 2.220533916431685
Validation loss: 2.48780948381005

Epoch: 6| Step: 5
Training loss: 2.178083807447644
Validation loss: 2.488906530140959

Epoch: 6| Step: 6
Training loss: 2.326055746438759
Validation loss: 2.5087123949777483

Epoch: 6| Step: 7
Training loss: 2.4391235422124082
Validation loss: 2.494795137202129

Epoch: 6| Step: 8
Training loss: 2.214394283269934
Validation loss: 2.5142073716125006

Epoch: 6| Step: 9
Training loss: 2.532899483958533
Validation loss: 2.5094449683336824

Epoch: 6| Step: 10
Training loss: 1.941711094829584
Validation loss: 2.5199267849668723

Epoch: 6| Step: 11
Training loss: 2.0323828252633147
Validation loss: 2.5163748791689815

Epoch: 6| Step: 12
Training loss: 2.130965442622514
Validation loss: 2.5091880409844456

Epoch: 6| Step: 13
Training loss: 2.5923097587390878
Validation loss: 2.5046272902782882

Epoch: 248| Step: 0
Training loss: 2.1071377793405603
Validation loss: 2.5254737407556855

Epoch: 6| Step: 1
Training loss: 2.136475599774975
Validation loss: 2.5238216057904945

Epoch: 6| Step: 2
Training loss: 1.838112958539831
Validation loss: 2.541193300389457

Epoch: 6| Step: 3
Training loss: 2.84899452274823
Validation loss: 2.5603221028949577

Epoch: 6| Step: 4
Training loss: 2.377066365838126
Validation loss: 2.5083646230722345

Epoch: 6| Step: 5
Training loss: 2.516014305935262
Validation loss: 2.488020842991556

Epoch: 6| Step: 6
Training loss: 1.6761075926957913
Validation loss: 2.4542722227811873

Epoch: 6| Step: 7
Training loss: 2.64975959839006
Validation loss: 2.4490699545580337

Epoch: 6| Step: 8
Training loss: 2.4740076214080085
Validation loss: 2.443414653991711

Epoch: 6| Step: 9
Training loss: 2.7180420403222216
Validation loss: 2.4460819148738553

Epoch: 6| Step: 10
Training loss: 2.209082374456369
Validation loss: 2.4597940413936814

Epoch: 6| Step: 11
Training loss: 2.10672961470964
Validation loss: 2.478265678404804

Epoch: 6| Step: 12
Training loss: 1.795718675155642
Validation loss: 2.5317879716233893

Epoch: 6| Step: 13
Training loss: 2.78705471228478
Validation loss: 2.5575729466714323

Epoch: 249| Step: 0
Training loss: 2.090184150139442
Validation loss: 2.514479641177784

Epoch: 6| Step: 1
Training loss: 2.549557729776315
Validation loss: 2.4917644530381895

Epoch: 6| Step: 2
Training loss: 2.6891572854660883
Validation loss: 2.479026441640463

Epoch: 6| Step: 3
Training loss: 2.248356112663336
Validation loss: 2.4860093209027716

Epoch: 6| Step: 4
Training loss: 2.2055505697523383
Validation loss: 2.493796976700582

Epoch: 6| Step: 5
Training loss: 2.040833737970543
Validation loss: 2.4998107336039146

Epoch: 6| Step: 6
Training loss: 2.282835213654594
Validation loss: 2.520162676410909

Epoch: 6| Step: 7
Training loss: 2.4042719848236924
Validation loss: 2.511453058380822

Epoch: 6| Step: 8
Training loss: 2.1320286243012987
Validation loss: 2.5242299335078244

Epoch: 6| Step: 9
Training loss: 2.6643019761546554
Validation loss: 2.557272635798581

Epoch: 6| Step: 10
Training loss: 2.136271930401211
Validation loss: 2.5848772590392373

Epoch: 6| Step: 11
Training loss: 2.035670707828968
Validation loss: 2.5457720033690525

Epoch: 6| Step: 12
Training loss: 2.246694998501195
Validation loss: 2.5374371370758473

Epoch: 6| Step: 13
Training loss: 1.988337607793485
Validation loss: 2.5116770541879703

Epoch: 250| Step: 0
Training loss: 2.1132122035566474
Validation loss: 2.494000708562935

Epoch: 6| Step: 1
Training loss: 2.1314408918789494
Validation loss: 2.4786492008716365

Epoch: 6| Step: 2
Training loss: 2.4435666222807213
Validation loss: 2.4821701404316654

Epoch: 6| Step: 3
Training loss: 2.51918848352789
Validation loss: 2.4824405211616862

Epoch: 6| Step: 4
Training loss: 1.9563422598731295
Validation loss: 2.4870838832386815

Epoch: 6| Step: 5
Training loss: 2.471866813096331
Validation loss: 2.5192947010828357

Epoch: 6| Step: 6
Training loss: 1.7227545124150414
Validation loss: 2.559001443183591

Epoch: 6| Step: 7
Training loss: 2.3999151095635805
Validation loss: 2.5814164501288666

Epoch: 6| Step: 8
Training loss: 2.198189909765426
Validation loss: 2.5705814200321444

Epoch: 6| Step: 9
Training loss: 2.4507458077161095
Validation loss: 2.5838652426056443

Epoch: 6| Step: 10
Training loss: 2.075777951296424
Validation loss: 2.530085468083202

Epoch: 6| Step: 11
Training loss: 2.4901558657967406
Validation loss: 2.4866558689259204

Epoch: 6| Step: 12
Training loss: 2.699817905643418
Validation loss: 2.4726939196298603

Epoch: 6| Step: 13
Training loss: 2.037908234683776
Validation loss: 2.4731583370555534

Epoch: 251| Step: 0
Training loss: 2.4975451814919687
Validation loss: 2.467778413575225

Epoch: 6| Step: 1
Training loss: 1.900728201606062
Validation loss: 2.4520352128847183

Epoch: 6| Step: 2
Training loss: 2.3183065149697257
Validation loss: 2.4723858968284738

Epoch: 6| Step: 3
Training loss: 2.4799138927893067
Validation loss: 2.4874106000035785

Epoch: 6| Step: 4
Training loss: 2.6534818699089593
Validation loss: 2.466605171048444

Epoch: 6| Step: 5
Training loss: 2.5085689556520525
Validation loss: 2.459932801457415

Epoch: 6| Step: 6
Training loss: 2.273587041701691
Validation loss: 2.463178850957853

Epoch: 6| Step: 7
Training loss: 2.2883637178667695
Validation loss: 2.4531557859630446

Epoch: 6| Step: 8
Training loss: 2.2708639673622373
Validation loss: 2.4532616157078637

Epoch: 6| Step: 9
Training loss: 1.9974896053764675
Validation loss: 2.4743035406035165

Epoch: 6| Step: 10
Training loss: 1.8084698298866784
Validation loss: 2.4971876445895584

Epoch: 6| Step: 11
Training loss: 2.48186197877387
Validation loss: 2.5330553461972705

Epoch: 6| Step: 12
Training loss: 2.115613514180186
Validation loss: 2.5821787158926823

Epoch: 6| Step: 13
Training loss: 1.9837138358595392
Validation loss: 2.600022573388854

Epoch: 252| Step: 0
Training loss: 2.6898708088422607
Validation loss: 2.562110633191208

Epoch: 6| Step: 1
Training loss: 2.220793092326104
Validation loss: 2.5267135956150972

Epoch: 6| Step: 2
Training loss: 1.9895698253978589
Validation loss: 2.513276132916443

Epoch: 6| Step: 3
Training loss: 2.371541667529554
Validation loss: 2.4578729166731

Epoch: 6| Step: 4
Training loss: 2.1146892151530374
Validation loss: 2.4692428530975907

Epoch: 6| Step: 5
Training loss: 1.8519430936305517
Validation loss: 2.4813571327691752

Epoch: 6| Step: 6
Training loss: 1.9666652237622846
Validation loss: 2.5009992007558073

Epoch: 6| Step: 7
Training loss: 2.3842880933129837
Validation loss: 2.5219192206812946

Epoch: 6| Step: 8
Training loss: 2.4423221914645428
Validation loss: 2.534475744646562

Epoch: 6| Step: 9
Training loss: 2.1500335868163725
Validation loss: 2.5183078047627236

Epoch: 6| Step: 10
Training loss: 2.655396627337265
Validation loss: 2.500849470797428

Epoch: 6| Step: 11
Training loss: 2.4340086165426884
Validation loss: 2.478587270984869

Epoch: 6| Step: 12
Training loss: 2.4652058717750887
Validation loss: 2.4782826867647443

Epoch: 6| Step: 13
Training loss: 1.012849507231008
Validation loss: 2.470390555630343

Epoch: 253| Step: 0
Training loss: 2.144044025154175
Validation loss: 2.4614709742402905

Epoch: 6| Step: 1
Training loss: 2.466517827552445
Validation loss: 2.4408315209984837

Epoch: 6| Step: 2
Training loss: 2.384153295286359
Validation loss: 2.452331554688542

Epoch: 6| Step: 3
Training loss: 2.7552811457357884
Validation loss: 2.4352090843440064

Epoch: 6| Step: 4
Training loss: 2.3330119002423375
Validation loss: 2.4364638859670054

Epoch: 6| Step: 5
Training loss: 1.8391305630517507
Validation loss: 2.444316718006223

Epoch: 6| Step: 6
Training loss: 2.741685261610178
Validation loss: 2.454445009265932

Epoch: 6| Step: 7
Training loss: 2.3460722544698744
Validation loss: 2.4441471273483275

Epoch: 6| Step: 8
Training loss: 1.4560910379642626
Validation loss: 2.4724895622832483

Epoch: 6| Step: 9
Training loss: 1.9513139797085466
Validation loss: 2.4736686048989336

Epoch: 6| Step: 10
Training loss: 1.9934751052048307
Validation loss: 2.5223008113974856

Epoch: 6| Step: 11
Training loss: 2.197139644825965
Validation loss: 2.5352255025233212

Epoch: 6| Step: 12
Training loss: 1.9736576975329967
Validation loss: 2.540536952865936

Epoch: 6| Step: 13
Training loss: 2.4990107486428057
Validation loss: 2.5297115486298747

Epoch: 254| Step: 0
Training loss: 2.8730332654971678
Validation loss: 2.5333970824749774

Epoch: 6| Step: 1
Training loss: 1.9865878525190792
Validation loss: 2.570209712443603

Epoch: 6| Step: 2
Training loss: 2.611961133951077
Validation loss: 2.529691261048983

Epoch: 6| Step: 3
Training loss: 2.0090356804283926
Validation loss: 2.490686323062748

Epoch: 6| Step: 4
Training loss: 2.1518985128544617
Validation loss: 2.4796162982843346

Epoch: 6| Step: 5
Training loss: 2.389725858855144
Validation loss: 2.492482844760941

Epoch: 6| Step: 6
Training loss: 2.138583469741025
Validation loss: 2.4962147553983436

Epoch: 6| Step: 7
Training loss: 2.5053957884215867
Validation loss: 2.4742315250110196

Epoch: 6| Step: 8
Training loss: 2.0160157763756965
Validation loss: 2.4912701275950417

Epoch: 6| Step: 9
Training loss: 1.9554037000235829
Validation loss: 2.491573050588151

Epoch: 6| Step: 10
Training loss: 1.7120554158965855
Validation loss: 2.509905250431773

Epoch: 6| Step: 11
Training loss: 2.010554597171638
Validation loss: 2.5328180471391186

Epoch: 6| Step: 12
Training loss: 2.66826667071753
Validation loss: 2.536607548958619

Epoch: 6| Step: 13
Training loss: 2.2757732544433438
Validation loss: 2.536928463857178

Epoch: 255| Step: 0
Training loss: 2.7156679068842267
Validation loss: 2.5161163282362926

Epoch: 6| Step: 1
Training loss: 2.21289364174
Validation loss: 2.514879194982362

Epoch: 6| Step: 2
Training loss: 2.557022007996302
Validation loss: 2.5183366893661443

Epoch: 6| Step: 3
Training loss: 2.35732073752604
Validation loss: 2.502245759812788

Epoch: 6| Step: 4
Training loss: 2.0105209191786786
Validation loss: 2.5088493026894056

Epoch: 6| Step: 5
Training loss: 2.030795941588438
Validation loss: 2.5072678135562905

Epoch: 6| Step: 6
Training loss: 2.410915656989009
Validation loss: 2.506815575235665

Epoch: 6| Step: 7
Training loss: 2.510974162604979
Validation loss: 2.484282179383404

Epoch: 6| Step: 8
Training loss: 2.162257133473002
Validation loss: 2.4656489023050576

Epoch: 6| Step: 9
Training loss: 2.0148164768747154
Validation loss: 2.459338794055071

Epoch: 6| Step: 10
Training loss: 1.6247410201062111
Validation loss: 2.4390565158372515

Epoch: 6| Step: 11
Training loss: 2.395405993842316
Validation loss: 2.4327506163567145

Epoch: 6| Step: 12
Training loss: 2.02856279300333
Validation loss: 2.4324925568009172

Epoch: 6| Step: 13
Training loss: 1.0168008892904816
Validation loss: 2.4456083722933255

Epoch: 256| Step: 0
Training loss: 2.5711444099788197
Validation loss: 2.4723277234425196

Epoch: 6| Step: 1
Training loss: 1.95928253004301
Validation loss: 2.4728445758234905

Epoch: 6| Step: 2
Training loss: 2.1776347458292165
Validation loss: 2.506147015930926

Epoch: 6| Step: 3
Training loss: 2.841212555369633
Validation loss: 2.5335508691002144

Epoch: 6| Step: 4
Training loss: 1.9098510498366765
Validation loss: 2.5308440305851194

Epoch: 6| Step: 5
Training loss: 1.8555248372485122
Validation loss: 2.5413364392225133

Epoch: 6| Step: 6
Training loss: 1.9583976072220428
Validation loss: 2.571813766389885

Epoch: 6| Step: 7
Training loss: 2.113745788172987
Validation loss: 2.5411472331086884

Epoch: 6| Step: 8
Training loss: 2.408540997467287
Validation loss: 2.5103013115060633

Epoch: 6| Step: 9
Training loss: 2.367266864516317
Validation loss: 2.4939129136579705

Epoch: 6| Step: 10
Training loss: 2.237349337827859
Validation loss: 2.4694783808258696

Epoch: 6| Step: 11
Training loss: 2.0134502181593312
Validation loss: 2.4710751372563173

Epoch: 6| Step: 12
Training loss: 1.7560529252116546
Validation loss: 2.459483461786789

Epoch: 6| Step: 13
Training loss: 2.63169470356781
Validation loss: 2.4534892160689186

Epoch: 257| Step: 0
Training loss: 1.9711240955848803
Validation loss: 2.4533401770059347

Epoch: 6| Step: 1
Training loss: 2.180930600104163
Validation loss: 2.458099964912391

Epoch: 6| Step: 2
Training loss: 2.0029177839724293
Validation loss: 2.454194779787546

Epoch: 6| Step: 3
Training loss: 2.4842574373655806
Validation loss: 2.4533910241985804

Epoch: 6| Step: 4
Training loss: 1.9814738294599594
Validation loss: 2.4510498183827214

Epoch: 6| Step: 5
Training loss: 1.6901565410412396
Validation loss: 2.461029253641037

Epoch: 6| Step: 6
Training loss: 2.1980866521636315
Validation loss: 2.475712866038326

Epoch: 6| Step: 7
Training loss: 2.2740656977803093
Validation loss: 2.476082673008646

Epoch: 6| Step: 8
Training loss: 1.7770797365725373
Validation loss: 2.484606934737446

Epoch: 6| Step: 9
Training loss: 2.730498175946814
Validation loss: 2.4825488299183256

Epoch: 6| Step: 10
Training loss: 2.4351699647587606
Validation loss: 2.4901595257024867

Epoch: 6| Step: 11
Training loss: 2.4264663981845196
Validation loss: 2.497707654193912

Epoch: 6| Step: 12
Training loss: 2.1008389159686636
Validation loss: 2.500500300809932

Epoch: 6| Step: 13
Training loss: 2.377478059653401
Validation loss: 2.5214813858448775

Epoch: 258| Step: 0
Training loss: 2.3209352010928956
Validation loss: 2.545765403358336

Epoch: 6| Step: 1
Training loss: 2.350716574968688
Validation loss: 2.5077246473363823

Epoch: 6| Step: 2
Training loss: 2.0811110533192503
Validation loss: 2.4900830371866727

Epoch: 6| Step: 3
Training loss: 2.440522300913746
Validation loss: 2.4600393432137593

Epoch: 6| Step: 4
Training loss: 1.9417968602661058
Validation loss: 2.432253544515644

Epoch: 6| Step: 5
Training loss: 2.1905761887449358
Validation loss: 2.45180887344144

Epoch: 6| Step: 6
Training loss: 2.0665264707614828
Validation loss: 2.423111429615729

Epoch: 6| Step: 7
Training loss: 2.7346097136986263
Validation loss: 2.4269521157488145

Epoch: 6| Step: 8
Training loss: 1.6540150227769697
Validation loss: 2.428724061193484

Epoch: 6| Step: 9
Training loss: 2.3731469404056793
Validation loss: 2.466880821788721

Epoch: 6| Step: 10
Training loss: 2.134807170941791
Validation loss: 2.478567287933508

Epoch: 6| Step: 11
Training loss: 2.514698308061308
Validation loss: 2.530134517617109

Epoch: 6| Step: 12
Training loss: 1.698342002844029
Validation loss: 2.5492924658724108

Epoch: 6| Step: 13
Training loss: 2.225128032986775
Validation loss: 2.5737545737655045

Epoch: 259| Step: 0
Training loss: 2.4092276838614333
Validation loss: 2.5868904081316617

Epoch: 6| Step: 1
Training loss: 2.205884787614264
Validation loss: 2.493542159822162

Epoch: 6| Step: 2
Training loss: 2.3323902767496207
Validation loss: 2.454087057698747

Epoch: 6| Step: 3
Training loss: 2.3311135996168972
Validation loss: 2.437911988246892

Epoch: 6| Step: 4
Training loss: 2.276651214986544
Validation loss: 2.4292638540117406

Epoch: 6| Step: 5
Training loss: 1.9592255190056913
Validation loss: 2.4347428693241167

Epoch: 6| Step: 6
Training loss: 2.7491978429079023
Validation loss: 2.434965001316491

Epoch: 6| Step: 7
Training loss: 1.4193901735113725
Validation loss: 2.4502380283927807

Epoch: 6| Step: 8
Training loss: 1.6917919397557388
Validation loss: 2.4852263898930413

Epoch: 6| Step: 9
Training loss: 2.46318005306472
Validation loss: 2.508455950606805

Epoch: 6| Step: 10
Training loss: 2.188887346926607
Validation loss: 2.518197002044922

Epoch: 6| Step: 11
Training loss: 1.930408852611689
Validation loss: 2.5613575191061937

Epoch: 6| Step: 12
Training loss: 2.3097613846372056
Validation loss: 2.6180293470836196

Epoch: 6| Step: 13
Training loss: 2.7847174985046994
Validation loss: 2.619055251813702

Epoch: 260| Step: 0
Training loss: 1.995113243961778
Validation loss: 2.601244085277501

Epoch: 6| Step: 1
Training loss: 1.968684119681453
Validation loss: 2.52402422795517

Epoch: 6| Step: 2
Training loss: 1.6943152522602598
Validation loss: 2.490131187287643

Epoch: 6| Step: 3
Training loss: 2.322554510193426
Validation loss: 2.454092245381841

Epoch: 6| Step: 4
Training loss: 2.166815263592087
Validation loss: 2.4658809869238567

Epoch: 6| Step: 5
Training loss: 2.3259945536817845
Validation loss: 2.4644760711251683

Epoch: 6| Step: 6
Training loss: 2.612046570191863
Validation loss: 2.473173040980396

Epoch: 6| Step: 7
Training loss: 2.4012784255021797
Validation loss: 2.4934343938771657

Epoch: 6| Step: 8
Training loss: 2.0755425950221356
Validation loss: 2.4854670806173584

Epoch: 6| Step: 9
Training loss: 2.0810801210464827
Validation loss: 2.504750603912439

Epoch: 6| Step: 10
Training loss: 2.3232775922388966
Validation loss: 2.505076446210021

Epoch: 6| Step: 11
Training loss: 2.00051038905361
Validation loss: 2.5096740039426075

Epoch: 6| Step: 12
Training loss: 2.3533211148875095
Validation loss: 2.525288147974941

Epoch: 6| Step: 13
Training loss: 2.6589968671374966
Validation loss: 2.5558208194447727

Epoch: 261| Step: 0
Training loss: 2.6273137749065993
Validation loss: 2.493594641303516

Epoch: 6| Step: 1
Training loss: 1.3438204813371077
Validation loss: 2.471143385593952

Epoch: 6| Step: 2
Training loss: 2.306058107575331
Validation loss: 2.451905842098121

Epoch: 6| Step: 3
Training loss: 2.3368565209171543
Validation loss: 2.4215187776692106

Epoch: 6| Step: 4
Training loss: 2.0954024213801117
Validation loss: 2.4183413011319814

Epoch: 6| Step: 5
Training loss: 2.033824052640643
Validation loss: 2.4122874026483405

Epoch: 6| Step: 6
Training loss: 2.1924976480225635
Validation loss: 2.4145683557435733

Epoch: 6| Step: 7
Training loss: 2.76687455909093
Validation loss: 2.41399513594274

Epoch: 6| Step: 8
Training loss: 2.2537664042810466
Validation loss: 2.4396359488054986

Epoch: 6| Step: 9
Training loss: 1.8878732627987453
Validation loss: 2.4392900333500616

Epoch: 6| Step: 10
Training loss: 2.120812497539384
Validation loss: 2.4441256381270673

Epoch: 6| Step: 11
Training loss: 2.298212816574774
Validation loss: 2.516183549490462

Epoch: 6| Step: 12
Training loss: 2.0491552100909107
Validation loss: 2.5716497580180184

Epoch: 6| Step: 13
Training loss: 2.0110695393213245
Validation loss: 2.621597495199302

Epoch: 262| Step: 0
Training loss: 2.5094117386386263
Validation loss: 2.6702572340347617

Epoch: 6| Step: 1
Training loss: 2.6176746427465583
Validation loss: 2.6137957264016234

Epoch: 6| Step: 2
Training loss: 2.2048016384110363
Validation loss: 2.550858616909962

Epoch: 6| Step: 3
Training loss: 1.6278942449838572
Validation loss: 2.50802493742586

Epoch: 6| Step: 4
Training loss: 2.3480811218597166
Validation loss: 2.4750631994500343

Epoch: 6| Step: 5
Training loss: 1.6362706847956143
Validation loss: 2.4475068331600043

Epoch: 6| Step: 6
Training loss: 2.618867704891772
Validation loss: 2.436717168249489

Epoch: 6| Step: 7
Training loss: 2.50776021076961
Validation loss: 2.4368575043168015

Epoch: 6| Step: 8
Training loss: 1.981113607242562
Validation loss: 2.433316671550692

Epoch: 6| Step: 9
Training loss: 1.920421143477818
Validation loss: 2.440266478320162

Epoch: 6| Step: 10
Training loss: 2.137615678122126
Validation loss: 2.455440343793038

Epoch: 6| Step: 11
Training loss: 2.154966995446762
Validation loss: 2.464718780930058

Epoch: 6| Step: 12
Training loss: 2.1084495492299427
Validation loss: 2.4702159101107624

Epoch: 6| Step: 13
Training loss: 2.3944520921675987
Validation loss: 2.4538227544464855

Epoch: 263| Step: 0
Training loss: 2.256691941702472
Validation loss: 2.4901466928447786

Epoch: 6| Step: 1
Training loss: 2.4324627202814604
Validation loss: 2.485657569141146

Epoch: 6| Step: 2
Training loss: 2.2170779953220654
Validation loss: 2.538545235699639

Epoch: 6| Step: 3
Training loss: 2.2775630681740733
Validation loss: 2.547079450910656

Epoch: 6| Step: 4
Training loss: 2.2600148161680966
Validation loss: 2.5451498605290146

Epoch: 6| Step: 5
Training loss: 2.172717143840839
Validation loss: 2.53765872438896

Epoch: 6| Step: 6
Training loss: 2.3331695794364093
Validation loss: 2.516896732446252

Epoch: 6| Step: 7
Training loss: 1.9988100565081943
Validation loss: 2.4916124745486252

Epoch: 6| Step: 8
Training loss: 1.555764366886595
Validation loss: 2.465079963239248

Epoch: 6| Step: 9
Training loss: 2.0342225845362893
Validation loss: 2.4590493705069076

Epoch: 6| Step: 10
Training loss: 2.4150098404772704
Validation loss: 2.4378812779369867

Epoch: 6| Step: 11
Training loss: 2.0712861848385833
Validation loss: 2.4312222584715673

Epoch: 6| Step: 12
Training loss: 1.9847098240762835
Validation loss: 2.4480642706661686

Epoch: 6| Step: 13
Training loss: 2.1214285739056478
Validation loss: 2.43172412921177

Epoch: 264| Step: 0
Training loss: 1.9498129877255592
Validation loss: 2.457750125767334

Epoch: 6| Step: 1
Training loss: 2.5196131966445896
Validation loss: 2.4815653493040197

Epoch: 6| Step: 2
Training loss: 2.0048862611468756
Validation loss: 2.494150445205873

Epoch: 6| Step: 3
Training loss: 2.1480641543506223
Validation loss: 2.474095766733016

Epoch: 6| Step: 4
Training loss: 2.4271619617567
Validation loss: 2.4861496195405266

Epoch: 6| Step: 5
Training loss: 2.106730859579213
Validation loss: 2.52205085048276

Epoch: 6| Step: 6
Training loss: 1.7677594002349812
Validation loss: 2.510960999146014

Epoch: 6| Step: 7
Training loss: 1.8962768692597414
Validation loss: 2.519098583126923

Epoch: 6| Step: 8
Training loss: 2.2167351399030415
Validation loss: 2.498535865255604

Epoch: 6| Step: 9
Training loss: 2.0667201706923297
Validation loss: 2.4890080145606963

Epoch: 6| Step: 10
Training loss: 2.0199174935893307
Validation loss: 2.480925385916217

Epoch: 6| Step: 11
Training loss: 2.242132844159091
Validation loss: 2.492789216266848

Epoch: 6| Step: 12
Training loss: 2.1063846443222154
Validation loss: 2.5011012154094048

Epoch: 6| Step: 13
Training loss: 2.463339853118954
Validation loss: 2.5347318949065096

Epoch: 265| Step: 0
Training loss: 2.0033078257523127
Validation loss: 2.5075081859223496

Epoch: 6| Step: 1
Training loss: 2.3130496634805615
Validation loss: 2.524320876963325

Epoch: 6| Step: 2
Training loss: 1.8750681546857961
Validation loss: 2.5172290654688028

Epoch: 6| Step: 3
Training loss: 2.079375844255281
Validation loss: 2.5295264046136783

Epoch: 6| Step: 4
Training loss: 2.1976512248459477
Validation loss: 2.5192378215479008

Epoch: 6| Step: 5
Training loss: 2.0908563460229854
Validation loss: 2.51266936370763

Epoch: 6| Step: 6
Training loss: 2.194757248787099
Validation loss: 2.488946176589946

Epoch: 6| Step: 7
Training loss: 1.8210594380213516
Validation loss: 2.4953117968181564

Epoch: 6| Step: 8
Training loss: 1.6293502678144596
Validation loss: 2.469882166014978

Epoch: 6| Step: 9
Training loss: 2.2415138854346166
Validation loss: 2.4709042607138203

Epoch: 6| Step: 10
Training loss: 2.7151439912383943
Validation loss: 2.4411406593818654

Epoch: 6| Step: 11
Training loss: 1.707084881880603
Validation loss: 2.4420659170534997

Epoch: 6| Step: 12
Training loss: 2.2731024111741625
Validation loss: 2.4506421718159035

Epoch: 6| Step: 13
Training loss: 2.3030471395222403
Validation loss: 2.435742033265323

Epoch: 266| Step: 0
Training loss: 2.293819237269542
Validation loss: 2.4368797524887085

Epoch: 6| Step: 1
Training loss: 2.737079786682696
Validation loss: 2.449551111610429

Epoch: 6| Step: 2
Training loss: 2.2442950933429895
Validation loss: 2.463332316232048

Epoch: 6| Step: 3
Training loss: 2.10288919881265
Validation loss: 2.4539754749380394

Epoch: 6| Step: 4
Training loss: 2.249573985141192
Validation loss: 2.4451976262819057

Epoch: 6| Step: 5
Training loss: 2.065455198017694
Validation loss: 2.4377114672521114

Epoch: 6| Step: 6
Training loss: 1.6412660345498509
Validation loss: 2.443082634932903

Epoch: 6| Step: 7
Training loss: 1.6586868784665534
Validation loss: 2.4209436325382105

Epoch: 6| Step: 8
Training loss: 1.8320211642054798
Validation loss: 2.437304909394951

Epoch: 6| Step: 9
Training loss: 1.960726297258863
Validation loss: 2.43865310365191

Epoch: 6| Step: 10
Training loss: 2.138680347443264
Validation loss: 2.4526547593315824

Epoch: 6| Step: 11
Training loss: 1.9564016703836988
Validation loss: 2.4867471576525406

Epoch: 6| Step: 12
Training loss: 2.0805485869447846
Validation loss: 2.5426068149924013

Epoch: 6| Step: 13
Training loss: 2.2326015023014323
Validation loss: 2.597921765266342

Epoch: 267| Step: 0
Training loss: 2.1346643254570847
Validation loss: 2.5950005752607415

Epoch: 6| Step: 1
Training loss: 1.9552456748728244
Validation loss: 2.5804371896127614

Epoch: 6| Step: 2
Training loss: 1.735068380234086
Validation loss: 2.5394661319251157

Epoch: 6| Step: 3
Training loss: 2.526020346220565
Validation loss: 2.4904253121063364

Epoch: 6| Step: 4
Training loss: 2.2767777172984665
Validation loss: 2.467791552339405

Epoch: 6| Step: 5
Training loss: 2.5856350724778125
Validation loss: 2.4662767651365862

Epoch: 6| Step: 6
Training loss: 2.450352943066215
Validation loss: 2.4485910712399748

Epoch: 6| Step: 7
Training loss: 1.6877130444582604
Validation loss: 2.441778276216454

Epoch: 6| Step: 8
Training loss: 2.255545775178815
Validation loss: 2.429240912919932

Epoch: 6| Step: 9
Training loss: 1.8890819715785279
Validation loss: 2.445827472496177

Epoch: 6| Step: 10
Training loss: 1.9523296109924384
Validation loss: 2.4641847655400677

Epoch: 6| Step: 11
Training loss: 1.8359824317141458
Validation loss: 2.4762992487355318

Epoch: 6| Step: 12
Training loss: 1.6319198723785098
Validation loss: 2.50427399326609

Epoch: 6| Step: 13
Training loss: 2.3160616279005612
Validation loss: 2.497130132145032

Epoch: 268| Step: 0
Training loss: 1.976603028858199
Validation loss: 2.5210322992499505

Epoch: 6| Step: 1
Training loss: 2.290674364669145
Validation loss: 2.5056664509740796

Epoch: 6| Step: 2
Training loss: 1.7620456163951042
Validation loss: 2.4730002713393757

Epoch: 6| Step: 3
Training loss: 1.6045915940847295
Validation loss: 2.460533113813302

Epoch: 6| Step: 4
Training loss: 2.183935585630079
Validation loss: 2.4387175682429554

Epoch: 6| Step: 5
Training loss: 1.8579266460955148
Validation loss: 2.4153881739968073

Epoch: 6| Step: 6
Training loss: 2.1522638821884734
Validation loss: 2.4311896720976898

Epoch: 6| Step: 7
Training loss: 2.26838169103346
Validation loss: 2.4243305525068397

Epoch: 6| Step: 8
Training loss: 2.224273468727279
Validation loss: 2.418358028111615

Epoch: 6| Step: 9
Training loss: 2.6315675956079687
Validation loss: 2.447238625218056

Epoch: 6| Step: 10
Training loss: 1.8006751966381505
Validation loss: 2.45458471612883

Epoch: 6| Step: 11
Training loss: 2.1947749555615728
Validation loss: 2.4709933519247786

Epoch: 6| Step: 12
Training loss: 1.8096894144223652
Validation loss: 2.488414439712508

Epoch: 6| Step: 13
Training loss: 2.203608899373136
Validation loss: 2.4917099226013577

Epoch: 269| Step: 0
Training loss: 1.941599968622818
Validation loss: 2.5172585103634173

Epoch: 6| Step: 1
Training loss: 2.029137319656786
Validation loss: 2.5235948212929498

Epoch: 6| Step: 2
Training loss: 2.117570793112422
Validation loss: 2.514492368202708

Epoch: 6| Step: 3
Training loss: 1.7694403012378732
Validation loss: 2.4946540350804858

Epoch: 6| Step: 4
Training loss: 1.9971295261698268
Validation loss: 2.479984627459215

Epoch: 6| Step: 5
Training loss: 2.6127389935411385
Validation loss: 2.4462812844449298

Epoch: 6| Step: 6
Training loss: 2.417341455982839
Validation loss: 2.4316255202213233

Epoch: 6| Step: 7
Training loss: 1.8554354052308069
Validation loss: 2.411688189006939

Epoch: 6| Step: 8
Training loss: 2.206363651276921
Validation loss: 2.4275115644644316

Epoch: 6| Step: 9
Training loss: 2.208504352305336
Validation loss: 2.456744385652854

Epoch: 6| Step: 10
Training loss: 1.4249677453657124
Validation loss: 2.450897606993987

Epoch: 6| Step: 11
Training loss: 2.118547966701046
Validation loss: 2.46859858920727

Epoch: 6| Step: 12
Training loss: 2.2332131092488243
Validation loss: 2.473380721342284

Epoch: 6| Step: 13
Training loss: 1.802677174298193
Validation loss: 2.4526905280937092

Epoch: 270| Step: 0
Training loss: 2.0902847537758285
Validation loss: 2.4509080282768987

Epoch: 6| Step: 1
Training loss: 2.38380986587092
Validation loss: 2.4401634038303714

Epoch: 6| Step: 2
Training loss: 2.0200167575934245
Validation loss: 2.4565513462098583

Epoch: 6| Step: 3
Training loss: 1.8771070720880596
Validation loss: 2.4247662168007795

Epoch: 6| Step: 4
Training loss: 2.706313793672677
Validation loss: 2.429321445080658

Epoch: 6| Step: 5
Training loss: 2.3021147252584857
Validation loss: 2.4319204939756003

Epoch: 6| Step: 6
Training loss: 1.5658327037220585
Validation loss: 2.4163420246614784

Epoch: 6| Step: 7
Training loss: 1.6897426820143056
Validation loss: 2.4466217335526528

Epoch: 6| Step: 8
Training loss: 2.3552956588687617
Validation loss: 2.4577927353927276

Epoch: 6| Step: 9
Training loss: 1.5886410374646465
Validation loss: 2.4795207240183768

Epoch: 6| Step: 10
Training loss: 2.0196620522497946
Validation loss: 2.5032526719213433

Epoch: 6| Step: 11
Training loss: 2.3243487153460873
Validation loss: 2.5062519797588716

Epoch: 6| Step: 12
Training loss: 1.6139922341841784
Validation loss: 2.4933026198091826

Epoch: 6| Step: 13
Training loss: 1.8897224352638347
Validation loss: 2.475129121296167

Epoch: 271| Step: 0
Training loss: 2.32515614303159
Validation loss: 2.4603744620609636

Epoch: 6| Step: 1
Training loss: 1.8823727295953874
Validation loss: 2.4233162255859755

Epoch: 6| Step: 2
Training loss: 2.1488493923347676
Validation loss: 2.4279344349715886

Epoch: 6| Step: 3
Training loss: 2.0715608108290344
Validation loss: 2.4321543783099737

Epoch: 6| Step: 4
Training loss: 1.8035955386998543
Validation loss: 2.4353954378857927

Epoch: 6| Step: 5
Training loss: 2.2445123296591496
Validation loss: 2.4250537770360467

Epoch: 6| Step: 6
Training loss: 1.6990024472825789
Validation loss: 2.438495627747572

Epoch: 6| Step: 7
Training loss: 2.2532751829593254
Validation loss: 2.46148719358413

Epoch: 6| Step: 8
Training loss: 2.2640074118368188
Validation loss: 2.493085864582824

Epoch: 6| Step: 9
Training loss: 1.9947701860537888
Validation loss: 2.51461414288684

Epoch: 6| Step: 10
Training loss: 1.6838553594916763
Validation loss: 2.5082177306383837

Epoch: 6| Step: 11
Training loss: 2.045125898295841
Validation loss: 2.4964383770814718

Epoch: 6| Step: 12
Training loss: 2.3058061374190535
Validation loss: 2.5126310353624706

Epoch: 6| Step: 13
Training loss: 1.4865773777741484
Validation loss: 2.514922557385384

Epoch: 272| Step: 0
Training loss: 1.6509487314472209
Validation loss: 2.5184007821956644

Epoch: 6| Step: 1
Training loss: 2.1082864849127643
Validation loss: 2.5078900557503947

Epoch: 6| Step: 2
Training loss: 1.8284787218933192
Validation loss: 2.523976740178045

Epoch: 6| Step: 3
Training loss: 1.9050471779095224
Validation loss: 2.501913051417662

Epoch: 6| Step: 4
Training loss: 1.904988230871656
Validation loss: 2.4715040994263107

Epoch: 6| Step: 5
Training loss: 1.941049093939411
Validation loss: 2.454733599213478

Epoch: 6| Step: 6
Training loss: 2.3927548962121397
Validation loss: 2.4254925034364634

Epoch: 6| Step: 7
Training loss: 2.113973169349597
Validation loss: 2.3981281826737253

Epoch: 6| Step: 8
Training loss: 2.3248870658108136
Validation loss: 2.4164268983265127

Epoch: 6| Step: 9
Training loss: 1.6320686653782437
Validation loss: 2.4177804451764007

Epoch: 6| Step: 10
Training loss: 2.334545524527485
Validation loss: 2.4241778732598758

Epoch: 6| Step: 11
Training loss: 2.3043795105052203
Validation loss: 2.4144654912467494

Epoch: 6| Step: 12
Training loss: 1.814529992190764
Validation loss: 2.422078780678963

Epoch: 6| Step: 13
Training loss: 1.701944344432035
Validation loss: 2.4240857860353913

Epoch: 273| Step: 0
Training loss: 0.9535774970384545
Validation loss: 2.4483802792754976

Epoch: 6| Step: 1
Training loss: 1.9098649066064375
Validation loss: 2.4501396853012687

Epoch: 6| Step: 2
Training loss: 2.6601932651896556
Validation loss: 2.4726551053767163

Epoch: 6| Step: 3
Training loss: 2.3356006596343004
Validation loss: 2.5010932172845224

Epoch: 6| Step: 4
Training loss: 1.6312179445354513
Validation loss: 2.4815949973175675

Epoch: 6| Step: 5
Training loss: 1.8725613311787357
Validation loss: 2.4771458614270663

Epoch: 6| Step: 6
Training loss: 1.9326482753942262
Validation loss: 2.4553355951619564

Epoch: 6| Step: 7
Training loss: 2.395647146758057
Validation loss: 2.4424792437972407

Epoch: 6| Step: 8
Training loss: 1.778410941196956
Validation loss: 2.441491142257268

Epoch: 6| Step: 9
Training loss: 1.75554324010293
Validation loss: 2.4452975373352728

Epoch: 6| Step: 10
Training loss: 2.257196362121668
Validation loss: 2.4528955347440493

Epoch: 6| Step: 11
Training loss: 2.5470248687272927
Validation loss: 2.4312563459473453

Epoch: 6| Step: 12
Training loss: 1.9602683091925601
Validation loss: 2.426675820304084

Epoch: 6| Step: 13
Training loss: 1.1481623936410872
Validation loss: 2.4456858680967786

Epoch: 274| Step: 0
Training loss: 1.502315958592239
Validation loss: 2.4844894981300425

Epoch: 6| Step: 1
Training loss: 1.405961452126632
Validation loss: 2.4845158924043416

Epoch: 6| Step: 2
Training loss: 2.352469741351027
Validation loss: 2.5277426101682496

Epoch: 6| Step: 3
Training loss: 2.056296527185426
Validation loss: 2.5381854871407374

Epoch: 6| Step: 4
Training loss: 2.1480345192023367
Validation loss: 2.5217176584770593

Epoch: 6| Step: 5
Training loss: 1.7072407399701623
Validation loss: 2.4667188238620534

Epoch: 6| Step: 6
Training loss: 1.9773208912251978
Validation loss: 2.4406746194566513

Epoch: 6| Step: 7
Training loss: 2.073186987754324
Validation loss: 2.420336410518855

Epoch: 6| Step: 8
Training loss: 1.9996332786041962
Validation loss: 2.4201442031690976

Epoch: 6| Step: 9
Training loss: 1.941087846339372
Validation loss: 2.4440994155144895

Epoch: 6| Step: 10
Training loss: 2.397539101004346
Validation loss: 2.4533048257781

Epoch: 6| Step: 11
Training loss: 1.831029361804024
Validation loss: 2.504952357505994

Epoch: 6| Step: 12
Training loss: 2.101383924874091
Validation loss: 2.5355978677388675

Epoch: 6| Step: 13
Training loss: 2.9466216317212064
Validation loss: 2.5541003763260806

Epoch: 275| Step: 0
Training loss: 1.977725082878934
Validation loss: 2.5300701799329555

Epoch: 6| Step: 1
Training loss: 1.50284386303643
Validation loss: 2.4740330617571376

Epoch: 6| Step: 2
Training loss: 1.4260484418947244
Validation loss: 2.4358425084472075

Epoch: 6| Step: 3
Training loss: 2.047460574188535
Validation loss: 2.4204744426203995

Epoch: 6| Step: 4
Training loss: 1.9265976233579474
Validation loss: 2.399178683327185

Epoch: 6| Step: 5
Training loss: 1.979282241926802
Validation loss: 2.3741719886371344

Epoch: 6| Step: 6
Training loss: 2.4441609459060154
Validation loss: 2.380232982212125

Epoch: 6| Step: 7
Training loss: 2.367819421603762
Validation loss: 2.373698565038436

Epoch: 6| Step: 8
Training loss: 2.167785196867882
Validation loss: 2.385516130804635

Epoch: 6| Step: 9
Training loss: 2.069899607817754
Validation loss: 2.420996434023256

Epoch: 6| Step: 10
Training loss: 2.165881992961316
Validation loss: 2.4604414640987957

Epoch: 6| Step: 11
Training loss: 1.6962142866362624
Validation loss: 2.5027708582595256

Epoch: 6| Step: 12
Training loss: 2.1848560158364037
Validation loss: 2.5074701137771918

Epoch: 6| Step: 13
Training loss: 2.513278411683391
Validation loss: 2.518589188017693

Epoch: 276| Step: 0
Training loss: 1.7710203259043176
Validation loss: 2.477993313579799

Epoch: 6| Step: 1
Training loss: 2.38547144886618
Validation loss: 2.43761217812589

Epoch: 6| Step: 2
Training loss: 2.342204487174681
Validation loss: 2.411891730250292

Epoch: 6| Step: 3
Training loss: 1.9023307157536014
Validation loss: 2.4098587696843943

Epoch: 6| Step: 4
Training loss: 2.1881789107601795
Validation loss: 2.3693665409920937

Epoch: 6| Step: 5
Training loss: 2.009630382202481
Validation loss: 2.3860762503210755

Epoch: 6| Step: 6
Training loss: 2.657558522768768
Validation loss: 2.4065255437627284

Epoch: 6| Step: 7
Training loss: 1.8472033988101926
Validation loss: 2.417193868357331

Epoch: 6| Step: 8
Training loss: 2.2307128772650007
Validation loss: 2.4292861020784953

Epoch: 6| Step: 9
Training loss: 2.1484125309273483
Validation loss: 2.4496449928833166

Epoch: 6| Step: 10
Training loss: 1.1067587937840875
Validation loss: 2.4620527332769857

Epoch: 6| Step: 11
Training loss: 1.6683977991251033
Validation loss: 2.4776111568219608

Epoch: 6| Step: 12
Training loss: 1.5044951635849038
Validation loss: 2.4647608769203053

Epoch: 6| Step: 13
Training loss: 1.8443485516907865
Validation loss: 2.468257694527745

Epoch: 277| Step: 0
Training loss: 2.1339150956772115
Validation loss: 2.4618147706247244

Epoch: 6| Step: 1
Training loss: 1.7609084606737961
Validation loss: 2.461590667628311

Epoch: 6| Step: 2
Training loss: 2.1060459570149654
Validation loss: 2.4424202678286724

Epoch: 6| Step: 3
Training loss: 2.1622106016699947
Validation loss: 2.452830426340255

Epoch: 6| Step: 4
Training loss: 2.0993304683939935
Validation loss: 2.454524498808592

Epoch: 6| Step: 5
Training loss: 1.5762326820868209
Validation loss: 2.4152437988804745

Epoch: 6| Step: 6
Training loss: 1.8819759932435103
Validation loss: 2.422431607149734

Epoch: 6| Step: 7
Training loss: 2.427801547114766
Validation loss: 2.465343766747355

Epoch: 6| Step: 8
Training loss: 1.4238935960491828
Validation loss: 2.50691843616345

Epoch: 6| Step: 9
Training loss: 1.7696673949290378
Validation loss: 2.5431171261353955

Epoch: 6| Step: 10
Training loss: 2.136249832501525
Validation loss: 2.489674940331897

Epoch: 6| Step: 11
Training loss: 2.215838604141667
Validation loss: 2.4489183544743955

Epoch: 6| Step: 12
Training loss: 1.8602181454373845
Validation loss: 2.4102436788477246

Epoch: 6| Step: 13
Training loss: 2.1777717073944154
Validation loss: 2.383317472871372

Epoch: 278| Step: 0
Training loss: 1.705797810423013
Validation loss: 2.391991714896832

Epoch: 6| Step: 1
Training loss: 2.0931224736642386
Validation loss: 2.406166743231308

Epoch: 6| Step: 2
Training loss: 1.471093519862112
Validation loss: 2.3763234434742504

Epoch: 6| Step: 3
Training loss: 2.222114698139917
Validation loss: 2.3929091475734885

Epoch: 6| Step: 4
Training loss: 2.1586956584123187
Validation loss: 2.3869832215611413

Epoch: 6| Step: 5
Training loss: 1.7858225707873379
Validation loss: 2.4115820688421215

Epoch: 6| Step: 6
Training loss: 1.316677891808155
Validation loss: 2.4471707441834467

Epoch: 6| Step: 7
Training loss: 1.7776808199006442
Validation loss: 2.507133711224164

Epoch: 6| Step: 8
Training loss: 1.9114055019911376
Validation loss: 2.571601801391753

Epoch: 6| Step: 9
Training loss: 1.75787109277347
Validation loss: 2.6194182046788503

Epoch: 6| Step: 10
Training loss: 2.4626559600239344
Validation loss: 2.577252638348905

Epoch: 6| Step: 11
Training loss: 2.2600624990682943
Validation loss: 2.533522830858588

Epoch: 6| Step: 12
Training loss: 2.735205388002313
Validation loss: 2.4919735108173566

Epoch: 6| Step: 13
Training loss: 2.267727422276135
Validation loss: 2.4470068133269756

Epoch: 279| Step: 0
Training loss: 2.273758488702683
Validation loss: 2.4266225349311648

Epoch: 6| Step: 1
Training loss: 1.6445206666728192
Validation loss: 2.418097627895388

Epoch: 6| Step: 2
Training loss: 1.9942548608891628
Validation loss: 2.4119457226389796

Epoch: 6| Step: 3
Training loss: 1.9770586800788432
Validation loss: 2.430989356953007

Epoch: 6| Step: 4
Training loss: 2.2811663886646754
Validation loss: 2.4000316443459306

Epoch: 6| Step: 5
Training loss: 2.3181158386197542
Validation loss: 2.4311868619071393

Epoch: 6| Step: 6
Training loss: 2.0110209319525296
Validation loss: 2.4783313030107688

Epoch: 6| Step: 7
Training loss: 2.3703583986368564
Validation loss: 2.511939104408236

Epoch: 6| Step: 8
Training loss: 1.803368883481768
Validation loss: 2.5312283635401625

Epoch: 6| Step: 9
Training loss: 1.7757183985196145
Validation loss: 2.543915911456124

Epoch: 6| Step: 10
Training loss: 1.619720391998074
Validation loss: 2.516656163772391

Epoch: 6| Step: 11
Training loss: 1.4065229786725835
Validation loss: 2.5176513638819515

Epoch: 6| Step: 12
Training loss: 2.1670788837434367
Validation loss: 2.5191270475244436

Epoch: 6| Step: 13
Training loss: 2.0778868115671196
Validation loss: 2.493528756289897

Epoch: 280| Step: 0
Training loss: 1.4057034596027398
Validation loss: 2.4388452041048274

Epoch: 6| Step: 1
Training loss: 1.4563161613922895
Validation loss: 2.4054572657790882

Epoch: 6| Step: 2
Training loss: 1.9578205275922813
Validation loss: 2.395813842808296

Epoch: 6| Step: 3
Training loss: 1.8835502223931009
Validation loss: 2.374735890930466

Epoch: 6| Step: 4
Training loss: 2.1243647579564606
Validation loss: 2.383535849929954

Epoch: 6| Step: 5
Training loss: 2.060015482427692
Validation loss: 2.368288323326854

Epoch: 6| Step: 6
Training loss: 2.0539414824681157
Validation loss: 2.3856935069537215

Epoch: 6| Step: 7
Training loss: 2.186804960731363
Validation loss: 2.407635840921393

Epoch: 6| Step: 8
Training loss: 1.7929366364439254
Validation loss: 2.3848051032440862

Epoch: 6| Step: 9
Training loss: 1.7243486943991633
Validation loss: 2.4031808737387537

Epoch: 6| Step: 10
Training loss: 2.4649834207901904
Validation loss: 2.445772504845842

Epoch: 6| Step: 11
Training loss: 1.9646375180077613
Validation loss: 2.4852777946998956

Epoch: 6| Step: 12
Training loss: 2.3847634255338956
Validation loss: 2.535360058395808

Epoch: 6| Step: 13
Training loss: 1.6994646267196365
Validation loss: 2.568697057208904

Epoch: 281| Step: 0
Training loss: 1.9002815991577175
Validation loss: 2.6152665188966493

Epoch: 6| Step: 1
Training loss: 2.2887722000553787
Validation loss: 2.6418043205606567

Epoch: 6| Step: 2
Training loss: 2.4567977721566594
Validation loss: 2.5962589166752856

Epoch: 6| Step: 3
Training loss: 1.6968967752482111
Validation loss: 2.549977021794439

Epoch: 6| Step: 4
Training loss: 1.5858060284320403
Validation loss: 2.4902450372772083

Epoch: 6| Step: 5
Training loss: 2.154238218475598
Validation loss: 2.4505837730901785

Epoch: 6| Step: 6
Training loss: 1.8695701815054226
Validation loss: 2.4263016527600962

Epoch: 6| Step: 7
Training loss: 2.0067546744495934
Validation loss: 2.4473439660504965

Epoch: 6| Step: 8
Training loss: 1.6827825375353862
Validation loss: 2.395777717647475

Epoch: 6| Step: 9
Training loss: 2.0131041857861183
Validation loss: 2.4128823248734097

Epoch: 6| Step: 10
Training loss: 1.849566965714635
Validation loss: 2.4290037881052995

Epoch: 6| Step: 11
Training loss: 1.8672648776952137
Validation loss: 2.436189944687645

Epoch: 6| Step: 12
Training loss: 1.7204701918725085
Validation loss: 2.447536218141356

Epoch: 6| Step: 13
Training loss: 2.3013396176568808
Validation loss: 2.44852842717072

Epoch: 282| Step: 0
Training loss: 1.978028308017847
Validation loss: 2.4316148623713527

Epoch: 6| Step: 1
Training loss: 2.6145255600421597
Validation loss: 2.428429118282831

Epoch: 6| Step: 2
Training loss: 1.5555250509238074
Validation loss: 2.446520487884661

Epoch: 6| Step: 3
Training loss: 1.7329757131997792
Validation loss: 2.44251686243276

Epoch: 6| Step: 4
Training loss: 1.2877824843791243
Validation loss: 2.4186913133646235

Epoch: 6| Step: 5
Training loss: 2.108308649735334
Validation loss: 2.4057611225325517

Epoch: 6| Step: 6
Training loss: 1.8444268228973448
Validation loss: 2.4124805377606817

Epoch: 6| Step: 7
Training loss: 1.860087282327358
Validation loss: 2.4135097719533842

Epoch: 6| Step: 8
Training loss: 1.6887435569612037
Validation loss: 2.4189372684716064

Epoch: 6| Step: 9
Training loss: 2.126590806490979
Validation loss: 2.404780748628848

Epoch: 6| Step: 10
Training loss: 1.8309515595958363
Validation loss: 2.4365055042221497

Epoch: 6| Step: 11
Training loss: 2.1353092321646936
Validation loss: 2.460834655852484

Epoch: 6| Step: 12
Training loss: 1.9928729504955947
Validation loss: 2.444946313015241

Epoch: 6| Step: 13
Training loss: 2.132630504626316
Validation loss: 2.444704386619303

Epoch: 283| Step: 0
Training loss: 1.7939670418143385
Validation loss: 2.4173815740872255

Epoch: 6| Step: 1
Training loss: 2.3979585150661027
Validation loss: 2.3911291876674245

Epoch: 6| Step: 2
Training loss: 2.0719521992888
Validation loss: 2.390562144201205

Epoch: 6| Step: 3
Training loss: 1.7275990960368084
Validation loss: 2.3617088348681063

Epoch: 6| Step: 4
Training loss: 2.4516373515326806
Validation loss: 2.3702010724102296

Epoch: 6| Step: 5
Training loss: 1.8568512273632216
Validation loss: 2.3913338800725144

Epoch: 6| Step: 6
Training loss: 1.9530590809188468
Validation loss: 2.3869143701694133

Epoch: 6| Step: 7
Training loss: 1.887180943080517
Validation loss: 2.3952070743660614

Epoch: 6| Step: 8
Training loss: 2.0392109900883644
Validation loss: 2.4087566375721856

Epoch: 6| Step: 9
Training loss: 1.8304813555528867
Validation loss: 2.4821953504627907

Epoch: 6| Step: 10
Training loss: 1.9683659496829693
Validation loss: 2.5376350897483406

Epoch: 6| Step: 11
Training loss: 2.1068470818891543
Validation loss: 2.6097127248726237

Epoch: 6| Step: 12
Training loss: 1.437360176252158
Validation loss: 2.631088516657902

Epoch: 6| Step: 13
Training loss: 1.5827648581200726
Validation loss: 2.6149790213223834

Epoch: 284| Step: 0
Training loss: 2.239259090165357
Validation loss: 2.5970907568655246

Epoch: 6| Step: 1
Training loss: 1.926463905651765
Validation loss: 2.574818463312564

Epoch: 6| Step: 2
Training loss: 1.8659177157545166
Validation loss: 2.528528057774055

Epoch: 6| Step: 3
Training loss: 1.9002017390914618
Validation loss: 2.4903665543634887

Epoch: 6| Step: 4
Training loss: 2.0015204134111433
Validation loss: 2.451119598039077

Epoch: 6| Step: 5
Training loss: 1.468958900692122
Validation loss: 2.413324073427463

Epoch: 6| Step: 6
Training loss: 1.7229554485244527
Validation loss: 2.4311882622576584

Epoch: 6| Step: 7
Training loss: 1.931842419273387
Validation loss: 2.430971043804488

Epoch: 6| Step: 8
Training loss: 2.025792699061361
Validation loss: 2.421312613130434

Epoch: 6| Step: 9
Training loss: 2.183845300805797
Validation loss: 2.419408977442878

Epoch: 6| Step: 10
Training loss: 2.3273996336836107
Validation loss: 2.428141684329736

Epoch: 6| Step: 11
Training loss: 1.8280593990717107
Validation loss: 2.4178401960492715

Epoch: 6| Step: 12
Training loss: 1.7986493845058238
Validation loss: 2.438729451785901

Epoch: 6| Step: 13
Training loss: 1.4561564501400754
Validation loss: 2.4290191973173965

Epoch: 285| Step: 0
Training loss: 1.8924564287015146
Validation loss: 2.43458345515283

Epoch: 6| Step: 1
Training loss: 2.657904704186067
Validation loss: 2.4213919600809826

Epoch: 6| Step: 2
Training loss: 1.685691005162712
Validation loss: 2.4279908306541795

Epoch: 6| Step: 3
Training loss: 1.9040624855751476
Validation loss: 2.431517806206767

Epoch: 6| Step: 4
Training loss: 1.6433655147741557
Validation loss: 2.449547061359175

Epoch: 6| Step: 5
Training loss: 1.5706675113946644
Validation loss: 2.4517631489276943

Epoch: 6| Step: 6
Training loss: 1.8842006014310433
Validation loss: 2.489569144754082

Epoch: 6| Step: 7
Training loss: 1.7978022297685694
Validation loss: 2.4871443631061174

Epoch: 6| Step: 8
Training loss: 2.1226207652967695
Validation loss: 2.4752516197144114

Epoch: 6| Step: 9
Training loss: 1.454309124604266
Validation loss: 2.4596037428170328

Epoch: 6| Step: 10
Training loss: 1.6939233810815446
Validation loss: 2.431550529462503

Epoch: 6| Step: 11
Training loss: 2.014885108644559
Validation loss: 2.399663246065046

Epoch: 6| Step: 12
Training loss: 2.187774205051801
Validation loss: 2.40593023829747

Epoch: 6| Step: 13
Training loss: 2.089082211934278
Validation loss: 2.411748112074596

Epoch: 286| Step: 0
Training loss: 1.7563499639441331
Validation loss: 2.393613972077815

Epoch: 6| Step: 1
Training loss: 2.3630703918717524
Validation loss: 2.396897013960594

Epoch: 6| Step: 2
Training loss: 1.4143496901421688
Validation loss: 2.410770304729402

Epoch: 6| Step: 3
Training loss: 2.2724359672430214
Validation loss: 2.4110758800250367

Epoch: 6| Step: 4
Training loss: 1.8372204782063506
Validation loss: 2.4419999860821147

Epoch: 6| Step: 5
Training loss: 1.8366118795504827
Validation loss: 2.438739062018186

Epoch: 6| Step: 6
Training loss: 1.6749345111855132
Validation loss: 2.468151721499694

Epoch: 6| Step: 7
Training loss: 2.2560759205116634
Validation loss: 2.485332723108932

Epoch: 6| Step: 8
Training loss: 1.3591521069424912
Validation loss: 2.4590327295354917

Epoch: 6| Step: 9
Training loss: 1.569888233167008
Validation loss: 2.44372041594826

Epoch: 6| Step: 10
Training loss: 2.28155076643964
Validation loss: 2.4360930360707136

Epoch: 6| Step: 11
Training loss: 1.917493959539217
Validation loss: 2.4405790653879516

Epoch: 6| Step: 12
Training loss: 1.518690882030627
Validation loss: 2.4558319733876957

Epoch: 6| Step: 13
Training loss: 2.34851820065335
Validation loss: 2.4577317621991566

Epoch: 287| Step: 0
Training loss: 2.1486257019840758
Validation loss: 2.4413976583350165

Epoch: 6| Step: 1
Training loss: 1.6964562420990443
Validation loss: 2.4564191120689203

Epoch: 6| Step: 2
Training loss: 1.4467283170428857
Validation loss: 2.437548560917473

Epoch: 6| Step: 3
Training loss: 1.39234320971787
Validation loss: 2.4456773538359813

Epoch: 6| Step: 4
Training loss: 2.094057999916177
Validation loss: 2.453128135150876

Epoch: 6| Step: 5
Training loss: 1.4766793179597966
Validation loss: 2.4623358651447482

Epoch: 6| Step: 6
Training loss: 2.214160093796172
Validation loss: 2.4736070887252635

Epoch: 6| Step: 7
Training loss: 2.0133411568790707
Validation loss: 2.481172516100844

Epoch: 6| Step: 8
Training loss: 1.155237837409802
Validation loss: 2.4918858291582975

Epoch: 6| Step: 9
Training loss: 1.9735118256961928
Validation loss: 2.5258438917569253

Epoch: 6| Step: 10
Training loss: 2.16333943209893
Validation loss: 2.529909451177661

Epoch: 6| Step: 11
Training loss: 2.207654368791056
Validation loss: 2.481835522704

Epoch: 6| Step: 12
Training loss: 1.9998251123258044
Validation loss: 2.41796937342431

Epoch: 6| Step: 13
Training loss: 2.132826361419013
Validation loss: 2.4208294408747615

Epoch: 288| Step: 0
Training loss: 1.902135818052592
Validation loss: 2.409217388214353

Epoch: 6| Step: 1
Training loss: 1.5879419747808785
Validation loss: 2.4061170567114076

Epoch: 6| Step: 2
Training loss: 2.02333369044008
Validation loss: 2.4057848432414266

Epoch: 6| Step: 3
Training loss: 1.9388533142030038
Validation loss: 2.42243709544721

Epoch: 6| Step: 4
Training loss: 1.6573487002447254
Validation loss: 2.4104473755693054

Epoch: 6| Step: 5
Training loss: 1.8197552396916608
Validation loss: 2.4308058691167207

Epoch: 6| Step: 6
Training loss: 1.7585213143383216
Validation loss: 2.4494605989331055

Epoch: 6| Step: 7
Training loss: 1.7406480085677387
Validation loss: 2.496807135034793

Epoch: 6| Step: 8
Training loss: 1.6380247309102163
Validation loss: 2.5399509558522206

Epoch: 6| Step: 9
Training loss: 2.6564537418989853
Validation loss: 2.6195095809609326

Epoch: 6| Step: 10
Training loss: 2.0681870400422873
Validation loss: 2.5912735581306947

Epoch: 6| Step: 11
Training loss: 1.647412600709834
Validation loss: 2.5156753372968024

Epoch: 6| Step: 12
Training loss: 2.2896073770229624
Validation loss: 2.4466211446728146

Epoch: 6| Step: 13
Training loss: 2.2660883988648206
Validation loss: 2.4166774926316177

Epoch: 289| Step: 0
Training loss: 2.1856628332662464
Validation loss: 2.4096431228828448

Epoch: 6| Step: 1
Training loss: 1.5171878268617696
Validation loss: 2.393142251031609

Epoch: 6| Step: 2
Training loss: 1.7849182370904682
Validation loss: 2.3943251011999354

Epoch: 6| Step: 3
Training loss: 1.3950527722621249
Validation loss: 2.4050547493577636

Epoch: 6| Step: 4
Training loss: 2.238036137286558
Validation loss: 2.425083720566941

Epoch: 6| Step: 5
Training loss: 1.8863240652540312
Validation loss: 2.4172370157699112

Epoch: 6| Step: 6
Training loss: 1.767580013379516
Validation loss: 2.427740136423842

Epoch: 6| Step: 7
Training loss: 2.120371208980468
Validation loss: 2.4257297479687767

Epoch: 6| Step: 8
Training loss: 1.841202543932914
Validation loss: 2.4180872666455695

Epoch: 6| Step: 9
Training loss: 1.891411546765127
Validation loss: 2.441581733024646

Epoch: 6| Step: 10
Training loss: 1.731062741945749
Validation loss: 2.4408900044326343

Epoch: 6| Step: 11
Training loss: 1.8193287298988334
Validation loss: 2.4551773081928405

Epoch: 6| Step: 12
Training loss: 1.7733532049504568
Validation loss: 2.451619148178976

Epoch: 6| Step: 13
Training loss: 1.8441466211998405
Validation loss: 2.4528583501609376

Epoch: 290| Step: 0
Training loss: 2.1481258651824886
Validation loss: 2.497063888684055

Epoch: 6| Step: 1
Training loss: 1.6913142014051545
Validation loss: 2.5252301902628496

Epoch: 6| Step: 2
Training loss: 2.1340196707479433
Validation loss: 2.5228520145320634

Epoch: 6| Step: 3
Training loss: 1.6281382261826325
Validation loss: 2.5394474194023133

Epoch: 6| Step: 4
Training loss: 1.5267595896003554
Validation loss: 2.516507743338277

Epoch: 6| Step: 5
Training loss: 1.8343160408591797
Validation loss: 2.490689229778404

Epoch: 6| Step: 6
Training loss: 2.0737370795640153
Validation loss: 2.4792002731393508

Epoch: 6| Step: 7
Training loss: 2.043052306937303
Validation loss: 2.432478615572028

Epoch: 6| Step: 8
Training loss: 1.966885001245314
Validation loss: 2.4330257467337395

Epoch: 6| Step: 9
Training loss: 1.3821831256918844
Validation loss: 2.421769903140794

Epoch: 6| Step: 10
Training loss: 2.0446280456882233
Validation loss: 2.4135026243695705

Epoch: 6| Step: 11
Training loss: 1.885404583240659
Validation loss: 2.423931060707675

Epoch: 6| Step: 12
Training loss: 1.6312023053559406
Validation loss: 2.4138626093929667

Epoch: 6| Step: 13
Training loss: 1.6091280256966116
Validation loss: 2.4122130297105295

Epoch: 291| Step: 0
Training loss: 1.8498583326998206
Validation loss: 2.3747420438045306

Epoch: 6| Step: 1
Training loss: 1.849504187874901
Validation loss: 2.3880386345613247

Epoch: 6| Step: 2
Training loss: 2.0677312918540696
Validation loss: 2.363046158850725

Epoch: 6| Step: 3
Training loss: 1.1465583010596896
Validation loss: 2.355974605936176

Epoch: 6| Step: 4
Training loss: 1.826059201278394
Validation loss: 2.367778521676029

Epoch: 6| Step: 5
Training loss: 1.923125565720637
Validation loss: 2.361253241383675

Epoch: 6| Step: 6
Training loss: 1.9271649386336533
Validation loss: 2.364795052111646

Epoch: 6| Step: 7
Training loss: 2.0829350154297703
Validation loss: 2.3846458360696197

Epoch: 6| Step: 8
Training loss: 1.8548512284497096
Validation loss: 2.3940630817465496

Epoch: 6| Step: 9
Training loss: 1.8849341124496546
Validation loss: 2.4426859056056394

Epoch: 6| Step: 10
Training loss: 1.6732258553329589
Validation loss: 2.497239802050056

Epoch: 6| Step: 11
Training loss: 1.8261478524489485
Validation loss: 2.4809702634874786

Epoch: 6| Step: 12
Training loss: 2.1311739821315054
Validation loss: 2.513875053160859

Epoch: 6| Step: 13
Training loss: 1.0276183714982892
Validation loss: 2.5123308560213258

Epoch: 292| Step: 0
Training loss: 1.7001767319086303
Validation loss: 2.521279306674323

Epoch: 6| Step: 1
Training loss: 1.2892308443135791
Validation loss: 2.496988082917099

Epoch: 6| Step: 2
Training loss: 1.8664223607590686
Validation loss: 2.4763905734769467

Epoch: 6| Step: 3
Training loss: 1.4315224633887675
Validation loss: 2.45248512067284

Epoch: 6| Step: 4
Training loss: 1.539819057040168
Validation loss: 2.439223261164011

Epoch: 6| Step: 5
Training loss: 1.6005675411970954
Validation loss: 2.4300467289524548

Epoch: 6| Step: 6
Training loss: 1.2184034979811993
Validation loss: 2.427187880439778

Epoch: 6| Step: 7
Training loss: 1.8573974864493752
Validation loss: 2.433297286003326

Epoch: 6| Step: 8
Training loss: 2.5034801102677258
Validation loss: 2.4397812090047024

Epoch: 6| Step: 9
Training loss: 1.9506975882437618
Validation loss: 2.42087505867224

Epoch: 6| Step: 10
Training loss: 2.047805807451116
Validation loss: 2.447018598993334

Epoch: 6| Step: 11
Training loss: 2.443039297580267
Validation loss: 2.4406092890247586

Epoch: 6| Step: 12
Training loss: 1.298657857877425
Validation loss: 2.4587958769587743

Epoch: 6| Step: 13
Training loss: 2.4937545967537718
Validation loss: 2.5025886187808264

Epoch: 293| Step: 0
Training loss: 1.6978860473992368
Validation loss: 2.5010099719218997

Epoch: 6| Step: 1
Training loss: 2.149049761835499
Validation loss: 2.449449116500056

Epoch: 6| Step: 2
Training loss: 1.9133000937951752
Validation loss: 2.43597254763518

Epoch: 6| Step: 3
Training loss: 1.785117718637603
Validation loss: 2.3893593286140145

Epoch: 6| Step: 4
Training loss: 1.9531240234372558
Validation loss: 2.3987094951658188

Epoch: 6| Step: 5
Training loss: 2.1008435689436458
Validation loss: 2.391633099146078

Epoch: 6| Step: 6
Training loss: 2.0822998789678944
Validation loss: 2.404280604661164

Epoch: 6| Step: 7
Training loss: 1.350691012737989
Validation loss: 2.3849215873451364

Epoch: 6| Step: 8
Training loss: 1.599694553664481
Validation loss: 2.4103172063552956

Epoch: 6| Step: 9
Training loss: 1.706179687951634
Validation loss: 2.424048431314244

Epoch: 6| Step: 10
Training loss: 1.9599248087337158
Validation loss: 2.446390315387864

Epoch: 6| Step: 11
Training loss: 1.9994560932624346
Validation loss: 2.485484325407856

Epoch: 6| Step: 12
Training loss: 1.0685607608768295
Validation loss: 2.517761201918751

Epoch: 6| Step: 13
Training loss: 1.9060517505052816
Validation loss: 2.5306296753816553

Epoch: 294| Step: 0
Training loss: 2.336638992769687
Validation loss: 2.51231653025949

Epoch: 6| Step: 1
Training loss: 2.1085016773950835
Validation loss: 2.502752075215693

Epoch: 6| Step: 2
Training loss: 1.7362310427460874
Validation loss: 2.4797338214591713

Epoch: 6| Step: 3
Training loss: 1.543710650973437
Validation loss: 2.446483038481877

Epoch: 6| Step: 4
Training loss: 1.7961198629809827
Validation loss: 2.410764197549971

Epoch: 6| Step: 5
Training loss: 1.9209650257944098
Validation loss: 2.425238150373096

Epoch: 6| Step: 6
Training loss: 1.614960542320825
Validation loss: 2.4027808903417474

Epoch: 6| Step: 7
Training loss: 1.8723386314543056
Validation loss: 2.4148898659735867

Epoch: 6| Step: 8
Training loss: 1.8115467327090455
Validation loss: 2.416627819596292

Epoch: 6| Step: 9
Training loss: 1.4948126584305879
Validation loss: 2.4226109799896056

Epoch: 6| Step: 10
Training loss: 2.1590898030109402
Validation loss: 2.4652835470553143

Epoch: 6| Step: 11
Training loss: 1.1645028734249503
Validation loss: 2.491237674759599

Epoch: 6| Step: 12
Training loss: 1.7373077066619353
Validation loss: 2.502321567150026

Epoch: 6| Step: 13
Training loss: 1.9363862805216778
Validation loss: 2.5196142690618393

Epoch: 295| Step: 0
Training loss: 1.5418123571615467
Validation loss: 2.4671588088166923

Epoch: 6| Step: 1
Training loss: 1.560874704008547
Validation loss: 2.423287805834089

Epoch: 6| Step: 2
Training loss: 1.9600688940707631
Validation loss: 2.399878359261987

Epoch: 6| Step: 3
Training loss: 1.6160160558016257
Validation loss: 2.3662131054565756

Epoch: 6| Step: 4
Training loss: 2.6293449772634343
Validation loss: 2.371021054545161

Epoch: 6| Step: 5
Training loss: 1.9199830954522776
Validation loss: 2.385238789855944

Epoch: 6| Step: 6
Training loss: 1.403448832977276
Validation loss: 2.3974969057745397

Epoch: 6| Step: 7
Training loss: 1.7776533255461244
Validation loss: 2.41329896828931

Epoch: 6| Step: 8
Training loss: 1.690190889536596
Validation loss: 2.4298552401243976

Epoch: 6| Step: 9
Training loss: 1.399012655120502
Validation loss: 2.433099287506694

Epoch: 6| Step: 10
Training loss: 2.048033641166356
Validation loss: 2.4559252168552597

Epoch: 6| Step: 11
Training loss: 1.641019210684386
Validation loss: 2.46559829958435

Epoch: 6| Step: 12
Training loss: 1.96410020596311
Validation loss: 2.504306052465723

Epoch: 6| Step: 13
Training loss: 1.5847759785265765
Validation loss: 2.5330653353525485

Epoch: 296| Step: 0
Training loss: 1.6427588255707162
Validation loss: 2.537982807411722

Epoch: 6| Step: 1
Training loss: 1.771872750201807
Validation loss: 2.5468729586492103

Epoch: 6| Step: 2
Training loss: 1.50054715032074
Validation loss: 2.555861904436194

Epoch: 6| Step: 3
Training loss: 2.028299742049338
Validation loss: 2.5385321980412474

Epoch: 6| Step: 4
Training loss: 2.081295491772436
Validation loss: 2.4761763818035014

Epoch: 6| Step: 5
Training loss: 1.7229499134083293
Validation loss: 2.44135077011895

Epoch: 6| Step: 6
Training loss: 2.010877829780136
Validation loss: 2.4153954996188434

Epoch: 6| Step: 7
Training loss: 1.6167504646108304
Validation loss: 2.4151947772873323

Epoch: 6| Step: 8
Training loss: 1.8462803175289433
Validation loss: 2.3960091435867437

Epoch: 6| Step: 9
Training loss: 1.6534101503482608
Validation loss: 2.4126481066593235

Epoch: 6| Step: 10
Training loss: 1.9053263067890516
Validation loss: 2.4231145739758815

Epoch: 6| Step: 11
Training loss: 1.8270071149331515
Validation loss: 2.43358581970426

Epoch: 6| Step: 12
Training loss: 1.8588320155670786
Validation loss: 2.461988656336398

Epoch: 6| Step: 13
Training loss: 1.4254157447012816
Validation loss: 2.4241975257875072

Epoch: 297| Step: 0
Training loss: 1.761634097211764
Validation loss: 2.452464090761996

Epoch: 6| Step: 1
Training loss: 1.6901489941530372
Validation loss: 2.414056233359006

Epoch: 6| Step: 2
Training loss: 1.9181954119782858
Validation loss: 2.386840792218785

Epoch: 6| Step: 3
Training loss: 1.6255734238881416
Validation loss: 2.372443709748066

Epoch: 6| Step: 4
Training loss: 1.689827761704516
Validation loss: 2.3703510084532535

Epoch: 6| Step: 5
Training loss: 1.6339327970713664
Validation loss: 2.3886412024087194

Epoch: 6| Step: 6
Training loss: 1.9619545293938225
Validation loss: 2.4321775264475183

Epoch: 6| Step: 7
Training loss: 1.3071964376145409
Validation loss: 2.4711404289139693

Epoch: 6| Step: 8
Training loss: 1.2756163322905603
Validation loss: 2.469158086956986

Epoch: 6| Step: 9
Training loss: 1.5113954814494535
Validation loss: 2.5036708041569837

Epoch: 6| Step: 10
Training loss: 1.7672955872039797
Validation loss: 2.492255820295426

Epoch: 6| Step: 11
Training loss: 2.4920336636983578
Validation loss: 2.5194174494492203

Epoch: 6| Step: 12
Training loss: 1.883009967500031
Validation loss: 2.5276259854484255

Epoch: 6| Step: 13
Training loss: 2.440752646885048
Validation loss: 2.475034447881144

Epoch: 298| Step: 0
Training loss: 1.7256698026716417
Validation loss: 2.4337573139605713

Epoch: 6| Step: 1
Training loss: 2.016329619981211
Validation loss: 2.4090872493789903

Epoch: 6| Step: 2
Training loss: 1.6747293794566582
Validation loss: 2.378820005848174

Epoch: 6| Step: 3
Training loss: 1.9436426310921155
Validation loss: 2.358034496998103

Epoch: 6| Step: 4
Training loss: 2.066843257045472
Validation loss: 2.3910767028430224

Epoch: 6| Step: 5
Training loss: 1.591644991316012
Validation loss: 2.3833886159997593

Epoch: 6| Step: 6
Training loss: 1.9881675103111929
Validation loss: 2.3803610712413072

Epoch: 6| Step: 7
Training loss: 1.8228561899961688
Validation loss: 2.3955187540639815

Epoch: 6| Step: 8
Training loss: 1.9702123025076548
Validation loss: 2.3893223955671834

Epoch: 6| Step: 9
Training loss: 1.368447208444149
Validation loss: 2.4305493719097493

Epoch: 6| Step: 10
Training loss: 1.5881360979829635
Validation loss: 2.437172516688869

Epoch: 6| Step: 11
Training loss: 1.4772252608723062
Validation loss: 2.4582946952284828

Epoch: 6| Step: 12
Training loss: 1.5662133913868885
Validation loss: 2.489274435762212

Epoch: 6| Step: 13
Training loss: 1.6905509072248677
Validation loss: 2.519564636217858

Epoch: 299| Step: 0
Training loss: 1.9458080717593973
Validation loss: 2.5292524231158393

Epoch: 6| Step: 1
Training loss: 1.3771709296932917
Validation loss: 2.5360509892318728

Epoch: 6| Step: 2
Training loss: 1.9620033802077237
Validation loss: 2.4799445560468634

Epoch: 6| Step: 3
Training loss: 1.2329391143721737
Validation loss: 2.4650025654680654

Epoch: 6| Step: 4
Training loss: 1.6373758749472813
Validation loss: 2.417843353626368

Epoch: 6| Step: 5
Training loss: 2.0741208155728956
Validation loss: 2.404509885899221

Epoch: 6| Step: 6
Training loss: 1.717076544609001
Validation loss: 2.374175016405886

Epoch: 6| Step: 7
Training loss: 2.0724549921576205
Validation loss: 2.367311030208956

Epoch: 6| Step: 8
Training loss: 1.817296160846497
Validation loss: 2.366074118195161

Epoch: 6| Step: 9
Training loss: 2.007317270439963
Validation loss: 2.357294553088169

Epoch: 6| Step: 10
Training loss: 1.682713324866197
Validation loss: 2.3458415050870975

Epoch: 6| Step: 11
Training loss: 1.6167312199528376
Validation loss: 2.3665497906827513

Epoch: 6| Step: 12
Training loss: 1.5673802265847048
Validation loss: 2.4109491532593683

Epoch: 6| Step: 13
Training loss: 1.9933974238312735
Validation loss: 2.481233136957768

Epoch: 300| Step: 0
Training loss: 1.9852536276301516
Validation loss: 2.571500739738059

Epoch: 6| Step: 1
Training loss: 1.9634932926064386
Validation loss: 2.6367339885701258

Epoch: 6| Step: 2
Training loss: 1.3775073511997142
Validation loss: 2.6554431044407236

Epoch: 6| Step: 3
Training loss: 1.6473896619464272
Validation loss: 2.6511170121728127

Epoch: 6| Step: 4
Training loss: 2.121635241439321
Validation loss: 2.591563111248916

Epoch: 6| Step: 5
Training loss: 1.915596359063713
Validation loss: 2.5345610335043256

Epoch: 6| Step: 6
Training loss: 1.6289579168308517
Validation loss: 2.4160557566308545

Epoch: 6| Step: 7
Training loss: 2.0882188986772254
Validation loss: 2.3840165486407288

Epoch: 6| Step: 8
Training loss: 1.399147237188784
Validation loss: 2.3581345112765777

Epoch: 6| Step: 9
Training loss: 1.8443482285162436
Validation loss: 2.3272737668946846

Epoch: 6| Step: 10
Training loss: 1.9059667533184437
Validation loss: 2.331916622541577

Epoch: 6| Step: 11
Training loss: 1.4170062368736227
Validation loss: 2.3489411736358536

Epoch: 6| Step: 12
Training loss: 1.6779627261562973
Validation loss: 2.3840047348696287

Epoch: 6| Step: 13
Training loss: 1.8213535328108446
Validation loss: 2.3944062943095985

Epoch: 301| Step: 0
Training loss: 1.5397073392091203
Validation loss: 2.424152726654216

Epoch: 6| Step: 1
Training loss: 1.3219156858707546
Validation loss: 2.4772275854133086

Epoch: 6| Step: 2
Training loss: 1.7204901469269178
Validation loss: 2.4796405381406283

Epoch: 6| Step: 3
Training loss: 1.4472644718386938
Validation loss: 2.5328124984210123

Epoch: 6| Step: 4
Training loss: 1.6391378292668803
Validation loss: 2.5302634099665053

Epoch: 6| Step: 5
Training loss: 1.8136962363163722
Validation loss: 2.511969400211671

Epoch: 6| Step: 6
Training loss: 1.9529732607072103
Validation loss: 2.4714331033643995

Epoch: 6| Step: 7
Training loss: 1.8900660799978457
Validation loss: 2.4238903011270567

Epoch: 6| Step: 8
Training loss: 1.8976678112144287
Validation loss: 2.4058387835398434

Epoch: 6| Step: 9
Training loss: 1.896214066166846
Validation loss: 2.3795450095476163

Epoch: 6| Step: 10
Training loss: 1.981079308410329
Validation loss: 2.3588672861232305

Epoch: 6| Step: 11
Training loss: 1.6110106369273578
Validation loss: 2.37848744603218

Epoch: 6| Step: 12
Training loss: 1.6761509058575703
Validation loss: 2.3975851330669036

Epoch: 6| Step: 13
Training loss: 2.1465880045289882
Validation loss: 2.4165796827193127

Epoch: 302| Step: 0
Training loss: 1.210479748253562
Validation loss: 2.4270165335775276

Epoch: 6| Step: 1
Training loss: 1.7917762397557546
Validation loss: 2.488304046512525

Epoch: 6| Step: 2
Training loss: 1.2898121821273765
Validation loss: 2.4858562500935415

Epoch: 6| Step: 3
Training loss: 1.8113558874250593
Validation loss: 2.5177154100084533

Epoch: 6| Step: 4
Training loss: 1.6369911276752243
Validation loss: 2.560236348454932

Epoch: 6| Step: 5
Training loss: 1.5829662432851723
Validation loss: 2.532497855487229

Epoch: 6| Step: 6
Training loss: 1.9399449088936098
Validation loss: 2.4556773388864577

Epoch: 6| Step: 7
Training loss: 1.6454210207544973
Validation loss: 2.4215985328578187

Epoch: 6| Step: 8
Training loss: 1.5050890742204897
Validation loss: 2.4037622345316154

Epoch: 6| Step: 9
Training loss: 1.8319266803886955
Validation loss: 2.3733207009558743

Epoch: 6| Step: 10
Training loss: 1.7177256219139205
Validation loss: 2.367398012002891

Epoch: 6| Step: 11
Training loss: 1.9708727942206583
Validation loss: 2.365494274844335

Epoch: 6| Step: 12
Training loss: 2.2543009870164803
Validation loss: 2.3575766547836663

Epoch: 6| Step: 13
Training loss: 1.8171151039351074
Validation loss: 2.368550042244739

Epoch: 303| Step: 0
Training loss: 1.690424327963052
Validation loss: 2.3783131391857943

Epoch: 6| Step: 1
Training loss: 1.4508951778183707
Validation loss: 2.41616682315525

Epoch: 6| Step: 2
Training loss: 1.699112110518705
Validation loss: 2.4396482813055456

Epoch: 6| Step: 3
Training loss: 1.244062005018736
Validation loss: 2.4757988734795866

Epoch: 6| Step: 4
Training loss: 2.044235974316313
Validation loss: 2.5032004216039474

Epoch: 6| Step: 5
Training loss: 1.1700635005966415
Validation loss: 2.51811126176082

Epoch: 6| Step: 6
Training loss: 1.6974023691453217
Validation loss: 2.501767763033121

Epoch: 6| Step: 7
Training loss: 1.9505534829300395
Validation loss: 2.4319526320310265

Epoch: 6| Step: 8
Training loss: 1.6029384749915245
Validation loss: 2.4191631365269446

Epoch: 6| Step: 9
Training loss: 1.7825215134787025
Validation loss: 2.3721823090989362

Epoch: 6| Step: 10
Training loss: 1.7968645178447655
Validation loss: 2.361746605707982

Epoch: 6| Step: 11
Training loss: 1.9119588697231276
Validation loss: 2.3426095431520144

Epoch: 6| Step: 12
Training loss: 2.1585964759259957
Validation loss: 2.3551567163595792

Epoch: 6| Step: 13
Training loss: 1.956287356863948
Validation loss: 2.349345362753932

Epoch: 304| Step: 0
Training loss: 1.7702235200342833
Validation loss: 2.3709105823148686

Epoch: 6| Step: 1
Training loss: 1.9349244134023542
Validation loss: 2.40836167311562

Epoch: 6| Step: 2
Training loss: 1.260184947170144
Validation loss: 2.472250888551187

Epoch: 6| Step: 3
Training loss: 2.3770435977415234
Validation loss: 2.5351472509970763

Epoch: 6| Step: 4
Training loss: 1.3627745115587715
Validation loss: 2.5391122030310864

Epoch: 6| Step: 5
Training loss: 1.5387920781075677
Validation loss: 2.5577209311536553

Epoch: 6| Step: 6
Training loss: 1.9511951525333526
Validation loss: 2.5193325108383293

Epoch: 6| Step: 7
Training loss: 1.223361168595818
Validation loss: 2.456627304020709

Epoch: 6| Step: 8
Training loss: 1.7452678732771678
Validation loss: 2.419927117914613

Epoch: 6| Step: 9
Training loss: 1.4598404136079823
Validation loss: 2.384579765107283

Epoch: 6| Step: 10
Training loss: 2.0098569680560496
Validation loss: 2.393082219875609

Epoch: 6| Step: 11
Training loss: 1.7265868724639004
Validation loss: 2.366785440977072

Epoch: 6| Step: 12
Training loss: 1.4737662020529574
Validation loss: 2.373393520942654

Epoch: 6| Step: 13
Training loss: 1.7920951626577994
Validation loss: 2.3779849275087703

Epoch: 305| Step: 0
Training loss: 1.517725482006845
Validation loss: 2.397151362085189

Epoch: 6| Step: 1
Training loss: 1.6874854475736094
Validation loss: 2.413552268251833

Epoch: 6| Step: 2
Training loss: 1.799188865582389
Validation loss: 2.4485378036760106

Epoch: 6| Step: 3
Training loss: 1.2331350835203252
Validation loss: 2.485680465521039

Epoch: 6| Step: 4
Training loss: 1.480063108567884
Validation loss: 2.516693674974984

Epoch: 6| Step: 5
Training loss: 1.2897198474876868
Validation loss: 2.471549948312629

Epoch: 6| Step: 6
Training loss: 2.302569848574035
Validation loss: 2.443717132348169

Epoch: 6| Step: 7
Training loss: 1.816321586358545
Validation loss: 2.4401349281466906

Epoch: 6| Step: 8
Training loss: 1.5494725160429312
Validation loss: 2.403361332400181

Epoch: 6| Step: 9
Training loss: 1.6663460264130112
Validation loss: 2.4000720314954482

Epoch: 6| Step: 10
Training loss: 1.408771966121525
Validation loss: 2.4071387138828424

Epoch: 6| Step: 11
Training loss: 1.8058526047454477
Validation loss: 2.4111999997567137

Epoch: 6| Step: 12
Training loss: 2.1749612300530523
Validation loss: 2.4282304895106632

Epoch: 6| Step: 13
Training loss: 1.6760373931254957
Validation loss: 2.4326400572323212

Epoch: 306| Step: 0
Training loss: 1.7606362952593504
Validation loss: 2.4342802641752566

Epoch: 6| Step: 1
Training loss: 2.054139851155877
Validation loss: 2.4643817540993007

Epoch: 6| Step: 2
Training loss: 1.6930929676178654
Validation loss: 2.4696744800292154

Epoch: 6| Step: 3
Training loss: 1.532691432826346
Validation loss: 2.484092660758238

Epoch: 6| Step: 4
Training loss: 1.4942905325891356
Validation loss: 2.465842033200406

Epoch: 6| Step: 5
Training loss: 2.154880918323739
Validation loss: 2.4763647929414576

Epoch: 6| Step: 6
Training loss: 1.9024445117372695
Validation loss: 2.4467817302022152

Epoch: 6| Step: 7
Training loss: 1.183727999586478
Validation loss: 2.422329929586375

Epoch: 6| Step: 8
Training loss: 1.5424404350415757
Validation loss: 2.429457156966682

Epoch: 6| Step: 9
Training loss: 1.2755736238711475
Validation loss: 2.3939556448494255

Epoch: 6| Step: 10
Training loss: 1.9892378568701743
Validation loss: 2.3924739785680806

Epoch: 6| Step: 11
Training loss: 1.1647147585025726
Validation loss: 2.39185839390431

Epoch: 6| Step: 12
Training loss: 1.8649897070388457
Validation loss: 2.3995990864389625

Epoch: 6| Step: 13
Training loss: 1.5981565405665108
Validation loss: 2.472111495623465

Epoch: 307| Step: 0
Training loss: 1.5685211136247796
Validation loss: 2.446894417365385

Epoch: 6| Step: 1
Training loss: 1.6843000377613124
Validation loss: 2.4670576694735797

Epoch: 6| Step: 2
Training loss: 1.4646705626787664
Validation loss: 2.492653317835518

Epoch: 6| Step: 3
Training loss: 2.067459847407463
Validation loss: 2.4719971138215877

Epoch: 6| Step: 4
Training loss: 1.3184035004189696
Validation loss: 2.477284308769116

Epoch: 6| Step: 5
Training loss: 2.1049452999736946
Validation loss: 2.5047098494065296

Epoch: 6| Step: 6
Training loss: 1.678226278932117
Validation loss: 2.452551641030198

Epoch: 6| Step: 7
Training loss: 1.141783452615791
Validation loss: 2.4344399446192377

Epoch: 6| Step: 8
Training loss: 1.8681810361307452
Validation loss: 2.425269319924687

Epoch: 6| Step: 9
Training loss: 1.3335130788921936
Validation loss: 2.4546567681721965

Epoch: 6| Step: 10
Training loss: 1.5748116486565962
Validation loss: 2.4249599480543154

Epoch: 6| Step: 11
Training loss: 1.759276598385736
Validation loss: 2.4117384793282417

Epoch: 6| Step: 12
Training loss: 1.6747300200875648
Validation loss: 2.400032934694357

Epoch: 6| Step: 13
Training loss: 2.144905099436709
Validation loss: 2.4225268801540736

Epoch: 308| Step: 0
Training loss: 1.6625018614564957
Validation loss: 2.376464380421555

Epoch: 6| Step: 1
Training loss: 1.6879641989396148
Validation loss: 2.378603634877761

Epoch: 6| Step: 2
Training loss: 1.735796921168512
Validation loss: 2.359480339034352

Epoch: 6| Step: 3
Training loss: 1.6781664681594421
Validation loss: 2.41399366481953

Epoch: 6| Step: 4
Training loss: 1.872895903962
Validation loss: 2.4299936145573833

Epoch: 6| Step: 5
Training loss: 1.3100513140987644
Validation loss: 2.490289912641026

Epoch: 6| Step: 6
Training loss: 1.7809977436469049
Validation loss: 2.513137453716242

Epoch: 6| Step: 7
Training loss: 1.586643306228962
Validation loss: 2.5686492610346034

Epoch: 6| Step: 8
Training loss: 1.7705456518726057
Validation loss: 2.5022810937577638

Epoch: 6| Step: 9
Training loss: 1.4345355773002924
Validation loss: 2.455806659749453

Epoch: 6| Step: 10
Training loss: 1.48208956204059
Validation loss: 2.414139159635716

Epoch: 6| Step: 11
Training loss: 1.8877926252279058
Validation loss: 2.3657626966316547

Epoch: 6| Step: 12
Training loss: 1.5864861201831206
Validation loss: 2.329869456608621

Epoch: 6| Step: 13
Training loss: 1.9079612180339212
Validation loss: 2.3429590696839044

Epoch: 309| Step: 0
Training loss: 1.6557337118180218
Validation loss: 2.3385285020551754

Epoch: 6| Step: 1
Training loss: 1.9190755164160476
Validation loss: 2.3592032614735423

Epoch: 6| Step: 2
Training loss: 1.3903593602582225
Validation loss: 2.358290650964807

Epoch: 6| Step: 3
Training loss: 1.7892865036570273
Validation loss: 2.374729177753693

Epoch: 6| Step: 4
Training loss: 0.9011352835883468
Validation loss: 2.428631772669263

Epoch: 6| Step: 5
Training loss: 1.674493539450875
Validation loss: 2.455236607354921

Epoch: 6| Step: 6
Training loss: 1.4747261860035892
Validation loss: 2.530531899496703

Epoch: 6| Step: 7
Training loss: 2.2983684226002277
Validation loss: 2.52653739250539

Epoch: 6| Step: 8
Training loss: 1.906713648208361
Validation loss: 2.5015264916508775

Epoch: 6| Step: 9
Training loss: 1.3570492020178884
Validation loss: 2.4448097844777275

Epoch: 6| Step: 10
Training loss: 1.7534812633251944
Validation loss: 2.402262976704395

Epoch: 6| Step: 11
Training loss: 1.3256312575995173
Validation loss: 2.4052842898753086

Epoch: 6| Step: 12
Training loss: 1.6045884737922838
Validation loss: 2.41080261626839

Epoch: 6| Step: 13
Training loss: 1.9290477603440077
Validation loss: 2.395836759959834

Epoch: 310| Step: 0
Training loss: 1.631061984513973
Validation loss: 2.3924643292967893

Epoch: 6| Step: 1
Training loss: 1.4058604230609197
Validation loss: 2.4013468960078512

Epoch: 6| Step: 2
Training loss: 1.2851338022236907
Validation loss: 2.426526021279426

Epoch: 6| Step: 3
Training loss: 1.9352228873171666
Validation loss: 2.4447761667453207

Epoch: 6| Step: 4
Training loss: 1.775743774609379
Validation loss: 2.465193505940818

Epoch: 6| Step: 5
Training loss: 1.1354645301926263
Validation loss: 2.489228956082255

Epoch: 6| Step: 6
Training loss: 1.5168636019498147
Validation loss: 2.5173436818965156

Epoch: 6| Step: 7
Training loss: 1.8459850923426016
Validation loss: 2.546764826120113

Epoch: 6| Step: 8
Training loss: 1.7674677861797383
Validation loss: 2.5836939313593468

Epoch: 6| Step: 9
Training loss: 1.351199900768518
Validation loss: 2.5098978329462716

Epoch: 6| Step: 10
Training loss: 1.9059656275024546
Validation loss: 2.5005182118821616

Epoch: 6| Step: 11
Training loss: 1.9953884364220995
Validation loss: 2.4535039532353564

Epoch: 6| Step: 12
Training loss: 1.7700254579642154
Validation loss: 2.428880890335106

Epoch: 6| Step: 13
Training loss: 1.4170035447888667
Validation loss: 2.4003925025604387

Epoch: 311| Step: 0
Training loss: 1.5186132487201054
Validation loss: 2.366651327770094

Epoch: 6| Step: 1
Training loss: 1.6787781138846072
Validation loss: 2.371886101555321

Epoch: 6| Step: 2
Training loss: 1.574772663966539
Validation loss: 2.3877214749206415

Epoch: 6| Step: 3
Training loss: 1.6268311966616698
Validation loss: 2.381127331644862

Epoch: 6| Step: 4
Training loss: 1.9247371791418049
Validation loss: 2.439931823343512

Epoch: 6| Step: 5
Training loss: 1.497027949600396
Validation loss: 2.495849915854295

Epoch: 6| Step: 6
Training loss: 1.479094499072209
Validation loss: 2.5253794725794867

Epoch: 6| Step: 7
Training loss: 1.9443248401671944
Validation loss: 2.5415778017638964

Epoch: 6| Step: 8
Training loss: 1.8638999439612183
Validation loss: 2.4871236762491455

Epoch: 6| Step: 9
Training loss: 1.4243360746252984
Validation loss: 2.4249812524305754

Epoch: 6| Step: 10
Training loss: 1.499625238651156
Validation loss: 2.415793794485838

Epoch: 6| Step: 11
Training loss: 1.2884475628415706
Validation loss: 2.4138372029204573

Epoch: 6| Step: 12
Training loss: 1.9180732900560946
Validation loss: 2.4006482856159956

Epoch: 6| Step: 13
Training loss: 1.546519537263653
Validation loss: 2.3772559016973696

Epoch: 312| Step: 0
Training loss: 1.9047773958041734
Validation loss: 2.3883703480173577

Epoch: 6| Step: 1
Training loss: 1.4874614550300775
Validation loss: 2.4020078074511857

Epoch: 6| Step: 2
Training loss: 1.4376627788430694
Validation loss: 2.403842583116478

Epoch: 6| Step: 3
Training loss: 1.7407372429920043
Validation loss: 2.3976057964173356

Epoch: 6| Step: 4
Training loss: 1.772958026886169
Validation loss: 2.4032884283909635

Epoch: 6| Step: 5
Training loss: 1.2852169126901478
Validation loss: 2.4062789086367373

Epoch: 6| Step: 6
Training loss: 1.2753440766653907
Validation loss: 2.4299550645911157

Epoch: 6| Step: 7
Training loss: 1.613223834551672
Validation loss: 2.4288143175193717

Epoch: 6| Step: 8
Training loss: 1.9449872583790768
Validation loss: 2.4374114810088328

Epoch: 6| Step: 9
Training loss: 1.4315057251203176
Validation loss: 2.442634714872539

Epoch: 6| Step: 10
Training loss: 1.8299347486484083
Validation loss: 2.468425894049772

Epoch: 6| Step: 11
Training loss: 1.3853165535380243
Validation loss: 2.498060585769498

Epoch: 6| Step: 12
Training loss: 1.667541949589499
Validation loss: 2.5035392606576314

Epoch: 6| Step: 13
Training loss: 1.8646098584325403
Validation loss: 2.5000282665418476

Epoch: 313| Step: 0
Training loss: 1.4314673346211153
Validation loss: 2.4680318799126684

Epoch: 6| Step: 1
Training loss: 1.4639474797130374
Validation loss: 2.44785411460687

Epoch: 6| Step: 2
Training loss: 1.7717007102219473
Validation loss: 2.4182336601071097

Epoch: 6| Step: 3
Training loss: 1.5414983382560987
Validation loss: 2.4120235655528317

Epoch: 6| Step: 4
Training loss: 1.831713423174114
Validation loss: 2.4018257421006304

Epoch: 6| Step: 5
Training loss: 2.0692179539572444
Validation loss: 2.3940550183639924

Epoch: 6| Step: 6
Training loss: 1.6978640713961008
Validation loss: 2.397305642287416

Epoch: 6| Step: 7
Training loss: 1.8744709540085904
Validation loss: 2.3905632562805237

Epoch: 6| Step: 8
Training loss: 1.5093730697461536
Validation loss: 2.3984698745377284

Epoch: 6| Step: 9
Training loss: 1.767298352772503
Validation loss: 2.415645029282405

Epoch: 6| Step: 10
Training loss: 1.094352447259955
Validation loss: 2.444024955396872

Epoch: 6| Step: 11
Training loss: 1.4246209426799346
Validation loss: 2.4506125405784913

Epoch: 6| Step: 12
Training loss: 1.5229651868251526
Validation loss: 2.4445354484194564

Epoch: 6| Step: 13
Training loss: 1.1203225703298922
Validation loss: 2.489115906229029

Epoch: 314| Step: 0
Training loss: 1.6973619861706484
Validation loss: 2.5132511142859753

Epoch: 6| Step: 1
Training loss: 1.48006568595389
Validation loss: 2.520433280935538

Epoch: 6| Step: 2
Training loss: 1.9743103948047733
Validation loss: 2.502092373889613

Epoch: 6| Step: 3
Training loss: 1.0829291078607028
Validation loss: 2.477589014690842

Epoch: 6| Step: 4
Training loss: 1.6342087757781134
Validation loss: 2.4891018135168212

Epoch: 6| Step: 5
Training loss: 1.879158875420342
Validation loss: 2.4518027503302666

Epoch: 6| Step: 6
Training loss: 1.5451629874913546
Validation loss: 2.448649738399134

Epoch: 6| Step: 7
Training loss: 1.6192308131593809
Validation loss: 2.4348969971107457

Epoch: 6| Step: 8
Training loss: 1.6875798241844397
Validation loss: 2.4422225418365437

Epoch: 6| Step: 9
Training loss: 1.5471340694613183
Validation loss: 2.430430003105771

Epoch: 6| Step: 10
Training loss: 1.5532016267045408
Validation loss: 2.436194302322566

Epoch: 6| Step: 11
Training loss: 1.8677805194283679
Validation loss: 2.4539446754914347

Epoch: 6| Step: 12
Training loss: 1.2686788191347784
Validation loss: 2.448393329474512

Epoch: 6| Step: 13
Training loss: 1.0509005340599498
Validation loss: 2.4380257609792952

Epoch: 315| Step: 0
Training loss: 2.1665340040625436
Validation loss: 2.4547126689825847

Epoch: 6| Step: 1
Training loss: 1.7351635351805288
Validation loss: 2.4360034767014396

Epoch: 6| Step: 2
Training loss: 1.1314576037526376
Validation loss: 2.427046751820261

Epoch: 6| Step: 3
Training loss: 1.131192067807375
Validation loss: 2.432581927159627

Epoch: 6| Step: 4
Training loss: 2.04828472949914
Validation loss: 2.419465392775979

Epoch: 6| Step: 5
Training loss: 1.4190226019900092
Validation loss: 2.428018142668092

Epoch: 6| Step: 6
Training loss: 1.086948664989272
Validation loss: 2.4307858328620213

Epoch: 6| Step: 7
Training loss: 1.9447083051973288
Validation loss: 2.429111762407733

Epoch: 6| Step: 8
Training loss: 1.7983523722369386
Validation loss: 2.4287069876058767

Epoch: 6| Step: 9
Training loss: 1.5950311485525621
Validation loss: 2.4284325376233875

Epoch: 6| Step: 10
Training loss: 1.4921143998220687
Validation loss: 2.4539016091064263

Epoch: 6| Step: 11
Training loss: 1.4300036471660493
Validation loss: 2.48506933730449

Epoch: 6| Step: 12
Training loss: 1.1010915412301463
Validation loss: 2.4882709296065553

Epoch: 6| Step: 13
Training loss: 1.6982409239770313
Validation loss: 2.5274267690676395

Epoch: 316| Step: 0
Training loss: 1.2709559501319876
Validation loss: 2.480033759759974

Epoch: 6| Step: 1
Training loss: 1.5047598658002361
Validation loss: 2.4700252727773133

Epoch: 6| Step: 2
Training loss: 1.3496161762954983
Validation loss: 2.4601843876136296

Epoch: 6| Step: 3
Training loss: 1.4547205543245467
Validation loss: 2.437994184059048

Epoch: 6| Step: 4
Training loss: 1.8952135882626786
Validation loss: 2.4373219974333016

Epoch: 6| Step: 5
Training loss: 1.7581449067215722
Validation loss: 2.3942824333484705

Epoch: 6| Step: 6
Training loss: 1.2285266869657974
Validation loss: 2.4045521606354816

Epoch: 6| Step: 7
Training loss: 1.067221640715164
Validation loss: 2.3889362296014465

Epoch: 6| Step: 8
Training loss: 1.9228506325583392
Validation loss: 2.384383730301932

Epoch: 6| Step: 9
Training loss: 1.8689012523667543
Validation loss: 2.4007563296111867

Epoch: 6| Step: 10
Training loss: 1.7025451372971883
Validation loss: 2.4552976968060363

Epoch: 6| Step: 11
Training loss: 1.0397710463789323
Validation loss: 2.4817220782093417

Epoch: 6| Step: 12
Training loss: 1.5950506550269965
Validation loss: 2.5444863509693056

Epoch: 6| Step: 13
Training loss: 2.191476314193002
Validation loss: 2.5681171444154884

Epoch: 317| Step: 0
Training loss: 1.5930136681285827
Validation loss: 2.5689120182162273

Epoch: 6| Step: 1
Training loss: 1.6602096728536773
Validation loss: 2.4979431653694015

Epoch: 6| Step: 2
Training loss: 1.4831748527703605
Validation loss: 2.454239568496828

Epoch: 6| Step: 3
Training loss: 1.5433952418132506
Validation loss: 2.421617784446805

Epoch: 6| Step: 4
Training loss: 1.708319066926266
Validation loss: 2.381718635130168

Epoch: 6| Step: 5
Training loss: 1.6576834179872886
Validation loss: 2.3844893385500137

Epoch: 6| Step: 6
Training loss: 1.5353222628608567
Validation loss: 2.366433562509839

Epoch: 6| Step: 7
Training loss: 1.6621613006908085
Validation loss: 2.3842283026556887

Epoch: 6| Step: 8
Training loss: 1.5888860193788334
Validation loss: 2.4064291674388567

Epoch: 6| Step: 9
Training loss: 1.393945993233817
Validation loss: 2.415187593823719

Epoch: 6| Step: 10
Training loss: 1.540392770345399
Validation loss: 2.5138530713541547

Epoch: 6| Step: 11
Training loss: 1.7106214257489718
Validation loss: 2.546226046854662

Epoch: 6| Step: 12
Training loss: 1.661701658920541
Validation loss: 2.608938197182472

Epoch: 6| Step: 13
Training loss: 1.748427842891638
Validation loss: 2.63832996114802

Epoch: 318| Step: 0
Training loss: 1.8058627706797379
Validation loss: 2.5734312584044448

Epoch: 6| Step: 1
Training loss: 1.841694219161615
Validation loss: 2.5000158227399303

Epoch: 6| Step: 2
Training loss: 1.332002611495657
Validation loss: 2.465261493863829

Epoch: 6| Step: 3
Training loss: 1.79862983265105
Validation loss: 2.412288485582828

Epoch: 6| Step: 4
Training loss: 1.99634193624334
Validation loss: 2.3888072347442186

Epoch: 6| Step: 5
Training loss: 1.0991206599149521
Validation loss: 2.3659767745782334

Epoch: 6| Step: 6
Training loss: 1.593760471683582
Validation loss: 2.3813623968699456

Epoch: 6| Step: 7
Training loss: 1.417408141400949
Validation loss: 2.361037890388534

Epoch: 6| Step: 8
Training loss: 1.56962114744085
Validation loss: 2.3918033521206117

Epoch: 6| Step: 9
Training loss: 1.559570694686279
Validation loss: 2.422247015954525

Epoch: 6| Step: 10
Training loss: 1.5295967207596155
Validation loss: 2.4524219049572387

Epoch: 6| Step: 11
Training loss: 1.5629443490487007
Validation loss: 2.4572491073753424

Epoch: 6| Step: 12
Training loss: 1.1055510796936099
Validation loss: 2.465241743886757

Epoch: 6| Step: 13
Training loss: 1.8782812018664596
Validation loss: 2.4348435273517803

Epoch: 319| Step: 0
Training loss: 1.4210055700860058
Validation loss: 2.455230655680329

Epoch: 6| Step: 1
Training loss: 2.20974602288515
Validation loss: 2.4737023271743737

Epoch: 6| Step: 2
Training loss: 0.944309616905526
Validation loss: 2.453811163920508

Epoch: 6| Step: 3
Training loss: 1.4509208944776626
Validation loss: 2.4284477118787127

Epoch: 6| Step: 4
Training loss: 1.7144021267192855
Validation loss: 2.4027243457361562

Epoch: 6| Step: 5
Training loss: 1.6689462410626805
Validation loss: 2.3821463587265947

Epoch: 6| Step: 6
Training loss: 1.7579379566775353
Validation loss: 2.35317254173077

Epoch: 6| Step: 7
Training loss: 1.9899185124682965
Validation loss: 2.3480507400774067

Epoch: 6| Step: 8
Training loss: 1.2355406363924017
Validation loss: 2.3810180276326234

Epoch: 6| Step: 9
Training loss: 1.5884213844996289
Validation loss: 2.4210052410417564

Epoch: 6| Step: 10
Training loss: 1.6212942711778984
Validation loss: 2.4507659025519555

Epoch: 6| Step: 11
Training loss: 1.4526172694338724
Validation loss: 2.4576133277092924

Epoch: 6| Step: 12
Training loss: 1.2744522732088939
Validation loss: 2.523342585793849

Epoch: 6| Step: 13
Training loss: 1.0749922862995984
Validation loss: 2.5702703413710175

Epoch: 320| Step: 0
Training loss: 1.1278733540788994
Validation loss: 2.6068534533520125

Epoch: 6| Step: 1
Training loss: 1.9294210396708606
Validation loss: 2.573565038005469

Epoch: 6| Step: 2
Training loss: 1.5479727808902835
Validation loss: 2.5617471755121746

Epoch: 6| Step: 3
Training loss: 1.5284797365931226
Validation loss: 2.4654738954279134

Epoch: 6| Step: 4
Training loss: 1.944638913133213
Validation loss: 2.4259602684389345

Epoch: 6| Step: 5
Training loss: 1.4677674273725088
Validation loss: 2.406044204769377

Epoch: 6| Step: 6
Training loss: 1.788718644459795
Validation loss: 2.3845292170102645

Epoch: 6| Step: 7
Training loss: 1.5969762870781357
Validation loss: 2.3996446836986824

Epoch: 6| Step: 8
Training loss: 1.0264451190605552
Validation loss: 2.41383349898236

Epoch: 6| Step: 9
Training loss: 1.8935101146281788
Validation loss: 2.3897385159696936

Epoch: 6| Step: 10
Training loss: 1.4325870648567143
Validation loss: 2.4076669008157956

Epoch: 6| Step: 11
Training loss: 1.4284429918182362
Validation loss: 2.4390509750689784

Epoch: 6| Step: 12
Training loss: 1.8034193859734102
Validation loss: 2.5049633214758042

Epoch: 6| Step: 13
Training loss: 0.8356885806812685
Validation loss: 2.5342189271353055

Epoch: 321| Step: 0
Training loss: 1.4872216485149494
Validation loss: 2.52880960093436

Epoch: 6| Step: 1
Training loss: 1.7363868935147277
Validation loss: 2.499744349913541

Epoch: 6| Step: 2
Training loss: 1.662515772120872
Validation loss: 2.470569659098598

Epoch: 6| Step: 3
Training loss: 1.177267763435983
Validation loss: 2.423512590362779

Epoch: 6| Step: 4
Training loss: 1.579064722050157
Validation loss: 2.406312760300521

Epoch: 6| Step: 5
Training loss: 1.763442522008337
Validation loss: 2.395098350823256

Epoch: 6| Step: 6
Training loss: 1.4042195814823597
Validation loss: 2.3729820821601324

Epoch: 6| Step: 7
Training loss: 1.5005973580136964
Validation loss: 2.392063775727124

Epoch: 6| Step: 8
Training loss: 1.0240222337924154
Validation loss: 2.41692702942136

Epoch: 6| Step: 9
Training loss: 1.4301456905389018
Validation loss: 2.392764695380988

Epoch: 6| Step: 10
Training loss: 1.922822300120153
Validation loss: 2.427458259417385

Epoch: 6| Step: 11
Training loss: 1.638007337295252
Validation loss: 2.4427319768729596

Epoch: 6| Step: 12
Training loss: 1.6179309555052794
Validation loss: 2.4794256527114795

Epoch: 6| Step: 13
Training loss: 1.5746342037422827
Validation loss: 2.486229623569287

Epoch: 322| Step: 0
Training loss: 1.8088412352397292
Validation loss: 2.508734234822476

Epoch: 6| Step: 1
Training loss: 1.698571233037818
Validation loss: 2.5157266722514606

Epoch: 6| Step: 2
Training loss: 1.4278204561889756
Validation loss: 2.48620921215024

Epoch: 6| Step: 3
Training loss: 1.5919095052177854
Validation loss: 2.4713103959593092

Epoch: 6| Step: 4
Training loss: 1.260702284721458
Validation loss: 2.459792258679835

Epoch: 6| Step: 5
Training loss: 1.3424570827621372
Validation loss: 2.438307978727916

Epoch: 6| Step: 6
Training loss: 1.6796026164053344
Validation loss: 2.4369630109033373

Epoch: 6| Step: 7
Training loss: 1.6317121092352433
Validation loss: 2.4616980145011866

Epoch: 6| Step: 8
Training loss: 1.5435888661912505
Validation loss: 2.503966776591886

Epoch: 6| Step: 9
Training loss: 1.7313603500287313
Validation loss: 2.518738165708292

Epoch: 6| Step: 10
Training loss: 1.5707213215982303
Validation loss: 2.5365136435244104

Epoch: 6| Step: 11
Training loss: 1.0433466651682226
Validation loss: 2.519561042937007

Epoch: 6| Step: 12
Training loss: 1.775838428253116
Validation loss: 2.5034750443824394

Epoch: 6| Step: 13
Training loss: 0.643314808898358
Validation loss: 2.46129559478294

Epoch: 323| Step: 0
Training loss: 1.240747300661015
Validation loss: 2.451670276275322

Epoch: 6| Step: 1
Training loss: 0.8798250270416973
Validation loss: 2.4595949197466638

Epoch: 6| Step: 2
Training loss: 1.695567309659783
Validation loss: 2.4446046956694074

Epoch: 6| Step: 3
Training loss: 1.7706421992055374
Validation loss: 2.4558229900980906

Epoch: 6| Step: 4
Training loss: 1.3330118815042062
Validation loss: 2.459938888699479

Epoch: 6| Step: 5
Training loss: 1.4432027729236159
Validation loss: 2.493315392210797

Epoch: 6| Step: 6
Training loss: 1.4197873730033646
Validation loss: 2.4835803117294226

Epoch: 6| Step: 7
Training loss: 1.550464203756845
Validation loss: 2.5106097370817113

Epoch: 6| Step: 8
Training loss: 2.1073858984562386
Validation loss: 2.481076430896598

Epoch: 6| Step: 9
Training loss: 1.5632465867713405
Validation loss: 2.442413182807468

Epoch: 6| Step: 10
Training loss: 1.2940766811261695
Validation loss: 2.419087234860374

Epoch: 6| Step: 11
Training loss: 1.5908830324738854
Validation loss: 2.4119586277218814

Epoch: 6| Step: 12
Training loss: 1.3032169391939747
Validation loss: 2.411534007185249

Epoch: 6| Step: 13
Training loss: 2.1600585694672847
Validation loss: 2.4256188751763226

Epoch: 324| Step: 0
Training loss: 1.3628052150896373
Validation loss: 2.4419918348040435

Epoch: 6| Step: 1
Training loss: 1.5841111063089444
Validation loss: 2.4810543731638544

Epoch: 6| Step: 2
Training loss: 1.508515110267671
Validation loss: 2.5214305625484337

Epoch: 6| Step: 3
Training loss: 1.124899329873502
Validation loss: 2.4720104572810233

Epoch: 6| Step: 4
Training loss: 1.2368874392045393
Validation loss: 2.460363093081147

Epoch: 6| Step: 5
Training loss: 1.2729066081463887
Validation loss: 2.440944018112736

Epoch: 6| Step: 6
Training loss: 1.3070348307485833
Validation loss: 2.423135927374321

Epoch: 6| Step: 7
Training loss: 1.634007067138629
Validation loss: 2.421241080805846

Epoch: 6| Step: 8
Training loss: 1.6911200794467287
Validation loss: 2.4087496280795997

Epoch: 6| Step: 9
Training loss: 1.8997480476370365
Validation loss: 2.416565237013623

Epoch: 6| Step: 10
Training loss: 1.7266992022911434
Validation loss: 2.421286656966534

Epoch: 6| Step: 11
Training loss: 1.5635337461727976
Validation loss: 2.451359802632531

Epoch: 6| Step: 12
Training loss: 1.670693951863188
Validation loss: 2.4540327576891285

Epoch: 6| Step: 13
Training loss: 1.3910315273011171
Validation loss: 2.480562921463879

Epoch: 325| Step: 0
Training loss: 1.2869214859987315
Validation loss: 2.4989155375852135

Epoch: 6| Step: 1
Training loss: 1.4860293354974061
Validation loss: 2.561812581985887

Epoch: 6| Step: 2
Training loss: 1.4217688552306444
Validation loss: 2.563234616598531

Epoch: 6| Step: 3
Training loss: 0.8586446953498741
Validation loss: 2.5183399051933333

Epoch: 6| Step: 4
Training loss: 1.2542900377513109
Validation loss: 2.4937907685588554

Epoch: 6| Step: 5
Training loss: 2.0028073158619666
Validation loss: 2.4513178864703087

Epoch: 6| Step: 6
Training loss: 1.1518275252280286
Validation loss: 2.4495554580353978

Epoch: 6| Step: 7
Training loss: 1.7053209199674808
Validation loss: 2.412881529075317

Epoch: 6| Step: 8
Training loss: 1.0382195976099315
Validation loss: 2.4417293631740566

Epoch: 6| Step: 9
Training loss: 1.5456474134128928
Validation loss: 2.4533228901833217

Epoch: 6| Step: 10
Training loss: 1.804762669438635
Validation loss: 2.448511038320181

Epoch: 6| Step: 11
Training loss: 1.814609483894683
Validation loss: 2.4810936039104456

Epoch: 6| Step: 12
Training loss: 1.2393561189707045
Validation loss: 2.4883574580373087

Epoch: 6| Step: 13
Training loss: 2.171882684268668
Validation loss: 2.4795498247253005

Epoch: 326| Step: 0
Training loss: 1.9456835779672113
Validation loss: 2.531341393088237

Epoch: 6| Step: 1
Training loss: 1.5155958192513443
Validation loss: 2.529877245224499

Epoch: 6| Step: 2
Training loss: 1.2760042872760462
Validation loss: 2.4907094356814827

Epoch: 6| Step: 3
Training loss: 1.5739506571305033
Validation loss: 2.4754389734364333

Epoch: 6| Step: 4
Training loss: 1.456433375523112
Validation loss: 2.4318083210648664

Epoch: 6| Step: 5
Training loss: 1.4063277329047579
Validation loss: 2.4098843542666835

Epoch: 6| Step: 6
Training loss: 1.1654765098426982
Validation loss: 2.3878308639536217

Epoch: 6| Step: 7
Training loss: 1.1975784266519574
Validation loss: 2.3872738676610905

Epoch: 6| Step: 8
Training loss: 1.2572659080835487
Validation loss: 2.4226824967337293

Epoch: 6| Step: 9
Training loss: 1.724494766107958
Validation loss: 2.46515570817904

Epoch: 6| Step: 10
Training loss: 1.4753567248088995
Validation loss: 2.46238221894135

Epoch: 6| Step: 11
Training loss: 1.3236052405694283
Validation loss: 2.484526378012924

Epoch: 6| Step: 12
Training loss: 1.7399670602157922
Validation loss: 2.524246167013184

Epoch: 6| Step: 13
Training loss: 2.055733882053619
Validation loss: 2.4959000911560336

Epoch: 327| Step: 0
Training loss: 1.6436281601456737
Validation loss: 2.4971767563281513

Epoch: 6| Step: 1
Training loss: 0.7892666543164647
Validation loss: 2.4710508792567683

Epoch: 6| Step: 2
Training loss: 1.1506686174288496
Validation loss: 2.463642383577001

Epoch: 6| Step: 3
Training loss: 1.6524265710441934
Validation loss: 2.4586246777381495

Epoch: 6| Step: 4
Training loss: 1.4160226124558202
Validation loss: 2.4362108472685033

Epoch: 6| Step: 5
Training loss: 1.7277768382771437
Validation loss: 2.4755232505938167

Epoch: 6| Step: 6
Training loss: 1.780333768541123
Validation loss: 2.504083057628256

Epoch: 6| Step: 7
Training loss: 1.6753940090395192
Validation loss: 2.5412529726878987

Epoch: 6| Step: 8
Training loss: 1.575201215455074
Validation loss: 2.5393911828278934

Epoch: 6| Step: 9
Training loss: 1.4305570699113817
Validation loss: 2.5016615914070197

Epoch: 6| Step: 10
Training loss: 1.2988369819511218
Validation loss: 2.433451841415435

Epoch: 6| Step: 11
Training loss: 1.4084687425573157
Validation loss: 2.434972931331836

Epoch: 6| Step: 12
Training loss: 1.2852280431480971
Validation loss: 2.3872368765765333

Epoch: 6| Step: 13
Training loss: 1.8940787178003566
Validation loss: 2.3768457258070885

Epoch: 328| Step: 0
Training loss: 1.7342060453583847
Validation loss: 2.3907413174211185

Epoch: 6| Step: 1
Training loss: 1.1909421923786934
Validation loss: 2.3905595125283168

Epoch: 6| Step: 2
Training loss: 1.7657943239294283
Validation loss: 2.4221885221523523

Epoch: 6| Step: 3
Training loss: 1.6291569578592064
Validation loss: 2.461398670161071

Epoch: 6| Step: 4
Training loss: 1.654802661666961
Validation loss: 2.4396522723313194

Epoch: 6| Step: 5
Training loss: 1.2492266169831732
Validation loss: 2.430119484800906

Epoch: 6| Step: 6
Training loss: 1.9255497234207488
Validation loss: 2.45007955230714

Epoch: 6| Step: 7
Training loss: 1.4406850607840893
Validation loss: 2.4551769406423714

Epoch: 6| Step: 8
Training loss: 0.7872507048912927
Validation loss: 2.4523741847621277

Epoch: 6| Step: 9
Training loss: 1.4208562366209514
Validation loss: 2.4513019962088776

Epoch: 6| Step: 10
Training loss: 1.530426115149995
Validation loss: 2.4434789252902376

Epoch: 6| Step: 11
Training loss: 0.695471563254267
Validation loss: 2.4219502395337815

Epoch: 6| Step: 12
Training loss: 1.3699416838715663
Validation loss: 2.4614585052801656

Epoch: 6| Step: 13
Training loss: 1.865054584246431
Validation loss: 2.438741909759683

Epoch: 329| Step: 0
Training loss: 1.8506537029973946
Validation loss: 2.423528834195728

Epoch: 6| Step: 1
Training loss: 1.3550735469156865
Validation loss: 2.4328665893880443

Epoch: 6| Step: 2
Training loss: 1.3968461001690105
Validation loss: 2.4355664994728192

Epoch: 6| Step: 3
Training loss: 1.7985501649301483
Validation loss: 2.427694454377542

Epoch: 6| Step: 4
Training loss: 1.7746850553678108
Validation loss: 2.442502549135554

Epoch: 6| Step: 5
Training loss: 1.5143649182080479
Validation loss: 2.428428798412196

Epoch: 6| Step: 6
Training loss: 1.3457122492377087
Validation loss: 2.4709698608752624

Epoch: 6| Step: 7
Training loss: 0.838147246359248
Validation loss: 2.4462928289058152

Epoch: 6| Step: 8
Training loss: 1.3068375374939998
Validation loss: 2.489668540682381

Epoch: 6| Step: 9
Training loss: 1.8109557709582709
Validation loss: 2.462256103025688

Epoch: 6| Step: 10
Training loss: 1.3809044384111746
Validation loss: 2.4735721478854713

Epoch: 6| Step: 11
Training loss: 1.1331368869803948
Validation loss: 2.4993422227407964

Epoch: 6| Step: 12
Training loss: 1.2002271953721364
Validation loss: 2.4940779542365985

Epoch: 6| Step: 13
Training loss: 1.1179402622989163
Validation loss: 2.4787457139681

Epoch: 330| Step: 0
Training loss: 1.4892645363577721
Validation loss: 2.448141383999403

Epoch: 6| Step: 1
Training loss: 1.913800529146794
Validation loss: 2.4356171240723143

Epoch: 6| Step: 2
Training loss: 1.334465733107842
Validation loss: 2.39568501388331

Epoch: 6| Step: 3
Training loss: 1.4818445420885837
Validation loss: 2.3995220076856487

Epoch: 6| Step: 4
Training loss: 1.2278022574999745
Validation loss: 2.3615021678765604

Epoch: 6| Step: 5
Training loss: 1.0530941831341702
Validation loss: 2.3815725493775357

Epoch: 6| Step: 6
Training loss: 1.1382113485663052
Validation loss: 2.424153788953809

Epoch: 6| Step: 7
Training loss: 1.7315169834336213
Validation loss: 2.4666593896857725

Epoch: 6| Step: 8
Training loss: 1.410288965631956
Validation loss: 2.5052938534755262

Epoch: 6| Step: 9
Training loss: 1.3474147414375113
Validation loss: 2.522860988292735

Epoch: 6| Step: 10
Training loss: 1.7628742497040948
Validation loss: 2.5589876602047097

Epoch: 6| Step: 11
Training loss: 1.2295796406422337
Validation loss: 2.5881654219132826

Epoch: 6| Step: 12
Training loss: 1.4234906753004166
Validation loss: 2.542049434276427

Epoch: 6| Step: 13
Training loss: 1.5706480815874886
Validation loss: 2.540504073342863

Epoch: 331| Step: 0
Training loss: 1.212945368663177
Validation loss: 2.503331486224044

Epoch: 6| Step: 1
Training loss: 1.4099211351510343
Validation loss: 2.450259834911064

Epoch: 6| Step: 2
Training loss: 1.4492092080843217
Validation loss: 2.4366599676634544

Epoch: 6| Step: 3
Training loss: 1.5363749163553657
Validation loss: 2.384611326349721

Epoch: 6| Step: 4
Training loss: 0.9903425951327414
Validation loss: 2.37858251544427

Epoch: 6| Step: 5
Training loss: 1.4506761980205285
Validation loss: 2.426450668477518

Epoch: 6| Step: 6
Training loss: 1.6228016875854623
Validation loss: 2.440719491362284

Epoch: 6| Step: 7
Training loss: 1.2308725814570884
Validation loss: 2.4573670393605087

Epoch: 6| Step: 8
Training loss: 1.6653812537851458
Validation loss: 2.474647991811067

Epoch: 6| Step: 9
Training loss: 1.3693704670666076
Validation loss: 2.5502800529711003

Epoch: 6| Step: 10
Training loss: 1.7653339787555986
Validation loss: 2.5360572081517283

Epoch: 6| Step: 11
Training loss: 1.2564424908186924
Validation loss: 2.5249843247255117

Epoch: 6| Step: 12
Training loss: 1.808369567027586
Validation loss: 2.4649345870439867

Epoch: 6| Step: 13
Training loss: 0.7950233188544081
Validation loss: 2.4198754414980552

Epoch: 332| Step: 0
Training loss: 1.4719053423238448
Validation loss: 2.3761792798352146

Epoch: 6| Step: 1
Training loss: 0.9216880932145937
Validation loss: 2.3862172751895825

Epoch: 6| Step: 2
Training loss: 1.6835555848931532
Validation loss: 2.352611776023777

Epoch: 6| Step: 3
Training loss: 1.2084120472668312
Validation loss: 2.350308368761687

Epoch: 6| Step: 4
Training loss: 1.8367263722393414
Validation loss: 2.3831166106112756

Epoch: 6| Step: 5
Training loss: 1.6953004054328085
Validation loss: 2.4150456503570377

Epoch: 6| Step: 6
Training loss: 1.2790508936493603
Validation loss: 2.470749501841183

Epoch: 6| Step: 7
Training loss: 1.4971186461487822
Validation loss: 2.5073383618986247

Epoch: 6| Step: 8
Training loss: 1.457713849326803
Validation loss: 2.5402655243671743

Epoch: 6| Step: 9
Training loss: 1.625555383701508
Validation loss: 2.5266922850663867

Epoch: 6| Step: 10
Training loss: 1.5117045557109776
Validation loss: 2.5374979984298385

Epoch: 6| Step: 11
Training loss: 1.4307493841878822
Validation loss: 2.492600425704548

Epoch: 6| Step: 12
Training loss: 1.2091989157381284
Validation loss: 2.446392130398292

Epoch: 6| Step: 13
Training loss: 0.6642415422411517
Validation loss: 2.4244383458063687

Epoch: 333| Step: 0
Training loss: 1.6779898647688818
Validation loss: 2.428663754739753

Epoch: 6| Step: 1
Training loss: 1.1804202500888246
Validation loss: 2.402619814307225

Epoch: 6| Step: 2
Training loss: 1.3822632038067437
Validation loss: 2.397585939823047

Epoch: 6| Step: 3
Training loss: 1.2713683935377629
Validation loss: 2.4053119641699636

Epoch: 6| Step: 4
Training loss: 1.293337305561009
Validation loss: 2.385691766118475

Epoch: 6| Step: 5
Training loss: 1.464507285576981
Validation loss: 2.4040461338559163

Epoch: 6| Step: 6
Training loss: 1.4426637865297498
Validation loss: 2.4394589827537723

Epoch: 6| Step: 7
Training loss: 1.6187396133855512
Validation loss: 2.4562405277509898

Epoch: 6| Step: 8
Training loss: 1.8605969685168657
Validation loss: 2.4734200735410257

Epoch: 6| Step: 9
Training loss: 1.4542957634810165
Validation loss: 2.4843442433453293

Epoch: 6| Step: 10
Training loss: 1.183213125534841
Validation loss: 2.482038850787608

Epoch: 6| Step: 11
Training loss: 1.1214129694598751
Validation loss: 2.4240251484379995

Epoch: 6| Step: 12
Training loss: 0.7084801512382961
Validation loss: 2.434457881529193

Epoch: 6| Step: 13
Training loss: 1.692804124518131
Validation loss: 2.4225332042516783

Epoch: 334| Step: 0
Training loss: 1.5373978495585157
Validation loss: 2.4579322686617253

Epoch: 6| Step: 1
Training loss: 1.6767659173235252
Validation loss: 2.474966034418439

Epoch: 6| Step: 2
Training loss: 0.6909509226350554
Validation loss: 2.45648175111466

Epoch: 6| Step: 3
Training loss: 1.262112393695854
Validation loss: 2.4780843865718216

Epoch: 6| Step: 4
Training loss: 1.3970360153214245
Validation loss: 2.4997060695257654

Epoch: 6| Step: 5
Training loss: 1.4024528949735278
Validation loss: 2.4627687588130094

Epoch: 6| Step: 6
Training loss: 1.657452632520665
Validation loss: 2.4810495614010675

Epoch: 6| Step: 7
Training loss: 1.4276229877569635
Validation loss: 2.4705864630996963

Epoch: 6| Step: 8
Training loss: 1.347390853622941
Validation loss: 2.4936118052131593

Epoch: 6| Step: 9
Training loss: 1.301306266337719
Validation loss: 2.4851407479260406

Epoch: 6| Step: 10
Training loss: 1.4525460351158785
Validation loss: 2.480827260030129

Epoch: 6| Step: 11
Training loss: 1.569712813771521
Validation loss: 2.5003680419732537

Epoch: 6| Step: 12
Training loss: 1.1376614152172575
Validation loss: 2.5029714317275635

Epoch: 6| Step: 13
Training loss: 1.1455403329016856
Validation loss: 2.4765979985179016

Epoch: 335| Step: 0
Training loss: 1.3022389535096712
Validation loss: 2.4760399981465353

Epoch: 6| Step: 1
Training loss: 1.6533792916698826
Validation loss: 2.5174580537948534

Epoch: 6| Step: 2
Training loss: 1.5948717246298154
Validation loss: 2.491576771176481

Epoch: 6| Step: 3
Training loss: 1.5806001948910033
Validation loss: 2.472589021146031

Epoch: 6| Step: 4
Training loss: 1.459895450820174
Validation loss: 2.48415289404745

Epoch: 6| Step: 5
Training loss: 1.2256462902999734
Validation loss: 2.45945796996248

Epoch: 6| Step: 6
Training loss: 1.5761174189012894
Validation loss: 2.4220881913078793

Epoch: 6| Step: 7
Training loss: 1.755672389715275
Validation loss: 2.421962350890295

Epoch: 6| Step: 8
Training loss: 1.2199987225447673
Validation loss: 2.374089823841974

Epoch: 6| Step: 9
Training loss: 1.6033844795449423
Validation loss: 2.403885592112661

Epoch: 6| Step: 10
Training loss: 1.0695788242634885
Validation loss: 2.3672058847686035

Epoch: 6| Step: 11
Training loss: 0.8075420524583519
Validation loss: 2.404565039830388

Epoch: 6| Step: 12
Training loss: 0.995578587773913
Validation loss: 2.4078734788484164

Epoch: 6| Step: 13
Training loss: 0.9658373145602053
Validation loss: 2.430667200781387

Epoch: 336| Step: 0
Training loss: 1.078244188879899
Validation loss: 2.4701651300710714

Epoch: 6| Step: 1
Training loss: 0.9208596991019562
Validation loss: 2.548046074088199

Epoch: 6| Step: 2
Training loss: 1.2767595827703997
Validation loss: 2.55404716375006

Epoch: 6| Step: 3
Training loss: 1.0736631864151622
Validation loss: 2.518463891083891

Epoch: 6| Step: 4
Training loss: 1.6877150221985895
Validation loss: 2.498909839723037

Epoch: 6| Step: 5
Training loss: 1.5777174923950505
Validation loss: 2.432749990397472

Epoch: 6| Step: 6
Training loss: 1.1060824897797576
Validation loss: 2.4181865549180266

Epoch: 6| Step: 7
Training loss: 1.866910650566134
Validation loss: 2.376143458195536

Epoch: 6| Step: 8
Training loss: 1.372098505673979
Validation loss: 2.3865140522319823

Epoch: 6| Step: 9
Training loss: 1.425279251978789
Validation loss: 2.4094290985383644

Epoch: 6| Step: 10
Training loss: 1.2687337864934434
Validation loss: 2.4137705194821186

Epoch: 6| Step: 11
Training loss: 1.3908390351931514
Validation loss: 2.4379525049896453

Epoch: 6| Step: 12
Training loss: 1.2108939870584408
Validation loss: 2.4392214518548507

Epoch: 6| Step: 13
Training loss: 1.9815768240071185
Validation loss: 2.4935281990501315

Epoch: 337| Step: 0
Training loss: 1.184374762462099
Validation loss: 2.5175963269815984

Epoch: 6| Step: 1
Training loss: 1.7981402379339326
Validation loss: 2.4985239285910197

Epoch: 6| Step: 2
Training loss: 1.3812938907606114
Validation loss: 2.45765166706557

Epoch: 6| Step: 3
Training loss: 1.4027600108911047
Validation loss: 2.4146010623823093

Epoch: 6| Step: 4
Training loss: 1.6755932967058493
Validation loss: 2.441417662103704

Epoch: 6| Step: 5
Training loss: 1.4189580823582302
Validation loss: 2.4049726051293536

Epoch: 6| Step: 6
Training loss: 1.3393469242458946
Validation loss: 2.3957792713830193

Epoch: 6| Step: 7
Training loss: 1.3122760490816043
Validation loss: 2.3979768691842898

Epoch: 6| Step: 8
Training loss: 0.9434986840922727
Validation loss: 2.388744011295343

Epoch: 6| Step: 9
Training loss: 1.1439572089268517
Validation loss: 2.4108809533370135

Epoch: 6| Step: 10
Training loss: 1.4953786869209296
Validation loss: 2.455350434009521

Epoch: 6| Step: 11
Training loss: 1.2045543156685596
Validation loss: 2.4730308554937124

Epoch: 6| Step: 12
Training loss: 1.4397187731894112
Validation loss: 2.460251660543983

Epoch: 6| Step: 13
Training loss: 0.8734600958178949
Validation loss: 2.477426504441919

Epoch: 338| Step: 0
Training loss: 1.0365541627886163
Validation loss: 2.4558492790849797

Epoch: 6| Step: 1
Training loss: 1.7111030394018343
Validation loss: 2.4653655249218827

Epoch: 6| Step: 2
Training loss: 1.2226004298328734
Validation loss: 2.4584642249944264

Epoch: 6| Step: 3
Training loss: 1.3222530482720982
Validation loss: 2.444115180058446

Epoch: 6| Step: 4
Training loss: 1.1108786909416164
Validation loss: 2.429265222756005

Epoch: 6| Step: 5
Training loss: 1.1991706863364227
Validation loss: 2.45658847802402

Epoch: 6| Step: 6
Training loss: 1.2606724040887498
Validation loss: 2.4452254055647353

Epoch: 6| Step: 7
Training loss: 1.6562693612748436
Validation loss: 2.4903075826534007

Epoch: 6| Step: 8
Training loss: 1.288465188094619
Validation loss: 2.4728499864449143

Epoch: 6| Step: 9
Training loss: 1.4424062841903715
Validation loss: 2.4901736309598026

Epoch: 6| Step: 10
Training loss: 1.6383476072888072
Validation loss: 2.456749525462602

Epoch: 6| Step: 11
Training loss: 1.3574368921999806
Validation loss: 2.439367921151547

Epoch: 6| Step: 12
Training loss: 1.0994450122775457
Validation loss: 2.437063330026979

Epoch: 6| Step: 13
Training loss: 1.3231859258536331
Validation loss: 2.462718264510327

Epoch: 339| Step: 0
Training loss: 0.9853516834814717
Validation loss: 2.432419186340813

Epoch: 6| Step: 1
Training loss: 1.1415990563488316
Validation loss: 2.4643023536478914

Epoch: 6| Step: 2
Training loss: 1.3561389156854378
Validation loss: 2.4601686682054704

Epoch: 6| Step: 3
Training loss: 1.5348238597296784
Validation loss: 2.4614575944770194

Epoch: 6| Step: 4
Training loss: 1.367379224140726
Validation loss: 2.428993205297328

Epoch: 6| Step: 5
Training loss: 1.8379573668017402
Validation loss: 2.453840467138401

Epoch: 6| Step: 6
Training loss: 1.2988926462768677
Validation loss: 2.411765221744172

Epoch: 6| Step: 7
Training loss: 1.6775361944350191
Validation loss: 2.407330817219119

Epoch: 6| Step: 8
Training loss: 1.3094526518236003
Validation loss: 2.4092750546568875

Epoch: 6| Step: 9
Training loss: 1.3462157581051433
Validation loss: 2.3888069879108333

Epoch: 6| Step: 10
Training loss: 0.7145620322504967
Validation loss: 2.4514360488875715

Epoch: 6| Step: 11
Training loss: 1.420153403525365
Validation loss: 2.467108105096366

Epoch: 6| Step: 12
Training loss: 1.0230047461249518
Validation loss: 2.4689005406957367

Epoch: 6| Step: 13
Training loss: 1.2150379283306774
Validation loss: 2.475814370427293

Epoch: 340| Step: 0
Training loss: 1.015235532765097
Validation loss: 2.5212625761665763

Epoch: 6| Step: 1
Training loss: 0.8724739533173607
Validation loss: 2.473159590287381

Epoch: 6| Step: 2
Training loss: 1.4085298071982035
Validation loss: 2.490114504884635

Epoch: 6| Step: 3
Training loss: 1.1873223021214543
Validation loss: 2.4603360275915183

Epoch: 6| Step: 4
Training loss: 1.0683520663776804
Validation loss: 2.446019130033207

Epoch: 6| Step: 5
Training loss: 1.2412369167871522
Validation loss: 2.4460828906175296

Epoch: 6| Step: 6
Training loss: 1.6636588453260457
Validation loss: 2.4540424479768843

Epoch: 6| Step: 7
Training loss: 1.1827218145682092
Validation loss: 2.4598786388257428

Epoch: 6| Step: 8
Training loss: 1.037715641269915
Validation loss: 2.4354359828103975

Epoch: 6| Step: 9
Training loss: 1.5220870855232784
Validation loss: 2.428726596624203

Epoch: 6| Step: 10
Training loss: 1.333287069392248
Validation loss: 2.444103939459693

Epoch: 6| Step: 11
Training loss: 1.2760755210070505
Validation loss: 2.443319424274836

Epoch: 6| Step: 12
Training loss: 1.7095390422431818
Validation loss: 2.41884925297143

Epoch: 6| Step: 13
Training loss: 1.865164071400859
Validation loss: 2.4245362415461957

Epoch: 341| Step: 0
Training loss: 1.4931481749124107
Validation loss: 2.4299849952009316

Epoch: 6| Step: 1
Training loss: 0.7362616228180372
Validation loss: 2.4545199502024087

Epoch: 6| Step: 2
Training loss: 1.535038834369496
Validation loss: 2.4590760175113955

Epoch: 6| Step: 3
Training loss: 1.1815584012262885
Validation loss: 2.4892253869838923

Epoch: 6| Step: 4
Training loss: 0.7620113495509646
Validation loss: 2.489064985462678

Epoch: 6| Step: 5
Training loss: 1.233757927124158
Validation loss: 2.5126775800549863

Epoch: 6| Step: 6
Training loss: 1.3231786733776805
Validation loss: 2.51729514083069

Epoch: 6| Step: 7
Training loss: 1.3180195688378138
Validation loss: 2.4519369586041893

Epoch: 6| Step: 8
Training loss: 1.783850261006407
Validation loss: 2.3886088975053985

Epoch: 6| Step: 9
Training loss: 1.6221695237476368
Validation loss: 2.364818708912719

Epoch: 6| Step: 10
Training loss: 1.1295970136563807
Validation loss: 2.363303875151698

Epoch: 6| Step: 11
Training loss: 0.9435800171920486
Validation loss: 2.361907724185819

Epoch: 6| Step: 12
Training loss: 1.538482246809751
Validation loss: 2.3702855286679383

Epoch: 6| Step: 13
Training loss: 1.3620824926604607
Validation loss: 2.4270589792852735

Epoch: 342| Step: 0
Training loss: 1.3273833055086395
Validation loss: 2.479853003462615

Epoch: 6| Step: 1
Training loss: 1.6739546773601963
Validation loss: 2.5720152630806092

Epoch: 6| Step: 2
Training loss: 0.8740290295299462
Validation loss: 2.569681111435161

Epoch: 6| Step: 3
Training loss: 0.9421395259555762
Validation loss: 2.5487189901043523

Epoch: 6| Step: 4
Training loss: 1.3459764709570048
Validation loss: 2.499779496287298

Epoch: 6| Step: 5
Training loss: 0.9573144610447705
Validation loss: 2.4469493420026573

Epoch: 6| Step: 6
Training loss: 1.1380831470785897
Validation loss: 2.41294897867258

Epoch: 6| Step: 7
Training loss: 1.0253677220284476
Validation loss: 2.4042489497451713

Epoch: 6| Step: 8
Training loss: 1.356668518465045
Validation loss: 2.3721217788522693

Epoch: 6| Step: 9
Training loss: 1.3222246036899894
Validation loss: 2.3678774850678526

Epoch: 6| Step: 10
Training loss: 2.3298839094850297
Validation loss: 2.3689584837119835

Epoch: 6| Step: 11
Training loss: 0.8333324948942417
Validation loss: 2.371049694233074

Epoch: 6| Step: 12
Training loss: 1.431719976830761
Validation loss: 2.426335342352681

Epoch: 6| Step: 13
Training loss: 1.1361036176571708
Validation loss: 2.454180990044618

Epoch: 343| Step: 0
Training loss: 1.739609251761992
Validation loss: 2.4942825362708843

Epoch: 6| Step: 1
Training loss: 1.3501346962454066
Validation loss: 2.515878082611528

Epoch: 6| Step: 2
Training loss: 1.101745590253072
Validation loss: 2.527433646204526

Epoch: 6| Step: 3
Training loss: 1.317950285560053
Validation loss: 2.5026248590718683

Epoch: 6| Step: 4
Training loss: 1.1573205064716114
Validation loss: 2.468433053962067

Epoch: 6| Step: 5
Training loss: 0.7553104112412371
Validation loss: 2.445279708244571

Epoch: 6| Step: 6
Training loss: 0.9864946281472459
Validation loss: 2.414679493868101

Epoch: 6| Step: 7
Training loss: 1.3688601479998257
Validation loss: 2.424137063894244

Epoch: 6| Step: 8
Training loss: 1.2136763578442014
Validation loss: 2.408970196475653

Epoch: 6| Step: 9
Training loss: 0.7847935992011963
Validation loss: 2.446603858052493

Epoch: 6| Step: 10
Training loss: 1.5571572321232012
Validation loss: 2.4246569588858673

Epoch: 6| Step: 11
Training loss: 1.0822291003963205
Validation loss: 2.4410459096476287

Epoch: 6| Step: 12
Training loss: 1.4304299016455608
Validation loss: 2.4682533727269678

Epoch: 6| Step: 13
Training loss: 1.9120066286873934
Validation loss: 2.478496539189661

Epoch: 344| Step: 0
Training loss: 1.160829393736614
Validation loss: 2.4839439485079207

Epoch: 6| Step: 1
Training loss: 1.424614917858356
Validation loss: 2.5213700728787622

Epoch: 6| Step: 2
Training loss: 1.3497096685526337
Validation loss: 2.4906125094637512

Epoch: 6| Step: 3
Training loss: 1.621757794152847
Validation loss: 2.475129997549278

Epoch: 6| Step: 4
Training loss: 0.8882283875262263
Validation loss: 2.4516010147520517

Epoch: 6| Step: 5
Training loss: 1.36951675363845
Validation loss: 2.4541932755696747

Epoch: 6| Step: 6
Training loss: 1.5876146290161581
Validation loss: 2.4281251313850944

Epoch: 6| Step: 7
Training loss: 1.2201645296186903
Validation loss: 2.389349982210154

Epoch: 6| Step: 8
Training loss: 1.2229754728944202
Validation loss: 2.416770793494731

Epoch: 6| Step: 9
Training loss: 1.2931709707652046
Validation loss: 2.4012355924102144

Epoch: 6| Step: 10
Training loss: 1.2252957551449748
Validation loss: 2.4437906482652862

Epoch: 6| Step: 11
Training loss: 1.390468888681964
Validation loss: 2.3903156187294803

Epoch: 6| Step: 12
Training loss: 1.1013315919230398
Validation loss: 2.393283894295296

Epoch: 6| Step: 13
Training loss: 0.8469954345201764
Validation loss: 2.4128819710673475

Epoch: 345| Step: 0
Training loss: 1.1690705374915833
Validation loss: 2.4671273008296715

Epoch: 6| Step: 1
Training loss: 1.2088873459145417
Validation loss: 2.525396035723321

Epoch: 6| Step: 2
Training loss: 1.115120636439608
Validation loss: 2.5746745457733256

Epoch: 6| Step: 3
Training loss: 0.9926056468860645
Validation loss: 2.5831976304813855

Epoch: 6| Step: 4
Training loss: 1.1936573212282706
Validation loss: 2.6024932965044365

Epoch: 6| Step: 5
Training loss: 1.2247623427159038
Validation loss: 2.5742179522913875

Epoch: 6| Step: 6
Training loss: 1.1631548626492947
Validation loss: 2.5084321225761435

Epoch: 6| Step: 7
Training loss: 1.3669123781498156
Validation loss: 2.445155511171691

Epoch: 6| Step: 8
Training loss: 1.6576209242540287
Validation loss: 2.386825003565769

Epoch: 6| Step: 9
Training loss: 0.915672351797522
Validation loss: 2.3577528768573703

Epoch: 6| Step: 10
Training loss: 1.1717519059699826
Validation loss: 2.338292394701906

Epoch: 6| Step: 11
Training loss: 1.457508571462144
Validation loss: 2.3202840616104776

Epoch: 6| Step: 12
Training loss: 1.7018810243811644
Validation loss: 2.374740985850304

Epoch: 6| Step: 13
Training loss: 1.4930462987253037
Validation loss: 2.417881337534879

Epoch: 346| Step: 0
Training loss: 1.3562140271035088
Validation loss: 2.476266083609078

Epoch: 6| Step: 1
Training loss: 1.2290759726648435
Validation loss: 2.5179184105358927

Epoch: 6| Step: 2
Training loss: 1.2079674506633788
Validation loss: 2.5219225895042614

Epoch: 6| Step: 3
Training loss: 1.5303839745246326
Validation loss: 2.509310326452663

Epoch: 6| Step: 4
Training loss: 1.7689738290380825
Validation loss: 2.4902847808040978

Epoch: 6| Step: 5
Training loss: 1.0209195561228894
Validation loss: 2.4504494017775365

Epoch: 6| Step: 6
Training loss: 0.8566940450993703
Validation loss: 2.3948625763833897

Epoch: 6| Step: 7
Training loss: 1.096093473753891
Validation loss: 2.3501951282495446

Epoch: 6| Step: 8
Training loss: 1.7441506721916311
Validation loss: 2.342038558616416

Epoch: 6| Step: 9
Training loss: 0.9844142058300378
Validation loss: 2.3543750112825776

Epoch: 6| Step: 10
Training loss: 1.1569056327469691
Validation loss: 2.3697751965649654

Epoch: 6| Step: 11
Training loss: 1.3409850484027304
Validation loss: 2.3882520417036073

Epoch: 6| Step: 12
Training loss: 1.1744420228259687
Validation loss: 2.447640961197478

Epoch: 6| Step: 13
Training loss: 0.41006143473117757
Validation loss: 2.499541240561764

Epoch: 347| Step: 0
Training loss: 1.3028390547804178
Validation loss: 2.5141450501446085

Epoch: 6| Step: 1
Training loss: 1.7413084267085683
Validation loss: 2.5441375244743663

Epoch: 6| Step: 2
Training loss: 1.2346991584167553
Validation loss: 2.5172082627771784

Epoch: 6| Step: 3
Training loss: 1.1521889792780204
Validation loss: 2.5257445512162646

Epoch: 6| Step: 4
Training loss: 1.1242340447377548
Validation loss: 2.5002323370819726

Epoch: 6| Step: 5
Training loss: 0.9931983904312003
Validation loss: 2.422615804382014

Epoch: 6| Step: 6
Training loss: 1.4294312461124776
Validation loss: 2.3919526692957582

Epoch: 6| Step: 7
Training loss: 1.134649431645367
Validation loss: 2.383497555312138

Epoch: 6| Step: 8
Training loss: 1.0077731102631233
Validation loss: 2.361553732104943

Epoch: 6| Step: 9
Training loss: 1.4585792969864664
Validation loss: 2.3882458884803683

Epoch: 6| Step: 10
Training loss: 1.0770512638199912
Validation loss: 2.407427038179848

Epoch: 6| Step: 11
Training loss: 1.1032843693493413
Validation loss: 2.438737314897172

Epoch: 6| Step: 12
Training loss: 1.153512291107372
Validation loss: 2.519913847328427

Epoch: 6| Step: 13
Training loss: 1.5088534542034215
Validation loss: 2.5054801046649557

Epoch: 348| Step: 0
Training loss: 1.0171814949104496
Validation loss: 2.531796508680204

Epoch: 6| Step: 1
Training loss: 1.1711533931434008
Validation loss: 2.4930721501056436

Epoch: 6| Step: 2
Training loss: 1.658395565085731
Validation loss: 2.478800951306661

Epoch: 6| Step: 3
Training loss: 1.2197192323951582
Validation loss: 2.4238628463530234

Epoch: 6| Step: 4
Training loss: 1.1584000058276878
Validation loss: 2.411404907666665

Epoch: 6| Step: 5
Training loss: 1.2961449923971557
Validation loss: 2.393118984557749

Epoch: 6| Step: 6
Training loss: 1.0768666318102251
Validation loss: 2.3749345188580544

Epoch: 6| Step: 7
Training loss: 1.2677184322626753
Validation loss: 2.415635829685239

Epoch: 6| Step: 8
Training loss: 0.911747012971044
Validation loss: 2.437966950680781

Epoch: 6| Step: 9
Training loss: 1.5051560794335619
Validation loss: 2.4975676804587157

Epoch: 6| Step: 10
Training loss: 1.587285263075977
Validation loss: 2.5028260613799476

Epoch: 6| Step: 11
Training loss: 1.0352812493625474
Validation loss: 2.487230736438186

Epoch: 6| Step: 12
Training loss: 1.1501097668216393
Validation loss: 2.451242299611093

Epoch: 6| Step: 13
Training loss: 1.1001468517073778
Validation loss: 2.4601717558240286

Epoch: 349| Step: 0
Training loss: 1.5831971946546886
Validation loss: 2.38289143448218

Epoch: 6| Step: 1
Training loss: 1.2074312207870117
Validation loss: 2.383207062361507

Epoch: 6| Step: 2
Training loss: 1.4492965636222948
Validation loss: 2.336321485962175

Epoch: 6| Step: 3
Training loss: 1.323786347046013
Validation loss: 2.3492379640210976

Epoch: 6| Step: 4
Training loss: 1.3941261707603008
Validation loss: 2.351652671920175

Epoch: 6| Step: 5
Training loss: 0.6574459758291603
Validation loss: 2.396500789732105

Epoch: 6| Step: 6
Training loss: 1.5475848332140836
Validation loss: 2.4458866707949287

Epoch: 6| Step: 7
Training loss: 0.9992153546452343
Validation loss: 2.492584655657409

Epoch: 6| Step: 8
Training loss: 0.9413279900529771
Validation loss: 2.478522164121462

Epoch: 6| Step: 9
Training loss: 1.4868806270767083
Validation loss: 2.4770140115481545

Epoch: 6| Step: 10
Training loss: 0.7948386408838679
Validation loss: 2.476730936686896

Epoch: 6| Step: 11
Training loss: 1.2890593557608434
Validation loss: 2.4613364661124617

Epoch: 6| Step: 12
Training loss: 0.903802526485578
Validation loss: 2.444146567765633

Epoch: 6| Step: 13
Training loss: 1.4152931211715294
Validation loss: 2.4612963634701703

Epoch: 350| Step: 0
Training loss: 1.3371181513380996
Validation loss: 2.4460806540573388

Epoch: 6| Step: 1
Training loss: 1.1014837142149057
Validation loss: 2.4537266137964795

Epoch: 6| Step: 2
Training loss: 1.2185545544533307
Validation loss: 2.467460583242971

Epoch: 6| Step: 3
Training loss: 1.401850706681654
Validation loss: 2.4591440588477975

Epoch: 6| Step: 4
Training loss: 1.6687698763117247
Validation loss: 2.474178880447317

Epoch: 6| Step: 5
Training loss: 1.3947486173763421
Validation loss: 2.481066054701502

Epoch: 6| Step: 6
Training loss: 1.1907128489367396
Validation loss: 2.4480510590124065

Epoch: 6| Step: 7
Training loss: 1.2901045777565716
Validation loss: 2.464473374827874

Epoch: 6| Step: 8
Training loss: 0.8766326658620036
Validation loss: 2.472797331130244

Epoch: 6| Step: 9
Training loss: 0.8334879413869765
Validation loss: 2.436042254033065

Epoch: 6| Step: 10
Training loss: 0.9372965591946245
Validation loss: 2.414889262455429

Epoch: 6| Step: 11
Training loss: 1.218494633061326
Validation loss: 2.39717349698577

Epoch: 6| Step: 12
Training loss: 1.4490974971912576
Validation loss: 2.418935476313547

Epoch: 6| Step: 13
Training loss: 0.6073558317631007
Validation loss: 2.384657437028717

Epoch: 351| Step: 0
Training loss: 0.7405106323400996
Validation loss: 2.3678258550048157

Epoch: 6| Step: 1
Training loss: 1.7693149863966129
Validation loss: 2.3972006638946834

Epoch: 6| Step: 2
Training loss: 1.3163385571923296
Validation loss: 2.3851059609500402

Epoch: 6| Step: 3
Training loss: 1.276871526846921
Validation loss: 2.425876036370375

Epoch: 6| Step: 4
Training loss: 1.2724964900989504
Validation loss: 2.450249685519095

Epoch: 6| Step: 5
Training loss: 1.2271223794956365
Validation loss: 2.4598089252581574

Epoch: 6| Step: 6
Training loss: 0.9310469105105436
Validation loss: 2.4368445117449355

Epoch: 6| Step: 7
Training loss: 1.4843839143184219
Validation loss: 2.4616921742585354

Epoch: 6| Step: 8
Training loss: 1.113352883694555
Validation loss: 2.535798711834751

Epoch: 6| Step: 9
Training loss: 1.1661441802398882
Validation loss: 2.541971906155667

Epoch: 6| Step: 10
Training loss: 0.959816627870638
Validation loss: 2.5284027266283755

Epoch: 6| Step: 11
Training loss: 0.8717671686576266
Validation loss: 2.511617899982388

Epoch: 6| Step: 12
Training loss: 1.286612847607588
Validation loss: 2.4903169078851026

Epoch: 6| Step: 13
Training loss: 1.305769329064559
Validation loss: 2.48384627370035

Epoch: 352| Step: 0
Training loss: 1.2445168397958795
Validation loss: 2.4615267567532793

Epoch: 6| Step: 1
Training loss: 1.2552011523958098
Validation loss: 2.46797572297322

Epoch: 6| Step: 2
Training loss: 1.1816252904480198
Validation loss: 2.4680655296288294

Epoch: 6| Step: 3
Training loss: 1.1151002178570624
Validation loss: 2.472656158761932

Epoch: 6| Step: 4
Training loss: 1.3630190271937244
Validation loss: 2.4224108158506463

Epoch: 6| Step: 5
Training loss: 1.0976542951356036
Validation loss: 2.392073274429487

Epoch: 6| Step: 6
Training loss: 1.1874941775530574
Validation loss: 2.4248860911874512

Epoch: 6| Step: 7
Training loss: 1.5876028403064775
Validation loss: 2.3947475949685493

Epoch: 6| Step: 8
Training loss: 1.298648403037995
Validation loss: 2.397226219950392

Epoch: 6| Step: 9
Training loss: 1.106962455167965
Validation loss: 2.41503009944006

Epoch: 6| Step: 10
Training loss: 1.0494961733264412
Validation loss: 2.4323426390816634

Epoch: 6| Step: 11
Training loss: 1.0508632698806506
Validation loss: 2.4416303471579153

Epoch: 6| Step: 12
Training loss: 0.7579219778363104
Validation loss: 2.432487337807745

Epoch: 6| Step: 13
Training loss: 1.422181819467719
Validation loss: 2.430727536103225

Epoch: 353| Step: 0
Training loss: 1.0077667225931495
Validation loss: 2.4594109059153366

Epoch: 6| Step: 1
Training loss: 0.8046011276555818
Validation loss: 2.455435875710517

Epoch: 6| Step: 2
Training loss: 1.190744334971271
Validation loss: 2.446580132825166

Epoch: 6| Step: 3
Training loss: 1.0309944414160999
Validation loss: 2.4516275889972015

Epoch: 6| Step: 4
Training loss: 1.8598602687483807
Validation loss: 2.4387791729233705

Epoch: 6| Step: 5
Training loss: 1.1620747537023786
Validation loss: 2.4245237359562726

Epoch: 6| Step: 6
Training loss: 1.3972764123292793
Validation loss: 2.3970697453926286

Epoch: 6| Step: 7
Training loss: 1.2473841476158527
Validation loss: 2.375853509823072

Epoch: 6| Step: 8
Training loss: 1.250925103230246
Validation loss: 2.3906129776010734

Epoch: 6| Step: 9
Training loss: 1.0735860730095064
Validation loss: 2.3886633163573974

Epoch: 6| Step: 10
Training loss: 0.8410468776510895
Validation loss: 2.4303256248282348

Epoch: 6| Step: 11
Training loss: 1.2501526739343245
Validation loss: 2.463583816417146

Epoch: 6| Step: 12
Training loss: 1.0820685424988512
Validation loss: 2.5173445546576168

Epoch: 6| Step: 13
Training loss: 1.4059134186502975
Validation loss: 2.5392080634130108

Epoch: 354| Step: 0
Training loss: 1.110081085302076
Validation loss: 2.4946461118573016

Epoch: 6| Step: 1
Training loss: 1.2193953932675283
Validation loss: 2.479287591723453

Epoch: 6| Step: 2
Training loss: 0.8529463556511577
Validation loss: 2.4299172187748

Epoch: 6| Step: 3
Training loss: 0.8893952831279625
Validation loss: 2.3790343538876093

Epoch: 6| Step: 4
Training loss: 1.4246161730316194
Validation loss: 2.358129002420691

Epoch: 6| Step: 5
Training loss: 1.1230474057403637
Validation loss: 2.380541977707036

Epoch: 6| Step: 6
Training loss: 1.190932482966854
Validation loss: 2.3717643315410974

Epoch: 6| Step: 7
Training loss: 0.7806205502605441
Validation loss: 2.447848871811277

Epoch: 6| Step: 8
Training loss: 1.0187519939379692
Validation loss: 2.5060004108935603

Epoch: 6| Step: 9
Training loss: 1.0561336069477607
Validation loss: 2.5910873281983435

Epoch: 6| Step: 10
Training loss: 1.71484375
Validation loss: 2.619427040422826

Epoch: 6| Step: 11
Training loss: 1.942002509982749
Validation loss: 2.6374525175071533

Epoch: 6| Step: 12
Training loss: 1.6112895059292494
Validation loss: 2.4706744243798715

Epoch: 6| Step: 13
Training loss: 1.0148671770805668
Validation loss: 2.37487356327547

Epoch: 355| Step: 0
Training loss: 1.2653128156522628
Validation loss: 2.320881965622393

Epoch: 6| Step: 1
Training loss: 1.6281973853833087
Validation loss: 2.3083739461228845

Epoch: 6| Step: 2
Training loss: 1.3755445702423479
Validation loss: 2.3043249291039323

Epoch: 6| Step: 3
Training loss: 1.408675496823073
Validation loss: 2.329868944952046

Epoch: 6| Step: 4
Training loss: 1.1278916389686426
Validation loss: 2.367871216374045

Epoch: 6| Step: 5
Training loss: 1.1746564281643825
Validation loss: 2.403869218209228

Epoch: 6| Step: 6
Training loss: 1.3534500084146845
Validation loss: 2.459873984958716

Epoch: 6| Step: 7
Training loss: 1.3528190020120558
Validation loss: 2.533290546949955

Epoch: 6| Step: 8
Training loss: 1.146030316615919
Validation loss: 2.551876889673417

Epoch: 6| Step: 9
Training loss: 1.037209601148132
Validation loss: 2.611300919174053

Epoch: 6| Step: 10
Training loss: 1.1543444835055658
Validation loss: 2.583693409441834

Epoch: 6| Step: 11
Training loss: 1.3275181000763316
Validation loss: 2.5350710433605386

Epoch: 6| Step: 12
Training loss: 0.9787139082547428
Validation loss: 2.493686054853342

Epoch: 6| Step: 13
Training loss: 0.9298406522888676
Validation loss: 2.4760540280144046

Epoch: 356| Step: 0
Training loss: 1.2096456219995813
Validation loss: 2.4803267078071567

Epoch: 6| Step: 1
Training loss: 1.093815229378158
Validation loss: 2.4770440866226693

Epoch: 6| Step: 2
Training loss: 0.8710999424461965
Validation loss: 2.433348771675763

Epoch: 6| Step: 3
Training loss: 0.8201037186645178
Validation loss: 2.4591896633267027

Epoch: 6| Step: 4
Training loss: 1.184143241008122
Validation loss: 2.4652069439423063

Epoch: 6| Step: 5
Training loss: 0.8276627167976062
Validation loss: 2.475375405606917

Epoch: 6| Step: 6
Training loss: 1.278475105816068
Validation loss: 2.4579321518449353

Epoch: 6| Step: 7
Training loss: 1.3843191527388867
Validation loss: 2.448916049841616

Epoch: 6| Step: 8
Training loss: 1.1660508449225708
Validation loss: 2.435027189968592

Epoch: 6| Step: 9
Training loss: 1.1782475961700725
Validation loss: 2.4171079763795884

Epoch: 6| Step: 10
Training loss: 1.5954502983995102
Validation loss: 2.386247786630989

Epoch: 6| Step: 11
Training loss: 1.2204021601641257
Validation loss: 2.374593410921371

Epoch: 6| Step: 12
Training loss: 1.6139853651997529
Validation loss: 2.3717116884129252

Epoch: 6| Step: 13
Training loss: 0.569185842420938
Validation loss: 2.4091820764336287

Epoch: 357| Step: 0
Training loss: 1.7005614139063139
Validation loss: 2.4033279437158197

Epoch: 6| Step: 1
Training loss: 1.0139994009456332
Validation loss: 2.447271507003458

Epoch: 6| Step: 2
Training loss: 1.3961275511814046
Validation loss: 2.4740093384403337

Epoch: 6| Step: 3
Training loss: 1.381786288929743
Validation loss: 2.500336314724384

Epoch: 6| Step: 4
Training loss: 1.0049231459046033
Validation loss: 2.507748033304929

Epoch: 6| Step: 5
Training loss: 1.1574588848251717
Validation loss: 2.4714446988996284

Epoch: 6| Step: 6
Training loss: 1.168040295709233
Validation loss: 2.4517681799782127

Epoch: 6| Step: 7
Training loss: 0.8037115307941309
Validation loss: 2.4451200479018578

Epoch: 6| Step: 8
Training loss: 1.1316206351250495
Validation loss: 2.412157644129574

Epoch: 6| Step: 9
Training loss: 0.9801776347418836
Validation loss: 2.3808809684702843

Epoch: 6| Step: 10
Training loss: 1.3079321256228116
Validation loss: 2.4080751324158958

Epoch: 6| Step: 11
Training loss: 0.7502818770000255
Validation loss: 2.3782135638786475

Epoch: 6| Step: 12
Training loss: 1.0890594723192817
Validation loss: 2.36300950182515

Epoch: 6| Step: 13
Training loss: 1.4337530645256251
Validation loss: 2.3944011379137837

Epoch: 358| Step: 0
Training loss: 0.9082102457403142
Validation loss: 2.4328409219353855

Epoch: 6| Step: 1
Training loss: 1.4011603332333438
Validation loss: 2.432516844153141

Epoch: 6| Step: 2
Training loss: 1.370710705235835
Validation loss: 2.461079865410392

Epoch: 6| Step: 3
Training loss: 1.4694574153995097
Validation loss: 2.4248566400016287

Epoch: 6| Step: 4
Training loss: 1.053187398448593
Validation loss: 2.444366899183591

Epoch: 6| Step: 5
Training loss: 0.9932092526937794
Validation loss: 2.457266262248122

Epoch: 6| Step: 6
Training loss: 0.7746321189569253
Validation loss: 2.4438285278530247

Epoch: 6| Step: 7
Training loss: 1.5066909967556685
Validation loss: 2.467310983341682

Epoch: 6| Step: 8
Training loss: 0.9503063987729258
Validation loss: 2.5293206802966557

Epoch: 6| Step: 9
Training loss: 0.9191126412648036
Validation loss: 2.483830780418818

Epoch: 6| Step: 10
Training loss: 0.8087999385055495
Validation loss: 2.4614180158751653

Epoch: 6| Step: 11
Training loss: 0.7487099997609659
Validation loss: 2.4133576881749343

Epoch: 6| Step: 12
Training loss: 1.724851286738873
Validation loss: 2.3983836684873587

Epoch: 6| Step: 13
Training loss: 1.251330764023696
Validation loss: 2.4078551235098145

Epoch: 359| Step: 0
Training loss: 1.0226834846524528
Validation loss: 2.3503707238560563

Epoch: 6| Step: 1
Training loss: 1.5278402238664575
Validation loss: 2.3530569476580623

Epoch: 6| Step: 2
Training loss: 0.9620284733771706
Validation loss: 2.39599647733372

Epoch: 6| Step: 3
Training loss: 1.1691049006363872
Validation loss: 2.3914123928509508

Epoch: 6| Step: 4
Training loss: 1.2463986014917776
Validation loss: 2.4051997355516526

Epoch: 6| Step: 5
Training loss: 0.9092508159148169
Validation loss: 2.403358227264632

Epoch: 6| Step: 6
Training loss: 1.1683020482974034
Validation loss: 2.4000283890971286

Epoch: 6| Step: 7
Training loss: 1.4014739843206945
Validation loss: 2.4576525871026313

Epoch: 6| Step: 8
Training loss: 1.3398224853963518
Validation loss: 2.426767737410675

Epoch: 6| Step: 9
Training loss: 1.1137435221028775
Validation loss: 2.471351802907828

Epoch: 6| Step: 10
Training loss: 0.6385878061382418
Validation loss: 2.4723285317324275

Epoch: 6| Step: 11
Training loss: 0.7309558896429796
Validation loss: 2.495553804641684

Epoch: 6| Step: 12
Training loss: 1.5140610323840764
Validation loss: 2.5162394201366203

Epoch: 6| Step: 13
Training loss: 1.0349735890580045
Validation loss: 2.4686640346352973

Epoch: 360| Step: 0
Training loss: 0.7370144910849955
Validation loss: 2.4986785026256544

Epoch: 6| Step: 1
Training loss: 0.5921118876716842
Validation loss: 2.487651778106944

Epoch: 6| Step: 2
Training loss: 1.2270641394486523
Validation loss: 2.4622362550178605

Epoch: 6| Step: 3
Training loss: 1.007608319084713
Validation loss: 2.486779273221245

Epoch: 6| Step: 4
Training loss: 1.2495840334193367
Validation loss: 2.4908686110061873

Epoch: 6| Step: 5
Training loss: 1.3320734459242887
Validation loss: 2.4832504512447477

Epoch: 6| Step: 6
Training loss: 0.8106636422857956
Validation loss: 2.4935040217155904

Epoch: 6| Step: 7
Training loss: 0.9393389785164692
Validation loss: 2.4823085027439977

Epoch: 6| Step: 8
Training loss: 1.711874648585428
Validation loss: 2.485882237454114

Epoch: 6| Step: 9
Training loss: 1.1985017204733839
Validation loss: 2.456351268694777

Epoch: 6| Step: 10
Training loss: 1.1191325295573258
Validation loss: 2.4411045649037004

Epoch: 6| Step: 11
Training loss: 1.6041549913386088
Validation loss: 2.412124561070869

Epoch: 6| Step: 12
Training loss: 1.2213219134769961
Validation loss: 2.420556800566797

Epoch: 6| Step: 13
Training loss: 0.7215076287884719
Validation loss: 2.4268324889296857

Epoch: 361| Step: 0
Training loss: 0.9062388846932501
Validation loss: 2.439765492637864

Epoch: 6| Step: 1
Training loss: 1.596097003412502
Validation loss: 2.4935234491415392

Epoch: 6| Step: 2
Training loss: 0.9628646568526255
Validation loss: 2.533006908862316

Epoch: 6| Step: 3
Training loss: 0.8453518179671049
Validation loss: 2.494974716951616

Epoch: 6| Step: 4
Training loss: 1.453255760298265
Validation loss: 2.489541417477538

Epoch: 6| Step: 5
Training loss: 1.0547733413236597
Validation loss: 2.4450420707252007

Epoch: 6| Step: 6
Training loss: 0.7988642752006144
Validation loss: 2.4200132721320293

Epoch: 6| Step: 7
Training loss: 0.6436958679105707
Validation loss: 2.408050392012256

Epoch: 6| Step: 8
Training loss: 1.1347561702892484
Validation loss: 2.4340445587288304

Epoch: 6| Step: 9
Training loss: 1.2464628719243167
Validation loss: 2.415062475530725

Epoch: 6| Step: 10
Training loss: 1.1168122628410422
Validation loss: 2.4466965143772073

Epoch: 6| Step: 11
Training loss: 0.6444062776494787
Validation loss: 2.4926583419484962

Epoch: 6| Step: 12
Training loss: 1.3286365197170664
Validation loss: 2.510769707196799

Epoch: 6| Step: 13
Training loss: 2.308241041062176
Validation loss: 2.537790726804817

Epoch: 362| Step: 0
Training loss: 1.0081162105964683
Validation loss: 2.4853806537299024

Epoch: 6| Step: 1
Training loss: 1.2974202492079463
Validation loss: 2.435620570161365

Epoch: 6| Step: 2
Training loss: 0.7502205842202632
Validation loss: 2.4305696738009344

Epoch: 6| Step: 3
Training loss: 1.3289815496767077
Validation loss: 2.407079193943202

Epoch: 6| Step: 4
Training loss: 0.9745706309718963
Validation loss: 2.407105419396556

Epoch: 6| Step: 5
Training loss: 1.0437360933942108
Validation loss: 2.415654587550869

Epoch: 6| Step: 6
Training loss: 1.324358187285672
Validation loss: 2.411380036638942

Epoch: 6| Step: 7
Training loss: 1.302453875905667
Validation loss: 2.4373972997072704

Epoch: 6| Step: 8
Training loss: 0.8068355297123606
Validation loss: 2.4244516850763507

Epoch: 6| Step: 9
Training loss: 1.642800695918595
Validation loss: 2.3986901698007426

Epoch: 6| Step: 10
Training loss: 1.20663959358643
Validation loss: 2.409283784282685

Epoch: 6| Step: 11
Training loss: 1.1133344135640857
Validation loss: 2.419202249493687

Epoch: 6| Step: 12
Training loss: 1.1407976411781695
Validation loss: 2.3916252789370165

Epoch: 6| Step: 13
Training loss: 0.7997033284369796
Validation loss: 2.40135867463834

Epoch: 363| Step: 0
Training loss: 0.8534750154030678
Validation loss: 2.388936767239831

Epoch: 6| Step: 1
Training loss: 0.9448957549226784
Validation loss: 2.3881613626439027

Epoch: 6| Step: 2
Training loss: 1.4479096044281268
Validation loss: 2.368274565963298

Epoch: 6| Step: 3
Training loss: 1.2426388478364676
Validation loss: 2.412943612225397

Epoch: 6| Step: 4
Training loss: 0.980124850202699
Validation loss: 2.430280580528832

Epoch: 6| Step: 5
Training loss: 0.9909023462253704
Validation loss: 2.451179416855539

Epoch: 6| Step: 6
Training loss: 0.9278267262319888
Validation loss: 2.4877403695136002

Epoch: 6| Step: 7
Training loss: 1.2738457709818292
Validation loss: 2.4640407629470085

Epoch: 6| Step: 8
Training loss: 1.8671950336128746
Validation loss: 2.5243976574315905

Epoch: 6| Step: 9
Training loss: 0.7973772597854246
Validation loss: 2.509736067681377

Epoch: 6| Step: 10
Training loss: 1.1738036497487354
Validation loss: 2.484537796359026

Epoch: 6| Step: 11
Training loss: 1.2608277567361736
Validation loss: 2.465793473779835

Epoch: 6| Step: 12
Training loss: 1.100499120095788
Validation loss: 2.467331715266859

Epoch: 6| Step: 13
Training loss: 0.5821996355660392
Validation loss: 2.423118437766821

Epoch: 364| Step: 0
Training loss: 0.7529293312635952
Validation loss: 2.4344307955121733

Epoch: 6| Step: 1
Training loss: 1.3093330686132574
Validation loss: 2.4263432873650044

Epoch: 6| Step: 2
Training loss: 0.9335064069040753
Validation loss: 2.4509641808969604

Epoch: 6| Step: 3
Training loss: 1.260710511227017
Validation loss: 2.487039575721996

Epoch: 6| Step: 4
Training loss: 1.2367432486444496
Validation loss: 2.490297645120578

Epoch: 6| Step: 5
Training loss: 1.0903805740285692
Validation loss: 2.4919758975375204

Epoch: 6| Step: 6
Training loss: 0.8796427713680319
Validation loss: 2.4936345123854586

Epoch: 6| Step: 7
Training loss: 0.9842093494848715
Validation loss: 2.422535300639828

Epoch: 6| Step: 8
Training loss: 0.8392329634231828
Validation loss: 2.437592999482934

Epoch: 6| Step: 9
Training loss: 0.9087766743645099
Validation loss: 2.4506812845007016

Epoch: 6| Step: 10
Training loss: 1.1163127115197213
Validation loss: 2.437731005942037

Epoch: 6| Step: 11
Training loss: 1.698688994512929
Validation loss: 2.453448015480654

Epoch: 6| Step: 12
Training loss: 1.4205038984568137
Validation loss: 2.443881657839932

Epoch: 6| Step: 13
Training loss: 0.9636112634766154
Validation loss: 2.472573101692901

Epoch: 365| Step: 0
Training loss: 0.9017169641567295
Validation loss: 2.4341268114121677

Epoch: 6| Step: 1
Training loss: 1.085450701384362
Validation loss: 2.4660369443243226

Epoch: 6| Step: 2
Training loss: 1.5620571271777786
Validation loss: 2.432704932500774

Epoch: 6| Step: 3
Training loss: 1.6732760111931324
Validation loss: 2.421091669263325

Epoch: 6| Step: 4
Training loss: 1.0567770709434483
Validation loss: 2.4380401420938447

Epoch: 6| Step: 5
Training loss: 1.0115600815002548
Validation loss: 2.409343088292295

Epoch: 6| Step: 6
Training loss: 0.9757993233734868
Validation loss: 2.429269945287158

Epoch: 6| Step: 7
Training loss: 0.6679540264447745
Validation loss: 2.4432605619717873

Epoch: 6| Step: 8
Training loss: 0.9643151692528978
Validation loss: 2.438440036961315

Epoch: 6| Step: 9
Training loss: 0.7514765827137033
Validation loss: 2.436580197285175

Epoch: 6| Step: 10
Training loss: 1.2436105985491075
Validation loss: 2.4173433627982925

Epoch: 6| Step: 11
Training loss: 1.2812218081466349
Validation loss: 2.4205575758366207

Epoch: 6| Step: 12
Training loss: 1.0491732521446338
Validation loss: 2.432887437276316

Epoch: 6| Step: 13
Training loss: 1.0258393386698095
Validation loss: 2.443533008690444

Epoch: 366| Step: 0
Training loss: 1.2853986981010344
Validation loss: 2.472300035076239

Epoch: 6| Step: 1
Training loss: 1.6411959426705147
Validation loss: 2.485866373223243

Epoch: 6| Step: 2
Training loss: 1.12581303145944
Validation loss: 2.525638523710716

Epoch: 6| Step: 3
Training loss: 1.2644955811489331
Validation loss: 2.5310501501830127

Epoch: 6| Step: 4
Training loss: 1.2626679337108127
Validation loss: 2.531439279487688

Epoch: 6| Step: 5
Training loss: 1.1143321648546993
Validation loss: 2.4693966754955525

Epoch: 6| Step: 6
Training loss: 1.0870878315475896
Validation loss: 2.4316509042506045

Epoch: 6| Step: 7
Training loss: 1.3247953976700955
Validation loss: 2.37760444197863

Epoch: 6| Step: 8
Training loss: 0.7879465350927128
Validation loss: 2.372065231837985

Epoch: 6| Step: 9
Training loss: 0.8669449750605368
Validation loss: 2.3551238253397107

Epoch: 6| Step: 10
Training loss: 1.1479891985474817
Validation loss: 2.355498506069684

Epoch: 6| Step: 11
Training loss: 0.9928133034755396
Validation loss: 2.4011644143352324

Epoch: 6| Step: 12
Training loss: 0.6205284857255404
Validation loss: 2.427569664407454

Epoch: 6| Step: 13
Training loss: 0.7115798395898079
Validation loss: 2.4697441756640854

Epoch: 367| Step: 0
Training loss: 1.040154936876882
Validation loss: 2.4939371425377876

Epoch: 6| Step: 1
Training loss: 1.0957509402689467
Validation loss: 2.5086479626491185

Epoch: 6| Step: 2
Training loss: 1.1310230723016819
Validation loss: 2.5573774319669225

Epoch: 6| Step: 3
Training loss: 1.4137636996549012
Validation loss: 2.503805268070811

Epoch: 6| Step: 4
Training loss: 1.2276848681399881
Validation loss: 2.4899594460525796

Epoch: 6| Step: 5
Training loss: 0.9896267864658796
Validation loss: 2.4768023310243423

Epoch: 6| Step: 6
Training loss: 1.7383727317483106
Validation loss: 2.4572809454637996

Epoch: 6| Step: 7
Training loss: 0.8189558163603153
Validation loss: 2.4007685687092923

Epoch: 6| Step: 8
Training loss: 1.137226214314643
Validation loss: 2.4295509621038582

Epoch: 6| Step: 9
Training loss: 0.9928711465786968
Validation loss: 2.4398365921826977

Epoch: 6| Step: 10
Training loss: 0.7557353230880023
Validation loss: 2.4107134147382467

Epoch: 6| Step: 11
Training loss: 0.9271814244414874
Validation loss: 2.4035734566744615

Epoch: 6| Step: 12
Training loss: 0.8945235206236751
Validation loss: 2.474492706633996

Epoch: 6| Step: 13
Training loss: 1.0979834778138444
Validation loss: 2.4632400140352755

Epoch: 368| Step: 0
Training loss: 1.1290224008964898
Validation loss: 2.4845180118174777

Epoch: 6| Step: 1
Training loss: 0.8990211249766586
Validation loss: 2.5189481591681333

Epoch: 6| Step: 2
Training loss: 0.8724721087613095
Validation loss: 2.4921016950298944

Epoch: 6| Step: 3
Training loss: 1.1385352443689603
Validation loss: 2.4565721219783083

Epoch: 6| Step: 4
Training loss: 1.0473145658105358
Validation loss: 2.4225165971107234

Epoch: 6| Step: 5
Training loss: 1.204459008146013
Validation loss: 2.4105168905750043

Epoch: 6| Step: 6
Training loss: 1.3722193952592223
Validation loss: 2.445107843653852

Epoch: 6| Step: 7
Training loss: 1.0568960166749974
Validation loss: 2.4031235341811796

Epoch: 6| Step: 8
Training loss: 0.7212017371096983
Validation loss: 2.4082177337069517

Epoch: 6| Step: 9
Training loss: 1.4788362465324643
Validation loss: 2.4189906722648025

Epoch: 6| Step: 10
Training loss: 0.9516366062215678
Validation loss: 2.4710527669323294

Epoch: 6| Step: 11
Training loss: 1.1163409567039477
Validation loss: 2.5217261574458174

Epoch: 6| Step: 12
Training loss: 1.1645773958567769
Validation loss: 2.5122529067263746

Epoch: 6| Step: 13
Training loss: 1.405666823793227
Validation loss: 2.488528069489943

Epoch: 369| Step: 0
Training loss: 1.0951990610278879
Validation loss: 2.4842716746850084

Epoch: 6| Step: 1
Training loss: 0.5728763797351354
Validation loss: 2.4613326571082124

Epoch: 6| Step: 2
Training loss: 1.1447988464204373
Validation loss: 2.434521825911656

Epoch: 6| Step: 3
Training loss: 0.9566648443605654
Validation loss: 2.420547966497893

Epoch: 6| Step: 4
Training loss: 0.8561097621934602
Validation loss: 2.4208008150746263

Epoch: 6| Step: 5
Training loss: 0.8224876991905862
Validation loss: 2.4214927633691574

Epoch: 6| Step: 6
Training loss: 1.21392571698696
Validation loss: 2.389787307749257

Epoch: 6| Step: 7
Training loss: 0.6220796066380364
Validation loss: 2.410221884156836

Epoch: 6| Step: 8
Training loss: 1.5727194942486475
Validation loss: 2.4238644529492217

Epoch: 6| Step: 9
Training loss: 0.6894917031536548
Validation loss: 2.4532543080625846

Epoch: 6| Step: 10
Training loss: 1.3049561001347167
Validation loss: 2.5110616218429556

Epoch: 6| Step: 11
Training loss: 1.426958157509347
Validation loss: 2.5386563169137015

Epoch: 6| Step: 12
Training loss: 1.5681912342738744
Validation loss: 2.527643715969809

Epoch: 6| Step: 13
Training loss: 0.6555715414386243
Validation loss: 2.5085030633176433

Epoch: 370| Step: 0
Training loss: 0.7681596412017396
Validation loss: 2.500003054832315

Epoch: 6| Step: 1
Training loss: 1.5706517246946425
Validation loss: 2.5381301003404584

Epoch: 6| Step: 2
Training loss: 1.2850600557357366
Validation loss: 2.505075446881005

Epoch: 6| Step: 3
Training loss: 1.1689732037549478
Validation loss: 2.456897268873422

Epoch: 6| Step: 4
Training loss: 1.1037016315165769
Validation loss: 2.4231175966628014

Epoch: 6| Step: 5
Training loss: 0.6319241351635764
Validation loss: 2.368995529165703

Epoch: 6| Step: 6
Training loss: 1.4117475075001413
Validation loss: 2.3821920468328015

Epoch: 6| Step: 7
Training loss: 1.088023042410286
Validation loss: 2.390241958587391

Epoch: 6| Step: 8
Training loss: 0.6250218149192752
Validation loss: 2.3601282801507115

Epoch: 6| Step: 9
Training loss: 1.158925903614491
Validation loss: 2.409105042771847

Epoch: 6| Step: 10
Training loss: 1.254784487423454
Validation loss: 2.458453283065405

Epoch: 6| Step: 11
Training loss: 1.0035542267962432
Validation loss: 2.480426785197482

Epoch: 6| Step: 12
Training loss: 1.0162894789568828
Validation loss: 2.489336430354473

Epoch: 6| Step: 13
Training loss: 1.114204104547536
Validation loss: 2.4976281327896643

Epoch: 371| Step: 0
Training loss: 1.1502481317270747
Validation loss: 2.4610331667633116

Epoch: 6| Step: 1
Training loss: 0.4267067955127698
Validation loss: 2.45687522909949

Epoch: 6| Step: 2
Training loss: 1.1476056466265174
Validation loss: 2.4298297824724693

Epoch: 6| Step: 3
Training loss: 1.1831697516584947
Validation loss: 2.4200967919496814

Epoch: 6| Step: 4
Training loss: 0.7932702604700621
Validation loss: 2.3475184961639326

Epoch: 6| Step: 5
Training loss: 1.095329288892734
Validation loss: 2.3592412153198734

Epoch: 6| Step: 6
Training loss: 1.401310191839645
Validation loss: 2.362779951374522

Epoch: 6| Step: 7
Training loss: 0.9579734679432428
Validation loss: 2.4186307774221962

Epoch: 6| Step: 8
Training loss: 0.6390460490228846
Validation loss: 2.4213515166797968

Epoch: 6| Step: 9
Training loss: 1.2697021369362687
Validation loss: 2.438331530533189

Epoch: 6| Step: 10
Training loss: 1.6098957145277029
Validation loss: 2.4496238485872692

Epoch: 6| Step: 11
Training loss: 1.4250608531607278
Validation loss: 2.490610315978984

Epoch: 6| Step: 12
Training loss: 0.6470235092042735
Validation loss: 2.5217975659512173

Epoch: 6| Step: 13
Training loss: 1.0581439424499015
Validation loss: 2.551763261752234

Epoch: 372| Step: 0
Training loss: 1.0646293844177754
Validation loss: 2.525342559401451

Epoch: 6| Step: 1
Training loss: 0.700068761649922
Validation loss: 2.5287987089263986

Epoch: 6| Step: 2
Training loss: 1.1500824028014873
Validation loss: 2.4887418233925103

Epoch: 6| Step: 3
Training loss: 0.6819301307412204
Validation loss: 2.4608728023006217

Epoch: 6| Step: 4
Training loss: 0.8664413885312608
Validation loss: 2.3894753739785233

Epoch: 6| Step: 5
Training loss: 1.373994372832479
Validation loss: 2.4094491687499886

Epoch: 6| Step: 6
Training loss: 0.7464843845816571
Validation loss: 2.4098728013454878

Epoch: 6| Step: 7
Training loss: 0.9267935389233842
Validation loss: 2.396988358542895

Epoch: 6| Step: 8
Training loss: 1.3874592697763748
Validation loss: 2.403375920936772

Epoch: 6| Step: 9
Training loss: 1.0552082612821223
Validation loss: 2.4451637635635324

Epoch: 6| Step: 10
Training loss: 0.9894013220730985
Validation loss: 2.4549993728734805

Epoch: 6| Step: 11
Training loss: 0.9541043425005079
Validation loss: 2.4250975721659715

Epoch: 6| Step: 12
Training loss: 1.0777798528640363
Validation loss: 2.464514290197913

Epoch: 6| Step: 13
Training loss: 2.096202836981849
Validation loss: 2.4388497041589585

Epoch: 373| Step: 0
Training loss: 1.0892149502462614
Validation loss: 2.471389378314403

Epoch: 6| Step: 1
Training loss: 1.1737981655975531
Validation loss: 2.4546317473821126

Epoch: 6| Step: 2
Training loss: 0.5869429036954841
Validation loss: 2.4365270359240347

Epoch: 6| Step: 3
Training loss: 1.2019760293300044
Validation loss: 2.454258875325753

Epoch: 6| Step: 4
Training loss: 0.5864666139233757
Validation loss: 2.449110998508954

Epoch: 6| Step: 5
Training loss: 1.1885696412298368
Validation loss: 2.4798882057392007

Epoch: 6| Step: 6
Training loss: 0.9820385710353072
Validation loss: 2.469531086144997

Epoch: 6| Step: 7
Training loss: 0.9194684703206621
Validation loss: 2.481030993649138

Epoch: 6| Step: 8
Training loss: 1.3766574406872734
Validation loss: 2.4703871954029477

Epoch: 6| Step: 9
Training loss: 0.9953860592570847
Validation loss: 2.452770992705663

Epoch: 6| Step: 10
Training loss: 1.0398009694826627
Validation loss: 2.4719393746451668

Epoch: 6| Step: 11
Training loss: 1.439168459359742
Validation loss: 2.4471874637216597

Epoch: 6| Step: 12
Training loss: 1.0996253112397052
Validation loss: 2.4510801032653284

Epoch: 6| Step: 13
Training loss: 1.142523505054647
Validation loss: 2.405850158166215

Epoch: 374| Step: 0
Training loss: 0.5104438683663838
Validation loss: 2.4134564072778906

Epoch: 6| Step: 1
Training loss: 0.8999144645946808
Validation loss: 2.4086956236508255

Epoch: 6| Step: 2
Training loss: 0.785110927810969
Validation loss: 2.385818055046139

Epoch: 6| Step: 3
Training loss: 1.2315270126793745
Validation loss: 2.399542457239491

Epoch: 6| Step: 4
Training loss: 0.7787851359981167
Validation loss: 2.426930519168619

Epoch: 6| Step: 5
Training loss: 1.1577735863451302
Validation loss: 2.449208218950503

Epoch: 6| Step: 6
Training loss: 1.174231334626456
Validation loss: 2.4677711239852

Epoch: 6| Step: 7
Training loss: 1.1487136301254328
Validation loss: 2.5086325658255144

Epoch: 6| Step: 8
Training loss: 1.5257124909252102
Validation loss: 2.5378069240752774

Epoch: 6| Step: 9
Training loss: 0.9205087462221586
Validation loss: 2.519305155909429

Epoch: 6| Step: 10
Training loss: 0.8572337437309565
Validation loss: 2.48976451722317

Epoch: 6| Step: 11
Training loss: 1.479105137722843
Validation loss: 2.486948285359148

Epoch: 6| Step: 12
Training loss: 1.10103145271022
Validation loss: 2.4175903346514604

Epoch: 6| Step: 13
Training loss: 0.8738282736998539
Validation loss: 2.432172147616209

Epoch: 375| Step: 0
Training loss: 0.9229138227179277
Validation loss: 2.4383594080149926

Epoch: 6| Step: 1
Training loss: 1.61599923674877
Validation loss: 2.4551710608715633

Epoch: 6| Step: 2
Training loss: 1.048145548028221
Validation loss: 2.487071008741512

Epoch: 6| Step: 3
Training loss: 0.8613384358660414
Validation loss: 2.505000775459315

Epoch: 6| Step: 4
Training loss: 0.9300249593215711
Validation loss: 2.5004214649358194

Epoch: 6| Step: 5
Training loss: 1.0898247720576866
Validation loss: 2.4847556336177012

Epoch: 6| Step: 6
Training loss: 0.63773139045388
Validation loss: 2.43485958187976

Epoch: 6| Step: 7
Training loss: 1.2135864325958816
Validation loss: 2.389559720837453

Epoch: 6| Step: 8
Training loss: 0.8903978292293084
Validation loss: 2.327762046635046

Epoch: 6| Step: 9
Training loss: 1.1108408095806241
Validation loss: 2.3641914764689114

Epoch: 6| Step: 10
Training loss: 1.1022510946523172
Validation loss: 2.4025987830068534

Epoch: 6| Step: 11
Training loss: 1.300795317336073
Validation loss: 2.4383884448359265

Epoch: 6| Step: 12
Training loss: 1.1961092817717074
Validation loss: 2.452069917478112

Epoch: 6| Step: 13
Training loss: 0.6631228362253968
Validation loss: 2.4530055373159905

Epoch: 376| Step: 0
Training loss: 0.872892908093157
Validation loss: 2.4926565997086225

Epoch: 6| Step: 1
Training loss: 1.0718674328595295
Validation loss: 2.5118331310283653

Epoch: 6| Step: 2
Training loss: 0.9852390432999633
Validation loss: 2.4874288568058778

Epoch: 6| Step: 3
Training loss: 1.6498878209676389
Validation loss: 2.445021902634193

Epoch: 6| Step: 4
Training loss: 0.7850726638256277
Validation loss: 2.45985262583161

Epoch: 6| Step: 5
Training loss: 1.145517074404426
Validation loss: 2.4372038323444087

Epoch: 6| Step: 6
Training loss: 0.7461312968607813
Validation loss: 2.4467293840640996

Epoch: 6| Step: 7
Training loss: 1.1066906110823553
Validation loss: 2.441976738411925

Epoch: 6| Step: 8
Training loss: 0.7048104536292862
Validation loss: 2.448370815259281

Epoch: 6| Step: 9
Training loss: 1.111934771161507
Validation loss: 2.419037754377113

Epoch: 6| Step: 10
Training loss: 1.0531115590491433
Validation loss: 2.444360221494482

Epoch: 6| Step: 11
Training loss: 0.9771170605584227
Validation loss: 2.465585944036406

Epoch: 6| Step: 12
Training loss: 0.8101794777522814
Validation loss: 2.4702093707953288

Epoch: 6| Step: 13
Training loss: 1.4813341816992152
Validation loss: 2.497704902420974

Epoch: 377| Step: 0
Training loss: 0.7520536677532135
Validation loss: 2.485053285286736

Epoch: 6| Step: 1
Training loss: 1.1091779077095467
Validation loss: 2.426814253484088

Epoch: 6| Step: 2
Training loss: 0.7751009998343138
Validation loss: 2.408746762972901

Epoch: 6| Step: 3
Training loss: 0.8272539992456267
Validation loss: 2.409755629680794

Epoch: 6| Step: 4
Training loss: 0.8927122052945919
Validation loss: 2.4385310901098265

Epoch: 6| Step: 5
Training loss: 1.215865364925202
Validation loss: 2.4152973851734183

Epoch: 6| Step: 6
Training loss: 1.5678891894004012
Validation loss: 2.4123226142425955

Epoch: 6| Step: 7
Training loss: 1.2313293838083084
Validation loss: 2.509248044783219

Epoch: 6| Step: 8
Training loss: 1.1136076866873914
Validation loss: 2.5026015927167915

Epoch: 6| Step: 9
Training loss: 1.0698706835742033
Validation loss: 2.546292711837332

Epoch: 6| Step: 10
Training loss: 0.6552901969392386
Validation loss: 2.541155701395515

Epoch: 6| Step: 11
Training loss: 1.0656593697562289
Validation loss: 2.5482834983397566

Epoch: 6| Step: 12
Training loss: 0.9417824527707356
Validation loss: 2.512170338327582

Epoch: 6| Step: 13
Training loss: 1.1397645395953473
Validation loss: 2.4757060155718116

Epoch: 378| Step: 0
Training loss: 0.8900439056539285
Validation loss: 2.4007791910404643

Epoch: 6| Step: 1
Training loss: 0.7797534341397114
Validation loss: 2.3996881477214034

Epoch: 6| Step: 2
Training loss: 1.5878708804171033
Validation loss: 2.403390507251457

Epoch: 6| Step: 3
Training loss: 0.8810368462736858
Validation loss: 2.425650404461971

Epoch: 6| Step: 4
Training loss: 1.1107118637643814
Validation loss: 2.4548019264389445

Epoch: 6| Step: 5
Training loss: 1.154847196239129
Validation loss: 2.522333233005044

Epoch: 6| Step: 6
Training loss: 0.7506374987626484
Validation loss: 2.5244736790061344

Epoch: 6| Step: 7
Training loss: 0.970265556588175
Validation loss: 2.5861961632674286

Epoch: 6| Step: 8
Training loss: 1.1302968472511474
Validation loss: 2.529213261510021

Epoch: 6| Step: 9
Training loss: 1.3724641825131518
Validation loss: 2.438491351497367

Epoch: 6| Step: 10
Training loss: 1.2302282673606686
Validation loss: 2.329625465098253

Epoch: 6| Step: 11
Training loss: 1.032187526978906
Validation loss: 2.322675099654113

Epoch: 6| Step: 12
Training loss: 0.8338552549229196
Validation loss: 2.3323932312558764

Epoch: 6| Step: 13
Training loss: 1.1102256200218519
Validation loss: 2.3628182041887777

Epoch: 379| Step: 0
Training loss: 1.0949036100281548
Validation loss: 2.413414504149489

Epoch: 6| Step: 1
Training loss: 0.5536058383346448
Validation loss: 2.5035943992198733

Epoch: 6| Step: 2
Training loss: 0.8397356895301767
Validation loss: 2.546827246759753

Epoch: 6| Step: 3
Training loss: 0.9231553642325776
Validation loss: 2.624280468623191

Epoch: 6| Step: 4
Training loss: 0.9183795415626591
Validation loss: 2.6355285267353903

Epoch: 6| Step: 5
Training loss: 0.9669933697395287
Validation loss: 2.577622360597494

Epoch: 6| Step: 6
Training loss: 1.6703983095714083
Validation loss: 2.537156578072679

Epoch: 6| Step: 7
Training loss: 1.2703738189574667
Validation loss: 2.4763587357241423

Epoch: 6| Step: 8
Training loss: 1.0618523138271183
Validation loss: 2.456237012481316

Epoch: 6| Step: 9
Training loss: 1.1007345348054094
Validation loss: 2.431950079934759

Epoch: 6| Step: 10
Training loss: 1.1303484722864687
Validation loss: 2.403910599866185

Epoch: 6| Step: 11
Training loss: 0.9763411614401694
Validation loss: 2.379249469191217

Epoch: 6| Step: 12
Training loss: 0.671847054543511
Validation loss: 2.3914632459656544

Epoch: 6| Step: 13
Training loss: 1.1132252997008207
Validation loss: 2.4394878215294926

Epoch: 380| Step: 0
Training loss: 0.7220665252396368
Validation loss: 2.453633682246975

Epoch: 6| Step: 1
Training loss: 1.0256431631912675
Validation loss: 2.476737696853651

Epoch: 6| Step: 2
Training loss: 1.1831875850126745
Validation loss: 2.474098102310863

Epoch: 6| Step: 3
Training loss: 0.8968608788631357
Validation loss: 2.4969367692913984

Epoch: 6| Step: 4
Training loss: 1.2636299892836094
Validation loss: 2.478428699177301

Epoch: 6| Step: 5
Training loss: 1.1123905299472543
Validation loss: 2.4738049648825817

Epoch: 6| Step: 6
Training loss: 0.7946860223622148
Validation loss: 2.491405097691743

Epoch: 6| Step: 7
Training loss: 1.5379078983017993
Validation loss: 2.5169795623800484

Epoch: 6| Step: 8
Training loss: 0.8946811600386205
Validation loss: 2.5218485831326336

Epoch: 6| Step: 9
Training loss: 1.0445870977292566
Validation loss: 2.508856966982831

Epoch: 6| Step: 10
Training loss: 1.0169816566245866
Validation loss: 2.5047510650042533

Epoch: 6| Step: 11
Training loss: 0.8461367088112987
Validation loss: 2.459056754758552

Epoch: 6| Step: 12
Training loss: 0.9094571879367994
Validation loss: 2.444456737342283

Epoch: 6| Step: 13
Training loss: 0.6877473256257787
Validation loss: 2.45597119008088

Epoch: 381| Step: 0
Training loss: 0.8294897170599286
Validation loss: 2.4466237406678335

Epoch: 6| Step: 1
Training loss: 1.0861142241120882
Validation loss: 2.4512714494699

Epoch: 6| Step: 2
Training loss: 0.861987840929593
Validation loss: 2.4640330991913713

Epoch: 6| Step: 3
Training loss: 1.0066949725329333
Validation loss: 2.451227652387366

Epoch: 6| Step: 4
Training loss: 0.9815443605764744
Validation loss: 2.5317417904162243

Epoch: 6| Step: 5
Training loss: 0.9157855755609927
Validation loss: 2.5381670194530703

Epoch: 6| Step: 6
Training loss: 0.9191743117424064
Validation loss: 2.5669264869910755

Epoch: 6| Step: 7
Training loss: 0.8014005917628108
Validation loss: 2.5497706405226515

Epoch: 6| Step: 8
Training loss: 1.2768271798670776
Validation loss: 2.50102769996303

Epoch: 6| Step: 9
Training loss: 1.0705243200384105
Validation loss: 2.4594631702910745

Epoch: 6| Step: 10
Training loss: 1.55245105389824
Validation loss: 2.4563941050554017

Epoch: 6| Step: 11
Training loss: 0.9672359509881137
Validation loss: 2.455755335387887

Epoch: 6| Step: 12
Training loss: 0.8207338613340437
Validation loss: 2.464436407587131

Epoch: 6| Step: 13
Training loss: 1.2258967639962848
Validation loss: 2.4504399933545438

Epoch: 382| Step: 0
Training loss: 0.9941376271980219
Validation loss: 2.4398961969391935

Epoch: 6| Step: 1
Training loss: 1.2219551196745735
Validation loss: 2.4138277123310643

Epoch: 6| Step: 2
Training loss: 0.9022126866396823
Validation loss: 2.391874970608339

Epoch: 6| Step: 3
Training loss: 1.587730108690004
Validation loss: 2.402637676136408

Epoch: 6| Step: 4
Training loss: 0.7529248189212122
Validation loss: 2.421181697630118

Epoch: 6| Step: 5
Training loss: 0.9642774951170767
Validation loss: 2.4314713147460583

Epoch: 6| Step: 6
Training loss: 1.4383113064337247
Validation loss: 2.429645973876554

Epoch: 6| Step: 7
Training loss: 0.642222714908848
Validation loss: 2.444095578598222

Epoch: 6| Step: 8
Training loss: 1.0399746440584134
Validation loss: 2.4252315299497726

Epoch: 6| Step: 9
Training loss: 0.9250357157023789
Validation loss: 2.440745380564006

Epoch: 6| Step: 10
Training loss: 0.7861162835510012
Validation loss: 2.4532341897194816

Epoch: 6| Step: 11
Training loss: 0.8482956825724778
Validation loss: 2.467914904237521

Epoch: 6| Step: 12
Training loss: 0.77524025177201
Validation loss: 2.503697618264378

Epoch: 6| Step: 13
Training loss: 0.8317704485990096
Validation loss: 2.4919343446186764

Epoch: 383| Step: 0
Training loss: 0.9776586255591406
Validation loss: 2.526347144003966

Epoch: 6| Step: 1
Training loss: 1.0845164050158085
Validation loss: 2.539019790176612

Epoch: 6| Step: 2
Training loss: 0.6204956821964603
Validation loss: 2.4807238236338076

Epoch: 6| Step: 3
Training loss: 0.7664824374999402
Validation loss: 2.469590066599957

Epoch: 6| Step: 4
Training loss: 1.0837034669101668
Validation loss: 2.435383290172014

Epoch: 6| Step: 5
Training loss: 1.106947701477424
Validation loss: 2.4376046342586175

Epoch: 6| Step: 6
Training loss: 0.8986602838699429
Validation loss: 2.373549620282216

Epoch: 6| Step: 7
Training loss: 1.173719759745534
Validation loss: 2.4031417603079426

Epoch: 6| Step: 8
Training loss: 1.0918703549247506
Validation loss: 2.391204754034514

Epoch: 6| Step: 9
Training loss: 1.4184819913627937
Validation loss: 2.4189793981111043

Epoch: 6| Step: 10
Training loss: 1.0709419348797167
Validation loss: 2.444628968604687

Epoch: 6| Step: 11
Training loss: 0.6369901207527594
Validation loss: 2.463419066049878

Epoch: 6| Step: 12
Training loss: 1.073047790415859
Validation loss: 2.512590593355579

Epoch: 6| Step: 13
Training loss: 0.7697448434040618
Validation loss: 2.5001706249708415

Epoch: 384| Step: 0
Training loss: 0.6811727541254905
Validation loss: 2.505129923290671

Epoch: 6| Step: 1
Training loss: 0.8153783724965257
Validation loss: 2.4509972757600043

Epoch: 6| Step: 2
Training loss: 0.963384288960349
Validation loss: 2.435890204672268

Epoch: 6| Step: 3
Training loss: 0.8093606380528718
Validation loss: 2.404270592254274

Epoch: 6| Step: 4
Training loss: 1.0617985934676617
Validation loss: 2.4157015866405285

Epoch: 6| Step: 5
Training loss: 1.2304504877582039
Validation loss: 2.43594489962847

Epoch: 6| Step: 6
Training loss: 0.8487727112463297
Validation loss: 2.4840573673866784

Epoch: 6| Step: 7
Training loss: 0.9322346646803787
Validation loss: 2.506948369278131

Epoch: 6| Step: 8
Training loss: 1.7652961627287291
Validation loss: 2.5336829357814175

Epoch: 6| Step: 9
Training loss: 1.0663686892423672
Validation loss: 2.5666695344533617

Epoch: 6| Step: 10
Training loss: 0.8984923967921784
Validation loss: 2.531891934227607

Epoch: 6| Step: 11
Training loss: 0.44723015856990117
Validation loss: 2.482407410715863

Epoch: 6| Step: 12
Training loss: 0.9961842514512604
Validation loss: 2.4119465894282044

Epoch: 6| Step: 13
Training loss: 1.1183666062462687
Validation loss: 2.394068415557458

Epoch: 385| Step: 0
Training loss: 0.8273455712547825
Validation loss: 2.3616994452535813

Epoch: 6| Step: 1
Training loss: 0.8580270773298553
Validation loss: 2.3815916705278535

Epoch: 6| Step: 2
Training loss: 1.0609070673806853
Validation loss: 2.3730863099894073

Epoch: 6| Step: 3
Training loss: 1.2297459008043263
Validation loss: 2.397833064413302

Epoch: 6| Step: 4
Training loss: 1.2404195812440117
Validation loss: 2.4520912529165817

Epoch: 6| Step: 5
Training loss: 1.019663484263081
Validation loss: 2.500305321722708

Epoch: 6| Step: 6
Training loss: 0.7794614154473807
Validation loss: 2.535471891635151

Epoch: 6| Step: 7
Training loss: 1.6206826297680508
Validation loss: 2.579456478487953

Epoch: 6| Step: 8
Training loss: 0.9675187623622183
Validation loss: 2.6261281169152717

Epoch: 6| Step: 9
Training loss: 0.7580911183156867
Validation loss: 2.5710392905082835

Epoch: 6| Step: 10
Training loss: 0.8271962481916297
Validation loss: 2.5067459448798357

Epoch: 6| Step: 11
Training loss: 0.7954678546733385
Validation loss: 2.441459477326357

Epoch: 6| Step: 12
Training loss: 0.9037918427253073
Validation loss: 2.391912841718751

Epoch: 6| Step: 13
Training loss: 0.8665289569227201
Validation loss: 2.4083828933299634

Epoch: 386| Step: 0
Training loss: 0.8124894728345404
Validation loss: 2.409434601557413

Epoch: 6| Step: 1
Training loss: 1.1423518551828653
Validation loss: 2.403095343952848

Epoch: 6| Step: 2
Training loss: 1.2685538417469755
Validation loss: 2.427722898574668

Epoch: 6| Step: 3
Training loss: 0.6299404384068755
Validation loss: 2.4178016996255693

Epoch: 6| Step: 4
Training loss: 1.2319565270791974
Validation loss: 2.4744962239423103

Epoch: 6| Step: 5
Training loss: 1.5340702787611207
Validation loss: 2.5106053145953298

Epoch: 6| Step: 6
Training loss: 0.706707369139022
Validation loss: 2.594890643650986

Epoch: 6| Step: 7
Training loss: 0.6716675770858325
Validation loss: 2.5817275903584918

Epoch: 6| Step: 8
Training loss: 0.9085836290236967
Validation loss: 2.5771749884656834

Epoch: 6| Step: 9
Training loss: 0.8590902029977697
Validation loss: 2.536611725495982

Epoch: 6| Step: 10
Training loss: 1.1201354925760167
Validation loss: 2.517496744494654

Epoch: 6| Step: 11
Training loss: 0.967433342325432
Validation loss: 2.4574936794942936

Epoch: 6| Step: 12
Training loss: 0.8379022201767264
Validation loss: 2.4425531194539905

Epoch: 6| Step: 13
Training loss: 0.9348242403774834
Validation loss: 2.4513969053679445

Epoch: 387| Step: 0
Training loss: 0.9989028514826326
Validation loss: 2.4450843744201585

Epoch: 6| Step: 1
Training loss: 0.8328622599152208
Validation loss: 2.4675549810246302

Epoch: 6| Step: 2
Training loss: 0.8415864119335701
Validation loss: 2.47027904926338

Epoch: 6| Step: 3
Training loss: 1.232257813961169
Validation loss: 2.5014687218011624

Epoch: 6| Step: 4
Training loss: 1.0350379732325405
Validation loss: 2.4938645456543194

Epoch: 6| Step: 5
Training loss: 0.38435564612688805
Validation loss: 2.5406392729386464

Epoch: 6| Step: 6
Training loss: 1.3225667095125446
Validation loss: 2.534563883834285

Epoch: 6| Step: 7
Training loss: 0.9372730298269275
Validation loss: 2.516090547182132

Epoch: 6| Step: 8
Training loss: 0.771573488907335
Validation loss: 2.394046633702331

Epoch: 6| Step: 9
Training loss: 1.7785439264268905
Validation loss: 2.3785667417618934

Epoch: 6| Step: 10
Training loss: 0.6636989046893867
Validation loss: 2.3388802141064056

Epoch: 6| Step: 11
Training loss: 0.9686110919914345
Validation loss: 2.3546844408149985

Epoch: 6| Step: 12
Training loss: 0.5664100909924991
Validation loss: 2.394481619678039

Epoch: 6| Step: 13
Training loss: 1.1057484411116083
Validation loss: 2.3814395848773033

Epoch: 388| Step: 0
Training loss: 0.8418411632667885
Validation loss: 2.422029926532897

Epoch: 6| Step: 1
Training loss: 1.0501115217475687
Validation loss: 2.447024358490958

Epoch: 6| Step: 2
Training loss: 1.0242907047093155
Validation loss: 2.5220555395489046

Epoch: 6| Step: 3
Training loss: 0.8812347762504087
Validation loss: 2.582194626789164

Epoch: 6| Step: 4
Training loss: 0.9067098831881774
Validation loss: 2.551239537838338

Epoch: 6| Step: 5
Training loss: 1.6106768777446776
Validation loss: 2.525994665234862

Epoch: 6| Step: 6
Training loss: 0.8848837127364382
Validation loss: 2.5147599603199806

Epoch: 6| Step: 7
Training loss: 0.7202561809508944
Validation loss: 2.4884674877797623

Epoch: 6| Step: 8
Training loss: 0.9398213574920012
Validation loss: 2.448485269969254

Epoch: 6| Step: 9
Training loss: 0.8135512593607814
Validation loss: 2.4624398105416168

Epoch: 6| Step: 10
Training loss: 0.9875305098637116
Validation loss: 2.437343160096959

Epoch: 6| Step: 11
Training loss: 1.0266085122304573
Validation loss: 2.3937856290223

Epoch: 6| Step: 12
Training loss: 1.112518423977999
Validation loss: 2.427358735717304

Epoch: 6| Step: 13
Training loss: 0.7809818188996935
Validation loss: 2.4397842572767403

Epoch: 389| Step: 0
Training loss: 0.8619938913491773
Validation loss: 2.468745690483879

Epoch: 6| Step: 1
Training loss: 1.1650996867903607
Validation loss: 2.462274800383643

Epoch: 6| Step: 2
Training loss: 0.6945565218023292
Validation loss: 2.4674585011274406

Epoch: 6| Step: 3
Training loss: 1.1018122396700885
Validation loss: 2.458927840449967

Epoch: 6| Step: 4
Training loss: 0.7129056746057011
Validation loss: 2.4782064513267117

Epoch: 6| Step: 5
Training loss: 0.7698993867312058
Validation loss: 2.4988204665314977

Epoch: 6| Step: 6
Training loss: 1.021579541063934
Validation loss: 2.4969375331667054

Epoch: 6| Step: 7
Training loss: 0.8048212625379493
Validation loss: 2.4993471677615964

Epoch: 6| Step: 8
Training loss: 0.7165848005096195
Validation loss: 2.527840222146306

Epoch: 6| Step: 9
Training loss: 0.8242641996896658
Validation loss: 2.5146851375907215

Epoch: 6| Step: 10
Training loss: 1.6258147471330302
Validation loss: 2.496409698142738

Epoch: 6| Step: 11
Training loss: 1.1199076688548697
Validation loss: 2.4560787950876

Epoch: 6| Step: 12
Training loss: 0.5988567736118771
Validation loss: 2.432125914262856

Epoch: 6| Step: 13
Training loss: 1.1204446116166589
Validation loss: 2.411260428013381

Epoch: 390| Step: 0
Training loss: 0.8776703685991987
Validation loss: 2.4244551692413996

Epoch: 6| Step: 1
Training loss: 0.8009815988891588
Validation loss: 2.4193570568389022

Epoch: 6| Step: 2
Training loss: 1.0648542575779547
Validation loss: 2.413823782689349

Epoch: 6| Step: 3
Training loss: 1.1351890627482668
Validation loss: 2.4040193567596044

Epoch: 6| Step: 4
Training loss: 0.9650860069173528
Validation loss: 2.415335298734433

Epoch: 6| Step: 5
Training loss: 1.6830315237509887
Validation loss: 2.454435178516458

Epoch: 6| Step: 6
Training loss: 0.7672087967474706
Validation loss: 2.5016779457402

Epoch: 6| Step: 7
Training loss: 0.794127646291855
Validation loss: 2.5430509837721305

Epoch: 6| Step: 8
Training loss: 0.9039548552558232
Validation loss: 2.51358737662185

Epoch: 6| Step: 9
Training loss: 1.1347310623972167
Validation loss: 2.457067640548199

Epoch: 6| Step: 10
Training loss: 0.5708730372893605
Validation loss: 2.441069304285524

Epoch: 6| Step: 11
Training loss: 0.8463699495849104
Validation loss: 2.3984844073174267

Epoch: 6| Step: 12
Training loss: 0.8967409452412451
Validation loss: 2.3601472398007313

Epoch: 6| Step: 13
Training loss: 0.836663545840802
Validation loss: 2.364016258679386

Epoch: 391| Step: 0
Training loss: 0.8086584314101
Validation loss: 2.3484362785236788

Epoch: 6| Step: 1
Training loss: 1.3583944445399843
Validation loss: 2.3774324168252736

Epoch: 6| Step: 2
Training loss: 1.0123068966805553
Validation loss: 2.384961286590779

Epoch: 6| Step: 3
Training loss: 1.2396456064348482
Validation loss: 2.4304171027514543

Epoch: 6| Step: 4
Training loss: 0.7374232316876103
Validation loss: 2.448552798366673

Epoch: 6| Step: 5
Training loss: 1.2986312372797917
Validation loss: 2.4593461326141948

Epoch: 6| Step: 6
Training loss: 0.8314866625392264
Validation loss: 2.4613047856833665

Epoch: 6| Step: 7
Training loss: 0.7364088666850384
Validation loss: 2.5122475758646394

Epoch: 6| Step: 8
Training loss: 0.8274517921742299
Validation loss: 2.487191640888219

Epoch: 6| Step: 9
Training loss: 0.9383356820230129
Validation loss: 2.4714102834909273

Epoch: 6| Step: 10
Training loss: 0.8441992729181169
Validation loss: 2.5104133031678995

Epoch: 6| Step: 11
Training loss: 0.8354643436313546
Validation loss: 2.4737570348599167

Epoch: 6| Step: 12
Training loss: 0.7728960473188423
Validation loss: 2.4423426358677607

Epoch: 6| Step: 13
Training loss: 0.900098376725463
Validation loss: 2.4122067795203828

Epoch: 392| Step: 0
Training loss: 1.1596246908042918
Validation loss: 2.475882431177263

Epoch: 6| Step: 1
Training loss: 0.7199828727989791
Validation loss: 2.496573084714786

Epoch: 6| Step: 2
Training loss: 0.5714129191409204
Validation loss: 2.4934419785757047

Epoch: 6| Step: 3
Training loss: 0.9880889584882905
Validation loss: 2.508998266077107

Epoch: 6| Step: 4
Training loss: 0.8547139779126738
Validation loss: 2.5691023897042014

Epoch: 6| Step: 5
Training loss: 0.9720731159190474
Validation loss: 2.558041114494738

Epoch: 6| Step: 6
Training loss: 0.957989738208307
Validation loss: 2.5734064301042627

Epoch: 6| Step: 7
Training loss: 1.2678095014206177
Validation loss: 2.527497084374033

Epoch: 6| Step: 8
Training loss: 0.8294283489095873
Validation loss: 2.50848662266718

Epoch: 6| Step: 9
Training loss: 1.4734228754379686
Validation loss: 2.4788363939816533

Epoch: 6| Step: 10
Training loss: 0.6486901859500187
Validation loss: 2.4801789848067015

Epoch: 6| Step: 11
Training loss: 0.9150107917774598
Validation loss: 2.449345000265897

Epoch: 6| Step: 12
Training loss: 1.0068442846594157
Validation loss: 2.4242428026124467

Epoch: 6| Step: 13
Training loss: 0.543901534176497
Validation loss: 2.4283546991914693

Epoch: 393| Step: 0
Training loss: 0.8024897515899255
Validation loss: 2.4149765342860317

Epoch: 6| Step: 1
Training loss: 1.6939005091611854
Validation loss: 2.416434401686228

Epoch: 6| Step: 2
Training loss: 0.8357037012305604
Validation loss: 2.418500108956478

Epoch: 6| Step: 3
Training loss: 1.1145291478661186
Validation loss: 2.4316169772872294

Epoch: 6| Step: 4
Training loss: 0.829427809942018
Validation loss: 2.4265044304155117

Epoch: 6| Step: 5
Training loss: 0.9506116466600099
Validation loss: 2.424379021911066

Epoch: 6| Step: 6
Training loss: 1.3441926537587559
Validation loss: 2.440037011031095

Epoch: 6| Step: 7
Training loss: 0.9776700567532887
Validation loss: 2.4545348973815595

Epoch: 6| Step: 8
Training loss: 0.7357693684627781
Validation loss: 2.4305916420112803

Epoch: 6| Step: 9
Training loss: 0.5590551911287307
Validation loss: 2.457917769778238

Epoch: 6| Step: 10
Training loss: 0.7044323952146121
Validation loss: 2.457913730184863

Epoch: 6| Step: 11
Training loss: 0.3449373546336691
Validation loss: 2.418261919281745

Epoch: 6| Step: 12
Training loss: 0.7602797781303509
Validation loss: 2.472757411247516

Epoch: 6| Step: 13
Training loss: 0.8977956386407542
Validation loss: 2.489669102904864

Epoch: 394| Step: 0
Training loss: 0.7952537874685047
Validation loss: 2.4809903134658287

Epoch: 6| Step: 1
Training loss: 0.9179444005455782
Validation loss: 2.4747304115544524

Epoch: 6| Step: 2
Training loss: 1.064396679982796
Validation loss: 2.4917557212111627

Epoch: 6| Step: 3
Training loss: 0.7440979312053354
Validation loss: 2.4618565226432962

Epoch: 6| Step: 4
Training loss: 0.90609591917149
Validation loss: 2.489219258586496

Epoch: 6| Step: 5
Training loss: 0.8650514913128167
Validation loss: 2.4535216901713133

Epoch: 6| Step: 6
Training loss: 0.3380205863673518
Validation loss: 2.4691481927900174

Epoch: 6| Step: 7
Training loss: 0.9689087891418524
Validation loss: 2.4615191789043185

Epoch: 6| Step: 8
Training loss: 1.5331152629581968
Validation loss: 2.458758786300351

Epoch: 6| Step: 9
Training loss: 0.6888401883888176
Validation loss: 2.443798729027515

Epoch: 6| Step: 10
Training loss: 1.1879013788601422
Validation loss: 2.4596398571433817

Epoch: 6| Step: 11
Training loss: 0.8638971125615735
Validation loss: 2.509176697009481

Epoch: 6| Step: 12
Training loss: 0.9417953320320113
Validation loss: 2.506267505259643

Epoch: 6| Step: 13
Training loss: 0.7690275063549731
Validation loss: 2.4941254999160503

Epoch: 395| Step: 0
Training loss: 1.2332245499517263
Validation loss: 2.4678744135033837

Epoch: 6| Step: 1
Training loss: 0.996611397070867
Validation loss: 2.4715539780656006

Epoch: 6| Step: 2
Training loss: 1.0501472233692388
Validation loss: 2.420686087146378

Epoch: 6| Step: 3
Training loss: 1.0343672714636158
Validation loss: 2.4186978154892445

Epoch: 6| Step: 4
Training loss: 0.7801470027461875
Validation loss: 2.3775704247158136

Epoch: 6| Step: 5
Training loss: 0.8208042668910225
Validation loss: 2.4380233703401415

Epoch: 6| Step: 6
Training loss: 0.3217779110337671
Validation loss: 2.4554464280774035

Epoch: 6| Step: 7
Training loss: 0.7280869437165274
Validation loss: 2.507568145062521

Epoch: 6| Step: 8
Training loss: 0.765185716687553
Validation loss: 2.5221893130127144

Epoch: 6| Step: 9
Training loss: 1.4862866590132
Validation loss: 2.5413384063360476

Epoch: 6| Step: 10
Training loss: 0.9418488724292482
Validation loss: 2.5422655674578265

Epoch: 6| Step: 11
Training loss: 0.7479698201226237
Validation loss: 2.5351143844942072

Epoch: 6| Step: 12
Training loss: 0.9493406241084286
Validation loss: 2.5232680094380884

Epoch: 6| Step: 13
Training loss: 0.6784218810685131
Validation loss: 2.4426938546352446

Epoch: 396| Step: 0
Training loss: 0.6905127749162504
Validation loss: 2.4417493406020956

Epoch: 6| Step: 1
Training loss: 1.575357181677435
Validation loss: 2.4227831008332497

Epoch: 6| Step: 2
Training loss: 0.5799047551383274
Validation loss: 2.432879209628944

Epoch: 6| Step: 3
Training loss: 0.8970166456704487
Validation loss: 2.4400499319699653

Epoch: 6| Step: 4
Training loss: 0.826101025007642
Validation loss: 2.4623073892330614

Epoch: 6| Step: 5
Training loss: 0.5339851931919396
Validation loss: 2.48430017952122

Epoch: 6| Step: 6
Training loss: 0.9674919943268827
Validation loss: 2.4574599580435317

Epoch: 6| Step: 7
Training loss: 0.7021790605215288
Validation loss: 2.481259567421248

Epoch: 6| Step: 8
Training loss: 0.7439374671416206
Validation loss: 2.461404694410401

Epoch: 6| Step: 9
Training loss: 1.2690135663256539
Validation loss: 2.441347440277905

Epoch: 6| Step: 10
Training loss: 0.8310771360850641
Validation loss: 2.4720609370421838

Epoch: 6| Step: 11
Training loss: 1.0198643165923704
Validation loss: 2.4472423529739684

Epoch: 6| Step: 12
Training loss: 1.0101528937688953
Validation loss: 2.402082616961761

Epoch: 6| Step: 13
Training loss: 0.7214467417305067
Validation loss: 2.3869205120571557

Epoch: 397| Step: 0
Training loss: 0.9649433903074873
Validation loss: 2.35538427238525

Epoch: 6| Step: 1
Training loss: 1.1033262377239
Validation loss: 2.3860863186605537

Epoch: 6| Step: 2
Training loss: 0.8353339538787562
Validation loss: 2.3524533196156505

Epoch: 6| Step: 3
Training loss: 0.822884007703192
Validation loss: 2.411599624574402

Epoch: 6| Step: 4
Training loss: 0.513346783128429
Validation loss: 2.4665336260244564

Epoch: 6| Step: 5
Training loss: 0.5454848468015013
Validation loss: 2.516685399414485

Epoch: 6| Step: 6
Training loss: 1.6722304777333776
Validation loss: 2.5268420963370444

Epoch: 6| Step: 7
Training loss: 1.3799359418679757
Validation loss: 2.594111989955192

Epoch: 6| Step: 8
Training loss: 0.8521570002851108
Validation loss: 2.5933423137638476

Epoch: 6| Step: 9
Training loss: 0.72135312921516
Validation loss: 2.506696094059514

Epoch: 6| Step: 10
Training loss: 0.7725866627768706
Validation loss: 2.436860140695804

Epoch: 6| Step: 11
Training loss: 0.6673222140028277
Validation loss: 2.4136705970836787

Epoch: 6| Step: 12
Training loss: 0.7664981456418136
Validation loss: 2.388316789267834

Epoch: 6| Step: 13
Training loss: 0.9068071691487961
Validation loss: 2.3847212509702214

Epoch: 398| Step: 0
Training loss: 0.8494162153583821
Validation loss: 2.3535096971235245

Epoch: 6| Step: 1
Training loss: 0.6811628224650417
Validation loss: 2.4141390311424913

Epoch: 6| Step: 2
Training loss: 0.6476014964262536
Validation loss: 2.432084220536349

Epoch: 6| Step: 3
Training loss: 0.7205978357996695
Validation loss: 2.501648153494371

Epoch: 6| Step: 4
Training loss: 1.24811755533916
Validation loss: 2.5144832208193595

Epoch: 6| Step: 5
Training loss: 0.9706686155759019
Validation loss: 2.491321812620797

Epoch: 6| Step: 6
Training loss: 0.7500231659808276
Validation loss: 2.4420580132203376

Epoch: 6| Step: 7
Training loss: 1.3302574092900248
Validation loss: 2.395953889536025

Epoch: 6| Step: 8
Training loss: 0.6731511792942516
Validation loss: 2.454775278467624

Epoch: 6| Step: 9
Training loss: 0.8796363002587374
Validation loss: 2.4840248285756896

Epoch: 6| Step: 10
Training loss: 0.9683954143703947
Validation loss: 2.5272212486580297

Epoch: 6| Step: 11
Training loss: 1.0017485828089752
Validation loss: 2.5462472054961647

Epoch: 6| Step: 12
Training loss: 1.2998451324063018
Validation loss: 2.556711989868184

Epoch: 6| Step: 13
Training loss: 0.47568905630873304
Validation loss: 2.5535623536874708

Epoch: 399| Step: 0
Training loss: 0.7504059964243386
Validation loss: 2.452475874767952

Epoch: 6| Step: 1
Training loss: 0.5429725372401923
Validation loss: 2.4145237251453953

Epoch: 6| Step: 2
Training loss: 0.8735652468484559
Validation loss: 2.409314837829234

Epoch: 6| Step: 3
Training loss: 1.1238308235271304
Validation loss: 2.39434795176251

Epoch: 6| Step: 4
Training loss: 0.6737716429990487
Validation loss: 2.3669285277385153

Epoch: 6| Step: 5
Training loss: 0.7946067391602107
Validation loss: 2.4208259610223437

Epoch: 6| Step: 6
Training loss: 1.4434743378607393
Validation loss: 2.436083524845587

Epoch: 6| Step: 7
Training loss: 0.7174042251677315
Validation loss: 2.4740926187767767

Epoch: 6| Step: 8
Training loss: 0.9784969244291208
Validation loss: 2.557857317455466

Epoch: 6| Step: 9
Training loss: 1.1250597620031628
Validation loss: 2.561299883129097

Epoch: 6| Step: 10
Training loss: 0.6462264915189657
Validation loss: 2.5249149324424933

Epoch: 6| Step: 11
Training loss: 1.1811485085458613
Validation loss: 2.4728156004432305

Epoch: 6| Step: 12
Training loss: 1.0626176881124638
Validation loss: 2.4158413124369393

Epoch: 6| Step: 13
Training loss: 0.3943938780980248
Validation loss: 2.3763326426097664

Epoch: 400| Step: 0
Training loss: 1.2111321077558526
Validation loss: 2.3669517808827503

Epoch: 6| Step: 1
Training loss: 0.5755846554910488
Validation loss: 2.3455442816564442

Epoch: 6| Step: 2
Training loss: 0.815323179678753
Validation loss: 2.3771142448883062

Epoch: 6| Step: 3
Training loss: 1.2384853255042054
Validation loss: 2.35121396076821

Epoch: 6| Step: 4
Training loss: 0.7059878664595045
Validation loss: 2.3726579271852786

Epoch: 6| Step: 5
Training loss: 0.7718763683476848
Validation loss: 2.4697597147551216

Epoch: 6| Step: 6
Training loss: 1.350586158162152
Validation loss: 2.502612717570025

Epoch: 6| Step: 7
Training loss: 1.1386705140094247
Validation loss: 2.5774132047710707

Epoch: 6| Step: 8
Training loss: 0.8832195997494229
Validation loss: 2.567196536641641

Epoch: 6| Step: 9
Training loss: 0.6572243178897522
Validation loss: 2.5192591508879856

Epoch: 6| Step: 10
Training loss: 0.5093324070072405
Validation loss: 2.5020814316636906

Epoch: 6| Step: 11
Training loss: 1.0676857674547848
Validation loss: 2.401076828926004

Epoch: 6| Step: 12
Training loss: 0.735639173943182
Validation loss: 2.3906288069195334

Epoch: 6| Step: 13
Training loss: 0.6413244522850182
Validation loss: 2.3617073998334823

Testing loss: 2.3419060671825656
