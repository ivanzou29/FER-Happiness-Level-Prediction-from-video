Epoch: 1| Step: 0
Training loss: 5.809080123901367
Validation loss: 5.175893993787868

Epoch: 5| Step: 1
Training loss: 4.886571884155273
Validation loss: 5.163981740192701

Epoch: 5| Step: 2
Training loss: 5.557746410369873
Validation loss: 5.153262922840733

Epoch: 5| Step: 3
Training loss: 5.390339374542236
Validation loss: 5.143272522957094

Epoch: 5| Step: 4
Training loss: 5.233994007110596
Validation loss: 5.133594348866453

Epoch: 5| Step: 5
Training loss: 4.4319939613342285
Validation loss: 5.123171867862824

Epoch: 5| Step: 6
Training loss: 5.054999828338623
Validation loss: 5.112847292295066

Epoch: 5| Step: 7
Training loss: 4.60848331451416
Validation loss: 5.101716646584132

Epoch: 5| Step: 8
Training loss: 2.8520634174346924
Validation loss: 5.089719526229366

Epoch: 5| Step: 9
Training loss: 4.570110321044922
Validation loss: 5.077016697135023

Epoch: 5| Step: 10
Training loss: 5.844071388244629
Validation loss: 5.063162183248869

Epoch: 2| Step: 0
Training loss: 5.5836944580078125
Validation loss: 5.0483196627709175

Epoch: 5| Step: 1
Training loss: 3.9307148456573486
Validation loss: 5.032775986579157

Epoch: 5| Step: 2
Training loss: 3.3571064472198486
Validation loss: 5.015291029407132

Epoch: 5| Step: 3
Training loss: 4.963343143463135
Validation loss: 4.996915109695927

Epoch: 5| Step: 4
Training loss: 5.402824878692627
Validation loss: 4.97744414114183

Epoch: 5| Step: 5
Training loss: 4.961987495422363
Validation loss: 4.956008367640997

Epoch: 5| Step: 6
Training loss: 5.0532145500183105
Validation loss: 4.933207255537792

Epoch: 5| Step: 7
Training loss: 5.231451988220215
Validation loss: 4.909399037720055

Epoch: 5| Step: 8
Training loss: 5.092487335205078
Validation loss: 4.883598250727499

Epoch: 5| Step: 9
Training loss: 4.8982038497924805
Validation loss: 4.8570466400474634

Epoch: 5| Step: 10
Training loss: 3.5071730613708496
Validation loss: 4.829376769322221

Epoch: 3| Step: 0
Training loss: 4.8289384841918945
Validation loss: 4.799393002704908

Epoch: 5| Step: 1
Training loss: 4.78175687789917
Validation loss: 4.769297230628229

Epoch: 5| Step: 2
Training loss: 4.882882595062256
Validation loss: 4.739047178658106

Epoch: 5| Step: 3
Training loss: 4.597970008850098
Validation loss: 4.709068554703907

Epoch: 5| Step: 4
Training loss: 4.6116943359375
Validation loss: 4.678720843407415

Epoch: 5| Step: 5
Training loss: 4.841617107391357
Validation loss: 4.648718695486745

Epoch: 5| Step: 6
Training loss: 4.537248134613037
Validation loss: 4.6195079844485045

Epoch: 5| Step: 7
Training loss: 3.2973732948303223
Validation loss: 4.590668739811067

Epoch: 5| Step: 8
Training loss: 4.527161598205566
Validation loss: 4.5616344277576735

Epoch: 5| Step: 9
Training loss: 3.8265960216522217
Validation loss: 4.532391686593333

Epoch: 5| Step: 10
Training loss: 4.00770902633667
Validation loss: 4.503201010406658

Epoch: 4| Step: 0
Training loss: 3.657280683517456
Validation loss: 4.47246628935619

Epoch: 5| Step: 1
Training loss: 4.210385322570801
Validation loss: 4.444461730218703

Epoch: 5| Step: 2
Training loss: 4.088397026062012
Validation loss: 4.41314314257714

Epoch: 5| Step: 3
Training loss: 4.196173191070557
Validation loss: 4.383181254069011

Epoch: 5| Step: 4
Training loss: 3.927922487258911
Validation loss: 4.352253554969706

Epoch: 5| Step: 5
Training loss: 4.723496913909912
Validation loss: 4.320996763885662

Epoch: 5| Step: 6
Training loss: 4.450904846191406
Validation loss: 4.293385105748331

Epoch: 5| Step: 7
Training loss: 3.818796157836914
Validation loss: 4.2639973394332396

Epoch: 5| Step: 8
Training loss: 4.6484785079956055
Validation loss: 4.234914602771882

Epoch: 5| Step: 9
Training loss: 3.798736572265625
Validation loss: 4.20664285331644

Epoch: 5| Step: 10
Training loss: 3.8421616554260254
Validation loss: 4.176790868082354

Epoch: 5| Step: 0
Training loss: 3.908869504928589
Validation loss: 4.148486009208105

Epoch: 5| Step: 1
Training loss: 3.403357744216919
Validation loss: 4.116882380618844

Epoch: 5| Step: 2
Training loss: 4.129103183746338
Validation loss: 4.091176961057929

Epoch: 5| Step: 3
Training loss: 2.6940791606903076
Validation loss: 4.062333599213631

Epoch: 5| Step: 4
Training loss: 3.656038761138916
Validation loss: 4.038710307049495

Epoch: 5| Step: 5
Training loss: 3.876600742340088
Validation loss: 4.015944347586683

Epoch: 5| Step: 6
Training loss: 4.089421272277832
Validation loss: 3.9963339631275465

Epoch: 5| Step: 7
Training loss: 3.9330127239227295
Validation loss: 3.9775380652437926

Epoch: 5| Step: 8
Training loss: 4.3219404220581055
Validation loss: 3.961770949825164

Epoch: 5| Step: 9
Training loss: 4.273031711578369
Validation loss: 3.943814323794457

Epoch: 5| Step: 10
Training loss: 4.305325984954834
Validation loss: 3.9283873035061743

Epoch: 6| Step: 0
Training loss: 4.8198442459106445
Validation loss: 3.9146292235261653

Epoch: 5| Step: 1
Training loss: 4.183484077453613
Validation loss: 3.8976058498505624

Epoch: 5| Step: 2
Training loss: 3.7221755981445312
Validation loss: 3.8842468312991563

Epoch: 5| Step: 3
Training loss: 3.673145294189453
Validation loss: 3.8698276371084233

Epoch: 5| Step: 4
Training loss: 4.5356574058532715
Validation loss: 3.8597150771848616

Epoch: 5| Step: 5
Training loss: 2.6508688926696777
Validation loss: 3.8485050970508206

Epoch: 5| Step: 6
Training loss: 3.5885703563690186
Validation loss: 3.8389132868859077

Epoch: 5| Step: 7
Training loss: 3.656818389892578
Validation loss: 3.830551414079564

Epoch: 5| Step: 8
Training loss: 4.678948879241943
Validation loss: 3.8205982741489204

Epoch: 5| Step: 9
Training loss: 2.7123196125030518
Validation loss: 3.8124491655698387

Epoch: 5| Step: 10
Training loss: 2.6464858055114746
Validation loss: 3.7992212387823288

Epoch: 7| Step: 0
Training loss: 3.844691753387451
Validation loss: 3.78831543460969

Epoch: 5| Step: 1
Training loss: 4.3718061447143555
Validation loss: 3.7789425901187363

Epoch: 5| Step: 2
Training loss: 2.758857011795044
Validation loss: 3.7682866716897614

Epoch: 5| Step: 3
Training loss: 3.7666008472442627
Validation loss: 3.763211627160349

Epoch: 5| Step: 4
Training loss: 3.4780356884002686
Validation loss: 3.7503170813283613

Epoch: 5| Step: 5
Training loss: 3.139604091644287
Validation loss: 3.7356032043374996

Epoch: 5| Step: 6
Training loss: 4.133610725402832
Validation loss: 3.725476182917113

Epoch: 5| Step: 7
Training loss: 3.027127742767334
Validation loss: 3.7161419083995204

Epoch: 5| Step: 8
Training loss: 2.733638048171997
Validation loss: 3.7053740973113687

Epoch: 5| Step: 9
Training loss: 4.421090126037598
Validation loss: 3.6992645212399062

Epoch: 5| Step: 10
Training loss: 4.443099498748779
Validation loss: 3.6922454910893596

Epoch: 8| Step: 0
Training loss: 3.2219643592834473
Validation loss: 3.684812348376038

Epoch: 5| Step: 1
Training loss: 3.5202369689941406
Validation loss: 3.6795345455087642

Epoch: 5| Step: 2
Training loss: 3.8316650390625
Validation loss: 3.67534444409032

Epoch: 5| Step: 3
Training loss: 4.3917741775512695
Validation loss: 3.6657281203936507

Epoch: 5| Step: 4
Training loss: 2.7682065963745117
Validation loss: 3.6580122927183747

Epoch: 5| Step: 5
Training loss: 3.7956364154815674
Validation loss: 3.6532490279084895

Epoch: 5| Step: 6
Training loss: 3.2709522247314453
Validation loss: 3.647169595123619

Epoch: 5| Step: 7
Training loss: 3.4184041023254395
Validation loss: 3.6416038031219156

Epoch: 5| Step: 8
Training loss: 3.5692546367645264
Validation loss: 3.6344546912818827

Epoch: 5| Step: 9
Training loss: 3.0845324993133545
Validation loss: 3.6263890061327206

Epoch: 5| Step: 10
Training loss: 4.491360187530518
Validation loss: 3.62158017517418

Epoch: 9| Step: 0
Training loss: 3.4112601280212402
Validation loss: 3.615324961241855

Epoch: 5| Step: 1
Training loss: 3.1717941761016846
Validation loss: 3.609327364993352

Epoch: 5| Step: 2
Training loss: 4.346367835998535
Validation loss: 3.6067711025156

Epoch: 5| Step: 3
Training loss: 4.082719326019287
Validation loss: 3.600145532238868

Epoch: 5| Step: 4
Training loss: 3.2330100536346436
Validation loss: 3.59438136828843

Epoch: 5| Step: 5
Training loss: 4.091481685638428
Validation loss: 3.5901885494109123

Epoch: 5| Step: 6
Training loss: 3.6461684703826904
Validation loss: 3.583373528654857

Epoch: 5| Step: 7
Training loss: 2.5234689712524414
Validation loss: 3.578211917672106

Epoch: 5| Step: 8
Training loss: 4.190793037414551
Validation loss: 3.5726302310984623

Epoch: 5| Step: 9
Training loss: 2.4428467750549316
Validation loss: 3.565882505909089

Epoch: 5| Step: 10
Training loss: 3.4867911338806152
Validation loss: 3.5604102765360186

Epoch: 10| Step: 0
Training loss: 3.2231342792510986
Validation loss: 3.5538163133846816

Epoch: 5| Step: 1
Training loss: 4.221041679382324
Validation loss: 3.5480862125273673

Epoch: 5| Step: 2
Training loss: 4.295085906982422
Validation loss: 3.5417916287658033

Epoch: 5| Step: 3
Training loss: 3.3116507530212402
Validation loss: 3.5354861982407106

Epoch: 5| Step: 4
Training loss: 2.7601871490478516
Validation loss: 3.527063726097025

Epoch: 5| Step: 5
Training loss: 3.455152988433838
Validation loss: 3.522430827540736

Epoch: 5| Step: 6
Training loss: 4.351220607757568
Validation loss: 3.5169274499339442

Epoch: 5| Step: 7
Training loss: 3.1725411415100098
Validation loss: 3.510295811519828

Epoch: 5| Step: 8
Training loss: 3.1158597469329834
Validation loss: 3.503360822636594

Epoch: 5| Step: 9
Training loss: 2.4199280738830566
Validation loss: 3.5001705897751676

Epoch: 5| Step: 10
Training loss: 3.7236971855163574
Validation loss: 3.492084539064797

Epoch: 11| Step: 0
Training loss: 3.437063694000244
Validation loss: 3.484588981956564

Epoch: 5| Step: 1
Training loss: 2.3533427715301514
Validation loss: 3.481483223617718

Epoch: 5| Step: 2
Training loss: 3.142871141433716
Validation loss: 3.472250694869667

Epoch: 5| Step: 3
Training loss: 4.330384731292725
Validation loss: 3.4694314438809633

Epoch: 5| Step: 4
Training loss: 3.1700329780578613
Validation loss: 3.4604370747843096

Epoch: 5| Step: 5
Training loss: 3.2352070808410645
Validation loss: 3.4568474677301224

Epoch: 5| Step: 6
Training loss: 3.320730686187744
Validation loss: 3.450874738795783

Epoch: 5| Step: 7
Training loss: 3.4655330181121826
Validation loss: 3.444906901287776

Epoch: 5| Step: 8
Training loss: 3.722081422805786
Validation loss: 3.438563193044355

Epoch: 5| Step: 9
Training loss: 4.109579563140869
Validation loss: 3.4312837457144134

Epoch: 5| Step: 10
Training loss: 3.0291576385498047
Validation loss: 3.42110171369327

Epoch: 12| Step: 0
Training loss: 3.487407684326172
Validation loss: 3.4244337184454805

Epoch: 5| Step: 1
Training loss: 2.6340532302856445
Validation loss: 3.4121220111846924

Epoch: 5| Step: 2
Training loss: 2.823110342025757
Validation loss: 3.410906753232402

Epoch: 5| Step: 3
Training loss: 3.3290717601776123
Validation loss: 3.4118307867357807

Epoch: 5| Step: 4
Training loss: 3.485316514968872
Validation loss: 3.4051940697495655

Epoch: 5| Step: 5
Training loss: 2.9323954582214355
Validation loss: 3.394374716666437

Epoch: 5| Step: 6
Training loss: 3.944753646850586
Validation loss: 3.385372272101782

Epoch: 5| Step: 7
Training loss: 3.4458789825439453
Validation loss: 3.390663357191188

Epoch: 5| Step: 8
Training loss: 3.9381535053253174
Validation loss: 3.3920653789274153

Epoch: 5| Step: 9
Training loss: 3.1002719402313232
Validation loss: 3.374443269545032

Epoch: 5| Step: 10
Training loss: 3.769752025604248
Validation loss: 3.3843061385616178

Epoch: 13| Step: 0
Training loss: 3.8696837425231934
Validation loss: 3.362470183321225

Epoch: 5| Step: 1
Training loss: 4.123814582824707
Validation loss: 3.36692794933114

Epoch: 5| Step: 2
Training loss: 3.771015167236328
Validation loss: 3.3636445178780505

Epoch: 5| Step: 3
Training loss: 3.5718955993652344
Validation loss: 3.360077475988737

Epoch: 5| Step: 4
Training loss: 2.938685894012451
Validation loss: 3.3518839061901136

Epoch: 5| Step: 5
Training loss: 2.9055895805358887
Validation loss: 3.342096487681071

Epoch: 5| Step: 6
Training loss: 3.296196460723877
Validation loss: 3.3364587727413384

Epoch: 5| Step: 7
Training loss: 3.4097423553466797
Validation loss: 3.3307981285997617

Epoch: 5| Step: 8
Training loss: 2.424044132232666
Validation loss: 3.3271620632499777

Epoch: 5| Step: 9
Training loss: 3.023991346359253
Validation loss: 3.3201431535905406

Epoch: 5| Step: 10
Training loss: 2.9967997074127197
Validation loss: 3.3133121254623576

Epoch: 14| Step: 0
Training loss: 3.452108383178711
Validation loss: 3.3073497100542952

Epoch: 5| Step: 1
Training loss: 3.948801040649414
Validation loss: 3.3046402418485252

Epoch: 5| Step: 2
Training loss: 3.231110095977783
Validation loss: 3.2950918930833057

Epoch: 5| Step: 3
Training loss: 1.7807241678237915
Validation loss: 3.289469713805824

Epoch: 5| Step: 4
Training loss: 3.706956386566162
Validation loss: 3.287999035209738

Epoch: 5| Step: 5
Training loss: 4.0234832763671875
Validation loss: 3.283790285869311

Epoch: 5| Step: 6
Training loss: 3.047457456588745
Validation loss: 3.2798040656633276

Epoch: 5| Step: 7
Training loss: 4.163224220275879
Validation loss: 3.2726448479519097

Epoch: 5| Step: 8
Training loss: 2.8867197036743164
Validation loss: 3.265405642089023

Epoch: 5| Step: 9
Training loss: 2.2982890605926514
Validation loss: 3.2636552728632444

Epoch: 5| Step: 10
Training loss: 3.3081443309783936
Validation loss: 3.2601818833299863

Epoch: 15| Step: 0
Training loss: 2.5802700519561768
Validation loss: 3.2551274376530803

Epoch: 5| Step: 1
Training loss: 2.9119534492492676
Validation loss: 3.24735588412131

Epoch: 5| Step: 2
Training loss: 3.543732166290283
Validation loss: 3.2432937468251875

Epoch: 5| Step: 3
Training loss: 3.5217597484588623
Validation loss: 3.237748033256941

Epoch: 5| Step: 4
Training loss: 3.4767913818359375
Validation loss: 3.231826182334654

Epoch: 5| Step: 5
Training loss: 3.501258373260498
Validation loss: 3.2296641283137824

Epoch: 5| Step: 6
Training loss: 2.4849700927734375
Validation loss: 3.2286982895225607

Epoch: 5| Step: 7
Training loss: 3.6049587726593018
Validation loss: 3.218973159790039

Epoch: 5| Step: 8
Training loss: 3.9676055908203125
Validation loss: 3.214486183658723

Epoch: 5| Step: 9
Training loss: 2.867192029953003
Validation loss: 3.213703052971953

Epoch: 5| Step: 10
Training loss: 2.8987016677856445
Validation loss: 3.2084086941134546

Epoch: 16| Step: 0
Training loss: 3.0615315437316895
Validation loss: 3.2052512886703655

Epoch: 5| Step: 1
Training loss: 2.5294785499572754
Validation loss: 3.2006366945082143

Epoch: 5| Step: 2
Training loss: 3.271665573120117
Validation loss: 3.195342525359123

Epoch: 5| Step: 3
Training loss: 2.8139796257019043
Validation loss: 3.1923526076860327

Epoch: 5| Step: 4
Training loss: 3.749345302581787
Validation loss: 3.1884521745866343

Epoch: 5| Step: 5
Training loss: 3.326629638671875
Validation loss: 3.187368110943866

Epoch: 5| Step: 6
Training loss: 2.948908567428589
Validation loss: 3.1823055359625045

Epoch: 5| Step: 7
Training loss: 3.854001522064209
Validation loss: 3.1801917732402845

Epoch: 5| Step: 8
Training loss: 2.4669880867004395
Validation loss: 3.176405806695261

Epoch: 5| Step: 9
Training loss: 2.7384238243103027
Validation loss: 3.1733716303302395

Epoch: 5| Step: 10
Training loss: 4.49623966217041
Validation loss: 3.1699647544532694

Epoch: 17| Step: 0
Training loss: 3.8581948280334473
Validation loss: 3.1683335073532595

Epoch: 5| Step: 1
Training loss: 3.9123778343200684
Validation loss: 3.1677824989441903

Epoch: 5| Step: 2
Training loss: 2.6103084087371826
Validation loss: 3.16033830693973

Epoch: 5| Step: 3
Training loss: 2.447178602218628
Validation loss: 3.1580211193330827

Epoch: 5| Step: 4
Training loss: 3.6197898387908936
Validation loss: 3.154762544939595

Epoch: 5| Step: 5
Training loss: 2.865112781524658
Validation loss: 3.151458935071063

Epoch: 5| Step: 6
Training loss: 3.9284186363220215
Validation loss: 3.150472979391775

Epoch: 5| Step: 7
Training loss: 2.799436092376709
Validation loss: 3.140906985088061

Epoch: 5| Step: 8
Training loss: 3.0237796306610107
Validation loss: 3.1409975431298696

Epoch: 5| Step: 9
Training loss: 2.978830337524414
Validation loss: 3.137183153501121

Epoch: 5| Step: 10
Training loss: 2.6924221515655518
Validation loss: 3.1367896859363844

Epoch: 18| Step: 0
Training loss: 3.6991515159606934
Validation loss: 3.133739648326751

Epoch: 5| Step: 1
Training loss: 2.9225101470947266
Validation loss: 3.1348581083359255

Epoch: 5| Step: 2
Training loss: 2.5978684425354004
Validation loss: 3.137693856352119

Epoch: 5| Step: 3
Training loss: 3.8407654762268066
Validation loss: 3.1394950702626216

Epoch: 5| Step: 4
Training loss: 2.967679500579834
Validation loss: 3.130266010120351

Epoch: 5| Step: 5
Training loss: 4.198993682861328
Validation loss: 3.133621092765562

Epoch: 5| Step: 6
Training loss: 3.870246410369873
Validation loss: 3.126168550983552

Epoch: 5| Step: 7
Training loss: 2.173041343688965
Validation loss: 3.1212774553606586

Epoch: 5| Step: 8
Training loss: 2.7126617431640625
Validation loss: 3.116201857084869

Epoch: 5| Step: 9
Training loss: 2.9530365467071533
Validation loss: 3.111978151464975

Epoch: 5| Step: 10
Training loss: 2.568819761276245
Validation loss: 3.1131222888987553

Epoch: 19| Step: 0
Training loss: 3.2247817516326904
Validation loss: 3.1111969204359156

Epoch: 5| Step: 1
Training loss: 2.7102084159851074
Validation loss: 3.111531678066459

Epoch: 5| Step: 2
Training loss: 3.751554489135742
Validation loss: 3.1143071600185928

Epoch: 5| Step: 3
Training loss: 2.7426371574401855
Validation loss: 3.1122812712064354

Epoch: 5| Step: 4
Training loss: 3.0244476795196533
Validation loss: 3.1097542983229443

Epoch: 5| Step: 5
Training loss: 3.1441311836242676
Validation loss: 3.106731478885938

Epoch: 5| Step: 6
Training loss: 2.490905284881592
Validation loss: 3.1059185228040143

Epoch: 5| Step: 7
Training loss: 3.6930222511291504
Validation loss: 3.1065062656197497

Epoch: 5| Step: 8
Training loss: 3.3560938835144043
Validation loss: 3.0966022834982923

Epoch: 5| Step: 9
Training loss: 3.1577346324920654
Validation loss: 3.094118377213837

Epoch: 5| Step: 10
Training loss: 3.177973747253418
Validation loss: 3.091949778218423

Epoch: 20| Step: 0
Training loss: 2.218596935272217
Validation loss: 3.120237088972522

Epoch: 5| Step: 1
Training loss: 3.3293983936309814
Validation loss: 3.1293090107620403

Epoch: 5| Step: 2
Training loss: 2.9791088104248047
Validation loss: 3.103649826459987

Epoch: 5| Step: 3
Training loss: 3.3700759410858154
Validation loss: 3.0874502094843055

Epoch: 5| Step: 4
Training loss: 3.4072296619415283
Validation loss: 3.0893667128778275

Epoch: 5| Step: 5
Training loss: 3.81915020942688
Validation loss: 3.096749359561551

Epoch: 5| Step: 6
Training loss: 4.322396755218506
Validation loss: 3.105252904276694

Epoch: 5| Step: 7
Training loss: 2.8696773052215576
Validation loss: 3.093739463436988

Epoch: 5| Step: 8
Training loss: 1.9150832891464233
Validation loss: 3.0819126431659987

Epoch: 5| Step: 9
Training loss: 2.6489851474761963
Validation loss: 3.0764835752466673

Epoch: 5| Step: 10
Training loss: 3.6045889854431152
Validation loss: 3.0774152227627334

Epoch: 21| Step: 0
Training loss: 2.9477596282958984
Validation loss: 3.083522791503578

Epoch: 5| Step: 1
Training loss: 3.3309032917022705
Validation loss: 3.0992453226479153

Epoch: 5| Step: 2
Training loss: 2.781891345977783
Validation loss: 3.0871286417848323

Epoch: 5| Step: 3
Training loss: 3.000950336456299
Validation loss: 3.074550031333841

Epoch: 5| Step: 4
Training loss: 2.6247310638427734
Validation loss: 3.0712496311433855

Epoch: 5| Step: 5
Training loss: 3.420457124710083
Validation loss: 3.0697464814750095

Epoch: 5| Step: 6
Training loss: 3.8170769214630127
Validation loss: 3.0659444947396555

Epoch: 5| Step: 7
Training loss: 3.7151694297790527
Validation loss: 3.0669556151154223

Epoch: 5| Step: 8
Training loss: 2.206188440322876
Validation loss: 3.0652628867856917

Epoch: 5| Step: 9
Training loss: 3.349600315093994
Validation loss: 3.059839863930979

Epoch: 5| Step: 10
Training loss: 3.0043156147003174
Validation loss: 3.0565395611588673

Epoch: 22| Step: 0
Training loss: 3.7537715435028076
Validation loss: 3.0536561960815103

Epoch: 5| Step: 1
Training loss: 2.1775431632995605
Validation loss: 3.0497286268459853

Epoch: 5| Step: 2
Training loss: 2.4429471492767334
Validation loss: 3.0491805538054435

Epoch: 5| Step: 3
Training loss: 3.105801820755005
Validation loss: 3.04688552887209

Epoch: 5| Step: 4
Training loss: 3.3281047344207764
Validation loss: 3.0460948687727734

Epoch: 5| Step: 5
Training loss: 3.7746498584747314
Validation loss: 3.0427469027939664

Epoch: 5| Step: 6
Training loss: 2.9194841384887695
Validation loss: 3.0387501101340018

Epoch: 5| Step: 7
Training loss: 3.444448947906494
Validation loss: 3.0402031278097503

Epoch: 5| Step: 8
Training loss: 2.4650986194610596
Validation loss: 3.03416197787049

Epoch: 5| Step: 9
Training loss: 2.9514222145080566
Validation loss: 3.0351615080269436

Epoch: 5| Step: 10
Training loss: 3.7527904510498047
Validation loss: 3.0304136430063555

Epoch: 23| Step: 0
Training loss: 3.3041675090789795
Validation loss: 3.0296904220375964

Epoch: 5| Step: 1
Training loss: 3.6726760864257812
Validation loss: 3.0264932442736883

Epoch: 5| Step: 2
Training loss: 3.0953516960144043
Validation loss: 3.023614570658694

Epoch: 5| Step: 3
Training loss: 3.142285108566284
Validation loss: 3.021126611258394

Epoch: 5| Step: 4
Training loss: 2.6565699577331543
Validation loss: 3.019455332909861

Epoch: 5| Step: 5
Training loss: 3.0963387489318848
Validation loss: 3.011800968518821

Epoch: 5| Step: 6
Training loss: 3.6488964557647705
Validation loss: 3.0153992842602473

Epoch: 5| Step: 7
Training loss: 2.4762122631073
Validation loss: 3.017990699378393

Epoch: 5| Step: 8
Training loss: 3.5089690685272217
Validation loss: 3.017217533562773

Epoch: 5| Step: 9
Training loss: 2.5632576942443848
Validation loss: 3.0137717723846436

Epoch: 5| Step: 10
Training loss: 2.6215243339538574
Validation loss: 3.008759790851224

Epoch: 24| Step: 0
Training loss: 2.428480625152588
Validation loss: 3.0070873332279984

Epoch: 5| Step: 1
Training loss: 2.41865611076355
Validation loss: 3.003071541427284

Epoch: 5| Step: 2
Training loss: 3.1357078552246094
Validation loss: 3.0024344408383934

Epoch: 5| Step: 3
Training loss: 2.7567477226257324
Validation loss: 3.002345887563562

Epoch: 5| Step: 4
Training loss: 3.0178465843200684
Validation loss: 2.998368678554412

Epoch: 5| Step: 5
Training loss: 3.7227485179901123
Validation loss: 2.998721927724859

Epoch: 5| Step: 6
Training loss: 3.0833919048309326
Validation loss: 2.9963063501542613

Epoch: 5| Step: 7
Training loss: 3.322160005569458
Validation loss: 2.993493016048144

Epoch: 5| Step: 8
Training loss: 2.622448444366455
Validation loss: 2.9927110620724258

Epoch: 5| Step: 9
Training loss: 3.337282657623291
Validation loss: 2.990155771214475

Epoch: 5| Step: 10
Training loss: 4.000602722167969
Validation loss: 2.985748896034815

Epoch: 25| Step: 0
Training loss: 3.347006320953369
Validation loss: 2.9878980139250397

Epoch: 5| Step: 1
Training loss: 3.3512065410614014
Validation loss: 2.9885701056449645

Epoch: 5| Step: 2
Training loss: 3.4211525917053223
Validation loss: 2.9812439564735658

Epoch: 5| Step: 3
Training loss: 2.3221588134765625
Validation loss: 2.98202544899397

Epoch: 5| Step: 4
Training loss: 3.168264865875244
Validation loss: 2.978507690532233

Epoch: 5| Step: 5
Training loss: 3.151258945465088
Validation loss: 2.9755158706377913

Epoch: 5| Step: 6
Training loss: 3.4534835815429688
Validation loss: 2.97433957745952

Epoch: 5| Step: 7
Training loss: 2.4365549087524414
Validation loss: 2.9735496428705033

Epoch: 5| Step: 8
Training loss: 3.376030683517456
Validation loss: 2.9730344767211587

Epoch: 5| Step: 9
Training loss: 2.5045113563537598
Validation loss: 2.9718365130885953

Epoch: 5| Step: 10
Training loss: 3.043351650238037
Validation loss: 2.9699194098031647

Epoch: 26| Step: 0
Training loss: 3.858219861984253
Validation loss: 2.9696345252375447

Epoch: 5| Step: 1
Training loss: 2.789741039276123
Validation loss: 2.966262076490669

Epoch: 5| Step: 2
Training loss: 3.1347479820251465
Validation loss: 2.9627073708400933

Epoch: 5| Step: 3
Training loss: 2.358457088470459
Validation loss: 2.962860950859644

Epoch: 5| Step: 4
Training loss: 2.751690626144409
Validation loss: 2.958680957876226

Epoch: 5| Step: 5
Training loss: 3.3191802501678467
Validation loss: 2.958431154169062

Epoch: 5| Step: 6
Training loss: 3.282334089279175
Validation loss: 2.9536426298079954

Epoch: 5| Step: 7
Training loss: 3.2911651134490967
Validation loss: 2.950529547147853

Epoch: 5| Step: 8
Training loss: 2.3317363262176514
Validation loss: 2.954298375755228

Epoch: 5| Step: 9
Training loss: 2.877063512802124
Validation loss: 2.9475176949654855

Epoch: 5| Step: 10
Training loss: 3.48337721824646
Validation loss: 2.946400124539611

Epoch: 27| Step: 0
Training loss: 2.7869861125946045
Validation loss: 2.942869391492618

Epoch: 5| Step: 1
Training loss: 2.938589096069336
Validation loss: 2.94268306609123

Epoch: 5| Step: 2
Training loss: 3.3164589405059814
Validation loss: 2.941731855433474

Epoch: 5| Step: 3
Training loss: 3.7084126472473145
Validation loss: 2.940798092913884

Epoch: 5| Step: 4
Training loss: 3.1376540660858154
Validation loss: 2.939197914574736

Epoch: 5| Step: 5
Training loss: 2.5404365062713623
Validation loss: 2.9369134031316286

Epoch: 5| Step: 6
Training loss: 3.068495273590088
Validation loss: 2.937616571303337

Epoch: 5| Step: 7
Training loss: 2.953172206878662
Validation loss: 2.9321720574491765

Epoch: 5| Step: 8
Training loss: 2.5935540199279785
Validation loss: 2.9305187502214984

Epoch: 5| Step: 9
Training loss: 3.175011157989502
Validation loss: 2.933708337045485

Epoch: 5| Step: 10
Training loss: 3.0666768550872803
Validation loss: 2.9334695005929596

Epoch: 28| Step: 0
Training loss: 3.6278483867645264
Validation loss: 2.9449203706556752

Epoch: 5| Step: 1
Training loss: 3.2359561920166016
Validation loss: 2.9377882916440248

Epoch: 5| Step: 2
Training loss: 2.5255825519561768
Validation loss: 2.921569634509343

Epoch: 5| Step: 3
Training loss: 2.8534209728240967
Validation loss: 2.920026866338586

Epoch: 5| Step: 4
Training loss: 3.0891215801239014
Validation loss: 2.925820453192598

Epoch: 5| Step: 5
Training loss: 2.865556240081787
Validation loss: 2.9279521075628137

Epoch: 5| Step: 6
Training loss: 2.2408299446105957
Validation loss: 2.9307889015443864

Epoch: 5| Step: 7
Training loss: 2.9619970321655273
Validation loss: 2.938624164109589

Epoch: 5| Step: 8
Training loss: 3.579130172729492
Validation loss: 2.922246830437773

Epoch: 5| Step: 9
Training loss: 3.274998188018799
Validation loss: 2.921200644585394

Epoch: 5| Step: 10
Training loss: 2.9333889484405518
Validation loss: 2.921834004822598

Epoch: 29| Step: 0
Training loss: 2.77353572845459
Validation loss: 2.919279352311165

Epoch: 5| Step: 1
Training loss: 3.4332077503204346
Validation loss: 2.9191327761578303

Epoch: 5| Step: 2
Training loss: 2.7189536094665527
Validation loss: 2.9187774145475

Epoch: 5| Step: 3
Training loss: 3.4600205421447754
Validation loss: 2.914291415163266

Epoch: 5| Step: 4
Training loss: 2.1695122718811035
Validation loss: 2.9147837290199856

Epoch: 5| Step: 5
Training loss: 3.1805896759033203
Validation loss: 2.9134019549174974

Epoch: 5| Step: 6
Training loss: 4.142263889312744
Validation loss: 2.9131341621439946

Epoch: 5| Step: 7
Training loss: 2.940448045730591
Validation loss: 2.91249607968074

Epoch: 5| Step: 8
Training loss: 2.728684663772583
Validation loss: 2.9068707650707615

Epoch: 5| Step: 9
Training loss: 2.6847987174987793
Validation loss: 2.9057713811115553

Epoch: 5| Step: 10
Training loss: 2.8489830493927
Validation loss: 2.905313786639962

Epoch: 30| Step: 0
Training loss: 3.161127805709839
Validation loss: 2.9031368455579205

Epoch: 5| Step: 1
Training loss: 2.7678263187408447
Validation loss: 2.902211591761599

Epoch: 5| Step: 2
Training loss: 3.75762939453125
Validation loss: 2.902326650516961

Epoch: 5| Step: 3
Training loss: 3.5226314067840576
Validation loss: 2.8985813535669798

Epoch: 5| Step: 4
Training loss: 2.831674098968506
Validation loss: 2.897529950705908

Epoch: 5| Step: 5
Training loss: 3.292004346847534
Validation loss: 2.8937098185221353

Epoch: 5| Step: 6
Training loss: 2.813570499420166
Validation loss: 2.8927273827214397

Epoch: 5| Step: 7
Training loss: 2.4684979915618896
Validation loss: 2.890864618362919

Epoch: 5| Step: 8
Training loss: 3.1171956062316895
Validation loss: 2.8906324166123585

Epoch: 5| Step: 9
Training loss: 2.532618522644043
Validation loss: 2.8952130425360894

Epoch: 5| Step: 10
Training loss: 2.667658567428589
Validation loss: 2.892936219451248

Epoch: 31| Step: 0
Training loss: 3.372628688812256
Validation loss: 2.900235027395269

Epoch: 5| Step: 1
Training loss: 3.348198652267456
Validation loss: 2.920902846961893

Epoch: 5| Step: 2
Training loss: 2.8351387977600098
Validation loss: 2.9182543498213573

Epoch: 5| Step: 3
Training loss: 2.6225807666778564
Validation loss: 2.911413949023011

Epoch: 5| Step: 4
Training loss: 2.823613166809082
Validation loss: 2.8876604085327475

Epoch: 5| Step: 5
Training loss: 2.6663436889648438
Validation loss: 2.888750894095308

Epoch: 5| Step: 6
Training loss: 3.114716053009033
Validation loss: 2.8892760917704594

Epoch: 5| Step: 7
Training loss: 3.408179521560669
Validation loss: 2.8934993590078046

Epoch: 5| Step: 8
Training loss: 3.3464531898498535
Validation loss: 2.8871298784850747

Epoch: 5| Step: 9
Training loss: 2.835102081298828
Validation loss: 2.8829416280151694

Epoch: 5| Step: 10
Training loss: 2.486133098602295
Validation loss: 2.8843175621442896

Epoch: 32| Step: 0
Training loss: 2.8571937084198
Validation loss: 2.8984425811357397

Epoch: 5| Step: 1
Training loss: 2.8399572372436523
Validation loss: 2.9030971988554923

Epoch: 5| Step: 2
Training loss: 2.4824254512786865
Validation loss: 2.9179262602201073

Epoch: 5| Step: 3
Training loss: 2.9136111736297607
Validation loss: 2.9089918956961682

Epoch: 5| Step: 4
Training loss: 3.22247576713562
Validation loss: 2.8840840093551146

Epoch: 5| Step: 5
Training loss: 3.311258316040039
Validation loss: 2.8826731533132572

Epoch: 5| Step: 6
Training loss: 2.7767322063446045
Validation loss: 2.8881171467483684

Epoch: 5| Step: 7
Training loss: 2.7081966400146484
Validation loss: 2.897648808776691

Epoch: 5| Step: 8
Training loss: 2.6990647315979004
Validation loss: 2.8965838186202513

Epoch: 5| Step: 9
Training loss: 3.792694568634033
Validation loss: 2.8994219277494695

Epoch: 5| Step: 10
Training loss: 3.4092612266540527
Validation loss: 2.8907617163914505

Epoch: 33| Step: 0
Training loss: 2.7984542846679688
Validation loss: 2.886282923401043

Epoch: 5| Step: 1
Training loss: 2.9039981365203857
Validation loss: 2.8831194575114916

Epoch: 5| Step: 2
Training loss: 3.1317360401153564
Validation loss: 2.883126640832552

Epoch: 5| Step: 3
Training loss: 3.406571865081787
Validation loss: 2.8848423470732985

Epoch: 5| Step: 4
Training loss: 2.9654555320739746
Validation loss: 2.882604509271601

Epoch: 5| Step: 5
Training loss: 2.619162082672119
Validation loss: 2.8830002507855816

Epoch: 5| Step: 6
Training loss: 2.891475200653076
Validation loss: 2.885109252827142

Epoch: 5| Step: 7
Training loss: 3.2910614013671875
Validation loss: 2.882272481918335

Epoch: 5| Step: 8
Training loss: 2.3180675506591797
Validation loss: 2.881458641380392

Epoch: 5| Step: 9
Training loss: 3.0546460151672363
Validation loss: 2.882538726252894

Epoch: 5| Step: 10
Training loss: 3.571658134460449
Validation loss: 2.884614734239476

Epoch: 34| Step: 0
Training loss: 2.7935454845428467
Validation loss: 2.8860802906815723

Epoch: 5| Step: 1
Training loss: 3.5174241065979004
Validation loss: 2.8790328964110343

Epoch: 5| Step: 2
Training loss: 1.9450862407684326
Validation loss: 2.872620123688893

Epoch: 5| Step: 3
Training loss: 2.3020217418670654
Validation loss: 2.8707233141827326

Epoch: 5| Step: 4
Training loss: 2.4947996139526367
Validation loss: 2.8681647546829714

Epoch: 5| Step: 5
Training loss: 3.1787500381469727
Validation loss: 2.868533375442669

Epoch: 5| Step: 6
Training loss: 3.646808624267578
Validation loss: 2.8656496104373725

Epoch: 5| Step: 7
Training loss: 3.3379955291748047
Validation loss: 2.861347052358812

Epoch: 5| Step: 8
Training loss: 3.8539130687713623
Validation loss: 2.86265625492219

Epoch: 5| Step: 9
Training loss: 2.6760759353637695
Validation loss: 2.858859846668859

Epoch: 5| Step: 10
Training loss: 2.989290237426758
Validation loss: 2.85931134223938

Epoch: 35| Step: 0
Training loss: 2.495194673538208
Validation loss: 2.859599636447045

Epoch: 5| Step: 1
Training loss: 1.7480041980743408
Validation loss: 2.858168243080057

Epoch: 5| Step: 2
Training loss: 2.922515392303467
Validation loss: 2.8618258840294293

Epoch: 5| Step: 3
Training loss: 3.541217803955078
Validation loss: 2.856226956972512

Epoch: 5| Step: 4
Training loss: 2.964587450027466
Validation loss: 2.8533706665039062

Epoch: 5| Step: 5
Training loss: 2.7814011573791504
Validation loss: 2.850200791512766

Epoch: 5| Step: 6
Training loss: 2.9502575397491455
Validation loss: 2.851439304249261

Epoch: 5| Step: 7
Training loss: 3.7552857398986816
Validation loss: 2.8500910215480353

Epoch: 5| Step: 8
Training loss: 3.1210777759552
Validation loss: 2.8504864272250923

Epoch: 5| Step: 9
Training loss: 3.475764513015747
Validation loss: 2.850834684987222

Epoch: 5| Step: 10
Training loss: 2.88920521736145
Validation loss: 2.849397982320478

Epoch: 36| Step: 0
Training loss: 2.334543228149414
Validation loss: 2.8495177889382965

Epoch: 5| Step: 1
Training loss: 3.550065279006958
Validation loss: 2.848054414154381

Epoch: 5| Step: 2
Training loss: 2.6472325325012207
Validation loss: 2.8493082036254225

Epoch: 5| Step: 3
Training loss: 2.590078592300415
Validation loss: 2.8473478286497054

Epoch: 5| Step: 4
Training loss: 2.166088581085205
Validation loss: 2.8467814999241985

Epoch: 5| Step: 5
Training loss: 3.3422484397888184
Validation loss: 2.845741759064377

Epoch: 5| Step: 6
Training loss: 3.275216579437256
Validation loss: 2.844522096777475

Epoch: 5| Step: 7
Training loss: 2.805999279022217
Validation loss: 2.8469234640880297

Epoch: 5| Step: 8
Training loss: 3.4665839672088623
Validation loss: 2.8451335712145736

Epoch: 5| Step: 9
Training loss: 3.247563123703003
Validation loss: 2.8451276774047525

Epoch: 5| Step: 10
Training loss: 3.2238667011260986
Validation loss: 2.8434587396601194

Epoch: 37| Step: 0
Training loss: 3.267864942550659
Validation loss: 2.843809696935838

Epoch: 5| Step: 1
Training loss: 3.0020127296447754
Validation loss: 2.84340379827766

Epoch: 5| Step: 2
Training loss: 3.358078718185425
Validation loss: 2.842036800999795

Epoch: 5| Step: 3
Training loss: 2.932182550430298
Validation loss: 2.8414474841087096

Epoch: 5| Step: 4
Training loss: 2.590053081512451
Validation loss: 2.8429672436047624

Epoch: 5| Step: 5
Training loss: 2.9749438762664795
Validation loss: 2.8479648456778577

Epoch: 5| Step: 6
Training loss: 3.286701202392578
Validation loss: 2.8587193360892673

Epoch: 5| Step: 7
Training loss: 2.377171754837036
Validation loss: 2.841000021144908

Epoch: 5| Step: 8
Training loss: 3.4582409858703613
Validation loss: 2.844626852261123

Epoch: 5| Step: 9
Training loss: 2.797595262527466
Validation loss: 2.8514663480943248

Epoch: 5| Step: 10
Training loss: 2.510383367538452
Validation loss: 2.850251920761601

Epoch: 38| Step: 0
Training loss: 3.4423556327819824
Validation loss: 2.8468301552598194

Epoch: 5| Step: 1
Training loss: 2.9913442134857178
Validation loss: 2.8462598195639988

Epoch: 5| Step: 2
Training loss: 3.267909526824951
Validation loss: 2.842648749710411

Epoch: 5| Step: 3
Training loss: 2.6968672275543213
Validation loss: 2.839844952347458

Epoch: 5| Step: 4
Training loss: 3.514136552810669
Validation loss: 2.844557621145761

Epoch: 5| Step: 5
Training loss: 3.3630900382995605
Validation loss: 2.843148216124504

Epoch: 5| Step: 6
Training loss: 2.914417028427124
Validation loss: 2.844083527083038

Epoch: 5| Step: 7
Training loss: 2.1396141052246094
Validation loss: 2.8404981449086177

Epoch: 5| Step: 8
Training loss: 2.4233322143554688
Validation loss: 2.843237620528026

Epoch: 5| Step: 9
Training loss: 2.817999839782715
Validation loss: 2.846816555146248

Epoch: 5| Step: 10
Training loss: 3.0580952167510986
Validation loss: 2.8423008841852986

Epoch: 39| Step: 0
Training loss: 2.952993392944336
Validation loss: 2.8398684199138353

Epoch: 5| Step: 1
Training loss: 2.551497220993042
Validation loss: 2.8394729783458095

Epoch: 5| Step: 2
Training loss: 3.0565812587738037
Validation loss: 2.8405307467265795

Epoch: 5| Step: 3
Training loss: 3.078042507171631
Validation loss: 2.836383796507312

Epoch: 5| Step: 4
Training loss: 3.174959182739258
Validation loss: 2.834905696171586

Epoch: 5| Step: 5
Training loss: 3.5293173789978027
Validation loss: 2.83542186726806

Epoch: 5| Step: 6
Training loss: 3.0229835510253906
Validation loss: 2.8410844033764255

Epoch: 5| Step: 7
Training loss: 2.9333369731903076
Validation loss: 2.8388992150624595

Epoch: 5| Step: 8
Training loss: 2.8349456787109375
Validation loss: 2.837341118884343

Epoch: 5| Step: 9
Training loss: 2.731854200363159
Validation loss: 2.839625612381966

Epoch: 5| Step: 10
Training loss: 2.651113271713257
Validation loss: 2.837728895166869

Epoch: 40| Step: 0
Training loss: 3.0060999393463135
Validation loss: 2.8383612017477713

Epoch: 5| Step: 1
Training loss: 2.5657200813293457
Validation loss: 2.8379568669103805

Epoch: 5| Step: 2
Training loss: 2.727688789367676
Validation loss: 2.8338328382020355

Epoch: 5| Step: 3
Training loss: 3.150642156600952
Validation loss: 2.8299487944572204

Epoch: 5| Step: 4
Training loss: 2.2704434394836426
Validation loss: 2.8358932592535533

Epoch: 5| Step: 5
Training loss: 2.2651500701904297
Validation loss: 2.827380164977043

Epoch: 5| Step: 6
Training loss: 2.97152042388916
Validation loss: 2.827194977832097

Epoch: 5| Step: 7
Training loss: 3.06400203704834
Validation loss: 2.825833366763207

Epoch: 5| Step: 8
Training loss: 4.115941524505615
Validation loss: 2.8257582854199153

Epoch: 5| Step: 9
Training loss: 3.3417229652404785
Validation loss: 2.8245222183965866

Epoch: 5| Step: 10
Training loss: 2.999032974243164
Validation loss: 2.8234774117828696

Epoch: 41| Step: 0
Training loss: 2.8062548637390137
Validation loss: 2.8228623431216002

Epoch: 5| Step: 1
Training loss: 3.1778736114501953
Validation loss: 2.8221891336543585

Epoch: 5| Step: 2
Training loss: 2.685678720474243
Validation loss: 2.8212908647393666

Epoch: 5| Step: 3
Training loss: 3.215773105621338
Validation loss: 2.821219805748232

Epoch: 5| Step: 4
Training loss: 3.39753794670105
Validation loss: 2.8212772107893422

Epoch: 5| Step: 5
Training loss: 3.742260456085205
Validation loss: 2.820253277337679

Epoch: 5| Step: 6
Training loss: 2.7389254570007324
Validation loss: 2.819986661275228

Epoch: 5| Step: 7
Training loss: 2.3947930335998535
Validation loss: 2.8197005435984623

Epoch: 5| Step: 8
Training loss: 2.4354822635650635
Validation loss: 2.818401680197767

Epoch: 5| Step: 9
Training loss: 2.7917332649230957
Validation loss: 2.818445408216087

Epoch: 5| Step: 10
Training loss: 3.0513436794281006
Validation loss: 2.8176107688616683

Epoch: 42| Step: 0
Training loss: 2.4612784385681152
Validation loss: 2.817198166283228

Epoch: 5| Step: 1
Training loss: 2.6713414192199707
Validation loss: 2.8176194237124537

Epoch: 5| Step: 2
Training loss: 2.6994268894195557
Validation loss: 2.8156657782934045

Epoch: 5| Step: 3
Training loss: 2.355673313140869
Validation loss: 2.8160392802248717

Epoch: 5| Step: 4
Training loss: 2.376081943511963
Validation loss: 2.8159072758049093

Epoch: 5| Step: 5
Training loss: 3.207883358001709
Validation loss: 2.8156310332718717

Epoch: 5| Step: 6
Training loss: 3.096402406692505
Validation loss: 2.815255365064067

Epoch: 5| Step: 7
Training loss: 3.3502578735351562
Validation loss: 2.8147622641696723

Epoch: 5| Step: 8
Training loss: 3.4404711723327637
Validation loss: 2.8138276889760006

Epoch: 5| Step: 9
Training loss: 3.5605435371398926
Validation loss: 2.8136227028344267

Epoch: 5| Step: 10
Training loss: 3.2233219146728516
Validation loss: 2.8115751435679774

Epoch: 43| Step: 0
Training loss: 2.8264224529266357
Validation loss: 2.812795559565226

Epoch: 5| Step: 1
Training loss: 3.086265802383423
Validation loss: 2.8117090707184165

Epoch: 5| Step: 2
Training loss: 3.0802230834960938
Validation loss: 2.8112947710098757

Epoch: 5| Step: 3
Training loss: 2.649348735809326
Validation loss: 2.810292402903239

Epoch: 5| Step: 4
Training loss: 2.03289794921875
Validation loss: 2.80970694429131

Epoch: 5| Step: 5
Training loss: 2.755836248397827
Validation loss: 2.8088845335027224

Epoch: 5| Step: 6
Training loss: 4.01902961730957
Validation loss: 2.808277599273189

Epoch: 5| Step: 7
Training loss: 3.246929168701172
Validation loss: 2.808232617634599

Epoch: 5| Step: 8
Training loss: 2.462614059448242
Validation loss: 2.80769540673943

Epoch: 5| Step: 9
Training loss: 3.164987564086914
Validation loss: 2.806135282721571

Epoch: 5| Step: 10
Training loss: 3.055868625640869
Validation loss: 2.8064797334773566

Epoch: 44| Step: 0
Training loss: 3.578758955001831
Validation loss: 2.806904467203284

Epoch: 5| Step: 1
Training loss: 2.751892566680908
Validation loss: 2.806868230142901

Epoch: 5| Step: 2
Training loss: 2.7452120780944824
Validation loss: 2.804711003457346

Epoch: 5| Step: 3
Training loss: 2.3426876068115234
Validation loss: 2.806041640620078

Epoch: 5| Step: 4
Training loss: 3.172550678253174
Validation loss: 2.8022907318607455

Epoch: 5| Step: 5
Training loss: 2.694709300994873
Validation loss: 2.8027939873356975

Epoch: 5| Step: 6
Training loss: 2.8838276863098145
Validation loss: 2.8094171580447944

Epoch: 5| Step: 7
Training loss: 3.5833210945129395
Validation loss: 2.8598457972208657

Epoch: 5| Step: 8
Training loss: 2.9786581993103027
Validation loss: 2.799618508226128

Epoch: 5| Step: 9
Training loss: 3.583664655685425
Validation loss: 2.8035822042854885

Epoch: 5| Step: 10
Training loss: 1.8742256164550781
Validation loss: 2.8061238053024455

Epoch: 45| Step: 0
Training loss: 3.0307724475860596
Validation loss: 2.812496946704003

Epoch: 5| Step: 1
Training loss: 3.627124786376953
Validation loss: 2.82670457132401

Epoch: 5| Step: 2
Training loss: 3.746044635772705
Validation loss: 2.8315241875187045

Epoch: 5| Step: 3
Training loss: 3.371781826019287
Validation loss: 2.818259939070671

Epoch: 5| Step: 4
Training loss: 2.70739483833313
Validation loss: 2.808362101995817

Epoch: 5| Step: 5
Training loss: 2.816924571990967
Validation loss: 2.799881209609329

Epoch: 5| Step: 6
Training loss: 2.8306236267089844
Validation loss: 2.796742534124723

Epoch: 5| Step: 7
Training loss: 3.183922290802002
Validation loss: 2.7947007545860867

Epoch: 5| Step: 8
Training loss: 3.1705150604248047
Validation loss: 2.7931873618915515

Epoch: 5| Step: 9
Training loss: 1.8879890441894531
Validation loss: 2.789956672217256

Epoch: 5| Step: 10
Training loss: 1.7991470098495483
Validation loss: 2.788746928655973

Epoch: 46| Step: 0
Training loss: 3.5134449005126953
Validation loss: 2.787906495473718

Epoch: 5| Step: 1
Training loss: 2.347947359085083
Validation loss: 2.7882686789317797

Epoch: 5| Step: 2
Training loss: 2.0678293704986572
Validation loss: 2.7969929172146704

Epoch: 5| Step: 3
Training loss: 2.7878971099853516
Validation loss: 2.7845612828449537

Epoch: 5| Step: 4
Training loss: 2.8536620140075684
Validation loss: 2.783255551450996

Epoch: 5| Step: 5
Training loss: 3.131145715713501
Validation loss: 2.781633379638836

Epoch: 5| Step: 6
Training loss: 3.435839891433716
Validation loss: 2.7830402120467155

Epoch: 5| Step: 7
Training loss: 2.3844826221466064
Validation loss: 2.7816677247324297

Epoch: 5| Step: 8
Training loss: 3.5093395709991455
Validation loss: 2.7814520841003745

Epoch: 5| Step: 9
Training loss: 2.8302977085113525
Validation loss: 2.7815615643737135

Epoch: 5| Step: 10
Training loss: 3.409856081008911
Validation loss: 2.780401873332198

Epoch: 47| Step: 0
Training loss: 3.077468156814575
Validation loss: 2.7809785463476695

Epoch: 5| Step: 1
Training loss: 3.199725389480591
Validation loss: 2.7816485692096014

Epoch: 5| Step: 2
Training loss: 2.868711471557617
Validation loss: 2.7805045086850404

Epoch: 5| Step: 3
Training loss: 2.4573230743408203
Validation loss: 2.7809436269985732

Epoch: 5| Step: 4
Training loss: 3.460048198699951
Validation loss: 2.7791979543624388

Epoch: 5| Step: 5
Training loss: 2.8953380584716797
Validation loss: 2.779269100517355

Epoch: 5| Step: 6
Training loss: 3.623605251312256
Validation loss: 2.777917262046568

Epoch: 5| Step: 7
Training loss: 2.2051587104797363
Validation loss: 2.7762844485621296

Epoch: 5| Step: 8
Training loss: 2.776082754135132
Validation loss: 2.7765756166109474

Epoch: 5| Step: 9
Training loss: 2.3859074115753174
Validation loss: 2.775878021793981

Epoch: 5| Step: 10
Training loss: 3.252366304397583
Validation loss: 2.776553379592075

Epoch: 48| Step: 0
Training loss: 2.9268369674682617
Validation loss: 2.7746705573092223

Epoch: 5| Step: 1
Training loss: 2.4822113513946533
Validation loss: 2.7745741080212336

Epoch: 5| Step: 2
Training loss: 2.7856082916259766
Validation loss: 2.772994879753359

Epoch: 5| Step: 3
Training loss: 3.433619260787964
Validation loss: 2.7737364538254274

Epoch: 5| Step: 4
Training loss: 2.5605902671813965
Validation loss: 2.772445458237843

Epoch: 5| Step: 5
Training loss: 3.40824556350708
Validation loss: 2.7711042409302085

Epoch: 5| Step: 6
Training loss: 2.592555522918701
Validation loss: 2.769504185645811

Epoch: 5| Step: 7
Training loss: 2.9553894996643066
Validation loss: 2.769905387714345

Epoch: 5| Step: 8
Training loss: 3.058520555496216
Validation loss: 2.7686384724032496

Epoch: 5| Step: 9
Training loss: 2.547255039215088
Validation loss: 2.7671029747173352

Epoch: 5| Step: 10
Training loss: 3.414635181427002
Validation loss: 2.7660730808011946

Epoch: 49| Step: 0
Training loss: 3.2105393409729004
Validation loss: 2.7657532256136657

Epoch: 5| Step: 1
Training loss: 3.0498709678649902
Validation loss: 2.764204430323775

Epoch: 5| Step: 2
Training loss: 3.4007086753845215
Validation loss: 2.76356771684462

Epoch: 5| Step: 3
Training loss: 3.2426819801330566
Validation loss: 2.7614596274591263

Epoch: 5| Step: 4
Training loss: 2.5429091453552246
Validation loss: 2.75887155789201

Epoch: 5| Step: 5
Training loss: 2.8937199115753174
Validation loss: 2.7571455176158617

Epoch: 5| Step: 6
Training loss: 2.177391767501831
Validation loss: 2.758223433648386

Epoch: 5| Step: 7
Training loss: 2.975740909576416
Validation loss: 2.7564790992326635

Epoch: 5| Step: 8
Training loss: 2.787630796432495
Validation loss: 2.754863969741329

Epoch: 5| Step: 9
Training loss: 2.6307358741760254
Validation loss: 2.7544996328251337

Epoch: 5| Step: 10
Training loss: 3.1302664279937744
Validation loss: 2.754975539381786

Epoch: 50| Step: 0
Training loss: 2.5761008262634277
Validation loss: 2.7523291598084154

Epoch: 5| Step: 1
Training loss: 2.919567823410034
Validation loss: 2.752993852861466

Epoch: 5| Step: 2
Training loss: 2.5571160316467285
Validation loss: 2.7502350499553065

Epoch: 5| Step: 3
Training loss: 3.664860963821411
Validation loss: 2.75068764276402

Epoch: 5| Step: 4
Training loss: 3.6848983764648438
Validation loss: 2.7526997212440736

Epoch: 5| Step: 5
Training loss: 2.7588090896606445
Validation loss: 2.749157015995313

Epoch: 5| Step: 6
Training loss: 2.984576463699341
Validation loss: 2.748580668562202

Epoch: 5| Step: 7
Training loss: 2.9508588314056396
Validation loss: 2.748855677984094

Epoch: 5| Step: 8
Training loss: 2.9113502502441406
Validation loss: 2.748413224374094

Epoch: 5| Step: 9
Training loss: 2.524602174758911
Validation loss: 2.749388058980306

Epoch: 5| Step: 10
Training loss: 2.309364080429077
Validation loss: 2.749065145369499

Epoch: 51| Step: 0
Training loss: 3.038989543914795
Validation loss: 2.7475028089297715

Epoch: 5| Step: 1
Training loss: 3.9440064430236816
Validation loss: 2.747358973308276

Epoch: 5| Step: 2
Training loss: 2.879969835281372
Validation loss: 2.748698631922404

Epoch: 5| Step: 3
Training loss: 2.997213840484619
Validation loss: 2.7463778782916326

Epoch: 5| Step: 4
Training loss: 3.0340256690979004
Validation loss: 2.7472529206224667

Epoch: 5| Step: 5
Training loss: 2.9475762844085693
Validation loss: 2.747024090059342

Epoch: 5| Step: 6
Training loss: 3.013856887817383
Validation loss: 2.7468464169450986

Epoch: 5| Step: 7
Training loss: 2.478968620300293
Validation loss: 2.7458578694251274

Epoch: 5| Step: 8
Training loss: 2.082360029220581
Validation loss: 2.7441791693369546

Epoch: 5| Step: 9
Training loss: 3.3759448528289795
Validation loss: 2.7428781960600164

Epoch: 5| Step: 10
Training loss: 1.9748926162719727
Validation loss: 2.7424353527766403

Epoch: 52| Step: 0
Training loss: 2.9602999687194824
Validation loss: 2.742466785574472

Epoch: 5| Step: 1
Training loss: 3.469686985015869
Validation loss: 2.741610603947793

Epoch: 5| Step: 2
Training loss: 2.043753147125244
Validation loss: 2.7409412989052395

Epoch: 5| Step: 3
Training loss: 2.6715304851531982
Validation loss: 2.743264554649271

Epoch: 5| Step: 4
Training loss: 3.5328831672668457
Validation loss: 2.744097045672837

Epoch: 5| Step: 5
Training loss: 2.213479518890381
Validation loss: 2.7418069147294566

Epoch: 5| Step: 6
Training loss: 2.823695659637451
Validation loss: 2.738870859146118

Epoch: 5| Step: 7
Training loss: 2.9683356285095215
Validation loss: 2.7391642857623357

Epoch: 5| Step: 8
Training loss: 3.1876657009124756
Validation loss: 2.739019657975884

Epoch: 5| Step: 9
Training loss: 2.738715171813965
Validation loss: 2.736000302017376

Epoch: 5| Step: 10
Training loss: 3.3255372047424316
Validation loss: 2.736958119177049

Epoch: 53| Step: 0
Training loss: 2.7245678901672363
Validation loss: 2.7373639998897428

Epoch: 5| Step: 1
Training loss: 3.312678575515747
Validation loss: 2.7391857741981425

Epoch: 5| Step: 2
Training loss: 2.2585904598236084
Validation loss: 2.739465590446226

Epoch: 5| Step: 3
Training loss: 3.0769200325012207
Validation loss: 2.7381059559442664

Epoch: 5| Step: 4
Training loss: 3.5736801624298096
Validation loss: 2.7399577145935385

Epoch: 5| Step: 5
Training loss: 3.0907459259033203
Validation loss: 2.7358512032416558

Epoch: 5| Step: 6
Training loss: 2.5357792377471924
Validation loss: 2.7374487487218713

Epoch: 5| Step: 7
Training loss: 2.6172938346862793
Validation loss: 2.7370039468170493

Epoch: 5| Step: 8
Training loss: 2.7920870780944824
Validation loss: 2.7385424926716793

Epoch: 5| Step: 9
Training loss: 2.5409741401672363
Validation loss: 2.733562377191359

Epoch: 5| Step: 10
Training loss: 3.3642890453338623
Validation loss: 2.731477616935648

Epoch: 54| Step: 0
Training loss: 3.15881085395813
Validation loss: 2.7348560133287982

Epoch: 5| Step: 1
Training loss: 2.9875426292419434
Validation loss: 2.7357709407806396

Epoch: 5| Step: 2
Training loss: 2.6120378971099854
Validation loss: 2.7351597175803235

Epoch: 5| Step: 3
Training loss: 2.9402458667755127
Validation loss: 2.7332339312440608

Epoch: 5| Step: 4
Training loss: 3.5954604148864746
Validation loss: 2.733237794650498

Epoch: 5| Step: 5
Training loss: 3.095525026321411
Validation loss: 2.733653809434624

Epoch: 5| Step: 6
Training loss: 2.8889553546905518
Validation loss: 2.7335682581829768

Epoch: 5| Step: 7
Training loss: 2.8714067935943604
Validation loss: 2.7340421010089178

Epoch: 5| Step: 8
Training loss: 2.6644110679626465
Validation loss: 2.7324363980242

Epoch: 5| Step: 9
Training loss: 2.2853493690490723
Validation loss: 2.730290312920847

Epoch: 5| Step: 10
Training loss: 2.689399480819702
Validation loss: 2.7293037958042596

Epoch: 55| Step: 0
Training loss: 2.0944652557373047
Validation loss: 2.7291237846497567

Epoch: 5| Step: 1
Training loss: 3.7827582359313965
Validation loss: 2.7310486737117974

Epoch: 5| Step: 2
Training loss: 2.91227126121521
Validation loss: 2.7299917692779214

Epoch: 5| Step: 3
Training loss: 3.198057174682617
Validation loss: 2.729567958462623

Epoch: 5| Step: 4
Training loss: 2.4547677040100098
Validation loss: 2.7299700936963482

Epoch: 5| Step: 5
Training loss: 3.0867795944213867
Validation loss: 2.7311311460310415

Epoch: 5| Step: 6
Training loss: 2.944568395614624
Validation loss: 2.7318502318474556

Epoch: 5| Step: 7
Training loss: 2.5043482780456543
Validation loss: 2.7324680718042518

Epoch: 5| Step: 8
Training loss: 2.8226897716522217
Validation loss: 2.734870005679387

Epoch: 5| Step: 9
Training loss: 2.9681873321533203
Validation loss: 2.727240506038871

Epoch: 5| Step: 10
Training loss: 2.9992880821228027
Validation loss: 2.727944048502112

Epoch: 56| Step: 0
Training loss: 2.565539598464966
Validation loss: 2.7262559706164944

Epoch: 5| Step: 1
Training loss: 2.6570920944213867
Validation loss: 2.7270443875302552

Epoch: 5| Step: 2
Training loss: 3.0628466606140137
Validation loss: 2.723588543553506

Epoch: 5| Step: 3
Training loss: 2.682267427444458
Validation loss: 2.7244795086563274

Epoch: 5| Step: 4
Training loss: 3.9466826915740967
Validation loss: 2.725573388479089

Epoch: 5| Step: 5
Training loss: 3.4374091625213623
Validation loss: 2.723958794788648

Epoch: 5| Step: 6
Training loss: 2.5821642875671387
Validation loss: 2.723879498820151

Epoch: 5| Step: 7
Training loss: 2.7273993492126465
Validation loss: 2.7234680165526686

Epoch: 5| Step: 8
Training loss: 2.56827712059021
Validation loss: 2.7286318117572415

Epoch: 5| Step: 9
Training loss: 2.742769718170166
Validation loss: 2.7493123469814176

Epoch: 5| Step: 10
Training loss: 2.7327897548675537
Validation loss: 2.7703291831477994

Epoch: 57| Step: 0
Training loss: 3.0801825523376465
Validation loss: 2.758545260275564

Epoch: 5| Step: 1
Training loss: 2.6175365447998047
Validation loss: 2.726195396915559

Epoch: 5| Step: 2
Training loss: 3.1693787574768066
Validation loss: 2.720662998896773

Epoch: 5| Step: 3
Training loss: 2.3462817668914795
Validation loss: 2.7214397512456423

Epoch: 5| Step: 4
Training loss: 2.7770490646362305
Validation loss: 2.723765565503028

Epoch: 5| Step: 5
Training loss: 3.431485652923584
Validation loss: 2.7277817546680407

Epoch: 5| Step: 6
Training loss: 2.9253547191619873
Validation loss: 2.7448019725020214

Epoch: 5| Step: 7
Training loss: 2.6128056049346924
Validation loss: 2.7688844485949446

Epoch: 5| Step: 8
Training loss: 2.5473787784576416
Validation loss: 2.8147648175557456

Epoch: 5| Step: 9
Training loss: 3.120262622833252
Validation loss: 2.8394730347459034

Epoch: 5| Step: 10
Training loss: 3.450129270553589
Validation loss: 2.8427941055708033

Epoch: 58| Step: 0
Training loss: 3.089122772216797
Validation loss: 2.8305526523179907

Epoch: 5| Step: 1
Training loss: 3.377338409423828
Validation loss: 2.8076751975603003

Epoch: 5| Step: 2
Training loss: 2.9591877460479736
Validation loss: 2.7977305253346763

Epoch: 5| Step: 3
Training loss: 3.4060370922088623
Validation loss: 2.7917248536181707

Epoch: 5| Step: 4
Training loss: 2.78100323677063
Validation loss: 2.7815921255337295

Epoch: 5| Step: 5
Training loss: 2.5103347301483154
Validation loss: 2.7282363214800434

Epoch: 5| Step: 6
Training loss: 2.528714895248413
Validation loss: 2.760678175956972

Epoch: 5| Step: 7
Training loss: 2.653154134750366
Validation loss: 2.793359077104958

Epoch: 5| Step: 8
Training loss: 3.0994479656219482
Validation loss: 2.818732633385607

Epoch: 5| Step: 9
Training loss: 1.9580211639404297
Validation loss: 2.7511998658539145

Epoch: 5| Step: 10
Training loss: 3.8644516468048096
Validation loss: 2.7186888161525933

Epoch: 59| Step: 0
Training loss: 2.287456750869751
Validation loss: 2.714343673439436

Epoch: 5| Step: 1
Training loss: 2.6965882778167725
Validation loss: 2.721868194559569

Epoch: 5| Step: 2
Training loss: 2.9012341499328613
Validation loss: 2.728314351010066

Epoch: 5| Step: 3
Training loss: 3.363131046295166
Validation loss: 2.7292064646238923

Epoch: 5| Step: 4
Training loss: 2.9759223461151123
Validation loss: 2.7242505037656395

Epoch: 5| Step: 5
Training loss: 2.957195997238159
Validation loss: 2.722778699731314

Epoch: 5| Step: 6
Training loss: 2.8650834560394287
Validation loss: 2.722222148731191

Epoch: 5| Step: 7
Training loss: 2.9250895977020264
Validation loss: 2.718635851337064

Epoch: 5| Step: 8
Training loss: 2.647188186645508
Validation loss: 2.715620620276338

Epoch: 5| Step: 9
Training loss: 3.9029364585876465
Validation loss: 2.7154984166545253

Epoch: 5| Step: 10
Training loss: 2.0724589824676514
Validation loss: 2.7175711688174995

Epoch: 60| Step: 0
Training loss: 3.6011428833007812
Validation loss: 2.716832096858691

Epoch: 5| Step: 1
Training loss: 3.118842601776123
Validation loss: 2.7199339123182398

Epoch: 5| Step: 2
Training loss: 2.64367938041687
Validation loss: 2.7251686896047285

Epoch: 5| Step: 3
Training loss: 2.9895143508911133
Validation loss: 2.722788013437743

Epoch: 5| Step: 4
Training loss: 2.165984630584717
Validation loss: 2.7225412296992477

Epoch: 5| Step: 5
Training loss: 2.1128287315368652
Validation loss: 2.7328240230519283

Epoch: 5| Step: 6
Training loss: 2.8095901012420654
Validation loss: 2.7296659023531022

Epoch: 5| Step: 7
Training loss: 2.6861538887023926
Validation loss: 2.718435140066249

Epoch: 5| Step: 8
Training loss: 3.408777952194214
Validation loss: 2.7147451344356743

Epoch: 5| Step: 9
Training loss: 3.24101185798645
Validation loss: 2.712381498787993

Epoch: 5| Step: 10
Training loss: 2.865539789199829
Validation loss: 2.7125554136050645

Epoch: 61| Step: 0
Training loss: 2.9048945903778076
Validation loss: 2.713634752458142

Epoch: 5| Step: 1
Training loss: 2.378802537918091
Validation loss: 2.7084046486885316

Epoch: 5| Step: 2
Training loss: 2.4605038166046143
Validation loss: 2.704832189826555

Epoch: 5| Step: 3
Training loss: 3.1546998023986816
Validation loss: 2.711985613710137

Epoch: 5| Step: 4
Training loss: 3.458482027053833
Validation loss: 2.704937211928829

Epoch: 5| Step: 5
Training loss: 2.9797229766845703
Validation loss: 2.705885312890494

Epoch: 5| Step: 6
Training loss: 3.595757246017456
Validation loss: 2.709948798661591

Epoch: 5| Step: 7
Training loss: 2.840094804763794
Validation loss: 2.708065986633301

Epoch: 5| Step: 8
Training loss: 3.0953831672668457
Validation loss: 2.7123367196770123

Epoch: 5| Step: 9
Training loss: 2.269702672958374
Validation loss: 2.7154432240352837

Epoch: 5| Step: 10
Training loss: 2.4015908241271973
Validation loss: 2.7185533149268037

Epoch: 62| Step: 0
Training loss: 2.5028469562530518
Validation loss: 2.7678210145683697

Epoch: 5| Step: 1
Training loss: 3.3875184059143066
Validation loss: 2.7904524777525213

Epoch: 5| Step: 2
Training loss: 2.7940497398376465
Validation loss: 2.8039906768388647

Epoch: 5| Step: 3
Training loss: 3.2493770122528076
Validation loss: 2.825931356799218

Epoch: 5| Step: 4
Training loss: 2.1414105892181396
Validation loss: 2.817283115079326

Epoch: 5| Step: 5
Training loss: 2.898062229156494
Validation loss: 2.7849742725331295

Epoch: 5| Step: 6
Training loss: 3.554185390472412
Validation loss: 2.766146534232683

Epoch: 5| Step: 7
Training loss: 2.5315709114074707
Validation loss: 2.7491394499296784

Epoch: 5| Step: 8
Training loss: 1.9686444997787476
Validation loss: 2.7208685721120527

Epoch: 5| Step: 9
Training loss: 3.6282219886779785
Validation loss: 2.7208419692131782

Epoch: 5| Step: 10
Training loss: 3.4241957664489746
Validation loss: 2.749045425845731

Epoch: 63| Step: 0
Training loss: 3.126002788543701
Validation loss: 2.7458223578750447

Epoch: 5| Step: 1
Training loss: 2.9124836921691895
Validation loss: 2.744603705662553

Epoch: 5| Step: 2
Training loss: 2.9108941555023193
Validation loss: 2.7328614419506443

Epoch: 5| Step: 3
Training loss: 3.861987352371216
Validation loss: 2.733911665537024

Epoch: 5| Step: 4
Training loss: 2.964320421218872
Validation loss: 2.7174332064967

Epoch: 5| Step: 5
Training loss: 2.8650338649749756
Validation loss: 2.6994093002811557

Epoch: 5| Step: 6
Training loss: 2.452990770339966
Validation loss: 2.7023636064221783

Epoch: 5| Step: 7
Training loss: 2.8582568168640137
Validation loss: 2.708952357692103

Epoch: 5| Step: 8
Training loss: 2.9734854698181152
Validation loss: 2.7207298842809533

Epoch: 5| Step: 9
Training loss: 2.5009968280792236
Validation loss: 2.732792792781707

Epoch: 5| Step: 10
Training loss: 2.160158634185791
Validation loss: 2.742710851853894

Epoch: 64| Step: 0
Training loss: 3.0255722999572754
Validation loss: 2.7242684043863767

Epoch: 5| Step: 1
Training loss: 2.737096071243286
Validation loss: 2.7177270509863414

Epoch: 5| Step: 2
Training loss: 2.505404472351074
Validation loss: 2.7061997203416723

Epoch: 5| Step: 3
Training loss: 3.1855874061584473
Validation loss: 2.7047656582247828

Epoch: 5| Step: 4
Training loss: 3.725964069366455
Validation loss: 2.6995747397022862

Epoch: 5| Step: 5
Training loss: 2.806459426879883
Validation loss: 2.69356676583649

Epoch: 5| Step: 6
Training loss: 2.5303921699523926
Validation loss: 2.695949682625391

Epoch: 5| Step: 7
Training loss: 2.644186496734619
Validation loss: 2.6940990391597954

Epoch: 5| Step: 8
Training loss: 2.8409204483032227
Validation loss: 2.695533608877531

Epoch: 5| Step: 9
Training loss: 2.814485549926758
Validation loss: 2.6943152848110405

Epoch: 5| Step: 10
Training loss: 2.6356616020202637
Validation loss: 2.6950781883731967

Epoch: 65| Step: 0
Training loss: 2.737447738647461
Validation loss: 2.692285760756462

Epoch: 5| Step: 1
Training loss: 2.306241989135742
Validation loss: 2.6923663872544483

Epoch: 5| Step: 2
Training loss: 3.3342716693878174
Validation loss: 2.696205903125066

Epoch: 5| Step: 3
Training loss: 3.1649117469787598
Validation loss: 2.694367326715941

Epoch: 5| Step: 4
Training loss: 3.216358184814453
Validation loss: 2.696526260786159

Epoch: 5| Step: 5
Training loss: 3.4895381927490234
Validation loss: 2.695187476373488

Epoch: 5| Step: 6
Training loss: 1.7417371273040771
Validation loss: 2.6902335510458997

Epoch: 5| Step: 7
Training loss: 2.333865165710449
Validation loss: 2.6894534659642044

Epoch: 5| Step: 8
Training loss: 2.928220272064209
Validation loss: 2.688916734469834

Epoch: 5| Step: 9
Training loss: 3.166776180267334
Validation loss: 2.6917262333695606

Epoch: 5| Step: 10
Training loss: 2.8029417991638184
Validation loss: 2.714293849083685

Epoch: 66| Step: 0
Training loss: 2.3237171173095703
Validation loss: 2.73313061652645

Epoch: 5| Step: 1
Training loss: 2.9130523204803467
Validation loss: 2.7318239494036605

Epoch: 5| Step: 2
Training loss: 3.209829807281494
Validation loss: 2.751159470568421

Epoch: 5| Step: 3
Training loss: 2.5588672161102295
Validation loss: 2.706649067581341

Epoch: 5| Step: 4
Training loss: 3.4538111686706543
Validation loss: 2.6880703869686333

Epoch: 5| Step: 5
Training loss: 2.131901264190674
Validation loss: 2.6833281055573495

Epoch: 5| Step: 6
Training loss: 3.751110076904297
Validation loss: 2.6897018545417377

Epoch: 5| Step: 7
Training loss: 2.748887062072754
Validation loss: 2.6918200677441013

Epoch: 5| Step: 8
Training loss: 3.345149517059326
Validation loss: 2.6902288954745055

Epoch: 5| Step: 9
Training loss: 2.5388998985290527
Validation loss: 2.690921104082497

Epoch: 5| Step: 10
Training loss: 2.3078067302703857
Validation loss: 2.693510424706244

Epoch: 67| Step: 0
Training loss: 3.57232403755188
Validation loss: 2.6941061532625588

Epoch: 5| Step: 1
Training loss: 2.5368878841400146
Validation loss: 2.6938670860823763

Epoch: 5| Step: 2
Training loss: 2.998291492462158
Validation loss: 2.7042132039223947

Epoch: 5| Step: 3
Training loss: 2.7796120643615723
Validation loss: 2.699178303441694

Epoch: 5| Step: 4
Training loss: 2.618403434753418
Validation loss: 2.6956199779305408

Epoch: 5| Step: 5
Training loss: 3.0632219314575195
Validation loss: 2.7336593930439284

Epoch: 5| Step: 6
Training loss: 3.4569015502929688
Validation loss: 2.685411942902432

Epoch: 5| Step: 7
Training loss: 2.677067279815674
Validation loss: 2.6784646805896553

Epoch: 5| Step: 8
Training loss: 2.2382445335388184
Validation loss: 2.6873694876188874

Epoch: 5| Step: 9
Training loss: 2.6992340087890625
Validation loss: 2.6791714699037614

Epoch: 5| Step: 10
Training loss: 2.742710828781128
Validation loss: 2.6795818421148483

Epoch: 68| Step: 0
Training loss: 3.247476100921631
Validation loss: 2.677936407827562

Epoch: 5| Step: 1
Training loss: 2.5437986850738525
Validation loss: 2.682499385649158

Epoch: 5| Step: 2
Training loss: 2.8516740798950195
Validation loss: 2.679930276768182

Epoch: 5| Step: 3
Training loss: 2.31837797164917
Validation loss: 2.6812932747666554

Epoch: 5| Step: 4
Training loss: 2.9860100746154785
Validation loss: 2.679158003099503

Epoch: 5| Step: 5
Training loss: 2.9880759716033936
Validation loss: 2.676396228933847

Epoch: 5| Step: 6
Training loss: 2.851938247680664
Validation loss: 2.674192659316524

Epoch: 5| Step: 7
Training loss: 2.7938485145568848
Validation loss: 2.6731843486908944

Epoch: 5| Step: 8
Training loss: 3.628328323364258
Validation loss: 2.6831275801504813

Epoch: 5| Step: 9
Training loss: 3.000152587890625
Validation loss: 2.699179152006744

Epoch: 5| Step: 10
Training loss: 1.7850431203842163
Validation loss: 2.7322822155491

Epoch: 69| Step: 0
Training loss: 2.923367977142334
Validation loss: 2.777452822654478

Epoch: 5| Step: 1
Training loss: 2.556720733642578
Validation loss: 2.7676000415637927

Epoch: 5| Step: 2
Training loss: 3.179988384246826
Validation loss: 2.734885149104621

Epoch: 5| Step: 3
Training loss: 2.518601655960083
Validation loss: 2.698509339363344

Epoch: 5| Step: 4
Training loss: 2.9872684478759766
Validation loss: 2.673965654065532

Epoch: 5| Step: 5
Training loss: 2.4688169956207275
Validation loss: 2.6757702878726426

Epoch: 5| Step: 6
Training loss: 2.7188282012939453
Validation loss: 2.6807743400655766

Epoch: 5| Step: 7
Training loss: 3.135957717895508
Validation loss: 2.6824220739385134

Epoch: 5| Step: 8
Training loss: 2.743431329727173
Validation loss: 2.6858035031185357

Epoch: 5| Step: 9
Training loss: 3.1144678592681885
Validation loss: 2.685777028401693

Epoch: 5| Step: 10
Training loss: 3.0382091999053955
Validation loss: 2.685601585654802

Epoch: 70| Step: 0
Training loss: 2.748169422149658
Validation loss: 2.684099071769304

Epoch: 5| Step: 1
Training loss: 2.5264785289764404
Validation loss: 2.68178060490598

Epoch: 5| Step: 2
Training loss: 3.5807137489318848
Validation loss: 2.677976408312398

Epoch: 5| Step: 3
Training loss: 2.696760654449463
Validation loss: 2.6768452582820768

Epoch: 5| Step: 4
Training loss: 3.4708189964294434
Validation loss: 2.671797375525198

Epoch: 5| Step: 5
Training loss: 3.336111545562744
Validation loss: 2.668465950155771

Epoch: 5| Step: 6
Training loss: 2.6770424842834473
Validation loss: 2.669562896092733

Epoch: 5| Step: 7
Training loss: 3.105044364929199
Validation loss: 2.6745195337521133

Epoch: 5| Step: 8
Training loss: 2.882143497467041
Validation loss: 2.686299785490959

Epoch: 5| Step: 9
Training loss: 2.610962390899658
Validation loss: 2.709747996381534

Epoch: 5| Step: 10
Training loss: 1.347682237625122
Validation loss: 2.7060692438515286

Epoch: 71| Step: 0
Training loss: 3.1869170665740967
Validation loss: 2.692338779408445

Epoch: 5| Step: 1
Training loss: 2.4681432247161865
Validation loss: 2.6753644622782224

Epoch: 5| Step: 2
Training loss: 2.4738588333129883
Validation loss: 2.6692490667425175

Epoch: 5| Step: 3
Training loss: 2.125375509262085
Validation loss: 2.665450490931029

Epoch: 5| Step: 4
Training loss: 2.919039249420166
Validation loss: 2.6680428904871785

Epoch: 5| Step: 5
Training loss: 2.800809383392334
Validation loss: 2.671604723058721

Epoch: 5| Step: 6
Training loss: 3.2101283073425293
Validation loss: 2.676591222004224

Epoch: 5| Step: 7
Training loss: 2.7757315635681152
Validation loss: 2.675367283564742

Epoch: 5| Step: 8
Training loss: 3.5008087158203125
Validation loss: 2.6816269543863114

Epoch: 5| Step: 9
Training loss: 2.4185707569122314
Validation loss: 2.679671500318794

Epoch: 5| Step: 10
Training loss: 3.3062915802001953
Validation loss: 2.6781531995342625

Epoch: 72| Step: 0
Training loss: 2.8044850826263428
Validation loss: 2.6724776555133123

Epoch: 5| Step: 1
Training loss: 2.405656337738037
Validation loss: 2.6624957822984263

Epoch: 5| Step: 2
Training loss: 3.232807159423828
Validation loss: 2.660163220538888

Epoch: 5| Step: 3
Training loss: 2.690284013748169
Validation loss: 2.658049742380778

Epoch: 5| Step: 4
Training loss: 2.7371177673339844
Validation loss: 2.662713066224129

Epoch: 5| Step: 5
Training loss: 3.3763229846954346
Validation loss: 2.664593360757315

Epoch: 5| Step: 6
Training loss: 2.9078445434570312
Validation loss: 2.675301931237662

Epoch: 5| Step: 7
Training loss: 2.6472017765045166
Validation loss: 2.6759081143204884

Epoch: 5| Step: 8
Training loss: 2.5163681507110596
Validation loss: 2.6837171713511148

Epoch: 5| Step: 9
Training loss: 2.752101421356201
Validation loss: 2.6859010945084276

Epoch: 5| Step: 10
Training loss: 2.9467151165008545
Validation loss: 2.686443508312266

Epoch: 73| Step: 0
Training loss: 3.59533429145813
Validation loss: 2.6845257589893956

Epoch: 5| Step: 1
Training loss: 2.5528013706207275
Validation loss: 2.674973331471925

Epoch: 5| Step: 2
Training loss: 2.1355435848236084
Validation loss: 2.6649240780902166

Epoch: 5| Step: 3
Training loss: 2.7993831634521484
Validation loss: 2.6613053429511284

Epoch: 5| Step: 4
Training loss: 2.8317482471466064
Validation loss: 2.6577890098735852

Epoch: 5| Step: 5
Training loss: 3.4726662635803223
Validation loss: 2.658774955298311

Epoch: 5| Step: 6
Training loss: 3.121910810470581
Validation loss: 2.6543511985450663

Epoch: 5| Step: 7
Training loss: 2.4202938079833984
Validation loss: 2.6556736218032015

Epoch: 5| Step: 8
Training loss: 2.6900811195373535
Validation loss: 2.653970754274758

Epoch: 5| Step: 9
Training loss: 2.998121500015259
Validation loss: 2.6612023743250037

Epoch: 5| Step: 10
Training loss: 2.257089614868164
Validation loss: 2.6635973402248916

Epoch: 74| Step: 0
Training loss: 3.486344814300537
Validation loss: 2.667181673870292

Epoch: 5| Step: 1
Training loss: 3.3566784858703613
Validation loss: 2.6636195951892483

Epoch: 5| Step: 2
Training loss: 2.7211387157440186
Validation loss: 2.6579131516077186

Epoch: 5| Step: 3
Training loss: 3.0576610565185547
Validation loss: 2.6527283935136694

Epoch: 5| Step: 4
Training loss: 2.476273775100708
Validation loss: 2.653617076976325

Epoch: 5| Step: 5
Training loss: 2.4880449771881104
Validation loss: 2.658042482150498

Epoch: 5| Step: 6
Training loss: 2.360600233078003
Validation loss: 2.6552710046050367

Epoch: 5| Step: 7
Training loss: 2.728921413421631
Validation loss: 2.6533358250894854

Epoch: 5| Step: 8
Training loss: 2.0547492504119873
Validation loss: 2.6550562612472044

Epoch: 5| Step: 9
Training loss: 3.0001778602600098
Validation loss: 2.652190436599075

Epoch: 5| Step: 10
Training loss: 3.2452332973480225
Validation loss: 2.652954916800222

Epoch: 75| Step: 0
Training loss: 3.9528427124023438
Validation loss: 2.6510349858191704

Epoch: 5| Step: 1
Training loss: 2.5427005290985107
Validation loss: 2.650073964108703

Epoch: 5| Step: 2
Training loss: 2.8274598121643066
Validation loss: 2.6507694362312235

Epoch: 5| Step: 3
Training loss: 2.9542737007141113
Validation loss: 2.6549299942549838

Epoch: 5| Step: 4
Training loss: 2.2896363735198975
Validation loss: 2.6573812141213367

Epoch: 5| Step: 5
Training loss: 2.793926239013672
Validation loss: 2.662324459322037

Epoch: 5| Step: 6
Training loss: 2.5563933849334717
Validation loss: 2.6618571896706857

Epoch: 5| Step: 7
Training loss: 3.1922810077667236
Validation loss: 2.655464067254015

Epoch: 5| Step: 8
Training loss: 2.476112127304077
Validation loss: 2.6552341471436205

Epoch: 5| Step: 9
Training loss: 2.4954960346221924
Validation loss: 2.647021673058951

Epoch: 5| Step: 10
Training loss: 2.7221333980560303
Validation loss: 2.646744038469048

Epoch: 76| Step: 0
Training loss: 2.8745527267456055
Validation loss: 2.6509425922106673

Epoch: 5| Step: 1
Training loss: 2.9941718578338623
Validation loss: 2.6466646784095356

Epoch: 5| Step: 2
Training loss: 2.5287485122680664
Validation loss: 2.6488216359128236

Epoch: 5| Step: 3
Training loss: 2.233386516571045
Validation loss: 2.647719698567544

Epoch: 5| Step: 4
Training loss: 3.301196336746216
Validation loss: 2.648367658738167

Epoch: 5| Step: 5
Training loss: 2.7252132892608643
Validation loss: 2.64506007266301

Epoch: 5| Step: 6
Training loss: 2.2179906368255615
Validation loss: 2.6442319295739614

Epoch: 5| Step: 7
Training loss: 3.590317964553833
Validation loss: 2.641121482336393

Epoch: 5| Step: 8
Training loss: 2.5171713829040527
Validation loss: 2.6430218604303177

Epoch: 5| Step: 9
Training loss: 3.10465931892395
Validation loss: 2.644970578532065

Epoch: 5| Step: 10
Training loss: 2.672311782836914
Validation loss: 2.6409560890607935

Epoch: 77| Step: 0
Training loss: 2.88100266456604
Validation loss: 2.6447893419573383

Epoch: 5| Step: 1
Training loss: 2.4342892169952393
Validation loss: 2.6496681808143534

Epoch: 5| Step: 2
Training loss: 2.67132306098938
Validation loss: 2.6558571810363443

Epoch: 5| Step: 3
Training loss: 2.7301888465881348
Validation loss: 2.6708945305116716

Epoch: 5| Step: 4
Training loss: 1.915222406387329
Validation loss: 2.6781695504342355

Epoch: 5| Step: 5
Training loss: 3.282817840576172
Validation loss: 2.67787080682734

Epoch: 5| Step: 6
Training loss: 2.8101863861083984
Validation loss: 2.6624267511470343

Epoch: 5| Step: 7
Training loss: 3.6884593963623047
Validation loss: 2.6544694926149104

Epoch: 5| Step: 8
Training loss: 2.569031238555908
Validation loss: 2.6535238040390836

Epoch: 5| Step: 9
Training loss: 2.4661383628845215
Validation loss: 2.6449262506218365

Epoch: 5| Step: 10
Training loss: 3.515465021133423
Validation loss: 2.6424022259250766

Epoch: 78| Step: 0
Training loss: 2.868675708770752
Validation loss: 2.639252926713677

Epoch: 5| Step: 1
Training loss: 3.015277624130249
Validation loss: 2.641473972669212

Epoch: 5| Step: 2
Training loss: 3.0909364223480225
Validation loss: 2.643437667559552

Epoch: 5| Step: 3
Training loss: 2.408008098602295
Validation loss: 2.6392231731004614

Epoch: 5| Step: 4
Training loss: 3.0994811058044434
Validation loss: 2.6423712930371686

Epoch: 5| Step: 5
Training loss: 2.2971129417419434
Validation loss: 2.6402021044044086

Epoch: 5| Step: 6
Training loss: 3.1930127143859863
Validation loss: 2.636988068139681

Epoch: 5| Step: 7
Training loss: 2.113832473754883
Validation loss: 2.6369292915508313

Epoch: 5| Step: 8
Training loss: 2.6523849964141846
Validation loss: 2.6348968270004436

Epoch: 5| Step: 9
Training loss: 3.198603868484497
Validation loss: 2.642634550730387

Epoch: 5| Step: 10
Training loss: 2.790977954864502
Validation loss: 2.6491498793325117

Epoch: 79| Step: 0
Training loss: 2.391489267349243
Validation loss: 2.6482982148406324

Epoch: 5| Step: 1
Training loss: 3.0086076259613037
Validation loss: 2.6489036672858783

Epoch: 5| Step: 2
Training loss: 2.1019115447998047
Validation loss: 2.6697417536089496

Epoch: 5| Step: 3
Training loss: 2.991550922393799
Validation loss: 2.673761513925368

Epoch: 5| Step: 4
Training loss: 3.4992873668670654
Validation loss: 2.677425148666546

Epoch: 5| Step: 5
Training loss: 2.9396071434020996
Validation loss: 2.6746284013153403

Epoch: 5| Step: 6
Training loss: 3.2562737464904785
Validation loss: 2.657613733763336

Epoch: 5| Step: 7
Training loss: 2.6757216453552246
Validation loss: 2.63944734040127

Epoch: 5| Step: 8
Training loss: 2.559298515319824
Validation loss: 2.6320325020820863

Epoch: 5| Step: 9
Training loss: 2.8634891510009766
Validation loss: 2.6387453284314883

Epoch: 5| Step: 10
Training loss: 2.474231243133545
Validation loss: 2.6335329060913413

Epoch: 80| Step: 0
Training loss: 2.370903491973877
Validation loss: 2.6354401111602783

Epoch: 5| Step: 1
Training loss: 3.1556010246276855
Validation loss: 2.634257311462074

Epoch: 5| Step: 2
Training loss: 2.7580857276916504
Validation loss: 2.6321891353976343

Epoch: 5| Step: 3
Training loss: 3.140007972717285
Validation loss: 2.6318950319802887

Epoch: 5| Step: 4
Training loss: 2.8466219902038574
Validation loss: 2.635705537693475

Epoch: 5| Step: 5
Training loss: 2.404156446456909
Validation loss: 2.639152139745733

Epoch: 5| Step: 6
Training loss: 3.108818531036377
Validation loss: 2.63508116814398

Epoch: 5| Step: 7
Training loss: 2.7796592712402344
Validation loss: 2.634518664370301

Epoch: 5| Step: 8
Training loss: 2.7501468658447266
Validation loss: 2.638081771071239

Epoch: 5| Step: 9
Training loss: 2.7724039554595947
Validation loss: 2.633531424307054

Epoch: 5| Step: 10
Training loss: 2.5738840103149414
Validation loss: 2.6309017263432986

Epoch: 81| Step: 0
Training loss: 2.7982678413391113
Validation loss: 2.629869907133041

Epoch: 5| Step: 1
Training loss: 2.7675764560699463
Validation loss: 2.6298538818154285

Epoch: 5| Step: 2
Training loss: 2.7938790321350098
Validation loss: 2.6298899496755292

Epoch: 5| Step: 3
Training loss: 2.431300401687622
Validation loss: 2.6396032174428306

Epoch: 5| Step: 4
Training loss: 3.5839691162109375
Validation loss: 2.644378877455188

Epoch: 5| Step: 5
Training loss: 2.6222946643829346
Validation loss: 2.6497837933160926

Epoch: 5| Step: 6
Training loss: 2.970799446105957
Validation loss: 2.64902768083798

Epoch: 5| Step: 7
Training loss: 2.7811317443847656
Validation loss: 2.6456256989509828

Epoch: 5| Step: 8
Training loss: 2.1743946075439453
Validation loss: 2.642828984927106

Epoch: 5| Step: 9
Training loss: 3.151674747467041
Validation loss: 2.646253034632693

Epoch: 5| Step: 10
Training loss: 2.5390169620513916
Validation loss: 2.6432693030244563

Epoch: 82| Step: 0
Training loss: 2.869072198867798
Validation loss: 2.6366385336845153

Epoch: 5| Step: 1
Training loss: 3.0343947410583496
Validation loss: 2.627149333236038

Epoch: 5| Step: 2
Training loss: 3.310940980911255
Validation loss: 2.6248343042148057

Epoch: 5| Step: 3
Training loss: 2.7829625606536865
Validation loss: 2.628712679750176

Epoch: 5| Step: 4
Training loss: 2.176298141479492
Validation loss: 2.628123960187358

Epoch: 5| Step: 5
Training loss: 2.5279626846313477
Validation loss: 2.625410618320588

Epoch: 5| Step: 6
Training loss: 3.260913848876953
Validation loss: 2.624713087594637

Epoch: 5| Step: 7
Training loss: 2.6878769397735596
Validation loss: 2.6268947432118077

Epoch: 5| Step: 8
Training loss: 2.7291007041931152
Validation loss: 2.6265758109349076

Epoch: 5| Step: 9
Training loss: 2.9886348247528076
Validation loss: 2.6228828686539845

Epoch: 5| Step: 10
Training loss: 2.1213178634643555
Validation loss: 2.623099857761014

Epoch: 83| Step: 0
Training loss: 2.9355921745300293
Validation loss: 2.623293184464978

Epoch: 5| Step: 1
Training loss: 2.159416913986206
Validation loss: 2.6200540937403196

Epoch: 5| Step: 2
Training loss: 3.2840099334716797
Validation loss: 2.622569812241421

Epoch: 5| Step: 3
Training loss: 2.0539438724517822
Validation loss: 2.627954916287494

Epoch: 5| Step: 4
Training loss: 3.0407729148864746
Validation loss: 2.625674186214324

Epoch: 5| Step: 5
Training loss: 2.7666256427764893
Validation loss: 2.6257471115358415

Epoch: 5| Step: 6
Training loss: 3.0340492725372314
Validation loss: 2.6307722266002367

Epoch: 5| Step: 7
Training loss: 2.932070255279541
Validation loss: 2.6410297629653767

Epoch: 5| Step: 8
Training loss: 3.0155563354492188
Validation loss: 2.6431465815472346

Epoch: 5| Step: 9
Training loss: 2.236999034881592
Validation loss: 2.6409665358963834

Epoch: 5| Step: 10
Training loss: 3.1168463230133057
Validation loss: 2.6304915643507436

Epoch: 84| Step: 0
Training loss: 2.27571702003479
Validation loss: 2.6222969844777095

Epoch: 5| Step: 1
Training loss: 2.6817545890808105
Validation loss: 2.6156154114712953

Epoch: 5| Step: 2
Training loss: 2.86202335357666
Validation loss: 2.618093354727632

Epoch: 5| Step: 3
Training loss: 2.3521430492401123
Validation loss: 2.618456861024262

Epoch: 5| Step: 4
Training loss: 3.1203017234802246
Validation loss: 2.6226848504876576

Epoch: 5| Step: 5
Training loss: 2.0958752632141113
Validation loss: 2.6268559553289927

Epoch: 5| Step: 6
Training loss: 2.9438910484313965
Validation loss: 2.622981507291076

Epoch: 5| Step: 7
Training loss: 2.4983644485473633
Validation loss: 2.6180230263740785

Epoch: 5| Step: 8
Training loss: 2.520087480545044
Validation loss: 2.6133685958000923

Epoch: 5| Step: 9
Training loss: 3.3005881309509277
Validation loss: 2.610998028068132

Epoch: 5| Step: 10
Training loss: 4.110246658325195
Validation loss: 2.6161356074835664

Epoch: 85| Step: 0
Training loss: 1.738851547241211
Validation loss: 2.624874737954909

Epoch: 5| Step: 1
Training loss: 3.3971266746520996
Validation loss: 2.6183198472504974

Epoch: 5| Step: 2
Training loss: 2.702266216278076
Validation loss: 2.620014420119665

Epoch: 5| Step: 3
Training loss: 3.0215866565704346
Validation loss: 2.6170537599953274

Epoch: 5| Step: 4
Training loss: 2.5112144947052
Validation loss: 2.609828684919624

Epoch: 5| Step: 5
Training loss: 2.1861939430236816
Validation loss: 2.6112193394732732

Epoch: 5| Step: 6
Training loss: 2.6758649349212646
Validation loss: 2.618637643834596

Epoch: 5| Step: 7
Training loss: 2.9647068977355957
Validation loss: 2.6289816966620823

Epoch: 5| Step: 8
Training loss: 3.5654728412628174
Validation loss: 2.6356113828638548

Epoch: 5| Step: 9
Training loss: 2.8714406490325928
Validation loss: 2.6451236483871297

Epoch: 5| Step: 10
Training loss: 2.9615886211395264
Validation loss: 2.6355606535429597

Epoch: 86| Step: 0
Training loss: 2.1332039833068848
Validation loss: 2.621764216371762

Epoch: 5| Step: 1
Training loss: 2.299513816833496
Validation loss: 2.612402564735823

Epoch: 5| Step: 2
Training loss: 3.1479926109313965
Validation loss: 2.609576709808842

Epoch: 5| Step: 3
Training loss: 3.633349657058716
Validation loss: 2.608110212510632

Epoch: 5| Step: 4
Training loss: 2.329908847808838
Validation loss: 2.6195713704632175

Epoch: 5| Step: 5
Training loss: 2.6868443489074707
Validation loss: 2.6194512280084754

Epoch: 5| Step: 6
Training loss: 2.841322183609009
Validation loss: 2.6218544308857252

Epoch: 5| Step: 7
Training loss: 2.437525987625122
Validation loss: 2.623172229336154

Epoch: 5| Step: 8
Training loss: 2.3877015113830566
Validation loss: 2.6263382332299345

Epoch: 5| Step: 9
Training loss: 3.252588987350464
Validation loss: 2.630855611575547

Epoch: 5| Step: 10
Training loss: 3.448169708251953
Validation loss: 2.641414362897155

Epoch: 87| Step: 0
Training loss: 2.5574069023132324
Validation loss: 2.626907948524721

Epoch: 5| Step: 1
Training loss: 2.4731452465057373
Validation loss: 2.6081651872204197

Epoch: 5| Step: 2
Training loss: 2.659646987915039
Validation loss: 2.6055767433617705

Epoch: 5| Step: 3
Training loss: 2.5240631103515625
Validation loss: 2.604888362269248

Epoch: 5| Step: 4
Training loss: 2.766490936279297
Validation loss: 2.604874928792318

Epoch: 5| Step: 5
Training loss: 3.5783705711364746
Validation loss: 2.6077401432939755

Epoch: 5| Step: 6
Training loss: 2.2390201091766357
Validation loss: 2.609169134529688

Epoch: 5| Step: 7
Training loss: 3.3038859367370605
Validation loss: 2.608884572982788

Epoch: 5| Step: 8
Training loss: 3.0832390785217285
Validation loss: 2.605340903805148

Epoch: 5| Step: 9
Training loss: 2.849597692489624
Validation loss: 2.6067633833936465

Epoch: 5| Step: 10
Training loss: 2.4740817546844482
Validation loss: 2.603665292903941

Epoch: 88| Step: 0
Training loss: 2.272124767303467
Validation loss: 2.6053940660210064

Epoch: 5| Step: 1
Training loss: 2.9798734188079834
Validation loss: 2.605437529984341

Epoch: 5| Step: 2
Training loss: 2.4763851165771484
Validation loss: 2.6032891863135883

Epoch: 5| Step: 3
Training loss: 2.4494824409484863
Validation loss: 2.6042707684219524

Epoch: 5| Step: 4
Training loss: 3.480829954147339
Validation loss: 2.600806946395546

Epoch: 5| Step: 5
Training loss: 2.3753902912139893
Validation loss: 2.5990379664205734

Epoch: 5| Step: 6
Training loss: 2.768920660018921
Validation loss: 2.599381544256723

Epoch: 5| Step: 7
Training loss: 3.1039412021636963
Validation loss: 2.599339269822644

Epoch: 5| Step: 8
Training loss: 3.0668134689331055
Validation loss: 2.602378273522982

Epoch: 5| Step: 9
Training loss: 2.0400643348693848
Validation loss: 2.6015201153293734

Epoch: 5| Step: 10
Training loss: 3.546504497528076
Validation loss: 2.5969176523147093

Epoch: 89| Step: 0
Training loss: 3.178067445755005
Validation loss: 2.611297468985281

Epoch: 5| Step: 1
Training loss: 2.272500991821289
Validation loss: 2.6232266220995175

Epoch: 5| Step: 2
Training loss: 3.2495980262756348
Validation loss: 2.6293019607502925

Epoch: 5| Step: 3
Training loss: 3.0246872901916504
Validation loss: 2.630763453821982

Epoch: 5| Step: 4
Training loss: 2.4129233360290527
Validation loss: 2.6304488310249905

Epoch: 5| Step: 5
Training loss: 2.5556387901306152
Validation loss: 2.6218760116125948

Epoch: 5| Step: 6
Training loss: 2.4114255905151367
Validation loss: 2.6218450735974055

Epoch: 5| Step: 7
Training loss: 2.4837779998779297
Validation loss: 2.626691238854521

Epoch: 5| Step: 8
Training loss: 3.379694700241089
Validation loss: 2.6222067071545507

Epoch: 5| Step: 9
Training loss: 2.75897479057312
Validation loss: 2.6056408369412987

Epoch: 5| Step: 10
Training loss: 2.7321369647979736
Validation loss: 2.5930587450663247

Epoch: 90| Step: 0
Training loss: 3.6125664710998535
Validation loss: 2.588569205294373

Epoch: 5| Step: 1
Training loss: 2.8414275646209717
Validation loss: 2.5945126959072646

Epoch: 5| Step: 2
Training loss: 3.0039420127868652
Validation loss: 2.596194498000606

Epoch: 5| Step: 3
Training loss: 2.312283754348755
Validation loss: 2.611139699976931

Epoch: 5| Step: 4
Training loss: 3.0026612281799316
Validation loss: 2.650559945773053

Epoch: 5| Step: 5
Training loss: 2.8642280101776123
Validation loss: 2.679301082447011

Epoch: 5| Step: 6
Training loss: 2.1783251762390137
Validation loss: 2.6828740822371615

Epoch: 5| Step: 7
Training loss: 2.183196783065796
Validation loss: 2.69461396432692

Epoch: 5| Step: 8
Training loss: 2.780673027038574
Validation loss: 2.687799184553085

Epoch: 5| Step: 9
Training loss: 3.0735678672790527
Validation loss: 2.668461230493361

Epoch: 5| Step: 10
Training loss: 2.9977710247039795
Validation loss: 2.6473476245839107

Epoch: 91| Step: 0
Training loss: 2.7860374450683594
Validation loss: 2.6474979077616045

Epoch: 5| Step: 1
Training loss: 3.1184287071228027
Validation loss: 2.6644734259574645

Epoch: 5| Step: 2
Training loss: 2.8510003089904785
Validation loss: 2.6831188201904297

Epoch: 5| Step: 3
Training loss: 3.202224016189575
Validation loss: 2.6857665020932435

Epoch: 5| Step: 4
Training loss: 2.7785675525665283
Validation loss: 2.6614336788013415

Epoch: 5| Step: 5
Training loss: 2.6894307136535645
Validation loss: 2.6464188842363257

Epoch: 5| Step: 6
Training loss: 3.3438315391540527
Validation loss: 2.6210689711314377

Epoch: 5| Step: 7
Training loss: 2.314279317855835
Validation loss: 2.611815775594404

Epoch: 5| Step: 8
Training loss: 2.3667359352111816
Validation loss: 2.596894206539277

Epoch: 5| Step: 9
Training loss: 2.5964198112487793
Validation loss: 2.5961306505305792

Epoch: 5| Step: 10
Training loss: 2.45721435546875
Validation loss: 2.587704525198988

Epoch: 92| Step: 0
Training loss: 2.440640926361084
Validation loss: 2.587274597537133

Epoch: 5| Step: 1
Training loss: 2.7867884635925293
Validation loss: 2.592931721800117

Epoch: 5| Step: 2
Training loss: 2.9085679054260254
Validation loss: 2.5895929669821136

Epoch: 5| Step: 3
Training loss: 3.10660457611084
Validation loss: 2.5882798728122505

Epoch: 5| Step: 4
Training loss: 2.7450103759765625
Validation loss: 2.584856107670774

Epoch: 5| Step: 5
Training loss: 2.3486242294311523
Validation loss: 2.582824922377063

Epoch: 5| Step: 6
Training loss: 3.115355968475342
Validation loss: 2.578364528635497

Epoch: 5| Step: 7
Training loss: 2.7486941814422607
Validation loss: 2.5787181649156796

Epoch: 5| Step: 8
Training loss: 2.984793186187744
Validation loss: 2.5769139592365553

Epoch: 5| Step: 9
Training loss: 2.3239521980285645
Validation loss: 2.5814036502633044

Epoch: 5| Step: 10
Training loss: 2.7712652683258057
Validation loss: 2.5817627137707126

Epoch: 93| Step: 0
Training loss: 3.063260555267334
Validation loss: 2.5909409753737913

Epoch: 5| Step: 1
Training loss: 2.5384955406188965
Validation loss: 2.6190500310672227

Epoch: 5| Step: 2
Training loss: 3.0463249683380127
Validation loss: 2.6839181812860633

Epoch: 5| Step: 3
Training loss: 3.0112366676330566
Validation loss: 2.7430604170727473

Epoch: 5| Step: 4
Training loss: 3.032672882080078
Validation loss: 2.655115407000306

Epoch: 5| Step: 5
Training loss: 2.802734613418579
Validation loss: 2.6059372348170124

Epoch: 5| Step: 6
Training loss: 2.520564556121826
Validation loss: 2.5820506259959233

Epoch: 5| Step: 7
Training loss: 2.7614846229553223
Validation loss: 2.581002232848957

Epoch: 5| Step: 8
Training loss: 2.7603797912597656
Validation loss: 2.588532955415787

Epoch: 5| Step: 9
Training loss: 2.9857993125915527
Validation loss: 2.6003160220320507

Epoch: 5| Step: 10
Training loss: 1.9792983531951904
Validation loss: 2.622791897866034

Epoch: 94| Step: 0
Training loss: 2.669872283935547
Validation loss: 2.6533355994891097

Epoch: 5| Step: 1
Training loss: 2.381432056427002
Validation loss: 2.631314662195021

Epoch: 5| Step: 2
Training loss: 2.900155544281006
Validation loss: 2.606666326522827

Epoch: 5| Step: 3
Training loss: 3.3567261695861816
Validation loss: 2.6023171588938725

Epoch: 5| Step: 4
Training loss: 3.0026588439941406
Validation loss: 2.6107590762517785

Epoch: 5| Step: 5
Training loss: 2.4709057807922363
Validation loss: 2.5977137729685795

Epoch: 5| Step: 6
Training loss: 2.0336756706237793
Validation loss: 2.5884984257400676

Epoch: 5| Step: 7
Training loss: 2.4506752490997314
Validation loss: 2.6002570890611216

Epoch: 5| Step: 8
Training loss: 4.0291361808776855
Validation loss: 2.6002386923759215

Epoch: 5| Step: 9
Training loss: 2.5347495079040527
Validation loss: 2.6366823206665697

Epoch: 5| Step: 10
Training loss: 2.7182602882385254
Validation loss: 2.6168166693820747

Epoch: 95| Step: 0
Training loss: 3.1100497245788574
Validation loss: 2.6131981803524877

Epoch: 5| Step: 1
Training loss: 2.8410916328430176
Validation loss: 2.605341278096681

Epoch: 5| Step: 2
Training loss: 1.8187916278839111
Validation loss: 2.5998290584933375

Epoch: 5| Step: 3
Training loss: 2.9787991046905518
Validation loss: 2.5988130082366285

Epoch: 5| Step: 4
Training loss: 3.1928176879882812
Validation loss: 2.593026868758663

Epoch: 5| Step: 5
Training loss: 3.116137981414795
Validation loss: 2.587578381261518

Epoch: 5| Step: 6
Training loss: 2.4330368041992188
Validation loss: 2.580440395621843

Epoch: 5| Step: 7
Training loss: 3.0695924758911133
Validation loss: 2.575708222645585

Epoch: 5| Step: 8
Training loss: 2.5423285961151123
Validation loss: 2.5750634336984284

Epoch: 5| Step: 9
Training loss: 2.8353967666625977
Validation loss: 2.570082886244661

Epoch: 5| Step: 10
Training loss: 2.1820967197418213
Validation loss: 2.5691737051933043

Epoch: 96| Step: 0
Training loss: 2.7259368896484375
Validation loss: 2.57037018704158

Epoch: 5| Step: 1
Training loss: 2.4546732902526855
Validation loss: 2.571486783284013

Epoch: 5| Step: 2
Training loss: 2.61403226852417
Validation loss: 2.578019493369646

Epoch: 5| Step: 3
Training loss: 3.0354108810424805
Validation loss: 2.5816143789599018

Epoch: 5| Step: 4
Training loss: 2.1888699531555176
Validation loss: 2.581970130243609

Epoch: 5| Step: 5
Training loss: 2.6427266597747803
Validation loss: 2.5829727162597

Epoch: 5| Step: 6
Training loss: 2.7592740058898926
Validation loss: 2.5803003746976136

Epoch: 5| Step: 7
Training loss: 2.7237515449523926
Validation loss: 2.5753815174102783

Epoch: 5| Step: 8
Training loss: 3.371079206466675
Validation loss: 2.571412791487991

Epoch: 5| Step: 9
Training loss: 2.4975788593292236
Validation loss: 2.5773581612494683

Epoch: 5| Step: 10
Training loss: 3.206157684326172
Validation loss: 2.5688907587400047

Epoch: 97| Step: 0
Training loss: 3.3727283477783203
Validation loss: 2.566133542727399

Epoch: 5| Step: 1
Training loss: 2.5203113555908203
Validation loss: 2.563392604551008

Epoch: 5| Step: 2
Training loss: 2.766719341278076
Validation loss: 2.566933439623925

Epoch: 5| Step: 3
Training loss: 2.906217336654663
Validation loss: 2.5637984788545998

Epoch: 5| Step: 4
Training loss: 2.4796502590179443
Validation loss: 2.5669015940799507

Epoch: 5| Step: 5
Training loss: 2.571990489959717
Validation loss: 2.566349193614016

Epoch: 5| Step: 6
Training loss: 2.1956934928894043
Validation loss: 2.566639695116269

Epoch: 5| Step: 7
Training loss: 3.367199420928955
Validation loss: 2.564361415883546

Epoch: 5| Step: 8
Training loss: 2.53840970993042
Validation loss: 2.5630794173927716

Epoch: 5| Step: 9
Training loss: 2.5562891960144043
Validation loss: 2.5644949020877963

Epoch: 5| Step: 10
Training loss: 2.9244754314422607
Validation loss: 2.560183350757886

Epoch: 98| Step: 0
Training loss: 2.989915132522583
Validation loss: 2.5589284127758396

Epoch: 5| Step: 1
Training loss: 2.2508416175842285
Validation loss: 2.561889748419485

Epoch: 5| Step: 2
Training loss: 2.979210138320923
Validation loss: 2.5612431341601956

Epoch: 5| Step: 3
Training loss: 2.56402850151062
Validation loss: 2.56576140849821

Epoch: 5| Step: 4
Training loss: 2.731419086456299
Validation loss: 2.568050984413393

Epoch: 5| Step: 5
Training loss: 2.8059096336364746
Validation loss: 2.565699665777145

Epoch: 5| Step: 6
Training loss: 2.9853312969207764
Validation loss: 2.5649294032845447

Epoch: 5| Step: 7
Training loss: 2.454793930053711
Validation loss: 2.5652755486067904

Epoch: 5| Step: 8
Training loss: 2.7102437019348145
Validation loss: 2.5590781165707495

Epoch: 5| Step: 9
Training loss: 2.779404878616333
Validation loss: 2.5594604681896906

Epoch: 5| Step: 10
Training loss: 2.8218960762023926
Validation loss: 2.5593936622783704

Epoch: 99| Step: 0
Training loss: 2.4924492835998535
Validation loss: 2.570860993477606

Epoch: 5| Step: 1
Training loss: 2.5541634559631348
Validation loss: 2.5765917839542514

Epoch: 5| Step: 2
Training loss: 1.900556206703186
Validation loss: 2.5783920006085466

Epoch: 5| Step: 3
Training loss: 3.9103996753692627
Validation loss: 2.5867898746203353

Epoch: 5| Step: 4
Training loss: 3.193493366241455
Validation loss: 2.586261864631407

Epoch: 5| Step: 5
Training loss: 2.9498507976531982
Validation loss: 2.579736889049571

Epoch: 5| Step: 6
Training loss: 2.9030144214630127
Validation loss: 2.5808665675501667

Epoch: 5| Step: 7
Training loss: 2.30492901802063
Validation loss: 2.577357812594342

Epoch: 5| Step: 8
Training loss: 2.6945748329162598
Validation loss: 2.5715121761445077

Epoch: 5| Step: 9
Training loss: 2.764338254928589
Validation loss: 2.563321805769397

Epoch: 5| Step: 10
Training loss: 2.567854642868042
Validation loss: 2.5609729366917766

Epoch: 100| Step: 0
Training loss: 2.5207228660583496
Validation loss: 2.554472538732713

Epoch: 5| Step: 1
Training loss: 2.391953706741333
Validation loss: 2.549277913185858

Epoch: 5| Step: 2
Training loss: 2.7936851978302
Validation loss: 2.5644551605306645

Epoch: 5| Step: 3
Training loss: 3.102189540863037
Validation loss: 2.572178453527471

Epoch: 5| Step: 4
Training loss: 3.4529640674591064
Validation loss: 2.5916790423854703

Epoch: 5| Step: 5
Training loss: 3.2782034873962402
Validation loss: 2.57844026114351

Epoch: 5| Step: 6
Training loss: 2.287719488143921
Validation loss: 2.5633595323049896

Epoch: 5| Step: 7
Training loss: 2.3154094219207764
Validation loss: 2.5552218601267827

Epoch: 5| Step: 8
Training loss: 2.295419454574585
Validation loss: 2.548827750708467

Epoch: 5| Step: 9
Training loss: 2.689138412475586
Validation loss: 2.549483165946058

Epoch: 5| Step: 10
Training loss: 2.9416861534118652
Validation loss: 2.5501374993273007

Epoch: 101| Step: 0
Training loss: 2.5494165420532227
Validation loss: 2.551854315624442

Epoch: 5| Step: 1
Training loss: 2.778850555419922
Validation loss: 2.5533271066604124

Epoch: 5| Step: 2
Training loss: 2.51627779006958
Validation loss: 2.564271560279272

Epoch: 5| Step: 3
Training loss: 2.5063998699188232
Validation loss: 2.5700645010958434

Epoch: 5| Step: 4
Training loss: 2.7404916286468506
Validation loss: 2.5852285328731743

Epoch: 5| Step: 5
Training loss: 3.0521371364593506
Validation loss: 2.603553730954406

Epoch: 5| Step: 6
Training loss: 3.068319797515869
Validation loss: 2.6166263088103263

Epoch: 5| Step: 7
Training loss: 3.2194762229919434
Validation loss: 2.58586557193469

Epoch: 5| Step: 8
Training loss: 2.4245567321777344
Validation loss: 2.5554635550386164

Epoch: 5| Step: 9
Training loss: 2.8441519737243652
Validation loss: 2.546593286657846

Epoch: 5| Step: 10
Training loss: 2.493452548980713
Validation loss: 2.5518689360669864

Epoch: 102| Step: 0
Training loss: 2.9968619346618652
Validation loss: 2.551309367661835

Epoch: 5| Step: 1
Training loss: 2.9318630695343018
Validation loss: 2.557073490594023

Epoch: 5| Step: 2
Training loss: 2.5822794437408447
Validation loss: 2.5732172432766167

Epoch: 5| Step: 3
Training loss: 2.2734920978546143
Validation loss: 2.5912983853329896

Epoch: 5| Step: 4
Training loss: 2.877525806427002
Validation loss: 2.595774427536995

Epoch: 5| Step: 5
Training loss: 2.772181272506714
Validation loss: 2.585917483093918

Epoch: 5| Step: 6
Training loss: 2.8983347415924072
Validation loss: 2.5805952548980713

Epoch: 5| Step: 7
Training loss: 2.559211254119873
Validation loss: 2.571237382068429

Epoch: 5| Step: 8
Training loss: 2.9776699542999268
Validation loss: 2.565335278869957

Epoch: 5| Step: 9
Training loss: 2.8997292518615723
Validation loss: 2.546769134459957

Epoch: 5| Step: 10
Training loss: 2.2685718536376953
Validation loss: 2.5447730761702343

Epoch: 103| Step: 0
Training loss: 2.7363903522491455
Validation loss: 2.542060831541656

Epoch: 5| Step: 1
Training loss: 3.040442943572998
Validation loss: 2.5397337072639057

Epoch: 5| Step: 2
Training loss: 3.01139760017395
Validation loss: 2.541704526511572

Epoch: 5| Step: 3
Training loss: 3.251582384109497
Validation loss: 2.54345541872004

Epoch: 5| Step: 4
Training loss: 1.8968498706817627
Validation loss: 2.5491079156116774

Epoch: 5| Step: 5
Training loss: 2.139049530029297
Validation loss: 2.55078399309548

Epoch: 5| Step: 6
Training loss: 2.3898720741271973
Validation loss: 2.5506374348876295

Epoch: 5| Step: 7
Training loss: 3.4829306602478027
Validation loss: 2.5514565078161096

Epoch: 5| Step: 8
Training loss: 2.9632785320281982
Validation loss: 2.543380468122421

Epoch: 5| Step: 9
Training loss: 2.18633770942688
Validation loss: 2.5431293261948453

Epoch: 5| Step: 10
Training loss: 3.048949718475342
Validation loss: 2.5399803730749313

Epoch: 104| Step: 0
Training loss: 2.6638174057006836
Validation loss: 2.5393413471919235

Epoch: 5| Step: 1
Training loss: 2.7003297805786133
Validation loss: 2.5389989370940835

Epoch: 5| Step: 2
Training loss: 2.6824393272399902
Validation loss: 2.5444713382310766

Epoch: 5| Step: 3
Training loss: 2.7921223640441895
Validation loss: 2.54562089520116

Epoch: 5| Step: 4
Training loss: 3.1908485889434814
Validation loss: 2.548029271505212

Epoch: 5| Step: 5
Training loss: 2.4360249042510986
Validation loss: 2.556346147291122

Epoch: 5| Step: 6
Training loss: 2.646251678466797
Validation loss: 2.54815068808935

Epoch: 5| Step: 7
Training loss: 2.7982017993927
Validation loss: 2.5420549915682886

Epoch: 5| Step: 8
Training loss: 2.493204355239868
Validation loss: 2.5379601011994066

Epoch: 5| Step: 9
Training loss: 2.9399373531341553
Validation loss: 2.541209490068497

Epoch: 5| Step: 10
Training loss: 2.5560197830200195
Validation loss: 2.5365797114628617

Epoch: 105| Step: 0
Training loss: 2.1129283905029297
Validation loss: 2.536780462470106

Epoch: 5| Step: 1
Training loss: 2.2984066009521484
Validation loss: 2.534190798318514

Epoch: 5| Step: 2
Training loss: 3.221588134765625
Validation loss: 2.532026790803479

Epoch: 5| Step: 3
Training loss: 2.402827501296997
Validation loss: 2.529393075614847

Epoch: 5| Step: 4
Training loss: 3.407109022140503
Validation loss: 2.5295639986632974

Epoch: 5| Step: 5
Training loss: 3.3703675270080566
Validation loss: 2.5351291395002797

Epoch: 5| Step: 6
Training loss: 2.761820077896118
Validation loss: 2.5294333324637464

Epoch: 5| Step: 7
Training loss: 3.0610084533691406
Validation loss: 2.529171792409753

Epoch: 5| Step: 8
Training loss: 2.4065401554107666
Validation loss: 2.535720463721983

Epoch: 5| Step: 9
Training loss: 2.573751926422119
Validation loss: 2.535687582467192

Epoch: 5| Step: 10
Training loss: 2.1831936836242676
Validation loss: 2.540300723045103

Epoch: 106| Step: 0
Training loss: 2.5488083362579346
Validation loss: 2.5340850353240967

Epoch: 5| Step: 1
Training loss: 2.620241165161133
Validation loss: 2.534220382731448

Epoch: 5| Step: 2
Training loss: 2.8069052696228027
Validation loss: 2.531246833903815

Epoch: 5| Step: 3
Training loss: 3.195148229598999
Validation loss: 2.5303554201638825

Epoch: 5| Step: 4
Training loss: 2.8115477561950684
Validation loss: 2.529184420903524

Epoch: 5| Step: 5
Training loss: 2.284857749938965
Validation loss: 2.5319628946242796

Epoch: 5| Step: 6
Training loss: 2.503575563430786
Validation loss: 2.528772912999635

Epoch: 5| Step: 7
Training loss: 3.1835849285125732
Validation loss: 2.5298980000198528

Epoch: 5| Step: 8
Training loss: 2.6113102436065674
Validation loss: 2.531843718662057

Epoch: 5| Step: 9
Training loss: 2.7265098094940186
Validation loss: 2.529536803563436

Epoch: 5| Step: 10
Training loss: 2.5045387744903564
Validation loss: 2.5255928449733283

Epoch: 107| Step: 0
Training loss: 2.6668362617492676
Validation loss: 2.5303004967269076

Epoch: 5| Step: 1
Training loss: 3.0848562717437744
Validation loss: 2.5270345903212026

Epoch: 5| Step: 2
Training loss: 2.9066970348358154
Validation loss: 2.525328787424231

Epoch: 5| Step: 3
Training loss: 2.232290267944336
Validation loss: 2.5268771110042447

Epoch: 5| Step: 4
Training loss: 3.1713035106658936
Validation loss: 2.5305971919849353

Epoch: 5| Step: 5
Training loss: 2.8925392627716064
Validation loss: 2.5248488046789683

Epoch: 5| Step: 6
Training loss: 2.943361759185791
Validation loss: 2.531334618086456

Epoch: 5| Step: 7
Training loss: 2.88023042678833
Validation loss: 2.5282622844942155

Epoch: 5| Step: 8
Training loss: 2.1426610946655273
Validation loss: 2.530297927958991

Epoch: 5| Step: 9
Training loss: 2.384580135345459
Validation loss: 2.531782880906136

Epoch: 5| Step: 10
Training loss: 2.459944725036621
Validation loss: 2.5309881728182555

Epoch: 108| Step: 0
Training loss: 2.3535993099212646
Validation loss: 2.5283394526409846

Epoch: 5| Step: 1
Training loss: 2.6282410621643066
Validation loss: 2.524416128794352

Epoch: 5| Step: 2
Training loss: 2.603484630584717
Validation loss: 2.5232812563578286

Epoch: 5| Step: 3
Training loss: 3.051626682281494
Validation loss: 2.5248934479169947

Epoch: 5| Step: 4
Training loss: 2.734083652496338
Validation loss: 2.5228249872884443

Epoch: 5| Step: 5
Training loss: 2.371220111846924
Validation loss: 2.5254883484173845

Epoch: 5| Step: 6
Training loss: 2.9709067344665527
Validation loss: 2.530358729823943

Epoch: 5| Step: 7
Training loss: 2.582857608795166
Validation loss: 2.5300070829288934

Epoch: 5| Step: 8
Training loss: 2.7575020790100098
Validation loss: 2.526600012215235

Epoch: 5| Step: 9
Training loss: 3.2088654041290283
Validation loss: 2.530170158673358

Epoch: 5| Step: 10
Training loss: 2.4912631511688232
Validation loss: 2.533593826396491

Epoch: 109| Step: 0
Training loss: 2.7633087635040283
Validation loss: 2.5333255772949546

Epoch: 5| Step: 1
Training loss: 2.7434768676757812
Validation loss: 2.537383792220905

Epoch: 5| Step: 2
Training loss: 2.8252882957458496
Validation loss: 2.543593983496389

Epoch: 5| Step: 3
Training loss: 2.8932273387908936
Validation loss: 2.5438664651686147

Epoch: 5| Step: 4
Training loss: 2.190829038619995
Validation loss: 2.541645601231565

Epoch: 5| Step: 5
Training loss: 2.916424512863159
Validation loss: 2.544808336483535

Epoch: 5| Step: 6
Training loss: 2.1992337703704834
Validation loss: 2.5332157637483332

Epoch: 5| Step: 7
Training loss: 2.8028016090393066
Validation loss: 2.5463186335820023

Epoch: 5| Step: 8
Training loss: 2.958707332611084
Validation loss: 2.5328812496636504

Epoch: 5| Step: 9
Training loss: 2.779719591140747
Validation loss: 2.5309628055941675

Epoch: 5| Step: 10
Training loss: 2.7312216758728027
Validation loss: 2.5386182800416024

Epoch: 110| Step: 0
Training loss: 2.5020878314971924
Validation loss: 2.5332414539911414

Epoch: 5| Step: 1
Training loss: 3.047828197479248
Validation loss: 2.5377247154071765

Epoch: 5| Step: 2
Training loss: 2.242490291595459
Validation loss: 2.544328879284602

Epoch: 5| Step: 3
Training loss: 3.029902696609497
Validation loss: 2.5485623600662395

Epoch: 5| Step: 4
Training loss: 3.6129627227783203
Validation loss: 2.545563631160285

Epoch: 5| Step: 5
Training loss: 2.491957902908325
Validation loss: 2.5450905164082847

Epoch: 5| Step: 6
Training loss: 2.3218274116516113
Validation loss: 2.537197897511144

Epoch: 5| Step: 7
Training loss: 2.9593138694763184
Validation loss: 2.527823894254623

Epoch: 5| Step: 8
Training loss: 2.4800312519073486
Validation loss: 2.524433174440938

Epoch: 5| Step: 9
Training loss: 3.0010159015655518
Validation loss: 2.5236368281866914

Epoch: 5| Step: 10
Training loss: 1.8532354831695557
Validation loss: 2.519752105077108

Epoch: 111| Step: 0
Training loss: 2.41056489944458
Validation loss: 2.5235284374606226

Epoch: 5| Step: 1
Training loss: 2.868058919906616
Validation loss: 2.5286641172183457

Epoch: 5| Step: 2
Training loss: 3.1668741703033447
Validation loss: 2.5238377637760614

Epoch: 5| Step: 3
Training loss: 2.172563314437866
Validation loss: 2.5282976601713445

Epoch: 5| Step: 4
Training loss: 3.1876819133758545
Validation loss: 2.5299324297135874

Epoch: 5| Step: 5
Training loss: 2.679150104522705
Validation loss: 2.5340178551212436

Epoch: 5| Step: 6
Training loss: 2.809422016143799
Validation loss: 2.5264895782675794

Epoch: 5| Step: 7
Training loss: 2.96659517288208
Validation loss: 2.5140338815668577

Epoch: 5| Step: 8
Training loss: 2.733015537261963
Validation loss: 2.5112154124885477

Epoch: 5| Step: 9
Training loss: 2.4023096561431885
Validation loss: 2.5164173444112143

Epoch: 5| Step: 10
Training loss: 2.35345721244812
Validation loss: 2.533946160347231

Epoch: 112| Step: 0
Training loss: 2.429370164871216
Validation loss: 2.5606226126352944

Epoch: 5| Step: 1
Training loss: 2.720432758331299
Validation loss: 2.5712458267006824

Epoch: 5| Step: 2
Training loss: 3.342146635055542
Validation loss: 2.571696630088232

Epoch: 5| Step: 3
Training loss: 2.246094226837158
Validation loss: 2.5698042966986216

Epoch: 5| Step: 4
Training loss: 1.6127116680145264
Validation loss: 2.54650907234479

Epoch: 5| Step: 5
Training loss: 2.926393747329712
Validation loss: 2.528255513919297

Epoch: 5| Step: 6
Training loss: 2.6789753437042236
Validation loss: 2.5209371735972743

Epoch: 5| Step: 7
Training loss: 3.282153606414795
Validation loss: 2.5155152351625505

Epoch: 5| Step: 8
Training loss: 3.1835343837738037
Validation loss: 2.515854944464981

Epoch: 5| Step: 9
Training loss: 3.094954252243042
Validation loss: 2.518271976901639

Epoch: 5| Step: 10
Training loss: 2.1975908279418945
Validation loss: 2.514839918382706

Epoch: 113| Step: 0
Training loss: 2.813978672027588
Validation loss: 2.5178322407507125

Epoch: 5| Step: 1
Training loss: 2.3846681118011475
Validation loss: 2.5175596590965026

Epoch: 5| Step: 2
Training loss: 2.6101386547088623
Validation loss: 2.517951052675965

Epoch: 5| Step: 3
Training loss: 2.83772611618042
Validation loss: 2.5158799258611535

Epoch: 5| Step: 4
Training loss: 2.3766512870788574
Validation loss: 2.517988363901774

Epoch: 5| Step: 5
Training loss: 2.9086456298828125
Validation loss: 2.517310814190936

Epoch: 5| Step: 6
Training loss: 2.413743019104004
Validation loss: 2.515789977965816

Epoch: 5| Step: 7
Training loss: 3.011401414871216
Validation loss: 2.51574856235135

Epoch: 5| Step: 8
Training loss: 3.202505588531494
Validation loss: 2.5202270887231313

Epoch: 5| Step: 9
Training loss: 2.5494163036346436
Validation loss: 2.5273025394767843

Epoch: 5| Step: 10
Training loss: 2.716618061065674
Validation loss: 2.518103794385028

Epoch: 114| Step: 0
Training loss: 2.3193318843841553
Validation loss: 2.520918551311698

Epoch: 5| Step: 1
Training loss: 2.1068310737609863
Validation loss: 2.52415221224549

Epoch: 5| Step: 2
Training loss: 2.5593655109405518
Validation loss: 2.522464898324782

Epoch: 5| Step: 3
Training loss: 3.357175350189209
Validation loss: 2.523662572265953

Epoch: 5| Step: 4
Training loss: 2.2986104488372803
Validation loss: 2.525086202929097

Epoch: 5| Step: 5
Training loss: 2.7533440589904785
Validation loss: 2.523064515923941

Epoch: 5| Step: 6
Training loss: 3.8525173664093018
Validation loss: 2.5345633260665403

Epoch: 5| Step: 7
Training loss: 2.9255459308624268
Validation loss: 2.534999955085016

Epoch: 5| Step: 8
Training loss: 2.723006010055542
Validation loss: 2.535544749229185

Epoch: 5| Step: 9
Training loss: 2.54472017288208
Validation loss: 2.534690667224187

Epoch: 5| Step: 10
Training loss: 2.2446529865264893
Validation loss: 2.5151452813097226

Epoch: 115| Step: 0
Training loss: 2.047107219696045
Validation loss: 2.50922816799533

Epoch: 5| Step: 1
Training loss: 2.159550666809082
Validation loss: 2.520791389608896

Epoch: 5| Step: 2
Training loss: 2.1964728832244873
Validation loss: 2.5169307672849266

Epoch: 5| Step: 3
Training loss: 2.700711727142334
Validation loss: 2.515318751335144

Epoch: 5| Step: 4
Training loss: 3.6639556884765625
Validation loss: 2.505935758672735

Epoch: 5| Step: 5
Training loss: 2.610748767852783
Validation loss: 2.5010593014378704

Epoch: 5| Step: 6
Training loss: 2.966564655303955
Validation loss: 2.502673469563966

Epoch: 5| Step: 7
Training loss: 1.8560909032821655
Validation loss: 2.5021066229830504

Epoch: 5| Step: 8
Training loss: 2.6703319549560547
Validation loss: 2.502442507333653

Epoch: 5| Step: 9
Training loss: 3.557201385498047
Validation loss: 2.503602934140031

Epoch: 5| Step: 10
Training loss: 3.3262064456939697
Validation loss: 2.5070917734535794

Epoch: 116| Step: 0
Training loss: 2.8203723430633545
Validation loss: 2.505656639734904

Epoch: 5| Step: 1
Training loss: 2.7707901000976562
Validation loss: 2.5125590498729418

Epoch: 5| Step: 2
Training loss: 2.677703857421875
Validation loss: 2.5087219899700535

Epoch: 5| Step: 3
Training loss: 3.0689878463745117
Validation loss: 2.4987405474467943

Epoch: 5| Step: 4
Training loss: 2.217062473297119
Validation loss: 2.5019765797481743

Epoch: 5| Step: 5
Training loss: 2.504676103591919
Validation loss: 2.4952263627001035

Epoch: 5| Step: 6
Training loss: 2.446200132369995
Validation loss: 2.4940315882364907

Epoch: 5| Step: 7
Training loss: 2.7934863567352295
Validation loss: 2.4938953691913235

Epoch: 5| Step: 8
Training loss: 2.585320472717285
Validation loss: 2.491912921269735

Epoch: 5| Step: 9
Training loss: 2.5525259971618652
Validation loss: 2.4952171566665813

Epoch: 5| Step: 10
Training loss: 3.314152240753174
Validation loss: 2.495665934778029

Epoch: 117| Step: 0
Training loss: 2.8112547397613525
Validation loss: 2.499052911676386

Epoch: 5| Step: 1
Training loss: 2.015630006790161
Validation loss: 2.4962198298464537

Epoch: 5| Step: 2
Training loss: 3.1639838218688965
Validation loss: 2.4923094677668747

Epoch: 5| Step: 3
Training loss: 3.129040479660034
Validation loss: 2.4906370665437434

Epoch: 5| Step: 4
Training loss: 2.2978322505950928
Validation loss: 2.4914372864589898

Epoch: 5| Step: 5
Training loss: 2.727780818939209
Validation loss: 2.489263665291571

Epoch: 5| Step: 6
Training loss: 2.694213390350342
Validation loss: 2.498442098658572

Epoch: 5| Step: 7
Training loss: 2.9364936351776123
Validation loss: 2.5122756573461715

Epoch: 5| Step: 8
Training loss: 2.5671515464782715
Validation loss: 2.5259039966008996

Epoch: 5| Step: 9
Training loss: 3.1071343421936035
Validation loss: 2.5542259511127265

Epoch: 5| Step: 10
Training loss: 2.1382367610931396
Validation loss: 2.5708112742311213

Epoch: 118| Step: 0
Training loss: 1.4310775995254517
Validation loss: 2.578381053863033

Epoch: 5| Step: 1
Training loss: 2.502110004425049
Validation loss: 2.5493485427671865

Epoch: 5| Step: 2
Training loss: 2.9928767681121826
Validation loss: 2.538203130486191

Epoch: 5| Step: 3
Training loss: 2.7951714992523193
Validation loss: 2.513320016604598

Epoch: 5| Step: 4
Training loss: 2.1705563068389893
Validation loss: 2.499985561575941

Epoch: 5| Step: 5
Training loss: 2.828040361404419
Validation loss: 2.4908511869369017

Epoch: 5| Step: 6
Training loss: 2.8314406871795654
Validation loss: 2.503005709699405

Epoch: 5| Step: 7
Training loss: 3.2832188606262207
Validation loss: 2.511791918867378

Epoch: 5| Step: 8
Training loss: 3.2028136253356934
Validation loss: 2.5156430531573553

Epoch: 5| Step: 9
Training loss: 3.279672622680664
Validation loss: 2.5165311187826176

Epoch: 5| Step: 10
Training loss: 2.4175102710723877
Validation loss: 2.519593966904507

Epoch: 119| Step: 0
Training loss: 2.7404422760009766
Validation loss: 2.5192106462294057

Epoch: 5| Step: 1
Training loss: 2.347075939178467
Validation loss: 2.5022310492812947

Epoch: 5| Step: 2
Training loss: 2.9265739917755127
Validation loss: 2.4931286329864175

Epoch: 5| Step: 3
Training loss: 2.584385633468628
Validation loss: 2.4930452018655758

Epoch: 5| Step: 4
Training loss: 2.6958606243133545
Validation loss: 2.497278441664993

Epoch: 5| Step: 5
Training loss: 2.9171218872070312
Validation loss: 2.499049960926015

Epoch: 5| Step: 6
Training loss: 2.6381421089172363
Validation loss: 2.5069372115596646

Epoch: 5| Step: 7
Training loss: 2.1317074298858643
Validation loss: 2.510436822009343

Epoch: 5| Step: 8
Training loss: 3.16011118888855
Validation loss: 2.518459568741501

Epoch: 5| Step: 9
Training loss: 2.3217034339904785
Validation loss: 2.5197375333437355

Epoch: 5| Step: 10
Training loss: 3.3870253562927246
Validation loss: 2.5096071561177573

Epoch: 120| Step: 0
Training loss: 2.5018503665924072
Validation loss: 2.4896142713485228

Epoch: 5| Step: 1
Training loss: 2.6470415592193604
Validation loss: 2.4822769805949223

Epoch: 5| Step: 2
Training loss: 2.6836166381835938
Validation loss: 2.486145250258907

Epoch: 5| Step: 3
Training loss: 3.026428699493408
Validation loss: 2.490988134056009

Epoch: 5| Step: 4
Training loss: 2.6890921592712402
Validation loss: 2.49629783374007

Epoch: 5| Step: 5
Training loss: 2.938619375228882
Validation loss: 2.4948868418252594

Epoch: 5| Step: 6
Training loss: 2.140918493270874
Validation loss: 2.496659060960175

Epoch: 5| Step: 7
Training loss: 3.007308006286621
Validation loss: 2.4985041361983105

Epoch: 5| Step: 8
Training loss: 2.1352438926696777
Validation loss: 2.4986191539354223

Epoch: 5| Step: 9
Training loss: 3.074427843093872
Validation loss: 2.4930555205191336

Epoch: 5| Step: 10
Training loss: 2.8425822257995605
Validation loss: 2.4901810358929377

Epoch: 121| Step: 0
Training loss: 2.3664333820343018
Validation loss: 2.4888581537431285

Epoch: 5| Step: 1
Training loss: 2.7151477336883545
Validation loss: 2.4852015946501043

Epoch: 5| Step: 2
Training loss: 3.773045301437378
Validation loss: 2.48257520891005

Epoch: 5| Step: 3
Training loss: 2.425447940826416
Validation loss: 2.480868172901933

Epoch: 5| Step: 4
Training loss: 2.2102410793304443
Validation loss: 2.484651034878146

Epoch: 5| Step: 5
Training loss: 2.5307323932647705
Validation loss: 2.4864058802204747

Epoch: 5| Step: 6
Training loss: 1.9537477493286133
Validation loss: 2.4830742343779533

Epoch: 5| Step: 7
Training loss: 3.3638243675231934
Validation loss: 2.4815444638652187

Epoch: 5| Step: 8
Training loss: 2.5047316551208496
Validation loss: 2.482376298596782

Epoch: 5| Step: 9
Training loss: 3.531215190887451
Validation loss: 2.4842651146714405

Epoch: 5| Step: 10
Training loss: 2.1424901485443115
Validation loss: 2.4882720029482277

Epoch: 122| Step: 0
Training loss: 2.263009548187256
Validation loss: 2.484408788783576

Epoch: 5| Step: 1
Training loss: 2.8151297569274902
Validation loss: 2.482747031796363

Epoch: 5| Step: 2
Training loss: 2.2777047157287598
Validation loss: 2.48854459229336

Epoch: 5| Step: 3
Training loss: 2.562918186187744
Validation loss: 2.4854133795666438

Epoch: 5| Step: 4
Training loss: 2.784303903579712
Validation loss: 2.492240418669998

Epoch: 5| Step: 5
Training loss: 3.1105360984802246
Validation loss: 2.4883997286519697

Epoch: 5| Step: 6
Training loss: 2.731283664703369
Validation loss: 2.483377843774775

Epoch: 5| Step: 7
Training loss: 2.946345806121826
Validation loss: 2.4856502830341296

Epoch: 5| Step: 8
Training loss: 2.176203489303589
Validation loss: 2.4879572212055163

Epoch: 5| Step: 9
Training loss: 2.8878777027130127
Validation loss: 2.486092946862662

Epoch: 5| Step: 10
Training loss: 3.0286896228790283
Validation loss: 2.495209035053048

Epoch: 123| Step: 0
Training loss: 2.9408156871795654
Validation loss: 2.4929316530945482

Epoch: 5| Step: 1
Training loss: 2.409771203994751
Validation loss: 2.480642316161945

Epoch: 5| Step: 2
Training loss: 2.0840649604797363
Validation loss: 2.4877710419316448

Epoch: 5| Step: 3
Training loss: 1.9809099435806274
Validation loss: 2.4955079196601786

Epoch: 5| Step: 4
Training loss: 2.542243480682373
Validation loss: 2.492578001432521

Epoch: 5| Step: 5
Training loss: 2.587646484375
Validation loss: 2.4884679932748117

Epoch: 5| Step: 6
Training loss: 3.5707664489746094
Validation loss: 2.485659337812854

Epoch: 5| Step: 7
Training loss: 2.704087018966675
Validation loss: 2.4839577239046813

Epoch: 5| Step: 8
Training loss: 2.5769667625427246
Validation loss: 2.4786658184502715

Epoch: 5| Step: 9
Training loss: 2.8656558990478516
Validation loss: 2.485377509106872

Epoch: 5| Step: 10
Training loss: 3.341548204421997
Validation loss: 2.4986601157854964

Epoch: 124| Step: 0
Training loss: 2.243241548538208
Validation loss: 2.509487421281876

Epoch: 5| Step: 1
Training loss: 3.196138620376587
Validation loss: 2.510397377834525

Epoch: 5| Step: 2
Training loss: 2.1887354850769043
Validation loss: 2.508566492347307

Epoch: 5| Step: 3
Training loss: 2.9396820068359375
Validation loss: 2.5139348929928196

Epoch: 5| Step: 4
Training loss: 1.9445641040802002
Validation loss: 2.496317501991026

Epoch: 5| Step: 5
Training loss: 2.8822054862976074
Validation loss: 2.480165796895181

Epoch: 5| Step: 6
Training loss: 2.758746862411499
Validation loss: 2.4776455715138423

Epoch: 5| Step: 7
Training loss: 3.032230854034424
Validation loss: 2.4777996488796767

Epoch: 5| Step: 8
Training loss: 2.7697603702545166
Validation loss: 2.4787639187228296

Epoch: 5| Step: 9
Training loss: 3.1813158988952637
Validation loss: 2.479706225856658

Epoch: 5| Step: 10
Training loss: 2.442460536956787
Validation loss: 2.471211302664972

Epoch: 125| Step: 0
Training loss: 2.279989719390869
Validation loss: 2.472285952619327

Epoch: 5| Step: 1
Training loss: 3.254634141921997
Validation loss: 2.47327099820619

Epoch: 5| Step: 2
Training loss: 2.235464572906494
Validation loss: 2.4684754674152662

Epoch: 5| Step: 3
Training loss: 2.5728492736816406
Validation loss: 2.47273894791962

Epoch: 5| Step: 4
Training loss: 2.8267433643341064
Validation loss: 2.476859829759085

Epoch: 5| Step: 5
Training loss: 2.5396194458007812
Validation loss: 2.488921783303702

Epoch: 5| Step: 6
Training loss: 2.7091641426086426
Validation loss: 2.4980852014275006

Epoch: 5| Step: 7
Training loss: 2.407829761505127
Validation loss: 2.4903429579991165

Epoch: 5| Step: 8
Training loss: 3.0654075145721436
Validation loss: 2.483407523042412

Epoch: 5| Step: 9
Training loss: 2.585733652114868
Validation loss: 2.4738855285029255

Epoch: 5| Step: 10
Training loss: 3.0758376121520996
Validation loss: 2.4698518642815213

Epoch: 126| Step: 0
Training loss: 2.621178150177002
Validation loss: 2.469840157416559

Epoch: 5| Step: 1
Training loss: 2.6522841453552246
Validation loss: 2.4708557513452347

Epoch: 5| Step: 2
Training loss: 2.664356231689453
Validation loss: 2.4709518494144564

Epoch: 5| Step: 3
Training loss: 2.1639084815979004
Validation loss: 2.468397207157586

Epoch: 5| Step: 4
Training loss: 3.118755340576172
Validation loss: 2.472165133363457

Epoch: 5| Step: 5
Training loss: 1.9973440170288086
Validation loss: 2.48164519956035

Epoch: 5| Step: 6
Training loss: 2.9460201263427734
Validation loss: 2.4861835305408766

Epoch: 5| Step: 7
Training loss: 2.3770217895507812
Validation loss: 2.490241568575623

Epoch: 5| Step: 8
Training loss: 3.165682315826416
Validation loss: 2.494832479825584

Epoch: 5| Step: 9
Training loss: 2.744110345840454
Validation loss: 2.5083330677401636

Epoch: 5| Step: 10
Training loss: 2.9879133701324463
Validation loss: 2.498335135880337

Epoch: 127| Step: 0
Training loss: 2.382336139678955
Validation loss: 2.4841571597642798

Epoch: 5| Step: 1
Training loss: 2.8987643718719482
Validation loss: 2.477259910234841

Epoch: 5| Step: 2
Training loss: 2.816495418548584
Validation loss: 2.471761665036601

Epoch: 5| Step: 3
Training loss: 3.09993314743042
Validation loss: 2.4685300703971618

Epoch: 5| Step: 4
Training loss: 3.35371470451355
Validation loss: 2.4652728829332577

Epoch: 5| Step: 5
Training loss: 2.175032615661621
Validation loss: 2.463578439527942

Epoch: 5| Step: 6
Training loss: 2.7486846446990967
Validation loss: 2.4695957117183234

Epoch: 5| Step: 7
Training loss: 2.8625710010528564
Validation loss: 2.4678962999774563

Epoch: 5| Step: 8
Training loss: 2.2948873043060303
Validation loss: 2.4697106371643724

Epoch: 5| Step: 9
Training loss: 2.3578429222106934
Validation loss: 2.4701015487793954

Epoch: 5| Step: 10
Training loss: 2.4567151069641113
Validation loss: 2.4671786241633917

Epoch: 128| Step: 0
Training loss: 3.001716136932373
Validation loss: 2.4692815247402398

Epoch: 5| Step: 1
Training loss: 1.862569808959961
Validation loss: 2.4676072238593973

Epoch: 5| Step: 2
Training loss: 2.2027809619903564
Validation loss: 2.47336511201756

Epoch: 5| Step: 3
Training loss: 3.279597759246826
Validation loss: 2.471453202668057

Epoch: 5| Step: 4
Training loss: 2.673987627029419
Validation loss: 2.464578890031384

Epoch: 5| Step: 5
Training loss: 3.5863022804260254
Validation loss: 2.470506642454414

Epoch: 5| Step: 6
Training loss: 1.9944641590118408
Validation loss: 2.4705456995194957

Epoch: 5| Step: 7
Training loss: 2.9839377403259277
Validation loss: 2.4693177054005284

Epoch: 5| Step: 8
Training loss: 2.141226053237915
Validation loss: 2.4751576685136363

Epoch: 5| Step: 9
Training loss: 3.018895149230957
Validation loss: 2.4712742195334485

Epoch: 5| Step: 10
Training loss: 2.6139283180236816
Validation loss: 2.475908294800789

Epoch: 129| Step: 0
Training loss: 2.367577075958252
Validation loss: 2.486062034483879

Epoch: 5| Step: 1
Training loss: 2.747652530670166
Validation loss: 2.4920343711812007

Epoch: 5| Step: 2
Training loss: 2.6687417030334473
Validation loss: 2.4950884260157102

Epoch: 5| Step: 3
Training loss: 2.922849178314209
Validation loss: 2.4976728962313746

Epoch: 5| Step: 4
Training loss: 2.852627992630005
Validation loss: 2.4908977272689983

Epoch: 5| Step: 5
Training loss: 2.271925210952759
Validation loss: 2.487473093053346

Epoch: 5| Step: 6
Training loss: 3.047469139099121
Validation loss: 2.4764848063069005

Epoch: 5| Step: 7
Training loss: 2.3809618949890137
Validation loss: 2.467823456692439

Epoch: 5| Step: 8
Training loss: 3.1167502403259277
Validation loss: 2.4652693169091338

Epoch: 5| Step: 9
Training loss: 2.299539566040039
Validation loss: 2.4643353416073706

Epoch: 5| Step: 10
Training loss: 2.7570302486419678
Validation loss: 2.4702044789509108

Epoch: 130| Step: 0
Training loss: 2.9339284896850586
Validation loss: 2.4871418783741612

Epoch: 5| Step: 1
Training loss: 2.241387128829956
Validation loss: 2.50045451553919

Epoch: 5| Step: 2
Training loss: 2.9821746349334717
Validation loss: 2.5095143138721423

Epoch: 5| Step: 3
Training loss: 2.6532580852508545
Validation loss: 2.4927801291147866

Epoch: 5| Step: 4
Training loss: 2.7717525959014893
Validation loss: 2.4751660798185613

Epoch: 5| Step: 5
Training loss: 3.3317389488220215
Validation loss: 2.4636675055309007

Epoch: 5| Step: 6
Training loss: 2.2492928504943848
Validation loss: 2.460956770886657

Epoch: 5| Step: 7
Training loss: 2.9903604984283447
Validation loss: 2.4586458975268948

Epoch: 5| Step: 8
Training loss: 2.7310423851013184
Validation loss: 2.456285807394212

Epoch: 5| Step: 9
Training loss: 2.405226707458496
Validation loss: 2.4629414235391924

Epoch: 5| Step: 10
Training loss: 2.100776195526123
Validation loss: 2.4693264166514077

Epoch: 131| Step: 0
Training loss: 3.064216136932373
Validation loss: 2.4796041211774273

Epoch: 5| Step: 1
Training loss: 2.4829206466674805
Validation loss: 2.496420039925524

Epoch: 5| Step: 2
Training loss: 2.0780911445617676
Validation loss: 2.4988205817437943

Epoch: 5| Step: 3
Training loss: 2.515578508377075
Validation loss: 2.5093594622868363

Epoch: 5| Step: 4
Training loss: 2.519242763519287
Validation loss: 2.5214630839645222

Epoch: 5| Step: 5
Training loss: 2.679356098175049
Validation loss: 2.506384121474399

Epoch: 5| Step: 6
Training loss: 2.9997410774230957
Validation loss: 2.4944846553187214

Epoch: 5| Step: 7
Training loss: 2.8903303146362305
Validation loss: 2.4809365887795725

Epoch: 5| Step: 8
Training loss: 3.0231480598449707
Validation loss: 2.4706280564749115

Epoch: 5| Step: 9
Training loss: 2.644521713256836
Validation loss: 2.4653330618335354

Epoch: 5| Step: 10
Training loss: 2.690859079360962
Validation loss: 2.461672930307286

Epoch: 132| Step: 0
Training loss: 3.3994622230529785
Validation loss: 2.464234878939967

Epoch: 5| Step: 1
Training loss: 3.1123251914978027
Validation loss: 2.461414731958861

Epoch: 5| Step: 2
Training loss: 2.0920050144195557
Validation loss: 2.4649715987584924

Epoch: 5| Step: 3
Training loss: 2.795825481414795
Validation loss: 2.465239101840604

Epoch: 5| Step: 4
Training loss: 2.7775237560272217
Validation loss: 2.4637049244296167

Epoch: 5| Step: 5
Training loss: 2.5221500396728516
Validation loss: 2.4638348805007113

Epoch: 5| Step: 6
Training loss: 2.716954469680786
Validation loss: 2.462405079154558

Epoch: 5| Step: 7
Training loss: 2.7468135356903076
Validation loss: 2.4597611299125095

Epoch: 5| Step: 8
Training loss: 2.5962579250335693
Validation loss: 2.4618863726174958

Epoch: 5| Step: 9
Training loss: 2.3612747192382812
Validation loss: 2.4618481846265894

Epoch: 5| Step: 10
Training loss: 2.2359111309051514
Validation loss: 2.4598380814316454

Epoch: 133| Step: 0
Training loss: 3.398712635040283
Validation loss: 2.4737302436623523

Epoch: 5| Step: 1
Training loss: 2.2795767784118652
Validation loss: 2.489720941871725

Epoch: 5| Step: 2
Training loss: 2.2466509342193604
Validation loss: 2.487628229202763

Epoch: 5| Step: 3
Training loss: 2.8335938453674316
Validation loss: 2.4742459122852614

Epoch: 5| Step: 4
Training loss: 1.9737049341201782
Validation loss: 2.4780998947799846

Epoch: 5| Step: 5
Training loss: 3.654865264892578
Validation loss: 2.468082986852174

Epoch: 5| Step: 6
Training loss: 2.3874127864837646
Validation loss: 2.461653863230059

Epoch: 5| Step: 7
Training loss: 2.0749316215515137
Validation loss: 2.457853655661306

Epoch: 5| Step: 8
Training loss: 3.241180896759033
Validation loss: 2.44930943622384

Epoch: 5| Step: 9
Training loss: 2.758690357208252
Validation loss: 2.45260799572032

Epoch: 5| Step: 10
Training loss: 2.464547634124756
Validation loss: 2.450153071393249

Epoch: 134| Step: 0
Training loss: 2.8155195713043213
Validation loss: 2.447462167791141

Epoch: 5| Step: 1
Training loss: 2.7959797382354736
Validation loss: 2.447237624916979

Epoch: 5| Step: 2
Training loss: 3.291128158569336
Validation loss: 2.451293550511842

Epoch: 5| Step: 3
Training loss: 2.554513692855835
Validation loss: 2.450240986321562

Epoch: 5| Step: 4
Training loss: 2.3143012523651123
Validation loss: 2.4549628457715436

Epoch: 5| Step: 5
Training loss: 3.3670825958251953
Validation loss: 2.455967031499391

Epoch: 5| Step: 6
Training loss: 2.261509418487549
Validation loss: 2.4586418726110972

Epoch: 5| Step: 7
Training loss: 2.711818218231201
Validation loss: 2.4619295622712825

Epoch: 5| Step: 8
Training loss: 2.284992218017578
Validation loss: 2.461481345597134

Epoch: 5| Step: 9
Training loss: 2.529142141342163
Validation loss: 2.468610199548865

Epoch: 5| Step: 10
Training loss: 2.2318241596221924
Validation loss: 2.4788878733111965

Epoch: 135| Step: 0
Training loss: 2.620013475418091
Validation loss: 2.4746109977845223

Epoch: 5| Step: 1
Training loss: 2.320533037185669
Validation loss: 2.4652238045969317

Epoch: 5| Step: 2
Training loss: 3.7279839515686035
Validation loss: 2.4712032323242514

Epoch: 5| Step: 3
Training loss: 3.320697069168091
Validation loss: 2.466356590229978

Epoch: 5| Step: 4
Training loss: 2.562077045440674
Validation loss: 2.4579907796716176

Epoch: 5| Step: 5
Training loss: 2.3146414756774902
Validation loss: 2.4521139103879213

Epoch: 5| Step: 6
Training loss: 2.4624104499816895
Validation loss: 2.450122812742828

Epoch: 5| Step: 7
Training loss: 2.391878843307495
Validation loss: 2.448718906730734

Epoch: 5| Step: 8
Training loss: 2.2371010780334473
Validation loss: 2.4460601652822187

Epoch: 5| Step: 9
Training loss: 3.10949969291687
Validation loss: 2.4525955159177064

Epoch: 5| Step: 10
Training loss: 2.0791258811950684
Validation loss: 2.4457126637940765

Epoch: 136| Step: 0
Training loss: 2.1578774452209473
Validation loss: 2.4445749777619556

Epoch: 5| Step: 1
Training loss: 3.245483875274658
Validation loss: 2.448908995556575

Epoch: 5| Step: 2
Training loss: 2.4626047611236572
Validation loss: 2.4443764378947597

Epoch: 5| Step: 3
Training loss: 3.042663335800171
Validation loss: 2.4478813960988033

Epoch: 5| Step: 4
Training loss: 2.196687936782837
Validation loss: 2.4495495468057613

Epoch: 5| Step: 5
Training loss: 2.1637187004089355
Validation loss: 2.45234182829498

Epoch: 5| Step: 6
Training loss: 2.8983514308929443
Validation loss: 2.452154635101236

Epoch: 5| Step: 7
Training loss: 2.442754030227661
Validation loss: 2.4527393361573577

Epoch: 5| Step: 8
Training loss: 3.044895648956299
Validation loss: 2.4551846211956394

Epoch: 5| Step: 9
Training loss: 2.704342842102051
Validation loss: 2.455249217248732

Epoch: 5| Step: 10
Training loss: 2.8796441555023193
Validation loss: 2.460664579945226

Epoch: 137| Step: 0
Training loss: 2.8706002235412598
Validation loss: 2.4653905924930366

Epoch: 5| Step: 1
Training loss: 2.2918827533721924
Validation loss: 2.4707701847117436

Epoch: 5| Step: 2
Training loss: 2.5961296558380127
Validation loss: 2.473472467032812

Epoch: 5| Step: 3
Training loss: 3.0382184982299805
Validation loss: 2.4620720186541156

Epoch: 5| Step: 4
Training loss: 2.504263401031494
Validation loss: 2.4599721739369054

Epoch: 5| Step: 5
Training loss: 2.628537654876709
Validation loss: 2.4616178594609743

Epoch: 5| Step: 6
Training loss: 2.3058459758758545
Validation loss: 2.4480711106331117

Epoch: 5| Step: 7
Training loss: 2.8771002292633057
Validation loss: 2.4484492527541293

Epoch: 5| Step: 8
Training loss: 2.988055467605591
Validation loss: 2.44692462746815

Epoch: 5| Step: 9
Training loss: 2.6234121322631836
Validation loss: 2.450939457903626

Epoch: 5| Step: 10
Training loss: 2.4667727947235107
Validation loss: 2.448766254609631

Epoch: 138| Step: 0
Training loss: 2.754927396774292
Validation loss: 2.439327962936894

Epoch: 5| Step: 1
Training loss: 3.073728322982788
Validation loss: 2.4434898899447535

Epoch: 5| Step: 2
Training loss: 2.6033194065093994
Validation loss: 2.446592048932147

Epoch: 5| Step: 3
Training loss: 2.3397529125213623
Validation loss: 2.459462909288304

Epoch: 5| Step: 4
Training loss: 2.6872286796569824
Validation loss: 2.4759684762647076

Epoch: 5| Step: 5
Training loss: 2.7885870933532715
Validation loss: 2.4699734872387302

Epoch: 5| Step: 6
Training loss: 2.2490780353546143
Validation loss: 2.4708879737443823

Epoch: 5| Step: 7
Training loss: 3.1806464195251465
Validation loss: 2.469669429204797

Epoch: 5| Step: 8
Training loss: 2.310556411743164
Validation loss: 2.4624080093958045

Epoch: 5| Step: 9
Training loss: 2.1469593048095703
Validation loss: 2.4459439016157583

Epoch: 5| Step: 10
Training loss: 3.224655866622925
Validation loss: 2.4418565611685477

Epoch: 139| Step: 0
Training loss: 2.6748404502868652
Validation loss: 2.437127682470506

Epoch: 5| Step: 1
Training loss: 1.93246591091156
Validation loss: 2.4395768437334286

Epoch: 5| Step: 2
Training loss: 2.5717453956604004
Validation loss: 2.436604228070987

Epoch: 5| Step: 3
Training loss: 2.947157621383667
Validation loss: 2.435854478548932

Epoch: 5| Step: 4
Training loss: 2.17828631401062
Validation loss: 2.437030830690938

Epoch: 5| Step: 5
Training loss: 2.9450087547302246
Validation loss: 2.4360392657659387

Epoch: 5| Step: 6
Training loss: 3.61425518989563
Validation loss: 2.439101698578045

Epoch: 5| Step: 7
Training loss: 2.471806287765503
Validation loss: 2.434534021603164

Epoch: 5| Step: 8
Training loss: 2.200432300567627
Validation loss: 2.4389643464037167

Epoch: 5| Step: 9
Training loss: 3.087351083755493
Validation loss: 2.443326796254804

Epoch: 5| Step: 10
Training loss: 2.602930784225464
Validation loss: 2.4471211869229554

Epoch: 140| Step: 0
Training loss: 3.0213119983673096
Validation loss: 2.4439101834451

Epoch: 5| Step: 1
Training loss: 2.338582992553711
Validation loss: 2.4518747893712853

Epoch: 5| Step: 2
Training loss: 2.303025722503662
Validation loss: 2.4588458794419483

Epoch: 5| Step: 3
Training loss: 2.9263486862182617
Validation loss: 2.4523329760438655

Epoch: 5| Step: 4
Training loss: 2.374809741973877
Validation loss: 2.4556362167481454

Epoch: 5| Step: 5
Training loss: 3.4323151111602783
Validation loss: 2.4492930186692106

Epoch: 5| Step: 6
Training loss: 2.789827823638916
Validation loss: 2.4559725997268513

Epoch: 5| Step: 7
Training loss: 2.0468080043792725
Validation loss: 2.455412877503262

Epoch: 5| Step: 8
Training loss: 2.5420737266540527
Validation loss: 2.456139023585986

Epoch: 5| Step: 9
Training loss: 2.6131272315979004
Validation loss: 2.446573313846383

Epoch: 5| Step: 10
Training loss: 2.741384506225586
Validation loss: 2.4409950907512377

Epoch: 141| Step: 0
Training loss: 3.2013611793518066
Validation loss: 2.437218819895098

Epoch: 5| Step: 1
Training loss: 3.2256920337677
Validation loss: 2.439005651781636

Epoch: 5| Step: 2
Training loss: 2.900233745574951
Validation loss: 2.4347409099660893

Epoch: 5| Step: 3
Training loss: 3.0685696601867676
Validation loss: 2.4329852314405542

Epoch: 5| Step: 4
Training loss: 1.8525069952011108
Validation loss: 2.4388052186658307

Epoch: 5| Step: 5
Training loss: 2.1865603923797607
Validation loss: 2.4397556909950833

Epoch: 5| Step: 6
Training loss: 2.136042356491089
Validation loss: 2.440516000152916

Epoch: 5| Step: 7
Training loss: 2.3712210655212402
Validation loss: 2.4447587292681456

Epoch: 5| Step: 8
Training loss: 2.4608705043792725
Validation loss: 2.451728661855062

Epoch: 5| Step: 9
Training loss: 2.6923880577087402
Validation loss: 2.4541954327655096

Epoch: 5| Step: 10
Training loss: 3.162691831588745
Validation loss: 2.44751472883327

Epoch: 142| Step: 0
Training loss: 3.2703232765197754
Validation loss: 2.442234532807463

Epoch: 5| Step: 1
Training loss: 2.612825870513916
Validation loss: 2.442016483635031

Epoch: 5| Step: 2
Training loss: 2.8214468955993652
Validation loss: 2.4372007564831804

Epoch: 5| Step: 3
Training loss: 2.5997045040130615
Validation loss: 2.437309895792315

Epoch: 5| Step: 4
Training loss: 2.802635669708252
Validation loss: 2.435568468545073

Epoch: 5| Step: 5
Training loss: 2.1898601055145264
Validation loss: 2.4359252350304716

Epoch: 5| Step: 6
Training loss: 2.6480400562286377
Validation loss: 2.4415392593670915

Epoch: 5| Step: 7
Training loss: 2.303560256958008
Validation loss: 2.4395986680061585

Epoch: 5| Step: 8
Training loss: 2.7650370597839355
Validation loss: 2.456089458157939

Epoch: 5| Step: 9
Training loss: 2.466240167617798
Validation loss: 2.4532988686715402

Epoch: 5| Step: 10
Training loss: 2.621487617492676
Validation loss: 2.445323731309624

Epoch: 143| Step: 0
Training loss: 2.3885750770568848
Validation loss: 2.4438081864387757

Epoch: 5| Step: 1
Training loss: 2.8314921855926514
Validation loss: 2.44391817174932

Epoch: 5| Step: 2
Training loss: 2.2206053733825684
Validation loss: 2.4343813055305072

Epoch: 5| Step: 3
Training loss: 2.5919995307922363
Validation loss: 2.439814693184309

Epoch: 5| Step: 4
Training loss: 2.0400853157043457
Validation loss: 2.437079139935073

Epoch: 5| Step: 5
Training loss: 2.628756284713745
Validation loss: 2.4453893297462055

Epoch: 5| Step: 6
Training loss: 2.483884334564209
Validation loss: 2.445956867228272

Epoch: 5| Step: 7
Training loss: 2.3313488960266113
Validation loss: 2.4563744709055912

Epoch: 5| Step: 8
Training loss: 3.249593734741211
Validation loss: 2.459107824551162

Epoch: 5| Step: 9
Training loss: 3.3912391662597656
Validation loss: 2.463470361566031

Epoch: 5| Step: 10
Training loss: 3.007030487060547
Validation loss: 2.4478169641187115

Epoch: 144| Step: 0
Training loss: 2.402221918106079
Validation loss: 2.4437624562171196

Epoch: 5| Step: 1
Training loss: 2.193448781967163
Validation loss: 2.442804972330729

Epoch: 5| Step: 2
Training loss: 2.934253454208374
Validation loss: 2.4442207633808093

Epoch: 5| Step: 3
Training loss: 2.796356439590454
Validation loss: 2.4501812714402393

Epoch: 5| Step: 4
Training loss: 2.8476524353027344
Validation loss: 2.4426995195368284

Epoch: 5| Step: 5
Training loss: 2.05631422996521
Validation loss: 2.4474637828847414

Epoch: 5| Step: 6
Training loss: 3.300856113433838
Validation loss: 2.4456292429277973

Epoch: 5| Step: 7
Training loss: 2.8631186485290527
Validation loss: 2.4509506763950473

Epoch: 5| Step: 8
Training loss: 2.5915160179138184
Validation loss: 2.4588877744572137

Epoch: 5| Step: 9
Training loss: 2.3312177658081055
Validation loss: 2.45586867742641

Epoch: 5| Step: 10
Training loss: 2.853757858276367
Validation loss: 2.4410696106572307

Epoch: 145| Step: 0
Training loss: 2.5220086574554443
Validation loss: 2.4395264810131443

Epoch: 5| Step: 1
Training loss: 2.3337104320526123
Validation loss: 2.438093944262433

Epoch: 5| Step: 2
Training loss: 2.694483518600464
Validation loss: 2.43864966207935

Epoch: 5| Step: 3
Training loss: 2.687465190887451
Validation loss: 2.4497994325494252

Epoch: 5| Step: 4
Training loss: 2.407748222351074
Validation loss: 2.4479838545604418

Epoch: 5| Step: 5
Training loss: 1.7752513885498047
Validation loss: 2.4532938516268166

Epoch: 5| Step: 6
Training loss: 2.2578816413879395
Validation loss: 2.4592694595295894

Epoch: 5| Step: 7
Training loss: 2.763354778289795
Validation loss: 2.457519253094991

Epoch: 5| Step: 8
Training loss: 3.208293914794922
Validation loss: 2.4536735114230903

Epoch: 5| Step: 9
Training loss: 2.9949588775634766
Validation loss: 2.4380644982860935

Epoch: 5| Step: 10
Training loss: 3.581437587738037
Validation loss: 2.430859973353724

Epoch: 146| Step: 0
Training loss: 3.217440128326416
Validation loss: 2.424877961476644

Epoch: 5| Step: 1
Training loss: 1.9732290506362915
Validation loss: 2.421916495087326

Epoch: 5| Step: 2
Training loss: 2.1544671058654785
Validation loss: 2.4181027745687835

Epoch: 5| Step: 3
Training loss: 3.352252244949341
Validation loss: 2.4182925890850764

Epoch: 5| Step: 4
Training loss: 2.331238269805908
Validation loss: 2.417182742908437

Epoch: 5| Step: 5
Training loss: 3.058809995651245
Validation loss: 2.4169145348251506

Epoch: 5| Step: 6
Training loss: 2.8970704078674316
Validation loss: 2.4194697000647105

Epoch: 5| Step: 7
Training loss: 2.5082130432128906
Validation loss: 2.425853160119826

Epoch: 5| Step: 8
Training loss: 2.5771679878234863
Validation loss: 2.435278131115821

Epoch: 5| Step: 9
Training loss: 2.604703426361084
Validation loss: 2.438634549417803

Epoch: 5| Step: 10
Training loss: 2.432729482650757
Validation loss: 2.4391868704108783

Epoch: 147| Step: 0
Training loss: 2.5176689624786377
Validation loss: 2.4314151604970298

Epoch: 5| Step: 1
Training loss: 2.2398765087127686
Validation loss: 2.4227451996136735

Epoch: 5| Step: 2
Training loss: 2.939318895339966
Validation loss: 2.4157504368853826

Epoch: 5| Step: 3
Training loss: 1.8776524066925049
Validation loss: 2.4177075996193835

Epoch: 5| Step: 4
Training loss: 2.215270519256592
Validation loss: 2.421437289125176

Epoch: 5| Step: 5
Training loss: 3.19016170501709
Validation loss: 2.4309668874227874

Epoch: 5| Step: 6
Training loss: 1.8903411626815796
Validation loss: 2.4248602108288835

Epoch: 5| Step: 7
Training loss: 2.233901262283325
Validation loss: 2.4285607530224707

Epoch: 5| Step: 8
Training loss: 3.4830374717712402
Validation loss: 2.4361237864340506

Epoch: 5| Step: 9
Training loss: 3.0194907188415527
Validation loss: 2.4360637152066795

Epoch: 5| Step: 10
Training loss: 3.67751407623291
Validation loss: 2.429960653346072

Epoch: 148| Step: 0
Training loss: 2.395624876022339
Validation loss: 2.4203429196470525

Epoch: 5| Step: 1
Training loss: 2.6247897148132324
Validation loss: 2.4212771308037544

Epoch: 5| Step: 2
Training loss: 2.6569857597351074
Validation loss: 2.4201338342441026

Epoch: 5| Step: 3
Training loss: 3.352611541748047
Validation loss: 2.41620821081182

Epoch: 5| Step: 4
Training loss: 3.2901268005371094
Validation loss: 2.425892291530486

Epoch: 5| Step: 5
Training loss: 2.95227313041687
Validation loss: 2.4234424585937173

Epoch: 5| Step: 6
Training loss: 2.5898470878601074
Validation loss: 2.429003333532682

Epoch: 5| Step: 7
Training loss: 2.0068352222442627
Validation loss: 2.427366077259023

Epoch: 5| Step: 8
Training loss: 2.467284679412842
Validation loss: 2.424749107771022

Epoch: 5| Step: 9
Training loss: 2.549797296524048
Validation loss: 2.422434758114558

Epoch: 5| Step: 10
Training loss: 2.047999858856201
Validation loss: 2.4294205583551878

Epoch: 149| Step: 0
Training loss: 2.2507100105285645
Validation loss: 2.4274536589140534

Epoch: 5| Step: 1
Training loss: 3.370129346847534
Validation loss: 2.4245320725184616

Epoch: 5| Step: 2
Training loss: 2.3047759532928467
Validation loss: 2.422866834107266

Epoch: 5| Step: 3
Training loss: 3.276287078857422
Validation loss: 2.4278484800810456

Epoch: 5| Step: 4
Training loss: 2.5873501300811768
Validation loss: 2.4215747951179423

Epoch: 5| Step: 5
Training loss: 2.428849697113037
Validation loss: 2.422330717886648

Epoch: 5| Step: 6
Training loss: 2.785928249359131
Validation loss: 2.4275041100799397

Epoch: 5| Step: 7
Training loss: 2.2227001190185547
Validation loss: 2.4272223441831526

Epoch: 5| Step: 8
Training loss: 2.25756573677063
Validation loss: 2.426599984527916

Epoch: 5| Step: 9
Training loss: 2.496857166290283
Validation loss: 2.4320505383194133

Epoch: 5| Step: 10
Training loss: 3.0244603157043457
Validation loss: 2.441575660500475

Epoch: 150| Step: 0
Training loss: 2.182284355163574
Validation loss: 2.4390576680501304

Epoch: 5| Step: 1
Training loss: 2.0970449447631836
Validation loss: 2.4396336617008334

Epoch: 5| Step: 2
Training loss: 2.572835922241211
Validation loss: 2.4340263848663657

Epoch: 5| Step: 3
Training loss: 3.128647565841675
Validation loss: 2.427789462509976

Epoch: 5| Step: 4
Training loss: 2.5020670890808105
Validation loss: 2.4249258810474026

Epoch: 5| Step: 5
Training loss: 1.7353925704956055
Validation loss: 2.423705259958903

Epoch: 5| Step: 6
Training loss: 3.0495643615722656
Validation loss: 2.421593999349943

Epoch: 5| Step: 7
Training loss: 2.8270764350891113
Validation loss: 2.416449392995527

Epoch: 5| Step: 8
Training loss: 2.857572317123413
Validation loss: 2.4155706103130052

Epoch: 5| Step: 9
Training loss: 3.0374128818511963
Validation loss: 2.4207438345878356

Epoch: 5| Step: 10
Training loss: 2.9760890007019043
Validation loss: 2.4144677295479724

Epoch: 151| Step: 0
Training loss: 2.599562406539917
Validation loss: 2.4195701409411687

Epoch: 5| Step: 1
Training loss: 3.293093204498291
Validation loss: 2.4183745563671155

Epoch: 5| Step: 2
Training loss: 2.4508607387542725
Validation loss: 2.41932858702957

Epoch: 5| Step: 3
Training loss: 3.380359172821045
Validation loss: 2.416838848462669

Epoch: 5| Step: 4
Training loss: 2.7132668495178223
Validation loss: 2.419436526554887

Epoch: 5| Step: 5
Training loss: 2.0065178871154785
Validation loss: 2.4262978902427097

Epoch: 5| Step: 6
Training loss: 2.2207388877868652
Validation loss: 2.4296422799428306

Epoch: 5| Step: 7
Training loss: 2.493830442428589
Validation loss: 2.421266435295023

Epoch: 5| Step: 8
Training loss: 2.813303232192993
Validation loss: 2.4174898785929524

Epoch: 5| Step: 9
Training loss: 2.3323333263397217
Validation loss: 2.4128061853429323

Epoch: 5| Step: 10
Training loss: 2.6378133296966553
Validation loss: 2.4150446435456634

Epoch: 152| Step: 0
Training loss: 3.0361788272857666
Validation loss: 2.416371532665786

Epoch: 5| Step: 1
Training loss: 2.2274813652038574
Validation loss: 2.421561005294964

Epoch: 5| Step: 2
Training loss: 2.2600998878479004
Validation loss: 2.428408443286855

Epoch: 5| Step: 3
Training loss: 2.720402240753174
Validation loss: 2.421259562174479

Epoch: 5| Step: 4
Training loss: 2.6601810455322266
Validation loss: 2.427032305348304

Epoch: 5| Step: 5
Training loss: 2.3258116245269775
Validation loss: 2.421995896165089

Epoch: 5| Step: 6
Training loss: 2.787012815475464
Validation loss: 2.424383181397633

Epoch: 5| Step: 7
Training loss: 2.9338576793670654
Validation loss: 2.4304937829253492

Epoch: 5| Step: 8
Training loss: 2.80385422706604
Validation loss: 2.4347483035056823

Epoch: 5| Step: 9
Training loss: 2.697638750076294
Validation loss: 2.4249978885855725

Epoch: 5| Step: 10
Training loss: 2.656526803970337
Validation loss: 2.4103723443964475

Epoch: 153| Step: 0
Training loss: 2.4429612159729004
Validation loss: 2.4106468051992436

Epoch: 5| Step: 1
Training loss: 2.796494483947754
Validation loss: 2.414174666968725

Epoch: 5| Step: 2
Training loss: 2.9335408210754395
Validation loss: 2.4201855633848455

Epoch: 5| Step: 3
Training loss: 2.503568410873413
Validation loss: 2.4191240392705446

Epoch: 5| Step: 4
Training loss: 2.273165702819824
Validation loss: 2.409715219210553

Epoch: 5| Step: 5
Training loss: 2.4974136352539062
Validation loss: 2.4113345325634046

Epoch: 5| Step: 6
Training loss: 2.225451946258545
Validation loss: 2.406217118745209

Epoch: 5| Step: 7
Training loss: 2.6699166297912598
Validation loss: 2.402457921735702

Epoch: 5| Step: 8
Training loss: 3.320643663406372
Validation loss: 2.4060045224364086

Epoch: 5| Step: 9
Training loss: 2.8952033519744873
Validation loss: 2.407395044962565

Epoch: 5| Step: 10
Training loss: 2.4640848636627197
Validation loss: 2.4146746179108978

Epoch: 154| Step: 0
Training loss: 2.6948018074035645
Validation loss: 2.422355967183267

Epoch: 5| Step: 1
Training loss: 2.7326600551605225
Validation loss: 2.432198409111269

Epoch: 5| Step: 2
Training loss: 2.923262119293213
Validation loss: 2.444724827684382

Epoch: 5| Step: 3
Training loss: 3.3804214000701904
Validation loss: 2.447186282885972

Epoch: 5| Step: 4
Training loss: 2.219404697418213
Validation loss: 2.4445113930650937

Epoch: 5| Step: 5
Training loss: 2.0862038135528564
Validation loss: 2.4368388422073854

Epoch: 5| Step: 6
Training loss: 2.7240586280822754
Validation loss: 2.4225803805935766

Epoch: 5| Step: 7
Training loss: 2.5114827156066895
Validation loss: 2.423151652018229

Epoch: 5| Step: 8
Training loss: 2.8601012229919434
Validation loss: 2.4204232077444754

Epoch: 5| Step: 9
Training loss: 2.885880708694458
Validation loss: 2.430551463557828

Epoch: 5| Step: 10
Training loss: 1.8785260915756226
Validation loss: 2.423880143832135

Epoch: 155| Step: 0
Training loss: 2.9758458137512207
Validation loss: 2.423479569855557

Epoch: 5| Step: 1
Training loss: 2.480120897293091
Validation loss: 2.4366762304818756

Epoch: 5| Step: 2
Training loss: 2.251990795135498
Validation loss: 2.432735340569609

Epoch: 5| Step: 3
Training loss: 2.001756191253662
Validation loss: 2.436607358276203

Epoch: 5| Step: 4
Training loss: 2.238445281982422
Validation loss: 2.431685206710651

Epoch: 5| Step: 5
Training loss: 2.9353315830230713
Validation loss: 2.4344150917504424

Epoch: 5| Step: 6
Training loss: 2.916992664337158
Validation loss: 2.439661982238934

Epoch: 5| Step: 7
Training loss: 2.8340086936950684
Validation loss: 2.4279532201828493

Epoch: 5| Step: 8
Training loss: 2.91198992729187
Validation loss: 2.4243110815684

Epoch: 5| Step: 9
Training loss: 2.6760191917419434
Validation loss: 2.42319748222187

Epoch: 5| Step: 10
Training loss: 2.8390746116638184
Validation loss: 2.41081380075024

Epoch: 156| Step: 0
Training loss: 2.0140557289123535
Validation loss: 2.402572270362608

Epoch: 5| Step: 1
Training loss: 2.8758387565612793
Validation loss: 2.4040896367001277

Epoch: 5| Step: 2
Training loss: 2.5625905990600586
Validation loss: 2.401846358853002

Epoch: 5| Step: 3
Training loss: 3.0817904472351074
Validation loss: 2.415612277164254

Epoch: 5| Step: 4
Training loss: 2.9601924419403076
Validation loss: 2.4026545106723742

Epoch: 5| Step: 5
Training loss: 2.6134700775146484
Validation loss: 2.406431939012261

Epoch: 5| Step: 6
Training loss: 2.651027202606201
Validation loss: 2.4141342998832784

Epoch: 5| Step: 7
Training loss: 2.6366515159606934
Validation loss: 2.426984412695772

Epoch: 5| Step: 8
Training loss: 3.0082011222839355
Validation loss: 2.440648312209755

Epoch: 5| Step: 9
Training loss: 2.4478554725646973
Validation loss: 2.4209002012847574

Epoch: 5| Step: 10
Training loss: 2.088315725326538
Validation loss: 2.4186261033499115

Epoch: 157| Step: 0
Training loss: 2.645528793334961
Validation loss: 2.402804482367731

Epoch: 5| Step: 1
Training loss: 2.4234097003936768
Validation loss: 2.398078208328575

Epoch: 5| Step: 2
Training loss: 2.8521816730499268
Validation loss: 2.391206697751117

Epoch: 5| Step: 3
Training loss: 2.40765118598938
Validation loss: 2.3915976350025465

Epoch: 5| Step: 4
Training loss: 2.3967692852020264
Validation loss: 2.3907717863718667

Epoch: 5| Step: 5
Training loss: 2.7676968574523926
Validation loss: 2.393102345928069

Epoch: 5| Step: 6
Training loss: 3.1283907890319824
Validation loss: 2.3932939806292133

Epoch: 5| Step: 7
Training loss: 2.343496084213257
Validation loss: 2.3898559078093498

Epoch: 5| Step: 8
Training loss: 2.5239639282226562
Validation loss: 2.3915325544213735

Epoch: 5| Step: 9
Training loss: 2.3039302825927734
Validation loss: 2.3897815878673265

Epoch: 5| Step: 10
Training loss: 3.183091640472412
Validation loss: 2.3924605564404557

Epoch: 158| Step: 0
Training loss: 1.7826182842254639
Validation loss: 2.3939946133603334

Epoch: 5| Step: 1
Training loss: 2.859107255935669
Validation loss: 2.3918021519978843

Epoch: 5| Step: 2
Training loss: 2.530974864959717
Validation loss: 2.3917799329244964

Epoch: 5| Step: 3
Training loss: 2.6400604248046875
Validation loss: 2.392330854169784

Epoch: 5| Step: 4
Training loss: 2.9106690883636475
Validation loss: 2.4041537007977887

Epoch: 5| Step: 5
Training loss: 2.379542589187622
Validation loss: 2.405249810987903

Epoch: 5| Step: 6
Training loss: 2.52366042137146
Validation loss: 2.404181739335419

Epoch: 5| Step: 7
Training loss: 2.486354351043701
Validation loss: 2.4057034497619956

Epoch: 5| Step: 8
Training loss: 3.3193728923797607
Validation loss: 2.4053988046543573

Epoch: 5| Step: 9
Training loss: 2.8024044036865234
Validation loss: 2.4198900294560257

Epoch: 5| Step: 10
Training loss: 2.5550668239593506
Validation loss: 2.4259458664924867

Epoch: 159| Step: 0
Training loss: 2.6985113620758057
Validation loss: 2.430000146230062

Epoch: 5| Step: 1
Training loss: 2.5172247886657715
Validation loss: 2.430199738471739

Epoch: 5| Step: 2
Training loss: 3.4495577812194824
Validation loss: 2.4299851002231723

Epoch: 5| Step: 3
Training loss: 3.4918856620788574
Validation loss: 2.4277795745480444

Epoch: 5| Step: 4
Training loss: 2.323415994644165
Validation loss: 2.4316344261169434

Epoch: 5| Step: 5
Training loss: 2.2221755981445312
Validation loss: 2.4244384868170625

Epoch: 5| Step: 6
Training loss: 2.504027843475342
Validation loss: 2.424621597413094

Epoch: 5| Step: 7
Training loss: 2.228209972381592
Validation loss: 2.422321629780595

Epoch: 5| Step: 8
Training loss: 2.556508779525757
Validation loss: 2.43063965664115

Epoch: 5| Step: 9
Training loss: 2.442316770553589
Validation loss: 2.4286719022258634

Epoch: 5| Step: 10
Training loss: 2.340365409851074
Validation loss: 2.409566379362537

Epoch: 160| Step: 0
Training loss: 2.5679633617401123
Validation loss: 2.403432946051321

Epoch: 5| Step: 1
Training loss: 3.13622784614563
Validation loss: 2.3971940061097503

Epoch: 5| Step: 2
Training loss: 2.35432767868042
Validation loss: 2.4072661117840837

Epoch: 5| Step: 3
Training loss: 2.803314208984375
Validation loss: 2.4077502040452856

Epoch: 5| Step: 4
Training loss: 2.1118111610412598
Validation loss: 2.4122745042206137

Epoch: 5| Step: 5
Training loss: 2.824920177459717
Validation loss: 2.4215965296632502

Epoch: 5| Step: 6
Training loss: 2.6562483310699463
Validation loss: 2.409590546802808

Epoch: 5| Step: 7
Training loss: 2.9049010276794434
Validation loss: 2.4133279503032727

Epoch: 5| Step: 8
Training loss: 2.0191404819488525
Validation loss: 2.4225734049274075

Epoch: 5| Step: 9
Training loss: 2.4887032508850098
Validation loss: 2.4176576816907493

Epoch: 5| Step: 10
Training loss: 3.006230354309082
Validation loss: 2.406442396102413

Epoch: 161| Step: 0
Training loss: 2.7396187782287598
Validation loss: 2.392898505733859

Epoch: 5| Step: 1
Training loss: 1.9973163604736328
Validation loss: 2.3829427739625335

Epoch: 5| Step: 2
Training loss: 2.6198573112487793
Validation loss: 2.3803874856682232

Epoch: 5| Step: 3
Training loss: 3.1377742290496826
Validation loss: 2.387131590997019

Epoch: 5| Step: 4
Training loss: 1.6515014171600342
Validation loss: 2.3936350191793134

Epoch: 5| Step: 5
Training loss: 3.007216691970825
Validation loss: 2.401733867583736

Epoch: 5| Step: 6
Training loss: 3.0984129905700684
Validation loss: 2.4122322810593473

Epoch: 5| Step: 7
Training loss: 2.8794188499450684
Validation loss: 2.409146508862895

Epoch: 5| Step: 8
Training loss: 3.0156569480895996
Validation loss: 2.4051155223641345

Epoch: 5| Step: 9
Training loss: 2.022303819656372
Validation loss: 2.4077270492430656

Epoch: 5| Step: 10
Training loss: 2.9561045169830322
Validation loss: 2.4024829659410702

Epoch: 162| Step: 0
Training loss: 2.5263724327087402
Validation loss: 2.4035034346324142

Epoch: 5| Step: 1
Training loss: 2.9847805500030518
Validation loss: 2.40054637898681

Epoch: 5| Step: 2
Training loss: 3.3275997638702393
Validation loss: 2.388505272967841

Epoch: 5| Step: 3
Training loss: 2.99802303314209
Validation loss: 2.384314662666731

Epoch: 5| Step: 4
Training loss: 3.1368980407714844
Validation loss: 2.3947340596106743

Epoch: 5| Step: 5
Training loss: 2.1526503562927246
Validation loss: 2.3929985851369877

Epoch: 5| Step: 6
Training loss: 2.6427958011627197
Validation loss: 2.3945753036006803

Epoch: 5| Step: 7
Training loss: 1.887353539466858
Validation loss: 2.398526604457568

Epoch: 5| Step: 8
Training loss: 2.356461763381958
Validation loss: 2.4147202173868814

Epoch: 5| Step: 9
Training loss: 2.309908390045166
Validation loss: 2.435026704624135

Epoch: 5| Step: 10
Training loss: 2.44002628326416
Validation loss: 2.4362261500409854

Epoch: 163| Step: 0
Training loss: 3.165015697479248
Validation loss: 2.4274348648645545

Epoch: 5| Step: 1
Training loss: 2.4050862789154053
Validation loss: 2.414941659537695

Epoch: 5| Step: 2
Training loss: 3.243861436843872
Validation loss: 2.4143846137549287

Epoch: 5| Step: 3
Training loss: 2.296086549758911
Validation loss: 2.3944674050936134

Epoch: 5| Step: 4
Training loss: 2.7113871574401855
Validation loss: 2.383281320653936

Epoch: 5| Step: 5
Training loss: 2.64774227142334
Validation loss: 2.3884246016061432

Epoch: 5| Step: 6
Training loss: 2.1810762882232666
Validation loss: 2.388635799448977

Epoch: 5| Step: 7
Training loss: 2.4351425170898438
Validation loss: 2.393249727064563

Epoch: 5| Step: 8
Training loss: 2.6072115898132324
Validation loss: 2.394417744810863

Epoch: 5| Step: 9
Training loss: 2.17006778717041
Validation loss: 2.399428044596026

Epoch: 5| Step: 10
Training loss: 3.029454469680786
Validation loss: 2.393703258165749

Epoch: 164| Step: 0
Training loss: 2.944359302520752
Validation loss: 2.3956913230239705

Epoch: 5| Step: 1
Training loss: 1.9885421991348267
Validation loss: 2.396086346718573

Epoch: 5| Step: 2
Training loss: 1.9512510299682617
Validation loss: 2.399248892261136

Epoch: 5| Step: 3
Training loss: 2.573637008666992
Validation loss: 2.395012040292063

Epoch: 5| Step: 4
Training loss: 2.569018602371216
Validation loss: 2.3964437592414116

Epoch: 5| Step: 5
Training loss: 2.4340968132019043
Validation loss: 2.418794026938818

Epoch: 5| Step: 6
Training loss: 2.587359666824341
Validation loss: 2.433000681220844

Epoch: 5| Step: 7
Training loss: 2.9843640327453613
Validation loss: 2.434810317972655

Epoch: 5| Step: 8
Training loss: 2.6855244636535645
Validation loss: 2.429773535779727

Epoch: 5| Step: 9
Training loss: 3.286607265472412
Validation loss: 2.4192023764374437

Epoch: 5| Step: 10
Training loss: 2.9540584087371826
Validation loss: 2.4091118048596125

Epoch: 165| Step: 0
Training loss: 2.857316493988037
Validation loss: 2.3985949024077384

Epoch: 5| Step: 1
Training loss: 1.469795823097229
Validation loss: 2.3801761698979202

Epoch: 5| Step: 2
Training loss: 2.9981868267059326
Validation loss: 2.382897328304988

Epoch: 5| Step: 3
Training loss: 2.560375452041626
Validation loss: 2.3806406272354947

Epoch: 5| Step: 4
Training loss: 2.4073562622070312
Validation loss: 2.37818831013095

Epoch: 5| Step: 5
Training loss: 2.5250658988952637
Validation loss: 2.3794243720269974

Epoch: 5| Step: 6
Training loss: 2.869441270828247
Validation loss: 2.377678132826282

Epoch: 5| Step: 7
Training loss: 2.0878918170928955
Validation loss: 2.375780487573275

Epoch: 5| Step: 8
Training loss: 3.008791208267212
Validation loss: 2.3759493827819824

Epoch: 5| Step: 9
Training loss: 2.7853405475616455
Validation loss: 2.372341540551955

Epoch: 5| Step: 10
Training loss: 3.2313873767852783
Validation loss: 2.374941070874532

Epoch: 166| Step: 0
Training loss: 2.835703134536743
Validation loss: 2.3768403145574752

Epoch: 5| Step: 1
Training loss: 1.8593189716339111
Validation loss: 2.379096382407732

Epoch: 5| Step: 2
Training loss: 2.3616957664489746
Validation loss: 2.380124863757882

Epoch: 5| Step: 3
Training loss: 2.825873374938965
Validation loss: 2.398021938980267

Epoch: 5| Step: 4
Training loss: 2.5831475257873535
Validation loss: 2.3897566487712245

Epoch: 5| Step: 5
Training loss: 3.0175487995147705
Validation loss: 2.412049626791349

Epoch: 5| Step: 6
Training loss: 3.4233551025390625
Validation loss: 2.407569864744781

Epoch: 5| Step: 7
Training loss: 2.9473073482513428
Validation loss: 2.393035891235516

Epoch: 5| Step: 8
Training loss: 2.0993945598602295
Validation loss: 2.388158577744679

Epoch: 5| Step: 9
Training loss: 2.321150302886963
Validation loss: 2.391536610100859

Epoch: 5| Step: 10
Training loss: 2.3152689933776855
Validation loss: 2.389875691424134

Epoch: 167| Step: 0
Training loss: 2.8831353187561035
Validation loss: 2.3863134025245585

Epoch: 5| Step: 1
Training loss: 2.786766767501831
Validation loss: 2.396140580536217

Epoch: 5| Step: 2
Training loss: 2.607630968093872
Validation loss: 2.377430985050817

Epoch: 5| Step: 3
Training loss: 2.3302314281463623
Validation loss: 2.372644057837866

Epoch: 5| Step: 4
Training loss: 1.999566674232483
Validation loss: 2.379860883118004

Epoch: 5| Step: 5
Training loss: 3.2158195972442627
Validation loss: 2.3800309896469116

Epoch: 5| Step: 6
Training loss: 2.3788909912109375
Validation loss: 2.3897374471028647

Epoch: 5| Step: 7
Training loss: 2.9247756004333496
Validation loss: 2.3935227650468067

Epoch: 5| Step: 8
Training loss: 2.6636831760406494
Validation loss: 2.3925267727144304

Epoch: 5| Step: 9
Training loss: 2.5705485343933105
Validation loss: 2.3881963145348335

Epoch: 5| Step: 10
Training loss: 2.246255874633789
Validation loss: 2.3871080901033137

Epoch: 168| Step: 0
Training loss: 2.901681661605835
Validation loss: 2.379699819831438

Epoch: 5| Step: 1
Training loss: 2.231102705001831
Validation loss: 2.3781130595873763

Epoch: 5| Step: 2
Training loss: 2.9899537563323975
Validation loss: 2.3751394774324153

Epoch: 5| Step: 3
Training loss: 2.393505573272705
Validation loss: 2.3785189710637575

Epoch: 5| Step: 4
Training loss: 2.2922160625457764
Validation loss: 2.3789560564102663

Epoch: 5| Step: 5
Training loss: 2.839783191680908
Validation loss: 2.3771972143521873

Epoch: 5| Step: 6
Training loss: 2.7870144844055176
Validation loss: 2.3685828921615437

Epoch: 5| Step: 7
Training loss: 2.1754050254821777
Validation loss: 2.3701120166368383

Epoch: 5| Step: 8
Training loss: 2.5543875694274902
Validation loss: 2.3751826158133884

Epoch: 5| Step: 9
Training loss: 2.749817132949829
Validation loss: 2.3847201460151264

Epoch: 5| Step: 10
Training loss: 2.7812607288360596
Validation loss: 2.3931887893266577

Epoch: 169| Step: 0
Training loss: 2.803067445755005
Validation loss: 2.3814748640983336

Epoch: 5| Step: 1
Training loss: 2.8943634033203125
Validation loss: 2.386304501564272

Epoch: 5| Step: 2
Training loss: 2.6764795780181885
Validation loss: 2.370845002512778

Epoch: 5| Step: 3
Training loss: 2.376284122467041
Validation loss: 2.3653858477069485

Epoch: 5| Step: 4
Training loss: 2.8343820571899414
Validation loss: 2.3672633940173733

Epoch: 5| Step: 5
Training loss: 3.0133392810821533
Validation loss: 2.368130922317505

Epoch: 5| Step: 6
Training loss: 1.8756730556488037
Validation loss: 2.370671751678631

Epoch: 5| Step: 7
Training loss: 2.779409885406494
Validation loss: 2.3809787919444423

Epoch: 5| Step: 8
Training loss: 2.4956841468811035
Validation loss: 2.38724660617049

Epoch: 5| Step: 9
Training loss: 2.744191884994507
Validation loss: 2.387213712097496

Epoch: 5| Step: 10
Training loss: 2.0200319290161133
Validation loss: 2.3838077668220765

Epoch: 170| Step: 0
Training loss: 2.849792718887329
Validation loss: 2.3879454571713685

Epoch: 5| Step: 1
Training loss: 2.02235746383667
Validation loss: 2.3854302398620115

Epoch: 5| Step: 2
Training loss: 2.965773105621338
Validation loss: 2.385696513678438

Epoch: 5| Step: 3
Training loss: 2.3508753776550293
Validation loss: 2.3823167944467194

Epoch: 5| Step: 4
Training loss: 2.8863155841827393
Validation loss: 2.3770776307711037

Epoch: 5| Step: 5
Training loss: 2.4499053955078125
Validation loss: 2.378619788795389

Epoch: 5| Step: 6
Training loss: 2.5427253246307373
Validation loss: 2.384523755760603

Epoch: 5| Step: 7
Training loss: 2.6414902210235596
Validation loss: 2.3850352687220417

Epoch: 5| Step: 8
Training loss: 2.158750534057617
Validation loss: 2.38056517160067

Epoch: 5| Step: 9
Training loss: 2.797945737838745
Validation loss: 2.3794268382492887

Epoch: 5| Step: 10
Training loss: 2.8495655059814453
Validation loss: 2.37188377688008

Epoch: 171| Step: 0
Training loss: 2.540006637573242
Validation loss: 2.377178047292976

Epoch: 5| Step: 1
Training loss: 2.6691861152648926
Validation loss: 2.3793833307040635

Epoch: 5| Step: 2
Training loss: 2.8148422241210938
Validation loss: 2.372498954496076

Epoch: 5| Step: 3
Training loss: 2.5984716415405273
Validation loss: 2.36155838735642

Epoch: 5| Step: 4
Training loss: 2.44346284866333
Validation loss: 2.3670634659387733

Epoch: 5| Step: 5
Training loss: 1.8619855642318726
Validation loss: 2.364331809423303

Epoch: 5| Step: 6
Training loss: 2.2706573009490967
Validation loss: 2.3683057677361274

Epoch: 5| Step: 7
Training loss: 3.252340316772461
Validation loss: 2.360560045447401

Epoch: 5| Step: 8
Training loss: 3.0308547019958496
Validation loss: 2.3590985651939147

Epoch: 5| Step: 9
Training loss: 2.481452465057373
Validation loss: 2.355358810834987

Epoch: 5| Step: 10
Training loss: 2.52295184135437
Validation loss: 2.3582467058653473

Epoch: 172| Step: 0
Training loss: 2.8677268028259277
Validation loss: 2.3573579736935195

Epoch: 5| Step: 1
Training loss: 2.6757819652557373
Validation loss: 2.360569123298891

Epoch: 5| Step: 2
Training loss: 3.116600513458252
Validation loss: 2.3601750430240425

Epoch: 5| Step: 3
Training loss: 2.9240760803222656
Validation loss: 2.3629444824751986

Epoch: 5| Step: 4
Training loss: 2.564873218536377
Validation loss: 2.364819408744894

Epoch: 5| Step: 5
Training loss: 2.376643657684326
Validation loss: 2.3715172659966255

Epoch: 5| Step: 6
Training loss: 2.052574634552002
Validation loss: 2.37471422841472

Epoch: 5| Step: 7
Training loss: 1.9480350017547607
Validation loss: 2.387858711263185

Epoch: 5| Step: 8
Training loss: 2.6381547451019287
Validation loss: 2.4145884795855452

Epoch: 5| Step: 9
Training loss: 2.9262876510620117
Validation loss: 2.433832755652807

Epoch: 5| Step: 10
Training loss: 2.381010055541992
Validation loss: 2.4249354152269262

Epoch: 173| Step: 0
Training loss: 2.436215877532959
Validation loss: 2.4302472863146054

Epoch: 5| Step: 1
Training loss: 2.3887691497802734
Validation loss: 2.4171524329852034

Epoch: 5| Step: 2
Training loss: 2.9322447776794434
Validation loss: 2.405449367338611

Epoch: 5| Step: 3
Training loss: 3.4218947887420654
Validation loss: 2.3837443679891606

Epoch: 5| Step: 4
Training loss: 2.4303250312805176
Validation loss: 2.3800927541589223

Epoch: 5| Step: 5
Training loss: 2.360457181930542
Validation loss: 2.3672113880034416

Epoch: 5| Step: 6
Training loss: 3.2500815391540527
Validation loss: 2.3634145567494054

Epoch: 5| Step: 7
Training loss: 2.9335854053497314
Validation loss: 2.351355980801326

Epoch: 5| Step: 8
Training loss: 1.954833984375
Validation loss: 2.3466256382644817

Epoch: 5| Step: 9
Training loss: 2.464442014694214
Validation loss: 2.342475098948325

Epoch: 5| Step: 10
Training loss: 1.8560179471969604
Validation loss: 2.34606187317961

Epoch: 174| Step: 0
Training loss: 2.474095582962036
Validation loss: 2.347440637567992

Epoch: 5| Step: 1
Training loss: 2.281162977218628
Validation loss: 2.3492598546448575

Epoch: 5| Step: 2
Training loss: 2.0399951934814453
Validation loss: 2.35100277521277

Epoch: 5| Step: 3
Training loss: 2.182478666305542
Validation loss: 2.3594624047638266

Epoch: 5| Step: 4
Training loss: 3.0057339668273926
Validation loss: 2.358317203419183

Epoch: 5| Step: 5
Training loss: 2.8303585052490234
Validation loss: 2.355068850260909

Epoch: 5| Step: 6
Training loss: 3.006593942642212
Validation loss: 2.362030754807175

Epoch: 5| Step: 7
Training loss: 2.3763937950134277
Validation loss: 2.3680273871267996

Epoch: 5| Step: 8
Training loss: 2.327613353729248
Validation loss: 2.3658906413662817

Epoch: 5| Step: 9
Training loss: 2.9454455375671387
Validation loss: 2.3621690811649447

Epoch: 5| Step: 10
Training loss: 3.025606155395508
Validation loss: 2.351301316292055

Epoch: 175| Step: 0
Training loss: 3.4917705059051514
Validation loss: 2.3560112266130346

Epoch: 5| Step: 1
Training loss: 2.75117826461792
Validation loss: 2.3535446479756343

Epoch: 5| Step: 2
Training loss: 2.1500887870788574
Validation loss: 2.353356146043347

Epoch: 5| Step: 3
Training loss: 3.1948611736297607
Validation loss: 2.3537911484318395

Epoch: 5| Step: 4
Training loss: 2.3451321125030518
Validation loss: 2.350989685263685

Epoch: 5| Step: 5
Training loss: 2.6782803535461426
Validation loss: 2.3512440932694303

Epoch: 5| Step: 6
Training loss: 2.293506383895874
Validation loss: 2.3594562238262546

Epoch: 5| Step: 7
Training loss: 2.4046192169189453
Validation loss: 2.3842093201093775

Epoch: 5| Step: 8
Training loss: 2.7047743797302246
Validation loss: 2.407836780753187

Epoch: 5| Step: 9
Training loss: 2.592423677444458
Validation loss: 2.438868736708036

Epoch: 5| Step: 10
Training loss: 1.8708122968673706
Validation loss: 2.428092095159715

Epoch: 176| Step: 0
Training loss: 2.890242099761963
Validation loss: 2.3966115572119273

Epoch: 5| Step: 1
Training loss: 2.247436285018921
Validation loss: 2.367518409605949

Epoch: 5| Step: 2
Training loss: 2.5035200119018555
Validation loss: 2.346474778267645

Epoch: 5| Step: 3
Training loss: 2.4075281620025635
Validation loss: 2.3472208156380603

Epoch: 5| Step: 4
Training loss: 2.3487823009490967
Validation loss: 2.345394419085595

Epoch: 5| Step: 5
Training loss: 2.8350815773010254
Validation loss: 2.3449736179844027

Epoch: 5| Step: 6
Training loss: 2.405012845993042
Validation loss: 2.3479469924844723

Epoch: 5| Step: 7
Training loss: 1.9335658550262451
Validation loss: 2.3424280484517417

Epoch: 5| Step: 8
Training loss: 2.784926414489746
Validation loss: 2.3514838987781155

Epoch: 5| Step: 9
Training loss: 3.001415252685547
Validation loss: 2.3489708387723534

Epoch: 5| Step: 10
Training loss: 3.177624464035034
Validation loss: 2.3617035086436937

Epoch: 177| Step: 0
Training loss: 2.933265209197998
Validation loss: 2.3640040684771795

Epoch: 5| Step: 1
Training loss: 2.8293240070343018
Validation loss: 2.365114660673244

Epoch: 5| Step: 2
Training loss: 2.4221034049987793
Validation loss: 2.3631723901276946

Epoch: 5| Step: 3
Training loss: 2.4216012954711914
Validation loss: 2.3556624304863716

Epoch: 5| Step: 4
Training loss: 2.974012851715088
Validation loss: 2.363888140647642

Epoch: 5| Step: 5
Training loss: 1.905677080154419
Validation loss: 2.363161407491212

Epoch: 5| Step: 6
Training loss: 2.4766151905059814
Validation loss: 2.3650717684017715

Epoch: 5| Step: 7
Training loss: 2.538961172103882
Validation loss: 2.364194672594788

Epoch: 5| Step: 8
Training loss: 2.152761936187744
Validation loss: 2.3587751747459493

Epoch: 5| Step: 9
Training loss: 2.3660683631896973
Validation loss: 2.3663286829507477

Epoch: 5| Step: 10
Training loss: 3.433119297027588
Validation loss: 2.3804727010829474

Epoch: 178| Step: 0
Training loss: 1.838727355003357
Validation loss: 2.400508024359262

Epoch: 5| Step: 1
Training loss: 2.5709424018859863
Validation loss: 2.382284105464976

Epoch: 5| Step: 2
Training loss: 2.0766172409057617
Validation loss: 2.3668718620013167

Epoch: 5| Step: 3
Training loss: 2.3967037200927734
Validation loss: 2.3640104621969242

Epoch: 5| Step: 4
Training loss: 3.5754971504211426
Validation loss: 2.37192343383707

Epoch: 5| Step: 5
Training loss: 3.011099100112915
Validation loss: 2.381766762784732

Epoch: 5| Step: 6
Training loss: 2.954028367996216
Validation loss: 2.396461525271016

Epoch: 5| Step: 7
Training loss: 2.4437198638916016
Validation loss: 2.400743353751398

Epoch: 5| Step: 8
Training loss: 2.0320353507995605
Validation loss: 2.411048414886639

Epoch: 5| Step: 9
Training loss: 2.9638352394104004
Validation loss: 2.4171591881782777

Epoch: 5| Step: 10
Training loss: 2.6102774143218994
Validation loss: 2.417614811210222

Epoch: 179| Step: 0
Training loss: 2.103564977645874
Validation loss: 2.4220301720403854

Epoch: 5| Step: 1
Training loss: 2.2992520332336426
Validation loss: 2.4107396884631087

Epoch: 5| Step: 2
Training loss: 2.7301974296569824
Validation loss: 2.382422331840761

Epoch: 5| Step: 3
Training loss: 3.4704251289367676
Validation loss: 2.37119980524945

Epoch: 5| Step: 4
Training loss: 2.403996229171753
Validation loss: 2.354399276036088

Epoch: 5| Step: 5
Training loss: 1.9049127101898193
Validation loss: 2.345167471516517

Epoch: 5| Step: 6
Training loss: 2.963311195373535
Validation loss: 2.344668616530716

Epoch: 5| Step: 7
Training loss: 2.8238306045532227
Validation loss: 2.343792135997485

Epoch: 5| Step: 8
Training loss: 2.3883471488952637
Validation loss: 2.3420050298013995

Epoch: 5| Step: 9
Training loss: 2.979483127593994
Validation loss: 2.334689171083512

Epoch: 5| Step: 10
Training loss: 2.306873321533203
Validation loss: 2.3441350075506393

Epoch: 180| Step: 0
Training loss: 2.780543088912964
Validation loss: 2.3431349826115433

Epoch: 5| Step: 1
Training loss: 2.400970697402954
Validation loss: 2.3504392408555552

Epoch: 5| Step: 2
Training loss: 2.551419734954834
Validation loss: 2.3619341260643414

Epoch: 5| Step: 3
Training loss: 2.331463575363159
Validation loss: 2.391466720129854

Epoch: 5| Step: 4
Training loss: 2.6909122467041016
Validation loss: 2.4061255557562715

Epoch: 5| Step: 5
Training loss: 2.2254323959350586
Validation loss: 2.407328313396823

Epoch: 5| Step: 6
Training loss: 2.7087032794952393
Validation loss: 2.3859468121682443

Epoch: 5| Step: 7
Training loss: 2.676553726196289
Validation loss: 2.383598812164799

Epoch: 5| Step: 8
Training loss: 2.215944766998291
Validation loss: 2.373457677902714

Epoch: 5| Step: 9
Training loss: 3.03379487991333
Validation loss: 2.379687169546722

Epoch: 5| Step: 10
Training loss: 2.751587152481079
Validation loss: 2.3697719676520235

Epoch: 181| Step: 0
Training loss: 2.9978299140930176
Validation loss: 2.3597982186143116

Epoch: 5| Step: 1
Training loss: 2.7076144218444824
Validation loss: 2.3655137836292224

Epoch: 5| Step: 2
Training loss: 2.3330960273742676
Validation loss: 2.3712631707550376

Epoch: 5| Step: 3
Training loss: 2.627429485321045
Validation loss: 2.3758692946485294

Epoch: 5| Step: 4
Training loss: 2.1167378425598145
Validation loss: 2.3656643821347143

Epoch: 5| Step: 5
Training loss: 2.4955673217773438
Validation loss: 2.3597937066067933

Epoch: 5| Step: 6
Training loss: 3.4723758697509766
Validation loss: 2.349113497682797

Epoch: 5| Step: 7
Training loss: 2.091732978820801
Validation loss: 2.328472891161519

Epoch: 5| Step: 8
Training loss: 2.6146063804626465
Validation loss: 2.313986809022965

Epoch: 5| Step: 9
Training loss: 2.11537504196167
Validation loss: 2.304036742897444

Epoch: 5| Step: 10
Training loss: 2.6853106021881104
Validation loss: 2.3047087653990714

Epoch: 182| Step: 0
Training loss: 2.6780295372009277
Validation loss: 2.313999970753988

Epoch: 5| Step: 1
Training loss: 2.1411666870117188
Validation loss: 2.3096655132949993

Epoch: 5| Step: 2
Training loss: 3.3344178199768066
Validation loss: 2.3171568480871056

Epoch: 5| Step: 3
Training loss: 2.360752820968628
Validation loss: 2.313500504339895

Epoch: 5| Step: 4
Training loss: 2.173175811767578
Validation loss: 2.307112472031706

Epoch: 5| Step: 5
Training loss: 2.37705659866333
Validation loss: 2.305896197595904

Epoch: 5| Step: 6
Training loss: 2.2519748210906982
Validation loss: 2.3103501924904446

Epoch: 5| Step: 7
Training loss: 2.9982028007507324
Validation loss: 2.322273923504737

Epoch: 5| Step: 8
Training loss: 2.6632518768310547
Validation loss: 2.33466003787133

Epoch: 5| Step: 9
Training loss: 2.726008892059326
Validation loss: 2.3569559038326306

Epoch: 5| Step: 10
Training loss: 2.733156442642212
Validation loss: 2.403570176452719

Epoch: 183| Step: 0
Training loss: 1.9282957315444946
Validation loss: 2.3847215867811635

Epoch: 5| Step: 1
Training loss: 2.0062649250030518
Validation loss: 2.368863862047913

Epoch: 5| Step: 2
Training loss: 2.550252676010132
Validation loss: 2.3509612391071935

Epoch: 5| Step: 3
Training loss: 2.9399847984313965
Validation loss: 2.34886307613824

Epoch: 5| Step: 4
Training loss: 2.8889412879943848
Validation loss: 2.342226548861432

Epoch: 5| Step: 5
Training loss: 2.864838123321533
Validation loss: 2.3331137972493328

Epoch: 5| Step: 6
Training loss: 2.2935738563537598
Validation loss: 2.338354814437128

Epoch: 5| Step: 7
Training loss: 2.839775800704956
Validation loss: 2.353154241397817

Epoch: 5| Step: 8
Training loss: 2.603865385055542
Validation loss: 2.3653978083723333

Epoch: 5| Step: 9
Training loss: 2.7600083351135254
Validation loss: 2.3615848992460515

Epoch: 5| Step: 10
Training loss: 2.293693780899048
Validation loss: 2.33451932989141

Epoch: 184| Step: 0
Training loss: 2.5432095527648926
Validation loss: 2.3192857285981536

Epoch: 5| Step: 1
Training loss: 2.4422366619110107
Validation loss: 2.310348282578171

Epoch: 5| Step: 2
Training loss: 2.4032649993896484
Validation loss: 2.301218089237008

Epoch: 5| Step: 3
Training loss: 2.067276954650879
Validation loss: 2.29933496444456

Epoch: 5| Step: 4
Training loss: 2.937591075897217
Validation loss: 2.3106808072777203

Epoch: 5| Step: 5
Training loss: 2.848803758621216
Validation loss: 2.321832036459318

Epoch: 5| Step: 6
Training loss: 2.7739694118499756
Validation loss: 2.331336493133217

Epoch: 5| Step: 7
Training loss: 2.381906032562256
Validation loss: 2.3226113755215883

Epoch: 5| Step: 8
Training loss: 2.4973092079162598
Validation loss: 2.3120619635428152

Epoch: 5| Step: 9
Training loss: 2.652508020401001
Validation loss: 2.3107939997026996

Epoch: 5| Step: 10
Training loss: 2.6851768493652344
Validation loss: 2.3080267675461306

Epoch: 185| Step: 0
Training loss: 2.781372547149658
Validation loss: 2.3043124291204635

Epoch: 5| Step: 1
Training loss: 2.771571159362793
Validation loss: 2.307207551053775

Epoch: 5| Step: 2
Training loss: 2.311338424682617
Validation loss: 2.3191806321503012

Epoch: 5| Step: 3
Training loss: 2.3405585289001465
Validation loss: 2.3437813020521596

Epoch: 5| Step: 4
Training loss: 2.3006937503814697
Validation loss: 2.352911603066229

Epoch: 5| Step: 5
Training loss: 2.66326642036438
Validation loss: 2.368421328965054

Epoch: 5| Step: 6
Training loss: 2.4682295322418213
Validation loss: 2.382445248224402

Epoch: 5| Step: 7
Training loss: 2.6468071937561035
Validation loss: 2.359882672627767

Epoch: 5| Step: 8
Training loss: 2.6657419204711914
Validation loss: 2.333019300173688

Epoch: 5| Step: 9
Training loss: 2.686415433883667
Validation loss: 2.3156582834900066

Epoch: 5| Step: 10
Training loss: 2.5374014377593994
Validation loss: 2.3118654143425728

Epoch: 186| Step: 0
Training loss: 2.0203211307525635
Validation loss: 2.3076947453201457

Epoch: 5| Step: 1
Training loss: 3.1275787353515625
Validation loss: 2.3164980488438762

Epoch: 5| Step: 2
Training loss: 2.4483253955841064
Validation loss: 2.3139383459603913

Epoch: 5| Step: 3
Training loss: 3.0821166038513184
Validation loss: 2.33608317118819

Epoch: 5| Step: 4
Training loss: 2.7083685398101807
Validation loss: 2.3417313765454035

Epoch: 5| Step: 5
Training loss: 2.254209518432617
Validation loss: 2.324270009994507

Epoch: 5| Step: 6
Training loss: 2.55668568611145
Validation loss: 2.3385274410247803

Epoch: 5| Step: 7
Training loss: 2.2258458137512207
Validation loss: 2.3309429153319328

Epoch: 5| Step: 8
Training loss: 2.6040537357330322
Validation loss: 2.3274933676565848

Epoch: 5| Step: 9
Training loss: 2.681372880935669
Validation loss: 2.309280069925452

Epoch: 5| Step: 10
Training loss: 2.487626552581787
Validation loss: 2.297485154162171

Epoch: 187| Step: 0
Training loss: 2.8273062705993652
Validation loss: 2.2897995031008156

Epoch: 5| Step: 1
Training loss: 2.7596282958984375
Validation loss: 2.2871388209763395

Epoch: 5| Step: 2
Training loss: 2.1151890754699707
Validation loss: 2.2899864694123626

Epoch: 5| Step: 3
Training loss: 2.2551605701446533
Validation loss: 2.2905082882091565

Epoch: 5| Step: 4
Training loss: 2.496746063232422
Validation loss: 2.297437262791459

Epoch: 5| Step: 5
Training loss: 2.467463493347168
Validation loss: 2.301193996142316

Epoch: 5| Step: 6
Training loss: 2.6636502742767334
Validation loss: 2.30679323339975

Epoch: 5| Step: 7
Training loss: 2.678349018096924
Validation loss: 2.3053969003820933

Epoch: 5| Step: 8
Training loss: 2.352100372314453
Validation loss: 2.308995052050519

Epoch: 5| Step: 9
Training loss: 2.513622760772705
Validation loss: 2.3168911613443846

Epoch: 5| Step: 10
Training loss: 2.9939017295837402
Validation loss: 2.3250831480949157

Epoch: 188| Step: 0
Training loss: 2.456195116043091
Validation loss: 2.336745233945949

Epoch: 5| Step: 1
Training loss: 2.2611682415008545
Validation loss: 2.339924479043612

Epoch: 5| Step: 2
Training loss: 2.549180507659912
Validation loss: 2.326517730630854

Epoch: 5| Step: 3
Training loss: 2.6855807304382324
Validation loss: 2.319263196760608

Epoch: 5| Step: 4
Training loss: 2.9689197540283203
Validation loss: 2.309873398914132

Epoch: 5| Step: 5
Training loss: 2.3317418098449707
Validation loss: 2.3079562687104747

Epoch: 5| Step: 6
Training loss: 2.9869143962860107
Validation loss: 2.3034161547178864

Epoch: 5| Step: 7
Training loss: 2.8304049968719482
Validation loss: 2.3037544347906627

Epoch: 5| Step: 8
Training loss: 2.7418313026428223
Validation loss: 2.306586642419138

Epoch: 5| Step: 9
Training loss: 1.668911337852478
Validation loss: 2.298619931743991

Epoch: 5| Step: 10
Training loss: 2.5969998836517334
Validation loss: 2.3144433882928666

Epoch: 189| Step: 0
Training loss: 2.3034770488739014
Validation loss: 2.317692554125222

Epoch: 5| Step: 1
Training loss: 2.8793187141418457
Validation loss: 2.319177887773001

Epoch: 5| Step: 2
Training loss: 2.179244041442871
Validation loss: 2.3299222018129084

Epoch: 5| Step: 3
Training loss: 2.879782199859619
Validation loss: 2.3412614176350255

Epoch: 5| Step: 4
Training loss: 2.3481028079986572
Validation loss: 2.351732935956729

Epoch: 5| Step: 5
Training loss: 3.043333053588867
Validation loss: 2.3681470168534147

Epoch: 5| Step: 6
Training loss: 2.651634454727173
Validation loss: 2.379118001589211

Epoch: 5| Step: 7
Training loss: 2.376248598098755
Validation loss: 2.34466750391068

Epoch: 5| Step: 8
Training loss: 2.4054462909698486
Validation loss: 2.3233962853749595

Epoch: 5| Step: 9
Training loss: 2.599717855453491
Validation loss: 2.3201941444027807

Epoch: 5| Step: 10
Training loss: 2.3126559257507324
Validation loss: 2.316078632108627

Epoch: 190| Step: 0
Training loss: 2.771974802017212
Validation loss: 2.308402704936202

Epoch: 5| Step: 1
Training loss: 2.4432005882263184
Validation loss: 2.307708486433952

Epoch: 5| Step: 2
Training loss: 2.853276014328003
Validation loss: 2.30421700785237

Epoch: 5| Step: 3
Training loss: 2.197148084640503
Validation loss: 2.3028760597270024

Epoch: 5| Step: 4
Training loss: 3.2753608226776123
Validation loss: 2.3014005922502085

Epoch: 5| Step: 5
Training loss: 2.779780626296997
Validation loss: 2.304900912828343

Epoch: 5| Step: 6
Training loss: 1.9639739990234375
Validation loss: 2.295788235561822

Epoch: 5| Step: 7
Training loss: 2.134469747543335
Validation loss: 2.289346243745537

Epoch: 5| Step: 8
Training loss: 2.473566770553589
Validation loss: 2.2989835816044963

Epoch: 5| Step: 9
Training loss: 2.772491931915283
Validation loss: 2.316856838041736

Epoch: 5| Step: 10
Training loss: 2.2895619869232178
Validation loss: 2.3378679188348914

Epoch: 191| Step: 0
Training loss: 2.5506386756896973
Validation loss: 2.3423093339448333

Epoch: 5| Step: 1
Training loss: 2.754988193511963
Validation loss: 2.346366064522856

Epoch: 5| Step: 2
Training loss: 2.380492687225342
Validation loss: 2.3523102165550314

Epoch: 5| Step: 3
Training loss: 2.008566379547119
Validation loss: 2.3789906963225333

Epoch: 5| Step: 4
Training loss: 2.744614839553833
Validation loss: 2.378484308078725

Epoch: 5| Step: 5
Training loss: 2.621696949005127
Validation loss: 2.369063590162544

Epoch: 5| Step: 6
Training loss: 2.7257771492004395
Validation loss: 2.367013987674508

Epoch: 5| Step: 7
Training loss: 2.5862042903900146
Validation loss: 2.3539599244312575

Epoch: 5| Step: 8
Training loss: 2.4160399436950684
Validation loss: 2.3391389833983554

Epoch: 5| Step: 9
Training loss: 2.4066169261932373
Validation loss: 2.32498098188831

Epoch: 5| Step: 10
Training loss: 2.8066813945770264
Validation loss: 2.316048747749739

Epoch: 192| Step: 0
Training loss: 3.120755434036255
Validation loss: 2.305970791847475

Epoch: 5| Step: 1
Training loss: 1.8346045017242432
Validation loss: 2.30006439967822

Epoch: 5| Step: 2
Training loss: 2.8728039264678955
Validation loss: 2.2926112426224576

Epoch: 5| Step: 3
Training loss: 2.865100383758545
Validation loss: 2.2910295481322915

Epoch: 5| Step: 4
Training loss: 2.7016749382019043
Validation loss: 2.279595431461129

Epoch: 5| Step: 5
Training loss: 2.2104339599609375
Validation loss: 2.282874779034686

Epoch: 5| Step: 6
Training loss: 3.165043592453003
Validation loss: 2.280300962027683

Epoch: 5| Step: 7
Training loss: 2.5777034759521484
Validation loss: 2.2780077790701263

Epoch: 5| Step: 8
Training loss: 2.702993869781494
Validation loss: 2.2791206298335904

Epoch: 5| Step: 9
Training loss: 2.084068536758423
Validation loss: 2.2851285575538554

Epoch: 5| Step: 10
Training loss: 1.5898278951644897
Validation loss: 2.3013254980887137

Epoch: 193| Step: 0
Training loss: 2.877119541168213
Validation loss: 2.323188917611235

Epoch: 5| Step: 1
Training loss: 3.1153151988983154
Validation loss: 2.3365437958830144

Epoch: 5| Step: 2
Training loss: 2.5964319705963135
Validation loss: 2.3618300294363372

Epoch: 5| Step: 3
Training loss: 2.1934971809387207
Validation loss: 2.3635716002474547

Epoch: 5| Step: 4
Training loss: 2.534291982650757
Validation loss: 2.3622851371765137

Epoch: 5| Step: 5
Training loss: 2.5671842098236084
Validation loss: 2.3525570413117767

Epoch: 5| Step: 6
Training loss: 2.4489986896514893
Validation loss: 2.349728092070549

Epoch: 5| Step: 7
Training loss: 2.152873992919922
Validation loss: 2.3446745462315057

Epoch: 5| Step: 8
Training loss: 2.03427791595459
Validation loss: 2.348892798987768

Epoch: 5| Step: 9
Training loss: 2.7616522312164307
Validation loss: 2.347132423872589

Epoch: 5| Step: 10
Training loss: 2.47324538230896
Validation loss: 2.346858013060785

Epoch: 194| Step: 0
Training loss: 1.662798523902893
Validation loss: 2.342398948566888

Epoch: 5| Step: 1
Training loss: 3.015439510345459
Validation loss: 2.327577316632835

Epoch: 5| Step: 2
Training loss: 1.9131901264190674
Validation loss: 2.329801041592834

Epoch: 5| Step: 3
Training loss: 3.0597317218780518
Validation loss: 2.324981448470905

Epoch: 5| Step: 4
Training loss: 3.3555922508239746
Validation loss: 2.3139909980117634

Epoch: 5| Step: 5
Training loss: 2.546740770339966
Validation loss: 2.3065142118802635

Epoch: 5| Step: 6
Training loss: 2.6092944145202637
Validation loss: 2.30835279598031

Epoch: 5| Step: 7
Training loss: 2.4677963256835938
Validation loss: 2.3059555279311312

Epoch: 5| Step: 8
Training loss: 2.59511137008667
Validation loss: 2.3136819947150444

Epoch: 5| Step: 9
Training loss: 2.713712692260742
Validation loss: 2.315096498817526

Epoch: 5| Step: 10
Training loss: 1.9448702335357666
Validation loss: 2.31889138555014

Epoch: 195| Step: 0
Training loss: 2.253232955932617
Validation loss: 2.3181711396863385

Epoch: 5| Step: 1
Training loss: 1.5545058250427246
Validation loss: 2.3128956748593237

Epoch: 5| Step: 2
Training loss: 2.350412130355835
Validation loss: 2.3185251271852882

Epoch: 5| Step: 3
Training loss: 2.7036454677581787
Validation loss: 2.32536220037809

Epoch: 5| Step: 4
Training loss: 1.820464849472046
Validation loss: 2.327158163952571

Epoch: 5| Step: 5
Training loss: 2.733030080795288
Validation loss: 2.3409772226887364

Epoch: 5| Step: 6
Training loss: 2.9516758918762207
Validation loss: 2.365731280337098

Epoch: 5| Step: 7
Training loss: 3.065757989883423
Validation loss: 2.3511964146808912

Epoch: 5| Step: 8
Training loss: 2.8150534629821777
Validation loss: 2.3497934572158323

Epoch: 5| Step: 9
Training loss: 2.9764456748962402
Validation loss: 2.334384508030389

Epoch: 5| Step: 10
Training loss: 2.629683256149292
Validation loss: 2.324162870325068

Epoch: 196| Step: 0
Training loss: 2.751619815826416
Validation loss: 2.3241292853509226

Epoch: 5| Step: 1
Training loss: 2.488663673400879
Validation loss: 2.326594091230823

Epoch: 5| Step: 2
Training loss: 2.7161967754364014
Validation loss: 2.3408843060975433

Epoch: 5| Step: 3
Training loss: 2.9539284706115723
Validation loss: 2.3576333061341317

Epoch: 5| Step: 4
Training loss: 1.7716058492660522
Validation loss: 2.3297528810398553

Epoch: 5| Step: 5
Training loss: 1.8619096279144287
Validation loss: 2.314831749085457

Epoch: 5| Step: 6
Training loss: 3.163177967071533
Validation loss: 2.31663772367662

Epoch: 5| Step: 7
Training loss: 2.3671658039093018
Validation loss: 2.3141945151872534

Epoch: 5| Step: 8
Training loss: 2.0482234954833984
Validation loss: 2.3303489454330935

Epoch: 5| Step: 9
Training loss: 3.112027406692505
Validation loss: 2.3331687655500186

Epoch: 5| Step: 10
Training loss: 2.5341720581054688
Validation loss: 2.3430038549566783

Epoch: 197| Step: 0
Training loss: 2.640551805496216
Validation loss: 2.3461630472572903

Epoch: 5| Step: 1
Training loss: 2.919607639312744
Validation loss: 2.3418792242644937

Epoch: 5| Step: 2
Training loss: 2.1892120838165283
Validation loss: 2.3215671931543658

Epoch: 5| Step: 3
Training loss: 3.0313267707824707
Validation loss: 2.3047158410472255

Epoch: 5| Step: 4
Training loss: 2.4790327548980713
Validation loss: 2.2904373189454437

Epoch: 5| Step: 5
Training loss: 2.300842046737671
Validation loss: 2.290956481810539

Epoch: 5| Step: 6
Training loss: 2.6170084476470947
Validation loss: 2.2953979917751846

Epoch: 5| Step: 7
Training loss: 1.5514609813690186
Validation loss: 2.3044593282925185

Epoch: 5| Step: 8
Training loss: 2.007660388946533
Validation loss: 2.3151699317398893

Epoch: 5| Step: 9
Training loss: 2.9417214393615723
Validation loss: 2.322777212307017

Epoch: 5| Step: 10
Training loss: 3.16691517829895
Validation loss: 2.33797054008771

Epoch: 198| Step: 0
Training loss: 2.8107759952545166
Validation loss: 2.325512903992848

Epoch: 5| Step: 1
Training loss: 1.7927852869033813
Validation loss: 2.330354672606273

Epoch: 5| Step: 2
Training loss: 2.419757127761841
Validation loss: 2.32239176893747

Epoch: 5| Step: 3
Training loss: 2.046785593032837
Validation loss: 2.3309087086749334

Epoch: 5| Step: 4
Training loss: 2.287724256515503
Validation loss: 2.335227240798294

Epoch: 5| Step: 5
Training loss: 2.194850206375122
Validation loss: 2.3266435771860103

Epoch: 5| Step: 6
Training loss: 2.3393821716308594
Validation loss: 2.321627850173622

Epoch: 5| Step: 7
Training loss: 3.2677760124206543
Validation loss: 2.3160666701614216

Epoch: 5| Step: 8
Training loss: 2.9467315673828125
Validation loss: 2.2959827633314234

Epoch: 5| Step: 9
Training loss: 2.8304920196533203
Validation loss: 2.2875612192256476

Epoch: 5| Step: 10
Training loss: 2.6642911434173584
Validation loss: 2.286298913340415

Epoch: 199| Step: 0
Training loss: 3.0032851696014404
Validation loss: 2.2857823256523377

Epoch: 5| Step: 1
Training loss: 2.255385160446167
Validation loss: 2.2893920072945217

Epoch: 5| Step: 2
Training loss: 2.7961034774780273
Validation loss: 2.2953971688465407

Epoch: 5| Step: 3
Training loss: 2.136746644973755
Validation loss: 2.3026037857096684

Epoch: 5| Step: 4
Training loss: 2.5300943851470947
Validation loss: 2.3195944140034337

Epoch: 5| Step: 5
Training loss: 2.3986384868621826
Validation loss: 2.3294373635322816

Epoch: 5| Step: 6
Training loss: 2.497279405593872
Validation loss: 2.3283582836069088

Epoch: 5| Step: 7
Training loss: 2.3792309761047363
Validation loss: 2.3283231463483585

Epoch: 5| Step: 8
Training loss: 2.192762613296509
Validation loss: 2.332495294591432

Epoch: 5| Step: 9
Training loss: 3.211010456085205
Validation loss: 2.32653610937057

Epoch: 5| Step: 10
Training loss: 2.413684844970703
Validation loss: 2.3240800365324943

Epoch: 200| Step: 0
Training loss: 2.3941445350646973
Validation loss: 2.337236773583197

Epoch: 5| Step: 1
Training loss: 1.862799048423767
Validation loss: 2.3390572968349663

Epoch: 5| Step: 2
Training loss: 2.443070411682129
Validation loss: 2.342790908710931

Epoch: 5| Step: 3
Training loss: 2.1764698028564453
Validation loss: 2.3345634527103876

Epoch: 5| Step: 4
Training loss: 3.279876708984375
Validation loss: 2.317037187596803

Epoch: 5| Step: 5
Training loss: 2.1078591346740723
Validation loss: 2.3256491050925305

Epoch: 5| Step: 6
Training loss: 2.2723817825317383
Validation loss: 2.3043008876103226

Epoch: 5| Step: 7
Training loss: 3.3744988441467285
Validation loss: 2.31391163538861

Epoch: 5| Step: 8
Training loss: 2.8354125022888184
Validation loss: 2.3061386667272097

Epoch: 5| Step: 9
Training loss: 2.5843071937561035
Validation loss: 2.302515214489352

Epoch: 5| Step: 10
Training loss: 2.2623860836029053
Validation loss: 2.3013976825180875

Epoch: 201| Step: 0
Training loss: 2.407092332839966
Validation loss: 2.2954207261403403

Epoch: 5| Step: 1
Training loss: 2.792696714401245
Validation loss: 2.298532703871368

Epoch: 5| Step: 2
Training loss: 2.5591723918914795
Validation loss: 2.2912889654918382

Epoch: 5| Step: 3
Training loss: 2.3631227016448975
Validation loss: 2.2861195661688365

Epoch: 5| Step: 4
Training loss: 2.5248334407806396
Validation loss: 2.2762266102657525

Epoch: 5| Step: 5
Training loss: 2.4031567573547363
Validation loss: 2.2731124790765906

Epoch: 5| Step: 6
Training loss: 3.3061816692352295
Validation loss: 2.2788181920205393

Epoch: 5| Step: 7
Training loss: 2.404710531234741
Validation loss: 2.2791274260449153

Epoch: 5| Step: 8
Training loss: 2.051551342010498
Validation loss: 2.28933620965609

Epoch: 5| Step: 9
Training loss: 2.302661657333374
Validation loss: 2.282411349717007

Epoch: 5| Step: 10
Training loss: 2.3683059215545654
Validation loss: 2.3146971579520934

Epoch: 202| Step: 0
Training loss: 2.5275344848632812
Validation loss: 2.3284336751507175

Epoch: 5| Step: 1
Training loss: 2.9397778511047363
Validation loss: 2.350966538152387

Epoch: 5| Step: 2
Training loss: 2.709216356277466
Validation loss: 2.3455305330214964

Epoch: 5| Step: 3
Training loss: 2.5796432495117188
Validation loss: 2.3399001962395123

Epoch: 5| Step: 4
Training loss: 2.2982258796691895
Validation loss: 2.3365542042639946

Epoch: 5| Step: 5
Training loss: 3.095149040222168
Validation loss: 2.3218988269887944

Epoch: 5| Step: 6
Training loss: 1.6321592330932617
Validation loss: 2.3121510013457267

Epoch: 5| Step: 7
Training loss: 1.9718910455703735
Validation loss: 2.3057103157043457

Epoch: 5| Step: 8
Training loss: 2.246547222137451
Validation loss: 2.3008456281436387

Epoch: 5| Step: 9
Training loss: 2.4211719036102295
Validation loss: 2.3200919294870026

Epoch: 5| Step: 10
Training loss: 3.1330418586730957
Validation loss: 2.315631981818907

Epoch: 203| Step: 0
Training loss: 2.849520206451416
Validation loss: 2.316271763975902

Epoch: 5| Step: 1
Training loss: 2.500286817550659
Validation loss: 2.33086641885901

Epoch: 5| Step: 2
Training loss: 2.0667479038238525
Validation loss: 2.3454055183677265

Epoch: 5| Step: 3
Training loss: 2.18457293510437
Validation loss: 2.3386169710466937

Epoch: 5| Step: 4
Training loss: 2.7794036865234375
Validation loss: 2.3582268889232347

Epoch: 5| Step: 5
Training loss: 2.710907459259033
Validation loss: 2.3579672267360072

Epoch: 5| Step: 6
Training loss: 2.117074966430664
Validation loss: 2.3709849208913822

Epoch: 5| Step: 7
Training loss: 3.0759122371673584
Validation loss: 2.380136259140507

Epoch: 5| Step: 8
Training loss: 2.102715253829956
Validation loss: 2.3961421443570043

Epoch: 5| Step: 9
Training loss: 2.9636828899383545
Validation loss: 2.3783355861581783

Epoch: 5| Step: 10
Training loss: 2.525052070617676
Validation loss: 2.3785571411091793

Epoch: 204| Step: 0
Training loss: 3.030104398727417
Validation loss: 2.357671196742724

Epoch: 5| Step: 1
Training loss: 2.8741867542266846
Validation loss: 2.3467206724228395

Epoch: 5| Step: 2
Training loss: 2.172322988510132
Validation loss: 2.338405703985563

Epoch: 5| Step: 3
Training loss: 1.9054861068725586
Validation loss: 2.3319949667940856

Epoch: 5| Step: 4
Training loss: 2.5721850395202637
Validation loss: 2.342771171241678

Epoch: 5| Step: 5
Training loss: 2.9838318824768066
Validation loss: 2.3649450796906666

Epoch: 5| Step: 6
Training loss: 2.772721290588379
Validation loss: 2.3818299206354285

Epoch: 5| Step: 7
Training loss: 2.067155361175537
Validation loss: 2.3646012044722036

Epoch: 5| Step: 8
Training loss: 2.374272108078003
Validation loss: 2.3483773059742425

Epoch: 5| Step: 9
Training loss: 2.4445791244506836
Validation loss: 2.335488821870537

Epoch: 5| Step: 10
Training loss: 2.849281072616577
Validation loss: 2.348186436519828

Epoch: 205| Step: 0
Training loss: 2.206779956817627
Validation loss: 2.3317997378687703

Epoch: 5| Step: 1
Training loss: 2.6402602195739746
Validation loss: 2.3488490235420967

Epoch: 5| Step: 2
Training loss: 2.756432056427002
Validation loss: 2.3388615218541955

Epoch: 5| Step: 3
Training loss: 2.8456687927246094
Validation loss: 2.330568580217259

Epoch: 5| Step: 4
Training loss: 2.4661407470703125
Validation loss: 2.3341166934659405

Epoch: 5| Step: 5
Training loss: 2.3064446449279785
Validation loss: 2.3266604485050326

Epoch: 5| Step: 6
Training loss: 1.940359115600586
Validation loss: 2.3524207094664216

Epoch: 5| Step: 7
Training loss: 2.735260486602783
Validation loss: 2.379121408667616

Epoch: 5| Step: 8
Training loss: 2.9912121295928955
Validation loss: 2.377529767251784

Epoch: 5| Step: 9
Training loss: 2.8385403156280518
Validation loss: 2.3687019681417816

Epoch: 5| Step: 10
Training loss: 2.0555827617645264
Validation loss: 2.3468250920695644

Epoch: 206| Step: 0
Training loss: 2.3571300506591797
Validation loss: 2.3242046089582544

Epoch: 5| Step: 1
Training loss: 2.7804903984069824
Validation loss: 2.3116417379789453

Epoch: 5| Step: 2
Training loss: 3.007481098175049
Validation loss: 2.320217494041689

Epoch: 5| Step: 3
Training loss: 1.99225652217865
Validation loss: 2.303952793921194

Epoch: 5| Step: 4
Training loss: 3.0389599800109863
Validation loss: 2.28503736629281

Epoch: 5| Step: 5
Training loss: 2.2559821605682373
Validation loss: 2.2563341715002574

Epoch: 5| Step: 6
Training loss: 2.4984233379364014
Validation loss: 2.2490103860055246

Epoch: 5| Step: 7
Training loss: 2.704160213470459
Validation loss: 2.2612978437895417

Epoch: 5| Step: 8
Training loss: 2.4136135578155518
Validation loss: 2.3027315857589885

Epoch: 5| Step: 9
Training loss: 2.688464403152466
Validation loss: 2.32318684106232

Epoch: 5| Step: 10
Training loss: 1.9564191102981567
Validation loss: 2.346482305116551

Epoch: 207| Step: 0
Training loss: 3.3246543407440186
Validation loss: 2.3517652891015493

Epoch: 5| Step: 1
Training loss: 3.0151138305664062
Validation loss: 2.347155688911356

Epoch: 5| Step: 2
Training loss: 2.4912383556365967
Validation loss: 2.3295382427912887

Epoch: 5| Step: 3
Training loss: 1.9064817428588867
Validation loss: 2.292929836498794

Epoch: 5| Step: 4
Training loss: 1.4509620666503906
Validation loss: 2.2722241545236237

Epoch: 5| Step: 5
Training loss: 2.2896649837493896
Validation loss: 2.2735454933617705

Epoch: 5| Step: 6
Training loss: 2.4665229320526123
Validation loss: 2.2637091990440124

Epoch: 5| Step: 7
Training loss: 2.977513551712036
Validation loss: 2.2613728495054346

Epoch: 5| Step: 8
Training loss: 2.393378496170044
Validation loss: 2.2700127119659097

Epoch: 5| Step: 9
Training loss: 2.873725652694702
Validation loss: 2.260711787849344

Epoch: 5| Step: 10
Training loss: 2.528083086013794
Validation loss: 2.290301440864481

Epoch: 208| Step: 0
Training loss: 2.5870985984802246
Validation loss: 2.2832240237984607

Epoch: 5| Step: 1
Training loss: 2.8003485202789307
Validation loss: 2.3037677503401235

Epoch: 5| Step: 2
Training loss: 2.555199146270752
Validation loss: 2.308479344973

Epoch: 5| Step: 3
Training loss: 2.0004751682281494
Validation loss: 2.322653393591604

Epoch: 5| Step: 4
Training loss: 2.1829094886779785
Validation loss: 2.333339182279443

Epoch: 5| Step: 5
Training loss: 3.0670104026794434
Validation loss: 2.3446294492290867

Epoch: 5| Step: 6
Training loss: 1.9109874963760376
Validation loss: 2.326299049521005

Epoch: 5| Step: 7
Training loss: 2.758608818054199
Validation loss: 2.312693544613418

Epoch: 5| Step: 8
Training loss: 2.3804900646209717
Validation loss: 2.3065316318183817

Epoch: 5| Step: 9
Training loss: 2.580002784729004
Validation loss: 2.2997691990226827

Epoch: 5| Step: 10
Training loss: 2.578504800796509
Validation loss: 2.2823624328900407

Epoch: 209| Step: 0
Training loss: 3.2402405738830566
Validation loss: 2.287115066282211

Epoch: 5| Step: 1
Training loss: 3.1323344707489014
Validation loss: 2.263195401878767

Epoch: 5| Step: 2
Training loss: 2.0585196018218994
Validation loss: 2.2631486744009037

Epoch: 5| Step: 3
Training loss: 2.0932652950286865
Validation loss: 2.2510246615256033

Epoch: 5| Step: 4
Training loss: 2.1917660236358643
Validation loss: 2.267084406268212

Epoch: 5| Step: 5
Training loss: 2.2805256843566895
Validation loss: 2.2650248773636354

Epoch: 5| Step: 6
Training loss: 2.606374740600586
Validation loss: 2.280677928719469

Epoch: 5| Step: 7
Training loss: 2.10300612449646
Validation loss: 2.2933476945405364

Epoch: 5| Step: 8
Training loss: 2.5439975261688232
Validation loss: 2.2921790794659684

Epoch: 5| Step: 9
Training loss: 2.57869029045105
Validation loss: 2.307714557134977

Epoch: 5| Step: 10
Training loss: 2.5740091800689697
Validation loss: 2.319704709514495

Epoch: 210| Step: 0
Training loss: 2.3912792205810547
Validation loss: 2.317199114830263

Epoch: 5| Step: 1
Training loss: 2.202972412109375
Validation loss: 2.309853369189847

Epoch: 5| Step: 2
Training loss: 2.595266342163086
Validation loss: 2.3362392123027513

Epoch: 5| Step: 3
Training loss: 2.532411813735962
Validation loss: 2.3565793819324945

Epoch: 5| Step: 4
Training loss: 2.929856538772583
Validation loss: 2.353194006027714

Epoch: 5| Step: 5
Training loss: 2.25030517578125
Validation loss: 2.35353870032936

Epoch: 5| Step: 6
Training loss: 2.165172576904297
Validation loss: 2.3283901842691566

Epoch: 5| Step: 7
Training loss: 2.6224255561828613
Validation loss: 2.3061111139994797

Epoch: 5| Step: 8
Training loss: 2.2050507068634033
Validation loss: 2.2929180565700737

Epoch: 5| Step: 9
Training loss: 2.694920778274536
Validation loss: 2.2631530274627027

Epoch: 5| Step: 10
Training loss: 2.852773666381836
Validation loss: 2.255360145722666

Epoch: 211| Step: 0
Training loss: 2.730170249938965
Validation loss: 2.243784099496821

Epoch: 5| Step: 1
Training loss: 2.6358392238616943
Validation loss: 2.2497970493890906

Epoch: 5| Step: 2
Training loss: 2.4761881828308105
Validation loss: 2.2498189697983446

Epoch: 5| Step: 3
Training loss: 2.7563583850860596
Validation loss: 2.268786689286591

Epoch: 5| Step: 4
Training loss: 1.8393504619598389
Validation loss: 2.274119446354528

Epoch: 5| Step: 5
Training loss: 2.179180860519409
Validation loss: 2.2691801927422963

Epoch: 5| Step: 6
Training loss: 1.9959198236465454
Validation loss: 2.267795452507593

Epoch: 5| Step: 7
Training loss: 2.9352164268493652
Validation loss: 2.2692742501535723

Epoch: 5| Step: 8
Training loss: 2.749617576599121
Validation loss: 2.262897119727186

Epoch: 5| Step: 9
Training loss: 2.0678184032440186
Validation loss: 2.2487330282888105

Epoch: 5| Step: 10
Training loss: 3.0960559844970703
Validation loss: 2.2538269309587378

Epoch: 212| Step: 0
Training loss: 2.712035894393921
Validation loss: 2.258439020443988

Epoch: 5| Step: 1
Training loss: 3.011063814163208
Validation loss: 2.251280928170809

Epoch: 5| Step: 2
Training loss: 2.542280673980713
Validation loss: 2.25561007120276

Epoch: 5| Step: 3
Training loss: 2.279872417449951
Validation loss: 2.252121974063176

Epoch: 5| Step: 4
Training loss: 2.0688350200653076
Validation loss: 2.2612801623600784

Epoch: 5| Step: 5
Training loss: 3.0247421264648438
Validation loss: 2.2766081838197607

Epoch: 5| Step: 6
Training loss: 1.7158100605010986
Validation loss: 2.284874446930424

Epoch: 5| Step: 7
Training loss: 2.960444927215576
Validation loss: 2.2872734492824924

Epoch: 5| Step: 8
Training loss: 2.2451794147491455
Validation loss: 2.2821081299935617

Epoch: 5| Step: 9
Training loss: 2.4267468452453613
Validation loss: 2.301466126595774

Epoch: 5| Step: 10
Training loss: 2.398883581161499
Validation loss: 2.343134876220457

Epoch: 213| Step: 0
Training loss: 2.463005542755127
Validation loss: 2.3900737454814296

Epoch: 5| Step: 1
Training loss: 2.6767730712890625
Validation loss: 2.468445688165644

Epoch: 5| Step: 2
Training loss: 2.214517593383789
Validation loss: 2.5172541526056107

Epoch: 5| Step: 3
Training loss: 2.417238712310791
Validation loss: 2.5449606244282057

Epoch: 5| Step: 4
Training loss: 3.446885585784912
Validation loss: 2.5076861868622484

Epoch: 5| Step: 5
Training loss: 2.446485757827759
Validation loss: 2.4195845742379465

Epoch: 5| Step: 6
Training loss: 2.7454426288604736
Validation loss: 2.37382907764886

Epoch: 5| Step: 7
Training loss: 3.0302443504333496
Validation loss: 2.34480744536205

Epoch: 5| Step: 8
Training loss: 1.7699508666992188
Validation loss: 2.337017395163095

Epoch: 5| Step: 9
Training loss: 2.320199728012085
Validation loss: 2.3061636929870932

Epoch: 5| Step: 10
Training loss: 2.2292428016662598
Validation loss: 2.292402687893119

Epoch: 214| Step: 0
Training loss: 3.3315863609313965
Validation loss: 2.2859550060764438

Epoch: 5| Step: 1
Training loss: 3.2814249992370605
Validation loss: 2.269090070519396

Epoch: 5| Step: 2
Training loss: 2.2919535636901855
Validation loss: 2.2572517061746247

Epoch: 5| Step: 3
Training loss: 2.46008038520813
Validation loss: 2.242180460242815

Epoch: 5| Step: 4
Training loss: 2.252852201461792
Validation loss: 2.246189166140813

Epoch: 5| Step: 5
Training loss: 2.5308635234832764
Validation loss: 2.251941724490094

Epoch: 5| Step: 6
Training loss: 2.4279088973999023
Validation loss: 2.254019803898309

Epoch: 5| Step: 7
Training loss: 2.4398388862609863
Validation loss: 2.2620757818222046

Epoch: 5| Step: 8
Training loss: 1.7001888751983643
Validation loss: 2.2617058459148613

Epoch: 5| Step: 9
Training loss: 2.5885424613952637
Validation loss: 2.265803260187949

Epoch: 5| Step: 10
Training loss: 2.155961275100708
Validation loss: 2.2619028142703477

Epoch: 215| Step: 0
Training loss: 2.6254496574401855
Validation loss: 2.272403842659407

Epoch: 5| Step: 1
Training loss: 2.979464054107666
Validation loss: 2.2768221619308635

Epoch: 5| Step: 2
Training loss: 2.813209056854248
Validation loss: 2.276140643704322

Epoch: 5| Step: 3
Training loss: 2.371878147125244
Validation loss: 2.2797122745103735

Epoch: 5| Step: 4
Training loss: 2.054727554321289
Validation loss: 2.2762397617422123

Epoch: 5| Step: 5
Training loss: 2.864314556121826
Validation loss: 2.2830599456705074

Epoch: 5| Step: 6
Training loss: 1.8676462173461914
Validation loss: 2.3035425498921382

Epoch: 5| Step: 7
Training loss: 2.6057143211364746
Validation loss: 2.3258597389344247

Epoch: 5| Step: 8
Training loss: 2.8216254711151123
Validation loss: 2.3190870977217153

Epoch: 5| Step: 9
Training loss: 1.9403963088989258
Validation loss: 2.3133876580064014

Epoch: 5| Step: 10
Training loss: 2.430551290512085
Validation loss: 2.308087282283332

Epoch: 216| Step: 0
Training loss: 1.8652238845825195
Validation loss: 2.2996676403989076

Epoch: 5| Step: 1
Training loss: 2.7186853885650635
Validation loss: 2.289404317896853

Epoch: 5| Step: 2
Training loss: 2.7578201293945312
Validation loss: 2.263093122871973

Epoch: 5| Step: 3
Training loss: 2.564098834991455
Validation loss: 2.245798605744557

Epoch: 5| Step: 4
Training loss: 2.3381447792053223
Validation loss: 2.2306077300861316

Epoch: 5| Step: 5
Training loss: 2.02091646194458
Validation loss: 2.2377274215862317

Epoch: 5| Step: 6
Training loss: 2.4906673431396484
Validation loss: 2.2589447549594346

Epoch: 5| Step: 7
Training loss: 3.069459915161133
Validation loss: 2.2607489298748713

Epoch: 5| Step: 8
Training loss: 2.8902642726898193
Validation loss: 2.263728375075966

Epoch: 5| Step: 9
Training loss: 2.2207281589508057
Validation loss: 2.261180741812593

Epoch: 5| Step: 10
Training loss: 2.499094009399414
Validation loss: 2.249871994859429

Epoch: 217| Step: 0
Training loss: 3.0152838230133057
Validation loss: 2.2487480384047314

Epoch: 5| Step: 1
Training loss: 3.3275363445281982
Validation loss: 2.24732268241144

Epoch: 5| Step: 2
Training loss: 2.3535962104797363
Validation loss: 2.244206761801115

Epoch: 5| Step: 3
Training loss: 2.4121623039245605
Validation loss: 2.2433094273331347

Epoch: 5| Step: 4
Training loss: 1.6726728677749634
Validation loss: 2.2580099516017462

Epoch: 5| Step: 5
Training loss: 2.0497002601623535
Validation loss: 2.2699686916925574

Epoch: 5| Step: 6
Training loss: 2.5838005542755127
Validation loss: 2.2800026580851567

Epoch: 5| Step: 7
Training loss: 3.073366165161133
Validation loss: 2.2886761414107455

Epoch: 5| Step: 8
Training loss: 2.1410365104675293
Validation loss: 2.3004623074685373

Epoch: 5| Step: 9
Training loss: 2.45355224609375
Validation loss: 2.29830841864309

Epoch: 5| Step: 10
Training loss: 1.986358642578125
Validation loss: 2.2898323048827467

Epoch: 218| Step: 0
Training loss: 2.672456979751587
Validation loss: 2.28564215090967

Epoch: 5| Step: 1
Training loss: 1.988313913345337
Validation loss: 2.293942159222018

Epoch: 5| Step: 2
Training loss: 2.297607421875
Validation loss: 2.314673945467959

Epoch: 5| Step: 3
Training loss: 2.1939826011657715
Validation loss: 2.327040136501353

Epoch: 5| Step: 4
Training loss: 2.470309019088745
Validation loss: 2.3211257739733626

Epoch: 5| Step: 5
Training loss: 2.581174373626709
Validation loss: 2.302212658748832

Epoch: 5| Step: 6
Training loss: 2.226541519165039
Validation loss: 2.2791567182028167

Epoch: 5| Step: 7
Training loss: 2.882652759552002
Validation loss: 2.2754821059524373

Epoch: 5| Step: 8
Training loss: 2.2345776557922363
Validation loss: 2.2688050680263068

Epoch: 5| Step: 9
Training loss: 2.736290693283081
Validation loss: 2.2844713913497103

Epoch: 5| Step: 10
Training loss: 2.8641512393951416
Validation loss: 2.259945002935266

Epoch: 219| Step: 0
Training loss: 2.7765369415283203
Validation loss: 2.258909007554413

Epoch: 5| Step: 1
Training loss: 2.1603031158447266
Validation loss: 2.2613809647098666

Epoch: 5| Step: 2
Training loss: 2.2588934898376465
Validation loss: 2.256250094341975

Epoch: 5| Step: 3
Training loss: 2.2841436862945557
Validation loss: 2.260918471121019

Epoch: 5| Step: 4
Training loss: 2.1796867847442627
Validation loss: 2.2688293328849216

Epoch: 5| Step: 5
Training loss: 2.3249080181121826
Validation loss: 2.274532118151265

Epoch: 5| Step: 6
Training loss: 3.028327226638794
Validation loss: 2.2716152911545127

Epoch: 5| Step: 7
Training loss: 2.3395819664001465
Validation loss: 2.2625209849367858

Epoch: 5| Step: 8
Training loss: 2.919215679168701
Validation loss: 2.283526675675505

Epoch: 5| Step: 9
Training loss: 2.1472487449645996
Validation loss: 2.2928888054304224

Epoch: 5| Step: 10
Training loss: 2.408062219619751
Validation loss: 2.2981480257485503

Epoch: 220| Step: 0
Training loss: 2.549403667449951
Validation loss: 2.2903845246120165

Epoch: 5| Step: 1
Training loss: 2.1373705863952637
Validation loss: 2.293374587130803

Epoch: 5| Step: 2
Training loss: 2.8531441688537598
Validation loss: 2.2931805361983595

Epoch: 5| Step: 3
Training loss: 1.905514121055603
Validation loss: 2.282178214801255

Epoch: 5| Step: 4
Training loss: 2.001004934310913
Validation loss: 2.2653503084695465

Epoch: 5| Step: 5
Training loss: 3.326279401779175
Validation loss: 2.2603776198561474

Epoch: 5| Step: 6
Training loss: 2.4342732429504395
Validation loss: 2.246123747159076

Epoch: 5| Step: 7
Training loss: 2.2613282203674316
Validation loss: 2.2467117001933437

Epoch: 5| Step: 8
Training loss: 2.643203020095825
Validation loss: 2.2461125799404678

Epoch: 5| Step: 9
Training loss: 2.4066638946533203
Validation loss: 2.258880261451967

Epoch: 5| Step: 10
Training loss: 2.2127845287323
Validation loss: 2.262628742443618

Epoch: 221| Step: 0
Training loss: 2.642970323562622
Validation loss: 2.281429603535642

Epoch: 5| Step: 1
Training loss: 2.3763949871063232
Validation loss: 2.2946262205800703

Epoch: 5| Step: 2
Training loss: 2.2203733921051025
Validation loss: 2.304748078828217

Epoch: 5| Step: 3
Training loss: 2.8278396129608154
Validation loss: 2.305334655187463

Epoch: 5| Step: 4
Training loss: 2.5820815563201904
Validation loss: 2.3152166387086273

Epoch: 5| Step: 5
Training loss: 2.9115612506866455
Validation loss: 2.3032624336981002

Epoch: 5| Step: 6
Training loss: 2.099795341491699
Validation loss: 2.310472492248781

Epoch: 5| Step: 7
Training loss: 2.1769492626190186
Validation loss: 2.318826312659889

Epoch: 5| Step: 8
Training loss: 2.1687569618225098
Validation loss: 2.303557188280167

Epoch: 5| Step: 9
Training loss: 2.610788345336914
Validation loss: 2.2996698553844164

Epoch: 5| Step: 10
Training loss: 2.259521484375
Validation loss: 2.292788900354857

Epoch: 222| Step: 0
Training loss: 2.6585192680358887
Validation loss: 2.2844640080646803

Epoch: 5| Step: 1
Training loss: 3.083920955657959
Validation loss: 2.277200054096919

Epoch: 5| Step: 2
Training loss: 2.2785775661468506
Validation loss: 2.2676386333280996

Epoch: 5| Step: 3
Training loss: 2.0970563888549805
Validation loss: 2.27014131956203

Epoch: 5| Step: 4
Training loss: 2.568589925765991
Validation loss: 2.262123559110908

Epoch: 5| Step: 5
Training loss: 2.3274807929992676
Validation loss: 2.256509106646302

Epoch: 5| Step: 6
Training loss: 2.4764294624328613
Validation loss: 2.2569127954462522

Epoch: 5| Step: 7
Training loss: 2.1778762340545654
Validation loss: 2.2454224145540627

Epoch: 5| Step: 8
Training loss: 2.2255606651306152
Validation loss: 2.2635754923666678

Epoch: 5| Step: 9
Training loss: 2.579077959060669
Validation loss: 2.2551586345959733

Epoch: 5| Step: 10
Training loss: 2.202357053756714
Validation loss: 2.2792552491670013

Epoch: 223| Step: 0
Training loss: 2.5402073860168457
Validation loss: 2.270191707918721

Epoch: 5| Step: 1
Training loss: 2.5912506580352783
Validation loss: 2.2766589964589765

Epoch: 5| Step: 2
Training loss: 2.1614537239074707
Validation loss: 2.2815833143008653

Epoch: 5| Step: 3
Training loss: 2.9654440879821777
Validation loss: 2.2863002797608734

Epoch: 5| Step: 4
Training loss: 2.1892738342285156
Validation loss: 2.263443716110722

Epoch: 5| Step: 5
Training loss: 2.3224148750305176
Validation loss: 2.2650805955292075

Epoch: 5| Step: 6
Training loss: 2.5499038696289062
Validation loss: 2.259920163821149

Epoch: 5| Step: 7
Training loss: 2.121030330657959
Validation loss: 2.2425586305638796

Epoch: 5| Step: 8
Training loss: 2.516378402709961
Validation loss: 2.2364793618520102

Epoch: 5| Step: 9
Training loss: 2.3865599632263184
Validation loss: 2.240410876530473

Epoch: 5| Step: 10
Training loss: 2.322446584701538
Validation loss: 2.25897975121775

Epoch: 224| Step: 0
Training loss: 2.1288371086120605
Validation loss: 2.286582480194748

Epoch: 5| Step: 1
Training loss: 2.279555320739746
Validation loss: 2.313058002020723

Epoch: 5| Step: 2
Training loss: 2.3174710273742676
Validation loss: 2.3310604018549763

Epoch: 5| Step: 3
Training loss: 3.049431324005127
Validation loss: 2.34413137999914

Epoch: 5| Step: 4
Training loss: 1.8522329330444336
Validation loss: 2.330724254731209

Epoch: 5| Step: 5
Training loss: 1.6002708673477173
Validation loss: 2.3205890693972187

Epoch: 5| Step: 6
Training loss: 2.7540194988250732
Validation loss: 2.3272211808030323

Epoch: 5| Step: 7
Training loss: 3.17615008354187
Validation loss: 2.341770971975019

Epoch: 5| Step: 8
Training loss: 2.642040252685547
Validation loss: 2.3255305802950295

Epoch: 5| Step: 9
Training loss: 2.67631196975708
Validation loss: 2.311993578428863

Epoch: 5| Step: 10
Training loss: 2.1523289680480957
Validation loss: 2.2848654203517462

Epoch: 225| Step: 0
Training loss: 2.1544125080108643
Validation loss: 2.2569063632718978

Epoch: 5| Step: 1
Training loss: 2.5443994998931885
Validation loss: 2.2465122361336984

Epoch: 5| Step: 2
Training loss: 2.686305284500122
Validation loss: 2.2345707647262083

Epoch: 5| Step: 3
Training loss: 2.1918599605560303
Validation loss: 2.233267666191183

Epoch: 5| Step: 4
Training loss: 2.4220426082611084
Validation loss: 2.256792099245133

Epoch: 5| Step: 5
Training loss: 2.9047374725341797
Validation loss: 2.2875937210616244

Epoch: 5| Step: 6
Training loss: 2.410942554473877
Validation loss: 2.2938771068408923

Epoch: 5| Step: 7
Training loss: 1.9505054950714111
Validation loss: 2.301308754951723

Epoch: 5| Step: 8
Training loss: 2.977163076400757
Validation loss: 2.307321999662666

Epoch: 5| Step: 9
Training loss: 2.2205958366394043
Validation loss: 2.303982045060845

Epoch: 5| Step: 10
Training loss: 2.3221511840820312
Validation loss: 2.272747139776907

Epoch: 226| Step: 0
Training loss: 2.833712100982666
Validation loss: 2.255550842131338

Epoch: 5| Step: 1
Training loss: 1.7766920328140259
Validation loss: 2.2467930983471613

Epoch: 5| Step: 2
Training loss: 2.684981346130371
Validation loss: 2.2585702660263225

Epoch: 5| Step: 3
Training loss: 2.1547741889953613
Validation loss: 2.289792835071523

Epoch: 5| Step: 4
Training loss: 3.028930187225342
Validation loss: 2.3275479873021445

Epoch: 5| Step: 5
Training loss: 2.436746835708618
Validation loss: 2.353270020536197

Epoch: 5| Step: 6
Training loss: 2.9136855602264404
Validation loss: 2.3723614472214893

Epoch: 5| Step: 7
Training loss: 2.10060453414917
Validation loss: 2.3300045856865506

Epoch: 5| Step: 8
Training loss: 2.732367992401123
Validation loss: 2.3039033028387252

Epoch: 5| Step: 9
Training loss: 2.0244498252868652
Validation loss: 2.2858843777769353

Epoch: 5| Step: 10
Training loss: 2.125638008117676
Validation loss: 2.275961963079309

Epoch: 227| Step: 0
Training loss: 2.415494203567505
Validation loss: 2.308282297144654

Epoch: 5| Step: 1
Training loss: 2.6369452476501465
Validation loss: 2.319233250874345

Epoch: 5| Step: 2
Training loss: 2.605856418609619
Validation loss: 2.3443679373751403

Epoch: 5| Step: 3
Training loss: 2.414307117462158
Validation loss: 2.3366425165566067

Epoch: 5| Step: 4
Training loss: 2.194624423980713
Validation loss: 2.32534538033188

Epoch: 5| Step: 5
Training loss: 2.2589428424835205
Validation loss: 2.3161959135404198

Epoch: 5| Step: 6
Training loss: 1.8765983581542969
Validation loss: 2.29549341817056

Epoch: 5| Step: 7
Training loss: 3.1173489093780518
Validation loss: 2.2842373283960486

Epoch: 5| Step: 8
Training loss: 2.1717922687530518
Validation loss: 2.301947621889012

Epoch: 5| Step: 9
Training loss: 2.3279659748077393
Validation loss: 2.2958410632225776

Epoch: 5| Step: 10
Training loss: 2.5678322315216064
Validation loss: 2.262524958579771

Epoch: 228| Step: 0
Training loss: 2.886927604675293
Validation loss: 2.2461105469734437

Epoch: 5| Step: 1
Training loss: 2.3739442825317383
Validation loss: 2.2361888693225

Epoch: 5| Step: 2
Training loss: 2.297919750213623
Validation loss: 2.2269372452971754

Epoch: 5| Step: 3
Training loss: 2.9286792278289795
Validation loss: 2.2326025988466

Epoch: 5| Step: 4
Training loss: 2.4475643634796143
Validation loss: 2.2332710924968926

Epoch: 5| Step: 5
Training loss: 2.1165900230407715
Validation loss: 2.2460517985846407

Epoch: 5| Step: 6
Training loss: 1.5989898443222046
Validation loss: 2.247519467466621

Epoch: 5| Step: 7
Training loss: 2.9532551765441895
Validation loss: 2.2466042836507163

Epoch: 5| Step: 8
Training loss: 2.403350353240967
Validation loss: 2.2531757252190703

Epoch: 5| Step: 9
Training loss: 2.611079454421997
Validation loss: 2.268443763896983

Epoch: 5| Step: 10
Training loss: 1.9819163084030151
Validation loss: 2.2749687881879908

Epoch: 229| Step: 0
Training loss: 2.3511242866516113
Validation loss: 2.2692439312575967

Epoch: 5| Step: 1
Training loss: 2.801551103591919
Validation loss: 2.26306241045716

Epoch: 5| Step: 2
Training loss: 2.3597781658172607
Validation loss: 2.260348682762474

Epoch: 5| Step: 3
Training loss: 2.4239025115966797
Validation loss: 2.2719076051506946

Epoch: 5| Step: 4
Training loss: 3.1220781803131104
Validation loss: 2.257592829324866

Epoch: 5| Step: 5
Training loss: 2.1742186546325684
Validation loss: 2.2515452728476575

Epoch: 5| Step: 6
Training loss: 2.377351760864258
Validation loss: 2.250940938149729

Epoch: 5| Step: 7
Training loss: 2.0284018516540527
Validation loss: 2.2573282462294384

Epoch: 5| Step: 8
Training loss: 2.811190605163574
Validation loss: 2.2692296915156867

Epoch: 5| Step: 9
Training loss: 1.9463717937469482
Validation loss: 2.275672884397609

Epoch: 5| Step: 10
Training loss: 1.911975383758545
Validation loss: 2.278727731397075

Epoch: 230| Step: 0
Training loss: 2.519178867340088
Validation loss: 2.277295897083898

Epoch: 5| Step: 1
Training loss: 2.397547483444214
Validation loss: 2.3057796211652857

Epoch: 5| Step: 2
Training loss: 2.6321606636047363
Validation loss: 2.2900972725242696

Epoch: 5| Step: 3
Training loss: 2.2074341773986816
Validation loss: 2.2704447187403196

Epoch: 5| Step: 4
Training loss: 2.419300079345703
Validation loss: 2.2473115280110347

Epoch: 5| Step: 5
Training loss: 2.1688742637634277
Validation loss: 2.234334394495974

Epoch: 5| Step: 6
Training loss: 3.0035641193389893
Validation loss: 2.2415104348172425

Epoch: 5| Step: 7
Training loss: 2.2142653465270996
Validation loss: 2.235021182285842

Epoch: 5| Step: 8
Training loss: 1.9152679443359375
Validation loss: 2.235236032034761

Epoch: 5| Step: 9
Training loss: 2.2336363792419434
Validation loss: 2.242232907202936

Epoch: 5| Step: 10
Training loss: 2.5890936851501465
Validation loss: 2.2538920884491294

Epoch: 231| Step: 0
Training loss: 1.9301378726959229
Validation loss: 2.2468377108215005

Epoch: 5| Step: 1
Training loss: 2.0440306663513184
Validation loss: 2.247057226396376

Epoch: 5| Step: 2
Training loss: 2.812497138977051
Validation loss: 2.260685384914439

Epoch: 5| Step: 3
Training loss: 2.4470200538635254
Validation loss: 2.253777460385394

Epoch: 5| Step: 4
Training loss: 2.8320846557617188
Validation loss: 2.2500714409735894

Epoch: 5| Step: 5
Training loss: 2.2984025478363037
Validation loss: 2.255662682235882

Epoch: 5| Step: 6
Training loss: 2.4518795013427734
Validation loss: 2.2459773248241794

Epoch: 5| Step: 7
Training loss: 2.4284167289733887
Validation loss: 2.2646653113826627

Epoch: 5| Step: 8
Training loss: 2.254544973373413
Validation loss: 2.2867879406098397

Epoch: 5| Step: 9
Training loss: 2.2779250144958496
Validation loss: 2.284935633341471

Epoch: 5| Step: 10
Training loss: 2.3403170108795166
Validation loss: 2.2627360743861042

Epoch: 232| Step: 0
Training loss: 2.5037739276885986
Validation loss: 2.250530755648049

Epoch: 5| Step: 1
Training loss: 2.354641914367676
Validation loss: 2.2543519081607943

Epoch: 5| Step: 2
Training loss: 2.089266538619995
Validation loss: 2.2494350915314048

Epoch: 5| Step: 3
Training loss: 2.731227159500122
Validation loss: 2.2663604264618247

Epoch: 5| Step: 4
Training loss: 2.379683017730713
Validation loss: 2.2795353781792427

Epoch: 5| Step: 5
Training loss: 2.110382080078125
Validation loss: 2.262513563197146

Epoch: 5| Step: 6
Training loss: 2.302168369293213
Validation loss: 2.2573041633893083

Epoch: 5| Step: 7
Training loss: 3.1735053062438965
Validation loss: 2.2280063321513515

Epoch: 5| Step: 8
Training loss: 1.8904415369033813
Validation loss: 2.2264536144912883

Epoch: 5| Step: 9
Training loss: 2.4803199768066406
Validation loss: 2.2285016454676145

Epoch: 5| Step: 10
Training loss: 2.1829662322998047
Validation loss: 2.2469957772121636

Epoch: 233| Step: 0
Training loss: 2.1431946754455566
Validation loss: 2.2472048267241447

Epoch: 5| Step: 1
Training loss: 2.830404758453369
Validation loss: 2.2511350339458835

Epoch: 5| Step: 2
Training loss: 2.4954774379730225
Validation loss: 2.240115607938459

Epoch: 5| Step: 3
Training loss: 2.312995433807373
Validation loss: 2.2474037524192565

Epoch: 5| Step: 4
Training loss: 2.393294095993042
Validation loss: 2.250447598836755

Epoch: 5| Step: 5
Training loss: 2.6116747856140137
Validation loss: 2.2711222556329544

Epoch: 5| Step: 6
Training loss: 1.876635193824768
Validation loss: 2.2855828051925986

Epoch: 5| Step: 7
Training loss: 2.4058837890625
Validation loss: 2.3195203170981458

Epoch: 5| Step: 8
Training loss: 2.697067975997925
Validation loss: 2.309691643202177

Epoch: 5| Step: 9
Training loss: 2.2902307510375977
Validation loss: 2.2724052347162718

Epoch: 5| Step: 10
Training loss: 1.9890490770339966
Validation loss: 2.237615680181852

Epoch: 234| Step: 0
Training loss: 2.2977447509765625
Validation loss: 2.228212797513572

Epoch: 5| Step: 1
Training loss: 1.6287200450897217
Validation loss: 2.2182423376267955

Epoch: 5| Step: 2
Training loss: 2.0002455711364746
Validation loss: 2.234441893075102

Epoch: 5| Step: 3
Training loss: 2.3647544384002686
Validation loss: 2.2342079019033783

Epoch: 5| Step: 4
Training loss: 2.8595757484436035
Validation loss: 2.249750514184275

Epoch: 5| Step: 5
Training loss: 2.6133549213409424
Validation loss: 2.260905618308693

Epoch: 5| Step: 6
Training loss: 2.8904669284820557
Validation loss: 2.244137574267644

Epoch: 5| Step: 7
Training loss: 2.6002097129821777
Validation loss: 2.235527943539363

Epoch: 5| Step: 8
Training loss: 2.3870511054992676
Validation loss: 2.2363111690808366

Epoch: 5| Step: 9
Training loss: 1.9332516193389893
Validation loss: 2.2308681703382924

Epoch: 5| Step: 10
Training loss: 2.850353717803955
Validation loss: 2.24267312019102

Epoch: 235| Step: 0
Training loss: 1.814191460609436
Validation loss: 2.240286301541072

Epoch: 5| Step: 1
Training loss: 3.129206657409668
Validation loss: 2.2352966364993843

Epoch: 5| Step: 2
Training loss: 2.2479805946350098
Validation loss: 2.2333003526092856

Epoch: 5| Step: 3
Training loss: 3.094654083251953
Validation loss: 2.2251975510710027

Epoch: 5| Step: 4
Training loss: 2.4234516620635986
Validation loss: 2.2253240410999586

Epoch: 5| Step: 5
Training loss: 1.6865246295928955
Validation loss: 2.2171830848980973

Epoch: 5| Step: 6
Training loss: 2.227907657623291
Validation loss: 2.2215149274436374

Epoch: 5| Step: 7
Training loss: 2.6409175395965576
Validation loss: 2.2325345598241335

Epoch: 5| Step: 8
Training loss: 2.0666661262512207
Validation loss: 2.2535691312564317

Epoch: 5| Step: 9
Training loss: 2.099050998687744
Validation loss: 2.2821333177628054

Epoch: 5| Step: 10
Training loss: 2.559187412261963
Validation loss: 2.311739052495649

Epoch: 236| Step: 0
Training loss: 2.4316766262054443
Validation loss: 2.292990771673059

Epoch: 5| Step: 1
Training loss: 2.5229668617248535
Validation loss: 2.2566339867089384

Epoch: 5| Step: 2
Training loss: 2.8030104637145996
Validation loss: 2.2501563538787184

Epoch: 5| Step: 3
Training loss: 2.172062873840332
Validation loss: 2.2311212196145007

Epoch: 5| Step: 4
Training loss: 2.1744155883789062
Validation loss: 2.2471458322258404

Epoch: 5| Step: 5
Training loss: 1.4141861200332642
Validation loss: 2.2553838914440525

Epoch: 5| Step: 6
Training loss: 2.5631251335144043
Validation loss: 2.257433975896528

Epoch: 5| Step: 7
Training loss: 2.0536551475524902
Validation loss: 2.2432270716595393

Epoch: 5| Step: 8
Training loss: 2.6973838806152344
Validation loss: 2.2409052387360604

Epoch: 5| Step: 9
Training loss: 2.1963629722595215
Validation loss: 2.2428182940329275

Epoch: 5| Step: 10
Training loss: 2.988903522491455
Validation loss: 2.2382045574085687

Epoch: 237| Step: 0
Training loss: 2.364609718322754
Validation loss: 2.245169734442106

Epoch: 5| Step: 1
Training loss: 2.2760396003723145
Validation loss: 2.2517131887456423

Epoch: 5| Step: 2
Training loss: 1.8919000625610352
Validation loss: 2.2522970579003774

Epoch: 5| Step: 3
Training loss: 2.6875858306884766
Validation loss: 2.2856780405967467

Epoch: 5| Step: 4
Training loss: 1.434554100036621
Validation loss: 2.287971806782548

Epoch: 5| Step: 5
Training loss: 2.2075390815734863
Validation loss: 2.3080850339704946

Epoch: 5| Step: 6
Training loss: 3.1109516620635986
Validation loss: 2.2951819614697526

Epoch: 5| Step: 7
Training loss: 2.7479796409606934
Validation loss: 2.2926646868387857

Epoch: 5| Step: 8
Training loss: 1.7075437307357788
Validation loss: 2.2616039476087018

Epoch: 5| Step: 9
Training loss: 2.756641387939453
Validation loss: 2.2315656497914302

Epoch: 5| Step: 10
Training loss: 2.805781602859497
Validation loss: 2.217302950479651

Epoch: 238| Step: 0
Training loss: 2.4865198135375977
Validation loss: 2.1962619263638734

Epoch: 5| Step: 1
Training loss: 2.3292222023010254
Validation loss: 2.1973585672275995

Epoch: 5| Step: 2
Training loss: 2.445509433746338
Validation loss: 2.2126352838290635

Epoch: 5| Step: 3
Training loss: 3.1791648864746094
Validation loss: 2.207058322045111

Epoch: 5| Step: 4
Training loss: 1.7165491580963135
Validation loss: 2.2069294606485674

Epoch: 5| Step: 5
Training loss: 2.1171600818634033
Validation loss: 2.216714125807567

Epoch: 5| Step: 6
Training loss: 2.630612850189209
Validation loss: 2.2159251256655623

Epoch: 5| Step: 7
Training loss: 2.162015199661255
Validation loss: 2.230196260636853

Epoch: 5| Step: 8
Training loss: 2.187413215637207
Validation loss: 2.2230702536080473

Epoch: 5| Step: 9
Training loss: 2.1347484588623047
Validation loss: 2.2604358221894953

Epoch: 5| Step: 10
Training loss: 2.4667298793792725
Validation loss: 2.28095866018726

Epoch: 239| Step: 0
Training loss: 2.630791187286377
Validation loss: 2.294752941336683

Epoch: 5| Step: 1
Training loss: 2.065769672393799
Validation loss: 2.2681018357635825

Epoch: 5| Step: 2
Training loss: 2.4141006469726562
Validation loss: 2.241013034697502

Epoch: 5| Step: 3
Training loss: 2.2069122791290283
Validation loss: 2.240947751588719

Epoch: 5| Step: 4
Training loss: 2.9756524562835693
Validation loss: 2.2249383182935816

Epoch: 5| Step: 5
Training loss: 2.172778844833374
Validation loss: 2.227493337405625

Epoch: 5| Step: 6
Training loss: 1.800302267074585
Validation loss: 2.227141652055966

Epoch: 5| Step: 7
Training loss: 2.2904741764068604
Validation loss: 2.2360068649374027

Epoch: 5| Step: 8
Training loss: 2.572070360183716
Validation loss: 2.2372940073731127

Epoch: 5| Step: 9
Training loss: 2.125457763671875
Validation loss: 2.245972974326021

Epoch: 5| Step: 10
Training loss: 2.4737446308135986
Validation loss: 2.248775069431592

Epoch: 240| Step: 0
Training loss: 2.163642406463623
Validation loss: 2.2516281681676067

Epoch: 5| Step: 1
Training loss: 2.6161446571350098
Validation loss: 2.2427797599505355

Epoch: 5| Step: 2
Training loss: 2.848588228225708
Validation loss: 2.245046173372576

Epoch: 5| Step: 3
Training loss: 2.6675326824188232
Validation loss: 2.244930544207173

Epoch: 5| Step: 4
Training loss: 2.4812538623809814
Validation loss: 2.2335561013990834

Epoch: 5| Step: 5
Training loss: 2.233933448791504
Validation loss: 2.2277187531994236

Epoch: 5| Step: 6
Training loss: 2.1416218280792236
Validation loss: 2.253184364688012

Epoch: 5| Step: 7
Training loss: 2.6231069564819336
Validation loss: 2.260402061605966

Epoch: 5| Step: 8
Training loss: 1.9141407012939453
Validation loss: 2.265327621531743

Epoch: 5| Step: 9
Training loss: 1.6688711643218994
Validation loss: 2.2590448792262743

Epoch: 5| Step: 10
Training loss: 2.234607458114624
Validation loss: 2.250452895318308

Epoch: 241| Step: 0
Training loss: 1.9245685338974
Validation loss: 2.2396680206380863

Epoch: 5| Step: 1
Training loss: 2.5874698162078857
Validation loss: 2.227461644398269

Epoch: 5| Step: 2
Training loss: 2.468555450439453
Validation loss: 2.217149019241333

Epoch: 5| Step: 3
Training loss: 2.553213596343994
Validation loss: 2.2270294671417563

Epoch: 5| Step: 4
Training loss: 2.131762742996216
Validation loss: 2.2116870521217264

Epoch: 5| Step: 5
Training loss: 2.7279016971588135
Validation loss: 2.2001959200828307

Epoch: 5| Step: 6
Training loss: 2.096564769744873
Validation loss: 2.1995653285775134

Epoch: 5| Step: 7
Training loss: 1.845332384109497
Validation loss: 2.210038395338161

Epoch: 5| Step: 8
Training loss: 2.4817099571228027
Validation loss: 2.2185712860476587

Epoch: 5| Step: 9
Training loss: 2.797775983810425
Validation loss: 2.227465424486386

Epoch: 5| Step: 10
Training loss: 1.9835553169250488
Validation loss: 2.2352894647147066

Epoch: 242| Step: 0
Training loss: 2.817211151123047
Validation loss: 2.2341587082032235

Epoch: 5| Step: 1
Training loss: 2.1696295738220215
Validation loss: 2.2534127466140257

Epoch: 5| Step: 2
Training loss: 1.5470726490020752
Validation loss: 2.2477952536716255

Epoch: 5| Step: 3
Training loss: 2.189211845397949
Validation loss: 2.245152355522238

Epoch: 5| Step: 4
Training loss: 2.790700912475586
Validation loss: 2.2548251946767173

Epoch: 5| Step: 5
Training loss: 2.0447885990142822
Validation loss: 2.271794219170847

Epoch: 5| Step: 6
Training loss: 3.043524980545044
Validation loss: 2.275579026950303

Epoch: 5| Step: 7
Training loss: 1.7966091632843018
Validation loss: 2.269647131684006

Epoch: 5| Step: 8
Training loss: 2.1130688190460205
Validation loss: 2.253869318193005

Epoch: 5| Step: 9
Training loss: 2.6680638790130615
Validation loss: 2.235487222671509

Epoch: 5| Step: 10
Training loss: 2.176607131958008
Validation loss: 2.2081242774122503

Epoch: 243| Step: 0
Training loss: 1.640798807144165
Validation loss: 2.2014519194121003

Epoch: 5| Step: 1
Training loss: 2.3515002727508545
Validation loss: 2.203528501654184

Epoch: 5| Step: 2
Training loss: 2.1936912536621094
Validation loss: 2.1908269620710805

Epoch: 5| Step: 3
Training loss: 2.6322555541992188
Validation loss: 2.1902483253068823

Epoch: 5| Step: 4
Training loss: 2.1745779514312744
Validation loss: 2.1840168429959204

Epoch: 5| Step: 5
Training loss: 2.2883193492889404
Validation loss: 2.2064855816543743

Epoch: 5| Step: 6
Training loss: 1.615007758140564
Validation loss: 2.2247788188278035

Epoch: 5| Step: 7
Training loss: 2.653827428817749
Validation loss: 2.2365684124731247

Epoch: 5| Step: 8
Training loss: 3.2271766662597656
Validation loss: 2.257669165570249

Epoch: 5| Step: 9
Training loss: 2.163583278656006
Validation loss: 2.261550598247077

Epoch: 5| Step: 10
Training loss: 2.58073091506958
Validation loss: 2.268481393014231

Epoch: 244| Step: 0
Training loss: 3.0141148567199707
Validation loss: 2.2495833007238244

Epoch: 5| Step: 1
Training loss: 2.5296547412872314
Validation loss: 2.2288502441939486

Epoch: 5| Step: 2
Training loss: 2.443122386932373
Validation loss: 2.220096690680391

Epoch: 5| Step: 3
Training loss: 1.9246015548706055
Validation loss: 2.204532636109219

Epoch: 5| Step: 4
Training loss: 1.842659592628479
Validation loss: 2.2035289195276078

Epoch: 5| Step: 5
Training loss: 1.619630217552185
Validation loss: 2.1926753674784014

Epoch: 5| Step: 6
Training loss: 2.032400608062744
Validation loss: 2.1995754190670547

Epoch: 5| Step: 7
Training loss: 2.7760753631591797
Validation loss: 2.2047184590370423

Epoch: 5| Step: 8
Training loss: 1.922149658203125
Validation loss: 2.2215135379504134

Epoch: 5| Step: 9
Training loss: 2.668896198272705
Validation loss: 2.230715064592259

Epoch: 5| Step: 10
Training loss: 2.540372848510742
Validation loss: 2.248465099642354

Epoch: 245| Step: 0
Training loss: 1.9869792461395264
Validation loss: 2.2499450022174465

Epoch: 5| Step: 1
Training loss: 1.614540457725525
Validation loss: 2.2504341935598724

Epoch: 5| Step: 2
Training loss: 2.3039071559906006
Validation loss: 2.2796382109324136

Epoch: 5| Step: 3
Training loss: 1.8925964832305908
Validation loss: 2.282461932910386

Epoch: 5| Step: 4
Training loss: 1.9745982885360718
Validation loss: 2.2841677050436697

Epoch: 5| Step: 5
Training loss: 3.1767354011535645
Validation loss: 2.2753052621759395

Epoch: 5| Step: 6
Training loss: 2.1895699501037598
Validation loss: 2.2362824460511566

Epoch: 5| Step: 7
Training loss: 2.5916147232055664
Validation loss: 2.2212451401577202

Epoch: 5| Step: 8
Training loss: 2.411679744720459
Validation loss: 2.1974288212355746

Epoch: 5| Step: 9
Training loss: 2.4093422889709473
Validation loss: 2.19483886226531

Epoch: 5| Step: 10
Training loss: 2.588062286376953
Validation loss: 2.1850025500020673

Epoch: 246| Step: 0
Training loss: 2.068782091140747
Validation loss: 2.1955172297775105

Epoch: 5| Step: 1
Training loss: 2.4591522216796875
Validation loss: 2.191185243668095

Epoch: 5| Step: 2
Training loss: 2.1017425060272217
Validation loss: 2.189903738678143

Epoch: 5| Step: 3
Training loss: 1.7916176319122314
Validation loss: 2.2001064323609874

Epoch: 5| Step: 4
Training loss: 2.3032822608947754
Validation loss: 2.2129696594771517

Epoch: 5| Step: 5
Training loss: 2.614503860473633
Validation loss: 2.246182600657145

Epoch: 5| Step: 6
Training loss: 2.36711049079895
Validation loss: 2.2699815291230396

Epoch: 5| Step: 7
Training loss: 2.0049915313720703
Validation loss: 2.2542174093184935

Epoch: 5| Step: 8
Training loss: 2.4085001945495605
Validation loss: 2.223377307256063

Epoch: 5| Step: 9
Training loss: 2.8680245876312256
Validation loss: 2.218241055806478

Epoch: 5| Step: 10
Training loss: 2.0264413356781006
Validation loss: 2.213313123231293

Epoch: 247| Step: 0
Training loss: 2.3935720920562744
Validation loss: 2.2059694144033615

Epoch: 5| Step: 1
Training loss: 2.0740368366241455
Validation loss: 2.2023755811875865

Epoch: 5| Step: 2
Training loss: 2.96502685546875
Validation loss: 2.1984445536008446

Epoch: 5| Step: 3
Training loss: 1.7141777276992798
Validation loss: 2.2266645700700822

Epoch: 5| Step: 4
Training loss: 1.651868462562561
Validation loss: 2.247882035470778

Epoch: 5| Step: 5
Training loss: 2.560271739959717
Validation loss: 2.2491121240841445

Epoch: 5| Step: 6
Training loss: 2.6219329833984375
Validation loss: 2.214349349339803

Epoch: 5| Step: 7
Training loss: 2.6586434841156006
Validation loss: 2.2116173185328

Epoch: 5| Step: 8
Training loss: 1.7901685237884521
Validation loss: 2.1923355274302985

Epoch: 5| Step: 9
Training loss: 1.9887663125991821
Validation loss: 2.204183392627265

Epoch: 5| Step: 10
Training loss: 2.688715934753418
Validation loss: 2.209391619569512

Epoch: 248| Step: 0
Training loss: 2.185879945755005
Validation loss: 2.208705799553984

Epoch: 5| Step: 1
Training loss: 1.9858360290527344
Validation loss: 2.1922129123441634

Epoch: 5| Step: 2
Training loss: 2.216599941253662
Validation loss: 2.1894579472080355

Epoch: 5| Step: 3
Training loss: 2.067432165145874
Validation loss: 2.202384579566217

Epoch: 5| Step: 4
Training loss: 2.0434889793395996
Validation loss: 2.213417483914283

Epoch: 5| Step: 5
Training loss: 2.6384315490722656
Validation loss: 2.2366908199043682

Epoch: 5| Step: 6
Training loss: 2.1661925315856934
Validation loss: 2.2775971633131786

Epoch: 5| Step: 7
Training loss: 2.938643217086792
Validation loss: 2.2897336739365772

Epoch: 5| Step: 8
Training loss: 2.217808246612549
Validation loss: 2.2892498277848765

Epoch: 5| Step: 9
Training loss: 2.237480878829956
Validation loss: 2.3127020148820776

Epoch: 5| Step: 10
Training loss: 2.359503746032715
Validation loss: 2.2982088006952757

Epoch: 249| Step: 0
Training loss: 2.161395788192749
Validation loss: 2.2623099947488434

Epoch: 5| Step: 1
Training loss: 2.4370815753936768
Validation loss: 2.2367553172572965

Epoch: 5| Step: 2
Training loss: 2.333108425140381
Validation loss: 2.215080843176893

Epoch: 5| Step: 3
Training loss: 2.5076327323913574
Validation loss: 2.2002973838519027

Epoch: 5| Step: 4
Training loss: 2.3613638877868652
Validation loss: 2.2073094844818115

Epoch: 5| Step: 5
Training loss: 2.1635143756866455
Validation loss: 2.2114112325893935

Epoch: 5| Step: 6
Training loss: 1.6984443664550781
Validation loss: 2.2043736878261773

Epoch: 5| Step: 7
Training loss: 2.7585158348083496
Validation loss: 2.2291281043842273

Epoch: 5| Step: 8
Training loss: 1.8147920370101929
Validation loss: 2.2426450124350925

Epoch: 5| Step: 9
Training loss: 2.157651662826538
Validation loss: 2.2440796077892347

Epoch: 5| Step: 10
Training loss: 2.5820255279541016
Validation loss: 2.2234417392361547

Epoch: 250| Step: 0
Training loss: 2.331618547439575
Validation loss: 2.2292199468099945

Epoch: 5| Step: 1
Training loss: 1.8006786108016968
Validation loss: 2.222673846829322

Epoch: 5| Step: 2
Training loss: 2.045989990234375
Validation loss: 2.2386885484059653

Epoch: 5| Step: 3
Training loss: 1.8714072704315186
Validation loss: 2.229087750116984

Epoch: 5| Step: 4
Training loss: 2.8248724937438965
Validation loss: 2.2312717258289294

Epoch: 5| Step: 5
Training loss: 2.43811297416687
Validation loss: 2.2349840351330337

Epoch: 5| Step: 6
Training loss: 2.49216890335083
Validation loss: 2.2434343138048725

Epoch: 5| Step: 7
Training loss: 2.3121001720428467
Validation loss: 2.217004285063795

Epoch: 5| Step: 8
Training loss: 1.6383683681488037
Validation loss: 2.216692134898196

Epoch: 5| Step: 9
Training loss: 2.198908567428589
Validation loss: 2.2226839091188166

Epoch: 5| Step: 10
Training loss: 3.0925676822662354
Validation loss: 2.257800507289107

Epoch: 251| Step: 0
Training loss: 2.7210803031921387
Validation loss: 2.258795339574096

Epoch: 5| Step: 1
Training loss: 2.1512832641601562
Validation loss: 2.231686524165574

Epoch: 5| Step: 2
Training loss: 1.9698083400726318
Validation loss: 2.2117747850315546

Epoch: 5| Step: 3
Training loss: 2.486976146697998
Validation loss: 2.1860622347042127

Epoch: 5| Step: 4
Training loss: 2.351834535598755
Validation loss: 2.1785690822908954

Epoch: 5| Step: 5
Training loss: 2.047140598297119
Validation loss: 2.185593415332097

Epoch: 5| Step: 6
Training loss: 2.16253662109375
Validation loss: 2.1949853486912225

Epoch: 5| Step: 7
Training loss: 2.1237292289733887
Validation loss: 2.190117282252158

Epoch: 5| Step: 8
Training loss: 2.2764415740966797
Validation loss: 2.19293321845352

Epoch: 5| Step: 9
Training loss: 2.0720043182373047
Validation loss: 2.1929095611777356

Epoch: 5| Step: 10
Training loss: 2.6780941486358643
Validation loss: 2.230890909830729

Epoch: 252| Step: 0
Training loss: 2.62349271774292
Validation loss: 2.2833292586829073

Epoch: 5| Step: 1
Training loss: 1.860320806503296
Validation loss: 2.331220711431196

Epoch: 5| Step: 2
Training loss: 2.115898609161377
Validation loss: 2.3652715554801365

Epoch: 5| Step: 3
Training loss: 2.272357702255249
Validation loss: 2.3498217341720418

Epoch: 5| Step: 4
Training loss: 2.6691267490386963
Validation loss: 2.309913707035844

Epoch: 5| Step: 5
Training loss: 2.1238486766815186
Validation loss: 2.2922048722544024

Epoch: 5| Step: 6
Training loss: 2.3431365489959717
Validation loss: 2.2677104934569328

Epoch: 5| Step: 7
Training loss: 2.65189528465271
Validation loss: 2.2369740470763175

Epoch: 5| Step: 8
Training loss: 2.2968246936798096
Validation loss: 2.2125563134429274

Epoch: 5| Step: 9
Training loss: 2.142787456512451
Validation loss: 2.2130319969628447

Epoch: 5| Step: 10
Training loss: 2.0342249870300293
Validation loss: 2.2031822499408515

Epoch: 253| Step: 0
Training loss: 2.915306806564331
Validation loss: 2.1904218914688274

Epoch: 5| Step: 1
Training loss: 2.3760643005371094
Validation loss: 2.208751404157249

Epoch: 5| Step: 2
Training loss: 1.8450756072998047
Validation loss: 2.1963819124365367

Epoch: 5| Step: 3
Training loss: 1.7936480045318604
Validation loss: 2.2028395155424714

Epoch: 5| Step: 4
Training loss: 2.5358595848083496
Validation loss: 2.2061080650616716

Epoch: 5| Step: 5
Training loss: 2.5510401725769043
Validation loss: 2.2059061193978913

Epoch: 5| Step: 6
Training loss: 2.367579221725464
Validation loss: 2.222729200957924

Epoch: 5| Step: 7
Training loss: 1.81488835811615
Validation loss: 2.242068595783685

Epoch: 5| Step: 8
Training loss: 2.2050347328186035
Validation loss: 2.257966669656897

Epoch: 5| Step: 9
Training loss: 2.167375087738037
Validation loss: 2.2406260069980415

Epoch: 5| Step: 10
Training loss: 1.9613237380981445
Validation loss: 2.2102375145881408

Epoch: 254| Step: 0
Training loss: 2.5327279567718506
Validation loss: 2.218947361874324

Epoch: 5| Step: 1
Training loss: 2.4420368671417236
Validation loss: 2.2217894933556996

Epoch: 5| Step: 2
Training loss: 2.37811017036438
Validation loss: 2.2084911113144248

Epoch: 5| Step: 3
Training loss: 2.257467031478882
Validation loss: 2.198921080558531

Epoch: 5| Step: 4
Training loss: 2.3522980213165283
Validation loss: 2.2073861963005474

Epoch: 5| Step: 5
Training loss: 1.4701873064041138
Validation loss: 2.2117259015319166

Epoch: 5| Step: 6
Training loss: 1.7690820693969727
Validation loss: 2.2208974899784213

Epoch: 5| Step: 7
Training loss: 2.1133015155792236
Validation loss: 2.224536298423685

Epoch: 5| Step: 8
Training loss: 2.5476016998291016
Validation loss: 2.222715082988944

Epoch: 5| Step: 9
Training loss: 2.1126341819763184
Validation loss: 2.1906094615177443

Epoch: 5| Step: 10
Training loss: 2.510043144226074
Validation loss: 2.2192990677331084

Epoch: 255| Step: 0
Training loss: 1.7884902954101562
Validation loss: 2.2356528389838433

Epoch: 5| Step: 1
Training loss: 1.6718032360076904
Validation loss: 2.270116641957273

Epoch: 5| Step: 2
Training loss: 1.764642357826233
Validation loss: 2.3024889807547293

Epoch: 5| Step: 3
Training loss: 2.018319845199585
Validation loss: 2.3619733369478615

Epoch: 5| Step: 4
Training loss: 2.862938642501831
Validation loss: 2.3921694217189664

Epoch: 5| Step: 5
Training loss: 3.3471972942352295
Validation loss: 2.400137923097098

Epoch: 5| Step: 6
Training loss: 2.3058762550354004
Validation loss: 2.3684423174909366

Epoch: 5| Step: 7
Training loss: 2.0308806896209717
Validation loss: 2.2798984832661127

Epoch: 5| Step: 8
Training loss: 2.4706921577453613
Validation loss: 2.2054909583060973

Epoch: 5| Step: 9
Training loss: 2.7942540645599365
Validation loss: 2.174607479444114

Epoch: 5| Step: 10
Training loss: 1.8740808963775635
Validation loss: 2.1720977342256935

Epoch: 256| Step: 0
Training loss: 1.8227459192276
Validation loss: 2.1687968700162825

Epoch: 5| Step: 1
Training loss: 2.851891040802002
Validation loss: 2.16603474591368

Epoch: 5| Step: 2
Training loss: 2.368764638900757
Validation loss: 2.1582101673208256

Epoch: 5| Step: 3
Training loss: 1.9430534839630127
Validation loss: 2.1560880240573677

Epoch: 5| Step: 4
Training loss: 1.9144309759140015
Validation loss: 2.1443285890804824

Epoch: 5| Step: 5
Training loss: 2.21268630027771
Validation loss: 2.1493420293254237

Epoch: 5| Step: 6
Training loss: 2.5866451263427734
Validation loss: 2.1538330124270533

Epoch: 5| Step: 7
Training loss: 2.0238022804260254
Validation loss: 2.159067110348773

Epoch: 5| Step: 8
Training loss: 2.597459316253662
Validation loss: 2.1646877386236705

Epoch: 5| Step: 9
Training loss: 2.3623461723327637
Validation loss: 2.1830772328120407

Epoch: 5| Step: 10
Training loss: 2.4491682052612305
Validation loss: 2.192334489155841

Epoch: 257| Step: 0
Training loss: 2.234196186065674
Validation loss: 2.207263949096844

Epoch: 5| Step: 1
Training loss: 2.51192045211792
Validation loss: 2.237972749176846

Epoch: 5| Step: 2
Training loss: 2.617828130722046
Validation loss: 2.2480021240890666

Epoch: 5| Step: 3
Training loss: 2.832717180252075
Validation loss: 2.243604770270727

Epoch: 5| Step: 4
Training loss: 1.8842103481292725
Validation loss: 2.252259910747569

Epoch: 5| Step: 5
Training loss: 2.1371829509735107
Validation loss: 2.259548717929471

Epoch: 5| Step: 6
Training loss: 2.4194960594177246
Validation loss: 2.247666779384818

Epoch: 5| Step: 7
Training loss: 1.7505075931549072
Validation loss: 2.266087414115988

Epoch: 5| Step: 8
Training loss: 2.1825828552246094
Validation loss: 2.269732482971684

Epoch: 5| Step: 9
Training loss: 2.09053897857666
Validation loss: 2.267365204390659

Epoch: 5| Step: 10
Training loss: 1.9760373830795288
Validation loss: 2.249760872574263

Epoch: 258| Step: 0
Training loss: 2.991960048675537
Validation loss: 2.2543056677746516

Epoch: 5| Step: 1
Training loss: 1.7467625141143799
Validation loss: 2.261392690802133

Epoch: 5| Step: 2
Training loss: 2.592787504196167
Validation loss: 2.2485767154283423

Epoch: 5| Step: 3
Training loss: 2.0330023765563965
Validation loss: 2.2028165504496586

Epoch: 5| Step: 4
Training loss: 2.239189624786377
Validation loss: 2.180235867859215

Epoch: 5| Step: 5
Training loss: 1.8984251022338867
Validation loss: 2.168483644403437

Epoch: 5| Step: 6
Training loss: 2.581411600112915
Validation loss: 2.167550212593489

Epoch: 5| Step: 7
Training loss: 1.9457924365997314
Validation loss: 2.1509055911853747

Epoch: 5| Step: 8
Training loss: 2.127678632736206
Validation loss: 2.1569847868334864

Epoch: 5| Step: 9
Training loss: 2.2205758094787598
Validation loss: 2.158225174873106

Epoch: 5| Step: 10
Training loss: 2.4229776859283447
Validation loss: 2.1606996213236163

Epoch: 259| Step: 0
Training loss: 1.4830042123794556
Validation loss: 2.1784600211728002

Epoch: 5| Step: 1
Training loss: 1.7803065776824951
Validation loss: 2.18984136273784

Epoch: 5| Step: 2
Training loss: 2.221846342086792
Validation loss: 2.223531425640147

Epoch: 5| Step: 3
Training loss: 3.3464877605438232
Validation loss: 2.2561631971789944

Epoch: 5| Step: 4
Training loss: 2.442613124847412
Validation loss: 2.2838882438598143

Epoch: 5| Step: 5
Training loss: 2.066213846206665
Validation loss: 2.2843699275806384

Epoch: 5| Step: 6
Training loss: 1.7082208395004272
Validation loss: 2.2810017139680925

Epoch: 5| Step: 7
Training loss: 2.2026829719543457
Validation loss: 2.2613433394380795

Epoch: 5| Step: 8
Training loss: 2.4149110317230225
Validation loss: 2.260677542737735

Epoch: 5| Step: 9
Training loss: 2.3602871894836426
Validation loss: 2.239153390289635

Epoch: 5| Step: 10
Training loss: 2.3619771003723145
Validation loss: 2.2320189091467086

Epoch: 260| Step: 0
Training loss: 2.2909371852874756
Validation loss: 2.21879332552674

Epoch: 5| Step: 1
Training loss: 2.2029690742492676
Validation loss: 2.2101874261774044

Epoch: 5| Step: 2
Training loss: 2.0528411865234375
Validation loss: 2.2026854638130433

Epoch: 5| Step: 3
Training loss: 2.6310408115386963
Validation loss: 2.198101500029205

Epoch: 5| Step: 4
Training loss: 2.1104862689971924
Validation loss: 2.178687767315936

Epoch: 5| Step: 5
Training loss: 2.6815905570983887
Validation loss: 2.184575173162645

Epoch: 5| Step: 6
Training loss: 2.5615038871765137
Validation loss: 2.1965460059463338

Epoch: 5| Step: 7
Training loss: 2.2512104511260986
Validation loss: 2.2102469859584684

Epoch: 5| Step: 8
Training loss: 1.8540194034576416
Validation loss: 2.2222068668693624

Epoch: 5| Step: 9
Training loss: 2.0988271236419678
Validation loss: 2.2120133317926878

Epoch: 5| Step: 10
Training loss: 1.4281543493270874
Validation loss: 2.208189049074727

Epoch: 261| Step: 0
Training loss: 2.4172375202178955
Validation loss: 2.195626761323662

Epoch: 5| Step: 1
Training loss: 2.5895042419433594
Validation loss: 2.184640117870864

Epoch: 5| Step: 2
Training loss: 2.414433479309082
Validation loss: 2.190454085667928

Epoch: 5| Step: 3
Training loss: 2.4423348903656006
Validation loss: 2.201379414527647

Epoch: 5| Step: 4
Training loss: 2.078084707260132
Validation loss: 2.21331190037471

Epoch: 5| Step: 5
Training loss: 1.6407934427261353
Validation loss: 2.22681523394841

Epoch: 5| Step: 6
Training loss: 1.8882087469100952
Validation loss: 2.2522285266589095

Epoch: 5| Step: 7
Training loss: 2.1930301189422607
Validation loss: 2.246797025844615

Epoch: 5| Step: 8
Training loss: 2.751619338989258
Validation loss: 2.239387568607125

Epoch: 5| Step: 9
Training loss: 1.4042574167251587
Validation loss: 2.2289873118041665

Epoch: 5| Step: 10
Training loss: 2.2591896057128906
Validation loss: 2.229602062573997

Epoch: 262| Step: 0
Training loss: 1.6656490564346313
Validation loss: 2.2175988510090816

Epoch: 5| Step: 1
Training loss: 2.2983641624450684
Validation loss: 2.19449185299617

Epoch: 5| Step: 2
Training loss: 2.166635751724243
Validation loss: 2.179381401308121

Epoch: 5| Step: 3
Training loss: 2.466919422149658
Validation loss: 2.187232567418006

Epoch: 5| Step: 4
Training loss: 1.4950957298278809
Validation loss: 2.193296552986227

Epoch: 5| Step: 5
Training loss: 2.0323283672332764
Validation loss: 2.185245421624953

Epoch: 5| Step: 6
Training loss: 2.215646266937256
Validation loss: 2.204420861377511

Epoch: 5| Step: 7
Training loss: 2.317530393600464
Validation loss: 2.2137723686874553

Epoch: 5| Step: 8
Training loss: 2.0600690841674805
Validation loss: 2.1878301610228834

Epoch: 5| Step: 9
Training loss: 2.861307144165039
Validation loss: 2.1760456562042236

Epoch: 5| Step: 10
Training loss: 2.493283271789551
Validation loss: 2.1644155709974227

Epoch: 263| Step: 0
Training loss: 2.6859734058380127
Validation loss: 2.1595427759232058

Epoch: 5| Step: 1
Training loss: 2.1364943981170654
Validation loss: 2.1422100413230156

Epoch: 5| Step: 2
Training loss: 1.98468017578125
Validation loss: 2.13970923167403

Epoch: 5| Step: 3
Training loss: 2.54205060005188
Validation loss: 2.144374667957265

Epoch: 5| Step: 4
Training loss: 2.1332061290740967
Validation loss: 2.149519525548463

Epoch: 5| Step: 5
Training loss: 1.6743967533111572
Validation loss: 2.161074464039136

Epoch: 5| Step: 6
Training loss: 2.4956254959106445
Validation loss: 2.170284343022172

Epoch: 5| Step: 7
Training loss: 1.9727662801742554
Validation loss: 2.205789209693991

Epoch: 5| Step: 8
Training loss: 2.0949769020080566
Validation loss: 2.2393085136208484

Epoch: 5| Step: 9
Training loss: 1.9962489604949951
Validation loss: 2.2618344522291616

Epoch: 5| Step: 10
Training loss: 2.2927489280700684
Validation loss: 2.2789035689446235

Epoch: 264| Step: 0
Training loss: 1.531579852104187
Validation loss: 2.2432525927020657

Epoch: 5| Step: 1
Training loss: 2.5436084270477295
Validation loss: 2.249093747908069

Epoch: 5| Step: 2
Training loss: 1.8860852718353271
Validation loss: 2.2368259917023363

Epoch: 5| Step: 3
Training loss: 2.631061553955078
Validation loss: 2.2305379682971584

Epoch: 5| Step: 4
Training loss: 2.2677080631256104
Validation loss: 2.2237799347087903

Epoch: 5| Step: 5
Training loss: 2.1961007118225098
Validation loss: 2.215425063205022

Epoch: 5| Step: 6
Training loss: 2.413264513015747
Validation loss: 2.1879324887388494

Epoch: 5| Step: 7
Training loss: 2.4271035194396973
Validation loss: 2.1904478380756993

Epoch: 5| Step: 8
Training loss: 1.56516432762146
Validation loss: 2.1910692081656507

Epoch: 5| Step: 9
Training loss: 2.14658784866333
Validation loss: 2.1862744413396364

Epoch: 5| Step: 10
Training loss: 2.4144704341888428
Validation loss: 2.1895314237122894

Epoch: 265| Step: 0
Training loss: 2.114471673965454
Validation loss: 2.1868428645595426

Epoch: 5| Step: 1
Training loss: 2.4942269325256348
Validation loss: 2.1949928114491124

Epoch: 5| Step: 2
Training loss: 1.8326902389526367
Validation loss: 2.1802408233765633

Epoch: 5| Step: 3
Training loss: 1.7700399160385132
Validation loss: 2.1924797104251

Epoch: 5| Step: 4
Training loss: 2.105226516723633
Validation loss: 2.201260265483651

Epoch: 5| Step: 5
Training loss: 2.0237245559692383
Validation loss: 2.2438033447470715

Epoch: 5| Step: 6
Training loss: 3.0259881019592285
Validation loss: 2.2572768836893062

Epoch: 5| Step: 7
Training loss: 2.0295958518981934
Validation loss: 2.2626634900287916

Epoch: 5| Step: 8
Training loss: 2.4173314571380615
Validation loss: 2.2593075152366393

Epoch: 5| Step: 9
Training loss: 2.0265588760375977
Validation loss: 2.2412856727518062

Epoch: 5| Step: 10
Training loss: 2.163695812225342
Validation loss: 2.2161584925907913

Epoch: 266| Step: 0
Training loss: 2.190115451812744
Validation loss: 2.210970808100957

Epoch: 5| Step: 1
Training loss: 1.9566259384155273
Validation loss: 2.202597569393855

Epoch: 5| Step: 2
Training loss: 2.1120553016662598
Validation loss: 2.196669387561019

Epoch: 5| Step: 3
Training loss: 2.7908756732940674
Validation loss: 2.2026143432945333

Epoch: 5| Step: 4
Training loss: 2.1046693325042725
Validation loss: 2.191743835326164

Epoch: 5| Step: 5
Training loss: 2.198122501373291
Validation loss: 2.214837763899116

Epoch: 5| Step: 6
Training loss: 1.8214458227157593
Validation loss: 2.208658864421229

Epoch: 5| Step: 7
Training loss: 2.5665621757507324
Validation loss: 2.1953984870705554

Epoch: 5| Step: 8
Training loss: 2.045044183731079
Validation loss: 2.1761380523763676

Epoch: 5| Step: 9
Training loss: 1.8778076171875
Validation loss: 2.1697854649636055

Epoch: 5| Step: 10
Training loss: 1.9500099420547485
Validation loss: 2.154527307838522

Epoch: 267| Step: 0
Training loss: 2.160579204559326
Validation loss: 2.147159235451811

Epoch: 5| Step: 1
Training loss: 2.4294183254241943
Validation loss: 2.1696262257073515

Epoch: 5| Step: 2
Training loss: 1.8914191722869873
Validation loss: 2.179566091106784

Epoch: 5| Step: 3
Training loss: 2.3467977046966553
Validation loss: 2.1888575528257634

Epoch: 5| Step: 4
Training loss: 1.8722931146621704
Validation loss: 2.19414077010206

Epoch: 5| Step: 5
Training loss: 2.260436773300171
Validation loss: 2.18116484918902

Epoch: 5| Step: 6
Training loss: 1.8559424877166748
Validation loss: 2.1812698777003954

Epoch: 5| Step: 7
Training loss: 2.293381929397583
Validation loss: 2.174144874336899

Epoch: 5| Step: 8
Training loss: 1.9684959650039673
Validation loss: 2.1767995549786474

Epoch: 5| Step: 9
Training loss: 2.1609716415405273
Validation loss: 2.180058520327332

Epoch: 5| Step: 10
Training loss: 2.362769842147827
Validation loss: 2.2050760458874445

Epoch: 268| Step: 0
Training loss: 2.108185291290283
Validation loss: 2.220401963879985

Epoch: 5| Step: 1
Training loss: 1.535945177078247
Validation loss: 2.2083786251724407

Epoch: 5| Step: 2
Training loss: 1.8505675792694092
Validation loss: 2.187187220460625

Epoch: 5| Step: 3
Training loss: 2.4924259185791016
Validation loss: 2.176428007823165

Epoch: 5| Step: 4
Training loss: 2.227634906768799
Validation loss: 2.1667266225302093

Epoch: 5| Step: 5
Training loss: 2.4599459171295166
Validation loss: 2.155440374087262

Epoch: 5| Step: 6
Training loss: 1.7537641525268555
Validation loss: 2.153834837739186

Epoch: 5| Step: 7
Training loss: 2.3558545112609863
Validation loss: 2.1584492396282893

Epoch: 5| Step: 8
Training loss: 2.1432321071624756
Validation loss: 2.172517418861389

Epoch: 5| Step: 9
Training loss: 2.6615986824035645
Validation loss: 2.184460281043924

Epoch: 5| Step: 10
Training loss: 1.9334355592727661
Validation loss: 2.21918579839891

Epoch: 269| Step: 0
Training loss: 2.185804843902588
Validation loss: 2.253470705401513

Epoch: 5| Step: 1
Training loss: 1.6160335540771484
Validation loss: 2.3025649183539936

Epoch: 5| Step: 2
Training loss: 1.884360909461975
Validation loss: 2.315731172920555

Epoch: 5| Step: 3
Training loss: 2.8338990211486816
Validation loss: 2.3591691524751726

Epoch: 5| Step: 4
Training loss: 2.3410532474517822
Validation loss: 2.362023304867488

Epoch: 5| Step: 5
Training loss: 2.118983745574951
Validation loss: 2.3117584182370092

Epoch: 5| Step: 6
Training loss: 2.404813289642334
Validation loss: 2.2862577335808867

Epoch: 5| Step: 7
Training loss: 2.053684711456299
Validation loss: 2.2338692488208896

Epoch: 5| Step: 8
Training loss: 2.758716106414795
Validation loss: 2.2127732282043784

Epoch: 5| Step: 9
Training loss: 1.7110306024551392
Validation loss: 2.1819922026767524

Epoch: 5| Step: 10
Training loss: 1.7148103713989258
Validation loss: 2.1679058485133673

Epoch: 270| Step: 0
Training loss: 1.8996541500091553
Validation loss: 2.1519942860449515

Epoch: 5| Step: 1
Training loss: 2.072000026702881
Validation loss: 2.1477812515792025

Epoch: 5| Step: 2
Training loss: 1.8683907985687256
Validation loss: 2.137931389193381

Epoch: 5| Step: 3
Training loss: 2.1396565437316895
Validation loss: 2.1460583568901144

Epoch: 5| Step: 4
Training loss: 1.5194364786148071
Validation loss: 2.1443910803846133

Epoch: 5| Step: 5
Training loss: 2.2007546424865723
Validation loss: 2.167164385959666

Epoch: 5| Step: 6
Training loss: 2.860792398452759
Validation loss: 2.1987819299902966

Epoch: 5| Step: 7
Training loss: 2.1580543518066406
Validation loss: 2.226368873350082

Epoch: 5| Step: 8
Training loss: 1.7185688018798828
Validation loss: 2.2302371660868325

Epoch: 5| Step: 9
Training loss: 2.793264150619507
Validation loss: 2.221059126238669

Epoch: 5| Step: 10
Training loss: 2.6940510272979736
Validation loss: 2.1799582076329056

Epoch: 271| Step: 0
Training loss: 2.8153154850006104
Validation loss: 2.1803758631470385

Epoch: 5| Step: 1
Training loss: 1.7720600366592407
Validation loss: 2.175893134968255

Epoch: 5| Step: 2
Training loss: 2.127035617828369
Validation loss: 2.2082597401834305

Epoch: 5| Step: 3
Training loss: 2.4448494911193848
Validation loss: 2.186512762500394

Epoch: 5| Step: 4
Training loss: 2.368004083633423
Validation loss: 2.188458081214659

Epoch: 5| Step: 5
Training loss: 1.4583417177200317
Validation loss: 2.176819162984048

Epoch: 5| Step: 6
Training loss: 2.1163322925567627
Validation loss: 2.1546831938528244

Epoch: 5| Step: 7
Training loss: 2.036841869354248
Validation loss: 2.1522504744991178

Epoch: 5| Step: 8
Training loss: 2.1913468837738037
Validation loss: 2.155698104571271

Epoch: 5| Step: 9
Training loss: 1.9680649042129517
Validation loss: 2.1654497423479633

Epoch: 5| Step: 10
Training loss: 2.109351396560669
Validation loss: 2.1717106911443893

Epoch: 272| Step: 0
Training loss: 2.092928171157837
Validation loss: 2.187969425673126

Epoch: 5| Step: 1
Training loss: 1.8322484493255615
Validation loss: 2.191542597227199

Epoch: 5| Step: 2
Training loss: 2.0977783203125
Validation loss: 2.169953312925113

Epoch: 5| Step: 3
Training loss: 1.9959319829940796
Validation loss: 2.167173203601632

Epoch: 5| Step: 4
Training loss: 2.218834161758423
Validation loss: 2.173345063322334

Epoch: 5| Step: 5
Training loss: 1.8389670848846436
Validation loss: 2.1754974165270404

Epoch: 5| Step: 6
Training loss: 1.8327865600585938
Validation loss: 2.184828071184056

Epoch: 5| Step: 7
Training loss: 2.4659407138824463
Validation loss: 2.179796277835805

Epoch: 5| Step: 8
Training loss: 2.955713987350464
Validation loss: 2.2098239314171577

Epoch: 5| Step: 9
Training loss: 2.0831942558288574
Validation loss: 2.1794496326036352

Epoch: 5| Step: 10
Training loss: 1.8186899423599243
Validation loss: 2.184436144367341

Epoch: 273| Step: 0
Training loss: 1.4116604328155518
Validation loss: 2.170926922111101

Epoch: 5| Step: 1
Training loss: 2.520416736602783
Validation loss: 2.1890793641408286

Epoch: 5| Step: 2
Training loss: 2.29697585105896
Validation loss: 2.182573994000753

Epoch: 5| Step: 3
Training loss: 2.2161450386047363
Validation loss: 2.19203854632634

Epoch: 5| Step: 4
Training loss: 2.3428378105163574
Validation loss: 2.1839201963076027

Epoch: 5| Step: 5
Training loss: 2.4102349281311035
Validation loss: 2.1641420497689197

Epoch: 5| Step: 6
Training loss: 2.2713303565979004
Validation loss: 2.1593866809721916

Epoch: 5| Step: 7
Training loss: 1.613713264465332
Validation loss: 2.1796872487632175

Epoch: 5| Step: 8
Training loss: 1.9311676025390625
Validation loss: 2.1903226939580773

Epoch: 5| Step: 9
Training loss: 1.8952499628067017
Validation loss: 2.1948048696723035

Epoch: 5| Step: 10
Training loss: 2.260232925415039
Validation loss: 2.1977498057068034

Epoch: 274| Step: 0
Training loss: 2.2007477283477783
Validation loss: 2.1899823373363865

Epoch: 5| Step: 1
Training loss: 1.775244116783142
Validation loss: 2.1958977817207255

Epoch: 5| Step: 2
Training loss: 2.816723346710205
Validation loss: 2.173807805584323

Epoch: 5| Step: 3
Training loss: 2.7008070945739746
Validation loss: 2.1748388531387493

Epoch: 5| Step: 4
Training loss: 2.0294570922851562
Validation loss: 2.1528077535731818

Epoch: 5| Step: 5
Training loss: 1.5706684589385986
Validation loss: 2.163220808070193

Epoch: 5| Step: 6
Training loss: 2.1042885780334473
Validation loss: 2.164637396412511

Epoch: 5| Step: 7
Training loss: 2.042538642883301
Validation loss: 2.1635699400337796

Epoch: 5| Step: 8
Training loss: 1.5768243074417114
Validation loss: 2.1670164062130834

Epoch: 5| Step: 9
Training loss: 1.7763874530792236
Validation loss: 2.1678114539833477

Epoch: 5| Step: 10
Training loss: 2.340773344039917
Validation loss: 2.1960528896700953

Epoch: 275| Step: 0
Training loss: 1.6597471237182617
Validation loss: 2.194698643940751

Epoch: 5| Step: 1
Training loss: 1.8568155765533447
Validation loss: 2.1919433737313874

Epoch: 5| Step: 2
Training loss: 2.032226085662842
Validation loss: 2.1706014884415494

Epoch: 5| Step: 3
Training loss: 2.256470203399658
Validation loss: 2.1584609990478842

Epoch: 5| Step: 4
Training loss: 1.7915868759155273
Validation loss: 2.1581097520807737

Epoch: 5| Step: 5
Training loss: 2.2743582725524902
Validation loss: 2.1559248329490743

Epoch: 5| Step: 6
Training loss: 2.253708600997925
Validation loss: 2.1339712219853557

Epoch: 5| Step: 7
Training loss: 2.184232473373413
Validation loss: 2.1577060889172297

Epoch: 5| Step: 8
Training loss: 2.4161670207977295
Validation loss: 2.156795214581233

Epoch: 5| Step: 9
Training loss: 1.6800224781036377
Validation loss: 2.1704590218041533

Epoch: 5| Step: 10
Training loss: 2.512901782989502
Validation loss: 2.1748740185973463

Epoch: 276| Step: 0
Training loss: 1.2904363870620728
Validation loss: 2.172935685803813

Epoch: 5| Step: 1
Training loss: 1.962149977684021
Validation loss: 2.1906327586020193

Epoch: 5| Step: 2
Training loss: 2.3358798027038574
Validation loss: 2.202611225907521

Epoch: 5| Step: 3
Training loss: 2.5655837059020996
Validation loss: 2.1958901292534283

Epoch: 5| Step: 4
Training loss: 1.684226393699646
Validation loss: 2.162863594229503

Epoch: 5| Step: 5
Training loss: 1.9591621160507202
Validation loss: 2.1234829964176303

Epoch: 5| Step: 6
Training loss: 2.7203617095947266
Validation loss: 2.105145828698271

Epoch: 5| Step: 7
Training loss: 2.1530284881591797
Validation loss: 2.1105747684355705

Epoch: 5| Step: 8
Training loss: 1.9391300678253174
Validation loss: 2.1274390643642795

Epoch: 5| Step: 9
Training loss: 2.142695903778076
Validation loss: 2.142679375986899

Epoch: 5| Step: 10
Training loss: 2.2016284465789795
Validation loss: 2.150934580833681

Epoch: 277| Step: 0
Training loss: 1.9984525442123413
Validation loss: 2.184114049839717

Epoch: 5| Step: 1
Training loss: 1.780843734741211
Validation loss: 2.2002830633553128

Epoch: 5| Step: 2
Training loss: 2.3566575050354004
Validation loss: 2.238194993747178

Epoch: 5| Step: 3
Training loss: 1.317427635192871
Validation loss: 2.2465252325099003

Epoch: 5| Step: 4
Training loss: 2.5955233573913574
Validation loss: 2.2473081004235054

Epoch: 5| Step: 5
Training loss: 1.8345667123794556
Validation loss: 2.238123183609337

Epoch: 5| Step: 6
Training loss: 1.7113109827041626
Validation loss: 2.1957837125306487

Epoch: 5| Step: 7
Training loss: 1.9863828420639038
Validation loss: 2.1520411378593853

Epoch: 5| Step: 8
Training loss: 2.362678050994873
Validation loss: 2.129071440747989

Epoch: 5| Step: 9
Training loss: 2.595552921295166
Validation loss: 2.1022640466690063

Epoch: 5| Step: 10
Training loss: 2.414569139480591
Validation loss: 2.0944632496885074

Epoch: 278| Step: 0
Training loss: 2.694624662399292
Validation loss: 2.08767669944353

Epoch: 5| Step: 1
Training loss: 1.873880386352539
Validation loss: 2.0840674779748403

Epoch: 5| Step: 2
Training loss: 1.8582435846328735
Validation loss: 2.102643600074194

Epoch: 5| Step: 3
Training loss: 2.360886335372925
Validation loss: 2.113563331224585

Epoch: 5| Step: 4
Training loss: 2.5114948749542236
Validation loss: 2.121467275004233

Epoch: 5| Step: 5
Training loss: 2.2310333251953125
Validation loss: 2.1469691286804857

Epoch: 5| Step: 6
Training loss: 2.27325701713562
Validation loss: 2.1767316966928463

Epoch: 5| Step: 7
Training loss: 1.9524281024932861
Validation loss: 2.183596903277982

Epoch: 5| Step: 8
Training loss: 1.4326014518737793
Validation loss: 2.1883983124968824

Epoch: 5| Step: 9
Training loss: 1.6652138233184814
Validation loss: 2.204228525520653

Epoch: 5| Step: 10
Training loss: 2.06213641166687
Validation loss: 2.231677588596139

Epoch: 279| Step: 0
Training loss: 1.8304815292358398
Validation loss: 2.262488224173105

Epoch: 5| Step: 1
Training loss: 2.15701961517334
Validation loss: 2.230605812482936

Epoch: 5| Step: 2
Training loss: 2.0461184978485107
Validation loss: 2.2334387033216414

Epoch: 5| Step: 3
Training loss: 1.9079723358154297
Validation loss: 2.1833671523678686

Epoch: 5| Step: 4
Training loss: 2.010275363922119
Validation loss: 2.161051209254931

Epoch: 5| Step: 5
Training loss: 1.8120695352554321
Validation loss: 2.15149748709894

Epoch: 5| Step: 6
Training loss: 1.7703771591186523
Validation loss: 2.1385160210312053

Epoch: 5| Step: 7
Training loss: 2.603546619415283
Validation loss: 2.128278006789505

Epoch: 5| Step: 8
Training loss: 2.0774013996124268
Validation loss: 2.137111576654578

Epoch: 5| Step: 9
Training loss: 1.8845924139022827
Validation loss: 2.1080919568256666

Epoch: 5| Step: 10
Training loss: 2.669384002685547
Validation loss: 2.1089975910802043

Epoch: 280| Step: 0
Training loss: 2.092486619949341
Validation loss: 2.109603520362608

Epoch: 5| Step: 1
Training loss: 1.8575098514556885
Validation loss: 2.0904284600288636

Epoch: 5| Step: 2
Training loss: 2.14359974861145
Validation loss: 2.0904368944065546

Epoch: 5| Step: 3
Training loss: 1.9860318899154663
Validation loss: 2.102755114596377

Epoch: 5| Step: 4
Training loss: 1.7440500259399414
Validation loss: 2.1055396218453684

Epoch: 5| Step: 5
Training loss: 2.2580201625823975
Validation loss: 2.115879838184644

Epoch: 5| Step: 6
Training loss: 1.6880840063095093
Validation loss: 2.133013081806962

Epoch: 5| Step: 7
Training loss: 2.2695794105529785
Validation loss: 2.1330115333680184

Epoch: 5| Step: 8
Training loss: 2.1189537048339844
Validation loss: 2.1295595809977543

Epoch: 5| Step: 9
Training loss: 2.3013696670532227
Validation loss: 2.1424904433629846

Epoch: 5| Step: 10
Training loss: 2.0792787075042725
Validation loss: 2.145206561652563

Epoch: 281| Step: 0
Training loss: 1.7737003564834595
Validation loss: 2.1568217444163498

Epoch: 5| Step: 1
Training loss: 2.270425319671631
Validation loss: 2.1925502438699045

Epoch: 5| Step: 2
Training loss: 1.7554302215576172
Validation loss: 2.160637791438769

Epoch: 5| Step: 3
Training loss: 1.9782741069793701
Validation loss: 2.1632240613301597

Epoch: 5| Step: 4
Training loss: 2.4238815307617188
Validation loss: 2.1461384937327397

Epoch: 5| Step: 5
Training loss: 1.8187801837921143
Validation loss: 2.1407164168614212

Epoch: 5| Step: 6
Training loss: 2.466078519821167
Validation loss: 2.1345859278914747

Epoch: 5| Step: 7
Training loss: 2.5637247562408447
Validation loss: 2.11217281510753

Epoch: 5| Step: 8
Training loss: 2.035632848739624
Validation loss: 2.116202090376167

Epoch: 5| Step: 9
Training loss: 1.7354021072387695
Validation loss: 2.1098909967689106

Epoch: 5| Step: 10
Training loss: 1.5507705211639404
Validation loss: 2.1219066855727986

Epoch: 282| Step: 0
Training loss: 2.2063305377960205
Validation loss: 2.1267163292054208

Epoch: 5| Step: 1
Training loss: 2.21498703956604
Validation loss: 2.149661652503475

Epoch: 5| Step: 2
Training loss: 2.070343494415283
Validation loss: 2.1390454846043743

Epoch: 5| Step: 3
Training loss: 2.813829183578491
Validation loss: 2.1446408020552767

Epoch: 5| Step: 4
Training loss: 2.435635805130005
Validation loss: 2.159666215219805

Epoch: 5| Step: 5
Training loss: 1.7919957637786865
Validation loss: 2.171403310632193

Epoch: 5| Step: 6
Training loss: 1.8124380111694336
Validation loss: 2.2121482767084593

Epoch: 5| Step: 7
Training loss: 1.9334917068481445
Validation loss: 2.2102866531700216

Epoch: 5| Step: 8
Training loss: 2.3040754795074463
Validation loss: 2.207108602728895

Epoch: 5| Step: 9
Training loss: 1.0828580856323242
Validation loss: 2.176874214603055

Epoch: 5| Step: 10
Training loss: 1.6958603858947754
Validation loss: 2.1496653018459195

Epoch: 283| Step: 0
Training loss: 2.849055528640747
Validation loss: 2.1340491566606747

Epoch: 5| Step: 1
Training loss: 1.9629923105239868
Validation loss: 2.1184417073444655

Epoch: 5| Step: 2
Training loss: 2.3382363319396973
Validation loss: 2.0984740052171933

Epoch: 5| Step: 3
Training loss: 1.5310598611831665
Validation loss: 2.0777197371246996

Epoch: 5| Step: 4
Training loss: 2.252615451812744
Validation loss: 2.0780800824524253

Epoch: 5| Step: 5
Training loss: 1.603928804397583
Validation loss: 2.082126284158358

Epoch: 5| Step: 6
Training loss: 1.5363832712173462
Validation loss: 2.0847208807545323

Epoch: 5| Step: 7
Training loss: 2.0384488105773926
Validation loss: 2.101169750254641

Epoch: 5| Step: 8
Training loss: 1.6994796991348267
Validation loss: 2.1081002348212787

Epoch: 5| Step: 9
Training loss: 2.6999874114990234
Validation loss: 2.125901977221171

Epoch: 5| Step: 10
Training loss: 1.7169537544250488
Validation loss: 2.150826831017771

Epoch: 284| Step: 0
Training loss: 1.9003350734710693
Validation loss: 2.160750481390184

Epoch: 5| Step: 1
Training loss: 1.9319183826446533
Validation loss: 2.1836142052886305

Epoch: 5| Step: 2
Training loss: 1.7246145009994507
Validation loss: 2.1742459612507976

Epoch: 5| Step: 3
Training loss: 2.102581739425659
Validation loss: 2.152288157452819

Epoch: 5| Step: 4
Training loss: 2.1949493885040283
Validation loss: 2.1329208804715063

Epoch: 5| Step: 5
Training loss: 1.8072738647460938
Validation loss: 2.111301511846563

Epoch: 5| Step: 6
Training loss: 2.434844493865967
Validation loss: 2.1052103991149576

Epoch: 5| Step: 7
Training loss: 1.9747326374053955
Validation loss: 2.1226600088098997

Epoch: 5| Step: 8
Training loss: 1.6133674383163452
Validation loss: 2.101678830321117

Epoch: 5| Step: 9
Training loss: 1.8277349472045898
Validation loss: 2.1004018424659647

Epoch: 5| Step: 10
Training loss: 2.7616381645202637
Validation loss: 2.112552131375959

Epoch: 285| Step: 0
Training loss: 1.8754386901855469
Validation loss: 2.140827217409688

Epoch: 5| Step: 1
Training loss: 1.6312201023101807
Validation loss: 2.1431825391707884

Epoch: 5| Step: 2
Training loss: 1.8961149454116821
Validation loss: 2.147995302754064

Epoch: 5| Step: 3
Training loss: 2.0151352882385254
Validation loss: 2.1572953808692192

Epoch: 5| Step: 4
Training loss: 1.736335039138794
Validation loss: 2.1721708954021497

Epoch: 5| Step: 5
Training loss: 1.8301852941513062
Validation loss: 2.1720513951393867

Epoch: 5| Step: 6
Training loss: 2.215392589569092
Validation loss: 2.1673513356075493

Epoch: 5| Step: 7
Training loss: 2.2944765090942383
Validation loss: 2.162125397753972

Epoch: 5| Step: 8
Training loss: 2.273197650909424
Validation loss: 2.159924075167666

Epoch: 5| Step: 9
Training loss: 1.9771747589111328
Validation loss: 2.134757670023108

Epoch: 5| Step: 10
Training loss: 2.2926104068756104
Validation loss: 2.1369541178467455

Epoch: 286| Step: 0
Training loss: 1.8942420482635498
Validation loss: 2.135912218401509

Epoch: 5| Step: 1
Training loss: 2.129084348678589
Validation loss: 2.1223453808856267

Epoch: 5| Step: 2
Training loss: 2.0186538696289062
Validation loss: 2.107149424091462

Epoch: 5| Step: 3
Training loss: 1.9530725479125977
Validation loss: 2.118988334491689

Epoch: 5| Step: 4
Training loss: 1.7067384719848633
Validation loss: 2.1141605966834613

Epoch: 5| Step: 5
Training loss: 2.0255815982818604
Validation loss: 2.0954554529600244

Epoch: 5| Step: 6
Training loss: 2.377544403076172
Validation loss: 2.0962280047837125

Epoch: 5| Step: 7
Training loss: 1.944648027420044
Validation loss: 2.0956624887322866

Epoch: 5| Step: 8
Training loss: 1.737025499343872
Validation loss: 2.1075288762328444

Epoch: 5| Step: 9
Training loss: 1.664557695388794
Validation loss: 2.1113645799698366

Epoch: 5| Step: 10
Training loss: 2.5173091888427734
Validation loss: 2.1448208157734205

Epoch: 287| Step: 0
Training loss: 1.6530030965805054
Validation loss: 2.1670395661425847

Epoch: 5| Step: 1
Training loss: 1.6310136318206787
Validation loss: 2.1840413539640364

Epoch: 5| Step: 2
Training loss: 2.510653018951416
Validation loss: 2.207431165120935

Epoch: 5| Step: 3
Training loss: 2.4382967948913574
Validation loss: 2.206043833045549

Epoch: 5| Step: 4
Training loss: 1.8761208057403564
Validation loss: 2.187848691017397

Epoch: 5| Step: 5
Training loss: 1.7719436883926392
Validation loss: 2.1920952566208376

Epoch: 5| Step: 6
Training loss: 1.8228862285614014
Validation loss: 2.190258877251738

Epoch: 5| Step: 7
Training loss: 2.5721051692962646
Validation loss: 2.176325382724885

Epoch: 5| Step: 8
Training loss: 2.1074681282043457
Validation loss: 2.1666228002117527

Epoch: 5| Step: 9
Training loss: 1.5337415933609009
Validation loss: 2.157207700514024

Epoch: 5| Step: 10
Training loss: 1.9321410655975342
Validation loss: 2.1502624211772794

Epoch: 288| Step: 0
Training loss: 2.4769043922424316
Validation loss: 2.1292627037212415

Epoch: 5| Step: 1
Training loss: 2.1195836067199707
Validation loss: 2.1104445175458024

Epoch: 5| Step: 2
Training loss: 1.970819115638733
Validation loss: 2.0901684402137675

Epoch: 5| Step: 3
Training loss: 2.0586934089660645
Validation loss: 2.079781383596441

Epoch: 5| Step: 4
Training loss: 2.047450542449951
Validation loss: 2.084095824149347

Epoch: 5| Step: 5
Training loss: 1.9088302850723267
Validation loss: 2.07915368259594

Epoch: 5| Step: 6
Training loss: 1.3664557933807373
Validation loss: 2.0899921283927014

Epoch: 5| Step: 7
Training loss: 2.1848576068878174
Validation loss: 2.1050294868407713

Epoch: 5| Step: 8
Training loss: 1.5836635828018188
Validation loss: 2.139344024401839

Epoch: 5| Step: 9
Training loss: 2.10145902633667
Validation loss: 2.1717865723435597

Epoch: 5| Step: 10
Training loss: 2.079636573791504
Validation loss: 2.1842664646845993

Epoch: 289| Step: 0
Training loss: 2.058702230453491
Validation loss: 2.1849780082702637

Epoch: 5| Step: 1
Training loss: 1.6665807962417603
Validation loss: 2.1810327447870725

Epoch: 5| Step: 2
Training loss: 1.655113935470581
Validation loss: 2.1532080429856495

Epoch: 5| Step: 3
Training loss: 1.9150460958480835
Validation loss: 2.1271311903512604

Epoch: 5| Step: 4
Training loss: 1.766424536705017
Validation loss: 2.12868046504195

Epoch: 5| Step: 5
Training loss: 1.7544078826904297
Validation loss: 2.1323086151512722

Epoch: 5| Step: 6
Training loss: 2.108182191848755
Validation loss: 2.147701738983072

Epoch: 5| Step: 7
Training loss: 1.6492198705673218
Validation loss: 2.1055861826865905

Epoch: 5| Step: 8
Training loss: 2.931211471557617
Validation loss: 2.1090257244725383

Epoch: 5| Step: 9
Training loss: 2.0139222145080566
Validation loss: 2.1207384576079664

Epoch: 5| Step: 10
Training loss: 2.3310649394989014
Validation loss: 2.1218242773445706

Epoch: 290| Step: 0
Training loss: 1.5266437530517578
Validation loss: 2.137856445004863

Epoch: 5| Step: 1
Training loss: 1.9291982650756836
Validation loss: 2.167634120551489

Epoch: 5| Step: 2
Training loss: 2.1947872638702393
Validation loss: 2.12681181200089

Epoch: 5| Step: 3
Training loss: 2.2985973358154297
Validation loss: 2.123233920784407

Epoch: 5| Step: 4
Training loss: 1.6718435287475586
Validation loss: 2.0872330845043225

Epoch: 5| Step: 5
Training loss: 2.8247456550598145
Validation loss: 2.0643416245778403

Epoch: 5| Step: 6
Training loss: 1.5606918334960938
Validation loss: 2.0653926775019658

Epoch: 5| Step: 7
Training loss: 1.913156509399414
Validation loss: 2.084036921942106

Epoch: 5| Step: 8
Training loss: 2.2329819202423096
Validation loss: 2.085042976563977

Epoch: 5| Step: 9
Training loss: 2.2344374656677246
Validation loss: 2.108305208144649

Epoch: 5| Step: 10
Training loss: 1.696048378944397
Validation loss: 2.1254997150872343

Epoch: 291| Step: 0
Training loss: 2.267380475997925
Validation loss: 2.1657860073992

Epoch: 5| Step: 1
Training loss: 2.081223964691162
Validation loss: 2.1748649433094966

Epoch: 5| Step: 2
Training loss: 2.081359624862671
Validation loss: 2.1600101429929017

Epoch: 5| Step: 3
Training loss: 2.118278980255127
Validation loss: 2.179976991427842

Epoch: 5| Step: 4
Training loss: 1.6992753744125366
Validation loss: 2.134558162381572

Epoch: 5| Step: 5
Training loss: 2.0833323001861572
Validation loss: 2.1503723129149406

Epoch: 5| Step: 6
Training loss: 1.76898193359375
Validation loss: 2.1482316268387662

Epoch: 5| Step: 7
Training loss: 2.118248701095581
Validation loss: 2.1320132388863513

Epoch: 5| Step: 8
Training loss: 1.623936414718628
Validation loss: 2.1379725138346353

Epoch: 5| Step: 9
Training loss: 2.0215628147125244
Validation loss: 2.144400421009269

Epoch: 5| Step: 10
Training loss: 1.750268816947937
Validation loss: 2.121438403283396

Epoch: 292| Step: 0
Training loss: 2.7782974243164062
Validation loss: 2.118523692571989

Epoch: 5| Step: 1
Training loss: 2.028061628341675
Validation loss: 2.1072235581695393

Epoch: 5| Step: 2
Training loss: 1.8048946857452393
Validation loss: 2.125017971120855

Epoch: 5| Step: 3
Training loss: 1.9054632186889648
Validation loss: 2.130104964779269

Epoch: 5| Step: 4
Training loss: 1.5046848058700562
Validation loss: 2.134630366038251

Epoch: 5| Step: 5
Training loss: 1.7153289318084717
Validation loss: 2.13667602821063

Epoch: 5| Step: 6
Training loss: 1.6659786701202393
Validation loss: 2.1514068239478656

Epoch: 5| Step: 7
Training loss: 2.402700662612915
Validation loss: 2.1666961613521782

Epoch: 5| Step: 8
Training loss: 2.1917495727539062
Validation loss: 2.1851394458483626

Epoch: 5| Step: 9
Training loss: 1.8214848041534424
Validation loss: 2.177828082474329

Epoch: 5| Step: 10
Training loss: 1.8266150951385498
Validation loss: 2.123912957406813

Epoch: 293| Step: 0
Training loss: 1.2426636219024658
Validation loss: 2.121851057134649

Epoch: 5| Step: 1
Training loss: 1.884548544883728
Validation loss: 2.0940678247841458

Epoch: 5| Step: 2
Training loss: 1.969840407371521
Validation loss: 2.0934937038729267

Epoch: 5| Step: 3
Training loss: 2.5062661170959473
Validation loss: 2.091106555795157

Epoch: 5| Step: 4
Training loss: 1.6719074249267578
Validation loss: 2.086272090993902

Epoch: 5| Step: 5
Training loss: 2.9901676177978516
Validation loss: 2.0897073579090897

Epoch: 5| Step: 6
Training loss: 1.5041043758392334
Validation loss: 2.0842702773309525

Epoch: 5| Step: 7
Training loss: 1.8085581064224243
Validation loss: 2.10133602798626

Epoch: 5| Step: 8
Training loss: 1.6696077585220337
Validation loss: 2.120889743169149

Epoch: 5| Step: 9
Training loss: 2.137286901473999
Validation loss: 2.113795967512233

Epoch: 5| Step: 10
Training loss: 2.111470937728882
Validation loss: 2.133001204459898

Epoch: 294| Step: 0
Training loss: 2.3918395042419434
Validation loss: 2.1558432361131072

Epoch: 5| Step: 1
Training loss: 1.6620393991470337
Validation loss: 2.196846121100969

Epoch: 5| Step: 2
Training loss: 1.4281108379364014
Validation loss: 2.157850169366406

Epoch: 5| Step: 3
Training loss: 2.3224499225616455
Validation loss: 2.1588200061551985

Epoch: 5| Step: 4
Training loss: 2.112818717956543
Validation loss: 2.129462421581309

Epoch: 5| Step: 5
Training loss: 2.3537306785583496
Validation loss: 2.113950462751491

Epoch: 5| Step: 6
Training loss: 2.0290656089782715
Validation loss: 2.0737690515415643

Epoch: 5| Step: 7
Training loss: 1.2682077884674072
Validation loss: 2.086773672411519

Epoch: 5| Step: 8
Training loss: 2.320739269256592
Validation loss: 2.0981933698859265

Epoch: 5| Step: 9
Training loss: 2.1004245281219482
Validation loss: 2.1060391062049457

Epoch: 5| Step: 10
Training loss: 1.6629921197891235
Validation loss: 2.1173715411975818

Epoch: 295| Step: 0
Training loss: 1.707180380821228
Validation loss: 2.115295430665375

Epoch: 5| Step: 1
Training loss: 1.7965450286865234
Validation loss: 2.128429082132155

Epoch: 5| Step: 2
Training loss: 1.4071424007415771
Validation loss: 2.1218748528470277

Epoch: 5| Step: 3
Training loss: 2.168865919113159
Validation loss: 2.1066726048787436

Epoch: 5| Step: 4
Training loss: 2.246386766433716
Validation loss: 2.1400923395669587

Epoch: 5| Step: 5
Training loss: 2.0722463130950928
Validation loss: 2.1421307799636677

Epoch: 5| Step: 6
Training loss: 1.8820394277572632
Validation loss: 2.148568667391295

Epoch: 5| Step: 7
Training loss: 2.0701744556427
Validation loss: 2.1346096556673766

Epoch: 5| Step: 8
Training loss: 1.553891897201538
Validation loss: 2.135323634711645

Epoch: 5| Step: 9
Training loss: 2.7452597618103027
Validation loss: 2.114636774986021

Epoch: 5| Step: 10
Training loss: 1.697426438331604
Validation loss: 2.0871647686086674

Epoch: 296| Step: 0
Training loss: 1.7864902019500732
Validation loss: 2.0791673403914257

Epoch: 5| Step: 1
Training loss: 2.0421929359436035
Validation loss: 2.078023606731046

Epoch: 5| Step: 2
Training loss: 1.9278955459594727
Validation loss: 2.0960069471789944

Epoch: 5| Step: 3
Training loss: 1.839836835861206
Validation loss: 2.0973084575386456

Epoch: 5| Step: 4
Training loss: 1.7728607654571533
Validation loss: 2.1226013937304096

Epoch: 5| Step: 5
Training loss: 2.0987489223480225
Validation loss: 2.118899755580451

Epoch: 5| Step: 6
Training loss: 1.7120603322982788
Validation loss: 2.1270048631134855

Epoch: 5| Step: 7
Training loss: 2.380896806716919
Validation loss: 2.138124571051649

Epoch: 5| Step: 8
Training loss: 1.859521508216858
Validation loss: 2.1519189214193695

Epoch: 5| Step: 9
Training loss: 1.9606043100357056
Validation loss: 2.1498298542473906

Epoch: 5| Step: 10
Training loss: 1.9050827026367188
Validation loss: 2.152704643946822

Epoch: 297| Step: 0
Training loss: 2.302285671234131
Validation loss: 2.118525843466482

Epoch: 5| Step: 1
Training loss: 2.3583741188049316
Validation loss: 2.113894316457933

Epoch: 5| Step: 2
Training loss: 1.2449971437454224
Validation loss: 2.0980358482688986

Epoch: 5| Step: 3
Training loss: 1.8045251369476318
Validation loss: 2.097907195809067

Epoch: 5| Step: 4
Training loss: 1.485238790512085
Validation loss: 2.079453473450035

Epoch: 5| Step: 5
Training loss: 2.4133949279785156
Validation loss: 2.1028763427529285

Epoch: 5| Step: 6
Training loss: 1.718848466873169
Validation loss: 2.0919274283993627

Epoch: 5| Step: 7
Training loss: 2.5878779888153076
Validation loss: 2.1204263728152037

Epoch: 5| Step: 8
Training loss: 1.8800041675567627
Validation loss: 2.186298753625603

Epoch: 5| Step: 9
Training loss: 1.5664494037628174
Validation loss: 2.2544449965159097

Epoch: 5| Step: 10
Training loss: 2.0824804306030273
Validation loss: 2.242198477509201

Epoch: 298| Step: 0
Training loss: 1.8583112955093384
Validation loss: 2.2351981260443248

Epoch: 5| Step: 1
Training loss: 2.221778392791748
Validation loss: 2.2017853516404347

Epoch: 5| Step: 2
Training loss: 2.2858760356903076
Validation loss: 2.16733012019947

Epoch: 5| Step: 3
Training loss: 1.7155622243881226
Validation loss: 2.12896300900367

Epoch: 5| Step: 4
Training loss: 1.7341228723526
Validation loss: 2.1367487061408257

Epoch: 5| Step: 5
Training loss: 1.3361010551452637
Validation loss: 2.094858013173585

Epoch: 5| Step: 6
Training loss: 1.1270573139190674
Validation loss: 2.1044753520719466

Epoch: 5| Step: 7
Training loss: 2.441962242126465
Validation loss: 2.076407617138278

Epoch: 5| Step: 8
Training loss: 2.1024444103240967
Validation loss: 2.0950059942019883

Epoch: 5| Step: 9
Training loss: 2.448026657104492
Validation loss: 2.09687364485956

Epoch: 5| Step: 10
Training loss: 2.057997226715088
Validation loss: 2.0842313740843084

Epoch: 299| Step: 0
Training loss: 1.9040040969848633
Validation loss: 2.1142048810117986

Epoch: 5| Step: 1
Training loss: 1.8555612564086914
Validation loss: 2.126396268926641

Epoch: 5| Step: 2
Training loss: 2.1499948501586914
Validation loss: 2.112448861522059

Epoch: 5| Step: 3
Training loss: 1.5238500833511353
Validation loss: 2.118597792040917

Epoch: 5| Step: 4
Training loss: 2.0527281761169434
Validation loss: 2.113501666694559

Epoch: 5| Step: 5
Training loss: 1.3399707078933716
Validation loss: 2.1220535770539315

Epoch: 5| Step: 6
Training loss: 2.1329119205474854
Validation loss: 2.1725505885257514

Epoch: 5| Step: 7
Training loss: 2.508133888244629
Validation loss: 2.1788183130243772

Epoch: 5| Step: 8
Training loss: 2.0282535552978516
Validation loss: 2.1839292767227336

Epoch: 5| Step: 9
Training loss: 1.907838225364685
Validation loss: 2.162479651871548

Epoch: 5| Step: 10
Training loss: 2.054574966430664
Validation loss: 2.138433369257117

Epoch: 300| Step: 0
Training loss: 1.8188730478286743
Validation loss: 2.0918592406857397

Epoch: 5| Step: 1
Training loss: 2.239600658416748
Validation loss: 2.068336376579859

Epoch: 5| Step: 2
Training loss: 2.2339839935302734
Validation loss: 2.060816272612541

Epoch: 5| Step: 3
Training loss: 2.0734846591949463
Validation loss: 2.0610760270908313

Epoch: 5| Step: 4
Training loss: 2.481794834136963
Validation loss: 2.0720136562983194

Epoch: 5| Step: 5
Training loss: 1.7173805236816406
Validation loss: 2.063752066704535

Epoch: 5| Step: 6
Training loss: 2.0998311042785645
Validation loss: 2.0675176369246615

Epoch: 5| Step: 7
Training loss: 2.149353504180908
Validation loss: 2.09667125568595

Epoch: 5| Step: 8
Training loss: 1.352847695350647
Validation loss: 2.0926309734262447

Epoch: 5| Step: 9
Training loss: 1.2344386577606201
Validation loss: 2.1004788952489055

Epoch: 5| Step: 10
Training loss: 1.7477996349334717
Validation loss: 2.1151887242512037

Epoch: 301| Step: 0
Training loss: 2.0063600540161133
Validation loss: 2.111920690023771

Epoch: 5| Step: 1
Training loss: 2.941986322402954
Validation loss: 2.1189412237495504

Epoch: 5| Step: 2
Training loss: 1.6742470264434814
Validation loss: 2.1214422410534275

Epoch: 5| Step: 3
Training loss: 1.5216015577316284
Validation loss: 2.126733427406639

Epoch: 5| Step: 4
Training loss: 1.763641119003296
Validation loss: 2.0945435390677503

Epoch: 5| Step: 5
Training loss: 1.5438239574432373
Validation loss: 2.093447789069145

Epoch: 5| Step: 6
Training loss: 2.2136127948760986
Validation loss: 2.082403063774109

Epoch: 5| Step: 7
Training loss: 1.7499475479125977
Validation loss: 2.076126194769336

Epoch: 5| Step: 8
Training loss: 1.7665634155273438
Validation loss: 2.0960320759845037

Epoch: 5| Step: 9
Training loss: 1.5947173833847046
Validation loss: 2.09212314954368

Epoch: 5| Step: 10
Training loss: 2.09898042678833
Validation loss: 2.1062973058351906

Epoch: 302| Step: 0
Training loss: 1.9643898010253906
Validation loss: 2.111272237634146

Epoch: 5| Step: 1
Training loss: 2.660043239593506
Validation loss: 2.1236907282183246

Epoch: 5| Step: 2
Training loss: 2.047750949859619
Validation loss: 2.1454572062338553

Epoch: 5| Step: 3
Training loss: 1.8297561407089233
Validation loss: 2.141785051233025

Epoch: 5| Step: 4
Training loss: 1.9692480564117432
Validation loss: 2.1390443258388068

Epoch: 5| Step: 5
Training loss: 1.1505767107009888
Validation loss: 2.1536829702315794

Epoch: 5| Step: 6
Training loss: 1.9291801452636719
Validation loss: 2.1423944734757945

Epoch: 5| Step: 7
Training loss: 1.6500688791275024
Validation loss: 2.1478036116528254

Epoch: 5| Step: 8
Training loss: 1.8375438451766968
Validation loss: 2.1270471567748697

Epoch: 5| Step: 9
Training loss: 1.9272489547729492
Validation loss: 2.112508202111849

Epoch: 5| Step: 10
Training loss: 1.5882532596588135
Validation loss: 2.1006040239846833

Epoch: 303| Step: 0
Training loss: 1.9948657751083374
Validation loss: 2.1018811220763833

Epoch: 5| Step: 1
Training loss: 1.9205173254013062
Validation loss: 2.0916021370118663

Epoch: 5| Step: 2
Training loss: 2.0896198749542236
Validation loss: 2.0836587285482757

Epoch: 5| Step: 3
Training loss: 1.3085672855377197
Validation loss: 2.0938480489997455

Epoch: 5| Step: 4
Training loss: 1.584498405456543
Validation loss: 2.068772174978769

Epoch: 5| Step: 5
Training loss: 1.8654314279556274
Validation loss: 2.064510909459924

Epoch: 5| Step: 6
Training loss: 1.7366688251495361
Validation loss: 2.0816774701559417

Epoch: 5| Step: 7
Training loss: 2.0854930877685547
Validation loss: 2.0985893562275875

Epoch: 5| Step: 8
Training loss: 2.5631203651428223
Validation loss: 2.0887352343528502

Epoch: 5| Step: 9
Training loss: 1.663412094116211
Validation loss: 2.113613833663284

Epoch: 5| Step: 10
Training loss: 1.8085951805114746
Validation loss: 2.1328499470987627

Epoch: 304| Step: 0
Training loss: 1.618307113647461
Validation loss: 2.1410369283409527

Epoch: 5| Step: 1
Training loss: 2.036048412322998
Validation loss: 2.1712530877000544

Epoch: 5| Step: 2
Training loss: 2.00122332572937
Validation loss: 2.1514883759201213

Epoch: 5| Step: 3
Training loss: 1.5469229221343994
Validation loss: 2.1401047322057907

Epoch: 5| Step: 4
Training loss: 1.418434739112854
Validation loss: 2.1185184422359673

Epoch: 5| Step: 5
Training loss: 1.710563063621521
Validation loss: 2.0710973021804646

Epoch: 5| Step: 6
Training loss: 1.9821678400039673
Validation loss: 2.065623667932326

Epoch: 5| Step: 7
Training loss: 2.381744146347046
Validation loss: 2.0773052092521422

Epoch: 5| Step: 8
Training loss: 1.9801762104034424
Validation loss: 2.0692256048161495

Epoch: 5| Step: 9
Training loss: 2.268887758255005
Validation loss: 2.0763953014086654

Epoch: 5| Step: 10
Training loss: 1.732442855834961
Validation loss: 2.060359275469216

Epoch: 305| Step: 0
Training loss: 1.6356217861175537
Validation loss: 2.0720947134879326

Epoch: 5| Step: 1
Training loss: 1.4721965789794922
Validation loss: 2.0727913097668718

Epoch: 5| Step: 2
Training loss: 1.9419100284576416
Validation loss: 2.095177230014596

Epoch: 5| Step: 3
Training loss: 1.4657037258148193
Validation loss: 2.1077641210248395

Epoch: 5| Step: 4
Training loss: 1.8490413427352905
Validation loss: 2.126531724006899

Epoch: 5| Step: 5
Training loss: 2.5980308055877686
Validation loss: 2.1229517870051886

Epoch: 5| Step: 6
Training loss: 2.022195816040039
Validation loss: 2.1445853402537685

Epoch: 5| Step: 7
Training loss: 1.7730270624160767
Validation loss: 2.16480069006643

Epoch: 5| Step: 8
Training loss: 1.2471387386322021
Validation loss: 2.1742928694653254

Epoch: 5| Step: 9
Training loss: 2.4420247077941895
Validation loss: 2.1708353629676242

Epoch: 5| Step: 10
Training loss: 2.1762940883636475
Validation loss: 2.172789324996292

Epoch: 306| Step: 0
Training loss: 1.6090774536132812
Validation loss: 2.1340881855257097

Epoch: 5| Step: 1
Training loss: 2.000997304916382
Validation loss: 2.1219414229034097

Epoch: 5| Step: 2
Training loss: 1.59856379032135
Validation loss: 2.071685162923669

Epoch: 5| Step: 3
Training loss: 1.851952314376831
Validation loss: 2.056363663365764

Epoch: 5| Step: 4
Training loss: 1.593788504600525
Validation loss: 2.053706404983356

Epoch: 5| Step: 5
Training loss: 1.9943797588348389
Validation loss: 2.0538842267887567

Epoch: 5| Step: 6
Training loss: 2.215801954269409
Validation loss: 2.0583246651516167

Epoch: 5| Step: 7
Training loss: 1.50767982006073
Validation loss: 2.0779476422135548

Epoch: 5| Step: 8
Training loss: 1.8283298015594482
Validation loss: 2.0969240332162506

Epoch: 5| Step: 9
Training loss: 2.0838656425476074
Validation loss: 2.1363655264659593

Epoch: 5| Step: 10
Training loss: 2.424546003341675
Validation loss: 2.1512986870222193

Epoch: 307| Step: 0
Training loss: 1.8988507986068726
Validation loss: 2.140713155910533

Epoch: 5| Step: 1
Training loss: 1.6833120584487915
Validation loss: 2.1603836346698064

Epoch: 5| Step: 2
Training loss: 2.3257477283477783
Validation loss: 2.1364151175304125

Epoch: 5| Step: 3
Training loss: 1.527762532234192
Validation loss: 2.13755585429489

Epoch: 5| Step: 4
Training loss: 1.8543193340301514
Validation loss: 2.119901554558867

Epoch: 5| Step: 5
Training loss: 1.7412612438201904
Validation loss: 2.1052255476674726

Epoch: 5| Step: 6
Training loss: 2.123508930206299
Validation loss: 2.1060108856488298

Epoch: 5| Step: 7
Training loss: 1.7775968313217163
Validation loss: 2.0976559372358423

Epoch: 5| Step: 8
Training loss: 1.8671993017196655
Validation loss: 2.116837052888768

Epoch: 5| Step: 9
Training loss: 1.5496230125427246
Validation loss: 2.1199378890375935

Epoch: 5| Step: 10
Training loss: 2.125505208969116
Validation loss: 2.121862970372682

Epoch: 308| Step: 0
Training loss: 1.4519445896148682
Validation loss: 2.1330074341066423

Epoch: 5| Step: 1
Training loss: 1.9581091403961182
Validation loss: 2.1451393891406316

Epoch: 5| Step: 2
Training loss: 1.5816987752914429
Validation loss: 2.1188636646475842

Epoch: 5| Step: 3
Training loss: 1.722508192062378
Validation loss: 2.1098940064830165

Epoch: 5| Step: 4
Training loss: 1.750293493270874
Validation loss: 2.1474505393735823

Epoch: 5| Step: 5
Training loss: 1.913575530052185
Validation loss: 2.1346187207006637

Epoch: 5| Step: 6
Training loss: 2.4422364234924316
Validation loss: 2.1522444473799838

Epoch: 5| Step: 7
Training loss: 1.92138671875
Validation loss: 2.1373367976116877

Epoch: 5| Step: 8
Training loss: 1.6897834539413452
Validation loss: 2.0994014945081485

Epoch: 5| Step: 9
Training loss: 1.9442269802093506
Validation loss: 2.080720196488083

Epoch: 5| Step: 10
Training loss: 1.940886378288269
Validation loss: 2.0385421014601186

Epoch: 309| Step: 0
Training loss: 2.0049126148223877
Validation loss: 2.043856647706801

Epoch: 5| Step: 1
Training loss: 1.9807052612304688
Validation loss: 2.0429787687076035

Epoch: 5| Step: 2
Training loss: 1.7210441827774048
Validation loss: 2.040287652323323

Epoch: 5| Step: 3
Training loss: 1.9517278671264648
Validation loss: 2.0481913038479385

Epoch: 5| Step: 4
Training loss: 1.5772929191589355
Validation loss: 2.075888910601216

Epoch: 5| Step: 5
Training loss: 1.8088948726654053
Validation loss: 2.0956206680625997

Epoch: 5| Step: 6
Training loss: 2.066636562347412
Validation loss: 2.1040665846998974

Epoch: 5| Step: 7
Training loss: 2.074071168899536
Validation loss: 2.1254920318562496

Epoch: 5| Step: 8
Training loss: 1.737994909286499
Validation loss: 2.102904518445333

Epoch: 5| Step: 9
Training loss: 1.7361036539077759
Validation loss: 2.0944794429245817

Epoch: 5| Step: 10
Training loss: 1.910664677619934
Validation loss: 2.0875717157958658

Epoch: 310| Step: 0
Training loss: 1.4771881103515625
Validation loss: 2.0832875236388175

Epoch: 5| Step: 1
Training loss: 1.543381929397583
Validation loss: 2.102939713385797

Epoch: 5| Step: 2
Training loss: 1.9077125787734985
Validation loss: 2.1108613065494004

Epoch: 5| Step: 3
Training loss: 1.8628575801849365
Validation loss: 2.11075912239731

Epoch: 5| Step: 4
Training loss: 2.072969436645508
Validation loss: 2.1478617063132663

Epoch: 5| Step: 5
Training loss: 2.213085174560547
Validation loss: 2.139731007237588

Epoch: 5| Step: 6
Training loss: 1.8589999675750732
Validation loss: 2.1229064221023233

Epoch: 5| Step: 7
Training loss: 2.497537612915039
Validation loss: 2.121441856507332

Epoch: 5| Step: 8
Training loss: 1.5575132369995117
Validation loss: 2.1307099301327943

Epoch: 5| Step: 9
Training loss: 1.8357584476470947
Validation loss: 2.111551184808054

Epoch: 5| Step: 10
Training loss: 1.6671817302703857
Validation loss: 2.102199900534845

Epoch: 311| Step: 0
Training loss: 2.1481337547302246
Validation loss: 2.090545295387186

Epoch: 5| Step: 1
Training loss: 2.2192158699035645
Validation loss: 2.0853875452472317

Epoch: 5| Step: 2
Training loss: 1.8432029485702515
Validation loss: 2.0592861124264297

Epoch: 5| Step: 3
Training loss: 2.4560306072235107
Validation loss: 2.062945068523448

Epoch: 5| Step: 4
Training loss: 1.7467950582504272
Validation loss: 2.069911826041437

Epoch: 5| Step: 5
Training loss: 1.769635796546936
Validation loss: 2.087540472707441

Epoch: 5| Step: 6
Training loss: 1.92317795753479
Validation loss: 2.0909773470253072

Epoch: 5| Step: 7
Training loss: 1.8135411739349365
Validation loss: 2.0562936106035785

Epoch: 5| Step: 8
Training loss: 1.9419037103652954
Validation loss: 2.048036911154306

Epoch: 5| Step: 9
Training loss: 1.0627425909042358
Validation loss: 2.0396039665386243

Epoch: 5| Step: 10
Training loss: 1.697205662727356
Validation loss: 2.053948626723341

Epoch: 312| Step: 0
Training loss: 1.6730800867080688
Validation loss: 2.074172475004709

Epoch: 5| Step: 1
Training loss: 1.678977608680725
Validation loss: 2.0813233903659287

Epoch: 5| Step: 2
Training loss: 2.0493531227111816
Validation loss: 2.095347317316199

Epoch: 5| Step: 3
Training loss: 1.9414316415786743
Validation loss: 2.11395445177632

Epoch: 5| Step: 4
Training loss: 1.4252593517303467
Validation loss: 2.1377203528599074

Epoch: 5| Step: 5
Training loss: 2.4854636192321777
Validation loss: 2.141675096686168

Epoch: 5| Step: 6
Training loss: 1.636620283126831
Validation loss: 2.1212215269765546

Epoch: 5| Step: 7
Training loss: 1.9100147485733032
Validation loss: 2.1192456060840237

Epoch: 5| Step: 8
Training loss: 1.8495724201202393
Validation loss: 2.115439684160294

Epoch: 5| Step: 9
Training loss: 1.6566250324249268
Validation loss: 2.1406257921649563

Epoch: 5| Step: 10
Training loss: 1.8839678764343262
Validation loss: 2.150794347127279

Epoch: 313| Step: 0
Training loss: 1.6007792949676514
Validation loss: 2.1597552914773264

Epoch: 5| Step: 1
Training loss: 1.5914983749389648
Validation loss: 2.1339485696567

Epoch: 5| Step: 2
Training loss: 1.8268496990203857
Validation loss: 2.132112382560648

Epoch: 5| Step: 3
Training loss: 1.8534669876098633
Validation loss: 2.1054799582368586

Epoch: 5| Step: 4
Training loss: 1.5764049291610718
Validation loss: 2.1118455497167443

Epoch: 5| Step: 5
Training loss: 1.8695201873779297
Validation loss: 2.111286278693907

Epoch: 5| Step: 6
Training loss: 2.0402190685272217
Validation loss: 2.090094309981151

Epoch: 5| Step: 7
Training loss: 2.018738269805908
Validation loss: 2.0733095907395884

Epoch: 5| Step: 8
Training loss: 1.7902536392211914
Validation loss: 2.053611073442685

Epoch: 5| Step: 9
Training loss: 2.1248300075531006
Validation loss: 2.0568790179426952

Epoch: 5| Step: 10
Training loss: 1.6159980297088623
Validation loss: 2.0678892648348244

Epoch: 314| Step: 0
Training loss: 1.337725043296814
Validation loss: 2.0916972185975764

Epoch: 5| Step: 1
Training loss: 1.784494400024414
Validation loss: 2.1006574015463553

Epoch: 5| Step: 2
Training loss: 2.657719373703003
Validation loss: 2.131569516274237

Epoch: 5| Step: 3
Training loss: 1.5985718965530396
Validation loss: 2.1034853202040478

Epoch: 5| Step: 4
Training loss: 1.400144100189209
Validation loss: 2.1046099073143414

Epoch: 5| Step: 5
Training loss: 2.2647836208343506
Validation loss: 2.053406761538598

Epoch: 5| Step: 6
Training loss: 1.8057769536972046
Validation loss: 2.068013030995605

Epoch: 5| Step: 7
Training loss: 1.4956657886505127
Validation loss: 2.070413927878103

Epoch: 5| Step: 8
Training loss: 1.9275497198104858
Validation loss: 2.0698031840785855

Epoch: 5| Step: 9
Training loss: 1.9632513523101807
Validation loss: 2.0819278878550374

Epoch: 5| Step: 10
Training loss: 1.7277376651763916
Validation loss: 2.07959956635711

Epoch: 315| Step: 0
Training loss: 1.6407649517059326
Validation loss: 2.065130288882922

Epoch: 5| Step: 1
Training loss: 1.899019479751587
Validation loss: 2.073731635206489

Epoch: 5| Step: 2
Training loss: 1.449815034866333
Validation loss: 2.0942371814481673

Epoch: 5| Step: 3
Training loss: 1.7953498363494873
Validation loss: 2.075192347649605

Epoch: 5| Step: 4
Training loss: 1.3963737487792969
Validation loss: 2.085983391731016

Epoch: 5| Step: 5
Training loss: 2.3440728187561035
Validation loss: 2.099772616099286

Epoch: 5| Step: 6
Training loss: 1.9008800983428955
Validation loss: 2.096122608389906

Epoch: 5| Step: 7
Training loss: 2.014080286026001
Validation loss: 2.1145062369685017

Epoch: 5| Step: 8
Training loss: 1.7279659509658813
Validation loss: 2.13777401626751

Epoch: 5| Step: 9
Training loss: 2.1416022777557373
Validation loss: 2.1500825471775507

Epoch: 5| Step: 10
Training loss: 1.2967387437820435
Validation loss: 2.135139637095954

Epoch: 316| Step: 0
Training loss: 1.2876449823379517
Validation loss: 2.111438892220938

Epoch: 5| Step: 1
Training loss: 2.033898115158081
Validation loss: 2.1131510901194748

Epoch: 5| Step: 2
Training loss: 2.3319039344787598
Validation loss: 2.117157038821969

Epoch: 5| Step: 3
Training loss: 2.047179698944092
Validation loss: 2.1023398227589105

Epoch: 5| Step: 4
Training loss: 1.9955295324325562
Validation loss: 2.0911168962396602

Epoch: 5| Step: 5
Training loss: 1.5397599935531616
Validation loss: 2.097861454051028

Epoch: 5| Step: 6
Training loss: 1.752563714981079
Validation loss: 2.0836958013555056

Epoch: 5| Step: 7
Training loss: 2.101264476776123
Validation loss: 2.106477201625865

Epoch: 5| Step: 8
Training loss: 1.521050214767456
Validation loss: 2.0812551590704147

Epoch: 5| Step: 9
Training loss: 1.6025810241699219
Validation loss: 2.0638056544847387

Epoch: 5| Step: 10
Training loss: 1.6440744400024414
Validation loss: 2.081040187548566

Epoch: 317| Step: 0
Training loss: 2.117356538772583
Validation loss: 2.101366614782682

Epoch: 5| Step: 1
Training loss: 2.3172197341918945
Validation loss: 2.124056572555214

Epoch: 5| Step: 2
Training loss: 1.7620242834091187
Validation loss: 2.1276230837709162

Epoch: 5| Step: 3
Training loss: 1.2726292610168457
Validation loss: 2.1224157566665323

Epoch: 5| Step: 4
Training loss: 1.7638477087020874
Validation loss: 2.1285506627892934

Epoch: 5| Step: 5
Training loss: 1.3586804866790771
Validation loss: 2.1234280986170613

Epoch: 5| Step: 6
Training loss: 1.5084731578826904
Validation loss: 2.1070025813195015

Epoch: 5| Step: 7
Training loss: 1.7352573871612549
Validation loss: 2.134118257030364

Epoch: 5| Step: 8
Training loss: 1.6073427200317383
Validation loss: 2.158172530512656

Epoch: 5| Step: 9
Training loss: 2.2109732627868652
Validation loss: 2.1756430082423712

Epoch: 5| Step: 10
Training loss: 1.9532643556594849
Validation loss: 2.1747595853702997

Epoch: 318| Step: 0
Training loss: 1.559749960899353
Validation loss: 2.1127648045939784

Epoch: 5| Step: 1
Training loss: 1.1800081729888916
Validation loss: 2.0830417768929594

Epoch: 5| Step: 2
Training loss: 1.66720449924469
Validation loss: 2.07006359997616

Epoch: 5| Step: 3
Training loss: 1.6353394985198975
Validation loss: 2.0557859097757647

Epoch: 5| Step: 4
Training loss: 2.43481707572937
Validation loss: 2.0336396412182878

Epoch: 5| Step: 5
Training loss: 1.610736608505249
Validation loss: 2.049769296441027

Epoch: 5| Step: 6
Training loss: 2.224790096282959
Validation loss: 2.0540125818662744

Epoch: 5| Step: 7
Training loss: 1.6983048915863037
Validation loss: 2.060257557899721

Epoch: 5| Step: 8
Training loss: 1.4699068069458008
Validation loss: 2.0946640891413533

Epoch: 5| Step: 9
Training loss: 2.284311294555664
Validation loss: 2.1109648032854964

Epoch: 5| Step: 10
Training loss: 1.7715578079223633
Validation loss: 2.11281886792952

Epoch: 319| Step: 0
Training loss: 2.0288851261138916
Validation loss: 2.1532782585390153

Epoch: 5| Step: 1
Training loss: 2.0239062309265137
Validation loss: 2.1726534135880007

Epoch: 5| Step: 2
Training loss: 1.6633479595184326
Validation loss: 2.1791020772790395

Epoch: 5| Step: 3
Training loss: 1.8871791362762451
Validation loss: 2.160490741011917

Epoch: 5| Step: 4
Training loss: 1.1273826360702515
Validation loss: 2.1205630840793734

Epoch: 5| Step: 5
Training loss: 1.6122620105743408
Validation loss: 2.1041475008892756

Epoch: 5| Step: 6
Training loss: 1.6294965744018555
Validation loss: 2.132959831145502

Epoch: 5| Step: 7
Training loss: 1.5755116939544678
Validation loss: 2.1389469677402126

Epoch: 5| Step: 8
Training loss: 1.6386382579803467
Validation loss: 2.142842374822145

Epoch: 5| Step: 9
Training loss: 2.0628693103790283
Validation loss: 2.135433973804597

Epoch: 5| Step: 10
Training loss: 2.2967326641082764
Validation loss: 2.159099619875672

Epoch: 320| Step: 0
Training loss: 1.5777878761291504
Validation loss: 2.143350621705414

Epoch: 5| Step: 1
Training loss: 1.6661478281021118
Validation loss: 2.154838861957673

Epoch: 5| Step: 2
Training loss: 1.5724778175354004
Validation loss: 2.1490211807271486

Epoch: 5| Step: 3
Training loss: 2.1397533416748047
Validation loss: 2.1447631133499967

Epoch: 5| Step: 4
Training loss: 1.996368408203125
Validation loss: 2.142140242361253

Epoch: 5| Step: 5
Training loss: 1.8742625713348389
Validation loss: 2.0980162312907558

Epoch: 5| Step: 6
Training loss: 1.5873901844024658
Validation loss: 2.0847538325094406

Epoch: 5| Step: 7
Training loss: 1.8540589809417725
Validation loss: 2.053327992398252

Epoch: 5| Step: 8
Training loss: 1.5305989980697632
Validation loss: 2.069696525091766

Epoch: 5| Step: 9
Training loss: 1.3130916357040405
Validation loss: 2.0666438225776917

Epoch: 5| Step: 10
Training loss: 2.2271838188171387
Validation loss: 2.0370479552976546

Epoch: 321| Step: 0
Training loss: 1.4835227727890015
Validation loss: 2.064854386032269

Epoch: 5| Step: 1
Training loss: 2.366853713989258
Validation loss: 2.06467798192014

Epoch: 5| Step: 2
Training loss: 1.4626400470733643
Validation loss: 2.07616336371309

Epoch: 5| Step: 3
Training loss: 2.008718490600586
Validation loss: 2.1236117321957826

Epoch: 5| Step: 4
Training loss: 1.9460262060165405
Validation loss: 2.091604826270893

Epoch: 5| Step: 5
Training loss: 1.6924097537994385
Validation loss: 2.1136472212371005

Epoch: 5| Step: 6
Training loss: 1.147283673286438
Validation loss: 2.1382834270436275

Epoch: 5| Step: 7
Training loss: 1.3857285976409912
Validation loss: 2.162863100728681

Epoch: 5| Step: 8
Training loss: 2.4111487865448
Validation loss: 2.1578548967197375

Epoch: 5| Step: 9
Training loss: 2.136353015899658
Validation loss: 2.1396464173511793

Epoch: 5| Step: 10
Training loss: 1.430212378501892
Validation loss: 2.1104782858202533

Epoch: 322| Step: 0
Training loss: 1.6605987548828125
Validation loss: 2.0845476863204793

Epoch: 5| Step: 1
Training loss: 2.1009976863861084
Validation loss: 2.0818689433477258

Epoch: 5| Step: 2
Training loss: 1.6755626201629639
Validation loss: 2.0852618909651235

Epoch: 5| Step: 3
Training loss: 1.8841640949249268
Validation loss: 2.0708838919157624

Epoch: 5| Step: 4
Training loss: 2.1243269443511963
Validation loss: 2.071784210461442

Epoch: 5| Step: 5
Training loss: 1.2234013080596924
Validation loss: 2.078274237212314

Epoch: 5| Step: 6
Training loss: 1.8422149419784546
Validation loss: 2.102940856769521

Epoch: 5| Step: 7
Training loss: 0.9677547216415405
Validation loss: 2.1286609621458155

Epoch: 5| Step: 8
Training loss: 1.7494500875473022
Validation loss: 2.146156936563471

Epoch: 5| Step: 9
Training loss: 2.3521530628204346
Validation loss: 2.1641443365363666

Epoch: 5| Step: 10
Training loss: 1.839737892150879
Validation loss: 2.1447835968386744

Epoch: 323| Step: 0
Training loss: 1.9503567218780518
Validation loss: 2.12192012417701

Epoch: 5| Step: 1
Training loss: 1.8168236017227173
Validation loss: 2.1146108104336645

Epoch: 5| Step: 2
Training loss: 1.4837956428527832
Validation loss: 2.074731872927758

Epoch: 5| Step: 3
Training loss: 1.6633100509643555
Validation loss: 2.086199116963212

Epoch: 5| Step: 4
Training loss: 1.3384068012237549
Validation loss: 2.095094624386039

Epoch: 5| Step: 5
Training loss: 1.6490166187286377
Validation loss: 2.107371002115229

Epoch: 5| Step: 6
Training loss: 2.109158992767334
Validation loss: 2.0896102254108717

Epoch: 5| Step: 7
Training loss: 1.8406641483306885
Validation loss: 2.1308857240984516

Epoch: 5| Step: 8
Training loss: 1.5799263715744019
Validation loss: 2.1493563857129825

Epoch: 5| Step: 9
Training loss: 1.7699276208877563
Validation loss: 2.137488067791026

Epoch: 5| Step: 10
Training loss: 2.0065770149230957
Validation loss: 2.15858248613214

Epoch: 324| Step: 0
Training loss: 1.5410865545272827
Validation loss: 2.126732721123644

Epoch: 5| Step: 1
Training loss: 1.449044942855835
Validation loss: 2.119314261662063

Epoch: 5| Step: 2
Training loss: 2.3151180744171143
Validation loss: 2.166076011555169

Epoch: 5| Step: 3
Training loss: 1.9468374252319336
Validation loss: 2.186072628985169

Epoch: 5| Step: 4
Training loss: 1.8523164987564087
Validation loss: 2.1777760777422177

Epoch: 5| Step: 5
Training loss: 1.608515977859497
Validation loss: 2.17387891328463

Epoch: 5| Step: 6
Training loss: 1.496522307395935
Validation loss: 2.116626065264466

Epoch: 5| Step: 7
Training loss: 1.224587082862854
Validation loss: 2.0654714261331866

Epoch: 5| Step: 8
Training loss: 1.8767473697662354
Validation loss: 2.049385275892032

Epoch: 5| Step: 9
Training loss: 1.8096774816513062
Validation loss: 2.0423256222919752

Epoch: 5| Step: 10
Training loss: 2.101999282836914
Validation loss: 2.090807295614673

Epoch: 325| Step: 0
Training loss: 1.5160915851593018
Validation loss: 2.0941142728251796

Epoch: 5| Step: 1
Training loss: 2.073606014251709
Validation loss: 2.119417154660789

Epoch: 5| Step: 2
Training loss: 1.6872937679290771
Validation loss: 2.0981713520583285

Epoch: 5| Step: 3
Training loss: 2.1883926391601562
Validation loss: 2.1112406369178527

Epoch: 5| Step: 4
Training loss: 1.5301889181137085
Validation loss: 2.1405088824610554

Epoch: 5| Step: 5
Training loss: 1.5884363651275635
Validation loss: 2.1886819331876692

Epoch: 5| Step: 6
Training loss: 1.9307734966278076
Validation loss: 2.2061093507274503

Epoch: 5| Step: 7
Training loss: 1.8202192783355713
Validation loss: 2.2379156145998227

Epoch: 5| Step: 8
Training loss: 1.8951740264892578
Validation loss: 2.2085198484441286

Epoch: 5| Step: 9
Training loss: 2.0234744548797607
Validation loss: 2.1971234557449177

Epoch: 5| Step: 10
Training loss: 1.704084038734436
Validation loss: 2.106096492018751

Epoch: 326| Step: 0
Training loss: 2.3546550273895264
Validation loss: 2.0954579896824335

Epoch: 5| Step: 1
Training loss: 1.9135303497314453
Validation loss: 2.051049719574631

Epoch: 5| Step: 2
Training loss: 1.5817172527313232
Validation loss: 2.0707966076430453

Epoch: 5| Step: 3
Training loss: 1.660504698753357
Validation loss: 2.073789470939226

Epoch: 5| Step: 4
Training loss: 1.9481134414672852
Validation loss: 2.076292132818571

Epoch: 5| Step: 5
Training loss: 1.8292839527130127
Validation loss: 2.1378587907360447

Epoch: 5| Step: 6
Training loss: 1.7873222827911377
Validation loss: 2.152915423916232

Epoch: 5| Step: 7
Training loss: 1.1621615886688232
Validation loss: 2.130689891435767

Epoch: 5| Step: 8
Training loss: 1.8973697423934937
Validation loss: 2.131474651316161

Epoch: 5| Step: 9
Training loss: 1.5223716497421265
Validation loss: 2.131656810801516

Epoch: 5| Step: 10
Training loss: 1.5298850536346436
Validation loss: 2.130770367960776

Epoch: 327| Step: 0
Training loss: 1.6861717700958252
Validation loss: 2.103652810537687

Epoch: 5| Step: 1
Training loss: 1.9129273891448975
Validation loss: 2.081616404236004

Epoch: 5| Step: 2
Training loss: 2.1087985038757324
Validation loss: 2.032200715875113

Epoch: 5| Step: 3
Training loss: 1.6076122522354126
Validation loss: 2.031982360347625

Epoch: 5| Step: 4
Training loss: 1.8907819986343384
Validation loss: 2.0239025072384904

Epoch: 5| Step: 5
Training loss: 1.5807180404663086
Validation loss: 2.0446213983720347

Epoch: 5| Step: 6
Training loss: 1.877760887145996
Validation loss: 2.053343471660409

Epoch: 5| Step: 7
Training loss: 1.9406583309173584
Validation loss: 2.0659431103737123

Epoch: 5| Step: 8
Training loss: 1.5249402523040771
Validation loss: 2.1078102511744343

Epoch: 5| Step: 9
Training loss: 1.2308628559112549
Validation loss: 2.1324485809572282

Epoch: 5| Step: 10
Training loss: 1.8350292444229126
Validation loss: 2.188861623887093

Epoch: 328| Step: 0
Training loss: 1.8821117877960205
Validation loss: 2.201456605747182

Epoch: 5| Step: 1
Training loss: 2.035924196243286
Validation loss: 2.2266409012579147

Epoch: 5| Step: 2
Training loss: 2.154632568359375
Validation loss: 2.210142579129947

Epoch: 5| Step: 3
Training loss: 1.7722065448760986
Validation loss: 2.1725424105121243

Epoch: 5| Step: 4
Training loss: 1.4622859954833984
Validation loss: 2.1234686810483216

Epoch: 5| Step: 5
Training loss: 1.6475324630737305
Validation loss: 2.1205480380724837

Epoch: 5| Step: 6
Training loss: 2.108168601989746
Validation loss: 2.094865059339872

Epoch: 5| Step: 7
Training loss: 1.3517303466796875
Validation loss: 2.0768583589984524

Epoch: 5| Step: 8
Training loss: 1.7098491191864014
Validation loss: 2.0580971087178876

Epoch: 5| Step: 9
Training loss: 1.4831430912017822
Validation loss: 2.079618546270555

Epoch: 5| Step: 10
Training loss: 1.412187099456787
Validation loss: 2.067748003108527

Epoch: 329| Step: 0
Training loss: 1.9540584087371826
Validation loss: 2.0983929467457596

Epoch: 5| Step: 1
Training loss: 1.9065742492675781
Validation loss: 2.1156266761082474

Epoch: 5| Step: 2
Training loss: 1.6347293853759766
Validation loss: 2.1412913491649013

Epoch: 5| Step: 3
Training loss: 1.7409019470214844
Validation loss: 2.11388921994035

Epoch: 5| Step: 4
Training loss: 2.5523509979248047
Validation loss: 2.124811170562621

Epoch: 5| Step: 5
Training loss: 1.2511380910873413
Validation loss: 2.1277643660063386

Epoch: 5| Step: 6
Training loss: 1.704218864440918
Validation loss: 2.1176969056488364

Epoch: 5| Step: 7
Training loss: 1.4434436559677124
Validation loss: 2.112856211200837

Epoch: 5| Step: 8
Training loss: 1.7658326625823975
Validation loss: 2.100434341738301

Epoch: 5| Step: 9
Training loss: 1.291015863418579
Validation loss: 2.0950565171498123

Epoch: 5| Step: 10
Training loss: 1.7529590129852295
Validation loss: 2.101067050810783

Epoch: 330| Step: 0
Training loss: 2.011302947998047
Validation loss: 2.0817395538412113

Epoch: 5| Step: 1
Training loss: 1.777541160583496
Validation loss: 2.0714837607517036

Epoch: 5| Step: 2
Training loss: 1.1650464534759521
Validation loss: 2.08054377443047

Epoch: 5| Step: 3
Training loss: 1.9853870868682861
Validation loss: 2.0877626378049134

Epoch: 5| Step: 4
Training loss: 2.105661153793335
Validation loss: 2.1021836983260287

Epoch: 5| Step: 5
Training loss: 1.464238166809082
Validation loss: 2.0989942601931992

Epoch: 5| Step: 6
Training loss: 1.7698720693588257
Validation loss: 2.0724169849067606

Epoch: 5| Step: 7
Training loss: 1.1577155590057373
Validation loss: 2.0880364166793

Epoch: 5| Step: 8
Training loss: 1.547170877456665
Validation loss: 2.096223182575677

Epoch: 5| Step: 9
Training loss: 1.7799880504608154
Validation loss: 2.104405403137207

Epoch: 5| Step: 10
Training loss: 1.9083806276321411
Validation loss: 2.1538671293566303

Epoch: 331| Step: 0
Training loss: 1.4444020986557007
Validation loss: 2.1404832383637786

Epoch: 5| Step: 1
Training loss: 1.9333698749542236
Validation loss: 2.1346801416848296

Epoch: 5| Step: 2
Training loss: 1.5223782062530518
Validation loss: 2.131714859316426

Epoch: 5| Step: 3
Training loss: 2.1632578372955322
Validation loss: 2.1143438162342196

Epoch: 5| Step: 4
Training loss: 1.381296157836914
Validation loss: 2.1088803455393803

Epoch: 5| Step: 5
Training loss: 0.9762386083602905
Validation loss: 2.12809730217021

Epoch: 5| Step: 6
Training loss: 2.0070338249206543
Validation loss: 2.137433659645819

Epoch: 5| Step: 7
Training loss: 1.7358185052871704
Validation loss: 2.1352642838672926

Epoch: 5| Step: 8
Training loss: 2.0713508129119873
Validation loss: 2.1313415470943657

Epoch: 5| Step: 9
Training loss: 1.7930866479873657
Validation loss: 2.114038082861131

Epoch: 5| Step: 10
Training loss: 1.4739940166473389
Validation loss: 2.101827775278399

Epoch: 332| Step: 0
Training loss: 1.5253530740737915
Validation loss: 2.1026564028955277

Epoch: 5| Step: 1
Training loss: 1.3164528608322144
Validation loss: 2.109901899932533

Epoch: 5| Step: 2
Training loss: 1.785210371017456
Validation loss: 2.1240557368083666

Epoch: 5| Step: 3
Training loss: 1.5111099481582642
Validation loss: 2.1485883061603834

Epoch: 5| Step: 4
Training loss: 1.095088005065918
Validation loss: 2.16281101652371

Epoch: 5| Step: 5
Training loss: 1.2183094024658203
Validation loss: 2.157616587095363

Epoch: 5| Step: 6
Training loss: 1.671444296836853
Validation loss: 2.181463018540413

Epoch: 5| Step: 7
Training loss: 2.348543405532837
Validation loss: 2.202601117472495

Epoch: 5| Step: 8
Training loss: 1.9489943981170654
Validation loss: 2.1912653958925636

Epoch: 5| Step: 9
Training loss: 2.4418089389801025
Validation loss: 2.171939439671014

Epoch: 5| Step: 10
Training loss: 1.4274675846099854
Validation loss: 2.124891092700343

Epoch: 333| Step: 0
Training loss: 1.606483817100525
Validation loss: 2.1265175111832155

Epoch: 5| Step: 1
Training loss: 1.3903100490570068
Validation loss: 2.1318059505954867

Epoch: 5| Step: 2
Training loss: 1.473150372505188
Validation loss: 2.125487119920792

Epoch: 5| Step: 3
Training loss: 1.5841648578643799
Validation loss: 2.1386791557394047

Epoch: 5| Step: 4
Training loss: 1.6083837747573853
Validation loss: 2.1289274423353133

Epoch: 5| Step: 5
Training loss: 1.7398960590362549
Validation loss: 2.1369184691418885

Epoch: 5| Step: 6
Training loss: 2.1793291568756104
Validation loss: 2.1525091958302323

Epoch: 5| Step: 7
Training loss: 1.7688792943954468
Validation loss: 2.1278128265052714

Epoch: 5| Step: 8
Training loss: 1.552193284034729
Validation loss: 2.1048133283533077

Epoch: 5| Step: 9
Training loss: 1.4783433675765991
Validation loss: 2.1232015138031333

Epoch: 5| Step: 10
Training loss: 1.9984357357025146
Validation loss: 2.1416488232151156

Epoch: 334| Step: 0
Training loss: 1.379623532295227
Validation loss: 2.1321084191722255

Epoch: 5| Step: 1
Training loss: 1.2459149360656738
Validation loss: 2.1291614937525924

Epoch: 5| Step: 2
Training loss: 1.6592400074005127
Validation loss: 2.122354443355273

Epoch: 5| Step: 3
Training loss: 2.177456855773926
Validation loss: 2.143488178970993

Epoch: 5| Step: 4
Training loss: 2.1560163497924805
Validation loss: 2.139343730864986

Epoch: 5| Step: 5
Training loss: 1.7447935342788696
Validation loss: 2.1346015801993747

Epoch: 5| Step: 6
Training loss: 1.1711864471435547
Validation loss: 2.121708905825051

Epoch: 5| Step: 7
Training loss: 1.5346325635910034
Validation loss: 2.120371921088106

Epoch: 5| Step: 8
Training loss: 1.694673776626587
Validation loss: 2.1449582499842488

Epoch: 5| Step: 9
Training loss: 1.8427482843399048
Validation loss: 2.1569491060831214

Epoch: 5| Step: 10
Training loss: 1.6407721042633057
Validation loss: 2.1483926080888316

Epoch: 335| Step: 0
Training loss: 1.936151146888733
Validation loss: 2.169387181599935

Epoch: 5| Step: 1
Training loss: 1.6050872802734375
Validation loss: 2.1119225102086223

Epoch: 5| Step: 2
Training loss: 2.1121628284454346
Validation loss: 2.1299073670500066

Epoch: 5| Step: 3
Training loss: 1.5678892135620117
Validation loss: 2.0849994844005955

Epoch: 5| Step: 4
Training loss: 1.3226574659347534
Validation loss: 2.083106481259869

Epoch: 5| Step: 5
Training loss: 1.0752003192901611
Validation loss: 2.103391638366125

Epoch: 5| Step: 6
Training loss: 1.5409444570541382
Validation loss: 2.1135633683973745

Epoch: 5| Step: 7
Training loss: 1.9192373752593994
Validation loss: 2.1522859578491538

Epoch: 5| Step: 8
Training loss: 1.3581554889678955
Validation loss: 2.1695689808937813

Epoch: 5| Step: 9
Training loss: 1.5742515325546265
Validation loss: 2.1612961010266374

Epoch: 5| Step: 10
Training loss: 2.2765703201293945
Validation loss: 2.2006449776311077

Epoch: 336| Step: 0
Training loss: 1.7906568050384521
Validation loss: 2.214382997123144

Epoch: 5| Step: 1
Training loss: 1.6490310430526733
Validation loss: 2.2038773080354095

Epoch: 5| Step: 2
Training loss: 1.7659623622894287
Validation loss: 2.1716950055091613

Epoch: 5| Step: 3
Training loss: 1.4647009372711182
Validation loss: 2.1127415369915705

Epoch: 5| Step: 4
Training loss: 2.15649676322937
Validation loss: 2.073525477481145

Epoch: 5| Step: 5
Training loss: 1.889715552330017
Validation loss: 2.0729309589632097

Epoch: 5| Step: 6
Training loss: 2.275895357131958
Validation loss: 2.0688854520038893

Epoch: 5| Step: 7
Training loss: 1.2603261470794678
Validation loss: 2.09517644041328

Epoch: 5| Step: 8
Training loss: 1.0397510528564453
Validation loss: 2.098068501359673

Epoch: 5| Step: 9
Training loss: 1.6026599407196045
Validation loss: 2.1372389947214434

Epoch: 5| Step: 10
Training loss: 1.9311622381210327
Validation loss: 2.133137164577361

Epoch: 337| Step: 0
Training loss: 1.6622951030731201
Validation loss: 2.102747191664993

Epoch: 5| Step: 1
Training loss: 1.5962175130844116
Validation loss: 2.0974297446589314

Epoch: 5| Step: 2
Training loss: 2.183216094970703
Validation loss: 2.0865704244182957

Epoch: 5| Step: 3
Training loss: 1.4497647285461426
Validation loss: 2.0827149755211285

Epoch: 5| Step: 4
Training loss: 1.4329307079315186
Validation loss: 2.0788092664493028

Epoch: 5| Step: 5
Training loss: 1.254109263420105
Validation loss: 2.101269655330207

Epoch: 5| Step: 6
Training loss: 1.5983049869537354
Validation loss: 2.1127616256795902

Epoch: 5| Step: 7
Training loss: 1.8111331462860107
Validation loss: 2.142911934083508

Epoch: 5| Step: 8
Training loss: 1.9089969396591187
Validation loss: 2.17455780377952

Epoch: 5| Step: 9
Training loss: 1.7158660888671875
Validation loss: 2.178077082480154

Epoch: 5| Step: 10
Training loss: 1.738749384880066
Validation loss: 2.1967347334789973

Epoch: 338| Step: 0
Training loss: 1.1406205892562866
Validation loss: 2.147456625456451

Epoch: 5| Step: 1
Training loss: 1.2631914615631104
Validation loss: 2.1618445227223058

Epoch: 5| Step: 2
Training loss: 1.5527441501617432
Validation loss: 2.1394641450656358

Epoch: 5| Step: 3
Training loss: 1.7803808450698853
Validation loss: 2.100868958298878

Epoch: 5| Step: 4
Training loss: 1.5991803407669067
Validation loss: 2.101871887842814

Epoch: 5| Step: 5
Training loss: 1.9723132848739624
Validation loss: 2.075061842959414

Epoch: 5| Step: 6
Training loss: 1.5699340105056763
Validation loss: 2.0462852037081154

Epoch: 5| Step: 7
Training loss: 2.023815631866455
Validation loss: 2.0565797295621646

Epoch: 5| Step: 8
Training loss: 1.837812066078186
Validation loss: 2.0537884748110207

Epoch: 5| Step: 9
Training loss: 1.7016197443008423
Validation loss: 2.087534030278524

Epoch: 5| Step: 10
Training loss: 1.941545844078064
Validation loss: 2.1103632847468057

Epoch: 339| Step: 0
Training loss: 1.3249363899230957
Validation loss: 2.137854519710746

Epoch: 5| Step: 1
Training loss: 1.3422133922576904
Validation loss: 2.1513495035068964

Epoch: 5| Step: 2
Training loss: 1.876503586769104
Validation loss: 2.100380104075196

Epoch: 5| Step: 3
Training loss: 1.9046566486358643
Validation loss: 2.0722224635462605

Epoch: 5| Step: 4
Training loss: 1.451842188835144
Validation loss: 2.0742083595645044

Epoch: 5| Step: 5
Training loss: 1.7032763957977295
Validation loss: 2.072275887253464

Epoch: 5| Step: 6
Training loss: 1.9181022644042969
Validation loss: 2.09237176628523

Epoch: 5| Step: 7
Training loss: 1.6936566829681396
Validation loss: 2.09550444669621

Epoch: 5| Step: 8
Training loss: 1.6555026769638062
Validation loss: 2.1110433916891775

Epoch: 5| Step: 9
Training loss: 1.3183308839797974
Validation loss: 2.1416973529323453

Epoch: 5| Step: 10
Training loss: 2.1121039390563965
Validation loss: 2.1259836432754353

Epoch: 340| Step: 0
Training loss: 1.7115522623062134
Validation loss: 2.11112783544807

Epoch: 5| Step: 1
Training loss: 1.326534628868103
Validation loss: 2.108890692392985

Epoch: 5| Step: 2
Training loss: 1.3774714469909668
Validation loss: 2.107815323337432

Epoch: 5| Step: 3
Training loss: 1.5592979192733765
Validation loss: 2.1062529702340402

Epoch: 5| Step: 4
Training loss: 1.313806414604187
Validation loss: 2.1307523224943425

Epoch: 5| Step: 5
Training loss: 1.2191866636276245
Validation loss: 2.129793106868703

Epoch: 5| Step: 6
Training loss: 1.5111124515533447
Validation loss: 2.1496283982389714

Epoch: 5| Step: 7
Training loss: 2.317962169647217
Validation loss: 2.1797287617960284

Epoch: 5| Step: 8
Training loss: 2.0919601917266846
Validation loss: 2.203330350178544

Epoch: 5| Step: 9
Training loss: 1.9718124866485596
Validation loss: 2.218350802698443

Epoch: 5| Step: 10
Training loss: 1.6824531555175781
Validation loss: 2.1646386897692116

Epoch: 341| Step: 0
Training loss: 1.6632884740829468
Validation loss: 2.175218336043819

Epoch: 5| Step: 1
Training loss: 1.9027414321899414
Validation loss: 2.171267786333638

Epoch: 5| Step: 2
Training loss: 1.8908154964447021
Validation loss: 2.1825718392607985

Epoch: 5| Step: 3
Training loss: 1.427501916885376
Validation loss: 2.198305768351401

Epoch: 5| Step: 4
Training loss: 1.462079644203186
Validation loss: 2.159754163475447

Epoch: 5| Step: 5
Training loss: 1.2167750597000122
Validation loss: 2.1359557028739684

Epoch: 5| Step: 6
Training loss: 1.5748425722122192
Validation loss: 2.108932432307992

Epoch: 5| Step: 7
Training loss: 1.8721014261245728
Validation loss: 2.107011834780375

Epoch: 5| Step: 8
Training loss: 1.8902820348739624
Validation loss: 2.1106858689297914

Epoch: 5| Step: 9
Training loss: 1.8481184244155884
Validation loss: 2.0984734950527066

Epoch: 5| Step: 10
Training loss: 1.4769970178604126
Validation loss: 2.114329493173989

Epoch: 342| Step: 0
Training loss: 1.6137454509735107
Validation loss: 2.1432115326645556

Epoch: 5| Step: 1
Training loss: 1.754844069480896
Validation loss: 2.17790283695344

Epoch: 5| Step: 2
Training loss: 1.1982285976409912
Validation loss: 2.1901701188856557

Epoch: 5| Step: 3
Training loss: 2.4005768299102783
Validation loss: 2.1762731664924213

Epoch: 5| Step: 4
Training loss: 1.991735816001892
Validation loss: 2.156579958495273

Epoch: 5| Step: 5
Training loss: 1.845924735069275
Validation loss: 2.1433493847488077

Epoch: 5| Step: 6
Training loss: 1.9223096370697021
Validation loss: 2.1476592376667965

Epoch: 5| Step: 7
Training loss: 1.216808557510376
Validation loss: 2.1779826853864934

Epoch: 5| Step: 8
Training loss: 1.7009586095809937
Validation loss: 2.166202195229069

Epoch: 5| Step: 9
Training loss: 1.2788506746292114
Validation loss: 2.147175588915425

Epoch: 5| Step: 10
Training loss: 1.0018302202224731
Validation loss: 2.151047128503041

Epoch: 343| Step: 0
Training loss: 1.5597894191741943
Validation loss: 2.1028421232777257

Epoch: 5| Step: 1
Training loss: 1.1918056011199951
Validation loss: 2.096134449846001

Epoch: 5| Step: 2
Training loss: 2.231985092163086
Validation loss: 2.0942248708458355

Epoch: 5| Step: 3
Training loss: 1.311901569366455
Validation loss: 2.111280793784767

Epoch: 5| Step: 4
Training loss: 1.7507117986679077
Validation loss: 2.078872414045436

Epoch: 5| Step: 5
Training loss: 1.6380460262298584
Validation loss: 2.12595473950909

Epoch: 5| Step: 6
Training loss: 1.3027317523956299
Validation loss: 2.125823989991219

Epoch: 5| Step: 7
Training loss: 1.5437425374984741
Validation loss: 2.127642557185183

Epoch: 5| Step: 8
Training loss: 2.4352028369903564
Validation loss: 2.1715192025707615

Epoch: 5| Step: 9
Training loss: 1.7965360879898071
Validation loss: 2.1492049437697216

Epoch: 5| Step: 10
Training loss: 1.250420093536377
Validation loss: 2.1301155346696095

Epoch: 344| Step: 0
Training loss: 1.7618614435195923
Validation loss: 2.117336783357846

Epoch: 5| Step: 1
Training loss: 1.4113452434539795
Validation loss: 2.077964694269242

Epoch: 5| Step: 2
Training loss: 2.160189151763916
Validation loss: 2.0898867755807857

Epoch: 5| Step: 3
Training loss: 0.9005321264266968
Validation loss: 2.096670112302226

Epoch: 5| Step: 4
Training loss: 2.14056396484375
Validation loss: 2.131519247126836

Epoch: 5| Step: 5
Training loss: 1.8593658208847046
Validation loss: 2.113312557179441

Epoch: 5| Step: 6
Training loss: 1.5918238162994385
Validation loss: 2.1120060079841205

Epoch: 5| Step: 7
Training loss: 1.272849678993225
Validation loss: 2.0748977943133284

Epoch: 5| Step: 8
Training loss: 1.7261556386947632
Validation loss: 2.1237521966298423

Epoch: 5| Step: 9
Training loss: 1.9423013925552368
Validation loss: 2.078706177332068

Epoch: 5| Step: 10
Training loss: 1.1095969676971436
Validation loss: 2.0998922419804398

Epoch: 345| Step: 0
Training loss: 1.3735835552215576
Validation loss: 2.1483165410257157

Epoch: 5| Step: 1
Training loss: 1.810948133468628
Validation loss: 2.181194818148049

Epoch: 5| Step: 2
Training loss: 1.7968766689300537
Validation loss: 2.1955133535528697

Epoch: 5| Step: 3
Training loss: 2.1885251998901367
Validation loss: 2.191719565340268

Epoch: 5| Step: 4
Training loss: 1.8012149333953857
Validation loss: 2.178383458045221

Epoch: 5| Step: 5
Training loss: 0.846348762512207
Validation loss: 2.1465757046976397

Epoch: 5| Step: 6
Training loss: 1.6887725591659546
Validation loss: 2.134167073875345

Epoch: 5| Step: 7
Training loss: 1.8302701711654663
Validation loss: 2.0875359376271567

Epoch: 5| Step: 8
Training loss: 1.3316574096679688
Validation loss: 2.069230456506052

Epoch: 5| Step: 9
Training loss: 1.4617602825164795
Validation loss: 2.054997964571881

Epoch: 5| Step: 10
Training loss: 1.9251289367675781
Validation loss: 2.0386986271027596

Epoch: 346| Step: 0
Training loss: 1.300478219985962
Validation loss: 2.063797370080025

Epoch: 5| Step: 1
Training loss: 1.5809355974197388
Validation loss: 2.120843941165555

Epoch: 5| Step: 2
Training loss: 1.82985520362854
Validation loss: 2.134733610255744

Epoch: 5| Step: 3
Training loss: 1.428521752357483
Validation loss: 2.1760714900109077

Epoch: 5| Step: 4
Training loss: 1.8968387842178345
Validation loss: 2.209399018236386

Epoch: 5| Step: 5
Training loss: 1.6145689487457275
Validation loss: 2.205791591316141

Epoch: 5| Step: 6
Training loss: 1.351519227027893
Validation loss: 2.2238027690559306

Epoch: 5| Step: 7
Training loss: 1.814164161682129
Validation loss: 2.1955179552878104

Epoch: 5| Step: 8
Training loss: 1.6957213878631592
Validation loss: 2.164788612755396

Epoch: 5| Step: 9
Training loss: 1.3493059873580933
Validation loss: 2.153375494864679

Epoch: 5| Step: 10
Training loss: 2.016092300415039
Validation loss: 2.101318472175188

Epoch: 347| Step: 0
Training loss: 1.311616063117981
Validation loss: 2.0690318602387623

Epoch: 5| Step: 1
Training loss: 1.5581482648849487
Validation loss: 2.0651108552050847

Epoch: 5| Step: 2
Training loss: 1.576279878616333
Validation loss: 2.0782398793005172

Epoch: 5| Step: 3
Training loss: 1.6563838720321655
Validation loss: 2.0917454791325394

Epoch: 5| Step: 4
Training loss: 1.2560107707977295
Validation loss: 2.077319537439654

Epoch: 5| Step: 5
Training loss: 1.4789279699325562
Validation loss: 2.127076748878725

Epoch: 5| Step: 6
Training loss: 2.0769972801208496
Validation loss: 2.197571776246512

Epoch: 5| Step: 7
Training loss: 1.5965006351470947
Validation loss: 2.208315744194933

Epoch: 5| Step: 8
Training loss: 1.8906177282333374
Validation loss: 2.2507541615475892

Epoch: 5| Step: 9
Training loss: 1.3936264514923096
Validation loss: 2.216255218751969

Epoch: 5| Step: 10
Training loss: 2.1796953678131104
Validation loss: 2.199745560205111

Epoch: 348| Step: 0
Training loss: 1.678545594215393
Validation loss: 2.174937337957403

Epoch: 5| Step: 1
Training loss: 1.9293625354766846
Validation loss: 2.1625177039895007

Epoch: 5| Step: 2
Training loss: 1.188759684562683
Validation loss: 2.1795667781624743

Epoch: 5| Step: 3
Training loss: 2.1305837631225586
Validation loss: 2.135478678569999

Epoch: 5| Step: 4
Training loss: 1.144911527633667
Validation loss: 2.114950874800323

Epoch: 5| Step: 5
Training loss: 1.5039523839950562
Validation loss: 2.1357472840175835

Epoch: 5| Step: 6
Training loss: 1.9591119289398193
Validation loss: 2.14143301851006

Epoch: 5| Step: 7
Training loss: 1.7094367742538452
Validation loss: 2.1176610146799395

Epoch: 5| Step: 8
Training loss: 1.328750491142273
Validation loss: 2.10623667060688

Epoch: 5| Step: 9
Training loss: 1.118544340133667
Validation loss: 2.1155646206230245

Epoch: 5| Step: 10
Training loss: 2.2587809562683105
Validation loss: 2.1419184272007277

Epoch: 349| Step: 0
Training loss: 1.6585222482681274
Validation loss: 2.1060364964187785

Epoch: 5| Step: 1
Training loss: 1.7870538234710693
Validation loss: 2.0803400675455728

Epoch: 5| Step: 2
Training loss: 1.4289690256118774
Validation loss: 2.0884180094606135

Epoch: 5| Step: 3
Training loss: 1.3632783889770508
Validation loss: 2.12998652714555

Epoch: 5| Step: 4
Training loss: 1.698387861251831
Validation loss: 2.13500948362453

Epoch: 5| Step: 5
Training loss: 1.8331775665283203
Validation loss: 2.1384133036418627

Epoch: 5| Step: 6
Training loss: 2.1301746368408203
Validation loss: 2.1549370673394974

Epoch: 5| Step: 7
Training loss: 1.6076581478118896
Validation loss: 2.1222705892337266

Epoch: 5| Step: 8
Training loss: 1.5909388065338135
Validation loss: 2.1527741814172394

Epoch: 5| Step: 9
Training loss: 0.8953474760055542
Validation loss: 2.137493823164253

Epoch: 5| Step: 10
Training loss: 1.8927441835403442
Validation loss: 2.1404031245939192

Epoch: 350| Step: 0
Training loss: 1.1823453903198242
Validation loss: 2.1515777136689875

Epoch: 5| Step: 1
Training loss: 2.127943754196167
Validation loss: 2.167878702122678

Epoch: 5| Step: 2
Training loss: 1.7489478588104248
Validation loss: 2.1145593709843133

Epoch: 5| Step: 3
Training loss: 1.1130783557891846
Validation loss: 2.09526877890351

Epoch: 5| Step: 4
Training loss: 2.129990339279175
Validation loss: 2.084753995300621

Epoch: 5| Step: 5
Training loss: 1.5209100246429443
Validation loss: 2.08076032259131

Epoch: 5| Step: 6
Training loss: 2.1752936840057373
Validation loss: 2.084324954658426

Epoch: 5| Step: 7
Training loss: 0.9949215650558472
Validation loss: 2.078843960198023

Epoch: 5| Step: 8
Training loss: 1.608628511428833
Validation loss: 2.126150136352867

Epoch: 5| Step: 9
Training loss: 1.4840798377990723
Validation loss: 2.1239345688973703

Epoch: 5| Step: 10
Training loss: 1.5032545328140259
Validation loss: 2.1420264628625687

Epoch: 351| Step: 0
Training loss: 1.55742347240448
Validation loss: 2.168454862410022

Epoch: 5| Step: 1
Training loss: 1.5393095016479492
Validation loss: 2.1699263306074243

Epoch: 5| Step: 2
Training loss: 1.6110403537750244
Validation loss: 2.171175874689574

Epoch: 5| Step: 3
Training loss: 1.4409170150756836
Validation loss: 2.174722333108225

Epoch: 5| Step: 4
Training loss: 1.1059608459472656
Validation loss: 2.156068194297052

Epoch: 5| Step: 5
Training loss: 1.3657668828964233
Validation loss: 2.1410068004362044

Epoch: 5| Step: 6
Training loss: 1.0534042119979858
Validation loss: 2.161887479084794

Epoch: 5| Step: 7
Training loss: 1.842832326889038
Validation loss: 2.1267695696123186

Epoch: 5| Step: 8
Training loss: 2.0977816581726074
Validation loss: 2.1315996723790325

Epoch: 5| Step: 9
Training loss: 2.0986151695251465
Validation loss: 2.1080971353797504

Epoch: 5| Step: 10
Training loss: 1.8336656093597412
Validation loss: 2.114330026411241

Epoch: 352| Step: 0
Training loss: 1.7569761276245117
Validation loss: 2.128352108822074

Epoch: 5| Step: 1
Training loss: 1.4532049894332886
Validation loss: 2.1484778414490404

Epoch: 5| Step: 2
Training loss: 1.9903316497802734
Validation loss: 2.1235147829978698

Epoch: 5| Step: 3
Training loss: 1.5175695419311523
Validation loss: 2.1042127942526214

Epoch: 5| Step: 4
Training loss: 1.5101863145828247
Validation loss: 2.0705616166514735

Epoch: 5| Step: 5
Training loss: 1.5281959772109985
Validation loss: 2.097563535936417

Epoch: 5| Step: 6
Training loss: 1.0181047916412354
Validation loss: 2.108830390437957

Epoch: 5| Step: 7
Training loss: 1.4351856708526611
Validation loss: 2.1330930584220478

Epoch: 5| Step: 8
Training loss: 1.8134912252426147
Validation loss: 2.1261154502950688

Epoch: 5| Step: 9
Training loss: 1.5787315368652344
Validation loss: 2.1485943512250016

Epoch: 5| Step: 10
Training loss: 1.938521385192871
Validation loss: 2.149305010354647

Epoch: 353| Step: 0
Training loss: 1.895788550376892
Validation loss: 2.152718247905854

Epoch: 5| Step: 1
Training loss: 1.8192516565322876
Validation loss: 2.1447114072820193

Epoch: 5| Step: 2
Training loss: 2.071949005126953
Validation loss: 2.129164247102635

Epoch: 5| Step: 3
Training loss: 1.325447916984558
Validation loss: 2.13899851101701

Epoch: 5| Step: 4
Training loss: 2.2522149085998535
Validation loss: 2.1516256319579257

Epoch: 5| Step: 5
Training loss: 0.9231313467025757
Validation loss: 2.109724934383105

Epoch: 5| Step: 6
Training loss: 1.522369623184204
Validation loss: 2.1086887646746892

Epoch: 5| Step: 7
Training loss: 1.1837142705917358
Validation loss: 2.083108578958819

Epoch: 5| Step: 8
Training loss: 1.6556575298309326
Validation loss: 2.0983096399614887

Epoch: 5| Step: 9
Training loss: 1.613590955734253
Validation loss: 2.093947272146902

Epoch: 5| Step: 10
Training loss: 1.2117319107055664
Validation loss: 2.1690961955696024

Epoch: 354| Step: 0
Training loss: 1.55874764919281
Validation loss: 2.193773700344947

Epoch: 5| Step: 1
Training loss: 2.1366305351257324
Validation loss: 2.2399799593033327

Epoch: 5| Step: 2
Training loss: 1.525557041168213
Validation loss: 2.2528341713772027

Epoch: 5| Step: 3
Training loss: 1.9043724536895752
Validation loss: 2.1971791200740363

Epoch: 5| Step: 4
Training loss: 1.1424232721328735
Validation loss: 2.131671490207795

Epoch: 5| Step: 5
Training loss: 1.7542083263397217
Validation loss: 2.099247122323641

Epoch: 5| Step: 6
Training loss: 1.4613066911697388
Validation loss: 2.079201776494262

Epoch: 5| Step: 7
Training loss: 1.543797254562378
Validation loss: 2.0580733591510403

Epoch: 5| Step: 8
Training loss: 1.8846184015274048
Validation loss: 2.083450278928203

Epoch: 5| Step: 9
Training loss: 1.1951420307159424
Validation loss: 2.0813769345642417

Epoch: 5| Step: 10
Training loss: 1.3683003187179565
Validation loss: 2.0689188921323387

Epoch: 355| Step: 0
Training loss: 1.4572155475616455
Validation loss: 2.0871899281778643

Epoch: 5| Step: 1
Training loss: 2.020477771759033
Validation loss: 2.063256473951442

Epoch: 5| Step: 2
Training loss: 1.5058531761169434
Validation loss: 2.073515433137135

Epoch: 5| Step: 3
Training loss: 1.8147971630096436
Validation loss: 2.0935876061839442

Epoch: 5| Step: 4
Training loss: 2.1089696884155273
Validation loss: 2.180229094720656

Epoch: 5| Step: 5
Training loss: 1.6247141361236572
Validation loss: 2.1871288412360737

Epoch: 5| Step: 6
Training loss: 1.054588794708252
Validation loss: 2.2110665946878414

Epoch: 5| Step: 7
Training loss: 1.6926895380020142
Validation loss: 2.1888242998430805

Epoch: 5| Step: 8
Training loss: 1.5678837299346924
Validation loss: 2.1307693501954437

Epoch: 5| Step: 9
Training loss: 1.5127489566802979
Validation loss: 2.0911367734273276

Epoch: 5| Step: 10
Training loss: 1.3334131240844727
Validation loss: 2.066432099188528

Epoch: 356| Step: 0
Training loss: 1.8055442571640015
Validation loss: 2.081617873202088

Epoch: 5| Step: 1
Training loss: 1.0995419025421143
Validation loss: 2.050886737403049

Epoch: 5| Step: 2
Training loss: 1.5142933130264282
Validation loss: 2.0699848205812517

Epoch: 5| Step: 3
Training loss: 1.7686693668365479
Validation loss: 2.081454469311622

Epoch: 5| Step: 4
Training loss: 1.4116660356521606
Validation loss: 2.0555055756722727

Epoch: 5| Step: 5
Training loss: 1.9882720708847046
Validation loss: 2.065263822514524

Epoch: 5| Step: 6
Training loss: 1.6581785678863525
Validation loss: 2.0667394515006774

Epoch: 5| Step: 7
Training loss: 1.3046437501907349
Validation loss: 2.101264484467045

Epoch: 5| Step: 8
Training loss: 1.5727412700653076
Validation loss: 2.1303930718411683

Epoch: 5| Step: 9
Training loss: 2.2182323932647705
Validation loss: 2.149875017904466

Epoch: 5| Step: 10
Training loss: 0.792322039604187
Validation loss: 2.186816733370545

Epoch: 357| Step: 0
Training loss: 1.5181244611740112
Validation loss: 2.2404300371805825

Epoch: 5| Step: 1
Training loss: 1.401937484741211
Validation loss: 2.206819770156696

Epoch: 5| Step: 2
Training loss: 0.9486568570137024
Validation loss: 2.2009967834718767

Epoch: 5| Step: 3
Training loss: 1.6533002853393555
Validation loss: 2.141860246658325

Epoch: 5| Step: 4
Training loss: 1.3887966871261597
Validation loss: 2.0899743892813243

Epoch: 5| Step: 5
Training loss: 1.6559327840805054
Validation loss: 2.086749953608359

Epoch: 5| Step: 6
Training loss: 1.629045844078064
Validation loss: 2.0767024511932046

Epoch: 5| Step: 7
Training loss: 2.215841054916382
Validation loss: 2.0729656347664456

Epoch: 5| Step: 8
Training loss: 1.7021892070770264
Validation loss: 2.036391673549529

Epoch: 5| Step: 9
Training loss: 1.6365454196929932
Validation loss: 2.042399275687433

Epoch: 5| Step: 10
Training loss: 1.5403238534927368
Validation loss: 2.046576007719963

Epoch: 358| Step: 0
Training loss: 2.0179405212402344
Validation loss: 2.0632312451639483

Epoch: 5| Step: 1
Training loss: 1.8544734716415405
Validation loss: 2.056436050322748

Epoch: 5| Step: 2
Training loss: 1.3505146503448486
Validation loss: 2.107065172605617

Epoch: 5| Step: 3
Training loss: 1.2726589441299438
Validation loss: 2.0898910799334125

Epoch: 5| Step: 4
Training loss: 1.7189576625823975
Validation loss: 2.0826311188359417

Epoch: 5| Step: 5
Training loss: 1.2018828392028809
Validation loss: 2.0794393349719305

Epoch: 5| Step: 6
Training loss: 1.7087953090667725
Validation loss: 2.079073764944589

Epoch: 5| Step: 7
Training loss: 2.0512256622314453
Validation loss: 2.1156099714258665

Epoch: 5| Step: 8
Training loss: 1.362872838973999
Validation loss: 2.1261306757568033

Epoch: 5| Step: 9
Training loss: 1.292398452758789
Validation loss: 2.1432797780600925

Epoch: 5| Step: 10
Training loss: 1.2717641592025757
Validation loss: 2.1229938409661733

Epoch: 359| Step: 0
Training loss: 1.702472448348999
Validation loss: 2.1003152221761723

Epoch: 5| Step: 1
Training loss: 1.6878303289413452
Validation loss: 2.0711650861206876

Epoch: 5| Step: 2
Training loss: 1.5879417657852173
Validation loss: 2.042972574951828

Epoch: 5| Step: 3
Training loss: 2.0606045722961426
Validation loss: 2.0567672637201126

Epoch: 5| Step: 4
Training loss: 1.5204905271530151
Validation loss: 2.042925529582526

Epoch: 5| Step: 5
Training loss: 1.4252569675445557
Validation loss: 2.0603003040436776

Epoch: 5| Step: 6
Training loss: 1.673265814781189
Validation loss: 2.1012966555933796

Epoch: 5| Step: 7
Training loss: 1.6681588888168335
Validation loss: 2.1406096489198747

Epoch: 5| Step: 8
Training loss: 1.0258762836456299
Validation loss: 2.1361613863257953

Epoch: 5| Step: 9
Training loss: 1.2527199983596802
Validation loss: 2.0957722048605643

Epoch: 5| Step: 10
Training loss: 1.4705175161361694
Validation loss: 2.1125762206251903

Epoch: 360| Step: 0
Training loss: 1.5188583135604858
Validation loss: 2.1182926970143474

Epoch: 5| Step: 1
Training loss: 1.274423360824585
Validation loss: 2.117293914159139

Epoch: 5| Step: 2
Training loss: 1.2100955247879028
Validation loss: 2.114909830913749

Epoch: 5| Step: 3
Training loss: 1.1191723346710205
Validation loss: 2.0983865312350694

Epoch: 5| Step: 4
Training loss: 2.016693592071533
Validation loss: 2.0770259980232484

Epoch: 5| Step: 5
Training loss: 1.501507043838501
Validation loss: 2.132861142517418

Epoch: 5| Step: 6
Training loss: 1.547519564628601
Validation loss: 2.1405821564376994

Epoch: 5| Step: 7
Training loss: 1.8312509059906006
Validation loss: 2.1231699425687074

Epoch: 5| Step: 8
Training loss: 1.679882287979126
Validation loss: 2.1298074747926448

Epoch: 5| Step: 9
Training loss: 1.6522414684295654
Validation loss: 2.120480204141268

Epoch: 5| Step: 10
Training loss: 1.7347683906555176
Validation loss: 2.1052821656709075

Epoch: 361| Step: 0
Training loss: 0.9144570231437683
Validation loss: 2.0839630762736

Epoch: 5| Step: 1
Training loss: 1.446305513381958
Validation loss: 2.100419311113255

Epoch: 5| Step: 2
Training loss: 2.2439229488372803
Validation loss: 2.0847626821969145

Epoch: 5| Step: 3
Training loss: 1.8138993978500366
Validation loss: 2.0980428111168647

Epoch: 5| Step: 4
Training loss: 1.729140281677246
Validation loss: 2.1234480873230965

Epoch: 5| Step: 5
Training loss: 1.3133560419082642
Validation loss: 2.1515010326139388

Epoch: 5| Step: 6
Training loss: 1.3143033981323242
Validation loss: 2.1234830784541305

Epoch: 5| Step: 7
Training loss: 1.5375878810882568
Validation loss: 2.1004517232218096

Epoch: 5| Step: 8
Training loss: 1.3594108819961548
Validation loss: 2.106327833667878

Epoch: 5| Step: 9
Training loss: 1.4983646869659424
Validation loss: 2.1055013466906805

Epoch: 5| Step: 10
Training loss: 1.7679998874664307
Validation loss: 2.0708095001918014

Epoch: 362| Step: 0
Training loss: 1.2985948324203491
Validation loss: 2.067127355965235

Epoch: 5| Step: 1
Training loss: 1.793575644493103
Validation loss: 2.057472046985421

Epoch: 5| Step: 2
Training loss: 1.2850162982940674
Validation loss: 2.0562648234828824

Epoch: 5| Step: 3
Training loss: 1.6145967245101929
Validation loss: 2.0603377357605965

Epoch: 5| Step: 4
Training loss: 1.4022457599639893
Validation loss: 2.0577780174952682

Epoch: 5| Step: 5
Training loss: 1.139997959136963
Validation loss: 2.081170469202021

Epoch: 5| Step: 6
Training loss: 1.5848138332366943
Validation loss: 2.162588042597617

Epoch: 5| Step: 7
Training loss: 1.8739421367645264
Validation loss: 2.2033057315375215

Epoch: 5| Step: 8
Training loss: 1.7862188816070557
Validation loss: 2.2837155275447394

Epoch: 5| Step: 9
Training loss: 1.5626784563064575
Validation loss: 2.247331198825631

Epoch: 5| Step: 10
Training loss: 1.806050181388855
Validation loss: 2.2101848176730576

Epoch: 363| Step: 0
Training loss: 1.6709051132202148
Validation loss: 2.182304641251923

Epoch: 5| Step: 1
Training loss: 1.5456445217132568
Validation loss: 2.142655018837221

Epoch: 5| Step: 2
Training loss: 1.42960524559021
Validation loss: 2.1037854635587303

Epoch: 5| Step: 3
Training loss: 1.5648609399795532
Validation loss: 2.058479127063546

Epoch: 5| Step: 4
Training loss: 1.5481696128845215
Validation loss: 2.0645271321778655

Epoch: 5| Step: 5
Training loss: 1.563819408416748
Validation loss: 2.046098429669616

Epoch: 5| Step: 6
Training loss: 1.5632308721542358
Validation loss: 2.0543265829804125

Epoch: 5| Step: 7
Training loss: 1.7290292978286743
Validation loss: 2.0761299671665316

Epoch: 5| Step: 8
Training loss: 1.5019581317901611
Validation loss: 2.085782071595551

Epoch: 5| Step: 9
Training loss: 1.212619423866272
Validation loss: 2.108279482010872

Epoch: 5| Step: 10
Training loss: 1.435214877128601
Validation loss: 2.1369246667431248

Epoch: 364| Step: 0
Training loss: 2.529658079147339
Validation loss: 2.12510222388852

Epoch: 5| Step: 1
Training loss: 0.8822922706604004
Validation loss: 2.184997753430438

Epoch: 5| Step: 2
Training loss: 2.113308906555176
Validation loss: 2.2197177179398073

Epoch: 5| Step: 3
Training loss: 1.3516534566879272
Validation loss: 2.2022864972391436

Epoch: 5| Step: 4
Training loss: 1.0977783203125
Validation loss: 2.200326996464883

Epoch: 5| Step: 5
Training loss: 1.8713783025741577
Validation loss: 2.1653174866912184

Epoch: 5| Step: 6
Training loss: 1.1883118152618408
Validation loss: 2.1259798055054038

Epoch: 5| Step: 7
Training loss: 1.4202795028686523
Validation loss: 2.125441320480839

Epoch: 5| Step: 8
Training loss: 1.92030930519104
Validation loss: 2.105052794179609

Epoch: 5| Step: 9
Training loss: 1.3518046140670776
Validation loss: 2.0740471642504454

Epoch: 5| Step: 10
Training loss: 1.0056289434432983
Validation loss: 2.0807212860353532

Epoch: 365| Step: 0
Training loss: 0.7919108867645264
Validation loss: 2.0581297566813808

Epoch: 5| Step: 1
Training loss: 2.113032817840576
Validation loss: 2.065673694815687

Epoch: 5| Step: 2
Training loss: 1.1746399402618408
Validation loss: 2.1287857024900374

Epoch: 5| Step: 3
Training loss: 1.790361762046814
Validation loss: 2.154371835852182

Epoch: 5| Step: 4
Training loss: 1.1205974817276
Validation loss: 2.1258334408524218

Epoch: 5| Step: 5
Training loss: 1.5093740224838257
Validation loss: 2.1423512274219143

Epoch: 5| Step: 6
Training loss: 1.3140869140625
Validation loss: 2.1492970835778022

Epoch: 5| Step: 7
Training loss: 1.6501191854476929
Validation loss: 2.159713734862625

Epoch: 5| Step: 8
Training loss: 1.737173080444336
Validation loss: 2.185245519043297

Epoch: 5| Step: 9
Training loss: 2.2134201526641846
Validation loss: 2.1569210047362954

Epoch: 5| Step: 10
Training loss: 1.630061149597168
Validation loss: 2.139634939932054

Epoch: 366| Step: 0
Training loss: 1.2013652324676514
Validation loss: 2.1301539944064234

Epoch: 5| Step: 1
Training loss: 2.1210708618164062
Validation loss: 2.1207311512321554

Epoch: 5| Step: 2
Training loss: 1.4839099645614624
Validation loss: 2.1387465179607434

Epoch: 5| Step: 3
Training loss: 1.894191026687622
Validation loss: 2.122421549212548

Epoch: 5| Step: 4
Training loss: 1.2924511432647705
Validation loss: 2.098601051556167

Epoch: 5| Step: 5
Training loss: 1.0902152061462402
Validation loss: 2.0997061062884588

Epoch: 5| Step: 6
Training loss: 1.5426533222198486
Validation loss: 2.0484625498453775

Epoch: 5| Step: 7
Training loss: 1.6024129390716553
Validation loss: 2.048841098303436

Epoch: 5| Step: 8
Training loss: 2.3907244205474854
Validation loss: 2.031768937264719

Epoch: 5| Step: 9
Training loss: 1.429800271987915
Validation loss: 2.0394849828494492

Epoch: 5| Step: 10
Training loss: 0.9344073534011841
Validation loss: 2.036852995554606

Epoch: 367| Step: 0
Training loss: 1.5655615329742432
Validation loss: 2.074534485417028

Epoch: 5| Step: 1
Training loss: 0.9869739413261414
Validation loss: 2.101339622210431

Epoch: 5| Step: 2
Training loss: 1.3921505212783813
Validation loss: 2.155456413504898

Epoch: 5| Step: 3
Training loss: 1.3380346298217773
Validation loss: 2.154618032516972

Epoch: 5| Step: 4
Training loss: 2.011155366897583
Validation loss: 2.222551723962189

Epoch: 5| Step: 5
Training loss: 2.1554770469665527
Validation loss: 2.200031699672822

Epoch: 5| Step: 6
Training loss: 1.4538856744766235
Validation loss: 2.1874112903430896

Epoch: 5| Step: 7
Training loss: 1.189178705215454
Validation loss: 2.163168425201088

Epoch: 5| Step: 8
Training loss: 1.1626758575439453
Validation loss: 2.1754519888149795

Epoch: 5| Step: 9
Training loss: 1.819736123085022
Validation loss: 2.1825922355856946

Epoch: 5| Step: 10
Training loss: 1.6861813068389893
Validation loss: 2.134337112467776

Epoch: 368| Step: 0
Training loss: 1.1312651634216309
Validation loss: 2.089356812097693

Epoch: 5| Step: 1
Training loss: 1.6157604455947876
Validation loss: 2.0661799023228307

Epoch: 5| Step: 2
Training loss: 2.246706008911133
Validation loss: 2.0518621424193024

Epoch: 5| Step: 3
Training loss: 1.4763199090957642
Validation loss: 2.0515228266357095

Epoch: 5| Step: 4
Training loss: 1.3149980306625366
Validation loss: 2.0801844558408185

Epoch: 5| Step: 5
Training loss: 1.470208764076233
Validation loss: 2.057929218456309

Epoch: 5| Step: 6
Training loss: 1.440723180770874
Validation loss: 2.108558318948233

Epoch: 5| Step: 7
Training loss: 1.597021460533142
Validation loss: 2.185356209355016

Epoch: 5| Step: 8
Training loss: 1.6872332096099854
Validation loss: 2.204725888467604

Epoch: 5| Step: 9
Training loss: 1.501349687576294
Validation loss: 2.2407251557996197

Epoch: 5| Step: 10
Training loss: 1.3512547016143799
Validation loss: 2.212289315398021

Epoch: 369| Step: 0
Training loss: 1.9255926609039307
Validation loss: 2.1828385783780004

Epoch: 5| Step: 1
Training loss: 0.895398736000061
Validation loss: 2.1228425810413976

Epoch: 5| Step: 2
Training loss: 1.9309990406036377
Validation loss: 2.08081236193257

Epoch: 5| Step: 3
Training loss: 1.6673065423965454
Validation loss: 2.047804804258449

Epoch: 5| Step: 4
Training loss: 1.382568359375
Validation loss: 2.0627623552917154

Epoch: 5| Step: 5
Training loss: 1.655571699142456
Validation loss: 2.054408045225246

Epoch: 5| Step: 6
Training loss: 1.589308500289917
Validation loss: 2.02880016193595

Epoch: 5| Step: 7
Training loss: 1.246793508529663
Validation loss: 2.0645614490714124

Epoch: 5| Step: 8
Training loss: 1.7967078685760498
Validation loss: 2.0769883842878443

Epoch: 5| Step: 9
Training loss: 1.2758177518844604
Validation loss: 2.1345654610664613

Epoch: 5| Step: 10
Training loss: 1.3841323852539062
Validation loss: 2.1229381958643594

Epoch: 370| Step: 0
Training loss: 1.4991422891616821
Validation loss: 2.1365597940260366

Epoch: 5| Step: 1
Training loss: 1.7713077068328857
Validation loss: 2.13555799248398

Epoch: 5| Step: 2
Training loss: 1.4007291793823242
Validation loss: 2.130173598566363

Epoch: 5| Step: 3
Training loss: 1.6831483840942383
Validation loss: 2.1225756086328977

Epoch: 5| Step: 4
Training loss: 1.2297170162200928
Validation loss: 2.0887768242948797

Epoch: 5| Step: 5
Training loss: 1.5413588285446167
Validation loss: 2.0622477480160293

Epoch: 5| Step: 6
Training loss: 1.4251333475112915
Validation loss: 2.07172058474633

Epoch: 5| Step: 7
Training loss: 1.754033088684082
Validation loss: 2.0621151795951267

Epoch: 5| Step: 8
Training loss: 1.4583297967910767
Validation loss: 2.0898259532067085

Epoch: 5| Step: 9
Training loss: 1.4461157321929932
Validation loss: 2.085573269474891

Epoch: 5| Step: 10
Training loss: 1.1880608797073364
Validation loss: 2.0770500603542534

Epoch: 371| Step: 0
Training loss: 1.7631895542144775
Validation loss: 2.133980971510692

Epoch: 5| Step: 1
Training loss: 1.3144327402114868
Validation loss: 2.108365137089965

Epoch: 5| Step: 2
Training loss: 1.7233244180679321
Validation loss: 2.097961151471702

Epoch: 5| Step: 3
Training loss: 1.5473811626434326
Validation loss: 2.0686247541058447

Epoch: 5| Step: 4
Training loss: 1.4898074865341187
Validation loss: 2.062806101255519

Epoch: 5| Step: 5
Training loss: 1.6931829452514648
Validation loss: 2.041259555406468

Epoch: 5| Step: 6
Training loss: 0.9333004951477051
Validation loss: 2.0817594989653556

Epoch: 5| Step: 7
Training loss: 1.498483657836914
Validation loss: 2.08575023886978

Epoch: 5| Step: 8
Training loss: 2.0955722332000732
Validation loss: 2.0686411729422947

Epoch: 5| Step: 9
Training loss: 0.9308678507804871
Validation loss: 2.0690982726312455

Epoch: 5| Step: 10
Training loss: 1.4540668725967407
Validation loss: 2.1026577987978534

Epoch: 372| Step: 0
Training loss: 1.5177570581436157
Validation loss: 2.101338099407893

Epoch: 5| Step: 1
Training loss: 1.6761003732681274
Validation loss: 2.1438189193766606

Epoch: 5| Step: 2
Training loss: 1.399390459060669
Validation loss: 2.147309345583762

Epoch: 5| Step: 3
Training loss: 1.399490237236023
Validation loss: 2.1746652728767804

Epoch: 5| Step: 4
Training loss: 2.353895902633667
Validation loss: 2.209733873285273

Epoch: 5| Step: 5
Training loss: 1.1088234186172485
Validation loss: 2.2050634020118305

Epoch: 5| Step: 6
Training loss: 1.5536785125732422
Validation loss: 2.207526453079716

Epoch: 5| Step: 7
Training loss: 1.3709238767623901
Validation loss: 2.1960930080824

Epoch: 5| Step: 8
Training loss: 1.6421524286270142
Validation loss: 2.1783055259335424

Epoch: 5| Step: 9
Training loss: 1.2812588214874268
Validation loss: 2.1286078242845434

Epoch: 5| Step: 10
Training loss: 1.1070410013198853
Validation loss: 2.1060613022055676

Epoch: 373| Step: 0
Training loss: 1.9536030292510986
Validation loss: 2.079837244044068

Epoch: 5| Step: 1
Training loss: 1.7188880443572998
Validation loss: 2.0508981186856508

Epoch: 5| Step: 2
Training loss: 1.733104944229126
Validation loss: 2.0488729451292302

Epoch: 5| Step: 3
Training loss: 1.463375449180603
Validation loss: 2.0498465786698046

Epoch: 5| Step: 4
Training loss: 1.3240246772766113
Validation loss: 2.0388533607605965

Epoch: 5| Step: 5
Training loss: 1.833030104637146
Validation loss: 2.049849722975044

Epoch: 5| Step: 6
Training loss: 1.3410106897354126
Validation loss: 2.0473204453786216

Epoch: 5| Step: 7
Training loss: 2.036839246749878
Validation loss: 2.0676089025312856

Epoch: 5| Step: 8
Training loss: 1.212388277053833
Validation loss: 2.0925104438617663

Epoch: 5| Step: 9
Training loss: 0.8615924715995789
Validation loss: 2.1353446232375277

Epoch: 5| Step: 10
Training loss: 0.8900919556617737
Validation loss: 2.1381905386524815

Epoch: 374| Step: 0
Training loss: 1.3727829456329346
Validation loss: 2.159554804525068

Epoch: 5| Step: 1
Training loss: 1.280799150466919
Validation loss: 2.210953276644471

Epoch: 5| Step: 2
Training loss: 1.4999964237213135
Validation loss: 2.2059057348517963

Epoch: 5| Step: 3
Training loss: 1.2635557651519775
Validation loss: 2.1509265989385624

Epoch: 5| Step: 4
Training loss: 1.3603041172027588
Validation loss: 2.138091330887169

Epoch: 5| Step: 5
Training loss: 1.863114356994629
Validation loss: 2.1092276009180213

Epoch: 5| Step: 6
Training loss: 1.0066349506378174
Validation loss: 2.106059141056512

Epoch: 5| Step: 7
Training loss: 1.2210749387741089
Validation loss: 2.1179043118671705

Epoch: 5| Step: 8
Training loss: 2.046304941177368
Validation loss: 2.1253049245444675

Epoch: 5| Step: 9
Training loss: 1.9494367837905884
Validation loss: 2.1190043162274104

Epoch: 5| Step: 10
Training loss: 1.4519612789154053
Validation loss: 2.11243038792764

Epoch: 375| Step: 0
Training loss: 0.9291622042655945
Validation loss: 2.078817835418127

Epoch: 5| Step: 1
Training loss: 2.1798341274261475
Validation loss: 2.0556398360959944

Epoch: 5| Step: 2
Training loss: 2.0307884216308594
Validation loss: 2.0455798308054605

Epoch: 5| Step: 3
Training loss: 0.9769167900085449
Validation loss: 2.039963601737894

Epoch: 5| Step: 4
Training loss: 1.7150051593780518
Validation loss: 2.0701467785783993

Epoch: 5| Step: 5
Training loss: 1.4771764278411865
Validation loss: 2.102747577492909

Epoch: 5| Step: 6
Training loss: 1.1620476245880127
Validation loss: 2.1220583723437403

Epoch: 5| Step: 7
Training loss: 1.4078094959259033
Validation loss: 2.1392195276034776

Epoch: 5| Step: 8
Training loss: 1.6755698919296265
Validation loss: 2.1241307438060804

Epoch: 5| Step: 9
Training loss: 1.1189606189727783
Validation loss: 2.112139178860572

Epoch: 5| Step: 10
Training loss: 1.8352259397506714
Validation loss: 2.1293232434539386

Epoch: 376| Step: 0
Training loss: 1.1970617771148682
Validation loss: 2.1296848802156347

Epoch: 5| Step: 1
Training loss: 2.181366205215454
Validation loss: 2.102905334964875

Epoch: 5| Step: 2
Training loss: 1.806423544883728
Validation loss: 2.08245184088266

Epoch: 5| Step: 3
Training loss: 1.581713318824768
Validation loss: 2.080978516609438

Epoch: 5| Step: 4
Training loss: 1.3529049158096313
Validation loss: 2.109691171235936

Epoch: 5| Step: 5
Training loss: 1.6587083339691162
Validation loss: 2.1106156508127847

Epoch: 5| Step: 6
Training loss: 1.5736312866210938
Validation loss: 2.0637262149523665

Epoch: 5| Step: 7
Training loss: 1.3041108846664429
Validation loss: 2.1086356537316435

Epoch: 5| Step: 8
Training loss: 1.172613501548767
Validation loss: 2.096040689817039

Epoch: 5| Step: 9
Training loss: 1.0025643110275269
Validation loss: 2.0739590083399126

Epoch: 5| Step: 10
Training loss: 1.3456997871398926
Validation loss: 2.0617978880482335

Epoch: 377| Step: 0
Training loss: 0.9903513789176941
Validation loss: 2.09613436396404

Epoch: 5| Step: 1
Training loss: 0.9881270527839661
Validation loss: 2.1054734581260273

Epoch: 5| Step: 2
Training loss: 1.2055799961090088
Validation loss: 2.1221709289858417

Epoch: 5| Step: 3
Training loss: 1.7058007717132568
Validation loss: 2.134670957442253

Epoch: 5| Step: 4
Training loss: 1.479204773902893
Validation loss: 2.147764322578266

Epoch: 5| Step: 5
Training loss: 1.7474448680877686
Validation loss: 2.141289234161377

Epoch: 5| Step: 6
Training loss: 2.108783006668091
Validation loss: 2.1331768702435236

Epoch: 5| Step: 7
Training loss: 1.3818271160125732
Validation loss: 2.0783231501938193

Epoch: 5| Step: 8
Training loss: 1.6991643905639648
Validation loss: 2.0666485858219925

Epoch: 5| Step: 9
Training loss: 1.5350592136383057
Validation loss: 2.028569452224239

Epoch: 5| Step: 10
Training loss: 0.9520362615585327
Validation loss: 2.0524323832604194

Epoch: 378| Step: 0
Training loss: 1.3222907781600952
Validation loss: 2.0582106421070714

Epoch: 5| Step: 1
Training loss: 1.5064232349395752
Validation loss: 2.064274569993378

Epoch: 5| Step: 2
Training loss: 1.3070844411849976
Validation loss: 2.0798536526259555

Epoch: 5| Step: 3
Training loss: 1.9652316570281982
Validation loss: 2.1355753303855978

Epoch: 5| Step: 4
Training loss: 1.1622045040130615
Validation loss: 2.158993051898095

Epoch: 5| Step: 5
Training loss: 1.8433482646942139
Validation loss: 2.1659566305016957

Epoch: 5| Step: 6
Training loss: 1.6944307088851929
Validation loss: 2.1554407201787478

Epoch: 5| Step: 7
Training loss: 1.525194764137268
Validation loss: 2.1567072201800603

Epoch: 5| Step: 8
Training loss: 1.1076576709747314
Validation loss: 2.1053944736398678

Epoch: 5| Step: 9
Training loss: 0.8789499402046204
Validation loss: 2.1154111841673493

Epoch: 5| Step: 10
Training loss: 1.6590648889541626
Validation loss: 2.066888283657771

Epoch: 379| Step: 0
Training loss: 1.561301350593567
Validation loss: 2.0350767899585027

Epoch: 5| Step: 1
Training loss: 1.5545953512191772
Validation loss: 2.0273124915297314

Epoch: 5| Step: 2
Training loss: 1.2738358974456787
Validation loss: 2.0134780791498

Epoch: 5| Step: 3
Training loss: 1.3785535097122192
Validation loss: 2.01686869641786

Epoch: 5| Step: 4
Training loss: 1.3539289236068726
Validation loss: 2.0445295815826743

Epoch: 5| Step: 5
Training loss: 1.164357304573059
Validation loss: 2.0514334376140306

Epoch: 5| Step: 6
Training loss: 1.813865065574646
Validation loss: 2.0948297028900473

Epoch: 5| Step: 7
Training loss: 1.6344003677368164
Validation loss: 2.116878258284702

Epoch: 5| Step: 8
Training loss: 1.759542465209961
Validation loss: 2.12862660807948

Epoch: 5| Step: 9
Training loss: 1.3556233644485474
Validation loss: 2.15996285920502

Epoch: 5| Step: 10
Training loss: 1.7903987169265747
Validation loss: 2.191317850543607

Epoch: 380| Step: 0
Training loss: 1.5006650686264038
Validation loss: 2.17877673333691

Epoch: 5| Step: 1
Training loss: 0.9826261401176453
Validation loss: 2.1942852709883

Epoch: 5| Step: 2
Training loss: 1.4710712432861328
Validation loss: 2.1257755230831843

Epoch: 5| Step: 3
Training loss: 1.5640686750411987
Validation loss: 2.080671569352509

Epoch: 5| Step: 4
Training loss: 1.103464126586914
Validation loss: 2.0234883639120285

Epoch: 5| Step: 5
Training loss: 1.401369571685791
Validation loss: 2.0034139156341553

Epoch: 5| Step: 6
Training loss: 1.240149736404419
Validation loss: 1.9995313844373148

Epoch: 5| Step: 7
Training loss: 1.7579982280731201
Validation loss: 1.9779814186916556

Epoch: 5| Step: 8
Training loss: 2.0071306228637695
Validation loss: 1.9897448157751432

Epoch: 5| Step: 9
Training loss: 1.6523540019989014
Validation loss: 1.9956187919903827

Epoch: 5| Step: 10
Training loss: 1.8252136707305908
Validation loss: 2.0356756512836744

Epoch: 381| Step: 0
Training loss: 1.4421722888946533
Validation loss: 2.039306104824107

Epoch: 5| Step: 1
Training loss: 1.4655864238739014
Validation loss: 2.0674061954662366

Epoch: 5| Step: 2
Training loss: 2.0281124114990234
Validation loss: 2.148052982104722

Epoch: 5| Step: 3
Training loss: 1.1829159259796143
Validation loss: 2.209672216446169

Epoch: 5| Step: 4
Training loss: 1.5219318866729736
Validation loss: 2.2512227207101803

Epoch: 5| Step: 5
Training loss: 1.3927857875823975
Validation loss: 2.2569587128136748

Epoch: 5| Step: 6
Training loss: 1.3371223211288452
Validation loss: 2.2506431071988997

Epoch: 5| Step: 7
Training loss: 1.0602355003356934
Validation loss: 2.2140430122293453

Epoch: 5| Step: 8
Training loss: 1.458897352218628
Validation loss: 2.1800347938332507

Epoch: 5| Step: 9
Training loss: 1.5791760683059692
Validation loss: 2.116751399091495

Epoch: 5| Step: 10
Training loss: 1.287470817565918
Validation loss: 2.076427318716562

Epoch: 382| Step: 0
Training loss: 1.196334719657898
Validation loss: 2.0490688700829782

Epoch: 5| Step: 1
Training loss: 1.1855552196502686
Validation loss: 2.0328693582165624

Epoch: 5| Step: 2
Training loss: 1.3870278596878052
Validation loss: 2.0356846560714064

Epoch: 5| Step: 3
Training loss: 1.8596675395965576
Validation loss: 2.0372416665477138

Epoch: 5| Step: 4
Training loss: 1.5337337255477905
Validation loss: 2.0537568728129068

Epoch: 5| Step: 5
Training loss: 1.5574133396148682
Validation loss: 2.0820267943925757

Epoch: 5| Step: 6
Training loss: 1.2526012659072876
Validation loss: 2.066259845610588

Epoch: 5| Step: 7
Training loss: 1.3795762062072754
Validation loss: 2.1190984095296552

Epoch: 5| Step: 8
Training loss: 1.1490017175674438
Validation loss: 2.190154478114138

Epoch: 5| Step: 9
Training loss: 1.515871286392212
Validation loss: 2.2347601216326476

Epoch: 5| Step: 10
Training loss: 1.9614877700805664
Validation loss: 2.2554413451943347

Epoch: 383| Step: 0
Training loss: 1.309868335723877
Validation loss: 2.169243968943114

Epoch: 5| Step: 1
Training loss: 1.564390778541565
Validation loss: 2.1896240583030124

Epoch: 5| Step: 2
Training loss: 1.5221889019012451
Validation loss: 2.148035410911806

Epoch: 5| Step: 3
Training loss: 1.8749805688858032
Validation loss: 2.096487802843894

Epoch: 5| Step: 4
Training loss: 1.119911551475525
Validation loss: 2.0650107937474407

Epoch: 5| Step: 5
Training loss: 1.3023300170898438
Validation loss: 2.0596947798164944

Epoch: 5| Step: 6
Training loss: 1.6473281383514404
Validation loss: 2.0553290446599326

Epoch: 5| Step: 7
Training loss: 1.2415688037872314
Validation loss: 2.042035771954444

Epoch: 5| Step: 8
Training loss: 1.482417106628418
Validation loss: 2.038885901051183

Epoch: 5| Step: 9
Training loss: 1.3816981315612793
Validation loss: 2.088364771617356

Epoch: 5| Step: 10
Training loss: 1.3726682662963867
Validation loss: 2.1286790473486787

Epoch: 384| Step: 0
Training loss: 1.3579374551773071
Validation loss: 2.130319280009116

Epoch: 5| Step: 1
Training loss: 1.366930603981018
Validation loss: 2.1017193178976736

Epoch: 5| Step: 2
Training loss: 1.6032631397247314
Validation loss: 2.1047064258206274

Epoch: 5| Step: 3
Training loss: 0.9613750576972961
Validation loss: 2.135577832498858

Epoch: 5| Step: 4
Training loss: 1.1777441501617432
Validation loss: 2.1453546939357633

Epoch: 5| Step: 5
Training loss: 1.6954619884490967
Validation loss: 2.14768341536163

Epoch: 5| Step: 6
Training loss: 1.2009108066558838
Validation loss: 2.127370934332571

Epoch: 5| Step: 7
Training loss: 1.132204294204712
Validation loss: 2.1277801875145204

Epoch: 5| Step: 8
Training loss: 1.9496901035308838
Validation loss: 2.124551021924583

Epoch: 5| Step: 9
Training loss: 1.6926014423370361
Validation loss: 2.139882141543973

Epoch: 5| Step: 10
Training loss: 1.4449207782745361
Validation loss: 2.1214894889503397

Epoch: 385| Step: 0
Training loss: 1.470844030380249
Validation loss: 2.118768178006654

Epoch: 5| Step: 1
Training loss: 1.1694059371948242
Validation loss: 2.104528127178069

Epoch: 5| Step: 2
Training loss: 1.2854126691818237
Validation loss: 2.1078782978878228

Epoch: 5| Step: 3
Training loss: 1.731492280960083
Validation loss: 2.177326388256524

Epoch: 5| Step: 4
Training loss: 1.447908639907837
Validation loss: 2.1729392800279843

Epoch: 5| Step: 5
Training loss: 1.0742536783218384
Validation loss: 2.1306591803027737

Epoch: 5| Step: 6
Training loss: 1.4830973148345947
Validation loss: 2.107931875413464

Epoch: 5| Step: 7
Training loss: 1.1913909912109375
Validation loss: 2.0424477541318504

Epoch: 5| Step: 8
Training loss: 1.2878687381744385
Validation loss: 2.087411706165601

Epoch: 5| Step: 9
Training loss: 1.7347818613052368
Validation loss: 2.088968466686946

Epoch: 5| Step: 10
Training loss: 2.0813188552856445
Validation loss: 2.1195998114924275

Epoch: 386| Step: 0
Training loss: 1.171371579170227
Validation loss: 2.138888374451668

Epoch: 5| Step: 1
Training loss: 1.0013341903686523
Validation loss: 2.1333323909390356

Epoch: 5| Step: 2
Training loss: 1.5793904066085815
Validation loss: 2.121718724568685

Epoch: 5| Step: 3
Training loss: 1.4316407442092896
Validation loss: 2.119775068375372

Epoch: 5| Step: 4
Training loss: 1.236615538597107
Validation loss: 2.1643750077934674

Epoch: 5| Step: 5
Training loss: 1.3266491889953613
Validation loss: 2.121653349168839

Epoch: 5| Step: 6
Training loss: 1.2288331985473633
Validation loss: 2.0666522313189764

Epoch: 5| Step: 7
Training loss: 2.013932466506958
Validation loss: 2.065035109878868

Epoch: 5| Step: 8
Training loss: 1.9735504388809204
Validation loss: 2.032777137653802

Epoch: 5| Step: 9
Training loss: 1.3413076400756836
Validation loss: 2.0516129475767895

Epoch: 5| Step: 10
Training loss: 1.5565952062606812
Validation loss: 2.0519092031704482

Epoch: 387| Step: 0
Training loss: 1.4323270320892334
Validation loss: 2.0799914278009886

Epoch: 5| Step: 1
Training loss: 1.4343267679214478
Validation loss: 2.1179781318992696

Epoch: 5| Step: 2
Training loss: 1.5144833326339722
Validation loss: 2.1528882582982383

Epoch: 5| Step: 3
Training loss: 1.183532476425171
Validation loss: 2.1432535532982118

Epoch: 5| Step: 4
Training loss: 1.243996500968933
Validation loss: 2.122034130557891

Epoch: 5| Step: 5
Training loss: 1.6489505767822266
Validation loss: 2.0881409439989316

Epoch: 5| Step: 6
Training loss: 1.458142876625061
Validation loss: 2.0826757441284838

Epoch: 5| Step: 7
Training loss: 1.221297264099121
Validation loss: 2.13332091095627

Epoch: 5| Step: 8
Training loss: 1.1132402420043945
Validation loss: 2.107368967866385

Epoch: 5| Step: 9
Training loss: 2.2925846576690674
Validation loss: 2.152994719884729

Epoch: 5| Step: 10
Training loss: 0.8783053159713745
Validation loss: 2.1399786190320085

Epoch: 388| Step: 0
Training loss: 1.251047134399414
Validation loss: 2.1032752221630466

Epoch: 5| Step: 1
Training loss: 0.9640007019042969
Validation loss: 2.086000934723885

Epoch: 5| Step: 2
Training loss: 1.9332517385482788
Validation loss: 2.0616502095294256

Epoch: 5| Step: 3
Training loss: 1.627585768699646
Validation loss: 2.0827576114285375

Epoch: 5| Step: 4
Training loss: 1.2157647609710693
Validation loss: 2.058572757628656

Epoch: 5| Step: 5
Training loss: 1.2992231845855713
Validation loss: 2.0549162562175463

Epoch: 5| Step: 6
Training loss: 1.792458176612854
Validation loss: 2.021540762275778

Epoch: 5| Step: 7
Training loss: 1.3997490406036377
Validation loss: 2.062635411498367

Epoch: 5| Step: 8
Training loss: 1.160302758216858
Validation loss: 2.1130466307363203

Epoch: 5| Step: 9
Training loss: 1.3092423677444458
Validation loss: 2.121359207296884

Epoch: 5| Step: 10
Training loss: 1.6592084169387817
Validation loss: 2.161060446052141

Epoch: 389| Step: 0
Training loss: 1.7210010290145874
Validation loss: 2.1794320178288284

Epoch: 5| Step: 1
Training loss: 1.361648440361023
Validation loss: 2.1574816203886464

Epoch: 5| Step: 2
Training loss: 1.7516082525253296
Validation loss: 2.1655118029604674

Epoch: 5| Step: 3
Training loss: 1.4101841449737549
Validation loss: 2.121927297243508

Epoch: 5| Step: 4
Training loss: 2.1213502883911133
Validation loss: 2.104430639615623

Epoch: 5| Step: 5
Training loss: 1.3662786483764648
Validation loss: 2.089756809255128

Epoch: 5| Step: 6
Training loss: 1.4415009021759033
Validation loss: 2.1041607113294702

Epoch: 5| Step: 7
Training loss: 0.8231579065322876
Validation loss: 2.0693673164613786

Epoch: 5| Step: 8
Training loss: 1.584351897239685
Validation loss: 2.0707380143545007

Epoch: 5| Step: 9
Training loss: 0.9019098281860352
Validation loss: 2.0325605395019695

Epoch: 5| Step: 10
Training loss: 0.8470368385314941
Validation loss: 2.059175575933149

Epoch: 390| Step: 0
Training loss: 1.2789490222930908
Validation loss: 2.0399800628744145

Epoch: 5| Step: 1
Training loss: 1.3766874074935913
Validation loss: 2.065019174288678

Epoch: 5| Step: 2
Training loss: 1.2975575923919678
Validation loss: 2.036980705876504

Epoch: 5| Step: 3
Training loss: 1.299856185913086
Validation loss: 2.096533352328885

Epoch: 5| Step: 4
Training loss: 1.386736512184143
Validation loss: 2.1559746367957002

Epoch: 5| Step: 5
Training loss: 1.462051510810852
Validation loss: 2.2113277989049114

Epoch: 5| Step: 6
Training loss: 1.2460987567901611
Validation loss: 2.2461660985023744

Epoch: 5| Step: 7
Training loss: 1.2878270149230957
Validation loss: 2.2521811351981214

Epoch: 5| Step: 8
Training loss: 1.623721718788147
Validation loss: 2.206694363265909

Epoch: 5| Step: 9
Training loss: 1.704097032546997
Validation loss: 2.1744399865468345

Epoch: 5| Step: 10
Training loss: 1.495621919631958
Validation loss: 2.140095382608393

Epoch: 391| Step: 0
Training loss: 1.7218191623687744
Validation loss: 2.090621994387719

Epoch: 5| Step: 1
Training loss: 1.7023341655731201
Validation loss: 2.055215661243726

Epoch: 5| Step: 2
Training loss: 1.5528523921966553
Validation loss: 2.0456177829414286

Epoch: 5| Step: 3
Training loss: 1.6306617259979248
Validation loss: 2.0001415193721814

Epoch: 5| Step: 4
Training loss: 1.1213632822036743
Validation loss: 2.016631469931654

Epoch: 5| Step: 5
Training loss: 1.4166862964630127
Validation loss: 2.0242501856178365

Epoch: 5| Step: 6
Training loss: 1.2009387016296387
Validation loss: 2.044957296822661

Epoch: 5| Step: 7
Training loss: 1.274020791053772
Validation loss: 2.063701634765953

Epoch: 5| Step: 8
Training loss: 1.2825632095336914
Validation loss: 2.11873467891447

Epoch: 5| Step: 9
Training loss: 1.3058019876480103
Validation loss: 2.187965199511538

Epoch: 5| Step: 10
Training loss: 1.1946144104003906
Validation loss: 2.2234678332523634

Epoch: 392| Step: 0
Training loss: 1.0776447057724
Validation loss: 2.265561608858006

Epoch: 5| Step: 1
Training loss: 1.4438114166259766
Validation loss: 2.2672836408820203

Epoch: 5| Step: 2
Training loss: 1.871346116065979
Validation loss: 2.2869916769766037

Epoch: 5| Step: 3
Training loss: 2.0460894107818604
Validation loss: 2.23799495286839

Epoch: 5| Step: 4
Training loss: 1.4243872165679932
Validation loss: 2.1750417063313146

Epoch: 5| Step: 5
Training loss: 1.5370279550552368
Validation loss: 2.1425032461843183

Epoch: 5| Step: 6
Training loss: 1.2690227031707764
Validation loss: 2.084503730138143

Epoch: 5| Step: 7
Training loss: 1.1782386302947998
Validation loss: 2.046341726856847

Epoch: 5| Step: 8
Training loss: 1.1990959644317627
Validation loss: 2.052081820785358

Epoch: 5| Step: 9
Training loss: 1.1052497625350952
Validation loss: 2.0406931292626167

Epoch: 5| Step: 10
Training loss: 1.3151240348815918
Validation loss: 2.016502147079796

Epoch: 393| Step: 0
Training loss: 1.4792914390563965
Validation loss: 2.0428639099162114

Epoch: 5| Step: 1
Training loss: 1.5913466215133667
Validation loss: 2.0411318271390853

Epoch: 5| Step: 2
Training loss: 1.1399809122085571
Validation loss: 2.0559876759847007

Epoch: 5| Step: 3
Training loss: 1.7649080753326416
Validation loss: 2.084607731911444

Epoch: 5| Step: 4
Training loss: 1.7037153244018555
Validation loss: 2.115758386991357

Epoch: 5| Step: 5
Training loss: 1.464484453201294
Validation loss: 2.140285183024663

Epoch: 5| Step: 6
Training loss: 1.5661119222640991
Validation loss: 2.1129327345919866

Epoch: 5| Step: 7
Training loss: 1.1839377880096436
Validation loss: 2.1307092533316663

Epoch: 5| Step: 8
Training loss: 1.1713964939117432
Validation loss: 2.08412028128101

Epoch: 5| Step: 9
Training loss: 1.250194787979126
Validation loss: 2.1253450250112884

Epoch: 5| Step: 10
Training loss: 0.850791871547699
Validation loss: 2.145545977418141

Epoch: 394| Step: 0
Training loss: 1.5393879413604736
Validation loss: 2.118216214641448

Epoch: 5| Step: 1
Training loss: 1.4262480735778809
Validation loss: 2.101503551647227

Epoch: 5| Step: 2
Training loss: 1.4721342325210571
Validation loss: 2.061972855239786

Epoch: 5| Step: 3
Training loss: 1.3132799863815308
Validation loss: 2.019576495693576

Epoch: 5| Step: 4
Training loss: 1.3501323461532593
Validation loss: 2.0502669272884244

Epoch: 5| Step: 5
Training loss: 1.467969298362732
Validation loss: 2.044699926530161

Epoch: 5| Step: 6
Training loss: 1.709381103515625
Validation loss: 2.0212023847846576

Epoch: 5| Step: 7
Training loss: 1.2708057165145874
Validation loss: 2.0588122490913636

Epoch: 5| Step: 8
Training loss: 1.5353256464004517
Validation loss: 2.100103283441195

Epoch: 5| Step: 9
Training loss: 1.145263433456421
Validation loss: 2.070625187248312

Epoch: 5| Step: 10
Training loss: 0.8630053997039795
Validation loss: 2.073573576506748

Epoch: 395| Step: 0
Training loss: 1.3994176387786865
Validation loss: 2.0613753398259482

Epoch: 5| Step: 1
Training loss: 0.7580969929695129
Validation loss: 2.089146278237784

Epoch: 5| Step: 2
Training loss: 1.4677972793579102
Validation loss: 2.0960927919674943

Epoch: 5| Step: 3
Training loss: 1.4286882877349854
Validation loss: 2.075434059225103

Epoch: 5| Step: 4
Training loss: 1.2027937173843384
Validation loss: 2.072085121626495

Epoch: 5| Step: 5
Training loss: 1.2105728387832642
Validation loss: 2.0582533587691603

Epoch: 5| Step: 6
Training loss: 1.6438621282577515
Validation loss: 2.0498645074905886

Epoch: 5| Step: 7
Training loss: 1.445292353630066
Validation loss: 2.0966323524393062

Epoch: 5| Step: 8
Training loss: 1.9591665267944336
Validation loss: 2.071266678071791

Epoch: 5| Step: 9
Training loss: 1.1198149919509888
Validation loss: 2.052641572490815

Epoch: 5| Step: 10
Training loss: 1.58076810836792
Validation loss: 2.0775649573213313

Epoch: 396| Step: 0
Training loss: 1.2646218538284302
Validation loss: 2.0540809221165155

Epoch: 5| Step: 1
Training loss: 1.86038339138031
Validation loss: 2.083817071812127

Epoch: 5| Step: 2
Training loss: 1.5986658334732056
Validation loss: 2.0673267328610985

Epoch: 5| Step: 3
Training loss: 1.5313104391098022
Validation loss: 2.111470350655176

Epoch: 5| Step: 4
Training loss: 1.3855475187301636
Validation loss: 2.0847244967696485

Epoch: 5| Step: 5
Training loss: 1.5218578577041626
Validation loss: 2.090584405006901

Epoch: 5| Step: 6
Training loss: 1.8056488037109375
Validation loss: 2.090540316797072

Epoch: 5| Step: 7
Training loss: 0.990386962890625
Validation loss: 2.083214311189549

Epoch: 5| Step: 8
Training loss: 1.3042032718658447
Validation loss: 2.1071038169245564

Epoch: 5| Step: 9
Training loss: 0.7392102479934692
Validation loss: 2.127797125488199

Epoch: 5| Step: 10
Training loss: 0.9204354286193848
Validation loss: 2.150049122430945

Epoch: 397| Step: 0
Training loss: 1.2862907648086548
Validation loss: 2.132855257680339

Epoch: 5| Step: 1
Training loss: 1.2364501953125
Validation loss: 2.1172187943612375

Epoch: 5| Step: 2
Training loss: 1.1424401998519897
Validation loss: 2.079547275779068

Epoch: 5| Step: 3
Training loss: 1.1234114170074463
Validation loss: 2.069626162129064

Epoch: 5| Step: 4
Training loss: 1.2578901052474976
Validation loss: 2.078184154725844

Epoch: 5| Step: 5
Training loss: 2.0117244720458984
Validation loss: 2.1168674756121892

Epoch: 5| Step: 6
Training loss: 1.4227416515350342
Validation loss: 2.1238921380812124

Epoch: 5| Step: 7
Training loss: 1.3252954483032227
Validation loss: 2.113901517724478

Epoch: 5| Step: 8
Training loss: 1.4139492511749268
Validation loss: 2.1000415125200824

Epoch: 5| Step: 9
Training loss: 1.3687840700149536
Validation loss: 2.072358459554693

Epoch: 5| Step: 10
Training loss: 1.3924322128295898
Validation loss: 2.05930583964112

Epoch: 398| Step: 0
Training loss: 1.5124326944351196
Validation loss: 2.1004841250758015

Epoch: 5| Step: 1
Training loss: 1.3376123905181885
Validation loss: 2.080269734064738

Epoch: 5| Step: 2
Training loss: 1.5522806644439697
Validation loss: 2.0647080585520756

Epoch: 5| Step: 3
Training loss: 1.3559495210647583
Validation loss: 2.04859051909498

Epoch: 5| Step: 4
Training loss: 1.3522541522979736
Validation loss: 2.0756062551211287

Epoch: 5| Step: 5
Training loss: 1.3872811794281006
Validation loss: 2.0702315145923245

Epoch: 5| Step: 6
Training loss: 1.1261221170425415
Validation loss: 2.0981579570360083

Epoch: 5| Step: 7
Training loss: 1.22256600856781
Validation loss: 2.163005264856482

Epoch: 5| Step: 8
Training loss: 1.4741021394729614
Validation loss: 2.1491398221702984

Epoch: 5| Step: 9
Training loss: 1.2950266599655151
Validation loss: 2.1165614217840214

Epoch: 5| Step: 10
Training loss: 1.490270733833313
Validation loss: 2.1309544117219987

Epoch: 399| Step: 0
Training loss: 0.8836663961410522
Validation loss: 2.052014534191419

Epoch: 5| Step: 1
Training loss: 1.2268706560134888
Validation loss: 2.0312579254950247

Epoch: 5| Step: 2
Training loss: 1.6691539287567139
Validation loss: 2.011936867108909

Epoch: 5| Step: 3
Training loss: 1.265020728111267
Validation loss: 2.0050445884786625

Epoch: 5| Step: 4
Training loss: 1.2699358463287354
Validation loss: 2.0069924169971096

Epoch: 5| Step: 5
Training loss: 1.4737318754196167
Validation loss: 2.0367732586399203

Epoch: 5| Step: 6
Training loss: 1.40778386592865
Validation loss: 2.064072266701729

Epoch: 5| Step: 7
Training loss: 1.424425721168518
Validation loss: 2.0873503274815057

Epoch: 5| Step: 8
Training loss: 1.0975873470306396
Validation loss: 2.123565238009217

Epoch: 5| Step: 9
Training loss: 1.5685502290725708
Validation loss: 2.1469727459774224

Epoch: 5| Step: 10
Training loss: 1.9567294120788574
Validation loss: 2.1892470364929526

Epoch: 400| Step: 0
Training loss: 1.6552257537841797
Validation loss: 2.195141233423705

Epoch: 5| Step: 1
Training loss: 1.1421626806259155
Validation loss: 2.1913051553951797

Epoch: 5| Step: 2
Training loss: 0.9997408986091614
Validation loss: 2.1828415598920596

Epoch: 5| Step: 3
Training loss: 1.714043378829956
Validation loss: 2.161274471590596

Epoch: 5| Step: 4
Training loss: 1.094496726989746
Validation loss: 2.1116690251135055

Epoch: 5| Step: 5
Training loss: 0.8927024006843567
Validation loss: 2.0815284085530106

Epoch: 5| Step: 6
Training loss: 1.7932698726654053
Validation loss: 2.0387337066793956

Epoch: 5| Step: 7
Training loss: 1.4904534816741943
Validation loss: 2.0369522443381687

Epoch: 5| Step: 8
Training loss: 1.6912553310394287
Validation loss: 2.0427163416339504

Epoch: 5| Step: 9
Training loss: 1.0372618436813354
Validation loss: 2.009518889970677

Epoch: 5| Step: 10
Training loss: 1.5816128253936768
Validation loss: 1.9990394679448937

Epoch: 401| Step: 0
Training loss: 1.4944186210632324
Validation loss: 2.0379527922599547

Epoch: 5| Step: 1
Training loss: 1.4342454671859741
Validation loss: 2.088201540772633

Epoch: 5| Step: 2
Training loss: 1.4191449880599976
Validation loss: 2.1120931935566727

Epoch: 5| Step: 3
Training loss: 1.407220482826233
Validation loss: 2.162515163421631

Epoch: 5| Step: 4
Training loss: 1.766078233718872
Validation loss: 2.2083983511053105

Epoch: 5| Step: 5
Training loss: 1.3608524799346924
Validation loss: 2.1629664000644477

Epoch: 5| Step: 6
Training loss: 1.1071722507476807
Validation loss: 2.163395030524141

Epoch: 5| Step: 7
Training loss: 1.3811876773834229
Validation loss: 2.1662041346232095

Epoch: 5| Step: 8
Training loss: 1.4187287092208862
Validation loss: 2.161164299134285

Epoch: 5| Step: 9
Training loss: 0.7739365696907043
Validation loss: 2.127699752007761

Epoch: 5| Step: 10
Training loss: 1.355328917503357
Validation loss: 2.0880004744375906

Epoch: 402| Step: 0
Training loss: 1.6655597686767578
Validation loss: 2.068202050783301

Epoch: 5| Step: 1
Training loss: 1.2838940620422363
Validation loss: 2.045949859003867

Epoch: 5| Step: 2
Training loss: 0.7474310994148254
Validation loss: 2.0482835051833943

Epoch: 5| Step: 3
Training loss: 1.4488199949264526
Validation loss: 2.0143649988276984

Epoch: 5| Step: 4
Training loss: 0.7484098076820374
Validation loss: 2.0159179382426764

Epoch: 5| Step: 5
Training loss: 1.4659717082977295
Validation loss: 2.033908112074739

Epoch: 5| Step: 6
Training loss: 1.2795766592025757
Validation loss: 2.0485034373498734

Epoch: 5| Step: 7
Training loss: 1.316702127456665
Validation loss: 2.053440991268363

Epoch: 5| Step: 8
Training loss: 1.3259629011154175
Validation loss: 2.0875686778817126

Epoch: 5| Step: 9
Training loss: 2.486497163772583
Validation loss: 2.126649215657224

Epoch: 5| Step: 10
Training loss: 1.258413553237915
Validation loss: 2.144285712190854

Epoch: 403| Step: 0
Training loss: 2.1609723567962646
Validation loss: 2.1704814280233076

Epoch: 5| Step: 1
Training loss: 1.590331792831421
Validation loss: 2.18359225796115

Epoch: 5| Step: 2
Training loss: 1.2837183475494385
Validation loss: 2.14099536659897

Epoch: 5| Step: 3
Training loss: 1.056563377380371
Validation loss: 2.094343316170477

Epoch: 5| Step: 4
Training loss: 1.1924470663070679
Validation loss: 2.0636983712514243

Epoch: 5| Step: 5
Training loss: 0.8617056608200073
Validation loss: 2.099530412304786

Epoch: 5| Step: 6
Training loss: 0.9087527990341187
Validation loss: 2.0294288435289936

Epoch: 5| Step: 7
Training loss: 1.5105605125427246
Validation loss: 2.037387340299545

Epoch: 5| Step: 8
Training loss: 1.2776734828948975
Validation loss: 2.0187404283913235

Epoch: 5| Step: 9
Training loss: 1.3107707500457764
Validation loss: 2.0461923691534225

Epoch: 5| Step: 10
Training loss: 1.753984808921814
Validation loss: 2.0602771492414576

Epoch: 404| Step: 0
Training loss: 1.277449369430542
Validation loss: 2.0621674624822472

Epoch: 5| Step: 1
Training loss: 1.1553194522857666
Validation loss: 2.0762486688552366

Epoch: 5| Step: 2
Training loss: 1.147277593612671
Validation loss: 2.0709521488476823

Epoch: 5| Step: 3
Training loss: 1.400683045387268
Validation loss: 2.0964803118859567

Epoch: 5| Step: 4
Training loss: 1.3763530254364014
Validation loss: 2.1330551075679

Epoch: 5| Step: 5
Training loss: 1.2063243389129639
Validation loss: 2.082154832860475

Epoch: 5| Step: 6
Training loss: 0.9385770559310913
Validation loss: 2.096049354922387

Epoch: 5| Step: 7
Training loss: 1.5940229892730713
Validation loss: 2.1139899812718874

Epoch: 5| Step: 8
Training loss: 1.2034951448440552
Validation loss: 2.0759958323612007

Epoch: 5| Step: 9
Training loss: 1.5524413585662842
Validation loss: 2.068554482152385

Epoch: 5| Step: 10
Training loss: 1.663172960281372
Validation loss: 2.078115200483671

Epoch: 405| Step: 0
Training loss: 2.000653028488159
Validation loss: 2.096144945390763

Epoch: 5| Step: 1
Training loss: 0.8010693788528442
Validation loss: 2.0776594761879212

Epoch: 5| Step: 2
Training loss: 1.849225401878357
Validation loss: 2.0825378228259344

Epoch: 5| Step: 3
Training loss: 1.3496954441070557
Validation loss: 2.1022746204048075

Epoch: 5| Step: 4
Training loss: 0.8776552081108093
Validation loss: 2.1224416379005677

Epoch: 5| Step: 5
Training loss: 1.3968262672424316
Validation loss: 2.1305008421662035

Epoch: 5| Step: 6
Training loss: 1.2963021993637085
Validation loss: 2.1350303414047405

Epoch: 5| Step: 7
Training loss: 1.4373118877410889
Validation loss: 2.128599069451773

Epoch: 5| Step: 8
Training loss: 1.389085054397583
Validation loss: 2.09733138802231

Epoch: 5| Step: 9
Training loss: 0.962586522102356
Validation loss: 2.082739517252932

Epoch: 5| Step: 10
Training loss: 1.2714929580688477
Validation loss: 2.1017402513052827

Epoch: 406| Step: 0
Training loss: 0.7888578176498413
Validation loss: 2.1051755707751036

Epoch: 5| Step: 1
Training loss: 0.9877235293388367
Validation loss: 2.101890961329142

Epoch: 5| Step: 2
Training loss: 1.5972448587417603
Validation loss: 2.1294457784263034

Epoch: 5| Step: 3
Training loss: 1.4255003929138184
Validation loss: 2.1088922151955227

Epoch: 5| Step: 4
Training loss: 1.1736372709274292
Validation loss: 2.100616221786827

Epoch: 5| Step: 5
Training loss: 1.5914777517318726
Validation loss: 2.096549625037819

Epoch: 5| Step: 6
Training loss: 1.7272379398345947
Validation loss: 2.121833755124

Epoch: 5| Step: 7
Training loss: 1.0089452266693115
Validation loss: 2.1174988746643066

Epoch: 5| Step: 8
Training loss: 1.5999515056610107
Validation loss: 2.1082038251302575

Epoch: 5| Step: 9
Training loss: 1.2546542882919312
Validation loss: 2.056910922450404

Epoch: 5| Step: 10
Training loss: 1.3580213785171509
Validation loss: 2.0753809687911824

Epoch: 407| Step: 0
Training loss: 1.3111258745193481
Validation loss: 2.0612853470669

Epoch: 5| Step: 1
Training loss: 1.6715657711029053
Validation loss: 2.083184121757425

Epoch: 5| Step: 2
Training loss: 1.1354771852493286
Validation loss: 2.054364158261207

Epoch: 5| Step: 3
Training loss: 1.5906871557235718
Validation loss: 2.046782555118684

Epoch: 5| Step: 4
Training loss: 0.7183977365493774
Validation loss: 2.06459576981042

Epoch: 5| Step: 5
Training loss: 0.9049205780029297
Validation loss: 2.094023228973471

Epoch: 5| Step: 6
Training loss: 1.8986902236938477
Validation loss: 2.09677243104545

Epoch: 5| Step: 7
Training loss: 1.0756303071975708
Validation loss: 2.119009619118065

Epoch: 5| Step: 8
Training loss: 1.1576707363128662
Validation loss: 2.119105879978467

Epoch: 5| Step: 9
Training loss: 1.186124324798584
Validation loss: 2.115447803210187

Epoch: 5| Step: 10
Training loss: 1.7684400081634521
Validation loss: 2.1080007194190897

Epoch: 408| Step: 0
Training loss: 1.030953288078308
Validation loss: 2.1023214555555776

Epoch: 5| Step: 1
Training loss: 1.912862777709961
Validation loss: 2.063352015710646

Epoch: 5| Step: 2
Training loss: 1.0475729703903198
Validation loss: 2.058519205739421

Epoch: 5| Step: 3
Training loss: 1.4817163944244385
Validation loss: 2.035875619098704

Epoch: 5| Step: 4
Training loss: 1.634930968284607
Validation loss: 2.0420779951157106

Epoch: 5| Step: 5
Training loss: 1.284749150276184
Validation loss: 2.024732400012273

Epoch: 5| Step: 6
Training loss: 1.155949354171753
Validation loss: 2.060549856514059

Epoch: 5| Step: 7
Training loss: 1.0813748836517334
Validation loss: 2.076682940606148

Epoch: 5| Step: 8
Training loss: 0.9136239290237427
Validation loss: 2.121458738080917

Epoch: 5| Step: 9
Training loss: 1.2707182168960571
Validation loss: 2.1255998252540507

Epoch: 5| Step: 10
Training loss: 1.8478505611419678
Validation loss: 2.144046647574312

Epoch: 409| Step: 0
Training loss: 1.696598768234253
Validation loss: 2.1130308310190835

Epoch: 5| Step: 1
Training loss: 1.3920619487762451
Validation loss: 2.106753169849355

Epoch: 5| Step: 2
Training loss: 1.2842768430709839
Validation loss: 2.1264825277431036

Epoch: 5| Step: 3
Training loss: 1.2074145078659058
Validation loss: 2.0965775738480272

Epoch: 5| Step: 4
Training loss: 1.4384578466415405
Validation loss: 2.1100528688840967

Epoch: 5| Step: 5
Training loss: 1.0417966842651367
Validation loss: 2.0956093931710846

Epoch: 5| Step: 6
Training loss: 1.158867359161377
Validation loss: 2.0831249836952455

Epoch: 5| Step: 7
Training loss: 1.1894581317901611
Validation loss: 2.0812522262655277

Epoch: 5| Step: 8
Training loss: 1.2815920114517212
Validation loss: 2.064377700128863

Epoch: 5| Step: 9
Training loss: 1.4312257766723633
Validation loss: 2.099264883225964

Epoch: 5| Step: 10
Training loss: 1.0319957733154297
Validation loss: 2.0706616447817896

Epoch: 410| Step: 0
Training loss: 1.3095247745513916
Validation loss: 2.0801161117451166

Epoch: 5| Step: 1
Training loss: 0.9793182611465454
Validation loss: 2.0811827451952043

Epoch: 5| Step: 2
Training loss: 1.5194981098175049
Validation loss: 2.0895393458745812

Epoch: 5| Step: 3
Training loss: 1.8667831420898438
Validation loss: 2.111822642305846

Epoch: 5| Step: 4
Training loss: 1.4227927923202515
Validation loss: 2.0893494441945064

Epoch: 5| Step: 5
Training loss: 1.3374565839767456
Validation loss: 2.0841078104511386

Epoch: 5| Step: 6
Training loss: 1.0165196657180786
Validation loss: 2.0834569136301675

Epoch: 5| Step: 7
Training loss: 1.1241246461868286
Validation loss: 2.0877196558060183

Epoch: 5| Step: 8
Training loss: 0.882115364074707
Validation loss: 2.060724313541125

Epoch: 5| Step: 9
Training loss: 1.0605789422988892
Validation loss: 2.0904648509076846

Epoch: 5| Step: 10
Training loss: 1.6191173791885376
Validation loss: 2.0797690704304683

Epoch: 411| Step: 0
Training loss: 1.081174373626709
Validation loss: 2.125776831821729

Epoch: 5| Step: 1
Training loss: 1.2448768615722656
Validation loss: 2.1391679086992816

Epoch: 5| Step: 2
Training loss: 1.1485952138900757
Validation loss: 2.1215318454209195

Epoch: 5| Step: 3
Training loss: 1.0508174896240234
Validation loss: 2.119566827692011

Epoch: 5| Step: 4
Training loss: 1.2828824520111084
Validation loss: 2.0983798350057294

Epoch: 5| Step: 5
Training loss: 1.289752721786499
Validation loss: 2.0561757959345335

Epoch: 5| Step: 6
Training loss: 1.1143804788589478
Validation loss: 2.0438850695087063

Epoch: 5| Step: 7
Training loss: 1.9206031560897827
Validation loss: 2.0488780006285636

Epoch: 5| Step: 8
Training loss: 1.212142825126648
Validation loss: 2.0865965530436528

Epoch: 5| Step: 9
Training loss: 1.679309606552124
Validation loss: 2.088304509398758

Epoch: 5| Step: 10
Training loss: 1.4629173278808594
Validation loss: 2.095616125291394

Epoch: 412| Step: 0
Training loss: 1.234116792678833
Validation loss: 2.0846958621855705

Epoch: 5| Step: 1
Training loss: 1.3035123348236084
Validation loss: 2.07793338324434

Epoch: 5| Step: 2
Training loss: 1.9095757007598877
Validation loss: 2.0876130032283005

Epoch: 5| Step: 3
Training loss: 1.453973412513733
Validation loss: 2.1216991896270425

Epoch: 5| Step: 4
Training loss: 0.9842567443847656
Validation loss: 2.147845627159201

Epoch: 5| Step: 5
Training loss: 1.301048994064331
Validation loss: 2.1194987681604203

Epoch: 5| Step: 6
Training loss: 0.9377815127372742
Validation loss: 2.0805158974021993

Epoch: 5| Step: 7
Training loss: 1.0426982641220093
Validation loss: 2.0621620660187094

Epoch: 5| Step: 8
Training loss: 1.2343358993530273
Validation loss: 2.0868289496309016

Epoch: 5| Step: 9
Training loss: 1.4825555086135864
Validation loss: 2.0606762439973894

Epoch: 5| Step: 10
Training loss: 1.4861921072006226
Validation loss: 2.047572289743731

Epoch: 413| Step: 0
Training loss: 1.2274575233459473
Validation loss: 2.057006174518216

Epoch: 5| Step: 1
Training loss: 1.318084478378296
Validation loss: 2.041960213773994

Epoch: 5| Step: 2
Training loss: 1.2016617059707642
Validation loss: 2.0436767314070012

Epoch: 5| Step: 3
Training loss: 1.5430686473846436
Validation loss: 2.0869915818655365

Epoch: 5| Step: 4
Training loss: 1.313624382019043
Validation loss: 2.097773631413778

Epoch: 5| Step: 5
Training loss: 1.455116629600525
Validation loss: 2.1442337677042973

Epoch: 5| Step: 6
Training loss: 0.8392986059188843
Validation loss: 2.127376151341264

Epoch: 5| Step: 7
Training loss: 1.1432619094848633
Validation loss: 2.1081547057756813

Epoch: 5| Step: 8
Training loss: 1.6154921054840088
Validation loss: 2.1229897865685086

Epoch: 5| Step: 9
Training loss: 1.5088497400283813
Validation loss: 2.107935352991986

Epoch: 5| Step: 10
Training loss: 1.1955206394195557
Validation loss: 2.075095679170342

Epoch: 414| Step: 0
Training loss: 1.1552419662475586
Validation loss: 2.047343982163296

Epoch: 5| Step: 1
Training loss: 1.0988597869873047
Validation loss: 2.06488379868128

Epoch: 5| Step: 2
Training loss: 1.6569690704345703
Validation loss: 2.095909946708269

Epoch: 5| Step: 3
Training loss: 1.3687210083007812
Validation loss: 2.1337488235965854

Epoch: 5| Step: 4
Training loss: 1.529952049255371
Validation loss: 2.090210558265768

Epoch: 5| Step: 5
Training loss: 1.4128791093826294
Validation loss: 2.1126718687754806

Epoch: 5| Step: 6
Training loss: 1.2811195850372314
Validation loss: 2.1131803451045865

Epoch: 5| Step: 7
Training loss: 0.8307433128356934
Validation loss: 2.1011774283583446

Epoch: 5| Step: 8
Training loss: 1.0245616436004639
Validation loss: 2.11219677617473

Epoch: 5| Step: 9
Training loss: 1.66169011592865
Validation loss: 2.0847064602759575

Epoch: 5| Step: 10
Training loss: 1.0947390794754028
Validation loss: 2.0692440412377797

Epoch: 415| Step: 0
Training loss: 1.4156831502914429
Validation loss: 2.037843112022646

Epoch: 5| Step: 1
Training loss: 1.1369411945343018
Validation loss: 2.0201832068863737

Epoch: 5| Step: 2
Training loss: 0.8185809254646301
Validation loss: 2.031826571751666

Epoch: 5| Step: 3
Training loss: 1.5711820125579834
Validation loss: 2.065544684727987

Epoch: 5| Step: 4
Training loss: 1.2677135467529297
Validation loss: 2.0904676939851496

Epoch: 5| Step: 5
Training loss: 1.6180986166000366
Validation loss: 2.087830078217291

Epoch: 5| Step: 6
Training loss: 1.0444965362548828
Validation loss: 2.1429586025976364

Epoch: 5| Step: 7
Training loss: 1.5432685613632202
Validation loss: 2.105982618947183

Epoch: 5| Step: 8
Training loss: 0.9762805104255676
Validation loss: 2.108836204774918

Epoch: 5| Step: 9
Training loss: 1.2155330181121826
Validation loss: 2.1320422849347516

Epoch: 5| Step: 10
Training loss: 1.3354895114898682
Validation loss: 2.1230849835180465

Epoch: 416| Step: 0
Training loss: 1.4565759897232056
Validation loss: 2.1070552666982016

Epoch: 5| Step: 1
Training loss: 1.1963517665863037
Validation loss: 2.102302194923483

Epoch: 5| Step: 2
Training loss: 1.6527820825576782
Validation loss: 2.0468722748500046

Epoch: 5| Step: 3
Training loss: 1.579472303390503
Validation loss: 2.074850836107808

Epoch: 5| Step: 4
Training loss: 1.0874302387237549
Validation loss: 2.046609854185453

Epoch: 5| Step: 5
Training loss: 1.0721420049667358
Validation loss: 2.0576430802704184

Epoch: 5| Step: 6
Training loss: 1.1238040924072266
Validation loss: 2.0727539395773285

Epoch: 5| Step: 7
Training loss: 0.8579753041267395
Validation loss: 2.0444965260003203

Epoch: 5| Step: 8
Training loss: 1.595287561416626
Validation loss: 2.051995300477551

Epoch: 5| Step: 9
Training loss: 1.0848134756088257
Validation loss: 2.0501012597032773

Epoch: 5| Step: 10
Training loss: 1.2344567775726318
Validation loss: 2.069551211531444

Epoch: 417| Step: 0
Training loss: 1.327429175376892
Validation loss: 2.112265335616245

Epoch: 5| Step: 1
Training loss: 0.8040227890014648
Validation loss: 2.12146831071505

Epoch: 5| Step: 2
Training loss: 1.694968819618225
Validation loss: 2.14820433175692

Epoch: 5| Step: 3
Training loss: 1.3129396438598633
Validation loss: 2.153564142924483

Epoch: 5| Step: 4
Training loss: 0.8660010099411011
Validation loss: 2.1221865274572886

Epoch: 5| Step: 5
Training loss: 0.6417022943496704
Validation loss: 2.078584647947742

Epoch: 5| Step: 6
Training loss: 1.135080337524414
Validation loss: 2.035216489145833

Epoch: 5| Step: 7
Training loss: 1.7137343883514404
Validation loss: 2.0199993630891204

Epoch: 5| Step: 8
Training loss: 1.0202734470367432
Validation loss: 2.0286659630396033

Epoch: 5| Step: 9
Training loss: 2.0140678882598877
Validation loss: 1.9984883980084491

Epoch: 5| Step: 10
Training loss: 1.5237462520599365
Validation loss: 2.000232458114624

Epoch: 418| Step: 0
Training loss: 1.0410534143447876
Validation loss: 2.0204096737728325

Epoch: 5| Step: 1
Training loss: 1.5205672979354858
Validation loss: 2.063499963411721

Epoch: 5| Step: 2
Training loss: 0.9337354898452759
Validation loss: 2.1030942957888366

Epoch: 5| Step: 3
Training loss: 0.9739181399345398
Validation loss: 2.1503785130798176

Epoch: 5| Step: 4
Training loss: 1.2826296091079712
Validation loss: 2.1865722927995908

Epoch: 5| Step: 5
Training loss: 1.2823090553283691
Validation loss: 2.174929726508356

Epoch: 5| Step: 6
Training loss: 1.2420270442962646
Validation loss: 2.1510176761175996

Epoch: 5| Step: 7
Training loss: 1.4412510395050049
Validation loss: 2.132309744434972

Epoch: 5| Step: 8
Training loss: 1.1272469758987427
Validation loss: 2.1118860808751916

Epoch: 5| Step: 9
Training loss: 1.2515817880630493
Validation loss: 2.0410974820454917

Epoch: 5| Step: 10
Training loss: 2.0448551177978516
Validation loss: 2.0437014436209076

Epoch: 419| Step: 0
Training loss: 1.3203418254852295
Validation loss: 2.0466328179964455

Epoch: 5| Step: 1
Training loss: 1.411750078201294
Validation loss: 2.081546352755639

Epoch: 5| Step: 2
Training loss: 1.5808361768722534
Validation loss: 2.0618081528653383

Epoch: 5| Step: 3
Training loss: 1.6330692768096924
Validation loss: 2.0732453869235132

Epoch: 5| Step: 4
Training loss: 1.0477781295776367
Validation loss: 2.132424098189159

Epoch: 5| Step: 5
Training loss: 0.628004789352417
Validation loss: 2.1160543093117337

Epoch: 5| Step: 6
Training loss: 1.8632709980010986
Validation loss: 2.1738527615865073

Epoch: 5| Step: 7
Training loss: 1.5925501585006714
Validation loss: 2.1239804401192615

Epoch: 5| Step: 8
Training loss: 1.0225824117660522
Validation loss: 2.085264613551478

Epoch: 5| Step: 9
Training loss: 1.0497232675552368
Validation loss: 2.06561940844341

Epoch: 5| Step: 10
Training loss: 0.729506254196167
Validation loss: 2.0749252714136595

Epoch: 420| Step: 0
Training loss: 1.182021975517273
Validation loss: 2.057946394848567

Epoch: 5| Step: 1
Training loss: 1.3997764587402344
Validation loss: 2.05580908765075

Epoch: 5| Step: 2
Training loss: 1.0402815341949463
Validation loss: 2.0797403281734836

Epoch: 5| Step: 3
Training loss: 1.1741536855697632
Validation loss: 2.087224693708522

Epoch: 5| Step: 4
Training loss: 1.4846203327178955
Validation loss: 2.0550243880159114

Epoch: 5| Step: 5
Training loss: 1.1624819040298462
Validation loss: 2.0430887001816944

Epoch: 5| Step: 6
Training loss: 1.725799560546875
Validation loss: 2.045014500617981

Epoch: 5| Step: 7
Training loss: 1.3933336734771729
Validation loss: 2.073236593636133

Epoch: 5| Step: 8
Training loss: 1.1411174535751343
Validation loss: 2.043457335041415

Epoch: 5| Step: 9
Training loss: 1.168365240097046
Validation loss: 2.068841747058335

Epoch: 5| Step: 10
Training loss: 1.114858627319336
Validation loss: 2.0743555279188257

Epoch: 421| Step: 0
Training loss: 1.241916298866272
Validation loss: 2.1105732443512126

Epoch: 5| Step: 1
Training loss: 1.3011530637741089
Validation loss: 2.1570836164618052

Epoch: 5| Step: 2
Training loss: 1.1197624206542969
Validation loss: 2.1528774333256546

Epoch: 5| Step: 3
Training loss: 1.329538345336914
Validation loss: 2.1577353067295526

Epoch: 5| Step: 4
Training loss: 1.3760454654693604
Validation loss: 2.108462487497637

Epoch: 5| Step: 5
Training loss: 1.324863314628601
Validation loss: 2.0873739898845716

Epoch: 5| Step: 6
Training loss: 1.3451929092407227
Validation loss: 2.0243941558304654

Epoch: 5| Step: 7
Training loss: 1.145214557647705
Validation loss: 2.011878505829842

Epoch: 5| Step: 8
Training loss: 1.4258496761322021
Validation loss: 1.9858979999378163

Epoch: 5| Step: 9
Training loss: 1.2132036685943604
Validation loss: 2.0190309375844975

Epoch: 5| Step: 10
Training loss: 1.1867772340774536
Validation loss: 1.9939908263503865

Epoch: 422| Step: 0
Training loss: 1.402083158493042
Validation loss: 2.029720437142157

Epoch: 5| Step: 1
Training loss: 1.2025963068008423
Validation loss: 2.0318201152227258

Epoch: 5| Step: 2
Training loss: 1.5104424953460693
Validation loss: 2.0960667928059897

Epoch: 5| Step: 3
Training loss: 1.4450700283050537
Validation loss: 2.1449660511427027

Epoch: 5| Step: 4
Training loss: 1.2096879482269287
Validation loss: 2.1901502429798083

Epoch: 5| Step: 5
Training loss: 1.3910462856292725
Validation loss: 2.2246093198817265

Epoch: 5| Step: 6
Training loss: 1.4527465105056763
Validation loss: 2.224111731334399

Epoch: 5| Step: 7
Training loss: 1.2129640579223633
Validation loss: 2.228780592641523

Epoch: 5| Step: 8
Training loss: 0.9093130826950073
Validation loss: 2.1805392798557075

Epoch: 5| Step: 9
Training loss: 1.1152652502059937
Validation loss: 2.0829885454588037

Epoch: 5| Step: 10
Training loss: 1.1975125074386597
Validation loss: 2.0028268867923367

Epoch: 423| Step: 0
Training loss: 1.3868311643600464
Validation loss: 1.9703400827223254

Epoch: 5| Step: 1
Training loss: 1.1497396230697632
Validation loss: 1.969703048788091

Epoch: 5| Step: 2
Training loss: 0.7029964923858643
Validation loss: 1.9464477826190252

Epoch: 5| Step: 3
Training loss: 1.087517499923706
Validation loss: 1.97330125429297

Epoch: 5| Step: 4
Training loss: 1.9774200916290283
Validation loss: 2.011653927064711

Epoch: 5| Step: 5
Training loss: 1.7107226848602295
Validation loss: 2.045540791685863

Epoch: 5| Step: 6
Training loss: 1.7756599187850952
Validation loss: 2.047026184297377

Epoch: 5| Step: 7
Training loss: 0.9401447176933289
Validation loss: 2.05140027564059

Epoch: 5| Step: 8
Training loss: 1.5899308919906616
Validation loss: 2.0620613854418517

Epoch: 5| Step: 9
Training loss: 1.1071306467056274
Validation loss: 2.1112621625264487

Epoch: 5| Step: 10
Training loss: 1.0276176929473877
Validation loss: 2.1239954553624636

Epoch: 424| Step: 0
Training loss: 0.8952006101608276
Validation loss: 2.179642515797769

Epoch: 5| Step: 1
Training loss: 0.9867850542068481
Validation loss: 2.1745279168569915

Epoch: 5| Step: 2
Training loss: 1.616155982017517
Validation loss: 2.1714936302554224

Epoch: 5| Step: 3
Training loss: 2.0275917053222656
Validation loss: 2.138474154215987

Epoch: 5| Step: 4
Training loss: 1.562265157699585
Validation loss: 2.1052819195614068

Epoch: 5| Step: 5
Training loss: 0.9684966802597046
Validation loss: 2.0666726225165912

Epoch: 5| Step: 6
Training loss: 1.4198018312454224
Validation loss: 2.055574187668421

Epoch: 5| Step: 7
Training loss: 1.1599681377410889
Validation loss: 2.012967244271309

Epoch: 5| Step: 8
Training loss: 0.9093077778816223
Validation loss: 2.0098326821481027

Epoch: 5| Step: 9
Training loss: 1.4534093141555786
Validation loss: 2.013270321712699

Epoch: 5| Step: 10
Training loss: 1.1350305080413818
Validation loss: 2.0024548204996253

Epoch: 425| Step: 0
Training loss: 1.3887691497802734
Validation loss: 2.021290356113065

Epoch: 5| Step: 1
Training loss: 1.4056565761566162
Validation loss: 2.040378253947022

Epoch: 5| Step: 2
Training loss: 1.1825263500213623
Validation loss: 2.0770281873723513

Epoch: 5| Step: 3
Training loss: 1.4801628589630127
Validation loss: 2.1151748472644436

Epoch: 5| Step: 4
Training loss: 1.1246302127838135
Validation loss: 2.170535255503911

Epoch: 5| Step: 5
Training loss: 1.654270887374878
Validation loss: 2.204115490759573

Epoch: 5| Step: 6
Training loss: 0.9496471285820007
Validation loss: 2.1927349054685203

Epoch: 5| Step: 7
Training loss: 1.5198386907577515
Validation loss: 2.20221895299932

Epoch: 5| Step: 8
Training loss: 1.227839708328247
Validation loss: 2.1584711946466917

Epoch: 5| Step: 9
Training loss: 1.1686383485794067
Validation loss: 2.1042461369627263

Epoch: 5| Step: 10
Training loss: 0.7542006373405457
Validation loss: 2.0808871792208765

Epoch: 426| Step: 0
Training loss: 1.5220863819122314
Validation loss: 2.031728980361774

Epoch: 5| Step: 1
Training loss: 1.543995976448059
Validation loss: 2.023994263782296

Epoch: 5| Step: 2
Training loss: 1.0337480306625366
Validation loss: 2.0118456399568947

Epoch: 5| Step: 3
Training loss: 1.0626524686813354
Validation loss: 1.9967221906108241

Epoch: 5| Step: 4
Training loss: 1.4162179231643677
Validation loss: 2.0150638088103263

Epoch: 5| Step: 5
Training loss: 1.8067033290863037
Validation loss: 1.992629498563787

Epoch: 5| Step: 6
Training loss: 1.0972026586532593
Validation loss: 2.0253339275237052

Epoch: 5| Step: 7
Training loss: 0.9538202285766602
Validation loss: 2.0221793818217453

Epoch: 5| Step: 8
Training loss: 1.1062450408935547
Validation loss: 2.0932246715791765

Epoch: 5| Step: 9
Training loss: 1.141623616218567
Validation loss: 2.121065573025775

Epoch: 5| Step: 10
Training loss: 1.495908260345459
Validation loss: 2.1568007904996156

Epoch: 427| Step: 0
Training loss: 1.244347333908081
Validation loss: 2.129353982146068

Epoch: 5| Step: 1
Training loss: 1.0962556600570679
Validation loss: 2.1040431953245595

Epoch: 5| Step: 2
Training loss: 1.1980664730072021
Validation loss: 2.0884300970262095

Epoch: 5| Step: 3
Training loss: 1.2469552755355835
Validation loss: 2.076068789728226

Epoch: 5| Step: 4
Training loss: 1.2664897441864014
Validation loss: 2.0224774704184583

Epoch: 5| Step: 5
Training loss: 1.0857818126678467
Validation loss: 2.014604333908327

Epoch: 5| Step: 6
Training loss: 1.3397969007492065
Validation loss: 2.029399815426078

Epoch: 5| Step: 7
Training loss: 1.5901987552642822
Validation loss: 2.009438322436425

Epoch: 5| Step: 8
Training loss: 1.1709566116333008
Validation loss: 1.9937423865000408

Epoch: 5| Step: 9
Training loss: 1.3872489929199219
Validation loss: 2.007945309403122

Epoch: 5| Step: 10
Training loss: 1.5086891651153564
Validation loss: 1.9875869161339217

Epoch: 428| Step: 0
Training loss: 0.9909918904304504
Validation loss: 1.9758811407191779

Epoch: 5| Step: 1
Training loss: 1.12856924533844
Validation loss: 1.9776340697401313

Epoch: 5| Step: 2
Training loss: 1.1878362894058228
Validation loss: 2.0142299718754266

Epoch: 5| Step: 3
Training loss: 0.8527647852897644
Validation loss: 2.0331173789116646

Epoch: 5| Step: 4
Training loss: 1.0633465051651
Validation loss: 2.0455725603206183

Epoch: 5| Step: 5
Training loss: 1.2165089845657349
Validation loss: 2.0681063539238385

Epoch: 5| Step: 6
Training loss: 1.1362704038619995
Validation loss: 2.0720149509368406

Epoch: 5| Step: 7
Training loss: 1.5968260765075684
Validation loss: 2.0848080804271083

Epoch: 5| Step: 8
Training loss: 1.173964262008667
Validation loss: 2.0688712968621203

Epoch: 5| Step: 9
Training loss: 1.3579270839691162
Validation loss: 2.0519610335749965

Epoch: 5| Step: 10
Training loss: 1.7499996423721313
Validation loss: 2.0882494808525167

Epoch: 429| Step: 0
Training loss: 0.7815445065498352
Validation loss: 2.0949389960176203

Epoch: 5| Step: 1
Training loss: 1.2602193355560303
Validation loss: 2.0756434907195387

Epoch: 5| Step: 2
Training loss: 1.6153926849365234
Validation loss: 2.063704708571075

Epoch: 5| Step: 3
Training loss: 1.3539934158325195
Validation loss: 2.0390761372863606

Epoch: 5| Step: 4
Training loss: 0.8809094429016113
Validation loss: 2.048038390374953

Epoch: 5| Step: 5
Training loss: 1.313783884048462
Validation loss: 2.0257712512887935

Epoch: 5| Step: 6
Training loss: 1.072667121887207
Validation loss: 2.019295996235263

Epoch: 5| Step: 7
Training loss: 1.4474939107894897
Validation loss: 2.050736855435115

Epoch: 5| Step: 8
Training loss: 1.5370525121688843
Validation loss: 2.046417264528172

Epoch: 5| Step: 9
Training loss: 1.1840189695358276
Validation loss: 2.0721428381499423

Epoch: 5| Step: 10
Training loss: 1.028846025466919
Validation loss: 2.093679343500445

Epoch: 430| Step: 0
Training loss: 1.2887638807296753
Validation loss: 2.087285613500944

Epoch: 5| Step: 1
Training loss: 1.2727681398391724
Validation loss: 2.098510024368122

Epoch: 5| Step: 2
Training loss: 1.3775609731674194
Validation loss: 2.1054147930555445

Epoch: 5| Step: 3
Training loss: 1.2327473163604736
Validation loss: 2.0832055166203487

Epoch: 5| Step: 4
Training loss: 1.2188459634780884
Validation loss: 2.0595745578888924

Epoch: 5| Step: 5
Training loss: 1.3317251205444336
Validation loss: 2.014355626157535

Epoch: 5| Step: 6
Training loss: 1.1824500560760498
Validation loss: 2.0058269026458904

Epoch: 5| Step: 7
Training loss: 1.0458858013153076
Validation loss: 2.0278865342499106

Epoch: 5| Step: 8
Training loss: 1.3455815315246582
Validation loss: 2.0382542174349547

Epoch: 5| Step: 9
Training loss: 0.8559123873710632
Validation loss: 2.0799124240875244

Epoch: 5| Step: 10
Training loss: 1.2794930934906006
Validation loss: 2.0852349432565833

Epoch: 431| Step: 0
Training loss: 1.3139524459838867
Validation loss: 2.1186739629314792

Epoch: 5| Step: 1
Training loss: 1.2115581035614014
Validation loss: 2.1403248297270907

Epoch: 5| Step: 2
Training loss: 1.4579287767410278
Validation loss: 2.121242392447687

Epoch: 5| Step: 3
Training loss: 1.19452702999115
Validation loss: 2.1879152546646776

Epoch: 5| Step: 4
Training loss: 1.00255286693573
Validation loss: 2.1394033226915585

Epoch: 5| Step: 5
Training loss: 1.106382131576538
Validation loss: 2.1310333423717047

Epoch: 5| Step: 6
Training loss: 1.571048617362976
Validation loss: 2.0809904093383462

Epoch: 5| Step: 7
Training loss: 0.9117664098739624
Validation loss: 2.068549866317421

Epoch: 5| Step: 8
Training loss: 1.0823192596435547
Validation loss: 2.019119985641972

Epoch: 5| Step: 9
Training loss: 1.2944185733795166
Validation loss: 2.005456698838101

Epoch: 5| Step: 10
Training loss: 1.6301069259643555
Validation loss: 2.0147154254298054

Epoch: 432| Step: 0
Training loss: 1.3079819679260254
Validation loss: 2.002041780820457

Epoch: 5| Step: 1
Training loss: 1.0809907913208008
Validation loss: 2.0471288158047583

Epoch: 5| Step: 2
Training loss: 1.7629865407943726
Validation loss: 2.0769309228466404

Epoch: 5| Step: 3
Training loss: 1.2984178066253662
Validation loss: 2.054511515043115

Epoch: 5| Step: 4
Training loss: 0.7485616207122803
Validation loss: 2.0568444062304754

Epoch: 5| Step: 5
Training loss: 1.7956254482269287
Validation loss: 2.0423314417562177

Epoch: 5| Step: 6
Training loss: 1.3017784357070923
Validation loss: 2.059500713502207

Epoch: 5| Step: 7
Training loss: 0.947109043598175
Validation loss: 2.076168780685753

Epoch: 5| Step: 8
Training loss: 1.0552805662155151
Validation loss: 2.0897804998582408

Epoch: 5| Step: 9
Training loss: 1.0582232475280762
Validation loss: 2.088183226123933

Epoch: 5| Step: 10
Training loss: 1.0777742862701416
Validation loss: 2.066016771460092

Epoch: 433| Step: 0
Training loss: 1.1038017272949219
Validation loss: 2.089133943280866

Epoch: 5| Step: 1
Training loss: 1.4649854898452759
Validation loss: 2.0858802590318906

Epoch: 5| Step: 2
Training loss: 1.3560024499893188
Validation loss: 2.060603012320816

Epoch: 5| Step: 3
Training loss: 1.2874990701675415
Validation loss: 2.0646773922827935

Epoch: 5| Step: 4
Training loss: 1.5756547451019287
Validation loss: 2.0264118615017144

Epoch: 5| Step: 5
Training loss: 1.030923843383789
Validation loss: 2.0187164634786625

Epoch: 5| Step: 6
Training loss: 1.206268548965454
Validation loss: 2.0096030555745608

Epoch: 5| Step: 7
Training loss: 1.1177061796188354
Validation loss: 2.000335503649968

Epoch: 5| Step: 8
Training loss: 1.37526535987854
Validation loss: 2.0325533664354714

Epoch: 5| Step: 9
Training loss: 0.9874328374862671
Validation loss: 2.0755984206353464

Epoch: 5| Step: 10
Training loss: 0.7008205652236938
Validation loss: 2.1113123252827632

Epoch: 434| Step: 0
Training loss: 1.1876857280731201
Validation loss: 2.1486154192237445

Epoch: 5| Step: 1
Training loss: 1.5992006063461304
Validation loss: 2.111422154211229

Epoch: 5| Step: 2
Training loss: 1.5596951246261597
Validation loss: 2.1239167951768443

Epoch: 5| Step: 3
Training loss: 1.6196283102035522
Validation loss: 2.127831503909121

Epoch: 5| Step: 4
Training loss: 1.1938121318817139
Validation loss: 2.117261396941318

Epoch: 5| Step: 5
Training loss: 1.0315635204315186
Validation loss: 2.071088896002821

Epoch: 5| Step: 6
Training loss: 0.8581418991088867
Validation loss: 2.039359946404734

Epoch: 5| Step: 7
Training loss: 1.0393046140670776
Validation loss: 2.05386342540864

Epoch: 5| Step: 8
Training loss: 0.6133686900138855
Validation loss: 2.0503082185663204

Epoch: 5| Step: 9
Training loss: 1.633784532546997
Validation loss: 2.021649370911301

Epoch: 5| Step: 10
Training loss: 0.837786078453064
Validation loss: 2.022558955736058

Epoch: 435| Step: 0
Training loss: 1.1184676885604858
Validation loss: 2.0363978967871716

Epoch: 5| Step: 1
Training loss: 1.0131620168685913
Validation loss: 2.0447695985917123

Epoch: 5| Step: 2
Training loss: 1.5300390720367432
Validation loss: 2.048816188689201

Epoch: 5| Step: 3
Training loss: 1.1036601066589355
Validation loss: 2.0677060260567615

Epoch: 5| Step: 4
Training loss: 1.2136236429214478
Validation loss: 2.041515297787164

Epoch: 5| Step: 5
Training loss: 1.3585411310195923
Validation loss: 2.037019734741539

Epoch: 5| Step: 6
Training loss: 1.109480619430542
Validation loss: 1.985118084056403

Epoch: 5| Step: 7
Training loss: 0.9230874180793762
Validation loss: 2.023632211069907

Epoch: 5| Step: 8
Training loss: 1.1701009273529053
Validation loss: 2.036938900588661

Epoch: 5| Step: 9
Training loss: 1.4106566905975342
Validation loss: 1.9766452812379407

Epoch: 5| Step: 10
Training loss: 1.1444246768951416
Validation loss: 2.0131503279491136

Epoch: 436| Step: 0
Training loss: 1.8221505880355835
Validation loss: 2.043795677923387

Epoch: 5| Step: 1
Training loss: 1.2549641132354736
Validation loss: 2.065810652189357

Epoch: 5| Step: 2
Training loss: 1.3289514780044556
Validation loss: 2.1374828225822857

Epoch: 5| Step: 3
Training loss: 1.1854201555252075
Validation loss: 2.1123987756749636

Epoch: 5| Step: 4
Training loss: 0.9722690582275391
Validation loss: 2.1010116095184

Epoch: 5| Step: 5
Training loss: 1.0542317628860474
Validation loss: 2.085345870705061

Epoch: 5| Step: 6
Training loss: 1.2630524635314941
Validation loss: 2.0908880797765588

Epoch: 5| Step: 7
Training loss: 0.8664478063583374
Validation loss: 2.0490546636683966

Epoch: 5| Step: 8
Training loss: 0.9394657015800476
Validation loss: 2.0848832489341818

Epoch: 5| Step: 9
Training loss: 1.4362739324569702
Validation loss: 2.03742165078399

Epoch: 5| Step: 10
Training loss: 0.9384211301803589
Validation loss: 2.053630441747686

Epoch: 437| Step: 0
Training loss: 1.6600592136383057
Validation loss: 2.064597737404608

Epoch: 5| Step: 1
Training loss: 0.9705149531364441
Validation loss: 2.0598088438792894

Epoch: 5| Step: 2
Training loss: 0.8132294416427612
Validation loss: 2.048419121773012

Epoch: 5| Step: 3
Training loss: 1.064518690109253
Validation loss: 2.027501489526482

Epoch: 5| Step: 4
Training loss: 1.3634182214736938
Validation loss: 2.0663502626521613

Epoch: 5| Step: 5
Training loss: 1.56223464012146
Validation loss: 2.0444696411009757

Epoch: 5| Step: 6
Training loss: 0.8705238103866577
Validation loss: 2.059335397135827

Epoch: 5| Step: 7
Training loss: 1.2068626880645752
Validation loss: 2.0747270737924883

Epoch: 5| Step: 8
Training loss: 1.109048843383789
Validation loss: 2.0962454029308852

Epoch: 5| Step: 9
Training loss: 1.2368173599243164
Validation loss: 2.1210834210918796

Epoch: 5| Step: 10
Training loss: 1.1780673265457153
Validation loss: 2.164583824014151

Epoch: 438| Step: 0
Training loss: 0.7031320333480835
Validation loss: 2.1221284891969416

Epoch: 5| Step: 1
Training loss: 1.3057959079742432
Validation loss: 2.0924230390979397

Epoch: 5| Step: 2
Training loss: 1.091968297958374
Validation loss: 2.1087848819712156

Epoch: 5| Step: 3
Training loss: 1.0242252349853516
Validation loss: 2.084544119014535

Epoch: 5| Step: 4
Training loss: 1.3415943384170532
Validation loss: 2.0425723624485794

Epoch: 5| Step: 5
Training loss: 1.2729880809783936
Validation loss: 2.0301426354274956

Epoch: 5| Step: 6
Training loss: 1.498557448387146
Validation loss: 2.039428463546179

Epoch: 5| Step: 7
Training loss: 1.1925525665283203
Validation loss: 2.0580397934041996

Epoch: 5| Step: 8
Training loss: 0.6659963726997375
Validation loss: 2.064320413015222

Epoch: 5| Step: 9
Training loss: 1.3705095052719116
Validation loss: 2.032309442438105

Epoch: 5| Step: 10
Training loss: 1.5121062994003296
Validation loss: 2.06565999215649

Epoch: 439| Step: 0
Training loss: 0.9277527928352356
Validation loss: 2.074429794024396

Epoch: 5| Step: 1
Training loss: 1.515243649482727
Validation loss: 2.074734318640924

Epoch: 5| Step: 2
Training loss: 1.3888174295425415
Validation loss: 2.0834858802057084

Epoch: 5| Step: 3
Training loss: 1.0717092752456665
Validation loss: 2.0670686511583227

Epoch: 5| Step: 4
Training loss: 0.7097629904747009
Validation loss: 2.0883563936397596

Epoch: 5| Step: 5
Training loss: 1.56315279006958
Validation loss: 2.0755434164436917

Epoch: 5| Step: 6
Training loss: 1.1103270053863525
Validation loss: 2.050350882673776

Epoch: 5| Step: 7
Training loss: 0.9314990043640137
Validation loss: 2.060482709638534

Epoch: 5| Step: 8
Training loss: 1.0062227249145508
Validation loss: 2.075190303146198

Epoch: 5| Step: 9
Training loss: 1.3445372581481934
Validation loss: 2.0277304572443806

Epoch: 5| Step: 10
Training loss: 1.1985137462615967
Validation loss: 2.0514645448295017

Epoch: 440| Step: 0
Training loss: 1.682408094406128
Validation loss: 2.061790339408382

Epoch: 5| Step: 1
Training loss: 1.5233209133148193
Validation loss: 2.048074073688958

Epoch: 5| Step: 2
Training loss: 1.4214513301849365
Validation loss: 2.048524974494852

Epoch: 5| Step: 3
Training loss: 1.1830605268478394
Validation loss: 2.0465540116833103

Epoch: 5| Step: 4
Training loss: 0.9092780947685242
Validation loss: 2.0523825653137697

Epoch: 5| Step: 5
Training loss: 0.8837131261825562
Validation loss: 2.065998213265532

Epoch: 5| Step: 6
Training loss: 1.1805498600006104
Validation loss: 2.1024818625501407

Epoch: 5| Step: 7
Training loss: 1.109196662902832
Validation loss: 2.0837878424634217

Epoch: 5| Step: 8
Training loss: 0.7636640667915344
Validation loss: 2.0517625116532847

Epoch: 5| Step: 9
Training loss: 0.9806197881698608
Validation loss: 2.0507583169526953

Epoch: 5| Step: 10
Training loss: 1.0606646537780762
Validation loss: 2.017785369708974

Epoch: 441| Step: 0
Training loss: 1.1872073411941528
Validation loss: 2.016881310811607

Epoch: 5| Step: 1
Training loss: 1.4544343948364258
Validation loss: 2.003206596579603

Epoch: 5| Step: 2
Training loss: 1.2616150379180908
Validation loss: 2.0306467048583494

Epoch: 5| Step: 3
Training loss: 1.3094485998153687
Validation loss: 2.0063470063670987

Epoch: 5| Step: 4
Training loss: 0.848824679851532
Validation loss: 2.028017761886761

Epoch: 5| Step: 5
Training loss: 1.1505552530288696
Validation loss: 2.0314645164756366

Epoch: 5| Step: 6
Training loss: 0.9838285446166992
Validation loss: 2.07943905040782

Epoch: 5| Step: 7
Training loss: 1.1940940618515015
Validation loss: 2.1075376464474584

Epoch: 5| Step: 8
Training loss: 1.279888391494751
Validation loss: 2.08548148985832

Epoch: 5| Step: 9
Training loss: 0.7542580366134644
Validation loss: 2.05843517088121

Epoch: 5| Step: 10
Training loss: 1.3102903366088867
Validation loss: 2.0775371802750455

Epoch: 442| Step: 0
Training loss: 1.140346884727478
Validation loss: 2.0489358722522693

Epoch: 5| Step: 1
Training loss: 0.977096438407898
Validation loss: 2.03687144607626

Epoch: 5| Step: 2
Training loss: 0.7189327478408813
Validation loss: 2.0140627225240073

Epoch: 5| Step: 3
Training loss: 1.162917971611023
Validation loss: 1.994232177734375

Epoch: 5| Step: 4
Training loss: 1.035593032836914
Validation loss: 1.9815446369109615

Epoch: 5| Step: 5
Training loss: 1.2032994031906128
Validation loss: 1.998547173315479

Epoch: 5| Step: 6
Training loss: 1.5191895961761475
Validation loss: 2.0464628178586244

Epoch: 5| Step: 7
Training loss: 1.098035454750061
Validation loss: 2.0563367233481458

Epoch: 5| Step: 8
Training loss: 1.2094991207122803
Validation loss: 2.0958746351221555

Epoch: 5| Step: 9
Training loss: 1.5992618799209595
Validation loss: 2.118623051592099

Epoch: 5| Step: 10
Training loss: 1.0843279361724854
Validation loss: 2.1244484263081707

Epoch: 443| Step: 0
Training loss: 0.8215070962905884
Validation loss: 2.1541900865493284

Epoch: 5| Step: 1
Training loss: 1.6306569576263428
Validation loss: 2.15681291139254

Epoch: 5| Step: 2
Training loss: 0.9836453199386597
Validation loss: 2.1176180916447795

Epoch: 5| Step: 3
Training loss: 0.8566924929618835
Validation loss: 2.081657604504657

Epoch: 5| Step: 4
Training loss: 1.368449091911316
Validation loss: 2.0705823231768865

Epoch: 5| Step: 5
Training loss: 1.0683118104934692
Validation loss: 2.0388350563664592

Epoch: 5| Step: 6
Training loss: 1.1279566287994385
Validation loss: 2.0416339905031267

Epoch: 5| Step: 7
Training loss: 1.2679455280303955
Validation loss: 2.0643069013472526

Epoch: 5| Step: 8
Training loss: 1.4482576847076416
Validation loss: 2.061613823777886

Epoch: 5| Step: 9
Training loss: 1.3335473537445068
Validation loss: 2.0765254766710344

Epoch: 5| Step: 10
Training loss: 0.937707245349884
Validation loss: 2.0742171502882436

Epoch: 444| Step: 0
Training loss: 1.1042848825454712
Validation loss: 2.0484518235729587

Epoch: 5| Step: 1
Training loss: 1.1829248666763306
Validation loss: 2.031742968866902

Epoch: 5| Step: 2
Training loss: 1.0215504169464111
Validation loss: 2.0218261659786267

Epoch: 5| Step: 3
Training loss: 1.2269119024276733
Validation loss: 2.058906275738952

Epoch: 5| Step: 4
Training loss: 0.8907723426818848
Validation loss: 2.059881530782228

Epoch: 5| Step: 5
Training loss: 1.1462570428848267
Validation loss: 2.068821414824455

Epoch: 5| Step: 6
Training loss: 1.186832070350647
Validation loss: 2.083938208959436

Epoch: 5| Step: 7
Training loss: 1.446190595626831
Validation loss: 2.142927281318172

Epoch: 5| Step: 8
Training loss: 1.254852533340454
Validation loss: 2.143724860683564

Epoch: 5| Step: 9
Training loss: 1.1005901098251343
Validation loss: 2.173574295095218

Epoch: 5| Step: 10
Training loss: 1.3748263120651245
Validation loss: 2.0914520448254

Epoch: 445| Step: 0
Training loss: 1.3255013227462769
Validation loss: 2.081022411264399

Epoch: 5| Step: 1
Training loss: 0.6237592101097107
Validation loss: 2.058992237173101

Epoch: 5| Step: 2
Training loss: 1.0933722257614136
Validation loss: 2.0281534092400664

Epoch: 5| Step: 3
Training loss: 1.1830393075942993
Validation loss: 2.0643563937115412

Epoch: 5| Step: 4
Training loss: 1.6710548400878906
Validation loss: 2.079186608714442

Epoch: 5| Step: 5
Training loss: 1.5981099605560303
Validation loss: 2.129944580857472

Epoch: 5| Step: 6
Training loss: 1.4526259899139404
Validation loss: 2.095466036950388

Epoch: 5| Step: 7
Training loss: 1.3970978260040283
Validation loss: 2.1025757866521038

Epoch: 5| Step: 8
Training loss: 0.8927257657051086
Validation loss: 2.0635795618898127

Epoch: 5| Step: 9
Training loss: 1.1089390516281128
Validation loss: 2.0371173633042203

Epoch: 5| Step: 10
Training loss: 0.8946281671524048
Validation loss: 2.0342141120664534

Epoch: 446| Step: 0
Training loss: 0.9187706112861633
Validation loss: 2.0472356375827583

Epoch: 5| Step: 1
Training loss: 1.23264479637146
Validation loss: 2.0567692595143474

Epoch: 5| Step: 2
Training loss: 1.2971856594085693
Validation loss: 2.020970539380145

Epoch: 5| Step: 3
Training loss: 1.3087599277496338
Validation loss: 2.0542684165380334

Epoch: 5| Step: 4
Training loss: 1.4471694231033325
Validation loss: 2.027191171082117

Epoch: 5| Step: 5
Training loss: 0.8453240394592285
Validation loss: 2.064533702788814

Epoch: 5| Step: 6
Training loss: 1.1740376949310303
Validation loss: 2.002450030337098

Epoch: 5| Step: 7
Training loss: 1.1063988208770752
Validation loss: 2.070163339696905

Epoch: 5| Step: 8
Training loss: 0.9575284719467163
Validation loss: 2.1101207117880545

Epoch: 5| Step: 9
Training loss: 0.9552812576293945
Validation loss: 2.140537272217453

Epoch: 5| Step: 10
Training loss: 1.6585198640823364
Validation loss: 2.157107171191964

Epoch: 447| Step: 0
Training loss: 1.6734346151351929
Validation loss: 2.1345169877493255

Epoch: 5| Step: 1
Training loss: 1.2939519882202148
Validation loss: 2.1565361407495316

Epoch: 5| Step: 2
Training loss: 1.2616446018218994
Validation loss: 2.140698371394988

Epoch: 5| Step: 3
Training loss: 0.9929553866386414
Validation loss: 2.119191138975082

Epoch: 5| Step: 4
Training loss: 0.9245807528495789
Validation loss: 2.064126517183037

Epoch: 5| Step: 5
Training loss: 1.0622371435165405
Validation loss: 2.0496057900049354

Epoch: 5| Step: 6
Training loss: 0.7713366746902466
Validation loss: 2.0399671857075026

Epoch: 5| Step: 7
Training loss: 1.1690022945404053
Validation loss: 2.023020695614558

Epoch: 5| Step: 8
Training loss: 1.4679443836212158
Validation loss: 1.996905816498623

Epoch: 5| Step: 9
Training loss: 1.3913242816925049
Validation loss: 2.038259297288874

Epoch: 5| Step: 10
Training loss: 0.8633242249488831
Validation loss: 2.068073712369447

Epoch: 448| Step: 0
Training loss: 0.9823930859565735
Validation loss: 2.108503149401757

Epoch: 5| Step: 1
Training loss: 1.1082351207733154
Validation loss: 2.0801487456085863

Epoch: 5| Step: 2
Training loss: 1.4147063493728638
Validation loss: 2.094986290060064

Epoch: 5| Step: 3
Training loss: 1.0752573013305664
Validation loss: 2.071730048425736

Epoch: 5| Step: 4
Training loss: 1.3771541118621826
Validation loss: 2.050079322630359

Epoch: 5| Step: 5
Training loss: 1.1765447854995728
Validation loss: 2.0342900265929518

Epoch: 5| Step: 6
Training loss: 1.2872178554534912
Validation loss: 2.0219238214595343

Epoch: 5| Step: 7
Training loss: 0.8875683546066284
Validation loss: 1.9965831182336296

Epoch: 5| Step: 8
Training loss: 1.1668049097061157
Validation loss: 2.07288541588732

Epoch: 5| Step: 9
Training loss: 1.050463318824768
Validation loss: 2.091779944717243

Epoch: 5| Step: 10
Training loss: 1.0065160989761353
Validation loss: 2.1013409963218113

Epoch: 449| Step: 0
Training loss: 0.9687656164169312
Validation loss: 2.0862207720356603

Epoch: 5| Step: 1
Training loss: 0.9874833226203918
Validation loss: 2.096186899369763

Epoch: 5| Step: 2
Training loss: 1.2383005619049072
Validation loss: 2.0402234574799896

Epoch: 5| Step: 3
Training loss: 1.412043809890747
Validation loss: 2.060731141797958

Epoch: 5| Step: 4
Training loss: 1.1745530366897583
Validation loss: 2.042872989049522

Epoch: 5| Step: 5
Training loss: 1.3041950464248657
Validation loss: 2.034011439610553

Epoch: 5| Step: 6
Training loss: 1.2016719579696655
Validation loss: 2.0027769714273433

Epoch: 5| Step: 7
Training loss: 1.3647347688674927
Validation loss: 2.0186776961049726

Epoch: 5| Step: 8
Training loss: 1.1548378467559814
Validation loss: 2.0531278541011195

Epoch: 5| Step: 9
Training loss: 0.5661224126815796
Validation loss: 2.0297281524186492

Epoch: 5| Step: 10
Training loss: 1.1527214050292969
Validation loss: 2.033393793208625

Epoch: 450| Step: 0
Training loss: 1.3705415725708008
Validation loss: 2.031089211022982

Epoch: 5| Step: 1
Training loss: 0.967041015625
Validation loss: 2.041571188998479

Epoch: 5| Step: 2
Training loss: 1.0962998867034912
Validation loss: 2.074794941051032

Epoch: 5| Step: 3
Training loss: 1.2715545892715454
Validation loss: 2.0758772742363716

Epoch: 5| Step: 4
Training loss: 0.696351170539856
Validation loss: 2.049130755086099

Epoch: 5| Step: 5
Training loss: 1.0650538206100464
Validation loss: 2.036178991358767

Epoch: 5| Step: 6
Training loss: 0.7883841395378113
Validation loss: 2.016690590048349

Epoch: 5| Step: 7
Training loss: 1.1171562671661377
Validation loss: 2.050055432063277

Epoch: 5| Step: 8
Training loss: 1.3629438877105713
Validation loss: 2.0570854217775407

Epoch: 5| Step: 9
Training loss: 1.0904605388641357
Validation loss: 2.0632076673610236

Epoch: 5| Step: 10
Training loss: 1.5473920106887817
Validation loss: 2.049868837479622

Testing loss: 2.152091211742825
