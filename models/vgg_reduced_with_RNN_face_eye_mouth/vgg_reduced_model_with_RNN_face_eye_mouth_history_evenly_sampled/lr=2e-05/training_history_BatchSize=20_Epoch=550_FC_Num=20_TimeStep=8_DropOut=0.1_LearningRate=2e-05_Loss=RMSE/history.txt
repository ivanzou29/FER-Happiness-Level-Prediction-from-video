Epoch: 1| Step: 0
Training loss: 5.851136786708831
Validation loss: 5.811185459016455

Epoch: 5| Step: 1
Training loss: 6.206011583372144
Validation loss: 5.7893494687436915

Epoch: 5| Step: 2
Training loss: 5.389878196401649
Validation loss: 5.773851082360309

Epoch: 5| Step: 3
Training loss: 5.249246634062809
Validation loss: 5.758946304222217

Epoch: 5| Step: 4
Training loss: 6.178563301465386
Validation loss: 5.74267161057726

Epoch: 5| Step: 5
Training loss: 6.509468225186066
Validation loss: 5.724213033458229

Epoch: 5| Step: 6
Training loss: 5.229083218864895
Validation loss: 5.702526408703211

Epoch: 5| Step: 7
Training loss: 6.365494466725127
Validation loss: 5.679056572447566

Epoch: 5| Step: 8
Training loss: 5.568488337302225
Validation loss: 5.652556128814746

Epoch: 5| Step: 9
Training loss: 5.648549607722184
Validation loss: 5.622767274433839

Epoch: 5| Step: 10
Training loss: 4.681057788279474
Validation loss: 5.5891913897863565

Epoch: 2| Step: 0
Training loss: 4.821522169869791
Validation loss: 5.551182769796773

Epoch: 5| Step: 1
Training loss: 5.832748420091516
Validation loss: 5.509856940261223

Epoch: 5| Step: 2
Training loss: 5.0817439403436815
Validation loss: 5.463170013820606

Epoch: 5| Step: 3
Training loss: 5.657313462914688
Validation loss: 5.412517870210615

Epoch: 5| Step: 4
Training loss: 4.542719564385349
Validation loss: 5.358938192127401

Epoch: 5| Step: 5
Training loss: 5.711210022567459
Validation loss: 5.298461726738418

Epoch: 5| Step: 6
Training loss: 6.2868372421882865
Validation loss: 5.232759051729627

Epoch: 5| Step: 7
Training loss: 6.087688541821646
Validation loss: 5.165261379516357

Epoch: 5| Step: 8
Training loss: 4.266374794593116
Validation loss: 5.093717533574057

Epoch: 5| Step: 9
Training loss: 5.065900814165232
Validation loss: 5.024897007954797

Epoch: 5| Step: 10
Training loss: 4.842700672314544
Validation loss: 4.95730262577945

Epoch: 3| Step: 0
Training loss: 4.869466526648519
Validation loss: 4.895035520264642

Epoch: 5| Step: 1
Training loss: 5.057711750449482
Validation loss: 4.834115731319183

Epoch: 5| Step: 2
Training loss: 5.119031827105965
Validation loss: 4.780779803712984

Epoch: 5| Step: 3
Training loss: 5.571543681873403
Validation loss: 4.726755751806119

Epoch: 5| Step: 4
Training loss: 4.6409254394275905
Validation loss: 4.667830714647976

Epoch: 5| Step: 5
Training loss: 4.79513886188001
Validation loss: 4.6221352296258456

Epoch: 5| Step: 6
Training loss: 5.190592567852377
Validation loss: 4.576986662233045

Epoch: 5| Step: 7
Training loss: 5.1351296407200815
Validation loss: 4.532711751972379

Epoch: 5| Step: 8
Training loss: 3.930945132613799
Validation loss: 4.486353546885845

Epoch: 5| Step: 9
Training loss: 4.143910382189175
Validation loss: 4.4468505593050365

Epoch: 5| Step: 10
Training loss: 3.082682996331537
Validation loss: 4.41635151762448

Epoch: 4| Step: 0
Training loss: 4.395719023509416
Validation loss: 4.3952331498710295

Epoch: 5| Step: 1
Training loss: 3.721003642924411
Validation loss: 4.366316843631095

Epoch: 5| Step: 2
Training loss: 4.201447219373655
Validation loss: 4.3431379740339064

Epoch: 5| Step: 3
Training loss: 4.454676521793514
Validation loss: 4.328837203029831

Epoch: 5| Step: 4
Training loss: 4.818531566770206
Validation loss: 4.322056038272175

Epoch: 5| Step: 5
Training loss: 4.7259115480208465
Validation loss: 4.30975750498341

Epoch: 5| Step: 6
Training loss: 4.156701084984595
Validation loss: 4.2971192840315675

Epoch: 5| Step: 7
Training loss: 4.606145833259718
Validation loss: 4.284637167565457

Epoch: 5| Step: 8
Training loss: 3.999951004681927
Validation loss: 4.269834372889953

Epoch: 5| Step: 9
Training loss: 5.534108947872623
Validation loss: 4.256007931134815

Epoch: 5| Step: 10
Training loss: 3.8045867342598276
Validation loss: 4.241295151183288

Epoch: 5| Step: 0
Training loss: 4.707742749649241
Validation loss: 4.227285400229047

Epoch: 5| Step: 1
Training loss: 4.414704996796528
Validation loss: 4.213898211213732

Epoch: 5| Step: 2
Training loss: 3.8215171615253176
Validation loss: 4.200038662550369

Epoch: 5| Step: 3
Training loss: 4.457147220637383
Validation loss: 4.1851879282142255

Epoch: 5| Step: 4
Training loss: 4.085493541398229
Validation loss: 4.1692889376889655

Epoch: 5| Step: 5
Training loss: 3.7362829465871568
Validation loss: 4.156458799237141

Epoch: 5| Step: 6
Training loss: 4.146957449535362
Validation loss: 4.14613795211283

Epoch: 5| Step: 7
Training loss: 4.4982359925506055
Validation loss: 4.133211093187285

Epoch: 5| Step: 8
Training loss: 4.518393331251545
Validation loss: 4.119140171912656

Epoch: 5| Step: 9
Training loss: 3.918767663164502
Validation loss: 4.103695679336958

Epoch: 5| Step: 10
Training loss: 4.896518459132967
Validation loss: 4.095996618783569

Epoch: 6| Step: 0
Training loss: 3.676983465436081
Validation loss: 4.082612214861352

Epoch: 5| Step: 1
Training loss: 3.951055173333707
Validation loss: 4.080583890264991

Epoch: 5| Step: 2
Training loss: 3.5402152434607332
Validation loss: 4.06825178075756

Epoch: 5| Step: 3
Training loss: 3.7798680073535817
Validation loss: 4.055666741396787

Epoch: 5| Step: 4
Training loss: 4.165307980584403
Validation loss: 4.041484334317533

Epoch: 5| Step: 5
Training loss: 5.295572216320593
Validation loss: 4.026358831268925

Epoch: 5| Step: 6
Training loss: 4.778797991943448
Validation loss: 4.019120453994238

Epoch: 5| Step: 7
Training loss: 4.25105115569605
Validation loss: 4.008269189247975

Epoch: 5| Step: 8
Training loss: 4.711889673673928
Validation loss: 3.995874344854602

Epoch: 5| Step: 9
Training loss: 3.6911716608660274
Validation loss: 3.9846720266890623

Epoch: 5| Step: 10
Training loss: 3.63511614208612
Validation loss: 3.9732549238868122

Epoch: 7| Step: 0
Training loss: 3.6758349553562053
Validation loss: 3.966358221492609

Epoch: 5| Step: 1
Training loss: 3.2938939216918324
Validation loss: 3.9566806695855172

Epoch: 5| Step: 2
Training loss: 3.26788689795593
Validation loss: 3.9507726086870614

Epoch: 5| Step: 3
Training loss: 3.191577621957514
Validation loss: 3.9395914690551646

Epoch: 5| Step: 4
Training loss: 4.33593222128057
Validation loss: 3.9326350818873723

Epoch: 5| Step: 5
Training loss: 5.209099349593512
Validation loss: 3.918371494982337

Epoch: 5| Step: 6
Training loss: 3.9499138013874573
Validation loss: 3.909789094755135

Epoch: 5| Step: 7
Training loss: 4.744630891132715
Validation loss: 3.900071740154542

Epoch: 5| Step: 8
Training loss: 4.112860184407485
Validation loss: 3.889592720002528

Epoch: 5| Step: 9
Training loss: 4.855357972137344
Validation loss: 3.881930869018675

Epoch: 5| Step: 10
Training loss: 3.518253005384903
Validation loss: 3.8685930127750545

Epoch: 8| Step: 0
Training loss: 3.5733311952992586
Validation loss: 3.859834741035186

Epoch: 5| Step: 1
Training loss: 4.435670717392665
Validation loss: 3.8475700609044106

Epoch: 5| Step: 2
Training loss: 4.047486483649717
Validation loss: 3.8396887017229746

Epoch: 5| Step: 3
Training loss: 3.6191548544310126
Validation loss: 3.830842146717325

Epoch: 5| Step: 4
Training loss: 4.121296925530684
Validation loss: 3.8186479848662627

Epoch: 5| Step: 5
Training loss: 3.7872078357978083
Validation loss: 3.8100475086818704

Epoch: 5| Step: 6
Training loss: 4.49708759582048
Validation loss: 3.802515534589826

Epoch: 5| Step: 7
Training loss: 4.568382338147717
Validation loss: 3.7909477730642154

Epoch: 5| Step: 8
Training loss: 3.4996198720228495
Validation loss: 3.7798438919355206

Epoch: 5| Step: 9
Training loss: 3.770284721692699
Validation loss: 3.7692461772590318

Epoch: 5| Step: 10
Training loss: 3.6474971498788076
Validation loss: 3.756280751577048

Epoch: 9| Step: 0
Training loss: 4.5981650382908565
Validation loss: 3.7470186831559267

Epoch: 5| Step: 1
Training loss: 3.8351321491813772
Validation loss: 3.7382487328872083

Epoch: 5| Step: 2
Training loss: 4.4747248900683125
Validation loss: 3.7343120613411616

Epoch: 5| Step: 3
Training loss: 4.495294229724234
Validation loss: 3.723226389802232

Epoch: 5| Step: 4
Training loss: 3.5004580061831563
Validation loss: 3.7081258304874924

Epoch: 5| Step: 5
Training loss: 2.6889500808933997
Validation loss: 3.6955089744498757

Epoch: 5| Step: 6
Training loss: 3.9522947864474243
Validation loss: 3.689979281494729

Epoch: 5| Step: 7
Training loss: 3.4019365910132575
Validation loss: 3.6751293163806573

Epoch: 5| Step: 8
Training loss: 4.22823956229334
Validation loss: 3.6622513637348337

Epoch: 5| Step: 9
Training loss: 3.5855634240735723
Validation loss: 3.659695537638727

Epoch: 5| Step: 10
Training loss: 3.5658824991496423
Validation loss: 3.650783244183364

Epoch: 10| Step: 0
Training loss: 3.4546499898143117
Validation loss: 3.640438223800037

Epoch: 5| Step: 1
Training loss: 4.239771033528585
Validation loss: 3.632266438127251

Epoch: 5| Step: 2
Training loss: 4.207252942887966
Validation loss: 3.6252920424204946

Epoch: 5| Step: 3
Training loss: 4.158198538043501
Validation loss: 3.6130219507230388

Epoch: 5| Step: 4
Training loss: 3.537279905340139
Validation loss: 3.624738466689026

Epoch: 5| Step: 5
Training loss: 3.696608463330212
Validation loss: 3.6064521821451376

Epoch: 5| Step: 6
Training loss: 3.3321012286119527
Validation loss: 3.602618978018585

Epoch: 5| Step: 7
Training loss: 3.4819410915398343
Validation loss: 3.5920824116970493

Epoch: 5| Step: 8
Training loss: 4.180770705140961
Validation loss: 3.5761193583505664

Epoch: 5| Step: 9
Training loss: 3.27175590640876
Validation loss: 3.562345177928068

Epoch: 5| Step: 10
Training loss: 4.145777537419309
Validation loss: 3.557965582047608

Epoch: 11| Step: 0
Training loss: 3.459170473801673
Validation loss: 3.5436355146663527

Epoch: 5| Step: 1
Training loss: 3.466655751969199
Validation loss: 3.537209906924302

Epoch: 5| Step: 2
Training loss: 3.5978248382730547
Validation loss: 3.5356039911871537

Epoch: 5| Step: 3
Training loss: 4.084960353850365
Validation loss: 3.5327631534050963

Epoch: 5| Step: 4
Training loss: 3.815512795637928
Validation loss: 3.511471969695752

Epoch: 5| Step: 5
Training loss: 4.05355319288508
Validation loss: 3.506114467700619

Epoch: 5| Step: 6
Training loss: 4.380388483734361
Validation loss: 3.500185766725114

Epoch: 5| Step: 7
Training loss: 3.5082134875730766
Validation loss: 3.4887775595887267

Epoch: 5| Step: 8
Training loss: 3.89641364088366
Validation loss: 3.474143061337356

Epoch: 5| Step: 9
Training loss: 2.978645136784695
Validation loss: 3.4654817373123317

Epoch: 5| Step: 10
Training loss: 3.3701043119049174
Validation loss: 3.458865448842432

Epoch: 12| Step: 0
Training loss: 3.3791009924010416
Validation loss: 3.46047058118785

Epoch: 5| Step: 1
Training loss: 3.7127397196532796
Validation loss: 3.443013423612529

Epoch: 5| Step: 2
Training loss: 3.9610403073905296
Validation loss: 3.447804679324628

Epoch: 5| Step: 3
Training loss: 3.822614042827547
Validation loss: 3.450024702825768

Epoch: 5| Step: 4
Training loss: 3.9587909367055483
Validation loss: 3.4480278419291976

Epoch: 5| Step: 5
Training loss: 3.8778905854550914
Validation loss: 3.4328090173191517

Epoch: 5| Step: 6
Training loss: 3.4214505145708634
Validation loss: 3.422401566390243

Epoch: 5| Step: 7
Training loss: 3.1874065011467
Validation loss: 3.413805139733235

Epoch: 5| Step: 8
Training loss: 4.457940532932894
Validation loss: 3.4031794454043793

Epoch: 5| Step: 9
Training loss: 3.519403622564554
Validation loss: 3.394413290602576

Epoch: 5| Step: 10
Training loss: 2.326886353199917
Validation loss: 3.3879860481652635

Epoch: 13| Step: 0
Training loss: 3.6615898068926875
Validation loss: 3.384800106474352

Epoch: 5| Step: 1
Training loss: 3.6449656007920064
Validation loss: 3.3609861096807174

Epoch: 5| Step: 2
Training loss: 3.596097627182287
Validation loss: 3.3576439906164812

Epoch: 5| Step: 3
Training loss: 4.066654369981863
Validation loss: 3.3621492568819638

Epoch: 5| Step: 4
Training loss: 3.7814127989473034
Validation loss: 3.354534854806534

Epoch: 5| Step: 5
Training loss: 3.5175153609145786
Validation loss: 3.348277703141205

Epoch: 5| Step: 6
Training loss: 3.9525935000435997
Validation loss: 3.3327693344139346

Epoch: 5| Step: 7
Training loss: 3.0539159556517874
Validation loss: 3.3181394855579422

Epoch: 5| Step: 8
Training loss: 3.106999395531877
Validation loss: 3.3189850917833152

Epoch: 5| Step: 9
Training loss: 3.6995301644262883
Validation loss: 3.3072088467466085

Epoch: 5| Step: 10
Training loss: 3.0532237104313107
Validation loss: 3.309553562197044

Epoch: 14| Step: 0
Training loss: 3.999117157784579
Validation loss: 3.2953812255968358

Epoch: 5| Step: 1
Training loss: 2.84678906709888
Validation loss: 3.291883106107112

Epoch: 5| Step: 2
Training loss: 2.525950028372969
Validation loss: 3.2888846353813603

Epoch: 5| Step: 3
Training loss: 4.1536735637380895
Validation loss: 3.284844325588921

Epoch: 5| Step: 4
Training loss: 4.129554777000784
Validation loss: 3.2823075691394776

Epoch: 5| Step: 5
Training loss: 3.8029930524419036
Validation loss: 3.26825513324032

Epoch: 5| Step: 6
Training loss: 3.4693053204839557
Validation loss: 3.2635752246544634

Epoch: 5| Step: 7
Training loss: 3.713989673072209
Validation loss: 3.251604463500314

Epoch: 5| Step: 8
Training loss: 3.1387678890105883
Validation loss: 3.2429488643071602

Epoch: 5| Step: 9
Training loss: 2.6539401613976796
Validation loss: 3.236604861643531

Epoch: 5| Step: 10
Training loss: 3.784820006309887
Validation loss: 3.233376443417157

Epoch: 15| Step: 0
Training loss: 2.934551951117682
Validation loss: 3.229511326481915

Epoch: 5| Step: 1
Training loss: 3.116350640034832
Validation loss: 3.236529443934599

Epoch: 5| Step: 2
Training loss: 3.0758137812406843
Validation loss: 3.2197743088323385

Epoch: 5| Step: 3
Training loss: 3.981567830045585
Validation loss: 3.2101419563787714

Epoch: 5| Step: 4
Training loss: 3.775729602765951
Validation loss: 3.2052233442127736

Epoch: 5| Step: 5
Training loss: 4.022125563563657
Validation loss: 3.2026081299464058

Epoch: 5| Step: 6
Training loss: 3.4667202621376196
Validation loss: 3.1945579029519093

Epoch: 5| Step: 7
Training loss: 3.621921942524336
Validation loss: 3.1904090653605546

Epoch: 5| Step: 8
Training loss: 3.4528234013511274
Validation loss: 3.183782062387835

Epoch: 5| Step: 9
Training loss: 3.424278634392153
Validation loss: 3.1797910118503183

Epoch: 5| Step: 10
Training loss: 2.9277086415855402
Validation loss: 3.175460512862352

Epoch: 16| Step: 0
Training loss: 3.4087452279740473
Validation loss: 3.1726033439228565

Epoch: 5| Step: 1
Training loss: 4.044478601677085
Validation loss: 3.16283266794392

Epoch: 5| Step: 2
Training loss: 2.934959286824917
Validation loss: 3.1637824413262283

Epoch: 5| Step: 3
Training loss: 2.9419356600470454
Validation loss: 3.1588658186687297

Epoch: 5| Step: 4
Training loss: 4.0776205518199
Validation loss: 3.158782737969997

Epoch: 5| Step: 5
Training loss: 3.663525637599807
Validation loss: 3.1546847518288637

Epoch: 5| Step: 6
Training loss: 3.9281599894492536
Validation loss: 3.1442364338884707

Epoch: 5| Step: 7
Training loss: 3.7221719080496176
Validation loss: 3.1353934009198334

Epoch: 5| Step: 8
Training loss: 3.150662452431259
Validation loss: 3.128178302257946

Epoch: 5| Step: 9
Training loss: 2.5511223884751204
Validation loss: 3.123605133819222

Epoch: 5| Step: 10
Training loss: 2.6866636527386114
Validation loss: 3.123220561399076

Epoch: 17| Step: 0
Training loss: 3.3578253432037566
Validation loss: 3.1222174005572523

Epoch: 5| Step: 1
Training loss: 3.9201887540721443
Validation loss: 3.1216436947822004

Epoch: 5| Step: 2
Training loss: 3.4267432016021515
Validation loss: 3.1162672954233854

Epoch: 5| Step: 3
Training loss: 3.3272656687961533
Validation loss: 3.099649217085907

Epoch: 5| Step: 4
Training loss: 3.232954957458889
Validation loss: 3.0981811249243596

Epoch: 5| Step: 5
Training loss: 2.932185458512192
Validation loss: 3.109581408526698

Epoch: 5| Step: 6
Training loss: 3.320242129309429
Validation loss: 3.0855471327643023

Epoch: 5| Step: 7
Training loss: 3.208643481303634
Validation loss: 3.0879144863732706

Epoch: 5| Step: 8
Training loss: 3.6244877420418895
Validation loss: 3.08800374425699

Epoch: 5| Step: 9
Training loss: 3.283929511871476
Validation loss: 3.0948044566911723

Epoch: 5| Step: 10
Training loss: 3.4861642665449604
Validation loss: 3.088848002881913

Epoch: 18| Step: 0
Training loss: 2.574881623148913
Validation loss: 3.073488324474018

Epoch: 5| Step: 1
Training loss: 3.8650855931603965
Validation loss: 3.0702671921381572

Epoch: 5| Step: 2
Training loss: 2.7246677406102955
Validation loss: 3.0603738427219183

Epoch: 5| Step: 3
Training loss: 2.9394167875660964
Validation loss: 3.0573289001101625

Epoch: 5| Step: 4
Training loss: 3.9299224115919658
Validation loss: 3.0515267116798084

Epoch: 5| Step: 5
Training loss: 3.3372129909821724
Validation loss: 3.047769887642812

Epoch: 5| Step: 6
Training loss: 3.8267651692338562
Validation loss: 3.039368260173262

Epoch: 5| Step: 7
Training loss: 3.706583846239567
Validation loss: 3.0354538017562893

Epoch: 5| Step: 8
Training loss: 3.133628986153876
Validation loss: 3.028976846560487

Epoch: 5| Step: 9
Training loss: 3.015364561545731
Validation loss: 3.026575814668362

Epoch: 5| Step: 10
Training loss: 3.2836521619982975
Validation loss: 3.023982349636795

Epoch: 19| Step: 0
Training loss: 3.355530424073053
Validation loss: 3.0256499682815168

Epoch: 5| Step: 1
Training loss: 3.328757928830945
Validation loss: 3.0190368475975533

Epoch: 5| Step: 2
Training loss: 2.940970136473325
Validation loss: 3.011403665688318

Epoch: 5| Step: 3
Training loss: 3.1877281256927352
Validation loss: 3.025114467261603

Epoch: 5| Step: 4
Training loss: 2.580153066397189
Validation loss: 2.9978799738015924

Epoch: 5| Step: 5
Training loss: 3.09656527574634
Validation loss: 2.9994226382075184

Epoch: 5| Step: 6
Training loss: 3.381482997347841
Validation loss: 2.998462072579963

Epoch: 5| Step: 7
Training loss: 3.726550600044876
Validation loss: 2.9913960185461552

Epoch: 5| Step: 8
Training loss: 3.5715990816012404
Validation loss: 2.992498304949973

Epoch: 5| Step: 9
Training loss: 3.291749413975301
Validation loss: 2.98768059580312

Epoch: 5| Step: 10
Training loss: 3.7452787560895158
Validation loss: 2.9845273434764192

Epoch: 20| Step: 0
Training loss: 3.889370022635238
Validation loss: 2.981456917216188

Epoch: 5| Step: 1
Training loss: 2.8422471990706577
Validation loss: 2.9762599908588925

Epoch: 5| Step: 2
Training loss: 3.2651685185778567
Validation loss: 2.970159113106921

Epoch: 5| Step: 3
Training loss: 3.9085943892648265
Validation loss: 2.968979853921613

Epoch: 5| Step: 4
Training loss: 3.6690331682820223
Validation loss: 2.960554837121445

Epoch: 5| Step: 5
Training loss: 2.561289990077079
Validation loss: 2.952931066290216

Epoch: 5| Step: 6
Training loss: 2.642962262187666
Validation loss: 2.9498181140488002

Epoch: 5| Step: 7
Training loss: 3.613971640124615
Validation loss: 2.9485501560565117

Epoch: 5| Step: 8
Training loss: 2.8660656971825342
Validation loss: 2.945618917590005

Epoch: 5| Step: 9
Training loss: 3.461236600674269
Validation loss: 2.947705102594215

Epoch: 5| Step: 10
Training loss: 2.81909364690511
Validation loss: 2.945358243371452

Epoch: 21| Step: 0
Training loss: 3.652622346911226
Validation loss: 2.945689074382198

Epoch: 5| Step: 1
Training loss: 3.5268584093876187
Validation loss: 2.939680801103316

Epoch: 5| Step: 2
Training loss: 3.5983705753756787
Validation loss: 2.928671289228998

Epoch: 5| Step: 3
Training loss: 3.219051013685701
Validation loss: 2.92232521496936

Epoch: 5| Step: 4
Training loss: 3.4345138063573963
Validation loss: 2.9208938858009326

Epoch: 5| Step: 5
Training loss: 3.2011471480321694
Validation loss: 2.919487941115281

Epoch: 5| Step: 6
Training loss: 3.134933856953857
Validation loss: 2.92216601152837

Epoch: 5| Step: 7
Training loss: 3.0153897050368443
Validation loss: 2.9204598918092954

Epoch: 5| Step: 8
Training loss: 2.4584126432739835
Validation loss: 2.921633402608232

Epoch: 5| Step: 9
Training loss: 3.20572850557636
Validation loss: 2.9163411206335956

Epoch: 5| Step: 10
Training loss: 3.031700651353379
Validation loss: 2.9158800415030197

Epoch: 22| Step: 0
Training loss: 3.5345167055737594
Validation loss: 2.910420599459776

Epoch: 5| Step: 1
Training loss: 3.05393032045947
Validation loss: 2.9067117644185414

Epoch: 5| Step: 2
Training loss: 3.3832550816498843
Validation loss: 2.905130326581081

Epoch: 5| Step: 3
Training loss: 3.0116517768270823
Validation loss: 2.8992708975633175

Epoch: 5| Step: 4
Training loss: 3.1907463745584375
Validation loss: 2.89961347115041

Epoch: 5| Step: 5
Training loss: 3.0808308902476615
Validation loss: 2.8968348252348015

Epoch: 5| Step: 6
Training loss: 3.409738556580395
Validation loss: 2.888625794857801

Epoch: 5| Step: 7
Training loss: 2.8397028703127725
Validation loss: 2.8844947934140137

Epoch: 5| Step: 8
Training loss: 3.326705988292916
Validation loss: 2.883618730026157

Epoch: 5| Step: 9
Training loss: 2.910082679177002
Validation loss: 2.878447904416079

Epoch: 5| Step: 10
Training loss: 3.6338693701653986
Validation loss: 2.8765602283232976

Epoch: 23| Step: 0
Training loss: 3.703062419121129
Validation loss: 2.8778053870743965

Epoch: 5| Step: 1
Training loss: 2.8357976032987615
Validation loss: 2.870350861708204

Epoch: 5| Step: 2
Training loss: 3.3808087411809917
Validation loss: 2.8693279082736503

Epoch: 5| Step: 3
Training loss: 3.687235159980985
Validation loss: 2.879237668180417

Epoch: 5| Step: 4
Training loss: 2.994717715912144
Validation loss: 2.8623040945756046

Epoch: 5| Step: 5
Training loss: 3.20882611804491
Validation loss: 2.8730396205326745

Epoch: 5| Step: 6
Training loss: 2.963320294220268
Validation loss: 2.858774743613731

Epoch: 5| Step: 7
Training loss: 3.1679478278921485
Validation loss: 2.8579567903892413

Epoch: 5| Step: 8
Training loss: 2.172390444399883
Validation loss: 2.858605573419459

Epoch: 5| Step: 9
Training loss: 3.635459804916575
Validation loss: 2.8747976748203383

Epoch: 5| Step: 10
Training loss: 3.1209292028257054
Validation loss: 2.876252798917176

Epoch: 24| Step: 0
Training loss: 3.6263654044722147
Validation loss: 2.8559930342889794

Epoch: 5| Step: 1
Training loss: 3.316322568235321
Validation loss: 2.8470492412391417

Epoch: 5| Step: 2
Training loss: 3.3975205861661606
Validation loss: 2.844650279303697

Epoch: 5| Step: 3
Training loss: 3.0291292302801796
Validation loss: 2.8488440672447246

Epoch: 5| Step: 4
Training loss: 3.0416087489079042
Validation loss: 2.8421437070904436

Epoch: 5| Step: 5
Training loss: 2.776161167418803
Validation loss: 2.8426329302741467

Epoch: 5| Step: 6
Training loss: 2.7700280092386347
Validation loss: 2.844470773301805

Epoch: 5| Step: 7
Training loss: 2.6430485004387236
Validation loss: 2.8839770799180378

Epoch: 5| Step: 8
Training loss: 3.600243184035197
Validation loss: 2.9321811796333135

Epoch: 5| Step: 9
Training loss: 3.088688109830309
Validation loss: 2.8501176226583627

Epoch: 5| Step: 10
Training loss: 3.7056440967795425
Validation loss: 2.8379538252612875

Epoch: 25| Step: 0
Training loss: 2.2863892448490004
Validation loss: 2.8545980589307436

Epoch: 5| Step: 1
Training loss: 2.965647632444181
Validation loss: 2.8714126982336428

Epoch: 5| Step: 2
Training loss: 3.342469442565976
Validation loss: 2.860816399053122

Epoch: 5| Step: 3
Training loss: 3.8000802533559472
Validation loss: 2.8472496368211555

Epoch: 5| Step: 4
Training loss: 3.1055898966641116
Validation loss: 2.8437823032661598

Epoch: 5| Step: 5
Training loss: 2.959258476629973
Validation loss: 2.8660819695304056

Epoch: 5| Step: 6
Training loss: 3.1092059985675315
Validation loss: 2.8822383376095106

Epoch: 5| Step: 7
Training loss: 3.346393289102332
Validation loss: 2.865104925524327

Epoch: 5| Step: 8
Training loss: 3.348738327433202
Validation loss: 2.8734310768248053

Epoch: 5| Step: 9
Training loss: 3.190684354792323
Validation loss: 2.8668661957670265

Epoch: 5| Step: 10
Training loss: 3.3094929415657375
Validation loss: 2.841604901075169

Epoch: 26| Step: 0
Training loss: 2.8641081444765377
Validation loss: 2.8310611947216784

Epoch: 5| Step: 1
Training loss: 3.123908042863316
Validation loss: 2.822707873932769

Epoch: 5| Step: 2
Training loss: 3.3792518394890223
Validation loss: 2.8187952756354897

Epoch: 5| Step: 3
Training loss: 3.45152155729699
Validation loss: 2.8141388793090094

Epoch: 5| Step: 4
Training loss: 3.3111362169012315
Validation loss: 2.811193219569632

Epoch: 5| Step: 5
Training loss: 3.6621190104039907
Validation loss: 2.8117553901115984

Epoch: 5| Step: 6
Training loss: 3.048206058165141
Validation loss: 2.808257299414945

Epoch: 5| Step: 7
Training loss: 2.9883789046543616
Validation loss: 2.807001552346661

Epoch: 5| Step: 8
Training loss: 2.834377395645694
Validation loss: 2.8032223192444365

Epoch: 5| Step: 9
Training loss: 2.922103464914952
Validation loss: 2.802763087056367

Epoch: 5| Step: 10
Training loss: 2.823073876614547
Validation loss: 2.800446153069565

Epoch: 27| Step: 0
Training loss: 3.299435746475022
Validation loss: 2.7970545817583363

Epoch: 5| Step: 1
Training loss: 2.94814724688762
Validation loss: 2.7997517661033156

Epoch: 5| Step: 2
Training loss: 3.1869383672446836
Validation loss: 2.8071521025204467

Epoch: 5| Step: 3
Training loss: 2.699586702432918
Validation loss: 2.794918643528215

Epoch: 5| Step: 4
Training loss: 3.0253526403260227
Validation loss: 2.79638604996694

Epoch: 5| Step: 5
Training loss: 3.3916135129270457
Validation loss: 2.8143038207576274

Epoch: 5| Step: 6
Training loss: 3.057170356453645
Validation loss: 2.784312953713191

Epoch: 5| Step: 7
Training loss: 3.0009241270231914
Validation loss: 2.785190932929438

Epoch: 5| Step: 8
Training loss: 3.2355235543723735
Validation loss: 2.7863471598504685

Epoch: 5| Step: 9
Training loss: 3.0318459780280502
Validation loss: 2.792143681018672

Epoch: 5| Step: 10
Training loss: 3.441668947479256
Validation loss: 2.799988569582038

Epoch: 28| Step: 0
Training loss: 3.228316229947431
Validation loss: 2.79671006877342

Epoch: 5| Step: 1
Training loss: 2.8656419127452963
Validation loss: 2.791834706033639

Epoch: 5| Step: 2
Training loss: 3.0689918065413866
Validation loss: 2.7831153131264466

Epoch: 5| Step: 3
Training loss: 2.446721557638963
Validation loss: 2.779514764627965

Epoch: 5| Step: 4
Training loss: 2.975732882971168
Validation loss: 2.7827125170735365

Epoch: 5| Step: 5
Training loss: 3.270772427196336
Validation loss: 2.803489209474503

Epoch: 5| Step: 6
Training loss: 3.230923345054954
Validation loss: 2.8727733867564367

Epoch: 5| Step: 7
Training loss: 3.266298653509948
Validation loss: 2.827960047434992

Epoch: 5| Step: 8
Training loss: 3.694087206428171
Validation loss: 2.786202968840739

Epoch: 5| Step: 9
Training loss: 3.578213086772243
Validation loss: 2.768506839579846

Epoch: 5| Step: 10
Training loss: 2.302935745972811
Validation loss: 2.778409716256227

Epoch: 29| Step: 0
Training loss: 2.9180939224951157
Validation loss: 2.7887497777123307

Epoch: 5| Step: 1
Training loss: 3.3602631570305728
Validation loss: 2.787695048787671

Epoch: 5| Step: 2
Training loss: 3.3401686839377143
Validation loss: 2.7726456103933272

Epoch: 5| Step: 3
Training loss: 2.584372147508959
Validation loss: 2.777802813700854

Epoch: 5| Step: 4
Training loss: 2.857211435721117
Validation loss: 2.804871805966593

Epoch: 5| Step: 5
Training loss: 3.5893413536677468
Validation loss: 2.787011729733043

Epoch: 5| Step: 6
Training loss: 2.8447351111805124
Validation loss: 2.7703910682544124

Epoch: 5| Step: 7
Training loss: 3.2927915043490503
Validation loss: 2.7672780420235026

Epoch: 5| Step: 8
Training loss: 3.2534315626240278
Validation loss: 2.772079184602973

Epoch: 5| Step: 9
Training loss: 2.735765376142176
Validation loss: 2.7690006930845605

Epoch: 5| Step: 10
Training loss: 3.367556381376634
Validation loss: 2.7760124421254737

Epoch: 30| Step: 0
Training loss: 2.9324973504590277
Validation loss: 2.7682663373637832

Epoch: 5| Step: 1
Training loss: 2.541604515524825
Validation loss: 2.7683899989138125

Epoch: 5| Step: 2
Training loss: 3.5336217426656265
Validation loss: 2.7670312412449927

Epoch: 5| Step: 3
Training loss: 3.60115085326296
Validation loss: 2.7714973861087255

Epoch: 5| Step: 4
Training loss: 2.5941169203479526
Validation loss: 2.7905825452277524

Epoch: 5| Step: 5
Training loss: 2.8016597801122347
Validation loss: 2.7976325095394805

Epoch: 5| Step: 6
Training loss: 3.060095329545032
Validation loss: 2.8003172836051284

Epoch: 5| Step: 7
Training loss: 2.903767335456537
Validation loss: 2.793035958999774

Epoch: 5| Step: 8
Training loss: 3.123535728722884
Validation loss: 2.780591910138594

Epoch: 5| Step: 9
Training loss: 3.3323389159503023
Validation loss: 2.7743800247379333

Epoch: 5| Step: 10
Training loss: 3.46035162313209
Validation loss: 2.7528909038383187

Epoch: 31| Step: 0
Training loss: 3.2172523643917152
Validation loss: 2.740859592312092

Epoch: 5| Step: 1
Training loss: 3.677044674649422
Validation loss: 2.740531077766678

Epoch: 5| Step: 2
Training loss: 2.9870499212016006
Validation loss: 2.7396165900424756

Epoch: 5| Step: 3
Training loss: 3.094788348182141
Validation loss: 2.734599065785368

Epoch: 5| Step: 4
Training loss: 2.913022753253761
Validation loss: 2.7352651095994682

Epoch: 5| Step: 5
Training loss: 3.1041659327427213
Validation loss: 2.731749948277679

Epoch: 5| Step: 6
Training loss: 2.179694172291815
Validation loss: 2.7290229155190175

Epoch: 5| Step: 7
Training loss: 3.3127891846149313
Validation loss: 2.725725142155831

Epoch: 5| Step: 8
Training loss: 2.9601921008897247
Validation loss: 2.7244410955928897

Epoch: 5| Step: 9
Training loss: 2.5459399232751005
Validation loss: 2.7258674517732553

Epoch: 5| Step: 10
Training loss: 3.667599660485354
Validation loss: 2.7397346868074743

Epoch: 32| Step: 0
Training loss: 2.7920967928386426
Validation loss: 2.791851014350391

Epoch: 5| Step: 1
Training loss: 2.8410428754343275
Validation loss: 2.8398144730871353

Epoch: 5| Step: 2
Training loss: 2.8421497243894747
Validation loss: 2.839489689537653

Epoch: 5| Step: 3
Training loss: 2.816174374583851
Validation loss: 2.808046697876564

Epoch: 5| Step: 4
Training loss: 3.288598107107465
Validation loss: 2.7720096039602926

Epoch: 5| Step: 5
Training loss: 3.2221122883718616
Validation loss: 2.7277097894182316

Epoch: 5| Step: 6
Training loss: 3.080654441118558
Validation loss: 2.72205033184103

Epoch: 5| Step: 7
Training loss: 3.0650203999125165
Validation loss: 2.723888519533757

Epoch: 5| Step: 8
Training loss: 3.522964614971988
Validation loss: 2.740169285777624

Epoch: 5| Step: 9
Training loss: 2.9121116673993326
Validation loss: 2.7316995064746905

Epoch: 5| Step: 10
Training loss: 3.3648316534820006
Validation loss: 2.7263226833643897

Epoch: 33| Step: 0
Training loss: 2.768165757513769
Validation loss: 2.7194829350541725

Epoch: 5| Step: 1
Training loss: 2.840351799143111
Validation loss: 2.7173285751913774

Epoch: 5| Step: 2
Training loss: 3.2000881778965837
Validation loss: 2.735375177663455

Epoch: 5| Step: 3
Training loss: 2.351305164945361
Validation loss: 2.744736168023941

Epoch: 5| Step: 4
Training loss: 3.5541135890585522
Validation loss: 2.771930099716376

Epoch: 5| Step: 5
Training loss: 2.7667663288167157
Validation loss: 2.814261120475746

Epoch: 5| Step: 6
Training loss: 3.403435060162047
Validation loss: 2.785411297510602

Epoch: 5| Step: 7
Training loss: 3.1920633001528365
Validation loss: 2.7671094418777087

Epoch: 5| Step: 8
Training loss: 2.7554173429326694
Validation loss: 2.719733452025561

Epoch: 5| Step: 9
Training loss: 2.872162289202185
Validation loss: 2.71525948434589

Epoch: 5| Step: 10
Training loss: 3.7401637456614587
Validation loss: 2.721333927990517

Epoch: 34| Step: 0
Training loss: 3.0369979003858796
Validation loss: 2.7247402614159277

Epoch: 5| Step: 1
Training loss: 3.624037253030457
Validation loss: 2.7282774092611826

Epoch: 5| Step: 2
Training loss: 2.9566908203250857
Validation loss: 2.7296603480467496

Epoch: 5| Step: 3
Training loss: 2.3288780888925
Validation loss: 2.723101970433983

Epoch: 5| Step: 4
Training loss: 3.2886669800043746
Validation loss: 2.7185518208806547

Epoch: 5| Step: 5
Training loss: 3.1037162778315235
Validation loss: 2.7124525815810183

Epoch: 5| Step: 6
Training loss: 2.808249843801506
Validation loss: 2.7057720223845463

Epoch: 5| Step: 7
Training loss: 2.9602262503269916
Validation loss: 2.714146069168778

Epoch: 5| Step: 8
Training loss: 3.1343911015561936
Validation loss: 2.739821823958107

Epoch: 5| Step: 9
Training loss: 3.27322933290781
Validation loss: 2.770153168652362

Epoch: 5| Step: 10
Training loss: 3.016223274931463
Validation loss: 2.7689136677584782

Epoch: 35| Step: 0
Training loss: 2.763560240954284
Validation loss: 2.7584133832772615

Epoch: 5| Step: 1
Training loss: 2.814143654237173
Validation loss: 2.7442977905226136

Epoch: 5| Step: 2
Training loss: 3.2294292876396513
Validation loss: 2.7117932141636416

Epoch: 5| Step: 3
Training loss: 2.776254775770151
Validation loss: 2.706650198795388

Epoch: 5| Step: 4
Training loss: 2.923904122363191
Validation loss: 2.7033055017777827

Epoch: 5| Step: 5
Training loss: 3.252271885184437
Validation loss: 2.7041541013759587

Epoch: 5| Step: 6
Training loss: 3.544152916771642
Validation loss: 2.702989248470581

Epoch: 5| Step: 7
Training loss: 3.1120590816861546
Validation loss: 2.704276735832772

Epoch: 5| Step: 8
Training loss: 2.6874599897378286
Validation loss: 2.7061323661581187

Epoch: 5| Step: 9
Training loss: 3.2689576004653436
Validation loss: 2.7078834147359494

Epoch: 5| Step: 10
Training loss: 2.969447967397156
Validation loss: 2.70630302874579

Epoch: 36| Step: 0
Training loss: 3.434985264020515
Validation loss: 2.7002470729115338

Epoch: 5| Step: 1
Training loss: 2.4799545596174406
Validation loss: 2.701307459721672

Epoch: 5| Step: 2
Training loss: 3.297826259110434
Validation loss: 2.6935030681807866

Epoch: 5| Step: 3
Training loss: 3.097517551621779
Validation loss: 2.694156223104063

Epoch: 5| Step: 4
Training loss: 3.248853334469194
Validation loss: 2.6908085721407313

Epoch: 5| Step: 5
Training loss: 2.918073823357115
Validation loss: 2.6926236335195752

Epoch: 5| Step: 6
Training loss: 3.1036692653914573
Validation loss: 2.6890080221019397

Epoch: 5| Step: 7
Training loss: 3.048690176952054
Validation loss: 2.6926139659026753

Epoch: 5| Step: 8
Training loss: 2.3287972113450763
Validation loss: 2.6943400888589006

Epoch: 5| Step: 9
Training loss: 2.831776153651133
Validation loss: 2.7094487098242666

Epoch: 5| Step: 10
Training loss: 3.487034078122453
Validation loss: 2.729096035457069

Epoch: 37| Step: 0
Training loss: 2.991596213301919
Validation loss: 2.722540888935633

Epoch: 5| Step: 1
Training loss: 2.2290877093535846
Validation loss: 2.7120199255094404

Epoch: 5| Step: 2
Training loss: 3.528615728533749
Validation loss: 2.7242816345829155

Epoch: 5| Step: 3
Training loss: 3.536108674791617
Validation loss: 2.7101215476145404

Epoch: 5| Step: 4
Training loss: 2.3466022683468424
Validation loss: 2.6902451833175824

Epoch: 5| Step: 5
Training loss: 2.911791532736289
Validation loss: 2.686118941277221

Epoch: 5| Step: 6
Training loss: 3.0679240558381062
Validation loss: 2.6863852008599176

Epoch: 5| Step: 7
Training loss: 2.9708979816723566
Validation loss: 2.693663141588873

Epoch: 5| Step: 8
Training loss: 2.8954505027001285
Validation loss: 2.6930685291349645

Epoch: 5| Step: 9
Training loss: 3.489200962050862
Validation loss: 2.6979712609301485

Epoch: 5| Step: 10
Training loss: 3.184669883783366
Validation loss: 2.689893737751463

Epoch: 38| Step: 0
Training loss: 3.1775846158818286
Validation loss: 2.6864905401549954

Epoch: 5| Step: 1
Training loss: 3.414947046006185
Validation loss: 2.6835898074685813

Epoch: 5| Step: 2
Training loss: 2.796092259507103
Validation loss: 2.681933015109875

Epoch: 5| Step: 3
Training loss: 3.094300808665317
Validation loss: 2.6808818498324576

Epoch: 5| Step: 4
Training loss: 2.9772929098913097
Validation loss: 2.685146782956851

Epoch: 5| Step: 5
Training loss: 2.622203972675735
Validation loss: 2.6889466629580556

Epoch: 5| Step: 6
Training loss: 2.89799623652096
Validation loss: 2.710010095335411

Epoch: 5| Step: 7
Training loss: 3.1131706648921638
Validation loss: 2.7168594083867488

Epoch: 5| Step: 8
Training loss: 2.7321638485826045
Validation loss: 2.731165714511679

Epoch: 5| Step: 9
Training loss: 3.267134614112335
Validation loss: 2.7137830268415795

Epoch: 5| Step: 10
Training loss: 3.168107223776944
Validation loss: 2.6973566109142326

Epoch: 39| Step: 0
Training loss: 3.5303732534730505
Validation loss: 2.682840044208439

Epoch: 5| Step: 1
Training loss: 3.2442881937012102
Validation loss: 2.684421680330162

Epoch: 5| Step: 2
Training loss: 2.991772814667745
Validation loss: 2.699138251878684

Epoch: 5| Step: 3
Training loss: 2.736818366343522
Validation loss: 2.7485553856857345

Epoch: 5| Step: 4
Training loss: 2.7972485170345958
Validation loss: 2.7099355371066953

Epoch: 5| Step: 5
Training loss: 2.8706969525443062
Validation loss: 2.6905346940769923

Epoch: 5| Step: 6
Training loss: 3.068413921529403
Validation loss: 2.6834190120583754

Epoch: 5| Step: 7
Training loss: 2.966485535167648
Validation loss: 2.6818158683586435

Epoch: 5| Step: 8
Training loss: 3.298839399680999
Validation loss: 2.680087965095743

Epoch: 5| Step: 9
Training loss: 3.096251738158544
Validation loss: 2.700513064457666

Epoch: 5| Step: 10
Training loss: 2.730852834076838
Validation loss: 2.71963360734127

Epoch: 40| Step: 0
Training loss: 2.760460983976259
Validation loss: 2.7501441213032924

Epoch: 5| Step: 1
Training loss: 3.5338322473163397
Validation loss: 2.7723896095007965

Epoch: 5| Step: 2
Training loss: 2.5979193762117854
Validation loss: 2.6918473811434502

Epoch: 5| Step: 3
Training loss: 2.8910132894827414
Validation loss: 2.6831767037329013

Epoch: 5| Step: 4
Training loss: 3.1864700149233887
Validation loss: 2.6844472619721955

Epoch: 5| Step: 5
Training loss: 2.6742299727422543
Validation loss: 2.686235006611571

Epoch: 5| Step: 6
Training loss: 3.1042295274620852
Validation loss: 2.695149203896179

Epoch: 5| Step: 7
Training loss: 3.123271922101828
Validation loss: 2.693132999476357

Epoch: 5| Step: 8
Training loss: 2.9544226000659206
Validation loss: 2.686558195224855

Epoch: 5| Step: 9
Training loss: 3.3838162595858683
Validation loss: 2.6885058520827765

Epoch: 5| Step: 10
Training loss: 3.0910185498730316
Validation loss: 2.6771167708189987

Epoch: 41| Step: 0
Training loss: 2.9000325299773375
Validation loss: 2.674113953893203

Epoch: 5| Step: 1
Training loss: 3.266399237007764
Validation loss: 2.675779376932388

Epoch: 5| Step: 2
Training loss: 2.2390596590736185
Validation loss: 2.676274761943638

Epoch: 5| Step: 3
Training loss: 2.9424839350570546
Validation loss: 2.6774215988881678

Epoch: 5| Step: 4
Training loss: 3.07021931514125
Validation loss: 2.685093979101207

Epoch: 5| Step: 5
Training loss: 3.2690381187534037
Validation loss: 2.6912332824471594

Epoch: 5| Step: 6
Training loss: 2.7929921395983035
Validation loss: 2.69750366362901

Epoch: 5| Step: 7
Training loss: 3.2555471177872413
Validation loss: 2.707548050035024

Epoch: 5| Step: 8
Training loss: 3.0138406959661324
Validation loss: 2.683620001551708

Epoch: 5| Step: 9
Training loss: 3.654998043284173
Validation loss: 2.670288167392712

Epoch: 5| Step: 10
Training loss: 2.655262931979723
Validation loss: 2.66796283663915

Epoch: 42| Step: 0
Training loss: 3.173742186336507
Validation loss: 2.6679743789231276

Epoch: 5| Step: 1
Training loss: 3.1623498873460476
Validation loss: 2.6680224193482096

Epoch: 5| Step: 2
Training loss: 2.986316947841248
Validation loss: 2.668606492554161

Epoch: 5| Step: 3
Training loss: 2.9792948519643714
Validation loss: 2.669412688841119

Epoch: 5| Step: 4
Training loss: 2.781518816011879
Validation loss: 2.6700422824235317

Epoch: 5| Step: 5
Training loss: 3.262340883781489
Validation loss: 2.6696964082928907

Epoch: 5| Step: 6
Training loss: 3.1451864187910634
Validation loss: 2.6684727481062116

Epoch: 5| Step: 7
Training loss: 2.9536978352735423
Validation loss: 2.663368834144806

Epoch: 5| Step: 8
Training loss: 2.574436577942377
Validation loss: 2.663140582213339

Epoch: 5| Step: 9
Training loss: 2.79326597112796
Validation loss: 2.6607199961722015

Epoch: 5| Step: 10
Training loss: 3.369831366012811
Validation loss: 2.6586341981853607

Epoch: 43| Step: 0
Training loss: 3.3803388965158288
Validation loss: 2.6615777080523153

Epoch: 5| Step: 1
Training loss: 3.3551246901876155
Validation loss: 2.6720243943651756

Epoch: 5| Step: 2
Training loss: 2.915408235364819
Validation loss: 2.6870339617451324

Epoch: 5| Step: 3
Training loss: 2.584798971361424
Validation loss: 2.704481660872396

Epoch: 5| Step: 4
Training loss: 3.0611220393261744
Validation loss: 2.743353995101074

Epoch: 5| Step: 5
Training loss: 2.852082505561554
Validation loss: 2.769023638909895

Epoch: 5| Step: 6
Training loss: 2.9579028680521366
Validation loss: 2.7337439192902866

Epoch: 5| Step: 7
Training loss: 3.197789209333777
Validation loss: 2.722787760396771

Epoch: 5| Step: 8
Training loss: 3.2089513868701562
Validation loss: 2.686890905353719

Epoch: 5| Step: 9
Training loss: 2.8137216246100714
Validation loss: 2.660009194123111

Epoch: 5| Step: 10
Training loss: 2.6183583843053473
Validation loss: 2.652251581417416

Epoch: 44| Step: 0
Training loss: 2.939428467504554
Validation loss: 2.6587307535872804

Epoch: 5| Step: 1
Training loss: 3.008014147055615
Validation loss: 2.667869640379565

Epoch: 5| Step: 2
Training loss: 3.162242526101418
Validation loss: 2.6823709321886766

Epoch: 5| Step: 3
Training loss: 3.640316929696206
Validation loss: 2.66904053533696

Epoch: 5| Step: 4
Training loss: 2.536417642902784
Validation loss: 2.6617466861254697

Epoch: 5| Step: 5
Training loss: 2.59642121060408
Validation loss: 2.6611306719034253

Epoch: 5| Step: 6
Training loss: 2.755038933452903
Validation loss: 2.658118096936453

Epoch: 5| Step: 7
Training loss: 3.368125271594542
Validation loss: 2.665742081922413

Epoch: 5| Step: 8
Training loss: 3.138675369232265
Validation loss: 2.6697974867643253

Epoch: 5| Step: 9
Training loss: 3.318735120492112
Validation loss: 2.674998466568696

Epoch: 5| Step: 10
Training loss: 2.577535665951672
Validation loss: 2.6728349587643097

Epoch: 45| Step: 0
Training loss: 2.858361736931285
Validation loss: 2.6757442530789977

Epoch: 5| Step: 1
Training loss: 2.467019259108204
Validation loss: 2.685225293666117

Epoch: 5| Step: 2
Training loss: 3.1707072997808847
Validation loss: 2.6917661768546246

Epoch: 5| Step: 3
Training loss: 2.609956048471156
Validation loss: 2.6814520211735675

Epoch: 5| Step: 4
Training loss: 2.575557007775031
Validation loss: 2.6988909032117134

Epoch: 5| Step: 5
Training loss: 3.4341764161834645
Validation loss: 2.709046644897251

Epoch: 5| Step: 6
Training loss: 3.420110517578871
Validation loss: 2.6900626134685406

Epoch: 5| Step: 7
Training loss: 3.226858351769984
Validation loss: 2.663040773060402

Epoch: 5| Step: 8
Training loss: 2.6501505215199845
Validation loss: 2.6554802712496586

Epoch: 5| Step: 9
Training loss: 3.292718373256889
Validation loss: 2.654790641720472

Epoch: 5| Step: 10
Training loss: 3.3353213739612166
Validation loss: 2.6536031218409777

Epoch: 46| Step: 0
Training loss: 2.711069505099549
Validation loss: 2.65360788759807

Epoch: 5| Step: 1
Training loss: 3.4411892600610576
Validation loss: 2.6535425361784566

Epoch: 5| Step: 2
Training loss: 2.341568198345383
Validation loss: 2.6537230157571154

Epoch: 5| Step: 3
Training loss: 3.220023338517618
Validation loss: 2.650684764847607

Epoch: 5| Step: 4
Training loss: 2.7978636629864857
Validation loss: 2.65280727589196

Epoch: 5| Step: 5
Training loss: 3.0657291126362467
Validation loss: 2.65290180723044

Epoch: 5| Step: 6
Training loss: 3.866672550942339
Validation loss: 2.649227235487828

Epoch: 5| Step: 7
Training loss: 2.6885373974342155
Validation loss: 2.6478796598395817

Epoch: 5| Step: 8
Training loss: 3.0592077815459655
Validation loss: 2.643079127590546

Epoch: 5| Step: 9
Training loss: 2.7050874675493
Validation loss: 2.653300019303615

Epoch: 5| Step: 10
Training loss: 2.8712277750924606
Validation loss: 2.6709877761843246

Epoch: 47| Step: 0
Training loss: 2.711508479163298
Validation loss: 2.697216432590677

Epoch: 5| Step: 1
Training loss: 3.1134316516956453
Validation loss: 2.728729386481803

Epoch: 5| Step: 2
Training loss: 2.829538571647749
Validation loss: 2.7342399045793226

Epoch: 5| Step: 3
Training loss: 3.3196736517761614
Validation loss: 2.7378828395998114

Epoch: 5| Step: 4
Training loss: 2.7555580325867517
Validation loss: 2.739672759769227

Epoch: 5| Step: 5
Training loss: 3.0923913611878935
Validation loss: 2.741724270172063

Epoch: 5| Step: 6
Training loss: 2.9611713246642233
Validation loss: 2.7215243695759708

Epoch: 5| Step: 7
Training loss: 2.9982666730300256
Validation loss: 2.7079631530348336

Epoch: 5| Step: 8
Training loss: 2.7136120533859915
Validation loss: 2.7056583187331746

Epoch: 5| Step: 9
Training loss: 3.802653244712687
Validation loss: 2.705786575500603

Epoch: 5| Step: 10
Training loss: 2.9664705861760137
Validation loss: 2.700462366702698

Epoch: 48| Step: 0
Training loss: 3.1474501810532147
Validation loss: 2.7027306307846595

Epoch: 5| Step: 1
Training loss: 2.5808170943898414
Validation loss: 2.7047840181682945

Epoch: 5| Step: 2
Training loss: 2.8017630884513762
Validation loss: 2.7122598564735583

Epoch: 5| Step: 3
Training loss: 3.3137984699861605
Validation loss: 2.7226695697761274

Epoch: 5| Step: 4
Training loss: 2.766931171489014
Validation loss: 2.7232613593114547

Epoch: 5| Step: 5
Training loss: 3.2958881654932526
Validation loss: 2.742415437006273

Epoch: 5| Step: 6
Training loss: 2.892018410198026
Validation loss: 2.741927572675677

Epoch: 5| Step: 7
Training loss: 3.1014422722486423
Validation loss: 2.730320403321718

Epoch: 5| Step: 8
Training loss: 2.9340724021231783
Validation loss: 2.7250232732794464

Epoch: 5| Step: 9
Training loss: 3.143070919643431
Validation loss: 2.697333115305266

Epoch: 5| Step: 10
Training loss: 3.369354471247791
Validation loss: 2.6914003747989974

Epoch: 49| Step: 0
Training loss: 3.583246954534758
Validation loss: 2.689693518258795

Epoch: 5| Step: 1
Training loss: 2.821353963103465
Validation loss: 2.681275434101126

Epoch: 5| Step: 2
Training loss: 3.1468268503484933
Validation loss: 2.6793281522073693

Epoch: 5| Step: 3
Training loss: 2.9333726822496917
Validation loss: 2.6692630647455715

Epoch: 5| Step: 4
Training loss: 2.907468314814101
Validation loss: 2.656809734940325

Epoch: 5| Step: 5
Training loss: 2.6592610963484287
Validation loss: 2.6448394343285204

Epoch: 5| Step: 6
Training loss: 3.0947174717344392
Validation loss: 2.635912274224397

Epoch: 5| Step: 7
Training loss: 2.5338317514638895
Validation loss: 2.638228663364996

Epoch: 5| Step: 8
Training loss: 3.503918089575524
Validation loss: 2.6379834179451493

Epoch: 5| Step: 9
Training loss: 3.061878686277028
Validation loss: 2.63987078850936

Epoch: 5| Step: 10
Training loss: 2.7536046072611593
Validation loss: 2.640496227709167

Epoch: 50| Step: 0
Training loss: 2.4580212950005182
Validation loss: 2.638903103113527

Epoch: 5| Step: 1
Training loss: 3.054660338454211
Validation loss: 2.6376167312355507

Epoch: 5| Step: 2
Training loss: 3.135291586035942
Validation loss: 2.635790404946686

Epoch: 5| Step: 3
Training loss: 3.5697899901437435
Validation loss: 2.6336193711179936

Epoch: 5| Step: 4
Training loss: 3.2524250959586722
Validation loss: 2.6313338366940786

Epoch: 5| Step: 5
Training loss: 2.88441005367251
Validation loss: 2.629686513914257

Epoch: 5| Step: 6
Training loss: 2.863922338807344
Validation loss: 2.6303567486077215

Epoch: 5| Step: 7
Training loss: 3.24834297193099
Validation loss: 2.6316508581086775

Epoch: 5| Step: 8
Training loss: 2.9800537140376857
Validation loss: 2.6351037167746596

Epoch: 5| Step: 9
Training loss: 2.425064349549675
Validation loss: 2.641581675200416

Epoch: 5| Step: 10
Training loss: 2.8830376100392585
Validation loss: 2.642419808850786

Epoch: 51| Step: 0
Training loss: 2.978455589815045
Validation loss: 2.638496712574536

Epoch: 5| Step: 1
Training loss: 2.905212545317757
Validation loss: 2.6368750925933266

Epoch: 5| Step: 2
Training loss: 2.8412555192053808
Validation loss: 2.648314414317816

Epoch: 5| Step: 3
Training loss: 2.99770378609975
Validation loss: 2.6415999495496982

Epoch: 5| Step: 4
Training loss: 2.4092252098455575
Validation loss: 2.649732068053615

Epoch: 5| Step: 5
Training loss: 3.253191334747102
Validation loss: 2.645647375890504

Epoch: 5| Step: 6
Training loss: 3.3873129986600166
Validation loss: 2.6501041827983296

Epoch: 5| Step: 7
Training loss: 3.4106397428048885
Validation loss: 2.6446262468035053

Epoch: 5| Step: 8
Training loss: 3.181702071709436
Validation loss: 2.6366055124047088

Epoch: 5| Step: 9
Training loss: 2.6226674570270867
Validation loss: 2.6310680812208154

Epoch: 5| Step: 10
Training loss: 2.5264192803626218
Validation loss: 2.625145742586586

Epoch: 52| Step: 0
Training loss: 3.204615250939678
Validation loss: 2.6214588371269767

Epoch: 5| Step: 1
Training loss: 2.7439358346348963
Validation loss: 2.624699117797689

Epoch: 5| Step: 2
Training loss: 3.364909877618875
Validation loss: 2.6262003199841555

Epoch: 5| Step: 3
Training loss: 2.9959046703293435
Validation loss: 2.629442866559389

Epoch: 5| Step: 4
Training loss: 2.4439478957495537
Validation loss: 2.631572168440796

Epoch: 5| Step: 5
Training loss: 3.142335188860022
Validation loss: 2.6294689752809814

Epoch: 5| Step: 6
Training loss: 3.013413008365162
Validation loss: 2.629119611331086

Epoch: 5| Step: 7
Training loss: 3.250338463398535
Validation loss: 2.6270960824901737

Epoch: 5| Step: 8
Training loss: 3.2384931359264715
Validation loss: 2.626755867934721

Epoch: 5| Step: 9
Training loss: 2.6185174551981683
Validation loss: 2.6239112553322412

Epoch: 5| Step: 10
Training loss: 2.6562599630729973
Validation loss: 2.6203248728165414

Epoch: 53| Step: 0
Training loss: 3.376855128440022
Validation loss: 2.6209573061777105

Epoch: 5| Step: 1
Training loss: 3.3361634796575075
Validation loss: 2.623921220044706

Epoch: 5| Step: 2
Training loss: 2.8967936910763368
Validation loss: 2.634741047747201

Epoch: 5| Step: 3
Training loss: 2.9645215891030885
Validation loss: 2.6434800975402757

Epoch: 5| Step: 4
Training loss: 2.9538815452674605
Validation loss: 2.638137335872597

Epoch: 5| Step: 5
Training loss: 2.949477269039973
Validation loss: 2.647108798775443

Epoch: 5| Step: 6
Training loss: 3.117431478106763
Validation loss: 2.6638876203482305

Epoch: 5| Step: 7
Training loss: 2.654356337576682
Validation loss: 2.636803444338064

Epoch: 5| Step: 8
Training loss: 2.926242440599718
Validation loss: 2.62904185320343

Epoch: 5| Step: 9
Training loss: 2.6598409278172075
Validation loss: 2.629562350911068

Epoch: 5| Step: 10
Training loss: 2.6402872986956023
Validation loss: 2.625630456831903

Epoch: 54| Step: 0
Training loss: 2.919615172541975
Validation loss: 2.6135033154559584

Epoch: 5| Step: 1
Training loss: 2.0932577892610946
Validation loss: 2.61290397945339

Epoch: 5| Step: 2
Training loss: 2.9945035491784746
Validation loss: 2.609608487048145

Epoch: 5| Step: 3
Training loss: 3.1239877205679405
Validation loss: 2.6102547982707214

Epoch: 5| Step: 4
Training loss: 3.0421495620407466
Validation loss: 2.611868953742348

Epoch: 5| Step: 5
Training loss: 2.9596635397858644
Validation loss: 2.6138446174308423

Epoch: 5| Step: 6
Training loss: 3.2459430315303486
Validation loss: 2.614180669471049

Epoch: 5| Step: 7
Training loss: 3.245805674783164
Validation loss: 2.6158995734577415

Epoch: 5| Step: 8
Training loss: 3.1492449385307153
Validation loss: 2.6186030211609577

Epoch: 5| Step: 9
Training loss: 3.0007773028136464
Validation loss: 2.618991149619322

Epoch: 5| Step: 10
Training loss: 2.5905176267011325
Validation loss: 2.61357957311421

Epoch: 55| Step: 0
Training loss: 3.031949463989309
Validation loss: 2.6137683733902866

Epoch: 5| Step: 1
Training loss: 2.707466916122558
Validation loss: 2.614797522516096

Epoch: 5| Step: 2
Training loss: 2.934818261155737
Validation loss: 2.6222776524887887

Epoch: 5| Step: 3
Training loss: 2.8434209947686626
Validation loss: 2.620975505227328

Epoch: 5| Step: 4
Training loss: 2.76004638107692
Validation loss: 2.626723646991744

Epoch: 5| Step: 5
Training loss: 2.889740349744321
Validation loss: 2.6239011987407403

Epoch: 5| Step: 6
Training loss: 3.2070725841390813
Validation loss: 2.6227992833874154

Epoch: 5| Step: 7
Training loss: 2.6344715177654665
Validation loss: 2.5995713472599284

Epoch: 5| Step: 8
Training loss: 3.2401955241793834
Validation loss: 2.6011315484956263

Epoch: 5| Step: 9
Training loss: 3.2337368690392223
Validation loss: 2.597550013397033

Epoch: 5| Step: 10
Training loss: 2.9345381393827035
Validation loss: 2.5970491355977137

Epoch: 56| Step: 0
Training loss: 2.9840033334708322
Validation loss: 2.5941204316041118

Epoch: 5| Step: 1
Training loss: 2.292409279462424
Validation loss: 2.595801714087646

Epoch: 5| Step: 2
Training loss: 1.973051367743072
Validation loss: 2.5961936937049623

Epoch: 5| Step: 3
Training loss: 3.0276351296266553
Validation loss: 2.6012196062191624

Epoch: 5| Step: 4
Training loss: 3.522760770308455
Validation loss: 2.6030000386094088

Epoch: 5| Step: 5
Training loss: 3.212590073090896
Validation loss: 2.5928607201481233

Epoch: 5| Step: 6
Training loss: 2.8411714370277834
Validation loss: 2.5913154680502553

Epoch: 5| Step: 7
Training loss: 3.1864973997174015
Validation loss: 2.5917006421111743

Epoch: 5| Step: 8
Training loss: 2.579994310032684
Validation loss: 2.5935967374518114

Epoch: 5| Step: 9
Training loss: 3.132528468167821
Validation loss: 2.6053864002873794

Epoch: 5| Step: 10
Training loss: 3.3465906358975763
Validation loss: 2.6128341635958456

Epoch: 57| Step: 0
Training loss: 2.872791437117271
Validation loss: 2.607294487331081

Epoch: 5| Step: 1
Training loss: 2.8935197512023563
Validation loss: 2.607377195634149

Epoch: 5| Step: 2
Training loss: 2.871606897701487
Validation loss: 2.599471256133455

Epoch: 5| Step: 3
Training loss: 3.012381593268747
Validation loss: 2.607815571318932

Epoch: 5| Step: 4
Training loss: 3.498360113435489
Validation loss: 2.604032527955442

Epoch: 5| Step: 5
Training loss: 3.1154238652204858
Validation loss: 2.610447376918668

Epoch: 5| Step: 6
Training loss: 3.1370635074781594
Validation loss: 2.6080504355378786

Epoch: 5| Step: 7
Training loss: 2.94837399946524
Validation loss: 2.5942908962379887

Epoch: 5| Step: 8
Training loss: 3.0474533705864046
Validation loss: 2.5916576255822914

Epoch: 5| Step: 9
Training loss: 2.2764687795728973
Validation loss: 2.5894493637084994

Epoch: 5| Step: 10
Training loss: 2.398699618750216
Validation loss: 2.585141146473391

Epoch: 58| Step: 0
Training loss: 2.527918754624141
Validation loss: 2.5841941120545964

Epoch: 5| Step: 1
Training loss: 3.0215497099230606
Validation loss: 2.5861314775716857

Epoch: 5| Step: 2
Training loss: 2.880059310249391
Validation loss: 2.5855317042289383

Epoch: 5| Step: 3
Training loss: 3.366838264498607
Validation loss: 2.5862126699842167

Epoch: 5| Step: 4
Training loss: 2.5406090354652457
Validation loss: 2.595926543059039

Epoch: 5| Step: 5
Training loss: 2.875439154214508
Validation loss: 2.5901312483426526

Epoch: 5| Step: 6
Training loss: 2.8277853240149966
Validation loss: 2.591605944859063

Epoch: 5| Step: 7
Training loss: 2.9041108493193364
Validation loss: 2.586399997778884

Epoch: 5| Step: 8
Training loss: 3.0211589418514064
Validation loss: 2.5814141187928636

Epoch: 5| Step: 9
Training loss: 3.027064156695798
Validation loss: 2.57576520955245

Epoch: 5| Step: 10
Training loss: 3.2134944638207092
Validation loss: 2.5764032366495675

Epoch: 59| Step: 0
Training loss: 2.597738210202548
Validation loss: 2.574638832235647

Epoch: 5| Step: 1
Training loss: 2.7933762473161083
Validation loss: 2.5833669035758433

Epoch: 5| Step: 2
Training loss: 2.8715238703114685
Validation loss: 2.6105329893837608

Epoch: 5| Step: 3
Training loss: 3.0427521810971214
Validation loss: 2.6408877930367463

Epoch: 5| Step: 4
Training loss: 2.8796942161775654
Validation loss: 2.6473061724953553

Epoch: 5| Step: 5
Training loss: 3.088429818318004
Validation loss: 2.6213633254383244

Epoch: 5| Step: 6
Training loss: 3.0753466465025996
Validation loss: 2.585817923211731

Epoch: 5| Step: 7
Training loss: 2.567318735233561
Validation loss: 2.573879166700496

Epoch: 5| Step: 8
Training loss: 3.1049042578539283
Validation loss: 2.5672559345655657

Epoch: 5| Step: 9
Training loss: 3.5251401183504614
Validation loss: 2.5702273232571375

Epoch: 5| Step: 10
Training loss: 2.595274695408736
Validation loss: 2.571947555366835

Epoch: 60| Step: 0
Training loss: 2.964821555314653
Validation loss: 2.5703532795470543

Epoch: 5| Step: 1
Training loss: 3.158146505609123
Validation loss: 2.571484921687292

Epoch: 5| Step: 2
Training loss: 2.4101240999868963
Validation loss: 2.570670994952671

Epoch: 5| Step: 3
Training loss: 2.6461009293248487
Validation loss: 2.569614323930585

Epoch: 5| Step: 4
Training loss: 3.276060523791035
Validation loss: 2.568564681883029

Epoch: 5| Step: 5
Training loss: 2.898754997035264
Validation loss: 2.565671423406026

Epoch: 5| Step: 6
Training loss: 2.6673722724401845
Validation loss: 2.564258469301796

Epoch: 5| Step: 7
Training loss: 2.3232996557888046
Validation loss: 2.5657931520886454

Epoch: 5| Step: 8
Training loss: 2.8871326691786225
Validation loss: 2.5751043319473284

Epoch: 5| Step: 9
Training loss: 3.102251951520916
Validation loss: 2.5957044395589683

Epoch: 5| Step: 10
Training loss: 3.7865444979861906
Validation loss: 2.6382783347170524

Epoch: 61| Step: 0
Training loss: 2.9323248220481153
Validation loss: 2.6207491456810903

Epoch: 5| Step: 1
Training loss: 2.8606282807211123
Validation loss: 2.590129380641305

Epoch: 5| Step: 2
Training loss: 2.9291723179841815
Validation loss: 2.585877020299363

Epoch: 5| Step: 3
Training loss: 2.9745051765852124
Validation loss: 2.5727570465847642

Epoch: 5| Step: 4
Training loss: 3.3050730234640335
Validation loss: 2.5685255557349946

Epoch: 5| Step: 5
Training loss: 2.829285441523909
Validation loss: 2.5628087187693565

Epoch: 5| Step: 6
Training loss: 2.8401792136585753
Validation loss: 2.5644709093019706

Epoch: 5| Step: 7
Training loss: 2.6819739193654537
Validation loss: 2.561754107622738

Epoch: 5| Step: 8
Training loss: 2.517490051007429
Validation loss: 2.5635588914470935

Epoch: 5| Step: 9
Training loss: 3.324402639321115
Validation loss: 2.560185948032219

Epoch: 5| Step: 10
Training loss: 2.7212056437335015
Validation loss: 2.5612207716751065

Epoch: 62| Step: 0
Training loss: 2.8817474134467833
Validation loss: 2.5653165719428705

Epoch: 5| Step: 1
Training loss: 3.0821496048745938
Validation loss: 2.5624212047308648

Epoch: 5| Step: 2
Training loss: 2.4352439808271336
Validation loss: 2.5617565233993176

Epoch: 5| Step: 3
Training loss: 2.3676518655183925
Validation loss: 2.5625318389683374

Epoch: 5| Step: 4
Training loss: 2.8347585870666734
Validation loss: 2.5617156470319187

Epoch: 5| Step: 5
Training loss: 2.9528514594088553
Validation loss: 2.5586463289698793

Epoch: 5| Step: 6
Training loss: 3.448000734961978
Validation loss: 2.5584030244353793

Epoch: 5| Step: 7
Training loss: 2.8197930615838196
Validation loss: 2.5566292218383517

Epoch: 5| Step: 8
Training loss: 2.688934120957251
Validation loss: 2.5588043980359343

Epoch: 5| Step: 9
Training loss: 3.2204065596953755
Validation loss: 2.5630583186152953

Epoch: 5| Step: 10
Training loss: 3.1375065594486804
Validation loss: 2.566579978697776

Epoch: 63| Step: 0
Training loss: 2.930441960146474
Validation loss: 2.5822577903734194

Epoch: 5| Step: 1
Training loss: 2.907429609553648
Validation loss: 2.602760595580268

Epoch: 5| Step: 2
Training loss: 2.7229131634861643
Validation loss: 2.6137386317658704

Epoch: 5| Step: 3
Training loss: 3.183302415494584
Validation loss: 2.604080419937526

Epoch: 5| Step: 4
Training loss: 2.8380072320976346
Validation loss: 2.5746137726206597

Epoch: 5| Step: 5
Training loss: 2.5785666347590435
Validation loss: 2.563067193615841

Epoch: 5| Step: 6
Training loss: 3.28024218386235
Validation loss: 2.560884170854387

Epoch: 5| Step: 7
Training loss: 2.8400472491994826
Validation loss: 2.55408191355276

Epoch: 5| Step: 8
Training loss: 2.895154054591378
Validation loss: 2.555570194719048

Epoch: 5| Step: 9
Training loss: 3.4033843418923015
Validation loss: 2.5538346958636104

Epoch: 5| Step: 10
Training loss: 2.2120699189709208
Validation loss: 2.557698219609812

Epoch: 64| Step: 0
Training loss: 2.9750803063076283
Validation loss: 2.5553212268692884

Epoch: 5| Step: 1
Training loss: 2.821434072727131
Validation loss: 2.560435834593436

Epoch: 5| Step: 2
Training loss: 2.958101308257469
Validation loss: 2.5621187049958216

Epoch: 5| Step: 3
Training loss: 2.8887294843499003
Validation loss: 2.574288371780679

Epoch: 5| Step: 4
Training loss: 3.1849893892551617
Validation loss: 2.593594993825466

Epoch: 5| Step: 5
Training loss: 2.88892046185708
Validation loss: 2.5889354186883877

Epoch: 5| Step: 6
Training loss: 3.0371685647869753
Validation loss: 2.587446461950428

Epoch: 5| Step: 7
Training loss: 2.8573901682494114
Validation loss: 2.589512234008595

Epoch: 5| Step: 8
Training loss: 3.1576320530573407
Validation loss: 2.5700786100284123

Epoch: 5| Step: 9
Training loss: 2.3589638863419315
Validation loss: 2.558494937569594

Epoch: 5| Step: 10
Training loss: 2.757929985850665
Validation loss: 2.54844857388746

Epoch: 65| Step: 0
Training loss: 3.0829363558792218
Validation loss: 2.5475228710682156

Epoch: 5| Step: 1
Training loss: 2.544610262783936
Validation loss: 2.5489635247533453

Epoch: 5| Step: 2
Training loss: 3.1981357329611373
Validation loss: 2.5483521144569243

Epoch: 5| Step: 3
Training loss: 3.18580432742604
Validation loss: 2.547426036434154

Epoch: 5| Step: 4
Training loss: 3.0480300670152043
Validation loss: 2.5473594952084455

Epoch: 5| Step: 5
Training loss: 3.064955369335029
Validation loss: 2.5466987754742436

Epoch: 5| Step: 6
Training loss: 3.2247693711253587
Validation loss: 2.549060694217185

Epoch: 5| Step: 7
Training loss: 2.875513777228728
Validation loss: 2.553596768750279

Epoch: 5| Step: 8
Training loss: 2.8813148474687975
Validation loss: 2.5545672642749744

Epoch: 5| Step: 9
Training loss: 1.7477132979773542
Validation loss: 2.5593316985451193

Epoch: 5| Step: 10
Training loss: 2.6863061781698554
Validation loss: 2.5528151614093026

Epoch: 66| Step: 0
Training loss: 3.1978153042877437
Validation loss: 2.560417692850297

Epoch: 5| Step: 1
Training loss: 2.9157664044957268
Validation loss: 2.5624688919704295

Epoch: 5| Step: 2
Training loss: 3.0874165141443943
Validation loss: 2.5603938027049105

Epoch: 5| Step: 3
Training loss: 2.7168467206516502
Validation loss: 2.5626664956720546

Epoch: 5| Step: 4
Training loss: 3.089170515210499
Validation loss: 2.558660654838514

Epoch: 5| Step: 5
Training loss: 2.96487623757316
Validation loss: 2.5579309775671204

Epoch: 5| Step: 6
Training loss: 3.106590979913431
Validation loss: 2.5557835535024416

Epoch: 5| Step: 7
Training loss: 3.10184660025975
Validation loss: 2.551557025964213

Epoch: 5| Step: 8
Training loss: 2.9660963546113717
Validation loss: 2.547421172667025

Epoch: 5| Step: 9
Training loss: 2.595700736866377
Validation loss: 2.5474541219162976

Epoch: 5| Step: 10
Training loss: 1.7402962995786517
Validation loss: 2.546370620856773

Epoch: 67| Step: 0
Training loss: 2.9329459418625814
Validation loss: 2.544236812392855

Epoch: 5| Step: 1
Training loss: 2.389105419823757
Validation loss: 2.5480800183455394

Epoch: 5| Step: 2
Training loss: 2.9011091478992825
Validation loss: 2.5574602690068993

Epoch: 5| Step: 3
Training loss: 2.5693436393781846
Validation loss: 2.5514415304796145

Epoch: 5| Step: 4
Training loss: 3.192358017454948
Validation loss: 2.563441744035172

Epoch: 5| Step: 5
Training loss: 3.08747273174399
Validation loss: 2.5659223353673277

Epoch: 5| Step: 6
Training loss: 2.788590591641765
Validation loss: 2.5613137717726118

Epoch: 5| Step: 7
Training loss: 2.9065704169071735
Validation loss: 2.5536367571053353

Epoch: 5| Step: 8
Training loss: 3.0735811883552278
Validation loss: 2.5465387348477755

Epoch: 5| Step: 9
Training loss: 3.0250898868037273
Validation loss: 2.5378255436362855

Epoch: 5| Step: 10
Training loss: 2.8712815826632045
Validation loss: 2.5415841937658517

Epoch: 68| Step: 0
Training loss: 3.294794375265437
Validation loss: 2.548454026191863

Epoch: 5| Step: 1
Training loss: 2.8950117487166644
Validation loss: 2.5431123337650643

Epoch: 5| Step: 2
Training loss: 3.183127452191019
Validation loss: 2.5448972369838807

Epoch: 5| Step: 3
Training loss: 2.093918864714107
Validation loss: 2.553371679009045

Epoch: 5| Step: 4
Training loss: 2.6547646352463503
Validation loss: 2.553839652819201

Epoch: 5| Step: 5
Training loss: 2.7303106128484824
Validation loss: 2.5651492588612017

Epoch: 5| Step: 6
Training loss: 2.7990877572790067
Validation loss: 2.5717752778062417

Epoch: 5| Step: 7
Training loss: 2.8799919244864944
Validation loss: 2.596970658088972

Epoch: 5| Step: 8
Training loss: 2.9313725622781135
Validation loss: 2.6061780145933375

Epoch: 5| Step: 9
Training loss: 3.257502332966131
Validation loss: 2.6183967197949576

Epoch: 5| Step: 10
Training loss: 2.8615517590721007
Validation loss: 2.5864654736641683

Epoch: 69| Step: 0
Training loss: 2.8481778058365084
Validation loss: 2.5565072714102115

Epoch: 5| Step: 1
Training loss: 3.0249716639176776
Validation loss: 2.546511636684254

Epoch: 5| Step: 2
Training loss: 2.916610135938397
Validation loss: 2.53713339850807

Epoch: 5| Step: 3
Training loss: 2.701993848916485
Validation loss: 2.5379466543238283

Epoch: 5| Step: 4
Training loss: 3.2918505235018785
Validation loss: 2.548598687058937

Epoch: 5| Step: 5
Training loss: 3.0348835040740494
Validation loss: 2.5515038487642516

Epoch: 5| Step: 6
Training loss: 3.0133247101359357
Validation loss: 2.5500327853951004

Epoch: 5| Step: 7
Training loss: 2.6360384141093998
Validation loss: 2.546099725653506

Epoch: 5| Step: 8
Training loss: 3.2077047219359023
Validation loss: 2.5400547165678127

Epoch: 5| Step: 9
Training loss: 2.5967209128743756
Validation loss: 2.53812906705816

Epoch: 5| Step: 10
Training loss: 2.5357141571505415
Validation loss: 2.548849169507103

Epoch: 70| Step: 0
Training loss: 2.7371119289459775
Validation loss: 2.5705787233317556

Epoch: 5| Step: 1
Training loss: 2.7018435753947894
Validation loss: 2.61759626746894

Epoch: 5| Step: 2
Training loss: 3.1161093317225785
Validation loss: 2.6652584286330083

Epoch: 5| Step: 3
Training loss: 3.1503573260406954
Validation loss: 2.73979021034679

Epoch: 5| Step: 4
Training loss: 3.022185783618467
Validation loss: 2.686683845649323

Epoch: 5| Step: 5
Training loss: 2.9728565925529025
Validation loss: 2.5870951838331573

Epoch: 5| Step: 6
Training loss: 3.008112112208296
Validation loss: 2.544703168758506

Epoch: 5| Step: 7
Training loss: 2.6155572624960817
Validation loss: 2.5400509751433575

Epoch: 5| Step: 8
Training loss: 2.264470299429761
Validation loss: 2.532362872173484

Epoch: 5| Step: 9
Training loss: 3.124783470281584
Validation loss: 2.539202832555404

Epoch: 5| Step: 10
Training loss: 3.1675663891272756
Validation loss: 2.5435119011548846

Epoch: 71| Step: 0
Training loss: 2.9270948814806856
Validation loss: 2.5426637888105823

Epoch: 5| Step: 1
Training loss: 2.8338487567696897
Validation loss: 2.5440671566797293

Epoch: 5| Step: 2
Training loss: 2.653280415829969
Validation loss: 2.5383461157880145

Epoch: 5| Step: 3
Training loss: 2.733930889576083
Validation loss: 2.5358137066390727

Epoch: 5| Step: 4
Training loss: 2.8478285497964313
Validation loss: 2.5296082038062235

Epoch: 5| Step: 5
Training loss: 2.8792709471555105
Validation loss: 2.5390439445379225

Epoch: 5| Step: 6
Training loss: 3.2548929209170216
Validation loss: 2.5381538313758147

Epoch: 5| Step: 7
Training loss: 2.9620760135414415
Validation loss: 2.55309164400214

Epoch: 5| Step: 8
Training loss: 2.772843676112042
Validation loss: 2.5832498178336456

Epoch: 5| Step: 9
Training loss: 3.1154789652217616
Validation loss: 2.592192220471863

Epoch: 5| Step: 10
Training loss: 2.938498469353784
Validation loss: 2.5575651577245253

Epoch: 72| Step: 0
Training loss: 2.8693109699368082
Validation loss: 2.5455306527893384

Epoch: 5| Step: 1
Training loss: 2.9669553451957684
Validation loss: 2.543595420557101

Epoch: 5| Step: 2
Training loss: 3.057323830395833
Validation loss: 2.5497158022461037

Epoch: 5| Step: 3
Training loss: 3.1019037861269445
Validation loss: 2.545678852412478

Epoch: 5| Step: 4
Training loss: 2.6618039577988117
Validation loss: 2.5352812498145245

Epoch: 5| Step: 5
Training loss: 2.8293086994308
Validation loss: 2.5278162604165075

Epoch: 5| Step: 6
Training loss: 2.7985121554624772
Validation loss: 2.5296143706640906

Epoch: 5| Step: 7
Training loss: 2.5554859651774637
Validation loss: 2.53366444969359

Epoch: 5| Step: 8
Training loss: 3.3157590272727777
Validation loss: 2.5332619563155196

Epoch: 5| Step: 9
Training loss: 2.81777163356301
Validation loss: 2.5348175104150705

Epoch: 5| Step: 10
Training loss: 2.7425264763053945
Validation loss: 2.5323182098809984

Epoch: 73| Step: 0
Training loss: 2.829652826696043
Validation loss: 2.5286882371463433

Epoch: 5| Step: 1
Training loss: 3.1905005300904317
Validation loss: 2.529086496030218

Epoch: 5| Step: 2
Training loss: 3.2119976437608715
Validation loss: 2.524715113237119

Epoch: 5| Step: 3
Training loss: 2.8598882495948854
Validation loss: 2.540152690068157

Epoch: 5| Step: 4
Training loss: 2.445337264937995
Validation loss: 2.556121858021144

Epoch: 5| Step: 5
Training loss: 2.8627292990985005
Validation loss: 2.5675988091078863

Epoch: 5| Step: 6
Training loss: 2.6190075367589336
Validation loss: 2.560629081887915

Epoch: 5| Step: 7
Training loss: 2.8075642827895946
Validation loss: 2.5437374471347796

Epoch: 5| Step: 8
Training loss: 2.9117533762320984
Validation loss: 2.540498908727602

Epoch: 5| Step: 9
Training loss: 2.683571450308777
Validation loss: 2.531636356354129

Epoch: 5| Step: 10
Training loss: 3.169215548473784
Validation loss: 2.5300666345036866

Epoch: 74| Step: 0
Training loss: 2.6723635042909417
Validation loss: 2.5261018580750276

Epoch: 5| Step: 1
Training loss: 2.4184662487363466
Validation loss: 2.535924599168972

Epoch: 5| Step: 2
Training loss: 2.8952902597972043
Validation loss: 2.540901758560763

Epoch: 5| Step: 3
Training loss: 2.7917810862612344
Validation loss: 2.5404030294419853

Epoch: 5| Step: 4
Training loss: 3.1314510136268505
Validation loss: 2.5444951386112606

Epoch: 5| Step: 5
Training loss: 2.9773065232867704
Validation loss: 2.532961757942556

Epoch: 5| Step: 6
Training loss: 2.7977718002373986
Validation loss: 2.5214147796358577

Epoch: 5| Step: 7
Training loss: 3.4566314983387536
Validation loss: 2.5254374065630656

Epoch: 5| Step: 8
Training loss: 2.5406697512130543
Validation loss: 2.526382070849748

Epoch: 5| Step: 9
Training loss: 3.1045101581640147
Validation loss: 2.5223258182722916

Epoch: 5| Step: 10
Training loss: 2.666594703021189
Validation loss: 2.5209234172929182

Epoch: 75| Step: 0
Training loss: 2.1783265818243414
Validation loss: 2.521083442757446

Epoch: 5| Step: 1
Training loss: 3.262797760803644
Validation loss: 2.5273107150674825

Epoch: 5| Step: 2
Training loss: 3.018229728393678
Validation loss: 2.5328052978226987

Epoch: 5| Step: 3
Training loss: 2.873570957787275
Validation loss: 2.5464880562729775

Epoch: 5| Step: 4
Training loss: 2.841386252818775
Validation loss: 2.5596779611549487

Epoch: 5| Step: 5
Training loss: 3.1511801613041075
Validation loss: 2.5603498656824732

Epoch: 5| Step: 6
Training loss: 3.048788399104577
Validation loss: 2.5670280018682496

Epoch: 5| Step: 7
Training loss: 2.7923900084660636
Validation loss: 2.578545336672053

Epoch: 5| Step: 8
Training loss: 2.99252946856656
Validation loss: 2.5604152928319324

Epoch: 5| Step: 9
Training loss: 2.433801534976016
Validation loss: 2.5340287798518952

Epoch: 5| Step: 10
Training loss: 2.7383038006995384
Validation loss: 2.5312607437203547

Epoch: 76| Step: 0
Training loss: 2.785469198100107
Validation loss: 2.5202973325701326

Epoch: 5| Step: 1
Training loss: 3.056243578196139
Validation loss: 2.5252836709946673

Epoch: 5| Step: 2
Training loss: 2.409351084549656
Validation loss: 2.5221197015244345

Epoch: 5| Step: 3
Training loss: 3.1503493039660717
Validation loss: 2.5264414095596885

Epoch: 5| Step: 4
Training loss: 2.32463016234693
Validation loss: 2.5327277104314754

Epoch: 5| Step: 5
Training loss: 3.258227132121797
Validation loss: 2.5332632116911875

Epoch: 5| Step: 6
Training loss: 2.6795079474170245
Validation loss: 2.5381347051584124

Epoch: 5| Step: 7
Training loss: 3.0071478567609335
Validation loss: 2.5432357329114224

Epoch: 5| Step: 8
Training loss: 2.711761964867411
Validation loss: 2.528316963355279

Epoch: 5| Step: 9
Training loss: 3.140484707104405
Validation loss: 2.531375411459112

Epoch: 5| Step: 10
Training loss: 2.732168124497916
Validation loss: 2.524254384271426

Epoch: 77| Step: 0
Training loss: 3.0754815383627423
Validation loss: 2.518262532819691

Epoch: 5| Step: 1
Training loss: 2.8561327954041125
Validation loss: 2.521726704388041

Epoch: 5| Step: 2
Training loss: 2.8936647670379134
Validation loss: 2.522569596585543

Epoch: 5| Step: 3
Training loss: 2.9639196350384247
Validation loss: 2.5209441364465857

Epoch: 5| Step: 4
Training loss: 2.7265004148218877
Validation loss: 2.523107041434519

Epoch: 5| Step: 5
Training loss: 2.737879050153206
Validation loss: 2.5231974502902514

Epoch: 5| Step: 6
Training loss: 2.442092286424204
Validation loss: 2.5247033221782313

Epoch: 5| Step: 7
Training loss: 2.6680299631806856
Validation loss: 2.525119324793502

Epoch: 5| Step: 8
Training loss: 3.2185339994082214
Validation loss: 2.54156489061734

Epoch: 5| Step: 9
Training loss: 2.8895604828304853
Validation loss: 2.5266083200494966

Epoch: 5| Step: 10
Training loss: 2.8259980860742133
Validation loss: 2.5313705178651125

Epoch: 78| Step: 0
Training loss: 2.76490791636543
Validation loss: 2.537700598430809

Epoch: 5| Step: 1
Training loss: 3.1126841662970257
Validation loss: 2.536056688561154

Epoch: 5| Step: 2
Training loss: 3.028248037824654
Validation loss: 2.5336074586744517

Epoch: 5| Step: 3
Training loss: 3.140356251619386
Validation loss: 2.52417130961577

Epoch: 5| Step: 4
Training loss: 2.293257375095027
Validation loss: 2.519282314794518

Epoch: 5| Step: 5
Training loss: 3.395153063327969
Validation loss: 2.530329301998613

Epoch: 5| Step: 6
Training loss: 2.8575642172872353
Validation loss: 2.534106953622135

Epoch: 5| Step: 7
Training loss: 2.7704080719015343
Validation loss: 2.552276134595696

Epoch: 5| Step: 8
Training loss: 2.6133131815010104
Validation loss: 2.544823275164166

Epoch: 5| Step: 9
Training loss: 2.530338358662744
Validation loss: 2.5216076735443997

Epoch: 5| Step: 10
Training loss: 2.6588800312593803
Validation loss: 2.5201305910599214

Epoch: 79| Step: 0
Training loss: 3.194544319766077
Validation loss: 2.5160595847070115

Epoch: 5| Step: 1
Training loss: 2.878121381626899
Validation loss: 2.5143394520439437

Epoch: 5| Step: 2
Training loss: 2.3429797114732436
Validation loss: 2.5122696809070177

Epoch: 5| Step: 3
Training loss: 3.160984227904736
Validation loss: 2.516301850705499

Epoch: 5| Step: 4
Training loss: 2.9313663809310717
Validation loss: 2.5256649574142855

Epoch: 5| Step: 5
Training loss: 3.381030593494461
Validation loss: 2.5442487678541252

Epoch: 5| Step: 6
Training loss: 2.131077546332814
Validation loss: 2.5726727718838682

Epoch: 5| Step: 7
Training loss: 2.5575879165588296
Validation loss: 2.6277966814747904

Epoch: 5| Step: 8
Training loss: 2.8714567824267747
Validation loss: 2.596971614652463

Epoch: 5| Step: 9
Training loss: 3.0734125459217476
Validation loss: 2.550077912533573

Epoch: 5| Step: 10
Training loss: 2.6960457951479446
Validation loss: 2.530271220645456

Epoch: 80| Step: 0
Training loss: 2.4558138355749244
Validation loss: 2.5193632234694308

Epoch: 5| Step: 1
Training loss: 2.920584327288835
Validation loss: 2.510714341777006

Epoch: 5| Step: 2
Training loss: 3.1808952268622277
Validation loss: 2.510096205855745

Epoch: 5| Step: 3
Training loss: 3.0702199363830065
Validation loss: 2.5153052788549606

Epoch: 5| Step: 4
Training loss: 2.41481830900694
Validation loss: 2.514466180007784

Epoch: 5| Step: 5
Training loss: 2.84384373101668
Validation loss: 2.525357036635113

Epoch: 5| Step: 6
Training loss: 2.826283482349447
Validation loss: 2.5206930290465666

Epoch: 5| Step: 7
Training loss: 2.8903115592309123
Validation loss: 2.5397040140587683

Epoch: 5| Step: 8
Training loss: 2.6630817297191274
Validation loss: 2.5715448944796817

Epoch: 5| Step: 9
Training loss: 2.902343914293821
Validation loss: 2.583226375039435

Epoch: 5| Step: 10
Training loss: 3.2444476602994174
Validation loss: 2.5632347096132606

Epoch: 81| Step: 0
Training loss: 2.3707975048537984
Validation loss: 2.528672466076781

Epoch: 5| Step: 1
Training loss: 3.0715723922869813
Validation loss: 2.524035043060153

Epoch: 5| Step: 2
Training loss: 2.601486434053605
Validation loss: 2.5129610250374714

Epoch: 5| Step: 3
Training loss: 3.1377769196028553
Validation loss: 2.5106516109328787

Epoch: 5| Step: 4
Training loss: 2.9260292915760657
Validation loss: 2.514310399165565

Epoch: 5| Step: 5
Training loss: 2.986809980439487
Validation loss: 2.5125468907281197

Epoch: 5| Step: 6
Training loss: 3.118379216905745
Validation loss: 2.5134355804149253

Epoch: 5| Step: 7
Training loss: 2.9838892356625983
Validation loss: 2.513090139193468

Epoch: 5| Step: 8
Training loss: 2.435928424967561
Validation loss: 2.5201983939115955

Epoch: 5| Step: 9
Training loss: 2.9838141268809646
Validation loss: 2.5201375145559735

Epoch: 5| Step: 10
Training loss: 2.5535378391979666
Validation loss: 2.5340865818541207

Epoch: 82| Step: 0
Training loss: 2.6067675508877985
Validation loss: 2.547637590751051

Epoch: 5| Step: 1
Training loss: 2.880768834647153
Validation loss: 2.553489249254217

Epoch: 5| Step: 2
Training loss: 2.6089758653383455
Validation loss: 2.573227181657166

Epoch: 5| Step: 3
Training loss: 3.107797653906926
Validation loss: 2.6109625059801953

Epoch: 5| Step: 4
Training loss: 2.66179482161253
Validation loss: 2.636067847728519

Epoch: 5| Step: 5
Training loss: 3.08204099704376
Validation loss: 2.6614543525533265

Epoch: 5| Step: 6
Training loss: 3.0342944086374635
Validation loss: 2.644826018224854

Epoch: 5| Step: 7
Training loss: 2.9881973155083204
Validation loss: 2.5852604431907165

Epoch: 5| Step: 8
Training loss: 2.7156923134278186
Validation loss: 2.5042055555288103

Epoch: 5| Step: 9
Training loss: 2.7799712252328366
Validation loss: 2.504965455314812

Epoch: 5| Step: 10
Training loss: 2.695861495124929
Validation loss: 2.5228363863330863

Epoch: 83| Step: 0
Training loss: 3.271199264628532
Validation loss: 2.5386720650914016

Epoch: 5| Step: 1
Training loss: 2.9963063707965145
Validation loss: 2.536197753493291

Epoch: 5| Step: 2
Training loss: 2.6462593236298573
Validation loss: 2.5355657067392166

Epoch: 5| Step: 3
Training loss: 2.9782354504497173
Validation loss: 2.530241729608199

Epoch: 5| Step: 4
Training loss: 3.08445468478865
Validation loss: 2.5300005451308647

Epoch: 5| Step: 5
Training loss: 2.356202778229202
Validation loss: 2.5280837676116676

Epoch: 5| Step: 6
Training loss: 3.1880767898788234
Validation loss: 2.52441936665401

Epoch: 5| Step: 7
Training loss: 2.65469521290701
Validation loss: 2.52237745923145

Epoch: 5| Step: 8
Training loss: 2.9915581183190745
Validation loss: 2.5244234755123505

Epoch: 5| Step: 9
Training loss: 2.8455638759792112
Validation loss: 2.5237789001209503

Epoch: 5| Step: 10
Training loss: 3.0272602685062227
Validation loss: 2.5213914756894473

Epoch: 84| Step: 0
Training loss: 2.7908354608302313
Validation loss: 2.527577369011869

Epoch: 5| Step: 1
Training loss: 2.495474916259072
Validation loss: 2.5244257706206232

Epoch: 5| Step: 2
Training loss: 2.8674607315633995
Validation loss: 2.5516639637806344

Epoch: 5| Step: 3
Training loss: 3.0700883856361
Validation loss: 2.5664824926169576

Epoch: 5| Step: 4
Training loss: 3.1094829598091946
Validation loss: 2.550816098565781

Epoch: 5| Step: 5
Training loss: 2.854163919340793
Validation loss: 2.526999092048874

Epoch: 5| Step: 6
Training loss: 2.9672174613930475
Validation loss: 2.5211585555516693

Epoch: 5| Step: 7
Training loss: 3.0910486314761982
Validation loss: 2.5223730065594294

Epoch: 5| Step: 8
Training loss: 2.907218197575722
Validation loss: 2.5269058562550577

Epoch: 5| Step: 9
Training loss: 2.4393414119799712
Validation loss: 2.545822045676634

Epoch: 5| Step: 10
Training loss: 2.774451443864457
Validation loss: 2.588537829270342

Epoch: 85| Step: 0
Training loss: 3.161423173402011
Validation loss: 2.6075351942564393

Epoch: 5| Step: 1
Training loss: 2.7838021901877723
Validation loss: 2.57939056030886

Epoch: 5| Step: 2
Training loss: 3.120108017885587
Validation loss: 2.541541853135963

Epoch: 5| Step: 3
Training loss: 3.409273817762008
Validation loss: 2.521500483841635

Epoch: 5| Step: 4
Training loss: 2.819435723034963
Validation loss: 2.5023631453103015

Epoch: 5| Step: 5
Training loss: 2.515178569726186
Validation loss: 2.5075953847091195

Epoch: 5| Step: 6
Training loss: 3.064218933998691
Validation loss: 2.51606525595891

Epoch: 5| Step: 7
Training loss: 2.307701906771136
Validation loss: 2.5282168712609523

Epoch: 5| Step: 8
Training loss: 2.6056205556588665
Validation loss: 2.5588936628775185

Epoch: 5| Step: 9
Training loss: 2.945755902414334
Validation loss: 2.6259009694599116

Epoch: 5| Step: 10
Training loss: 2.4876713986028696
Validation loss: 2.6302376268612164

Epoch: 86| Step: 0
Training loss: 2.4946558098379232
Validation loss: 2.6384847420747723

Epoch: 5| Step: 1
Training loss: 3.2142002578758984
Validation loss: 2.643348876789905

Epoch: 5| Step: 2
Training loss: 2.976101737016439
Validation loss: 2.6826499593735735

Epoch: 5| Step: 3
Training loss: 2.640419314347366
Validation loss: 2.62631822995417

Epoch: 5| Step: 4
Training loss: 2.5146385770437742
Validation loss: 2.5995115792420256

Epoch: 5| Step: 5
Training loss: 3.4371906488110917
Validation loss: 2.586850755437078

Epoch: 5| Step: 6
Training loss: 2.5230566156591756
Validation loss: 2.579564668747933

Epoch: 5| Step: 7
Training loss: 3.163934398930753
Validation loss: 2.5788895225119712

Epoch: 5| Step: 8
Training loss: 2.609987655259678
Validation loss: 2.577683903214272

Epoch: 5| Step: 9
Training loss: 2.6927746310210328
Validation loss: 2.5726120082442603

Epoch: 5| Step: 10
Training loss: 3.4967625495072894
Validation loss: 2.558636878541793

Epoch: 87| Step: 0
Training loss: 2.563514787661432
Validation loss: 2.541843369499492

Epoch: 5| Step: 1
Training loss: 3.133622138599281
Validation loss: 2.5416503147895018

Epoch: 5| Step: 2
Training loss: 3.326282259710479
Validation loss: 2.5368348087959425

Epoch: 5| Step: 3
Training loss: 2.6836908536664534
Validation loss: 2.5331559970273325

Epoch: 5| Step: 4
Training loss: 2.6590924481592713
Validation loss: 2.5167022112828805

Epoch: 5| Step: 5
Training loss: 3.1667774749910738
Validation loss: 2.5205518673366964

Epoch: 5| Step: 6
Training loss: 2.60561753610268
Validation loss: 2.5632534275087124

Epoch: 5| Step: 7
Training loss: 2.857039034183236
Validation loss: 2.5698168490154427

Epoch: 5| Step: 8
Training loss: 2.6775014429596076
Validation loss: 2.5461334461537213

Epoch: 5| Step: 9
Training loss: 2.5403202638942703
Validation loss: 2.5055631309115665

Epoch: 5| Step: 10
Training loss: 2.9942304444698045
Validation loss: 2.498974688300848

Epoch: 88| Step: 0
Training loss: 3.189078295536351
Validation loss: 2.490106011270678

Epoch: 5| Step: 1
Training loss: 2.292256389225008
Validation loss: 2.5043600143265605

Epoch: 5| Step: 2
Training loss: 3.383268330016924
Validation loss: 2.5254785503553934

Epoch: 5| Step: 3
Training loss: 2.869665255015345
Validation loss: 2.5283740939042216

Epoch: 5| Step: 4
Training loss: 2.73994636789445
Validation loss: 2.5422866320027993

Epoch: 5| Step: 5
Training loss: 2.484689272790084
Validation loss: 2.5440697484667965

Epoch: 5| Step: 6
Training loss: 2.7458043603907347
Validation loss: 2.533895971380427

Epoch: 5| Step: 7
Training loss: 2.3401287331994274
Validation loss: 2.523052509655302

Epoch: 5| Step: 8
Training loss: 2.910597963541357
Validation loss: 2.5425045004942257

Epoch: 5| Step: 9
Training loss: 2.9395864665561975
Validation loss: 2.5158830909150978

Epoch: 5| Step: 10
Training loss: 3.0468016004279974
Validation loss: 2.5008303268334777

Epoch: 89| Step: 0
Training loss: 2.3497506191960262
Validation loss: 2.4879647786466865

Epoch: 5| Step: 1
Training loss: 2.8700081985303365
Validation loss: 2.4874548359818704

Epoch: 5| Step: 2
Training loss: 2.807633746554429
Validation loss: 2.4915308241964547

Epoch: 5| Step: 3
Training loss: 2.613487064485009
Validation loss: 2.489468391707759

Epoch: 5| Step: 4
Training loss: 2.792950738168538
Validation loss: 2.4855238737927903

Epoch: 5| Step: 5
Training loss: 2.864865227903025
Validation loss: 2.4947880231472874

Epoch: 5| Step: 6
Training loss: 3.262144579473027
Validation loss: 2.520454916996342

Epoch: 5| Step: 7
Training loss: 3.092320584001323
Validation loss: 2.535808560778381

Epoch: 5| Step: 8
Training loss: 2.5748936603402766
Validation loss: 2.52857303084756

Epoch: 5| Step: 9
Training loss: 2.641986653856619
Validation loss: 2.519800665339113

Epoch: 5| Step: 10
Training loss: 3.0670409499383333
Validation loss: 2.522898379804134

Epoch: 90| Step: 0
Training loss: 2.8769047274018087
Validation loss: 2.508574735813964

Epoch: 5| Step: 1
Training loss: 2.66685442462187
Validation loss: 2.501679742158651

Epoch: 5| Step: 2
Training loss: 2.3266683027959423
Validation loss: 2.5000959644562575

Epoch: 5| Step: 3
Training loss: 3.2669858880323526
Validation loss: 2.4911835608914843

Epoch: 5| Step: 4
Training loss: 3.27553183627099
Validation loss: 2.4860156660361414

Epoch: 5| Step: 5
Training loss: 2.5966602222850717
Validation loss: 2.4997518457285874

Epoch: 5| Step: 6
Training loss: 3.018632407099595
Validation loss: 2.510003195546807

Epoch: 5| Step: 7
Training loss: 2.577994048520862
Validation loss: 2.50355768963593

Epoch: 5| Step: 8
Training loss: 2.3804964410105853
Validation loss: 2.5068860565389315

Epoch: 5| Step: 9
Training loss: 3.246349191541984
Validation loss: 2.502010292964683

Epoch: 5| Step: 10
Training loss: 2.3524336611143464
Validation loss: 2.5107381205794805

Epoch: 91| Step: 0
Training loss: 2.6560980360655293
Validation loss: 2.50025166916282

Epoch: 5| Step: 1
Training loss: 3.035909316265378
Validation loss: 2.513131245916373

Epoch: 5| Step: 2
Training loss: 2.5641687123618295
Validation loss: 2.514554003081187

Epoch: 5| Step: 3
Training loss: 2.857053721263659
Validation loss: 2.501295734272398

Epoch: 5| Step: 4
Training loss: 2.3965385946966014
Validation loss: 2.5020954763726038

Epoch: 5| Step: 5
Training loss: 2.7364386918072503
Validation loss: 2.4932090179683435

Epoch: 5| Step: 6
Training loss: 2.4684166985067657
Validation loss: 2.481355808256823

Epoch: 5| Step: 7
Training loss: 2.9327183215994705
Validation loss: 2.4906677998757836

Epoch: 5| Step: 8
Training loss: 2.9903211225986692
Validation loss: 2.4849344610240505

Epoch: 5| Step: 9
Training loss: 3.041046514825854
Validation loss: 2.4971151119197588

Epoch: 5| Step: 10
Training loss: 3.1485368509448657
Validation loss: 2.499804227608426

Epoch: 92| Step: 0
Training loss: 2.687076002873932
Validation loss: 2.5122141801667475

Epoch: 5| Step: 1
Training loss: 3.080898062084742
Validation loss: 2.5137911062018277

Epoch: 5| Step: 2
Training loss: 2.858462328729491
Validation loss: 2.508314944954723

Epoch: 5| Step: 3
Training loss: 2.4239522577878194
Validation loss: 2.4925219272578785

Epoch: 5| Step: 4
Training loss: 2.741099954335077
Validation loss: 2.48412367904636

Epoch: 5| Step: 5
Training loss: 2.2219119040728077
Validation loss: 2.479907337696083

Epoch: 5| Step: 6
Training loss: 2.822660953064861
Validation loss: 2.486617630356823

Epoch: 5| Step: 7
Training loss: 3.216821926369136
Validation loss: 2.484897807463295

Epoch: 5| Step: 8
Training loss: 3.0832012938674405
Validation loss: 2.480738627394782

Epoch: 5| Step: 9
Training loss: 2.8662941187887245
Validation loss: 2.4828404848106365

Epoch: 5| Step: 10
Training loss: 3.0204017243129946
Validation loss: 2.483285650783949

Epoch: 93| Step: 0
Training loss: 2.3490985115217065
Validation loss: 2.5044410401556303

Epoch: 5| Step: 1
Training loss: 2.6232002991709025
Validation loss: 2.5377845091024374

Epoch: 5| Step: 2
Training loss: 2.9984734147919117
Validation loss: 2.5700695986425295

Epoch: 5| Step: 3
Training loss: 2.78125685787427
Validation loss: 2.5822751328735474

Epoch: 5| Step: 4
Training loss: 2.848866983700768
Validation loss: 2.5690715237772586

Epoch: 5| Step: 5
Training loss: 2.4317579861550285
Validation loss: 2.5692060787012143

Epoch: 5| Step: 6
Training loss: 3.441335168595867
Validation loss: 2.5507344533378347

Epoch: 5| Step: 7
Training loss: 2.5379709567789805
Validation loss: 2.535052549697707

Epoch: 5| Step: 8
Training loss: 3.0469717157125924
Validation loss: 2.502721119300512

Epoch: 5| Step: 9
Training loss: 2.682277839896604
Validation loss: 2.477816463177782

Epoch: 5| Step: 10
Training loss: 3.0596544708940923
Validation loss: 2.4817893034426284

Epoch: 94| Step: 0
Training loss: 3.040455947363633
Validation loss: 2.482443674539035

Epoch: 5| Step: 1
Training loss: 2.8496389930027792
Validation loss: 2.4854528929510398

Epoch: 5| Step: 2
Training loss: 2.6941339984694497
Validation loss: 2.481643583797705

Epoch: 5| Step: 3
Training loss: 2.922661007507906
Validation loss: 2.4798361113199765

Epoch: 5| Step: 4
Training loss: 2.8778609263396553
Validation loss: 2.475982040557126

Epoch: 5| Step: 5
Training loss: 2.933735972282768
Validation loss: 2.4789726961823604

Epoch: 5| Step: 6
Training loss: 1.9363613474421664
Validation loss: 2.488809726331939

Epoch: 5| Step: 7
Training loss: 2.4567937933311454
Validation loss: 2.5215527829815856

Epoch: 5| Step: 8
Training loss: 2.9342298770398814
Validation loss: 2.54043479215193

Epoch: 5| Step: 9
Training loss: 3.3696045310146663
Validation loss: 2.5807864336343513

Epoch: 5| Step: 10
Training loss: 2.8031392619132727
Validation loss: 2.5250707321794765

Epoch: 95| Step: 0
Training loss: 2.835070769218908
Validation loss: 2.5201946179226926

Epoch: 5| Step: 1
Training loss: 2.680009650170332
Validation loss: 2.498714206608706

Epoch: 5| Step: 2
Training loss: 2.866200290120769
Validation loss: 2.482985391857434

Epoch: 5| Step: 3
Training loss: 2.5541287899061094
Validation loss: 2.474261252613657

Epoch: 5| Step: 4
Training loss: 3.168638936942409
Validation loss: 2.4717237953224926

Epoch: 5| Step: 5
Training loss: 2.759623681134932
Validation loss: 2.4791503937427524

Epoch: 5| Step: 6
Training loss: 2.9890072009349877
Validation loss: 2.4785802521115823

Epoch: 5| Step: 7
Training loss: 2.7764791653244862
Validation loss: 2.476447507518288

Epoch: 5| Step: 8
Training loss: 2.5826669161567835
Validation loss: 2.4784790807989876

Epoch: 5| Step: 9
Training loss: 2.475034513136542
Validation loss: 2.5033567473629867

Epoch: 5| Step: 10
Training loss: 3.2264998386015913
Validation loss: 2.5108480445813632

Epoch: 96| Step: 0
Training loss: 3.2174819374318475
Validation loss: 2.52063602850652

Epoch: 5| Step: 1
Training loss: 2.394010452961549
Validation loss: 2.516796839104097

Epoch: 5| Step: 2
Training loss: 2.661661358061457
Validation loss: 2.521799067457977

Epoch: 5| Step: 3
Training loss: 3.0386422854766755
Validation loss: 2.5074916048154456

Epoch: 5| Step: 4
Training loss: 3.1948023904214753
Validation loss: 2.493853394112091

Epoch: 5| Step: 5
Training loss: 3.0841997492975217
Validation loss: 2.513406103993993

Epoch: 5| Step: 6
Training loss: 2.2543910941365666
Validation loss: 2.516447945244539

Epoch: 5| Step: 7
Training loss: 2.864823949707448
Validation loss: 2.5024666051748903

Epoch: 5| Step: 8
Training loss: 2.334332989949182
Validation loss: 2.528360919639528

Epoch: 5| Step: 9
Training loss: 2.637668376447526
Validation loss: 2.5319124613580186

Epoch: 5| Step: 10
Training loss: 2.93374653709152
Validation loss: 2.5344920723442836

Epoch: 97| Step: 0
Training loss: 3.235336824125048
Validation loss: 2.523172026079867

Epoch: 5| Step: 1
Training loss: 3.4548654442296205
Validation loss: 2.510840138766141

Epoch: 5| Step: 2
Training loss: 2.9520520072428935
Validation loss: 2.507821781096677

Epoch: 5| Step: 3
Training loss: 2.462718694435059
Validation loss: 2.4876854190368305

Epoch: 5| Step: 4
Training loss: 2.1351852911918834
Validation loss: 2.4823801590567984

Epoch: 5| Step: 5
Training loss: 2.573179460662175
Validation loss: 2.4770068215858614

Epoch: 5| Step: 6
Training loss: 3.1318164488207167
Validation loss: 2.4752949637608865

Epoch: 5| Step: 7
Training loss: 2.715872809689033
Validation loss: 2.4765389303095944

Epoch: 5| Step: 8
Training loss: 2.448011182759492
Validation loss: 2.499863673154021

Epoch: 5| Step: 9
Training loss: 2.672460123876219
Validation loss: 2.511790561403802

Epoch: 5| Step: 10
Training loss: 2.8227448264508657
Validation loss: 2.521691982471143

Epoch: 98| Step: 0
Training loss: 2.7888981960423336
Validation loss: 2.4936628973451396

Epoch: 5| Step: 1
Training loss: 2.910264882357934
Validation loss: 2.490582387221553

Epoch: 5| Step: 2
Training loss: 2.390561769933314
Validation loss: 2.4879073013352326

Epoch: 5| Step: 3
Training loss: 2.7071930367700383
Validation loss: 2.494087840474004

Epoch: 5| Step: 4
Training loss: 2.494333712303741
Validation loss: 2.492159153784835

Epoch: 5| Step: 5
Training loss: 2.413968278842397
Validation loss: 2.490828574200652

Epoch: 5| Step: 6
Training loss: 3.028887270321145
Validation loss: 2.490489223564763

Epoch: 5| Step: 7
Training loss: 2.822312763176845
Validation loss: 2.5001886265874185

Epoch: 5| Step: 8
Training loss: 2.551361438610705
Validation loss: 2.5134607859026725

Epoch: 5| Step: 9
Training loss: 3.2153269519345797
Validation loss: 2.528702233938885

Epoch: 5| Step: 10
Training loss: 3.2236066306968434
Validation loss: 2.5307875088809753

Epoch: 99| Step: 0
Training loss: 3.0463187467998964
Validation loss: 2.5276401640942985

Epoch: 5| Step: 1
Training loss: 2.6254490059626288
Validation loss: 2.500269024228045

Epoch: 5| Step: 2
Training loss: 2.8195316998573086
Validation loss: 2.4924659950149395

Epoch: 5| Step: 3
Training loss: 2.5029296875
Validation loss: 2.4886160044025747

Epoch: 5| Step: 4
Training loss: 2.445350914796603
Validation loss: 2.4971527354606105

Epoch: 5| Step: 5
Training loss: 2.826525915783189
Validation loss: 2.513552889044473

Epoch: 5| Step: 6
Training loss: 3.0957769054200797
Validation loss: 2.52090038541581

Epoch: 5| Step: 7
Training loss: 2.854233084321214
Validation loss: 2.5296472650481876

Epoch: 5| Step: 8
Training loss: 2.532750756218906
Validation loss: 2.5148308795487644

Epoch: 5| Step: 9
Training loss: 2.6256843764672513
Validation loss: 2.4909993055980433

Epoch: 5| Step: 10
Training loss: 3.213562127063149
Validation loss: 2.483953383292621

Epoch: 100| Step: 0
Training loss: 2.066396904331123
Validation loss: 2.4746213892065976

Epoch: 5| Step: 1
Training loss: 2.5857808506473363
Validation loss: 2.4769605401673833

Epoch: 5| Step: 2
Training loss: 2.7495537309073863
Validation loss: 2.4703338452136343

Epoch: 5| Step: 3
Training loss: 2.361061049535265
Validation loss: 2.47398896401856

Epoch: 5| Step: 4
Training loss: 3.211491223782517
Validation loss: 2.470848799371789

Epoch: 5| Step: 5
Training loss: 3.034227305156202
Validation loss: 2.4934843443012786

Epoch: 5| Step: 6
Training loss: 2.7225464370452297
Validation loss: 2.514723837311762

Epoch: 5| Step: 7
Training loss: 3.2127858431811958
Validation loss: 2.554748965923787

Epoch: 5| Step: 8
Training loss: 3.0234496439214285
Validation loss: 2.590690143247649

Epoch: 5| Step: 9
Training loss: 2.882718878158806
Validation loss: 2.5863783796084614

Epoch: 5| Step: 10
Training loss: 2.809693865136145
Validation loss: 2.5613541370920228

Epoch: 101| Step: 0
Training loss: 2.5495142455345476
Validation loss: 2.496908007778645

Epoch: 5| Step: 1
Training loss: 2.4977429691995026
Validation loss: 2.4715385467211366

Epoch: 5| Step: 2
Training loss: 2.750063115175936
Validation loss: 2.473578092739365

Epoch: 5| Step: 3
Training loss: 1.944163216583596
Validation loss: 2.479365219792215

Epoch: 5| Step: 4
Training loss: 3.0061374508415364
Validation loss: 2.4825599269087917

Epoch: 5| Step: 5
Training loss: 3.0817654377809123
Validation loss: 2.47757885877545

Epoch: 5| Step: 6
Training loss: 2.6983843561272614
Validation loss: 2.4718088701873704

Epoch: 5| Step: 7
Training loss: 3.2080901578092105
Validation loss: 2.4704693961704685

Epoch: 5| Step: 8
Training loss: 3.130183231974586
Validation loss: 2.474576058762288

Epoch: 5| Step: 9
Training loss: 2.912637561611059
Validation loss: 2.4885012608794934

Epoch: 5| Step: 10
Training loss: 2.8610141412624834
Validation loss: 2.520388752572039

Epoch: 102| Step: 0
Training loss: 3.3629993847844437
Validation loss: 2.5413239969419417

Epoch: 5| Step: 1
Training loss: 2.788592900083524
Validation loss: 2.55666489314922

Epoch: 5| Step: 2
Training loss: 2.124557673475202
Validation loss: 2.580686146400433

Epoch: 5| Step: 3
Training loss: 3.320438589058086
Validation loss: 2.6101373663226615

Epoch: 5| Step: 4
Training loss: 3.1206404221877735
Validation loss: 2.575332705569102

Epoch: 5| Step: 5
Training loss: 2.804628504395628
Validation loss: 2.5337542885893996

Epoch: 5| Step: 6
Training loss: 2.489309149504955
Validation loss: 2.509651697272792

Epoch: 5| Step: 7
Training loss: 2.309553382601797
Validation loss: 2.479882972776457

Epoch: 5| Step: 8
Training loss: 2.649410102973451
Validation loss: 2.4715495505232727

Epoch: 5| Step: 9
Training loss: 2.8356472739105145
Validation loss: 2.4673983912322353

Epoch: 5| Step: 10
Training loss: 2.4766538585093767
Validation loss: 2.466645826563757

Epoch: 103| Step: 0
Training loss: 2.6188760804481857
Validation loss: 2.4695573439159

Epoch: 5| Step: 1
Training loss: 2.6366560864949617
Validation loss: 2.4686011942841626

Epoch: 5| Step: 2
Training loss: 2.9887098216982237
Validation loss: 2.464947866291086

Epoch: 5| Step: 3
Training loss: 3.0243208824340644
Validation loss: 2.469392450161317

Epoch: 5| Step: 4
Training loss: 2.6373914072542575
Validation loss: 2.465473695263214

Epoch: 5| Step: 5
Training loss: 2.8789963520499966
Validation loss: 2.483534019649044

Epoch: 5| Step: 6
Training loss: 2.3378039402136395
Validation loss: 2.485975866633413

Epoch: 5| Step: 7
Training loss: 2.8935321107898346
Validation loss: 2.5017630267189004

Epoch: 5| Step: 8
Training loss: 2.847668306301639
Validation loss: 2.5160970783124066

Epoch: 5| Step: 9
Training loss: 3.0834467239837298
Validation loss: 2.531389004501088

Epoch: 5| Step: 10
Training loss: 2.750931495348812
Validation loss: 2.5450373555958707

Epoch: 104| Step: 0
Training loss: 2.530176193977566
Validation loss: 2.5457185099607074

Epoch: 5| Step: 1
Training loss: 2.993900774700939
Validation loss: 2.5146486087730917

Epoch: 5| Step: 2
Training loss: 3.2032286092237032
Validation loss: 2.4955311745162523

Epoch: 5| Step: 3
Training loss: 2.212632139753547
Validation loss: 2.4783030786434446

Epoch: 5| Step: 4
Training loss: 2.9955564014548073
Validation loss: 2.4899774247113213

Epoch: 5| Step: 5
Training loss: 2.5118919775570134
Validation loss: 2.475276593642033

Epoch: 5| Step: 6
Training loss: 2.642740068456883
Validation loss: 2.473455800611991

Epoch: 5| Step: 7
Training loss: 3.1181706381566276
Validation loss: 2.4675630525333405

Epoch: 5| Step: 8
Training loss: 3.136842338056027
Validation loss: 2.4650612549185933

Epoch: 5| Step: 9
Training loss: 2.4701676945768387
Validation loss: 2.4708510140311746

Epoch: 5| Step: 10
Training loss: 2.4856994745129577
Validation loss: 2.4709358543790034

Epoch: 105| Step: 0
Training loss: 3.016106917856429
Validation loss: 2.4680558227273863

Epoch: 5| Step: 1
Training loss: 2.7723969562668467
Validation loss: 2.4721711518224954

Epoch: 5| Step: 2
Training loss: 2.9692180063878784
Validation loss: 2.47613884487355

Epoch: 5| Step: 3
Training loss: 2.421070974463804
Validation loss: 2.4790410187226373

Epoch: 5| Step: 4
Training loss: 2.8697262368240644
Validation loss: 2.4825531423225233

Epoch: 5| Step: 5
Training loss: 2.4221194236223815
Validation loss: 2.473751670784897

Epoch: 5| Step: 6
Training loss: 2.8228044569698443
Validation loss: 2.487354578590812

Epoch: 5| Step: 7
Training loss: 2.9959075352618725
Validation loss: 2.5024584608199665

Epoch: 5| Step: 8
Training loss: 2.3303780118929653
Validation loss: 2.5067614008463885

Epoch: 5| Step: 9
Training loss: 2.6670476124779103
Validation loss: 2.5308365873531926

Epoch: 5| Step: 10
Training loss: 3.1427876631995795
Validation loss: 2.527743025990877

Epoch: 106| Step: 0
Training loss: 2.5772656482380962
Validation loss: 2.5388872508614893

Epoch: 5| Step: 1
Training loss: 2.5688955001276663
Validation loss: 2.526364075248261

Epoch: 5| Step: 2
Training loss: 2.895660797760759
Validation loss: 2.5110089980138945

Epoch: 5| Step: 3
Training loss: 2.559373669746249
Validation loss: 2.4969799853748578

Epoch: 5| Step: 4
Training loss: 2.99946112561363
Validation loss: 2.483076446943844

Epoch: 5| Step: 5
Training loss: 2.754176349786385
Validation loss: 2.4817313680396924

Epoch: 5| Step: 6
Training loss: 2.984678083278534
Validation loss: 2.4762124407814583

Epoch: 5| Step: 7
Training loss: 2.6949478566180343
Validation loss: 2.4756458920904296

Epoch: 5| Step: 8
Training loss: 2.8575395206578653
Validation loss: 2.4725872875750214

Epoch: 5| Step: 9
Training loss: 2.91600090784548
Validation loss: 2.480286080672996

Epoch: 5| Step: 10
Training loss: 2.729858068193152
Validation loss: 2.4764773751869353

Epoch: 107| Step: 0
Training loss: 2.4479875162030718
Validation loss: 2.481408862585467

Epoch: 5| Step: 1
Training loss: 2.794734881934731
Validation loss: 2.491777059450167

Epoch: 5| Step: 2
Training loss: 2.1891242400454325
Validation loss: 2.499750029977396

Epoch: 5| Step: 3
Training loss: 2.367244908609252
Validation loss: 2.5003156862599614

Epoch: 5| Step: 4
Training loss: 2.9049428645964492
Validation loss: 2.5044516736830156

Epoch: 5| Step: 5
Training loss: 3.32714972735336
Validation loss: 2.5135704444778733

Epoch: 5| Step: 6
Training loss: 2.7149854005593186
Validation loss: 2.5145054173381

Epoch: 5| Step: 7
Training loss: 3.082402080085106
Validation loss: 2.5087884861687706

Epoch: 5| Step: 8
Training loss: 3.173760966837544
Validation loss: 2.4966794573280184

Epoch: 5| Step: 9
Training loss: 2.46590568772374
Validation loss: 2.4911187256093075

Epoch: 5| Step: 10
Training loss: 2.69528622821775
Validation loss: 2.4774659478534375

Epoch: 108| Step: 0
Training loss: 2.662299235480167
Validation loss: 2.473996843557488

Epoch: 5| Step: 1
Training loss: 2.6235509233339953
Validation loss: 2.473468186290718

Epoch: 5| Step: 2
Training loss: 2.730919447390788
Validation loss: 2.4606106667559566

Epoch: 5| Step: 3
Training loss: 2.3082687226582173
Validation loss: 2.4714010368128148

Epoch: 5| Step: 4
Training loss: 2.1947480151363776
Validation loss: 2.488806029418922

Epoch: 5| Step: 5
Training loss: 2.905416061362645
Validation loss: 2.4967589853313292

Epoch: 5| Step: 6
Training loss: 3.040076549971645
Validation loss: 2.490988170045491

Epoch: 5| Step: 7
Training loss: 2.779302794074205
Validation loss: 2.491683356058784

Epoch: 5| Step: 8
Training loss: 3.2081114126631527
Validation loss: 2.4703372895729276

Epoch: 5| Step: 9
Training loss: 2.997028309517499
Validation loss: 2.4737186782551013

Epoch: 5| Step: 10
Training loss: 2.6569809749325577
Validation loss: 2.4649285651813826

Epoch: 109| Step: 0
Training loss: 2.543733402732296
Validation loss: 2.4540777248558405

Epoch: 5| Step: 1
Training loss: 2.4731510384446724
Validation loss: 2.4557457886147036

Epoch: 5| Step: 2
Training loss: 3.0518767164336063
Validation loss: 2.4504463427101295

Epoch: 5| Step: 3
Training loss: 3.1036075028682912
Validation loss: 2.453583607529667

Epoch: 5| Step: 4
Training loss: 2.133222044585117
Validation loss: 2.466049630276283

Epoch: 5| Step: 5
Training loss: 2.881082320557604
Validation loss: 2.476881429096344

Epoch: 5| Step: 6
Training loss: 3.113653565165005
Validation loss: 2.4984456008629685

Epoch: 5| Step: 7
Training loss: 2.6541536024441825
Validation loss: 2.524151050632247

Epoch: 5| Step: 8
Training loss: 3.0557899924614165
Validation loss: 2.527480595857245

Epoch: 5| Step: 9
Training loss: 2.5923195076982073
Validation loss: 2.538755346861218

Epoch: 5| Step: 10
Training loss: 2.704831417140023
Validation loss: 2.5477541446674477

Epoch: 110| Step: 0
Training loss: 2.628151863314654
Validation loss: 2.5173865333964165

Epoch: 5| Step: 1
Training loss: 2.9845670468517405
Validation loss: 2.4909598287075894

Epoch: 5| Step: 2
Training loss: 2.926816464314715
Validation loss: 2.476164612231584

Epoch: 5| Step: 3
Training loss: 3.401183393640051
Validation loss: 2.476008732599494

Epoch: 5| Step: 4
Training loss: 2.0421606621003945
Validation loss: 2.46735575630993

Epoch: 5| Step: 5
Training loss: 2.5052420970098135
Validation loss: 2.4670114508083096

Epoch: 5| Step: 6
Training loss: 2.8718871804395194
Validation loss: 2.463647154675684

Epoch: 5| Step: 7
Training loss: 3.0264971724565837
Validation loss: 2.464138090361986

Epoch: 5| Step: 8
Training loss: 2.367834625926157
Validation loss: 2.472786502906311

Epoch: 5| Step: 9
Training loss: 2.4720134170686614
Validation loss: 2.473451526242862

Epoch: 5| Step: 10
Training loss: 2.8866834005997006
Validation loss: 2.4588827388632093

Epoch: 111| Step: 0
Training loss: 2.5387539250593774
Validation loss: 2.4815377857036127

Epoch: 5| Step: 1
Training loss: 2.585844747026607
Validation loss: 2.5109496948314427

Epoch: 5| Step: 2
Training loss: 2.932172286120091
Validation loss: 2.564600391097464

Epoch: 5| Step: 3
Training loss: 3.3973645149708336
Validation loss: 2.5924106524619703

Epoch: 5| Step: 4
Training loss: 2.976331807005164
Validation loss: 2.574796623444383

Epoch: 5| Step: 5
Training loss: 2.615321618719587
Validation loss: 2.536896478886277

Epoch: 5| Step: 6
Training loss: 2.8000422610772073
Validation loss: 2.4874074214882294

Epoch: 5| Step: 7
Training loss: 2.674578275147343
Validation loss: 2.4687013529144384

Epoch: 5| Step: 8
Training loss: 2.7178574774218984
Validation loss: 2.4501251685552408

Epoch: 5| Step: 9
Training loss: 2.472597046153887
Validation loss: 2.465120639748888

Epoch: 5| Step: 10
Training loss: 2.5981274170321744
Validation loss: 2.4770958676992145

Epoch: 112| Step: 0
Training loss: 3.0430919147290405
Validation loss: 2.4952027336318414

Epoch: 5| Step: 1
Training loss: 3.0925438581608566
Validation loss: 2.4921002610129435

Epoch: 5| Step: 2
Training loss: 2.7706916218326167
Validation loss: 2.479885178850995

Epoch: 5| Step: 3
Training loss: 2.786870271174407
Validation loss: 2.462093226561095

Epoch: 5| Step: 4
Training loss: 3.166003425475802
Validation loss: 2.4538387088298257

Epoch: 5| Step: 5
Training loss: 2.580775614967483
Validation loss: 2.45403847617534

Epoch: 5| Step: 6
Training loss: 1.92355446975013
Validation loss: 2.4618246697930837

Epoch: 5| Step: 7
Training loss: 2.3798375303447505
Validation loss: 2.4913097647283955

Epoch: 5| Step: 8
Training loss: 2.8021254884935796
Validation loss: 2.5122719473210604

Epoch: 5| Step: 9
Training loss: 3.1476368229148877
Validation loss: 2.517129609002227

Epoch: 5| Step: 10
Training loss: 2.6983890389937693
Validation loss: 2.508707111775071

Epoch: 113| Step: 0
Training loss: 2.7255488481666728
Validation loss: 2.5105489734180026

Epoch: 5| Step: 1
Training loss: 2.7447683682016897
Validation loss: 2.504781955915449

Epoch: 5| Step: 2
Training loss: 2.563117162305992
Validation loss: 2.505769015824534

Epoch: 5| Step: 3
Training loss: 2.439184340489092
Validation loss: 2.4988252761350265

Epoch: 5| Step: 4
Training loss: 3.1269043269927552
Validation loss: 2.488528125119853

Epoch: 5| Step: 5
Training loss: 2.140014338579004
Validation loss: 2.4885895634757156

Epoch: 5| Step: 6
Training loss: 2.452405204379673
Validation loss: 2.478537330638095

Epoch: 5| Step: 7
Training loss: 2.8294379627190076
Validation loss: 2.479856162714708

Epoch: 5| Step: 8
Training loss: 2.7218687212901176
Validation loss: 2.4618505036649965

Epoch: 5| Step: 9
Training loss: 3.036227357606416
Validation loss: 2.46457679423197

Epoch: 5| Step: 10
Training loss: 3.2758910968830595
Validation loss: 2.4601982213391596

Epoch: 114| Step: 0
Training loss: 3.0136100085293553
Validation loss: 2.4551992681893364

Epoch: 5| Step: 1
Training loss: 2.6188621515189467
Validation loss: 2.4571051307788445

Epoch: 5| Step: 2
Training loss: 2.664381528305442
Validation loss: 2.455249462922803

Epoch: 5| Step: 3
Training loss: 2.4341878640325945
Validation loss: 2.4544856259707912

Epoch: 5| Step: 4
Training loss: 3.002425008404258
Validation loss: 2.4672221441397344

Epoch: 5| Step: 5
Training loss: 2.4918727377026624
Validation loss: 2.4641926322138636

Epoch: 5| Step: 6
Training loss: 2.6350434130688103
Validation loss: 2.4673496572343954

Epoch: 5| Step: 7
Training loss: 2.996804442783368
Validation loss: 2.4729084823960488

Epoch: 5| Step: 8
Training loss: 2.473710593150163
Validation loss: 2.4581919626501456

Epoch: 5| Step: 9
Training loss: 2.8191925107481914
Validation loss: 2.452695166324433

Epoch: 5| Step: 10
Training loss: 2.975414465234919
Validation loss: 2.4540461011511137

Epoch: 115| Step: 0
Training loss: 2.727460390916978
Validation loss: 2.472394880596801

Epoch: 5| Step: 1
Training loss: 2.7387079404372265
Validation loss: 2.4717254371895114

Epoch: 5| Step: 2
Training loss: 2.40922511088487
Validation loss: 2.4699865411381197

Epoch: 5| Step: 3
Training loss: 2.517934177692769
Validation loss: 2.4767795523398295

Epoch: 5| Step: 4
Training loss: 3.022938137560957
Validation loss: 2.478516469025505

Epoch: 5| Step: 5
Training loss: 2.311409357992401
Validation loss: 2.491717993028977

Epoch: 5| Step: 6
Training loss: 2.9197703242443387
Validation loss: 2.48199912189192

Epoch: 5| Step: 7
Training loss: 2.9093173667698027
Validation loss: 2.4727762116694034

Epoch: 5| Step: 8
Training loss: 2.8618833452358396
Validation loss: 2.476733593762755

Epoch: 5| Step: 9
Training loss: 2.5335467244506003
Validation loss: 2.471823838314589

Epoch: 5| Step: 10
Training loss: 3.0326841442180075
Validation loss: 2.4651413963346713

Epoch: 116| Step: 0
Training loss: 2.489758590424487
Validation loss: 2.4545403326968653

Epoch: 5| Step: 1
Training loss: 2.6878110129018857
Validation loss: 2.4664529446612136

Epoch: 5| Step: 2
Training loss: 2.6848986255965466
Validation loss: 2.4618783319442583

Epoch: 5| Step: 3
Training loss: 2.823802194438022
Validation loss: 2.4651434239896695

Epoch: 5| Step: 4
Training loss: 2.205045039264075
Validation loss: 2.4626479734098203

Epoch: 5| Step: 5
Training loss: 3.266500109364385
Validation loss: 2.4745214748575473

Epoch: 5| Step: 6
Training loss: 2.977885115129718
Validation loss: 2.474354224315571

Epoch: 5| Step: 7
Training loss: 3.274733694183737
Validation loss: 2.4559020555935684

Epoch: 5| Step: 8
Training loss: 2.5418211988988584
Validation loss: 2.4611191455469767

Epoch: 5| Step: 9
Training loss: 2.619348436683743
Validation loss: 2.455992287037779

Epoch: 5| Step: 10
Training loss: 2.097109703879943
Validation loss: 2.439677636944416

Epoch: 117| Step: 0
Training loss: 3.059987497241838
Validation loss: 2.451737050350824

Epoch: 5| Step: 1
Training loss: 2.1224808065492424
Validation loss: 2.460298516779283

Epoch: 5| Step: 2
Training loss: 2.3351369653430654
Validation loss: 2.452885404096558

Epoch: 5| Step: 3
Training loss: 2.636536452031457
Validation loss: 2.459162867435809

Epoch: 5| Step: 4
Training loss: 2.9700613237722506
Validation loss: 2.4539263594484044

Epoch: 5| Step: 5
Training loss: 2.8752023376913867
Validation loss: 2.475397015538035

Epoch: 5| Step: 6
Training loss: 2.7125130508038575
Validation loss: 2.474976847409713

Epoch: 5| Step: 7
Training loss: 2.968914147908519
Validation loss: 2.4619292209502524

Epoch: 5| Step: 8
Training loss: 2.73652311688136
Validation loss: 2.48959539713189

Epoch: 5| Step: 9
Training loss: 2.7671595050207727
Validation loss: 2.4976158510103863

Epoch: 5| Step: 10
Training loss: 2.5728551468592187
Validation loss: 2.5135300935710734

Epoch: 118| Step: 0
Training loss: 3.0679593374847656
Validation loss: 2.497589571566873

Epoch: 5| Step: 1
Training loss: 2.594639912724477
Validation loss: 2.492195490702357

Epoch: 5| Step: 2
Training loss: 2.5633043096889265
Validation loss: 2.4609619483182588

Epoch: 5| Step: 3
Training loss: 3.4644003049974756
Validation loss: 2.459194778740004

Epoch: 5| Step: 4
Training loss: 2.4189682775769477
Validation loss: 2.4560348467862427

Epoch: 5| Step: 5
Training loss: 1.8032535950077364
Validation loss: 2.4604806950372606

Epoch: 5| Step: 6
Training loss: 2.7897191917454207
Validation loss: 2.4596686104344907

Epoch: 5| Step: 7
Training loss: 2.6154712116784333
Validation loss: 2.4657769609781095

Epoch: 5| Step: 8
Training loss: 2.938191758537302
Validation loss: 2.4811696721128316

Epoch: 5| Step: 9
Training loss: 2.7733744009657495
Validation loss: 2.4902145873314474

Epoch: 5| Step: 10
Training loss: 2.7171114664698472
Validation loss: 2.4834407257783924

Epoch: 119| Step: 0
Training loss: 3.0183412642421263
Validation loss: 2.5023193286058807

Epoch: 5| Step: 1
Training loss: 2.71153520926256
Validation loss: 2.5121398571752795

Epoch: 5| Step: 2
Training loss: 3.2893931750433807
Validation loss: 2.521734239572551

Epoch: 5| Step: 3
Training loss: 2.8372818043709636
Validation loss: 2.522810922409457

Epoch: 5| Step: 4
Training loss: 2.5963386578544663
Validation loss: 2.5330303275929316

Epoch: 5| Step: 5
Training loss: 2.47862999714565
Validation loss: 2.5261960536274928

Epoch: 5| Step: 6
Training loss: 2.6789079872497283
Validation loss: 2.4656311839847413

Epoch: 5| Step: 7
Training loss: 2.7167030608970952
Validation loss: 2.4399228282692538

Epoch: 5| Step: 8
Training loss: 2.7061106339793612
Validation loss: 2.4469256567945714

Epoch: 5| Step: 9
Training loss: 2.4789725048637803
Validation loss: 2.479536743614143

Epoch: 5| Step: 10
Training loss: 2.7630244382977973
Validation loss: 2.444632233152425

Epoch: 120| Step: 0
Training loss: 2.6866429758881094
Validation loss: 2.436550164615057

Epoch: 5| Step: 1
Training loss: 2.497333821523564
Validation loss: 2.442060952622031

Epoch: 5| Step: 2
Training loss: 2.370227837857984
Validation loss: 2.4385136615084417

Epoch: 5| Step: 3
Training loss: 2.3623788671370543
Validation loss: 2.462528341823695

Epoch: 5| Step: 4
Training loss: 3.246712856264427
Validation loss: 2.5038307537805475

Epoch: 5| Step: 5
Training loss: 2.512237922322831
Validation loss: 2.484519505930423

Epoch: 5| Step: 6
Training loss: 2.8246126230036817
Validation loss: 2.4659475524101873

Epoch: 5| Step: 7
Training loss: 2.711622256114811
Validation loss: 2.452407515664433

Epoch: 5| Step: 8
Training loss: 3.025047327097009
Validation loss: 2.4526118534799286

Epoch: 5| Step: 9
Training loss: 2.8098432920750738
Validation loss: 2.4459625578398625

Epoch: 5| Step: 10
Training loss: 2.885154868321071
Validation loss: 2.4310373877774

Epoch: 121| Step: 0
Training loss: 2.5561857817028546
Validation loss: 2.444422703898316

Epoch: 5| Step: 1
Training loss: 2.550929580745347
Validation loss: 2.4387466780635805

Epoch: 5| Step: 2
Training loss: 2.605453102259281
Validation loss: 2.4555512027791297

Epoch: 5| Step: 3
Training loss: 3.2386263857844453
Validation loss: 2.468518982713639

Epoch: 5| Step: 4
Training loss: 2.6476526588467366
Validation loss: 2.4630480041025966

Epoch: 5| Step: 5
Training loss: 2.7906978311464723
Validation loss: 2.463796386024031

Epoch: 5| Step: 6
Training loss: 2.747637167119456
Validation loss: 2.4650820598435774

Epoch: 5| Step: 7
Training loss: 3.0071957438892185
Validation loss: 2.4540956247868984

Epoch: 5| Step: 8
Training loss: 2.5323473588559176
Validation loss: 2.4532286553696925

Epoch: 5| Step: 9
Training loss: 2.4868765658373433
Validation loss: 2.442677596564602

Epoch: 5| Step: 10
Training loss: 2.7963086625734035
Validation loss: 2.4256951463429717

Epoch: 122| Step: 0
Training loss: 2.6805918421510095
Validation loss: 2.43366712718549

Epoch: 5| Step: 1
Training loss: 2.9868668144578474
Validation loss: 2.43644989801642

Epoch: 5| Step: 2
Training loss: 2.965060219884909
Validation loss: 2.4377079662775625

Epoch: 5| Step: 3
Training loss: 2.3007124419358704
Validation loss: 2.435435664912687

Epoch: 5| Step: 4
Training loss: 2.4913390817137806
Validation loss: 2.4399886814062017

Epoch: 5| Step: 5
Training loss: 2.905337446773862
Validation loss: 2.4413605086440833

Epoch: 5| Step: 6
Training loss: 2.7374823652422324
Validation loss: 2.453527746299875

Epoch: 5| Step: 7
Training loss: 2.521482483902273
Validation loss: 2.468450202771132

Epoch: 5| Step: 8
Training loss: 2.3572323398201633
Validation loss: 2.46511814175028

Epoch: 5| Step: 9
Training loss: 3.0385506402372386
Validation loss: 2.4618919707946345

Epoch: 5| Step: 10
Training loss: 2.817745572805967
Validation loss: 2.445613775034578

Epoch: 123| Step: 0
Training loss: 2.1667939173181545
Validation loss: 2.4349716974012456

Epoch: 5| Step: 1
Training loss: 2.6090893617636897
Validation loss: 2.4426952195274145

Epoch: 5| Step: 2
Training loss: 2.854045967464332
Validation loss: 2.4396493647047097

Epoch: 5| Step: 3
Training loss: 3.030668065163787
Validation loss: 2.440813439242961

Epoch: 5| Step: 4
Training loss: 2.8254822243485913
Validation loss: 2.434878965517563

Epoch: 5| Step: 5
Training loss: 2.562504465983151
Validation loss: 2.445329192405114

Epoch: 5| Step: 6
Training loss: 3.164059636621004
Validation loss: 2.4627180927486094

Epoch: 5| Step: 7
Training loss: 2.8799228814184383
Validation loss: 2.4746633799388853

Epoch: 5| Step: 8
Training loss: 2.3664094256798185
Validation loss: 2.490519955285354

Epoch: 5| Step: 9
Training loss: 2.3647311216262814
Validation loss: 2.496136211423297

Epoch: 5| Step: 10
Training loss: 2.9548709289969417
Validation loss: 2.4980569261508103

Epoch: 124| Step: 0
Training loss: 2.6047969106339544
Validation loss: 2.4898899033948436

Epoch: 5| Step: 1
Training loss: 2.5723434818798077
Validation loss: 2.485831066876381

Epoch: 5| Step: 2
Training loss: 2.493425976346164
Validation loss: 2.4644762167584258

Epoch: 5| Step: 3
Training loss: 2.7180501979939033
Validation loss: 2.4550422338666498

Epoch: 5| Step: 4
Training loss: 3.1488450309584466
Validation loss: 2.447686965906919

Epoch: 5| Step: 5
Training loss: 3.1284779840139456
Validation loss: 2.4394888524552916

Epoch: 5| Step: 6
Training loss: 3.1482469676180442
Validation loss: 2.440666272056794

Epoch: 5| Step: 7
Training loss: 1.9554353400990971
Validation loss: 2.4407487416865754

Epoch: 5| Step: 8
Training loss: 2.9579215681034814
Validation loss: 2.4519242038172666

Epoch: 5| Step: 9
Training loss: 2.4348578193403476
Validation loss: 2.439943145679295

Epoch: 5| Step: 10
Training loss: 2.220076902964878
Validation loss: 2.4406885254240485

Epoch: 125| Step: 0
Training loss: 2.9098005038959536
Validation loss: 2.439963739251115

Epoch: 5| Step: 1
Training loss: 2.8380320986974943
Validation loss: 2.4441770462181536

Epoch: 5| Step: 2
Training loss: 2.5617016735013807
Validation loss: 2.449225609654891

Epoch: 5| Step: 3
Training loss: 2.884785625618293
Validation loss: 2.459197035689912

Epoch: 5| Step: 4
Training loss: 2.4763853569336005
Validation loss: 2.4750478179511943

Epoch: 5| Step: 5
Training loss: 2.0184613756703995
Validation loss: 2.475418869691348

Epoch: 5| Step: 6
Training loss: 2.51512131476124
Validation loss: 2.466023867423293

Epoch: 5| Step: 7
Training loss: 2.6284542063525813
Validation loss: 2.448451597212151

Epoch: 5| Step: 8
Training loss: 3.188847873909863
Validation loss: 2.4335577368950037

Epoch: 5| Step: 9
Training loss: 3.269218110797938
Validation loss: 2.43393592586461

Epoch: 5| Step: 10
Training loss: 2.148422962486327
Validation loss: 2.4299293294579516

Epoch: 126| Step: 0
Training loss: 2.670322167751251
Validation loss: 2.4405582059968265

Epoch: 5| Step: 1
Training loss: 1.9903102631929932
Validation loss: 2.4452808164071786

Epoch: 5| Step: 2
Training loss: 2.5393804263095214
Validation loss: 2.4458870266396793

Epoch: 5| Step: 3
Training loss: 2.2337985061988888
Validation loss: 2.464154243253013

Epoch: 5| Step: 4
Training loss: 2.6258306551424986
Validation loss: 2.4586953205489146

Epoch: 5| Step: 5
Training loss: 2.1027310324069544
Validation loss: 2.4438608324074065

Epoch: 5| Step: 6
Training loss: 2.665249825625284
Validation loss: 2.451016661995116

Epoch: 5| Step: 7
Training loss: 2.7752792905184984
Validation loss: 2.4581110752831483

Epoch: 5| Step: 8
Training loss: 3.2922837528013833
Validation loss: 2.451721799606477

Epoch: 5| Step: 9
Training loss: 3.0413845575922562
Validation loss: 2.4521655261237374

Epoch: 5| Step: 10
Training loss: 3.319660436891063
Validation loss: 2.4544871185203156

Epoch: 127| Step: 0
Training loss: 2.744786088178975
Validation loss: 2.455888007161029

Epoch: 5| Step: 1
Training loss: 2.34929682174063
Validation loss: 2.4679774109617076

Epoch: 5| Step: 2
Training loss: 2.649144621216647
Validation loss: 2.485481811774869

Epoch: 5| Step: 3
Training loss: 2.538093546334545
Validation loss: 2.4666770860700815

Epoch: 5| Step: 4
Training loss: 2.2583927873994227
Validation loss: 2.47183260114024

Epoch: 5| Step: 5
Training loss: 2.7481759697822614
Validation loss: 2.4364257761362413

Epoch: 5| Step: 6
Training loss: 3.0347798039152614
Validation loss: 2.4286715828832235

Epoch: 5| Step: 7
Training loss: 2.216078641046938
Validation loss: 2.422836315103762

Epoch: 5| Step: 8
Training loss: 2.957181374935453
Validation loss: 2.42821412298729

Epoch: 5| Step: 9
Training loss: 3.117327158770335
Validation loss: 2.4213084642921627

Epoch: 5| Step: 10
Training loss: 2.790155191378049
Validation loss: 2.4336100181918487

Epoch: 128| Step: 0
Training loss: 2.6190534174636135
Validation loss: 2.4329774000641096

Epoch: 5| Step: 1
Training loss: 2.971663801869716
Validation loss: 2.4499144149306953

Epoch: 5| Step: 2
Training loss: 2.81907140417694
Validation loss: 2.456040802774916

Epoch: 5| Step: 3
Training loss: 2.4856640812230877
Validation loss: 2.48266185353367

Epoch: 5| Step: 4
Training loss: 2.3386971493513813
Validation loss: 2.50086756029917

Epoch: 5| Step: 5
Training loss: 2.8919654831046566
Validation loss: 2.5255491797644196

Epoch: 5| Step: 6
Training loss: 2.5619930603266883
Validation loss: 2.5422325318009813

Epoch: 5| Step: 7
Training loss: 2.87452395271146
Validation loss: 2.529995939694192

Epoch: 5| Step: 8
Training loss: 2.5257006437947926
Validation loss: 2.519522640858726

Epoch: 5| Step: 9
Training loss: 2.5458877615929785
Validation loss: 2.4764905552733114

Epoch: 5| Step: 10
Training loss: 3.15943853387991
Validation loss: 2.463776515046493

Epoch: 129| Step: 0
Training loss: 3.016703042360745
Validation loss: 2.4818363810948885

Epoch: 5| Step: 1
Training loss: 2.7630041603115045
Validation loss: 2.4945712818877324

Epoch: 5| Step: 2
Training loss: 2.8645293259586895
Validation loss: 2.5010438770112335

Epoch: 5| Step: 3
Training loss: 3.231545210141803
Validation loss: 2.5016617835523536

Epoch: 5| Step: 4
Training loss: 2.1886312556884646
Validation loss: 2.469349838247701

Epoch: 5| Step: 5
Training loss: 2.465849705889167
Validation loss: 2.4667590981689327

Epoch: 5| Step: 6
Training loss: 3.0463286081095102
Validation loss: 2.4998257771153387

Epoch: 5| Step: 7
Training loss: 2.4635164825464093
Validation loss: 2.5471334511850925

Epoch: 5| Step: 8
Training loss: 2.274344142233807
Validation loss: 2.574108624037295

Epoch: 5| Step: 9
Training loss: 3.2848354550380154
Validation loss: 2.593294327273819

Epoch: 5| Step: 10
Training loss: 2.758423821231803
Validation loss: 2.4999161337044518

Epoch: 130| Step: 0
Training loss: 2.4166037014179698
Validation loss: 2.440931388630796

Epoch: 5| Step: 1
Training loss: 2.5724610969115336
Validation loss: 2.436557058094624

Epoch: 5| Step: 2
Training loss: 2.9303833808962954
Validation loss: 2.440188279858536

Epoch: 5| Step: 3
Training loss: 3.1762843560496656
Validation loss: 2.453066440915586

Epoch: 5| Step: 4
Training loss: 2.4042700015316276
Validation loss: 2.4598798248282936

Epoch: 5| Step: 5
Training loss: 3.1873913914745846
Validation loss: 2.4685536653479714

Epoch: 5| Step: 6
Training loss: 2.7909836763938576
Validation loss: 2.4546377025976707

Epoch: 5| Step: 7
Training loss: 2.600045159754667
Validation loss: 2.430830198632545

Epoch: 5| Step: 8
Training loss: 2.4136320551340877
Validation loss: 2.4330463598692025

Epoch: 5| Step: 9
Training loss: 2.6916688921026553
Validation loss: 2.4486735911940865

Epoch: 5| Step: 10
Training loss: 2.776065580588299
Validation loss: 2.512251314816321

Epoch: 131| Step: 0
Training loss: 2.507766295390654
Validation loss: 2.5744901278748933

Epoch: 5| Step: 1
Training loss: 2.8981627465168085
Validation loss: 2.5913980353954487

Epoch: 5| Step: 2
Training loss: 2.4725004270609148
Validation loss: 2.6008506174638844

Epoch: 5| Step: 3
Training loss: 2.6614123276369175
Validation loss: 2.5790477146824813

Epoch: 5| Step: 4
Training loss: 3.0104767332497335
Validation loss: 2.522092828140047

Epoch: 5| Step: 5
Training loss: 3.0010663362650094
Validation loss: 2.4758212925592167

Epoch: 5| Step: 6
Training loss: 2.677175874013583
Validation loss: 2.4370367863193767

Epoch: 5| Step: 7
Training loss: 2.277544748848596
Validation loss: 2.431258744294915

Epoch: 5| Step: 8
Training loss: 2.352320146648126
Validation loss: 2.427509909590237

Epoch: 5| Step: 9
Training loss: 2.8865175499698905
Validation loss: 2.439691962611726

Epoch: 5| Step: 10
Training loss: 2.9868559586053114
Validation loss: 2.4429443092865206

Epoch: 132| Step: 0
Training loss: 2.731894976059161
Validation loss: 2.4331155358244008

Epoch: 5| Step: 1
Training loss: 2.6154143290752105
Validation loss: 2.4344202647294333

Epoch: 5| Step: 2
Training loss: 2.891854679324002
Validation loss: 2.43829039975738

Epoch: 5| Step: 3
Training loss: 2.7273582893012454
Validation loss: 2.431793771846516

Epoch: 5| Step: 4
Training loss: 2.661525200428711
Validation loss: 2.444053432959662

Epoch: 5| Step: 5
Training loss: 2.6680888516159253
Validation loss: 2.449676989976336

Epoch: 5| Step: 6
Training loss: 2.294814035032752
Validation loss: 2.4518949717993963

Epoch: 5| Step: 7
Training loss: 3.060104678987682
Validation loss: 2.476511343890918

Epoch: 5| Step: 8
Training loss: 2.411598207002531
Validation loss: 2.4960670863260037

Epoch: 5| Step: 9
Training loss: 2.5618012568852904
Validation loss: 2.5045398765813687

Epoch: 5| Step: 10
Training loss: 2.5407990605974744
Validation loss: 2.5014459714725494

Epoch: 133| Step: 0
Training loss: 2.3410257401320247
Validation loss: 2.4998523832649804

Epoch: 5| Step: 1
Training loss: 3.0126942045682727
Validation loss: 2.485435601526514

Epoch: 5| Step: 2
Training loss: 2.768429987822185
Validation loss: 2.517817618948604

Epoch: 5| Step: 3
Training loss: 2.752922066214176
Validation loss: 2.5180921675837107

Epoch: 5| Step: 4
Training loss: 2.706718922221806
Validation loss: 2.5118081143551803

Epoch: 5| Step: 5
Training loss: 2.690255637518977
Validation loss: 2.498445718863803

Epoch: 5| Step: 6
Training loss: 2.192035115628998
Validation loss: 2.483596194691668

Epoch: 5| Step: 7
Training loss: 2.7058447237032515
Validation loss: 2.461902262232173

Epoch: 5| Step: 8
Training loss: 2.3498754184247086
Validation loss: 2.463652010052557

Epoch: 5| Step: 9
Training loss: 2.844499258748369
Validation loss: 2.456592671115119

Epoch: 5| Step: 10
Training loss: 2.6590324638482374
Validation loss: 2.4511717264845143

Epoch: 134| Step: 0
Training loss: 2.732459830837836
Validation loss: 2.4342901815849496

Epoch: 5| Step: 1
Training loss: 2.6568696140835053
Validation loss: 2.43751801115228

Epoch: 5| Step: 2
Training loss: 2.2230780926920395
Validation loss: 2.444931898599875

Epoch: 5| Step: 3
Training loss: 2.670641341031086
Validation loss: 2.4535489718884933

Epoch: 5| Step: 4
Training loss: 2.6051246610309686
Validation loss: 2.456563238970825

Epoch: 5| Step: 5
Training loss: 2.453696409117321
Validation loss: 2.4519184594887395

Epoch: 5| Step: 6
Training loss: 2.842642599939143
Validation loss: 2.4646864210730195

Epoch: 5| Step: 7
Training loss: 2.5252848851606235
Validation loss: 2.479001223168617

Epoch: 5| Step: 8
Training loss: 2.8250072006538915
Validation loss: 2.4947980031647563

Epoch: 5| Step: 9
Training loss: 2.7620638749058752
Validation loss: 2.5151284905599667

Epoch: 5| Step: 10
Training loss: 2.8369194411523884
Validation loss: 2.4988179878584877

Epoch: 135| Step: 0
Training loss: 2.693950895177687
Validation loss: 2.4868007752917993

Epoch: 5| Step: 1
Training loss: 2.6797633924942326
Validation loss: 2.476271849103414

Epoch: 5| Step: 2
Training loss: 2.418510018994153
Validation loss: 2.488018074322539

Epoch: 5| Step: 3
Training loss: 3.2528289806818123
Validation loss: 2.495954354410802

Epoch: 5| Step: 4
Training loss: 2.3292713799137705
Validation loss: 2.4926875186288

Epoch: 5| Step: 5
Training loss: 2.339666140124978
Validation loss: 2.5014975892142575

Epoch: 5| Step: 6
Training loss: 3.203305420795289
Validation loss: 2.504749759515445

Epoch: 5| Step: 7
Training loss: 2.098403769056547
Validation loss: 2.4935358482345604

Epoch: 5| Step: 8
Training loss: 2.110260615050624
Validation loss: 2.481120708512108

Epoch: 5| Step: 9
Training loss: 2.8637098795604263
Validation loss: 2.4897851054282856

Epoch: 5| Step: 10
Training loss: 2.661631708538616
Validation loss: 2.492443818736536

Epoch: 136| Step: 0
Training loss: 3.0362009732217135
Validation loss: 2.501500091877993

Epoch: 5| Step: 1
Training loss: 2.4128430690837295
Validation loss: 2.476750124084961

Epoch: 5| Step: 2
Training loss: 2.3558585127555522
Validation loss: 2.4599929155694085

Epoch: 5| Step: 3
Training loss: 2.8584848487963583
Validation loss: 2.439161998775241

Epoch: 5| Step: 4
Training loss: 2.7324863559839465
Validation loss: 2.43228269849721

Epoch: 5| Step: 5
Training loss: 2.641763565821403
Validation loss: 2.434990047316493

Epoch: 5| Step: 6
Training loss: 2.6154336547137786
Validation loss: 2.468965991618365

Epoch: 5| Step: 7
Training loss: 2.7118238599623203
Validation loss: 2.457159860042165

Epoch: 5| Step: 8
Training loss: 2.5580720558904204
Validation loss: 2.4663820069282516

Epoch: 5| Step: 9
Training loss: 2.482915005449419
Validation loss: 2.4712596726429887

Epoch: 5| Step: 10
Training loss: 2.5782973723152827
Validation loss: 2.4588651896924083

Epoch: 137| Step: 0
Training loss: 2.873877264642066
Validation loss: 2.4647778661391033

Epoch: 5| Step: 1
Training loss: 2.09343181868433
Validation loss: 2.4733930783753295

Epoch: 5| Step: 2
Training loss: 2.8924973481082876
Validation loss: 2.4708152684909845

Epoch: 5| Step: 3
Training loss: 2.430221646094345
Validation loss: 2.4762249451905736

Epoch: 5| Step: 4
Training loss: 3.291366821023921
Validation loss: 2.4473919713053447

Epoch: 5| Step: 5
Training loss: 2.54353291103037
Validation loss: 2.445350840886283

Epoch: 5| Step: 6
Training loss: 2.0067855643008863
Validation loss: 2.4366673408573467

Epoch: 5| Step: 7
Training loss: 2.887787617152159
Validation loss: 2.4314899161815884

Epoch: 5| Step: 8
Training loss: 2.542537623364332
Validation loss: 2.4359982736494086

Epoch: 5| Step: 9
Training loss: 2.426508452040146
Validation loss: 2.4388028605118865

Epoch: 5| Step: 10
Training loss: 2.716215684430849
Validation loss: 2.440285805352854

Epoch: 138| Step: 0
Training loss: 2.618881542753155
Validation loss: 2.454859672899832

Epoch: 5| Step: 1
Training loss: 2.548778267442206
Validation loss: 2.4626061879635888

Epoch: 5| Step: 2
Training loss: 2.5390138592095752
Validation loss: 2.4615857831905092

Epoch: 5| Step: 3
Training loss: 2.8133620742336176
Validation loss: 2.467680715488794

Epoch: 5| Step: 4
Training loss: 2.5070427875009624
Validation loss: 2.4712581528776933

Epoch: 5| Step: 5
Training loss: 2.136882433994123
Validation loss: 2.470407717832272

Epoch: 5| Step: 6
Training loss: 2.6090299640892636
Validation loss: 2.4656442962402556

Epoch: 5| Step: 7
Training loss: 2.884510728942734
Validation loss: 2.4779813302055427

Epoch: 5| Step: 8
Training loss: 2.444501943586314
Validation loss: 2.4586802287040124

Epoch: 5| Step: 9
Training loss: 2.886211097689711
Validation loss: 2.4644421144157587

Epoch: 5| Step: 10
Training loss: 2.518085295477072
Validation loss: 2.473717454842534

Epoch: 139| Step: 0
Training loss: 3.016844191693221
Validation loss: 2.4920692864568816

Epoch: 5| Step: 1
Training loss: 3.026325906260884
Validation loss: 2.5095293283259377

Epoch: 5| Step: 2
Training loss: 2.2891362409464096
Validation loss: 2.488578529428107

Epoch: 5| Step: 3
Training loss: 2.7014078849466716
Validation loss: 2.483187144295094

Epoch: 5| Step: 4
Training loss: 2.707430283061852
Validation loss: 2.47318030842905

Epoch: 5| Step: 5
Training loss: 2.6733642354052773
Validation loss: 2.448172532121035

Epoch: 5| Step: 6
Training loss: 1.9398693855794829
Validation loss: 2.455865265190173

Epoch: 5| Step: 7
Training loss: 2.5474308086129462
Validation loss: 2.4617626946786615

Epoch: 5| Step: 8
Training loss: 2.5509300480623573
Validation loss: 2.4576734589166254

Epoch: 5| Step: 9
Training loss: 2.6822629069048793
Validation loss: 2.4537207551030358

Epoch: 5| Step: 10
Training loss: 2.3198547939372443
Validation loss: 2.473087353755988

Epoch: 140| Step: 0
Training loss: 2.0211130584396106
Validation loss: 2.495248674642639

Epoch: 5| Step: 1
Training loss: 2.7081952475534052
Validation loss: 2.501639676494423

Epoch: 5| Step: 2
Training loss: 2.755873044072674
Validation loss: 2.5388846406571774

Epoch: 5| Step: 3
Training loss: 2.953527513956117
Validation loss: 2.6008809746643258

Epoch: 5| Step: 4
Training loss: 2.7594796563732786
Validation loss: 2.6497044561594967

Epoch: 5| Step: 5
Training loss: 2.2887517828858877
Validation loss: 2.583526528352618

Epoch: 5| Step: 6
Training loss: 2.6231735778338803
Validation loss: 2.5099439799318657

Epoch: 5| Step: 7
Training loss: 2.678276380001844
Validation loss: 2.4525917904929746

Epoch: 5| Step: 8
Training loss: 2.6020204066620596
Validation loss: 2.446533744217099

Epoch: 5| Step: 9
Training loss: 2.6828432768987605
Validation loss: 2.458015322951317

Epoch: 5| Step: 10
Training loss: 2.5392026891887634
Validation loss: 2.4714282923190085

Epoch: 141| Step: 0
Training loss: 3.072313273182241
Validation loss: 2.4781386644087307

Epoch: 5| Step: 1
Training loss: 2.562606251072269
Validation loss: 2.4710341997986704

Epoch: 5| Step: 2
Training loss: 2.670063765689483
Validation loss: 2.462394747252702

Epoch: 5| Step: 3
Training loss: 2.7925155165197673
Validation loss: 2.4759606174469515

Epoch: 5| Step: 4
Training loss: 2.3360155787862964
Validation loss: 2.4824516532319345

Epoch: 5| Step: 5
Training loss: 2.8996105853426006
Validation loss: 2.4980501816011462

Epoch: 5| Step: 6
Training loss: 2.3050778850380107
Validation loss: 2.4996553757744295

Epoch: 5| Step: 7
Training loss: 2.3148395972161535
Validation loss: 2.5218925332231232

Epoch: 5| Step: 8
Training loss: 2.043586477101493
Validation loss: 2.5389759952017346

Epoch: 5| Step: 9
Training loss: 2.5866206900289215
Validation loss: 2.5611791160172017

Epoch: 5| Step: 10
Training loss: 2.675011561716353
Validation loss: 2.508274916287263

Epoch: 142| Step: 0
Training loss: 2.6847898435839306
Validation loss: 2.494681226651169

Epoch: 5| Step: 1
Training loss: 2.3099530602512175
Validation loss: 2.4746502616021955

Epoch: 5| Step: 2
Training loss: 2.772767321784873
Validation loss: 2.464847086582123

Epoch: 5| Step: 3
Training loss: 2.534510455292272
Validation loss: 2.443255362832137

Epoch: 5| Step: 4
Training loss: 2.3245827782477493
Validation loss: 2.4451791705399533

Epoch: 5| Step: 5
Training loss: 2.7414250631657113
Validation loss: 2.4542821440153983

Epoch: 5| Step: 6
Training loss: 2.198501605500257
Validation loss: 2.4537376525503714

Epoch: 5| Step: 7
Training loss: 2.2923302354427895
Validation loss: 2.465775432635132

Epoch: 5| Step: 8
Training loss: 2.668533466497358
Validation loss: 2.4848656165084004

Epoch: 5| Step: 9
Training loss: 2.5841839425662667
Validation loss: 2.48424275415762

Epoch: 5| Step: 10
Training loss: 2.7631291048562607
Validation loss: 2.4979303078420627

Epoch: 143| Step: 0
Training loss: 2.7068196884208153
Validation loss: 2.506111398916694

Epoch: 5| Step: 1
Training loss: 2.4458955794758417
Validation loss: 2.517749816131099

Epoch: 5| Step: 2
Training loss: 2.2732025759205614
Validation loss: 2.532202423595559

Epoch: 5| Step: 3
Training loss: 2.5801513107050162
Validation loss: 2.562987329507639

Epoch: 5| Step: 4
Training loss: 2.6919531190482884
Validation loss: 2.535347484658896

Epoch: 5| Step: 5
Training loss: 2.782129555829038
Validation loss: 2.5102904219131434

Epoch: 5| Step: 6
Training loss: 2.731372514504069
Validation loss: 2.4795100373374974

Epoch: 5| Step: 7
Training loss: 2.207447762135855
Validation loss: 2.4694122904825115

Epoch: 5| Step: 8
Training loss: 2.466932279445143
Validation loss: 2.4694953510855804

Epoch: 5| Step: 9
Training loss: 2.31341617065804
Validation loss: 2.4716624034412544

Epoch: 5| Step: 10
Training loss: 2.6463671668867716
Validation loss: 2.471354448132241

Epoch: 144| Step: 0
Training loss: 2.319650472093394
Validation loss: 2.5128636196173058

Epoch: 5| Step: 1
Training loss: 3.0282193794147876
Validation loss: 2.518869279834939

Epoch: 5| Step: 2
Training loss: 2.7536804539525765
Validation loss: 2.5111692795901206

Epoch: 5| Step: 3
Training loss: 2.780652614258322
Validation loss: 2.4908243841933935

Epoch: 5| Step: 4
Training loss: 2.4640889651970284
Validation loss: 2.5090682426277398

Epoch: 5| Step: 5
Training loss: 2.1026603922406624
Validation loss: 2.53800833780183

Epoch: 5| Step: 6
Training loss: 2.81276828757822
Validation loss: 2.5681388763760484

Epoch: 5| Step: 7
Training loss: 2.4846043510855216
Validation loss: 2.5620659801530197

Epoch: 5| Step: 8
Training loss: 2.5073083864063186
Validation loss: 2.522191623367637

Epoch: 5| Step: 9
Training loss: 2.3640654972962554
Validation loss: 2.4769616217364416

Epoch: 5| Step: 10
Training loss: 2.367967533726696
Validation loss: 2.4726782279084443

Epoch: 145| Step: 0
Training loss: 2.7568841944169113
Validation loss: 2.4582497645280514

Epoch: 5| Step: 1
Training loss: 2.7290365367664733
Validation loss: 2.433353478380201

Epoch: 5| Step: 2
Training loss: 2.4182397940081257
Validation loss: 2.42507914845419

Epoch: 5| Step: 3
Training loss: 2.617237329720365
Validation loss: 2.4335308831561298

Epoch: 5| Step: 4
Training loss: 2.5261826833054597
Validation loss: 2.4321554007495507

Epoch: 5| Step: 5
Training loss: 2.3772457948800545
Validation loss: 2.444716539400491

Epoch: 5| Step: 6
Training loss: 2.3542825675948618
Validation loss: 2.4661625519169443

Epoch: 5| Step: 7
Training loss: 2.5254288601912673
Validation loss: 2.489259991728356

Epoch: 5| Step: 8
Training loss: 2.542178639195433
Validation loss: 2.4960681144248724

Epoch: 5| Step: 9
Training loss: 2.871209839011463
Validation loss: 2.5194109391370914

Epoch: 5| Step: 10
Training loss: 1.9806572638183286
Validation loss: 2.4833636277140294

Epoch: 146| Step: 0
Training loss: 2.237133004550156
Validation loss: 2.472544335684129

Epoch: 5| Step: 1
Training loss: 2.554598652172517
Validation loss: 2.4664897777396875

Epoch: 5| Step: 2
Training loss: 2.4176970839221594
Validation loss: 2.4843378820759634

Epoch: 5| Step: 3
Training loss: 2.6391996791819747
Validation loss: 2.4840219021929815

Epoch: 5| Step: 4
Training loss: 2.5397457201276064
Validation loss: 2.4745705296675933

Epoch: 5| Step: 5
Training loss: 2.663281457687822
Validation loss: 2.4704747196374623

Epoch: 5| Step: 6
Training loss: 2.5401067376425233
Validation loss: 2.469292747824132

Epoch: 5| Step: 7
Training loss: 2.6577933820410293
Validation loss: 2.467654543197217

Epoch: 5| Step: 8
Training loss: 1.9864677147592924
Validation loss: 2.4459558404862625

Epoch: 5| Step: 9
Training loss: 2.6262420259088657
Validation loss: 2.4518943381807285

Epoch: 5| Step: 10
Training loss: 2.3363193978033583
Validation loss: 2.444736543277381

Epoch: 147| Step: 0
Training loss: 2.1266132289825515
Validation loss: 2.477664616230938

Epoch: 5| Step: 1
Training loss: 2.405381578561428
Validation loss: 2.515021220427386

Epoch: 5| Step: 2
Training loss: 2.715171651454617
Validation loss: 2.5029349890432044

Epoch: 5| Step: 3
Training loss: 2.5498174040998483
Validation loss: 2.4553176437117923

Epoch: 5| Step: 4
Training loss: 2.7458291068693366
Validation loss: 2.4523520672273422

Epoch: 5| Step: 5
Training loss: 2.2900791449383986
Validation loss: 2.4591094791095944

Epoch: 5| Step: 6
Training loss: 1.9183039789856655
Validation loss: 2.4611742433482258

Epoch: 5| Step: 7
Training loss: 2.9164168841262392
Validation loss: 2.479363738083067

Epoch: 5| Step: 8
Training loss: 2.4529604522527797
Validation loss: 2.500385844286012

Epoch: 5| Step: 9
Training loss: 2.554136164256468
Validation loss: 2.5227720053024254

Epoch: 5| Step: 10
Training loss: 2.5136637179961863
Validation loss: 2.5302631556554998

Epoch: 148| Step: 0
Training loss: 2.533024107314193
Validation loss: 2.5291026436254134

Epoch: 5| Step: 1
Training loss: 2.93621522118769
Validation loss: 2.5229470132421006

Epoch: 5| Step: 2
Training loss: 2.063669508918765
Validation loss: 2.5188181188502936

Epoch: 5| Step: 3
Training loss: 2.87591339197389
Validation loss: 2.5261539117561815

Epoch: 5| Step: 4
Training loss: 2.0692405372653058
Validation loss: 2.5488176554866113

Epoch: 5| Step: 5
Training loss: 2.842509240074204
Validation loss: 2.493211786014147

Epoch: 5| Step: 6
Training loss: 2.706712580167718
Validation loss: 2.4746060795520903

Epoch: 5| Step: 7
Training loss: 2.1507450542736732
Validation loss: 2.4274522332986797

Epoch: 5| Step: 8
Training loss: 2.406102361732409
Validation loss: 2.430273652104258

Epoch: 5| Step: 9
Training loss: 2.288432272124111
Validation loss: 2.436024293007983

Epoch: 5| Step: 10
Training loss: 2.053126681485351
Validation loss: 2.453123804461411

Epoch: 149| Step: 0
Training loss: 2.551349010050888
Validation loss: 2.4751615393474493

Epoch: 5| Step: 1
Training loss: 2.554710364749791
Validation loss: 2.4571508727389055

Epoch: 5| Step: 2
Training loss: 2.5973685886893785
Validation loss: 2.4878671395895764

Epoch: 5| Step: 3
Training loss: 2.724310439470045
Validation loss: 2.4674139752273443

Epoch: 5| Step: 4
Training loss: 2.0210906451554957
Validation loss: 2.4749165264946993

Epoch: 5| Step: 5
Training loss: 2.0374568302753304
Validation loss: 2.507197742787178

Epoch: 5| Step: 6
Training loss: 2.391430488471067
Validation loss: 2.539594626376141

Epoch: 5| Step: 7
Training loss: 2.3333914159175975
Validation loss: 2.5598471641118046

Epoch: 5| Step: 8
Training loss: 2.8093584953391892
Validation loss: 2.5891649066185

Epoch: 5| Step: 9
Training loss: 2.3189300631710346
Validation loss: 2.548183306194617

Epoch: 5| Step: 10
Training loss: 2.1348285020117443
Validation loss: 2.5578024250359572

Epoch: 150| Step: 0
Training loss: 2.133332576850916
Validation loss: 2.5530921139358025

Epoch: 5| Step: 1
Training loss: 2.688324735201641
Validation loss: 2.5548733292460866

Epoch: 5| Step: 2
Training loss: 2.4355278840353223
Validation loss: 2.5028550529528784

Epoch: 5| Step: 3
Training loss: 2.988219655717335
Validation loss: 2.501269650819005

Epoch: 5| Step: 4
Training loss: 2.2060463657365728
Validation loss: 2.4661408418360438

Epoch: 5| Step: 5
Training loss: 2.0397261785478387
Validation loss: 2.439588357338718

Epoch: 5| Step: 6
Training loss: 2.2191149988962753
Validation loss: 2.42625851228169

Epoch: 5| Step: 7
Training loss: 2.0306016327372642
Validation loss: 2.4272501088648415

Epoch: 5| Step: 8
Training loss: 2.9467753614973655
Validation loss: 2.4554581278189214

Epoch: 5| Step: 9
Training loss: 2.4320257287923193
Validation loss: 2.4604889283286044

Epoch: 5| Step: 10
Training loss: 2.701900403240649
Validation loss: 2.4438908822356025

Epoch: 151| Step: 0
Training loss: 2.3830508253638003
Validation loss: 2.4350411545074784

Epoch: 5| Step: 1
Training loss: 1.9211803514492853
Validation loss: 2.4280339234597372

Epoch: 5| Step: 2
Training loss: 2.2590931359114905
Validation loss: 2.4447606901170644

Epoch: 5| Step: 3
Training loss: 2.452575136019495
Validation loss: 2.473669547997184

Epoch: 5| Step: 4
Training loss: 2.293982000857367
Validation loss: 2.4942748472361114

Epoch: 5| Step: 5
Training loss: 3.113017340259189
Validation loss: 2.5136272202303283

Epoch: 5| Step: 6
Training loss: 2.7025164321555115
Validation loss: 2.524215464028506

Epoch: 5| Step: 7
Training loss: 2.0821785078522956
Validation loss: 2.5373941260909163

Epoch: 5| Step: 8
Training loss: 2.368758180951407
Validation loss: 2.5260574342019684

Epoch: 5| Step: 9
Training loss: 2.149641885430153
Validation loss: 2.5285654795434325

Epoch: 5| Step: 10
Training loss: 2.5087915333653656
Validation loss: 2.550997491561589

Epoch: 152| Step: 0
Training loss: 1.9221005811343985
Validation loss: 2.542702495231516

Epoch: 5| Step: 1
Training loss: 2.843552802657954
Validation loss: 2.528243397659048

Epoch: 5| Step: 2
Training loss: 2.3871265818381953
Validation loss: 2.5040206623236587

Epoch: 5| Step: 3
Training loss: 2.6982358255218157
Validation loss: 2.505736438210536

Epoch: 5| Step: 4
Training loss: 2.180538981942313
Validation loss: 2.5099827057702218

Epoch: 5| Step: 5
Training loss: 2.71781072066706
Validation loss: 2.5046844811368514

Epoch: 5| Step: 6
Training loss: 2.5700781811055142
Validation loss: 2.4614186118906196

Epoch: 5| Step: 7
Training loss: 2.044807496465454
Validation loss: 2.4100277750229666

Epoch: 5| Step: 8
Training loss: 2.3725758277344076
Validation loss: 2.3841217838959397

Epoch: 5| Step: 9
Training loss: 2.535972428566065
Validation loss: 2.3812173981701434

Epoch: 5| Step: 10
Training loss: 2.0697605764904647
Validation loss: 2.3902897260201854

Epoch: 153| Step: 0
Training loss: 2.5805534254196933
Validation loss: 2.402247675466832

Epoch: 5| Step: 1
Training loss: 2.5249293024722315
Validation loss: 2.4057393335872725

Epoch: 5| Step: 2
Training loss: 2.2401710507955657
Validation loss: 2.414317917884014

Epoch: 5| Step: 3
Training loss: 2.7487834493658405
Validation loss: 2.4546065707183797

Epoch: 5| Step: 4
Training loss: 2.296251588674462
Validation loss: 2.4943167506979034

Epoch: 5| Step: 5
Training loss: 1.8157859481410668
Validation loss: 2.552882926665728

Epoch: 5| Step: 6
Training loss: 2.7626607925777265
Validation loss: 2.577261930991498

Epoch: 5| Step: 7
Training loss: 2.304590462403647
Validation loss: 2.591780109083759

Epoch: 5| Step: 8
Training loss: 2.1446201882741676
Validation loss: 2.5592139278924715

Epoch: 5| Step: 9
Training loss: 2.6086695282775225
Validation loss: 2.5321316608474502

Epoch: 5| Step: 10
Training loss: 1.9577981812850855
Validation loss: 2.500329680906038

Epoch: 154| Step: 0
Training loss: 2.2960355093865097
Validation loss: 2.4792288006091603

Epoch: 5| Step: 1
Training loss: 2.4162393279809407
Validation loss: 2.477114580859922

Epoch: 5| Step: 2
Training loss: 2.7244702375427683
Validation loss: 2.4701285251194127

Epoch: 5| Step: 3
Training loss: 2.1591656639992927
Validation loss: 2.4557589421689716

Epoch: 5| Step: 4
Training loss: 2.0873481466831127
Validation loss: 2.4606500314797826

Epoch: 5| Step: 5
Training loss: 1.8074577174642683
Validation loss: 2.4609211718174984

Epoch: 5| Step: 6
Training loss: 2.706875971404425
Validation loss: 2.4708941478750486

Epoch: 5| Step: 7
Training loss: 2.27648742174963
Validation loss: 2.4653556950840776

Epoch: 5| Step: 8
Training loss: 2.3638916236252983
Validation loss: 2.4728055845802066

Epoch: 5| Step: 9
Training loss: 2.0547085024844485
Validation loss: 2.479222026553961

Epoch: 5| Step: 10
Training loss: 2.7539383690225816
Validation loss: 2.4779631838132175

Epoch: 155| Step: 0
Training loss: 2.0355158687639223
Validation loss: 2.5035435706975484

Epoch: 5| Step: 1
Training loss: 2.488009691017142
Validation loss: 2.5276920405557206

Epoch: 5| Step: 2
Training loss: 2.5170861970299723
Validation loss: 2.560785758150653

Epoch: 5| Step: 3
Training loss: 2.371966985192925
Validation loss: 2.5702955460664842

Epoch: 5| Step: 4
Training loss: 2.433237309934549
Validation loss: 2.583842920607112

Epoch: 5| Step: 5
Training loss: 2.715135824834965
Validation loss: 2.570479315436176

Epoch: 5| Step: 6
Training loss: 2.054962487910957
Validation loss: 2.517099936495004

Epoch: 5| Step: 7
Training loss: 2.0500464876067754
Validation loss: 2.5007061658282885

Epoch: 5| Step: 8
Training loss: 2.080355830750557
Validation loss: 2.467706712452234

Epoch: 5| Step: 9
Training loss: 2.2263259494341296
Validation loss: 2.4381937486403924

Epoch: 5| Step: 10
Training loss: 2.604063281232304
Validation loss: 2.415850801483022

Epoch: 156| Step: 0
Training loss: 2.632157784848697
Validation loss: 2.40126571231025

Epoch: 5| Step: 1
Training loss: 2.44495211252072
Validation loss: 2.393356947735949

Epoch: 5| Step: 2
Training loss: 2.1457401613420806
Validation loss: 2.399314840423158

Epoch: 5| Step: 3
Training loss: 2.095139910412109
Validation loss: 2.4190698622285662

Epoch: 5| Step: 4
Training loss: 2.5588635950259677
Validation loss: 2.4462857907315327

Epoch: 5| Step: 5
Training loss: 2.4516871423685314
Validation loss: 2.458522430274621

Epoch: 5| Step: 6
Training loss: 2.039864101184206
Validation loss: 2.463795100975872

Epoch: 5| Step: 7
Training loss: 1.8609311299891633
Validation loss: 2.496475810061468

Epoch: 5| Step: 8
Training loss: 2.5743457259263876
Validation loss: 2.5078639989704627

Epoch: 5| Step: 9
Training loss: 2.3953604079380697
Validation loss: 2.5242354350772356

Epoch: 5| Step: 10
Training loss: 2.1482266409309947
Validation loss: 2.522720098294216

Epoch: 157| Step: 0
Training loss: 2.254198184354185
Validation loss: 2.5568199423540188

Epoch: 5| Step: 1
Training loss: 2.3523961614054962
Validation loss: 2.5175865849919274

Epoch: 5| Step: 2
Training loss: 2.432856807905516
Validation loss: 2.5008870960760197

Epoch: 5| Step: 3
Training loss: 2.1772062884445806
Validation loss: 2.504349721805681

Epoch: 5| Step: 4
Training loss: 2.187176162727406
Validation loss: 2.499342284284364

Epoch: 5| Step: 5
Training loss: 2.027440063305604
Validation loss: 2.5037289558069222

Epoch: 5| Step: 6
Training loss: 2.649963119538102
Validation loss: 2.5082085501505627

Epoch: 5| Step: 7
Training loss: 2.380958110711606
Validation loss: 2.510341059191641

Epoch: 5| Step: 8
Training loss: 2.3335716489160987
Validation loss: 2.514422136815255

Epoch: 5| Step: 9
Training loss: 2.078990096530565
Validation loss: 2.4908726805210337

Epoch: 5| Step: 10
Training loss: 2.173782937676123
Validation loss: 2.496046644428114

Epoch: 158| Step: 0
Training loss: 2.147487360924863
Validation loss: 2.509012252143055

Epoch: 5| Step: 1
Training loss: 2.074498504336561
Validation loss: 2.5167910737509342

Epoch: 5| Step: 2
Training loss: 2.716614597110193
Validation loss: 2.537634257303897

Epoch: 5| Step: 3
Training loss: 2.3151438265915956
Validation loss: 2.5600128579377603

Epoch: 5| Step: 4
Training loss: 2.1347838293697157
Validation loss: 2.5597123721137622

Epoch: 5| Step: 5
Training loss: 2.1193899262919906
Validation loss: 2.5602932223475414

Epoch: 5| Step: 6
Training loss: 1.99107054271104
Validation loss: 2.549969176971337

Epoch: 5| Step: 7
Training loss: 2.2914729527761053
Validation loss: 2.5331208650266763

Epoch: 5| Step: 8
Training loss: 2.4828595991810745
Validation loss: 2.522280612603545

Epoch: 5| Step: 9
Training loss: 2.577168050086418
Validation loss: 2.522869713062169

Epoch: 5| Step: 10
Training loss: 1.8826819410208784
Validation loss: 2.508474902493262

Epoch: 159| Step: 0
Training loss: 1.8246761295926666
Validation loss: 2.4731608419636966

Epoch: 5| Step: 1
Training loss: 2.055085002319917
Validation loss: 2.4688784813927924

Epoch: 5| Step: 2
Training loss: 2.3033023098274668
Validation loss: 2.459484875211907

Epoch: 5| Step: 3
Training loss: 2.742206801648149
Validation loss: 2.4482068087336417

Epoch: 5| Step: 4
Training loss: 2.2260319663303383
Validation loss: 2.460364253842744

Epoch: 5| Step: 5
Training loss: 2.6350940813500223
Validation loss: 2.46885514570871

Epoch: 5| Step: 6
Training loss: 1.8791905939421354
Validation loss: 2.4686004605842915

Epoch: 5| Step: 7
Training loss: 2.3313130306283076
Validation loss: 2.4634295852605854

Epoch: 5| Step: 8
Training loss: 2.469414247409956
Validation loss: 2.4766303621476933

Epoch: 5| Step: 9
Training loss: 1.6730107522859512
Validation loss: 2.469477295460274

Epoch: 5| Step: 10
Training loss: 2.293880872604904
Validation loss: 2.461461576699611

Epoch: 160| Step: 0
Training loss: 1.9793417468347752
Validation loss: 2.478673596536047

Epoch: 5| Step: 1
Training loss: 2.585911960994308
Validation loss: 2.509518185099269

Epoch: 5| Step: 2
Training loss: 1.6774617196730983
Validation loss: 2.5115370740461183

Epoch: 5| Step: 3
Training loss: 2.3631544347108804
Validation loss: 2.5143518055841985

Epoch: 5| Step: 4
Training loss: 2.482864400466428
Validation loss: 2.510777766902482

Epoch: 5| Step: 5
Training loss: 2.2005845160364186
Validation loss: 2.528574204907051

Epoch: 5| Step: 6
Training loss: 2.4026271745919905
Validation loss: 2.5119320970802628

Epoch: 5| Step: 7
Training loss: 2.0049471466251916
Validation loss: 2.5198466197789036

Epoch: 5| Step: 8
Training loss: 2.5764711566230747
Validation loss: 2.5156432680865275

Epoch: 5| Step: 9
Training loss: 1.9177093641232426
Validation loss: 2.5063773266611986

Epoch: 5| Step: 10
Training loss: 1.9073888784816517
Validation loss: 2.5277533789380504

Epoch: 161| Step: 0
Training loss: 2.3904935513927845
Validation loss: 2.541531891244324

Epoch: 5| Step: 1
Training loss: 2.074355528608783
Validation loss: 2.519606600352739

Epoch: 5| Step: 2
Training loss: 1.938715768655767
Validation loss: 2.5567832003367656

Epoch: 5| Step: 3
Training loss: 2.250605713587666
Validation loss: 2.535745792569108

Epoch: 5| Step: 4
Training loss: 2.2115422692154474
Validation loss: 2.516863161106541

Epoch: 5| Step: 5
Training loss: 2.0255264633962344
Validation loss: 2.496415030989991

Epoch: 5| Step: 6
Training loss: 2.640288562898672
Validation loss: 2.4799475332426963

Epoch: 5| Step: 7
Training loss: 2.212545288829327
Validation loss: 2.4923966590964874

Epoch: 5| Step: 8
Training loss: 2.191779392181544
Validation loss: 2.5273670051487342

Epoch: 5| Step: 9
Training loss: 1.8595367489512202
Validation loss: 2.5194737418841435

Epoch: 5| Step: 10
Training loss: 2.296045374092986
Validation loss: 2.5332563169842586

Epoch: 162| Step: 0
Training loss: 1.9232758169758342
Validation loss: 2.5268063509986773

Epoch: 5| Step: 1
Training loss: 2.426362439497689
Validation loss: 2.5367409577569546

Epoch: 5| Step: 2
Training loss: 1.7078062345314793
Validation loss: 2.5351620120147635

Epoch: 5| Step: 3
Training loss: 1.8715036855014688
Validation loss: 2.525641175010877

Epoch: 5| Step: 4
Training loss: 2.295883899092633
Validation loss: 2.549068317561346

Epoch: 5| Step: 5
Training loss: 2.37887397831918
Validation loss: 2.5421461318480048

Epoch: 5| Step: 6
Training loss: 2.5511287434987993
Validation loss: 2.551240540689232

Epoch: 5| Step: 7
Training loss: 2.01928213564196
Validation loss: 2.5411371708021875

Epoch: 5| Step: 8
Training loss: 2.4270596045997275
Validation loss: 2.5263525394868216

Epoch: 5| Step: 9
Training loss: 1.9719918822456086
Validation loss: 2.5034002479071584

Epoch: 5| Step: 10
Training loss: 2.270017693236377
Validation loss: 2.500170153293112

Epoch: 163| Step: 0
Training loss: 2.3498052069912565
Validation loss: 2.5059139034226887

Epoch: 5| Step: 1
Training loss: 1.7768909590222826
Validation loss: 2.513119831501753

Epoch: 5| Step: 2
Training loss: 2.1324011996458876
Validation loss: 2.512683829276729

Epoch: 5| Step: 3
Training loss: 2.423702018463532
Validation loss: 2.485203054526436

Epoch: 5| Step: 4
Training loss: 1.7432435260686958
Validation loss: 2.4962844700024975

Epoch: 5| Step: 5
Training loss: 1.9115215640995789
Validation loss: 2.4852704625680286

Epoch: 5| Step: 6
Training loss: 2.1207019872657082
Validation loss: 2.5005703552349425

Epoch: 5| Step: 7
Training loss: 2.3697679008437995
Validation loss: 2.523497863919209

Epoch: 5| Step: 8
Training loss: 2.2707364006235826
Validation loss: 2.5680403473646174

Epoch: 5| Step: 9
Training loss: 2.140779809853153
Validation loss: 2.5555566580694076

Epoch: 5| Step: 10
Training loss: 2.5229032441046506
Validation loss: 2.5692534973209304

Epoch: 164| Step: 0
Training loss: 1.8503541504331398
Validation loss: 2.56240881680845

Epoch: 5| Step: 1
Training loss: 2.328245633475421
Validation loss: 2.5337030922426846

Epoch: 5| Step: 2
Training loss: 2.0816766891462195
Validation loss: 2.5343916910448647

Epoch: 5| Step: 3
Training loss: 1.9167320475276801
Validation loss: 2.513703998936925

Epoch: 5| Step: 4
Training loss: 2.545119728015097
Validation loss: 2.5282446915236405

Epoch: 5| Step: 5
Training loss: 2.075664698753243
Validation loss: 2.5298185900594077

Epoch: 5| Step: 6
Training loss: 1.7008575604570022
Validation loss: 2.530012566851689

Epoch: 5| Step: 7
Training loss: 2.1039839057741947
Validation loss: 2.522434483432459

Epoch: 5| Step: 8
Training loss: 2.656286082303184
Validation loss: 2.509326774987752

Epoch: 5| Step: 9
Training loss: 2.2524601943619467
Validation loss: 2.474953768105603

Epoch: 5| Step: 10
Training loss: 1.6962494260805265
Validation loss: 2.4653862191344227

Epoch: 165| Step: 0
Training loss: 1.9291332854423795
Validation loss: 2.497500195268214

Epoch: 5| Step: 1
Training loss: 2.3309525082666696
Validation loss: 2.5470218013447803

Epoch: 5| Step: 2
Training loss: 2.055011796198121
Validation loss: 2.581606696933297

Epoch: 5| Step: 3
Training loss: 2.0025304045732324
Validation loss: 2.5604719334663937

Epoch: 5| Step: 4
Training loss: 1.929799559270014
Validation loss: 2.544932007967172

Epoch: 5| Step: 5
Training loss: 2.3192003455431216
Validation loss: 2.5200370894478055

Epoch: 5| Step: 6
Training loss: 1.9171726415877595
Validation loss: 2.5440575583784213

Epoch: 5| Step: 7
Training loss: 2.306369491004081
Validation loss: 2.5456915171146277

Epoch: 5| Step: 8
Training loss: 2.0250156684551883
Validation loss: 2.5284536125638044

Epoch: 5| Step: 9
Training loss: 2.1518979588817526
Validation loss: 2.531699756046737

Epoch: 5| Step: 10
Training loss: 2.296602401646301
Validation loss: 2.5304197496583396

Epoch: 166| Step: 0
Training loss: 2.113978357325178
Validation loss: 2.5159767438460405

Epoch: 5| Step: 1
Training loss: 1.9288059336771566
Validation loss: 2.4897585451188142

Epoch: 5| Step: 2
Training loss: 2.1064648934605086
Validation loss: 2.4748811126243

Epoch: 5| Step: 3
Training loss: 2.0577163708594126
Validation loss: 2.4803232814542695

Epoch: 5| Step: 4
Training loss: 2.254576690763681
Validation loss: 2.503163780493827

Epoch: 5| Step: 5
Training loss: 1.9220557399213223
Validation loss: 2.4819283201676594

Epoch: 5| Step: 6
Training loss: 1.1871937808688775
Validation loss: 2.476286166499821

Epoch: 5| Step: 7
Training loss: 2.3404015591037415
Validation loss: 2.4603779589156054

Epoch: 5| Step: 8
Training loss: 2.492084369498695
Validation loss: 2.477257760347104

Epoch: 5| Step: 9
Training loss: 2.532850160030495
Validation loss: 2.4859013439052604

Epoch: 5| Step: 10
Training loss: 1.8370285363553254
Validation loss: 2.5372841457550184

Epoch: 167| Step: 0
Training loss: 2.350444134887189
Validation loss: 2.5952550783979107

Epoch: 5| Step: 1
Training loss: 1.4075237862997676
Validation loss: 2.6680900161692613

Epoch: 5| Step: 2
Training loss: 2.479720932579491
Validation loss: 2.7175396742992812

Epoch: 5| Step: 3
Training loss: 1.9692141878795135
Validation loss: 2.722939639463727

Epoch: 5| Step: 4
Training loss: 2.1612538313735175
Validation loss: 2.6835141263648468

Epoch: 5| Step: 5
Training loss: 2.3050567848343855
Validation loss: 2.6168024378892976

Epoch: 5| Step: 6
Training loss: 2.217917380119332
Validation loss: 2.562688630987536

Epoch: 5| Step: 7
Training loss: 1.5386858639029144
Validation loss: 2.525006987347718

Epoch: 5| Step: 8
Training loss: 1.737390731559158
Validation loss: 2.4860149617096057

Epoch: 5| Step: 9
Training loss: 2.395799210899727
Validation loss: 2.478013442993779

Epoch: 5| Step: 10
Training loss: 2.0758066654623524
Validation loss: 2.451477113877765

Epoch: 168| Step: 0
Training loss: 2.172453988381462
Validation loss: 2.4481820885303445

Epoch: 5| Step: 1
Training loss: 2.236325246484228
Validation loss: 2.468244059173828

Epoch: 5| Step: 2
Training loss: 1.9471523669028326
Validation loss: 2.4927119301427614

Epoch: 5| Step: 3
Training loss: 2.2772365433599697
Validation loss: 2.557926527652552

Epoch: 5| Step: 4
Training loss: 2.118032927122994
Validation loss: 2.5901665829792577

Epoch: 5| Step: 5
Training loss: 1.9964758102361657
Validation loss: 2.5844132616992406

Epoch: 5| Step: 6
Training loss: 2.0067069130512545
Validation loss: 2.5964771536649978

Epoch: 5| Step: 7
Training loss: 1.7127973646397563
Validation loss: 2.5883429752205633

Epoch: 5| Step: 8
Training loss: 1.7074866483956654
Validation loss: 2.557382421151091

Epoch: 5| Step: 9
Training loss: 1.987080689349355
Validation loss: 2.558643995422763

Epoch: 5| Step: 10
Training loss: 2.4376009406683585
Validation loss: 2.5372930230056245

Epoch: 169| Step: 0
Training loss: 1.7239060485225668
Validation loss: 2.5470565458409915

Epoch: 5| Step: 1
Training loss: 1.9271480515068784
Validation loss: 2.5065920140835445

Epoch: 5| Step: 2
Training loss: 2.199954301186079
Validation loss: 2.4891073175425444

Epoch: 5| Step: 3
Training loss: 2.4524537158141126
Validation loss: 2.5077922243797475

Epoch: 5| Step: 4
Training loss: 1.741938141224884
Validation loss: 2.540755457733027

Epoch: 5| Step: 5
Training loss: 2.396157439050549
Validation loss: 2.5856013218152714

Epoch: 5| Step: 6
Training loss: 2.1532445777497937
Validation loss: 2.6345474448500505

Epoch: 5| Step: 7
Training loss: 2.050999569852385
Validation loss: 2.620572385163353

Epoch: 5| Step: 8
Training loss: 1.3072799692225852
Validation loss: 2.5886462757814845

Epoch: 5| Step: 9
Training loss: 1.970982814332619
Validation loss: 2.579016199887762

Epoch: 5| Step: 10
Training loss: 2.1239072570596336
Validation loss: 2.5597218846721956

Epoch: 170| Step: 0
Training loss: 1.9168124627209704
Validation loss: 2.5074184219140294

Epoch: 5| Step: 1
Training loss: 2.1254019637559955
Validation loss: 2.5043809652007547

Epoch: 5| Step: 2
Training loss: 1.9673928321046232
Validation loss: 2.4997033322596978

Epoch: 5| Step: 3
Training loss: 1.682468755355413
Validation loss: 2.497733491561958

Epoch: 5| Step: 4
Training loss: 2.0544628412112904
Validation loss: 2.50230437589923

Epoch: 5| Step: 5
Training loss: 2.598674465621172
Validation loss: 2.4843635055762117

Epoch: 5| Step: 6
Training loss: 1.9559488253578678
Validation loss: 2.4702889840448217

Epoch: 5| Step: 7
Training loss: 1.784126836352037
Validation loss: 2.5105151042821134

Epoch: 5| Step: 8
Training loss: 2.2340587045304083
Validation loss: 2.5543512456293382

Epoch: 5| Step: 9
Training loss: 1.7670405292191451
Validation loss: 2.6063187859699064

Epoch: 5| Step: 10
Training loss: 2.0220386279724467
Validation loss: 2.6066624016080797

Epoch: 171| Step: 0
Training loss: 2.1564584161405045
Validation loss: 2.6077396553283263

Epoch: 5| Step: 1
Training loss: 2.167030255059392
Validation loss: 2.5484093119215174

Epoch: 5| Step: 2
Training loss: 1.88781144307408
Validation loss: 2.5092432663960467

Epoch: 5| Step: 3
Training loss: 1.9770024831444635
Validation loss: 2.490238081116787

Epoch: 5| Step: 4
Training loss: 2.121052609882452
Validation loss: 2.5100600167514187

Epoch: 5| Step: 5
Training loss: 1.8288058455851888
Validation loss: 2.537582701790127

Epoch: 5| Step: 6
Training loss: 2.309368177927804
Validation loss: 2.5510766371634035

Epoch: 5| Step: 7
Training loss: 1.627277319070044
Validation loss: 2.5431240999556013

Epoch: 5| Step: 8
Training loss: 1.9942399765208443
Validation loss: 2.6023570083650482

Epoch: 5| Step: 9
Training loss: 2.089503522612082
Validation loss: 2.625009633411363

Epoch: 5| Step: 10
Training loss: 1.7591979945634113
Validation loss: 2.653237163807269

Epoch: 172| Step: 0
Training loss: 1.9150059457392807
Validation loss: 2.675839614321462

Epoch: 5| Step: 1
Training loss: 1.7946358038703354
Validation loss: 2.7372756044549416

Epoch: 5| Step: 2
Training loss: 2.6025584837455464
Validation loss: 2.6984805760487105

Epoch: 5| Step: 3
Training loss: 2.486035637683719
Validation loss: 2.6256983443857527

Epoch: 5| Step: 4
Training loss: 2.0480209520654022
Validation loss: 2.5151424425372997

Epoch: 5| Step: 5
Training loss: 1.873638039896479
Validation loss: 2.4323531672656764

Epoch: 5| Step: 6
Training loss: 1.9459799728303944
Validation loss: 2.4652329903909123

Epoch: 5| Step: 7
Training loss: 1.9564593730191628
Validation loss: 2.454171610551685

Epoch: 5| Step: 8
Training loss: 1.582539041287673
Validation loss: 2.4692546878466666

Epoch: 5| Step: 9
Training loss: 1.9274084555809066
Validation loss: 2.492586249842668

Epoch: 5| Step: 10
Training loss: 1.9590845358164977
Validation loss: 2.5293169559352

Epoch: 173| Step: 0
Training loss: 2.001195073705325
Validation loss: 2.551163979225218

Epoch: 5| Step: 1
Training loss: 1.8440222458356073
Validation loss: 2.60331469440987

Epoch: 5| Step: 2
Training loss: 2.106609764276263
Validation loss: 2.634258381647979

Epoch: 5| Step: 3
Training loss: 1.9772886367285356
Validation loss: 2.639062725991363

Epoch: 5| Step: 4
Training loss: 1.5698501133896579
Validation loss: 2.6340741488824397

Epoch: 5| Step: 5
Training loss: 2.066551275518448
Validation loss: 2.6137578236512184

Epoch: 5| Step: 6
Training loss: 1.9873660516286107
Validation loss: 2.5592178767079568

Epoch: 5| Step: 7
Training loss: 1.9935178615591758
Validation loss: 2.5280882213801297

Epoch: 5| Step: 8
Training loss: 1.9096211501068543
Validation loss: 2.484495504052907

Epoch: 5| Step: 9
Training loss: 2.0699795437230497
Validation loss: 2.479735285371966

Epoch: 5| Step: 10
Training loss: 2.191391453548532
Validation loss: 2.4756488930955745

Epoch: 174| Step: 0
Training loss: 1.9627804549695314
Validation loss: 2.5070424510735867

Epoch: 5| Step: 1
Training loss: 1.5536141835986443
Validation loss: 2.545868221203887

Epoch: 5| Step: 2
Training loss: 2.252740991806597
Validation loss: 2.6177546276521575

Epoch: 5| Step: 3
Training loss: 2.460698094908908
Validation loss: 2.624810287644087

Epoch: 5| Step: 4
Training loss: 1.916562188106644
Validation loss: 2.6268283543398967

Epoch: 5| Step: 5
Training loss: 2.0160458147655986
Validation loss: 2.6037947266467945

Epoch: 5| Step: 6
Training loss: 2.121468695279011
Validation loss: 2.579658129513522

Epoch: 5| Step: 7
Training loss: 1.5767019673294371
Validation loss: 2.5396536806029686

Epoch: 5| Step: 8
Training loss: 1.884754366668124
Validation loss: 2.5083499200095565

Epoch: 5| Step: 9
Training loss: 1.8627904729463949
Validation loss: 2.5200276040992082

Epoch: 5| Step: 10
Training loss: 1.5468773890004832
Validation loss: 2.5308109998102677

Epoch: 175| Step: 0
Training loss: 2.0929748466719014
Validation loss: 2.552811054061935

Epoch: 5| Step: 1
Training loss: 2.012423671435941
Validation loss: 2.544412145467688

Epoch: 5| Step: 2
Training loss: 1.9560649869650524
Validation loss: 2.553946362557352

Epoch: 5| Step: 3
Training loss: 1.7536972363148449
Validation loss: 2.580261244339759

Epoch: 5| Step: 4
Training loss: 1.6718850536578922
Validation loss: 2.561701541401466

Epoch: 5| Step: 5
Training loss: 2.2603665066499206
Validation loss: 2.5576967772661114

Epoch: 5| Step: 6
Training loss: 1.883631547875339
Validation loss: 2.549551402008032

Epoch: 5| Step: 7
Training loss: 2.0977173979245096
Validation loss: 2.5514356670718352

Epoch: 5| Step: 8
Training loss: 1.5373369021863668
Validation loss: 2.542654211930406

Epoch: 5| Step: 9
Training loss: 1.9506346427877146
Validation loss: 2.5227393098752806

Epoch: 5| Step: 10
Training loss: 1.734940994974319
Validation loss: 2.5340802103950177

Epoch: 176| Step: 0
Training loss: 1.4318786672997268
Validation loss: 2.5313212066807327

Epoch: 5| Step: 1
Training loss: 2.5713625910786257
Validation loss: 2.524367703739892

Epoch: 5| Step: 2
Training loss: 2.0373877886431577
Validation loss: 2.525698541684244

Epoch: 5| Step: 3
Training loss: 1.436385759489451
Validation loss: 2.491166750724731

Epoch: 5| Step: 4
Training loss: 1.4821058094692992
Validation loss: 2.510648631344719

Epoch: 5| Step: 5
Training loss: 1.698607937877509
Validation loss: 2.531933420669337

Epoch: 5| Step: 6
Training loss: 1.9800561478870746
Validation loss: 2.543070742385534

Epoch: 5| Step: 7
Training loss: 2.0350721345530904
Validation loss: 2.5539075996845244

Epoch: 5| Step: 8
Training loss: 1.8689066103630398
Validation loss: 2.5712446795290314

Epoch: 5| Step: 9
Training loss: 2.0495228421422014
Validation loss: 2.5831095052391615

Epoch: 5| Step: 10
Training loss: 1.876001980404327
Validation loss: 2.55457701727475

Epoch: 177| Step: 0
Training loss: 1.8226145321371627
Validation loss: 2.5202335646571585

Epoch: 5| Step: 1
Training loss: 2.0420543017214796
Validation loss: 2.5156225297319943

Epoch: 5| Step: 2
Training loss: 1.3536127229021602
Validation loss: 2.463058174136186

Epoch: 5| Step: 3
Training loss: 1.8334865361560146
Validation loss: 2.4585373562481294

Epoch: 5| Step: 4
Training loss: 1.775466430522891
Validation loss: 2.4733528219155683

Epoch: 5| Step: 5
Training loss: 2.238542418363672
Validation loss: 2.4983656658170013

Epoch: 5| Step: 6
Training loss: 1.83614195638895
Validation loss: 2.5068840470515616

Epoch: 5| Step: 7
Training loss: 1.9306928355610753
Validation loss: 2.5022572888888184

Epoch: 5| Step: 8
Training loss: 1.5863149409907535
Validation loss: 2.5280655660979345

Epoch: 5| Step: 9
Training loss: 1.6599105114542703
Validation loss: 2.528274918689057

Epoch: 5| Step: 10
Training loss: 2.263404968693656
Validation loss: 2.513242261260451

Epoch: 178| Step: 0
Training loss: 1.818286603379013
Validation loss: 2.545129516714431

Epoch: 5| Step: 1
Training loss: 1.8600119133024264
Validation loss: 2.568608666024313

Epoch: 5| Step: 2
Training loss: 2.3488666885892355
Validation loss: 2.5814705251125307

Epoch: 5| Step: 3
Training loss: 1.5210220359194146
Validation loss: 2.5476744455452645

Epoch: 5| Step: 4
Training loss: 1.4184477866523189
Validation loss: 2.5345765818231283

Epoch: 5| Step: 5
Training loss: 1.6975856606579847
Validation loss: 2.5025758916581955

Epoch: 5| Step: 6
Training loss: 2.1196604570150965
Validation loss: 2.5152102188128547

Epoch: 5| Step: 7
Training loss: 1.8907536234333566
Validation loss: 2.500135463202949

Epoch: 5| Step: 8
Training loss: 1.7856745061530808
Validation loss: 2.5227605079906654

Epoch: 5| Step: 9
Training loss: 1.750165999577546
Validation loss: 2.5358090986173543

Epoch: 5| Step: 10
Training loss: 1.9706745731640802
Validation loss: 2.5451779781790393

Epoch: 179| Step: 0
Training loss: 1.5820246943585239
Validation loss: 2.549633065512923

Epoch: 5| Step: 1
Training loss: 1.7086661255014917
Validation loss: 2.534574142163489

Epoch: 5| Step: 2
Training loss: 2.197108718355985
Validation loss: 2.5570211938943816

Epoch: 5| Step: 3
Training loss: 2.0485913018887083
Validation loss: 2.5515405221209364

Epoch: 5| Step: 4
Training loss: 1.5798359273875877
Validation loss: 2.563706890894175

Epoch: 5| Step: 5
Training loss: 1.2298234488772464
Validation loss: 2.5718841739570117

Epoch: 5| Step: 6
Training loss: 1.803586219230554
Validation loss: 2.56445591211517

Epoch: 5| Step: 7
Training loss: 1.9884729798811773
Validation loss: 2.5555461619503066

Epoch: 5| Step: 8
Training loss: 2.1020742027404515
Validation loss: 2.5209100942603793

Epoch: 5| Step: 9
Training loss: 1.6353506411043326
Validation loss: 2.5027116436132646

Epoch: 5| Step: 10
Training loss: 1.9892228151069677
Validation loss: 2.5082663053055527

Epoch: 180| Step: 0
Training loss: 1.5115902079656467
Validation loss: 2.5013462246451503

Epoch: 5| Step: 1
Training loss: 1.9194301778898313
Validation loss: 2.5062301704514858

Epoch: 5| Step: 2
Training loss: 1.95170150762657
Validation loss: 2.5352594627096514

Epoch: 5| Step: 3
Training loss: 1.7378684936129458
Validation loss: 2.5402512299921267

Epoch: 5| Step: 4
Training loss: 2.0687616261504176
Validation loss: 2.5570629233020665

Epoch: 5| Step: 5
Training loss: 1.8512851813229803
Validation loss: 2.5355532735507946

Epoch: 5| Step: 6
Training loss: 1.6280172652845095
Validation loss: 2.528449181238207

Epoch: 5| Step: 7
Training loss: 1.5752590329738079
Validation loss: 2.512526131917852

Epoch: 5| Step: 8
Training loss: 1.8756342768733663
Validation loss: 2.4767380218711565

Epoch: 5| Step: 9
Training loss: 2.0069207612091864
Validation loss: 2.4573559209311306

Epoch: 5| Step: 10
Training loss: 1.5958164506356183
Validation loss: 2.4564730039736595

Epoch: 181| Step: 0
Training loss: 1.7732299145440742
Validation loss: 2.436544367206528

Epoch: 5| Step: 1
Training loss: 2.1483152042607503
Validation loss: 2.406604724185525

Epoch: 5| Step: 2
Training loss: 2.075212775661816
Validation loss: 2.420278184074002

Epoch: 5| Step: 3
Training loss: 1.6970192891802178
Validation loss: 2.4328550407538723

Epoch: 5| Step: 4
Training loss: 1.7913304242582637
Validation loss: 2.452888768441885

Epoch: 5| Step: 5
Training loss: 2.020873341377348
Validation loss: 2.4647728538428826

Epoch: 5| Step: 6
Training loss: 1.3409479779216595
Validation loss: 2.4861755997099495

Epoch: 5| Step: 7
Training loss: 1.961808638068584
Validation loss: 2.533603695586933

Epoch: 5| Step: 8
Training loss: 1.350433186507803
Validation loss: 2.6209501814589196

Epoch: 5| Step: 9
Training loss: 1.4434817704891942
Validation loss: 2.6101285109177783

Epoch: 5| Step: 10
Training loss: 1.7712670711321943
Validation loss: 2.6179712999213534

Epoch: 182| Step: 0
Training loss: 1.6619149978604577
Validation loss: 2.5977407474546963

Epoch: 5| Step: 1
Training loss: 1.8990127257151224
Validation loss: 2.5553543401130097

Epoch: 5| Step: 2
Training loss: 1.9114379327362752
Validation loss: 2.4921112506641028

Epoch: 5| Step: 3
Training loss: 1.7795770384792473
Validation loss: 2.4767866404902197

Epoch: 5| Step: 4
Training loss: 2.1550393506769914
Validation loss: 2.4538900377579576

Epoch: 5| Step: 5
Training loss: 1.8326127485741694
Validation loss: 2.4516216337896415

Epoch: 5| Step: 6
Training loss: 1.4706212561770868
Validation loss: 2.454853793413432

Epoch: 5| Step: 7
Training loss: 1.395031152876425
Validation loss: 2.497932449741577

Epoch: 5| Step: 8
Training loss: 1.77494217147113
Validation loss: 2.511777864576845

Epoch: 5| Step: 9
Training loss: 1.1319788529068662
Validation loss: 2.5015626166650216

Epoch: 5| Step: 10
Training loss: 2.1812552553129967
Validation loss: 2.5169719406447717

Epoch: 183| Step: 0
Training loss: 1.6670836483358313
Validation loss: 2.523021624488463

Epoch: 5| Step: 1
Training loss: 1.6030698056600179
Validation loss: 2.5631776839495983

Epoch: 5| Step: 2
Training loss: 2.035780446691177
Validation loss: 2.545304196059515

Epoch: 5| Step: 3
Training loss: 1.6142246545246632
Validation loss: 2.5671443235321973

Epoch: 5| Step: 4
Training loss: 1.2097434278649801
Validation loss: 2.5421162824055537

Epoch: 5| Step: 5
Training loss: 1.7795787801515348
Validation loss: 2.5469177794108346

Epoch: 5| Step: 6
Training loss: 1.397938090395695
Validation loss: 2.488363766275566

Epoch: 5| Step: 7
Training loss: 2.122721404085518
Validation loss: 2.464218879766957

Epoch: 5| Step: 8
Training loss: 1.8820135550421269
Validation loss: 2.4167519138167846

Epoch: 5| Step: 9
Training loss: 1.8077510576019549
Validation loss: 2.4353886587531663

Epoch: 5| Step: 10
Training loss: 1.6611496769196474
Validation loss: 2.415989865534209

Epoch: 184| Step: 0
Training loss: 1.671794711172676
Validation loss: 2.4419784244252987

Epoch: 5| Step: 1
Training loss: 1.8863487117715918
Validation loss: 2.4421872595695335

Epoch: 5| Step: 2
Training loss: 1.8510047941841348
Validation loss: 2.455510159984826

Epoch: 5| Step: 3
Training loss: 1.7143820312667328
Validation loss: 2.487510106917533

Epoch: 5| Step: 4
Training loss: 1.4288189026512375
Validation loss: 2.4972437995871113

Epoch: 5| Step: 5
Training loss: 1.6966187678822469
Validation loss: 2.531753871712808

Epoch: 5| Step: 6
Training loss: 1.575056965115667
Validation loss: 2.576772403243179

Epoch: 5| Step: 7
Training loss: 2.0072892394065205
Validation loss: 2.553370039441043

Epoch: 5| Step: 8
Training loss: 1.5569074107762415
Validation loss: 2.564648109788807

Epoch: 5| Step: 9
Training loss: 2.0837682524341075
Validation loss: 2.5934544491399043

Epoch: 5| Step: 10
Training loss: 1.3248602739471806
Validation loss: 2.5835181026957135

Epoch: 185| Step: 0
Training loss: 2.068140466793047
Validation loss: 2.5167458417542963

Epoch: 5| Step: 1
Training loss: 1.733751614548551
Validation loss: 2.496328604188213

Epoch: 5| Step: 2
Training loss: 1.388970794911735
Validation loss: 2.460262888324156

Epoch: 5| Step: 3
Training loss: 1.948915997005774
Validation loss: 2.459824770987587

Epoch: 5| Step: 4
Training loss: 1.6391802284573092
Validation loss: 2.47824832855744

Epoch: 5| Step: 5
Training loss: 1.491382401656866
Validation loss: 2.5035479534342597

Epoch: 5| Step: 6
Training loss: 1.7164416678051315
Validation loss: 2.5278195159067383

Epoch: 5| Step: 7
Training loss: 1.7430050561014139
Validation loss: 2.5656773207276795

Epoch: 5| Step: 8
Training loss: 1.696907172416183
Validation loss: 2.563344762676818

Epoch: 5| Step: 9
Training loss: 1.656523052235951
Validation loss: 2.549372317542191

Epoch: 5| Step: 10
Training loss: 1.6306804261852628
Validation loss: 2.5145580811619177

Epoch: 186| Step: 0
Training loss: 1.3299128447923392
Validation loss: 2.524234562667453

Epoch: 5| Step: 1
Training loss: 1.3750941070950797
Validation loss: 2.477624671298971

Epoch: 5| Step: 2
Training loss: 1.4848234603444552
Validation loss: 2.476797997997898

Epoch: 5| Step: 3
Training loss: 1.7484975223278265
Validation loss: 2.4652368396450965

Epoch: 5| Step: 4
Training loss: 2.1039439042522
Validation loss: 2.460066971576311

Epoch: 5| Step: 5
Training loss: 1.548901550168854
Validation loss: 2.465053049378776

Epoch: 5| Step: 6
Training loss: 1.4842112400673335
Validation loss: 2.464675342423199

Epoch: 5| Step: 7
Training loss: 1.9822833233602772
Validation loss: 2.4744586646329

Epoch: 5| Step: 8
Training loss: 1.5446213768773545
Validation loss: 2.5048237460350773

Epoch: 5| Step: 9
Training loss: 1.6368127035701439
Validation loss: 2.5182945961611316

Epoch: 5| Step: 10
Training loss: 2.0584882387052734
Validation loss: 2.5565260225168394

Epoch: 187| Step: 0
Training loss: 1.1126298571460125
Validation loss: 2.5823746178107587

Epoch: 5| Step: 1
Training loss: 1.6759834789973165
Validation loss: 2.5876087676507513

Epoch: 5| Step: 2
Training loss: 1.4031837094264965
Validation loss: 2.5697150991277193

Epoch: 5| Step: 3
Training loss: 2.168220354206309
Validation loss: 2.5848026529735595

Epoch: 5| Step: 4
Training loss: 2.01847720355035
Validation loss: 2.573568689865734

Epoch: 5| Step: 5
Training loss: 1.395970603493998
Validation loss: 2.5613719158871944

Epoch: 5| Step: 6
Training loss: 1.332715258790787
Validation loss: 2.519641481242444

Epoch: 5| Step: 7
Training loss: 1.9299688095576775
Validation loss: 2.499690012017708

Epoch: 5| Step: 8
Training loss: 1.3973937161723775
Validation loss: 2.4679199127492653

Epoch: 5| Step: 9
Training loss: 1.6438365927975294
Validation loss: 2.4762658837991043

Epoch: 5| Step: 10
Training loss: 1.8896281238814479
Validation loss: 2.4584174219151227

Epoch: 188| Step: 0
Training loss: 1.1343886361471647
Validation loss: 2.495388136363155

Epoch: 5| Step: 1
Training loss: 1.2302060770288115
Validation loss: 2.511451921997415

Epoch: 5| Step: 2
Training loss: 2.0384804782901096
Validation loss: 2.53284712963226

Epoch: 5| Step: 3
Training loss: 1.4224441562947558
Validation loss: 2.5371610543111953

Epoch: 5| Step: 4
Training loss: 1.7960342430554554
Validation loss: 2.5532219488753127

Epoch: 5| Step: 5
Training loss: 1.541023206027376
Validation loss: 2.5240024117322615

Epoch: 5| Step: 6
Training loss: 1.8673929396738649
Validation loss: 2.5505422942461684

Epoch: 5| Step: 7
Training loss: 1.4648152666501593
Validation loss: 2.539364075526875

Epoch: 5| Step: 8
Training loss: 2.1574954430453555
Validation loss: 2.544557060300133

Epoch: 5| Step: 9
Training loss: 1.494143736592961
Validation loss: 2.5442870118537875

Epoch: 5| Step: 10
Training loss: 1.6617287044110416
Validation loss: 2.565991935476825

Epoch: 189| Step: 0
Training loss: 1.6525282880753975
Validation loss: 2.5015857763677407

Epoch: 5| Step: 1
Training loss: 1.600479727590748
Validation loss: 2.482847539137343

Epoch: 5| Step: 2
Training loss: 1.2539888158691896
Validation loss: 2.485417513684793

Epoch: 5| Step: 3
Training loss: 1.3786921780757324
Validation loss: 2.4562591247798244

Epoch: 5| Step: 4
Training loss: 1.9676685087563817
Validation loss: 2.473860174972447

Epoch: 5| Step: 5
Training loss: 1.4950711014594555
Validation loss: 2.4628712786224107

Epoch: 5| Step: 6
Training loss: 1.9069992844130679
Validation loss: 2.5151992001323533

Epoch: 5| Step: 7
Training loss: 1.7711076262224523
Validation loss: 2.522534182994272

Epoch: 5| Step: 8
Training loss: 1.546908291545162
Validation loss: 2.521195103934264

Epoch: 5| Step: 9
Training loss: 1.5212322217142233
Validation loss: 2.5388924889326456

Epoch: 5| Step: 10
Training loss: 1.760168438025622
Validation loss: 2.5495869390659736

Epoch: 190| Step: 0
Training loss: 1.6703421437529695
Validation loss: 2.508177734660235

Epoch: 5| Step: 1
Training loss: 0.9326210860725125
Validation loss: 2.5048264828229754

Epoch: 5| Step: 2
Training loss: 1.5544443371642225
Validation loss: 2.4666294862804707

Epoch: 5| Step: 3
Training loss: 2.0318060480655054
Validation loss: 2.4856250146638437

Epoch: 5| Step: 4
Training loss: 1.893366693663968
Validation loss: 2.5003700659251207

Epoch: 5| Step: 5
Training loss: 1.5845384863298981
Validation loss: 2.501917317124203

Epoch: 5| Step: 6
Training loss: 1.8920689893003946
Validation loss: 2.469663138290809

Epoch: 5| Step: 7
Training loss: 1.2706090020384304
Validation loss: 2.5125099645172244

Epoch: 5| Step: 8
Training loss: 1.6640167946426452
Validation loss: 2.5441052452038933

Epoch: 5| Step: 9
Training loss: 1.4960667381138941
Validation loss: 2.541501220557965

Epoch: 5| Step: 10
Training loss: 1.4027973174737105
Validation loss: 2.4942248119155526

Epoch: 191| Step: 0
Training loss: 1.463388192850914
Validation loss: 2.4755857899313796

Epoch: 5| Step: 1
Training loss: 1.3035622043992454
Validation loss: 2.4518542253943303

Epoch: 5| Step: 2
Training loss: 1.6818643348040991
Validation loss: 2.4746213436237907

Epoch: 5| Step: 3
Training loss: 1.6145222395956793
Validation loss: 2.4716249390199736

Epoch: 5| Step: 4
Training loss: 1.705424794614902
Validation loss: 2.4920320969354472

Epoch: 5| Step: 5
Training loss: 1.6804318929875155
Validation loss: 2.5329557257486894

Epoch: 5| Step: 6
Training loss: 1.4738538815138171
Validation loss: 2.5426888850362133

Epoch: 5| Step: 7
Training loss: 1.8506238143386315
Validation loss: 2.561550663840462

Epoch: 5| Step: 8
Training loss: 1.7348575779836946
Validation loss: 2.574349932357982

Epoch: 5| Step: 9
Training loss: 1.457976006827192
Validation loss: 2.527362558224164

Epoch: 5| Step: 10
Training loss: 1.5231826960390193
Validation loss: 2.5045905850857904

Epoch: 192| Step: 0
Training loss: 1.6094341082042232
Validation loss: 2.5689131169567507

Epoch: 5| Step: 1
Training loss: 1.6782573910565644
Validation loss: 2.553297265858668

Epoch: 5| Step: 2
Training loss: 1.858057725537297
Validation loss: 2.5527447430870334

Epoch: 5| Step: 3
Training loss: 1.1024517501168722
Validation loss: 2.517945821256282

Epoch: 5| Step: 4
Training loss: 1.5648555547580358
Validation loss: 2.4936705255552076

Epoch: 5| Step: 5
Training loss: 1.768622832562583
Validation loss: 2.52040899602495

Epoch: 5| Step: 6
Training loss: 1.7538053147938333
Validation loss: 2.4857206553773206

Epoch: 5| Step: 7
Training loss: 1.3357296609102915
Validation loss: 2.5208081708842287

Epoch: 5| Step: 8
Training loss: 1.5791936598645668
Validation loss: 2.540679871876847

Epoch: 5| Step: 9
Training loss: 1.5638281708594564
Validation loss: 2.57288967053806

Epoch: 5| Step: 10
Training loss: 1.4536243524152208
Validation loss: 2.5924082790955687

Epoch: 193| Step: 0
Training loss: 1.8049000536439126
Validation loss: 2.5793003539118082

Epoch: 5| Step: 1
Training loss: 1.1688800433428135
Validation loss: 2.551729345393036

Epoch: 5| Step: 2
Training loss: 1.2955338310850713
Validation loss: 2.54375514749292

Epoch: 5| Step: 3
Training loss: 1.9539363549135202
Validation loss: 2.492889870063137

Epoch: 5| Step: 4
Training loss: 1.4761171829981876
Validation loss: 2.4719840596349445

Epoch: 5| Step: 5
Training loss: 1.600184820348666
Validation loss: 2.4613116345692267

Epoch: 5| Step: 6
Training loss: 1.8021143945505076
Validation loss: 2.4443407693566006

Epoch: 5| Step: 7
Training loss: 1.6804252955849446
Validation loss: 2.466563366373473

Epoch: 5| Step: 8
Training loss: 1.3979308419946743
Validation loss: 2.5207073870398555

Epoch: 5| Step: 9
Training loss: 1.353277188171556
Validation loss: 2.536670072999901

Epoch: 5| Step: 10
Training loss: 1.6080052741234672
Validation loss: 2.612577279556188

Epoch: 194| Step: 0
Training loss: 1.5885728259756757
Validation loss: 2.627446245316627

Epoch: 5| Step: 1
Training loss: 2.0191770497536745
Validation loss: 2.5613238889353935

Epoch: 5| Step: 2
Training loss: 1.4859791169220193
Validation loss: 2.5112222747210615

Epoch: 5| Step: 3
Training loss: 1.433435914708407
Validation loss: 2.4759780361305936

Epoch: 5| Step: 4
Training loss: 1.1728900836396268
Validation loss: 2.4582278880980497

Epoch: 5| Step: 5
Training loss: 1.5662527413431764
Validation loss: 2.4467416404711297

Epoch: 5| Step: 6
Training loss: 1.0664794114276583
Validation loss: 2.449208577976194

Epoch: 5| Step: 7
Training loss: 1.8451570217645545
Validation loss: 2.497812955215193

Epoch: 5| Step: 8
Training loss: 1.3396133803126813
Validation loss: 2.515021713783838

Epoch: 5| Step: 9
Training loss: 1.7188287890321885
Validation loss: 2.56353893073292

Epoch: 5| Step: 10
Training loss: 1.7523395703249307
Validation loss: 2.614062257136642

Epoch: 195| Step: 0
Training loss: 1.6173035216061813
Validation loss: 2.6106776100035205

Epoch: 5| Step: 1
Training loss: 1.2604811890956424
Validation loss: 2.5607299639108883

Epoch: 5| Step: 2
Training loss: 1.851040022002609
Validation loss: 2.547513639009076

Epoch: 5| Step: 3
Training loss: 1.445137137007101
Validation loss: 2.5386967847290616

Epoch: 5| Step: 4
Training loss: 1.6009980486370063
Validation loss: 2.509430240952801

Epoch: 5| Step: 5
Training loss: 1.9221435607343458
Validation loss: 2.4668951141887474

Epoch: 5| Step: 6
Training loss: 1.6110518524993696
Validation loss: 2.5008232176454266

Epoch: 5| Step: 7
Training loss: 1.020505359409432
Validation loss: 2.4819934998465056

Epoch: 5| Step: 8
Training loss: 1.3284104881869618
Validation loss: 2.487419886625106

Epoch: 5| Step: 9
Training loss: 1.1052849283141808
Validation loss: 2.4875497591332274

Epoch: 5| Step: 10
Training loss: 2.02500730913515
Validation loss: 2.493660246999306

Epoch: 196| Step: 0
Training loss: 1.2939553544716467
Validation loss: 2.514192488588176

Epoch: 5| Step: 1
Training loss: 1.6140437875643427
Validation loss: 2.46498942691847

Epoch: 5| Step: 2
Training loss: 1.588773700048122
Validation loss: 2.48435944706914

Epoch: 5| Step: 3
Training loss: 1.2617009400802561
Validation loss: 2.4911191207883556

Epoch: 5| Step: 4
Training loss: 1.625421029347179
Validation loss: 2.4755278993774645

Epoch: 5| Step: 5
Training loss: 1.4415873592076531
Validation loss: 2.4886051981357156

Epoch: 5| Step: 6
Training loss: 1.6385797740710926
Validation loss: 2.473435247503662

Epoch: 5| Step: 7
Training loss: 1.7328717702320795
Validation loss: 2.4866518657082954

Epoch: 5| Step: 8
Training loss: 1.5000536432210994
Validation loss: 2.441904758412817

Epoch: 5| Step: 9
Training loss: 1.6299817676343606
Validation loss: 2.445256575104423

Epoch: 5| Step: 10
Training loss: 1.3763515592239677
Validation loss: 2.474054555959266

Epoch: 197| Step: 0
Training loss: 1.6515637443775986
Validation loss: 2.446538915432577

Epoch: 5| Step: 1
Training loss: 1.888633372595847
Validation loss: 2.4978231971820297

Epoch: 5| Step: 2
Training loss: 1.439282348937191
Validation loss: 2.4909952692232857

Epoch: 5| Step: 3
Training loss: 1.5600073195554727
Validation loss: 2.531422411557639

Epoch: 5| Step: 4
Training loss: 1.4771541641247417
Validation loss: 2.52958007423066

Epoch: 5| Step: 5
Training loss: 1.703593758285062
Validation loss: 2.5474836340826386

Epoch: 5| Step: 6
Training loss: 1.038565437914661
Validation loss: 2.55495906301047

Epoch: 5| Step: 7
Training loss: 1.3659008402236934
Validation loss: 2.5453399666591716

Epoch: 5| Step: 8
Training loss: 1.423964421952948
Validation loss: 2.546747593624961

Epoch: 5| Step: 9
Training loss: 1.1475433190174593
Validation loss: 2.5509505546524722

Epoch: 5| Step: 10
Training loss: 1.7908472212863424
Validation loss: 2.538960234015814

Epoch: 198| Step: 0
Training loss: 1.3048078744145502
Validation loss: 2.5421170175779633

Epoch: 5| Step: 1
Training loss: 1.6787771907601172
Validation loss: 2.506201161661154

Epoch: 5| Step: 2
Training loss: 1.364226136764855
Validation loss: 2.508552959986051

Epoch: 5| Step: 3
Training loss: 1.3203520909981497
Validation loss: 2.553550638605928

Epoch: 5| Step: 4
Training loss: 1.479853036517252
Validation loss: 2.512342715351506

Epoch: 5| Step: 5
Training loss: 1.6129152192162093
Validation loss: 2.5096969314826536

Epoch: 5| Step: 6
Training loss: 1.39471348872706
Validation loss: 2.5406777201039965

Epoch: 5| Step: 7
Training loss: 1.9003295888635805
Validation loss: 2.5251158932284463

Epoch: 5| Step: 8
Training loss: 1.672425010265862
Validation loss: 2.5374532365816567

Epoch: 5| Step: 9
Training loss: 1.4072016145293542
Validation loss: 2.5344592003796937

Epoch: 5| Step: 10
Training loss: 1.0670202814014063
Validation loss: 2.5252648087094327

Epoch: 199| Step: 0
Training loss: 1.5621150496261256
Validation loss: 2.5003152094829626

Epoch: 5| Step: 1
Training loss: 1.1808518480470498
Validation loss: 2.5014709400970165

Epoch: 5| Step: 2
Training loss: 1.0119710482462967
Validation loss: 2.5524702748595867

Epoch: 5| Step: 3
Training loss: 1.6023444523058858
Validation loss: 2.5227673145193696

Epoch: 5| Step: 4
Training loss: 1.583386780020805
Validation loss: 2.5214246867980896

Epoch: 5| Step: 5
Training loss: 1.6989759951417416
Validation loss: 2.488340262520752

Epoch: 5| Step: 6
Training loss: 1.406598620117283
Validation loss: 2.492415280521178

Epoch: 5| Step: 7
Training loss: 1.4601294582923614
Validation loss: 2.4767150448916393

Epoch: 5| Step: 8
Training loss: 1.8315470692144515
Validation loss: 2.4465146174359758

Epoch: 5| Step: 9
Training loss: 1.2577772431733785
Validation loss: 2.433826015720029

Epoch: 5| Step: 10
Training loss: 1.4946632817479875
Validation loss: 2.4699057587491327

Epoch: 200| Step: 0
Training loss: 1.3842008700767796
Validation loss: 2.4408177592145055

Epoch: 5| Step: 1
Training loss: 1.598174218712955
Validation loss: 2.457309614726803

Epoch: 5| Step: 2
Training loss: 1.3574467279368283
Validation loss: 2.4886379083246126

Epoch: 5| Step: 3
Training loss: 1.4235958543078817
Validation loss: 2.5458514871405367

Epoch: 5| Step: 4
Training loss: 1.3761503002977926
Validation loss: 2.541947425117031

Epoch: 5| Step: 5
Training loss: 1.1326028564093769
Validation loss: 2.5139748739459837

Epoch: 5| Step: 6
Training loss: 1.4634767384454552
Validation loss: 2.5360556857712617

Epoch: 5| Step: 7
Training loss: 1.629135664557911
Validation loss: 2.5149177316755913

Epoch: 5| Step: 8
Training loss: 1.3029077234419744
Validation loss: 2.4929019864189086

Epoch: 5| Step: 9
Training loss: 1.3338088538672943
Validation loss: 2.4890276027361753

Epoch: 5| Step: 10
Training loss: 2.0835031313047594
Validation loss: 2.461467115451745

Epoch: 201| Step: 0
Training loss: 1.3180050069890408
Validation loss: 2.490661172213911

Epoch: 5| Step: 1
Training loss: 1.2014415407250258
Validation loss: 2.4834125677388923

Epoch: 5| Step: 2
Training loss: 1.428351272921406
Validation loss: 2.539093935182655

Epoch: 5| Step: 3
Training loss: 1.322449303720774
Validation loss: 2.529638717697754

Epoch: 5| Step: 4
Training loss: 1.4868334037924136
Validation loss: 2.560551534618919

Epoch: 5| Step: 5
Training loss: 1.018236236677804
Validation loss: 2.5425631977564103

Epoch: 5| Step: 6
Training loss: 1.6305583379065745
Validation loss: 2.5236556578800666

Epoch: 5| Step: 7
Training loss: 1.6668798389800827
Validation loss: 2.5192509173363598

Epoch: 5| Step: 8
Training loss: 1.5826760567453761
Validation loss: 2.4474528763292014

Epoch: 5| Step: 9
Training loss: 1.277492222920912
Validation loss: 2.4473496435998396

Epoch: 5| Step: 10
Training loss: 1.933573898059392
Validation loss: 2.459066205275568

Epoch: 202| Step: 0
Training loss: 1.0659769053292443
Validation loss: 2.441397271908895

Epoch: 5| Step: 1
Training loss: 1.286358488380775
Validation loss: 2.4656894727344176

Epoch: 5| Step: 2
Training loss: 1.5658114628721949
Validation loss: 2.463839290639916

Epoch: 5| Step: 3
Training loss: 1.4720013930687326
Validation loss: 2.5087528933713346

Epoch: 5| Step: 4
Training loss: 1.564480403895678
Validation loss: 2.527011459788382

Epoch: 5| Step: 5
Training loss: 1.7439443172349887
Validation loss: 2.5481772396092985

Epoch: 5| Step: 6
Training loss: 1.6486909499739486
Validation loss: 2.5482907975543077

Epoch: 5| Step: 7
Training loss: 1.380213477167105
Validation loss: 2.497897221573043

Epoch: 5| Step: 8
Training loss: 1.6204182515815457
Validation loss: 2.4621853260240765

Epoch: 5| Step: 9
Training loss: 1.3896058023095534
Validation loss: 2.4643925105441076

Epoch: 5| Step: 10
Training loss: 0.9640775101295368
Validation loss: 2.454911454588881

Epoch: 203| Step: 0
Training loss: 0.9636583034269472
Validation loss: 2.46120498279162

Epoch: 5| Step: 1
Training loss: 1.5612850806492264
Validation loss: 2.5155088254802904

Epoch: 5| Step: 2
Training loss: 1.3777349754875137
Validation loss: 2.5244543475904835

Epoch: 5| Step: 3
Training loss: 2.0092295829871905
Validation loss: 2.5312013032726592

Epoch: 5| Step: 4
Training loss: 1.4553663134808346
Validation loss: 2.5568964226929487

Epoch: 5| Step: 5
Training loss: 1.1601836846700968
Validation loss: 2.526486418254807

Epoch: 5| Step: 6
Training loss: 1.7197707179746242
Validation loss: 2.537436825895187

Epoch: 5| Step: 7
Training loss: 1.2420927287482957
Validation loss: 2.510959271647479

Epoch: 5| Step: 8
Training loss: 1.3492524797191667
Validation loss: 2.505380293332798

Epoch: 5| Step: 9
Training loss: 1.138049942214634
Validation loss: 2.4921030858403816

Epoch: 5| Step: 10
Training loss: 1.4232085964091217
Validation loss: 2.48660198938576

Epoch: 204| Step: 0
Training loss: 1.250094362511895
Validation loss: 2.4875339725256556

Epoch: 5| Step: 1
Training loss: 1.6487130752836305
Validation loss: 2.4633304065090447

Epoch: 5| Step: 2
Training loss: 1.0480718461117642
Validation loss: 2.4623783475256436

Epoch: 5| Step: 3
Training loss: 1.7620580646720347
Validation loss: 2.4922169820465307

Epoch: 5| Step: 4
Training loss: 1.0923333939672675
Validation loss: 2.450887847787939

Epoch: 5| Step: 5
Training loss: 1.1123897262097442
Validation loss: 2.4535865952925096

Epoch: 5| Step: 6
Training loss: 1.7072118318832374
Validation loss: 2.443903100952768

Epoch: 5| Step: 7
Training loss: 1.5617415303891709
Validation loss: 2.4318500780293735

Epoch: 5| Step: 8
Training loss: 1.446468076889683
Validation loss: 2.4445715221282587

Epoch: 5| Step: 9
Training loss: 1.3881245109766787
Validation loss: 2.466181095435704

Epoch: 5| Step: 10
Training loss: 1.308229948117956
Validation loss: 2.482702004484006

Epoch: 205| Step: 0
Training loss: 1.2478256865353252
Validation loss: 2.484253655765446

Epoch: 5| Step: 1
Training loss: 1.632259074333863
Validation loss: 2.4985842651860324

Epoch: 5| Step: 2
Training loss: 1.0227512067826376
Validation loss: 2.5431544889754893

Epoch: 5| Step: 3
Training loss: 1.4083420768255703
Validation loss: 2.5522879037407593

Epoch: 5| Step: 4
Training loss: 1.4349166213212678
Validation loss: 2.542119622446395

Epoch: 5| Step: 5
Training loss: 1.154618323374226
Validation loss: 2.535600873617358

Epoch: 5| Step: 6
Training loss: 1.4500621387715866
Validation loss: 2.526748756841214

Epoch: 5| Step: 7
Training loss: 1.750868309406377
Validation loss: 2.5334368027517833

Epoch: 5| Step: 8
Training loss: 1.4275199426437124
Validation loss: 2.5070975805899978

Epoch: 5| Step: 9
Training loss: 1.5206316025947693
Validation loss: 2.497981545639078

Epoch: 5| Step: 10
Training loss: 1.1115982451441182
Validation loss: 2.4767366224324237

Epoch: 206| Step: 0
Training loss: 0.9420139361644495
Validation loss: 2.4870940410565265

Epoch: 5| Step: 1
Training loss: 1.8082621787468158
Validation loss: 2.4728124798857656

Epoch: 5| Step: 2
Training loss: 1.030782188888106
Validation loss: 2.4953185015098636

Epoch: 5| Step: 3
Training loss: 1.3923611037121415
Validation loss: 2.518648241090812

Epoch: 5| Step: 4
Training loss: 1.5220379000041597
Validation loss: 2.5617020567912463

Epoch: 5| Step: 5
Training loss: 1.4298304085103346
Validation loss: 2.572194462428261

Epoch: 5| Step: 6
Training loss: 1.8243247415925887
Validation loss: 2.5787873869935383

Epoch: 5| Step: 7
Training loss: 0.9547224884364566
Validation loss: 2.5436444434000753

Epoch: 5| Step: 8
Training loss: 1.2162026413168547
Validation loss: 2.523070914986509

Epoch: 5| Step: 9
Training loss: 1.489008528060522
Validation loss: 2.44957991634368

Epoch: 5| Step: 10
Training loss: 1.4098044508748087
Validation loss: 2.4657860395238065

Epoch: 207| Step: 0
Training loss: 1.4304841537104573
Validation loss: 2.4724320969403077

Epoch: 5| Step: 1
Training loss: 1.4687050345822261
Validation loss: 2.436885691121396

Epoch: 5| Step: 2
Training loss: 1.0619676602750348
Validation loss: 2.4709622217229295

Epoch: 5| Step: 3
Training loss: 1.5530461987896405
Validation loss: 2.472704224168963

Epoch: 5| Step: 4
Training loss: 1.441163660326806
Validation loss: 2.4820446359244768

Epoch: 5| Step: 5
Training loss: 0.7312632844810486
Validation loss: 2.5575516647124235

Epoch: 5| Step: 6
Training loss: 1.8176904220208667
Validation loss: 2.544094165752594

Epoch: 5| Step: 7
Training loss: 1.1807562426859
Validation loss: 2.5257334714091066

Epoch: 5| Step: 8
Training loss: 1.3491369985829589
Validation loss: 2.5391194574295457

Epoch: 5| Step: 9
Training loss: 1.3800891848784207
Validation loss: 2.533213732923467

Epoch: 5| Step: 10
Training loss: 1.528088868382956
Validation loss: 2.5222490268256497

Epoch: 208| Step: 0
Training loss: 1.059138815779019
Validation loss: 2.495201090774261

Epoch: 5| Step: 1
Training loss: 1.2972461674858407
Validation loss: 2.4659308571466196

Epoch: 5| Step: 2
Training loss: 1.182337330119803
Validation loss: 2.4692582717949305

Epoch: 5| Step: 3
Training loss: 1.3373795695766526
Validation loss: 2.4857215495550418

Epoch: 5| Step: 4
Training loss: 1.6308846660183423
Validation loss: 2.4811273833571375

Epoch: 5| Step: 5
Training loss: 1.5273845696421489
Validation loss: 2.498450337309482

Epoch: 5| Step: 6
Training loss: 1.2228797001534384
Validation loss: 2.4942270155834287

Epoch: 5| Step: 7
Training loss: 1.5637264778691673
Validation loss: 2.5059396838022985

Epoch: 5| Step: 8
Training loss: 0.910033582025814
Validation loss: 2.4900667168616377

Epoch: 5| Step: 9
Training loss: 1.4926164419990908
Validation loss: 2.5084874668282726

Epoch: 5| Step: 10
Training loss: 1.6725492454771378
Validation loss: 2.5484689173615935

Epoch: 209| Step: 0
Training loss: 0.8628334851944262
Validation loss: 2.538785540776083

Epoch: 5| Step: 1
Training loss: 1.589898635704165
Validation loss: 2.592869778881703

Epoch: 5| Step: 2
Training loss: 1.4233370798911844
Validation loss: 2.6102956427778796

Epoch: 5| Step: 3
Training loss: 1.1017682579991184
Validation loss: 2.5706241315394807

Epoch: 5| Step: 4
Training loss: 1.012291352237376
Validation loss: 2.5510380130819157

Epoch: 5| Step: 5
Training loss: 1.4724135464481152
Validation loss: 2.525206389551719

Epoch: 5| Step: 6
Training loss: 1.451836127205405
Validation loss: 2.5116750311819565

Epoch: 5| Step: 7
Training loss: 1.4299354546658734
Validation loss: 2.509463766663688

Epoch: 5| Step: 8
Training loss: 1.6406367710236214
Validation loss: 2.4919462176867424

Epoch: 5| Step: 9
Training loss: 1.3745588982244852
Validation loss: 2.490985959395679

Epoch: 5| Step: 10
Training loss: 1.272490166586783
Validation loss: 2.4802272362212725

Epoch: 210| Step: 0
Training loss: 1.36784373201756
Validation loss: 2.457780817288935

Epoch: 5| Step: 1
Training loss: 1.232692876120065
Validation loss: 2.426402590177639

Epoch: 5| Step: 2
Training loss: 1.5341672550817076
Validation loss: 2.453949612486416

Epoch: 5| Step: 3
Training loss: 1.2487036181476519
Validation loss: 2.442856846019665

Epoch: 5| Step: 4
Training loss: 1.785445909768819
Validation loss: 2.456048460155186

Epoch: 5| Step: 5
Training loss: 1.1862776136651338
Validation loss: 2.449992171110327

Epoch: 5| Step: 6
Training loss: 1.3165343813696972
Validation loss: 2.4778308875277775

Epoch: 5| Step: 7
Training loss: 1.2069793986321946
Validation loss: 2.4832623689296778

Epoch: 5| Step: 8
Training loss: 1.6649653175109698
Validation loss: 2.475470497834687

Epoch: 5| Step: 9
Training loss: 0.932857622240578
Validation loss: 2.4473279399965198

Epoch: 5| Step: 10
Training loss: 0.9290756327820092
Validation loss: 2.4895210249734907

Epoch: 211| Step: 0
Training loss: 1.441865511872516
Validation loss: 2.477232191673116

Epoch: 5| Step: 1
Training loss: 1.0406366341888478
Validation loss: 2.4670944166277864

Epoch: 5| Step: 2
Training loss: 0.8220608925274022
Validation loss: 2.487931684531124

Epoch: 5| Step: 3
Training loss: 1.5196965380209069
Validation loss: 2.511729938579953

Epoch: 5| Step: 4
Training loss: 1.4743057847927492
Validation loss: 2.5136657720379

Epoch: 5| Step: 5
Training loss: 1.1400440774728549
Validation loss: 2.5125918911993486

Epoch: 5| Step: 6
Training loss: 1.0317353349202192
Validation loss: 2.5260412681553057

Epoch: 5| Step: 7
Training loss: 1.6567826764010147
Validation loss: 2.529122660215655

Epoch: 5| Step: 8
Training loss: 1.7879557955438516
Validation loss: 2.49974453759122

Epoch: 5| Step: 9
Training loss: 0.9820976860012911
Validation loss: 2.4941340302074297

Epoch: 5| Step: 10
Training loss: 1.3072589044404443
Validation loss: 2.501282067884553

Epoch: 212| Step: 0
Training loss: 1.3026350861420537
Validation loss: 2.5056459947963416

Epoch: 5| Step: 1
Training loss: 1.2196537481706173
Validation loss: 2.503578235068083

Epoch: 5| Step: 2
Training loss: 1.249656153116664
Validation loss: 2.4777518513228967

Epoch: 5| Step: 3
Training loss: 1.3722597907702712
Validation loss: 2.4942855472291856

Epoch: 5| Step: 4
Training loss: 1.601092460321328
Validation loss: 2.498554221863946

Epoch: 5| Step: 5
Training loss: 1.1127661868760494
Validation loss: 2.4653424003558704

Epoch: 5| Step: 6
Training loss: 1.4927997231929886
Validation loss: 2.4621481651232378

Epoch: 5| Step: 7
Training loss: 1.1340008520597455
Validation loss: 2.4814571283107267

Epoch: 5| Step: 8
Training loss: 1.3855207829563465
Validation loss: 2.4696824605292855

Epoch: 5| Step: 9
Training loss: 1.5158158801505146
Validation loss: 2.453125101369941

Epoch: 5| Step: 10
Training loss: 0.8384967381226814
Validation loss: 2.5046795661008443

Epoch: 213| Step: 0
Training loss: 1.3216643325637534
Validation loss: 2.5172002781480334

Epoch: 5| Step: 1
Training loss: 1.7408153108011142
Validation loss: 2.504364137157983

Epoch: 5| Step: 2
Training loss: 1.2492619242790886
Validation loss: 2.498453367358186

Epoch: 5| Step: 3
Training loss: 1.3437615771127602
Validation loss: 2.503992141894509

Epoch: 5| Step: 4
Training loss: 1.0983145155232883
Validation loss: 2.508511318860672

Epoch: 5| Step: 5
Training loss: 1.4387877128424271
Validation loss: 2.456671465041446

Epoch: 5| Step: 6
Training loss: 1.3775364282848679
Validation loss: 2.4492990643795967

Epoch: 5| Step: 7
Training loss: 1.5420572799849683
Validation loss: 2.468972004671964

Epoch: 5| Step: 8
Training loss: 0.9371702567991765
Validation loss: 2.5063010916888913

Epoch: 5| Step: 9
Training loss: 1.1444839103204383
Validation loss: 2.5025344481580496

Epoch: 5| Step: 10
Training loss: 0.7821774508981009
Validation loss: 2.5291709631321324

Epoch: 214| Step: 0
Training loss: 1.6080436755364766
Validation loss: 2.5188575825267563

Epoch: 5| Step: 1
Training loss: 1.426159784939168
Validation loss: 2.5337991724423694

Epoch: 5| Step: 2
Training loss: 1.310035435219157
Validation loss: 2.535018206494163

Epoch: 5| Step: 3
Training loss: 1.4899759731019633
Validation loss: 2.492802318335668

Epoch: 5| Step: 4
Training loss: 1.3363541070619587
Validation loss: 2.4275730136751537

Epoch: 5| Step: 5
Training loss: 1.0102356751881774
Validation loss: 2.431435279166872

Epoch: 5| Step: 6
Training loss: 1.2173777459741604
Validation loss: 2.4317314678219857

Epoch: 5| Step: 7
Training loss: 1.5464917103014577
Validation loss: 2.392055292988572

Epoch: 5| Step: 8
Training loss: 1.1666763963747755
Validation loss: 2.4205070164975813

Epoch: 5| Step: 9
Training loss: 1.0531739854598061
Validation loss: 2.4165132309094113

Epoch: 5| Step: 10
Training loss: 0.8318799736510526
Validation loss: 2.439921845859298

Epoch: 215| Step: 0
Training loss: 0.7927142331425545
Validation loss: 2.4740819915453516

Epoch: 5| Step: 1
Training loss: 1.0786190283204746
Validation loss: 2.4863631840468905

Epoch: 5| Step: 2
Training loss: 0.8581817665967059
Validation loss: 2.4668263856195347

Epoch: 5| Step: 3
Training loss: 1.4985003127058618
Validation loss: 2.4896370230695064

Epoch: 5| Step: 4
Training loss: 1.2516764842502137
Validation loss: 2.4937721872176684

Epoch: 5| Step: 5
Training loss: 1.4425198354960533
Validation loss: 2.4820100726041177

Epoch: 5| Step: 6
Training loss: 1.5926824247832267
Validation loss: 2.47134299999553

Epoch: 5| Step: 7
Training loss: 1.5360029763500862
Validation loss: 2.4879250598847595

Epoch: 5| Step: 8
Training loss: 1.2345206742098631
Validation loss: 2.4919037826018475

Epoch: 5| Step: 9
Training loss: 1.1700487275043279
Validation loss: 2.5604685402701013

Epoch: 5| Step: 10
Training loss: 1.367438113540016
Validation loss: 2.5389857298396485

Epoch: 216| Step: 0
Training loss: 1.6937068947800311
Validation loss: 2.5532673750858748

Epoch: 5| Step: 1
Training loss: 0.8716234042394997
Validation loss: 2.5699816397123656

Epoch: 5| Step: 2
Training loss: 1.447998684908865
Validation loss: 2.5368732140799173

Epoch: 5| Step: 3
Training loss: 1.5430239124336476
Validation loss: 2.553605087327419

Epoch: 5| Step: 4
Training loss: 1.2586569942446877
Validation loss: 2.5160463429055953

Epoch: 5| Step: 5
Training loss: 0.9675209493611483
Validation loss: 2.5073190824130926

Epoch: 5| Step: 6
Training loss: 0.833904539481416
Validation loss: 2.50437525213437

Epoch: 5| Step: 7
Training loss: 1.4149967711179308
Validation loss: 2.4509631537519487

Epoch: 5| Step: 8
Training loss: 1.0683407964956548
Validation loss: 2.4546057445818787

Epoch: 5| Step: 9
Training loss: 1.1564432962042779
Validation loss: 2.4507681149613463

Epoch: 5| Step: 10
Training loss: 1.4849479774071106
Validation loss: 2.4662683115666164

Epoch: 217| Step: 0
Training loss: 1.1020134618251927
Validation loss: 2.4420661207115004

Epoch: 5| Step: 1
Training loss: 1.3723097405643712
Validation loss: 2.5049198409119393

Epoch: 5| Step: 2
Training loss: 1.0493754232291026
Validation loss: 2.5500822866708432

Epoch: 5| Step: 3
Training loss: 1.2671180677853702
Validation loss: 2.5357319398004114

Epoch: 5| Step: 4
Training loss: 1.3102962521456134
Validation loss: 2.5337990287699803

Epoch: 5| Step: 5
Training loss: 1.4418321099286961
Validation loss: 2.536336689995427

Epoch: 5| Step: 6
Training loss: 0.9903533984400353
Validation loss: 2.492192908745463

Epoch: 5| Step: 7
Training loss: 1.4116509882038648
Validation loss: 2.484180824914306

Epoch: 5| Step: 8
Training loss: 1.1650197746170312
Validation loss: 2.4667410817543725

Epoch: 5| Step: 9
Training loss: 1.416350058163204
Validation loss: 2.4588137623521615

Epoch: 5| Step: 10
Training loss: 1.2508637305185006
Validation loss: 2.421402861970736

Epoch: 218| Step: 0
Training loss: 1.3341531716561121
Validation loss: 2.4361661233033884

Epoch: 5| Step: 1
Training loss: 1.2247793758005119
Validation loss: 2.400442290484538

Epoch: 5| Step: 2
Training loss: 1.3973991758932411
Validation loss: 2.40701297191076

Epoch: 5| Step: 3
Training loss: 1.0527569090743987
Validation loss: 2.4902520932768226

Epoch: 5| Step: 4
Training loss: 1.0360272467907563
Validation loss: 2.498754494621095

Epoch: 5| Step: 5
Training loss: 1.3677554449531892
Validation loss: 2.5469571378472935

Epoch: 5| Step: 6
Training loss: 1.261656815747833
Validation loss: 2.5842201134616527

Epoch: 5| Step: 7
Training loss: 1.1878245060892771
Validation loss: 2.599324203195402

Epoch: 5| Step: 8
Training loss: 1.4519873647113786
Validation loss: 2.568263070453135

Epoch: 5| Step: 9
Training loss: 1.3505525288342413
Validation loss: 2.5425299209491152

Epoch: 5| Step: 10
Training loss: 1.1252213896034116
Validation loss: 2.486357960587508

Epoch: 219| Step: 0
Training loss: 0.9409269640284214
Validation loss: 2.456377234231172

Epoch: 5| Step: 1
Training loss: 0.9487331074252421
Validation loss: 2.3924648168511307

Epoch: 5| Step: 2
Training loss: 1.6376940750545042
Validation loss: 2.399446715008624

Epoch: 5| Step: 3
Training loss: 1.2853988835832215
Validation loss: 2.4040638043367064

Epoch: 5| Step: 4
Training loss: 1.548906552805275
Validation loss: 2.4428996377596546

Epoch: 5| Step: 5
Training loss: 1.303006808549332
Validation loss: 2.50466025284325

Epoch: 5| Step: 6
Training loss: 1.329119590395966
Validation loss: 2.558609414790474

Epoch: 5| Step: 7
Training loss: 1.1485717072212027
Validation loss: 2.580417830378204

Epoch: 5| Step: 8
Training loss: 0.7735641067610246
Validation loss: 2.582578636809636

Epoch: 5| Step: 9
Training loss: 1.200440570302447
Validation loss: 2.5149432780665717

Epoch: 5| Step: 10
Training loss: 1.6727132389314838
Validation loss: 2.51325156514783

Epoch: 220| Step: 0
Training loss: 1.553120959639331
Validation loss: 2.4423876461212424

Epoch: 5| Step: 1
Training loss: 1.1639894296126838
Validation loss: 2.392156369051395

Epoch: 5| Step: 2
Training loss: 1.1849529657807818
Validation loss: 2.368555819913261

Epoch: 5| Step: 3
Training loss: 1.0763066756049515
Validation loss: 2.348811240738819

Epoch: 5| Step: 4
Training loss: 0.7775722148758428
Validation loss: 2.3207527119541327

Epoch: 5| Step: 5
Training loss: 1.3278860887051724
Validation loss: 2.3807867370651685

Epoch: 5| Step: 6
Training loss: 1.0392501776288807
Validation loss: 2.382318556795541

Epoch: 5| Step: 7
Training loss: 1.6668043159227586
Validation loss: 2.42918101241607

Epoch: 5| Step: 8
Training loss: 1.3262949283910443
Validation loss: 2.429511706566144

Epoch: 5| Step: 9
Training loss: 1.3965297024713237
Validation loss: 2.4622964503266176

Epoch: 5| Step: 10
Training loss: 1.0365933788761545
Validation loss: 2.4608836813838293

Epoch: 221| Step: 0
Training loss: 1.3089982503612647
Validation loss: 2.4633411384046022

Epoch: 5| Step: 1
Training loss: 1.4709500818502605
Validation loss: 2.489305394631516

Epoch: 5| Step: 2
Training loss: 1.0460714985971595
Validation loss: 2.4787184993623868

Epoch: 5| Step: 3
Training loss: 0.9469679217177426
Validation loss: 2.453950670767071

Epoch: 5| Step: 4
Training loss: 1.4805945189507892
Validation loss: 2.484517797193445

Epoch: 5| Step: 5
Training loss: 1.1381114804314882
Validation loss: 2.4997556900299926

Epoch: 5| Step: 6
Training loss: 1.3937321358121757
Validation loss: 2.448719699517648

Epoch: 5| Step: 7
Training loss: 0.9213778561568664
Validation loss: 2.427185642311838

Epoch: 5| Step: 8
Training loss: 1.1571094308798662
Validation loss: 2.3825615594565392

Epoch: 5| Step: 9
Training loss: 1.4940231775735453
Validation loss: 2.3376401295405933

Epoch: 5| Step: 10
Training loss: 1.1973186935437456
Validation loss: 2.3396738441846825

Epoch: 222| Step: 0
Training loss: 1.2284507552397088
Validation loss: 2.346967111866329

Epoch: 5| Step: 1
Training loss: 1.2192190685904896
Validation loss: 2.373852159356309

Epoch: 5| Step: 2
Training loss: 1.1837219571716404
Validation loss: 2.3146543974056577

Epoch: 5| Step: 3
Training loss: 1.412915054038382
Validation loss: 2.3522664019149833

Epoch: 5| Step: 4
Training loss: 1.2741864114349635
Validation loss: 2.360990173947127

Epoch: 5| Step: 5
Training loss: 0.8804678036025477
Validation loss: 2.373737159219982

Epoch: 5| Step: 6
Training loss: 1.5885782289727
Validation loss: 2.388597171917875

Epoch: 5| Step: 7
Training loss: 0.962441670520535
Validation loss: 2.4222247508611794

Epoch: 5| Step: 8
Training loss: 1.154336376772937
Validation loss: 2.4569884518762777

Epoch: 5| Step: 9
Training loss: 1.2878584816380687
Validation loss: 2.480260322540216

Epoch: 5| Step: 10
Training loss: 0.9269492913258106
Validation loss: 2.4513030796866033

Epoch: 223| Step: 0
Training loss: 1.0317461380882813
Validation loss: 2.486802546375791

Epoch: 5| Step: 1
Training loss: 1.3242433708850299
Validation loss: 2.500458692699149

Epoch: 5| Step: 2
Training loss: 1.1534459936283472
Validation loss: 2.52614463001756

Epoch: 5| Step: 3
Training loss: 1.4898337129315808
Validation loss: 2.5147577644506227

Epoch: 5| Step: 4
Training loss: 0.8960581578683438
Validation loss: 2.4925824680221718

Epoch: 5| Step: 5
Training loss: 1.090890689174465
Validation loss: 2.4477632867695434

Epoch: 5| Step: 6
Training loss: 1.3705989890494097
Validation loss: 2.4417643386583654

Epoch: 5| Step: 7
Training loss: 1.1903913333713212
Validation loss: 2.4242838661091826

Epoch: 5| Step: 8
Training loss: 0.9976970858420187
Validation loss: 2.397353718108193

Epoch: 5| Step: 9
Training loss: 1.4061367413158368
Validation loss: 2.40039951509685

Epoch: 5| Step: 10
Training loss: 1.0978348338968822
Validation loss: 2.417171693535125

Epoch: 224| Step: 0
Training loss: 0.9464028430793635
Validation loss: 2.405808174770716

Epoch: 5| Step: 1
Training loss: 1.3874362862194722
Validation loss: 2.4544024376170257

Epoch: 5| Step: 2
Training loss: 1.0457537895642843
Validation loss: 2.4616881028472286

Epoch: 5| Step: 3
Training loss: 1.3690669193644922
Validation loss: 2.4800116413258704

Epoch: 5| Step: 4
Training loss: 1.0140174467779117
Validation loss: 2.47495269290994

Epoch: 5| Step: 5
Training loss: 1.1513394392065535
Validation loss: 2.456467590154566

Epoch: 5| Step: 6
Training loss: 1.0082255854981323
Validation loss: 2.442332105084837

Epoch: 5| Step: 7
Training loss: 1.3557170013964441
Validation loss: 2.4136072707857057

Epoch: 5| Step: 8
Training loss: 1.3339115865796587
Validation loss: 2.3850199764559923

Epoch: 5| Step: 9
Training loss: 1.2394683634978096
Validation loss: 2.3599578228837292

Epoch: 5| Step: 10
Training loss: 1.1240556780237192
Validation loss: 2.389322703505876

Epoch: 225| Step: 0
Training loss: 1.4190867826714932
Validation loss: 2.3735388264059365

Epoch: 5| Step: 1
Training loss: 0.8898671590055308
Validation loss: 2.3870115972381085

Epoch: 5| Step: 2
Training loss: 1.168067647261798
Validation loss: 2.4102058107053024

Epoch: 5| Step: 3
Training loss: 1.1724206289987735
Validation loss: 2.42454943436082

Epoch: 5| Step: 4
Training loss: 1.1124886887221774
Validation loss: 2.4268103659986404

Epoch: 5| Step: 5
Training loss: 1.180060220410194
Validation loss: 2.445088899688431

Epoch: 5| Step: 6
Training loss: 1.6025244824329128
Validation loss: 2.4921782224003297

Epoch: 5| Step: 7
Training loss: 1.023205330409347
Validation loss: 2.47462463697943

Epoch: 5| Step: 8
Training loss: 1.3201751186066744
Validation loss: 2.4813374127528167

Epoch: 5| Step: 9
Training loss: 1.049655126519323
Validation loss: 2.4531397613003936

Epoch: 5| Step: 10
Training loss: 0.6773813521035793
Validation loss: 2.4484117829769576

Epoch: 226| Step: 0
Training loss: 1.2397961420486863
Validation loss: 2.4069597603562816

Epoch: 5| Step: 1
Training loss: 1.2281625115875665
Validation loss: 2.386986560114706

Epoch: 5| Step: 2
Training loss: 1.2874803948993014
Validation loss: 2.4009413643617417

Epoch: 5| Step: 3
Training loss: 0.982298007080284
Validation loss: 2.3999338503663368

Epoch: 5| Step: 4
Training loss: 0.8929140222687992
Validation loss: 2.4178999306017244

Epoch: 5| Step: 5
Training loss: 0.9151952197059253
Validation loss: 2.4066146981198773

Epoch: 5| Step: 6
Training loss: 1.306118391790037
Validation loss: 2.417330741518535

Epoch: 5| Step: 7
Training loss: 1.1945392875326133
Validation loss: 2.4637036974748603

Epoch: 5| Step: 8
Training loss: 0.9077794224922484
Validation loss: 2.468530151081888

Epoch: 5| Step: 9
Training loss: 1.1623683608801136
Validation loss: 2.4753667723525203

Epoch: 5| Step: 10
Training loss: 1.5476095594038421
Validation loss: 2.464465220383036

Epoch: 227| Step: 0
Training loss: 1.2232453995646795
Validation loss: 2.4688968170859353

Epoch: 5| Step: 1
Training loss: 1.0847402325832454
Validation loss: 2.4512515470313687

Epoch: 5| Step: 2
Training loss: 1.4289987708287328
Validation loss: 2.441306882218405

Epoch: 5| Step: 3
Training loss: 1.2723164216519076
Validation loss: 2.421836877602888

Epoch: 5| Step: 4
Training loss: 1.2548238183786153
Validation loss: 2.40001265435318

Epoch: 5| Step: 5
Training loss: 0.9343188355065383
Validation loss: 2.406177009846675

Epoch: 5| Step: 6
Training loss: 1.133160189183723
Validation loss: 2.3993541765097532

Epoch: 5| Step: 7
Training loss: 1.131255348993796
Validation loss: 2.389217214477945

Epoch: 5| Step: 8
Training loss: 0.9063488150031146
Validation loss: 2.3974151340292353

Epoch: 5| Step: 9
Training loss: 1.1184871556615037
Validation loss: 2.4087594281661993

Epoch: 5| Step: 10
Training loss: 1.07396620122554
Validation loss: 2.4149067410657934

Epoch: 228| Step: 0
Training loss: 1.1750255703680141
Validation loss: 2.4367236964461307

Epoch: 5| Step: 1
Training loss: 1.0548824553973775
Validation loss: 2.451856159739878

Epoch: 5| Step: 2
Training loss: 0.6939897921839357
Validation loss: 2.4340192460057994

Epoch: 5| Step: 3
Training loss: 1.4844872683181167
Validation loss: 2.4387621413482794

Epoch: 5| Step: 4
Training loss: 1.170770658849618
Validation loss: 2.4194254739937042

Epoch: 5| Step: 5
Training loss: 1.0552508509744785
Validation loss: 2.4166162830004487

Epoch: 5| Step: 6
Training loss: 1.2777823065709746
Validation loss: 2.404827696921228

Epoch: 5| Step: 7
Training loss: 1.3642124613581021
Validation loss: 2.416186103168402

Epoch: 5| Step: 8
Training loss: 0.8913792545065681
Validation loss: 2.3830699817178433

Epoch: 5| Step: 9
Training loss: 1.1324327555854483
Validation loss: 2.3620585057551144

Epoch: 5| Step: 10
Training loss: 1.0167765031694334
Validation loss: 2.4049836699242397

Epoch: 229| Step: 0
Training loss: 0.8832363360309285
Validation loss: 2.376549049902418

Epoch: 5| Step: 1
Training loss: 1.0501758859549886
Validation loss: 2.4112067147910534

Epoch: 5| Step: 2
Training loss: 1.1319918060275764
Validation loss: 2.4221914644983227

Epoch: 5| Step: 3
Training loss: 0.9932303167428831
Validation loss: 2.5062564672092518

Epoch: 5| Step: 4
Training loss: 0.9633797724353049
Validation loss: 2.4554527081080026

Epoch: 5| Step: 5
Training loss: 1.1702803888741253
Validation loss: 2.5028017341756166

Epoch: 5| Step: 6
Training loss: 1.0806837263857147
Validation loss: 2.465664467205293

Epoch: 5| Step: 7
Training loss: 1.590437269842734
Validation loss: 2.476849144305107

Epoch: 5| Step: 8
Training loss: 1.322479816708212
Validation loss: 2.490043858754965

Epoch: 5| Step: 9
Training loss: 0.9256460356656349
Validation loss: 2.4793832845783217

Epoch: 5| Step: 10
Training loss: 1.1826913748922958
Validation loss: 2.4579212732570217

Epoch: 230| Step: 0
Training loss: 0.9286649193177919
Validation loss: 2.443368601892045

Epoch: 5| Step: 1
Training loss: 1.148107104881012
Validation loss: 2.4484737347986085

Epoch: 5| Step: 2
Training loss: 1.3618346138192106
Validation loss: 2.421442291315068

Epoch: 5| Step: 3
Training loss: 0.9911962047665885
Validation loss: 2.4017663453376055

Epoch: 5| Step: 4
Training loss: 1.2934856937238093
Validation loss: 2.375796859555101

Epoch: 5| Step: 5
Training loss: 0.441777689118345
Validation loss: 2.396587012164434

Epoch: 5| Step: 6
Training loss: 0.7165682061521749
Validation loss: 2.3952535986311587

Epoch: 5| Step: 7
Training loss: 1.5436205296143937
Validation loss: 2.3571252090856367

Epoch: 5| Step: 8
Training loss: 1.3007825788428131
Validation loss: 2.359623655284943

Epoch: 5| Step: 9
Training loss: 1.0291107993979263
Validation loss: 2.3651883322265332

Epoch: 5| Step: 10
Training loss: 1.1781976652123223
Validation loss: 2.391246586428337

Epoch: 231| Step: 0
Training loss: 1.0079262839262333
Validation loss: 2.387818558541501

Epoch: 5| Step: 1
Training loss: 1.2569392709408975
Validation loss: 2.4044886368355654

Epoch: 5| Step: 2
Training loss: 0.5490599173331487
Validation loss: 2.3856588597950057

Epoch: 5| Step: 3
Training loss: 1.095090807193381
Validation loss: 2.392602969139616

Epoch: 5| Step: 4
Training loss: 0.7635283664587561
Validation loss: 2.3813118310764914

Epoch: 5| Step: 5
Training loss: 1.1186201073452908
Validation loss: 2.4035090670414814

Epoch: 5| Step: 6
Training loss: 1.1131228685653132
Validation loss: 2.4134733189484026

Epoch: 5| Step: 7
Training loss: 0.9582506779947726
Validation loss: 2.4046437053723237

Epoch: 5| Step: 8
Training loss: 1.049725310407528
Validation loss: 2.387354895742534

Epoch: 5| Step: 9
Training loss: 1.5404651272598913
Validation loss: 2.3943747079988644

Epoch: 5| Step: 10
Training loss: 1.5040654878410307
Validation loss: 2.3715654656631426

Epoch: 232| Step: 0
Training loss: 1.1520389994437337
Validation loss: 2.39904921333546

Epoch: 5| Step: 1
Training loss: 1.040923438365168
Validation loss: 2.3902396987352645

Epoch: 5| Step: 2
Training loss: 0.7749274958258523
Validation loss: 2.390225660147069

Epoch: 5| Step: 3
Training loss: 1.1001064877551354
Validation loss: 2.4352224030405463

Epoch: 5| Step: 4
Training loss: 1.183755190071563
Validation loss: 2.4441605127169987

Epoch: 5| Step: 5
Training loss: 1.1498868969570255
Validation loss: 2.4368351507380765

Epoch: 5| Step: 6
Training loss: 1.2088454849257932
Validation loss: 2.4486427844746865

Epoch: 5| Step: 7
Training loss: 1.2823698220914908
Validation loss: 2.4649085920450724

Epoch: 5| Step: 8
Training loss: 1.5004286948183352
Validation loss: 2.4157228214412676

Epoch: 5| Step: 9
Training loss: 0.7929294369728793
Validation loss: 2.4137242310480755

Epoch: 5| Step: 10
Training loss: 0.560622233465847
Validation loss: 2.4146663129530195

Epoch: 233| Step: 0
Training loss: 1.4846838378861085
Validation loss: 2.4242846137500322

Epoch: 5| Step: 1
Training loss: 1.483786616913996
Validation loss: 2.414772757270887

Epoch: 5| Step: 2
Training loss: 0.5542996353392526
Validation loss: 2.3748571118655026

Epoch: 5| Step: 3
Training loss: 0.9850811922913709
Validation loss: 2.4004039526569008

Epoch: 5| Step: 4
Training loss: 0.733460079604586
Validation loss: 2.4293137583301174

Epoch: 5| Step: 5
Training loss: 1.102378056328271
Validation loss: 2.4118449880238684

Epoch: 5| Step: 6
Training loss: 1.052915992711441
Validation loss: 2.406329737091774

Epoch: 5| Step: 7
Training loss: 1.1677513302938585
Validation loss: 2.4071010378571818

Epoch: 5| Step: 8
Training loss: 1.0503885322342832
Validation loss: 2.407250079204608

Epoch: 5| Step: 9
Training loss: 1.1519828101802851
Validation loss: 2.4654872981072997

Epoch: 5| Step: 10
Training loss: 0.9548543656236149
Validation loss: 2.459080626496456

Epoch: 234| Step: 0
Training loss: 0.8905941138014962
Validation loss: 2.461954811101526

Epoch: 5| Step: 1
Training loss: 1.1588474173474306
Validation loss: 2.4434683440601592

Epoch: 5| Step: 2
Training loss: 0.9466425783546936
Validation loss: 2.4205034207358826

Epoch: 5| Step: 3
Training loss: 1.2922136112697773
Validation loss: 2.4249546991059603

Epoch: 5| Step: 4
Training loss: 1.5095743746609693
Validation loss: 2.4018989626777465

Epoch: 5| Step: 5
Training loss: 0.9052925972006651
Validation loss: 2.4331253526174237

Epoch: 5| Step: 6
Training loss: 0.8885628434251855
Validation loss: 2.3838197835430885

Epoch: 5| Step: 7
Training loss: 1.0264879150236677
Validation loss: 2.404156254861541

Epoch: 5| Step: 8
Training loss: 1.2875635853593344
Validation loss: 2.3702513420112714

Epoch: 5| Step: 9
Training loss: 1.119418710508014
Validation loss: 2.3973580746878587

Epoch: 5| Step: 10
Training loss: 0.6388344047529771
Validation loss: 2.4096038792215677

Epoch: 235| Step: 0
Training loss: 1.2318223078203379
Validation loss: 2.401574480352184

Epoch: 5| Step: 1
Training loss: 0.7939947847199859
Validation loss: 2.392695781601573

Epoch: 5| Step: 2
Training loss: 0.6489224286706804
Validation loss: 2.41348176836592

Epoch: 5| Step: 3
Training loss: 0.9124438960973933
Validation loss: 2.387472765186887

Epoch: 5| Step: 4
Training loss: 1.3707798873005816
Validation loss: 2.4050881060752825

Epoch: 5| Step: 5
Training loss: 0.8808921926267838
Validation loss: 2.425267633922971

Epoch: 5| Step: 6
Training loss: 1.3342851827441862
Validation loss: 2.45898454597996

Epoch: 5| Step: 7
Training loss: 0.9016261694786984
Validation loss: 2.4859617844798723

Epoch: 5| Step: 8
Training loss: 1.4103029972553356
Validation loss: 2.444162767816365

Epoch: 5| Step: 9
Training loss: 1.2258466830759567
Validation loss: 2.4168860838351347

Epoch: 5| Step: 10
Training loss: 0.9347898729609082
Validation loss: 2.395034933791743

Epoch: 236| Step: 0
Training loss: 0.8596882682638781
Validation loss: 2.4110200233301207

Epoch: 5| Step: 1
Training loss: 1.1106332440089095
Validation loss: 2.4321573391673215

Epoch: 5| Step: 2
Training loss: 1.3330588753669892
Validation loss: 2.412054614649089

Epoch: 5| Step: 3
Training loss: 1.0178017398030033
Validation loss: 2.4321002505883325

Epoch: 5| Step: 4
Training loss: 1.275998261420641
Validation loss: 2.4654173521534193

Epoch: 5| Step: 5
Training loss: 1.2087565809857732
Validation loss: 2.4231307368960295

Epoch: 5| Step: 6
Training loss: 0.5847179691565754
Validation loss: 2.469910825500721

Epoch: 5| Step: 7
Training loss: 1.0656395695828595
Validation loss: 2.429576699134494

Epoch: 5| Step: 8
Training loss: 0.8840440245363465
Validation loss: 2.362836082631773

Epoch: 5| Step: 9
Training loss: 1.2499463069828103
Validation loss: 2.354128545883883

Epoch: 5| Step: 10
Training loss: 1.0384360124162368
Validation loss: 2.3190464468545655

Epoch: 237| Step: 0
Training loss: 0.9489808589021931
Validation loss: 2.3493564472886086

Epoch: 5| Step: 1
Training loss: 1.2492777168141327
Validation loss: 2.308814693844388

Epoch: 5| Step: 2
Training loss: 1.0241895635128622
Validation loss: 2.3439754123374628

Epoch: 5| Step: 3
Training loss: 1.2017054915450058
Validation loss: 2.361221371182821

Epoch: 5| Step: 4
Training loss: 0.9977718803054002
Validation loss: 2.347643431795954

Epoch: 5| Step: 5
Training loss: 0.9745902936821969
Validation loss: 2.3287767730000497

Epoch: 5| Step: 6
Training loss: 1.0176304897080148
Validation loss: 2.360955305425901

Epoch: 5| Step: 7
Training loss: 0.9758509981319458
Validation loss: 2.3746880875380234

Epoch: 5| Step: 8
Training loss: 1.0800701230737433
Validation loss: 2.3755526630951596

Epoch: 5| Step: 9
Training loss: 0.9684129251597614
Validation loss: 2.3649548068074595

Epoch: 5| Step: 10
Training loss: 1.293718978952214
Validation loss: 2.396694340731863

Epoch: 238| Step: 0
Training loss: 1.170617051471827
Validation loss: 2.3753079515337436

Epoch: 5| Step: 1
Training loss: 0.8734656232151667
Validation loss: 2.392853151795565

Epoch: 5| Step: 2
Training loss: 1.1670953042668102
Validation loss: 2.379853681251328

Epoch: 5| Step: 3
Training loss: 0.723341498380128
Validation loss: 2.4099805636944005

Epoch: 5| Step: 4
Training loss: 1.0569450800043423
Validation loss: 2.4190384480010767

Epoch: 5| Step: 5
Training loss: 0.9714806127532888
Validation loss: 2.447380637339952

Epoch: 5| Step: 6
Training loss: 1.1166280666246435
Validation loss: 2.417896896620794

Epoch: 5| Step: 7
Training loss: 1.3742129934601308
Validation loss: 2.4448013555111907

Epoch: 5| Step: 8
Training loss: 0.8876873893090437
Validation loss: 2.4534806991082765

Epoch: 5| Step: 9
Training loss: 0.821927723807081
Validation loss: 2.4285726641597276

Epoch: 5| Step: 10
Training loss: 1.408639192191988
Validation loss: 2.425914149188936

Epoch: 239| Step: 0
Training loss: 1.0483036825679952
Validation loss: 2.3818806521191664

Epoch: 5| Step: 1
Training loss: 1.0693845415609355
Validation loss: 2.3806729592378533

Epoch: 5| Step: 2
Training loss: 1.4143499429988982
Validation loss: 2.3832374326998744

Epoch: 5| Step: 3
Training loss: 0.9759472549248995
Validation loss: 2.362087165114642

Epoch: 5| Step: 4
Training loss: 0.8729682221282188
Validation loss: 2.3766015443502218

Epoch: 5| Step: 5
Training loss: 0.6994472961285166
Validation loss: 2.379175475057384

Epoch: 5| Step: 6
Training loss: 1.2254490749341476
Validation loss: 2.3986179585475718

Epoch: 5| Step: 7
Training loss: 0.8055941094749475
Validation loss: 2.393847795106637

Epoch: 5| Step: 8
Training loss: 1.0239229870759443
Validation loss: 2.4311389363225206

Epoch: 5| Step: 9
Training loss: 1.1138609330645355
Validation loss: 2.422439717888085

Epoch: 5| Step: 10
Training loss: 1.079420334350446
Validation loss: 2.4456710764823377

Epoch: 240| Step: 0
Training loss: 1.0188663112029812
Validation loss: 2.439098127692626

Epoch: 5| Step: 1
Training loss: 0.9042357718666919
Validation loss: 2.40446071210315

Epoch: 5| Step: 2
Training loss: 0.9040935773943929
Validation loss: 2.4265528748860734

Epoch: 5| Step: 3
Training loss: 0.9701861534234637
Validation loss: 2.4704761184725004

Epoch: 5| Step: 4
Training loss: 1.109322667566555
Validation loss: 2.433416182298398

Epoch: 5| Step: 5
Training loss: 1.1974216378202345
Validation loss: 2.417472809037384

Epoch: 5| Step: 6
Training loss: 0.9805389622325028
Validation loss: 2.4220626499016746

Epoch: 5| Step: 7
Training loss: 1.2373480905870256
Validation loss: 2.407519374461881

Epoch: 5| Step: 8
Training loss: 1.0532745504173278
Validation loss: 2.3493338569559845

Epoch: 5| Step: 9
Training loss: 0.8462876905108383
Validation loss: 2.3926901538329375

Epoch: 5| Step: 10
Training loss: 1.1113674378104013
Validation loss: 2.355665675080889

Epoch: 241| Step: 0
Training loss: 1.0839382402379794
Validation loss: 2.430345555700408

Epoch: 5| Step: 1
Training loss: 0.9346684610614431
Validation loss: 2.4175404719970826

Epoch: 5| Step: 2
Training loss: 1.1880288703152697
Validation loss: 2.433312257137997

Epoch: 5| Step: 3
Training loss: 1.1863744320340053
Validation loss: 2.4226661768565174

Epoch: 5| Step: 4
Training loss: 0.968068129000078
Validation loss: 2.421799336818456

Epoch: 5| Step: 5
Training loss: 0.8403362161021233
Validation loss: 2.41307584051539

Epoch: 5| Step: 6
Training loss: 0.9990130859316004
Validation loss: 2.4110762043243867

Epoch: 5| Step: 7
Training loss: 1.2384072609693495
Validation loss: 2.380609481532172

Epoch: 5| Step: 8
Training loss: 1.287671118540371
Validation loss: 2.3917570252242935

Epoch: 5| Step: 9
Training loss: 0.8689551680647543
Validation loss: 2.3614761568193825

Epoch: 5| Step: 10
Training loss: 0.6496596022758914
Validation loss: 2.393178445969339

Epoch: 242| Step: 0
Training loss: 0.8816725198218525
Validation loss: 2.4200399199301534

Epoch: 5| Step: 1
Training loss: 1.3567627109081888
Validation loss: 2.454625413030521

Epoch: 5| Step: 2
Training loss: 1.1843298206418618
Validation loss: 2.4684171887150277

Epoch: 5| Step: 3
Training loss: 1.176713542184638
Validation loss: 2.470489460288842

Epoch: 5| Step: 4
Training loss: 0.775484478168604
Validation loss: 2.422029039536736

Epoch: 5| Step: 5
Training loss: 1.0122863473469172
Validation loss: 2.4530399919919477

Epoch: 5| Step: 6
Training loss: 0.6413399033609762
Validation loss: 2.4588248528155217

Epoch: 5| Step: 7
Training loss: 0.5667289603812034
Validation loss: 2.391161263393271

Epoch: 5| Step: 8
Training loss: 0.8188168287303292
Validation loss: 2.409368712931473

Epoch: 5| Step: 9
Training loss: 1.4523916547486664
Validation loss: 2.4178123725061353

Epoch: 5| Step: 10
Training loss: 0.94547913398897
Validation loss: 2.401875269767933

Epoch: 243| Step: 0
Training loss: 1.367784903659502
Validation loss: 2.3891937831654917

Epoch: 5| Step: 1
Training loss: 1.0784183047942744
Validation loss: 2.415365118626967

Epoch: 5| Step: 2
Training loss: 0.9537441556459001
Validation loss: 2.4414283433140125

Epoch: 5| Step: 3
Training loss: 0.9388713343770559
Validation loss: 2.398927151808523

Epoch: 5| Step: 4
Training loss: 0.9692380045162545
Validation loss: 2.4328933756436024

Epoch: 5| Step: 5
Training loss: 0.7998644162559975
Validation loss: 2.4156723450396633

Epoch: 5| Step: 6
Training loss: 1.2301084929588377
Validation loss: 2.4021324392259134

Epoch: 5| Step: 7
Training loss: 0.9187433748590251
Validation loss: 2.4219699932288226

Epoch: 5| Step: 8
Training loss: 1.0207153693310387
Validation loss: 2.3837636968538995

Epoch: 5| Step: 9
Training loss: 0.9986293459167536
Validation loss: 2.390009789713041

Epoch: 5| Step: 10
Training loss: 0.496236600358639
Validation loss: 2.375101332345877

Epoch: 244| Step: 0
Training loss: 1.1997654566435891
Validation loss: 2.394553070003738

Epoch: 5| Step: 1
Training loss: 1.3954586930703294
Validation loss: 2.379656678595656

Epoch: 5| Step: 2
Training loss: 1.224829257042826
Validation loss: 2.4103786067904127

Epoch: 5| Step: 3
Training loss: 0.688762156453655
Validation loss: 2.4022190902357994

Epoch: 5| Step: 4
Training loss: 1.0203105535094315
Validation loss: 2.4007625343286247

Epoch: 5| Step: 5
Training loss: 0.9311032454814195
Validation loss: 2.4299588098938067

Epoch: 5| Step: 6
Training loss: 0.5760368576906792
Validation loss: 2.4174201888174247

Epoch: 5| Step: 7
Training loss: 1.1000044605858268
Validation loss: 2.430605254966511

Epoch: 5| Step: 8
Training loss: 0.49090272247272887
Validation loss: 2.4175697816680635

Epoch: 5| Step: 9
Training loss: 0.9607875675993137
Validation loss: 2.3837967960323816

Epoch: 5| Step: 10
Training loss: 1.0572526044472985
Validation loss: 2.3672633005126937

Epoch: 245| Step: 0
Training loss: 0.747885026678692
Validation loss: 2.382366796237978

Epoch: 5| Step: 1
Training loss: 0.7027187021234865
Validation loss: 2.3384815015292486

Epoch: 5| Step: 2
Training loss: 1.1539191388008916
Validation loss: 2.3400577615270475

Epoch: 5| Step: 3
Training loss: 0.9801150288025384
Validation loss: 2.3461822643099572

Epoch: 5| Step: 4
Training loss: 1.000366024741155
Validation loss: 2.3701728167208227

Epoch: 5| Step: 5
Training loss: 0.8421494880548335
Validation loss: 2.3821518591242143

Epoch: 5| Step: 6
Training loss: 0.9105498809306615
Validation loss: 2.431617335747365

Epoch: 5| Step: 7
Training loss: 1.0043555415796104
Validation loss: 2.46408069919718

Epoch: 5| Step: 8
Training loss: 0.7506372208438186
Validation loss: 2.458241198359888

Epoch: 5| Step: 9
Training loss: 1.329414011423654
Validation loss: 2.4701181963431216

Epoch: 5| Step: 10
Training loss: 1.3072650597690278
Validation loss: 2.443221390300577

Epoch: 246| Step: 0
Training loss: 0.9251607110911816
Validation loss: 2.466030558181223

Epoch: 5| Step: 1
Training loss: 1.144905367692887
Validation loss: 2.4429813026699083

Epoch: 5| Step: 2
Training loss: 1.1985184802531164
Validation loss: 2.4095941527888565

Epoch: 5| Step: 3
Training loss: 0.9377057803331895
Validation loss: 2.4117637537784002

Epoch: 5| Step: 4
Training loss: 1.0815824273276087
Validation loss: 2.384951902527858

Epoch: 5| Step: 5
Training loss: 1.1106240132015655
Validation loss: 2.3532368733814253

Epoch: 5| Step: 6
Training loss: 0.803119650500104
Validation loss: 2.3341221746783347

Epoch: 5| Step: 7
Training loss: 1.0127953063390547
Validation loss: 2.331232506981291

Epoch: 5| Step: 8
Training loss: 1.0712742626242397
Validation loss: 2.3665680005820113

Epoch: 5| Step: 9
Training loss: 0.8971574371839212
Validation loss: 2.4096696864125096

Epoch: 5| Step: 10
Training loss: 0.4473634970913649
Validation loss: 2.4559875897942445

Epoch: 247| Step: 0
Training loss: 0.9739744147674738
Validation loss: 2.4713008366606535

Epoch: 5| Step: 1
Training loss: 1.1831371572346483
Validation loss: 2.490146678431584

Epoch: 5| Step: 2
Training loss: 1.040346771711609
Validation loss: 2.4674558641941724

Epoch: 5| Step: 3
Training loss: 0.7620853031175399
Validation loss: 2.392068494538846

Epoch: 5| Step: 4
Training loss: 0.9914427838459144
Validation loss: 2.397544156554906

Epoch: 5| Step: 5
Training loss: 1.1369687359352239
Validation loss: 2.348222057311867

Epoch: 5| Step: 6
Training loss: 1.0167976065774837
Validation loss: 2.3150972372019845

Epoch: 5| Step: 7
Training loss: 1.1090264108503838
Validation loss: 2.3218611775703963

Epoch: 5| Step: 8
Training loss: 0.9954900969391623
Validation loss: 2.3488471539638276

Epoch: 5| Step: 9
Training loss: 1.0157887253473759
Validation loss: 2.3589599055164405

Epoch: 5| Step: 10
Training loss: 0.6763045649629249
Validation loss: 2.381815825119288

Epoch: 248| Step: 0
Training loss: 0.9863621167661438
Validation loss: 2.419247831213641

Epoch: 5| Step: 1
Training loss: 0.7735939253019236
Validation loss: 2.422677112165224

Epoch: 5| Step: 2
Training loss: 1.1496037899481804
Validation loss: 2.453040591871913

Epoch: 5| Step: 3
Training loss: 1.3379596330429422
Validation loss: 2.45062239712378

Epoch: 5| Step: 4
Training loss: 0.6626570695342663
Validation loss: 2.4705060095615967

Epoch: 5| Step: 5
Training loss: 1.2058518459232073
Validation loss: 2.441235465296675

Epoch: 5| Step: 6
Training loss: 0.6386637789245192
Validation loss: 2.452796967923043

Epoch: 5| Step: 7
Training loss: 0.8451609999300517
Validation loss: 2.419055978234196

Epoch: 5| Step: 8
Training loss: 1.0982518870864797
Validation loss: 2.4303892807893903

Epoch: 5| Step: 9
Training loss: 0.9522455879924434
Validation loss: 2.422528587111764

Epoch: 5| Step: 10
Training loss: 0.8306150607166688
Validation loss: 2.422324665413968

Epoch: 249| Step: 0
Training loss: 0.558097939427968
Validation loss: 2.39071627110283

Epoch: 5| Step: 1
Training loss: 1.1491933917081647
Validation loss: 2.4307663997097726

Epoch: 5| Step: 2
Training loss: 1.033042794318853
Validation loss: 2.417972673435518

Epoch: 5| Step: 3
Training loss: 0.9045839451372376
Validation loss: 2.4503445622007205

Epoch: 5| Step: 4
Training loss: 1.0633593618162986
Validation loss: 2.4379088913645997

Epoch: 5| Step: 5
Training loss: 1.0397968422092063
Validation loss: 2.4292294504715977

Epoch: 5| Step: 6
Training loss: 0.9474263477636655
Validation loss: 2.414642914129996

Epoch: 5| Step: 7
Training loss: 0.7108175155501606
Validation loss: 2.389986085134255

Epoch: 5| Step: 8
Training loss: 1.3358913212876131
Validation loss: 2.4176587519646784

Epoch: 5| Step: 9
Training loss: 0.8038213568257999
Validation loss: 2.396393187722666

Epoch: 5| Step: 10
Training loss: 0.8511758328923942
Validation loss: 2.371270754104142

Epoch: 250| Step: 0
Training loss: 1.1399247619830783
Validation loss: 2.4096249459316432

Epoch: 5| Step: 1
Training loss: 1.0850652031709644
Validation loss: 2.4086468780291783

Epoch: 5| Step: 2
Training loss: 0.7100248662193964
Validation loss: 2.3787747185494337

Epoch: 5| Step: 3
Training loss: 1.004098183656449
Validation loss: 2.3820506426717074

Epoch: 5| Step: 4
Training loss: 0.8918724358888697
Validation loss: 2.3731438540708494

Epoch: 5| Step: 5
Training loss: 1.1123642742215578
Validation loss: 2.3755226019036444

Epoch: 5| Step: 6
Training loss: 1.0474866532087712
Validation loss: 2.3682031982895837

Epoch: 5| Step: 7
Training loss: 0.4148056630612476
Validation loss: 2.381152926168371

Epoch: 5| Step: 8
Training loss: 0.8361517373188614
Validation loss: 2.3992676661862236

Epoch: 5| Step: 9
Training loss: 0.5775409790048546
Validation loss: 2.4062103430158657

Epoch: 5| Step: 10
Training loss: 1.3965551398427545
Validation loss: 2.4047168769260825

Epoch: 251| Step: 0
Training loss: 0.5589533895225817
Validation loss: 2.4022992871392828

Epoch: 5| Step: 1
Training loss: 1.19706901192964
Validation loss: 2.388694634218164

Epoch: 5| Step: 2
Training loss: 1.2066937811230578
Validation loss: 2.4308754821642244

Epoch: 5| Step: 3
Training loss: 0.5967364744644048
Validation loss: 2.4552960314241945

Epoch: 5| Step: 4
Training loss: 0.8760897117863212
Validation loss: 2.4520578366886103

Epoch: 5| Step: 5
Training loss: 0.7217960909036011
Validation loss: 2.4449814044792073

Epoch: 5| Step: 6
Training loss: 0.8315940388773649
Validation loss: 2.4170875635405693

Epoch: 5| Step: 7
Training loss: 1.0346293133890816
Validation loss: 2.3955906258621837

Epoch: 5| Step: 8
Training loss: 1.0688979553962543
Validation loss: 2.400899272705025

Epoch: 5| Step: 9
Training loss: 1.1567479169837955
Validation loss: 2.3604579918190662

Epoch: 5| Step: 10
Training loss: 0.975689245793139
Validation loss: 2.343310585532378

Epoch: 252| Step: 0
Training loss: 0.9026295263063073
Validation loss: 2.3062204175816436

Epoch: 5| Step: 1
Training loss: 0.8071720690993115
Validation loss: 2.330588527846784

Epoch: 5| Step: 2
Training loss: 1.2788434105816657
Validation loss: 2.336795651587658

Epoch: 5| Step: 3
Training loss: 0.8674300258459322
Validation loss: 2.389871477328814

Epoch: 5| Step: 4
Training loss: 0.9698063720560657
Validation loss: 2.4420436247980013

Epoch: 5| Step: 5
Training loss: 0.6746523915741995
Validation loss: 2.447457310278098

Epoch: 5| Step: 6
Training loss: 0.7669336073662163
Validation loss: 2.518447034988595

Epoch: 5| Step: 7
Training loss: 0.7900452867034059
Validation loss: 2.5642187005775443

Epoch: 5| Step: 8
Training loss: 1.4801972877614697
Validation loss: 2.5607067529528704

Epoch: 5| Step: 9
Training loss: 0.729430986362426
Validation loss: 2.517691382464873

Epoch: 5| Step: 10
Training loss: 0.9905143507524921
Validation loss: 2.470465932278767

Epoch: 253| Step: 0
Training loss: 0.9910515116748624
Validation loss: 2.426867767046272

Epoch: 5| Step: 1
Training loss: 1.1147131562014152
Validation loss: 2.3753827657688507

Epoch: 5| Step: 2
Training loss: 0.7834049259773992
Validation loss: 2.392968497425056

Epoch: 5| Step: 3
Training loss: 0.8633411438476958
Validation loss: 2.3582585048279907

Epoch: 5| Step: 4
Training loss: 1.318239198081579
Validation loss: 2.3734470043766938

Epoch: 5| Step: 5
Training loss: 0.9529278660760928
Validation loss: 2.4147691020112516

Epoch: 5| Step: 6
Training loss: 1.0504809663111323
Validation loss: 2.4045649982503168

Epoch: 5| Step: 7
Training loss: 0.9816797080952059
Validation loss: 2.4289749050681095

Epoch: 5| Step: 8
Training loss: 0.7766798625351666
Validation loss: 2.493161786942045

Epoch: 5| Step: 9
Training loss: 0.7412999518097662
Validation loss: 2.4693312276828885

Epoch: 5| Step: 10
Training loss: 0.6833490206111813
Validation loss: 2.4972949601049717

Epoch: 254| Step: 0
Training loss: 1.046128305629376
Validation loss: 2.507408547339529

Epoch: 5| Step: 1
Training loss: 0.7465250256706982
Validation loss: 2.4435064985419244

Epoch: 5| Step: 2
Training loss: 0.8849722513600851
Validation loss: 2.4060402181969915

Epoch: 5| Step: 3
Training loss: 0.9042323771271078
Validation loss: 2.333982490150575

Epoch: 5| Step: 4
Training loss: 0.5171838950408963
Validation loss: 2.315367327571209

Epoch: 5| Step: 5
Training loss: 0.7738388253347851
Validation loss: 2.328243653689544

Epoch: 5| Step: 6
Training loss: 0.9522954739233229
Validation loss: 2.2849399517221416

Epoch: 5| Step: 7
Training loss: 0.9016760795886966
Validation loss: 2.2912730694679264

Epoch: 5| Step: 8
Training loss: 1.3517755770442663
Validation loss: 2.3011989837217874

Epoch: 5| Step: 9
Training loss: 0.8806892112242634
Validation loss: 2.3324035522137594

Epoch: 5| Step: 10
Training loss: 1.2055498927774952
Validation loss: 2.3753112951646584

Epoch: 255| Step: 0
Training loss: 0.533781834486072
Validation loss: 2.4182564951868954

Epoch: 5| Step: 1
Training loss: 1.0646995889051842
Validation loss: 2.4395071641890667

Epoch: 5| Step: 2
Training loss: 0.790487871604208
Validation loss: 2.424561841483489

Epoch: 5| Step: 3
Training loss: 0.809329449170872
Validation loss: 2.427171492098888

Epoch: 5| Step: 4
Training loss: 0.8394310580442321
Validation loss: 2.3581110874747524

Epoch: 5| Step: 5
Training loss: 1.1097594656096945
Validation loss: 2.343833728238147

Epoch: 5| Step: 6
Training loss: 0.7053564267387686
Validation loss: 2.384792352758596

Epoch: 5| Step: 7
Training loss: 0.8809923295803193
Validation loss: 2.3506837984980455

Epoch: 5| Step: 8
Training loss: 1.3336190076602739
Validation loss: 2.3748337903932515

Epoch: 5| Step: 9
Training loss: 1.071562656459313
Validation loss: 2.403392144599622

Epoch: 5| Step: 10
Training loss: 0.8424872733606655
Validation loss: 2.423661207432037

Epoch: 256| Step: 0
Training loss: 0.8327491421244179
Validation loss: 2.4383040438546746

Epoch: 5| Step: 1
Training loss: 0.8855735004126005
Validation loss: 2.429593975534495

Epoch: 5| Step: 2
Training loss: 1.105032305612025
Validation loss: 2.44443316956577

Epoch: 5| Step: 3
Training loss: 0.6762168670970786
Validation loss: 2.4702695918290716

Epoch: 5| Step: 4
Training loss: 0.4676856036139487
Validation loss: 2.455698843422657

Epoch: 5| Step: 5
Training loss: 1.1355478870031717
Validation loss: 2.436205987185847

Epoch: 5| Step: 6
Training loss: 0.5875450461953928
Validation loss: 2.455900969969309

Epoch: 5| Step: 7
Training loss: 1.1459024697456006
Validation loss: 2.452310056167813

Epoch: 5| Step: 8
Training loss: 0.732803367443968
Validation loss: 2.4962614829458394

Epoch: 5| Step: 9
Training loss: 1.083209116245433
Validation loss: 2.4682890603335994

Epoch: 5| Step: 10
Training loss: 1.1688103338977978
Validation loss: 2.4566722716995253

Epoch: 257| Step: 0
Training loss: 0.8074736277286299
Validation loss: 2.4502000088153943

Epoch: 5| Step: 1
Training loss: 0.9031541166264836
Validation loss: 2.449748869802222

Epoch: 5| Step: 2
Training loss: 1.0500096320664163
Validation loss: 2.4303081822142008

Epoch: 5| Step: 3
Training loss: 0.9207329869434729
Validation loss: 2.4009165419055103

Epoch: 5| Step: 4
Training loss: 0.9880011240686362
Validation loss: 2.422376962670529

Epoch: 5| Step: 5
Training loss: 0.7643877269468248
Validation loss: 2.42390975238924

Epoch: 5| Step: 6
Training loss: 0.7458794171109983
Validation loss: 2.410701552074906

Epoch: 5| Step: 7
Training loss: 0.8843693466814601
Validation loss: 2.4079765876817714

Epoch: 5| Step: 8
Training loss: 1.1516377500794865
Validation loss: 2.390427526234385

Epoch: 5| Step: 9
Training loss: 0.9738223887066876
Validation loss: 2.373174949493954

Epoch: 5| Step: 10
Training loss: 0.775032325808791
Validation loss: 2.3757095129854156

Epoch: 258| Step: 0
Training loss: 0.749425906758069
Validation loss: 2.395736690960051

Epoch: 5| Step: 1
Training loss: 0.8870833735348782
Validation loss: 2.36105807118335

Epoch: 5| Step: 2
Training loss: 0.8436268257373447
Validation loss: 2.3429834469994666

Epoch: 5| Step: 3
Training loss: 0.7147332611579006
Validation loss: 2.357079689855914

Epoch: 5| Step: 4
Training loss: 1.1886251038605342
Validation loss: 2.3434588343744576

Epoch: 5| Step: 5
Training loss: 0.9952228403953949
Validation loss: 2.363171719377623

Epoch: 5| Step: 6
Training loss: 0.7480138467613731
Validation loss: 2.3446531244342346

Epoch: 5| Step: 7
Training loss: 0.7645894657550849
Validation loss: 2.401561273412564

Epoch: 5| Step: 8
Training loss: 1.0490591693333267
Validation loss: 2.4282762227059944

Epoch: 5| Step: 9
Training loss: 0.9230152449190955
Validation loss: 2.4171134682799336

Epoch: 5| Step: 10
Training loss: 1.0682653633332393
Validation loss: 2.4418379921089626

Epoch: 259| Step: 0
Training loss: 0.9507270101656042
Validation loss: 2.434003912158371

Epoch: 5| Step: 1
Training loss: 1.1555424148982087
Validation loss: 2.4283727253889578

Epoch: 5| Step: 2
Training loss: 0.6463482762472286
Validation loss: 2.413382190400613

Epoch: 5| Step: 3
Training loss: 0.9087769039217117
Validation loss: 2.404028455247289

Epoch: 5| Step: 4
Training loss: 0.6961555727510891
Validation loss: 2.453978432450182

Epoch: 5| Step: 5
Training loss: 0.780509216053795
Validation loss: 2.439160888883759

Epoch: 5| Step: 6
Training loss: 0.7959905465777146
Validation loss: 2.4216587050778444

Epoch: 5| Step: 7
Training loss: 1.083767816029748
Validation loss: 2.4094527810085684

Epoch: 5| Step: 8
Training loss: 0.9804955892954844
Validation loss: 2.4266915390437513

Epoch: 5| Step: 9
Training loss: 0.7310637636306668
Validation loss: 2.4323785726853386

Epoch: 5| Step: 10
Training loss: 1.0639383453668754
Validation loss: 2.418771618068689

Epoch: 260| Step: 0
Training loss: 0.856327897029958
Validation loss: 2.4551131155043806

Epoch: 5| Step: 1
Training loss: 1.0110267422890737
Validation loss: 2.4202276941055536

Epoch: 5| Step: 2
Training loss: 0.9842616424685872
Validation loss: 2.4107909917144

Epoch: 5| Step: 3
Training loss: 1.0381095359610464
Validation loss: 2.414354745705801

Epoch: 5| Step: 4
Training loss: 0.7793970258792577
Validation loss: 2.419288719873473

Epoch: 5| Step: 5
Training loss: 0.7917797024656753
Validation loss: 2.4023808616921722

Epoch: 5| Step: 6
Training loss: 0.7381089024480171
Validation loss: 2.431857150603529

Epoch: 5| Step: 7
Training loss: 0.7446773325697845
Validation loss: 2.4369420563885846

Epoch: 5| Step: 8
Training loss: 1.2950562742518195
Validation loss: 2.388822030749299

Epoch: 5| Step: 9
Training loss: 0.6697290660225085
Validation loss: 2.3764507313399377

Epoch: 5| Step: 10
Training loss: 0.6540397480426196
Validation loss: 2.388507754504419

Epoch: 261| Step: 0
Training loss: 0.7925331535384182
Validation loss: 2.36532278363025

Epoch: 5| Step: 1
Training loss: 1.0400595792797345
Validation loss: 2.3973355559833656

Epoch: 5| Step: 2
Training loss: 1.1674948659126398
Validation loss: 2.3916600776259456

Epoch: 5| Step: 3
Training loss: 0.651765006999911
Validation loss: 2.424523302430818

Epoch: 5| Step: 4
Training loss: 0.9567365542967916
Validation loss: 2.4033882810961704

Epoch: 5| Step: 5
Training loss: 0.8088249576270402
Validation loss: 2.4081640431062303

Epoch: 5| Step: 6
Training loss: 0.6088401452357078
Validation loss: 2.44392416886523

Epoch: 5| Step: 7
Training loss: 0.9223110008467968
Validation loss: 2.443460936043967

Epoch: 5| Step: 8
Training loss: 1.1040429399853993
Validation loss: 2.4025364197348034

Epoch: 5| Step: 9
Training loss: 0.7173245018645252
Validation loss: 2.401724808251973

Epoch: 5| Step: 10
Training loss: 0.716227541799448
Validation loss: 2.406655258147353

Epoch: 262| Step: 0
Training loss: 1.0200793667376915
Validation loss: 2.3696339429104927

Epoch: 5| Step: 1
Training loss: 0.8186365354700589
Validation loss: 2.3858506335948606

Epoch: 5| Step: 2
Training loss: 1.0870201696544248
Validation loss: 2.3875081301469487

Epoch: 5| Step: 3
Training loss: 0.8774312846131226
Validation loss: 2.4165368110668317

Epoch: 5| Step: 4
Training loss: 0.9438866825787725
Validation loss: 2.395646860499744

Epoch: 5| Step: 5
Training loss: 1.0167752135025179
Validation loss: 2.4629422690702985

Epoch: 5| Step: 6
Training loss: 0.5522735615854922
Validation loss: 2.4377599640137366

Epoch: 5| Step: 7
Training loss: 0.6798588328528447
Validation loss: 2.467111515511472

Epoch: 5| Step: 8
Training loss: 0.7998767489619687
Validation loss: 2.4432434603806676

Epoch: 5| Step: 9
Training loss: 0.7683962279317035
Validation loss: 2.4434626052954775

Epoch: 5| Step: 10
Training loss: 0.9910838980608316
Validation loss: 2.403269724414657

Epoch: 263| Step: 0
Training loss: 0.5202007998602238
Validation loss: 2.3898510142124514

Epoch: 5| Step: 1
Training loss: 0.821210315390014
Validation loss: 2.348027254986176

Epoch: 5| Step: 2
Training loss: 1.034771023452173
Validation loss: 2.333165550205782

Epoch: 5| Step: 3
Training loss: 0.9659434241042544
Validation loss: 2.3180403276796424

Epoch: 5| Step: 4
Training loss: 0.7357052462878294
Validation loss: 2.3227086113129203

Epoch: 5| Step: 5
Training loss: 0.8101652786796507
Validation loss: 2.319491797606879

Epoch: 5| Step: 6
Training loss: 0.9822912413730017
Validation loss: 2.349102075801332

Epoch: 5| Step: 7
Training loss: 1.1458179935237693
Validation loss: 2.382498688915189

Epoch: 5| Step: 8
Training loss: 0.9346522949996245
Validation loss: 2.3928440900971752

Epoch: 5| Step: 9
Training loss: 0.5730633952354006
Validation loss: 2.43766227436528

Epoch: 5| Step: 10
Training loss: 0.9084983427907035
Validation loss: 2.4512958299983407

Epoch: 264| Step: 0
Training loss: 0.8756910728559764
Validation loss: 2.460807696602862

Epoch: 5| Step: 1
Training loss: 0.7169209718472602
Validation loss: 2.4648811084370856

Epoch: 5| Step: 2
Training loss: 0.6969046633441349
Validation loss: 2.432177759392913

Epoch: 5| Step: 3
Training loss: 0.7831003021705345
Validation loss: 2.4231798217022327

Epoch: 5| Step: 4
Training loss: 0.7460721796722377
Validation loss: 2.4268992378530645

Epoch: 5| Step: 5
Training loss: 0.9985425281952048
Validation loss: 2.4255096213188487

Epoch: 5| Step: 6
Training loss: 1.0589033849372622
Validation loss: 2.415938640244054

Epoch: 5| Step: 7
Training loss: 0.9249177599767936
Validation loss: 2.403848653490709

Epoch: 5| Step: 8
Training loss: 1.0644696995555922
Validation loss: 2.3773271917145182

Epoch: 5| Step: 9
Training loss: 0.5525311477218317
Validation loss: 2.377951032661466

Epoch: 5| Step: 10
Training loss: 1.0689457429689488
Validation loss: 2.3828432486957625

Epoch: 265| Step: 0
Training loss: 0.714577338598554
Validation loss: 2.3992370318192093

Epoch: 5| Step: 1
Training loss: 1.0149881567052657
Validation loss: 2.3978329938494727

Epoch: 5| Step: 2
Training loss: 1.0860808024089492
Validation loss: 2.3889146670904338

Epoch: 5| Step: 3
Training loss: 0.5941084733298082
Validation loss: 2.4160240618126148

Epoch: 5| Step: 4
Training loss: 1.0218653943838185
Validation loss: 2.4270588979521315

Epoch: 5| Step: 5
Training loss: 1.023844514240424
Validation loss: 2.407437204645988

Epoch: 5| Step: 6
Training loss: 0.8385860518245563
Validation loss: 2.4275018337457386

Epoch: 5| Step: 7
Training loss: 0.6623144816712484
Validation loss: 2.3995984176442167

Epoch: 5| Step: 8
Training loss: 0.6625311529284437
Validation loss: 2.385932616873053

Epoch: 5| Step: 9
Training loss: 1.0711828994656636
Validation loss: 2.3581213958896114

Epoch: 5| Step: 10
Training loss: 0.5165783709276277
Validation loss: 2.3757423164797897

Epoch: 266| Step: 0
Training loss: 0.8593934837434278
Validation loss: 2.3805529148275437

Epoch: 5| Step: 1
Training loss: 0.9742728896649397
Validation loss: 2.4046757799352947

Epoch: 5| Step: 2
Training loss: 0.8487853866751061
Validation loss: 2.434775321802956

Epoch: 5| Step: 3
Training loss: 0.6863765206640569
Validation loss: 2.4520596872331386

Epoch: 5| Step: 4
Training loss: 0.4677727048227071
Validation loss: 2.4620598607013955

Epoch: 5| Step: 5
Training loss: 0.6477636259774001
Validation loss: 2.456424728984233

Epoch: 5| Step: 6
Training loss: 0.7997314270524476
Validation loss: 2.448750106393675

Epoch: 5| Step: 7
Training loss: 1.126666477182662
Validation loss: 2.3838882242502026

Epoch: 5| Step: 8
Training loss: 0.8197339515452989
Validation loss: 2.3690019177096655

Epoch: 5| Step: 9
Training loss: 1.110500248571898
Validation loss: 2.3503891921735263

Epoch: 5| Step: 10
Training loss: 0.8904810002681313
Validation loss: 2.3023376777209443

Epoch: 267| Step: 0
Training loss: 1.204774493726628
Validation loss: 2.292454132488292

Epoch: 5| Step: 1
Training loss: 0.5762961819279504
Validation loss: 2.2740264300046764

Epoch: 5| Step: 2
Training loss: 0.7545329834141414
Validation loss: 2.310820480971905

Epoch: 5| Step: 3
Training loss: 0.9077972817909943
Validation loss: 2.3655544352463718

Epoch: 5| Step: 4
Training loss: 0.7605139961835766
Validation loss: 2.4085907138120417

Epoch: 5| Step: 5
Training loss: 1.0478255098913545
Validation loss: 2.4771496756111384

Epoch: 5| Step: 6
Training loss: 0.9456169331793349
Validation loss: 2.511605974710809

Epoch: 5| Step: 7
Training loss: 0.8190375456488891
Validation loss: 2.5157233735981253

Epoch: 5| Step: 8
Training loss: 1.0960505677551633
Validation loss: 2.562423416782103

Epoch: 5| Step: 9
Training loss: 0.7710226874569673
Validation loss: 2.508523473202566

Epoch: 5| Step: 10
Training loss: 0.24639482095515294
Validation loss: 2.4397384266669855

Epoch: 268| Step: 0
Training loss: 0.567966863112221
Validation loss: 2.3705075384979377

Epoch: 5| Step: 1
Training loss: 1.226084913832286
Validation loss: 2.359079509926755

Epoch: 5| Step: 2
Training loss: 0.8235307325825397
Validation loss: 2.323058356671647

Epoch: 5| Step: 3
Training loss: 0.9469586691069768
Validation loss: 2.3170783205758494

Epoch: 5| Step: 4
Training loss: 1.0101262229002848
Validation loss: 2.337688908213027

Epoch: 5| Step: 5
Training loss: 0.9271082321138089
Validation loss: 2.3362156810065877

Epoch: 5| Step: 6
Training loss: 0.8869719962910835
Validation loss: 2.332040866801678

Epoch: 5| Step: 7
Training loss: 0.9143944813966468
Validation loss: 2.3707827563975026

Epoch: 5| Step: 8
Training loss: 0.6979634615644623
Validation loss: 2.383121021187255

Epoch: 5| Step: 9
Training loss: 0.4686887383165494
Validation loss: 2.435775105507737

Epoch: 5| Step: 10
Training loss: 0.546070597189194
Validation loss: 2.509391363562022

Epoch: 269| Step: 0
Training loss: 0.745561979433227
Validation loss: 2.5141040696159807

Epoch: 5| Step: 1
Training loss: 1.0763972162450988
Validation loss: 2.539762101258817

Epoch: 5| Step: 2
Training loss: 1.0365741735289244
Validation loss: 2.5245191584312625

Epoch: 5| Step: 3
Training loss: 0.7173769731748717
Validation loss: 2.47023379169273

Epoch: 5| Step: 4
Training loss: 0.7906517416310354
Validation loss: 2.4803964338353883

Epoch: 5| Step: 5
Training loss: 0.8939340922022591
Validation loss: 2.429513270911773

Epoch: 5| Step: 6
Training loss: 0.6908480443718756
Validation loss: 2.4084527239192357

Epoch: 5| Step: 7
Training loss: 0.9208603140098915
Validation loss: 2.3862791469367606

Epoch: 5| Step: 8
Training loss: 0.6800797963655937
Validation loss: 2.3483334074671967

Epoch: 5| Step: 9
Training loss: 0.793014111654267
Validation loss: 2.3440202257799263

Epoch: 5| Step: 10
Training loss: 0.8997770523388323
Validation loss: 2.3705759753040914

Epoch: 270| Step: 0
Training loss: 1.003255848654366
Validation loss: 2.36384128168042

Epoch: 5| Step: 1
Training loss: 0.7894777772613297
Validation loss: 2.3484633673470157

Epoch: 5| Step: 2
Training loss: 0.860444184079549
Validation loss: 2.4016491902108554

Epoch: 5| Step: 3
Training loss: 0.6833544939145274
Validation loss: 2.4037778492792365

Epoch: 5| Step: 4
Training loss: 0.8880620519892113
Validation loss: 2.4503077945483858

Epoch: 5| Step: 5
Training loss: 0.7704724205794558
Validation loss: 2.453848882555045

Epoch: 5| Step: 6
Training loss: 0.8919499897857893
Validation loss: 2.47979272879314

Epoch: 5| Step: 7
Training loss: 0.6788598206055225
Validation loss: 2.4693048756265434

Epoch: 5| Step: 8
Training loss: 0.7172271102571596
Validation loss: 2.4823410810931765

Epoch: 5| Step: 9
Training loss: 1.1287645297208395
Validation loss: 2.470968474769789

Epoch: 5| Step: 10
Training loss: 0.6899150997257266
Validation loss: 2.462720395395612

Epoch: 271| Step: 0
Training loss: 1.0030265545890673
Validation loss: 2.445527064522899

Epoch: 5| Step: 1
Training loss: 0.9974941208553824
Validation loss: 2.4461081340505992

Epoch: 5| Step: 2
Training loss: 0.8974611035368624
Validation loss: 2.458811864759172

Epoch: 5| Step: 3
Training loss: 0.720951027348487
Validation loss: 2.4366743394790835

Epoch: 5| Step: 4
Training loss: 0.4983179887856625
Validation loss: 2.4234872543781174

Epoch: 5| Step: 5
Training loss: 0.8601193758815731
Validation loss: 2.3749616994397913

Epoch: 5| Step: 6
Training loss: 1.0235509445563982
Validation loss: 2.3552047665098637

Epoch: 5| Step: 7
Training loss: 0.837874690262232
Validation loss: 2.3682447409284095

Epoch: 5| Step: 8
Training loss: 0.5720583699895312
Validation loss: 2.3873736717863983

Epoch: 5| Step: 9
Training loss: 0.6061474103743754
Validation loss: 2.361184791144806

Epoch: 5| Step: 10
Training loss: 0.8134598564273463
Validation loss: 2.362802095246415

Epoch: 272| Step: 0
Training loss: 0.6018919599922364
Validation loss: 2.3743941649409

Epoch: 5| Step: 1
Training loss: 0.7583409069717102
Validation loss: 2.371909691955476

Epoch: 5| Step: 2
Training loss: 0.8728824605741756
Validation loss: 2.366584975418431

Epoch: 5| Step: 3
Training loss: 0.6913597608551371
Validation loss: 2.355446868600574

Epoch: 5| Step: 4
Training loss: 0.6334334023582588
Validation loss: 2.366116613755911

Epoch: 5| Step: 5
Training loss: 0.8066282848679655
Validation loss: 2.3780400347125408

Epoch: 5| Step: 6
Training loss: 0.8854025259945711
Validation loss: 2.372021378388007

Epoch: 5| Step: 7
Training loss: 0.9295898514443153
Validation loss: 2.386888822388947

Epoch: 5| Step: 8
Training loss: 1.1709866017292612
Validation loss: 2.399061095146587

Epoch: 5| Step: 9
Training loss: 0.8371940865423098
Validation loss: 2.4183762342993878

Epoch: 5| Step: 10
Training loss: 0.6135918626399262
Validation loss: 2.3834382750973364

Epoch: 273| Step: 0
Training loss: 0.6639568244774101
Validation loss: 2.372507362170604

Epoch: 5| Step: 1
Training loss: 0.7149837335990367
Validation loss: 2.3940869879635036

Epoch: 5| Step: 2
Training loss: 0.4264869790767251
Validation loss: 2.361714966863268

Epoch: 5| Step: 3
Training loss: 0.8320477622815916
Validation loss: 2.361429966945919

Epoch: 5| Step: 4
Training loss: 1.1884036390489594
Validation loss: 2.362050899668112

Epoch: 5| Step: 5
Training loss: 0.7157161371426312
Validation loss: 2.3749754752774863

Epoch: 5| Step: 6
Training loss: 0.8934459182326651
Validation loss: 2.421814317634376

Epoch: 5| Step: 7
Training loss: 0.9590221638430404
Validation loss: 2.438110967043597

Epoch: 5| Step: 8
Training loss: 0.8027445474615876
Validation loss: 2.4389131308080927

Epoch: 5| Step: 9
Training loss: 0.8416352437703437
Validation loss: 2.4079237562151

Epoch: 5| Step: 10
Training loss: 0.5650059721639521
Validation loss: 2.4324481359817014

Epoch: 274| Step: 0
Training loss: 0.8982544422246846
Validation loss: 2.4612166551590335

Epoch: 5| Step: 1
Training loss: 0.8864754498476978
Validation loss: 2.4238213399571475

Epoch: 5| Step: 2
Training loss: 0.5171467548927626
Validation loss: 2.3998294687273254

Epoch: 5| Step: 3
Training loss: 0.7399084737597438
Validation loss: 2.413897108749714

Epoch: 5| Step: 4
Training loss: 0.9154359003812099
Validation loss: 2.3825577783830534

Epoch: 5| Step: 5
Training loss: 0.5358623107126754
Validation loss: 2.4032910386582764

Epoch: 5| Step: 6
Training loss: 0.6821715902027633
Validation loss: 2.376406514357632

Epoch: 5| Step: 7
Training loss: 0.9106054548209507
Validation loss: 2.3699729589554557

Epoch: 5| Step: 8
Training loss: 0.5105811133137468
Validation loss: 2.3603605979699553

Epoch: 5| Step: 9
Training loss: 1.1293709402428318
Validation loss: 2.33805045542397

Epoch: 5| Step: 10
Training loss: 0.8757217700098806
Validation loss: 2.3214272447131745

Epoch: 275| Step: 0
Training loss: 0.8377088869844542
Validation loss: 2.315742740043267

Epoch: 5| Step: 1
Training loss: 0.6845550970761949
Validation loss: 2.3333402983683103

Epoch: 5| Step: 2
Training loss: 1.0092908086003127
Validation loss: 2.331100543356206

Epoch: 5| Step: 3
Training loss: 0.5352574273689431
Validation loss: 2.393599670525404

Epoch: 5| Step: 4
Training loss: 0.7389787074003891
Validation loss: 2.369978057083379

Epoch: 5| Step: 5
Training loss: 0.9008959099216794
Validation loss: 2.3947783777587013

Epoch: 5| Step: 6
Training loss: 0.793310307948643
Validation loss: 2.4310039710956146

Epoch: 5| Step: 7
Training loss: 0.8926887360198159
Validation loss: 2.404599261051361

Epoch: 5| Step: 8
Training loss: 0.7648209222615234
Validation loss: 2.413187041534057

Epoch: 5| Step: 9
Training loss: 0.5693468253139884
Validation loss: 2.4071715717906645

Epoch: 5| Step: 10
Training loss: 0.918253395913458
Validation loss: 2.3985067517019414

Epoch: 276| Step: 0
Training loss: 0.8155262050499662
Validation loss: 2.3857229773823287

Epoch: 5| Step: 1
Training loss: 0.8905397675537893
Validation loss: 2.3829318743732975

Epoch: 5| Step: 2
Training loss: 0.5509599165918817
Validation loss: 2.372138946303155

Epoch: 5| Step: 3
Training loss: 0.7771463574853573
Validation loss: 2.4410769834246655

Epoch: 5| Step: 4
Training loss: 0.8974017600057341
Validation loss: 2.4235758440133597

Epoch: 5| Step: 5
Training loss: 0.7321492819554015
Validation loss: 2.4004010872008914

Epoch: 5| Step: 6
Training loss: 0.63679768359737
Validation loss: 2.4206143477896904

Epoch: 5| Step: 7
Training loss: 0.9868659639820605
Validation loss: 2.3979593061947835

Epoch: 5| Step: 8
Training loss: 0.9238829324283944
Validation loss: 2.4240924275664906

Epoch: 5| Step: 9
Training loss: 0.43821037045734046
Validation loss: 2.3945458168545315

Epoch: 5| Step: 10
Training loss: 0.8373436910035229
Validation loss: 2.4065991635633575

Epoch: 277| Step: 0
Training loss: 0.41144718283823284
Validation loss: 2.4020813447905103

Epoch: 5| Step: 1
Training loss: 0.7539589028427898
Validation loss: 2.404646193163889

Epoch: 5| Step: 2
Training loss: 0.6247143569523916
Validation loss: 2.400040986538319

Epoch: 5| Step: 3
Training loss: 0.8353231436368498
Validation loss: 2.4313234903496515

Epoch: 5| Step: 4
Training loss: 0.8523586296370168
Validation loss: 2.4081334899746043

Epoch: 5| Step: 5
Training loss: 0.7570528371782062
Validation loss: 2.406689401712419

Epoch: 5| Step: 6
Training loss: 0.9935098681830921
Validation loss: 2.4186087217706813

Epoch: 5| Step: 7
Training loss: 0.5905454137960424
Validation loss: 2.4312025978779084

Epoch: 5| Step: 8
Training loss: 1.0922010625561986
Validation loss: 2.420817198888532

Epoch: 5| Step: 9
Training loss: 0.7023049128469615
Validation loss: 2.3494155955679377

Epoch: 5| Step: 10
Training loss: 0.7928851229162629
Validation loss: 2.3937009501952065

Epoch: 278| Step: 0
Training loss: 0.7524754679283467
Validation loss: 2.357607297657343

Epoch: 5| Step: 1
Training loss: 0.6448982349963708
Validation loss: 2.375641097805832

Epoch: 5| Step: 2
Training loss: 1.0463547054205204
Validation loss: 2.3560687067868877

Epoch: 5| Step: 3
Training loss: 0.7838157483863909
Validation loss: 2.356063862012356

Epoch: 5| Step: 4
Training loss: 0.589232121338378
Validation loss: 2.3906742342616893

Epoch: 5| Step: 5
Training loss: 0.8520813507454961
Validation loss: 2.365728711196332

Epoch: 5| Step: 6
Training loss: 0.77992116450228
Validation loss: 2.360979232527291

Epoch: 5| Step: 7
Training loss: 0.867197328803921
Validation loss: 2.3947973487741385

Epoch: 5| Step: 8
Training loss: 0.6067710898293757
Validation loss: 2.3783934251079057

Epoch: 5| Step: 9
Training loss: 0.928464774671986
Validation loss: 2.407074710111862

Epoch: 5| Step: 10
Training loss: 0.5220758177370312
Validation loss: 2.4047810556541167

Epoch: 279| Step: 0
Training loss: 0.49281489031205344
Validation loss: 2.404067166090849

Epoch: 5| Step: 1
Training loss: 1.1717461578748904
Validation loss: 2.431245563107717

Epoch: 5| Step: 2
Training loss: 0.5477404150182962
Validation loss: 2.454533155237212

Epoch: 5| Step: 3
Training loss: 0.794440871418148
Validation loss: 2.4711805549092842

Epoch: 5| Step: 4
Training loss: 0.7099214776366398
Validation loss: 2.4128758405456576

Epoch: 5| Step: 5
Training loss: 0.8174827450789035
Validation loss: 2.439259461253774

Epoch: 5| Step: 6
Training loss: 0.7544736950272269
Validation loss: 2.4468021541075125

Epoch: 5| Step: 7
Training loss: 0.484962307286258
Validation loss: 2.4308941973110607

Epoch: 5| Step: 8
Training loss: 0.37436676204196057
Validation loss: 2.447719158791516

Epoch: 5| Step: 9
Training loss: 1.2553267944069069
Validation loss: 2.4089237295991364

Epoch: 5| Step: 10
Training loss: 0.5598973089390908
Validation loss: 2.40146499356744

Epoch: 280| Step: 0
Training loss: 0.3138806243470048
Validation loss: 2.408616886619384

Epoch: 5| Step: 1
Training loss: 0.6183966369390645
Validation loss: 2.4036098241061334

Epoch: 5| Step: 2
Training loss: 0.6839070065594176
Validation loss: 2.389207341743863

Epoch: 5| Step: 3
Training loss: 0.5599282336655745
Validation loss: 2.43126811570069

Epoch: 5| Step: 4
Training loss: 0.8355569775556014
Validation loss: 2.3847435337648664

Epoch: 5| Step: 5
Training loss: 1.2286104732706018
Validation loss: 2.4045830641904815

Epoch: 5| Step: 6
Training loss: 0.7225566486075191
Validation loss: 2.411598658797181

Epoch: 5| Step: 7
Training loss: 0.4075328672061199
Validation loss: 2.3948547854533055

Epoch: 5| Step: 8
Training loss: 0.9861351202040394
Validation loss: 2.3896315792917324

Epoch: 5| Step: 9
Training loss: 0.9347945276200584
Validation loss: 2.408526959111737

Epoch: 5| Step: 10
Training loss: 0.6865525653243608
Validation loss: 2.382039560678505

Epoch: 281| Step: 0
Training loss: 0.8602003122628485
Validation loss: 2.3776675896498713

Epoch: 5| Step: 1
Training loss: 1.0268962741349958
Validation loss: 2.410238826500033

Epoch: 5| Step: 2
Training loss: 0.4982730127696227
Validation loss: 2.451915329064507

Epoch: 5| Step: 3
Training loss: 0.8284811657506956
Validation loss: 2.4504051547785095

Epoch: 5| Step: 4
Training loss: 0.6458162848980885
Validation loss: 2.4229114983334177

Epoch: 5| Step: 5
Training loss: 0.4170387474349432
Validation loss: 2.4687771134336907

Epoch: 5| Step: 6
Training loss: 0.8675454577977572
Validation loss: 2.405853745992146

Epoch: 5| Step: 7
Training loss: 0.5999498177444254
Validation loss: 2.4229098847568284

Epoch: 5| Step: 8
Training loss: 0.8700536839594994
Validation loss: 2.4294066847017284

Epoch: 5| Step: 9
Training loss: 0.9878826317514702
Validation loss: 2.4392790968464513

Epoch: 5| Step: 10
Training loss: 0.5680348889069118
Validation loss: 2.4190941465748828

Epoch: 282| Step: 0
Training loss: 0.8537454186647517
Validation loss: 2.4058488879871747

Epoch: 5| Step: 1
Training loss: 0.5491445043526946
Validation loss: 2.4411068742857616

Epoch: 5| Step: 2
Training loss: 0.5923993408634117
Validation loss: 2.4395739459436916

Epoch: 5| Step: 3
Training loss: 0.6158653777547479
Validation loss: 2.4640225981635733

Epoch: 5| Step: 4
Training loss: 0.6196453311748279
Validation loss: 2.4476127940342467

Epoch: 5| Step: 5
Training loss: 0.8062077208086584
Validation loss: 2.4571708411174447

Epoch: 5| Step: 6
Training loss: 1.0633871077649444
Validation loss: 2.417796615126421

Epoch: 5| Step: 7
Training loss: 0.802723497006112
Validation loss: 2.408419290325691

Epoch: 5| Step: 8
Training loss: 0.8504071578809235
Validation loss: 2.4135181474203375

Epoch: 5| Step: 9
Training loss: 0.6560442919984993
Validation loss: 2.3520153076980876

Epoch: 5| Step: 10
Training loss: 0.9152613871516488
Validation loss: 2.351013926345662

Epoch: 283| Step: 0
Training loss: 0.7829866562019325
Validation loss: 2.363114987488363

Epoch: 5| Step: 1
Training loss: 0.7031728728209542
Validation loss: 2.3689951487851815

Epoch: 5| Step: 2
Training loss: 1.0336441800479315
Validation loss: 2.397789581732391

Epoch: 5| Step: 3
Training loss: 0.7499878405538978
Validation loss: 2.405110176992062

Epoch: 5| Step: 4
Training loss: 0.44626058074417935
Validation loss: 2.4003408669771793

Epoch: 5| Step: 5
Training loss: 0.8865067484835996
Validation loss: 2.453728034194504

Epoch: 5| Step: 6
Training loss: 0.3779503474145497
Validation loss: 2.402983378808764

Epoch: 5| Step: 7
Training loss: 0.6060948979680832
Validation loss: 2.403362695629155

Epoch: 5| Step: 8
Training loss: 0.8904252079179311
Validation loss: 2.3471296880598684

Epoch: 5| Step: 9
Training loss: 0.957315861946544
Validation loss: 2.3807738842981627

Epoch: 5| Step: 10
Training loss: 0.5414772130305141
Validation loss: 2.3722968291506543

Epoch: 284| Step: 0
Training loss: 1.0790045647157802
Validation loss: 2.3764378934185

Epoch: 5| Step: 1
Training loss: 0.7909293422029587
Validation loss: 2.344492015350487

Epoch: 5| Step: 2
Training loss: 0.4848727929295431
Validation loss: 2.3845654797906506

Epoch: 5| Step: 3
Training loss: 0.731293401489785
Validation loss: 2.426383499114571

Epoch: 5| Step: 4
Training loss: 0.6737954394388007
Validation loss: 2.417701029535977

Epoch: 5| Step: 5
Training loss: 0.8323704560902405
Validation loss: 2.41960980100766

Epoch: 5| Step: 6
Training loss: 0.47995702893911973
Validation loss: 2.4396947010081504

Epoch: 5| Step: 7
Training loss: 0.5949008980532492
Validation loss: 2.4239618007496686

Epoch: 5| Step: 8
Training loss: 0.849049701727598
Validation loss: 2.470365192961019

Epoch: 5| Step: 9
Training loss: 0.7600342734037406
Validation loss: 2.4544429704226984

Epoch: 5| Step: 10
Training loss: 0.6794045396434728
Validation loss: 2.4314935447233337

Epoch: 285| Step: 0
Training loss: 0.5194344107644214
Validation loss: 2.4403705632519936

Epoch: 5| Step: 1
Training loss: 0.9020651184839052
Validation loss: 2.3996704840135954

Epoch: 5| Step: 2
Training loss: 0.707777104113764
Validation loss: 2.422103745067777

Epoch: 5| Step: 3
Training loss: 0.6020415244276447
Validation loss: 2.392942991246601

Epoch: 5| Step: 4
Training loss: 0.8526219418365572
Validation loss: 2.41546502187137

Epoch: 5| Step: 5
Training loss: 0.7607506884980134
Validation loss: 2.407322149199597

Epoch: 5| Step: 6
Training loss: 0.4325479318540891
Validation loss: 2.3776816517090267

Epoch: 5| Step: 7
Training loss: 0.5775013988444904
Validation loss: 2.4067380804611216

Epoch: 5| Step: 8
Training loss: 0.6534011403078813
Validation loss: 2.430360523921083

Epoch: 5| Step: 9
Training loss: 1.179644602822995
Validation loss: 2.431406385474254

Epoch: 5| Step: 10
Training loss: 0.6015983174547803
Validation loss: 2.419711660679107

Epoch: 286| Step: 0
Training loss: 0.7367784655935363
Validation loss: 2.4238113479818297

Epoch: 5| Step: 1
Training loss: 0.99570957329908
Validation loss: 2.4361471055960333

Epoch: 5| Step: 2
Training loss: 0.7801917347247994
Validation loss: 2.4426924314942693

Epoch: 5| Step: 3
Training loss: 0.7894800044735342
Validation loss: 2.392207505076908

Epoch: 5| Step: 4
Training loss: 0.642694248269761
Validation loss: 2.414880349796365

Epoch: 5| Step: 5
Training loss: 0.5937999403179084
Validation loss: 2.3988035226764364

Epoch: 5| Step: 6
Training loss: 0.48797243652514694
Validation loss: 2.4116756457613433

Epoch: 5| Step: 7
Training loss: 0.6427408029854552
Validation loss: 2.405668928700199

Epoch: 5| Step: 8
Training loss: 0.3274005317148576
Validation loss: 2.391316597416849

Epoch: 5| Step: 9
Training loss: 0.7025990956554462
Validation loss: 2.3735920802916364

Epoch: 5| Step: 10
Training loss: 1.0844070297919537
Validation loss: 2.3958087220784825

Epoch: 287| Step: 0
Training loss: 0.6710343535564733
Validation loss: 2.41155462702426

Epoch: 5| Step: 1
Training loss: 0.5957520511734357
Validation loss: 2.3453308571281686

Epoch: 5| Step: 2
Training loss: 0.5336893121760294
Validation loss: 2.3812782645718085

Epoch: 5| Step: 3
Training loss: 0.7375990930354114
Validation loss: 2.3259012454329966

Epoch: 5| Step: 4
Training loss: 0.7035274413544608
Validation loss: 2.360898647324055

Epoch: 5| Step: 5
Training loss: 0.8709719448717405
Validation loss: 2.3905009264929786

Epoch: 5| Step: 6
Training loss: 0.6644186971941125
Validation loss: 2.3970235135946285

Epoch: 5| Step: 7
Training loss: 0.8286844199399777
Validation loss: 2.4278485238296965

Epoch: 5| Step: 8
Training loss: 0.8077213907420404
Validation loss: 2.4366936765916942

Epoch: 5| Step: 9
Training loss: 0.6570214324108821
Validation loss: 2.4281001697788485

Epoch: 5| Step: 10
Training loss: 0.847831778217487
Validation loss: 2.431811708244503

Epoch: 288| Step: 0
Training loss: 0.6048587310205001
Validation loss: 2.4422510404161515

Epoch: 5| Step: 1
Training loss: 0.6049314514450528
Validation loss: 2.4088359011040996

Epoch: 5| Step: 2
Training loss: 0.9945744615203602
Validation loss: 2.4254704774150673

Epoch: 5| Step: 3
Training loss: 0.6927795994938679
Validation loss: 2.4152006933458283

Epoch: 5| Step: 4
Training loss: 0.47631374495718626
Validation loss: 2.4171373899316677

Epoch: 5| Step: 5
Training loss: 0.7001670927482143
Validation loss: 2.4186767260502164

Epoch: 5| Step: 6
Training loss: 0.6998081174186699
Validation loss: 2.3999460674877855

Epoch: 5| Step: 7
Training loss: 0.6312792535178775
Validation loss: 2.4315780640166684

Epoch: 5| Step: 8
Training loss: 0.5362198833642788
Validation loss: 2.4500520572150295

Epoch: 5| Step: 9
Training loss: 0.9113931396420385
Validation loss: 2.4460823058002075

Epoch: 5| Step: 10
Training loss: 0.9343353263061622
Validation loss: 2.44061925844661

Epoch: 289| Step: 0
Training loss: 0.6872117565361736
Validation loss: 2.440808411345226

Epoch: 5| Step: 1
Training loss: 0.3470220245619059
Validation loss: 2.4361500794903423

Epoch: 5| Step: 2
Training loss: 0.773286438649179
Validation loss: 2.426564701260697

Epoch: 5| Step: 3
Training loss: 0.49648835415449855
Validation loss: 2.428251981622589

Epoch: 5| Step: 4
Training loss: 0.6853547655771612
Validation loss: 2.3480797723915456

Epoch: 5| Step: 5
Training loss: 0.7581766571031844
Validation loss: 2.403413901490805

Epoch: 5| Step: 6
Training loss: 0.8539546649187418
Validation loss: 2.3745558430794977

Epoch: 5| Step: 7
Training loss: 0.6319680643267048
Validation loss: 2.371884581887119

Epoch: 5| Step: 8
Training loss: 0.9390683089852567
Validation loss: 2.4018242947442765

Epoch: 5| Step: 9
Training loss: 0.7264757001978148
Validation loss: 2.39160780007972

Epoch: 5| Step: 10
Training loss: 0.7895776181446132
Validation loss: 2.3670177460445525

Epoch: 290| Step: 0
Training loss: 0.36681155986863656
Validation loss: 2.4213172707051096

Epoch: 5| Step: 1
Training loss: 0.9506309898333222
Validation loss: 2.4291661171346237

Epoch: 5| Step: 2
Training loss: 0.5247062565243851
Validation loss: 2.4259059930010127

Epoch: 5| Step: 3
Training loss: 0.9239430587922344
Validation loss: 2.4027649821045185

Epoch: 5| Step: 4
Training loss: 0.8949545645768913
Validation loss: 2.414369373202264

Epoch: 5| Step: 5
Training loss: 0.8611101839272488
Validation loss: 2.4237431820862176

Epoch: 5| Step: 6
Training loss: 0.33070752556150956
Validation loss: 2.424809914570744

Epoch: 5| Step: 7
Training loss: 0.3449185730893823
Validation loss: 2.377933268938014

Epoch: 5| Step: 8
Training loss: 0.8385956472393513
Validation loss: 2.3804602632483336

Epoch: 5| Step: 9
Training loss: 0.6251213671146394
Validation loss: 2.38338781358079

Epoch: 5| Step: 10
Training loss: 0.7348417462713593
Validation loss: 2.375621690538652

Epoch: 291| Step: 0
Training loss: 0.8402214443004542
Validation loss: 2.4182711640146053

Epoch: 5| Step: 1
Training loss: 0.6163566405007227
Validation loss: 2.395664190034818

Epoch: 5| Step: 2
Training loss: 0.4222408050949824
Validation loss: 2.411907352953232

Epoch: 5| Step: 3
Training loss: 1.0005702538557706
Validation loss: 2.4430085132062307

Epoch: 5| Step: 4
Training loss: 0.3947497980601668
Validation loss: 2.4466678978330476

Epoch: 5| Step: 5
Training loss: 0.5654244430904916
Validation loss: 2.4306503117066085

Epoch: 5| Step: 6
Training loss: 0.7162753086378744
Validation loss: 2.439754958611978

Epoch: 5| Step: 7
Training loss: 0.7356915137752079
Validation loss: 2.4463105154256333

Epoch: 5| Step: 8
Training loss: 0.884323380112908
Validation loss: 2.463590144384792

Epoch: 5| Step: 9
Training loss: 0.67500046182546
Validation loss: 2.3970323359664434

Epoch: 5| Step: 10
Training loss: 0.6299955281976909
Validation loss: 2.3997695877620653

Epoch: 292| Step: 0
Training loss: 0.8154934247171071
Validation loss: 2.353035787961728

Epoch: 5| Step: 1
Training loss: 0.612921882838864
Validation loss: 2.3303386534090227

Epoch: 5| Step: 2
Training loss: 0.4709329479329131
Validation loss: 2.3104958212425193

Epoch: 5| Step: 3
Training loss: 0.8957136576948661
Validation loss: 2.352268771269037

Epoch: 5| Step: 4
Training loss: 0.983940573607498
Validation loss: 2.350822944303941

Epoch: 5| Step: 5
Training loss: 0.5593498554652041
Validation loss: 2.4030179042003983

Epoch: 5| Step: 6
Training loss: 0.5160934458866546
Validation loss: 2.402385201685557

Epoch: 5| Step: 7
Training loss: 0.43629804761966934
Validation loss: 2.420032650740783

Epoch: 5| Step: 8
Training loss: 0.7739333287782604
Validation loss: 2.4110431532115437

Epoch: 5| Step: 9
Training loss: 0.6259073585189228
Validation loss: 2.431584340324731

Epoch: 5| Step: 10
Training loss: 0.9035659373615714
Validation loss: 2.37369169178466

Epoch: 293| Step: 0
Training loss: 0.7378246368741304
Validation loss: 2.3840627396442082

Epoch: 5| Step: 1
Training loss: 0.757051301893356
Validation loss: 2.3594488653779053

Epoch: 5| Step: 2
Training loss: 0.4907834295341629
Validation loss: 2.3587975597081563

Epoch: 5| Step: 3
Training loss: 0.6323208488462929
Validation loss: 2.3729590334160346

Epoch: 5| Step: 4
Training loss: 0.7827168998286703
Validation loss: 2.3609450180713547

Epoch: 5| Step: 5
Training loss: 0.7838954766795201
Validation loss: 2.3770028576082094

Epoch: 5| Step: 6
Training loss: 0.4512666214711054
Validation loss: 2.366926865166236

Epoch: 5| Step: 7
Training loss: 0.8366145306816591
Validation loss: 2.3795289755956848

Epoch: 5| Step: 8
Training loss: 0.6795306846982947
Validation loss: 2.3972173009745785

Epoch: 5| Step: 9
Training loss: 0.8667856608521081
Validation loss: 2.457242601366603

Epoch: 5| Step: 10
Training loss: 0.562797255915911
Validation loss: 2.4164731262375283

Epoch: 294| Step: 0
Training loss: 0.5186345960180277
Validation loss: 2.397080731697107

Epoch: 5| Step: 1
Training loss: 0.3882418606771423
Validation loss: 2.38087347043073

Epoch: 5| Step: 2
Training loss: 0.4292345781049824
Validation loss: 2.416152280548358

Epoch: 5| Step: 3
Training loss: 0.7472144293309794
Validation loss: 2.3914238934481244

Epoch: 5| Step: 4
Training loss: 0.9175732998581028
Validation loss: 2.3765428849864296

Epoch: 5| Step: 5
Training loss: 0.7063615693945483
Validation loss: 2.366405437879133

Epoch: 5| Step: 6
Training loss: 0.5518345062157369
Validation loss: 2.4044562841624857

Epoch: 5| Step: 7
Training loss: 0.7407731081151664
Validation loss: 2.3845796715743495

Epoch: 5| Step: 8
Training loss: 0.9851330457188684
Validation loss: 2.3832194174013446

Epoch: 5| Step: 9
Training loss: 0.501805621490676
Validation loss: 2.438009765681757

Epoch: 5| Step: 10
Training loss: 0.9125130064572973
Validation loss: 2.4565166590093748

Epoch: 295| Step: 0
Training loss: 0.8024309981916362
Validation loss: 2.4600266325204534

Epoch: 5| Step: 1
Training loss: 0.7407109077945195
Validation loss: 2.437823348557541

Epoch: 5| Step: 2
Training loss: 0.6122316015694897
Validation loss: 2.405989935300883

Epoch: 5| Step: 3
Training loss: 0.563295199661957
Validation loss: 2.3940704458505575

Epoch: 5| Step: 4
Training loss: 0.7756748399236947
Validation loss: 2.3491060929758976

Epoch: 5| Step: 5
Training loss: 0.5938119855950178
Validation loss: 2.3343922124902035

Epoch: 5| Step: 6
Training loss: 0.8494071982977599
Validation loss: 2.341953218350787

Epoch: 5| Step: 7
Training loss: 0.6112531670876425
Validation loss: 2.299949963387843

Epoch: 5| Step: 8
Training loss: 0.7124730389496599
Validation loss: 2.320028210918573

Epoch: 5| Step: 9
Training loss: 0.3418122860295248
Validation loss: 2.2874757359400912

Epoch: 5| Step: 10
Training loss: 0.9710913635862924
Validation loss: 2.3327703672114763

Epoch: 296| Step: 0
Training loss: 0.7773333601520832
Validation loss: 2.3581981944449026

Epoch: 5| Step: 1
Training loss: 0.6720936219913266
Validation loss: 2.3536257378739776

Epoch: 5| Step: 2
Training loss: 0.6978670406253212
Validation loss: 2.3883380582349223

Epoch: 5| Step: 3
Training loss: 0.36643899555737175
Validation loss: 2.4139458099484075

Epoch: 5| Step: 4
Training loss: 0.7960164175760627
Validation loss: 2.435403032807774

Epoch: 5| Step: 5
Training loss: 0.7708404557869891
Validation loss: 2.3951487336641515

Epoch: 5| Step: 6
Training loss: 0.6471866815065432
Validation loss: 2.3935224387378184

Epoch: 5| Step: 7
Training loss: 0.8493238649000207
Validation loss: 2.376803830867894

Epoch: 5| Step: 8
Training loss: 0.686448007620766
Validation loss: 2.3364516059575613

Epoch: 5| Step: 9
Training loss: 0.3690458710983591
Validation loss: 2.3557596511531425

Epoch: 5| Step: 10
Training loss: 0.8224014931102105
Validation loss: 2.338598596016189

Epoch: 297| Step: 0
Training loss: 0.7210935450064884
Validation loss: 2.338793374173899

Epoch: 5| Step: 1
Training loss: 0.7734264796849435
Validation loss: 2.33406354828499

Epoch: 5| Step: 2
Training loss: 0.6215964388320053
Validation loss: 2.3723509089639703

Epoch: 5| Step: 3
Training loss: 0.8349131431062303
Validation loss: 2.413990489463002

Epoch: 5| Step: 4
Training loss: 0.6847765689373548
Validation loss: 2.4152668670841426

Epoch: 5| Step: 5
Training loss: 0.6812532739823091
Validation loss: 2.4521071014714666

Epoch: 5| Step: 6
Training loss: 0.6725410220954097
Validation loss: 2.4613432508541306

Epoch: 5| Step: 7
Training loss: 0.5401439323488458
Validation loss: 2.4359114395007646

Epoch: 5| Step: 8
Training loss: 0.447880268466251
Validation loss: 2.4401881705970356

Epoch: 5| Step: 9
Training loss: 0.5788903711692119
Validation loss: 2.3500405378342717

Epoch: 5| Step: 10
Training loss: 0.9523458266450743
Validation loss: 2.3610775243247084

Epoch: 298| Step: 0
Training loss: 0.703806800887639
Validation loss: 2.3525151601639003

Epoch: 5| Step: 1
Training loss: 0.6980804469441406
Validation loss: 2.3581204555013873

Epoch: 5| Step: 2
Training loss: 0.5464022909473156
Validation loss: 2.328534871682572

Epoch: 5| Step: 3
Training loss: 0.35238821759828975
Validation loss: 2.330524576437629

Epoch: 5| Step: 4
Training loss: 0.5603477576290496
Validation loss: 2.3544130718167073

Epoch: 5| Step: 5
Training loss: 0.8244789761325972
Validation loss: 2.3559825836535295

Epoch: 5| Step: 6
Training loss: 0.7569735100519365
Validation loss: 2.350182864942646

Epoch: 5| Step: 7
Training loss: 0.5049112042647174
Validation loss: 2.358852622836676

Epoch: 5| Step: 8
Training loss: 0.6238863321282881
Validation loss: 2.311647335566117

Epoch: 5| Step: 9
Training loss: 0.9831053402166339
Validation loss: 2.3742812957692165

Epoch: 5| Step: 10
Training loss: 0.7155119061122541
Validation loss: 2.3544973572569603

Epoch: 299| Step: 0
Training loss: 0.7143845881421893
Validation loss: 2.382093956336468

Epoch: 5| Step: 1
Training loss: 0.22120478675909525
Validation loss: 2.4083214154015824

Epoch: 5| Step: 2
Training loss: 0.6696557497872425
Validation loss: 2.3925865823120356

Epoch: 5| Step: 3
Training loss: 0.7506426997960551
Validation loss: 2.409808264602485

Epoch: 5| Step: 4
Training loss: 0.5904922709609249
Validation loss: 2.4307740502268715

Epoch: 5| Step: 5
Training loss: 0.7170988273239708
Validation loss: 2.3974515093322353

Epoch: 5| Step: 6
Training loss: 0.7189163347252856
Validation loss: 2.4168576096860765

Epoch: 5| Step: 7
Training loss: 0.8013097740170413
Validation loss: 2.4269247420904487

Epoch: 5| Step: 8
Training loss: 0.6207145156919501
Validation loss: 2.3655634383805775

Epoch: 5| Step: 9
Training loss: 0.7536488622372987
Validation loss: 2.3936531265985135

Epoch: 5| Step: 10
Training loss: 0.6972670354748733
Validation loss: 2.381226666680988

Epoch: 300| Step: 0
Training loss: 0.7887822777239015
Validation loss: 2.3769966803876934

Epoch: 5| Step: 1
Training loss: 0.45691829491913705
Validation loss: 2.426662772162115

Epoch: 5| Step: 2
Training loss: 0.44946630539806504
Validation loss: 2.436871622482351

Epoch: 5| Step: 3
Training loss: 0.4750483958787076
Validation loss: 2.4029625493943194

Epoch: 5| Step: 4
Training loss: 0.7513627546242627
Validation loss: 2.3957048236324865

Epoch: 5| Step: 5
Training loss: 0.5878151880067959
Validation loss: 2.4111110295676474

Epoch: 5| Step: 6
Training loss: 0.7434902603137424
Validation loss: 2.380773913910432

Epoch: 5| Step: 7
Training loss: 0.992919081459412
Validation loss: 2.3729961287714154

Epoch: 5| Step: 8
Training loss: 0.4367879283891466
Validation loss: 2.3551905702487104

Epoch: 5| Step: 9
Training loss: 0.7966174289086805
Validation loss: 2.297230289346346

Epoch: 5| Step: 10
Training loss: 0.5818129264427571
Validation loss: 2.288942663095241

Epoch: 301| Step: 0
Training loss: 0.8174539806233815
Validation loss: 2.2858277646703646

Epoch: 5| Step: 1
Training loss: 0.6728758786794732
Validation loss: 2.3134837941672277

Epoch: 5| Step: 2
Training loss: 0.3904507820724371
Validation loss: 2.2927927731371707

Epoch: 5| Step: 3
Training loss: 0.7725021794976658
Validation loss: 2.3298671965161493

Epoch: 5| Step: 4
Training loss: 0.7830653271541487
Validation loss: 2.3406145196328976

Epoch: 5| Step: 5
Training loss: 0.7560082419617279
Validation loss: 2.369418331156015

Epoch: 5| Step: 6
Training loss: 0.5143805427298987
Validation loss: 2.3751936489791703

Epoch: 5| Step: 7
Training loss: 0.6832302980161097
Validation loss: 2.457032582408045

Epoch: 5| Step: 8
Training loss: 0.5071153403498274
Validation loss: 2.425461037630381

Epoch: 5| Step: 9
Training loss: 0.7348338377874345
Validation loss: 2.4261498837187068

Epoch: 5| Step: 10
Training loss: 0.4588333855497416
Validation loss: 2.41391383997428

Epoch: 302| Step: 0
Training loss: 0.6327464928757782
Validation loss: 2.433514197260127

Epoch: 5| Step: 1
Training loss: 0.503792121441938
Validation loss: 2.39126585294837

Epoch: 5| Step: 2
Training loss: 0.6926351068747569
Validation loss: 2.4274309601140267

Epoch: 5| Step: 3
Training loss: 0.5404112983335015
Validation loss: 2.416385489652726

Epoch: 5| Step: 4
Training loss: 0.5852817935496042
Validation loss: 2.3912140063479534

Epoch: 5| Step: 5
Training loss: 0.6017481282169025
Validation loss: 2.3765196609624626

Epoch: 5| Step: 6
Training loss: 0.7463184437762267
Validation loss: 2.3707820016166425

Epoch: 5| Step: 7
Training loss: 0.82226261672967
Validation loss: 2.4055018631673253

Epoch: 5| Step: 8
Training loss: 0.6893132313700154
Validation loss: 2.3846636605206295

Epoch: 5| Step: 9
Training loss: 0.7551188624207893
Validation loss: 2.397230394960761

Epoch: 5| Step: 10
Training loss: 0.5935360623469224
Validation loss: 2.4015210458139986

Epoch: 303| Step: 0
Training loss: 0.7424444456542271
Validation loss: 2.3497348243495795

Epoch: 5| Step: 1
Training loss: 0.809031860785125
Validation loss: 2.3912486791545158

Epoch: 5| Step: 2
Training loss: 0.3664269789178056
Validation loss: 2.392911200277142

Epoch: 5| Step: 3
Training loss: 0.5983302984010167
Validation loss: 2.3701072308777107

Epoch: 5| Step: 4
Training loss: 0.7860261264225015
Validation loss: 2.3610691919371654

Epoch: 5| Step: 5
Training loss: 0.8807881193246726
Validation loss: 2.368002814319643

Epoch: 5| Step: 6
Training loss: 0.5806571305647426
Validation loss: 2.3867889636184776

Epoch: 5| Step: 7
Training loss: 0.6800256085482389
Validation loss: 2.399993624687273

Epoch: 5| Step: 8
Training loss: 0.41563025162899697
Validation loss: 2.415907089797515

Epoch: 5| Step: 9
Training loss: 0.5684031309083859
Validation loss: 2.375146128417885

Epoch: 5| Step: 10
Training loss: 0.4501828835316999
Validation loss: 2.416283185262109

Epoch: 304| Step: 0
Training loss: 0.7322015456359687
Validation loss: 2.3745417160849276

Epoch: 5| Step: 1
Training loss: 0.6399565442426995
Validation loss: 2.377162495037932

Epoch: 5| Step: 2
Training loss: 0.6372630361448536
Validation loss: 2.3219522373943207

Epoch: 5| Step: 3
Training loss: 0.6187525595024422
Validation loss: 2.326038680830044

Epoch: 5| Step: 4
Training loss: 0.6670663549425666
Validation loss: 2.323129401298877

Epoch: 5| Step: 5
Training loss: 0.5244715142346835
Validation loss: 2.3043803237484233

Epoch: 5| Step: 6
Training loss: 0.5396241565368154
Validation loss: 2.279571122197992

Epoch: 5| Step: 7
Training loss: 0.685558655901156
Validation loss: 2.3283908788800187

Epoch: 5| Step: 8
Training loss: 0.5414133641159528
Validation loss: 2.330069927111795

Epoch: 5| Step: 9
Training loss: 0.7860050452994988
Validation loss: 2.377290530053882

Epoch: 5| Step: 10
Training loss: 0.6551040225747362
Validation loss: 2.3935978786750622

Epoch: 305| Step: 0
Training loss: 0.8748320690859802
Validation loss: 2.3914811919265686

Epoch: 5| Step: 1
Training loss: 0.5256033541183343
Validation loss: 2.4123766012383054

Epoch: 5| Step: 2
Training loss: 0.8162711364790187
Validation loss: 2.4446141643031343

Epoch: 5| Step: 3
Training loss: 0.45303703967090164
Validation loss: 2.4802266759930154

Epoch: 5| Step: 4
Training loss: 0.4896822856438007
Validation loss: 2.4505145441508374

Epoch: 5| Step: 5
Training loss: 0.6247730558353459
Validation loss: 2.4033606294516052

Epoch: 5| Step: 6
Training loss: 0.46522278919415216
Validation loss: 2.371595028417423

Epoch: 5| Step: 7
Training loss: 0.8017258817793792
Validation loss: 2.3461634705809353

Epoch: 5| Step: 8
Training loss: 0.61612469875261
Validation loss: 2.3166478281176603

Epoch: 5| Step: 9
Training loss: 0.3985042516105845
Validation loss: 2.2914296345515197

Epoch: 5| Step: 10
Training loss: 0.7001555789330502
Validation loss: 2.3137289571404347

Epoch: 306| Step: 0
Training loss: 0.5828740463281757
Validation loss: 2.298530846205703

Epoch: 5| Step: 1
Training loss: 0.6220829362052507
Validation loss: 2.3297088107294517

Epoch: 5| Step: 2
Training loss: 0.7438727269574633
Validation loss: 2.345974404361486

Epoch: 5| Step: 3
Training loss: 0.7401778066152289
Validation loss: 2.403670900464092

Epoch: 5| Step: 4
Training loss: 0.8529610305104196
Validation loss: 2.4049703953621955

Epoch: 5| Step: 5
Training loss: 0.6454067410797023
Validation loss: 2.4185502523336204

Epoch: 5| Step: 6
Training loss: 0.48992946915115937
Validation loss: 2.4117798939119837

Epoch: 5| Step: 7
Training loss: 0.6028304917739005
Validation loss: 2.3779783485610073

Epoch: 5| Step: 8
Training loss: 0.381112586725404
Validation loss: 2.3928467824687005

Epoch: 5| Step: 9
Training loss: 0.4722545587775017
Validation loss: 2.3849565085702285

Epoch: 5| Step: 10
Training loss: 0.6725866629552336
Validation loss: 2.358212092125508

Epoch: 307| Step: 0
Training loss: 0.5670511192105551
Validation loss: 2.3835391605075555

Epoch: 5| Step: 1
Training loss: 0.5309485814564241
Validation loss: 2.36340771896649

Epoch: 5| Step: 2
Training loss: 0.6706153238954748
Validation loss: 2.3891044401246777

Epoch: 5| Step: 3
Training loss: 0.56768312894068
Validation loss: 2.3858513889812443

Epoch: 5| Step: 4
Training loss: 0.541339130286989
Validation loss: 2.3956334625023015

Epoch: 5| Step: 5
Training loss: 0.44537113874412027
Validation loss: 2.3931529066775985

Epoch: 5| Step: 6
Training loss: 0.8838961878812921
Validation loss: 2.434649939188133

Epoch: 5| Step: 7
Training loss: 0.7761554549255735
Validation loss: 2.3889489611892873

Epoch: 5| Step: 8
Training loss: 0.743526215104592
Validation loss: 2.402471708592746

Epoch: 5| Step: 9
Training loss: 0.4754974157521875
Validation loss: 2.352054556322497

Epoch: 5| Step: 10
Training loss: 0.6063935139475268
Validation loss: 2.4012502451076267

Epoch: 308| Step: 0
Training loss: 0.3271727823337504
Validation loss: 2.3578502571899596

Epoch: 5| Step: 1
Training loss: 0.45298301182191403
Validation loss: 2.366696593038926

Epoch: 5| Step: 2
Training loss: 0.6814356717110782
Validation loss: 2.3695058325486027

Epoch: 5| Step: 3
Training loss: 0.756129726587482
Validation loss: 2.357299885266875

Epoch: 5| Step: 4
Training loss: 0.5048400447594965
Validation loss: 2.3445012868966577

Epoch: 5| Step: 5
Training loss: 0.6765623925189138
Validation loss: 2.37370228570255

Epoch: 5| Step: 6
Training loss: 0.685713788441069
Validation loss: 2.3714189144446776

Epoch: 5| Step: 7
Training loss: 0.8311074012686582
Validation loss: 2.415171679735325

Epoch: 5| Step: 8
Training loss: 0.6236343006244112
Validation loss: 2.3743335013196867

Epoch: 5| Step: 9
Training loss: 0.45946318629819893
Validation loss: 2.340514985657088

Epoch: 5| Step: 10
Training loss: 0.6365016262815785
Validation loss: 2.3616997329128466

Epoch: 309| Step: 0
Training loss: 0.548932510169143
Validation loss: 2.3598942838840404

Epoch: 5| Step: 1
Training loss: 0.5072756643989449
Validation loss: 2.361026229836672

Epoch: 5| Step: 2
Training loss: 0.4002543147591377
Validation loss: 2.3472866629908

Epoch: 5| Step: 3
Training loss: 0.6053162413458343
Validation loss: 2.338979409370055

Epoch: 5| Step: 4
Training loss: 0.8471325781737808
Validation loss: 2.359630885132989

Epoch: 5| Step: 5
Training loss: 0.5569512822129661
Validation loss: 2.4025314208395265

Epoch: 5| Step: 6
Training loss: 0.7175897687653614
Validation loss: 2.374632831293651

Epoch: 5| Step: 7
Training loss: 0.6816007935874197
Validation loss: 2.374669373128428

Epoch: 5| Step: 8
Training loss: 0.5442556321304334
Validation loss: 2.350793743027077

Epoch: 5| Step: 9
Training loss: 0.7217472855186883
Validation loss: 2.386036978985981

Epoch: 5| Step: 10
Training loss: 0.5468382959310218
Validation loss: 2.3478627752447485

Epoch: 310| Step: 0
Training loss: 0.8100011620101129
Validation loss: 2.3536994471174517

Epoch: 5| Step: 1
Training loss: 0.7027115347915889
Validation loss: 2.4066322658535784

Epoch: 5| Step: 2
Training loss: 0.3140798212845061
Validation loss: 2.410936547419404

Epoch: 5| Step: 3
Training loss: 0.541055202757918
Validation loss: 2.4295009750752135

Epoch: 5| Step: 4
Training loss: 0.558451574411836
Validation loss: 2.4514128781537448

Epoch: 5| Step: 5
Training loss: 0.3061309028187229
Validation loss: 2.4630524661826825

Epoch: 5| Step: 6
Training loss: 0.7846560047047029
Validation loss: 2.4452012402485828

Epoch: 5| Step: 7
Training loss: 0.652279171059963
Validation loss: 2.3991782270566024

Epoch: 5| Step: 8
Training loss: 0.8186109788817816
Validation loss: 2.361384858020766

Epoch: 5| Step: 9
Training loss: 0.6753404535795015
Validation loss: 2.2970717463533292

Epoch: 5| Step: 10
Training loss: 0.4256402753477942
Validation loss: 2.2972194660834844

Epoch: 311| Step: 0
Training loss: 0.8641134195345022
Validation loss: 2.2935672633012456

Epoch: 5| Step: 1
Training loss: 0.49877747448080867
Validation loss: 2.309476098682009

Epoch: 5| Step: 2
Training loss: 0.6656084801858099
Validation loss: 2.344987711172922

Epoch: 5| Step: 3
Training loss: 0.693171129058993
Validation loss: 2.348994576452158

Epoch: 5| Step: 4
Training loss: 0.3652102620533951
Validation loss: 2.354730516956646

Epoch: 5| Step: 5
Training loss: 0.5701266992029697
Validation loss: 2.395850200691788

Epoch: 5| Step: 6
Training loss: 0.8542843636781393
Validation loss: 2.4233454606403484

Epoch: 5| Step: 7
Training loss: 0.5923392199617531
Validation loss: 2.4836775412821486

Epoch: 5| Step: 8
Training loss: 0.5584688113613158
Validation loss: 2.4501783796369856

Epoch: 5| Step: 9
Training loss: 0.34000482797700987
Validation loss: 2.4440727216548206

Epoch: 5| Step: 10
Training loss: 0.3630590477107986
Validation loss: 2.40825127388976

Epoch: 312| Step: 0
Training loss: 0.7194341223290062
Validation loss: 2.374993409005709

Epoch: 5| Step: 1
Training loss: 0.4055634713198758
Validation loss: 2.36091749260812

Epoch: 5| Step: 2
Training loss: 0.5115186285409717
Validation loss: 2.326082483115576

Epoch: 5| Step: 3
Training loss: 0.4851377849167074
Validation loss: 2.3489015117284917

Epoch: 5| Step: 4
Training loss: 0.6663161240305512
Validation loss: 2.321050450405423

Epoch: 5| Step: 5
Training loss: 0.7801345873529182
Validation loss: 2.317331671494569

Epoch: 5| Step: 6
Training loss: 0.7501340587331522
Validation loss: 2.4000850372733558

Epoch: 5| Step: 7
Training loss: 0.3012948790633827
Validation loss: 2.393297594663211

Epoch: 5| Step: 8
Training loss: 0.40220647155073685
Validation loss: 2.415883866410652

Epoch: 5| Step: 9
Training loss: 0.5166079082712214
Validation loss: 2.4187711888117303

Epoch: 5| Step: 10
Training loss: 0.9023902517779689
Validation loss: 2.3898068263276357

Epoch: 313| Step: 0
Training loss: 0.6066852285441445
Validation loss: 2.3998647680347314

Epoch: 5| Step: 1
Training loss: 0.3510908353690504
Validation loss: 2.391109215104137

Epoch: 5| Step: 2
Training loss: 0.6045274616358399
Validation loss: 2.3668196040408995

Epoch: 5| Step: 3
Training loss: 0.73906274839885
Validation loss: 2.3773082090745037

Epoch: 5| Step: 4
Training loss: 0.6050360825710489
Validation loss: 2.3263307842609673

Epoch: 5| Step: 5
Training loss: 0.5142090168312591
Validation loss: 2.284546465517204

Epoch: 5| Step: 6
Training loss: 0.6854172065021589
Validation loss: 2.3296794405353953

Epoch: 5| Step: 7
Training loss: 0.6891032079319457
Validation loss: 2.3037970701115986

Epoch: 5| Step: 8
Training loss: 0.5976493436127586
Validation loss: 2.354491490648994

Epoch: 5| Step: 9
Training loss: 0.6661861346841284
Validation loss: 2.3519171941717514

Epoch: 5| Step: 10
Training loss: 0.3699053356819684
Validation loss: 2.380676043349846

Epoch: 314| Step: 0
Training loss: 0.5088343389650902
Validation loss: 2.3588128700039808

Epoch: 5| Step: 1
Training loss: 0.6001004373409926
Validation loss: 2.3599695908269918

Epoch: 5| Step: 2
Training loss: 0.5286688650842362
Validation loss: 2.379887774137773

Epoch: 5| Step: 3
Training loss: 0.8418053009248767
Validation loss: 2.370997775894006

Epoch: 5| Step: 4
Training loss: 0.48118714380356387
Validation loss: 2.367240613029285

Epoch: 5| Step: 5
Training loss: 0.4839170506090827
Validation loss: 2.340720752775157

Epoch: 5| Step: 6
Training loss: 0.510394910102162
Validation loss: 2.365260042869084

Epoch: 5| Step: 7
Training loss: 0.8001863083857732
Validation loss: 2.3772940056945844

Epoch: 5| Step: 8
Training loss: 0.3645128272773056
Validation loss: 2.365797019670296

Epoch: 5| Step: 9
Training loss: 0.5389354113715611
Validation loss: 2.369300476756858

Epoch: 5| Step: 10
Training loss: 0.7418997759004103
Validation loss: 2.3543125499057194

Epoch: 315| Step: 0
Training loss: 0.6181163558509827
Validation loss: 2.3553544958248684

Epoch: 5| Step: 1
Training loss: 0.7071880777839596
Validation loss: 2.3247291915103423

Epoch: 5| Step: 2
Training loss: 0.34399202886275704
Validation loss: 2.3592137090974146

Epoch: 5| Step: 3
Training loss: 0.8708202120752182
Validation loss: 2.3369861048636733

Epoch: 5| Step: 4
Training loss: 0.6571405816483047
Validation loss: 2.327537417325108

Epoch: 5| Step: 5
Training loss: 0.41618490580758366
Validation loss: 2.3415542642855205

Epoch: 5| Step: 6
Training loss: 0.6346373912690293
Validation loss: 2.3420156338919687

Epoch: 5| Step: 7
Training loss: 0.6596162381843576
Validation loss: 2.377278397084003

Epoch: 5| Step: 8
Training loss: 0.41474503817243197
Validation loss: 2.3766713179717533

Epoch: 5| Step: 9
Training loss: 0.49775684364055356
Validation loss: 2.3553073978601056

Epoch: 5| Step: 10
Training loss: 0.4389972441430367
Validation loss: 2.377949709847038

Epoch: 316| Step: 0
Training loss: 0.7965656876977267
Validation loss: 2.4022462091553667

Epoch: 5| Step: 1
Training loss: 0.2653750618140804
Validation loss: 2.4243976433963215

Epoch: 5| Step: 2
Training loss: 0.5324072854722232
Validation loss: 2.3847787099538755

Epoch: 5| Step: 3
Training loss: 0.6250754072475674
Validation loss: 2.40500387317031

Epoch: 5| Step: 4
Training loss: 0.5562209839700184
Validation loss: 2.4009721403488413

Epoch: 5| Step: 5
Training loss: 0.46849760572072047
Validation loss: 2.335060366777986

Epoch: 5| Step: 6
Training loss: 0.6874995448371074
Validation loss: 2.330623352394977

Epoch: 5| Step: 7
Training loss: 0.692575834026302
Validation loss: 2.2995755357021492

Epoch: 5| Step: 8
Training loss: 0.5606767988994165
Validation loss: 2.3332445908589525

Epoch: 5| Step: 9
Training loss: 0.500942058007058
Validation loss: 2.325234196855843

Epoch: 5| Step: 10
Training loss: 0.5937148635908126
Validation loss: 2.3403008658672393

Epoch: 317| Step: 0
Training loss: 0.5677210575975942
Validation loss: 2.3480443147282752

Epoch: 5| Step: 1
Training loss: 0.30620389562121403
Validation loss: 2.3441882953528412

Epoch: 5| Step: 2
Training loss: 0.7882171483814752
Validation loss: 2.331742482053766

Epoch: 5| Step: 3
Training loss: 0.6487507350821915
Validation loss: 2.3566237062035604

Epoch: 5| Step: 4
Training loss: 0.4254377536921433
Validation loss: 2.358053180350634

Epoch: 5| Step: 5
Training loss: 0.6596290695501521
Validation loss: 2.378479171402257

Epoch: 5| Step: 6
Training loss: 0.6181798514086883
Validation loss: 2.366246028682925

Epoch: 5| Step: 7
Training loss: 0.4661537432576662
Validation loss: 2.3610591102952543

Epoch: 5| Step: 8
Training loss: 0.6305636253017941
Validation loss: 2.379147503207822

Epoch: 5| Step: 9
Training loss: 0.4059211426949346
Validation loss: 2.3713869614074894

Epoch: 5| Step: 10
Training loss: 0.7146019448469266
Validation loss: 2.386699215834364

Epoch: 318| Step: 0
Training loss: 0.49139432725861426
Validation loss: 2.3638658034354507

Epoch: 5| Step: 1
Training loss: 0.7548911031289963
Validation loss: 2.370073213634996

Epoch: 5| Step: 2
Training loss: 0.41676002489697483
Validation loss: 2.3724141997128023

Epoch: 5| Step: 3
Training loss: 0.5607737437649581
Validation loss: 2.3419277093685347

Epoch: 5| Step: 4
Training loss: 0.4445128371677486
Validation loss: 2.349886946663156

Epoch: 5| Step: 5
Training loss: 0.712610769863471
Validation loss: 2.314308255498502

Epoch: 5| Step: 6
Training loss: 0.5959003059610477
Validation loss: 2.32749281026771

Epoch: 5| Step: 7
Training loss: 0.5788891098635653
Validation loss: 2.301022456423404

Epoch: 5| Step: 8
Training loss: 0.37344439033312565
Validation loss: 2.28924690838482

Epoch: 5| Step: 9
Training loss: 0.543851888910373
Validation loss: 2.3143328049950047

Epoch: 5| Step: 10
Training loss: 0.7489438965899985
Validation loss: 2.362599201814041

Epoch: 319| Step: 0
Training loss: 0.6509166801005609
Validation loss: 2.331430401027388

Epoch: 5| Step: 1
Training loss: 0.6457750283861554
Validation loss: 2.3405595838595756

Epoch: 5| Step: 2
Training loss: 0.3819630989181617
Validation loss: 2.3352518892181444

Epoch: 5| Step: 3
Training loss: 0.5827819540083065
Validation loss: 2.344772301315016

Epoch: 5| Step: 4
Training loss: 0.7247350948705112
Validation loss: 2.3181024422097916

Epoch: 5| Step: 5
Training loss: 0.6246361150021735
Validation loss: 2.331229763245035

Epoch: 5| Step: 6
Training loss: 0.49487994226395227
Validation loss: 2.337971872209198

Epoch: 5| Step: 7
Training loss: 0.7987269778209758
Validation loss: 2.310659226352586

Epoch: 5| Step: 8
Training loss: 0.26047289082439984
Validation loss: 2.3121795975548887

Epoch: 5| Step: 9
Training loss: 0.47876650403312665
Validation loss: 2.3086952098478117

Epoch: 5| Step: 10
Training loss: 0.3773437610570934
Validation loss: 2.3543428378152838

Epoch: 320| Step: 0
Training loss: 0.7359243241930694
Validation loss: 2.382569892000262

Epoch: 5| Step: 1
Training loss: 0.2669750434154236
Validation loss: 2.40037406972349

Epoch: 5| Step: 2
Training loss: 0.6156368573978424
Validation loss: 2.4336575411679657

Epoch: 5| Step: 3
Training loss: 0.5463247255502943
Validation loss: 2.3918610948881014

Epoch: 5| Step: 4
Training loss: 0.6450855530325832
Validation loss: 2.4230049083020893

Epoch: 5| Step: 5
Training loss: 0.7788969079531605
Validation loss: 2.4297731757221896

Epoch: 5| Step: 6
Training loss: 0.19277276538550056
Validation loss: 2.3436593331468565

Epoch: 5| Step: 7
Training loss: 0.6797491023768693
Validation loss: 2.344319347289301

Epoch: 5| Step: 8
Training loss: 0.5693273789038984
Validation loss: 2.3328139738652114

Epoch: 5| Step: 9
Training loss: 0.4884329293220838
Validation loss: 2.3195860422857457

Epoch: 5| Step: 10
Training loss: 0.4584906987044475
Validation loss: 2.317806190304357

Epoch: 321| Step: 0
Training loss: 0.6700790265435168
Validation loss: 2.2886145850429718

Epoch: 5| Step: 1
Training loss: 0.636325831962374
Validation loss: 2.2984757076554434

Epoch: 5| Step: 2
Training loss: 0.4088245571453892
Validation loss: 2.2939558444397794

Epoch: 5| Step: 3
Training loss: 0.6835855102042465
Validation loss: 2.332428371237604

Epoch: 5| Step: 4
Training loss: 0.5930782835141826
Validation loss: 2.3480019102585445

Epoch: 5| Step: 5
Training loss: 0.5016565003056722
Validation loss: 2.3570774754315105

Epoch: 5| Step: 6
Training loss: 0.5852365497247746
Validation loss: 2.422039628429122

Epoch: 5| Step: 7
Training loss: 0.31787008587139803
Validation loss: 2.4268910142004914

Epoch: 5| Step: 8
Training loss: 0.6206153130519632
Validation loss: 2.4270930903759416

Epoch: 5| Step: 9
Training loss: 0.7101226160794724
Validation loss: 2.4298170804509103

Epoch: 5| Step: 10
Training loss: 0.32690030836958417
Validation loss: 2.3890795011215995

Epoch: 322| Step: 0
Training loss: 0.4744980606968023
Validation loss: 2.403611186127594

Epoch: 5| Step: 1
Training loss: 0.5041500654981549
Validation loss: 2.38449289293354

Epoch: 5| Step: 2
Training loss: 0.5119081685332018
Validation loss: 2.381357984113317

Epoch: 5| Step: 3
Training loss: 0.5725467499131449
Validation loss: 2.3397788222080362

Epoch: 5| Step: 4
Training loss: 0.8044528433858618
Validation loss: 2.304410679431001

Epoch: 5| Step: 5
Training loss: 0.5616224118785882
Validation loss: 2.332019653280485

Epoch: 5| Step: 6
Training loss: 0.7956284141017783
Validation loss: 2.3350972029100947

Epoch: 5| Step: 7
Training loss: 0.48109163056489357
Validation loss: 2.3287724499467473

Epoch: 5| Step: 8
Training loss: 0.4992502820439657
Validation loss: 2.3669989179195285

Epoch: 5| Step: 9
Training loss: 0.3818015744095898
Validation loss: 2.3629211091708733

Epoch: 5| Step: 10
Training loss: 0.5249227830322878
Validation loss: 2.350013090283536

Epoch: 323| Step: 0
Training loss: 0.3935888573742625
Validation loss: 2.3126069254545683

Epoch: 5| Step: 1
Training loss: 0.6920507196860178
Validation loss: 2.3684195127525953

Epoch: 5| Step: 2
Training loss: 0.6453151675116061
Validation loss: 2.3415752633320337

Epoch: 5| Step: 3
Training loss: 0.2488062041970659
Validation loss: 2.3320482937420888

Epoch: 5| Step: 4
Training loss: 0.4156686473099223
Validation loss: 2.3455844440754694

Epoch: 5| Step: 5
Training loss: 0.9963114481873091
Validation loss: 2.346158633762396

Epoch: 5| Step: 6
Training loss: 0.36443545430511576
Validation loss: 2.350053524868726

Epoch: 5| Step: 7
Training loss: 0.7187371874786809
Validation loss: 2.3693055330509094

Epoch: 5| Step: 8
Training loss: 0.5382781472967942
Validation loss: 2.3928537528362996

Epoch: 5| Step: 9
Training loss: 0.3292908393062363
Validation loss: 2.3717657604907845

Epoch: 5| Step: 10
Training loss: 0.21547655199350385
Validation loss: 2.384415861826401

Epoch: 324| Step: 0
Training loss: 0.6402333620911755
Validation loss: 2.3816519759720896

Epoch: 5| Step: 1
Training loss: 0.6415632866484385
Validation loss: 2.370549301384891

Epoch: 5| Step: 2
Training loss: 0.4218190827222736
Validation loss: 2.3645144502198754

Epoch: 5| Step: 3
Training loss: 0.2984242421345987
Validation loss: 2.350199402897842

Epoch: 5| Step: 4
Training loss: 0.5056191245776225
Validation loss: 2.3526599642358255

Epoch: 5| Step: 5
Training loss: 0.6166405004242409
Validation loss: 2.338759272519459

Epoch: 5| Step: 6
Training loss: 0.5123567753212505
Validation loss: 2.3497831490225827

Epoch: 5| Step: 7
Training loss: 0.7745107275341185
Validation loss: 2.341213296843102

Epoch: 5| Step: 8
Training loss: 0.4825683402301059
Validation loss: 2.328738778954398

Epoch: 5| Step: 9
Training loss: 0.5619019667165852
Validation loss: 2.3133050109953115

Epoch: 5| Step: 10
Training loss: 0.4166027278320496
Validation loss: 2.3465362831791756

Epoch: 325| Step: 0
Training loss: 0.5937683955906631
Validation loss: 2.3641557486225255

Epoch: 5| Step: 1
Training loss: 0.490276562824611
Validation loss: 2.371190667859891

Epoch: 5| Step: 2
Training loss: 0.43656020041688176
Validation loss: 2.3645779463841397

Epoch: 5| Step: 3
Training loss: 0.5568379905553118
Validation loss: 2.403665839135005

Epoch: 5| Step: 4
Training loss: 0.3431056659580875
Validation loss: 2.3860354092365457

Epoch: 5| Step: 5
Training loss: 0.48963041451162626
Validation loss: 2.3724786471496895

Epoch: 5| Step: 6
Training loss: 0.7123606763110222
Validation loss: 2.3755049748856387

Epoch: 5| Step: 7
Training loss: 0.7232717830939132
Validation loss: 2.3496076445270164

Epoch: 5| Step: 8
Training loss: 0.3754384735765403
Validation loss: 2.343011217616297

Epoch: 5| Step: 9
Training loss: 0.5742418193724358
Validation loss: 2.3067010697573265

Epoch: 5| Step: 10
Training loss: 0.5259712442780098
Validation loss: 2.284784612663928

Epoch: 326| Step: 0
Training loss: 0.196357809904856
Validation loss: 2.31241174311619

Epoch: 5| Step: 1
Training loss: 0.5270262150731775
Validation loss: 2.2900491366300497

Epoch: 5| Step: 2
Training loss: 0.6664758250151237
Validation loss: 2.3185496191687607

Epoch: 5| Step: 3
Training loss: 0.5591811446245177
Validation loss: 2.3170721257731195

Epoch: 5| Step: 4
Training loss: 0.6483136943606448
Validation loss: 2.3422897876393916

Epoch: 5| Step: 5
Training loss: 0.7348584551985425
Validation loss: 2.375302630639465

Epoch: 5| Step: 6
Training loss: 0.6091746954730185
Validation loss: 2.3745494910705958

Epoch: 5| Step: 7
Training loss: 0.6449427822520365
Validation loss: 2.373374376140292

Epoch: 5| Step: 8
Training loss: 0.15878843422327873
Validation loss: 2.3703150695310535

Epoch: 5| Step: 9
Training loss: 0.5375122224172156
Validation loss: 2.373070903808172

Epoch: 5| Step: 10
Training loss: 0.32011750729203325
Validation loss: 2.3646699312120485

Epoch: 327| Step: 0
Training loss: 0.4591788671203061
Validation loss: 2.4224624963874635

Epoch: 5| Step: 1
Training loss: 0.6079041262408013
Validation loss: 2.3852010556853664

Epoch: 5| Step: 2
Training loss: 0.3863246142282833
Validation loss: 2.4002713531139

Epoch: 5| Step: 3
Training loss: 0.41526217578397484
Validation loss: 2.436534919821041

Epoch: 5| Step: 4
Training loss: 0.7113196215888551
Validation loss: 2.4059369469952867

Epoch: 5| Step: 5
Training loss: 0.5716967570705496
Validation loss: 2.4031085168583193

Epoch: 5| Step: 6
Training loss: 0.5306885782081937
Validation loss: 2.38817375485122

Epoch: 5| Step: 7
Training loss: 0.6604405304561345
Validation loss: 2.373942211943584

Epoch: 5| Step: 8
Training loss: 0.3492266088706585
Validation loss: 2.3086890824959907

Epoch: 5| Step: 9
Training loss: 0.4883931298826766
Validation loss: 2.345829743315704

Epoch: 5| Step: 10
Training loss: 0.6195312615451114
Validation loss: 2.3210170142135067

Epoch: 328| Step: 0
Training loss: 0.612921882838864
Validation loss: 2.3576216076776793

Epoch: 5| Step: 1
Training loss: 0.5613690769492113
Validation loss: 2.302930506665376

Epoch: 5| Step: 2
Training loss: 0.21208712986306597
Validation loss: 2.3056692755818737

Epoch: 5| Step: 3
Training loss: 0.8209989672688018
Validation loss: 2.3005591100610094

Epoch: 5| Step: 4
Training loss: 0.3882246271674396
Validation loss: 2.3009284842326747

Epoch: 5| Step: 5
Training loss: 0.6066127674906102
Validation loss: 2.312924982080068

Epoch: 5| Step: 6
Training loss: 0.4227909987424852
Validation loss: 2.334593226921924

Epoch: 5| Step: 7
Training loss: 0.49629776431715195
Validation loss: 2.363110554760579

Epoch: 5| Step: 8
Training loss: 0.700839248009337
Validation loss: 2.3922745656020297

Epoch: 5| Step: 9
Training loss: 0.3405823190879483
Validation loss: 2.3890977673223976

Epoch: 5| Step: 10
Training loss: 0.4789960512534064
Validation loss: 2.348028064030185

Epoch: 329| Step: 0
Training loss: 0.7466469356648969
Validation loss: 2.3809143639897297

Epoch: 5| Step: 1
Training loss: 0.14499106593396827
Validation loss: 2.401913278854198

Epoch: 5| Step: 2
Training loss: 0.5506728315849212
Validation loss: 2.3443659453644288

Epoch: 5| Step: 3
Training loss: 0.49514832107199985
Validation loss: 2.3709554883817314

Epoch: 5| Step: 4
Training loss: 0.6624663524360266
Validation loss: 2.345090613661548

Epoch: 5| Step: 5
Training loss: 0.5559383848203637
Validation loss: 2.3271954658686904

Epoch: 5| Step: 6
Training loss: 0.487271860121626
Validation loss: 2.373193128001777

Epoch: 5| Step: 7
Training loss: 0.4655746996035649
Validation loss: 2.3002556794713676

Epoch: 5| Step: 8
Training loss: 0.556605876708045
Validation loss: 2.3086694311095135

Epoch: 5| Step: 9
Training loss: 0.2646729855571823
Validation loss: 2.3350602372269016

Epoch: 5| Step: 10
Training loss: 0.6543829106943017
Validation loss: 2.3447791877264694

Epoch: 330| Step: 0
Training loss: 0.4476623108671567
Validation loss: 2.394004513986394

Epoch: 5| Step: 1
Training loss: 0.5377897357722276
Validation loss: 2.3842818322830928

Epoch: 5| Step: 2
Training loss: 0.5053145962154433
Validation loss: 2.327438708118092

Epoch: 5| Step: 3
Training loss: 0.6285531610692373
Validation loss: 2.3812415334736037

Epoch: 5| Step: 4
Training loss: 0.6021516812831381
Validation loss: 2.3669758493631545

Epoch: 5| Step: 5
Training loss: 0.5247766814516011
Validation loss: 2.345113386983012

Epoch: 5| Step: 6
Training loss: 0.5616961139049438
Validation loss: 2.329309175968602

Epoch: 5| Step: 7
Training loss: 0.4733788350083158
Validation loss: 2.3249268253334776

Epoch: 5| Step: 8
Training loss: 0.6997474078436701
Validation loss: 2.350080821406687

Epoch: 5| Step: 9
Training loss: 0.11945313366352896
Validation loss: 2.3622028507077553

Epoch: 5| Step: 10
Training loss: 0.4349393499230622
Validation loss: 2.356777515899334

Epoch: 331| Step: 0
Training loss: 0.5201398969871668
Validation loss: 2.3800631828225014

Epoch: 5| Step: 1
Training loss: 0.2958860992780101
Validation loss: 2.4097586611456054

Epoch: 5| Step: 2
Training loss: 0.47885849793971486
Validation loss: 2.3863585731879864

Epoch: 5| Step: 3
Training loss: 0.6367553279176033
Validation loss: 2.3832554795950376

Epoch: 5| Step: 4
Training loss: 0.42442395918042675
Validation loss: 2.398293433699777

Epoch: 5| Step: 5
Training loss: 0.46249865583276023
Validation loss: 2.3638727510797133

Epoch: 5| Step: 6
Training loss: 0.4036870955840083
Validation loss: 2.314844441332532

Epoch: 5| Step: 7
Training loss: 0.620890746139498
Validation loss: 2.317169332146434

Epoch: 5| Step: 8
Training loss: 0.44672334271712283
Validation loss: 2.31439250497839

Epoch: 5| Step: 9
Training loss: 0.3137546268631107
Validation loss: 2.2782234594079087

Epoch: 5| Step: 10
Training loss: 0.8872623877715252
Validation loss: 2.298810349845075

Epoch: 332| Step: 0
Training loss: 0.5800401052223733
Validation loss: 2.2853854829817095

Epoch: 5| Step: 1
Training loss: 0.49515992230359346
Validation loss: 2.323240801534466

Epoch: 5| Step: 2
Training loss: 0.41331318766134234
Validation loss: 2.302648365185629

Epoch: 5| Step: 3
Training loss: 0.6234755521170634
Validation loss: 2.318597579066828

Epoch: 5| Step: 4
Training loss: 0.3695049203924477
Validation loss: 2.3375663199653354

Epoch: 5| Step: 5
Training loss: 0.5934187818551219
Validation loss: 2.3240880636974874

Epoch: 5| Step: 6
Training loss: 0.5194618924531703
Validation loss: 2.3732811775032596

Epoch: 5| Step: 7
Training loss: 0.40391448730096974
Validation loss: 2.3734677536587507

Epoch: 5| Step: 8
Training loss: 0.4077781765111821
Validation loss: 2.3820289446467666

Epoch: 5| Step: 9
Training loss: 0.731703220017717
Validation loss: 2.3402260669266215

Epoch: 5| Step: 10
Training loss: 0.39660203061827165
Validation loss: 2.3244870399221784

Epoch: 333| Step: 0
Training loss: 0.6275651742897005
Validation loss: 2.4019628100530754

Epoch: 5| Step: 1
Training loss: 0.21696137725443754
Validation loss: 2.3714741028782367

Epoch: 5| Step: 2
Training loss: 0.47000351828414877
Validation loss: 2.3495502970661155

Epoch: 5| Step: 3
Training loss: 0.8202701739336172
Validation loss: 2.3656733226247306

Epoch: 5| Step: 4
Training loss: 0.4660831565561044
Validation loss: 2.348940291782342

Epoch: 5| Step: 5
Training loss: 0.6646630656885509
Validation loss: 2.344968913883049

Epoch: 5| Step: 6
Training loss: 0.666218209429676
Validation loss: 2.3549517854986757

Epoch: 5| Step: 7
Training loss: 0.44985045093820325
Validation loss: 2.404141360220958

Epoch: 5| Step: 8
Training loss: 0.2603762054800037
Validation loss: 2.3376395428173016

Epoch: 5| Step: 9
Training loss: 0.33752313375661336
Validation loss: 2.370516867268359

Epoch: 5| Step: 10
Training loss: 0.4459485814910391
Validation loss: 2.381600142365018

Epoch: 334| Step: 0
Training loss: 0.3955189644454004
Validation loss: 2.368854716022633

Epoch: 5| Step: 1
Training loss: 0.6364218833046533
Validation loss: 2.3740288508904706

Epoch: 5| Step: 2
Training loss: 0.22627233142132658
Validation loss: 2.3762751978646914

Epoch: 5| Step: 3
Training loss: 0.46017389571289025
Validation loss: 2.3309049942278834

Epoch: 5| Step: 4
Training loss: 0.641901326517142
Validation loss: 2.3615271668813813

Epoch: 5| Step: 5
Training loss: 0.4495819945163726
Validation loss: 2.33318570617829

Epoch: 5| Step: 6
Training loss: 0.6236508112077369
Validation loss: 2.349725138675089

Epoch: 5| Step: 7
Training loss: 0.46423630333592686
Validation loss: 2.3278678944228806

Epoch: 5| Step: 8
Training loss: 0.6625348639761434
Validation loss: 2.3354998609465647

Epoch: 5| Step: 9
Training loss: 0.5428359603423956
Validation loss: 2.3111633033823837

Epoch: 5| Step: 10
Training loss: 0.4761568437915456
Validation loss: 2.364329515041398

Epoch: 335| Step: 0
Training loss: 0.4760385353213549
Validation loss: 2.4054157583239175

Epoch: 5| Step: 1
Training loss: 0.6595123581845488
Validation loss: 2.3986645042953114

Epoch: 5| Step: 2
Training loss: 0.42254232679899245
Validation loss: 2.3639020228736123

Epoch: 5| Step: 3
Training loss: 0.5313219414412739
Validation loss: 2.3314004482835085

Epoch: 5| Step: 4
Training loss: 0.32031978040655507
Validation loss: 2.3591432023594567

Epoch: 5| Step: 5
Training loss: 0.704657072268859
Validation loss: 2.357222411429036

Epoch: 5| Step: 6
Training loss: 0.44217466463796745
Validation loss: 2.3457018080439878

Epoch: 5| Step: 7
Training loss: 0.5481493135668754
Validation loss: 2.315649633138322

Epoch: 5| Step: 8
Training loss: 0.5976668462873587
Validation loss: 2.3100588157045876

Epoch: 5| Step: 9
Training loss: 0.38816674153917
Validation loss: 2.3119711810325367

Epoch: 5| Step: 10
Training loss: 0.4587241875977006
Validation loss: 2.3146965007238474

Epoch: 336| Step: 0
Training loss: 0.711322303006575
Validation loss: 2.3185013221361657

Epoch: 5| Step: 1
Training loss: 0.5542781017476659
Validation loss: 2.2981975242284136

Epoch: 5| Step: 2
Training loss: 0.4796926541626217
Validation loss: 2.319057908911428

Epoch: 5| Step: 3
Training loss: 0.3045036910785464
Validation loss: 2.366125833071452

Epoch: 5| Step: 4
Training loss: 0.6291609064895325
Validation loss: 2.338418824469497

Epoch: 5| Step: 5
Training loss: 0.408843218500914
Validation loss: 2.348755767020929

Epoch: 5| Step: 6
Training loss: 0.3105329834332166
Validation loss: 2.320459183255373

Epoch: 5| Step: 7
Training loss: 0.4910807655115648
Validation loss: 2.298027124084523

Epoch: 5| Step: 8
Training loss: 0.7115171814946374
Validation loss: 2.287067673456071

Epoch: 5| Step: 9
Training loss: 0.5693594402611658
Validation loss: 2.295441967972994

Epoch: 5| Step: 10
Training loss: 0.22128283903523527
Validation loss: 2.318584310245298

Epoch: 337| Step: 0
Training loss: 0.6188644130003875
Validation loss: 2.3398308914622583

Epoch: 5| Step: 1
Training loss: 0.4218706554612993
Validation loss: 2.356165681245713

Epoch: 5| Step: 2
Training loss: 0.4782134211191656
Validation loss: 2.366377148784982

Epoch: 5| Step: 3
Training loss: 0.3792918298230593
Validation loss: 2.389560041619768

Epoch: 5| Step: 4
Training loss: 0.3389774220165212
Validation loss: 2.340033341682004

Epoch: 5| Step: 5
Training loss: 0.6481926927006341
Validation loss: 2.290060074942432

Epoch: 5| Step: 6
Training loss: 0.532984342858622
Validation loss: 2.278798361927991

Epoch: 5| Step: 7
Training loss: 0.544244680430358
Validation loss: 2.264649798760709

Epoch: 5| Step: 8
Training loss: 0.41831732858321535
Validation loss: 2.244197004858361

Epoch: 5| Step: 9
Training loss: 0.5103297419067643
Validation loss: 2.227225784615486

Epoch: 5| Step: 10
Training loss: 0.684703144676494
Validation loss: 2.2819430655009985

Epoch: 338| Step: 0
Training loss: 0.5843429995256119
Validation loss: 2.2657356028704405

Epoch: 5| Step: 1
Training loss: 0.4050702792284282
Validation loss: 2.2859628038418465

Epoch: 5| Step: 2
Training loss: 0.4730927052177969
Validation loss: 2.2957407154275544

Epoch: 5| Step: 3
Training loss: 0.6441498986496772
Validation loss: 2.372991326659007

Epoch: 5| Step: 4
Training loss: 0.29863197770635114
Validation loss: 2.384886233477631

Epoch: 5| Step: 5
Training loss: 0.4826288126923584
Validation loss: 2.4357709597271864

Epoch: 5| Step: 6
Training loss: 0.3199261102640582
Validation loss: 2.4230312258925495

Epoch: 5| Step: 7
Training loss: 0.5283797084399118
Validation loss: 2.434956302695874

Epoch: 5| Step: 8
Training loss: 0.6970859584618311
Validation loss: 2.4507428096905564

Epoch: 5| Step: 9
Training loss: 0.7862839831845263
Validation loss: 2.3987261554464174

Epoch: 5| Step: 10
Training loss: 0.13800378160288304
Validation loss: 2.349923886393286

Epoch: 339| Step: 0
Training loss: 0.5425769847091656
Validation loss: 2.26593870056964

Epoch: 5| Step: 1
Training loss: 0.7614722219749566
Validation loss: 2.2703871780264935

Epoch: 5| Step: 2
Training loss: 0.6401708667996063
Validation loss: 2.2326904625656114

Epoch: 5| Step: 3
Training loss: 0.6790030310581404
Validation loss: 2.254569964908207

Epoch: 5| Step: 4
Training loss: 0.4882624050318518
Validation loss: 2.2570342755063764

Epoch: 5| Step: 5
Training loss: 0.4088678195722889
Validation loss: 2.3193837493303393

Epoch: 5| Step: 6
Training loss: 0.24777295163831806
Validation loss: 2.356195171735916

Epoch: 5| Step: 7
Training loss: 0.3468676635035077
Validation loss: 2.3720505734024124

Epoch: 5| Step: 8
Training loss: 0.38173075053978694
Validation loss: 2.3910209900980073

Epoch: 5| Step: 9
Training loss: 0.5705333438894834
Validation loss: 2.3842938005881424

Epoch: 5| Step: 10
Training loss: 0.45840189883303195
Validation loss: 2.3982395861257735

Epoch: 340| Step: 0
Training loss: 0.5372040266387412
Validation loss: 2.4019328157665334

Epoch: 5| Step: 1
Training loss: 0.34557825193141084
Validation loss: 2.405852242451844

Epoch: 5| Step: 2
Training loss: 0.508558986430872
Validation loss: 2.358589415903631

Epoch: 5| Step: 3
Training loss: 0.4327534273784274
Validation loss: 2.399095379916822

Epoch: 5| Step: 4
Training loss: 0.5951262385422162
Validation loss: 2.345195819266642

Epoch: 5| Step: 5
Training loss: 0.6986093689416693
Validation loss: 2.326080036390129

Epoch: 5| Step: 6
Training loss: 0.5090788969393101
Validation loss: 2.2841732429784174

Epoch: 5| Step: 7
Training loss: 0.5695652181074305
Validation loss: 2.300851486657442

Epoch: 5| Step: 8
Training loss: 0.24234374451529658
Validation loss: 2.299997114854727

Epoch: 5| Step: 9
Training loss: 0.37027111224577147
Validation loss: 2.2938989899425217

Epoch: 5| Step: 10
Training loss: 0.617154277438506
Validation loss: 2.2772476428451416

Epoch: 341| Step: 0
Training loss: 0.3621627241585096
Validation loss: 2.282670879202762

Epoch: 5| Step: 1
Training loss: 0.6037915534178913
Validation loss: 2.3064938843325176

Epoch: 5| Step: 2
Training loss: 0.7527826662909766
Validation loss: 2.3075610551038324

Epoch: 5| Step: 3
Training loss: 0.3894995689438674
Validation loss: 2.329996517813785

Epoch: 5| Step: 4
Training loss: 0.2122670586867173
Validation loss: 2.3452040364281848

Epoch: 5| Step: 5
Training loss: 0.467204103844603
Validation loss: 2.379981838628218

Epoch: 5| Step: 6
Training loss: 0.3649237836993246
Validation loss: 2.3777568060858285

Epoch: 5| Step: 7
Training loss: 0.5807610803795938
Validation loss: 2.3987857177953402

Epoch: 5| Step: 8
Training loss: 0.5556363063644534
Validation loss: 2.382226881084359

Epoch: 5| Step: 9
Training loss: 0.42779382092287777
Validation loss: 2.3923375060732024

Epoch: 5| Step: 10
Training loss: 0.666852408601167
Validation loss: 2.3384620983123234

Epoch: 342| Step: 0
Training loss: 0.5030221502250369
Validation loss: 2.3411626599719915

Epoch: 5| Step: 1
Training loss: 0.4769960838672939
Validation loss: 2.3212737244883113

Epoch: 5| Step: 2
Training loss: 0.20535118452751752
Validation loss: 2.327747755146413

Epoch: 5| Step: 3
Training loss: 0.41835510365703665
Validation loss: 2.3415240759102223

Epoch: 5| Step: 4
Training loss: 0.35750741404068137
Validation loss: 2.337938960378922

Epoch: 5| Step: 5
Training loss: 0.6164970398775366
Validation loss: 2.359896489690425

Epoch: 5| Step: 6
Training loss: 0.31647176417507517
Validation loss: 2.3466012741802964

Epoch: 5| Step: 7
Training loss: 0.5133030368588014
Validation loss: 2.3603757699656978

Epoch: 5| Step: 8
Training loss: 0.3768287611663886
Validation loss: 2.3712937322284136

Epoch: 5| Step: 9
Training loss: 0.6265582210556382
Validation loss: 2.372701468498682

Epoch: 5| Step: 10
Training loss: 0.7948736227701166
Validation loss: 2.380912860851477

Epoch: 343| Step: 0
Training loss: 0.30777897289114287
Validation loss: 2.3797798524114766

Epoch: 5| Step: 1
Training loss: 0.48983765313888394
Validation loss: 2.4054322831643242

Epoch: 5| Step: 2
Training loss: 0.39614173101962075
Validation loss: 2.4010127385716684

Epoch: 5| Step: 3
Training loss: 0.6454782176194903
Validation loss: 2.3806853807329893

Epoch: 5| Step: 4
Training loss: 0.7666694368091239
Validation loss: 2.3663286001736497

Epoch: 5| Step: 5
Training loss: 0.5411349003274523
Validation loss: 2.3159850803112665

Epoch: 5| Step: 6
Training loss: 0.4571427918305308
Validation loss: 2.317628946819368

Epoch: 5| Step: 7
Training loss: 0.3719728797837815
Validation loss: 2.2878555749736096

Epoch: 5| Step: 8
Training loss: 0.33856830003096594
Validation loss: 2.251918802601996

Epoch: 5| Step: 9
Training loss: 0.44043005966542964
Validation loss: 2.2120591883850502

Epoch: 5| Step: 10
Training loss: 0.5306260427727579
Validation loss: 2.233616363162201

Epoch: 344| Step: 0
Training loss: 0.33921179714659316
Validation loss: 2.2062221654673273

Epoch: 5| Step: 1
Training loss: 0.2747789176998985
Validation loss: 2.2366844883838035

Epoch: 5| Step: 2
Training loss: 0.6849959896137318
Validation loss: 2.2468871952916936

Epoch: 5| Step: 3
Training loss: 0.47416392956878395
Validation loss: 2.2938757204643796

Epoch: 5| Step: 4
Training loss: 0.499767040580449
Validation loss: 2.3103175120290325

Epoch: 5| Step: 5
Training loss: 0.5889379860496358
Validation loss: 2.3777472453397586

Epoch: 5| Step: 6
Training loss: 0.5195985908174972
Validation loss: 2.388233945884616

Epoch: 5| Step: 7
Training loss: 0.4428478432538104
Validation loss: 2.368223064716434

Epoch: 5| Step: 8
Training loss: 0.42709787468074395
Validation loss: 2.3799073006564866

Epoch: 5| Step: 9
Training loss: 0.6140099587906493
Validation loss: 2.3679771929617885

Epoch: 5| Step: 10
Training loss: 0.42808580984912037
Validation loss: 2.3654362767037136

Epoch: 345| Step: 0
Training loss: 0.49103228920857145
Validation loss: 2.3242468369219837

Epoch: 5| Step: 1
Training loss: 0.3674928531795188
Validation loss: 2.3202218989984615

Epoch: 5| Step: 2
Training loss: 0.5556029435318737
Validation loss: 2.2962745594336362

Epoch: 5| Step: 3
Training loss: 0.5699425111189108
Validation loss: 2.3304616914291145

Epoch: 5| Step: 4
Training loss: 0.5059768952647122
Validation loss: 2.2960253643821407

Epoch: 5| Step: 5
Training loss: 0.5267159009305883
Validation loss: 2.2678998944059856

Epoch: 5| Step: 6
Training loss: 0.5548499232222425
Validation loss: 2.2717958457432412

Epoch: 5| Step: 7
Training loss: 0.22812081326601166
Validation loss: 2.282702831398803

Epoch: 5| Step: 8
Training loss: 0.5005511286283745
Validation loss: 2.281862374224556

Epoch: 5| Step: 9
Training loss: 0.24263591170205542
Validation loss: 2.269090519551978

Epoch: 5| Step: 10
Training loss: 0.6290807778005084
Validation loss: 2.2979314217801083

Epoch: 346| Step: 0
Training loss: 0.4280916576906614
Validation loss: 2.280575159521113

Epoch: 5| Step: 1
Training loss: 0.3400140094675752
Validation loss: 2.3451885072039125

Epoch: 5| Step: 2
Training loss: 0.40466918020132897
Validation loss: 2.3837328073141726

Epoch: 5| Step: 3
Training loss: 0.5480173441515942
Validation loss: 2.381558634084751

Epoch: 5| Step: 4
Training loss: 0.5020643474687805
Validation loss: 2.3400892374439857

Epoch: 5| Step: 5
Training loss: 0.5479663041938301
Validation loss: 2.371909281778938

Epoch: 5| Step: 6
Training loss: 0.5796972495027772
Validation loss: 2.329000535918858

Epoch: 5| Step: 7
Training loss: 0.4473461928119376
Validation loss: 2.3091453053144626

Epoch: 5| Step: 8
Training loss: 0.28096852522679716
Validation loss: 2.3173253766964583

Epoch: 5| Step: 9
Training loss: 0.5050700742429534
Validation loss: 2.2833072103145713

Epoch: 5| Step: 10
Training loss: 0.6053731535230222
Validation loss: 2.3216571703307616

Epoch: 347| Step: 0
Training loss: 0.3757810009739421
Validation loss: 2.319397717104827

Epoch: 5| Step: 1
Training loss: 0.4070291383655563
Validation loss: 2.3390794783264752

Epoch: 5| Step: 2
Training loss: 0.45955765005971644
Validation loss: 2.3956741158831707

Epoch: 5| Step: 3
Training loss: 0.6379198552364872
Validation loss: 2.351056406249693

Epoch: 5| Step: 4
Training loss: 0.5298806381321581
Validation loss: 2.362019035617106

Epoch: 5| Step: 5
Training loss: 0.4875679146092285
Validation loss: 2.3542870888132765

Epoch: 5| Step: 6
Training loss: 0.38954092277700375
Validation loss: 2.344887769170915

Epoch: 5| Step: 7
Training loss: 0.5119554685564915
Validation loss: 2.340583619240535

Epoch: 5| Step: 8
Training loss: 0.4175614484806008
Validation loss: 2.3222268951693352

Epoch: 5| Step: 9
Training loss: 0.4009404942437128
Validation loss: 2.3219633732036753

Epoch: 5| Step: 10
Training loss: 0.5777201910644228
Validation loss: 2.3140918925220317

Epoch: 348| Step: 0
Training loss: 0.5294518613356952
Validation loss: 2.352294509231793

Epoch: 5| Step: 1
Training loss: 0.3708681324193423
Validation loss: 2.3676611562741976

Epoch: 5| Step: 2
Training loss: 0.1808592386430593
Validation loss: 2.3779467235395524

Epoch: 5| Step: 3
Training loss: 0.5816964588305383
Validation loss: 2.385021959632256

Epoch: 5| Step: 4
Training loss: 0.45545161560179104
Validation loss: 2.3679519036973664

Epoch: 5| Step: 5
Training loss: 0.6366164704535442
Validation loss: 2.3628650482866673

Epoch: 5| Step: 6
Training loss: 0.44767154780640844
Validation loss: 2.3714093865236534

Epoch: 5| Step: 7
Training loss: 0.3161030128656731
Validation loss: 2.3907630554010137

Epoch: 5| Step: 8
Training loss: 0.5869448839368417
Validation loss: 2.3629807077306766

Epoch: 5| Step: 9
Training loss: 0.4006126904493436
Validation loss: 2.3662498174031246

Epoch: 5| Step: 10
Training loss: 0.5290529315351358
Validation loss: 2.327011856454813

Epoch: 349| Step: 0
Training loss: 0.4873467620237957
Validation loss: 2.3027400606303985

Epoch: 5| Step: 1
Training loss: 0.43190308613408757
Validation loss: 2.323125831931626

Epoch: 5| Step: 2
Training loss: 0.38369897459686997
Validation loss: 2.3287445893434877

Epoch: 5| Step: 3
Training loss: 0.2622604031649481
Validation loss: 2.328746190005157

Epoch: 5| Step: 4
Training loss: 0.32025487893234794
Validation loss: 2.3287231289218284

Epoch: 5| Step: 5
Training loss: 0.45939839945773
Validation loss: 2.320863890469276

Epoch: 5| Step: 6
Training loss: 0.4685033467172232
Validation loss: 2.371058175354844

Epoch: 5| Step: 7
Training loss: 0.646034522149828
Validation loss: 2.4232461012759745

Epoch: 5| Step: 8
Training loss: 0.4556380989274425
Validation loss: 2.394257085182772

Epoch: 5| Step: 9
Training loss: 0.7224734100807955
Validation loss: 2.394895265256888

Epoch: 5| Step: 10
Training loss: 0.4232156256705669
Validation loss: 2.3934394311737854

Epoch: 350| Step: 0
Training loss: 0.40916502933148696
Validation loss: 2.363185528144054

Epoch: 5| Step: 1
Training loss: 0.4120158229423643
Validation loss: 2.3126905651555743

Epoch: 5| Step: 2
Training loss: 0.5855248842188041
Validation loss: 2.2639114157020237

Epoch: 5| Step: 3
Training loss: 0.5615049143514149
Validation loss: 2.2939521609485127

Epoch: 5| Step: 4
Training loss: 0.4216550500906818
Validation loss: 2.2693298814175242

Epoch: 5| Step: 5
Training loss: 0.5045830373450791
Validation loss: 2.271771326337401

Epoch: 5| Step: 6
Training loss: 0.4292821706348352
Validation loss: 2.2643029553385396

Epoch: 5| Step: 7
Training loss: 0.48066431422965206
Validation loss: 2.269032601374619

Epoch: 5| Step: 8
Training loss: 0.28917363324462775
Validation loss: 2.3091383315077767

Epoch: 5| Step: 9
Training loss: 0.44993255957588124
Validation loss: 2.3186013444770803

Epoch: 5| Step: 10
Training loss: 0.552255483694209
Validation loss: 2.3154826519562848

Epoch: 351| Step: 0
Training loss: 0.6018213483084878
Validation loss: 2.362624898311995

Epoch: 5| Step: 1
Training loss: 0.5097185602787055
Validation loss: 2.3614657300612

Epoch: 5| Step: 2
Training loss: 0.4885917896784051
Validation loss: 2.393901992059715

Epoch: 5| Step: 3
Training loss: 0.4532002024892538
Validation loss: 2.3938096252921803

Epoch: 5| Step: 4
Training loss: 0.5069228375270559
Validation loss: 2.3545786759968363

Epoch: 5| Step: 5
Training loss: 0.5479190125312434
Validation loss: 2.3227577995745308

Epoch: 5| Step: 6
Training loss: 0.45641844984215485
Validation loss: 2.335890090104041

Epoch: 5| Step: 7
Training loss: 0.37970892449360194
Validation loss: 2.3097427568453615

Epoch: 5| Step: 8
Training loss: 0.39662034658184203
Validation loss: 2.3264224250868764

Epoch: 5| Step: 9
Training loss: 0.2220038509979966
Validation loss: 2.2889866499790186

Epoch: 5| Step: 10
Training loss: 0.380380260665574
Validation loss: 2.300406515748168

Epoch: 352| Step: 0
Training loss: 0.3577618467300777
Validation loss: 2.3327477822050473

Epoch: 5| Step: 1
Training loss: 0.21460627522710468
Validation loss: 2.3278677270279045

Epoch: 5| Step: 2
Training loss: 0.6456386647066229
Validation loss: 2.3781331624668542

Epoch: 5| Step: 3
Training loss: 0.3049174199327407
Validation loss: 2.3631229340488056

Epoch: 5| Step: 4
Training loss: 0.4273176209657764
Validation loss: 2.395726099240519

Epoch: 5| Step: 5
Training loss: 0.40812240605603417
Validation loss: 2.4130496905737044

Epoch: 5| Step: 6
Training loss: 0.4989539917403245
Validation loss: 2.4145826201606977

Epoch: 5| Step: 7
Training loss: 0.5047772295287589
Validation loss: 2.4156655360278645

Epoch: 5| Step: 8
Training loss: 0.5712368672320013
Validation loss: 2.403117570788649

Epoch: 5| Step: 9
Training loss: 0.4715720581087094
Validation loss: 2.3469357514040956

Epoch: 5| Step: 10
Training loss: 0.5540638493641421
Validation loss: 2.313677547004714

Epoch: 353| Step: 0
Training loss: 0.6024569017974705
Validation loss: 2.292516401678658

Epoch: 5| Step: 1
Training loss: 0.28681602542944135
Validation loss: 2.2601046784715275

Epoch: 5| Step: 2
Training loss: 0.6749110710762097
Validation loss: 2.2715425026540275

Epoch: 5| Step: 3
Training loss: 0.4925082236537705
Validation loss: 2.2839012231416556

Epoch: 5| Step: 4
Training loss: 0.3699567139925902
Validation loss: 2.320125659181701

Epoch: 5| Step: 5
Training loss: 0.31975448663559775
Validation loss: 2.307894526555684

Epoch: 5| Step: 6
Training loss: 0.554367322255741
Validation loss: 2.366088620794416

Epoch: 5| Step: 7
Training loss: 0.2863457053747526
Validation loss: 2.3706205519278987

Epoch: 5| Step: 8
Training loss: 0.44418053896403625
Validation loss: 2.3638411482840667

Epoch: 5| Step: 9
Training loss: 0.17329308859799042
Validation loss: 2.3264520793796177

Epoch: 5| Step: 10
Training loss: 0.5655122475971571
Validation loss: 2.3516180007169014

Epoch: 354| Step: 0
Training loss: 0.6036021593393363
Validation loss: 2.3161271425206578

Epoch: 5| Step: 1
Training loss: 0.520428764252537
Validation loss: 2.3360581525471287

Epoch: 5| Step: 2
Training loss: 0.391647107907539
Validation loss: 2.3575265205306226

Epoch: 5| Step: 3
Training loss: 0.499244148432136
Validation loss: 2.3736757819186507

Epoch: 5| Step: 4
Training loss: 0.5992707778247224
Validation loss: 2.38335885640126

Epoch: 5| Step: 5
Training loss: 0.2657873835408174
Validation loss: 2.379017679629701

Epoch: 5| Step: 6
Training loss: 0.43987194872050156
Validation loss: 2.3677994651734315

Epoch: 5| Step: 7
Training loss: 0.3786682876092733
Validation loss: 2.3682373842019198

Epoch: 5| Step: 8
Training loss: 0.3380761161096067
Validation loss: 2.399536808669301

Epoch: 5| Step: 9
Training loss: 0.4406679105493435
Validation loss: 2.3760313310953274

Epoch: 5| Step: 10
Training loss: 0.4498866879004056
Validation loss: 2.3691930942341823

Epoch: 355| Step: 0
Training loss: 0.5752470967892195
Validation loss: 2.3644898113190753

Epoch: 5| Step: 1
Training loss: 0.280278594604258
Validation loss: 2.3486525835885823

Epoch: 5| Step: 2
Training loss: 0.41872896597116743
Validation loss: 2.3218845927742624

Epoch: 5| Step: 3
Training loss: 0.5871215555091219
Validation loss: 2.310901813502912

Epoch: 5| Step: 4
Training loss: 0.4077564697945166
Validation loss: 2.3348687792186773

Epoch: 5| Step: 5
Training loss: 0.5413944281626387
Validation loss: 2.356332054394785

Epoch: 5| Step: 6
Training loss: 0.280121393200091
Validation loss: 2.360653227378589

Epoch: 5| Step: 7
Training loss: 0.44264284285288963
Validation loss: 2.31740108904011

Epoch: 5| Step: 8
Training loss: 0.4906883569373934
Validation loss: 2.3341267333000655

Epoch: 5| Step: 9
Training loss: 0.2215732873676769
Validation loss: 2.331860922263616

Epoch: 5| Step: 10
Training loss: 0.5582963645377351
Validation loss: 2.3393137429460245

Epoch: 356| Step: 0
Training loss: 0.41679243534086785
Validation loss: 2.314187491491016

Epoch: 5| Step: 1
Training loss: 0.4203866737178613
Validation loss: 2.3392179472185397

Epoch: 5| Step: 2
Training loss: 0.3139875175392847
Validation loss: 2.3229555707716316

Epoch: 5| Step: 3
Training loss: 0.5164516931065647
Validation loss: 2.331594553967742

Epoch: 5| Step: 4
Training loss: 0.38590986253260146
Validation loss: 2.308989029372448

Epoch: 5| Step: 5
Training loss: 0.28917899233074795
Validation loss: 2.3215761047210863

Epoch: 5| Step: 6
Training loss: 0.5820847301106862
Validation loss: 2.3358242912761793

Epoch: 5| Step: 7
Training loss: 0.2725327099845315
Validation loss: 2.3478448199075577

Epoch: 5| Step: 8
Training loss: 0.5522073180652921
Validation loss: 2.3375999200107795

Epoch: 5| Step: 9
Training loss: 0.5328519454181728
Validation loss: 2.346008662854226

Epoch: 5| Step: 10
Training loss: 0.44926080921481465
Validation loss: 2.3415163910765133

Epoch: 357| Step: 0
Training loss: 0.4166462197849973
Validation loss: 2.3513767467641795

Epoch: 5| Step: 1
Training loss: 0.6220857148232412
Validation loss: 2.3209815352274727

Epoch: 5| Step: 2
Training loss: 0.28201233015767574
Validation loss: 2.2992879863589204

Epoch: 5| Step: 3
Training loss: 0.35052304779683363
Validation loss: 2.3075995833650147

Epoch: 5| Step: 4
Training loss: 0.34764881340388354
Validation loss: 2.3523819046025936

Epoch: 5| Step: 5
Training loss: 0.2905693344416881
Validation loss: 2.322280149485915

Epoch: 5| Step: 6
Training loss: 0.4657982235195718
Validation loss: 2.342679131447427

Epoch: 5| Step: 7
Training loss: 0.5864322099801792
Validation loss: 2.2956494729876096

Epoch: 5| Step: 8
Training loss: 0.34411223789180023
Validation loss: 2.297474620268773

Epoch: 5| Step: 9
Training loss: 0.38162231323290996
Validation loss: 2.2965986018418874

Epoch: 5| Step: 10
Training loss: 0.595625525251159
Validation loss: 2.3040153968086075

Epoch: 358| Step: 0
Training loss: 0.16141030086777564
Validation loss: 2.2734783509910215

Epoch: 5| Step: 1
Training loss: 0.6107097337747539
Validation loss: 2.3117338916426973

Epoch: 5| Step: 2
Training loss: 0.404075598862137
Validation loss: 2.2890740869963735

Epoch: 5| Step: 3
Training loss: 0.4791617566009169
Validation loss: 2.3291890235309407

Epoch: 5| Step: 4
Training loss: 0.49266678317031637
Validation loss: 2.3326395071901844

Epoch: 5| Step: 5
Training loss: 0.555710024684256
Validation loss: 2.318107013948852

Epoch: 5| Step: 6
Training loss: 0.4265847804639956
Validation loss: 2.325482481090975

Epoch: 5| Step: 7
Training loss: 0.4439139909347939
Validation loss: 2.3498873655930614

Epoch: 5| Step: 8
Training loss: 0.407200032566103
Validation loss: 2.3847924000583904

Epoch: 5| Step: 9
Training loss: 0.3659248149833047
Validation loss: 2.362660793621355

Epoch: 5| Step: 10
Training loss: 0.21758899661559877
Validation loss: 2.3750342165301555

Epoch: 359| Step: 0
Training loss: 0.6763912600915883
Validation loss: 2.358507144125968

Epoch: 5| Step: 1
Training loss: 0.3435652192861566
Validation loss: 2.353844092293054

Epoch: 5| Step: 2
Training loss: 0.37956027972537604
Validation loss: 2.348583654213667

Epoch: 5| Step: 3
Training loss: 0.5231479014462039
Validation loss: 2.3634767279803808

Epoch: 5| Step: 4
Training loss: 0.35278571632836425
Validation loss: 2.3526235643669255

Epoch: 5| Step: 5
Training loss: 0.3274640055888917
Validation loss: 2.313885387706939

Epoch: 5| Step: 6
Training loss: 0.26575986860277045
Validation loss: 2.3206389270666357

Epoch: 5| Step: 7
Training loss: 0.16056693733701957
Validation loss: 2.3338888828347346

Epoch: 5| Step: 8
Training loss: 0.4685040146402257
Validation loss: 2.2874821408979624

Epoch: 5| Step: 9
Training loss: 0.5289345377312069
Validation loss: 2.336599066087078

Epoch: 5| Step: 10
Training loss: 0.554483268641878
Validation loss: 2.3255213449360435

Epoch: 360| Step: 0
Training loss: 0.3666496802137836
Validation loss: 2.3722545831666473

Epoch: 5| Step: 1
Training loss: 0.4852306130834145
Validation loss: 2.34113629809924

Epoch: 5| Step: 2
Training loss: 0.45491761745561526
Validation loss: 2.390282985203816

Epoch: 5| Step: 3
Training loss: 0.30646717730212275
Validation loss: 2.379216040605085

Epoch: 5| Step: 4
Training loss: 0.5535566596069481
Validation loss: 2.367028369290951

Epoch: 5| Step: 5
Training loss: 0.5186855345046517
Validation loss: 2.3808425288560993

Epoch: 5| Step: 6
Training loss: 0.40503669166367734
Validation loss: 2.366285810484166

Epoch: 5| Step: 7
Training loss: 0.45459771072677263
Validation loss: 2.3871836312177965

Epoch: 5| Step: 8
Training loss: 0.3910412668515036
Validation loss: 2.3993650481787316

Epoch: 5| Step: 9
Training loss: 0.43620534482486
Validation loss: 2.368321857445228

Epoch: 5| Step: 10
Training loss: 0.31855025156792866
Validation loss: 2.3580919854780444

Epoch: 361| Step: 0
Training loss: 0.42342969739418396
Validation loss: 2.3361230328562677

Epoch: 5| Step: 1
Training loss: 0.46496213479357806
Validation loss: 2.317463218906033

Epoch: 5| Step: 2
Training loss: 0.4148092553691637
Validation loss: 2.311542004916029

Epoch: 5| Step: 3
Training loss: 0.38966975715459695
Validation loss: 2.3018352865088496

Epoch: 5| Step: 4
Training loss: 0.42570928962935894
Validation loss: 2.3096794841637913

Epoch: 5| Step: 5
Training loss: 0.5179495576320644
Validation loss: 2.2582539727421524

Epoch: 5| Step: 6
Training loss: 0.4743124421527187
Validation loss: 2.3074707916897688

Epoch: 5| Step: 7
Training loss: 0.4581113913727944
Validation loss: 2.2583260082641754

Epoch: 5| Step: 8
Training loss: 0.3898682894274448
Validation loss: 2.2313960576006164

Epoch: 5| Step: 9
Training loss: 0.37838504771113757
Validation loss: 2.2382338928196246

Epoch: 5| Step: 10
Training loss: 0.3890660458138909
Validation loss: 2.2497331057622048

Epoch: 362| Step: 0
Training loss: 0.32298801259481036
Validation loss: 2.283958282737248

Epoch: 5| Step: 1
Training loss: 0.42329123106799293
Validation loss: 2.2560522404630046

Epoch: 5| Step: 2
Training loss: 0.4879187649872591
Validation loss: 2.323426482102248

Epoch: 5| Step: 3
Training loss: 0.43750466616730743
Validation loss: 2.373705449072473

Epoch: 5| Step: 4
Training loss: 0.25072274936936695
Validation loss: 2.4044735160879545

Epoch: 5| Step: 5
Training loss: 0.5335146095488539
Validation loss: 2.3874999243632047

Epoch: 5| Step: 6
Training loss: 0.4155116005413116
Validation loss: 2.406517847051069

Epoch: 5| Step: 7
Training loss: 0.4484461733680416
Validation loss: 2.3921671673357703

Epoch: 5| Step: 8
Training loss: 0.4199973282558748
Validation loss: 2.398616811725899

Epoch: 5| Step: 9
Training loss: 0.2301108766052069
Validation loss: 2.336763318362681

Epoch: 5| Step: 10
Training loss: 0.5481728548323279
Validation loss: 2.3097532184173333

Epoch: 363| Step: 0
Training loss: 0.37956781738064166
Validation loss: 2.30375631328806

Epoch: 5| Step: 1
Training loss: 0.29761791132528376
Validation loss: 2.300805318742613

Epoch: 5| Step: 2
Training loss: 0.30463421184431766
Validation loss: 2.285530162251611

Epoch: 5| Step: 3
Training loss: 0.36830563441437775
Validation loss: 2.3144223748846926

Epoch: 5| Step: 4
Training loss: 0.3609065096212859
Validation loss: 2.295064944431173

Epoch: 5| Step: 5
Training loss: 0.47999653444926593
Validation loss: 2.3258324618609847

Epoch: 5| Step: 6
Training loss: 0.49408530125371103
Validation loss: 2.2749369766591125

Epoch: 5| Step: 7
Training loss: 0.41384046827462717
Validation loss: 2.320438324559349

Epoch: 5| Step: 8
Training loss: 0.6422340840245567
Validation loss: 2.2931815620925136

Epoch: 5| Step: 9
Training loss: 0.3703745649131153
Validation loss: 2.3562068681644464

Epoch: 5| Step: 10
Training loss: 0.36087740030339394
Validation loss: 2.344133146955737

Epoch: 364| Step: 0
Training loss: 0.4265537428742993
Validation loss: 2.3896649372730354

Epoch: 5| Step: 1
Training loss: 0.46233144214539446
Validation loss: 2.3613380003011972

Epoch: 5| Step: 2
Training loss: 0.47660692977165464
Validation loss: 2.3580366094148344

Epoch: 5| Step: 3
Training loss: 0.3769091051716407
Validation loss: 2.372271800988245

Epoch: 5| Step: 4
Training loss: 0.407832273829671
Validation loss: 2.3526006033049636

Epoch: 5| Step: 5
Training loss: 0.3227577497798815
Validation loss: 2.3229442885231926

Epoch: 5| Step: 6
Training loss: 0.6058584374347371
Validation loss: 2.3482318266990654

Epoch: 5| Step: 7
Training loss: 0.459936153448772
Validation loss: 2.3211216045354575

Epoch: 5| Step: 8
Training loss: 0.3947153322943036
Validation loss: 2.289739782746492

Epoch: 5| Step: 9
Training loss: 0.22147724806203029
Validation loss: 2.2688427381760716

Epoch: 5| Step: 10
Training loss: 0.22453259524086422
Validation loss: 2.303430737190355

Epoch: 365| Step: 0
Training loss: 0.37854915190906424
Validation loss: 2.31572887310624

Epoch: 5| Step: 1
Training loss: 0.43992426729847417
Validation loss: 2.301002878271703

Epoch: 5| Step: 2
Training loss: 0.288027805993572
Validation loss: 2.3443024605621066

Epoch: 5| Step: 3
Training loss: 0.15399276364110176
Validation loss: 2.3362792176651204

Epoch: 5| Step: 4
Training loss: 0.4775532601397098
Validation loss: 2.361002526891969

Epoch: 5| Step: 5
Training loss: 0.5059505071258039
Validation loss: 2.351883668682257

Epoch: 5| Step: 6
Training loss: 0.6177394909476193
Validation loss: 2.359866537585892

Epoch: 5| Step: 7
Training loss: 0.37734842080331343
Validation loss: 2.361201543562072

Epoch: 5| Step: 8
Training loss: 0.40406567878387345
Validation loss: 2.341106452561859

Epoch: 5| Step: 9
Training loss: 0.468065604629642
Validation loss: 2.327790247191272

Epoch: 5| Step: 10
Training loss: 0.28645815271314073
Validation loss: 2.3550186985714756

Epoch: 366| Step: 0
Training loss: 0.30162992514262044
Validation loss: 2.3534971185820446

Epoch: 5| Step: 1
Training loss: 0.45785588263973087
Validation loss: 2.3354386933558153

Epoch: 5| Step: 2
Training loss: 0.5411621060707418
Validation loss: 2.37318116474879

Epoch: 5| Step: 3
Training loss: 0.33585700467948787
Validation loss: 2.3669756933986297

Epoch: 5| Step: 4
Training loss: 0.21856201132331654
Validation loss: 2.3871750328739383

Epoch: 5| Step: 5
Training loss: 0.2793125334931936
Validation loss: 2.3529605968579914

Epoch: 5| Step: 6
Training loss: 0.43261779027341435
Validation loss: 2.3457339513956597

Epoch: 5| Step: 7
Training loss: 0.6004451679777667
Validation loss: 2.3728564049349856

Epoch: 5| Step: 8
Training loss: 0.46853259131107855
Validation loss: 2.322996618137562

Epoch: 5| Step: 9
Training loss: 0.22911248144486554
Validation loss: 2.279127002640961

Epoch: 5| Step: 10
Training loss: 0.42350770994642317
Validation loss: 2.259866970775932

Epoch: 367| Step: 0
Training loss: 0.58440529443887
Validation loss: 2.259649141228439

Epoch: 5| Step: 1
Training loss: 0.3681428736248115
Validation loss: 2.245280432987528

Epoch: 5| Step: 2
Training loss: 0.2966419610351825
Validation loss: 2.228825963936979

Epoch: 5| Step: 3
Training loss: 0.44578657514117176
Validation loss: 2.2617320310894953

Epoch: 5| Step: 4
Training loss: 0.4413135397444609
Validation loss: 2.2500442331904282

Epoch: 5| Step: 5
Training loss: 0.12145614618032832
Validation loss: 2.2928154945465513

Epoch: 5| Step: 6
Training loss: 0.4312103681735947
Validation loss: 2.3145034302045158

Epoch: 5| Step: 7
Training loss: 0.3965996259981894
Validation loss: 2.3126403513241303

Epoch: 5| Step: 8
Training loss: 0.46661191332431035
Validation loss: 2.3419835347410984

Epoch: 5| Step: 9
Training loss: 0.3003689553489595
Validation loss: 2.357252784843971

Epoch: 5| Step: 10
Training loss: 0.47821460520016235
Validation loss: 2.352057971430862

Epoch: 368| Step: 0
Training loss: 0.365628239217902
Validation loss: 2.365111527332783

Epoch: 5| Step: 1
Training loss: 0.6186269560725361
Validation loss: 2.3805883944316513

Epoch: 5| Step: 2
Training loss: 0.4941245819020547
Validation loss: 2.3348589187830306

Epoch: 5| Step: 3
Training loss: 0.3613000807317817
Validation loss: 2.3567547834945906

Epoch: 5| Step: 4
Training loss: 0.2820468317097022
Validation loss: 2.3174703186607393

Epoch: 5| Step: 5
Training loss: 0.33360997904267736
Validation loss: 2.33146229415454

Epoch: 5| Step: 6
Training loss: 0.5681086245989577
Validation loss: 2.3605129651706203

Epoch: 5| Step: 7
Training loss: 0.38711350455136073
Validation loss: 2.307901670186912

Epoch: 5| Step: 8
Training loss: 0.35633434501827876
Validation loss: 2.340641959654236

Epoch: 5| Step: 9
Training loss: 0.292863407269461
Validation loss: 2.3659709678572325

Epoch: 5| Step: 10
Training loss: 0.16572403825713022
Validation loss: 2.3178817979072965

Epoch: 369| Step: 0
Training loss: 0.4033229356731243
Validation loss: 2.3552683601814377

Epoch: 5| Step: 1
Training loss: 0.3469427802904365
Validation loss: 2.3672598892006445

Epoch: 5| Step: 2
Training loss: 0.2639069815897132
Validation loss: 2.3854624870152947

Epoch: 5| Step: 3
Training loss: 0.28908652128468854
Validation loss: 2.3618232858409116

Epoch: 5| Step: 4
Training loss: 0.3724396642041754
Validation loss: 2.371995155742925

Epoch: 5| Step: 5
Training loss: 0.5508556721505653
Validation loss: 2.3395013497904915

Epoch: 5| Step: 6
Training loss: 0.46432058562333506
Validation loss: 2.346485301762351

Epoch: 5| Step: 7
Training loss: 0.5018300302579014
Validation loss: 2.2997017473979717

Epoch: 5| Step: 8
Training loss: 0.27988474672851055
Validation loss: 2.346905127039573

Epoch: 5| Step: 9
Training loss: 0.40427520251581306
Validation loss: 2.3065012601561308

Epoch: 5| Step: 10
Training loss: 0.3688730955756629
Validation loss: 2.327625619444901

Epoch: 370| Step: 0
Training loss: 0.4410465766850861
Validation loss: 2.295438227673913

Epoch: 5| Step: 1
Training loss: 0.39365217265165825
Validation loss: 2.3100598361405296

Epoch: 5| Step: 2
Training loss: 0.6452392388754123
Validation loss: 2.305517196850964

Epoch: 5| Step: 3
Training loss: 0.3085064704214927
Validation loss: 2.3245048034628715

Epoch: 5| Step: 4
Training loss: 0.45269904998597876
Validation loss: 2.327070872021667

Epoch: 5| Step: 5
Training loss: 0.48389235415290305
Validation loss: 2.322246762461992

Epoch: 5| Step: 6
Training loss: 0.2739592886981817
Validation loss: 2.349637794508583

Epoch: 5| Step: 7
Training loss: 0.34545394839872323
Validation loss: 2.4016887175622745

Epoch: 5| Step: 8
Training loss: 0.3304827540611608
Validation loss: 2.3830294139997417

Epoch: 5| Step: 9
Training loss: 0.3035526169630336
Validation loss: 2.406362552511544

Epoch: 5| Step: 10
Training loss: 0.22848561896879196
Validation loss: 2.423524581783192

Epoch: 371| Step: 0
Training loss: 0.34812678951303433
Validation loss: 2.4490653487159744

Epoch: 5| Step: 1
Training loss: 0.28713515548698787
Validation loss: 2.379186613492314

Epoch: 5| Step: 2
Training loss: 0.4348890528654761
Validation loss: 2.3810313910494845

Epoch: 5| Step: 3
Training loss: 0.4647244051789989
Validation loss: 2.385274150320517

Epoch: 5| Step: 4
Training loss: 0.38238287192026704
Validation loss: 2.330276527983647

Epoch: 5| Step: 5
Training loss: 0.4280835646744491
Validation loss: 2.2997017184139272

Epoch: 5| Step: 6
Training loss: 0.44981553614955117
Validation loss: 2.303630160142637

Epoch: 5| Step: 7
Training loss: 0.3667450125757558
Validation loss: 2.31537792704514

Epoch: 5| Step: 8
Training loss: 0.530715533285136
Validation loss: 2.316008280406731

Epoch: 5| Step: 9
Training loss: 0.4346644610312928
Validation loss: 2.3217946918774914

Epoch: 5| Step: 10
Training loss: 0.34072115966958016
Validation loss: 2.3438258836281882

Epoch: 372| Step: 0
Training loss: 0.3294525877939376
Validation loss: 2.307225516521536

Epoch: 5| Step: 1
Training loss: 0.42462620986932315
Validation loss: 2.328362001847172

Epoch: 5| Step: 2
Training loss: 0.2679472277926234
Validation loss: 2.3318445192043913

Epoch: 5| Step: 3
Training loss: 0.4279986048769272
Validation loss: 2.365560970175963

Epoch: 5| Step: 4
Training loss: 0.47773545172282267
Validation loss: 2.362262827691129

Epoch: 5| Step: 5
Training loss: 0.48151372458307007
Validation loss: 2.3428775823518593

Epoch: 5| Step: 6
Training loss: 0.494162140630395
Validation loss: 2.3766230254895473

Epoch: 5| Step: 7
Training loss: 0.39207916435244106
Validation loss: 2.3685590550984155

Epoch: 5| Step: 8
Training loss: 0.24252727731194484
Validation loss: 2.3259635185813416

Epoch: 5| Step: 9
Training loss: 0.38967172653468907
Validation loss: 2.3330755626083093

Epoch: 5| Step: 10
Training loss: 0.4487312325189875
Validation loss: 2.3346536705173215

Epoch: 373| Step: 0
Training loss: 0.33657850057454264
Validation loss: 2.3215974236081824

Epoch: 5| Step: 1
Training loss: 0.23664297458493533
Validation loss: 2.3312449142372866

Epoch: 5| Step: 2
Training loss: 0.30067816119538
Validation loss: 2.3759719142324895

Epoch: 5| Step: 3
Training loss: 0.4234985265357136
Validation loss: 2.3721013582319026

Epoch: 5| Step: 4
Training loss: 0.49068229850953704
Validation loss: 2.3754901790325706

Epoch: 5| Step: 5
Training loss: 0.6286123785700176
Validation loss: 2.3771758030204353

Epoch: 5| Step: 6
Training loss: 0.35688975595943206
Validation loss: 2.3485370653224007

Epoch: 5| Step: 7
Training loss: 0.4883030543227315
Validation loss: 2.4058258360391322

Epoch: 5| Step: 8
Training loss: 0.37882493316507815
Validation loss: 2.4273306980976463

Epoch: 5| Step: 9
Training loss: 0.1890620885797233
Validation loss: 2.4160775692576966

Epoch: 5| Step: 10
Training loss: 0.42680569866736773
Validation loss: 2.4600539520409064

Epoch: 374| Step: 0
Training loss: 0.3998544592129428
Validation loss: 2.47084589681098

Epoch: 5| Step: 1
Training loss: 0.40926977363126243
Validation loss: 2.415507221092711

Epoch: 5| Step: 2
Training loss: 0.3241991933416654
Validation loss: 2.418821796092436

Epoch: 5| Step: 3
Training loss: 0.32705052746830976
Validation loss: 2.4127522206175414

Epoch: 5| Step: 4
Training loss: 0.40052318704588974
Validation loss: 2.384300988423724

Epoch: 5| Step: 5
Training loss: 0.505950978354639
Validation loss: 2.366481854930966

Epoch: 5| Step: 6
Training loss: 0.30779478002751515
Validation loss: 2.323705935242201

Epoch: 5| Step: 7
Training loss: 0.4386496255451475
Validation loss: 2.324455466331404

Epoch: 5| Step: 8
Training loss: 0.3100735157657437
Validation loss: 2.3086768044243797

Epoch: 5| Step: 9
Training loss: 0.43080294352781445
Validation loss: 2.2585848235938806

Epoch: 5| Step: 10
Training loss: 0.4589102827290449
Validation loss: 2.3147120706004305

Epoch: 375| Step: 0
Training loss: 0.2835301057213719
Validation loss: 2.301189758848588

Epoch: 5| Step: 1
Training loss: 0.34344128270795166
Validation loss: 2.315468860964232

Epoch: 5| Step: 2
Training loss: 0.5851470447422304
Validation loss: 2.3459585305438555

Epoch: 5| Step: 3
Training loss: 0.13060382543630722
Validation loss: 2.3728782932539745

Epoch: 5| Step: 4
Training loss: 0.30431709026526416
Validation loss: 2.3992118957457738

Epoch: 5| Step: 5
Training loss: 0.31169998762603723
Validation loss: 2.39640252912228

Epoch: 5| Step: 6
Training loss: 0.4202459814479753
Validation loss: 2.3751482288539005

Epoch: 5| Step: 7
Training loss: 0.4828628501439918
Validation loss: 2.320979943570078

Epoch: 5| Step: 8
Training loss: 0.4835307547069284
Validation loss: 2.3213587338772936

Epoch: 5| Step: 9
Training loss: 0.30612812828655633
Validation loss: 2.3642005981088623

Epoch: 5| Step: 10
Training loss: 0.4917580683928198
Validation loss: 2.337141144680976

Epoch: 376| Step: 0
Training loss: 0.44691503518839515
Validation loss: 2.313276092483319

Epoch: 5| Step: 1
Training loss: 0.5914177766228442
Validation loss: 2.367866507534711

Epoch: 5| Step: 2
Training loss: 0.24396074916600102
Validation loss: 2.3850900444591927

Epoch: 5| Step: 3
Training loss: 0.15762058783813945
Validation loss: 2.3727365252770736

Epoch: 5| Step: 4
Training loss: 0.4227161851507466
Validation loss: 2.3784891932181704

Epoch: 5| Step: 5
Training loss: 0.2925494563237356
Validation loss: 2.390380358927997

Epoch: 5| Step: 6
Training loss: 0.43799437111455725
Validation loss: 2.4000755008491415

Epoch: 5| Step: 7
Training loss: 0.2897672053438249
Validation loss: 2.3853802651100042

Epoch: 5| Step: 8
Training loss: 0.3401274976375777
Validation loss: 2.3721163081534304

Epoch: 5| Step: 9
Training loss: 0.3409433224860059
Validation loss: 2.350986392563588

Epoch: 5| Step: 10
Training loss: 0.4840271685310785
Validation loss: 2.347579660238357

Epoch: 377| Step: 0
Training loss: 0.22460020295364946
Validation loss: 2.341393364611603

Epoch: 5| Step: 1
Training loss: 0.3839010216089494
Validation loss: 2.34395312013609

Epoch: 5| Step: 2
Training loss: 0.40890074624543676
Validation loss: 2.3456669111725668

Epoch: 5| Step: 3
Training loss: 0.37745698055296245
Validation loss: 2.343323868600678

Epoch: 5| Step: 4
Training loss: 0.5307333621931474
Validation loss: 2.32142612877922

Epoch: 5| Step: 5
Training loss: 0.41511694682257794
Validation loss: 2.3464378099921643

Epoch: 5| Step: 6
Training loss: 0.4202004329365511
Validation loss: 2.374809851210011

Epoch: 5| Step: 7
Training loss: 0.1502818048307886
Validation loss: 2.4033341108597406

Epoch: 5| Step: 8
Training loss: 0.2929645410871167
Validation loss: 2.3977736778010326

Epoch: 5| Step: 9
Training loss: 0.40573801276667787
Validation loss: 2.3674794231006175

Epoch: 5| Step: 10
Training loss: 0.40428038116571663
Validation loss: 2.3762098468046062

Epoch: 378| Step: 0
Training loss: 0.24909658666614776
Validation loss: 2.3852081002557943

Epoch: 5| Step: 1
Training loss: 0.38137576967910025
Validation loss: 2.367818642058859

Epoch: 5| Step: 2
Training loss: 0.28684552064077545
Validation loss: 2.390651967872865

Epoch: 5| Step: 3
Training loss: 0.46975316152782676
Validation loss: 2.3862439361945413

Epoch: 5| Step: 4
Training loss: 0.41507517937983346
Validation loss: 2.343339514659953

Epoch: 5| Step: 5
Training loss: 0.42857927112272415
Validation loss: 2.341705975425026

Epoch: 5| Step: 6
Training loss: 0.33178600903371397
Validation loss: 2.3390081421695843

Epoch: 5| Step: 7
Training loss: 0.4795460874636729
Validation loss: 2.358596202735196

Epoch: 5| Step: 8
Training loss: 0.43388604287063326
Validation loss: 2.3437789444862314

Epoch: 5| Step: 9
Training loss: 0.381200256385647
Validation loss: 2.330282259728839

Epoch: 5| Step: 10
Training loss: 0.4008041107617938
Validation loss: 2.338129162089303

Epoch: 379| Step: 0
Training loss: 0.3208150526614423
Validation loss: 2.3411583077758156

Epoch: 5| Step: 1
Training loss: 0.4089785060807602
Validation loss: 2.3870334293266406

Epoch: 5| Step: 2
Training loss: 0.3829162029011726
Validation loss: 2.361595119782577

Epoch: 5| Step: 3
Training loss: 0.43562907995560085
Validation loss: 2.3438460130064707

Epoch: 5| Step: 4
Training loss: 0.2610325428910024
Validation loss: 2.339641843846201

Epoch: 5| Step: 5
Training loss: 0.6600603112927749
Validation loss: 2.305520402070602

Epoch: 5| Step: 6
Training loss: 0.498650398347719
Validation loss: 2.3063990190904495

Epoch: 5| Step: 7
Training loss: 0.24618645844259784
Validation loss: 2.291638549975266

Epoch: 5| Step: 8
Training loss: 0.2442063128793985
Validation loss: 2.278729306896797

Epoch: 5| Step: 9
Training loss: 0.350010199909085
Validation loss: 2.2901725626753833

Epoch: 5| Step: 10
Training loss: 0.3497090117764097
Validation loss: 2.3157975504966117

Epoch: 380| Step: 0
Training loss: 0.385090685790672
Validation loss: 2.3027085929893443

Epoch: 5| Step: 1
Training loss: 0.4198744281311774
Validation loss: 2.333876954552322

Epoch: 5| Step: 2
Training loss: 0.3770330077603434
Validation loss: 2.3460021280990078

Epoch: 5| Step: 3
Training loss: 0.4498788213490716
Validation loss: 2.327288683122888

Epoch: 5| Step: 4
Training loss: 0.3639953731489081
Validation loss: 2.3655868214435256

Epoch: 5| Step: 5
Training loss: 0.5241396166316551
Validation loss: 2.3596951857500317

Epoch: 5| Step: 6
Training loss: 0.3038560575797575
Validation loss: 2.2883883081926726

Epoch: 5| Step: 7
Training loss: 0.2720557039806745
Validation loss: 2.3221685800710574

Epoch: 5| Step: 8
Training loss: 0.4730019526804243
Validation loss: 2.3399173401031055

Epoch: 5| Step: 9
Training loss: 0.3374285211635028
Validation loss: 2.2952813404269374

Epoch: 5| Step: 10
Training loss: 0.1450035715793714
Validation loss: 2.2733040083172407

Epoch: 381| Step: 0
Training loss: 0.4190133313001976
Validation loss: 2.3375671172759436

Epoch: 5| Step: 1
Training loss: 0.48130234458422816
Validation loss: 2.3090756512335844

Epoch: 5| Step: 2
Training loss: 0.2802502293564524
Validation loss: 2.304166102676784

Epoch: 5| Step: 3
Training loss: 0.4804829851228225
Validation loss: 2.3131043897884287

Epoch: 5| Step: 4
Training loss: 0.4546307013780588
Validation loss: 2.352131112635223

Epoch: 5| Step: 5
Training loss: 0.39145284668489955
Validation loss: 2.3438560144655365

Epoch: 5| Step: 6
Training loss: 0.4006722367062688
Validation loss: 2.3894114160936533

Epoch: 5| Step: 7
Training loss: 0.31693496798777293
Validation loss: 2.340006844382859

Epoch: 5| Step: 8
Training loss: 0.3269053908565526
Validation loss: 2.3665498025988523

Epoch: 5| Step: 9
Training loss: 0.3051900509359138
Validation loss: 2.3648969756580986

Epoch: 5| Step: 10
Training loss: 0.272716142913187
Validation loss: 2.3818636135416034

Epoch: 382| Step: 0
Training loss: 0.2638815999418678
Validation loss: 2.3745337256857115

Epoch: 5| Step: 1
Training loss: 0.2879677610954737
Validation loss: 2.3749050732366186

Epoch: 5| Step: 2
Training loss: 0.334614510631495
Validation loss: 2.371768584879729

Epoch: 5| Step: 3
Training loss: 0.44901904767293666
Validation loss: 2.393844436671448

Epoch: 5| Step: 4
Training loss: 0.24819579872795292
Validation loss: 2.3838875381429663

Epoch: 5| Step: 5
Training loss: 0.4420406711096239
Validation loss: 2.4301447954195887

Epoch: 5| Step: 6
Training loss: 0.3327047697512199
Validation loss: 2.391847906126823

Epoch: 5| Step: 7
Training loss: 0.37847372321123823
Validation loss: 2.3558565126466906

Epoch: 5| Step: 8
Training loss: 0.38734527852263473
Validation loss: 2.3900515950217995

Epoch: 5| Step: 9
Training loss: 0.2706135704895454
Validation loss: 2.3463240404122865

Epoch: 5| Step: 10
Training loss: 0.6061629714636426
Validation loss: 2.3445503694947853

Epoch: 383| Step: 0
Training loss: 0.43788407701127563
Validation loss: 2.3304426812670176

Epoch: 5| Step: 1
Training loss: 0.4474030995546797
Validation loss: 2.346633819805999

Epoch: 5| Step: 2
Training loss: 0.1763124017546149
Validation loss: 2.3509838463539867

Epoch: 5| Step: 3
Training loss: 0.4696590033977224
Validation loss: 2.3225213191778553

Epoch: 5| Step: 4
Training loss: 0.38961091972367645
Validation loss: 2.3320586525035782

Epoch: 5| Step: 5
Training loss: 0.4324219997443732
Validation loss: 2.33531684736446

Epoch: 5| Step: 6
Training loss: 0.37578266643169983
Validation loss: 2.356233412313567

Epoch: 5| Step: 7
Training loss: 0.38555590803546774
Validation loss: 2.38798257020106

Epoch: 5| Step: 8
Training loss: 0.26877712401199344
Validation loss: 2.3642926225570995

Epoch: 5| Step: 9
Training loss: 0.34626622864325585
Validation loss: 2.361779796351175

Epoch: 5| Step: 10
Training loss: 0.36930351094803765
Validation loss: 2.30781963512053

Epoch: 384| Step: 0
Training loss: 0.28966137991533786
Validation loss: 2.3017786299770493

Epoch: 5| Step: 1
Training loss: 0.36852934345382
Validation loss: 2.361842292533322

Epoch: 5| Step: 2
Training loss: 0.3142927957602421
Validation loss: 2.3356873680188333

Epoch: 5| Step: 3
Training loss: 0.5197486709313512
Validation loss: 2.345219220665639

Epoch: 5| Step: 4
Training loss: 0.3887296662425124
Validation loss: 2.3948903978683287

Epoch: 5| Step: 5
Training loss: 0.34782583408210466
Validation loss: 2.369325735396943

Epoch: 5| Step: 6
Training loss: 0.18460193746584308
Validation loss: 2.379614952729538

Epoch: 5| Step: 7
Training loss: 0.24237337977815596
Validation loss: 2.36764568826357

Epoch: 5| Step: 8
Training loss: 0.5867208203966207
Validation loss: 2.331376353966252

Epoch: 5| Step: 9
Training loss: 0.43445069456252383
Validation loss: 2.3611200050373085

Epoch: 5| Step: 10
Training loss: 0.33470802657353416
Validation loss: 2.3500828177041453

Epoch: 385| Step: 0
Training loss: 0.2878963557880255
Validation loss: 2.3451542476618212

Epoch: 5| Step: 1
Training loss: 0.271650318502706
Validation loss: 2.3168282737176034

Epoch: 5| Step: 2
Training loss: 0.24416050639263595
Validation loss: 2.331508430079531

Epoch: 5| Step: 3
Training loss: 0.41923038413915803
Validation loss: 2.343802665747677

Epoch: 5| Step: 4
Training loss: 0.2515791697932076
Validation loss: 2.346050055406819

Epoch: 5| Step: 5
Training loss: 0.31812467290265667
Validation loss: 2.357446884649405

Epoch: 5| Step: 6
Training loss: 0.5512488254006949
Validation loss: 2.3479257073773243

Epoch: 5| Step: 7
Training loss: 0.3963839587002505
Validation loss: 2.3468748398158077

Epoch: 5| Step: 8
Training loss: 0.24187847387544692
Validation loss: 2.34456114702645

Epoch: 5| Step: 9
Training loss: 0.5252066931975723
Validation loss: 2.3749875325780807

Epoch: 5| Step: 10
Training loss: 0.3838978969797084
Validation loss: 2.3801401614613815

Epoch: 386| Step: 0
Training loss: 0.34769750200333716
Validation loss: 2.3785802843933945

Epoch: 5| Step: 1
Training loss: 0.42763051204702746
Validation loss: 2.3543120413834733

Epoch: 5| Step: 2
Training loss: 0.2688766214471694
Validation loss: 2.3488336789286293

Epoch: 5| Step: 3
Training loss: 0.32682524701791
Validation loss: 2.30408000945161

Epoch: 5| Step: 4
Training loss: 0.40204850261747643
Validation loss: 2.3192165484180656

Epoch: 5| Step: 5
Training loss: 0.4256534734660182
Validation loss: 2.3115322900774977

Epoch: 5| Step: 6
Training loss: 0.2775135058046163
Validation loss: 2.309784395296776

Epoch: 5| Step: 7
Training loss: 0.3999838646972243
Validation loss: 2.3261261413023395

Epoch: 5| Step: 8
Training loss: 0.3603704597459711
Validation loss: 2.3156102069892985

Epoch: 5| Step: 9
Training loss: 0.3411634952642044
Validation loss: 2.3521953392567103

Epoch: 5| Step: 10
Training loss: 0.35943391565782007
Validation loss: 2.3762251916375026

Epoch: 387| Step: 0
Training loss: 0.308297352957552
Validation loss: 2.3639401599277283

Epoch: 5| Step: 1
Training loss: 0.38224029594313724
Validation loss: 2.3715163622251447

Epoch: 5| Step: 2
Training loss: 0.11401180126934664
Validation loss: 2.3481722724904017

Epoch: 5| Step: 3
Training loss: 0.2974427716725264
Validation loss: 2.323385655840063

Epoch: 5| Step: 4
Training loss: 0.3682651937397163
Validation loss: 2.295964595023836

Epoch: 5| Step: 5
Training loss: 0.3670437308146712
Validation loss: 2.3200384509687706

Epoch: 5| Step: 6
Training loss: 0.25349338416301676
Validation loss: 2.297219817615739

Epoch: 5| Step: 7
Training loss: 0.45295944149036294
Validation loss: 2.303334587421767

Epoch: 5| Step: 8
Training loss: 0.21185175247709992
Validation loss: 2.2866429038983442

Epoch: 5| Step: 9
Training loss: 0.45465959286337554
Validation loss: 2.3120396351780497

Epoch: 5| Step: 10
Training loss: 0.5306368262385053
Validation loss: 2.3149030638614057

Epoch: 388| Step: 0
Training loss: 0.5360944001102981
Validation loss: 2.334739996815852

Epoch: 5| Step: 1
Training loss: 0.23740894868639223
Validation loss: 2.38188830897223

Epoch: 5| Step: 2
Training loss: 0.285265731697002
Validation loss: 2.405203116502623

Epoch: 5| Step: 3
Training loss: 0.5020787122785509
Validation loss: 2.413620011378856

Epoch: 5| Step: 4
Training loss: 0.35061031246191726
Validation loss: 2.3976532877667984

Epoch: 5| Step: 5
Training loss: 0.4363245671058063
Validation loss: 2.432763667675616

Epoch: 5| Step: 6
Training loss: 0.2661942385098036
Validation loss: 2.408377600801404

Epoch: 5| Step: 7
Training loss: 0.17547431215147907
Validation loss: 2.356806924766023

Epoch: 5| Step: 8
Training loss: 0.3198964277680337
Validation loss: 2.3077609334681592

Epoch: 5| Step: 9
Training loss: 0.3814939250137382
Validation loss: 2.3045340938691474

Epoch: 5| Step: 10
Training loss: 0.33092506369114427
Validation loss: 2.313628021646968

Epoch: 389| Step: 0
Training loss: 0.2691114999545137
Validation loss: 2.3009723489466176

Epoch: 5| Step: 1
Training loss: 0.34544613008880987
Validation loss: 2.2929983164908285

Epoch: 5| Step: 2
Training loss: 0.29244340206385694
Validation loss: 2.289891313949825

Epoch: 5| Step: 3
Training loss: 0.35676810920213653
Validation loss: 2.3120319233075066

Epoch: 5| Step: 4
Training loss: 0.5354488157820103
Validation loss: 2.349038028713417

Epoch: 5| Step: 5
Training loss: 0.25927094992245087
Validation loss: 2.3636676745972984

Epoch: 5| Step: 6
Training loss: 0.3588130122680941
Validation loss: 2.3541766431551525

Epoch: 5| Step: 7
Training loss: 0.42688136636390583
Validation loss: 2.3582372455885383

Epoch: 5| Step: 8
Training loss: 0.1648334373394079
Validation loss: 2.403807562986065

Epoch: 5| Step: 9
Training loss: 0.4736384755218794
Validation loss: 2.3540226166917204

Epoch: 5| Step: 10
Training loss: 0.22640452961501709
Validation loss: 2.3580594794935568

Epoch: 390| Step: 0
Training loss: 0.4214371245505731
Validation loss: 2.3761049333085222

Epoch: 5| Step: 1
Training loss: 0.3093910059015547
Validation loss: 2.365718845012299

Epoch: 5| Step: 2
Training loss: 0.22429830322820718
Validation loss: 2.3030051571831263

Epoch: 5| Step: 3
Training loss: 0.5224808733692822
Validation loss: 2.313079421607919

Epoch: 5| Step: 4
Training loss: 0.23858406024735074
Validation loss: 2.302682567427898

Epoch: 5| Step: 5
Training loss: 0.430145903468798
Validation loss: 2.3177713180746036

Epoch: 5| Step: 6
Training loss: 0.26900052602975316
Validation loss: 2.3303823083157864

Epoch: 5| Step: 7
Training loss: 0.2002536316570906
Validation loss: 2.3062930074455004

Epoch: 5| Step: 8
Training loss: 0.2010388258418712
Validation loss: 2.3579688404466124

Epoch: 5| Step: 9
Training loss: 0.3358105486144496
Validation loss: 2.3630778710017153

Epoch: 5| Step: 10
Training loss: 0.5119713894889468
Validation loss: 2.373891821253144

Epoch: 391| Step: 0
Training loss: 0.25267384082750605
Validation loss: 2.3615188871030757

Epoch: 5| Step: 1
Training loss: 0.4615570043237958
Validation loss: 2.381994472352083

Epoch: 5| Step: 2
Training loss: 0.37982338094763574
Validation loss: 2.3539677988862464

Epoch: 5| Step: 3
Training loss: 0.3021870002229615
Validation loss: 2.3637544965434176

Epoch: 5| Step: 4
Training loss: 0.43622490149387616
Validation loss: 2.3602785981020564

Epoch: 5| Step: 5
Training loss: 0.1189042623431465
Validation loss: 2.3676815236965503

Epoch: 5| Step: 6
Training loss: 0.2943438872521195
Validation loss: 2.389943186961308

Epoch: 5| Step: 7
Training loss: 0.36601439224410115
Validation loss: 2.379707306491334

Epoch: 5| Step: 8
Training loss: 0.34793622819460107
Validation loss: 2.3722502145264155

Epoch: 5| Step: 9
Training loss: 0.2592423553709967
Validation loss: 2.322408114924795

Epoch: 5| Step: 10
Training loss: 0.4259334432194633
Validation loss: 2.336390588920754

Epoch: 392| Step: 0
Training loss: 0.4373614057634323
Validation loss: 2.3360400801385945

Epoch: 5| Step: 1
Training loss: 0.3637927566384995
Validation loss: 2.332819319140876

Epoch: 5| Step: 2
Training loss: 0.3225893533184036
Validation loss: 2.3315870706057074

Epoch: 5| Step: 3
Training loss: 0.32327544626121524
Validation loss: 2.3273798599457005

Epoch: 5| Step: 4
Training loss: 0.22101940010220492
Validation loss: 2.3281971777875152

Epoch: 5| Step: 5
Training loss: 0.2663192931523916
Validation loss: 2.3412653336474163

Epoch: 5| Step: 6
Training loss: 0.13851378388534052
Validation loss: 2.3624430235093787

Epoch: 5| Step: 7
Training loss: 0.3409927391072081
Validation loss: 2.3601467970300027

Epoch: 5| Step: 8
Training loss: 0.5260958564972179
Validation loss: 2.3725988893855985

Epoch: 5| Step: 9
Training loss: 0.2574472875019535
Validation loss: 2.366430498836079

Epoch: 5| Step: 10
Training loss: 0.3792722644934316
Validation loss: 2.3718821467410915

Epoch: 393| Step: 0
Training loss: 0.3684579905344034
Validation loss: 2.3904044800058015

Epoch: 5| Step: 1
Training loss: 0.5271607823320363
Validation loss: 2.369766730324167

Epoch: 5| Step: 2
Training loss: 0.12143275277267478
Validation loss: 2.3856501038984343

Epoch: 5| Step: 3
Training loss: 0.31770935866185235
Validation loss: 2.3633260347249667

Epoch: 5| Step: 4
Training loss: 0.26631032665487625
Validation loss: 2.3712341653007556

Epoch: 5| Step: 5
Training loss: 0.3570159524858251
Validation loss: 2.4020020499445116

Epoch: 5| Step: 6
Training loss: 0.32195919380124016
Validation loss: 2.3509121947760856

Epoch: 5| Step: 7
Training loss: 0.29341399373894883
Validation loss: 2.3476085165565372

Epoch: 5| Step: 8
Training loss: 0.41978965274463387
Validation loss: 2.3433720809712697

Epoch: 5| Step: 9
Training loss: 0.30835771587767286
Validation loss: 2.3484846108135473

Epoch: 5| Step: 10
Training loss: 0.22333403372536148
Validation loss: 2.3649019644004765

Epoch: 394| Step: 0
Training loss: 0.35333945168215175
Validation loss: 2.3447597141687004

Epoch: 5| Step: 1
Training loss: 0.48384680713302963
Validation loss: 2.3466717497126397

Epoch: 5| Step: 2
Training loss: 0.44431611740007
Validation loss: 2.357249838657263

Epoch: 5| Step: 3
Training loss: 0.2615700911601898
Validation loss: 2.365539856761268

Epoch: 5| Step: 4
Training loss: 0.25719185017815277
Validation loss: 2.3911281171289693

Epoch: 5| Step: 5
Training loss: 0.4409101280622073
Validation loss: 2.3503312131456116

Epoch: 5| Step: 6
Training loss: 0.2935204207368961
Validation loss: 2.401731980212579

Epoch: 5| Step: 7
Training loss: 0.38361993610946565
Validation loss: 2.3806162298171794

Epoch: 5| Step: 8
Training loss: 0.17690993449288128
Validation loss: 2.3957186171651186

Epoch: 5| Step: 9
Training loss: 0.2221536317328407
Validation loss: 2.3646534229071454

Epoch: 5| Step: 10
Training loss: 0.17529581646744585
Validation loss: 2.326015265561894

Epoch: 395| Step: 0
Training loss: 0.27267805629852515
Validation loss: 2.329628844033185

Epoch: 5| Step: 1
Training loss: 0.30872435160139505
Validation loss: 2.3290273609717214

Epoch: 5| Step: 2
Training loss: 0.36690457583890956
Validation loss: 2.30441297784029

Epoch: 5| Step: 3
Training loss: 0.4779278005696015
Validation loss: 2.308254456804122

Epoch: 5| Step: 4
Training loss: 0.3543114319558296
Validation loss: 2.313196591725242

Epoch: 5| Step: 5
Training loss: 0.4027582274365572
Validation loss: 2.3762467775919984

Epoch: 5| Step: 6
Training loss: 0.3848717635100103
Validation loss: 2.36171612509105

Epoch: 5| Step: 7
Training loss: 0.20960317782391322
Validation loss: 2.4093940446929643

Epoch: 5| Step: 8
Training loss: 0.3471665737805461
Validation loss: 2.385904755403144

Epoch: 5| Step: 9
Training loss: 0.4175586471082954
Validation loss: 2.426816397936711

Epoch: 5| Step: 10
Training loss: 0.26607069322168075
Validation loss: 2.3752117483564743

Epoch: 396| Step: 0
Training loss: 0.5468125988917338
Validation loss: 2.38715008069455

Epoch: 5| Step: 1
Training loss: 0.3162190154129454
Validation loss: 2.3398131637440844

Epoch: 5| Step: 2
Training loss: 0.2568794184673686
Validation loss: 2.312940319481821

Epoch: 5| Step: 3
Training loss: 0.5312402668229617
Validation loss: 2.3212021199899664

Epoch: 5| Step: 4
Training loss: 0.18341023830679848
Validation loss: 2.2872447095038937

Epoch: 5| Step: 5
Training loss: 0.37771182224677324
Validation loss: 2.30552836144844

Epoch: 5| Step: 6
Training loss: 0.11152316459181442
Validation loss: 2.3173070395423423

Epoch: 5| Step: 7
Training loss: 0.4245605117771514
Validation loss: 2.3718094900423203

Epoch: 5| Step: 8
Training loss: 0.27829782495501976
Validation loss: 2.381312070074251

Epoch: 5| Step: 9
Training loss: 0.32306729797605516
Validation loss: 2.427908687923476

Epoch: 5| Step: 10
Training loss: 0.3718801698405475
Validation loss: 2.4178043422036946

Epoch: 397| Step: 0
Training loss: 0.34370404716597247
Validation loss: 2.375959161661719

Epoch: 5| Step: 1
Training loss: 0.39808916310899567
Validation loss: 2.386612425104871

Epoch: 5| Step: 2
Training loss: 0.27602674185993864
Validation loss: 2.4155105000571866

Epoch: 5| Step: 3
Training loss: 0.48085772268474686
Validation loss: 2.3724410320427727

Epoch: 5| Step: 4
Training loss: 0.2697783318959076
Validation loss: 2.382639950281405

Epoch: 5| Step: 5
Training loss: 0.34475031438596027
Validation loss: 2.394125158174557

Epoch: 5| Step: 6
Training loss: 0.2647686646512969
Validation loss: 2.3224284625030345

Epoch: 5| Step: 7
Training loss: 0.22667274588053868
Validation loss: 2.36534875021952

Epoch: 5| Step: 8
Training loss: 0.416658218616037
Validation loss: 2.3492116578451743

Epoch: 5| Step: 9
Training loss: 0.34365392556115065
Validation loss: 2.3850732088495326

Epoch: 5| Step: 10
Training loss: 0.2889272785940924
Validation loss: 2.4144212776285836

Epoch: 398| Step: 0
Training loss: 0.19280262951185545
Validation loss: 2.4021597080013626

Epoch: 5| Step: 1
Training loss: 0.45004117565389007
Validation loss: 2.3968628207467897

Epoch: 5| Step: 2
Training loss: 0.4127144552287406
Validation loss: 2.374497523474583

Epoch: 5| Step: 3
Training loss: 0.3604847524899817
Validation loss: 2.3504022067310624

Epoch: 5| Step: 4
Training loss: 0.47254463328114316
Validation loss: 2.3498829793714298

Epoch: 5| Step: 5
Training loss: 0.48592243355212
Validation loss: 2.3737614056787435

Epoch: 5| Step: 6
Training loss: 0.3134837283447362
Validation loss: 2.3532305270128

Epoch: 5| Step: 7
Training loss: 0.16019710740686346
Validation loss: 2.32715907144415

Epoch: 5| Step: 8
Training loss: 0.2634509962839911
Validation loss: 2.304355928552527

Epoch: 5| Step: 9
Training loss: 0.19461694844324526
Validation loss: 2.34918981474332

Epoch: 5| Step: 10
Training loss: 0.17239602726140787
Validation loss: 2.3433378287874556

Epoch: 399| Step: 0
Training loss: 0.33187767291743747
Validation loss: 2.355499143851115

Epoch: 5| Step: 1
Training loss: 0.31874190208021913
Validation loss: 2.363261587192845

Epoch: 5| Step: 2
Training loss: 0.474336742069643
Validation loss: 2.374496271613054

Epoch: 5| Step: 3
Training loss: 0.29665870064896865
Validation loss: 2.39096724679424

Epoch: 5| Step: 4
Training loss: 0.1308212865370047
Validation loss: 2.3831164922786368

Epoch: 5| Step: 5
Training loss: 0.34896409566116615
Validation loss: 2.4329554786849577

Epoch: 5| Step: 6
Training loss: 0.41219300058901215
Validation loss: 2.3760835726418574

Epoch: 5| Step: 7
Training loss: 0.3894484922387952
Validation loss: 2.4033394171616003

Epoch: 5| Step: 8
Training loss: 0.1791568778842295
Validation loss: 2.395920739489958

Epoch: 5| Step: 9
Training loss: 0.3197680824459366
Validation loss: 2.3930650741147907

Epoch: 5| Step: 10
Training loss: 0.30377537574264496
Validation loss: 2.396510453238618

Epoch: 400| Step: 0
Training loss: 0.12072832977066841
Validation loss: 2.384450729712107

Epoch: 5| Step: 1
Training loss: 0.34913742987552937
Validation loss: 2.3985538126450616

Epoch: 5| Step: 2
Training loss: 0.3053449482303292
Validation loss: 2.416482873518178

Epoch: 5| Step: 3
Training loss: 0.3200674049718203
Validation loss: 2.3782991056528022

Epoch: 5| Step: 4
Training loss: 0.28947415552175065
Validation loss: 2.385315056027702

Epoch: 5| Step: 5
Training loss: 0.5682025181727616
Validation loss: 2.3928181476084394

Epoch: 5| Step: 6
Training loss: 0.3401222622406171
Validation loss: 2.393130729232928

Epoch: 5| Step: 7
Training loss: 0.3525726534830751
Validation loss: 2.429529391263337

Epoch: 5| Step: 8
Training loss: 0.39274847785028266
Validation loss: 2.4233053989523756

Epoch: 5| Step: 9
Training loss: 0.26866793932171573
Validation loss: 2.42586418603093

Epoch: 5| Step: 10
Training loss: 0.20155183778699526
Validation loss: 2.4087148219110963

Epoch: 401| Step: 0
Training loss: 0.4013522811312046
Validation loss: 2.3599589048460685

Epoch: 5| Step: 1
Training loss: 0.23435503556734227
Validation loss: 2.3227231539994646

Epoch: 5| Step: 2
Training loss: 0.22080409010812507
Validation loss: 2.3228125162355675

Epoch: 5| Step: 3
Training loss: 0.29461220405331007
Validation loss: 2.2785194294876967

Epoch: 5| Step: 4
Training loss: 0.5117646990231842
Validation loss: 2.3201128858359095

Epoch: 5| Step: 5
Training loss: 0.26468285199602726
Validation loss: 2.3278658537451467

Epoch: 5| Step: 6
Training loss: 0.3646741027463243
Validation loss: 2.3105568031288644

Epoch: 5| Step: 7
Training loss: 0.3809769082280506
Validation loss: 2.3592786578440426

Epoch: 5| Step: 8
Training loss: 0.2353131433050068
Validation loss: 2.389180598994488

Epoch: 5| Step: 9
Training loss: 0.34775718552442036
Validation loss: 2.3784912896240957

Epoch: 5| Step: 10
Training loss: 0.35262282794985256
Validation loss: 2.403862578393501

Epoch: 402| Step: 0
Training loss: 0.39151148342717834
Validation loss: 2.413207413534358

Epoch: 5| Step: 1
Training loss: 0.36725652330031044
Validation loss: 2.3551403394844463

Epoch: 5| Step: 2
Training loss: 0.3003629029259338
Validation loss: 2.3406059577721843

Epoch: 5| Step: 3
Training loss: 0.23229703836402582
Validation loss: 2.365488595094469

Epoch: 5| Step: 4
Training loss: 0.3450032061621364
Validation loss: 2.363610558722496

Epoch: 5| Step: 5
Training loss: 0.4084411547671701
Validation loss: 2.3319936541689765

Epoch: 5| Step: 6
Training loss: 0.2838249351895528
Validation loss: 2.3251479663796952

Epoch: 5| Step: 7
Training loss: 0.4047070693656742
Validation loss: 2.3515707908503023

Epoch: 5| Step: 8
Training loss: 0.34877940710227023
Validation loss: 2.3327219274837248

Epoch: 5| Step: 9
Training loss: 0.1898722682144859
Validation loss: 2.3978755423928626

Epoch: 5| Step: 10
Training loss: 0.42694073909513097
Validation loss: 2.384093125965092

Epoch: 403| Step: 0
Training loss: 0.19483464913424273
Validation loss: 2.371891170711772

Epoch: 5| Step: 1
Training loss: 0.3116351916723396
Validation loss: 2.3771944885315532

Epoch: 5| Step: 2
Training loss: 0.341191109232375
Validation loss: 2.421010478433503

Epoch: 5| Step: 3
Training loss: 0.2840886707651219
Validation loss: 2.3903076724796666

Epoch: 5| Step: 4
Training loss: 0.48717657633653794
Validation loss: 2.379248334583742

Epoch: 5| Step: 5
Training loss: 0.338552224165794
Validation loss: 2.393722631310379

Epoch: 5| Step: 6
Training loss: 0.44535561403068286
Validation loss: 2.347679481093154

Epoch: 5| Step: 7
Training loss: 0.14677927215182468
Validation loss: 2.318736120410823

Epoch: 5| Step: 8
Training loss: 0.3683999922073107
Validation loss: 2.3382557185448505

Epoch: 5| Step: 9
Training loss: 0.26696600126315806
Validation loss: 2.3074765478647175

Epoch: 5| Step: 10
Training loss: 0.2204073214908518
Validation loss: 2.3260360196903536

Epoch: 404| Step: 0
Training loss: 0.4050088409353669
Validation loss: 2.320358675317764

Epoch: 5| Step: 1
Training loss: 0.3565690962225608
Validation loss: 2.363139494811865

Epoch: 5| Step: 2
Training loss: 0.395841744818743
Validation loss: 2.3464324236304264

Epoch: 5| Step: 3
Training loss: 0.2606686834963007
Validation loss: 2.384914024075883

Epoch: 5| Step: 4
Training loss: 0.3843676450072204
Validation loss: 2.3441162003769507

Epoch: 5| Step: 5
Training loss: 0.26536814107310003
Validation loss: 2.3458336737483565

Epoch: 5| Step: 6
Training loss: 0.19404052441021663
Validation loss: 2.384518966851794

Epoch: 5| Step: 7
Training loss: 0.22746395950891016
Validation loss: 2.392328467604453

Epoch: 5| Step: 8
Training loss: 0.4159485848008045
Validation loss: 2.3578157673663904

Epoch: 5| Step: 9
Training loss: 0.2937338692720456
Validation loss: 2.4084963722649504

Epoch: 5| Step: 10
Training loss: 0.176482027628411
Validation loss: 2.3770897948241685

Epoch: 405| Step: 0
Training loss: 0.488491242076453
Validation loss: 2.3736117512169397

Epoch: 5| Step: 1
Training loss: 0.31941637431853787
Validation loss: 2.313623920156091

Epoch: 5| Step: 2
Training loss: 0.3278370683843851
Validation loss: 2.3220232468609607

Epoch: 5| Step: 3
Training loss: 0.2539978742341575
Validation loss: 2.2994810333446916

Epoch: 5| Step: 4
Training loss: 0.24333078727767335
Validation loss: 2.3639302716384223

Epoch: 5| Step: 5
Training loss: 0.31885304234674217
Validation loss: 2.3313820879558036

Epoch: 5| Step: 6
Training loss: 0.15855342441571693
Validation loss: 2.329738615210655

Epoch: 5| Step: 7
Training loss: 0.2752563744533593
Validation loss: 2.3539471973638655

Epoch: 5| Step: 8
Training loss: 0.3346835286130105
Validation loss: 2.3697521593617874

Epoch: 5| Step: 9
Training loss: 0.46566197165336676
Validation loss: 2.367914686013702

Epoch: 5| Step: 10
Training loss: 0.19177522906194122
Validation loss: 2.367180670654556

Epoch: 406| Step: 0
Training loss: 0.22078468706137788
Validation loss: 2.3882289565015027

Epoch: 5| Step: 1
Training loss: 0.4367312250419861
Validation loss: 2.3395693392086656

Epoch: 5| Step: 2
Training loss: 0.17680181303389264
Validation loss: 2.3262955907427623

Epoch: 5| Step: 3
Training loss: 0.1741962018410955
Validation loss: 2.319368956904531

Epoch: 5| Step: 4
Training loss: 0.2860736069601422
Validation loss: 2.3415632814174066

Epoch: 5| Step: 5
Training loss: 0.24638158374807415
Validation loss: 2.3768241959863112

Epoch: 5| Step: 6
Training loss: 0.2870287749630743
Validation loss: 2.34948250427503

Epoch: 5| Step: 7
Training loss: 0.30445469006925835
Validation loss: 2.338875847798143

Epoch: 5| Step: 8
Training loss: 0.355999518895092
Validation loss: 2.3265239773900537

Epoch: 5| Step: 9
Training loss: 0.4380464206922477
Validation loss: 2.339488658125927

Epoch: 5| Step: 10
Training loss: 0.3802351702620477
Validation loss: 2.3602280384332284

Epoch: 407| Step: 0
Training loss: 0.29767477073019855
Validation loss: 2.3426459082036972

Epoch: 5| Step: 1
Training loss: 0.27898177131542423
Validation loss: 2.4031581295668873

Epoch: 5| Step: 2
Training loss: 0.379291770892859
Validation loss: 2.3726505041857324

Epoch: 5| Step: 3
Training loss: 0.40782624510186416
Validation loss: 2.364882935142837

Epoch: 5| Step: 4
Training loss: 0.2912817512649497
Validation loss: 2.3656591761808423

Epoch: 5| Step: 5
Training loss: 0.2147016749082156
Validation loss: 2.3615645639345346

Epoch: 5| Step: 6
Training loss: 0.4339819536390492
Validation loss: 2.3646865185435972

Epoch: 5| Step: 7
Training loss: 0.23504253533872357
Validation loss: 2.3546524261789616

Epoch: 5| Step: 8
Training loss: 0.305106693839958
Validation loss: 2.3139610552843486

Epoch: 5| Step: 9
Training loss: 0.3921262883294988
Validation loss: 2.3543665087186474

Epoch: 5| Step: 10
Training loss: 0.13694282969606508
Validation loss: 2.3494418781825996

Epoch: 408| Step: 0
Training loss: 0.36302054700288283
Validation loss: 2.3065722940432303

Epoch: 5| Step: 1
Training loss: 0.3085071949351638
Validation loss: 2.3087143324554034

Epoch: 5| Step: 2
Training loss: 0.3961287157625352
Validation loss: 2.3142278181271583

Epoch: 5| Step: 3
Training loss: 0.31517253349499796
Validation loss: 2.3241388464539487

Epoch: 5| Step: 4
Training loss: 0.3465870370769391
Validation loss: 2.3284625782982458

Epoch: 5| Step: 5
Training loss: 0.3118537658235895
Validation loss: 2.3359714859109495

Epoch: 5| Step: 6
Training loss: 0.367240394678312
Validation loss: 2.3203954879655146

Epoch: 5| Step: 7
Training loss: 0.16399509316756503
Validation loss: 2.3579854814405192

Epoch: 5| Step: 8
Training loss: 0.19527702963131638
Validation loss: 2.3313857617923057

Epoch: 5| Step: 9
Training loss: 0.24485288862203572
Validation loss: 2.3537319376176447

Epoch: 5| Step: 10
Training loss: 0.4095056732935204
Validation loss: 2.3714182063517897

Epoch: 409| Step: 0
Training loss: 0.22529431273642794
Validation loss: 2.360866193557188

Epoch: 5| Step: 1
Training loss: 0.3749408079161343
Validation loss: 2.370478480213453

Epoch: 5| Step: 2
Training loss: 0.3653419254679317
Validation loss: 2.324345380022608

Epoch: 5| Step: 3
Training loss: 0.3094171692786504
Validation loss: 2.3259542767470385

Epoch: 5| Step: 4
Training loss: 0.28938956701883306
Validation loss: 2.358031550700892

Epoch: 5| Step: 5
Training loss: 0.2828474376237037
Validation loss: 2.3232417891453414

Epoch: 5| Step: 6
Training loss: 0.27679878744551606
Validation loss: 2.3100850966416586

Epoch: 5| Step: 7
Training loss: 0.4290905707526783
Validation loss: 2.3043027639754894

Epoch: 5| Step: 8
Training loss: 0.1672773102157941
Validation loss: 2.34261055105046

Epoch: 5| Step: 9
Training loss: 0.2548201326785436
Validation loss: 2.3782333065305084

Epoch: 5| Step: 10
Training loss: 0.39359302192066387
Validation loss: 2.32103613360658

Epoch: 410| Step: 0
Training loss: 0.29103417305434354
Validation loss: 2.3081683025434

Epoch: 5| Step: 1
Training loss: 0.44525904083604595
Validation loss: 2.3348440662894188

Epoch: 5| Step: 2
Training loss: 0.3499528061179379
Validation loss: 2.3439201517450123

Epoch: 5| Step: 3
Training loss: 0.24097413242232193
Validation loss: 2.343678981566417

Epoch: 5| Step: 4
Training loss: 0.22459645441459136
Validation loss: 2.3508128492551514

Epoch: 5| Step: 5
Training loss: 0.3068325025534965
Validation loss: 2.3592227842411817

Epoch: 5| Step: 6
Training loss: 0.23649528203536702
Validation loss: 2.3515037006253126

Epoch: 5| Step: 7
Training loss: 0.12618539932565678
Validation loss: 2.368686208770528

Epoch: 5| Step: 8
Training loss: 0.1704726937866659
Validation loss: 2.3355054157694206

Epoch: 5| Step: 9
Training loss: 0.33230382165631217
Validation loss: 2.360379344368998

Epoch: 5| Step: 10
Training loss: 0.4736739150627356
Validation loss: 2.325246430497383

Epoch: 411| Step: 0
Training loss: 0.3088663442418542
Validation loss: 2.3576745626965954

Epoch: 5| Step: 1
Training loss: 0.3350103803350171
Validation loss: 2.32853382025861

Epoch: 5| Step: 2
Training loss: 0.4401853776149668
Validation loss: 2.3580054252549782

Epoch: 5| Step: 3
Training loss: 0.3087865734060342
Validation loss: 2.330123328942444

Epoch: 5| Step: 4
Training loss: 0.25584774136484706
Validation loss: 2.34543092780947

Epoch: 5| Step: 5
Training loss: 0.3988843357030127
Validation loss: 2.329190936473836

Epoch: 5| Step: 6
Training loss: 0.23842801592652219
Validation loss: 2.31630713616648

Epoch: 5| Step: 7
Training loss: 0.2796790569245778
Validation loss: 2.3181973088897587

Epoch: 5| Step: 8
Training loss: 0.127426205017128
Validation loss: 2.351872490324439

Epoch: 5| Step: 9
Training loss: 0.2833932435751353
Validation loss: 2.342241742891009

Epoch: 5| Step: 10
Training loss: 0.31132989210443346
Validation loss: 2.3266298170433384

Epoch: 412| Step: 0
Training loss: 0.23125333107018337
Validation loss: 2.352398245101603

Epoch: 5| Step: 1
Training loss: 0.4019351476980999
Validation loss: 2.36359645958764

Epoch: 5| Step: 2
Training loss: 0.1322100523384974
Validation loss: 2.373165563115786

Epoch: 5| Step: 3
Training loss: 0.3769680474840898
Validation loss: 2.3871532208742767

Epoch: 5| Step: 4
Training loss: 0.15488415629704708
Validation loss: 2.344180021043427

Epoch: 5| Step: 5
Training loss: 0.47522279947592083
Validation loss: 2.3561776394968366

Epoch: 5| Step: 6
Training loss: 0.2887709539208765
Validation loss: 2.367520332526758

Epoch: 5| Step: 7
Training loss: 0.19521480024069168
Validation loss: 2.369702123667401

Epoch: 5| Step: 8
Training loss: 0.2599874567481632
Validation loss: 2.362553090865552

Epoch: 5| Step: 9
Training loss: 0.25467432198629414
Validation loss: 2.354717079944312

Epoch: 5| Step: 10
Training loss: 0.3285523878249944
Validation loss: 2.3612134817379657

Epoch: 413| Step: 0
Training loss: 0.357955679919219
Validation loss: 2.3784607778434093

Epoch: 5| Step: 1
Training loss: 0.19359058466825935
Validation loss: 2.4035755034703565

Epoch: 5| Step: 2
Training loss: 0.3799002283021824
Validation loss: 2.356929161905328

Epoch: 5| Step: 3
Training loss: 0.27035102018520474
Validation loss: 2.3787874333942436

Epoch: 5| Step: 4
Training loss: 0.1650824517993251
Validation loss: 2.398473356363119

Epoch: 5| Step: 5
Training loss: 0.26761109086390483
Validation loss: 2.4100627659328544

Epoch: 5| Step: 6
Training loss: 0.34365186590978297
Validation loss: 2.3904817492547608

Epoch: 5| Step: 7
Training loss: 0.4225991004199497
Validation loss: 2.415473885674112

Epoch: 5| Step: 8
Training loss: 0.263992058652588
Validation loss: 2.3900231044629234

Epoch: 5| Step: 9
Training loss: 0.2696308560078114
Validation loss: 2.3955931843212586

Epoch: 5| Step: 10
Training loss: 0.32892304964269425
Validation loss: 2.3622323862930243

Epoch: 414| Step: 0
Training loss: 0.39192796835899757
Validation loss: 2.3488039110073995

Epoch: 5| Step: 1
Training loss: 0.3019820309284158
Validation loss: 2.361323254103214

Epoch: 5| Step: 2
Training loss: 0.32304349710711894
Validation loss: 2.3437107610665113

Epoch: 5| Step: 3
Training loss: 0.26285132841388076
Validation loss: 2.3787190000435583

Epoch: 5| Step: 4
Training loss: 0.16419373667488482
Validation loss: 2.369502325197801

Epoch: 5| Step: 5
Training loss: 0.2543474325852485
Validation loss: 2.3961008376435675

Epoch: 5| Step: 6
Training loss: 0.27911608520054393
Validation loss: 2.3771103187238567

Epoch: 5| Step: 7
Training loss: 0.113188039315496
Validation loss: 2.409385073933498

Epoch: 5| Step: 8
Training loss: 0.245113380372167
Validation loss: 2.397391899399212

Epoch: 5| Step: 9
Training loss: 0.34635228560469894
Validation loss: 2.3743693977732567

Epoch: 5| Step: 10
Training loss: 0.47085693822052643
Validation loss: 2.3947317971576556

Epoch: 415| Step: 0
Training loss: 0.1404082031156608
Validation loss: 2.4018537316235586

Epoch: 5| Step: 1
Training loss: 0.20479644322249763
Validation loss: 2.3708530591800865

Epoch: 5| Step: 2
Training loss: 0.30596925654431234
Validation loss: 2.382725463869934

Epoch: 5| Step: 3
Training loss: 0.1713499643850192
Validation loss: 2.3748570147111687

Epoch: 5| Step: 4
Training loss: 0.17390009108276955
Validation loss: 2.372423677672891

Epoch: 5| Step: 5
Training loss: 0.3383321578415681
Validation loss: 2.3984014699397527

Epoch: 5| Step: 6
Training loss: 0.24846945832988387
Validation loss: 2.3943311025519436

Epoch: 5| Step: 7
Training loss: 0.4781027277577229
Validation loss: 2.387407111785698

Epoch: 5| Step: 8
Training loss: 0.38871772534011273
Validation loss: 2.4065421110507956

Epoch: 5| Step: 9
Training loss: 0.3335817486750536
Validation loss: 2.380030975300509

Epoch: 5| Step: 10
Training loss: 0.2684949496325253
Validation loss: 2.400563912408083

Epoch: 416| Step: 0
Training loss: 0.12984554214939226
Validation loss: 2.4330891850675664

Epoch: 5| Step: 1
Training loss: 0.21514112526029724
Validation loss: 2.4226193218754895

Epoch: 5| Step: 2
Training loss: 0.20828041159481825
Validation loss: 2.390262903679005

Epoch: 5| Step: 3
Training loss: 0.2275979943969802
Validation loss: 2.402810223745409

Epoch: 5| Step: 4
Training loss: 0.1876068307598115
Validation loss: 2.386999415408686

Epoch: 5| Step: 5
Training loss: 0.43797457023942254
Validation loss: 2.4011323702738823

Epoch: 5| Step: 6
Training loss: 0.34851400236886343
Validation loss: 2.35521835748296

Epoch: 5| Step: 7
Training loss: 0.32011187480919234
Validation loss: 2.3605841656883833

Epoch: 5| Step: 8
Training loss: 0.42459888954165625
Validation loss: 2.3536911648545167

Epoch: 5| Step: 9
Training loss: 0.17988362182700204
Validation loss: 2.332940963710225

Epoch: 5| Step: 10
Training loss: 0.29657648789165153
Validation loss: 2.357035795791188

Epoch: 417| Step: 0
Training loss: 0.20263234329095772
Validation loss: 2.3138471469244943

Epoch: 5| Step: 1
Training loss: 0.18770822248409721
Validation loss: 2.339529771549372

Epoch: 5| Step: 2
Training loss: 0.26643033520064696
Validation loss: 2.32811160378636

Epoch: 5| Step: 3
Training loss: 0.40393068250769637
Validation loss: 2.3573955513994824

Epoch: 5| Step: 4
Training loss: 0.36926788074225875
Validation loss: 2.3502981021602514

Epoch: 5| Step: 5
Training loss: 0.10607161237576666
Validation loss: 2.3528185233145935

Epoch: 5| Step: 6
Training loss: 0.1501015882901548
Validation loss: 2.332381559395549

Epoch: 5| Step: 7
Training loss: 0.35400380101695633
Validation loss: 2.3554805795520153

Epoch: 5| Step: 8
Training loss: 0.4335461495879713
Validation loss: 2.391261363051503

Epoch: 5| Step: 9
Training loss: 0.36515233959606525
Validation loss: 2.370369547138931

Epoch: 5| Step: 10
Training loss: 0.12360524839018674
Validation loss: 2.3770591194574897

Epoch: 418| Step: 0
Training loss: 0.28530405734002084
Validation loss: 2.3704688971416052

Epoch: 5| Step: 1
Training loss: 0.2529518824674116
Validation loss: 2.339733146296577

Epoch: 5| Step: 2
Training loss: 0.24452639047833608
Validation loss: 2.323275372630866

Epoch: 5| Step: 3
Training loss: 0.15744064990553946
Validation loss: 2.311252401571379

Epoch: 5| Step: 4
Training loss: 0.3301643055927372
Validation loss: 2.3026160665600677

Epoch: 5| Step: 5
Training loss: 0.3809353874842687
Validation loss: 2.31106787466373

Epoch: 5| Step: 6
Training loss: 0.43875714608700833
Validation loss: 2.3057748350353884

Epoch: 5| Step: 7
Training loss: 0.2544567010222403
Validation loss: 2.330771400690928

Epoch: 5| Step: 8
Training loss: 0.31516053612460704
Validation loss: 2.3601617238295787

Epoch: 5| Step: 9
Training loss: 0.3671500815947186
Validation loss: 2.419338849025104

Epoch: 5| Step: 10
Training loss: 0.16547343408656578
Validation loss: 2.4252634881507578

Epoch: 419| Step: 0
Training loss: 0.18227732238645147
Validation loss: 2.467625254938828

Epoch: 5| Step: 1
Training loss: 0.21074101339018447
Validation loss: 2.432441053532585

Epoch: 5| Step: 2
Training loss: 0.5444163229901482
Validation loss: 2.428715181359576

Epoch: 5| Step: 3
Training loss: 0.19354872631820697
Validation loss: 2.397106337692462

Epoch: 5| Step: 4
Training loss: 0.285063571762315
Validation loss: 2.3735027872378707

Epoch: 5| Step: 5
Training loss: 0.284813478946573
Validation loss: 2.3313291757109216

Epoch: 5| Step: 6
Training loss: 0.20019053941944795
Validation loss: 2.3343987347191515

Epoch: 5| Step: 7
Training loss: 0.3358222076053711
Validation loss: 2.3078418011857216

Epoch: 5| Step: 8
Training loss: 0.41111936569876434
Validation loss: 2.2772262087838344

Epoch: 5| Step: 9
Training loss: 0.2682651415406214
Validation loss: 2.2730129070842087

Epoch: 5| Step: 10
Training loss: 0.20193635254796322
Validation loss: 2.3306847140088474

Epoch: 420| Step: 0
Training loss: 0.34161694831725486
Validation loss: 2.3090534773058544

Epoch: 5| Step: 1
Training loss: 0.37337232044843355
Validation loss: 2.3105086466454425

Epoch: 5| Step: 2
Training loss: 0.2571974700951255
Validation loss: 2.3492697839951404

Epoch: 5| Step: 3
Training loss: 0.3247793246222892
Validation loss: 2.3431149241000004

Epoch: 5| Step: 4
Training loss: 0.19250556011963718
Validation loss: 2.3775387813290267

Epoch: 5| Step: 5
Training loss: 0.33323433518562645
Validation loss: 2.3885597204887716

Epoch: 5| Step: 6
Training loss: 0.2569578338404993
Validation loss: 2.407393651573624

Epoch: 5| Step: 7
Training loss: 0.2877827099180974
Validation loss: 2.4293563454081766

Epoch: 5| Step: 8
Training loss: 0.19163949534553287
Validation loss: 2.3731233374581158

Epoch: 5| Step: 9
Training loss: 0.2646175239779115
Validation loss: 2.37187524444498

Epoch: 5| Step: 10
Training loss: 0.4166955898100968
Validation loss: 2.341893726698975

Epoch: 421| Step: 0
Training loss: 0.17670264357874746
Validation loss: 2.3125293494803496

Epoch: 5| Step: 1
Training loss: 0.15672785881780033
Validation loss: 2.3297240463029874

Epoch: 5| Step: 2
Training loss: 0.28630284800203853
Validation loss: 2.2762072662425323

Epoch: 5| Step: 3
Training loss: 0.3096978679888453
Validation loss: 2.3174901277242217

Epoch: 5| Step: 4
Training loss: 0.1978397324424848
Validation loss: 2.2950711036884655

Epoch: 5| Step: 5
Training loss: 0.4090573986192903
Validation loss: 2.309869062827642

Epoch: 5| Step: 6
Training loss: 0.3137143026804845
Validation loss: 2.3272427036885546

Epoch: 5| Step: 7
Training loss: 0.20734047738362232
Validation loss: 2.3111270741280716

Epoch: 5| Step: 8
Training loss: 0.44244936680308206
Validation loss: 2.3753237835521275

Epoch: 5| Step: 9
Training loss: 0.20206418331753617
Validation loss: 2.3366606185693444

Epoch: 5| Step: 10
Training loss: 0.33202469763180853
Validation loss: 2.3552536222418485

Epoch: 422| Step: 0
Training loss: 0.2863638143948281
Validation loss: 2.3360884291149784

Epoch: 5| Step: 1
Training loss: 0.3832679685895563
Validation loss: 2.3730473454775947

Epoch: 5| Step: 2
Training loss: 0.36666351835387545
Validation loss: 2.355880613954242

Epoch: 5| Step: 3
Training loss: 0.2575306507728992
Validation loss: 2.3551533223445626

Epoch: 5| Step: 4
Training loss: 0.3033339193403082
Validation loss: 2.3684303727152787

Epoch: 5| Step: 5
Training loss: 0.2278155991718906
Validation loss: 2.3679115479288084

Epoch: 5| Step: 6
Training loss: 0.19405930924979087
Validation loss: 2.3453729043642935

Epoch: 5| Step: 7
Training loss: 0.3688993119359289
Validation loss: 2.373900458529838

Epoch: 5| Step: 8
Training loss: 0.18269318004160498
Validation loss: 2.3664063820167405

Epoch: 5| Step: 9
Training loss: 0.24895154625860066
Validation loss: 2.369818254276827

Epoch: 5| Step: 10
Training loss: 0.2047525546382648
Validation loss: 2.353792334120058

Epoch: 423| Step: 0
Training loss: 0.23525205859277776
Validation loss: 2.3344316706536894

Epoch: 5| Step: 1
Training loss: 0.2567141574163243
Validation loss: 2.376840901002101

Epoch: 5| Step: 2
Training loss: 0.2713102564487171
Validation loss: 2.323008784104632

Epoch: 5| Step: 3
Training loss: 0.15353534586377549
Validation loss: 2.34050021670334

Epoch: 5| Step: 4
Training loss: 0.29258293178465244
Validation loss: 2.315257557106172

Epoch: 5| Step: 5
Training loss: 0.3736389016085481
Validation loss: 2.353239637213892

Epoch: 5| Step: 6
Training loss: 0.20691748858397552
Validation loss: 2.3411558445025613

Epoch: 5| Step: 7
Training loss: 0.30946091846031576
Validation loss: 2.359024521645323

Epoch: 5| Step: 8
Training loss: 0.341925351655889
Validation loss: 2.3791470129243875

Epoch: 5| Step: 9
Training loss: 0.3449828300315354
Validation loss: 2.383485164068586

Epoch: 5| Step: 10
Training loss: 0.25338984574109136
Validation loss: 2.369654165175806

Epoch: 424| Step: 0
Training loss: 0.22077749906513633
Validation loss: 2.41216074856576

Epoch: 5| Step: 1
Training loss: 0.262590039796414
Validation loss: 2.3939012247564517

Epoch: 5| Step: 2
Training loss: 0.39018615867730044
Validation loss: 2.3693567943691276

Epoch: 5| Step: 3
Training loss: 0.2707600983614749
Validation loss: 2.377731856959247

Epoch: 5| Step: 4
Training loss: 0.21678734663910768
Validation loss: 2.368278251849089

Epoch: 5| Step: 5
Training loss: 0.24828441389791536
Validation loss: 2.347967758370395

Epoch: 5| Step: 6
Training loss: 0.38219029601003074
Validation loss: 2.339191545894329

Epoch: 5| Step: 7
Training loss: 0.2307241447166275
Validation loss: 2.3788853285798135

Epoch: 5| Step: 8
Training loss: 0.10617793914285104
Validation loss: 2.3339505979599857

Epoch: 5| Step: 9
Training loss: 0.33499160937576516
Validation loss: 2.353897200362813

Epoch: 5| Step: 10
Training loss: 0.34087387800783914
Validation loss: 2.3651338854008594

Epoch: 425| Step: 0
Training loss: 0.4016997358881087
Validation loss: 2.3571536054092252

Epoch: 5| Step: 1
Training loss: 0.3289874753531906
Validation loss: 2.343748490527908

Epoch: 5| Step: 2
Training loss: 0.19888422498700792
Validation loss: 2.353229198472905

Epoch: 5| Step: 3
Training loss: 0.11917560095268424
Validation loss: 2.3511019450494786

Epoch: 5| Step: 4
Training loss: 0.2428800463895791
Validation loss: 2.3358187503820513

Epoch: 5| Step: 5
Training loss: 0.16459416346790476
Validation loss: 2.353228302974496

Epoch: 5| Step: 6
Training loss: 0.29711037640900606
Validation loss: 2.3583513201551565

Epoch: 5| Step: 7
Training loss: 0.19542479148098196
Validation loss: 2.341515904957106

Epoch: 5| Step: 8
Training loss: 0.24812206120035846
Validation loss: 2.3373472661220127

Epoch: 5| Step: 9
Training loss: 0.41054808655477487
Validation loss: 2.3115523918016563

Epoch: 5| Step: 10
Training loss: 0.2581486677721704
Validation loss: 2.282894808628708

Epoch: 426| Step: 0
Training loss: 0.43431649671717365
Validation loss: 2.297433468410598

Epoch: 5| Step: 1
Training loss: 0.3860790471882609
Validation loss: 2.306116208637861

Epoch: 5| Step: 2
Training loss: 0.24105844040098798
Validation loss: 2.2980929408821242

Epoch: 5| Step: 3
Training loss: 0.1670158492161847
Validation loss: 2.3217208067146076

Epoch: 5| Step: 4
Training loss: 0.20315029830382592
Validation loss: 2.354808483756481

Epoch: 5| Step: 5
Training loss: 0.30353020690688465
Validation loss: 2.37936800467635

Epoch: 5| Step: 6
Training loss: 0.20076976327656154
Validation loss: 2.3611391769983454

Epoch: 5| Step: 7
Training loss: 0.20113120547549249
Validation loss: 2.3669369597239194

Epoch: 5| Step: 8
Training loss: 0.20200287374019732
Validation loss: 2.388207047318451

Epoch: 5| Step: 9
Training loss: 0.1498997716030661
Validation loss: 2.393314781604941

Epoch: 5| Step: 10
Training loss: 0.4205803963987146
Validation loss: 2.392919880322919

Epoch: 427| Step: 0
Training loss: 0.3999900861346018
Validation loss: 2.413160999564359

Epoch: 5| Step: 1
Training loss: 0.24849206667072102
Validation loss: 2.3713201199304623

Epoch: 5| Step: 2
Training loss: 0.19055898140723837
Validation loss: 2.3887983551654344

Epoch: 5| Step: 3
Training loss: 0.3353997628570826
Validation loss: 2.3752869091080617

Epoch: 5| Step: 4
Training loss: 0.26824581069910247
Validation loss: 2.373804616934968

Epoch: 5| Step: 5
Training loss: 0.12816256519060365
Validation loss: 2.391187165427326

Epoch: 5| Step: 6
Training loss: 0.2596066067066162
Validation loss: 2.3899087987870558

Epoch: 5| Step: 7
Training loss: 0.24203578750169227
Validation loss: 2.3773401838924926

Epoch: 5| Step: 8
Training loss: 0.31759770087874095
Validation loss: 2.3828350322269287

Epoch: 5| Step: 9
Training loss: 0.24307515154287213
Validation loss: 2.406574925705222

Epoch: 5| Step: 10
Training loss: 0.2997394204933305
Validation loss: 2.3721306225096237

Epoch: 428| Step: 0
Training loss: 0.31615989419168467
Validation loss: 2.3533841663127837

Epoch: 5| Step: 1
Training loss: 0.39636097006988696
Validation loss: 2.3450862856997277

Epoch: 5| Step: 2
Training loss: 0.2637404458634153
Validation loss: 2.3400872665826307

Epoch: 5| Step: 3
Training loss: 0.213069481917952
Validation loss: 2.3271120307727444

Epoch: 5| Step: 4
Training loss: 0.29907453263649714
Validation loss: 2.333000327077992

Epoch: 5| Step: 5
Training loss: 0.18209372172920893
Validation loss: 2.3708353839277665

Epoch: 5| Step: 6
Training loss: 0.2812316544165561
Validation loss: 2.378459502738218

Epoch: 5| Step: 7
Training loss: 0.2664788631024626
Validation loss: 2.3440478277173553

Epoch: 5| Step: 8
Training loss: 0.24823554065368472
Validation loss: 2.3725671834743567

Epoch: 5| Step: 9
Training loss: 0.2704240414466596
Validation loss: 2.35214160965545

Epoch: 5| Step: 10
Training loss: 0.15939382764457424
Validation loss: 2.3762948759775715

Epoch: 429| Step: 0
Training loss: 0.16456581296096012
Validation loss: 2.3756143107930527

Epoch: 5| Step: 1
Training loss: 0.30618410082657155
Validation loss: 2.3782949669358673

Epoch: 5| Step: 2
Training loss: 0.16656457237686423
Validation loss: 2.373087803501063

Epoch: 5| Step: 3
Training loss: 0.39036372029635574
Validation loss: 2.375151669312272

Epoch: 5| Step: 4
Training loss: 0.37268464242190547
Validation loss: 2.397348845552117

Epoch: 5| Step: 5
Training loss: 0.11306776697971255
Validation loss: 2.346548012457462

Epoch: 5| Step: 6
Training loss: 0.3142223814721725
Validation loss: 2.3504588986206225

Epoch: 5| Step: 7
Training loss: 0.3666701629139643
Validation loss: 2.343830910109886

Epoch: 5| Step: 8
Training loss: 0.23377772361901325
Validation loss: 2.3351955505159236

Epoch: 5| Step: 9
Training loss: 0.16554502094593346
Validation loss: 2.3942391704683468

Epoch: 5| Step: 10
Training loss: 0.1935983876033851
Validation loss: 2.347731899265475

Epoch: 430| Step: 0
Training loss: 0.29237190486155257
Validation loss: 2.3806283188537662

Epoch: 5| Step: 1
Training loss: 0.2398779325947051
Validation loss: 2.3641359916984084

Epoch: 5| Step: 2
Training loss: 0.305211655606273
Validation loss: 2.38689022617336

Epoch: 5| Step: 3
Training loss: 0.23998170451375958
Validation loss: 2.385872254958076

Epoch: 5| Step: 4
Training loss: 0.3938601990548628
Validation loss: 2.4040821273060367

Epoch: 5| Step: 5
Training loss: 0.17997693510100182
Validation loss: 2.36949538242932

Epoch: 5| Step: 6
Training loss: 0.24847948841134804
Validation loss: 2.382936751664609

Epoch: 5| Step: 7
Training loss: 0.22428392798759822
Validation loss: 2.3788416630931803

Epoch: 5| Step: 8
Training loss: 0.1979249755888752
Validation loss: 2.370550152489239

Epoch: 5| Step: 9
Training loss: 0.23980169176019148
Validation loss: 2.3591306946058337

Epoch: 5| Step: 10
Training loss: 0.35325430595637963
Validation loss: 2.344821193469053

Epoch: 431| Step: 0
Training loss: 0.3527982926359027
Validation loss: 2.3707084179799014

Epoch: 5| Step: 1
Training loss: 0.22028386964835386
Validation loss: 2.3545634818897705

Epoch: 5| Step: 2
Training loss: 0.22122847223345002
Validation loss: 2.3464744554974244

Epoch: 5| Step: 3
Training loss: 0.4395400236890212
Validation loss: 2.3654256641897926

Epoch: 5| Step: 4
Training loss: 0.1727257286713171
Validation loss: 2.3982153466263743

Epoch: 5| Step: 5
Training loss: 0.24193884020606365
Validation loss: 2.352172131511052

Epoch: 5| Step: 6
Training loss: 0.3146723107741663
Validation loss: 2.36462289194252

Epoch: 5| Step: 7
Training loss: 0.2361082204629312
Validation loss: 2.3914861466528623

Epoch: 5| Step: 8
Training loss: 0.16564807596137077
Validation loss: 2.35200134778687

Epoch: 5| Step: 9
Training loss: 0.2202883680126841
Validation loss: 2.3666963493155966

Epoch: 5| Step: 10
Training loss: 0.23216341377642882
Validation loss: 2.3313924320834705

Epoch: 432| Step: 0
Training loss: 0.31252404358875174
Validation loss: 2.379724125121112

Epoch: 5| Step: 1
Training loss: 0.18988790469550562
Validation loss: 2.3488903071729137

Epoch: 5| Step: 2
Training loss: 0.35713680551715155
Validation loss: 2.348038218546027

Epoch: 5| Step: 3
Training loss: 0.33611987951867706
Validation loss: 2.35342116471205

Epoch: 5| Step: 4
Training loss: 0.1839110189741606
Validation loss: 2.3528714834691

Epoch: 5| Step: 5
Training loss: 0.3145955160236742
Validation loss: 2.3836565754827466

Epoch: 5| Step: 6
Training loss: 0.20746612759251612
Validation loss: 2.4121459293904515

Epoch: 5| Step: 7
Training loss: 0.2615038430677334
Validation loss: 2.4114324532477807

Epoch: 5| Step: 8
Training loss: 0.26745154178073005
Validation loss: 2.4248335176574396

Epoch: 5| Step: 9
Training loss: 0.2911919565238464
Validation loss: 2.4050785404561457

Epoch: 5| Step: 10
Training loss: 0.19357251451850796
Validation loss: 2.412990877135935

Epoch: 433| Step: 0
Training loss: 0.37728292239521594
Validation loss: 2.3976389621926963

Epoch: 5| Step: 1
Training loss: 0.2443116695144017
Validation loss: 2.3547263896180413

Epoch: 5| Step: 2
Training loss: 0.26193697926554416
Validation loss: 2.3714995772728464

Epoch: 5| Step: 3
Training loss: 0.22269918630108307
Validation loss: 2.322489189023796

Epoch: 5| Step: 4
Training loss: 0.25830089662834144
Validation loss: 2.3280150927208147

Epoch: 5| Step: 5
Training loss: 0.28882111961612916
Validation loss: 2.3308109201509284

Epoch: 5| Step: 6
Training loss: 0.2515211023896783
Validation loss: 2.332194504891348

Epoch: 5| Step: 7
Training loss: 0.33871503816695314
Validation loss: 2.3275198487550055

Epoch: 5| Step: 8
Training loss: 0.12517424449313624
Validation loss: 2.364625328059315

Epoch: 5| Step: 9
Training loss: 0.23116256246473618
Validation loss: 2.3448953363603815

Epoch: 5| Step: 10
Training loss: 0.3234548071132989
Validation loss: 2.3438909005638573

Epoch: 434| Step: 0
Training loss: 0.4038152728744973
Validation loss: 2.3337213381145117

Epoch: 5| Step: 1
Training loss: 0.18247542769450803
Validation loss: 2.407910353065727

Epoch: 5| Step: 2
Training loss: 0.253058706244298
Validation loss: 2.3702182040189155

Epoch: 5| Step: 3
Training loss: 0.24640656072709466
Validation loss: 2.362917771876144

Epoch: 5| Step: 4
Training loss: 0.3288746626086301
Validation loss: 2.346564459131758

Epoch: 5| Step: 5
Training loss: 0.2899714047417002
Validation loss: 2.328798299528351

Epoch: 5| Step: 6
Training loss: 0.2449531994489997
Validation loss: 2.3165857510819095

Epoch: 5| Step: 7
Training loss: 0.2863798149466714
Validation loss: 2.274100105002574

Epoch: 5| Step: 8
Training loss: 0.3873311020793161
Validation loss: 2.2958480562770864

Epoch: 5| Step: 9
Training loss: 0.2610822025121979
Validation loss: 2.3226414561642574

Epoch: 5| Step: 10
Training loss: 0.23725090673301524
Validation loss: 2.3335430710953884

Epoch: 435| Step: 0
Training loss: 0.26480618663407945
Validation loss: 2.3555471685145046

Epoch: 5| Step: 1
Training loss: 0.39429185232610736
Validation loss: 2.3961599896826247

Epoch: 5| Step: 2
Training loss: 0.2634072706813952
Validation loss: 2.3688641324687683

Epoch: 5| Step: 3
Training loss: 0.2923312945136226
Validation loss: 2.385552179234835

Epoch: 5| Step: 4
Training loss: 0.20244722813406657
Validation loss: 2.3979469549357515

Epoch: 5| Step: 5
Training loss: 0.22867686948805488
Validation loss: 2.3807272956665932

Epoch: 5| Step: 6
Training loss: 0.32322404701062324
Validation loss: 2.3656819812383256

Epoch: 5| Step: 7
Training loss: 0.31426678935732233
Validation loss: 2.40106271756746

Epoch: 5| Step: 8
Training loss: 0.2313914819882239
Validation loss: 2.3933896834160757

Epoch: 5| Step: 9
Training loss: 0.3020056290275606
Validation loss: 2.415074385241335

Epoch: 5| Step: 10
Training loss: 0.37052824198333606
Validation loss: 2.4479492087591344

Epoch: 436| Step: 0
Training loss: 0.2983456125653773
Validation loss: 2.4493891162225494

Epoch: 5| Step: 1
Training loss: 0.3632938628929709
Validation loss: 2.471102309211437

Epoch: 5| Step: 2
Training loss: 0.24153019553373978
Validation loss: 2.481316231150287

Epoch: 5| Step: 3
Training loss: 0.20049287964480242
Validation loss: 2.442041630190228

Epoch: 5| Step: 4
Training loss: 0.2219888992509058
Validation loss: 2.401085715414461

Epoch: 5| Step: 5
Training loss: 0.28266990712976753
Validation loss: 2.381283072850034

Epoch: 5| Step: 6
Training loss: 0.20041787406560335
Validation loss: 2.363444523301512

Epoch: 5| Step: 7
Training loss: 0.26319445019696536
Validation loss: 2.343121229484748

Epoch: 5| Step: 8
Training loss: 0.256586541177368
Validation loss: 2.344237331465006

Epoch: 5| Step: 9
Training loss: 0.42328952371446804
Validation loss: 2.3456898286284193

Epoch: 5| Step: 10
Training loss: 0.3667519400700675
Validation loss: 2.316424296576361

Epoch: 437| Step: 0
Training loss: 0.1830215770548555
Validation loss: 2.3526597495693475

Epoch: 5| Step: 1
Training loss: 0.3292883504214418
Validation loss: 2.3669654668689537

Epoch: 5| Step: 2
Training loss: 0.168798597940912
Validation loss: 2.3779178963157217

Epoch: 5| Step: 3
Training loss: 0.25458572144384617
Validation loss: 2.3762063792880377

Epoch: 5| Step: 4
Training loss: 0.2987212070851298
Validation loss: 2.3797006035684762

Epoch: 5| Step: 5
Training loss: 0.2954275961527883
Validation loss: 2.387722364998363

Epoch: 5| Step: 6
Training loss: 0.1994691378526773
Validation loss: 2.381492466707745

Epoch: 5| Step: 7
Training loss: 0.3215917535419081
Validation loss: 2.3096477120341046

Epoch: 5| Step: 8
Training loss: 0.37553240810690924
Validation loss: 2.348978377074967

Epoch: 5| Step: 9
Training loss: 0.24057231177610267
Validation loss: 2.3281776332528477

Epoch: 5| Step: 10
Training loss: 0.21187845273707007
Validation loss: 2.3396043481230793

Epoch: 438| Step: 0
Training loss: 0.2888519577128077
Validation loss: 2.3575714156605687

Epoch: 5| Step: 1
Training loss: 0.13625004672128418
Validation loss: 2.3791435696232655

Epoch: 5| Step: 2
Training loss: 0.2954957065762539
Validation loss: 2.370863817165579

Epoch: 5| Step: 3
Training loss: 0.30475615681538304
Validation loss: 2.3740496685176304

Epoch: 5| Step: 4
Training loss: 0.30754686793148195
Validation loss: 2.404224710586119

Epoch: 5| Step: 5
Training loss: 0.12625503073243757
Validation loss: 2.424959556894407

Epoch: 5| Step: 6
Training loss: 0.30418322476732795
Validation loss: 2.412571018696878

Epoch: 5| Step: 7
Training loss: 0.23957677327725552
Validation loss: 2.382572763837414

Epoch: 5| Step: 8
Training loss: 0.1982540258621782
Validation loss: 2.3947998018332712

Epoch: 5| Step: 9
Training loss: 0.15637155811187214
Validation loss: 2.385393750788675

Epoch: 5| Step: 10
Training loss: 0.40621854586977263
Validation loss: 2.350691371567596

Epoch: 439| Step: 0
Training loss: 0.28243150496783787
Validation loss: 2.3054008590954487

Epoch: 5| Step: 1
Training loss: 0.2848422529523371
Validation loss: 2.330369787557208

Epoch: 5| Step: 2
Training loss: 0.2052040621672858
Validation loss: 2.330322512465038

Epoch: 5| Step: 3
Training loss: 0.2519374812984247
Validation loss: 2.2928521238333675

Epoch: 5| Step: 4
Training loss: 0.17085598009501715
Validation loss: 2.330861163782725

Epoch: 5| Step: 5
Training loss: 0.2390302704920569
Validation loss: 2.298485627695291

Epoch: 5| Step: 6
Training loss: 0.2202591692853924
Validation loss: 2.344393629072795

Epoch: 5| Step: 7
Training loss: 0.4460758893768282
Validation loss: 2.374245150176233

Epoch: 5| Step: 8
Training loss: 0.2437988482948385
Validation loss: 2.3455480229351595

Epoch: 5| Step: 9
Training loss: 0.14593267817771516
Validation loss: 2.3467223103152124

Epoch: 5| Step: 10
Training loss: 0.2007061465322881
Validation loss: 2.345236485025828

Epoch: 440| Step: 0
Training loss: 0.23301771867131613
Validation loss: 2.3409310115856616

Epoch: 5| Step: 1
Training loss: 0.25507005851106934
Validation loss: 2.3319546802433266

Epoch: 5| Step: 2
Training loss: 0.1538185842993257
Validation loss: 2.347946320788962

Epoch: 5| Step: 3
Training loss: 0.35021289753629725
Validation loss: 2.3512701358988286

Epoch: 5| Step: 4
Training loss: 0.2793056513334422
Validation loss: 2.341578156981501

Epoch: 5| Step: 5
Training loss: 0.16112961043441854
Validation loss: 2.3756008866872778

Epoch: 5| Step: 6
Training loss: 0.1839215618879819
Validation loss: 2.33246383602731

Epoch: 5| Step: 7
Training loss: 0.26382488473535265
Validation loss: 2.3449531742892837

Epoch: 5| Step: 8
Training loss: 0.37933793007798017
Validation loss: 2.3638749927581957

Epoch: 5| Step: 9
Training loss: 0.1957622499676625
Validation loss: 2.324401610852062

Epoch: 5| Step: 10
Training loss: 0.1871599949194381
Validation loss: 2.3402524297413456

Epoch: 441| Step: 0
Training loss: 0.3068377960362473
Validation loss: 2.296313687904187

Epoch: 5| Step: 1
Training loss: 0.32110874716455257
Validation loss: 2.3039124968498754

Epoch: 5| Step: 2
Training loss: 0.2596664095828563
Validation loss: 2.2841166556617503

Epoch: 5| Step: 3
Training loss: 0.22962136386905874
Validation loss: 2.353926811301219

Epoch: 5| Step: 4
Training loss: 0.29203399307897576
Validation loss: 2.367925326077214

Epoch: 5| Step: 5
Training loss: 0.3435085163677948
Validation loss: 2.4000218492114977

Epoch: 5| Step: 6
Training loss: 0.12680126056854948
Validation loss: 2.3825091532862896

Epoch: 5| Step: 7
Training loss: 0.17421814208501976
Validation loss: 2.3962535416530395

Epoch: 5| Step: 8
Training loss: 0.32756940033545995
Validation loss: 2.418252669212938

Epoch: 5| Step: 9
Training loss: 0.17709469174440445
Validation loss: 2.4156498797913244

Epoch: 5| Step: 10
Training loss: 0.2724911662734752
Validation loss: 2.3952303911974138

Epoch: 442| Step: 0
Training loss: 0.33705091046823066
Validation loss: 2.3671790028443978

Epoch: 5| Step: 1
Training loss: 0.30233509435757666
Validation loss: 2.308343324928017

Epoch: 5| Step: 2
Training loss: 0.28405056146728375
Validation loss: 2.3076035861345012

Epoch: 5| Step: 3
Training loss: 0.3094316767786264
Validation loss: 2.29515040237049

Epoch: 5| Step: 4
Training loss: 0.3160345696616583
Validation loss: 2.3016497342347755

Epoch: 5| Step: 5
Training loss: 0.27116504248449386
Validation loss: 2.311648058086195

Epoch: 5| Step: 6
Training loss: 0.23781786089254733
Validation loss: 2.3530704709593064

Epoch: 5| Step: 7
Training loss: 0.12997933436700504
Validation loss: 2.4068684544267667

Epoch: 5| Step: 8
Training loss: 0.3432719309170877
Validation loss: 2.4227295552473493

Epoch: 5| Step: 9
Training loss: 0.20445777071498436
Validation loss: 2.4419106522795246

Epoch: 5| Step: 10
Training loss: 0.19232567069260134
Validation loss: 2.4500039722376106

Epoch: 443| Step: 0
Training loss: 0.33585175817264257
Validation loss: 2.4145677749724417

Epoch: 5| Step: 1
Training loss: 0.2974521522952923
Validation loss: 2.421618429163304

Epoch: 5| Step: 2
Training loss: 0.26450236888935214
Validation loss: 2.3763005549816025

Epoch: 5| Step: 3
Training loss: 0.28848280644874946
Validation loss: 2.3810383933143093

Epoch: 5| Step: 4
Training loss: 0.31574188938431197
Validation loss: 2.3519701702618203

Epoch: 5| Step: 5
Training loss: 0.2396994582305359
Validation loss: 2.353794717186223

Epoch: 5| Step: 6
Training loss: 0.37342697272366077
Validation loss: 2.3741612920736737

Epoch: 5| Step: 7
Training loss: 0.13810286843019642
Validation loss: 2.3855895424752562

Epoch: 5| Step: 8
Training loss: 0.20797597614634275
Validation loss: 2.3981599964190483

Epoch: 5| Step: 9
Training loss: 0.30346908016067065
Validation loss: 2.3804878255126396

Epoch: 5| Step: 10
Training loss: 0.22176570315867963
Validation loss: 2.377889502414604

Epoch: 444| Step: 0
Training loss: 0.28075304100889753
Validation loss: 2.3088623998817956

Epoch: 5| Step: 1
Training loss: 0.3193897586928518
Validation loss: 2.299133815192234

Epoch: 5| Step: 2
Training loss: 0.3244219797949329
Validation loss: 2.2609997704136036

Epoch: 5| Step: 3
Training loss: 0.22742762312968237
Validation loss: 2.268043538632448

Epoch: 5| Step: 4
Training loss: 0.2229486018476001
Validation loss: 2.2584969145022105

Epoch: 5| Step: 5
Training loss: 0.20214482548384563
Validation loss: 2.225322556167936

Epoch: 5| Step: 6
Training loss: 0.29166782185916107
Validation loss: 2.3048426666779216

Epoch: 5| Step: 7
Training loss: 0.3808508651956449
Validation loss: 2.3424666995298513

Epoch: 5| Step: 8
Training loss: 0.1644705455097821
Validation loss: 2.3464235486711242

Epoch: 5| Step: 9
Training loss: 0.2870758711800582
Validation loss: 2.3957482243027446

Epoch: 5| Step: 10
Training loss: 0.2600314565574542
Validation loss: 2.4274892779561132

Epoch: 445| Step: 0
Training loss: 0.2505647865937077
Validation loss: 2.3927539330071754

Epoch: 5| Step: 1
Training loss: 0.23625900897252303
Validation loss: 2.4022495414375875

Epoch: 5| Step: 2
Training loss: 0.2730054848533935
Validation loss: 2.3483401355129474

Epoch: 5| Step: 3
Training loss: 0.26908936420712315
Validation loss: 2.3385437784204366

Epoch: 5| Step: 4
Training loss: 0.2388032292650878
Validation loss: 2.3172092982181356

Epoch: 5| Step: 5
Training loss: 0.2836300493028792
Validation loss: 2.329418247403117

Epoch: 5| Step: 6
Training loss: 0.33265988920845235
Validation loss: 2.344381117533676

Epoch: 5| Step: 7
Training loss: 0.23103378020729834
Validation loss: 2.3645781561739847

Epoch: 5| Step: 8
Training loss: 0.3791325866488509
Validation loss: 2.330986478324423

Epoch: 5| Step: 9
Training loss: 0.15156904113064865
Validation loss: 2.3420408299503865

Epoch: 5| Step: 10
Training loss: 0.305719193919231
Validation loss: 2.3577587021870188

Epoch: 446| Step: 0
Training loss: 0.248792518810929
Validation loss: 2.383103317516198

Epoch: 5| Step: 1
Training loss: 0.3315302266297397
Validation loss: 2.3932740918963598

Epoch: 5| Step: 2
Training loss: 0.384853236878739
Validation loss: 2.39330061109021

Epoch: 5| Step: 3
Training loss: 0.3103775786532004
Validation loss: 2.3857101888191696

Epoch: 5| Step: 4
Training loss: 0.2641243901604519
Validation loss: 2.3587676985307886

Epoch: 5| Step: 5
Training loss: 0.25200445554215534
Validation loss: 2.3357422279564313

Epoch: 5| Step: 6
Training loss: 0.16467604694136448
Validation loss: 2.317973581427786

Epoch: 5| Step: 7
Training loss: 0.19602369523720364
Validation loss: 2.3253724119822223

Epoch: 5| Step: 8
Training loss: 0.17901092115976164
Validation loss: 2.3060004958759768

Epoch: 5| Step: 9
Training loss: 0.33572008061262926
Validation loss: 2.3008327432754037

Epoch: 5| Step: 10
Training loss: 0.1657861807015327
Validation loss: 2.3016698158990327

Epoch: 447| Step: 0
Training loss: 0.1941975431457255
Validation loss: 2.283413040087902

Epoch: 5| Step: 1
Training loss: 0.2740996925580521
Validation loss: 2.3272830387390857

Epoch: 5| Step: 2
Training loss: 0.29502955106850737
Validation loss: 2.31091663017507

Epoch: 5| Step: 3
Training loss: 0.316997058899139
Validation loss: 2.3112720953294166

Epoch: 5| Step: 4
Training loss: 0.19209512025522207
Validation loss: 2.350110076812636

Epoch: 5| Step: 5
Training loss: 0.1867799642607008
Validation loss: 2.342172763308568

Epoch: 5| Step: 6
Training loss: 0.26726130364121137
Validation loss: 2.3789544907448645

Epoch: 5| Step: 7
Training loss: 0.3250309755162599
Validation loss: 2.3490756185900605

Epoch: 5| Step: 8
Training loss: 0.1600631815617658
Validation loss: 2.3502317931620307

Epoch: 5| Step: 9
Training loss: 0.3566504946091973
Validation loss: 2.3774662953435604

Epoch: 5| Step: 10
Training loss: 0.14837507767462366
Validation loss: 2.330313986498712

Epoch: 448| Step: 0
Training loss: 0.39884910640394083
Validation loss: 2.347192365155466

Epoch: 5| Step: 1
Training loss: 0.15541402582076005
Validation loss: 2.318161699383111

Epoch: 5| Step: 2
Training loss: 0.20268214072883087
Validation loss: 2.3448003426647044

Epoch: 5| Step: 3
Training loss: 0.17986317008565267
Validation loss: 2.329489916300463

Epoch: 5| Step: 4
Training loss: 0.17322554244939087
Validation loss: 2.3251217956080033

Epoch: 5| Step: 5
Training loss: 0.3072835172229908
Validation loss: 2.329876092729203

Epoch: 5| Step: 6
Training loss: 0.34927226175042114
Validation loss: 2.370891381780089

Epoch: 5| Step: 7
Training loss: 0.29278762304589023
Validation loss: 2.349530258567216

Epoch: 5| Step: 8
Training loss: 0.25204528187749686
Validation loss: 2.3480327141171333

Epoch: 5| Step: 9
Training loss: 0.21485675425620251
Validation loss: 2.35833888402367

Epoch: 5| Step: 10
Training loss: 0.18787825696372074
Validation loss: 2.400178600477856

Epoch: 449| Step: 0
Training loss: 0.29370595368434965
Validation loss: 2.354261092777755

Epoch: 5| Step: 1
Training loss: 0.24973406654658203
Validation loss: 2.3818190283012135

Epoch: 5| Step: 2
Training loss: 0.2851715214441658
Validation loss: 2.351133858648563

Epoch: 5| Step: 3
Training loss: 0.12285604514235776
Validation loss: 2.3594998377790475

Epoch: 5| Step: 4
Training loss: 0.4167228740292117
Validation loss: 2.3617576798005127

Epoch: 5| Step: 5
Training loss: 0.20637248152138268
Validation loss: 2.3950749417241384

Epoch: 5| Step: 6
Training loss: 0.28130591684370987
Validation loss: 2.3812270704078444

Epoch: 5| Step: 7
Training loss: 0.1990326779123104
Validation loss: 2.361685197392055

Epoch: 5| Step: 8
Training loss: 0.17476426088655952
Validation loss: 2.3383420664492265

Epoch: 5| Step: 9
Training loss: 0.2021908001578799
Validation loss: 2.31276151535878

Epoch: 5| Step: 10
Training loss: 0.12867894505878408
Validation loss: 2.2934190707940276

Epoch: 450| Step: 0
Training loss: 0.2748817856251622
Validation loss: 2.2929618818435937

Epoch: 5| Step: 1
Training loss: 0.1347086274510288
Validation loss: 2.2719651000639622

Epoch: 5| Step: 2
Training loss: 0.12841923789205842
Validation loss: 2.273067126057642

Epoch: 5| Step: 3
Training loss: 0.2112731823390157
Validation loss: 2.2747407963649944

Epoch: 5| Step: 4
Training loss: 0.4225379362229731
Validation loss: 2.2891063681082264

Epoch: 5| Step: 5
Training loss: 0.32317367703561045
Validation loss: 2.32702139815352

Epoch: 5| Step: 6
Training loss: 0.2823595439882307
Validation loss: 2.3530615292468324

Epoch: 5| Step: 7
Training loss: 0.2015371524782242
Validation loss: 2.3779347653349605

Epoch: 5| Step: 8
Training loss: 0.21943355096834424
Validation loss: 2.3913408923717796

Epoch: 5| Step: 9
Training loss: 0.32545078541169636
Validation loss: 2.434988447008085

Epoch: 5| Step: 10
Training loss: 0.1266198110920014
Validation loss: 2.4335873809042687

Epoch: 451| Step: 0
Training loss: 0.2432849767248819
Validation loss: 2.4329064446370494

Epoch: 5| Step: 1
Training loss: 0.3041340006418745
Validation loss: 2.4049381272538097

Epoch: 5| Step: 2
Training loss: 0.22104878490688268
Validation loss: 2.414782668140352

Epoch: 5| Step: 3
Training loss: 0.2155685769079232
Validation loss: 2.3794953136414447

Epoch: 5| Step: 4
Training loss: 0.31136560776816696
Validation loss: 2.3738578701228032

Epoch: 5| Step: 5
Training loss: 0.19860804205489116
Validation loss: 2.3399934855153868

Epoch: 5| Step: 6
Training loss: 0.17082471074658054
Validation loss: 2.340449673392926

Epoch: 5| Step: 7
Training loss: 0.4118820395034515
Validation loss: 2.3538958863575585

Epoch: 5| Step: 8
Training loss: 0.2564001701698839
Validation loss: 2.331007312469022

Epoch: 5| Step: 9
Training loss: 0.22392468791150746
Validation loss: 2.3387107556863573

Epoch: 5| Step: 10
Training loss: 0.21044990911171388
Validation loss: 2.358023957717236

Epoch: 452| Step: 0
Training loss: 0.3083946938073073
Validation loss: 2.3332854835889467

Epoch: 5| Step: 1
Training loss: 0.17668144409905542
Validation loss: 2.3360258178938293

Epoch: 5| Step: 2
Training loss: 0.23531186097401532
Validation loss: 2.3318440695478584

Epoch: 5| Step: 3
Training loss: 0.18623714545073003
Validation loss: 2.3248280300953463

Epoch: 5| Step: 4
Training loss: 0.2500533404666632
Validation loss: 2.315111969441282

Epoch: 5| Step: 5
Training loss: 0.2129256455900871
Validation loss: 2.3031225281509826

Epoch: 5| Step: 6
Training loss: 0.30085650654398355
Validation loss: 2.327814585122194

Epoch: 5| Step: 7
Training loss: 0.23096133786595724
Validation loss: 2.308887516371015

Epoch: 5| Step: 8
Training loss: 0.31681550014698573
Validation loss: 2.287881095759221

Epoch: 5| Step: 9
Training loss: 0.3312082637728885
Validation loss: 2.3630349107042306

Epoch: 5| Step: 10
Training loss: 0.16598935760931158
Validation loss: 2.345929574155202

Epoch: 453| Step: 0
Training loss: 0.3221800141339006
Validation loss: 2.3407709320979384

Epoch: 5| Step: 1
Training loss: 0.22984471130948042
Validation loss: 2.3527157626900363

Epoch: 5| Step: 2
Training loss: 0.2434548244383951
Validation loss: 2.332136375825425

Epoch: 5| Step: 3
Training loss: 0.2141260644415271
Validation loss: 2.3294192224899786

Epoch: 5| Step: 4
Training loss: 0.3070171983915312
Validation loss: 2.299318520208913

Epoch: 5| Step: 5
Training loss: 0.16748577365314374
Validation loss: 2.291986901365221

Epoch: 5| Step: 6
Training loss: 0.26668833623450594
Validation loss: 2.3042812606044154

Epoch: 5| Step: 7
Training loss: 0.30659220853882097
Validation loss: 2.3011698066821795

Epoch: 5| Step: 8
Training loss: 0.16546060685282746
Validation loss: 2.335293538298998

Epoch: 5| Step: 9
Training loss: 0.26524779239476526
Validation loss: 2.358920843513705

Epoch: 5| Step: 10
Training loss: 0.1598999368242529
Validation loss: 2.374493604319859

Epoch: 454| Step: 0
Training loss: 0.2422304038530777
Validation loss: 2.3751125848722223

Epoch: 5| Step: 1
Training loss: 0.1648620581742522
Validation loss: 2.3589404653417514

Epoch: 5| Step: 2
Training loss: 0.15923461083540785
Validation loss: 2.3522864454415235

Epoch: 5| Step: 3
Training loss: 0.26690543327300376
Validation loss: 2.3704428146811147

Epoch: 5| Step: 4
Training loss: 0.3136929273369551
Validation loss: 2.3546021670583923

Epoch: 5| Step: 5
Training loss: 0.2713957580181133
Validation loss: 2.3431541872347714

Epoch: 5| Step: 6
Training loss: 0.20529491228750213
Validation loss: 2.357305881914384

Epoch: 5| Step: 7
Training loss: 0.3489449650305702
Validation loss: 2.34368432284526

Epoch: 5| Step: 8
Training loss: 0.1274458128068652
Validation loss: 2.3553698480928102

Epoch: 5| Step: 9
Training loss: 0.1505606792160918
Validation loss: 2.32536466660467

Epoch: 5| Step: 10
Training loss: 0.3788208619481757
Validation loss: 2.3288893919307707

Epoch: 455| Step: 0
Training loss: 0.1488536347281168
Validation loss: 2.336905063630525

Epoch: 5| Step: 1
Training loss: 0.26666851390755125
Validation loss: 2.3452060445288696

Epoch: 5| Step: 2
Training loss: 0.22923803663082287
Validation loss: 2.3154992960331158

Epoch: 5| Step: 3
Training loss: 0.22987355138229937
Validation loss: 2.349223378676486

Epoch: 5| Step: 4
Training loss: 0.3087654360491704
Validation loss: 2.3773732258472617

Epoch: 5| Step: 5
Training loss: 0.382013323622671
Validation loss: 2.3325460932707927

Epoch: 5| Step: 6
Training loss: 0.21045305111398263
Validation loss: 2.3846617297240473

Epoch: 5| Step: 7
Training loss: 0.11802191894022977
Validation loss: 2.382534976144639

Epoch: 5| Step: 8
Training loss: 0.28536147740741596
Validation loss: 2.351733888444556

Epoch: 5| Step: 9
Training loss: 0.13151375291073605
Validation loss: 2.3830295678377924

Epoch: 5| Step: 10
Training loss: 0.18633234511100863
Validation loss: 2.3748796180997

Epoch: 456| Step: 0
Training loss: 0.22118106506291632
Validation loss: 2.3685884264592927

Epoch: 5| Step: 1
Training loss: 0.2642288964712876
Validation loss: 2.3889929031039125

Epoch: 5| Step: 2
Training loss: 0.19656958391375892
Validation loss: 2.35242264447898

Epoch: 5| Step: 3
Training loss: 0.21989326087631186
Validation loss: 2.3973395607736574

Epoch: 5| Step: 4
Training loss: 0.1236934853479479
Validation loss: 2.3960175256606027

Epoch: 5| Step: 5
Training loss: 0.10364155037655315
Validation loss: 2.3228855875008136

Epoch: 5| Step: 6
Training loss: 0.27460330668835364
Validation loss: 2.3639039695418758

Epoch: 5| Step: 7
Training loss: 0.3483110754455206
Validation loss: 2.3701593455710377

Epoch: 5| Step: 8
Training loss: 0.24879662151116527
Validation loss: 2.3839237961664517

Epoch: 5| Step: 9
Training loss: 0.20377941352240186
Validation loss: 2.392778530504803

Epoch: 5| Step: 10
Training loss: 0.28287190767031645
Validation loss: 2.4063666008733384

Epoch: 457| Step: 0
Training loss: 0.25924747100983386
Validation loss: 2.3803117184402764

Epoch: 5| Step: 1
Training loss: 0.2582334059187388
Validation loss: 2.3634375833472605

Epoch: 5| Step: 2
Training loss: 0.13558844909935408
Validation loss: 2.3357853483404263

Epoch: 5| Step: 3
Training loss: 0.3937120525300036
Validation loss: 2.3321704182280913

Epoch: 5| Step: 4
Training loss: 0.1838121332815404
Validation loss: 2.3194563682389995

Epoch: 5| Step: 5
Training loss: 0.234141782121978
Validation loss: 2.3418533438944396

Epoch: 5| Step: 6
Training loss: 0.21881569148473545
Validation loss: 2.3424588437753417

Epoch: 5| Step: 7
Training loss: 0.16997201223726788
Validation loss: 2.300653702409373

Epoch: 5| Step: 8
Training loss: 0.15529303157182855
Validation loss: 2.3074758868108063

Epoch: 5| Step: 9
Training loss: 0.1758212256010593
Validation loss: 2.3281568365514183

Epoch: 5| Step: 10
Training loss: 0.2891761968583121
Validation loss: 2.3192699846045106

Epoch: 458| Step: 0
Training loss: 0.18245517459458768
Validation loss: 2.3175244759756763

Epoch: 5| Step: 1
Training loss: 0.123933436560855
Validation loss: 2.335033155951898

Epoch: 5| Step: 2
Training loss: 0.1378549367524667
Validation loss: 2.327914272829784

Epoch: 5| Step: 3
Training loss: 0.25313646561357267
Validation loss: 2.3388577412604996

Epoch: 5| Step: 4
Training loss: 0.2515129265601065
Validation loss: 2.3329821134031334

Epoch: 5| Step: 5
Training loss: 0.24420517640274583
Validation loss: 2.3386944571237764

Epoch: 5| Step: 6
Training loss: 0.24132660166024064
Validation loss: 2.358984924941988

Epoch: 5| Step: 7
Training loss: 0.2814795563915601
Validation loss: 2.3387814092473493

Epoch: 5| Step: 8
Training loss: 0.3669978118514228
Validation loss: 2.3646436666149766

Epoch: 5| Step: 9
Training loss: 0.30453067802974404
Validation loss: 2.3752543891195725

Epoch: 5| Step: 10
Training loss: 0.10880267316644054
Validation loss: 2.359760611753781

Epoch: 459| Step: 0
Training loss: 0.12293769140039544
Validation loss: 2.400325166856789

Epoch: 5| Step: 1
Training loss: 0.2336359850233262
Validation loss: 2.3939736173709183

Epoch: 5| Step: 2
Training loss: 0.14145866945163119
Validation loss: 2.366184362806418

Epoch: 5| Step: 3
Training loss: 0.25454669289667003
Validation loss: 2.3464653681953123

Epoch: 5| Step: 4
Training loss: 0.3505142478645441
Validation loss: 2.3486353929132093

Epoch: 5| Step: 5
Training loss: 0.33010779478816454
Validation loss: 2.3042696721978864

Epoch: 5| Step: 6
Training loss: 0.29982372310483896
Validation loss: 2.3200609740581646

Epoch: 5| Step: 7
Training loss: 0.1653461477310928
Validation loss: 2.3329517239958912

Epoch: 5| Step: 8
Training loss: 0.1889730742483202
Validation loss: 2.314159406553208

Epoch: 5| Step: 9
Training loss: 0.2186281256405939
Validation loss: 2.3397384319371537

Epoch: 5| Step: 10
Training loss: 0.29853109170419734
Validation loss: 2.3870822006835

Epoch: 460| Step: 0
Training loss: 0.3587800574587289
Validation loss: 2.3852532361200165

Epoch: 5| Step: 1
Training loss: 0.3852992158070932
Validation loss: 2.3915903361018356

Epoch: 5| Step: 2
Training loss: 0.22794331507407928
Validation loss: 2.3767684716635045

Epoch: 5| Step: 3
Training loss: 0.2520934017524664
Validation loss: 2.3790226339121556

Epoch: 5| Step: 4
Training loss: 0.1177375362328752
Validation loss: 2.360945973622325

Epoch: 5| Step: 5
Training loss: 0.1394431866649352
Validation loss: 2.3406130880945955

Epoch: 5| Step: 6
Training loss: 0.26015288662955843
Validation loss: 2.2942894262115647

Epoch: 5| Step: 7
Training loss: 0.12955206871686972
Validation loss: 2.3180064753569436

Epoch: 5| Step: 8
Training loss: 0.16175852000918464
Validation loss: 2.304929932082386

Epoch: 5| Step: 9
Training loss: 0.2108078487515329
Validation loss: 2.308756644034661

Epoch: 5| Step: 10
Training loss: 0.2619540452130381
Validation loss: 2.3421894568789257

Epoch: 461| Step: 0
Training loss: 0.20030974862326256
Validation loss: 2.346883674835929

Epoch: 5| Step: 1
Training loss: 0.26337012932975956
Validation loss: 2.365639661556919

Epoch: 5| Step: 2
Training loss: 0.3214684423343391
Validation loss: 2.3355857481942537

Epoch: 5| Step: 3
Training loss: 0.14981740228639487
Validation loss: 2.3145840562586506

Epoch: 5| Step: 4
Training loss: 0.3627332224879954
Validation loss: 2.3296593675719306

Epoch: 5| Step: 5
Training loss: 0.1407132004599357
Validation loss: 2.3183474052424224

Epoch: 5| Step: 6
Training loss: 0.26882127881166756
Validation loss: 2.3131544223161056

Epoch: 5| Step: 7
Training loss: 0.19033604789398428
Validation loss: 2.291916193945905

Epoch: 5| Step: 8
Training loss: 0.4079071870403067
Validation loss: 2.2831491823813015

Epoch: 5| Step: 9
Training loss: 0.22476404918108975
Validation loss: 2.314971382584202

Epoch: 5| Step: 10
Training loss: 0.16092084178079868
Validation loss: 2.3158476416285114

Epoch: 462| Step: 0
Training loss: 0.20844071521595517
Validation loss: 2.3188516882480674

Epoch: 5| Step: 1
Training loss: 0.15418639634050127
Validation loss: 2.347454546204272

Epoch: 5| Step: 2
Training loss: 0.312072628565106
Validation loss: 2.380998250736267

Epoch: 5| Step: 3
Training loss: 0.26120415670916
Validation loss: 2.3887877423405777

Epoch: 5| Step: 4
Training loss: 0.2607517454988643
Validation loss: 2.3947979680607414

Epoch: 5| Step: 5
Training loss: 0.18265938908707977
Validation loss: 2.3760698679651213

Epoch: 5| Step: 6
Training loss: 0.27124027557784763
Validation loss: 2.380676188725138

Epoch: 5| Step: 7
Training loss: 0.18404900130560828
Validation loss: 2.389993564775367

Epoch: 5| Step: 8
Training loss: 0.17566859556070472
Validation loss: 2.3578160527812373

Epoch: 5| Step: 9
Training loss: 0.12527217142329486
Validation loss: 2.361225560997701

Epoch: 5| Step: 10
Training loss: 0.38124229548439525
Validation loss: 2.345776864613658

Epoch: 463| Step: 0
Training loss: 0.27460401212358326
Validation loss: 2.3508647319139553

Epoch: 5| Step: 1
Training loss: 0.2797736786357186
Validation loss: 2.3578359028913396

Epoch: 5| Step: 2
Training loss: 0.24592016546773865
Validation loss: 2.343663400670364

Epoch: 5| Step: 3
Training loss: 0.22792755982387375
Validation loss: 2.3082315816635934

Epoch: 5| Step: 4
Training loss: 0.15569762702074105
Validation loss: 2.3427024573093367

Epoch: 5| Step: 5
Training loss: 0.18816307165808774
Validation loss: 2.385956291882611

Epoch: 5| Step: 6
Training loss: 0.2944334166164087
Validation loss: 2.3765550821196957

Epoch: 5| Step: 7
Training loss: 0.20729551004236582
Validation loss: 2.369366752521932

Epoch: 5| Step: 8
Training loss: 0.3269615436595825
Validation loss: 2.3987817645808223

Epoch: 5| Step: 9
Training loss: 0.3666569752748996
Validation loss: 2.3862990438999914

Epoch: 5| Step: 10
Training loss: 0.1603355392739586
Validation loss: 2.3876935720505537

Epoch: 464| Step: 0
Training loss: 0.19621112092131254
Validation loss: 2.3785931910476372

Epoch: 5| Step: 1
Training loss: 0.17035008330775586
Validation loss: 2.337622742728452

Epoch: 5| Step: 2
Training loss: 0.3052576794404249
Validation loss: 2.3627414207163118

Epoch: 5| Step: 3
Training loss: 0.2651260823457487
Validation loss: 2.3719740828477285

Epoch: 5| Step: 4
Training loss: 0.2955424619381004
Validation loss: 2.327249176555094

Epoch: 5| Step: 5
Training loss: 0.28661909216420733
Validation loss: 2.3409817290303

Epoch: 5| Step: 6
Training loss: 0.2739557803993551
Validation loss: 2.3662312139378128

Epoch: 5| Step: 7
Training loss: 0.2031665172696314
Validation loss: 2.3556730814073057

Epoch: 5| Step: 8
Training loss: 0.28436143706539463
Validation loss: 2.381977168212912

Epoch: 5| Step: 9
Training loss: 0.29267652560506313
Validation loss: 2.350331937408264

Epoch: 5| Step: 10
Training loss: 0.2190807175645792
Validation loss: 2.339449794817058

Epoch: 465| Step: 0
Training loss: 0.28152040886708757
Validation loss: 2.3414495563751427

Epoch: 5| Step: 1
Training loss: 0.3267193271662879
Validation loss: 2.320663673616825

Epoch: 5| Step: 2
Training loss: 0.3046986749018046
Validation loss: 2.3473497165067045

Epoch: 5| Step: 3
Training loss: 0.13518994330342357
Validation loss: 2.32661637640978

Epoch: 5| Step: 4
Training loss: 0.2221011721625607
Validation loss: 2.3642072706984902

Epoch: 5| Step: 5
Training loss: 0.2792453985193706
Validation loss: 2.369185872465843

Epoch: 5| Step: 6
Training loss: 0.2473767080778124
Validation loss: 2.4040350466172913

Epoch: 5| Step: 7
Training loss: 0.26279787805366844
Validation loss: 2.4243121129200658

Epoch: 5| Step: 8
Training loss: 0.24513800027339222
Validation loss: 2.4211022029584703

Epoch: 5| Step: 9
Training loss: 0.19951878188332872
Validation loss: 2.4102690466177688

Epoch: 5| Step: 10
Training loss: 0.3466332847810206
Validation loss: 2.4211558491242715

Epoch: 466| Step: 0
Training loss: 0.21139430985773186
Validation loss: 2.358572515042976

Epoch: 5| Step: 1
Training loss: 0.2280002880178272
Validation loss: 2.330827946969174

Epoch: 5| Step: 2
Training loss: 0.47810324201755283
Validation loss: 2.2986123269528593

Epoch: 5| Step: 3
Training loss: 0.5449634659184662
Validation loss: 2.3269604819809566

Epoch: 5| Step: 4
Training loss: 0.3374897447546799
Validation loss: 2.3922751378540426

Epoch: 5| Step: 5
Training loss: 0.2601096807503154
Validation loss: 2.410293904646135

Epoch: 5| Step: 6
Training loss: 0.46735780922452475
Validation loss: 2.4042099016746885

Epoch: 5| Step: 7
Training loss: 0.4225731653425648
Validation loss: 2.419850856700932

Epoch: 5| Step: 8
Training loss: 0.3293408392793763
Validation loss: 2.4234388401301272

Epoch: 5| Step: 9
Training loss: 0.47540442666900395
Validation loss: 2.4195821980665704

Epoch: 5| Step: 10
Training loss: 0.2968096535691382
Validation loss: 2.3883653546256447

Epoch: 467| Step: 0
Training loss: 0.2771219656240015
Validation loss: 2.335383471169542

Epoch: 5| Step: 1
Training loss: 0.38136078522534334
Validation loss: 2.3352185081604904

Epoch: 5| Step: 2
Training loss: 0.3766566479385769
Validation loss: 2.3404417966284554

Epoch: 5| Step: 3
Training loss: 0.383442982336769
Validation loss: 2.392643145777883

Epoch: 5| Step: 4
Training loss: 0.32184210025828636
Validation loss: 2.392936410569872

Epoch: 5| Step: 5
Training loss: 0.5847150384482301
Validation loss: 2.4430599915007796

Epoch: 5| Step: 6
Training loss: 0.27145690230087277
Validation loss: 2.4179067386226594

Epoch: 5| Step: 7
Training loss: 0.23133897551726984
Validation loss: 2.4196438963292985

Epoch: 5| Step: 8
Training loss: 0.24781406169990958
Validation loss: 2.3884832096248103

Epoch: 5| Step: 9
Training loss: 0.3394573580145428
Validation loss: 2.374014837386505

Epoch: 5| Step: 10
Training loss: 0.3310875890355724
Validation loss: 2.349747916721366

Epoch: 468| Step: 0
Training loss: 0.45726442502097503
Validation loss: 2.3896879959977575

Epoch: 5| Step: 1
Training loss: 0.27100603240062826
Validation loss: 2.37054775220116

Epoch: 5| Step: 2
Training loss: 0.19359791616493685
Validation loss: 2.3926192122768164

Epoch: 5| Step: 3
Training loss: 0.251313780807195
Validation loss: 2.42197611819644

Epoch: 5| Step: 4
Training loss: 0.1833734204796995
Validation loss: 2.4396981996571303

Epoch: 5| Step: 5
Training loss: 0.32040195844092795
Validation loss: 2.4984444177760317

Epoch: 5| Step: 6
Training loss: 0.327282903565282
Validation loss: 2.5041921005553096

Epoch: 5| Step: 7
Training loss: 0.30251539370485253
Validation loss: 2.5032960708393577

Epoch: 5| Step: 8
Training loss: 0.36970988788677017
Validation loss: 2.458973134084119

Epoch: 5| Step: 9
Training loss: 0.32475411210015226
Validation loss: 2.37321080945935

Epoch: 5| Step: 10
Training loss: 0.331308689406393
Validation loss: 2.332428881783162

Epoch: 469| Step: 0
Training loss: 0.41056850242088716
Validation loss: 2.30375652972939

Epoch: 5| Step: 1
Training loss: 0.4391526784635574
Validation loss: 2.2824179996502796

Epoch: 5| Step: 2
Training loss: 0.4375922071836571
Validation loss: 2.290446717606946

Epoch: 5| Step: 3
Training loss: 0.3291331312846311
Validation loss: 2.2866342217946642

Epoch: 5| Step: 4
Training loss: 0.3851509295051587
Validation loss: 2.3558307945559056

Epoch: 5| Step: 5
Training loss: 0.3358394790296912
Validation loss: 2.4092208779174475

Epoch: 5| Step: 6
Training loss: 0.25906837792624865
Validation loss: 2.4004308822226315

Epoch: 5| Step: 7
Training loss: 0.11389702296462885
Validation loss: 2.4732138362693026

Epoch: 5| Step: 8
Training loss: 0.37395040331891577
Validation loss: 2.473289688674331

Epoch: 5| Step: 9
Training loss: 0.22946549930007737
Validation loss: 2.4332340564386636

Epoch: 5| Step: 10
Training loss: 0.3500658284168533
Validation loss: 2.4109660134008313

Epoch: 470| Step: 0
Training loss: 0.28374117022484574
Validation loss: 2.3545491347736984

Epoch: 5| Step: 1
Training loss: 0.24149518890011423
Validation loss: 2.3868386408501125

Epoch: 5| Step: 2
Training loss: 0.27781114013648006
Validation loss: 2.371055938845757

Epoch: 5| Step: 3
Training loss: 0.28026244510799647
Validation loss: 2.3332184180588507

Epoch: 5| Step: 4
Training loss: 0.21569754271725775
Validation loss: 2.3160764193119845

Epoch: 5| Step: 5
Training loss: 0.23777930751151993
Validation loss: 2.3315423150693295

Epoch: 5| Step: 6
Training loss: 0.20916782776509046
Validation loss: 2.337779082305804

Epoch: 5| Step: 7
Training loss: 0.3521364613050021
Validation loss: 2.33529113635316

Epoch: 5| Step: 8
Training loss: 0.22344104590636732
Validation loss: 2.3540211715262647

Epoch: 5| Step: 9
Training loss: 0.19789825634072553
Validation loss: 2.3593138097564523

Epoch: 5| Step: 10
Training loss: 0.32365964457142515
Validation loss: 2.3528592403767123

Epoch: 471| Step: 0
Training loss: 0.24222676666403725
Validation loss: 2.364752012431321

Epoch: 5| Step: 1
Training loss: 0.25680859496340597
Validation loss: 2.346365802163289

Epoch: 5| Step: 2
Training loss: 0.12666091301073576
Validation loss: 2.3674549877747015

Epoch: 5| Step: 3
Training loss: 0.12639129738847527
Validation loss: 2.4193552957213047

Epoch: 5| Step: 4
Training loss: 0.17937282291779222
Validation loss: 2.3621433063226527

Epoch: 5| Step: 5
Training loss: 0.3735848387545268
Validation loss: 2.3705625697100485

Epoch: 5| Step: 6
Training loss: 0.1670273693568861
Validation loss: 2.3676640202082373

Epoch: 5| Step: 7
Training loss: 0.32854570938232314
Validation loss: 2.375377195464168

Epoch: 5| Step: 8
Training loss: 0.2664349353146946
Validation loss: 2.3712802020386907

Epoch: 5| Step: 9
Training loss: 0.2637136073112249
Validation loss: 2.382976025141738

Epoch: 5| Step: 10
Training loss: 0.29320577569948025
Validation loss: 2.4061403786265894

Epoch: 472| Step: 0
Training loss: 0.14049707660696645
Validation loss: 2.3789273940394313

Epoch: 5| Step: 1
Training loss: 0.2664719989892145
Validation loss: 2.389723191932429

Epoch: 5| Step: 2
Training loss: 0.2045329704532871
Validation loss: 2.388460216549618

Epoch: 5| Step: 3
Training loss: 0.18149986760933307
Validation loss: 2.3890634817980403

Epoch: 5| Step: 4
Training loss: 0.2500714259634268
Validation loss: 2.3867138906415013

Epoch: 5| Step: 5
Training loss: 0.306936837742673
Validation loss: 2.374315651145616

Epoch: 5| Step: 6
Training loss: 0.2666826928185774
Validation loss: 2.344253803099117

Epoch: 5| Step: 7
Training loss: 0.1814758106794011
Validation loss: 2.3779151309796838

Epoch: 5| Step: 8
Training loss: 0.3117481246530862
Validation loss: 2.3760194247517856

Epoch: 5| Step: 9
Training loss: 0.30621471104399606
Validation loss: 2.35003385556527

Epoch: 5| Step: 10
Training loss: 0.20414185012292094
Validation loss: 2.3786550277696477

Epoch: 473| Step: 0
Training loss: 0.12815130853370002
Validation loss: 2.366381208676722

Epoch: 5| Step: 1
Training loss: 0.28364427342419624
Validation loss: 2.386542242815558

Epoch: 5| Step: 2
Training loss: 0.23742495342441763
Validation loss: 2.3828640700068084

Epoch: 5| Step: 3
Training loss: 0.25964688333476926
Validation loss: 2.3929921906728655

Epoch: 5| Step: 4
Training loss: 0.2078223408971858
Validation loss: 2.388601093153939

Epoch: 5| Step: 5
Training loss: 0.2552125194102447
Validation loss: 2.382202989291512

Epoch: 5| Step: 6
Training loss: 0.3052230310101755
Validation loss: 2.406545380392201

Epoch: 5| Step: 7
Training loss: 0.2169208773396524
Validation loss: 2.4034771987694072

Epoch: 5| Step: 8
Training loss: 0.15495051387138192
Validation loss: 2.4034345499285177

Epoch: 5| Step: 9
Training loss: 0.14130620077831602
Validation loss: 2.393229035265435

Epoch: 5| Step: 10
Training loss: 0.24175478363975048
Validation loss: 2.413564890702247

Epoch: 474| Step: 0
Training loss: 0.30811205825167337
Validation loss: 2.3817299155937115

Epoch: 5| Step: 1
Training loss: 0.16790904603053963
Validation loss: 2.4057774297458137

Epoch: 5| Step: 2
Training loss: 0.1509305377997268
Validation loss: 2.4123038331246685

Epoch: 5| Step: 3
Training loss: 0.24403498843770133
Validation loss: 2.408341953636718

Epoch: 5| Step: 4
Training loss: 0.3391785524114911
Validation loss: 2.3693416993591567

Epoch: 5| Step: 5
Training loss: 0.216559976587828
Validation loss: 2.4114211905345

Epoch: 5| Step: 6
Training loss: 0.2601024193960301
Validation loss: 2.3746373526312734

Epoch: 5| Step: 7
Training loss: 0.2330400836273445
Validation loss: 2.3207550074346375

Epoch: 5| Step: 8
Training loss: 0.2701995001525336
Validation loss: 2.327368642654628

Epoch: 5| Step: 9
Training loss: 0.16153150997262714
Validation loss: 2.3908533057939474

Epoch: 5| Step: 10
Training loss: 0.18194079464203283
Validation loss: 2.3621209012263438

Epoch: 475| Step: 0
Training loss: 0.0972328448689352
Validation loss: 2.364773232616942

Epoch: 5| Step: 1
Training loss: 0.35284191025904776
Validation loss: 2.413896688184241

Epoch: 5| Step: 2
Training loss: 0.14173373926419863
Validation loss: 2.405936323117014

Epoch: 5| Step: 3
Training loss: 0.2833476914362769
Validation loss: 2.372432614216698

Epoch: 5| Step: 4
Training loss: 0.23777611142042043
Validation loss: 2.3884333183850033

Epoch: 5| Step: 5
Training loss: 0.09916435669347667
Validation loss: 2.3577134208113004

Epoch: 5| Step: 6
Training loss: 0.22614684287580514
Validation loss: 2.375946237461865

Epoch: 5| Step: 7
Training loss: 0.2576784883783575
Validation loss: 2.4076265111621376

Epoch: 5| Step: 8
Training loss: 0.1922521873871785
Validation loss: 2.378062577661547

Epoch: 5| Step: 9
Training loss: 0.18128359992903254
Validation loss: 2.404762242821593

Epoch: 5| Step: 10
Training loss: 0.1747733572902208
Validation loss: 2.435475020228543

Epoch: 476| Step: 0
Training loss: 0.18758938566103936
Validation loss: 2.4440939973632076

Epoch: 5| Step: 1
Training loss: 0.19393691114839684
Validation loss: 2.4542217625836

Epoch: 5| Step: 2
Training loss: 0.15954385535778817
Validation loss: 2.428391543223961

Epoch: 5| Step: 3
Training loss: 0.15917904976559066
Validation loss: 2.456175553941546

Epoch: 5| Step: 4
Training loss: 0.18730497151374167
Validation loss: 2.4434974767584614

Epoch: 5| Step: 5
Training loss: 0.27400744847629227
Validation loss: 2.3918061432013724

Epoch: 5| Step: 6
Training loss: 0.2640191510977519
Validation loss: 2.408413739215311

Epoch: 5| Step: 7
Training loss: 0.2118972209091994
Validation loss: 2.392524295592273

Epoch: 5| Step: 8
Training loss: 0.18088375858199018
Validation loss: 2.368833842460284

Epoch: 5| Step: 9
Training loss: 0.18732446162407237
Validation loss: 2.389459105178461

Epoch: 5| Step: 10
Training loss: 0.33760524009636733
Validation loss: 2.347336178267925

Epoch: 477| Step: 0
Training loss: 0.2961620755236007
Validation loss: 2.38180963401083

Epoch: 5| Step: 1
Training loss: 0.16805417638653702
Validation loss: 2.389771367726845

Epoch: 5| Step: 2
Training loss: 0.23648227834386457
Validation loss: 2.367829925946301

Epoch: 5| Step: 3
Training loss: 0.16768939607830027
Validation loss: 2.3801624147095746

Epoch: 5| Step: 4
Training loss: 0.25912216629101936
Validation loss: 2.3996891775839897

Epoch: 5| Step: 5
Training loss: 0.2949980580540765
Validation loss: 2.4072019025677753

Epoch: 5| Step: 6
Training loss: 0.22579295085168233
Validation loss: 2.389175474241335

Epoch: 5| Step: 7
Training loss: 0.1184518949774143
Validation loss: 2.4170133817938186

Epoch: 5| Step: 8
Training loss: 0.1944971613909736
Validation loss: 2.437512620967377

Epoch: 5| Step: 9
Training loss: 0.12265429237042674
Validation loss: 2.410110419747033

Epoch: 5| Step: 10
Training loss: 0.11886066233952157
Validation loss: 2.421472555299345

Epoch: 478| Step: 0
Training loss: 0.25102635642939786
Validation loss: 2.4402702603247985

Epoch: 5| Step: 1
Training loss: 0.12041921171616694
Validation loss: 2.412573853227893

Epoch: 5| Step: 2
Training loss: 0.2643713538727816
Validation loss: 2.419808985110267

Epoch: 5| Step: 3
Training loss: 0.28511506919842206
Validation loss: 2.412430657162707

Epoch: 5| Step: 4
Training loss: 0.17782572609932712
Validation loss: 2.4024870633579694

Epoch: 5| Step: 5
Training loss: 0.14060071894511392
Validation loss: 2.373729440703874

Epoch: 5| Step: 6
Training loss: 0.09980300707811456
Validation loss: 2.3657894093482814

Epoch: 5| Step: 7
Training loss: 0.2642361854110883
Validation loss: 2.382946731603245

Epoch: 5| Step: 8
Training loss: 0.16227027652228004
Validation loss: 2.4078568610977475

Epoch: 5| Step: 9
Training loss: 0.22287528658135475
Validation loss: 2.369012727387654

Epoch: 5| Step: 10
Training loss: 0.24456124502620905
Validation loss: 2.4185025549343604

Epoch: 479| Step: 0
Training loss: 0.17666810746906217
Validation loss: 2.381002614631104

Epoch: 5| Step: 1
Training loss: 0.1681222436104622
Validation loss: 2.4088348517382148

Epoch: 5| Step: 2
Training loss: 0.19723157305518904
Validation loss: 2.413139244501359

Epoch: 5| Step: 3
Training loss: 0.1785120039224126
Validation loss: 2.4302346023407035

Epoch: 5| Step: 4
Training loss: 0.273698654802938
Validation loss: 2.3648685097057567

Epoch: 5| Step: 5
Training loss: 0.16297125638861318
Validation loss: 2.373850579929527

Epoch: 5| Step: 6
Training loss: 0.24797171107196606
Validation loss: 2.353745302922512

Epoch: 5| Step: 7
Training loss: 0.17920818878092018
Validation loss: 2.3705202911969137

Epoch: 5| Step: 8
Training loss: 0.2744529669392275
Validation loss: 2.3893649390138334

Epoch: 5| Step: 9
Training loss: 0.19387680718534567
Validation loss: 2.3758115477504824

Epoch: 5| Step: 10
Training loss: 0.20897629089406272
Validation loss: 2.3431336295876086

Epoch: 480| Step: 0
Training loss: 0.15165101789563018
Validation loss: 2.3817193272441166

Epoch: 5| Step: 1
Training loss: 0.07236701065111054
Validation loss: 2.3898257011079553

Epoch: 5| Step: 2
Training loss: 0.10230936025906444
Validation loss: 2.353208149812505

Epoch: 5| Step: 3
Training loss: 0.23788480140811485
Validation loss: 2.3849505940769764

Epoch: 5| Step: 4
Training loss: 0.16455768038721943
Validation loss: 2.3882264918626244

Epoch: 5| Step: 5
Training loss: 0.2502086632864304
Validation loss: 2.4267153509603014

Epoch: 5| Step: 6
Training loss: 0.21487640652853632
Validation loss: 2.3881594448732253

Epoch: 5| Step: 7
Training loss: 0.3256643767170616
Validation loss: 2.3777211979742754

Epoch: 5| Step: 8
Training loss: 0.22825344238787718
Validation loss: 2.364674062606831

Epoch: 5| Step: 9
Training loss: 0.10490098650162073
Validation loss: 2.3820339470163594

Epoch: 5| Step: 10
Training loss: 0.3172185854407342
Validation loss: 2.375071351253805

Epoch: 481| Step: 0
Training loss: 0.1314923861075268
Validation loss: 2.369426736428605

Epoch: 5| Step: 1
Training loss: 0.25326807076054997
Validation loss: 2.3740692333356117

Epoch: 5| Step: 2
Training loss: 0.26631631367890773
Validation loss: 2.4023672675485552

Epoch: 5| Step: 3
Training loss: 0.19716462297326282
Validation loss: 2.4103421170670036

Epoch: 5| Step: 4
Training loss: 0.2677989939173958
Validation loss: 2.4144252551407104

Epoch: 5| Step: 5
Training loss: 0.18752783330326273
Validation loss: 2.4143903630257135

Epoch: 5| Step: 6
Training loss: 0.17785070615579446
Validation loss: 2.4075233777521796

Epoch: 5| Step: 7
Training loss: 0.1199199949732233
Validation loss: 2.405480810438372

Epoch: 5| Step: 8
Training loss: 0.1392776328022201
Validation loss: 2.3636140447176386

Epoch: 5| Step: 9
Training loss: 0.31948286870091164
Validation loss: 2.3489467228661027

Epoch: 5| Step: 10
Training loss: 0.1438693794789889
Validation loss: 2.3811273903222836

Epoch: 482| Step: 0
Training loss: 0.22189641432781146
Validation loss: 2.3495722792064937

Epoch: 5| Step: 1
Training loss: 0.1023642639538054
Validation loss: 2.3513745662188223

Epoch: 5| Step: 2
Training loss: 0.1916324874388091
Validation loss: 2.37701129484043

Epoch: 5| Step: 3
Training loss: 0.2754494218758599
Validation loss: 2.374982980603482

Epoch: 5| Step: 4
Training loss: 0.15362082024545884
Validation loss: 2.3767552514659083

Epoch: 5| Step: 5
Training loss: 0.2749389434355116
Validation loss: 2.372673001097318

Epoch: 5| Step: 6
Training loss: 0.17794634157998557
Validation loss: 2.34616032853492

Epoch: 5| Step: 7
Training loss: 0.24811839026432214
Validation loss: 2.3686855242125944

Epoch: 5| Step: 8
Training loss: 0.1905767704189244
Validation loss: 2.3558355429591717

Epoch: 5| Step: 9
Training loss: 0.07724589819226306
Validation loss: 2.3425732705572226

Epoch: 5| Step: 10
Training loss: 0.24257717009523816
Validation loss: 2.3688948398228726

Epoch: 483| Step: 0
Training loss: 0.1827394922493225
Validation loss: 2.341515773026033

Epoch: 5| Step: 1
Training loss: 0.21917300537561946
Validation loss: 2.32851560963037

Epoch: 5| Step: 2
Training loss: 0.28627734390990217
Validation loss: 2.3286710314778007

Epoch: 5| Step: 3
Training loss: 0.09579801234638925
Validation loss: 2.3620493240176743

Epoch: 5| Step: 4
Training loss: 0.321223104367811
Validation loss: 2.3762054919093845

Epoch: 5| Step: 5
Training loss: 0.280978535401678
Validation loss: 2.3775019072728187

Epoch: 5| Step: 6
Training loss: 0.1922920322690266
Validation loss: 2.3520566817395996

Epoch: 5| Step: 7
Training loss: 0.1742461942003305
Validation loss: 2.3435180319567395

Epoch: 5| Step: 8
Training loss: 0.21676328759729802
Validation loss: 2.3600851645979444

Epoch: 5| Step: 9
Training loss: 0.3063282195258682
Validation loss: 2.334040067439654

Epoch: 5| Step: 10
Training loss: 0.17300065932534106
Validation loss: 2.3406456781012235

Epoch: 484| Step: 0
Training loss: 0.2780430265772867
Validation loss: 2.3457573747483216

Epoch: 5| Step: 1
Training loss: 0.23691827215242667
Validation loss: 2.34848409775452

Epoch: 5| Step: 2
Training loss: 0.36794547718097137
Validation loss: 2.3668049331559087

Epoch: 5| Step: 3
Training loss: 0.2508300472331534
Validation loss: 2.3252069564856965

Epoch: 5| Step: 4
Training loss: 0.18977820634654713
Validation loss: 2.365242645023495

Epoch: 5| Step: 5
Training loss: 0.24994947250691715
Validation loss: 2.397967716731801

Epoch: 5| Step: 6
Training loss: 0.24185272890510767
Validation loss: 2.418326333784681

Epoch: 5| Step: 7
Training loss: 0.27176859955011595
Validation loss: 2.4411428474339343

Epoch: 5| Step: 8
Training loss: 0.19246861437287827
Validation loss: 2.410125592352662

Epoch: 5| Step: 9
Training loss: 0.24968647668984495
Validation loss: 2.437125333646619

Epoch: 5| Step: 10
Training loss: 0.20079367929423472
Validation loss: 2.387994108787365

Epoch: 485| Step: 0
Training loss: 0.20936556837559794
Validation loss: 2.4075084283386214

Epoch: 5| Step: 1
Training loss: 0.13563524465718704
Validation loss: 2.385456699784666

Epoch: 5| Step: 2
Training loss: 0.3300918485959953
Validation loss: 2.3566701382219564

Epoch: 5| Step: 3
Training loss: 0.32055245692362194
Validation loss: 2.356414399937581

Epoch: 5| Step: 4
Training loss: 0.20340678037292095
Validation loss: 2.3562445248297337

Epoch: 5| Step: 5
Training loss: 0.19361781179360316
Validation loss: 2.396929677227921

Epoch: 5| Step: 6
Training loss: 0.2820529733887921
Validation loss: 2.3570867170504237

Epoch: 5| Step: 7
Training loss: 0.20627686874621312
Validation loss: 2.393434495486642

Epoch: 5| Step: 8
Training loss: 0.29791161604025757
Validation loss: 2.368647043080151

Epoch: 5| Step: 9
Training loss: 0.19868093712195353
Validation loss: 2.400777639472931

Epoch: 5| Step: 10
Training loss: 0.2279389269213811
Validation loss: 2.4444209713273395

Epoch: 486| Step: 0
Training loss: 0.2512358576556886
Validation loss: 2.4254829469433234

Epoch: 5| Step: 1
Training loss: 0.17506035164288064
Validation loss: 2.4111352686097676

Epoch: 5| Step: 2
Training loss: 0.14479155554755724
Validation loss: 2.4113039431391505

Epoch: 5| Step: 3
Training loss: 0.18357854130835963
Validation loss: 2.3866192471838286

Epoch: 5| Step: 4
Training loss: 0.2578661024839531
Validation loss: 2.3659639578398286

Epoch: 5| Step: 5
Training loss: 0.2246493511284186
Validation loss: 2.3656487261373624

Epoch: 5| Step: 6
Training loss: 0.20024705543805807
Validation loss: 2.379023388233756

Epoch: 5| Step: 7
Training loss: 0.25074687793514755
Validation loss: 2.3450907637025162

Epoch: 5| Step: 8
Training loss: 0.15076062278779154
Validation loss: 2.338636483591278

Epoch: 5| Step: 9
Training loss: 0.2639809245448248
Validation loss: 2.3564037478798627

Epoch: 5| Step: 10
Training loss: 0.27561688428508685
Validation loss: 2.312741509497389

Epoch: 487| Step: 0
Training loss: 0.15813572943325466
Validation loss: 2.37712936064178

Epoch: 5| Step: 1
Training loss: 0.2752324725606951
Validation loss: 2.354833724198828

Epoch: 5| Step: 2
Training loss: 0.1592385469918927
Validation loss: 2.3474789986039073

Epoch: 5| Step: 3
Training loss: 0.15142483382640246
Validation loss: 2.3314325249036267

Epoch: 5| Step: 4
Training loss: 0.25154924180059296
Validation loss: 2.34450740758416

Epoch: 5| Step: 5
Training loss: 0.18801077175605288
Validation loss: 2.343034272104406

Epoch: 5| Step: 6
Training loss: 0.1749263851270945
Validation loss: 2.3551133486870985

Epoch: 5| Step: 7
Training loss: 0.18336751878334745
Validation loss: 2.338254436864365

Epoch: 5| Step: 8
Training loss: 0.258429987128215
Validation loss: 2.341085770164222

Epoch: 5| Step: 9
Training loss: 0.19093053439806426
Validation loss: 2.3325255789654085

Epoch: 5| Step: 10
Training loss: 0.19642194358988957
Validation loss: 2.322381647241793

Epoch: 488| Step: 0
Training loss: 0.14130514624449414
Validation loss: 2.3610749846543206

Epoch: 5| Step: 1
Training loss: 0.22854409488795188
Validation loss: 2.403172668665292

Epoch: 5| Step: 2
Training loss: 0.14904135924999806
Validation loss: 2.3684441172672437

Epoch: 5| Step: 3
Training loss: 0.2676866408785639
Validation loss: 2.375923981950117

Epoch: 5| Step: 4
Training loss: 0.19376947282025664
Validation loss: 2.322466791588586

Epoch: 5| Step: 5
Training loss: 0.215460438405506
Validation loss: 2.363132975425395

Epoch: 5| Step: 6
Training loss: 0.19768279881153292
Validation loss: 2.35288278619534

Epoch: 5| Step: 7
Training loss: 0.2236072242456922
Validation loss: 2.3303208567798244

Epoch: 5| Step: 8
Training loss: 0.26008990131919124
Validation loss: 2.3467941078419687

Epoch: 5| Step: 9
Training loss: 0.20659478982638632
Validation loss: 2.355186111721186

Epoch: 5| Step: 10
Training loss: 0.08702876526626063
Validation loss: 2.361996878163101

Epoch: 489| Step: 0
Training loss: 0.14380084232286228
Validation loss: 2.3414153187685454

Epoch: 5| Step: 1
Training loss: 0.3214246817289119
Validation loss: 2.3318906761511013

Epoch: 5| Step: 2
Training loss: 0.218709643932945
Validation loss: 2.364224421883732

Epoch: 5| Step: 3
Training loss: 0.16664747162393656
Validation loss: 2.3611938348265453

Epoch: 5| Step: 4
Training loss: 0.17990234219281165
Validation loss: 2.380328372863298

Epoch: 5| Step: 5
Training loss: 0.19693020356988747
Validation loss: 2.392268418706607

Epoch: 5| Step: 6
Training loss: 0.14204078823791327
Validation loss: 2.3868112961193964

Epoch: 5| Step: 7
Training loss: 0.19113469810343148
Validation loss: 2.3935193176249507

Epoch: 5| Step: 8
Training loss: 0.280579164283316
Validation loss: 2.3852370820074698

Epoch: 5| Step: 9
Training loss: 0.2508984158340865
Validation loss: 2.3827230295819772

Epoch: 5| Step: 10
Training loss: 0.12151682687042162
Validation loss: 2.3659146606697465

Epoch: 490| Step: 0
Training loss: 0.26165309481037957
Validation loss: 2.3522397961066117

Epoch: 5| Step: 1
Training loss: 0.17070604121076322
Validation loss: 2.3436128837374013

Epoch: 5| Step: 2
Training loss: 0.1799349428699422
Validation loss: 2.3163579257086515

Epoch: 5| Step: 3
Training loss: 0.16783678060297746
Validation loss: 2.2906033279805476

Epoch: 5| Step: 4
Training loss: 0.1890546698564529
Validation loss: 2.311952372558757

Epoch: 5| Step: 5
Training loss: 0.11716404521189348
Validation loss: 2.3277277795148454

Epoch: 5| Step: 6
Training loss: 0.23337444676914443
Validation loss: 2.346177303510037

Epoch: 5| Step: 7
Training loss: 0.21122441382334142
Validation loss: 2.334080652973232

Epoch: 5| Step: 8
Training loss: 0.3814000131612054
Validation loss: 2.3801357663650586

Epoch: 5| Step: 9
Training loss: 0.24925581617561746
Validation loss: 2.423096157404661

Epoch: 5| Step: 10
Training loss: 0.13338946093046533
Validation loss: 2.373764192593536

Epoch: 491| Step: 0
Training loss: 0.16345774361091334
Validation loss: 2.3887178579275687

Epoch: 5| Step: 1
Training loss: 0.2116253991914692
Validation loss: 2.3971474355854063

Epoch: 5| Step: 2
Training loss: 0.1749869733457926
Validation loss: 2.367982605017669

Epoch: 5| Step: 3
Training loss: 0.3306464319547988
Validation loss: 2.3775557835084746

Epoch: 5| Step: 4
Training loss: 0.2502026034982037
Validation loss: 2.3565532323937233

Epoch: 5| Step: 5
Training loss: 0.177705374646871
Validation loss: 2.322583230395599

Epoch: 5| Step: 6
Training loss: 0.2696380818155279
Validation loss: 2.3068036819589453

Epoch: 5| Step: 7
Training loss: 0.27501540628540155
Validation loss: 2.3109296057788278

Epoch: 5| Step: 8
Training loss: 0.16832002790687708
Validation loss: 2.344121240453533

Epoch: 5| Step: 9
Training loss: 0.19525486095607555
Validation loss: 2.3525890829155185

Epoch: 5| Step: 10
Training loss: 0.21697707891871493
Validation loss: 2.3569019386992114

Epoch: 492| Step: 0
Training loss: 0.2082825578961871
Validation loss: 2.3740069888378588

Epoch: 5| Step: 1
Training loss: 0.22238225977360074
Validation loss: 2.3909591268655688

Epoch: 5| Step: 2
Training loss: 0.2648474870266197
Validation loss: 2.3966847159397626

Epoch: 5| Step: 3
Training loss: 0.29187210828994625
Validation loss: 2.3888208373706954

Epoch: 5| Step: 4
Training loss: 0.19950707458677508
Validation loss: 2.3970570189699694

Epoch: 5| Step: 5
Training loss: 0.22692615821555834
Validation loss: 2.346106460175877

Epoch: 5| Step: 6
Training loss: 0.2845003737236009
Validation loss: 2.357104469297118

Epoch: 5| Step: 7
Training loss: 0.14865117003554257
Validation loss: 2.3235749961237118

Epoch: 5| Step: 8
Training loss: 0.1542166368480792
Validation loss: 2.3053764196533937

Epoch: 5| Step: 9
Training loss: 0.20808257966566449
Validation loss: 2.29981797019868

Epoch: 5| Step: 10
Training loss: 0.18525070847248404
Validation loss: 2.2776332880761534

Epoch: 493| Step: 0
Training loss: 0.22585677530381887
Validation loss: 2.2672263862567394

Epoch: 5| Step: 1
Training loss: 0.27024172699834376
Validation loss: 2.313456351720809

Epoch: 5| Step: 2
Training loss: 0.18534778152966794
Validation loss: 2.3486112516396482

Epoch: 5| Step: 3
Training loss: 0.14918089731050002
Validation loss: 2.346228002609576

Epoch: 5| Step: 4
Training loss: 0.2679099927716647
Validation loss: 2.3618681953570797

Epoch: 5| Step: 5
Training loss: 0.2708852455321005
Validation loss: 2.360928409882203

Epoch: 5| Step: 6
Training loss: 0.17999294484074074
Validation loss: 2.393891098793423

Epoch: 5| Step: 7
Training loss: 0.22132584820783807
Validation loss: 2.379895631299834

Epoch: 5| Step: 8
Training loss: 0.1513229859325847
Validation loss: 2.4157607198356605

Epoch: 5| Step: 9
Training loss: 0.22366290327300256
Validation loss: 2.402545731113212

Epoch: 5| Step: 10
Training loss: 0.22831722352065129
Validation loss: 2.370941007442622

Epoch: 494| Step: 0
Training loss: 0.16146708408350519
Validation loss: 2.3771198766393122

Epoch: 5| Step: 1
Training loss: 0.2140337674147024
Validation loss: 2.352907539559067

Epoch: 5| Step: 2
Training loss: 0.2900331284657722
Validation loss: 2.35781322092078

Epoch: 5| Step: 3
Training loss: 0.18893531943238676
Validation loss: 2.341323931360205

Epoch: 5| Step: 4
Training loss: 0.23619857894541046
Validation loss: 2.3617941321072724

Epoch: 5| Step: 5
Training loss: 0.26577953443472524
Validation loss: 2.2962720524781135

Epoch: 5| Step: 6
Training loss: 0.18216817396726406
Validation loss: 2.331139756458252

Epoch: 5| Step: 7
Training loss: 0.2720954248103633
Validation loss: 2.35609236361527

Epoch: 5| Step: 8
Training loss: 0.23704166513945785
Validation loss: 2.3127013193404076

Epoch: 5| Step: 9
Training loss: 0.24113786803012743
Validation loss: 2.348875434259762

Epoch: 5| Step: 10
Training loss: 0.15550601383252777
Validation loss: 2.372469449279177

Epoch: 495| Step: 0
Training loss: 0.20954393183471917
Validation loss: 2.3818463111425543

Epoch: 5| Step: 1
Training loss: 0.30978749355557356
Validation loss: 2.3469818540525687

Epoch: 5| Step: 2
Training loss: 0.1635783009944927
Validation loss: 2.3375361604225824

Epoch: 5| Step: 3
Training loss: 0.2611023633347729
Validation loss: 2.3362355505948127

Epoch: 5| Step: 4
Training loss: 0.1609640624986225
Validation loss: 2.3442433191503285

Epoch: 5| Step: 5
Training loss: 0.1856114927508723
Validation loss: 2.3386288956016985

Epoch: 5| Step: 6
Training loss: 0.09766198141445415
Validation loss: 2.373605263023894

Epoch: 5| Step: 7
Training loss: 0.24355840305409554
Validation loss: 2.344854127872137

Epoch: 5| Step: 8
Training loss: 0.24668045345861017
Validation loss: 2.344507828022045

Epoch: 5| Step: 9
Training loss: 0.16369996432986772
Validation loss: 2.342381455852705

Epoch: 5| Step: 10
Training loss: 0.2007497321153186
Validation loss: 2.3334988996403823

Epoch: 496| Step: 0
Training loss: 0.3391646033692144
Validation loss: 2.3542588626349197

Epoch: 5| Step: 1
Training loss: 0.23262267694794325
Validation loss: 2.3460703990012237

Epoch: 5| Step: 2
Training loss: 0.20612644916577894
Validation loss: 2.3896359006001853

Epoch: 5| Step: 3
Training loss: 0.2467203941797767
Validation loss: 2.369343077833701

Epoch: 5| Step: 4
Training loss: 0.19042134388960463
Validation loss: 2.390259477463476

Epoch: 5| Step: 5
Training loss: 0.13437680808780408
Validation loss: 2.393686620780939

Epoch: 5| Step: 6
Training loss: 0.09990108541402802
Validation loss: 2.3822185242034792

Epoch: 5| Step: 7
Training loss: 0.1605574363056284
Validation loss: 2.3856394657847333

Epoch: 5| Step: 8
Training loss: 0.1648554824884414
Validation loss: 2.378008276292717

Epoch: 5| Step: 9
Training loss: 0.19326115049613077
Validation loss: 2.3805281220822603

Epoch: 5| Step: 10
Training loss: 0.18374401395804657
Validation loss: 2.3822965114712886

Epoch: 497| Step: 0
Training loss: 0.11912601412624663
Validation loss: 2.3770152093048016

Epoch: 5| Step: 1
Training loss: 0.1607754993800512
Validation loss: 2.3793841210596423

Epoch: 5| Step: 2
Training loss: 0.2276313823661965
Validation loss: 2.3762270775034

Epoch: 5| Step: 3
Training loss: 0.25112548447178185
Validation loss: 2.3933998101615743

Epoch: 5| Step: 4
Training loss: 0.2205125272667477
Validation loss: 2.4000769620778906

Epoch: 5| Step: 5
Training loss: 0.17763702115729932
Validation loss: 2.352243099506768

Epoch: 5| Step: 6
Training loss: 0.26425699373444045
Validation loss: 2.3554818453290647

Epoch: 5| Step: 7
Training loss: 0.14973406712419682
Validation loss: 2.3674060172817915

Epoch: 5| Step: 8
Training loss: 0.1676668181381559
Validation loss: 2.3684191409389777

Epoch: 5| Step: 9
Training loss: 0.14303631514902185
Validation loss: 2.339442796558522

Epoch: 5| Step: 10
Training loss: 0.24668289236854657
Validation loss: 2.352982632666468

Epoch: 498| Step: 0
Training loss: 0.13338279297271677
Validation loss: 2.3715443959763407

Epoch: 5| Step: 1
Training loss: 0.15291498145163182
Validation loss: 2.3936493362701277

Epoch: 5| Step: 2
Training loss: 0.2793499956099573
Validation loss: 2.3665472969664236

Epoch: 5| Step: 3
Training loss: 0.241306347838463
Validation loss: 2.3708382721417744

Epoch: 5| Step: 4
Training loss: 0.30035739610721907
Validation loss: 2.3609903411653765

Epoch: 5| Step: 5
Training loss: 0.234272616594334
Validation loss: 2.368904344850344

Epoch: 5| Step: 6
Training loss: 0.10653052287918056
Validation loss: 2.3627778535061337

Epoch: 5| Step: 7
Training loss: 0.15221005466492782
Validation loss: 2.355746810386426

Epoch: 5| Step: 8
Training loss: 0.13563240881429614
Validation loss: 2.3665696157423963

Epoch: 5| Step: 9
Training loss: 0.2396430981079321
Validation loss: 2.360246559960759

Epoch: 5| Step: 10
Training loss: 0.15420321748657112
Validation loss: 2.420579296000105

Epoch: 499| Step: 0
Training loss: 0.22308292832413212
Validation loss: 2.3927347052549757

Epoch: 5| Step: 1
Training loss: 0.30541642123746354
Validation loss: 2.388446773945279

Epoch: 5| Step: 2
Training loss: 0.12205459493538226
Validation loss: 2.405305178055233

Epoch: 5| Step: 3
Training loss: 0.13777036853267513
Validation loss: 2.4249079782075995

Epoch: 5| Step: 4
Training loss: 0.18038573605804561
Validation loss: 2.4301241167930625

Epoch: 5| Step: 5
Training loss: 0.22738563702298112
Validation loss: 2.4463837453951505

Epoch: 5| Step: 6
Training loss: 0.19742255059425926
Validation loss: 2.435014580333874

Epoch: 5| Step: 7
Training loss: 0.1435622323577173
Validation loss: 2.4256341663814593

Epoch: 5| Step: 8
Training loss: 0.1351502017503567
Validation loss: 2.4299583467426036

Epoch: 5| Step: 9
Training loss: 0.18336285620734175
Validation loss: 2.4230243582076554

Epoch: 5| Step: 10
Training loss: 0.15361803148106973
Validation loss: 2.425010342666294

Epoch: 500| Step: 0
Training loss: 0.13249788465925602
Validation loss: 2.4067603077415014

Epoch: 5| Step: 1
Training loss: 0.23491278778910674
Validation loss: 2.417848960489171

Epoch: 5| Step: 2
Training loss: 0.10042360780727647
Validation loss: 2.380575613822956

Epoch: 5| Step: 3
Training loss: 0.1779526742769871
Validation loss: 2.3776158260644573

Epoch: 5| Step: 4
Training loss: 0.19547568180103395
Validation loss: 2.355864577275469

Epoch: 5| Step: 5
Training loss: 0.23419498046877932
Validation loss: 2.3760857483140576

Epoch: 5| Step: 6
Training loss: 0.21275434594304596
Validation loss: 2.379514622787252

Epoch: 5| Step: 7
Training loss: 0.193406590563594
Validation loss: 2.354136718797637

Epoch: 5| Step: 8
Training loss: 0.18872066364559337
Validation loss: 2.3865116921699263

Epoch: 5| Step: 9
Training loss: 0.31236880647992377
Validation loss: 2.3864823850965524

Epoch: 5| Step: 10
Training loss: 0.11094809803911918
Validation loss: 2.4161967802676045

Epoch: 501| Step: 0
Training loss: 0.1261438102334185
Validation loss: 2.3791749136625047

Epoch: 5| Step: 1
Training loss: 0.19759575441988728
Validation loss: 2.420777033407685

Epoch: 5| Step: 2
Training loss: 0.2009788994982261
Validation loss: 2.420115517357832

Epoch: 5| Step: 3
Training loss: 0.16606972317856425
Validation loss: 2.421498716446446

Epoch: 5| Step: 4
Training loss: 0.2638833222443449
Validation loss: 2.400440248492944

Epoch: 5| Step: 5
Training loss: 0.23649786536078013
Validation loss: 2.3817524322294576

Epoch: 5| Step: 6
Training loss: 0.1491166252161204
Validation loss: 2.362101356828116

Epoch: 5| Step: 7
Training loss: 0.2219129083378798
Validation loss: 2.3747553621124764

Epoch: 5| Step: 8
Training loss: 0.1297214839829151
Validation loss: 2.3523189107750033

Epoch: 5| Step: 9
Training loss: 0.14970024601141146
Validation loss: 2.3536556512175633

Epoch: 5| Step: 10
Training loss: 0.25526097624060423
Validation loss: 2.354366698729536

Epoch: 502| Step: 0
Training loss: 0.1771830086584558
Validation loss: 2.347413044633578

Epoch: 5| Step: 1
Training loss: 0.2338805227713274
Validation loss: 2.346829909378717

Epoch: 5| Step: 2
Training loss: 0.15572993632884444
Validation loss: 2.387134862470226

Epoch: 5| Step: 3
Training loss: 0.2278661219227027
Validation loss: 2.340890323599636

Epoch: 5| Step: 4
Training loss: 0.16549288973451978
Validation loss: 2.389284832113762

Epoch: 5| Step: 5
Training loss: 0.2064640805348793
Validation loss: 2.3875333411189765

Epoch: 5| Step: 6
Training loss: 0.13801721727084762
Validation loss: 2.363780888151792

Epoch: 5| Step: 7
Training loss: 0.21061057788475085
Validation loss: 2.344543119932604

Epoch: 5| Step: 8
Training loss: 0.12037885279099865
Validation loss: 2.353264465805324

Epoch: 5| Step: 9
Training loss: 0.15341126726594378
Validation loss: 2.3158919604562005

Epoch: 5| Step: 10
Training loss: 0.2164603964343499
Validation loss: 2.321861768832871

Epoch: 503| Step: 0
Training loss: 0.17266018828478918
Validation loss: 2.3173818069044505

Epoch: 5| Step: 1
Training loss: 0.1817639762674442
Validation loss: 2.316127409828599

Epoch: 5| Step: 2
Training loss: 0.10355027986238394
Validation loss: 2.3395091968472173

Epoch: 5| Step: 3
Training loss: 0.30055692903317865
Validation loss: 2.3139610802121293

Epoch: 5| Step: 4
Training loss: 0.1562331369360317
Validation loss: 2.311123246068914

Epoch: 5| Step: 5
Training loss: 0.19896084790529794
Validation loss: 2.3161533457467955

Epoch: 5| Step: 6
Training loss: 0.12219122429754872
Validation loss: 2.3236440771068034

Epoch: 5| Step: 7
Training loss: 0.15353597064518637
Validation loss: 2.3593625695359455

Epoch: 5| Step: 8
Training loss: 0.14390004065927575
Validation loss: 2.383064474295275

Epoch: 5| Step: 9
Training loss: 0.21866678460272315
Validation loss: 2.363067059127365

Epoch: 5| Step: 10
Training loss: 0.2365602346536068
Validation loss: 2.3915662012576346

Epoch: 504| Step: 0
Training loss: 0.13704187492275718
Validation loss: 2.36674616746713

Epoch: 5| Step: 1
Training loss: 0.09157845707982698
Validation loss: 2.3591608467641265

Epoch: 5| Step: 2
Training loss: 0.30632763579216915
Validation loss: 2.3521885475802633

Epoch: 5| Step: 3
Training loss: 0.07993130191551781
Validation loss: 2.3453472626028127

Epoch: 5| Step: 4
Training loss: 0.23107985926129573
Validation loss: 2.3735781732964965

Epoch: 5| Step: 5
Training loss: 0.11389095555620062
Validation loss: 2.3441664743413724

Epoch: 5| Step: 6
Training loss: 0.24681196162430022
Validation loss: 2.3377450881296804

Epoch: 5| Step: 7
Training loss: 0.1960982158805868
Validation loss: 2.362693777198299

Epoch: 5| Step: 8
Training loss: 0.19494962360967505
Validation loss: 2.3605280536475926

Epoch: 5| Step: 9
Training loss: 0.1069239956105999
Validation loss: 2.3509055733259543

Epoch: 5| Step: 10
Training loss: 0.07789623622904021
Validation loss: 2.3699791869343487

Epoch: 505| Step: 0
Training loss: 0.17389366435962084
Validation loss: 2.401895222185019

Epoch: 5| Step: 1
Training loss: 0.2984508052076923
Validation loss: 2.363898270516893

Epoch: 5| Step: 2
Training loss: 0.21018902122498345
Validation loss: 2.442128444510791

Epoch: 5| Step: 3
Training loss: 0.11567819924426755
Validation loss: 2.383360283777627

Epoch: 5| Step: 4
Training loss: 0.12429375363452197
Validation loss: 2.4314102445236236

Epoch: 5| Step: 5
Training loss: 0.23916438867290465
Validation loss: 2.410261245923953

Epoch: 5| Step: 6
Training loss: 0.17923858792196765
Validation loss: 2.4169967399082792

Epoch: 5| Step: 7
Training loss: 0.14643735130854443
Validation loss: 2.4233109762510034

Epoch: 5| Step: 8
Training loss: 0.1730932496492861
Validation loss: 2.3977916548488487

Epoch: 5| Step: 9
Training loss: 0.1049617040852477
Validation loss: 2.4354126587978646

Epoch: 5| Step: 10
Training loss: 0.09639108332962346
Validation loss: 2.4060175972170743

Epoch: 506| Step: 0
Training loss: 0.17840486383358986
Validation loss: 2.415146351253584

Epoch: 5| Step: 1
Training loss: 0.25929313367332285
Validation loss: 2.4081545897745142

Epoch: 5| Step: 2
Training loss: 0.22593102750569116
Validation loss: 2.395455810492921

Epoch: 5| Step: 3
Training loss: 0.09895545762886318
Validation loss: 2.373853200427473

Epoch: 5| Step: 4
Training loss: 0.10287718202801827
Validation loss: 2.3999263376122633

Epoch: 5| Step: 5
Training loss: 0.2081894954206704
Validation loss: 2.402292539469419

Epoch: 5| Step: 6
Training loss: 0.1433219970080117
Validation loss: 2.3808825943793868

Epoch: 5| Step: 7
Training loss: 0.16769635491410376
Validation loss: 2.3723176090249405

Epoch: 5| Step: 8
Training loss: 0.14558439351689162
Validation loss: 2.3707406126564683

Epoch: 5| Step: 9
Training loss: 0.14602764133261512
Validation loss: 2.3802670632035565

Epoch: 5| Step: 10
Training loss: 0.15521459244155364
Validation loss: 2.3752415323198806

Epoch: 507| Step: 0
Training loss: 0.2605966311733624
Validation loss: 2.3749855609923354

Epoch: 5| Step: 1
Training loss: 0.12094431162411963
Validation loss: 2.3909534665952688

Epoch: 5| Step: 2
Training loss: 0.15688630123200173
Validation loss: 2.377324578820216

Epoch: 5| Step: 3
Training loss: 0.23534029225316772
Validation loss: 2.3992430988867524

Epoch: 5| Step: 4
Training loss: 0.15164440979673524
Validation loss: 2.366554579867338

Epoch: 5| Step: 5
Training loss: 0.14629528557002505
Validation loss: 2.358510512662152

Epoch: 5| Step: 6
Training loss: 0.15047713677235483
Validation loss: 2.382378726815839

Epoch: 5| Step: 7
Training loss: 0.20790309687966613
Validation loss: 2.3989579156987606

Epoch: 5| Step: 8
Training loss: 0.1928072956656463
Validation loss: 2.4397869230668485

Epoch: 5| Step: 9
Training loss: 0.17584975814961334
Validation loss: 2.391553089122917

Epoch: 5| Step: 10
Training loss: 0.08596511689676285
Validation loss: 2.4040315168614566

Epoch: 508| Step: 0
Training loss: 0.2627652298581304
Validation loss: 2.3962055646549647

Epoch: 5| Step: 1
Training loss: 0.17949012614032636
Validation loss: 2.405069169864561

Epoch: 5| Step: 2
Training loss: 0.1433901330241717
Validation loss: 2.369471032268929

Epoch: 5| Step: 3
Training loss: 0.14964534586055608
Validation loss: 2.3868783729226357

Epoch: 5| Step: 4
Training loss: 0.1931448526733699
Validation loss: 2.408042223226409

Epoch: 5| Step: 5
Training loss: 0.21095099229400666
Validation loss: 2.3765135315686625

Epoch: 5| Step: 6
Training loss: 0.14932031744854823
Validation loss: 2.4121942844054236

Epoch: 5| Step: 7
Training loss: 0.2908687861147275
Validation loss: 2.3884778880280835

Epoch: 5| Step: 8
Training loss: 0.12019735080427554
Validation loss: 2.4082042214811175

Epoch: 5| Step: 9
Training loss: 0.15007925001375075
Validation loss: 2.3830851780286655

Epoch: 5| Step: 10
Training loss: 0.0873514831929162
Validation loss: 2.3870255806235874

Epoch: 509| Step: 0
Training loss: 0.18939257175139604
Validation loss: 2.4167708019809

Epoch: 5| Step: 1
Training loss: 0.22158367749842953
Validation loss: 2.3552026395796983

Epoch: 5| Step: 2
Training loss: 0.21778612142668555
Validation loss: 2.3827261820516514

Epoch: 5| Step: 3
Training loss: 0.10336571761181716
Validation loss: 2.336782345672804

Epoch: 5| Step: 4
Training loss: 0.10691814659410197
Validation loss: 2.299245783184362

Epoch: 5| Step: 5
Training loss: 0.2275566372612535
Validation loss: 2.337936949326013

Epoch: 5| Step: 6
Training loss: 0.18131857183257727
Validation loss: 2.3654451616128807

Epoch: 5| Step: 7
Training loss: 0.15117282078567873
Validation loss: 2.3312060965987693

Epoch: 5| Step: 8
Training loss: 0.18653970417772353
Validation loss: 2.3633749221655793

Epoch: 5| Step: 9
Training loss: 0.1407002803847482
Validation loss: 2.3617728905822317

Epoch: 5| Step: 10
Training loss: 0.24879700332836657
Validation loss: 2.362447353856599

Epoch: 510| Step: 0
Training loss: 0.19340703357630873
Validation loss: 2.3439928865539343

Epoch: 5| Step: 1
Training loss: 0.23165810536756073
Validation loss: 2.3833927345775883

Epoch: 5| Step: 2
Training loss: 0.21921809386021254
Validation loss: 2.342266389260789

Epoch: 5| Step: 3
Training loss: 0.09412543799544124
Validation loss: 2.35192157387462

Epoch: 5| Step: 4
Training loss: 0.0976846176907166
Validation loss: 2.3898561246443806

Epoch: 5| Step: 5
Training loss: 0.16726517811323083
Validation loss: 2.4014818402302365

Epoch: 5| Step: 6
Training loss: 0.13786679269956018
Validation loss: 2.397613333550613

Epoch: 5| Step: 7
Training loss: 0.13952628041395693
Validation loss: 2.3739677262672605

Epoch: 5| Step: 8
Training loss: 0.13417372433489744
Validation loss: 2.373850974651327

Epoch: 5| Step: 9
Training loss: 0.19922195693782066
Validation loss: 2.376205065212297

Epoch: 5| Step: 10
Training loss: 0.252616806631655
Validation loss: 2.3515374364891217

Epoch: 511| Step: 0
Training loss: 0.12996821356477165
Validation loss: 2.3460988843264756

Epoch: 5| Step: 1
Training loss: 0.20728583247794133
Validation loss: 2.346364681154827

Epoch: 5| Step: 2
Training loss: 0.16835937433618958
Validation loss: 2.3757939827645016

Epoch: 5| Step: 3
Training loss: 0.1098010883196044
Validation loss: 2.3664919654699035

Epoch: 5| Step: 4
Training loss: 0.1458696244985106
Validation loss: 2.3947081553789276

Epoch: 5| Step: 5
Training loss: 0.2906227403983597
Validation loss: 2.385917597722329

Epoch: 5| Step: 6
Training loss: 0.2184599758967783
Validation loss: 2.4311764763004446

Epoch: 5| Step: 7
Training loss: 0.2535147068847583
Validation loss: 2.439859340657407

Epoch: 5| Step: 8
Training loss: 0.15214877000020707
Validation loss: 2.419632057318366

Epoch: 5| Step: 9
Training loss: 0.1739594895406283
Validation loss: 2.4210999041433046

Epoch: 5| Step: 10
Training loss: 0.09291630836632987
Validation loss: 2.4097190486054125

Epoch: 512| Step: 0
Training loss: 0.19449871281367076
Validation loss: 2.3867920435869587

Epoch: 5| Step: 1
Training loss: 0.1721978514860445
Validation loss: 2.408755890433194

Epoch: 5| Step: 2
Training loss: 0.188549699577076
Validation loss: 2.3463473852156405

Epoch: 5| Step: 3
Training loss: 0.23761802363401438
Validation loss: 2.3280799004100494

Epoch: 5| Step: 4
Training loss: 0.12137781557069371
Validation loss: 2.285835822900203

Epoch: 5| Step: 5
Training loss: 0.13202222449022347
Validation loss: 2.2999138160990737

Epoch: 5| Step: 6
Training loss: 0.22584296112429494
Validation loss: 2.2842282408075296

Epoch: 5| Step: 7
Training loss: 0.17224291416031715
Validation loss: 2.331400874933712

Epoch: 5| Step: 8
Training loss: 0.25095840863427227
Validation loss: 2.311500360416751

Epoch: 5| Step: 9
Training loss: 0.17511458604945102
Validation loss: 2.3271623482049852

Epoch: 5| Step: 10
Training loss: 0.290298782328405
Validation loss: 2.3684274599164596

Epoch: 513| Step: 0
Training loss: 0.11370709551994475
Validation loss: 2.3901449256707554

Epoch: 5| Step: 1
Training loss: 0.2553930765467828
Validation loss: 2.4423833593662057

Epoch: 5| Step: 2
Training loss: 0.24695070108046555
Validation loss: 2.430837068520664

Epoch: 5| Step: 3
Training loss: 0.21090514323410048
Validation loss: 2.410477105439079

Epoch: 5| Step: 4
Training loss: 0.15224848727632
Validation loss: 2.392817906545752

Epoch: 5| Step: 5
Training loss: 0.2753553164958553
Validation loss: 2.387228421789887

Epoch: 5| Step: 6
Training loss: 0.20715938057967442
Validation loss: 2.3362693011836413

Epoch: 5| Step: 7
Training loss: 0.18336878852751518
Validation loss: 2.3444060044026616

Epoch: 5| Step: 8
Training loss: 0.17446405905229012
Validation loss: 2.354536953211971

Epoch: 5| Step: 9
Training loss: 0.16643578710473222
Validation loss: 2.35634218890071

Epoch: 5| Step: 10
Training loss: 0.1972546716047415
Validation loss: 2.34026708085501

Epoch: 514| Step: 0
Training loss: 0.194150423996163
Validation loss: 2.3221285514167618

Epoch: 5| Step: 1
Training loss: 0.12415085652549844
Validation loss: 2.411351414546301

Epoch: 5| Step: 2
Training loss: 0.16384471902955441
Validation loss: 2.4139160850974046

Epoch: 5| Step: 3
Training loss: 0.2141292916812591
Validation loss: 2.377114266457658

Epoch: 5| Step: 4
Training loss: 0.28547385569800027
Validation loss: 2.389441591699706

Epoch: 5| Step: 5
Training loss: 0.2354973938751184
Validation loss: 2.3681996476028884

Epoch: 5| Step: 6
Training loss: 0.28120379598234074
Validation loss: 2.409182863876711

Epoch: 5| Step: 7
Training loss: 0.13357924973838384
Validation loss: 2.3205148843352235

Epoch: 5| Step: 8
Training loss: 0.2140525380482668
Validation loss: 2.356502213662347

Epoch: 5| Step: 9
Training loss: 0.1823944324379336
Validation loss: 2.323826810804955

Epoch: 5| Step: 10
Training loss: 0.2523903859744938
Validation loss: 2.3449001823444218

Epoch: 515| Step: 0
Training loss: 0.19242929003697196
Validation loss: 2.374246605166969

Epoch: 5| Step: 1
Training loss: 0.17898280409044875
Validation loss: 2.3369950562508803

Epoch: 5| Step: 2
Training loss: 0.11441020909596362
Validation loss: 2.3189470014466504

Epoch: 5| Step: 3
Training loss: 0.2293192272566723
Validation loss: 2.3079698645924664

Epoch: 5| Step: 4
Training loss: 0.1628944163258581
Validation loss: 2.258913335760777

Epoch: 5| Step: 5
Training loss: 0.2325810760731119
Validation loss: 2.3062735479569807

Epoch: 5| Step: 6
Training loss: 0.16135928104841538
Validation loss: 2.3222181451828456

Epoch: 5| Step: 7
Training loss: 0.2072364042571469
Validation loss: 2.344821533764975

Epoch: 5| Step: 8
Training loss: 0.2876155698731533
Validation loss: 2.3502010074910875

Epoch: 5| Step: 9
Training loss: 0.19381049542280732
Validation loss: 2.374198429652772

Epoch: 5| Step: 10
Training loss: 0.1746111549696348
Validation loss: 2.366655170003145

Epoch: 516| Step: 0
Training loss: 0.1061194225804126
Validation loss: 2.3340948436295323

Epoch: 5| Step: 1
Training loss: 0.18357244327359085
Validation loss: 2.350691928313754

Epoch: 5| Step: 2
Training loss: 0.1559263871672821
Validation loss: 2.3316291710766466

Epoch: 5| Step: 3
Training loss: 0.2215090443565422
Validation loss: 2.3053870155775344

Epoch: 5| Step: 4
Training loss: 0.24263628018378036
Validation loss: 2.312689851829275

Epoch: 5| Step: 5
Training loss: 0.2729428995182307
Validation loss: 2.340812518026976

Epoch: 5| Step: 6
Training loss: 0.17021374464090536
Validation loss: 2.3388781079542094

Epoch: 5| Step: 7
Training loss: 0.1413328976349855
Validation loss: 2.37656362341976

Epoch: 5| Step: 8
Training loss: 0.12585224256900682
Validation loss: 2.365833713150452

Epoch: 5| Step: 9
Training loss: 0.230522068774232
Validation loss: 2.357601083210367

Epoch: 5| Step: 10
Training loss: 0.15775917304191012
Validation loss: 2.3788961302575378

Epoch: 517| Step: 0
Training loss: 0.15529909461749872
Validation loss: 2.3844372967583776

Epoch: 5| Step: 1
Training loss: 0.18480854705282956
Validation loss: 2.385929689983448

Epoch: 5| Step: 2
Training loss: 0.08928388323353875
Validation loss: 2.378041847988113

Epoch: 5| Step: 3
Training loss: 0.1729778108920025
Validation loss: 2.365364989218435

Epoch: 5| Step: 4
Training loss: 0.22781164190081038
Validation loss: 2.33662165336593

Epoch: 5| Step: 5
Training loss: 0.20093776450725606
Validation loss: 2.36088360356495

Epoch: 5| Step: 6
Training loss: 0.2531564793027097
Validation loss: 2.3670280893191724

Epoch: 5| Step: 7
Training loss: 0.20505813319536662
Validation loss: 2.3718442800607886

Epoch: 5| Step: 8
Training loss: 0.1389010040807341
Validation loss: 2.400853013742469

Epoch: 5| Step: 9
Training loss: 0.17943731803844956
Validation loss: 2.3976578202246137

Epoch: 5| Step: 10
Training loss: 0.1613826144750414
Validation loss: 2.3724887703580175

Epoch: 518| Step: 0
Training loss: 0.2646547999444205
Validation loss: 2.380971326415692

Epoch: 5| Step: 1
Training loss: 0.16394791120896804
Validation loss: 2.379535266369211

Epoch: 5| Step: 2
Training loss: 0.1374302402637237
Validation loss: 2.3840371951782244

Epoch: 5| Step: 3
Training loss: 0.18222471892476108
Validation loss: 2.3628786754862214

Epoch: 5| Step: 4
Training loss: 0.17732869475062488
Validation loss: 2.357418780040156

Epoch: 5| Step: 5
Training loss: 0.2381186868801938
Validation loss: 2.3495698782188117

Epoch: 5| Step: 6
Training loss: 0.13178430181836276
Validation loss: 2.359030543250652

Epoch: 5| Step: 7
Training loss: 0.14405555670094447
Validation loss: 2.342926880603327

Epoch: 5| Step: 8
Training loss: 0.23144970660323944
Validation loss: 2.316612053144277

Epoch: 5| Step: 9
Training loss: 0.1637435719633414
Validation loss: 2.3423723455576693

Epoch: 5| Step: 10
Training loss: 0.2041454724255662
Validation loss: 2.3363726776397726

Epoch: 519| Step: 0
Training loss: 0.2171919547797354
Validation loss: 2.2921725334737295

Epoch: 5| Step: 1
Training loss: 0.16647734108489087
Validation loss: 2.3506360867263476

Epoch: 5| Step: 2
Training loss: 0.18386048359235607
Validation loss: 2.331907299860039

Epoch: 5| Step: 3
Training loss: 0.14177824376134984
Validation loss: 2.3827667656915104

Epoch: 5| Step: 4
Training loss: 0.09202236016832478
Validation loss: 2.3372664863975183

Epoch: 5| Step: 5
Training loss: 0.12024668559257239
Validation loss: 2.359937870583674

Epoch: 5| Step: 6
Training loss: 0.21597050062708398
Validation loss: 2.3804003990605436

Epoch: 5| Step: 7
Training loss: 0.20812716216605234
Validation loss: 2.373692422959837

Epoch: 5| Step: 8
Training loss: 0.23528214376631706
Validation loss: 2.3979162320656155

Epoch: 5| Step: 9
Training loss: 0.12531697793222968
Validation loss: 2.3864701946574285

Epoch: 5| Step: 10
Training loss: 0.1344266442926394
Validation loss: 2.4086257889279117

Epoch: 520| Step: 0
Training loss: 0.10183950392342397
Validation loss: 2.4015078076226444

Epoch: 5| Step: 1
Training loss: 0.15710734947943772
Validation loss: 2.3924408194156963

Epoch: 5| Step: 2
Training loss: 0.14852038378368115
Validation loss: 2.4377724127449425

Epoch: 5| Step: 3
Training loss: 0.1457997280524835
Validation loss: 2.4086105097512425

Epoch: 5| Step: 4
Training loss: 0.26901143853337217
Validation loss: 2.3998255289830444

Epoch: 5| Step: 5
Training loss: 0.17893385403496537
Validation loss: 2.381566129428934

Epoch: 5| Step: 6
Training loss: 0.11813948903838707
Validation loss: 2.362902112783671

Epoch: 5| Step: 7
Training loss: 0.19145986234353932
Validation loss: 2.3430817360300003

Epoch: 5| Step: 8
Training loss: 0.09921467877843669
Validation loss: 2.3560848323880177

Epoch: 5| Step: 9
Training loss: 0.26257860505441255
Validation loss: 2.348067086697747

Epoch: 5| Step: 10
Training loss: 0.09719313482526869
Validation loss: 2.3713235859432547

Epoch: 521| Step: 0
Training loss: 0.19962626271932357
Validation loss: 2.3508263909183738

Epoch: 5| Step: 1
Training loss: 0.13959604894548178
Validation loss: 2.3610396798041906

Epoch: 5| Step: 2
Training loss: 0.21337668027087725
Validation loss: 2.375519527828462

Epoch: 5| Step: 3
Training loss: 0.14700012964126163
Validation loss: 2.387627792116708

Epoch: 5| Step: 4
Training loss: 0.14238870789053484
Validation loss: 2.396007217652942

Epoch: 5| Step: 5
Training loss: 0.21105266888500543
Validation loss: 2.4035966507483195

Epoch: 5| Step: 6
Training loss: 0.13875993431027897
Validation loss: 2.390373349173378

Epoch: 5| Step: 7
Training loss: 0.15393056725809803
Validation loss: 2.38007387494269

Epoch: 5| Step: 8
Training loss: 0.17688391597301334
Validation loss: 2.355729802615418

Epoch: 5| Step: 9
Training loss: 0.14844788966710548
Validation loss: 2.3778348076150273

Epoch: 5| Step: 10
Training loss: 0.15883833905358138
Validation loss: 2.356606835847391

Epoch: 522| Step: 0
Training loss: 0.14707800425848022
Validation loss: 2.336711893877881

Epoch: 5| Step: 1
Training loss: 0.20785454131201578
Validation loss: 2.354112109583811

Epoch: 5| Step: 2
Training loss: 0.12218667016028056
Validation loss: 2.3374865346128857

Epoch: 5| Step: 3
Training loss: 0.1171291921515742
Validation loss: 2.3560542790679557

Epoch: 5| Step: 4
Training loss: 0.22819326764071154
Validation loss: 2.345236831546968

Epoch: 5| Step: 5
Training loss: 0.1163549732714192
Validation loss: 2.382381340085425

Epoch: 5| Step: 6
Training loss: 0.1579530234295489
Validation loss: 2.3675501785983935

Epoch: 5| Step: 7
Training loss: 0.21592361256483933
Validation loss: 2.3890019783370984

Epoch: 5| Step: 8
Training loss: 0.11776101124307024
Validation loss: 2.3767626298261897

Epoch: 5| Step: 9
Training loss: 0.24092704653791533
Validation loss: 2.3836205414055383

Epoch: 5| Step: 10
Training loss: 0.13778095422783518
Validation loss: 2.3745856935690584

Epoch: 523| Step: 0
Training loss: 0.17322955854245023
Validation loss: 2.3241111564326147

Epoch: 5| Step: 1
Training loss: 0.21107635519556614
Validation loss: 2.3642828848360073

Epoch: 5| Step: 2
Training loss: 0.134741711913662
Validation loss: 2.3623766913210105

Epoch: 5| Step: 3
Training loss: 0.10954721550758642
Validation loss: 2.332120009330769

Epoch: 5| Step: 4
Training loss: 0.11263399356662833
Validation loss: 2.3455885241085688

Epoch: 5| Step: 5
Training loss: 0.12495295563200137
Validation loss: 2.365831361715982

Epoch: 5| Step: 6
Training loss: 0.153252136963496
Validation loss: 2.320951795022605

Epoch: 5| Step: 7
Training loss: 0.16791755428347804
Validation loss: 2.3502263906796936

Epoch: 5| Step: 8
Training loss: 0.21947286582910291
Validation loss: 2.3800794948435535

Epoch: 5| Step: 9
Training loss: 0.22769849537110218
Validation loss: 2.375407502944256

Epoch: 5| Step: 10
Training loss: 0.1338270230980007
Validation loss: 2.350375722706841

Epoch: 524| Step: 0
Training loss: 0.12201242600271565
Validation loss: 2.383853653018105

Epoch: 5| Step: 1
Training loss: 0.14583226328411805
Validation loss: 2.38325371546516

Epoch: 5| Step: 2
Training loss: 0.19549527199508612
Validation loss: 2.382174603149679

Epoch: 5| Step: 3
Training loss: 0.20429250920373734
Validation loss: 2.355325199436318

Epoch: 5| Step: 4
Training loss: 0.13070779533273483
Validation loss: 2.3795945813294432

Epoch: 5| Step: 5
Training loss: 0.15811908514849116
Validation loss: 2.3753804224381017

Epoch: 5| Step: 6
Training loss: 0.11691107732426627
Validation loss: 2.364284920647057

Epoch: 5| Step: 7
Training loss: 0.21339733297364882
Validation loss: 2.3676084197474476

Epoch: 5| Step: 8
Training loss: 0.09881781705241367
Validation loss: 2.376701332813662

Epoch: 5| Step: 9
Training loss: 0.14902368048051895
Validation loss: 2.351506300782622

Epoch: 5| Step: 10
Training loss: 0.24390980299439613
Validation loss: 2.3607086376274555

Epoch: 525| Step: 0
Training loss: 0.17485206111248666
Validation loss: 2.356180263329542

Epoch: 5| Step: 1
Training loss: 0.07910208643045104
Validation loss: 2.3563048536658604

Epoch: 5| Step: 2
Training loss: 0.07945829472653808
Validation loss: 2.370774567877409

Epoch: 5| Step: 3
Training loss: 0.1976184522351167
Validation loss: 2.361381554924254

Epoch: 5| Step: 4
Training loss: 0.11048124508422609
Validation loss: 2.3892070842217237

Epoch: 5| Step: 5
Training loss: 0.1828427680952001
Validation loss: 2.365340541261807

Epoch: 5| Step: 6
Training loss: 0.1427649097531173
Validation loss: 2.3733916047411125

Epoch: 5| Step: 7
Training loss: 0.2598839683856771
Validation loss: 2.382125236263801

Epoch: 5| Step: 8
Training loss: 0.09399636996709422
Validation loss: 2.3598721920300347

Epoch: 5| Step: 9
Training loss: 0.12198157327521869
Validation loss: 2.3308364089122584

Epoch: 5| Step: 10
Training loss: 0.08750019509855726
Validation loss: 2.356975850037719

Epoch: 526| Step: 0
Training loss: 0.07650747097573704
Validation loss: 2.322949164297656

Epoch: 5| Step: 1
Training loss: 0.10745945186551782
Validation loss: 2.345335479770441

Epoch: 5| Step: 2
Training loss: 0.22740544337435858
Validation loss: 2.334128264920282

Epoch: 5| Step: 3
Training loss: 0.1253268171631456
Validation loss: 2.352682574390529

Epoch: 5| Step: 4
Training loss: 0.17278485169247065
Validation loss: 2.3392046359031955

Epoch: 5| Step: 5
Training loss: 0.1437052371985708
Validation loss: 2.342864590554982

Epoch: 5| Step: 6
Training loss: 0.19678531375012967
Validation loss: 2.3493824315768217

Epoch: 5| Step: 7
Training loss: 0.14304566477123518
Validation loss: 2.365624710260501

Epoch: 5| Step: 8
Training loss: 0.20388272979251693
Validation loss: 2.378642934093026

Epoch: 5| Step: 9
Training loss: 0.26530673089287005
Validation loss: 2.363045550228428

Epoch: 5| Step: 10
Training loss: 0.09696480583845143
Validation loss: 2.3555745978352234

Epoch: 527| Step: 0
Training loss: 0.23674393164270402
Validation loss: 2.3428275367842004

Epoch: 5| Step: 1
Training loss: 0.07300057295189022
Validation loss: 2.336361541929601

Epoch: 5| Step: 2
Training loss: 0.16005141618612145
Validation loss: 2.321495135116009

Epoch: 5| Step: 3
Training loss: 0.12372461875688948
Validation loss: 2.2681051092041105

Epoch: 5| Step: 4
Training loss: 0.15258572996517117
Validation loss: 2.2966942994079025

Epoch: 5| Step: 5
Training loss: 0.18882255224007302
Validation loss: 2.2901377040021753

Epoch: 5| Step: 6
Training loss: 0.17044529374980985
Validation loss: 2.297048624527788

Epoch: 5| Step: 7
Training loss: 0.1474301577648437
Validation loss: 2.322180779079716

Epoch: 5| Step: 8
Training loss: 0.21733327611372005
Validation loss: 2.3346547806777274

Epoch: 5| Step: 9
Training loss: 0.17773922714485066
Validation loss: 2.367173779017119

Epoch: 5| Step: 10
Training loss: 0.20688201816040877
Validation loss: 2.365760397141482

Epoch: 528| Step: 0
Training loss: 0.08823332994560597
Validation loss: 2.3640135963705795

Epoch: 5| Step: 1
Training loss: 0.1551575858297784
Validation loss: 2.3768309857584686

Epoch: 5| Step: 2
Training loss: 0.12044396958249218
Validation loss: 2.352771777746082

Epoch: 5| Step: 3
Training loss: 0.1385857086042121
Validation loss: 2.3558694153865694

Epoch: 5| Step: 4
Training loss: 0.08436305592909511
Validation loss: 2.345962979835185

Epoch: 5| Step: 5
Training loss: 0.13019258801310404
Validation loss: 2.3199998215325923

Epoch: 5| Step: 6
Training loss: 0.14526609530951837
Validation loss: 2.347904910348147

Epoch: 5| Step: 7
Training loss: 0.15343599146821993
Validation loss: 2.31831478762964

Epoch: 5| Step: 8
Training loss: 0.2607376726881187
Validation loss: 2.342992969063024

Epoch: 5| Step: 9
Training loss: 0.26957616569997894
Validation loss: 2.3838975103373383

Epoch: 5| Step: 10
Training loss: 0.19370512442646573
Validation loss: 2.3707189181726935

Epoch: 529| Step: 0
Training loss: 0.11649630474607033
Validation loss: 2.3879662265484014

Epoch: 5| Step: 1
Training loss: 0.23369633645110818
Validation loss: 2.3707750988209364

Epoch: 5| Step: 2
Training loss: 0.21528212299798408
Validation loss: 2.3502964291872694

Epoch: 5| Step: 3
Training loss: 0.14006438033098448
Validation loss: 2.34087758087457

Epoch: 5| Step: 4
Training loss: 0.13677637384493765
Validation loss: 2.3794763103197143

Epoch: 5| Step: 5
Training loss: 0.07418201817511623
Validation loss: 2.370171166699726

Epoch: 5| Step: 6
Training loss: 0.19463896967035543
Validation loss: 2.3999879365877623

Epoch: 5| Step: 7
Training loss: 0.22412071144885864
Validation loss: 2.380795776817424

Epoch: 5| Step: 8
Training loss: 0.1638126287012275
Validation loss: 2.3683302649855333

Epoch: 5| Step: 9
Training loss: 0.10307787609634081
Validation loss: 2.3820528026696226

Epoch: 5| Step: 10
Training loss: 0.125135623849098
Validation loss: 2.3621497264223685

Epoch: 530| Step: 0
Training loss: 0.14787598487585685
Validation loss: 2.3571966881205944

Epoch: 5| Step: 1
Training loss: 0.21978024992436618
Validation loss: 2.3257073138380817

Epoch: 5| Step: 2
Training loss: 0.18732947303897216
Validation loss: 2.3723457230006244

Epoch: 5| Step: 3
Training loss: 0.13448462699626307
Validation loss: 2.3604885315815873

Epoch: 5| Step: 4
Training loss: 0.20890938670186643
Validation loss: 2.359347853368249

Epoch: 5| Step: 5
Training loss: 0.1586996340452673
Validation loss: 2.3364741864327505

Epoch: 5| Step: 6
Training loss: 0.10218754415481966
Validation loss: 2.346219143267051

Epoch: 5| Step: 7
Training loss: 0.18750300007645246
Validation loss: 2.3710885234447487

Epoch: 5| Step: 8
Training loss: 0.2153420737902547
Validation loss: 2.369764951825578

Epoch: 5| Step: 9
Training loss: 0.12486319207925654
Validation loss: 2.3492791938249855

Epoch: 5| Step: 10
Training loss: 0.07668809017348364
Validation loss: 2.317333797782792

Epoch: 531| Step: 0
Training loss: 0.10588298354877061
Validation loss: 2.3267566838515674

Epoch: 5| Step: 1
Training loss: 0.16958136806552115
Validation loss: 2.3535396250132234

Epoch: 5| Step: 2
Training loss: 0.15231215320496022
Validation loss: 2.3278198466148283

Epoch: 5| Step: 3
Training loss: 0.14245469485747722
Validation loss: 2.3417514497381458

Epoch: 5| Step: 4
Training loss: 0.1566570225834891
Validation loss: 2.3455524145307822

Epoch: 5| Step: 5
Training loss: 0.16511523729106234
Validation loss: 2.34514493497036

Epoch: 5| Step: 6
Training loss: 0.24956253639104373
Validation loss: 2.381638702689055

Epoch: 5| Step: 7
Training loss: 0.21148953786973274
Validation loss: 2.3375749080391186

Epoch: 5| Step: 8
Training loss: 0.09342630951669016
Validation loss: 2.372339898909291

Epoch: 5| Step: 9
Training loss: 0.19179310921198262
Validation loss: 2.372902149287585

Epoch: 5| Step: 10
Training loss: 0.08419937514270902
Validation loss: 2.364108205719901

Epoch: 532| Step: 0
Training loss: 0.12121764121171742
Validation loss: 2.3607831633304026

Epoch: 5| Step: 1
Training loss: 0.14226068143514342
Validation loss: 2.375575988301762

Epoch: 5| Step: 2
Training loss: 0.08799010580798233
Validation loss: 2.375665286523712

Epoch: 5| Step: 3
Training loss: 0.27030194708450644
Validation loss: 2.3621852659250524

Epoch: 5| Step: 4
Training loss: 0.17328128094066622
Validation loss: 2.3783038895026007

Epoch: 5| Step: 5
Training loss: 0.19305194150296176
Validation loss: 2.355645112894123

Epoch: 5| Step: 6
Training loss: 0.10232413336889903
Validation loss: 2.3649860765680826

Epoch: 5| Step: 7
Training loss: 0.14533471045416713
Validation loss: 2.362509312600223

Epoch: 5| Step: 8
Training loss: 0.09571297264037225
Validation loss: 2.3533460324915123

Epoch: 5| Step: 9
Training loss: 0.23919846713478388
Validation loss: 2.3446434128470304

Epoch: 5| Step: 10
Training loss: 0.08748152412191865
Validation loss: 2.3498353937135064

Epoch: 533| Step: 0
Training loss: 0.11579732457697663
Validation loss: 2.336725182091618

Epoch: 5| Step: 1
Training loss: 0.11539144640961421
Validation loss: 2.369963809232421

Epoch: 5| Step: 2
Training loss: 0.2392955049680422
Validation loss: 2.362774441685684

Epoch: 5| Step: 3
Training loss: 0.15125601592986226
Validation loss: 2.356288727394479

Epoch: 5| Step: 4
Training loss: 0.12356480706255489
Validation loss: 2.377565760155659

Epoch: 5| Step: 5
Training loss: 0.22250622161996206
Validation loss: 2.3732266489865603

Epoch: 5| Step: 6
Training loss: 0.11401443154451564
Validation loss: 2.375607918448274

Epoch: 5| Step: 7
Training loss: 0.13324042410509823
Validation loss: 2.4052833540703706

Epoch: 5| Step: 8
Training loss: 0.19876999895374967
Validation loss: 2.4114233561178704

Epoch: 5| Step: 9
Training loss: 0.19741505920938726
Validation loss: 2.409818739640282

Epoch: 5| Step: 10
Training loss: 0.1676586360086131
Validation loss: 2.3893505712567755

Epoch: 534| Step: 0
Training loss: 0.13222144946717107
Validation loss: 2.4008222661271903

Epoch: 5| Step: 1
Training loss: 0.23337716041529366
Validation loss: 2.370506795525657

Epoch: 5| Step: 2
Training loss: 0.10812461480171298
Validation loss: 2.3915800829765943

Epoch: 5| Step: 3
Training loss: 0.16024286556393358
Validation loss: 2.339889952939082

Epoch: 5| Step: 4
Training loss: 0.11417793677152907
Validation loss: 2.356764692100111

Epoch: 5| Step: 5
Training loss: 0.20331231980091533
Validation loss: 2.3319705339544847

Epoch: 5| Step: 6
Training loss: 0.12755757733443712
Validation loss: 2.3550008282741515

Epoch: 5| Step: 7
Training loss: 0.21589990589463134
Validation loss: 2.371585903329118

Epoch: 5| Step: 8
Training loss: 0.19061738569655137
Validation loss: 2.3670279658499824

Epoch: 5| Step: 9
Training loss: 0.08968840520514937
Validation loss: 2.3694015286362204

Epoch: 5| Step: 10
Training loss: 0.19682042712773556
Validation loss: 2.360234087381115

Epoch: 535| Step: 0
Training loss: 0.08834612749595865
Validation loss: 2.3473517052975463

Epoch: 5| Step: 1
Training loss: 0.22972876346794105
Validation loss: 2.3644706692367485

Epoch: 5| Step: 2
Training loss: 0.12328610174376681
Validation loss: 2.323511117583654

Epoch: 5| Step: 3
Training loss: 0.23704220733261294
Validation loss: 2.348388654817821

Epoch: 5| Step: 4
Training loss: 0.20328754560440399
Validation loss: 2.3247173626223416

Epoch: 5| Step: 5
Training loss: 0.12203513973865182
Validation loss: 2.3166809632975727

Epoch: 5| Step: 6
Training loss: 0.16280915420704112
Validation loss: 2.3584933710129956

Epoch: 5| Step: 7
Training loss: 0.062316963651583276
Validation loss: 2.340499245137647

Epoch: 5| Step: 8
Training loss: 0.11241636114271021
Validation loss: 2.3173898693568242

Epoch: 5| Step: 9
Training loss: 0.20528737246819437
Validation loss: 2.3968487867240813

Epoch: 5| Step: 10
Training loss: 0.15565177720625642
Validation loss: 2.3131423031581644

Epoch: 536| Step: 0
Training loss: 0.15273563404003349
Validation loss: 2.3340294500175656

Epoch: 5| Step: 1
Training loss: 0.12373165665969311
Validation loss: 2.3506790445958674

Epoch: 5| Step: 2
Training loss: 0.10378587730812232
Validation loss: 2.3620356505186537

Epoch: 5| Step: 3
Training loss: 0.22023184429445444
Validation loss: 2.3647324008817128

Epoch: 5| Step: 4
Training loss: 0.12874622960958612
Validation loss: 2.3395406571329347

Epoch: 5| Step: 5
Training loss: 0.15302698662380865
Validation loss: 2.3682680374390275

Epoch: 5| Step: 6
Training loss: 0.24425717432892555
Validation loss: 2.315411198315842

Epoch: 5| Step: 7
Training loss: 0.12679838139690383
Validation loss: 2.3399587724810487

Epoch: 5| Step: 8
Training loss: 0.2440901589686823
Validation loss: 2.317591917112938

Epoch: 5| Step: 9
Training loss: 0.12639103948841376
Validation loss: 2.3254413497219866

Epoch: 5| Step: 10
Training loss: 0.1308434889530906
Validation loss: 2.3157933687142958

Epoch: 537| Step: 0
Training loss: 0.21993038472706747
Validation loss: 2.2835467137660324

Epoch: 5| Step: 1
Training loss: 0.1222192275582476
Validation loss: 2.339955715228951

Epoch: 5| Step: 2
Training loss: 0.13453858365529187
Validation loss: 2.3141916567888363

Epoch: 5| Step: 3
Training loss: 0.10761876702231259
Validation loss: 2.3007507762328543

Epoch: 5| Step: 4
Training loss: 0.12332475030748302
Validation loss: 2.3025581413288334

Epoch: 5| Step: 5
Training loss: 0.16999448671762293
Validation loss: 2.337671475703789

Epoch: 5| Step: 6
Training loss: 0.12064706031158046
Validation loss: 2.3482822385365094

Epoch: 5| Step: 7
Training loss: 0.22571564945635456
Validation loss: 2.3124057630845156

Epoch: 5| Step: 8
Training loss: 0.13417631336617394
Validation loss: 2.3507659492949915

Epoch: 5| Step: 9
Training loss: 0.27585295158433415
Validation loss: 2.3670286156877505

Epoch: 5| Step: 10
Training loss: 0.17480643500621368
Validation loss: 2.3720643575004545

Epoch: 538| Step: 0
Training loss: 0.2327305483111294
Validation loss: 2.389744931664188

Epoch: 5| Step: 1
Training loss: 0.11752317751020326
Validation loss: 2.4189532711866155

Epoch: 5| Step: 2
Training loss: 0.13539302983379717
Validation loss: 2.3734115616774845

Epoch: 5| Step: 3
Training loss: 0.14698164142505102
Validation loss: 2.3695187272317253

Epoch: 5| Step: 4
Training loss: 0.09628238345305157
Validation loss: 2.3747780258426183

Epoch: 5| Step: 5
Training loss: 0.17529840912518654
Validation loss: 2.3622600999191037

Epoch: 5| Step: 6
Training loss: 0.12594265444503713
Validation loss: 2.357849379755792

Epoch: 5| Step: 7
Training loss: 0.19407555854094885
Validation loss: 2.381508000333923

Epoch: 5| Step: 8
Training loss: 0.1696026862506696
Validation loss: 2.378567784002966

Epoch: 5| Step: 9
Training loss: 0.23405712346878096
Validation loss: 2.36679581288772

Epoch: 5| Step: 10
Training loss: 0.22701981035882896
Validation loss: 2.334564461748021

Epoch: 539| Step: 0
Training loss: 0.14245361613692833
Validation loss: 2.3624021268109066

Epoch: 5| Step: 1
Training loss: 0.1139489792909578
Validation loss: 2.389091030117816

Epoch: 5| Step: 2
Training loss: 0.11266049536458259
Validation loss: 2.362551645492585

Epoch: 5| Step: 3
Training loss: 0.14901600590445496
Validation loss: 2.3691556249850643

Epoch: 5| Step: 4
Training loss: 0.21639885321690505
Validation loss: 2.347370597088309

Epoch: 5| Step: 5
Training loss: 0.2661840362278682
Validation loss: 2.321986700155297

Epoch: 5| Step: 6
Training loss: 0.1504156599634126
Validation loss: 2.3893205001875613

Epoch: 5| Step: 7
Training loss: 0.1756572179837202
Validation loss: 2.408274444201864

Epoch: 5| Step: 8
Training loss: 0.13221768810068488
Validation loss: 2.3997570877131627

Epoch: 5| Step: 9
Training loss: 0.1761868671373393
Validation loss: 2.4111709776113726

Epoch: 5| Step: 10
Training loss: 0.22220895410124714
Validation loss: 2.4172302737391793

Epoch: 540| Step: 0
Training loss: 0.1394516218195236
Validation loss: 2.382439204144914

Epoch: 5| Step: 1
Training loss: 0.286659173206781
Validation loss: 2.42954434393605

Epoch: 5| Step: 2
Training loss: 0.10595665329544936
Validation loss: 2.399052495025124

Epoch: 5| Step: 3
Training loss: 0.13974107990560658
Validation loss: 2.415853983944951

Epoch: 5| Step: 4
Training loss: 0.14947740296797604
Validation loss: 2.3888203995122095

Epoch: 5| Step: 5
Training loss: 0.1591979232827106
Validation loss: 2.4360555697529596

Epoch: 5| Step: 6
Training loss: 0.23178864617779468
Validation loss: 2.418311362104365

Epoch: 5| Step: 7
Training loss: 0.09060342075494489
Validation loss: 2.374456936697187

Epoch: 5| Step: 8
Training loss: 0.1340092566383504
Validation loss: 2.3831167310954107

Epoch: 5| Step: 9
Training loss: 0.12263380835479291
Validation loss: 2.3853542199518194

Epoch: 5| Step: 10
Training loss: 0.13102813770137917
Validation loss: 2.352563111705773

Epoch: 541| Step: 0
Training loss: 0.09660780286088162
Validation loss: 2.348559520049334

Epoch: 5| Step: 1
Training loss: 0.06746353966642685
Validation loss: 2.360370986165268

Epoch: 5| Step: 2
Training loss: 0.2201883084365985
Validation loss: 2.289997391916665

Epoch: 5| Step: 3
Training loss: 0.11638881789643185
Validation loss: 2.2996034102377494

Epoch: 5| Step: 4
Training loss: 0.11242093828114581
Validation loss: 2.2804539362340233

Epoch: 5| Step: 5
Training loss: 0.22240918656908668
Validation loss: 2.329694071758155

Epoch: 5| Step: 6
Training loss: 0.12047097974042187
Validation loss: 2.3059882232224167

Epoch: 5| Step: 7
Training loss: 0.2120252308873162
Validation loss: 2.31576316611389

Epoch: 5| Step: 8
Training loss: 0.1371714182619164
Validation loss: 2.3275615976420085

Epoch: 5| Step: 9
Training loss: 0.17118458361611827
Validation loss: 2.360226648118002

Epoch: 5| Step: 10
Training loss: 0.08332907832230006
Validation loss: 2.3090882857917467

Epoch: 542| Step: 0
Training loss: 0.2496264990602543
Validation loss: 2.3252876595784

Epoch: 5| Step: 1
Training loss: 0.11163716755339012
Validation loss: 2.3218771493332313

Epoch: 5| Step: 2
Training loss: 0.08152476695776675
Validation loss: 2.352588208967668

Epoch: 5| Step: 3
Training loss: 0.14507652858046835
Validation loss: 2.3594336656908546

Epoch: 5| Step: 4
Training loss: 0.0803837468418035
Validation loss: 2.3494163823102205

Epoch: 5| Step: 5
Training loss: 0.12204730007696842
Validation loss: 2.318446102891201

Epoch: 5| Step: 6
Training loss: 0.14568713358649313
Validation loss: 2.3484623177496253

Epoch: 5| Step: 7
Training loss: 0.10769971549352729
Validation loss: 2.360323526690437

Epoch: 5| Step: 8
Training loss: 0.1917970424270676
Validation loss: 2.3381106682018347

Epoch: 5| Step: 9
Training loss: 0.1887588561108809
Validation loss: 2.338908726167502

Epoch: 5| Step: 10
Training loss: 0.097972068327355
Validation loss: 2.3620156126609864

Epoch: 543| Step: 0
Training loss: 0.08109294896014978
Validation loss: 2.361735876749365

Epoch: 5| Step: 1
Training loss: 0.10094980977496541
Validation loss: 2.3731485176000873

Epoch: 5| Step: 2
Training loss: 0.10076579892200728
Validation loss: 2.364682516453959

Epoch: 5| Step: 3
Training loss: 0.0985216420701013
Validation loss: 2.37851381644006

Epoch: 5| Step: 4
Training loss: 0.2303166534147662
Validation loss: 2.3921818595043787

Epoch: 5| Step: 5
Training loss: 0.07793265148253053
Validation loss: 2.354846313563741

Epoch: 5| Step: 6
Training loss: 0.09684886483696266
Validation loss: 2.365441375939025

Epoch: 5| Step: 7
Training loss: 0.2330518007924789
Validation loss: 2.3668140143951573

Epoch: 5| Step: 8
Training loss: 0.11473345585480478
Validation loss: 2.352075554269272

Epoch: 5| Step: 9
Training loss: 0.1973553632821206
Validation loss: 2.3438292940460617

Epoch: 5| Step: 10
Training loss: 0.2167040394147542
Validation loss: 2.327298904445834

Epoch: 544| Step: 0
Training loss: 0.14401025562265876
Validation loss: 2.3303367865130267

Epoch: 5| Step: 1
Training loss: 0.09722532084566088
Validation loss: 2.3364209253699144

Epoch: 5| Step: 2
Training loss: 0.17743598077317826
Validation loss: 2.3264716152697327

Epoch: 5| Step: 3
Training loss: 0.18079724944127587
Validation loss: 2.3242369165328425

Epoch: 5| Step: 4
Training loss: 0.1567411452177316
Validation loss: 2.3187548448362585

Epoch: 5| Step: 5
Training loss: 0.20794505753182457
Validation loss: 2.3100874179815145

Epoch: 5| Step: 6
Training loss: 0.14616311767295587
Validation loss: 2.34509285252323

Epoch: 5| Step: 7
Training loss: 0.19499509770087722
Validation loss: 2.346804162827022

Epoch: 5| Step: 8
Training loss: 0.11978051835166832
Validation loss: 2.3594295889549355

Epoch: 5| Step: 9
Training loss: 0.15312796268711046
Validation loss: 2.33638843279318

Epoch: 5| Step: 10
Training loss: 0.15730033352218417
Validation loss: 2.3317241683977388

Epoch: 545| Step: 0
Training loss: 0.2765578565908165
Validation loss: 2.3725635215401955

Epoch: 5| Step: 1
Training loss: 0.14793563377531227
Validation loss: 2.3620022843850608

Epoch: 5| Step: 2
Training loss: 0.10129161619651716
Validation loss: 2.3451867647236475

Epoch: 5| Step: 3
Training loss: 0.130394172768757
Validation loss: 2.3535062114119003

Epoch: 5| Step: 4
Training loss: 0.11706505577497066
Validation loss: 2.384481312676615

Epoch: 5| Step: 5
Training loss: 0.142781902380622
Validation loss: 2.3231831629537694

Epoch: 5| Step: 6
Training loss: 0.13439685011799238
Validation loss: 2.38534882259082

Epoch: 5| Step: 7
Training loss: 0.15360920410177786
Validation loss: 2.379089533764856

Epoch: 5| Step: 8
Training loss: 0.13407562362796868
Validation loss: 2.371474946083456

Epoch: 5| Step: 9
Training loss: 0.22255006567101934
Validation loss: 2.3588736515610114

Epoch: 5| Step: 10
Training loss: 0.17487417470268266
Validation loss: 2.3630521799719575

Epoch: 546| Step: 0
Training loss: 0.16355596412031087
Validation loss: 2.3674132233632665

Epoch: 5| Step: 1
Training loss: 0.1184003060450497
Validation loss: 2.3576681312262093

Epoch: 5| Step: 2
Training loss: 0.08993343355212367
Validation loss: 2.365086105805998

Epoch: 5| Step: 3
Training loss: 0.08978446787582108
Validation loss: 2.3455366744806185

Epoch: 5| Step: 4
Training loss: 0.16580483012716096
Validation loss: 2.3595044000665495

Epoch: 5| Step: 5
Training loss: 0.23341073518540517
Validation loss: 2.362979419932493

Epoch: 5| Step: 6
Training loss: 0.1548423781656572
Validation loss: 2.3500568155242285

Epoch: 5| Step: 7
Training loss: 0.17676826572595328
Validation loss: 2.3285261481522213

Epoch: 5| Step: 8
Training loss: 0.17889127335475474
Validation loss: 2.2939587523373843

Epoch: 5| Step: 9
Training loss: 0.12399071539595699
Validation loss: 2.2712256785152958

Epoch: 5| Step: 10
Training loss: 0.24440561790565038
Validation loss: 2.297774370330367

Epoch: 547| Step: 0
Training loss: 0.14141054752837667
Validation loss: 2.3125553141117074

Epoch: 5| Step: 1
Training loss: 0.12956216857267866
Validation loss: 2.322904268821484

Epoch: 5| Step: 2
Training loss: 0.2018724575561712
Validation loss: 2.3122770916508015

Epoch: 5| Step: 3
Training loss: 0.16083171339858093
Validation loss: 2.349249650346494

Epoch: 5| Step: 4
Training loss: 0.08320391715035318
Validation loss: 2.340895214562276

Epoch: 5| Step: 5
Training loss: 0.17002228806400774
Validation loss: 2.356009775861701

Epoch: 5| Step: 6
Training loss: 0.1438336419286029
Validation loss: 2.390627872884344

Epoch: 5| Step: 7
Training loss: 0.16276010640432667
Validation loss: 2.402253515624975

Epoch: 5| Step: 8
Training loss: 0.13565346679477472
Validation loss: 2.4136058177483837

Epoch: 5| Step: 9
Training loss: 0.17278483552225765
Validation loss: 2.415791369642374

Epoch: 5| Step: 10
Training loss: 0.28250542561629427
Validation loss: 2.4087704058548676

Epoch: 548| Step: 0
Training loss: 0.13582968464755374
Validation loss: 2.3996341370056067

Epoch: 5| Step: 1
Training loss: 0.18993496332297918
Validation loss: 2.3912020281867923

Epoch: 5| Step: 2
Training loss: 0.2282715986118949
Validation loss: 2.351333905219128

Epoch: 5| Step: 3
Training loss: 0.11410563678774135
Validation loss: 2.3285739859680485

Epoch: 5| Step: 4
Training loss: 0.11520484772313395
Validation loss: 2.3204998494398787

Epoch: 5| Step: 5
Training loss: 0.16961739105160387
Validation loss: 2.3066220259097414

Epoch: 5| Step: 6
Training loss: 0.19223630719600193
Validation loss: 2.301737278849885

Epoch: 5| Step: 7
Training loss: 0.14880664625394271
Validation loss: 2.2896059818941565

Epoch: 5| Step: 8
Training loss: 0.1569740981391392
Validation loss: 2.3123877874197385

Epoch: 5| Step: 9
Training loss: 0.13560158150513385
Validation loss: 2.3026607739320735

Epoch: 5| Step: 10
Training loss: 0.2397633874564425
Validation loss: 2.349251590604809

Epoch: 549| Step: 0
Training loss: 0.14157439004046576
Validation loss: 2.3441966401709986

Epoch: 5| Step: 1
Training loss: 0.21883872480776928
Validation loss: 2.372985998409524

Epoch: 5| Step: 2
Training loss: 0.14434851229017964
Validation loss: 2.34726171109797

Epoch: 5| Step: 3
Training loss: 0.20229569199489375
Validation loss: 2.3770696013038175

Epoch: 5| Step: 4
Training loss: 0.17972827531661273
Validation loss: 2.3686588717562

Epoch: 5| Step: 5
Training loss: 0.14086155069356118
Validation loss: 2.375986784772188

Epoch: 5| Step: 6
Training loss: 0.12507058177458882
Validation loss: 2.3728145611069147

Epoch: 5| Step: 7
Training loss: 0.10151638304450995
Validation loss: 2.3753050946575063

Epoch: 5| Step: 8
Training loss: 0.11035305629833195
Validation loss: 2.376159569476903

Epoch: 5| Step: 9
Training loss: 0.0939070607862841
Validation loss: 2.3731961148897014

Epoch: 5| Step: 10
Training loss: 0.10570859569960696
Validation loss: 2.3596230001484706

Epoch: 550| Step: 0
Training loss: 0.1806411934889767
Validation loss: 2.3308629895636224

Epoch: 5| Step: 1
Training loss: 0.21667005936705128
Validation loss: 2.322795337124174

Epoch: 5| Step: 2
Training loss: 0.0843578285828735
Validation loss: 2.360660673442285

Epoch: 5| Step: 3
Training loss: 0.11789835067168478
Validation loss: 2.323984083429568

Epoch: 5| Step: 4
Training loss: 0.1441000809028466
Validation loss: 2.331997148400464

Epoch: 5| Step: 5
Training loss: 0.17293606863749547
Validation loss: 2.3029519129988896

Epoch: 5| Step: 6
Training loss: 0.10790042919662661
Validation loss: 2.3175131429508036

Epoch: 5| Step: 7
Training loss: 0.08597852800419911
Validation loss: 2.314794476897157

Epoch: 5| Step: 8
Training loss: 0.07213480488085076
Validation loss: 2.3077842834481967

Epoch: 5| Step: 9
Training loss: 0.1937856502959197
Validation loss: 2.330846804955994

Epoch: 5| Step: 10
Training loss: 0.1604680828630347
Validation loss: 2.332910965525564

Testing loss: 2.73003949096026
