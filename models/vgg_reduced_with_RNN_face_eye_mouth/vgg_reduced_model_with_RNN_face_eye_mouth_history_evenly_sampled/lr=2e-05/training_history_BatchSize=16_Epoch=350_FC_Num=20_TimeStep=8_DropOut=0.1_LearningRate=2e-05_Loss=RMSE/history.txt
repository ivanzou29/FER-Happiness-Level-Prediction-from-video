Epoch: 1| Step: 0
Training loss: 6.188852181697693
Validation loss: 5.798198609317347

Epoch: 6| Step: 1
Training loss: 5.230677878975955
Validation loss: 5.782917246801531

Epoch: 6| Step: 2
Training loss: 5.981361686277658
Validation loss: 5.767933227381498

Epoch: 6| Step: 3
Training loss: 5.247708683453341
Validation loss: 5.7512740854352895

Epoch: 6| Step: 4
Training loss: 5.380083563343563
Validation loss: 5.733096808448028

Epoch: 6| Step: 5
Training loss: 5.783369016216619
Validation loss: 5.712543455053626

Epoch: 6| Step: 6
Training loss: 6.1476172320530775
Validation loss: 5.68900534185262

Epoch: 6| Step: 7
Training loss: 5.1054973295035015
Validation loss: 5.661952203221946

Epoch: 6| Step: 8
Training loss: 7.12824670536376
Validation loss: 5.631216905522643

Epoch: 6| Step: 9
Training loss: 5.592561563588665
Validation loss: 5.596308605340535

Epoch: 6| Step: 10
Training loss: 4.93395153932002
Validation loss: 5.557146025751316

Epoch: 6| Step: 11
Training loss: 5.519258248069818
Validation loss: 5.511599230069814

Epoch: 6| Step: 12
Training loss: 5.607810649728031
Validation loss: 5.464393928932871

Epoch: 6| Step: 13
Training loss: 5.309766357799001
Validation loss: 5.412371298092409

Epoch: 2| Step: 0
Training loss: 5.982722519890087
Validation loss: 5.358566153783141

Epoch: 6| Step: 1
Training loss: 5.111042462224236
Validation loss: 5.303215152484366

Epoch: 6| Step: 2
Training loss: 5.38596414504669
Validation loss: 5.245629925054343

Epoch: 6| Step: 3
Training loss: 4.585021777252097
Validation loss: 5.187477992426613

Epoch: 6| Step: 4
Training loss: 4.805455985290314
Validation loss: 5.127919369794437

Epoch: 6| Step: 5
Training loss: 5.153401090629694
Validation loss: 5.065166762027658

Epoch: 6| Step: 6
Training loss: 5.300105997141247
Validation loss: 5.000788663377101

Epoch: 6| Step: 7
Training loss: 5.015465469437714
Validation loss: 4.9362294504358655

Epoch: 6| Step: 8
Training loss: 4.847723530833465
Validation loss: 4.871825310654057

Epoch: 6| Step: 9
Training loss: 5.4201089142839365
Validation loss: 4.808278964778462

Epoch: 6| Step: 10
Training loss: 4.947381091662304
Validation loss: 4.746842725877743

Epoch: 6| Step: 11
Training loss: 4.741431689795197
Validation loss: 4.688773376985875

Epoch: 6| Step: 12
Training loss: 3.9542486832811816
Validation loss: 4.639183099128304

Epoch: 6| Step: 13
Training loss: 5.485137277865637
Validation loss: 4.5966507508852175

Epoch: 3| Step: 0
Training loss: 4.758370102151863
Validation loss: 4.558994838681403

Epoch: 6| Step: 1
Training loss: 5.697509676702031
Validation loss: 4.526289086520333

Epoch: 6| Step: 2
Training loss: 4.037461337917155
Validation loss: 4.489635129853021

Epoch: 6| Step: 3
Training loss: 4.736500480111419
Validation loss: 4.454135126076102

Epoch: 6| Step: 4
Training loss: 4.169037614820603
Validation loss: 4.420923872619959

Epoch: 6| Step: 5
Training loss: 4.7205368599831905
Validation loss: 4.3922468370814185

Epoch: 6| Step: 6
Training loss: 4.967902921050632
Validation loss: 4.365413192849136

Epoch: 6| Step: 7
Training loss: 4.044032214073216
Validation loss: 4.324180135906438

Epoch: 6| Step: 8
Training loss: 3.90127441907071
Validation loss: 4.283355741145778

Epoch: 6| Step: 9
Training loss: 3.6962452007800497
Validation loss: 4.260201679077322

Epoch: 6| Step: 10
Training loss: 4.945426083867899
Validation loss: 4.249594095379875

Epoch: 6| Step: 11
Training loss: 4.51536480111069
Validation loss: 4.23453428464315

Epoch: 6| Step: 12
Training loss: 3.6291141183569327
Validation loss: 4.218317385375757

Epoch: 6| Step: 13
Training loss: 4.553625385381479
Validation loss: 4.197916112971145

Epoch: 4| Step: 0
Training loss: 3.820013428509662
Validation loss: 4.181292602257281

Epoch: 6| Step: 1
Training loss: 5.38507803092675
Validation loss: 4.168764266061501

Epoch: 6| Step: 2
Training loss: 4.5685322220400675
Validation loss: 4.161262181183629

Epoch: 6| Step: 3
Training loss: 5.131825809486913
Validation loss: 4.143406624883851

Epoch: 6| Step: 4
Training loss: 3.9610403073905296
Validation loss: 4.134943109581175

Epoch: 6| Step: 5
Training loss: 4.447433528821553
Validation loss: 4.1237773506507285

Epoch: 6| Step: 6
Training loss: 3.6622296855237315
Validation loss: 4.108345241155384

Epoch: 6| Step: 7
Training loss: 3.8029126799973425
Validation loss: 4.09661647647103

Epoch: 6| Step: 8
Training loss: 3.888634597699278
Validation loss: 4.0834234017205

Epoch: 6| Step: 9
Training loss: 4.150141077056617
Validation loss: 4.072394674200121

Epoch: 6| Step: 10
Training loss: 3.7560453641628087
Validation loss: 4.062383392907019

Epoch: 6| Step: 11
Training loss: 3.9758285714539863
Validation loss: 4.055203626268818

Epoch: 6| Step: 12
Training loss: 4.576453623155443
Validation loss: 4.052441636054204

Epoch: 6| Step: 13
Training loss: 3.7681218017524056
Validation loss: 4.039926324016406

Epoch: 5| Step: 0
Training loss: 4.836076528002052
Validation loss: 4.0310379383361825

Epoch: 6| Step: 1
Training loss: 4.348081994610998
Validation loss: 4.0233773526184935

Epoch: 6| Step: 2
Training loss: 4.003867187309449
Validation loss: 4.014287466098265

Epoch: 6| Step: 3
Training loss: 3.6419869032597614
Validation loss: 4.005585472680137

Epoch: 6| Step: 4
Training loss: 3.759090087444362
Validation loss: 4.001397826925993

Epoch: 6| Step: 5
Training loss: 4.819093423324505
Validation loss: 3.994278669224524

Epoch: 6| Step: 6
Training loss: 3.7094156778832006
Validation loss: 3.9848293778055863

Epoch: 6| Step: 7
Training loss: 4.198361104277962
Validation loss: 3.9750174651197905

Epoch: 6| Step: 8
Training loss: 4.830266483766628
Validation loss: 3.96420113697187

Epoch: 6| Step: 9
Training loss: 4.219262212105566
Validation loss: 3.9567687218987704

Epoch: 6| Step: 10
Training loss: 3.120533765226621
Validation loss: 3.9517290973678247

Epoch: 6| Step: 11
Training loss: 3.4631344816404757
Validation loss: 3.946090864808849

Epoch: 6| Step: 12
Training loss: 4.30106507351395
Validation loss: 3.9327130391885876

Epoch: 6| Step: 13
Training loss: 4.3322036199786425
Validation loss: 3.9279504709018536

Epoch: 6| Step: 0
Training loss: 4.508922631935621
Validation loss: 3.9233423238550493

Epoch: 6| Step: 1
Training loss: 3.3980878277363233
Validation loss: 3.9156418434649414

Epoch: 6| Step: 2
Training loss: 3.790096432910931
Validation loss: 3.9080562584558582

Epoch: 6| Step: 3
Training loss: 3.7498012490055332
Validation loss: 3.901352182943898

Epoch: 6| Step: 4
Training loss: 3.6574509433421114
Validation loss: 3.898823872441177

Epoch: 6| Step: 5
Training loss: 4.238448207397031
Validation loss: 3.8973835301235633

Epoch: 6| Step: 6
Training loss: 4.388021654379869
Validation loss: 3.8872954605833994

Epoch: 6| Step: 7
Training loss: 4.6246391361805275
Validation loss: 3.8797120637979914

Epoch: 6| Step: 8
Training loss: 3.1797393869576367
Validation loss: 3.873521765652853

Epoch: 6| Step: 9
Training loss: 5.146397465762856
Validation loss: 3.8664238321673214

Epoch: 6| Step: 10
Training loss: 4.45864665038652
Validation loss: 3.8617183749456325

Epoch: 6| Step: 11
Training loss: 3.044999861192622
Validation loss: 3.8559632446190966

Epoch: 6| Step: 12
Training loss: 3.792162321342684
Validation loss: 3.849374783584536

Epoch: 6| Step: 13
Training loss: 4.254664610073733
Validation loss: 3.844786444136383

Epoch: 7| Step: 0
Training loss: 3.7176024645888104
Validation loss: 3.8418840904459737

Epoch: 6| Step: 1
Training loss: 2.930047992144001
Validation loss: 3.837516491599222

Epoch: 6| Step: 2
Training loss: 4.005428445403812
Validation loss: 3.839458717626721

Epoch: 6| Step: 3
Training loss: 4.404379373187994
Validation loss: 3.835124824166275

Epoch: 6| Step: 4
Training loss: 4.369067720530552
Validation loss: 3.8269556720311018

Epoch: 6| Step: 5
Training loss: 2.6657906126427298
Validation loss: 3.8223218919835924

Epoch: 6| Step: 6
Training loss: 4.079479708688782
Validation loss: 3.8177997421649668

Epoch: 6| Step: 7
Training loss: 4.548236865824656
Validation loss: 3.812190976152113

Epoch: 6| Step: 8
Training loss: 4.3783275483878175
Validation loss: 3.8064852978189387

Epoch: 6| Step: 9
Training loss: 4.1587977810618115
Validation loss: 3.801475744490462

Epoch: 6| Step: 10
Training loss: 4.175024551045306
Validation loss: 3.797324878395525

Epoch: 6| Step: 11
Training loss: 3.079257814729906
Validation loss: 3.7890380168462516

Epoch: 6| Step: 12
Training loss: 4.777424197950511
Validation loss: 3.7853310038609957

Epoch: 6| Step: 13
Training loss: 3.8127466340883385
Validation loss: 3.777768514679328

Epoch: 8| Step: 0
Training loss: 3.9524784087062463
Validation loss: 3.7715582949826985

Epoch: 6| Step: 1
Training loss: 3.5134422477426117
Validation loss: 3.766018508190889

Epoch: 6| Step: 2
Training loss: 3.7604230350570784
Validation loss: 3.757570108946477

Epoch: 6| Step: 3
Training loss: 3.977799318801075
Validation loss: 3.7508973022291454

Epoch: 6| Step: 4
Training loss: 3.255069007435029
Validation loss: 3.7475382295737774

Epoch: 6| Step: 5
Training loss: 3.801759944731935
Validation loss: 3.754975688361821

Epoch: 6| Step: 6
Training loss: 3.727702544227442
Validation loss: 3.7324380641878134

Epoch: 6| Step: 7
Training loss: 4.022695054374403
Validation loss: 3.7316161252017963

Epoch: 6| Step: 8
Training loss: 3.996486789917778
Validation loss: 3.7413055012842227

Epoch: 6| Step: 9
Training loss: 4.22945013489975
Validation loss: 3.7218785226497904

Epoch: 6| Step: 10
Training loss: 4.260352372832351
Validation loss: 3.740866163252987

Epoch: 6| Step: 11
Training loss: 2.713452845978915
Validation loss: 3.737823523797495

Epoch: 6| Step: 12
Training loss: 5.211976915637734
Validation loss: 3.7465786793951183

Epoch: 6| Step: 13
Training loss: 4.174664768305878
Validation loss: 3.715604560891256

Epoch: 9| Step: 0
Training loss: 4.1782445395466
Validation loss: 3.7132802286531974

Epoch: 6| Step: 1
Training loss: 3.522876094236327
Validation loss: 3.7149571480741304

Epoch: 6| Step: 2
Training loss: 3.6624743307730876
Validation loss: 3.717064370408409

Epoch: 6| Step: 3
Training loss: 4.863968717098024
Validation loss: 3.713810408057403

Epoch: 6| Step: 4
Training loss: 3.9862573104317667
Validation loss: 3.7003612798117436

Epoch: 6| Step: 5
Training loss: 3.5486706461000557
Validation loss: 3.693981790010041

Epoch: 6| Step: 6
Training loss: 4.2973723522533085
Validation loss: 3.6942315802196144

Epoch: 6| Step: 7
Training loss: 3.6679476898856267
Validation loss: 3.68708964936416

Epoch: 6| Step: 8
Training loss: 4.910661402826304
Validation loss: 3.6922457360545766

Epoch: 6| Step: 9
Training loss: 3.5744220613282036
Validation loss: 3.687916568942851

Epoch: 6| Step: 10
Training loss: 4.0771139360441415
Validation loss: 3.6795367796638336

Epoch: 6| Step: 11
Training loss: 3.2421995599361546
Validation loss: 3.6760475707607427

Epoch: 6| Step: 12
Training loss: 2.746535546481632
Validation loss: 3.6698086152054965

Epoch: 6| Step: 13
Training loss: 3.216469855208933
Validation loss: 3.6655010167907043

Epoch: 10| Step: 0
Training loss: 4.103372926332506
Validation loss: 3.663296662934172

Epoch: 6| Step: 1
Training loss: 3.629664478401419
Validation loss: 3.65779356184765

Epoch: 6| Step: 2
Training loss: 3.4287995251212458
Validation loss: 3.649236885701365

Epoch: 6| Step: 3
Training loss: 3.8482016239836714
Validation loss: 3.640621442501269

Epoch: 6| Step: 4
Training loss: 2.732460267108769
Validation loss: 3.633819262036393

Epoch: 6| Step: 5
Training loss: 3.4343644146326575
Validation loss: 3.6348901088714376

Epoch: 6| Step: 6
Training loss: 3.920786307549828
Validation loss: 3.648933041291925

Epoch: 6| Step: 7
Training loss: 4.311321152707962
Validation loss: 3.615103026282308

Epoch: 6| Step: 8
Training loss: 3.7631133634637286
Validation loss: 3.616482800540809

Epoch: 6| Step: 9
Training loss: 4.312728212371963
Validation loss: 3.6147184692741616

Epoch: 6| Step: 10
Training loss: 3.9136399823408583
Validation loss: 3.611649303360376

Epoch: 6| Step: 11
Training loss: 4.402199256238406
Validation loss: 3.6086344746568497

Epoch: 6| Step: 12
Training loss: 3.8199898363147957
Validation loss: 3.604511602737973

Epoch: 6| Step: 13
Training loss: 3.494785102273354
Validation loss: 3.605443728336172

Epoch: 11| Step: 0
Training loss: 3.6877787856413202
Validation loss: 3.6018300123382962

Epoch: 6| Step: 1
Training loss: 3.964645666426565
Validation loss: 3.5902925806810186

Epoch: 6| Step: 2
Training loss: 4.254126396823029
Validation loss: 3.5833029010011765

Epoch: 6| Step: 3
Training loss: 3.4363850952990354
Validation loss: 3.577320693967701

Epoch: 6| Step: 4
Training loss: 4.30848529087764
Validation loss: 3.5738785751565976

Epoch: 6| Step: 5
Training loss: 3.89184220358558
Validation loss: 3.5708182434386555

Epoch: 6| Step: 6
Training loss: 3.3458824131945826
Validation loss: 3.564739238130416

Epoch: 6| Step: 7
Training loss: 3.724361001321443
Validation loss: 3.5609340856672964

Epoch: 6| Step: 8
Training loss: 3.5196515569754245
Validation loss: 3.55444023086359

Epoch: 6| Step: 9
Training loss: 4.268691752582336
Validation loss: 3.5511471489557014

Epoch: 6| Step: 10
Training loss: 3.4070671571249047
Validation loss: 3.5604183071274806

Epoch: 6| Step: 11
Training loss: 3.658131563593641
Validation loss: 3.5581763900894017

Epoch: 6| Step: 12
Training loss: 3.4983729258988543
Validation loss: 3.5431884266264424

Epoch: 6| Step: 13
Training loss: 3.6131696034271465
Validation loss: 3.5350459585897833

Epoch: 12| Step: 0
Training loss: 3.400255440484858
Validation loss: 3.533304973955939

Epoch: 6| Step: 1
Training loss: 3.399589255710746
Validation loss: 3.5296144813411736

Epoch: 6| Step: 2
Training loss: 4.407319500494984
Validation loss: 3.5258774415215535

Epoch: 6| Step: 3
Training loss: 3.3433096051982587
Validation loss: 3.525236990421054

Epoch: 6| Step: 4
Training loss: 3.6385243130472196
Validation loss: 3.521465802214946

Epoch: 6| Step: 5
Training loss: 3.3382403177706443
Validation loss: 3.513388173211469

Epoch: 6| Step: 6
Training loss: 3.7800645467505047
Validation loss: 3.509467522102232

Epoch: 6| Step: 7
Training loss: 3.352054728750862
Validation loss: 3.505753572551473

Epoch: 6| Step: 8
Training loss: 4.142133330081243
Validation loss: 3.5077986754521313

Epoch: 6| Step: 9
Training loss: 3.479956318372862
Validation loss: 3.4935188876390226

Epoch: 6| Step: 10
Training loss: 3.7906225394722926
Validation loss: 3.4948814190694972

Epoch: 6| Step: 11
Training loss: 4.450187919163542
Validation loss: 3.496738321850784

Epoch: 6| Step: 12
Training loss: 4.024772230065479
Validation loss: 3.4863225430206377

Epoch: 6| Step: 13
Training loss: 2.883938039825702
Validation loss: 3.4843428592017114

Epoch: 13| Step: 0
Training loss: 3.241327157828964
Validation loss: 3.4913613376624477

Epoch: 6| Step: 1
Training loss: 3.4302088313020787
Validation loss: 3.4950279203787815

Epoch: 6| Step: 2
Training loss: 4.636196090948439
Validation loss: 3.4919758078462553

Epoch: 6| Step: 3
Training loss: 3.4139863797917838
Validation loss: 3.483111376392404

Epoch: 6| Step: 4
Training loss: 3.317851799578282
Validation loss: 3.4812315811810235

Epoch: 6| Step: 5
Training loss: 3.303062959519661
Validation loss: 3.4744645347183023

Epoch: 6| Step: 6
Training loss: 3.2015064150811354
Validation loss: 3.4705892304312806

Epoch: 6| Step: 7
Training loss: 4.24500272573287
Validation loss: 3.466396252692613

Epoch: 6| Step: 8
Training loss: 3.566724046501097
Validation loss: 3.4617310023619954

Epoch: 6| Step: 9
Training loss: 3.735002664465509
Validation loss: 3.46198295155498

Epoch: 6| Step: 10
Training loss: 3.7047729688267426
Validation loss: 3.459052797674687

Epoch: 6| Step: 11
Training loss: 4.76312490453496
Validation loss: 3.4540458434718793

Epoch: 6| Step: 12
Training loss: 3.37855427402668
Validation loss: 3.4462534302535337

Epoch: 6| Step: 13
Training loss: 2.8430228508867215
Validation loss: 3.4427829661303453

Epoch: 14| Step: 0
Training loss: 4.007777520635
Validation loss: 3.4412877697479174

Epoch: 6| Step: 1
Training loss: 3.655267697614382
Validation loss: 3.4411322517075904

Epoch: 6| Step: 2
Training loss: 3.282304140335799
Validation loss: 3.44058162571003

Epoch: 6| Step: 3
Training loss: 3.186027785252489
Validation loss: 3.440988876612459

Epoch: 6| Step: 4
Training loss: 4.315093656476086
Validation loss: 3.4414932265872182

Epoch: 6| Step: 5
Training loss: 3.6428370488571633
Validation loss: 3.434055285637037

Epoch: 6| Step: 6
Training loss: 3.8415419276267007
Validation loss: 3.4317504783799904

Epoch: 6| Step: 7
Training loss: 4.2122517589017745
Validation loss: 3.42971733648933

Epoch: 6| Step: 8
Training loss: 2.5428254867959046
Validation loss: 3.4273578079942015

Epoch: 6| Step: 9
Training loss: 3.866069840267589
Validation loss: 3.4260073691817685

Epoch: 6| Step: 10
Training loss: 3.7274646106987026
Validation loss: 3.425517546662918

Epoch: 6| Step: 11
Training loss: 2.972797565885847
Validation loss: 3.4235439114365853

Epoch: 6| Step: 12
Training loss: 4.13789202627891
Validation loss: 3.422044199282863

Epoch: 6| Step: 13
Training loss: 3.1277857761344783
Validation loss: 3.4207661123841717

Epoch: 15| Step: 0
Training loss: 3.699807528051818
Validation loss: 3.4203417996397074

Epoch: 6| Step: 1
Training loss: 4.143041287167886
Validation loss: 3.419723690811779

Epoch: 6| Step: 2
Training loss: 3.884337465407198
Validation loss: 3.4180687539373733

Epoch: 6| Step: 3
Training loss: 3.1445778031783056
Validation loss: 3.417925713474738

Epoch: 6| Step: 4
Training loss: 2.419681663382978
Validation loss: 3.412378329166748

Epoch: 6| Step: 5
Training loss: 3.0979728777432687
Validation loss: 3.410688726616087

Epoch: 6| Step: 6
Training loss: 3.4458970592530402
Validation loss: 3.409782484377339

Epoch: 6| Step: 7
Training loss: 3.049582975050246
Validation loss: 3.408086612184992

Epoch: 6| Step: 8
Training loss: 3.687507500075132
Validation loss: 3.4072808185498915

Epoch: 6| Step: 9
Training loss: 3.8182086417259193
Validation loss: 3.4064518339162317

Epoch: 6| Step: 10
Training loss: 4.056117281630765
Validation loss: 3.4051529321006577

Epoch: 6| Step: 11
Training loss: 3.9534235302530014
Validation loss: 3.4046414895536636

Epoch: 6| Step: 12
Training loss: 3.703032029670896
Validation loss: 3.402651572438501

Epoch: 6| Step: 13
Training loss: 4.824566069544432
Validation loss: 3.40198721180239

Epoch: 16| Step: 0
Training loss: 3.965978420612456
Validation loss: 3.3999944247104166

Epoch: 6| Step: 1
Training loss: 3.386556548883993
Validation loss: 3.3984229483909933

Epoch: 6| Step: 2
Training loss: 3.43855574607952
Validation loss: 3.3975566268843083

Epoch: 6| Step: 3
Training loss: 3.0387169805793897
Validation loss: 3.395876552705112

Epoch: 6| Step: 4
Training loss: 3.795448694655509
Validation loss: 3.392498271799419

Epoch: 6| Step: 5
Training loss: 4.018346198457059
Validation loss: 3.3920134326262916

Epoch: 6| Step: 6
Training loss: 3.3014537961281163
Validation loss: 3.389409200695886

Epoch: 6| Step: 7
Training loss: 2.698200746011606
Validation loss: 3.387488502882821

Epoch: 6| Step: 8
Training loss: 4.279871363622995
Validation loss: 3.38570238950704

Epoch: 6| Step: 9
Training loss: 4.071678708454636
Validation loss: 3.3831030808866958

Epoch: 6| Step: 10
Training loss: 3.6619445275397497
Validation loss: 3.380211698724239

Epoch: 6| Step: 11
Training loss: 3.5374404524788803
Validation loss: 3.377395953761689

Epoch: 6| Step: 12
Training loss: 4.008405912909331
Validation loss: 3.374622080740633

Epoch: 6| Step: 13
Training loss: 2.597674422810023
Validation loss: 3.3708442463808375

Epoch: 17| Step: 0
Training loss: 3.5827478921208082
Validation loss: 3.36702751626809

Epoch: 6| Step: 1
Training loss: 2.976254264511264
Validation loss: 3.3663037363289225

Epoch: 6| Step: 2
Training loss: 4.303588948556166
Validation loss: 3.3636077580975736

Epoch: 6| Step: 3
Training loss: 3.9424961424369056
Validation loss: 3.3615583554850783

Epoch: 6| Step: 4
Training loss: 3.1904352174634507
Validation loss: 3.360123005662464

Epoch: 6| Step: 5
Training loss: 3.109887622385212
Validation loss: 3.3573837571608443

Epoch: 6| Step: 6
Training loss: 3.5871372584468384
Validation loss: 3.3568196740353833

Epoch: 6| Step: 7
Training loss: 3.6952926280352307
Validation loss: 3.355353485113736

Epoch: 6| Step: 8
Training loss: 3.0077072323299947
Validation loss: 3.352847576279421

Epoch: 6| Step: 9
Training loss: 3.1304013684120373
Validation loss: 3.351316216229759

Epoch: 6| Step: 10
Training loss: 3.5358082206985677
Validation loss: 3.350291748150337

Epoch: 6| Step: 11
Training loss: 4.573328415299896
Validation loss: 3.3490422845825014

Epoch: 6| Step: 12
Training loss: 3.6508451763542347
Validation loss: 3.347049042888289

Epoch: 6| Step: 13
Training loss: 3.6150662029108434
Validation loss: 3.345498881307574

Epoch: 18| Step: 0
Training loss: 3.239629632715062
Validation loss: 3.34423017346109

Epoch: 6| Step: 1
Training loss: 3.124574556000522
Validation loss: 3.3435369804579573

Epoch: 6| Step: 2
Training loss: 3.829051127608744
Validation loss: 3.341709011266725

Epoch: 6| Step: 3
Training loss: 3.172712093445144
Validation loss: 3.3390110780046887

Epoch: 6| Step: 4
Training loss: 4.091397373844678
Validation loss: 3.3384532513935663

Epoch: 6| Step: 5
Training loss: 3.352463109939231
Validation loss: 3.3377262061710824

Epoch: 6| Step: 6
Training loss: 3.3985068127809535
Validation loss: 3.334915184697235

Epoch: 6| Step: 7
Training loss: 3.890613724412627
Validation loss: 3.3337669633997855

Epoch: 6| Step: 8
Training loss: 4.273304492617053
Validation loss: 3.331302476904527

Epoch: 6| Step: 9
Training loss: 3.219539952792851
Validation loss: 3.3295887731247746

Epoch: 6| Step: 10
Training loss: 3.193497345069939
Validation loss: 3.3278839472344215

Epoch: 6| Step: 11
Training loss: 3.549094560160443
Validation loss: 3.3259796726189044

Epoch: 6| Step: 12
Training loss: 3.477914337331698
Validation loss: 3.3255896456344725

Epoch: 6| Step: 13
Training loss: 4.222425653899659
Validation loss: 3.325014592719348

Epoch: 19| Step: 0
Training loss: 4.18669803968042
Validation loss: 3.3233862484756638

Epoch: 6| Step: 1
Training loss: 4.312947567920669
Validation loss: 3.320696879558541

Epoch: 6| Step: 2
Training loss: 2.7212199249498097
Validation loss: 3.3196815272419244

Epoch: 6| Step: 3
Training loss: 3.17989504275065
Validation loss: 3.3183159010676953

Epoch: 6| Step: 4
Training loss: 3.553587623882427
Validation loss: 3.3166813292982864

Epoch: 6| Step: 5
Training loss: 3.156934607257799
Validation loss: 3.315620269993152

Epoch: 6| Step: 6
Training loss: 3.296234502542553
Validation loss: 3.314164374880009

Epoch: 6| Step: 7
Training loss: 3.375092681742468
Validation loss: 3.313182238151867

Epoch: 6| Step: 8
Training loss: 3.2919474292882116
Validation loss: 3.311841145778706

Epoch: 6| Step: 9
Training loss: 2.963115766567608
Validation loss: 3.310146682280377

Epoch: 6| Step: 10
Training loss: 3.8033169073429396
Validation loss: 3.3082620447888984

Epoch: 6| Step: 11
Training loss: 3.8386099337852606
Validation loss: 3.306788440518613

Epoch: 6| Step: 12
Training loss: 4.342399551907701
Validation loss: 3.3053201328638733

Epoch: 6| Step: 13
Training loss: 3.14259329840184
Validation loss: 3.304697729140608

Epoch: 20| Step: 0
Training loss: 2.945575894586497
Validation loss: 3.302720538115616

Epoch: 6| Step: 1
Training loss: 3.66270450893369
Validation loss: 3.3016069298310184

Epoch: 6| Step: 2
Training loss: 4.132998947235719
Validation loss: 3.2991054579129493

Epoch: 6| Step: 3
Training loss: 2.813513424865898
Validation loss: 3.2969766023896794

Epoch: 6| Step: 4
Training loss: 3.1005081191021984
Validation loss: 3.2968757138341154

Epoch: 6| Step: 5
Training loss: 3.731095154582803
Validation loss: 3.293943035226281

Epoch: 6| Step: 6
Training loss: 4.469112781657651
Validation loss: 3.29354046538847

Epoch: 6| Step: 7
Training loss: 3.6168569986446824
Validation loss: 3.291662581973321

Epoch: 6| Step: 8
Training loss: 3.515678981790421
Validation loss: 3.2900995647027838

Epoch: 6| Step: 9
Training loss: 3.697136652531285
Validation loss: 3.2887743549235005

Epoch: 6| Step: 10
Training loss: 3.312588096742733
Validation loss: 3.2878506447923606

Epoch: 6| Step: 11
Training loss: 3.1782863819779834
Validation loss: 3.2854365629079236

Epoch: 6| Step: 12
Training loss: 3.364123585629643
Validation loss: 3.2846907163549712

Epoch: 6| Step: 13
Training loss: 3.7371103651384963
Validation loss: 3.2834804159871616

Epoch: 21| Step: 0
Training loss: 3.17015412350063
Validation loss: 3.281338459156578

Epoch: 6| Step: 1
Training loss: 3.9531385097348206
Validation loss: 3.280200680697055

Epoch: 6| Step: 2
Training loss: 4.228686125315468
Validation loss: 3.279427961919184

Epoch: 6| Step: 3
Training loss: 3.7031587365782603
Validation loss: 3.278079133814734

Epoch: 6| Step: 4
Training loss: 3.7029897930716436
Validation loss: 3.276489532911826

Epoch: 6| Step: 5
Training loss: 3.1040975746470485
Validation loss: 3.2754990706641447

Epoch: 6| Step: 6
Training loss: 3.8097922293012694
Validation loss: 3.276113829820657

Epoch: 6| Step: 7
Training loss: 2.9228049037789368
Validation loss: 3.271976493513929

Epoch: 6| Step: 8
Training loss: 4.161600899034731
Validation loss: 3.27099953401539

Epoch: 6| Step: 9
Training loss: 4.231224549074698
Validation loss: 3.270795122911904

Epoch: 6| Step: 10
Training loss: 2.0951194270287274
Validation loss: 3.268500296578112

Epoch: 6| Step: 11
Training loss: 3.557073107028462
Validation loss: 3.2678480762102535

Epoch: 6| Step: 12
Training loss: 2.601191680415759
Validation loss: 3.2673446398955535

Epoch: 6| Step: 13
Training loss: 3.192577282620637
Validation loss: 3.2659221721402845

Epoch: 22| Step: 0
Training loss: 4.080235662199186
Validation loss: 3.268870988077775

Epoch: 6| Step: 1
Training loss: 3.928325075624505
Validation loss: 3.2637333325737043

Epoch: 6| Step: 2
Training loss: 3.268687295403437
Validation loss: 3.2633304030569383

Epoch: 6| Step: 3
Training loss: 3.3516371925407387
Validation loss: 3.2634292618111806

Epoch: 6| Step: 4
Training loss: 3.2886662550340238
Validation loss: 3.2624491455857045

Epoch: 6| Step: 5
Training loss: 3.54212505889633
Validation loss: 3.2622767092468523

Epoch: 6| Step: 6
Training loss: 3.1321055692027464
Validation loss: 3.2592240718715635

Epoch: 6| Step: 7
Training loss: 3.945487382997453
Validation loss: 3.2587302431013767

Epoch: 6| Step: 8
Training loss: 2.924865008768617
Validation loss: 3.257031661311978

Epoch: 6| Step: 9
Training loss: 2.993107507367415
Validation loss: 3.257022212835566

Epoch: 6| Step: 10
Training loss: 2.921928364475499
Validation loss: 3.2614973559372937

Epoch: 6| Step: 11
Training loss: 4.185413353125762
Validation loss: 3.2548685658324636

Epoch: 6| Step: 12
Training loss: 3.5388892259768956
Validation loss: 3.2539022618221445

Epoch: 6| Step: 13
Training loss: 3.893408335089593
Validation loss: 3.2526296132517594

Epoch: 23| Step: 0
Training loss: 2.95870057812935
Validation loss: 3.2513590306873223

Epoch: 6| Step: 1
Training loss: 3.1079705675221545
Validation loss: 3.2508405051358746

Epoch: 6| Step: 2
Training loss: 3.469966091023306
Validation loss: 3.249907786510168

Epoch: 6| Step: 3
Training loss: 3.570277508119691
Validation loss: 3.2490458685245254

Epoch: 6| Step: 4
Training loss: 3.7352518624357955
Validation loss: 3.2485187805740323

Epoch: 6| Step: 5
Training loss: 4.547409393263532
Validation loss: 3.2466922394521363

Epoch: 6| Step: 6
Training loss: 2.9191300661357276
Validation loss: 3.2456421138664617

Epoch: 6| Step: 7
Training loss: 3.808429734048479
Validation loss: 3.243861000156164

Epoch: 6| Step: 8
Training loss: 3.6787397131871633
Validation loss: 3.242267465426896

Epoch: 6| Step: 9
Training loss: 3.6287306957670946
Validation loss: 3.2414662908769634

Epoch: 6| Step: 10
Training loss: 3.02766710092699
Validation loss: 3.2401892911048047

Epoch: 6| Step: 11
Training loss: 3.548612328761606
Validation loss: 3.2394417589807203

Epoch: 6| Step: 12
Training loss: 3.1540498524598113
Validation loss: 3.2380102700234366

Epoch: 6| Step: 13
Training loss: 3.4969263204263714
Validation loss: 3.237219428205829

Epoch: 24| Step: 0
Training loss: 2.184828407480894
Validation loss: 3.2355513194954484

Epoch: 6| Step: 1
Training loss: 3.4329223670793305
Validation loss: 3.235108925437598

Epoch: 6| Step: 2
Training loss: 4.098121929344992
Validation loss: 3.2338491215117693

Epoch: 6| Step: 3
Training loss: 2.772805843149666
Validation loss: 3.2337125781809135

Epoch: 6| Step: 4
Training loss: 3.456281781179817
Validation loss: 3.232090988550408

Epoch: 6| Step: 5
Training loss: 3.442394309599595
Validation loss: 3.2314926619649937

Epoch: 6| Step: 6
Training loss: 3.7514991306861663
Validation loss: 3.2311283822967263

Epoch: 6| Step: 7
Training loss: 3.4551284984757085
Validation loss: 3.2294736064645

Epoch: 6| Step: 8
Training loss: 2.9562668007500266
Validation loss: 3.2285880203824675

Epoch: 6| Step: 9
Training loss: 4.1231356945075515
Validation loss: 3.2274394110136666

Epoch: 6| Step: 10
Training loss: 3.479121331625751
Validation loss: 3.22598197895278

Epoch: 6| Step: 11
Training loss: 3.8797017767432647
Validation loss: 3.224271470664831

Epoch: 6| Step: 12
Training loss: 3.669590015846377
Validation loss: 3.2231586139073776

Epoch: 6| Step: 13
Training loss: 3.678111652100488
Validation loss: 3.221123578150359

Epoch: 25| Step: 0
Training loss: 4.0398484430118025
Validation loss: 3.220095318169612

Epoch: 6| Step: 1
Training loss: 3.5060911309192386
Validation loss: 3.2196825466432872

Epoch: 6| Step: 2
Training loss: 3.8983072324098926
Validation loss: 3.2170645066789643

Epoch: 6| Step: 3
Training loss: 3.8499741441923616
Validation loss: 3.216474634230196

Epoch: 6| Step: 4
Training loss: 3.2616610036523697
Validation loss: 3.215218798603944

Epoch: 6| Step: 5
Training loss: 3.036412827078247
Validation loss: 3.2128411254401055

Epoch: 6| Step: 6
Training loss: 3.4955585091329087
Validation loss: 3.2128150192717135

Epoch: 6| Step: 7
Training loss: 3.1155681945458555
Validation loss: 3.2116965692652175

Epoch: 6| Step: 8
Training loss: 3.2624790059433626
Validation loss: 3.2094145493694035

Epoch: 6| Step: 9
Training loss: 3.281071249316421
Validation loss: 3.207967786629301

Epoch: 6| Step: 10
Training loss: 3.5400435075403127
Validation loss: 3.2063886797526386

Epoch: 6| Step: 11
Training loss: 3.378810285848246
Validation loss: 3.204654331515308

Epoch: 6| Step: 12
Training loss: 2.8899647551502667
Validation loss: 3.20291287780028

Epoch: 6| Step: 13
Training loss: 4.103687832907866
Validation loss: 3.2015715066581945

Epoch: 26| Step: 0
Training loss: 3.6197552063933034
Validation loss: 3.200182334835061

Epoch: 6| Step: 1
Training loss: 3.7156222998735196
Validation loss: 3.1965574904984946

Epoch: 6| Step: 2
Training loss: 3.2922872288340144
Validation loss: 3.192720517001751

Epoch: 6| Step: 3
Training loss: 3.9109587098421703
Validation loss: 3.1875483947335828

Epoch: 6| Step: 4
Training loss: 2.9687628494787712
Validation loss: 3.1884878728132957

Epoch: 6| Step: 5
Training loss: 3.776508984642296
Validation loss: 3.1768342384286523

Epoch: 6| Step: 6
Training loss: 3.3066585064859093
Validation loss: 3.175654144764647

Epoch: 6| Step: 7
Training loss: 3.0417390231231276
Validation loss: 3.173979061301918

Epoch: 6| Step: 8
Training loss: 3.7823104002052736
Validation loss: 3.173036758698736

Epoch: 6| Step: 9
Training loss: 2.5101137624849708
Validation loss: 3.1721704712049865

Epoch: 6| Step: 10
Training loss: 3.6248834525479112
Validation loss: 3.170598567203522

Epoch: 6| Step: 11
Training loss: 3.65477207668209
Validation loss: 3.1702407659226743

Epoch: 6| Step: 12
Training loss: 3.083656878292718
Validation loss: 3.1673393787108575

Epoch: 6| Step: 13
Training loss: 3.7884664479633114
Validation loss: 3.16628487627258

Epoch: 27| Step: 0
Training loss: 2.7267873064725805
Validation loss: 3.166918193000826

Epoch: 6| Step: 1
Training loss: 3.0035935178358844
Validation loss: 3.168636941782997

Epoch: 6| Step: 2
Training loss: 2.345338003692112
Validation loss: 3.1737951317169513

Epoch: 6| Step: 3
Training loss: 3.813279119208455
Validation loss: 3.170140838475686

Epoch: 6| Step: 4
Training loss: 3.4415358000498704
Validation loss: 3.160740278068068

Epoch: 6| Step: 5
Training loss: 3.6807798801093594
Validation loss: 3.1617030964483055

Epoch: 6| Step: 6
Training loss: 3.874392307991743
Validation loss: 3.1602173535207916

Epoch: 6| Step: 7
Training loss: 3.147699236392843
Validation loss: 3.159302244357598

Epoch: 6| Step: 8
Training loss: 3.675955854397798
Validation loss: 3.1592000460789316

Epoch: 6| Step: 9
Training loss: 4.090177884885311
Validation loss: 3.1587366644066357

Epoch: 6| Step: 10
Training loss: 4.310348637546302
Validation loss: 3.157454170084958

Epoch: 6| Step: 11
Training loss: 2.792996663841061
Validation loss: 3.155578015413282

Epoch: 6| Step: 12
Training loss: 2.8274179491572005
Validation loss: 3.155901595308669

Epoch: 6| Step: 13
Training loss: 3.781284805011562
Validation loss: 3.152485260295126

Epoch: 28| Step: 0
Training loss: 3.438826565099849
Validation loss: 3.152351411610215

Epoch: 6| Step: 1
Training loss: 3.648173222578456
Validation loss: 3.188542790017112

Epoch: 6| Step: 2
Training loss: 3.5967320550508175
Validation loss: 3.148790441547751

Epoch: 6| Step: 3
Training loss: 2.9211947215264886
Validation loss: 3.145978296910349

Epoch: 6| Step: 4
Training loss: 4.117180319387121
Validation loss: 3.1479097041652615

Epoch: 6| Step: 5
Training loss: 3.181283910904109
Validation loss: 3.1631504726947055

Epoch: 6| Step: 6
Training loss: 4.094464654641126
Validation loss: 3.179647215993439

Epoch: 6| Step: 7
Training loss: 3.9687814786368496
Validation loss: 3.1968639025512946

Epoch: 6| Step: 8
Training loss: 3.9512826599489785
Validation loss: 3.3045885644390283

Epoch: 6| Step: 9
Training loss: 2.527952330248494
Validation loss: 3.3207796435815746

Epoch: 6| Step: 10
Training loss: 3.5217511186585093
Validation loss: 3.392973702061822

Epoch: 6| Step: 11
Training loss: 3.290558608382503
Validation loss: 3.336950928352007

Epoch: 6| Step: 12
Training loss: 3.3281400438425397
Validation loss: 3.2997077374324726

Epoch: 6| Step: 13
Training loss: 1.9692844694752225
Validation loss: 3.240912966047776

Epoch: 29| Step: 0
Training loss: 2.2358274207485453
Validation loss: 3.167700406649757

Epoch: 6| Step: 1
Training loss: 2.5113513731254966
Validation loss: 3.18885310674751

Epoch: 6| Step: 2
Training loss: 3.230555688871332
Validation loss: 3.250050827525006

Epoch: 6| Step: 3
Training loss: 3.688633114272682
Validation loss: 3.279266642431422

Epoch: 6| Step: 4
Training loss: 3.3161974730000083
Validation loss: 3.261721765011927

Epoch: 6| Step: 5
Training loss: 3.73999953366853
Validation loss: 3.2170959023257426

Epoch: 6| Step: 6
Training loss: 2.945570552459506
Validation loss: 3.181721096904235

Epoch: 6| Step: 7
Training loss: 3.22344450586975
Validation loss: 3.190180888690067

Epoch: 6| Step: 8
Training loss: 4.490719019490277
Validation loss: 3.181982687437238

Epoch: 6| Step: 9
Training loss: 4.371334174995367
Validation loss: 3.1848903664645554

Epoch: 6| Step: 10
Training loss: 2.558158359901892
Validation loss: 3.162071127416594

Epoch: 6| Step: 11
Training loss: 3.7355655065365254
Validation loss: 3.1890751137722932

Epoch: 6| Step: 12
Training loss: 4.105860146141469
Validation loss: 3.2516462985469325

Epoch: 6| Step: 13
Training loss: 3.8635853646732317
Validation loss: 3.2794773796491175

Epoch: 30| Step: 0
Training loss: 3.8603697201460774
Validation loss: 3.258545478397983

Epoch: 6| Step: 1
Training loss: 3.71677275593199
Validation loss: 3.2278509952275525

Epoch: 6| Step: 2
Training loss: 3.5477492813583806
Validation loss: 3.2003774300510632

Epoch: 6| Step: 3
Training loss: 3.200839087625019
Validation loss: 3.1745969589356156

Epoch: 6| Step: 4
Training loss: 3.668643779614159
Validation loss: 3.1701332061114864

Epoch: 6| Step: 5
Training loss: 3.3361830609817913
Validation loss: 3.1524135764186387

Epoch: 6| Step: 6
Training loss: 3.111100681226898
Validation loss: 3.144964014223706

Epoch: 6| Step: 7
Training loss: 3.0011314801475812
Validation loss: 3.144342388763459

Epoch: 6| Step: 8
Training loss: 3.35032819592137
Validation loss: 3.1498366137567606

Epoch: 6| Step: 9
Training loss: 3.5930654122492203
Validation loss: 3.143857421096577

Epoch: 6| Step: 10
Training loss: 3.013220584526733
Validation loss: 3.124454204518681

Epoch: 6| Step: 11
Training loss: 3.681192337387617
Validation loss: 3.110156829106338

Epoch: 6| Step: 12
Training loss: 3.5004273562424584
Validation loss: 3.107291539522464

Epoch: 6| Step: 13
Training loss: 3.177653043769434
Validation loss: 3.104749960204258

Epoch: 31| Step: 0
Training loss: 2.982445217758192
Validation loss: 3.106924703316808

Epoch: 6| Step: 1
Training loss: 3.1977890602191423
Validation loss: 3.1176989595266607

Epoch: 6| Step: 2
Training loss: 3.2537547210178426
Validation loss: 3.1112355654396024

Epoch: 6| Step: 3
Training loss: 3.07816093927306
Validation loss: 3.106423936412051

Epoch: 6| Step: 4
Training loss: 3.703982740769846
Validation loss: 3.0983841718939926

Epoch: 6| Step: 5
Training loss: 2.9767387117707016
Validation loss: 3.0923670228525526

Epoch: 6| Step: 6
Training loss: 3.436487222075798
Validation loss: 3.0890534899640882

Epoch: 6| Step: 7
Training loss: 4.132288187440767
Validation loss: 3.0850346399358446

Epoch: 6| Step: 8
Training loss: 3.2751477856087847
Validation loss: 3.0833991846592754

Epoch: 6| Step: 9
Training loss: 3.3256016868056624
Validation loss: 3.0810107557697974

Epoch: 6| Step: 10
Training loss: 3.5891843237854784
Validation loss: 3.0796041183541343

Epoch: 6| Step: 11
Training loss: 3.46383098263959
Validation loss: 3.0785483874953736

Epoch: 6| Step: 12
Training loss: 2.8763933537123814
Validation loss: 3.078450393697141

Epoch: 6| Step: 13
Training loss: 3.9264214292626995
Validation loss: 3.077196544931507

Epoch: 32| Step: 0
Training loss: 3.382774440912492
Validation loss: 3.0755529097850105

Epoch: 6| Step: 1
Training loss: 2.0346768156792603
Validation loss: 3.0752771509612504

Epoch: 6| Step: 2
Training loss: 3.495640082733446
Validation loss: 3.073932452423759

Epoch: 6| Step: 3
Training loss: 3.4609129756291086
Validation loss: 3.07327652470596

Epoch: 6| Step: 4
Training loss: 3.518887781728475
Validation loss: 3.072950551447741

Epoch: 6| Step: 5
Training loss: 3.219724341019479
Validation loss: 3.0719239970482333

Epoch: 6| Step: 6
Training loss: 3.5103614568849455
Validation loss: 3.071441795901993

Epoch: 6| Step: 7
Training loss: 3.0014498703897905
Validation loss: 3.07027995742994

Epoch: 6| Step: 8
Training loss: 3.891483074380316
Validation loss: 3.0689682307509885

Epoch: 6| Step: 9
Training loss: 3.3219039154947416
Validation loss: 3.068198164394347

Epoch: 6| Step: 10
Training loss: 3.605729016202029
Validation loss: 3.067331480466255

Epoch: 6| Step: 11
Training loss: 3.488985441239285
Validation loss: 3.0662277342150177

Epoch: 6| Step: 12
Training loss: 3.3797291718275804
Validation loss: 3.065480370636957

Epoch: 6| Step: 13
Training loss: 3.3087091887421147
Validation loss: 3.0640830409672177

Epoch: 33| Step: 0
Training loss: 2.7888323691603207
Validation loss: 3.063706343533202

Epoch: 6| Step: 1
Training loss: 3.5829972989335395
Validation loss: 3.062331729306771

Epoch: 6| Step: 2
Training loss: 3.6822884149100887
Validation loss: 3.061927807250711

Epoch: 6| Step: 3
Training loss: 2.2199871214072093
Validation loss: 3.060419051610324

Epoch: 6| Step: 4
Training loss: 3.062958663536962
Validation loss: 3.0593937524977095

Epoch: 6| Step: 5
Training loss: 3.4833032986990293
Validation loss: 3.058851287249801

Epoch: 6| Step: 6
Training loss: 3.5005603069313604
Validation loss: 3.058447638979132

Epoch: 6| Step: 7
Training loss: 3.02122586210281
Validation loss: 3.057480611991471

Epoch: 6| Step: 8
Training loss: 2.7204280366415072
Validation loss: 3.056605663936369

Epoch: 6| Step: 9
Training loss: 3.7103119332926693
Validation loss: 3.055629474520156

Epoch: 6| Step: 10
Training loss: 4.348038785956225
Validation loss: 3.0541560872078297

Epoch: 6| Step: 11
Training loss: 3.844040650334403
Validation loss: 3.053273560071059

Epoch: 6| Step: 12
Training loss: 2.816906422976611
Validation loss: 3.0518152380349752

Epoch: 6| Step: 13
Training loss: 3.559548745004963
Validation loss: 3.049694319169581

Epoch: 34| Step: 0
Training loss: 2.773226103986876
Validation loss: 3.0516564877332253

Epoch: 6| Step: 1
Training loss: 3.699733291498545
Validation loss: 3.0505607430439103

Epoch: 6| Step: 2
Training loss: 2.978945121441491
Validation loss: 3.0474019636396066

Epoch: 6| Step: 3
Training loss: 3.4364220055984864
Validation loss: 3.0450195636973154

Epoch: 6| Step: 4
Training loss: 3.3621091140387085
Validation loss: 3.046123622131151

Epoch: 6| Step: 5
Training loss: 3.8717204336329525
Validation loss: 3.0458526031861832

Epoch: 6| Step: 6
Training loss: 3.535186463959283
Validation loss: 3.044034750500161

Epoch: 6| Step: 7
Training loss: 3.177669250158569
Validation loss: 3.043405118352017

Epoch: 6| Step: 8
Training loss: 2.113252819384774
Validation loss: 3.0423291493928617

Epoch: 6| Step: 9
Training loss: 3.364421797300595
Validation loss: 3.0421868903596123

Epoch: 6| Step: 10
Training loss: 3.4002405754695264
Validation loss: 3.040651191232958

Epoch: 6| Step: 11
Training loss: 3.2813369012860005
Validation loss: 3.038390024916857

Epoch: 6| Step: 12
Training loss: 3.5779582821848517
Validation loss: 3.0397693151518155

Epoch: 6| Step: 13
Training loss: 4.034959372844159
Validation loss: 3.037059142712195

Epoch: 35| Step: 0
Training loss: 3.7094649113570095
Validation loss: 3.0358610747632153

Epoch: 6| Step: 1
Training loss: 3.17979517199071
Validation loss: 3.0336543701553214

Epoch: 6| Step: 2
Training loss: 2.9260015875811387
Validation loss: 3.033810286046355

Epoch: 6| Step: 3
Training loss: 2.761454222877654
Validation loss: 3.032371136905414

Epoch: 6| Step: 4
Training loss: 3.4767093927446857
Validation loss: 3.032036629661866

Epoch: 6| Step: 5
Training loss: 2.7412531203614448
Validation loss: 3.033612135957133

Epoch: 6| Step: 6
Training loss: 2.730722571105578
Validation loss: 3.0347506952621193

Epoch: 6| Step: 7
Training loss: 3.903627537673242
Validation loss: 3.036379843510225

Epoch: 6| Step: 8
Training loss: 2.5233097575542245
Validation loss: 3.0368989068906447

Epoch: 6| Step: 9
Training loss: 3.832451318082038
Validation loss: 3.03571129896376

Epoch: 6| Step: 10
Training loss: 3.3705977940323497
Validation loss: 3.035704463619875

Epoch: 6| Step: 11
Training loss: 4.075660867286059
Validation loss: 3.033551021793885

Epoch: 6| Step: 12
Training loss: 3.4496956621915453
Validation loss: 3.032693218053628

Epoch: 6| Step: 13
Training loss: 3.4963970713391164
Validation loss: 3.0278655664108407

Epoch: 36| Step: 0
Training loss: 3.4232715561247336
Validation loss: 3.0592338669481927

Epoch: 6| Step: 1
Training loss: 3.444929244334943
Validation loss: 3.034918804908147

Epoch: 6| Step: 2
Training loss: 3.2257577109500053
Validation loss: 3.0268853575737213

Epoch: 6| Step: 3
Training loss: 3.37833917522882
Validation loss: 3.0273146697733977

Epoch: 6| Step: 4
Training loss: 3.3820943796985437
Validation loss: 3.0255369411071618

Epoch: 6| Step: 5
Training loss: 3.3699107475800116
Validation loss: 3.0202706672574138

Epoch: 6| Step: 6
Training loss: 3.2643495834269687
Validation loss: 3.022253166334781

Epoch: 6| Step: 7
Training loss: 3.013002510421725
Validation loss: 3.022165289257035

Epoch: 6| Step: 8
Training loss: 3.5440070703233584
Validation loss: 3.0204221763194656

Epoch: 6| Step: 9
Training loss: 2.9603631662844925
Validation loss: 3.022354977245797

Epoch: 6| Step: 10
Training loss: 3.2577144324455847
Validation loss: 3.021533215966395

Epoch: 6| Step: 11
Training loss: 3.1130545616184246
Validation loss: 3.021301205858953

Epoch: 6| Step: 12
Training loss: 3.9171778297989683
Validation loss: 3.0196166754264504

Epoch: 6| Step: 13
Training loss: 2.9184259467586062
Validation loss: 3.0207320323984312

Epoch: 37| Step: 0
Training loss: 3.4670359182552004
Validation loss: 3.019129204054032

Epoch: 6| Step: 1
Training loss: 2.152553984245304
Validation loss: 3.0177304225302644

Epoch: 6| Step: 2
Training loss: 3.921450770561204
Validation loss: 3.0164804573038966

Epoch: 6| Step: 3
Training loss: 4.030280418010977
Validation loss: 3.016446727153861

Epoch: 6| Step: 4
Training loss: 3.3682137538466232
Validation loss: 3.0133367859146083

Epoch: 6| Step: 5
Training loss: 3.2424454551938457
Validation loss: 3.013668860223563

Epoch: 6| Step: 6
Training loss: 2.3271037684550544
Validation loss: 3.0113223720659983

Epoch: 6| Step: 7
Training loss: 2.8545865680492692
Validation loss: 3.009517598582915

Epoch: 6| Step: 8
Training loss: 3.530751691109481
Validation loss: 3.0086774937731837

Epoch: 6| Step: 9
Training loss: 2.9399060074709316
Validation loss: 3.0087854106087564

Epoch: 6| Step: 10
Training loss: 3.195320259961543
Validation loss: 3.0077944135608203

Epoch: 6| Step: 11
Training loss: 2.8982382651895757
Validation loss: 3.007722973619856

Epoch: 6| Step: 12
Training loss: 4.320255989684668
Validation loss: 3.006833069338454

Epoch: 6| Step: 13
Training loss: 3.421684224981294
Validation loss: 3.004925850614106

Epoch: 38| Step: 0
Training loss: 3.285028806702349
Validation loss: 3.005723291329306

Epoch: 6| Step: 1
Training loss: 3.040142426416958
Validation loss: 3.0038896207606394

Epoch: 6| Step: 2
Training loss: 3.4254196132704005
Validation loss: 3.002042445994814

Epoch: 6| Step: 3
Training loss: 2.767551591593875
Validation loss: 3.0025255022377046

Epoch: 6| Step: 4
Training loss: 3.885551238946793
Validation loss: 3.0007790524718057

Epoch: 6| Step: 5
Training loss: 3.0213240301668525
Validation loss: 3.0022588569596182

Epoch: 6| Step: 6
Training loss: 3.8585875167224786
Validation loss: 3.001925308679699

Epoch: 6| Step: 7
Training loss: 3.4869244062906706
Validation loss: 3.002501279036884

Epoch: 6| Step: 8
Training loss: 2.9054332939214498
Validation loss: 3.0039415120465676

Epoch: 6| Step: 9
Training loss: 3.0258208745267257
Validation loss: 3.011778392818047

Epoch: 6| Step: 10
Training loss: 2.9438356293941794
Validation loss: 3.0139823646605146

Epoch: 6| Step: 11
Training loss: 3.523921823307757
Validation loss: 3.00108628448689

Epoch: 6| Step: 12
Training loss: 3.437003082424954
Validation loss: 3.0027351421623085

Epoch: 6| Step: 13
Training loss: 3.4366592766293516
Validation loss: 3.0004213696919377

Epoch: 39| Step: 0
Training loss: 3.5639978572697735
Validation loss: 2.997853844543026

Epoch: 6| Step: 1
Training loss: 3.070454601464702
Validation loss: 2.9945780756659133

Epoch: 6| Step: 2
Training loss: 3.0922770991748223
Validation loss: 2.9937404613491485

Epoch: 6| Step: 3
Training loss: 2.8582809940213525
Validation loss: 2.9937517032759313

Epoch: 6| Step: 4
Training loss: 3.0903407877428677
Validation loss: 2.9949114775087655

Epoch: 6| Step: 5
Training loss: 3.265587911440853
Validation loss: 2.995269135251927

Epoch: 6| Step: 6
Training loss: 3.759456409768338
Validation loss: 2.993031985798841

Epoch: 6| Step: 7
Training loss: 3.0614559963165915
Validation loss: 2.9903400588642888

Epoch: 6| Step: 8
Training loss: 2.5999217315043794
Validation loss: 2.992187189846322

Epoch: 6| Step: 9
Training loss: 3.2909569437924886
Validation loss: 2.992601439115038

Epoch: 6| Step: 10
Training loss: 3.5430306594301593
Validation loss: 2.9910128340306024

Epoch: 6| Step: 11
Training loss: 3.4736370679707558
Validation loss: 2.9882884546190778

Epoch: 6| Step: 12
Training loss: 3.7563136039845624
Validation loss: 2.992749132145448

Epoch: 6| Step: 13
Training loss: 3.3742706075800606
Validation loss: 2.990159573065509

Epoch: 40| Step: 0
Training loss: 3.2735508282329167
Validation loss: 2.9929091936577477

Epoch: 6| Step: 1
Training loss: 3.21710948432643
Validation loss: 2.99123252156551

Epoch: 6| Step: 2
Training loss: 3.0419446913928536
Validation loss: 2.989706455293849

Epoch: 6| Step: 3
Training loss: 3.0758027742353136
Validation loss: 2.993472814297751

Epoch: 6| Step: 4
Training loss: 3.799550561929167
Validation loss: 3.0218784435289203

Epoch: 6| Step: 5
Training loss: 2.3974460205111288
Validation loss: 2.993183578612001

Epoch: 6| Step: 6
Training loss: 3.3279566475997284
Validation loss: 3.0010889206628533

Epoch: 6| Step: 7
Training loss: 4.028085338790879
Validation loss: 3.015017521862621

Epoch: 6| Step: 8
Training loss: 3.8943533440668716
Validation loss: 3.0075181070936727

Epoch: 6| Step: 9
Training loss: 3.235990701235318
Validation loss: 2.9791295429110765

Epoch: 6| Step: 10
Training loss: 2.6843123938261964
Validation loss: 2.9819705612339305

Epoch: 6| Step: 11
Training loss: 2.08089337200323
Validation loss: 2.9901492628754145

Epoch: 6| Step: 12
Training loss: 3.304547101729129
Validation loss: 3.031775622333221

Epoch: 6| Step: 13
Training loss: 4.494047042091162
Validation loss: 2.9973980445404993

Epoch: 41| Step: 0
Training loss: 3.020476712628853
Validation loss: 2.9907212054425107

Epoch: 6| Step: 1
Training loss: 3.657065667355335
Validation loss: 2.982786599765434

Epoch: 6| Step: 2
Training loss: 2.686684684393253
Validation loss: 2.982268485256476

Epoch: 6| Step: 3
Training loss: 3.640966440324309
Validation loss: 2.9757124046722137

Epoch: 6| Step: 4
Training loss: 3.595291337900494
Validation loss: 2.9749605372862002

Epoch: 6| Step: 5
Training loss: 3.29038094306545
Validation loss: 2.9741507281331847

Epoch: 6| Step: 6
Training loss: 3.1992607812600693
Validation loss: 2.9730062201788736

Epoch: 6| Step: 7
Training loss: 3.2297338828422832
Validation loss: 2.9735831106278816

Epoch: 6| Step: 8
Training loss: 2.908279202749038
Validation loss: 2.9735952598595286

Epoch: 6| Step: 9
Training loss: 3.675263355187009
Validation loss: 2.973557990390803

Epoch: 6| Step: 10
Training loss: 3.5738403787089084
Validation loss: 2.973179295445269

Epoch: 6| Step: 11
Training loss: 3.535904509036052
Validation loss: 2.970199361562291

Epoch: 6| Step: 12
Training loss: 2.6188957446927557
Validation loss: 2.9704105355300934

Epoch: 6| Step: 13
Training loss: 2.5873767731298027
Validation loss: 2.9698909248916716

Epoch: 42| Step: 0
Training loss: 3.3554130434112777
Validation loss: 2.9701097881318423

Epoch: 6| Step: 1
Training loss: 3.3386650994980682
Validation loss: 2.971042216600749

Epoch: 6| Step: 2
Training loss: 2.615926227975935
Validation loss: 2.9755029036643976

Epoch: 6| Step: 3
Training loss: 2.822522172190345
Validation loss: 2.9729026019784413

Epoch: 6| Step: 4
Training loss: 2.5395168426129398
Validation loss: 2.978226785706917

Epoch: 6| Step: 5
Training loss: 2.9238724842159374
Validation loss: 2.998819830045772

Epoch: 6| Step: 6
Training loss: 3.883258264386339
Validation loss: 2.9646709923098538

Epoch: 6| Step: 7
Training loss: 3.668628052434503
Validation loss: 2.9639987803154932

Epoch: 6| Step: 8
Training loss: 3.430523538032514
Validation loss: 2.960942444697227

Epoch: 6| Step: 9
Training loss: 3.126340654805963
Validation loss: 2.9617710847651986

Epoch: 6| Step: 10
Training loss: 2.5508003175732585
Validation loss: 2.9608693937695856

Epoch: 6| Step: 11
Training loss: 4.095911518229017
Validation loss: 2.962505544762255

Epoch: 6| Step: 12
Training loss: 3.3072897763384526
Validation loss: 2.960025065043495

Epoch: 6| Step: 13
Training loss: 3.689548117614788
Validation loss: 2.9610278521943303

Epoch: 43| Step: 0
Training loss: 3.1018489061618904
Validation loss: 2.9566343036760743

Epoch: 6| Step: 1
Training loss: 3.3619854387992585
Validation loss: 2.955484821078037

Epoch: 6| Step: 2
Training loss: 3.730615231499111
Validation loss: 2.955931780770801

Epoch: 6| Step: 3
Training loss: 2.298835177479624
Validation loss: 2.9565249046774467

Epoch: 6| Step: 4
Training loss: 3.933448644876697
Validation loss: 2.9564942000531946

Epoch: 6| Step: 5
Training loss: 2.9036622370554492
Validation loss: 2.9542450684882056

Epoch: 6| Step: 6
Training loss: 2.9436112810563833
Validation loss: 2.9534856981066575

Epoch: 6| Step: 7
Training loss: 3.392687051854876
Validation loss: 2.955387198512891

Epoch: 6| Step: 8
Training loss: 3.1617851444528324
Validation loss: 2.953778452168203

Epoch: 6| Step: 9
Training loss: 3.1517861403708514
Validation loss: 2.952390884345187

Epoch: 6| Step: 10
Training loss: 3.2185255546462024
Validation loss: 2.9500775851389913

Epoch: 6| Step: 11
Training loss: 3.806102199848091
Validation loss: 2.9526676861929824

Epoch: 6| Step: 12
Training loss: 2.920676898621718
Validation loss: 2.9464951636098697

Epoch: 6| Step: 13
Training loss: 3.3184901363840633
Validation loss: 2.9464010916120387

Epoch: 44| Step: 0
Training loss: 3.200690856506348
Validation loss: 2.9514273652366185

Epoch: 6| Step: 1
Training loss: 3.215905719808006
Validation loss: 2.953800259422157

Epoch: 6| Step: 2
Training loss: 3.1885443079996785
Validation loss: 2.949638151616913

Epoch: 6| Step: 3
Training loss: 3.9023501040050874
Validation loss: 2.9488770393787185

Epoch: 6| Step: 4
Training loss: 3.9011548802135585
Validation loss: 2.9468302646609392

Epoch: 6| Step: 5
Training loss: 2.7252951575900703
Validation loss: 2.947767027712385

Epoch: 6| Step: 6
Training loss: 3.7099101682413953
Validation loss: 2.946587380295766

Epoch: 6| Step: 7
Training loss: 3.1708626470493226
Validation loss: 2.9455813185152304

Epoch: 6| Step: 8
Training loss: 2.6809079252124266
Validation loss: 2.9445152418992686

Epoch: 6| Step: 9
Training loss: 2.5378933606361276
Validation loss: 2.9443285452265706

Epoch: 6| Step: 10
Training loss: 2.9397220729328932
Validation loss: 2.9429678226542015

Epoch: 6| Step: 11
Training loss: 3.3429410437184415
Validation loss: 2.9466088127142185

Epoch: 6| Step: 12
Training loss: 2.806654726336792
Validation loss: 2.9449854238550435

Epoch: 6| Step: 13
Training loss: 4.0816085961664434
Validation loss: 2.943951613941463

Epoch: 45| Step: 0
Training loss: 3.0944068288504862
Validation loss: 2.944001619263864

Epoch: 6| Step: 1
Training loss: 2.766243558342661
Validation loss: 2.9454430556943

Epoch: 6| Step: 2
Training loss: 3.095068910537231
Validation loss: 2.9417687483741686

Epoch: 6| Step: 3
Training loss: 2.82357219296657
Validation loss: 2.9388736802257682

Epoch: 6| Step: 4
Training loss: 3.6523612445269515
Validation loss: 2.938870923690752

Epoch: 6| Step: 5
Training loss: 2.6059299043726996
Validation loss: 2.9405778161321314

Epoch: 6| Step: 6
Training loss: 4.133407809499191
Validation loss: 2.9391253715082537

Epoch: 6| Step: 7
Training loss: 2.764778050625397
Validation loss: 2.940802385426342

Epoch: 6| Step: 8
Training loss: 3.1431748396827914
Validation loss: 2.9391750045088663

Epoch: 6| Step: 9
Training loss: 3.4336547151779784
Validation loss: 2.9425493504321247

Epoch: 6| Step: 10
Training loss: 3.490837911671283
Validation loss: 2.941109047140428

Epoch: 6| Step: 11
Training loss: 2.8594625490887466
Validation loss: 2.942243359015944

Epoch: 6| Step: 12
Training loss: 4.0155076777912395
Validation loss: 2.9375490905806996

Epoch: 6| Step: 13
Training loss: 2.7992523148760395
Validation loss: 2.9387653028360745

Epoch: 46| Step: 0
Training loss: 3.3859654064991256
Validation loss: 2.936268342502328

Epoch: 6| Step: 1
Training loss: 3.3516936732234313
Validation loss: 2.932213730955643

Epoch: 6| Step: 2
Training loss: 3.798291856428535
Validation loss: 2.929228061323245

Epoch: 6| Step: 3
Training loss: 3.2537556003166244
Validation loss: 2.928996589818055

Epoch: 6| Step: 4
Training loss: 3.1045574650556893
Validation loss: 2.92953144710672

Epoch: 6| Step: 5
Training loss: 3.4109959568076884
Validation loss: 2.928544860058461

Epoch: 6| Step: 6
Training loss: 2.7888233926469344
Validation loss: 2.9266944048521943

Epoch: 6| Step: 7
Training loss: 2.958542955162474
Validation loss: 2.9292880149482956

Epoch: 6| Step: 8
Training loss: 2.732020557918249
Validation loss: 2.9331985709295347

Epoch: 6| Step: 9
Training loss: 3.3106963807502336
Validation loss: 2.942966597006032

Epoch: 6| Step: 10
Training loss: 3.1032054018666435
Validation loss: 2.9335550486160464

Epoch: 6| Step: 11
Training loss: 3.818469392796431
Validation loss: 2.9314019715984934

Epoch: 6| Step: 12
Training loss: 2.6582564012961085
Validation loss: 2.9232946323684157

Epoch: 6| Step: 13
Training loss: 3.0282050501081477
Validation loss: 2.922529746373463

Epoch: 47| Step: 0
Training loss: 3.307419821992099
Validation loss: 2.9218730170849874

Epoch: 6| Step: 1
Training loss: 3.347395291389472
Validation loss: 2.91825189243697

Epoch: 6| Step: 2
Training loss: 3.185426972902506
Validation loss: 2.9190427345566543

Epoch: 6| Step: 3
Training loss: 3.0831527313401956
Validation loss: 2.9181105161716507

Epoch: 6| Step: 4
Training loss: 2.8255615418954467
Validation loss: 2.9155644867170647

Epoch: 6| Step: 5
Training loss: 3.310909249156845
Validation loss: 2.9139108908440186

Epoch: 6| Step: 6
Training loss: 3.146619854217857
Validation loss: 2.9158872131255316

Epoch: 6| Step: 7
Training loss: 3.1525726046206746
Validation loss: 2.916946767433364

Epoch: 6| Step: 8
Training loss: 4.075698539913966
Validation loss: 2.9164554261622464

Epoch: 6| Step: 9
Training loss: 2.4742120124187945
Validation loss: 2.914841638782973

Epoch: 6| Step: 10
Training loss: 2.6274297459118006
Validation loss: 2.9145208443294015

Epoch: 6| Step: 11
Training loss: 3.1468362451646312
Validation loss: 2.9141760908469414

Epoch: 6| Step: 12
Training loss: 4.099574015747941
Validation loss: 2.912811092412793

Epoch: 6| Step: 13
Training loss: 2.4769259887036643
Validation loss: 2.9127469692506294

Epoch: 48| Step: 0
Training loss: 2.1209955069760977
Validation loss: 2.9116722270657664

Epoch: 6| Step: 1
Training loss: 3.2901877609985286
Validation loss: 2.9097463989375933

Epoch: 6| Step: 2
Training loss: 2.507769147551686
Validation loss: 2.907217742557013

Epoch: 6| Step: 3
Training loss: 3.451239299709225
Validation loss: 2.9083652514919254

Epoch: 6| Step: 4
Training loss: 2.8078518923637485
Validation loss: 2.955799408157944

Epoch: 6| Step: 5
Training loss: 3.448572117641406
Validation loss: 3.062952188638964

Epoch: 6| Step: 6
Training loss: 3.340973316158
Validation loss: 3.164012493395177

Epoch: 6| Step: 7
Training loss: 3.268348835531142
Validation loss: 3.098208345137922

Epoch: 6| Step: 8
Training loss: 3.0945128454033295
Validation loss: 3.0086270969474618

Epoch: 6| Step: 9
Training loss: 2.754467716201656
Validation loss: 2.947132026319498

Epoch: 6| Step: 10
Training loss: 4.04569654354611
Validation loss: 2.925698447384148

Epoch: 6| Step: 11
Training loss: 3.315211212195948
Validation loss: 2.9158958477110155

Epoch: 6| Step: 12
Training loss: 3.4767432690889435
Validation loss: 2.9091695595683227

Epoch: 6| Step: 13
Training loss: 4.510886269923633
Validation loss: 2.9251450945697877

Epoch: 49| Step: 0
Training loss: 2.841684450632718
Validation loss: 2.909176733633723

Epoch: 6| Step: 1
Training loss: 3.280924317681975
Validation loss: 2.9126576164066003

Epoch: 6| Step: 2
Training loss: 3.1602909922313502
Validation loss: 2.904579930936981

Epoch: 6| Step: 3
Training loss: 3.253659755350714
Validation loss: 2.902852612582558

Epoch: 6| Step: 4
Training loss: 2.9574045326128524
Validation loss: 2.9055506473112547

Epoch: 6| Step: 5
Training loss: 3.405994510693251
Validation loss: 2.9183382629296486

Epoch: 6| Step: 6
Training loss: 3.2701679370931385
Validation loss: 2.926399010537651

Epoch: 6| Step: 7
Training loss: 3.099568453868978
Validation loss: 2.9275537039268267

Epoch: 6| Step: 8
Training loss: 3.4321854169238906
Validation loss: 2.931775894110974

Epoch: 6| Step: 9
Training loss: 3.347673627525638
Validation loss: 2.922734796764286

Epoch: 6| Step: 10
Training loss: 3.266910135836663
Validation loss: 2.9171151767090415

Epoch: 6| Step: 11
Training loss: 3.227401365727617
Validation loss: 2.908340888403325

Epoch: 6| Step: 12
Training loss: 3.321529820506018
Validation loss: 2.904524696045798

Epoch: 6| Step: 13
Training loss: 2.9127369338163165
Validation loss: 2.902388970198297

Epoch: 50| Step: 0
Training loss: 2.6754351538262147
Validation loss: 2.9004667565248194

Epoch: 6| Step: 1
Training loss: 2.7078106791583156
Validation loss: 2.900883308628227

Epoch: 6| Step: 2
Training loss: 2.9936542153216505
Validation loss: 2.8977757927945587

Epoch: 6| Step: 3
Training loss: 2.908577591950821
Validation loss: 2.8945591816882943

Epoch: 6| Step: 4
Training loss: 3.6728275443328613
Validation loss: 2.8915034251213596

Epoch: 6| Step: 5
Training loss: 3.4946895912298555
Validation loss: 2.888335183349552

Epoch: 6| Step: 6
Training loss: 2.973105678595807
Validation loss: 2.8894395166108766

Epoch: 6| Step: 7
Training loss: 3.10750335644075
Validation loss: 2.8875255238573736

Epoch: 6| Step: 8
Training loss: 2.9219508849708835
Validation loss: 2.887726349152168

Epoch: 6| Step: 9
Training loss: 4.007710892428499
Validation loss: 2.8871907718556535

Epoch: 6| Step: 10
Training loss: 3.085596611413141
Validation loss: 2.8853983934966365

Epoch: 6| Step: 11
Training loss: 3.0794606675406144
Validation loss: 2.88846074449255

Epoch: 6| Step: 12
Training loss: 3.2811856218107858
Validation loss: 2.8857384420801977

Epoch: 6| Step: 13
Training loss: 3.710942639799072
Validation loss: 2.886636700788566

Epoch: 51| Step: 0
Training loss: 3.6014714095042546
Validation loss: 2.8846879939871304

Epoch: 6| Step: 1
Training loss: 2.9436671672594987
Validation loss: 2.8843670998119824

Epoch: 6| Step: 2
Training loss: 2.9782466579377838
Validation loss: 2.883745226394862

Epoch: 6| Step: 3
Training loss: 3.414204539960375
Validation loss: 2.88351158676059

Epoch: 6| Step: 4
Training loss: 3.6149106862285243
Validation loss: 2.8818973262799865

Epoch: 6| Step: 5
Training loss: 3.2004705083173905
Validation loss: 2.882022566580137

Epoch: 6| Step: 6
Training loss: 3.0477932059957205
Validation loss: 2.880543727973555

Epoch: 6| Step: 7
Training loss: 3.438755846368721
Validation loss: 2.882982099361745

Epoch: 6| Step: 8
Training loss: 3.396045904390723
Validation loss: 2.8812107986005313

Epoch: 6| Step: 9
Training loss: 2.6568412571507243
Validation loss: 2.893887820129376

Epoch: 6| Step: 10
Training loss: 3.3110492336399786
Validation loss: 2.8846097014470855

Epoch: 6| Step: 11
Training loss: 3.0263207066755697
Validation loss: 2.8759028250868597

Epoch: 6| Step: 12
Training loss: 2.95952707481986
Validation loss: 2.871572593396155

Epoch: 6| Step: 13
Training loss: 2.441551167573974
Validation loss: 2.8706055451071566

Epoch: 52| Step: 0
Training loss: 3.134582476152875
Validation loss: 2.8701427325309066

Epoch: 6| Step: 1
Training loss: 3.639565244009959
Validation loss: 2.8695685321108675

Epoch: 6| Step: 2
Training loss: 3.8935724453680196
Validation loss: 2.868312131739923

Epoch: 6| Step: 3
Training loss: 2.6368635123744735
Validation loss: 2.8690659273648103

Epoch: 6| Step: 4
Training loss: 3.1973461590727865
Validation loss: 2.8710728789455406

Epoch: 6| Step: 5
Training loss: 3.5311280626157253
Validation loss: 2.872822529483567

Epoch: 6| Step: 6
Training loss: 2.9960097160640182
Validation loss: 2.8721392444251865

Epoch: 6| Step: 7
Training loss: 2.7390752014109387
Validation loss: 2.864382665024955

Epoch: 6| Step: 8
Training loss: 2.572653125027758
Validation loss: 2.865863693050683

Epoch: 6| Step: 9
Training loss: 3.4608173564784295
Validation loss: 2.8627538667778234

Epoch: 6| Step: 10
Training loss: 3.180312936368052
Validation loss: 2.864493031500108

Epoch: 6| Step: 11
Training loss: 3.4649455884484253
Validation loss: 2.863526710594714

Epoch: 6| Step: 12
Training loss: 2.994006527798658
Validation loss: 2.862085304254261

Epoch: 6| Step: 13
Training loss: 2.2530349819279905
Validation loss: 2.8622557161884923

Epoch: 53| Step: 0
Training loss: 2.085687743818709
Validation loss: 2.864674568998011

Epoch: 6| Step: 1
Training loss: 3.658883214362379
Validation loss: 2.8630597872043393

Epoch: 6| Step: 2
Training loss: 3.638780380326628
Validation loss: 2.864851660070591

Epoch: 6| Step: 3
Training loss: 2.908683496361685
Validation loss: 2.8640892239567766

Epoch: 6| Step: 4
Training loss: 3.211276962268056
Validation loss: 2.866316421696775

Epoch: 6| Step: 5
Training loss: 2.932926107085138
Validation loss: 2.8639439977795234

Epoch: 6| Step: 6
Training loss: 3.6831163115166694
Validation loss: 2.8644362109635724

Epoch: 6| Step: 7
Training loss: 3.330828361237109
Validation loss: 2.8630261675723387

Epoch: 6| Step: 8
Training loss: 3.3344972167993743
Validation loss: 2.861925558931989

Epoch: 6| Step: 9
Training loss: 3.1484617322268464
Validation loss: 2.861525217259792

Epoch: 6| Step: 10
Training loss: 3.0090529224918003
Validation loss: 2.859677814309895

Epoch: 6| Step: 11
Training loss: 2.8538255882194474
Validation loss: 2.8589066291564755

Epoch: 6| Step: 12
Training loss: 3.2921452878500785
Validation loss: 2.857956160682057

Epoch: 6| Step: 13
Training loss: 2.8095511341998374
Validation loss: 2.857759041161356

Epoch: 54| Step: 0
Training loss: 3.676319954422846
Validation loss: 2.8555547624601303

Epoch: 6| Step: 1
Training loss: 3.412313681186634
Validation loss: 2.8538769441030034

Epoch: 6| Step: 2
Training loss: 3.2865905896319703
Validation loss: 2.8545003818204076

Epoch: 6| Step: 3
Training loss: 3.7016855009293437
Validation loss: 2.8497380197230555

Epoch: 6| Step: 4
Training loss: 3.1752755113145548
Validation loss: 2.8499356796355304

Epoch: 6| Step: 5
Training loss: 3.3018411413157587
Validation loss: 2.851674777663853

Epoch: 6| Step: 6
Training loss: 2.432957647228576
Validation loss: 2.855726107216761

Epoch: 6| Step: 7
Training loss: 2.5288330595486936
Validation loss: 2.8586061079212066

Epoch: 6| Step: 8
Training loss: 2.962794222486159
Validation loss: 2.8549343921224795

Epoch: 6| Step: 9
Training loss: 2.95221999091461
Validation loss: 2.8468315640522484

Epoch: 6| Step: 10
Training loss: 3.276484198264513
Validation loss: 2.846660825853013

Epoch: 6| Step: 11
Training loss: 2.753298082226086
Validation loss: 2.844622692086881

Epoch: 6| Step: 12
Training loss: 3.180124463698592
Validation loss: 2.848141799867813

Epoch: 6| Step: 13
Training loss: 3.4351489263286865
Validation loss: 2.8470612199710637

Epoch: 55| Step: 0
Training loss: 3.6702708534680903
Validation loss: 2.8468326834035733

Epoch: 6| Step: 1
Training loss: 3.4360337338018407
Validation loss: 2.845267003787953

Epoch: 6| Step: 2
Training loss: 2.9868728809464913
Validation loss: 2.846123759518721

Epoch: 6| Step: 3
Training loss: 3.1160972428628635
Validation loss: 2.8471878530564063

Epoch: 6| Step: 4
Training loss: 3.165366123229949
Validation loss: 2.8474172830648303

Epoch: 6| Step: 5
Training loss: 2.571336721868889
Validation loss: 2.847215108381526

Epoch: 6| Step: 6
Training loss: 2.618044402629685
Validation loss: 2.84698990691846

Epoch: 6| Step: 7
Training loss: 3.6695590893065217
Validation loss: 2.845910956124185

Epoch: 6| Step: 8
Training loss: 3.529872119089305
Validation loss: 2.845652252681039

Epoch: 6| Step: 9
Training loss: 3.3660235240746643
Validation loss: 2.845973037848094

Epoch: 6| Step: 10
Training loss: 3.1532073510174907
Validation loss: 2.8445437483246203

Epoch: 6| Step: 11
Training loss: 2.8775898422414024
Validation loss: 2.8449819232011637

Epoch: 6| Step: 12
Training loss: 2.9328135990878503
Validation loss: 2.842261889526555

Epoch: 6| Step: 13
Training loss: 2.61960456033363
Validation loss: 2.8427243191090232

Epoch: 56| Step: 0
Training loss: 3.21549645584948
Validation loss: 2.83955543991951

Epoch: 6| Step: 1
Training loss: 3.2381392978160384
Validation loss: 2.8342441136117507

Epoch: 6| Step: 2
Training loss: 3.8101531763398766
Validation loss: 2.8341767800765436

Epoch: 6| Step: 3
Training loss: 3.7348092437198313
Validation loss: 2.8454964228986603

Epoch: 6| Step: 4
Training loss: 3.439198022552653
Validation loss: 2.838935175557288

Epoch: 6| Step: 5
Training loss: 2.8446422476669917
Validation loss: 2.8475329346540046

Epoch: 6| Step: 6
Training loss: 1.6626483478184488
Validation loss: 2.847966958954185

Epoch: 6| Step: 7
Training loss: 3.597287899548599
Validation loss: 2.847458411150555

Epoch: 6| Step: 8
Training loss: 3.0283152737986136
Validation loss: 2.8566906012571764

Epoch: 6| Step: 9
Training loss: 3.3594371701187664
Validation loss: 2.847111102748007

Epoch: 6| Step: 10
Training loss: 2.8661548719495253
Validation loss: 2.8346079638121244

Epoch: 6| Step: 11
Training loss: 2.823987684914642
Validation loss: 2.8263774615373873

Epoch: 6| Step: 12
Training loss: 2.7351594508135193
Validation loss: 2.82451831189583

Epoch: 6| Step: 13
Training loss: 3.070221800107521
Validation loss: 2.8242957157547313

Epoch: 57| Step: 0
Training loss: 3.077297661061632
Validation loss: 2.8261231248285963

Epoch: 6| Step: 1
Training loss: 3.250217137052274
Validation loss: 2.8271773976248187

Epoch: 6| Step: 2
Training loss: 3.136999514355073
Validation loss: 2.8313088184369772

Epoch: 6| Step: 3
Training loss: 3.4381732628144026
Validation loss: 2.8332362055794285

Epoch: 6| Step: 4
Training loss: 2.9434283880636842
Validation loss: 2.8388131005768935

Epoch: 6| Step: 5
Training loss: 3.0057215172557874
Validation loss: 2.8319955239537227

Epoch: 6| Step: 6
Training loss: 3.6827499054164305
Validation loss: 2.8318057064984203

Epoch: 6| Step: 7
Training loss: 3.3555542976034585
Validation loss: 2.8250300790672056

Epoch: 6| Step: 8
Training loss: 2.8069769990234823
Validation loss: 2.825047877293769

Epoch: 6| Step: 9
Training loss: 3.154880188663553
Validation loss: 2.8224679046593257

Epoch: 6| Step: 10
Training loss: 2.126464002852159
Validation loss: 2.821713087500087

Epoch: 6| Step: 11
Training loss: 3.415678362067439
Validation loss: 2.820570892685884

Epoch: 6| Step: 12
Training loss: 2.6425008938732817
Validation loss: 2.819372582315829

Epoch: 6| Step: 13
Training loss: 3.918714488475462
Validation loss: 2.81899702585291

Epoch: 58| Step: 0
Training loss: 2.73913204019972
Validation loss: 2.8212532204145866

Epoch: 6| Step: 1
Training loss: 2.671056967987188
Validation loss: 2.820260064326716

Epoch: 6| Step: 2
Training loss: 3.201626459677126
Validation loss: 2.8265340179445193

Epoch: 6| Step: 3
Training loss: 2.6526246406688316
Validation loss: 2.8346663553750204

Epoch: 6| Step: 4
Training loss: 2.765851889748508
Validation loss: 2.8421558165422374

Epoch: 6| Step: 5
Training loss: 3.111385443112176
Validation loss: 2.8391945804429004

Epoch: 6| Step: 6
Training loss: 3.4451967942234787
Validation loss: 2.843871409625797

Epoch: 6| Step: 7
Training loss: 3.7024961814886437
Validation loss: 2.829283603934523

Epoch: 6| Step: 8
Training loss: 3.4391278660622633
Validation loss: 2.80640891558565

Epoch: 6| Step: 9
Training loss: 2.6860679537087138
Validation loss: 2.8067921499186577

Epoch: 6| Step: 10
Training loss: 2.9657479617451
Validation loss: 2.8046139934183953

Epoch: 6| Step: 11
Training loss: 4.170287326638148
Validation loss: 2.8048851968849275

Epoch: 6| Step: 12
Training loss: 3.024848076654565
Validation loss: 2.805496450612701

Epoch: 6| Step: 13
Training loss: 2.2693076885371686
Validation loss: 2.8090130755951055

Epoch: 59| Step: 0
Training loss: 2.555606968219719
Validation loss: 2.8092404289564876

Epoch: 6| Step: 1
Training loss: 3.326747842179256
Validation loss: 2.810785849992815

Epoch: 6| Step: 2
Training loss: 2.70660106328877
Validation loss: 2.8108566035868976

Epoch: 6| Step: 3
Training loss: 3.102091323777346
Validation loss: 2.812117290094678

Epoch: 6| Step: 4
Training loss: 2.743885177723418
Validation loss: 2.813157108526071

Epoch: 6| Step: 5
Training loss: 2.8767812435395834
Validation loss: 2.8165834159608427

Epoch: 6| Step: 6
Training loss: 3.6022053639245386
Validation loss: 2.8124921281310185

Epoch: 6| Step: 7
Training loss: 4.126743757260188
Validation loss: 2.811874090299489

Epoch: 6| Step: 8
Training loss: 2.539211233624498
Validation loss: 2.8084898403498446

Epoch: 6| Step: 9
Training loss: 3.5059715826838107
Validation loss: 2.807704830219553

Epoch: 6| Step: 10
Training loss: 3.1087342181876942
Validation loss: 2.805070072949996

Epoch: 6| Step: 11
Training loss: 3.1577395710552825
Validation loss: 2.8035264427416204

Epoch: 6| Step: 12
Training loss: 2.982403648335759
Validation loss: 2.800781845880123

Epoch: 6| Step: 13
Training loss: 3.024152804192518
Validation loss: 2.7997563609171516

Epoch: 60| Step: 0
Training loss: 2.9122591958756696
Validation loss: 2.797641488027739

Epoch: 6| Step: 1
Training loss: 3.3746250085549145
Validation loss: 2.795916493609516

Epoch: 6| Step: 2
Training loss: 3.111974808225679
Validation loss: 2.7966382280549156

Epoch: 6| Step: 3
Training loss: 3.1266571228868574
Validation loss: 2.7964892075198007

Epoch: 6| Step: 4
Training loss: 3.0570263896448235
Validation loss: 2.79887551685029

Epoch: 6| Step: 5
Training loss: 3.701532335267155
Validation loss: 2.8005559616154265

Epoch: 6| Step: 6
Training loss: 3.185451672205534
Validation loss: 2.793356860549732

Epoch: 6| Step: 7
Training loss: 3.0307053538766517
Validation loss: 2.7904359225564583

Epoch: 6| Step: 8
Training loss: 3.0120091081864033
Validation loss: 2.78831493469613

Epoch: 6| Step: 9
Training loss: 3.1873294560304393
Validation loss: 2.786245029961595

Epoch: 6| Step: 10
Training loss: 3.2045621299678713
Validation loss: 2.78591921519574

Epoch: 6| Step: 11
Training loss: 2.6758770333848734
Validation loss: 2.7864365443536534

Epoch: 6| Step: 12
Training loss: 3.259430334950946
Validation loss: 2.785357673735688

Epoch: 6| Step: 13
Training loss: 2.2071115124716982
Validation loss: 2.784290056546628

Epoch: 61| Step: 0
Training loss: 3.6003709919822464
Validation loss: 2.78411706028666

Epoch: 6| Step: 1
Training loss: 3.1677700596600924
Validation loss: 2.791711703729854

Epoch: 6| Step: 2
Training loss: 2.6452051653550974
Validation loss: 2.7939704905096616

Epoch: 6| Step: 3
Training loss: 3.6859679838167567
Validation loss: 2.7957494050415113

Epoch: 6| Step: 4
Training loss: 3.130573642802196
Validation loss: 2.799117166170582

Epoch: 6| Step: 5
Training loss: 3.5223717272370427
Validation loss: 2.800162085845972

Epoch: 6| Step: 6
Training loss: 2.503367540131714
Validation loss: 2.794574630472935

Epoch: 6| Step: 7
Training loss: 2.518034923889994
Validation loss: 2.795326829653429

Epoch: 6| Step: 8
Training loss: 2.6001432746144872
Validation loss: 2.7873761736737093

Epoch: 6| Step: 9
Training loss: 3.45858870946027
Validation loss: 2.782206841880525

Epoch: 6| Step: 10
Training loss: 2.827070513822482
Validation loss: 2.7791679380722396

Epoch: 6| Step: 11
Training loss: 3.335410583477839
Validation loss: 2.777384708411116

Epoch: 6| Step: 12
Training loss: 2.9411374560741734
Validation loss: 2.777058642489435

Epoch: 6| Step: 13
Training loss: 3.3242067007346257
Validation loss: 2.7745191956685913

Epoch: 62| Step: 0
Training loss: 2.5537606053965383
Validation loss: 2.775497641485466

Epoch: 6| Step: 1
Training loss: 3.0128208226996147
Validation loss: 2.773943324673406

Epoch: 6| Step: 2
Training loss: 2.6499393672124545
Validation loss: 2.7772004244973743

Epoch: 6| Step: 3
Training loss: 3.16258781823823
Validation loss: 2.782814173194032

Epoch: 6| Step: 4
Training loss: 3.3041936987933243
Validation loss: 2.794266137141133

Epoch: 6| Step: 5
Training loss: 3.5607386467829056
Validation loss: 2.804304479932109

Epoch: 6| Step: 6
Training loss: 2.8518293700036184
Validation loss: 2.806304035259883

Epoch: 6| Step: 7
Training loss: 3.189644335348841
Validation loss: 2.7822396542161614

Epoch: 6| Step: 8
Training loss: 3.0452504057251737
Validation loss: 2.7735161217431776

Epoch: 6| Step: 9
Training loss: 2.6950001411225633
Validation loss: 2.77216746720572

Epoch: 6| Step: 10
Training loss: 3.5964772366572744
Validation loss: 2.7724938919933795

Epoch: 6| Step: 11
Training loss: 2.437891024012045
Validation loss: 2.7737903352623743

Epoch: 6| Step: 12
Training loss: 3.826270576827991
Validation loss: 2.7760002934888743

Epoch: 6| Step: 13
Training loss: 3.403826630199398
Validation loss: 2.778165861591233

Epoch: 63| Step: 0
Training loss: 3.5098669751817773
Validation loss: 2.7783128236099155

Epoch: 6| Step: 1
Training loss: 3.281041311258004
Validation loss: 2.778642668121928

Epoch: 6| Step: 2
Training loss: 3.7003109053846797
Validation loss: 2.7814120146040153

Epoch: 6| Step: 3
Training loss: 3.0180218120416202
Validation loss: 2.778985506729027

Epoch: 6| Step: 4
Training loss: 2.8657675405013934
Validation loss: 2.7759333240410635

Epoch: 6| Step: 5
Training loss: 3.313961066708563
Validation loss: 2.7752609172393825

Epoch: 6| Step: 6
Training loss: 2.47890258365604
Validation loss: 2.7742041801868718

Epoch: 6| Step: 7
Training loss: 3.2459110066265606
Validation loss: 2.772516902299249

Epoch: 6| Step: 8
Training loss: 2.418391127663659
Validation loss: 2.7707794804736494

Epoch: 6| Step: 9
Training loss: 2.8653087645315076
Validation loss: 2.76921116279932

Epoch: 6| Step: 10
Training loss: 3.2322460299601823
Validation loss: 2.767509638206347

Epoch: 6| Step: 11
Training loss: 3.122352546771515
Validation loss: 2.766715568241762

Epoch: 6| Step: 12
Training loss: 3.076751557484675
Validation loss: 2.7598342463730847

Epoch: 6| Step: 13
Training loss: 2.9980592808171664
Validation loss: 2.756497714581555

Epoch: 64| Step: 0
Training loss: 2.934001056215893
Validation loss: 2.7574794079746328

Epoch: 6| Step: 1
Training loss: 3.366407689120573
Validation loss: 2.765503668598905

Epoch: 6| Step: 2
Training loss: 2.690818955079909
Validation loss: 2.779748254710484

Epoch: 6| Step: 3
Training loss: 3.2945782946420272
Validation loss: 2.7752697852022568

Epoch: 6| Step: 4
Training loss: 3.245819190357297
Validation loss: 2.7703301059672025

Epoch: 6| Step: 5
Training loss: 2.94947468234505
Validation loss: 2.7690040575706845

Epoch: 6| Step: 6
Training loss: 3.1461673247698094
Validation loss: 2.7562056447210552

Epoch: 6| Step: 7
Training loss: 3.155172787391895
Validation loss: 2.7551335702386

Epoch: 6| Step: 8
Training loss: 3.3129269306796463
Validation loss: 2.7532693999711637

Epoch: 6| Step: 9
Training loss: 3.8600691815832637
Validation loss: 2.7518568770932603

Epoch: 6| Step: 10
Training loss: 2.936095693406024
Validation loss: 2.7521241412774464

Epoch: 6| Step: 11
Training loss: 2.4926070574665653
Validation loss: 2.7518216184540756

Epoch: 6| Step: 12
Training loss: 2.1883368934821257
Validation loss: 2.7494160376132664

Epoch: 6| Step: 13
Training loss: 3.3674855819427476
Validation loss: 2.7501610674259216

Epoch: 65| Step: 0
Training loss: 2.5476013271257054
Validation loss: 2.7499574525586374

Epoch: 6| Step: 1
Training loss: 3.568318484217681
Validation loss: 2.7541922155564813

Epoch: 6| Step: 2
Training loss: 2.5474091888204504
Validation loss: 2.76948724568818

Epoch: 6| Step: 3
Training loss: 3.1921217080243562
Validation loss: 2.7903926898231983

Epoch: 6| Step: 4
Training loss: 3.2170261840987937
Validation loss: 2.783218853856942

Epoch: 6| Step: 5
Training loss: 2.529856734007776
Validation loss: 2.760270485206606

Epoch: 6| Step: 6
Training loss: 3.4310744833048075
Validation loss: 2.74970667963018

Epoch: 6| Step: 7
Training loss: 2.7595536136385195
Validation loss: 2.7475345089992356

Epoch: 6| Step: 8
Training loss: 3.6371137853134172
Validation loss: 2.745298763553635

Epoch: 6| Step: 9
Training loss: 2.4164861962468587
Validation loss: 2.7492187729021476

Epoch: 6| Step: 10
Training loss: 2.9324745857457866
Validation loss: 2.748252319835073

Epoch: 6| Step: 11
Training loss: 2.695777211693401
Validation loss: 2.752059460881445

Epoch: 6| Step: 12
Training loss: 3.7974481346300277
Validation loss: 2.7531102659443842

Epoch: 6| Step: 13
Training loss: 3.610044871339343
Validation loss: 2.7499590690751226

Epoch: 66| Step: 0
Training loss: 3.112619365563411
Validation loss: 2.7532740630460633

Epoch: 6| Step: 1
Training loss: 3.222540688032185
Validation loss: 2.7512281701326002

Epoch: 6| Step: 2
Training loss: 3.3011646296401675
Validation loss: 2.7534845356699367

Epoch: 6| Step: 3
Training loss: 2.731919150361172
Validation loss: 2.7576157820056246

Epoch: 6| Step: 4
Training loss: 3.3172225396870223
Validation loss: 2.7534325042003367

Epoch: 6| Step: 5
Training loss: 3.5498440453027906
Validation loss: 2.750532790373486

Epoch: 6| Step: 6
Training loss: 2.5248227878741227
Validation loss: 2.7503770418751556

Epoch: 6| Step: 7
Training loss: 2.604279253751132
Validation loss: 2.7475793370243293

Epoch: 6| Step: 8
Training loss: 2.8559631671079795
Validation loss: 2.7443507742645488

Epoch: 6| Step: 9
Training loss: 3.341488510164596
Validation loss: 2.743794314526267

Epoch: 6| Step: 10
Training loss: 2.467494790362547
Validation loss: 2.7438208973448157

Epoch: 6| Step: 11
Training loss: 2.963143606330662
Validation loss: 2.747783683239622

Epoch: 6| Step: 12
Training loss: 3.5876854187370384
Validation loss: 2.747702512355973

Epoch: 6| Step: 13
Training loss: 3.5023485206232845
Validation loss: 2.750053550668665

Epoch: 67| Step: 0
Training loss: 2.731112119219085
Validation loss: 2.747576565851747

Epoch: 6| Step: 1
Training loss: 3.041109391116234
Validation loss: 2.7425771227921065

Epoch: 6| Step: 2
Training loss: 2.7357085545560573
Validation loss: 2.7423864801420055

Epoch: 6| Step: 3
Training loss: 3.0475125159365692
Validation loss: 2.7413797379940785

Epoch: 6| Step: 4
Training loss: 2.3537412163342126
Validation loss: 2.739577749854807

Epoch: 6| Step: 5
Training loss: 2.6343889808510053
Validation loss: 2.7421363330535353

Epoch: 6| Step: 6
Training loss: 3.5415997367967362
Validation loss: 2.739416748007863

Epoch: 6| Step: 7
Training loss: 3.3685356680606886
Validation loss: 2.7379061941608933

Epoch: 6| Step: 8
Training loss: 2.9744904282070093
Validation loss: 2.7392758694784884

Epoch: 6| Step: 9
Training loss: 3.5770208662499985
Validation loss: 2.7392542570562406

Epoch: 6| Step: 10
Training loss: 3.1857603224971998
Validation loss: 2.7400946350347906

Epoch: 6| Step: 11
Training loss: 3.1217831648721224
Validation loss: 2.737692278338234

Epoch: 6| Step: 12
Training loss: 2.7720811562926424
Validation loss: 2.7344830122795916

Epoch: 6| Step: 13
Training loss: 3.933472041469901
Validation loss: 2.7314971602493374

Epoch: 68| Step: 0
Training loss: 3.569674712462665
Validation loss: 2.7308779169369286

Epoch: 6| Step: 1
Training loss: 2.3991491398950138
Validation loss: 2.7317479700012925

Epoch: 6| Step: 2
Training loss: 3.3419561119644996
Validation loss: 2.7287976496813586

Epoch: 6| Step: 3
Training loss: 3.0816982848500363
Validation loss: 2.730480361367582

Epoch: 6| Step: 4
Training loss: 3.1627313521730023
Validation loss: 2.7307347259036487

Epoch: 6| Step: 5
Training loss: 3.1249281302770746
Validation loss: 2.728606039587454

Epoch: 6| Step: 6
Training loss: 2.879115434808178
Validation loss: 2.7302007293498254

Epoch: 6| Step: 7
Training loss: 2.938925539239692
Validation loss: 2.7293942852925324

Epoch: 6| Step: 8
Training loss: 2.498350552971834
Validation loss: 2.7281247457526168

Epoch: 6| Step: 9
Training loss: 3.228566136458312
Validation loss: 2.731760510635185

Epoch: 6| Step: 10
Training loss: 3.012711773151952
Validation loss: 2.7308441983249585

Epoch: 6| Step: 11
Training loss: 2.8947312341298077
Validation loss: 2.728631796076908

Epoch: 6| Step: 12
Training loss: 3.45113816215141
Validation loss: 2.730368723257655

Epoch: 6| Step: 13
Training loss: 3.154643187983968
Validation loss: 2.729107557788729

Epoch: 69| Step: 0
Training loss: 3.2998392239332803
Validation loss: 2.728921146679264

Epoch: 6| Step: 1
Training loss: 3.454783459956353
Validation loss: 2.7251273438644943

Epoch: 6| Step: 2
Training loss: 2.8839210095110306
Validation loss: 2.72859282583337

Epoch: 6| Step: 3
Training loss: 2.5014513571243646
Validation loss: 2.735442306895354

Epoch: 6| Step: 4
Training loss: 3.1416574176142884
Validation loss: 2.774247403217103

Epoch: 6| Step: 5
Training loss: 2.55822136185571
Validation loss: 2.7812385296144346

Epoch: 6| Step: 6
Training loss: 2.7318243719090542
Validation loss: 2.762298221965156

Epoch: 6| Step: 7
Training loss: 2.815638422960469
Validation loss: 2.735532613436778

Epoch: 6| Step: 8
Training loss: 3.306328981317896
Validation loss: 2.72417473577041

Epoch: 6| Step: 9
Training loss: 2.9667345132106107
Validation loss: 2.7225562488474906

Epoch: 6| Step: 10
Training loss: 3.1892379809651956
Validation loss: 2.7177212826555803

Epoch: 6| Step: 11
Training loss: 3.061943782198131
Validation loss: 2.718642330147516

Epoch: 6| Step: 12
Training loss: 3.4888334616802568
Validation loss: 2.7163657753760093

Epoch: 6| Step: 13
Training loss: 3.2205803861068993
Validation loss: 2.71892863002564

Epoch: 70| Step: 0
Training loss: 2.7412142425723753
Validation loss: 2.721023275837866

Epoch: 6| Step: 1
Training loss: 3.12051008016324
Validation loss: 2.7268642760743274

Epoch: 6| Step: 2
Training loss: 3.107971948337506
Validation loss: 2.7188429250219617

Epoch: 6| Step: 3
Training loss: 2.921224429892336
Validation loss: 2.716353804495738

Epoch: 6| Step: 4
Training loss: 2.773475324345948
Validation loss: 2.713895623994641

Epoch: 6| Step: 5
Training loss: 3.1271391604169585
Validation loss: 2.7126082620516834

Epoch: 6| Step: 6
Training loss: 2.7252022484435674
Validation loss: 2.711464956151142

Epoch: 6| Step: 7
Training loss: 2.988807462349669
Validation loss: 2.7132297872239812

Epoch: 6| Step: 8
Training loss: 3.261328978863375
Validation loss: 2.714088765683883

Epoch: 6| Step: 9
Training loss: 2.4897681663778157
Validation loss: 2.7132890127157703

Epoch: 6| Step: 10
Training loss: 3.7890400994022126
Validation loss: 2.710771662988708

Epoch: 6| Step: 11
Training loss: 2.7930651241294346
Validation loss: 2.7087535074711404

Epoch: 6| Step: 12
Training loss: 3.5770979160966188
Validation loss: 2.7074149708485673

Epoch: 6| Step: 13
Training loss: 2.8499513856188186
Validation loss: 2.712971658133649

Epoch: 71| Step: 0
Training loss: 2.827632629359955
Validation loss: 2.710502582768634

Epoch: 6| Step: 1
Training loss: 3.1603750334687892
Validation loss: 2.7190446534844965

Epoch: 6| Step: 2
Training loss: 3.059447655287525
Validation loss: 2.7179897406612463

Epoch: 6| Step: 3
Training loss: 2.768582244682077
Validation loss: 2.7177182678504685

Epoch: 6| Step: 4
Training loss: 2.7201157570497783
Validation loss: 2.7083591920613665

Epoch: 6| Step: 5
Training loss: 2.969658963438539
Validation loss: 2.707855501137576

Epoch: 6| Step: 6
Training loss: 3.347135737046216
Validation loss: 2.704707715917146

Epoch: 6| Step: 7
Training loss: 3.0772992105933663
Validation loss: 2.704853873284629

Epoch: 6| Step: 8
Training loss: 3.5478027743600453
Validation loss: 2.706170067379595

Epoch: 6| Step: 9
Training loss: 3.8540855330441888
Validation loss: 2.704043032660241

Epoch: 6| Step: 10
Training loss: 2.7852409959823374
Validation loss: 2.7022165980319426

Epoch: 6| Step: 11
Training loss: 2.7182093992657808
Validation loss: 2.700879567700756

Epoch: 6| Step: 12
Training loss: 2.9350042901340823
Validation loss: 2.703774051772147

Epoch: 6| Step: 13
Training loss: 2.1078579569016003
Validation loss: 2.7011517657205872

Epoch: 72| Step: 0
Training loss: 2.709291073600339
Validation loss: 2.703551442356321

Epoch: 6| Step: 1
Training loss: 2.674972077696341
Validation loss: 2.7256008306553987

Epoch: 6| Step: 2
Training loss: 3.345513279968458
Validation loss: 2.7214244097294147

Epoch: 6| Step: 3
Training loss: 3.5276403291880905
Validation loss: 2.7353483196986073

Epoch: 6| Step: 4
Training loss: 2.6994813385580017
Validation loss: 2.7287942243487313

Epoch: 6| Step: 5
Training loss: 2.6699152669427186
Validation loss: 2.7195800996317985

Epoch: 6| Step: 6
Training loss: 2.947585627611943
Validation loss: 2.71213704797874

Epoch: 6| Step: 7
Training loss: 3.3236637212451843
Validation loss: 2.709583948503824

Epoch: 6| Step: 8
Training loss: 3.255154263873866
Validation loss: 2.7046157242092326

Epoch: 6| Step: 9
Training loss: 2.606509617011884
Validation loss: 2.6960512703619846

Epoch: 6| Step: 10
Training loss: 3.5186052363753797
Validation loss: 2.6971454757406867

Epoch: 6| Step: 11
Training loss: 2.5082163262773602
Validation loss: 2.697877963848755

Epoch: 6| Step: 12
Training loss: 3.4801393774775633
Validation loss: 2.7016945840202236

Epoch: 6| Step: 13
Training loss: 2.873939484417724
Validation loss: 2.7021150776418907

Epoch: 73| Step: 0
Training loss: 3.00609081584423
Validation loss: 2.708036037879136

Epoch: 6| Step: 1
Training loss: 2.7763409098409095
Validation loss: 2.708085990825062

Epoch: 6| Step: 2
Training loss: 3.551769761072492
Validation loss: 2.7062328046401944

Epoch: 6| Step: 3
Training loss: 2.966478944761266
Validation loss: 2.704286595910066

Epoch: 6| Step: 4
Training loss: 2.5422981186558538
Validation loss: 2.7043285707507825

Epoch: 6| Step: 5
Training loss: 3.290512526456567
Validation loss: 2.7050763404537923

Epoch: 6| Step: 6
Training loss: 2.700025424131149
Validation loss: 2.6997348178148166

Epoch: 6| Step: 7
Training loss: 2.9159536489248628
Validation loss: 2.6982428107754313

Epoch: 6| Step: 8
Training loss: 2.7974435239107533
Validation loss: 2.696875150992785

Epoch: 6| Step: 9
Training loss: 2.638430614722247
Validation loss: 2.6945171412643685

Epoch: 6| Step: 10
Training loss: 3.2349964963725957
Validation loss: 2.694717852872193

Epoch: 6| Step: 11
Training loss: 3.2903367426179613
Validation loss: 2.7024303242863277

Epoch: 6| Step: 12
Training loss: 3.574454611411784
Validation loss: 2.717674371682797

Epoch: 6| Step: 13
Training loss: 3.213890184559548
Validation loss: 2.7040504968590806

Epoch: 74| Step: 0
Training loss: 2.6760530876687105
Validation loss: 2.6913141160751577

Epoch: 6| Step: 1
Training loss: 2.934135133082151
Validation loss: 2.6919455155965064

Epoch: 6| Step: 2
Training loss: 2.827562392108848
Validation loss: 2.6915054692346323

Epoch: 6| Step: 3
Training loss: 3.000391775616968
Validation loss: 2.695250463522304

Epoch: 6| Step: 4
Training loss: 3.3849034003444007
Validation loss: 2.6947423930328678

Epoch: 6| Step: 5
Training loss: 3.12142572081711
Validation loss: 2.6981423779633698

Epoch: 6| Step: 6
Training loss: 3.258642150475556
Validation loss: 2.6987457062707523

Epoch: 6| Step: 7
Training loss: 3.16304387779809
Validation loss: 2.6938633553465747

Epoch: 6| Step: 8
Training loss: 2.9865720959858786
Validation loss: 2.692943739237266

Epoch: 6| Step: 9
Training loss: 3.4058515683152586
Validation loss: 2.709251636852684

Epoch: 6| Step: 10
Training loss: 3.1708008398996923
Validation loss: 2.716146453758876

Epoch: 6| Step: 11
Training loss: 2.5898457752985107
Validation loss: 2.6977072025626034

Epoch: 6| Step: 12
Training loss: 3.081850846767837
Validation loss: 2.6960613687651045

Epoch: 6| Step: 13
Training loss: 2.4191209454431255
Validation loss: 2.6991963134581556

Epoch: 75| Step: 0
Training loss: 2.5521566471286894
Validation loss: 2.6922562025355634

Epoch: 6| Step: 1
Training loss: 3.4506722279090623
Validation loss: 2.6931901938846443

Epoch: 6| Step: 2
Training loss: 2.8592139026724377
Validation loss: 2.6937108856643612

Epoch: 6| Step: 3
Training loss: 3.1196667747569546
Validation loss: 2.694483402444029

Epoch: 6| Step: 4
Training loss: 3.0809779234692325
Validation loss: 2.6906376918646644

Epoch: 6| Step: 5
Training loss: 3.121156847033122
Validation loss: 2.6943646667136023

Epoch: 6| Step: 6
Training loss: 3.195229079223175
Validation loss: 2.6862516429985828

Epoch: 6| Step: 7
Training loss: 2.9111457524976583
Validation loss: 2.680942230761863

Epoch: 6| Step: 8
Training loss: 2.9312951318320617
Validation loss: 2.6796232715865345

Epoch: 6| Step: 9
Training loss: 2.559489365701852
Validation loss: 2.677009329322209

Epoch: 6| Step: 10
Training loss: 3.2604709088543253
Validation loss: 2.6775562961392234

Epoch: 6| Step: 11
Training loss: 3.2880718705613114
Validation loss: 2.675416303765068

Epoch: 6| Step: 12
Training loss: 2.7244107300458147
Validation loss: 2.6788314369878226

Epoch: 6| Step: 13
Training loss: 3.2180166057113175
Validation loss: 2.678878041506343

Epoch: 76| Step: 0
Training loss: 2.881026709917712
Validation loss: 2.6769836315921913

Epoch: 6| Step: 1
Training loss: 2.9974833104780148
Validation loss: 2.673279007725973

Epoch: 6| Step: 2
Training loss: 2.2829470658116127
Validation loss: 2.675913842609725

Epoch: 6| Step: 3
Training loss: 3.024340433142736
Validation loss: 2.675063809413991

Epoch: 6| Step: 4
Training loss: 3.022340245217492
Validation loss: 2.6871176121150744

Epoch: 6| Step: 5
Training loss: 2.789444413737098
Validation loss: 2.687873416608077

Epoch: 6| Step: 6
Training loss: 3.338744793612564
Validation loss: 2.6929556680523272

Epoch: 6| Step: 7
Training loss: 3.126666273294626
Validation loss: 2.698427210370631

Epoch: 6| Step: 8
Training loss: 3.58423768689279
Validation loss: 2.692787054217946

Epoch: 6| Step: 9
Training loss: 2.9654088543507644
Validation loss: 2.6821176155664403

Epoch: 6| Step: 10
Training loss: 2.5921357428480833
Validation loss: 2.6813324330241395

Epoch: 6| Step: 11
Training loss: 3.1557414334433322
Validation loss: 2.672644523008824

Epoch: 6| Step: 12
Training loss: 2.95084450481993
Validation loss: 2.6749138104125234

Epoch: 6| Step: 13
Training loss: 3.571974219465186
Validation loss: 2.670227140391532

Epoch: 77| Step: 0
Training loss: 2.9668737003507593
Validation loss: 2.6662816700994

Epoch: 6| Step: 1
Training loss: 3.023165905013054
Validation loss: 2.669242102315543

Epoch: 6| Step: 2
Training loss: 3.199693432666529
Validation loss: 2.6735628902961213

Epoch: 6| Step: 3
Training loss: 2.998180791492014
Validation loss: 2.678055545332576

Epoch: 6| Step: 4
Training loss: 2.2040433660488237
Validation loss: 2.671577676463413

Epoch: 6| Step: 5
Training loss: 3.161282898477924
Validation loss: 2.67463391817625

Epoch: 6| Step: 6
Training loss: 2.5345093264653697
Validation loss: 2.678379966916981

Epoch: 6| Step: 7
Training loss: 2.688958238157517
Validation loss: 2.6747202149878095

Epoch: 6| Step: 8
Training loss: 3.7852902856170383
Validation loss: 2.6774884547800277

Epoch: 6| Step: 9
Training loss: 2.934443730371034
Validation loss: 2.669926493524949

Epoch: 6| Step: 10
Training loss: 2.943934920348373
Validation loss: 2.6643299438506154

Epoch: 6| Step: 11
Training loss: 2.9568611206941653
Validation loss: 2.667434618016247

Epoch: 6| Step: 12
Training loss: 3.3459293001757975
Validation loss: 2.6704387871801396

Epoch: 6| Step: 13
Training loss: 3.2813342855618224
Validation loss: 2.6682712056366404

Epoch: 78| Step: 0
Training loss: 2.662885120459462
Validation loss: 2.678183383735785

Epoch: 6| Step: 1
Training loss: 3.2575780111766113
Validation loss: 2.6949085400724098

Epoch: 6| Step: 2
Training loss: 3.2683543795527736
Validation loss: 2.711297596934284

Epoch: 6| Step: 3
Training loss: 3.4056906984642565
Validation loss: 2.7005040943545713

Epoch: 6| Step: 4
Training loss: 2.575331035186719
Validation loss: 2.6747877858309432

Epoch: 6| Step: 5
Training loss: 2.8747313000709167
Validation loss: 2.661726708554392

Epoch: 6| Step: 6
Training loss: 3.494196303357395
Validation loss: 2.658183752983325

Epoch: 6| Step: 7
Training loss: 2.92755651665397
Validation loss: 2.659161518537331

Epoch: 6| Step: 8
Training loss: 2.837166680071478
Validation loss: 2.660518535137069

Epoch: 6| Step: 9
Training loss: 3.347159100610517
Validation loss: 2.65748483329241

Epoch: 6| Step: 10
Training loss: 3.023505946919829
Validation loss: 2.6595868832213982

Epoch: 6| Step: 11
Training loss: 2.374544601950107
Validation loss: 2.6582679066447197

Epoch: 6| Step: 12
Training loss: 2.672457715120152
Validation loss: 2.6552225691930276

Epoch: 6| Step: 13
Training loss: 3.237275081171181
Validation loss: 2.6570356747667843

Epoch: 79| Step: 0
Training loss: 2.6591725147947702
Validation loss: 2.657128101921324

Epoch: 6| Step: 1
Training loss: 3.46022319095893
Validation loss: 2.6547364248239256

Epoch: 6| Step: 2
Training loss: 3.2005654133526042
Validation loss: 2.6585414569566517

Epoch: 6| Step: 3
Training loss: 3.0479505939033817
Validation loss: 2.681913252907959

Epoch: 6| Step: 4
Training loss: 2.8928575297091323
Validation loss: 2.694409117703011

Epoch: 6| Step: 5
Training loss: 2.8634211361634083
Validation loss: 2.718900711018089

Epoch: 6| Step: 6
Training loss: 3.2667003850429333
Validation loss: 2.721005839217724

Epoch: 6| Step: 7
Training loss: 3.3493452941180846
Validation loss: 2.7412141565320582

Epoch: 6| Step: 8
Training loss: 3.318221710744367
Validation loss: 2.6651545317987413

Epoch: 6| Step: 9
Training loss: 2.904449068967482
Validation loss: 2.654236225971968

Epoch: 6| Step: 10
Training loss: 3.125793813972422
Validation loss: 2.6547148262127913

Epoch: 6| Step: 11
Training loss: 3.286424607447956
Validation loss: 2.6577000712909764

Epoch: 6| Step: 12
Training loss: 2.407898870524385
Validation loss: 2.6685431089526217

Epoch: 6| Step: 13
Training loss: 1.4262858294868597
Validation loss: 2.6759845351929243

Epoch: 80| Step: 0
Training loss: 2.9689440212092615
Validation loss: 2.6811545807115733

Epoch: 6| Step: 1
Training loss: 2.4019521998938593
Validation loss: 2.6846111230956238

Epoch: 6| Step: 2
Training loss: 3.3232827936561957
Validation loss: 2.6867792985621763

Epoch: 6| Step: 3
Training loss: 2.958850457210909
Validation loss: 2.6701785453302564

Epoch: 6| Step: 4
Training loss: 2.7193734342114224
Validation loss: 2.660678439494217

Epoch: 6| Step: 5
Training loss: 3.441215864927442
Validation loss: 2.656194139311846

Epoch: 6| Step: 6
Training loss: 3.589712246384217
Validation loss: 2.6554050238032114

Epoch: 6| Step: 7
Training loss: 2.400089850333285
Validation loss: 2.660567059000419

Epoch: 6| Step: 8
Training loss: 2.796375336581406
Validation loss: 2.6567449949362185

Epoch: 6| Step: 9
Training loss: 3.3632327617911537
Validation loss: 2.6612932771981432

Epoch: 6| Step: 10
Training loss: 2.777542557823815
Validation loss: 2.6728427805936086

Epoch: 6| Step: 11
Training loss: 3.4649722861410575
Validation loss: 2.676655077485138

Epoch: 6| Step: 12
Training loss: 2.793136143503177
Validation loss: 2.667073156026399

Epoch: 6| Step: 13
Training loss: 2.5722862943776144
Validation loss: 2.6643170656223507

Epoch: 81| Step: 0
Training loss: 3.3058163854307048
Validation loss: 2.6630456576647936

Epoch: 6| Step: 1
Training loss: 3.026065758474091
Validation loss: 2.661983294613039

Epoch: 6| Step: 2
Training loss: 3.1248812843661495
Validation loss: 2.6519859317022876

Epoch: 6| Step: 3
Training loss: 2.7735256986966186
Validation loss: 2.6506848480235075

Epoch: 6| Step: 4
Training loss: 3.522848211097466
Validation loss: 2.6530431075244714

Epoch: 6| Step: 5
Training loss: 2.886656475298763
Validation loss: 2.6501395216850967

Epoch: 6| Step: 6
Training loss: 2.9359188288348226
Validation loss: 2.6500116344915488

Epoch: 6| Step: 7
Training loss: 2.763928253898823
Validation loss: 2.6491681600288666

Epoch: 6| Step: 8
Training loss: 3.3544677378111887
Validation loss: 2.6498432073955644

Epoch: 6| Step: 9
Training loss: 3.2562902173507595
Validation loss: 2.645641829310671

Epoch: 6| Step: 10
Training loss: 2.6603007228343727
Validation loss: 2.650534467535713

Epoch: 6| Step: 11
Training loss: 2.55448348137709
Validation loss: 2.6505972855676916

Epoch: 6| Step: 12
Training loss: 3.2130204844102295
Validation loss: 2.670332757072826

Epoch: 6| Step: 13
Training loss: 1.858422363896982
Validation loss: 2.679674349253636

Epoch: 82| Step: 0
Training loss: 3.104325531514895
Validation loss: 2.661180357962235

Epoch: 6| Step: 1
Training loss: 3.123183828933078
Validation loss: 2.6596840758684914

Epoch: 6| Step: 2
Training loss: 2.7140075713173624
Validation loss: 2.6455252718931255

Epoch: 6| Step: 3
Training loss: 2.7274259495320243
Validation loss: 2.644606501483687

Epoch: 6| Step: 4
Training loss: 2.4041159939067422
Validation loss: 2.6477917519112375

Epoch: 6| Step: 5
Training loss: 2.720469490091921
Validation loss: 2.654768434210262

Epoch: 6| Step: 6
Training loss: 2.9989557038101657
Validation loss: 2.6543613270179596

Epoch: 6| Step: 7
Training loss: 3.141028838502862
Validation loss: 2.6575633065138335

Epoch: 6| Step: 8
Training loss: 3.6997557172810356
Validation loss: 2.6579903920448134

Epoch: 6| Step: 9
Training loss: 3.2117623339428287
Validation loss: 2.6579880820582877

Epoch: 6| Step: 10
Training loss: 3.0931346551078094
Validation loss: 2.6566861291050685

Epoch: 6| Step: 11
Training loss: 3.0346440456242276
Validation loss: 2.6585195720003174

Epoch: 6| Step: 12
Training loss: 3.1633257726398742
Validation loss: 2.6573127391648534

Epoch: 6| Step: 13
Training loss: 2.791188089903035
Validation loss: 2.6538908227847924

Epoch: 83| Step: 0
Training loss: 2.978065091438193
Validation loss: 2.650296140481916

Epoch: 6| Step: 1
Training loss: 2.881646145213806
Validation loss: 2.649074748692223

Epoch: 6| Step: 2
Training loss: 3.014325113755724
Validation loss: 2.64683239030555

Epoch: 6| Step: 3
Training loss: 3.3951390186550023
Validation loss: 2.6484977349178878

Epoch: 6| Step: 4
Training loss: 3.48894580692047
Validation loss: 2.6495967845358153

Epoch: 6| Step: 5
Training loss: 3.0597239777482095
Validation loss: 2.649526029887668

Epoch: 6| Step: 6
Training loss: 3.2654792716624654
Validation loss: 2.6474487654462364

Epoch: 6| Step: 7
Training loss: 2.377230149286817
Validation loss: 2.643369276446389

Epoch: 6| Step: 8
Training loss: 3.1243776846178015
Validation loss: 2.6410662563991703

Epoch: 6| Step: 9
Training loss: 3.169896753837998
Validation loss: 2.64016777828122

Epoch: 6| Step: 10
Training loss: 2.776764585303339
Validation loss: 2.6407488586188643

Epoch: 6| Step: 11
Training loss: 2.810116584504255
Validation loss: 2.636598148968066

Epoch: 6| Step: 12
Training loss: 2.463262132158507
Validation loss: 2.643900298775742

Epoch: 6| Step: 13
Training loss: 2.9975647579066975
Validation loss: 2.6564356565891263

Epoch: 84| Step: 0
Training loss: 3.828152901684032
Validation loss: 2.6710336470274174

Epoch: 6| Step: 1
Training loss: 2.649161180856726
Validation loss: 2.683214441823575

Epoch: 6| Step: 2
Training loss: 3.0445200108650323
Validation loss: 2.6603509813820607

Epoch: 6| Step: 3
Training loss: 2.9636079929395907
Validation loss: 2.656697618094706

Epoch: 6| Step: 4
Training loss: 2.3622643166506982
Validation loss: 2.6374080581864394

Epoch: 6| Step: 5
Training loss: 3.113185981623449
Validation loss: 2.629820071893328

Epoch: 6| Step: 6
Training loss: 2.9329264322465054
Validation loss: 2.626563848150704

Epoch: 6| Step: 7
Training loss: 3.2340494627841387
Validation loss: 2.629153292836951

Epoch: 6| Step: 8
Training loss: 2.7380083631077086
Validation loss: 2.628057146998032

Epoch: 6| Step: 9
Training loss: 3.1049871875050163
Validation loss: 2.6292909532913593

Epoch: 6| Step: 10
Training loss: 3.031461885263313
Validation loss: 2.6266046376689105

Epoch: 6| Step: 11
Training loss: 2.812371738476199
Validation loss: 2.6231839333371476

Epoch: 6| Step: 12
Training loss: 2.6779167174422436
Validation loss: 2.6298349449087826

Epoch: 6| Step: 13
Training loss: 3.1540143243709915
Validation loss: 2.633287279586402

Epoch: 85| Step: 0
Training loss: 2.883567649125812
Validation loss: 2.650758051475239

Epoch: 6| Step: 1
Training loss: 2.7247124546473254
Validation loss: 2.6699231299721227

Epoch: 6| Step: 2
Training loss: 3.1128624762460206
Validation loss: 2.7160040850344256

Epoch: 6| Step: 3
Training loss: 3.4714268159048944
Validation loss: 2.710277396033897

Epoch: 6| Step: 4
Training loss: 3.0032121627813333
Validation loss: 2.690274591343255

Epoch: 6| Step: 5
Training loss: 3.2070954812386314
Validation loss: 2.6705643973365105

Epoch: 6| Step: 6
Training loss: 2.61701349847189
Validation loss: 2.640078147285923

Epoch: 6| Step: 7
Training loss: 2.7156161080973167
Validation loss: 2.625140508161966

Epoch: 6| Step: 8
Training loss: 2.842499174924813
Validation loss: 2.6257444918840362

Epoch: 6| Step: 9
Training loss: 3.0033034574297797
Validation loss: 2.625480004414695

Epoch: 6| Step: 10
Training loss: 3.579038811480942
Validation loss: 2.6281494671113825

Epoch: 6| Step: 11
Training loss: 2.620680206466991
Validation loss: 2.6266650453219675

Epoch: 6| Step: 12
Training loss: 2.889343967621789
Validation loss: 2.6291594875270117

Epoch: 6| Step: 13
Training loss: 3.0181840701789433
Validation loss: 2.6280738551191907

Epoch: 86| Step: 0
Training loss: 2.757479466546007
Validation loss: 2.6308170776879454

Epoch: 6| Step: 1
Training loss: 2.7767894851736066
Validation loss: 2.6445909360304514

Epoch: 6| Step: 2
Training loss: 2.959993639758726
Validation loss: 2.6674157748492986

Epoch: 6| Step: 3
Training loss: 3.135872504639888
Validation loss: 2.671680667173602

Epoch: 6| Step: 4
Training loss: 3.1891561955131458
Validation loss: 2.6701887742248984

Epoch: 6| Step: 5
Training loss: 3.502283441354921
Validation loss: 2.6431388192542555

Epoch: 6| Step: 6
Training loss: 2.785409367470223
Validation loss: 2.633977986058223

Epoch: 6| Step: 7
Training loss: 2.450257782122636
Validation loss: 2.626180379995631

Epoch: 6| Step: 8
Training loss: 3.4442777918079015
Validation loss: 2.62383272730592

Epoch: 6| Step: 9
Training loss: 3.2574999908658056
Validation loss: 2.620152616754935

Epoch: 6| Step: 10
Training loss: 2.9063809273053822
Validation loss: 2.6203898767021734

Epoch: 6| Step: 11
Training loss: 2.0656516530774427
Validation loss: 2.6218443046365927

Epoch: 6| Step: 12
Training loss: 2.802976038280223
Validation loss: 2.6186843189137177

Epoch: 6| Step: 13
Training loss: 3.590306498160348
Validation loss: 2.618457360862131

Epoch: 87| Step: 0
Training loss: 3.4153502804913214
Validation loss: 2.616621724935381

Epoch: 6| Step: 1
Training loss: 2.8041917793165942
Validation loss: 2.6170351569685386

Epoch: 6| Step: 2
Training loss: 2.754662808866406
Validation loss: 2.6165051710294422

Epoch: 6| Step: 3
Training loss: 3.07328578650159
Validation loss: 2.616461405147035

Epoch: 6| Step: 4
Training loss: 3.124967346020801
Validation loss: 2.617924521851779

Epoch: 6| Step: 5
Training loss: 3.0646085681477095
Validation loss: 2.6148366710174202

Epoch: 6| Step: 6
Training loss: 2.5969884487302086
Validation loss: 2.6141315572078714

Epoch: 6| Step: 7
Training loss: 2.8907312322118024
Validation loss: 2.615671849420219

Epoch: 6| Step: 8
Training loss: 2.2984643743980886
Validation loss: 2.6193060337470655

Epoch: 6| Step: 9
Training loss: 3.037972458253118
Validation loss: 2.6253850491387865

Epoch: 6| Step: 10
Training loss: 2.9409085241448256
Validation loss: 2.6282293171042608

Epoch: 6| Step: 11
Training loss: 2.5308627550585645
Validation loss: 2.6336042800098864

Epoch: 6| Step: 12
Training loss: 3.493129253347322
Validation loss: 2.6638045002755857

Epoch: 6| Step: 13
Training loss: 3.5221077382615475
Validation loss: 2.663727646859297

Epoch: 88| Step: 0
Training loss: 2.7072820726151026
Validation loss: 2.624403429190203

Epoch: 6| Step: 1
Training loss: 2.8417643227302265
Validation loss: 2.61334565411305

Epoch: 6| Step: 2
Training loss: 2.7129290298588766
Validation loss: 2.6107114872100023

Epoch: 6| Step: 3
Training loss: 2.7798111869307514
Validation loss: 2.612507725314787

Epoch: 6| Step: 4
Training loss: 2.742034907863794
Validation loss: 2.610317330988225

Epoch: 6| Step: 5
Training loss: 3.197911033666829
Validation loss: 2.6105167454550853

Epoch: 6| Step: 6
Training loss: 3.154425065119645
Validation loss: 2.612837216511828

Epoch: 6| Step: 7
Training loss: 3.1463076673882693
Validation loss: 2.6135160801515007

Epoch: 6| Step: 8
Training loss: 3.664233498558465
Validation loss: 2.6165024971654853

Epoch: 6| Step: 9
Training loss: 2.8132548696715975
Validation loss: 2.615047267740025

Epoch: 6| Step: 10
Training loss: 2.7052309509514783
Validation loss: 2.612384731817146

Epoch: 6| Step: 11
Training loss: 2.336639911083041
Validation loss: 2.611677837971322

Epoch: 6| Step: 12
Training loss: 3.301965769571273
Validation loss: 2.6110399826783417

Epoch: 6| Step: 13
Training loss: 3.2957379879926814
Validation loss: 2.6116728955765804

Epoch: 89| Step: 0
Training loss: 3.239064967315073
Validation loss: 2.6081356656841614

Epoch: 6| Step: 1
Training loss: 2.7761597933277544
Validation loss: 2.608265548129813

Epoch: 6| Step: 2
Training loss: 2.973019391009148
Validation loss: 2.6057568334713643

Epoch: 6| Step: 3
Training loss: 2.4553437131043796
Validation loss: 2.605561629897996

Epoch: 6| Step: 4
Training loss: 3.273993906881154
Validation loss: 2.6051661395038304

Epoch: 6| Step: 5
Training loss: 2.8862571915131756
Validation loss: 2.607934070678747

Epoch: 6| Step: 6
Training loss: 2.875649586145253
Validation loss: 2.6164136143736916

Epoch: 6| Step: 7
Training loss: 2.6812446007307416
Validation loss: 2.6502886535425345

Epoch: 6| Step: 8
Training loss: 3.498293596914067
Validation loss: 2.6743493752236316

Epoch: 6| Step: 9
Training loss: 2.9237759368254888
Validation loss: 2.624032512241684

Epoch: 6| Step: 10
Training loss: 2.3431666347562357
Validation loss: 2.6063530601619447

Epoch: 6| Step: 11
Training loss: 3.038762801036289
Validation loss: 2.604011037462619

Epoch: 6| Step: 12
Training loss: 3.3911363066735394
Validation loss: 2.6004716677252047

Epoch: 6| Step: 13
Training loss: 2.789217648077752
Validation loss: 2.599583448624659

Epoch: 90| Step: 0
Training loss: 3.1022368882199056
Validation loss: 2.6005769401474343

Epoch: 6| Step: 1
Training loss: 2.9229770152975902
Validation loss: 2.601915207421242

Epoch: 6| Step: 2
Training loss: 2.6451934481225985
Validation loss: 2.601226644045945

Epoch: 6| Step: 3
Training loss: 1.9613675561590678
Validation loss: 2.6043823651639806

Epoch: 6| Step: 4
Training loss: 3.1680884097603883
Validation loss: 2.6033067414745448

Epoch: 6| Step: 5
Training loss: 2.8360649479583655
Validation loss: 2.6035671503051403

Epoch: 6| Step: 6
Training loss: 3.1378483430722226
Validation loss: 2.6048051670731107

Epoch: 6| Step: 7
Training loss: 2.892279898694132
Validation loss: 2.605334046274129

Epoch: 6| Step: 8
Training loss: 3.0224200762080424
Validation loss: 2.602905907076379

Epoch: 6| Step: 9
Training loss: 3.1313511205856597
Validation loss: 2.6075372579216114

Epoch: 6| Step: 10
Training loss: 3.191731355839893
Validation loss: 2.6132830736867074

Epoch: 6| Step: 11
Training loss: 3.4409290203654828
Validation loss: 2.6355492408017502

Epoch: 6| Step: 12
Training loss: 2.690864940405304
Validation loss: 2.652300213029018

Epoch: 6| Step: 13
Training loss: 2.9906003243475703
Validation loss: 2.6817275457147756

Epoch: 91| Step: 0
Training loss: 3.7859442710422324
Validation loss: 2.6626109043370647

Epoch: 6| Step: 1
Training loss: 2.5440828897539807
Validation loss: 2.6115318807460377

Epoch: 6| Step: 2
Training loss: 2.871853640936623
Validation loss: 2.5959740088462873

Epoch: 6| Step: 3
Training loss: 2.082388841792433
Validation loss: 2.5985596372544437

Epoch: 6| Step: 4
Training loss: 3.3487463014360817
Validation loss: 2.602165083648344

Epoch: 6| Step: 5
Training loss: 3.133321896660677
Validation loss: 2.6006604190448366

Epoch: 6| Step: 6
Training loss: 3.276166920574604
Validation loss: 2.597375745522151

Epoch: 6| Step: 7
Training loss: 3.5041205809500053
Validation loss: 2.595969991510929

Epoch: 6| Step: 8
Training loss: 2.8900297634611665
Validation loss: 2.5967802208993747

Epoch: 6| Step: 9
Training loss: 2.3823040529192365
Validation loss: 2.593801328643149

Epoch: 6| Step: 10
Training loss: 3.254760044001825
Validation loss: 2.5940040605291426

Epoch: 6| Step: 11
Training loss: 2.6694408728551067
Validation loss: 2.5919748254102535

Epoch: 6| Step: 12
Training loss: 2.59518190867213
Validation loss: 2.601058121743573

Epoch: 6| Step: 13
Training loss: 2.704797392782801
Validation loss: 2.60848895655795

Epoch: 92| Step: 0
Training loss: 2.8569051779932986
Validation loss: 2.6277910484374254

Epoch: 6| Step: 1
Training loss: 3.1490647517040364
Validation loss: 2.6495095354213167

Epoch: 6| Step: 2
Training loss: 2.6501622168356436
Validation loss: 2.703588791739906

Epoch: 6| Step: 3
Training loss: 2.660375734480846
Validation loss: 2.7431938092585364

Epoch: 6| Step: 4
Training loss: 2.615007728288073
Validation loss: 2.783423895636999

Epoch: 6| Step: 5
Training loss: 3.0378671369298202
Validation loss: 2.813109621909231

Epoch: 6| Step: 6
Training loss: 3.1380943616850265
Validation loss: 2.8045602203381104

Epoch: 6| Step: 7
Training loss: 2.7813640099635304
Validation loss: 2.7634714162085343

Epoch: 6| Step: 8
Training loss: 2.683599258261723
Validation loss: 2.7209027774376358

Epoch: 6| Step: 9
Training loss: 3.4558950507512
Validation loss: 2.682365969998574

Epoch: 6| Step: 10
Training loss: 3.8628219470317573
Validation loss: 2.6733131570458455

Epoch: 6| Step: 11
Training loss: 3.278021832089108
Validation loss: 2.6634814315209607

Epoch: 6| Step: 12
Training loss: 2.672670658611318
Validation loss: 2.665231818278277

Epoch: 6| Step: 13
Training loss: 3.236207894190951
Validation loss: 2.6618445954374135

Epoch: 93| Step: 0
Training loss: 2.9254795626857306
Validation loss: 2.6600526540730574

Epoch: 6| Step: 1
Training loss: 2.809564457192152
Validation loss: 2.655488221430746

Epoch: 6| Step: 2
Training loss: 3.026456838328063
Validation loss: 2.6369911010044627

Epoch: 6| Step: 3
Training loss: 3.615616723053607
Validation loss: 2.627627231424269

Epoch: 6| Step: 4
Training loss: 2.571188362951715
Validation loss: 2.6110578335697014

Epoch: 6| Step: 5
Training loss: 3.7545712901088675
Validation loss: 2.614950955208901

Epoch: 6| Step: 6
Training loss: 2.81836639636058
Validation loss: 2.6184748694276303

Epoch: 6| Step: 7
Training loss: 3.134369194656731
Validation loss: 2.6332885130757937

Epoch: 6| Step: 8
Training loss: 2.7225550190784356
Validation loss: 2.630504337509858

Epoch: 6| Step: 9
Training loss: 3.000713899229531
Validation loss: 2.6306726481828497

Epoch: 6| Step: 10
Training loss: 2.9175180191751884
Validation loss: 2.6243688563932004

Epoch: 6| Step: 11
Training loss: 2.9249636395142535
Validation loss: 2.606248237454047

Epoch: 6| Step: 12
Training loss: 2.330416479748994
Validation loss: 2.6185132952420482

Epoch: 6| Step: 13
Training loss: 2.6554664802597685
Validation loss: 2.609377276389082

Epoch: 94| Step: 0
Training loss: 3.4105312495168056
Validation loss: 2.60225415362495

Epoch: 6| Step: 1
Training loss: 2.402642853267811
Validation loss: 2.600276652037873

Epoch: 6| Step: 2
Training loss: 2.9277965902954235
Validation loss: 2.597148417862273

Epoch: 6| Step: 3
Training loss: 3.191572990403975
Validation loss: 2.5929540823167123

Epoch: 6| Step: 4
Training loss: 3.0246658392839123
Validation loss: 2.5929740143305193

Epoch: 6| Step: 5
Training loss: 2.4975404084290287
Validation loss: 2.5951457186735696

Epoch: 6| Step: 6
Training loss: 2.823070751831883
Validation loss: 2.61976307801352

Epoch: 6| Step: 7
Training loss: 3.289202979342997
Validation loss: 2.6375960994993477

Epoch: 6| Step: 8
Training loss: 2.7561670857455502
Validation loss: 2.642641283498081

Epoch: 6| Step: 9
Training loss: 2.790098281141099
Validation loss: 2.637039349084296

Epoch: 6| Step: 10
Training loss: 3.1242867227969198
Validation loss: 2.6280580912711398

Epoch: 6| Step: 11
Training loss: 2.732919621753641
Validation loss: 2.5870509144679037

Epoch: 6| Step: 12
Training loss: 3.217468302821814
Validation loss: 2.5804756572902248

Epoch: 6| Step: 13
Training loss: 3.0389217550052905
Validation loss: 2.5830017413576205

Epoch: 95| Step: 0
Training loss: 2.5187191149614168
Validation loss: 2.585393588883031

Epoch: 6| Step: 1
Training loss: 3.231530897079856
Validation loss: 2.5863934806282387

Epoch: 6| Step: 2
Training loss: 2.649946294996094
Validation loss: 2.5937338506198575

Epoch: 6| Step: 3
Training loss: 3.612333332163732
Validation loss: 2.5958509855003182

Epoch: 6| Step: 4
Training loss: 3.3177388348018217
Validation loss: 2.6129275651188335

Epoch: 6| Step: 5
Training loss: 2.7545945193501593
Validation loss: 2.617214776137129

Epoch: 6| Step: 6
Training loss: 3.519998500346818
Validation loss: 2.6185931448813946

Epoch: 6| Step: 7
Training loss: 2.813510204724451
Validation loss: 2.6037936869315574

Epoch: 6| Step: 8
Training loss: 2.8013414915941355
Validation loss: 2.5914206632956955

Epoch: 6| Step: 9
Training loss: 2.421606233511779
Validation loss: 2.582359576680739

Epoch: 6| Step: 10
Training loss: 2.511248080232455
Validation loss: 2.5835714286723257

Epoch: 6| Step: 11
Training loss: 3.109296174703588
Validation loss: 2.5804046406615386

Epoch: 6| Step: 12
Training loss: 3.247322740423063
Validation loss: 2.57903138178859

Epoch: 6| Step: 13
Training loss: 1.8219640876882184
Validation loss: 2.5762218343089063

Epoch: 96| Step: 0
Training loss: 2.7392049801333336
Validation loss: 2.576811619067542

Epoch: 6| Step: 1
Training loss: 3.5493206717391654
Validation loss: 2.59258824233901

Epoch: 6| Step: 2
Training loss: 2.55213198453242
Validation loss: 2.591077235729847

Epoch: 6| Step: 3
Training loss: 2.7911277839222737
Validation loss: 2.580590911841083

Epoch: 6| Step: 4
Training loss: 2.4835619285731254
Validation loss: 2.5876816214864196

Epoch: 6| Step: 5
Training loss: 2.632007872108815
Validation loss: 2.594975191642225

Epoch: 6| Step: 6
Training loss: 2.761997408479639
Validation loss: 2.5899085171927645

Epoch: 6| Step: 7
Training loss: 3.1633732551277163
Validation loss: 2.588018079216809

Epoch: 6| Step: 8
Training loss: 2.676661615267968
Validation loss: 2.583312745728429

Epoch: 6| Step: 9
Training loss: 2.9686696894976032
Validation loss: 2.5802945720527175

Epoch: 6| Step: 10
Training loss: 3.0613633206734137
Validation loss: 2.5853201926129694

Epoch: 6| Step: 11
Training loss: 3.5480289682627095
Validation loss: 2.5790843204263436

Epoch: 6| Step: 12
Training loss: 2.861348122797012
Validation loss: 2.5758645707047383

Epoch: 6| Step: 13
Training loss: 3.171020543056267
Validation loss: 2.5768072614515662

Epoch: 97| Step: 0
Training loss: 2.785528513893744
Validation loss: 2.577140314288268

Epoch: 6| Step: 1
Training loss: 2.865780186169109
Validation loss: 2.573841548661416

Epoch: 6| Step: 2
Training loss: 3.0439489154714803
Validation loss: 2.5808753037249406

Epoch: 6| Step: 3
Training loss: 2.362385931742912
Validation loss: 2.583986887064313

Epoch: 6| Step: 4
Training loss: 3.301749291757343
Validation loss: 2.583700765889214

Epoch: 6| Step: 5
Training loss: 3.2201982221543166
Validation loss: 2.5999355222975407

Epoch: 6| Step: 6
Training loss: 2.7875002805427442
Validation loss: 2.5983798567170466

Epoch: 6| Step: 7
Training loss: 3.6457457322995084
Validation loss: 2.6067765362161186

Epoch: 6| Step: 8
Training loss: 2.3579169814595
Validation loss: 2.5972086479243637

Epoch: 6| Step: 9
Training loss: 2.295304156990028
Validation loss: 2.6087240019005087

Epoch: 6| Step: 10
Training loss: 3.532530560857346
Validation loss: 2.5862361788880603

Epoch: 6| Step: 11
Training loss: 2.9378593711981047
Validation loss: 2.578429638715442

Epoch: 6| Step: 12
Training loss: 2.958595980594782
Validation loss: 2.569554372924937

Epoch: 6| Step: 13
Training loss: 2.36788768925328
Validation loss: 2.5726840909798048

Epoch: 98| Step: 0
Training loss: 2.869980119908825
Validation loss: 2.56805698276103

Epoch: 6| Step: 1
Training loss: 2.79597987337195
Validation loss: 2.5679636553361

Epoch: 6| Step: 2
Training loss: 2.670002152659945
Validation loss: 2.5700805072632558

Epoch: 6| Step: 3
Training loss: 3.7327736968701837
Validation loss: 2.5715483239037313

Epoch: 6| Step: 4
Training loss: 2.711267456730123
Validation loss: 2.567632612693441

Epoch: 6| Step: 5
Training loss: 2.362142392497557
Validation loss: 2.5685552928994833

Epoch: 6| Step: 6
Training loss: 2.869202615108492
Validation loss: 2.569232283678533

Epoch: 6| Step: 7
Training loss: 2.8526960236364975
Validation loss: 2.573603481892691

Epoch: 6| Step: 8
Training loss: 2.9806264933068247
Validation loss: 2.5788429192907505

Epoch: 6| Step: 9
Training loss: 2.5556937286322694
Validation loss: 2.5780657629999286

Epoch: 6| Step: 10
Training loss: 3.482930931928871
Validation loss: 2.5850046178638015

Epoch: 6| Step: 11
Training loss: 2.789648256313225
Validation loss: 2.5979954390383906

Epoch: 6| Step: 12
Training loss: 2.733206362992937
Validation loss: 2.594081940940756

Epoch: 6| Step: 13
Training loss: 3.496517356058142
Validation loss: 2.605499721485138

Epoch: 99| Step: 0
Training loss: 3.094020947238115
Validation loss: 2.6217982576517445

Epoch: 6| Step: 1
Training loss: 2.920577633304447
Validation loss: 2.624998234261399

Epoch: 6| Step: 2
Training loss: 3.058500831722379
Validation loss: 2.5868783722572966

Epoch: 6| Step: 3
Training loss: 3.0818302683696825
Validation loss: 2.57935932799674

Epoch: 6| Step: 4
Training loss: 3.14477962673966
Validation loss: 2.5715370666027697

Epoch: 6| Step: 5
Training loss: 2.521208543412992
Validation loss: 2.5672168793445573

Epoch: 6| Step: 6
Training loss: 3.2156789999413906
Validation loss: 2.5634732902884902

Epoch: 6| Step: 7
Training loss: 2.759158921556846
Validation loss: 2.566352829073051

Epoch: 6| Step: 8
Training loss: 2.6892397372738026
Validation loss: 2.5683809601785863

Epoch: 6| Step: 9
Training loss: 2.927986648206025
Validation loss: 2.5634460513657236

Epoch: 6| Step: 10
Training loss: 3.3842077043066774
Validation loss: 2.568939561433637

Epoch: 6| Step: 11
Training loss: 2.7769965747541514
Validation loss: 2.567021814036831

Epoch: 6| Step: 12
Training loss: 2.5553854825837155
Validation loss: 2.566683493922474

Epoch: 6| Step: 13
Training loss: 2.4847915588090603
Validation loss: 2.5686235591200055

Epoch: 100| Step: 0
Training loss: 3.0060617875724254
Validation loss: 2.5689430452304243

Epoch: 6| Step: 1
Training loss: 3.7598609971669936
Validation loss: 2.578381635186398

Epoch: 6| Step: 2
Training loss: 3.181831105936728
Validation loss: 2.5802894274678363

Epoch: 6| Step: 3
Training loss: 3.2040374200662156
Validation loss: 2.5827620433968357

Epoch: 6| Step: 4
Training loss: 2.485467058956861
Validation loss: 2.583879927712512

Epoch: 6| Step: 5
Training loss: 2.8851713955376064
Validation loss: 2.5824625487413835

Epoch: 6| Step: 6
Training loss: 2.769252316480747
Validation loss: 2.576150117260892

Epoch: 6| Step: 7
Training loss: 1.9909589981309936
Validation loss: 2.590491770643462

Epoch: 6| Step: 8
Training loss: 3.1842627448454137
Validation loss: 2.6008177483324366

Epoch: 6| Step: 9
Training loss: 2.778091866431879
Validation loss: 2.608068661741605

Epoch: 6| Step: 10
Training loss: 2.709361208976309
Validation loss: 2.5945471240364864

Epoch: 6| Step: 11
Training loss: 3.038994717271085
Validation loss: 2.5967853298520427

Epoch: 6| Step: 12
Training loss: 2.7945404538884726
Validation loss: 2.5885334190966347

Epoch: 6| Step: 13
Training loss: 2.5842972362032213
Validation loss: 2.5831689322481663

Epoch: 101| Step: 0
Training loss: 2.894564197265254
Validation loss: 2.5814300036156443

Epoch: 6| Step: 1
Training loss: 3.07969803481717
Validation loss: 2.5557381900706044

Epoch: 6| Step: 2
Training loss: 2.0111206350692314
Validation loss: 2.5565503820035325

Epoch: 6| Step: 3
Training loss: 2.836342690686157
Validation loss: 2.566828769374675

Epoch: 6| Step: 4
Training loss: 2.5353652092114047
Validation loss: 2.5695121409965638

Epoch: 6| Step: 5
Training loss: 2.9891065866476443
Validation loss: 2.5688549409436794

Epoch: 6| Step: 6
Training loss: 3.377147132856075
Validation loss: 2.5641498541770114

Epoch: 6| Step: 7
Training loss: 2.5305334890245392
Validation loss: 2.562015850872187

Epoch: 6| Step: 8
Training loss: 3.182894502387737
Validation loss: 2.5666729594045505

Epoch: 6| Step: 9
Training loss: 3.677769641028473
Validation loss: 2.5586780104938622

Epoch: 6| Step: 10
Training loss: 2.604521022847266
Validation loss: 2.5616985431318726

Epoch: 6| Step: 11
Training loss: 3.308246977197106
Validation loss: 2.5697517250820723

Epoch: 6| Step: 12
Training loss: 2.7594488978616125
Validation loss: 2.5768574283082892

Epoch: 6| Step: 13
Training loss: 2.460701389187991
Validation loss: 2.5887608922551752

Epoch: 102| Step: 0
Training loss: 2.146765595914866
Validation loss: 2.6573774904202385

Epoch: 6| Step: 1
Training loss: 3.2700286814980424
Validation loss: 2.7617090931150767

Epoch: 6| Step: 2
Training loss: 2.6965375244879644
Validation loss: 2.7330071647346044

Epoch: 6| Step: 3
Training loss: 2.565919873557214
Validation loss: 2.7298727699414025

Epoch: 6| Step: 4
Training loss: 2.636060392344956
Validation loss: 2.674954005457318

Epoch: 6| Step: 5
Training loss: 3.107472513434822
Validation loss: 2.625999938985024

Epoch: 6| Step: 6
Training loss: 3.312734487619167
Validation loss: 2.590466636768183

Epoch: 6| Step: 7
Training loss: 3.1842721789590134
Validation loss: 2.5819867260120697

Epoch: 6| Step: 8
Training loss: 2.777173601778705
Validation loss: 2.5724346477759856

Epoch: 6| Step: 9
Training loss: 3.0544283627695403
Validation loss: 2.5712609571959786

Epoch: 6| Step: 10
Training loss: 3.060825746608035
Validation loss: 2.562526371597823

Epoch: 6| Step: 11
Training loss: 2.5653537583631807
Validation loss: 2.55874217089092

Epoch: 6| Step: 12
Training loss: 3.394586736052202
Validation loss: 2.565464191189203

Epoch: 6| Step: 13
Training loss: 2.8593986802084683
Validation loss: 2.56179075432833

Epoch: 103| Step: 0
Training loss: 3.155800513563665
Validation loss: 2.5603397917314394

Epoch: 6| Step: 1
Training loss: 2.893809775606375
Validation loss: 2.5579583634137237

Epoch: 6| Step: 2
Training loss: 2.753597334180979
Validation loss: 2.557798447975864

Epoch: 6| Step: 3
Training loss: 3.152967502376915
Validation loss: 2.5570937562268456

Epoch: 6| Step: 4
Training loss: 3.405231428529953
Validation loss: 2.5572324807402462

Epoch: 6| Step: 5
Training loss: 2.7559727051356364
Validation loss: 2.558818131907718

Epoch: 6| Step: 6
Training loss: 3.289040318502624
Validation loss: 2.563264276874425

Epoch: 6| Step: 7
Training loss: 3.190664627770637
Validation loss: 2.562323129203892

Epoch: 6| Step: 8
Training loss: 2.6837296763815677
Validation loss: 2.562410491612639

Epoch: 6| Step: 9
Training loss: 2.289848427066562
Validation loss: 2.5656264436421545

Epoch: 6| Step: 10
Training loss: 2.8342068017684294
Validation loss: 2.5695959566634285

Epoch: 6| Step: 11
Training loss: 2.462923635069475
Validation loss: 2.5813070121161297

Epoch: 6| Step: 12
Training loss: 2.713355313648669
Validation loss: 2.5858405325256264

Epoch: 6| Step: 13
Training loss: 3.01265637636914
Validation loss: 2.605765446952246

Epoch: 104| Step: 0
Training loss: 2.276365092770379
Validation loss: 2.608093841255656

Epoch: 6| Step: 1
Training loss: 2.7647562332724642
Validation loss: 2.61955379307332

Epoch: 6| Step: 2
Training loss: 3.141316655609642
Validation loss: 2.616696000847543

Epoch: 6| Step: 3
Training loss: 2.665091844303723
Validation loss: 2.6034970882544144

Epoch: 6| Step: 4
Training loss: 3.492942506558901
Validation loss: 2.567314183759599

Epoch: 6| Step: 5
Training loss: 3.1009407092801213
Validation loss: 2.557058324999757

Epoch: 6| Step: 6
Training loss: 3.270910630659261
Validation loss: 2.5446774365469893

Epoch: 6| Step: 7
Training loss: 2.7952572709966375
Validation loss: 2.5464946463568556

Epoch: 6| Step: 8
Training loss: 3.081713139080604
Validation loss: 2.552211363148614

Epoch: 6| Step: 9
Training loss: 3.0191765462145326
Validation loss: 2.545195350229059

Epoch: 6| Step: 10
Training loss: 2.5878817806452643
Validation loss: 2.5519121632903556

Epoch: 6| Step: 11
Training loss: 2.5359504290408057
Validation loss: 2.5441067940055655

Epoch: 6| Step: 12
Training loss: 3.0055265384886507
Validation loss: 2.5478522205527625

Epoch: 6| Step: 13
Training loss: 2.601392402472304
Validation loss: 2.5492194843711355

Epoch: 105| Step: 0
Training loss: 2.570502648088612
Validation loss: 2.549624790284242

Epoch: 6| Step: 1
Training loss: 2.7101711102339694
Validation loss: 2.5487169733651482

Epoch: 6| Step: 2
Training loss: 2.8799452336720215
Validation loss: 2.5480542669118473

Epoch: 6| Step: 3
Training loss: 2.9935516355415217
Validation loss: 2.5522569168322042

Epoch: 6| Step: 4
Training loss: 3.213924605657328
Validation loss: 2.5620342154455127

Epoch: 6| Step: 5
Training loss: 2.3602204481710696
Validation loss: 2.561307486059739

Epoch: 6| Step: 6
Training loss: 2.703862966010823
Validation loss: 2.556743724439482

Epoch: 6| Step: 7
Training loss: 3.176681709961098
Validation loss: 2.5595563142365716

Epoch: 6| Step: 8
Training loss: 2.913020297879741
Validation loss: 2.5574358770873755

Epoch: 6| Step: 9
Training loss: 3.005645843516083
Validation loss: 2.5599237392780028

Epoch: 6| Step: 10
Training loss: 3.0096673967990997
Validation loss: 2.5571305308760874

Epoch: 6| Step: 11
Training loss: 2.954128357316497
Validation loss: 2.548794237979542

Epoch: 6| Step: 12
Training loss: 3.015191081556985
Validation loss: 2.5463922263112932

Epoch: 6| Step: 13
Training loss: 3.0892154329654598
Validation loss: 2.547076014710411

Epoch: 106| Step: 0
Training loss: 2.865004870292425
Validation loss: 2.5463325762864994

Epoch: 6| Step: 1
Training loss: 3.144212486269571
Validation loss: 2.5482610558025867

Epoch: 6| Step: 2
Training loss: 2.9319076873902303
Validation loss: 2.552207766611942

Epoch: 6| Step: 3
Training loss: 3.057379665548838
Validation loss: 2.5424877170670137

Epoch: 6| Step: 4
Training loss: 2.7330869420191335
Validation loss: 2.5407189324176405

Epoch: 6| Step: 5
Training loss: 2.8143578221362127
Validation loss: 2.548323692804077

Epoch: 6| Step: 6
Training loss: 2.3227324020676576
Validation loss: 2.5453218401985005

Epoch: 6| Step: 7
Training loss: 3.0587059965035666
Validation loss: 2.5513816352680823

Epoch: 6| Step: 8
Training loss: 2.913524751928931
Validation loss: 2.5590260746386138

Epoch: 6| Step: 9
Training loss: 2.75421443865075
Validation loss: 2.5710408629696846

Epoch: 6| Step: 10
Training loss: 2.9429238749648094
Validation loss: 2.6048158062176516

Epoch: 6| Step: 11
Training loss: 3.309761498839338
Validation loss: 2.6670807996266785

Epoch: 6| Step: 12
Training loss: 3.1451523066819136
Validation loss: 2.598167254814115

Epoch: 6| Step: 13
Training loss: 2.4971314185180757
Validation loss: 2.5730302166270205

Epoch: 107| Step: 0
Training loss: 1.8771949636083314
Validation loss: 2.563969081710548

Epoch: 6| Step: 1
Training loss: 2.828403438118145
Validation loss: 2.5444168749365286

Epoch: 6| Step: 2
Training loss: 2.172998809968611
Validation loss: 2.5408853408873715

Epoch: 6| Step: 3
Training loss: 3.2106924590007337
Validation loss: 2.545891671666743

Epoch: 6| Step: 4
Training loss: 3.0420533200117372
Validation loss: 2.543502602125567

Epoch: 6| Step: 5
Training loss: 3.065231039726744
Validation loss: 2.5446980942685165

Epoch: 6| Step: 6
Training loss: 2.541685093880648
Validation loss: 2.5402447115124134

Epoch: 6| Step: 7
Training loss: 3.0720950477618545
Validation loss: 2.5450740536357066

Epoch: 6| Step: 8
Training loss: 3.364673215691038
Validation loss: 2.5400920507768783

Epoch: 6| Step: 9
Training loss: 2.934664717439486
Validation loss: 2.541856644838229

Epoch: 6| Step: 10
Training loss: 2.897506852359914
Validation loss: 2.5397562906302573

Epoch: 6| Step: 11
Training loss: 2.714803352329831
Validation loss: 2.53808568801307

Epoch: 6| Step: 12
Training loss: 3.379890571944647
Validation loss: 2.546476001590235

Epoch: 6| Step: 13
Training loss: 3.262095172656112
Validation loss: 2.5605448645730604

Epoch: 108| Step: 0
Training loss: 2.521667426546852
Validation loss: 2.575171877019779

Epoch: 6| Step: 1
Training loss: 2.79849494606749
Validation loss: 2.609670713529057

Epoch: 6| Step: 2
Training loss: 2.935113627429168
Validation loss: 2.589799935456491

Epoch: 6| Step: 3
Training loss: 2.862662671393615
Validation loss: 2.558929072198752

Epoch: 6| Step: 4
Training loss: 2.778282210854732
Validation loss: 2.5485562255680225

Epoch: 6| Step: 5
Training loss: 3.239964617076808
Validation loss: 2.540283397268845

Epoch: 6| Step: 6
Training loss: 3.2313356723901547
Validation loss: 2.5402960404290496

Epoch: 6| Step: 7
Training loss: 3.1884982471984666
Validation loss: 2.534622469643737

Epoch: 6| Step: 8
Training loss: 2.20181473531769
Validation loss: 2.538720675067264

Epoch: 6| Step: 9
Training loss: 2.5663885989808723
Validation loss: 2.5436038413860906

Epoch: 6| Step: 10
Training loss: 2.7813715533150782
Validation loss: 2.5385039158882803

Epoch: 6| Step: 11
Training loss: 3.219350073719191
Validation loss: 2.540672744027702

Epoch: 6| Step: 12
Training loss: 3.195904889024763
Validation loss: 2.54262985492386

Epoch: 6| Step: 13
Training loss: 2.7866849622931986
Validation loss: 2.545433263968728

Epoch: 109| Step: 0
Training loss: 2.790343431234478
Validation loss: 2.5456191635158585

Epoch: 6| Step: 1
Training loss: 2.7041389459992655
Validation loss: 2.5470896316583334

Epoch: 6| Step: 2
Training loss: 2.8988819861127806
Validation loss: 2.5497099906730067

Epoch: 6| Step: 3
Training loss: 2.8043862183671453
Validation loss: 2.555709383111043

Epoch: 6| Step: 4
Training loss: 2.846893250190199
Validation loss: 2.568838186965613

Epoch: 6| Step: 5
Training loss: 2.614587750880751
Validation loss: 2.578959498331165

Epoch: 6| Step: 6
Training loss: 3.028015455975008
Validation loss: 2.562616949366522

Epoch: 6| Step: 7
Training loss: 2.737653151456452
Validation loss: 2.5567008858337212

Epoch: 6| Step: 8
Training loss: 3.0499070950726055
Validation loss: 2.558063894149005

Epoch: 6| Step: 9
Training loss: 2.750083488584183
Validation loss: 2.569140945272872

Epoch: 6| Step: 10
Training loss: 3.1045844972415706
Validation loss: 2.5451791808400013

Epoch: 6| Step: 11
Training loss: 3.290655552214159
Validation loss: 2.5406543239342207

Epoch: 6| Step: 12
Training loss: 2.736472235621199
Validation loss: 2.5407715296539135

Epoch: 6| Step: 13
Training loss: 3.0647207499454963
Validation loss: 2.534475784095345

Epoch: 110| Step: 0
Training loss: 2.881130813483535
Validation loss: 2.532040414743825

Epoch: 6| Step: 1
Training loss: 3.489597665937606
Validation loss: 2.529212393858094

Epoch: 6| Step: 2
Training loss: 3.121340172579949
Validation loss: 2.533196398124543

Epoch: 6| Step: 3
Training loss: 2.6707785514970115
Validation loss: 2.534823497723654

Epoch: 6| Step: 4
Training loss: 2.827631111646681
Validation loss: 2.53192015253415

Epoch: 6| Step: 5
Training loss: 2.7950449662523864
Validation loss: 2.5340249860277457

Epoch: 6| Step: 6
Training loss: 2.1958424210284946
Validation loss: 2.532357147320881

Epoch: 6| Step: 7
Training loss: 3.0298883584986793
Validation loss: 2.5369426733756386

Epoch: 6| Step: 8
Training loss: 3.279754007000456
Validation loss: 2.537263929837829

Epoch: 6| Step: 9
Training loss: 2.475172164015286
Validation loss: 2.53971001306425

Epoch: 6| Step: 10
Training loss: 3.0073370223307774
Validation loss: 2.539293465912195

Epoch: 6| Step: 11
Training loss: 2.7830732562902347
Validation loss: 2.5401203818583964

Epoch: 6| Step: 12
Training loss: 3.1012531577866453
Validation loss: 2.5411583122936006

Epoch: 6| Step: 13
Training loss: 2.1531401612920376
Validation loss: 2.5394299242398173

Epoch: 111| Step: 0
Training loss: 3.065732223393256
Validation loss: 2.5319301826189493

Epoch: 6| Step: 1
Training loss: 2.311395226594571
Validation loss: 2.5331616047029177

Epoch: 6| Step: 2
Training loss: 3.159012142968334
Validation loss: 2.5376186246739114

Epoch: 6| Step: 3
Training loss: 3.0627964421257965
Validation loss: 2.5552930272019294

Epoch: 6| Step: 4
Training loss: 2.6716710062957505
Validation loss: 2.557547253230801

Epoch: 6| Step: 5
Training loss: 3.60490742092328
Validation loss: 2.5689976038056974

Epoch: 6| Step: 6
Training loss: 3.1802273228804436
Validation loss: 2.5893707845774334

Epoch: 6| Step: 7
Training loss: 2.7165901110887227
Validation loss: 2.6263730354471444

Epoch: 6| Step: 8
Training loss: 2.68737118434471
Validation loss: 2.628763736180694

Epoch: 6| Step: 9
Training loss: 2.3878048487464425
Validation loss: 2.5641629555411964

Epoch: 6| Step: 10
Training loss: 2.8505660314802572
Validation loss: 2.5305628652238066

Epoch: 6| Step: 11
Training loss: 2.732169782504094
Validation loss: 2.526224514672044

Epoch: 6| Step: 12
Training loss: 3.1296379767245357
Validation loss: 2.5402313878856475

Epoch: 6| Step: 13
Training loss: 2.240294504730578
Validation loss: 2.5614766364218555

Epoch: 112| Step: 0
Training loss: 3.397495604028728
Validation loss: 2.574894908859634

Epoch: 6| Step: 1
Training loss: 2.781995951882001
Validation loss: 2.65178967777229

Epoch: 6| Step: 2
Training loss: 2.5782762887665513
Validation loss: 2.692838115440186

Epoch: 6| Step: 3
Training loss: 3.373216511006513
Validation loss: 2.7009392633299103

Epoch: 6| Step: 4
Training loss: 2.9150388989216873
Validation loss: 2.668419327998829

Epoch: 6| Step: 5
Training loss: 2.486239327570361
Validation loss: 2.6149041907556225

Epoch: 6| Step: 6
Training loss: 3.161781675760257
Validation loss: 2.5938069722411927

Epoch: 6| Step: 7
Training loss: 3.2547724968648204
Validation loss: 2.548221876461761

Epoch: 6| Step: 8
Training loss: 2.644371670256763
Validation loss: 2.5396243409154162

Epoch: 6| Step: 9
Training loss: 3.2509882964830292
Validation loss: 2.549678390766561

Epoch: 6| Step: 10
Training loss: 2.7455935287148123
Validation loss: 2.5602973337125623

Epoch: 6| Step: 11
Training loss: 3.316864880592575
Validation loss: 2.586525084240826

Epoch: 6| Step: 12
Training loss: 2.849564194402797
Validation loss: 2.5929428764238094

Epoch: 6| Step: 13
Training loss: 2.8466064862479374
Validation loss: 2.6256861085478578

Epoch: 113| Step: 0
Training loss: 2.5848681494845587
Validation loss: 2.6740629895598893

Epoch: 6| Step: 1
Training loss: 3.3368909130013518
Validation loss: 2.633218790325145

Epoch: 6| Step: 2
Training loss: 2.9052640821803157
Validation loss: 2.617449171110644

Epoch: 6| Step: 3
Training loss: 2.913663535125985
Validation loss: 2.5971261034235695

Epoch: 6| Step: 4
Training loss: 2.9097796919758308
Validation loss: 2.5903141152204965

Epoch: 6| Step: 5
Training loss: 2.727672798983674
Validation loss: 2.598261006470589

Epoch: 6| Step: 6
Training loss: 2.582023308953844
Validation loss: 2.5950245780325436

Epoch: 6| Step: 7
Training loss: 3.3075586566639976
Validation loss: 2.581627093413089

Epoch: 6| Step: 8
Training loss: 2.163673558727793
Validation loss: 2.5472489210909526

Epoch: 6| Step: 9
Training loss: 3.324828615289053
Validation loss: 2.5401743080397687

Epoch: 6| Step: 10
Training loss: 2.752046257267914
Validation loss: 2.5278057799406666

Epoch: 6| Step: 11
Training loss: 3.299755411042624
Validation loss: 2.527678691331763

Epoch: 6| Step: 12
Training loss: 2.6781861128004834
Validation loss: 2.5237035504101657

Epoch: 6| Step: 13
Training loss: 2.8277365064659046
Validation loss: 2.5231567214412576

Epoch: 114| Step: 0
Training loss: 2.5408262729098356
Validation loss: 2.519415754714227

Epoch: 6| Step: 1
Training loss: 3.3437731020120456
Validation loss: 2.526357463095878

Epoch: 6| Step: 2
Training loss: 3.0897523888199765
Validation loss: 2.550672321292449

Epoch: 6| Step: 3
Training loss: 2.9105281720183203
Validation loss: 2.6106477595182427

Epoch: 6| Step: 4
Training loss: 2.9726020316795045
Validation loss: 2.670955755772754

Epoch: 6| Step: 5
Training loss: 2.8390537931553337
Validation loss: 2.728503060995898

Epoch: 6| Step: 6
Training loss: 3.478086536122813
Validation loss: 2.7708163696134935

Epoch: 6| Step: 7
Training loss: 2.51203216448316
Validation loss: 2.7127701348614623

Epoch: 6| Step: 8
Training loss: 2.38386247358541
Validation loss: 2.6673800362829483

Epoch: 6| Step: 9
Training loss: 3.2907151082191715
Validation loss: 2.6380564354765332

Epoch: 6| Step: 10
Training loss: 2.8479266672765746
Validation loss: 2.5950442940938303

Epoch: 6| Step: 11
Training loss: 2.7643276124118636
Validation loss: 2.55733033948324

Epoch: 6| Step: 12
Training loss: 3.1189837717879776
Validation loss: 2.559558161178403

Epoch: 6| Step: 13
Training loss: 2.7123256504262097
Validation loss: 2.535815245340379

Epoch: 115| Step: 0
Training loss: 3.120987414099077
Validation loss: 2.527382293420961

Epoch: 6| Step: 1
Training loss: 2.975337700149622
Validation loss: 2.5174533011745974

Epoch: 6| Step: 2
Training loss: 2.996062874168645
Validation loss: 2.519549528429103

Epoch: 6| Step: 3
Training loss: 2.8701656995517353
Validation loss: 2.5205347821174215

Epoch: 6| Step: 4
Training loss: 3.0186632100457302
Validation loss: 2.5144544928031065

Epoch: 6| Step: 5
Training loss: 2.7096301177579636
Validation loss: 2.514563100250698

Epoch: 6| Step: 6
Training loss: 3.397820076816026
Validation loss: 2.515979452199032

Epoch: 6| Step: 7
Training loss: 2.507896065433795
Validation loss: 2.513293012471467

Epoch: 6| Step: 8
Training loss: 3.0638555523959132
Validation loss: 2.516156348818238

Epoch: 6| Step: 9
Training loss: 2.6461052542099344
Validation loss: 2.536513933593743

Epoch: 6| Step: 10
Training loss: 2.7883458004718555
Validation loss: 2.5932496476942295

Epoch: 6| Step: 11
Training loss: 2.0901413750174447
Validation loss: 2.6739309580828254

Epoch: 6| Step: 12
Training loss: 3.513952510158944
Validation loss: 2.765141613527413

Epoch: 6| Step: 13
Training loss: 1.860358290772774
Validation loss: 2.7667193849074923

Epoch: 116| Step: 0
Training loss: 2.8803733700220917
Validation loss: 2.7444211215440504

Epoch: 6| Step: 1
Training loss: 3.297790689445964
Validation loss: 2.6501727938450785

Epoch: 6| Step: 2
Training loss: 3.049661936550688
Validation loss: 2.586003905587713

Epoch: 6| Step: 3
Training loss: 2.67764934290705
Validation loss: 2.546965149975593

Epoch: 6| Step: 4
Training loss: 2.3951898014621045
Validation loss: 2.514861836763533

Epoch: 6| Step: 5
Training loss: 2.8044209898239747
Validation loss: 2.5092729843020014

Epoch: 6| Step: 6
Training loss: 2.4336552742273123
Validation loss: 2.5061526584673515

Epoch: 6| Step: 7
Training loss: 3.19226286841628
Validation loss: 2.5095562422628426

Epoch: 6| Step: 8
Training loss: 3.072413688918615
Validation loss: 2.508541370933548

Epoch: 6| Step: 9
Training loss: 2.720051596376562
Validation loss: 2.5066701486184138

Epoch: 6| Step: 10
Training loss: 2.8389635991540607
Validation loss: 2.5070453986462473

Epoch: 6| Step: 11
Training loss: 3.1845939703199746
Validation loss: 2.510300971430398

Epoch: 6| Step: 12
Training loss: 3.2601547054723157
Validation loss: 2.5128469687664157

Epoch: 6| Step: 13
Training loss: 2.6243269829605596
Validation loss: 2.516695167302976

Epoch: 117| Step: 0
Training loss: 2.5238993785950945
Validation loss: 2.5238817482306266

Epoch: 6| Step: 1
Training loss: 2.7734773015134806
Validation loss: 2.5287217599737595

Epoch: 6| Step: 2
Training loss: 3.591295681326634
Validation loss: 2.542556399857233

Epoch: 6| Step: 3
Training loss: 3.0939210786623517
Validation loss: 2.5368256045382642

Epoch: 6| Step: 4
Training loss: 2.700208556986053
Validation loss: 2.5457411702762958

Epoch: 6| Step: 5
Training loss: 2.433394079451712
Validation loss: 2.528688135764107

Epoch: 6| Step: 6
Training loss: 2.552645645992868
Validation loss: 2.525423009478087

Epoch: 6| Step: 7
Training loss: 2.749753073963813
Validation loss: 2.518454429330417

Epoch: 6| Step: 8
Training loss: 2.8390232249321423
Validation loss: 2.5147982149313464

Epoch: 6| Step: 9
Training loss: 3.3769615971915123
Validation loss: 2.5100350375594536

Epoch: 6| Step: 10
Training loss: 2.884799344970493
Validation loss: 2.5120543755156914

Epoch: 6| Step: 11
Training loss: 2.8344478845951357
Validation loss: 2.5042862603065883

Epoch: 6| Step: 12
Training loss: 2.933531982746878
Validation loss: 2.5077463112602594

Epoch: 6| Step: 13
Training loss: 2.5735827573488557
Validation loss: 2.507097073403563

Epoch: 118| Step: 0
Training loss: 2.842717077442856
Validation loss: 2.510241369649967

Epoch: 6| Step: 1
Training loss: 3.3605597247807335
Validation loss: 2.5064040136213035

Epoch: 6| Step: 2
Training loss: 2.8500373837880195
Validation loss: 2.5045424724231613

Epoch: 6| Step: 3
Training loss: 3.382447819952247
Validation loss: 2.505905019360586

Epoch: 6| Step: 4
Training loss: 2.7240496316833185
Validation loss: 2.5076972659706795

Epoch: 6| Step: 5
Training loss: 1.932093861232909
Validation loss: 2.505905160540078

Epoch: 6| Step: 6
Training loss: 3.1873557862213913
Validation loss: 2.5065302376295704

Epoch: 6| Step: 7
Training loss: 2.759725366556592
Validation loss: 2.51339488411596

Epoch: 6| Step: 8
Training loss: 2.871381389715598
Validation loss: 2.517983641085078

Epoch: 6| Step: 9
Training loss: 2.879067901669197
Validation loss: 2.5210307983034115

Epoch: 6| Step: 10
Training loss: 3.2020212644386796
Validation loss: 2.5274891525345264

Epoch: 6| Step: 11
Training loss: 2.5317291936462984
Validation loss: 2.538883667762157

Epoch: 6| Step: 12
Training loss: 2.198412027326664
Validation loss: 2.560495574578191

Epoch: 6| Step: 13
Training loss: 2.9918582426342586
Validation loss: 2.558242621708709

Epoch: 119| Step: 0
Training loss: 2.3637769447215136
Validation loss: 2.549939101407062

Epoch: 6| Step: 1
Training loss: 2.580320590896922
Validation loss: 2.528470489146296

Epoch: 6| Step: 2
Training loss: 2.759847176785154
Validation loss: 2.5565546828948875

Epoch: 6| Step: 3
Training loss: 3.499870570378198
Validation loss: 2.5644135112486484

Epoch: 6| Step: 4
Training loss: 2.802603624862867
Validation loss: 2.5545936966896954

Epoch: 6| Step: 5
Training loss: 2.851158134321767
Validation loss: 2.5521305721917757

Epoch: 6| Step: 6
Training loss: 2.5540410428375138
Validation loss: 2.523388703303461

Epoch: 6| Step: 7
Training loss: 3.074347332176354
Validation loss: 2.5152331509269525

Epoch: 6| Step: 8
Training loss: 2.6623598626020457
Validation loss: 2.51073040637998

Epoch: 6| Step: 9
Training loss: 3.4541273776689403
Validation loss: 2.510965519019832

Epoch: 6| Step: 10
Training loss: 2.624452715543152
Validation loss: 2.515045484480039

Epoch: 6| Step: 11
Training loss: 3.1425142441747673
Validation loss: 2.5165161233930617

Epoch: 6| Step: 12
Training loss: 2.8128199077500606
Validation loss: 2.5245591966061722

Epoch: 6| Step: 13
Training loss: 2.862222556449181
Validation loss: 2.528810097683418

Epoch: 120| Step: 0
Training loss: 3.170023861864456
Validation loss: 2.520091560334311

Epoch: 6| Step: 1
Training loss: 2.8998855305145907
Validation loss: 2.5233570191318875

Epoch: 6| Step: 2
Training loss: 2.979893700156668
Validation loss: 2.522007225384278

Epoch: 6| Step: 3
Training loss: 3.0474191033107254
Validation loss: 2.510414382578834

Epoch: 6| Step: 4
Training loss: 2.8563084235361855
Validation loss: 2.5141646178590267

Epoch: 6| Step: 5
Training loss: 2.88532195412066
Validation loss: 2.5149395125360807

Epoch: 6| Step: 6
Training loss: 2.532666975355552
Validation loss: 2.5184032039301965

Epoch: 6| Step: 7
Training loss: 2.822059069403905
Validation loss: 2.5171770360113035

Epoch: 6| Step: 8
Training loss: 2.601738084704409
Validation loss: 2.524028580207629

Epoch: 6| Step: 9
Training loss: 2.8390262481776736
Validation loss: 2.5340872475280283

Epoch: 6| Step: 10
Training loss: 3.1728225570484754
Validation loss: 2.5644276019619143

Epoch: 6| Step: 11
Training loss: 2.257985989462109
Validation loss: 2.5632612036714173

Epoch: 6| Step: 12
Training loss: 3.061302106483155
Validation loss: 2.5627427425107037

Epoch: 6| Step: 13
Training loss: 2.7282069802392868
Validation loss: 2.562940788224816

Epoch: 121| Step: 0
Training loss: 3.174161641130369
Validation loss: 2.5782972569747002

Epoch: 6| Step: 1
Training loss: 3.1945728294631413
Validation loss: 2.585120609627705

Epoch: 6| Step: 2
Training loss: 3.19930460049646
Validation loss: 2.580376731014706

Epoch: 6| Step: 3
Training loss: 2.9154831437807904
Validation loss: 2.5692934295818173

Epoch: 6| Step: 4
Training loss: 2.9826268373620173
Validation loss: 2.5584641095066503

Epoch: 6| Step: 5
Training loss: 2.9813277580309188
Validation loss: 2.5477091615190735

Epoch: 6| Step: 6
Training loss: 2.9616822285011652
Validation loss: 2.538898003663256

Epoch: 6| Step: 7
Training loss: 2.5097744596451994
Validation loss: 2.533422095433602

Epoch: 6| Step: 8
Training loss: 3.0480017510456654
Validation loss: 2.5296440200176677

Epoch: 6| Step: 9
Training loss: 2.526831549932084
Validation loss: 2.5279453277576263

Epoch: 6| Step: 10
Training loss: 2.626777138186167
Validation loss: 2.5175616672404697

Epoch: 6| Step: 11
Training loss: 2.5904682954115597
Validation loss: 2.520411220536767

Epoch: 6| Step: 12
Training loss: 2.3215332929864125
Validation loss: 2.511053574278724

Epoch: 6| Step: 13
Training loss: 2.7995635169281194
Validation loss: 2.5100699135780355

Epoch: 122| Step: 0
Training loss: 3.0555615357619823
Validation loss: 2.5053584406231204

Epoch: 6| Step: 1
Training loss: 2.536975836524874
Validation loss: 2.50812763938819

Epoch: 6| Step: 2
Training loss: 2.3100805255346284
Validation loss: 2.510254223353527

Epoch: 6| Step: 3
Training loss: 2.5468954073784595
Validation loss: 2.5134710956821382

Epoch: 6| Step: 4
Training loss: 2.7755253200073593
Validation loss: 2.512614244208371

Epoch: 6| Step: 5
Training loss: 2.670694012115139
Validation loss: 2.5097426909371694

Epoch: 6| Step: 6
Training loss: 3.269432950564563
Validation loss: 2.5100687982719716

Epoch: 6| Step: 7
Training loss: 2.5864657412814798
Validation loss: 2.519767299544574

Epoch: 6| Step: 8
Training loss: 3.3500654527333724
Validation loss: 2.5221277071720603

Epoch: 6| Step: 9
Training loss: 2.4293366697137047
Validation loss: 2.522573713538254

Epoch: 6| Step: 10
Training loss: 2.697711617669119
Validation loss: 2.533772827646532

Epoch: 6| Step: 11
Training loss: 3.4778667617994783
Validation loss: 2.533142277853857

Epoch: 6| Step: 12
Training loss: 3.129361123156536
Validation loss: 2.5289470182791898

Epoch: 6| Step: 13
Training loss: 2.859388340986637
Validation loss: 2.5508562149328537

Epoch: 123| Step: 0
Training loss: 3.2367795400322654
Validation loss: 2.5443793663999665

Epoch: 6| Step: 1
Training loss: 2.822575810160209
Validation loss: 2.508592311266898

Epoch: 6| Step: 2
Training loss: 3.155376653420503
Validation loss: 2.5032434148492104

Epoch: 6| Step: 3
Training loss: 2.977376831479492
Validation loss: 2.499870258984541

Epoch: 6| Step: 4
Training loss: 2.348308758179528
Validation loss: 2.499976756900494

Epoch: 6| Step: 5
Training loss: 3.037734185127492
Validation loss: 2.497333139893579

Epoch: 6| Step: 6
Training loss: 2.647278838893722
Validation loss: 2.504069377786593

Epoch: 6| Step: 7
Training loss: 3.104129065642173
Validation loss: 2.504625741628916

Epoch: 6| Step: 8
Training loss: 2.504333935661079
Validation loss: 2.504185339769822

Epoch: 6| Step: 9
Training loss: 3.075604486364098
Validation loss: 2.511585957081343

Epoch: 6| Step: 10
Training loss: 2.412840104712835
Validation loss: 2.535661570772593

Epoch: 6| Step: 11
Training loss: 2.8998598788380328
Validation loss: 2.549052728904471

Epoch: 6| Step: 12
Training loss: 2.8908549449292797
Validation loss: 2.549455356362068

Epoch: 6| Step: 13
Training loss: 2.916649536809119
Validation loss: 2.5478398422902186

Epoch: 124| Step: 0
Training loss: 3.00775717151831
Validation loss: 2.5185231079253714

Epoch: 6| Step: 1
Training loss: 2.4073092618591128
Validation loss: 2.5036019782260612

Epoch: 6| Step: 2
Training loss: 2.640083844414016
Validation loss: 2.499860106420128

Epoch: 6| Step: 3
Training loss: 2.5907520295256377
Validation loss: 2.499418922799887

Epoch: 6| Step: 4
Training loss: 2.890382498801825
Validation loss: 2.496331549520407

Epoch: 6| Step: 5
Training loss: 3.0322743680812847
Validation loss: 2.495540747837356

Epoch: 6| Step: 6
Training loss: 2.8301490579986637
Validation loss: 2.494092884310742

Epoch: 6| Step: 7
Training loss: 2.716405273999052
Validation loss: 2.4959328022924283

Epoch: 6| Step: 8
Training loss: 2.7359067277904314
Validation loss: 2.497666250006126

Epoch: 6| Step: 9
Training loss: 2.582595648088306
Validation loss: 2.4932280024644315

Epoch: 6| Step: 10
Training loss: 2.7705462792260396
Validation loss: 2.4978321212786314

Epoch: 6| Step: 11
Training loss: 3.5882800061742617
Validation loss: 2.4981768918367195

Epoch: 6| Step: 12
Training loss: 2.9427665412119697
Validation loss: 2.4993298462986213

Epoch: 6| Step: 13
Training loss: 3.060556378864073
Validation loss: 2.5036219652296903

Epoch: 125| Step: 0
Training loss: 2.80796100136718
Validation loss: 2.511395169544476

Epoch: 6| Step: 1
Training loss: 2.6477597249900335
Validation loss: 2.519897765986252

Epoch: 6| Step: 2
Training loss: 3.177705864288972
Validation loss: 2.5205647406749057

Epoch: 6| Step: 3
Training loss: 3.3105543648514093
Validation loss: 2.528483228888987

Epoch: 6| Step: 4
Training loss: 2.9181900042665103
Validation loss: 2.506188544947192

Epoch: 6| Step: 5
Training loss: 2.965875458667832
Validation loss: 2.4984005467109296

Epoch: 6| Step: 6
Training loss: 2.465499186236979
Validation loss: 2.498412555279489

Epoch: 6| Step: 7
Training loss: 2.947343930164205
Validation loss: 2.5024421525659455

Epoch: 6| Step: 8
Training loss: 2.8325464240475857
Validation loss: 2.497324194509341

Epoch: 6| Step: 9
Training loss: 2.689099124390836
Validation loss: 2.5073027301112774

Epoch: 6| Step: 10
Training loss: 2.4444868259898116
Validation loss: 2.5126321087191767

Epoch: 6| Step: 11
Training loss: 2.2088537742532246
Validation loss: 2.5222033123284278

Epoch: 6| Step: 12
Training loss: 2.7599988705176655
Validation loss: 2.5364510089961985

Epoch: 6| Step: 13
Training loss: 3.704286288606617
Validation loss: 2.5400185243378237

Epoch: 126| Step: 0
Training loss: 3.194700299028119
Validation loss: 2.5520389275939044

Epoch: 6| Step: 1
Training loss: 2.6921447715091698
Validation loss: 2.5716881567681202

Epoch: 6| Step: 2
Training loss: 3.504990153822626
Validation loss: 2.5649629867094164

Epoch: 6| Step: 3
Training loss: 2.8888281934018942
Validation loss: 2.562772138137738

Epoch: 6| Step: 4
Training loss: 2.5715727803498445
Validation loss: 2.5407361381980746

Epoch: 6| Step: 5
Training loss: 2.1404242873939543
Validation loss: 2.536490551069134

Epoch: 6| Step: 6
Training loss: 3.189528175307298
Validation loss: 2.5244024985322606

Epoch: 6| Step: 7
Training loss: 2.1877004259116317
Validation loss: 2.5371049592978485

Epoch: 6| Step: 8
Training loss: 3.281816996677697
Validation loss: 2.53191395889138

Epoch: 6| Step: 9
Training loss: 2.9135384996160796
Validation loss: 2.5336450447213212

Epoch: 6| Step: 10
Training loss: 2.8905303114770105
Validation loss: 2.5330100321819153

Epoch: 6| Step: 11
Training loss: 3.034987829143121
Validation loss: 2.5366564981509208

Epoch: 6| Step: 12
Training loss: 2.83135043675546
Validation loss: 2.534889977643094

Epoch: 6| Step: 13
Training loss: 2.114174137706234
Validation loss: 2.5373846965339295

Epoch: 127| Step: 0
Training loss: 2.9900455627031866
Validation loss: 2.5456311719023743

Epoch: 6| Step: 1
Training loss: 2.566236237769148
Validation loss: 2.534087526746819

Epoch: 6| Step: 2
Training loss: 2.6649125608374433
Validation loss: 2.5378047693614003

Epoch: 6| Step: 3
Training loss: 2.8134146156893
Validation loss: 2.530127537884311

Epoch: 6| Step: 4
Training loss: 3.11639164681885
Validation loss: 2.5224302148182094

Epoch: 6| Step: 5
Training loss: 2.755475661656034
Validation loss: 2.5282768097761226

Epoch: 6| Step: 6
Training loss: 3.130414011328888
Validation loss: 2.5370207998001355

Epoch: 6| Step: 7
Training loss: 2.8545314435057274
Validation loss: 2.533655039646341

Epoch: 6| Step: 8
Training loss: 2.903563539624662
Validation loss: 2.543047780039636

Epoch: 6| Step: 9
Training loss: 2.7161023632361325
Validation loss: 2.556302696014023

Epoch: 6| Step: 10
Training loss: 2.8874492624292167
Validation loss: 2.574071443584806

Epoch: 6| Step: 11
Training loss: 2.8989893961064763
Validation loss: 2.5979528060001877

Epoch: 6| Step: 12
Training loss: 2.8252921906998556
Validation loss: 2.586837469686231

Epoch: 6| Step: 13
Training loss: 2.5637756521949413
Validation loss: 2.573199530906005

Epoch: 128| Step: 0
Training loss: 2.5799940328011517
Validation loss: 2.58731370132079

Epoch: 6| Step: 1
Training loss: 2.899378374496177
Validation loss: 2.5872586144102456

Epoch: 6| Step: 2
Training loss: 2.0447984018731478
Validation loss: 2.5545198550433708

Epoch: 6| Step: 3
Training loss: 2.901158949685931
Validation loss: 2.550165260150679

Epoch: 6| Step: 4
Training loss: 2.414787307124058
Validation loss: 2.5393671890082974

Epoch: 6| Step: 5
Training loss: 2.265475774651909
Validation loss: 2.534024442751663

Epoch: 6| Step: 6
Training loss: 2.8460311962356086
Validation loss: 2.5233839679488965

Epoch: 6| Step: 7
Training loss: 3.222261161861226
Validation loss: 2.5253923162329626

Epoch: 6| Step: 8
Training loss: 3.1324322629091066
Validation loss: 2.524638333284428

Epoch: 6| Step: 9
Training loss: 2.8345765770812914
Validation loss: 2.5388556990166133

Epoch: 6| Step: 10
Training loss: 2.8342638357752956
Validation loss: 2.533878684753901

Epoch: 6| Step: 11
Training loss: 3.07977777249101
Validation loss: 2.5248727468505883

Epoch: 6| Step: 12
Training loss: 3.440654347751056
Validation loss: 2.5393496175756063

Epoch: 6| Step: 13
Training loss: 3.1378323869062656
Validation loss: 2.5411149693229653

Epoch: 129| Step: 0
Training loss: 3.264092921018931
Validation loss: 2.551632726156149

Epoch: 6| Step: 1
Training loss: 2.0907269189279667
Validation loss: 2.5533899240266313

Epoch: 6| Step: 2
Training loss: 2.621032441242274
Validation loss: 2.5446876984334215

Epoch: 6| Step: 3
Training loss: 3.2154538953391567
Validation loss: 2.5421726369393993

Epoch: 6| Step: 4
Training loss: 2.7029799053081685
Validation loss: 2.537811994161333

Epoch: 6| Step: 5
Training loss: 3.0042522811506407
Validation loss: 2.5344977620296234

Epoch: 6| Step: 6
Training loss: 2.6137359178000454
Validation loss: 2.53730346732501

Epoch: 6| Step: 7
Training loss: 2.825209911953507
Validation loss: 2.5546524774497

Epoch: 6| Step: 8
Training loss: 3.194404155827281
Validation loss: 2.5732342183343704

Epoch: 6| Step: 9
Training loss: 3.213049869011434
Validation loss: 2.578139775477157

Epoch: 6| Step: 10
Training loss: 3.07233857142818
Validation loss: 2.5894556662516783

Epoch: 6| Step: 11
Training loss: 2.8379699317893126
Validation loss: 2.5624999199643885

Epoch: 6| Step: 12
Training loss: 2.333286988842617
Validation loss: 2.542392655943376

Epoch: 6| Step: 13
Training loss: 2.335624240041134
Validation loss: 2.5239921236403013

Epoch: 130| Step: 0
Training loss: 2.851121675044438
Validation loss: 2.5192299705549726

Epoch: 6| Step: 1
Training loss: 2.294770502820274
Validation loss: 2.517771518526094

Epoch: 6| Step: 2
Training loss: 3.4416530143953477
Validation loss: 2.515414761727585

Epoch: 6| Step: 3
Training loss: 2.9530780122439917
Validation loss: 2.5176067562758906

Epoch: 6| Step: 4
Training loss: 2.876767485948924
Validation loss: 2.52091274239794

Epoch: 6| Step: 5
Training loss: 2.71857934175005
Validation loss: 2.5149924888727826

Epoch: 6| Step: 6
Training loss: 2.4311176764166915
Validation loss: 2.518411581749643

Epoch: 6| Step: 7
Training loss: 2.2731889411884154
Validation loss: 2.515275906902454

Epoch: 6| Step: 8
Training loss: 2.7464552488099674
Validation loss: 2.518470765211269

Epoch: 6| Step: 9
Training loss: 3.004845996788605
Validation loss: 2.5306624213287927

Epoch: 6| Step: 10
Training loss: 3.045326191385494
Validation loss: 2.5412243122428553

Epoch: 6| Step: 11
Training loss: 3.443502145145347
Validation loss: 2.5629532035840175

Epoch: 6| Step: 12
Training loss: 2.8371433185120964
Validation loss: 2.5760769572070994

Epoch: 6| Step: 13
Training loss: 2.6335770490190935
Validation loss: 2.589293611963928

Epoch: 131| Step: 0
Training loss: 2.8607774640776604
Validation loss: 2.615979432318344

Epoch: 6| Step: 1
Training loss: 2.749551563113115
Validation loss: 2.618577229973462

Epoch: 6| Step: 2
Training loss: 2.597338664209325
Validation loss: 2.6114702120344955

Epoch: 6| Step: 3
Training loss: 2.7696619258553405
Validation loss: 2.608833801645873

Epoch: 6| Step: 4
Training loss: 2.7329888890498033
Validation loss: 2.6136190537396633

Epoch: 6| Step: 5
Training loss: 3.421228217047579
Validation loss: 2.624029238851104

Epoch: 6| Step: 6
Training loss: 2.621311138933562
Validation loss: 2.5787748023166643

Epoch: 6| Step: 7
Training loss: 2.367074894508701
Validation loss: 2.555821751286981

Epoch: 6| Step: 8
Training loss: 2.8385747411825
Validation loss: 2.5232584752748193

Epoch: 6| Step: 9
Training loss: 2.9576397651415696
Validation loss: 2.5072073104169057

Epoch: 6| Step: 10
Training loss: 3.344206591653861
Validation loss: 2.503995957673803

Epoch: 6| Step: 11
Training loss: 2.610926732075903
Validation loss: 2.510615740254986

Epoch: 6| Step: 12
Training loss: 2.794197036512891
Validation loss: 2.514357149317825

Epoch: 6| Step: 13
Training loss: 3.531421218367076
Validation loss: 2.5161328586202725

Epoch: 132| Step: 0
Training loss: 2.792979591188531
Validation loss: 2.514197950941607

Epoch: 6| Step: 1
Training loss: 2.8828604676099063
Validation loss: 2.5189620268894743

Epoch: 6| Step: 2
Training loss: 2.688537308754555
Validation loss: 2.5120362170621418

Epoch: 6| Step: 3
Training loss: 3.0754840190771797
Validation loss: 2.507859353904446

Epoch: 6| Step: 4
Training loss: 2.624693898110188
Validation loss: 2.4999415226731845

Epoch: 6| Step: 5
Training loss: 3.336515640082647
Validation loss: 2.503966878975057

Epoch: 6| Step: 6
Training loss: 3.2135910615674685
Validation loss: 2.5134234131075948

Epoch: 6| Step: 7
Training loss: 2.4752488367624865
Validation loss: 2.530718640404493

Epoch: 6| Step: 8
Training loss: 1.8961603769888378
Validation loss: 2.5403374229254085

Epoch: 6| Step: 9
Training loss: 2.9433201696750255
Validation loss: 2.5632022272642354

Epoch: 6| Step: 10
Training loss: 3.1843955686015364
Validation loss: 2.586257958830403

Epoch: 6| Step: 11
Training loss: 2.6074769203576382
Validation loss: 2.601969041130968

Epoch: 6| Step: 12
Training loss: 2.7863750599809842
Validation loss: 2.6522755914116383

Epoch: 6| Step: 13
Training loss: 3.3752003363031156
Validation loss: 2.6741007977870725

Epoch: 133| Step: 0
Training loss: 2.7451446325557973
Validation loss: 2.6946320209629984

Epoch: 6| Step: 1
Training loss: 2.7317857090363464
Validation loss: 2.642586813457522

Epoch: 6| Step: 2
Training loss: 2.6172343235666857
Validation loss: 2.6333595229274773

Epoch: 6| Step: 3
Training loss: 2.648156525327666
Validation loss: 2.594990225839971

Epoch: 6| Step: 4
Training loss: 3.412739303079163
Validation loss: 2.572572759294171

Epoch: 6| Step: 5
Training loss: 3.1795576289317737
Validation loss: 2.57844145949705

Epoch: 6| Step: 6
Training loss: 2.490356538057454
Validation loss: 2.5820016223665383

Epoch: 6| Step: 7
Training loss: 3.121990433125375
Validation loss: 2.6168912996374796

Epoch: 6| Step: 8
Training loss: 3.1827689570958384
Validation loss: 2.6058315804181507

Epoch: 6| Step: 9
Training loss: 2.4373896647203432
Validation loss: 2.595867120721779

Epoch: 6| Step: 10
Training loss: 2.737113235534062
Validation loss: 2.56331702132506

Epoch: 6| Step: 11
Training loss: 2.784480073018763
Validation loss: 2.532182486021328

Epoch: 6| Step: 12
Training loss: 2.9170292946773535
Validation loss: 2.508397702093097

Epoch: 6| Step: 13
Training loss: 3.136392198716532
Validation loss: 2.505580934170255

Epoch: 134| Step: 0
Training loss: 2.567625641539107
Validation loss: 2.5078291116973865

Epoch: 6| Step: 1
Training loss: 3.1025438269655736
Validation loss: 2.5149908890130317

Epoch: 6| Step: 2
Training loss: 2.4979763423694297
Validation loss: 2.517380901782684

Epoch: 6| Step: 3
Training loss: 2.837707975722829
Validation loss: 2.521984987139721

Epoch: 6| Step: 4
Training loss: 3.6475451274587605
Validation loss: 2.5379937145510523

Epoch: 6| Step: 5
Training loss: 2.6137026231833076
Validation loss: 2.5134835667053146

Epoch: 6| Step: 6
Training loss: 2.3800604264418173
Validation loss: 2.5066451918963493

Epoch: 6| Step: 7
Training loss: 3.1866217506573786
Validation loss: 2.497493237759076

Epoch: 6| Step: 8
Training loss: 3.025858695735413
Validation loss: 2.4998493010723153

Epoch: 6| Step: 9
Training loss: 2.995927271389294
Validation loss: 2.500667585433048

Epoch: 6| Step: 10
Training loss: 2.726920730098953
Validation loss: 2.5056902352208477

Epoch: 6| Step: 11
Training loss: 2.9093762062799593
Validation loss: 2.530761964906973

Epoch: 6| Step: 12
Training loss: 2.4033320185234013
Validation loss: 2.5692935852385914

Epoch: 6| Step: 13
Training loss: 3.2694641616847577
Validation loss: 2.588382455498488

Epoch: 135| Step: 0
Training loss: 2.9429802602973743
Validation loss: 2.597488634523101

Epoch: 6| Step: 1
Training loss: 2.956034846470827
Validation loss: 2.6150104105429306

Epoch: 6| Step: 2
Training loss: 2.935624193301465
Validation loss: 2.5957288926047584

Epoch: 6| Step: 3
Training loss: 2.619467854948621
Validation loss: 2.5675122043598217

Epoch: 6| Step: 4
Training loss: 2.786915869300872
Validation loss: 2.527691092258062

Epoch: 6| Step: 5
Training loss: 2.238507164543842
Validation loss: 2.50289637642619

Epoch: 6| Step: 6
Training loss: 2.5376141452015037
Validation loss: 2.4905586753752362

Epoch: 6| Step: 7
Training loss: 2.7302064346681405
Validation loss: 2.4817042453151243

Epoch: 6| Step: 8
Training loss: 3.274162266871434
Validation loss: 2.491492963989001

Epoch: 6| Step: 9
Training loss: 2.5820863749611496
Validation loss: 2.5137094674511737

Epoch: 6| Step: 10
Training loss: 2.458080752915576
Validation loss: 2.5175060825567903

Epoch: 6| Step: 11
Training loss: 2.8538387880619798
Validation loss: 2.5219730338878867

Epoch: 6| Step: 12
Training loss: 3.309874159619161
Validation loss: 2.5305605665639614

Epoch: 6| Step: 13
Training loss: 3.1648754441278193
Validation loss: 2.566264836654194

Epoch: 136| Step: 0
Training loss: 2.952471948501705
Validation loss: 2.6036189296136953

Epoch: 6| Step: 1
Training loss: 3.048586633613433
Validation loss: 2.5524545975018667

Epoch: 6| Step: 2
Training loss: 3.335296640772122
Validation loss: 2.5165348566774384

Epoch: 6| Step: 3
Training loss: 3.1172526646736607
Validation loss: 2.5122816344067513

Epoch: 6| Step: 4
Training loss: 2.900226709120243
Validation loss: 2.4850579136635473

Epoch: 6| Step: 5
Training loss: 2.5163242481873
Validation loss: 2.489346619659634

Epoch: 6| Step: 6
Training loss: 2.117314746594143
Validation loss: 2.5461956199870244

Epoch: 6| Step: 7
Training loss: 3.135705995781489
Validation loss: 2.574669996350009

Epoch: 6| Step: 8
Training loss: 2.834552857728936
Validation loss: 2.611673237176359

Epoch: 6| Step: 9
Training loss: 2.523654987422891
Validation loss: 2.626500085381427

Epoch: 6| Step: 10
Training loss: 3.125842934409556
Validation loss: 2.6626514690026313

Epoch: 6| Step: 11
Training loss: 2.7443745903652497
Validation loss: 2.6718572877331486

Epoch: 6| Step: 12
Training loss: 3.03820788765007
Validation loss: 2.6767691712838557

Epoch: 6| Step: 13
Training loss: 2.91253130981905
Validation loss: 2.642064165397075

Epoch: 137| Step: 0
Training loss: 2.827554971985229
Validation loss: 2.585292859610185

Epoch: 6| Step: 1
Training loss: 2.702256961872479
Validation loss: 2.5633902225203338

Epoch: 6| Step: 2
Training loss: 2.230212408991841
Validation loss: 2.5409483675475917

Epoch: 6| Step: 3
Training loss: 2.574302289935714
Validation loss: 2.512913206791274

Epoch: 6| Step: 4
Training loss: 2.838694007821897
Validation loss: 2.513047993814088

Epoch: 6| Step: 5
Training loss: 2.5826870407215967
Validation loss: 2.514846428542554

Epoch: 6| Step: 6
Training loss: 3.1516564812404013
Validation loss: 2.5152864344905552

Epoch: 6| Step: 7
Training loss: 2.7214708415790425
Validation loss: 2.5107978239040794

Epoch: 6| Step: 8
Training loss: 3.4647765900340035
Validation loss: 2.5145613150752353

Epoch: 6| Step: 9
Training loss: 2.8640636920666336
Validation loss: 2.520890405005974

Epoch: 6| Step: 10
Training loss: 2.813706880812714
Validation loss: 2.514385666371714

Epoch: 6| Step: 11
Training loss: 3.3585124483137645
Validation loss: 2.5155027432810733

Epoch: 6| Step: 12
Training loss: 2.77202559516837
Validation loss: 2.514800917927337

Epoch: 6| Step: 13
Training loss: 2.753616382683579
Validation loss: 2.5204126181028577

Epoch: 138| Step: 0
Training loss: 3.2430792260151367
Validation loss: 2.5224708995000116

Epoch: 6| Step: 1
Training loss: 3.1292354110569085
Validation loss: 2.534052183068716

Epoch: 6| Step: 2
Training loss: 3.045575613102474
Validation loss: 2.541432511268763

Epoch: 6| Step: 3
Training loss: 3.0175068572186903
Validation loss: 2.5471027452870967

Epoch: 6| Step: 4
Training loss: 2.701672025703074
Validation loss: 2.5378996821165196

Epoch: 6| Step: 5
Training loss: 2.388845342293421
Validation loss: 2.5326155090277123

Epoch: 6| Step: 6
Training loss: 2.2978431581537233
Validation loss: 2.527261469727865

Epoch: 6| Step: 7
Training loss: 2.9796866294407485
Validation loss: 2.5246431820471664

Epoch: 6| Step: 8
Training loss: 2.6764102391428106
Validation loss: 2.5190450626755427

Epoch: 6| Step: 9
Training loss: 2.749812900073857
Validation loss: 2.511934520968862

Epoch: 6| Step: 10
Training loss: 2.9700497642997488
Validation loss: 2.507111594642337

Epoch: 6| Step: 11
Training loss: 2.810449234019923
Validation loss: 2.5122128413090032

Epoch: 6| Step: 12
Training loss: 2.971704398311653
Validation loss: 2.5143383834945263

Epoch: 6| Step: 13
Training loss: 2.5690906716423756
Validation loss: 2.513141353538964

Epoch: 139| Step: 0
Training loss: 2.314909324270812
Validation loss: 2.5218814039623645

Epoch: 6| Step: 1
Training loss: 3.1176882845897476
Validation loss: 2.5197486096230324

Epoch: 6| Step: 2
Training loss: 3.5595677672744674
Validation loss: 2.5194026073783036

Epoch: 6| Step: 3
Training loss: 2.4478121038519602
Validation loss: 2.5234356764015935

Epoch: 6| Step: 4
Training loss: 3.2058631172776533
Validation loss: 2.519024313653895

Epoch: 6| Step: 5
Training loss: 2.73802307914442
Validation loss: 2.523877588210498

Epoch: 6| Step: 6
Training loss: 2.1391948739799993
Validation loss: 2.5260441463666763

Epoch: 6| Step: 7
Training loss: 2.4517105787205598
Validation loss: 2.529801784286186

Epoch: 6| Step: 8
Training loss: 2.6620399650766484
Validation loss: 2.528157179763398

Epoch: 6| Step: 9
Training loss: 2.913438827414508
Validation loss: 2.5327432133217553

Epoch: 6| Step: 10
Training loss: 2.985705972635165
Validation loss: 2.5317730167690358

Epoch: 6| Step: 11
Training loss: 3.34277372279432
Validation loss: 2.530956359141263

Epoch: 6| Step: 12
Training loss: 2.6906527279655665
Validation loss: 2.5576125175233186

Epoch: 6| Step: 13
Training loss: 2.5531292283806404
Validation loss: 2.575029505453009

Epoch: 140| Step: 0
Training loss: 2.5992811126153095
Validation loss: 2.581644958013123

Epoch: 6| Step: 1
Training loss: 2.6246267689172385
Validation loss: 2.607408481692702

Epoch: 6| Step: 2
Training loss: 2.6364340847492356
Validation loss: 2.6323278850227116

Epoch: 6| Step: 3
Training loss: 2.8307058455633367
Validation loss: 2.7025432843937014

Epoch: 6| Step: 4
Training loss: 3.6379273206215257
Validation loss: 2.7333367101837034

Epoch: 6| Step: 5
Training loss: 2.7628639361207425
Validation loss: 2.678979142934222

Epoch: 6| Step: 6
Training loss: 2.398425273056426
Validation loss: 2.6342680931185485

Epoch: 6| Step: 7
Training loss: 3.2758059434530913
Validation loss: 2.591898341593356

Epoch: 6| Step: 8
Training loss: 2.766314059695261
Validation loss: 2.577972147050133

Epoch: 6| Step: 9
Training loss: 3.468950695383541
Validation loss: 2.5565458825554734

Epoch: 6| Step: 10
Training loss: 2.9251576307811162
Validation loss: 2.550114039405168

Epoch: 6| Step: 11
Training loss: 3.041153607579298
Validation loss: 2.540061928912434

Epoch: 6| Step: 12
Training loss: 2.4158946371661543
Validation loss: 2.5210243613071035

Epoch: 6| Step: 13
Training loss: 2.1400993425716104
Validation loss: 2.497262286316237

Epoch: 141| Step: 0
Training loss: 2.786351871536357
Validation loss: 2.473001788997413

Epoch: 6| Step: 1
Training loss: 2.5579902228316937
Validation loss: 2.4831676845246973

Epoch: 6| Step: 2
Training loss: 2.6472734351828864
Validation loss: 2.481920197248563

Epoch: 6| Step: 3
Training loss: 3.2758829455394123
Validation loss: 2.5014882385352974

Epoch: 6| Step: 4
Training loss: 3.259922432942052
Validation loss: 2.4995407308164137

Epoch: 6| Step: 5
Training loss: 2.5357813835860923
Validation loss: 2.520084716060123

Epoch: 6| Step: 6
Training loss: 3.268594514201265
Validation loss: 2.5050573243152896

Epoch: 6| Step: 7
Training loss: 3.1276740268313183
Validation loss: 2.512917871590637

Epoch: 6| Step: 8
Training loss: 2.826696045410983
Validation loss: 2.5135001266433994

Epoch: 6| Step: 9
Training loss: 2.8413359068249213
Validation loss: 2.514482511212662

Epoch: 6| Step: 10
Training loss: 2.5629540017979315
Validation loss: 2.5101261327366022

Epoch: 6| Step: 11
Training loss: 2.577031776531325
Validation loss: 2.51325872996428

Epoch: 6| Step: 12
Training loss: 2.42352474997577
Validation loss: 2.535999010312955

Epoch: 6| Step: 13
Training loss: 2.2845524960299555
Validation loss: 2.550541521296842

Epoch: 142| Step: 0
Training loss: 3.15648265018949
Validation loss: 2.5728964470808715

Epoch: 6| Step: 1
Training loss: 2.409849966610425
Validation loss: 2.598250750944571

Epoch: 6| Step: 2
Training loss: 3.067480747003923
Validation loss: 2.5846949596845556

Epoch: 6| Step: 3
Training loss: 2.4731057287337324
Validation loss: 2.549883425237795

Epoch: 6| Step: 4
Training loss: 3.0199399131203624
Validation loss: 2.5390387956318925

Epoch: 6| Step: 5
Training loss: 2.762983709595876
Validation loss: 2.520030867616568

Epoch: 6| Step: 6
Training loss: 2.809225422544515
Validation loss: 2.4969029470405406

Epoch: 6| Step: 7
Training loss: 2.8253467043238762
Validation loss: 2.498719717162347

Epoch: 6| Step: 8
Training loss: 2.9733974019091653
Validation loss: 2.487353824140584

Epoch: 6| Step: 9
Training loss: 2.8724430157592646
Validation loss: 2.4894039061763578

Epoch: 6| Step: 10
Training loss: 2.026159274913528
Validation loss: 2.4838835197275944

Epoch: 6| Step: 11
Training loss: 3.2035437333485945
Validation loss: 2.4821722959308374

Epoch: 6| Step: 12
Training loss: 2.645463832575553
Validation loss: 2.4923155672590442

Epoch: 6| Step: 13
Training loss: 2.805565061857361
Validation loss: 2.4805880682510146

Epoch: 143| Step: 0
Training loss: 2.6358841995250217
Validation loss: 2.481441466176474

Epoch: 6| Step: 1
Training loss: 3.182479494902305
Validation loss: 2.4854476407606056

Epoch: 6| Step: 2
Training loss: 2.513647498758797
Validation loss: 2.4871664784074756

Epoch: 6| Step: 3
Training loss: 2.7191512590026945
Validation loss: 2.4875431767545866

Epoch: 6| Step: 4
Training loss: 2.3416421185312024
Validation loss: 2.4901047871583506

Epoch: 6| Step: 5
Training loss: 2.9745994362317547
Validation loss: 2.478724256049647

Epoch: 6| Step: 6
Training loss: 2.9066248826281296
Validation loss: 2.4774793058363294

Epoch: 6| Step: 7
Training loss: 2.5245783916533524
Validation loss: 2.489812832050354

Epoch: 6| Step: 8
Training loss: 3.2182194541039224
Validation loss: 2.4985528756864683

Epoch: 6| Step: 9
Training loss: 2.8273520915152663
Validation loss: 2.491041860034313

Epoch: 6| Step: 10
Training loss: 2.898094136343385
Validation loss: 2.492504939951746

Epoch: 6| Step: 11
Training loss: 2.873480519672273
Validation loss: 2.518409203286481

Epoch: 6| Step: 12
Training loss: 2.612375053812803
Validation loss: 2.5035975146892895

Epoch: 6| Step: 13
Training loss: 2.3106522266041662
Validation loss: 2.4982703101133468

Epoch: 144| Step: 0
Training loss: 2.6947809994524166
Validation loss: 2.4949527458723577

Epoch: 6| Step: 1
Training loss: 2.8093740257456683
Validation loss: 2.4877926024115125

Epoch: 6| Step: 2
Training loss: 3.0292014839308763
Validation loss: 2.4934879489429487

Epoch: 6| Step: 3
Training loss: 2.2816406333595487
Validation loss: 2.5064947129988058

Epoch: 6| Step: 4
Training loss: 2.6976246522344915
Validation loss: 2.50062009955418

Epoch: 6| Step: 5
Training loss: 2.832150455465348
Validation loss: 2.5062994070080045

Epoch: 6| Step: 6
Training loss: 3.105284333901255
Validation loss: 2.4845589014848652

Epoch: 6| Step: 7
Training loss: 1.9699637894763813
Validation loss: 2.466807847471186

Epoch: 6| Step: 8
Training loss: 3.5826009549000544
Validation loss: 2.467332214002952

Epoch: 6| Step: 9
Training loss: 2.9308758982920047
Validation loss: 2.46204830687052

Epoch: 6| Step: 10
Training loss: 2.8469984343952874
Validation loss: 2.46375864382833

Epoch: 6| Step: 11
Training loss: 3.0116288187772815
Validation loss: 2.4647420590447586

Epoch: 6| Step: 12
Training loss: 2.285987846148631
Validation loss: 2.470645060893159

Epoch: 6| Step: 13
Training loss: 2.2978382815436427
Validation loss: 2.4587368565313863

Epoch: 145| Step: 0
Training loss: 3.3388080619582143
Validation loss: 2.4651002464593366

Epoch: 6| Step: 1
Training loss: 2.6564260985399906
Validation loss: 2.461719911122118

Epoch: 6| Step: 2
Training loss: 2.6319420165020277
Validation loss: 2.467206433723026

Epoch: 6| Step: 3
Training loss: 3.238919810617703
Validation loss: 2.4744352437791584

Epoch: 6| Step: 4
Training loss: 2.6938648703880617
Validation loss: 2.473300932933556

Epoch: 6| Step: 5
Training loss: 2.6451036743729257
Validation loss: 2.481913121693352

Epoch: 6| Step: 6
Training loss: 2.5940692199612636
Validation loss: 2.4914511961917585

Epoch: 6| Step: 7
Training loss: 2.6090511646451717
Validation loss: 2.503825513519606

Epoch: 6| Step: 8
Training loss: 3.297688026880626
Validation loss: 2.5378000275701758

Epoch: 6| Step: 9
Training loss: 2.2175742244232586
Validation loss: 2.502620540279059

Epoch: 6| Step: 10
Training loss: 2.5088918864560115
Validation loss: 2.4984360940817645

Epoch: 6| Step: 11
Training loss: 2.7895096278881724
Validation loss: 2.498684982311386

Epoch: 6| Step: 12
Training loss: 2.471755311096171
Validation loss: 2.496331525900253

Epoch: 6| Step: 13
Training loss: 2.8619506575344915
Validation loss: 2.4966952744146464

Epoch: 146| Step: 0
Training loss: 2.627864818417365
Validation loss: 2.4878389296330155

Epoch: 6| Step: 1
Training loss: 2.438495432727597
Validation loss: 2.4929656523656374

Epoch: 6| Step: 2
Training loss: 2.8939855887496444
Validation loss: 2.505248960344183

Epoch: 6| Step: 3
Training loss: 2.049299711314383
Validation loss: 2.515891996805669

Epoch: 6| Step: 4
Training loss: 2.6504537733703164
Validation loss: 2.5234421651549392

Epoch: 6| Step: 5
Training loss: 2.9909585764728934
Validation loss: 2.5079857566372326

Epoch: 6| Step: 6
Training loss: 2.542636738328809
Validation loss: 2.481606699812405

Epoch: 6| Step: 7
Training loss: 3.0318151517397705
Validation loss: 2.4738213655458443

Epoch: 6| Step: 8
Training loss: 2.2331484115488003
Validation loss: 2.4729707317646943

Epoch: 6| Step: 9
Training loss: 2.6580483127333685
Validation loss: 2.478920041649534

Epoch: 6| Step: 10
Training loss: 2.968858897571005
Validation loss: 2.4719134159737317

Epoch: 6| Step: 11
Training loss: 2.7485173303266985
Validation loss: 2.475504490711005

Epoch: 6| Step: 12
Training loss: 3.1478076995900865
Validation loss: 2.4682631858315878

Epoch: 6| Step: 13
Training loss: 3.8623990091991023
Validation loss: 2.463885357591135

Epoch: 147| Step: 0
Training loss: 2.6027700926419466
Validation loss: 2.4753742140828945

Epoch: 6| Step: 1
Training loss: 3.2217834400446437
Validation loss: 2.4854180758374214

Epoch: 6| Step: 2
Training loss: 3.242298390893537
Validation loss: 2.482899955502453

Epoch: 6| Step: 3
Training loss: 2.7898505457290868
Validation loss: 2.4822210095064046

Epoch: 6| Step: 4
Training loss: 2.3616924904017393
Validation loss: 2.4924710801901826

Epoch: 6| Step: 5
Training loss: 2.800944856895549
Validation loss: 2.485600076639197

Epoch: 6| Step: 6
Training loss: 2.393980974254042
Validation loss: 2.509585287865064

Epoch: 6| Step: 7
Training loss: 2.5432014417468434
Validation loss: 2.53124952803688

Epoch: 6| Step: 8
Training loss: 2.908004395283522
Validation loss: 2.6171369180090633

Epoch: 6| Step: 9
Training loss: 3.0366691049453656
Validation loss: 2.697211464445822

Epoch: 6| Step: 10
Training loss: 2.833709430042384
Validation loss: 2.7614269134596556

Epoch: 6| Step: 11
Training loss: 2.9149466392906938
Validation loss: 2.706910939437376

Epoch: 6| Step: 12
Training loss: 2.958404181979717
Validation loss: 2.625804579563738

Epoch: 6| Step: 13
Training loss: 2.3061622168729214
Validation loss: 2.5438303144412613

Epoch: 148| Step: 0
Training loss: 3.166433392682981
Validation loss: 2.50391698306446

Epoch: 6| Step: 1
Training loss: 2.48735040952897
Validation loss: 2.4967944225929446

Epoch: 6| Step: 2
Training loss: 2.6589826103867
Validation loss: 2.484965862898767

Epoch: 6| Step: 3
Training loss: 2.5852846548931843
Validation loss: 2.4992972724530804

Epoch: 6| Step: 4
Training loss: 2.965532667613956
Validation loss: 2.489737413021427

Epoch: 6| Step: 5
Training loss: 2.3197463658235806
Validation loss: 2.487863040427412

Epoch: 6| Step: 6
Training loss: 2.870679677570847
Validation loss: 2.4880724311707256

Epoch: 6| Step: 7
Training loss: 2.2067329677790113
Validation loss: 2.496862822180599

Epoch: 6| Step: 8
Training loss: 2.5955852771698313
Validation loss: 2.4901583839771924

Epoch: 6| Step: 9
Training loss: 3.360862225301855
Validation loss: 2.4952320891260378

Epoch: 6| Step: 10
Training loss: 2.493865115154677
Validation loss: 2.4923378346818725

Epoch: 6| Step: 11
Training loss: 3.4490885207755264
Validation loss: 2.4914267558611063

Epoch: 6| Step: 12
Training loss: 3.0682324068156714
Validation loss: 2.493890937336141

Epoch: 6| Step: 13
Training loss: 2.4743963449457937
Validation loss: 2.4886445238624626

Epoch: 149| Step: 0
Training loss: 3.2451946238974108
Validation loss: 2.4998285009154855

Epoch: 6| Step: 1
Training loss: 1.9660574651063645
Validation loss: 2.509776838630366

Epoch: 6| Step: 2
Training loss: 3.2569944969367346
Validation loss: 2.5249217890068407

Epoch: 6| Step: 3
Training loss: 2.9010087199140884
Validation loss: 2.5349193316739487

Epoch: 6| Step: 4
Training loss: 3.0217977803886087
Validation loss: 2.556635968280617

Epoch: 6| Step: 5
Training loss: 2.7027274484403674
Validation loss: 2.597068541631379

Epoch: 6| Step: 6
Training loss: 2.8445259125619384
Validation loss: 2.555645981177576

Epoch: 6| Step: 7
Training loss: 2.847670985472849
Validation loss: 2.544257624834719

Epoch: 6| Step: 8
Training loss: 2.693412487012584
Validation loss: 2.4916458407909143

Epoch: 6| Step: 9
Training loss: 2.0512727275660945
Validation loss: 2.479391477847574

Epoch: 6| Step: 10
Training loss: 2.9034039087254375
Validation loss: 2.462565320009949

Epoch: 6| Step: 11
Training loss: 2.9194119930026483
Validation loss: 2.4590674583915892

Epoch: 6| Step: 12
Training loss: 2.5643936231672813
Validation loss: 2.463780657404669

Epoch: 6| Step: 13
Training loss: 2.5841194515431654
Validation loss: 2.471649592788998

Epoch: 150| Step: 0
Training loss: 2.9459334713014114
Validation loss: 2.4729057279079587

Epoch: 6| Step: 1
Training loss: 2.7941827016526397
Validation loss: 2.486100514268025

Epoch: 6| Step: 2
Training loss: 2.4911089150635273
Validation loss: 2.487969731855178

Epoch: 6| Step: 3
Training loss: 2.9559632240867475
Validation loss: 2.494590846932587

Epoch: 6| Step: 4
Training loss: 2.6851486743135333
Validation loss: 2.499898682869053

Epoch: 6| Step: 5
Training loss: 3.139098446432747
Validation loss: 2.4990552645101207

Epoch: 6| Step: 6
Training loss: 2.238456040193368
Validation loss: 2.5056879157896867

Epoch: 6| Step: 7
Training loss: 2.613342740599899
Validation loss: 2.51131811659337

Epoch: 6| Step: 8
Training loss: 3.0538811363266927
Validation loss: 2.510648675252315

Epoch: 6| Step: 9
Training loss: 2.6765707591520083
Validation loss: 2.4969166250759813

Epoch: 6| Step: 10
Training loss: 2.3332485683121638
Validation loss: 2.5127320707049337

Epoch: 6| Step: 11
Training loss: 2.9922893297681683
Validation loss: 2.535660296869147

Epoch: 6| Step: 12
Training loss: 2.913547173718642
Validation loss: 2.5522755248928384

Epoch: 6| Step: 13
Training loss: 2.2736415705902533
Validation loss: 2.555805789555377

Epoch: 151| Step: 0
Training loss: 3.1606638044585593
Validation loss: 2.5518321740976426

Epoch: 6| Step: 1
Training loss: 2.814659815233145
Validation loss: 2.549688391212048

Epoch: 6| Step: 2
Training loss: 2.6141403451149134
Validation loss: 2.5610824393687404

Epoch: 6| Step: 3
Training loss: 2.5811540784400977
Validation loss: 2.554588852590575

Epoch: 6| Step: 4
Training loss: 2.603151678015025
Validation loss: 2.530798906921851

Epoch: 6| Step: 5
Training loss: 3.1456557638481915
Validation loss: 2.499073648591295

Epoch: 6| Step: 6
Training loss: 2.697122690224126
Validation loss: 2.5001590647392895

Epoch: 6| Step: 7
Training loss: 2.3632054844841046
Validation loss: 2.492775398343206

Epoch: 6| Step: 8
Training loss: 2.888254214122349
Validation loss: 2.485591462395944

Epoch: 6| Step: 9
Training loss: 2.550827423191878
Validation loss: 2.476641494972957

Epoch: 6| Step: 10
Training loss: 2.687279093335129
Validation loss: 2.4806440616195955

Epoch: 6| Step: 11
Training loss: 3.1996312882673488
Validation loss: 2.4675135560763644

Epoch: 6| Step: 12
Training loss: 2.2544333967064865
Validation loss: 2.4698870610328143

Epoch: 6| Step: 13
Training loss: 2.514355925796532
Validation loss: 2.4708344442428727

Epoch: 152| Step: 0
Training loss: 2.770405404070905
Validation loss: 2.475267024803676

Epoch: 6| Step: 1
Training loss: 2.6958336367796107
Validation loss: 2.473703530385456

Epoch: 6| Step: 2
Training loss: 3.0452757722098984
Validation loss: 2.4758622223103752

Epoch: 6| Step: 3
Training loss: 3.1003392495369337
Validation loss: 2.4659731715552287

Epoch: 6| Step: 4
Training loss: 2.705884109676991
Validation loss: 2.4740548429894824

Epoch: 6| Step: 5
Training loss: 2.594101296040433
Validation loss: 2.4943198309908285

Epoch: 6| Step: 6
Training loss: 2.8365121474655677
Validation loss: 2.5146068504168966

Epoch: 6| Step: 7
Training loss: 2.4938016345957434
Validation loss: 2.5290219705081847

Epoch: 6| Step: 8
Training loss: 2.7556891115015216
Validation loss: 2.5634973907483984

Epoch: 6| Step: 9
Training loss: 2.5790862170004476
Validation loss: 2.5862771127761235

Epoch: 6| Step: 10
Training loss: 2.364696942483594
Validation loss: 2.6164019925838704

Epoch: 6| Step: 11
Training loss: 2.7383731929999287
Validation loss: 2.6204039070845435

Epoch: 6| Step: 12
Training loss: 3.1108333675596733
Validation loss: 2.6129710399310273

Epoch: 6| Step: 13
Training loss: 2.3896010456132726
Validation loss: 2.600806379179124

Epoch: 153| Step: 0
Training loss: 2.355823192846736
Validation loss: 2.55777598268209

Epoch: 6| Step: 1
Training loss: 1.534632314327912
Validation loss: 2.520794545702974

Epoch: 6| Step: 2
Training loss: 2.5448764378318622
Validation loss: 2.5056133460080368

Epoch: 6| Step: 3
Training loss: 3.557617857663607
Validation loss: 2.4893384498875446

Epoch: 6| Step: 4
Training loss: 2.811777149133473
Validation loss: 2.4921702460440964

Epoch: 6| Step: 5
Training loss: 2.77495333658111
Validation loss: 2.487450238346055

Epoch: 6| Step: 6
Training loss: 2.9190300947979173
Validation loss: 2.4949965254903925

Epoch: 6| Step: 7
Training loss: 2.8053092586145483
Validation loss: 2.4898283766573055

Epoch: 6| Step: 8
Training loss: 2.368670411395867
Validation loss: 2.4858020015439095

Epoch: 6| Step: 9
Training loss: 3.1984182620902573
Validation loss: 2.4816119322394976

Epoch: 6| Step: 10
Training loss: 3.0622480639157983
Validation loss: 2.474753916631815

Epoch: 6| Step: 11
Training loss: 2.636754466627307
Validation loss: 2.478172704479595

Epoch: 6| Step: 12
Training loss: 2.4378498511013538
Validation loss: 2.4787255023303425

Epoch: 6| Step: 13
Training loss: 3.0866945521150355
Validation loss: 2.4825387800047594

Epoch: 154| Step: 0
Training loss: 2.4461080701196227
Validation loss: 2.4919844403309592

Epoch: 6| Step: 1
Training loss: 2.033923458493403
Validation loss: 2.5033137253411923

Epoch: 6| Step: 2
Training loss: 3.003743379341922
Validation loss: 2.517884988235284

Epoch: 6| Step: 3
Training loss: 2.61473501507632
Validation loss: 2.5304985293124767

Epoch: 6| Step: 4
Training loss: 2.7976630608401982
Validation loss: 2.5447099538707634

Epoch: 6| Step: 5
Training loss: 3.162597015460893
Validation loss: 2.545056092493316

Epoch: 6| Step: 6
Training loss: 2.8179959322573107
Validation loss: 2.5628124699839034

Epoch: 6| Step: 7
Training loss: 2.333187053273167
Validation loss: 2.5809820886147863

Epoch: 6| Step: 8
Training loss: 2.9625103077125696
Validation loss: 2.585062983809451

Epoch: 6| Step: 9
Training loss: 2.850300548834976
Validation loss: 2.5790662671181153

Epoch: 6| Step: 10
Training loss: 3.007693280916509
Validation loss: 2.556530189076486

Epoch: 6| Step: 11
Training loss: 3.1173548450342317
Validation loss: 2.5393625167656113

Epoch: 6| Step: 12
Training loss: 2.5237881915758105
Validation loss: 2.51680658822513

Epoch: 6| Step: 13
Training loss: 2.03351290905215
Validation loss: 2.493719727977548

Epoch: 155| Step: 0
Training loss: 3.0170605656983893
Validation loss: 2.48928923450199

Epoch: 6| Step: 1
Training loss: 2.693955497249516
Validation loss: 2.4833689648332875

Epoch: 6| Step: 2
Training loss: 2.51484573330998
Validation loss: 2.4941191394388085

Epoch: 6| Step: 3
Training loss: 2.9078650140299387
Validation loss: 2.498832337658587

Epoch: 6| Step: 4
Training loss: 3.2357646518373486
Validation loss: 2.5203298704799386

Epoch: 6| Step: 5
Training loss: 2.571995332111495
Validation loss: 2.525378805625416

Epoch: 6| Step: 6
Training loss: 2.453539187702789
Validation loss: 2.5037970005946018

Epoch: 6| Step: 7
Training loss: 2.710975228962286
Validation loss: 2.489113202634429

Epoch: 6| Step: 8
Training loss: 2.180839644255184
Validation loss: 2.491151882354147

Epoch: 6| Step: 9
Training loss: 2.812928824052139
Validation loss: 2.4952044812859038

Epoch: 6| Step: 10
Training loss: 2.826954636330258
Validation loss: 2.5023587758658117

Epoch: 6| Step: 11
Training loss: 2.970093754274381
Validation loss: 2.513723686348431

Epoch: 6| Step: 12
Training loss: 2.7235577047393216
Validation loss: 2.5315602572091898

Epoch: 6| Step: 13
Training loss: 2.725307055331087
Validation loss: 2.5440899667337495

Epoch: 156| Step: 0
Training loss: 2.9368025580785506
Validation loss: 2.5570960821656405

Epoch: 6| Step: 1
Training loss: 2.7764090938404347
Validation loss: 2.5646353357769867

Epoch: 6| Step: 2
Training loss: 2.7605927801033228
Validation loss: 2.5623195833791694

Epoch: 6| Step: 3
Training loss: 2.597570524020147
Validation loss: 2.5430920915963835

Epoch: 6| Step: 4
Training loss: 2.8350196382895314
Validation loss: 2.5190500351692737

Epoch: 6| Step: 5
Training loss: 2.56643291209871
Validation loss: 2.5104744244640846

Epoch: 6| Step: 6
Training loss: 3.103980824755401
Validation loss: 2.4994363415987078

Epoch: 6| Step: 7
Training loss: 2.112953597809034
Validation loss: 2.4866209954569776

Epoch: 6| Step: 8
Training loss: 2.7484875768249233
Validation loss: 2.489586537217021

Epoch: 6| Step: 9
Training loss: 2.8175563712518485
Validation loss: 2.486717675190169

Epoch: 6| Step: 10
Training loss: 2.4920792989650877
Validation loss: 2.4900689509775535

Epoch: 6| Step: 11
Training loss: 3.0975554210517067
Validation loss: 2.485393560707322

Epoch: 6| Step: 12
Training loss: 2.7161256247500463
Validation loss: 2.492844641455441

Epoch: 6| Step: 13
Training loss: 2.333293426263232
Validation loss: 2.4911785718804613

Epoch: 157| Step: 0
Training loss: 3.364157603505755
Validation loss: 2.506714044723509

Epoch: 6| Step: 1
Training loss: 2.783841843513831
Validation loss: 2.515176079653613

Epoch: 6| Step: 2
Training loss: 2.70376976129415
Validation loss: 2.516073255397949

Epoch: 6| Step: 3
Training loss: 2.9847848021669137
Validation loss: 2.5215824498575627

Epoch: 6| Step: 4
Training loss: 2.2703257235452385
Validation loss: 2.5113500011414756

Epoch: 6| Step: 5
Training loss: 3.3327836219191047
Validation loss: 2.5093179673725277

Epoch: 6| Step: 6
Training loss: 2.550508680282865
Validation loss: 2.510863603945333

Epoch: 6| Step: 7
Training loss: 2.4275695793952385
Validation loss: 2.5115469711767964

Epoch: 6| Step: 8
Training loss: 2.198716643288062
Validation loss: 2.5104394672638115

Epoch: 6| Step: 9
Training loss: 2.892180483091839
Validation loss: 2.5138019775705795

Epoch: 6| Step: 10
Training loss: 3.0478686155302332
Validation loss: 2.5058401035736675

Epoch: 6| Step: 11
Training loss: 2.139141153208935
Validation loss: 2.508031258548699

Epoch: 6| Step: 12
Training loss: 2.427951990196515
Validation loss: 2.5084533393968167

Epoch: 6| Step: 13
Training loss: 2.1884038965024932
Validation loss: 2.514297033953865

Epoch: 158| Step: 0
Training loss: 2.595038036736528
Validation loss: 2.525703441192693

Epoch: 6| Step: 1
Training loss: 2.3964941246872784
Validation loss: 2.508292101367615

Epoch: 6| Step: 2
Training loss: 2.4355101655275306
Validation loss: 2.505672525844027

Epoch: 6| Step: 3
Training loss: 2.526316792295491
Validation loss: 2.4996126141409776

Epoch: 6| Step: 4
Training loss: 2.2995588750333993
Validation loss: 2.508065441809211

Epoch: 6| Step: 5
Training loss: 2.669888834550042
Validation loss: 2.5090369268146255

Epoch: 6| Step: 6
Training loss: 2.7981975135157984
Validation loss: 2.51580330740265

Epoch: 6| Step: 7
Training loss: 3.0813369645851534
Validation loss: 2.5198814698773244

Epoch: 6| Step: 8
Training loss: 3.284407195741936
Validation loss: 2.5306511285354487

Epoch: 6| Step: 9
Training loss: 2.1756842709746635
Validation loss: 2.530879181023013

Epoch: 6| Step: 10
Training loss: 2.584718722419025
Validation loss: 2.5430749380468445

Epoch: 6| Step: 11
Training loss: 2.7756069241342956
Validation loss: 2.5515352582707145

Epoch: 6| Step: 12
Training loss: 3.2603400143193912
Validation loss: 2.5461031400129195

Epoch: 6| Step: 13
Training loss: 2.666697164202183
Validation loss: 2.5356141457466186

Epoch: 159| Step: 0
Training loss: 2.6759896524397475
Validation loss: 2.5496957070168214

Epoch: 6| Step: 1
Training loss: 3.2591222238952753
Validation loss: 2.5362605357871733

Epoch: 6| Step: 2
Training loss: 2.210149510017007
Validation loss: 2.5198106602391066

Epoch: 6| Step: 3
Training loss: 3.0894656329758496
Validation loss: 2.51842116276489

Epoch: 6| Step: 4
Training loss: 2.3661570304747297
Validation loss: 2.5042809391025425

Epoch: 6| Step: 5
Training loss: 3.0565195662928217
Validation loss: 2.5077115066898994

Epoch: 6| Step: 6
Training loss: 2.84917845680525
Validation loss: 2.5054791182871137

Epoch: 6| Step: 7
Training loss: 2.2327390430451963
Validation loss: 2.4996658645394114

Epoch: 6| Step: 8
Training loss: 2.65765783363379
Validation loss: 2.4988174446224978

Epoch: 6| Step: 9
Training loss: 2.3390180503275944
Validation loss: 2.5097711552116544

Epoch: 6| Step: 10
Training loss: 2.9841260556551625
Validation loss: 2.50610118059259

Epoch: 6| Step: 11
Training loss: 2.7188404988978787
Validation loss: 2.5125301959441972

Epoch: 6| Step: 12
Training loss: 2.4164809670846212
Validation loss: 2.5202173612530254

Epoch: 6| Step: 13
Training loss: 2.1316311537364605
Validation loss: 2.503236752890399

Epoch: 160| Step: 0
Training loss: 1.7759580471307472
Validation loss: 2.5164946755518884

Epoch: 6| Step: 1
Training loss: 2.661112026868365
Validation loss: 2.507836655927312

Epoch: 6| Step: 2
Training loss: 2.906448357488661
Validation loss: 2.502914069596483

Epoch: 6| Step: 3
Training loss: 2.818239755398517
Validation loss: 2.4956287243121644

Epoch: 6| Step: 4
Training loss: 2.5893408745964592
Validation loss: 2.5015505330339587

Epoch: 6| Step: 5
Training loss: 2.5202453074570976
Validation loss: 2.4943516707394346

Epoch: 6| Step: 6
Training loss: 2.955552813720706
Validation loss: 2.500421576691708

Epoch: 6| Step: 7
Training loss: 2.2728089187868696
Validation loss: 2.49252534198454

Epoch: 6| Step: 8
Training loss: 2.6526880953698906
Validation loss: 2.4834806793589155

Epoch: 6| Step: 9
Training loss: 3.1618591925909625
Validation loss: 2.4861993471724664

Epoch: 6| Step: 10
Training loss: 2.7757591308949308
Validation loss: 2.495683529681264

Epoch: 6| Step: 11
Training loss: 2.4368531762726207
Validation loss: 2.5091169459153155

Epoch: 6| Step: 12
Training loss: 3.1330681979503434
Validation loss: 2.511292767098561

Epoch: 6| Step: 13
Training loss: 2.3427686544149275
Validation loss: 2.529740298971619

Epoch: 161| Step: 0
Training loss: 2.6365301220144537
Validation loss: 2.5347263898228514

Epoch: 6| Step: 1
Training loss: 2.4607664987401834
Validation loss: 2.546564621404827

Epoch: 6| Step: 2
Training loss: 2.610636514679856
Validation loss: 2.558116259525697

Epoch: 6| Step: 3
Training loss: 2.7605426879522867
Validation loss: 2.5293168099810677

Epoch: 6| Step: 4
Training loss: 2.9151061288348674
Validation loss: 2.511325705466943

Epoch: 6| Step: 5
Training loss: 2.958436901446659
Validation loss: 2.5088058751681808

Epoch: 6| Step: 6
Training loss: 3.2607863504047363
Validation loss: 2.4908503320714637

Epoch: 6| Step: 7
Training loss: 2.6047728379794632
Validation loss: 2.483227712093671

Epoch: 6| Step: 8
Training loss: 1.651313334195437
Validation loss: 2.4883914603134625

Epoch: 6| Step: 9
Training loss: 3.1881073017896697
Validation loss: 2.4974007486750125

Epoch: 6| Step: 10
Training loss: 2.75790811432383
Validation loss: 2.489460604390245

Epoch: 6| Step: 11
Training loss: 2.06680219062348
Validation loss: 2.498664523868682

Epoch: 6| Step: 12
Training loss: 2.4988254649076724
Validation loss: 2.5039975916896675

Epoch: 6| Step: 13
Training loss: 2.468144885881673
Validation loss: 2.514546984688763

Epoch: 162| Step: 0
Training loss: 1.9327720051920132
Validation loss: 2.5060514376581517

Epoch: 6| Step: 1
Training loss: 3.361019991505671
Validation loss: 2.534422486206328

Epoch: 6| Step: 2
Training loss: 2.4154572146082463
Validation loss: 2.524328474478723

Epoch: 6| Step: 3
Training loss: 2.7688352412412782
Validation loss: 2.524037490875191

Epoch: 6| Step: 4
Training loss: 2.192016951655533
Validation loss: 2.5145957215348216

Epoch: 6| Step: 5
Training loss: 2.5412392074423336
Validation loss: 2.512005926146766

Epoch: 6| Step: 6
Training loss: 1.8821657581647493
Validation loss: 2.500490002141619

Epoch: 6| Step: 7
Training loss: 2.3195496406481384
Validation loss: 2.4867024183580293

Epoch: 6| Step: 8
Training loss: 3.1661549372206688
Validation loss: 2.502535785022818

Epoch: 6| Step: 9
Training loss: 2.4351390261587103
Validation loss: 2.5240956852011838

Epoch: 6| Step: 10
Training loss: 3.377319951429134
Validation loss: 2.517353824033976

Epoch: 6| Step: 11
Training loss: 2.9502743480289584
Validation loss: 2.514034337247047

Epoch: 6| Step: 12
Training loss: 3.2235823716611876
Validation loss: 2.518291969702615

Epoch: 6| Step: 13
Training loss: 2.093420657545558
Validation loss: 2.5191031667613206

Epoch: 163| Step: 0
Training loss: 2.5610697406655554
Validation loss: 2.5293211277872603

Epoch: 6| Step: 1
Training loss: 2.5521670165582258
Validation loss: 2.5443786137449718

Epoch: 6| Step: 2
Training loss: 2.418423463529536
Validation loss: 2.5634493256121527

Epoch: 6| Step: 3
Training loss: 2.798849250836181
Validation loss: 2.5623807821846434

Epoch: 6| Step: 4
Training loss: 2.5114473519598732
Validation loss: 2.545611841030965

Epoch: 6| Step: 5
Training loss: 2.125562032536947
Validation loss: 2.5360687685090393

Epoch: 6| Step: 6
Training loss: 2.8023684804445703
Validation loss: 2.525311872792351

Epoch: 6| Step: 7
Training loss: 2.9313219724493846
Validation loss: 2.510161287327139

Epoch: 6| Step: 8
Training loss: 2.542855490229331
Validation loss: 2.503641767760131

Epoch: 6| Step: 9
Training loss: 2.663988934617073
Validation loss: 2.4918603241614377

Epoch: 6| Step: 10
Training loss: 2.785429995915531
Validation loss: 2.475503698474349

Epoch: 6| Step: 11
Training loss: 2.6533500548974804
Validation loss: 2.4861949596318853

Epoch: 6| Step: 12
Training loss: 2.628363498021987
Validation loss: 2.488515747949308

Epoch: 6| Step: 13
Training loss: 3.1325073093533007
Validation loss: 2.4839567685153914

Epoch: 164| Step: 0
Training loss: 2.394216793751342
Validation loss: 2.4849082326543037

Epoch: 6| Step: 1
Training loss: 2.170650548677487
Validation loss: 2.4857719942713663

Epoch: 6| Step: 2
Training loss: 3.214664866776703
Validation loss: 2.4853175970293013

Epoch: 6| Step: 3
Training loss: 2.715302309238181
Validation loss: 2.5227335372703843

Epoch: 6| Step: 4
Training loss: 2.7822100236159444
Validation loss: 2.527883278046486

Epoch: 6| Step: 5
Training loss: 2.295936652303186
Validation loss: 2.537948650327919

Epoch: 6| Step: 6
Training loss: 2.7744407021446316
Validation loss: 2.5950394385676487

Epoch: 6| Step: 7
Training loss: 3.09018555883379
Validation loss: 2.590095361913153

Epoch: 6| Step: 8
Training loss: 2.3676235691197345
Validation loss: 2.5448412208241664

Epoch: 6| Step: 9
Training loss: 2.876909865541617
Validation loss: 2.52894990129325

Epoch: 6| Step: 10
Training loss: 2.6199148059418014
Validation loss: 2.5109849542824447

Epoch: 6| Step: 11
Training loss: 2.2922420357403444
Validation loss: 2.5014332047155396

Epoch: 6| Step: 12
Training loss: 2.5367642844119294
Validation loss: 2.4917615877018346

Epoch: 6| Step: 13
Training loss: 3.3203102022050874
Validation loss: 2.4997879487007904

Epoch: 165| Step: 0
Training loss: 2.6952049344478195
Validation loss: 2.512119956311117

Epoch: 6| Step: 1
Training loss: 2.39174451357943
Validation loss: 2.5049713451104103

Epoch: 6| Step: 2
Training loss: 2.6991223816292513
Validation loss: 2.5022597528851147

Epoch: 6| Step: 3
Training loss: 2.3015154199906176
Validation loss: 2.5252933863363416

Epoch: 6| Step: 4
Training loss: 2.71525954760464
Validation loss: 2.544118397392132

Epoch: 6| Step: 5
Training loss: 2.4931965761197596
Validation loss: 2.577342581207139

Epoch: 6| Step: 6
Training loss: 2.960049861024056
Validation loss: 2.615200720090342

Epoch: 6| Step: 7
Training loss: 3.0303577801064447
Validation loss: 2.591739893192908

Epoch: 6| Step: 8
Training loss: 2.1586526946208027
Validation loss: 2.55581320621099

Epoch: 6| Step: 9
Training loss: 2.861647406461224
Validation loss: 2.5128577044511253

Epoch: 6| Step: 10
Training loss: 3.115840764356106
Validation loss: 2.4888372289674545

Epoch: 6| Step: 11
Training loss: 2.4250709366009042
Validation loss: 2.4871404838503737

Epoch: 6| Step: 12
Training loss: 2.6671173390399456
Validation loss: 2.4732164442590943

Epoch: 6| Step: 13
Training loss: 1.9805665603350984
Validation loss: 2.48269264290546

Epoch: 166| Step: 0
Training loss: 1.9158911241684269
Validation loss: 2.492691361997693

Epoch: 6| Step: 1
Training loss: 2.893709094291908
Validation loss: 2.4815879673230463

Epoch: 6| Step: 2
Training loss: 2.4315614986184744
Validation loss: 2.4761343245837226

Epoch: 6| Step: 3
Training loss: 2.827485576022836
Validation loss: 2.4721440911683517

Epoch: 6| Step: 4
Training loss: 1.812410089301637
Validation loss: 2.4866136446042413

Epoch: 6| Step: 5
Training loss: 2.804663442864487
Validation loss: 2.4875816293688624

Epoch: 6| Step: 6
Training loss: 2.4217923057958766
Validation loss: 2.4879924822777717

Epoch: 6| Step: 7
Training loss: 2.5997058555302597
Validation loss: 2.503794390157252

Epoch: 6| Step: 8
Training loss: 2.684833001709848
Validation loss: 2.5251991672646077

Epoch: 6| Step: 9
Training loss: 2.6761207086796954
Validation loss: 2.558528049818122

Epoch: 6| Step: 10
Training loss: 3.208856135456852
Validation loss: 2.585111976943833

Epoch: 6| Step: 11
Training loss: 2.4903917689230597
Validation loss: 2.6169912143126752

Epoch: 6| Step: 12
Training loss: 2.9701322851037504
Validation loss: 2.6701723670742727

Epoch: 6| Step: 13
Training loss: 3.5820110158234395
Validation loss: 2.6462401775799167

Epoch: 167| Step: 0
Training loss: 2.9374084458388734
Validation loss: 2.582306689303108

Epoch: 6| Step: 1
Training loss: 2.493812724689397
Validation loss: 2.5484271347500953

Epoch: 6| Step: 2
Training loss: 2.6811970276479338
Validation loss: 2.545027943277289

Epoch: 6| Step: 3
Training loss: 2.9557439907335215
Validation loss: 2.5487927916029673

Epoch: 6| Step: 4
Training loss: 2.558965338594092
Validation loss: 2.54347222028867

Epoch: 6| Step: 5
Training loss: 2.4509967878204675
Validation loss: 2.532120958282947

Epoch: 6| Step: 6
Training loss: 1.9509732409724017
Validation loss: 2.499062282298487

Epoch: 6| Step: 7
Training loss: 2.4434918825855
Validation loss: 2.503427299420472

Epoch: 6| Step: 8
Training loss: 2.5942334563319758
Validation loss: 2.503477576302332

Epoch: 6| Step: 9
Training loss: 2.5450174309334077
Validation loss: 2.516195814506168

Epoch: 6| Step: 10
Training loss: 2.623320087397804
Validation loss: 2.5249492759974554

Epoch: 6| Step: 11
Training loss: 3.4162122998074866
Validation loss: 2.513609348513236

Epoch: 6| Step: 12
Training loss: 2.727303040942871
Validation loss: 2.5404424575267504

Epoch: 6| Step: 13
Training loss: 2.3213490441083002
Validation loss: 2.558877120192835

Epoch: 168| Step: 0
Training loss: 1.9688925313066747
Validation loss: 2.562751618604113

Epoch: 6| Step: 1
Training loss: 2.501322015262258
Validation loss: 2.5802841477499374

Epoch: 6| Step: 2
Training loss: 2.4351986511474863
Validation loss: 2.593717922541623

Epoch: 6| Step: 3
Training loss: 2.58169825912791
Validation loss: 2.6071436454396575

Epoch: 6| Step: 4
Training loss: 2.7823460165980616
Validation loss: 2.616095568670233

Epoch: 6| Step: 5
Training loss: 2.624225865610236
Validation loss: 2.6142866734985994

Epoch: 6| Step: 6
Training loss: 2.8369545702249988
Validation loss: 2.599961100051452

Epoch: 6| Step: 7
Training loss: 2.60892843662544
Validation loss: 2.6017225987889088

Epoch: 6| Step: 8
Training loss: 2.8176240655751874
Validation loss: 2.609550095386085

Epoch: 6| Step: 9
Training loss: 3.0717369444395723
Validation loss: 2.595136914850365

Epoch: 6| Step: 10
Training loss: 2.4483265202243327
Validation loss: 2.5879674090345746

Epoch: 6| Step: 11
Training loss: 2.792178851916343
Validation loss: 2.5645762930058575

Epoch: 6| Step: 12
Training loss: 2.4547288838958607
Validation loss: 2.5589068642879584

Epoch: 6| Step: 13
Training loss: 2.423528193160883
Validation loss: 2.557893953841725

Epoch: 169| Step: 0
Training loss: 2.784025714514352
Validation loss: 2.545708697343013

Epoch: 6| Step: 1
Training loss: 3.13962231472414
Validation loss: 2.538891490796932

Epoch: 6| Step: 2
Training loss: 2.2852135284287804
Validation loss: 2.54480163019672

Epoch: 6| Step: 3
Training loss: 2.9649592240152716
Validation loss: 2.5548241074416054

Epoch: 6| Step: 4
Training loss: 2.373844568378595
Validation loss: 2.572523648931941

Epoch: 6| Step: 5
Training loss: 2.473305856426988
Validation loss: 2.565479760067554

Epoch: 6| Step: 6
Training loss: 2.742524824560405
Validation loss: 2.5817129590433514

Epoch: 6| Step: 7
Training loss: 2.8496234310396993
Validation loss: 2.586159665374872

Epoch: 6| Step: 8
Training loss: 2.7736430347201337
Validation loss: 2.59208208173481

Epoch: 6| Step: 9
Training loss: 1.5163636128377986
Validation loss: 2.566329614527681

Epoch: 6| Step: 10
Training loss: 2.2253219628718766
Validation loss: 2.5512926572424823

Epoch: 6| Step: 11
Training loss: 2.4716316498813717
Validation loss: 2.5260860825289364

Epoch: 6| Step: 12
Training loss: 2.8108241704600507
Validation loss: 2.5149121026885064

Epoch: 6| Step: 13
Training loss: 2.6442668112052448
Validation loss: 2.5129311155949097

Epoch: 170| Step: 0
Training loss: 2.8953706293915067
Validation loss: 2.5086280310180826

Epoch: 6| Step: 1
Training loss: 2.3756947755991473
Validation loss: 2.5037114373447182

Epoch: 6| Step: 2
Training loss: 2.8919560847344683
Validation loss: 2.479116044458763

Epoch: 6| Step: 3
Training loss: 3.145978019031288
Validation loss: 2.4735716514439225

Epoch: 6| Step: 4
Training loss: 3.0238390121194976
Validation loss: 2.4688881705224963

Epoch: 6| Step: 5
Training loss: 2.77997868660091
Validation loss: 2.488870394475526

Epoch: 6| Step: 6
Training loss: 2.3153118874241034
Validation loss: 2.49331737870306

Epoch: 6| Step: 7
Training loss: 1.890959907062333
Validation loss: 2.5065182418711744

Epoch: 6| Step: 8
Training loss: 1.6419694750337928
Validation loss: 2.5258673626905197

Epoch: 6| Step: 9
Training loss: 2.0477224444795357
Validation loss: 2.538279742042932

Epoch: 6| Step: 10
Training loss: 2.7449838666320185
Validation loss: 2.598359198566982

Epoch: 6| Step: 11
Training loss: 3.115391416986038
Validation loss: 2.618154828864045

Epoch: 6| Step: 12
Training loss: 2.234317698777648
Validation loss: 2.6179391481059926

Epoch: 6| Step: 13
Training loss: 2.5184028405174708
Validation loss: 2.605048705002288

Epoch: 171| Step: 0
Training loss: 2.278841916321477
Validation loss: 2.619425016464609

Epoch: 6| Step: 1
Training loss: 2.5134465043199397
Validation loss: 2.601437890223315

Epoch: 6| Step: 2
Training loss: 2.714647727860275
Validation loss: 2.5678234374483364

Epoch: 6| Step: 3
Training loss: 2.120477463918868
Validation loss: 2.5287697461353

Epoch: 6| Step: 4
Training loss: 2.8976399848833236
Validation loss: 2.524820232175253

Epoch: 6| Step: 5
Training loss: 2.7366797624925945
Validation loss: 2.4994634862712375

Epoch: 6| Step: 6
Training loss: 2.4086394893078387
Validation loss: 2.4996055763597202

Epoch: 6| Step: 7
Training loss: 2.663368291263382
Validation loss: 2.5091533355953253

Epoch: 6| Step: 8
Training loss: 2.8416685095041814
Validation loss: 2.5131206016792667

Epoch: 6| Step: 9
Training loss: 2.2024933470886414
Validation loss: 2.528410469038125

Epoch: 6| Step: 10
Training loss: 2.402327275413531
Validation loss: 2.527093216622497

Epoch: 6| Step: 11
Training loss: 2.875269172341179
Validation loss: 2.541705317500084

Epoch: 6| Step: 12
Training loss: 2.812921958635457
Validation loss: 2.5391571981409933

Epoch: 6| Step: 13
Training loss: 2.59828873585258
Validation loss: 2.547740065381595

Epoch: 172| Step: 0
Training loss: 2.957897870604603
Validation loss: 2.5506279615123244

Epoch: 6| Step: 1
Training loss: 2.5366339234366357
Validation loss: 2.555239667900528

Epoch: 6| Step: 2
Training loss: 2.5331370536993663
Validation loss: 2.5550325578416015

Epoch: 6| Step: 3
Training loss: 2.9563642225720272
Validation loss: 2.5384209510685416

Epoch: 6| Step: 4
Training loss: 2.475633898388964
Validation loss: 2.525484089809135

Epoch: 6| Step: 5
Training loss: 2.6438334458621306
Validation loss: 2.520694020658436

Epoch: 6| Step: 6
Training loss: 2.445243663854905
Validation loss: 2.5393775551374773

Epoch: 6| Step: 7
Training loss: 2.0776215136965646
Validation loss: 2.5640629669631156

Epoch: 6| Step: 8
Training loss: 2.4347875125610536
Validation loss: 2.6186992737756842

Epoch: 6| Step: 9
Training loss: 3.036016590228884
Validation loss: 2.6423132860217686

Epoch: 6| Step: 10
Training loss: 1.9003591348640345
Validation loss: 2.6214487642816957

Epoch: 6| Step: 11
Training loss: 2.4667046681475346
Validation loss: 2.600945808052089

Epoch: 6| Step: 12
Training loss: 2.918030193044536
Validation loss: 2.5767406526828474

Epoch: 6| Step: 13
Training loss: 2.5745407620876066
Validation loss: 2.5641444442458834

Epoch: 173| Step: 0
Training loss: 2.502282721721806
Validation loss: 2.590929817194263

Epoch: 6| Step: 1
Training loss: 2.5991502180085564
Validation loss: 2.607474491881563

Epoch: 6| Step: 2
Training loss: 3.028389751249603
Validation loss: 2.652631004763123

Epoch: 6| Step: 3
Training loss: 2.814781450423365
Validation loss: 2.670513566859008

Epoch: 6| Step: 4
Training loss: 2.379678034121747
Validation loss: 2.687692212277997

Epoch: 6| Step: 5
Training loss: 2.211579030918307
Validation loss: 2.704518099738741

Epoch: 6| Step: 6
Training loss: 2.1744013302210203
Validation loss: 2.6901244284147077

Epoch: 6| Step: 7
Training loss: 2.3760401807014158
Validation loss: 2.6601833303398053

Epoch: 6| Step: 8
Training loss: 2.619015820834516
Validation loss: 2.67519849505194

Epoch: 6| Step: 9
Training loss: 2.677061879904514
Validation loss: 2.689181822984079

Epoch: 6| Step: 10
Training loss: 2.2872370709508205
Validation loss: 2.676814950716693

Epoch: 6| Step: 11
Training loss: 2.779555501049898
Validation loss: 2.657540369733254

Epoch: 6| Step: 12
Training loss: 2.434356325050972
Validation loss: 2.6172056322077286

Epoch: 6| Step: 13
Training loss: 2.693472944912268
Validation loss: 2.5906639742288675

Epoch: 174| Step: 0
Training loss: 2.693815219027678
Validation loss: 2.548836611017485

Epoch: 6| Step: 1
Training loss: 2.8918629237991116
Validation loss: 2.529368132610839

Epoch: 6| Step: 2
Training loss: 1.8971249159655628
Validation loss: 2.5294606244364015

Epoch: 6| Step: 3
Training loss: 2.0117202906926748
Validation loss: 2.5184906759496837

Epoch: 6| Step: 4
Training loss: 2.5165458557571365
Validation loss: 2.5115924570549537

Epoch: 6| Step: 5
Training loss: 2.7573347245156907
Validation loss: 2.5026510815441503

Epoch: 6| Step: 6
Training loss: 2.040028310467118
Validation loss: 2.533779292962831

Epoch: 6| Step: 7
Training loss: 2.371653960411293
Validation loss: 2.5361032309194447

Epoch: 6| Step: 8
Training loss: 2.9313382393705765
Validation loss: 2.5870377615421285

Epoch: 6| Step: 9
Training loss: 2.7666022519192577
Validation loss: 2.6035175835360875

Epoch: 6| Step: 10
Training loss: 2.593948908153426
Validation loss: 2.5967420460919906

Epoch: 6| Step: 11
Training loss: 2.628447766164347
Validation loss: 2.5870554252728257

Epoch: 6| Step: 12
Training loss: 2.316536962413935
Validation loss: 2.6002817511631355

Epoch: 6| Step: 13
Training loss: 2.8763845675677637
Validation loss: 2.6027532930037776

Epoch: 175| Step: 0
Training loss: 2.249181916603419
Validation loss: 2.6198622735361554

Epoch: 6| Step: 1
Training loss: 2.2678145779025485
Validation loss: 2.6322631847122477

Epoch: 6| Step: 2
Training loss: 2.9889803997276485
Validation loss: 2.6357813847894342

Epoch: 6| Step: 3
Training loss: 2.505382180212632
Validation loss: 2.6058276766610016

Epoch: 6| Step: 4
Training loss: 3.006556181671542
Validation loss: 2.596041080047623

Epoch: 6| Step: 5
Training loss: 1.4375962764178045
Validation loss: 2.5711848213761774

Epoch: 6| Step: 6
Training loss: 2.1106450531255136
Validation loss: 2.5359645636717754

Epoch: 6| Step: 7
Training loss: 2.9450009937640913
Validation loss: 2.519023716257028

Epoch: 6| Step: 8
Training loss: 2.370852915365094
Validation loss: 2.5007854150826847

Epoch: 6| Step: 9
Training loss: 3.2650858602874178
Validation loss: 2.5267776423532813

Epoch: 6| Step: 10
Training loss: 2.2583693507326505
Validation loss: 2.5303448854387454

Epoch: 6| Step: 11
Training loss: 3.154611596625094
Validation loss: 2.521120589129081

Epoch: 6| Step: 12
Training loss: 2.158102152261836
Validation loss: 2.534784632051342

Epoch: 6| Step: 13
Training loss: 1.7555304061051302
Validation loss: 2.56330571687315

Epoch: 176| Step: 0
Training loss: 2.63621541057991
Validation loss: 2.571929579550536

Epoch: 6| Step: 1
Training loss: 1.563667928979923
Validation loss: 2.578932975678302

Epoch: 6| Step: 2
Training loss: 2.906455084014805
Validation loss: 2.6030245501679112

Epoch: 6| Step: 3
Training loss: 2.119731880363388
Validation loss: 2.6389636547447606

Epoch: 6| Step: 4
Training loss: 2.164730037922734
Validation loss: 2.6290051180922576

Epoch: 6| Step: 5
Training loss: 2.7302225026434073
Validation loss: 2.6398439960463658

Epoch: 6| Step: 6
Training loss: 2.997707762783872
Validation loss: 2.689158355096428

Epoch: 6| Step: 7
Training loss: 2.062678820631981
Validation loss: 2.706021923385922

Epoch: 6| Step: 8
Training loss: 3.0027392914742825
Validation loss: 2.6773673749141147

Epoch: 6| Step: 9
Training loss: 2.9672298354050977
Validation loss: 2.6929803475514755

Epoch: 6| Step: 10
Training loss: 2.0463754757841057
Validation loss: 2.680996383389588

Epoch: 6| Step: 11
Training loss: 2.2915215417397508
Validation loss: 2.6585958662564027

Epoch: 6| Step: 12
Training loss: 2.5192888010165184
Validation loss: 2.6326390939577706

Epoch: 6| Step: 13
Training loss: 2.320598854351213
Validation loss: 2.623270724060569

Epoch: 177| Step: 0
Training loss: 2.938865182064262
Validation loss: 2.5760211831624824

Epoch: 6| Step: 1
Training loss: 2.800923406379718
Validation loss: 2.548772592536408

Epoch: 6| Step: 2
Training loss: 2.7433454454261996
Validation loss: 2.5236226904771213

Epoch: 6| Step: 3
Training loss: 1.8136920954940754
Validation loss: 2.545717176639259

Epoch: 6| Step: 4
Training loss: 2.025668883820819
Validation loss: 2.5421464656466735

Epoch: 6| Step: 5
Training loss: 2.5013877831465487
Validation loss: 2.575302350829136

Epoch: 6| Step: 6
Training loss: 2.235006923280784
Validation loss: 2.6197171294928148

Epoch: 6| Step: 7
Training loss: 2.3598334264968295
Validation loss: 2.678162750538261

Epoch: 6| Step: 8
Training loss: 2.671355169044069
Validation loss: 2.659730963843121

Epoch: 6| Step: 9
Training loss: 2.5201632867620622
Validation loss: 2.603602636147831

Epoch: 6| Step: 10
Training loss: 2.812900090900265
Validation loss: 2.551195689355098

Epoch: 6| Step: 11
Training loss: 2.7949636737462322
Validation loss: 2.499067881332578

Epoch: 6| Step: 12
Training loss: 2.2857782022871924
Validation loss: 2.4956907634234335

Epoch: 6| Step: 13
Training loss: 2.3791981785742244
Validation loss: 2.489223307110188

Epoch: 178| Step: 0
Training loss: 2.7219650726656144
Validation loss: 2.496911971964993

Epoch: 6| Step: 1
Training loss: 2.3505145301004586
Validation loss: 2.499624412790136

Epoch: 6| Step: 2
Training loss: 1.8613106405551763
Validation loss: 2.51759213162744

Epoch: 6| Step: 3
Training loss: 2.5040662122265944
Validation loss: 2.5171446233572277

Epoch: 6| Step: 4
Training loss: 2.5800678677466906
Validation loss: 2.517961347960162

Epoch: 6| Step: 5
Training loss: 2.8026420764146804
Validation loss: 2.5494039845942322

Epoch: 6| Step: 6
Training loss: 2.902035682727006
Validation loss: 2.5871196508693948

Epoch: 6| Step: 7
Training loss: 2.3657687628537225
Validation loss: 2.614659654926505

Epoch: 6| Step: 8
Training loss: 2.261864217715087
Validation loss: 2.644766611818873

Epoch: 6| Step: 9
Training loss: 2.9655276830240074
Validation loss: 2.692653805325081

Epoch: 6| Step: 10
Training loss: 1.7223048121977087
Validation loss: 2.7337441424810693

Epoch: 6| Step: 11
Training loss: 2.612027036938787
Validation loss: 2.7501311601849587

Epoch: 6| Step: 12
Training loss: 2.1684874317947536
Validation loss: 2.756484508976346

Epoch: 6| Step: 13
Training loss: 2.6477191142039493
Validation loss: 2.744403807426805

Epoch: 179| Step: 0
Training loss: 1.9589027091106352
Validation loss: 2.640081033236785

Epoch: 6| Step: 1
Training loss: 2.5354812484285527
Validation loss: 2.5912609153730446

Epoch: 6| Step: 2
Training loss: 2.263782462314374
Validation loss: 2.5397894806324866

Epoch: 6| Step: 3
Training loss: 3.0089858899836344
Validation loss: 2.5425496947030397

Epoch: 6| Step: 4
Training loss: 2.4052929647058034
Validation loss: 2.526042977220563

Epoch: 6| Step: 5
Training loss: 2.4933486194787995
Validation loss: 2.5236662134937258

Epoch: 6| Step: 6
Training loss: 2.585156371738296
Validation loss: 2.525946158474863

Epoch: 6| Step: 7
Training loss: 2.5693615484755483
Validation loss: 2.493112241371128

Epoch: 6| Step: 8
Training loss: 2.3191969530725745
Validation loss: 2.4915912130977946

Epoch: 6| Step: 9
Training loss: 1.3856568474867133
Validation loss: 2.5054865826201596

Epoch: 6| Step: 10
Training loss: 2.327468267402716
Validation loss: 2.54797203866354

Epoch: 6| Step: 11
Training loss: 3.505277741620261
Validation loss: 2.5916779118021487

Epoch: 6| Step: 12
Training loss: 2.5958674416870346
Validation loss: 2.6195835234789806

Epoch: 6| Step: 13
Training loss: 1.7258599694648027
Validation loss: 2.628839783260325

Epoch: 180| Step: 0
Training loss: 2.259513240821841
Validation loss: 2.675403609220422

Epoch: 6| Step: 1
Training loss: 2.450923733860448
Validation loss: 2.682692354936239

Epoch: 6| Step: 2
Training loss: 2.3190122101377177
Validation loss: 2.6268752432105935

Epoch: 6| Step: 3
Training loss: 2.507400431305817
Validation loss: 2.5993424688883437

Epoch: 6| Step: 4
Training loss: 2.8192128074298792
Validation loss: 2.5706800760332293

Epoch: 6| Step: 5
Training loss: 2.4792073564369193
Validation loss: 2.5775666816577383

Epoch: 6| Step: 6
Training loss: 2.0421827273907747
Validation loss: 2.5626235429909396

Epoch: 6| Step: 7
Training loss: 2.5787350944202903
Validation loss: 2.5657273075283173

Epoch: 6| Step: 8
Training loss: 2.2530175213833017
Validation loss: 2.559920250217011

Epoch: 6| Step: 9
Training loss: 2.392713843408356
Validation loss: 2.5484129223696823

Epoch: 6| Step: 10
Training loss: 2.7604051889624786
Validation loss: 2.5491949995205023

Epoch: 6| Step: 11
Training loss: 2.597012409931155
Validation loss: 2.538040035532374

Epoch: 6| Step: 12
Training loss: 2.5723330084129183
Validation loss: 2.512901852597729

Epoch: 6| Step: 13
Training loss: 2.380428635121826
Validation loss: 2.5225182362480867

Epoch: 181| Step: 0
Training loss: 2.430889850212713
Validation loss: 2.506303283204379

Epoch: 6| Step: 1
Training loss: 2.4164756392473077
Validation loss: 2.521604617435196

Epoch: 6| Step: 2
Training loss: 2.6596463200623206
Validation loss: 2.510580728859989

Epoch: 6| Step: 3
Training loss: 2.3061870287229946
Validation loss: 2.53471704743691

Epoch: 6| Step: 4
Training loss: 2.3624122724442316
Validation loss: 2.543907697242571

Epoch: 6| Step: 5
Training loss: 2.255044474533219
Validation loss: 2.571889293489739

Epoch: 6| Step: 6
Training loss: 2.565612019774374
Validation loss: 2.58541565257369

Epoch: 6| Step: 7
Training loss: 3.0260602432880117
Validation loss: 2.6185564139581006

Epoch: 6| Step: 8
Training loss: 2.354182307998774
Validation loss: 2.62392710076078

Epoch: 6| Step: 9
Training loss: 2.2478065395395523
Validation loss: 2.634738439094653

Epoch: 6| Step: 10
Training loss: 1.8812111657275437
Validation loss: 2.6201169781127556

Epoch: 6| Step: 11
Training loss: 2.3326532757965186
Validation loss: 2.622238291473691

Epoch: 6| Step: 12
Training loss: 2.2150776519252857
Validation loss: 2.6044629649933904

Epoch: 6| Step: 13
Training loss: 2.0840204123158137
Validation loss: 2.5960989717327916

Epoch: 182| Step: 0
Training loss: 2.1169137249837693
Validation loss: 2.555194520556603

Epoch: 6| Step: 1
Training loss: 2.383089643526754
Validation loss: 2.5370793824297664

Epoch: 6| Step: 2
Training loss: 2.4883423802219213
Validation loss: 2.524234856179043

Epoch: 6| Step: 3
Training loss: 1.992710538531564
Validation loss: 2.5058523609013754

Epoch: 6| Step: 4
Training loss: 2.9138779159871033
Validation loss: 2.503462461035395

Epoch: 6| Step: 5
Training loss: 2.7283634042296403
Validation loss: 2.496125694475027

Epoch: 6| Step: 6
Training loss: 2.3352204820331273
Validation loss: 2.5209773880238235

Epoch: 6| Step: 7
Training loss: 2.2182821935791535
Validation loss: 2.5220020137421435

Epoch: 6| Step: 8
Training loss: 2.3545037312424397
Validation loss: 2.529764249570812

Epoch: 6| Step: 9
Training loss: 2.351186018807921
Validation loss: 2.530197428068489

Epoch: 6| Step: 10
Training loss: 1.4809347340319905
Validation loss: 2.5516013545217078

Epoch: 6| Step: 11
Training loss: 2.3397420564947273
Validation loss: 2.587495622972509

Epoch: 6| Step: 12
Training loss: 2.1875414163210984
Validation loss: 2.6135077688341117

Epoch: 6| Step: 13
Training loss: 2.704534791440175
Validation loss: 2.6341901210380168

Epoch: 183| Step: 0
Training loss: 1.7753009836460942
Validation loss: 2.7113533066398463

Epoch: 6| Step: 1
Training loss: 2.2528672492837893
Validation loss: 2.7635539467829964

Epoch: 6| Step: 2
Training loss: 2.888335109680064
Validation loss: 2.7423509109048347

Epoch: 6| Step: 3
Training loss: 1.35659848495662
Validation loss: 2.6992404654847895

Epoch: 6| Step: 4
Training loss: 2.7752413189409193
Validation loss: 2.656504949486811

Epoch: 6| Step: 5
Training loss: 2.52593558701567
Validation loss: 2.6334918050667593

Epoch: 6| Step: 6
Training loss: 2.7578026444472443
Validation loss: 2.634439541051363

Epoch: 6| Step: 7
Training loss: 2.2036616977044563
Validation loss: 2.5752014368892295

Epoch: 6| Step: 8
Training loss: 2.67969497368218
Validation loss: 2.5561270412174495

Epoch: 6| Step: 9
Training loss: 2.309837458122709
Validation loss: 2.5568661458643973

Epoch: 6| Step: 10
Training loss: 2.1195204152759377
Validation loss: 2.5445691512760638

Epoch: 6| Step: 11
Training loss: 1.9142510768871908
Validation loss: 2.5527238803320187

Epoch: 6| Step: 12
Training loss: 2.9075084955775226
Validation loss: 2.5883451393666985

Epoch: 6| Step: 13
Training loss: 1.8003785847852853
Validation loss: 2.569054565146806

Epoch: 184| Step: 0
Training loss: 2.2668635698886965
Validation loss: 2.549776538425128

Epoch: 6| Step: 1
Training loss: 1.9905680338375313
Validation loss: 2.538193522665251

Epoch: 6| Step: 2
Training loss: 2.2482267385692167
Validation loss: 2.4979147110224695

Epoch: 6| Step: 3
Training loss: 2.216794723980234
Validation loss: 2.4875462540986404

Epoch: 6| Step: 4
Training loss: 2.6020309438895963
Validation loss: 2.469509988580572

Epoch: 6| Step: 5
Training loss: 2.318938802348364
Validation loss: 2.4835284578523855

Epoch: 6| Step: 6
Training loss: 2.596396601160223
Validation loss: 2.5004367426371754

Epoch: 6| Step: 7
Training loss: 2.372089509976608
Validation loss: 2.5273080497959426

Epoch: 6| Step: 8
Training loss: 2.5112737139754215
Validation loss: 2.590123553839945

Epoch: 6| Step: 9
Training loss: 2.398157954622127
Validation loss: 2.606690245199315

Epoch: 6| Step: 10
Training loss: 1.9495915914437938
Validation loss: 2.6198391338931133

Epoch: 6| Step: 11
Training loss: 2.8706718705775813
Validation loss: 2.640445146566031

Epoch: 6| Step: 12
Training loss: 2.2460854704331097
Validation loss: 2.626778677281372

Epoch: 6| Step: 13
Training loss: 1.447648176735828
Validation loss: 2.609832527065931

Epoch: 185| Step: 0
Training loss: 3.087561380494372
Validation loss: 2.628626330946612

Epoch: 6| Step: 1
Training loss: 1.9918161681924678
Validation loss: 2.645262225306482

Epoch: 6| Step: 2
Training loss: 2.454363662075727
Validation loss: 2.6805332972532794

Epoch: 6| Step: 3
Training loss: 2.368879965888024
Validation loss: 2.6352324587784173

Epoch: 6| Step: 4
Training loss: 2.002975872517248
Validation loss: 2.624284063586149

Epoch: 6| Step: 5
Training loss: 2.015415387750293
Validation loss: 2.619128599314607

Epoch: 6| Step: 6
Training loss: 1.7165640368229895
Validation loss: 2.6775182331881795

Epoch: 6| Step: 7
Training loss: 2.4934081911725556
Validation loss: 2.710987637786635

Epoch: 6| Step: 8
Training loss: 2.577331790855855
Validation loss: 2.722682800977988

Epoch: 6| Step: 9
Training loss: 2.2883436096175527
Validation loss: 2.6798188690269913

Epoch: 6| Step: 10
Training loss: 2.1787034961773415
Validation loss: 2.625517384471678

Epoch: 6| Step: 11
Training loss: 1.9077237795134019
Validation loss: 2.5693029086630426

Epoch: 6| Step: 12
Training loss: 2.7705819917038923
Validation loss: 2.544492308473981

Epoch: 6| Step: 13
Training loss: 2.060943709936034
Validation loss: 2.539661985293165

Epoch: 186| Step: 0
Training loss: 2.4552935109005625
Validation loss: 2.518851834103768

Epoch: 6| Step: 1
Training loss: 2.0229231132721512
Validation loss: 2.5634502686823555

Epoch: 6| Step: 2
Training loss: 1.3438649682830919
Validation loss: 2.544719726012527

Epoch: 6| Step: 3
Training loss: 2.206608176402199
Validation loss: 2.5962928931530787

Epoch: 6| Step: 4
Training loss: 2.758858371640434
Validation loss: 2.6089656145912983

Epoch: 6| Step: 5
Training loss: 2.3887960381415616
Validation loss: 2.6126904689162904

Epoch: 6| Step: 6
Training loss: 2.0143213122081387
Validation loss: 2.641340207059472

Epoch: 6| Step: 7
Training loss: 2.0404671109911026
Validation loss: 2.704591539990001

Epoch: 6| Step: 8
Training loss: 2.6452669954301054
Validation loss: 2.7221553646181937

Epoch: 6| Step: 9
Training loss: 2.52528979460832
Validation loss: 2.7115950683370236

Epoch: 6| Step: 10
Training loss: 2.472137252071295
Validation loss: 2.6566154870349283

Epoch: 6| Step: 11
Training loss: 2.519935090576298
Validation loss: 2.604638418147625

Epoch: 6| Step: 12
Training loss: 2.4343799282508884
Validation loss: 2.55577927639032

Epoch: 6| Step: 13
Training loss: 1.3866313208299517
Validation loss: 2.5456768624694535

Epoch: 187| Step: 0
Training loss: 2.106043692879119
Validation loss: 2.5063694589094005

Epoch: 6| Step: 1
Training loss: 2.7630285801660563
Validation loss: 2.4868422779116055

Epoch: 6| Step: 2
Training loss: 2.263666292830423
Validation loss: 2.5045336080627294

Epoch: 6| Step: 3
Training loss: 2.040168433061351
Validation loss: 2.51413880761399

Epoch: 6| Step: 4
Training loss: 2.224885221799791
Validation loss: 2.5175785791601344

Epoch: 6| Step: 5
Training loss: 2.224136047648
Validation loss: 2.5689709274097434

Epoch: 6| Step: 6
Training loss: 2.074380929357428
Validation loss: 2.6530588127830113

Epoch: 6| Step: 7
Training loss: 2.9277910528619953
Validation loss: 2.71047101781915

Epoch: 6| Step: 8
Training loss: 1.6935281108486204
Validation loss: 2.6971483861744994

Epoch: 6| Step: 9
Training loss: 2.4466983658333494
Validation loss: 2.683172287640308

Epoch: 6| Step: 10
Training loss: 2.265838192084227
Validation loss: 2.6516389495295525

Epoch: 6| Step: 11
Training loss: 2.3176559499471527
Validation loss: 2.6348584227630867

Epoch: 6| Step: 12
Training loss: 1.8481485948807703
Validation loss: 2.607956261185074

Epoch: 6| Step: 13
Training loss: 2.3695678828847933
Validation loss: 2.5728398258817333

Epoch: 188| Step: 0
Training loss: 1.9448591569639782
Validation loss: 2.575541164369749

Epoch: 6| Step: 1
Training loss: 2.1816831360912454
Validation loss: 2.5690368045922547

Epoch: 6| Step: 2
Training loss: 2.384081393222148
Validation loss: 2.536433856016629

Epoch: 6| Step: 3
Training loss: 1.4403262343675722
Validation loss: 2.5444012436760306

Epoch: 6| Step: 4
Training loss: 2.339318014190224
Validation loss: 2.537335470909154

Epoch: 6| Step: 5
Training loss: 2.017136945615479
Validation loss: 2.5489486404962083

Epoch: 6| Step: 6
Training loss: 2.188162676027318
Validation loss: 2.5902396632769893

Epoch: 6| Step: 7
Training loss: 2.5786470751578654
Validation loss: 2.61332662694965

Epoch: 6| Step: 8
Training loss: 2.229410698863936
Validation loss: 2.6704916216172943

Epoch: 6| Step: 9
Training loss: 2.572546454808153
Validation loss: 2.6728709351530244

Epoch: 6| Step: 10
Training loss: 2.497791840968848
Validation loss: 2.649937147918627

Epoch: 6| Step: 11
Training loss: 2.2814556708442404
Validation loss: 2.6470148673172305

Epoch: 6| Step: 12
Training loss: 2.134288347085426
Validation loss: 2.613796989686396

Epoch: 6| Step: 13
Training loss: 2.000821898381505
Validation loss: 2.6125202623089763

Epoch: 189| Step: 0
Training loss: 1.688449945455149
Validation loss: 2.6347547156431905

Epoch: 6| Step: 1
Training loss: 1.966427598851755
Validation loss: 2.6428410536370976

Epoch: 6| Step: 2
Training loss: 1.7037126419774304
Validation loss: 2.6291163808403137

Epoch: 6| Step: 3
Training loss: 2.1937203386263215
Validation loss: 2.603212646636584

Epoch: 6| Step: 4
Training loss: 2.076361574853081
Validation loss: 2.592325490760056

Epoch: 6| Step: 5
Training loss: 1.9325556887440647
Validation loss: 2.603761812959866

Epoch: 6| Step: 6
Training loss: 2.208744646550563
Validation loss: 2.643646552237652

Epoch: 6| Step: 7
Training loss: 1.9631762244613715
Validation loss: 2.633462094416661

Epoch: 6| Step: 8
Training loss: 2.0593833494813074
Validation loss: 2.634548504540244

Epoch: 6| Step: 9
Training loss: 2.2973625029056866
Validation loss: 2.609267943609584

Epoch: 6| Step: 10
Training loss: 2.1562589562271537
Validation loss: 2.6083205835457424

Epoch: 6| Step: 11
Training loss: 2.914737899277459
Validation loss: 2.5838406316438323

Epoch: 6| Step: 12
Training loss: 2.10923404929105
Validation loss: 2.5838734230568656

Epoch: 6| Step: 13
Training loss: 2.8851150373401966
Validation loss: 2.5485790306512413

Epoch: 190| Step: 0
Training loss: 2.394903007884723
Validation loss: 2.54603774481977

Epoch: 6| Step: 1
Training loss: 2.09500061945576
Validation loss: 2.5187811522624926

Epoch: 6| Step: 2
Training loss: 1.869797546320803
Validation loss: 2.519765822262408

Epoch: 6| Step: 3
Training loss: 1.8353369197198424
Validation loss: 2.504444802021894

Epoch: 6| Step: 4
Training loss: 2.088190012664484
Validation loss: 2.526202145599712

Epoch: 6| Step: 5
Training loss: 1.459033561806842
Validation loss: 2.540765703171819

Epoch: 6| Step: 6
Training loss: 2.406439637477076
Validation loss: 2.547485851053844

Epoch: 6| Step: 7
Training loss: 2.6050609629814057
Validation loss: 2.5966451780105713

Epoch: 6| Step: 8
Training loss: 2.1505205633142186
Validation loss: 2.6204560999170483

Epoch: 6| Step: 9
Training loss: 2.4982686723515006
Validation loss: 2.659377060416762

Epoch: 6| Step: 10
Training loss: 2.1563687499145203
Validation loss: 2.6786145118026057

Epoch: 6| Step: 11
Training loss: 2.3386698279205382
Validation loss: 2.6778778937419787

Epoch: 6| Step: 12
Training loss: 1.4741373481372404
Validation loss: 2.6372818525804607

Epoch: 6| Step: 13
Training loss: 1.7982737528795247
Validation loss: 2.59399816386172

Epoch: 191| Step: 0
Training loss: 2.212278033830401
Validation loss: 2.5542220201218577

Epoch: 6| Step: 1
Training loss: 2.2944036150181595
Validation loss: 2.4692218475501257

Epoch: 6| Step: 2
Training loss: 2.51741977900985
Validation loss: 2.449085303464166

Epoch: 6| Step: 3
Training loss: 2.232874333010665
Validation loss: 2.438442425614955

Epoch: 6| Step: 4
Training loss: 1.747314708966072
Validation loss: 2.4534660934602766

Epoch: 6| Step: 5
Training loss: 2.0356126152788554
Validation loss: 2.4764309482604863

Epoch: 6| Step: 6
Training loss: 1.8452658160422981
Validation loss: 2.5087084903139414

Epoch: 6| Step: 7
Training loss: 2.215420656237102
Validation loss: 2.512378079741739

Epoch: 6| Step: 8
Training loss: 2.501553815532337
Validation loss: 2.5343827399043897

Epoch: 6| Step: 9
Training loss: 1.396339931887397
Validation loss: 2.575226795408934

Epoch: 6| Step: 10
Training loss: 1.9436295058016468
Validation loss: 2.6436926472920335

Epoch: 6| Step: 11
Training loss: 2.0053886299490444
Validation loss: 2.662222875946966

Epoch: 6| Step: 12
Training loss: 2.3402915360536527
Validation loss: 2.6867806000479297

Epoch: 6| Step: 13
Training loss: 2.5469306050414824
Validation loss: 2.710806289490089

Epoch: 192| Step: 0
Training loss: 2.229628850730928
Validation loss: 2.717724976636258

Epoch: 6| Step: 1
Training loss: 2.469355255488286
Validation loss: 2.684468939374711

Epoch: 6| Step: 2
Training loss: 1.630591967925464
Validation loss: 2.61682119290104

Epoch: 6| Step: 3
Training loss: 2.572305109854979
Validation loss: 2.59165814787432

Epoch: 6| Step: 4
Training loss: 1.7731909895656148
Validation loss: 2.527172506761432

Epoch: 6| Step: 5
Training loss: 2.0333341030473764
Validation loss: 2.5230793728180965

Epoch: 6| Step: 6
Training loss: 2.228838269533768
Validation loss: 2.5398393016646565

Epoch: 6| Step: 7
Training loss: 2.1443659261824495
Validation loss: 2.501911052281491

Epoch: 6| Step: 8
Training loss: 2.1267170420373485
Validation loss: 2.505913907514833

Epoch: 6| Step: 9
Training loss: 2.3512927943081503
Validation loss: 2.4906695445361335

Epoch: 6| Step: 10
Training loss: 2.1285335109475167
Validation loss: 2.5056622156939308

Epoch: 6| Step: 11
Training loss: 1.873182433058978
Validation loss: 2.523574416474574

Epoch: 6| Step: 12
Training loss: 2.088997985254524
Validation loss: 2.5238186006116345

Epoch: 6| Step: 13
Training loss: 1.5543565254049174
Validation loss: 2.5672788351683784

Epoch: 193| Step: 0
Training loss: 2.2205641945465233
Validation loss: 2.6209623650684217

Epoch: 6| Step: 1
Training loss: 2.0112129834872063
Validation loss: 2.6674158834530597

Epoch: 6| Step: 2
Training loss: 1.8325101637200623
Validation loss: 2.7124560379466316

Epoch: 6| Step: 3
Training loss: 1.6399483874968641
Validation loss: 2.742652924853967

Epoch: 6| Step: 4
Training loss: 2.13783137558075
Validation loss: 2.757461028587836

Epoch: 6| Step: 5
Training loss: 1.952939566392593
Validation loss: 2.7323266936445756

Epoch: 6| Step: 6
Training loss: 2.1452342064247993
Validation loss: 2.6902751068777864

Epoch: 6| Step: 7
Training loss: 2.2048791706083173
Validation loss: 2.683989554209641

Epoch: 6| Step: 8
Training loss: 2.2801145053017837
Validation loss: 2.632057742674186

Epoch: 6| Step: 9
Training loss: 2.515600737460637
Validation loss: 2.588655821653686

Epoch: 6| Step: 10
Training loss: 2.225651069280614
Validation loss: 2.5489665913078565

Epoch: 6| Step: 11
Training loss: 1.9669115474421888
Validation loss: 2.4766591769641124

Epoch: 6| Step: 12
Training loss: 2.0589967510536797
Validation loss: 2.4566390106609792

Epoch: 6| Step: 13
Training loss: 1.5552072087680084
Validation loss: 2.427131399556904

Epoch: 194| Step: 0
Training loss: 1.673333503348252
Validation loss: 2.4828170666151568

Epoch: 6| Step: 1
Training loss: 2.2884418570542002
Validation loss: 2.500092124267045

Epoch: 6| Step: 2
Training loss: 1.9698007595175826
Validation loss: 2.5254292144718935

Epoch: 6| Step: 3
Training loss: 1.9126641595734717
Validation loss: 2.5629244907239643

Epoch: 6| Step: 4
Training loss: 1.618454883435679
Validation loss: 2.578222071714777

Epoch: 6| Step: 5
Training loss: 1.9236125999594877
Validation loss: 2.6434715710660877

Epoch: 6| Step: 6
Training loss: 1.9828814795890268
Validation loss: 2.6507331220051413

Epoch: 6| Step: 7
Training loss: 2.0159083913849
Validation loss: 2.6388896888885696

Epoch: 6| Step: 8
Training loss: 2.466696162520005
Validation loss: 2.659727513178541

Epoch: 6| Step: 9
Training loss: 2.2481925910501164
Validation loss: 2.629821829520236

Epoch: 6| Step: 10
Training loss: 2.1406633136968134
Validation loss: 2.6152331712258925

Epoch: 6| Step: 11
Training loss: 1.9303556204560837
Validation loss: 2.593394878226671

Epoch: 6| Step: 12
Training loss: 2.3636401699942504
Validation loss: 2.5476261593673004

Epoch: 6| Step: 13
Training loss: 2.0260713733629765
Validation loss: 2.5338002216552735

Epoch: 195| Step: 0
Training loss: 2.190609928356788
Validation loss: 2.5197230549751937

Epoch: 6| Step: 1
Training loss: 2.1452899973356647
Validation loss: 2.5060608551948356

Epoch: 6| Step: 2
Training loss: 1.7613516888255212
Validation loss: 2.5411755483908185

Epoch: 6| Step: 3
Training loss: 1.8692917717835975
Validation loss: 2.5602898118921518

Epoch: 6| Step: 4
Training loss: 1.8182631978332644
Validation loss: 2.5905748827937334

Epoch: 6| Step: 5
Training loss: 2.205072070131191
Validation loss: 2.6190822476407165

Epoch: 6| Step: 6
Training loss: 1.4920448914133093
Validation loss: 2.6055122656337764

Epoch: 6| Step: 7
Training loss: 1.5480383149612327
Validation loss: 2.607630325655136

Epoch: 6| Step: 8
Training loss: 2.4536614287098133
Validation loss: 2.5881425020709794

Epoch: 6| Step: 9
Training loss: 1.9169161330151598
Validation loss: 2.5505402819640786

Epoch: 6| Step: 10
Training loss: 1.8181439363261267
Validation loss: 2.516996596360598

Epoch: 6| Step: 11
Training loss: 2.33199475130436
Validation loss: 2.4988185634115045

Epoch: 6| Step: 12
Training loss: 2.5145128528374956
Validation loss: 2.465968195475836

Epoch: 6| Step: 13
Training loss: 1.9614358701819194
Validation loss: 2.475061927502106

Epoch: 196| Step: 0
Training loss: 2.182328241325526
Validation loss: 2.4756056556952757

Epoch: 6| Step: 1
Training loss: 1.7646534364985225
Validation loss: 2.5055097879077604

Epoch: 6| Step: 2
Training loss: 2.1854100734246376
Validation loss: 2.5034770637743664

Epoch: 6| Step: 3
Training loss: 1.8078280778772569
Validation loss: 2.529089112292283

Epoch: 6| Step: 4
Training loss: 2.3653101763245785
Validation loss: 2.5454753746997816

Epoch: 6| Step: 5
Training loss: 2.131954928968441
Validation loss: 2.5885116493866693

Epoch: 6| Step: 6
Training loss: 1.595772600470797
Validation loss: 2.567218824630172

Epoch: 6| Step: 7
Training loss: 1.9050830959108949
Validation loss: 2.5452408159498217

Epoch: 6| Step: 8
Training loss: 2.0981160659758915
Validation loss: 2.544261927361378

Epoch: 6| Step: 9
Training loss: 1.9981478220925262
Validation loss: 2.4953595100779857

Epoch: 6| Step: 10
Training loss: 2.322882567926636
Validation loss: 2.471938645565946

Epoch: 6| Step: 11
Training loss: 2.2146933637422705
Validation loss: 2.470989477919359

Epoch: 6| Step: 12
Training loss: 1.1235048106777688
Validation loss: 2.4695537770112455

Epoch: 6| Step: 13
Training loss: 1.7312503194980808
Validation loss: 2.4873157941930994

Epoch: 197| Step: 0
Training loss: 2.0024975441144917
Validation loss: 2.4748620547221756

Epoch: 6| Step: 1
Training loss: 2.1872783003587393
Validation loss: 2.520492227233129

Epoch: 6| Step: 2
Training loss: 2.2016536046732473
Validation loss: 2.534613686207892

Epoch: 6| Step: 3
Training loss: 2.2588308605082137
Validation loss: 2.5581091211332736

Epoch: 6| Step: 4
Training loss: 2.068727512756016
Validation loss: 2.599234677745825

Epoch: 6| Step: 5
Training loss: 2.0358845584570284
Validation loss: 2.6357712557988315

Epoch: 6| Step: 6
Training loss: 1.8252519381389665
Validation loss: 2.6037889570096513

Epoch: 6| Step: 7
Training loss: 1.1675966620608922
Validation loss: 2.6378429631339246

Epoch: 6| Step: 8
Training loss: 2.1474144181594506
Validation loss: 2.679278495545925

Epoch: 6| Step: 9
Training loss: 2.114494384498383
Validation loss: 2.619813161120144

Epoch: 6| Step: 10
Training loss: 1.818437322631974
Validation loss: 2.588247104207319

Epoch: 6| Step: 11
Training loss: 1.7984988628826093
Validation loss: 2.5610769368720243

Epoch: 6| Step: 12
Training loss: 1.509306330727989
Validation loss: 2.5274874657475443

Epoch: 6| Step: 13
Training loss: 2.235165756189371
Validation loss: 2.4879540921713956

Epoch: 198| Step: 0
Training loss: 2.2049100962192694
Validation loss: 2.4653061688679565

Epoch: 6| Step: 1
Training loss: 1.998952829877849
Validation loss: 2.425181279470204

Epoch: 6| Step: 2
Training loss: 1.395674250443102
Validation loss: 2.408455064077771

Epoch: 6| Step: 3
Training loss: 1.9940483228821857
Validation loss: 2.4014749771055937

Epoch: 6| Step: 4
Training loss: 1.6191247955395174
Validation loss: 2.445795964331863

Epoch: 6| Step: 5
Training loss: 1.9894449542057753
Validation loss: 2.5042366010968657

Epoch: 6| Step: 6
Training loss: 1.7807168664662711
Validation loss: 2.5421156037071047

Epoch: 6| Step: 7
Training loss: 1.9275239870233878
Validation loss: 2.580083411101253

Epoch: 6| Step: 8
Training loss: 2.1008935026605906
Validation loss: 2.5754260869810692

Epoch: 6| Step: 9
Training loss: 2.211854993692525
Validation loss: 2.6161931903633433

Epoch: 6| Step: 10
Training loss: 2.1676290159976346
Validation loss: 2.5673571558229744

Epoch: 6| Step: 11
Training loss: 1.7456744413821266
Validation loss: 2.5408743725067633

Epoch: 6| Step: 12
Training loss: 2.13717038474193
Validation loss: 2.592090981978608

Epoch: 6| Step: 13
Training loss: 1.7954262905729022
Validation loss: 2.5708861070185907

Epoch: 199| Step: 0
Training loss: 2.2647666620647375
Validation loss: 2.6046679182123804

Epoch: 6| Step: 1
Training loss: 1.9804866872723823
Validation loss: 2.6069894975760115

Epoch: 6| Step: 2
Training loss: 1.9626248459679558
Validation loss: 2.5963624502829026

Epoch: 6| Step: 3
Training loss: 1.7872761299420536
Validation loss: 2.5732702980639495

Epoch: 6| Step: 4
Training loss: 1.5795439582303672
Validation loss: 2.553984044773742

Epoch: 6| Step: 5
Training loss: 1.7625965714206937
Validation loss: 2.527254049419755

Epoch: 6| Step: 6
Training loss: 1.4098117227857851
Validation loss: 2.5483314672420994

Epoch: 6| Step: 7
Training loss: 2.1605570802394127
Validation loss: 2.5018451475218786

Epoch: 6| Step: 8
Training loss: 1.885939474665786
Validation loss: 2.508081088964097

Epoch: 6| Step: 9
Training loss: 2.1192705668326344
Validation loss: 2.5504432321971264

Epoch: 6| Step: 10
Training loss: 1.7415158469623373
Validation loss: 2.5785476949601622

Epoch: 6| Step: 11
Training loss: 2.5400722901877977
Validation loss: 2.6211170331024363

Epoch: 6| Step: 12
Training loss: 1.8739988833315198
Validation loss: 2.658810256448065

Epoch: 6| Step: 13
Training loss: 1.2676790311880572
Validation loss: 2.630665746629816

Epoch: 200| Step: 0
Training loss: 2.0563562383136142
Validation loss: 2.6139280967886642

Epoch: 6| Step: 1
Training loss: 1.7406495837353808
Validation loss: 2.5789560310473423

Epoch: 6| Step: 2
Training loss: 1.7521377177043955
Validation loss: 2.5258526265220596

Epoch: 6| Step: 3
Training loss: 1.2066556969735893
Validation loss: 2.526491782999122

Epoch: 6| Step: 4
Training loss: 1.7983380539590266
Validation loss: 2.5383325781815795

Epoch: 6| Step: 5
Training loss: 1.5154520309694912
Validation loss: 2.5242795903994826

Epoch: 6| Step: 6
Training loss: 2.234287393626459
Validation loss: 2.509792642634299

Epoch: 6| Step: 7
Training loss: 1.7412855610498956
Validation loss: 2.5062729419239935

Epoch: 6| Step: 8
Training loss: 2.028277055538981
Validation loss: 2.5280388147356723

Epoch: 6| Step: 9
Training loss: 2.3574931743114442
Validation loss: 2.508460499522292

Epoch: 6| Step: 10
Training loss: 2.078726315802131
Validation loss: 2.5548980225750264

Epoch: 6| Step: 11
Training loss: 1.907261501916107
Validation loss: 2.527443804654939

Epoch: 6| Step: 12
Training loss: 1.9398669889412354
Validation loss: 2.5487394470924327

Epoch: 6| Step: 13
Training loss: 2.0318922934710013
Validation loss: 2.554751114374522

Epoch: 201| Step: 0
Training loss: 1.9998300003281284
Validation loss: 2.5522116780525055

Epoch: 6| Step: 1
Training loss: 1.8003956677760795
Validation loss: 2.5643192369366736

Epoch: 6| Step: 2
Training loss: 1.8032925982407833
Validation loss: 2.588950505288392

Epoch: 6| Step: 3
Training loss: 1.5009277971197508
Validation loss: 2.5695389753973004

Epoch: 6| Step: 4
Training loss: 1.7381390116928237
Validation loss: 2.5738980790994064

Epoch: 6| Step: 5
Training loss: 1.8052780704341855
Validation loss: 2.5749253102187004

Epoch: 6| Step: 6
Training loss: 1.9053118539101768
Validation loss: 2.5739033629526102

Epoch: 6| Step: 7
Training loss: 2.210689463367115
Validation loss: 2.5768066008443

Epoch: 6| Step: 8
Training loss: 2.0088800939130165
Validation loss: 2.5955576324915803

Epoch: 6| Step: 9
Training loss: 1.8844783267512952
Validation loss: 2.5837994230126626

Epoch: 6| Step: 10
Training loss: 1.2080844370687454
Validation loss: 2.5333309190843325

Epoch: 6| Step: 11
Training loss: 2.3826543036305394
Validation loss: 2.508630601680068

Epoch: 6| Step: 12
Training loss: 1.7558526536517975
Validation loss: 2.507937349801028

Epoch: 6| Step: 13
Training loss: 1.8199079989141536
Validation loss: 2.4793604680832955

Epoch: 202| Step: 0
Training loss: 1.9998842444300082
Validation loss: 2.472269073760739

Epoch: 6| Step: 1
Training loss: 2.0045552829304105
Validation loss: 2.4373353555972552

Epoch: 6| Step: 2
Training loss: 2.02871828027397
Validation loss: 2.4497546234040852

Epoch: 6| Step: 3
Training loss: 1.9711634662529405
Validation loss: 2.485376310129604

Epoch: 6| Step: 4
Training loss: 2.228020013633707
Validation loss: 2.5066654992946313

Epoch: 6| Step: 5
Training loss: 1.88928969967695
Validation loss: 2.514272033639105

Epoch: 6| Step: 6
Training loss: 1.286430492434486
Validation loss: 2.5943790033370204

Epoch: 6| Step: 7
Training loss: 1.8600703630161666
Validation loss: 2.655151926805287

Epoch: 6| Step: 8
Training loss: 1.6660345150233302
Validation loss: 2.6605568210573205

Epoch: 6| Step: 9
Training loss: 2.417088658112639
Validation loss: 2.676927712272377

Epoch: 6| Step: 10
Training loss: 1.7893978953920358
Validation loss: 2.624158340507741

Epoch: 6| Step: 11
Training loss: 1.7798288933883477
Validation loss: 2.5783354274655528

Epoch: 6| Step: 12
Training loss: 1.6104375054054498
Validation loss: 2.546450241989642

Epoch: 6| Step: 13
Training loss: 0.8984978033642885
Validation loss: 2.5394922662320223

Epoch: 203| Step: 0
Training loss: 2.0826309800373255
Validation loss: 2.5264656136543997

Epoch: 6| Step: 1
Training loss: 2.0683766653402667
Validation loss: 2.5262151829594957

Epoch: 6| Step: 2
Training loss: 1.8011210818089576
Validation loss: 2.513079179565401

Epoch: 6| Step: 3
Training loss: 1.851259874810793
Validation loss: 2.5033697767144596

Epoch: 6| Step: 4
Training loss: 1.7997116255231933
Validation loss: 2.4822604828513004

Epoch: 6| Step: 5
Training loss: 1.8007555647402207
Validation loss: 2.493788666278514

Epoch: 6| Step: 6
Training loss: 1.9450532671540517
Validation loss: 2.506925095496839

Epoch: 6| Step: 7
Training loss: 1.5268620270386013
Validation loss: 2.5417492828041017

Epoch: 6| Step: 8
Training loss: 2.068034289697407
Validation loss: 2.5599655856074044

Epoch: 6| Step: 9
Training loss: 1.7533307395064939
Validation loss: 2.6040285141918607

Epoch: 6| Step: 10
Training loss: 1.4046705064604905
Validation loss: 2.6109674556109024

Epoch: 6| Step: 11
Training loss: 2.499875065542827
Validation loss: 2.6412196229229004

Epoch: 6| Step: 12
Training loss: 1.579518599871327
Validation loss: 2.650624070890917

Epoch: 6| Step: 13
Training loss: 1.6916641144506184
Validation loss: 2.618964019236735

Epoch: 204| Step: 0
Training loss: 1.8872933786237556
Validation loss: 2.595816060075926

Epoch: 6| Step: 1
Training loss: 1.6612464825526214
Validation loss: 2.551677014718048

Epoch: 6| Step: 2
Training loss: 1.3646729806276579
Validation loss: 2.547661295614611

Epoch: 6| Step: 3
Training loss: 2.4451757033234425
Validation loss: 2.5356259376319326

Epoch: 6| Step: 4
Training loss: 2.0570398361658535
Validation loss: 2.5305304578781787

Epoch: 6| Step: 5
Training loss: 1.6244142650454139
Validation loss: 2.530261873968171

Epoch: 6| Step: 6
Training loss: 1.424815731515628
Validation loss: 2.5035341058032827

Epoch: 6| Step: 7
Training loss: 1.687527126518082
Validation loss: 2.5055701514473334

Epoch: 6| Step: 8
Training loss: 2.035403304379924
Validation loss: 2.497443348011718

Epoch: 6| Step: 9
Training loss: 2.0806755533261856
Validation loss: 2.496151170268011

Epoch: 6| Step: 10
Training loss: 1.618381225526821
Validation loss: 2.500583229944168

Epoch: 6| Step: 11
Training loss: 1.9010595730151614
Validation loss: 2.509679751935898

Epoch: 6| Step: 12
Training loss: 1.7149171574550164
Validation loss: 2.519692631613816

Epoch: 6| Step: 13
Training loss: 1.8344893567703684
Validation loss: 2.5633807075732693

Epoch: 205| Step: 0
Training loss: 1.7802735714224442
Validation loss: 2.5792603012561957

Epoch: 6| Step: 1
Training loss: 1.5409881628028683
Validation loss: 2.617495752975551

Epoch: 6| Step: 2
Training loss: 2.2043862486450356
Validation loss: 2.604820985034358

Epoch: 6| Step: 3
Training loss: 1.8368952424192062
Validation loss: 2.6029002841915267

Epoch: 6| Step: 4
Training loss: 2.3284094719895143
Validation loss: 2.6337324596874754

Epoch: 6| Step: 5
Training loss: 1.786904578642925
Validation loss: 2.6045877597766034

Epoch: 6| Step: 6
Training loss: 1.9229121937257179
Validation loss: 2.584810528947862

Epoch: 6| Step: 7
Training loss: 1.2794733988570741
Validation loss: 2.5694350035040463

Epoch: 6| Step: 8
Training loss: 1.3756139424983218
Validation loss: 2.52889210860129

Epoch: 6| Step: 9
Training loss: 1.392741275341649
Validation loss: 2.521457102386699

Epoch: 6| Step: 10
Training loss: 1.7827296218531201
Validation loss: 2.4899333015029046

Epoch: 6| Step: 11
Training loss: 2.189069348473629
Validation loss: 2.4751160572162396

Epoch: 6| Step: 12
Training loss: 1.5962501811458332
Validation loss: 2.5017420923485756

Epoch: 6| Step: 13
Training loss: 2.172802953283525
Validation loss: 2.5227650803987673

Epoch: 206| Step: 0
Training loss: 2.267369723210345
Validation loss: 2.564425506604275

Epoch: 6| Step: 1
Training loss: 1.0098774182177013
Validation loss: 2.5218337380881537

Epoch: 6| Step: 2
Training loss: 1.6839796009142052
Validation loss: 2.56865183001426

Epoch: 6| Step: 3
Training loss: 2.063080099195623
Validation loss: 2.5214270029373407

Epoch: 6| Step: 4
Training loss: 2.3705402463510956
Validation loss: 2.559116331512443

Epoch: 6| Step: 5
Training loss: 2.120169591058374
Validation loss: 2.519669712615335

Epoch: 6| Step: 6
Training loss: 2.2360618999218205
Validation loss: 2.549811542487146

Epoch: 6| Step: 7
Training loss: 1.1646851276182144
Validation loss: 2.5407878466587803

Epoch: 6| Step: 8
Training loss: 1.7616765932845853
Validation loss: 2.5135962498499578

Epoch: 6| Step: 9
Training loss: 1.791585883455901
Validation loss: 2.5094565378893554

Epoch: 6| Step: 10
Training loss: 2.089758527212387
Validation loss: 2.5168042433872233

Epoch: 6| Step: 11
Training loss: 0.8482245372927123
Validation loss: 2.5071189569733607

Epoch: 6| Step: 12
Training loss: 1.8590908314233658
Validation loss: 2.5260433517127363

Epoch: 6| Step: 13
Training loss: 0.6111744452901181
Validation loss: 2.5943945192523263

Epoch: 207| Step: 0
Training loss: 1.3093849636964283
Validation loss: 2.5998157432775955

Epoch: 6| Step: 1
Training loss: 2.2597092841534194
Validation loss: 2.619769194114401

Epoch: 6| Step: 2
Training loss: 1.7850432579291244
Validation loss: 2.616304050424974

Epoch: 6| Step: 3
Training loss: 1.4319305334557337
Validation loss: 2.605038042206203

Epoch: 6| Step: 4
Training loss: 1.5349245163440526
Validation loss: 2.5810900570014566

Epoch: 6| Step: 5
Training loss: 1.866901008621459
Validation loss: 2.5520535522357344

Epoch: 6| Step: 6
Training loss: 1.5749046781244327
Validation loss: 2.5540347874063216

Epoch: 6| Step: 7
Training loss: 2.0233710436420265
Validation loss: 2.544788200472735

Epoch: 6| Step: 8
Training loss: 2.1269159094827286
Validation loss: 2.5150516218089773

Epoch: 6| Step: 9
Training loss: 1.8918150001995064
Validation loss: 2.5609325093729614

Epoch: 6| Step: 10
Training loss: 1.9768153093017677
Validation loss: 2.559413819257364

Epoch: 6| Step: 11
Training loss: 1.639642475746681
Validation loss: 2.588551070640525

Epoch: 6| Step: 12
Training loss: 1.152992815748001
Validation loss: 2.6121570448602016

Epoch: 6| Step: 13
Training loss: 1.8732743905705735
Validation loss: 2.657493422850116

Epoch: 208| Step: 0
Training loss: 1.3906730043505184
Validation loss: 2.6457119775726468

Epoch: 6| Step: 1
Training loss: 1.8190274266235222
Validation loss: 2.614765973868326

Epoch: 6| Step: 2
Training loss: 1.6881994987581954
Validation loss: 2.577162579944564

Epoch: 6| Step: 3
Training loss: 2.1209375032374624
Validation loss: 2.5516224937076717

Epoch: 6| Step: 4
Training loss: 1.278993247305885
Validation loss: 2.5167483088824714

Epoch: 6| Step: 5
Training loss: 1.405989898363184
Validation loss: 2.4795451586681967

Epoch: 6| Step: 6
Training loss: 1.7421479498646288
Validation loss: 2.450576822561605

Epoch: 6| Step: 7
Training loss: 1.6835817836681395
Validation loss: 2.454902146810281

Epoch: 6| Step: 8
Training loss: 2.006670081345873
Validation loss: 2.474683009141993

Epoch: 6| Step: 9
Training loss: 2.0134272459160694
Validation loss: 2.5244349175203418

Epoch: 6| Step: 10
Training loss: 1.4918992328313772
Validation loss: 2.5879257673407055

Epoch: 6| Step: 11
Training loss: 2.0287552992962476
Validation loss: 2.6351295719160914

Epoch: 6| Step: 12
Training loss: 1.8815823410348962
Validation loss: 2.7290356884935307

Epoch: 6| Step: 13
Training loss: 1.8127678640335283
Validation loss: 2.7721769202745574

Epoch: 209| Step: 0
Training loss: 1.6420918764390482
Validation loss: 2.776550928406663

Epoch: 6| Step: 1
Training loss: 1.723248230820753
Validation loss: 2.757087353524576

Epoch: 6| Step: 2
Training loss: 1.4775241364445608
Validation loss: 2.6990285629841746

Epoch: 6| Step: 3
Training loss: 1.789653164171361
Validation loss: 2.670204788597359

Epoch: 6| Step: 4
Training loss: 1.637056010966449
Validation loss: 2.6369528870899095

Epoch: 6| Step: 5
Training loss: 1.3073048179339843
Validation loss: 2.5801519664815196

Epoch: 6| Step: 6
Training loss: 1.6129872051802883
Validation loss: 2.577125894181448

Epoch: 6| Step: 7
Training loss: 1.7870922317099533
Validation loss: 2.5365893211855344

Epoch: 6| Step: 8
Training loss: 2.0670098214693566
Validation loss: 2.4993979123822188

Epoch: 6| Step: 9
Training loss: 2.1726661174375894
Validation loss: 2.5507590244187193

Epoch: 6| Step: 10
Training loss: 1.6883913441162983
Validation loss: 2.550805260324889

Epoch: 6| Step: 11
Training loss: 2.0843113193192337
Validation loss: 2.5718383229835107

Epoch: 6| Step: 12
Training loss: 1.0372266685121743
Validation loss: 2.605134978063241

Epoch: 6| Step: 13
Training loss: 1.7908302469110082
Validation loss: 2.6451964254094227

Epoch: 210| Step: 0
Training loss: 1.7941552850716918
Validation loss: 2.648709155141682

Epoch: 6| Step: 1
Training loss: 1.9459440745739918
Validation loss: 2.6433334232227836

Epoch: 6| Step: 2
Training loss: 2.0248359943426517
Validation loss: 2.644488100145264

Epoch: 6| Step: 3
Training loss: 1.605511518590921
Validation loss: 2.6527145889835

Epoch: 6| Step: 4
Training loss: 1.7252422826041862
Validation loss: 2.642953629768875

Epoch: 6| Step: 5
Training loss: 1.5765493855531105
Validation loss: 2.577518369639997

Epoch: 6| Step: 6
Training loss: 1.4824265390757492
Validation loss: 2.55200540115139

Epoch: 6| Step: 7
Training loss: 1.2644356213460888
Validation loss: 2.5531479912432324

Epoch: 6| Step: 8
Training loss: 2.076224009737591
Validation loss: 2.529197076103565

Epoch: 6| Step: 9
Training loss: 1.460067734910728
Validation loss: 2.5156596833665277

Epoch: 6| Step: 10
Training loss: 1.6962744449211855
Validation loss: 2.542798975402996

Epoch: 6| Step: 11
Training loss: 1.3095494666207663
Validation loss: 2.5574000120326033

Epoch: 6| Step: 12
Training loss: 1.8257723284508707
Validation loss: 2.5483523760167484

Epoch: 6| Step: 13
Training loss: 1.9302382822144262
Validation loss: 2.5367344565328978

Epoch: 211| Step: 0
Training loss: 1.7970132525788027
Validation loss: 2.552370412793058

Epoch: 6| Step: 1
Training loss: 1.992177207770595
Validation loss: 2.5438133865766996

Epoch: 6| Step: 2
Training loss: 1.731591198622625
Validation loss: 2.5425046759407017

Epoch: 6| Step: 3
Training loss: 1.6624619214279026
Validation loss: 2.569052421672527

Epoch: 6| Step: 4
Training loss: 1.6028669302019611
Validation loss: 2.6097531814932156

Epoch: 6| Step: 5
Training loss: 1.6943055427749247
Validation loss: 2.61960812550397

Epoch: 6| Step: 6
Training loss: 2.357039249091757
Validation loss: 2.6066489080154547

Epoch: 6| Step: 7
Training loss: 1.028041066277185
Validation loss: 2.5993278237973287

Epoch: 6| Step: 8
Training loss: 1.6137121331745892
Validation loss: 2.605761666075452

Epoch: 6| Step: 9
Training loss: 1.9583160386099652
Validation loss: 2.576253746499561

Epoch: 6| Step: 10
Training loss: 1.169873066235874
Validation loss: 2.5735631662507497

Epoch: 6| Step: 11
Training loss: 1.2741883761342636
Validation loss: 2.5686334428899644

Epoch: 6| Step: 12
Training loss: 1.233239822880828
Validation loss: 2.603030706582633

Epoch: 6| Step: 13
Training loss: 1.7504577038167939
Validation loss: 2.5877580357594447

Epoch: 212| Step: 0
Training loss: 1.9160354722110116
Validation loss: 2.588668769282169

Epoch: 6| Step: 1
Training loss: 1.3922455164405114
Validation loss: 2.544501954503894

Epoch: 6| Step: 2
Training loss: 1.6285401442876366
Validation loss: 2.5347105733870032

Epoch: 6| Step: 3
Training loss: 0.9576459817682849
Validation loss: 2.5012666662043785

Epoch: 6| Step: 4
Training loss: 1.5846359850575022
Validation loss: 2.524607861516872

Epoch: 6| Step: 5
Training loss: 1.9922050924085366
Validation loss: 2.5380387820143957

Epoch: 6| Step: 6
Training loss: 1.551376343899038
Validation loss: 2.5272636080709834

Epoch: 6| Step: 7
Training loss: 1.8049655716589907
Validation loss: 2.50272538721495

Epoch: 6| Step: 8
Training loss: 1.3026193914041044
Validation loss: 2.50913560161824

Epoch: 6| Step: 9
Training loss: 1.293054030449707
Validation loss: 2.529691677564718

Epoch: 6| Step: 10
Training loss: 1.8951973599448924
Validation loss: 2.5185312837995957

Epoch: 6| Step: 11
Training loss: 1.6499790016918912
Validation loss: 2.5372038227048006

Epoch: 6| Step: 12
Training loss: 1.8762855573178319
Validation loss: 2.532288477945374

Epoch: 6| Step: 13
Training loss: 1.908086298760317
Validation loss: 2.575830804486239

Epoch: 213| Step: 0
Training loss: 1.1123314804855826
Validation loss: 2.55961655750665

Epoch: 6| Step: 1
Training loss: 1.6664946785242984
Validation loss: 2.5456180124238372

Epoch: 6| Step: 2
Training loss: 1.623146173444096
Validation loss: 2.548589177243245

Epoch: 6| Step: 3
Training loss: 1.419522529705432
Validation loss: 2.5582616386804005

Epoch: 6| Step: 4
Training loss: 1.4090692023453961
Validation loss: 2.560944926459798

Epoch: 6| Step: 5
Training loss: 1.6071725237091308
Validation loss: 2.578363319934146

Epoch: 6| Step: 6
Training loss: 2.0711465559033417
Validation loss: 2.5893841246541616

Epoch: 6| Step: 7
Training loss: 1.8545765870119506
Validation loss: 2.586495137387791

Epoch: 6| Step: 8
Training loss: 1.7325852240756594
Validation loss: 2.586082376862438

Epoch: 6| Step: 9
Training loss: 1.5455566336832705
Validation loss: 2.6191045076464152

Epoch: 6| Step: 10
Training loss: 1.9431185319117406
Validation loss: 2.634802448124212

Epoch: 6| Step: 11
Training loss: 1.5661305781912174
Validation loss: 2.6554126585108437

Epoch: 6| Step: 12
Training loss: 1.5538089129080968
Validation loss: 2.629173264395174

Epoch: 6| Step: 13
Training loss: 1.6536094921854658
Validation loss: 2.5800160075307397

Epoch: 214| Step: 0
Training loss: 1.760477309527402
Validation loss: 2.50494436758383

Epoch: 6| Step: 1
Training loss: 1.7794592706832342
Validation loss: 2.4696641171743674

Epoch: 6| Step: 2
Training loss: 1.8245905429894813
Validation loss: 2.466001068186261

Epoch: 6| Step: 3
Training loss: 1.8039517574922492
Validation loss: 2.438597017624684

Epoch: 6| Step: 4
Training loss: 1.521385023132159
Validation loss: 2.4467866211421705

Epoch: 6| Step: 5
Training loss: 1.2196793558531522
Validation loss: 2.4553182879323345

Epoch: 6| Step: 6
Training loss: 1.304171340170257
Validation loss: 2.493995079136393

Epoch: 6| Step: 7
Training loss: 1.8637466329317744
Validation loss: 2.507018966490558

Epoch: 6| Step: 8
Training loss: 1.8890102205701744
Validation loss: 2.533836110140961

Epoch: 6| Step: 9
Training loss: 1.720614722207686
Validation loss: 2.587137270440604

Epoch: 6| Step: 10
Training loss: 1.5319125240839675
Validation loss: 2.636363328855326

Epoch: 6| Step: 11
Training loss: 1.6443514691666106
Validation loss: 2.696284099302018

Epoch: 6| Step: 12
Training loss: 1.3840257742361592
Validation loss: 2.733578807508845

Epoch: 6| Step: 13
Training loss: 1.3483097869049319
Validation loss: 2.7361239004813966

Epoch: 215| Step: 0
Training loss: 1.0637894267430836
Validation loss: 2.716793930884748

Epoch: 6| Step: 1
Training loss: 1.40634807668515
Validation loss: 2.618489993882948

Epoch: 6| Step: 2
Training loss: 1.583244179005827
Validation loss: 2.567096478474833

Epoch: 6| Step: 3
Training loss: 1.6391709196381052
Validation loss: 2.518036017341645

Epoch: 6| Step: 4
Training loss: 1.4605060287032505
Validation loss: 2.5194651213534907

Epoch: 6| Step: 5
Training loss: 1.86088077897526
Validation loss: 2.4880819703381585

Epoch: 6| Step: 6
Training loss: 1.9031287733519782
Validation loss: 2.5104907571279615

Epoch: 6| Step: 7
Training loss: 1.9663520620622132
Validation loss: 2.5456098026955676

Epoch: 6| Step: 8
Training loss: 2.0687388071178043
Validation loss: 2.5567980344734074

Epoch: 6| Step: 9
Training loss: 2.0099312257150723
Validation loss: 2.6073343148361716

Epoch: 6| Step: 10
Training loss: 1.200711591657098
Validation loss: 2.602788353851717

Epoch: 6| Step: 11
Training loss: 1.2273756114143506
Validation loss: 2.6237218228489234

Epoch: 6| Step: 12
Training loss: 1.1776816386345372
Validation loss: 2.650193980626895

Epoch: 6| Step: 13
Training loss: 1.605144904300886
Validation loss: 2.6808665475935576

Epoch: 216| Step: 0
Training loss: 1.6591456310421047
Validation loss: 2.662676248374237

Epoch: 6| Step: 1
Training loss: 1.7293773507452768
Validation loss: 2.6053306888745293

Epoch: 6| Step: 2
Training loss: 2.062214687149123
Validation loss: 2.5926249822236347

Epoch: 6| Step: 3
Training loss: 1.4494462567274984
Validation loss: 2.5331352866737316

Epoch: 6| Step: 4
Training loss: 1.7616357889540006
Validation loss: 2.4726549291212723

Epoch: 6| Step: 5
Training loss: 1.2449005058089595
Validation loss: 2.447851094188247

Epoch: 6| Step: 6
Training loss: 1.3739703831735952
Validation loss: 2.4281370873566828

Epoch: 6| Step: 7
Training loss: 1.9999199493600404
Validation loss: 2.4670915080912015

Epoch: 6| Step: 8
Training loss: 1.6885482922878408
Validation loss: 2.4846790076379586

Epoch: 6| Step: 9
Training loss: 1.354587675330342
Validation loss: 2.5090875148034173

Epoch: 6| Step: 10
Training loss: 1.9468664374247397
Validation loss: 2.559536773029586

Epoch: 6| Step: 11
Training loss: 1.648815310603967
Validation loss: 2.6055772100814107

Epoch: 6| Step: 12
Training loss: 1.4280582170293252
Validation loss: 2.6656893437686437

Epoch: 6| Step: 13
Training loss: 1.451806239102173
Validation loss: 2.691115931813875

Epoch: 217| Step: 0
Training loss: 1.6733356405650086
Validation loss: 2.700285218972524

Epoch: 6| Step: 1
Training loss: 1.5935170620500672
Validation loss: 2.738521775604545

Epoch: 6| Step: 2
Training loss: 1.5368625777193579
Validation loss: 2.701794030808147

Epoch: 6| Step: 3
Training loss: 2.061930837993885
Validation loss: 2.681133730378859

Epoch: 6| Step: 4
Training loss: 1.2745287847220328
Validation loss: 2.6501485210257516

Epoch: 6| Step: 5
Training loss: 2.0886035126798745
Validation loss: 2.5997912468259257

Epoch: 6| Step: 6
Training loss: 1.1772713581350391
Validation loss: 2.5612629331253216

Epoch: 6| Step: 7
Training loss: 1.643265697075212
Validation loss: 2.541902151618517

Epoch: 6| Step: 8
Training loss: 1.4229970843190758
Validation loss: 2.531223697543422

Epoch: 6| Step: 9
Training loss: 1.7797655311203664
Validation loss: 2.5216002925158407

Epoch: 6| Step: 10
Training loss: 1.0837923446883306
Validation loss: 2.5584309112574974

Epoch: 6| Step: 11
Training loss: 1.746154237932648
Validation loss: 2.533756719932296

Epoch: 6| Step: 12
Training loss: 1.477965319276928
Validation loss: 2.5600229231611804

Epoch: 6| Step: 13
Training loss: 1.5234518979688216
Validation loss: 2.5798415131828984

Epoch: 218| Step: 0
Training loss: 1.7460564730972687
Validation loss: 2.5844576615523414

Epoch: 6| Step: 1
Training loss: 1.8499309578461591
Validation loss: 2.580978867402285

Epoch: 6| Step: 2
Training loss: 1.1058351698004723
Validation loss: 2.573003323484691

Epoch: 6| Step: 3
Training loss: 1.0123014208243948
Validation loss: 2.5651841351003806

Epoch: 6| Step: 4
Training loss: 2.049103666528768
Validation loss: 2.5535579363179335

Epoch: 6| Step: 5
Training loss: 1.4953639389326698
Validation loss: 2.5274946672956538

Epoch: 6| Step: 6
Training loss: 1.3293222752828264
Validation loss: 2.5666435325423254

Epoch: 6| Step: 7
Training loss: 1.374146369906024
Validation loss: 2.51333574535108

Epoch: 6| Step: 8
Training loss: 1.7665840177576821
Validation loss: 2.5264857678282513

Epoch: 6| Step: 9
Training loss: 1.6637455454823327
Validation loss: 2.5345607968195787

Epoch: 6| Step: 10
Training loss: 1.984984176726416
Validation loss: 2.5332493301668424

Epoch: 6| Step: 11
Training loss: 1.2790336978818748
Validation loss: 2.5282160215192873

Epoch: 6| Step: 12
Training loss: 0.9353325584394363
Validation loss: 2.534388718883324

Epoch: 6| Step: 13
Training loss: 1.8611270119413228
Validation loss: 2.560925389842292

Epoch: 219| Step: 0
Training loss: 1.0535171797319764
Validation loss: 2.578836300531179

Epoch: 6| Step: 1
Training loss: 1.7659420302695275
Validation loss: 2.6372597182977042

Epoch: 6| Step: 2
Training loss: 1.3353122787421838
Validation loss: 2.7100284153028618

Epoch: 6| Step: 3
Training loss: 1.4428335840090531
Validation loss: 2.7276813329326743

Epoch: 6| Step: 4
Training loss: 1.9311732082469595
Validation loss: 2.761001134668917

Epoch: 6| Step: 5
Training loss: 1.7170779331230044
Validation loss: 2.732893861586118

Epoch: 6| Step: 6
Training loss: 1.8388035257252153
Validation loss: 2.699110734142217

Epoch: 6| Step: 7
Training loss: 1.382871551114902
Validation loss: 2.6616924067285854

Epoch: 6| Step: 8
Training loss: 1.674978352876532
Validation loss: 2.6184116547597136

Epoch: 6| Step: 9
Training loss: 1.7450811193460734
Validation loss: 2.561690829276617

Epoch: 6| Step: 10
Training loss: 1.3138755674450782
Validation loss: 2.562591060898295

Epoch: 6| Step: 11
Training loss: 1.8844252521146854
Validation loss: 2.518056236948614

Epoch: 6| Step: 12
Training loss: 1.0713698461878403
Validation loss: 2.522024747889095

Epoch: 6| Step: 13
Training loss: 0.8878954503355806
Validation loss: 2.4879203456483023

Epoch: 220| Step: 0
Training loss: 1.6476312627294931
Validation loss: 2.5172842305718177

Epoch: 6| Step: 1
Training loss: 1.867183286271069
Validation loss: 2.539905660897721

Epoch: 6| Step: 2
Training loss: 1.1590172927856583
Validation loss: 2.5339313192608444

Epoch: 6| Step: 3
Training loss: 1.7176083327641618
Validation loss: 2.5877056500418534

Epoch: 6| Step: 4
Training loss: 1.1819239757442468
Validation loss: 2.5875927879988034

Epoch: 6| Step: 5
Training loss: 1.5171674764394179
Validation loss: 2.582633323249357

Epoch: 6| Step: 6
Training loss: 1.5310592532561245
Validation loss: 2.581077241200182

Epoch: 6| Step: 7
Training loss: 1.4738009023894758
Validation loss: 2.598879276564113

Epoch: 6| Step: 8
Training loss: 1.6763506724417327
Validation loss: 2.570340775257826

Epoch: 6| Step: 9
Training loss: 1.1732809660796024
Validation loss: 2.594611497165001

Epoch: 6| Step: 10
Training loss: 1.5302957169226115
Validation loss: 2.585867976725138

Epoch: 6| Step: 11
Training loss: 1.4015548314593897
Validation loss: 2.594498322903931

Epoch: 6| Step: 12
Training loss: 1.9615961313760268
Validation loss: 2.617803708177858

Epoch: 6| Step: 13
Training loss: 1.1295751154333429
Validation loss: 2.638864397137868

Epoch: 221| Step: 0
Training loss: 1.5834800585306277
Validation loss: 2.5934775711387545

Epoch: 6| Step: 1
Training loss: 1.515092421882072
Validation loss: 2.5881814148685485

Epoch: 6| Step: 2
Training loss: 0.9735150816052384
Validation loss: 2.5900062321122195

Epoch: 6| Step: 3
Training loss: 1.931344868820516
Validation loss: 2.590127523826123

Epoch: 6| Step: 4
Training loss: 1.958498954533095
Validation loss: 2.5671353318052827

Epoch: 6| Step: 5
Training loss: 1.4372982215243453
Validation loss: 2.573475114541378

Epoch: 6| Step: 6
Training loss: 1.1695966825866098
Validation loss: 2.5746945769807437

Epoch: 6| Step: 7
Training loss: 1.2602409471498086
Validation loss: 2.5663642599543106

Epoch: 6| Step: 8
Training loss: 1.2196049747994897
Validation loss: 2.5589771801621444

Epoch: 6| Step: 9
Training loss: 1.6430279527446776
Validation loss: 2.527201945360391

Epoch: 6| Step: 10
Training loss: 1.4414326321635
Validation loss: 2.507052357767187

Epoch: 6| Step: 11
Training loss: 1.465810390695518
Validation loss: 2.5351519967388616

Epoch: 6| Step: 12
Training loss: 1.6175783578798357
Validation loss: 2.5585255708732437

Epoch: 6| Step: 13
Training loss: 1.6782626473859328
Validation loss: 2.5658592907033544

Epoch: 222| Step: 0
Training loss: 1.8570829738142718
Validation loss: 2.55845082665138

Epoch: 6| Step: 1
Training loss: 1.245357379559328
Validation loss: 2.5872023808547744

Epoch: 6| Step: 2
Training loss: 1.8066436602592746
Validation loss: 2.5976058995791065

Epoch: 6| Step: 3
Training loss: 1.565389250710776
Validation loss: 2.625606104563502

Epoch: 6| Step: 4
Training loss: 1.3537491766168939
Validation loss: 2.6046129985324993

Epoch: 6| Step: 5
Training loss: 1.6137985619315787
Validation loss: 2.6101630739349955

Epoch: 6| Step: 6
Training loss: 1.2036122908210936
Validation loss: 2.593755092188372

Epoch: 6| Step: 7
Training loss: 1.2726529753041624
Validation loss: 2.552006674932203

Epoch: 6| Step: 8
Training loss: 0.8617843492289462
Validation loss: 2.5444294789179813

Epoch: 6| Step: 9
Training loss: 1.8869675497914808
Validation loss: 2.5224936253558496

Epoch: 6| Step: 10
Training loss: 1.5284412080278735
Validation loss: 2.522154462276767

Epoch: 6| Step: 11
Training loss: 1.3805630162193339
Validation loss: 2.5428765871896597

Epoch: 6| Step: 12
Training loss: 1.7238750687359141
Validation loss: 2.563178226047435

Epoch: 6| Step: 13
Training loss: 1.2234430188752439
Validation loss: 2.5986430704643366

Epoch: 223| Step: 0
Training loss: 1.3615680412020377
Validation loss: 2.6237873845149267

Epoch: 6| Step: 1
Training loss: 1.5345352897128646
Validation loss: 2.6304218456963966

Epoch: 6| Step: 2
Training loss: 1.3420257151111268
Validation loss: 2.652658284664471

Epoch: 6| Step: 3
Training loss: 1.6385263007773887
Validation loss: 2.664924514598163

Epoch: 6| Step: 4
Training loss: 0.9114130208695702
Validation loss: 2.6393732034695767

Epoch: 6| Step: 5
Training loss: 1.5321885171692764
Validation loss: 2.603151869070456

Epoch: 6| Step: 6
Training loss: 1.719942962011247
Validation loss: 2.5915680865544153

Epoch: 6| Step: 7
Training loss: 1.4021616527945795
Validation loss: 2.5725458867813558

Epoch: 6| Step: 8
Training loss: 1.6850190468908681
Validation loss: 2.564517397824453

Epoch: 6| Step: 9
Training loss: 1.6445004421800695
Validation loss: 2.5561532849991786

Epoch: 6| Step: 10
Training loss: 1.391032469984094
Validation loss: 2.5952688791716327

Epoch: 6| Step: 11
Training loss: 1.7185908850798497
Validation loss: 2.6123429332191757

Epoch: 6| Step: 12
Training loss: 1.2700078920434554
Validation loss: 2.6072789862379144

Epoch: 6| Step: 13
Training loss: 1.4173104936249346
Validation loss: 2.5979801661614754

Epoch: 224| Step: 0
Training loss: 1.2118643874224573
Validation loss: 2.6446215142993204

Epoch: 6| Step: 1
Training loss: 1.7636449733638382
Validation loss: 2.648053512302441

Epoch: 6| Step: 2
Training loss: 1.3136972688641746
Validation loss: 2.6755720245524497

Epoch: 6| Step: 3
Training loss: 1.859418852473295
Validation loss: 2.6660342511270105

Epoch: 6| Step: 4
Training loss: 0.8978355713325377
Validation loss: 2.623995494504075

Epoch: 6| Step: 5
Training loss: 1.0622240718012321
Validation loss: 2.607691329165793

Epoch: 6| Step: 6
Training loss: 2.066950418107388
Validation loss: 2.6133069414002574

Epoch: 6| Step: 7
Training loss: 1.3073102435530997
Validation loss: 2.5868873637395833

Epoch: 6| Step: 8
Training loss: 1.386102157840765
Validation loss: 2.5691830291362177

Epoch: 6| Step: 9
Training loss: 1.2389582759706852
Validation loss: 2.585567638135491

Epoch: 6| Step: 10
Training loss: 1.1607256689666265
Validation loss: 2.5859224662099627

Epoch: 6| Step: 11
Training loss: 1.3868164028116419
Validation loss: 2.580954936140792

Epoch: 6| Step: 12
Training loss: 1.5191591881117867
Validation loss: 2.601487830439055

Epoch: 6| Step: 13
Training loss: 2.539982274061212
Validation loss: 2.603938099008289

Epoch: 225| Step: 0
Training loss: 1.3105388703648986
Validation loss: 2.640150176646547

Epoch: 6| Step: 1
Training loss: 1.2489377276470925
Validation loss: 2.6926239496159767

Epoch: 6| Step: 2
Training loss: 1.956189977925541
Validation loss: 2.6881772251899565

Epoch: 6| Step: 3
Training loss: 0.9374051363951396
Validation loss: 2.7003646718256

Epoch: 6| Step: 4
Training loss: 1.6622616331691962
Validation loss: 2.652327716708917

Epoch: 6| Step: 5
Training loss: 1.2171563708887483
Validation loss: 2.6398927950479187

Epoch: 6| Step: 6
Training loss: 1.6528652802001036
Validation loss: 2.6077675105198836

Epoch: 6| Step: 7
Training loss: 1.5381142265503644
Validation loss: 2.6021898877905034

Epoch: 6| Step: 8
Training loss: 1.193313572780379
Validation loss: 2.6070157598696806

Epoch: 6| Step: 9
Training loss: 1.4429808082758302
Validation loss: 2.5768354982742987

Epoch: 6| Step: 10
Training loss: 1.7243310654101283
Validation loss: 2.601182851719297

Epoch: 6| Step: 11
Training loss: 1.4559218040941762
Validation loss: 2.573895194638867

Epoch: 6| Step: 12
Training loss: 1.399040347961961
Validation loss: 2.583597158508911

Epoch: 6| Step: 13
Training loss: 1.4001109164442125
Validation loss: 2.573949217976375

Epoch: 226| Step: 0
Training loss: 1.6570344902413363
Validation loss: 2.6270555748193942

Epoch: 6| Step: 1
Training loss: 1.612632269942057
Validation loss: 2.6224460062792128

Epoch: 6| Step: 2
Training loss: 1.6191553499405826
Validation loss: 2.6622615677984767

Epoch: 6| Step: 3
Training loss: 1.5991564285218287
Validation loss: 2.6725355980924963

Epoch: 6| Step: 4
Training loss: 1.5867327119935175
Validation loss: 2.6697550611979355

Epoch: 6| Step: 5
Training loss: 1.066676961332552
Validation loss: 2.66243274504987

Epoch: 6| Step: 6
Training loss: 1.2546330422332468
Validation loss: 2.685466602844792

Epoch: 6| Step: 7
Training loss: 1.68345383064899
Validation loss: 2.6641449730725206

Epoch: 6| Step: 8
Training loss: 1.216585780856036
Validation loss: 2.6359244178543477

Epoch: 6| Step: 9
Training loss: 1.6296980509137573
Validation loss: 2.6079178724925822

Epoch: 6| Step: 10
Training loss: 1.0111492424599564
Validation loss: 2.5565549857319168

Epoch: 6| Step: 11
Training loss: 1.6627642084574847
Validation loss: 2.5246958466264964

Epoch: 6| Step: 12
Training loss: 1.2141899483847933
Validation loss: 2.493384942146378

Epoch: 6| Step: 13
Training loss: 0.6936410895767462
Validation loss: 2.4900525934962943

Epoch: 227| Step: 0
Training loss: 1.3999449208187777
Validation loss: 2.500844756321593

Epoch: 6| Step: 1
Training loss: 1.5957622166948418
Validation loss: 2.499234321202429

Epoch: 6| Step: 2
Training loss: 1.5235655119494076
Validation loss: 2.5219516848061185

Epoch: 6| Step: 3
Training loss: 1.4287991291186593
Validation loss: 2.5409920952337375

Epoch: 6| Step: 4
Training loss: 1.597174387597924
Validation loss: 2.557557259995823

Epoch: 6| Step: 5
Training loss: 1.3302955841788342
Validation loss: 2.6090336881519263

Epoch: 6| Step: 6
Training loss: 1.2369757668967123
Validation loss: 2.611773317606915

Epoch: 6| Step: 7
Training loss: 1.2044225854188253
Validation loss: 2.652153092737145

Epoch: 6| Step: 8
Training loss: 1.101487718573426
Validation loss: 2.639076321962977

Epoch: 6| Step: 9
Training loss: 1.1768528310315536
Validation loss: 2.6244992151060305

Epoch: 6| Step: 10
Training loss: 1.388157401842471
Validation loss: 2.5873229459378555

Epoch: 6| Step: 11
Training loss: 1.6725242281129675
Validation loss: 2.571480306803864

Epoch: 6| Step: 12
Training loss: 1.6797320692669786
Validation loss: 2.5791876180676074

Epoch: 6| Step: 13
Training loss: 1.958274705158042
Validation loss: 2.556394238402509

Epoch: 228| Step: 0
Training loss: 1.3709021975178615
Validation loss: 2.583883338780725

Epoch: 6| Step: 1
Training loss: 1.2422661906335184
Validation loss: 2.589183566765327

Epoch: 6| Step: 2
Training loss: 1.2707007083582538
Validation loss: 2.5968994442052007

Epoch: 6| Step: 3
Training loss: 1.9848619599472848
Validation loss: 2.5974389520048518

Epoch: 6| Step: 4
Training loss: 1.3974225927353088
Validation loss: 2.6367043475111305

Epoch: 6| Step: 5
Training loss: 1.6665543359413084
Validation loss: 2.6565066298668327

Epoch: 6| Step: 6
Training loss: 1.3759281320489085
Validation loss: 2.636404891512156

Epoch: 6| Step: 7
Training loss: 1.5410353510649297
Validation loss: 2.623709549457339

Epoch: 6| Step: 8
Training loss: 1.1918148153199444
Validation loss: 2.639782687683857

Epoch: 6| Step: 9
Training loss: 0.7602312480316128
Validation loss: 2.624138293658446

Epoch: 6| Step: 10
Training loss: 1.4060601000251776
Validation loss: 2.6310292706997154

Epoch: 6| Step: 11
Training loss: 1.5184877239807535
Validation loss: 2.6002538537383577

Epoch: 6| Step: 12
Training loss: 1.257741937968242
Validation loss: 2.5807678736972544

Epoch: 6| Step: 13
Training loss: 1.5151827452070892
Validation loss: 2.6023455198402274

Epoch: 229| Step: 0
Training loss: 1.4137830089219945
Validation loss: 2.574150558465525

Epoch: 6| Step: 1
Training loss: 1.481982903704958
Validation loss: 2.575603739131364

Epoch: 6| Step: 2
Training loss: 1.3335755644744434
Validation loss: 2.5996943947347715

Epoch: 6| Step: 3
Training loss: 1.1513553842031758
Validation loss: 2.622215041790996

Epoch: 6| Step: 4
Training loss: 1.3179591949062255
Validation loss: 2.6297176508098454

Epoch: 6| Step: 5
Training loss: 1.6414506560341886
Validation loss: 2.6197235901653873

Epoch: 6| Step: 6
Training loss: 2.033482425205737
Validation loss: 2.6195882610920336

Epoch: 6| Step: 7
Training loss: 0.968712406044273
Validation loss: 2.6028582535058207

Epoch: 6| Step: 8
Training loss: 1.1638673452347446
Validation loss: 2.5942835994660265

Epoch: 6| Step: 9
Training loss: 1.1189858427745885
Validation loss: 2.626305432795687

Epoch: 6| Step: 10
Training loss: 1.3781379958597486
Validation loss: 2.5955723225600247

Epoch: 6| Step: 11
Training loss: 1.5028281571049957
Validation loss: 2.612963548080694

Epoch: 6| Step: 12
Training loss: 1.201738524720026
Validation loss: 2.583792441898061

Epoch: 6| Step: 13
Training loss: 1.460535902016274
Validation loss: 2.5685275479381526

Epoch: 230| Step: 0
Training loss: 1.397182050236581
Validation loss: 2.565880922890912

Epoch: 6| Step: 1
Training loss: 1.5074521755900863
Validation loss: 2.5653388063111118

Epoch: 6| Step: 2
Training loss: 1.24171385942079
Validation loss: 2.5780512317235265

Epoch: 6| Step: 3
Training loss: 1.3816686522251367
Validation loss: 2.573211083803368

Epoch: 6| Step: 4
Training loss: 1.2645476665630806
Validation loss: 2.592087017966698

Epoch: 6| Step: 5
Training loss: 1.3961674257209362
Validation loss: 2.580541978908793

Epoch: 6| Step: 6
Training loss: 1.46783548656687
Validation loss: 2.5877013325665605

Epoch: 6| Step: 7
Training loss: 1.749112108326887
Validation loss: 2.608777597819531

Epoch: 6| Step: 8
Training loss: 1.0441145300324821
Validation loss: 2.648349733526139

Epoch: 6| Step: 9
Training loss: 1.2720302458921873
Validation loss: 2.644739143889715

Epoch: 6| Step: 10
Training loss: 0.629960592036455
Validation loss: 2.6597921670935127

Epoch: 6| Step: 11
Training loss: 1.705961752217944
Validation loss: 2.642479831681729

Epoch: 6| Step: 12
Training loss: 0.9029132317543854
Validation loss: 2.6565671341787063

Epoch: 6| Step: 13
Training loss: 1.9715831292718227
Validation loss: 2.65384593994363

Epoch: 231| Step: 0
Training loss: 1.3763710902107158
Validation loss: 2.6636245209215166

Epoch: 6| Step: 1
Training loss: 1.5646076483261493
Validation loss: 2.687179263932593

Epoch: 6| Step: 2
Training loss: 1.4663620061606795
Validation loss: 2.668794076253035

Epoch: 6| Step: 3
Training loss: 1.5034488923825198
Validation loss: 2.636421519503085

Epoch: 6| Step: 4
Training loss: 0.9529771533801332
Validation loss: 2.6137231551589677

Epoch: 6| Step: 5
Training loss: 1.3793501099042074
Validation loss: 2.617564836781847

Epoch: 6| Step: 6
Training loss: 1.2400194357302508
Validation loss: 2.610440135128454

Epoch: 6| Step: 7
Training loss: 1.3863495241149004
Validation loss: 2.6360092622000217

Epoch: 6| Step: 8
Training loss: 1.4314759121972427
Validation loss: 2.6097172564303968

Epoch: 6| Step: 9
Training loss: 1.2043706712313402
Validation loss: 2.6084063709795795

Epoch: 6| Step: 10
Training loss: 1.2781605573338963
Validation loss: 2.6001137587095724

Epoch: 6| Step: 11
Training loss: 1.1484217220961237
Validation loss: 2.6315113707416566

Epoch: 6| Step: 12
Training loss: 1.689569123095089
Validation loss: 2.599048001791389

Epoch: 6| Step: 13
Training loss: 1.068454773041668
Validation loss: 2.6172025442264975

Epoch: 232| Step: 0
Training loss: 1.3387488070072162
Validation loss: 2.621069123773965

Epoch: 6| Step: 1
Training loss: 1.83170561346706
Validation loss: 2.607660045517654

Epoch: 6| Step: 2
Training loss: 1.3691989597839274
Validation loss: 2.609174594327162

Epoch: 6| Step: 3
Training loss: 1.2297456099898494
Validation loss: 2.5997164484869755

Epoch: 6| Step: 4
Training loss: 1.1229527707686071
Validation loss: 2.6467392985030385

Epoch: 6| Step: 5
Training loss: 1.2916357539179748
Validation loss: 2.64569156594101

Epoch: 6| Step: 6
Training loss: 1.008399851367823
Validation loss: 2.6654463970353937

Epoch: 6| Step: 7
Training loss: 1.0824530705417357
Validation loss: 2.6673387486804114

Epoch: 6| Step: 8
Training loss: 1.8054443357724308
Validation loss: 2.679457795607412

Epoch: 6| Step: 9
Training loss: 1.4165607113577598
Validation loss: 2.650076602835504

Epoch: 6| Step: 10
Training loss: 1.4053742967030591
Validation loss: 2.6270348942952704

Epoch: 6| Step: 11
Training loss: 1.0948491159761902
Validation loss: 2.6530766776069137

Epoch: 6| Step: 12
Training loss: 1.4547507103319888
Validation loss: 2.627439373829602

Epoch: 6| Step: 13
Training loss: 0.8547559581726332
Validation loss: 2.582277980175601

Epoch: 233| Step: 0
Training loss: 1.1540945427642857
Validation loss: 2.6231705599143256

Epoch: 6| Step: 1
Training loss: 0.8926239335807367
Validation loss: 2.6160441992313137

Epoch: 6| Step: 2
Training loss: 1.1804083333437752
Validation loss: 2.608453766923783

Epoch: 6| Step: 3
Training loss: 1.3253765165037341
Validation loss: 2.6023858220557115

Epoch: 6| Step: 4
Training loss: 1.4150592810408555
Validation loss: 2.605667172872607

Epoch: 6| Step: 5
Training loss: 1.4218895879982256
Validation loss: 2.59410735405319

Epoch: 6| Step: 6
Training loss: 1.0652346480578698
Validation loss: 2.5833139008642285

Epoch: 6| Step: 7
Training loss: 1.5045575997916125
Validation loss: 2.5438474175470462

Epoch: 6| Step: 8
Training loss: 1.3789997015130464
Validation loss: 2.542155937039577

Epoch: 6| Step: 9
Training loss: 1.2830701785261285
Validation loss: 2.5945833095394546

Epoch: 6| Step: 10
Training loss: 1.0897772984088347
Validation loss: 2.5981214868003843

Epoch: 6| Step: 11
Training loss: 1.1765919675341132
Validation loss: 2.5952985212983037

Epoch: 6| Step: 12
Training loss: 1.9676985582062099
Validation loss: 2.5961089246986515

Epoch: 6| Step: 13
Training loss: 1.617442161669791
Validation loss: 2.616882000772009

Epoch: 234| Step: 0
Training loss: 1.6933958408252825
Validation loss: 2.6157391182607306

Epoch: 6| Step: 1
Training loss: 0.5651824357871987
Validation loss: 2.596129376595549

Epoch: 6| Step: 2
Training loss: 1.213728463308898
Validation loss: 2.6150331164651477

Epoch: 6| Step: 3
Training loss: 1.0492634642298158
Validation loss: 2.5681968799450647

Epoch: 6| Step: 4
Training loss: 0.8206739809943134
Validation loss: 2.572403634472795

Epoch: 6| Step: 5
Training loss: 1.546724408458545
Validation loss: 2.567911582117345

Epoch: 6| Step: 6
Training loss: 1.188450683713215
Validation loss: 2.54205416814107

Epoch: 6| Step: 7
Training loss: 1.3087382678040735
Validation loss: 2.5535262384555075

Epoch: 6| Step: 8
Training loss: 1.719488852089576
Validation loss: 2.584554615443417

Epoch: 6| Step: 9
Training loss: 1.4242897070421388
Validation loss: 2.603643665258212

Epoch: 6| Step: 10
Training loss: 0.7973714291961606
Validation loss: 2.6239375959352165

Epoch: 6| Step: 11
Training loss: 1.4561647185538575
Validation loss: 2.6223603369503152

Epoch: 6| Step: 12
Training loss: 1.5815327176747895
Validation loss: 2.61467055743252

Epoch: 6| Step: 13
Training loss: 1.687620935698364
Validation loss: 2.599922566684625

Epoch: 235| Step: 0
Training loss: 1.4332823038258469
Validation loss: 2.6166206589648766

Epoch: 6| Step: 1
Training loss: 1.2253824376619218
Validation loss: 2.654266668493702

Epoch: 6| Step: 2
Training loss: 1.7090051617039408
Validation loss: 2.6530411198406876

Epoch: 6| Step: 3
Training loss: 1.328865742276278
Validation loss: 2.6381982087481566

Epoch: 6| Step: 4
Training loss: 1.515578121758115
Validation loss: 2.6331442308136337

Epoch: 6| Step: 5
Training loss: 1.2418090435726632
Validation loss: 2.66970450339229

Epoch: 6| Step: 6
Training loss: 1.2453680526231776
Validation loss: 2.689076200146459

Epoch: 6| Step: 7
Training loss: 1.438951505839313
Validation loss: 2.7161150468974293

Epoch: 6| Step: 8
Training loss: 1.2653195047785257
Validation loss: 2.7150018560547897

Epoch: 6| Step: 9
Training loss: 1.1398938069323667
Validation loss: 2.677759115801727

Epoch: 6| Step: 10
Training loss: 1.2867899427423495
Validation loss: 2.6362055122745245

Epoch: 6| Step: 11
Training loss: 1.4572265330499847
Validation loss: 2.580781731081026

Epoch: 6| Step: 12
Training loss: 1.266322520628017
Validation loss: 2.5327829610599566

Epoch: 6| Step: 13
Training loss: 0.7688444529248253
Validation loss: 2.5012715715478255

Epoch: 236| Step: 0
Training loss: 1.1244676177983841
Validation loss: 2.5085574014200236

Epoch: 6| Step: 1
Training loss: 1.386417151951776
Validation loss: 2.488401867777061

Epoch: 6| Step: 2
Training loss: 1.417938484310263
Validation loss: 2.5179506146908834

Epoch: 6| Step: 3
Training loss: 1.6099638370930685
Validation loss: 2.569362075299855

Epoch: 6| Step: 4
Training loss: 1.2207530263237878
Validation loss: 2.618781206812053

Epoch: 6| Step: 5
Training loss: 1.0821399840658952
Validation loss: 2.6610435350594126

Epoch: 6| Step: 6
Training loss: 1.124795259282851
Validation loss: 2.6945135391533315

Epoch: 6| Step: 7
Training loss: 1.1105425426332902
Validation loss: 2.762078024687759

Epoch: 6| Step: 8
Training loss: 1.3229823459130723
Validation loss: 2.754090541798866

Epoch: 6| Step: 9
Training loss: 1.52570334927582
Validation loss: 2.724803142204978

Epoch: 6| Step: 10
Training loss: 1.339264858628422
Validation loss: 2.7203321293553357

Epoch: 6| Step: 11
Training loss: 1.3622935742434252
Validation loss: 2.652357019823808

Epoch: 6| Step: 12
Training loss: 1.5945192612267867
Validation loss: 2.556178415271301

Epoch: 6| Step: 13
Training loss: 1.1856185665167214
Validation loss: 2.488420694749574

Epoch: 237| Step: 0
Training loss: 1.3046567079485287
Validation loss: 2.4613690314520493

Epoch: 6| Step: 1
Training loss: 1.390092855068972
Validation loss: 2.4492593285542585

Epoch: 6| Step: 2
Training loss: 1.1316285358872198
Validation loss: 2.4339949399406624

Epoch: 6| Step: 3
Training loss: 1.2146014496295732
Validation loss: 2.4343140150077867

Epoch: 6| Step: 4
Training loss: 1.4698686600743116
Validation loss: 2.5032722100789266

Epoch: 6| Step: 5
Training loss: 0.9910036969698129
Validation loss: 2.558638707110172

Epoch: 6| Step: 6
Training loss: 1.7739855889828484
Validation loss: 2.611417465577038

Epoch: 6| Step: 7
Training loss: 1.3781257992696716
Validation loss: 2.6941741465540736

Epoch: 6| Step: 8
Training loss: 1.1279101349428127
Validation loss: 2.727705317133822

Epoch: 6| Step: 9
Training loss: 1.3202147588723483
Validation loss: 2.723209568457732

Epoch: 6| Step: 10
Training loss: 1.807615077153009
Validation loss: 2.756528039151145

Epoch: 6| Step: 11
Training loss: 1.3039209089603694
Validation loss: 2.7469248558633614

Epoch: 6| Step: 12
Training loss: 1.2202731664670663
Validation loss: 2.683978475758449

Epoch: 6| Step: 13
Training loss: 0.48067829555874325
Validation loss: 2.6758454815333663

Epoch: 238| Step: 0
Training loss: 1.1399118467178322
Validation loss: 2.646515103817777

Epoch: 6| Step: 1
Training loss: 1.1192921907006463
Validation loss: 2.621380097739904

Epoch: 6| Step: 2
Training loss: 1.0684649260159271
Validation loss: 2.6148670560467533

Epoch: 6| Step: 3
Training loss: 0.8255133924339442
Validation loss: 2.615901022910728

Epoch: 6| Step: 4
Training loss: 1.121134421644242
Validation loss: 2.6218078651815526

Epoch: 6| Step: 5
Training loss: 1.2520232991801963
Validation loss: 2.625349197365867

Epoch: 6| Step: 6
Training loss: 1.3260978936528083
Validation loss: 2.6335241943555836

Epoch: 6| Step: 7
Training loss: 1.1595954438670388
Validation loss: 2.6208703258670045

Epoch: 6| Step: 8
Training loss: 1.2957327534850616
Validation loss: 2.610288101017262

Epoch: 6| Step: 9
Training loss: 1.3562218940037603
Validation loss: 2.6169702544124678

Epoch: 6| Step: 10
Training loss: 1.3309525851567916
Validation loss: 2.5791490119007654

Epoch: 6| Step: 11
Training loss: 1.4936967177843863
Validation loss: 2.5393995380966867

Epoch: 6| Step: 12
Training loss: 1.581203517306001
Validation loss: 2.5042116600478437

Epoch: 6| Step: 13
Training loss: 1.9680686861705583
Validation loss: 2.4882801681997604

Epoch: 239| Step: 0
Training loss: 1.4602813879348229
Validation loss: 2.4635620289784668

Epoch: 6| Step: 1
Training loss: 1.3054241453594362
Validation loss: 2.4279470708184263

Epoch: 6| Step: 2
Training loss: 1.4611568184308195
Validation loss: 2.4454711487274334

Epoch: 6| Step: 3
Training loss: 1.3598242707880737
Validation loss: 2.4431060037715517

Epoch: 6| Step: 4
Training loss: 0.8600522926977299
Validation loss: 2.5073214821322725

Epoch: 6| Step: 5
Training loss: 0.968418926148295
Validation loss: 2.545422461223201

Epoch: 6| Step: 6
Training loss: 1.1192209371406672
Validation loss: 2.632789186924783

Epoch: 6| Step: 7
Training loss: 1.1676786438805653
Validation loss: 2.6619354649393454

Epoch: 6| Step: 8
Training loss: 1.3254252201313192
Validation loss: 2.675535889015343

Epoch: 6| Step: 9
Training loss: 1.1670643548717312
Validation loss: 2.7049367375272166

Epoch: 6| Step: 10
Training loss: 1.688437448713749
Validation loss: 2.715696168761824

Epoch: 6| Step: 11
Training loss: 1.376925853702678
Validation loss: 2.730040303237455

Epoch: 6| Step: 12
Training loss: 1.2786177601681559
Validation loss: 2.665209900245804

Epoch: 6| Step: 13
Training loss: 1.0883654888381964
Validation loss: 2.669106272805426

Epoch: 240| Step: 0
Training loss: 1.192971024326837
Validation loss: 2.603009981930975

Epoch: 6| Step: 1
Training loss: 1.0878237253435636
Validation loss: 2.589457078035088

Epoch: 6| Step: 2
Training loss: 0.841417798146346
Validation loss: 2.547376482535088

Epoch: 6| Step: 3
Training loss: 1.720624421795444
Validation loss: 2.5286259004973535

Epoch: 6| Step: 4
Training loss: 1.4890368688564983
Validation loss: 2.5368399374164694

Epoch: 6| Step: 5
Training loss: 1.0747316003232898
Validation loss: 2.518290251305018

Epoch: 6| Step: 6
Training loss: 1.3162651552376605
Validation loss: 2.5081051901753284

Epoch: 6| Step: 7
Training loss: 1.098695147971153
Validation loss: 2.5523570781368448

Epoch: 6| Step: 8
Training loss: 1.4410159195041123
Validation loss: 2.5627630295357897

Epoch: 6| Step: 9
Training loss: 1.1478579869073502
Validation loss: 2.591835195839189

Epoch: 6| Step: 10
Training loss: 0.7073633246623637
Validation loss: 2.587502540593869

Epoch: 6| Step: 11
Training loss: 1.457570485002355
Validation loss: 2.639291819833692

Epoch: 6| Step: 12
Training loss: 1.1591693006787698
Validation loss: 2.679277709023391

Epoch: 6| Step: 13
Training loss: 1.5433577807627492
Validation loss: 2.627898066278205

Epoch: 241| Step: 0
Training loss: 1.3262483689912048
Validation loss: 2.639059802012895

Epoch: 6| Step: 1
Training loss: 1.400098400404459
Validation loss: 2.6509529026543057

Epoch: 6| Step: 2
Training loss: 1.1317595751513019
Validation loss: 2.6101585578838886

Epoch: 6| Step: 3
Training loss: 1.0774401825588706
Validation loss: 2.624182427786483

Epoch: 6| Step: 4
Training loss: 1.2869149554711672
Validation loss: 2.611185658134813

Epoch: 6| Step: 5
Training loss: 1.050275943463823
Validation loss: 2.6291984660580696

Epoch: 6| Step: 6
Training loss: 1.415468475917828
Validation loss: 2.634571368055149

Epoch: 6| Step: 7
Training loss: 1.1784891774842265
Validation loss: 2.6562088289393855

Epoch: 6| Step: 8
Training loss: 0.871991776606955
Validation loss: 2.6766706231303994

Epoch: 6| Step: 9
Training loss: 1.320685339658141
Validation loss: 2.7155691286602237

Epoch: 6| Step: 10
Training loss: 1.8120210606738436
Validation loss: 2.75651409245745

Epoch: 6| Step: 11
Training loss: 1.4643861589971252
Validation loss: 2.6999042781905778

Epoch: 6| Step: 12
Training loss: 1.0495520567212286
Validation loss: 2.6338387290034984

Epoch: 6| Step: 13
Training loss: 1.3771378629952298
Validation loss: 2.594645958611112

Epoch: 242| Step: 0
Training loss: 1.4102732855502966
Validation loss: 2.521515958155836

Epoch: 6| Step: 1
Training loss: 1.069214696412386
Validation loss: 2.5015788373952774

Epoch: 6| Step: 2
Training loss: 1.3051193344976784
Validation loss: 2.465932272074331

Epoch: 6| Step: 3
Training loss: 1.3825359606765322
Validation loss: 2.4761631006533746

Epoch: 6| Step: 4
Training loss: 1.4173752564671305
Validation loss: 2.4809313327835665

Epoch: 6| Step: 5
Training loss: 1.2507843894371076
Validation loss: 2.4998254848399206

Epoch: 6| Step: 6
Training loss: 1.4089778298230464
Validation loss: 2.536208673363449

Epoch: 6| Step: 7
Training loss: 0.8677245530485921
Validation loss: 2.597890949155691

Epoch: 6| Step: 8
Training loss: 0.9883746378203114
Validation loss: 2.6307527407360936

Epoch: 6| Step: 9
Training loss: 1.1183312170365876
Validation loss: 2.6097316094221736

Epoch: 6| Step: 10
Training loss: 1.320878669289642
Validation loss: 2.637530696402362

Epoch: 6| Step: 11
Training loss: 1.4177268586453764
Validation loss: 2.679991944793316

Epoch: 6| Step: 12
Training loss: 1.0639702217767932
Validation loss: 2.682491826347735

Epoch: 6| Step: 13
Training loss: 1.754430204093037
Validation loss: 2.6585231582718625

Epoch: 243| Step: 0
Training loss: 0.9709556450696849
Validation loss: 2.6662721694609135

Epoch: 6| Step: 1
Training loss: 1.0600205269211542
Validation loss: 2.6406175497160747

Epoch: 6| Step: 2
Training loss: 1.1871623512891913
Validation loss: 2.589604773454241

Epoch: 6| Step: 3
Training loss: 1.3272745438844784
Validation loss: 2.5660754280401736

Epoch: 6| Step: 4
Training loss: 1.1331403586708624
Validation loss: 2.572492543523459

Epoch: 6| Step: 5
Training loss: 1.1556171541169433
Validation loss: 2.546608580834906

Epoch: 6| Step: 6
Training loss: 1.1834469946597994
Validation loss: 2.5290951283670036

Epoch: 6| Step: 7
Training loss: 1.2467367014278006
Validation loss: 2.5267924674832987

Epoch: 6| Step: 8
Training loss: 1.0141554544456488
Validation loss: 2.569385299364041

Epoch: 6| Step: 9
Training loss: 1.1520797168382904
Validation loss: 2.579635889372304

Epoch: 6| Step: 10
Training loss: 1.6705246222381842
Validation loss: 2.6032760585348242

Epoch: 6| Step: 11
Training loss: 1.4905082480974348
Validation loss: 2.611053372821986

Epoch: 6| Step: 12
Training loss: 1.0399753318208556
Validation loss: 2.6385771049272524

Epoch: 6| Step: 13
Training loss: 1.3591166283623222
Validation loss: 2.6442599267124343

Epoch: 244| Step: 0
Training loss: 1.6311574332329075
Validation loss: 2.660863040414613

Epoch: 6| Step: 1
Training loss: 1.145816172846981
Validation loss: 2.636328597833597

Epoch: 6| Step: 2
Training loss: 1.4499636481102085
Validation loss: 2.6502721938091933

Epoch: 6| Step: 3
Training loss: 0.4395002551767001
Validation loss: 2.6517433846131575

Epoch: 6| Step: 4
Training loss: 1.447926070733943
Validation loss: 2.6578683631733866

Epoch: 6| Step: 5
Training loss: 1.19791836392932
Validation loss: 2.616209924277063

Epoch: 6| Step: 6
Training loss: 1.4059689558842607
Validation loss: 2.5741747671052777

Epoch: 6| Step: 7
Training loss: 0.9816954336717078
Validation loss: 2.5791889460140447

Epoch: 6| Step: 8
Training loss: 0.7855512469989018
Validation loss: 2.5577078268610323

Epoch: 6| Step: 9
Training loss: 1.4622915592167296
Validation loss: 2.574200080964348

Epoch: 6| Step: 10
Training loss: 1.036391187374643
Validation loss: 2.54771422598667

Epoch: 6| Step: 11
Training loss: 0.8971970993267216
Validation loss: 2.5130623327483463

Epoch: 6| Step: 12
Training loss: 1.3102801032943492
Validation loss: 2.5932317345215434

Epoch: 6| Step: 13
Training loss: 0.9532965208717789
Validation loss: 2.596770159935371

Epoch: 245| Step: 0
Training loss: 1.3774641671340424
Validation loss: 2.6081860280900684

Epoch: 6| Step: 1
Training loss: 0.4848637729730639
Validation loss: 2.6705141428471753

Epoch: 6| Step: 2
Training loss: 1.3052540080285324
Validation loss: 2.643843499360627

Epoch: 6| Step: 3
Training loss: 1.6638805307819826
Validation loss: 2.6508541075078433

Epoch: 6| Step: 4
Training loss: 1.0085177652234498
Validation loss: 2.621861761250556

Epoch: 6| Step: 5
Training loss: 1.1094654744824661
Validation loss: 2.5663987400905706

Epoch: 6| Step: 6
Training loss: 0.9844949437288137
Validation loss: 2.552051080060864

Epoch: 6| Step: 7
Training loss: 0.8908035032513493
Validation loss: 2.5058670714569824

Epoch: 6| Step: 8
Training loss: 1.0080465592046293
Validation loss: 2.4929364259799054

Epoch: 6| Step: 9
Training loss: 1.0580636699678383
Validation loss: 2.492977425914262

Epoch: 6| Step: 10
Training loss: 1.7505301626135228
Validation loss: 2.4952914499308343

Epoch: 6| Step: 11
Training loss: 1.2203196663346916
Validation loss: 2.5343779613642

Epoch: 6| Step: 12
Training loss: 1.1896949359409905
Validation loss: 2.5809361857087763

Epoch: 6| Step: 13
Training loss: 1.3741101506681073
Validation loss: 2.5627517136370668

Epoch: 246| Step: 0
Training loss: 0.7516676323652584
Validation loss: 2.628446672803548

Epoch: 6| Step: 1
Training loss: 1.547962307503138
Validation loss: 2.6099552695433546

Epoch: 6| Step: 2
Training loss: 1.3090273010810682
Validation loss: 2.646269985990775

Epoch: 6| Step: 3
Training loss: 0.904275321291631
Validation loss: 2.629239010917782

Epoch: 6| Step: 4
Training loss: 1.4702150059157997
Validation loss: 2.5894961057203774

Epoch: 6| Step: 5
Training loss: 1.395636411791901
Validation loss: 2.6069017881630643

Epoch: 6| Step: 6
Training loss: 0.9961559201454889
Validation loss: 2.6201617112627127

Epoch: 6| Step: 7
Training loss: 1.1358010169395305
Validation loss: 2.6132575193936813

Epoch: 6| Step: 8
Training loss: 1.033440084993436
Validation loss: 2.618453449493498

Epoch: 6| Step: 9
Training loss: 0.899769732369934
Validation loss: 2.6038705459737765

Epoch: 6| Step: 10
Training loss: 1.0667661401937023
Validation loss: 2.5939155819312805

Epoch: 6| Step: 11
Training loss: 1.2817950601263237
Validation loss: 2.5923807449197773

Epoch: 6| Step: 12
Training loss: 1.2046901876021314
Validation loss: 2.5719206474149874

Epoch: 6| Step: 13
Training loss: 1.3020030289364226
Validation loss: 2.604982893154268

Epoch: 247| Step: 0
Training loss: 1.014075108994913
Validation loss: 2.594215198148254

Epoch: 6| Step: 1
Training loss: 1.139718309367289
Validation loss: 2.6219758262589647

Epoch: 6| Step: 2
Training loss: 0.9612082743424698
Validation loss: 2.5958805795015953

Epoch: 6| Step: 3
Training loss: 1.1936706037231841
Validation loss: 2.6170041971017954

Epoch: 6| Step: 4
Training loss: 0.7786585744030133
Validation loss: 2.601287784919235

Epoch: 6| Step: 5
Training loss: 0.8674388212018973
Validation loss: 2.583857010535378

Epoch: 6| Step: 6
Training loss: 1.3543094657530532
Validation loss: 2.5866655584431695

Epoch: 6| Step: 7
Training loss: 1.5144653603190141
Validation loss: 2.5845236895479218

Epoch: 6| Step: 8
Training loss: 1.410699037190092
Validation loss: 2.5623834755068113

Epoch: 6| Step: 9
Training loss: 0.932988213837767
Validation loss: 2.564783995786219

Epoch: 6| Step: 10
Training loss: 1.1624574284295626
Validation loss: 2.5446666064138332

Epoch: 6| Step: 11
Training loss: 0.8834400478416705
Validation loss: 2.574357299571757

Epoch: 6| Step: 12
Training loss: 1.4654551133069316
Validation loss: 2.552798958940006

Epoch: 6| Step: 13
Training loss: 1.3807488684565852
Validation loss: 2.558105531385235

Epoch: 248| Step: 0
Training loss: 1.0141968883461405
Validation loss: 2.580667691539402

Epoch: 6| Step: 1
Training loss: 0.9066006869847244
Validation loss: 2.6091493397603367

Epoch: 6| Step: 2
Training loss: 1.5525227720399584
Validation loss: 2.602784929145924

Epoch: 6| Step: 3
Training loss: 1.3189958858411366
Validation loss: 2.6100726610648652

Epoch: 6| Step: 4
Training loss: 0.8295166989255772
Validation loss: 2.6510273858302673

Epoch: 6| Step: 5
Training loss: 0.9925923760422058
Validation loss: 2.633030009943832

Epoch: 6| Step: 6
Training loss: 1.16330320441317
Validation loss: 2.6349577660865378

Epoch: 6| Step: 7
Training loss: 1.5132547308272635
Validation loss: 2.5897686623751803

Epoch: 6| Step: 8
Training loss: 0.7197524005284083
Validation loss: 2.5965430665689677

Epoch: 6| Step: 9
Training loss: 1.3299218532721582
Validation loss: 2.585086613247739

Epoch: 6| Step: 10
Training loss: 1.0961625331143192
Validation loss: 2.5923811345517156

Epoch: 6| Step: 11
Training loss: 1.1728940474845782
Validation loss: 2.5679347294500996

Epoch: 6| Step: 12
Training loss: 1.163982516619546
Validation loss: 2.554434880316644

Epoch: 6| Step: 13
Training loss: 0.8608676778239056
Validation loss: 2.581405205820184

Epoch: 249| Step: 0
Training loss: 1.2823727038528674
Validation loss: 2.5690648474119646

Epoch: 6| Step: 1
Training loss: 1.1303956130068855
Validation loss: 2.5407068170647342

Epoch: 6| Step: 2
Training loss: 1.0864996792809916
Validation loss: 2.578973499629113

Epoch: 6| Step: 3
Training loss: 1.1358572720369713
Validation loss: 2.534149306182741

Epoch: 6| Step: 4
Training loss: 1.0251609908420067
Validation loss: 2.566833171895936

Epoch: 6| Step: 5
Training loss: 1.3329206612850972
Validation loss: 2.584661274111604

Epoch: 6| Step: 6
Training loss: 0.8128569992421105
Validation loss: 2.5860985735279933

Epoch: 6| Step: 7
Training loss: 1.1421982875580692
Validation loss: 2.6014513645283377

Epoch: 6| Step: 8
Training loss: 1.0827264308438451
Validation loss: 2.621239109268523

Epoch: 6| Step: 9
Training loss: 1.3045727342394131
Validation loss: 2.5772326106107073

Epoch: 6| Step: 10
Training loss: 1.1640347471065087
Validation loss: 2.6206917398301646

Epoch: 6| Step: 11
Training loss: 1.3509276558391405
Validation loss: 2.611392016723727

Epoch: 6| Step: 12
Training loss: 0.710654988591337
Validation loss: 2.631842129285095

Epoch: 6| Step: 13
Training loss: 1.2275714005100558
Validation loss: 2.600209211912093

Epoch: 250| Step: 0
Training loss: 0.9833880729848864
Validation loss: 2.5867029255641

Epoch: 6| Step: 1
Training loss: 1.4446199974745162
Validation loss: 2.568760386518512

Epoch: 6| Step: 2
Training loss: 1.4733877616569786
Validation loss: 2.560462413682108

Epoch: 6| Step: 3
Training loss: 1.1617431063430064
Validation loss: 2.55998243971283

Epoch: 6| Step: 4
Training loss: 1.0251682003925353
Validation loss: 2.5447801804829946

Epoch: 6| Step: 5
Training loss: 1.2577161574340188
Validation loss: 2.5419395726584706

Epoch: 6| Step: 6
Training loss: 1.1142483977472546
Validation loss: 2.5511380247794477

Epoch: 6| Step: 7
Training loss: 0.9884160066789002
Validation loss: 2.585757443688587

Epoch: 6| Step: 8
Training loss: 1.1846217358930522
Validation loss: 2.577133818485787

Epoch: 6| Step: 9
Training loss: 0.93603200419437
Validation loss: 2.559208636750654

Epoch: 6| Step: 10
Training loss: 1.049984030375064
Validation loss: 2.5539611303584846

Epoch: 6| Step: 11
Training loss: 1.2858478111610692
Validation loss: 2.5918411058350705

Epoch: 6| Step: 12
Training loss: 0.6721944493103461
Validation loss: 2.6035779035598243

Epoch: 6| Step: 13
Training loss: 0.7139321439859888
Validation loss: 2.6181255561623704

Epoch: 251| Step: 0
Training loss: 1.005592681194733
Validation loss: 2.602037733211074

Epoch: 6| Step: 1
Training loss: 0.7372674995795483
Validation loss: 2.6221692007631243

Epoch: 6| Step: 2
Training loss: 1.1257932833068829
Validation loss: 2.620579384712136

Epoch: 6| Step: 3
Training loss: 1.2288598577493663
Validation loss: 2.58788309224279

Epoch: 6| Step: 4
Training loss: 1.176828519984113
Validation loss: 2.611664812017058

Epoch: 6| Step: 5
Training loss: 1.3278799391903067
Validation loss: 2.631846417695322

Epoch: 6| Step: 6
Training loss: 1.3257805270730847
Validation loss: 2.5884649004921703

Epoch: 6| Step: 7
Training loss: 0.46207704148797407
Validation loss: 2.5776421088174972

Epoch: 6| Step: 8
Training loss: 0.9971581251312139
Validation loss: 2.563353430662547

Epoch: 6| Step: 9
Training loss: 1.0319617733898752
Validation loss: 2.5311604550696245

Epoch: 6| Step: 10
Training loss: 1.03020956555567
Validation loss: 2.5243513846931593

Epoch: 6| Step: 11
Training loss: 1.1510817001538498
Validation loss: 2.5361924396044504

Epoch: 6| Step: 12
Training loss: 1.2442873594267865
Validation loss: 2.5143801345840675

Epoch: 6| Step: 13
Training loss: 1.6729761935704703
Validation loss: 2.5650266550780354

Epoch: 252| Step: 0
Training loss: 1.2567904092861049
Validation loss: 2.5295393006886324

Epoch: 6| Step: 1
Training loss: 1.1271108850765286
Validation loss: 2.601890109011929

Epoch: 6| Step: 2
Training loss: 0.6118275123069196
Validation loss: 2.589019591297064

Epoch: 6| Step: 3
Training loss: 1.0321327823707258
Validation loss: 2.6158718259314173

Epoch: 6| Step: 4
Training loss: 1.1991209307112134
Validation loss: 2.605362894935642

Epoch: 6| Step: 5
Training loss: 1.0526738476736803
Validation loss: 2.6078941894190906

Epoch: 6| Step: 6
Training loss: 1.3699275869180267
Validation loss: 2.6321404237902932

Epoch: 6| Step: 7
Training loss: 0.6488105436236231
Validation loss: 2.6150327802060045

Epoch: 6| Step: 8
Training loss: 1.179095694536966
Validation loss: 2.593503309454127

Epoch: 6| Step: 9
Training loss: 0.9520695267280708
Validation loss: 2.5828827115304316

Epoch: 6| Step: 10
Training loss: 1.045974799893831
Validation loss: 2.605320779994093

Epoch: 6| Step: 11
Training loss: 0.9936583422730487
Validation loss: 2.605131142147391

Epoch: 6| Step: 12
Training loss: 1.4908568355924683
Validation loss: 2.5945188784018494

Epoch: 6| Step: 13
Training loss: 1.3207673412327599
Validation loss: 2.598703721651404

Epoch: 253| Step: 0
Training loss: 1.5865785402513126
Validation loss: 2.572133573865573

Epoch: 6| Step: 1
Training loss: 0.7807545426010895
Validation loss: 2.592563639031677

Epoch: 6| Step: 2
Training loss: 1.0605922288839067
Validation loss: 2.5562513033971896

Epoch: 6| Step: 3
Training loss: 0.9377399773221008
Validation loss: 2.5660934653459657

Epoch: 6| Step: 4
Training loss: 1.1805864155544374
Validation loss: 2.5826178131090476

Epoch: 6| Step: 5
Training loss: 1.2376210471397302
Validation loss: 2.5856163544980664

Epoch: 6| Step: 6
Training loss: 0.5882399778845788
Validation loss: 2.628055634989767

Epoch: 6| Step: 7
Training loss: 1.528310952447376
Validation loss: 2.6307984507128337

Epoch: 6| Step: 8
Training loss: 1.19587833749619
Validation loss: 2.6542278721703987

Epoch: 6| Step: 9
Training loss: 0.9175652124268545
Validation loss: 2.607908281129318

Epoch: 6| Step: 10
Training loss: 1.1339361471603204
Validation loss: 2.6680046680526015

Epoch: 6| Step: 11
Training loss: 1.1414124370514316
Validation loss: 2.6202239258508664

Epoch: 6| Step: 12
Training loss: 0.4034462425058849
Validation loss: 2.590639959753008

Epoch: 6| Step: 13
Training loss: 1.240054380316554
Validation loss: 2.59971213222226

Epoch: 254| Step: 0
Training loss: 1.2793804578194166
Validation loss: 2.59728526851822

Epoch: 6| Step: 1
Training loss: 1.204923697149134
Validation loss: 2.538610922867781

Epoch: 6| Step: 2
Training loss: 0.9551171916936552
Validation loss: 2.5340561549069105

Epoch: 6| Step: 3
Training loss: 0.9516894677053457
Validation loss: 2.516082472908798

Epoch: 6| Step: 4
Training loss: 0.9948475241166344
Validation loss: 2.5375537847014513

Epoch: 6| Step: 5
Training loss: 0.8467810195070541
Validation loss: 2.5685576563674797

Epoch: 6| Step: 6
Training loss: 1.0021802856642412
Validation loss: 2.5529126291330075

Epoch: 6| Step: 7
Training loss: 0.9440947641859239
Validation loss: 2.5452156680846523

Epoch: 6| Step: 8
Training loss: 1.3653731159664133
Validation loss: 2.57000430754469

Epoch: 6| Step: 9
Training loss: 1.2661497182196717
Validation loss: 2.603685341602086

Epoch: 6| Step: 10
Training loss: 0.4929951897980359
Validation loss: 2.610294230479529

Epoch: 6| Step: 11
Training loss: 1.5467322697921912
Validation loss: 2.6476405525487143

Epoch: 6| Step: 12
Training loss: 1.1384823675788052
Validation loss: 2.639615924258884

Epoch: 6| Step: 13
Training loss: 1.2036690906020289
Validation loss: 2.590996405516857

Epoch: 255| Step: 0
Training loss: 1.245449700928311
Validation loss: 2.5387391940144646

Epoch: 6| Step: 1
Training loss: 0.9560516637923807
Validation loss: 2.5046813409192072

Epoch: 6| Step: 2
Training loss: 0.9621839115761042
Validation loss: 2.5189935663589367

Epoch: 6| Step: 3
Training loss: 1.3644334356469279
Validation loss: 2.502026788466183

Epoch: 6| Step: 4
Training loss: 0.9427590997560734
Validation loss: 2.490852495497425

Epoch: 6| Step: 5
Training loss: 1.3326882898158123
Validation loss: 2.5442822972576784

Epoch: 6| Step: 6
Training loss: 0.8248686917163929
Validation loss: 2.547718429094692

Epoch: 6| Step: 7
Training loss: 1.3774412331619885
Validation loss: 2.5823168115820754

Epoch: 6| Step: 8
Training loss: 1.3618168001663333
Validation loss: 2.634165335011239

Epoch: 6| Step: 9
Training loss: 1.195539066558667
Validation loss: 2.6551760080906144

Epoch: 6| Step: 10
Training loss: 0.6544379238855547
Validation loss: 2.6300334789856348

Epoch: 6| Step: 11
Training loss: 1.0569679754453034
Validation loss: 2.573227558248901

Epoch: 6| Step: 12
Training loss: 1.055985958345575
Validation loss: 2.5651718304791356

Epoch: 6| Step: 13
Training loss: 0.7706861785092809
Validation loss: 2.5646604529084223

Epoch: 256| Step: 0
Training loss: 0.9377100391339935
Validation loss: 2.5464240995592906

Epoch: 6| Step: 1
Training loss: 0.5670260228420411
Validation loss: 2.5372657748197573

Epoch: 6| Step: 2
Training loss: 0.8434661105074613
Validation loss: 2.548456089413236

Epoch: 6| Step: 3
Training loss: 1.2533557669850344
Validation loss: 2.5131388390057805

Epoch: 6| Step: 4
Training loss: 0.6418412456161782
Validation loss: 2.53985466626654

Epoch: 6| Step: 5
Training loss: 0.7068969851986588
Validation loss: 2.518565597344823

Epoch: 6| Step: 6
Training loss: 1.1422432694081321
Validation loss: 2.5253703199645607

Epoch: 6| Step: 7
Training loss: 1.161377748621824
Validation loss: 2.5596475269314665

Epoch: 6| Step: 8
Training loss: 1.183402873847983
Validation loss: 2.593276587904152

Epoch: 6| Step: 9
Training loss: 1.2576876750161676
Validation loss: 2.5709367862857384

Epoch: 6| Step: 10
Training loss: 1.3435201670130736
Validation loss: 2.549319052534633

Epoch: 6| Step: 11
Training loss: 1.045027283672826
Validation loss: 2.53842542709734

Epoch: 6| Step: 12
Training loss: 1.4768534378757197
Validation loss: 2.544551912978637

Epoch: 6| Step: 13
Training loss: 1.2484214351990686
Validation loss: 2.535836258326216

Epoch: 257| Step: 0
Training loss: 1.1503137326408814
Validation loss: 2.5320175224643573

Epoch: 6| Step: 1
Training loss: 0.9057170353070263
Validation loss: 2.571523499356201

Epoch: 6| Step: 2
Training loss: 0.8700852650481903
Validation loss: 2.5896674400115565

Epoch: 6| Step: 3
Training loss: 0.9614961442438618
Validation loss: 2.601523839580838

Epoch: 6| Step: 4
Training loss: 0.8249049290873606
Validation loss: 2.56376778809705

Epoch: 6| Step: 5
Training loss: 1.022582126201292
Validation loss: 2.6124816443274432

Epoch: 6| Step: 6
Training loss: 1.0651303438111464
Validation loss: 2.6154364149475193

Epoch: 6| Step: 7
Training loss: 1.024219709056926
Validation loss: 2.6057730805090493

Epoch: 6| Step: 8
Training loss: 1.1665568413585699
Validation loss: 2.614889777919779

Epoch: 6| Step: 9
Training loss: 1.1471797777215784
Validation loss: 2.5768477700828645

Epoch: 6| Step: 10
Training loss: 1.3626399677022503
Validation loss: 2.5775334449884157

Epoch: 6| Step: 11
Training loss: 0.7308367042144787
Validation loss: 2.5649431418687736

Epoch: 6| Step: 12
Training loss: 0.4577320789879222
Validation loss: 2.6048842495217297

Epoch: 6| Step: 13
Training loss: 1.8728073014636415
Validation loss: 2.565200432236509

Epoch: 258| Step: 0
Training loss: 1.0109952011032237
Validation loss: 2.6027934017633143

Epoch: 6| Step: 1
Training loss: 1.4940182305363776
Validation loss: 2.606411476235136

Epoch: 6| Step: 2
Training loss: 0.8879395538153813
Validation loss: 2.573712309655235

Epoch: 6| Step: 3
Training loss: 0.9546311469545121
Validation loss: 2.585863143624651

Epoch: 6| Step: 4
Training loss: 1.0809682864954904
Validation loss: 2.573408167485388

Epoch: 6| Step: 5
Training loss: 0.8149423570667386
Validation loss: 2.606921879052794

Epoch: 6| Step: 6
Training loss: 0.988454961776263
Validation loss: 2.58491759062419

Epoch: 6| Step: 7
Training loss: 0.8797495547372353
Validation loss: 2.5745516398144432

Epoch: 6| Step: 8
Training loss: 1.1966970565429456
Validation loss: 2.549731120403415

Epoch: 6| Step: 9
Training loss: 1.0462743829691126
Validation loss: 2.5718155766180657

Epoch: 6| Step: 10
Training loss: 1.0982001101014252
Validation loss: 2.5761688154534337

Epoch: 6| Step: 11
Training loss: 0.8104118878208137
Validation loss: 2.5808063682329325

Epoch: 6| Step: 12
Training loss: 1.2953413662150108
Validation loss: 2.5766226798012704

Epoch: 6| Step: 13
Training loss: 0.5249566480357886
Validation loss: 2.569433625617989

Epoch: 259| Step: 0
Training loss: 1.38780762810508
Validation loss: 2.5437595728151647

Epoch: 6| Step: 1
Training loss: 1.2637729987552402
Validation loss: 2.551953081160136

Epoch: 6| Step: 2
Training loss: 0.8661075775512668
Validation loss: 2.5502840427610494

Epoch: 6| Step: 3
Training loss: 1.3023863732240164
Validation loss: 2.5640504040019425

Epoch: 6| Step: 4
Training loss: 0.6016046831277797
Validation loss: 2.549190504689026

Epoch: 6| Step: 5
Training loss: 1.5309224459579
Validation loss: 2.545902421065986

Epoch: 6| Step: 6
Training loss: 1.135071915016093
Validation loss: 2.6049460903857433

Epoch: 6| Step: 7
Training loss: 0.4559027441163094
Validation loss: 2.580662602832264

Epoch: 6| Step: 8
Training loss: 1.1192322272448278
Validation loss: 2.5987525907989895

Epoch: 6| Step: 9
Training loss: 0.7344515334486316
Validation loss: 2.6325404753076818

Epoch: 6| Step: 10
Training loss: 0.4661905988228926
Validation loss: 2.559314870205011

Epoch: 6| Step: 11
Training loss: 1.1819002733196224
Validation loss: 2.5785350007430763

Epoch: 6| Step: 12
Training loss: 1.1103235407290282
Validation loss: 2.5554493905766194

Epoch: 6| Step: 13
Training loss: 0.5087370452356191
Validation loss: 2.5302203418813827

Epoch: 260| Step: 0
Training loss: 1.200496129949227
Validation loss: 2.5368520388986853

Epoch: 6| Step: 1
Training loss: 0.7933290912477359
Validation loss: 2.546044097431244

Epoch: 6| Step: 2
Training loss: 0.4367436956333847
Validation loss: 2.5492390041004214

Epoch: 6| Step: 3
Training loss: 1.190480056711004
Validation loss: 2.578678131181276

Epoch: 6| Step: 4
Training loss: 1.3101852077134162
Validation loss: 2.5720733307337684

Epoch: 6| Step: 5
Training loss: 1.0011584009758918
Validation loss: 2.577269282420884

Epoch: 6| Step: 6
Training loss: 0.8567573561763057
Validation loss: 2.579870842668009

Epoch: 6| Step: 7
Training loss: 1.394968685495988
Validation loss: 2.594084501534353

Epoch: 6| Step: 8
Training loss: 0.9008821813012116
Validation loss: 2.5996939874624134

Epoch: 6| Step: 9
Training loss: 1.0952307895106745
Validation loss: 2.5903582278695265

Epoch: 6| Step: 10
Training loss: 1.034702532678345
Validation loss: 2.5531746160769213

Epoch: 6| Step: 11
Training loss: 0.6143004580008408
Validation loss: 2.5571005094639827

Epoch: 6| Step: 12
Training loss: 0.8411096303292122
Validation loss: 2.5652947930879177

Epoch: 6| Step: 13
Training loss: 1.307557700800445
Validation loss: 2.5734188507595985

Epoch: 261| Step: 0
Training loss: 1.309752813561569
Validation loss: 2.560814497994328

Epoch: 6| Step: 1
Training loss: 1.17095814760246
Validation loss: 2.542866322531145

Epoch: 6| Step: 2
Training loss: 0.9586580735242825
Validation loss: 2.552968403925744

Epoch: 6| Step: 3
Training loss: 0.7546964467152143
Validation loss: 2.5508810727739784

Epoch: 6| Step: 4
Training loss: 0.6833942667225231
Validation loss: 2.511774472961805

Epoch: 6| Step: 5
Training loss: 0.759556837249291
Validation loss: 2.54453442873231

Epoch: 6| Step: 6
Training loss: 0.9370135952849729
Validation loss: 2.5690272357157826

Epoch: 6| Step: 7
Training loss: 0.9328538204990194
Validation loss: 2.5588872690303597

Epoch: 6| Step: 8
Training loss: 1.0152890163158526
Validation loss: 2.590353433827299

Epoch: 6| Step: 9
Training loss: 0.9345676976150395
Validation loss: 2.5867223438057314

Epoch: 6| Step: 10
Training loss: 1.4049405677280307
Validation loss: 2.5982727991901293

Epoch: 6| Step: 11
Training loss: 1.1557445968049442
Validation loss: 2.5939505705000334

Epoch: 6| Step: 12
Training loss: 0.9084491683583272
Validation loss: 2.6101506366052996

Epoch: 6| Step: 13
Training loss: 0.8446045186516518
Validation loss: 2.630385005105677

Epoch: 262| Step: 0
Training loss: 1.2430458222380507
Validation loss: 2.583532521854642

Epoch: 6| Step: 1
Training loss: 1.0007591941958145
Validation loss: 2.627107471561628

Epoch: 6| Step: 2
Training loss: 1.1096889427732146
Validation loss: 2.6076736056454046

Epoch: 6| Step: 3
Training loss: 0.8738021144141985
Validation loss: 2.6145677311537203

Epoch: 6| Step: 4
Training loss: 0.7066710170875848
Validation loss: 2.5755996074085172

Epoch: 6| Step: 5
Training loss: 1.0471185429385244
Validation loss: 2.5839532121033884

Epoch: 6| Step: 6
Training loss: 0.9839918813990803
Validation loss: 2.537284844943195

Epoch: 6| Step: 7
Training loss: 1.2066817286817646
Validation loss: 2.5262352721540244

Epoch: 6| Step: 8
Training loss: 1.0405966540075877
Validation loss: 2.528585716338854

Epoch: 6| Step: 9
Training loss: 0.9677567466120286
Validation loss: 2.517757233903269

Epoch: 6| Step: 10
Training loss: 0.547168326050102
Validation loss: 2.517801469234574

Epoch: 6| Step: 11
Training loss: 1.1499078381967989
Validation loss: 2.5291835756843697

Epoch: 6| Step: 12
Training loss: 1.1035626156684766
Validation loss: 2.5589289519778022

Epoch: 6| Step: 13
Training loss: 0.9027535304864364
Validation loss: 2.563663185651159

Epoch: 263| Step: 0
Training loss: 0.8442436469609707
Validation loss: 2.5507511809956096

Epoch: 6| Step: 1
Training loss: 0.933855155835086
Validation loss: 2.5325201704696747

Epoch: 6| Step: 2
Training loss: 1.1618314522907807
Validation loss: 2.536385507458948

Epoch: 6| Step: 3
Training loss: 0.700534924409144
Validation loss: 2.5260301713816182

Epoch: 6| Step: 4
Training loss: 1.2452434640317311
Validation loss: 2.501257551423448

Epoch: 6| Step: 5
Training loss: 1.253983777462978
Validation loss: 2.511866617523761

Epoch: 6| Step: 6
Training loss: 0.9216609641709835
Validation loss: 2.5770401099880855

Epoch: 6| Step: 7
Training loss: 0.9558739963873923
Validation loss: 2.535356922803883

Epoch: 6| Step: 8
Training loss: 0.7979601035649644
Validation loss: 2.564326711947124

Epoch: 6| Step: 9
Training loss: 0.9365303110898696
Validation loss: 2.5708847468623617

Epoch: 6| Step: 10
Training loss: 0.7180071184368628
Validation loss: 2.582661190642787

Epoch: 6| Step: 11
Training loss: 1.291293346641296
Validation loss: 2.59264324567326

Epoch: 6| Step: 12
Training loss: 0.8339772994659238
Validation loss: 2.5643529128014144

Epoch: 6| Step: 13
Training loss: 1.1946833332217606
Validation loss: 2.5618633977173992

Epoch: 264| Step: 0
Training loss: 0.6211141666919331
Validation loss: 2.54350654811929

Epoch: 6| Step: 1
Training loss: 1.0270674301267768
Validation loss: 2.5159913666758964

Epoch: 6| Step: 2
Training loss: 0.915267085403816
Validation loss: 2.515937039341827

Epoch: 6| Step: 3
Training loss: 1.081870883116225
Validation loss: 2.499362772053687

Epoch: 6| Step: 4
Training loss: 0.9631694521538341
Validation loss: 2.5430291382285137

Epoch: 6| Step: 5
Training loss: 1.2894821870955768
Validation loss: 2.5501751430796973

Epoch: 6| Step: 6
Training loss: 0.7329380911955389
Validation loss: 2.5517861798294845

Epoch: 6| Step: 7
Training loss: 0.9243569664940284
Validation loss: 2.5667155167137063

Epoch: 6| Step: 8
Training loss: 1.2332439794047394
Validation loss: 2.585573024063603

Epoch: 6| Step: 9
Training loss: 0.946777752959314
Validation loss: 2.5786985741876336

Epoch: 6| Step: 10
Training loss: 0.667976691661717
Validation loss: 2.568535586601933

Epoch: 6| Step: 11
Training loss: 1.0470300815782403
Validation loss: 2.575197313480528

Epoch: 6| Step: 12
Training loss: 1.2028207765860874
Validation loss: 2.57448928643578

Epoch: 6| Step: 13
Training loss: 1.4457574932571098
Validation loss: 2.575921531471968

Epoch: 265| Step: 0
Training loss: 1.3756038900208885
Validation loss: 2.5659167790565522

Epoch: 6| Step: 1
Training loss: 1.174139758998169
Validation loss: 2.5756575096499703

Epoch: 6| Step: 2
Training loss: 0.6730486576988801
Validation loss: 2.5871091445694563

Epoch: 6| Step: 3
Training loss: 1.1050552835055705
Validation loss: 2.5928584292584005

Epoch: 6| Step: 4
Training loss: 1.0517915314747823
Validation loss: 2.6037677332992533

Epoch: 6| Step: 5
Training loss: 0.9462948573577729
Validation loss: 2.589800174022164

Epoch: 6| Step: 6
Training loss: 0.9527862134330808
Validation loss: 2.599011819265974

Epoch: 6| Step: 7
Training loss: 0.7664723281294687
Validation loss: 2.595189741292979

Epoch: 6| Step: 8
Training loss: 1.1549335924684523
Validation loss: 2.5962151955843518

Epoch: 6| Step: 9
Training loss: 1.0031091516496553
Validation loss: 2.5908602537325516

Epoch: 6| Step: 10
Training loss: 0.8989476289844864
Validation loss: 2.5418099375273124

Epoch: 6| Step: 11
Training loss: 0.8590037497659536
Validation loss: 2.5425013807715304

Epoch: 6| Step: 12
Training loss: 0.68855917144162
Validation loss: 2.5012162264984727

Epoch: 6| Step: 13
Training loss: 0.8482308615592192
Validation loss: 2.533843526350038

Epoch: 266| Step: 0
Training loss: 1.0791559127998416
Validation loss: 2.5610630519491866

Epoch: 6| Step: 1
Training loss: 0.8684017855729099
Validation loss: 2.5422118671541565

Epoch: 6| Step: 2
Training loss: 0.7860822388866382
Validation loss: 2.536980832988954

Epoch: 6| Step: 3
Training loss: 0.9556330529441858
Validation loss: 2.528187855159293

Epoch: 6| Step: 4
Training loss: 1.2461685588707172
Validation loss: 2.5819468659513314

Epoch: 6| Step: 5
Training loss: 0.6424971880276072
Validation loss: 2.600390062818849

Epoch: 6| Step: 6
Training loss: 1.1669015761435804
Validation loss: 2.6087264537813417

Epoch: 6| Step: 7
Training loss: 0.7012640804774303
Validation loss: 2.646530792600586

Epoch: 6| Step: 8
Training loss: 0.9373542672374995
Validation loss: 2.5956593135588624

Epoch: 6| Step: 9
Training loss: 0.67249934441063
Validation loss: 2.622826410263297

Epoch: 6| Step: 10
Training loss: 1.0409879126089785
Validation loss: 2.6358769731544416

Epoch: 6| Step: 11
Training loss: 1.1422727519103197
Validation loss: 2.591386952371126

Epoch: 6| Step: 12
Training loss: 0.977006460363685
Validation loss: 2.605141766183708

Epoch: 6| Step: 13
Training loss: 0.9739024134339572
Validation loss: 2.600945961814588

Epoch: 267| Step: 0
Training loss: 0.753184274264066
Validation loss: 2.6020456525858804

Epoch: 6| Step: 1
Training loss: 0.6706335441564122
Validation loss: 2.6103678359374665

Epoch: 6| Step: 2
Training loss: 1.1003726999747825
Validation loss: 2.605342502729798

Epoch: 6| Step: 3
Training loss: 1.2192496718186638
Validation loss: 2.5781471447880753

Epoch: 6| Step: 4
Training loss: 0.8962828964516738
Validation loss: 2.574013244720722

Epoch: 6| Step: 5
Training loss: 0.7784927540897
Validation loss: 2.5934666106786572

Epoch: 6| Step: 6
Training loss: 1.091602888258359
Validation loss: 2.5556337630465

Epoch: 6| Step: 7
Training loss: 1.0744068327887437
Validation loss: 2.548651391757612

Epoch: 6| Step: 8
Training loss: 1.1570077423654324
Validation loss: 2.584362206877057

Epoch: 6| Step: 9
Training loss: 0.3900857636712104
Validation loss: 2.600755860069608

Epoch: 6| Step: 10
Training loss: 1.2044752396587692
Validation loss: 2.632747509005928

Epoch: 6| Step: 11
Training loss: 0.9786164313679528
Validation loss: 2.6170789651737802

Epoch: 6| Step: 12
Training loss: 0.9417085281002119
Validation loss: 2.61008366474531

Epoch: 6| Step: 13
Training loss: 0.2803199543381734
Validation loss: 2.6049195223136508

Epoch: 268| Step: 0
Training loss: 1.0422378436372648
Validation loss: 2.6052521577488488

Epoch: 6| Step: 1
Training loss: 1.0745581628209029
Validation loss: 2.5785592964734234

Epoch: 6| Step: 2
Training loss: 0.7990412719198315
Validation loss: 2.52538678774454

Epoch: 6| Step: 3
Training loss: 1.0052614082726952
Validation loss: 2.5117989133089194

Epoch: 6| Step: 4
Training loss: 0.9641497506053752
Validation loss: 2.495952633986894

Epoch: 6| Step: 5
Training loss: 1.2697399730763403
Validation loss: 2.5120450182083833

Epoch: 6| Step: 6
Training loss: 0.7133520435912802
Validation loss: 2.4880592537059143

Epoch: 6| Step: 7
Training loss: 0.912518166661689
Validation loss: 2.5268886481194275

Epoch: 6| Step: 8
Training loss: 1.1347033275108669
Validation loss: 2.52488989917409

Epoch: 6| Step: 9
Training loss: 0.6357652979340406
Validation loss: 2.551545966813529

Epoch: 6| Step: 10
Training loss: 0.8310709681636405
Validation loss: 2.6203719093675786

Epoch: 6| Step: 11
Training loss: 1.0153421448254056
Validation loss: 2.6508964700116073

Epoch: 6| Step: 12
Training loss: 1.046723995420527
Validation loss: 2.661576835389913

Epoch: 6| Step: 13
Training loss: 0.7167634462466443
Validation loss: 2.631524680343955

Epoch: 269| Step: 0
Training loss: 0.6073387800582049
Validation loss: 2.65872441759306

Epoch: 6| Step: 1
Training loss: 0.8746507833337871
Validation loss: 2.6039959278535436

Epoch: 6| Step: 2
Training loss: 0.7515542297542711
Validation loss: 2.6415198947355076

Epoch: 6| Step: 3
Training loss: 0.9047078790823554
Validation loss: 2.6058120635415563

Epoch: 6| Step: 4
Training loss: 1.0071136653963524
Validation loss: 2.5738697074608514

Epoch: 6| Step: 5
Training loss: 0.9869123786868119
Validation loss: 2.5584489207924697

Epoch: 6| Step: 6
Training loss: 0.5896907380565534
Validation loss: 2.557243805021756

Epoch: 6| Step: 7
Training loss: 1.032733197421127
Validation loss: 2.5386540152313004

Epoch: 6| Step: 8
Training loss: 1.1814767771217214
Validation loss: 2.5039472407824466

Epoch: 6| Step: 9
Training loss: 1.238456930219385
Validation loss: 2.4727564595073472

Epoch: 6| Step: 10
Training loss: 0.9692800363919908
Validation loss: 2.5122517342234905

Epoch: 6| Step: 11
Training loss: 1.144720276725992
Validation loss: 2.490982162795592

Epoch: 6| Step: 12
Training loss: 0.5787889946145013
Validation loss: 2.488731965363348

Epoch: 6| Step: 13
Training loss: 1.0101963209331057
Validation loss: 2.5099216695330178

Epoch: 270| Step: 0
Training loss: 0.6508160136487096
Validation loss: 2.5425624727959133

Epoch: 6| Step: 1
Training loss: 0.8900224420846916
Validation loss: 2.5922572068863934

Epoch: 6| Step: 2
Training loss: 1.426948132572792
Validation loss: 2.578415036908042

Epoch: 6| Step: 3
Training loss: 0.8184826742073409
Validation loss: 2.5957650181781586

Epoch: 6| Step: 4
Training loss: 1.2300439010321915
Validation loss: 2.5805289348711864

Epoch: 6| Step: 5
Training loss: 1.0835450527962411
Validation loss: 2.564151098429562

Epoch: 6| Step: 6
Training loss: 0.9745145763091935
Validation loss: 2.535963989472882

Epoch: 6| Step: 7
Training loss: 0.742100399327296
Validation loss: 2.567521957612064

Epoch: 6| Step: 8
Training loss: 0.6505197391139393
Validation loss: 2.559996267407014

Epoch: 6| Step: 9
Training loss: 1.0180880098314853
Validation loss: 2.541006848529607

Epoch: 6| Step: 10
Training loss: 0.9847393875228136
Validation loss: 2.522831305966269

Epoch: 6| Step: 11
Training loss: 0.8556157512736162
Validation loss: 2.5476025215985962

Epoch: 6| Step: 12
Training loss: 0.8614386662764059
Validation loss: 2.560147057329252

Epoch: 6| Step: 13
Training loss: 0.3506387336101647
Validation loss: 2.642322898516824

Epoch: 271| Step: 0
Training loss: 0.8175667358713306
Validation loss: 2.6413838159767242

Epoch: 6| Step: 1
Training loss: 0.9162175132956238
Validation loss: 2.6239969766109437

Epoch: 6| Step: 2
Training loss: 1.2390986010378158
Validation loss: 2.6225338490664605

Epoch: 6| Step: 3
Training loss: 0.8895686728336274
Validation loss: 2.5791495735033694

Epoch: 6| Step: 4
Training loss: 0.870035186911034
Validation loss: 2.5423433205669426

Epoch: 6| Step: 5
Training loss: 0.8873834009542628
Validation loss: 2.508928328447039

Epoch: 6| Step: 6
Training loss: 0.3586360549073836
Validation loss: 2.460062363136561

Epoch: 6| Step: 7
Training loss: 1.0375422779339483
Validation loss: 2.486565090284292

Epoch: 6| Step: 8
Training loss: 1.0648522984699629
Validation loss: 2.4548787847884492

Epoch: 6| Step: 9
Training loss: 1.0929187340570796
Validation loss: 2.4732436072007355

Epoch: 6| Step: 10
Training loss: 0.6541511031646162
Validation loss: 2.479681541837418

Epoch: 6| Step: 11
Training loss: 1.1329328801878522
Validation loss: 2.4767354527825804

Epoch: 6| Step: 12
Training loss: 1.0025176304054118
Validation loss: 2.5186902540827805

Epoch: 6| Step: 13
Training loss: 0.668987567987098
Validation loss: 2.5285845564788025

Epoch: 272| Step: 0
Training loss: 0.9398876303610387
Validation loss: 2.5603637314435033

Epoch: 6| Step: 1
Training loss: 0.7946122524864597
Validation loss: 2.57197560233332

Epoch: 6| Step: 2
Training loss: 0.8277766376703705
Validation loss: 2.6161051603949548

Epoch: 6| Step: 3
Training loss: 0.8976501995842248
Validation loss: 2.6056548941323103

Epoch: 6| Step: 4
Training loss: 1.018230324408742
Validation loss: 2.6519776723146955

Epoch: 6| Step: 5
Training loss: 1.0565670643583476
Validation loss: 2.5846145012006345

Epoch: 6| Step: 6
Training loss: 0.8621871021320991
Validation loss: 2.6002438791729827

Epoch: 6| Step: 7
Training loss: 1.1360942790104045
Validation loss: 2.5501871682133683

Epoch: 6| Step: 8
Training loss: 0.7943611135402047
Validation loss: 2.5584080356686134

Epoch: 6| Step: 9
Training loss: 0.9701068359215941
Validation loss: 2.488448956318256

Epoch: 6| Step: 10
Training loss: 0.7416521249552809
Validation loss: 2.4663073489907497

Epoch: 6| Step: 11
Training loss: 0.6337999716173998
Validation loss: 2.5139764759819454

Epoch: 6| Step: 12
Training loss: 0.6152595635964742
Validation loss: 2.484398841034081

Epoch: 6| Step: 13
Training loss: 1.5077851446170574
Validation loss: 2.4838335599480934

Epoch: 273| Step: 0
Training loss: 0.706187677587488
Validation loss: 2.5486332048568685

Epoch: 6| Step: 1
Training loss: 0.7439207217678331
Validation loss: 2.5541234781926185

Epoch: 6| Step: 2
Training loss: 0.9908326878931902
Validation loss: 2.567948485372047

Epoch: 6| Step: 3
Training loss: 0.3981124075270995
Validation loss: 2.566826118669711

Epoch: 6| Step: 4
Training loss: 1.5748858304499493
Validation loss: 2.555936352248621

Epoch: 6| Step: 5
Training loss: 0.9806345157392572
Validation loss: 2.5711247534381436

Epoch: 6| Step: 6
Training loss: 1.0166623026853194
Validation loss: 2.6062914803934656

Epoch: 6| Step: 7
Training loss: 1.1131431627799773
Validation loss: 2.557272021272044

Epoch: 6| Step: 8
Training loss: 0.9426820586250512
Validation loss: 2.5994100715472483

Epoch: 6| Step: 9
Training loss: 0.7577340783510847
Validation loss: 2.556314429572277

Epoch: 6| Step: 10
Training loss: 0.5904679437749425
Validation loss: 2.544235543790675

Epoch: 6| Step: 11
Training loss: 0.8856988494600264
Validation loss: 2.5274664259521904

Epoch: 6| Step: 12
Training loss: 0.6352578001027616
Validation loss: 2.5402950282115646

Epoch: 6| Step: 13
Training loss: 0.6078724554543223
Validation loss: 2.500074477778355

Epoch: 274| Step: 0
Training loss: 0.8314496725522316
Validation loss: 2.5543648187759045

Epoch: 6| Step: 1
Training loss: 0.8964147270590417
Validation loss: 2.5888535526325818

Epoch: 6| Step: 2
Training loss: 0.9262924070856513
Validation loss: 2.5513274375285584

Epoch: 6| Step: 3
Training loss: 0.608776777019275
Validation loss: 2.564024858957754

Epoch: 6| Step: 4
Training loss: 1.0166998823920548
Validation loss: 2.5712840175462723

Epoch: 6| Step: 5
Training loss: 0.5306215215148857
Validation loss: 2.554431662760731

Epoch: 6| Step: 6
Training loss: 0.7676333730290984
Validation loss: 2.557999258731417

Epoch: 6| Step: 7
Training loss: 1.2496470429877529
Validation loss: 2.5700728754230977

Epoch: 6| Step: 8
Training loss: 1.117563837860742
Validation loss: 2.5634932902660026

Epoch: 6| Step: 9
Training loss: 0.9132091418696382
Validation loss: 2.543325237748935

Epoch: 6| Step: 10
Training loss: 0.7166230201367799
Validation loss: 2.5500537515983464

Epoch: 6| Step: 11
Training loss: 0.8485561463522113
Validation loss: 2.55069930891876

Epoch: 6| Step: 12
Training loss: 0.9111323545726676
Validation loss: 2.5265916380198763

Epoch: 6| Step: 13
Training loss: 1.00749455840958
Validation loss: 2.52521019459431

Epoch: 275| Step: 0
Training loss: 0.8394081227917288
Validation loss: 2.539858389306948

Epoch: 6| Step: 1
Training loss: 0.8402787966936588
Validation loss: 2.5105435245693957

Epoch: 6| Step: 2
Training loss: 0.7620772080742766
Validation loss: 2.4930504075122877

Epoch: 6| Step: 3
Training loss: 0.7735193767944005
Validation loss: 2.5343972878940115

Epoch: 6| Step: 4
Training loss: 1.040329297183086
Validation loss: 2.4949618713561508

Epoch: 6| Step: 5
Training loss: 0.8093636574557962
Validation loss: 2.4647548941578514

Epoch: 6| Step: 6
Training loss: 1.0559962312024227
Validation loss: 2.4804816132898995

Epoch: 6| Step: 7
Training loss: 1.0951766382867525
Validation loss: 2.5061725151639833

Epoch: 6| Step: 8
Training loss: 1.2244349207876017
Validation loss: 2.462477907658752

Epoch: 6| Step: 9
Training loss: 0.6321850008497938
Validation loss: 2.5324813802957618

Epoch: 6| Step: 10
Training loss: 0.7061678425086811
Validation loss: 2.5600361417807154

Epoch: 6| Step: 11
Training loss: 0.8549787955973063
Validation loss: 2.558733574951858

Epoch: 6| Step: 12
Training loss: 0.719122582768224
Validation loss: 2.5889624513218177

Epoch: 6| Step: 13
Training loss: 1.2625868323652378
Validation loss: 2.6443215578457258

Epoch: 276| Step: 0
Training loss: 0.869443964797251
Validation loss: 2.6256871151849346

Epoch: 6| Step: 1
Training loss: 0.5884846319284089
Validation loss: 2.651492435513566

Epoch: 6| Step: 2
Training loss: 1.139675633646152
Validation loss: 2.6307058322965733

Epoch: 6| Step: 3
Training loss: 0.7734803852560742
Validation loss: 2.586705679290337

Epoch: 6| Step: 4
Training loss: 0.9733317224334642
Validation loss: 2.596195383250589

Epoch: 6| Step: 5
Training loss: 0.36006370149718875
Validation loss: 2.5846787090937244

Epoch: 6| Step: 6
Training loss: 0.7261173155974433
Validation loss: 2.529052457007827

Epoch: 6| Step: 7
Training loss: 0.9439982586658711
Validation loss: 2.5785806431612115

Epoch: 6| Step: 8
Training loss: 1.110151529536993
Validation loss: 2.534284718346153

Epoch: 6| Step: 9
Training loss: 1.1430110795793174
Validation loss: 2.568627399652323

Epoch: 6| Step: 10
Training loss: 0.9469131600524472
Validation loss: 2.56751744743645

Epoch: 6| Step: 11
Training loss: 0.6178749698127247
Validation loss: 2.553754448159732

Epoch: 6| Step: 12
Training loss: 1.0604517772885034
Validation loss: 2.55275230019484

Epoch: 6| Step: 13
Training loss: 0.6166556275728561
Validation loss: 2.508466798085655

Epoch: 277| Step: 0
Training loss: 0.8156867256046881
Validation loss: 2.5654264022904982

Epoch: 6| Step: 1
Training loss: 0.6466497111883295
Validation loss: 2.5550404232396167

Epoch: 6| Step: 2
Training loss: 0.9518610593960934
Validation loss: 2.5791497424811203

Epoch: 6| Step: 3
Training loss: 1.1461363073975483
Validation loss: 2.582492497685232

Epoch: 6| Step: 4
Training loss: 0.7301743265922926
Validation loss: 2.5634099288694836

Epoch: 6| Step: 5
Training loss: 0.534159965081313
Validation loss: 2.5742259502800353

Epoch: 6| Step: 6
Training loss: 0.8267688443182122
Validation loss: 2.572583408169711

Epoch: 6| Step: 7
Training loss: 1.058578040650418
Validation loss: 2.6245857572116438

Epoch: 6| Step: 8
Training loss: 1.0675365340795337
Validation loss: 2.5922334979273947

Epoch: 6| Step: 9
Training loss: 0.9692153428291629
Validation loss: 2.591000681881602

Epoch: 6| Step: 10
Training loss: 0.613197612526259
Validation loss: 2.548373656836496

Epoch: 6| Step: 11
Training loss: 0.9147657313905941
Validation loss: 2.5828105953033274

Epoch: 6| Step: 12
Training loss: 0.9689905421737323
Validation loss: 2.5560842223650946

Epoch: 6| Step: 13
Training loss: 0.6612055863822915
Validation loss: 2.587358024153546

Epoch: 278| Step: 0
Training loss: 0.6758528654926882
Validation loss: 2.5489246891211366

Epoch: 6| Step: 1
Training loss: 1.0054055384496847
Validation loss: 2.609066414475042

Epoch: 6| Step: 2
Training loss: 0.6162257366549454
Validation loss: 2.614770333914508

Epoch: 6| Step: 3
Training loss: 0.47270271766434974
Validation loss: 2.628049319663259

Epoch: 6| Step: 4
Training loss: 0.9495398837687729
Validation loss: 2.6264487496003945

Epoch: 6| Step: 5
Training loss: 0.5685244710448164
Validation loss: 2.625167523442705

Epoch: 6| Step: 6
Training loss: 0.8707488536164555
Validation loss: 2.6076220447346596

Epoch: 6| Step: 7
Training loss: 1.0736803959945063
Validation loss: 2.5518466798720834

Epoch: 6| Step: 8
Training loss: 0.6308045496309683
Validation loss: 2.5774332808384113

Epoch: 6| Step: 9
Training loss: 1.0510117515538524
Validation loss: 2.5305067070187794

Epoch: 6| Step: 10
Training loss: 0.9641633202064179
Validation loss: 2.4789702834988634

Epoch: 6| Step: 11
Training loss: 0.8723813791168876
Validation loss: 2.4796470396608097

Epoch: 6| Step: 12
Training loss: 0.9203815000408924
Validation loss: 2.4814844293646066

Epoch: 6| Step: 13
Training loss: 1.3216497657740747
Validation loss: 2.514950483934731

Epoch: 279| Step: 0
Training loss: 0.9782699611605311
Validation loss: 2.5200597589200955

Epoch: 6| Step: 1
Training loss: 0.9766862104259327
Validation loss: 2.539463862524216

Epoch: 6| Step: 2
Training loss: 0.8893219299459871
Validation loss: 2.524852436634975

Epoch: 6| Step: 3
Training loss: 0.6939695440474969
Validation loss: 2.5399009109165323

Epoch: 6| Step: 4
Training loss: 0.6947817115890252
Validation loss: 2.548143241312559

Epoch: 6| Step: 5
Training loss: 0.600244887365567
Validation loss: 2.5714217078311346

Epoch: 6| Step: 6
Training loss: 0.7872000138036602
Validation loss: 2.586993953978586

Epoch: 6| Step: 7
Training loss: 1.2434263948959448
Validation loss: 2.580747853371404

Epoch: 6| Step: 8
Training loss: 0.7886567536142465
Validation loss: 2.6647666371329533

Epoch: 6| Step: 9
Training loss: 0.7433669105424472
Validation loss: 2.59249732235889

Epoch: 6| Step: 10
Training loss: 0.6935601172184979
Validation loss: 2.6424783143437134

Epoch: 6| Step: 11
Training loss: 0.4919140676860253
Validation loss: 2.611246319399384

Epoch: 6| Step: 12
Training loss: 0.9021161275339862
Validation loss: 2.5962860004341337

Epoch: 6| Step: 13
Training loss: 1.2672142599833942
Validation loss: 2.602008927488855

Epoch: 280| Step: 0
Training loss: 0.887336045554344
Validation loss: 2.5488585194364446

Epoch: 6| Step: 1
Training loss: 0.9592977349794486
Validation loss: 2.6054563325714986

Epoch: 6| Step: 2
Training loss: 0.6037235087156764
Validation loss: 2.585569845256873

Epoch: 6| Step: 3
Training loss: 0.7107557965826191
Validation loss: 2.5493533690113366

Epoch: 6| Step: 4
Training loss: 0.6319067088471125
Validation loss: 2.578175153148146

Epoch: 6| Step: 5
Training loss: 1.0287325794325568
Validation loss: 2.5665039227715476

Epoch: 6| Step: 6
Training loss: 0.8531185597047395
Validation loss: 2.558355608123631

Epoch: 6| Step: 7
Training loss: 0.9273602504274571
Validation loss: 2.5922769741585276

Epoch: 6| Step: 8
Training loss: 0.8491058260492146
Validation loss: 2.586606964029783

Epoch: 6| Step: 9
Training loss: 0.9066861845877189
Validation loss: 2.562774993603508

Epoch: 6| Step: 10
Training loss: 0.490376820329705
Validation loss: 2.568003231793568

Epoch: 6| Step: 11
Training loss: 0.8871225118399282
Validation loss: 2.595696019851574

Epoch: 6| Step: 12
Training loss: 0.8719163782288869
Validation loss: 2.608653063420519

Epoch: 6| Step: 13
Training loss: 0.9634371245436381
Validation loss: 2.5829637231961686

Epoch: 281| Step: 0
Training loss: 1.2369515773975774
Validation loss: 2.57077787462495

Epoch: 6| Step: 1
Training loss: 0.3979488817459271
Validation loss: 2.593656380826083

Epoch: 6| Step: 2
Training loss: 0.45654243020418606
Validation loss: 2.596720181314057

Epoch: 6| Step: 3
Training loss: 0.6787428594533284
Validation loss: 2.5735757515088147

Epoch: 6| Step: 4
Training loss: 0.7320029726541329
Validation loss: 2.579949486573365

Epoch: 6| Step: 5
Training loss: 1.0861238827378599
Validation loss: 2.587882707877421

Epoch: 6| Step: 6
Training loss: 0.9209918301455031
Validation loss: 2.5780119034915656

Epoch: 6| Step: 7
Training loss: 0.8863022956430188
Validation loss: 2.5708690182586245

Epoch: 6| Step: 8
Training loss: 0.678261631504187
Validation loss: 2.571295614942911

Epoch: 6| Step: 9
Training loss: 0.6327211290492721
Validation loss: 2.5450593752891124

Epoch: 6| Step: 10
Training loss: 0.7294295563679158
Validation loss: 2.51500637483797

Epoch: 6| Step: 11
Training loss: 0.8446373688459884
Validation loss: 2.5371802121186415

Epoch: 6| Step: 12
Training loss: 1.0968751673684713
Validation loss: 2.5126850729975367

Epoch: 6| Step: 13
Training loss: 0.8277386897912109
Validation loss: 2.5095688348950755

Epoch: 282| Step: 0
Training loss: 0.9383097648258042
Validation loss: 2.5023672637480643

Epoch: 6| Step: 1
Training loss: 0.9701861841416118
Validation loss: 2.556173703552145

Epoch: 6| Step: 2
Training loss: 0.8109567364301941
Validation loss: 2.5563773275464383

Epoch: 6| Step: 3
Training loss: 0.7956628368817155
Validation loss: 2.5582335395692253

Epoch: 6| Step: 4
Training loss: 0.7799837531940871
Validation loss: 2.549839171377286

Epoch: 6| Step: 5
Training loss: 0.7565639474721784
Validation loss: 2.5778344232675323

Epoch: 6| Step: 6
Training loss: 1.0440962051664613
Validation loss: 2.5556298849312706

Epoch: 6| Step: 7
Training loss: 0.8155342446182441
Validation loss: 2.5605650949227665

Epoch: 6| Step: 8
Training loss: 0.7896811826428336
Validation loss: 2.561635555641755

Epoch: 6| Step: 9
Training loss: 0.579220069737625
Validation loss: 2.5657951394192473

Epoch: 6| Step: 10
Training loss: 1.0603177717118848
Validation loss: 2.6086036878812466

Epoch: 6| Step: 11
Training loss: 0.8337204669714658
Validation loss: 2.599506772494439

Epoch: 6| Step: 12
Training loss: 0.5208712627587155
Validation loss: 2.5806424803617354

Epoch: 6| Step: 13
Training loss: 0.4845389580874665
Validation loss: 2.5705409782051043

Epoch: 283| Step: 0
Training loss: 0.3208488300635058
Validation loss: 2.5891511455899368

Epoch: 6| Step: 1
Training loss: 0.8441461763283271
Validation loss: 2.580071535243573

Epoch: 6| Step: 2
Training loss: 1.1003781708976406
Validation loss: 2.5665103595743095

Epoch: 6| Step: 3
Training loss: 0.8871183797227269
Validation loss: 2.5533436606250874

Epoch: 6| Step: 4
Training loss: 0.6683004793652008
Validation loss: 2.551992001300355

Epoch: 6| Step: 5
Training loss: 0.6848890838483868
Validation loss: 2.564710261610634

Epoch: 6| Step: 6
Training loss: 0.8360951711677873
Validation loss: 2.5420798674062186

Epoch: 6| Step: 7
Training loss: 0.620836696572976
Validation loss: 2.5814134931304467

Epoch: 6| Step: 8
Training loss: 0.8620472714966566
Validation loss: 2.5929358210564772

Epoch: 6| Step: 9
Training loss: 0.376792359535643
Validation loss: 2.6060608263683824

Epoch: 6| Step: 10
Training loss: 1.1134183029674034
Validation loss: 2.625974324906975

Epoch: 6| Step: 11
Training loss: 0.9406590008847984
Validation loss: 2.643465887057951

Epoch: 6| Step: 12
Training loss: 1.0476699771308928
Validation loss: 2.656860630754199

Epoch: 6| Step: 13
Training loss: 0.788217828957345
Validation loss: 2.589171051431781

Epoch: 284| Step: 0
Training loss: 0.7403210108643393
Validation loss: 2.608179319646096

Epoch: 6| Step: 1
Training loss: 0.7693596275770926
Validation loss: 2.5643764581514925

Epoch: 6| Step: 2
Training loss: 0.8275179527386686
Validation loss: 2.508973860777503

Epoch: 6| Step: 3
Training loss: 0.8742153191520452
Validation loss: 2.5256216495207267

Epoch: 6| Step: 4
Training loss: 1.1337616725770778
Validation loss: 2.5436311335497552

Epoch: 6| Step: 5
Training loss: 0.4469159687709439
Validation loss: 2.5622141148614146

Epoch: 6| Step: 6
Training loss: 0.8290767958034353
Validation loss: 2.593382309076502

Epoch: 6| Step: 7
Training loss: 0.6967203481843648
Validation loss: 2.567763469589722

Epoch: 6| Step: 8
Training loss: 0.8774534977168406
Validation loss: 2.575541118582296

Epoch: 6| Step: 9
Training loss: 0.7163687942680729
Validation loss: 2.5891314403489227

Epoch: 6| Step: 10
Training loss: 0.7946821971480872
Validation loss: 2.5375441779277566

Epoch: 6| Step: 11
Training loss: 0.7632448997939406
Validation loss: 2.519209093816377

Epoch: 6| Step: 12
Training loss: 0.753089224887687
Validation loss: 2.522905155476488

Epoch: 6| Step: 13
Training loss: 1.2599822102153682
Validation loss: 2.5522401267215713

Epoch: 285| Step: 0
Training loss: 0.6425713999665899
Validation loss: 2.5099871569307646

Epoch: 6| Step: 1
Training loss: 0.9042129642452421
Validation loss: 2.511067960334476

Epoch: 6| Step: 2
Training loss: 1.1927557134865248
Validation loss: 2.5473098660437183

Epoch: 6| Step: 3
Training loss: 0.8651818804176397
Validation loss: 2.518802589285413

Epoch: 6| Step: 4
Training loss: 0.5751881364203119
Validation loss: 2.479927948810783

Epoch: 6| Step: 5
Training loss: 0.4820105772361592
Validation loss: 2.5235250423486297

Epoch: 6| Step: 6
Training loss: 0.8858688919978561
Validation loss: 2.5126951696614723

Epoch: 6| Step: 7
Training loss: 0.6173852289931527
Validation loss: 2.5508014582864105

Epoch: 6| Step: 8
Training loss: 0.8338194065286904
Validation loss: 2.543253568811476

Epoch: 6| Step: 9
Training loss: 0.8352606341482296
Validation loss: 2.5792431278323495

Epoch: 6| Step: 10
Training loss: 0.5949474857701338
Validation loss: 2.5972311906533787

Epoch: 6| Step: 11
Training loss: 1.0454801120006674
Validation loss: 2.5629856270732336

Epoch: 6| Step: 12
Training loss: 0.9064068165293848
Validation loss: 2.5892646575318863

Epoch: 6| Step: 13
Training loss: 0.13581457883522718
Validation loss: 2.6338333493057564

Epoch: 286| Step: 0
Training loss: 0.8785796512325308
Validation loss: 2.606407422857006

Epoch: 6| Step: 1
Training loss: 0.8119601510304676
Validation loss: 2.652958634965166

Epoch: 6| Step: 2
Training loss: 0.5761636507126221
Validation loss: 2.596906526070451

Epoch: 6| Step: 3
Training loss: 1.1365199488723792
Validation loss: 2.594935539985051

Epoch: 6| Step: 4
Training loss: 0.834344861918574
Validation loss: 2.632970023869051

Epoch: 6| Step: 5
Training loss: 0.4455810874607458
Validation loss: 2.6184248977940867

Epoch: 6| Step: 6
Training loss: 0.8668186674950016
Validation loss: 2.620981342668481

Epoch: 6| Step: 7
Training loss: 0.7626595189564334
Validation loss: 2.5596836098800813

Epoch: 6| Step: 8
Training loss: 0.5873065467655347
Validation loss: 2.5956274048847696

Epoch: 6| Step: 9
Training loss: 0.5167312315110211
Validation loss: 2.5475540931733636

Epoch: 6| Step: 10
Training loss: 0.7099574953439166
Validation loss: 2.5690678700148872

Epoch: 6| Step: 11
Training loss: 0.7651736038168847
Validation loss: 2.549043195639525

Epoch: 6| Step: 12
Training loss: 1.0940435832964333
Validation loss: 2.541773184795749

Epoch: 6| Step: 13
Training loss: 0.7772016155708119
Validation loss: 2.571634388986657

Epoch: 287| Step: 0
Training loss: 0.5856877112424358
Validation loss: 2.5662231989373803

Epoch: 6| Step: 1
Training loss: 0.9625901068582676
Validation loss: 2.55258414549069

Epoch: 6| Step: 2
Training loss: 0.964351265813626
Validation loss: 2.542548015890989

Epoch: 6| Step: 3
Training loss: 0.5272114340477104
Validation loss: 2.5200278268893372

Epoch: 6| Step: 4
Training loss: 0.9965327473574495
Validation loss: 2.540748905231603

Epoch: 6| Step: 5
Training loss: 0.615975118695024
Validation loss: 2.5179629444053364

Epoch: 6| Step: 6
Training loss: 0.9646525946537398
Validation loss: 2.5028226361238803

Epoch: 6| Step: 7
Training loss: 0.9168479407854511
Validation loss: 2.5432975401112454

Epoch: 6| Step: 8
Training loss: 0.7840251841660354
Validation loss: 2.5060755614576795

Epoch: 6| Step: 9
Training loss: 0.6448283579981063
Validation loss: 2.543763337003727

Epoch: 6| Step: 10
Training loss: 0.6422993481358501
Validation loss: 2.556067593296448

Epoch: 6| Step: 11
Training loss: 0.6814998492270825
Validation loss: 2.5499253197129113

Epoch: 6| Step: 12
Training loss: 0.8543188300710698
Validation loss: 2.567577677647049

Epoch: 6| Step: 13
Training loss: 0.6434216513773106
Validation loss: 2.587073611109558

Epoch: 288| Step: 0
Training loss: 0.7329029995278495
Validation loss: 2.5677707284058537

Epoch: 6| Step: 1
Training loss: 1.0573000163733604
Validation loss: 2.5412018073627247

Epoch: 6| Step: 2
Training loss: 0.7012060470542272
Validation loss: 2.5124008305662544

Epoch: 6| Step: 3
Training loss: 0.939776073628909
Validation loss: 2.5265083743653305

Epoch: 6| Step: 4
Training loss: 0.7074227697997646
Validation loss: 2.531912405668796

Epoch: 6| Step: 5
Training loss: 0.7895944898181187
Validation loss: 2.516190861843374

Epoch: 6| Step: 6
Training loss: 1.0794075234377667
Validation loss: 2.5127914088502186

Epoch: 6| Step: 7
Training loss: 0.690784972637494
Validation loss: 2.5336501595618386

Epoch: 6| Step: 8
Training loss: 0.7496371981181899
Validation loss: 2.5127270591816178

Epoch: 6| Step: 9
Training loss: 0.7171515229287247
Validation loss: 2.5303960788108566

Epoch: 6| Step: 10
Training loss: 0.47881231646925765
Validation loss: 2.493269229982791

Epoch: 6| Step: 11
Training loss: 0.5456267416053409
Validation loss: 2.51738448646413

Epoch: 6| Step: 12
Training loss: 0.9089535146080311
Validation loss: 2.4864873044835276

Epoch: 6| Step: 13
Training loss: 0.7736119545597735
Validation loss: 2.5246251486644806

Epoch: 289| Step: 0
Training loss: 0.688725852473771
Validation loss: 2.5110132768550923

Epoch: 6| Step: 1
Training loss: 0.8342608098674945
Validation loss: 2.488596171930996

Epoch: 6| Step: 2
Training loss: 0.7778667435021679
Validation loss: 2.523953529463612

Epoch: 6| Step: 3
Training loss: 0.6378061335543563
Validation loss: 2.5343582513080096

Epoch: 6| Step: 4
Training loss: 0.7979334365503422
Validation loss: 2.4825338872146046

Epoch: 6| Step: 5
Training loss: 0.4159144963667895
Validation loss: 2.5259016922807724

Epoch: 6| Step: 6
Training loss: 0.8081725124426461
Validation loss: 2.533372407259978

Epoch: 6| Step: 7
Training loss: 0.7934007642309087
Validation loss: 2.5543494059626184

Epoch: 6| Step: 8
Training loss: 1.0739360645450877
Validation loss: 2.6216878890494697

Epoch: 6| Step: 9
Training loss: 0.7447087879795987
Validation loss: 2.5868454712722295

Epoch: 6| Step: 10
Training loss: 1.0031037444242454
Validation loss: 2.6095674922848637

Epoch: 6| Step: 11
Training loss: 0.8630259554950206
Validation loss: 2.60879906476992

Epoch: 6| Step: 12
Training loss: 0.5477347291883511
Validation loss: 2.585777317160937

Epoch: 6| Step: 13
Training loss: 0.8580849414652428
Validation loss: 2.5411759539446392

Epoch: 290| Step: 0
Training loss: 0.6333078870764373
Validation loss: 2.5345748653630054

Epoch: 6| Step: 1
Training loss: 0.7980507049991459
Validation loss: 2.5082180331789377

Epoch: 6| Step: 2
Training loss: 0.385850065574329
Validation loss: 2.520763786439305

Epoch: 6| Step: 3
Training loss: 0.893991232374581
Validation loss: 2.5100715344477784

Epoch: 6| Step: 4
Training loss: 0.8806293466323999
Validation loss: 2.4798034886899396

Epoch: 6| Step: 5
Training loss: 0.8856317520691839
Validation loss: 2.5070127491644834

Epoch: 6| Step: 6
Training loss: 0.6371545294986751
Validation loss: 2.519170633963896

Epoch: 6| Step: 7
Training loss: 0.5703207041529176
Validation loss: 2.536266229591609

Epoch: 6| Step: 8
Training loss: 0.5134346708009659
Validation loss: 2.5362694833328043

Epoch: 6| Step: 9
Training loss: 0.9211013586556737
Validation loss: 2.552356390108478

Epoch: 6| Step: 10
Training loss: 0.9323367670896342
Validation loss: 2.570301237286427

Epoch: 6| Step: 11
Training loss: 0.8389935115249589
Validation loss: 2.590935924179967

Epoch: 6| Step: 12
Training loss: 1.030268924938281
Validation loss: 2.5875303000634364

Epoch: 6| Step: 13
Training loss: 0.9693422967939288
Validation loss: 2.595079660622858

Epoch: 291| Step: 0
Training loss: 0.8835886691189365
Validation loss: 2.5450864413207577

Epoch: 6| Step: 1
Training loss: 0.7606643813257995
Validation loss: 2.4948086274413748

Epoch: 6| Step: 2
Training loss: 0.8625204609088704
Validation loss: 2.4708902830519266

Epoch: 6| Step: 3
Training loss: 0.9133881257553517
Validation loss: 2.4515943008221996

Epoch: 6| Step: 4
Training loss: 0.5445083087921234
Validation loss: 2.4927931047294662

Epoch: 6| Step: 5
Training loss: 0.6788300553771942
Validation loss: 2.498488622571784

Epoch: 6| Step: 6
Training loss: 0.5007281068404856
Validation loss: 2.526212369891216

Epoch: 6| Step: 7
Training loss: 0.8260611241194898
Validation loss: 2.5117768163713015

Epoch: 6| Step: 8
Training loss: 1.2052225431342563
Validation loss: 2.5031631004513835

Epoch: 6| Step: 9
Training loss: 0.7825603939552384
Validation loss: 2.5130487313694045

Epoch: 6| Step: 10
Training loss: 0.4870048471979178
Validation loss: 2.519035995939952

Epoch: 6| Step: 11
Training loss: 0.7394101428131017
Validation loss: 2.51256396904466

Epoch: 6| Step: 12
Training loss: 0.4838900907612627
Validation loss: 2.547996790825645

Epoch: 6| Step: 13
Training loss: 0.7641394079152075
Validation loss: 2.5802326386368124

Epoch: 292| Step: 0
Training loss: 0.831320481431465
Validation loss: 2.5611168334590695

Epoch: 6| Step: 1
Training loss: 0.4074667535571019
Validation loss: 2.5336114210912988

Epoch: 6| Step: 2
Training loss: 0.7713049571335606
Validation loss: 2.542657471612679

Epoch: 6| Step: 3
Training loss: 0.7852717072730109
Validation loss: 2.5440617423353173

Epoch: 6| Step: 4
Training loss: 1.0305439236907885
Validation loss: 2.529834523215618

Epoch: 6| Step: 5
Training loss: 0.7850430155467263
Validation loss: 2.487221981479684

Epoch: 6| Step: 6
Training loss: 0.7225483994293911
Validation loss: 2.4749819871635004

Epoch: 6| Step: 7
Training loss: 0.959918218149165
Validation loss: 2.509852926150716

Epoch: 6| Step: 8
Training loss: 0.6451423291334888
Validation loss: 2.516164685213129

Epoch: 6| Step: 9
Training loss: 0.7310406083492237
Validation loss: 2.5521804104679164

Epoch: 6| Step: 10
Training loss: 0.445102140030851
Validation loss: 2.5473125269929775

Epoch: 6| Step: 11
Training loss: 0.7817258530057115
Validation loss: 2.578534857574858

Epoch: 6| Step: 12
Training loss: 0.8947530746279232
Validation loss: 2.5858441442473064

Epoch: 6| Step: 13
Training loss: 0.652765514605791
Validation loss: 2.585364797025459

Epoch: 293| Step: 0
Training loss: 0.5974237575728321
Validation loss: 2.5938511826366515

Epoch: 6| Step: 1
Training loss: 0.8767643578808294
Validation loss: 2.5372279372659183

Epoch: 6| Step: 2
Training loss: 0.4795544772273128
Validation loss: 2.5185783841358225

Epoch: 6| Step: 3
Training loss: 0.6741475771648189
Validation loss: 2.4974164595682407

Epoch: 6| Step: 4
Training loss: 0.8267424937306304
Validation loss: 2.5118782432855338

Epoch: 6| Step: 5
Training loss: 0.8435822779353573
Validation loss: 2.5435202436433673

Epoch: 6| Step: 6
Training loss: 0.8474608868600901
Validation loss: 2.495641883380915

Epoch: 6| Step: 7
Training loss: 0.7620422458852626
Validation loss: 2.5121200726491226

Epoch: 6| Step: 8
Training loss: 0.7037898840705974
Validation loss: 2.569776209600074

Epoch: 6| Step: 9
Training loss: 0.891559980076686
Validation loss: 2.5844087204916426

Epoch: 6| Step: 10
Training loss: 0.7984624646010992
Validation loss: 2.602562530312649

Epoch: 6| Step: 11
Training loss: 0.8459191872256642
Validation loss: 2.6137135556736797

Epoch: 6| Step: 12
Training loss: 0.7810441318112518
Validation loss: 2.6298249748213625

Epoch: 6| Step: 13
Training loss: 0.6209277524984564
Validation loss: 2.598922584901545

Epoch: 294| Step: 0
Training loss: 0.8228196839432962
Validation loss: 2.5534178103784795

Epoch: 6| Step: 1
Training loss: 0.3659792968569678
Validation loss: 2.5327664745645815

Epoch: 6| Step: 2
Training loss: 0.6131403086828608
Validation loss: 2.5410815630782437

Epoch: 6| Step: 3
Training loss: 1.000409519265882
Validation loss: 2.493789642888184

Epoch: 6| Step: 4
Training loss: 0.24821413963691907
Validation loss: 2.51067486446498

Epoch: 6| Step: 5
Training loss: 0.5592887129909426
Validation loss: 2.4981701501764575

Epoch: 6| Step: 6
Training loss: 1.0314515812688219
Validation loss: 2.4990191565951574

Epoch: 6| Step: 7
Training loss: 0.677049604211563
Validation loss: 2.5010054063800027

Epoch: 6| Step: 8
Training loss: 0.8824999095495248
Validation loss: 2.5199761492249464

Epoch: 6| Step: 9
Training loss: 0.615706731724954
Validation loss: 2.528669760166621

Epoch: 6| Step: 10
Training loss: 0.7968535700889742
Validation loss: 2.555369214146269

Epoch: 6| Step: 11
Training loss: 0.9409748529363803
Validation loss: 2.5297508302099607

Epoch: 6| Step: 12
Training loss: 0.5773208283247682
Validation loss: 2.5785402164353854

Epoch: 6| Step: 13
Training loss: 0.8104078426387358
Validation loss: 2.5942152021011116

Epoch: 295| Step: 0
Training loss: 0.6319389907778583
Validation loss: 2.5596239400842538

Epoch: 6| Step: 1
Training loss: 0.6344807146807445
Validation loss: 2.5409172287307795

Epoch: 6| Step: 2
Training loss: 0.8773862453098192
Validation loss: 2.5419719828035188

Epoch: 6| Step: 3
Training loss: 0.29387828785149495
Validation loss: 2.5449572006918166

Epoch: 6| Step: 4
Training loss: 1.025758397587935
Validation loss: 2.520457530012482

Epoch: 6| Step: 5
Training loss: 0.4462920341142349
Validation loss: 2.51810777890412

Epoch: 6| Step: 6
Training loss: 0.9946097295801077
Validation loss: 2.5245066088930215

Epoch: 6| Step: 7
Training loss: 0.5078304287606532
Validation loss: 2.52994450870855

Epoch: 6| Step: 8
Training loss: 0.6364791044684478
Validation loss: 2.4770071527779036

Epoch: 6| Step: 9
Training loss: 0.7551425028204196
Validation loss: 2.4950976779559424

Epoch: 6| Step: 10
Training loss: 0.5995590735593765
Validation loss: 2.4865728990417466

Epoch: 6| Step: 11
Training loss: 0.7609086644155004
Validation loss: 2.4895966276731283

Epoch: 6| Step: 12
Training loss: 0.8535118539408254
Validation loss: 2.5037877941704596

Epoch: 6| Step: 13
Training loss: 0.9773527686223645
Validation loss: 2.5343997590815595

Epoch: 296| Step: 0
Training loss: 1.0777060759072314
Validation loss: 2.5559169172687204

Epoch: 6| Step: 1
Training loss: 0.7829890921893796
Validation loss: 2.530739055491541

Epoch: 6| Step: 2
Training loss: 0.7627057454547118
Validation loss: 2.5244800117491075

Epoch: 6| Step: 3
Training loss: 0.4685497173953687
Validation loss: 2.5729371498039537

Epoch: 6| Step: 4
Training loss: 0.4879772155252151
Validation loss: 2.54863602586939

Epoch: 6| Step: 5
Training loss: 0.6211198285463908
Validation loss: 2.5574068506706538

Epoch: 6| Step: 6
Training loss: 0.8245010254195981
Validation loss: 2.556237433381307

Epoch: 6| Step: 7
Training loss: 0.6921401573851452
Validation loss: 2.563820679428113

Epoch: 6| Step: 8
Training loss: 0.43051205328993514
Validation loss: 2.5446024527970805

Epoch: 6| Step: 9
Training loss: 0.7121377810589594
Validation loss: 2.538229219751793

Epoch: 6| Step: 10
Training loss: 0.6672775306081705
Validation loss: 2.4981383057323994

Epoch: 6| Step: 11
Training loss: 0.7729078849300453
Validation loss: 2.547977561411822

Epoch: 6| Step: 12
Training loss: 0.9618314291223998
Validation loss: 2.507590173784751

Epoch: 6| Step: 13
Training loss: 0.35112995453364343
Validation loss: 2.4991061684184164

Epoch: 297| Step: 0
Training loss: 0.6040592646228488
Validation loss: 2.5125387729262507

Epoch: 6| Step: 1
Training loss: 0.8497895499169791
Validation loss: 2.501359446901269

Epoch: 6| Step: 2
Training loss: 0.5426840275784403
Validation loss: 2.5230469831525304

Epoch: 6| Step: 3
Training loss: 0.7608479535249988
Validation loss: 2.555642154240504

Epoch: 6| Step: 4
Training loss: 0.669223766428342
Validation loss: 2.5356272358177905

Epoch: 6| Step: 5
Training loss: 0.46606896120012326
Validation loss: 2.554784448746

Epoch: 6| Step: 6
Training loss: 0.4992388803306762
Validation loss: 2.5802764228891713

Epoch: 6| Step: 7
Training loss: 0.7766107141275865
Validation loss: 2.5657203321963906

Epoch: 6| Step: 8
Training loss: 0.9602478157501286
Validation loss: 2.5450195301822442

Epoch: 6| Step: 9
Training loss: 0.6421122151818023
Validation loss: 2.557680776117153

Epoch: 6| Step: 10
Training loss: 0.7888880999617893
Validation loss: 2.5825128519284637

Epoch: 6| Step: 11
Training loss: 0.7182159927926707
Validation loss: 2.5294338645172743

Epoch: 6| Step: 12
Training loss: 0.8906531747745027
Validation loss: 2.5542349074364528

Epoch: 6| Step: 13
Training loss: 0.7125426815031606
Validation loss: 2.4932893661369815

Epoch: 298| Step: 0
Training loss: 0.5417407578145145
Validation loss: 2.5192181660347845

Epoch: 6| Step: 1
Training loss: 0.5088955992818913
Validation loss: 2.4956612931374837

Epoch: 6| Step: 2
Training loss: 0.9974102221746692
Validation loss: 2.4914663601480624

Epoch: 6| Step: 3
Training loss: 0.9444301680501863
Validation loss: 2.5359715915322028

Epoch: 6| Step: 4
Training loss: 0.6905521354384297
Validation loss: 2.5071182411921265

Epoch: 6| Step: 5
Training loss: 0.7654801056442591
Validation loss: 2.517282037922841

Epoch: 6| Step: 6
Training loss: 0.7107257737342401
Validation loss: 2.537612351995967

Epoch: 6| Step: 7
Training loss: 0.541585161116901
Validation loss: 2.561764645355571

Epoch: 6| Step: 8
Training loss: 0.9164194221558065
Validation loss: 2.556573703898749

Epoch: 6| Step: 9
Training loss: 0.6161163305816916
Validation loss: 2.514363178210303

Epoch: 6| Step: 10
Training loss: 0.8228892591395026
Validation loss: 2.522435594287316

Epoch: 6| Step: 11
Training loss: 0.5742553647363267
Validation loss: 2.4941029030856017

Epoch: 6| Step: 12
Training loss: 0.49896329453881433
Validation loss: 2.551104794503454

Epoch: 6| Step: 13
Training loss: 0.3816220789515498
Validation loss: 2.504302850351897

Epoch: 299| Step: 0
Training loss: 0.9390504731536351
Validation loss: 2.519354647334061

Epoch: 6| Step: 1
Training loss: 0.40528568111447205
Validation loss: 2.5367469769074176

Epoch: 6| Step: 2
Training loss: 0.519434525513535
Validation loss: 2.5128773801293947

Epoch: 6| Step: 3
Training loss: 0.677690883857056
Validation loss: 2.5263490497259524

Epoch: 6| Step: 4
Training loss: 0.6117248710238387
Validation loss: 2.5468573625946487

Epoch: 6| Step: 5
Training loss: 0.6747037202017017
Validation loss: 2.514766652918337

Epoch: 6| Step: 6
Training loss: 0.9133656771935699
Validation loss: 2.504523450859197

Epoch: 6| Step: 7
Training loss: 0.3016630968498238
Validation loss: 2.5398279169414124

Epoch: 6| Step: 8
Training loss: 1.0170552087125235
Validation loss: 2.518498053876585

Epoch: 6| Step: 9
Training loss: 0.7446328284988913
Validation loss: 2.5769653755161714

Epoch: 6| Step: 10
Training loss: 0.8099151723501006
Validation loss: 2.5079728488863235

Epoch: 6| Step: 11
Training loss: 0.4379879920643816
Validation loss: 2.510947287348916

Epoch: 6| Step: 12
Training loss: 0.8159924786445447
Validation loss: 2.5189066206826194

Epoch: 6| Step: 13
Training loss: 0.7468890599798829
Validation loss: 2.525383889496141

Epoch: 300| Step: 0
Training loss: 0.8571490503269069
Validation loss: 2.4978794959460107

Epoch: 6| Step: 1
Training loss: 0.7079561622458665
Validation loss: 2.506982060094375

Epoch: 6| Step: 2
Training loss: 0.3141416819947663
Validation loss: 2.4899114892862015

Epoch: 6| Step: 3
Training loss: 0.4963068316752898
Validation loss: 2.511644938009584

Epoch: 6| Step: 4
Training loss: 0.5476380066275057
Validation loss: 2.5264662945275633

Epoch: 6| Step: 5
Training loss: 0.4635892979299149
Validation loss: 2.5156454448395267

Epoch: 6| Step: 6
Training loss: 0.7812826912715861
Validation loss: 2.556960526530541

Epoch: 6| Step: 7
Training loss: 0.654908239074095
Validation loss: 2.552388322464618

Epoch: 6| Step: 8
Training loss: 1.027742257807509
Validation loss: 2.5783248818911115

Epoch: 6| Step: 9
Training loss: 1.0426345461188973
Validation loss: 2.57392411728517

Epoch: 6| Step: 10
Training loss: 0.49302589822802145
Validation loss: 2.554489822017596

Epoch: 6| Step: 11
Training loss: 0.7772412256461524
Validation loss: 2.5454347132614186

Epoch: 6| Step: 12
Training loss: 0.7740920408708276
Validation loss: 2.5228735033381144

Epoch: 6| Step: 13
Training loss: 0.25354206670281837
Validation loss: 2.509828794736263

Epoch: 301| Step: 0
Training loss: 0.7162009108200184
Validation loss: 2.501869343645152

Epoch: 6| Step: 1
Training loss: 0.767735899417816
Validation loss: 2.5233553504099806

Epoch: 6| Step: 2
Training loss: 0.6907561958634307
Validation loss: 2.4674083033253225

Epoch: 6| Step: 3
Training loss: 0.7286995663211936
Validation loss: 2.488074156013171

Epoch: 6| Step: 4
Training loss: 0.7227443332087099
Validation loss: 2.502480984762742

Epoch: 6| Step: 5
Training loss: 0.6930857588630123
Validation loss: 2.496897548497898

Epoch: 6| Step: 6
Training loss: 0.5743722256416006
Validation loss: 2.458660820000684

Epoch: 6| Step: 7
Training loss: 0.9803221391587619
Validation loss: 2.511673770629958

Epoch: 6| Step: 8
Training loss: 0.28043270570156603
Validation loss: 2.4966461752998823

Epoch: 6| Step: 9
Training loss: 0.4682081269433533
Validation loss: 2.5552191094487133

Epoch: 6| Step: 10
Training loss: 0.6866944752504959
Validation loss: 2.524082851200628

Epoch: 6| Step: 11
Training loss: 0.8321275968690188
Validation loss: 2.564756917719785

Epoch: 6| Step: 12
Training loss: 0.8038195401093929
Validation loss: 2.5605727721214295

Epoch: 6| Step: 13
Training loss: 0.574700341716457
Validation loss: 2.5435825992748904

Epoch: 302| Step: 0
Training loss: 0.46857581081058697
Validation loss: 2.5597402316515203

Epoch: 6| Step: 1
Training loss: 0.9045167000780374
Validation loss: 2.5931371149322526

Epoch: 6| Step: 2
Training loss: 0.9643316724714351
Validation loss: 2.5269308330292137

Epoch: 6| Step: 3
Training loss: 0.6336525180716349
Validation loss: 2.489205569151582

Epoch: 6| Step: 4
Training loss: 0.9979785515080069
Validation loss: 2.5023128567944486

Epoch: 6| Step: 5
Training loss: 0.8086283211067133
Validation loss: 2.529280888791231

Epoch: 6| Step: 6
Training loss: 0.3306609093323649
Validation loss: 2.505326352935964

Epoch: 6| Step: 7
Training loss: 0.826636794560622
Validation loss: 2.5021484382786774

Epoch: 6| Step: 8
Training loss: 0.4380643134322466
Validation loss: 2.5441466231773657

Epoch: 6| Step: 9
Training loss: 0.5034574535732301
Validation loss: 2.5100885336008565

Epoch: 6| Step: 10
Training loss: 0.3272886971950689
Validation loss: 2.546649785253496

Epoch: 6| Step: 11
Training loss: 0.7140376648037713
Validation loss: 2.565275058745304

Epoch: 6| Step: 12
Training loss: 0.8506058034755827
Validation loss: 2.5544246495586886

Epoch: 6| Step: 13
Training loss: 0.3302151773547755
Validation loss: 2.532712651807148

Epoch: 303| Step: 0
Training loss: 0.6166216997127498
Validation loss: 2.5756377551715035

Epoch: 6| Step: 1
Training loss: 0.7531519065894088
Validation loss: 2.60694179720274

Epoch: 6| Step: 2
Training loss: 1.0390865925455208
Validation loss: 2.549082563498922

Epoch: 6| Step: 3
Training loss: 0.6592017728143413
Validation loss: 2.5509031867426115

Epoch: 6| Step: 4
Training loss: 0.722392142207794
Validation loss: 2.593821177053933

Epoch: 6| Step: 5
Training loss: 0.8766198151425726
Validation loss: 2.6115141243901605

Epoch: 6| Step: 6
Training loss: 0.5646692146165343
Validation loss: 2.6145214398198897

Epoch: 6| Step: 7
Training loss: 0.6967275343737067
Validation loss: 2.623975828420106

Epoch: 6| Step: 8
Training loss: 0.6482406915025037
Validation loss: 2.594160429743709

Epoch: 6| Step: 9
Training loss: 0.6126132412762504
Validation loss: 2.576861994761971

Epoch: 6| Step: 10
Training loss: 0.48597253875501645
Validation loss: 2.5623671154319445

Epoch: 6| Step: 11
Training loss: 0.6197352877921464
Validation loss: 2.49495460775736

Epoch: 6| Step: 12
Training loss: 0.4767431010750798
Validation loss: 2.5572346210894352

Epoch: 6| Step: 13
Training loss: 0.6859056017851448
Validation loss: 2.5180736413594307

Epoch: 304| Step: 0
Training loss: 0.4795921672064897
Validation loss: 2.5334526311874908

Epoch: 6| Step: 1
Training loss: 0.6772748725128646
Validation loss: 2.527251250695016

Epoch: 6| Step: 2
Training loss: 0.3712993855172581
Validation loss: 2.571046945404859

Epoch: 6| Step: 3
Training loss: 0.7233098141923531
Validation loss: 2.5513383413766886

Epoch: 6| Step: 4
Training loss: 0.5861332629925663
Validation loss: 2.5355487793077267

Epoch: 6| Step: 5
Training loss: 0.887498823353162
Validation loss: 2.561559885341575

Epoch: 6| Step: 6
Training loss: 0.8297567306342117
Validation loss: 2.5614795929157617

Epoch: 6| Step: 7
Training loss: 0.854127991583861
Validation loss: 2.56148569705403

Epoch: 6| Step: 8
Training loss: 0.7295138803956446
Validation loss: 2.5658585843145882

Epoch: 6| Step: 9
Training loss: 0.7785806065077177
Validation loss: 2.562114869716101

Epoch: 6| Step: 10
Training loss: 0.7355607382449949
Validation loss: 2.5910369089975123

Epoch: 6| Step: 11
Training loss: 0.42618926211237723
Validation loss: 2.5619671155214534

Epoch: 6| Step: 12
Training loss: 0.6067390651872803
Validation loss: 2.6212994987592473

Epoch: 6| Step: 13
Training loss: 0.6519997426366005
Validation loss: 2.622221824802855

Epoch: 305| Step: 0
Training loss: 0.6915555458736228
Validation loss: 2.5984323903098683

Epoch: 6| Step: 1
Training loss: 0.39451676521527806
Validation loss: 2.5668515419536377

Epoch: 6| Step: 2
Training loss: 0.6208747621662136
Validation loss: 2.5724543570916967

Epoch: 6| Step: 3
Training loss: 0.9203288156199791
Validation loss: 2.547529302494919

Epoch: 6| Step: 4
Training loss: 0.4192915155115505
Validation loss: 2.5278096175807567

Epoch: 6| Step: 5
Training loss: 0.762939570312491
Validation loss: 2.5309167437723215

Epoch: 6| Step: 6
Training loss: 0.727143250394892
Validation loss: 2.5007919051988314

Epoch: 6| Step: 7
Training loss: 0.4497452345866507
Validation loss: 2.52337112220084

Epoch: 6| Step: 8
Training loss: 0.567854745749275
Validation loss: 2.524655070869358

Epoch: 6| Step: 9
Training loss: 0.6483208424983806
Validation loss: 2.5081569744406855

Epoch: 6| Step: 10
Training loss: 0.9039158852738741
Validation loss: 2.521244761622769

Epoch: 6| Step: 11
Training loss: 0.8336354939699293
Validation loss: 2.5090417847812305

Epoch: 6| Step: 12
Training loss: 0.6365219701449818
Validation loss: 2.5017296847395403

Epoch: 6| Step: 13
Training loss: 0.6273985139309348
Validation loss: 2.5218491285234474

Epoch: 306| Step: 0
Training loss: 0.5461279807870535
Validation loss: 2.5783907398183623

Epoch: 6| Step: 1
Training loss: 0.4170250086855083
Validation loss: 2.5347287372979808

Epoch: 6| Step: 2
Training loss: 0.5037607382110232
Validation loss: 2.5553285205279583

Epoch: 6| Step: 3
Training loss: 0.6804953192200237
Validation loss: 2.5314483666130716

Epoch: 6| Step: 4
Training loss: 1.0003346836784763
Validation loss: 2.551538914532786

Epoch: 6| Step: 5
Training loss: 0.351032896620927
Validation loss: 2.5390522375916986

Epoch: 6| Step: 6
Training loss: 0.5076300366585548
Validation loss: 2.5374861768524544

Epoch: 6| Step: 7
Training loss: 0.733157874018288
Validation loss: 2.510780385395073

Epoch: 6| Step: 8
Training loss: 0.6046631406466052
Validation loss: 2.5073684009352477

Epoch: 6| Step: 9
Training loss: 0.9725043856171321
Validation loss: 2.5227979396065265

Epoch: 6| Step: 10
Training loss: 0.3712554177938926
Validation loss: 2.5290710285038442

Epoch: 6| Step: 11
Training loss: 0.702144150594854
Validation loss: 2.5135929341220624

Epoch: 6| Step: 12
Training loss: 1.014117133927375
Validation loss: 2.538277190803448

Epoch: 6| Step: 13
Training loss: 0.2725936129087632
Validation loss: 2.5007702574025874

Epoch: 307| Step: 0
Training loss: 0.6266972385044348
Validation loss: 2.4903035405249527

Epoch: 6| Step: 1
Training loss: 0.6317822582430987
Validation loss: 2.467455989910913

Epoch: 6| Step: 2
Training loss: 0.7700331547027249
Validation loss: 2.507670231894714

Epoch: 6| Step: 3
Training loss: 0.5119795680570015
Validation loss: 2.439210323759472

Epoch: 6| Step: 4
Training loss: 0.605906518987153
Validation loss: 2.505411527457614

Epoch: 6| Step: 5
Training loss: 1.051238914004917
Validation loss: 2.5048200338651134

Epoch: 6| Step: 6
Training loss: 0.6012386094122683
Validation loss: 2.5300737192776532

Epoch: 6| Step: 7
Training loss: 0.6036222789558512
Validation loss: 2.5421172555761187

Epoch: 6| Step: 8
Training loss: 0.4692143365663221
Validation loss: 2.541041305510718

Epoch: 6| Step: 9
Training loss: 0.6733575034367255
Validation loss: 2.5714273462115194

Epoch: 6| Step: 10
Training loss: 0.5845006746413854
Validation loss: 2.6000719432800543

Epoch: 6| Step: 11
Training loss: 0.5178940870232907
Validation loss: 2.5569190641562476

Epoch: 6| Step: 12
Training loss: 0.749460821256366
Validation loss: 2.535786128141094

Epoch: 6| Step: 13
Training loss: 0.8552793528301519
Validation loss: 2.5274255995467763

Epoch: 308| Step: 0
Training loss: 0.507367276373751
Validation loss: 2.514240001590658

Epoch: 6| Step: 1
Training loss: 0.7410344050575958
Validation loss: 2.4632978462845636

Epoch: 6| Step: 2
Training loss: 0.700086257933305
Validation loss: 2.4456770902052725

Epoch: 6| Step: 3
Training loss: 0.5098393412524208
Validation loss: 2.4774646202259807

Epoch: 6| Step: 4
Training loss: 0.4647164691445563
Validation loss: 2.449042255521366

Epoch: 6| Step: 5
Training loss: 0.6833243138795775
Validation loss: 2.475618081360371

Epoch: 6| Step: 6
Training loss: 0.6695721884177599
Validation loss: 2.463046144119544

Epoch: 6| Step: 7
Training loss: 0.7381709182888414
Validation loss: 2.488362260562465

Epoch: 6| Step: 8
Training loss: 0.665970518313091
Validation loss: 2.535527237162745

Epoch: 6| Step: 9
Training loss: 0.6966905546503817
Validation loss: 2.527532057200751

Epoch: 6| Step: 10
Training loss: 0.3374441648144094
Validation loss: 2.5445391962591257

Epoch: 6| Step: 11
Training loss: 1.0651343169604521
Validation loss: 2.54283671191221

Epoch: 6| Step: 12
Training loss: 0.6844701326345215
Validation loss: 2.53750307721555

Epoch: 6| Step: 13
Training loss: 0.40086736441757753
Validation loss: 2.583987371221767

Epoch: 309| Step: 0
Training loss: 0.7875555775724675
Validation loss: 2.5331662570098046

Epoch: 6| Step: 1
Training loss: 0.33351326223837974
Validation loss: 2.5332548232804166

Epoch: 6| Step: 2
Training loss: 0.4074779621846755
Validation loss: 2.507750151484699

Epoch: 6| Step: 3
Training loss: 0.7005625550468043
Validation loss: 2.5020661307050545

Epoch: 6| Step: 4
Training loss: 0.7689233692963406
Validation loss: 2.514294762227876

Epoch: 6| Step: 5
Training loss: 0.9038238276800622
Validation loss: 2.455333375382931

Epoch: 6| Step: 6
Training loss: 0.5952067824483589
Validation loss: 2.5283448038097807

Epoch: 6| Step: 7
Training loss: 0.46379194753696207
Validation loss: 2.508913055450686

Epoch: 6| Step: 8
Training loss: 0.6247433612344061
Validation loss: 2.4447520462742536

Epoch: 6| Step: 9
Training loss: 0.4431068945065728
Validation loss: 2.4817345662207666

Epoch: 6| Step: 10
Training loss: 0.8678581462609861
Validation loss: 2.4920693358354242

Epoch: 6| Step: 11
Training loss: 0.644380632777343
Validation loss: 2.4591122626036523

Epoch: 6| Step: 12
Training loss: 0.6462393581613582
Validation loss: 2.4449963292346126

Epoch: 6| Step: 13
Training loss: 0.657906666446743
Validation loss: 2.496534501034549

Epoch: 310| Step: 0
Training loss: 0.450902387715234
Validation loss: 2.5185936473792014

Epoch: 6| Step: 1
Training loss: 0.6279504751795791
Validation loss: 2.5345108012229964

Epoch: 6| Step: 2
Training loss: 0.4143252528724366
Validation loss: 2.517467448009268

Epoch: 6| Step: 3
Training loss: 0.7548678891383479
Validation loss: 2.5462653938333273

Epoch: 6| Step: 4
Training loss: 0.8888290769268986
Validation loss: 2.533168467282695

Epoch: 6| Step: 5
Training loss: 0.5628207404906445
Validation loss: 2.5406773785445744

Epoch: 6| Step: 6
Training loss: 0.7600887758706807
Validation loss: 2.5115010164562706

Epoch: 6| Step: 7
Training loss: 0.7337926625419076
Validation loss: 2.5364989591001006

Epoch: 6| Step: 8
Training loss: 0.6724614755238894
Validation loss: 2.5346386052336993

Epoch: 6| Step: 9
Training loss: 0.5501022753122884
Validation loss: 2.4701612682586993

Epoch: 6| Step: 10
Training loss: 0.8299957234490767
Validation loss: 2.530081396791346

Epoch: 6| Step: 11
Training loss: 0.564133259781041
Validation loss: 2.5140017086784905

Epoch: 6| Step: 12
Training loss: 0.514933382373658
Validation loss: 2.525225105067479

Epoch: 6| Step: 13
Training loss: 0.4391416844815156
Validation loss: 2.492070679342894

Epoch: 311| Step: 0
Training loss: 0.38415670864345025
Validation loss: 2.5199805674737155

Epoch: 6| Step: 1
Training loss: 0.6397622043687271
Validation loss: 2.534773687841387

Epoch: 6| Step: 2
Training loss: 0.42825599114391044
Validation loss: 2.548028027246193

Epoch: 6| Step: 3
Training loss: 0.7489404744303513
Validation loss: 2.524289717872379

Epoch: 6| Step: 4
Training loss: 0.663847495783313
Validation loss: 2.5896323331856004

Epoch: 6| Step: 5
Training loss: 0.7990132982295606
Validation loss: 2.553595111255989

Epoch: 6| Step: 6
Training loss: 0.824966886607222
Validation loss: 2.612080858539712

Epoch: 6| Step: 7
Training loss: 0.7281995808793736
Validation loss: 2.5665227956233068

Epoch: 6| Step: 8
Training loss: 0.39529450869424027
Validation loss: 2.537950155410937

Epoch: 6| Step: 9
Training loss: 0.2648561232835707
Validation loss: 2.4845396350937508

Epoch: 6| Step: 10
Training loss: 0.7832318155641574
Validation loss: 2.542049878013581

Epoch: 6| Step: 11
Training loss: 0.7014356451743357
Validation loss: 2.476142340172166

Epoch: 6| Step: 12
Training loss: 0.43745480031449135
Validation loss: 2.47363820947888

Epoch: 6| Step: 13
Training loss: 0.8870744705892255
Validation loss: 2.466683732444619

Epoch: 312| Step: 0
Training loss: 0.5093423832941094
Validation loss: 2.4866044946695296

Epoch: 6| Step: 1
Training loss: 0.2937377627847166
Validation loss: 2.5005593627766607

Epoch: 6| Step: 2
Training loss: 0.5051675137680857
Validation loss: 2.455096664004332

Epoch: 6| Step: 3
Training loss: 0.7410144570622468
Validation loss: 2.49339158210353

Epoch: 6| Step: 4
Training loss: 0.8363455730045347
Validation loss: 2.51664917365323

Epoch: 6| Step: 5
Training loss: 0.49929930345985973
Validation loss: 2.497059754312711

Epoch: 6| Step: 6
Training loss: 0.6982984826929268
Validation loss: 2.4996249296976925

Epoch: 6| Step: 7
Training loss: 0.5869945908838238
Validation loss: 2.4748153582017496

Epoch: 6| Step: 8
Training loss: 0.8282951324168808
Validation loss: 2.51084782914491

Epoch: 6| Step: 9
Training loss: 0.30355460506993287
Validation loss: 2.515067909459185

Epoch: 6| Step: 10
Training loss: 0.635556148374647
Validation loss: 2.488428146892537

Epoch: 6| Step: 11
Training loss: 0.911176772452381
Validation loss: 2.4977856961271874

Epoch: 6| Step: 12
Training loss: 0.5366360052256729
Validation loss: 2.4977217311945474

Epoch: 6| Step: 13
Training loss: 0.6873705265199973
Validation loss: 2.4803314065023945

Epoch: 313| Step: 0
Training loss: 0.5857097182984659
Validation loss: 2.5076686452540646

Epoch: 6| Step: 1
Training loss: 0.7066185099534658
Validation loss: 2.510850426633427

Epoch: 6| Step: 2
Training loss: 0.6448947228412025
Validation loss: 2.464982432767686

Epoch: 6| Step: 3
Training loss: 0.4635877872053999
Validation loss: 2.48121089799622

Epoch: 6| Step: 4
Training loss: 0.5849377813834805
Validation loss: 2.5006121952345506

Epoch: 6| Step: 5
Training loss: 0.7412857600909085
Validation loss: 2.483038233783939

Epoch: 6| Step: 6
Training loss: 0.3621817943330937
Validation loss: 2.5170769388900402

Epoch: 6| Step: 7
Training loss: 0.5562033022877512
Validation loss: 2.4931803748889863

Epoch: 6| Step: 8
Training loss: 0.649552661762153
Validation loss: 2.5405662951322747

Epoch: 6| Step: 9
Training loss: 0.811962316573535
Validation loss: 2.5212602995318347

Epoch: 6| Step: 10
Training loss: 0.7878234501780921
Validation loss: 2.526694974323772

Epoch: 6| Step: 11
Training loss: 0.3803903675215581
Validation loss: 2.537271771506956

Epoch: 6| Step: 12
Training loss: 0.8700854705612824
Validation loss: 2.540297220171552

Epoch: 6| Step: 13
Training loss: 0.21965144250840246
Validation loss: 2.519741570089697

Epoch: 314| Step: 0
Training loss: 0.5395055691517342
Validation loss: 2.56009269266787

Epoch: 6| Step: 1
Training loss: 0.6484071655531717
Validation loss: 2.5501658381889816

Epoch: 6| Step: 2
Training loss: 0.23413397793885668
Validation loss: 2.5288543191101263

Epoch: 6| Step: 3
Training loss: 0.6284079858421205
Validation loss: 2.5345414776054507

Epoch: 6| Step: 4
Training loss: 0.6373716645932499
Validation loss: 2.5119153839219885

Epoch: 6| Step: 5
Training loss: 0.3429868311015316
Validation loss: 2.466905534400865

Epoch: 6| Step: 6
Training loss: 0.5051068338376323
Validation loss: 2.515684558813287

Epoch: 6| Step: 7
Training loss: 0.6889169136964565
Validation loss: 2.4794461189405235

Epoch: 6| Step: 8
Training loss: 0.9568947208099056
Validation loss: 2.5002515317655094

Epoch: 6| Step: 9
Training loss: 0.6929556947529867
Validation loss: 2.512068589493741

Epoch: 6| Step: 10
Training loss: 0.8831526177063914
Validation loss: 2.4838126643760976

Epoch: 6| Step: 11
Training loss: 0.43568452447562755
Validation loss: 2.4713588879535187

Epoch: 6| Step: 12
Training loss: 0.7115327208816784
Validation loss: 2.512935501342456

Epoch: 6| Step: 13
Training loss: 0.3542400966517214
Validation loss: 2.5214427034178204

Epoch: 315| Step: 0
Training loss: 0.7746020325867223
Validation loss: 2.5821297713509836

Epoch: 6| Step: 1
Training loss: 0.39704166202036084
Validation loss: 2.599377367642937

Epoch: 6| Step: 2
Training loss: 0.5668171148807395
Validation loss: 2.6068879614500338

Epoch: 6| Step: 3
Training loss: 0.8287088027771969
Validation loss: 2.574980678898037

Epoch: 6| Step: 4
Training loss: 0.8296389147080269
Validation loss: 2.536337468284443

Epoch: 6| Step: 5
Training loss: 0.6828630738548028
Validation loss: 2.524371885294567

Epoch: 6| Step: 6
Training loss: 0.29444123569775443
Validation loss: 2.5365141882887396

Epoch: 6| Step: 7
Training loss: 0.7361082360873268
Validation loss: 2.5082468397786055

Epoch: 6| Step: 8
Training loss: 0.7369843248022799
Validation loss: 2.5007529293942814

Epoch: 6| Step: 9
Training loss: 0.47713389302281706
Validation loss: 2.4759752897166685

Epoch: 6| Step: 10
Training loss: 0.6092338398514795
Validation loss: 2.497841052527748

Epoch: 6| Step: 11
Training loss: 0.6346272948732448
Validation loss: 2.4632733482982214

Epoch: 6| Step: 12
Training loss: 0.4050435528767025
Validation loss: 2.478069781102634

Epoch: 6| Step: 13
Training loss: 0.6073070307162752
Validation loss: 2.5256058978742173

Epoch: 316| Step: 0
Training loss: 0.6016814869704739
Validation loss: 2.5290350470567815

Epoch: 6| Step: 1
Training loss: 0.4748770818280614
Validation loss: 2.5493740511904788

Epoch: 6| Step: 2
Training loss: 0.6014598412049431
Validation loss: 2.566009172609457

Epoch: 6| Step: 3
Training loss: 0.7619937498131684
Validation loss: 2.573691252295973

Epoch: 6| Step: 4
Training loss: 0.7798493609095667
Validation loss: 2.5604304909077387

Epoch: 6| Step: 5
Training loss: 0.579076525193569
Validation loss: 2.5895851639808214

Epoch: 6| Step: 6
Training loss: 0.7357389080884904
Validation loss: 2.603854846292824

Epoch: 6| Step: 7
Training loss: 0.7186948920975392
Validation loss: 2.589083058215855

Epoch: 6| Step: 8
Training loss: 0.5006622161081166
Validation loss: 2.579272868655155

Epoch: 6| Step: 9
Training loss: 0.4670341399464893
Validation loss: 2.5199259405684966

Epoch: 6| Step: 10
Training loss: 0.7472066916853293
Validation loss: 2.5332332444240016

Epoch: 6| Step: 11
Training loss: 0.4525889810780908
Validation loss: 2.497409103536058

Epoch: 6| Step: 12
Training loss: 0.5828676550490544
Validation loss: 2.4769285513845674

Epoch: 6| Step: 13
Training loss: 0.6244009007608098
Validation loss: 2.4272647254533024

Epoch: 317| Step: 0
Training loss: 0.6491343878367078
Validation loss: 2.4371691211812965

Epoch: 6| Step: 1
Training loss: 0.9161207061554526
Validation loss: 2.4751397429958915

Epoch: 6| Step: 2
Training loss: 0.373862986598329
Validation loss: 2.4680706089874027

Epoch: 6| Step: 3
Training loss: 0.7179541950597673
Validation loss: 2.538691264007297

Epoch: 6| Step: 4
Training loss: 0.6384180713746495
Validation loss: 2.561552559385077

Epoch: 6| Step: 5
Training loss: 0.6258675276468502
Validation loss: 2.5707351133168648

Epoch: 6| Step: 6
Training loss: 0.45143387358411863
Validation loss: 2.563899130218182

Epoch: 6| Step: 7
Training loss: 0.7803321405703383
Validation loss: 2.589166600750721

Epoch: 6| Step: 8
Training loss: 0.4736648076842193
Validation loss: 2.5244878118874365

Epoch: 6| Step: 9
Training loss: 0.4471245089137127
Validation loss: 2.557683270915757

Epoch: 6| Step: 10
Training loss: 0.39697034771800505
Validation loss: 2.5473452557370235

Epoch: 6| Step: 11
Training loss: 0.6155025805830604
Validation loss: 2.549184143324882

Epoch: 6| Step: 12
Training loss: 0.8593558569423286
Validation loss: 2.5617314528514803

Epoch: 6| Step: 13
Training loss: 0.6175562324479988
Validation loss: 2.511318777073323

Epoch: 318| Step: 0
Training loss: 0.6322166557584673
Validation loss: 2.4899471938857145

Epoch: 6| Step: 1
Training loss: 0.5985570862807964
Validation loss: 2.475499855346266

Epoch: 6| Step: 2
Training loss: 0.7057113129068886
Validation loss: 2.5062657581597336

Epoch: 6| Step: 3
Training loss: 0.38612267765990477
Validation loss: 2.4715758900565334

Epoch: 6| Step: 4
Training loss: 0.6405470265642925
Validation loss: 2.5411674816899286

Epoch: 6| Step: 5
Training loss: 0.6289386148595458
Validation loss: 2.5603652098327876

Epoch: 6| Step: 6
Training loss: 0.3877659500304549
Validation loss: 2.527122723098838

Epoch: 6| Step: 7
Training loss: 0.6671424573573003
Validation loss: 2.5077946788486996

Epoch: 6| Step: 8
Training loss: 0.5659160202558938
Validation loss: 2.508973748700075

Epoch: 6| Step: 9
Training loss: 0.6217340971075204
Validation loss: 2.4923123661977957

Epoch: 6| Step: 10
Training loss: 0.6119064179596501
Validation loss: 2.4886095731857303

Epoch: 6| Step: 11
Training loss: 0.526209820099197
Validation loss: 2.494988639317898

Epoch: 6| Step: 12
Training loss: 0.7797268706569978
Validation loss: 2.473204874133975

Epoch: 6| Step: 13
Training loss: 0.7190786108063113
Validation loss: 2.5309911849041

Epoch: 319| Step: 0
Training loss: 0.6799170665446017
Validation loss: 2.5061183529590676

Epoch: 6| Step: 1
Training loss: 0.4226418519167805
Validation loss: 2.5389965145349507

Epoch: 6| Step: 2
Training loss: 0.6202087815291332
Validation loss: 2.506168996791604

Epoch: 6| Step: 3
Training loss: 0.6270341672242492
Validation loss: 2.5298053290732585

Epoch: 6| Step: 4
Training loss: 0.3991339337752578
Validation loss: 2.525829787777717

Epoch: 6| Step: 5
Training loss: 0.5319930658067809
Validation loss: 2.5243078044304283

Epoch: 6| Step: 6
Training loss: 0.3391863065128898
Validation loss: 2.5522952683433155

Epoch: 6| Step: 7
Training loss: 0.4889711008191533
Validation loss: 2.5114845709325633

Epoch: 6| Step: 8
Training loss: 0.9751491236964964
Validation loss: 2.488826201168155

Epoch: 6| Step: 9
Training loss: 0.21192606878768266
Validation loss: 2.484244513133835

Epoch: 6| Step: 10
Training loss: 0.6740079777950089
Validation loss: 2.470027782419614

Epoch: 6| Step: 11
Training loss: 0.8746048852652808
Validation loss: 2.460823893232062

Epoch: 6| Step: 12
Training loss: 0.5740437403122712
Validation loss: 2.4653755200579335

Epoch: 6| Step: 13
Training loss: 0.6095192567319653
Validation loss: 2.445373646569452

Epoch: 320| Step: 0
Training loss: 0.6990556153669085
Validation loss: 2.4165473821208794

Epoch: 6| Step: 1
Training loss: 0.8592325959561545
Validation loss: 2.4401564519868093

Epoch: 6| Step: 2
Training loss: 0.6059559000574907
Validation loss: 2.4600899560699716

Epoch: 6| Step: 3
Training loss: 0.6513339467410176
Validation loss: 2.460172079903916

Epoch: 6| Step: 4
Training loss: 0.5273649423367591
Validation loss: 2.4649996887837835

Epoch: 6| Step: 5
Training loss: 0.6217660444265563
Validation loss: 2.435165188398532

Epoch: 6| Step: 6
Training loss: 0.6396127472449978
Validation loss: 2.4678465588250558

Epoch: 6| Step: 7
Training loss: 0.574799172948217
Validation loss: 2.449230667898823

Epoch: 6| Step: 8
Training loss: 0.4864252598592571
Validation loss: 2.436975772460645

Epoch: 6| Step: 9
Training loss: 0.5045699251295556
Validation loss: 2.455901433447417

Epoch: 6| Step: 10
Training loss: 0.44301358152521053
Validation loss: 2.4908461925328207

Epoch: 6| Step: 11
Training loss: 0.5615034016890847
Validation loss: 2.470692674111413

Epoch: 6| Step: 12
Training loss: 0.4751925084618914
Validation loss: 2.4727531019766036

Epoch: 6| Step: 13
Training loss: 0.4518887657822924
Validation loss: 2.4620267640790945

Epoch: 321| Step: 0
Training loss: 0.638676541279303
Validation loss: 2.478557812476913

Epoch: 6| Step: 1
Training loss: 0.5976123669040494
Validation loss: 2.4844506494003658

Epoch: 6| Step: 2
Training loss: 0.41033640946558164
Validation loss: 2.4651182207877436

Epoch: 6| Step: 3
Training loss: 0.5420252609471883
Validation loss: 2.4719291561083976

Epoch: 6| Step: 4
Training loss: 0.5412903786942135
Validation loss: 2.440912953145793

Epoch: 6| Step: 5
Training loss: 0.4106561067199341
Validation loss: 2.496160085963854

Epoch: 6| Step: 6
Training loss: 0.5908457853012148
Validation loss: 2.5002912915661692

Epoch: 6| Step: 7
Training loss: 0.5769831490113795
Validation loss: 2.4963969497881178

Epoch: 6| Step: 8
Training loss: 0.6621302598568248
Validation loss: 2.4932171843115727

Epoch: 6| Step: 9
Training loss: 0.4778907276731552
Validation loss: 2.521436826679031

Epoch: 6| Step: 10
Training loss: 0.6354217424867441
Validation loss: 2.468381664981169

Epoch: 6| Step: 11
Training loss: 0.490285574378548
Validation loss: 2.4963293816001513

Epoch: 6| Step: 12
Training loss: 0.8274308300209061
Validation loss: 2.4656242540395983

Epoch: 6| Step: 13
Training loss: 0.810589083756047
Validation loss: 2.5184478585059873

Epoch: 322| Step: 0
Training loss: 0.6223974879627233
Validation loss: 2.4687204376066516

Epoch: 6| Step: 1
Training loss: 0.6341935852050568
Validation loss: 2.4666355996086438

Epoch: 6| Step: 2
Training loss: 0.6102729441554025
Validation loss: 2.462598921581281

Epoch: 6| Step: 3
Training loss: 0.8148687386270005
Validation loss: 2.4476264437715276

Epoch: 6| Step: 4
Training loss: 0.5803180031625907
Validation loss: 2.480966078530696

Epoch: 6| Step: 5
Training loss: 0.4766634380819224
Validation loss: 2.4560890680879686

Epoch: 6| Step: 6
Training loss: 0.2143033600819237
Validation loss: 2.4506541727574107

Epoch: 6| Step: 7
Training loss: 0.6201882148976133
Validation loss: 2.4739010532313137

Epoch: 6| Step: 8
Training loss: 0.29382983502613325
Validation loss: 2.4765094867732285

Epoch: 6| Step: 9
Training loss: 0.7540797691090952
Validation loss: 2.501777302241968

Epoch: 6| Step: 10
Training loss: 0.6914278447286419
Validation loss: 2.513812600055835

Epoch: 6| Step: 11
Training loss: 0.6802130673191685
Validation loss: 2.4607995435542196

Epoch: 6| Step: 12
Training loss: 0.5138383312815409
Validation loss: 2.523261384092517

Epoch: 6| Step: 13
Training loss: 0.46935747837729985
Validation loss: 2.492248561153662

Epoch: 323| Step: 0
Training loss: 0.625145704451717
Validation loss: 2.4961617466768637

Epoch: 6| Step: 1
Training loss: 0.5975593039478334
Validation loss: 2.5020756277921463

Epoch: 6| Step: 2
Training loss: 0.5109128940268566
Validation loss: 2.5103670923029506

Epoch: 6| Step: 3
Training loss: 0.6168547590465622
Validation loss: 2.4782728760938144

Epoch: 6| Step: 4
Training loss: 0.5185334799357709
Validation loss: 2.4958595988858088

Epoch: 6| Step: 5
Training loss: 0.789224891193115
Validation loss: 2.4925850125492945

Epoch: 6| Step: 6
Training loss: 0.6327948391180661
Validation loss: 2.500933168434589

Epoch: 6| Step: 7
Training loss: 0.5722967666641289
Validation loss: 2.477580582645428

Epoch: 6| Step: 8
Training loss: 0.33383218744485676
Validation loss: 2.482997895197176

Epoch: 6| Step: 9
Training loss: 0.42429540514142644
Validation loss: 2.5395388657555533

Epoch: 6| Step: 10
Training loss: 0.7621195985547287
Validation loss: 2.5311247666650893

Epoch: 6| Step: 11
Training loss: 0.7270951318375625
Validation loss: 2.561714544203589

Epoch: 6| Step: 12
Training loss: 0.5469949863141301
Validation loss: 2.6045460329092256

Epoch: 6| Step: 13
Training loss: 0.2943416977124464
Validation loss: 2.583545517981716

Epoch: 324| Step: 0
Training loss: 0.5995229602883851
Validation loss: 2.559385182883051

Epoch: 6| Step: 1
Training loss: 0.6359267194054405
Validation loss: 2.5632734634566137

Epoch: 6| Step: 2
Training loss: 0.5866626067544879
Validation loss: 2.5104273650885554

Epoch: 6| Step: 3
Training loss: 0.7184219026137649
Validation loss: 2.4948989304246396

Epoch: 6| Step: 4
Training loss: 0.4044503551828214
Validation loss: 2.4977093610922005

Epoch: 6| Step: 5
Training loss: 0.5161605134859386
Validation loss: 2.48507442833088

Epoch: 6| Step: 6
Training loss: 0.534865947979319
Validation loss: 2.5068419732315728

Epoch: 6| Step: 7
Training loss: 0.15510469540526595
Validation loss: 2.473895013816018

Epoch: 6| Step: 8
Training loss: 0.5411008912247816
Validation loss: 2.474408908263506

Epoch: 6| Step: 9
Training loss: 0.1439055741218658
Validation loss: 2.442199284213044

Epoch: 6| Step: 10
Training loss: 1.0061800843585254
Validation loss: 2.459505689783179

Epoch: 6| Step: 11
Training loss: 0.6776015841419951
Validation loss: 2.4546886597274336

Epoch: 6| Step: 12
Training loss: 0.6303884679644182
Validation loss: 2.4662206623073017

Epoch: 6| Step: 13
Training loss: 0.3723985520732667
Validation loss: 2.4428984414145427

Epoch: 325| Step: 0
Training loss: 0.9093698534213592
Validation loss: 2.4496487870951116

Epoch: 6| Step: 1
Training loss: 0.5273909371068581
Validation loss: 2.4613254671669815

Epoch: 6| Step: 2
Training loss: 0.5357476190005898
Validation loss: 2.5173345616776652

Epoch: 6| Step: 3
Training loss: 0.6260103642090177
Validation loss: 2.4752259386561186

Epoch: 6| Step: 4
Training loss: 0.5973257010903984
Validation loss: 2.488193990481626

Epoch: 6| Step: 5
Training loss: 0.7116267039032195
Validation loss: 2.465733806238363

Epoch: 6| Step: 6
Training loss: 0.4312826545072757
Validation loss: 2.4869414323391124

Epoch: 6| Step: 7
Training loss: 0.44349560766184637
Validation loss: 2.4619304273118825

Epoch: 6| Step: 8
Training loss: 0.4542350654834311
Validation loss: 2.5052101152814634

Epoch: 6| Step: 9
Training loss: 0.7035686788512143
Validation loss: 2.520192323030121

Epoch: 6| Step: 10
Training loss: 0.23006145403944714
Validation loss: 2.5313985475385783

Epoch: 6| Step: 11
Training loss: 0.6491866782078454
Validation loss: 2.483970247435912

Epoch: 6| Step: 12
Training loss: 0.44744772722982307
Validation loss: 2.5476714136610905

Epoch: 6| Step: 13
Training loss: 0.6560712525484457
Validation loss: 2.544326848280347

Epoch: 326| Step: 0
Training loss: 0.5561738315681286
Validation loss: 2.4983861000278678

Epoch: 6| Step: 1
Training loss: 0.4729163660000869
Validation loss: 2.4876227072531045

Epoch: 6| Step: 2
Training loss: 0.35043518735647416
Validation loss: 2.5192389969050737

Epoch: 6| Step: 3
Training loss: 0.6998205525428196
Validation loss: 2.5047767212267766

Epoch: 6| Step: 4
Training loss: 0.6455845866521261
Validation loss: 2.497863145480466

Epoch: 6| Step: 5
Training loss: 0.690940570798595
Validation loss: 2.4623402223190554

Epoch: 6| Step: 6
Training loss: 0.7830683337729673
Validation loss: 2.4742054225323686

Epoch: 6| Step: 7
Training loss: 0.5350417132916665
Validation loss: 2.4857968511600137

Epoch: 6| Step: 8
Training loss: 0.5401884013906292
Validation loss: 2.498521433206818

Epoch: 6| Step: 9
Training loss: 0.6208180949455283
Validation loss: 2.536707399417557

Epoch: 6| Step: 10
Training loss: 0.4016332371078075
Validation loss: 2.510954111606362

Epoch: 6| Step: 11
Training loss: 0.5549282303792185
Validation loss: 2.5296723302857727

Epoch: 6| Step: 12
Training loss: 0.5087832635413592
Validation loss: 2.5025352748630136

Epoch: 6| Step: 13
Training loss: 0.483412910013585
Validation loss: 2.47047345466652

Epoch: 327| Step: 0
Training loss: 0.7982102968525299
Validation loss: 2.464130633945357

Epoch: 6| Step: 1
Training loss: 0.6089029195262264
Validation loss: 2.4915356468428023

Epoch: 6| Step: 2
Training loss: 0.43682466904662537
Validation loss: 2.5170668903577105

Epoch: 6| Step: 3
Training loss: 0.38807657554020103
Validation loss: 2.502713649792516

Epoch: 6| Step: 4
Training loss: 0.6804971805068445
Validation loss: 2.5156077294739934

Epoch: 6| Step: 5
Training loss: 0.4406318961611623
Validation loss: 2.5471257928620035

Epoch: 6| Step: 6
Training loss: 0.576797611091947
Validation loss: 2.564394202996909

Epoch: 6| Step: 7
Training loss: 0.31924999608821764
Validation loss: 2.5752106095086638

Epoch: 6| Step: 8
Training loss: 0.585146891948194
Validation loss: 2.5669272160565195

Epoch: 6| Step: 9
Training loss: 0.24556458817426938
Validation loss: 2.53752706870818

Epoch: 6| Step: 10
Training loss: 0.7040361223219436
Validation loss: 2.4891916304034387

Epoch: 6| Step: 11
Training loss: 0.4896812814440613
Validation loss: 2.547069282200358

Epoch: 6| Step: 12
Training loss: 0.7673992307658611
Validation loss: 2.498035076083699

Epoch: 6| Step: 13
Training loss: 0.5986757247504333
Validation loss: 2.4883217532928033

Epoch: 328| Step: 0
Training loss: 0.4864556325419547
Validation loss: 2.504344193953644

Epoch: 6| Step: 1
Training loss: 0.40256246159125
Validation loss: 2.489412694653997

Epoch: 6| Step: 2
Training loss: 0.5880630595135325
Validation loss: 2.4635989749995324

Epoch: 6| Step: 3
Training loss: 0.6028786417981432
Validation loss: 2.4582268201870585

Epoch: 6| Step: 4
Training loss: 0.2768988466003907
Validation loss: 2.452176188222973

Epoch: 6| Step: 5
Training loss: 0.7385211938155548
Validation loss: 2.4744511243149954

Epoch: 6| Step: 6
Training loss: 0.6884216286677783
Validation loss: 2.4798507084536623

Epoch: 6| Step: 7
Training loss: 0.47548392453080973
Validation loss: 2.47803282012892

Epoch: 6| Step: 8
Training loss: 0.4838956491394958
Validation loss: 2.4959613131282414

Epoch: 6| Step: 9
Training loss: 0.7872413543536554
Validation loss: 2.531203848477448

Epoch: 6| Step: 10
Training loss: 0.5490158140236073
Validation loss: 2.5175633718791395

Epoch: 6| Step: 11
Training loss: 0.33181721015341953
Validation loss: 2.499524380448382

Epoch: 6| Step: 12
Training loss: 0.5651514821672752
Validation loss: 2.505807660907298

Epoch: 6| Step: 13
Training loss: 0.872821787379452
Validation loss: 2.487430531593327

Epoch: 329| Step: 0
Training loss: 0.4174956380307877
Validation loss: 2.5216143347516264

Epoch: 6| Step: 1
Training loss: 0.6660848452934567
Validation loss: 2.493490273553652

Epoch: 6| Step: 2
Training loss: 0.595767733712974
Validation loss: 2.5207199000647442

Epoch: 6| Step: 3
Training loss: 0.25914500966817633
Validation loss: 2.536218262957943

Epoch: 6| Step: 4
Training loss: 0.5753059216091627
Validation loss: 2.510901846959501

Epoch: 6| Step: 5
Training loss: 0.6931847365825293
Validation loss: 2.5038052353060825

Epoch: 6| Step: 6
Training loss: 0.5984925297069342
Validation loss: 2.484257250065832

Epoch: 6| Step: 7
Training loss: 0.5018010187312033
Validation loss: 2.4734082001612863

Epoch: 6| Step: 8
Training loss: 0.6713483209900513
Validation loss: 2.4924264883835257

Epoch: 6| Step: 9
Training loss: 0.5693892753310603
Validation loss: 2.5135728810654463

Epoch: 6| Step: 10
Training loss: 0.4941925805562692
Validation loss: 2.4474553274146307

Epoch: 6| Step: 11
Training loss: 0.6732691118408176
Validation loss: 2.45887337104968

Epoch: 6| Step: 12
Training loss: 0.5017783606610509
Validation loss: 2.4412744966128965

Epoch: 6| Step: 13
Training loss: 0.19387774870477775
Validation loss: 2.500822205853069

Epoch: 330| Step: 0
Training loss: 0.34886000680842755
Validation loss: 2.455083958003615

Epoch: 6| Step: 1
Training loss: 0.46316687473119944
Validation loss: 2.4691858577962247

Epoch: 6| Step: 2
Training loss: 0.5200699616098512
Validation loss: 2.4780696424754427

Epoch: 6| Step: 3
Training loss: 0.41423840654917965
Validation loss: 2.463596164315904

Epoch: 6| Step: 4
Training loss: 0.5771193650309119
Validation loss: 2.4965931372314074

Epoch: 6| Step: 5
Training loss: 0.722832323223895
Validation loss: 2.4868100214084734

Epoch: 6| Step: 6
Training loss: 0.7417622602842591
Validation loss: 2.4905443489297916

Epoch: 6| Step: 7
Training loss: 0.508256571346795
Validation loss: 2.432117500102778

Epoch: 6| Step: 8
Training loss: 0.7312782005023798
Validation loss: 2.474355753058122

Epoch: 6| Step: 9
Training loss: 0.4438982138465236
Validation loss: 2.4526383159052516

Epoch: 6| Step: 10
Training loss: 0.6289437324300798
Validation loss: 2.4512435603873093

Epoch: 6| Step: 11
Training loss: 0.49594901068537134
Validation loss: 2.4669118289067966

Epoch: 6| Step: 12
Training loss: 0.49330480097029966
Validation loss: 2.4240575783616936

Epoch: 6| Step: 13
Training loss: 0.7705466063660555
Validation loss: 2.418088833611197

Epoch: 331| Step: 0
Training loss: 0.7828941211293097
Validation loss: 2.4803077403263663

Epoch: 6| Step: 1
Training loss: 0.372057596625159
Validation loss: 2.5445412042194584

Epoch: 6| Step: 2
Training loss: 0.6869086192948233
Validation loss: 2.5850568163387817

Epoch: 6| Step: 3
Training loss: 0.6553525692136833
Validation loss: 2.587877596208834

Epoch: 6| Step: 4
Training loss: 0.4569219311772611
Validation loss: 2.5345607482688584

Epoch: 6| Step: 5
Training loss: 0.5766543162774512
Validation loss: 2.5784334169171554

Epoch: 6| Step: 6
Training loss: 0.2638515848986526
Validation loss: 2.541703241234056

Epoch: 6| Step: 7
Training loss: 0.6315219576590537
Validation loss: 2.482358791679671

Epoch: 6| Step: 8
Training loss: 0.36066991291653566
Validation loss: 2.472559434666269

Epoch: 6| Step: 9
Training loss: 0.5160616846197117
Validation loss: 2.422748540717667

Epoch: 6| Step: 10
Training loss: 0.7346759747534581
Validation loss: 2.465269113244554

Epoch: 6| Step: 11
Training loss: 0.646524526034968
Validation loss: 2.443720146336534

Epoch: 6| Step: 12
Training loss: 0.5206998431480792
Validation loss: 2.414432162150337

Epoch: 6| Step: 13
Training loss: 0.5886902551243292
Validation loss: 2.4201906839485843

Epoch: 332| Step: 0
Training loss: 0.5233026302294873
Validation loss: 2.4631615363907473

Epoch: 6| Step: 1
Training loss: 0.6017459738215937
Validation loss: 2.500455537947089

Epoch: 6| Step: 2
Training loss: 0.39500649787893966
Validation loss: 2.5285703248309908

Epoch: 6| Step: 3
Training loss: 0.6391361893603819
Validation loss: 2.5015789357769442

Epoch: 6| Step: 4
Training loss: 0.2505082834448433
Validation loss: 2.5136571259795786

Epoch: 6| Step: 5
Training loss: 0.5076454474701997
Validation loss: 2.52450526233747

Epoch: 6| Step: 6
Training loss: 0.6180472602597115
Validation loss: 2.5524793192520914

Epoch: 6| Step: 7
Training loss: 0.4957654422340199
Validation loss: 2.5492788395725987

Epoch: 6| Step: 8
Training loss: 0.5734660346807912
Validation loss: 2.532169881319444

Epoch: 6| Step: 9
Training loss: 0.5321448587122111
Validation loss: 2.5316737478741103

Epoch: 6| Step: 10
Training loss: 0.5309646064255812
Validation loss: 2.4994790323996305

Epoch: 6| Step: 11
Training loss: 0.8499816079113339
Validation loss: 2.4945661033632036

Epoch: 6| Step: 12
Training loss: 0.503660008790836
Validation loss: 2.4870296418816236

Epoch: 6| Step: 13
Training loss: 0.7112802790010896
Validation loss: 2.519653350931617

Epoch: 333| Step: 0
Training loss: 0.5489051737613264
Validation loss: 2.500004494570722

Epoch: 6| Step: 1
Training loss: 0.4591715329645644
Validation loss: 2.5071704190634905

Epoch: 6| Step: 2
Training loss: 0.5930314484470436
Validation loss: 2.537304068501029

Epoch: 6| Step: 3
Training loss: 0.48199969517630914
Validation loss: 2.5193145523945772

Epoch: 6| Step: 4
Training loss: 0.504642658190215
Validation loss: 2.5394460403881105

Epoch: 6| Step: 5
Training loss: 0.7159246392096061
Validation loss: 2.5146293486330493

Epoch: 6| Step: 6
Training loss: 0.7200158623431548
Validation loss: 2.5432547905267393

Epoch: 6| Step: 7
Training loss: 0.41868971205618305
Validation loss: 2.544830618051122

Epoch: 6| Step: 8
Training loss: 0.5236316434739754
Validation loss: 2.5381723261778504

Epoch: 6| Step: 9
Training loss: 0.8196139313016019
Validation loss: 2.508331818546613

Epoch: 6| Step: 10
Training loss: 0.34802728848301956
Validation loss: 2.5154816980245274

Epoch: 6| Step: 11
Training loss: 0.3468563972674231
Validation loss: 2.524295803273774

Epoch: 6| Step: 12
Training loss: 0.5803906148124116
Validation loss: 2.4982310887058428

Epoch: 6| Step: 13
Training loss: 0.2390807606074565
Validation loss: 2.524716285028974

Epoch: 334| Step: 0
Training loss: 0.4969042217610764
Validation loss: 2.520790055656966

Epoch: 6| Step: 1
Training loss: 0.6339947994030913
Validation loss: 2.529290160034302

Epoch: 6| Step: 2
Training loss: 0.5234802570245379
Validation loss: 2.533270010240426

Epoch: 6| Step: 3
Training loss: 0.4489417175557955
Validation loss: 2.519459560016984

Epoch: 6| Step: 4
Training loss: 0.6346263791456822
Validation loss: 2.4816731544324484

Epoch: 6| Step: 5
Training loss: 0.5178450274107271
Validation loss: 2.5172168156719863

Epoch: 6| Step: 6
Training loss: 0.23272152825863054
Validation loss: 2.5150902506554895

Epoch: 6| Step: 7
Training loss: 0.30151173208747856
Validation loss: 2.5086818176494203

Epoch: 6| Step: 8
Training loss: 0.8289747377050605
Validation loss: 2.505024655573862

Epoch: 6| Step: 9
Training loss: 0.5768847177664427
Validation loss: 2.516450934266097

Epoch: 6| Step: 10
Training loss: 0.7922581838640717
Validation loss: 2.55017286008729

Epoch: 6| Step: 11
Training loss: 0.3637957877085649
Validation loss: 2.4925944274827625

Epoch: 6| Step: 12
Training loss: 0.49914026852360793
Validation loss: 2.506626048218253

Epoch: 6| Step: 13
Training loss: 0.1907329296776989
Validation loss: 2.528680792637914

Epoch: 335| Step: 0
Training loss: 0.1964868526416285
Validation loss: 2.51228216707803

Epoch: 6| Step: 1
Training loss: 0.4711364555929672
Validation loss: 2.5282578993488114

Epoch: 6| Step: 2
Training loss: 0.8474587065277661
Validation loss: 2.5162145858349394

Epoch: 6| Step: 3
Training loss: 0.6646727058403479
Validation loss: 2.546338783687378

Epoch: 6| Step: 4
Training loss: 0.5902665498700373
Validation loss: 2.5090522363510694

Epoch: 6| Step: 5
Training loss: 0.32808799762081303
Validation loss: 2.486681654111678

Epoch: 6| Step: 6
Training loss: 0.4842187260211989
Validation loss: 2.5175559514991597

Epoch: 6| Step: 7
Training loss: 0.5795805367137902
Validation loss: 2.5137732672648534

Epoch: 6| Step: 8
Training loss: 0.20065829078077346
Validation loss: 2.5483067947880804

Epoch: 6| Step: 9
Training loss: 0.4321935228216358
Validation loss: 2.516911594386987

Epoch: 6| Step: 10
Training loss: 0.48835506644184445
Validation loss: 2.546108928605309

Epoch: 6| Step: 11
Training loss: 0.4606710407327287
Validation loss: 2.524066218498833

Epoch: 6| Step: 12
Training loss: 0.7685991635474111
Validation loss: 2.519477431445969

Epoch: 6| Step: 13
Training loss: 0.7143547595236355
Validation loss: 2.539449770589517

Epoch: 336| Step: 0
Training loss: 0.7806870530374341
Validation loss: 2.519715985864925

Epoch: 6| Step: 1
Training loss: 0.3866362435537187
Validation loss: 2.4648468598444535

Epoch: 6| Step: 2
Training loss: 0.7093089808189276
Validation loss: 2.466183899015245

Epoch: 6| Step: 3
Training loss: 0.817897402212129
Validation loss: 2.4415178527919204

Epoch: 6| Step: 4
Training loss: 0.37866405730050834
Validation loss: 2.4825315136192843

Epoch: 6| Step: 5
Training loss: 0.7672697811715244
Validation loss: 2.4272307905195785

Epoch: 6| Step: 6
Training loss: 0.4842282042022008
Validation loss: 2.4650633120192236

Epoch: 6| Step: 7
Training loss: 0.5001243794234053
Validation loss: 2.4706940333935057

Epoch: 6| Step: 8
Training loss: 0.5018555364480671
Validation loss: 2.4618236232281445

Epoch: 6| Step: 9
Training loss: 0.5040220674592086
Validation loss: 2.527574385033893

Epoch: 6| Step: 10
Training loss: 0.40634654805188836
Validation loss: 2.53112555060809

Epoch: 6| Step: 11
Training loss: 0.24902541963872984
Validation loss: 2.5611294638620845

Epoch: 6| Step: 12
Training loss: 0.5929278403583307
Validation loss: 2.574338883987399

Epoch: 6| Step: 13
Training loss: 0.3485263052703931
Validation loss: 2.6058344492036984

Epoch: 337| Step: 0
Training loss: 0.4668955838212111
Validation loss: 2.565665348211293

Epoch: 6| Step: 1
Training loss: 0.44673663511495393
Validation loss: 2.579914318060084

Epoch: 6| Step: 2
Training loss: 0.5613458767329129
Validation loss: 2.5310163735726614

Epoch: 6| Step: 3
Training loss: 0.48594412906454976
Validation loss: 2.503584220286117

Epoch: 6| Step: 4
Training loss: 0.3650500806652942
Validation loss: 2.5064528024308785

Epoch: 6| Step: 5
Training loss: 0.6882751170133035
Validation loss: 2.50320310998359

Epoch: 6| Step: 6
Training loss: 0.6286979946523763
Validation loss: 2.4564455663545894

Epoch: 6| Step: 7
Training loss: 0.4363827574703404
Validation loss: 2.47357763464618

Epoch: 6| Step: 8
Training loss: 0.7153994375504481
Validation loss: 2.4550888209178043

Epoch: 6| Step: 9
Training loss: 0.7611485621325673
Validation loss: 2.485811977417327

Epoch: 6| Step: 10
Training loss: 0.5328091294078545
Validation loss: 2.469991722932528

Epoch: 6| Step: 11
Training loss: 0.5883997996565907
Validation loss: 2.505402174502736

Epoch: 6| Step: 12
Training loss: 0.5073706538636156
Validation loss: 2.5127060161840036

Epoch: 6| Step: 13
Training loss: 0.605688387503174
Validation loss: 2.5337762049922214

Epoch: 338| Step: 0
Training loss: 0.36002117611274376
Validation loss: 2.554414055452235

Epoch: 6| Step: 1
Training loss: 0.5883846551764655
Validation loss: 2.5456497679715024

Epoch: 6| Step: 2
Training loss: 0.5915324309576735
Validation loss: 2.553328578000698

Epoch: 6| Step: 3
Training loss: 0.572347901975176
Validation loss: 2.550452111391083

Epoch: 6| Step: 4
Training loss: 0.662920294902982
Validation loss: 2.559959629061611

Epoch: 6| Step: 5
Training loss: 0.3654133567239679
Validation loss: 2.585327521624337

Epoch: 6| Step: 6
Training loss: 0.5718235743179197
Validation loss: 2.5306928561563082

Epoch: 6| Step: 7
Training loss: 0.5664987685837455
Validation loss: 2.5130981032176853

Epoch: 6| Step: 8
Training loss: 0.4701568631148849
Validation loss: 2.5137383702177294

Epoch: 6| Step: 9
Training loss: 0.5399175855653604
Validation loss: 2.4644668852900584

Epoch: 6| Step: 10
Training loss: 0.6595390865942133
Validation loss: 2.4677996433316682

Epoch: 6| Step: 11
Training loss: 0.5954551555890512
Validation loss: 2.4662001824790107

Epoch: 6| Step: 12
Training loss: 0.6038822924363736
Validation loss: 2.484822965584858

Epoch: 6| Step: 13
Training loss: 0.6332467555382011
Validation loss: 2.494914908821096

Epoch: 339| Step: 0
Training loss: 0.5608048858720878
Validation loss: 2.542055632470657

Epoch: 6| Step: 1
Training loss: 0.5033584988799723
Validation loss: 2.5379812195190348

Epoch: 6| Step: 2
Training loss: 0.5656034634109789
Validation loss: 2.5374768062355755

Epoch: 6| Step: 3
Training loss: 0.43773658350193867
Validation loss: 2.524885451948143

Epoch: 6| Step: 4
Training loss: 0.5728496396708481
Validation loss: 2.5708919863953015

Epoch: 6| Step: 5
Training loss: 0.6677819598742787
Validation loss: 2.5123033105670616

Epoch: 6| Step: 6
Training loss: 0.5707079940055549
Validation loss: 2.5031911510246507

Epoch: 6| Step: 7
Training loss: 0.5323141883320789
Validation loss: 2.495668637885596

Epoch: 6| Step: 8
Training loss: 0.7912926082980771
Validation loss: 2.481622071649736

Epoch: 6| Step: 9
Training loss: 0.5482065339381342
Validation loss: 2.4943632219135234

Epoch: 6| Step: 10
Training loss: 0.482106217500877
Validation loss: 2.491861075189641

Epoch: 6| Step: 11
Training loss: 0.16801209223249136
Validation loss: 2.4882253491598467

Epoch: 6| Step: 12
Training loss: 0.5782913793394597
Validation loss: 2.478015682803851

Epoch: 6| Step: 13
Training loss: 0.42512628067640257
Validation loss: 2.5094970263170753

Epoch: 340| Step: 0
Training loss: 0.44826522468757246
Validation loss: 2.492539432825198

Epoch: 6| Step: 1
Training loss: 0.6943303576109741
Validation loss: 2.527739262793606

Epoch: 6| Step: 2
Training loss: 0.5768805848881432
Validation loss: 2.517484050988236

Epoch: 6| Step: 3
Training loss: 0.13765128764323806
Validation loss: 2.499337709541732

Epoch: 6| Step: 4
Training loss: 0.4421012268555881
Validation loss: 2.493468107927139

Epoch: 6| Step: 5
Training loss: 0.7555894788749694
Validation loss: 2.524104860719981

Epoch: 6| Step: 6
Training loss: 0.6788187723462701
Validation loss: 2.4979853705998147

Epoch: 6| Step: 7
Training loss: 0.32860790775434584
Validation loss: 2.5243679657537212

Epoch: 6| Step: 8
Training loss: 0.368076728965514
Validation loss: 2.525425055478139

Epoch: 6| Step: 9
Training loss: 0.32977714585326257
Validation loss: 2.487472214370723

Epoch: 6| Step: 10
Training loss: 0.5248983693526861
Validation loss: 2.501664474097859

Epoch: 6| Step: 11
Training loss: 0.5241283014667955
Validation loss: 2.480437248817374

Epoch: 6| Step: 12
Training loss: 0.6154762398156804
Validation loss: 2.4992112638286015

Epoch: 6| Step: 13
Training loss: 0.7931477762714035
Validation loss: 2.4945787300444167

Epoch: 341| Step: 0
Training loss: 0.7072848292054453
Validation loss: 2.4849974191237565

Epoch: 6| Step: 1
Training loss: 0.5993339079771728
Validation loss: 2.456301991970961

Epoch: 6| Step: 2
Training loss: 0.3984557876877905
Validation loss: 2.494515757863665

Epoch: 6| Step: 3
Training loss: 0.35373632381004666
Validation loss: 2.4926696016842627

Epoch: 6| Step: 4
Training loss: 0.3065838609383113
Validation loss: 2.4986622625541024

Epoch: 6| Step: 5
Training loss: 0.6330005931354293
Validation loss: 2.4500582893373877

Epoch: 6| Step: 6
Training loss: 0.4296833558316224
Validation loss: 2.487498933071799

Epoch: 6| Step: 7
Training loss: 0.5519713402163441
Validation loss: 2.47661057085234

Epoch: 6| Step: 8
Training loss: 0.581039454156277
Validation loss: 2.4890406463279393

Epoch: 6| Step: 9
Training loss: 0.5017418620899368
Validation loss: 2.4585192050261595

Epoch: 6| Step: 10
Training loss: 0.18593662886856277
Validation loss: 2.485612969069133

Epoch: 6| Step: 11
Training loss: 0.6625040279122031
Validation loss: 2.5160704585010616

Epoch: 6| Step: 12
Training loss: 0.6102792681794142
Validation loss: 2.52667797630206

Epoch: 6| Step: 13
Training loss: 0.41145639982453286
Validation loss: 2.4981904577116882

Epoch: 342| Step: 0
Training loss: 0.6078411017114039
Validation loss: 2.5165776801830146

Epoch: 6| Step: 1
Training loss: 0.46700116399787406
Validation loss: 2.533915556542641

Epoch: 6| Step: 2
Training loss: 0.4354536187616288
Validation loss: 2.516124200152366

Epoch: 6| Step: 3
Training loss: 0.506064472817939
Validation loss: 2.5057379677575073

Epoch: 6| Step: 4
Training loss: 0.49208250893866434
Validation loss: 2.5728192655764612

Epoch: 6| Step: 5
Training loss: 0.817847408122516
Validation loss: 2.548889122714242

Epoch: 6| Step: 6
Training loss: 0.4885593690355848
Validation loss: 2.519537308229281

Epoch: 6| Step: 7
Training loss: 0.3885534288127696
Validation loss: 2.5424236022459

Epoch: 6| Step: 8
Training loss: 0.4455535470515464
Validation loss: 2.543597349639956

Epoch: 6| Step: 9
Training loss: 0.45962181467421026
Validation loss: 2.4746897800828407

Epoch: 6| Step: 10
Training loss: 0.6785485821298238
Validation loss: 2.5213900806994354

Epoch: 6| Step: 11
Training loss: 0.3964602646285362
Validation loss: 2.5184166745951586

Epoch: 6| Step: 12
Training loss: 0.42364153292427137
Validation loss: 2.4928350464679463

Epoch: 6| Step: 13
Training loss: 0.22057282137427736
Validation loss: 2.4722222546373938

Epoch: 343| Step: 0
Training loss: 0.10172718249730356
Validation loss: 2.5159979663323333

Epoch: 6| Step: 1
Training loss: 0.18178813851039838
Validation loss: 2.494568912038389

Epoch: 6| Step: 2
Training loss: 0.5968129809848335
Validation loss: 2.4799635459464766

Epoch: 6| Step: 3
Training loss: 0.6299175873849056
Validation loss: 2.467068603375663

Epoch: 6| Step: 4
Training loss: 0.539086106377793
Validation loss: 2.4843828326676

Epoch: 6| Step: 5
Training loss: 0.707123049682927
Validation loss: 2.4887289183282526

Epoch: 6| Step: 6
Training loss: 0.49681198512261926
Validation loss: 2.4692805125070487

Epoch: 6| Step: 7
Training loss: 0.4696343979858483
Validation loss: 2.4735208211058906

Epoch: 6| Step: 8
Training loss: 0.5566821701875643
Validation loss: 2.486707136965278

Epoch: 6| Step: 9
Training loss: 0.5068048603621912
Validation loss: 2.509054357005958

Epoch: 6| Step: 10
Training loss: 0.5811641301540154
Validation loss: 2.5387154023077945

Epoch: 6| Step: 11
Training loss: 0.4344713076851156
Validation loss: 2.5319254898179673

Epoch: 6| Step: 12
Training loss: 0.4969608958391935
Validation loss: 2.579427946352203

Epoch: 6| Step: 13
Training loss: 0.5421775432189122
Validation loss: 2.5359601004850543

Epoch: 344| Step: 0
Training loss: 0.40883682197987875
Validation loss: 2.5461717434008744

Epoch: 6| Step: 1
Training loss: 0.7010201207591459
Validation loss: 2.5220207977631817

Epoch: 6| Step: 2
Training loss: 0.45427610262927537
Validation loss: 2.5036305921851336

Epoch: 6| Step: 3
Training loss: 0.5677163068112265
Validation loss: 2.469122862005259

Epoch: 6| Step: 4
Training loss: 0.5857479806214779
Validation loss: 2.439545962541864

Epoch: 6| Step: 5
Training loss: 0.5033917720871716
Validation loss: 2.4568242807997756

Epoch: 6| Step: 6
Training loss: 0.31910261910728593
Validation loss: 2.435876560736177

Epoch: 6| Step: 7
Training loss: 0.4208331843020235
Validation loss: 2.443183890591173

Epoch: 6| Step: 8
Training loss: 0.6114845928768318
Validation loss: 2.4265205321934364

Epoch: 6| Step: 9
Training loss: 0.6243356750369348
Validation loss: 2.4409795704099317

Epoch: 6| Step: 10
Training loss: 0.4352801750871481
Validation loss: 2.4578869297709787

Epoch: 6| Step: 11
Training loss: 0.24422179589352086
Validation loss: 2.46980529344884

Epoch: 6| Step: 12
Training loss: 0.476404898802035
Validation loss: 2.454197159374767

Epoch: 6| Step: 13
Training loss: 0.6415696041793407
Validation loss: 2.4580585850403542

Epoch: 345| Step: 0
Training loss: 0.5031610049520662
Validation loss: 2.4850407463810713

Epoch: 6| Step: 1
Training loss: 0.24395878695802242
Validation loss: 2.476121948099765

Epoch: 6| Step: 2
Training loss: 0.46586128870359717
Validation loss: 2.4839145891359555

Epoch: 6| Step: 3
Training loss: 0.4014017503247876
Validation loss: 2.5100671835285224

Epoch: 6| Step: 4
Training loss: 0.6688736703196829
Validation loss: 2.513297717877133

Epoch: 6| Step: 5
Training loss: 0.31959910150361076
Validation loss: 2.4794988202019552

Epoch: 6| Step: 6
Training loss: 0.42003355093757794
Validation loss: 2.5270572415066117

Epoch: 6| Step: 7
Training loss: 0.5818872977820524
Validation loss: 2.4934142151971788

Epoch: 6| Step: 8
Training loss: 0.7635098648907904
Validation loss: 2.5038436547279224

Epoch: 6| Step: 9
Training loss: 0.457011426185988
Validation loss: 2.4573968577851564

Epoch: 6| Step: 10
Training loss: 0.6123670336362254
Validation loss: 2.4840352115044

Epoch: 6| Step: 11
Training loss: 0.3879816645709281
Validation loss: 2.511799922720965

Epoch: 6| Step: 12
Training loss: 0.6025277357721596
Validation loss: 2.4804291757933132

Epoch: 6| Step: 13
Training loss: 0.2585354263824137
Validation loss: 2.4682352347912904

Epoch: 346| Step: 0
Training loss: 0.4045714215562408
Validation loss: 2.495062805344747

Epoch: 6| Step: 1
Training loss: 0.7452639613950455
Validation loss: 2.4957241542370094

Epoch: 6| Step: 2
Training loss: 0.597135953130757
Validation loss: 2.5076328198268536

Epoch: 6| Step: 3
Training loss: 0.4392137511303744
Validation loss: 2.4849435696512767

Epoch: 6| Step: 4
Training loss: 0.5130331615638474
Validation loss: 2.4860327739942223

Epoch: 6| Step: 5
Training loss: 0.18444111252946818
Validation loss: 2.5258711352738574

Epoch: 6| Step: 6
Training loss: 0.5686484057476638
Validation loss: 2.533366159233566

Epoch: 6| Step: 7
Training loss: 0.38229607762313483
Validation loss: 2.5504309544629984

Epoch: 6| Step: 8
Training loss: 0.4458008313884059
Validation loss: 2.5850652439224504

Epoch: 6| Step: 9
Training loss: 0.506287088330716
Validation loss: 2.56711036371962

Epoch: 6| Step: 10
Training loss: 0.27500282199452053
Validation loss: 2.556097883094136

Epoch: 6| Step: 11
Training loss: 0.3742870865706202
Validation loss: 2.5847736055857133

Epoch: 6| Step: 12
Training loss: 0.746555604834988
Validation loss: 2.5524029687079666

Epoch: 6| Step: 13
Training loss: 0.4364719573863317
Validation loss: 2.5620183274405908

Epoch: 347| Step: 0
Training loss: 0.33792354445429373
Validation loss: 2.5908753241768503

Epoch: 6| Step: 1
Training loss: 0.5981192945489249
Validation loss: 2.528658263311099

Epoch: 6| Step: 2
Training loss: 0.42409269803050015
Validation loss: 2.522063913367864

Epoch: 6| Step: 3
Training loss: 0.5260094044174629
Validation loss: 2.481122184005713

Epoch: 6| Step: 4
Training loss: 0.21017407976264185
Validation loss: 2.4926240523046896

Epoch: 6| Step: 5
Training loss: 0.6975319831789261
Validation loss: 2.522028269046042

Epoch: 6| Step: 6
Training loss: 0.537571711524833
Validation loss: 2.524694908373126

Epoch: 6| Step: 7
Training loss: 0.6235563294020416
Validation loss: 2.520439569413228

Epoch: 6| Step: 8
Training loss: 0.47984689307169415
Validation loss: 2.5231084497001497

Epoch: 6| Step: 9
Training loss: 0.3767980345459619
Validation loss: 2.5166208920970914

Epoch: 6| Step: 10
Training loss: 0.49047524967122114
Validation loss: 2.4750416404657654

Epoch: 6| Step: 11
Training loss: 0.6091173556556799
Validation loss: 2.545588765649569

Epoch: 6| Step: 12
Training loss: 0.16235563233795489
Validation loss: 2.4952938863880263

Epoch: 6| Step: 13
Training loss: 0.475336436284055
Validation loss: 2.5235430846086273

Epoch: 348| Step: 0
Training loss: 0.4949127919026722
Validation loss: 2.5214859275291706

Epoch: 6| Step: 1
Training loss: 0.533110055031993
Validation loss: 2.5068226679411074

Epoch: 6| Step: 2
Training loss: 0.25987228555715813
Validation loss: 2.495500512212877

Epoch: 6| Step: 3
Training loss: 0.2357048137782576
Validation loss: 2.5144839712078335

Epoch: 6| Step: 4
Training loss: 0.499756560071222
Validation loss: 2.469020513519544

Epoch: 6| Step: 5
Training loss: 0.4427538698749947
Validation loss: 2.4795624653224784

Epoch: 6| Step: 6
Training loss: 0.6388473969498981
Validation loss: 2.5119888358717497

Epoch: 6| Step: 7
Training loss: 0.43719427462080884
Validation loss: 2.506007368312914

Epoch: 6| Step: 8
Training loss: 0.5825256705460222
Validation loss: 2.5123310274524138

Epoch: 6| Step: 9
Training loss: 0.39752699094580485
Validation loss: 2.536798739900204

Epoch: 6| Step: 10
Training loss: 0.6313495916232178
Validation loss: 2.5084230093038062

Epoch: 6| Step: 11
Training loss: 0.4627752361454242
Validation loss: 2.5018339956873037

Epoch: 6| Step: 12
Training loss: 0.5828720778216748
Validation loss: 2.539662118539462

Epoch: 6| Step: 13
Training loss: 0.4330385106913596
Validation loss: 2.495653424474264

Epoch: 349| Step: 0
Training loss: 0.4970482032520455
Validation loss: 2.491602939637611

Epoch: 6| Step: 1
Training loss: 0.562792198793572
Validation loss: 2.5165925552135855

Epoch: 6| Step: 2
Training loss: 0.22505751973950042
Validation loss: 2.510225324385461

Epoch: 6| Step: 3
Training loss: 0.3773322496576946
Validation loss: 2.5170058079437663

Epoch: 6| Step: 4
Training loss: 0.5044847464963428
Validation loss: 2.510110309384525

Epoch: 6| Step: 5
Training loss: 0.5019931109343253
Validation loss: 2.4935459586931352

Epoch: 6| Step: 6
Training loss: 0.6542433076253129
Validation loss: 2.534917158324281

Epoch: 6| Step: 7
Training loss: 0.16279598546794258
Validation loss: 2.5141946676169056

Epoch: 6| Step: 8
Training loss: 0.7939501172210089
Validation loss: 2.529181038582757

Epoch: 6| Step: 9
Training loss: 0.2729189178626322
Validation loss: 2.4998682336025086

Epoch: 6| Step: 10
Training loss: 0.6686501624549663
Validation loss: 2.5254528161495466

Epoch: 6| Step: 11
Training loss: 0.14626802361926605
Validation loss: 2.5284694140216195

Epoch: 6| Step: 12
Training loss: 0.33802875275389027
Validation loss: 2.516043416576274

Epoch: 6| Step: 13
Training loss: 0.5123094832631814
Validation loss: 2.5044403553418166

Epoch: 350| Step: 0
Training loss: 0.24890938933476706
Validation loss: 2.549929342229968

Epoch: 6| Step: 1
Training loss: 0.6258081694681432
Validation loss: 2.4761077969630003

Epoch: 6| Step: 2
Training loss: 0.5360497582313285
Validation loss: 2.4877155516241833

Epoch: 6| Step: 3
Training loss: 0.43214145793035225
Validation loss: 2.49817444382443

Epoch: 6| Step: 4
Training loss: 0.540016270410056
Validation loss: 2.4729246391641087

Epoch: 6| Step: 5
Training loss: 0.4360843301792416
Validation loss: 2.5002455339554115

Epoch: 6| Step: 6
Training loss: 0.5933996471929835
Validation loss: 2.4928233894854324

Epoch: 6| Step: 7
Training loss: 0.18092381130743607
Validation loss: 2.5018912073613238

Epoch: 6| Step: 8
Training loss: 0.5007006385421262
Validation loss: 2.4966760914094808

Epoch: 6| Step: 9
Training loss: 0.4437045463600771
Validation loss: 2.473027015779273

Epoch: 6| Step: 10
Training loss: 0.6682506211945471
Validation loss: 2.4570578145533575

Epoch: 6| Step: 11
Training loss: 0.36076286021234744
Validation loss: 2.488856741233515

Epoch: 6| Step: 12
Training loss: 0.3514365500434412
Validation loss: 2.50353631663703

Epoch: 6| Step: 13
Training loss: 0.4961195210649054
Validation loss: 2.4712210225945426

Testing loss: 2.4681903274462966
