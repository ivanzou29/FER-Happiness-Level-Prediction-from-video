Epoch: 1| Step: 0
Training loss: 5.524003982543945
Validation loss: 5.1660405076960085

Epoch: 5| Step: 1
Training loss: 4.135018348693848
Validation loss: 5.137490667322631

Epoch: 5| Step: 2
Training loss: 4.656165599822998
Validation loss: 5.107803703636251

Epoch: 5| Step: 3
Training loss: 4.8968377113342285
Validation loss: 5.074022610982259

Epoch: 5| Step: 4
Training loss: 4.569412708282471
Validation loss: 5.03615415224465

Epoch: 5| Step: 5
Training loss: 4.429460048675537
Validation loss: 4.993222016160206

Epoch: 5| Step: 6
Training loss: 5.204827785491943
Validation loss: 4.944308178399199

Epoch: 5| Step: 7
Training loss: 3.859516143798828
Validation loss: 4.889814853668213

Epoch: 5| Step: 8
Training loss: 4.3463239669799805
Validation loss: 4.828485817037603

Epoch: 5| Step: 9
Training loss: 5.276483058929443
Validation loss: 4.762781245734102

Epoch: 5| Step: 10
Training loss: 5.6429266929626465
Validation loss: 4.69113096626856

Epoch: 2| Step: 0
Training loss: 4.9467244148254395
Validation loss: 4.618598071477747

Epoch: 5| Step: 1
Training loss: 4.6249823570251465
Validation loss: 4.542746020901587

Epoch: 5| Step: 2
Training loss: 3.6169352531433105
Validation loss: 4.465433802655948

Epoch: 5| Step: 3
Training loss: 3.970690965652466
Validation loss: 4.390248970318866

Epoch: 5| Step: 4
Training loss: 4.018939971923828
Validation loss: 4.318066279093425

Epoch: 5| Step: 5
Training loss: 4.073277950286865
Validation loss: 4.24855702410462

Epoch: 5| Step: 6
Training loss: 5.10886812210083
Validation loss: 4.18245663181428

Epoch: 5| Step: 7
Training loss: 5.010893821716309
Validation loss: 4.119573449575773

Epoch: 5| Step: 8
Training loss: 3.316646099090576
Validation loss: 4.056109636060653

Epoch: 5| Step: 9
Training loss: 3.101663589477539
Validation loss: 3.990679225613994

Epoch: 5| Step: 10
Training loss: 2.9416584968566895
Validation loss: 3.9290061561010217

Epoch: 3| Step: 0
Training loss: 3.789630174636841
Validation loss: 3.87284085571125

Epoch: 5| Step: 1
Training loss: 4.356137752532959
Validation loss: 3.822251889013475

Epoch: 5| Step: 2
Training loss: 4.107283592224121
Validation loss: 3.7688742632506997

Epoch: 5| Step: 3
Training loss: 3.3887991905212402
Validation loss: 3.7158914073821037

Epoch: 5| Step: 4
Training loss: 4.194664478302002
Validation loss: 3.6637389326608307

Epoch: 5| Step: 5
Training loss: 2.5594048500061035
Validation loss: 3.6187849019163396

Epoch: 5| Step: 6
Training loss: 3.1575927734375
Validation loss: 3.582917413403911

Epoch: 5| Step: 7
Training loss: 3.648996353149414
Validation loss: 3.549271934775896

Epoch: 5| Step: 8
Training loss: 3.1761574745178223
Validation loss: 3.5151225777082544

Epoch: 5| Step: 9
Training loss: 2.925283432006836
Validation loss: 3.4761584907449703

Epoch: 5| Step: 10
Training loss: 3.8190739154815674
Validation loss: 3.438833244385258

Epoch: 4| Step: 0
Training loss: 3.5783638954162598
Validation loss: 3.4003721308964554

Epoch: 5| Step: 1
Training loss: 3.5102486610412598
Validation loss: 3.367186141270463

Epoch: 5| Step: 2
Training loss: 3.7011189460754395
Validation loss: 3.338382826056532

Epoch: 5| Step: 3
Training loss: 3.0289816856384277
Validation loss: 3.3129707356934905

Epoch: 5| Step: 4
Training loss: 3.422152042388916
Validation loss: 3.288520554060577

Epoch: 5| Step: 5
Training loss: 3.0063929557800293
Validation loss: 3.2609395596288864

Epoch: 5| Step: 6
Training loss: 2.960111141204834
Validation loss: 3.2270515247057845

Epoch: 5| Step: 7
Training loss: 2.3132457733154297
Validation loss: 3.199993546291064

Epoch: 5| Step: 8
Training loss: 3.756870985031128
Validation loss: 3.1847544280431603

Epoch: 5| Step: 9
Training loss: 3.223660945892334
Validation loss: 3.1699981843271563

Epoch: 5| Step: 10
Training loss: 3.2458534240722656
Validation loss: 3.1481959281429166

Epoch: 5| Step: 0
Training loss: 3.022573471069336
Validation loss: 3.137806130993751

Epoch: 5| Step: 1
Training loss: 2.593841075897217
Validation loss: 3.117122386091499

Epoch: 5| Step: 2
Training loss: 3.190192937850952
Validation loss: 3.1036641802839053

Epoch: 5| Step: 3
Training loss: 3.47896146774292
Validation loss: 3.099225046814129

Epoch: 5| Step: 4
Training loss: 3.0320663452148438
Validation loss: 3.0748841531815065

Epoch: 5| Step: 5
Training loss: 3.1615116596221924
Validation loss: 3.061257882784772

Epoch: 5| Step: 6
Training loss: 3.3027355670928955
Validation loss: 3.049376913296279

Epoch: 5| Step: 7
Training loss: 3.4818084239959717
Validation loss: 3.0321864005058043

Epoch: 5| Step: 8
Training loss: 2.944596767425537
Validation loss: 3.0208049025586856

Epoch: 5| Step: 9
Training loss: 3.433152675628662
Validation loss: 3.031003216261505

Epoch: 5| Step: 10
Training loss: 2.4047319889068604
Validation loss: 3.069790727348738

Epoch: 6| Step: 0
Training loss: 2.637692928314209
Validation loss: 3.1086478720429125

Epoch: 5| Step: 1
Training loss: 3.0032427310943604
Validation loss: 3.0577659658206406

Epoch: 5| Step: 2
Training loss: 2.8685851097106934
Validation loss: 2.9717734654744468

Epoch: 5| Step: 3
Training loss: 3.0656867027282715
Validation loss: 2.9816147204368346

Epoch: 5| Step: 4
Training loss: 3.316990613937378
Validation loss: 3.0059583725467807

Epoch: 5| Step: 5
Training loss: 2.7888400554656982
Validation loss: 3.0227100182605047

Epoch: 5| Step: 6
Training loss: 2.467524290084839
Validation loss: 3.047317599737516

Epoch: 5| Step: 7
Training loss: 3.133756637573242
Validation loss: 3.013093025453629

Epoch: 5| Step: 8
Training loss: 2.8462936878204346
Validation loss: 2.9750950669729583

Epoch: 5| Step: 9
Training loss: 4.260331153869629
Validation loss: 2.9492649955134236

Epoch: 5| Step: 10
Training loss: 3.4069783687591553
Validation loss: 2.9266416231791177

Epoch: 7| Step: 0
Training loss: 3.70159649848938
Validation loss: 2.9162408280116257

Epoch: 5| Step: 1
Training loss: 2.6667675971984863
Validation loss: 2.9162493392985356

Epoch: 5| Step: 2
Training loss: 2.7796764373779297
Validation loss: 2.9417266768793904

Epoch: 5| Step: 3
Training loss: 3.028510332107544
Validation loss: 2.9336010333030456

Epoch: 5| Step: 4
Training loss: 2.185162305831909
Validation loss: 2.9171757185330955

Epoch: 5| Step: 5
Training loss: 3.253620147705078
Validation loss: 2.8800097768024733

Epoch: 5| Step: 6
Training loss: 2.7910375595092773
Validation loss: 2.85073160740637

Epoch: 5| Step: 7
Training loss: 3.0692954063415527
Validation loss: 2.8347287049857517

Epoch: 5| Step: 8
Training loss: 3.0035617351531982
Validation loss: 2.8471462675320205

Epoch: 5| Step: 9
Training loss: 3.7308239936828613
Validation loss: 2.853956091788507

Epoch: 5| Step: 10
Training loss: 2.476593017578125
Validation loss: 2.830410070316766

Epoch: 8| Step: 0
Training loss: 2.90594220161438
Validation loss: 2.825750474006899

Epoch: 5| Step: 1
Training loss: 3.035248279571533
Validation loss: 2.8132444940587527

Epoch: 5| Step: 2
Training loss: 2.6100621223449707
Validation loss: 2.8091377750519784

Epoch: 5| Step: 3
Training loss: 3.0319201946258545
Validation loss: 2.852055529112457

Epoch: 5| Step: 4
Training loss: 2.608715534210205
Validation loss: 2.858337704853345

Epoch: 5| Step: 5
Training loss: 3.42121958732605
Validation loss: 2.7890857599114858

Epoch: 5| Step: 6
Training loss: 2.9156391620635986
Validation loss: 2.785036043454242

Epoch: 5| Step: 7
Training loss: 3.499938488006592
Validation loss: 2.7840085696148615

Epoch: 5| Step: 8
Training loss: 2.6908912658691406
Validation loss: 2.781094374195222

Epoch: 5| Step: 9
Training loss: 3.051257848739624
Validation loss: 2.776756663476267

Epoch: 5| Step: 10
Training loss: 2.404313087463379
Validation loss: 2.7695638031087895

Epoch: 9| Step: 0
Training loss: 3.190574884414673
Validation loss: 2.7681140463839293

Epoch: 5| Step: 1
Training loss: 2.383715867996216
Validation loss: 2.760700087393484

Epoch: 5| Step: 2
Training loss: 2.622612953186035
Validation loss: 2.7578078623740905

Epoch: 5| Step: 3
Training loss: 3.008481502532959
Validation loss: 2.754299940601472

Epoch: 5| Step: 4
Training loss: 2.289950132369995
Validation loss: 2.7429718073978218

Epoch: 5| Step: 5
Training loss: 2.974773406982422
Validation loss: 2.73600616762715

Epoch: 5| Step: 6
Training loss: 3.24040150642395
Validation loss: 2.726137935474355

Epoch: 5| Step: 7
Training loss: 3.2986655235290527
Validation loss: 2.7153414244292886

Epoch: 5| Step: 8
Training loss: 2.9479870796203613
Validation loss: 2.7100112361292683

Epoch: 5| Step: 9
Training loss: 2.8017396926879883
Validation loss: 2.706513868865146

Epoch: 5| Step: 10
Training loss: 2.9861745834350586
Validation loss: 2.7065750142579437

Epoch: 10| Step: 0
Training loss: 3.0324630737304688
Validation loss: 2.7213013505422943

Epoch: 5| Step: 1
Training loss: 2.756124496459961
Validation loss: 2.6935570983476538

Epoch: 5| Step: 2
Training loss: 3.319514036178589
Validation loss: 2.6739204622084096

Epoch: 5| Step: 3
Training loss: 2.8345444202423096
Validation loss: 2.668226900921073

Epoch: 5| Step: 4
Training loss: 3.2193915843963623
Validation loss: 2.66955901217717

Epoch: 5| Step: 5
Training loss: 2.254514694213867
Validation loss: 2.6685432926301034

Epoch: 5| Step: 6
Training loss: 2.589892864227295
Validation loss: 2.66506225832047

Epoch: 5| Step: 7
Training loss: 2.5168027877807617
Validation loss: 2.6595244766563497

Epoch: 5| Step: 8
Training loss: 3.2750887870788574
Validation loss: 2.657474176858061

Epoch: 5| Step: 9
Training loss: 2.505720376968384
Validation loss: 2.6677704447059223

Epoch: 5| Step: 10
Training loss: 3.041849374771118
Validation loss: 2.679240939437702

Epoch: 11| Step: 0
Training loss: 2.309382677078247
Validation loss: 2.6944303410027617

Epoch: 5| Step: 1
Training loss: 2.8610191345214844
Validation loss: 2.658639710436585

Epoch: 5| Step: 2
Training loss: 3.3948028087615967
Validation loss: 2.65530587011768

Epoch: 5| Step: 3
Training loss: 3.3591747283935547
Validation loss: 2.6453882417371197

Epoch: 5| Step: 4
Training loss: 2.8326032161712646
Validation loss: 2.6306306828734694

Epoch: 5| Step: 5
Training loss: 3.1146087646484375
Validation loss: 2.631317869309456

Epoch: 5| Step: 6
Training loss: 2.8101143836975098
Validation loss: 2.6210094728777484

Epoch: 5| Step: 7
Training loss: 2.960063934326172
Validation loss: 2.614653164340604

Epoch: 5| Step: 8
Training loss: 1.9203307628631592
Validation loss: 2.6103788345090804

Epoch: 5| Step: 9
Training loss: 2.695883274078369
Validation loss: 2.6061352401651363

Epoch: 5| Step: 10
Training loss: 2.704366445541382
Validation loss: 2.603521926428682

Epoch: 12| Step: 0
Training loss: 3.46191668510437
Validation loss: 2.6411157731086976

Epoch: 5| Step: 1
Training loss: 2.5342001914978027
Validation loss: 2.643218478848857

Epoch: 5| Step: 2
Training loss: 3.2736496925354004
Validation loss: 2.6126015827219975

Epoch: 5| Step: 3
Training loss: 2.4730465412139893
Validation loss: 2.5892059649190595

Epoch: 5| Step: 4
Training loss: 2.730646848678589
Validation loss: 2.582872383056148

Epoch: 5| Step: 5
Training loss: 2.856407403945923
Validation loss: 2.585409470783767

Epoch: 5| Step: 6
Training loss: 2.604905128479004
Validation loss: 2.5869002008950837

Epoch: 5| Step: 7
Training loss: 2.6356770992279053
Validation loss: 2.5820240102788454

Epoch: 5| Step: 8
Training loss: 2.5977158546447754
Validation loss: 2.5798600258365756

Epoch: 5| Step: 9
Training loss: 3.057358980178833
Validation loss: 2.583297162927607

Epoch: 5| Step: 10
Training loss: 2.468714714050293
Validation loss: 2.590971362206244

Epoch: 13| Step: 0
Training loss: 2.6007752418518066
Validation loss: 2.6142467657725015

Epoch: 5| Step: 1
Training loss: 3.079981565475464
Validation loss: 2.667495440411311

Epoch: 5| Step: 2
Training loss: 2.832134962081909
Validation loss: 2.6507457738281577

Epoch: 5| Step: 3
Training loss: 2.5006558895111084
Validation loss: 2.6262881627646824

Epoch: 5| Step: 4
Training loss: 3.0458171367645264
Validation loss: 2.5912259163395053

Epoch: 5| Step: 5
Training loss: 3.5029754638671875
Validation loss: 2.5838548060386413

Epoch: 5| Step: 6
Training loss: 2.3881497383117676
Validation loss: 2.581623779830112

Epoch: 5| Step: 7
Training loss: 2.9266273975372314
Validation loss: 2.583263663835423

Epoch: 5| Step: 8
Training loss: 2.5317835807800293
Validation loss: 2.5730926016325593

Epoch: 5| Step: 9
Training loss: 2.756969690322876
Validation loss: 2.5531377971813245

Epoch: 5| Step: 10
Training loss: 2.631103754043579
Validation loss: 2.5576816784438265

Epoch: 14| Step: 0
Training loss: 3.009446144104004
Validation loss: 2.5673269302614274

Epoch: 5| Step: 1
Training loss: 2.7327499389648438
Validation loss: 2.5537573804137526

Epoch: 5| Step: 2
Training loss: 3.267765522003174
Validation loss: 2.538181789459721

Epoch: 5| Step: 3
Training loss: 2.3773298263549805
Validation loss: 2.5321727901376705

Epoch: 5| Step: 4
Training loss: 3.929656505584717
Validation loss: 2.5391846190216723

Epoch: 5| Step: 5
Training loss: 2.160362720489502
Validation loss: 2.5284156978771253

Epoch: 5| Step: 6
Training loss: 2.753018617630005
Validation loss: 2.518226238989061

Epoch: 5| Step: 7
Training loss: 2.754765033721924
Validation loss: 2.527714062762517

Epoch: 5| Step: 8
Training loss: 2.0437378883361816
Validation loss: 2.5565613008314565

Epoch: 5| Step: 9
Training loss: 2.121812105178833
Validation loss: 2.6547645599611345

Epoch: 5| Step: 10
Training loss: 3.457080841064453
Validation loss: 2.6824395887313353

Epoch: 15| Step: 0
Training loss: 2.6583549976348877
Validation loss: 2.633493461916524

Epoch: 5| Step: 1
Training loss: 3.578037977218628
Validation loss: 2.608475926101849

Epoch: 5| Step: 2
Training loss: 3.024632692337036
Validation loss: 2.5982164772607947

Epoch: 5| Step: 3
Training loss: 2.8482282161712646
Validation loss: 2.6023909737986903

Epoch: 5| Step: 4
Training loss: 2.4280381202697754
Validation loss: 2.6180085161680817

Epoch: 5| Step: 5
Training loss: 2.8121731281280518
Validation loss: 2.6241381706730014

Epoch: 5| Step: 6
Training loss: 3.0483596324920654
Validation loss: 2.6237534733228784

Epoch: 5| Step: 7
Training loss: 3.1167731285095215
Validation loss: 2.608382009690808

Epoch: 5| Step: 8
Training loss: 2.2628891468048096
Validation loss: 2.5960100286750385

Epoch: 5| Step: 9
Training loss: 2.65673828125
Validation loss: 2.583591120217436

Epoch: 5| Step: 10
Training loss: 2.46766996383667
Validation loss: 2.567912422200685

Epoch: 16| Step: 0
Training loss: 2.4587302207946777
Validation loss: 2.55690828446419

Epoch: 5| Step: 1
Training loss: 2.4183006286621094
Validation loss: 2.552819821142381

Epoch: 5| Step: 2
Training loss: 2.7458221912384033
Validation loss: 2.5570311802689747

Epoch: 5| Step: 3
Training loss: 2.5301527976989746
Validation loss: 2.5875330894224104

Epoch: 5| Step: 4
Training loss: 3.2195515632629395
Validation loss: 2.5984745589635705

Epoch: 5| Step: 5
Training loss: 2.4534413814544678
Validation loss: 2.5588715537901847

Epoch: 5| Step: 6
Training loss: 2.951129674911499
Validation loss: 2.543933273643576

Epoch: 5| Step: 7
Training loss: 3.4835383892059326
Validation loss: 2.5360671397178405

Epoch: 5| Step: 8
Training loss: 2.5945096015930176
Validation loss: 2.532698356977073

Epoch: 5| Step: 9
Training loss: 2.899853229522705
Validation loss: 2.5264962821878414

Epoch: 5| Step: 10
Training loss: 2.6406633853912354
Validation loss: 2.5220795600645003

Epoch: 17| Step: 0
Training loss: 2.8273441791534424
Validation loss: 2.5107413286803872

Epoch: 5| Step: 1
Training loss: 2.387969970703125
Validation loss: 2.5062952195444415

Epoch: 5| Step: 2
Training loss: 3.1160378456115723
Validation loss: 2.4896593760418635

Epoch: 5| Step: 3
Training loss: 2.7850940227508545
Validation loss: 2.4822084647352978

Epoch: 5| Step: 4
Training loss: 3.24269437789917
Validation loss: 2.478588327284782

Epoch: 5| Step: 5
Training loss: 2.4418022632598877
Validation loss: 2.4766268114889822

Epoch: 5| Step: 6
Training loss: 1.9398530721664429
Validation loss: 2.478315225211523

Epoch: 5| Step: 7
Training loss: 2.2141313552856445
Validation loss: 2.4738994849625455

Epoch: 5| Step: 8
Training loss: 3.255316972732544
Validation loss: 2.4726009420169297

Epoch: 5| Step: 9
Training loss: 3.4914779663085938
Validation loss: 2.4721218565458893

Epoch: 5| Step: 10
Training loss: 2.267871618270874
Validation loss: 2.466407193932482

Epoch: 18| Step: 0
Training loss: 3.0502970218658447
Validation loss: 2.475432526680731

Epoch: 5| Step: 1
Training loss: 2.5534636974334717
Validation loss: 2.500223498190603

Epoch: 5| Step: 2
Training loss: 3.102774143218994
Validation loss: 2.5449589503708707

Epoch: 5| Step: 3
Training loss: 2.7111496925354004
Validation loss: 2.525022401604601

Epoch: 5| Step: 4
Training loss: 2.318356990814209
Validation loss: 2.4810002644856772

Epoch: 5| Step: 5
Training loss: 2.0014894008636475
Validation loss: 2.464521538826727

Epoch: 5| Step: 6
Training loss: 2.754204511642456
Validation loss: 2.4723257710856776

Epoch: 5| Step: 7
Training loss: 2.775521993637085
Validation loss: 2.4760172367095947

Epoch: 5| Step: 8
Training loss: 2.497560501098633
Validation loss: 2.4802510558917956

Epoch: 5| Step: 9
Training loss: 2.801208734512329
Validation loss: 2.4734140570445726

Epoch: 5| Step: 10
Training loss: 3.4381988048553467
Validation loss: 2.4712387925835064

Epoch: 19| Step: 0
Training loss: 2.4363317489624023
Validation loss: 2.445857404380716

Epoch: 5| Step: 1
Training loss: 3.3004062175750732
Validation loss: 2.4346285661061606

Epoch: 5| Step: 2
Training loss: 2.7355587482452393
Validation loss: 2.4203701121832735

Epoch: 5| Step: 3
Training loss: 3.3298022747039795
Validation loss: 2.418015473632402

Epoch: 5| Step: 4
Training loss: 2.754399538040161
Validation loss: 2.420024853880687

Epoch: 5| Step: 5
Training loss: 2.251293897628784
Validation loss: 2.4301161125142086

Epoch: 5| Step: 6
Training loss: 2.7473716735839844
Validation loss: 2.437285505315309

Epoch: 5| Step: 7
Training loss: 2.567258596420288
Validation loss: 2.4463299371862925

Epoch: 5| Step: 8
Training loss: 2.355616331100464
Validation loss: 2.4692398860890377

Epoch: 5| Step: 9
Training loss: 2.7149624824523926
Validation loss: 2.5070568079589517

Epoch: 5| Step: 10
Training loss: 2.3174233436584473
Validation loss: 2.5216462509606474

Epoch: 20| Step: 0
Training loss: 2.177074432373047
Validation loss: 2.5103730104302846

Epoch: 5| Step: 1
Training loss: 2.4993011951446533
Validation loss: 2.437045274242278

Epoch: 5| Step: 2
Training loss: 3.8252511024475098
Validation loss: 2.4091648440207205

Epoch: 5| Step: 3
Training loss: 2.2662999629974365
Validation loss: 2.418666019234606

Epoch: 5| Step: 4
Training loss: 3.355625867843628
Validation loss: 2.4299884303923576

Epoch: 5| Step: 5
Training loss: 2.6777756214141846
Validation loss: 2.43426989611759

Epoch: 5| Step: 6
Training loss: 2.834688663482666
Validation loss: 2.4292803246487855

Epoch: 5| Step: 7
Training loss: 2.719334840774536
Validation loss: 2.4165466318848314

Epoch: 5| Step: 8
Training loss: 2.3181400299072266
Validation loss: 2.4061580806650142

Epoch: 5| Step: 9
Training loss: 2.5587446689605713
Validation loss: 2.4025806150128766

Epoch: 5| Step: 10
Training loss: 2.583986759185791
Validation loss: 2.429066345255862

Epoch: 21| Step: 0
Training loss: 3.66810941696167
Validation loss: 2.4714642750319613

Epoch: 5| Step: 1
Training loss: 2.892876386642456
Validation loss: 2.4890958839847195

Epoch: 5| Step: 2
Training loss: 2.9730145931243896
Validation loss: 2.454780391467515

Epoch: 5| Step: 3
Training loss: 1.9181970357894897
Validation loss: 2.428934069089992

Epoch: 5| Step: 4
Training loss: 3.068175792694092
Validation loss: 2.4106719801502843

Epoch: 5| Step: 5
Training loss: 2.7580888271331787
Validation loss: 2.4181898896412184

Epoch: 5| Step: 6
Training loss: 2.5775880813598633
Validation loss: 2.4175556013661046

Epoch: 5| Step: 7
Training loss: 2.5950043201446533
Validation loss: 2.4204660384885726

Epoch: 5| Step: 8
Training loss: 2.295687437057495
Validation loss: 2.4212257541635984

Epoch: 5| Step: 9
Training loss: 2.5417237281799316
Validation loss: 2.4248486334277737

Epoch: 5| Step: 10
Training loss: 2.19172739982605
Validation loss: 2.4276029884174304

Epoch: 22| Step: 0
Training loss: 2.979498863220215
Validation loss: 2.4339267515367076

Epoch: 5| Step: 1
Training loss: 2.7872111797332764
Validation loss: 2.4444022024831464

Epoch: 5| Step: 2
Training loss: 2.5276331901550293
Validation loss: 2.4369906456239763

Epoch: 5| Step: 3
Training loss: 1.940036416053772
Validation loss: 2.4138377122981574

Epoch: 5| Step: 4
Training loss: 2.3841137886047363
Validation loss: 2.4103392683049685

Epoch: 5| Step: 5
Training loss: 2.6789870262145996
Validation loss: 2.4053694663509244

Epoch: 5| Step: 6
Training loss: 3.3581840991973877
Validation loss: 2.399614667379728

Epoch: 5| Step: 7
Training loss: 3.0289909839630127
Validation loss: 2.4026694297790527

Epoch: 5| Step: 8
Training loss: 2.215756893157959
Validation loss: 2.4111000901909283

Epoch: 5| Step: 9
Training loss: 2.1778035163879395
Validation loss: 2.411751085712064

Epoch: 5| Step: 10
Training loss: 3.412342071533203
Validation loss: 2.417661977070634

Epoch: 23| Step: 0
Training loss: 2.323589324951172
Validation loss: 2.424202339623564

Epoch: 5| Step: 1
Training loss: 2.7558834552764893
Validation loss: 2.4414674133382817

Epoch: 5| Step: 2
Training loss: 3.3302090167999268
Validation loss: 2.4598152586208877

Epoch: 5| Step: 3
Training loss: 2.655188798904419
Validation loss: 2.4397986832485405

Epoch: 5| Step: 4
Training loss: 2.436379909515381
Validation loss: 2.4095895444193194

Epoch: 5| Step: 5
Training loss: 2.9432883262634277
Validation loss: 2.4003697723470707

Epoch: 5| Step: 6
Training loss: 2.100363254547119
Validation loss: 2.3850483304710797

Epoch: 5| Step: 7
Training loss: 2.372954845428467
Validation loss: 2.3783103971071142

Epoch: 5| Step: 8
Training loss: 2.433532238006592
Validation loss: 2.370958599992978

Epoch: 5| Step: 9
Training loss: 2.848292589187622
Validation loss: 2.3663978371568906

Epoch: 5| Step: 10
Training loss: 3.1679587364196777
Validation loss: 2.3613589707241265

Epoch: 24| Step: 0
Training loss: 3.3796756267547607
Validation loss: 2.36758662808326

Epoch: 5| Step: 1
Training loss: 2.426625967025757
Validation loss: 2.362511316935221

Epoch: 5| Step: 2
Training loss: 3.026442527770996
Validation loss: 2.360062719673239

Epoch: 5| Step: 3
Training loss: 2.3407459259033203
Validation loss: 2.3584451547233005

Epoch: 5| Step: 4
Training loss: 3.1655380725860596
Validation loss: 2.3594674705177225

Epoch: 5| Step: 5
Training loss: 2.258023738861084
Validation loss: 2.3557272213761524

Epoch: 5| Step: 6
Training loss: 2.500840663909912
Validation loss: 2.355570100968884

Epoch: 5| Step: 7
Training loss: 2.5990843772888184
Validation loss: 2.355141367963565

Epoch: 5| Step: 8
Training loss: 2.581587553024292
Validation loss: 2.357339648790257

Epoch: 5| Step: 9
Training loss: 2.256969451904297
Validation loss: 2.37582593066718

Epoch: 5| Step: 10
Training loss: 2.4555046558380127
Validation loss: 2.384505917949061

Epoch: 25| Step: 0
Training loss: 2.8184940814971924
Validation loss: 2.388677256081694

Epoch: 5| Step: 1
Training loss: 2.73160457611084
Validation loss: 2.377524939916467

Epoch: 5| Step: 2
Training loss: 1.9665924310684204
Validation loss: 2.3564239701917096

Epoch: 5| Step: 3
Training loss: 2.7873425483703613
Validation loss: 2.344904399687244

Epoch: 5| Step: 4
Training loss: 2.888774871826172
Validation loss: 2.3364059873806533

Epoch: 5| Step: 5
Training loss: 2.256441116333008
Validation loss: 2.3404281831556752

Epoch: 5| Step: 6
Training loss: 2.326718807220459
Validation loss: 2.340701618502217

Epoch: 5| Step: 7
Training loss: 3.273392915725708
Validation loss: 2.3445780200342976

Epoch: 5| Step: 8
Training loss: 2.682331085205078
Validation loss: 2.3438821454201975

Epoch: 5| Step: 9
Training loss: 2.567732810974121
Validation loss: 2.34891083932692

Epoch: 5| Step: 10
Training loss: 2.8312485218048096
Validation loss: 2.358015775680542

Epoch: 26| Step: 0
Training loss: 2.8344459533691406
Validation loss: 2.3656418605517318

Epoch: 5| Step: 1
Training loss: 2.403958797454834
Validation loss: 2.380010353621616

Epoch: 5| Step: 2
Training loss: 3.3516247272491455
Validation loss: 2.426404571020475

Epoch: 5| Step: 3
Training loss: 2.8994333744049072
Validation loss: 2.413864645906674

Epoch: 5| Step: 4
Training loss: 2.697446823120117
Validation loss: 2.385797808247228

Epoch: 5| Step: 5
Training loss: 2.6324713230133057
Validation loss: 2.3526276311566754

Epoch: 5| Step: 6
Training loss: 2.3671040534973145
Validation loss: 2.3372361429276003

Epoch: 5| Step: 7
Training loss: 2.7020809650421143
Validation loss: 2.3341077989147556

Epoch: 5| Step: 8
Training loss: 2.349331855773926
Validation loss: 2.336600588214013

Epoch: 5| Step: 9
Training loss: 2.1735386848449707
Validation loss: 2.3353936492755847

Epoch: 5| Step: 10
Training loss: 2.4950790405273438
Validation loss: 2.332786862568189

Epoch: 27| Step: 0
Training loss: 2.585935592651367
Validation loss: 2.3344395955403647

Epoch: 5| Step: 1
Training loss: 2.721635341644287
Validation loss: 2.333476766463249

Epoch: 5| Step: 2
Training loss: 2.6408514976501465
Validation loss: 2.330540516043222

Epoch: 5| Step: 3
Training loss: 2.388056993484497
Validation loss: 2.333714421077441

Epoch: 5| Step: 4
Training loss: 2.3898377418518066
Validation loss: 2.332023484732515

Epoch: 5| Step: 5
Training loss: 2.0096640586853027
Validation loss: 2.335916103855256

Epoch: 5| Step: 6
Training loss: 2.4388954639434814
Validation loss: 2.3598483941888295

Epoch: 5| Step: 7
Training loss: 2.303006649017334
Validation loss: 2.3555965679948048

Epoch: 5| Step: 8
Training loss: 3.144782543182373
Validation loss: 2.362165104958319

Epoch: 5| Step: 9
Training loss: 2.994957208633423
Validation loss: 2.34774419312836

Epoch: 5| Step: 10
Training loss: 3.2447171211242676
Validation loss: 2.3212356336655153

Epoch: 28| Step: 0
Training loss: 1.7833009958267212
Validation loss: 2.3182759900246896

Epoch: 5| Step: 1
Training loss: 2.5626235008239746
Validation loss: 2.3172614471886748

Epoch: 5| Step: 2
Training loss: 2.975494861602783
Validation loss: 2.319932819694601

Epoch: 5| Step: 3
Training loss: 2.1284549236297607
Validation loss: 2.314988761819819

Epoch: 5| Step: 4
Training loss: 3.0882863998413086
Validation loss: 2.315170649559267

Epoch: 5| Step: 5
Training loss: 2.5439629554748535
Validation loss: 2.316019214609618

Epoch: 5| Step: 6
Training loss: 2.6403725147247314
Validation loss: 2.3251178008253857

Epoch: 5| Step: 7
Training loss: 2.6659271717071533
Validation loss: 2.3403901002740346

Epoch: 5| Step: 8
Training loss: 2.539527177810669
Validation loss: 2.3567139256385063

Epoch: 5| Step: 9
Training loss: 3.173797607421875
Validation loss: 2.397975501193795

Epoch: 5| Step: 10
Training loss: 2.6507015228271484
Validation loss: 2.3600444562973513

Epoch: 29| Step: 0
Training loss: 2.5904688835144043
Validation loss: 2.331349972755678

Epoch: 5| Step: 1
Training loss: 2.514153003692627
Validation loss: 2.310078231237268

Epoch: 5| Step: 2
Training loss: 2.9568259716033936
Validation loss: 2.3118409187563005

Epoch: 5| Step: 3
Training loss: 2.6079790592193604
Validation loss: 2.314951099375243

Epoch: 5| Step: 4
Training loss: 2.2774453163146973
Validation loss: 2.3219661943374144

Epoch: 5| Step: 5
Training loss: 2.8908843994140625
Validation loss: 2.3334373504884782

Epoch: 5| Step: 6
Training loss: 2.491258144378662
Validation loss: 2.3643452377729517

Epoch: 5| Step: 7
Training loss: 2.835440158843994
Validation loss: 2.325809583869032

Epoch: 5| Step: 8
Training loss: 2.7474522590637207
Validation loss: 2.3133038474667456

Epoch: 5| Step: 9
Training loss: 2.1878859996795654
Validation loss: 2.305790803765738

Epoch: 5| Step: 10
Training loss: 2.6428260803222656
Validation loss: 2.307404041290283

Epoch: 30| Step: 0
Training loss: 2.1579298973083496
Validation loss: 2.30723669452052

Epoch: 5| Step: 1
Training loss: 3.37372088432312
Validation loss: 2.3036134037920224

Epoch: 5| Step: 2
Training loss: 2.470834255218506
Validation loss: 2.305706577916299

Epoch: 5| Step: 3
Training loss: 2.6004085540771484
Validation loss: 2.3075183668444232

Epoch: 5| Step: 4
Training loss: 2.4469051361083984
Validation loss: 2.309487271052535

Epoch: 5| Step: 5
Training loss: 3.185774326324463
Validation loss: 2.306918751808905

Epoch: 5| Step: 6
Training loss: 2.7689170837402344
Validation loss: 2.30227263768514

Epoch: 5| Step: 7
Training loss: 2.2051100730895996
Validation loss: 2.3100289529369724

Epoch: 5| Step: 8
Training loss: 2.0708980560302734
Validation loss: 2.3108876982042865

Epoch: 5| Step: 9
Training loss: 2.4643986225128174
Validation loss: 2.3202990742139917

Epoch: 5| Step: 10
Training loss: 2.665597915649414
Validation loss: 2.3592502532466764

Epoch: 31| Step: 0
Training loss: 2.5030784606933594
Validation loss: 2.445705077981436

Epoch: 5| Step: 1
Training loss: 2.759878158569336
Validation loss: 2.472293661486718

Epoch: 5| Step: 2
Training loss: 2.525034189224243
Validation loss: 2.4263318943720993

Epoch: 5| Step: 3
Training loss: 2.614689588546753
Validation loss: 2.365921225599063

Epoch: 5| Step: 4
Training loss: 2.694823980331421
Validation loss: 2.32408247968202

Epoch: 5| Step: 5
Training loss: 2.455716609954834
Validation loss: 2.297846463418776

Epoch: 5| Step: 6
Training loss: 2.2020816802978516
Validation loss: 2.2911894270168838

Epoch: 5| Step: 7
Training loss: 3.1060798168182373
Validation loss: 2.298343802011141

Epoch: 5| Step: 8
Training loss: 2.1366753578186035
Validation loss: 2.313627730133713

Epoch: 5| Step: 9
Training loss: 3.048757553100586
Validation loss: 2.3165932650207193

Epoch: 5| Step: 10
Training loss: 2.8392763137817383
Validation loss: 2.3139237998634257

Epoch: 32| Step: 0
Training loss: 2.4699082374572754
Validation loss: 2.3130558690717145

Epoch: 5| Step: 1
Training loss: 2.308216094970703
Validation loss: 2.308898530980592

Epoch: 5| Step: 2
Training loss: 2.399231433868408
Validation loss: 2.3044173435498307

Epoch: 5| Step: 3
Training loss: 2.814936876296997
Validation loss: 2.302709407703851

Epoch: 5| Step: 4
Training loss: 3.0938589572906494
Validation loss: 2.3093285740062757

Epoch: 5| Step: 5
Training loss: 2.6680779457092285
Validation loss: 2.3037575983232066

Epoch: 5| Step: 6
Training loss: 2.765103816986084
Validation loss: 2.2923609697690575

Epoch: 5| Step: 7
Training loss: 2.5196919441223145
Validation loss: 2.298375360427364

Epoch: 5| Step: 8
Training loss: 1.5373985767364502
Validation loss: 2.3079829113457793

Epoch: 5| Step: 9
Training loss: 3.2038016319274902
Validation loss: 2.340533284730809

Epoch: 5| Step: 10
Training loss: 2.842275619506836
Validation loss: 2.3708627198332097

Epoch: 33| Step: 0
Training loss: 2.3053345680236816
Validation loss: 2.4384186998490365

Epoch: 5| Step: 1
Training loss: 2.216629981994629
Validation loss: 2.5341390896868963

Epoch: 5| Step: 2
Training loss: 2.352687120437622
Validation loss: 2.564065638408866

Epoch: 5| Step: 3
Training loss: 2.5114855766296387
Validation loss: 2.535322750768354

Epoch: 5| Step: 4
Training loss: 3.253859758377075
Validation loss: 2.484728092788368

Epoch: 5| Step: 5
Training loss: 2.745110034942627
Validation loss: 2.41425685985114

Epoch: 5| Step: 6
Training loss: 2.5994420051574707
Validation loss: 2.3618438679684877

Epoch: 5| Step: 7
Training loss: 3.093903064727783
Validation loss: 2.3477920537353842

Epoch: 5| Step: 8
Training loss: 2.925036907196045
Validation loss: 2.38049074398574

Epoch: 5| Step: 9
Training loss: 2.726520299911499
Validation loss: 2.3914211667994016

Epoch: 5| Step: 10
Training loss: 2.5878121852874756
Validation loss: 2.4009062756774244

Epoch: 34| Step: 0
Training loss: 2.5876364707946777
Validation loss: 2.3412717029612553

Epoch: 5| Step: 1
Training loss: 2.3324661254882812
Validation loss: 2.2911029887455765

Epoch: 5| Step: 2
Training loss: 2.619948625564575
Validation loss: 2.268898901119027

Epoch: 5| Step: 3
Training loss: 2.975583553314209
Validation loss: 2.273161244648759

Epoch: 5| Step: 4
Training loss: 2.6630380153656006
Validation loss: 2.3226016054871264

Epoch: 5| Step: 5
Training loss: 2.622464656829834
Validation loss: 2.3845762770663024

Epoch: 5| Step: 6
Training loss: 2.8922677040100098
Validation loss: 2.405131827118576

Epoch: 5| Step: 7
Training loss: 2.581733465194702
Validation loss: 2.397333668124291

Epoch: 5| Step: 8
Training loss: 2.571004629135132
Validation loss: 2.3341594537099204

Epoch: 5| Step: 9
Training loss: 2.9090421199798584
Validation loss: 2.2966779765262397

Epoch: 5| Step: 10
Training loss: 2.199948310852051
Validation loss: 2.270520449966513

Epoch: 35| Step: 0
Training loss: 2.406813621520996
Validation loss: 2.266253632883872

Epoch: 5| Step: 1
Training loss: 2.392059087753296
Validation loss: 2.264805369479682

Epoch: 5| Step: 2
Training loss: 1.9197629690170288
Validation loss: 2.270698437126734

Epoch: 5| Step: 3
Training loss: 2.3999781608581543
Validation loss: 2.282548127635833

Epoch: 5| Step: 4
Training loss: 2.8383712768554688
Validation loss: 2.2807012475946897

Epoch: 5| Step: 5
Training loss: 2.679166555404663
Validation loss: 2.2782396501110447

Epoch: 5| Step: 6
Training loss: 2.9789819717407227
Validation loss: 2.2826643425931215

Epoch: 5| Step: 7
Training loss: 2.6536755561828613
Validation loss: 2.2892929841113347

Epoch: 5| Step: 8
Training loss: 2.5043931007385254
Validation loss: 2.2911138278181835

Epoch: 5| Step: 9
Training loss: 2.116980791091919
Validation loss: 2.295051013269732

Epoch: 5| Step: 10
Training loss: 3.453223466873169
Validation loss: 2.2917849248455417

Epoch: 36| Step: 0
Training loss: 1.8729593753814697
Validation loss: 2.295116300223976

Epoch: 5| Step: 1
Training loss: 3.227095127105713
Validation loss: 2.2869510727543987

Epoch: 5| Step: 2
Training loss: 2.350567579269409
Validation loss: 2.267158205791186

Epoch: 5| Step: 3
Training loss: 2.2017014026641846
Validation loss: 2.2522131012332056

Epoch: 5| Step: 4
Training loss: 2.565140962600708
Validation loss: 2.248105264479114

Epoch: 5| Step: 5
Training loss: 2.194361448287964
Validation loss: 2.2461742970251266

Epoch: 5| Step: 6
Training loss: 2.55320405960083
Validation loss: 2.2501300637440016

Epoch: 5| Step: 7
Training loss: 2.897648334503174
Validation loss: 2.245349089304606

Epoch: 5| Step: 8
Training loss: 2.8290212154388428
Validation loss: 2.244894653238276

Epoch: 5| Step: 9
Training loss: 2.947883367538452
Validation loss: 2.245479740122313

Epoch: 5| Step: 10
Training loss: 2.703444004058838
Validation loss: 2.245044195523826

Epoch: 37| Step: 0
Training loss: 2.8323476314544678
Validation loss: 2.251355194276379

Epoch: 5| Step: 1
Training loss: 2.530099391937256
Validation loss: 2.261220770497476

Epoch: 5| Step: 2
Training loss: 1.7498096227645874
Validation loss: 2.262918365898953

Epoch: 5| Step: 3
Training loss: 2.268092632293701
Validation loss: 2.2830707949976765

Epoch: 5| Step: 4
Training loss: 2.9691078662872314
Validation loss: 2.290002094802036

Epoch: 5| Step: 5
Training loss: 2.7296814918518066
Validation loss: 2.2886997063954673

Epoch: 5| Step: 6
Training loss: 2.6885828971862793
Validation loss: 2.2810770183481197

Epoch: 5| Step: 7
Training loss: 2.7083754539489746
Validation loss: 2.2689958977442917

Epoch: 5| Step: 8
Training loss: 2.8503501415252686
Validation loss: 2.2658052777731292

Epoch: 5| Step: 9
Training loss: 2.5754220485687256
Validation loss: 2.2535086883011686

Epoch: 5| Step: 10
Training loss: 2.099235773086548
Validation loss: 2.247888121553647

Epoch: 38| Step: 0
Training loss: 2.389190912246704
Validation loss: 2.251126338076848

Epoch: 5| Step: 1
Training loss: 2.21820330619812
Validation loss: 2.2427306816142094

Epoch: 5| Step: 2
Training loss: 2.9468042850494385
Validation loss: 2.234437342612974

Epoch: 5| Step: 3
Training loss: 2.7348530292510986
Validation loss: 2.236717877849456

Epoch: 5| Step: 4
Training loss: 2.5102219581604004
Validation loss: 2.241464699468305

Epoch: 5| Step: 5
Training loss: 2.238680362701416
Validation loss: 2.235694063607083

Epoch: 5| Step: 6
Training loss: 2.5133321285247803
Validation loss: 2.236928338645607

Epoch: 5| Step: 7
Training loss: 2.829801321029663
Validation loss: 2.2381736283661215

Epoch: 5| Step: 8
Training loss: 2.657463312149048
Validation loss: 2.2377292238255984

Epoch: 5| Step: 9
Training loss: 2.8365044593811035
Validation loss: 2.238158133722121

Epoch: 5| Step: 10
Training loss: 2.025202989578247
Validation loss: 2.2457592436062392

Epoch: 39| Step: 0
Training loss: 2.6419355869293213
Validation loss: 2.248445515991539

Epoch: 5| Step: 1
Training loss: 2.3823776245117188
Validation loss: 2.2638307258646977

Epoch: 5| Step: 2
Training loss: 2.5828187465667725
Validation loss: 2.300036266285886

Epoch: 5| Step: 3
Training loss: 2.9954519271850586
Validation loss: 2.308603589252759

Epoch: 5| Step: 4
Training loss: 2.1386330127716064
Validation loss: 2.3310820556456044

Epoch: 5| Step: 5
Training loss: 3.091031312942505
Validation loss: 2.3318901241466565

Epoch: 5| Step: 6
Training loss: 2.3068058490753174
Validation loss: 2.3298167951645388

Epoch: 5| Step: 7
Training loss: 2.1398444175720215
Validation loss: 2.3013721281482327

Epoch: 5| Step: 8
Training loss: 2.5322999954223633
Validation loss: 2.2781461925916773

Epoch: 5| Step: 9
Training loss: 1.9516853094100952
Validation loss: 2.255024597208987

Epoch: 5| Step: 10
Training loss: 3.2880704402923584
Validation loss: 2.2330013321292017

Epoch: 40| Step: 0
Training loss: 2.203078269958496
Validation loss: 2.224217173873737

Epoch: 5| Step: 1
Training loss: 2.946903705596924
Validation loss: 2.2227202692339496

Epoch: 5| Step: 2
Training loss: 2.788278579711914
Validation loss: 2.220848365496564

Epoch: 5| Step: 3
Training loss: 3.2464098930358887
Validation loss: 2.227565094988833

Epoch: 5| Step: 4
Training loss: 2.593301296234131
Validation loss: 2.222856706188571

Epoch: 5| Step: 5
Training loss: 2.4040133953094482
Validation loss: 2.2220139144569315

Epoch: 5| Step: 6
Training loss: 2.9551022052764893
Validation loss: 2.219172008575932

Epoch: 5| Step: 7
Training loss: 2.3661751747131348
Validation loss: 2.2152812686017764

Epoch: 5| Step: 8
Training loss: 1.7710927724838257
Validation loss: 2.215255856513977

Epoch: 5| Step: 9
Training loss: 2.2088334560394287
Validation loss: 2.2303907819973525

Epoch: 5| Step: 10
Training loss: 2.5833067893981934
Validation loss: 2.260041691923654

Epoch: 41| Step: 0
Training loss: 2.3728268146514893
Validation loss: 2.281109981639411

Epoch: 5| Step: 1
Training loss: 2.2951207160949707
Validation loss: 2.265608681145535

Epoch: 5| Step: 2
Training loss: 2.7748403549194336
Validation loss: 2.262188526891893

Epoch: 5| Step: 3
Training loss: 2.6052985191345215
Validation loss: 2.2773008013284333

Epoch: 5| Step: 4
Training loss: 2.421034574508667
Validation loss: 2.2594100300983717

Epoch: 5| Step: 5
Training loss: 2.3793888092041016
Validation loss: 2.2337354434433805

Epoch: 5| Step: 6
Training loss: 2.3680102825164795
Validation loss: 2.230010353108888

Epoch: 5| Step: 7
Training loss: 2.6220858097076416
Validation loss: 2.2263970169969785

Epoch: 5| Step: 8
Training loss: 2.3928370475769043
Validation loss: 2.2245259054245485

Epoch: 5| Step: 9
Training loss: 2.7053351402282715
Validation loss: 2.2203148206075034

Epoch: 5| Step: 10
Training loss: 2.951204299926758
Validation loss: 2.213699589493454

Epoch: 42| Step: 0
Training loss: 2.6955411434173584
Validation loss: 2.2156434700053227

Epoch: 5| Step: 1
Training loss: 2.5180280208587646
Validation loss: 2.2103021273048977

Epoch: 5| Step: 2
Training loss: 2.918652057647705
Validation loss: 2.20513948445679

Epoch: 5| Step: 3
Training loss: 2.6568970680236816
Validation loss: 2.2056757557776665

Epoch: 5| Step: 4
Training loss: 2.155148983001709
Validation loss: 2.2088144004985852

Epoch: 5| Step: 5
Training loss: 2.1499104499816895
Validation loss: 2.2041772437352005

Epoch: 5| Step: 6
Training loss: 2.791168689727783
Validation loss: 2.2082193359251945

Epoch: 5| Step: 7
Training loss: 2.4467363357543945
Validation loss: 2.2094478889178206

Epoch: 5| Step: 8
Training loss: 2.7282803058624268
Validation loss: 2.209945691529141

Epoch: 5| Step: 9
Training loss: 2.0740039348602295
Validation loss: 2.218015673340008

Epoch: 5| Step: 10
Training loss: 2.5952301025390625
Validation loss: 2.215253517191897

Epoch: 43| Step: 0
Training loss: 2.852189064025879
Validation loss: 2.221868727796821

Epoch: 5| Step: 1
Training loss: 2.306392192840576
Validation loss: 2.2295329852770736

Epoch: 5| Step: 2
Training loss: 2.0943169593811035
Validation loss: 2.2312548378462433

Epoch: 5| Step: 3
Training loss: 2.2015957832336426
Validation loss: 2.243586850422685

Epoch: 5| Step: 4
Training loss: 2.6208584308624268
Validation loss: 2.25781233849064

Epoch: 5| Step: 5
Training loss: 2.574373722076416
Validation loss: 2.275672217851044

Epoch: 5| Step: 6
Training loss: 2.903587818145752
Validation loss: 2.2584450501267628

Epoch: 5| Step: 7
Training loss: 2.6960203647613525
Validation loss: 2.241676915076471

Epoch: 5| Step: 8
Training loss: 2.519718885421753
Validation loss: 2.2261973991188952

Epoch: 5| Step: 9
Training loss: 2.492159128189087
Validation loss: 2.2001511332809285

Epoch: 5| Step: 10
Training loss: 2.518725633621216
Validation loss: 2.196740250433645

Epoch: 44| Step: 0
Training loss: 2.5147998332977295
Validation loss: 2.193089588995903

Epoch: 5| Step: 1
Training loss: 2.5479602813720703
Validation loss: 2.1921206699904574

Epoch: 5| Step: 2
Training loss: 3.243366241455078
Validation loss: 2.1925056390864874

Epoch: 5| Step: 3
Training loss: 2.4009737968444824
Validation loss: 2.18953461288124

Epoch: 5| Step: 4
Training loss: 2.521303653717041
Validation loss: 2.1918965462715394

Epoch: 5| Step: 5
Training loss: 2.8643298149108887
Validation loss: 2.192918808229508

Epoch: 5| Step: 6
Training loss: 2.0550949573516846
Validation loss: 2.19307715149336

Epoch: 5| Step: 7
Training loss: 2.355633020401001
Validation loss: 2.2120824577987834

Epoch: 5| Step: 8
Training loss: 2.1656153202056885
Validation loss: 2.232682943344116

Epoch: 5| Step: 9
Training loss: 2.7212796211242676
Validation loss: 2.2881496055151826

Epoch: 5| Step: 10
Training loss: 2.4273386001586914
Validation loss: 2.3277057114467827

Epoch: 45| Step: 0
Training loss: 3.289947509765625
Validation loss: 2.274327770356209

Epoch: 5| Step: 1
Training loss: 2.2072877883911133
Validation loss: 2.2208874225616455

Epoch: 5| Step: 2
Training loss: 2.590049982070923
Validation loss: 2.195286794375348

Epoch: 5| Step: 3
Training loss: 2.573171615600586
Validation loss: 2.188461426765688

Epoch: 5| Step: 4
Training loss: 2.242774248123169
Validation loss: 2.1878678798675537

Epoch: 5| Step: 5
Training loss: 2.304990291595459
Validation loss: 2.1837560258885866

Epoch: 5| Step: 6
Training loss: 2.057543992996216
Validation loss: 2.181927578423613

Epoch: 5| Step: 7
Training loss: 2.2608489990234375
Validation loss: 2.1798830852713635

Epoch: 5| Step: 8
Training loss: 2.9050495624542236
Validation loss: 2.1817848477312314

Epoch: 5| Step: 9
Training loss: 2.5300421714782715
Validation loss: 2.181784370894073

Epoch: 5| Step: 10
Training loss: 2.7078585624694824
Validation loss: 2.179308719532464

Epoch: 46| Step: 0
Training loss: 2.4996745586395264
Validation loss: 2.1801071397719847

Epoch: 5| Step: 1
Training loss: 2.3903324604034424
Validation loss: 2.177949477267522

Epoch: 5| Step: 2
Training loss: 2.673701763153076
Validation loss: 2.1846967961198542

Epoch: 5| Step: 3
Training loss: 2.9930615425109863
Validation loss: 2.188977474807411

Epoch: 5| Step: 4
Training loss: 2.3721389770507812
Validation loss: 2.212161676858061

Epoch: 5| Step: 5
Training loss: 2.4579434394836426
Validation loss: 2.2465487090490197

Epoch: 5| Step: 6
Training loss: 1.7703803777694702
Validation loss: 2.2607820187845538

Epoch: 5| Step: 7
Training loss: 2.5124030113220215
Validation loss: 2.267705991703977

Epoch: 5| Step: 8
Training loss: 2.709024667739868
Validation loss: 2.255347430065114

Epoch: 5| Step: 9
Training loss: 2.647993564605713
Validation loss: 2.251910589074576

Epoch: 5| Step: 10
Training loss: 2.6877665519714355
Validation loss: 2.235380421402634

Epoch: 47| Step: 0
Training loss: 2.593916893005371
Validation loss: 2.216320868461363

Epoch: 5| Step: 1
Training loss: 1.652928113937378
Validation loss: 2.19999663547803

Epoch: 5| Step: 2
Training loss: 2.82247257232666
Validation loss: 2.1893171751370994

Epoch: 5| Step: 3
Training loss: 2.4786360263824463
Validation loss: 2.18025037037429

Epoch: 5| Step: 4
Training loss: 3.1786537170410156
Validation loss: 2.1812537613735405

Epoch: 5| Step: 5
Training loss: 2.6056971549987793
Validation loss: 2.1855062207868023

Epoch: 5| Step: 6
Training loss: 2.505082130432129
Validation loss: 2.190813587557885

Epoch: 5| Step: 7
Training loss: 2.1682796478271484
Validation loss: 2.193762702326621

Epoch: 5| Step: 8
Training loss: 2.838404655456543
Validation loss: 2.185647428676646

Epoch: 5| Step: 9
Training loss: 2.1668782234191895
Validation loss: 2.183950452394383

Epoch: 5| Step: 10
Training loss: 2.684756278991699
Validation loss: 2.186394697876387

Epoch: 48| Step: 0
Training loss: 2.3621346950531006
Validation loss: 2.203157542854227

Epoch: 5| Step: 1
Training loss: 2.378296375274658
Validation loss: 2.2291235231584117

Epoch: 5| Step: 2
Training loss: 3.0217788219451904
Validation loss: 2.2657172500446277

Epoch: 5| Step: 3
Training loss: 2.3974368572235107
Validation loss: 2.264441841392107

Epoch: 5| Step: 4
Training loss: 3.0544819831848145
Validation loss: 2.3002911793288363

Epoch: 5| Step: 5
Training loss: 2.7798593044281006
Validation loss: 2.3161743789590816

Epoch: 5| Step: 6
Training loss: 1.720889687538147
Validation loss: 2.279657333127914

Epoch: 5| Step: 7
Training loss: 2.663726568222046
Validation loss: 2.2500171802377187

Epoch: 5| Step: 8
Training loss: 2.350144147872925
Validation loss: 2.2002478286784184

Epoch: 5| Step: 9
Training loss: 2.12084698677063
Validation loss: 2.176043495055168

Epoch: 5| Step: 10
Training loss: 2.8093464374542236
Validation loss: 2.1640058358510337

Epoch: 49| Step: 0
Training loss: 2.3557801246643066
Validation loss: 2.161826732338116

Epoch: 5| Step: 1
Training loss: 2.631028413772583
Validation loss: 2.1627930313028316

Epoch: 5| Step: 2
Training loss: 2.2250442504882812
Validation loss: 2.163469955485354

Epoch: 5| Step: 3
Training loss: 2.7095115184783936
Validation loss: 2.1583218536069317

Epoch: 5| Step: 4
Training loss: 2.9722533226013184
Validation loss: 2.1599001128186464

Epoch: 5| Step: 5
Training loss: 2.310091018676758
Validation loss: 2.1574227168995845

Epoch: 5| Step: 6
Training loss: 2.3662514686584473
Validation loss: 2.1528170621523293

Epoch: 5| Step: 7
Training loss: 2.58478045463562
Validation loss: 2.143675499064948

Epoch: 5| Step: 8
Training loss: 2.5814762115478516
Validation loss: 2.1459865313704296

Epoch: 5| Step: 9
Training loss: 2.5979723930358887
Validation loss: 2.1659115565720426

Epoch: 5| Step: 10
Training loss: 2.0832784175872803
Validation loss: 2.184996892047185

Epoch: 50| Step: 0
Training loss: 2.316087007522583
Validation loss: 2.2216181062882945

Epoch: 5| Step: 1
Training loss: 2.0609376430511475
Validation loss: 2.2350548915965582

Epoch: 5| Step: 2
Training loss: 2.396742582321167
Validation loss: 2.2311570208559752

Epoch: 5| Step: 3
Training loss: 2.755964517593384
Validation loss: 2.230125969456088

Epoch: 5| Step: 4
Training loss: 2.997697114944458
Validation loss: 2.2423992618437736

Epoch: 5| Step: 5
Training loss: 2.042560577392578
Validation loss: 2.2271157605673677

Epoch: 5| Step: 6
Training loss: 2.769545078277588
Validation loss: 2.2007625692634174

Epoch: 5| Step: 7
Training loss: 2.4608168601989746
Validation loss: 2.165180975391019

Epoch: 5| Step: 8
Training loss: 2.3070199489593506
Validation loss: 2.145423114940684

Epoch: 5| Step: 9
Training loss: 2.685490846633911
Validation loss: 2.1396414695247525

Epoch: 5| Step: 10
Training loss: 2.5581166744232178
Validation loss: 2.1353462191038233

Epoch: 51| Step: 0
Training loss: 2.0378050804138184
Validation loss: 2.1427491429031535

Epoch: 5| Step: 1
Training loss: 2.304427146911621
Validation loss: 2.1469894839871313

Epoch: 5| Step: 2
Training loss: 3.1252071857452393
Validation loss: 2.1476081494362123

Epoch: 5| Step: 3
Training loss: 2.0106515884399414
Validation loss: 2.1492929663709415

Epoch: 5| Step: 4
Training loss: 2.927119255065918
Validation loss: 2.147042373175262

Epoch: 5| Step: 5
Training loss: 2.1117217540740967
Validation loss: 2.1415754466928463

Epoch: 5| Step: 6
Training loss: 2.5556640625
Validation loss: 2.140856335240026

Epoch: 5| Step: 7
Training loss: 2.9926984310150146
Validation loss: 2.1375521511159916

Epoch: 5| Step: 8
Training loss: 3.102820634841919
Validation loss: 2.1443106461596746

Epoch: 5| Step: 9
Training loss: 2.539358139038086
Validation loss: 2.144731794634173

Epoch: 5| Step: 10
Training loss: 1.684402346611023
Validation loss: 2.1605410729685137

Epoch: 52| Step: 0
Training loss: 2.6283841133117676
Validation loss: 2.194800474310434

Epoch: 5| Step: 1
Training loss: 1.8790857791900635
Validation loss: 2.252883808587187

Epoch: 5| Step: 2
Training loss: 3.0521063804626465
Validation loss: 2.3281565686707855

Epoch: 5| Step: 3
Training loss: 2.442713975906372
Validation loss: 2.335699604403588

Epoch: 5| Step: 4
Training loss: 2.5761897563934326
Validation loss: 2.2841805437559723

Epoch: 5| Step: 5
Training loss: 2.7502729892730713
Validation loss: 2.2351665343007734

Epoch: 5| Step: 6
Training loss: 3.107952117919922
Validation loss: 2.197500580100603

Epoch: 5| Step: 7
Training loss: 1.830190658569336
Validation loss: 2.1696566830399218

Epoch: 5| Step: 8
Training loss: 2.593066692352295
Validation loss: 2.1417666378841607

Epoch: 5| Step: 9
Training loss: 1.9718806743621826
Validation loss: 2.130799933146405

Epoch: 5| Step: 10
Training loss: 2.663241386413574
Validation loss: 2.119598232289796

Epoch: 53| Step: 0
Training loss: 2.74650502204895
Validation loss: 2.120598639211347

Epoch: 5| Step: 1
Training loss: 2.6192100048065186
Validation loss: 2.1229086793879026

Epoch: 5| Step: 2
Training loss: 2.630121946334839
Validation loss: 2.1226177420667423

Epoch: 5| Step: 3
Training loss: 2.308326244354248
Validation loss: 2.119535005220803

Epoch: 5| Step: 4
Training loss: 1.8479785919189453
Validation loss: 2.118832434377363

Epoch: 5| Step: 5
Training loss: 2.5433859825134277
Validation loss: 2.1103621452085433

Epoch: 5| Step: 6
Training loss: 2.5733389854431152
Validation loss: 2.1144332475559686

Epoch: 5| Step: 7
Training loss: 2.9098269939422607
Validation loss: 2.110009362620692

Epoch: 5| Step: 8
Training loss: 2.2242071628570557
Validation loss: 2.114981225741807

Epoch: 5| Step: 9
Training loss: 2.5209591388702393
Validation loss: 2.139070740310095

Epoch: 5| Step: 10
Training loss: 2.203544855117798
Validation loss: 2.1678839947587702

Epoch: 54| Step: 0
Training loss: 3.315277099609375
Validation loss: 2.1833746356348835

Epoch: 5| Step: 1
Training loss: 2.222623348236084
Validation loss: 2.2253533306942193

Epoch: 5| Step: 2
Training loss: 2.1399216651916504
Validation loss: 2.227769156937958

Epoch: 5| Step: 3
Training loss: 2.958138942718506
Validation loss: 2.2204267337758052

Epoch: 5| Step: 4
Training loss: 2.398312568664551
Validation loss: 2.178171883347214

Epoch: 5| Step: 5
Training loss: 2.086555004119873
Validation loss: 2.1409591949114235

Epoch: 5| Step: 6
Training loss: 2.8112316131591797
Validation loss: 2.0997182117995394

Epoch: 5| Step: 7
Training loss: 2.2306840419769287
Validation loss: 2.0915866180132796

Epoch: 5| Step: 8
Training loss: 2.1046130657196045
Validation loss: 2.0928037628050773

Epoch: 5| Step: 9
Training loss: 2.4298863410949707
Validation loss: 2.0884709255669707

Epoch: 5| Step: 10
Training loss: 2.600149631500244
Validation loss: 2.0918100059673352

Epoch: 55| Step: 0
Training loss: 2.971200942993164
Validation loss: 2.08847701421348

Epoch: 5| Step: 1
Training loss: 2.318979501724243
Validation loss: 2.095133496868995

Epoch: 5| Step: 2
Training loss: 2.7106144428253174
Validation loss: 2.1008431706377255

Epoch: 5| Step: 3
Training loss: 2.242924213409424
Validation loss: 2.1122428524878716

Epoch: 5| Step: 4
Training loss: 2.91845965385437
Validation loss: 2.1198648278431227

Epoch: 5| Step: 5
Training loss: 2.457540988922119
Validation loss: 2.1375483287278043

Epoch: 5| Step: 6
Training loss: 2.5846381187438965
Validation loss: 2.132340241503972

Epoch: 5| Step: 7
Training loss: 2.5046732425689697
Validation loss: 2.120552319352345

Epoch: 5| Step: 8
Training loss: 2.67616605758667
Validation loss: 2.1073842112736036

Epoch: 5| Step: 9
Training loss: 1.6240602731704712
Validation loss: 2.116618974234468

Epoch: 5| Step: 10
Training loss: 1.9318652153015137
Validation loss: 2.114236016427317

Epoch: 56| Step: 0
Training loss: 2.242130994796753
Validation loss: 2.116255262846588

Epoch: 5| Step: 1
Training loss: 1.9717200994491577
Validation loss: 2.1110724479921403

Epoch: 5| Step: 2
Training loss: 2.796323299407959
Validation loss: 2.106781695478706

Epoch: 5| Step: 3
Training loss: 2.7211241722106934
Validation loss: 2.1003197508473552

Epoch: 5| Step: 4
Training loss: 2.6536786556243896
Validation loss: 2.1092177155197307

Epoch: 5| Step: 5
Training loss: 2.1930980682373047
Validation loss: 2.1065181250213296

Epoch: 5| Step: 6
Training loss: 2.008784055709839
Validation loss: 2.110137765125562

Epoch: 5| Step: 7
Training loss: 2.5425448417663574
Validation loss: 2.1065020048490135

Epoch: 5| Step: 8
Training loss: 2.286369562149048
Validation loss: 2.110079803774434

Epoch: 5| Step: 9
Training loss: 2.6368870735168457
Validation loss: 2.127249381875479

Epoch: 5| Step: 10
Training loss: 2.906352996826172
Validation loss: 2.140332575767271

Epoch: 57| Step: 0
Training loss: 2.7507760524749756
Validation loss: 2.1305152011174027

Epoch: 5| Step: 1
Training loss: 3.1301803588867188
Validation loss: 2.1073610423713602

Epoch: 5| Step: 2
Training loss: 2.9270853996276855
Validation loss: 2.0980733774041616

Epoch: 5| Step: 3
Training loss: 2.1532397270202637
Validation loss: 2.09007849231843

Epoch: 5| Step: 4
Training loss: 2.4643826484680176
Validation loss: 2.0916791385219944

Epoch: 5| Step: 5
Training loss: 2.8710532188415527
Validation loss: 2.0962003405376146

Epoch: 5| Step: 6
Training loss: 1.8202216625213623
Validation loss: 2.0960004714227494

Epoch: 5| Step: 7
Training loss: 2.4836864471435547
Validation loss: 2.0990987234218146

Epoch: 5| Step: 8
Training loss: 1.8529856204986572
Validation loss: 2.1025558453734203

Epoch: 5| Step: 9
Training loss: 2.101097822189331
Validation loss: 2.101358223986882

Epoch: 5| Step: 10
Training loss: 2.2489826679229736
Validation loss: 2.0942607720692954

Epoch: 58| Step: 0
Training loss: 2.3141064643859863
Validation loss: 2.092720139411188

Epoch: 5| Step: 1
Training loss: 2.7440123558044434
Validation loss: 2.09451199090609

Epoch: 5| Step: 2
Training loss: 2.038510799407959
Validation loss: 2.0924890143896944

Epoch: 5| Step: 3
Training loss: 2.038536548614502
Validation loss: 2.0958190054021855

Epoch: 5| Step: 4
Training loss: 2.8296561241149902
Validation loss: 2.1005109074295207

Epoch: 5| Step: 5
Training loss: 2.198171377182007
Validation loss: 2.0924695396936066

Epoch: 5| Step: 6
Training loss: 2.6109814643859863
Validation loss: 2.0878344684518795

Epoch: 5| Step: 7
Training loss: 2.662376880645752
Validation loss: 2.090642834222445

Epoch: 5| Step: 8
Training loss: 2.484437942504883
Validation loss: 2.0870401038918445

Epoch: 5| Step: 9
Training loss: 2.661036968231201
Validation loss: 2.0878802358463244

Epoch: 5| Step: 10
Training loss: 2.1963188648223877
Validation loss: 2.089538692146219

Epoch: 59| Step: 0
Training loss: 2.7376046180725098
Validation loss: 2.08493604711307

Epoch: 5| Step: 1
Training loss: 2.6266987323760986
Validation loss: 2.0917731895241687

Epoch: 5| Step: 2
Training loss: 2.5851569175720215
Validation loss: 2.092494854363062

Epoch: 5| Step: 3
Training loss: 2.6742312908172607
Validation loss: 2.0915442743609027

Epoch: 5| Step: 4
Training loss: 2.573828935623169
Validation loss: 2.1093207815642

Epoch: 5| Step: 5
Training loss: 2.054152727127075
Validation loss: 2.126885239795972

Epoch: 5| Step: 6
Training loss: 3.058004856109619
Validation loss: 2.1594402661887546

Epoch: 5| Step: 7
Training loss: 2.6041367053985596
Validation loss: 2.1615318303467124

Epoch: 5| Step: 8
Training loss: 1.386312484741211
Validation loss: 2.16877164635607

Epoch: 5| Step: 9
Training loss: 2.8080496788024902
Validation loss: 2.179394539966378

Epoch: 5| Step: 10
Training loss: 1.542744517326355
Validation loss: 2.1561109263409852

Epoch: 60| Step: 0
Training loss: 1.773611307144165
Validation loss: 2.1233976861482025

Epoch: 5| Step: 1
Training loss: 2.480377674102783
Validation loss: 2.1157710911125265

Epoch: 5| Step: 2
Training loss: 2.1923911571502686
Validation loss: 2.1097431516134613

Epoch: 5| Step: 3
Training loss: 1.377748966217041
Validation loss: 2.100573601261262

Epoch: 5| Step: 4
Training loss: 2.5067358016967773
Validation loss: 2.091962024729739

Epoch: 5| Step: 5
Training loss: 2.4986681938171387
Validation loss: 2.084931783778693

Epoch: 5| Step: 6
Training loss: 2.38053822517395
Validation loss: 2.0864539659151466

Epoch: 5| Step: 7
Training loss: 2.233523368835449
Validation loss: 2.080868115989111

Epoch: 5| Step: 8
Training loss: 2.674262046813965
Validation loss: 2.0837436568352485

Epoch: 5| Step: 9
Training loss: 3.155561923980713
Validation loss: 2.083323060825307

Epoch: 5| Step: 10
Training loss: 3.5983760356903076
Validation loss: 2.0807690440967517

Epoch: 61| Step: 0
Training loss: 2.1549768447875977
Validation loss: 2.0876330893526793

Epoch: 5| Step: 1
Training loss: 2.9158012866973877
Validation loss: 2.095152470373338

Epoch: 5| Step: 2
Training loss: 2.5693485736846924
Validation loss: 2.125346529868341

Epoch: 5| Step: 3
Training loss: 2.3194196224212646
Validation loss: 2.14439062405658

Epoch: 5| Step: 4
Training loss: 2.881178140640259
Validation loss: 2.1783728086820213

Epoch: 5| Step: 5
Training loss: 3.0229618549346924
Validation loss: 2.1925438424592376

Epoch: 5| Step: 6
Training loss: 2.8761496543884277
Validation loss: 2.1946620761707263

Epoch: 5| Step: 7
Training loss: 2.0324692726135254
Validation loss: 2.1455955710462344

Epoch: 5| Step: 8
Training loss: 1.880707025527954
Validation loss: 2.1154776747508715

Epoch: 5| Step: 9
Training loss: 1.7078899145126343
Validation loss: 2.075610949147132

Epoch: 5| Step: 10
Training loss: 2.3063597679138184
Validation loss: 2.0581202481382634

Epoch: 62| Step: 0
Training loss: 2.6776633262634277
Validation loss: 2.0639112046969834

Epoch: 5| Step: 1
Training loss: 2.3234825134277344
Validation loss: 2.077695673511874

Epoch: 5| Step: 2
Training loss: 2.6203091144561768
Validation loss: 2.086630569991245

Epoch: 5| Step: 3
Training loss: 2.856300115585327
Validation loss: 2.0906745156934186

Epoch: 5| Step: 4
Training loss: 2.0321717262268066
Validation loss: 2.0891993199625323

Epoch: 5| Step: 5
Training loss: 2.2135732173919678
Validation loss: 2.0972079487257105

Epoch: 5| Step: 6
Training loss: 2.473217010498047
Validation loss: 2.094938926799323

Epoch: 5| Step: 7
Training loss: 2.5539534091949463
Validation loss: 2.089871286064066

Epoch: 5| Step: 8
Training loss: 2.5414912700653076
Validation loss: 2.0784227143051806

Epoch: 5| Step: 9
Training loss: 2.1699626445770264
Validation loss: 2.072951668052263

Epoch: 5| Step: 10
Training loss: 2.643582582473755
Validation loss: 2.087072269890898

Epoch: 63| Step: 0
Training loss: 2.2134854793548584
Validation loss: 2.1153002400552072

Epoch: 5| Step: 1
Training loss: 1.7120201587677002
Validation loss: 2.1476631241460002

Epoch: 5| Step: 2
Training loss: 2.5719776153564453
Validation loss: 2.2085646993370465

Epoch: 5| Step: 3
Training loss: 2.6813175678253174
Validation loss: 2.2517644897583993

Epoch: 5| Step: 4
Training loss: 2.9659576416015625
Validation loss: 2.2868698156008156

Epoch: 5| Step: 5
Training loss: 2.214909791946411
Validation loss: 2.2585934490285893

Epoch: 5| Step: 6
Training loss: 2.218207836151123
Validation loss: 2.225899814277567

Epoch: 5| Step: 7
Training loss: 2.878011703491211
Validation loss: 2.161149240309192

Epoch: 5| Step: 8
Training loss: 2.6858763694763184
Validation loss: 2.1197029006096626

Epoch: 5| Step: 9
Training loss: 2.584794521331787
Validation loss: 2.0962060754017164

Epoch: 5| Step: 10
Training loss: 2.224259376525879
Validation loss: 2.071371422019056

Epoch: 64| Step: 0
Training loss: 3.5264594554901123
Validation loss: 2.0630649751232517

Epoch: 5| Step: 1
Training loss: 2.455444812774658
Validation loss: 2.054787649903246

Epoch: 5| Step: 2
Training loss: 2.864091396331787
Validation loss: 2.0567278259543964

Epoch: 5| Step: 3
Training loss: 1.957457184791565
Validation loss: 2.057579744246698

Epoch: 5| Step: 4
Training loss: 2.161224365234375
Validation loss: 2.0582657065442813

Epoch: 5| Step: 5
Training loss: 2.7805893421173096
Validation loss: 2.055097573546953

Epoch: 5| Step: 6
Training loss: 2.316742420196533
Validation loss: 2.057700621184482

Epoch: 5| Step: 7
Training loss: 2.359693765640259
Validation loss: 2.057745525913854

Epoch: 5| Step: 8
Training loss: 2.0078396797180176
Validation loss: 2.067651876839258

Epoch: 5| Step: 9
Training loss: 2.0694355964660645
Validation loss: 2.0878089525366343

Epoch: 5| Step: 10
Training loss: 2.0958480834960938
Validation loss: 2.1170549161972536

Epoch: 65| Step: 0
Training loss: 2.404329776763916
Validation loss: 2.1463196380164034

Epoch: 5| Step: 1
Training loss: 1.8695310354232788
Validation loss: 2.153899513265138

Epoch: 5| Step: 2
Training loss: 2.82774019241333
Validation loss: 2.1397998256068074

Epoch: 5| Step: 3
Training loss: 2.18194842338562
Validation loss: 2.096883617421632

Epoch: 5| Step: 4
Training loss: 2.049980401992798
Validation loss: 2.083328136833765

Epoch: 5| Step: 5
Training loss: 3.2139668464660645
Validation loss: 2.061279559648165

Epoch: 5| Step: 6
Training loss: 2.1233069896698
Validation loss: 2.0521288251364105

Epoch: 5| Step: 7
Training loss: 2.676745653152466
Validation loss: 2.049668340272801

Epoch: 5| Step: 8
Training loss: 2.271644115447998
Validation loss: 2.0499441880051807

Epoch: 5| Step: 9
Training loss: 2.604365587234497
Validation loss: 2.050987507707329

Epoch: 5| Step: 10
Training loss: 2.3087871074676514
Validation loss: 2.062359707329863

Epoch: 66| Step: 0
Training loss: 2.1492056846618652
Validation loss: 2.0598130841409006

Epoch: 5| Step: 1
Training loss: 2.1162142753601074
Validation loss: 2.059267524750002

Epoch: 5| Step: 2
Training loss: 2.8443896770477295
Validation loss: 2.0672189394632974

Epoch: 5| Step: 3
Training loss: 1.9294418096542358
Validation loss: 2.0704047449173464

Epoch: 5| Step: 4
Training loss: 2.9422125816345215
Validation loss: 2.090499113964778

Epoch: 5| Step: 5
Training loss: 2.3511040210723877
Validation loss: 2.136893126272386

Epoch: 5| Step: 6
Training loss: 2.77823805809021
Validation loss: 2.1831257266383015

Epoch: 5| Step: 7
Training loss: 2.9443039894104004
Validation loss: 2.181095496300728

Epoch: 5| Step: 8
Training loss: 2.599010944366455
Validation loss: 2.1201071572560135

Epoch: 5| Step: 9
Training loss: 2.028327465057373
Validation loss: 2.091984466839862

Epoch: 5| Step: 10
Training loss: 1.6876429319381714
Validation loss: 2.0704647828173894

Epoch: 67| Step: 0
Training loss: 2.6386210918426514
Validation loss: 2.064386567761821

Epoch: 5| Step: 1
Training loss: 2.07763671875
Validation loss: 2.062242087497506

Epoch: 5| Step: 2
Training loss: 2.0011744499206543
Validation loss: 2.058482341868903

Epoch: 5| Step: 3
Training loss: 2.3342299461364746
Validation loss: 2.0789024291499967

Epoch: 5| Step: 4
Training loss: 2.7674174308776855
Validation loss: 2.0875390627050914

Epoch: 5| Step: 5
Training loss: 2.368675470352173
Validation loss: 2.101369155350552

Epoch: 5| Step: 6
Training loss: 2.325155735015869
Validation loss: 2.1004890703385874

Epoch: 5| Step: 7
Training loss: 2.5504062175750732
Validation loss: 2.117308529474402

Epoch: 5| Step: 8
Training loss: 2.091639280319214
Validation loss: 2.1193914644179808

Epoch: 5| Step: 9
Training loss: 2.7373390197753906
Validation loss: 2.1051321183481524

Epoch: 5| Step: 10
Training loss: 2.599916458129883
Validation loss: 2.078684801696449

Epoch: 68| Step: 0
Training loss: 2.2379937171936035
Validation loss: 2.064495410970462

Epoch: 5| Step: 1
Training loss: 2.6150028705596924
Validation loss: 2.0580571697604273

Epoch: 5| Step: 2
Training loss: 2.2590575218200684
Validation loss: 2.0490877064325477

Epoch: 5| Step: 3
Training loss: 2.3707292079925537
Validation loss: 2.0474421811360184

Epoch: 5| Step: 4
Training loss: 2.6124885082244873
Validation loss: 2.0526221490675405

Epoch: 5| Step: 5
Training loss: 2.7279765605926514
Validation loss: 2.0665553628757434

Epoch: 5| Step: 6
Training loss: 1.9939510822296143
Validation loss: 2.0722119295468895

Epoch: 5| Step: 7
Training loss: 2.156572103500366
Validation loss: 2.0587002961866316

Epoch: 5| Step: 8
Training loss: 2.533318042755127
Validation loss: 2.054863219620079

Epoch: 5| Step: 9
Training loss: 2.4539780616760254
Validation loss: 2.0517467811543453

Epoch: 5| Step: 10
Training loss: 2.3023252487182617
Validation loss: 2.041555163680866

Epoch: 69| Step: 0
Training loss: 3.171788215637207
Validation loss: 2.0457182391997306

Epoch: 5| Step: 1
Training loss: 1.7103157043457031
Validation loss: 2.0488536934698782

Epoch: 5| Step: 2
Training loss: 1.8405475616455078
Validation loss: 2.042356679516454

Epoch: 5| Step: 3
Training loss: 2.545201539993286
Validation loss: 2.043984046546362

Epoch: 5| Step: 4
Training loss: 3.0554230213165283
Validation loss: 2.056619054527693

Epoch: 5| Step: 5
Training loss: 2.1266632080078125
Validation loss: 2.06603269679572

Epoch: 5| Step: 6
Training loss: 2.2844157218933105
Validation loss: 2.0732744547628585

Epoch: 5| Step: 7
Training loss: 2.629499912261963
Validation loss: 2.0760290263801493

Epoch: 5| Step: 8
Training loss: 2.7183454036712646
Validation loss: 2.07615162480262

Epoch: 5| Step: 9
Training loss: 1.950015664100647
Validation loss: 2.076188584809662

Epoch: 5| Step: 10
Training loss: 2.0079264640808105
Validation loss: 2.0786635029700493

Epoch: 70| Step: 0
Training loss: 3.1207218170166016
Validation loss: 2.0817381502479635

Epoch: 5| Step: 1
Training loss: 2.5719752311706543
Validation loss: 2.073569425972559

Epoch: 5| Step: 2
Training loss: 1.992452621459961
Validation loss: 2.058408634636992

Epoch: 5| Step: 3
Training loss: 1.910256028175354
Validation loss: 2.0609742364575787

Epoch: 5| Step: 4
Training loss: 2.8506922721862793
Validation loss: 2.056438663954376

Epoch: 5| Step: 5
Training loss: 2.2209434509277344
Validation loss: 2.069531986790319

Epoch: 5| Step: 6
Training loss: 2.368773937225342
Validation loss: 2.0665641535994825

Epoch: 5| Step: 7
Training loss: 2.1220245361328125
Validation loss: 2.0583084629428003

Epoch: 5| Step: 8
Training loss: 2.6263818740844727
Validation loss: 2.0441082651897142

Epoch: 5| Step: 9
Training loss: 2.2661890983581543
Validation loss: 2.047105825075539

Epoch: 5| Step: 10
Training loss: 1.9781314134597778
Validation loss: 2.038204680206955

Epoch: 71| Step: 0
Training loss: 2.287966251373291
Validation loss: 2.03763150143367

Epoch: 5| Step: 1
Training loss: 2.4148173332214355
Validation loss: 2.0518411410752164

Epoch: 5| Step: 2
Training loss: 2.0310676097869873
Validation loss: 2.066247676008491

Epoch: 5| Step: 3
Training loss: 2.178070068359375
Validation loss: 2.0644986039848736

Epoch: 5| Step: 4
Training loss: 2.0781188011169434
Validation loss: 2.0658314304967083

Epoch: 5| Step: 5
Training loss: 1.5015723705291748
Validation loss: 2.0498724906675276

Epoch: 5| Step: 6
Training loss: 2.5556232929229736
Validation loss: 2.0280526966177006

Epoch: 5| Step: 7
Training loss: 1.9708788394927979
Validation loss: 2.0197840711121917

Epoch: 5| Step: 8
Training loss: 2.9148917198181152
Validation loss: 2.014421434812648

Epoch: 5| Step: 9
Training loss: 3.2189669609069824
Validation loss: 2.0226035682103967

Epoch: 5| Step: 10
Training loss: 3.0057780742645264
Validation loss: 2.025564867963073

Epoch: 72| Step: 0
Training loss: 2.1737046241760254
Validation loss: 2.02636557497004

Epoch: 5| Step: 1
Training loss: 1.6040008068084717
Validation loss: 2.0240692579618065

Epoch: 5| Step: 2
Training loss: 2.4716134071350098
Validation loss: 2.0230672410739365

Epoch: 5| Step: 3
Training loss: 2.096892833709717
Validation loss: 2.0311372626212334

Epoch: 5| Step: 4
Training loss: 3.076986789703369
Validation loss: 2.0410398552494664

Epoch: 5| Step: 5
Training loss: 2.1935677528381348
Validation loss: 2.0493446883334907

Epoch: 5| Step: 6
Training loss: 2.1693642139434814
Validation loss: 2.081548801032446

Epoch: 5| Step: 7
Training loss: 2.47161865234375
Validation loss: 2.112216129097887

Epoch: 5| Step: 8
Training loss: 2.806431531906128
Validation loss: 2.1089357842681227

Epoch: 5| Step: 9
Training loss: 2.8261566162109375
Validation loss: 2.0841427669730237

Epoch: 5| Step: 10
Training loss: 2.2502634525299072
Validation loss: 2.056126240761049

Epoch: 73| Step: 0
Training loss: 2.2618155479431152
Validation loss: 2.046119515613843

Epoch: 5| Step: 1
Training loss: 2.61979603767395
Validation loss: 2.046507872560973

Epoch: 5| Step: 2
Training loss: 2.2859268188476562
Validation loss: 2.0334892221676406

Epoch: 5| Step: 3
Training loss: 2.184699535369873
Validation loss: 2.030419031778971

Epoch: 5| Step: 4
Training loss: 1.8734546899795532
Validation loss: 2.0298864174914617

Epoch: 5| Step: 5
Training loss: 2.545313596725464
Validation loss: 2.0250764149491505

Epoch: 5| Step: 6
Training loss: 2.3321125507354736
Validation loss: 2.0269023269735356

Epoch: 5| Step: 7
Training loss: 2.7482521533966064
Validation loss: 2.038844952019312

Epoch: 5| Step: 8
Training loss: 2.173521041870117
Validation loss: 2.0488227823729157

Epoch: 5| Step: 9
Training loss: 2.2948672771453857
Validation loss: 2.059024098098919

Epoch: 5| Step: 10
Training loss: 2.648266553878784
Validation loss: 2.074887693569224

Epoch: 74| Step: 0
Training loss: 2.245814085006714
Validation loss: 2.100105616354173

Epoch: 5| Step: 1
Training loss: 2.1124138832092285
Validation loss: 2.126544015381926

Epoch: 5| Step: 2
Training loss: 2.6006462574005127
Validation loss: 2.1294116179148355

Epoch: 5| Step: 3
Training loss: 2.302649974822998
Validation loss: 2.121823451852286

Epoch: 5| Step: 4
Training loss: 2.074125289916992
Validation loss: 2.0606541838697208

Epoch: 5| Step: 5
Training loss: 2.8080825805664062
Validation loss: 2.0333781203915997

Epoch: 5| Step: 6
Training loss: 2.5217323303222656
Validation loss: 2.0162441474135204

Epoch: 5| Step: 7
Training loss: 2.617772102355957
Validation loss: 2.003243513004754

Epoch: 5| Step: 8
Training loss: 2.4052789211273193
Validation loss: 2.0020069563260643

Epoch: 5| Step: 9
Training loss: 2.308797836303711
Validation loss: 2.008462941774758

Epoch: 5| Step: 10
Training loss: 1.7992769479751587
Validation loss: 2.008067164369809

Epoch: 75| Step: 0
Training loss: 2.226545810699463
Validation loss: 2.007811562989348

Epoch: 5| Step: 1
Training loss: 2.6802189350128174
Validation loss: 2.0068266084117274

Epoch: 5| Step: 2
Training loss: 2.2435288429260254
Validation loss: 2.0010226900859545

Epoch: 5| Step: 3
Training loss: 2.1792805194854736
Validation loss: 2.000769320354667

Epoch: 5| Step: 4
Training loss: 2.1475908756256104
Validation loss: 2.004573714348578

Epoch: 5| Step: 5
Training loss: 2.741331100463867
Validation loss: 2.010825830121194

Epoch: 5| Step: 6
Training loss: 3.0899546146392822
Validation loss: 2.039629581154034

Epoch: 5| Step: 7
Training loss: 2.334627151489258
Validation loss: 2.0676815061159033

Epoch: 5| Step: 8
Training loss: 1.7765995264053345
Validation loss: 2.0959257028436147

Epoch: 5| Step: 9
Training loss: 2.302823305130005
Validation loss: 2.106323142205515

Epoch: 5| Step: 10
Training loss: 2.4768309593200684
Validation loss: 2.0742655377234183

Epoch: 76| Step: 0
Training loss: 1.952368140220642
Validation loss: 2.0512329365617488

Epoch: 5| Step: 1
Training loss: 2.431385040283203
Validation loss: 2.0218713873176166

Epoch: 5| Step: 2
Training loss: 2.6734249591827393
Validation loss: 2.018990873008646

Epoch: 5| Step: 3
Training loss: 2.351296901702881
Validation loss: 2.02050337483806

Epoch: 5| Step: 4
Training loss: 2.585867404937744
Validation loss: 2.0080639649462957

Epoch: 5| Step: 5
Training loss: 2.485555648803711
Validation loss: 2.0080798838728215

Epoch: 5| Step: 6
Training loss: 2.5229456424713135
Validation loss: 2.007387449664454

Epoch: 5| Step: 7
Training loss: 2.216170072555542
Validation loss: 2.000805370269283

Epoch: 5| Step: 8
Training loss: 1.4340198040008545
Validation loss: 2.0092792818623204

Epoch: 5| Step: 9
Training loss: 2.6838417053222656
Validation loss: 2.022475516924294

Epoch: 5| Step: 10
Training loss: 2.540660858154297
Validation loss: 2.0328734984961887

Epoch: 77| Step: 0
Training loss: 2.659519910812378
Validation loss: 2.053259536784182

Epoch: 5| Step: 1
Training loss: 2.722886562347412
Validation loss: 2.0781502390420563

Epoch: 5| Step: 2
Training loss: 2.167239189147949
Validation loss: 2.11630767391574

Epoch: 5| Step: 3
Training loss: 2.575706958770752
Validation loss: 2.157860327792424

Epoch: 5| Step: 4
Training loss: 2.7147626876831055
Validation loss: 2.1384279548480944

Epoch: 5| Step: 5
Training loss: 2.377462387084961
Validation loss: 2.094869887957009

Epoch: 5| Step: 6
Training loss: 2.3299684524536133
Validation loss: 2.076765993589996

Epoch: 5| Step: 7
Training loss: 2.300034999847412
Validation loss: 2.0585965802592616

Epoch: 5| Step: 8
Training loss: 1.9606965780258179
Validation loss: 2.0375915791398738

Epoch: 5| Step: 9
Training loss: 2.211440324783325
Validation loss: 2.0227402602472613

Epoch: 5| Step: 10
Training loss: 1.7692956924438477
Validation loss: 2.018200789728472

Epoch: 78| Step: 0
Training loss: 2.2174177169799805
Validation loss: 2.014213433829687

Epoch: 5| Step: 1
Training loss: 1.7956836223602295
Validation loss: 2.0181654755787184

Epoch: 5| Step: 2
Training loss: 2.339259624481201
Validation loss: 2.0114908936203166

Epoch: 5| Step: 3
Training loss: 2.264991521835327
Validation loss: 2.0285441362729637

Epoch: 5| Step: 4
Training loss: 2.3645973205566406
Validation loss: 2.048386263590987

Epoch: 5| Step: 5
Training loss: 2.5351104736328125
Validation loss: 2.110021116913006

Epoch: 5| Step: 6
Training loss: 2.7989368438720703
Validation loss: 2.1969029493229364

Epoch: 5| Step: 7
Training loss: 2.5629048347473145
Validation loss: 2.2030184345860637

Epoch: 5| Step: 8
Training loss: 2.237469434738159
Validation loss: 2.1510900233381536

Epoch: 5| Step: 9
Training loss: 2.2854275703430176
Validation loss: 2.1156588344163794

Epoch: 5| Step: 10
Training loss: 2.687575340270996
Validation loss: 2.0715590882044967

Epoch: 79| Step: 0
Training loss: 2.369884490966797
Validation loss: 2.0390669043346117

Epoch: 5| Step: 1
Training loss: 2.201125144958496
Validation loss: 2.020909345278176

Epoch: 5| Step: 2
Training loss: 2.1004226207733154
Validation loss: 2.009541529481129

Epoch: 5| Step: 3
Training loss: 2.5328540802001953
Validation loss: 2.0102793183377994

Epoch: 5| Step: 4
Training loss: 3.08943510055542
Validation loss: 2.011359650601623

Epoch: 5| Step: 5
Training loss: 2.76194429397583
Validation loss: 2.011545455583962

Epoch: 5| Step: 6
Training loss: 2.351546287536621
Validation loss: 2.006439201293453

Epoch: 5| Step: 7
Training loss: 1.6937267780303955
Validation loss: 2.000947363914982

Epoch: 5| Step: 8
Training loss: 2.132483720779419
Validation loss: 2.007755676905314

Epoch: 5| Step: 9
Training loss: 2.33874773979187
Validation loss: 2.0235679380355345

Epoch: 5| Step: 10
Training loss: 1.8584953546524048
Validation loss: 2.0483848869159655

Epoch: 80| Step: 0
Training loss: 2.386357069015503
Validation loss: 2.0864920346967635

Epoch: 5| Step: 1
Training loss: 2.844358444213867
Validation loss: 2.1326567485768306

Epoch: 5| Step: 2
Training loss: 2.6518394947052
Validation loss: 2.175830030954012

Epoch: 5| Step: 3
Training loss: 2.6491076946258545
Validation loss: 2.177593900311378

Epoch: 5| Step: 4
Training loss: 2.575596570968628
Validation loss: 2.095914574079616

Epoch: 5| Step: 5
Training loss: 1.4570746421813965
Validation loss: 2.0283437364844867

Epoch: 5| Step: 6
Training loss: 3.1126253604888916
Validation loss: 2.006233151241015

Epoch: 5| Step: 7
Training loss: 1.900518774986267
Validation loss: 2.0107222398122153

Epoch: 5| Step: 8
Training loss: 2.249268054962158
Validation loss: 2.0077122603693316

Epoch: 5| Step: 9
Training loss: 2.3309366703033447
Validation loss: 2.01552382592232

Epoch: 5| Step: 10
Training loss: 1.72837233543396
Validation loss: 2.015241712652227

Epoch: 81| Step: 0
Training loss: 1.9265083074569702
Validation loss: 2.0119628444794686

Epoch: 5| Step: 1
Training loss: 2.101087808609009
Validation loss: 2.008035652099117

Epoch: 5| Step: 2
Training loss: 2.604724884033203
Validation loss: 1.994034118549798

Epoch: 5| Step: 3
Training loss: 2.6674091815948486
Validation loss: 2.000073366267707

Epoch: 5| Step: 4
Training loss: 2.3489060401916504
Validation loss: 2.0068050712667485

Epoch: 5| Step: 5
Training loss: 2.6946053504943848
Validation loss: 2.062572593330055

Epoch: 5| Step: 6
Training loss: 2.0621063709259033
Validation loss: 2.110360619842365

Epoch: 5| Step: 7
Training loss: 2.6131818294525146
Validation loss: 2.167012978625554

Epoch: 5| Step: 8
Training loss: 2.972973346710205
Validation loss: 2.1814648720525924

Epoch: 5| Step: 9
Training loss: 1.8068424463272095
Validation loss: 2.15846235265014

Epoch: 5| Step: 10
Training loss: 1.863930583000183
Validation loss: 2.1321641142650316

Epoch: 82| Step: 0
Training loss: 2.5043113231658936
Validation loss: 2.0994029916742796

Epoch: 5| Step: 1
Training loss: 2.2177505493164062
Validation loss: 2.0454970008583477

Epoch: 5| Step: 2
Training loss: 1.675405502319336
Validation loss: 2.012195018029982

Epoch: 5| Step: 3
Training loss: 2.445793867111206
Validation loss: 1.9903059467192619

Epoch: 5| Step: 4
Training loss: 2.654120683670044
Validation loss: 1.9869395827734342

Epoch: 5| Step: 5
Training loss: 2.8079652786254883
Validation loss: 1.9823411049381379

Epoch: 5| Step: 6
Training loss: 2.0509724617004395
Validation loss: 1.9833109378814697

Epoch: 5| Step: 7
Training loss: 2.1561038494110107
Validation loss: 1.9848848901769167

Epoch: 5| Step: 8
Training loss: 2.2095510959625244
Validation loss: 1.989052414894104

Epoch: 5| Step: 9
Training loss: 2.523888111114502
Validation loss: 1.9901889075515091

Epoch: 5| Step: 10
Training loss: 2.3100523948669434
Validation loss: 1.9897823897741174

Epoch: 83| Step: 0
Training loss: 2.756946086883545
Validation loss: 1.981911305458315

Epoch: 5| Step: 1
Training loss: 2.684727191925049
Validation loss: 1.9847463369369507

Epoch: 5| Step: 2
Training loss: 2.301783800125122
Validation loss: 1.9856637549656693

Epoch: 5| Step: 3
Training loss: 1.990825891494751
Validation loss: 1.995822145092872

Epoch: 5| Step: 4
Training loss: 2.2213358879089355
Validation loss: 2.017270343278044

Epoch: 5| Step: 5
Training loss: 2.467961072921753
Validation loss: 2.055894764520789

Epoch: 5| Step: 6
Training loss: 1.6091651916503906
Validation loss: 2.0369791869194276

Epoch: 5| Step: 7
Training loss: 2.4676012992858887
Validation loss: 2.0253163204398206

Epoch: 5| Step: 8
Training loss: 1.811753511428833
Validation loss: 2.013239035042383

Epoch: 5| Step: 9
Training loss: 2.3527214527130127
Validation loss: 2.0020410745374617

Epoch: 5| Step: 10
Training loss: 3.009178876876831
Validation loss: 1.9860610449185936

Epoch: 84| Step: 0
Training loss: 2.2397096157073975
Validation loss: 1.9901243589257682

Epoch: 5| Step: 1
Training loss: 2.042454242706299
Validation loss: 1.9813450972239177

Epoch: 5| Step: 2
Training loss: 2.354140043258667
Validation loss: 1.983733670685881

Epoch: 5| Step: 3
Training loss: 2.5445358753204346
Validation loss: 1.9850612994163268

Epoch: 5| Step: 4
Training loss: 2.4439151287078857
Validation loss: 1.989035541011441

Epoch: 5| Step: 5
Training loss: 2.5637850761413574
Validation loss: 1.9897149455162786

Epoch: 5| Step: 6
Training loss: 2.1258158683776855
Validation loss: 1.993074172286577

Epoch: 5| Step: 7
Training loss: 1.817907691001892
Validation loss: 1.9955918506909442

Epoch: 5| Step: 8
Training loss: 1.9641876220703125
Validation loss: 2.003440997933829

Epoch: 5| Step: 9
Training loss: 2.4777774810791016
Validation loss: 2.0037796830618255

Epoch: 5| Step: 10
Training loss: 2.731231927871704
Validation loss: 2.0147120234786824

Epoch: 85| Step: 0
Training loss: 2.355435371398926
Validation loss: 2.0285778276381956

Epoch: 5| Step: 1
Training loss: 2.072272777557373
Validation loss: 2.035536958325294

Epoch: 5| Step: 2
Training loss: 2.6751394271850586
Validation loss: 2.0491849478854927

Epoch: 5| Step: 3
Training loss: 2.996189832687378
Validation loss: 2.0455039496062906

Epoch: 5| Step: 4
Training loss: 1.65982985496521
Validation loss: 2.041181433585382

Epoch: 5| Step: 5
Training loss: 2.4183146953582764
Validation loss: 2.052696863810221

Epoch: 5| Step: 6
Training loss: 1.99745774269104
Validation loss: 2.068209448168355

Epoch: 5| Step: 7
Training loss: 2.0287725925445557
Validation loss: 2.0852674027924896

Epoch: 5| Step: 8
Training loss: 2.2318105697631836
Validation loss: 2.0897191814197007

Epoch: 5| Step: 9
Training loss: 2.6392529010772705
Validation loss: 2.0586610878667524

Epoch: 5| Step: 10
Training loss: 2.3695805072784424
Validation loss: 2.0368862818646174

Epoch: 86| Step: 0
Training loss: 1.770981788635254
Validation loss: 2.0305447142611266

Epoch: 5| Step: 1
Training loss: 1.8811414241790771
Validation loss: 2.023393431017476

Epoch: 5| Step: 2
Training loss: 2.273019790649414
Validation loss: 2.0290043123306765

Epoch: 5| Step: 3
Training loss: 1.7451763153076172
Validation loss: 2.034435805454049

Epoch: 5| Step: 4
Training loss: 3.097972869873047
Validation loss: 2.0652792710129932

Epoch: 5| Step: 5
Training loss: 2.4818296432495117
Validation loss: 2.084164079799447

Epoch: 5| Step: 6
Training loss: 2.7596435546875
Validation loss: 2.126497140494726

Epoch: 5| Step: 7
Training loss: 2.6685779094696045
Validation loss: 2.1320735254595355

Epoch: 5| Step: 8
Training loss: 2.876267671585083
Validation loss: 2.1655987975417927

Epoch: 5| Step: 9
Training loss: 1.962802529335022
Validation loss: 2.178546526098764

Epoch: 5| Step: 10
Training loss: 2.088054656982422
Validation loss: 2.148314872095662

Epoch: 87| Step: 0
Training loss: 2.792825222015381
Validation loss: 2.10319411113698

Epoch: 5| Step: 1
Training loss: 2.057089328765869
Validation loss: 2.0866964273555304

Epoch: 5| Step: 2
Training loss: 2.8937716484069824
Validation loss: 2.032607852771718

Epoch: 5| Step: 3
Training loss: 1.7899665832519531
Validation loss: 2.0186972002829275

Epoch: 5| Step: 4
Training loss: 2.0223724842071533
Validation loss: 2.0278965452665925

Epoch: 5| Step: 5
Training loss: 2.176623821258545
Validation loss: 2.0439423617496284

Epoch: 5| Step: 6
Training loss: 1.7533843517303467
Validation loss: 2.0569882290337675

Epoch: 5| Step: 7
Training loss: 2.2379682064056396
Validation loss: 2.045650855187447

Epoch: 5| Step: 8
Training loss: 3.1197402477264404
Validation loss: 2.0175170398527578

Epoch: 5| Step: 9
Training loss: 2.007011890411377
Validation loss: 2.011279841904999

Epoch: 5| Step: 10
Training loss: 2.5142078399658203
Validation loss: 2.0262508648698048

Epoch: 88| Step: 0
Training loss: 2.0707695484161377
Validation loss: 2.0508576003454064

Epoch: 5| Step: 1
Training loss: 2.3520143032073975
Validation loss: 2.0819794798410065

Epoch: 5| Step: 2
Training loss: 2.636003017425537
Validation loss: 2.126905033665319

Epoch: 5| Step: 3
Training loss: 2.2209126949310303
Validation loss: 2.137706320772889

Epoch: 5| Step: 4
Training loss: 2.2104902267456055
Validation loss: 2.0992717512192263

Epoch: 5| Step: 5
Training loss: 2.554473876953125
Validation loss: 2.038266228091332

Epoch: 5| Step: 6
Training loss: 2.3130416870117188
Validation loss: 2.0260085431478356

Epoch: 5| Step: 7
Training loss: 1.9899940490722656
Validation loss: 2.0055004883837957

Epoch: 5| Step: 8
Training loss: 2.1710476875305176
Validation loss: 2.0011103050683134

Epoch: 5| Step: 9
Training loss: 1.9905080795288086
Validation loss: 1.9885223629654094

Epoch: 5| Step: 10
Training loss: 3.044285774230957
Validation loss: 1.9852833722227363

Epoch: 89| Step: 0
Training loss: 1.9905906915664673
Validation loss: 1.9889034237912906

Epoch: 5| Step: 1
Training loss: 3.0431454181671143
Validation loss: 1.9925427359919394

Epoch: 5| Step: 2
Training loss: 2.008838653564453
Validation loss: 2.0031573234065885

Epoch: 5| Step: 3
Training loss: 2.1849677562713623
Validation loss: 2.0100415522052395

Epoch: 5| Step: 4
Training loss: 2.1692163944244385
Validation loss: 1.9968281997147428

Epoch: 5| Step: 5
Training loss: 2.1848063468933105
Validation loss: 1.9963189658298288

Epoch: 5| Step: 6
Training loss: 2.351296901702881
Validation loss: 1.9861522143886936

Epoch: 5| Step: 7
Training loss: 2.2133007049560547
Validation loss: 1.9846915583456717

Epoch: 5| Step: 8
Training loss: 2.6906630992889404
Validation loss: 1.9860498943636495

Epoch: 5| Step: 9
Training loss: 2.1712377071380615
Validation loss: 2.0073398774670017

Epoch: 5| Step: 10
Training loss: 2.1263086795806885
Validation loss: 2.0316904514066634

Epoch: 90| Step: 0
Training loss: 2.1581733226776123
Validation loss: 2.07773934384828

Epoch: 5| Step: 1
Training loss: 2.5490100383758545
Validation loss: 2.1156074693126063

Epoch: 5| Step: 2
Training loss: 2.1431355476379395
Validation loss: 2.095844345708047

Epoch: 5| Step: 3
Training loss: 2.214252471923828
Validation loss: 2.0809952802555536

Epoch: 5| Step: 4
Training loss: 1.6725385189056396
Validation loss: 2.0632840305246334

Epoch: 5| Step: 5
Training loss: 2.333845376968384
Validation loss: 2.0345001015611874

Epoch: 5| Step: 6
Training loss: 2.2830162048339844
Validation loss: 2.0076259566891577

Epoch: 5| Step: 7
Training loss: 2.364811420440674
Validation loss: 1.9924351476853894

Epoch: 5| Step: 8
Training loss: 2.6732535362243652
Validation loss: 1.979497234026591

Epoch: 5| Step: 9
Training loss: 2.5611660480499268
Validation loss: 1.9693562087192331

Epoch: 5| Step: 10
Training loss: 2.225266218185425
Validation loss: 1.9717842366105767

Epoch: 91| Step: 0
Training loss: 2.663184642791748
Validation loss: 1.963848440877853

Epoch: 5| Step: 1
Training loss: 2.3694844245910645
Validation loss: 1.9645888651570966

Epoch: 5| Step: 2
Training loss: 2.1949620246887207
Validation loss: 1.9682089641530027

Epoch: 5| Step: 3
Training loss: 2.3717868328094482
Validation loss: 1.9750944183718773

Epoch: 5| Step: 4
Training loss: 1.6612516641616821
Validation loss: 1.9933153736975886

Epoch: 5| Step: 5
Training loss: 2.338848114013672
Validation loss: 2.0203910155962874

Epoch: 5| Step: 6
Training loss: 1.9862337112426758
Validation loss: 2.0541126305057156

Epoch: 5| Step: 7
Training loss: 2.3218891620635986
Validation loss: 2.0451257587761007

Epoch: 5| Step: 8
Training loss: 2.7531235218048096
Validation loss: 2.0533237149638515

Epoch: 5| Step: 9
Training loss: 2.286288022994995
Validation loss: 2.0520840088526406

Epoch: 5| Step: 10
Training loss: 1.9838351011276245
Validation loss: 2.0423808072202947

Epoch: 92| Step: 0
Training loss: 2.764923095703125
Validation loss: 2.0287075555452736

Epoch: 5| Step: 1
Training loss: 1.0557832717895508
Validation loss: 2.0143644181630944

Epoch: 5| Step: 2
Training loss: 2.7460241317749023
Validation loss: 1.995769444332328

Epoch: 5| Step: 3
Training loss: 2.3602044582366943
Validation loss: 1.9828727142785185

Epoch: 5| Step: 4
Training loss: 2.719708204269409
Validation loss: 1.9770832382222658

Epoch: 5| Step: 5
Training loss: 1.569318413734436
Validation loss: 1.9772777711191485

Epoch: 5| Step: 6
Training loss: 2.6718666553497314
Validation loss: 1.9707843821535829

Epoch: 5| Step: 7
Training loss: 2.2659811973571777
Validation loss: 1.9768724492801133

Epoch: 5| Step: 8
Training loss: 1.8829333782196045
Validation loss: 1.978741099757533

Epoch: 5| Step: 9
Training loss: 2.5674517154693604
Validation loss: 1.9828338187227967

Epoch: 5| Step: 10
Training loss: 2.103034734725952
Validation loss: 2.00899681480982

Epoch: 93| Step: 0
Training loss: 1.8316692113876343
Validation loss: 2.0361891126119964

Epoch: 5| Step: 1
Training loss: 2.6320457458496094
Validation loss: 2.044191404055524

Epoch: 5| Step: 2
Training loss: 2.235731840133667
Validation loss: 2.0666719790427917

Epoch: 5| Step: 3
Training loss: 2.4819350242614746
Validation loss: 2.067735928361134

Epoch: 5| Step: 4
Training loss: 2.428920030593872
Validation loss: 2.0671204110627532

Epoch: 5| Step: 5
Training loss: 1.5388565063476562
Validation loss: 2.0546654924269645

Epoch: 5| Step: 6
Training loss: 2.460413694381714
Validation loss: 2.045584258212838

Epoch: 5| Step: 7
Training loss: 2.589477300643921
Validation loss: 2.033637842824382

Epoch: 5| Step: 8
Training loss: 2.1462242603302
Validation loss: 2.0107639335816905

Epoch: 5| Step: 9
Training loss: 2.1966917514801025
Validation loss: 2.0037751364451584

Epoch: 5| Step: 10
Training loss: 2.239838123321533
Validation loss: 1.99370067093962

Epoch: 94| Step: 0
Training loss: 2.577014207839966
Validation loss: 1.9833439370637298

Epoch: 5| Step: 1
Training loss: 2.3709750175476074
Validation loss: 1.9837738160164125

Epoch: 5| Step: 2
Training loss: 2.3448760509490967
Validation loss: 1.9733021079853017

Epoch: 5| Step: 3
Training loss: 1.9132111072540283
Validation loss: 1.9764462696608676

Epoch: 5| Step: 4
Training loss: 1.7884536981582642
Validation loss: 1.9762236328535183

Epoch: 5| Step: 5
Training loss: 2.3912482261657715
Validation loss: 1.97819931532747

Epoch: 5| Step: 6
Training loss: 1.9799102544784546
Validation loss: 1.9814684057748446

Epoch: 5| Step: 7
Training loss: 2.068279504776001
Validation loss: 1.9953542499132053

Epoch: 5| Step: 8
Training loss: 2.4964475631713867
Validation loss: 2.008101817100279

Epoch: 5| Step: 9
Training loss: 2.3341870307922363
Validation loss: 2.0361471663239183

Epoch: 5| Step: 10
Training loss: 2.5442066192626953
Validation loss: 2.0453315640008576

Epoch: 95| Step: 0
Training loss: 1.6573985815048218
Validation loss: 2.040477859076633

Epoch: 5| Step: 1
Training loss: 1.6417226791381836
Validation loss: 2.0081214045965545

Epoch: 5| Step: 2
Training loss: 2.3350656032562256
Validation loss: 1.9874275833047845

Epoch: 5| Step: 3
Training loss: 2.16631817817688
Validation loss: 1.9674987921150782

Epoch: 5| Step: 4
Training loss: 2.7201154232025146
Validation loss: 1.9533284723117788

Epoch: 5| Step: 5
Training loss: 1.9086265563964844
Validation loss: 1.9531473267462947

Epoch: 5| Step: 6
Training loss: 2.8546295166015625
Validation loss: 1.95498324466008

Epoch: 5| Step: 7
Training loss: 2.1830573081970215
Validation loss: 1.9611399199372979

Epoch: 5| Step: 8
Training loss: 2.548607349395752
Validation loss: 1.9683100997760732

Epoch: 5| Step: 9
Training loss: 2.184140682220459
Validation loss: 1.975991218320785

Epoch: 5| Step: 10
Training loss: 2.259003162384033
Validation loss: 1.9724588983802385

Epoch: 96| Step: 0
Training loss: 2.0639419555664062
Validation loss: 1.9860997276921426

Epoch: 5| Step: 1
Training loss: 2.162938117980957
Validation loss: 1.9840560343957716

Epoch: 5| Step: 2
Training loss: 2.3913145065307617
Validation loss: 1.9780023303083194

Epoch: 5| Step: 3
Training loss: 2.576275587081909
Validation loss: 1.9679085721251786

Epoch: 5| Step: 4
Training loss: 1.9615609645843506
Validation loss: 1.96960247460232

Epoch: 5| Step: 5
Training loss: 2.27510142326355
Validation loss: 1.9649059311036141

Epoch: 5| Step: 6
Training loss: 1.8657188415527344
Validation loss: 1.9693109232892272

Epoch: 5| Step: 7
Training loss: 2.156909942626953
Validation loss: 1.9706047504178938

Epoch: 5| Step: 8
Training loss: 1.907152533531189
Validation loss: 1.9616324670853154

Epoch: 5| Step: 9
Training loss: 3.1129117012023926
Validation loss: 1.9656507866356963

Epoch: 5| Step: 10
Training loss: 1.763905644416809
Validation loss: 1.975220985310052

Epoch: 97| Step: 0
Training loss: 1.730690360069275
Validation loss: 1.9762842539818055

Epoch: 5| Step: 1
Training loss: 2.6072678565979004
Validation loss: 1.9637999201333651

Epoch: 5| Step: 2
Training loss: 2.3598883152008057
Validation loss: 1.9711879645624468

Epoch: 5| Step: 3
Training loss: 2.200493097305298
Validation loss: 1.970554183888179

Epoch: 5| Step: 4
Training loss: 2.2340505123138428
Validation loss: 1.966485277298958

Epoch: 5| Step: 5
Training loss: 2.3111774921417236
Validation loss: 1.9592038252020394

Epoch: 5| Step: 6
Training loss: 2.1299073696136475
Validation loss: 1.9831772683769144

Epoch: 5| Step: 7
Training loss: 1.4355696439743042
Validation loss: 1.9844422468575098

Epoch: 5| Step: 8
Training loss: 2.86008620262146
Validation loss: 2.003086911734714

Epoch: 5| Step: 9
Training loss: 1.9515621662139893
Validation loss: 2.014396911026329

Epoch: 5| Step: 10
Training loss: 2.603008270263672
Validation loss: 2.0050139093911774

Epoch: 98| Step: 0
Training loss: 1.7807867527008057
Validation loss: 1.9873583214257353

Epoch: 5| Step: 1
Training loss: 1.8276439905166626
Validation loss: 1.9842936069734636

Epoch: 5| Step: 2
Training loss: 2.4879584312438965
Validation loss: 1.9772630224945724

Epoch: 5| Step: 3
Training loss: 2.702238082885742
Validation loss: 1.9850198376563288

Epoch: 5| Step: 4
Training loss: 2.1042165756225586
Validation loss: 1.9818839719218593

Epoch: 5| Step: 5
Training loss: 2.305964708328247
Validation loss: 1.9749098413734025

Epoch: 5| Step: 6
Training loss: 1.4553171396255493
Validation loss: 1.9795207054384294

Epoch: 5| Step: 7
Training loss: 2.5049211978912354
Validation loss: 1.9967287022580382

Epoch: 5| Step: 8
Training loss: 2.3652172088623047
Validation loss: 2.011819774104703

Epoch: 5| Step: 9
Training loss: 2.6647472381591797
Validation loss: 2.0164504256299747

Epoch: 5| Step: 10
Training loss: 2.11193585395813
Validation loss: 2.0062005635230773

Epoch: 99| Step: 0
Training loss: 2.3764126300811768
Validation loss: 2.005721156315137

Epoch: 5| Step: 1
Training loss: 2.6782712936401367
Validation loss: 1.9961306920615576

Epoch: 5| Step: 2
Training loss: 1.704856514930725
Validation loss: 1.9763750465967322

Epoch: 5| Step: 3
Training loss: 1.8305091857910156
Validation loss: 1.9718372514170985

Epoch: 5| Step: 4
Training loss: 2.1544747352600098
Validation loss: 1.9797271438824233

Epoch: 5| Step: 5
Training loss: 2.1319682598114014
Validation loss: 1.962104200035013

Epoch: 5| Step: 6
Training loss: 2.409221887588501
Validation loss: 1.9721040674435195

Epoch: 5| Step: 7
Training loss: 1.921494722366333
Validation loss: 1.972138488164512

Epoch: 5| Step: 8
Training loss: 2.6472437381744385
Validation loss: 1.9770358365069154

Epoch: 5| Step: 9
Training loss: 1.8024590015411377
Validation loss: 1.9758377613559845

Epoch: 5| Step: 10
Training loss: 2.5202479362487793
Validation loss: 1.9693498162813083

Epoch: 100| Step: 0
Training loss: 2.4318857192993164
Validation loss: 1.9757751213606967

Epoch: 5| Step: 1
Training loss: 2.749131679534912
Validation loss: 1.9804778816879436

Epoch: 5| Step: 2
Training loss: 2.336216449737549
Validation loss: 1.9813972762835923

Epoch: 5| Step: 3
Training loss: 1.9972854852676392
Validation loss: 1.9824086748143679

Epoch: 5| Step: 4
Training loss: 2.112612009048462
Validation loss: 1.9863733348026071

Epoch: 5| Step: 5
Training loss: 2.948139190673828
Validation loss: 1.9853354769368325

Epoch: 5| Step: 6
Training loss: 1.6850087642669678
Validation loss: 1.9843214211925384

Epoch: 5| Step: 7
Training loss: 2.4514288902282715
Validation loss: 1.9742101751348025

Epoch: 5| Step: 8
Training loss: 1.3260352611541748
Validation loss: 1.9780707769496466

Epoch: 5| Step: 9
Training loss: 1.4739047288894653
Validation loss: 1.9806481766444382

Epoch: 5| Step: 10
Training loss: 2.4894161224365234
Validation loss: 1.982587924567602

Epoch: 101| Step: 0
Training loss: 2.0980682373046875
Validation loss: 1.9949393439036545

Epoch: 5| Step: 1
Training loss: 1.8733594417572021
Validation loss: 1.9950514583177463

Epoch: 5| Step: 2
Training loss: 2.464223623275757
Validation loss: 2.01010279117092

Epoch: 5| Step: 3
Training loss: 2.9859659671783447
Validation loss: 2.0318541654976467

Epoch: 5| Step: 4
Training loss: 2.0389270782470703
Validation loss: 2.0200854578325824

Epoch: 5| Step: 5
Training loss: 2.259883403778076
Validation loss: 2.0130948225657144

Epoch: 5| Step: 6
Training loss: 2.4215519428253174
Validation loss: 1.992812648896248

Epoch: 5| Step: 7
Training loss: 2.103778839111328
Validation loss: 1.981707602418879

Epoch: 5| Step: 8
Training loss: 1.90827214717865
Validation loss: 1.9689658149596183

Epoch: 5| Step: 9
Training loss: 1.5892865657806396
Validation loss: 1.9760636219414331

Epoch: 5| Step: 10
Training loss: 2.2209928035736084
Validation loss: 1.9834766259757421

Epoch: 102| Step: 0
Training loss: 2.0251827239990234
Validation loss: 2.0064027027417253

Epoch: 5| Step: 1
Training loss: 2.1775214672088623
Validation loss: 2.012178122356374

Epoch: 5| Step: 2
Training loss: 1.9472448825836182
Validation loss: 2.0056084996910504

Epoch: 5| Step: 3
Training loss: 1.9786148071289062
Validation loss: 2.011774263074321

Epoch: 5| Step: 4
Training loss: 2.85817551612854
Validation loss: 2.01821247864795

Epoch: 5| Step: 5
Training loss: 2.361203193664551
Validation loss: 2.0376544870356077

Epoch: 5| Step: 6
Training loss: 1.8641307353973389
Validation loss: 2.047190632871402

Epoch: 5| Step: 7
Training loss: 2.0806961059570312
Validation loss: 2.0320113410231886

Epoch: 5| Step: 8
Training loss: 2.3774027824401855
Validation loss: 2.0029115433334024

Epoch: 5| Step: 9
Training loss: 1.9593791961669922
Validation loss: 1.9960860872781405

Epoch: 5| Step: 10
Training loss: 2.3899309635162354
Validation loss: 1.9928594686651742

Epoch: 103| Step: 0
Training loss: 1.9568713903427124
Validation loss: 2.0065402946164532

Epoch: 5| Step: 1
Training loss: 2.412914752960205
Validation loss: 2.0155869837730163

Epoch: 5| Step: 2
Training loss: 2.2300918102264404
Validation loss: 2.0054882726361676

Epoch: 5| Step: 3
Training loss: 2.5085339546203613
Validation loss: 1.9996128825731174

Epoch: 5| Step: 4
Training loss: 2.2437620162963867
Validation loss: 1.9857725686924432

Epoch: 5| Step: 5
Training loss: 2.177699565887451
Validation loss: 1.994154812187277

Epoch: 5| Step: 6
Training loss: 2.0670266151428223
Validation loss: 2.0681302483363817

Epoch: 5| Step: 7
Training loss: 2.084582567214966
Validation loss: 2.1266980581386115

Epoch: 5| Step: 8
Training loss: 2.248915195465088
Validation loss: 2.162404703837569

Epoch: 5| Step: 9
Training loss: 2.053616762161255
Validation loss: 2.1503395585603613

Epoch: 5| Step: 10
Training loss: 2.7203965187072754
Validation loss: 2.1300865757849907

Epoch: 104| Step: 0
Training loss: 2.4814467430114746
Validation loss: 2.1112699995758715

Epoch: 5| Step: 1
Training loss: 2.212761402130127
Validation loss: 2.0708240975615797

Epoch: 5| Step: 2
Training loss: 2.122864007949829
Validation loss: 2.0243917883083387

Epoch: 5| Step: 3
Training loss: 1.7239681482315063
Validation loss: 2.006289420589324

Epoch: 5| Step: 4
Training loss: 2.4270472526550293
Validation loss: 1.9974618316978536

Epoch: 5| Step: 5
Training loss: 2.318800449371338
Validation loss: 2.0087621827279367

Epoch: 5| Step: 6
Training loss: 2.1425445079803467
Validation loss: 2.00589914988446

Epoch: 5| Step: 7
Training loss: 2.092879056930542
Validation loss: 2.000388655611264

Epoch: 5| Step: 8
Training loss: 2.3890271186828613
Validation loss: 1.9863166578354374

Epoch: 5| Step: 9
Training loss: 2.0453832149505615
Validation loss: 1.9883508579705351

Epoch: 5| Step: 10
Training loss: 1.8858619928359985
Validation loss: 1.9925765286209762

Epoch: 105| Step: 0
Training loss: 1.6933696269989014
Validation loss: 1.999452519160445

Epoch: 5| Step: 1
Training loss: 1.1850279569625854
Validation loss: 2.014823644391952

Epoch: 5| Step: 2
Training loss: 2.0886154174804688
Validation loss: 2.0353686373720885

Epoch: 5| Step: 3
Training loss: 2.3722267150878906
Validation loss: 2.0195704070470666

Epoch: 5| Step: 4
Training loss: 2.240866184234619
Validation loss: 2.032183026754728

Epoch: 5| Step: 5
Training loss: 2.438852071762085
Validation loss: 2.0370852857507686

Epoch: 5| Step: 6
Training loss: 2.2134947776794434
Validation loss: 2.0174062405863116

Epoch: 5| Step: 7
Training loss: 2.7576470375061035
Validation loss: 1.9962265004393875

Epoch: 5| Step: 8
Training loss: 1.971848487854004
Validation loss: 1.9846176178224626

Epoch: 5| Step: 9
Training loss: 2.234544515609741
Validation loss: 1.9896734555562336

Epoch: 5| Step: 10
Training loss: 2.466432571411133
Validation loss: 1.9906438345550208

Epoch: 106| Step: 0
Training loss: 2.1053903102874756
Validation loss: 2.0000305560327347

Epoch: 5| Step: 1
Training loss: 2.395202875137329
Validation loss: 2.00312477286144

Epoch: 5| Step: 2
Training loss: 2.7194137573242188
Validation loss: 1.9958142811252224

Epoch: 5| Step: 3
Training loss: 1.9446313381195068
Validation loss: 1.985507575414514

Epoch: 5| Step: 4
Training loss: 2.2751388549804688
Validation loss: 2.002554629438667

Epoch: 5| Step: 5
Training loss: 1.946718454360962
Validation loss: 2.044046773705431

Epoch: 5| Step: 6
Training loss: 1.6583595275878906
Validation loss: 2.056777838737734

Epoch: 5| Step: 7
Training loss: 2.0865657329559326
Validation loss: 2.065209460514848

Epoch: 5| Step: 8
Training loss: 2.266570568084717
Validation loss: 2.0609189874382428

Epoch: 5| Step: 9
Training loss: 2.374861240386963
Validation loss: 2.072413585519278

Epoch: 5| Step: 10
Training loss: 1.6951301097869873
Validation loss: 2.072569586897409

Epoch: 107| Step: 0
Training loss: 1.9116874933242798
Validation loss: 2.063394587527039

Epoch: 5| Step: 1
Training loss: 2.0817461013793945
Validation loss: 2.037450554550335

Epoch: 5| Step: 2
Training loss: 2.0203213691711426
Validation loss: 2.021224355184904

Epoch: 5| Step: 3
Training loss: 2.774325132369995
Validation loss: 2.014626887536818

Epoch: 5| Step: 4
Training loss: 2.5019309520721436
Validation loss: 2.0093726881088747

Epoch: 5| Step: 5
Training loss: 1.6507751941680908
Validation loss: 2.008448390550511

Epoch: 5| Step: 6
Training loss: 1.6336685419082642
Validation loss: 2.012000048032371

Epoch: 5| Step: 7
Training loss: 1.9303661584854126
Validation loss: 2.008598312254875

Epoch: 5| Step: 8
Training loss: 2.3258156776428223
Validation loss: 2.019765366790115

Epoch: 5| Step: 9
Training loss: 2.2888243198394775
Validation loss: 2.028654630466174

Epoch: 5| Step: 10
Training loss: 2.3697142601013184
Validation loss: 2.0397158643250823

Epoch: 108| Step: 0
Training loss: 2.5167365074157715
Validation loss: 2.0259466414810507

Epoch: 5| Step: 1
Training loss: 1.8740698099136353
Validation loss: 2.0070421157344693

Epoch: 5| Step: 2
Training loss: 2.3381857872009277
Validation loss: 2.0007261512100056

Epoch: 5| Step: 3
Training loss: 1.984378457069397
Validation loss: 1.9879621946683494

Epoch: 5| Step: 4
Training loss: 1.9065818786621094
Validation loss: 1.9831419555089806

Epoch: 5| Step: 5
Training loss: 2.036541700363159
Validation loss: 2.0064331690470376

Epoch: 5| Step: 6
Training loss: 2.516087293624878
Validation loss: 2.004262634502944

Epoch: 5| Step: 7
Training loss: 2.009382963180542
Validation loss: 2.0087072490363993

Epoch: 5| Step: 8
Training loss: 2.1656551361083984
Validation loss: 2.0343485224631523

Epoch: 5| Step: 9
Training loss: 1.5262566804885864
Validation loss: 2.081512886990783

Epoch: 5| Step: 10
Training loss: 2.220156669616699
Validation loss: 2.133897235316615

Epoch: 109| Step: 0
Training loss: 1.8562551736831665
Validation loss: 2.1851975251269597

Epoch: 5| Step: 1
Training loss: 2.1203701496124268
Validation loss: 2.22859723337235

Epoch: 5| Step: 2
Training loss: 2.223214864730835
Validation loss: 2.2222991886959282

Epoch: 5| Step: 3
Training loss: 2.0425639152526855
Validation loss: 2.176661010711424

Epoch: 5| Step: 4
Training loss: 3.189352512359619
Validation loss: 2.1019629175944994

Epoch: 5| Step: 5
Training loss: 1.8799407482147217
Validation loss: 2.0453369412370908

Epoch: 5| Step: 6
Training loss: 1.661412239074707
Validation loss: 2.0160242883107995

Epoch: 5| Step: 7
Training loss: 2.203198194503784
Validation loss: 2.010844983080382

Epoch: 5| Step: 8
Training loss: 2.3096776008605957
Validation loss: 2.013482347611458

Epoch: 5| Step: 9
Training loss: 2.190882921218872
Validation loss: 2.0174902985172887

Epoch: 5| Step: 10
Training loss: 2.41976261138916
Validation loss: 2.0297062243184736

Epoch: 110| Step: 0
Training loss: 1.2412083148956299
Validation loss: 2.027900154872607

Epoch: 5| Step: 1
Training loss: 2.3817543983459473
Validation loss: 2.050770533982144

Epoch: 5| Step: 2
Training loss: 1.9756025075912476
Validation loss: 2.089325184463173

Epoch: 5| Step: 3
Training loss: 2.137237071990967
Validation loss: 2.1315281929508334

Epoch: 5| Step: 4
Training loss: 2.0534026622772217
Validation loss: 2.1305893749319096

Epoch: 5| Step: 5
Training loss: 2.1171019077301025
Validation loss: 2.112682411747594

Epoch: 5| Step: 6
Training loss: 1.9927713871002197
Validation loss: 2.078064872372535

Epoch: 5| Step: 7
Training loss: 2.828023910522461
Validation loss: 2.044678654721988

Epoch: 5| Step: 8
Training loss: 2.0343708992004395
Validation loss: 2.0234724783128306

Epoch: 5| Step: 9
Training loss: 2.772533893585205
Validation loss: 2.004701829725696

Epoch: 5| Step: 10
Training loss: 1.883495807647705
Validation loss: 1.9990964397307365

Epoch: 111| Step: 0
Training loss: 1.374851942062378
Validation loss: 1.9935223761425223

Epoch: 5| Step: 1
Training loss: 2.250915288925171
Validation loss: 2.008935205398067

Epoch: 5| Step: 2
Training loss: 1.9195940494537354
Validation loss: 2.018440955428667

Epoch: 5| Step: 3
Training loss: 2.26588773727417
Validation loss: 2.019265556848177

Epoch: 5| Step: 4
Training loss: 2.519958019256592
Validation loss: 2.029345671335856

Epoch: 5| Step: 5
Training loss: 1.4369418621063232
Validation loss: 2.0228388437660794

Epoch: 5| Step: 6
Training loss: 2.0816149711608887
Validation loss: 2.0299221225964126

Epoch: 5| Step: 7
Training loss: 2.6799392700195312
Validation loss: 2.043461654775886

Epoch: 5| Step: 8
Training loss: 2.4666459560394287
Validation loss: 2.0667313926963398

Epoch: 5| Step: 9
Training loss: 1.7967573404312134
Validation loss: 2.0752036315138622

Epoch: 5| Step: 10
Training loss: 1.8782895803451538
Validation loss: 2.085202802893936

Epoch: 112| Step: 0
Training loss: 2.2367987632751465
Validation loss: 2.109684277606267

Epoch: 5| Step: 1
Training loss: 1.7397006750106812
Validation loss: 2.111590670001122

Epoch: 5| Step: 2
Training loss: 2.298011064529419
Validation loss: 2.1058677114466184

Epoch: 5| Step: 3
Training loss: 1.6609470844268799
Validation loss: 2.084391998988326

Epoch: 5| Step: 4
Training loss: 2.4101202487945557
Validation loss: 2.0709851839209117

Epoch: 5| Step: 5
Training loss: 1.6675564050674438
Validation loss: 2.0594296032382595

Epoch: 5| Step: 6
Training loss: 2.143157720565796
Validation loss: 2.069031133446642

Epoch: 5| Step: 7
Training loss: 2.7446608543395996
Validation loss: 2.064071633482492

Epoch: 5| Step: 8
Training loss: 2.0268256664276123
Validation loss: 2.050989512474306

Epoch: 5| Step: 9
Training loss: 1.7709827423095703
Validation loss: 2.0571872085653324

Epoch: 5| Step: 10
Training loss: 2.1921322345733643
Validation loss: 2.0461901695497575

Epoch: 113| Step: 0
Training loss: 1.5531425476074219
Validation loss: 2.036364181067354

Epoch: 5| Step: 1
Training loss: 1.7922929525375366
Validation loss: 2.031672371331082

Epoch: 5| Step: 2
Training loss: 2.720147132873535
Validation loss: 2.03665489919724

Epoch: 5| Step: 3
Training loss: 1.711560606956482
Validation loss: 2.0422646076448503

Epoch: 5| Step: 4
Training loss: 2.3523826599121094
Validation loss: 2.04228889044895

Epoch: 5| Step: 5
Training loss: 2.1381373405456543
Validation loss: 2.0342716068349858

Epoch: 5| Step: 6
Training loss: 1.8206405639648438
Validation loss: 2.018434903954947

Epoch: 5| Step: 7
Training loss: 2.4644229412078857
Validation loss: 2.0077806813742525

Epoch: 5| Step: 8
Training loss: 1.588128924369812
Validation loss: 1.9931971591006044

Epoch: 5| Step: 9
Training loss: 2.384702682495117
Validation loss: 2.00529396405784

Epoch: 5| Step: 10
Training loss: 2.0875394344329834
Validation loss: 2.0186906168537755

Epoch: 114| Step: 0
Training loss: 2.125415802001953
Validation loss: 2.01648977879555

Epoch: 5| Step: 1
Training loss: 1.5872317552566528
Validation loss: 2.0268460550615863

Epoch: 5| Step: 2
Training loss: 1.6027694940567017
Validation loss: 2.049440236501796

Epoch: 5| Step: 3
Training loss: 1.747745156288147
Validation loss: 2.0572974399853776

Epoch: 5| Step: 4
Training loss: 2.3400955200195312
Validation loss: 2.0760540141854236

Epoch: 5| Step: 5
Training loss: 2.0901236534118652
Validation loss: 2.0850148534262054

Epoch: 5| Step: 6
Training loss: 2.156297206878662
Validation loss: 2.087770659436462

Epoch: 5| Step: 7
Training loss: 2.1482276916503906
Validation loss: 2.0879565515825824

Epoch: 5| Step: 8
Training loss: 2.771514415740967
Validation loss: 2.0778236273796327

Epoch: 5| Step: 9
Training loss: 1.663403868675232
Validation loss: 2.0744999813777145

Epoch: 5| Step: 10
Training loss: 1.9761154651641846
Validation loss: 2.088500202343028

Epoch: 115| Step: 0
Training loss: 1.992278814315796
Validation loss: 2.076733860918271

Epoch: 5| Step: 1
Training loss: 2.1067376136779785
Validation loss: 2.087635337665517

Epoch: 5| Step: 2
Training loss: 2.7882959842681885
Validation loss: 2.0885363445487073

Epoch: 5| Step: 3
Training loss: 1.7066577672958374
Validation loss: 2.070007901037893

Epoch: 5| Step: 4
Training loss: 1.8849884271621704
Validation loss: 2.075683529658984

Epoch: 5| Step: 5
Training loss: 1.7800956964492798
Validation loss: 2.0674101665455806

Epoch: 5| Step: 6
Training loss: 2.7375473976135254
Validation loss: 2.055342044881595

Epoch: 5| Step: 7
Training loss: 2.079752206802368
Validation loss: 2.07216977560392

Epoch: 5| Step: 8
Training loss: 1.7992446422576904
Validation loss: 2.056018970345938

Epoch: 5| Step: 9
Training loss: 1.7928346395492554
Validation loss: 2.0418249253303773

Epoch: 5| Step: 10
Training loss: 1.3621759414672852
Validation loss: 2.044205278478643

Epoch: 116| Step: 0
Training loss: 2.297940492630005
Validation loss: 2.0610536465080838

Epoch: 5| Step: 1
Training loss: 2.75616192817688
Validation loss: 2.085407046861546

Epoch: 5| Step: 2
Training loss: 1.6605724096298218
Validation loss: 2.0629847908532746

Epoch: 5| Step: 3
Training loss: 1.7367839813232422
Validation loss: 2.043987317751813

Epoch: 5| Step: 4
Training loss: 1.994685411453247
Validation loss: 2.054340236930437

Epoch: 5| Step: 5
Training loss: 1.593801736831665
Validation loss: 2.0568614493134203

Epoch: 5| Step: 6
Training loss: 1.5936180353164673
Validation loss: 2.0713083820958293

Epoch: 5| Step: 7
Training loss: 1.8671268224716187
Validation loss: 2.083485003440611

Epoch: 5| Step: 8
Training loss: 2.3578431606292725
Validation loss: 2.0813932188095583

Epoch: 5| Step: 9
Training loss: 1.9195671081542969
Validation loss: 2.098933110954941

Epoch: 5| Step: 10
Training loss: 2.1640446186065674
Validation loss: 2.1318636248188634

Epoch: 117| Step: 0
Training loss: 2.3316080570220947
Validation loss: 2.1455199923566592

Epoch: 5| Step: 1
Training loss: 2.3032119274139404
Validation loss: 2.1420324169179445

Epoch: 5| Step: 2
Training loss: 1.873765230178833
Validation loss: 2.1026730716869397

Epoch: 5| Step: 3
Training loss: 2.219076633453369
Validation loss: 2.073262950425507

Epoch: 5| Step: 4
Training loss: 2.5642123222351074
Validation loss: 2.048169666720975

Epoch: 5| Step: 5
Training loss: 1.4859592914581299
Validation loss: 2.037793113339332

Epoch: 5| Step: 6
Training loss: 1.9119462966918945
Validation loss: 2.018789114490632

Epoch: 5| Step: 7
Training loss: 1.7175045013427734
Validation loss: 2.0124226359910864

Epoch: 5| Step: 8
Training loss: 1.7691450119018555
Validation loss: 2.0328832634033693

Epoch: 5| Step: 9
Training loss: 1.3813636302947998
Validation loss: 2.037168413080195

Epoch: 5| Step: 10
Training loss: 2.176234006881714
Validation loss: 2.041131506684006

Epoch: 118| Step: 0
Training loss: 2.4324252605438232
Validation loss: 2.05035872228684

Epoch: 5| Step: 1
Training loss: 2.156851291656494
Validation loss: 2.0513635553339475

Epoch: 5| Step: 2
Training loss: 1.955528974533081
Validation loss: 2.0496764541954122

Epoch: 5| Step: 3
Training loss: 2.4265143871307373
Validation loss: 2.0510090627977924

Epoch: 5| Step: 4
Training loss: 2.3629250526428223
Validation loss: 2.066977377860777

Epoch: 5| Step: 5
Training loss: 1.4562593698501587
Validation loss: 2.0793721957873275

Epoch: 5| Step: 6
Training loss: 1.7330907583236694
Validation loss: 2.101385385759415

Epoch: 5| Step: 7
Training loss: 1.9361505508422852
Validation loss: 2.0940226060087963

Epoch: 5| Step: 8
Training loss: 1.453545331954956
Validation loss: 2.0819066404014506

Epoch: 5| Step: 9
Training loss: 1.310114860534668
Validation loss: 2.0660710437323457

Epoch: 5| Step: 10
Training loss: 2.228832960128784
Validation loss: 2.0565748881268244

Epoch: 119| Step: 0
Training loss: 1.7257106304168701
Validation loss: 2.05919954340945

Epoch: 5| Step: 1
Training loss: 2.1997525691986084
Validation loss: 2.0653743449077813

Epoch: 5| Step: 2
Training loss: 2.331005573272705
Validation loss: 2.0433992390991538

Epoch: 5| Step: 3
Training loss: 2.08577299118042
Validation loss: 2.0172125331817137

Epoch: 5| Step: 4
Training loss: 1.9865001440048218
Validation loss: 2.0372286560714885

Epoch: 5| Step: 5
Training loss: 2.034865617752075
Validation loss: 2.025189627883255

Epoch: 5| Step: 6
Training loss: 1.768955945968628
Validation loss: 2.0182967160337713

Epoch: 5| Step: 7
Training loss: 2.080130100250244
Validation loss: 2.0145602597985217

Epoch: 5| Step: 8
Training loss: 2.0338950157165527
Validation loss: 2.0238359359002884

Epoch: 5| Step: 9
Training loss: 1.4242184162139893
Validation loss: 2.033212298988014

Epoch: 5| Step: 10
Training loss: 1.8029299974441528
Validation loss: 2.070154200318039

Epoch: 120| Step: 0
Training loss: 1.7012040615081787
Validation loss: 2.1075294940702376

Epoch: 5| Step: 1
Training loss: 2.003006935119629
Validation loss: 2.1129516645144393

Epoch: 5| Step: 2
Training loss: 1.6518043279647827
Validation loss: 2.0858953165751632

Epoch: 5| Step: 3
Training loss: 1.7977800369262695
Validation loss: 2.0796610450231903

Epoch: 5| Step: 4
Training loss: 2.049522876739502
Validation loss: 2.044747162890691

Epoch: 5| Step: 5
Training loss: 1.9004499912261963
Validation loss: 2.027024680568326

Epoch: 5| Step: 6
Training loss: 2.1768620014190674
Validation loss: 2.027142196573237

Epoch: 5| Step: 7
Training loss: 1.7827043533325195
Validation loss: 2.018171651389009

Epoch: 5| Step: 8
Training loss: 2.5617549419403076
Validation loss: 2.0165322519117788

Epoch: 5| Step: 9
Training loss: 1.7614047527313232
Validation loss: 2.00842926579137

Epoch: 5| Step: 10
Training loss: 1.9393155574798584
Validation loss: 2.0080002815492692

Epoch: 121| Step: 0
Training loss: 2.601897716522217
Validation loss: 2.0266476087672736

Epoch: 5| Step: 1
Training loss: 2.044196844100952
Validation loss: 2.0620654295849543

Epoch: 5| Step: 2
Training loss: 1.7615416049957275
Validation loss: 2.0977647586535384

Epoch: 5| Step: 3
Training loss: 2.199664831161499
Validation loss: 2.1357952292247484

Epoch: 5| Step: 4
Training loss: 1.8758007287979126
Validation loss: 2.16572154209178

Epoch: 5| Step: 5
Training loss: 2.0486185550689697
Validation loss: 2.1354842121883104

Epoch: 5| Step: 6
Training loss: 1.8125629425048828
Validation loss: 2.1077473202059345

Epoch: 5| Step: 7
Training loss: 1.5068767070770264
Validation loss: 2.0740208805248304

Epoch: 5| Step: 8
Training loss: 1.648952841758728
Validation loss: 2.06076652772965

Epoch: 5| Step: 9
Training loss: 2.076779842376709
Validation loss: 2.0531957098232803

Epoch: 5| Step: 10
Training loss: 1.8637317419052124
Validation loss: 2.041980266571045

Epoch: 122| Step: 0
Training loss: 1.9786579608917236
Validation loss: 2.0380410660979567

Epoch: 5| Step: 1
Training loss: 1.8232914209365845
Validation loss: 2.0300152314606534

Epoch: 5| Step: 2
Training loss: 2.285079002380371
Validation loss: 2.0192759677927983

Epoch: 5| Step: 3
Training loss: 2.082502841949463
Validation loss: 2.0197196224684357

Epoch: 5| Step: 4
Training loss: 2.1915178298950195
Validation loss: 2.040898238458941

Epoch: 5| Step: 5
Training loss: 2.050957202911377
Validation loss: 2.0708686049266527

Epoch: 5| Step: 6
Training loss: 1.838126540184021
Validation loss: 2.090791179287818

Epoch: 5| Step: 7
Training loss: 1.9451053142547607
Validation loss: 2.095743115230273

Epoch: 5| Step: 8
Training loss: 1.5736457109451294
Validation loss: 2.095025216379473

Epoch: 5| Step: 9
Training loss: 1.472727656364441
Validation loss: 2.076029259671447

Epoch: 5| Step: 10
Training loss: 2.0405564308166504
Validation loss: 2.0393922380221787

Epoch: 123| Step: 0
Training loss: 2.1688780784606934
Validation loss: 2.0468856314177155

Epoch: 5| Step: 1
Training loss: 2.0373780727386475
Validation loss: 2.0441806867558467

Epoch: 5| Step: 2
Training loss: 2.154625654220581
Validation loss: 2.0293101597857732

Epoch: 5| Step: 3
Training loss: 2.171832799911499
Validation loss: 2.023672785810245

Epoch: 5| Step: 4
Training loss: 1.390704870223999
Validation loss: 2.010383153474459

Epoch: 5| Step: 5
Training loss: 1.9066473245620728
Validation loss: 2.023874818637807

Epoch: 5| Step: 6
Training loss: 1.2905354499816895
Validation loss: 2.0291895917666856

Epoch: 5| Step: 7
Training loss: 1.7554391622543335
Validation loss: 2.039945343489288

Epoch: 5| Step: 8
Training loss: 2.159832715988159
Validation loss: 2.0584487966311875

Epoch: 5| Step: 9
Training loss: 2.4040777683258057
Validation loss: 2.0843785347477084

Epoch: 5| Step: 10
Training loss: 1.4344431161880493
Validation loss: 2.106493419216525

Epoch: 124| Step: 0
Training loss: 1.8346588611602783
Validation loss: 2.106227744010187

Epoch: 5| Step: 1
Training loss: 1.7031151056289673
Validation loss: 2.0936737906548286

Epoch: 5| Step: 2
Training loss: 2.0107550621032715
Validation loss: 2.0419318073539325

Epoch: 5| Step: 3
Training loss: 2.0637753009796143
Validation loss: 2.027383573593632

Epoch: 5| Step: 4
Training loss: 2.1235146522521973
Validation loss: 2.0359692009546424

Epoch: 5| Step: 5
Training loss: 1.3508762121200562
Validation loss: 2.051702848044775

Epoch: 5| Step: 6
Training loss: 2.0323781967163086
Validation loss: 2.048594355583191

Epoch: 5| Step: 7
Training loss: 1.978675127029419
Validation loss: 2.0728142646051224

Epoch: 5| Step: 8
Training loss: 2.127013683319092
Validation loss: 2.0463839782181608

Epoch: 5| Step: 9
Training loss: 1.2060515880584717
Validation loss: 2.043505983967935

Epoch: 5| Step: 10
Training loss: 2.5422213077545166
Validation loss: 2.046832189765028

Epoch: 125| Step: 0
Training loss: 2.0314128398895264
Validation loss: 2.059267244031352

Epoch: 5| Step: 1
Training loss: 1.953127145767212
Validation loss: 2.0719337937652424

Epoch: 5| Step: 2
Training loss: 1.672265648841858
Validation loss: 2.080046652465738

Epoch: 5| Step: 3
Training loss: 1.8656545877456665
Validation loss: 2.056842674491226

Epoch: 5| Step: 4
Training loss: 1.7798926830291748
Validation loss: 2.047229855291305

Epoch: 5| Step: 5
Training loss: 1.8903754949569702
Validation loss: 2.0444900117894655

Epoch: 5| Step: 6
Training loss: 1.9265010356903076
Validation loss: 2.04510151186297

Epoch: 5| Step: 7
Training loss: 2.1774775981903076
Validation loss: 2.022989111561929

Epoch: 5| Step: 8
Training loss: 1.471392273902893
Validation loss: 2.0265509646425963

Epoch: 5| Step: 9
Training loss: 1.861830472946167
Validation loss: 2.01977042869855

Epoch: 5| Step: 10
Training loss: 1.8192451000213623
Validation loss: 2.005256954059806

Epoch: 126| Step: 0
Training loss: 1.4896483421325684
Validation loss: 1.9906978684086953

Epoch: 5| Step: 1
Training loss: 1.503960371017456
Validation loss: 1.9814764889337684

Epoch: 5| Step: 2
Training loss: 2.0321173667907715
Validation loss: 1.9911257631035262

Epoch: 5| Step: 3
Training loss: 1.7378381490707397
Validation loss: 1.9938034370381346

Epoch: 5| Step: 4
Training loss: 2.1017189025878906
Validation loss: 2.013676187043549

Epoch: 5| Step: 5
Training loss: 1.364091157913208
Validation loss: 2.0090660997616347

Epoch: 5| Step: 6
Training loss: 2.2383503913879395
Validation loss: 2.0301713097480034

Epoch: 5| Step: 7
Training loss: 2.363913059234619
Validation loss: 2.0422780372763194

Epoch: 5| Step: 8
Training loss: 1.5576815605163574
Validation loss: 2.061034164121074

Epoch: 5| Step: 9
Training loss: 2.2243494987487793
Validation loss: 2.058517784200689

Epoch: 5| Step: 10
Training loss: 1.6799033880233765
Validation loss: 2.0516751735441145

Epoch: 127| Step: 0
Training loss: 1.657092809677124
Validation loss: 2.049952409600699

Epoch: 5| Step: 1
Training loss: 1.6657756567001343
Validation loss: 2.0539943351540515

Epoch: 5| Step: 2
Training loss: 1.7300183773040771
Validation loss: 2.045246986932652

Epoch: 5| Step: 3
Training loss: 1.7401847839355469
Validation loss: 2.0323230297334733

Epoch: 5| Step: 4
Training loss: 1.722088098526001
Validation loss: 2.0176015605208693

Epoch: 5| Step: 5
Training loss: 1.9888222217559814
Validation loss: 2.011890379331445

Epoch: 5| Step: 6
Training loss: 1.688886284828186
Validation loss: 2.002505161428964

Epoch: 5| Step: 7
Training loss: 2.144615650177002
Validation loss: 1.9939781876020535

Epoch: 5| Step: 8
Training loss: 1.8514254093170166
Validation loss: 1.9932192269191946

Epoch: 5| Step: 9
Training loss: 1.9571460485458374
Validation loss: 1.980257490629791

Epoch: 5| Step: 10
Training loss: 1.8280386924743652
Validation loss: 1.9994016949848463

Epoch: 128| Step: 0
Training loss: 1.6805022954940796
Validation loss: 1.9941669279529202

Epoch: 5| Step: 1
Training loss: 2.3742356300354004
Validation loss: 1.9950208728031447

Epoch: 5| Step: 2
Training loss: 1.1742844581604004
Validation loss: 2.0044459066083355

Epoch: 5| Step: 3
Training loss: 1.9229053258895874
Validation loss: 1.9947826708516767

Epoch: 5| Step: 4
Training loss: 1.6103626489639282
Validation loss: 2.0049771108934955

Epoch: 5| Step: 5
Training loss: 2.080526828765869
Validation loss: 1.9988329077279696

Epoch: 5| Step: 6
Training loss: 1.4463013410568237
Validation loss: 2.024647303806838

Epoch: 5| Step: 7
Training loss: 2.121819257736206
Validation loss: 2.0368927499299407

Epoch: 5| Step: 8
Training loss: 1.4603890180587769
Validation loss: 2.044315989299487

Epoch: 5| Step: 9
Training loss: 1.8816392421722412
Validation loss: 2.0364992695470012

Epoch: 5| Step: 10
Training loss: 1.8707095384597778
Validation loss: 2.045666886914161

Epoch: 129| Step: 0
Training loss: 1.8684139251708984
Validation loss: 2.0389538080461564

Epoch: 5| Step: 1
Training loss: 2.1102147102355957
Validation loss: 2.031480314911053

Epoch: 5| Step: 2
Training loss: 1.5881134271621704
Validation loss: 2.0482233955014135

Epoch: 5| Step: 3
Training loss: 1.8928016424179077
Validation loss: 2.053624763283678

Epoch: 5| Step: 4
Training loss: 1.4299713373184204
Validation loss: 2.0434811486992785

Epoch: 5| Step: 5
Training loss: 1.8657804727554321
Validation loss: 2.0228263844725904

Epoch: 5| Step: 6
Training loss: 1.8531795740127563
Validation loss: 2.016149156837053

Epoch: 5| Step: 7
Training loss: 1.3672231435775757
Validation loss: 2.024352578706639

Epoch: 5| Step: 8
Training loss: 1.5078861713409424
Validation loss: 2.0341113485315794

Epoch: 5| Step: 9
Training loss: 1.6281057596206665
Validation loss: 2.037760946058458

Epoch: 5| Step: 10
Training loss: 2.4983348846435547
Validation loss: 2.013429623778148

Epoch: 130| Step: 0
Training loss: 1.432262659072876
Validation loss: 2.014789165989045

Epoch: 5| Step: 1
Training loss: 1.9274488687515259
Validation loss: 2.003275009893602

Epoch: 5| Step: 2
Training loss: 1.8042703866958618
Validation loss: 2.007329951050461

Epoch: 5| Step: 3
Training loss: 1.2669036388397217
Validation loss: 2.017854372660319

Epoch: 5| Step: 4
Training loss: 1.6249027252197266
Validation loss: 2.0282255270147838

Epoch: 5| Step: 5
Training loss: 1.7911968231201172
Validation loss: 2.060444836975426

Epoch: 5| Step: 6
Training loss: 1.9376506805419922
Validation loss: 2.0741753103912517

Epoch: 5| Step: 7
Training loss: 1.4335591793060303
Validation loss: 2.0883730073128977

Epoch: 5| Step: 8
Training loss: 2.450047016143799
Validation loss: 2.107866297486008

Epoch: 5| Step: 9
Training loss: 1.8337671756744385
Validation loss: 2.060665120360672

Epoch: 5| Step: 10
Training loss: 2.277677536010742
Validation loss: 2.036003202520391

Epoch: 131| Step: 0
Training loss: 2.4883198738098145
Validation loss: 2.0212372349154566

Epoch: 5| Step: 1
Training loss: 1.4344522953033447
Validation loss: 2.0345154680231565

Epoch: 5| Step: 2
Training loss: 1.905401587486267
Validation loss: 2.0341992993508615

Epoch: 5| Step: 3
Training loss: 1.6282269954681396
Validation loss: 2.05346010000475

Epoch: 5| Step: 4
Training loss: 1.8457412719726562
Validation loss: 2.0489753253998293

Epoch: 5| Step: 5
Training loss: 1.5171247720718384
Validation loss: 2.031676092455464

Epoch: 5| Step: 6
Training loss: 1.6688579320907593
Validation loss: 2.0110498705217914

Epoch: 5| Step: 7
Training loss: 1.2192624807357788
Validation loss: 1.999298636631299

Epoch: 5| Step: 8
Training loss: 2.0292677879333496
Validation loss: 1.9985786830225298

Epoch: 5| Step: 9
Training loss: 1.6926755905151367
Validation loss: 1.9758812048101937

Epoch: 5| Step: 10
Training loss: 1.8301262855529785
Validation loss: 1.9690675415018553

Epoch: 132| Step: 0
Training loss: 1.1927821636199951
Validation loss: 1.9867729448503064

Epoch: 5| Step: 1
Training loss: 1.4389002323150635
Validation loss: 1.986872032124509

Epoch: 5| Step: 2
Training loss: 1.5767005681991577
Validation loss: 1.9956269494948848

Epoch: 5| Step: 3
Training loss: 2.1020348072052
Validation loss: 2.0129162316681235

Epoch: 5| Step: 4
Training loss: 2.1593990325927734
Validation loss: 2.0193921301954534

Epoch: 5| Step: 5
Training loss: 1.5051295757293701
Validation loss: 2.018861657829695

Epoch: 5| Step: 6
Training loss: 1.9187549352645874
Validation loss: 2.014877901282362

Epoch: 5| Step: 7
Training loss: 2.021852731704712
Validation loss: 1.997599087735658

Epoch: 5| Step: 8
Training loss: 1.513749122619629
Validation loss: 1.9912063985742547

Epoch: 5| Step: 9
Training loss: 2.357632637023926
Validation loss: 2.002825874154286

Epoch: 5| Step: 10
Training loss: 1.7062722444534302
Validation loss: 2.0158183574676514

Epoch: 133| Step: 0
Training loss: 1.3570572137832642
Validation loss: 2.031474216009981

Epoch: 5| Step: 1
Training loss: 1.4359605312347412
Validation loss: 2.0506255857406126

Epoch: 5| Step: 2
Training loss: 2.160518169403076
Validation loss: 2.054488294868059

Epoch: 5| Step: 3
Training loss: 1.4118404388427734
Validation loss: 2.05925674592295

Epoch: 5| Step: 4
Training loss: 2.2001824378967285
Validation loss: 2.067602267829321

Epoch: 5| Step: 5
Training loss: 2.0952258110046387
Validation loss: 2.0433078863287486

Epoch: 5| Step: 6
Training loss: 1.656622290611267
Validation loss: 2.0464277754547777

Epoch: 5| Step: 7
Training loss: 1.3916385173797607
Validation loss: 2.0482564562110492

Epoch: 5| Step: 8
Training loss: 1.8340654373168945
Validation loss: 2.0555203883878645

Epoch: 5| Step: 9
Training loss: 1.9887926578521729
Validation loss: 2.0867203871409097

Epoch: 5| Step: 10
Training loss: 1.7715911865234375
Validation loss: 2.125363357605473

Epoch: 134| Step: 0
Training loss: 1.8161404132843018
Validation loss: 2.1215013970610914

Epoch: 5| Step: 1
Training loss: 1.352250099182129
Validation loss: 2.0911030743711736

Epoch: 5| Step: 2
Training loss: 1.7172317504882812
Validation loss: 2.0642993091255106

Epoch: 5| Step: 3
Training loss: 2.1030502319335938
Validation loss: 2.04547780816273

Epoch: 5| Step: 4
Training loss: 1.5759027004241943
Validation loss: 2.024428270196402

Epoch: 5| Step: 5
Training loss: 1.8563886880874634
Validation loss: 1.974251498458206

Epoch: 5| Step: 6
Training loss: 1.4999860525131226
Validation loss: 1.9571891048903107

Epoch: 5| Step: 7
Training loss: 2.1790406703948975
Validation loss: 1.9698823882687477

Epoch: 5| Step: 8
Training loss: 1.4272180795669556
Validation loss: 1.9644464062106224

Epoch: 5| Step: 9
Training loss: 1.5247480869293213
Validation loss: 1.956955922547207

Epoch: 5| Step: 10
Training loss: 1.8235082626342773
Validation loss: 1.9682735845606814

Epoch: 135| Step: 0
Training loss: 1.5957057476043701
Validation loss: 1.9660116780188777

Epoch: 5| Step: 1
Training loss: 1.5311836004257202
Validation loss: 1.9970506686036305

Epoch: 5| Step: 2
Training loss: 1.750292181968689
Validation loss: 2.013598721514466

Epoch: 5| Step: 3
Training loss: 1.5058386325836182
Validation loss: 2.0418492440254457

Epoch: 5| Step: 4
Training loss: 1.713439702987671
Validation loss: 2.052117934790991

Epoch: 5| Step: 5
Training loss: 1.770787000656128
Validation loss: 2.0448690845120336

Epoch: 5| Step: 6
Training loss: 1.9085906744003296
Validation loss: 2.013482439902521

Epoch: 5| Step: 7
Training loss: 1.4869959354400635
Validation loss: 2.0278579086385746

Epoch: 5| Step: 8
Training loss: 1.6286331415176392
Validation loss: 2.039828338930684

Epoch: 5| Step: 9
Training loss: 1.904051423072815
Validation loss: 2.0364420439607356

Epoch: 5| Step: 10
Training loss: 1.663966417312622
Validation loss: 2.038018271487246

Epoch: 136| Step: 0
Training loss: 1.4184995889663696
Validation loss: 2.028964384909599

Epoch: 5| Step: 1
Training loss: 1.3320462703704834
Validation loss: 2.022944314505464

Epoch: 5| Step: 2
Training loss: 2.1257641315460205
Validation loss: 2.010717447086047

Epoch: 5| Step: 3
Training loss: 1.8026459217071533
Validation loss: 1.9977694275558635

Epoch: 5| Step: 4
Training loss: 1.5557966232299805
Validation loss: 2.009777215219313

Epoch: 5| Step: 5
Training loss: 0.9892678260803223
Validation loss: 2.0064354378690004

Epoch: 5| Step: 6
Training loss: 1.638458251953125
Validation loss: 2.0188058640367244

Epoch: 5| Step: 7
Training loss: 1.5739741325378418
Validation loss: 2.0361432708719724

Epoch: 5| Step: 8
Training loss: 1.9817750453948975
Validation loss: 2.0589780038402927

Epoch: 5| Step: 9
Training loss: 1.6179265975952148
Validation loss: 2.07165979185412

Epoch: 5| Step: 10
Training loss: 2.249781847000122
Validation loss: 2.0890207316285823

Epoch: 137| Step: 0
Training loss: 1.6610740423202515
Validation loss: 2.0609648535328526

Epoch: 5| Step: 1
Training loss: 1.5447337627410889
Validation loss: 2.054003691160551

Epoch: 5| Step: 2
Training loss: 1.8930000066757202
Validation loss: 2.028128506034933

Epoch: 5| Step: 3
Training loss: 1.5894536972045898
Validation loss: 1.9947217113228255

Epoch: 5| Step: 4
Training loss: 2.1812212467193604
Validation loss: 1.979242568374962

Epoch: 5| Step: 5
Training loss: 2.1762590408325195
Validation loss: 1.9636284946113505

Epoch: 5| Step: 6
Training loss: 1.8426986932754517
Validation loss: 1.9674182284262873

Epoch: 5| Step: 7
Training loss: 1.5928882360458374
Validation loss: 1.948821690774733

Epoch: 5| Step: 8
Training loss: 1.594165325164795
Validation loss: 1.956549418869839

Epoch: 5| Step: 9
Training loss: 0.7154197096824646
Validation loss: 1.9781623450658654

Epoch: 5| Step: 10
Training loss: 1.10133695602417
Validation loss: 2.000196587654852

Epoch: 138| Step: 0
Training loss: 1.1987229585647583
Validation loss: 2.0420433090579126

Epoch: 5| Step: 1
Training loss: 1.4518496990203857
Validation loss: 2.0539274702789965

Epoch: 5| Step: 2
Training loss: 1.285989761352539
Validation loss: 2.0870580673217773

Epoch: 5| Step: 3
Training loss: 1.845039963722229
Validation loss: 2.096840491858862

Epoch: 5| Step: 4
Training loss: 1.5307371616363525
Validation loss: 2.0950515885506906

Epoch: 5| Step: 5
Training loss: 1.7198688983917236
Validation loss: 2.0915978647047475

Epoch: 5| Step: 6
Training loss: 1.8804943561553955
Validation loss: 2.0503864672876175

Epoch: 5| Step: 7
Training loss: 1.4164377450942993
Validation loss: 2.0103681356676164

Epoch: 5| Step: 8
Training loss: 1.5989733934402466
Validation loss: 1.9872191234301495

Epoch: 5| Step: 9
Training loss: 2.07448148727417
Validation loss: 1.9692779305160686

Epoch: 5| Step: 10
Training loss: 1.876958966255188
Validation loss: 1.9622247219085693

Epoch: 139| Step: 0
Training loss: 1.555710792541504
Validation loss: 1.9618971706718527

Epoch: 5| Step: 1
Training loss: 2.118752956390381
Validation loss: 1.9804682398355136

Epoch: 5| Step: 2
Training loss: 1.7914985418319702
Validation loss: 1.9603984637926983

Epoch: 5| Step: 3
Training loss: 1.487511157989502
Validation loss: 1.9868032022189068

Epoch: 5| Step: 4
Training loss: 2.047640562057495
Validation loss: 2.018116069096391

Epoch: 5| Step: 5
Training loss: 1.2260181903839111
Validation loss: 2.029676773214853

Epoch: 5| Step: 6
Training loss: 1.9107736349105835
Validation loss: 2.0288523807320544

Epoch: 5| Step: 7
Training loss: 1.7787154912948608
Validation loss: 2.0224571253663752

Epoch: 5| Step: 8
Training loss: 1.2324669361114502
Validation loss: 2.0125400917504424

Epoch: 5| Step: 9
Training loss: 0.9321429133415222
Validation loss: 2.0002411129654094

Epoch: 5| Step: 10
Training loss: 1.2904597520828247
Validation loss: 2.0022775127041723

Epoch: 140| Step: 0
Training loss: 1.2577550411224365
Validation loss: 2.024494191651703

Epoch: 5| Step: 1
Training loss: 1.09274423122406
Validation loss: 2.008146496229274

Epoch: 5| Step: 2
Training loss: 1.2927261590957642
Validation loss: 1.9990789633925243

Epoch: 5| Step: 3
Training loss: 1.933652639389038
Validation loss: 1.9848382524264756

Epoch: 5| Step: 4
Training loss: 1.5044180154800415
Validation loss: 1.994692099991665

Epoch: 5| Step: 5
Training loss: 1.5378906726837158
Validation loss: 1.9949975347006192

Epoch: 5| Step: 6
Training loss: 2.2653965950012207
Validation loss: 1.9864980648922663

Epoch: 5| Step: 7
Training loss: 1.8403904438018799
Validation loss: 2.0122583425173195

Epoch: 5| Step: 8
Training loss: 1.1396433115005493
Validation loss: 2.018825884788267

Epoch: 5| Step: 9
Training loss: 1.4523125886917114
Validation loss: 2.0491767724355063

Epoch: 5| Step: 10
Training loss: 1.7720086574554443
Validation loss: 2.050285129136937

Epoch: 141| Step: 0
Training loss: 1.4741297960281372
Validation loss: 2.076631861348306

Epoch: 5| Step: 1
Training loss: 1.3102362155914307
Validation loss: 2.062464068012853

Epoch: 5| Step: 2
Training loss: 1.9122202396392822
Validation loss: 2.043196141078908

Epoch: 5| Step: 3
Training loss: 1.6172668933868408
Validation loss: 2.0244540911848827

Epoch: 5| Step: 4
Training loss: 0.7916039228439331
Validation loss: 1.9972205828594904

Epoch: 5| Step: 5
Training loss: 1.4360015392303467
Validation loss: 1.9979614826940721

Epoch: 5| Step: 6
Training loss: 1.5624229907989502
Validation loss: 2.0076191143323014

Epoch: 5| Step: 7
Training loss: 1.7420517206192017
Validation loss: 2.032394761680275

Epoch: 5| Step: 8
Training loss: 1.498107671737671
Validation loss: 2.0588456738379692

Epoch: 5| Step: 9
Training loss: 1.9629968404769897
Validation loss: 2.051646342841528

Epoch: 5| Step: 10
Training loss: 1.7558282613754272
Validation loss: 2.041656450558734

Epoch: 142| Step: 0
Training loss: 1.5448850393295288
Validation loss: 2.03873021628267

Epoch: 5| Step: 1
Training loss: 1.5147122144699097
Validation loss: 2.0472771762519755

Epoch: 5| Step: 2
Training loss: 1.70990788936615
Validation loss: 2.0420161113944104

Epoch: 5| Step: 3
Training loss: 1.6475276947021484
Validation loss: 2.017851734674105

Epoch: 5| Step: 4
Training loss: 1.2977052927017212
Validation loss: 2.0107990900675454

Epoch: 5| Step: 5
Training loss: 1.6161441802978516
Validation loss: 2.019842550318728

Epoch: 5| Step: 6
Training loss: 0.8189708590507507
Validation loss: 2.0306296707481466

Epoch: 5| Step: 7
Training loss: 1.5861527919769287
Validation loss: 2.0640034060324393

Epoch: 5| Step: 8
Training loss: 1.468719720840454
Validation loss: 2.086166020362608

Epoch: 5| Step: 9
Training loss: 2.07576322555542
Validation loss: 2.085603980607884

Epoch: 5| Step: 10
Training loss: 1.8578500747680664
Validation loss: 2.0392120192127843

Epoch: 143| Step: 0
Training loss: 1.6802895069122314
Validation loss: 2.0198406801428845

Epoch: 5| Step: 1
Training loss: 1.5042102336883545
Validation loss: 1.997233401062668

Epoch: 5| Step: 2
Training loss: 1.2983323335647583
Validation loss: 2.0114708318505237

Epoch: 5| Step: 3
Training loss: 2.039979934692383
Validation loss: 2.039290435852543

Epoch: 5| Step: 4
Training loss: 1.5950992107391357
Validation loss: 2.0454912416396605

Epoch: 5| Step: 5
Training loss: 1.4060859680175781
Validation loss: 2.025281495945428

Epoch: 5| Step: 6
Training loss: 1.4552342891693115
Validation loss: 2.0101073429148686

Epoch: 5| Step: 7
Training loss: 1.4614311456680298
Validation loss: 2.0237827916299143

Epoch: 5| Step: 8
Training loss: 1.118833303451538
Validation loss: 1.9971576031818186

Epoch: 5| Step: 9
Training loss: 1.6763191223144531
Validation loss: 1.962747068815334

Epoch: 5| Step: 10
Training loss: 1.5666780471801758
Validation loss: 1.9265208154596307

Epoch: 144| Step: 0
Training loss: 1.003426432609558
Validation loss: 1.9202842161219607

Epoch: 5| Step: 1
Training loss: 1.1959688663482666
Validation loss: 1.918437348899021

Epoch: 5| Step: 2
Training loss: 1.580209732055664
Validation loss: 1.9577422923939203

Epoch: 5| Step: 3
Training loss: 1.5568166971206665
Validation loss: 1.9637278895224295

Epoch: 5| Step: 4
Training loss: 1.090684175491333
Validation loss: 1.9740277746672272

Epoch: 5| Step: 5
Training loss: 1.358291506767273
Validation loss: 2.013974861432147

Epoch: 5| Step: 6
Training loss: 1.9530004262924194
Validation loss: 1.9942400352929228

Epoch: 5| Step: 7
Training loss: 1.8778623342514038
Validation loss: 2.020877117751747

Epoch: 5| Step: 8
Training loss: 1.3680870532989502
Validation loss: 2.0358560341660694

Epoch: 5| Step: 9
Training loss: 1.8112516403198242
Validation loss: 2.01409040727923

Epoch: 5| Step: 10
Training loss: 1.9038909673690796
Validation loss: 1.9894415934880574

Epoch: 145| Step: 0
Training loss: 1.4456760883331299
Validation loss: 1.9985539169721707

Epoch: 5| Step: 1
Training loss: 1.6105104684829712
Validation loss: 1.9980103828573739

Epoch: 5| Step: 2
Training loss: 1.6306746006011963
Validation loss: 1.994867350465508

Epoch: 5| Step: 3
Training loss: 1.0122979879379272
Validation loss: 1.9655153571918447

Epoch: 5| Step: 4
Training loss: 1.5249547958374023
Validation loss: 1.974124728992421

Epoch: 5| Step: 5
Training loss: 1.4297605752944946
Validation loss: 1.9251578777067122

Epoch: 5| Step: 6
Training loss: 1.5589849948883057
Validation loss: 1.9233318413457563

Epoch: 5| Step: 7
Training loss: 1.637195348739624
Validation loss: 1.9258854748100362

Epoch: 5| Step: 8
Training loss: 1.5969908237457275
Validation loss: 1.9320033134952668

Epoch: 5| Step: 9
Training loss: 1.1773247718811035
Validation loss: 1.9493941158376715

Epoch: 5| Step: 10
Training loss: 1.7495489120483398
Validation loss: 1.989174601852253

Epoch: 146| Step: 0
Training loss: 1.3023240566253662
Validation loss: 1.9948736301032446

Epoch: 5| Step: 1
Training loss: 1.7932822704315186
Validation loss: 2.007381853236947

Epoch: 5| Step: 2
Training loss: 1.1176146268844604
Validation loss: 2.0060284188998643

Epoch: 5| Step: 3
Training loss: 1.6642967462539673
Validation loss: 2.031205984853929

Epoch: 5| Step: 4
Training loss: 1.272118091583252
Validation loss: 2.0327619352648334

Epoch: 5| Step: 5
Training loss: 1.7315517663955688
Validation loss: 2.0230863068693425

Epoch: 5| Step: 6
Training loss: 1.7316598892211914
Validation loss: 2.0239689709037862

Epoch: 5| Step: 7
Training loss: 1.1512072086334229
Validation loss: 2.0140923377006286

Epoch: 5| Step: 8
Training loss: 1.2013450860977173
Validation loss: 1.9936099001156387

Epoch: 5| Step: 9
Training loss: 1.589229941368103
Validation loss: 1.9916247962623514

Epoch: 5| Step: 10
Training loss: 1.4309507608413696
Validation loss: 1.9731533629919893

Epoch: 147| Step: 0
Training loss: 0.9666630625724792
Validation loss: 1.9724034775969803

Epoch: 5| Step: 1
Training loss: 1.0350637435913086
Validation loss: 1.9575542096168763

Epoch: 5| Step: 2
Training loss: 1.3489450216293335
Validation loss: 1.9321908643168788

Epoch: 5| Step: 3
Training loss: 1.3463208675384521
Validation loss: 1.959676637444445

Epoch: 5| Step: 4
Training loss: 1.9264857769012451
Validation loss: 1.9528927572311894

Epoch: 5| Step: 5
Training loss: 1.6291930675506592
Validation loss: 1.954321797176074

Epoch: 5| Step: 6
Training loss: 1.0087491273880005
Validation loss: 1.9623800093127834

Epoch: 5| Step: 7
Training loss: 1.4866663217544556
Validation loss: 1.9924493938364007

Epoch: 5| Step: 8
Training loss: 1.7381105422973633
Validation loss: 1.9812695031524987

Epoch: 5| Step: 9
Training loss: 1.258884310722351
Validation loss: 1.9948678490936116

Epoch: 5| Step: 10
Training loss: 1.9195737838745117
Validation loss: 2.0131199488075833

Epoch: 148| Step: 0
Training loss: 1.4435964822769165
Validation loss: 2.0077736621261923

Epoch: 5| Step: 1
Training loss: 1.4187740087509155
Validation loss: 1.9766907615046347

Epoch: 5| Step: 2
Training loss: 1.1502258777618408
Validation loss: 1.9683661614694903

Epoch: 5| Step: 3
Training loss: 1.0950881242752075
Validation loss: 1.955632048268472

Epoch: 5| Step: 4
Training loss: 1.3065402507781982
Validation loss: 1.9641434902785926

Epoch: 5| Step: 5
Training loss: 1.47539484500885
Validation loss: 1.9759193261464436

Epoch: 5| Step: 6
Training loss: 1.2491047382354736
Validation loss: 2.00381625083185

Epoch: 5| Step: 7
Training loss: 1.8537229299545288
Validation loss: 2.03407484228893

Epoch: 5| Step: 8
Training loss: 1.4338054656982422
Validation loss: 2.0525873168822257

Epoch: 5| Step: 9
Training loss: 1.530178189277649
Validation loss: 2.058126411130351

Epoch: 5| Step: 10
Training loss: 1.2612766027450562
Validation loss: 2.0367664470467517

Epoch: 149| Step: 0
Training loss: 1.3736220598220825
Validation loss: 1.9952831857947892

Epoch: 5| Step: 1
Training loss: 1.2445869445800781
Validation loss: 1.9737326983482606

Epoch: 5| Step: 2
Training loss: 0.9694311022758484
Validation loss: 1.9307540334681028

Epoch: 5| Step: 3
Training loss: 1.2459546327590942
Validation loss: 1.9153232382189842

Epoch: 5| Step: 4
Training loss: 1.1400045156478882
Validation loss: 1.9097452176514493

Epoch: 5| Step: 5
Training loss: 1.5582427978515625
Validation loss: 1.927182424452997

Epoch: 5| Step: 6
Training loss: 1.3883349895477295
Validation loss: 1.956951948904222

Epoch: 5| Step: 7
Training loss: 1.5078115463256836
Validation loss: 1.9629862064956336

Epoch: 5| Step: 8
Training loss: 1.6781749725341797
Validation loss: 1.9582360944440287

Epoch: 5| Step: 9
Training loss: 1.738247275352478
Validation loss: 1.9732177898448

Epoch: 5| Step: 10
Training loss: 1.4231081008911133
Validation loss: 1.9712700779720018

Epoch: 150| Step: 0
Training loss: 1.3370792865753174
Validation loss: 1.998939916651736

Epoch: 5| Step: 1
Training loss: 1.074906349182129
Validation loss: 2.0064608691841044

Epoch: 5| Step: 2
Training loss: 1.4719853401184082
Validation loss: 2.010395291031048

Epoch: 5| Step: 3
Training loss: 0.8100445866584778
Validation loss: 2.0207027927521737

Epoch: 5| Step: 4
Training loss: 1.494571566581726
Validation loss: 2.005182053453179

Epoch: 5| Step: 5
Training loss: 1.9662030935287476
Validation loss: 1.9933082339584187

Epoch: 5| Step: 6
Training loss: 1.1319414377212524
Validation loss: 2.0011859555398264

Epoch: 5| Step: 7
Training loss: 1.1277827024459839
Validation loss: 1.9642651645086144

Epoch: 5| Step: 8
Training loss: 1.4701755046844482
Validation loss: 1.9684140964220929

Epoch: 5| Step: 9
Training loss: 1.6825034618377686
Validation loss: 1.9565092696938464

Epoch: 5| Step: 10
Training loss: 1.412226915359497
Validation loss: 1.943071884493674

Epoch: 151| Step: 0
Training loss: 0.7932430505752563
Validation loss: 1.967576196116786

Epoch: 5| Step: 1
Training loss: 0.8926655054092407
Validation loss: 1.9719410929628598

Epoch: 5| Step: 2
Training loss: 0.9906914830207825
Validation loss: 1.998246818460444

Epoch: 5| Step: 3
Training loss: 1.1789308786392212
Validation loss: 1.9932313478121193

Epoch: 5| Step: 4
Training loss: 2.027108907699585
Validation loss: 1.996019059611905

Epoch: 5| Step: 5
Training loss: 1.1816011667251587
Validation loss: 2.0236445370540825

Epoch: 5| Step: 6
Training loss: 1.2702922821044922
Validation loss: 2.039429808175692

Epoch: 5| Step: 7
Training loss: 1.7204265594482422
Validation loss: 2.0558264665706183

Epoch: 5| Step: 8
Training loss: 1.7844794988632202
Validation loss: 2.0604028060872066

Epoch: 5| Step: 9
Training loss: 1.416024088859558
Validation loss: 2.0288069978837044

Epoch: 5| Step: 10
Training loss: 1.615098237991333
Validation loss: 2.01493493459558

Epoch: 152| Step: 0
Training loss: 1.2604392766952515
Validation loss: 1.9444668395544893

Epoch: 5| Step: 1
Training loss: 1.5926340818405151
Validation loss: 1.9274484354962584

Epoch: 5| Step: 2
Training loss: 0.9053606986999512
Validation loss: 1.9072835727404522

Epoch: 5| Step: 3
Training loss: 1.0764720439910889
Validation loss: 1.8912947562433058

Epoch: 5| Step: 4
Training loss: 1.87810480594635
Validation loss: 1.905513104572091

Epoch: 5| Step: 5
Training loss: 1.442042589187622
Validation loss: 1.9435850907397527

Epoch: 5| Step: 6
Training loss: 1.3352651596069336
Validation loss: 1.9683426118666125

Epoch: 5| Step: 7
Training loss: 1.3087139129638672
Validation loss: 1.9844849609559583

Epoch: 5| Step: 8
Training loss: 1.4154917001724243
Validation loss: 1.9885187123411445

Epoch: 5| Step: 9
Training loss: 1.3049834966659546
Validation loss: 1.9873605838385962

Epoch: 5| Step: 10
Training loss: 1.002616047859192
Validation loss: 2.0080139329356532

Epoch: 153| Step: 0
Training loss: 1.1495540142059326
Validation loss: 2.0644615824504564

Epoch: 5| Step: 1
Training loss: 1.5795226097106934
Validation loss: 2.0661120504461308

Epoch: 5| Step: 2
Training loss: 1.238775372505188
Validation loss: 2.022754235934186

Epoch: 5| Step: 3
Training loss: 1.148525595664978
Validation loss: 1.9937177473498928

Epoch: 5| Step: 4
Training loss: 1.092703938484192
Validation loss: 1.9613382124131726

Epoch: 5| Step: 5
Training loss: 1.0186443328857422
Validation loss: 1.980954324045489

Epoch: 5| Step: 6
Training loss: 1.3472172021865845
Validation loss: 1.988044624687523

Epoch: 5| Step: 7
Training loss: 1.9876317977905273
Validation loss: 1.9692766217775242

Epoch: 5| Step: 8
Training loss: 1.4793798923492432
Validation loss: 1.9592716104240828

Epoch: 5| Step: 9
Training loss: 1.413511037826538
Validation loss: 1.9347236156463623

Epoch: 5| Step: 10
Training loss: 0.981438934803009
Validation loss: 1.9304522365652106

Epoch: 154| Step: 0
Training loss: 1.978022813796997
Validation loss: 1.949196429662807

Epoch: 5| Step: 1
Training loss: 1.0314650535583496
Validation loss: 1.9840396911867204

Epoch: 5| Step: 2
Training loss: 1.384009599685669
Validation loss: 1.9822320912473945

Epoch: 5| Step: 3
Training loss: 1.4224283695220947
Validation loss: 2.0361893074486845

Epoch: 5| Step: 4
Training loss: 1.1949975490570068
Validation loss: 2.041348744464177

Epoch: 5| Step: 5
Training loss: 1.4800207614898682
Validation loss: 2.026012687272923

Epoch: 5| Step: 6
Training loss: 1.084787130355835
Validation loss: 1.9624233271486016

Epoch: 5| Step: 7
Training loss: 0.9296728372573853
Validation loss: 1.9399658223634124

Epoch: 5| Step: 8
Training loss: 1.3158025741577148
Validation loss: 1.9250316530145624

Epoch: 5| Step: 9
Training loss: 1.1635007858276367
Validation loss: 1.901500596795031

Epoch: 5| Step: 10
Training loss: 1.3056472539901733
Validation loss: 1.905729611714681

Epoch: 155| Step: 0
Training loss: 1.8265750408172607
Validation loss: 1.9175779986125168

Epoch: 5| Step: 1
Training loss: 1.0515711307525635
Validation loss: 1.9253964398496894

Epoch: 5| Step: 2
Training loss: 1.0217598676681519
Validation loss: 1.9680557212521952

Epoch: 5| Step: 3
Training loss: 1.5989024639129639
Validation loss: 2.0002535543134137

Epoch: 5| Step: 4
Training loss: 1.7534719705581665
Validation loss: 2.0669944311982844

Epoch: 5| Step: 5
Training loss: 1.8113481998443604
Validation loss: 2.078220475104547

Epoch: 5| Step: 6
Training loss: 1.3479931354522705
Validation loss: 2.07115359972882

Epoch: 5| Step: 7
Training loss: 0.819595217704773
Validation loss: 2.0637959639231362

Epoch: 5| Step: 8
Training loss: 0.9386908411979675
Validation loss: 2.02227968810707

Epoch: 5| Step: 9
Training loss: 0.8404979705810547
Validation loss: 2.017878488827777

Epoch: 5| Step: 10
Training loss: 1.0832486152648926
Validation loss: 1.994508304903584

Epoch: 156| Step: 0
Training loss: 0.91631680727005
Validation loss: 1.9832858526578514

Epoch: 5| Step: 1
Training loss: 1.252150297164917
Validation loss: 1.9591725949318177

Epoch: 5| Step: 2
Training loss: 0.7814807295799255
Validation loss: 1.9694065919486425

Epoch: 5| Step: 3
Training loss: 1.484760046005249
Validation loss: 1.9884666012179466

Epoch: 5| Step: 4
Training loss: 1.4099289178848267
Validation loss: 1.958418628220917

Epoch: 5| Step: 5
Training loss: 1.3321665525436401
Validation loss: 1.9509747079623643

Epoch: 5| Step: 6
Training loss: 1.7689697742462158
Validation loss: 1.936054168208953

Epoch: 5| Step: 7
Training loss: 1.3451778888702393
Validation loss: 1.9303681619705693

Epoch: 5| Step: 8
Training loss: 1.6733795404434204
Validation loss: 1.9232359432405042

Epoch: 5| Step: 9
Training loss: 1.4294848442077637
Validation loss: 1.9336790474512244

Epoch: 5| Step: 10
Training loss: 0.5774669647216797
Validation loss: 1.9554209452803417

Epoch: 157| Step: 0
Training loss: 1.3744409084320068
Validation loss: 1.9702697274505452

Epoch: 5| Step: 1
Training loss: 1.5662901401519775
Validation loss: 1.9878630548395135

Epoch: 5| Step: 2
Training loss: 1.2948535680770874
Validation loss: 2.011042848710091

Epoch: 5| Step: 3
Training loss: 1.5340076684951782
Validation loss: 2.0277751235551733

Epoch: 5| Step: 4
Training loss: 1.0199116468429565
Validation loss: 2.0480866727008613

Epoch: 5| Step: 5
Training loss: 0.7264119386672974
Validation loss: 2.0519348241949595

Epoch: 5| Step: 6
Training loss: 1.3612823486328125
Validation loss: 2.033193293438163

Epoch: 5| Step: 7
Training loss: 1.776519536972046
Validation loss: 2.001271358100317

Epoch: 5| Step: 8
Training loss: 0.795462965965271
Validation loss: 1.9545341871118034

Epoch: 5| Step: 9
Training loss: 1.2172671556472778
Validation loss: 1.9332348172382643

Epoch: 5| Step: 10
Training loss: 1.1199811697006226
Validation loss: 1.9128641159303728

Epoch: 158| Step: 0
Training loss: 1.3447787761688232
Validation loss: 1.9327170759119012

Epoch: 5| Step: 1
Training loss: 1.2434298992156982
Validation loss: 1.9337137117180774

Epoch: 5| Step: 2
Training loss: 0.8228175044059753
Validation loss: 1.9540428089839157

Epoch: 5| Step: 3
Training loss: 1.0223506689071655
Validation loss: 1.9529039680316884

Epoch: 5| Step: 4
Training loss: 1.7067101001739502
Validation loss: 1.9768707906046221

Epoch: 5| Step: 5
Training loss: 0.8540083765983582
Validation loss: 2.0184156728047196

Epoch: 5| Step: 6
Training loss: 1.5244083404541016
Validation loss: 2.0553190323614303

Epoch: 5| Step: 7
Training loss: 1.2398359775543213
Validation loss: 2.0400065811731483

Epoch: 5| Step: 8
Training loss: 1.3030239343643188
Validation loss: 2.029907218871578

Epoch: 5| Step: 9
Training loss: 1.2695609331130981
Validation loss: 1.9900370810621528

Epoch: 5| Step: 10
Training loss: 1.6533819437026978
Validation loss: 1.9574455279175953

Epoch: 159| Step: 0
Training loss: 0.9145475625991821
Validation loss: 1.931432052325177

Epoch: 5| Step: 1
Training loss: 1.4752038717269897
Validation loss: 1.9384350212671424

Epoch: 5| Step: 2
Training loss: 1.2934080362319946
Validation loss: 1.9363360020422167

Epoch: 5| Step: 3
Training loss: 1.565951943397522
Validation loss: 1.9296104638807234

Epoch: 5| Step: 4
Training loss: 1.3850953578948975
Validation loss: 1.9894376595815022

Epoch: 5| Step: 5
Training loss: 1.4768487215042114
Validation loss: 2.008252546351443

Epoch: 5| Step: 6
Training loss: 0.8221527338027954
Validation loss: 1.9963268874793925

Epoch: 5| Step: 7
Training loss: 1.1446197032928467
Validation loss: 1.9936322127619097

Epoch: 5| Step: 8
Training loss: 1.100319504737854
Validation loss: 1.9823354995378883

Epoch: 5| Step: 9
Training loss: 1.2565765380859375
Validation loss: 1.9942822507632676

Epoch: 5| Step: 10
Training loss: 1.1688472032546997
Validation loss: 1.9981926474519955

Epoch: 160| Step: 0
Training loss: 0.9777995944023132
Validation loss: 1.9672094352783696

Epoch: 5| Step: 1
Training loss: 1.054306983947754
Validation loss: 1.9395487000865321

Epoch: 5| Step: 2
Training loss: 1.1686094999313354
Validation loss: 1.9180642545864146

Epoch: 5| Step: 3
Training loss: 1.2381864786148071
Validation loss: 1.9106679026798536

Epoch: 5| Step: 4
Training loss: 1.0981401205062866
Validation loss: 1.9121748580727527

Epoch: 5| Step: 5
Training loss: 1.6923112869262695
Validation loss: 1.9359356382841706

Epoch: 5| Step: 6
Training loss: 1.5823886394500732
Validation loss: 1.9367256420914845

Epoch: 5| Step: 7
Training loss: 1.1355632543563843
Validation loss: 1.9426727243649062

Epoch: 5| Step: 8
Training loss: 1.5669031143188477
Validation loss: 1.9921324817083215

Epoch: 5| Step: 9
Training loss: 1.2840207815170288
Validation loss: 2.0358879130373717

Epoch: 5| Step: 10
Training loss: 0.7036223411560059
Validation loss: 2.080639031625563

Epoch: 161| Step: 0
Training loss: 1.144436240196228
Validation loss: 2.1261518629648353

Epoch: 5| Step: 1
Training loss: 1.7259514331817627
Validation loss: 2.158767923232048

Epoch: 5| Step: 2
Training loss: 0.6591651439666748
Validation loss: 2.1159412553233485

Epoch: 5| Step: 3
Training loss: 1.1553055047988892
Validation loss: 2.075912635813477

Epoch: 5| Step: 4
Training loss: 1.0492080450057983
Validation loss: 2.004556473865304

Epoch: 5| Step: 5
Training loss: 1.3477027416229248
Validation loss: 1.9604220646683888

Epoch: 5| Step: 6
Training loss: 0.8381834030151367
Validation loss: 1.9165932375897643

Epoch: 5| Step: 7
Training loss: 1.0813010931015015
Validation loss: 1.892778370970039

Epoch: 5| Step: 8
Training loss: 1.7359193563461304
Validation loss: 1.8692909415050218

Epoch: 5| Step: 9
Training loss: 1.499228835105896
Validation loss: 1.8614132481236612

Epoch: 5| Step: 10
Training loss: 1.3503302335739136
Validation loss: 1.8565493681097542

Epoch: 162| Step: 0
Training loss: 1.2782142162322998
Validation loss: 1.874474076814549

Epoch: 5| Step: 1
Training loss: 1.132886290550232
Validation loss: 1.921906421261449

Epoch: 5| Step: 2
Training loss: 1.4543062448501587
Validation loss: 1.922650675619802

Epoch: 5| Step: 3
Training loss: 0.8325067758560181
Validation loss: 1.9549829447141258

Epoch: 5| Step: 4
Training loss: 1.1389214992523193
Validation loss: 1.9472134882403958

Epoch: 5| Step: 5
Training loss: 0.7865122556686401
Validation loss: 1.9419411741277224

Epoch: 5| Step: 6
Training loss: 1.3971704244613647
Validation loss: 1.9343101298937233

Epoch: 5| Step: 7
Training loss: 1.3383005857467651
Validation loss: 1.9381786507944907

Epoch: 5| Step: 8
Training loss: 1.5174942016601562
Validation loss: 1.9228976259949386

Epoch: 5| Step: 9
Training loss: 1.1724908351898193
Validation loss: 1.946378388712483

Epoch: 5| Step: 10
Training loss: 1.0551276206970215
Validation loss: 1.9421776571581442

Epoch: 163| Step: 0
Training loss: 1.4225547313690186
Validation loss: 1.9388946051238685

Epoch: 5| Step: 1
Training loss: 0.858737587928772
Validation loss: 1.9350401381010651

Epoch: 5| Step: 2
Training loss: 1.0736931562423706
Validation loss: 1.9149556365064395

Epoch: 5| Step: 3
Training loss: 1.1430704593658447
Validation loss: 1.8586231790563112

Epoch: 5| Step: 4
Training loss: 0.7696607708930969
Validation loss: 1.8807037773952688

Epoch: 5| Step: 5
Training loss: 1.1781843900680542
Validation loss: 1.8821192069720196

Epoch: 5| Step: 6
Training loss: 1.2198622226715088
Validation loss: 1.9104761205693728

Epoch: 5| Step: 7
Training loss: 1.4041023254394531
Validation loss: 1.9293566057758946

Epoch: 5| Step: 8
Training loss: 1.381998062133789
Validation loss: 1.9420661272541169

Epoch: 5| Step: 9
Training loss: 1.3983081579208374
Validation loss: 1.9868488516858829

Epoch: 5| Step: 10
Training loss: 1.1574649810791016
Validation loss: 2.021588865146842

Epoch: 164| Step: 0
Training loss: 1.0980281829833984
Validation loss: 2.0493351310812016

Epoch: 5| Step: 1
Training loss: 0.822413444519043
Validation loss: 2.0448781162179928

Epoch: 5| Step: 2
Training loss: 1.5191328525543213
Validation loss: 2.000116809721916

Epoch: 5| Step: 3
Training loss: 0.9451066851615906
Validation loss: 1.9316940628072268

Epoch: 5| Step: 4
Training loss: 1.2079765796661377
Validation loss: 1.9098078999468076

Epoch: 5| Step: 5
Training loss: 1.4982951879501343
Validation loss: 1.929777850386917

Epoch: 5| Step: 6
Training loss: 1.0493948459625244
Validation loss: 1.9185798181000577

Epoch: 5| Step: 7
Training loss: 1.1325105428695679
Validation loss: 1.9142628049337735

Epoch: 5| Step: 8
Training loss: 1.4061164855957031
Validation loss: 1.938495494986093

Epoch: 5| Step: 9
Training loss: 1.212607979774475
Validation loss: 1.9396064960828392

Epoch: 5| Step: 10
Training loss: 0.8680474758148193
Validation loss: 1.9474497405431603

Epoch: 165| Step: 0
Training loss: 1.1574592590332031
Validation loss: 1.944566503647835

Epoch: 5| Step: 1
Training loss: 1.027382493019104
Validation loss: 1.932254119585919

Epoch: 5| Step: 2
Training loss: 0.5930505990982056
Validation loss: 1.955485761806529

Epoch: 5| Step: 3
Training loss: 1.1273478269577026
Validation loss: 1.9730800659425798

Epoch: 5| Step: 4
Training loss: 1.216141700744629
Validation loss: 2.0156669642335627

Epoch: 5| Step: 5
Training loss: 1.6048113107681274
Validation loss: 2.0207040027905534

Epoch: 5| Step: 6
Training loss: 1.642431616783142
Validation loss: 2.007577218035216

Epoch: 5| Step: 7
Training loss: 1.0243778228759766
Validation loss: 1.9668733637820008

Epoch: 5| Step: 8
Training loss: 1.1017147302627563
Validation loss: 1.9117063963285057

Epoch: 5| Step: 9
Training loss: 1.2891547679901123
Validation loss: 1.8920408705229401

Epoch: 5| Step: 10
Training loss: 0.7462878227233887
Validation loss: 1.855379778851745

Epoch: 166| Step: 0
Training loss: 0.8569177389144897
Validation loss: 1.84454071393577

Epoch: 5| Step: 1
Training loss: 1.2666813135147095
Validation loss: 1.860845617068711

Epoch: 5| Step: 2
Training loss: 0.7872681021690369
Validation loss: 1.8961765304688485

Epoch: 5| Step: 3
Training loss: 1.0771772861480713
Validation loss: 1.932813384199655

Epoch: 5| Step: 4
Training loss: 1.0548597574234009
Validation loss: 1.973269017793799

Epoch: 5| Step: 5
Training loss: 1.2268269062042236
Validation loss: 1.9723230228629163

Epoch: 5| Step: 6
Training loss: 1.671831488609314
Validation loss: 1.9796912272771199

Epoch: 5| Step: 7
Training loss: 1.107771396636963
Validation loss: 1.9607635492919593

Epoch: 5| Step: 8
Training loss: 1.3853644132614136
Validation loss: 1.9769967525236067

Epoch: 5| Step: 9
Training loss: 0.8815914392471313
Validation loss: 2.005636065236984

Epoch: 5| Step: 10
Training loss: 0.9713109135627747
Validation loss: 2.0085633480420677

Epoch: 167| Step: 0
Training loss: 1.187518835067749
Validation loss: 2.045951730461531

Epoch: 5| Step: 1
Training loss: 1.2811164855957031
Validation loss: 2.0703382825338714

Epoch: 5| Step: 2
Training loss: 0.9410303831100464
Validation loss: 2.0753473979170605

Epoch: 5| Step: 3
Training loss: 0.8756949305534363
Validation loss: 2.064105333820466

Epoch: 5| Step: 4
Training loss: 1.48561692237854
Validation loss: 1.9976252048246321

Epoch: 5| Step: 5
Training loss: 1.019812822341919
Validation loss: 1.9456845714199928

Epoch: 5| Step: 6
Training loss: 1.1484991312026978
Validation loss: 1.8688641927575553

Epoch: 5| Step: 7
Training loss: 1.1161844730377197
Validation loss: 1.860640020780666

Epoch: 5| Step: 8
Training loss: 1.7404413223266602
Validation loss: 1.844852957674252

Epoch: 5| Step: 9
Training loss: 0.8683508634567261
Validation loss: 1.8736113412405855

Epoch: 5| Step: 10
Training loss: 0.7006088495254517
Validation loss: 1.8926849403688986

Epoch: 168| Step: 0
Training loss: 0.7800910472869873
Validation loss: 1.9411361666135891

Epoch: 5| Step: 1
Training loss: 1.1658049821853638
Validation loss: 1.9481559786745297

Epoch: 5| Step: 2
Training loss: 1.2699832916259766
Validation loss: 1.963662411576958

Epoch: 5| Step: 3
Training loss: 1.6315933465957642
Validation loss: 1.9764883774583057

Epoch: 5| Step: 4
Training loss: 0.5994224548339844
Validation loss: 1.9993473586215769

Epoch: 5| Step: 5
Training loss: 1.3244686126708984
Validation loss: 2.01451942997594

Epoch: 5| Step: 6
Training loss: 1.0778617858886719
Validation loss: 2.0233668409368044

Epoch: 5| Step: 7
Training loss: 1.0744282007217407
Validation loss: 2.0022339692679783

Epoch: 5| Step: 8
Training loss: 0.9696828126907349
Validation loss: 1.9735570056464082

Epoch: 5| Step: 9
Training loss: 1.2009785175323486
Validation loss: 1.9653512393274615

Epoch: 5| Step: 10
Training loss: 1.3108949661254883
Validation loss: 1.9508175747368925

Epoch: 169| Step: 0
Training loss: 1.3351932764053345
Validation loss: 1.9383573826923166

Epoch: 5| Step: 1
Training loss: 1.2439213991165161
Validation loss: 1.9190423821890226

Epoch: 5| Step: 2
Training loss: 1.0407353639602661
Validation loss: 1.919594536545456

Epoch: 5| Step: 3
Training loss: 0.6195464134216309
Validation loss: 1.9534106331486856

Epoch: 5| Step: 4
Training loss: 1.4415667057037354
Validation loss: 1.9567291134147233

Epoch: 5| Step: 5
Training loss: 1.2610396146774292
Validation loss: 1.9662771788976525

Epoch: 5| Step: 6
Training loss: 1.196326494216919
Validation loss: 1.948858566181634

Epoch: 5| Step: 7
Training loss: 1.0663667917251587
Validation loss: 1.9473207330191007

Epoch: 5| Step: 8
Training loss: 1.40242600440979
Validation loss: 1.958319462755675

Epoch: 5| Step: 9
Training loss: 0.5961834788322449
Validation loss: 1.9467769643311859

Epoch: 5| Step: 10
Training loss: 0.945846676826477
Validation loss: 1.9732259422220209

Epoch: 170| Step: 0
Training loss: 1.1646349430084229
Validation loss: 1.9561490551117928

Epoch: 5| Step: 1
Training loss: 1.394418478012085
Validation loss: 1.9656022223093177

Epoch: 5| Step: 2
Training loss: 1.0176308155059814
Validation loss: 1.9855211088734288

Epoch: 5| Step: 3
Training loss: 1.599179983139038
Validation loss: 1.9785298442327848

Epoch: 5| Step: 4
Training loss: 1.1702461242675781
Validation loss: 1.967839321782512

Epoch: 5| Step: 5
Training loss: 0.8660088777542114
Validation loss: 1.9700819523103776

Epoch: 5| Step: 6
Training loss: 0.8948239088058472
Validation loss: 1.9158502471062444

Epoch: 5| Step: 7
Training loss: 1.050679087638855
Validation loss: 1.9376833528600714

Epoch: 5| Step: 8
Training loss: 1.2323198318481445
Validation loss: 1.9391755878284413

Epoch: 5| Step: 9
Training loss: 0.7500162124633789
Validation loss: 1.9363657248917447

Epoch: 5| Step: 10
Training loss: 0.859253466129303
Validation loss: 1.9320899914669734

Epoch: 171| Step: 0
Training loss: 1.2961418628692627
Validation loss: 1.979561508342784

Epoch: 5| Step: 1
Training loss: 1.1177769899368286
Validation loss: 1.97705203230663

Epoch: 5| Step: 2
Training loss: 0.8333637118339539
Validation loss: 1.9928759374926168

Epoch: 5| Step: 3
Training loss: 1.1498076915740967
Validation loss: 2.009424158321914

Epoch: 5| Step: 4
Training loss: 0.9756733179092407
Validation loss: 2.010256630118175

Epoch: 5| Step: 5
Training loss: 1.3219420909881592
Validation loss: 2.0248516490382533

Epoch: 5| Step: 6
Training loss: 1.1408822536468506
Validation loss: 2.0250825805048787

Epoch: 5| Step: 7
Training loss: 1.4551260471343994
Validation loss: 2.0102348250727498

Epoch: 5| Step: 8
Training loss: 1.036354899406433
Validation loss: 2.0256727023791243

Epoch: 5| Step: 9
Training loss: 0.48975294828414917
Validation loss: 1.9957429503881803

Epoch: 5| Step: 10
Training loss: 1.1609593629837036
Validation loss: 1.9804902076721191

Epoch: 172| Step: 0
Training loss: 1.2417991161346436
Validation loss: 1.9472535489707865

Epoch: 5| Step: 1
Training loss: 0.8404413461685181
Validation loss: 1.9063464826153171

Epoch: 5| Step: 2
Training loss: 1.0628893375396729
Validation loss: 1.880158011631299

Epoch: 5| Step: 3
Training loss: 1.0231143236160278
Validation loss: 1.916534472537297

Epoch: 5| Step: 4
Training loss: 1.649543046951294
Validation loss: 1.9039390023036669

Epoch: 5| Step: 5
Training loss: 1.2216541767120361
Validation loss: 1.8856872743175876

Epoch: 5| Step: 6
Training loss: 0.6538970470428467
Validation loss: 1.9115475326456048

Epoch: 5| Step: 7
Training loss: 1.1507112979888916
Validation loss: 1.9444861847867247

Epoch: 5| Step: 8
Training loss: 1.047282338142395
Validation loss: 1.9709863419173865

Epoch: 5| Step: 9
Training loss: 0.9634979367256165
Validation loss: 2.005579540806432

Epoch: 5| Step: 10
Training loss: 0.9462636113166809
Validation loss: 2.0107645757736696

Epoch: 173| Step: 0
Training loss: 1.3688850402832031
Validation loss: 2.033350590736635

Epoch: 5| Step: 1
Training loss: 1.2666347026824951
Validation loss: 2.0233408225479947

Epoch: 5| Step: 2
Training loss: 0.9423366785049438
Validation loss: 2.003869059265301

Epoch: 5| Step: 3
Training loss: 0.8555908203125
Validation loss: 1.991644310694869

Epoch: 5| Step: 4
Training loss: 0.6544007062911987
Validation loss: 1.9630133310953777

Epoch: 5| Step: 5
Training loss: 1.3360164165496826
Validation loss: 1.950177679779709

Epoch: 5| Step: 6
Training loss: 0.8468127250671387
Validation loss: 1.9718353953412784

Epoch: 5| Step: 7
Training loss: 1.2806212902069092
Validation loss: 1.9651597597265755

Epoch: 5| Step: 8
Training loss: 1.0403201580047607
Validation loss: 1.9228187196998185

Epoch: 5| Step: 9
Training loss: 1.2290951013565063
Validation loss: 1.907271078837815

Epoch: 5| Step: 10
Training loss: 0.7362053990364075
Validation loss: 1.913694921360221

Epoch: 174| Step: 0
Training loss: 0.6076047420501709
Validation loss: 1.9163360480339295

Epoch: 5| Step: 1
Training loss: 0.9936162829399109
Validation loss: 1.9263902864148539

Epoch: 5| Step: 2
Training loss: 0.9210804104804993
Validation loss: 1.9563254002601869

Epoch: 5| Step: 3
Training loss: 1.394619345664978
Validation loss: 1.976467747842112

Epoch: 5| Step: 4
Training loss: 1.2653977870941162
Validation loss: 1.9790619983468005

Epoch: 5| Step: 5
Training loss: 0.6990793347358704
Validation loss: 1.9783257874109412

Epoch: 5| Step: 6
Training loss: 1.157618522644043
Validation loss: 1.9697368350080264

Epoch: 5| Step: 7
Training loss: 1.1037788391113281
Validation loss: 1.9537600201945151

Epoch: 5| Step: 8
Training loss: 0.9154753684997559
Validation loss: 1.956035824232204

Epoch: 5| Step: 9
Training loss: 1.173075556755066
Validation loss: 1.9276313243373748

Epoch: 5| Step: 10
Training loss: 0.9080683588981628
Validation loss: 1.938812804478471

Epoch: 175| Step: 0
Training loss: 0.5740345120429993
Validation loss: 1.9163543549917077

Epoch: 5| Step: 1
Training loss: 0.8162482976913452
Validation loss: 1.9287104401537167

Epoch: 5| Step: 2
Training loss: 0.7007907032966614
Validation loss: 1.9440022296802972

Epoch: 5| Step: 3
Training loss: 0.7295380234718323
Validation loss: 1.963670592154226

Epoch: 5| Step: 4
Training loss: 1.0492759943008423
Validation loss: 1.957764301248776

Epoch: 5| Step: 5
Training loss: 1.5875422954559326
Validation loss: 1.9466926410634031

Epoch: 5| Step: 6
Training loss: 0.9999868273735046
Validation loss: 1.9485098854187997

Epoch: 5| Step: 7
Training loss: 1.1901060342788696
Validation loss: 1.9618239812953497

Epoch: 5| Step: 8
Training loss: 0.7652571797370911
Validation loss: 1.9863586579599688

Epoch: 5| Step: 9
Training loss: 1.4419046640396118
Validation loss: 2.038874872269169

Epoch: 5| Step: 10
Training loss: 1.5815762281417847
Validation loss: 2.095601885549484

Epoch: 176| Step: 0
Training loss: 0.6821731328964233
Validation loss: 2.113283452167306

Epoch: 5| Step: 1
Training loss: 1.5329803228378296
Validation loss: 2.0662100571458057

Epoch: 5| Step: 2
Training loss: 1.0223630666732788
Validation loss: 2.080132238326534

Epoch: 5| Step: 3
Training loss: 0.7201040387153625
Validation loss: 2.000618806449316

Epoch: 5| Step: 4
Training loss: 0.6453481912612915
Validation loss: 1.9151236652046122

Epoch: 5| Step: 5
Training loss: 0.9220942258834839
Validation loss: 1.909336382342923

Epoch: 5| Step: 6
Training loss: 0.9844062924385071
Validation loss: 1.929070649608489

Epoch: 5| Step: 7
Training loss: 1.3165314197540283
Validation loss: 1.930952973263238

Epoch: 5| Step: 8
Training loss: 1.257563829421997
Validation loss: 1.9180236542096702

Epoch: 5| Step: 9
Training loss: 1.6056060791015625
Validation loss: 1.8949142604745843

Epoch: 5| Step: 10
Training loss: 0.6907596588134766
Validation loss: 1.8738268318996634

Epoch: 177| Step: 0
Training loss: 0.8070684671401978
Validation loss: 1.8960413971254904

Epoch: 5| Step: 1
Training loss: 0.8617008924484253
Validation loss: 1.9027801687999437

Epoch: 5| Step: 2
Training loss: 1.0671366453170776
Validation loss: 1.9160584352349723

Epoch: 5| Step: 3
Training loss: 1.1968144178390503
Validation loss: 1.921973709137209

Epoch: 5| Step: 4
Training loss: 0.9752146005630493
Validation loss: 1.9661917583916777

Epoch: 5| Step: 5
Training loss: 1.0174366235733032
Validation loss: 1.9826602807608984

Epoch: 5| Step: 6
Training loss: 0.9157495498657227
Validation loss: 1.9970796954247259

Epoch: 5| Step: 7
Training loss: 1.186543345451355
Validation loss: 2.0213288363590034

Epoch: 5| Step: 8
Training loss: 1.298384666442871
Validation loss: 2.0319357995064027

Epoch: 5| Step: 9
Training loss: 0.7097217440605164
Validation loss: 2.0431121100661573

Epoch: 5| Step: 10
Training loss: 0.6738594174385071
Validation loss: 1.987233664399834

Epoch: 178| Step: 0
Training loss: 1.2172095775604248
Validation loss: 1.948287393457146

Epoch: 5| Step: 1
Training loss: 0.6393827795982361
Validation loss: 1.9291339228230138

Epoch: 5| Step: 2
Training loss: 0.9520689845085144
Validation loss: 1.9345788583960584

Epoch: 5| Step: 3
Training loss: 0.81849604845047
Validation loss: 1.9440317512840353

Epoch: 5| Step: 4
Training loss: 0.8679084777832031
Validation loss: 1.956986120952073

Epoch: 5| Step: 5
Training loss: 0.7055531144142151
Validation loss: 1.9566622421305666

Epoch: 5| Step: 6
Training loss: 1.607216238975525
Validation loss: 1.9813903018992434

Epoch: 5| Step: 7
Training loss: 1.023984432220459
Validation loss: 1.9924150282336819

Epoch: 5| Step: 8
Training loss: 0.9082139730453491
Validation loss: 2.005479144793685

Epoch: 5| Step: 9
Training loss: 1.068886637687683
Validation loss: 2.009368574747475

Epoch: 5| Step: 10
Training loss: 0.9528175592422485
Validation loss: 1.9755128801509898

Epoch: 179| Step: 0
Training loss: 0.5740839838981628
Validation loss: 1.9229526724866641

Epoch: 5| Step: 1
Training loss: 1.019648551940918
Validation loss: 1.896138068168394

Epoch: 5| Step: 2
Training loss: 0.7988960146903992
Validation loss: 1.9083701525965044

Epoch: 5| Step: 3
Training loss: 1.2181861400604248
Validation loss: 1.9043466352647351

Epoch: 5| Step: 4
Training loss: 1.0699018239974976
Validation loss: 1.9023389803465975

Epoch: 5| Step: 5
Training loss: 0.9166984558105469
Validation loss: 1.8906139596816032

Epoch: 5| Step: 6
Training loss: 1.2880803346633911
Validation loss: 1.931900805042636

Epoch: 5| Step: 7
Training loss: 0.9029064178466797
Validation loss: 1.962912146763135

Epoch: 5| Step: 8
Training loss: 1.085176706314087
Validation loss: 1.9764574958432106

Epoch: 5| Step: 9
Training loss: 0.5816022157669067
Validation loss: 1.9925277681760891

Epoch: 5| Step: 10
Training loss: 1.0736263990402222
Validation loss: 1.9830134068765948

Epoch: 180| Step: 0
Training loss: 0.8263075947761536
Validation loss: 1.9979451753759896

Epoch: 5| Step: 1
Training loss: 0.8798255920410156
Validation loss: 1.999309817949931

Epoch: 5| Step: 2
Training loss: 0.9696404337882996
Validation loss: 1.9857487934891895

Epoch: 5| Step: 3
Training loss: 1.1788647174835205
Validation loss: 1.9495349609723656

Epoch: 5| Step: 4
Training loss: 1.0206297636032104
Validation loss: 1.9369737396958053

Epoch: 5| Step: 5
Training loss: 0.6733824014663696
Validation loss: 1.9383441658430203

Epoch: 5| Step: 6
Training loss: 0.9195103645324707
Validation loss: 1.9383779700084398

Epoch: 5| Step: 7
Training loss: 0.5376894474029541
Validation loss: 1.9203195815445275

Epoch: 5| Step: 8
Training loss: 0.8959223031997681
Validation loss: 1.9242429682003555

Epoch: 5| Step: 9
Training loss: 1.2199994325637817
Validation loss: 1.8875596010556785

Epoch: 5| Step: 10
Training loss: 1.4655238389968872
Validation loss: 1.8767123183896464

Epoch: 181| Step: 0
Training loss: 1.0503500699996948
Validation loss: 1.8581023934066936

Epoch: 5| Step: 1
Training loss: 1.012765645980835
Validation loss: 1.8724711710406887

Epoch: 5| Step: 2
Training loss: 1.0784685611724854
Validation loss: 1.875846629501671

Epoch: 5| Step: 3
Training loss: 0.9443349838256836
Validation loss: 1.8916481156503

Epoch: 5| Step: 4
Training loss: 1.0495059490203857
Validation loss: 1.8876606572058894

Epoch: 5| Step: 5
Training loss: 0.8948644399642944
Validation loss: 1.9126993404921664

Epoch: 5| Step: 6
Training loss: 0.9233649969100952
Validation loss: 1.9068418061861427

Epoch: 5| Step: 7
Training loss: 0.6475389003753662
Validation loss: 1.9493095695331533

Epoch: 5| Step: 8
Training loss: 0.7676352262496948
Validation loss: 1.9377648727868193

Epoch: 5| Step: 9
Training loss: 0.6705888509750366
Validation loss: 1.9362249348753242

Epoch: 5| Step: 10
Training loss: 1.3191474676132202
Validation loss: 1.9256195355487127

Epoch: 182| Step: 0
Training loss: 0.4512161314487457
Validation loss: 1.9205228577377975

Epoch: 5| Step: 1
Training loss: 1.1447030305862427
Validation loss: 1.9183783685007403

Epoch: 5| Step: 2
Training loss: 1.094555139541626
Validation loss: 1.9056093782506964

Epoch: 5| Step: 3
Training loss: 0.7387998104095459
Validation loss: 1.8874496324087984

Epoch: 5| Step: 4
Training loss: 1.1478240489959717
Validation loss: 1.9180751462136545

Epoch: 5| Step: 5
Training loss: 1.2304432392120361
Validation loss: 1.9402990700096212

Epoch: 5| Step: 6
Training loss: 1.2132915258407593
Validation loss: 1.9511773163272488

Epoch: 5| Step: 7
Training loss: 0.9390286207199097
Validation loss: 1.9903243562226653

Epoch: 5| Step: 8
Training loss: 0.653014063835144
Validation loss: 1.9740591741377307

Epoch: 5| Step: 9
Training loss: 1.216977596282959
Validation loss: 1.9653748184122064

Epoch: 5| Step: 10
Training loss: 0.497182160615921
Validation loss: 1.9419227543697561

Epoch: 183| Step: 0
Training loss: 1.2250043153762817
Validation loss: 1.915412683640757

Epoch: 5| Step: 1
Training loss: 0.8041073679924011
Validation loss: 1.9020283658017394

Epoch: 5| Step: 2
Training loss: 0.6552637815475464
Validation loss: 1.9188644937289658

Epoch: 5| Step: 3
Training loss: 0.9450559616088867
Validation loss: 1.9051896090148597

Epoch: 5| Step: 4
Training loss: 0.9709633588790894
Validation loss: 1.9173643127564461

Epoch: 5| Step: 5
Training loss: 0.9998403787612915
Validation loss: 1.9146711595596806

Epoch: 5| Step: 6
Training loss: 1.2155320644378662
Validation loss: 1.8889449232368059

Epoch: 5| Step: 7
Training loss: 0.7600713968276978
Validation loss: 1.9105454298757738

Epoch: 5| Step: 8
Training loss: 0.4291148781776428
Validation loss: 1.8938398976479807

Epoch: 5| Step: 9
Training loss: 0.7618220448493958
Validation loss: 1.9058833891345608

Epoch: 5| Step: 10
Training loss: 1.2236567735671997
Validation loss: 1.9253015364370039

Epoch: 184| Step: 0
Training loss: 0.5068031549453735
Validation loss: 1.9223152950245848

Epoch: 5| Step: 1
Training loss: 1.5426127910614014
Validation loss: 1.9251328693923129

Epoch: 5| Step: 2
Training loss: 0.9808831214904785
Validation loss: 1.9133267441103536

Epoch: 5| Step: 3
Training loss: 1.1284377574920654
Validation loss: 1.9045391364764142

Epoch: 5| Step: 4
Training loss: 0.926888644695282
Validation loss: 1.901612352299434

Epoch: 5| Step: 5
Training loss: 0.6543057560920715
Validation loss: 1.9237851532556678

Epoch: 5| Step: 6
Training loss: 0.6619178056716919
Validation loss: 1.9301072679540163

Epoch: 5| Step: 7
Training loss: 0.8799476623535156
Validation loss: 1.934889438331768

Epoch: 5| Step: 8
Training loss: 1.02736496925354
Validation loss: 1.9401852635927097

Epoch: 5| Step: 9
Training loss: 0.941076397895813
Validation loss: 1.9494514311513593

Epoch: 5| Step: 10
Training loss: 0.5693642497062683
Validation loss: 1.9449145999006046

Epoch: 185| Step: 0
Training loss: 0.5956910848617554
Validation loss: 1.9471270627872919

Epoch: 5| Step: 1
Training loss: 0.4742375314235687
Validation loss: 1.9555655397394651

Epoch: 5| Step: 2
Training loss: 0.5855593085289001
Validation loss: 1.9360718445111347

Epoch: 5| Step: 3
Training loss: 0.7474472522735596
Validation loss: 1.908108410014901

Epoch: 5| Step: 4
Training loss: 1.1795604228973389
Validation loss: 1.9282307317180019

Epoch: 5| Step: 5
Training loss: 0.9452478289604187
Validation loss: 1.9565916189583399

Epoch: 5| Step: 6
Training loss: 0.673965334892273
Validation loss: 1.9358163264489943

Epoch: 5| Step: 7
Training loss: 1.1612880229949951
Validation loss: 1.9458110601671281

Epoch: 5| Step: 8
Training loss: 1.3672372102737427
Validation loss: 1.9410487221133323

Epoch: 5| Step: 9
Training loss: 0.9391672015190125
Validation loss: 1.9400595247104604

Epoch: 5| Step: 10
Training loss: 0.9030987620353699
Validation loss: 1.9806337920568322

Epoch: 186| Step: 0
Training loss: 0.7590895891189575
Validation loss: 1.9704796293730378

Epoch: 5| Step: 1
Training loss: 1.1820666790008545
Validation loss: 1.9632478760134788

Epoch: 5| Step: 2
Training loss: 0.9304735064506531
Validation loss: 1.9520403018561743

Epoch: 5| Step: 3
Training loss: 0.7797161340713501
Validation loss: 1.9487993922284854

Epoch: 5| Step: 4
Training loss: 0.8973949551582336
Validation loss: 1.9328246808821155

Epoch: 5| Step: 5
Training loss: 0.9044011831283569
Validation loss: 1.9022812484413065

Epoch: 5| Step: 6
Training loss: 1.2082321643829346
Validation loss: 1.8727228590237197

Epoch: 5| Step: 7
Training loss: 0.8944681882858276
Validation loss: 1.8686545753991732

Epoch: 5| Step: 8
Training loss: 0.732517659664154
Validation loss: 1.8496195629078855

Epoch: 5| Step: 9
Training loss: 0.4951278269290924
Validation loss: 1.853423713355936

Epoch: 5| Step: 10
Training loss: 0.9074043035507202
Validation loss: 1.8774393617465932

Epoch: 187| Step: 0
Training loss: 0.6268098950386047
Validation loss: 1.8768970120337702

Epoch: 5| Step: 1
Training loss: 0.6939421892166138
Validation loss: 1.8642315198016424

Epoch: 5| Step: 2
Training loss: 0.8903297185897827
Validation loss: 1.8311662802132227

Epoch: 5| Step: 3
Training loss: 1.0070115327835083
Validation loss: 1.8554899307989305

Epoch: 5| Step: 4
Training loss: 0.9318321943283081
Validation loss: 1.8604641896422192

Epoch: 5| Step: 5
Training loss: 1.2193548679351807
Validation loss: 1.8912438243948004

Epoch: 5| Step: 6
Training loss: 0.8336294293403625
Validation loss: 1.901049795971122

Epoch: 5| Step: 7
Training loss: 0.8577259182929993
Validation loss: 1.9630020638947845

Epoch: 5| Step: 8
Training loss: 0.7740039825439453
Validation loss: 1.971955971051288

Epoch: 5| Step: 9
Training loss: 0.8565723299980164
Validation loss: 1.9903767942100443

Epoch: 5| Step: 10
Training loss: 0.7353183031082153
Validation loss: 1.974821690590151

Epoch: 188| Step: 0
Training loss: 0.8065681457519531
Validation loss: 1.93814621433135

Epoch: 5| Step: 1
Training loss: 0.5331003069877625
Validation loss: 1.8921128613974458

Epoch: 5| Step: 2
Training loss: 0.4435657858848572
Validation loss: 1.8622155984242756

Epoch: 5| Step: 3
Training loss: 0.4726443290710449
Validation loss: 1.8228755843254827

Epoch: 5| Step: 4
Training loss: 0.7815898656845093
Validation loss: 1.825392541065011

Epoch: 5| Step: 5
Training loss: 1.23923659324646
Validation loss: 1.8408114243579168

Epoch: 5| Step: 6
Training loss: 1.2098017930984497
Validation loss: 1.8546792973754227

Epoch: 5| Step: 7
Training loss: 0.8813484311103821
Validation loss: 1.845211346944173

Epoch: 5| Step: 8
Training loss: 1.0116780996322632
Validation loss: 1.8631476804774294

Epoch: 5| Step: 9
Training loss: 1.1291545629501343
Validation loss: 1.8888188254448675

Epoch: 5| Step: 10
Training loss: 0.8059702515602112
Validation loss: 1.9013138432656564

Epoch: 189| Step: 0
Training loss: 0.8542613983154297
Validation loss: 1.9355980901307956

Epoch: 5| Step: 1
Training loss: 1.0399094820022583
Validation loss: 1.9471880287252448

Epoch: 5| Step: 2
Training loss: 1.1285158395767212
Validation loss: 1.9397511456602363

Epoch: 5| Step: 3
Training loss: 0.8603864908218384
Validation loss: 1.9211522891957273

Epoch: 5| Step: 4
Training loss: 1.0648576021194458
Validation loss: 1.9407201223475958

Epoch: 5| Step: 5
Training loss: 0.9206012487411499
Validation loss: 1.9272026502957909

Epoch: 5| Step: 6
Training loss: 0.6223088502883911
Validation loss: 1.959432278909991

Epoch: 5| Step: 7
Training loss: 1.087920904159546
Validation loss: 1.9444868333878056

Epoch: 5| Step: 8
Training loss: 0.5161258578300476
Validation loss: 1.9470940315595238

Epoch: 5| Step: 9
Training loss: 0.4415419101715088
Validation loss: 1.934680454192623

Epoch: 5| Step: 10
Training loss: 0.6003496646881104
Validation loss: 1.8866639214177285

Epoch: 190| Step: 0
Training loss: 0.4993000030517578
Validation loss: 1.8944896959489392

Epoch: 5| Step: 1
Training loss: 0.662846565246582
Validation loss: 1.9126805182426208

Epoch: 5| Step: 2
Training loss: 0.7404980659484863
Validation loss: 1.9261620826618646

Epoch: 5| Step: 3
Training loss: 0.47507244348526
Validation loss: 1.9255751781566168

Epoch: 5| Step: 4
Training loss: 0.9454904794692993
Validation loss: 1.9421924160372825

Epoch: 5| Step: 5
Training loss: 1.0168739557266235
Validation loss: 1.9262409915206253

Epoch: 5| Step: 6
Training loss: 1.3061416149139404
Validation loss: 1.8958905935287476

Epoch: 5| Step: 7
Training loss: 0.990555465221405
Validation loss: 1.8860376804105696

Epoch: 5| Step: 8
Training loss: 0.8606762886047363
Validation loss: 1.8704455116743683

Epoch: 5| Step: 9
Training loss: 0.9935495257377625
Validation loss: 1.8860167021392493

Epoch: 5| Step: 10
Training loss: 0.5482584834098816
Validation loss: 1.9010293663188975

Epoch: 191| Step: 0
Training loss: 0.5394978523254395
Validation loss: 1.9002077246225009

Epoch: 5| Step: 1
Training loss: 0.48015087842941284
Validation loss: 1.9242191160878828

Epoch: 5| Step: 2
Training loss: 1.2858864068984985
Validation loss: 1.9527543103823097

Epoch: 5| Step: 3
Training loss: 1.1947609186172485
Validation loss: 1.9631434076575822

Epoch: 5| Step: 4
Training loss: 0.7312496304512024
Validation loss: 1.9866554608909033

Epoch: 5| Step: 5
Training loss: 0.4541819095611572
Validation loss: 1.975590741762551

Epoch: 5| Step: 6
Training loss: 0.8242791295051575
Validation loss: 1.9704242496080295

Epoch: 5| Step: 7
Training loss: 1.115048885345459
Validation loss: 1.9299210374073317

Epoch: 5| Step: 8
Training loss: 0.5164992809295654
Validation loss: 1.8907256408404278

Epoch: 5| Step: 9
Training loss: 0.7835928201675415
Validation loss: 1.8804288359098538

Epoch: 5| Step: 10
Training loss: 1.1795992851257324
Validation loss: 1.8623365227894118

Epoch: 192| Step: 0
Training loss: 0.755416989326477
Validation loss: 1.8536973153391192

Epoch: 5| Step: 1
Training loss: 0.3599608838558197
Validation loss: 1.8419419129689534

Epoch: 5| Step: 2
Training loss: 0.8503686189651489
Validation loss: 1.8291040338495725

Epoch: 5| Step: 3
Training loss: 1.2177364826202393
Validation loss: 1.8316377388533724

Epoch: 5| Step: 4
Training loss: 0.8188899755477905
Validation loss: 1.843728268018333

Epoch: 5| Step: 5
Training loss: 1.0304752588272095
Validation loss: 1.8355744423404816

Epoch: 5| Step: 6
Training loss: 0.498574823141098
Validation loss: 1.8277053358734294

Epoch: 5| Step: 7
Training loss: 0.6901137232780457
Validation loss: 1.8374235450580556

Epoch: 5| Step: 8
Training loss: 0.5357111692428589
Validation loss: 1.8664440583157282

Epoch: 5| Step: 9
Training loss: 0.9265671968460083
Validation loss: 1.8535660800113474

Epoch: 5| Step: 10
Training loss: 1.0693198442459106
Validation loss: 1.8545500860419324

Epoch: 193| Step: 0
Training loss: 0.8065629005432129
Validation loss: 1.8915994577510382

Epoch: 5| Step: 1
Training loss: 0.4600985646247864
Validation loss: 1.9432187054746894

Epoch: 5| Step: 2
Training loss: 1.1065176725387573
Validation loss: 1.9425466496457335

Epoch: 5| Step: 3
Training loss: 0.6557971239089966
Validation loss: 1.9791480764265983

Epoch: 5| Step: 4
Training loss: 0.8777279853820801
Validation loss: 1.9776440666567894

Epoch: 5| Step: 5
Training loss: 1.0994501113891602
Validation loss: 2.0069146387038694

Epoch: 5| Step: 6
Training loss: 0.6321458220481873
Validation loss: 1.9741702387409825

Epoch: 5| Step: 7
Training loss: 0.8529030680656433
Validation loss: 1.9443546379766157

Epoch: 5| Step: 8
Training loss: 0.6484334468841553
Validation loss: 1.904151278157388

Epoch: 5| Step: 9
Training loss: 0.7723376154899597
Validation loss: 1.8556975497994372

Epoch: 5| Step: 10
Training loss: 0.9148763418197632
Validation loss: 1.8529950136779456

Epoch: 194| Step: 0
Training loss: 0.5866303443908691
Validation loss: 1.8349936559636106

Epoch: 5| Step: 1
Training loss: 0.5390574932098389
Validation loss: 1.8408765498028006

Epoch: 5| Step: 2
Training loss: 0.9646978378295898
Validation loss: 1.8665888078751103

Epoch: 5| Step: 3
Training loss: 0.8375754356384277
Validation loss: 1.8523233347041632

Epoch: 5| Step: 4
Training loss: 0.49419260025024414
Validation loss: 1.893033553195256

Epoch: 5| Step: 5
Training loss: 0.8758076429367065
Validation loss: 1.909102584726067

Epoch: 5| Step: 6
Training loss: 1.0759369134902954
Validation loss: 1.9213902899014053

Epoch: 5| Step: 7
Training loss: 0.8006717562675476
Validation loss: 1.9594085165249404

Epoch: 5| Step: 8
Training loss: 0.8224363327026367
Validation loss: 1.9651520918774348

Epoch: 5| Step: 9
Training loss: 0.8897682428359985
Validation loss: 1.9814895917010564

Epoch: 5| Step: 10
Training loss: 0.7896813750267029
Validation loss: 1.9383349380185526

Epoch: 195| Step: 0
Training loss: 0.8190394639968872
Validation loss: 1.9244825737450713

Epoch: 5| Step: 1
Training loss: 0.7322927713394165
Validation loss: 1.8862866124799174

Epoch: 5| Step: 2
Training loss: 0.7918923497200012
Validation loss: 1.900269103306596

Epoch: 5| Step: 3
Training loss: 0.6917107105255127
Validation loss: 1.879822677181613

Epoch: 5| Step: 4
Training loss: 0.7917695641517639
Validation loss: 1.8851240642609135

Epoch: 5| Step: 5
Training loss: 0.7644767165184021
Validation loss: 1.8930547083577802

Epoch: 5| Step: 6
Training loss: 0.8795240521430969
Validation loss: 1.9007505819361696

Epoch: 5| Step: 7
Training loss: 0.7308804392814636
Validation loss: 1.8959501879189604

Epoch: 5| Step: 8
Training loss: 1.0128095149993896
Validation loss: 1.8635898200414514

Epoch: 5| Step: 9
Training loss: 0.6333199143409729
Validation loss: 1.8565302202778478

Epoch: 5| Step: 10
Training loss: 0.841834545135498
Validation loss: 1.8330000677416403

Epoch: 196| Step: 0
Training loss: 0.3971400558948517
Validation loss: 1.8653213913722704

Epoch: 5| Step: 1
Training loss: 0.9966825246810913
Validation loss: 1.8413664807555497

Epoch: 5| Step: 2
Training loss: 0.8848947286605835
Validation loss: 1.824964008023662

Epoch: 5| Step: 3
Training loss: 1.0604461431503296
Validation loss: 1.8319905932231615

Epoch: 5| Step: 4
Training loss: 0.6573042273521423
Validation loss: 1.8459921216451993

Epoch: 5| Step: 5
Training loss: 0.6431863903999329
Validation loss: 1.8680687642866565

Epoch: 5| Step: 6
Training loss: 0.8820788264274597
Validation loss: 1.895300442172635

Epoch: 5| Step: 7
Training loss: 0.8349488973617554
Validation loss: 1.9345176168667373

Epoch: 5| Step: 8
Training loss: 0.5744784474372864
Validation loss: 1.9793542841429352

Epoch: 5| Step: 9
Training loss: 0.4411153793334961
Validation loss: 2.006866765278642

Epoch: 5| Step: 10
Training loss: 0.9336320757865906
Validation loss: 1.9862554662971086

Epoch: 197| Step: 0
Training loss: 0.8431397676467896
Validation loss: 1.987193679296842

Epoch: 5| Step: 1
Training loss: 0.8261826634407043
Validation loss: 1.9736069299841439

Epoch: 5| Step: 2
Training loss: 0.7657567262649536
Validation loss: 1.926730045708277

Epoch: 5| Step: 3
Training loss: 0.4599936902523041
Validation loss: 1.919799506023366

Epoch: 5| Step: 4
Training loss: 0.6409540176391602
Validation loss: 1.8619171137450843

Epoch: 5| Step: 5
Training loss: 0.5775753259658813
Validation loss: 1.818981724400674

Epoch: 5| Step: 6
Training loss: 0.8713722229003906
Validation loss: 1.7945154379772883

Epoch: 5| Step: 7
Training loss: 0.8648307919502258
Validation loss: 1.7888600287898895

Epoch: 5| Step: 8
Training loss: 0.7438138723373413
Validation loss: 1.7814736853363693

Epoch: 5| Step: 9
Training loss: 0.9163063168525696
Validation loss: 1.8032313905736452

Epoch: 5| Step: 10
Training loss: 0.5969135165214539
Validation loss: 1.7882855887054114

Epoch: 198| Step: 0
Training loss: 0.6313478946685791
Validation loss: 1.8036559345901653

Epoch: 5| Step: 1
Training loss: 0.4301765561103821
Validation loss: 1.850008636392573

Epoch: 5| Step: 2
Training loss: 0.7729783058166504
Validation loss: 1.8831421072765062

Epoch: 5| Step: 3
Training loss: 0.8321449160575867
Validation loss: 1.8965653450258317

Epoch: 5| Step: 4
Training loss: 0.7756181359291077
Validation loss: 1.8685222236059045

Epoch: 5| Step: 5
Training loss: 0.8719347715377808
Validation loss: 1.8543883767179263

Epoch: 5| Step: 6
Training loss: 0.5309725999832153
Validation loss: 1.8496662967948503

Epoch: 5| Step: 7
Training loss: 0.779824435710907
Validation loss: 1.8427531014206588

Epoch: 5| Step: 8
Training loss: 0.9292305707931519
Validation loss: 1.850991500321255

Epoch: 5| Step: 9
Training loss: 0.7552963495254517
Validation loss: 1.8971085574037285

Epoch: 5| Step: 10
Training loss: 0.842589795589447
Validation loss: 1.8858201490935458

Epoch: 199| Step: 0
Training loss: 0.6914753913879395
Validation loss: 1.8999808885717904

Epoch: 5| Step: 1
Training loss: 0.6450426578521729
Validation loss: 1.9067863738665016

Epoch: 5| Step: 2
Training loss: 0.6257627606391907
Validation loss: 1.9446233959608181

Epoch: 5| Step: 3
Training loss: 0.6969238519668579
Validation loss: 1.9299819469451904

Epoch: 5| Step: 4
Training loss: 0.5942564010620117
Validation loss: 1.8767868767502487

Epoch: 5| Step: 5
Training loss: 0.8155696988105774
Validation loss: 1.8672628659074024

Epoch: 5| Step: 6
Training loss: 0.5467523336410522
Validation loss: 1.843077528861261

Epoch: 5| Step: 7
Training loss: 1.0862884521484375
Validation loss: 1.84245724831858

Epoch: 5| Step: 8
Training loss: 0.6850822567939758
Validation loss: 1.811246447665717

Epoch: 5| Step: 9
Training loss: 0.8648072481155396
Validation loss: 1.8474328376913582

Epoch: 5| Step: 10
Training loss: 0.6516262292861938
Validation loss: 1.8333894937269148

Epoch: 200| Step: 0
Training loss: 0.7082901000976562
Validation loss: 1.841293841279963

Epoch: 5| Step: 1
Training loss: 0.8258813619613647
Validation loss: 1.8549976169422109

Epoch: 5| Step: 2
Training loss: 0.6956313848495483
Validation loss: 1.8260724384297606

Epoch: 5| Step: 3
Training loss: 0.7474486827850342
Validation loss: 1.8448474253377607

Epoch: 5| Step: 4
Training loss: 0.6891404986381531
Validation loss: 1.8365335579841369

Epoch: 5| Step: 5
Training loss: 0.7604722380638123
Validation loss: 1.838424615962531

Epoch: 5| Step: 6
Training loss: 0.879925549030304
Validation loss: 1.8572667080868956

Epoch: 5| Step: 7
Training loss: 0.6067479252815247
Validation loss: 1.8576015733903455

Epoch: 5| Step: 8
Training loss: 0.629126787185669
Validation loss: 1.8845976155291322

Epoch: 5| Step: 9
Training loss: 0.5087944865226746
Validation loss: 1.8649694637585712

Epoch: 5| Step: 10
Training loss: 0.6931043267250061
Validation loss: 1.84348326857372

Epoch: 201| Step: 0
Training loss: 0.285883367061615
Validation loss: 1.8600483530311174

Epoch: 5| Step: 1
Training loss: 0.6617403626441956
Validation loss: 1.8441525364434848

Epoch: 5| Step: 2
Training loss: 0.5796735286712646
Validation loss: 1.8413978251077796

Epoch: 5| Step: 3
Training loss: 0.6456695795059204
Validation loss: 1.8317759293381886

Epoch: 5| Step: 4
Training loss: 0.9354124069213867
Validation loss: 1.8555985586617583

Epoch: 5| Step: 5
Training loss: 0.65746009349823
Validation loss: 1.8508886265498337

Epoch: 5| Step: 6
Training loss: 0.9485558271408081
Validation loss: 1.8534468707217966

Epoch: 5| Step: 7
Training loss: 1.034949541091919
Validation loss: 1.8513742275135492

Epoch: 5| Step: 8
Training loss: 0.44746822118759155
Validation loss: 1.8445056920410485

Epoch: 5| Step: 9
Training loss: 0.6587215662002563
Validation loss: 1.832088965241627

Epoch: 5| Step: 10
Training loss: 0.7366375923156738
Validation loss: 1.8559919928991666

Epoch: 202| Step: 0
Training loss: 0.5005723237991333
Validation loss: 1.8661219202062136

Epoch: 5| Step: 1
Training loss: 0.5385754704475403
Validation loss: 1.866828569801905

Epoch: 5| Step: 2
Training loss: 0.5505990982055664
Validation loss: 1.8309524584841985

Epoch: 5| Step: 3
Training loss: 1.1064860820770264
Validation loss: 1.8647720672750985

Epoch: 5| Step: 4
Training loss: 0.610075831413269
Validation loss: 1.847497317098802

Epoch: 5| Step: 5
Training loss: 0.6433978080749512
Validation loss: 1.8779746678567701

Epoch: 5| Step: 6
Training loss: 0.7967890501022339
Validation loss: 1.8321659500880907

Epoch: 5| Step: 7
Training loss: 0.7746893167495728
Validation loss: 1.8012017947371288

Epoch: 5| Step: 8
Training loss: 0.9093309640884399
Validation loss: 1.7853921023748254

Epoch: 5| Step: 9
Training loss: 0.7729056477546692
Validation loss: 1.780647470105079

Epoch: 5| Step: 10
Training loss: 0.42558708786964417
Validation loss: 1.8037127064120384

Epoch: 203| Step: 0
Training loss: 0.6182631254196167
Validation loss: 1.8094025888750631

Epoch: 5| Step: 1
Training loss: 0.5946832895278931
Validation loss: 1.8385837898459485

Epoch: 5| Step: 2
Training loss: 0.9142290353775024
Validation loss: 1.8565907452696113

Epoch: 5| Step: 3
Training loss: 1.0575257539749146
Validation loss: 1.8643755194961384

Epoch: 5| Step: 4
Training loss: 0.6400217413902283
Validation loss: 1.8523737576700026

Epoch: 5| Step: 5
Training loss: 0.6594557166099548
Validation loss: 1.8894851989643549

Epoch: 5| Step: 6
Training loss: 0.4521060883998871
Validation loss: 1.8826437483551681

Epoch: 5| Step: 7
Training loss: 0.719382643699646
Validation loss: 1.8750029507503714

Epoch: 5| Step: 8
Training loss: 0.6260111927986145
Validation loss: 1.8095813502547562

Epoch: 5| Step: 9
Training loss: 0.6101004481315613
Validation loss: 1.7760209139957224

Epoch: 5| Step: 10
Training loss: 0.7590544819831848
Validation loss: 1.788743096013223

Epoch: 204| Step: 0
Training loss: 0.6160950660705566
Validation loss: 1.809856613477071

Epoch: 5| Step: 1
Training loss: 0.9350358843803406
Validation loss: 1.7938469174087688

Epoch: 5| Step: 2
Training loss: 0.699573814868927
Validation loss: 1.8108013201785345

Epoch: 5| Step: 3
Training loss: 0.5458534955978394
Validation loss: 1.8025756343718498

Epoch: 5| Step: 4
Training loss: 0.4177113473415375
Validation loss: 1.8217018329969017

Epoch: 5| Step: 5
Training loss: 0.572109043598175
Validation loss: 1.827833391004993

Epoch: 5| Step: 6
Training loss: 0.7620929479598999
Validation loss: 1.8783416427591795

Epoch: 5| Step: 7
Training loss: 0.8267216682434082
Validation loss: 1.928821885457603

Epoch: 5| Step: 8
Training loss: 0.6523624658584595
Validation loss: 1.9485972530098372

Epoch: 5| Step: 9
Training loss: 1.0466792583465576
Validation loss: 1.942147724090084

Epoch: 5| Step: 10
Training loss: 0.5152033567428589
Validation loss: 1.8873312229751258

Epoch: 205| Step: 0
Training loss: 1.0502727031707764
Validation loss: 1.7865854476087837

Epoch: 5| Step: 1
Training loss: 0.7536706924438477
Validation loss: 1.808405186540337

Epoch: 5| Step: 2
Training loss: 0.8699973821640015
Validation loss: 1.785213666577493

Epoch: 5| Step: 3
Training loss: 0.669600248336792
Validation loss: 1.7769393100533435

Epoch: 5| Step: 4
Training loss: 0.9056552648544312
Validation loss: 1.7679935245103733

Epoch: 5| Step: 5
Training loss: 0.8677284121513367
Validation loss: 1.7513365668635215

Epoch: 5| Step: 6
Training loss: 0.6790310144424438
Validation loss: 1.7470064675936134

Epoch: 5| Step: 7
Training loss: 0.485666424036026
Validation loss: 1.7718732344206942

Epoch: 5| Step: 8
Training loss: 0.4702242314815521
Validation loss: 1.89293150747976

Epoch: 5| Step: 9
Training loss: 0.434486448764801
Validation loss: 1.890050644515663

Epoch: 5| Step: 10
Training loss: 0.5070691704750061
Validation loss: 1.875197566965575

Epoch: 206| Step: 0
Training loss: 0.47719892859458923
Validation loss: 1.8645845331171507

Epoch: 5| Step: 1
Training loss: 0.6801344752311707
Validation loss: 1.8096508261977986

Epoch: 5| Step: 2
Training loss: 0.7940403819084167
Validation loss: 1.7829493399589293

Epoch: 5| Step: 3
Training loss: 1.0326225757598877
Validation loss: 1.7773821277003135

Epoch: 5| Step: 4
Training loss: 0.6064956784248352
Validation loss: 1.7711572493276289

Epoch: 5| Step: 5
Training loss: 0.7268339395523071
Validation loss: 1.7625528548353462

Epoch: 5| Step: 6
Training loss: 0.9054552316665649
Validation loss: 1.769709628115418

Epoch: 5| Step: 7
Training loss: 0.6573424935340881
Validation loss: 1.7683089766451108

Epoch: 5| Step: 8
Training loss: 0.5124449133872986
Validation loss: 1.7894853481682398

Epoch: 5| Step: 9
Training loss: 0.690855860710144
Validation loss: 1.8443174028909335

Epoch: 5| Step: 10
Training loss: 0.24508272111415863
Validation loss: 1.8868840189390286

Epoch: 207| Step: 0
Training loss: 0.7321652770042419
Validation loss: 1.8989898235567155

Epoch: 5| Step: 1
Training loss: 0.6186366677284241
Validation loss: 1.902729711224956

Epoch: 5| Step: 2
Training loss: 0.5876036286354065
Validation loss: 1.8725400099190332

Epoch: 5| Step: 3
Training loss: 0.6517492532730103
Validation loss: 1.8238452198684856

Epoch: 5| Step: 4
Training loss: 0.9265007972717285
Validation loss: 1.8346117657999839

Epoch: 5| Step: 5
Training loss: 0.9566227197647095
Validation loss: 1.843360318932482

Epoch: 5| Step: 6
Training loss: 0.7881631851196289
Validation loss: 1.8454458098257742

Epoch: 5| Step: 7
Training loss: 0.6670050024986267
Validation loss: 1.8524557198247602

Epoch: 5| Step: 8
Training loss: 0.48157596588134766
Validation loss: 1.8052826735281176

Epoch: 5| Step: 9
Training loss: 0.6533302068710327
Validation loss: 1.8173301425031436

Epoch: 5| Step: 10
Training loss: 0.32404667139053345
Validation loss: 1.8163467222644436

Epoch: 208| Step: 0
Training loss: 0.9122648239135742
Validation loss: 1.8097979714793544

Epoch: 5| Step: 1
Training loss: 0.6712702512741089
Validation loss: 1.8474249532145839

Epoch: 5| Step: 2
Training loss: 1.0145632028579712
Validation loss: 1.8210692123700214

Epoch: 5| Step: 3
Training loss: 0.8090750575065613
Validation loss: 1.8267643400417861

Epoch: 5| Step: 4
Training loss: 0.5719804167747498
Validation loss: 1.8328736712855678

Epoch: 5| Step: 5
Training loss: 0.6257458925247192
Validation loss: 1.8396932668583368

Epoch: 5| Step: 6
Training loss: 0.4794919490814209
Validation loss: 1.8295807120620564

Epoch: 5| Step: 7
Training loss: 0.8149770498275757
Validation loss: 1.8546724242548789

Epoch: 5| Step: 8
Training loss: 0.46268796920776367
Validation loss: 1.8135611587955105

Epoch: 5| Step: 9
Training loss: 0.6840757131576538
Validation loss: 1.7853510328518447

Epoch: 5| Step: 10
Training loss: 0.40715521574020386
Validation loss: 1.7562513684713712

Epoch: 209| Step: 0
Training loss: 1.1476151943206787
Validation loss: 1.7554500295269875

Epoch: 5| Step: 1
Training loss: 0.6359878778457642
Validation loss: 1.7672689781394055

Epoch: 5| Step: 2
Training loss: 0.5670710802078247
Validation loss: 1.7738179852885585

Epoch: 5| Step: 3
Training loss: 0.6577059030532837
Validation loss: 1.7852061615195325

Epoch: 5| Step: 4
Training loss: 0.7029275894165039
Validation loss: 1.8371055074917373

Epoch: 5| Step: 5
Training loss: 0.5665979981422424
Validation loss: 1.8494411104468889

Epoch: 5| Step: 6
Training loss: 0.506095290184021
Validation loss: 1.8807917641055198

Epoch: 5| Step: 7
Training loss: 0.586290717124939
Validation loss: 1.9098017023455711

Epoch: 5| Step: 8
Training loss: 0.3013584017753601
Validation loss: 1.9305818157811319

Epoch: 5| Step: 9
Training loss: 0.5428168773651123
Validation loss: 1.9516637812378586

Epoch: 5| Step: 10
Training loss: 0.8790075182914734
Validation loss: 1.941692885532174

Epoch: 210| Step: 0
Training loss: 0.37917381525039673
Validation loss: 1.9231142074831071

Epoch: 5| Step: 1
Training loss: 0.37197136878967285
Validation loss: 1.8975946736592118

Epoch: 5| Step: 2
Training loss: 0.5991927981376648
Validation loss: 1.8438755619910456

Epoch: 5| Step: 3
Training loss: 0.6636569499969482
Validation loss: 1.7724347114562988

Epoch: 5| Step: 4
Training loss: 0.7596226334571838
Validation loss: 1.7515703965258855

Epoch: 5| Step: 5
Training loss: 0.5000747442245483
Validation loss: 1.7524638201600762

Epoch: 5| Step: 6
Training loss: 0.9987403154373169
Validation loss: 1.7388398314035067

Epoch: 5| Step: 7
Training loss: 0.7437254190444946
Validation loss: 1.7416112474215928

Epoch: 5| Step: 8
Training loss: 0.3792743980884552
Validation loss: 1.7457812742520404

Epoch: 5| Step: 9
Training loss: 0.6622509360313416
Validation loss: 1.7776145089057185

Epoch: 5| Step: 10
Training loss: 0.749207079410553
Validation loss: 1.7721947264927689

Epoch: 211| Step: 0
Training loss: 0.5004061460494995
Validation loss: 1.8037340256475634

Epoch: 5| Step: 1
Training loss: 0.6745448112487793
Validation loss: 1.8021869633787422

Epoch: 5| Step: 2
Training loss: 0.7625807523727417
Validation loss: 1.8290190389079433

Epoch: 5| Step: 3
Training loss: 0.6389716863632202
Validation loss: 1.827212179860761

Epoch: 5| Step: 4
Training loss: 0.6240211725234985
Validation loss: 1.8215765107062556

Epoch: 5| Step: 5
Training loss: 0.7122602462768555
Validation loss: 1.8717060281384377

Epoch: 5| Step: 6
Training loss: 0.7065140008926392
Validation loss: 1.8886901665759344

Epoch: 5| Step: 7
Training loss: 0.4386439919471741
Validation loss: 1.93745082552715

Epoch: 5| Step: 8
Training loss: 0.4680684506893158
Validation loss: 1.8728542302244453

Epoch: 5| Step: 9
Training loss: 0.5561994314193726
Validation loss: 1.8717491024283952

Epoch: 5| Step: 10
Training loss: 0.8793025612831116
Validation loss: 1.812659849402725

Epoch: 212| Step: 0
Training loss: 0.4848126471042633
Validation loss: 1.8054768052152408

Epoch: 5| Step: 1
Training loss: 0.4538424611091614
Validation loss: 1.798760034704721

Epoch: 5| Step: 2
Training loss: 0.6352478265762329
Validation loss: 1.7992868192734257

Epoch: 5| Step: 3
Training loss: 0.45959582924842834
Validation loss: 1.8103522011028823

Epoch: 5| Step: 4
Training loss: 0.7216881513595581
Validation loss: 1.8018968528316868

Epoch: 5| Step: 5
Training loss: 0.8929104804992676
Validation loss: 1.8003873722527617

Epoch: 5| Step: 6
Training loss: 0.5297788381576538
Validation loss: 1.793622088688676

Epoch: 5| Step: 7
Training loss: 0.5313428044319153
Validation loss: 1.7817495023050616

Epoch: 5| Step: 8
Training loss: 0.5149351358413696
Validation loss: 1.7665447881144862

Epoch: 5| Step: 9
Training loss: 0.7383367419242859
Validation loss: 1.8046291669209797

Epoch: 5| Step: 10
Training loss: 0.6886807084083557
Validation loss: 1.8045968881217382

Epoch: 213| Step: 0
Training loss: 0.5101218223571777
Validation loss: 1.8405932047033822

Epoch: 5| Step: 1
Training loss: 0.9214358329772949
Validation loss: 1.8275536465388473

Epoch: 5| Step: 2
Training loss: 0.543053150177002
Validation loss: 1.821541783630207

Epoch: 5| Step: 3
Training loss: 0.6342631578445435
Validation loss: 1.8196805369469427

Epoch: 5| Step: 4
Training loss: 0.40987133979797363
Validation loss: 1.8229355786436348

Epoch: 5| Step: 5
Training loss: 0.4933130145072937
Validation loss: 1.8197676699648622

Epoch: 5| Step: 6
Training loss: 0.3617211878299713
Validation loss: 1.8167821527809225

Epoch: 5| Step: 7
Training loss: 0.8057808876037598
Validation loss: 1.8286200351612543

Epoch: 5| Step: 8
Training loss: 0.23475781083106995
Validation loss: 1.8151896487000168

Epoch: 5| Step: 9
Training loss: 1.1662908792495728
Validation loss: 1.7952744781330068

Epoch: 5| Step: 10
Training loss: 0.45718589425086975
Validation loss: 1.8075669644981303

Epoch: 214| Step: 0
Training loss: 0.6040529608726501
Validation loss: 1.8266822625232

Epoch: 5| Step: 1
Training loss: 0.4745699465274811
Validation loss: 1.8248072349896995

Epoch: 5| Step: 2
Training loss: 0.8144413232803345
Validation loss: 1.8262013619945896

Epoch: 5| Step: 3
Training loss: 0.7720544338226318
Validation loss: 1.8238627115885417

Epoch: 5| Step: 4
Training loss: 0.8427923321723938
Validation loss: 1.8115008454168997

Epoch: 5| Step: 5
Training loss: 0.20782439410686493
Validation loss: 1.823508906108077

Epoch: 5| Step: 6
Training loss: 0.734291672706604
Validation loss: 1.824302008075099

Epoch: 5| Step: 7
Training loss: 0.4601006507873535
Validation loss: 1.822969744282384

Epoch: 5| Step: 8
Training loss: 0.5157166123390198
Validation loss: 1.831822677325177

Epoch: 5| Step: 9
Training loss: 0.3956861197948456
Validation loss: 1.839404143312926

Epoch: 5| Step: 10
Training loss: 0.5965331196784973
Validation loss: 1.8305437744304698

Epoch: 215| Step: 0
Training loss: 0.5811372399330139
Validation loss: 1.8130946813091156

Epoch: 5| Step: 1
Training loss: 0.36683955788612366
Validation loss: 1.7870506804476503

Epoch: 5| Step: 2
Training loss: 0.46578583121299744
Validation loss: 1.7670635382334392

Epoch: 5| Step: 3
Training loss: 0.9450525045394897
Validation loss: 1.7543135150786369

Epoch: 5| Step: 4
Training loss: 0.7715591192245483
Validation loss: 1.742745740439302

Epoch: 5| Step: 5
Training loss: 0.46237343549728394
Validation loss: 1.7321175285564956

Epoch: 5| Step: 6
Training loss: 0.5794728398323059
Validation loss: 1.7344857454299927

Epoch: 5| Step: 7
Training loss: 0.549596905708313
Validation loss: 1.7232078083099858

Epoch: 5| Step: 8
Training loss: 0.472984254360199
Validation loss: 1.7381406073929162

Epoch: 5| Step: 9
Training loss: 0.37807497382164
Validation loss: 1.7337306814809

Epoch: 5| Step: 10
Training loss: 0.44130739569664
Validation loss: 1.74673939904859

Epoch: 216| Step: 0
Training loss: 0.505043625831604
Validation loss: 1.7884977966226556

Epoch: 5| Step: 1
Training loss: 0.6632400751113892
Validation loss: 1.8067617493291055

Epoch: 5| Step: 2
Training loss: 0.6044824123382568
Validation loss: 1.806194709193322

Epoch: 5| Step: 3
Training loss: 0.7609584331512451
Validation loss: 1.7967182218387563

Epoch: 5| Step: 4
Training loss: 0.4303768575191498
Validation loss: 1.8019074304129488

Epoch: 5| Step: 5
Training loss: 0.5410922169685364
Validation loss: 1.773406764512421

Epoch: 5| Step: 6
Training loss: 0.5376712083816528
Validation loss: 1.7722585265354445

Epoch: 5| Step: 7
Training loss: 0.6158755421638489
Validation loss: 1.7553788487629225

Epoch: 5| Step: 8
Training loss: 0.5185697674751282
Validation loss: 1.75447714841494

Epoch: 5| Step: 9
Training loss: 0.3580772280693054
Validation loss: 1.7719552478482645

Epoch: 5| Step: 10
Training loss: 0.645352303981781
Validation loss: 1.7608629734285417

Epoch: 217| Step: 0
Training loss: 0.33392924070358276
Validation loss: 1.7674802029004661

Epoch: 5| Step: 1
Training loss: 0.41902321577072144
Validation loss: 1.7700910978419806

Epoch: 5| Step: 2
Training loss: 0.6370006799697876
Validation loss: 1.7459741536007132

Epoch: 5| Step: 3
Training loss: 0.6174662709236145
Validation loss: 1.7947262820377146

Epoch: 5| Step: 4
Training loss: 0.5420072674751282
Validation loss: 1.8041757306744974

Epoch: 5| Step: 5
Training loss: 0.7924359440803528
Validation loss: 1.8062774160856843

Epoch: 5| Step: 6
Training loss: 0.3104398250579834
Validation loss: 1.7830636103947957

Epoch: 5| Step: 7
Training loss: 0.31981977820396423
Validation loss: 1.7815285011004376

Epoch: 5| Step: 8
Training loss: 0.6925017833709717
Validation loss: 1.757501781627696

Epoch: 5| Step: 9
Training loss: 0.8805031776428223
Validation loss: 1.7460240382020191

Epoch: 5| Step: 10
Training loss: 0.6490742564201355
Validation loss: 1.731621511520878

Epoch: 218| Step: 0
Training loss: 0.5683537125587463
Validation loss: 1.7309642466165687

Epoch: 5| Step: 1
Training loss: 0.3618268370628357
Validation loss: 1.747289628110906

Epoch: 5| Step: 2
Training loss: 0.4192715287208557
Validation loss: 1.767476809922085

Epoch: 5| Step: 3
Training loss: 0.5078328847885132
Validation loss: 1.7947870992845105

Epoch: 5| Step: 4
Training loss: 0.42058125138282776
Validation loss: 1.8057738529738558

Epoch: 5| Step: 5
Training loss: 0.6862363815307617
Validation loss: 1.7962531159001012

Epoch: 5| Step: 6
Training loss: 0.7032678723335266
Validation loss: 1.770960747554738

Epoch: 5| Step: 7
Training loss: 0.6096585392951965
Validation loss: 1.7554961865948093

Epoch: 5| Step: 8
Training loss: 0.6731799840927124
Validation loss: 1.7009740593612834

Epoch: 5| Step: 9
Training loss: 0.543246865272522
Validation loss: 1.6792043960222633

Epoch: 5| Step: 10
Training loss: 0.7429702281951904
Validation loss: 1.6777109023063415

Epoch: 219| Step: 0
Training loss: 0.7052817940711975
Validation loss: 1.6941874373343684

Epoch: 5| Step: 1
Training loss: 0.32610082626342773
Validation loss: 1.7055637631365048

Epoch: 5| Step: 2
Training loss: 0.7059125900268555
Validation loss: 1.729369064813019

Epoch: 5| Step: 3
Training loss: 0.4709225296974182
Validation loss: 1.783498606374187

Epoch: 5| Step: 4
Training loss: 0.360112726688385
Validation loss: 1.8202148086281233

Epoch: 5| Step: 5
Training loss: 0.2885214686393738
Validation loss: 1.7983168632753435

Epoch: 5| Step: 6
Training loss: 0.5786030292510986
Validation loss: 1.8160506986802625

Epoch: 5| Step: 7
Training loss: 0.7979841232299805
Validation loss: 1.7975704951952862

Epoch: 5| Step: 8
Training loss: 0.396340936422348
Validation loss: 1.7749627405597317

Epoch: 5| Step: 9
Training loss: 0.8658073544502258
Validation loss: 1.7440964970537411

Epoch: 5| Step: 10
Training loss: 0.5110993981361389
Validation loss: 1.7212849406785862

Epoch: 220| Step: 0
Training loss: 0.414865106344223
Validation loss: 1.7454843380117928

Epoch: 5| Step: 1
Training loss: 0.5266024470329285
Validation loss: 1.741127614052065

Epoch: 5| Step: 2
Training loss: 0.5930107235908508
Validation loss: 1.7485492460189327

Epoch: 5| Step: 3
Training loss: 0.67401123046875
Validation loss: 1.7801489855653496

Epoch: 5| Step: 4
Training loss: 0.5105517506599426
Validation loss: 1.8130448325987785

Epoch: 5| Step: 5
Training loss: 0.7401256561279297
Validation loss: 1.8227339841986214

Epoch: 5| Step: 6
Training loss: 0.5091546773910522
Validation loss: 1.7957443306522984

Epoch: 5| Step: 7
Training loss: 0.3858492076396942
Validation loss: 1.800620468713904

Epoch: 5| Step: 8
Training loss: 0.5069063901901245
Validation loss: 1.7735902878545946

Epoch: 5| Step: 9
Training loss: 0.48610028624534607
Validation loss: 1.7739693862135693

Epoch: 5| Step: 10
Training loss: 0.42193445563316345
Validation loss: 1.8094771613356888

Epoch: 221| Step: 0
Training loss: 0.21440306305885315
Validation loss: 1.7862454716877272

Epoch: 5| Step: 1
Training loss: 0.4976142942905426
Validation loss: 1.7578987101072907

Epoch: 5| Step: 2
Training loss: 0.39516761898994446
Validation loss: 1.7450929995506042

Epoch: 5| Step: 3
Training loss: 0.42686647176742554
Validation loss: 1.7783991752132293

Epoch: 5| Step: 4
Training loss: 0.40231984853744507
Validation loss: 1.7254897471397155

Epoch: 5| Step: 5
Training loss: 0.5186669230461121
Validation loss: 1.712600968217337

Epoch: 5| Step: 6
Training loss: 0.5371726751327515
Validation loss: 1.734709402566315

Epoch: 5| Step: 7
Training loss: 0.4095410406589508
Validation loss: 1.7357741748133013

Epoch: 5| Step: 8
Training loss: 0.8370264768600464
Validation loss: 1.7606325546900432

Epoch: 5| Step: 9
Training loss: 0.2883182168006897
Validation loss: 1.7726911870382165

Epoch: 5| Step: 10
Training loss: 0.9834285974502563
Validation loss: 1.7855368378341838

Epoch: 222| Step: 0
Training loss: 0.4502585828304291
Validation loss: 1.7569440513528802

Epoch: 5| Step: 1
Training loss: 0.7529299855232239
Validation loss: 1.7481132694469985

Epoch: 5| Step: 2
Training loss: 0.2151906043291092
Validation loss: 1.7508792543923983

Epoch: 5| Step: 3
Training loss: 0.513680636882782
Validation loss: 1.7090998759833715

Epoch: 5| Step: 4
Training loss: 0.5467127561569214
Validation loss: 1.6986257914573915

Epoch: 5| Step: 5
Training loss: 0.3756633400917053
Validation loss: 1.6862258834223594

Epoch: 5| Step: 6
Training loss: 0.898060142993927
Validation loss: 1.6903147389811854

Epoch: 5| Step: 7
Training loss: 0.38485169410705566
Validation loss: 1.7194772766482445

Epoch: 5| Step: 8
Training loss: 0.4638753831386566
Validation loss: 1.706714451953929

Epoch: 5| Step: 9
Training loss: 0.2523903250694275
Validation loss: 1.7283627358816003

Epoch: 5| Step: 10
Training loss: 0.6837040185928345
Validation loss: 1.7086116754880516

Epoch: 223| Step: 0
Training loss: 0.5230680704116821
Validation loss: 1.7266595222616707

Epoch: 5| Step: 1
Training loss: 0.5246587991714478
Validation loss: 1.7229331654887046

Epoch: 5| Step: 2
Training loss: 0.671604335308075
Validation loss: 1.730216690289077

Epoch: 5| Step: 3
Training loss: 0.46732109785079956
Validation loss: 1.7096644293877385

Epoch: 5| Step: 4
Training loss: 0.2720748484134674
Validation loss: 1.745626300893804

Epoch: 5| Step: 5
Training loss: 0.4403536915779114
Validation loss: 1.7456602332412556

Epoch: 5| Step: 6
Training loss: 0.43338918685913086
Validation loss: 1.7305895872013544

Epoch: 5| Step: 7
Training loss: 0.49645358324050903
Validation loss: 1.7401677587980866

Epoch: 5| Step: 8
Training loss: 0.6347312331199646
Validation loss: 1.7586981840031122

Epoch: 5| Step: 9
Training loss: 0.550263524055481
Validation loss: 1.755282860930248

Epoch: 5| Step: 10
Training loss: 0.5540757775306702
Validation loss: 1.7342280341732887

Epoch: 224| Step: 0
Training loss: 0.32564717531204224
Validation loss: 1.7179946989141486

Epoch: 5| Step: 1
Training loss: 0.4468308985233307
Validation loss: 1.7059505921538158

Epoch: 5| Step: 2
Training loss: 0.6595422029495239
Validation loss: 1.680535972759288

Epoch: 5| Step: 3
Training loss: 0.4144391119480133
Validation loss: 1.691453896543031

Epoch: 5| Step: 4
Training loss: 0.5536289811134338
Validation loss: 1.6945423336439236

Epoch: 5| Step: 5
Training loss: 0.4814700484275818
Validation loss: 1.7463400210103681

Epoch: 5| Step: 6
Training loss: 0.36291593313217163
Validation loss: 1.7364307090800295

Epoch: 5| Step: 7
Training loss: 0.4225485324859619
Validation loss: 1.7381828036359561

Epoch: 5| Step: 8
Training loss: 0.5803259611129761
Validation loss: 1.7380224120232366

Epoch: 5| Step: 9
Training loss: 0.5240591764450073
Validation loss: 1.6939187024229316

Epoch: 5| Step: 10
Training loss: 0.6199613213539124
Validation loss: 1.6985352013700752

Epoch: 225| Step: 0
Training loss: 0.6118951439857483
Validation loss: 1.6878820644911898

Epoch: 5| Step: 1
Training loss: 0.4103913903236389
Validation loss: 1.6803458557333997

Epoch: 5| Step: 2
Training loss: 0.6173375844955444
Validation loss: 1.7030874721465572

Epoch: 5| Step: 3
Training loss: 0.6765250563621521
Validation loss: 1.6818406825424523

Epoch: 5| Step: 4
Training loss: 0.7126554250717163
Validation loss: 1.6937411164724698

Epoch: 5| Step: 5
Training loss: 0.1914064884185791
Validation loss: 1.6907200813293457

Epoch: 5| Step: 6
Training loss: 0.47444209456443787
Validation loss: 1.707278642603146

Epoch: 5| Step: 7
Training loss: 0.5376217365264893
Validation loss: 1.6939050843638759

Epoch: 5| Step: 8
Training loss: 0.24555277824401855
Validation loss: 1.7143075594338038

Epoch: 5| Step: 9
Training loss: 0.2656015157699585
Validation loss: 1.6890928296632663

Epoch: 5| Step: 10
Training loss: 0.30988967418670654
Validation loss: 1.682407207386468

Epoch: 226| Step: 0
Training loss: 0.31556957960128784
Validation loss: 1.7278089536133634

Epoch: 5| Step: 1
Training loss: 0.3418346047401428
Validation loss: 1.7302800045218518

Epoch: 5| Step: 2
Training loss: 0.5350338816642761
Validation loss: 1.7455619547956733

Epoch: 5| Step: 3
Training loss: 0.5072416067123413
Validation loss: 1.7508887603718748

Epoch: 5| Step: 4
Training loss: 0.9313727617263794
Validation loss: 1.7603609843920636

Epoch: 5| Step: 5
Training loss: 0.22361624240875244
Validation loss: 1.7876233234200427

Epoch: 5| Step: 6
Training loss: 0.4494972825050354
Validation loss: 1.7697700479979157

Epoch: 5| Step: 7
Training loss: 0.4643276333808899
Validation loss: 1.7574586983649962

Epoch: 5| Step: 8
Training loss: 0.6794221997261047
Validation loss: 1.7576983859462123

Epoch: 5| Step: 9
Training loss: 0.34161177277565
Validation loss: 1.739570031883896

Epoch: 5| Step: 10
Training loss: 0.38189446926116943
Validation loss: 1.763100060083533

Epoch: 227| Step: 0
Training loss: 0.433236300945282
Validation loss: 1.7650800546010335

Epoch: 5| Step: 1
Training loss: 0.5549023747444153
Validation loss: 1.742523524069017

Epoch: 5| Step: 2
Training loss: 0.323309063911438
Validation loss: 1.7491026821956839

Epoch: 5| Step: 3
Training loss: 0.34375467896461487
Validation loss: 1.78367571420567

Epoch: 5| Step: 4
Training loss: 0.47479382157325745
Validation loss: 1.744342823182383

Epoch: 5| Step: 5
Training loss: 0.3895430564880371
Validation loss: 1.754800167135013

Epoch: 5| Step: 6
Training loss: 0.9091672897338867
Validation loss: 1.731116553788544

Epoch: 5| Step: 7
Training loss: 0.4408767819404602
Validation loss: 1.7208262329460473

Epoch: 5| Step: 8
Training loss: 0.4200456142425537
Validation loss: 1.7230169721828994

Epoch: 5| Step: 9
Training loss: 0.532750129699707
Validation loss: 1.7103822526111399

Epoch: 5| Step: 10
Training loss: 0.48631730675697327
Validation loss: 1.714608069389097

Epoch: 228| Step: 0
Training loss: 0.43331319093704224
Validation loss: 1.7216168629225863

Epoch: 5| Step: 1
Training loss: 0.3819388151168823
Validation loss: 1.7443740137161747

Epoch: 5| Step: 2
Training loss: 0.6186303496360779
Validation loss: 1.750117104540589

Epoch: 5| Step: 3
Training loss: 0.2640763223171234
Validation loss: 1.7448804724601008

Epoch: 5| Step: 4
Training loss: 0.36379605531692505
Validation loss: 1.7695475585999028

Epoch: 5| Step: 5
Training loss: 0.6033747792243958
Validation loss: 1.772573403132859

Epoch: 5| Step: 6
Training loss: 0.47685784101486206
Validation loss: 1.8256445341212775

Epoch: 5| Step: 7
Training loss: 0.7143744230270386
Validation loss: 1.8252398788288076

Epoch: 5| Step: 8
Training loss: 0.5015861988067627
Validation loss: 1.895971336672383

Epoch: 5| Step: 9
Training loss: 0.7840587496757507
Validation loss: 1.8686918148430445

Epoch: 5| Step: 10
Training loss: 0.5600647926330566
Validation loss: 1.8106002999890236

Epoch: 229| Step: 0
Training loss: 0.6139714121818542
Validation loss: 1.7385605983836676

Epoch: 5| Step: 1
Training loss: 0.6749756336212158
Validation loss: 1.716105664930036

Epoch: 5| Step: 2
Training loss: 0.4772811532020569
Validation loss: 1.704703164357011

Epoch: 5| Step: 3
Training loss: 0.4050082266330719
Validation loss: 1.6405543781095935

Epoch: 5| Step: 4
Training loss: 0.2980192303657532
Validation loss: 1.6638801354233936

Epoch: 5| Step: 5
Training loss: 0.3967103362083435
Validation loss: 1.6559347478292321

Epoch: 5| Step: 6
Training loss: 0.3723897933959961
Validation loss: 1.6577012333818661

Epoch: 5| Step: 7
Training loss: 0.2222977578639984
Validation loss: 1.695865620848953

Epoch: 5| Step: 8
Training loss: 0.7119554281234741
Validation loss: 1.7010019351077337

Epoch: 5| Step: 9
Training loss: 0.4337828755378723
Validation loss: 1.7297132015228271

Epoch: 5| Step: 10
Training loss: 0.6971035003662109
Validation loss: 1.7517518689555507

Epoch: 230| Step: 0
Training loss: 0.3911963105201721
Validation loss: 1.75513844977143

Epoch: 5| Step: 1
Training loss: 0.29136425256729126
Validation loss: 1.7670724597028507

Epoch: 5| Step: 2
Training loss: 0.5068627595901489
Validation loss: 1.8187540692667807

Epoch: 5| Step: 3
Training loss: 0.49237021803855896
Validation loss: 1.8160879124877274

Epoch: 5| Step: 4
Training loss: 0.5407518744468689
Validation loss: 1.779294934324039

Epoch: 5| Step: 5
Training loss: 0.543958842754364
Validation loss: 1.7592055925758936

Epoch: 5| Step: 6
Training loss: 0.4078572690486908
Validation loss: 1.7371602609593382

Epoch: 5| Step: 7
Training loss: 0.43860799074172974
Validation loss: 1.7297219486646755

Epoch: 5| Step: 8
Training loss: 0.7876394987106323
Validation loss: 1.718526751764359

Epoch: 5| Step: 9
Training loss: 0.729476273059845
Validation loss: 1.715320074430076

Epoch: 5| Step: 10
Training loss: 0.33134809136390686
Validation loss: 1.705653496967849

Epoch: 231| Step: 0
Training loss: 0.3653232455253601
Validation loss: 1.6611103191170642

Epoch: 5| Step: 1
Training loss: 0.8501766324043274
Validation loss: 1.6598853885486562

Epoch: 5| Step: 2
Training loss: 0.5713090896606445
Validation loss: 1.6423322084129497

Epoch: 5| Step: 3
Training loss: 0.49575042724609375
Validation loss: 1.6421604002675703

Epoch: 5| Step: 4
Training loss: 0.4085308611392975
Validation loss: 1.7013206353751562

Epoch: 5| Step: 5
Training loss: 0.46661368012428284
Validation loss: 1.722099495190446

Epoch: 5| Step: 6
Training loss: 0.30246108770370483
Validation loss: 1.7289223876050723

Epoch: 5| Step: 7
Training loss: 0.4384976327419281
Validation loss: 1.7686542695568455

Epoch: 5| Step: 8
Training loss: 0.6324173212051392
Validation loss: 1.7647788114445184

Epoch: 5| Step: 9
Training loss: 0.5398706197738647
Validation loss: 1.775364480992799

Epoch: 5| Step: 10
Training loss: 0.4005875885486603
Validation loss: 1.785708664565958

Epoch: 232| Step: 0
Training loss: 0.3480212688446045
Validation loss: 1.7588576386051793

Epoch: 5| Step: 1
Training loss: 0.3505364656448364
Validation loss: 1.7154054923724102

Epoch: 5| Step: 2
Training loss: 0.4038223326206207
Validation loss: 1.712830110262799

Epoch: 5| Step: 3
Training loss: 0.46682852506637573
Validation loss: 1.6970958004715622

Epoch: 5| Step: 4
Training loss: 0.5027731657028198
Validation loss: 1.711544443202275

Epoch: 5| Step: 5
Training loss: 0.5202853679656982
Validation loss: 1.713941768933368

Epoch: 5| Step: 6
Training loss: 0.6701210141181946
Validation loss: 1.68544985658379

Epoch: 5| Step: 7
Training loss: 0.24885742366313934
Validation loss: 1.7111068028275684

Epoch: 5| Step: 8
Training loss: 0.5655040740966797
Validation loss: 1.730605762491944

Epoch: 5| Step: 9
Training loss: 0.5102242827415466
Validation loss: 1.7407116466952908

Epoch: 5| Step: 10
Training loss: 0.29727426171302795
Validation loss: 1.7617588197031329

Epoch: 233| Step: 0
Training loss: 0.40031901001930237
Validation loss: 1.749155379110767

Epoch: 5| Step: 1
Training loss: 0.17894059419631958
Validation loss: 1.7272627648486887

Epoch: 5| Step: 2
Training loss: 0.6752991080284119
Validation loss: 1.7373941598399993

Epoch: 5| Step: 3
Training loss: 0.3601909279823303
Validation loss: 1.693872877346572

Epoch: 5| Step: 4
Training loss: 0.421531617641449
Validation loss: 1.704710606605776

Epoch: 5| Step: 5
Training loss: 0.47212880849838257
Validation loss: 1.6844744964312481

Epoch: 5| Step: 6
Training loss: 0.5458745956420898
Validation loss: 1.6857440984377297

Epoch: 5| Step: 7
Training loss: 0.6082451343536377
Validation loss: 1.7177719198247439

Epoch: 5| Step: 8
Training loss: 0.4290284216403961
Validation loss: 1.7433003276906989

Epoch: 5| Step: 9
Training loss: 0.43255653977394104
Validation loss: 1.7605504951169413

Epoch: 5| Step: 10
Training loss: 0.31944897770881653
Validation loss: 1.8139943550991755

Epoch: 234| Step: 0
Training loss: 0.5800555348396301
Validation loss: 1.850156093156466

Epoch: 5| Step: 1
Training loss: 0.29876989126205444
Validation loss: 1.8042594040593793

Epoch: 5| Step: 2
Training loss: 0.4892560839653015
Validation loss: 1.7214977023422078

Epoch: 5| Step: 3
Training loss: 0.40941280126571655
Validation loss: 1.6953113130343858

Epoch: 5| Step: 4
Training loss: 0.31827667355537415
Validation loss: 1.6913879366331204

Epoch: 5| Step: 5
Training loss: 0.8404108285903931
Validation loss: 1.6701016746541506

Epoch: 5| Step: 6
Training loss: 0.9763107299804688
Validation loss: 1.656599155036352

Epoch: 5| Step: 7
Training loss: 0.43261051177978516
Validation loss: 1.6246345530274093

Epoch: 5| Step: 8
Training loss: 0.5115970969200134
Validation loss: 1.6513524606663694

Epoch: 5| Step: 9
Training loss: 0.362920343875885
Validation loss: 1.6215064615331671

Epoch: 5| Step: 10
Training loss: 0.2238224595785141
Validation loss: 1.6686056326794367

Epoch: 235| Step: 0
Training loss: 0.5925623178482056
Validation loss: 1.722522594595468

Epoch: 5| Step: 1
Training loss: 0.6317570805549622
Validation loss: 1.766267721370984

Epoch: 5| Step: 2
Training loss: 0.4114467203617096
Validation loss: 1.7882218988992835

Epoch: 5| Step: 3
Training loss: 0.5105639696121216
Validation loss: 1.7924885390907206

Epoch: 5| Step: 4
Training loss: 0.4403914511203766
Validation loss: 1.8198236855127479

Epoch: 5| Step: 5
Training loss: 0.4684767723083496
Validation loss: 1.8152645762248705

Epoch: 5| Step: 6
Training loss: 0.3973286747932434
Validation loss: 1.7994149897688179

Epoch: 5| Step: 7
Training loss: 0.3008498251438141
Validation loss: 1.7611709948508971

Epoch: 5| Step: 8
Training loss: 0.4994579255580902
Validation loss: 1.7444770304105615

Epoch: 5| Step: 9
Training loss: 0.3517187535762787
Validation loss: 1.678832051574543

Epoch: 5| Step: 10
Training loss: 0.47010868787765503
Validation loss: 1.6923307552132556

Epoch: 236| Step: 0
Training loss: 0.26431724429130554
Validation loss: 1.6716103207680486

Epoch: 5| Step: 1
Training loss: 0.4049105644226074
Validation loss: 1.708687001659024

Epoch: 5| Step: 2
Training loss: 0.7033032178878784
Validation loss: 1.7017520563576811

Epoch: 5| Step: 3
Training loss: 0.4639381468296051
Validation loss: 1.7310946269701886

Epoch: 5| Step: 4
Training loss: 0.45774045586586
Validation loss: 1.732047575776295

Epoch: 5| Step: 5
Training loss: 0.36554980278015137
Validation loss: 1.7261265580372145

Epoch: 5| Step: 6
Training loss: 0.3330860137939453
Validation loss: 1.731638975040887

Epoch: 5| Step: 7
Training loss: 0.4712855815887451
Validation loss: 1.679846353428338

Epoch: 5| Step: 8
Training loss: 0.3658646047115326
Validation loss: 1.6644397333104124

Epoch: 5| Step: 9
Training loss: 0.6430511474609375
Validation loss: 1.6458630049100487

Epoch: 5| Step: 10
Training loss: 0.48187243938446045
Validation loss: 1.6588509262249034

Epoch: 237| Step: 0
Training loss: 0.30800095200538635
Validation loss: 1.663572895911432

Epoch: 5| Step: 1
Training loss: 0.7901167273521423
Validation loss: 1.686941287850821

Epoch: 5| Step: 2
Training loss: 0.7097612619400024
Validation loss: 1.6531432213321808

Epoch: 5| Step: 3
Training loss: 0.26198306679725647
Validation loss: 1.7249664465586345

Epoch: 5| Step: 4
Training loss: 0.33972612023353577
Validation loss: 1.732518446060919

Epoch: 5| Step: 5
Training loss: 0.4124564528465271
Validation loss: 1.7390092072948333

Epoch: 5| Step: 6
Training loss: 0.4692811369895935
Validation loss: 1.7411645958500523

Epoch: 5| Step: 7
Training loss: 0.23170360922813416
Validation loss: 1.765324386217261

Epoch: 5| Step: 8
Training loss: 0.40289658308029175
Validation loss: 1.7459737434182117

Epoch: 5| Step: 9
Training loss: 0.4856804311275482
Validation loss: 1.7413181963787283

Epoch: 5| Step: 10
Training loss: 0.44194716215133667
Validation loss: 1.7223243944106563

Epoch: 238| Step: 0
Training loss: 0.37053045630455017
Validation loss: 1.705685100247783

Epoch: 5| Step: 1
Training loss: 0.5798556804656982
Validation loss: 1.6904897023272771

Epoch: 5| Step: 2
Training loss: 0.3036745488643646
Validation loss: 1.666133971624477

Epoch: 5| Step: 3
Training loss: 0.31902822852134705
Validation loss: 1.6433343041327693

Epoch: 5| Step: 4
Training loss: 0.3502695858478546
Validation loss: 1.687167331736575

Epoch: 5| Step: 5
Training loss: 0.3579561114311218
Validation loss: 1.7297062438021424

Epoch: 5| Step: 6
Training loss: 0.37089526653289795
Validation loss: 1.7523553730339132

Epoch: 5| Step: 7
Training loss: 0.4137508273124695
Validation loss: 1.7969951975730158

Epoch: 5| Step: 8
Training loss: 0.6584701538085938
Validation loss: 1.7670357329871065

Epoch: 5| Step: 9
Training loss: 0.47450295090675354
Validation loss: 1.7562485792303597

Epoch: 5| Step: 10
Training loss: 0.5748531818389893
Validation loss: 1.7138938788444764

Epoch: 239| Step: 0
Training loss: 0.3311275839805603
Validation loss: 1.703312607221706

Epoch: 5| Step: 1
Training loss: 0.39379745721817017
Validation loss: 1.721776835380062

Epoch: 5| Step: 2
Training loss: 0.2126428186893463
Validation loss: 1.693953638435692

Epoch: 5| Step: 3
Training loss: 0.40035152435302734
Validation loss: 1.693844315826252

Epoch: 5| Step: 4
Training loss: 0.5772436857223511
Validation loss: 1.6943558467331754

Epoch: 5| Step: 5
Training loss: 0.6232067942619324
Validation loss: 1.7019971814206851

Epoch: 5| Step: 6
Training loss: 0.30009979009628296
Validation loss: 1.7085714596574024

Epoch: 5| Step: 7
Training loss: 0.30207234621047974
Validation loss: 1.678107843604139

Epoch: 5| Step: 8
Training loss: 0.4553988575935364
Validation loss: 1.7065297390825005

Epoch: 5| Step: 9
Training loss: 0.3266332745552063
Validation loss: 1.7037134401259884

Epoch: 5| Step: 10
Training loss: 0.45998677611351013
Validation loss: 1.7215540357815322

Epoch: 240| Step: 0
Training loss: 0.32853689789772034
Validation loss: 1.7234079683980634

Epoch: 5| Step: 1
Training loss: 0.38275155425071716
Validation loss: 1.7264017315321072

Epoch: 5| Step: 2
Training loss: 0.4065735936164856
Validation loss: 1.706681223325832

Epoch: 5| Step: 3
Training loss: 0.3424537777900696
Validation loss: 1.7135445456351004

Epoch: 5| Step: 4
Training loss: 0.24806571006774902
Validation loss: 1.7096828171001968

Epoch: 5| Step: 5
Training loss: 0.3514399230480194
Validation loss: 1.709193327093637

Epoch: 5| Step: 6
Training loss: 0.5153244733810425
Validation loss: 1.7050634135482132

Epoch: 5| Step: 7
Training loss: 0.3812679648399353
Validation loss: 1.7236861516070623

Epoch: 5| Step: 8
Training loss: 0.503682553768158
Validation loss: 1.69432464209936

Epoch: 5| Step: 9
Training loss: 0.6835367679595947
Validation loss: 1.7159336407979329

Epoch: 5| Step: 10
Training loss: 0.2842375338077545
Validation loss: 1.7113119825240104

Epoch: 241| Step: 0
Training loss: 0.24916759133338928
Validation loss: 1.7124759189544185

Epoch: 5| Step: 1
Training loss: 0.5985915064811707
Validation loss: 1.7281267335337978

Epoch: 5| Step: 2
Training loss: 0.5227975249290466
Validation loss: 1.7203739279059953

Epoch: 5| Step: 3
Training loss: 0.33442240953445435
Validation loss: 1.7110957073908981

Epoch: 5| Step: 4
Training loss: 0.5010329484939575
Validation loss: 1.7096977285159531

Epoch: 5| Step: 5
Training loss: 0.2626267075538635
Validation loss: 1.7162100525312527

Epoch: 5| Step: 6
Training loss: 0.24975165724754333
Validation loss: 1.6775282057382728

Epoch: 5| Step: 7
Training loss: 0.34645316004753113
Validation loss: 1.6665017335645613

Epoch: 5| Step: 8
Training loss: 0.40419119596481323
Validation loss: 1.6550131908027075

Epoch: 5| Step: 9
Training loss: 0.38215169310569763
Validation loss: 1.6565415090130222

Epoch: 5| Step: 10
Training loss: 0.41575899720191956
Validation loss: 1.6516115524435555

Epoch: 242| Step: 0
Training loss: 0.5558440685272217
Validation loss: 1.66222333651717

Epoch: 5| Step: 1
Training loss: 0.291020005941391
Validation loss: 1.6812632301802277

Epoch: 5| Step: 2
Training loss: 0.38436800241470337
Validation loss: 1.7018695646716702

Epoch: 5| Step: 3
Training loss: 0.31255903840065
Validation loss: 1.7108088052400978

Epoch: 5| Step: 4
Training loss: 0.6056796908378601
Validation loss: 1.6568537053241525

Epoch: 5| Step: 5
Training loss: 0.3667091429233551
Validation loss: 1.650861224820537

Epoch: 5| Step: 6
Training loss: 0.3105098307132721
Validation loss: 1.6622626871191046

Epoch: 5| Step: 7
Training loss: 0.3393002152442932
Validation loss: 1.6433023124612787

Epoch: 5| Step: 8
Training loss: 0.23279055953025818
Validation loss: 1.668529249006702

Epoch: 5| Step: 9
Training loss: 0.4740641713142395
Validation loss: 1.640010642749007

Epoch: 5| Step: 10
Training loss: 0.5306807160377502
Validation loss: 1.661638459851665

Epoch: 243| Step: 0
Training loss: 0.29094091057777405
Validation loss: 1.648716639446956

Epoch: 5| Step: 1
Training loss: 0.47553616762161255
Validation loss: 1.667650923934034

Epoch: 5| Step: 2
Training loss: 0.4573318362236023
Validation loss: 1.6464678497724636

Epoch: 5| Step: 3
Training loss: 0.20607559382915497
Validation loss: 1.668438660201206

Epoch: 5| Step: 4
Training loss: 0.20631662011146545
Validation loss: 1.6849841276804607

Epoch: 5| Step: 5
Training loss: 0.45351141691207886
Validation loss: 1.6906261315909765

Epoch: 5| Step: 6
Training loss: 0.23995772004127502
Validation loss: 1.6870479442739998

Epoch: 5| Step: 7
Training loss: 0.42262381315231323
Validation loss: 1.719801014469516

Epoch: 5| Step: 8
Training loss: 0.46268177032470703
Validation loss: 1.73850711699455

Epoch: 5| Step: 9
Training loss: 0.44154125452041626
Validation loss: 1.7404364501276324

Epoch: 5| Step: 10
Training loss: 0.40118253231048584
Validation loss: 1.7086826575699674

Epoch: 244| Step: 0
Training loss: 0.31603866815567017
Validation loss: 1.7159663502888014

Epoch: 5| Step: 1
Training loss: 0.6392854452133179
Validation loss: 1.6782601494942941

Epoch: 5| Step: 2
Training loss: 0.4825865626335144
Validation loss: 1.6963931693825671

Epoch: 5| Step: 3
Training loss: 0.3594911992549896
Validation loss: 1.68884959143977

Epoch: 5| Step: 4
Training loss: 0.3220692574977875
Validation loss: 1.6780405480374572

Epoch: 5| Step: 5
Training loss: 0.3527587056159973
Validation loss: 1.6704046790317824

Epoch: 5| Step: 6
Training loss: 0.5002609491348267
Validation loss: 1.6738040883054015

Epoch: 5| Step: 7
Training loss: 0.16693705320358276
Validation loss: 1.6632728217750468

Epoch: 5| Step: 8
Training loss: 0.36862191557884216
Validation loss: 1.644603758089004

Epoch: 5| Step: 9
Training loss: 0.2973582148551941
Validation loss: 1.6621123616413405

Epoch: 5| Step: 10
Training loss: 0.39082878828048706
Validation loss: 1.6564225612148162

Epoch: 245| Step: 0
Training loss: 0.35539108514785767
Validation loss: 1.6834280337056806

Epoch: 5| Step: 1
Training loss: 0.4289744794368744
Validation loss: 1.7064191461891256

Epoch: 5| Step: 2
Training loss: 0.4181882441043854
Validation loss: 1.6733701818732805

Epoch: 5| Step: 3
Training loss: 0.24831633269786835
Validation loss: 1.6889801640664377

Epoch: 5| Step: 4
Training loss: 0.2833681106567383
Validation loss: 1.677246501368861

Epoch: 5| Step: 5
Training loss: 0.4890293478965759
Validation loss: 1.6955379055392357

Epoch: 5| Step: 6
Training loss: 0.31121495366096497
Validation loss: 1.679328372401576

Epoch: 5| Step: 7
Training loss: 0.24131253361701965
Validation loss: 1.6951532543346446

Epoch: 5| Step: 8
Training loss: 0.2790139317512512
Validation loss: 1.6917757449611541

Epoch: 5| Step: 9
Training loss: 0.30271950364112854
Validation loss: 1.7063644727071126

Epoch: 5| Step: 10
Training loss: 0.7921168804168701
Validation loss: 1.6899516300488544

Epoch: 246| Step: 0
Training loss: 0.34146761894226074
Validation loss: 1.702734963868254

Epoch: 5| Step: 1
Training loss: 0.5307759046554565
Validation loss: 1.7288662631024596

Epoch: 5| Step: 2
Training loss: 0.3824743628501892
Validation loss: 1.7118875980377197

Epoch: 5| Step: 3
Training loss: 0.6184210777282715
Validation loss: 1.7003679993332073

Epoch: 5| Step: 4
Training loss: 0.2716034948825836
Validation loss: 1.6714375083164503

Epoch: 5| Step: 5
Training loss: 0.3039393424987793
Validation loss: 1.6798280362159974

Epoch: 5| Step: 6
Training loss: 0.3869531750679016
Validation loss: 1.6747188491206015

Epoch: 5| Step: 7
Training loss: 0.36994871497154236
Validation loss: 1.6803909834995066

Epoch: 5| Step: 8
Training loss: 0.2954845130443573
Validation loss: 1.660825393533194

Epoch: 5| Step: 9
Training loss: 0.26894572377204895
Validation loss: 1.6692924435420702

Epoch: 5| Step: 10
Training loss: 0.2271081656217575
Validation loss: 1.6591640723648893

Epoch: 247| Step: 0
Training loss: 0.5350806713104248
Validation loss: 1.6596791462231708

Epoch: 5| Step: 1
Training loss: 0.5004732012748718
Validation loss: 1.6408398305216143

Epoch: 5| Step: 2
Training loss: 0.35125744342803955
Validation loss: 1.639851334274456

Epoch: 5| Step: 3
Training loss: 0.4164430499076843
Validation loss: 1.6260487982021865

Epoch: 5| Step: 4
Training loss: 0.2920796275138855
Validation loss: 1.6521732396976923

Epoch: 5| Step: 5
Training loss: 0.3232617676258087
Validation loss: 1.676135495785744

Epoch: 5| Step: 6
Training loss: 0.27802351117134094
Validation loss: 1.6793104525535338

Epoch: 5| Step: 7
Training loss: 0.43554505705833435
Validation loss: 1.7151017778663225

Epoch: 5| Step: 8
Training loss: 0.21038511395454407
Validation loss: 1.7289310040012482

Epoch: 5| Step: 9
Training loss: 0.45188063383102417
Validation loss: 1.7295018998525475

Epoch: 5| Step: 10
Training loss: 0.29118263721466064
Validation loss: 1.7030993430845198

Epoch: 248| Step: 0
Training loss: 0.42078715562820435
Validation loss: 1.692855570905952

Epoch: 5| Step: 1
Training loss: 0.3327222466468811
Validation loss: 1.6678541962818434

Epoch: 5| Step: 2
Training loss: 0.1629965603351593
Validation loss: 1.691914508419652

Epoch: 5| Step: 3
Training loss: 0.2905826270580292
Validation loss: 1.7129467738571988

Epoch: 5| Step: 4
Training loss: 0.265665203332901
Validation loss: 1.7027610296844153

Epoch: 5| Step: 5
Training loss: 0.6569854617118835
Validation loss: 1.7115989449203655

Epoch: 5| Step: 6
Training loss: 0.4243435263633728
Validation loss: 1.6917998854831984

Epoch: 5| Step: 7
Training loss: 0.4779540002346039
Validation loss: 1.6804167045060026

Epoch: 5| Step: 8
Training loss: 0.2973521649837494
Validation loss: 1.6928759005761915

Epoch: 5| Step: 9
Training loss: 0.2025819718837738
Validation loss: 1.687098959440826

Epoch: 5| Step: 10
Training loss: 0.29295825958251953
Validation loss: 1.6621823733852756

Epoch: 249| Step: 0
Training loss: 0.3901748061180115
Validation loss: 1.6834736998363207

Epoch: 5| Step: 1
Training loss: 0.31770315766334534
Validation loss: 1.6881797800781906

Epoch: 5| Step: 2
Training loss: 0.15858575701713562
Validation loss: 1.6787218483545447

Epoch: 5| Step: 3
Training loss: 0.4636979103088379
Validation loss: 1.6654691632075975

Epoch: 5| Step: 4
Training loss: 0.4373929500579834
Validation loss: 1.6150617791760353

Epoch: 5| Step: 5
Training loss: 0.32446372509002686
Validation loss: 1.648162398287045

Epoch: 5| Step: 6
Training loss: 0.4241050183773041
Validation loss: 1.6542316547004126

Epoch: 5| Step: 7
Training loss: 0.41288504004478455
Validation loss: 1.6418827861867926

Epoch: 5| Step: 8
Training loss: 0.38992416858673096
Validation loss: 1.6750466644123037

Epoch: 5| Step: 9
Training loss: 0.30263814330101013
Validation loss: 1.6903949322239045

Epoch: 5| Step: 10
Training loss: 0.2965797483921051
Validation loss: 1.6848119215298725

Epoch: 250| Step: 0
Training loss: 0.4604113698005676
Validation loss: 1.7103053959467078

Epoch: 5| Step: 1
Training loss: 0.41017213463783264
Validation loss: 1.705977060461557

Epoch: 5| Step: 2
Training loss: 0.3195105195045471
Validation loss: 1.7010945030438003

Epoch: 5| Step: 3
Training loss: 0.5468891859054565
Validation loss: 1.7069543843628259

Epoch: 5| Step: 4
Training loss: 0.36953267455101013
Validation loss: 1.7157252680870794

Epoch: 5| Step: 5
Training loss: 0.25539928674697876
Validation loss: 1.6947629797843196

Epoch: 5| Step: 6
Training loss: 0.27662739157676697
Validation loss: 1.6626992507647442

Epoch: 5| Step: 7
Training loss: 0.4839286804199219
Validation loss: 1.6375672483956942

Epoch: 5| Step: 8
Training loss: 0.2517712712287903
Validation loss: 1.6178777064046552

Epoch: 5| Step: 9
Training loss: 0.2433721274137497
Validation loss: 1.6366683257523404

Epoch: 5| Step: 10
Training loss: 0.23117274045944214
Validation loss: 1.648217704347385

Epoch: 251| Step: 0
Training loss: 0.3358483910560608
Validation loss: 1.6766329093645977

Epoch: 5| Step: 1
Training loss: 0.38593873381614685
Validation loss: 1.683972160021464

Epoch: 5| Step: 2
Training loss: 0.3803578317165375
Validation loss: 1.682198127110799

Epoch: 5| Step: 3
Training loss: 0.2814302444458008
Validation loss: 1.6612584539639053

Epoch: 5| Step: 4
Training loss: 0.2764918804168701
Validation loss: 1.6523327314725487

Epoch: 5| Step: 5
Training loss: 0.492855966091156
Validation loss: 1.6788260770100418

Epoch: 5| Step: 6
Training loss: 0.2910398542881012
Validation loss: 1.6895201885572044

Epoch: 5| Step: 7
Training loss: 0.7188223600387573
Validation loss: 1.691183437583267

Epoch: 5| Step: 8
Training loss: 0.21532726287841797
Validation loss: 1.6586697242593254

Epoch: 5| Step: 9
Training loss: 0.3602110743522644
Validation loss: 1.6893283577375515

Epoch: 5| Step: 10
Training loss: 0.20807062089443207
Validation loss: 1.700197837686026

Epoch: 252| Step: 0
Training loss: 0.33985474705696106
Validation loss: 1.7121136855053645

Epoch: 5| Step: 1
Training loss: 0.25544247031211853
Validation loss: 1.7291861272627307

Epoch: 5| Step: 2
Training loss: 0.34086886048316956
Validation loss: 1.7064265615196639

Epoch: 5| Step: 3
Training loss: 0.4081447720527649
Validation loss: 1.704212991140222

Epoch: 5| Step: 4
Training loss: 0.19794002175331116
Validation loss: 1.6899871018625074

Epoch: 5| Step: 5
Training loss: 0.5667167901992798
Validation loss: 1.7086825806607482

Epoch: 5| Step: 6
Training loss: 0.3534991145133972
Validation loss: 1.7341832589077693

Epoch: 5| Step: 7
Training loss: 0.18800251185894012
Validation loss: 1.6879296674523303

Epoch: 5| Step: 8
Training loss: 0.5702055096626282
Validation loss: 1.6660982819013699

Epoch: 5| Step: 9
Training loss: 0.35425660014152527
Validation loss: 1.6435073293665403

Epoch: 5| Step: 10
Training loss: 0.23192955553531647
Validation loss: 1.6212919501848118

Epoch: 253| Step: 0
Training loss: 0.4500771462917328
Validation loss: 1.623532554154755

Epoch: 5| Step: 1
Training loss: 0.18480435013771057
Validation loss: 1.605566931027238

Epoch: 5| Step: 2
Training loss: 0.41015785932540894
Validation loss: 1.6233220638767365

Epoch: 5| Step: 3
Training loss: 0.4433228075504303
Validation loss: 1.6277421674420756

Epoch: 5| Step: 4
Training loss: 0.23698942363262177
Validation loss: 1.6249941561811714

Epoch: 5| Step: 5
Training loss: 0.4623285233974457
Validation loss: 1.6307876122895109

Epoch: 5| Step: 6
Training loss: 0.25036078691482544
Validation loss: 1.6744962635860647

Epoch: 5| Step: 7
Training loss: 0.29914456605911255
Validation loss: 1.7147371012677428

Epoch: 5| Step: 8
Training loss: 0.41620030999183655
Validation loss: 1.7040929909675353

Epoch: 5| Step: 9
Training loss: 0.4460674822330475
Validation loss: 1.7186571090452132

Epoch: 5| Step: 10
Training loss: 0.21320022642612457
Validation loss: 1.6630212530013053

Epoch: 254| Step: 0
Training loss: 0.24476106464862823
Validation loss: 1.650931558301372

Epoch: 5| Step: 1
Training loss: 0.39950770139694214
Validation loss: 1.6546535889307659

Epoch: 5| Step: 2
Training loss: 0.2894510328769684
Validation loss: 1.6587737439781107

Epoch: 5| Step: 3
Training loss: 0.5188099145889282
Validation loss: 1.6196184068597772

Epoch: 5| Step: 4
Training loss: 0.2034640610218048
Validation loss: 1.6614999130208006

Epoch: 5| Step: 5
Training loss: 0.35467538237571716
Validation loss: 1.6617689606963948

Epoch: 5| Step: 6
Training loss: 0.34928426146507263
Validation loss: 1.635373806440702

Epoch: 5| Step: 7
Training loss: 0.3187740743160248
Validation loss: 1.6731433189043434

Epoch: 5| Step: 8
Training loss: 0.1708538979291916
Validation loss: 1.680962392078933

Epoch: 5| Step: 9
Training loss: 0.40919724106788635
Validation loss: 1.6871713669069353

Epoch: 5| Step: 10
Training loss: 0.3210596740245819
Validation loss: 1.6948963301156157

Epoch: 255| Step: 0
Training loss: 0.23054997622966766
Validation loss: 1.689224450818954

Epoch: 5| Step: 1
Training loss: 0.41380223631858826
Validation loss: 1.718818244113717

Epoch: 5| Step: 2
Training loss: 0.33680206537246704
Validation loss: 1.7110976301213747

Epoch: 5| Step: 3
Training loss: 0.2483857125043869
Validation loss: 1.6990335167095225

Epoch: 5| Step: 4
Training loss: 0.6301313638687134
Validation loss: 1.6772128843492078

Epoch: 5| Step: 5
Training loss: 0.35268598794937134
Validation loss: 1.6595610726264216

Epoch: 5| Step: 6
Training loss: 0.22756095230579376
Validation loss: 1.666910938037339

Epoch: 5| Step: 7
Training loss: 0.2873896062374115
Validation loss: 1.6450725037564513

Epoch: 5| Step: 8
Training loss: 0.2993069291114807
Validation loss: 1.6259593989259453

Epoch: 5| Step: 9
Training loss: 0.2848767042160034
Validation loss: 1.6220315874263804

Epoch: 5| Step: 10
Training loss: 0.269229531288147
Validation loss: 1.649572451909383

Epoch: 256| Step: 0
Training loss: 0.3407483994960785
Validation loss: 1.6197732238359348

Epoch: 5| Step: 1
Training loss: 0.22919344902038574
Validation loss: 1.6344706012356667

Epoch: 5| Step: 2
Training loss: 0.34654393792152405
Validation loss: 1.6348414831264044

Epoch: 5| Step: 3
Training loss: 0.28993406891822815
Validation loss: 1.6477198318768573

Epoch: 5| Step: 4
Training loss: 0.5636304616928101
Validation loss: 1.6374647360976025

Epoch: 5| Step: 5
Training loss: 0.33754825592041016
Validation loss: 1.6298728937743812

Epoch: 5| Step: 6
Training loss: 0.19921335577964783
Validation loss: 1.6511491819094586

Epoch: 5| Step: 7
Training loss: 0.2322978973388672
Validation loss: 1.6408789260413057

Epoch: 5| Step: 8
Training loss: 0.349330335855484
Validation loss: 1.6122879546175721

Epoch: 5| Step: 9
Training loss: 0.3089035451412201
Validation loss: 1.6212559002701954

Epoch: 5| Step: 10
Training loss: 0.3191949129104614
Validation loss: 1.5908206509005638

Epoch: 257| Step: 0
Training loss: 0.26164448261260986
Validation loss: 1.6208972046452184

Epoch: 5| Step: 1
Training loss: 0.6515036821365356
Validation loss: 1.6069638229185534

Epoch: 5| Step: 2
Training loss: 0.318258136510849
Validation loss: 1.606297690381286

Epoch: 5| Step: 3
Training loss: 0.17610889673233032
Validation loss: 1.6592858042768253

Epoch: 5| Step: 4
Training loss: 0.3447776436805725
Validation loss: 1.702901001899473

Epoch: 5| Step: 5
Training loss: 0.25255095958709717
Validation loss: 1.7192223584780129

Epoch: 5| Step: 6
Training loss: 0.2977748215198517
Validation loss: 1.7006756310821862

Epoch: 5| Step: 7
Training loss: 0.43738359212875366
Validation loss: 1.7047636367941414

Epoch: 5| Step: 8
Training loss: 0.21997232735157013
Validation loss: 1.6753662516993861

Epoch: 5| Step: 9
Training loss: 0.37576887011528015
Validation loss: 1.6492953454294512

Epoch: 5| Step: 10
Training loss: 0.21810398995876312
Validation loss: 1.6310170350536224

Epoch: 258| Step: 0
Training loss: 0.22057366371154785
Validation loss: 1.626690483862354

Epoch: 5| Step: 1
Training loss: 0.28467831015586853
Validation loss: 1.5942416421828731

Epoch: 5| Step: 2
Training loss: 0.39870938658714294
Validation loss: 1.6376193172188216

Epoch: 5| Step: 3
Training loss: 0.254495233297348
Validation loss: 1.621372002427296

Epoch: 5| Step: 4
Training loss: 0.40869516134262085
Validation loss: 1.63727928105221

Epoch: 5| Step: 5
Training loss: 0.17653071880340576
Validation loss: 1.6904301130643455

Epoch: 5| Step: 6
Training loss: 0.5292296409606934
Validation loss: 1.7053112676066737

Epoch: 5| Step: 7
Training loss: 0.3806897699832916
Validation loss: 1.690104607612856

Epoch: 5| Step: 8
Training loss: 0.4083000123500824
Validation loss: 1.7095988873512513

Epoch: 5| Step: 9
Training loss: 0.5019123554229736
Validation loss: 1.7110655243678758

Epoch: 5| Step: 10
Training loss: 0.21445316076278687
Validation loss: 1.6952119360687912

Epoch: 259| Step: 0
Training loss: 0.3959326148033142
Validation loss: 1.679317792256673

Epoch: 5| Step: 1
Training loss: 0.2514563202857971
Validation loss: 1.699295486173322

Epoch: 5| Step: 2
Training loss: 0.5004923939704895
Validation loss: 1.6814246626310452

Epoch: 5| Step: 3
Training loss: 0.2568099796772003
Validation loss: 1.6722774069796327

Epoch: 5| Step: 4
Training loss: 0.2234339416027069
Validation loss: 1.640532778155419

Epoch: 5| Step: 5
Training loss: 0.23643848299980164
Validation loss: 1.6662986445170578

Epoch: 5| Step: 6
Training loss: 0.5369555354118347
Validation loss: 1.6670937922693068

Epoch: 5| Step: 7
Training loss: 0.31793469190597534
Validation loss: 1.6519238025911394

Epoch: 5| Step: 8
Training loss: 0.1571311354637146
Validation loss: 1.6504240882012151

Epoch: 5| Step: 9
Training loss: 0.23592281341552734
Validation loss: 1.6516299427196544

Epoch: 5| Step: 10
Training loss: 0.3056899905204773
Validation loss: 1.6476178681978615

Epoch: 260| Step: 0
Training loss: 0.2371823787689209
Validation loss: 1.6672552016473585

Epoch: 5| Step: 1
Training loss: 0.35123294591903687
Validation loss: 1.6608191831137544

Epoch: 5| Step: 2
Training loss: 0.47068357467651367
Validation loss: 1.6724149719361336

Epoch: 5| Step: 3
Training loss: 0.2060687243938446
Validation loss: 1.6757951064776349

Epoch: 5| Step: 4
Training loss: 0.1666601598262787
Validation loss: 1.6516347956913773

Epoch: 5| Step: 5
Training loss: 0.3682592511177063
Validation loss: 1.6920713865628807

Epoch: 5| Step: 6
Training loss: 0.39251500368118286
Validation loss: 1.6892969210942586

Epoch: 5| Step: 7
Training loss: 0.3746245801448822
Validation loss: 1.6792562815450853

Epoch: 5| Step: 8
Training loss: 0.22515764832496643
Validation loss: 1.666747086791582

Epoch: 5| Step: 9
Training loss: 0.3831369876861572
Validation loss: 1.6659965976592033

Epoch: 5| Step: 10
Training loss: 0.2480488419532776
Validation loss: 1.6858635602458831

Epoch: 261| Step: 0
Training loss: 0.26947394013404846
Validation loss: 1.6809702727102465

Epoch: 5| Step: 1
Training loss: 0.18105144798755646
Validation loss: 1.6514722519023444

Epoch: 5| Step: 2
Training loss: 0.3227007985115051
Validation loss: 1.62511033140203

Epoch: 5| Step: 3
Training loss: 0.5130274295806885
Validation loss: 1.6504185879102318

Epoch: 5| Step: 4
Training loss: 0.20699083805084229
Validation loss: 1.6203824576511179

Epoch: 5| Step: 5
Training loss: 0.1636490523815155
Validation loss: 1.594577993116071

Epoch: 5| Step: 6
Training loss: 0.2853569984436035
Validation loss: 1.604391759441745

Epoch: 5| Step: 7
Training loss: 0.43091168999671936
Validation loss: 1.6172615212778891

Epoch: 5| Step: 8
Training loss: 0.281928151845932
Validation loss: 1.6469568770418885

Epoch: 5| Step: 9
Training loss: 0.34410160779953003
Validation loss: 1.6121381431497552

Epoch: 5| Step: 10
Training loss: 0.3284676671028137
Validation loss: 1.6483358311396774

Epoch: 262| Step: 0
Training loss: 0.18791839480400085
Validation loss: 1.6471369407510246

Epoch: 5| Step: 1
Training loss: 0.26773613691329956
Validation loss: 1.6826956522080205

Epoch: 5| Step: 2
Training loss: 0.22028811275959015
Validation loss: 1.6950462338744954

Epoch: 5| Step: 3
Training loss: 0.19012144207954407
Validation loss: 1.7194802607259443

Epoch: 5| Step: 4
Training loss: 0.4985273480415344
Validation loss: 1.694326873748533

Epoch: 5| Step: 5
Training loss: 0.3106310963630676
Validation loss: 1.7000912415084017

Epoch: 5| Step: 6
Training loss: 0.3480446934700012
Validation loss: 1.6902003544633106

Epoch: 5| Step: 7
Training loss: 0.2493022382259369
Validation loss: 1.6883223466975714

Epoch: 5| Step: 8
Training loss: 0.3398216664791107
Validation loss: 1.655447216444118

Epoch: 5| Step: 9
Training loss: 0.42315778136253357
Validation loss: 1.6571890551556823

Epoch: 5| Step: 10
Training loss: 0.14618903398513794
Validation loss: 1.6128973166147869

Epoch: 263| Step: 0
Training loss: 0.22240230441093445
Validation loss: 1.6013073152111423

Epoch: 5| Step: 1
Training loss: 0.3480595052242279
Validation loss: 1.6010397749562417

Epoch: 5| Step: 2
Training loss: 0.18408818542957306
Validation loss: 1.607687231033079

Epoch: 5| Step: 3
Training loss: 0.37261074781417847
Validation loss: 1.598838593370171

Epoch: 5| Step: 4
Training loss: 0.3056394159793854
Validation loss: 1.5807051876539826

Epoch: 5| Step: 5
Training loss: 0.2756796181201935
Validation loss: 1.6027175726429108

Epoch: 5| Step: 6
Training loss: 0.22496004402637482
Validation loss: 1.592270302516158

Epoch: 5| Step: 7
Training loss: 0.13849833607673645
Validation loss: 1.629614407016385

Epoch: 5| Step: 8
Training loss: 0.5498055815696716
Validation loss: 1.6391529857471425

Epoch: 5| Step: 9
Training loss: 0.20036761462688446
Validation loss: 1.6507916219772831

Epoch: 5| Step: 10
Training loss: 0.263383150100708
Validation loss: 1.6431875280154649

Epoch: 264| Step: 0
Training loss: 0.1678839772939682
Validation loss: 1.6383764231076805

Epoch: 5| Step: 1
Training loss: 0.2221398800611496
Validation loss: 1.6260972792102444

Epoch: 5| Step: 2
Training loss: 0.38835781812667847
Validation loss: 1.6470774399336947

Epoch: 5| Step: 3
Training loss: 0.5102683901786804
Validation loss: 1.650491633722859

Epoch: 5| Step: 4
Training loss: 0.30307736992836
Validation loss: 1.650848674517806

Epoch: 5| Step: 5
Training loss: 0.5018025636672974
Validation loss: 1.666858285985967

Epoch: 5| Step: 6
Training loss: 0.35721877217292786
Validation loss: 1.6774636930035007

Epoch: 5| Step: 7
Training loss: 0.24557404220104218
Validation loss: 1.6594660641044698

Epoch: 5| Step: 8
Training loss: 0.16532203555107117
Validation loss: 1.6887668589110016

Epoch: 5| Step: 9
Training loss: 0.37293413281440735
Validation loss: 1.6999323188617665

Epoch: 5| Step: 10
Training loss: 0.28813081979751587
Validation loss: 1.702016681753179

Epoch: 265| Step: 0
Training loss: 0.34741413593292236
Validation loss: 1.6885108024843278

Epoch: 5| Step: 1
Training loss: 0.2244691401720047
Validation loss: 1.635723340895868

Epoch: 5| Step: 2
Training loss: 0.5612301230430603
Validation loss: 1.6424431877751504

Epoch: 5| Step: 3
Training loss: 0.5142189264297485
Validation loss: 1.6460102078735188

Epoch: 5| Step: 4
Training loss: 0.2751099467277527
Validation loss: 1.634851207015335

Epoch: 5| Step: 5
Training loss: 0.4253382086753845
Validation loss: 1.65496459058536

Epoch: 5| Step: 6
Training loss: 0.3109090030193329
Validation loss: 1.6627008812401884

Epoch: 5| Step: 7
Training loss: 0.18803906440734863
Validation loss: 1.6672428525904173

Epoch: 5| Step: 8
Training loss: 0.18816044926643372
Validation loss: 1.6622510353724163

Epoch: 5| Step: 9
Training loss: 0.12697061896324158
Validation loss: 1.6446508425538258

Epoch: 5| Step: 10
Training loss: 0.23452532291412354
Validation loss: 1.6363203320451962

Epoch: 266| Step: 0
Training loss: 0.3165704011917114
Validation loss: 1.6308716958568943

Epoch: 5| Step: 1
Training loss: 0.38813233375549316
Validation loss: 1.6025758481794787

Epoch: 5| Step: 2
Training loss: 0.5413597822189331
Validation loss: 1.5768228192483225

Epoch: 5| Step: 3
Training loss: 0.27127885818481445
Validation loss: 1.5998305261776011

Epoch: 5| Step: 4
Training loss: 0.2396615445613861
Validation loss: 1.5766085758004138

Epoch: 5| Step: 5
Training loss: 0.182292640209198
Validation loss: 1.5770031611124675

Epoch: 5| Step: 6
Training loss: 0.2558542490005493
Validation loss: 1.5965028039870723

Epoch: 5| Step: 7
Training loss: 0.18963180482387543
Validation loss: 1.628302558775871

Epoch: 5| Step: 8
Training loss: 0.38264042139053345
Validation loss: 1.6033034004190916

Epoch: 5| Step: 9
Training loss: 0.2033849060535431
Validation loss: 1.6064529188217656

Epoch: 5| Step: 10
Training loss: 0.3493225574493408
Validation loss: 1.6380189670029508

Epoch: 267| Step: 0
Training loss: 0.3886529803276062
Validation loss: 1.6329980396455335

Epoch: 5| Step: 1
Training loss: 0.20380711555480957
Validation loss: 1.6385343972072806

Epoch: 5| Step: 2
Training loss: 0.4723666310310364
Validation loss: 1.6128779047278947

Epoch: 5| Step: 3
Training loss: 0.23460182547569275
Validation loss: 1.6136245368629374

Epoch: 5| Step: 4
Training loss: 0.15413698554039001
Validation loss: 1.5797948157915505

Epoch: 5| Step: 5
Training loss: 0.2935400605201721
Validation loss: 1.60348516766743

Epoch: 5| Step: 6
Training loss: 0.22582273185253143
Validation loss: 1.6080571310494536

Epoch: 5| Step: 7
Training loss: 0.17453715205192566
Validation loss: 1.6193323648104103

Epoch: 5| Step: 8
Training loss: 0.5654547810554504
Validation loss: 1.6050339591118596

Epoch: 5| Step: 9
Training loss: 0.35319745540618896
Validation loss: 1.6148599886125135

Epoch: 5| Step: 10
Training loss: 0.11478416621685028
Validation loss: 1.6191387586696173

Epoch: 268| Step: 0
Training loss: 0.26364368200302124
Validation loss: 1.5990709515028103

Epoch: 5| Step: 1
Training loss: 0.36139172315597534
Validation loss: 1.620453933233856

Epoch: 5| Step: 2
Training loss: 0.19072729349136353
Validation loss: 1.6413290282731414

Epoch: 5| Step: 3
Training loss: 0.21936047077178955
Validation loss: 1.6236461029257825

Epoch: 5| Step: 4
Training loss: 0.5466791987419128
Validation loss: 1.618293075151341

Epoch: 5| Step: 5
Training loss: 0.28763261437416077
Validation loss: 1.6025923259796635

Epoch: 5| Step: 6
Training loss: 0.35702359676361084
Validation loss: 1.572819991778302

Epoch: 5| Step: 7
Training loss: 0.17156367003917694
Validation loss: 1.5680717742571266

Epoch: 5| Step: 8
Training loss: 0.1653028428554535
Validation loss: 1.5926786866239322

Epoch: 5| Step: 9
Training loss: 0.30134326219558716
Validation loss: 1.5765525012887933

Epoch: 5| Step: 10
Training loss: 0.20625530183315277
Validation loss: 1.5876061095986316

Epoch: 269| Step: 0
Training loss: 0.30112066864967346
Validation loss: 1.6079958344018588

Epoch: 5| Step: 1
Training loss: 0.23986828327178955
Validation loss: 1.592791344529839

Epoch: 5| Step: 2
Training loss: 0.262424111366272
Validation loss: 1.6027986285507039

Epoch: 5| Step: 3
Training loss: 0.2777565121650696
Validation loss: 1.6107058076448337

Epoch: 5| Step: 4
Training loss: 0.21979527175426483
Validation loss: 1.5981655620759534

Epoch: 5| Step: 5
Training loss: 0.29431748390197754
Validation loss: 1.6152842019193916

Epoch: 5| Step: 6
Training loss: 0.18357589840888977
Validation loss: 1.600727553008705

Epoch: 5| Step: 7
Training loss: 0.2637205123901367
Validation loss: 1.584039174100404

Epoch: 5| Step: 8
Training loss: 0.2055848091840744
Validation loss: 1.6274226634733138

Epoch: 5| Step: 9
Training loss: 0.3612167239189148
Validation loss: 1.6125987063172043

Epoch: 5| Step: 10
Training loss: 0.5007964968681335
Validation loss: 1.630216012718857

Epoch: 270| Step: 0
Training loss: 0.16004954278469086
Validation loss: 1.6098090217959495

Epoch: 5| Step: 1
Training loss: 0.26313260197639465
Validation loss: 1.609963918244967

Epoch: 5| Step: 2
Training loss: 0.28783923387527466
Validation loss: 1.6089019044753043

Epoch: 5| Step: 3
Training loss: 0.4076521396636963
Validation loss: 1.6018362596470823

Epoch: 5| Step: 4
Training loss: 0.23855800926685333
Validation loss: 1.637942329529793

Epoch: 5| Step: 5
Training loss: 0.23623695969581604
Validation loss: 1.6657387377113424

Epoch: 5| Step: 6
Training loss: 0.23533956706523895
Validation loss: 1.645768202120258

Epoch: 5| Step: 7
Training loss: 0.23216089606285095
Validation loss: 1.6546746146294378

Epoch: 5| Step: 8
Training loss: 0.6227012872695923
Validation loss: 1.675745835868261

Epoch: 5| Step: 9
Training loss: 0.208572655916214
Validation loss: 1.6607435685332104

Epoch: 5| Step: 10
Training loss: 0.21508169174194336
Validation loss: 1.681256801851334

Epoch: 271| Step: 0
Training loss: 0.22387394309043884
Validation loss: 1.663503658386969

Epoch: 5| Step: 1
Training loss: 0.2919023931026459
Validation loss: 1.7128992798507854

Epoch: 5| Step: 2
Training loss: 0.3131224811077118
Validation loss: 1.658255305341495

Epoch: 5| Step: 3
Training loss: 0.21365880966186523
Validation loss: 1.659485859255637

Epoch: 5| Step: 4
Training loss: 0.32627996802330017
Validation loss: 1.623539158093032

Epoch: 5| Step: 5
Training loss: 0.22380606830120087
Validation loss: 1.6325036582126413

Epoch: 5| Step: 6
Training loss: 0.3880757689476013
Validation loss: 1.637024741018972

Epoch: 5| Step: 7
Training loss: 0.31640762090682983
Validation loss: 1.6369625496607956

Epoch: 5| Step: 8
Training loss: 0.2068287581205368
Validation loss: 1.6290167813659997

Epoch: 5| Step: 9
Training loss: 0.27607226371765137
Validation loss: 1.638078417829288

Epoch: 5| Step: 10
Training loss: 0.5066355466842651
Validation loss: 1.634845632378773

Epoch: 272| Step: 0
Training loss: 0.2582993507385254
Validation loss: 1.636503246522719

Epoch: 5| Step: 1
Training loss: 0.18342316150665283
Validation loss: 1.6760365950163973

Epoch: 5| Step: 2
Training loss: 0.3903282880783081
Validation loss: 1.6817903493040351

Epoch: 5| Step: 3
Training loss: 0.3384193778038025
Validation loss: 1.6873373600744432

Epoch: 5| Step: 4
Training loss: 0.3184863030910492
Validation loss: 1.7336477553972633

Epoch: 5| Step: 5
Training loss: 0.5630475282669067
Validation loss: 1.7161555008221698

Epoch: 5| Step: 6
Training loss: 0.2341848611831665
Validation loss: 1.6943237486705984

Epoch: 5| Step: 7
Training loss: 0.5122355222702026
Validation loss: 1.7231924110843289

Epoch: 5| Step: 8
Training loss: 0.2039830982685089
Validation loss: 1.6506673635975007

Epoch: 5| Step: 9
Training loss: 0.2831409275531769
Validation loss: 1.6341169572645617

Epoch: 5| Step: 10
Training loss: 0.2577381134033203
Validation loss: 1.623621102302305

Epoch: 273| Step: 0
Training loss: 0.22567948698997498
Validation loss: 1.6149795465571906

Epoch: 5| Step: 1
Training loss: 0.27917468547821045
Validation loss: 1.6106706742317445

Epoch: 5| Step: 2
Training loss: 0.3016938269138336
Validation loss: 1.622614041451485

Epoch: 5| Step: 3
Training loss: 0.3360098898410797
Validation loss: 1.6404677360288558

Epoch: 5| Step: 4
Training loss: 0.22538094222545624
Validation loss: 1.6451751596184188

Epoch: 5| Step: 5
Training loss: 0.362224280834198
Validation loss: 1.6854200375977384

Epoch: 5| Step: 6
Training loss: 0.23671546578407288
Validation loss: 1.6653021253565305

Epoch: 5| Step: 7
Training loss: 0.28383681178092957
Validation loss: 1.6708068334928123

Epoch: 5| Step: 8
Training loss: 0.47231850028038025
Validation loss: 1.6591645530475083

Epoch: 5| Step: 9
Training loss: 0.21467456221580505
Validation loss: 1.6531047051952732

Epoch: 5| Step: 10
Training loss: 0.5480334758758545
Validation loss: 1.6917870647163802

Epoch: 274| Step: 0
Training loss: 0.27321484684944153
Validation loss: 1.7196800093497

Epoch: 5| Step: 1
Training loss: 0.26701441407203674
Validation loss: 1.6997729347598167

Epoch: 5| Step: 2
Training loss: 0.43190303444862366
Validation loss: 1.6328086289026404

Epoch: 5| Step: 3
Training loss: 0.22037310898303986
Validation loss: 1.6426982213092107

Epoch: 5| Step: 4
Training loss: 0.28315529227256775
Validation loss: 1.654055687689012

Epoch: 5| Step: 5
Training loss: 0.15706506371498108
Validation loss: 1.6610228925622919

Epoch: 5| Step: 6
Training loss: 0.19986844062805176
Validation loss: 1.6636642615000408

Epoch: 5| Step: 7
Training loss: 0.29284921288490295
Validation loss: 1.6818238099416096

Epoch: 5| Step: 8
Training loss: 0.4594198167324066
Validation loss: 1.6661542461764427

Epoch: 5| Step: 9
Training loss: 0.30288586020469666
Validation loss: 1.6467684776552263

Epoch: 5| Step: 10
Training loss: 0.2551998198032379
Validation loss: 1.6725081090004212

Epoch: 275| Step: 0
Training loss: 0.11878199875354767
Validation loss: 1.6340947715185021

Epoch: 5| Step: 1
Training loss: 0.3899136185646057
Validation loss: 1.6583554334537958

Epoch: 5| Step: 2
Training loss: 0.21603354811668396
Validation loss: 1.708172385410596

Epoch: 5| Step: 3
Training loss: 0.2706209123134613
Validation loss: 1.7122880643413914

Epoch: 5| Step: 4
Training loss: 0.31788522005081177
Validation loss: 1.7417182704453826

Epoch: 5| Step: 5
Training loss: 0.26867371797561646
Validation loss: 1.7137282381775558

Epoch: 5| Step: 6
Training loss: 0.20680618286132812
Validation loss: 1.723422686258952

Epoch: 5| Step: 7
Training loss: 0.22015805542469025
Validation loss: 1.6899185257573281

Epoch: 5| Step: 8
Training loss: 0.29812899231910706
Validation loss: 1.6714620192845662

Epoch: 5| Step: 9
Training loss: 0.24792170524597168
Validation loss: 1.6611323388673926

Epoch: 5| Step: 10
Training loss: 0.38662630319595337
Validation loss: 1.6684731693678005

Epoch: 276| Step: 0
Training loss: 0.13268467783927917
Validation loss: 1.630304512157235

Epoch: 5| Step: 1
Training loss: 0.19348451495170593
Validation loss: 1.6642946850868963

Epoch: 5| Step: 2
Training loss: 0.4458490312099457
Validation loss: 1.6299139786792058

Epoch: 5| Step: 3
Training loss: 0.2581426203250885
Validation loss: 1.6305367664624286

Epoch: 5| Step: 4
Training loss: 0.1980854868888855
Validation loss: 1.6349278688430786

Epoch: 5| Step: 5
Training loss: 0.3416121304035187
Validation loss: 1.6547740018495949

Epoch: 5| Step: 6
Training loss: 0.29862838983535767
Validation loss: 1.6572428698180823

Epoch: 5| Step: 7
Training loss: 0.4733216166496277
Validation loss: 1.665092522098172

Epoch: 5| Step: 8
Training loss: 0.24346080422401428
Validation loss: 1.6669273620010705

Epoch: 5| Step: 9
Training loss: 0.21922831237316132
Validation loss: 1.6657227739211051

Epoch: 5| Step: 10
Training loss: 0.23864538967609406
Validation loss: 1.6880814426688737

Epoch: 277| Step: 0
Training loss: 0.3124673664569855
Validation loss: 1.6458420522751347

Epoch: 5| Step: 1
Training loss: 0.26452550292015076
Validation loss: 1.623757585402458

Epoch: 5| Step: 2
Training loss: 0.15333035588264465
Validation loss: 1.6382465176684882

Epoch: 5| Step: 3
Training loss: 0.30398786067962646
Validation loss: 1.6153787592405915

Epoch: 5| Step: 4
Training loss: 0.3197020888328552
Validation loss: 1.606728511471902

Epoch: 5| Step: 5
Training loss: 0.11592566967010498
Validation loss: 1.6118760403766428

Epoch: 5| Step: 6
Training loss: 0.3196939527988434
Validation loss: 1.6602242569769583

Epoch: 5| Step: 7
Training loss: 0.3790490925312042
Validation loss: 1.6720971689429334

Epoch: 5| Step: 8
Training loss: 0.40555113554000854
Validation loss: 1.697272995466827

Epoch: 5| Step: 9
Training loss: 0.24412254989147186
Validation loss: 1.658787670955863

Epoch: 5| Step: 10
Training loss: 0.23579905927181244
Validation loss: 1.6383708805166266

Epoch: 278| Step: 0
Training loss: 0.2415795773267746
Validation loss: 1.6398688798309655

Epoch: 5| Step: 1
Training loss: 0.2777732014656067
Validation loss: 1.6123583919258528

Epoch: 5| Step: 2
Training loss: 0.41320428252220154
Validation loss: 1.638894078552082

Epoch: 5| Step: 3
Training loss: 0.21254876255989075
Validation loss: 1.6116737473395564

Epoch: 5| Step: 4
Training loss: 0.21095046401023865
Validation loss: 1.630762691138893

Epoch: 5| Step: 5
Training loss: 0.4618881344795227
Validation loss: 1.6069640190370622

Epoch: 5| Step: 6
Training loss: 0.2661512494087219
Validation loss: 1.630867914486957

Epoch: 5| Step: 7
Training loss: 0.25280916690826416
Validation loss: 1.6600341668692968

Epoch: 5| Step: 8
Training loss: 0.21564945578575134
Validation loss: 1.6763828005841983

Epoch: 5| Step: 9
Training loss: 0.4978453516960144
Validation loss: 1.682606359963776

Epoch: 5| Step: 10
Training loss: 0.29736849665641785
Validation loss: 1.6869723040570495

Epoch: 279| Step: 0
Training loss: 0.34888502955436707
Validation loss: 1.6425694060581986

Epoch: 5| Step: 1
Training loss: 0.4167274534702301
Validation loss: 1.5907779867931078

Epoch: 5| Step: 2
Training loss: 0.2716948091983795
Validation loss: 1.5421351322563746

Epoch: 5| Step: 3
Training loss: 0.2189714014530182
Validation loss: 1.5667320054064515

Epoch: 5| Step: 4
Training loss: 0.1736292988061905
Validation loss: 1.5727116343795613

Epoch: 5| Step: 5
Training loss: 0.34266942739486694
Validation loss: 1.5640455022934945

Epoch: 5| Step: 6
Training loss: 0.18580016493797302
Validation loss: 1.5654316345850627

Epoch: 5| Step: 7
Training loss: 0.3429349362850189
Validation loss: 1.6044817060552619

Epoch: 5| Step: 8
Training loss: 0.23387742042541504
Validation loss: 1.589463205747707

Epoch: 5| Step: 9
Training loss: 0.5372362732887268
Validation loss: 1.6558530292203348

Epoch: 5| Step: 10
Training loss: 0.24593913555145264
Validation loss: 1.6521552660131966

Epoch: 280| Step: 0
Training loss: 0.25588855147361755
Validation loss: 1.6569442620841406

Epoch: 5| Step: 1
Training loss: 0.3035063147544861
Validation loss: 1.6588174476418445

Epoch: 5| Step: 2
Training loss: 0.24854150414466858
Validation loss: 1.667689625934888

Epoch: 5| Step: 3
Training loss: 0.2183186560869217
Validation loss: 1.6560307920620005

Epoch: 5| Step: 4
Training loss: 0.2790621221065521
Validation loss: 1.6443401459724671

Epoch: 5| Step: 5
Training loss: 0.4356420934200287
Validation loss: 1.6436849294170257

Epoch: 5| Step: 6
Training loss: 0.24209490418434143
Validation loss: 1.5880707707456363

Epoch: 5| Step: 7
Training loss: 0.29290661215782166
Validation loss: 1.6054649788846251

Epoch: 5| Step: 8
Training loss: 0.3149072527885437
Validation loss: 1.5668458233597458

Epoch: 5| Step: 9
Training loss: 0.2469533383846283
Validation loss: 1.5928158003796813

Epoch: 5| Step: 10
Training loss: 0.434251070022583
Validation loss: 1.5770541878156765

Epoch: 281| Step: 0
Training loss: 0.32112306356430054
Validation loss: 1.581839212807276

Epoch: 5| Step: 1
Training loss: 0.13538852334022522
Validation loss: 1.5920832016134774

Epoch: 5| Step: 2
Training loss: 0.392574280500412
Validation loss: 1.6262407136219803

Epoch: 5| Step: 3
Training loss: 0.20454373955726624
Validation loss: 1.6189036984597482

Epoch: 5| Step: 4
Training loss: 0.20338575541973114
Validation loss: 1.6353843340309717

Epoch: 5| Step: 5
Training loss: 0.2647625207901001
Validation loss: 1.629987144982943

Epoch: 5| Step: 6
Training loss: 0.2092573195695877
Validation loss: 1.6432232267113143

Epoch: 5| Step: 7
Training loss: 0.20953471958637238
Validation loss: 1.6498171103897916

Epoch: 5| Step: 8
Training loss: 0.41082367300987244
Validation loss: 1.6625099207765313

Epoch: 5| Step: 9
Training loss: 0.19784976541996002
Validation loss: 1.645806416388481

Epoch: 5| Step: 10
Training loss: 0.4677392840385437
Validation loss: 1.6549841101451586

Epoch: 282| Step: 0
Training loss: 0.3561500906944275
Validation loss: 1.6672572922962967

Epoch: 5| Step: 1
Training loss: 0.2968045175075531
Validation loss: 1.6423508249303347

Epoch: 5| Step: 2
Training loss: 0.2571684420108795
Validation loss: 1.6334899933107438

Epoch: 5| Step: 3
Training loss: 0.16918544471263885
Validation loss: 1.6105199744624477

Epoch: 5| Step: 4
Training loss: 0.1991104781627655
Validation loss: 1.6184672232597106

Epoch: 5| Step: 5
Training loss: 0.19417111575603485
Validation loss: 1.617102066675822

Epoch: 5| Step: 6
Training loss: 0.21655353903770447
Validation loss: 1.6056433108545118

Epoch: 5| Step: 7
Training loss: 0.2736121118068695
Validation loss: 1.5956995551304152

Epoch: 5| Step: 8
Training loss: 0.286808580160141
Validation loss: 1.611142013662605

Epoch: 5| Step: 9
Training loss: 0.2838868796825409
Validation loss: 1.5930203814660349

Epoch: 5| Step: 10
Training loss: 0.47710728645324707
Validation loss: 1.612969934299428

Epoch: 283| Step: 0
Training loss: 0.24037018418312073
Validation loss: 1.6164138560654016

Epoch: 5| Step: 1
Training loss: 0.375773549079895
Validation loss: 1.6212553324237946

Epoch: 5| Step: 2
Training loss: 0.19205881655216217
Validation loss: 1.632051787068767

Epoch: 5| Step: 3
Training loss: 0.2434263676404953
Validation loss: 1.6512421946371756

Epoch: 5| Step: 4
Training loss: 0.2982872426509857
Validation loss: 1.6656065448637931

Epoch: 5| Step: 5
Training loss: 0.19542932510375977
Validation loss: 1.6961887574964953

Epoch: 5| Step: 6
Training loss: 0.1731332242488861
Validation loss: 1.6681601821735341

Epoch: 5| Step: 7
Training loss: 0.19466905295848846
Validation loss: 1.6542033944078671

Epoch: 5| Step: 8
Training loss: 0.20779767632484436
Validation loss: 1.671208813626279

Epoch: 5| Step: 9
Training loss: 0.21911099553108215
Validation loss: 1.64406753611821

Epoch: 5| Step: 10
Training loss: 0.4231877624988556
Validation loss: 1.6125483333423574

Epoch: 284| Step: 0
Training loss: 0.198414146900177
Validation loss: 1.635747624981788

Epoch: 5| Step: 1
Training loss: 0.2614370286464691
Validation loss: 1.6363489454792393

Epoch: 5| Step: 2
Training loss: 0.12869679927825928
Validation loss: 1.6180667293969022

Epoch: 5| Step: 3
Training loss: 0.15371064841747284
Validation loss: 1.6141333849199357

Epoch: 5| Step: 4
Training loss: 0.1932867020368576
Validation loss: 1.6087570305793517

Epoch: 5| Step: 5
Training loss: 0.5767163038253784
Validation loss: 1.6297713248960433

Epoch: 5| Step: 6
Training loss: 0.19152198731899261
Validation loss: 1.6451494283573602

Epoch: 5| Step: 7
Training loss: 0.1349598467350006
Validation loss: 1.6416461608743156

Epoch: 5| Step: 8
Training loss: 0.21159443259239197
Validation loss: 1.5897139490291636

Epoch: 5| Step: 9
Training loss: 0.27652886509895325
Validation loss: 1.5887746176412028

Epoch: 5| Step: 10
Training loss: 0.2213865965604782
Validation loss: 1.5798781059121574

Epoch: 285| Step: 0
Training loss: 0.1814882606267929
Validation loss: 1.5765800014618905

Epoch: 5| Step: 1
Training loss: 0.26057296991348267
Validation loss: 1.6027064131152244

Epoch: 5| Step: 2
Training loss: 0.4429995119571686
Validation loss: 1.6115193559277443

Epoch: 5| Step: 3
Training loss: 0.23360753059387207
Validation loss: 1.608671316536524

Epoch: 5| Step: 4
Training loss: 0.123294398188591
Validation loss: 1.6260824613673712

Epoch: 5| Step: 5
Training loss: 0.29135459661483765
Validation loss: 1.6284863961640226

Epoch: 5| Step: 6
Training loss: 0.2986931800842285
Validation loss: 1.6401614014820387

Epoch: 5| Step: 7
Training loss: 0.1694108247756958
Validation loss: 1.6249718909622521

Epoch: 5| Step: 8
Training loss: 0.16114133596420288
Validation loss: 1.6343892133364113

Epoch: 5| Step: 9
Training loss: 0.21241918206214905
Validation loss: 1.6430890483240927

Epoch: 5| Step: 10
Training loss: 0.3017807602882385
Validation loss: 1.6322606891714118

Epoch: 286| Step: 0
Training loss: 0.2731539309024811
Validation loss: 1.6402633856701594

Epoch: 5| Step: 1
Training loss: 0.2173967808485031
Validation loss: 1.65513002744285

Epoch: 5| Step: 2
Training loss: 0.27331215143203735
Validation loss: 1.645742142072288

Epoch: 5| Step: 3
Training loss: 0.21267247200012207
Validation loss: 1.625121412738677

Epoch: 5| Step: 4
Training loss: 0.1736740618944168
Validation loss: 1.6049097737958353

Epoch: 5| Step: 5
Training loss: 0.2263309210538864
Validation loss: 1.6108194794706119

Epoch: 5| Step: 6
Training loss: 0.4476109445095062
Validation loss: 1.636686146900218

Epoch: 5| Step: 7
Training loss: 0.2603897452354431
Validation loss: 1.6321583819645706

Epoch: 5| Step: 8
Training loss: 0.17443332076072693
Validation loss: 1.6066288794240644

Epoch: 5| Step: 9
Training loss: 0.42112380266189575
Validation loss: 1.6047481170264624

Epoch: 5| Step: 10
Training loss: 0.1712065041065216
Validation loss: 1.5680356051332207

Epoch: 287| Step: 0
Training loss: 0.16506442427635193
Validation loss: 1.5826931563756799

Epoch: 5| Step: 1
Training loss: 0.18424393236637115
Validation loss: 1.5858897560386247

Epoch: 5| Step: 2
Training loss: 0.46219849586486816
Validation loss: 1.5787967238374936

Epoch: 5| Step: 3
Training loss: 0.2395186871290207
Validation loss: 1.595572288318347

Epoch: 5| Step: 4
Training loss: 0.1741224229335785
Validation loss: 1.6216606401628064

Epoch: 5| Step: 5
Training loss: 0.29131239652633667
Validation loss: 1.6233611376054826

Epoch: 5| Step: 6
Training loss: 0.2716834247112274
Validation loss: 1.6012974580128987

Epoch: 5| Step: 7
Training loss: 0.2848379611968994
Validation loss: 1.6066675083611601

Epoch: 5| Step: 8
Training loss: 0.19608174264431
Validation loss: 1.6157775784051547

Epoch: 5| Step: 9
Training loss: 0.2558732330799103
Validation loss: 1.606571764074346

Epoch: 5| Step: 10
Training loss: 0.3107673227787018
Validation loss: 1.6094035948476484

Epoch: 288| Step: 0
Training loss: 0.26109227538108826
Validation loss: 1.6119487862433157

Epoch: 5| Step: 1
Training loss: 0.23273620009422302
Validation loss: 1.6020499249940277

Epoch: 5| Step: 2
Training loss: 0.3535017669200897
Validation loss: 1.574842360711867

Epoch: 5| Step: 3
Training loss: 0.16020944714546204
Validation loss: 1.5996884761318084

Epoch: 5| Step: 4
Training loss: 0.17431211471557617
Validation loss: 1.5884743775090864

Epoch: 5| Step: 5
Training loss: 0.15943652391433716
Validation loss: 1.6062715245831398

Epoch: 5| Step: 6
Training loss: 0.1970326006412506
Validation loss: 1.5830004727968605

Epoch: 5| Step: 7
Training loss: 0.16191962361335754
Validation loss: 1.5797994598265617

Epoch: 5| Step: 8
Training loss: 0.14449343085289001
Validation loss: 1.5924289534168858

Epoch: 5| Step: 9
Training loss: 0.5754584074020386
Validation loss: 1.603496459222609

Epoch: 5| Step: 10
Training loss: 0.2245856523513794
Validation loss: 1.5986026756225094

Epoch: 289| Step: 0
Training loss: 0.13221508264541626
Validation loss: 1.596278889204866

Epoch: 5| Step: 1
Training loss: 0.22448909282684326
Validation loss: 1.5769089114281438

Epoch: 5| Step: 2
Training loss: 0.1989540457725525
Validation loss: 1.5728231860745339

Epoch: 5| Step: 3
Training loss: 0.292058527469635
Validation loss: 1.577682375907898

Epoch: 5| Step: 4
Training loss: 0.11898203194141388
Validation loss: 1.5886169095193186

Epoch: 5| Step: 5
Training loss: 0.14615149796009064
Validation loss: 1.5938079587874874

Epoch: 5| Step: 6
Training loss: 0.39497822523117065
Validation loss: 1.5925986587360341

Epoch: 5| Step: 7
Training loss: 0.4188934862613678
Validation loss: 1.5813535285252396

Epoch: 5| Step: 8
Training loss: 0.1845512092113495
Validation loss: 1.6088638305664062

Epoch: 5| Step: 9
Training loss: 0.25176090002059937
Validation loss: 1.5947442080384941

Epoch: 5| Step: 10
Training loss: 0.2186800241470337
Validation loss: 1.616170754996679

Epoch: 290| Step: 0
Training loss: 0.14263483881950378
Validation loss: 1.6279261189122354

Epoch: 5| Step: 1
Training loss: 0.2227526605129242
Validation loss: 1.641883022041731

Epoch: 5| Step: 2
Training loss: 0.1695607453584671
Validation loss: 1.6210213040792814

Epoch: 5| Step: 3
Training loss: 0.1372600793838501
Validation loss: 1.607547753600664

Epoch: 5| Step: 4
Training loss: 0.40139394998550415
Validation loss: 1.605678100739756

Epoch: 5| Step: 5
Training loss: 0.24648639559745789
Validation loss: 1.6141237469129666

Epoch: 5| Step: 6
Training loss: 0.19845391809940338
Validation loss: 1.6284004622890103

Epoch: 5| Step: 7
Training loss: 0.19527342915534973
Validation loss: 1.6327493088219756

Epoch: 5| Step: 8
Training loss: 0.20542998611927032
Validation loss: 1.618945784466241

Epoch: 5| Step: 9
Training loss: 0.22568051517009735
Validation loss: 1.627062612964261

Epoch: 5| Step: 10
Training loss: 0.3530608117580414
Validation loss: 1.6089322515713271

Epoch: 291| Step: 0
Training loss: 0.16214381158351898
Validation loss: 1.6247611327837872

Epoch: 5| Step: 1
Training loss: 0.20491310954093933
Validation loss: 1.6169377148792308

Epoch: 5| Step: 2
Training loss: 0.19426237046718597
Validation loss: 1.6061967880495134

Epoch: 5| Step: 3
Training loss: 0.4402349591255188
Validation loss: 1.60930218491503

Epoch: 5| Step: 4
Training loss: 0.16159142553806305
Validation loss: 1.5775974283936203

Epoch: 5| Step: 5
Training loss: 0.12024471908807755
Validation loss: 1.570819704763351

Epoch: 5| Step: 6
Training loss: 0.24755942821502686
Validation loss: 1.5692376334180114

Epoch: 5| Step: 7
Training loss: 0.333252489566803
Validation loss: 1.6003832688895605

Epoch: 5| Step: 8
Training loss: 0.21266277134418488
Validation loss: 1.6172982595300163

Epoch: 5| Step: 9
Training loss: 0.2637391984462738
Validation loss: 1.6316217632703884

Epoch: 5| Step: 10
Training loss: 0.10630057752132416
Validation loss: 1.6556553712455175

Epoch: 292| Step: 0
Training loss: 0.15474554896354675
Validation loss: 1.6579465737906836

Epoch: 5| Step: 1
Training loss: 0.20934069156646729
Validation loss: 1.6229279861655286

Epoch: 5| Step: 2
Training loss: 0.1583530157804489
Validation loss: 1.5849205922054987

Epoch: 5| Step: 3
Training loss: 0.2860952913761139
Validation loss: 1.572411749952583

Epoch: 5| Step: 4
Training loss: 0.25495973229408264
Validation loss: 1.5692156232813352

Epoch: 5| Step: 5
Training loss: 0.25513651967048645
Validation loss: 1.5539193230290567

Epoch: 5| Step: 6
Training loss: 0.6057000160217285
Validation loss: 1.5788471237305672

Epoch: 5| Step: 7
Training loss: 0.24816890060901642
Validation loss: 1.5576409524486912

Epoch: 5| Step: 8
Training loss: 0.18142089247703552
Validation loss: 1.5666489972863147

Epoch: 5| Step: 9
Training loss: 0.2866518497467041
Validation loss: 1.5850939180261345

Epoch: 5| Step: 10
Training loss: 0.07990258932113647
Validation loss: 1.5629658852854083

Epoch: 293| Step: 0
Training loss: 0.23009423911571503
Validation loss: 1.5759094530536282

Epoch: 5| Step: 1
Training loss: 0.12116875499486923
Validation loss: 1.5849799122861636

Epoch: 5| Step: 2
Training loss: 0.28438669443130493
Validation loss: 1.614673896502423

Epoch: 5| Step: 3
Training loss: 0.15134304761886597
Validation loss: 1.6141629488237443

Epoch: 5| Step: 4
Training loss: 0.18051770329475403
Validation loss: 1.5970064549035923

Epoch: 5| Step: 5
Training loss: 0.16240641474723816
Validation loss: 1.6035643822403365

Epoch: 5| Step: 6
Training loss: 0.25143328309059143
Validation loss: 1.560592310402983

Epoch: 5| Step: 7
Training loss: 0.33474478125572205
Validation loss: 1.5698777603846725

Epoch: 5| Step: 8
Training loss: 0.11334886401891708
Validation loss: 1.573782814446316

Epoch: 5| Step: 9
Training loss: 0.32759398221969604
Validation loss: 1.6002467563075404

Epoch: 5| Step: 10
Training loss: 0.24684937298297882
Validation loss: 1.6079808230041175

Epoch: 294| Step: 0
Training loss: 0.20644867420196533
Validation loss: 1.623896914143716

Epoch: 5| Step: 1
Training loss: 0.22119095921516418
Validation loss: 1.6479096925386818

Epoch: 5| Step: 2
Training loss: 0.21003031730651855
Validation loss: 1.6103925897229103

Epoch: 5| Step: 3
Training loss: 0.29902076721191406
Validation loss: 1.611115909391834

Epoch: 5| Step: 4
Training loss: 0.23747587203979492
Validation loss: 1.6039292543165145

Epoch: 5| Step: 5
Training loss: 0.27019989490509033
Validation loss: 1.6190016846502981

Epoch: 5| Step: 6
Training loss: 0.17536744475364685
Validation loss: 1.6282761007226922

Epoch: 5| Step: 7
Training loss: 0.1141531839966774
Validation loss: 1.6491498921507148

Epoch: 5| Step: 8
Training loss: 0.11303486675024033
Validation loss: 1.6142248492087088

Epoch: 5| Step: 9
Training loss: 0.20755544304847717
Validation loss: 1.6403250412274433

Epoch: 5| Step: 10
Training loss: 0.43536579608917236
Validation loss: 1.6515052075027137

Epoch: 295| Step: 0
Training loss: 0.35615473985671997
Validation loss: 1.64640002353217

Epoch: 5| Step: 1
Training loss: 0.31684374809265137
Validation loss: 1.6134174523815032

Epoch: 5| Step: 2
Training loss: 0.13682623207569122
Validation loss: 1.5783399074308333

Epoch: 5| Step: 3
Training loss: 0.2511768639087677
Validation loss: 1.5909594284590853

Epoch: 5| Step: 4
Training loss: 0.2727542519569397
Validation loss: 1.5738850191075315

Epoch: 5| Step: 5
Training loss: 0.12598222494125366
Validation loss: 1.5930336342063

Epoch: 5| Step: 6
Training loss: 0.1343962401151657
Validation loss: 1.5815846702103973

Epoch: 5| Step: 7
Training loss: 0.17628292739391327
Validation loss: 1.607740395812578

Epoch: 5| Step: 8
Training loss: 0.24013538658618927
Validation loss: 1.5795722546115998

Epoch: 5| Step: 9
Training loss: 0.22597400844097137
Validation loss: 1.576579402851802

Epoch: 5| Step: 10
Training loss: 0.1512163132429123
Validation loss: 1.5883556271112094

Epoch: 296| Step: 0
Training loss: 0.15327472984790802
Validation loss: 1.5765534370176253

Epoch: 5| Step: 1
Training loss: 0.4036363959312439
Validation loss: 1.5824782399721042

Epoch: 5| Step: 2
Training loss: 0.16387110948562622
Validation loss: 1.576625608628796

Epoch: 5| Step: 3
Training loss: 0.2856846749782562
Validation loss: 1.5876558672997259

Epoch: 5| Step: 4
Training loss: 0.13080713152885437
Validation loss: 1.6071607541012507

Epoch: 5| Step: 5
Training loss: 0.20702242851257324
Validation loss: 1.6147180270123225

Epoch: 5| Step: 6
Training loss: 0.4416087567806244
Validation loss: 1.6265816662901191

Epoch: 5| Step: 7
Training loss: 0.14379823207855225
Validation loss: 1.6317937592024445

Epoch: 5| Step: 8
Training loss: 0.1736668050289154
Validation loss: 1.6607091708849835

Epoch: 5| Step: 9
Training loss: 0.16528227925300598
Validation loss: 1.6434885519807056

Epoch: 5| Step: 10
Training loss: 0.13831861317157745
Validation loss: 1.6585000894402946

Epoch: 297| Step: 0
Training loss: 0.15431515872478485
Validation loss: 1.6476083263274162

Epoch: 5| Step: 1
Training loss: 0.19154557585716248
Validation loss: 1.640111291921267

Epoch: 5| Step: 2
Training loss: 0.23117069900035858
Validation loss: 1.6207949051292994

Epoch: 5| Step: 3
Training loss: 0.26366710662841797
Validation loss: 1.6410148682132844

Epoch: 5| Step: 4
Training loss: 0.16060605645179749
Validation loss: 1.6039830600061724

Epoch: 5| Step: 5
Training loss: 0.35903894901275635
Validation loss: 1.58441597800101

Epoch: 5| Step: 6
Training loss: 0.1851954162120819
Validation loss: 1.5835268958922355

Epoch: 5| Step: 7
Training loss: 0.2867688536643982
Validation loss: 1.5790687825090142

Epoch: 5| Step: 8
Training loss: 0.21277344226837158
Validation loss: 1.590211441439967

Epoch: 5| Step: 9
Training loss: 0.22510142624378204
Validation loss: 1.5998699690705986

Epoch: 5| Step: 10
Training loss: 0.10862421244382858
Validation loss: 1.6152233385270642

Epoch: 298| Step: 0
Training loss: 0.13307349383831024
Validation loss: 1.6061575489659463

Epoch: 5| Step: 1
Training loss: 0.1493821144104004
Validation loss: 1.592818799839225

Epoch: 5| Step: 2
Training loss: 0.1621181070804596
Validation loss: 1.5977370732574052

Epoch: 5| Step: 3
Training loss: 0.20777645707130432
Validation loss: 1.5681434613402172

Epoch: 5| Step: 4
Training loss: 0.3344401717185974
Validation loss: 1.553296713418858

Epoch: 5| Step: 5
Training loss: 0.21933822333812714
Validation loss: 1.531255191372287

Epoch: 5| Step: 6
Training loss: 0.26702749729156494
Validation loss: 1.529119933805158

Epoch: 5| Step: 7
Training loss: 0.23220834136009216
Validation loss: 1.565098565111878

Epoch: 5| Step: 8
Training loss: 0.3952404856681824
Validation loss: 1.5697135854792852

Epoch: 5| Step: 9
Training loss: 0.1400456428527832
Validation loss: 1.5729253881721086

Epoch: 5| Step: 10
Training loss: 0.17207233607769012
Validation loss: 1.5935859398175312

Epoch: 299| Step: 0
Training loss: 0.28641849756240845
Validation loss: 1.6078655822302705

Epoch: 5| Step: 1
Training loss: 0.2274792641401291
Validation loss: 1.5966198957094582

Epoch: 5| Step: 2
Training loss: 0.18290510773658752
Validation loss: 1.6204029308852328

Epoch: 5| Step: 3
Training loss: 0.21931569278240204
Validation loss: 1.6112265202306932

Epoch: 5| Step: 4
Training loss: 0.15601089596748352
Validation loss: 1.593692776977375

Epoch: 5| Step: 5
Training loss: 0.14354686439037323
Validation loss: 1.5800569134373819

Epoch: 5| Step: 6
Training loss: 0.14941583573818207
Validation loss: 1.5849146214864587

Epoch: 5| Step: 7
Training loss: 0.2074713408946991
Validation loss: 1.5635462768616215

Epoch: 5| Step: 8
Training loss: 0.2834126353263855
Validation loss: 1.5702127025973411

Epoch: 5| Step: 9
Training loss: 0.321445107460022
Validation loss: 1.5518333155621764

Epoch: 5| Step: 10
Training loss: 0.36266031861305237
Validation loss: 1.5897339159442532

Epoch: 300| Step: 0
Training loss: 0.2175643891096115
Validation loss: 1.5915036816750803

Epoch: 5| Step: 1
Training loss: 0.10598678886890411
Validation loss: 1.5816004673639934

Epoch: 5| Step: 2
Training loss: 0.15011361241340637
Validation loss: 1.5644979938384025

Epoch: 5| Step: 3
Training loss: 0.17802993953227997
Validation loss: 1.5766023948628416

Epoch: 5| Step: 4
Training loss: 0.4158076345920563
Validation loss: 1.5433027180292274

Epoch: 5| Step: 5
Training loss: 0.14263349771499634
Validation loss: 1.5634006069552513

Epoch: 5| Step: 6
Training loss: 0.18957814574241638
Validation loss: 1.5681269848218529

Epoch: 5| Step: 7
Training loss: 0.16493351757526398
Validation loss: 1.5555202576421923

Epoch: 5| Step: 8
Training loss: 0.15403242409229279
Validation loss: 1.571946559413787

Epoch: 5| Step: 9
Training loss: 0.3721664249897003
Validation loss: 1.575185989820829

Epoch: 5| Step: 10
Training loss: 0.165183424949646
Validation loss: 1.5799651748390608

Epoch: 301| Step: 0
Training loss: 0.21185298264026642
Validation loss: 1.5935048851915585

Epoch: 5| Step: 1
Training loss: 0.13844674825668335
Validation loss: 1.600496474132743

Epoch: 5| Step: 2
Training loss: 0.20135410130023956
Validation loss: 1.606329192397415

Epoch: 5| Step: 3
Training loss: 0.32189488410949707
Validation loss: 1.5962093991618003

Epoch: 5| Step: 4
Training loss: 0.35146814584732056
Validation loss: 1.5909647813407324

Epoch: 5| Step: 5
Training loss: 0.10032930225133896
Validation loss: 1.6152647868279488

Epoch: 5| Step: 6
Training loss: 0.2084992378950119
Validation loss: 1.6181475616270495

Epoch: 5| Step: 7
Training loss: 0.3387632966041565
Validation loss: 1.6109027208820466

Epoch: 5| Step: 8
Training loss: 0.26211634278297424
Validation loss: 1.5855702738608084

Epoch: 5| Step: 9
Training loss: 0.14630268514156342
Validation loss: 1.597009184539959

Epoch: 5| Step: 10
Training loss: 0.18202164769172668
Validation loss: 1.5839577926102506

Epoch: 302| Step: 0
Training loss: 0.24128714203834534
Validation loss: 1.5919497961639075

Epoch: 5| Step: 1
Training loss: 0.4227631092071533
Validation loss: 1.5928062944002048

Epoch: 5| Step: 2
Training loss: 0.21756954491138458
Validation loss: 1.5462280614401704

Epoch: 5| Step: 3
Training loss: 0.26067429780960083
Validation loss: 1.5653413534164429

Epoch: 5| Step: 4
Training loss: 0.1492851972579956
Validation loss: 1.562471987098776

Epoch: 5| Step: 5
Training loss: 0.17800332605838776
Validation loss: 1.5837770790182135

Epoch: 5| Step: 6
Training loss: 0.2154419720172882
Validation loss: 1.5914319843374274

Epoch: 5| Step: 7
Training loss: 0.30656909942626953
Validation loss: 1.6069690469772584

Epoch: 5| Step: 8
Training loss: 0.16657300293445587
Validation loss: 1.5726082222436064

Epoch: 5| Step: 9
Training loss: 0.14959873259067535
Validation loss: 1.5382472866324968

Epoch: 5| Step: 10
Training loss: 0.10895209014415741
Validation loss: 1.5420670291428924

Epoch: 303| Step: 0
Training loss: 0.10482168197631836
Validation loss: 1.5319330448745399

Epoch: 5| Step: 1
Training loss: 0.13723240792751312
Validation loss: 1.5410787187596804

Epoch: 5| Step: 2
Training loss: 0.13315463066101074
Validation loss: 1.538736803557283

Epoch: 5| Step: 3
Training loss: 0.18709108233451843
Validation loss: 1.5483105631284817

Epoch: 5| Step: 4
Training loss: 0.2869933545589447
Validation loss: 1.531792760536235

Epoch: 5| Step: 5
Training loss: 0.1511525809764862
Validation loss: 1.5413072314313663

Epoch: 5| Step: 6
Training loss: 0.1022908091545105
Validation loss: 1.523834818152971

Epoch: 5| Step: 7
Training loss: 0.24726715683937073
Validation loss: 1.5463155187586302

Epoch: 5| Step: 8
Training loss: 0.17382054030895233
Validation loss: 1.5644582907358806

Epoch: 5| Step: 9
Training loss: 0.47842079401016235
Validation loss: 1.5937203156050814

Epoch: 5| Step: 10
Training loss: 0.1679953932762146
Validation loss: 1.6059824907651512

Epoch: 304| Step: 0
Training loss: 0.17526356875896454
Validation loss: 1.6281229244765414

Epoch: 5| Step: 1
Training loss: 0.11949994415044785
Validation loss: 1.6388918148574008

Epoch: 5| Step: 2
Training loss: 0.1207943707704544
Validation loss: 1.6301782131195068

Epoch: 5| Step: 3
Training loss: 0.14555692672729492
Validation loss: 1.6149300324019564

Epoch: 5| Step: 4
Training loss: 0.12736332416534424
Validation loss: 1.6229059055287351

Epoch: 5| Step: 5
Training loss: 0.21819250285625458
Validation loss: 1.606231826607899

Epoch: 5| Step: 6
Training loss: 0.09838670492172241
Validation loss: 1.6315640159832534

Epoch: 5| Step: 7
Training loss: 0.38298141956329346
Validation loss: 1.6335790644409836

Epoch: 5| Step: 8
Training loss: 0.16435319185256958
Validation loss: 1.6062134616477515

Epoch: 5| Step: 9
Training loss: 0.2235882729291916
Validation loss: 1.6012975041584303

Epoch: 5| Step: 10
Training loss: 0.4870363175868988
Validation loss: 1.5933119917428622

Epoch: 305| Step: 0
Training loss: 0.1757681667804718
Validation loss: 1.5966020014978224

Epoch: 5| Step: 1
Training loss: 0.3252328038215637
Validation loss: 1.614312591091279

Epoch: 5| Step: 2
Training loss: 0.3202081322669983
Validation loss: 1.6169494557124313

Epoch: 5| Step: 3
Training loss: 0.1526063084602356
Validation loss: 1.6208277979204733

Epoch: 5| Step: 4
Training loss: 0.17730368673801422
Validation loss: 1.6055897371743315

Epoch: 5| Step: 5
Training loss: 0.18627755343914032
Validation loss: 1.6020468742616716

Epoch: 5| Step: 6
Training loss: 0.20632994174957275
Validation loss: 1.616542411106889

Epoch: 5| Step: 7
Training loss: 0.2087877243757248
Validation loss: 1.603834016348726

Epoch: 5| Step: 8
Training loss: 0.08678213506937027
Validation loss: 1.6230289320791922

Epoch: 5| Step: 9
Training loss: 0.14544983208179474
Validation loss: 1.6066813866297405

Epoch: 5| Step: 10
Training loss: 0.21000388264656067
Validation loss: 1.591780427963503

Epoch: 306| Step: 0
Training loss: 0.4001479148864746
Validation loss: 1.5972439319856706

Epoch: 5| Step: 1
Training loss: 0.14770576357841492
Validation loss: 1.5907443300370248

Epoch: 5| Step: 2
Training loss: 0.1577368825674057
Validation loss: 1.6018565713718373

Epoch: 5| Step: 3
Training loss: 0.08848001807928085
Validation loss: 1.5951099177842498

Epoch: 5| Step: 4
Training loss: 0.2410353124141693
Validation loss: 1.575176763278182

Epoch: 5| Step: 5
Training loss: 0.1863497793674469
Validation loss: 1.5845739828642977

Epoch: 5| Step: 6
Training loss: 0.2470649778842926
Validation loss: 1.5506082478389944

Epoch: 5| Step: 7
Training loss: 0.23668238520622253
Validation loss: 1.576251970824375

Epoch: 5| Step: 8
Training loss: 0.16046980023384094
Validation loss: 1.6028895032021306

Epoch: 5| Step: 9
Training loss: 0.12494462728500366
Validation loss: 1.5981843048526394

Epoch: 5| Step: 10
Training loss: 0.08195632696151733
Validation loss: 1.6094040140028922

Epoch: 307| Step: 0
Training loss: 0.09458319842815399
Validation loss: 1.6193316559637747

Epoch: 5| Step: 1
Training loss: 0.18138691782951355
Validation loss: 1.6128064285042465

Epoch: 5| Step: 2
Training loss: 0.16909131407737732
Validation loss: 1.6034680822844147

Epoch: 5| Step: 3
Training loss: 0.13364094495773315
Validation loss: 1.600447594478566

Epoch: 5| Step: 4
Training loss: 0.11104995012283325
Validation loss: 1.6033460042809928

Epoch: 5| Step: 5
Training loss: 0.4987073838710785
Validation loss: 1.6090200498539915

Epoch: 5| Step: 6
Training loss: 0.1841188222169876
Validation loss: 1.6073568033915695

Epoch: 5| Step: 7
Training loss: 0.23142793774604797
Validation loss: 1.6136482915570658

Epoch: 5| Step: 8
Training loss: 0.20666411519050598
Validation loss: 1.5802294759340183

Epoch: 5| Step: 9
Training loss: 0.10959788411855698
Validation loss: 1.5778456208526448

Epoch: 5| Step: 10
Training loss: 0.1708877980709076
Validation loss: 1.5629547129395187

Epoch: 308| Step: 0
Training loss: 0.11773946136236191
Validation loss: 1.5638193943167245

Epoch: 5| Step: 1
Training loss: 0.14204099774360657
Validation loss: 1.557294104688911

Epoch: 5| Step: 2
Training loss: 0.3423786759376526
Validation loss: 1.5741757577465427

Epoch: 5| Step: 3
Training loss: 0.16094671189785004
Validation loss: 1.6059235103668705

Epoch: 5| Step: 4
Training loss: 0.23894166946411133
Validation loss: 1.6171777517564836

Epoch: 5| Step: 5
Training loss: 0.18697616457939148
Validation loss: 1.6171938885924637

Epoch: 5| Step: 6
Training loss: 0.22818884253501892
Validation loss: 1.5980815297813826

Epoch: 5| Step: 7
Training loss: 0.2018745392560959
Validation loss: 1.5875671563609954

Epoch: 5| Step: 8
Training loss: 0.22987505793571472
Validation loss: 1.5839524038376347

Epoch: 5| Step: 9
Training loss: 0.11799080669879913
Validation loss: 1.5551778334443287

Epoch: 5| Step: 10
Training loss: 0.17208510637283325
Validation loss: 1.5577257140990226

Epoch: 309| Step: 0
Training loss: 0.19301848113536835
Validation loss: 1.5411687025459864

Epoch: 5| Step: 1
Training loss: 0.1395532190799713
Validation loss: 1.5684311902651222

Epoch: 5| Step: 2
Training loss: 0.1441718190908432
Validation loss: 1.5744726593776415

Epoch: 5| Step: 3
Training loss: 0.374243825674057
Validation loss: 1.5877390510292464

Epoch: 5| Step: 4
Training loss: 0.14797163009643555
Validation loss: 1.5861164190435921

Epoch: 5| Step: 5
Training loss: 0.21172182261943817
Validation loss: 1.6037687998945995

Epoch: 5| Step: 6
Training loss: 0.32954999804496765
Validation loss: 1.5966946117339595

Epoch: 5| Step: 7
Training loss: 0.12521828711032867
Validation loss: 1.562948207701406

Epoch: 5| Step: 8
Training loss: 0.19193030893802643
Validation loss: 1.6027617685256466

Epoch: 5| Step: 9
Training loss: 0.17281246185302734
Validation loss: 1.5970127390277

Epoch: 5| Step: 10
Training loss: 0.10739769786596298
Validation loss: 1.6026811356185584

Epoch: 310| Step: 0
Training loss: 0.21352043747901917
Validation loss: 1.610394690626411

Epoch: 5| Step: 1
Training loss: 0.16965770721435547
Validation loss: 1.574704320200028

Epoch: 5| Step: 2
Training loss: 0.1301153600215912
Validation loss: 1.58512484130039

Epoch: 5| Step: 3
Training loss: 0.2764796316623688
Validation loss: 1.5940171281496684

Epoch: 5| Step: 4
Training loss: 0.19627052545547485
Validation loss: 1.5772348373166976

Epoch: 5| Step: 5
Training loss: 0.19562101364135742
Validation loss: 1.5971763749276437

Epoch: 5| Step: 6
Training loss: 0.16222918033599854
Validation loss: 1.6360373497009277

Epoch: 5| Step: 7
Training loss: 0.22010648250579834
Validation loss: 1.5827559335257417

Epoch: 5| Step: 8
Training loss: 0.2997441589832306
Validation loss: 1.5737457916300783

Epoch: 5| Step: 9
Training loss: 0.16609127819538116
Validation loss: 1.5597400152555077

Epoch: 5| Step: 10
Training loss: 0.4432280361652374
Validation loss: 1.5563742165924401

Epoch: 311| Step: 0
Training loss: 0.20997802913188934
Validation loss: 1.5698685671693535

Epoch: 5| Step: 1
Training loss: 0.2800759971141815
Validation loss: 1.5538272793574999

Epoch: 5| Step: 2
Training loss: 0.1134960800409317
Validation loss: 1.5823781182689052

Epoch: 5| Step: 3
Training loss: 0.2150346040725708
Validation loss: 1.6030223869508313

Epoch: 5| Step: 4
Training loss: 0.27225491404533386
Validation loss: 1.5812509585452337

Epoch: 5| Step: 5
Training loss: 0.1347821056842804
Validation loss: 1.616376551248694

Epoch: 5| Step: 6
Training loss: 0.37180179357528687
Validation loss: 1.6443456501089118

Epoch: 5| Step: 7
Training loss: 0.2321465015411377
Validation loss: 1.6454457224056285

Epoch: 5| Step: 8
Training loss: 0.1691131889820099
Validation loss: 1.6196607735849196

Epoch: 5| Step: 9
Training loss: 0.47620993852615356
Validation loss: 1.6130453457114518

Epoch: 5| Step: 10
Training loss: 0.11694470047950745
Validation loss: 1.6057738334901872

Epoch: 312| Step: 0
Training loss: 0.1004803404211998
Validation loss: 1.5776183348830028

Epoch: 5| Step: 1
Training loss: 0.22220361232757568
Validation loss: 1.5635327498118083

Epoch: 5| Step: 2
Training loss: 0.19796249270439148
Validation loss: 1.5790801676370765

Epoch: 5| Step: 3
Training loss: 0.18690484762191772
Validation loss: 1.6041123444034207

Epoch: 5| Step: 4
Training loss: 0.1348617970943451
Validation loss: 1.5772013189972087

Epoch: 5| Step: 5
Training loss: 0.10272393375635147
Validation loss: 1.5707111704734065

Epoch: 5| Step: 6
Training loss: 0.1540890485048294
Validation loss: 1.5606623157378166

Epoch: 5| Step: 7
Training loss: 0.29941436648368835
Validation loss: 1.5645926819052747

Epoch: 5| Step: 8
Training loss: 0.18273432552814484
Validation loss: 1.5663731880085443

Epoch: 5| Step: 9
Training loss: 0.18486711382865906
Validation loss: 1.5682573485118088

Epoch: 5| Step: 10
Training loss: 0.24607591331005096
Validation loss: 1.5628308980695662

Epoch: 313| Step: 0
Training loss: 0.2449861764907837
Validation loss: 1.5987130326609458

Epoch: 5| Step: 1
Training loss: 0.12929455935955048
Validation loss: 1.609682116457211

Epoch: 5| Step: 2
Training loss: 0.14637529850006104
Validation loss: 1.617628764080745

Epoch: 5| Step: 3
Training loss: 0.23308560252189636
Validation loss: 1.5878784169432938

Epoch: 5| Step: 4
Training loss: 0.4604436755180359
Validation loss: 1.603200292074552

Epoch: 5| Step: 5
Training loss: 0.23494596779346466
Validation loss: 1.5909709571510233

Epoch: 5| Step: 6
Training loss: 0.11271218955516815
Validation loss: 1.5860265134483256

Epoch: 5| Step: 7
Training loss: 0.19809943437576294
Validation loss: 1.6045373075751848

Epoch: 5| Step: 8
Training loss: 0.13965259492397308
Validation loss: 1.6207090462407758

Epoch: 5| Step: 9
Training loss: 0.14633798599243164
Validation loss: 1.6049611260814052

Epoch: 5| Step: 10
Training loss: 0.19659581780433655
Validation loss: 1.6106773114973498

Epoch: 314| Step: 0
Training loss: 0.21921586990356445
Validation loss: 1.6396968044260496

Epoch: 5| Step: 1
Training loss: 0.12153884023427963
Validation loss: 1.6098795372952697

Epoch: 5| Step: 2
Training loss: 0.1647668331861496
Validation loss: 1.5899390353951404

Epoch: 5| Step: 3
Training loss: 0.2133628875017166
Validation loss: 1.5622206387981292

Epoch: 5| Step: 4
Training loss: 0.13614706695079803
Validation loss: 1.5634473575058805

Epoch: 5| Step: 5
Training loss: 0.1668126881122589
Validation loss: 1.56012087996288

Epoch: 5| Step: 6
Training loss: 0.1492287814617157
Validation loss: 1.5693236973977858

Epoch: 5| Step: 7
Training loss: 0.14755161106586456
Validation loss: 1.5783088027790029

Epoch: 5| Step: 8
Training loss: 0.18487481772899628
Validation loss: 1.5587544377132128

Epoch: 5| Step: 9
Training loss: 0.1610030084848404
Validation loss: 1.5837798887683499

Epoch: 5| Step: 10
Training loss: 0.4944324493408203
Validation loss: 1.5999976178651214

Epoch: 315| Step: 0
Training loss: 0.14512838423252106
Validation loss: 1.6173956778741652

Epoch: 5| Step: 1
Training loss: 0.18298324942588806
Validation loss: 1.5891680038103493

Epoch: 5| Step: 2
Training loss: 0.19876167178153992
Validation loss: 1.6240548933705976

Epoch: 5| Step: 3
Training loss: 0.21498127281665802
Validation loss: 1.5884184632250058

Epoch: 5| Step: 4
Training loss: 0.15684504806995392
Validation loss: 1.580629038554366

Epoch: 5| Step: 5
Training loss: 0.3061668276786804
Validation loss: 1.561681738463781

Epoch: 5| Step: 6
Training loss: 0.21868178248405457
Validation loss: 1.571594956100628

Epoch: 5| Step: 7
Training loss: 0.194487065076828
Validation loss: 1.5659924912196335

Epoch: 5| Step: 8
Training loss: 0.14765718579292297
Validation loss: 1.5693734717625443

Epoch: 5| Step: 9
Training loss: 0.3163596987724304
Validation loss: 1.5595293903863559

Epoch: 5| Step: 10
Training loss: 0.20214325189590454
Validation loss: 1.594011281126289

Epoch: 316| Step: 0
Training loss: 0.08634140342473984
Validation loss: 1.5889721865295081

Epoch: 5| Step: 1
Training loss: 0.1611672341823578
Validation loss: 1.5732246131025336

Epoch: 5| Step: 2
Training loss: 0.19621597230434418
Validation loss: 1.5997111143604401

Epoch: 5| Step: 3
Training loss: 0.24898728728294373
Validation loss: 1.5823753469733781

Epoch: 5| Step: 4
Training loss: 0.20018620789051056
Validation loss: 1.5683349204319779

Epoch: 5| Step: 5
Training loss: 0.1229771226644516
Validation loss: 1.5530884945264427

Epoch: 5| Step: 6
Training loss: 0.29993778467178345
Validation loss: 1.5661104962389956

Epoch: 5| Step: 7
Training loss: 0.29696014523506165
Validation loss: 1.5856556187393844

Epoch: 5| Step: 8
Training loss: 0.24882766604423523
Validation loss: 1.6076669821175196

Epoch: 5| Step: 9
Training loss: 0.25400230288505554
Validation loss: 1.5948612587426299

Epoch: 5| Step: 10
Training loss: 0.21760648488998413
Validation loss: 1.58864051424047

Epoch: 317| Step: 0
Training loss: 0.11940733343362808
Validation loss: 1.5854336894968504

Epoch: 5| Step: 1
Training loss: 0.1487547606229782
Validation loss: 1.5861449997912171

Epoch: 5| Step: 2
Training loss: 0.16402652859687805
Validation loss: 1.5822515064670193

Epoch: 5| Step: 3
Training loss: 0.12978780269622803
Validation loss: 1.5771959802155853

Epoch: 5| Step: 4
Training loss: 0.1802593618631363
Validation loss: 1.5865479528263051

Epoch: 5| Step: 5
Training loss: 0.1517975777387619
Validation loss: 1.5966127854521557

Epoch: 5| Step: 6
Training loss: 0.34333017468452454
Validation loss: 1.5950568895186148

Epoch: 5| Step: 7
Training loss: 0.2673757076263428
Validation loss: 1.5932713618842504

Epoch: 5| Step: 8
Training loss: 0.14416173100471497
Validation loss: 1.5741860969092256

Epoch: 5| Step: 9
Training loss: 0.23940043151378632
Validation loss: 1.5854359480642504

Epoch: 5| Step: 10
Training loss: 0.33646368980407715
Validation loss: 1.5784761354487429

Epoch: 318| Step: 0
Training loss: 0.11862335354089737
Validation loss: 1.6037415971038163

Epoch: 5| Step: 1
Training loss: 0.1336817741394043
Validation loss: 1.6091429956497685

Epoch: 5| Step: 2
Training loss: 0.2570149004459381
Validation loss: 1.619021528510637

Epoch: 5| Step: 3
Training loss: 0.16876116394996643
Validation loss: 1.6457764833204207

Epoch: 5| Step: 4
Training loss: 0.29808467626571655
Validation loss: 1.6182304710470221

Epoch: 5| Step: 5
Training loss: 0.24229088425636292
Validation loss: 1.6615724871235509

Epoch: 5| Step: 6
Training loss: 0.1647166758775711
Validation loss: 1.6608155478713333

Epoch: 5| Step: 7
Training loss: 0.10564196109771729
Validation loss: 1.6550085262585712

Epoch: 5| Step: 8
Training loss: 0.18584850430488586
Validation loss: 1.6550017736291374

Epoch: 5| Step: 9
Training loss: 0.3163142204284668
Validation loss: 1.6579532751473047

Epoch: 5| Step: 10
Training loss: 0.07753933221101761
Validation loss: 1.6311489856371315

Epoch: 319| Step: 0
Training loss: 0.19174858927726746
Validation loss: 1.6121887353158766

Epoch: 5| Step: 1
Training loss: 0.36299648880958557
Validation loss: 1.6250135116679694

Epoch: 5| Step: 2
Training loss: 0.12341369688510895
Validation loss: 1.5941067908399849

Epoch: 5| Step: 3
Training loss: 0.14703230559825897
Validation loss: 1.6023063326394686

Epoch: 5| Step: 4
Training loss: 0.09172143787145615
Validation loss: 1.571437866457047

Epoch: 5| Step: 5
Training loss: 0.28964921832084656
Validation loss: 1.5855471100858463

Epoch: 5| Step: 6
Training loss: 0.1553744524717331
Validation loss: 1.597074456112359

Epoch: 5| Step: 7
Training loss: 0.17421291768550873
Validation loss: 1.5954845323357532

Epoch: 5| Step: 8
Training loss: 0.12691059708595276
Validation loss: 1.6195002371265041

Epoch: 5| Step: 9
Training loss: 0.2559484839439392
Validation loss: 1.6184646750009188

Epoch: 5| Step: 10
Training loss: 0.20637637376785278
Validation loss: 1.6270251171563261

Epoch: 320| Step: 0
Training loss: 0.34394553303718567
Validation loss: 1.5848493922141291

Epoch: 5| Step: 1
Training loss: 0.17879422008991241
Validation loss: 1.5992302433136971

Epoch: 5| Step: 2
Training loss: 0.2065078318119049
Validation loss: 1.571785362817908

Epoch: 5| Step: 3
Training loss: 0.08150065690279007
Validation loss: 1.5691061481352775

Epoch: 5| Step: 4
Training loss: 0.09816862642765045
Validation loss: 1.575587007307237

Epoch: 5| Step: 5
Training loss: 0.14445669949054718
Validation loss: 1.5833185898360385

Epoch: 5| Step: 6
Training loss: 0.16652320325374603
Validation loss: 1.6059208505897111

Epoch: 5| Step: 7
Training loss: 0.35719019174575806
Validation loss: 1.5855338817001672

Epoch: 5| Step: 8
Training loss: 0.1700093150138855
Validation loss: 1.5728343058657903

Epoch: 5| Step: 9
Training loss: 0.17509004473686218
Validation loss: 1.6086634346233901

Epoch: 5| Step: 10
Training loss: 0.09524715691804886
Validation loss: 1.5959389645566222

Epoch: 321| Step: 0
Training loss: 0.11216537654399872
Validation loss: 1.5979065125988376

Epoch: 5| Step: 1
Training loss: 0.26148509979248047
Validation loss: 1.5884391518049343

Epoch: 5| Step: 2
Training loss: 0.14597828686237335
Validation loss: 1.5834641225876347

Epoch: 5| Step: 3
Training loss: 0.15573029220104218
Validation loss: 1.592332269555779

Epoch: 5| Step: 4
Training loss: 0.08610054105520248
Validation loss: 1.5552382943450764

Epoch: 5| Step: 5
Training loss: 0.12629561126232147
Validation loss: 1.5652439696814424

Epoch: 5| Step: 6
Training loss: 0.13142146170139313
Validation loss: 1.5575989113059094

Epoch: 5| Step: 7
Training loss: 0.10621281713247299
Validation loss: 1.5551716102066862

Epoch: 5| Step: 8
Training loss: 0.24554824829101562
Validation loss: 1.5599017309886154

Epoch: 5| Step: 9
Training loss: 0.3131890296936035
Validation loss: 1.5815005392156622

Epoch: 5| Step: 10
Training loss: 0.22874030470848083
Validation loss: 1.5686679360687092

Epoch: 322| Step: 0
Training loss: 0.11939537525177002
Validation loss: 1.55897262788588

Epoch: 5| Step: 1
Training loss: 0.14189335703849792
Validation loss: 1.548667097604403

Epoch: 5| Step: 2
Training loss: 0.13467320799827576
Validation loss: 1.5725925430174796

Epoch: 5| Step: 3
Training loss: 0.2037140429019928
Validation loss: 1.5790829684144707

Epoch: 5| Step: 4
Training loss: 0.274455726146698
Validation loss: 1.5667929316079745

Epoch: 5| Step: 5
Training loss: 0.23629680275917053
Validation loss: 1.6185502634253552

Epoch: 5| Step: 6
Training loss: 0.1901487559080124
Validation loss: 1.605191429456075

Epoch: 5| Step: 7
Training loss: 0.1941090077161789
Validation loss: 1.6108044052636752

Epoch: 5| Step: 8
Training loss: 0.17810413241386414
Validation loss: 1.5745010619522424

Epoch: 5| Step: 9
Training loss: 0.33680492639541626
Validation loss: 1.6001474101056334

Epoch: 5| Step: 10
Training loss: 0.2155848890542984
Validation loss: 1.592323487804782

Epoch: 323| Step: 0
Training loss: 0.18364635109901428
Validation loss: 1.5859091345981886

Epoch: 5| Step: 1
Training loss: 0.13299866020679474
Validation loss: 1.573292870675364

Epoch: 5| Step: 2
Training loss: 0.13907641172409058
Validation loss: 1.582837661107381

Epoch: 5| Step: 3
Training loss: 0.17559698224067688
Validation loss: 1.5922721483374154

Epoch: 5| Step: 4
Training loss: 0.33441224694252014
Validation loss: 1.6483123610096593

Epoch: 5| Step: 5
Training loss: 0.24995648860931396
Validation loss: 1.654889554105779

Epoch: 5| Step: 6
Training loss: 0.1949077546596527
Validation loss: 1.6730529915901922

Epoch: 5| Step: 7
Training loss: 0.38052898645401
Validation loss: 1.6295534308238695

Epoch: 5| Step: 8
Training loss: 0.20705227553844452
Validation loss: 1.5864762644613943

Epoch: 5| Step: 9
Training loss: 0.2335982322692871
Validation loss: 1.599843507171959

Epoch: 5| Step: 10
Training loss: 0.19690614938735962
Validation loss: 1.596195101737976

Epoch: 324| Step: 0
Training loss: 0.26171934604644775
Validation loss: 1.5839015258255826

Epoch: 5| Step: 1
Training loss: 0.14933918416500092
Validation loss: 1.6121651786629871

Epoch: 5| Step: 2
Training loss: 0.28497037291526794
Validation loss: 1.6201970102966472

Epoch: 5| Step: 3
Training loss: 0.19723543524742126
Validation loss: 1.6083153127342142

Epoch: 5| Step: 4
Training loss: 0.18087175488471985
Validation loss: 1.5848844769180461

Epoch: 5| Step: 5
Training loss: 0.23870901763439178
Validation loss: 1.5599710608041415

Epoch: 5| Step: 6
Training loss: 0.1272204965353012
Validation loss: 1.5681004396048925

Epoch: 5| Step: 7
Training loss: 0.09280996769666672
Validation loss: 1.5505716223870554

Epoch: 5| Step: 8
Training loss: 0.3297383189201355
Validation loss: 1.539264860332653

Epoch: 5| Step: 9
Training loss: 0.09255576878786087
Validation loss: 1.5310899589651374

Epoch: 5| Step: 10
Training loss: 0.1811315268278122
Validation loss: 1.5353904718993812

Epoch: 325| Step: 0
Training loss: 0.22034716606140137
Validation loss: 1.5137959167521486

Epoch: 5| Step: 1
Training loss: 0.12972263991832733
Validation loss: 1.518568487577541

Epoch: 5| Step: 2
Training loss: 0.3620246350765228
Validation loss: 1.5297716074092413

Epoch: 5| Step: 3
Training loss: 0.1741882860660553
Validation loss: 1.5476617582382695

Epoch: 5| Step: 4
Training loss: 0.2019319087266922
Validation loss: 1.5618783017640472

Epoch: 5| Step: 5
Training loss: 0.10931344330310822
Validation loss: 1.529515916301358

Epoch: 5| Step: 6
Training loss: 0.17924568057060242
Validation loss: 1.5528201249337965

Epoch: 5| Step: 7
Training loss: 0.11878721415996552
Validation loss: 1.5414759612852527

Epoch: 5| Step: 8
Training loss: 0.3380202353000641
Validation loss: 1.5837140480677288

Epoch: 5| Step: 9
Training loss: 0.10470256954431534
Validation loss: 1.573468836404944

Epoch: 5| Step: 10
Training loss: 0.13947001099586487
Validation loss: 1.5707024041042532

Epoch: 326| Step: 0
Training loss: 0.1686762273311615
Validation loss: 1.5597858377682265

Epoch: 5| Step: 1
Training loss: 0.23015257716178894
Validation loss: 1.5845518753092775

Epoch: 5| Step: 2
Training loss: 0.12118983268737793
Validation loss: 1.5673178254917104

Epoch: 5| Step: 3
Training loss: 0.18414925038814545
Validation loss: 1.5517413346998152

Epoch: 5| Step: 4
Training loss: 0.292007178068161
Validation loss: 1.5444394170597036

Epoch: 5| Step: 5
Training loss: 0.13456936180591583
Validation loss: 1.513165476501629

Epoch: 5| Step: 6
Training loss: 0.143256276845932
Validation loss: 1.5304225772939704

Epoch: 5| Step: 7
Training loss: 0.1503162980079651
Validation loss: 1.521168202482244

Epoch: 5| Step: 8
Training loss: 0.13630303740501404
Validation loss: 1.5258284858478013

Epoch: 5| Step: 9
Training loss: 0.25753381848335266
Validation loss: 1.5220408952364357

Epoch: 5| Step: 10
Training loss: 0.31259095668792725
Validation loss: 1.5194353941948182

Epoch: 327| Step: 0
Training loss: 0.1819155216217041
Validation loss: 1.5076766911373343

Epoch: 5| Step: 1
Training loss: 0.18821445107460022
Validation loss: 1.5285563218978144

Epoch: 5| Step: 2
Training loss: 0.16386428475379944
Validation loss: 1.5488151145237747

Epoch: 5| Step: 3
Training loss: 0.2771361470222473
Validation loss: 1.5445442135616014

Epoch: 5| Step: 4
Training loss: 0.23461982607841492
Validation loss: 1.606833569465145

Epoch: 5| Step: 5
Training loss: 0.1942058801651001
Validation loss: 1.6227962278550672

Epoch: 5| Step: 6
Training loss: 0.15035389363765717
Validation loss: 1.6033999317435808

Epoch: 5| Step: 7
Training loss: 0.21612079441547394
Validation loss: 1.5881263209927468

Epoch: 5| Step: 8
Training loss: 0.22110001742839813
Validation loss: 1.5464407436309322

Epoch: 5| Step: 9
Training loss: 0.11609265953302383
Validation loss: 1.514392622055546

Epoch: 5| Step: 10
Training loss: 0.3755837082862854
Validation loss: 1.529608461164659

Epoch: 328| Step: 0
Training loss: 0.17551358044147491
Validation loss: 1.4979085986332228

Epoch: 5| Step: 1
Training loss: 0.16365250945091248
Validation loss: 1.5057494332713466

Epoch: 5| Step: 2
Training loss: 0.16243085265159607
Validation loss: 1.5174764202487083

Epoch: 5| Step: 3
Training loss: 0.19672445952892303
Validation loss: 1.5086462869439075

Epoch: 5| Step: 4
Training loss: 0.2758421003818512
Validation loss: 1.5279427612981489

Epoch: 5| Step: 5
Training loss: 0.31226426362991333
Validation loss: 1.5245139637301046

Epoch: 5| Step: 6
Training loss: 0.45180973410606384
Validation loss: 1.513119150233525

Epoch: 5| Step: 7
Training loss: 0.1945594847202301
Validation loss: 1.5605518458991923

Epoch: 5| Step: 8
Training loss: 0.20873884856700897
Validation loss: 1.5616695406616374

Epoch: 5| Step: 9
Training loss: 0.14285612106323242
Validation loss: 1.5735595316015265

Epoch: 5| Step: 10
Training loss: 0.10627605766057968
Validation loss: 1.5593338333150393

Epoch: 329| Step: 0
Training loss: 0.15944716334342957
Validation loss: 1.5819488430535922

Epoch: 5| Step: 1
Training loss: 0.3283687233924866
Validation loss: 1.557994556683366

Epoch: 5| Step: 2
Training loss: 0.13772699236869812
Validation loss: 1.560463418242752

Epoch: 5| Step: 3
Training loss: 0.32156985998153687
Validation loss: 1.5430030809935702

Epoch: 5| Step: 4
Training loss: 0.20392218232154846
Validation loss: 1.5257063732352307

Epoch: 5| Step: 5
Training loss: 0.1519852876663208
Validation loss: 1.521909781681594

Epoch: 5| Step: 6
Training loss: 0.1917067915201187
Validation loss: 1.4861621984871485

Epoch: 5| Step: 7
Training loss: 0.19973163306713104
Validation loss: 1.4814741996026808

Epoch: 5| Step: 8
Training loss: 0.1693183183670044
Validation loss: 1.4837961209717618

Epoch: 5| Step: 9
Training loss: 0.16272440552711487
Validation loss: 1.494811252881122

Epoch: 5| Step: 10
Training loss: 0.16652177274227142
Validation loss: 1.4836051976808937

Epoch: 330| Step: 0
Training loss: 0.1518654227256775
Validation loss: 1.511912722741404

Epoch: 5| Step: 1
Training loss: 0.2472676783800125
Validation loss: 1.5097046000983125

Epoch: 5| Step: 2
Training loss: 0.15999755263328552
Validation loss: 1.514949583238171

Epoch: 5| Step: 3
Training loss: 0.3218630254268646
Validation loss: 1.5457058516881799

Epoch: 5| Step: 4
Training loss: 0.16835917532444
Validation loss: 1.5305550047146377

Epoch: 5| Step: 5
Training loss: 0.2632749676704407
Validation loss: 1.5234849055608113

Epoch: 5| Step: 6
Training loss: 0.188665509223938
Validation loss: 1.5454029908744238

Epoch: 5| Step: 7
Training loss: 0.25691789388656616
Validation loss: 1.557298655151039

Epoch: 5| Step: 8
Training loss: 0.186900332570076
Validation loss: 1.581886188958281

Epoch: 5| Step: 9
Training loss: 0.26668933033943176
Validation loss: 1.5525192906779628

Epoch: 5| Step: 10
Training loss: 0.16810524463653564
Validation loss: 1.5581964651743572

Epoch: 331| Step: 0
Training loss: 0.129949688911438
Validation loss: 1.5642609942343928

Epoch: 5| Step: 1
Training loss: 0.107627734541893
Validation loss: 1.5485304619676323

Epoch: 5| Step: 2
Training loss: 0.3676573634147644
Validation loss: 1.5759419369441208

Epoch: 5| Step: 3
Training loss: 0.25165852904319763
Validation loss: 1.5908201823952377

Epoch: 5| Step: 4
Training loss: 0.19668729603290558
Validation loss: 1.5415196662308068

Epoch: 5| Step: 5
Training loss: 0.21188445389270782
Validation loss: 1.5389327554292576

Epoch: 5| Step: 6
Training loss: 0.19836129248142242
Validation loss: 1.5497713511989963

Epoch: 5| Step: 7
Training loss: 0.20837345719337463
Validation loss: 1.5449166285094393

Epoch: 5| Step: 8
Training loss: 0.15130290389060974
Validation loss: 1.5740364418234876

Epoch: 5| Step: 9
Training loss: 0.1823466271162033
Validation loss: 1.561688624402528

Epoch: 5| Step: 10
Training loss: 0.1732109785079956
Validation loss: 1.5671136597151398

Epoch: 332| Step: 0
Training loss: 0.08105169236660004
Validation loss: 1.554584805683423

Epoch: 5| Step: 1
Training loss: 0.1659872680902481
Validation loss: 1.6095329510268344

Epoch: 5| Step: 2
Training loss: 0.30806952714920044
Validation loss: 1.6244344121666365

Epoch: 5| Step: 3
Training loss: 0.23745933175086975
Validation loss: 1.6311219212829426

Epoch: 5| Step: 4
Training loss: 0.20901572704315186
Validation loss: 1.6222010786815355

Epoch: 5| Step: 5
Training loss: 0.20151939988136292
Validation loss: 1.5830163763415428

Epoch: 5| Step: 6
Training loss: 0.1371919959783554
Validation loss: 1.54820425920589

Epoch: 5| Step: 7
Training loss: 0.09811367094516754
Validation loss: 1.5046078530691003

Epoch: 5| Step: 8
Training loss: 0.12638935446739197
Validation loss: 1.4988908690790976

Epoch: 5| Step: 9
Training loss: 0.3312978446483612
Validation loss: 1.5019935971947127

Epoch: 5| Step: 10
Training loss: 0.15197360515594482
Validation loss: 1.4728370853649673

Epoch: 333| Step: 0
Training loss: 0.22094674408435822
Validation loss: 1.479445622813317

Epoch: 5| Step: 1
Training loss: 0.11732427775859833
Validation loss: 1.490482179067468

Epoch: 5| Step: 2
Training loss: 0.13426688313484192
Validation loss: 1.4729981422424316

Epoch: 5| Step: 3
Training loss: 0.19387802481651306
Validation loss: 1.4856549245055004

Epoch: 5| Step: 4
Training loss: 0.34346863627433777
Validation loss: 1.506542908248081

Epoch: 5| Step: 5
Training loss: 0.17083188891410828
Validation loss: 1.5132438854504657

Epoch: 5| Step: 6
Training loss: 0.1993436962366104
Validation loss: 1.5196700685767717

Epoch: 5| Step: 7
Training loss: 0.20974326133728027
Validation loss: 1.532328732552067

Epoch: 5| Step: 8
Training loss: 0.09602993726730347
Validation loss: 1.530755542939709

Epoch: 5| Step: 9
Training loss: 0.17797191441059113
Validation loss: 1.5398027768699072

Epoch: 5| Step: 10
Training loss: 0.17727425694465637
Validation loss: 1.540827948559997

Epoch: 334| Step: 0
Training loss: 0.2232871800661087
Validation loss: 1.5408767423322123

Epoch: 5| Step: 1
Training loss: 0.11501015722751617
Validation loss: 1.5189841306337746

Epoch: 5| Step: 2
Training loss: 0.21305632591247559
Validation loss: 1.5349572973866616

Epoch: 5| Step: 3
Training loss: 0.27308541536331177
Validation loss: 1.5328523612791491

Epoch: 5| Step: 4
Training loss: 0.16652807593345642
Validation loss: 1.5279795815867763

Epoch: 5| Step: 5
Training loss: 0.09977289289236069
Validation loss: 1.5217669753618137

Epoch: 5| Step: 6
Training loss: 0.1546684056520462
Validation loss: 1.520735602865937

Epoch: 5| Step: 7
Training loss: 0.1499844789505005
Validation loss: 1.5098619550786994

Epoch: 5| Step: 8
Training loss: 0.19597545266151428
Validation loss: 1.5429501033598376

Epoch: 5| Step: 9
Training loss: 0.1477620005607605
Validation loss: 1.5465674951512327

Epoch: 5| Step: 10
Training loss: 0.06861187517642975
Validation loss: 1.5189556255135486

Epoch: 335| Step: 0
Training loss: 0.11575338989496231
Validation loss: 1.5081162747516428

Epoch: 5| Step: 1
Training loss: 0.1723662167787552
Validation loss: 1.5097472129329559

Epoch: 5| Step: 2
Training loss: 0.11863694339990616
Validation loss: 1.5028694239995812

Epoch: 5| Step: 3
Training loss: 0.2397717535495758
Validation loss: 1.4925858615547098

Epoch: 5| Step: 4
Training loss: 0.23034267127513885
Validation loss: 1.4778984387715657

Epoch: 5| Step: 5
Training loss: 0.10927674919366837
Validation loss: 1.5064879014927854

Epoch: 5| Step: 6
Training loss: 0.2346646785736084
Validation loss: 1.5094488333630305

Epoch: 5| Step: 7
Training loss: 0.3331187665462494
Validation loss: 1.5355811272898028

Epoch: 5| Step: 8
Training loss: 0.12928763031959534
Validation loss: 1.5232983596863285

Epoch: 5| Step: 9
Training loss: 0.15649735927581787
Validation loss: 1.5336396181455223

Epoch: 5| Step: 10
Training loss: 0.11965956538915634
Validation loss: 1.543432161372195

Epoch: 336| Step: 0
Training loss: 0.10439479351043701
Validation loss: 1.5104160321656095

Epoch: 5| Step: 1
Training loss: 0.13893014192581177
Validation loss: 1.531767455480432

Epoch: 5| Step: 2
Training loss: 0.22852618992328644
Validation loss: 1.5220050773312968

Epoch: 5| Step: 3
Training loss: 0.14649125933647156
Validation loss: 1.5270087398508543

Epoch: 5| Step: 4
Training loss: 0.15029124915599823
Validation loss: 1.5121009785641906

Epoch: 5| Step: 5
Training loss: 0.12607309222221375
Validation loss: 1.5240137448874853

Epoch: 5| Step: 6
Training loss: 0.1331823170185089
Validation loss: 1.5398056058473484

Epoch: 5| Step: 7
Training loss: 0.29034143686294556
Validation loss: 1.519338966697775

Epoch: 5| Step: 8
Training loss: 0.22546963393688202
Validation loss: 1.4977174574329006

Epoch: 5| Step: 9
Training loss: 0.0946548581123352
Validation loss: 1.5058618822405416

Epoch: 5| Step: 10
Training loss: 0.1696358323097229
Validation loss: 1.5162227256323701

Epoch: 337| Step: 0
Training loss: 0.19752183556556702
Validation loss: 1.5505110550952215

Epoch: 5| Step: 1
Training loss: 0.12030341476202011
Validation loss: 1.5300115693000056

Epoch: 5| Step: 2
Training loss: 0.34553593397140503
Validation loss: 1.5460839040817753

Epoch: 5| Step: 3
Training loss: 0.17026476562023163
Validation loss: 1.544790155144148

Epoch: 5| Step: 4
Training loss: 0.13513721525669098
Validation loss: 1.532288666694395

Epoch: 5| Step: 5
Training loss: 0.26385852694511414
Validation loss: 1.5048457243109261

Epoch: 5| Step: 6
Training loss: 0.2376655638217926
Validation loss: 1.4990966640492922

Epoch: 5| Step: 7
Training loss: 0.16556529700756073
Validation loss: 1.5181042712221864

Epoch: 5| Step: 8
Training loss: 0.1629522293806076
Validation loss: 1.517619357314161

Epoch: 5| Step: 9
Training loss: 0.20433644950389862
Validation loss: 1.5008714481066632

Epoch: 5| Step: 10
Training loss: 0.1757144182920456
Validation loss: 1.5075066922813334

Epoch: 338| Step: 0
Training loss: 0.13095241785049438
Validation loss: 1.5436454280730216

Epoch: 5| Step: 1
Training loss: 0.0817229226231575
Validation loss: 1.5299074137082664

Epoch: 5| Step: 2
Training loss: 0.1604676991701126
Validation loss: 1.537250643135399

Epoch: 5| Step: 3
Training loss: 0.17487506568431854
Validation loss: 1.542691275637637

Epoch: 5| Step: 4
Training loss: 0.16713526844978333
Validation loss: 1.5344337994052517

Epoch: 5| Step: 5
Training loss: 0.10202197730541229
Validation loss: 1.536270481924857

Epoch: 5| Step: 6
Training loss: 0.10326866060495377
Validation loss: 1.5324277711170975

Epoch: 5| Step: 7
Training loss: 0.276084840297699
Validation loss: 1.5319470820888397

Epoch: 5| Step: 8
Training loss: 0.25811833143234253
Validation loss: 1.5370626218857304

Epoch: 5| Step: 9
Training loss: 0.1977699249982834
Validation loss: 1.5151029966210807

Epoch: 5| Step: 10
Training loss: 0.20192483067512512
Validation loss: 1.5719638921881234

Epoch: 339| Step: 0
Training loss: 0.09619957208633423
Validation loss: 1.5455398251933437

Epoch: 5| Step: 1
Training loss: 0.12202968448400497
Validation loss: 1.5494301267849502

Epoch: 5| Step: 2
Training loss: 0.1162443533539772
Validation loss: 1.5344684380356983

Epoch: 5| Step: 3
Training loss: 0.2838805615901947
Validation loss: 1.5537439853914323

Epoch: 5| Step: 4
Training loss: 0.13364841043949127
Validation loss: 1.5752301011034238

Epoch: 5| Step: 5
Training loss: 0.14544501900672913
Validation loss: 1.5543940862019856

Epoch: 5| Step: 6
Training loss: 0.10494886338710785
Validation loss: 1.594086895706833

Epoch: 5| Step: 7
Training loss: 0.14637835323810577
Validation loss: 1.5946388834266252

Epoch: 5| Step: 8
Training loss: 0.13620789349079132
Validation loss: 1.5837413328950123

Epoch: 5| Step: 9
Training loss: 0.20388571918010712
Validation loss: 1.5725020945713084

Epoch: 5| Step: 10
Training loss: 0.25637394189834595
Validation loss: 1.5900071256904191

Epoch: 340| Step: 0
Training loss: 0.11141574382781982
Validation loss: 1.588435813944827

Epoch: 5| Step: 1
Training loss: 0.1454782783985138
Validation loss: 1.5608981309398529

Epoch: 5| Step: 2
Training loss: 0.07922913879156113
Validation loss: 1.536580817673796

Epoch: 5| Step: 3
Training loss: 0.12599433958530426
Validation loss: 1.5545677690095798

Epoch: 5| Step: 4
Training loss: 0.2482149600982666
Validation loss: 1.5537879172191824

Epoch: 5| Step: 5
Training loss: 0.14368312060832977
Validation loss: 1.5220323352403538

Epoch: 5| Step: 6
Training loss: 0.11911962181329727
Validation loss: 1.5394744052681872

Epoch: 5| Step: 7
Training loss: 0.2011965811252594
Validation loss: 1.5545371219676027

Epoch: 5| Step: 8
Training loss: 0.3619367480278015
Validation loss: 1.5272675765457975

Epoch: 5| Step: 9
Training loss: 0.13932785391807556
Validation loss: 1.5303922289161271

Epoch: 5| Step: 10
Training loss: 0.1083139181137085
Validation loss: 1.5297519955583798

Epoch: 341| Step: 0
Training loss: 0.12501829862594604
Validation loss: 1.5359227285590222

Epoch: 5| Step: 1
Training loss: 0.22925035655498505
Validation loss: 1.5389577227254068

Epoch: 5| Step: 2
Training loss: 0.13803836703300476
Validation loss: 1.529215435827932

Epoch: 5| Step: 3
Training loss: 0.15189246833324432
Validation loss: 1.5329270580763459

Epoch: 5| Step: 4
Training loss: 0.2803158462047577
Validation loss: 1.5770868601337555

Epoch: 5| Step: 5
Training loss: 0.13933753967285156
Validation loss: 1.5472778004984702

Epoch: 5| Step: 6
Training loss: 0.1293880045413971
Validation loss: 1.565093618567272

Epoch: 5| Step: 7
Training loss: 0.09491832554340363
Validation loss: 1.5410006148840791

Epoch: 5| Step: 8
Training loss: 0.15942755341529846
Validation loss: 1.5524635289305

Epoch: 5| Step: 9
Training loss: 0.15540745854377747
Validation loss: 1.5476092228325464

Epoch: 5| Step: 10
Training loss: 0.14496465027332306
Validation loss: 1.5295680428063998

Epoch: 342| Step: 0
Training loss: 0.28559136390686035
Validation loss: 1.538687648311738

Epoch: 5| Step: 1
Training loss: 0.1570827066898346
Validation loss: 1.5117424764940817

Epoch: 5| Step: 2
Training loss: 0.2724336087703705
Validation loss: 1.5086496978677728

Epoch: 5| Step: 3
Training loss: 0.10397686064243317
Validation loss: 1.5005749092307141

Epoch: 5| Step: 4
Training loss: 0.14514124393463135
Validation loss: 1.5069017653824182

Epoch: 5| Step: 5
Training loss: 0.09036668390035629
Validation loss: 1.4939404162027503

Epoch: 5| Step: 6
Training loss: 0.1438186913728714
Validation loss: 1.5111031673287834

Epoch: 5| Step: 7
Training loss: 0.17318420112133026
Validation loss: 1.5119262318457327

Epoch: 5| Step: 8
Training loss: 0.13387197256088257
Validation loss: 1.5192154338282924

Epoch: 5| Step: 9
Training loss: 0.13512995839118958
Validation loss: 1.5486322795191119

Epoch: 5| Step: 10
Training loss: 0.1593342423439026
Validation loss: 1.5273122749020975

Epoch: 343| Step: 0
Training loss: 0.19368508458137512
Validation loss: 1.5463730096817017

Epoch: 5| Step: 1
Training loss: 0.18083535134792328
Validation loss: 1.5389020109689364

Epoch: 5| Step: 2
Training loss: 0.2366788387298584
Validation loss: 1.5578844624180948

Epoch: 5| Step: 3
Training loss: 0.16466233134269714
Validation loss: 1.5251636069308045

Epoch: 5| Step: 4
Training loss: 0.1312250792980194
Validation loss: 1.5145346387740104

Epoch: 5| Step: 5
Training loss: 0.09430006891489029
Validation loss: 1.5128873586654663

Epoch: 5| Step: 6
Training loss: 0.16002216935157776
Validation loss: 1.5309570771391674

Epoch: 5| Step: 7
Training loss: 0.25454360246658325
Validation loss: 1.532558750080806

Epoch: 5| Step: 8
Training loss: 0.24399082362651825
Validation loss: 1.552951071851997

Epoch: 5| Step: 9
Training loss: 0.09614105522632599
Validation loss: 1.5145279720265379

Epoch: 5| Step: 10
Training loss: 0.10577879101037979
Validation loss: 1.502731846224877

Epoch: 344| Step: 0
Training loss: 0.13326363265514374
Validation loss: 1.5204663930400726

Epoch: 5| Step: 1
Training loss: 0.08698520809412003
Validation loss: 1.4912930880823443

Epoch: 5| Step: 2
Training loss: 0.26173609495162964
Validation loss: 1.489366586490344

Epoch: 5| Step: 3
Training loss: 0.13118688762187958
Validation loss: 1.480063187178745

Epoch: 5| Step: 4
Training loss: 0.13506849110126495
Validation loss: 1.4914952580646803

Epoch: 5| Step: 5
Training loss: 0.13341091573238373
Validation loss: 1.482597888156932

Epoch: 5| Step: 6
Training loss: 0.24339604377746582
Validation loss: 1.5028065917312459

Epoch: 5| Step: 7
Training loss: 0.2819755971431732
Validation loss: 1.4909999011665263

Epoch: 5| Step: 8
Training loss: 0.14665445685386658
Validation loss: 1.498097574839028

Epoch: 5| Step: 9
Training loss: 0.09565936028957367
Validation loss: 1.500525491212004

Epoch: 5| Step: 10
Training loss: 0.11387407034635544
Validation loss: 1.4849698979367492

Epoch: 345| Step: 0
Training loss: 0.09871769696474075
Validation loss: 1.5451799285027288

Epoch: 5| Step: 1
Training loss: 0.11953113973140717
Validation loss: 1.5500803262956682

Epoch: 5| Step: 2
Training loss: 0.26679617166519165
Validation loss: 1.5165605134861444

Epoch: 5| Step: 3
Training loss: 0.17852027714252472
Validation loss: 1.5198766339209773

Epoch: 5| Step: 4
Training loss: 0.13258053362369537
Validation loss: 1.5134133074873237

Epoch: 5| Step: 5
Training loss: 0.11898145824670792
Validation loss: 1.5189736773890834

Epoch: 5| Step: 6
Training loss: 0.16524839401245117
Validation loss: 1.5122476803359164

Epoch: 5| Step: 7
Training loss: 0.2755574584007263
Validation loss: 1.5228648980458577

Epoch: 5| Step: 8
Training loss: 0.11505894362926483
Validation loss: 1.5385014754469677

Epoch: 5| Step: 9
Training loss: 0.09179503470659256
Validation loss: 1.540302352238727

Epoch: 5| Step: 10
Training loss: 0.15945914387702942
Validation loss: 1.5669201727836364

Epoch: 346| Step: 0
Training loss: 0.10622632503509521
Validation loss: 1.5366314380399642

Epoch: 5| Step: 1
Training loss: 0.13743215799331665
Validation loss: 1.5684051398308045

Epoch: 5| Step: 2
Training loss: 0.1337464153766632
Validation loss: 1.560371010534225

Epoch: 5| Step: 3
Training loss: 0.13332125544548035
Validation loss: 1.5366016241811937

Epoch: 5| Step: 4
Training loss: 0.13357579708099365
Validation loss: 1.5181310856214134

Epoch: 5| Step: 5
Training loss: 0.11281052976846695
Validation loss: 1.5005341370900471

Epoch: 5| Step: 6
Training loss: 0.1235474944114685
Validation loss: 1.5117943107440908

Epoch: 5| Step: 7
Training loss: 0.2682422399520874
Validation loss: 1.4901681862851626

Epoch: 5| Step: 8
Training loss: 0.15262115001678467
Validation loss: 1.4939141786226662

Epoch: 5| Step: 9
Training loss: 0.29893118143081665
Validation loss: 1.4824050882811188

Epoch: 5| Step: 10
Training loss: 0.11560535430908203
Validation loss: 1.4779882315666444

Epoch: 347| Step: 0
Training loss: 0.30101698637008667
Validation loss: 1.4875849760988706

Epoch: 5| Step: 1
Training loss: 0.10995285212993622
Validation loss: 1.4927253351416638

Epoch: 5| Step: 2
Training loss: 0.1792115867137909
Validation loss: 1.487898548444112

Epoch: 5| Step: 3
Training loss: 0.09982080012559891
Validation loss: 1.5128595764918993

Epoch: 5| Step: 4
Training loss: 0.19396564364433289
Validation loss: 1.5071745713551838

Epoch: 5| Step: 5
Training loss: 0.09268514811992645
Validation loss: 1.5043850098886797

Epoch: 5| Step: 6
Training loss: 0.11856086552143097
Validation loss: 1.5143794782700077

Epoch: 5| Step: 7
Training loss: 0.08818838000297546
Validation loss: 1.5314268476219588

Epoch: 5| Step: 8
Training loss: 0.19913700222969055
Validation loss: 1.5366222179064186

Epoch: 5| Step: 9
Training loss: 0.13933143019676208
Validation loss: 1.561009919771584

Epoch: 5| Step: 10
Training loss: 0.12501280009746552
Validation loss: 1.5489397805224183

Epoch: 348| Step: 0
Training loss: 0.13277044892311096
Validation loss: 1.5630903128654725

Epoch: 5| Step: 1
Training loss: 0.14210540056228638
Validation loss: 1.5496476472065013

Epoch: 5| Step: 2
Training loss: 0.2316972017288208
Validation loss: 1.5472285452709402

Epoch: 5| Step: 3
Training loss: 0.09088415652513504
Validation loss: 1.5206059601999098

Epoch: 5| Step: 4
Training loss: 0.15842361748218536
Validation loss: 1.5255625055682274

Epoch: 5| Step: 5
Training loss: 0.1584409773349762
Validation loss: 1.4955627905425204

Epoch: 5| Step: 6
Training loss: 0.2572108507156372
Validation loss: 1.5035955803368681

Epoch: 5| Step: 7
Training loss: 0.11910378932952881
Validation loss: 1.4887622787106423

Epoch: 5| Step: 8
Training loss: 0.18028470873832703
Validation loss: 1.4904730537886262

Epoch: 5| Step: 9
Training loss: 0.1440459042787552
Validation loss: 1.482625631234979

Epoch: 5| Step: 10
Training loss: 0.11136984080076218
Validation loss: 1.4975618149644585

Epoch: 349| Step: 0
Training loss: 0.19489161670207977
Validation loss: 1.4957838391744962

Epoch: 5| Step: 1
Training loss: 0.13497747480869293
Validation loss: 1.4940031395163587

Epoch: 5| Step: 2
Training loss: 0.1580699235200882
Validation loss: 1.4954189523573844

Epoch: 5| Step: 3
Training loss: 0.26002389192581177
Validation loss: 1.4889196426637712

Epoch: 5| Step: 4
Training loss: 0.12512001395225525
Validation loss: 1.4835195041471911

Epoch: 5| Step: 5
Training loss: 0.3515167832374573
Validation loss: 1.4867293168139715

Epoch: 5| Step: 6
Training loss: 0.09098043292760849
Validation loss: 1.466403422176197

Epoch: 5| Step: 7
Training loss: 0.09406131505966187
Validation loss: 1.4584879093272711

Epoch: 5| Step: 8
Training loss: 0.14572738111019135
Validation loss: 1.485736446995889

Epoch: 5| Step: 9
Training loss: 0.09426388144493103
Validation loss: 1.4751213788986206

Epoch: 5| Step: 10
Training loss: 0.1113119125366211
Validation loss: 1.4720645655867874

Epoch: 350| Step: 0
Training loss: 0.12859617173671722
Validation loss: 1.4698410252089142

Epoch: 5| Step: 1
Training loss: 0.10323633253574371
Validation loss: 1.4945988911454395

Epoch: 5| Step: 2
Training loss: 0.089324451982975
Validation loss: 1.500564258585694

Epoch: 5| Step: 3
Training loss: 0.13933353126049042
Validation loss: 1.5395145236804921

Epoch: 5| Step: 4
Training loss: 0.3614969849586487
Validation loss: 1.5311159292856853

Epoch: 5| Step: 5
Training loss: 0.2257283627986908
Validation loss: 1.5388715215908584

Epoch: 5| Step: 6
Training loss: 0.09535004198551178
Validation loss: 1.5554495902471646

Epoch: 5| Step: 7
Training loss: 0.1698942631483078
Validation loss: 1.5348632700981633

Epoch: 5| Step: 8
Training loss: 0.11076798290014267
Validation loss: 1.5624263081499326

Epoch: 5| Step: 9
Training loss: 0.10520520061254501
Validation loss: 1.5337799146611204

Epoch: 5| Step: 10
Training loss: 0.10631491243839264
Validation loss: 1.5432457244524391

Epoch: 351| Step: 0
Training loss: 0.14259210228919983
Validation loss: 1.5450921584201116

Epoch: 5| Step: 1
Training loss: 0.10914917290210724
Validation loss: 1.5185256459379708

Epoch: 5| Step: 2
Training loss: 0.15393014252185822
Validation loss: 1.4834971517644904

Epoch: 5| Step: 3
Training loss: 0.13412877917289734
Validation loss: 1.495117445145884

Epoch: 5| Step: 4
Training loss: 0.11531589180231094
Validation loss: 1.4620507212095364

Epoch: 5| Step: 5
Training loss: 0.11756972223520279
Validation loss: 1.4750198830840409

Epoch: 5| Step: 6
Training loss: 0.14082950353622437
Validation loss: 1.4920870539962605

Epoch: 5| Step: 7
Training loss: 0.13747236132621765
Validation loss: 1.456900429982011

Epoch: 5| Step: 8
Training loss: 0.190667524933815
Validation loss: 1.4803876940922072

Epoch: 5| Step: 9
Training loss: 0.23828420042991638
Validation loss: 1.4868829122153662

Epoch: 5| Step: 10
Training loss: 0.2679120898246765
Validation loss: 1.5010133302339943

Epoch: 352| Step: 0
Training loss: 0.10681726038455963
Validation loss: 1.4960319470333796

Epoch: 5| Step: 1
Training loss: 0.27647292613983154
Validation loss: 1.4931538797193957

Epoch: 5| Step: 2
Training loss: 0.12880249321460724
Validation loss: 1.5006459912946146

Epoch: 5| Step: 3
Training loss: 0.0797455757856369
Validation loss: 1.4883099473932737

Epoch: 5| Step: 4
Training loss: 0.12429580837488174
Validation loss: 1.5106956458860827

Epoch: 5| Step: 5
Training loss: 0.1617569476366043
Validation loss: 1.5065904189181585

Epoch: 5| Step: 6
Training loss: 0.13726384937763214
Validation loss: 1.5327677995927873

Epoch: 5| Step: 7
Training loss: 0.29106709361076355
Validation loss: 1.516495302159299

Epoch: 5| Step: 8
Training loss: 0.12132184207439423
Validation loss: 1.526797850926717

Epoch: 5| Step: 9
Training loss: 0.12320214509963989
Validation loss: 1.529649608878679

Epoch: 5| Step: 10
Training loss: 0.10958006978034973
Validation loss: 1.5439601508519982

Epoch: 353| Step: 0
Training loss: 0.07115880399942398
Validation loss: 1.5356616076602732

Epoch: 5| Step: 1
Training loss: 0.1647455245256424
Validation loss: 1.5392397193498508

Epoch: 5| Step: 2
Training loss: 0.12113859504461288
Validation loss: 1.5383473852629304

Epoch: 5| Step: 3
Training loss: 0.12514440715312958
Validation loss: 1.5150710882679108

Epoch: 5| Step: 4
Training loss: 0.281582772731781
Validation loss: 1.5239084946211947

Epoch: 5| Step: 5
Training loss: 0.08586423099040985
Validation loss: 1.5097007623282812

Epoch: 5| Step: 6
Training loss: 0.19302506744861603
Validation loss: 1.47716861514635

Epoch: 5| Step: 7
Training loss: 0.1897946298122406
Validation loss: 1.4798577511182396

Epoch: 5| Step: 8
Training loss: 0.12458240985870361
Validation loss: 1.466367519030007

Epoch: 5| Step: 9
Training loss: 0.13107874989509583
Validation loss: 1.4449235495700632

Epoch: 5| Step: 10
Training loss: 0.0785527378320694
Validation loss: 1.4548351854406378

Epoch: 354| Step: 0
Training loss: 0.24864229559898376
Validation loss: 1.4620922124514015

Epoch: 5| Step: 1
Training loss: 0.16852185130119324
Validation loss: 1.43333803197389

Epoch: 5| Step: 2
Training loss: 0.1245655044913292
Validation loss: 1.4491570277880597

Epoch: 5| Step: 3
Training loss: 0.07842793315649033
Validation loss: 1.4773734782331733

Epoch: 5| Step: 4
Training loss: 0.2513499855995178
Validation loss: 1.472465972746572

Epoch: 5| Step: 5
Training loss: 0.15484103560447693
Validation loss: 1.5100861198158675

Epoch: 5| Step: 6
Training loss: 0.08304063230752945
Validation loss: 1.4851475287509222

Epoch: 5| Step: 7
Training loss: 0.11839894950389862
Validation loss: 1.453707347634018

Epoch: 5| Step: 8
Training loss: 0.07683798670768738
Validation loss: 1.4790298874660204

Epoch: 5| Step: 9
Training loss: 0.16016273200511932
Validation loss: 1.4867131658779678

Epoch: 5| Step: 10
Training loss: 0.15342317521572113
Validation loss: 1.4887580153762654

Epoch: 355| Step: 0
Training loss: 0.2525753378868103
Validation loss: 1.5341521463086527

Epoch: 5| Step: 1
Training loss: 0.1325417459011078
Validation loss: 1.5313326248558619

Epoch: 5| Step: 2
Training loss: 0.14990127086639404
Validation loss: 1.5596433140898263

Epoch: 5| Step: 3
Training loss: 0.14021870493888855
Validation loss: 1.5085973611441992

Epoch: 5| Step: 4
Training loss: 0.09630034863948822
Validation loss: 1.5230007991995862

Epoch: 5| Step: 5
Training loss: 0.2020752876996994
Validation loss: 1.4981585151405745

Epoch: 5| Step: 6
Training loss: 0.09400329738855362
Validation loss: 1.5002463575332396

Epoch: 5| Step: 7
Training loss: 0.10341998189687729
Validation loss: 1.4712550704197218

Epoch: 5| Step: 8
Training loss: 0.15112599730491638
Validation loss: 1.483633807910386

Epoch: 5| Step: 9
Training loss: 0.1156376376748085
Validation loss: 1.4969299890661751

Epoch: 5| Step: 10
Training loss: 0.23934723436832428
Validation loss: 1.4876291392951884

Epoch: 356| Step: 0
Training loss: 0.14908958971500397
Validation loss: 1.5000684799686554

Epoch: 5| Step: 1
Training loss: 0.14450296759605408
Validation loss: 1.493648293197796

Epoch: 5| Step: 2
Training loss: 0.15017418563365936
Validation loss: 1.4809829124840357

Epoch: 5| Step: 3
Training loss: 0.148654505610466
Validation loss: 1.531541754481613

Epoch: 5| Step: 4
Training loss: 0.11450369656085968
Validation loss: 1.5447932699675202

Epoch: 5| Step: 5
Training loss: 0.19717925786972046
Validation loss: 1.5477209052731913

Epoch: 5| Step: 6
Training loss: 0.13807156682014465
Validation loss: 1.54492066496162

Epoch: 5| Step: 7
Training loss: 0.14293010532855988
Validation loss: 1.5581440361597205

Epoch: 5| Step: 8
Training loss: 0.0905681699514389
Validation loss: 1.5643002499816239

Epoch: 5| Step: 9
Training loss: 0.13271115720272064
Validation loss: 1.5547730634289403

Epoch: 5| Step: 10
Training loss: 0.21999222040176392
Validation loss: 1.5488408586030364

Epoch: 357| Step: 0
Training loss: 0.09789352864027023
Validation loss: 1.5402903582460137

Epoch: 5| Step: 1
Training loss: 0.07310304790735245
Validation loss: 1.504513627739363

Epoch: 5| Step: 2
Training loss: 0.07847657054662704
Validation loss: 1.5082414855239212

Epoch: 5| Step: 3
Training loss: 0.15544171631336212
Validation loss: 1.5087854323848602

Epoch: 5| Step: 4
Training loss: 0.10363553464412689
Validation loss: 1.5146650704004432

Epoch: 5| Step: 5
Training loss: 0.12785670161247253
Validation loss: 1.4910393158594768

Epoch: 5| Step: 6
Training loss: 0.21879379451274872
Validation loss: 1.4744093892394856

Epoch: 5| Step: 7
Training loss: 0.1621313989162445
Validation loss: 1.4736673780666885

Epoch: 5| Step: 8
Training loss: 0.1509535014629364
Validation loss: 1.4711840985923685

Epoch: 5| Step: 9
Training loss: 0.30938488245010376
Validation loss: 1.484169985658379

Epoch: 5| Step: 10
Training loss: 0.31878721714019775
Validation loss: 1.4809637005611131

Epoch: 358| Step: 0
Training loss: 0.24807319045066833
Validation loss: 1.5152807979173557

Epoch: 5| Step: 1
Training loss: 0.1430635154247284
Validation loss: 1.5017577877608679

Epoch: 5| Step: 2
Training loss: 0.07830049842596054
Validation loss: 1.5037048939735658

Epoch: 5| Step: 3
Training loss: 0.1958005130290985
Validation loss: 1.4873332797840078

Epoch: 5| Step: 4
Training loss: 0.11933921277523041
Validation loss: 1.4945688081044022

Epoch: 5| Step: 5
Training loss: 0.07125718891620636
Validation loss: 1.4916458027337187

Epoch: 5| Step: 6
Training loss: 0.264315664768219
Validation loss: 1.5039401720928889

Epoch: 5| Step: 7
Training loss: 0.1422424167394638
Validation loss: 1.529591542418285

Epoch: 5| Step: 8
Training loss: 0.11478426307439804
Validation loss: 1.4880696906838367

Epoch: 5| Step: 9
Training loss: 0.11681418120861053
Validation loss: 1.5009876784457956

Epoch: 5| Step: 10
Training loss: 0.1402367353439331
Validation loss: 1.5166892531097576

Epoch: 359| Step: 0
Training loss: 0.0834575742483139
Validation loss: 1.5088892136850665

Epoch: 5| Step: 1
Training loss: 0.14536388218402863
Validation loss: 1.4888901236236736

Epoch: 5| Step: 2
Training loss: 0.19783903658390045
Validation loss: 1.5069101830964446

Epoch: 5| Step: 3
Training loss: 0.2343892753124237
Validation loss: 1.4995844940985403

Epoch: 5| Step: 4
Training loss: 0.14462658762931824
Validation loss: 1.4541254505034416

Epoch: 5| Step: 5
Training loss: 0.14885561168193817
Validation loss: 1.4960873870439426

Epoch: 5| Step: 6
Training loss: 0.1144116073846817
Validation loss: 1.482562013851699

Epoch: 5| Step: 7
Training loss: 0.13829252123832703
Validation loss: 1.5058729674226494

Epoch: 5| Step: 8
Training loss: 0.31780919432640076
Validation loss: 1.4915701663622292

Epoch: 5| Step: 9
Training loss: 0.17866463959217072
Validation loss: 1.4904330045946184

Epoch: 5| Step: 10
Training loss: 0.08586970716714859
Validation loss: 1.4769098284423992

Epoch: 360| Step: 0
Training loss: 0.17087623476982117
Validation loss: 1.4702208836873372

Epoch: 5| Step: 1
Training loss: 0.10690176486968994
Validation loss: 1.4968914767747283

Epoch: 5| Step: 2
Training loss: 0.19394072890281677
Validation loss: 1.4978082718387726

Epoch: 5| Step: 3
Training loss: 0.23416399955749512
Validation loss: 1.5443664648199593

Epoch: 5| Step: 4
Training loss: 0.1831893026828766
Validation loss: 1.5437899840775358

Epoch: 5| Step: 5
Training loss: 0.16137751936912537
Validation loss: 1.5511340454060545

Epoch: 5| Step: 6
Training loss: 0.15813493728637695
Validation loss: 1.5356333037858367

Epoch: 5| Step: 7
Training loss: 0.11979415267705917
Validation loss: 1.5379736051764539

Epoch: 5| Step: 8
Training loss: 0.08822346478700638
Validation loss: 1.5173203304249754

Epoch: 5| Step: 9
Training loss: 0.12453939765691757
Validation loss: 1.488189479356171

Epoch: 5| Step: 10
Training loss: 0.12194103002548218
Validation loss: 1.5007856276727491

Epoch: 361| Step: 0
Training loss: 0.18066884577274323
Validation loss: 1.4776113917750697

Epoch: 5| Step: 1
Training loss: 0.14461371302604675
Validation loss: 1.4760141039407382

Epoch: 5| Step: 2
Training loss: 0.11407022178173065
Validation loss: 1.4728691898366457

Epoch: 5| Step: 3
Training loss: 0.20484991371631622
Validation loss: 1.4621968243711738

Epoch: 5| Step: 4
Training loss: 0.12641993165016174
Validation loss: 1.4976939206482263

Epoch: 5| Step: 5
Training loss: 0.11200232803821564
Validation loss: 1.5010324928068346

Epoch: 5| Step: 6
Training loss: 0.11720530688762665
Validation loss: 1.5223131231082383

Epoch: 5| Step: 7
Training loss: 0.11509380489587784
Validation loss: 1.5311631169370425

Epoch: 5| Step: 8
Training loss: 0.11584937572479248
Validation loss: 1.507576532261346

Epoch: 5| Step: 9
Training loss: 0.229280024766922
Validation loss: 1.522740614029669

Epoch: 5| Step: 10
Training loss: 0.30568063259124756
Validation loss: 1.5202951597911056

Epoch: 362| Step: 0
Training loss: 0.15000005066394806
Validation loss: 1.5396342559527325

Epoch: 5| Step: 1
Training loss: 0.12735378742218018
Validation loss: 1.532080493947511

Epoch: 5| Step: 2
Training loss: 0.24687185883522034
Validation loss: 1.5302743930970468

Epoch: 5| Step: 3
Training loss: 0.13184727728366852
Validation loss: 1.542382913251077

Epoch: 5| Step: 4
Training loss: 0.08721357583999634
Validation loss: 1.5134948543322984

Epoch: 5| Step: 5
Training loss: 0.11876679956912994
Validation loss: 1.5131541836646296

Epoch: 5| Step: 6
Training loss: 0.15886320173740387
Validation loss: 1.530334557256391

Epoch: 5| Step: 7
Training loss: 0.22848322987556458
Validation loss: 1.5295516175608481

Epoch: 5| Step: 8
Training loss: 0.1612507849931717
Validation loss: 1.5228925981829244

Epoch: 5| Step: 9
Training loss: 0.1538439691066742
Validation loss: 1.537061861766282

Epoch: 5| Step: 10
Training loss: 0.12767699360847473
Validation loss: 1.5207477038906467

Epoch: 363| Step: 0
Training loss: 0.22032484412193298
Validation loss: 1.5104664551314486

Epoch: 5| Step: 1
Training loss: 0.14153581857681274
Validation loss: 1.4744619272088493

Epoch: 5| Step: 2
Training loss: 0.2334281951189041
Validation loss: 1.5288108112991496

Epoch: 5| Step: 3
Training loss: 0.1826164871454239
Validation loss: 1.5265836997698712

Epoch: 5| Step: 4
Training loss: 0.08480657637119293
Validation loss: 1.492591783564578

Epoch: 5| Step: 5
Training loss: 0.10797439515590668
Validation loss: 1.5121040087874218

Epoch: 5| Step: 6
Training loss: 0.15158624947071075
Validation loss: 1.5061374710452171

Epoch: 5| Step: 7
Training loss: 0.11528034508228302
Validation loss: 1.472519314417275

Epoch: 5| Step: 8
Training loss: 0.16166549921035767
Validation loss: 1.5209265678159651

Epoch: 5| Step: 9
Training loss: 0.1756880134344101
Validation loss: 1.494042590100278

Epoch: 5| Step: 10
Training loss: 0.127305805683136
Validation loss: 1.5236793794939596

Epoch: 364| Step: 0
Training loss: 0.13080474734306335
Validation loss: 1.4950259949571343

Epoch: 5| Step: 1
Training loss: 0.36695200204849243
Validation loss: 1.5384725498896774

Epoch: 5| Step: 2
Training loss: 0.20015382766723633
Validation loss: 1.5277256055544781

Epoch: 5| Step: 3
Training loss: 0.10683629661798477
Validation loss: 1.5451943207812566

Epoch: 5| Step: 4
Training loss: 0.1046251431107521
Validation loss: 1.5410916779630928

Epoch: 5| Step: 5
Training loss: 0.09614820778369904
Validation loss: 1.5576884797824326

Epoch: 5| Step: 6
Training loss: 0.088809072971344
Validation loss: 1.5334412038967173

Epoch: 5| Step: 7
Training loss: 0.1417407989501953
Validation loss: 1.537408491616608

Epoch: 5| Step: 8
Training loss: 0.10707004368305206
Validation loss: 1.5536767077702347

Epoch: 5| Step: 9
Training loss: 0.08630955219268799
Validation loss: 1.5296014021801692

Epoch: 5| Step: 10
Training loss: 0.08249525725841522
Validation loss: 1.5121419442597257

Epoch: 365| Step: 0
Training loss: 0.08503061532974243
Validation loss: 1.5149461671870241

Epoch: 5| Step: 1
Training loss: 0.09184642136096954
Validation loss: 1.5099486638140935

Epoch: 5| Step: 2
Training loss: 0.11870186030864716
Validation loss: 1.5222651958465576

Epoch: 5| Step: 3
Training loss: 0.08512433618307114
Validation loss: 1.5255275349463187

Epoch: 5| Step: 4
Training loss: 0.12535840272903442
Validation loss: 1.4992513284888318

Epoch: 5| Step: 5
Training loss: 0.1671534776687622
Validation loss: 1.4777619813078193

Epoch: 5| Step: 6
Training loss: 0.08855439722537994
Validation loss: 1.493759165528

Epoch: 5| Step: 7
Training loss: 0.23076513409614563
Validation loss: 1.48388320912597

Epoch: 5| Step: 8
Training loss: 0.15395690500736237
Validation loss: 1.4898443106682069

Epoch: 5| Step: 9
Training loss: 0.15063194930553436
Validation loss: 1.4833868210033705

Epoch: 5| Step: 10
Training loss: 0.2777317762374878
Validation loss: 1.501179604120152

Epoch: 366| Step: 0
Training loss: 0.12609627842903137
Validation loss: 1.5247581697279406

Epoch: 5| Step: 1
Training loss: 0.0981486439704895
Validation loss: 1.5089457957975325

Epoch: 5| Step: 2
Training loss: 0.11861623823642731
Validation loss: 1.4927890300750732

Epoch: 5| Step: 3
Training loss: 0.2380521297454834
Validation loss: 1.5288722169014715

Epoch: 5| Step: 4
Training loss: 0.0998697429895401
Validation loss: 1.52050874053791

Epoch: 5| Step: 5
Training loss: 0.10855736583471298
Validation loss: 1.5154573481570008

Epoch: 5| Step: 6
Training loss: 0.11393876373767853
Validation loss: 1.52457469765858

Epoch: 5| Step: 7
Training loss: 0.1960132122039795
Validation loss: 1.5245284867543045

Epoch: 5| Step: 8
Training loss: 0.08465000241994858
Validation loss: 1.532528183793509

Epoch: 5| Step: 9
Training loss: 0.2535136342048645
Validation loss: 1.5266133764738679

Epoch: 5| Step: 10
Training loss: 0.1048966571688652
Validation loss: 1.5398708158923733

Epoch: 367| Step: 0
Training loss: 0.12496522814035416
Validation loss: 1.5458323096716275

Epoch: 5| Step: 1
Training loss: 0.16482149064540863
Validation loss: 1.5307997593315699

Epoch: 5| Step: 2
Training loss: 0.1270308494567871
Validation loss: 1.5392302710522887

Epoch: 5| Step: 3
Training loss: 0.19441011548042297
Validation loss: 1.5151952697384743

Epoch: 5| Step: 4
Training loss: 0.2423500120639801
Validation loss: 1.5218722833100187

Epoch: 5| Step: 5
Training loss: 0.1069013699889183
Validation loss: 1.4894908266041869

Epoch: 5| Step: 6
Training loss: 0.08760569989681244
Validation loss: 1.5009889589842929

Epoch: 5| Step: 7
Training loss: 0.1054845079779625
Validation loss: 1.500184080934012

Epoch: 5| Step: 8
Training loss: 0.10842375457286835
Validation loss: 1.5044154338939215

Epoch: 5| Step: 9
Training loss: 0.18689969182014465
Validation loss: 1.484131913031301

Epoch: 5| Step: 10
Training loss: 0.18222293257713318
Validation loss: 1.4978484017874605

Epoch: 368| Step: 0
Training loss: 0.09386871010065079
Validation loss: 1.486869788938953

Epoch: 5| Step: 1
Training loss: 0.11574218422174454
Validation loss: 1.4841720455436296

Epoch: 5| Step: 2
Training loss: 0.11803843080997467
Validation loss: 1.5216559287040465

Epoch: 5| Step: 3
Training loss: 0.11266245692968369
Validation loss: 1.5026621260950643

Epoch: 5| Step: 4
Training loss: 0.07529378682374954
Validation loss: 1.5203381546082035

Epoch: 5| Step: 5
Training loss: 0.09991536289453506
Validation loss: 1.516319856848768

Epoch: 5| Step: 6
Training loss: 0.26612967252731323
Validation loss: 1.5246810784903906

Epoch: 5| Step: 7
Training loss: 0.20634129643440247
Validation loss: 1.5361500991288053

Epoch: 5| Step: 8
Training loss: 0.19730594754219055
Validation loss: 1.5315387466902375

Epoch: 5| Step: 9
Training loss: 0.1509920358657837
Validation loss: 1.5252485441905197

Epoch: 5| Step: 10
Training loss: 0.1839737445116043
Validation loss: 1.5187709754513157

Epoch: 369| Step: 0
Training loss: 0.07203913480043411
Validation loss: 1.5078048808600313

Epoch: 5| Step: 1
Training loss: 0.12313312292098999
Validation loss: 1.5417745228736632

Epoch: 5| Step: 2
Training loss: 0.1634918749332428
Validation loss: 1.5160074951828166

Epoch: 5| Step: 3
Training loss: 0.08907879889011383
Validation loss: 1.501204248397581

Epoch: 5| Step: 4
Training loss: 0.131648987531662
Validation loss: 1.5176560199388893

Epoch: 5| Step: 5
Training loss: 0.24151651561260223
Validation loss: 1.5092564872516099

Epoch: 5| Step: 6
Training loss: 0.12506024539470673
Validation loss: 1.4839810978981756

Epoch: 5| Step: 7
Training loss: 0.12866882979869843
Validation loss: 1.5007499430769233

Epoch: 5| Step: 8
Training loss: 0.28088679909706116
Validation loss: 1.5093077972371092

Epoch: 5| Step: 9
Training loss: 0.11423619836568832
Validation loss: 1.5010438811394475

Epoch: 5| Step: 10
Training loss: 0.07735180854797363
Validation loss: 1.4828266571926814

Epoch: 370| Step: 0
Training loss: 0.1541602611541748
Validation loss: 1.4754165910905408

Epoch: 5| Step: 1
Training loss: 0.22846703231334686
Validation loss: 1.471948339093116

Epoch: 5| Step: 2
Training loss: 0.2547188401222229
Validation loss: 1.4667296255788496

Epoch: 5| Step: 3
Training loss: 0.0839909091591835
Validation loss: 1.4541661457348896

Epoch: 5| Step: 4
Training loss: 0.11731879413127899
Validation loss: 1.4513032026188348

Epoch: 5| Step: 5
Training loss: 0.058987073600292206
Validation loss: 1.4848555544371247

Epoch: 5| Step: 6
Training loss: 0.16598519682884216
Validation loss: 1.5012475444424538

Epoch: 5| Step: 7
Training loss: 0.09571100771427155
Validation loss: 1.5128696656996203

Epoch: 5| Step: 8
Training loss: 0.10907330363988876
Validation loss: 1.5289138606799546

Epoch: 5| Step: 9
Training loss: 0.15148451924324036
Validation loss: 1.5274831851323445

Epoch: 5| Step: 10
Training loss: 0.12382981181144714
Validation loss: 1.5509555839723157

Epoch: 371| Step: 0
Training loss: 0.09756583720445633
Validation loss: 1.5683416756250526

Epoch: 5| Step: 1
Training loss: 0.10970120131969452
Validation loss: 1.5538024588297772

Epoch: 5| Step: 2
Training loss: 0.13741561770439148
Validation loss: 1.547435664361523

Epoch: 5| Step: 3
Training loss: 0.25954151153564453
Validation loss: 1.5450545075119182

Epoch: 5| Step: 4
Training loss: 0.09646807610988617
Validation loss: 1.5179528933699413

Epoch: 5| Step: 5
Training loss: 0.1531239151954651
Validation loss: 1.5204522263619207

Epoch: 5| Step: 6
Training loss: 0.06760448217391968
Validation loss: 1.492732797899554

Epoch: 5| Step: 7
Training loss: 0.21933798491954803
Validation loss: 1.4767717430668492

Epoch: 5| Step: 8
Training loss: 0.13521143794059753
Validation loss: 1.5188952594675043

Epoch: 5| Step: 9
Training loss: 0.1781809777021408
Validation loss: 1.4890239392557452

Epoch: 5| Step: 10
Training loss: 0.14088734984397888
Validation loss: 1.4869858616141862

Epoch: 372| Step: 0
Training loss: 0.130939781665802
Validation loss: 1.4912676772763651

Epoch: 5| Step: 1
Training loss: 0.1230904832482338
Validation loss: 1.480895257765247

Epoch: 5| Step: 2
Training loss: 0.0820089802145958
Validation loss: 1.4691203640353294

Epoch: 5| Step: 3
Training loss: 0.21432900428771973
Validation loss: 1.508740863492412

Epoch: 5| Step: 4
Training loss: 0.13287219405174255
Validation loss: 1.5108566386725313

Epoch: 5| Step: 5
Training loss: 0.11135728657245636
Validation loss: 1.5635898369614796

Epoch: 5| Step: 6
Training loss: 0.15835630893707275
Validation loss: 1.546016945633837

Epoch: 5| Step: 7
Training loss: 0.23650458455085754
Validation loss: 1.5558559792016142

Epoch: 5| Step: 8
Training loss: 0.11913621425628662
Validation loss: 1.5411580083190755

Epoch: 5| Step: 9
Training loss: 0.10422620922327042
Validation loss: 1.5280702806288196

Epoch: 5| Step: 10
Training loss: 0.11135926842689514
Validation loss: 1.511231077614651

Epoch: 373| Step: 0
Training loss: 0.0968189686536789
Validation loss: 1.509790200059132

Epoch: 5| Step: 1
Training loss: 0.12153496593236923
Validation loss: 1.534024961533085

Epoch: 5| Step: 2
Training loss: 0.1911579817533493
Validation loss: 1.5121127328565043

Epoch: 5| Step: 3
Training loss: 0.12309134006500244
Validation loss: 1.525484501674611

Epoch: 5| Step: 4
Training loss: 0.08816242963075638
Validation loss: 1.5381817907415412

Epoch: 5| Step: 5
Training loss: 0.09053157269954681
Validation loss: 1.5342012554086664

Epoch: 5| Step: 6
Training loss: 0.08886955678462982
Validation loss: 1.5100939235379618

Epoch: 5| Step: 7
Training loss: 0.1227530688047409
Validation loss: 1.526680088812305

Epoch: 5| Step: 8
Training loss: 0.14834369719028473
Validation loss: 1.548990644434447

Epoch: 5| Step: 9
Training loss: 0.11390892416238785
Validation loss: 1.5289413518803094

Epoch: 5| Step: 10
Training loss: 0.27600035071372986
Validation loss: 1.5438234472787509

Epoch: 374| Step: 0
Training loss: 0.15895138680934906
Validation loss: 1.5158206301350747

Epoch: 5| Step: 1
Training loss: 0.07375411689281464
Validation loss: 1.5337399757036598

Epoch: 5| Step: 2
Training loss: 0.11486096680164337
Validation loss: 1.5496541441127818

Epoch: 5| Step: 3
Training loss: 0.09816266596317291
Validation loss: 1.5079891130488405

Epoch: 5| Step: 4
Training loss: 0.22771266102790833
Validation loss: 1.5206055833447365

Epoch: 5| Step: 5
Training loss: 0.10099363327026367
Validation loss: 1.5168630000083678

Epoch: 5| Step: 6
Training loss: 0.14032182097434998
Validation loss: 1.4986749797739007

Epoch: 5| Step: 7
Training loss: 0.09260819852352142
Validation loss: 1.4909516021769533

Epoch: 5| Step: 8
Training loss: 0.220821812748909
Validation loss: 1.5152959310880272

Epoch: 5| Step: 9
Training loss: 0.08974245935678482
Validation loss: 1.4972249077212425

Epoch: 5| Step: 10
Training loss: 0.08204802870750427
Validation loss: 1.4871377432218162

Epoch: 375| Step: 0
Training loss: 0.10338596999645233
Validation loss: 1.4810768455587409

Epoch: 5| Step: 1
Training loss: 0.11338156461715698
Validation loss: 1.501151333573044

Epoch: 5| Step: 2
Training loss: 0.0863364189863205
Validation loss: 1.4976448166754939

Epoch: 5| Step: 3
Training loss: 0.138109490275383
Validation loss: 1.4915800786787463

Epoch: 5| Step: 4
Training loss: 0.26218655705451965
Validation loss: 1.5147465768680777

Epoch: 5| Step: 5
Training loss: 0.08244528621435165
Validation loss: 1.5133801993503366

Epoch: 5| Step: 6
Training loss: 0.25255483388900757
Validation loss: 1.5034124229543953

Epoch: 5| Step: 7
Training loss: 0.08349712938070297
Validation loss: 1.5128408349970335

Epoch: 5| Step: 8
Training loss: 0.09033286571502686
Validation loss: 1.517509388667281

Epoch: 5| Step: 9
Training loss: 0.07935614883899689
Validation loss: 1.526627630315801

Epoch: 5| Step: 10
Training loss: 0.08859346061944962
Validation loss: 1.5438099022834533

Epoch: 376| Step: 0
Training loss: 0.09655115753412247
Validation loss: 1.5262156635202386

Epoch: 5| Step: 1
Training loss: 0.08521230518817902
Validation loss: 1.5356069322555297

Epoch: 5| Step: 2
Training loss: 0.08377522230148315
Validation loss: 1.5358316923982354

Epoch: 5| Step: 3
Training loss: 0.26491326093673706
Validation loss: 1.5148263182691348

Epoch: 5| Step: 4
Training loss: 0.1256297379732132
Validation loss: 1.5082727427123694

Epoch: 5| Step: 5
Training loss: 0.23161013424396515
Validation loss: 1.508004334665114

Epoch: 5| Step: 6
Training loss: 0.13683763146400452
Validation loss: 1.4976744459521385

Epoch: 5| Step: 7
Training loss: 0.10138630867004395
Validation loss: 1.4848043469972507

Epoch: 5| Step: 8
Training loss: 0.09986691921949387
Validation loss: 1.4696435184888943

Epoch: 5| Step: 9
Training loss: 0.0929039791226387
Validation loss: 1.4731959835175545

Epoch: 5| Step: 10
Training loss: 0.08234251290559769
Validation loss: 1.485358912457702

Epoch: 377| Step: 0
Training loss: 0.08433873951435089
Validation loss: 1.4941002233054048

Epoch: 5| Step: 1
Training loss: 0.3386412262916565
Validation loss: 1.5274342061370931

Epoch: 5| Step: 2
Training loss: 0.11092269420623779
Validation loss: 1.5197234704930296

Epoch: 5| Step: 3
Training loss: 0.10091147571802139
Validation loss: 1.5211145852201728

Epoch: 5| Step: 4
Training loss: 0.07917721569538116
Validation loss: 1.5114707510958436

Epoch: 5| Step: 5
Training loss: 0.1290891319513321
Validation loss: 1.541686442590529

Epoch: 5| Step: 6
Training loss: 0.09431058168411255
Validation loss: 1.5556305563578041

Epoch: 5| Step: 7
Training loss: 0.09921108931303024
Validation loss: 1.5494546294212341

Epoch: 5| Step: 8
Training loss: 0.1355181634426117
Validation loss: 1.5166821672070412

Epoch: 5| Step: 9
Training loss: 0.139613538980484
Validation loss: 1.5177678779889179

Epoch: 5| Step: 10
Training loss: 0.07043206691741943
Validation loss: 1.517167829698132

Epoch: 378| Step: 0
Training loss: 0.08202417194843292
Validation loss: 1.5169557704720447

Epoch: 5| Step: 1
Training loss: 0.2028118073940277
Validation loss: 1.5149092007708806

Epoch: 5| Step: 2
Training loss: 0.20360243320465088
Validation loss: 1.5052205907401217

Epoch: 5| Step: 3
Training loss: 0.08159799873828888
Validation loss: 1.5098119679317679

Epoch: 5| Step: 4
Training loss: 0.0909685492515564
Validation loss: 1.5107032739987938

Epoch: 5| Step: 5
Training loss: 0.06927106529474258
Validation loss: 1.5186342411143805

Epoch: 5| Step: 6
Training loss: 0.09814385324716568
Validation loss: 1.4954082017303796

Epoch: 5| Step: 7
Training loss: 0.1539078950881958
Validation loss: 1.5126319572489748

Epoch: 5| Step: 8
Training loss: 0.062039755284786224
Validation loss: 1.4922420683727469

Epoch: 5| Step: 9
Training loss: 0.10247267782688141
Validation loss: 1.5143482608179892

Epoch: 5| Step: 10
Training loss: 0.14617551863193512
Validation loss: 1.5405030083912674

Epoch: 379| Step: 0
Training loss: 0.07460757344961166
Validation loss: 1.5153509942434167

Epoch: 5| Step: 1
Training loss: 0.09633606672286987
Validation loss: 1.5093101711683377

Epoch: 5| Step: 2
Training loss: 0.15521283447742462
Validation loss: 1.5281573303284184

Epoch: 5| Step: 3
Training loss: 0.2514503598213196
Validation loss: 1.5186237750514862

Epoch: 5| Step: 4
Training loss: 0.10920989513397217
Validation loss: 1.5531027611865793

Epoch: 5| Step: 5
Training loss: 0.06156247854232788
Validation loss: 1.530854723786795

Epoch: 5| Step: 6
Training loss: 0.046764954924583435
Validation loss: 1.533337244423487

Epoch: 5| Step: 7
Training loss: 0.05342620611190796
Validation loss: 1.5110404350424325

Epoch: 5| Step: 8
Training loss: 0.09883781522512436
Validation loss: 1.499638408742925

Epoch: 5| Step: 9
Training loss: 0.22269852459430695
Validation loss: 1.4943037443263556

Epoch: 5| Step: 10
Training loss: 0.14943964779376984
Validation loss: 1.4753922864954958

Epoch: 380| Step: 0
Training loss: 0.23672690987586975
Validation loss: 1.4730472846697735

Epoch: 5| Step: 1
Training loss: 0.11921589076519012
Validation loss: 1.4563274960364065

Epoch: 5| Step: 2
Training loss: 0.09691313654184341
Validation loss: 1.4645786490491641

Epoch: 5| Step: 3
Training loss: 0.07694023102521896
Validation loss: 1.448716167480715

Epoch: 5| Step: 4
Training loss: 0.07411521673202515
Validation loss: 1.44893140433937

Epoch: 5| Step: 5
Training loss: 0.15784092247486115
Validation loss: 1.4726791689472813

Epoch: 5| Step: 6
Training loss: 0.2019893378019333
Validation loss: 1.4479106369838919

Epoch: 5| Step: 7
Training loss: 0.1525822877883911
Validation loss: 1.4897960808969313

Epoch: 5| Step: 8
Training loss: 0.0702938586473465
Validation loss: 1.5132348998900382

Epoch: 5| Step: 9
Training loss: 0.0726127177476883
Validation loss: 1.4831467995079615

Epoch: 5| Step: 10
Training loss: 0.0843358263373375
Validation loss: 1.4916299517436693

Epoch: 381| Step: 0
Training loss: 0.08261618763208389
Validation loss: 1.4804953875080231

Epoch: 5| Step: 1
Training loss: 0.06301450729370117
Validation loss: 1.5184335195890037

Epoch: 5| Step: 2
Training loss: 0.10719764232635498
Validation loss: 1.4971687934731925

Epoch: 5| Step: 3
Training loss: 0.20475201308727264
Validation loss: 1.492254966048784

Epoch: 5| Step: 4
Training loss: 0.04796421900391579
Validation loss: 1.491998452012257

Epoch: 5| Step: 5
Training loss: 0.07947604358196259
Validation loss: 1.5126425117574713

Epoch: 5| Step: 6
Training loss: 0.2020796835422516
Validation loss: 1.5167635704881401

Epoch: 5| Step: 7
Training loss: 0.16683772206306458
Validation loss: 1.514666001001994

Epoch: 5| Step: 8
Training loss: 0.08935953676700592
Validation loss: 1.4927321057165823

Epoch: 5| Step: 9
Training loss: 0.08636001497507095
Validation loss: 1.4931228160858154

Epoch: 5| Step: 10
Training loss: 0.07050786167383194
Validation loss: 1.5038643178119455

Epoch: 382| Step: 0
Training loss: 0.21192479133605957
Validation loss: 1.5212370067514398

Epoch: 5| Step: 1
Training loss: 0.14140982925891876
Validation loss: 1.5310367294537124

Epoch: 5| Step: 2
Training loss: 0.05340008810162544
Validation loss: 1.528571436482091

Epoch: 5| Step: 3
Training loss: 0.07484445720911026
Validation loss: 1.5485655056532992

Epoch: 5| Step: 4
Training loss: 0.06894214451313019
Validation loss: 1.5221674916564778

Epoch: 5| Step: 5
Training loss: 0.0758446678519249
Validation loss: 1.5256089215637536

Epoch: 5| Step: 6
Training loss: 0.058299534022808075
Validation loss: 1.499710734172534

Epoch: 5| Step: 7
Training loss: 0.10752759128808975
Validation loss: 1.5107674066738417

Epoch: 5| Step: 8
Training loss: 0.2740473747253418
Validation loss: 1.499819081316712

Epoch: 5| Step: 9
Training loss: 0.13486704230308533
Validation loss: 1.4751824666095037

Epoch: 5| Step: 10
Training loss: 0.10629642009735107
Validation loss: 1.4710374660389398

Epoch: 383| Step: 0
Training loss: 0.3130509555339813
Validation loss: 1.4775627556667532

Epoch: 5| Step: 1
Training loss: 0.15182313323020935
Validation loss: 1.4910391261500697

Epoch: 5| Step: 2
Training loss: 0.08792088180780411
Validation loss: 1.4863998607922626

Epoch: 5| Step: 3
Training loss: 0.08226045966148376
Validation loss: 1.4950125089255712

Epoch: 5| Step: 4
Training loss: 0.04460253193974495
Validation loss: 1.4832701862499278

Epoch: 5| Step: 5
Training loss: 0.05216662213206291
Validation loss: 1.5243036849524385

Epoch: 5| Step: 6
Training loss: 0.09097031503915787
Validation loss: 1.5137294864141813

Epoch: 5| Step: 7
Training loss: 0.1412697732448578
Validation loss: 1.5443062243923065

Epoch: 5| Step: 8
Training loss: 0.11046941578388214
Validation loss: 1.5355428841806227

Epoch: 5| Step: 9
Training loss: 0.10436101257801056
Validation loss: 1.5291943665473693

Epoch: 5| Step: 10
Training loss: 0.06608609855175018
Validation loss: 1.537133361703606

Epoch: 384| Step: 0
Training loss: 0.0891776829957962
Validation loss: 1.5092784473972936

Epoch: 5| Step: 1
Training loss: 0.07876331359148026
Validation loss: 1.5144643886114961

Epoch: 5| Step: 2
Training loss: 0.11720962822437286
Validation loss: 1.523002855239376

Epoch: 5| Step: 3
Training loss: 0.13665075600147247
Validation loss: 1.4884470432035384

Epoch: 5| Step: 4
Training loss: 0.14956292510032654
Validation loss: 1.5197532971700032

Epoch: 5| Step: 5
Training loss: 0.19750134646892548
Validation loss: 1.4914485344322779

Epoch: 5| Step: 6
Training loss: 0.06606363505125046
Validation loss: 1.5155988688110023

Epoch: 5| Step: 7
Training loss: 0.22082579135894775
Validation loss: 1.5047993929155412

Epoch: 5| Step: 8
Training loss: 0.13290894031524658
Validation loss: 1.5138682267999137

Epoch: 5| Step: 9
Training loss: 0.13581299781799316
Validation loss: 1.5262349574796614

Epoch: 5| Step: 10
Training loss: 0.11673526465892792
Validation loss: 1.5140612407397198

Epoch: 385| Step: 0
Training loss: 0.15323075652122498
Validation loss: 1.5130898311573973

Epoch: 5| Step: 1
Training loss: 0.13843710720539093
Validation loss: 1.4891813044906945

Epoch: 5| Step: 2
Training loss: 0.10495375096797943
Validation loss: 1.4933638598329277

Epoch: 5| Step: 3
Training loss: 0.15625086426734924
Validation loss: 1.507411358177021

Epoch: 5| Step: 4
Training loss: 0.3504740595817566
Validation loss: 1.4981825210714852

Epoch: 5| Step: 5
Training loss: 0.0632367804646492
Validation loss: 1.4702067253410176

Epoch: 5| Step: 6
Training loss: 0.09097213298082352
Validation loss: 1.4894822528285365

Epoch: 5| Step: 7
Training loss: 0.11925303936004639
Validation loss: 1.4861141558616393

Epoch: 5| Step: 8
Training loss: 0.10554780811071396
Validation loss: 1.4868079449540825

Epoch: 5| Step: 9
Training loss: 0.08582042157649994
Validation loss: 1.491793058251822

Epoch: 5| Step: 10
Training loss: 0.10515925288200378
Validation loss: 1.4868977941492552

Epoch: 386| Step: 0
Training loss: 0.06383117288351059
Validation loss: 1.5012621879577637

Epoch: 5| Step: 1
Training loss: 0.11300947517156601
Validation loss: 1.5313464467243483

Epoch: 5| Step: 2
Training loss: 0.09019331634044647
Validation loss: 1.5359472805453884

Epoch: 5| Step: 3
Training loss: 0.12354467809200287
Validation loss: 1.5160141991030784

Epoch: 5| Step: 4
Training loss: 0.07460673898458481
Validation loss: 1.5227696844326553

Epoch: 5| Step: 5
Training loss: 0.1902686506509781
Validation loss: 1.548245160810409

Epoch: 5| Step: 6
Training loss: 0.1121528148651123
Validation loss: 1.5134435571650022

Epoch: 5| Step: 7
Training loss: 0.18626700341701508
Validation loss: 1.5035864512125652

Epoch: 5| Step: 8
Training loss: 0.09540753066539764
Validation loss: 1.5107417510401817

Epoch: 5| Step: 9
Training loss: 0.1039990782737732
Validation loss: 1.5006050012444938

Epoch: 5| Step: 10
Training loss: 0.05570029094815254
Validation loss: 1.5245755692963958

Epoch: 387| Step: 0
Training loss: 0.23021197319030762
Validation loss: 1.5229437556318057

Epoch: 5| Step: 1
Training loss: 0.07285648584365845
Validation loss: 1.5235282554421374

Epoch: 5| Step: 2
Training loss: 0.20504291355609894
Validation loss: 1.5152687603427517

Epoch: 5| Step: 3
Training loss: 0.07318532466888428
Validation loss: 1.5145140014668947

Epoch: 5| Step: 4
Training loss: 0.09512617439031601
Validation loss: 1.51181972155007

Epoch: 5| Step: 5
Training loss: 0.15844516456127167
Validation loss: 1.4996234165724887

Epoch: 5| Step: 6
Training loss: 0.09973566234111786
Validation loss: 1.5124290643199798

Epoch: 5| Step: 7
Training loss: 0.14631390571594238
Validation loss: 1.514817835182272

Epoch: 5| Step: 8
Training loss: 0.05611785501241684
Validation loss: 1.5056151010656869

Epoch: 5| Step: 9
Training loss: 0.08980464935302734
Validation loss: 1.5170785829585085

Epoch: 5| Step: 10
Training loss: 0.1483757644891739
Validation loss: 1.5241435650856263

Epoch: 388| Step: 0
Training loss: 0.16098661720752716
Validation loss: 1.516035560638674

Epoch: 5| Step: 1
Training loss: 0.14107364416122437
Validation loss: 1.4822736299166115

Epoch: 5| Step: 2
Training loss: 0.0756804347038269
Validation loss: 1.4962567283261208

Epoch: 5| Step: 3
Training loss: 0.1248614564538002
Validation loss: 1.4898828947415916

Epoch: 5| Step: 4
Training loss: 0.11074487864971161
Validation loss: 1.4900433888999365

Epoch: 5| Step: 5
Training loss: 0.23079116642475128
Validation loss: 1.490315923126795

Epoch: 5| Step: 6
Training loss: 0.07549867779016495
Validation loss: 1.5164605827741726

Epoch: 5| Step: 7
Training loss: 0.14374889433383942
Validation loss: 1.5026198343564106

Epoch: 5| Step: 8
Training loss: 0.11087880283594131
Validation loss: 1.5447706727571384

Epoch: 5| Step: 9
Training loss: 0.08503853529691696
Validation loss: 1.5444200743911087

Epoch: 5| Step: 10
Training loss: 0.17711393535137177
Validation loss: 1.5273715834463797

Epoch: 389| Step: 0
Training loss: 0.13163867592811584
Validation loss: 1.5327847670483332

Epoch: 5| Step: 1
Training loss: 0.08009201288223267
Validation loss: 1.5132156059306154

Epoch: 5| Step: 2
Training loss: 0.07980432361364365
Validation loss: 1.5252612624117123

Epoch: 5| Step: 3
Training loss: 0.13100369274616241
Validation loss: 1.5158183978449913

Epoch: 5| Step: 4
Training loss: 0.17582884430885315
Validation loss: 1.5272710964243899

Epoch: 5| Step: 5
Training loss: 0.06838802248239517
Validation loss: 1.5150148522469304

Epoch: 5| Step: 6
Training loss: 0.17495372891426086
Validation loss: 1.5266289775089552

Epoch: 5| Step: 7
Training loss: 0.06891172379255295
Validation loss: 1.517857591311137

Epoch: 5| Step: 8
Training loss: 0.11724106967449188
Validation loss: 1.5433950949740667

Epoch: 5| Step: 9
Training loss: 0.1771893948316574
Validation loss: 1.534786480729298

Epoch: 5| Step: 10
Training loss: 0.16266809403896332
Validation loss: 1.5432562276881228

Epoch: 390| Step: 0
Training loss: 0.12979717552661896
Validation loss: 1.5029754869399532

Epoch: 5| Step: 1
Training loss: 0.16760095953941345
Validation loss: 1.5163046249779322

Epoch: 5| Step: 2
Training loss: 0.10285530239343643
Validation loss: 1.5057114619080738

Epoch: 5| Step: 3
Training loss: 0.11983941495418549
Validation loss: 1.5113263104551582

Epoch: 5| Step: 4
Training loss: 0.11739160865545273
Validation loss: 1.498110657097191

Epoch: 5| Step: 5
Training loss: 0.2060813009738922
Validation loss: 1.499103897361345

Epoch: 5| Step: 6
Training loss: 0.06924080848693848
Validation loss: 1.511006906468381

Epoch: 5| Step: 7
Training loss: 0.1163923516869545
Validation loss: 1.517817929226865

Epoch: 5| Step: 8
Training loss: 0.08974207192659378
Validation loss: 1.5050556082879343

Epoch: 5| Step: 9
Training loss: 0.10594937950372696
Validation loss: 1.48722287660004

Epoch: 5| Step: 10
Training loss: 0.12862466275691986
Validation loss: 1.5084720074489553

Epoch: 391| Step: 0
Training loss: 0.18177290260791779
Validation loss: 1.5067212607270928

Epoch: 5| Step: 1
Training loss: 0.12761349976062775
Validation loss: 1.4956596205311437

Epoch: 5| Step: 2
Training loss: 0.10270663350820541
Validation loss: 1.5045645095968758

Epoch: 5| Step: 3
Training loss: 0.0883173793554306
Validation loss: 1.5116538886101014

Epoch: 5| Step: 4
Training loss: 0.1269475519657135
Validation loss: 1.5043595760099349

Epoch: 5| Step: 5
Training loss: 0.16499638557434082
Validation loss: 1.505317872570407

Epoch: 5| Step: 6
Training loss: 0.10874740779399872
Validation loss: 1.5130937022547568

Epoch: 5| Step: 7
Training loss: 0.1286899298429489
Validation loss: 1.5173222441827097

Epoch: 5| Step: 8
Training loss: 0.09441494196653366
Validation loss: 1.509530637853889

Epoch: 5| Step: 9
Training loss: 0.10719625651836395
Validation loss: 1.483942703534198

Epoch: 5| Step: 10
Training loss: 0.3592072129249573
Validation loss: 1.4715914495529667

Epoch: 392| Step: 0
Training loss: 0.08228161931037903
Validation loss: 1.4895478576742194

Epoch: 5| Step: 1
Training loss: 0.06887292116880417
Validation loss: 1.4887767760984358

Epoch: 5| Step: 2
Training loss: 0.12378283590078354
Validation loss: 1.4697023335323538

Epoch: 5| Step: 3
Training loss: 0.11689929664134979
Validation loss: 1.491844270818977

Epoch: 5| Step: 4
Training loss: 0.09947577118873596
Validation loss: 1.463244838099326

Epoch: 5| Step: 5
Training loss: 0.08242138475179672
Validation loss: 1.4809590962625319

Epoch: 5| Step: 6
Training loss: 0.1260279417037964
Validation loss: 1.4427461239599413

Epoch: 5| Step: 7
Training loss: 0.17775097489356995
Validation loss: 1.438619714911266

Epoch: 5| Step: 8
Training loss: 0.14330391585826874
Validation loss: 1.4648711681365967

Epoch: 5| Step: 9
Training loss: 0.09085304290056229
Validation loss: 1.46672426244264

Epoch: 5| Step: 10
Training loss: 0.23408305644989014
Validation loss: 1.4800906360790294

Epoch: 393| Step: 0
Training loss: 0.07935459911823273
Validation loss: 1.4767569662422262

Epoch: 5| Step: 1
Training loss: 0.07144709676504135
Validation loss: 1.5001317698468444

Epoch: 5| Step: 2
Training loss: 0.056782472878694534
Validation loss: 1.500566960662924

Epoch: 5| Step: 3
Training loss: 0.09554143995046616
Validation loss: 1.5071133182894798

Epoch: 5| Step: 4
Training loss: 0.06980408728122711
Validation loss: 1.5121942002286193

Epoch: 5| Step: 5
Training loss: 0.0749480277299881
Validation loss: 1.4939849735588155

Epoch: 5| Step: 6
Training loss: 0.19407668709754944
Validation loss: 1.4893433368334206

Epoch: 5| Step: 7
Training loss: 0.23716077208518982
Validation loss: 1.4966682323845484

Epoch: 5| Step: 8
Training loss: 0.12455697357654572
Validation loss: 1.4868860488296838

Epoch: 5| Step: 9
Training loss: 0.06260570138692856
Validation loss: 1.492164413134257

Epoch: 5| Step: 10
Training loss: 0.08732183277606964
Validation loss: 1.4879022746957757

Epoch: 394| Step: 0
Training loss: 0.08413035422563553
Validation loss: 1.4858110668838664

Epoch: 5| Step: 1
Training loss: 0.09883038699626923
Validation loss: 1.476558509693351

Epoch: 5| Step: 2
Training loss: 0.06875894218683243
Validation loss: 1.4758759237104846

Epoch: 5| Step: 3
Training loss: 0.07179301977157593
Validation loss: 1.465669096157115

Epoch: 5| Step: 4
Training loss: 0.20244593918323517
Validation loss: 1.4842139572225592

Epoch: 5| Step: 5
Training loss: 0.09838302433490753
Validation loss: 1.4744795522382181

Epoch: 5| Step: 6
Training loss: 0.083896204829216
Validation loss: 1.4813842068436325

Epoch: 5| Step: 7
Training loss: 0.10030673444271088
Validation loss: 1.4817458660371843

Epoch: 5| Step: 8
Training loss: 0.12458831071853638
Validation loss: 1.4695746103922527

Epoch: 5| Step: 9
Training loss: 0.1854555904865265
Validation loss: 1.4993851172026766

Epoch: 5| Step: 10
Training loss: 0.13054817914962769
Validation loss: 1.4818423781343686

Epoch: 395| Step: 0
Training loss: 0.2084629088640213
Validation loss: 1.4743978797748525

Epoch: 5| Step: 1
Training loss: 0.11169560253620148
Validation loss: 1.50956682748692

Epoch: 5| Step: 2
Training loss: 0.1368829309940338
Validation loss: 1.5137464692515712

Epoch: 5| Step: 3
Training loss: 0.08438634127378464
Validation loss: 1.5224070792557092

Epoch: 5| Step: 4
Training loss: 0.1617305725812912
Validation loss: 1.5478270220500168

Epoch: 5| Step: 5
Training loss: 0.09926854074001312
Validation loss: 1.511583096237593

Epoch: 5| Step: 6
Training loss: 0.09206189215183258
Validation loss: 1.5219268157917967

Epoch: 5| Step: 7
Training loss: 0.0717058852314949
Validation loss: 1.5164314239255843

Epoch: 5| Step: 8
Training loss: 0.11912046372890472
Validation loss: 1.547674475177642

Epoch: 5| Step: 9
Training loss: 0.14654777944087982
Validation loss: 1.4942714270725046

Epoch: 5| Step: 10
Training loss: 0.09068582206964493
Validation loss: 1.4913359829174575

Epoch: 396| Step: 0
Training loss: 0.13620562851428986
Validation loss: 1.4929805853033578

Epoch: 5| Step: 1
Training loss: 0.15580512583255768
Validation loss: 1.4692432521491923

Epoch: 5| Step: 2
Training loss: 0.10064685344696045
Validation loss: 1.4905666382082048

Epoch: 5| Step: 3
Training loss: 0.08997827768325806
Validation loss: 1.4754884294284287

Epoch: 5| Step: 4
Training loss: 0.19737164676189423
Validation loss: 1.5107345209326795

Epoch: 5| Step: 5
Training loss: 0.07306970655918121
Validation loss: 1.5187695551944036

Epoch: 5| Step: 6
Training loss: 0.16291746497154236
Validation loss: 1.510891592630776

Epoch: 5| Step: 7
Training loss: 0.06541431695222855
Validation loss: 1.500119363107989

Epoch: 5| Step: 8
Training loss: 0.08005988597869873
Validation loss: 1.5062535078294816

Epoch: 5| Step: 9
Training loss: 0.06699489057064056
Validation loss: 1.4895729531524002

Epoch: 5| Step: 10
Training loss: 0.07727321237325668
Validation loss: 1.5104257368272351

Epoch: 397| Step: 0
Training loss: 0.09716163575649261
Validation loss: 1.4940167075844222

Epoch: 5| Step: 1
Training loss: 0.09657339006662369
Validation loss: 1.49471672760543

Epoch: 5| Step: 2
Training loss: 0.11534042656421661
Validation loss: 1.503234363371326

Epoch: 5| Step: 3
Training loss: 0.06939972192049026
Validation loss: 1.457143965587821

Epoch: 5| Step: 4
Training loss: 0.2003406286239624
Validation loss: 1.4712984472192743

Epoch: 5| Step: 5
Training loss: 0.20938467979431152
Validation loss: 1.4884913454773605

Epoch: 5| Step: 6
Training loss: 0.12522780895233154
Validation loss: 1.4754945167931177

Epoch: 5| Step: 7
Training loss: 0.09697356075048447
Validation loss: 1.44974547560497

Epoch: 5| Step: 8
Training loss: 0.14283856749534607
Validation loss: 1.4859273356776084

Epoch: 5| Step: 9
Training loss: 0.11312474310398102
Validation loss: 1.4710267179755754

Epoch: 5| Step: 10
Training loss: 0.08838432282209396
Validation loss: 1.496767415795275

Epoch: 398| Step: 0
Training loss: 0.07114049047231674
Validation loss: 1.5201767567665345

Epoch: 5| Step: 1
Training loss: 0.10013698041439056
Validation loss: 1.51387749051535

Epoch: 5| Step: 2
Training loss: 0.10302598774433136
Validation loss: 1.5444393427141252

Epoch: 5| Step: 3
Training loss: 0.1248435229063034
Validation loss: 1.537984791622367

Epoch: 5| Step: 4
Training loss: 0.15916819870471954
Validation loss: 1.540932624570785

Epoch: 5| Step: 5
Training loss: 0.06029237434267998
Validation loss: 1.5329190813085085

Epoch: 5| Step: 6
Training loss: 0.07245707511901855
Validation loss: 1.510223824490783

Epoch: 5| Step: 7
Training loss: 0.20809301733970642
Validation loss: 1.5045651325615503

Epoch: 5| Step: 8
Training loss: 0.07578983157873154
Validation loss: 1.4842940536878442

Epoch: 5| Step: 9
Training loss: 0.20661568641662598
Validation loss: 1.4989031348177182

Epoch: 5| Step: 10
Training loss: 0.07226573675870895
Validation loss: 1.4827947616577148

Epoch: 399| Step: 0
Training loss: 0.2428121566772461
Validation loss: 1.4536358438512331

Epoch: 5| Step: 1
Training loss: 0.10327551513910294
Validation loss: 1.46183229261829

Epoch: 5| Step: 2
Training loss: 0.13060231506824493
Validation loss: 1.4487956980223298

Epoch: 5| Step: 3
Training loss: 0.06518291682004929
Validation loss: 1.4597718523394676

Epoch: 5| Step: 4
Training loss: 0.06212495639920235
Validation loss: 1.4764053244744577

Epoch: 5| Step: 5
Training loss: 0.21072669327259064
Validation loss: 1.450562361747988

Epoch: 5| Step: 6
Training loss: 0.0693424791097641
Validation loss: 1.46646079837635

Epoch: 5| Step: 7
Training loss: 0.09157358109951019
Validation loss: 1.462365117124332

Epoch: 5| Step: 8
Training loss: 0.07122784107923508
Validation loss: 1.4935312168572539

Epoch: 5| Step: 9
Training loss: 0.09229167550802231
Validation loss: 1.493172396895706

Epoch: 5| Step: 10
Training loss: 0.1083865612745285
Validation loss: 1.5033754866610292

Epoch: 400| Step: 0
Training loss: 0.10346332937479019
Validation loss: 1.5028343521138674

Epoch: 5| Step: 1
Training loss: 0.07435309886932373
Validation loss: 1.5087129108367427

Epoch: 5| Step: 2
Training loss: 0.06764212250709534
Validation loss: 1.5070329917374479

Epoch: 5| Step: 3
Training loss: 0.12487077713012695
Validation loss: 1.5227971615329865

Epoch: 5| Step: 4
Training loss: 0.06346428394317627
Validation loss: 1.4842623138940463

Epoch: 5| Step: 5
Training loss: 0.17002925276756287
Validation loss: 1.5097951440400974

Epoch: 5| Step: 6
Training loss: 0.0902642011642456
Validation loss: 1.4834824018580939

Epoch: 5| Step: 7
Training loss: 0.07685525715351105
Validation loss: 1.4933969769426572

Epoch: 5| Step: 8
Training loss: 0.0640222504734993
Validation loss: 1.4939475097963888

Epoch: 5| Step: 9
Training loss: 0.1046803817152977
Validation loss: 1.499124849996259

Epoch: 5| Step: 10
Training loss: 0.25831204652786255
Validation loss: 1.485548973083496

Epoch: 401| Step: 0
Training loss: 0.068128302693367
Validation loss: 1.477839353264019

Epoch: 5| Step: 1
Training loss: 0.22199873626232147
Validation loss: 1.4987149264222832

Epoch: 5| Step: 2
Training loss: 0.1297105848789215
Validation loss: 1.4854855101595643

Epoch: 5| Step: 3
Training loss: 0.11450624465942383
Validation loss: 1.4926760779914034

Epoch: 5| Step: 4
Training loss: 0.20334839820861816
Validation loss: 1.4914884887715822

Epoch: 5| Step: 5
Training loss: 0.0789928212761879
Validation loss: 1.4745696001155402

Epoch: 5| Step: 6
Training loss: 0.09401409327983856
Validation loss: 1.4837664096586165

Epoch: 5| Step: 7
Training loss: 0.0901816114783287
Validation loss: 1.4877687308096117

Epoch: 5| Step: 8
Training loss: 0.09803985059261322
Validation loss: 1.4771902766278995

Epoch: 5| Step: 9
Training loss: 0.09616227447986603
Validation loss: 1.4925672918237665

Epoch: 5| Step: 10
Training loss: 0.11956831812858582
Validation loss: 1.5071132811166907

Epoch: 402| Step: 0
Training loss: 0.0930626392364502
Validation loss: 1.505318941608552

Epoch: 5| Step: 1
Training loss: 0.18690207600593567
Validation loss: 1.529280586268312

Epoch: 5| Step: 2
Training loss: 0.08677203953266144
Validation loss: 1.5092439971944338

Epoch: 5| Step: 3
Training loss: 0.15617240965366364
Validation loss: 1.5144016435069423

Epoch: 5| Step: 4
Training loss: 0.074712835252285
Validation loss: 1.5344273749218191

Epoch: 5| Step: 5
Training loss: 0.08056195080280304
Validation loss: 1.5288633454230525

Epoch: 5| Step: 6
Training loss: 0.07288645207881927
Validation loss: 1.5222030493520922

Epoch: 5| Step: 7
Training loss: 0.08280832320451736
Validation loss: 1.5265907843907673

Epoch: 5| Step: 8
Training loss: 0.11948263645172119
Validation loss: 1.545671388667117

Epoch: 5| Step: 9
Training loss: 0.21185898780822754
Validation loss: 1.524375161816997

Epoch: 5| Step: 10
Training loss: 0.08249197155237198
Validation loss: 1.5026914112029537

Epoch: 403| Step: 0
Training loss: 0.19172844290733337
Validation loss: 1.514143399012986

Epoch: 5| Step: 1
Training loss: 0.09948263317346573
Validation loss: 1.4995055480669903

Epoch: 5| Step: 2
Training loss: 0.09899475425481796
Validation loss: 1.5004486640294392

Epoch: 5| Step: 3
Training loss: 0.08198413252830505
Validation loss: 1.4913376967112224

Epoch: 5| Step: 4
Training loss: 0.21904964745044708
Validation loss: 1.4690487166886688

Epoch: 5| Step: 5
Training loss: 0.14062216877937317
Validation loss: 1.478094990535449

Epoch: 5| Step: 6
Training loss: 0.10784585773944855
Validation loss: 1.4776118096484934

Epoch: 5| Step: 7
Training loss: 0.09370022267103195
Validation loss: 1.4922741818171676

Epoch: 5| Step: 8
Training loss: 0.11138065904378891
Validation loss: 1.4735722746900333

Epoch: 5| Step: 9
Training loss: 0.10152298212051392
Validation loss: 1.5025882426128592

Epoch: 5| Step: 10
Training loss: 0.22330106794834137
Validation loss: 1.4996223257433983

Epoch: 404| Step: 0
Training loss: 0.09991946816444397
Validation loss: 1.460988979185781

Epoch: 5| Step: 1
Training loss: 0.08721703290939331
Validation loss: 1.4840837588874243

Epoch: 5| Step: 2
Training loss: 0.07890380918979645
Validation loss: 1.5079983908643004

Epoch: 5| Step: 3
Training loss: 0.11216486990451813
Validation loss: 1.5194188702491023

Epoch: 5| Step: 4
Training loss: 0.1007123738527298
Validation loss: 1.5067316421898462

Epoch: 5| Step: 5
Training loss: 0.12866005301475525
Validation loss: 1.5253113264678626

Epoch: 5| Step: 6
Training loss: 0.10283742100000381
Validation loss: 1.514929897041731

Epoch: 5| Step: 7
Training loss: 0.14512331783771515
Validation loss: 1.5036956142353755

Epoch: 5| Step: 8
Training loss: 0.1275663673877716
Validation loss: 1.5205227354521393

Epoch: 5| Step: 9
Training loss: 0.32638052105903625
Validation loss: 1.5038489398135935

Epoch: 5| Step: 10
Training loss: 0.11805419623851776
Validation loss: 1.4806577556876725

Epoch: 405| Step: 0
Training loss: 0.07699321955442429
Validation loss: 1.4824382387181765

Epoch: 5| Step: 1
Training loss: 0.11900298297405243
Validation loss: 1.4633727650488577

Epoch: 5| Step: 2
Training loss: 0.08841467648744583
Validation loss: 1.4938570863457137

Epoch: 5| Step: 3
Training loss: 0.04458005726337433
Validation loss: 1.4840822437758088

Epoch: 5| Step: 4
Training loss: 0.10362023115158081
Validation loss: 1.5008904011018815

Epoch: 5| Step: 5
Training loss: 0.11472566425800323
Validation loss: 1.4736214222446564

Epoch: 5| Step: 6
Training loss: 0.1031181588768959
Validation loss: 1.4967429663545342

Epoch: 5| Step: 7
Training loss: 0.12348710000514984
Validation loss: 1.5203746070143997

Epoch: 5| Step: 8
Training loss: 0.08225750923156738
Validation loss: 1.4962695644747825

Epoch: 5| Step: 9
Training loss: 0.23129768669605255
Validation loss: 1.4713531501831547

Epoch: 5| Step: 10
Training loss: 0.2296874076128006
Validation loss: 1.4945333593635148

Epoch: 406| Step: 0
Training loss: 0.07640652358531952
Validation loss: 1.4488835142504783

Epoch: 5| Step: 1
Training loss: 0.11006619036197662
Validation loss: 1.4581305878136748

Epoch: 5| Step: 2
Training loss: 0.06238045170903206
Validation loss: 1.4831221642032746

Epoch: 5| Step: 3
Training loss: 0.05967329069972038
Validation loss: 1.4732872862969675

Epoch: 5| Step: 4
Training loss: 0.08703296631574631
Validation loss: 1.4955451462858467

Epoch: 5| Step: 5
Training loss: 0.07543425261974335
Validation loss: 1.4832842388460714

Epoch: 5| Step: 6
Training loss: 0.08099989593029022
Validation loss: 1.4862413662736134

Epoch: 5| Step: 7
Training loss: 0.10893364995718002
Validation loss: 1.4804562983974334

Epoch: 5| Step: 8
Training loss: 0.21796536445617676
Validation loss: 1.490490896727449

Epoch: 5| Step: 9
Training loss: 0.10701005160808563
Validation loss: 1.4956561147525747

Epoch: 5| Step: 10
Training loss: 0.24289000034332275
Validation loss: 1.495447427354833

Epoch: 407| Step: 0
Training loss: 0.08210352808237076
Validation loss: 1.5053615800796016

Epoch: 5| Step: 1
Training loss: 0.11389727890491486
Validation loss: 1.486582097186837

Epoch: 5| Step: 2
Training loss: 0.07273371517658234
Validation loss: 1.483200733379651

Epoch: 5| Step: 3
Training loss: 0.15002116560935974
Validation loss: 1.5284621959091516

Epoch: 5| Step: 4
Training loss: 0.09359075874090195
Validation loss: 1.5035969749573739

Epoch: 5| Step: 5
Training loss: 0.04724173620343208
Validation loss: 1.4998969980465469

Epoch: 5| Step: 6
Training loss: 0.09277965128421783
Validation loss: 1.4976782555221229

Epoch: 5| Step: 7
Training loss: 0.16778212785720825
Validation loss: 1.4913368007188201

Epoch: 5| Step: 8
Training loss: 0.10345282405614853
Validation loss: 1.4994500119199035

Epoch: 5| Step: 9
Training loss: 0.1014920026063919
Validation loss: 1.5080316848652338

Epoch: 5| Step: 10
Training loss: 0.24525320529937744
Validation loss: 1.5092247352805188

Epoch: 408| Step: 0
Training loss: 0.13884548842906952
Validation loss: 1.532806449039008

Epoch: 5| Step: 1
Training loss: 0.300970196723938
Validation loss: 1.5232533665113552

Epoch: 5| Step: 2
Training loss: 0.09226872026920319
Validation loss: 1.4974706993308118

Epoch: 5| Step: 3
Training loss: 0.09297990053892136
Validation loss: 1.497785299055038

Epoch: 5| Step: 4
Training loss: 0.07566016912460327
Validation loss: 1.5026478562303769

Epoch: 5| Step: 5
Training loss: 0.10706362873315811
Validation loss: 1.4846764751659927

Epoch: 5| Step: 6
Training loss: 0.07832039892673492
Validation loss: 1.5103019809210172

Epoch: 5| Step: 7
Training loss: 0.10633932054042816
Validation loss: 1.495370864868164

Epoch: 5| Step: 8
Training loss: 0.13685394823551178
Validation loss: 1.4966305942945584

Epoch: 5| Step: 9
Training loss: 0.06446260213851929
Validation loss: 1.501499322793817

Epoch: 5| Step: 10
Training loss: 0.1091565266251564
Validation loss: 1.4846342058591946

Epoch: 409| Step: 0
Training loss: 0.06964461505413055
Validation loss: 1.4634465786718553

Epoch: 5| Step: 1
Training loss: 0.20996937155723572
Validation loss: 1.4681163295622794

Epoch: 5| Step: 2
Training loss: 0.1845126897096634
Validation loss: 1.4624455128946612

Epoch: 5| Step: 3
Training loss: 0.08341630548238754
Validation loss: 1.4713871414943407

Epoch: 5| Step: 4
Training loss: 0.1033029556274414
Validation loss: 1.4884403110832296

Epoch: 5| Step: 5
Training loss: 0.13715574145317078
Validation loss: 1.4845164078538136

Epoch: 5| Step: 6
Training loss: 0.13500039279460907
Validation loss: 1.5211845110821467

Epoch: 5| Step: 7
Training loss: 0.09025857597589493
Validation loss: 1.5443375520808722

Epoch: 5| Step: 8
Training loss: 0.15937663614749908
Validation loss: 1.5419529099618234

Epoch: 5| Step: 9
Training loss: 0.11988190561532974
Validation loss: 1.5535803212914416

Epoch: 5| Step: 10
Training loss: 0.09269136190414429
Validation loss: 1.5310812829643168

Epoch: 410| Step: 0
Training loss: 0.0793008878827095
Validation loss: 1.5234309550254577

Epoch: 5| Step: 1
Training loss: 0.1020476445555687
Validation loss: 1.5265297658981816

Epoch: 5| Step: 2
Training loss: 0.11093616485595703
Validation loss: 1.501501989620988

Epoch: 5| Step: 3
Training loss: 0.08924652636051178
Validation loss: 1.4899117626169676

Epoch: 5| Step: 4
Training loss: 0.17954352498054504
Validation loss: 1.491632855066689

Epoch: 5| Step: 5
Training loss: 0.09845604002475739
Validation loss: 1.4743002524939917

Epoch: 5| Step: 6
Training loss: 0.09631656110286713
Validation loss: 1.4856819786051267

Epoch: 5| Step: 7
Training loss: 0.19352321326732635
Validation loss: 1.4571742947383592

Epoch: 5| Step: 8
Training loss: 0.09057052433490753
Validation loss: 1.4826758241140714

Epoch: 5| Step: 9
Training loss: 0.0848676860332489
Validation loss: 1.4962541070035709

Epoch: 5| Step: 10
Training loss: 0.1011924222111702
Validation loss: 1.499045846282795

Epoch: 411| Step: 0
Training loss: 0.17865672707557678
Validation loss: 1.492098032787282

Epoch: 5| Step: 1
Training loss: 0.08370530605316162
Validation loss: 1.501475509776864

Epoch: 5| Step: 2
Training loss: 0.09762655198574066
Validation loss: 1.4880894076439641

Epoch: 5| Step: 3
Training loss: 0.10310795158147812
Validation loss: 1.5108470378383514

Epoch: 5| Step: 4
Training loss: 0.14710429310798645
Validation loss: 1.521479429737214

Epoch: 5| Step: 5
Training loss: 0.13168199360370636
Validation loss: 1.5140642799356931

Epoch: 5| Step: 6
Training loss: 0.20711641013622284
Validation loss: 1.5398307666983655

Epoch: 5| Step: 7
Training loss: 0.08167880773544312
Validation loss: 1.5140571491692656

Epoch: 5| Step: 8
Training loss: 0.12288614362478256
Validation loss: 1.5244867160756101

Epoch: 5| Step: 9
Training loss: 0.13640037178993225
Validation loss: 1.482396548794162

Epoch: 5| Step: 10
Training loss: 0.1316893994808197
Validation loss: 1.4749325718930972

Epoch: 412| Step: 0
Training loss: 0.10493282228708267
Validation loss: 1.490463343999719

Epoch: 5| Step: 1
Training loss: 0.1908169984817505
Validation loss: 1.5014567458501427

Epoch: 5| Step: 2
Training loss: 0.06103783845901489
Validation loss: 1.5050754893210627

Epoch: 5| Step: 3
Training loss: 0.12962272763252258
Validation loss: 1.4844553598793604

Epoch: 5| Step: 4
Training loss: 0.12227334082126617
Validation loss: 1.4768261242938299

Epoch: 5| Step: 5
Training loss: 0.13615229725837708
Validation loss: 1.4822213957386632

Epoch: 5| Step: 6
Training loss: 0.10143788158893585
Validation loss: 1.4731285828416065

Epoch: 5| Step: 7
Training loss: 0.21364736557006836
Validation loss: 1.4663432118713216

Epoch: 5| Step: 8
Training loss: 0.10230390727519989
Validation loss: 1.4460935054286834

Epoch: 5| Step: 9
Training loss: 0.13056397438049316
Validation loss: 1.4432288510825044

Epoch: 5| Step: 10
Training loss: 0.11262855678796768
Validation loss: 1.4742008845011394

Epoch: 413| Step: 0
Training loss: 0.07558480650186539
Validation loss: 1.4583253988655664

Epoch: 5| Step: 1
Training loss: 0.10337203741073608
Validation loss: 1.4869333518448697

Epoch: 5| Step: 2
Training loss: 0.09065701812505722
Validation loss: 1.4596155689608665

Epoch: 5| Step: 3
Training loss: 0.1182294487953186
Validation loss: 1.494383644032222

Epoch: 5| Step: 4
Training loss: 0.08576575666666031
Validation loss: 1.480721559575809

Epoch: 5| Step: 5
Training loss: 0.18625736236572266
Validation loss: 1.4962341734158096

Epoch: 5| Step: 6
Training loss: 0.22124645113945007
Validation loss: 1.5027036423324256

Epoch: 5| Step: 7
Training loss: 0.09452962130308151
Validation loss: 1.5093787293280325

Epoch: 5| Step: 8
Training loss: 0.12663237750530243
Validation loss: 1.5063142161215506

Epoch: 5| Step: 9
Training loss: 0.0903870090842247
Validation loss: 1.48444882259574

Epoch: 5| Step: 10
Training loss: 0.10494357347488403
Validation loss: 1.4941069182529245

Epoch: 414| Step: 0
Training loss: 0.1026342362165451
Validation loss: 1.4820035215347045

Epoch: 5| Step: 1
Training loss: 0.14855752885341644
Validation loss: 1.4877471231645154

Epoch: 5| Step: 2
Training loss: 0.1086939126253128
Validation loss: 1.5039324657891386

Epoch: 5| Step: 3
Training loss: 0.08301114290952682
Validation loss: 1.500088055928548

Epoch: 5| Step: 4
Training loss: 0.04366768151521683
Validation loss: 1.492864244727678

Epoch: 5| Step: 5
Training loss: 0.1036398783326149
Validation loss: 1.5057320261514315

Epoch: 5| Step: 6
Training loss: 0.09248395264148712
Validation loss: 1.496592886986271

Epoch: 5| Step: 7
Training loss: 0.09035652130842209
Validation loss: 1.5245153929597588

Epoch: 5| Step: 8
Training loss: 0.20176973938941956
Validation loss: 1.5189331603306595

Epoch: 5| Step: 9
Training loss: 0.08012925088405609
Validation loss: 1.5184528263666297

Epoch: 5| Step: 10
Training loss: 0.22125285863876343
Validation loss: 1.532883999168232

Epoch: 415| Step: 0
Training loss: 0.16804519295692444
Validation loss: 1.485853543845556

Epoch: 5| Step: 1
Training loss: 0.07566870748996735
Validation loss: 1.491511348755129

Epoch: 5| Step: 2
Training loss: 0.0728263258934021
Validation loss: 1.4636118905518645

Epoch: 5| Step: 3
Training loss: 0.1151014193892479
Validation loss: 1.4370008360955022

Epoch: 5| Step: 4
Training loss: 0.10362575203180313
Validation loss: 1.4719314754650157

Epoch: 5| Step: 5
Training loss: 0.09205971658229828
Validation loss: 1.461213501550818

Epoch: 5| Step: 6
Training loss: 0.08637604862451553
Validation loss: 1.4739187878947104

Epoch: 5| Step: 7
Training loss: 0.11544275283813477
Validation loss: 1.4889925397852415

Epoch: 5| Step: 8
Training loss: 0.11768170446157455
Validation loss: 1.470395266368825

Epoch: 5| Step: 9
Training loss: 0.25742635130882263
Validation loss: 1.480291320431617

Epoch: 5| Step: 10
Training loss: 0.07704740017652512
Validation loss: 1.5094100429165749

Epoch: 416| Step: 0
Training loss: 0.10563959926366806
Validation loss: 1.493571066087292

Epoch: 5| Step: 1
Training loss: 0.05244708061218262
Validation loss: 1.5017944074446155

Epoch: 5| Step: 2
Training loss: 0.09010379761457443
Validation loss: 1.4934776265134093

Epoch: 5| Step: 3
Training loss: 0.11974130570888519
Validation loss: 1.489891311173798

Epoch: 5| Step: 4
Training loss: 0.09606859087944031
Validation loss: 1.518883397502284

Epoch: 5| Step: 5
Training loss: 0.19848065078258514
Validation loss: 1.514508822912811

Epoch: 5| Step: 6
Training loss: 0.19245174527168274
Validation loss: 1.5121085547631787

Epoch: 5| Step: 7
Training loss: 0.056886326521635056
Validation loss: 1.515616423340254

Epoch: 5| Step: 8
Training loss: 0.12665459513664246
Validation loss: 1.5244007879687893

Epoch: 5| Step: 9
Training loss: 0.11880499124526978
Validation loss: 1.5294769989546908

Epoch: 5| Step: 10
Training loss: 0.09251493215560913
Validation loss: 1.534955551547389

Epoch: 417| Step: 0
Training loss: 0.0764830932021141
Validation loss: 1.533501760933989

Epoch: 5| Step: 1
Training loss: 0.08827809989452362
Validation loss: 1.5314707768860685

Epoch: 5| Step: 2
Training loss: 0.27348607778549194
Validation loss: 1.5280722148956791

Epoch: 5| Step: 3
Training loss: 0.07104764133691788
Validation loss: 1.5347347182612265

Epoch: 5| Step: 4
Training loss: 0.08276745676994324
Validation loss: 1.5356775714505104

Epoch: 5| Step: 5
Training loss: 0.0880667194724083
Validation loss: 1.5184192016560545

Epoch: 5| Step: 6
Training loss: 0.11611249297857285
Validation loss: 1.5222585214081632

Epoch: 5| Step: 7
Training loss: 0.07086224853992462
Validation loss: 1.4850891725991362

Epoch: 5| Step: 8
Training loss: 0.0968126580119133
Validation loss: 1.475165113326042

Epoch: 5| Step: 9
Training loss: 0.06999124586582184
Validation loss: 1.4826377771234

Epoch: 5| Step: 10
Training loss: 0.10160237550735474
Validation loss: 1.4680563467805103

Epoch: 418| Step: 0
Training loss: 0.07680656015872955
Validation loss: 1.4568747884483748

Epoch: 5| Step: 1
Training loss: 0.21061234176158905
Validation loss: 1.476049482181508

Epoch: 5| Step: 2
Training loss: 0.06915439665317535
Validation loss: 1.4585133547423987

Epoch: 5| Step: 3
Training loss: 0.08216027915477753
Validation loss: 1.4739920528986121

Epoch: 5| Step: 4
Training loss: 0.07879586517810822
Validation loss: 1.4661685292438795

Epoch: 5| Step: 5
Training loss: 0.09559482336044312
Validation loss: 1.4679464832428963

Epoch: 5| Step: 6
Training loss: 0.06803472340106964
Validation loss: 1.4853182326080978

Epoch: 5| Step: 7
Training loss: 0.10191698372364044
Validation loss: 1.4922232704777871

Epoch: 5| Step: 8
Training loss: 0.07927566766738892
Validation loss: 1.4919122137049192

Epoch: 5| Step: 9
Training loss: 0.18724395334720612
Validation loss: 1.534778069424373

Epoch: 5| Step: 10
Training loss: 0.1013593077659607
Validation loss: 1.5076366496342484

Epoch: 419| Step: 0
Training loss: 0.08906497061252594
Validation loss: 1.5191188743037563

Epoch: 5| Step: 1
Training loss: 0.17755654454231262
Validation loss: 1.5053700042027298

Epoch: 5| Step: 2
Training loss: 0.17812763154506683
Validation loss: 1.5223222599234632

Epoch: 5| Step: 3
Training loss: 0.08655806630849838
Validation loss: 1.5180251790631203

Epoch: 5| Step: 4
Training loss: 0.08799701184034348
Validation loss: 1.5079100625489348

Epoch: 5| Step: 5
Training loss: 0.08057950437068939
Validation loss: 1.4902668858087191

Epoch: 5| Step: 6
Training loss: 0.07617796212434769
Validation loss: 1.5072672469641573

Epoch: 5| Step: 7
Training loss: 0.1089969053864479
Validation loss: 1.508351928444319

Epoch: 5| Step: 8
Training loss: 0.11588957160711288
Validation loss: 1.4987544782700077

Epoch: 5| Step: 9
Training loss: 0.0927511677145958
Validation loss: 1.4874152752660936

Epoch: 5| Step: 10
Training loss: 0.08557255566120148
Validation loss: 1.4979147795707948

Epoch: 420| Step: 0
Training loss: 0.08424322307109833
Validation loss: 1.4860193319218133

Epoch: 5| Step: 1
Training loss: 0.10931003093719482
Validation loss: 1.49491633266531

Epoch: 5| Step: 2
Training loss: 0.09428051859140396
Validation loss: 1.4798752569383191

Epoch: 5| Step: 3
Training loss: 0.12463917583227158
Validation loss: 1.513828992843628

Epoch: 5| Step: 4
Training loss: 0.27315837144851685
Validation loss: 1.5309864654335925

Epoch: 5| Step: 5
Training loss: 0.1381443738937378
Validation loss: 1.5426946711796585

Epoch: 5| Step: 6
Training loss: 0.08069024980068207
Validation loss: 1.5037338784945908

Epoch: 5| Step: 7
Training loss: 0.18055030703544617
Validation loss: 1.4782012419034076

Epoch: 5| Step: 8
Training loss: 0.06358490884304047
Validation loss: 1.470503596849339

Epoch: 5| Step: 9
Training loss: 0.11088067293167114
Validation loss: 1.4486991641342

Epoch: 5| Step: 10
Training loss: 0.06780559569597244
Validation loss: 1.4617086020849084

Epoch: 421| Step: 0
Training loss: 0.10302400588989258
Validation loss: 1.476525947611819

Epoch: 5| Step: 1
Training loss: 0.20575709640979767
Validation loss: 1.4756019858903782

Epoch: 5| Step: 2
Training loss: 0.2279917299747467
Validation loss: 1.4757514474212483

Epoch: 5| Step: 3
Training loss: 0.08705606311559677
Validation loss: 1.464588704929557

Epoch: 5| Step: 4
Training loss: 0.09453094005584717
Validation loss: 1.4921899982677993

Epoch: 5| Step: 5
Training loss: 0.0630403533577919
Validation loss: 1.5015783816255548

Epoch: 5| Step: 6
Training loss: 0.11234170198440552
Validation loss: 1.515843656755263

Epoch: 5| Step: 7
Training loss: 0.13385865092277527
Validation loss: 1.5140941924946283

Epoch: 5| Step: 8
Training loss: 0.11229922622442245
Validation loss: 1.505890089978454

Epoch: 5| Step: 9
Training loss: 0.08705732226371765
Validation loss: 1.5212763855534215

Epoch: 5| Step: 10
Training loss: 0.095521479845047
Validation loss: 1.5056076536896408

Epoch: 422| Step: 0
Training loss: 0.07972349971532822
Validation loss: 1.5064853250339467

Epoch: 5| Step: 1
Training loss: 0.06008050590753555
Validation loss: 1.5352971643529914

Epoch: 5| Step: 2
Training loss: 0.08282243460416794
Validation loss: 1.5206790790762952

Epoch: 5| Step: 3
Training loss: 0.16218481957912445
Validation loss: 1.508046325816903

Epoch: 5| Step: 4
Training loss: 0.09295076131820679
Validation loss: 1.5035675174446517

Epoch: 5| Step: 5
Training loss: 0.08857574313879013
Validation loss: 1.500295490346929

Epoch: 5| Step: 6
Training loss: 0.07669959962368011
Validation loss: 1.4841832191713396

Epoch: 5| Step: 7
Training loss: 0.09455855190753937
Validation loss: 1.492268136752549

Epoch: 5| Step: 8
Training loss: 0.19044215977191925
Validation loss: 1.5075447008173952

Epoch: 5| Step: 9
Training loss: 0.08402235060930252
Validation loss: 1.5043169529207292

Epoch: 5| Step: 10
Training loss: 0.10293833911418915
Validation loss: 1.5005055986424929

Epoch: 423| Step: 0
Training loss: 0.053183525800704956
Validation loss: 1.5060283471179265

Epoch: 5| Step: 1
Training loss: 0.24343737959861755
Validation loss: 1.524604251307826

Epoch: 5| Step: 2
Training loss: 0.10399307310581207
Validation loss: 1.4891772859839982

Epoch: 5| Step: 3
Training loss: 0.08979462087154388
Validation loss: 1.514358853781095

Epoch: 5| Step: 4
Training loss: 0.08992216736078262
Validation loss: 1.504156756144698

Epoch: 5| Step: 5
Training loss: 0.06814195215702057
Validation loss: 1.5287224477337253

Epoch: 5| Step: 6
Training loss: 0.19211554527282715
Validation loss: 1.5169618373276086

Epoch: 5| Step: 7
Training loss: 0.11707437038421631
Validation loss: 1.500477942087317

Epoch: 5| Step: 8
Training loss: 0.07503271102905273
Validation loss: 1.51147033322242

Epoch: 5| Step: 9
Training loss: 0.1072295680642128
Validation loss: 1.4952182923593829

Epoch: 5| Step: 10
Training loss: 0.06274910271167755
Validation loss: 1.504280992733535

Epoch: 424| Step: 0
Training loss: 0.09860314428806305
Validation loss: 1.4928020277330953

Epoch: 5| Step: 1
Training loss: 0.18715165555477142
Validation loss: 1.496422529220581

Epoch: 5| Step: 2
Training loss: 0.061688411980867386
Validation loss: 1.496975528296604

Epoch: 5| Step: 3
Training loss: 0.08427105844020844
Validation loss: 1.4891589405716106

Epoch: 5| Step: 4
Training loss: 0.0724034458398819
Validation loss: 1.5036130810296664

Epoch: 5| Step: 5
Training loss: 0.17757785320281982
Validation loss: 1.4953086286462762

Epoch: 5| Step: 6
Training loss: 0.047347985208034515
Validation loss: 1.4923643937674902

Epoch: 5| Step: 7
Training loss: 0.0671229362487793
Validation loss: 1.4749793314164685

Epoch: 5| Step: 8
Training loss: 0.08511342108249664
Validation loss: 1.491235880441563

Epoch: 5| Step: 9
Training loss: 0.07966099679470062
Validation loss: 1.48469082514445

Epoch: 5| Step: 10
Training loss: 0.10782259702682495
Validation loss: 1.4666453728111841

Epoch: 425| Step: 0
Training loss: 0.06400101631879807
Validation loss: 1.4762052079682708

Epoch: 5| Step: 1
Training loss: 0.05974435806274414
Validation loss: 1.4832082435648928

Epoch: 5| Step: 2
Training loss: 0.06909335404634476
Validation loss: 1.468156937629946

Epoch: 5| Step: 3
Training loss: 0.06762095540761948
Validation loss: 1.487944072292697

Epoch: 5| Step: 4
Training loss: 0.25889530777931213
Validation loss: 1.505222958903159

Epoch: 5| Step: 5
Training loss: 0.09660961478948593
Validation loss: 1.4998110366123978

Epoch: 5| Step: 6
Training loss: 0.1425555944442749
Validation loss: 1.4585906177438714

Epoch: 5| Step: 7
Training loss: 0.08149804174900055
Validation loss: 1.4764019225233345

Epoch: 5| Step: 8
Training loss: 0.1703561246395111
Validation loss: 1.4791839930319017

Epoch: 5| Step: 9
Training loss: 0.10443596541881561
Validation loss: 1.472691415458597

Epoch: 5| Step: 10
Training loss: 0.07251661270856857
Validation loss: 1.49813889175333

Epoch: 426| Step: 0
Training loss: 0.10574924945831299
Validation loss: 1.4713186294801774

Epoch: 5| Step: 1
Training loss: 0.07292208820581436
Validation loss: 1.4733447156926638

Epoch: 5| Step: 2
Training loss: 0.0741637796163559
Validation loss: 1.4859207689121205

Epoch: 5| Step: 3
Training loss: 0.06932035088539124
Validation loss: 1.5004587570826213

Epoch: 5| Step: 4
Training loss: 0.14789102971553802
Validation loss: 1.5061624844868977

Epoch: 5| Step: 5
Training loss: 0.29531046748161316
Validation loss: 1.4983658854679396

Epoch: 5| Step: 6
Training loss: 0.08579304069280624
Validation loss: 1.5120510849901425

Epoch: 5| Step: 7
Training loss: 0.06383158266544342
Validation loss: 1.5215239601750528

Epoch: 5| Step: 8
Training loss: 0.07313839346170425
Validation loss: 1.5004294751792826

Epoch: 5| Step: 9
Training loss: 0.0735098272562027
Validation loss: 1.5160833584365023

Epoch: 5| Step: 10
Training loss: 0.10240986198186874
Validation loss: 1.4917833497447353

Epoch: 427| Step: 0
Training loss: 0.06637255847454071
Validation loss: 1.5053161792857672

Epoch: 5| Step: 1
Training loss: 0.06655029207468033
Validation loss: 1.5033067708374352

Epoch: 5| Step: 2
Training loss: 0.19642958045005798
Validation loss: 1.492202607534265

Epoch: 5| Step: 3
Training loss: 0.06846638768911362
Validation loss: 1.5022240428514377

Epoch: 5| Step: 4
Training loss: 0.06176517531275749
Validation loss: 1.4728369841011621

Epoch: 5| Step: 5
Training loss: 0.0963471531867981
Validation loss: 1.4777089716285787

Epoch: 5| Step: 6
Training loss: 0.15992087125778198
Validation loss: 1.4938436554324241

Epoch: 5| Step: 7
Training loss: 0.09702388197183609
Validation loss: 1.497137435020939

Epoch: 5| Step: 8
Training loss: 0.11986446380615234
Validation loss: 1.4955673563864924

Epoch: 5| Step: 9
Training loss: 0.0950448289513588
Validation loss: 1.495703306249393

Epoch: 5| Step: 10
Training loss: 0.12914180755615234
Validation loss: 1.5260155406049503

Epoch: 428| Step: 0
Training loss: 0.10217420756816864
Validation loss: 1.533309935241617

Epoch: 5| Step: 1
Training loss: 0.1015806794166565
Validation loss: 1.5152703241635395

Epoch: 5| Step: 2
Training loss: 0.05369166284799576
Validation loss: 1.5021192912132508

Epoch: 5| Step: 3
Training loss: 0.19809198379516602
Validation loss: 1.534378206858071

Epoch: 5| Step: 4
Training loss: 0.11489979177713394
Validation loss: 1.5402335120785622

Epoch: 5| Step: 5
Training loss: 0.07348310202360153
Validation loss: 1.547364827125303

Epoch: 5| Step: 6
Training loss: 0.15921802818775177
Validation loss: 1.5705336960413123

Epoch: 5| Step: 7
Training loss: 0.23186218738555908
Validation loss: 1.5588094406230475

Epoch: 5| Step: 8
Training loss: 0.05893288925290108
Validation loss: 1.5486993276944725

Epoch: 5| Step: 9
Training loss: 0.109285369515419
Validation loss: 1.5534680120406612

Epoch: 5| Step: 10
Training loss: 0.12979190051555634
Validation loss: 1.5490400022076023

Epoch: 429| Step: 0
Training loss: 0.1457788497209549
Validation loss: 1.5430089401942428

Epoch: 5| Step: 1
Training loss: 0.1459573209285736
Validation loss: 1.5322822575928063

Epoch: 5| Step: 2
Training loss: 0.11785091459751129
Validation loss: 1.493668504299656

Epoch: 5| Step: 3
Training loss: 0.11647069454193115
Validation loss: 1.4725967145735217

Epoch: 5| Step: 4
Training loss: 0.1995590329170227
Validation loss: 1.4606439554563133

Epoch: 5| Step: 5
Training loss: 0.12742753326892853
Validation loss: 1.475326523985914

Epoch: 5| Step: 6
Training loss: 0.14783063530921936
Validation loss: 1.4699971842509445

Epoch: 5| Step: 7
Training loss: 0.13073834776878357
Validation loss: 1.472884069206894

Epoch: 5| Step: 8
Training loss: 0.08987123519182205
Validation loss: 1.459063107608467

Epoch: 5| Step: 9
Training loss: 0.23005108535289764
Validation loss: 1.4718953909412507

Epoch: 5| Step: 10
Training loss: 0.08234944194555283
Validation loss: 1.4896951824106195

Epoch: 430| Step: 0
Training loss: 0.1032121330499649
Validation loss: 1.491623446505557

Epoch: 5| Step: 1
Training loss: 0.19292011857032776
Validation loss: 1.496883633316204

Epoch: 5| Step: 2
Training loss: 0.10837532579898834
Validation loss: 1.5228250436885382

Epoch: 5| Step: 3
Training loss: 0.11734277009963989
Validation loss: 1.5424331349711264

Epoch: 5| Step: 4
Training loss: 0.09832483530044556
Validation loss: 1.5485697061784807

Epoch: 5| Step: 5
Training loss: 0.10547518730163574
Validation loss: 1.53775950272878

Epoch: 5| Step: 6
Training loss: 0.10946740210056305
Validation loss: 1.529456418047669

Epoch: 5| Step: 7
Training loss: 0.08434320241212845
Validation loss: 1.539235044551152

Epoch: 5| Step: 8
Training loss: 0.0693158283829689
Validation loss: 1.5372413089198451

Epoch: 5| Step: 9
Training loss: 0.07921534776687622
Validation loss: 1.5147658419865433

Epoch: 5| Step: 10
Training loss: 0.1869475394487381
Validation loss: 1.4877477038291194

Epoch: 431| Step: 0
Training loss: 0.20546218752861023
Validation loss: 1.4861313534039322

Epoch: 5| Step: 1
Training loss: 0.11166737973690033
Validation loss: 1.4832528393755677

Epoch: 5| Step: 2
Training loss: 0.0757341980934143
Validation loss: 1.4618950172137188

Epoch: 5| Step: 3
Training loss: 0.08442147076129913
Validation loss: 1.4718412968420214

Epoch: 5| Step: 4
Training loss: 0.0998532846570015
Validation loss: 1.4744080330735894

Epoch: 5| Step: 5
Training loss: 0.08544611185789108
Validation loss: 1.5016231729138283

Epoch: 5| Step: 6
Training loss: 0.18379738926887512
Validation loss: 1.4893513712831723

Epoch: 5| Step: 7
Training loss: 0.07726897299289703
Validation loss: 1.4815633412330382

Epoch: 5| Step: 8
Training loss: 0.06846263259649277
Validation loss: 1.4712919881266933

Epoch: 5| Step: 9
Training loss: 0.06221505254507065
Validation loss: 1.4880536628025833

Epoch: 5| Step: 10
Training loss: 0.08684289455413818
Validation loss: 1.4974794913363714

Epoch: 432| Step: 0
Training loss: 0.08904623240232468
Validation loss: 1.4916713955581828

Epoch: 5| Step: 1
Training loss: 0.08428144454956055
Validation loss: 1.5016593138376872

Epoch: 5| Step: 2
Training loss: 0.21577946841716766
Validation loss: 1.4953002275959137

Epoch: 5| Step: 3
Training loss: 0.06835653632879257
Validation loss: 1.4850740137920584

Epoch: 5| Step: 4
Training loss: 0.05904359742999077
Validation loss: 1.501409884422056

Epoch: 5| Step: 5
Training loss: 0.09123457968235016
Validation loss: 1.4983010702235724

Epoch: 5| Step: 6
Training loss: 0.09809869527816772
Validation loss: 1.4820415102025515

Epoch: 5| Step: 7
Training loss: 0.1448494791984558
Validation loss: 1.4800271641823552

Epoch: 5| Step: 8
Training loss: 0.05747269466519356
Validation loss: 1.4926383392785185

Epoch: 5| Step: 9
Training loss: 0.08422411978244781
Validation loss: 1.4801598031033751

Epoch: 5| Step: 10
Training loss: 0.1926056444644928
Validation loss: 1.4957614265462404

Epoch: 433| Step: 0
Training loss: 0.06691770255565643
Validation loss: 1.4889456123434088

Epoch: 5| Step: 1
Training loss: 0.17420651018619537
Validation loss: 1.4960613507096485

Epoch: 5| Step: 2
Training loss: 0.07693994045257568
Validation loss: 1.4798182287523824

Epoch: 5| Step: 3
Training loss: 0.09304334223270416
Validation loss: 1.4846270404836184

Epoch: 5| Step: 4
Training loss: 0.09135372191667557
Validation loss: 1.483997312925195

Epoch: 5| Step: 5
Training loss: 0.12052063643932343
Validation loss: 1.4867803665899462

Epoch: 5| Step: 6
Training loss: 0.09622667729854584
Validation loss: 1.4842868287076232

Epoch: 5| Step: 7
Training loss: 0.1825191229581833
Validation loss: 1.5005872557240147

Epoch: 5| Step: 8
Training loss: 0.07541616261005402
Validation loss: 1.5080086172267955

Epoch: 5| Step: 9
Training loss: 0.08472879230976105
Validation loss: 1.5024632407772927

Epoch: 5| Step: 10
Training loss: 0.0649041011929512
Validation loss: 1.4831916696281844

Epoch: 434| Step: 0
Training loss: 0.058676827698946
Validation loss: 1.4782255362438899

Epoch: 5| Step: 1
Training loss: 0.08281747996807098
Validation loss: 1.4879642648081626

Epoch: 5| Step: 2
Training loss: 0.07940546423196793
Validation loss: 1.4831842350703415

Epoch: 5| Step: 3
Training loss: 0.10690988600254059
Validation loss: 1.46688509884701

Epoch: 5| Step: 4
Training loss: 0.20605984330177307
Validation loss: 1.467093857385779

Epoch: 5| Step: 5
Training loss: 0.10596829652786255
Validation loss: 1.4937996082408453

Epoch: 5| Step: 6
Training loss: 0.1883140355348587
Validation loss: 1.4676793416341145

Epoch: 5| Step: 7
Training loss: 0.10994516313076019
Validation loss: 1.4622948682436379

Epoch: 5| Step: 8
Training loss: 0.07833677530288696
Validation loss: 1.4932806645670245

Epoch: 5| Step: 9
Training loss: 0.0962497889995575
Validation loss: 1.4896743336031515

Epoch: 5| Step: 10
Training loss: 0.11082692444324493
Validation loss: 1.4954635981590516

Epoch: 435| Step: 0
Training loss: 0.072799913585186
Validation loss: 1.5080843369166057

Epoch: 5| Step: 1
Training loss: 0.11829368025064468
Validation loss: 1.5152516980325021

Epoch: 5| Step: 2
Training loss: 0.09688694030046463
Validation loss: 1.5202590957764657

Epoch: 5| Step: 3
Training loss: 0.06712539494037628
Validation loss: 1.5192815206384147

Epoch: 5| Step: 4
Training loss: 0.21633648872375488
Validation loss: 1.5243835833764845

Epoch: 5| Step: 5
Training loss: 0.04752619192004204
Validation loss: 1.5195278070306266

Epoch: 5| Step: 6
Training loss: 0.0507478341460228
Validation loss: 1.4785015941948019

Epoch: 5| Step: 7
Training loss: 0.1908527910709381
Validation loss: 1.4961663664028209

Epoch: 5| Step: 8
Training loss: 0.1350199282169342
Validation loss: 1.4523127258464854

Epoch: 5| Step: 9
Training loss: 0.0790901780128479
Validation loss: 1.4733531135384754

Epoch: 5| Step: 10
Training loss: 0.0940280631184578
Validation loss: 1.4348808911538893

Epoch: 436| Step: 0
Training loss: 0.05951113626360893
Validation loss: 1.4394986898668352

Epoch: 5| Step: 1
Training loss: 0.06025812774896622
Validation loss: 1.4291022054610714

Epoch: 5| Step: 2
Training loss: 0.137778639793396
Validation loss: 1.4405838994569675

Epoch: 5| Step: 3
Training loss: 0.36682766675949097
Validation loss: 1.4392153819402058

Epoch: 5| Step: 4
Training loss: 0.06898326426744461
Validation loss: 1.418872304501072

Epoch: 5| Step: 5
Training loss: 0.05798610299825668
Validation loss: 1.4355166214768604

Epoch: 5| Step: 6
Training loss: 0.1512686312198639
Validation loss: 1.455147582997558

Epoch: 5| Step: 7
Training loss: 0.07243258506059647
Validation loss: 1.4828389677950131

Epoch: 5| Step: 8
Training loss: 0.12103094905614853
Validation loss: 1.4971638879468363

Epoch: 5| Step: 9
Training loss: 0.10838763415813446
Validation loss: 1.502947017710696

Epoch: 5| Step: 10
Training loss: 0.1465776562690735
Validation loss: 1.5170176657297278

Epoch: 437| Step: 0
Training loss: 0.09625299274921417
Validation loss: 1.5171399090879707

Epoch: 5| Step: 1
Training loss: 0.20556072890758514
Validation loss: 1.5463410167283909

Epoch: 5| Step: 2
Training loss: 0.16862590610980988
Validation loss: 1.5212503287100023

Epoch: 5| Step: 3
Training loss: 0.09576407819986343
Validation loss: 1.4790974586240706

Epoch: 5| Step: 4
Training loss: 0.17557553946971893
Validation loss: 1.4840221533211329

Epoch: 5| Step: 5
Training loss: 0.06352102756500244
Validation loss: 1.4780182415439236

Epoch: 5| Step: 6
Training loss: 0.0908355787396431
Validation loss: 1.4750899198234722

Epoch: 5| Step: 7
Training loss: 0.10298429429531097
Validation loss: 1.4779877226839784

Epoch: 5| Step: 8
Training loss: 0.06319429725408554
Validation loss: 1.465064760177366

Epoch: 5| Step: 9
Training loss: 0.10593235492706299
Validation loss: 1.4540468800452448

Epoch: 5| Step: 10
Training loss: 0.05752062425017357
Validation loss: 1.4735120983533962

Epoch: 438| Step: 0
Training loss: 0.06152825802564621
Validation loss: 1.4876755142724642

Epoch: 5| Step: 1
Training loss: 0.07083940505981445
Validation loss: 1.5185782242846746

Epoch: 5| Step: 2
Training loss: 0.06153985112905502
Validation loss: 1.5080905370814826

Epoch: 5| Step: 3
Training loss: 0.08505360782146454
Validation loss: 1.5154126792825677

Epoch: 5| Step: 4
Training loss: 0.09419181197881699
Validation loss: 1.5168456813340545

Epoch: 5| Step: 5
Training loss: 0.1612134724855423
Validation loss: 1.5248904382028887

Epoch: 5| Step: 6
Training loss: 0.14253540337085724
Validation loss: 1.5228958950247815

Epoch: 5| Step: 7
Training loss: 0.1970837414264679
Validation loss: 1.5103183407937326

Epoch: 5| Step: 8
Training loss: 0.07565726339817047
Validation loss: 1.4852400800233245

Epoch: 5| Step: 9
Training loss: 0.08375708758831024
Validation loss: 1.4828313730096305

Epoch: 5| Step: 10
Training loss: 0.050783801823854446
Validation loss: 1.4754329996724282

Epoch: 439| Step: 0
Training loss: 0.07219129055738449
Validation loss: 1.462210520621269

Epoch: 5| Step: 1
Training loss: 0.10351898521184921
Validation loss: 1.4508931047172957

Epoch: 5| Step: 2
Training loss: 0.10817594826221466
Validation loss: 1.4563126903708263

Epoch: 5| Step: 3
Training loss: 0.055766839534044266
Validation loss: 1.4349347955437117

Epoch: 5| Step: 4
Training loss: 0.1326887160539627
Validation loss: 1.4295133775280369

Epoch: 5| Step: 5
Training loss: 0.14697293937206268
Validation loss: 1.4255652927583264

Epoch: 5| Step: 6
Training loss: 0.06574729830026627
Validation loss: 1.4400518466067571

Epoch: 5| Step: 7
Training loss: 0.10201698541641235
Validation loss: 1.45780046268176

Epoch: 5| Step: 8
Training loss: 0.21357819437980652
Validation loss: 1.5134875518019482

Epoch: 5| Step: 9
Training loss: 0.09519336372613907
Validation loss: 1.5261747747339227

Epoch: 5| Step: 10
Training loss: 0.1974768489599228
Validation loss: 1.5196546726329352

Epoch: 440| Step: 0
Training loss: 0.09329278022050858
Validation loss: 1.5229839829988376

Epoch: 5| Step: 1
Training loss: 0.10998652130365372
Validation loss: 1.4898467935541624

Epoch: 5| Step: 2
Training loss: 0.1089954748749733
Validation loss: 1.500997939417439

Epoch: 5| Step: 3
Training loss: 0.13451504707336426
Validation loss: 1.499440925095671

Epoch: 5| Step: 4
Training loss: 0.1860416978597641
Validation loss: 1.4834558066501413

Epoch: 5| Step: 5
Training loss: 0.19106654822826385
Validation loss: 1.494655865494923

Epoch: 5| Step: 6
Training loss: 0.05907292291522026
Validation loss: 1.4790139377758067

Epoch: 5| Step: 7
Training loss: 0.09015057981014252
Validation loss: 1.5159534510745798

Epoch: 5| Step: 8
Training loss: 0.10889773070812225
Validation loss: 1.5038992192155571

Epoch: 5| Step: 9
Training loss: 0.09300732612609863
Validation loss: 1.5243515686322284

Epoch: 5| Step: 10
Training loss: 0.1334252804517746
Validation loss: 1.4885163807099866

Epoch: 441| Step: 0
Training loss: 0.11282812058925629
Validation loss: 1.4911679132010347

Epoch: 5| Step: 1
Training loss: 0.18248260021209717
Validation loss: 1.4716877898862284

Epoch: 5| Step: 2
Training loss: 0.07892995327711105
Validation loss: 1.4890777077726138

Epoch: 5| Step: 3
Training loss: 0.10468502342700958
Validation loss: 1.4952292673049434

Epoch: 5| Step: 4
Training loss: 0.10035165399312973
Validation loss: 1.5171222020221014

Epoch: 5| Step: 5
Training loss: 0.10465110838413239
Validation loss: 1.505040129025777

Epoch: 5| Step: 6
Training loss: 0.08494971692562103
Validation loss: 1.5207467258617442

Epoch: 5| Step: 7
Training loss: 0.12079181522130966
Validation loss: 1.528578301911713

Epoch: 5| Step: 8
Training loss: 0.17510050535202026
Validation loss: 1.543232947267512

Epoch: 5| Step: 9
Training loss: 0.11246819794178009
Validation loss: 1.5450925814208163

Epoch: 5| Step: 10
Training loss: 0.09792976081371307
Validation loss: 1.5481925895137172

Epoch: 442| Step: 0
Training loss: 0.06736993789672852
Validation loss: 1.5676960599037908

Epoch: 5| Step: 1
Training loss: 0.08642331510782242
Validation loss: 1.5408471322828723

Epoch: 5| Step: 2
Training loss: 0.18652312457561493
Validation loss: 1.5596671796614123

Epoch: 5| Step: 3
Training loss: 0.18860875070095062
Validation loss: 1.5607486706908031

Epoch: 5| Step: 4
Training loss: 0.10358746349811554
Validation loss: 1.536914949776024

Epoch: 5| Step: 5
Training loss: 0.08249638974666595
Validation loss: 1.5365151577098395

Epoch: 5| Step: 6
Training loss: 0.08530227094888687
Validation loss: 1.5023209805129676

Epoch: 5| Step: 7
Training loss: 0.05027121305465698
Validation loss: 1.4906611096474431

Epoch: 5| Step: 8
Training loss: 0.07398579269647598
Validation loss: 1.4709575663330734

Epoch: 5| Step: 9
Training loss: 0.07546903938055038
Validation loss: 1.4705845297023814

Epoch: 5| Step: 10
Training loss: 0.09455204755067825
Validation loss: 1.4543654444397136

Epoch: 443| Step: 0
Training loss: 0.15829142928123474
Validation loss: 1.4567794504986014

Epoch: 5| Step: 1
Training loss: 0.0948004424571991
Validation loss: 1.450045968255689

Epoch: 5| Step: 2
Training loss: 0.17323723435401917
Validation loss: 1.4641133585283834

Epoch: 5| Step: 3
Training loss: 0.10440311580896378
Validation loss: 1.4683432373949277

Epoch: 5| Step: 4
Training loss: 0.12582997977733612
Validation loss: 1.439000011772238

Epoch: 5| Step: 5
Training loss: 0.09103654325008392
Validation loss: 1.4472076123760593

Epoch: 5| Step: 6
Training loss: 0.07487492263317108
Validation loss: 1.4454596952725483

Epoch: 5| Step: 7
Training loss: 0.08780773729085922
Validation loss: 1.4664266301739601

Epoch: 5| Step: 8
Training loss: 0.11197278648614883
Validation loss: 1.4559672519724856

Epoch: 5| Step: 9
Training loss: 0.08834584802389145
Validation loss: 1.4614058181803713

Epoch: 5| Step: 10
Training loss: 0.09036893397569656
Validation loss: 1.4865383076411423

Epoch: 444| Step: 0
Training loss: 0.05886251851916313
Validation loss: 1.459021032497447

Epoch: 5| Step: 1
Training loss: 0.045554790645837784
Validation loss: 1.4737697826918734

Epoch: 5| Step: 2
Training loss: 0.08862056583166122
Validation loss: 1.4773809102273756

Epoch: 5| Step: 3
Training loss: 0.10271843522787094
Validation loss: 1.471083761543356

Epoch: 5| Step: 4
Training loss: 0.18377867341041565
Validation loss: 1.4876359085882864

Epoch: 5| Step: 5
Training loss: 0.08966077864170074
Validation loss: 1.48020052653487

Epoch: 5| Step: 6
Training loss: 0.09859516471624374
Validation loss: 1.4670171712034492

Epoch: 5| Step: 7
Training loss: 0.1331174224615097
Validation loss: 1.4604573044725644

Epoch: 5| Step: 8
Training loss: 0.06801903247833252
Validation loss: 1.4555139182716288

Epoch: 5| Step: 9
Training loss: 0.17866499722003937
Validation loss: 1.4774530690203431

Epoch: 5| Step: 10
Training loss: 0.08047737926244736
Validation loss: 1.4783678670083322

Epoch: 445| Step: 0
Training loss: 0.1310228854417801
Validation loss: 1.4948567754478865

Epoch: 5| Step: 1
Training loss: 0.08032650500535965
Validation loss: 1.474114001438182

Epoch: 5| Step: 2
Training loss: 0.20729537308216095
Validation loss: 1.4852613684951619

Epoch: 5| Step: 3
Training loss: 0.14712536334991455
Validation loss: 1.5089021933976041

Epoch: 5| Step: 4
Training loss: 0.09924145042896271
Validation loss: 1.492325339266049

Epoch: 5| Step: 5
Training loss: 0.06254265457391739
Validation loss: 1.4928339514681088

Epoch: 5| Step: 6
Training loss: 0.10357789695262909
Validation loss: 1.5161629953692037

Epoch: 5| Step: 7
Training loss: 0.12378571927547455
Validation loss: 1.5251530985678396

Epoch: 5| Step: 8
Training loss: 0.21916286647319794
Validation loss: 1.5229634495191677

Epoch: 5| Step: 9
Training loss: 0.1732158213853836
Validation loss: 1.523674564976846

Epoch: 5| Step: 10
Training loss: 0.10374987870454788
Validation loss: 1.5062691806465067

Epoch: 446| Step: 0
Training loss: 0.09150036424398422
Validation loss: 1.4836433254262453

Epoch: 5| Step: 1
Training loss: 0.10051743686199188
Validation loss: 1.4846406188062442

Epoch: 5| Step: 2
Training loss: 0.07372166216373444
Validation loss: 1.4649817084753385

Epoch: 5| Step: 3
Training loss: 0.11066421121358871
Validation loss: 1.4438429417148713

Epoch: 5| Step: 4
Training loss: 0.19453644752502441
Validation loss: 1.4797610352116246

Epoch: 5| Step: 5
Training loss: 0.0649050921201706
Validation loss: 1.4652340335230674

Epoch: 5| Step: 6
Training loss: 0.1786448210477829
Validation loss: 1.4370002490217968

Epoch: 5| Step: 7
Training loss: 0.07546047121286392
Validation loss: 1.4424266763912734

Epoch: 5| Step: 8
Training loss: 0.08711652457714081
Validation loss: 1.4370219399852138

Epoch: 5| Step: 9
Training loss: 0.0999612957239151
Validation loss: 1.4690594903884395

Epoch: 5| Step: 10
Training loss: 0.07574596256017685
Validation loss: 1.4619043181019444

Epoch: 447| Step: 0
Training loss: 0.0941867083311081
Validation loss: 1.4766963630594232

Epoch: 5| Step: 1
Training loss: 0.1872042864561081
Validation loss: 1.4851412824405137

Epoch: 5| Step: 2
Training loss: 0.0687117949128151
Validation loss: 1.5022772178854993

Epoch: 5| Step: 3
Training loss: 0.07829881459474564
Validation loss: 1.4861102911733812

Epoch: 5| Step: 4
Training loss: 0.05498740077018738
Validation loss: 1.5299829077977005

Epoch: 5| Step: 5
Training loss: 0.12090454250574112
Validation loss: 1.5293058554331462

Epoch: 5| Step: 6
Training loss: 0.11432409286499023
Validation loss: 1.537158502045498

Epoch: 5| Step: 7
Training loss: 0.1321270763874054
Validation loss: 1.5604556055479153

Epoch: 5| Step: 8
Training loss: 0.34240278601646423
Validation loss: 1.5757366393202095

Epoch: 5| Step: 9
Training loss: 0.1358778029680252
Validation loss: 1.545312523841858

Epoch: 5| Step: 10
Training loss: 0.07400798797607422
Validation loss: 1.528472706835757

Epoch: 448| Step: 0
Training loss: 0.2933396100997925
Validation loss: 1.4786302735728603

Epoch: 5| Step: 1
Training loss: 0.09512448310852051
Validation loss: 1.5009081235495947

Epoch: 5| Step: 2
Training loss: 0.08907584846019745
Validation loss: 1.4824703072988858

Epoch: 5| Step: 3
Training loss: 0.1706903874874115
Validation loss: 1.4947306712468464

Epoch: 5| Step: 4
Training loss: 0.11535372585058212
Validation loss: 1.4781762117980628

Epoch: 5| Step: 5
Training loss: 0.08992622792720795
Validation loss: 1.479550100141956

Epoch: 5| Step: 6
Training loss: 0.10024192184209824
Validation loss: 1.5157811872420772

Epoch: 5| Step: 7
Training loss: 0.12969598174095154
Validation loss: 1.5139503043184999

Epoch: 5| Step: 8
Training loss: 0.09663138538599014
Validation loss: 1.5205633768471338

Epoch: 5| Step: 9
Training loss: 0.10317258536815643
Validation loss: 1.5434358748056556

Epoch: 5| Step: 10
Training loss: 0.11179833859205246
Validation loss: 1.5178654046468838

Epoch: 449| Step: 0
Training loss: 0.11756990104913712
Validation loss: 1.5297073510385328

Epoch: 5| Step: 1
Training loss: 0.18138551712036133
Validation loss: 1.5160934335442

Epoch: 5| Step: 2
Training loss: 0.06437287479639053
Validation loss: 1.515582166692262

Epoch: 5| Step: 3
Training loss: 0.08154664933681488
Validation loss: 1.5114218573416434

Epoch: 5| Step: 4
Training loss: 0.0850847139954567
Validation loss: 1.5042643623967324

Epoch: 5| Step: 5
Training loss: 0.12869493663311005
Validation loss: 1.524655584366091

Epoch: 5| Step: 6
Training loss: 0.07200641930103302
Validation loss: 1.5306597807074105

Epoch: 5| Step: 7
Training loss: 0.09186214208602905
Validation loss: 1.524810997388696

Epoch: 5| Step: 8
Training loss: 0.19728420674800873
Validation loss: 1.5403445177180792

Epoch: 5| Step: 9
Training loss: 0.11025039851665497
Validation loss: 1.5096681400011944

Epoch: 5| Step: 10
Training loss: 0.05203988030552864
Validation loss: 1.5093753581405969

Epoch: 450| Step: 0
Training loss: 0.11076369136571884
Validation loss: 1.478305665395593

Epoch: 5| Step: 1
Training loss: 0.19034545123577118
Validation loss: 1.4796177700001707

Epoch: 5| Step: 2
Training loss: 0.045853618532419205
Validation loss: 1.4922843825432561

Epoch: 5| Step: 3
Training loss: 0.10894725471735
Validation loss: 1.4897608692928026

Epoch: 5| Step: 4
Training loss: 0.07614942640066147
Validation loss: 1.490791097764046

Epoch: 5| Step: 5
Training loss: 0.09027749300003052
Validation loss: 1.5108600624146

Epoch: 5| Step: 6
Training loss: 0.17563936114311218
Validation loss: 1.4991057393371419

Epoch: 5| Step: 7
Training loss: 0.09151019155979156
Validation loss: 1.5064813911273915

Epoch: 5| Step: 8
Training loss: 0.07299073785543442
Validation loss: 1.4954275418353338

Epoch: 5| Step: 9
Training loss: 0.08954145014286041
Validation loss: 1.4997173035016624

Epoch: 5| Step: 10
Training loss: 0.06483855098485947
Validation loss: 1.5040970668997815

Epoch: 451| Step: 0
Training loss: 0.05156346410512924
Validation loss: 1.4729723033084665

Epoch: 5| Step: 1
Training loss: 0.061922766268253326
Validation loss: 1.4770729054686844

Epoch: 5| Step: 2
Training loss: 0.1507631242275238
Validation loss: 1.4761137103521695

Epoch: 5| Step: 3
Training loss: 0.0862208679318428
Validation loss: 1.5012795508548777

Epoch: 5| Step: 4
Training loss: 0.16699494421482086
Validation loss: 1.5065606794049662

Epoch: 5| Step: 5
Training loss: 0.09672688692808151
Validation loss: 1.5074952071712864

Epoch: 5| Step: 6
Training loss: 0.075016550719738
Validation loss: 1.460763971010844

Epoch: 5| Step: 7
Training loss: 0.08620412647724152
Validation loss: 1.5007701009832404

Epoch: 5| Step: 8
Training loss: 0.14747729897499084
Validation loss: 1.492246893144423

Epoch: 5| Step: 9
Training loss: 0.07321292161941528
Validation loss: 1.518457438997043

Epoch: 5| Step: 10
Training loss: 0.10032521933317184
Validation loss: 1.5101504953958655

Epoch: 452| Step: 0
Training loss: 0.06771369278430939
Validation loss: 1.5406879519903531

Epoch: 5| Step: 1
Training loss: 0.08459506928920746
Validation loss: 1.522039810816447

Epoch: 5| Step: 2
Training loss: 0.06625209003686905
Validation loss: 1.5259082932626047

Epoch: 5| Step: 3
Training loss: 0.08131931722164154
Validation loss: 1.5171821566038235

Epoch: 5| Step: 4
Training loss: 0.12285922467708588
Validation loss: 1.5082727497623813

Epoch: 5| Step: 5
Training loss: 0.1862940490245819
Validation loss: 1.5187546771059754

Epoch: 5| Step: 6
Training loss: 0.07640714943408966
Validation loss: 1.5293019067856573

Epoch: 5| Step: 7
Training loss: 0.10376985371112823
Validation loss: 1.5226376454035442

Epoch: 5| Step: 8
Training loss: 0.07985883951187134
Validation loss: 1.4974510317207665

Epoch: 5| Step: 9
Training loss: 0.15138395130634308
Validation loss: 1.5048529947957685

Epoch: 5| Step: 10
Training loss: 0.0670209601521492
Validation loss: 1.4722986823769026

Epoch: 453| Step: 0
Training loss: 0.0728457048535347
Validation loss: 1.4735554572074645

Epoch: 5| Step: 1
Training loss: 0.09864732623100281
Validation loss: 1.4743362959995066

Epoch: 5| Step: 2
Training loss: 0.08565561473369598
Validation loss: 1.465818916597674

Epoch: 5| Step: 3
Training loss: 0.1114635244011879
Validation loss: 1.4612979773552186

Epoch: 5| Step: 4
Training loss: 0.09831540286540985
Validation loss: 1.4580100749128608

Epoch: 5| Step: 5
Training loss: 0.10663143545389175
Validation loss: 1.437473637442435

Epoch: 5| Step: 6
Training loss: 0.10301367193460464
Validation loss: 1.4557694388974098

Epoch: 5| Step: 7
Training loss: 0.09171942621469498
Validation loss: 1.4749324885747765

Epoch: 5| Step: 8
Training loss: 0.3110937178134918
Validation loss: 1.4778594483611405

Epoch: 5| Step: 9
Training loss: 0.09093155711889267
Validation loss: 1.4867672215225876

Epoch: 5| Step: 10
Training loss: 0.05824122205376625
Validation loss: 1.4763486340481748

Epoch: 454| Step: 0
Training loss: 0.05169478803873062
Validation loss: 1.496097267314952

Epoch: 5| Step: 1
Training loss: 0.1550932675600052
Validation loss: 1.502949465987503

Epoch: 5| Step: 2
Training loss: 0.0570937879383564
Validation loss: 1.5144080833722187

Epoch: 5| Step: 3
Training loss: 0.0626041516661644
Validation loss: 1.5035626849820536

Epoch: 5| Step: 4
Training loss: 0.05995103716850281
Validation loss: 1.4814296819830453

Epoch: 5| Step: 5
Training loss: 0.10475514084100723
Validation loss: 1.507989449526674

Epoch: 5| Step: 6
Training loss: 0.08611847460269928
Validation loss: 1.4679974279096049

Epoch: 5| Step: 7
Training loss: 0.2086782455444336
Validation loss: 1.4659508735902849

Epoch: 5| Step: 8
Training loss: 0.0647302195429802
Validation loss: 1.471707033854659

Epoch: 5| Step: 9
Training loss: 0.1055879145860672
Validation loss: 1.44623040768408

Epoch: 5| Step: 10
Training loss: 0.11380401253700256
Validation loss: 1.4501820559142737

Epoch: 455| Step: 0
Training loss: 0.09460962563753128
Validation loss: 1.4763014534468293

Epoch: 5| Step: 1
Training loss: 0.06451255083084106
Validation loss: 1.449214130319575

Epoch: 5| Step: 2
Training loss: 0.07632331550121307
Validation loss: 1.464783348062987

Epoch: 5| Step: 3
Training loss: 0.0750449150800705
Validation loss: 1.4629597753606818

Epoch: 5| Step: 4
Training loss: 0.20811757445335388
Validation loss: 1.4628061658592635

Epoch: 5| Step: 5
Training loss: 0.06576523929834366
Validation loss: 1.4618364751979869

Epoch: 5| Step: 6
Training loss: 0.09131163358688354
Validation loss: 1.4740925629933674

Epoch: 5| Step: 7
Training loss: 0.16841575503349304
Validation loss: 1.4616501356965752

Epoch: 5| Step: 8
Training loss: 0.09746921807527542
Validation loss: 1.502143471471725

Epoch: 5| Step: 9
Training loss: 0.07411618530750275
Validation loss: 1.4800399157308763

Epoch: 5| Step: 10
Training loss: 0.07283564656972885
Validation loss: 1.4769763741441952

Epoch: 456| Step: 0
Training loss: 0.06943941116333008
Validation loss: 1.4812859950527069

Epoch: 5| Step: 1
Training loss: 0.07905862480401993
Validation loss: 1.4974311474830873

Epoch: 5| Step: 2
Training loss: 0.10284797847270966
Validation loss: 1.5015115353368944

Epoch: 5| Step: 3
Training loss: 0.17817887663841248
Validation loss: 1.5297548604267899

Epoch: 5| Step: 4
Training loss: 0.06178766489028931
Validation loss: 1.5094477213839048

Epoch: 5| Step: 5
Training loss: 0.08273956924676895
Validation loss: 1.5051018281649517

Epoch: 5| Step: 6
Training loss: 0.06745172291994095
Validation loss: 1.5032577399284608

Epoch: 5| Step: 7
Training loss: 0.04861015826463699
Validation loss: 1.4913160954752276

Epoch: 5| Step: 8
Training loss: 0.08145309239625931
Validation loss: 1.4727362868606404

Epoch: 5| Step: 9
Training loss: 0.16798365116119385
Validation loss: 1.4880361915916525

Epoch: 5| Step: 10
Training loss: 0.14213386178016663
Validation loss: 1.497976638296599

Epoch: 457| Step: 0
Training loss: 0.08102545142173767
Validation loss: 1.482786263189008

Epoch: 5| Step: 1
Training loss: 0.06527489423751831
Validation loss: 1.449037758893864

Epoch: 5| Step: 2
Training loss: 0.055443473160266876
Validation loss: 1.456198025775212

Epoch: 5| Step: 3
Training loss: 0.07025010138750076
Validation loss: 1.4603833395947692

Epoch: 5| Step: 4
Training loss: 0.11109913885593414
Validation loss: 1.4329784698383783

Epoch: 5| Step: 5
Training loss: 0.15574339032173157
Validation loss: 1.4300753608826668

Epoch: 5| Step: 6
Training loss: 0.1001017838716507
Validation loss: 1.4562332489157235

Epoch: 5| Step: 7
Training loss: 0.13997593522071838
Validation loss: 1.45607275988466

Epoch: 5| Step: 8
Training loss: 0.06380932033061981
Validation loss: 1.4583659966786702

Epoch: 5| Step: 9
Training loss: 0.10167582333087921
Validation loss: 1.458174350441143

Epoch: 5| Step: 10
Training loss: 0.19507236778736115
Validation loss: 1.4875632998763875

Epoch: 458| Step: 0
Training loss: 0.11477835476398468
Validation loss: 1.4791105639549993

Epoch: 5| Step: 1
Training loss: 0.1300460398197174
Validation loss: 1.4958179612313547

Epoch: 5| Step: 2
Training loss: 0.05721285939216614
Validation loss: 1.5005525324934272

Epoch: 5| Step: 3
Training loss: 0.11610893905162811
Validation loss: 1.5014582782663324

Epoch: 5| Step: 4
Training loss: 0.20412687957286835
Validation loss: 1.5095623231703235

Epoch: 5| Step: 5
Training loss: 0.1841065138578415
Validation loss: 1.5149174505664456

Epoch: 5| Step: 6
Training loss: 0.07879623770713806
Validation loss: 1.4921565901848577

Epoch: 5| Step: 7
Training loss: 0.06459708511829376
Validation loss: 1.4874177799429944

Epoch: 5| Step: 8
Training loss: 0.08557002246379852
Validation loss: 1.4795789667355117

Epoch: 5| Step: 9
Training loss: 0.07873546332120895
Validation loss: 1.4636856689248035

Epoch: 5| Step: 10
Training loss: 0.12550029158592224
Validation loss: 1.475216495093479

Epoch: 459| Step: 0
Training loss: 0.17365872859954834
Validation loss: 1.4687921808611961

Epoch: 5| Step: 1
Training loss: 0.09413476288318634
Validation loss: 1.4895085750087615

Epoch: 5| Step: 2
Training loss: 0.07315616309642792
Validation loss: 1.4571670665535876

Epoch: 5| Step: 3
Training loss: 0.05645192787051201
Validation loss: 1.450592129461227

Epoch: 5| Step: 4
Training loss: 0.13671474158763885
Validation loss: 1.4606733770780667

Epoch: 5| Step: 5
Training loss: 0.06758357584476471
Validation loss: 1.4523290357282084

Epoch: 5| Step: 6
Training loss: 0.07724227011203766
Validation loss: 1.4535536996779903

Epoch: 5| Step: 7
Training loss: 0.09718169271945953
Validation loss: 1.4602325167707217

Epoch: 5| Step: 8
Training loss: 0.10326800495386124
Validation loss: 1.48175980711496

Epoch: 5| Step: 9
Training loss: 0.06374993920326233
Validation loss: 1.454138296906666

Epoch: 5| Step: 10
Training loss: 0.0746816024184227
Validation loss: 1.4593652845710836

Epoch: 460| Step: 0
Training loss: 0.0639488697052002
Validation loss: 1.461780527586578

Epoch: 5| Step: 1
Training loss: 0.057136137038469315
Validation loss: 1.471014566318963

Epoch: 5| Step: 2
Training loss: 0.14314614236354828
Validation loss: 1.466612647938472

Epoch: 5| Step: 3
Training loss: 0.1446744203567505
Validation loss: 1.478104914388349

Epoch: 5| Step: 4
Training loss: 0.09738655388355255
Validation loss: 1.4686198631922405

Epoch: 5| Step: 5
Training loss: 0.06612490117549896
Validation loss: 1.46737043575574

Epoch: 5| Step: 6
Training loss: 0.08564787358045578
Validation loss: 1.4720836192049005

Epoch: 5| Step: 7
Training loss: 0.09732300043106079
Validation loss: 1.4926061604612617

Epoch: 5| Step: 8
Training loss: 0.04935692995786667
Validation loss: 1.4920991248981927

Epoch: 5| Step: 9
Training loss: 0.0651063546538353
Validation loss: 1.5088730448035783

Epoch: 5| Step: 10
Training loss: 0.0740552544593811
Validation loss: 1.4938360670561432

Epoch: 461| Step: 0
Training loss: 0.06332442909479141
Validation loss: 1.5166138295204408

Epoch: 5| Step: 1
Training loss: 0.17452022433280945
Validation loss: 1.5069335019716652

Epoch: 5| Step: 2
Training loss: 0.0740942731499672
Validation loss: 1.476460123574862

Epoch: 5| Step: 3
Training loss: 0.06110553815960884
Validation loss: 1.4514115638630365

Epoch: 5| Step: 4
Training loss: 0.06403028219938278
Validation loss: 1.4677299696912047

Epoch: 5| Step: 5
Training loss: 0.08061090111732483
Validation loss: 1.4743096315732567

Epoch: 5| Step: 6
Training loss: 0.08409872651100159
Validation loss: 1.47701975991649

Epoch: 5| Step: 7
Training loss: 0.07976724207401276
Validation loss: 1.4620838139646797

Epoch: 5| Step: 8
Training loss: 0.09522553533315659
Validation loss: 1.4583379325046335

Epoch: 5| Step: 9
Training loss: 0.16883356869220734
Validation loss: 1.4528789866355158

Epoch: 5| Step: 10
Training loss: 0.049943022429943085
Validation loss: 1.4553617713271931

Epoch: 462| Step: 0
Training loss: 0.10032252222299576
Validation loss: 1.4554631235778972

Epoch: 5| Step: 1
Training loss: 0.09239386022090912
Validation loss: 1.4564217700753161

Epoch: 5| Step: 2
Training loss: 0.06920526921749115
Validation loss: 1.4341888139324803

Epoch: 5| Step: 3
Training loss: 0.07345646619796753
Validation loss: 1.4297935116675593

Epoch: 5| Step: 4
Training loss: 0.08070926368236542
Validation loss: 1.4416686463099655

Epoch: 5| Step: 5
Training loss: 0.16189444065093994
Validation loss: 1.465443285562659

Epoch: 5| Step: 6
Training loss: 0.07190187275409698
Validation loss: 1.4617671043642106

Epoch: 5| Step: 7
Training loss: 0.08698849380016327
Validation loss: 1.4937508926596692

Epoch: 5| Step: 8
Training loss: 0.08127032220363617
Validation loss: 1.4680761034770677

Epoch: 5| Step: 9
Training loss: 0.18894045054912567
Validation loss: 1.487861943501298

Epoch: 5| Step: 10
Training loss: 0.055820927023887634
Validation loss: 1.4651048567987257

Epoch: 463| Step: 0
Training loss: 0.1716276854276657
Validation loss: 1.472770626826953

Epoch: 5| Step: 1
Training loss: 0.07914792001247406
Validation loss: 1.4587510266611654

Epoch: 5| Step: 2
Training loss: 0.07286892831325531
Validation loss: 1.4514247461031842

Epoch: 5| Step: 3
Training loss: 0.04332370311021805
Validation loss: 1.447183075771537

Epoch: 5| Step: 4
Training loss: 0.0516044907271862
Validation loss: 1.4436599285371843

Epoch: 5| Step: 5
Training loss: 0.0984484851360321
Validation loss: 1.4704401685345558

Epoch: 5| Step: 6
Training loss: 0.05564039200544357
Validation loss: 1.4376516213981054

Epoch: 5| Step: 7
Training loss: 0.08982431143522263
Validation loss: 1.4161302389637116

Epoch: 5| Step: 8
Training loss: 0.08653564751148224
Validation loss: 1.4437686627910984

Epoch: 5| Step: 9
Training loss: 0.14936697483062744
Validation loss: 1.4395709986327796

Epoch: 5| Step: 10
Training loss: 0.23858295381069183
Validation loss: 1.4307894963090138

Epoch: 464| Step: 0
Training loss: 0.05325032398104668
Validation loss: 1.4434376121849142

Epoch: 5| Step: 1
Training loss: 0.062364447861909866
Validation loss: 1.4235640225871917

Epoch: 5| Step: 2
Training loss: 0.08903290331363678
Validation loss: 1.432727877811719

Epoch: 5| Step: 3
Training loss: 0.07237667590379715
Validation loss: 1.4462633376480432

Epoch: 5| Step: 4
Training loss: 0.1917089968919754
Validation loss: 1.436043438091073

Epoch: 5| Step: 5
Training loss: 0.09465301781892776
Validation loss: 1.4725438766582037

Epoch: 5| Step: 6
Training loss: 0.18300579488277435
Validation loss: 1.4649242739523611

Epoch: 5| Step: 7
Training loss: 0.049190957099199295
Validation loss: 1.4500803050174509

Epoch: 5| Step: 8
Training loss: 0.07194717228412628
Validation loss: 1.454907710834216

Epoch: 5| Step: 9
Training loss: 0.06723970919847488
Validation loss: 1.4544002484249812

Epoch: 5| Step: 10
Training loss: 0.06128423288464546
Validation loss: 1.4364706611120572

Epoch: 465| Step: 0
Training loss: 0.09174390137195587
Validation loss: 1.4577021553952207

Epoch: 5| Step: 1
Training loss: 0.14060036838054657
Validation loss: 1.4385758907564226

Epoch: 5| Step: 2
Training loss: 0.05869493633508682
Validation loss: 1.4637658878039288

Epoch: 5| Step: 3
Training loss: 0.04728618264198303
Validation loss: 1.4637779228148922

Epoch: 5| Step: 4
Training loss: 0.07167179882526398
Validation loss: 1.4440662604506298

Epoch: 5| Step: 5
Training loss: 0.10364161431789398
Validation loss: 1.4641557329444475

Epoch: 5| Step: 6
Training loss: 0.1722119152545929
Validation loss: 1.4543724175422423

Epoch: 5| Step: 7
Training loss: 0.07362640649080276
Validation loss: 1.4346222550638261

Epoch: 5| Step: 8
Training loss: 0.07560546696186066
Validation loss: 1.443695108095805

Epoch: 5| Step: 9
Training loss: 0.06958401203155518
Validation loss: 1.450603287707093

Epoch: 5| Step: 10
Training loss: 0.042125154286623
Validation loss: 1.4448341438847203

Epoch: 466| Step: 0
Training loss: 0.0714782178401947
Validation loss: 1.4453721046447754

Epoch: 5| Step: 1
Training loss: 0.06414390355348587
Validation loss: 1.4722153576471473

Epoch: 5| Step: 2
Training loss: 0.09869231283664703
Validation loss: 1.4636566741492159

Epoch: 5| Step: 3
Training loss: 0.07199247926473618
Validation loss: 1.4873470523024117

Epoch: 5| Step: 4
Training loss: 0.0772821456193924
Validation loss: 1.4501513306812575

Epoch: 5| Step: 5
Training loss: 0.060118891298770905
Validation loss: 1.4316734626729002

Epoch: 5| Step: 6
Training loss: 0.09399471431970596
Validation loss: 1.4520594022607292

Epoch: 5| Step: 7
Training loss: 0.23610416054725647
Validation loss: 1.4665305896471905

Epoch: 5| Step: 8
Training loss: 0.06774649769067764
Validation loss: 1.4804689538094304

Epoch: 5| Step: 9
Training loss: 0.06092347949743271
Validation loss: 1.4518344094676356

Epoch: 5| Step: 10
Training loss: 0.05210118368268013
Validation loss: 1.4453677246647496

Epoch: 467| Step: 0
Training loss: 0.04948689416050911
Validation loss: 1.4620560484547769

Epoch: 5| Step: 1
Training loss: 0.06319420039653778
Validation loss: 1.441851399278128

Epoch: 5| Step: 2
Training loss: 0.07576113939285278
Validation loss: 1.447434252308261

Epoch: 5| Step: 3
Training loss: 0.04484174773097038
Validation loss: 1.4445867435906523

Epoch: 5| Step: 4
Training loss: 0.07700972259044647
Validation loss: 1.444533671102216

Epoch: 5| Step: 5
Training loss: 0.03726387768983841
Validation loss: 1.4197633343358194

Epoch: 5| Step: 6
Training loss: 0.15449345111846924
Validation loss: 1.4574519613737702

Epoch: 5| Step: 7
Training loss: 0.16407671570777893
Validation loss: 1.453305036149999

Epoch: 5| Step: 8
Training loss: 0.09650427848100662
Validation loss: 1.4371274491792083

Epoch: 5| Step: 9
Training loss: 0.09483233094215393
Validation loss: 1.459311125099018

Epoch: 5| Step: 10
Training loss: 0.08899715542793274
Validation loss: 1.4433384864561019

Epoch: 468| Step: 0
Training loss: 0.15641433000564575
Validation loss: 1.4431733803082538

Epoch: 5| Step: 1
Training loss: 0.0960635170340538
Validation loss: 1.4252152558295959

Epoch: 5| Step: 2
Training loss: 0.08303506672382355
Validation loss: 1.437858312360702

Epoch: 5| Step: 3
Training loss: 0.072191521525383
Validation loss: 1.4287244254542935

Epoch: 5| Step: 4
Training loss: 0.08182132244110107
Validation loss: 1.4490098132882068

Epoch: 5| Step: 5
Training loss: 0.17761221528053284
Validation loss: 1.4398689757111252

Epoch: 5| Step: 6
Training loss: 0.08947210758924484
Validation loss: 1.4424082143332368

Epoch: 5| Step: 7
Training loss: 0.07581856101751328
Validation loss: 1.4760630912678216

Epoch: 5| Step: 8
Training loss: 0.07276200503110886
Validation loss: 1.475687321796212

Epoch: 5| Step: 9
Training loss: 0.07844538986682892
Validation loss: 1.4839774357375277

Epoch: 5| Step: 10
Training loss: 0.03536393493413925
Validation loss: 1.502239877177823

Epoch: 469| Step: 0
Training loss: 0.07678131759166718
Validation loss: 1.495662990436759

Epoch: 5| Step: 1
Training loss: 0.17067137360572815
Validation loss: 1.5134208753544798

Epoch: 5| Step: 2
Training loss: 0.08129364252090454
Validation loss: 1.4844792299373175

Epoch: 5| Step: 3
Training loss: 0.07815725356340408
Validation loss: 1.4793524716490059

Epoch: 5| Step: 4
Training loss: 0.05947469547390938
Validation loss: 1.4782104928006408

Epoch: 5| Step: 5
Training loss: 0.09367598593235016
Validation loss: 1.4676637636717929

Epoch: 5| Step: 6
Training loss: 0.1583864539861679
Validation loss: 1.4579516380063948

Epoch: 5| Step: 7
Training loss: 0.05174709111452103
Validation loss: 1.4411805791239585

Epoch: 5| Step: 8
Training loss: 0.14181537926197052
Validation loss: 1.4410469262830672

Epoch: 5| Step: 9
Training loss: 0.07349452376365662
Validation loss: 1.4161609770149313

Epoch: 5| Step: 10
Training loss: 0.07945892214775085
Validation loss: 1.4164436555677844

Epoch: 470| Step: 0
Training loss: 0.07047697901725769
Validation loss: 1.4549143698907667

Epoch: 5| Step: 1
Training loss: 0.19725307822227478
Validation loss: 1.434159331424262

Epoch: 5| Step: 2
Training loss: 0.07432111352682114
Validation loss: 1.4323329335899764

Epoch: 5| Step: 3
Training loss: 0.06914738565683365
Validation loss: 1.4320232842558174

Epoch: 5| Step: 4
Training loss: 0.09607386589050293
Validation loss: 1.4354565822949974

Epoch: 5| Step: 5
Training loss: 0.09537520259618759
Validation loss: 1.467726566458261

Epoch: 5| Step: 6
Training loss: 0.04897133260965347
Validation loss: 1.4273156632659256

Epoch: 5| Step: 7
Training loss: 0.10338258743286133
Validation loss: 1.446464729565446

Epoch: 5| Step: 8
Training loss: 0.07811157405376434
Validation loss: 1.4508569753298195

Epoch: 5| Step: 9
Training loss: 0.09591257572174072
Validation loss: 1.432338668454078

Epoch: 5| Step: 10
Training loss: 0.18247924745082855
Validation loss: 1.4777418349378852

Epoch: 471| Step: 0
Training loss: 0.1352512240409851
Validation loss: 1.4544427567912686

Epoch: 5| Step: 1
Training loss: 0.23437127470970154
Validation loss: 1.4407153206486856

Epoch: 5| Step: 2
Training loss: 0.10534882545471191
Validation loss: 1.4649614800689041

Epoch: 5| Step: 3
Training loss: 0.08368809521198273
Validation loss: 1.4733189985316286

Epoch: 5| Step: 4
Training loss: 0.10087238252162933
Validation loss: 1.4509263307817521

Epoch: 5| Step: 5
Training loss: 0.1156381368637085
Validation loss: 1.4732562047179028

Epoch: 5| Step: 6
Training loss: 0.07866266369819641
Validation loss: 1.4907550888676797

Epoch: 5| Step: 7
Training loss: 0.1266670823097229
Validation loss: 1.4590331854358796

Epoch: 5| Step: 8
Training loss: 0.06587211042642593
Validation loss: 1.4783733749902377

Epoch: 5| Step: 9
Training loss: 0.06175835803151131
Validation loss: 1.4723692722218011

Epoch: 5| Step: 10
Training loss: 0.16413845121860504
Validation loss: 1.469272308452155

Epoch: 472| Step: 0
Training loss: 0.1635400950908661
Validation loss: 1.4720002015431721

Epoch: 5| Step: 1
Training loss: 0.12537150084972382
Validation loss: 1.4677913291479951

Epoch: 5| Step: 2
Training loss: 0.20331338047981262
Validation loss: 1.436650433847981

Epoch: 5| Step: 3
Training loss: 0.10049964487552643
Validation loss: 1.471315001928678

Epoch: 5| Step: 4
Training loss: 0.07376205176115036
Validation loss: 1.4269968027709632

Epoch: 5| Step: 5
Training loss: 0.10518145561218262
Validation loss: 1.4335718680453557

Epoch: 5| Step: 6
Training loss: 0.07465512305498123
Validation loss: 1.437226467235114

Epoch: 5| Step: 7
Training loss: 0.16554982960224152
Validation loss: 1.4152951009811894

Epoch: 5| Step: 8
Training loss: 0.05017634481191635
Validation loss: 1.4551749652431858

Epoch: 5| Step: 9
Training loss: 0.06876172870397568
Validation loss: 1.4423094257231681

Epoch: 5| Step: 10
Training loss: 0.05576976761221886
Validation loss: 1.4170547980134205

Epoch: 473| Step: 0
Training loss: 0.0905844196677208
Validation loss: 1.4573849016620266

Epoch: 5| Step: 1
Training loss: 0.07141818851232529
Validation loss: 1.4629514037921865

Epoch: 5| Step: 2
Training loss: 0.08391992747783661
Validation loss: 1.4772966677142727

Epoch: 5| Step: 3
Training loss: 0.06957748532295227
Validation loss: 1.4587038306779758

Epoch: 5| Step: 4
Training loss: 0.0651378184556961
Validation loss: 1.465128831965949

Epoch: 5| Step: 5
Training loss: 0.07229940593242645
Validation loss: 1.4518461086416756

Epoch: 5| Step: 6
Training loss: 0.0568547248840332
Validation loss: 1.4457479484619633

Epoch: 5| Step: 7
Training loss: 0.11408033221960068
Validation loss: 1.437671592158656

Epoch: 5| Step: 8
Training loss: 0.16336528956890106
Validation loss: 1.4368081656835412

Epoch: 5| Step: 9
Training loss: 0.06685955822467804
Validation loss: 1.4394368971547773

Epoch: 5| Step: 10
Training loss: 0.06542623788118362
Validation loss: 1.454098924513786

Epoch: 474| Step: 0
Training loss: 0.14489474892616272
Validation loss: 1.4554089359057847

Epoch: 5| Step: 1
Training loss: 0.06564357876777649
Validation loss: 1.4333069721857707

Epoch: 5| Step: 2
Training loss: 0.15877249836921692
Validation loss: 1.4300371639190181

Epoch: 5| Step: 3
Training loss: 0.06653865426778793
Validation loss: 1.4419097541480936

Epoch: 5| Step: 4
Training loss: 0.08591816574335098
Validation loss: 1.4315900680839375

Epoch: 5| Step: 5
Training loss: 0.06473000347614288
Validation loss: 1.4253741630943872

Epoch: 5| Step: 6
Training loss: 0.05827249959111214
Validation loss: 1.4038117495916222

Epoch: 5| Step: 7
Training loss: 0.05106079578399658
Validation loss: 1.4497280595123128

Epoch: 5| Step: 8
Training loss: 0.051517337560653687
Validation loss: 1.4371001387155184

Epoch: 5| Step: 9
Training loss: 0.06081299111247063
Validation loss: 1.4531840073165072

Epoch: 5| Step: 10
Training loss: 0.11180339008569717
Validation loss: 1.4459542535966443

Epoch: 475| Step: 0
Training loss: 0.05300723388791084
Validation loss: 1.455155541819911

Epoch: 5| Step: 1
Training loss: 0.07261484861373901
Validation loss: 1.4731406652799217

Epoch: 5| Step: 2
Training loss: 0.0830736979842186
Validation loss: 1.4720645412322013

Epoch: 5| Step: 3
Training loss: 0.1018831729888916
Validation loss: 1.4638087749481201

Epoch: 5| Step: 4
Training loss: 0.07987931370735168
Validation loss: 1.4609591601997294

Epoch: 5| Step: 5
Training loss: 0.13044677674770355
Validation loss: 1.4690743928314538

Epoch: 5| Step: 6
Training loss: 0.168000727891922
Validation loss: 1.4800189925778298

Epoch: 5| Step: 7
Training loss: 0.0605241060256958
Validation loss: 1.4585299511109628

Epoch: 5| Step: 8
Training loss: 0.08978575468063354
Validation loss: 1.466201275907537

Epoch: 5| Step: 9
Training loss: 0.0543353371322155
Validation loss: 1.442775591727226

Epoch: 5| Step: 10
Training loss: 0.08248982578516006
Validation loss: 1.4138571434123541

Epoch: 476| Step: 0
Training loss: 0.06271340698003769
Validation loss: 1.4182925672941311

Epoch: 5| Step: 1
Training loss: 0.06770171970129013
Validation loss: 1.4362939467994116

Epoch: 5| Step: 2
Training loss: 0.053928572684526443
Validation loss: 1.4335681328209497

Epoch: 5| Step: 3
Training loss: 0.08532863110303879
Validation loss: 1.4095710131429857

Epoch: 5| Step: 4
Training loss: 0.15908817946910858
Validation loss: 1.407703576549407

Epoch: 5| Step: 5
Training loss: 0.05503803491592407
Validation loss: 1.3903715918141026

Epoch: 5| Step: 6
Training loss: 0.09745803475379944
Validation loss: 1.3720152224263837

Epoch: 5| Step: 7
Training loss: 0.14812225103378296
Validation loss: 1.350486828434852

Epoch: 5| Step: 8
Training loss: 0.08704887330532074
Validation loss: 1.4060123485903586

Epoch: 5| Step: 9
Training loss: 0.07973504066467285
Validation loss: 1.3651033755271667

Epoch: 5| Step: 10
Training loss: 0.06930162012577057
Validation loss: 1.3861644575672765

Epoch: 477| Step: 0
Training loss: 0.05978628993034363
Validation loss: 1.38664650019779

Epoch: 5| Step: 1
Training loss: 0.05858951061964035
Validation loss: 1.4117291685073607

Epoch: 5| Step: 2
Training loss: 0.06325031816959381
Validation loss: 1.3854824701944988

Epoch: 5| Step: 3
Training loss: 0.09157834947109222
Validation loss: 1.4058361566194923

Epoch: 5| Step: 4
Training loss: 0.046746887266635895
Validation loss: 1.4118839354925259

Epoch: 5| Step: 5
Training loss: 0.08524705469608307
Validation loss: 1.4319784615629463

Epoch: 5| Step: 6
Training loss: 0.0769532173871994
Validation loss: 1.4358841712756822

Epoch: 5| Step: 7
Training loss: 0.21417203545570374
Validation loss: 1.4306218329296316

Epoch: 5| Step: 8
Training loss: 0.11421706527471542
Validation loss: 1.4386030403516625

Epoch: 5| Step: 9
Training loss: 0.06757096201181412
Validation loss: 1.4433080124598678

Epoch: 5| Step: 10
Training loss: 0.08036927878856659
Validation loss: 1.4413115516785653

Epoch: 478| Step: 0
Training loss: 0.1806551069021225
Validation loss: 1.4547904806752359

Epoch: 5| Step: 1
Training loss: 0.07417383044958115
Validation loss: 1.4361743055364138

Epoch: 5| Step: 2
Training loss: 0.05322752520442009
Validation loss: 1.445100079300583

Epoch: 5| Step: 3
Training loss: 0.0786169022321701
Validation loss: 1.4578854794143348

Epoch: 5| Step: 4
Training loss: 0.0554393045604229
Validation loss: 1.4450216908608713

Epoch: 5| Step: 5
Training loss: 0.06127768009901047
Validation loss: 1.4360344115123953

Epoch: 5| Step: 6
Training loss: 0.08942467719316483
Validation loss: 1.4552155707472114

Epoch: 5| Step: 7
Training loss: 0.053589772433042526
Validation loss: 1.4455741772087671

Epoch: 5| Step: 8
Training loss: 0.07220739126205444
Validation loss: 1.4424802475078131

Epoch: 5| Step: 9
Training loss: 0.04857436195015907
Validation loss: 1.4262214758062874

Epoch: 5| Step: 10
Training loss: 0.18813948333263397
Validation loss: 1.4258927196584723

Epoch: 479| Step: 0
Training loss: 0.1333894431591034
Validation loss: 1.417221196236149

Epoch: 5| Step: 1
Training loss: 0.06621504575014114
Validation loss: 1.4425061389964113

Epoch: 5| Step: 2
Training loss: 0.061559148132801056
Validation loss: 1.4408493631629533

Epoch: 5| Step: 3
Training loss: 0.06935202330350876
Validation loss: 1.4410971178803393

Epoch: 5| Step: 4
Training loss: 0.07151488959789276
Validation loss: 1.4491876652163844

Epoch: 5| Step: 5
Training loss: 0.07233725488185883
Validation loss: 1.4525837975163614

Epoch: 5| Step: 6
Training loss: 0.07389016449451447
Validation loss: 1.4423809218150314

Epoch: 5| Step: 7
Training loss: 0.07670846581459045
Validation loss: 1.4389608803615774

Epoch: 5| Step: 8
Training loss: 0.1368144303560257
Validation loss: 1.445903749876125

Epoch: 5| Step: 9
Training loss: 0.09302304685115814
Validation loss: 1.4552537792472429

Epoch: 5| Step: 10
Training loss: 0.044267863035202026
Validation loss: 1.437191495331385

Epoch: 480| Step: 0
Training loss: 0.048277031630277634
Validation loss: 1.4630556728250237

Epoch: 5| Step: 1
Training loss: 0.08954477310180664
Validation loss: 1.443246760675984

Epoch: 5| Step: 2
Training loss: 0.060758840292692184
Validation loss: 1.470039221548265

Epoch: 5| Step: 3
Training loss: 0.1691824495792389
Validation loss: 1.4746304096714142

Epoch: 5| Step: 4
Training loss: 0.06890246272087097
Validation loss: 1.4691999125224289

Epoch: 5| Step: 5
Training loss: 0.1354854702949524
Validation loss: 1.4733275085367181

Epoch: 5| Step: 6
Training loss: 0.08387388288974762
Validation loss: 1.4849194095980736

Epoch: 5| Step: 7
Training loss: 0.056743036955595016
Validation loss: 1.4765838128264233

Epoch: 5| Step: 8
Training loss: 0.07046639919281006
Validation loss: 1.4636651290360319

Epoch: 5| Step: 9
Training loss: 0.04618488997220993
Validation loss: 1.4694102707729544

Epoch: 5| Step: 10
Training loss: 0.06479062885046005
Validation loss: 1.4954871733983357

Epoch: 481| Step: 0
Training loss: 0.059022240340709686
Validation loss: 1.4649341388415265

Epoch: 5| Step: 1
Training loss: 0.08517441898584366
Validation loss: 1.467927796225394

Epoch: 5| Step: 2
Training loss: 0.071337029337883
Validation loss: 1.4679651901286135

Epoch: 5| Step: 3
Training loss: 0.15908539295196533
Validation loss: 1.4628939788828614

Epoch: 5| Step: 4
Training loss: 0.17806820571422577
Validation loss: 1.4580087174651444

Epoch: 5| Step: 5
Training loss: 0.07443612068891525
Validation loss: 1.4763930433539934

Epoch: 5| Step: 6
Training loss: 0.06591781228780746
Validation loss: 1.4748124678929646

Epoch: 5| Step: 7
Training loss: 0.0753517597913742
Validation loss: 1.460194763316903

Epoch: 5| Step: 8
Training loss: 0.0374629981815815
Validation loss: 1.4667399826870169

Epoch: 5| Step: 9
Training loss: 0.0648694857954979
Validation loss: 1.455811018584877

Epoch: 5| Step: 10
Training loss: 0.06306574493646622
Validation loss: 1.4675697306151032

Epoch: 482| Step: 0
Training loss: 0.09997747838497162
Validation loss: 1.4824628394137147

Epoch: 5| Step: 1
Training loss: 0.0653374120593071
Validation loss: 1.4597310391805505

Epoch: 5| Step: 2
Training loss: 0.0833650454878807
Validation loss: 1.4491081583884455

Epoch: 5| Step: 3
Training loss: 0.16446354985237122
Validation loss: 1.4679764868110738

Epoch: 5| Step: 4
Training loss: 0.06759177893400192
Validation loss: 1.4405269917621408

Epoch: 5| Step: 5
Training loss: 0.07551263272762299
Validation loss: 1.456399295919685

Epoch: 5| Step: 6
Training loss: 0.17551898956298828
Validation loss: 1.4338287884189236

Epoch: 5| Step: 7
Training loss: 0.07293234765529633
Validation loss: 1.4537419273007302

Epoch: 5| Step: 8
Training loss: 0.05562550947070122
Validation loss: 1.4381093684063162

Epoch: 5| Step: 9
Training loss: 0.10288938134908676
Validation loss: 1.4560505908022645

Epoch: 5| Step: 10
Training loss: 0.08162111788988113
Validation loss: 1.435517975079116

Epoch: 483| Step: 0
Training loss: 0.0723838210105896
Validation loss: 1.4412612113901364

Epoch: 5| Step: 1
Training loss: 0.21752305328845978
Validation loss: 1.4508612232823526

Epoch: 5| Step: 2
Training loss: 0.12584231793880463
Validation loss: 1.4218852109806512

Epoch: 5| Step: 3
Training loss: 0.17297257483005524
Validation loss: 1.4354825513337248

Epoch: 5| Step: 4
Training loss: 0.06969074159860611
Validation loss: 1.4445832506302865

Epoch: 5| Step: 5
Training loss: 0.09708206355571747
Validation loss: 1.429868241792084

Epoch: 5| Step: 6
Training loss: 0.06393884122371674
Validation loss: 1.4540531007192468

Epoch: 5| Step: 7
Training loss: 0.08423082530498505
Validation loss: 1.485606688325123

Epoch: 5| Step: 8
Training loss: 0.1303577423095703
Validation loss: 1.4870148909989225

Epoch: 5| Step: 9
Training loss: 0.08827182650566101
Validation loss: 1.4696659721354002

Epoch: 5| Step: 10
Training loss: 0.037759993225336075
Validation loss: 1.4812212477448166

Epoch: 484| Step: 0
Training loss: 0.07930514216423035
Validation loss: 1.4708114465077717

Epoch: 5| Step: 1
Training loss: 0.1806725710630417
Validation loss: 1.4899095873678885

Epoch: 5| Step: 2
Training loss: 0.06259818375110626
Validation loss: 1.4743898632705852

Epoch: 5| Step: 3
Training loss: 0.05729098245501518
Validation loss: 1.464090629290509

Epoch: 5| Step: 4
Training loss: 0.06205355003476143
Validation loss: 1.4674131498541882

Epoch: 5| Step: 5
Training loss: 0.07195569574832916
Validation loss: 1.4646780003783524

Epoch: 5| Step: 6
Training loss: 0.07047484815120697
Validation loss: 1.448172826279876

Epoch: 5| Step: 7
Training loss: 0.09526775032281876
Validation loss: 1.4618013930577103

Epoch: 5| Step: 8
Training loss: 0.18917155265808105
Validation loss: 1.4674894450813212

Epoch: 5| Step: 9
Training loss: 0.10122320801019669
Validation loss: 1.4563733967401649

Epoch: 5| Step: 10
Training loss: 0.06229684501886368
Validation loss: 1.4524333451383857

Epoch: 485| Step: 0
Training loss: 0.16362422704696655
Validation loss: 1.4445691236885645

Epoch: 5| Step: 1
Training loss: 0.087208092212677
Validation loss: 1.4459023091100878

Epoch: 5| Step: 2
Training loss: 0.16178688406944275
Validation loss: 1.4061271849498953

Epoch: 5| Step: 3
Training loss: 0.08526724576950073
Validation loss: 1.4386073132996917

Epoch: 5| Step: 4
Training loss: 0.06786766648292542
Validation loss: 1.4120317287342523

Epoch: 5| Step: 5
Training loss: 0.07531000673770905
Validation loss: 1.425054964198861

Epoch: 5| Step: 6
Training loss: 0.07401295006275177
Validation loss: 1.4292231766126489

Epoch: 5| Step: 7
Training loss: 0.09360744804143906
Validation loss: 1.4367813576934159

Epoch: 5| Step: 8
Training loss: 0.07691329717636108
Validation loss: 1.4658333998854443

Epoch: 5| Step: 9
Training loss: 0.06828571110963821
Validation loss: 1.4326383516352663

Epoch: 5| Step: 10
Training loss: 0.06254951655864716
Validation loss: 1.4402859877514582

Epoch: 486| Step: 0
Training loss: 0.051646292209625244
Validation loss: 1.4635522057933192

Epoch: 5| Step: 1
Training loss: 0.116346076130867
Validation loss: 1.4582714137210642

Epoch: 5| Step: 2
Training loss: 0.06791311502456665
Validation loss: 1.4466882944107056

Epoch: 5| Step: 3
Training loss: 0.08960004150867462
Validation loss: 1.457560581545676

Epoch: 5| Step: 4
Training loss: 0.10400994122028351
Validation loss: 1.4551112856916202

Epoch: 5| Step: 5
Training loss: 0.07641187310218811
Validation loss: 1.4507629756004579

Epoch: 5| Step: 6
Training loss: 0.1563868522644043
Validation loss: 1.4696937594362485

Epoch: 5| Step: 7
Training loss: 0.1443740427494049
Validation loss: 1.4605887718098138

Epoch: 5| Step: 8
Training loss: 0.059660185128450394
Validation loss: 1.4527580263794109

Epoch: 5| Step: 9
Training loss: 0.10485343635082245
Validation loss: 1.4393444766280472

Epoch: 5| Step: 10
Training loss: 0.0510198250412941
Validation loss: 1.4366779968302736

Epoch: 487| Step: 0
Training loss: 0.06588244438171387
Validation loss: 1.4380819387333368

Epoch: 5| Step: 1
Training loss: 0.047893743962049484
Validation loss: 1.457576701717992

Epoch: 5| Step: 2
Training loss: 0.06018756702542305
Validation loss: 1.4339774552211966

Epoch: 5| Step: 3
Training loss: 0.17808952927589417
Validation loss: 1.4624246538326304

Epoch: 5| Step: 4
Training loss: 0.07587817311286926
Validation loss: 1.4551830278929843

Epoch: 5| Step: 5
Training loss: 0.13860321044921875
Validation loss: 1.4440461422807427

Epoch: 5| Step: 6
Training loss: 0.05115490034222603
Validation loss: 1.472473402177134

Epoch: 5| Step: 7
Training loss: 0.11501172930002213
Validation loss: 1.4485117889219714

Epoch: 5| Step: 8
Training loss: 0.040491458028554916
Validation loss: 1.4703351066958519

Epoch: 5| Step: 9
Training loss: 0.08202848583459854
Validation loss: 1.4360379403637302

Epoch: 5| Step: 10
Training loss: 0.0877881720662117
Validation loss: 1.4521020625227241

Epoch: 488| Step: 0
Training loss: 0.06517763435840607
Validation loss: 1.4673842473696637

Epoch: 5| Step: 1
Training loss: 0.07322043925523758
Validation loss: 1.4571435041325067

Epoch: 5| Step: 2
Training loss: 0.07591471821069717
Validation loss: 1.4698846122269988

Epoch: 5| Step: 3
Training loss: 0.0745452269911766
Validation loss: 1.456279234219623

Epoch: 5| Step: 4
Training loss: 0.07197680324316025
Validation loss: 1.4618189463051416

Epoch: 5| Step: 5
Training loss: 0.054930973798036575
Validation loss: 1.4731665163911798

Epoch: 5| Step: 6
Training loss: 0.06070665270090103
Validation loss: 1.4733387116462953

Epoch: 5| Step: 7
Training loss: 0.08303231000900269
Validation loss: 1.445681429678394

Epoch: 5| Step: 8
Training loss: 0.23410841822624207
Validation loss: 1.459200853942543

Epoch: 5| Step: 9
Training loss: 0.08241678774356842
Validation loss: 1.4466512382671397

Epoch: 5| Step: 10
Training loss: 0.03823701664805412
Validation loss: 1.4338280834177488

Epoch: 489| Step: 0
Training loss: 0.056470680981874466
Validation loss: 1.432709264498885

Epoch: 5| Step: 1
Training loss: 0.14586308598518372
Validation loss: 1.4480205261579124

Epoch: 5| Step: 2
Training loss: 0.04735863208770752
Validation loss: 1.4205530548608432

Epoch: 5| Step: 3
Training loss: 0.15069304406642914
Validation loss: 1.432063054012996

Epoch: 5| Step: 4
Training loss: 0.039758697152137756
Validation loss: 1.4316719770431519

Epoch: 5| Step: 5
Training loss: 0.07730339467525482
Validation loss: 1.4363555792839295

Epoch: 5| Step: 6
Training loss: 0.07364411652088165
Validation loss: 1.4353145553219704

Epoch: 5| Step: 7
Training loss: 0.056669820100069046
Validation loss: 1.4288362867088729

Epoch: 5| Step: 8
Training loss: 0.1034940853714943
Validation loss: 1.4320662226728214

Epoch: 5| Step: 9
Training loss: 0.0687578096985817
Validation loss: 1.450017390712615

Epoch: 5| Step: 10
Training loss: 0.08081474900245667
Validation loss: 1.4541208026229695

Epoch: 490| Step: 0
Training loss: 0.06520461291074753
Validation loss: 1.4511712225534583

Epoch: 5| Step: 1
Training loss: 0.06933774054050446
Validation loss: 1.4574836736084313

Epoch: 5| Step: 2
Training loss: 0.09051947295665741
Validation loss: 1.4698641107928367

Epoch: 5| Step: 3
Training loss: 0.05755732208490372
Validation loss: 1.4697400369951803

Epoch: 5| Step: 4
Training loss: 0.054439567029476166
Validation loss: 1.4582514942333262

Epoch: 5| Step: 5
Training loss: 0.056202929466962814
Validation loss: 1.4484021843120616

Epoch: 5| Step: 6
Training loss: 0.0766134113073349
Validation loss: 1.452635783021168

Epoch: 5| Step: 7
Training loss: 0.08500196784734726
Validation loss: 1.4282865665292228

Epoch: 5| Step: 8
Training loss: 0.1478220671415329
Validation loss: 1.4187437206186273

Epoch: 5| Step: 9
Training loss: 0.0650450736284256
Validation loss: 1.4282769362131755

Epoch: 5| Step: 10
Training loss: 0.14669358730316162
Validation loss: 1.4397265629101825

Epoch: 491| Step: 0
Training loss: 0.09287343174219131
Validation loss: 1.4296355503861622

Epoch: 5| Step: 1
Training loss: 0.03801889345049858
Validation loss: 1.4163354833920796

Epoch: 5| Step: 2
Training loss: 0.06669823080301285
Validation loss: 1.4206845452708583

Epoch: 5| Step: 3
Training loss: 0.0741637796163559
Validation loss: 1.4314981378534788

Epoch: 5| Step: 4
Training loss: 0.06933305412530899
Validation loss: 1.4233701831551009

Epoch: 5| Step: 5
Training loss: 0.05989251285791397
Validation loss: 1.4358698398836198

Epoch: 5| Step: 6
Training loss: 0.041440773755311966
Validation loss: 1.4394436472205705

Epoch: 5| Step: 7
Training loss: 0.044961147010326385
Validation loss: 1.4445575206510481

Epoch: 5| Step: 8
Training loss: 0.12291522324085236
Validation loss: 1.4406647131007204

Epoch: 5| Step: 9
Training loss: 0.13774406909942627
Validation loss: 1.4654123321656258

Epoch: 5| Step: 10
Training loss: 0.07218477874994278
Validation loss: 1.4557780245298981

Epoch: 492| Step: 0
Training loss: 0.12915560603141785
Validation loss: 1.44377944033633

Epoch: 5| Step: 1
Training loss: 0.08767534792423248
Validation loss: 1.467198332150777

Epoch: 5| Step: 2
Training loss: 0.05193310230970383
Validation loss: 1.4441860439956828

Epoch: 5| Step: 3
Training loss: 0.1565101593732834
Validation loss: 1.470082265074535

Epoch: 5| Step: 4
Training loss: 0.05137906223535538
Validation loss: 1.470393184692629

Epoch: 5| Step: 5
Training loss: 0.05174212530255318
Validation loss: 1.4520467442850913

Epoch: 5| Step: 6
Training loss: 0.0647687315940857
Validation loss: 1.4538957970116728

Epoch: 5| Step: 7
Training loss: 0.06250260770320892
Validation loss: 1.4467679697980163

Epoch: 5| Step: 8
Training loss: 0.08318968117237091
Validation loss: 1.4603002968654837

Epoch: 5| Step: 9
Training loss: 0.08512119948863983
Validation loss: 1.4542322953542073

Epoch: 5| Step: 10
Training loss: 0.07667141407728195
Validation loss: 1.4275380590910554

Epoch: 493| Step: 0
Training loss: 0.04074593260884285
Validation loss: 1.4366257331704582

Epoch: 5| Step: 1
Training loss: 0.19468623399734497
Validation loss: 1.439382169836311

Epoch: 5| Step: 2
Training loss: 0.0712524875998497
Validation loss: 1.416084200464269

Epoch: 5| Step: 3
Training loss: 0.053279340267181396
Validation loss: 1.4277274236884168

Epoch: 5| Step: 4
Training loss: 0.07085580378770828
Validation loss: 1.4161146097285773

Epoch: 5| Step: 5
Training loss: 0.05100433900952339
Validation loss: 1.4286934566754166

Epoch: 5| Step: 6
Training loss: 0.06431221961975098
Validation loss: 1.4218492315661522

Epoch: 5| Step: 7
Training loss: 0.05854389816522598
Validation loss: 1.4210685222379622

Epoch: 5| Step: 8
Training loss: 0.06398096680641174
Validation loss: 1.434506949558053

Epoch: 5| Step: 9
Training loss: 0.0777856633067131
Validation loss: 1.4324956670884164

Epoch: 5| Step: 10
Training loss: 0.13684117794036865
Validation loss: 1.4539429231356549

Epoch: 494| Step: 0
Training loss: 0.17620530724525452
Validation loss: 1.4276472894094323

Epoch: 5| Step: 1
Training loss: 0.15839414298534393
Validation loss: 1.4377828849259244

Epoch: 5| Step: 2
Training loss: 0.06287004798650742
Validation loss: 1.4183621124554706

Epoch: 5| Step: 3
Training loss: 0.08103839308023453
Validation loss: 1.4465234625724055

Epoch: 5| Step: 4
Training loss: 0.053735263645648956
Validation loss: 1.4329387180266842

Epoch: 5| Step: 5
Training loss: 0.04195385053753853
Validation loss: 1.453966094601539

Epoch: 5| Step: 6
Training loss: 0.04389423877000809
Validation loss: 1.455131442957027

Epoch: 5| Step: 7
Training loss: 0.04990909621119499
Validation loss: 1.4558900210165209

Epoch: 5| Step: 8
Training loss: 0.03525174409151077
Validation loss: 1.4490302929314234

Epoch: 5| Step: 9
Training loss: 0.040084294974803925
Validation loss: 1.4714962859307565

Epoch: 5| Step: 10
Training loss: 0.1078663170337677
Validation loss: 1.4633695374252975

Epoch: 495| Step: 0
Training loss: 0.04449647292494774
Validation loss: 1.459038366553604

Epoch: 5| Step: 1
Training loss: 0.08378125727176666
Validation loss: 1.4407712592873523

Epoch: 5| Step: 2
Training loss: 0.05221991986036301
Validation loss: 1.44722241996437

Epoch: 5| Step: 3
Training loss: 0.11829332262277603
Validation loss: 1.439942749597693

Epoch: 5| Step: 4
Training loss: 0.04393206909298897
Validation loss: 1.4688792177425918

Epoch: 5| Step: 5
Training loss: 0.0687793642282486
Validation loss: 1.4353720885451122

Epoch: 5| Step: 6
Training loss: 0.05200537294149399
Validation loss: 1.4351916120898338

Epoch: 5| Step: 7
Training loss: 0.1649339497089386
Validation loss: 1.4351650021409477

Epoch: 5| Step: 8
Training loss: 0.07833407819271088
Validation loss: 1.4576387584850352

Epoch: 5| Step: 9
Training loss: 0.10035796463489532
Validation loss: 1.4410781302759725

Epoch: 5| Step: 10
Training loss: 0.0709889680147171
Validation loss: 1.452321147405973

Epoch: 496| Step: 0
Training loss: 0.036542341113090515
Validation loss: 1.4546093838189238

Epoch: 5| Step: 1
Training loss: 0.06787522882223129
Validation loss: 1.4439428993450698

Epoch: 5| Step: 2
Training loss: 0.06682824343442917
Validation loss: 1.4371255469578568

Epoch: 5| Step: 3
Training loss: 0.05491884425282478
Validation loss: 1.4300651934839064

Epoch: 5| Step: 4
Training loss: 0.15896514058113098
Validation loss: 1.4293952398402716

Epoch: 5| Step: 5
Training loss: 0.132658451795578
Validation loss: 1.4496843943031885

Epoch: 5| Step: 6
Training loss: 0.09696196764707565
Validation loss: 1.454961895942688

Epoch: 5| Step: 7
Training loss: 0.04094323143362999
Validation loss: 1.459782301738698

Epoch: 5| Step: 8
Training loss: 0.08683745563030243
Validation loss: 1.4916792069711993

Epoch: 5| Step: 9
Training loss: 0.04599154740571976
Validation loss: 1.4525832155699372

Epoch: 5| Step: 10
Training loss: 0.08370258659124374
Validation loss: 1.4665369141486384

Epoch: 497| Step: 0
Training loss: 0.061677731573581696
Validation loss: 1.4755758085558492

Epoch: 5| Step: 1
Training loss: 0.14033426344394684
Validation loss: 1.473810980396886

Epoch: 5| Step: 2
Training loss: 0.04681650921702385
Validation loss: 1.483052384468817

Epoch: 5| Step: 3
Training loss: 0.05721741169691086
Validation loss: 1.478434052518619

Epoch: 5| Step: 4
Training loss: 0.1596117615699768
Validation loss: 1.474404097885214

Epoch: 5| Step: 5
Training loss: 0.0871497392654419
Validation loss: 1.4780991731151458

Epoch: 5| Step: 6
Training loss: 0.08343169838190079
Validation loss: 1.4984472156852804

Epoch: 5| Step: 7
Training loss: 0.08369464427232742
Validation loss: 1.4823613141172676

Epoch: 5| Step: 8
Training loss: 0.07530660927295685
Validation loss: 1.4820090634848482

Epoch: 5| Step: 9
Training loss: 0.05034036561846733
Validation loss: 1.462525083172706

Epoch: 5| Step: 10
Training loss: 0.1007683128118515
Validation loss: 1.4609586570852546

Epoch: 498| Step: 0
Training loss: 0.12157205492258072
Validation loss: 1.4363136124867264

Epoch: 5| Step: 1
Training loss: 0.07837675511837006
Validation loss: 1.422908979077493

Epoch: 5| Step: 2
Training loss: 0.07393354177474976
Validation loss: 1.4558500295044274

Epoch: 5| Step: 3
Training loss: 0.08024267107248306
Validation loss: 1.4360621988132436

Epoch: 5| Step: 4
Training loss: 0.1480746567249298
Validation loss: 1.408145103403317

Epoch: 5| Step: 5
Training loss: 0.06318317353725433
Validation loss: 1.4197423829827258

Epoch: 5| Step: 6
Training loss: 0.04992563650012016
Validation loss: 1.411841880890631

Epoch: 5| Step: 7
Training loss: 0.0831514447927475
Validation loss: 1.3964064416065012

Epoch: 5| Step: 8
Training loss: 0.04413190484046936
Validation loss: 1.4130851376441218

Epoch: 5| Step: 9
Training loss: 0.06367652118206024
Validation loss: 1.3961948143538607

Epoch: 5| Step: 10
Training loss: 0.08994191884994507
Validation loss: 1.401708915669431

Epoch: 499| Step: 0
Training loss: 0.049182381480932236
Validation loss: 1.400672338342154

Epoch: 5| Step: 1
Training loss: 0.09073944389820099
Validation loss: 1.4169847978058683

Epoch: 5| Step: 2
Training loss: 0.06156112626194954
Validation loss: 1.402307539857844

Epoch: 5| Step: 3
Training loss: 0.08409228175878525
Validation loss: 1.3981255600529332

Epoch: 5| Step: 4
Training loss: 0.1678028255701065
Validation loss: 1.4148604921115342

Epoch: 5| Step: 5
Training loss: 0.1698414832353592
Validation loss: 1.4196550692281416

Epoch: 5| Step: 6
Training loss: 0.07760895043611526
Validation loss: 1.412008297699754

Epoch: 5| Step: 7
Training loss: 0.08392477035522461
Validation loss: 1.3896061656295613

Epoch: 5| Step: 8
Training loss: 0.0585603341460228
Validation loss: 1.4029218458360242

Epoch: 5| Step: 9
Training loss: 0.06860604137182236
Validation loss: 1.3943441253836437

Epoch: 5| Step: 10
Training loss: 0.08464764058589935
Validation loss: 1.4105192685639987

Epoch: 500| Step: 0
Training loss: 0.04637498781085014
Validation loss: 1.408393717581226

Epoch: 5| Step: 1
Training loss: 0.05708037689328194
Validation loss: 1.4298664190435921

Epoch: 5| Step: 2
Training loss: 0.0698724165558815
Validation loss: 1.4314242216848558

Epoch: 5| Step: 3
Training loss: 0.05848800390958786
Validation loss: 1.4501068361343876

Epoch: 5| Step: 4
Training loss: 0.15523065626621246
Validation loss: 1.4506029390519666

Epoch: 5| Step: 5
Training loss: 0.08216982334852219
Validation loss: 1.4458621612159155

Epoch: 5| Step: 6
Training loss: 0.12869402766227722
Validation loss: 1.4603045909635481

Epoch: 5| Step: 7
Training loss: 0.04920462518930435
Validation loss: 1.4621300646053847

Epoch: 5| Step: 8
Training loss: 0.09570775181055069
Validation loss: 1.4672341513377365

Epoch: 5| Step: 9
Training loss: 0.10626697540283203
Validation loss: 1.4630555914294334

Epoch: 5| Step: 10
Training loss: 0.09882355481386185
Validation loss: 1.4698542574400544

Epoch: 501| Step: 0
Training loss: 0.0623214952647686
Validation loss: 1.459457000096639

Epoch: 5| Step: 1
Training loss: 0.22716593742370605
Validation loss: 1.4641934191026995

Epoch: 5| Step: 2
Training loss: 0.07278773933649063
Validation loss: 1.460127886905465

Epoch: 5| Step: 3
Training loss: 0.0889153778553009
Validation loss: 1.4378898002768075

Epoch: 5| Step: 4
Training loss: 0.11744903028011322
Validation loss: 1.4453791392746793

Epoch: 5| Step: 5
Training loss: 0.07868252694606781
Validation loss: 1.4503403709780784

Epoch: 5| Step: 6
Training loss: 0.0814286321401596
Validation loss: 1.4421399959953882

Epoch: 5| Step: 7
Training loss: 0.06273618340492249
Validation loss: 1.436688562875153

Epoch: 5| Step: 8
Training loss: 0.08468567579984665
Validation loss: 1.4526776703455115

Epoch: 5| Step: 9
Training loss: 0.06835470348596573
Validation loss: 1.426373888087529

Epoch: 5| Step: 10
Training loss: 0.05561491847038269
Validation loss: 1.4248310237802484

Epoch: 502| Step: 0
Training loss: 0.07329311221837997
Validation loss: 1.4361634741547287

Epoch: 5| Step: 1
Training loss: 0.08356751501560211
Validation loss: 1.466072731120612

Epoch: 5| Step: 2
Training loss: 0.09998463094234467
Validation loss: 1.4615283230299592

Epoch: 5| Step: 3
Training loss: 0.08862456679344177
Validation loss: 1.4699334213810582

Epoch: 5| Step: 4
Training loss: 0.08638136833906174
Validation loss: 1.4745805904429445

Epoch: 5| Step: 5
Training loss: 0.15041136741638184
Validation loss: 1.472878049778682

Epoch: 5| Step: 6
Training loss: 0.16550052165985107
Validation loss: 1.4886192224359

Epoch: 5| Step: 7
Training loss: 0.1019013375043869
Validation loss: 1.4771069999664062

Epoch: 5| Step: 8
Training loss: 0.08355975896120071
Validation loss: 1.4812523344511628

Epoch: 5| Step: 9
Training loss: 0.1286247819662094
Validation loss: 1.491970076355883

Epoch: 5| Step: 10
Training loss: 0.08511608839035034
Validation loss: 1.4809873539914367

Epoch: 503| Step: 0
Training loss: 0.12393078953027725
Validation loss: 1.4765730455357542

Epoch: 5| Step: 1
Training loss: 0.07652159035205841
Validation loss: 1.4684977839069981

Epoch: 5| Step: 2
Training loss: 0.10037020593881607
Validation loss: 1.455746261022424

Epoch: 5| Step: 3
Training loss: 0.0940566435456276
Validation loss: 1.4545845780321347

Epoch: 5| Step: 4
Training loss: 0.0987524762749672
Validation loss: 1.456763163689644

Epoch: 5| Step: 5
Training loss: 0.0630384311079979
Validation loss: 1.4474319745135564

Epoch: 5| Step: 6
Training loss: 0.05044487863779068
Validation loss: 1.4563651879628499

Epoch: 5| Step: 7
Training loss: 0.09534665197134018
Validation loss: 1.4570853402537685

Epoch: 5| Step: 8
Training loss: 0.16908136010169983
Validation loss: 1.4512508723043627

Epoch: 5| Step: 9
Training loss: 0.08692481368780136
Validation loss: 1.464269854689157

Epoch: 5| Step: 10
Training loss: 0.06776998937129974
Validation loss: 1.448113101784901

Epoch: 504| Step: 0
Training loss: 0.0707409530878067
Validation loss: 1.4617912064316452

Epoch: 5| Step: 1
Training loss: 0.08455730974674225
Validation loss: 1.4941556940796554

Epoch: 5| Step: 2
Training loss: 0.08303715288639069
Validation loss: 1.4970980267370901

Epoch: 5| Step: 3
Training loss: 0.0728522315621376
Validation loss: 1.5024747092236754

Epoch: 5| Step: 4
Training loss: 0.08364196121692657
Validation loss: 1.4855576202433596

Epoch: 5| Step: 5
Training loss: 0.04794657602906227
Validation loss: 1.4512200637530255

Epoch: 5| Step: 6
Training loss: 0.06384017318487167
Validation loss: 1.455034553363759

Epoch: 5| Step: 7
Training loss: 0.2580420970916748
Validation loss: 1.4594466314520886

Epoch: 5| Step: 8
Training loss: 0.08391308039426804
Validation loss: 1.456681756563084

Epoch: 5| Step: 9
Training loss: 0.0653202012181282
Validation loss: 1.4618608028657976

Epoch: 5| Step: 10
Training loss: 0.06291615217924118
Validation loss: 1.4718542573272542

Epoch: 505| Step: 0
Training loss: 0.09441074728965759
Validation loss: 1.4521668585397864

Epoch: 5| Step: 1
Training loss: 0.06703555583953857
Validation loss: 1.471073309580485

Epoch: 5| Step: 2
Training loss: 0.16605444252490997
Validation loss: 1.4874400425982732

Epoch: 5| Step: 3
Training loss: 0.08667454123497009
Validation loss: 1.4595724100707679

Epoch: 5| Step: 4
Training loss: 0.08442948758602142
Validation loss: 1.4666635310778053

Epoch: 5| Step: 5
Training loss: 0.10491547733545303
Validation loss: 1.4926249134925105

Epoch: 5| Step: 6
Training loss: 0.09879454225301743
Validation loss: 1.4754847672677809

Epoch: 5| Step: 7
Training loss: 0.09407703578472137
Validation loss: 1.4742987258459932

Epoch: 5| Step: 8
Training loss: 0.12113449722528458
Validation loss: 1.4716926364488498

Epoch: 5| Step: 9
Training loss: 0.07289697229862213
Validation loss: 1.5149637294071976

Epoch: 5| Step: 10
Training loss: 0.06972262263298035
Validation loss: 1.5280530068182177

Epoch: 506| Step: 0
Training loss: 0.14520445466041565
Validation loss: 1.5316579085524364

Epoch: 5| Step: 1
Training loss: 0.10287830978631973
Validation loss: 1.5146109448966159

Epoch: 5| Step: 2
Training loss: 0.061059076339006424
Validation loss: 1.5139342226007932

Epoch: 5| Step: 3
Training loss: 0.06127120181918144
Validation loss: 1.481320128645948

Epoch: 5| Step: 4
Training loss: 0.06795372068881989
Validation loss: 1.4789308912010604

Epoch: 5| Step: 5
Training loss: 0.08202549070119858
Validation loss: 1.4624789735322357

Epoch: 5| Step: 6
Training loss: 0.07875697314739227
Validation loss: 1.4448983259098505

Epoch: 5| Step: 7
Training loss: 0.15761828422546387
Validation loss: 1.4421446272121963

Epoch: 5| Step: 8
Training loss: 0.11920888721942902
Validation loss: 1.4369541624540925

Epoch: 5| Step: 9
Training loss: 0.0920179933309555
Validation loss: 1.4351791527963453

Epoch: 5| Step: 10
Training loss: 0.06812161207199097
Validation loss: 1.4323679170300883

Epoch: 507| Step: 0
Training loss: 0.15243497490882874
Validation loss: 1.4145891551048524

Epoch: 5| Step: 1
Training loss: 0.07735854387283325
Validation loss: 1.4230066243038382

Epoch: 5| Step: 2
Training loss: 0.05812283605337143
Validation loss: 1.4013815515784807

Epoch: 5| Step: 3
Training loss: 0.05116156488656998
Validation loss: 1.379027444829223

Epoch: 5| Step: 4
Training loss: 0.058127909898757935
Validation loss: 1.3909430414117792

Epoch: 5| Step: 5
Training loss: 0.14049626886844635
Validation loss: 1.411773504749421

Epoch: 5| Step: 6
Training loss: 0.08553259074687958
Validation loss: 1.3922271843879455

Epoch: 5| Step: 7
Training loss: 0.08672163635492325
Validation loss: 1.381758507861886

Epoch: 5| Step: 8
Training loss: 0.04041488468647003
Validation loss: 1.3922979421513055

Epoch: 5| Step: 9
Training loss: 0.09200255572795868
Validation loss: 1.403183831963488

Epoch: 5| Step: 10
Training loss: 0.07242423295974731
Validation loss: 1.420814860251642

Epoch: 508| Step: 0
Training loss: 0.10755014419555664
Validation loss: 1.4062783243835613

Epoch: 5| Step: 1
Training loss: 0.057944852858781815
Validation loss: 1.379215532733548

Epoch: 5| Step: 2
Training loss: 0.03792945295572281
Validation loss: 1.3992075939332285

Epoch: 5| Step: 3
Training loss: 0.0551326647400856
Validation loss: 1.3989976939334665

Epoch: 5| Step: 4
Training loss: 0.17200808227062225
Validation loss: 1.4085744939824587

Epoch: 5| Step: 5
Training loss: 0.053250789642333984
Validation loss: 1.3801365026863672

Epoch: 5| Step: 6
Training loss: 0.04631013050675392
Validation loss: 1.4020754669302253

Epoch: 5| Step: 7
Training loss: 0.048707325011491776
Validation loss: 1.4146530192385438

Epoch: 5| Step: 8
Training loss: 0.07552282512187958
Validation loss: 1.4168780670371106

Epoch: 5| Step: 9
Training loss: 0.1303788125514984
Validation loss: 1.4193748915067284

Epoch: 5| Step: 10
Training loss: 0.0914500504732132
Validation loss: 1.4253509897057728

Epoch: 509| Step: 0
Training loss: 0.07314125448465347
Validation loss: 1.4206213810110604

Epoch: 5| Step: 1
Training loss: 0.04688059166073799
Validation loss: 1.4458033859088857

Epoch: 5| Step: 2
Training loss: 0.04282597452402115
Validation loss: 1.4395821812332317

Epoch: 5| Step: 3
Training loss: 0.07719440758228302
Validation loss: 1.440439365243399

Epoch: 5| Step: 4
Training loss: 0.13693058490753174
Validation loss: 1.460315050617341

Epoch: 5| Step: 5
Training loss: 0.1436188817024231
Validation loss: 1.4543664737414288

Epoch: 5| Step: 6
Training loss: 0.07588700950145721
Validation loss: 1.4389503989168393

Epoch: 5| Step: 7
Training loss: 0.060526132583618164
Validation loss: 1.4581550692999234

Epoch: 5| Step: 8
Training loss: 0.06999073177576065
Validation loss: 1.435488244538666

Epoch: 5| Step: 9
Training loss: 0.07918250560760498
Validation loss: 1.4308731709757159

Epoch: 5| Step: 10
Training loss: 0.17793989181518555
Validation loss: 1.4302910386875112

Epoch: 510| Step: 0
Training loss: 0.07342224568128586
Validation loss: 1.456476467911915

Epoch: 5| Step: 1
Training loss: 0.071042001247406
Validation loss: 1.4149721681430776

Epoch: 5| Step: 2
Training loss: 0.1732143610715866
Validation loss: 1.4351976366453274

Epoch: 5| Step: 3
Training loss: 0.0695682168006897
Validation loss: 1.4364238515976937

Epoch: 5| Step: 4
Training loss: 0.06663329154253006
Validation loss: 1.4513992673607283

Epoch: 5| Step: 5
Training loss: 0.08520469814538956
Validation loss: 1.463734967734224

Epoch: 5| Step: 6
Training loss: 0.05637875199317932
Validation loss: 1.4442165308101202

Epoch: 5| Step: 7
Training loss: 0.056647270917892456
Validation loss: 1.4516338891880487

Epoch: 5| Step: 8
Training loss: 0.06105984374880791
Validation loss: 1.434852869279923

Epoch: 5| Step: 9
Training loss: 0.13458925485610962
Validation loss: 1.462554399685193

Epoch: 5| Step: 10
Training loss: 0.06531154364347458
Validation loss: 1.4510712264686503

Epoch: 511| Step: 0
Training loss: 0.1371416300535202
Validation loss: 1.449546266627568

Epoch: 5| Step: 1
Training loss: 0.09773655980825424
Validation loss: 1.4392084960014588

Epoch: 5| Step: 2
Training loss: 0.07719311118125916
Validation loss: 1.4327648506369641

Epoch: 5| Step: 3
Training loss: 0.07023879885673523
Validation loss: 1.447981939520887

Epoch: 5| Step: 4
Training loss: 0.11403509229421616
Validation loss: 1.4422885256428872

Epoch: 5| Step: 5
Training loss: 0.05903216078877449
Validation loss: 1.4192538492141231

Epoch: 5| Step: 6
Training loss: 0.09378532320261002
Validation loss: 1.4336196555886218

Epoch: 5| Step: 7
Training loss: 0.06877229362726212
Validation loss: 1.4220766226450603

Epoch: 5| Step: 8
Training loss: 0.06199970096349716
Validation loss: 1.422977315482273

Epoch: 5| Step: 9
Training loss: 0.069205641746521
Validation loss: 1.447767004530917

Epoch: 5| Step: 10
Training loss: 0.09193242341279984
Validation loss: 1.4369580194514284

Epoch: 512| Step: 0
Training loss: 0.060440562665462494
Validation loss: 1.4377273423697359

Epoch: 5| Step: 1
Training loss: 0.07148853689432144
Validation loss: 1.458790994459583

Epoch: 5| Step: 2
Training loss: 0.05962204933166504
Validation loss: 1.4428225742873324

Epoch: 5| Step: 3
Training loss: 0.06271126866340637
Validation loss: 1.455269104690962

Epoch: 5| Step: 4
Training loss: 0.09078092873096466
Validation loss: 1.4590583078322872

Epoch: 5| Step: 5
Training loss: 0.05954451486468315
Validation loss: 1.4545591723534368

Epoch: 5| Step: 6
Training loss: 0.05430322885513306
Validation loss: 1.4487467658135198

Epoch: 5| Step: 7
Training loss: 0.04135674610733986
Validation loss: 1.4499769274906447

Epoch: 5| Step: 8
Training loss: 0.0671173557639122
Validation loss: 1.4494702239190378

Epoch: 5| Step: 9
Training loss: 0.19490960240364075
Validation loss: 1.4452475783645466

Epoch: 5| Step: 10
Training loss: 0.07752004265785217
Validation loss: 1.4264867075027958

Epoch: 513| Step: 0
Training loss: 0.11966101080179214
Validation loss: 1.4532413469847811

Epoch: 5| Step: 1
Training loss: 0.05936659500002861
Validation loss: 1.4281106110542052

Epoch: 5| Step: 2
Training loss: 0.06250028312206268
Validation loss: 1.4062692939594228

Epoch: 5| Step: 3
Training loss: 0.11445824056863785
Validation loss: 1.4217295198030369

Epoch: 5| Step: 4
Training loss: 0.07876342535018921
Validation loss: 1.450352261143346

Epoch: 5| Step: 5
Training loss: 0.07003337144851685
Validation loss: 1.4191388853134648

Epoch: 5| Step: 6
Training loss: 0.07034780830144882
Validation loss: 1.4519959034458283

Epoch: 5| Step: 7
Training loss: 0.04971417039632797
Validation loss: 1.422623752265848

Epoch: 5| Step: 8
Training loss: 0.05210311338305473
Validation loss: 1.4170608302598358

Epoch: 5| Step: 9
Training loss: 0.04620691388845444
Validation loss: 1.445166846757294

Epoch: 5| Step: 10
Training loss: 0.09407754242420197
Validation loss: 1.435726934863675

Epoch: 514| Step: 0
Training loss: 0.11546842753887177
Validation loss: 1.4219290761537449

Epoch: 5| Step: 1
Training loss: 0.061127763241529465
Validation loss: 1.4290940043746785

Epoch: 5| Step: 2
Training loss: 0.15574800968170166
Validation loss: 1.4268283677357498

Epoch: 5| Step: 3
Training loss: 0.07319848239421844
Validation loss: 1.412709096426605

Epoch: 5| Step: 4
Training loss: 0.0686071515083313
Validation loss: 1.4211148023605347

Epoch: 5| Step: 5
Training loss: 0.0805598646402359
Validation loss: 1.432550613598157

Epoch: 5| Step: 6
Training loss: 0.04059913009405136
Validation loss: 1.4085318016749557

Epoch: 5| Step: 7
Training loss: 0.09004814922809601
Validation loss: 1.4287911602245864

Epoch: 5| Step: 8
Training loss: 0.049355875700712204
Validation loss: 1.418053557795863

Epoch: 5| Step: 9
Training loss: 0.07205039262771606
Validation loss: 1.4118036057359429

Epoch: 5| Step: 10
Training loss: 0.05651718005537987
Validation loss: 1.4056789298211374

Epoch: 515| Step: 0
Training loss: 0.05269051343202591
Validation loss: 1.4450387563756717

Epoch: 5| Step: 1
Training loss: 0.056404732167720795
Validation loss: 1.444139289599593

Epoch: 5| Step: 2
Training loss: 0.044611066579818726
Validation loss: 1.4246812558943225

Epoch: 5| Step: 3
Training loss: 0.05743160843849182
Validation loss: 1.4554098620209643

Epoch: 5| Step: 4
Training loss: 0.145636647939682
Validation loss: 1.445434760021907

Epoch: 5| Step: 5
Training loss: 0.08683817088603973
Validation loss: 1.442281142357857

Epoch: 5| Step: 6
Training loss: 0.04838100075721741
Validation loss: 1.4291535269829534

Epoch: 5| Step: 7
Training loss: 0.055294640362262726
Validation loss: 1.4409933333755822

Epoch: 5| Step: 8
Training loss: 0.15557460486888885
Validation loss: 1.4292668514354254

Epoch: 5| Step: 9
Training loss: 0.10381995141506195
Validation loss: 1.439217799453325

Epoch: 5| Step: 10
Training loss: 0.06391781568527222
Validation loss: 1.453953348180299

Epoch: 516| Step: 0
Training loss: 0.06306218355894089
Validation loss: 1.4653507471084595

Epoch: 5| Step: 1
Training loss: 0.0846216231584549
Validation loss: 1.4283448547445319

Epoch: 5| Step: 2
Training loss: 0.11960472911596298
Validation loss: 1.4570106972930252

Epoch: 5| Step: 3
Training loss: 0.06350628286600113
Validation loss: 1.4347537986693844

Epoch: 5| Step: 4
Training loss: 0.0799534022808075
Validation loss: 1.4351238922406269

Epoch: 5| Step: 5
Training loss: 0.07674790918827057
Validation loss: 1.440954823647776

Epoch: 5| Step: 6
Training loss: 0.06333313882350922
Validation loss: 1.4425790745724913

Epoch: 5| Step: 7
Training loss: 0.13555948436260223
Validation loss: 1.4436514608321651

Epoch: 5| Step: 8
Training loss: 0.06705313920974731
Validation loss: 1.4505736520213466

Epoch: 5| Step: 9
Training loss: 0.05618273466825485
Validation loss: 1.4247440932899393

Epoch: 5| Step: 10
Training loss: 0.07006528228521347
Validation loss: 1.4287909910243044

Epoch: 517| Step: 0
Training loss: 0.045889586210250854
Validation loss: 1.464039300077705

Epoch: 5| Step: 1
Training loss: 0.2045517861843109
Validation loss: 1.427567158975909

Epoch: 5| Step: 2
Training loss: 0.07484043389558792
Validation loss: 1.431510438201248

Epoch: 5| Step: 3
Training loss: 0.07502290606498718
Validation loss: 1.4308863839795511

Epoch: 5| Step: 4
Training loss: 0.06698346138000488
Validation loss: 1.4416839089444888

Epoch: 5| Step: 5
Training loss: 0.07197479158639908
Validation loss: 1.4354169676380772

Epoch: 5| Step: 6
Training loss: 0.07175834476947784
Validation loss: 1.4463734613951815

Epoch: 5| Step: 7
Training loss: 0.036913953721523285
Validation loss: 1.4662733693276682

Epoch: 5| Step: 8
Training loss: 0.09453848749399185
Validation loss: 1.4905875709749037

Epoch: 5| Step: 9
Training loss: 0.05226283147931099
Validation loss: 1.489755468983804

Epoch: 5| Step: 10
Training loss: 0.06113642826676369
Validation loss: 1.4970724159671414

Epoch: 518| Step: 0
Training loss: 0.067191943526268
Validation loss: 1.4838671530446699

Epoch: 5| Step: 1
Training loss: 0.09777666628360748
Validation loss: 1.469509236274227

Epoch: 5| Step: 2
Training loss: 0.042209651321172714
Validation loss: 1.4275228720839306

Epoch: 5| Step: 3
Training loss: 0.05042558163404465
Validation loss: 1.4241445179908507

Epoch: 5| Step: 4
Training loss: 0.06301401555538177
Validation loss: 1.4274369183407034

Epoch: 5| Step: 5
Training loss: 0.05197273939847946
Validation loss: 1.428731732471015

Epoch: 5| Step: 6
Training loss: 0.04345065355300903
Validation loss: 1.4086521133299796

Epoch: 5| Step: 7
Training loss: 0.15999481081962585
Validation loss: 1.4170230588605326

Epoch: 5| Step: 8
Training loss: 0.04981031268835068
Validation loss: 1.4297964419088056

Epoch: 5| Step: 9
Training loss: 0.10836348682641983
Validation loss: 1.4216287828260852

Epoch: 5| Step: 10
Training loss: 0.060741692781448364
Validation loss: 1.4329339022277503

Epoch: 519| Step: 0
Training loss: 0.044439248740673065
Validation loss: 1.43047958548351

Epoch: 5| Step: 1
Training loss: 0.052384406328201294
Validation loss: 1.4311972318157073

Epoch: 5| Step: 2
Training loss: 0.09947618097066879
Validation loss: 1.4338698835783108

Epoch: 5| Step: 3
Training loss: 0.049663279205560684
Validation loss: 1.417214931980256

Epoch: 5| Step: 4
Training loss: 0.05041951686143875
Validation loss: 1.4556409851197274

Epoch: 5| Step: 5
Training loss: 0.06755037605762482
Validation loss: 1.4439362748976676

Epoch: 5| Step: 6
Training loss: 0.08479928225278854
Validation loss: 1.4513825703692693

Epoch: 5| Step: 7
Training loss: 0.1439022719860077
Validation loss: 1.45546987108005

Epoch: 5| Step: 8
Training loss: 0.04873013123869896
Validation loss: 1.4527356509239442

Epoch: 5| Step: 9
Training loss: 0.1041732057929039
Validation loss: 1.4358688516001548

Epoch: 5| Step: 10
Training loss: 0.049535736441612244
Validation loss: 1.4451024596409132

Epoch: 520| Step: 0
Training loss: 0.14948436617851257
Validation loss: 1.4386546361830927

Epoch: 5| Step: 1
Training loss: 0.05406714230775833
Validation loss: 1.4516737409817275

Epoch: 5| Step: 2
Training loss: 0.06216999888420105
Validation loss: 1.4328065194109434

Epoch: 5| Step: 3
Training loss: 0.0731365904211998
Validation loss: 1.4227504960952266

Epoch: 5| Step: 4
Training loss: 0.03997602313756943
Validation loss: 1.4253422303866314

Epoch: 5| Step: 5
Training loss: 0.09136106073856354
Validation loss: 1.4248420275667661

Epoch: 5| Step: 6
Training loss: 0.05164843052625656
Validation loss: 1.4001442514440066

Epoch: 5| Step: 7
Training loss: 0.06341139227151871
Validation loss: 1.4088923456848308

Epoch: 5| Step: 8
Training loss: 0.07531191408634186
Validation loss: 1.4135065822191135

Epoch: 5| Step: 9
Training loss: 0.1613980233669281
Validation loss: 1.3958125575896232

Epoch: 5| Step: 10
Training loss: 0.04931958392262459
Validation loss: 1.4209560463505406

Epoch: 521| Step: 0
Training loss: 0.06355651468038559
Validation loss: 1.4265841476378902

Epoch: 5| Step: 1
Training loss: 0.0446607768535614
Validation loss: 1.4088112179951002

Epoch: 5| Step: 2
Training loss: 0.07162342965602875
Validation loss: 1.4546836614608765

Epoch: 5| Step: 3
Training loss: 0.11144788563251495
Validation loss: 1.4368993095172349

Epoch: 5| Step: 4
Training loss: 0.05877285078167915
Validation loss: 1.421227744830552

Epoch: 5| Step: 5
Training loss: 0.04797633737325668
Validation loss: 1.4331480290300103

Epoch: 5| Step: 6
Training loss: 0.14133760333061218
Validation loss: 1.4191365049731346

Epoch: 5| Step: 7
Training loss: 0.08174421638250351
Validation loss: 1.4315241921332575

Epoch: 5| Step: 8
Training loss: 0.07445146888494492
Validation loss: 1.432873680386492

Epoch: 5| Step: 9
Training loss: 0.095340296626091
Validation loss: 1.4281664048471758

Epoch: 5| Step: 10
Training loss: 0.06716048717498779
Validation loss: 1.459234308171016

Epoch: 522| Step: 0
Training loss: 0.06396106630563736
Validation loss: 1.4399001931631437

Epoch: 5| Step: 1
Training loss: 0.12832298874855042
Validation loss: 1.465348098867683

Epoch: 5| Step: 2
Training loss: 0.058262504637241364
Validation loss: 1.4419514427902878

Epoch: 5| Step: 3
Training loss: 0.08044742047786713
Validation loss: 1.4473517658889934

Epoch: 5| Step: 4
Training loss: 0.0681387335062027
Validation loss: 1.4431491500587874

Epoch: 5| Step: 5
Training loss: 0.05095990374684334
Validation loss: 1.443985871089402

Epoch: 5| Step: 6
Training loss: 0.12767061591148376
Validation loss: 1.4372207721074421

Epoch: 5| Step: 7
Training loss: 0.07569130510091782
Validation loss: 1.4565055421603623

Epoch: 5| Step: 8
Training loss: 0.06485185027122498
Validation loss: 1.429239829381307

Epoch: 5| Step: 9
Training loss: 0.060215871781110764
Validation loss: 1.4482576635576063

Epoch: 5| Step: 10
Training loss: 0.07718247175216675
Validation loss: 1.4658100105101062

Epoch: 523| Step: 0
Training loss: 0.09496639668941498
Validation loss: 1.4768611538794734

Epoch: 5| Step: 1
Training loss: 0.08704845607280731
Validation loss: 1.4550446925624725

Epoch: 5| Step: 2
Training loss: 0.1000664234161377
Validation loss: 1.4543664160595144

Epoch: 5| Step: 3
Training loss: 0.07743354886770248
Validation loss: 1.4644463100740988

Epoch: 5| Step: 4
Training loss: 0.12625177204608917
Validation loss: 1.4616233635974187

Epoch: 5| Step: 5
Training loss: 0.05410509184002876
Validation loss: 1.426906717720852

Epoch: 5| Step: 6
Training loss: 0.05791286379098892
Validation loss: 1.437563282187267

Epoch: 5| Step: 7
Training loss: 0.05141408368945122
Validation loss: 1.4397344871233868

Epoch: 5| Step: 8
Training loss: 0.04830136522650719
Validation loss: 1.457791737330857

Epoch: 5| Step: 9
Training loss: 0.25509727001190186
Validation loss: 1.4566361211961316

Epoch: 5| Step: 10
Training loss: 0.07365831732749939
Validation loss: 1.4621975498814737

Epoch: 524| Step: 0
Training loss: 0.0558234266936779
Validation loss: 1.4504138308186685

Epoch: 5| Step: 1
Training loss: 0.08782491832971573
Validation loss: 1.4565774253619614

Epoch: 5| Step: 2
Training loss: 0.03888941928744316
Validation loss: 1.4650679647281606

Epoch: 5| Step: 3
Training loss: 0.16204802691936493
Validation loss: 1.4692414909280755

Epoch: 5| Step: 4
Training loss: 0.04164539650082588
Validation loss: 1.4548228863746888

Epoch: 5| Step: 5
Training loss: 0.06555405259132385
Validation loss: 1.441523160985721

Epoch: 5| Step: 6
Training loss: 0.09531717747449875
Validation loss: 1.466558814048767

Epoch: 5| Step: 7
Training loss: 0.033331189304590225
Validation loss: 1.4586896332361365

Epoch: 5| Step: 8
Training loss: 0.12836496531963348
Validation loss: 1.4502081230122557

Epoch: 5| Step: 9
Training loss: 0.0725448876619339
Validation loss: 1.4829304051655594

Epoch: 5| Step: 10
Training loss: 0.07500672340393066
Validation loss: 1.4498257957479006

Epoch: 525| Step: 0
Training loss: 0.05904317647218704
Validation loss: 1.4722464578126067

Epoch: 5| Step: 1
Training loss: 0.055391259491443634
Validation loss: 1.4527068958487561

Epoch: 5| Step: 2
Training loss: 0.07559721171855927
Validation loss: 1.4478751908066452

Epoch: 5| Step: 3
Training loss: 0.14969223737716675
Validation loss: 1.4494095797179847

Epoch: 5| Step: 4
Training loss: 0.07022019475698471
Validation loss: 1.4367530807372062

Epoch: 5| Step: 5
Training loss: 0.05394184589385986
Validation loss: 1.427704911078176

Epoch: 5| Step: 6
Training loss: 0.05904173105955124
Validation loss: 1.4386929068514096

Epoch: 5| Step: 7
Training loss: 0.06280404329299927
Validation loss: 1.4283602122337586

Epoch: 5| Step: 8
Training loss: 0.05750270560383797
Validation loss: 1.4212979296202302

Epoch: 5| Step: 9
Training loss: 0.04779980331659317
Validation loss: 1.4283479208587317

Epoch: 5| Step: 10
Training loss: 0.14952944219112396
Validation loss: 1.4267880288503503

Epoch: 526| Step: 0
Training loss: 0.1471371054649353
Validation loss: 1.4270345677611649

Epoch: 5| Step: 1
Training loss: 0.05306851118803024
Validation loss: 1.4254232773216822

Epoch: 5| Step: 2
Training loss: 0.051904577761888504
Validation loss: 1.445165229100053

Epoch: 5| Step: 3
Training loss: 0.05026688426733017
Validation loss: 1.439319843887001

Epoch: 5| Step: 4
Training loss: 0.0675305724143982
Validation loss: 1.438175634671283

Epoch: 5| Step: 5
Training loss: 0.03471789509057999
Validation loss: 1.4231623193269134

Epoch: 5| Step: 6
Training loss: 0.04100432246923447
Validation loss: 1.4187419952884797

Epoch: 5| Step: 7
Training loss: 0.06726102530956268
Validation loss: 1.395452453244117

Epoch: 5| Step: 8
Training loss: 0.049318306148052216
Validation loss: 1.4190853923879645

Epoch: 5| Step: 9
Training loss: 0.07932041585445404
Validation loss: 1.4521443690023115

Epoch: 5| Step: 10
Training loss: 0.11204808950424194
Validation loss: 1.4005159818997948

Epoch: 527| Step: 0
Training loss: 0.05071423575282097
Validation loss: 1.4204387100793983

Epoch: 5| Step: 1
Training loss: 0.06769319623708725
Validation loss: 1.4098313047039894

Epoch: 5| Step: 2
Training loss: 0.038219038397073746
Validation loss: 1.4180618511733187

Epoch: 5| Step: 3
Training loss: 0.05529196932911873
Validation loss: 1.4025005191885016

Epoch: 5| Step: 4
Training loss: 0.06274821609258652
Validation loss: 1.4206150834278395

Epoch: 5| Step: 5
Training loss: 0.055509112775325775
Validation loss: 1.4493363941869428

Epoch: 5| Step: 6
Training loss: 0.0844196006655693
Validation loss: 1.4484741444228797

Epoch: 5| Step: 7
Training loss: 0.22394795715808868
Validation loss: 1.4504573377229835

Epoch: 5| Step: 8
Training loss: 0.07041928917169571
Validation loss: 1.4526839794651154

Epoch: 5| Step: 9
Training loss: 0.05761561542749405
Validation loss: 1.4511749955915636

Epoch: 5| Step: 10
Training loss: 0.053446829319000244
Validation loss: 1.443422673850931

Epoch: 528| Step: 0
Training loss: 0.0859798938035965
Validation loss: 1.432078702475435

Epoch: 5| Step: 1
Training loss: 0.057705044746398926
Validation loss: 1.435461804430972

Epoch: 5| Step: 2
Training loss: 0.09110365062952042
Validation loss: 1.4431822184593446

Epoch: 5| Step: 3
Training loss: 0.08104686439037323
Validation loss: 1.433931266107867

Epoch: 5| Step: 4
Training loss: 0.16750703752040863
Validation loss: 1.4347538345603532

Epoch: 5| Step: 5
Training loss: 0.060752324759960175
Validation loss: 1.4280419298397597

Epoch: 5| Step: 6
Training loss: 0.052190929651260376
Validation loss: 1.4540317968655658

Epoch: 5| Step: 7
Training loss: 0.05885704606771469
Validation loss: 1.43040923149355

Epoch: 5| Step: 8
Training loss: 0.053425561636686325
Validation loss: 1.4412055771837953

Epoch: 5| Step: 9
Training loss: 0.04922904819250107
Validation loss: 1.4527484229815903

Epoch: 5| Step: 10
Training loss: 0.13156452775001526
Validation loss: 1.4537829455508982

Epoch: 529| Step: 0
Training loss: 0.06744806468486786
Validation loss: 1.4416121090612104

Epoch: 5| Step: 1
Training loss: 0.0579921193420887
Validation loss: 1.4427581910164125

Epoch: 5| Step: 2
Training loss: 0.05703078582882881
Validation loss: 1.4484647755981774

Epoch: 5| Step: 3
Training loss: 0.05795740336179733
Validation loss: 1.4409451805135256

Epoch: 5| Step: 4
Training loss: 0.1544705480337143
Validation loss: 1.4493592157158801

Epoch: 5| Step: 5
Training loss: 0.10657498985528946
Validation loss: 1.457147422657218

Epoch: 5| Step: 6
Training loss: 0.051619064062833786
Validation loss: 1.4371414863935081

Epoch: 5| Step: 7
Training loss: 0.07906369119882584
Validation loss: 1.4259802218406432

Epoch: 5| Step: 8
Training loss: 0.0823458582162857
Validation loss: 1.439675631061677

Epoch: 5| Step: 9
Training loss: 0.06616438925266266
Validation loss: 1.4279122301327285

Epoch: 5| Step: 10
Training loss: 0.05997409671545029
Validation loss: 1.4447356603478874

Epoch: 530| Step: 0
Training loss: 0.2129296511411667
Validation loss: 1.4205754367254113

Epoch: 5| Step: 1
Training loss: 0.053811002522706985
Validation loss: 1.408698853626046

Epoch: 5| Step: 2
Training loss: 0.051870740950107574
Validation loss: 1.4211363087418258

Epoch: 5| Step: 3
Training loss: 0.07315437495708466
Validation loss: 1.4242266301185853

Epoch: 5| Step: 4
Training loss: 0.052080750465393066
Validation loss: 1.428903914267017

Epoch: 5| Step: 5
Training loss: 0.07298137992620468
Validation loss: 1.402050240706372

Epoch: 5| Step: 6
Training loss: 0.06149393320083618
Validation loss: 1.420084402125369

Epoch: 5| Step: 7
Training loss: 0.051690779626369476
Validation loss: 1.4186876332888039

Epoch: 5| Step: 8
Training loss: 0.05742685869336128
Validation loss: 1.4208938293559576

Epoch: 5| Step: 9
Training loss: 0.06553640216588974
Validation loss: 1.4410252442923925

Epoch: 5| Step: 10
Training loss: 0.05900093913078308
Validation loss: 1.4227421232449111

Epoch: 531| Step: 0
Training loss: 0.051380954682826996
Validation loss: 1.4499357720857025

Epoch: 5| Step: 1
Training loss: 0.05499463528394699
Validation loss: 1.4704639911651611

Epoch: 5| Step: 2
Training loss: 0.048825088888406754
Validation loss: 1.4599675234927927

Epoch: 5| Step: 3
Training loss: 0.07690979540348053
Validation loss: 1.4455929827946488

Epoch: 5| Step: 4
Training loss: 0.07039974629878998
Validation loss: 1.4603656274016186

Epoch: 5| Step: 5
Training loss: 0.06296258419752121
Validation loss: 1.4502704335797219

Epoch: 5| Step: 6
Training loss: 0.15472914278507233
Validation loss: 1.4364070418060466

Epoch: 5| Step: 7
Training loss: 0.04421847313642502
Validation loss: 1.4222050354044924

Epoch: 5| Step: 8
Training loss: 0.05514683574438095
Validation loss: 1.432830395237092

Epoch: 5| Step: 9
Training loss: 0.049860887229442596
Validation loss: 1.4009032095632246

Epoch: 5| Step: 10
Training loss: 0.14772480726242065
Validation loss: 1.4231983410414828

Epoch: 532| Step: 0
Training loss: 0.07985337823629379
Validation loss: 1.4061292217623802

Epoch: 5| Step: 1
Training loss: 0.07071840763092041
Validation loss: 1.400963109026673

Epoch: 5| Step: 2
Training loss: 0.07382006198167801
Validation loss: 1.3893890470586798

Epoch: 5| Step: 3
Training loss: 0.08976022899150848
Validation loss: 1.4256561776643157

Epoch: 5| Step: 4
Training loss: 0.10260868072509766
Validation loss: 1.4162944696282829

Epoch: 5| Step: 5
Training loss: 0.05299786850810051
Validation loss: 1.4157931804656982

Epoch: 5| Step: 6
Training loss: 0.13983508944511414
Validation loss: 1.419309377670288

Epoch: 5| Step: 7
Training loss: 0.05174907296895981
Validation loss: 1.42009485537006

Epoch: 5| Step: 8
Training loss: 0.0874059796333313
Validation loss: 1.433272320737121

Epoch: 5| Step: 9
Training loss: 0.049909837543964386
Validation loss: 1.4470611362047092

Epoch: 5| Step: 10
Training loss: 0.07793949544429779
Validation loss: 1.4236731900963733

Epoch: 533| Step: 0
Training loss: 0.06505275517702103
Validation loss: 1.4322375136037027

Epoch: 5| Step: 1
Training loss: 0.05095486715435982
Validation loss: 1.4345428507815126

Epoch: 5| Step: 2
Training loss: 0.13422240316867828
Validation loss: 1.4393149986062

Epoch: 5| Step: 3
Training loss: 0.0605030283331871
Validation loss: 1.4196187027039067

Epoch: 5| Step: 4
Training loss: 0.03418406844139099
Validation loss: 1.4131453421808058

Epoch: 5| Step: 5
Training loss: 0.06870110332965851
Validation loss: 1.4263677263772616

Epoch: 5| Step: 6
Training loss: 0.06492984294891357
Validation loss: 1.4108321500080887

Epoch: 5| Step: 7
Training loss: 0.043253593146800995
Validation loss: 1.4189677046191307

Epoch: 5| Step: 8
Training loss: 0.10645725578069687
Validation loss: 1.4004464008474862

Epoch: 5| Step: 9
Training loss: 0.07021774351596832
Validation loss: 1.4081877085470385

Epoch: 5| Step: 10
Training loss: 0.06116904318332672
Validation loss: 1.4264535852657851

Epoch: 534| Step: 0
Training loss: 0.11214351654052734
Validation loss: 1.4092208288049186

Epoch: 5| Step: 1
Training loss: 0.05130497366189957
Validation loss: 1.4237398216801305

Epoch: 5| Step: 2
Training loss: 0.04996965080499649
Validation loss: 1.4262179226003668

Epoch: 5| Step: 3
Training loss: 0.04305509477853775
Validation loss: 1.4169233806671635

Epoch: 5| Step: 4
Training loss: 0.05443159490823746
Validation loss: 1.4179848810677886

Epoch: 5| Step: 5
Training loss: 0.04854535311460495
Validation loss: 1.4211164597542054

Epoch: 5| Step: 6
Training loss: 0.1633826494216919
Validation loss: 1.4272717327199957

Epoch: 5| Step: 7
Training loss: 0.05438956618309021
Validation loss: 1.4149291925532843

Epoch: 5| Step: 8
Training loss: 0.037887416779994965
Validation loss: 1.4172035827431628

Epoch: 5| Step: 9
Training loss: 0.06707803905010223
Validation loss: 1.4139305724892566

Epoch: 5| Step: 10
Training loss: 0.04897154122591019
Validation loss: 1.4046628013733895

Epoch: 535| Step: 0
Training loss: 0.04209526628255844
Validation loss: 1.4302652779445852

Epoch: 5| Step: 1
Training loss: 0.06383398920297623
Validation loss: 1.4223957343768048

Epoch: 5| Step: 2
Training loss: 0.04705236107110977
Validation loss: 1.4051448875857937

Epoch: 5| Step: 3
Training loss: 0.12443272769451141
Validation loss: 1.4141061357272569

Epoch: 5| Step: 4
Training loss: 0.07363702356815338
Validation loss: 1.4096828788839362

Epoch: 5| Step: 5
Training loss: 0.048910029232501984
Validation loss: 1.4172780308672177

Epoch: 5| Step: 6
Training loss: 0.04752212017774582
Validation loss: 1.422221952869046

Epoch: 5| Step: 7
Training loss: 0.06367827206850052
Validation loss: 1.4050252360682334

Epoch: 5| Step: 8
Training loss: 0.16210739314556122
Validation loss: 1.4059589216786046

Epoch: 5| Step: 9
Training loss: 0.05902528762817383
Validation loss: 1.4154564924137567

Epoch: 5| Step: 10
Training loss: 0.03879188373684883
Validation loss: 1.438475348616159

Epoch: 536| Step: 0
Training loss: 0.13083767890930176
Validation loss: 1.4210610614028027

Epoch: 5| Step: 1
Training loss: 0.06908790022134781
Validation loss: 1.4134525201653922

Epoch: 5| Step: 2
Training loss: 0.061120353639125824
Validation loss: 1.4225568771362305

Epoch: 5| Step: 3
Training loss: 0.047888778150081635
Validation loss: 1.4212015412187065

Epoch: 5| Step: 4
Training loss: 0.02994408644735813
Validation loss: 1.4364061022317538

Epoch: 5| Step: 5
Training loss: 0.04081731289625168
Validation loss: 1.4404294439541396

Epoch: 5| Step: 6
Training loss: 0.07202122360467911
Validation loss: 1.4115463495254517

Epoch: 5| Step: 7
Training loss: 0.06120367720723152
Validation loss: 1.4512157568367579

Epoch: 5| Step: 8
Training loss: 0.07630453258752823
Validation loss: 1.4255207482204642

Epoch: 5| Step: 9
Training loss: 0.07140748202800751
Validation loss: 1.4063580753982707

Epoch: 5| Step: 10
Training loss: 0.11262650042772293
Validation loss: 1.434295723515172

Epoch: 537| Step: 0
Training loss: 0.04271017760038376
Validation loss: 1.4347310912224553

Epoch: 5| Step: 1
Training loss: 0.05687369778752327
Validation loss: 1.459987929431341

Epoch: 5| Step: 2
Training loss: 0.06608577817678452
Validation loss: 1.4553443590799968

Epoch: 5| Step: 3
Training loss: 0.0500638410449028
Validation loss: 1.4566401461119294

Epoch: 5| Step: 4
Training loss: 0.1440848410129547
Validation loss: 1.4405175434645785

Epoch: 5| Step: 5
Training loss: 0.11320388317108154
Validation loss: 1.4645529549608949

Epoch: 5| Step: 6
Training loss: 0.0631110668182373
Validation loss: 1.436378107276014

Epoch: 5| Step: 7
Training loss: 0.037735193967819214
Validation loss: 1.4407653077956168

Epoch: 5| Step: 8
Training loss: 0.06541445851325989
Validation loss: 1.4338162727253412

Epoch: 5| Step: 9
Training loss: 0.046949051320552826
Validation loss: 1.448647476011707

Epoch: 5| Step: 10
Training loss: 0.07395702600479126
Validation loss: 1.423906123766335

Epoch: 538| Step: 0
Training loss: 0.05310554429888725
Validation loss: 1.4469172916104716

Epoch: 5| Step: 1
Training loss: 0.055808790028095245
Validation loss: 1.4488783844055668

Epoch: 5| Step: 2
Training loss: 0.07051045447587967
Validation loss: 1.4701575412545154

Epoch: 5| Step: 3
Training loss: 0.05232440307736397
Validation loss: 1.4364375382341363

Epoch: 5| Step: 4
Training loss: 0.06182727962732315
Validation loss: 1.4260171587749193

Epoch: 5| Step: 5
Training loss: 0.14382527768611908
Validation loss: 1.4395928216236893

Epoch: 5| Step: 6
Training loss: 0.11493265628814697
Validation loss: 1.4262836082007295

Epoch: 5| Step: 7
Training loss: 0.08136323094367981
Validation loss: 1.4484763171083184

Epoch: 5| Step: 8
Training loss: 0.0418633334338665
Validation loss: 1.4647379075327227

Epoch: 5| Step: 9
Training loss: 0.04698987677693367
Validation loss: 1.4602278124901555

Epoch: 5| Step: 10
Training loss: 0.05815797299146652
Validation loss: 1.4480524614293089

Epoch: 539| Step: 0
Training loss: 0.03881198912858963
Validation loss: 1.4739340005382415

Epoch: 5| Step: 1
Training loss: 0.04721764475107193
Validation loss: 1.449002427439536

Epoch: 5| Step: 2
Training loss: 0.06162504106760025
Validation loss: 1.4412536326275076

Epoch: 5| Step: 3
Training loss: 0.04823743551969528
Validation loss: 1.457986012581856

Epoch: 5| Step: 4
Training loss: 0.05621769279241562
Validation loss: 1.412967658812

Epoch: 5| Step: 5
Training loss: 0.05874025821685791
Validation loss: 1.43012067579454

Epoch: 5| Step: 6
Training loss: 0.13838963210582733
Validation loss: 1.4169213284728348

Epoch: 5| Step: 7
Training loss: 0.15637917816638947
Validation loss: 1.3888646819258248

Epoch: 5| Step: 8
Training loss: 0.056181468069553375
Validation loss: 1.419209885340865

Epoch: 5| Step: 9
Training loss: 0.07176937907934189
Validation loss: 1.4052618472806868

Epoch: 5| Step: 10
Training loss: 0.07796064764261246
Validation loss: 1.4066600056104763

Epoch: 540| Step: 0
Training loss: 0.06555351614952087
Validation loss: 1.4140850203011626

Epoch: 5| Step: 1
Training loss: 0.05843557044863701
Validation loss: 1.4292483265681932

Epoch: 5| Step: 2
Training loss: 0.06949279457330704
Validation loss: 1.4134927385596818

Epoch: 5| Step: 3
Training loss: 0.05386710166931152
Validation loss: 1.4081837643859207

Epoch: 5| Step: 4
Training loss: 0.09687398374080658
Validation loss: 1.4092637018490863

Epoch: 5| Step: 5
Training loss: 0.13588029146194458
Validation loss: 1.409160356367788

Epoch: 5| Step: 6
Training loss: 0.023947808891534805
Validation loss: 1.4362299211563603

Epoch: 5| Step: 7
Training loss: 0.07075542956590652
Validation loss: 1.4088398859065066

Epoch: 5| Step: 8
Training loss: 0.09656815975904465
Validation loss: 1.428714350346596

Epoch: 5| Step: 9
Training loss: 0.07475823909044266
Validation loss: 1.4143532617117769

Epoch: 5| Step: 10
Training loss: 0.050141651183366776
Validation loss: 1.4302486450441423

Epoch: 541| Step: 0
Training loss: 0.0635056123137474
Validation loss: 1.4187323662542528

Epoch: 5| Step: 1
Training loss: 0.04875176027417183
Validation loss: 1.4246671802254134

Epoch: 5| Step: 2
Training loss: 0.06735445559024811
Validation loss: 1.4111951884403025

Epoch: 5| Step: 3
Training loss: 0.05551272630691528
Validation loss: 1.412200830956941

Epoch: 5| Step: 4
Training loss: 0.03845422342419624
Validation loss: 1.4312052111471854

Epoch: 5| Step: 5
Training loss: 0.12286100536584854
Validation loss: 1.4216094581029748

Epoch: 5| Step: 6
Training loss: 0.04914512485265732
Validation loss: 1.4174012958362538

Epoch: 5| Step: 7
Training loss: 0.06893978267908096
Validation loss: 1.400551292844998

Epoch: 5| Step: 8
Training loss: 0.18428751826286316
Validation loss: 1.3970101443670129

Epoch: 5| Step: 9
Training loss: 0.0589761957526207
Validation loss: 1.3902645444357267

Epoch: 5| Step: 10
Training loss: 0.07156253606081009
Validation loss: 1.39909158086264

Epoch: 542| Step: 0
Training loss: 0.05911392718553543
Validation loss: 1.4248790933239845

Epoch: 5| Step: 1
Training loss: 0.1553778052330017
Validation loss: 1.4127614408411004

Epoch: 5| Step: 2
Training loss: 0.04643198102712631
Validation loss: 1.4145151626679204

Epoch: 5| Step: 3
Training loss: 0.05898900702595711
Validation loss: 1.4249354882906842

Epoch: 5| Step: 4
Training loss: 0.05487338453531265
Validation loss: 1.4432345077555666

Epoch: 5| Step: 5
Training loss: 0.05624376982450485
Validation loss: 1.4173323832532412

Epoch: 5| Step: 6
Training loss: 0.1749664843082428
Validation loss: 1.4310352930458643

Epoch: 5| Step: 7
Training loss: 0.059802938252687454
Validation loss: 1.4371349568008094

Epoch: 5| Step: 8
Training loss: 0.07579110562801361
Validation loss: 1.4200918366832118

Epoch: 5| Step: 9
Training loss: 0.05770760029554367
Validation loss: 1.3991096429927374

Epoch: 5| Step: 10
Training loss: 0.03497537970542908
Validation loss: 1.4194248876264017

Epoch: 543| Step: 0
Training loss: 0.0588165819644928
Validation loss: 1.4008261631893855

Epoch: 5| Step: 1
Training loss: 0.13569101691246033
Validation loss: 1.3995536040234309

Epoch: 5| Step: 2
Training loss: 0.06712616980075836
Validation loss: 1.4241452652920958

Epoch: 5| Step: 3
Training loss: 0.09242497384548187
Validation loss: 1.4304396260169245

Epoch: 5| Step: 4
Training loss: 0.05668537691235542
Validation loss: 1.4078199760888213

Epoch: 5| Step: 5
Training loss: 0.06618388742208481
Validation loss: 1.4100244275985225

Epoch: 5| Step: 6
Training loss: 0.06865743547677994
Validation loss: 1.4219291312720186

Epoch: 5| Step: 7
Training loss: 0.0428972952067852
Validation loss: 1.4164692637740925

Epoch: 5| Step: 8
Training loss: 0.1555740088224411
Validation loss: 1.4284336848925518

Epoch: 5| Step: 9
Training loss: 0.08867456763982773
Validation loss: 1.4138121169100526

Epoch: 5| Step: 10
Training loss: 0.0742897242307663
Validation loss: 1.3916486347875288

Epoch: 544| Step: 0
Training loss: 0.061852723360061646
Validation loss: 1.4167074195800289

Epoch: 5| Step: 1
Training loss: 0.0521727092564106
Validation loss: 1.3799024576781898

Epoch: 5| Step: 2
Training loss: 0.05629146099090576
Validation loss: 1.3919624974650722

Epoch: 5| Step: 3
Training loss: 0.0743916779756546
Validation loss: 1.4043266965496926

Epoch: 5| Step: 4
Training loss: 0.07105758041143417
Validation loss: 1.4001559288271013

Epoch: 5| Step: 5
Training loss: 0.11198196560144424
Validation loss: 1.411311634125248

Epoch: 5| Step: 6
Training loss: 0.11457838863134384
Validation loss: 1.4104117334529918

Epoch: 5| Step: 7
Training loss: 0.057486314326524734
Validation loss: 1.407177314963392

Epoch: 5| Step: 8
Training loss: 0.03540876880288124
Validation loss: 1.4346809964026175

Epoch: 5| Step: 9
Training loss: 0.05327481031417847
Validation loss: 1.4379156981745074

Epoch: 5| Step: 10
Training loss: 0.04989209398627281
Validation loss: 1.4380050577143186

Epoch: 545| Step: 0
Training loss: 0.05440068244934082
Validation loss: 1.4277051494967552

Epoch: 5| Step: 1
Training loss: 0.13758577406406403
Validation loss: 1.4177298392018964

Epoch: 5| Step: 2
Training loss: 0.06942594051361084
Validation loss: 1.4192853313620373

Epoch: 5| Step: 3
Training loss: 0.03421091288328171
Validation loss: 1.4177674849828084

Epoch: 5| Step: 4
Training loss: 0.05519067123532295
Validation loss: 1.4038811550345471

Epoch: 5| Step: 5
Training loss: 0.04218753054738045
Validation loss: 1.4333839121685232

Epoch: 5| Step: 6
Training loss: 0.12140704691410065
Validation loss: 1.4037664385252102

Epoch: 5| Step: 7
Training loss: 0.05924730747938156
Validation loss: 1.4071666027909966

Epoch: 5| Step: 8
Training loss: 0.0673605352640152
Validation loss: 1.3912385599587553

Epoch: 5| Step: 9
Training loss: 0.04380976781249046
Validation loss: 1.4066127320771575

Epoch: 5| Step: 10
Training loss: 0.035803668200969696
Validation loss: 1.3933936126770512

Epoch: 546| Step: 0
Training loss: 0.06531418114900589
Validation loss: 1.3796605948478944

Epoch: 5| Step: 1
Training loss: 0.1156192272901535
Validation loss: 1.415945912561109

Epoch: 5| Step: 2
Training loss: 0.05290784686803818
Validation loss: 1.3664940371308276

Epoch: 5| Step: 3
Training loss: 0.04750712588429451
Validation loss: 1.3732508138943744

Epoch: 5| Step: 4
Training loss: 0.06533549726009369
Validation loss: 1.3934803983216644

Epoch: 5| Step: 5
Training loss: 0.049257002770900726
Validation loss: 1.400944435468284

Epoch: 5| Step: 6
Training loss: 0.13431236147880554
Validation loss: 1.3828534464682303

Epoch: 5| Step: 7
Training loss: 0.053862832486629486
Validation loss: 1.3975584353170087

Epoch: 5| Step: 8
Training loss: 0.07257004082202911
Validation loss: 1.4044913707240936

Epoch: 5| Step: 9
Training loss: 0.09307695180177689
Validation loss: 1.4198911888625032

Epoch: 5| Step: 10
Training loss: 0.06257440894842148
Validation loss: 1.4050207778971682

Epoch: 547| Step: 0
Training loss: 0.07012806087732315
Validation loss: 1.4211958935183864

Epoch: 5| Step: 1
Training loss: 0.056663163006305695
Validation loss: 1.4040700274129068

Epoch: 5| Step: 2
Training loss: 0.051478058099746704
Validation loss: 1.3915260812287689

Epoch: 5| Step: 3
Training loss: 0.13530826568603516
Validation loss: 1.3997593592571955

Epoch: 5| Step: 4
Training loss: 0.062046729028224945
Validation loss: 1.4252093094651417

Epoch: 5| Step: 5
Training loss: 0.04777037724852562
Validation loss: 1.4074321357152795

Epoch: 5| Step: 6
Training loss: 0.051143549382686615
Validation loss: 1.413754842614615

Epoch: 5| Step: 7
Training loss: 0.05771448463201523
Validation loss: 1.4234745861381612

Epoch: 5| Step: 8
Training loss: 0.10517601668834686
Validation loss: 1.4140675055083407

Epoch: 5| Step: 9
Training loss: 0.1441127210855484
Validation loss: 1.4077484806378682

Epoch: 5| Step: 10
Training loss: 0.08654457330703735
Validation loss: 1.4055521783008371

Epoch: 548| Step: 0
Training loss: 0.08923854678869247
Validation loss: 1.4034145262933546

Epoch: 5| Step: 1
Training loss: 0.15927831828594208
Validation loss: 1.4058729640899166

Epoch: 5| Step: 2
Training loss: 0.04391730576753616
Validation loss: 1.396177839207393

Epoch: 5| Step: 3
Training loss: 0.04523995891213417
Validation loss: 1.3698220752900647

Epoch: 5| Step: 4
Training loss: 0.07525354623794556
Validation loss: 1.3860832029773342

Epoch: 5| Step: 5
Training loss: 0.05904113128781319
Validation loss: 1.3617499989847983

Epoch: 5| Step: 6
Training loss: 0.10776970535516739
Validation loss: 1.3675668060138662

Epoch: 5| Step: 7
Training loss: 0.08277156203985214
Validation loss: 1.3643691174445614

Epoch: 5| Step: 8
Training loss: 0.03911064192652702
Validation loss: 1.3652583437581216

Epoch: 5| Step: 9
Training loss: 0.0864262804389
Validation loss: 1.3647314245982836

Epoch: 5| Step: 10
Training loss: 0.06564261019229889
Validation loss: 1.3729698837444346

Epoch: 549| Step: 0
Training loss: 0.09532348066568375
Validation loss: 1.3831388642711024

Epoch: 5| Step: 1
Training loss: 0.07509322464466095
Validation loss: 1.3647819347279047

Epoch: 5| Step: 2
Training loss: 0.05888735130429268
Validation loss: 1.3486413109687068

Epoch: 5| Step: 3
Training loss: 0.17792505025863647
Validation loss: 1.3675518266616329

Epoch: 5| Step: 4
Training loss: 0.08945313841104507
Validation loss: 1.3895505295004895

Epoch: 5| Step: 5
Training loss: 0.054076820611953735
Validation loss: 1.3934691003573838

Epoch: 5| Step: 6
Training loss: 0.06419068574905396
Validation loss: 1.4102710844368063

Epoch: 5| Step: 7
Training loss: 0.05675455182790756
Validation loss: 1.4048903783162434

Epoch: 5| Step: 8
Training loss: 0.09401138126850128
Validation loss: 1.3934672263360792

Epoch: 5| Step: 9
Training loss: 0.05791879817843437
Validation loss: 1.4179142553319213

Epoch: 5| Step: 10
Training loss: 0.03865944966673851
Validation loss: 1.4219350776364725

Epoch: 550| Step: 0
Training loss: 0.07458945363759995
Validation loss: 1.4303633730898622

Epoch: 5| Step: 1
Training loss: 0.05557367205619812
Validation loss: 1.419781558616187

Epoch: 5| Step: 2
Training loss: 0.07460454851388931
Validation loss: 1.4140589647395636

Epoch: 5| Step: 3
Training loss: 0.05600953847169876
Validation loss: 1.441555929440324

Epoch: 5| Step: 4
Training loss: 0.06147754192352295
Validation loss: 1.4576181980871386

Epoch: 5| Step: 5
Training loss: 0.07112283259630203
Validation loss: 1.4815819378822082

Epoch: 5| Step: 6
Training loss: 0.07305842638015747
Validation loss: 1.4604936415149319

Epoch: 5| Step: 7
Training loss: 0.11698351055383682
Validation loss: 1.4663833238745247

Epoch: 5| Step: 8
Training loss: 0.0774645283818245
Validation loss: 1.442061972874467

Epoch: 5| Step: 9
Training loss: 0.15741536021232605
Validation loss: 1.4472738773592058

Epoch: 5| Step: 10
Training loss: 0.06108023226261139
Validation loss: 1.443579278966432

Epoch: 551| Step: 0
Training loss: 0.03579525649547577
Validation loss: 1.4205952273902072

Epoch: 5| Step: 1
Training loss: 0.04216581583023071
Validation loss: 1.4112271775481522

Epoch: 5| Step: 2
Training loss: 0.07032794505357742
Validation loss: 1.39177575290844

Epoch: 5| Step: 3
Training loss: 0.08174018561840057
Validation loss: 1.3864133896366242

Epoch: 5| Step: 4
Training loss: 0.12402722984552383
Validation loss: 1.369328151467026

Epoch: 5| Step: 5
Training loss: 0.07274924218654633
Validation loss: 1.3711927366513077

Epoch: 5| Step: 6
Training loss: 0.1262989640235901
Validation loss: 1.3728428130508752

Epoch: 5| Step: 7
Training loss: 0.08212412893772125
Validation loss: 1.3607140997404694

Epoch: 5| Step: 8
Training loss: 0.0883115753531456
Validation loss: 1.3744917159439416

Epoch: 5| Step: 9
Training loss: 0.09063456952571869
Validation loss: 1.3713315994508806

Epoch: 5| Step: 10
Training loss: 0.07727205008268356
Validation loss: 1.3517875081749373

Epoch: 552| Step: 0
Training loss: 0.06816672533750534
Validation loss: 1.3950181391931349

Epoch: 5| Step: 1
Training loss: 0.05591623857617378
Validation loss: 1.400775421050287

Epoch: 5| Step: 2
Training loss: 0.06343905627727509
Validation loss: 1.4010695090857885

Epoch: 5| Step: 3
Training loss: 0.06558902561664581
Validation loss: 1.4133326238201511

Epoch: 5| Step: 4
Training loss: 0.05584244802594185
Validation loss: 1.431351218172299

Epoch: 5| Step: 5
Training loss: 0.09120640158653259
Validation loss: 1.4110143992208666

Epoch: 5| Step: 6
Training loss: 0.08717385679483414
Validation loss: 1.423358492953803

Epoch: 5| Step: 7
Training loss: 0.08784808963537216
Validation loss: 1.4057184111687444

Epoch: 5| Step: 8
Training loss: 0.10270623862743378
Validation loss: 1.4072897511143838

Epoch: 5| Step: 9
Training loss: 0.14207878708839417
Validation loss: 1.3900507098884993

Epoch: 5| Step: 10
Training loss: 0.12045098841190338
Validation loss: 1.4201044292860134

Epoch: 553| Step: 0
Training loss: 0.0614909753203392
Validation loss: 1.4183612651722406

Epoch: 5| Step: 1
Training loss: 0.18175286054611206
Validation loss: 1.4243363270195581

Epoch: 5| Step: 2
Training loss: 0.06920778751373291
Validation loss: 1.4354991207840622

Epoch: 5| Step: 3
Training loss: 0.07529827207326889
Validation loss: 1.437666549477526

Epoch: 5| Step: 4
Training loss: 0.09369304031133652
Validation loss: 1.4220666321375037

Epoch: 5| Step: 5
Training loss: 0.06635455042123795
Validation loss: 1.4413554437698857

Epoch: 5| Step: 6
Training loss: 0.07509344816207886
Validation loss: 1.3962718684186217

Epoch: 5| Step: 7
Training loss: 0.06243367865681648
Validation loss: 1.4060308843530633

Epoch: 5| Step: 8
Training loss: 0.04505164176225662
Validation loss: 1.4244821238261398

Epoch: 5| Step: 9
Training loss: 0.07220125943422318
Validation loss: 1.4251483230180637

Epoch: 5| Step: 10
Training loss: 0.13495557010173798
Validation loss: 1.4182054163307272

Epoch: 554| Step: 0
Training loss: 0.06876131147146225
Validation loss: 1.4317936692186581

Epoch: 5| Step: 1
Training loss: 0.04688253253698349
Validation loss: 1.4128688099563762

Epoch: 5| Step: 2
Training loss: 0.07372262328863144
Validation loss: 1.4446969250197053

Epoch: 5| Step: 3
Training loss: 0.03386233001947403
Validation loss: 1.4261413146090764

Epoch: 5| Step: 4
Training loss: 0.03470998257398605
Validation loss: 1.451546565178902

Epoch: 5| Step: 5
Training loss: 0.08332457393407822
Validation loss: 1.4553967227217972

Epoch: 5| Step: 6
Training loss: 0.15266859531402588
Validation loss: 1.4852135988973802

Epoch: 5| Step: 7
Training loss: 0.07277244329452515
Validation loss: 1.4583618602445048

Epoch: 5| Step: 8
Training loss: 0.1399509608745575
Validation loss: 1.4471219995970368

Epoch: 5| Step: 9
Training loss: 0.06008106470108032
Validation loss: 1.4653157239319177

Epoch: 5| Step: 10
Training loss: 0.0586492083966732
Validation loss: 1.416750160596704

Epoch: 555| Step: 0
Training loss: 0.08472345024347305
Validation loss: 1.4255367479016703

Epoch: 5| Step: 1
Training loss: 0.09022022038698196
Validation loss: 1.4290011819972788

Epoch: 5| Step: 2
Training loss: 0.05306306481361389
Validation loss: 1.3941608808373893

Epoch: 5| Step: 3
Training loss: 0.03485729545354843
Validation loss: 1.4002125115804775

Epoch: 5| Step: 4
Training loss: 0.12922732532024384
Validation loss: 1.3911771543564335

Epoch: 5| Step: 5
Training loss: 0.07041347771883011
Validation loss: 1.3721504544699064

Epoch: 5| Step: 6
Training loss: 0.08296459913253784
Validation loss: 1.3920082251230876

Epoch: 5| Step: 7
Training loss: 0.15111044049263
Validation loss: 1.3858639501756238

Epoch: 5| Step: 8
Training loss: 0.03627421334385872
Validation loss: 1.3876621261719735

Epoch: 5| Step: 9
Training loss: 0.0473674014210701
Validation loss: 1.3737806094590055

Epoch: 5| Step: 10
Training loss: 0.05777361989021301
Validation loss: 1.3921178951058337

Epoch: 556| Step: 0
Training loss: 0.10524441301822662
Validation loss: 1.4040956984284103

Epoch: 5| Step: 1
Training loss: 0.08625545352697372
Validation loss: 1.402721792139033

Epoch: 5| Step: 2
Training loss: 0.0636695846915245
Validation loss: 1.384175585162255

Epoch: 5| Step: 3
Training loss: 0.040926508605480194
Validation loss: 1.4136064129491006

Epoch: 5| Step: 4
Training loss: 0.05744378641247749
Validation loss: 1.4065510047379362

Epoch: 5| Step: 5
Training loss: 0.07080601155757904
Validation loss: 1.394114685955868

Epoch: 5| Step: 6
Training loss: 0.04804634302854538
Validation loss: 1.3934460275916642

Epoch: 5| Step: 7
Training loss: 0.07312668114900589
Validation loss: 1.3929140311415478

Epoch: 5| Step: 8
Training loss: 0.04162324592471123
Validation loss: 1.3877628400761595

Epoch: 5| Step: 9
Training loss: 0.12120511382818222
Validation loss: 1.3928964118803702

Epoch: 5| Step: 10
Training loss: 0.0577581562101841
Validation loss: 1.3941465782862839

Epoch: 557| Step: 0
Training loss: 0.10134726762771606
Validation loss: 1.3965946384655532

Epoch: 5| Step: 1
Training loss: 0.07048739492893219
Validation loss: 1.408359134069053

Epoch: 5| Step: 2
Training loss: 0.08538752794265747
Validation loss: 1.4065156880245413

Epoch: 5| Step: 3
Training loss: 0.1636102944612503
Validation loss: 1.3911492196462487

Epoch: 5| Step: 4
Training loss: 0.058330435305833817
Validation loss: 1.3842568294976347

Epoch: 5| Step: 5
Training loss: 0.08584316819906235
Validation loss: 1.3791942429798905

Epoch: 5| Step: 6
Training loss: 0.07143481075763702
Validation loss: 1.3821927962764617

Epoch: 5| Step: 7
Training loss: 0.06201134994626045
Validation loss: 1.3700915696800395

Epoch: 5| Step: 8
Training loss: 0.06671382486820221
Validation loss: 1.3624435573495843

Epoch: 5| Step: 9
Training loss: 0.06591158360242844
Validation loss: 1.362764241874859

Epoch: 5| Step: 10
Training loss: 0.034585047513246536
Validation loss: 1.3495001164815759

Epoch: 558| Step: 0
Training loss: 0.05136497691273689
Validation loss: 1.3394425953588178

Epoch: 5| Step: 1
Training loss: 0.11197519302368164
Validation loss: 1.355647357561255

Epoch: 5| Step: 2
Training loss: 0.07168309390544891
Validation loss: 1.3493371586645804

Epoch: 5| Step: 3
Training loss: 0.0408276729285717
Validation loss: 1.3604061372818486

Epoch: 5| Step: 4
Training loss: 0.07061152905225754
Validation loss: 1.3665584069426342

Epoch: 5| Step: 5
Training loss: 0.0692475438117981
Validation loss: 1.376333890422698

Epoch: 5| Step: 6
Training loss: 0.12735547125339508
Validation loss: 1.3779145133110784

Epoch: 5| Step: 7
Training loss: 0.07820452749729156
Validation loss: 1.3853178613929338

Epoch: 5| Step: 8
Training loss: 0.047202181071043015
Validation loss: 1.4053099091335008

Epoch: 5| Step: 9
Training loss: 0.07628902792930603
Validation loss: 1.400318952016933

Epoch: 5| Step: 10
Training loss: 0.07457315921783447
Validation loss: 1.3945236770055627

Epoch: 559| Step: 0
Training loss: 0.051145635545253754
Validation loss: 1.4145119600398566

Epoch: 5| Step: 1
Training loss: 0.056119970977306366
Validation loss: 1.3958135753549554

Epoch: 5| Step: 2
Training loss: 0.045680321753025055
Validation loss: 1.3960778174861785

Epoch: 5| Step: 3
Training loss: 0.1299591064453125
Validation loss: 1.3873596806680002

Epoch: 5| Step: 4
Training loss: 0.054165780544281006
Validation loss: 1.3958936237519788

Epoch: 5| Step: 5
Training loss: 0.05815448611974716
Validation loss: 1.3912323008301437

Epoch: 5| Step: 6
Training loss: 0.05834456533193588
Validation loss: 1.411355903071742

Epoch: 5| Step: 7
Training loss: 0.05013586953282356
Validation loss: 1.395273688018963

Epoch: 5| Step: 8
Training loss: 0.06609135866165161
Validation loss: 1.3969910240942431

Epoch: 5| Step: 9
Training loss: 0.04971588775515556
Validation loss: 1.3912309241551224

Epoch: 5| Step: 10
Training loss: 0.15273170173168182
Validation loss: 1.3990368625169158

Epoch: 560| Step: 0
Training loss: 0.08061306923627853
Validation loss: 1.3867613506573502

Epoch: 5| Step: 1
Training loss: 0.05987027287483215
Validation loss: 1.3873502208340553

Epoch: 5| Step: 2
Training loss: 0.03877411410212517
Validation loss: 1.3780159020936618

Epoch: 5| Step: 3
Training loss: 0.037296462804079056
Validation loss: 1.3877232356738018

Epoch: 5| Step: 4
Training loss: 0.03450930118560791
Validation loss: 1.378610534052695

Epoch: 5| Step: 5
Training loss: 0.05620264261960983
Validation loss: 1.3842581959180935

Epoch: 5| Step: 6
Training loss: 0.09567741304636002
Validation loss: 1.3885323591129755

Epoch: 5| Step: 7
Training loss: 0.060662996023893356
Validation loss: 1.3827345428928253

Epoch: 5| Step: 8
Training loss: 0.058126889169216156
Validation loss: 1.3873787156997188

Epoch: 5| Step: 9
Training loss: 0.1411646604537964
Validation loss: 1.3876939422340804

Epoch: 5| Step: 10
Training loss: 0.053212348371744156
Validation loss: 1.3788419333837365

Epoch: 561| Step: 0
Training loss: 0.027025561779737473
Validation loss: 1.3904600989434026

Epoch: 5| Step: 1
Training loss: 0.1927327960729599
Validation loss: 1.3863381801113006

Epoch: 5| Step: 2
Training loss: 0.03923578932881355
Validation loss: 1.406328252566758

Epoch: 5| Step: 3
Training loss: 0.08368756622076035
Validation loss: 1.4179740849361624

Epoch: 5| Step: 4
Training loss: 0.06796417385339737
Validation loss: 1.4086570496200232

Epoch: 5| Step: 5
Training loss: 0.05442533642053604
Validation loss: 1.3942974985286753

Epoch: 5| Step: 6
Training loss: 0.045810453593730927
Validation loss: 1.380068112445134

Epoch: 5| Step: 7
Training loss: 0.059046901762485504
Validation loss: 1.4134522445740239

Epoch: 5| Step: 8
Training loss: 0.09119996428489685
Validation loss: 1.3922237004003217

Epoch: 5| Step: 9
Training loss: 0.08560805022716522
Validation loss: 1.400710166141551

Epoch: 5| Step: 10
Training loss: 0.08429896086454391
Validation loss: 1.409929721586166

Epoch: 562| Step: 0
Training loss: 0.06354473531246185
Validation loss: 1.3904595644243303

Epoch: 5| Step: 1
Training loss: 0.03355064243078232
Validation loss: 1.3854771006491877

Epoch: 5| Step: 2
Training loss: 0.14223691821098328
Validation loss: 1.3870598872502644

Epoch: 5| Step: 3
Training loss: 0.039418768137693405
Validation loss: 1.3956003688996839

Epoch: 5| Step: 4
Training loss: 0.09326012432575226
Validation loss: 1.414168288630824

Epoch: 5| Step: 5
Training loss: 0.07540138065814972
Validation loss: 1.4141034874864804

Epoch: 5| Step: 6
Training loss: 0.08164872229099274
Validation loss: 1.3795148454686648

Epoch: 5| Step: 7
Training loss: 0.032485850155353546
Validation loss: 1.3893766967199181

Epoch: 5| Step: 8
Training loss: 0.06220360845327377
Validation loss: 1.3623459685233332

Epoch: 5| Step: 9
Training loss: 0.07607071101665497
Validation loss: 1.3905396243577361

Epoch: 5| Step: 10
Training loss: 0.03955573961138725
Validation loss: 1.3792767627264864

Epoch: 563| Step: 0
Training loss: 0.04184919595718384
Validation loss: 1.392106689432616

Epoch: 5| Step: 1
Training loss: 0.11739327013492584
Validation loss: 1.381657765757653

Epoch: 5| Step: 2
Training loss: 0.13263705372810364
Validation loss: 1.3923304427054621

Epoch: 5| Step: 3
Training loss: 0.06966184079647064
Validation loss: 1.4023413004413727

Epoch: 5| Step: 4
Training loss: 0.07267151772975922
Validation loss: 1.4059653974348498

Epoch: 5| Step: 5
Training loss: 0.07030253112316132
Validation loss: 1.4169266044452626

Epoch: 5| Step: 6
Training loss: 0.06650279462337494
Validation loss: 1.4164480727205995

Epoch: 5| Step: 7
Training loss: 0.04444955289363861
Validation loss: 1.3937613797444168

Epoch: 5| Step: 8
Training loss: 0.053914107382297516
Validation loss: 1.43805000218012

Epoch: 5| Step: 9
Training loss: 0.039135731756687164
Validation loss: 1.4230433061558714

Epoch: 5| Step: 10
Training loss: 0.06931418180465698
Validation loss: 1.3994096120198567

Epoch: 564| Step: 0
Training loss: 0.1340237557888031
Validation loss: 1.3925263958592569

Epoch: 5| Step: 1
Training loss: 0.05089721083641052
Validation loss: 1.3993525684520762

Epoch: 5| Step: 2
Training loss: 0.0551886186003685
Validation loss: 1.4045768040482716

Epoch: 5| Step: 3
Training loss: 0.04912242293357849
Validation loss: 1.4016517669923845

Epoch: 5| Step: 4
Training loss: 0.06929939985275269
Validation loss: 1.3929244997680827

Epoch: 5| Step: 5
Training loss: 0.13716009259223938
Validation loss: 1.3999340623937628

Epoch: 5| Step: 6
Training loss: 0.07535793632268906
Validation loss: 1.4072569672779371

Epoch: 5| Step: 7
Training loss: 0.036055244505405426
Validation loss: 1.3783229499734857

Epoch: 5| Step: 8
Training loss: 0.07873746752738953
Validation loss: 1.4251601503741356

Epoch: 5| Step: 9
Training loss: 0.042830366641283035
Validation loss: 1.420096759514142

Epoch: 5| Step: 10
Training loss: 0.0528145506978035
Validation loss: 1.4266893350949852

Epoch: 565| Step: 0
Training loss: 0.04945846647024155
Validation loss: 1.44404040357118

Epoch: 5| Step: 1
Training loss: 0.05143215134739876
Validation loss: 1.4445377267817014

Epoch: 5| Step: 2
Training loss: 0.04167318344116211
Validation loss: 1.437670523120511

Epoch: 5| Step: 3
Training loss: 0.11492057144641876
Validation loss: 1.4137668096891014

Epoch: 5| Step: 4
Training loss: 0.053574658930301666
Validation loss: 1.4068851669629414

Epoch: 5| Step: 5
Training loss: 0.04620352014899254
Validation loss: 1.4057628954610517

Epoch: 5| Step: 6
Training loss: 0.07637441903352737
Validation loss: 1.3827435162759596

Epoch: 5| Step: 7
Training loss: 0.09752801805734634
Validation loss: 1.4065345384741341

Epoch: 5| Step: 8
Training loss: 0.03870101645588875
Validation loss: 1.3956921985072475

Epoch: 5| Step: 9
Training loss: 0.06731043010950089
Validation loss: 1.4026516150402766

Epoch: 5| Step: 10
Training loss: 0.05081413686275482
Validation loss: 1.4052461180635678

Epoch: 566| Step: 0
Training loss: 0.14744563400745392
Validation loss: 1.4127094591817548

Epoch: 5| Step: 1
Training loss: 0.03553969785571098
Validation loss: 1.4081623169683641

Epoch: 5| Step: 2
Training loss: 0.04454394429922104
Validation loss: 1.4093076708496257

Epoch: 5| Step: 3
Training loss: 0.11848577111959457
Validation loss: 1.411423251193057

Epoch: 5| Step: 4
Training loss: 0.04884488508105278
Validation loss: 1.4152819495047293

Epoch: 5| Step: 5
Training loss: 0.04899277538061142
Validation loss: 1.4190342759573331

Epoch: 5| Step: 6
Training loss: 0.042953141033649445
Validation loss: 1.4154577652613323

Epoch: 5| Step: 7
Training loss: 0.0752977579832077
Validation loss: 1.4157673428135533

Epoch: 5| Step: 8
Training loss: 0.05440386012196541
Validation loss: 1.404988093401796

Epoch: 5| Step: 9
Training loss: 0.07029292732477188
Validation loss: 1.4028133871734783

Epoch: 5| Step: 10
Training loss: 0.048280149698257446
Validation loss: 1.3951395942318825

Epoch: 567| Step: 0
Training loss: 0.06252783536911011
Validation loss: 1.4348930492196033

Epoch: 5| Step: 1
Training loss: 0.12798570096492767
Validation loss: 1.3892690058677428

Epoch: 5| Step: 2
Training loss: 0.05956891179084778
Validation loss: 1.4231010713884908

Epoch: 5| Step: 3
Training loss: 0.05327483266592026
Validation loss: 1.3971862805786954

Epoch: 5| Step: 4
Training loss: 0.04692705348134041
Validation loss: 1.3875282656761907

Epoch: 5| Step: 5
Training loss: 0.06343867629766464
Validation loss: 1.3775453785414338

Epoch: 5| Step: 6
Training loss: 0.09473258256912231
Validation loss: 1.3783012410645843

Epoch: 5| Step: 7
Training loss: 0.13199086487293243
Validation loss: 1.3990424666353451

Epoch: 5| Step: 8
Training loss: 0.03402314335107803
Validation loss: 1.403192759842001

Epoch: 5| Step: 9
Training loss: 0.04787056893110275
Validation loss: 1.4005265992174867

Epoch: 5| Step: 10
Training loss: 0.04965967312455177
Validation loss: 1.4206660409127512

Epoch: 568| Step: 0
Training loss: 0.08170419186353683
Validation loss: 1.415296805802212

Epoch: 5| Step: 1
Training loss: 0.05326138809323311
Validation loss: 1.4148772749849545

Epoch: 5| Step: 2
Training loss: 0.10968814045190811
Validation loss: 1.413045536446315

Epoch: 5| Step: 3
Training loss: 0.06784895062446594
Validation loss: 1.4023283207288353

Epoch: 5| Step: 4
Training loss: 0.051892004907131195
Validation loss: 1.392164259828547

Epoch: 5| Step: 5
Training loss: 0.032883353531360626
Validation loss: 1.3971877456993185

Epoch: 5| Step: 6
Training loss: 0.09478168189525604
Validation loss: 1.435410394463488

Epoch: 5| Step: 7
Training loss: 0.12600935995578766
Validation loss: 1.409087674592131

Epoch: 5| Step: 8
Training loss: 0.09824937582015991
Validation loss: 1.363989737726027

Epoch: 5| Step: 9
Training loss: 0.08517948538064957
Validation loss: 1.3914564591582104

Epoch: 5| Step: 10
Training loss: 0.05458633229136467
Validation loss: 1.3911882600476664

Epoch: 569| Step: 0
Training loss: 0.04999743774533272
Validation loss: 1.3800727987802157

Epoch: 5| Step: 1
Training loss: 0.06472134590148926
Validation loss: 1.3804939985275269

Epoch: 5| Step: 2
Training loss: 0.06994105875492096
Validation loss: 1.3909086347908102

Epoch: 5| Step: 3
Training loss: 0.06920138746500015
Validation loss: 1.4012917818561677

Epoch: 5| Step: 4
Training loss: 0.13705897331237793
Validation loss: 1.4008232175662954

Epoch: 5| Step: 5
Training loss: 0.06927214562892914
Validation loss: 1.3832430390901462

Epoch: 5| Step: 6
Training loss: 0.05482225492596626
Validation loss: 1.401990653366171

Epoch: 5| Step: 7
Training loss: 0.08954404294490814
Validation loss: 1.3899385006197038

Epoch: 5| Step: 8
Training loss: 0.12714967131614685
Validation loss: 1.4037982674055203

Epoch: 5| Step: 9
Training loss: 0.053423888981342316
Validation loss: 1.3915773796778854

Epoch: 5| Step: 10
Training loss: 0.07741421461105347
Validation loss: 1.3918306494271884

Epoch: 570| Step: 0
Training loss: 0.04578845947980881
Validation loss: 1.4041698453246907

Epoch: 5| Step: 1
Training loss: 0.07423357665538788
Validation loss: 1.4185704249207691

Epoch: 5| Step: 2
Training loss: 0.15338805317878723
Validation loss: 1.408696936663761

Epoch: 5| Step: 3
Training loss: 0.06052185967564583
Validation loss: 1.434861324166739

Epoch: 5| Step: 4
Training loss: 0.07315106689929962
Validation loss: 1.4087308042792863

Epoch: 5| Step: 5
Training loss: 0.042819663882255554
Validation loss: 1.3905060688654582

Epoch: 5| Step: 6
Training loss: 0.05277261883020401
Validation loss: 1.3916192247021584

Epoch: 5| Step: 7
Training loss: 0.05428788810968399
Validation loss: 1.3458077087197253

Epoch: 5| Step: 8
Training loss: 0.1016288548707962
Validation loss: 1.3442699011935983

Epoch: 5| Step: 9
Training loss: 0.12023260444402695
Validation loss: 1.3425576430495068

Epoch: 5| Step: 10
Training loss: 0.10003352910280228
Validation loss: 1.3494629577923847

Epoch: 571| Step: 0
Training loss: 0.07080630958080292
Validation loss: 1.3504269546078098

Epoch: 5| Step: 1
Training loss: 0.057180263102054596
Validation loss: 1.3439506599980016

Epoch: 5| Step: 2
Training loss: 0.12180030345916748
Validation loss: 1.3949515601640106

Epoch: 5| Step: 3
Training loss: 0.0545559898018837
Validation loss: 1.374064153240573

Epoch: 5| Step: 4
Training loss: 0.030752185732126236
Validation loss: 1.3588491588510492

Epoch: 5| Step: 5
Training loss: 0.15021786093711853
Validation loss: 1.3822436339111739

Epoch: 5| Step: 6
Training loss: 0.09710738807916641
Validation loss: 1.415342596269423

Epoch: 5| Step: 7
Training loss: 0.037476591765880585
Validation loss: 1.4063435767286567

Epoch: 5| Step: 8
Training loss: 0.05109589546918869
Validation loss: 1.397772841556098

Epoch: 5| Step: 9
Training loss: 0.03549164533615112
Validation loss: 1.3911454280217488

Epoch: 5| Step: 10
Training loss: 0.10722101479768753
Validation loss: 1.3945316422370173

Epoch: 572| Step: 0
Training loss: 0.06694860011339188
Validation loss: 1.3946003003786969

Epoch: 5| Step: 1
Training loss: 0.13872294127941132
Validation loss: 1.4072812167547082

Epoch: 5| Step: 2
Training loss: 0.05486661195755005
Validation loss: 1.3902344626765097

Epoch: 5| Step: 3
Training loss: 0.11391733586788177
Validation loss: 1.3670734538826892

Epoch: 5| Step: 4
Training loss: 0.054284822195768356
Validation loss: 1.3928453973544541

Epoch: 5| Step: 5
Training loss: 0.053556106984615326
Validation loss: 1.3835863746622556

Epoch: 5| Step: 6
Training loss: 0.036679707467556
Validation loss: 1.3979914688294934

Epoch: 5| Step: 7
Training loss: 0.0752827599644661
Validation loss: 1.3896942292490313

Epoch: 5| Step: 8
Training loss: 0.04667723551392555
Validation loss: 1.3765300102131341

Epoch: 5| Step: 9
Training loss: 0.058619946241378784
Validation loss: 1.3734868796922828

Epoch: 5| Step: 10
Training loss: 0.052745264023542404
Validation loss: 1.3913547787615048

Epoch: 573| Step: 0
Training loss: 0.04221193492412567
Validation loss: 1.3853934734098372

Epoch: 5| Step: 1
Training loss: 0.06516595184803009
Validation loss: 1.3834456936005624

Epoch: 5| Step: 2
Training loss: 0.0579390712082386
Validation loss: 1.3981815166370843

Epoch: 5| Step: 3
Training loss: 0.05704299733042717
Validation loss: 1.435520823283862

Epoch: 5| Step: 4
Training loss: 0.04290962219238281
Validation loss: 1.4372520459595548

Epoch: 5| Step: 5
Training loss: 0.04854314401745796
Validation loss: 1.415776442455989

Epoch: 5| Step: 6
Training loss: 0.07105988264083862
Validation loss: 1.3969838452595535

Epoch: 5| Step: 7
Training loss: 0.040509600192308426
Validation loss: 1.4036949437151673

Epoch: 5| Step: 8
Training loss: 0.1870981901884079
Validation loss: 1.4088218007036435

Epoch: 5| Step: 9
Training loss: 0.05613014101982117
Validation loss: 1.3923219814095447

Epoch: 5| Step: 10
Training loss: 0.06727272272109985
Validation loss: 1.3902853817068122

Epoch: 574| Step: 0
Training loss: 0.049577824771404266
Validation loss: 1.3707913762779647

Epoch: 5| Step: 1
Training loss: 0.13866491615772247
Validation loss: 1.3644130255586358

Epoch: 5| Step: 2
Training loss: 0.04525880143046379
Validation loss: 1.3792205613146546

Epoch: 5| Step: 3
Training loss: 0.03793488070368767
Validation loss: 1.3667949079185404

Epoch: 5| Step: 4
Training loss: 0.05138523131608963
Validation loss: 1.366958071467697

Epoch: 5| Step: 5
Training loss: 0.13669872283935547
Validation loss: 1.353793131407871

Epoch: 5| Step: 6
Training loss: 0.05714394524693489
Validation loss: 1.3618553543603549

Epoch: 5| Step: 7
Training loss: 0.0674426406621933
Validation loss: 1.3791628172320705

Epoch: 5| Step: 8
Training loss: 0.05823435261845589
Validation loss: 1.4036958858531008

Epoch: 5| Step: 9
Training loss: 0.07716973125934601
Validation loss: 1.4090164733189408

Epoch: 5| Step: 10
Training loss: 0.05312293395400047
Validation loss: 1.4183372784686346

Epoch: 575| Step: 0
Training loss: 0.050667017698287964
Validation loss: 1.4030227097131873

Epoch: 5| Step: 1
Training loss: 0.05888167768716812
Validation loss: 1.4040246932737288

Epoch: 5| Step: 2
Training loss: 0.11560801416635513
Validation loss: 1.3909117464096314

Epoch: 5| Step: 3
Training loss: 0.07555420696735382
Validation loss: 1.394885342608216

Epoch: 5| Step: 4
Training loss: 0.05317527800798416
Validation loss: 1.4092743768486926

Epoch: 5| Step: 5
Training loss: 0.06549724191427231
Validation loss: 1.4044872150626233

Epoch: 5| Step: 6
Training loss: 0.16830755770206451
Validation loss: 1.3979640942747875

Epoch: 5| Step: 7
Training loss: 0.04630974680185318
Validation loss: 1.4023129292713699

Epoch: 5| Step: 8
Training loss: 0.05435891076922417
Validation loss: 1.4055407124180948

Epoch: 5| Step: 9
Training loss: 0.036667801439762115
Validation loss: 1.412452288853225

Epoch: 5| Step: 10
Training loss: 0.07595407217741013
Validation loss: 1.4207406825916742

Epoch: 576| Step: 0
Training loss: 0.05668153241276741
Validation loss: 1.3925358518477409

Epoch: 5| Step: 1
Training loss: 0.06442500650882721
Validation loss: 1.3926183292942662

Epoch: 5| Step: 2
Training loss: 0.08468843996524811
Validation loss: 1.3577884192107825

Epoch: 5| Step: 3
Training loss: 0.0653751939535141
Validation loss: 1.3759359211050055

Epoch: 5| Step: 4
Training loss: 0.10886278003454208
Validation loss: 1.3716206101961033

Epoch: 5| Step: 5
Training loss: 0.05189146846532822
Validation loss: 1.3754783317606936

Epoch: 5| Step: 6
Training loss: 0.09902111440896988
Validation loss: 1.3689238602115261

Epoch: 5| Step: 7
Training loss: 0.06515701860189438
Validation loss: 1.4031489997781732

Epoch: 5| Step: 8
Training loss: 0.11999274790287018
Validation loss: 1.3929240998401438

Epoch: 5| Step: 9
Training loss: 0.060485683381557465
Validation loss: 1.4081359198016505

Epoch: 5| Step: 10
Training loss: 0.08106822520494461
Validation loss: 1.3860422770182292

Epoch: 577| Step: 0
Training loss: 0.05954186990857124
Validation loss: 1.407036937693114

Epoch: 5| Step: 1
Training loss: 0.06854452192783356
Validation loss: 1.3881956646519322

Epoch: 5| Step: 2
Training loss: 0.15825611352920532
Validation loss: 1.410357738053927

Epoch: 5| Step: 3
Training loss: 0.04610143229365349
Validation loss: 1.4110224990434543

Epoch: 5| Step: 4
Training loss: 0.05872241407632828
Validation loss: 1.4125009864889166

Epoch: 5| Step: 5
Training loss: 0.04760000854730606
Validation loss: 1.4044787755576513

Epoch: 5| Step: 6
Training loss: 0.06505706161260605
Validation loss: 1.3994857700922156

Epoch: 5| Step: 7
Training loss: 0.09071558713912964
Validation loss: 1.384883999824524

Epoch: 5| Step: 8
Training loss: 0.05170239135622978
Validation loss: 1.3919789996198428

Epoch: 5| Step: 9
Training loss: 0.07272426784038544
Validation loss: 1.3904786898243813

Epoch: 5| Step: 10
Training loss: 0.06182025372982025
Validation loss: 1.3855421850758214

Epoch: 578| Step: 0
Training loss: 0.09430758655071259
Validation loss: 1.3919144859237056

Epoch: 5| Step: 1
Training loss: 0.09588829427957535
Validation loss: 1.3919665339172527

Epoch: 5| Step: 2
Training loss: 0.06783225387334824
Validation loss: 1.3828649302964569

Epoch: 5| Step: 3
Training loss: 0.04064713045954704
Validation loss: 1.3668896664855301

Epoch: 5| Step: 4
Training loss: 0.12075918912887573
Validation loss: 1.3862717792552004

Epoch: 5| Step: 5
Training loss: 0.05442596599459648
Validation loss: 1.3732768822741765

Epoch: 5| Step: 6
Training loss: 0.04549543932080269
Validation loss: 1.3696371252818773

Epoch: 5| Step: 7
Training loss: 0.059434760361909866
Validation loss: 1.3966018653685046

Epoch: 5| Step: 8
Training loss: 0.06906931102275848
Validation loss: 1.4094764417217625

Epoch: 5| Step: 9
Training loss: 0.07468938827514648
Validation loss: 1.432354236161837

Epoch: 5| Step: 10
Training loss: 0.08154971897602081
Validation loss: 1.4327645218500527

Epoch: 579| Step: 0
Training loss: 0.06551467627286911
Validation loss: 1.4264521867998186

Epoch: 5| Step: 1
Training loss: 0.05439606308937073
Validation loss: 1.4341187836021505

Epoch: 5| Step: 2
Training loss: 0.05952073261141777
Validation loss: 1.430999828282223

Epoch: 5| Step: 3
Training loss: 0.11786790192127228
Validation loss: 1.419563320375258

Epoch: 5| Step: 4
Training loss: 0.059209804981946945
Validation loss: 1.4374486272053053

Epoch: 5| Step: 5
Training loss: 0.04654036834836006
Validation loss: 1.4256933940354215

Epoch: 5| Step: 6
Training loss: 0.1173446774482727
Validation loss: 1.4119443047431208

Epoch: 5| Step: 7
Training loss: 0.07231908291578293
Validation loss: 1.4093561595486057

Epoch: 5| Step: 8
Training loss: 0.04540294408798218
Validation loss: 1.4269520787782566

Epoch: 5| Step: 9
Training loss: 0.05771986395120621
Validation loss: 1.4230835719775128

Epoch: 5| Step: 10
Training loss: 0.043478161096572876
Validation loss: 1.4118127720330351

Epoch: 580| Step: 0
Training loss: 0.08345060050487518
Validation loss: 1.4048557672449338

Epoch: 5| Step: 1
Training loss: 0.06855811178684235
Validation loss: 1.4034708251235306

Epoch: 5| Step: 2
Training loss: 0.046363066881895065
Validation loss: 1.3949203247665076

Epoch: 5| Step: 3
Training loss: 0.08478210866451263
Validation loss: 1.3972312699082077

Epoch: 5| Step: 4
Training loss: 0.054317064583301544
Validation loss: 1.380992066475653

Epoch: 5| Step: 5
Training loss: 0.04509531334042549
Validation loss: 1.3887273976879735

Epoch: 5| Step: 6
Training loss: 0.07328154146671295
Validation loss: 1.3849487522596955

Epoch: 5| Step: 7
Training loss: 0.08523965626955032
Validation loss: 1.4115827211769678

Epoch: 5| Step: 8
Training loss: 0.05582121014595032
Validation loss: 1.390957490090401

Epoch: 5| Step: 9
Training loss: 0.11390380561351776
Validation loss: 1.38451644169387

Epoch: 5| Step: 10
Training loss: 0.05218029022216797
Validation loss: 1.4033892693058136

Epoch: 581| Step: 0
Training loss: 0.03868534043431282
Validation loss: 1.378528700079969

Epoch: 5| Step: 1
Training loss: 0.09568528831005096
Validation loss: 1.4118041479459373

Epoch: 5| Step: 2
Training loss: 0.048134204000234604
Validation loss: 1.409269586686165

Epoch: 5| Step: 3
Training loss: 0.036939848214387894
Validation loss: 1.4186187995377408

Epoch: 5| Step: 4
Training loss: 0.07639507204294205
Validation loss: 1.4192685722022929

Epoch: 5| Step: 5
Training loss: 0.02714116871356964
Validation loss: 1.42061210063196

Epoch: 5| Step: 6
Training loss: 0.13666583597660065
Validation loss: 1.4137971619124055

Epoch: 5| Step: 7
Training loss: 0.048636335879564285
Validation loss: 1.421648548495385

Epoch: 5| Step: 8
Training loss: 0.0774466022849083
Validation loss: 1.38765468905049

Epoch: 5| Step: 9
Training loss: 0.04001135751605034
Validation loss: 1.4100710538125807

Epoch: 5| Step: 10
Training loss: 0.06261605769395828
Validation loss: 1.397570449818847

Epoch: 582| Step: 0
Training loss: 0.12341199070215225
Validation loss: 1.4183186741285427

Epoch: 5| Step: 1
Training loss: 0.05115406587719917
Validation loss: 1.4087836729582919

Epoch: 5| Step: 2
Training loss: 0.08724628388881683
Validation loss: 1.4078099612266786

Epoch: 5| Step: 3
Training loss: 0.06936018168926239
Validation loss: 1.399992496736588

Epoch: 5| Step: 4
Training loss: 0.06125492602586746
Validation loss: 1.411545971388458

Epoch: 5| Step: 5
Training loss: 0.05843331664800644
Validation loss: 1.3950653973446097

Epoch: 5| Step: 6
Training loss: 0.08213652670383453
Validation loss: 1.3983714413899246

Epoch: 5| Step: 7
Training loss: 0.06708052009344101
Validation loss: 1.4280047275686776

Epoch: 5| Step: 8
Training loss: 0.05614747852087021
Validation loss: 1.4262980440611481

Epoch: 5| Step: 9
Training loss: 0.04496227949857712
Validation loss: 1.4163075236863987

Epoch: 5| Step: 10
Training loss: 0.042876750230789185
Validation loss: 1.4205330700002692

Epoch: 583| Step: 0
Training loss: 0.044577162712812424
Validation loss: 1.4131702735859861

Epoch: 5| Step: 1
Training loss: 0.054644763469696045
Validation loss: 1.429318756185552

Epoch: 5| Step: 2
Training loss: 0.04870937764644623
Validation loss: 1.4190794864008505

Epoch: 5| Step: 3
Training loss: 0.05048570781946182
Validation loss: 1.4118975221469838

Epoch: 5| Step: 4
Training loss: 0.08711881935596466
Validation loss: 1.447977239085782

Epoch: 5| Step: 5
Training loss: 0.053774990141391754
Validation loss: 1.440576700754063

Epoch: 5| Step: 6
Training loss: 0.07614636421203613
Validation loss: 1.423000842012385

Epoch: 5| Step: 7
Training loss: 0.10403947532176971
Validation loss: 1.4241452960557834

Epoch: 5| Step: 8
Training loss: 0.12976756691932678
Validation loss: 1.4318501910855692

Epoch: 5| Step: 9
Training loss: 0.06103731319308281
Validation loss: 1.4385944348509594

Epoch: 5| Step: 10
Training loss: 0.04192246496677399
Validation loss: 1.4175646023083759

Epoch: 584| Step: 0
Training loss: 0.06146322563290596
Validation loss: 1.4300121876501268

Epoch: 5| Step: 1
Training loss: 0.12346291542053223
Validation loss: 1.4156963248406687

Epoch: 5| Step: 2
Training loss: 0.03786086291074753
Validation loss: 1.4015449977690173

Epoch: 5| Step: 3
Training loss: 0.05831156298518181
Validation loss: 1.4255547190225253

Epoch: 5| Step: 4
Training loss: 0.1010379046201706
Validation loss: 1.4081967543530207

Epoch: 5| Step: 5
Training loss: 0.0774056538939476
Validation loss: 1.4028445853981921

Epoch: 5| Step: 6
Training loss: 0.05662465840578079
Validation loss: 1.4100378187753821

Epoch: 5| Step: 7
Training loss: 0.06055796146392822
Validation loss: 1.4087061574382167

Epoch: 5| Step: 8
Training loss: 0.05885202810168266
Validation loss: 1.4105036412515948

Epoch: 5| Step: 9
Training loss: 0.05730370432138443
Validation loss: 1.4042846002886373

Epoch: 5| Step: 10
Training loss: 0.04018877446651459
Validation loss: 1.426680221993436

Epoch: 585| Step: 0
Training loss: 0.10649552196264267
Validation loss: 1.4379305519083494

Epoch: 5| Step: 1
Training loss: 0.06498818099498749
Validation loss: 1.427525706188653

Epoch: 5| Step: 2
Training loss: 0.029516732320189476
Validation loss: 1.4429196773036834

Epoch: 5| Step: 3
Training loss: 0.07968021929264069
Validation loss: 1.4408770261272308

Epoch: 5| Step: 4
Training loss: 0.08061911165714264
Validation loss: 1.4578081241217993

Epoch: 5| Step: 5
Training loss: 0.03712373226881027
Validation loss: 1.4455044743835286

Epoch: 5| Step: 6
Training loss: 0.03656299039721489
Validation loss: 1.4585008595579414

Epoch: 5| Step: 7
Training loss: 0.0502612479031086
Validation loss: 1.4469721246791143

Epoch: 5| Step: 8
Training loss: 0.12431919574737549
Validation loss: 1.4383055202422603

Epoch: 5| Step: 9
Training loss: 0.03957454860210419
Validation loss: 1.463855593435226

Epoch: 5| Step: 10
Training loss: 0.04285591468214989
Validation loss: 1.4272407575320172

Epoch: 586| Step: 0
Training loss: 0.05629650503396988
Validation loss: 1.4270985626405286

Epoch: 5| Step: 1
Training loss: 0.07285324484109879
Validation loss: 1.41805923369623

Epoch: 5| Step: 2
Training loss: 0.060996610671281815
Validation loss: 1.41872319739352

Epoch: 5| Step: 3
Training loss: 0.056401729583740234
Validation loss: 1.411233558449694

Epoch: 5| Step: 4
Training loss: 0.03819374740123749
Validation loss: 1.3901958965486096

Epoch: 5| Step: 5
Training loss: 0.03676660731434822
Validation loss: 1.3948396546866304

Epoch: 5| Step: 6
Training loss: 0.038289062678813934
Validation loss: 1.3928987826070478

Epoch: 5| Step: 7
Training loss: 0.07309125363826752
Validation loss: 1.4077712656349264

Epoch: 5| Step: 8
Training loss: 0.06042886897921562
Validation loss: 1.4156084419578634

Epoch: 5| Step: 9
Training loss: 0.08679468929767609
Validation loss: 1.4188292295702043

Epoch: 5| Step: 10
Training loss: 0.16246046125888824
Validation loss: 1.3960773816672705

Epoch: 587| Step: 0
Training loss: 0.03597257286310196
Validation loss: 1.3658336862441032

Epoch: 5| Step: 1
Training loss: 0.07731913030147552
Validation loss: 1.356566693193169

Epoch: 5| Step: 2
Training loss: 0.1292147934436798
Validation loss: 1.3524794681097871

Epoch: 5| Step: 3
Training loss: 0.1070389598608017
Validation loss: 1.3614941079129455

Epoch: 5| Step: 4
Training loss: 0.044490374624729156
Validation loss: 1.3666454874059206

Epoch: 5| Step: 5
Training loss: 0.07958345115184784
Validation loss: 1.3839658780764508

Epoch: 5| Step: 6
Training loss: 0.04522791504859924
Validation loss: 1.3876517639365247

Epoch: 5| Step: 7
Training loss: 0.03696370869874954
Validation loss: 1.4053651325164302

Epoch: 5| Step: 8
Training loss: 0.05244893580675125
Validation loss: 1.3997066636239328

Epoch: 5| Step: 9
Training loss: 0.05091625452041626
Validation loss: 1.39444939936361

Epoch: 5| Step: 10
Training loss: 0.09201131761074066
Validation loss: 1.3998665014902751

Epoch: 588| Step: 0
Training loss: 0.0451936274766922
Validation loss: 1.4127330517256131

Epoch: 5| Step: 1
Training loss: 0.03727630898356438
Validation loss: 1.4064571344724266

Epoch: 5| Step: 2
Training loss: 0.03976476192474365
Validation loss: 1.401236448236691

Epoch: 5| Step: 3
Training loss: 0.035571467131376266
Validation loss: 1.391362763220264

Epoch: 5| Step: 4
Training loss: 0.04884790629148483
Validation loss: 1.3947727519978759

Epoch: 5| Step: 5
Training loss: 0.059703003615140915
Validation loss: 1.3883545629439815

Epoch: 5| Step: 6
Training loss: 0.06913397461175919
Validation loss: 1.4163740988700622

Epoch: 5| Step: 7
Training loss: 0.10346262156963348
Validation loss: 1.3740772419078375

Epoch: 5| Step: 8
Training loss: 0.10077930986881256
Validation loss: 1.372097163431106

Epoch: 5| Step: 9
Training loss: 0.1524832546710968
Validation loss: 1.4042658831483574

Epoch: 5| Step: 10
Training loss: 0.07124146074056625
Validation loss: 1.3728174112176383

Epoch: 589| Step: 0
Training loss: 0.04880528151988983
Validation loss: 1.3636756802117953

Epoch: 5| Step: 1
Training loss: 0.07578136026859283
Validation loss: 1.360928443170363

Epoch: 5| Step: 2
Training loss: 0.07352083921432495
Validation loss: 1.3738376991723174

Epoch: 5| Step: 3
Training loss: 0.057035405188798904
Validation loss: 1.3731296729016047

Epoch: 5| Step: 4
Training loss: 0.07015445828437805
Validation loss: 1.3744547764460247

Epoch: 5| Step: 5
Training loss: 0.14185622334480286
Validation loss: 1.384332505605554

Epoch: 5| Step: 6
Training loss: 0.052895449101924896
Validation loss: 1.3703568609811927

Epoch: 5| Step: 7
Training loss: 0.05736498907208443
Validation loss: 1.3817249882605769

Epoch: 5| Step: 8
Training loss: 0.042162515223026276
Validation loss: 1.384193721637931

Epoch: 5| Step: 9
Training loss: 0.06165754795074463
Validation loss: 1.4091899356534403

Epoch: 5| Step: 10
Training loss: 0.1198086142539978
Validation loss: 1.3896527277526034

Epoch: 590| Step: 0
Training loss: 0.043167661875486374
Validation loss: 1.3944975791438934

Epoch: 5| Step: 1
Training loss: 0.041156165301799774
Validation loss: 1.4065674979199645

Epoch: 5| Step: 2
Training loss: 0.07174312323331833
Validation loss: 1.401705813664262

Epoch: 5| Step: 3
Training loss: 0.08633855730295181
Validation loss: 1.4234323437495897

Epoch: 5| Step: 4
Training loss: 0.05368747189640999
Validation loss: 1.401707036520845

Epoch: 5| Step: 5
Training loss: 0.04478798061609268
Validation loss: 1.3890212524321772

Epoch: 5| Step: 6
Training loss: 0.05417945235967636
Validation loss: 1.4004091242308259

Epoch: 5| Step: 7
Training loss: 0.03563633933663368
Validation loss: 1.4009432651663338

Epoch: 5| Step: 8
Training loss: 0.0977223739027977
Validation loss: 1.3923781187303605

Epoch: 5| Step: 9
Training loss: 0.056484121829271317
Validation loss: 1.419827425351707

Epoch: 5| Step: 10
Training loss: 0.13717186450958252
Validation loss: 1.3869413073344896

Epoch: 591| Step: 0
Training loss: 0.07906567305326462
Validation loss: 1.3909154886840491

Epoch: 5| Step: 1
Training loss: 0.058379221707582474
Validation loss: 1.4057949973690895

Epoch: 5| Step: 2
Training loss: 0.0576038733124733
Validation loss: 1.3798851813039472

Epoch: 5| Step: 3
Training loss: 0.06758123636245728
Validation loss: 1.3822046928508307

Epoch: 5| Step: 4
Training loss: 0.05213587358593941
Validation loss: 1.3790027620971843

Epoch: 5| Step: 5
Training loss: 0.05927858501672745
Validation loss: 1.370115594197345

Epoch: 5| Step: 6
Training loss: 0.055537570267915726
Validation loss: 1.3898174826816847

Epoch: 5| Step: 7
Training loss: 0.0396917499601841
Validation loss: 1.3751241058431647

Epoch: 5| Step: 8
Training loss: 0.1410340964794159
Validation loss: 1.3749178455721947

Epoch: 5| Step: 9
Training loss: 0.0526207871735096
Validation loss: 1.3898402260195823

Epoch: 5| Step: 10
Training loss: 0.06811653077602386
Validation loss: 1.3704700200788436

Epoch: 592| Step: 0
Training loss: 0.1366867572069168
Validation loss: 1.36430694723642

Epoch: 5| Step: 1
Training loss: 0.0778009444475174
Validation loss: 1.3834103973962928

Epoch: 5| Step: 2
Training loss: 0.08194612711668015
Validation loss: 1.3732471940337971

Epoch: 5| Step: 3
Training loss: 0.05662590265274048
Validation loss: 1.3765570957173583

Epoch: 5| Step: 4
Training loss: 0.03723173215985298
Validation loss: 1.3865355804402342

Epoch: 5| Step: 5
Training loss: 0.03501320630311966
Validation loss: 1.3888112870595788

Epoch: 5| Step: 6
Training loss: 0.06056720018386841
Validation loss: 1.4016835984363352

Epoch: 5| Step: 7
Training loss: 0.040019355714321136
Validation loss: 1.3896494193743634

Epoch: 5| Step: 8
Training loss: 0.047105006873607635
Validation loss: 1.375651608231247

Epoch: 5| Step: 9
Training loss: 0.0306277833878994
Validation loss: 1.3666909484453098

Epoch: 5| Step: 10
Training loss: 0.06549954414367676
Validation loss: 1.3729762723368983

Epoch: 593| Step: 0
Training loss: 0.04565393179655075
Validation loss: 1.37106801232984

Epoch: 5| Step: 1
Training loss: 0.04328400269150734
Validation loss: 1.353693107123016

Epoch: 5| Step: 2
Training loss: 0.05432133004069328
Validation loss: 1.3663790264437277

Epoch: 5| Step: 3
Training loss: 0.04021671041846275
Validation loss: 1.3735922587815153

Epoch: 5| Step: 4
Training loss: 0.04600336030125618
Validation loss: 1.3612357147278324

Epoch: 5| Step: 5
Training loss: 0.06526373326778412
Validation loss: 1.3561581668033396

Epoch: 5| Step: 6
Training loss: 0.05485130101442337
Validation loss: 1.3750716576012232

Epoch: 5| Step: 7
Training loss: 0.13906076550483704
Validation loss: 1.3684959546212228

Epoch: 5| Step: 8
Training loss: 0.09787006676197052
Validation loss: 1.389308565406389

Epoch: 5| Step: 9
Training loss: 0.05431690067052841
Validation loss: 1.3750204258067633

Epoch: 5| Step: 10
Training loss: 0.07106363028287888
Validation loss: 1.3867641802757018

Epoch: 594| Step: 0
Training loss: 0.05171797424554825
Validation loss: 1.396624788161247

Epoch: 5| Step: 1
Training loss: 0.13317447900772095
Validation loss: 1.3804904235306608

Epoch: 5| Step: 2
Training loss: 0.043137114495038986
Validation loss: 1.3931703657232306

Epoch: 5| Step: 3
Training loss: 0.0548427477478981
Validation loss: 1.3791324887224423

Epoch: 5| Step: 4
Training loss: 0.09141187369823456
Validation loss: 1.4028567338502536

Epoch: 5| Step: 5
Training loss: 0.044664375483989716
Validation loss: 1.3976459656992266

Epoch: 5| Step: 6
Training loss: 0.04789969325065613
Validation loss: 1.3760697803189677

Epoch: 5| Step: 7
Training loss: 0.042912259697914124
Validation loss: 1.383665220711821

Epoch: 5| Step: 8
Training loss: 0.07147859036922455
Validation loss: 1.3942080210613947

Epoch: 5| Step: 9
Training loss: 0.05874697491526604
Validation loss: 1.3964450320889872

Epoch: 5| Step: 10
Training loss: 0.045641619712114334
Validation loss: 1.3818428657388175

Epoch: 595| Step: 0
Training loss: 0.04594471678137779
Validation loss: 1.3759572006041003

Epoch: 5| Step: 1
Training loss: 0.04143577069044113
Validation loss: 1.3708042290902906

Epoch: 5| Step: 2
Training loss: 0.04794273152947426
Validation loss: 1.3681188642337758

Epoch: 5| Step: 3
Training loss: 0.04722723364830017
Validation loss: 1.4155639615110172

Epoch: 5| Step: 4
Training loss: 0.04209711775183678
Validation loss: 1.3927022692977742

Epoch: 5| Step: 5
Training loss: 0.07080627232789993
Validation loss: 1.3806582599557855

Epoch: 5| Step: 6
Training loss: 0.09275601804256439
Validation loss: 1.378170765856261

Epoch: 5| Step: 7
Training loss: 0.13871993124485016
Validation loss: 1.3966388074300622

Epoch: 5| Step: 8
Training loss: 0.060954928398132324
Validation loss: 1.4025424097173957

Epoch: 5| Step: 9
Training loss: 0.08530182391405106
Validation loss: 1.3786772540820542

Epoch: 5| Step: 10
Training loss: 0.058978382498025894
Validation loss: 1.382375301853303

Epoch: 596| Step: 0
Training loss: 0.05059196799993515
Validation loss: 1.3956499458641134

Epoch: 5| Step: 1
Training loss: 0.03245699033141136
Validation loss: 1.368872743780895

Epoch: 5| Step: 2
Training loss: 0.051346875727176666
Validation loss: 1.400230638442501

Epoch: 5| Step: 3
Training loss: 0.07093401998281479
Validation loss: 1.3637570488837458

Epoch: 5| Step: 4
Training loss: 0.09177820384502411
Validation loss: 1.3625420819046676

Epoch: 5| Step: 5
Training loss: 0.04771341383457184
Validation loss: 1.3737762563972062

Epoch: 5| Step: 6
Training loss: 0.05897121876478195
Validation loss: 1.389319323724316

Epoch: 5| Step: 7
Training loss: 0.14514948427677155
Validation loss: 1.3889052073160808

Epoch: 5| Step: 8
Training loss: 0.043102748692035675
Validation loss: 1.3784357142704788

Epoch: 5| Step: 9
Training loss: 0.024185234680771828
Validation loss: 1.3937193962835497

Epoch: 5| Step: 10
Training loss: 0.05827724188566208
Validation loss: 1.40648695986758

Epoch: 597| Step: 0
Training loss: 0.05905020236968994
Validation loss: 1.3910317401732168

Epoch: 5| Step: 1
Training loss: 0.12901155650615692
Validation loss: 1.4057828431488366

Epoch: 5| Step: 2
Training loss: 0.05012570694088936
Validation loss: 1.3818422414923226

Epoch: 5| Step: 3
Training loss: 0.059107404202222824
Validation loss: 1.3885591363394132

Epoch: 5| Step: 4
Training loss: 0.07564613968133926
Validation loss: 1.3787474606626777

Epoch: 5| Step: 5
Training loss: 0.042418599128723145
Validation loss: 1.3744835443394159

Epoch: 5| Step: 6
Training loss: 0.05608990788459778
Validation loss: 1.3901331219621884

Epoch: 5| Step: 7
Training loss: 0.044817004352808
Validation loss: 1.36300794283549

Epoch: 5| Step: 8
Training loss: 0.06456995755434036
Validation loss: 1.3636131004620624

Epoch: 5| Step: 9
Training loss: 0.0603400282561779
Validation loss: 1.3843794362519377

Epoch: 5| Step: 10
Training loss: 0.03316055238246918
Validation loss: 1.3958057498419156

Epoch: 598| Step: 0
Training loss: 0.07529888302087784
Validation loss: 1.3918845525351904

Epoch: 5| Step: 1
Training loss: 0.0528857596218586
Validation loss: 1.3985524049369238

Epoch: 5| Step: 2
Training loss: 0.062069375067949295
Validation loss: 1.410910306438323

Epoch: 5| Step: 3
Training loss: 0.048706017434597015
Validation loss: 1.3818639081011537

Epoch: 5| Step: 4
Training loss: 0.1258094608783722
Validation loss: 1.3946598550324798

Epoch: 5| Step: 5
Training loss: 0.05407252162694931
Validation loss: 1.3809849869820379

Epoch: 5| Step: 6
Training loss: 0.036567918956279755
Validation loss: 1.3831661337165422

Epoch: 5| Step: 7
Training loss: 0.07269784063100815
Validation loss: 1.3932072449755926

Epoch: 5| Step: 8
Training loss: 0.06870625168085098
Validation loss: 1.3820001040735552

Epoch: 5| Step: 9
Training loss: 0.033851027488708496
Validation loss: 1.3821724768607848

Epoch: 5| Step: 10
Training loss: 0.05080803856253624
Validation loss: 1.374152256596473

Epoch: 599| Step: 0
Training loss: 0.07056514918804169
Validation loss: 1.3936362958723498

Epoch: 5| Step: 1
Training loss: 0.047789961099624634
Validation loss: 1.37730170706267

Epoch: 5| Step: 2
Training loss: 0.0940091609954834
Validation loss: 1.3724918602615275

Epoch: 5| Step: 3
Training loss: 0.05767650157213211
Validation loss: 1.384517668395914

Epoch: 5| Step: 4
Training loss: 0.0736343264579773
Validation loss: 1.3781404456784647

Epoch: 5| Step: 5
Training loss: 0.08162161707878113
Validation loss: 1.395205610541887

Epoch: 5| Step: 6
Training loss: 0.14992022514343262
Validation loss: 1.3964768404601722

Epoch: 5| Step: 7
Training loss: 0.05908992141485214
Validation loss: 1.4162518439754364

Epoch: 5| Step: 8
Training loss: 0.053596675395965576
Validation loss: 1.377445787511846

Epoch: 5| Step: 9
Training loss: 0.04908185452222824
Validation loss: 1.3898492064527286

Epoch: 5| Step: 10
Training loss: 0.04798464849591255
Validation loss: 1.3853059404639787

Epoch: 600| Step: 0
Training loss: 0.04074835777282715
Validation loss: 1.3608306454073997

Epoch: 5| Step: 1
Training loss: 0.12284501641988754
Validation loss: 1.3654471244863284

Epoch: 5| Step: 2
Training loss: 0.03221819922327995
Validation loss: 1.3734205986863823

Epoch: 5| Step: 3
Training loss: 0.12203395366668701
Validation loss: 1.366469467839887

Epoch: 5| Step: 4
Training loss: 0.07565544545650482
Validation loss: 1.3608384029839629

Epoch: 5| Step: 5
Training loss: 0.050317637622356415
Validation loss: 1.375357307413573

Epoch: 5| Step: 6
Training loss: 0.06618373095989227
Validation loss: 1.3516651071527952

Epoch: 5| Step: 7
Training loss: 0.049229882657527924
Validation loss: 1.3506072400718607

Epoch: 5| Step: 8
Training loss: 0.044409461319446564
Validation loss: 1.3538738745515064

Epoch: 5| Step: 9
Training loss: 0.07149144262075424
Validation loss: 1.3586149625880743

Epoch: 5| Step: 10
Training loss: 0.0565616711974144
Validation loss: 1.3448783127210473

Epoch: 601| Step: 0
Training loss: 0.13553164899349213
Validation loss: 1.3694865959946827

Epoch: 5| Step: 1
Training loss: 0.08353175967931747
Validation loss: 1.3617651001099618

Epoch: 5| Step: 2
Training loss: 0.03483499214053154
Validation loss: 1.3609331577054915

Epoch: 5| Step: 3
Training loss: 0.04768138378858566
Validation loss: 1.3507427566794938

Epoch: 5| Step: 4
Training loss: 0.06407401710748672
Validation loss: 1.361753345817648

Epoch: 5| Step: 5
Training loss: 0.07992497086524963
Validation loss: 1.3803882368149296

Epoch: 5| Step: 6
Training loss: 0.038108158856630325
Validation loss: 1.3498252752006694

Epoch: 5| Step: 7
Training loss: 0.051529884338378906
Validation loss: 1.368214132965252

Epoch: 5| Step: 8
Training loss: 0.0436599925160408
Validation loss: 1.4032815066717004

Epoch: 5| Step: 9
Training loss: 0.06964297592639923
Validation loss: 1.3782070272712297

Epoch: 5| Step: 10
Training loss: 0.039671044796705246
Validation loss: 1.3858202003663587

Epoch: 602| Step: 0
Training loss: 0.03198618441820145
Validation loss: 1.390085220336914

Epoch: 5| Step: 1
Training loss: 0.04277151823043823
Validation loss: 1.4075006336294196

Epoch: 5| Step: 2
Training loss: 0.06170622259378433
Validation loss: 1.401995587092574

Epoch: 5| Step: 3
Training loss: 0.06852899491786957
Validation loss: 1.4122714560518983

Epoch: 5| Step: 4
Training loss: 0.08469022810459137
Validation loss: 1.3988881341872677

Epoch: 5| Step: 5
Training loss: 0.049605853855609894
Validation loss: 1.395230165091894

Epoch: 5| Step: 6
Training loss: 0.04083925485610962
Validation loss: 1.3881349807144494

Epoch: 5| Step: 7
Training loss: 0.13030989468097687
Validation loss: 1.3890738589789278

Epoch: 5| Step: 8
Training loss: 0.05179411172866821
Validation loss: 1.3889206776054956

Epoch: 5| Step: 9
Training loss: 0.04801499843597412
Validation loss: 1.3825672736731909

Epoch: 5| Step: 10
Training loss: 0.043501224368810654
Validation loss: 1.4053560303103538

Epoch: 603| Step: 0
Training loss: 0.04874100536108017
Validation loss: 1.3807703948790027

Epoch: 5| Step: 1
Training loss: 0.05604024603962898
Validation loss: 1.3861141698334807

Epoch: 5| Step: 2
Training loss: 0.05175214260816574
Validation loss: 1.3509338132796749

Epoch: 5| Step: 3
Training loss: 0.0788683146238327
Validation loss: 1.3763942026322888

Epoch: 5| Step: 4
Training loss: 0.048655517399311066
Validation loss: 1.3564678033192952

Epoch: 5| Step: 5
Training loss: 0.029786307364702225
Validation loss: 1.3563028484262445

Epoch: 5| Step: 6
Training loss: 0.0692039355635643
Validation loss: 1.3594991737796414

Epoch: 5| Step: 7
Training loss: 0.07637473195791245
Validation loss: 1.3590512711514708

Epoch: 5| Step: 8
Training loss: 0.12814466655254364
Validation loss: 1.3790433124829364

Epoch: 5| Step: 9
Training loss: 0.026933962479233742
Validation loss: 1.350997991459344

Epoch: 5| Step: 10
Training loss: 0.05377088114619255
Validation loss: 1.3678578369079097

Epoch: 604| Step: 0
Training loss: 0.0428856797516346
Validation loss: 1.3638618556402062

Epoch: 5| Step: 1
Training loss: 0.06889895349740982
Validation loss: 1.3633456358345606

Epoch: 5| Step: 2
Training loss: 0.06731364876031876
Validation loss: 1.359466483516078

Epoch: 5| Step: 3
Training loss: 0.06094133108854294
Validation loss: 1.354470476027458

Epoch: 5| Step: 4
Training loss: 0.05918685346841812
Validation loss: 1.3625424267143331

Epoch: 5| Step: 5
Training loss: 0.040685445070266724
Validation loss: 1.3495650227351854

Epoch: 5| Step: 6
Training loss: 0.05426643416285515
Validation loss: 1.3704651696707613

Epoch: 5| Step: 7
Training loss: 0.043025389313697815
Validation loss: 1.348573738528836

Epoch: 5| Step: 8
Training loss: 0.03489697724580765
Validation loss: 1.348348213780311

Epoch: 5| Step: 9
Training loss: 0.11935548484325409
Validation loss: 1.3425130010933004

Epoch: 5| Step: 10
Training loss: 0.09277629107236862
Validation loss: 1.356248624863163

Epoch: 605| Step: 0
Training loss: 0.046115923672914505
Validation loss: 1.3606397592893211

Epoch: 5| Step: 1
Training loss: 0.038408298045396805
Validation loss: 1.371858367355921

Epoch: 5| Step: 2
Training loss: 0.06971675157546997
Validation loss: 1.3423780228502007

Epoch: 5| Step: 3
Training loss: 0.036808792501688004
Validation loss: 1.3751744865089335

Epoch: 5| Step: 4
Training loss: 0.03750971332192421
Validation loss: 1.3581468988490362

Epoch: 5| Step: 5
Training loss: 0.028980713337659836
Validation loss: 1.379954562392286

Epoch: 5| Step: 6
Training loss: 0.07100881636142731
Validation loss: 1.3808635332251107

Epoch: 5| Step: 7
Training loss: 0.053621720522642136
Validation loss: 1.3719027914026731

Epoch: 5| Step: 8
Training loss: 0.1210763230919838
Validation loss: 1.393027259457496

Epoch: 5| Step: 9
Training loss: 0.08164292573928833
Validation loss: 1.380887085391629

Epoch: 5| Step: 10
Training loss: 0.046891387552022934
Validation loss: 1.3612362031013734

Epoch: 606| Step: 0
Training loss: 0.10365904867649078
Validation loss: 1.3821661818412043

Epoch: 5| Step: 1
Training loss: 0.04522542282938957
Validation loss: 1.3670443322068901

Epoch: 5| Step: 2
Training loss: 0.047228939831256866
Validation loss: 1.3697418262881618

Epoch: 5| Step: 3
Training loss: 0.1253661960363388
Validation loss: 1.350591831309821

Epoch: 5| Step: 4
Training loss: 0.040287550538778305
Validation loss: 1.359096561708758

Epoch: 5| Step: 5
Training loss: 0.04213566333055496
Validation loss: 1.3715277743595902

Epoch: 5| Step: 6
Training loss: 0.03203630447387695
Validation loss: 1.371367592965403

Epoch: 5| Step: 7
Training loss: 0.07198910415172577
Validation loss: 1.3552785535012521

Epoch: 5| Step: 8
Training loss: 0.06207669526338577
Validation loss: 1.3422099441610358

Epoch: 5| Step: 9
Training loss: 0.06921510398387909
Validation loss: 1.3594248115375478

Epoch: 5| Step: 10
Training loss: 0.08095613121986389
Validation loss: 1.3293265258112261

Epoch: 607| Step: 0
Training loss: 0.060443758964538574
Validation loss: 1.351532014467383

Epoch: 5| Step: 1
Training loss: 0.040427543222904205
Validation loss: 1.3499436500251933

Epoch: 5| Step: 2
Training loss: 0.05470094829797745
Validation loss: 1.3575523463628625

Epoch: 5| Step: 3
Training loss: 0.05929455906152725
Validation loss: 1.372647439279864

Epoch: 5| Step: 4
Training loss: 0.05925978347659111
Validation loss: 1.3785086395919963

Epoch: 5| Step: 5
Training loss: 0.06549523770809174
Validation loss: 1.3883356035396617

Epoch: 5| Step: 6
Training loss: 0.042979296296834946
Validation loss: 1.401444104409987

Epoch: 5| Step: 7
Training loss: 0.06885699927806854
Validation loss: 1.3807089553084424

Epoch: 5| Step: 8
Training loss: 0.05778085067868233
Validation loss: 1.3999628149053103

Epoch: 5| Step: 9
Training loss: 0.05076248198747635
Validation loss: 1.4260353042233376

Epoch: 5| Step: 10
Training loss: 0.13647828996181488
Validation loss: 1.417369996988645

Epoch: 608| Step: 0
Training loss: 0.03596014529466629
Validation loss: 1.436731771756244

Epoch: 5| Step: 1
Training loss: 0.042907919734716415
Validation loss: 1.4189021049007293

Epoch: 5| Step: 2
Training loss: 0.04262896999716759
Validation loss: 1.4443319978252533

Epoch: 5| Step: 3
Training loss: 0.02881889045238495
Validation loss: 1.4411715025542884

Epoch: 5| Step: 4
Training loss: 0.06828337162733078
Validation loss: 1.4332027896758048

Epoch: 5| Step: 5
Training loss: 0.040923964232206345
Validation loss: 1.4156711511714484

Epoch: 5| Step: 6
Training loss: 0.05349373817443848
Validation loss: 1.4205850913960447

Epoch: 5| Step: 7
Training loss: 0.050212789326906204
Validation loss: 1.4031991471526444

Epoch: 5| Step: 8
Training loss: 0.15663708746433258
Validation loss: 1.401006789617641

Epoch: 5| Step: 9
Training loss: 0.0875435471534729
Validation loss: 1.4039294078785887

Epoch: 5| Step: 10
Training loss: 0.08949583023786545
Validation loss: 1.3998159670060681

Epoch: 609| Step: 0
Training loss: 0.06966917961835861
Validation loss: 1.3694056131506478

Epoch: 5| Step: 1
Training loss: 0.0640898197889328
Validation loss: 1.38506200621205

Epoch: 5| Step: 2
Training loss: 0.05758626386523247
Validation loss: 1.375850227571303

Epoch: 5| Step: 3
Training loss: 0.05893746763467789
Validation loss: 1.37029149839955

Epoch: 5| Step: 4
Training loss: 0.06705054640769958
Validation loss: 1.3871408906034244

Epoch: 5| Step: 5
Training loss: 0.05427604913711548
Validation loss: 1.391124326695678

Epoch: 5| Step: 6
Training loss: 0.04499772936105728
Validation loss: 1.4193566153126378

Epoch: 5| Step: 7
Training loss: 0.06768520921468735
Validation loss: 1.4355106776760471

Epoch: 5| Step: 8
Training loss: 0.16279198229312897
Validation loss: 1.4403384949571343

Epoch: 5| Step: 9
Training loss: 0.07891742140054703
Validation loss: 1.4063531179581918

Epoch: 5| Step: 10
Training loss: 0.051196835935115814
Validation loss: 1.4126597399352698

Epoch: 610| Step: 0
Training loss: 0.05352352187037468
Validation loss: 1.3976858213383665

Epoch: 5| Step: 1
Training loss: 0.046135034412145615
Validation loss: 1.3944866823893722

Epoch: 5| Step: 2
Training loss: 0.08801231533288956
Validation loss: 1.389930513597304

Epoch: 5| Step: 3
Training loss: 0.0589815154671669
Validation loss: 1.3838625761770433

Epoch: 5| Step: 4
Training loss: 0.06373587995767593
Validation loss: 1.4077335275629514

Epoch: 5| Step: 5
Training loss: 0.04119950532913208
Validation loss: 1.376046137143207

Epoch: 5| Step: 6
Training loss: 0.03514258190989494
Validation loss: 1.39310238950996

Epoch: 5| Step: 7
Training loss: 0.04527126997709274
Validation loss: 1.3789581214227984

Epoch: 5| Step: 8
Training loss: 0.05275958776473999
Validation loss: 1.390406358626581

Epoch: 5| Step: 9
Training loss: 0.043917469680309296
Validation loss: 1.3884267473733554

Epoch: 5| Step: 10
Training loss: 0.15801453590393066
Validation loss: 1.4013777676449026

Epoch: 611| Step: 0
Training loss: 0.062322068959474564
Validation loss: 1.3959088786955802

Epoch: 5| Step: 1
Training loss: 0.05480077117681503
Validation loss: 1.366532603899638

Epoch: 5| Step: 2
Training loss: 0.053183455020189285
Validation loss: 1.3878609890578895

Epoch: 5| Step: 3
Training loss: 0.04939963296055794
Validation loss: 1.3707138928033973

Epoch: 5| Step: 4
Training loss: 0.0640924870967865
Validation loss: 1.3788826491243096

Epoch: 5| Step: 5
Training loss: 0.06346913427114487
Validation loss: 1.3570322170052478

Epoch: 5| Step: 6
Training loss: 0.04491601511836052
Validation loss: 1.3752950968280915

Epoch: 5| Step: 7
Training loss: 0.08675388246774673
Validation loss: 1.3694028610824256

Epoch: 5| Step: 8
Training loss: 0.07465013116598129
Validation loss: 1.3737218251792334

Epoch: 5| Step: 9
Training loss: 0.05677909776568413
Validation loss: 1.3711847797516854

Epoch: 5| Step: 10
Training loss: 0.14347006380558014
Validation loss: 1.3488520601744294

Epoch: 612| Step: 0
Training loss: 0.06472276896238327
Validation loss: 1.3565258825978925

Epoch: 5| Step: 1
Training loss: 0.06000538915395737
Validation loss: 1.3663835602421914

Epoch: 5| Step: 2
Training loss: 0.07589074224233627
Validation loss: 1.3739823282405894

Epoch: 5| Step: 3
Training loss: 0.04856715723872185
Validation loss: 1.3660065499685143

Epoch: 5| Step: 4
Training loss: 0.05042340233922005
Validation loss: 1.3508644809005081

Epoch: 5| Step: 5
Training loss: 0.047028522938489914
Validation loss: 1.3678262528552805

Epoch: 5| Step: 6
Training loss: 0.08478201925754547
Validation loss: 1.3958712495783323

Epoch: 5| Step: 7
Training loss: 0.07068526744842529
Validation loss: 1.4011383684732581

Epoch: 5| Step: 8
Training loss: 0.04565759748220444
Validation loss: 1.4077140926032938

Epoch: 5| Step: 9
Training loss: 0.11983891576528549
Validation loss: 1.4018742986904678

Epoch: 5| Step: 10
Training loss: 0.036310695111751556
Validation loss: 1.414316354259368

Epoch: 613| Step: 0
Training loss: 0.03788898512721062
Validation loss: 1.4061538416852233

Epoch: 5| Step: 1
Training loss: 0.04023325443267822
Validation loss: 1.4176019609615367

Epoch: 5| Step: 2
Training loss: 0.058744896203279495
Validation loss: 1.420908058843305

Epoch: 5| Step: 3
Training loss: 0.06328411400318146
Validation loss: 1.3921274805581698

Epoch: 5| Step: 4
Training loss: 0.07145325839519501
Validation loss: 1.405170061255014

Epoch: 5| Step: 5
Training loss: 0.036333732306957245
Validation loss: 1.3913578923030565

Epoch: 5| Step: 6
Training loss: 0.0389900766313076
Validation loss: 1.3993169812745945

Epoch: 5| Step: 7
Training loss: 0.0584942027926445
Validation loss: 1.3854253317720147

Epoch: 5| Step: 8
Training loss: 0.1580391526222229
Validation loss: 1.3752471170117777

Epoch: 5| Step: 9
Training loss: 0.03838343173265457
Validation loss: 1.371100543647684

Epoch: 5| Step: 10
Training loss: 0.04250288009643555
Validation loss: 1.3808363483798118

Epoch: 614| Step: 0
Training loss: 0.07503916323184967
Validation loss: 1.405906049154138

Epoch: 5| Step: 1
Training loss: 0.05072609707713127
Validation loss: 1.391845735170508

Epoch: 5| Step: 2
Training loss: 0.04649728164076805
Validation loss: 1.4116147025938957

Epoch: 5| Step: 3
Training loss: 0.04632426053285599
Validation loss: 1.365786612033844

Epoch: 5| Step: 4
Training loss: 0.034999679774045944
Validation loss: 1.3565059733647171

Epoch: 5| Step: 5
Training loss: 0.05181317403912544
Validation loss: 1.375474226731126

Epoch: 5| Step: 6
Training loss: 0.09317187964916229
Validation loss: 1.383418103700043

Epoch: 5| Step: 7
Training loss: 0.03707500547170639
Validation loss: 1.3908983289554555

Epoch: 5| Step: 8
Training loss: 0.04865867644548416
Validation loss: 1.3870903753465222

Epoch: 5| Step: 9
Training loss: 0.11941751092672348
Validation loss: 1.3939152276644142

Epoch: 5| Step: 10
Training loss: 0.04294823855161667
Validation loss: 1.4012963079637097

Epoch: 615| Step: 0
Training loss: 0.04202260822057724
Validation loss: 1.4026918142072615

Epoch: 5| Step: 1
Training loss: 0.0632067322731018
Validation loss: 1.4012724135511665

Epoch: 5| Step: 2
Training loss: 0.04217292368412018
Validation loss: 1.3802006078022782

Epoch: 5| Step: 3
Training loss: 0.040270257741212845
Validation loss: 1.3953080074761504

Epoch: 5| Step: 4
Training loss: 0.05522772669792175
Validation loss: 1.3938674888303202

Epoch: 5| Step: 5
Training loss: 0.07934508472681046
Validation loss: 1.3841252032146658

Epoch: 5| Step: 6
Training loss: 0.1309661716222763
Validation loss: 1.393796295248052

Epoch: 5| Step: 7
Training loss: 0.048383332788944244
Validation loss: 1.3727967508377568

Epoch: 5| Step: 8
Training loss: 0.06023014336824417
Validation loss: 1.4184622533859745

Epoch: 5| Step: 9
Training loss: 0.04081340134143829
Validation loss: 1.3874397643150822

Epoch: 5| Step: 10
Training loss: 0.04438994824886322
Validation loss: 1.3840757108503772

Epoch: 616| Step: 0
Training loss: 0.054629527032375336
Validation loss: 1.3755117590709398

Epoch: 5| Step: 1
Training loss: 0.060418594628572464
Validation loss: 1.4060051120737547

Epoch: 5| Step: 2
Training loss: 0.04233507812023163
Validation loss: 1.3765845555131153

Epoch: 5| Step: 3
Training loss: 0.041142091155052185
Validation loss: 1.3808696641716907

Epoch: 5| Step: 4
Training loss: 0.1060744971036911
Validation loss: 1.3683635637324343

Epoch: 5| Step: 5
Training loss: 0.06001649424433708
Validation loss: 1.3986202048999008

Epoch: 5| Step: 6
Training loss: 0.030533593147993088
Validation loss: 1.4199203406610796

Epoch: 5| Step: 7
Training loss: 0.030700266361236572
Validation loss: 1.3929775350837297

Epoch: 5| Step: 8
Training loss: 0.083948515355587
Validation loss: 1.401411021909406

Epoch: 5| Step: 9
Training loss: 0.08941890299320221
Validation loss: 1.3903963802963175

Epoch: 5| Step: 10
Training loss: 0.07621139287948608
Validation loss: 1.4070009441785916

Epoch: 617| Step: 0
Training loss: 0.06549862027168274
Validation loss: 1.3780348518843293

Epoch: 5| Step: 1
Training loss: 0.07345057278871536
Validation loss: 1.3955819875963273

Epoch: 5| Step: 2
Training loss: 0.04999988526105881
Validation loss: 1.4125661068065192

Epoch: 5| Step: 3
Training loss: 0.07275460660457611
Validation loss: 1.4284292408215102

Epoch: 5| Step: 4
Training loss: 0.043174922466278076
Validation loss: 1.427397890757489

Epoch: 5| Step: 5
Training loss: 0.04926517605781555
Validation loss: 1.4288209087105208

Epoch: 5| Step: 6
Training loss: 0.05391724035143852
Validation loss: 1.4119645459677583

Epoch: 5| Step: 7
Training loss: 0.15371987223625183
Validation loss: 1.3986910453406713

Epoch: 5| Step: 8
Training loss: 0.05500032752752304
Validation loss: 1.4026757017258675

Epoch: 5| Step: 9
Training loss: 0.07597187906503677
Validation loss: 1.4089659907484566

Epoch: 5| Step: 10
Training loss: 0.07800230383872986
Validation loss: 1.4148011643399474

Epoch: 618| Step: 0
Training loss: 0.10599923133850098
Validation loss: 1.4039324047744914

Epoch: 5| Step: 1
Training loss: 0.07492795586585999
Validation loss: 1.4285267886295114

Epoch: 5| Step: 2
Training loss: 0.06014549732208252
Validation loss: 1.4161499751511442

Epoch: 5| Step: 3
Training loss: 0.08819212764501572
Validation loss: 1.4108557457564979

Epoch: 5| Step: 4
Training loss: 0.09536904096603394
Validation loss: 1.4134104059588524

Epoch: 5| Step: 5
Training loss: 0.05848891660571098
Validation loss: 1.4137294189904326

Epoch: 5| Step: 6
Training loss: 0.055548787117004395
Validation loss: 1.403528037891593

Epoch: 5| Step: 7
Training loss: 0.07030777633190155
Validation loss: 1.403072795560283

Epoch: 5| Step: 8
Training loss: 0.06505550444126129
Validation loss: 1.4078661998112996

Epoch: 5| Step: 9
Training loss: 0.05321810394525528
Validation loss: 1.4370086353312257

Epoch: 5| Step: 10
Training loss: 0.07663488388061523
Validation loss: 1.4234683513641357

Epoch: 619| Step: 0
Training loss: 0.07922416925430298
Validation loss: 1.423690430579647

Epoch: 5| Step: 1
Training loss: 0.05056758597493172
Validation loss: 1.42031846251539

Epoch: 5| Step: 2
Training loss: 0.05301351472735405
Validation loss: 1.3945920134103427

Epoch: 5| Step: 3
Training loss: 0.12699846923351288
Validation loss: 1.4044716409457627

Epoch: 5| Step: 4
Training loss: 0.048530854284763336
Validation loss: 1.391870625557438

Epoch: 5| Step: 5
Training loss: 0.058072127401828766
Validation loss: 1.3715555475604149

Epoch: 5| Step: 6
Training loss: 0.09687277674674988
Validation loss: 1.3914386546739967

Epoch: 5| Step: 7
Training loss: 0.03714551031589508
Validation loss: 1.3705459051234747

Epoch: 5| Step: 8
Training loss: 0.06848786771297455
Validation loss: 1.3777611313327667

Epoch: 5| Step: 9
Training loss: 0.08740075677633286
Validation loss: 1.3749956289927165

Epoch: 5| Step: 10
Training loss: 0.06976550072431564
Validation loss: 1.3926118561016616

Epoch: 620| Step: 0
Training loss: 0.058675844222307205
Validation loss: 1.3945889985689552

Epoch: 5| Step: 1
Training loss: 0.13065925240516663
Validation loss: 1.3868811361251339

Epoch: 5| Step: 2
Training loss: 0.07781064510345459
Validation loss: 1.4010877275979647

Epoch: 5| Step: 3
Training loss: 0.046503227204084396
Validation loss: 1.3851843136613087

Epoch: 5| Step: 4
Training loss: 0.047278471291065216
Validation loss: 1.3908047188994705

Epoch: 5| Step: 5
Training loss: 0.0620776042342186
Validation loss: 1.3884681040240872

Epoch: 5| Step: 6
Training loss: 0.06499837338924408
Validation loss: 1.39505777435918

Epoch: 5| Step: 7
Training loss: 0.07503283768892288
Validation loss: 1.3915660086498465

Epoch: 5| Step: 8
Training loss: 0.05509483814239502
Validation loss: 1.3865312658330446

Epoch: 5| Step: 9
Training loss: 0.057175278663635254
Validation loss: 1.4140752528303413

Epoch: 5| Step: 10
Training loss: 0.030789390206336975
Validation loss: 1.408119491351548

Epoch: 621| Step: 0
Training loss: 0.037883613258600235
Validation loss: 1.4113281023117803

Epoch: 5| Step: 1
Training loss: 0.051487185060977936
Validation loss: 1.3931668631492122

Epoch: 5| Step: 2
Training loss: 0.05970964580774307
Validation loss: 1.408503286300167

Epoch: 5| Step: 3
Training loss: 0.04239099472761154
Validation loss: 1.402567913455348

Epoch: 5| Step: 4
Training loss: 0.05983634665608406
Validation loss: 1.3909449654240762

Epoch: 5| Step: 5
Training loss: 0.06963261216878891
Validation loss: 1.3918424255104476

Epoch: 5| Step: 6
Training loss: 0.18463777005672455
Validation loss: 1.3698423126692414

Epoch: 5| Step: 7
Training loss: 0.0660724863409996
Validation loss: 1.3888355288454282

Epoch: 5| Step: 8
Training loss: 0.0270879864692688
Validation loss: 1.371579998282976

Epoch: 5| Step: 9
Training loss: 0.04129397124052048
Validation loss: 1.3547890186309814

Epoch: 5| Step: 10
Training loss: 0.04182916507124901
Validation loss: 1.3702084889975927

Epoch: 622| Step: 0
Training loss: 0.03868692368268967
Validation loss: 1.3807021379470825

Epoch: 5| Step: 1
Training loss: 0.06814555078744888
Validation loss: 1.3916205565134685

Epoch: 5| Step: 2
Training loss: 0.05118659883737564
Validation loss: 1.3907178704456618

Epoch: 5| Step: 3
Training loss: 0.0733703225851059
Validation loss: 1.4035533807610954

Epoch: 5| Step: 4
Training loss: 0.03880590945482254
Validation loss: 1.4067330116866736

Epoch: 5| Step: 5
Training loss: 0.06581450253725052
Validation loss: 1.4124566252513597

Epoch: 5| Step: 6
Training loss: 0.04242319613695145
Validation loss: 1.4100649215841805

Epoch: 5| Step: 7
Training loss: 0.08249552547931671
Validation loss: 1.409490272562991

Epoch: 5| Step: 8
Training loss: 0.13121190667152405
Validation loss: 1.3994400552524033

Epoch: 5| Step: 9
Training loss: 0.10737837851047516
Validation loss: 1.3962772328366515

Epoch: 5| Step: 10
Training loss: 0.056490808725357056
Validation loss: 1.3578847351894583

Epoch: 623| Step: 0
Training loss: 0.1300327330827713
Validation loss: 1.3454418938647035

Epoch: 5| Step: 1
Training loss: 0.04588067904114723
Validation loss: 1.3566594021294707

Epoch: 5| Step: 2
Training loss: 0.07547619193792343
Validation loss: 1.3349223905994045

Epoch: 5| Step: 3
Training loss: 0.04246320202946663
Validation loss: 1.3446017196101527

Epoch: 5| Step: 4
Training loss: 0.04083435609936714
Validation loss: 1.3526724384677025

Epoch: 5| Step: 5
Training loss: 0.06267707794904709
Validation loss: 1.3565483195807344

Epoch: 5| Step: 6
Training loss: 0.06111235171556473
Validation loss: 1.3788024302451842

Epoch: 5| Step: 7
Training loss: 0.05708811432123184
Validation loss: 1.3498870608627156

Epoch: 5| Step: 8
Training loss: 0.051320064812898636
Validation loss: 1.36693266899355

Epoch: 5| Step: 9
Training loss: 0.07965467870235443
Validation loss: 1.3851322973928144

Epoch: 5| Step: 10
Training loss: 0.06067890301346779
Validation loss: 1.402857921456778

Epoch: 624| Step: 0
Training loss: 0.06516353785991669
Validation loss: 1.4070594374851515

Epoch: 5| Step: 1
Training loss: 0.11244578659534454
Validation loss: 1.4196250489962998

Epoch: 5| Step: 2
Training loss: 0.0806623101234436
Validation loss: 1.4192862350453612

Epoch: 5| Step: 3
Training loss: 0.04669661074876785
Validation loss: 1.4317402775569628

Epoch: 5| Step: 4
Training loss: 0.06211784482002258
Validation loss: 1.4201310097530324

Epoch: 5| Step: 5
Training loss: 0.1049790233373642
Validation loss: 1.4184435465002572

Epoch: 5| Step: 6
Training loss: 0.0651588886976242
Validation loss: 1.4025408273102136

Epoch: 5| Step: 7
Training loss: 0.04877988249063492
Validation loss: 1.3930557068958078

Epoch: 5| Step: 8
Training loss: 0.04631803184747696
Validation loss: 1.3990229188754995

Epoch: 5| Step: 9
Training loss: 0.07190519571304321
Validation loss: 1.4102244877046155

Epoch: 5| Step: 10
Training loss: 0.10917798429727554
Validation loss: 1.4174396062410006

Epoch: 625| Step: 0
Training loss: 0.037394799292087555
Validation loss: 1.423745894944796

Epoch: 5| Step: 1
Training loss: 0.05545177310705185
Validation loss: 1.3940159620777253

Epoch: 5| Step: 2
Training loss: 0.07008383423089981
Validation loss: 1.387878547432602

Epoch: 5| Step: 3
Training loss: 0.04316709563136101
Validation loss: 1.415859354439602

Epoch: 5| Step: 4
Training loss: 0.059656549245119095
Validation loss: 1.3944036262009734

Epoch: 5| Step: 5
Training loss: 0.06073806434869766
Validation loss: 1.382100889759679

Epoch: 5| Step: 6
Training loss: 0.05347251892089844
Validation loss: 1.3800379665949012

Epoch: 5| Step: 7
Training loss: 0.04758857563138008
Validation loss: 1.3775244528247463

Epoch: 5| Step: 8
Training loss: 0.12239645421504974
Validation loss: 1.410126172086244

Epoch: 5| Step: 9
Training loss: 0.08165714144706726
Validation loss: 1.398942376977654

Epoch: 5| Step: 10
Training loss: 0.06778937578201294
Validation loss: 1.3965401662293302

Epoch: 626| Step: 0
Training loss: 0.04782517999410629
Validation loss: 1.390632567867156

Epoch: 5| Step: 1
Training loss: 0.05655509978532791
Validation loss: 1.389853350577816

Epoch: 5| Step: 2
Training loss: 0.12026379257440567
Validation loss: 1.4022037104893756

Epoch: 5| Step: 3
Training loss: 0.04073597118258476
Validation loss: 1.3750404478401266

Epoch: 5| Step: 4
Training loss: 0.04193654656410217
Validation loss: 1.3994564356342438

Epoch: 5| Step: 5
Training loss: 0.04918684437870979
Validation loss: 1.3996953297686834

Epoch: 5| Step: 6
Training loss: 0.03064187802374363
Validation loss: 1.3938149040745151

Epoch: 5| Step: 7
Training loss: 0.0448332205414772
Validation loss: 1.3906669360335155

Epoch: 5| Step: 8
Training loss: 0.048352308571338654
Validation loss: 1.3971510241108556

Epoch: 5| Step: 9
Training loss: 0.1014089360833168
Validation loss: 1.3959724108378093

Epoch: 5| Step: 10
Training loss: 0.046510014683008194
Validation loss: 1.39489959901379

Epoch: 627| Step: 0
Training loss: 0.07096956670284271
Validation loss: 1.3916782307368454

Epoch: 5| Step: 1
Training loss: 0.04746750742197037
Validation loss: 1.3850003878275554

Epoch: 5| Step: 2
Training loss: 0.050515420734882355
Validation loss: 1.4166510528133762

Epoch: 5| Step: 3
Training loss: 0.05891980975866318
Validation loss: 1.386702419609152

Epoch: 5| Step: 4
Training loss: 0.05479080229997635
Validation loss: 1.405779520670573

Epoch: 5| Step: 5
Training loss: 0.04259014129638672
Validation loss: 1.4020086642234557

Epoch: 5| Step: 6
Training loss: 0.12488217651844025
Validation loss: 1.3888146082560222

Epoch: 5| Step: 7
Training loss: 0.0792221873998642
Validation loss: 1.4049412691464989

Epoch: 5| Step: 8
Training loss: 0.04616720229387283
Validation loss: 1.399598733071358

Epoch: 5| Step: 9
Training loss: 0.06257249414920807
Validation loss: 1.3932870972541072

Epoch: 5| Step: 10
Training loss: 0.052814990282058716
Validation loss: 1.4124254411266697

Epoch: 628| Step: 0
Training loss: 0.05174430087208748
Validation loss: 1.4254419649800947

Epoch: 5| Step: 1
Training loss: 0.04689616337418556
Validation loss: 1.4262160588336248

Epoch: 5| Step: 2
Training loss: 0.11860833317041397
Validation loss: 1.4026825927918958

Epoch: 5| Step: 3
Training loss: 0.05957970768213272
Validation loss: 1.3960663016124437

Epoch: 5| Step: 4
Training loss: 0.05490662902593613
Validation loss: 1.4112212850201515

Epoch: 5| Step: 5
Training loss: 0.09376567602157593
Validation loss: 1.4146650196403585

Epoch: 5| Step: 6
Training loss: 0.04448983818292618
Validation loss: 1.4146295567994476

Epoch: 5| Step: 7
Training loss: 0.04317503422498703
Validation loss: 1.397248161736355

Epoch: 5| Step: 8
Training loss: 0.05462617427110672
Validation loss: 1.3852081657737814

Epoch: 5| Step: 9
Training loss: 0.054456524550914764
Validation loss: 1.3837855272395636

Epoch: 5| Step: 10
Training loss: 0.04385244846343994
Validation loss: 1.375844660625663

Epoch: 629| Step: 0
Training loss: 0.07663001120090485
Validation loss: 1.3844661174281951

Epoch: 5| Step: 1
Training loss: 0.06456959992647171
Validation loss: 1.3695195477495912

Epoch: 5| Step: 2
Training loss: 0.03162774071097374
Validation loss: 1.3812857404831917

Epoch: 5| Step: 3
Training loss: 0.05300409719347954
Validation loss: 1.4077810677148963

Epoch: 5| Step: 4
Training loss: 0.07395216077566147
Validation loss: 1.3806353051175353

Epoch: 5| Step: 5
Training loss: 0.04866410419344902
Validation loss: 1.3790629922702748

Epoch: 5| Step: 6
Training loss: 0.04176126420497894
Validation loss: 1.3882965445518494

Epoch: 5| Step: 7
Training loss: 0.027244482189416885
Validation loss: 1.398953756978435

Epoch: 5| Step: 8
Training loss: 0.04602247476577759
Validation loss: 1.392288472062798

Epoch: 5| Step: 9
Training loss: 0.04533562436699867
Validation loss: 1.4019645157680716

Epoch: 5| Step: 10
Training loss: 0.15255585312843323
Validation loss: 1.3950869191077448

Epoch: 630| Step: 0
Training loss: 0.09817572683095932
Validation loss: 1.3949477666167802

Epoch: 5| Step: 1
Training loss: 0.05498816445469856
Validation loss: 1.3993708843825965

Epoch: 5| Step: 2
Training loss: 0.047922033816576004
Validation loss: 1.3912795333452121

Epoch: 5| Step: 3
Training loss: 0.050234369933605194
Validation loss: 1.3637336236174389

Epoch: 5| Step: 4
Training loss: 0.04858711361885071
Validation loss: 1.3935029878411243

Epoch: 5| Step: 5
Training loss: 0.06312666833400726
Validation loss: 1.3797667154701807

Epoch: 5| Step: 6
Training loss: 0.06312388181686401
Validation loss: 1.3850360608869983

Epoch: 5| Step: 7
Training loss: 0.15071237087249756
Validation loss: 1.411602806660437

Epoch: 5| Step: 8
Training loss: 0.030155768617987633
Validation loss: 1.3744268898041017

Epoch: 5| Step: 9
Training loss: 0.040159277617931366
Validation loss: 1.375638110663301

Epoch: 5| Step: 10
Training loss: 0.07214127480983734
Validation loss: 1.3576853172753447

Epoch: 631| Step: 0
Training loss: 0.08364267647266388
Validation loss: 1.3611580684620848

Epoch: 5| Step: 1
Training loss: 0.10047952830791473
Validation loss: 1.3756701433530418

Epoch: 5| Step: 2
Training loss: 0.05644506216049194
Validation loss: 1.3660418025908931

Epoch: 5| Step: 3
Training loss: 0.048327140510082245
Validation loss: 1.3756889848298923

Epoch: 5| Step: 4
Training loss: 0.03683527186512947
Validation loss: 1.3690031343890774

Epoch: 5| Step: 5
Training loss: 0.05161316320300102
Validation loss: 1.3845513879611928

Epoch: 5| Step: 6
Training loss: 0.06696072965860367
Validation loss: 1.411956117999169

Epoch: 5| Step: 7
Training loss: 0.12587814033031464
Validation loss: 1.4053820230627572

Epoch: 5| Step: 8
Training loss: 0.0567815899848938
Validation loss: 1.3898810417421403

Epoch: 5| Step: 9
Training loss: 0.057436682283878326
Validation loss: 1.3706074837715394

Epoch: 5| Step: 10
Training loss: 0.07192470133304596
Validation loss: 1.3735088712425643

Epoch: 632| Step: 0
Training loss: 0.08495686203241348
Validation loss: 1.3644570855684177

Epoch: 5| Step: 1
Training loss: 0.18428023159503937
Validation loss: 1.376825636433017

Epoch: 5| Step: 2
Training loss: 0.053611766546964645
Validation loss: 1.373825498806533

Epoch: 5| Step: 3
Training loss: 0.08045285940170288
Validation loss: 1.3544207516536917

Epoch: 5| Step: 4
Training loss: 0.08926934003829956
Validation loss: 1.3914125010531435

Epoch: 5| Step: 5
Training loss: 0.04008505493402481
Validation loss: 1.379749382695844

Epoch: 5| Step: 6
Training loss: 0.06698934733867645
Validation loss: 1.3956064588280135

Epoch: 5| Step: 7
Training loss: 0.0658620148897171
Validation loss: 1.391313459283562

Epoch: 5| Step: 8
Training loss: 0.05182899162173271
Validation loss: 1.3803661254144484

Epoch: 5| Step: 9
Training loss: 0.05604173615574837
Validation loss: 1.3932209168711016

Epoch: 5| Step: 10
Training loss: 0.05011029914021492
Validation loss: 1.3573865582866054

Epoch: 633| Step: 0
Training loss: 0.040211401879787445
Validation loss: 1.3703106141859485

Epoch: 5| Step: 1
Training loss: 0.059969209134578705
Validation loss: 1.368154615484258

Epoch: 5| Step: 2
Training loss: 0.05813584849238396
Validation loss: 1.374366678217406

Epoch: 5| Step: 3
Training loss: 0.05059988051652908
Validation loss: 1.386251490603211

Epoch: 5| Step: 4
Training loss: 0.07579589635133743
Validation loss: 1.4037020539724698

Epoch: 5| Step: 5
Training loss: 0.12472988665103912
Validation loss: 1.381674631949394

Epoch: 5| Step: 6
Training loss: 0.05864933133125305
Validation loss: 1.4092779762001448

Epoch: 5| Step: 7
Training loss: 0.10271382331848145
Validation loss: 1.4054437324564943

Epoch: 5| Step: 8
Training loss: 0.06057247519493103
Validation loss: 1.3697478322572605

Epoch: 5| Step: 9
Training loss: 0.056298691779375076
Validation loss: 1.398846444263253

Epoch: 5| Step: 10
Training loss: 0.054445356130599976
Validation loss: 1.390450087926721

Epoch: 634| Step: 0
Training loss: 0.05754856392741203
Validation loss: 1.3800711875320764

Epoch: 5| Step: 1
Training loss: 0.061424799263477325
Validation loss: 1.3740911804219729

Epoch: 5| Step: 2
Training loss: 0.053730517625808716
Validation loss: 1.3907228836449244

Epoch: 5| Step: 3
Training loss: 0.06612680107355118
Validation loss: 1.3813150646866008

Epoch: 5| Step: 4
Training loss: 0.1421542912721634
Validation loss: 1.3791172965880363

Epoch: 5| Step: 5
Training loss: 0.05326996371150017
Validation loss: 1.3892550314626386

Epoch: 5| Step: 6
Training loss: 0.046609580516815186
Validation loss: 1.37600843111674

Epoch: 5| Step: 7
Training loss: 0.07589831203222275
Validation loss: 1.3739896358982209

Epoch: 5| Step: 8
Training loss: 0.06492079049348831
Validation loss: 1.3700709945412093

Epoch: 5| Step: 9
Training loss: 0.04609053581953049
Validation loss: 1.382475874757254

Epoch: 5| Step: 10
Training loss: 0.048104118555784225
Validation loss: 1.3582099150585871

Epoch: 635| Step: 0
Training loss: 0.03879357501864433
Validation loss: 1.35632933339765

Epoch: 5| Step: 1
Training loss: 0.05613797903060913
Validation loss: 1.3695077652572303

Epoch: 5| Step: 2
Training loss: 0.07337869703769684
Validation loss: 1.3533154841392272

Epoch: 5| Step: 3
Training loss: 0.11704319715499878
Validation loss: 1.3315400128723474

Epoch: 5| Step: 4
Training loss: 0.04088733345270157
Validation loss: 1.3474923128722816

Epoch: 5| Step: 5
Training loss: 0.06409992277622223
Validation loss: 1.3556911849206494

Epoch: 5| Step: 6
Training loss: 0.050838422030210495
Validation loss: 1.3514731994239233

Epoch: 5| Step: 7
Training loss: 0.040782421827316284
Validation loss: 1.337406208438258

Epoch: 5| Step: 8
Training loss: 0.04260346665978432
Validation loss: 1.3613331317901611

Epoch: 5| Step: 9
Training loss: 0.05693523958325386
Validation loss: 1.3717931188562864

Epoch: 5| Step: 10
Training loss: 0.047582972794771194
Validation loss: 1.3938617539662186

Epoch: 636| Step: 0
Training loss: 0.06045494228601456
Validation loss: 1.3694173789793445

Epoch: 5| Step: 1
Training loss: 0.03481846675276756
Validation loss: 1.3804632989309167

Epoch: 5| Step: 2
Training loss: 0.06500697135925293
Validation loss: 1.375154008147537

Epoch: 5| Step: 3
Training loss: 0.04662391543388367
Validation loss: 1.394585653017926

Epoch: 5| Step: 4
Training loss: 0.15744724869728088
Validation loss: 1.3748382842668923

Epoch: 5| Step: 5
Training loss: 0.04198464751243591
Validation loss: 1.3892873025709582

Epoch: 5| Step: 6
Training loss: 0.05840357020497322
Validation loss: 1.3494291702906291

Epoch: 5| Step: 7
Training loss: 0.04188714548945427
Validation loss: 1.3866331256845945

Epoch: 5| Step: 8
Training loss: 0.043872252106666565
Validation loss: 1.3778434812381704

Epoch: 5| Step: 9
Training loss: 0.034583281725645065
Validation loss: 1.4025891391179894

Epoch: 5| Step: 10
Training loss: 0.050053082406520844
Validation loss: 1.4120362099780832

Epoch: 637| Step: 0
Training loss: 0.03959813341498375
Validation loss: 1.3838262032437068

Epoch: 5| Step: 1
Training loss: 0.06705121695995331
Validation loss: 1.3920660198375743

Epoch: 5| Step: 2
Training loss: 0.04782453924417496
Validation loss: 1.3689562338654713

Epoch: 5| Step: 3
Training loss: 0.07620164752006531
Validation loss: 1.3788030301370928

Epoch: 5| Step: 4
Training loss: 0.04423229396343231
Validation loss: 1.3769708775704907

Epoch: 5| Step: 5
Training loss: 0.056378841400146484
Validation loss: 1.3776264421401485

Epoch: 5| Step: 6
Training loss: 0.12800075113773346
Validation loss: 1.373683391078826

Epoch: 5| Step: 7
Training loss: 0.04359463229775429
Validation loss: 1.3704432184978197

Epoch: 5| Step: 8
Training loss: 0.07011891901493073
Validation loss: 1.3714613414579822

Epoch: 5| Step: 9
Training loss: 0.034739211201667786
Validation loss: 1.3846716162978963

Epoch: 5| Step: 10
Training loss: 0.06727912276983261
Validation loss: 1.3900450025835345

Epoch: 638| Step: 0
Training loss: 0.06263749301433563
Validation loss: 1.3904239657104656

Epoch: 5| Step: 1
Training loss: 0.036749303340911865
Validation loss: 1.3786611890280118

Epoch: 5| Step: 2
Training loss: 0.0461573526263237
Validation loss: 1.3699422984994867

Epoch: 5| Step: 3
Training loss: 0.0336913987994194
Validation loss: 1.3708420242032697

Epoch: 5| Step: 4
Training loss: 0.052994318306446075
Validation loss: 1.3649817794881842

Epoch: 5| Step: 5
Training loss: 0.054962873458862305
Validation loss: 1.3542282389056297

Epoch: 5| Step: 6
Training loss: 0.04423746466636658
Validation loss: 1.344980473159462

Epoch: 5| Step: 7
Training loss: 0.048980601131916046
Validation loss: 1.3710387432447044

Epoch: 5| Step: 8
Training loss: 0.062289316207170486
Validation loss: 1.3772575124617545

Epoch: 5| Step: 9
Training loss: 0.16249880194664001
Validation loss: 1.37106075081774

Epoch: 5| Step: 10
Training loss: 0.07415958493947983
Validation loss: 1.3664991817166727

Epoch: 639| Step: 0
Training loss: 0.1269320547580719
Validation loss: 1.391180976744621

Epoch: 5| Step: 1
Training loss: 0.07272271811962128
Validation loss: 1.3797954487544235

Epoch: 5| Step: 2
Training loss: 0.029074599966406822
Validation loss: 1.382204540314213

Epoch: 5| Step: 3
Training loss: 0.04216384142637253
Validation loss: 1.407584313423403

Epoch: 5| Step: 4
Training loss: 0.06270718574523926
Validation loss: 1.4084778575487034

Epoch: 5| Step: 5
Training loss: 0.04639620706439018
Validation loss: 1.4181601193643385

Epoch: 5| Step: 6
Training loss: 0.051306795328855515
Validation loss: 1.4106153031831146

Epoch: 5| Step: 7
Training loss: 0.058041371405124664
Validation loss: 1.3935780884117208

Epoch: 5| Step: 8
Training loss: 0.05234476923942566
Validation loss: 1.379806254499702

Epoch: 5| Step: 9
Training loss: 0.054294854402542114
Validation loss: 1.3883999188741047

Epoch: 5| Step: 10
Training loss: 0.0511605478823185
Validation loss: 1.3835648798173474

Epoch: 640| Step: 0
Training loss: 0.04914337396621704
Validation loss: 1.3677779102838168

Epoch: 5| Step: 1
Training loss: 0.059818334877491
Validation loss: 1.3510983246628956

Epoch: 5| Step: 2
Training loss: 0.0928700715303421
Validation loss: 1.3705858645900604

Epoch: 5| Step: 3
Training loss: 0.06698193401098251
Validation loss: 1.3623747242394315

Epoch: 5| Step: 4
Training loss: 0.06914128363132477
Validation loss: 1.360115106387805

Epoch: 5| Step: 5
Training loss: 0.05776723474264145
Validation loss: 1.3661728136001094

Epoch: 5| Step: 6
Training loss: 0.07447276264429092
Validation loss: 1.3649226234805198

Epoch: 5| Step: 7
Training loss: 0.029690474271774292
Validation loss: 1.3863132576788626

Epoch: 5| Step: 8
Training loss: 0.05805528163909912
Validation loss: 1.3739622357071086

Epoch: 5| Step: 9
Training loss: 0.06408806145191193
Validation loss: 1.3833872528486355

Epoch: 5| Step: 10
Training loss: 0.13049282133579254
Validation loss: 1.3787424000360633

Epoch: 641| Step: 0
Training loss: 0.04594215750694275
Validation loss: 1.3978738579698788

Epoch: 5| Step: 1
Training loss: 0.12039230763912201
Validation loss: 1.401674166802437

Epoch: 5| Step: 2
Training loss: 0.05669577792286873
Validation loss: 1.3980847199757893

Epoch: 5| Step: 3
Training loss: 0.07115913927555084
Validation loss: 1.3909040625377367

Epoch: 5| Step: 4
Training loss: 0.04768378287553787
Validation loss: 1.377664384021554

Epoch: 5| Step: 5
Training loss: 0.12049814313650131
Validation loss: 1.3846961887933875

Epoch: 5| Step: 6
Training loss: 0.03584209084510803
Validation loss: 1.3652116662712508

Epoch: 5| Step: 7
Training loss: 0.050303854048252106
Validation loss: 1.375189382542846

Epoch: 5| Step: 8
Training loss: 0.04228533059358597
Validation loss: 1.3571987331554454

Epoch: 5| Step: 9
Training loss: 0.058842986822128296
Validation loss: 1.3678052271566083

Epoch: 5| Step: 10
Training loss: 0.032271407544612885
Validation loss: 1.3754709029710421

Epoch: 642| Step: 0
Training loss: 0.1234811320900917
Validation loss: 1.3645566035342473

Epoch: 5| Step: 1
Training loss: 0.043631087988615036
Validation loss: 1.3649654881928557

Epoch: 5| Step: 2
Training loss: 0.08271527290344238
Validation loss: 1.3603494116055068

Epoch: 5| Step: 3
Training loss: 0.05152087286114693
Validation loss: 1.3500639418120026

Epoch: 5| Step: 4
Training loss: 0.045168161392211914
Validation loss: 1.3668671615662114

Epoch: 5| Step: 5
Training loss: 0.056758128106594086
Validation loss: 1.350419097049262

Epoch: 5| Step: 6
Training loss: 0.045148223638534546
Validation loss: 1.3872997696681688

Epoch: 5| Step: 7
Training loss: 0.03935299813747406
Validation loss: 1.3716100787603727

Epoch: 5| Step: 8
Training loss: 0.0736660435795784
Validation loss: 1.3853144235508417

Epoch: 5| Step: 9
Training loss: 0.05842046067118645
Validation loss: 1.3826755567263531

Epoch: 5| Step: 10
Training loss: 0.03445277363061905
Validation loss: 1.386005695148181

Epoch: 643| Step: 0
Training loss: 0.17974942922592163
Validation loss: 1.4054602012839368

Epoch: 5| Step: 1
Training loss: 0.05370376259088516
Validation loss: 1.4231741671921105

Epoch: 5| Step: 2
Training loss: 0.06632685661315918
Validation loss: 1.4345028797785442

Epoch: 5| Step: 3
Training loss: 0.06331862509250641
Validation loss: 1.4231841871815343

Epoch: 5| Step: 4
Training loss: 0.06315386295318604
Validation loss: 1.411550953824033

Epoch: 5| Step: 5
Training loss: 0.054050564765930176
Validation loss: 1.4025996167172667

Epoch: 5| Step: 6
Training loss: 0.03495122119784355
Validation loss: 1.391397710769407

Epoch: 5| Step: 7
Training loss: 0.06801557540893555
Validation loss: 1.3861220139329151

Epoch: 5| Step: 8
Training loss: 0.0808890089392662
Validation loss: 1.3738623120451485

Epoch: 5| Step: 9
Training loss: 0.07482106238603592
Validation loss: 1.3759258639427923

Epoch: 5| Step: 10
Training loss: 0.057907335460186005
Validation loss: 1.3907704519969162

Epoch: 644| Step: 0
Training loss: 0.039754774421453476
Validation loss: 1.3871362042683426

Epoch: 5| Step: 1
Training loss: 0.035952042788267136
Validation loss: 1.3898596250882713

Epoch: 5| Step: 2
Training loss: 0.08775254338979721
Validation loss: 1.4083883339358914

Epoch: 5| Step: 3
Training loss: 0.06086461991071701
Validation loss: 1.4124883400496615

Epoch: 5| Step: 4
Training loss: 0.046427931636571884
Validation loss: 1.4116713564882997

Epoch: 5| Step: 5
Training loss: 0.045613206923007965
Validation loss: 1.391180258925243

Epoch: 5| Step: 6
Training loss: 0.06434235721826553
Validation loss: 1.3802435551920245

Epoch: 5| Step: 7
Training loss: 0.04016104340553284
Validation loss: 1.3842327684484503

Epoch: 5| Step: 8
Training loss: 0.05287691205739975
Validation loss: 1.3797787004901516

Epoch: 5| Step: 9
Training loss: 0.1295192539691925
Validation loss: 1.3850380618085143

Epoch: 5| Step: 10
Training loss: 0.0925973579287529
Validation loss: 1.363950846015766

Epoch: 645| Step: 0
Training loss: 0.060617100447416306
Validation loss: 1.3688429094129992

Epoch: 5| Step: 1
Training loss: 0.07215803116559982
Validation loss: 1.370493761954769

Epoch: 5| Step: 2
Training loss: 0.05939686298370361
Validation loss: 1.3716026877844205

Epoch: 5| Step: 3
Training loss: 0.11597707122564316
Validation loss: 1.3725109888661293

Epoch: 5| Step: 4
Training loss: 0.06256700307130814
Validation loss: 1.4066726533315514

Epoch: 5| Step: 5
Training loss: 0.09351728111505508
Validation loss: 1.4209696733823387

Epoch: 5| Step: 6
Training loss: 0.095009945333004
Validation loss: 1.4165551175353348

Epoch: 5| Step: 7
Training loss: 0.05650730058550835
Validation loss: 1.41426771174195

Epoch: 5| Step: 8
Training loss: 0.04953115060925484
Validation loss: 1.4126634136323006

Epoch: 5| Step: 9
Training loss: 0.04782877489924431
Validation loss: 1.3786119722550916

Epoch: 5| Step: 10
Training loss: 0.04180295392870903
Validation loss: 1.3824710922856485

Epoch: 646| Step: 0
Training loss: 0.04029209911823273
Validation loss: 1.3843126527724727

Epoch: 5| Step: 1
Training loss: 0.07543587684631348
Validation loss: 1.400025874055842

Epoch: 5| Step: 2
Training loss: 0.03662367910146713
Validation loss: 1.3954953955065819

Epoch: 5| Step: 3
Training loss: 0.12310434877872467
Validation loss: 1.391105894119509

Epoch: 5| Step: 4
Training loss: 0.04302346706390381
Validation loss: 1.3798235667649137

Epoch: 5| Step: 5
Training loss: 0.06266379356384277
Validation loss: 1.3865822656180269

Epoch: 5| Step: 6
Training loss: 0.03523978963494301
Validation loss: 1.394934565790238

Epoch: 5| Step: 7
Training loss: 0.06235809251666069
Validation loss: 1.4000223541772494

Epoch: 5| Step: 8
Training loss: 0.046325333416461945
Validation loss: 1.3816731335014425

Epoch: 5| Step: 9
Training loss: 0.0726032704114914
Validation loss: 1.3995999238824333

Epoch: 5| Step: 10
Training loss: 0.072346992790699
Validation loss: 1.3549080446202268

Epoch: 647| Step: 0
Training loss: 0.02960103191435337
Validation loss: 1.3703546806048321

Epoch: 5| Step: 1
Training loss: 0.044312603771686554
Validation loss: 1.381031940060277

Epoch: 5| Step: 2
Training loss: 0.06300771236419678
Validation loss: 1.3970080960181452

Epoch: 5| Step: 3
Training loss: 0.037941284477710724
Validation loss: 1.3970739956825011

Epoch: 5| Step: 4
Training loss: 0.06975205987691879
Validation loss: 1.3609395885980258

Epoch: 5| Step: 5
Training loss: 0.04638577252626419
Validation loss: 1.367934738436053

Epoch: 5| Step: 6
Training loss: 0.046401750296354294
Validation loss: 1.365745162451139

Epoch: 5| Step: 7
Training loss: 0.03173600509762764
Validation loss: 1.3449721669638028

Epoch: 5| Step: 8
Training loss: 0.05068925768136978
Validation loss: 1.3456796010335286

Epoch: 5| Step: 9
Training loss: 0.14981749653816223
Validation loss: 1.3665367569974674

Epoch: 5| Step: 10
Training loss: 0.0488198958337307
Validation loss: 1.3475445598684332

Epoch: 648| Step: 0
Training loss: 0.06402114778757095
Validation loss: 1.3664135317648611

Epoch: 5| Step: 1
Training loss: 0.11583230644464493
Validation loss: 1.3675967275455434

Epoch: 5| Step: 2
Training loss: 0.06997344642877579
Validation loss: 1.3558171961897163

Epoch: 5| Step: 3
Training loss: 0.04601164534687996
Validation loss: 1.3631749230046426

Epoch: 5| Step: 4
Training loss: 0.040069472044706345
Validation loss: 1.3746635426757157

Epoch: 5| Step: 5
Training loss: 0.042906057089567184
Validation loss: 1.380950072760223

Epoch: 5| Step: 6
Training loss: 0.08568127453327179
Validation loss: 1.403322503130923

Epoch: 5| Step: 7
Training loss: 0.054629482328891754
Validation loss: 1.4132798006457667

Epoch: 5| Step: 8
Training loss: 0.04625842720270157
Validation loss: 1.3994897744988883

Epoch: 5| Step: 9
Training loss: 0.0500214621424675
Validation loss: 1.439063443932482

Epoch: 5| Step: 10
Training loss: 0.042092591524124146
Validation loss: 1.4117098739070277

Epoch: 649| Step: 0
Training loss: 0.05953937768936157
Validation loss: 1.401146573405112

Epoch: 5| Step: 1
Training loss: 0.059745531529188156
Validation loss: 1.4206249662624892

Epoch: 5| Step: 2
Training loss: 0.05214152857661247
Validation loss: 1.4248706743281374

Epoch: 5| Step: 3
Training loss: 0.10865497589111328
Validation loss: 1.396597118787868

Epoch: 5| Step: 4
Training loss: 0.06751005351543427
Validation loss: 1.3967332506692538

Epoch: 5| Step: 5
Training loss: 0.05308884382247925
Validation loss: 1.4083256157495643

Epoch: 5| Step: 6
Training loss: 0.05430503562092781
Validation loss: 1.3693427885732343

Epoch: 5| Step: 7
Training loss: 0.04089362919330597
Validation loss: 1.3891846774726786

Epoch: 5| Step: 8
Training loss: 0.047005265951156616
Validation loss: 1.3804636821951917

Epoch: 5| Step: 9
Training loss: 0.053417254239320755
Validation loss: 1.3699873826837028

Epoch: 5| Step: 10
Training loss: 0.08846389502286911
Validation loss: 1.3563763198032175

Epoch: 650| Step: 0
Training loss: 0.10653825104236603
Validation loss: 1.3607410307853454

Epoch: 5| Step: 1
Training loss: 0.06010553240776062
Validation loss: 1.3636880907961118

Epoch: 5| Step: 2
Training loss: 0.03702728822827339
Validation loss: 1.372666298702199

Epoch: 5| Step: 3
Training loss: 0.042916614562273026
Validation loss: 1.3664892155637023

Epoch: 5| Step: 4
Training loss: 0.03485184162855148
Validation loss: 1.4009541234662455

Epoch: 5| Step: 5
Training loss: 0.05422614887356758
Validation loss: 1.409751662644007

Epoch: 5| Step: 6
Training loss: 0.050453782081604004
Validation loss: 1.4088830281329412

Epoch: 5| Step: 7
Training loss: 0.05118883401155472
Validation loss: 1.4026931485822123

Epoch: 5| Step: 8
Training loss: 0.08472737669944763
Validation loss: 1.4167459549442414

Epoch: 5| Step: 9
Training loss: 0.05385829880833626
Validation loss: 1.3970966826203048

Epoch: 5| Step: 10
Training loss: 0.06808969378471375
Validation loss: 1.4097366102280156

Epoch: 651| Step: 0
Training loss: 0.04840226098895073
Validation loss: 1.391317989236565

Epoch: 5| Step: 1
Training loss: 0.025838801637291908
Validation loss: 1.4082894972575608

Epoch: 5| Step: 2
Training loss: 0.024782193824648857
Validation loss: 1.3903864788752731

Epoch: 5| Step: 3
Training loss: 0.11792081594467163
Validation loss: 1.3962411457492458

Epoch: 5| Step: 4
Training loss: 0.06028237193822861
Validation loss: 1.3772265936738701

Epoch: 5| Step: 5
Training loss: 0.058815259486436844
Validation loss: 1.3912597587031703

Epoch: 5| Step: 6
Training loss: 0.03920576721429825
Validation loss: 1.3850835664297945

Epoch: 5| Step: 7
Training loss: 0.057477425783872604
Validation loss: 1.3609226326788626

Epoch: 5| Step: 8
Training loss: 0.07473288476467133
Validation loss: 1.374855153022274

Epoch: 5| Step: 9
Training loss: 0.044430606067180634
Validation loss: 1.3803141501642042

Epoch: 5| Step: 10
Training loss: 0.04028031975030899
Validation loss: 1.3786495770177534

Epoch: 652| Step: 0
Training loss: 0.041898537427186966
Validation loss: 1.3765486363441712

Epoch: 5| Step: 1
Training loss: 0.04176943749189377
Validation loss: 1.377527258729422

Epoch: 5| Step: 2
Training loss: 0.03076248988509178
Validation loss: 1.3771779639746553

Epoch: 5| Step: 3
Training loss: 0.03937350958585739
Validation loss: 1.3732404330725312

Epoch: 5| Step: 4
Training loss: 0.03806113824248314
Validation loss: 1.353566356884536

Epoch: 5| Step: 5
Training loss: 0.029308166354894638
Validation loss: 1.3598935437458817

Epoch: 5| Step: 6
Training loss: 0.07496752589941025
Validation loss: 1.3716585277229227

Epoch: 5| Step: 7
Training loss: 0.05422573536634445
Validation loss: 1.38252765645263

Epoch: 5| Step: 8
Training loss: 0.06600333750247955
Validation loss: 1.3788777423161331

Epoch: 5| Step: 9
Training loss: 0.1076292023062706
Validation loss: 1.3708085770248084

Epoch: 5| Step: 10
Training loss: 0.07662816345691681
Validation loss: 1.3830367672827937

Epoch: 653| Step: 0
Training loss: 0.05936501547694206
Validation loss: 1.3789414423768238

Epoch: 5| Step: 1
Training loss: 0.11997519433498383
Validation loss: 1.3880699969107104

Epoch: 5| Step: 2
Training loss: 0.034942325204610825
Validation loss: 1.4030161852477698

Epoch: 5| Step: 3
Training loss: 0.054528843611478806
Validation loss: 1.4127979823338088

Epoch: 5| Step: 4
Training loss: 0.062117911875247955
Validation loss: 1.3900157187574653

Epoch: 5| Step: 5
Training loss: 0.03454800322651863
Validation loss: 1.3943036858753493

Epoch: 5| Step: 6
Training loss: 0.07079790532588959
Validation loss: 1.4136529020083848

Epoch: 5| Step: 7
Training loss: 0.029128262773156166
Validation loss: 1.3854918197918964

Epoch: 5| Step: 8
Training loss: 0.05229970067739487
Validation loss: 1.4057177907677108

Epoch: 5| Step: 9
Training loss: 0.04118981584906578
Validation loss: 1.417238377755688

Epoch: 5| Step: 10
Training loss: 0.04436582326889038
Validation loss: 1.4035864235252462

Epoch: 654| Step: 0
Training loss: 0.031249171122908592
Validation loss: 1.3800108907043294

Epoch: 5| Step: 1
Training loss: 0.0872209444642067
Validation loss: 1.3944142697959818

Epoch: 5| Step: 2
Training loss: 0.040360674262046814
Validation loss: 1.3890076260412894

Epoch: 5| Step: 3
Training loss: 0.03409150242805481
Validation loss: 1.399659029899105

Epoch: 5| Step: 4
Training loss: 0.04214979335665703
Validation loss: 1.400680926538283

Epoch: 5| Step: 5
Training loss: 0.07557881623506546
Validation loss: 1.4190662798061167

Epoch: 5| Step: 6
Training loss: 0.03427015617489815
Validation loss: 1.3920266435992332

Epoch: 5| Step: 7
Training loss: 0.1295498162508011
Validation loss: 1.390669345855713

Epoch: 5| Step: 8
Training loss: 0.04731371998786926
Validation loss: 1.4210800631071931

Epoch: 5| Step: 9
Training loss: 0.040065325796604156
Validation loss: 1.405556462144339

Epoch: 5| Step: 10
Training loss: 0.04214192181825638
Validation loss: 1.396983797832202

Epoch: 655| Step: 0
Training loss: 0.04462027549743652
Validation loss: 1.4229202366644336

Epoch: 5| Step: 1
Training loss: 0.12534931302070618
Validation loss: 1.410891604679887

Epoch: 5| Step: 2
Training loss: 0.059335481375455856
Validation loss: 1.4121297482521302

Epoch: 5| Step: 3
Training loss: 0.08092673122882843
Validation loss: 1.4131625730504271

Epoch: 5| Step: 4
Training loss: 0.028981339186429977
Validation loss: 1.4211812275712208

Epoch: 5| Step: 5
Training loss: 0.021532390266656876
Validation loss: 1.4028300854467577

Epoch: 5| Step: 6
Training loss: 0.04987644404172897
Validation loss: 1.413366151112382

Epoch: 5| Step: 7
Training loss: 0.07770925760269165
Validation loss: 1.4322052258317188

Epoch: 5| Step: 8
Training loss: 0.07787297666072845
Validation loss: 1.4220465498585855

Epoch: 5| Step: 9
Training loss: 0.04749337583780289
Validation loss: 1.406007856451055

Epoch: 5| Step: 10
Training loss: 0.04721566662192345
Validation loss: 1.4096017114577755

Epoch: 656| Step: 0
Training loss: 0.07205812633037567
Validation loss: 1.406924513078505

Epoch: 5| Step: 1
Training loss: 0.14409488439559937
Validation loss: 1.4262798217035109

Epoch: 5| Step: 2
Training loss: 0.0653727799654007
Validation loss: 1.4141176041736399

Epoch: 5| Step: 3
Training loss: 0.06782563030719757
Validation loss: 1.4203398612237745

Epoch: 5| Step: 4
Training loss: 0.0614917166531086
Validation loss: 1.4139846281338764

Epoch: 5| Step: 5
Training loss: 0.044389139860868454
Validation loss: 1.4066993741578953

Epoch: 5| Step: 6
Training loss: 0.09688763320446014
Validation loss: 1.3872930465206024

Epoch: 5| Step: 7
Training loss: 0.07383149117231369
Validation loss: 1.4072209135178597

Epoch: 5| Step: 8
Training loss: 0.0695590153336525
Validation loss: 1.3973518520273187

Epoch: 5| Step: 9
Training loss: 0.05935092642903328
Validation loss: 1.4005207547577478

Epoch: 5| Step: 10
Training loss: 0.05551999434828758
Validation loss: 1.3970130502536733

Epoch: 657| Step: 0
Training loss: 0.05631742626428604
Validation loss: 1.406381134063967

Epoch: 5| Step: 1
Training loss: 0.04564818739891052
Validation loss: 1.377050522835024

Epoch: 5| Step: 2
Training loss: 0.06803248822689056
Validation loss: 1.3712131624580712

Epoch: 5| Step: 3
Training loss: 0.07040521502494812
Validation loss: 1.3767472979842976

Epoch: 5| Step: 4
Training loss: 0.05791276693344116
Validation loss: 1.370028067660588

Epoch: 5| Step: 5
Training loss: 0.12884582579135895
Validation loss: 1.3617803486444617

Epoch: 5| Step: 6
Training loss: 0.037688903510570526
Validation loss: 1.3585235944358252

Epoch: 5| Step: 7
Training loss: 0.06421458721160889
Validation loss: 1.3973777922250892

Epoch: 5| Step: 8
Training loss: 0.03137032315135002
Validation loss: 1.4115281322950959

Epoch: 5| Step: 9
Training loss: 0.037409864366054535
Validation loss: 1.3802396943492274

Epoch: 5| Step: 10
Training loss: 0.06044315546751022
Validation loss: 1.4061424027207077

Epoch: 658| Step: 0
Training loss: 0.043677918612957
Validation loss: 1.4047767910906064

Epoch: 5| Step: 1
Training loss: 0.033823080360889435
Validation loss: 1.4177551205440233

Epoch: 5| Step: 2
Training loss: 0.047876037657260895
Validation loss: 1.413492912887245

Epoch: 5| Step: 3
Training loss: 0.04875890538096428
Validation loss: 1.3971886775826896

Epoch: 5| Step: 4
Training loss: 0.12686951458454132
Validation loss: 1.420064995365758

Epoch: 5| Step: 5
Training loss: 0.032151706516742706
Validation loss: 1.3980577440672024

Epoch: 5| Step: 6
Training loss: 0.03032713569700718
Validation loss: 1.4148122661857194

Epoch: 5| Step: 7
Training loss: 0.03663889318704605
Validation loss: 1.3927231475871096

Epoch: 5| Step: 8
Training loss: 0.04157571867108345
Validation loss: 1.4009954615305829

Epoch: 5| Step: 9
Training loss: 0.05783103033900261
Validation loss: 1.3984098562630274

Epoch: 5| Step: 10
Training loss: 0.08938808739185333
Validation loss: 1.391133955729905

Epoch: 659| Step: 0
Training loss: 0.03879547491669655
Validation loss: 1.3874994952191588

Epoch: 5| Step: 1
Training loss: 0.048898886889219284
Validation loss: 1.3973371623664774

Epoch: 5| Step: 2
Training loss: 0.04495232552289963
Validation loss: 1.391755343765341

Epoch: 5| Step: 3
Training loss: 0.05646321922540665
Validation loss: 1.4044153818520166

Epoch: 5| Step: 4
Training loss: 0.04935333877801895
Validation loss: 1.401558272300228

Epoch: 5| Step: 5
Training loss: 0.04513048380613327
Validation loss: 1.3988797433914677

Epoch: 5| Step: 6
Training loss: 0.09791143238544464
Validation loss: 1.406748261502994

Epoch: 5| Step: 7
Training loss: 0.04228242486715317
Validation loss: 1.4060322187280143

Epoch: 5| Step: 8
Training loss: 0.04198804497718811
Validation loss: 1.4016743783027894

Epoch: 5| Step: 9
Training loss: 0.033815860748291016
Validation loss: 1.3838056838640602

Epoch: 5| Step: 10
Training loss: 0.09799569845199585
Validation loss: 1.3997815873033257

Epoch: 660| Step: 0
Training loss: 0.04285993427038193
Validation loss: 1.401159800508971

Epoch: 5| Step: 1
Training loss: 0.03314582630991936
Validation loss: 1.4049131421632663

Epoch: 5| Step: 2
Training loss: 0.030482541769742966
Validation loss: 1.399072931658837

Epoch: 5| Step: 3
Training loss: 0.026403144001960754
Validation loss: 1.4064284627155592

Epoch: 5| Step: 4
Training loss: 0.12351061403751373
Validation loss: 1.387393387415076

Epoch: 5| Step: 5
Training loss: 0.05577385425567627
Validation loss: 1.3968287680738716

Epoch: 5| Step: 6
Training loss: 0.03644387051463127
Validation loss: 1.413760180114418

Epoch: 5| Step: 7
Training loss: 0.050979744642972946
Validation loss: 1.3975031074657236

Epoch: 5| Step: 8
Training loss: 0.032144688069820404
Validation loss: 1.402257320701435

Epoch: 5| Step: 9
Training loss: 0.06408832222223282
Validation loss: 1.3942459847337456

Epoch: 5| Step: 10
Training loss: 0.03153917193412781
Validation loss: 1.3958549268784062

Epoch: 661| Step: 0
Training loss: 0.03295103833079338
Validation loss: 1.4125745681024366

Epoch: 5| Step: 1
Training loss: 0.05455688387155533
Validation loss: 1.39769011159097

Epoch: 5| Step: 2
Training loss: 0.042815614491701126
Validation loss: 1.4043555451977638

Epoch: 5| Step: 3
Training loss: 0.04512019827961922
Validation loss: 1.4016916226315241

Epoch: 5| Step: 4
Training loss: 0.025375330820679665
Validation loss: 1.4030086917261924

Epoch: 5| Step: 5
Training loss: 0.04690789803862572
Validation loss: 1.3874708478168776

Epoch: 5| Step: 6
Training loss: 0.05738739296793938
Validation loss: 1.3811795878153976

Epoch: 5| Step: 7
Training loss: 0.046266451478004456
Validation loss: 1.3816972317234162

Epoch: 5| Step: 8
Training loss: 0.12927213311195374
Validation loss: 1.395549621633304

Epoch: 5| Step: 9
Training loss: 0.051637202501297
Validation loss: 1.3884009411258083

Epoch: 5| Step: 10
Training loss: 0.052444253116846085
Validation loss: 1.381908296256937

Epoch: 662| Step: 0
Training loss: 0.036029450595378876
Validation loss: 1.381124939969791

Epoch: 5| Step: 1
Training loss: 0.037529073655605316
Validation loss: 1.3957415908895514

Epoch: 5| Step: 2
Training loss: 0.037332646548748016
Validation loss: 1.3734921037509877

Epoch: 5| Step: 3
Training loss: 0.03565241023898125
Validation loss: 1.39286676145369

Epoch: 5| Step: 4
Training loss: 0.05748281627893448
Validation loss: 1.396290575304339

Epoch: 5| Step: 5
Training loss: 0.06380463391542435
Validation loss: 1.3723183511405863

Epoch: 5| Step: 6
Training loss: 0.04782423749566078
Validation loss: 1.3939457529334611

Epoch: 5| Step: 7
Training loss: 0.04117041081190109
Validation loss: 1.3622332593446136

Epoch: 5| Step: 8
Training loss: 0.03244810551404953
Validation loss: 1.3736007143092412

Epoch: 5| Step: 9
Training loss: 0.04339612275362015
Validation loss: 1.3836954050166632

Epoch: 5| Step: 10
Training loss: 0.13666626811027527
Validation loss: 1.3637781912280666

Epoch: 663| Step: 0
Training loss: 0.0755758062005043
Validation loss: 1.3644893701358507

Epoch: 5| Step: 1
Training loss: 0.037522874772548676
Validation loss: 1.3553596824728034

Epoch: 5| Step: 2
Training loss: 0.026383107528090477
Validation loss: 1.3793634317254508

Epoch: 5| Step: 3
Training loss: 0.04243044927716255
Validation loss: 1.3636657755862

Epoch: 5| Step: 4
Training loss: 0.03197998180985451
Validation loss: 1.3682825885793215

Epoch: 5| Step: 5
Training loss: 0.04197191447019577
Validation loss: 1.3677438766725603

Epoch: 5| Step: 6
Training loss: 0.07293497771024704
Validation loss: 1.3739725261606195

Epoch: 5| Step: 7
Training loss: 0.05068176984786987
Validation loss: 1.3569628346350886

Epoch: 5| Step: 8
Training loss: 0.11734459549188614
Validation loss: 1.3919636434124363

Epoch: 5| Step: 9
Training loss: 0.030791860073804855
Validation loss: 1.3891800770195581

Epoch: 5| Step: 10
Training loss: 0.047700949013233185
Validation loss: 1.3936691168815858

Epoch: 664| Step: 0
Training loss: 0.0778527706861496
Validation loss: 1.3855783157451178

Epoch: 5| Step: 1
Training loss: 0.02333156205713749
Validation loss: 1.3803172624239357

Epoch: 5| Step: 2
Training loss: 0.10896877944469452
Validation loss: 1.4179727787612586

Epoch: 5| Step: 3
Training loss: 0.043857913464307785
Validation loss: 1.403566502755688

Epoch: 5| Step: 4
Training loss: 0.05553555488586426
Validation loss: 1.4053051843438098

Epoch: 5| Step: 5
Training loss: 0.05228033661842346
Validation loss: 1.3891162224995193

Epoch: 5| Step: 6
Training loss: 0.07513023912906647
Validation loss: 1.3931003885884439

Epoch: 5| Step: 7
Training loss: 0.0643579363822937
Validation loss: 1.3834942938179098

Epoch: 5| Step: 8
Training loss: 0.03488820791244507
Validation loss: 1.3993640586894045

Epoch: 5| Step: 9
Training loss: 0.04253947734832764
Validation loss: 1.3938355189497753

Epoch: 5| Step: 10
Training loss: 0.054890226572752
Validation loss: 1.370030754355974

Epoch: 665| Step: 0
Training loss: 0.07397033274173737
Validation loss: 1.367951609755075

Epoch: 5| Step: 1
Training loss: 0.028992753475904465
Validation loss: 1.3563146789868672

Epoch: 5| Step: 2
Training loss: 0.11285499483346939
Validation loss: 1.3445519478090349

Epoch: 5| Step: 3
Training loss: 0.04881247133016586
Validation loss: 1.3505811563102148

Epoch: 5| Step: 4
Training loss: 0.06855443865060806
Validation loss: 1.3619490118436917

Epoch: 5| Step: 5
Training loss: 0.0597064383327961
Validation loss: 1.3461884907496873

Epoch: 5| Step: 6
Training loss: 0.06240834668278694
Validation loss: 1.3855395355532247

Epoch: 5| Step: 7
Training loss: 0.042691878974437714
Validation loss: 1.396654789165784

Epoch: 5| Step: 8
Training loss: 0.05468655377626419
Validation loss: 1.4276625622985184

Epoch: 5| Step: 9
Training loss: 0.055237818509340286
Validation loss: 1.4395590418128557

Epoch: 5| Step: 10
Training loss: 0.08071374893188477
Validation loss: 1.4154942753494426

Epoch: 666| Step: 0
Training loss: 0.06259717792272568
Validation loss: 1.4387621751395605

Epoch: 5| Step: 1
Training loss: 0.15370023250579834
Validation loss: 1.4394710679208078

Epoch: 5| Step: 2
Training loss: 0.05461574345827103
Validation loss: 1.4280861103406517

Epoch: 5| Step: 3
Training loss: 0.05911581590771675
Validation loss: 1.4233534412999307

Epoch: 5| Step: 4
Training loss: 0.038846466690301895
Validation loss: 1.426758590564933

Epoch: 5| Step: 5
Training loss: 0.08089087158441544
Validation loss: 1.4236078352056525

Epoch: 5| Step: 6
Training loss: 0.04484560340642929
Validation loss: 1.4085020916436308

Epoch: 5| Step: 7
Training loss: 0.05255318805575371
Validation loss: 1.413921219046398

Epoch: 5| Step: 8
Training loss: 0.04507499560713768
Validation loss: 1.4134131182906449

Epoch: 5| Step: 9
Training loss: 0.05595492199063301
Validation loss: 1.4239841635509203

Epoch: 5| Step: 10
Training loss: 0.02832789719104767
Validation loss: 1.4215158717606657

Epoch: 667| Step: 0
Training loss: 0.03966382145881653
Validation loss: 1.3981871476737402

Epoch: 5| Step: 1
Training loss: 0.03128363937139511
Validation loss: 1.3842536070013558

Epoch: 5| Step: 2
Training loss: 0.05330843850970268
Validation loss: 1.3859507909385107

Epoch: 5| Step: 3
Training loss: 0.12186188995838165
Validation loss: 1.3683975460708782

Epoch: 5| Step: 4
Training loss: 0.06998460739850998
Validation loss: 1.3744895579994365

Epoch: 5| Step: 5
Training loss: 0.060425084084272385
Validation loss: 1.3827938527189276

Epoch: 5| Step: 6
Training loss: 0.049169592559337616
Validation loss: 1.3854547162209787

Epoch: 5| Step: 7
Training loss: 0.04337159916758537
Validation loss: 1.394719131531254

Epoch: 5| Step: 8
Training loss: 0.058322250843048096
Validation loss: 1.3874535111970798

Epoch: 5| Step: 9
Training loss: 0.08984312415122986
Validation loss: 1.4152767824870285

Epoch: 5| Step: 10
Training loss: 0.07217150926589966
Validation loss: 1.4168259251502253

Epoch: 668| Step: 0
Training loss: 0.13360482454299927
Validation loss: 1.412051934067921

Epoch: 5| Step: 1
Training loss: 0.06355661898851395
Validation loss: 1.4441345942917692

Epoch: 5| Step: 2
Training loss: 0.03935706987977028
Validation loss: 1.4336777284581175

Epoch: 5| Step: 3
Training loss: 0.04684864357113838
Validation loss: 1.4256706699248283

Epoch: 5| Step: 4
Training loss: 0.04729430004954338
Validation loss: 1.4231825387606056

Epoch: 5| Step: 5
Training loss: 0.05199472978711128
Validation loss: 1.4339314455627112

Epoch: 5| Step: 6
Training loss: 0.04788133129477501
Validation loss: 1.4375752441344722

Epoch: 5| Step: 7
Training loss: 0.04392261803150177
Validation loss: 1.412617212982588

Epoch: 5| Step: 8
Training loss: 0.04341517761349678
Validation loss: 1.397351941754741

Epoch: 5| Step: 9
Training loss: 0.04712950810790062
Validation loss: 1.4205396406112178

Epoch: 5| Step: 10
Training loss: 0.06030189245939255
Validation loss: 1.4073822793140207

Epoch: 669| Step: 0
Training loss: 0.04477139934897423
Validation loss: 1.4040374486677107

Epoch: 5| Step: 1
Training loss: 0.07032739371061325
Validation loss: 1.416429494016914

Epoch: 5| Step: 2
Training loss: 0.034739892929792404
Validation loss: 1.423413525345505

Epoch: 5| Step: 3
Training loss: 0.14943796396255493
Validation loss: 1.4252671964706913

Epoch: 5| Step: 4
Training loss: 0.059940747916698456
Validation loss: 1.4171017792917067

Epoch: 5| Step: 5
Training loss: 0.049308113753795624
Validation loss: 1.4202372335618543

Epoch: 5| Step: 6
Training loss: 0.04380539804697037
Validation loss: 1.4057083309337657

Epoch: 5| Step: 7
Training loss: 0.036695413291454315
Validation loss: 1.4375205591160765

Epoch: 5| Step: 8
Training loss: 0.05035241320729256
Validation loss: 1.4090390064383065

Epoch: 5| Step: 9
Training loss: 0.04512529820203781
Validation loss: 1.4183585015676354

Epoch: 5| Step: 10
Training loss: 0.052837640047073364
Validation loss: 1.43692655973537

Epoch: 670| Step: 0
Training loss: 0.039797116070985794
Validation loss: 1.4430541069276872

Epoch: 5| Step: 1
Training loss: 0.045393578708171844
Validation loss: 1.463486970111888

Epoch: 5| Step: 2
Training loss: 0.039410531520843506
Validation loss: 1.4345293416771838

Epoch: 5| Step: 3
Training loss: 0.04526141285896301
Validation loss: 1.4278100908443492

Epoch: 5| Step: 4
Training loss: 0.07630563527345657
Validation loss: 1.4295387293702813

Epoch: 5| Step: 5
Training loss: 0.029113560914993286
Validation loss: 1.4469537145348006

Epoch: 5| Step: 6
Training loss: 0.05265127494931221
Validation loss: 1.4351830931120022

Epoch: 5| Step: 7
Training loss: 0.04443605989217758
Validation loss: 1.4454973154170538

Epoch: 5| Step: 8
Training loss: 0.14107051491737366
Validation loss: 1.434878227531269

Epoch: 5| Step: 9
Training loss: 0.037959981709718704
Validation loss: 1.436727955136248

Epoch: 5| Step: 10
Training loss: 0.03809153288602829
Validation loss: 1.4349721215104545

Epoch: 671| Step: 0
Training loss: 0.06963266432285309
Validation loss: 1.4260418402251376

Epoch: 5| Step: 1
Training loss: 0.05351636931300163
Validation loss: 1.3986257455682243

Epoch: 5| Step: 2
Training loss: 0.0681324452161789
Validation loss: 1.4053015978105607

Epoch: 5| Step: 3
Training loss: 0.03585764020681381
Validation loss: 1.4282471018452798

Epoch: 5| Step: 4
Training loss: 0.04123472794890404
Validation loss: 1.443447934683933

Epoch: 5| Step: 5
Training loss: 0.05520106106996536
Validation loss: 1.4512504916037283

Epoch: 5| Step: 6
Training loss: 0.11490607261657715
Validation loss: 1.4270040412102976

Epoch: 5| Step: 7
Training loss: 0.040741514414548874
Validation loss: 1.435593234595432

Epoch: 5| Step: 8
Training loss: 0.052802134305238724
Validation loss: 1.4420331626810052

Epoch: 5| Step: 9
Training loss: 0.04172864556312561
Validation loss: 1.4211488987809868

Epoch: 5| Step: 10
Training loss: 0.06874530762434006
Validation loss: 1.4179632048453055

Epoch: 672| Step: 0
Training loss: 0.03595221787691116
Validation loss: 1.4343647328756188

Epoch: 5| Step: 1
Training loss: 0.07524053007364273
Validation loss: 1.4265484912421114

Epoch: 5| Step: 2
Training loss: 0.05044444650411606
Validation loss: 1.4296691212602841

Epoch: 5| Step: 3
Training loss: 0.0356217622756958
Validation loss: 1.4347712173256824

Epoch: 5| Step: 4
Training loss: 0.05504416301846504
Validation loss: 1.4254531962897188

Epoch: 5| Step: 5
Training loss: 0.07748010754585266
Validation loss: 1.415840350171571

Epoch: 5| Step: 6
Training loss: 0.16756793856620789
Validation loss: 1.437915866092969

Epoch: 5| Step: 7
Training loss: 0.024075442925095558
Validation loss: 1.4514206327417845

Epoch: 5| Step: 8
Training loss: 0.04434088617563248
Validation loss: 1.4706069871943483

Epoch: 5| Step: 9
Training loss: 0.055486489087343216
Validation loss: 1.4275290837851904

Epoch: 5| Step: 10
Training loss: 0.05224301666021347
Validation loss: 1.4264674519979825

Epoch: 673| Step: 0
Training loss: 0.08121204376220703
Validation loss: 1.4197453183512534

Epoch: 5| Step: 1
Training loss: 0.11482725292444229
Validation loss: 1.4419939184701571

Epoch: 5| Step: 2
Training loss: 0.06338733434677124
Validation loss: 1.450350953686622

Epoch: 5| Step: 3
Training loss: 0.03725660592317581
Validation loss: 1.4343411037998814

Epoch: 5| Step: 4
Training loss: 0.09078934043645859
Validation loss: 1.4466040544612433

Epoch: 5| Step: 5
Training loss: 0.04041571915149689
Validation loss: 1.4432288574916061

Epoch: 5| Step: 6
Training loss: 0.04293525218963623
Validation loss: 1.44709998689672

Epoch: 5| Step: 7
Training loss: 0.05454862117767334
Validation loss: 1.4495838752356909

Epoch: 5| Step: 8
Training loss: 0.06204811856150627
Validation loss: 1.4454145085427068

Epoch: 5| Step: 9
Training loss: 0.03652051463723183
Validation loss: 1.451849005555594

Epoch: 5| Step: 10
Training loss: 0.0328388512134552
Validation loss: 1.4308278624729445

Epoch: 674| Step: 0
Training loss: 0.0367368683218956
Validation loss: 1.4300978683656262

Epoch: 5| Step: 1
Training loss: 0.06289421766996384
Validation loss: 1.4172431320272467

Epoch: 5| Step: 2
Training loss: 0.05841417238116264
Validation loss: 1.4301257056574668

Epoch: 5| Step: 3
Training loss: 0.07128822058439255
Validation loss: 1.411841643753872

Epoch: 5| Step: 4
Training loss: 0.037936724722385406
Validation loss: 1.396960985916917

Epoch: 5| Step: 5
Training loss: 0.04851889982819557
Validation loss: 1.3822181494005266

Epoch: 5| Step: 6
Training loss: 0.05454425886273384
Validation loss: 1.3846715150340911

Epoch: 5| Step: 7
Training loss: 0.06962494552135468
Validation loss: 1.3915279731955579

Epoch: 5| Step: 8
Training loss: 0.05435211583971977
Validation loss: 1.4196858957249632

Epoch: 5| Step: 9
Training loss: 0.051228784024715424
Validation loss: 1.4114057485775282

Epoch: 5| Step: 10
Training loss: 0.12812970578670502
Validation loss: 1.40507290568403

Epoch: 675| Step: 0
Training loss: 0.08687399327754974
Validation loss: 1.431940451745064

Epoch: 5| Step: 1
Training loss: 0.03860364109277725
Validation loss: 1.4238875309626262

Epoch: 5| Step: 2
Training loss: 0.04656779021024704
Validation loss: 1.4387522179593322

Epoch: 5| Step: 3
Training loss: 0.05868110805749893
Validation loss: 1.431062098472349

Epoch: 5| Step: 4
Training loss: 0.04360228776931763
Validation loss: 1.43331233404016

Epoch: 5| Step: 5
Training loss: 0.10972781479358673
Validation loss: 1.4375409477500505

Epoch: 5| Step: 6
Training loss: 0.05738860368728638
Validation loss: 1.4256283986952998

Epoch: 5| Step: 7
Training loss: 0.0625569149851799
Validation loss: 1.412114151062504

Epoch: 5| Step: 8
Training loss: 0.049346793442964554
Validation loss: 1.4258190816448582

Epoch: 5| Step: 9
Training loss: 0.04583027586340904
Validation loss: 1.4181101443947002

Epoch: 5| Step: 10
Training loss: 0.05643622949719429
Validation loss: 1.4112614764962146

Epoch: 676| Step: 0
Training loss: 0.03958718851208687
Validation loss: 1.3890412674155286

Epoch: 5| Step: 1
Training loss: 0.10724637657403946
Validation loss: 1.4095522331935104

Epoch: 5| Step: 2
Training loss: 0.0438932441174984
Validation loss: 1.3957706625743578

Epoch: 5| Step: 3
Training loss: 0.04924970865249634
Validation loss: 1.3927080759438135

Epoch: 5| Step: 4
Training loss: 0.04512175917625427
Validation loss: 1.394500647821734

Epoch: 5| Step: 5
Training loss: 0.06733430922031403
Validation loss: 1.3813552369353592

Epoch: 5| Step: 6
Training loss: 0.07053634524345398
Validation loss: 1.3960117473397204

Epoch: 5| Step: 7
Training loss: 0.03836233168840408
Validation loss: 1.3901654904888523

Epoch: 5| Step: 8
Training loss: 0.0834372416138649
Validation loss: 1.4039857989998275

Epoch: 5| Step: 9
Training loss: 0.05449410527944565
Validation loss: 1.406808530130694

Epoch: 5| Step: 10
Training loss: 0.06485693156719208
Validation loss: 1.4083432343698317

Epoch: 677| Step: 0
Training loss: 0.04507257789373398
Validation loss: 1.403622527276316

Epoch: 5| Step: 1
Training loss: 0.03918791189789772
Validation loss: 1.4093985326828495

Epoch: 5| Step: 2
Training loss: 0.06250601261854172
Validation loss: 1.4276772160683908

Epoch: 5| Step: 3
Training loss: 0.05270712450146675
Validation loss: 1.4319218448413316

Epoch: 5| Step: 4
Training loss: 0.051994096487760544
Validation loss: 1.4379546270575574

Epoch: 5| Step: 5
Training loss: 0.05811188742518425
Validation loss: 1.4488427921008038

Epoch: 5| Step: 6
Training loss: 0.05104956775903702
Validation loss: 1.4514707019252162

Epoch: 5| Step: 7
Training loss: 0.04049874097108841
Validation loss: 1.4559090188754502

Epoch: 5| Step: 8
Training loss: 0.10911134630441666
Validation loss: 1.4624821037374518

Epoch: 5| Step: 9
Training loss: 0.0928928479552269
Validation loss: 1.4403992622129378

Epoch: 5| Step: 10
Training loss: 0.07102914899587631
Validation loss: 1.446902467358497

Epoch: 678| Step: 0
Training loss: 0.0524137020111084
Validation loss: 1.4278483031898417

Epoch: 5| Step: 1
Training loss: 0.031583476811647415
Validation loss: 1.4136897799789265

Epoch: 5| Step: 2
Training loss: 0.05701414495706558
Validation loss: 1.4027528493635115

Epoch: 5| Step: 3
Training loss: 0.048165030777454376
Validation loss: 1.4113145246300647

Epoch: 5| Step: 4
Training loss: 0.048022203147411346
Validation loss: 1.4129288094018095

Epoch: 5| Step: 5
Training loss: 0.02439989522099495
Validation loss: 1.3965158667615665

Epoch: 5| Step: 6
Training loss: 0.15538232028484344
Validation loss: 1.375043761345648

Epoch: 5| Step: 7
Training loss: 0.07058431208133698
Validation loss: 1.3895657267621768

Epoch: 5| Step: 8
Training loss: 0.051076143980026245
Validation loss: 1.396405243104504

Epoch: 5| Step: 9
Training loss: 0.10159485042095184
Validation loss: 1.388855247087376

Epoch: 5| Step: 10
Training loss: 0.05586005747318268
Validation loss: 1.3896387213019914

Epoch: 679| Step: 0
Training loss: 0.03193981945514679
Validation loss: 1.3899721599394275

Epoch: 5| Step: 1
Training loss: 0.050990067422389984
Validation loss: 1.3792402821202432

Epoch: 5| Step: 2
Training loss: 0.05201277881860733
Validation loss: 1.38190770277413

Epoch: 5| Step: 3
Training loss: 0.05459314584732056
Validation loss: 1.3770406092366865

Epoch: 5| Step: 4
Training loss: 0.035886794328689575
Validation loss: 1.3959053229260188

Epoch: 5| Step: 5
Training loss: 0.06269935518503189
Validation loss: 1.402643704927096

Epoch: 5| Step: 6
Training loss: 0.052714478224515915
Validation loss: 1.3891404636444584

Epoch: 5| Step: 7
Training loss: 0.040410835295915604
Validation loss: 1.384721061234833

Epoch: 5| Step: 8
Training loss: 0.10821142047643661
Validation loss: 1.3810418658359076

Epoch: 5| Step: 9
Training loss: 0.08760108053684235
Validation loss: 1.3898636474404285

Epoch: 5| Step: 10
Training loss: 0.05662572756409645
Validation loss: 1.3883907230951453

Epoch: 680| Step: 0
Training loss: 0.061771899461746216
Validation loss: 1.3757386643399474

Epoch: 5| Step: 1
Training loss: 0.04042553901672363
Validation loss: 1.3841038826973207

Epoch: 5| Step: 2
Training loss: 0.11762858927249908
Validation loss: 1.3871628366490847

Epoch: 5| Step: 3
Training loss: 0.039339907467365265
Validation loss: 1.3797774725062872

Epoch: 5| Step: 4
Training loss: 0.05877400189638138
Validation loss: 1.3954312480906004

Epoch: 5| Step: 5
Training loss: 0.04579703509807587
Validation loss: 1.3899076587410384

Epoch: 5| Step: 6
Training loss: 0.0681324303150177
Validation loss: 1.390945493534047

Epoch: 5| Step: 7
Training loss: 0.05088844895362854
Validation loss: 1.3942518875163088

Epoch: 5| Step: 8
Training loss: 0.06140918657183647
Validation loss: 1.3693703682191911

Epoch: 5| Step: 9
Training loss: 0.06878732144832611
Validation loss: 1.3588211792771534

Epoch: 5| Step: 10
Training loss: 0.05537692829966545
Validation loss: 1.3574180192844842

Epoch: 681| Step: 0
Training loss: 0.07333879172801971
Validation loss: 1.3450145221525622

Epoch: 5| Step: 1
Training loss: 0.05850083753466606
Validation loss: 1.3746562901363577

Epoch: 5| Step: 2
Training loss: 0.12350662797689438
Validation loss: 1.390136775150094

Epoch: 5| Step: 3
Training loss: 0.06607624143362045
Validation loss: 1.3875991195760748

Epoch: 5| Step: 4
Training loss: 0.0479036383330822
Validation loss: 1.3900170057050643

Epoch: 5| Step: 5
Training loss: 0.044413696974515915
Validation loss: 1.3998998288185365

Epoch: 5| Step: 6
Training loss: 0.07263904809951782
Validation loss: 1.3760034755993915

Epoch: 5| Step: 7
Training loss: 0.02494272030889988
Validation loss: 1.3828310787036855

Epoch: 5| Step: 8
Training loss: 0.07218227535486221
Validation loss: 1.3804850629580918

Epoch: 5| Step: 9
Training loss: 0.05596200376749039
Validation loss: 1.3908273968645322

Epoch: 5| Step: 10
Training loss: 0.04875849187374115
Validation loss: 1.4112981711664507

Epoch: 682| Step: 0
Training loss: 0.03900191932916641
Validation loss: 1.3944469600595453

Epoch: 5| Step: 1
Training loss: 0.050924789160490036
Validation loss: 1.4170639591832315

Epoch: 5| Step: 2
Training loss: 0.05316295474767685
Validation loss: 1.441178580766083

Epoch: 5| Step: 3
Training loss: 0.0851820856332779
Validation loss: 1.4127910303813156

Epoch: 5| Step: 4
Training loss: 0.052714478224515915
Validation loss: 1.4152305292826828

Epoch: 5| Step: 5
Training loss: 0.048690345138311386
Validation loss: 1.4189792243383264

Epoch: 5| Step: 6
Training loss: 0.04565746337175369
Validation loss: 1.4276883999506633

Epoch: 5| Step: 7
Training loss: 0.07703522592782974
Validation loss: 1.4337773899878226

Epoch: 5| Step: 8
Training loss: 0.04305146262049675
Validation loss: 1.4211145947056432

Epoch: 5| Step: 9
Training loss: 0.0874309092760086
Validation loss: 1.4196405436403008

Epoch: 5| Step: 10
Training loss: 0.1371869146823883
Validation loss: 1.394914501456804

Epoch: 683| Step: 0
Training loss: 0.055898599326610565
Validation loss: 1.401680011262176

Epoch: 5| Step: 1
Training loss: 0.07041921466588974
Validation loss: 1.4001100883688977

Epoch: 5| Step: 2
Training loss: 0.057723451405763626
Validation loss: 1.4056535061969553

Epoch: 5| Step: 3
Training loss: 0.040585748851299286
Validation loss: 1.397362401408534

Epoch: 5| Step: 4
Training loss: 0.04530695825815201
Validation loss: 1.4073893011257212

Epoch: 5| Step: 5
Training loss: 0.03330441564321518
Validation loss: 1.414481327097903

Epoch: 5| Step: 6
Training loss: 0.05950285121798515
Validation loss: 1.427107463600815

Epoch: 5| Step: 7
Training loss: 0.06058523803949356
Validation loss: 1.4209841617973902

Epoch: 5| Step: 8
Training loss: 0.05102564021945
Validation loss: 1.4158356881910754

Epoch: 5| Step: 9
Training loss: 0.17713341116905212
Validation loss: 1.4329182268470846

Epoch: 5| Step: 10
Training loss: 0.04232107847929001
Validation loss: 1.4352436463038127

Epoch: 684| Step: 0
Training loss: 0.03679226338863373
Validation loss: 1.4120395222017843

Epoch: 5| Step: 1
Training loss: 0.037438634783029556
Validation loss: 1.4128012323892245

Epoch: 5| Step: 2
Training loss: 0.035915471613407135
Validation loss: 1.4097829621325257

Epoch: 5| Step: 3
Training loss: 0.05061645433306694
Validation loss: 1.4130707876656645

Epoch: 5| Step: 4
Training loss: 0.061608802527189255
Validation loss: 1.4096709041185276

Epoch: 5| Step: 5
Training loss: 0.0353679284453392
Validation loss: 1.3959378837257304

Epoch: 5| Step: 6
Training loss: 0.04798251762986183
Validation loss: 1.3987326160553963

Epoch: 5| Step: 7
Training loss: 0.04683559387922287
Validation loss: 1.4120395068199403

Epoch: 5| Step: 8
Training loss: 0.03907818719744682
Validation loss: 1.4083026596294936

Epoch: 5| Step: 9
Training loss: 0.15049061179161072
Validation loss: 1.4087058055785395

Epoch: 5| Step: 10
Training loss: 0.056990787386894226
Validation loss: 1.4004502873266897

Epoch: 685| Step: 0
Training loss: 0.03690699487924576
Validation loss: 1.426666094410804

Epoch: 5| Step: 1
Training loss: 0.06110174581408501
Validation loss: 1.4100043824923936

Epoch: 5| Step: 2
Training loss: 0.03281881660223007
Validation loss: 1.4147032563404371

Epoch: 5| Step: 3
Training loss: 0.041269153356552124
Validation loss: 1.4134028675735637

Epoch: 5| Step: 4
Training loss: 0.12578800320625305
Validation loss: 1.4215028798708351

Epoch: 5| Step: 5
Training loss: 0.04710890352725983
Validation loss: 1.4148024756421325

Epoch: 5| Step: 6
Training loss: 0.047461144626140594
Validation loss: 1.4195518327015701

Epoch: 5| Step: 7
Training loss: 0.05500424653291702
Validation loss: 1.412573665060023

Epoch: 5| Step: 8
Training loss: 0.03987056016921997
Validation loss: 1.4272728812310003

Epoch: 5| Step: 9
Training loss: 0.06689391285181046
Validation loss: 1.412743471002066

Epoch: 5| Step: 10
Training loss: 0.05385502800345421
Validation loss: 1.4046622117360432

Epoch: 686| Step: 0
Training loss: 0.04076618328690529
Validation loss: 1.4269509277036112

Epoch: 5| Step: 1
Training loss: 0.060333482921123505
Validation loss: 1.411642825731667

Epoch: 5| Step: 2
Training loss: 0.05992532894015312
Validation loss: 1.4391950432972243

Epoch: 5| Step: 3
Training loss: 0.03715275973081589
Validation loss: 1.4184963177609187

Epoch: 5| Step: 4
Training loss: 0.04010937362909317
Validation loss: 1.4156515495751494

Epoch: 5| Step: 5
Training loss: 0.12821075320243835
Validation loss: 1.3991444610780286

Epoch: 5| Step: 6
Training loss: 0.037141602486371994
Validation loss: 1.4046721445616854

Epoch: 5| Step: 7
Training loss: 0.05484051629900932
Validation loss: 1.4068819758712605

Epoch: 5| Step: 8
Training loss: 0.03592786192893982
Validation loss: 1.4056732731480752

Epoch: 5| Step: 9
Training loss: 0.0473785363137722
Validation loss: 1.426408193444693

Epoch: 5| Step: 10
Training loss: 0.05440555512905121
Validation loss: 1.4056412263583111

Epoch: 687| Step: 0
Training loss: 0.04260166734457016
Validation loss: 1.40443177377024

Epoch: 5| Step: 1
Training loss: 0.04384574294090271
Validation loss: 1.3985662293690506

Epoch: 5| Step: 2
Training loss: 0.06246497109532356
Validation loss: 1.3812426187658822

Epoch: 5| Step: 3
Training loss: 0.05866742134094238
Validation loss: 1.403016149356801

Epoch: 5| Step: 4
Training loss: 0.05406997352838516
Validation loss: 1.3804401825833064

Epoch: 5| Step: 5
Training loss: 0.12399721145629883
Validation loss: 1.401169671807238

Epoch: 5| Step: 6
Training loss: 0.06258714199066162
Validation loss: 1.399204017013632

Epoch: 5| Step: 7
Training loss: 0.04222020506858826
Validation loss: 1.3949930584558876

Epoch: 5| Step: 8
Training loss: 0.0414629727602005
Validation loss: 1.4276308346820135

Epoch: 5| Step: 9
Training loss: 0.05169110372662544
Validation loss: 1.4265382289886475

Epoch: 5| Step: 10
Training loss: 0.05416931211948395
Validation loss: 1.4186734089287378

Epoch: 688| Step: 0
Training loss: 0.08964118361473083
Validation loss: 1.4058925990135438

Epoch: 5| Step: 1
Training loss: 0.11487698554992676
Validation loss: 1.4158206242387013

Epoch: 5| Step: 2
Training loss: 0.03597544506192207
Validation loss: 1.3923821680007442

Epoch: 5| Step: 3
Training loss: 0.04232832044363022
Validation loss: 1.395047321114489

Epoch: 5| Step: 4
Training loss: 0.047486912459135056
Validation loss: 1.372365508028256

Epoch: 5| Step: 5
Training loss: 0.02948703244328499
Validation loss: 1.3972060359934324

Epoch: 5| Step: 6
Training loss: 0.041970230638980865
Validation loss: 1.3928816536421418

Epoch: 5| Step: 7
Training loss: 0.053984809666872025
Validation loss: 1.391941318588872

Epoch: 5| Step: 8
Training loss: 0.04077604040503502
Validation loss: 1.3773635805294078

Epoch: 5| Step: 9
Training loss: 0.04432063549757004
Validation loss: 1.4160176233578754

Epoch: 5| Step: 10
Training loss: 0.04103272035717964
Validation loss: 1.4033184718060236

Epoch: 689| Step: 0
Training loss: 0.06059031933546066
Validation loss: 1.399000399856157

Epoch: 5| Step: 1
Training loss: 0.04300843924283981
Validation loss: 1.3860217012384886

Epoch: 5| Step: 2
Training loss: 0.10047809034585953
Validation loss: 1.4081355820419967

Epoch: 5| Step: 3
Training loss: 0.037377629429101944
Validation loss: 1.4151053191513143

Epoch: 5| Step: 4
Training loss: 0.03233245760202408
Validation loss: 1.3956247183584398

Epoch: 5| Step: 5
Training loss: 0.0545046329498291
Validation loss: 1.386100467815194

Epoch: 5| Step: 6
Training loss: 0.04509876295924187
Validation loss: 1.4137806264303063

Epoch: 5| Step: 7
Training loss: 0.05018412321805954
Validation loss: 1.387522820503481

Epoch: 5| Step: 8
Training loss: 0.03714732080698013
Validation loss: 1.408848121602048

Epoch: 5| Step: 9
Training loss: 0.041627924889326096
Validation loss: 1.4068412344942811

Epoch: 5| Step: 10
Training loss: 0.056613899767398834
Validation loss: 1.4082798534824001

Epoch: 690| Step: 0
Training loss: 0.06035049632191658
Validation loss: 1.417731701686818

Epoch: 5| Step: 1
Training loss: 0.053799331188201904
Validation loss: 1.4234502469339678

Epoch: 5| Step: 2
Training loss: 0.04793129116296768
Validation loss: 1.3956697384516399

Epoch: 5| Step: 3
Training loss: 0.044094111770391464
Validation loss: 1.4222572106187061

Epoch: 5| Step: 4
Training loss: 0.11080516874790192
Validation loss: 1.4241777466189476

Epoch: 5| Step: 5
Training loss: 0.04032224416732788
Validation loss: 1.3951337222130067

Epoch: 5| Step: 6
Training loss: 0.05453407019376755
Validation loss: 1.4219561757579926

Epoch: 5| Step: 7
Training loss: 0.05020264536142349
Validation loss: 1.4163250788565604

Epoch: 5| Step: 8
Training loss: 0.03073630854487419
Validation loss: 1.418402640409367

Epoch: 5| Step: 9
Training loss: 0.03960248827934265
Validation loss: 1.400949626840571

Epoch: 5| Step: 10
Training loss: 0.054239414632320404
Validation loss: 1.4108426378619285

Epoch: 691| Step: 0
Training loss: 0.02922632358968258
Validation loss: 1.427451486869525

Epoch: 5| Step: 1
Training loss: 0.06214774772524834
Validation loss: 1.4116292333090177

Epoch: 5| Step: 2
Training loss: 0.05756937339901924
Validation loss: 1.4057902661702966

Epoch: 5| Step: 3
Training loss: 0.03272949904203415
Validation loss: 1.416500105652758

Epoch: 5| Step: 4
Training loss: 0.043520741164684296
Validation loss: 1.400630941954992

Epoch: 5| Step: 5
Training loss: 0.10933588445186615
Validation loss: 1.4109430838656682

Epoch: 5| Step: 6
Training loss: 0.061220914125442505
Validation loss: 1.418436026060453

Epoch: 5| Step: 7
Training loss: 0.04342494159936905
Validation loss: 1.4297940692593973

Epoch: 5| Step: 8
Training loss: 0.05062929540872574
Validation loss: 1.402826004130866

Epoch: 5| Step: 9
Training loss: 0.04120669513940811
Validation loss: 1.4232659269404668

Epoch: 5| Step: 10
Training loss: 0.04270866885781288
Validation loss: 1.410479975003068

Epoch: 692| Step: 0
Training loss: 0.03624889254570007
Validation loss: 1.4257824946475286

Epoch: 5| Step: 1
Training loss: 0.04394746199250221
Validation loss: 1.4060042840178295

Epoch: 5| Step: 2
Training loss: 0.045697152614593506
Validation loss: 1.4205852849509126

Epoch: 5| Step: 3
Training loss: 0.05232008546590805
Validation loss: 1.4222384780965827

Epoch: 5| Step: 4
Training loss: 0.10703177750110626
Validation loss: 1.4081572204507806

Epoch: 5| Step: 5
Training loss: 0.06939826160669327
Validation loss: 1.3997088106729652

Epoch: 5| Step: 6
Training loss: 0.047768380492925644
Validation loss: 1.3990883340117752

Epoch: 5| Step: 7
Training loss: 0.05346440151333809
Validation loss: 1.4146231105250697

Epoch: 5| Step: 8
Training loss: 0.05363185331225395
Validation loss: 1.4083610362904047

Epoch: 5| Step: 9
Training loss: 0.0506591796875
Validation loss: 1.4315441680210892

Epoch: 5| Step: 10
Training loss: 0.053243618458509445
Validation loss: 1.442803116254909

Epoch: 693| Step: 0
Training loss: 0.1744118481874466
Validation loss: 1.4379289304056475

Epoch: 5| Step: 1
Training loss: 0.02804405428469181
Validation loss: 1.4074673601376113

Epoch: 5| Step: 2
Training loss: 0.04027291387319565
Validation loss: 1.395001229419503

Epoch: 5| Step: 3
Training loss: 0.03089570626616478
Validation loss: 1.3872117278396443

Epoch: 5| Step: 4
Training loss: 0.0362079031765461
Validation loss: 1.4065782818742978

Epoch: 5| Step: 5
Training loss: 0.03986860066652298
Validation loss: 1.3700380299680976

Epoch: 5| Step: 6
Training loss: 0.042068954557180405
Validation loss: 1.3868139713041243

Epoch: 5| Step: 7
Training loss: 0.04155624657869339
Validation loss: 1.3646688852258908

Epoch: 5| Step: 8
Training loss: 0.06544916331768036
Validation loss: 1.3875368077267882

Epoch: 5| Step: 9
Training loss: 0.054490573704242706
Validation loss: 1.375791976528783

Epoch: 5| Step: 10
Training loss: 0.04373098164796829
Validation loss: 1.3996140969696866

Epoch: 694| Step: 0
Training loss: 0.03689446300268173
Validation loss: 1.394587589207516

Epoch: 5| Step: 1
Training loss: 0.06389569491147995
Validation loss: 1.3755555024711035

Epoch: 5| Step: 2
Training loss: 0.052535831928253174
Validation loss: 1.3688850120831562

Epoch: 5| Step: 3
Training loss: 0.03245827555656433
Validation loss: 1.3852414354201286

Epoch: 5| Step: 4
Training loss: 0.03107449971139431
Validation loss: 1.394977725962157

Epoch: 5| Step: 5
Training loss: 0.0387999601662159
Validation loss: 1.4046157931768766

Epoch: 5| Step: 6
Training loss: 0.059451885521411896
Validation loss: 1.3752584547124884

Epoch: 5| Step: 7
Training loss: 0.035696081817150116
Validation loss: 1.3771535824703913

Epoch: 5| Step: 8
Training loss: 0.049402255564928055
Validation loss: 1.3529450393492175

Epoch: 5| Step: 9
Training loss: 0.1237730011343956
Validation loss: 1.3810849805032053

Epoch: 5| Step: 10
Training loss: 0.026075590401887894
Validation loss: 1.370688312797136

Epoch: 695| Step: 0
Training loss: 0.05015719681978226
Validation loss: 1.358087508909164

Epoch: 5| Step: 1
Training loss: 0.11753962188959122
Validation loss: 1.372282233289493

Epoch: 5| Step: 2
Training loss: 0.030436724424362183
Validation loss: 1.3684971089004188

Epoch: 5| Step: 3
Training loss: 0.05202602222561836
Validation loss: 1.3705013708401752

Epoch: 5| Step: 4
Training loss: 0.0402812585234642
Validation loss: 1.3711132105960642

Epoch: 5| Step: 5
Training loss: 0.05512217432260513
Validation loss: 1.3733913898468018

Epoch: 5| Step: 6
Training loss: 0.050946641713380814
Validation loss: 1.3924119120003076

Epoch: 5| Step: 7
Training loss: 0.04275199770927429
Validation loss: 1.3742469767088532

Epoch: 5| Step: 8
Training loss: 0.056208133697509766
Validation loss: 1.378689669793652

Epoch: 5| Step: 9
Training loss: 0.03364148736000061
Validation loss: 1.40514507344974

Epoch: 5| Step: 10
Training loss: 0.04803666099905968
Validation loss: 1.4109716825587775

Epoch: 696| Step: 0
Training loss: 0.041903652250766754
Validation loss: 1.41260447425227

Epoch: 5| Step: 1
Training loss: 0.03932087495923042
Validation loss: 1.4162584517591743

Epoch: 5| Step: 2
Training loss: 0.03381193429231644
Validation loss: 1.3748388828769806

Epoch: 5| Step: 3
Training loss: 0.028616566210985184
Validation loss: 1.3938110951454408

Epoch: 5| Step: 4
Training loss: 0.03226045146584511
Validation loss: 1.3807659687534455

Epoch: 5| Step: 5
Training loss: 0.056311190128326416
Validation loss: 1.4055275711961972

Epoch: 5| Step: 6
Training loss: 0.0467023141682148
Validation loss: 1.3882333142783052

Epoch: 5| Step: 7
Training loss: 0.10116414725780487
Validation loss: 1.4154024598419026

Epoch: 5| Step: 8
Training loss: 0.0317264087498188
Validation loss: 1.4071488598341584

Epoch: 5| Step: 9
Training loss: 0.06121684983372688
Validation loss: 1.3997033731911772

Epoch: 5| Step: 10
Training loss: 0.050665367394685745
Validation loss: 1.394097384586129

Epoch: 697| Step: 0
Training loss: 0.058374226093292236
Validation loss: 1.417245941777383

Epoch: 5| Step: 1
Training loss: 0.044441018253564835
Validation loss: 1.4131357028920164

Epoch: 5| Step: 2
Training loss: 0.02559811808168888
Validation loss: 1.4011589557893815

Epoch: 5| Step: 3
Training loss: 0.05263960361480713
Validation loss: 1.389455097977833

Epoch: 5| Step: 4
Training loss: 0.07799725234508514
Validation loss: 1.4090163707733154

Epoch: 5| Step: 5
Training loss: 0.06172021105885506
Validation loss: 1.4247405067566903

Epoch: 5| Step: 6
Training loss: 0.0495513454079628
Validation loss: 1.4025098213585474

Epoch: 5| Step: 7
Training loss: 0.03209995850920677
Validation loss: 1.3930896879524313

Epoch: 5| Step: 8
Training loss: 0.051105547696352005
Validation loss: 1.4025313501716943

Epoch: 5| Step: 9
Training loss: 0.12522664666175842
Validation loss: 1.424309943311958

Epoch: 5| Step: 10
Training loss: 0.05499536916613579
Validation loss: 1.407630035954137

Epoch: 698| Step: 0
Training loss: 0.05377646163105965
Validation loss: 1.42412704806174

Epoch: 5| Step: 1
Training loss: 0.09888491034507751
Validation loss: 1.4062998576830792

Epoch: 5| Step: 2
Training loss: 0.04533882066607475
Validation loss: 1.4290662125874591

Epoch: 5| Step: 3
Training loss: 0.04027579724788666
Validation loss: 1.4175739557512346

Epoch: 5| Step: 4
Training loss: 0.053620804101228714
Validation loss: 1.4398470085154298

Epoch: 5| Step: 5
Training loss: 0.047711074352264404
Validation loss: 1.4379479385191394

Epoch: 5| Step: 6
Training loss: 0.03441138193011284
Validation loss: 1.447001955201549

Epoch: 5| Step: 7
Training loss: 0.03858479857444763
Validation loss: 1.4543473823096162

Epoch: 5| Step: 8
Training loss: 0.06464598327875137
Validation loss: 1.4261202568648963

Epoch: 5| Step: 9
Training loss: 0.04944322258234024
Validation loss: 1.421924232154764

Epoch: 5| Step: 10
Training loss: 0.04782363399863243
Validation loss: 1.4246016266525432

Epoch: 699| Step: 0
Training loss: 0.04827185720205307
Validation loss: 1.4346326929266735

Epoch: 5| Step: 1
Training loss: 0.04190101474523544
Validation loss: 1.4272658337828934

Epoch: 5| Step: 2
Training loss: 0.03242696449160576
Validation loss: 1.4073280198599702

Epoch: 5| Step: 3
Training loss: 0.03026614710688591
Validation loss: 1.385737960056592

Epoch: 5| Step: 4
Training loss: 0.03584219887852669
Validation loss: 1.3907239565285303

Epoch: 5| Step: 5
Training loss: 0.05483429506421089
Validation loss: 1.3846114937977125

Epoch: 5| Step: 6
Training loss: 0.04738199710845947
Validation loss: 1.3912815547758532

Epoch: 5| Step: 7
Training loss: 0.04519777372479439
Validation loss: 1.3649912290675665

Epoch: 5| Step: 8
Training loss: 0.0428774431347847
Validation loss: 1.3735995625936857

Epoch: 5| Step: 9
Training loss: 0.1210564523935318
Validation loss: 1.3855731474455966

Epoch: 5| Step: 10
Training loss: 0.08351437002420425
Validation loss: 1.3919718483442902

Epoch: 700| Step: 0
Training loss: 0.09190241247415543
Validation loss: 1.371187508747142

Epoch: 5| Step: 1
Training loss: 0.0460454598069191
Validation loss: 1.372355322684011

Epoch: 5| Step: 2
Training loss: 0.06219436973333359
Validation loss: 1.3983933130900066

Epoch: 5| Step: 3
Training loss: 0.05360011011362076
Validation loss: 1.397646306663431

Epoch: 5| Step: 4
Training loss: 0.04583795368671417
Validation loss: 1.40253335109321

Epoch: 5| Step: 5
Training loss: 0.04077664017677307
Validation loss: 1.383242836562536

Epoch: 5| Step: 6
Training loss: 0.03328623250126839
Validation loss: 1.4046546900144188

Epoch: 5| Step: 7
Training loss: 0.032447658479213715
Validation loss: 1.3978851725978236

Epoch: 5| Step: 8
Training loss: 0.02775929868221283
Validation loss: 1.3998345303279098

Epoch: 5| Step: 9
Training loss: 0.04231380671262741
Validation loss: 1.396148552176773

Epoch: 5| Step: 10
Training loss: 0.03521260991692543
Validation loss: 1.3894046250210013

Testing loss: 2.2715135282940335
