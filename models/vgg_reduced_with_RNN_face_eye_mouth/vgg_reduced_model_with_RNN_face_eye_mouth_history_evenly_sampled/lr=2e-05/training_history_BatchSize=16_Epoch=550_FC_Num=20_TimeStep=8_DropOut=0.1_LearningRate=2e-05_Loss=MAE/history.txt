Epoch: 1| Step: 0
Training loss: 5.541838645935059
Validation loss: 5.176429230679748

Epoch: 6| Step: 1
Training loss: 4.520773887634277
Validation loss: 5.157651409026115

Epoch: 6| Step: 2
Training loss: 5.3489508628845215
Validation loss: 5.14395426165673

Epoch: 6| Step: 3
Training loss: 4.6219024658203125
Validation loss: 5.132533770735546

Epoch: 6| Step: 4
Training loss: 3.7608346939086914
Validation loss: 5.121081295833792

Epoch: 6| Step: 5
Training loss: 4.2954864501953125
Validation loss: 5.1087060948853855

Epoch: 6| Step: 6
Training loss: 6.238468170166016
Validation loss: 5.094840372762373

Epoch: 6| Step: 7
Training loss: 5.496549606323242
Validation loss: 5.079225160742319

Epoch: 6| Step: 8
Training loss: 5.05172872543335
Validation loss: 5.061150099641534

Epoch: 6| Step: 9
Training loss: 3.435375213623047
Validation loss: 5.03933520470896

Epoch: 6| Step: 10
Training loss: 4.5592851638793945
Validation loss: 5.014498459395542

Epoch: 6| Step: 11
Training loss: 6.057627201080322
Validation loss: 4.985885625244469

Epoch: 6| Step: 12
Training loss: 4.580925464630127
Validation loss: 4.951723416646321

Epoch: 6| Step: 13
Training loss: 4.51070499420166
Validation loss: 4.9147589898878525

Epoch: 2| Step: 0
Training loss: 5.470339775085449
Validation loss: 4.871307649920063

Epoch: 6| Step: 1
Training loss: 4.5351786613464355
Validation loss: 4.823351767755324

Epoch: 6| Step: 2
Training loss: 4.897714614868164
Validation loss: 4.768587430318196

Epoch: 6| Step: 3
Training loss: 4.674211025238037
Validation loss: 4.708371264960176

Epoch: 6| Step: 4
Training loss: 3.973464012145996
Validation loss: 4.644785588787448

Epoch: 6| Step: 5
Training loss: 3.5029170513153076
Validation loss: 4.574364267369752

Epoch: 6| Step: 6
Training loss: 4.410374641418457
Validation loss: 4.500157556226177

Epoch: 6| Step: 7
Training loss: 5.756031036376953
Validation loss: 4.422051898894772

Epoch: 6| Step: 8
Training loss: 3.3967161178588867
Validation loss: 4.343290262324835

Epoch: 6| Step: 9
Training loss: 4.720525741577148
Validation loss: 4.267358800416352

Epoch: 6| Step: 10
Training loss: 3.8816404342651367
Validation loss: 4.202838474704373

Epoch: 6| Step: 11
Training loss: 3.183781385421753
Validation loss: 4.140839884358067

Epoch: 6| Step: 12
Training loss: 3.1240930557250977
Validation loss: 4.0893625905436854

Epoch: 6| Step: 13
Training loss: 4.221816062927246
Validation loss: 4.044270223186862

Epoch: 3| Step: 0
Training loss: 4.393874645233154
Validation loss: 4.010186062064222

Epoch: 6| Step: 1
Training loss: 4.151089668273926
Validation loss: 3.9844334253700833

Epoch: 6| Step: 2
Training loss: 3.9957332611083984
Validation loss: 3.9618077483228458

Epoch: 6| Step: 3
Training loss: 3.7526588439941406
Validation loss: 3.9425338775880876

Epoch: 6| Step: 4
Training loss: 2.7777304649353027
Validation loss: 3.926199036259805

Epoch: 6| Step: 5
Training loss: 3.3684725761413574
Validation loss: 3.909992843545893

Epoch: 6| Step: 6
Training loss: 3.0314583778381348
Validation loss: 3.8910745805309666

Epoch: 6| Step: 7
Training loss: 4.28538703918457
Validation loss: 3.87035547789707

Epoch: 6| Step: 8
Training loss: 3.4731969833374023
Validation loss: 3.8511572653247463

Epoch: 6| Step: 9
Training loss: 4.357259750366211
Validation loss: 3.8313705228990123

Epoch: 6| Step: 10
Training loss: 4.853333473205566
Validation loss: 3.814861782135502

Epoch: 6| Step: 11
Training loss: 2.988083839416504
Validation loss: 3.7926817171035276

Epoch: 6| Step: 12
Training loss: 3.120497703552246
Validation loss: 3.7732805129020446

Epoch: 6| Step: 13
Training loss: 4.0330424308776855
Validation loss: 3.755200078410487

Epoch: 4| Step: 0
Training loss: 2.6935627460479736
Validation loss: 3.7372651151431504

Epoch: 6| Step: 1
Training loss: 4.899383544921875
Validation loss: 3.7232407703194568

Epoch: 6| Step: 2
Training loss: 3.9721505641937256
Validation loss: 3.704773182510048

Epoch: 6| Step: 3
Training loss: 3.31009578704834
Validation loss: 3.6951742787514963

Epoch: 6| Step: 4
Training loss: 4.736560344696045
Validation loss: 3.6828702444671304

Epoch: 6| Step: 5
Training loss: 3.245344400405884
Validation loss: 3.6722862848671536

Epoch: 6| Step: 6
Training loss: 2.8065924644470215
Validation loss: 3.649358187952349

Epoch: 6| Step: 7
Training loss: 4.103832244873047
Validation loss: 3.6214864894907963

Epoch: 6| Step: 8
Training loss: 3.3795297145843506
Validation loss: 3.6006381921870734

Epoch: 6| Step: 9
Training loss: 3.508375883102417
Validation loss: 3.5862220794923845

Epoch: 6| Step: 10
Training loss: 4.108543872833252
Validation loss: 3.5632922700656358

Epoch: 6| Step: 11
Training loss: 2.475782871246338
Validation loss: 3.548509200414022

Epoch: 6| Step: 12
Training loss: 2.6263914108276367
Validation loss: 3.5378915186851256

Epoch: 6| Step: 13
Training loss: 3.983729362487793
Validation loss: 3.5255583537522184

Epoch: 5| Step: 0
Training loss: 3.274238109588623
Validation loss: 3.5200513998667398

Epoch: 6| Step: 1
Training loss: 3.8599584102630615
Validation loss: 3.5109425411429456

Epoch: 6| Step: 2
Training loss: 2.994248628616333
Validation loss: 3.5020925716687272

Epoch: 6| Step: 3
Training loss: 3.7091941833496094
Validation loss: 3.484399193076677

Epoch: 6| Step: 4
Training loss: 3.414186954498291
Validation loss: 3.473579245228921

Epoch: 6| Step: 5
Training loss: 3.368025779724121
Validation loss: 3.4723105020420526

Epoch: 6| Step: 6
Training loss: 3.910738468170166
Validation loss: 3.4521354424056185

Epoch: 6| Step: 7
Training loss: 3.399298667907715
Validation loss: 3.4347611857998754

Epoch: 6| Step: 8
Training loss: 3.1805357933044434
Validation loss: 3.42957466904835

Epoch: 6| Step: 9
Training loss: 4.041541576385498
Validation loss: 3.429224891047324

Epoch: 6| Step: 10
Training loss: 2.950864315032959
Validation loss: 3.4113335199253534

Epoch: 6| Step: 11
Training loss: 3.1550517082214355
Validation loss: 3.401775590835079

Epoch: 6| Step: 12
Training loss: 2.7631702423095703
Validation loss: 3.3991696091108423

Epoch: 6| Step: 13
Training loss: 3.5502772331237793
Validation loss: 3.3946041753215175

Epoch: 6| Step: 0
Training loss: 3.757749319076538
Validation loss: 3.3850746539331253

Epoch: 6| Step: 1
Training loss: 3.645573616027832
Validation loss: 3.3718652750856135

Epoch: 6| Step: 2
Training loss: 3.6852498054504395
Validation loss: 3.356636570345971

Epoch: 6| Step: 3
Training loss: 2.775979995727539
Validation loss: 3.3513742493044947

Epoch: 6| Step: 4
Training loss: 2.7435357570648193
Validation loss: 3.340457457368092

Epoch: 6| Step: 5
Training loss: 2.9716928005218506
Validation loss: 3.330254175329721

Epoch: 6| Step: 6
Training loss: 4.049274444580078
Validation loss: 3.320038010997157

Epoch: 6| Step: 7
Training loss: 3.1380064487457275
Validation loss: 3.3136812922775105

Epoch: 6| Step: 8
Training loss: 2.932739734649658
Validation loss: 3.308957535733459

Epoch: 6| Step: 9
Training loss: 3.24057674407959
Validation loss: 3.289707419692829

Epoch: 6| Step: 10
Training loss: 3.0216472148895264
Validation loss: 3.2853801532458236

Epoch: 6| Step: 11
Training loss: 3.3142831325531006
Validation loss: 3.2815862368511897

Epoch: 6| Step: 12
Training loss: 2.8018057346343994
Validation loss: 3.2864985055820917

Epoch: 6| Step: 13
Training loss: 4.483983993530273
Validation loss: 3.306830362607074

Epoch: 7| Step: 0
Training loss: 2.4901881217956543
Validation loss: 3.2557238250650387

Epoch: 6| Step: 1
Training loss: 2.1290528774261475
Validation loss: 3.2923934716050343

Epoch: 6| Step: 2
Training loss: 4.277222633361816
Validation loss: 3.4650568475005445

Epoch: 6| Step: 3
Training loss: 3.6233956813812256
Validation loss: 3.345318086685673

Epoch: 6| Step: 4
Training loss: 3.0544557571411133
Validation loss: 3.2626604521146385

Epoch: 6| Step: 5
Training loss: 3.0587289333343506
Validation loss: 3.2561709034827446

Epoch: 6| Step: 6
Training loss: 3.03421688079834
Validation loss: 3.2632855035925425

Epoch: 6| Step: 7
Training loss: 3.306898832321167
Validation loss: 3.2696543534596763

Epoch: 6| Step: 8
Training loss: 4.1898040771484375
Validation loss: 3.2496001746064875

Epoch: 6| Step: 9
Training loss: 2.362470865249634
Validation loss: 3.238705717107301

Epoch: 6| Step: 10
Training loss: 3.662508010864258
Validation loss: 3.2279424821176836

Epoch: 6| Step: 11
Training loss: 4.413995742797852
Validation loss: 3.2320663570075907

Epoch: 6| Step: 12
Training loss: 2.9240126609802246
Validation loss: 3.2342870850716867

Epoch: 6| Step: 13
Training loss: 2.913639783859253
Validation loss: 3.2241136617557977

Epoch: 8| Step: 0
Training loss: 2.376732110977173
Validation loss: 3.2139671771757063

Epoch: 6| Step: 1
Training loss: 2.211724042892456
Validation loss: 3.206052382787069

Epoch: 6| Step: 2
Training loss: 3.3013696670532227
Validation loss: 3.194874619924894

Epoch: 6| Step: 3
Training loss: 3.3024954795837402
Validation loss: 3.1852164242857244

Epoch: 6| Step: 4
Training loss: 1.7723336219787598
Validation loss: 3.1738567557386173

Epoch: 6| Step: 5
Training loss: 3.130215644836426
Validation loss: 3.163665069046841

Epoch: 6| Step: 6
Training loss: 3.1506643295288086
Validation loss: 3.1581552464474916

Epoch: 6| Step: 7
Training loss: 3.7750329971313477
Validation loss: 3.151666154143631

Epoch: 6| Step: 8
Training loss: 4.319019317626953
Validation loss: 3.1437889837449595

Epoch: 6| Step: 9
Training loss: 2.7898690700531006
Validation loss: 3.132653138970816

Epoch: 6| Step: 10
Training loss: 4.112274169921875
Validation loss: 3.1251214704205914

Epoch: 6| Step: 11
Training loss: 3.5372772216796875
Validation loss: 3.117836747118222

Epoch: 6| Step: 12
Training loss: 3.7990896701812744
Validation loss: 3.1094899049369236

Epoch: 6| Step: 13
Training loss: 2.3106276988983154
Validation loss: 3.100834018440657

Epoch: 9| Step: 0
Training loss: 2.88962984085083
Validation loss: 3.0984444131133375

Epoch: 6| Step: 1
Training loss: 3.11885929107666
Validation loss: 3.096980610201436

Epoch: 6| Step: 2
Training loss: 3.07293701171875
Validation loss: 3.114586337920158

Epoch: 6| Step: 3
Training loss: 3.460793972015381
Validation loss: 3.070609733622561

Epoch: 6| Step: 4
Training loss: 3.8453259468078613
Validation loss: 3.080854651748493

Epoch: 6| Step: 5
Training loss: 4.5255584716796875
Validation loss: 3.102166837261569

Epoch: 6| Step: 6
Training loss: 2.7795815467834473
Validation loss: 3.1060931554404636

Epoch: 6| Step: 7
Training loss: 2.1027212142944336
Validation loss: 3.088353192934426

Epoch: 6| Step: 8
Training loss: 3.265361785888672
Validation loss: 3.073738472436064

Epoch: 6| Step: 9
Training loss: 2.4041452407836914
Validation loss: 3.078292667224843

Epoch: 6| Step: 10
Training loss: 2.633357524871826
Validation loss: 3.054927469581686

Epoch: 6| Step: 11
Training loss: 4.502658843994141
Validation loss: 3.0343735397502942

Epoch: 6| Step: 12
Training loss: 2.2538492679595947
Validation loss: 3.01818649999557

Epoch: 6| Step: 13
Training loss: 2.222851514816284
Validation loss: 3.015823728294783

Epoch: 10| Step: 0
Training loss: 3.290623188018799
Validation loss: 3.0823727141144457

Epoch: 6| Step: 1
Training loss: 3.908735752105713
Validation loss: 3.0833143777744745

Epoch: 6| Step: 2
Training loss: 2.9103875160217285
Validation loss: 3.089758211566556

Epoch: 6| Step: 3
Training loss: 2.302257537841797
Validation loss: 3.0691274801890054

Epoch: 6| Step: 4
Training loss: 3.213817596435547
Validation loss: 3.0666179144254295

Epoch: 6| Step: 5
Training loss: 3.5684189796447754
Validation loss: 3.061781088511149

Epoch: 6| Step: 6
Training loss: 2.7576448917388916
Validation loss: 3.059981494821528

Epoch: 6| Step: 7
Training loss: 3.000988245010376
Validation loss: 3.057081973680886

Epoch: 6| Step: 8
Training loss: 3.523552894592285
Validation loss: 3.052256363694386

Epoch: 6| Step: 9
Training loss: 2.4654359817504883
Validation loss: 3.0455737113952637

Epoch: 6| Step: 10
Training loss: 3.733315944671631
Validation loss: 3.0402867742764053

Epoch: 6| Step: 11
Training loss: 2.518118381500244
Validation loss: 3.0371834385779595

Epoch: 6| Step: 12
Training loss: 2.64104962348938
Validation loss: 3.0284783071087253

Epoch: 6| Step: 13
Training loss: 4.050366401672363
Validation loss: 3.0238868908215593

Epoch: 11| Step: 0
Training loss: 3.345454692840576
Validation loss: 3.0195943642688055

Epoch: 6| Step: 1
Training loss: 3.160085678100586
Validation loss: 3.0158807205897507

Epoch: 6| Step: 2
Training loss: 3.463986396789551
Validation loss: 3.005017570270005

Epoch: 6| Step: 3
Training loss: 3.3240585327148438
Validation loss: 2.999247427909605

Epoch: 6| Step: 4
Training loss: 2.303737163543701
Validation loss: 2.995174697650376

Epoch: 6| Step: 5
Training loss: 3.0444202423095703
Validation loss: 2.9915937864652244

Epoch: 6| Step: 6
Training loss: 3.2314536571502686
Validation loss: 2.989696143775858

Epoch: 6| Step: 7
Training loss: 2.1059658527374268
Validation loss: 2.9896837306279007

Epoch: 6| Step: 8
Training loss: 3.3031747341156006
Validation loss: 2.9844267701589935

Epoch: 6| Step: 9
Training loss: 3.0608344078063965
Validation loss: 2.9914066406988327

Epoch: 6| Step: 10
Training loss: 3.103785514831543
Validation loss: 2.975321659477808

Epoch: 6| Step: 11
Training loss: 2.682981252670288
Validation loss: 2.9730202126246628

Epoch: 6| Step: 12
Training loss: 3.0829195976257324
Validation loss: 2.9728604106492895

Epoch: 6| Step: 13
Training loss: 4.036182880401611
Validation loss: 2.9692059614325084

Epoch: 12| Step: 0
Training loss: 2.7173070907592773
Validation loss: 2.9667348425875426

Epoch: 6| Step: 1
Training loss: 3.6851584911346436
Validation loss: 2.9598560102524294

Epoch: 6| Step: 2
Training loss: 2.824979782104492
Validation loss: 2.954283058002431

Epoch: 6| Step: 3
Training loss: 2.2248661518096924
Validation loss: 2.953155138159311

Epoch: 6| Step: 4
Training loss: 3.6417324542999268
Validation loss: 2.9512587619084183

Epoch: 6| Step: 5
Training loss: 2.749835968017578
Validation loss: 2.948763273095572

Epoch: 6| Step: 6
Training loss: 2.799449920654297
Validation loss: 2.9442446052387194

Epoch: 6| Step: 7
Training loss: 2.3861966133117676
Validation loss: 2.9416308915743263

Epoch: 6| Step: 8
Training loss: 2.635054111480713
Validation loss: 2.93769068871775

Epoch: 6| Step: 9
Training loss: 3.6648805141448975
Validation loss: 2.939902654258154

Epoch: 6| Step: 10
Training loss: 4.024651527404785
Validation loss: 2.9307613988076486

Epoch: 6| Step: 11
Training loss: 2.8971786499023438
Validation loss: 2.929494050241286

Epoch: 6| Step: 12
Training loss: 3.2288684844970703
Validation loss: 2.928311663289224

Epoch: 6| Step: 13
Training loss: 2.8082406520843506
Validation loss: 2.925235914927657

Epoch: 13| Step: 0
Training loss: 2.707564353942871
Validation loss: 2.922785069352837

Epoch: 6| Step: 1
Training loss: 3.582303524017334
Validation loss: 2.9185444872866393

Epoch: 6| Step: 2
Training loss: 3.9113082885742188
Validation loss: 2.913961249013101

Epoch: 6| Step: 3
Training loss: 2.45438289642334
Validation loss: 2.9115514601430585

Epoch: 6| Step: 4
Training loss: 3.1538712978363037
Validation loss: 2.9077365398406982

Epoch: 6| Step: 5
Training loss: 2.9793078899383545
Validation loss: 2.90497879059084

Epoch: 6| Step: 6
Training loss: 2.7914280891418457
Validation loss: 2.903252455496019

Epoch: 6| Step: 7
Training loss: 2.518350124359131
Validation loss: 2.8985524715915805

Epoch: 6| Step: 8
Training loss: 2.1160919666290283
Validation loss: 2.8951939408497145

Epoch: 6| Step: 9
Training loss: 3.400383949279785
Validation loss: 2.8953716062730357

Epoch: 6| Step: 10
Training loss: 3.135342597961426
Validation loss: 2.8913778617817867

Epoch: 6| Step: 11
Training loss: 2.8830652236938477
Validation loss: 2.8909507925792406

Epoch: 6| Step: 12
Training loss: 2.6760220527648926
Validation loss: 2.8891138389546382

Epoch: 6| Step: 13
Training loss: 4.267996788024902
Validation loss: 2.885672917930029

Epoch: 14| Step: 0
Training loss: 2.8673503398895264
Validation loss: 2.8841578627145417

Epoch: 6| Step: 1
Training loss: 2.6285343170166016
Validation loss: 2.884507402296989

Epoch: 6| Step: 2
Training loss: 3.2722203731536865
Validation loss: 2.8877448317825154

Epoch: 6| Step: 3
Training loss: 2.621891736984253
Validation loss: 2.879795002680953

Epoch: 6| Step: 4
Training loss: 3.3436849117279053
Validation loss: 2.875606290755733

Epoch: 6| Step: 5
Training loss: 2.0688889026641846
Validation loss: 2.8776283905070317

Epoch: 6| Step: 6
Training loss: 3.662362813949585
Validation loss: 2.8832023887224096

Epoch: 6| Step: 7
Training loss: 2.0913443565368652
Validation loss: 2.8708990876392653

Epoch: 6| Step: 8
Training loss: 3.4492757320404053
Validation loss: 2.8671820907182592

Epoch: 6| Step: 9
Training loss: 3.638643264770508
Validation loss: 2.86861260732015

Epoch: 6| Step: 10
Training loss: 2.6411099433898926
Validation loss: 2.896724836800688

Epoch: 6| Step: 11
Training loss: 3.55019474029541
Validation loss: 2.855173590362713

Epoch: 6| Step: 12
Training loss: 2.6498241424560547
Validation loss: 2.8575104026384253

Epoch: 6| Step: 13
Training loss: 3.4306323528289795
Validation loss: 2.868275893631802

Epoch: 15| Step: 0
Training loss: 3.3756117820739746
Validation loss: 2.9623940913907942

Epoch: 6| Step: 1
Training loss: 3.504368543624878
Validation loss: 3.0022362047626125

Epoch: 6| Step: 2
Training loss: 2.792865753173828
Validation loss: 2.9501136169638684

Epoch: 6| Step: 3
Training loss: 2.615006923675537
Validation loss: 2.8855526908751457

Epoch: 6| Step: 4
Training loss: 3.017333507537842
Validation loss: 2.854679475548447

Epoch: 6| Step: 5
Training loss: 2.9152698516845703
Validation loss: 2.8678324607110794

Epoch: 6| Step: 6
Training loss: 3.391371726989746
Validation loss: 2.861689039455947

Epoch: 6| Step: 7
Training loss: 2.8447699546813965
Validation loss: 2.8698115656452794

Epoch: 6| Step: 8
Training loss: 3.0319459438323975
Validation loss: 2.8963373271367883

Epoch: 6| Step: 9
Training loss: 2.7145864963531494
Validation loss: 2.8751126643150084

Epoch: 6| Step: 10
Training loss: 3.038086414337158
Validation loss: 2.866092715212094

Epoch: 6| Step: 11
Training loss: 2.7066240310668945
Validation loss: 2.8471254789701073

Epoch: 6| Step: 12
Training loss: 3.1843385696411133
Validation loss: 2.868658624669557

Epoch: 6| Step: 13
Training loss: 2.52260684967041
Validation loss: 2.882610008280764

Epoch: 16| Step: 0
Training loss: 3.6430935859680176
Validation loss: 2.8751136692621375

Epoch: 6| Step: 1
Training loss: 2.2867205142974854
Validation loss: 2.8567284922445975

Epoch: 6| Step: 2
Training loss: 2.685594320297241
Validation loss: 2.833945531998911

Epoch: 6| Step: 3
Training loss: 3.2655422687530518
Validation loss: 2.8372935992415234

Epoch: 6| Step: 4
Training loss: 2.673727512359619
Validation loss: 2.8349737069940053

Epoch: 6| Step: 5
Training loss: 3.501648187637329
Validation loss: 2.830506073531284

Epoch: 6| Step: 6
Training loss: 1.8145322799682617
Validation loss: 2.827023829183271

Epoch: 6| Step: 7
Training loss: 2.9526801109313965
Validation loss: 2.8181577985004713

Epoch: 6| Step: 8
Training loss: 3.2923521995544434
Validation loss: 2.810432295645437

Epoch: 6| Step: 9
Training loss: 3.217477560043335
Validation loss: 2.8006009876087146

Epoch: 6| Step: 10
Training loss: 2.880279302597046
Validation loss: 2.7826914197655133

Epoch: 6| Step: 11
Training loss: 3.8672571182250977
Validation loss: 2.7688195936141478

Epoch: 6| Step: 12
Training loss: 2.226905107498169
Validation loss: 2.799927334631643

Epoch: 6| Step: 13
Training loss: 2.9780561923980713
Validation loss: 2.7755442229650353

Epoch: 17| Step: 0
Training loss: 2.0309414863586426
Validation loss: 2.7483984680585962

Epoch: 6| Step: 1
Training loss: 2.5169975757598877
Validation loss: 2.7505794571292017

Epoch: 6| Step: 2
Training loss: 3.5934600830078125
Validation loss: 2.7811516766907065

Epoch: 6| Step: 3
Training loss: 2.804165840148926
Validation loss: 2.774595906657557

Epoch: 6| Step: 4
Training loss: 2.96101975440979
Validation loss: 2.75463044258856

Epoch: 6| Step: 5
Training loss: 3.102010488510132
Validation loss: 2.7442840171116654

Epoch: 6| Step: 6
Training loss: 2.8842010498046875
Validation loss: 2.7373557526578187

Epoch: 6| Step: 7
Training loss: 3.647693634033203
Validation loss: 2.734156352217479

Epoch: 6| Step: 8
Training loss: 2.551887273788452
Validation loss: 2.736323095137073

Epoch: 6| Step: 9
Training loss: 2.312338352203369
Validation loss: 2.736578513217229

Epoch: 6| Step: 10
Training loss: 3.372995376586914
Validation loss: 2.7367572963878675

Epoch: 6| Step: 11
Training loss: 3.192190170288086
Validation loss: 2.738370592876147

Epoch: 6| Step: 12
Training loss: 2.3688206672668457
Validation loss: 2.74014130971765

Epoch: 6| Step: 13
Training loss: 3.3836562633514404
Validation loss: 2.7412338256835938

Epoch: 18| Step: 0
Training loss: 3.7627058029174805
Validation loss: 2.741814354414581

Epoch: 6| Step: 1
Training loss: 3.316297769546509
Validation loss: 2.7351593817434003

Epoch: 6| Step: 2
Training loss: 1.8907941579818726
Validation loss: 2.733302418903638

Epoch: 6| Step: 3
Training loss: 1.853912353515625
Validation loss: 2.7309608459472656

Epoch: 6| Step: 4
Training loss: 2.9019811153411865
Validation loss: 2.7254608010733

Epoch: 6| Step: 5
Training loss: 2.1358299255371094
Validation loss: 2.732328217516663

Epoch: 6| Step: 6
Training loss: 3.157744884490967
Validation loss: 2.733352335550452

Epoch: 6| Step: 7
Training loss: 2.6777613162994385
Validation loss: 2.7251093567058606

Epoch: 6| Step: 8
Training loss: 2.854961395263672
Validation loss: 2.7214753089412564

Epoch: 6| Step: 9
Training loss: 3.1194472312927246
Validation loss: 2.7208996383092736

Epoch: 6| Step: 10
Training loss: 3.301909923553467
Validation loss: 2.7234638890912457

Epoch: 6| Step: 11
Training loss: 3.280087947845459
Validation loss: 2.7221305267785185

Epoch: 6| Step: 12
Training loss: 3.261563301086426
Validation loss: 2.7214350059468257

Epoch: 6| Step: 13
Training loss: 2.9846737384796143
Validation loss: 2.720832727288687

Epoch: 19| Step: 0
Training loss: 3.5577001571655273
Validation loss: 2.721468925476074

Epoch: 6| Step: 1
Training loss: 1.9998424053192139
Validation loss: 2.7181229181187128

Epoch: 6| Step: 2
Training loss: 2.063807487487793
Validation loss: 2.719062151447419

Epoch: 6| Step: 3
Training loss: 3.123276472091675
Validation loss: 2.7206619349859094

Epoch: 6| Step: 4
Training loss: 2.98492169380188
Validation loss: 2.727478124762094

Epoch: 6| Step: 5
Training loss: 3.238551139831543
Validation loss: 2.7199485225062214

Epoch: 6| Step: 6
Training loss: 2.142575979232788
Validation loss: 2.7172576048040904

Epoch: 6| Step: 7
Training loss: 3.7209572792053223
Validation loss: 2.711162369738343

Epoch: 6| Step: 8
Training loss: 1.7460367679595947
Validation loss: 2.7117018725282405

Epoch: 6| Step: 9
Training loss: 3.6256155967712402
Validation loss: 2.7096727740380073

Epoch: 6| Step: 10
Training loss: 2.9265635013580322
Validation loss: 2.7066574814499065

Epoch: 6| Step: 11
Training loss: 2.7739176750183105
Validation loss: 2.7172173659006753

Epoch: 6| Step: 12
Training loss: 3.5986061096191406
Validation loss: 2.7395019479977187

Epoch: 6| Step: 13
Training loss: 2.791851043701172
Validation loss: 2.7338285138530116

Epoch: 20| Step: 0
Training loss: 2.38240385055542
Validation loss: 2.764054500928489

Epoch: 6| Step: 1
Training loss: 2.4441919326782227
Validation loss: 2.785775948596257

Epoch: 6| Step: 2
Training loss: 2.8298635482788086
Validation loss: 2.7866685851927726

Epoch: 6| Step: 3
Training loss: 3.309812545776367
Validation loss: 2.744042137617706

Epoch: 6| Step: 4
Training loss: 1.9084184169769287
Validation loss: 2.727616053755565

Epoch: 6| Step: 5
Training loss: 3.908082962036133
Validation loss: 2.733303980160785

Epoch: 6| Step: 6
Training loss: 3.3911497592926025
Validation loss: 2.7163559647016626

Epoch: 6| Step: 7
Training loss: 2.6804754734039307
Validation loss: 2.7046457464976976

Epoch: 6| Step: 8
Training loss: 2.8988993167877197
Validation loss: 2.703962546522899

Epoch: 6| Step: 9
Training loss: 2.6569056510925293
Validation loss: 2.7077361127381683

Epoch: 6| Step: 10
Training loss: 3.567193031311035
Validation loss: 2.7191717009390555

Epoch: 6| Step: 11
Training loss: 2.90917706489563
Validation loss: 2.7479638796980663

Epoch: 6| Step: 12
Training loss: 2.8531136512756348
Validation loss: 2.7514781336630545

Epoch: 6| Step: 13
Training loss: 2.4268734455108643
Validation loss: 2.7542317708333335

Epoch: 21| Step: 0
Training loss: 2.8382585048675537
Validation loss: 2.7767372438984532

Epoch: 6| Step: 1
Training loss: 2.7307040691375732
Validation loss: 2.761505796063331

Epoch: 6| Step: 2
Training loss: 3.1219327449798584
Validation loss: 2.7532088013105493

Epoch: 6| Step: 3
Training loss: 2.78275990486145
Validation loss: 2.7293650232335573

Epoch: 6| Step: 4
Training loss: 2.761211395263672
Validation loss: 2.72329068440263

Epoch: 6| Step: 5
Training loss: 2.0228395462036133
Validation loss: 2.7155623897429435

Epoch: 6| Step: 6
Training loss: 3.4881081581115723
Validation loss: 2.704530110923193

Epoch: 6| Step: 7
Training loss: 4.259093284606934
Validation loss: 2.69647208849589

Epoch: 6| Step: 8
Training loss: 2.747544765472412
Validation loss: 2.7008333949632544

Epoch: 6| Step: 9
Training loss: 2.8765742778778076
Validation loss: 2.7017457126289286

Epoch: 6| Step: 10
Training loss: 2.9905290603637695
Validation loss: 2.7009031336794616

Epoch: 6| Step: 11
Training loss: 2.269606590270996
Validation loss: 2.7025687181821434

Epoch: 6| Step: 12
Training loss: 2.475688934326172
Validation loss: 2.705275574038106

Epoch: 6| Step: 13
Training loss: 2.948411226272583
Validation loss: 2.7038049287693475

Epoch: 22| Step: 0
Training loss: 1.8778266906738281
Validation loss: 2.6906247190249863

Epoch: 6| Step: 1
Training loss: 2.7025153636932373
Validation loss: 2.68599897046243

Epoch: 6| Step: 2
Training loss: 2.8495805263519287
Validation loss: 2.682059798189389

Epoch: 6| Step: 3
Training loss: 2.5327565670013428
Validation loss: 2.6819784154174147

Epoch: 6| Step: 4
Training loss: 2.2215356826782227
Validation loss: 2.678114975652387

Epoch: 6| Step: 5
Training loss: 3.1092753410339355
Validation loss: 2.6792022259004655

Epoch: 6| Step: 6
Training loss: 3.3755125999450684
Validation loss: 2.6908291693656676

Epoch: 6| Step: 7
Training loss: 2.7342894077301025
Validation loss: 2.7464171378843245

Epoch: 6| Step: 8
Training loss: 3.383760690689087
Validation loss: 2.771231979452154

Epoch: 6| Step: 9
Training loss: 2.9255528450012207
Validation loss: 2.7529287517711682

Epoch: 6| Step: 10
Training loss: 3.6803693771362305
Validation loss: 2.7461082191877466

Epoch: 6| Step: 11
Training loss: 3.1276750564575195
Validation loss: 2.696362410822222

Epoch: 6| Step: 12
Training loss: 2.451992988586426
Validation loss: 2.677382489686371

Epoch: 6| Step: 13
Training loss: 3.194546699523926
Validation loss: 2.6729100211974113

Epoch: 23| Step: 0
Training loss: 3.079770565032959
Validation loss: 2.6783609697895665

Epoch: 6| Step: 1
Training loss: 2.933225631713867
Validation loss: 2.686404066701089

Epoch: 6| Step: 2
Training loss: 2.485102891921997
Validation loss: 2.6841152739781204

Epoch: 6| Step: 3
Training loss: 2.611362934112549
Validation loss: 2.7130037135975336

Epoch: 6| Step: 4
Training loss: 2.7622737884521484
Validation loss: 2.7007695398023053

Epoch: 6| Step: 5
Training loss: 3.112919330596924
Validation loss: 2.6825512045173237

Epoch: 6| Step: 6
Training loss: 2.6456167697906494
Validation loss: 2.6750846678210842

Epoch: 6| Step: 7
Training loss: 2.5153470039367676
Validation loss: 2.6747918616059008

Epoch: 6| Step: 8
Training loss: 3.212183713912964
Validation loss: 2.672257051672987

Epoch: 6| Step: 9
Training loss: 3.2464847564697266
Validation loss: 2.667835843178534

Epoch: 6| Step: 10
Training loss: 2.8117213249206543
Validation loss: 2.6691989206498667

Epoch: 6| Step: 11
Training loss: 2.7155089378356934
Validation loss: 2.6671042109048493

Epoch: 6| Step: 12
Training loss: 2.6241750717163086
Validation loss: 2.6946590946566675

Epoch: 6| Step: 13
Training loss: 3.124884605407715
Validation loss: 2.718178874702864

Epoch: 24| Step: 0
Training loss: 3.203688621520996
Validation loss: 2.6827693703354045

Epoch: 6| Step: 1
Training loss: 2.5335512161254883
Validation loss: 2.6635489079260055

Epoch: 6| Step: 2
Training loss: 2.6966428756713867
Validation loss: 2.6608367325157247

Epoch: 6| Step: 3
Training loss: 2.4332637786865234
Validation loss: 2.6688059350495696

Epoch: 6| Step: 4
Training loss: 2.9710352420806885
Validation loss: 2.670148741814398

Epoch: 6| Step: 5
Training loss: 2.627924680709839
Validation loss: 2.6828379451587634

Epoch: 6| Step: 6
Training loss: 1.9620490074157715
Validation loss: 2.682582116896106

Epoch: 6| Step: 7
Training loss: 3.8504161834716797
Validation loss: 2.6784097212617115

Epoch: 6| Step: 8
Training loss: 2.846203327178955
Validation loss: 2.6724006386213404

Epoch: 6| Step: 9
Training loss: 3.588787078857422
Validation loss: 2.6629730962937876

Epoch: 6| Step: 10
Training loss: 2.6161141395568848
Validation loss: 2.65835887898681

Epoch: 6| Step: 11
Training loss: 2.9767041206359863
Validation loss: 2.666690767452281

Epoch: 6| Step: 12
Training loss: 3.441628932952881
Validation loss: 2.6751522889701267

Epoch: 6| Step: 13
Training loss: 1.4736320972442627
Validation loss: 2.6780915593588226

Epoch: 25| Step: 0
Training loss: 2.0943727493286133
Validation loss: 2.6645610383761826

Epoch: 6| Step: 1
Training loss: 3.6291403770446777
Validation loss: 2.657778150291853

Epoch: 6| Step: 2
Training loss: 3.0841119289398193
Validation loss: 2.6568802966866443

Epoch: 6| Step: 3
Training loss: 2.660848379135132
Validation loss: 2.6574134365204842

Epoch: 6| Step: 4
Training loss: 2.3556385040283203
Validation loss: 2.6713609028888006

Epoch: 6| Step: 5
Training loss: 3.028432846069336
Validation loss: 2.6658665287879204

Epoch: 6| Step: 6
Training loss: 2.3108773231506348
Validation loss: 2.669340543849494

Epoch: 6| Step: 7
Training loss: 2.8610992431640625
Validation loss: 2.6638989884366273

Epoch: 6| Step: 8
Training loss: 2.6879777908325195
Validation loss: 2.6622848433832966

Epoch: 6| Step: 9
Training loss: 2.5658154487609863
Validation loss: 2.6601708678789038

Epoch: 6| Step: 10
Training loss: 3.204806327819824
Validation loss: 2.65418739216302

Epoch: 6| Step: 11
Training loss: 3.5720696449279785
Validation loss: 2.647484976758239

Epoch: 6| Step: 12
Training loss: 2.3463258743286133
Validation loss: 2.644233306248983

Epoch: 6| Step: 13
Training loss: 3.1935412883758545
Validation loss: 2.6457208971823416

Epoch: 26| Step: 0
Training loss: 3.0722551345825195
Validation loss: 2.6438003060638264

Epoch: 6| Step: 1
Training loss: 3.2176997661590576
Validation loss: 2.6427375885748092

Epoch: 6| Step: 2
Training loss: 2.9486145973205566
Validation loss: 2.641788318593015

Epoch: 6| Step: 3
Training loss: 2.1897501945495605
Validation loss: 2.644897166118827

Epoch: 6| Step: 4
Training loss: 2.57015323638916
Validation loss: 2.6503934321864957

Epoch: 6| Step: 5
Training loss: 2.9514098167419434
Validation loss: 2.6522946691000335

Epoch: 6| Step: 6
Training loss: 2.0059404373168945
Validation loss: 2.66167252807207

Epoch: 6| Step: 7
Training loss: 3.3950514793395996
Validation loss: 2.668108594033026

Epoch: 6| Step: 8
Training loss: 2.848069190979004
Validation loss: 2.672502976591869

Epoch: 6| Step: 9
Training loss: 3.4835164546966553
Validation loss: 2.671515836510607

Epoch: 6| Step: 10
Training loss: 2.5039222240448
Validation loss: 2.6602842807769775

Epoch: 6| Step: 11
Training loss: 2.639199733734131
Validation loss: 2.649344446838543

Epoch: 6| Step: 12
Training loss: 2.6607038974761963
Validation loss: 2.6402277331198416

Epoch: 6| Step: 13
Training loss: 2.84205961227417
Validation loss: 2.6371271507714384

Epoch: 27| Step: 0
Training loss: 2.381446361541748
Validation loss: 2.635969382460399

Epoch: 6| Step: 1
Training loss: 2.319568634033203
Validation loss: 2.632389424949564

Epoch: 6| Step: 2
Training loss: 2.1585488319396973
Validation loss: 2.633428012171099

Epoch: 6| Step: 3
Training loss: 3.192918300628662
Validation loss: 2.6348492458302486

Epoch: 6| Step: 4
Training loss: 3.1992223262786865
Validation loss: 2.628429038550264

Epoch: 6| Step: 5
Training loss: 3.0381104946136475
Validation loss: 2.6325685260116414

Epoch: 6| Step: 6
Training loss: 3.141757011413574
Validation loss: 2.6358386226879653

Epoch: 6| Step: 7
Training loss: 2.7708277702331543
Validation loss: 2.631258057009789

Epoch: 6| Step: 8
Training loss: 3.019082546234131
Validation loss: 2.637780640714912

Epoch: 6| Step: 9
Training loss: 3.2272348403930664
Validation loss: 2.633242940389982

Epoch: 6| Step: 10
Training loss: 2.7458739280700684
Validation loss: 2.633877543992894

Epoch: 6| Step: 11
Training loss: 2.736485004425049
Validation loss: 2.6315630430816324

Epoch: 6| Step: 12
Training loss: 2.6100735664367676
Validation loss: 2.63213469905238

Epoch: 6| Step: 13
Training loss: 2.611793041229248
Validation loss: 2.6343210128045853

Epoch: 28| Step: 0
Training loss: 2.123980760574341
Validation loss: 2.6386205791145243

Epoch: 6| Step: 1
Training loss: 1.9110428094863892
Validation loss: 2.6509223009950373

Epoch: 6| Step: 2
Training loss: 2.801802635192871
Validation loss: 2.6587864942448114

Epoch: 6| Step: 3
Training loss: 2.7832770347595215
Validation loss: 2.6549896681180565

Epoch: 6| Step: 4
Training loss: 3.726979970932007
Validation loss: 2.6375565195596344

Epoch: 6| Step: 5
Training loss: 2.965247869491577
Validation loss: 2.6212073987530125

Epoch: 6| Step: 6
Training loss: 3.2022898197174072
Validation loss: 2.6213480657146824

Epoch: 6| Step: 7
Training loss: 3.0371665954589844
Validation loss: 2.618257625128633

Epoch: 6| Step: 8
Training loss: 3.403195858001709
Validation loss: 2.619487134359216

Epoch: 6| Step: 9
Training loss: 2.7119545936584473
Validation loss: 2.6205315538631972

Epoch: 6| Step: 10
Training loss: 1.9830291271209717
Validation loss: 2.6210723461643344

Epoch: 6| Step: 11
Training loss: 2.3314828872680664
Validation loss: 2.6185177731257614

Epoch: 6| Step: 12
Training loss: 2.766601085662842
Validation loss: 2.6159864523077525

Epoch: 6| Step: 13
Training loss: 3.744032144546509
Validation loss: 2.6233296625075804

Epoch: 29| Step: 0
Training loss: 2.0054211616516113
Validation loss: 2.621491596262942

Epoch: 6| Step: 1
Training loss: 2.8469388484954834
Validation loss: 2.6191902032462497

Epoch: 6| Step: 2
Training loss: 2.775209426879883
Validation loss: 2.617152537069013

Epoch: 6| Step: 3
Training loss: 3.1213650703430176
Validation loss: 2.611026281951576

Epoch: 6| Step: 4
Training loss: 2.8240668773651123
Validation loss: 2.613139260199762

Epoch: 6| Step: 5
Training loss: 3.9673030376434326
Validation loss: 2.6396832158488612

Epoch: 6| Step: 6
Training loss: 2.7062134742736816
Validation loss: 2.618521444259151

Epoch: 6| Step: 7
Training loss: 1.9485139846801758
Validation loss: 2.609199434198359

Epoch: 6| Step: 8
Training loss: 2.7851340770721436
Validation loss: 2.6122760234340543

Epoch: 6| Step: 9
Training loss: 2.4413394927978516
Validation loss: 2.6059911738159838

Epoch: 6| Step: 10
Training loss: 2.8969879150390625
Validation loss: 2.608108405143984

Epoch: 6| Step: 11
Training loss: 2.7064497470855713
Validation loss: 2.6056666348570134

Epoch: 6| Step: 12
Training loss: 2.868398666381836
Validation loss: 2.6043921542424027

Epoch: 6| Step: 13
Training loss: 3.2085654735565186
Validation loss: 2.600832723802136

Epoch: 30| Step: 0
Training loss: 2.5170702934265137
Validation loss: 2.6209942115250455

Epoch: 6| Step: 1
Training loss: 3.5853757858276367
Validation loss: 2.6304409247572704

Epoch: 6| Step: 2
Training loss: 2.0499439239501953
Validation loss: 2.6370476445844098

Epoch: 6| Step: 3
Training loss: 2.379661798477173
Validation loss: 2.686980842262186

Epoch: 6| Step: 4
Training loss: 2.2394111156463623
Validation loss: 2.7050831651174896

Epoch: 6| Step: 5
Training loss: 2.8574414253234863
Validation loss: 2.6924629877972346

Epoch: 6| Step: 6
Training loss: 3.2040481567382812
Validation loss: 2.632126180074548

Epoch: 6| Step: 7
Training loss: 2.875037908554077
Validation loss: 2.598782954677459

Epoch: 6| Step: 8
Training loss: 3.6951112747192383
Validation loss: 2.604615073050222

Epoch: 6| Step: 9
Training loss: 2.4287056922912598
Validation loss: 2.635637003888366

Epoch: 6| Step: 10
Training loss: 3.2477216720581055
Validation loss: 2.656449056440784

Epoch: 6| Step: 11
Training loss: 2.0488247871398926
Validation loss: 2.6761147796466784

Epoch: 6| Step: 12
Training loss: 3.1958720684051514
Validation loss: 2.71454894158148

Epoch: 6| Step: 13
Training loss: 3.4784135818481445
Validation loss: 2.714744275616061

Epoch: 31| Step: 0
Training loss: 2.878610134124756
Validation loss: 2.7049069712238927

Epoch: 6| Step: 1
Training loss: 2.4284141063690186
Validation loss: 2.6136744099278606

Epoch: 6| Step: 2
Training loss: 2.8281476497650146
Validation loss: 2.5947033615522486

Epoch: 6| Step: 3
Training loss: 3.4504637718200684
Validation loss: 2.6110829807096914

Epoch: 6| Step: 4
Training loss: 2.7750730514526367
Validation loss: 2.6831787709266908

Epoch: 6| Step: 5
Training loss: 3.2229855060577393
Validation loss: 2.8259848625429216

Epoch: 6| Step: 6
Training loss: 2.4599685668945312
Validation loss: 2.882455543805194

Epoch: 6| Step: 7
Training loss: 2.764044761657715
Validation loss: 2.8295488588271605

Epoch: 6| Step: 8
Training loss: 2.370656728744507
Validation loss: 2.7556630642183366

Epoch: 6| Step: 9
Training loss: 2.97857666015625
Validation loss: 2.6843637522830757

Epoch: 6| Step: 10
Training loss: 3.5144801139831543
Validation loss: 2.614979992630661

Epoch: 6| Step: 11
Training loss: 3.0547244548797607
Validation loss: 2.5893850685447775

Epoch: 6| Step: 12
Training loss: 2.4218010902404785
Validation loss: 2.596756021181742

Epoch: 6| Step: 13
Training loss: 2.4644932746887207
Validation loss: 2.6125088763493363

Epoch: 32| Step: 0
Training loss: 1.8044925928115845
Validation loss: 2.6245947858338714

Epoch: 6| Step: 1
Training loss: 2.7088046073913574
Validation loss: 2.6473963619560323

Epoch: 6| Step: 2
Training loss: 3.5776731967926025
Validation loss: 2.6414978017089186

Epoch: 6| Step: 3
Training loss: 3.3442118167877197
Validation loss: 2.623494827619163

Epoch: 6| Step: 4
Training loss: 2.1240079402923584
Validation loss: 2.6076727861999185

Epoch: 6| Step: 5
Training loss: 3.0244345664978027
Validation loss: 2.603809618180798

Epoch: 6| Step: 6
Training loss: 2.387467384338379
Validation loss: 2.5991215193143455

Epoch: 6| Step: 7
Training loss: 2.609389305114746
Validation loss: 2.5939701141849643

Epoch: 6| Step: 8
Training loss: 2.977529525756836
Validation loss: 2.583353796312886

Epoch: 6| Step: 9
Training loss: 2.3757543563842773
Validation loss: 2.5875052098304994

Epoch: 6| Step: 10
Training loss: 2.776244878768921
Validation loss: 2.6047338721572713

Epoch: 6| Step: 11
Training loss: 3.5408849716186523
Validation loss: 2.6132828984209286

Epoch: 6| Step: 12
Training loss: 3.51228666305542
Validation loss: 2.635494811560518

Epoch: 6| Step: 13
Training loss: 2.221261739730835
Validation loss: 2.646281667934951

Epoch: 33| Step: 0
Training loss: 3.1326966285705566
Validation loss: 2.6318048815573416

Epoch: 6| Step: 1
Training loss: 2.3930602073669434
Validation loss: 2.60710112766553

Epoch: 6| Step: 2
Training loss: 2.190045118331909
Validation loss: 2.592222172726867

Epoch: 6| Step: 3
Training loss: 2.86702823638916
Validation loss: 2.592724515545753

Epoch: 6| Step: 4
Training loss: 2.5506746768951416
Validation loss: 2.578071512201781

Epoch: 6| Step: 5
Training loss: 2.925891876220703
Validation loss: 2.570874708955006

Epoch: 6| Step: 6
Training loss: 2.4374592304229736
Validation loss: 2.5661033712407595

Epoch: 6| Step: 7
Training loss: 2.888547897338867
Validation loss: 2.57338886619896

Epoch: 6| Step: 8
Training loss: 3.1160924434661865
Validation loss: 2.588031320161717

Epoch: 6| Step: 9
Training loss: 2.896758556365967
Validation loss: 2.5715446933623283

Epoch: 6| Step: 10
Training loss: 2.0732264518737793
Validation loss: 2.564963730432654

Epoch: 6| Step: 11
Training loss: 2.7451868057250977
Validation loss: 2.5670804592870895

Epoch: 6| Step: 12
Training loss: 3.290710210800171
Validation loss: 2.5674744190708285

Epoch: 6| Step: 13
Training loss: 3.358734607696533
Validation loss: 2.5716347591851347

Epoch: 34| Step: 0
Training loss: 2.5636749267578125
Validation loss: 2.5899964045452815

Epoch: 6| Step: 1
Training loss: 2.8222270011901855
Validation loss: 2.602688835513207

Epoch: 6| Step: 2
Training loss: 2.8038978576660156
Validation loss: 2.6121072948619886

Epoch: 6| Step: 3
Training loss: 3.042219877243042
Validation loss: 2.62957061747069

Epoch: 6| Step: 4
Training loss: 2.10738468170166
Validation loss: 2.6319314818228445

Epoch: 6| Step: 5
Training loss: 2.9605002403259277
Validation loss: 2.61414828864477

Epoch: 6| Step: 6
Training loss: 2.7413439750671387
Validation loss: 2.5900182544544177

Epoch: 6| Step: 7
Training loss: 3.126474618911743
Validation loss: 2.5593727352798625

Epoch: 6| Step: 8
Training loss: 3.218528985977173
Validation loss: 2.5497796996947257

Epoch: 6| Step: 9
Training loss: 2.5915942192077637
Validation loss: 2.5481417563653763

Epoch: 6| Step: 10
Training loss: 2.284752607345581
Validation loss: 2.5456839453789497

Epoch: 6| Step: 11
Training loss: 2.984189987182617
Validation loss: 2.5492389509754796

Epoch: 6| Step: 12
Training loss: 2.85595440864563
Validation loss: 2.544348857736075

Epoch: 6| Step: 13
Training loss: 2.119574785232544
Validation loss: 2.5469475330845004

Epoch: 35| Step: 0
Training loss: 2.346506118774414
Validation loss: 2.5479343373288392

Epoch: 6| Step: 1
Training loss: 2.8783535957336426
Validation loss: 2.547847468365905

Epoch: 6| Step: 2
Training loss: 3.0402894020080566
Validation loss: 2.5509294361196537

Epoch: 6| Step: 3
Training loss: 2.18131160736084
Validation loss: 2.5459154908375075

Epoch: 6| Step: 4
Training loss: 2.7785158157348633
Validation loss: 2.551888471008629

Epoch: 6| Step: 5
Training loss: 3.246875286102295
Validation loss: 2.5465059382941133

Epoch: 6| Step: 6
Training loss: 3.018800973892212
Validation loss: 2.54601776471702

Epoch: 6| Step: 7
Training loss: 2.8037638664245605
Validation loss: 2.547341328795238

Epoch: 6| Step: 8
Training loss: 2.884744644165039
Validation loss: 2.5419762237097627

Epoch: 6| Step: 9
Training loss: 2.0656604766845703
Validation loss: 2.5458503743653655

Epoch: 6| Step: 10
Training loss: 2.3155078887939453
Validation loss: 2.5443897862588205

Epoch: 6| Step: 11
Training loss: 2.8706774711608887
Validation loss: 2.53871650080527

Epoch: 6| Step: 12
Training loss: 2.9361443519592285
Validation loss: 2.540751302114097

Epoch: 6| Step: 13
Training loss: 2.90594220161438
Validation loss: 2.5379276019270702

Epoch: 36| Step: 0
Training loss: 2.894402503967285
Validation loss: 2.5382590921976234

Epoch: 6| Step: 1
Training loss: 2.897758960723877
Validation loss: 2.5407169403568393

Epoch: 6| Step: 2
Training loss: 2.863321304321289
Validation loss: 2.5383285963407127

Epoch: 6| Step: 3
Training loss: 2.2132163047790527
Validation loss: 2.539502925770257

Epoch: 6| Step: 4
Training loss: 3.1684110164642334
Validation loss: 2.5364486171353247

Epoch: 6| Step: 5
Training loss: 3.299569606781006
Validation loss: 2.537226541067964

Epoch: 6| Step: 6
Training loss: 2.1004695892333984
Validation loss: 2.547053316588043

Epoch: 6| Step: 7
Training loss: 2.9970569610595703
Validation loss: 2.5444401182154173

Epoch: 6| Step: 8
Training loss: 2.5937857627868652
Validation loss: 2.548719129254741

Epoch: 6| Step: 9
Training loss: 2.783291816711426
Validation loss: 2.546365794315133

Epoch: 6| Step: 10
Training loss: 1.7073557376861572
Validation loss: 2.54514653195617

Epoch: 6| Step: 11
Training loss: 3.100627899169922
Validation loss: 2.5382191237582954

Epoch: 6| Step: 12
Training loss: 2.4691920280456543
Validation loss: 2.5356234632512575

Epoch: 6| Step: 13
Training loss: 3.27697491645813
Validation loss: 2.539648832813386

Epoch: 37| Step: 0
Training loss: 2.892202377319336
Validation loss: 2.5364087755962084

Epoch: 6| Step: 1
Training loss: 2.642690658569336
Validation loss: 2.5310370293996667

Epoch: 6| Step: 2
Training loss: 3.3644373416900635
Validation loss: 2.5283036334540254

Epoch: 6| Step: 3
Training loss: 2.2178754806518555
Validation loss: 2.5305564967534875

Epoch: 6| Step: 4
Training loss: 3.1644835472106934
Validation loss: 2.533952884776618

Epoch: 6| Step: 5
Training loss: 2.708509683609009
Validation loss: 2.5308063773698706

Epoch: 6| Step: 6
Training loss: 2.490731716156006
Validation loss: 2.53008024666899

Epoch: 6| Step: 7
Training loss: 3.1231460571289062
Validation loss: 2.5299349907905824

Epoch: 6| Step: 8
Training loss: 2.2212977409362793
Validation loss: 2.527257009219098

Epoch: 6| Step: 9
Training loss: 3.2435731887817383
Validation loss: 2.5303915162240305

Epoch: 6| Step: 10
Training loss: 2.6028261184692383
Validation loss: 2.5270100716621644

Epoch: 6| Step: 11
Training loss: 2.600456953048706
Validation loss: 2.5261202858340357

Epoch: 6| Step: 12
Training loss: 2.4985501766204834
Validation loss: 2.521271559499925

Epoch: 6| Step: 13
Training loss: 2.0645949840545654
Validation loss: 2.5243850549062095

Epoch: 38| Step: 0
Training loss: 3.1735103130340576
Validation loss: 2.5340907471154326

Epoch: 6| Step: 1
Training loss: 2.8326292037963867
Validation loss: 2.594277020423643

Epoch: 6| Step: 2
Training loss: 2.263096332550049
Validation loss: 2.634351243254959

Epoch: 6| Step: 3
Training loss: 2.1503939628601074
Validation loss: 2.6244246857140654

Epoch: 6| Step: 4
Training loss: 3.2195682525634766
Validation loss: 2.589550628457018

Epoch: 6| Step: 5
Training loss: 3.0710887908935547
Validation loss: 2.568794893962081

Epoch: 6| Step: 6
Training loss: 2.263277292251587
Validation loss: 2.5499605850506852

Epoch: 6| Step: 7
Training loss: 2.7730519771575928
Validation loss: 2.5374281303856963

Epoch: 6| Step: 8
Training loss: 2.7337794303894043
Validation loss: 2.5219863948001655

Epoch: 6| Step: 9
Training loss: 2.3753457069396973
Validation loss: 2.52262367228026

Epoch: 6| Step: 10
Training loss: 2.7820990085601807
Validation loss: 2.5229234362161286

Epoch: 6| Step: 11
Training loss: 3.2457144260406494
Validation loss: 2.523840001834336

Epoch: 6| Step: 12
Training loss: 1.9871792793273926
Validation loss: 2.5229075006259385

Epoch: 6| Step: 13
Training loss: 3.6116366386413574
Validation loss: 2.516838108339617

Epoch: 39| Step: 0
Training loss: 1.8519718647003174
Validation loss: 2.517250689127112

Epoch: 6| Step: 1
Training loss: 3.283205032348633
Validation loss: 2.515858240025018

Epoch: 6| Step: 2
Training loss: 3.0500025749206543
Validation loss: 2.5149346756678757

Epoch: 6| Step: 3
Training loss: 3.7049760818481445
Validation loss: 2.5166600340156147

Epoch: 6| Step: 4
Training loss: 2.371058940887451
Validation loss: 2.5153878811867005

Epoch: 6| Step: 5
Training loss: 2.181382656097412
Validation loss: 2.5104005939217022

Epoch: 6| Step: 6
Training loss: 2.868399143218994
Validation loss: 2.514647901699107

Epoch: 6| Step: 7
Training loss: 2.2040202617645264
Validation loss: 2.5144218578133533

Epoch: 6| Step: 8
Training loss: 2.5282819271087646
Validation loss: 2.5087270300875426

Epoch: 6| Step: 9
Training loss: 3.215038299560547
Validation loss: 2.5102657643697595

Epoch: 6| Step: 10
Training loss: 2.682589054107666
Validation loss: 2.51533922841472

Epoch: 6| Step: 11
Training loss: 2.4082608222961426
Validation loss: 2.523538681768602

Epoch: 6| Step: 12
Training loss: 3.098454475402832
Validation loss: 2.5307536509729203

Epoch: 6| Step: 13
Training loss: 2.29067063331604
Validation loss: 2.548100550969442

Epoch: 40| Step: 0
Training loss: 2.618422031402588
Validation loss: 2.5302831613889305

Epoch: 6| Step: 1
Training loss: 2.9285950660705566
Validation loss: 2.5502309389011835

Epoch: 6| Step: 2
Training loss: 3.4800593852996826
Validation loss: 2.577496520934566

Epoch: 6| Step: 3
Training loss: 2.481144428253174
Validation loss: 2.5366348399910876

Epoch: 6| Step: 4
Training loss: 2.557530403137207
Validation loss: 2.5169205370769707

Epoch: 6| Step: 5
Training loss: 3.0214908123016357
Validation loss: 2.5031239909510457

Epoch: 6| Step: 6
Training loss: 2.5014922618865967
Validation loss: 2.5028690984172206

Epoch: 6| Step: 7
Training loss: 2.9818007946014404
Validation loss: 2.5119360082892963

Epoch: 6| Step: 8
Training loss: 2.8682913780212402
Validation loss: 2.5226971974936863

Epoch: 6| Step: 9
Training loss: 3.251431941986084
Validation loss: 2.5347499719230075

Epoch: 6| Step: 10
Training loss: 2.665712356567383
Validation loss: 2.51846492931407

Epoch: 6| Step: 11
Training loss: 1.907243013381958
Validation loss: 2.506528592878772

Epoch: 6| Step: 12
Training loss: 2.5458977222442627
Validation loss: 2.4972541947518625

Epoch: 6| Step: 13
Training loss: 2.3944151401519775
Validation loss: 2.4983832195240963

Epoch: 41| Step: 0
Training loss: 2.5625076293945312
Validation loss: 2.5094127808847735

Epoch: 6| Step: 1
Training loss: 2.967439889907837
Validation loss: 2.5312765541897027

Epoch: 6| Step: 2
Training loss: 2.8879079818725586
Validation loss: 2.577919157602454

Epoch: 6| Step: 3
Training loss: 2.532759428024292
Validation loss: 2.6248086088447162

Epoch: 6| Step: 4
Training loss: 2.1591525077819824
Validation loss: 2.6706240254063762

Epoch: 6| Step: 5
Training loss: 3.1475353240966797
Validation loss: 2.5988556595258814

Epoch: 6| Step: 6
Training loss: 2.404386043548584
Validation loss: 2.547725236544045

Epoch: 6| Step: 7
Training loss: 2.686018466949463
Validation loss: 2.5065228503237487

Epoch: 6| Step: 8
Training loss: 2.44625186920166
Validation loss: 2.495412613755913

Epoch: 6| Step: 9
Training loss: 3.16226863861084
Validation loss: 2.492519296625609

Epoch: 6| Step: 10
Training loss: 2.7274506092071533
Validation loss: 2.4956539959035893

Epoch: 6| Step: 11
Training loss: 2.121434211730957
Validation loss: 2.5043618422682568

Epoch: 6| Step: 12
Training loss: 3.439073085784912
Validation loss: 2.5107524753898702

Epoch: 6| Step: 13
Training loss: 3.039980411529541
Validation loss: 2.5131011906490532

Epoch: 42| Step: 0
Training loss: 3.004873037338257
Validation loss: 2.5116316605639715

Epoch: 6| Step: 1
Training loss: 2.962696075439453
Validation loss: 2.508583773848831

Epoch: 6| Step: 2
Training loss: 3.0571231842041016
Validation loss: 2.498943410893922

Epoch: 6| Step: 3
Training loss: 2.309504985809326
Validation loss: 2.4959410749455935

Epoch: 6| Step: 4
Training loss: 2.5343501567840576
Validation loss: 2.489422462319815

Epoch: 6| Step: 5
Training loss: 2.6329345703125
Validation loss: 2.485479308712867

Epoch: 6| Step: 6
Training loss: 3.0438358783721924
Validation loss: 2.4920007592888287

Epoch: 6| Step: 7
Training loss: 2.5048415660858154
Validation loss: 2.493670525089387

Epoch: 6| Step: 8
Training loss: 2.957963705062866
Validation loss: 2.506362038273965

Epoch: 6| Step: 9
Training loss: 2.7328875064849854
Validation loss: 2.520770178046278

Epoch: 6| Step: 10
Training loss: 2.4703519344329834
Validation loss: 2.5280508277236775

Epoch: 6| Step: 11
Training loss: 2.2856860160827637
Validation loss: 2.5119238027962307

Epoch: 6| Step: 12
Training loss: 2.8072280883789062
Validation loss: 2.5020087970200406

Epoch: 6| Step: 13
Training loss: 2.506575345993042
Validation loss: 2.4996663267894457

Epoch: 43| Step: 0
Training loss: 3.536651849746704
Validation loss: 2.481599384738553

Epoch: 6| Step: 1
Training loss: 2.111062526702881
Validation loss: 2.481411728807675

Epoch: 6| Step: 2
Training loss: 2.1348559856414795
Validation loss: 2.4793058415894866

Epoch: 6| Step: 3
Training loss: 2.9055728912353516
Validation loss: 2.4772791759942168

Epoch: 6| Step: 4
Training loss: 2.4341773986816406
Validation loss: 2.475810638038061

Epoch: 6| Step: 5
Training loss: 3.0109457969665527
Validation loss: 2.4784744580586753

Epoch: 6| Step: 6
Training loss: 2.8275551795959473
Validation loss: 2.484738003823065

Epoch: 6| Step: 7
Training loss: 2.3286924362182617
Validation loss: 2.4967319862816924

Epoch: 6| Step: 8
Training loss: 3.3821353912353516
Validation loss: 2.5121430299615346

Epoch: 6| Step: 9
Training loss: 2.3857719898223877
Validation loss: 2.5314177748977498

Epoch: 6| Step: 10
Training loss: 2.180149555206299
Validation loss: 2.537771876140307

Epoch: 6| Step: 11
Training loss: 2.964613914489746
Validation loss: 2.5451262381768998

Epoch: 6| Step: 12
Training loss: 2.7466886043548584
Validation loss: 2.5367592047619563

Epoch: 6| Step: 13
Training loss: 2.893897533416748
Validation loss: 2.5183980900754213

Epoch: 44| Step: 0
Training loss: 3.4521005153656006
Validation loss: 2.503478296341435

Epoch: 6| Step: 1
Training loss: 3.3400731086730957
Validation loss: 2.49184400035489

Epoch: 6| Step: 2
Training loss: 2.397758960723877
Validation loss: 2.4811612893176336

Epoch: 6| Step: 3
Training loss: 2.501384735107422
Validation loss: 2.4807104282481696

Epoch: 6| Step: 4
Training loss: 2.278981924057007
Validation loss: 2.4758662946762575

Epoch: 6| Step: 5
Training loss: 2.429657459259033
Validation loss: 2.4811825854803926

Epoch: 6| Step: 6
Training loss: 1.62416672706604
Validation loss: 2.495140560211674

Epoch: 6| Step: 7
Training loss: 2.870116710662842
Validation loss: 2.5161331827922533

Epoch: 6| Step: 8
Training loss: 2.9633090496063232
Validation loss: 2.513331392759918

Epoch: 6| Step: 9
Training loss: 2.98065185546875
Validation loss: 2.4939838635024203

Epoch: 6| Step: 10
Training loss: 2.4169766902923584
Validation loss: 2.4850053377048944

Epoch: 6| Step: 11
Training loss: 2.2633228302001953
Validation loss: 2.4814482196684806

Epoch: 6| Step: 12
Training loss: 3.3828516006469727
Validation loss: 2.474207898621918

Epoch: 6| Step: 13
Training loss: 3.1366567611694336
Validation loss: 2.4822072341877925

Epoch: 45| Step: 0
Training loss: 2.53552508354187
Validation loss: 2.4829342262719267

Epoch: 6| Step: 1
Training loss: 2.075404167175293
Validation loss: 2.471468292256837

Epoch: 6| Step: 2
Training loss: 2.182495355606079
Validation loss: 2.4765619129262944

Epoch: 6| Step: 3
Training loss: 3.0855205059051514
Validation loss: 2.485860593857304

Epoch: 6| Step: 4
Training loss: 3.1622519493103027
Validation loss: 2.4965650099580006

Epoch: 6| Step: 5
Training loss: 2.2250664234161377
Validation loss: 2.4967210933726323

Epoch: 6| Step: 6
Training loss: 2.517393112182617
Validation loss: 2.5000236213848157

Epoch: 6| Step: 7
Training loss: 2.4593687057495117
Validation loss: 2.4990657606432514

Epoch: 6| Step: 8
Training loss: 3.442229747772217
Validation loss: 2.5028918020186888

Epoch: 6| Step: 9
Training loss: 2.9456586837768555
Validation loss: 2.5102227887799664

Epoch: 6| Step: 10
Training loss: 2.9075369834899902
Validation loss: 2.509650230407715

Epoch: 6| Step: 11
Training loss: 2.388327121734619
Validation loss: 2.495785126122095

Epoch: 6| Step: 12
Training loss: 2.5474371910095215
Validation loss: 2.4820545924607145

Epoch: 6| Step: 13
Training loss: 3.739985942840576
Validation loss: 2.472040889083698

Epoch: 46| Step: 0
Training loss: 2.7125229835510254
Validation loss: 2.4735993031532533

Epoch: 6| Step: 1
Training loss: 2.460272789001465
Validation loss: 2.4658905511261313

Epoch: 6| Step: 2
Training loss: 2.3821940422058105
Validation loss: 2.4619409653448288

Epoch: 6| Step: 3
Training loss: 2.519390106201172
Validation loss: 2.4680084028551654

Epoch: 6| Step: 4
Training loss: 3.1524596214294434
Validation loss: 2.4750948106088946

Epoch: 6| Step: 5
Training loss: 2.6897473335266113
Validation loss: 2.4983189900716147

Epoch: 6| Step: 6
Training loss: 2.3909671306610107
Validation loss: 2.4978219950070946

Epoch: 6| Step: 7
Training loss: 2.43208646774292
Validation loss: 2.495000364959881

Epoch: 6| Step: 8
Training loss: 3.169299602508545
Validation loss: 2.4961456124500563

Epoch: 6| Step: 9
Training loss: 2.6584830284118652
Validation loss: 2.494237881834789

Epoch: 6| Step: 10
Training loss: 1.3530409336090088
Validation loss: 2.493449616175826

Epoch: 6| Step: 11
Training loss: 3.9636740684509277
Validation loss: 2.496547260592061

Epoch: 6| Step: 12
Training loss: 2.493778705596924
Validation loss: 2.4986199255912536

Epoch: 6| Step: 13
Training loss: 3.7988204956054688
Validation loss: 2.506044528817618

Epoch: 47| Step: 0
Training loss: 1.9636002779006958
Validation loss: 2.5054782718740483

Epoch: 6| Step: 1
Training loss: 2.068429946899414
Validation loss: 2.510726087836809

Epoch: 6| Step: 2
Training loss: 2.387985944747925
Validation loss: 2.5122735936154603

Epoch: 6| Step: 3
Training loss: 2.8140006065368652
Validation loss: 2.503446461052023

Epoch: 6| Step: 4
Training loss: 3.1272435188293457
Validation loss: 2.4982895774226033

Epoch: 6| Step: 5
Training loss: 2.5950987339019775
Validation loss: 2.4941505437256186

Epoch: 6| Step: 6
Training loss: 2.627864360809326
Validation loss: 2.492349640015633

Epoch: 6| Step: 7
Training loss: 3.0530686378479004
Validation loss: 2.5027709827628186

Epoch: 6| Step: 8
Training loss: 2.696178436279297
Validation loss: 2.5064295773865073

Epoch: 6| Step: 9
Training loss: 2.620560646057129
Validation loss: 2.512805820793234

Epoch: 6| Step: 10
Training loss: 3.0735044479370117
Validation loss: 2.52507879144402

Epoch: 6| Step: 11
Training loss: 3.2335305213928223
Validation loss: 2.5261442917649464

Epoch: 6| Step: 12
Training loss: 2.868533134460449
Validation loss: 2.5126552761241956

Epoch: 6| Step: 13
Training loss: 2.970118761062622
Validation loss: 2.497803052266439

Epoch: 48| Step: 0
Training loss: 2.582040309906006
Validation loss: 2.494790695046866

Epoch: 6| Step: 1
Training loss: 2.868992328643799
Validation loss: 2.4886796653911634

Epoch: 6| Step: 2
Training loss: 3.1555001735687256
Validation loss: 2.482895105115829

Epoch: 6| Step: 3
Training loss: 3.5259077548980713
Validation loss: 2.4900200161882626

Epoch: 6| Step: 4
Training loss: 3.171339511871338
Validation loss: 2.4934248129526773

Epoch: 6| Step: 5
Training loss: 2.3386125564575195
Validation loss: 2.495592583892166

Epoch: 6| Step: 6
Training loss: 2.9121439456939697
Validation loss: 2.4980901620721303

Epoch: 6| Step: 7
Training loss: 2.2823686599731445
Validation loss: 2.5028881103761735

Epoch: 6| Step: 8
Training loss: 2.5518112182617188
Validation loss: 2.500616681191229

Epoch: 6| Step: 9
Training loss: 2.611823081970215
Validation loss: 2.5029664475430726

Epoch: 6| Step: 10
Training loss: 2.1891303062438965
Validation loss: 2.5090107943422053

Epoch: 6| Step: 11
Training loss: 2.4236438274383545
Validation loss: 2.5095739774806525

Epoch: 6| Step: 12
Training loss: 2.2403831481933594
Validation loss: 2.4955010773033224

Epoch: 6| Step: 13
Training loss: 3.0646579265594482
Validation loss: 2.497352025842154

Epoch: 49| Step: 0
Training loss: 2.943617820739746
Validation loss: 2.484223235038019

Epoch: 6| Step: 1
Training loss: 2.2686100006103516
Validation loss: 2.4617689886400775

Epoch: 6| Step: 2
Training loss: 3.199428081512451
Validation loss: 2.4478811064074115

Epoch: 6| Step: 3
Training loss: 2.4516358375549316
Validation loss: 2.4446935064049176

Epoch: 6| Step: 4
Training loss: 2.345144033432007
Validation loss: 2.4434729058255433

Epoch: 6| Step: 5
Training loss: 2.3132717609405518
Validation loss: 2.4441711928254817

Epoch: 6| Step: 6
Training loss: 3.409809112548828
Validation loss: 2.4442996901850544

Epoch: 6| Step: 7
Training loss: 1.6509480476379395
Validation loss: 2.4357753915171467

Epoch: 6| Step: 8
Training loss: 2.8284244537353516
Validation loss: 2.4301043710400982

Epoch: 6| Step: 9
Training loss: 1.7514772415161133
Validation loss: 2.431852125352429

Epoch: 6| Step: 10
Training loss: 2.9803638458251953
Validation loss: 2.4328516606361634

Epoch: 6| Step: 11
Training loss: 3.7258214950561523
Validation loss: 2.448903624729444

Epoch: 6| Step: 12
Training loss: 3.2199501991271973
Validation loss: 2.464633580177061

Epoch: 6| Step: 13
Training loss: 2.115314245223999
Validation loss: 2.47607183840967

Epoch: 50| Step: 0
Training loss: 2.796435594558716
Validation loss: 2.489071828062816

Epoch: 6| Step: 1
Training loss: 2.9441750049591064
Validation loss: 2.502912505980461

Epoch: 6| Step: 2
Training loss: 2.6032817363739014
Validation loss: 2.4961049915641866

Epoch: 6| Step: 3
Training loss: 2.522631883621216
Validation loss: 2.4908044697136007

Epoch: 6| Step: 4
Training loss: 2.337082862854004
Validation loss: 2.4845855774418

Epoch: 6| Step: 5
Training loss: 2.1816108226776123
Validation loss: 2.4613039596106416

Epoch: 6| Step: 6
Training loss: 2.891447067260742
Validation loss: 2.45028870080107

Epoch: 6| Step: 7
Training loss: 2.860599994659424
Validation loss: 2.4371991054986113

Epoch: 6| Step: 8
Training loss: 2.6454973220825195
Validation loss: 2.4215423817275674

Epoch: 6| Step: 9
Training loss: 2.638946056365967
Validation loss: 2.4373086524266068

Epoch: 6| Step: 10
Training loss: 2.759766101837158
Validation loss: 2.438788024328088

Epoch: 6| Step: 11
Training loss: 2.920163631439209
Validation loss: 2.4482102445376817

Epoch: 6| Step: 12
Training loss: 2.77254319190979
Validation loss: 2.451247376780356

Epoch: 6| Step: 13
Training loss: 2.3142316341400146
Validation loss: 2.4553818138696815

Epoch: 51| Step: 0
Training loss: 2.5305867195129395
Validation loss: 2.478775721724315

Epoch: 6| Step: 1
Training loss: 1.892444133758545
Validation loss: 2.4818191528320312

Epoch: 6| Step: 2
Training loss: 3.052652597427368
Validation loss: 2.477825459613595

Epoch: 6| Step: 3
Training loss: 2.1465659141540527
Validation loss: 2.449375549952189

Epoch: 6| Step: 4
Training loss: 2.7363579273223877
Validation loss: 2.4420636007862706

Epoch: 6| Step: 5
Training loss: 1.9982542991638184
Validation loss: 2.4379662236859723

Epoch: 6| Step: 6
Training loss: 3.1647515296936035
Validation loss: 2.4435582801859868

Epoch: 6| Step: 7
Training loss: 2.1806318759918213
Validation loss: 2.434425884677518

Epoch: 6| Step: 8
Training loss: 2.5836093425750732
Validation loss: 2.429271754398141

Epoch: 6| Step: 9
Training loss: 3.1431055068969727
Validation loss: 2.43095164914285

Epoch: 6| Step: 10
Training loss: 2.6482882499694824
Validation loss: 2.43294374404415

Epoch: 6| Step: 11
Training loss: 2.643486499786377
Validation loss: 2.429937299861703

Epoch: 6| Step: 12
Training loss: 3.586423397064209
Validation loss: 2.4363706496454056

Epoch: 6| Step: 13
Training loss: 3.339768409729004
Validation loss: 2.4242626287603892

Epoch: 52| Step: 0
Training loss: 2.3121752738952637
Validation loss: 2.420675123891523

Epoch: 6| Step: 1
Training loss: 2.7504892349243164
Validation loss: 2.418676835234447

Epoch: 6| Step: 2
Training loss: 3.1101505756378174
Validation loss: 2.4250234224463023

Epoch: 6| Step: 3
Training loss: 2.298807382583618
Validation loss: 2.4231266616493143

Epoch: 6| Step: 4
Training loss: 2.5123748779296875
Validation loss: 2.422613525903353

Epoch: 6| Step: 5
Training loss: 2.477344512939453
Validation loss: 2.419721003501646

Epoch: 6| Step: 6
Training loss: 2.259763240814209
Validation loss: 2.41616730536184

Epoch: 6| Step: 7
Training loss: 3.1735284328460693
Validation loss: 2.414162430711972

Epoch: 6| Step: 8
Training loss: 2.64817476272583
Validation loss: 2.415068334148776

Epoch: 6| Step: 9
Training loss: 2.39241886138916
Validation loss: 2.4092395459451983

Epoch: 6| Step: 10
Training loss: 2.8420586585998535
Validation loss: 2.4094446218141945

Epoch: 6| Step: 11
Training loss: 2.3682901859283447
Validation loss: 2.4092048598874

Epoch: 6| Step: 12
Training loss: 3.146855354309082
Validation loss: 2.4083583431859172

Epoch: 6| Step: 13
Training loss: 3.264090061187744
Validation loss: 2.414376856178366

Epoch: 53| Step: 0
Training loss: 2.393584728240967
Validation loss: 2.417442916541971

Epoch: 6| Step: 1
Training loss: 2.508413314819336
Validation loss: 2.432609368396062

Epoch: 6| Step: 2
Training loss: 2.7042436599731445
Validation loss: 2.427607579897809

Epoch: 6| Step: 3
Training loss: 2.647597074508667
Validation loss: 2.424411540390343

Epoch: 6| Step: 4
Training loss: 2.024444818496704
Validation loss: 2.4287707754360732

Epoch: 6| Step: 5
Training loss: 3.374915838241577
Validation loss: 2.4205286579747356

Epoch: 6| Step: 6
Training loss: 2.594916820526123
Validation loss: 2.4128695200848322

Epoch: 6| Step: 7
Training loss: 2.5380687713623047
Validation loss: 2.410214344660441

Epoch: 6| Step: 8
Training loss: 2.86444091796875
Validation loss: 2.4062745340408815

Epoch: 6| Step: 9
Training loss: 2.8141136169433594
Validation loss: 2.4039522242802445

Epoch: 6| Step: 10
Training loss: 3.3254294395446777
Validation loss: 2.4055635929107666

Epoch: 6| Step: 11
Training loss: 2.0382862091064453
Validation loss: 2.406670570373535

Epoch: 6| Step: 12
Training loss: 2.72029447555542
Validation loss: 2.4030949172153266

Epoch: 6| Step: 13
Training loss: 2.594968795776367
Validation loss: 2.4026875060091735

Epoch: 54| Step: 0
Training loss: 2.0766983032226562
Validation loss: 2.4027042030006327

Epoch: 6| Step: 1
Training loss: 3.2136003971099854
Validation loss: 2.4038397266018774

Epoch: 6| Step: 2
Training loss: 3.1278703212738037
Validation loss: 2.4069930866200435

Epoch: 6| Step: 3
Training loss: 3.1035189628601074
Validation loss: 2.405725391962195

Epoch: 6| Step: 4
Training loss: 2.3104095458984375
Validation loss: 2.4067673657530095

Epoch: 6| Step: 5
Training loss: 2.9107632637023926
Validation loss: 2.4052669079073015

Epoch: 6| Step: 6
Training loss: 2.2817704677581787
Validation loss: 2.404000133596441

Epoch: 6| Step: 7
Training loss: 2.132528781890869
Validation loss: 2.414732789480558

Epoch: 6| Step: 8
Training loss: 3.074023723602295
Validation loss: 2.4303084804165747

Epoch: 6| Step: 9
Training loss: 2.1701903343200684
Validation loss: 2.4336394135669996

Epoch: 6| Step: 10
Training loss: 2.3621749877929688
Validation loss: 2.4610412736092844

Epoch: 6| Step: 11
Training loss: 2.7150864601135254
Validation loss: 2.467410182440153

Epoch: 6| Step: 12
Training loss: 3.3133151531219482
Validation loss: 2.46762518472569

Epoch: 6| Step: 13
Training loss: 2.066122531890869
Validation loss: 2.4365764023155294

Epoch: 55| Step: 0
Training loss: 2.294351816177368
Validation loss: 2.4136809097823275

Epoch: 6| Step: 1
Training loss: 3.479098320007324
Validation loss: 2.4040334942520305

Epoch: 6| Step: 2
Training loss: 2.1769678592681885
Validation loss: 2.396931903336638

Epoch: 6| Step: 3
Training loss: 2.887343406677246
Validation loss: 2.3998630482663392

Epoch: 6| Step: 4
Training loss: 2.3058502674102783
Validation loss: 2.406398998793735

Epoch: 6| Step: 5
Training loss: 3.192615509033203
Validation loss: 2.4100130886159916

Epoch: 6| Step: 6
Training loss: 2.6340155601501465
Validation loss: 2.4113105112506497

Epoch: 6| Step: 7
Training loss: 2.2975306510925293
Validation loss: 2.4145529603445404

Epoch: 6| Step: 8
Training loss: 3.475099563598633
Validation loss: 2.4152961751466155

Epoch: 6| Step: 9
Training loss: 2.3410441875457764
Validation loss: 2.4164119689695296

Epoch: 6| Step: 10
Training loss: 2.784923553466797
Validation loss: 2.417009761256556

Epoch: 6| Step: 11
Training loss: 2.464902400970459
Validation loss: 2.412829837491435

Epoch: 6| Step: 12
Training loss: 2.626532554626465
Validation loss: 2.40646090046052

Epoch: 6| Step: 13
Training loss: 1.8326570987701416
Validation loss: 2.4008222433828537

Epoch: 56| Step: 0
Training loss: 3.16147518157959
Validation loss: 2.395721204819218

Epoch: 6| Step: 1
Training loss: 2.1329071521759033
Validation loss: 2.389679011478219

Epoch: 6| Step: 2
Training loss: 2.881963014602661
Validation loss: 2.3857176137226883

Epoch: 6| Step: 3
Training loss: 2.240135669708252
Validation loss: 2.390990634118357

Epoch: 6| Step: 4
Training loss: 3.0197198390960693
Validation loss: 2.40005160403508

Epoch: 6| Step: 5
Training loss: 2.9979867935180664
Validation loss: 2.4026664277558685

Epoch: 6| Step: 6
Training loss: 2.611213207244873
Validation loss: 2.413887693035987

Epoch: 6| Step: 7
Training loss: 2.173689126968384
Validation loss: 2.4144159183707288

Epoch: 6| Step: 8
Training loss: 3.0358715057373047
Validation loss: 2.4481324790626444

Epoch: 6| Step: 9
Training loss: 2.517526388168335
Validation loss: 2.471206436875046

Epoch: 6| Step: 10
Training loss: 2.251432418823242
Validation loss: 2.4685306497799453

Epoch: 6| Step: 11
Training loss: 2.7946853637695312
Validation loss: 2.4614876777895036

Epoch: 6| Step: 12
Training loss: 2.5447540283203125
Validation loss: 2.4415703563280005

Epoch: 6| Step: 13
Training loss: 2.822377920150757
Validation loss: 2.4126950899759927

Epoch: 57| Step: 0
Training loss: 3.0815834999084473
Validation loss: 2.4046313352482294

Epoch: 6| Step: 1
Training loss: 2.1544101238250732
Validation loss: 2.3910384639616935

Epoch: 6| Step: 2
Training loss: 2.725353240966797
Validation loss: 2.388680704178349

Epoch: 6| Step: 3
Training loss: 2.429205894470215
Validation loss: 2.378303332995343

Epoch: 6| Step: 4
Training loss: 2.7655704021453857
Validation loss: 2.3877273016078497

Epoch: 6| Step: 5
Training loss: 2.5210158824920654
Validation loss: 2.386927191929151

Epoch: 6| Step: 6
Training loss: 2.550623655319214
Validation loss: 2.3876447267429803

Epoch: 6| Step: 7
Training loss: 3.112028121948242
Validation loss: 2.3822964878492456

Epoch: 6| Step: 8
Training loss: 2.9063477516174316
Validation loss: 2.384038504733834

Epoch: 6| Step: 9
Training loss: 2.1732516288757324
Validation loss: 2.3831011787537606

Epoch: 6| Step: 10
Training loss: 2.056387186050415
Validation loss: 2.383947954382948

Epoch: 6| Step: 11
Training loss: 2.672743558883667
Validation loss: 2.388904474114859

Epoch: 6| Step: 12
Training loss: 3.0225203037261963
Validation loss: 2.3888931556414534

Epoch: 6| Step: 13
Training loss: 2.9884185791015625
Validation loss: 2.4005733331044516

Epoch: 58| Step: 0
Training loss: 1.8753674030303955
Validation loss: 2.401442197061354

Epoch: 6| Step: 1
Training loss: 3.124074935913086
Validation loss: 2.3957547013477614

Epoch: 6| Step: 2
Training loss: 2.2975783348083496
Validation loss: 2.3995443723535024

Epoch: 6| Step: 3
Training loss: 2.5135490894317627
Validation loss: 2.396128349406745

Epoch: 6| Step: 4
Training loss: 2.569758415222168
Validation loss: 2.3912608162049325

Epoch: 6| Step: 5
Training loss: 3.068326234817505
Validation loss: 2.3851922558199976

Epoch: 6| Step: 6
Training loss: 2.776571035385132
Validation loss: 2.39178131985408

Epoch: 6| Step: 7
Training loss: 2.896108627319336
Validation loss: 2.3868390770368677

Epoch: 6| Step: 8
Training loss: 2.7355878353118896
Validation loss: 2.389869346413561

Epoch: 6| Step: 9
Training loss: 2.1782636642456055
Validation loss: 2.3892882511179936

Epoch: 6| Step: 10
Training loss: 3.0228209495544434
Validation loss: 2.389409929193476

Epoch: 6| Step: 11
Training loss: 2.2796831130981445
Validation loss: 2.3872973124186196

Epoch: 6| Step: 12
Training loss: 2.6444051265716553
Validation loss: 2.3924830523870324

Epoch: 6| Step: 13
Training loss: 2.8980047702789307
Validation loss: 2.382518122273107

Epoch: 59| Step: 0
Training loss: 2.3926589488983154
Validation loss: 2.380078569535286

Epoch: 6| Step: 1
Training loss: 2.7408742904663086
Validation loss: 2.377435653440414

Epoch: 6| Step: 2
Training loss: 2.191871166229248
Validation loss: 2.3822568924196306

Epoch: 6| Step: 3
Training loss: 3.2310428619384766
Validation loss: 2.3791454299803703

Epoch: 6| Step: 4
Training loss: 2.7921743392944336
Validation loss: 2.3811072123947965

Epoch: 6| Step: 5
Training loss: 2.5459625720977783
Validation loss: 2.386101153589064

Epoch: 6| Step: 6
Training loss: 2.376368522644043
Validation loss: 2.393580819970818

Epoch: 6| Step: 7
Training loss: 2.273089647293091
Validation loss: 2.38543539918879

Epoch: 6| Step: 8
Training loss: 2.716519832611084
Validation loss: 2.3837793796293196

Epoch: 6| Step: 9
Training loss: 3.154001235961914
Validation loss: 2.389454969795801

Epoch: 6| Step: 10
Training loss: 2.2975780963897705
Validation loss: 2.3858808240582867

Epoch: 6| Step: 11
Training loss: 2.635266065597534
Validation loss: 2.3885528733653407

Epoch: 6| Step: 12
Training loss: 2.502647638320923
Validation loss: 2.3805792203513523

Epoch: 6| Step: 13
Training loss: 3.1632707118988037
Validation loss: 2.383999614305394

Epoch: 60| Step: 0
Training loss: 2.856537342071533
Validation loss: 2.3869139404707056

Epoch: 6| Step: 1
Training loss: 2.9325973987579346
Validation loss: 2.3899764937739216

Epoch: 6| Step: 2
Training loss: 3.073559284210205
Validation loss: 2.3980190779573176

Epoch: 6| Step: 3
Training loss: 1.8533008098602295
Validation loss: 2.406987738865678

Epoch: 6| Step: 4
Training loss: 2.6422343254089355
Validation loss: 2.4010260335860716

Epoch: 6| Step: 5
Training loss: 2.8012075424194336
Validation loss: 2.391476123563705

Epoch: 6| Step: 6
Training loss: 2.461333751678467
Validation loss: 2.3830173015594482

Epoch: 6| Step: 7
Training loss: 2.1627347469329834
Validation loss: 2.385226764986592

Epoch: 6| Step: 8
Training loss: 2.587862968444824
Validation loss: 2.3730825634412867

Epoch: 6| Step: 9
Training loss: 2.627589225769043
Validation loss: 2.3744645990351194

Epoch: 6| Step: 10
Training loss: 2.7627129554748535
Validation loss: 2.3651038677461687

Epoch: 6| Step: 11
Training loss: 2.856375217437744
Validation loss: 2.366545472093808

Epoch: 6| Step: 12
Training loss: 2.0994253158569336
Validation loss: 2.3692887290831535

Epoch: 6| Step: 13
Training loss: 3.3540055751800537
Validation loss: 2.3764714784519647

Epoch: 61| Step: 0
Training loss: 2.8662431240081787
Validation loss: 2.3841609916379376

Epoch: 6| Step: 1
Training loss: 2.8045363426208496
Validation loss: 2.3822245892658027

Epoch: 6| Step: 2
Training loss: 2.7022480964660645
Validation loss: 2.3850686524503972

Epoch: 6| Step: 3
Training loss: 2.7582623958587646
Validation loss: 2.3807348897380214

Epoch: 6| Step: 4
Training loss: 2.7536816596984863
Validation loss: 2.3753518442953787

Epoch: 6| Step: 5
Training loss: 2.089578628540039
Validation loss: 2.3600027586824153

Epoch: 6| Step: 6
Training loss: 2.6780107021331787
Validation loss: 2.3668584413425897

Epoch: 6| Step: 7
Training loss: 2.724618911743164
Validation loss: 2.3638090984795683

Epoch: 6| Step: 8
Training loss: 2.81356143951416
Validation loss: 2.3613003210354875

Epoch: 6| Step: 9
Training loss: 2.756039619445801
Validation loss: 2.360951920991303

Epoch: 6| Step: 10
Training loss: 2.335461139678955
Validation loss: 2.357220019063642

Epoch: 6| Step: 11
Training loss: 2.4122138023376465
Validation loss: 2.3718912832198606

Epoch: 6| Step: 12
Training loss: 1.7052961587905884
Validation loss: 2.3861708359051774

Epoch: 6| Step: 13
Training loss: 3.731306791305542
Validation loss: 2.4124364904178086

Epoch: 62| Step: 0
Training loss: 3.4697394371032715
Validation loss: 2.4388775517863612

Epoch: 6| Step: 1
Training loss: 2.6685752868652344
Validation loss: 2.4279644950743644

Epoch: 6| Step: 2
Training loss: 2.204134464263916
Validation loss: 2.390694902789208

Epoch: 6| Step: 3
Training loss: 2.4720864295959473
Validation loss: 2.3551386633226947

Epoch: 6| Step: 4
Training loss: 2.9298911094665527
Validation loss: 2.3521619278897523

Epoch: 6| Step: 5
Training loss: 2.3518307209014893
Validation loss: 2.369477289979176

Epoch: 6| Step: 6
Training loss: 2.683398723602295
Validation loss: 2.3996197151881393

Epoch: 6| Step: 7
Training loss: 3.368217945098877
Validation loss: 2.4352799359188286

Epoch: 6| Step: 8
Training loss: 2.584038734436035
Validation loss: 2.4386258099668767

Epoch: 6| Step: 9
Training loss: 2.527703285217285
Validation loss: 2.429408779708288

Epoch: 6| Step: 10
Training loss: 3.5279715061187744
Validation loss: 2.4552412007444646

Epoch: 6| Step: 11
Training loss: 2.4851980209350586
Validation loss: 2.410330121235181

Epoch: 6| Step: 12
Training loss: 2.2712552547454834
Validation loss: 2.3735872391731507

Epoch: 6| Step: 13
Training loss: 2.0775270462036133
Validation loss: 2.3632837239132134

Epoch: 63| Step: 0
Training loss: 2.297403573989868
Validation loss: 2.3727413351817797

Epoch: 6| Step: 1
Training loss: 3.5400679111480713
Validation loss: 2.4284821941006567

Epoch: 6| Step: 2
Training loss: 3.0741047859191895
Validation loss: 2.4819013431508052

Epoch: 6| Step: 3
Training loss: 2.226323127746582
Validation loss: 2.5241887877064366

Epoch: 6| Step: 4
Training loss: 2.180436134338379
Validation loss: 2.481713746183662

Epoch: 6| Step: 5
Training loss: 2.47586989402771
Validation loss: 2.4303244954796246

Epoch: 6| Step: 6
Training loss: 2.5718233585357666
Validation loss: 2.4044572627672585

Epoch: 6| Step: 7
Training loss: 2.563621997833252
Validation loss: 2.3775244169337775

Epoch: 6| Step: 8
Training loss: 2.358685255050659
Validation loss: 2.3640035916400213

Epoch: 6| Step: 9
Training loss: 3.15692138671875
Validation loss: 2.356932327311526

Epoch: 6| Step: 10
Training loss: 2.642090082168579
Validation loss: 2.3448363863011843

Epoch: 6| Step: 11
Training loss: 2.437739372253418
Validation loss: 2.339443042714109

Epoch: 6| Step: 12
Training loss: 2.9425857067108154
Validation loss: 2.3426364788445095

Epoch: 6| Step: 13
Training loss: 1.7142307758331299
Validation loss: 2.3320628032889417

Epoch: 64| Step: 0
Training loss: 2.374713897705078
Validation loss: 2.337935104165026

Epoch: 6| Step: 1
Training loss: 2.864060878753662
Validation loss: 2.383890054559195

Epoch: 6| Step: 2
Training loss: 2.3984534740448
Validation loss: 2.4277183625005905

Epoch: 6| Step: 3
Training loss: 2.4705252647399902
Validation loss: 2.497480771874869

Epoch: 6| Step: 4
Training loss: 2.856924057006836
Validation loss: 2.476074908369331

Epoch: 6| Step: 5
Training loss: 2.8607804775238037
Validation loss: 2.4094051212392826

Epoch: 6| Step: 6
Training loss: 2.0343308448791504
Validation loss: 2.3656388226375786

Epoch: 6| Step: 7
Training loss: 3.4661786556243896
Validation loss: 2.3572831102596816

Epoch: 6| Step: 8
Training loss: 2.0101046562194824
Validation loss: 2.3591624690640356

Epoch: 6| Step: 9
Training loss: 2.598220109939575
Validation loss: 2.3763391689587663

Epoch: 6| Step: 10
Training loss: 2.7953715324401855
Validation loss: 2.3788755862943587

Epoch: 6| Step: 11
Training loss: 2.990422487258911
Validation loss: 2.357668953557168

Epoch: 6| Step: 12
Training loss: 2.547743082046509
Validation loss: 2.3400196080566733

Epoch: 6| Step: 13
Training loss: 2.227412700653076
Validation loss: 2.334233997970499

Epoch: 65| Step: 0
Training loss: 2.403797149658203
Validation loss: 2.3256250453251663

Epoch: 6| Step: 1
Training loss: 2.8990087509155273
Validation loss: 2.3210483417716077

Epoch: 6| Step: 2
Training loss: 2.3978705406188965
Validation loss: 2.3225498507099767

Epoch: 6| Step: 3
Training loss: 1.8934099674224854
Validation loss: 2.3246041241512505

Epoch: 6| Step: 4
Training loss: 3.221470832824707
Validation loss: 2.338330945660991

Epoch: 6| Step: 5
Training loss: 3.4766807556152344
Validation loss: 2.368755180348632

Epoch: 6| Step: 6
Training loss: 2.553297519683838
Validation loss: 2.3768173545919438

Epoch: 6| Step: 7
Training loss: 3.1171233654022217
Validation loss: 2.3697855036745787

Epoch: 6| Step: 8
Training loss: 2.983366012573242
Validation loss: 2.3588224457156275

Epoch: 6| Step: 9
Training loss: 2.462630271911621
Validation loss: 2.338217514817433

Epoch: 6| Step: 10
Training loss: 1.9071557521820068
Validation loss: 2.3239960542289158

Epoch: 6| Step: 11
Training loss: 2.3173413276672363
Validation loss: 2.3218267451050463

Epoch: 6| Step: 12
Training loss: 2.3492493629455566
Validation loss: 2.329714341830182

Epoch: 6| Step: 13
Training loss: 2.3277697563171387
Validation loss: 2.313985452857069

Epoch: 66| Step: 0
Training loss: 2.476012706756592
Validation loss: 2.306252864099318

Epoch: 6| Step: 1
Training loss: 2.424332618713379
Validation loss: 2.3027487749694497

Epoch: 6| Step: 2
Training loss: 2.2443370819091797
Validation loss: 2.3000409526209675

Epoch: 6| Step: 3
Training loss: 2.7212278842926025
Validation loss: 2.304896295711558

Epoch: 6| Step: 4
Training loss: 2.8130998611450195
Validation loss: 2.317178536486882

Epoch: 6| Step: 5
Training loss: 2.1406898498535156
Validation loss: 2.323188122882638

Epoch: 6| Step: 6
Training loss: 2.71683669090271
Validation loss: 2.353721154633389

Epoch: 6| Step: 7
Training loss: 3.307572841644287
Validation loss: 2.38925608511894

Epoch: 6| Step: 8
Training loss: 2.5065865516662598
Validation loss: 2.398569363419728

Epoch: 6| Step: 9
Training loss: 2.350165367126465
Validation loss: 2.3757312541366904

Epoch: 6| Step: 10
Training loss: 2.131200075149536
Validation loss: 2.35177077785615

Epoch: 6| Step: 11
Training loss: 2.6595165729522705
Validation loss: 2.3379813240420435

Epoch: 6| Step: 12
Training loss: 2.620882749557495
Validation loss: 2.3239306660108667

Epoch: 6| Step: 13
Training loss: 3.5820400714874268
Validation loss: 2.3164807775969147

Epoch: 67| Step: 0
Training loss: 2.1552815437316895
Validation loss: 2.3146199308415896

Epoch: 6| Step: 1
Training loss: 1.914175033569336
Validation loss: 2.316174563541207

Epoch: 6| Step: 2
Training loss: 1.9664993286132812
Validation loss: 2.321962841095463

Epoch: 6| Step: 3
Training loss: 2.099030017852783
Validation loss: 2.3245228990431754

Epoch: 6| Step: 4
Training loss: 3.0257835388183594
Validation loss: 2.321616393263622

Epoch: 6| Step: 5
Training loss: 2.116391181945801
Validation loss: 2.3224551831522295

Epoch: 6| Step: 6
Training loss: 2.733875274658203
Validation loss: 2.3397713656066568

Epoch: 6| Step: 7
Training loss: 2.920703887939453
Validation loss: 2.3299642250102055

Epoch: 6| Step: 8
Training loss: 3.3579554557800293
Validation loss: 2.332627809175881

Epoch: 6| Step: 9
Training loss: 2.7656941413879395
Validation loss: 2.3259585313899542

Epoch: 6| Step: 10
Training loss: 3.119650363922119
Validation loss: 2.3117653169939594

Epoch: 6| Step: 11
Training loss: 3.0382988452911377
Validation loss: 2.3180862998449676

Epoch: 6| Step: 12
Training loss: 1.700612187385559
Validation loss: 2.319565981946966

Epoch: 6| Step: 13
Training loss: 3.814826488494873
Validation loss: 2.326784935048831

Epoch: 68| Step: 0
Training loss: 3.001495361328125
Validation loss: 2.321385975806944

Epoch: 6| Step: 1
Training loss: 2.2075963020324707
Validation loss: 2.3214533662283294

Epoch: 6| Step: 2
Training loss: 2.789076566696167
Validation loss: 2.323564801164853

Epoch: 6| Step: 3
Training loss: 3.249002456665039
Validation loss: 2.315192655850482

Epoch: 6| Step: 4
Training loss: 2.6495728492736816
Validation loss: 2.3158770453545356

Epoch: 6| Step: 5
Training loss: 2.3908567428588867
Validation loss: 2.3211976353840162

Epoch: 6| Step: 6
Training loss: 2.356698989868164
Validation loss: 2.3261563777923584

Epoch: 6| Step: 7
Training loss: 2.138068675994873
Validation loss: 2.320220802419929

Epoch: 6| Step: 8
Training loss: 2.901998519897461
Validation loss: 2.303796481060725

Epoch: 6| Step: 9
Training loss: 2.1185309886932373
Validation loss: 2.3060138738283547

Epoch: 6| Step: 10
Training loss: 2.104466438293457
Validation loss: 2.297726420946019

Epoch: 6| Step: 11
Training loss: 2.585681200027466
Validation loss: 2.3067819738900788

Epoch: 6| Step: 12
Training loss: 2.9147777557373047
Validation loss: 2.332468189218993

Epoch: 6| Step: 13
Training loss: 2.4201154708862305
Validation loss: 2.334968997586158

Epoch: 69| Step: 0
Training loss: 3.2761831283569336
Validation loss: 2.3679576663560766

Epoch: 6| Step: 1
Training loss: 2.403573751449585
Validation loss: 2.3656689043967956

Epoch: 6| Step: 2
Training loss: 1.3922706842422485
Validation loss: 2.3626021569774998

Epoch: 6| Step: 3
Training loss: 2.905865430831909
Validation loss: 2.3658872932516117

Epoch: 6| Step: 4
Training loss: 2.7572860717773438
Validation loss: 2.3620416297707507

Epoch: 6| Step: 5
Training loss: 3.191091537475586
Validation loss: 2.369585073122414

Epoch: 6| Step: 6
Training loss: 3.040889024734497
Validation loss: 2.3451657910500803

Epoch: 6| Step: 7
Training loss: 2.326842784881592
Validation loss: 2.323515686937558

Epoch: 6| Step: 8
Training loss: 2.2487645149230957
Validation loss: 2.3124753249588834

Epoch: 6| Step: 9
Training loss: 2.9914369583129883
Validation loss: 2.3118973060320784

Epoch: 6| Step: 10
Training loss: 2.5844686031341553
Validation loss: 2.2985467039128786

Epoch: 6| Step: 11
Training loss: 2.174410343170166
Validation loss: 2.3030109995154926

Epoch: 6| Step: 12
Training loss: 2.035459518432617
Validation loss: 2.2977333658485004

Epoch: 6| Step: 13
Training loss: 2.7010927200317383
Validation loss: 2.307883019088417

Epoch: 70| Step: 0
Training loss: 2.6010851860046387
Validation loss: 2.3051463173281763

Epoch: 6| Step: 1
Training loss: 2.2945637702941895
Validation loss: 2.3027715862438245

Epoch: 6| Step: 2
Training loss: 2.2581496238708496
Validation loss: 2.303495207140523

Epoch: 6| Step: 3
Training loss: 2.1390204429626465
Validation loss: 2.3140702350165254

Epoch: 6| Step: 4
Training loss: 2.9439966678619385
Validation loss: 2.367282573894788

Epoch: 6| Step: 5
Training loss: 2.3719964027404785
Validation loss: 2.430800648145778

Epoch: 6| Step: 6
Training loss: 3.299337863922119
Validation loss: 2.437662322034118

Epoch: 6| Step: 7
Training loss: 2.887263298034668
Validation loss: 2.396668839198287

Epoch: 6| Step: 8
Training loss: 3.013242244720459
Validation loss: 2.323138375436106

Epoch: 6| Step: 9
Training loss: 2.31520414352417
Validation loss: 2.296496775842482

Epoch: 6| Step: 10
Training loss: 2.5150089263916016
Validation loss: 2.28497520185286

Epoch: 6| Step: 11
Training loss: 2.262737274169922
Validation loss: 2.3134094194699357

Epoch: 6| Step: 12
Training loss: 2.6996865272521973
Validation loss: 2.3415802114753315

Epoch: 6| Step: 13
Training loss: 2.834618091583252
Validation loss: 2.369236082159063

Epoch: 71| Step: 0
Training loss: 2.7014312744140625
Validation loss: 2.366873454022151

Epoch: 6| Step: 1
Training loss: 3.0386252403259277
Validation loss: 2.3377060890197754

Epoch: 6| Step: 2
Training loss: 2.597538948059082
Validation loss: 2.312195708674769

Epoch: 6| Step: 3
Training loss: 3.3250131607055664
Validation loss: 2.2895965140352965

Epoch: 6| Step: 4
Training loss: 2.5264952182769775
Validation loss: 2.2797552577910887

Epoch: 6| Step: 5
Training loss: 2.7127270698547363
Validation loss: 2.2822887051490044

Epoch: 6| Step: 6
Training loss: 2.731830596923828
Validation loss: 2.2932439606676818

Epoch: 6| Step: 7
Training loss: 2.0398950576782227
Validation loss: 2.3320038485270675

Epoch: 6| Step: 8
Training loss: 2.6087512969970703
Validation loss: 2.412125451590425

Epoch: 6| Step: 9
Training loss: 3.031031608581543
Validation loss: 2.431510115182528

Epoch: 6| Step: 10
Training loss: 1.8644840717315674
Validation loss: 2.4112551545584076

Epoch: 6| Step: 11
Training loss: 2.317991018295288
Validation loss: 2.3672359028170185

Epoch: 6| Step: 12
Training loss: 2.3843913078308105
Validation loss: 2.343418700720674

Epoch: 6| Step: 13
Training loss: 2.682354688644409
Validation loss: 2.325750261224726

Epoch: 72| Step: 0
Training loss: 2.65836763381958
Validation loss: 2.3226379092021654

Epoch: 6| Step: 1
Training loss: 3.253455400466919
Validation loss: 2.3165707254922516

Epoch: 6| Step: 2
Training loss: 2.168179988861084
Validation loss: 2.30452775186108

Epoch: 6| Step: 3
Training loss: 1.9644601345062256
Validation loss: 2.300330238957559

Epoch: 6| Step: 4
Training loss: 2.9115524291992188
Validation loss: 2.2986090413985716

Epoch: 6| Step: 5
Training loss: 3.085409641265869
Validation loss: 2.294260246779329

Epoch: 6| Step: 6
Training loss: 2.7071914672851562
Validation loss: 2.286912779654226

Epoch: 6| Step: 7
Training loss: 2.5938785076141357
Validation loss: 2.286553918674428

Epoch: 6| Step: 8
Training loss: 2.332794189453125
Validation loss: 2.293657741238994

Epoch: 6| Step: 9
Training loss: 2.439899206161499
Validation loss: 2.3060388154880975

Epoch: 6| Step: 10
Training loss: 3.247584104537964
Validation loss: 2.300124397841833

Epoch: 6| Step: 11
Training loss: 2.136453628540039
Validation loss: 2.293649063315443

Epoch: 6| Step: 12
Training loss: 2.358030319213867
Validation loss: 2.283862026788855

Epoch: 6| Step: 13
Training loss: 1.8879280090332031
Validation loss: 2.266663266766456

Epoch: 73| Step: 0
Training loss: 3.053067684173584
Validation loss: 2.2705083149735645

Epoch: 6| Step: 1
Training loss: 2.70743465423584
Validation loss: 2.2810519459427043

Epoch: 6| Step: 2
Training loss: 2.631166934967041
Validation loss: 2.2797051193893596

Epoch: 6| Step: 3
Training loss: 2.3725695610046387
Validation loss: 2.2901778631312872

Epoch: 6| Step: 4
Training loss: 2.6963253021240234
Validation loss: 2.2768211159654843

Epoch: 6| Step: 5
Training loss: 2.827038288116455
Validation loss: 2.2623359528920983

Epoch: 6| Step: 6
Training loss: 2.367137908935547
Validation loss: 2.2628832581222698

Epoch: 6| Step: 7
Training loss: 2.4438233375549316
Validation loss: 2.2689677848610827

Epoch: 6| Step: 8
Training loss: 2.610945701599121
Validation loss: 2.2712566391114266

Epoch: 6| Step: 9
Training loss: 1.7045719623565674
Validation loss: 2.2681789705830235

Epoch: 6| Step: 10
Training loss: 1.9722394943237305
Validation loss: 2.2612899734127905

Epoch: 6| Step: 11
Training loss: 2.8958652019500732
Validation loss: 2.255388959761589

Epoch: 6| Step: 12
Training loss: 3.065279722213745
Validation loss: 2.2692916342007217

Epoch: 6| Step: 13
Training loss: 2.8811521530151367
Validation loss: 2.2928833320576656

Epoch: 74| Step: 0
Training loss: 3.2269723415374756
Validation loss: 2.3146839423846175

Epoch: 6| Step: 1
Training loss: 2.5457305908203125
Validation loss: 2.3310014842658915

Epoch: 6| Step: 2
Training loss: 2.6806704998016357
Validation loss: 2.325925921881071

Epoch: 6| Step: 3
Training loss: 2.5516390800476074
Validation loss: 2.3185539758333595

Epoch: 6| Step: 4
Training loss: 2.47171688079834
Validation loss: 2.337224450162662

Epoch: 6| Step: 5
Training loss: 2.312234878540039
Validation loss: 2.3261757742974067

Epoch: 6| Step: 6
Training loss: 3.2025957107543945
Validation loss: 2.3087591766029276

Epoch: 6| Step: 7
Training loss: 2.5873489379882812
Validation loss: 2.30229829460062

Epoch: 6| Step: 8
Training loss: 2.8285281658172607
Validation loss: 2.2844183188612743

Epoch: 6| Step: 9
Training loss: 2.389285087585449
Validation loss: 2.271164850522113

Epoch: 6| Step: 10
Training loss: 2.1814470291137695
Validation loss: 2.2582399588759228

Epoch: 6| Step: 11
Training loss: 2.154369592666626
Validation loss: 2.2473426685538342

Epoch: 6| Step: 12
Training loss: 2.1902730464935303
Validation loss: 2.2434498417762017

Epoch: 6| Step: 13
Training loss: 2.4526431560516357
Validation loss: 2.2413968245188394

Epoch: 75| Step: 0
Training loss: 3.2276358604431152
Validation loss: 2.2433738144495154

Epoch: 6| Step: 1
Training loss: 2.629301071166992
Validation loss: 2.242295034470097

Epoch: 6| Step: 2
Training loss: 2.375670909881592
Validation loss: 2.246262352953675

Epoch: 6| Step: 3
Training loss: 2.868962287902832
Validation loss: 2.248225164669816

Epoch: 6| Step: 4
Training loss: 2.722809314727783
Validation loss: 2.245961840434741

Epoch: 6| Step: 5
Training loss: 2.4980080127716064
Validation loss: 2.2499831927719938

Epoch: 6| Step: 6
Training loss: 1.9404876232147217
Validation loss: 2.2493574824384464

Epoch: 6| Step: 7
Training loss: 2.1496667861938477
Validation loss: 2.247100127640591

Epoch: 6| Step: 8
Training loss: 2.4081099033355713
Validation loss: 2.2412262321800314

Epoch: 6| Step: 9
Training loss: 2.379798173904419
Validation loss: 2.2446863241093133

Epoch: 6| Step: 10
Training loss: 2.628034830093384
Validation loss: 2.2493568774192565

Epoch: 6| Step: 11
Training loss: 3.0389466285705566
Validation loss: 2.254898637853643

Epoch: 6| Step: 12
Training loss: 3.07755184173584
Validation loss: 2.2627408760850147

Epoch: 6| Step: 13
Training loss: 1.3408050537109375
Validation loss: 2.2594584829063824

Epoch: 76| Step: 0
Training loss: 1.8584702014923096
Validation loss: 2.276387576133974

Epoch: 6| Step: 1
Training loss: 2.5545923709869385
Validation loss: 2.3155933195544827

Epoch: 6| Step: 2
Training loss: 2.600642442703247
Validation loss: 2.365827978298228

Epoch: 6| Step: 3
Training loss: 3.089524269104004
Validation loss: 2.3403681221828667

Epoch: 6| Step: 4
Training loss: 3.247899055480957
Validation loss: 2.334507970399754

Epoch: 6| Step: 5
Training loss: 1.8914687633514404
Validation loss: 2.30768092473348

Epoch: 6| Step: 6
Training loss: 3.037339210510254
Validation loss: 2.297059659034975

Epoch: 6| Step: 7
Training loss: 2.5194363594055176
Validation loss: 2.29146215479861

Epoch: 6| Step: 8
Training loss: 3.2077836990356445
Validation loss: 2.2726032810826458

Epoch: 6| Step: 9
Training loss: 2.247281551361084
Validation loss: 2.262305312259223

Epoch: 6| Step: 10
Training loss: 1.6114699840545654
Validation loss: 2.2589590267468522

Epoch: 6| Step: 11
Training loss: 3.471938133239746
Validation loss: 2.2549806487175728

Epoch: 6| Step: 12
Training loss: 2.071514129638672
Validation loss: 2.2543735247786327

Epoch: 6| Step: 13
Training loss: 1.960428237915039
Validation loss: 2.255526086335541

Epoch: 77| Step: 0
Training loss: 1.947512149810791
Validation loss: 2.2612291997478855

Epoch: 6| Step: 1
Training loss: 2.6390762329101562
Validation loss: 2.2590207079405427

Epoch: 6| Step: 2
Training loss: 2.6687567234039307
Validation loss: 2.2562563521887666

Epoch: 6| Step: 3
Training loss: 1.9671752452850342
Validation loss: 2.2540038554899153

Epoch: 6| Step: 4
Training loss: 2.941676616668701
Validation loss: 2.2490421905312488

Epoch: 6| Step: 5
Training loss: 3.0987982749938965
Validation loss: 2.2660502720904607

Epoch: 6| Step: 6
Training loss: 2.1484522819519043
Validation loss: 2.268794882682062

Epoch: 6| Step: 7
Training loss: 2.7932119369506836
Validation loss: 2.2768771135678856

Epoch: 6| Step: 8
Training loss: 2.6529030799865723
Validation loss: 2.288553471206337

Epoch: 6| Step: 9
Training loss: 2.7621800899505615
Validation loss: 2.2755450382027576

Epoch: 6| Step: 10
Training loss: 2.8990211486816406
Validation loss: 2.270924929649599

Epoch: 6| Step: 11
Training loss: 2.3577005863189697
Validation loss: 2.265493551890055

Epoch: 6| Step: 12
Training loss: 2.042224884033203
Validation loss: 2.25063564444101

Epoch: 6| Step: 13
Training loss: 2.9601833820343018
Validation loss: 2.236560506205405

Epoch: 78| Step: 0
Training loss: 3.1253714561462402
Validation loss: 2.2285781906497095

Epoch: 6| Step: 1
Training loss: 3.0230069160461426
Validation loss: 2.2215928775008007

Epoch: 6| Step: 2
Training loss: 2.153970241546631
Validation loss: 2.223171854531893

Epoch: 6| Step: 3
Training loss: 2.9402294158935547
Validation loss: 2.2257669843653196

Epoch: 6| Step: 4
Training loss: 3.0370118618011475
Validation loss: 2.2230528503335933

Epoch: 6| Step: 5
Training loss: 3.140024185180664
Validation loss: 2.2254086591864146

Epoch: 6| Step: 6
Training loss: 2.641178846359253
Validation loss: 2.2248975615347586

Epoch: 6| Step: 7
Training loss: 1.8643274307250977
Validation loss: 2.221702503901656

Epoch: 6| Step: 8
Training loss: 2.355466842651367
Validation loss: 2.2257295270119943

Epoch: 6| Step: 9
Training loss: 2.8535287380218506
Validation loss: 2.2366380153163785

Epoch: 6| Step: 10
Training loss: 1.9915881156921387
Validation loss: 2.234931227981403

Epoch: 6| Step: 11
Training loss: 2.3532114028930664
Validation loss: 2.2569384574890137

Epoch: 6| Step: 12
Training loss: 1.8100172281265259
Validation loss: 2.265726702187651

Epoch: 6| Step: 13
Training loss: 1.9038655757904053
Validation loss: 2.2827948395923903

Epoch: 79| Step: 0
Training loss: 2.1548502445220947
Validation loss: 2.3234634168686403

Epoch: 6| Step: 1
Training loss: 2.4128754138946533
Validation loss: 2.4059787155479513

Epoch: 6| Step: 2
Training loss: 3.3333959579467773
Validation loss: 2.4180625433562906

Epoch: 6| Step: 3
Training loss: 2.818333864212036
Validation loss: 2.3710763428800847

Epoch: 6| Step: 4
Training loss: 2.3102774620056152
Validation loss: 2.304107509633546

Epoch: 6| Step: 5
Training loss: 2.276172161102295
Validation loss: 2.253667131547005

Epoch: 6| Step: 6
Training loss: 2.391476631164551
Validation loss: 2.235846947598201

Epoch: 6| Step: 7
Training loss: 2.4718666076660156
Validation loss: 2.235716986399825

Epoch: 6| Step: 8
Training loss: 2.7559943199157715
Validation loss: 2.240079679796773

Epoch: 6| Step: 9
Training loss: 2.66654109954834
Validation loss: 2.2444893993357176

Epoch: 6| Step: 10
Training loss: 2.1855154037475586
Validation loss: 2.2508923879233738

Epoch: 6| Step: 11
Training loss: 3.083606719970703
Validation loss: 2.250418378460792

Epoch: 6| Step: 12
Training loss: 2.80338978767395
Validation loss: 2.2448237288382744

Epoch: 6| Step: 13
Training loss: 1.9891095161437988
Validation loss: 2.237670644637077

Epoch: 80| Step: 0
Training loss: 2.144590377807617
Validation loss: 2.231572440875474

Epoch: 6| Step: 1
Training loss: 3.260453462600708
Validation loss: 2.2378607539720434

Epoch: 6| Step: 2
Training loss: 2.867579936981201
Validation loss: 2.2354798111864316

Epoch: 6| Step: 3
Training loss: 2.298776149749756
Validation loss: 2.2411793637019333

Epoch: 6| Step: 4
Training loss: 2.441913366317749
Validation loss: 2.2634185103959936

Epoch: 6| Step: 5
Training loss: 2.061293363571167
Validation loss: 2.266922200879743

Epoch: 6| Step: 6
Training loss: 2.1506433486938477
Validation loss: 2.2768729732882593

Epoch: 6| Step: 7
Training loss: 2.0243868827819824
Validation loss: 2.2753769479772097

Epoch: 6| Step: 8
Training loss: 3.21559739112854
Validation loss: 2.2679082321864303

Epoch: 6| Step: 9
Training loss: 1.9518991708755493
Validation loss: 2.255159167833226

Epoch: 6| Step: 10
Training loss: 2.7702770233154297
Validation loss: 2.2570796935789046

Epoch: 6| Step: 11
Training loss: 2.489546775817871
Validation loss: 2.2526936607976116

Epoch: 6| Step: 12
Training loss: 2.5996012687683105
Validation loss: 2.251966071385209

Epoch: 6| Step: 13
Training loss: 3.5857882499694824
Validation loss: 2.2471575993363575

Epoch: 81| Step: 0
Training loss: 2.2464776039123535
Validation loss: 2.2600374965257544

Epoch: 6| Step: 1
Training loss: 2.96299409866333
Validation loss: 2.2709161248258365

Epoch: 6| Step: 2
Training loss: 2.905299186706543
Validation loss: 2.263246754164337

Epoch: 6| Step: 3
Training loss: 2.2164483070373535
Validation loss: 2.2638787748993083

Epoch: 6| Step: 4
Training loss: 2.466193675994873
Validation loss: 2.279647816893875

Epoch: 6| Step: 5
Training loss: 2.699507236480713
Validation loss: 2.2755944882669756

Epoch: 6| Step: 6
Training loss: 2.7904229164123535
Validation loss: 2.278208573659261

Epoch: 6| Step: 7
Training loss: 2.046592950820923
Validation loss: 2.2729108102859987

Epoch: 6| Step: 8
Training loss: 2.7727982997894287
Validation loss: 2.2599212969503095

Epoch: 6| Step: 9
Training loss: 2.4384469985961914
Validation loss: 2.256970920870381

Epoch: 6| Step: 10
Training loss: 2.6872878074645996
Validation loss: 2.2465511496349047

Epoch: 6| Step: 11
Training loss: 2.236560821533203
Validation loss: 2.2370996270128476

Epoch: 6| Step: 12
Training loss: 2.1896424293518066
Validation loss: 2.225086659513494

Epoch: 6| Step: 13
Training loss: 2.7137105464935303
Validation loss: 2.2310043111924203

Epoch: 82| Step: 0
Training loss: 1.847388505935669
Validation loss: 2.243367225893082

Epoch: 6| Step: 1
Training loss: 2.3747453689575195
Validation loss: 2.269856740069646

Epoch: 6| Step: 2
Training loss: 3.0790762901306152
Validation loss: 2.3164870354437057

Epoch: 6| Step: 3
Training loss: 2.1832313537597656
Validation loss: 2.318870213723952

Epoch: 6| Step: 4
Training loss: 2.156135082244873
Validation loss: 2.3119150771889636

Epoch: 6| Step: 5
Training loss: 3.237476110458374
Validation loss: 2.27009061075026

Epoch: 6| Step: 6
Training loss: 3.2564852237701416
Validation loss: 2.2336126040386897

Epoch: 6| Step: 7
Training loss: 2.4399123191833496
Validation loss: 2.2119594235574045

Epoch: 6| Step: 8
Training loss: 2.2006144523620605
Validation loss: 2.204005245239504

Epoch: 6| Step: 9
Training loss: 2.5167481899261475
Validation loss: 2.2019620121166272

Epoch: 6| Step: 10
Training loss: 2.9350414276123047
Validation loss: 2.211245300949261

Epoch: 6| Step: 11
Training loss: 2.5522875785827637
Validation loss: 2.219401692831388

Epoch: 6| Step: 12
Training loss: 2.7344613075256348
Validation loss: 2.2180469318102767

Epoch: 6| Step: 13
Training loss: 2.0915911197662354
Validation loss: 2.2004195259463404

Epoch: 83| Step: 0
Training loss: 3.101231098175049
Validation loss: 2.2007219714503132

Epoch: 6| Step: 1
Training loss: 1.7266829013824463
Validation loss: 2.2143218055848153

Epoch: 6| Step: 2
Training loss: 2.1568655967712402
Validation loss: 2.2565904560909478

Epoch: 6| Step: 3
Training loss: 2.530355215072632
Validation loss: 2.2963802660665205

Epoch: 6| Step: 4
Training loss: 2.6874122619628906
Validation loss: 2.3232215707020094

Epoch: 6| Step: 5
Training loss: 2.697237968444824
Validation loss: 2.312058469300629

Epoch: 6| Step: 6
Training loss: 2.3042054176330566
Validation loss: 2.2678391497622252

Epoch: 6| Step: 7
Training loss: 2.1814751625061035
Validation loss: 2.234973358851607

Epoch: 6| Step: 8
Training loss: 2.341768741607666
Validation loss: 2.2017122340458695

Epoch: 6| Step: 9
Training loss: 3.37685489654541
Validation loss: 2.1900465847343527

Epoch: 6| Step: 10
Training loss: 2.704761028289795
Validation loss: 2.19328994904795

Epoch: 6| Step: 11
Training loss: 2.3747196197509766
Validation loss: 2.19676620985872

Epoch: 6| Step: 12
Training loss: 2.551328420639038
Validation loss: 2.1897327771750827

Epoch: 6| Step: 13
Training loss: 2.663508653640747
Validation loss: 2.197473600346555

Epoch: 84| Step: 0
Training loss: 2.078639030456543
Validation loss: 2.2010474602381387

Epoch: 6| Step: 1
Training loss: 2.521545886993408
Validation loss: 2.199593597842801

Epoch: 6| Step: 2
Training loss: 3.031301498413086
Validation loss: 2.2078703859800934

Epoch: 6| Step: 3
Training loss: 3.0156166553497314
Validation loss: 2.2298297343715543

Epoch: 6| Step: 4
Training loss: 2.363192319869995
Validation loss: 2.2380312488925074

Epoch: 6| Step: 5
Training loss: 2.324124336242676
Validation loss: 2.2477370128836682

Epoch: 6| Step: 6
Training loss: 2.3294854164123535
Validation loss: 2.228693691633081

Epoch: 6| Step: 7
Training loss: 1.9945080280303955
Validation loss: 2.213698382018715

Epoch: 6| Step: 8
Training loss: 2.3499755859375
Validation loss: 2.209986186796619

Epoch: 6| Step: 9
Training loss: 2.1495118141174316
Validation loss: 2.2013968357475857

Epoch: 6| Step: 10
Training loss: 2.8613390922546387
Validation loss: 2.189779989181026

Epoch: 6| Step: 11
Training loss: 2.1079821586608887
Validation loss: 2.1839836182132846

Epoch: 6| Step: 12
Training loss: 3.189441680908203
Validation loss: 2.1850376590605705

Epoch: 6| Step: 13
Training loss: 2.8937840461730957
Validation loss: 2.184986086301906

Epoch: 85| Step: 0
Training loss: 2.6194217205047607
Validation loss: 2.184082423487017

Epoch: 6| Step: 1
Training loss: 3.163084030151367
Validation loss: 2.181720100423341

Epoch: 6| Step: 2
Training loss: 2.682302951812744
Validation loss: 2.1849276634954635

Epoch: 6| Step: 3
Training loss: 2.518707275390625
Validation loss: 2.184607336598058

Epoch: 6| Step: 4
Training loss: 2.233377456665039
Validation loss: 2.1789723980811333

Epoch: 6| Step: 5
Training loss: 2.3161818981170654
Validation loss: 2.1872104419175016

Epoch: 6| Step: 6
Training loss: 2.258171558380127
Validation loss: 2.192053364169213

Epoch: 6| Step: 7
Training loss: 2.4727587699890137
Validation loss: 2.21024082040274

Epoch: 6| Step: 8
Training loss: 2.4093222618103027
Validation loss: 2.215951486300397

Epoch: 6| Step: 9
Training loss: 2.7227697372436523
Validation loss: 2.2197316026174896

Epoch: 6| Step: 10
Training loss: 2.1527411937713623
Validation loss: 2.2162847877830587

Epoch: 6| Step: 11
Training loss: 2.6598618030548096
Validation loss: 2.196631275197511

Epoch: 6| Step: 12
Training loss: 2.7333836555480957
Validation loss: 2.1773625471258677

Epoch: 6| Step: 13
Training loss: 2.170194625854492
Validation loss: 2.1843830590607016

Epoch: 86| Step: 0
Training loss: 2.2863550186157227
Validation loss: 2.1803861023277364

Epoch: 6| Step: 1
Training loss: 2.453472137451172
Validation loss: 2.191592465164841

Epoch: 6| Step: 2
Training loss: 2.5789694786071777
Validation loss: 2.1957300388684837

Epoch: 6| Step: 3
Training loss: 2.506760597229004
Validation loss: 2.2081390016822406

Epoch: 6| Step: 4
Training loss: 2.5310750007629395
Validation loss: 2.208793878555298

Epoch: 6| Step: 5
Training loss: 2.4015469551086426
Validation loss: 2.2120988086987565

Epoch: 6| Step: 6
Training loss: 2.6106295585632324
Validation loss: 2.2019787424354145

Epoch: 6| Step: 7
Training loss: 2.62876033782959
Validation loss: 2.1932856036770727

Epoch: 6| Step: 8
Training loss: 2.961063861846924
Validation loss: 2.179631604943224

Epoch: 6| Step: 9
Training loss: 2.757387399673462
Validation loss: 2.1795419018755675

Epoch: 6| Step: 10
Training loss: 2.0087876319885254
Validation loss: 2.1844392232997443

Epoch: 6| Step: 11
Training loss: 2.5615291595458984
Validation loss: 2.2002228280549407

Epoch: 6| Step: 12
Training loss: 2.8545408248901367
Validation loss: 2.2247650469503095

Epoch: 6| Step: 13
Training loss: 2.196077823638916
Validation loss: 2.2696330803696827

Epoch: 87| Step: 0
Training loss: 2.5983669757843018
Validation loss: 2.3295021980039534

Epoch: 6| Step: 1
Training loss: 2.748404026031494
Validation loss: 2.3795206341692197

Epoch: 6| Step: 2
Training loss: 3.0141243934631348
Validation loss: 2.367095883174609

Epoch: 6| Step: 3
Training loss: 2.0689215660095215
Validation loss: 2.294742850847142

Epoch: 6| Step: 4
Training loss: 2.9276492595672607
Validation loss: 2.2535325019590315

Epoch: 6| Step: 5
Training loss: 2.6696670055389404
Validation loss: 2.218278085031817

Epoch: 6| Step: 6
Training loss: 2.0057435035705566
Validation loss: 2.1929672636011595

Epoch: 6| Step: 7
Training loss: 2.8551440238952637
Validation loss: 2.174823361058389

Epoch: 6| Step: 8
Training loss: 2.007413387298584
Validation loss: 2.1769775344479467

Epoch: 6| Step: 9
Training loss: 2.6776063442230225
Validation loss: 2.167629006088421

Epoch: 6| Step: 10
Training loss: 2.2565977573394775
Validation loss: 2.1616808881041822

Epoch: 6| Step: 11
Training loss: 1.9866536855697632
Validation loss: 2.1654905349977556

Epoch: 6| Step: 12
Training loss: 2.970639944076538
Validation loss: 2.16164029413654

Epoch: 6| Step: 13
Training loss: 2.5424516201019287
Validation loss: 2.1685630557357625

Epoch: 88| Step: 0
Training loss: 2.6981186866760254
Validation loss: 2.1804344756628877

Epoch: 6| Step: 1
Training loss: 2.348641872406006
Validation loss: 2.2026677234198457

Epoch: 6| Step: 2
Training loss: 2.937814950942993
Validation loss: 2.2123264830599547

Epoch: 6| Step: 3
Training loss: 2.9664721488952637
Validation loss: 2.2214732990469983

Epoch: 6| Step: 4
Training loss: 1.9892985820770264
Validation loss: 2.2191953325784333

Epoch: 6| Step: 5
Training loss: 2.724485158920288
Validation loss: 2.2140269766571703

Epoch: 6| Step: 6
Training loss: 2.116663932800293
Validation loss: 2.209567169989309

Epoch: 6| Step: 7
Training loss: 2.442699909210205
Validation loss: 2.2050671397998767

Epoch: 6| Step: 8
Training loss: 2.259993553161621
Validation loss: 2.1900729825419765

Epoch: 6| Step: 9
Training loss: 2.0535097122192383
Validation loss: 2.188131183706304

Epoch: 6| Step: 10
Training loss: 2.859816312789917
Validation loss: 2.174413473375382

Epoch: 6| Step: 11
Training loss: 2.842008352279663
Validation loss: 2.164975584194224

Epoch: 6| Step: 12
Training loss: 2.0006914138793945
Validation loss: 2.1578469558428695

Epoch: 6| Step: 13
Training loss: 2.958866834640503
Validation loss: 2.1570548062683432

Epoch: 89| Step: 0
Training loss: 3.028179168701172
Validation loss: 2.166969942790206

Epoch: 6| Step: 1
Training loss: 2.4635870456695557
Validation loss: 2.1688999155516266

Epoch: 6| Step: 2
Training loss: 2.179032325744629
Validation loss: 2.1562322416613178

Epoch: 6| Step: 3
Training loss: 2.650219678878784
Validation loss: 2.1572969549445697

Epoch: 6| Step: 4
Training loss: 3.0400748252868652
Validation loss: 2.1573431645670245

Epoch: 6| Step: 5
Training loss: 2.068350315093994
Validation loss: 2.1612670703600814

Epoch: 6| Step: 6
Training loss: 2.539900302886963
Validation loss: 2.1634708476322952

Epoch: 6| Step: 7
Training loss: 3.10581636428833
Validation loss: 2.1706950100519324

Epoch: 6| Step: 8
Training loss: 3.4582908153533936
Validation loss: 2.172162604588334

Epoch: 6| Step: 9
Training loss: 2.5146589279174805
Validation loss: 2.1817436166988906

Epoch: 6| Step: 10
Training loss: 2.0072484016418457
Validation loss: 2.1761636195644254

Epoch: 6| Step: 11
Training loss: 1.7360920906066895
Validation loss: 2.1798237626270582

Epoch: 6| Step: 12
Training loss: 1.9830083847045898
Validation loss: 2.1631504489529516

Epoch: 6| Step: 13
Training loss: 2.005127191543579
Validation loss: 2.174482271235476

Epoch: 90| Step: 0
Training loss: 2.292982578277588
Validation loss: 2.179036799297538

Epoch: 6| Step: 1
Training loss: 2.912471055984497
Validation loss: 2.194276240564162

Epoch: 6| Step: 2
Training loss: 3.1086459159851074
Validation loss: 2.1961784747339066

Epoch: 6| Step: 3
Training loss: 2.061455249786377
Validation loss: 2.189899880398986

Epoch: 6| Step: 4
Training loss: 1.9300426244735718
Validation loss: 2.183645086903726

Epoch: 6| Step: 5
Training loss: 3.151850700378418
Validation loss: 2.173805785435502

Epoch: 6| Step: 6
Training loss: 2.6474742889404297
Validation loss: 2.1679162415125037

Epoch: 6| Step: 7
Training loss: 2.118199348449707
Validation loss: 2.1737411201641126

Epoch: 6| Step: 8
Training loss: 2.6056230068206787
Validation loss: 2.1568393399638515

Epoch: 6| Step: 9
Training loss: 2.9826622009277344
Validation loss: 2.159665484582224

Epoch: 6| Step: 10
Training loss: 1.6019192934036255
Validation loss: 2.1626114537639003

Epoch: 6| Step: 11
Training loss: 2.012024402618408
Validation loss: 2.160745479727304

Epoch: 6| Step: 12
Training loss: 2.6965789794921875
Validation loss: 2.166329155686081

Epoch: 6| Step: 13
Training loss: 2.7624101638793945
Validation loss: 2.1823881364637807

Epoch: 91| Step: 0
Training loss: 2.138911724090576
Validation loss: 2.201415333696591

Epoch: 6| Step: 1
Training loss: 2.6837148666381836
Validation loss: 2.191519219388244

Epoch: 6| Step: 2
Training loss: 2.4655375480651855
Validation loss: 2.183617368821175

Epoch: 6| Step: 3
Training loss: 2.0963189601898193
Validation loss: 2.182215767522012

Epoch: 6| Step: 4
Training loss: 2.6548213958740234
Validation loss: 2.1723239550026516

Epoch: 6| Step: 5
Training loss: 2.7875871658325195
Validation loss: 2.153141943357324

Epoch: 6| Step: 6
Training loss: 2.339907646179199
Validation loss: 2.147494887792936

Epoch: 6| Step: 7
Training loss: 2.050286054611206
Validation loss: 2.1450668560561312

Epoch: 6| Step: 8
Training loss: 2.4297757148742676
Validation loss: 2.1439690384813535

Epoch: 6| Step: 9
Training loss: 2.4750795364379883
Validation loss: 2.1523121992746987

Epoch: 6| Step: 10
Training loss: 2.8820862770080566
Validation loss: 2.1717586748061644

Epoch: 6| Step: 11
Training loss: 2.9379920959472656
Validation loss: 2.1884913777792327

Epoch: 6| Step: 12
Training loss: 2.5498878955841064
Validation loss: 2.158131307171237

Epoch: 6| Step: 13
Training loss: 2.000006675720215
Validation loss: 2.167738301779634

Epoch: 92| Step: 0
Training loss: 2.785801410675049
Validation loss: 2.193196563310521

Epoch: 6| Step: 1
Training loss: 2.3489599227905273
Validation loss: 2.202819553754663

Epoch: 6| Step: 2
Training loss: 2.3845274448394775
Validation loss: 2.2062684823107976

Epoch: 6| Step: 3
Training loss: 2.0458810329437256
Validation loss: 2.1910277053874028

Epoch: 6| Step: 4
Training loss: 2.3425216674804688
Validation loss: 2.2161191689070834

Epoch: 6| Step: 5
Training loss: 2.661576509475708
Validation loss: 2.177538089854743

Epoch: 6| Step: 6
Training loss: 2.5692102909088135
Validation loss: 2.176049461928747

Epoch: 6| Step: 7
Training loss: 2.497941732406616
Validation loss: 2.163666186794158

Epoch: 6| Step: 8
Training loss: 2.9383444786071777
Validation loss: 2.155766808858482

Epoch: 6| Step: 9
Training loss: 2.8998498916625977
Validation loss: 2.151125982243528

Epoch: 6| Step: 10
Training loss: 2.4589481353759766
Validation loss: 2.1527781101965133

Epoch: 6| Step: 11
Training loss: 2.2707762718200684
Validation loss: 2.147410877289311

Epoch: 6| Step: 12
Training loss: 2.2622501850128174
Validation loss: 2.149480471047022

Epoch: 6| Step: 13
Training loss: 1.6754518747329712
Validation loss: 2.1375007757576565

Epoch: 93| Step: 0
Training loss: 2.677257776260376
Validation loss: 2.1413142245302916

Epoch: 6| Step: 1
Training loss: 1.6552190780639648
Validation loss: 2.143738037796431

Epoch: 6| Step: 2
Training loss: 2.092881917953491
Validation loss: 2.138974816568436

Epoch: 6| Step: 3
Training loss: 2.2269721031188965
Validation loss: 2.1436138909350158

Epoch: 6| Step: 4
Training loss: 2.452700138092041
Validation loss: 2.152524132882395

Epoch: 6| Step: 5
Training loss: 2.7945146560668945
Validation loss: 2.191322636860673

Epoch: 6| Step: 6
Training loss: 2.838751792907715
Validation loss: 2.2192303519095145

Epoch: 6| Step: 7
Training loss: 2.3596572875976562
Validation loss: 2.2173263334458873

Epoch: 6| Step: 8
Training loss: 1.9011037349700928
Validation loss: 2.233854696314822

Epoch: 6| Step: 9
Training loss: 2.69000244140625
Validation loss: 2.202519057899393

Epoch: 6| Step: 10
Training loss: 2.510650157928467
Validation loss: 2.1541535162156626

Epoch: 6| Step: 11
Training loss: 2.373368263244629
Validation loss: 2.139720360438029

Epoch: 6| Step: 12
Training loss: 3.1011502742767334
Validation loss: 2.1325039094494236

Epoch: 6| Step: 13
Training loss: 2.899808168411255
Validation loss: 2.1288297791634836

Epoch: 94| Step: 0
Training loss: 2.2185733318328857
Validation loss: 2.129523156791605

Epoch: 6| Step: 1
Training loss: 1.2736655473709106
Validation loss: 2.1264791860375354

Epoch: 6| Step: 2
Training loss: 2.8234496116638184
Validation loss: 2.13352636368044

Epoch: 6| Step: 3
Training loss: 2.5025711059570312
Validation loss: 2.134139099428731

Epoch: 6| Step: 4
Training loss: 1.700591802597046
Validation loss: 2.1466173228397163

Epoch: 6| Step: 5
Training loss: 2.7159218788146973
Validation loss: 2.1460225838486866

Epoch: 6| Step: 6
Training loss: 2.0690908432006836
Validation loss: 2.1379778385162354

Epoch: 6| Step: 7
Training loss: 2.7474634647369385
Validation loss: 2.1485075130257556

Epoch: 6| Step: 8
Training loss: 3.1650726795196533
Validation loss: 2.1411806691077446

Epoch: 6| Step: 9
Training loss: 3.566047430038452
Validation loss: 2.1546977976317048

Epoch: 6| Step: 10
Training loss: 1.7883074283599854
Validation loss: 2.15931962895137

Epoch: 6| Step: 11
Training loss: 2.572421073913574
Validation loss: 2.1478797581888016

Epoch: 6| Step: 12
Training loss: 3.026177406311035
Validation loss: 2.1330918958110194

Epoch: 6| Step: 13
Training loss: 2.4368412494659424
Validation loss: 2.1320309100612516

Epoch: 95| Step: 0
Training loss: 2.6349854469299316
Validation loss: 2.1298877321263796

Epoch: 6| Step: 1
Training loss: 2.6651723384857178
Validation loss: 2.1347882465649675

Epoch: 6| Step: 2
Training loss: 2.2863008975982666
Validation loss: 2.1525951713644047

Epoch: 6| Step: 3
Training loss: 2.0686447620391846
Validation loss: 2.157901240933326

Epoch: 6| Step: 4
Training loss: 2.9092185497283936
Validation loss: 2.1716736414099254

Epoch: 6| Step: 5
Training loss: 2.165767192840576
Validation loss: 2.171899700677523

Epoch: 6| Step: 6
Training loss: 2.2983546257019043
Validation loss: 2.145962340857393

Epoch: 6| Step: 7
Training loss: 3.013495922088623
Validation loss: 2.129166535151902

Epoch: 6| Step: 8
Training loss: 2.7362260818481445
Validation loss: 2.1263010706952823

Epoch: 6| Step: 9
Training loss: 2.328329563140869
Validation loss: 2.124531417764643

Epoch: 6| Step: 10
Training loss: 2.2932276725769043
Validation loss: 2.119942234408471

Epoch: 6| Step: 11
Training loss: 2.4143667221069336
Validation loss: 2.1222811847604732

Epoch: 6| Step: 12
Training loss: 2.247093677520752
Validation loss: 2.12203574052421

Epoch: 6| Step: 13
Training loss: 2.3445539474487305
Validation loss: 2.126236069586969

Epoch: 96| Step: 0
Training loss: 2.2148683071136475
Validation loss: 2.1262580451144966

Epoch: 6| Step: 1
Training loss: 2.37648344039917
Validation loss: 2.1414507794123825

Epoch: 6| Step: 2
Training loss: 2.3276703357696533
Validation loss: 2.1450073642115437

Epoch: 6| Step: 3
Training loss: 2.737058162689209
Validation loss: 2.17833871482521

Epoch: 6| Step: 4
Training loss: 2.3426220417022705
Validation loss: 2.207578969258134

Epoch: 6| Step: 5
Training loss: 2.21634840965271
Validation loss: 2.2308637506218365

Epoch: 6| Step: 6
Training loss: 2.609867572784424
Validation loss: 2.2246125436598256

Epoch: 6| Step: 7
Training loss: 2.636897563934326
Validation loss: 2.174982415732517

Epoch: 6| Step: 8
Training loss: 2.9667015075683594
Validation loss: 2.150467295800486

Epoch: 6| Step: 9
Training loss: 2.4074277877807617
Validation loss: 2.1246961086027083

Epoch: 6| Step: 10
Training loss: 2.338993549346924
Validation loss: 2.123334966680055

Epoch: 6| Step: 11
Training loss: 2.545083999633789
Validation loss: 2.1202514299782376

Epoch: 6| Step: 12
Training loss: 2.6629974842071533
Validation loss: 2.1114974432094122

Epoch: 6| Step: 13
Training loss: 1.560551404953003
Validation loss: 2.1140442355986564

Epoch: 97| Step: 0
Training loss: 2.466744899749756
Validation loss: 2.112120295083651

Epoch: 6| Step: 1
Training loss: 2.620284080505371
Validation loss: 2.1156402634036158

Epoch: 6| Step: 2
Training loss: 2.0676023960113525
Validation loss: 2.113482920072412

Epoch: 6| Step: 3
Training loss: 2.648301601409912
Validation loss: 2.115277655663029

Epoch: 6| Step: 4
Training loss: 2.4626173973083496
Validation loss: 2.1274049692256476

Epoch: 6| Step: 5
Training loss: 2.070779323577881
Validation loss: 2.1362839821846253

Epoch: 6| Step: 6
Training loss: 2.8265373706817627
Validation loss: 2.119249145189921

Epoch: 6| Step: 7
Training loss: 2.0792555809020996
Validation loss: 2.116179963593842

Epoch: 6| Step: 8
Training loss: 2.4851255416870117
Validation loss: 2.1193897339605514

Epoch: 6| Step: 9
Training loss: 1.9313068389892578
Validation loss: 2.1170276441881732

Epoch: 6| Step: 10
Training loss: 2.027190685272217
Validation loss: 2.127588395149477

Epoch: 6| Step: 11
Training loss: 3.1171317100524902
Validation loss: 2.1445591577919583

Epoch: 6| Step: 12
Training loss: 2.983635187149048
Validation loss: 2.1826085198310112

Epoch: 6| Step: 13
Training loss: 2.397791624069214
Validation loss: 2.191640583417749

Epoch: 98| Step: 0
Training loss: 1.899611473083496
Validation loss: 2.198982460524446

Epoch: 6| Step: 1
Training loss: 2.9435477256774902
Validation loss: 2.1780483261231454

Epoch: 6| Step: 2
Training loss: 2.632478713989258
Validation loss: 2.1509959646450576

Epoch: 6| Step: 3
Training loss: 2.7108428478240967
Validation loss: 2.1270140499197026

Epoch: 6| Step: 4
Training loss: 2.4071333408355713
Validation loss: 2.1212471710738314

Epoch: 6| Step: 5
Training loss: 2.0262818336486816
Validation loss: 2.1072345882333736

Epoch: 6| Step: 6
Training loss: 2.5208585262298584
Validation loss: 2.1154801550731865

Epoch: 6| Step: 7
Training loss: 2.138458013534546
Validation loss: 2.11879797263812

Epoch: 6| Step: 8
Training loss: 2.162489891052246
Validation loss: 2.1161783843912105

Epoch: 6| Step: 9
Training loss: 2.3687047958374023
Validation loss: 2.1270898977915444

Epoch: 6| Step: 10
Training loss: 3.2280638217926025
Validation loss: 2.1391037253923315

Epoch: 6| Step: 11
Training loss: 2.400726318359375
Validation loss: 2.180145758454518

Epoch: 6| Step: 12
Training loss: 2.551725387573242
Validation loss: 2.2124125034578386

Epoch: 6| Step: 13
Training loss: 2.421905279159546
Validation loss: 2.201453833169835

Epoch: 99| Step: 0
Training loss: 2.0942625999450684
Validation loss: 2.1417743800788798

Epoch: 6| Step: 1
Training loss: 3.123326301574707
Validation loss: 2.110388284088463

Epoch: 6| Step: 2
Training loss: 1.7444795370101929
Validation loss: 2.098103928309615

Epoch: 6| Step: 3
Training loss: 2.418428897857666
Validation loss: 2.0990995168685913

Epoch: 6| Step: 4
Training loss: 2.2075870037078857
Validation loss: 2.09890583766404

Epoch: 6| Step: 5
Training loss: 2.793470621109009
Validation loss: 2.100953435385099

Epoch: 6| Step: 6
Training loss: 2.4713284969329834
Validation loss: 2.1005172114218436

Epoch: 6| Step: 7
Training loss: 1.5714013576507568
Validation loss: 2.110826566655149

Epoch: 6| Step: 8
Training loss: 2.9608421325683594
Validation loss: 2.107136618706488

Epoch: 6| Step: 9
Training loss: 2.962850570678711
Validation loss: 2.118558572184655

Epoch: 6| Step: 10
Training loss: 2.768428325653076
Validation loss: 2.1315864824479624

Epoch: 6| Step: 11
Training loss: 2.558065414428711
Validation loss: 2.1328213394329114

Epoch: 6| Step: 12
Training loss: 2.2714614868164062
Validation loss: 2.131680824423349

Epoch: 6| Step: 13
Training loss: 2.146206855773926
Validation loss: 2.13708992414577

Epoch: 100| Step: 0
Training loss: 2.434438705444336
Validation loss: 2.1507566129007647

Epoch: 6| Step: 1
Training loss: 2.487628936767578
Validation loss: 2.1645858415993313

Epoch: 6| Step: 2
Training loss: 2.7125086784362793
Validation loss: 2.186050958530877

Epoch: 6| Step: 3
Training loss: 2.820843458175659
Validation loss: 2.189893558461179

Epoch: 6| Step: 4
Training loss: 2.0786306858062744
Validation loss: 2.164533733039774

Epoch: 6| Step: 5
Training loss: 2.4403138160705566
Validation loss: 2.13936609350225

Epoch: 6| Step: 6
Training loss: 2.349205255508423
Validation loss: 2.121323303509784

Epoch: 6| Step: 7
Training loss: 2.767592668533325
Validation loss: 2.1017253193804013

Epoch: 6| Step: 8
Training loss: 2.705082416534424
Validation loss: 2.095563975713586

Epoch: 6| Step: 9
Training loss: 1.7532591819763184
Validation loss: 2.101315067660424

Epoch: 6| Step: 10
Training loss: 2.655056953430176
Validation loss: 2.1006199262475453

Epoch: 6| Step: 11
Training loss: 2.5416259765625
Validation loss: 2.0981586876735894

Epoch: 6| Step: 12
Training loss: 2.566835880279541
Validation loss: 2.1023402854960453

Epoch: 6| Step: 13
Training loss: 1.871429681777954
Validation loss: 2.093620450265946

Epoch: 101| Step: 0
Training loss: 2.8871917724609375
Validation loss: 2.0950137005057385

Epoch: 6| Step: 1
Training loss: 2.2241365909576416
Validation loss: 2.099944406940091

Epoch: 6| Step: 2
Training loss: 3.087188720703125
Validation loss: 2.0971924374180455

Epoch: 6| Step: 3
Training loss: 2.898913621902466
Validation loss: 2.1045834889975925

Epoch: 6| Step: 4
Training loss: 2.880213737487793
Validation loss: 2.102243838771697

Epoch: 6| Step: 5
Training loss: 1.8390012979507446
Validation loss: 2.110058399938768

Epoch: 6| Step: 6
Training loss: 2.5435431003570557
Validation loss: 2.125777406077231

Epoch: 6| Step: 7
Training loss: 2.2401328086853027
Validation loss: 2.148508623082151

Epoch: 6| Step: 8
Training loss: 1.7188684940338135
Validation loss: 2.161452562578263

Epoch: 6| Step: 9
Training loss: 3.0089831352233887
Validation loss: 2.1421854214001725

Epoch: 6| Step: 10
Training loss: 1.9405863285064697
Validation loss: 2.147305880823443

Epoch: 6| Step: 11
Training loss: 2.681185722351074
Validation loss: 2.151038113460746

Epoch: 6| Step: 12
Training loss: 2.0751028060913086
Validation loss: 2.1319446640629924

Epoch: 6| Step: 13
Training loss: 2.06244158744812
Validation loss: 2.1301892854834117

Epoch: 102| Step: 0
Training loss: 2.9142446517944336
Validation loss: 2.1307858241501676

Epoch: 6| Step: 1
Training loss: 1.8201940059661865
Validation loss: 2.1350237810483543

Epoch: 6| Step: 2
Training loss: 2.238043785095215
Validation loss: 2.1259030629229803

Epoch: 6| Step: 3
Training loss: 2.5159554481506348
Validation loss: 2.1199616078407533

Epoch: 6| Step: 4
Training loss: 2.303455352783203
Validation loss: 2.0971254251336537

Epoch: 6| Step: 5
Training loss: 2.3378005027770996
Validation loss: 2.0939864945668045

Epoch: 6| Step: 6
Training loss: 2.2446272373199463
Validation loss: 2.0853703304003646

Epoch: 6| Step: 7
Training loss: 2.602480888366699
Validation loss: 2.0867429061602523

Epoch: 6| Step: 8
Training loss: 2.661616802215576
Validation loss: 2.0918724152349655

Epoch: 6| Step: 9
Training loss: 2.8931937217712402
Validation loss: 2.097511545304329

Epoch: 6| Step: 10
Training loss: 2.5082998275756836
Validation loss: 2.0917062964490665

Epoch: 6| Step: 11
Training loss: 2.675503969192505
Validation loss: 2.0960323041485203

Epoch: 6| Step: 12
Training loss: 2.097888708114624
Validation loss: 2.0959928292100147

Epoch: 6| Step: 13
Training loss: 2.1995432376861572
Validation loss: 2.1019566982023177

Epoch: 103| Step: 0
Training loss: 2.8017587661743164
Validation loss: 2.184625771737868

Epoch: 6| Step: 1
Training loss: 2.1521127223968506
Validation loss: 2.294735267598142

Epoch: 6| Step: 2
Training loss: 2.20405650138855
Validation loss: 2.406674087688487

Epoch: 6| Step: 3
Training loss: 2.7412047386169434
Validation loss: 2.5267760856177217

Epoch: 6| Step: 4
Training loss: 2.8823232650756836
Validation loss: 2.6038511183954056

Epoch: 6| Step: 5
Training loss: 2.6578352451324463
Validation loss: 2.6154993246960383

Epoch: 6| Step: 6
Training loss: 2.653040885925293
Validation loss: 2.5207171337578886

Epoch: 6| Step: 7
Training loss: 2.498008966445923
Validation loss: 2.4185011745781027

Epoch: 6| Step: 8
Training loss: 3.1258480548858643
Validation loss: 2.3072652560408398

Epoch: 6| Step: 9
Training loss: 2.320167064666748
Validation loss: 2.175439288539271

Epoch: 6| Step: 10
Training loss: 2.3102223873138428
Validation loss: 2.108354091644287

Epoch: 6| Step: 11
Training loss: 2.257178783416748
Validation loss: 2.127146049212384

Epoch: 6| Step: 12
Training loss: 2.368665933609009
Validation loss: 2.1527182261149087

Epoch: 6| Step: 13
Training loss: 2.3373265266418457
Validation loss: 2.1566960683432956

Epoch: 104| Step: 0
Training loss: 2.1070799827575684
Validation loss: 2.108805330850745

Epoch: 6| Step: 1
Training loss: 2.60632061958313
Validation loss: 2.0937960506767355

Epoch: 6| Step: 2
Training loss: 2.511465072631836
Validation loss: 2.0983754422075007

Epoch: 6| Step: 3
Training loss: 3.044802665710449
Validation loss: 2.1206449026702554

Epoch: 6| Step: 4
Training loss: 2.6288514137268066
Validation loss: 2.1571971190873014

Epoch: 6| Step: 5
Training loss: 2.6485037803649902
Validation loss: 2.1754435954555387

Epoch: 6| Step: 6
Training loss: 2.2866342067718506
Validation loss: 2.173831824333437

Epoch: 6| Step: 7
Training loss: 2.014814853668213
Validation loss: 2.193775305183985

Epoch: 6| Step: 8
Training loss: 2.6787657737731934
Validation loss: 2.199810933041316

Epoch: 6| Step: 9
Training loss: 3.0303783416748047
Validation loss: 2.198678280717583

Epoch: 6| Step: 10
Training loss: 2.035639762878418
Validation loss: 2.1858049631118774

Epoch: 6| Step: 11
Training loss: 1.7882230281829834
Validation loss: 2.1811058495634343

Epoch: 6| Step: 12
Training loss: 2.55470871925354
Validation loss: 2.190688133239746

Epoch: 6| Step: 13
Training loss: 1.1719157695770264
Validation loss: 2.1536198815991803

Epoch: 105| Step: 0
Training loss: 2.6858057975769043
Validation loss: 2.1389061558631157

Epoch: 6| Step: 1
Training loss: 2.0169167518615723
Validation loss: 2.147590001424154

Epoch: 6| Step: 2
Training loss: 2.0643415451049805
Validation loss: 2.1633666766587125

Epoch: 6| Step: 3
Training loss: 2.3777544498443604
Validation loss: 2.1603540938387633

Epoch: 6| Step: 4
Training loss: 2.2390971183776855
Validation loss: 2.141295640699325

Epoch: 6| Step: 5
Training loss: 2.8432254791259766
Validation loss: 2.1082078513278755

Epoch: 6| Step: 6
Training loss: 2.5335865020751953
Validation loss: 2.09076399572434

Epoch: 6| Step: 7
Training loss: 2.259521484375
Validation loss: 2.089849491273203

Epoch: 6| Step: 8
Training loss: 2.702775001525879
Validation loss: 2.0932477340903333

Epoch: 6| Step: 9
Training loss: 2.721364974975586
Validation loss: 2.0936002551868396

Epoch: 6| Step: 10
Training loss: 2.5346755981445312
Validation loss: 2.083945482007919

Epoch: 6| Step: 11
Training loss: 2.216784715652466
Validation loss: 2.106920532000962

Epoch: 6| Step: 12
Training loss: 2.371920347213745
Validation loss: 2.1162553615467523

Epoch: 6| Step: 13
Training loss: 2.4247207641601562
Validation loss: 2.1278668090861332

Epoch: 106| Step: 0
Training loss: 1.993775725364685
Validation loss: 2.112428063987404

Epoch: 6| Step: 1
Training loss: 2.382875919342041
Validation loss: 2.106839551720568

Epoch: 6| Step: 2
Training loss: 2.0453977584838867
Validation loss: 2.0970552352166947

Epoch: 6| Step: 3
Training loss: 2.286470890045166
Validation loss: 2.1097036484749085

Epoch: 6| Step: 4
Training loss: 2.44920015335083
Validation loss: 2.1276479933851506

Epoch: 6| Step: 5
Training loss: 2.7296972274780273
Validation loss: 2.1317841288863972

Epoch: 6| Step: 6
Training loss: 2.5973546504974365
Validation loss: 2.150217099856305

Epoch: 6| Step: 7
Training loss: 1.927075982093811
Validation loss: 2.1430711284760506

Epoch: 6| Step: 8
Training loss: 1.951779842376709
Validation loss: 2.134650594444685

Epoch: 6| Step: 9
Training loss: 2.8010988235473633
Validation loss: 2.1353977008532454

Epoch: 6| Step: 10
Training loss: 2.800140857696533
Validation loss: 2.1311474807800783

Epoch: 6| Step: 11
Training loss: 2.7978765964508057
Validation loss: 2.1301044571784233

Epoch: 6| Step: 12
Training loss: 2.2072978019714355
Validation loss: 2.1304713808080202

Epoch: 6| Step: 13
Training loss: 3.3906946182250977
Validation loss: 2.1200767563235376

Epoch: 107| Step: 0
Training loss: 1.748471975326538
Validation loss: 2.111943083424722

Epoch: 6| Step: 1
Training loss: 2.58620285987854
Validation loss: 2.0952493811166413

Epoch: 6| Step: 2
Training loss: 2.7740378379821777
Validation loss: 2.0975321364659134

Epoch: 6| Step: 3
Training loss: 1.7439182996749878
Validation loss: 2.0933767646871586

Epoch: 6| Step: 4
Training loss: 2.2184033393859863
Validation loss: 2.10025514582152

Epoch: 6| Step: 5
Training loss: 2.179511070251465
Validation loss: 2.0949429030059488

Epoch: 6| Step: 6
Training loss: 3.3765311241149902
Validation loss: 2.1139669700335433

Epoch: 6| Step: 7
Training loss: 1.797054409980774
Validation loss: 2.092395536361202

Epoch: 6| Step: 8
Training loss: 2.113917112350464
Validation loss: 2.0929981970017955

Epoch: 6| Step: 9
Training loss: 2.0199379920959473
Validation loss: 2.0857854376557055

Epoch: 6| Step: 10
Training loss: 1.8785818815231323
Validation loss: 2.0900693119213147

Epoch: 6| Step: 11
Training loss: 2.999563694000244
Validation loss: 2.071784355307138

Epoch: 6| Step: 12
Training loss: 3.6541051864624023
Validation loss: 2.0752847169035222

Epoch: 6| Step: 13
Training loss: 2.652971029281616
Validation loss: 2.0768079244962303

Epoch: 108| Step: 0
Training loss: 2.803835391998291
Validation loss: 2.0907164568542154

Epoch: 6| Step: 1
Training loss: 2.338240623474121
Validation loss: 2.0753550157752088

Epoch: 6| Step: 2
Training loss: 2.1118485927581787
Validation loss: 2.1030342758342786

Epoch: 6| Step: 3
Training loss: 2.3042407035827637
Validation loss: 2.1095848083496094

Epoch: 6| Step: 4
Training loss: 2.4336423873901367
Validation loss: 2.149176888568427

Epoch: 6| Step: 5
Training loss: 2.049600601196289
Validation loss: 2.1793693560425953

Epoch: 6| Step: 6
Training loss: 2.146791458129883
Validation loss: 2.22100325810012

Epoch: 6| Step: 7
Training loss: 1.7332117557525635
Validation loss: 2.1704287631537325

Epoch: 6| Step: 8
Training loss: 2.099679470062256
Validation loss: 2.0976291728276077

Epoch: 6| Step: 9
Training loss: 2.9054126739501953
Validation loss: 2.075335177042151

Epoch: 6| Step: 10
Training loss: 2.894543409347534
Validation loss: 2.0618000991882814

Epoch: 6| Step: 11
Training loss: 2.7124688625335693
Validation loss: 2.065498403323594

Epoch: 6| Step: 12
Training loss: 2.2878403663635254
Validation loss: 2.0690513605712564

Epoch: 6| Step: 13
Training loss: 2.7868311405181885
Validation loss: 2.077674937504594

Epoch: 109| Step: 0
Training loss: 2.2221431732177734
Validation loss: 2.080925541539346

Epoch: 6| Step: 1
Training loss: 2.431114673614502
Validation loss: 2.0828330260451122

Epoch: 6| Step: 2
Training loss: 2.080441474914551
Validation loss: 2.0932976199734594

Epoch: 6| Step: 3
Training loss: 2.4060075283050537
Validation loss: 2.0914396624411307

Epoch: 6| Step: 4
Training loss: 1.9514904022216797
Validation loss: 2.083009478866413

Epoch: 6| Step: 5
Training loss: 2.092783212661743
Validation loss: 2.065766756252576

Epoch: 6| Step: 6
Training loss: 2.363182544708252
Validation loss: 2.0615311335491877

Epoch: 6| Step: 7
Training loss: 3.0621535778045654
Validation loss: 2.07746030951059

Epoch: 6| Step: 8
Training loss: 2.339552640914917
Validation loss: 2.084951405884117

Epoch: 6| Step: 9
Training loss: 2.799600124359131
Validation loss: 2.121036494931867

Epoch: 6| Step: 10
Training loss: 2.4515459537506104
Validation loss: 2.150502017749253

Epoch: 6| Step: 11
Training loss: 2.668846607208252
Validation loss: 2.2140673950154293

Epoch: 6| Step: 12
Training loss: 2.8128039836883545
Validation loss: 2.2315512690492856

Epoch: 6| Step: 13
Training loss: 2.5467114448547363
Validation loss: 2.295762815783101

Epoch: 110| Step: 0
Training loss: 2.6455812454223633
Validation loss: 2.2956811997198288

Epoch: 6| Step: 1
Training loss: 2.725203037261963
Validation loss: 2.318762961254325

Epoch: 6| Step: 2
Training loss: 1.3198695182800293
Validation loss: 2.206668961432672

Epoch: 6| Step: 3
Training loss: 2.1737008094787598
Validation loss: 2.160099883233347

Epoch: 6| Step: 4
Training loss: 2.3051748275756836
Validation loss: 2.129432560295187

Epoch: 6| Step: 5
Training loss: 2.9305553436279297
Validation loss: 2.1300590371572845

Epoch: 6| Step: 6
Training loss: 2.534233808517456
Validation loss: 2.1312094068014495

Epoch: 6| Step: 7
Training loss: 2.16776180267334
Validation loss: 2.1598091792034846

Epoch: 6| Step: 8
Training loss: 2.8557019233703613
Validation loss: 2.1480444631268902

Epoch: 6| Step: 9
Training loss: 2.558681011199951
Validation loss: 2.122112433115641

Epoch: 6| Step: 10
Training loss: 2.990945339202881
Validation loss: 2.110641118018858

Epoch: 6| Step: 11
Training loss: 2.2976412773132324
Validation loss: 2.119864140787432

Epoch: 6| Step: 12
Training loss: 2.6171722412109375
Validation loss: 2.1085678018549436

Epoch: 6| Step: 13
Training loss: 1.465881109237671
Validation loss: 2.087454783019199

Epoch: 111| Step: 0
Training loss: 2.2070493698120117
Validation loss: 2.085551950239366

Epoch: 6| Step: 1
Training loss: 2.8211686611175537
Validation loss: 2.0907778547656153

Epoch: 6| Step: 2
Training loss: 2.2052974700927734
Validation loss: 2.094006488400121

Epoch: 6| Step: 3
Training loss: 2.315154790878296
Validation loss: 2.0927687601376603

Epoch: 6| Step: 4
Training loss: 2.7020812034606934
Validation loss: 2.1109609347517773

Epoch: 6| Step: 5
Training loss: 2.5462682247161865
Validation loss: 2.144380474603304

Epoch: 6| Step: 6
Training loss: 2.441349744796753
Validation loss: 2.183323262840189

Epoch: 6| Step: 7
Training loss: 2.628652572631836
Validation loss: 2.182380904433548

Epoch: 6| Step: 8
Training loss: 1.8064554929733276
Validation loss: 2.1273927175870506

Epoch: 6| Step: 9
Training loss: 2.159144401550293
Validation loss: 2.0885558589812248

Epoch: 6| Step: 10
Training loss: 2.7637720108032227
Validation loss: 2.0619304667236986

Epoch: 6| Step: 11
Training loss: 2.5122833251953125
Validation loss: 2.0452969510068177

Epoch: 6| Step: 12
Training loss: 2.3129332065582275
Validation loss: 2.0498748338350685

Epoch: 6| Step: 13
Training loss: 2.2057385444641113
Validation loss: 2.0590088969917706

Epoch: 112| Step: 0
Training loss: 2.4187982082366943
Validation loss: 2.0586859615900184

Epoch: 6| Step: 1
Training loss: 2.229579448699951
Validation loss: 2.056787976654627

Epoch: 6| Step: 2
Training loss: 2.4717514514923096
Validation loss: 2.0618587078586703

Epoch: 6| Step: 3
Training loss: 2.2786598205566406
Validation loss: 2.0576250476221882

Epoch: 6| Step: 4
Training loss: 2.3444926738739014
Validation loss: 2.049461986428948

Epoch: 6| Step: 5
Training loss: 2.279329538345337
Validation loss: 2.0526370438196326

Epoch: 6| Step: 6
Training loss: 2.0231807231903076
Validation loss: 2.065297842025757

Epoch: 6| Step: 7
Training loss: 2.4504470825195312
Validation loss: 2.0799059662767636

Epoch: 6| Step: 8
Training loss: 2.4272193908691406
Validation loss: 2.0999798492718766

Epoch: 6| Step: 9
Training loss: 2.675093650817871
Validation loss: 2.1201551293814056

Epoch: 6| Step: 10
Training loss: 2.499901533126831
Validation loss: 2.167629882853518

Epoch: 6| Step: 11
Training loss: 3.1549856662750244
Validation loss: 2.2193970398236345

Epoch: 6| Step: 12
Training loss: 2.326477527618408
Validation loss: 2.2073790924523466

Epoch: 6| Step: 13
Training loss: 2.5866339206695557
Validation loss: 2.1669413235879715

Epoch: 113| Step: 0
Training loss: 2.2305796146392822
Validation loss: 2.124952754666728

Epoch: 6| Step: 1
Training loss: 2.846271514892578
Validation loss: 2.0775228905421432

Epoch: 6| Step: 2
Training loss: 2.025524139404297
Validation loss: 2.0767520755849858

Epoch: 6| Step: 3
Training loss: 2.19625186920166
Validation loss: 2.065453901085802

Epoch: 6| Step: 4
Training loss: 2.681140422821045
Validation loss: 2.067887356204371

Epoch: 6| Step: 5
Training loss: 1.8038946390151978
Validation loss: 2.063908633365426

Epoch: 6| Step: 6
Training loss: 2.42177677154541
Validation loss: 2.063008366092559

Epoch: 6| Step: 7
Training loss: 3.1075661182403564
Validation loss: 2.0615435825881137

Epoch: 6| Step: 8
Training loss: 2.783982753753662
Validation loss: 2.064128574504647

Epoch: 6| Step: 9
Training loss: 2.2944159507751465
Validation loss: 2.0571056681294597

Epoch: 6| Step: 10
Training loss: 2.676959753036499
Validation loss: 2.0673541971432265

Epoch: 6| Step: 11
Training loss: 1.6213345527648926
Validation loss: 2.066910793704371

Epoch: 6| Step: 12
Training loss: 2.394134283065796
Validation loss: 2.080046346110682

Epoch: 6| Step: 13
Training loss: 2.408966302871704
Validation loss: 2.0890144327635407

Epoch: 114| Step: 0
Training loss: 2.094381093978882
Validation loss: 2.100082923007268

Epoch: 6| Step: 1
Training loss: 2.095796585083008
Validation loss: 2.1087879032217045

Epoch: 6| Step: 2
Training loss: 2.335977077484131
Validation loss: 2.095926236080867

Epoch: 6| Step: 3
Training loss: 1.4795198440551758
Validation loss: 2.093401849910777

Epoch: 6| Step: 4
Training loss: 2.5832018852233887
Validation loss: 2.094412877995481

Epoch: 6| Step: 5
Training loss: 2.7264018058776855
Validation loss: 2.0859587525808685

Epoch: 6| Step: 6
Training loss: 3.013981819152832
Validation loss: 2.079144504762465

Epoch: 6| Step: 7
Training loss: 2.0012784004211426
Validation loss: 2.064128880859703

Epoch: 6| Step: 8
Training loss: 2.5164222717285156
Validation loss: 2.062867941394929

Epoch: 6| Step: 9
Training loss: 2.2618885040283203
Validation loss: 2.054026617798754

Epoch: 6| Step: 10
Training loss: 2.040867328643799
Validation loss: 2.04963949162473

Epoch: 6| Step: 11
Training loss: 2.538900852203369
Validation loss: 2.0497985552716

Epoch: 6| Step: 12
Training loss: 2.941602945327759
Validation loss: 2.0463713010152182

Epoch: 6| Step: 13
Training loss: 3.1021337509155273
Validation loss: 2.0494185750202467

Epoch: 115| Step: 0
Training loss: 2.0413706302642822
Validation loss: 2.0432092784553446

Epoch: 6| Step: 1
Training loss: 2.5519251823425293
Validation loss: 2.0421064079448743

Epoch: 6| Step: 2
Training loss: 1.5495343208312988
Validation loss: 2.0529492516671457

Epoch: 6| Step: 3
Training loss: 1.9409037828445435
Validation loss: 2.086142199013823

Epoch: 6| Step: 4
Training loss: 1.671313762664795
Validation loss: 2.089512122574673

Epoch: 6| Step: 5
Training loss: 2.619779109954834
Validation loss: 2.1013732443573656

Epoch: 6| Step: 6
Training loss: 2.8098902702331543
Validation loss: 2.0915002130693003

Epoch: 6| Step: 7
Training loss: 2.6161868572235107
Validation loss: 2.1020127816866805

Epoch: 6| Step: 8
Training loss: 2.2016518115997314
Validation loss: 2.1276018055536414

Epoch: 6| Step: 9
Training loss: 2.1099791526794434
Validation loss: 2.1531887387716644

Epoch: 6| Step: 10
Training loss: 2.9349493980407715
Validation loss: 2.130295862433731

Epoch: 6| Step: 11
Training loss: 2.9162774085998535
Validation loss: 2.0963841676712036

Epoch: 6| Step: 12
Training loss: 3.0802552700042725
Validation loss: 2.0734133412761073

Epoch: 6| Step: 13
Training loss: 2.077378988265991
Validation loss: 2.0670763600257134

Epoch: 116| Step: 0
Training loss: 1.6144565343856812
Validation loss: 2.0609300828749135

Epoch: 6| Step: 1
Training loss: 1.779088020324707
Validation loss: 2.0553258939455916

Epoch: 6| Step: 2
Training loss: 2.7701334953308105
Validation loss: 2.062780036721178

Epoch: 6| Step: 3
Training loss: 2.39520001411438
Validation loss: 2.080504528937801

Epoch: 6| Step: 4
Training loss: 1.779842495918274
Validation loss: 2.0824359155470327

Epoch: 6| Step: 5
Training loss: 2.5724971294403076
Validation loss: 2.0749431835707797

Epoch: 6| Step: 6
Training loss: 2.9475204944610596
Validation loss: 2.075476997642107

Epoch: 6| Step: 7
Training loss: 2.757750988006592
Validation loss: 2.0772147793923654

Epoch: 6| Step: 8
Training loss: 2.8564672470092773
Validation loss: 2.0910441644730104

Epoch: 6| Step: 9
Training loss: 2.004138946533203
Validation loss: 2.098118738461566

Epoch: 6| Step: 10
Training loss: 2.0293662548065186
Validation loss: 2.113802825250933

Epoch: 6| Step: 11
Training loss: 2.6464638710021973
Validation loss: 2.1213372676603255

Epoch: 6| Step: 12
Training loss: 2.6996545791625977
Validation loss: 2.113430203930024

Epoch: 6| Step: 13
Training loss: 2.0788557529449463
Validation loss: 2.0863085869819886

Epoch: 117| Step: 0
Training loss: 2.447550058364868
Validation loss: 2.08500172245887

Epoch: 6| Step: 1
Training loss: 1.871978521347046
Validation loss: 2.0550461353794223

Epoch: 6| Step: 2
Training loss: 2.447600841522217
Validation loss: 2.0640767210273334

Epoch: 6| Step: 3
Training loss: 2.9193153381347656
Validation loss: 2.0571979630377983

Epoch: 6| Step: 4
Training loss: 2.666269302368164
Validation loss: 2.061743390175604

Epoch: 6| Step: 5
Training loss: 1.5332173109054565
Validation loss: 2.068721088030005

Epoch: 6| Step: 6
Training loss: 2.772730588912964
Validation loss: 2.056119954714211

Epoch: 6| Step: 7
Training loss: 2.286503791809082
Validation loss: 2.0768393316576557

Epoch: 6| Step: 8
Training loss: 2.7486844062805176
Validation loss: 2.078970786063902

Epoch: 6| Step: 9
Training loss: 1.6206293106079102
Validation loss: 2.0568575500160136

Epoch: 6| Step: 10
Training loss: 2.813425302505493
Validation loss: 2.0564361208228656

Epoch: 6| Step: 11
Training loss: 2.3550305366516113
Validation loss: 2.0472001414145193

Epoch: 6| Step: 12
Training loss: 2.2074084281921387
Validation loss: 2.040020165904876

Epoch: 6| Step: 13
Training loss: 2.121342897415161
Validation loss: 2.0500742209854947

Epoch: 118| Step: 0
Training loss: 2.3739817142486572
Validation loss: 2.0501738299605665

Epoch: 6| Step: 1
Training loss: 1.9716228246688843
Validation loss: 2.0410482703998523

Epoch: 6| Step: 2
Training loss: 2.617964744567871
Validation loss: 2.043130220905427

Epoch: 6| Step: 3
Training loss: 2.233452796936035
Validation loss: 2.043902817592826

Epoch: 6| Step: 4
Training loss: 2.6280932426452637
Validation loss: 2.066045379125944

Epoch: 6| Step: 5
Training loss: 2.6963839530944824
Validation loss: 2.0758798096769597

Epoch: 6| Step: 6
Training loss: 2.1288399696350098
Validation loss: 2.0599961280822754

Epoch: 6| Step: 7
Training loss: 2.190248489379883
Validation loss: 2.040284384963333

Epoch: 6| Step: 8
Training loss: 1.9373936653137207
Validation loss: 2.0254229243083666

Epoch: 6| Step: 9
Training loss: 2.4847323894500732
Validation loss: 2.0420382663767827

Epoch: 6| Step: 10
Training loss: 2.523426055908203
Validation loss: 2.036394739663729

Epoch: 6| Step: 11
Training loss: 2.5783004760742188
Validation loss: 2.0360247986291045

Epoch: 6| Step: 12
Training loss: 2.194380283355713
Validation loss: 2.023567408643743

Epoch: 6| Step: 13
Training loss: 2.72861909866333
Validation loss: 2.028238042708366

Epoch: 119| Step: 0
Training loss: 2.747184991836548
Validation loss: 2.0126678917997625

Epoch: 6| Step: 1
Training loss: 1.8359601497650146
Validation loss: 2.028493127515239

Epoch: 6| Step: 2
Training loss: 2.194105625152588
Validation loss: 2.050514708283127

Epoch: 6| Step: 3
Training loss: 2.276116132736206
Validation loss: 2.06149818435792

Epoch: 6| Step: 4
Training loss: 2.2031946182250977
Validation loss: 2.0669721275247555

Epoch: 6| Step: 5
Training loss: 2.5905585289001465
Validation loss: 2.097402165012975

Epoch: 6| Step: 6
Training loss: 2.066094398498535
Validation loss: 2.115457950099822

Epoch: 6| Step: 7
Training loss: 2.1752798557281494
Validation loss: 2.166158583856398

Epoch: 6| Step: 8
Training loss: 1.8800346851348877
Validation loss: 2.1343136513105003

Epoch: 6| Step: 9
Training loss: 3.8334457874298096
Validation loss: 2.1014873763566375

Epoch: 6| Step: 10
Training loss: 2.9678988456726074
Validation loss: 2.073282341803274

Epoch: 6| Step: 11
Training loss: 1.5191071033477783
Validation loss: 2.086891287116594

Epoch: 6| Step: 12
Training loss: 2.2258152961730957
Validation loss: 2.0538157314382572

Epoch: 6| Step: 13
Training loss: 2.4171533584594727
Validation loss: 2.033216776386384

Epoch: 120| Step: 0
Training loss: 2.3324739933013916
Validation loss: 2.023809407346992

Epoch: 6| Step: 1
Training loss: 2.099074602127075
Validation loss: 2.0185348936306533

Epoch: 6| Step: 2
Training loss: 2.469541549682617
Validation loss: 2.018625533708962

Epoch: 6| Step: 3
Training loss: 2.5765976905822754
Validation loss: 2.022704847397343

Epoch: 6| Step: 4
Training loss: 2.381751775741577
Validation loss: 2.0206368841150755

Epoch: 6| Step: 5
Training loss: 2.8158679008483887
Validation loss: 2.0202858063482467

Epoch: 6| Step: 6
Training loss: 1.4782756567001343
Validation loss: 2.024648509999757

Epoch: 6| Step: 7
Training loss: 2.9880566596984863
Validation loss: 2.025662942599225

Epoch: 6| Step: 8
Training loss: 2.363032341003418
Validation loss: 2.0287054302871868

Epoch: 6| Step: 9
Training loss: 2.2367167472839355
Validation loss: 2.037217183779645

Epoch: 6| Step: 10
Training loss: 2.472893238067627
Validation loss: 2.0352647240443895

Epoch: 6| Step: 11
Training loss: 2.4189062118530273
Validation loss: 2.0521284482812368

Epoch: 6| Step: 12
Training loss: 2.3668432235717773
Validation loss: 2.082463261901691

Epoch: 6| Step: 13
Training loss: 1.7937030792236328
Validation loss: 2.110176706826815

Epoch: 121| Step: 0
Training loss: 2.297410011291504
Validation loss: 2.118480472154515

Epoch: 6| Step: 1
Training loss: 2.880789279937744
Validation loss: 2.09199922315536

Epoch: 6| Step: 2
Training loss: 1.940456748008728
Validation loss: 2.077151325441176

Epoch: 6| Step: 3
Training loss: 2.1685714721679688
Validation loss: 2.0590238237893708

Epoch: 6| Step: 4
Training loss: 2.3715217113494873
Validation loss: 2.050454519128287

Epoch: 6| Step: 5
Training loss: 2.2484841346740723
Validation loss: 2.0397093270414617

Epoch: 6| Step: 6
Training loss: 2.5353708267211914
Validation loss: 2.041306577703004

Epoch: 6| Step: 7
Training loss: 2.6287600994110107
Validation loss: 2.0416843583506923

Epoch: 6| Step: 8
Training loss: 2.2505269050598145
Validation loss: 2.0472896137545185

Epoch: 6| Step: 9
Training loss: 1.626930594444275
Validation loss: 2.0403798164859897

Epoch: 6| Step: 10
Training loss: 2.656066417694092
Validation loss: 2.0306777082463747

Epoch: 6| Step: 11
Training loss: 2.4247658252716064
Validation loss: 2.023262245680696

Epoch: 6| Step: 12
Training loss: 2.0717506408691406
Validation loss: 2.0511026202991443

Epoch: 6| Step: 13
Training loss: 2.8226284980773926
Validation loss: 2.0749860399512836

Epoch: 122| Step: 0
Training loss: 1.6906869411468506
Validation loss: 2.1105928779930196

Epoch: 6| Step: 1
Training loss: 2.4865736961364746
Validation loss: 2.0857463241905294

Epoch: 6| Step: 2
Training loss: 1.9277855157852173
Validation loss: 2.080630156301683

Epoch: 6| Step: 3
Training loss: 2.1061575412750244
Validation loss: 2.056276987957698

Epoch: 6| Step: 4
Training loss: 2.731558322906494
Validation loss: 2.0443072613849433

Epoch: 6| Step: 5
Training loss: 2.320755958557129
Validation loss: 2.020203628847676

Epoch: 6| Step: 6
Training loss: 2.387483835220337
Validation loss: 2.018968000206896

Epoch: 6| Step: 7
Training loss: 2.147141456604004
Validation loss: 2.0231474240620932

Epoch: 6| Step: 8
Training loss: 1.88746976852417
Validation loss: 2.02187241021023

Epoch: 6| Step: 9
Training loss: 2.733368396759033
Validation loss: 1.997432936904251

Epoch: 6| Step: 10
Training loss: 2.622109889984131
Validation loss: 2.0023738261192077

Epoch: 6| Step: 11
Training loss: 2.8896827697753906
Validation loss: 2.0282596426625408

Epoch: 6| Step: 12
Training loss: 1.6228995323181152
Validation loss: 2.037145406969132

Epoch: 6| Step: 13
Training loss: 3.4316134452819824
Validation loss: 2.06985572332977

Epoch: 123| Step: 0
Training loss: 2.2688956260681152
Validation loss: 2.066645271034651

Epoch: 6| Step: 1
Training loss: 2.1415934562683105
Validation loss: 2.0613263640352475

Epoch: 6| Step: 2
Training loss: 2.632110118865967
Validation loss: 2.0599194316453833

Epoch: 6| Step: 3
Training loss: 2.633624315261841
Validation loss: 2.034748113283547

Epoch: 6| Step: 4
Training loss: 1.8515018224716187
Validation loss: 2.0176105729995237

Epoch: 6| Step: 5
Training loss: 2.2115471363067627
Validation loss: 2.0121325728713826

Epoch: 6| Step: 6
Training loss: 1.9539800882339478
Validation loss: 2.0145231831458306

Epoch: 6| Step: 7
Training loss: 3.262779712677002
Validation loss: 2.013440757669428

Epoch: 6| Step: 8
Training loss: 1.9853261709213257
Validation loss: 2.023782214810771

Epoch: 6| Step: 9
Training loss: 2.163648843765259
Validation loss: 2.022366282760456

Epoch: 6| Step: 10
Training loss: 2.5680809020996094
Validation loss: 2.054432906130309

Epoch: 6| Step: 11
Training loss: 2.157209634780884
Validation loss: 2.099316084256736

Epoch: 6| Step: 12
Training loss: 2.12469744682312
Validation loss: 2.151854840658044

Epoch: 6| Step: 13
Training loss: 3.397646903991699
Validation loss: 2.187456184817899

Epoch: 124| Step: 0
Training loss: 1.747908353805542
Validation loss: 2.176902776123375

Epoch: 6| Step: 1
Training loss: 1.8505887985229492
Validation loss: 2.1100637348749305

Epoch: 6| Step: 2
Training loss: 1.9204881191253662
Validation loss: 2.029960657960625

Epoch: 6| Step: 3
Training loss: 3.0081896781921387
Validation loss: 1.9963097213416972

Epoch: 6| Step: 4
Training loss: 2.6108264923095703
Validation loss: 1.9988591696626397

Epoch: 6| Step: 5
Training loss: 2.128685712814331
Validation loss: 2.0040327554107993

Epoch: 6| Step: 6
Training loss: 2.385740280151367
Validation loss: 2.009154353090512

Epoch: 6| Step: 7
Training loss: 2.107990026473999
Validation loss: 2.0004494831126225

Epoch: 6| Step: 8
Training loss: 2.7694411277770996
Validation loss: 2.0008229388985583

Epoch: 6| Step: 9
Training loss: 2.7799429893493652
Validation loss: 1.994006626067623

Epoch: 6| Step: 10
Training loss: 1.815943717956543
Validation loss: 1.993741964781156

Epoch: 6| Step: 11
Training loss: 2.5894975662231445
Validation loss: 2.0084112382704213

Epoch: 6| Step: 12
Training loss: 2.4283719062805176
Validation loss: 2.016773230286055

Epoch: 6| Step: 13
Training loss: 2.800872802734375
Validation loss: 2.0670054458802745

Epoch: 125| Step: 0
Training loss: 2.289374589920044
Validation loss: 2.1001456604208997

Epoch: 6| Step: 1
Training loss: 1.957930088043213
Validation loss: 2.061586477423227

Epoch: 6| Step: 2
Training loss: 2.5790023803710938
Validation loss: 2.0202032545561432

Epoch: 6| Step: 3
Training loss: 2.4357659816741943
Validation loss: 2.0184822454247424

Epoch: 6| Step: 4
Training loss: 2.4863898754119873
Validation loss: 2.0100761305901313

Epoch: 6| Step: 5
Training loss: 1.9908719062805176
Validation loss: 2.0052985798928047

Epoch: 6| Step: 6
Training loss: 1.681464672088623
Validation loss: 2.0217181815895984

Epoch: 6| Step: 7
Training loss: 2.4921770095825195
Validation loss: 2.0417485647304083

Epoch: 6| Step: 8
Training loss: 1.9999282360076904
Validation loss: 2.0425198513974427

Epoch: 6| Step: 9
Training loss: 3.046440601348877
Validation loss: 2.0615855391307543

Epoch: 6| Step: 10
Training loss: 2.1636736392974854
Validation loss: 2.048024280096895

Epoch: 6| Step: 11
Training loss: 2.2390296459198
Validation loss: 2.044283236226728

Epoch: 6| Step: 12
Training loss: 2.1827359199523926
Validation loss: 2.0422142346700034

Epoch: 6| Step: 13
Training loss: 2.9811227321624756
Validation loss: 2.03968555952913

Epoch: 126| Step: 0
Training loss: 1.6280744075775146
Validation loss: 2.0234305192065496

Epoch: 6| Step: 1
Training loss: 2.2643790245056152
Validation loss: 2.019088691280734

Epoch: 6| Step: 2
Training loss: 2.1882452964782715
Validation loss: 2.0098821475941646

Epoch: 6| Step: 3
Training loss: 2.152512788772583
Validation loss: 2.00345003989435

Epoch: 6| Step: 4
Training loss: 2.633183002471924
Validation loss: 2.003405177465049

Epoch: 6| Step: 5
Training loss: 2.6636264324188232
Validation loss: 2.013540303835305

Epoch: 6| Step: 6
Training loss: 2.64920711517334
Validation loss: 2.0231630943154775

Epoch: 6| Step: 7
Training loss: 2.5261831283569336
Validation loss: 2.0305198725833686

Epoch: 6| Step: 8
Training loss: 2.2561655044555664
Validation loss: 2.029493583145962

Epoch: 6| Step: 9
Training loss: 2.501199722290039
Validation loss: 2.0174958808447725

Epoch: 6| Step: 10
Training loss: 2.663012981414795
Validation loss: 2.006690684185233

Epoch: 6| Step: 11
Training loss: 1.9708802700042725
Validation loss: 1.9976427939630323

Epoch: 6| Step: 12
Training loss: 2.3942747116088867
Validation loss: 2.001637146037112

Epoch: 6| Step: 13
Training loss: 1.1949716806411743
Validation loss: 2.0075830336539977

Epoch: 127| Step: 0
Training loss: 3.14925217628479
Validation loss: 2.007773906953873

Epoch: 6| Step: 1
Training loss: 2.508223533630371
Validation loss: 2.007441019499174

Epoch: 6| Step: 2
Training loss: 2.101914882659912
Validation loss: 1.9971951553898473

Epoch: 6| Step: 3
Training loss: 2.1429853439331055
Validation loss: 1.993222055896636

Epoch: 6| Step: 4
Training loss: 2.4487557411193848
Validation loss: 1.9916170348403275

Epoch: 6| Step: 5
Training loss: 2.4347219467163086
Validation loss: 1.9962161010311497

Epoch: 6| Step: 6
Training loss: 1.9491280317306519
Validation loss: 1.984234389438424

Epoch: 6| Step: 7
Training loss: 1.804736614227295
Validation loss: 1.998992230302544

Epoch: 6| Step: 8
Training loss: 2.264777183532715
Validation loss: 2.0203442573547363

Epoch: 6| Step: 9
Training loss: 2.3101089000701904
Validation loss: 2.0380808845643075

Epoch: 6| Step: 10
Training loss: 2.1910274028778076
Validation loss: 2.094449309892552

Epoch: 6| Step: 11
Training loss: 2.5644757747650146
Validation loss: 2.1703994274139404

Epoch: 6| Step: 12
Training loss: 2.2493386268615723
Validation loss: 2.201920086337674

Epoch: 6| Step: 13
Training loss: 1.8368386030197144
Validation loss: 2.1920894333111343

Epoch: 128| Step: 0
Training loss: 1.9830683469772339
Validation loss: 2.2352006153393815

Epoch: 6| Step: 1
Training loss: 2.594423294067383
Validation loss: 2.207207509266433

Epoch: 6| Step: 2
Training loss: 1.8349988460540771
Validation loss: 2.2129529778675368

Epoch: 6| Step: 3
Training loss: 2.72571063041687
Validation loss: 2.179426937974909

Epoch: 6| Step: 4
Training loss: 1.9678399562835693
Validation loss: 2.1280926299351517

Epoch: 6| Step: 5
Training loss: 1.9715373516082764
Validation loss: 2.027412724751298

Epoch: 6| Step: 6
Training loss: 3.156073808670044
Validation loss: 1.9834854705359346

Epoch: 6| Step: 7
Training loss: 2.3211286067962646
Validation loss: 1.9988208945079515

Epoch: 6| Step: 8
Training loss: 2.6477952003479004
Validation loss: 2.0050114918780584

Epoch: 6| Step: 9
Training loss: 1.99906587600708
Validation loss: 2.0180311472185197

Epoch: 6| Step: 10
Training loss: 2.455423593521118
Validation loss: 2.0281609617253786

Epoch: 6| Step: 11
Training loss: 2.699958324432373
Validation loss: 2.0344285054873397

Epoch: 6| Step: 12
Training loss: 2.167395830154419
Validation loss: 2.031516203316309

Epoch: 6| Step: 13
Training loss: 2.3596463203430176
Validation loss: 2.046601608235349

Epoch: 129| Step: 0
Training loss: 2.312628746032715
Validation loss: 2.040101966550273

Epoch: 6| Step: 1
Training loss: 1.9876439571380615
Validation loss: 2.0295374034553446

Epoch: 6| Step: 2
Training loss: 2.163386821746826
Validation loss: 2.0151892195465746

Epoch: 6| Step: 3
Training loss: 2.973590612411499
Validation loss: 2.031750391888362

Epoch: 6| Step: 4
Training loss: 2.1325721740722656
Validation loss: 2.085225666722944

Epoch: 6| Step: 5
Training loss: 2.223036766052246
Validation loss: 2.116677491895614

Epoch: 6| Step: 6
Training loss: 2.41823673248291
Validation loss: 2.171938634687854

Epoch: 6| Step: 7
Training loss: 3.1438283920288086
Validation loss: 2.17948583633669

Epoch: 6| Step: 8
Training loss: 2.504756212234497
Validation loss: 2.154302693182422

Epoch: 6| Step: 9
Training loss: 1.635781168937683
Validation loss: 2.1262381051176336

Epoch: 6| Step: 10
Training loss: 2.434896945953369
Validation loss: 2.0757062960696477

Epoch: 6| Step: 11
Training loss: 2.5028536319732666
Validation loss: 2.0452527871695896

Epoch: 6| Step: 12
Training loss: 2.194478750228882
Validation loss: 2.030716167983188

Epoch: 6| Step: 13
Training loss: 1.5982707738876343
Validation loss: 2.016484537432271

Epoch: 130| Step: 0
Training loss: 1.927669644355774
Validation loss: 2.025801529166519

Epoch: 6| Step: 1
Training loss: 2.709981918334961
Validation loss: 2.0384876779330674

Epoch: 6| Step: 2
Training loss: 2.715442657470703
Validation loss: 2.0508307462097495

Epoch: 6| Step: 3
Training loss: 2.183013677597046
Validation loss: 2.074627935245473

Epoch: 6| Step: 4
Training loss: 2.093015670776367
Validation loss: 2.0750920554643035

Epoch: 6| Step: 5
Training loss: 2.678635597229004
Validation loss: 2.0755151728148102

Epoch: 6| Step: 6
Training loss: 1.643629550933838
Validation loss: 2.0702953774441957

Epoch: 6| Step: 7
Training loss: 1.566593885421753
Validation loss: 2.0710893907854633

Epoch: 6| Step: 8
Training loss: 2.669738531112671
Validation loss: 2.0640065900741087

Epoch: 6| Step: 9
Training loss: 2.4494619369506836
Validation loss: 2.0778816182126283

Epoch: 6| Step: 10
Training loss: 2.0784261226654053
Validation loss: 2.0600749292681293

Epoch: 6| Step: 11
Training loss: 1.8793752193450928
Validation loss: 2.046167879976252

Epoch: 6| Step: 12
Training loss: 2.9085922241210938
Validation loss: 2.02881964560478

Epoch: 6| Step: 13
Training loss: 2.649129867553711
Validation loss: 2.007720631937827

Epoch: 131| Step: 0
Training loss: 2.7533016204833984
Validation loss: 2.020425342744397

Epoch: 6| Step: 1
Training loss: 1.4417498111724854
Validation loss: 2.0302344227349884

Epoch: 6| Step: 2
Training loss: 2.3005917072296143
Validation loss: 2.0271141939265753

Epoch: 6| Step: 3
Training loss: 2.5510666370391846
Validation loss: 2.0365576923534436

Epoch: 6| Step: 4
Training loss: 2.542569160461426
Validation loss: 2.055077577149996

Epoch: 6| Step: 5
Training loss: 2.727566719055176
Validation loss: 2.077577496087679

Epoch: 6| Step: 6
Training loss: 2.4016003608703613
Validation loss: 2.083912503334784

Epoch: 6| Step: 7
Training loss: 2.9242587089538574
Validation loss: 2.0815945568905083

Epoch: 6| Step: 8
Training loss: 1.8836870193481445
Validation loss: 2.0603255853858045

Epoch: 6| Step: 9
Training loss: 2.426572561264038
Validation loss: 2.04004382318066

Epoch: 6| Step: 10
Training loss: 2.4707069396972656
Validation loss: 2.0226053666043025

Epoch: 6| Step: 11
Training loss: 1.625449299812317
Validation loss: 2.0149905835428545

Epoch: 6| Step: 12
Training loss: 1.3902716636657715
Validation loss: 2.020166350949195

Epoch: 6| Step: 13
Training loss: 2.446169137954712
Validation loss: 2.021711339232742

Epoch: 132| Step: 0
Training loss: 1.9598912000656128
Validation loss: 2.0216588256179646

Epoch: 6| Step: 1
Training loss: 2.3437576293945312
Validation loss: 2.0243616539944886

Epoch: 6| Step: 2
Training loss: 1.820345401763916
Validation loss: 2.0253184572342904

Epoch: 6| Step: 3
Training loss: 2.570873498916626
Validation loss: 2.0269334444435696

Epoch: 6| Step: 4
Training loss: 2.1041831970214844
Validation loss: 2.0288918261886923

Epoch: 6| Step: 5
Training loss: 2.663026809692383
Validation loss: 2.027090113650086

Epoch: 6| Step: 6
Training loss: 1.704402208328247
Validation loss: 2.01072851304085

Epoch: 6| Step: 7
Training loss: 3.0537495613098145
Validation loss: 2.0117159851135744

Epoch: 6| Step: 8
Training loss: 1.8796417713165283
Validation loss: 2.011012541350498

Epoch: 6| Step: 9
Training loss: 2.7003140449523926
Validation loss: 2.012517798331476

Epoch: 6| Step: 10
Training loss: 1.735597014427185
Validation loss: 2.007110949485533

Epoch: 6| Step: 11
Training loss: 2.403947353363037
Validation loss: 2.0322675871592697

Epoch: 6| Step: 12
Training loss: 2.283236026763916
Validation loss: 2.0166660008891935

Epoch: 6| Step: 13
Training loss: 2.6125667095184326
Validation loss: 2.0150915884202525

Epoch: 133| Step: 0
Training loss: 2.0900845527648926
Validation loss: 2.015967058879073

Epoch: 6| Step: 1
Training loss: 1.5396555662155151
Validation loss: 2.0095713471853607

Epoch: 6| Step: 2
Training loss: 3.3336431980133057
Validation loss: 2.0014165011785363

Epoch: 6| Step: 3
Training loss: 2.7305946350097656
Validation loss: 1.992015879641297

Epoch: 6| Step: 4
Training loss: 2.4318666458129883
Validation loss: 1.9753455436357887

Epoch: 6| Step: 5
Training loss: 2.316577196121216
Validation loss: 1.9708307173944288

Epoch: 6| Step: 6
Training loss: 1.484740972518921
Validation loss: 1.9882654387463805

Epoch: 6| Step: 7
Training loss: 2.297166347503662
Validation loss: 2.018518199202835

Epoch: 6| Step: 8
Training loss: 2.2522566318511963
Validation loss: 2.0477166201478694

Epoch: 6| Step: 9
Training loss: 2.649261713027954
Validation loss: 2.0773992410270115

Epoch: 6| Step: 10
Training loss: 2.020693302154541
Validation loss: 2.1287458583872807

Epoch: 6| Step: 11
Training loss: 2.332146644592285
Validation loss: 2.163306669522357

Epoch: 6| Step: 12
Training loss: 2.010745048522949
Validation loss: 2.155583358580066

Epoch: 6| Step: 13
Training loss: 2.3375978469848633
Validation loss: 2.1029926038557485

Epoch: 134| Step: 0
Training loss: 1.8502631187438965
Validation loss: 2.0618653066696657

Epoch: 6| Step: 1
Training loss: 1.7447872161865234
Validation loss: 2.0206483692251225

Epoch: 6| Step: 2
Training loss: 2.4779586791992188
Validation loss: 1.9838345794267551

Epoch: 6| Step: 3
Training loss: 2.870946168899536
Validation loss: 1.9892147689737298

Epoch: 6| Step: 4
Training loss: 1.7549219131469727
Validation loss: 1.986410899828839

Epoch: 6| Step: 5
Training loss: 2.9096531867980957
Validation loss: 1.974735700955955

Epoch: 6| Step: 6
Training loss: 2.9869003295898438
Validation loss: 1.9831931616670342

Epoch: 6| Step: 7
Training loss: 2.5174484252929688
Validation loss: 1.9805346612007386

Epoch: 6| Step: 8
Training loss: 1.7547426223754883
Validation loss: 1.982987993506975

Epoch: 6| Step: 9
Training loss: 2.009185791015625
Validation loss: 1.9804269139484694

Epoch: 6| Step: 10
Training loss: 1.5526039600372314
Validation loss: 1.993648967435283

Epoch: 6| Step: 11
Training loss: 2.4629111289978027
Validation loss: 2.0067091885433403

Epoch: 6| Step: 12
Training loss: 1.8989742994308472
Validation loss: 2.001170663423436

Epoch: 6| Step: 13
Training loss: 2.7405927181243896
Validation loss: 2.0179088628420265

Epoch: 135| Step: 0
Training loss: 2.010274887084961
Validation loss: 2.035586248161972

Epoch: 6| Step: 1
Training loss: 2.6519696712493896
Validation loss: 2.0115449813104447

Epoch: 6| Step: 2
Training loss: 2.2714459896087646
Validation loss: 2.00604223820471

Epoch: 6| Step: 3
Training loss: 2.3756766319274902
Validation loss: 2.0117731760906916

Epoch: 6| Step: 4
Training loss: 2.391726016998291
Validation loss: 2.0169139305750527

Epoch: 6| Step: 5
Training loss: 2.0523014068603516
Validation loss: 2.030358996442569

Epoch: 6| Step: 6
Training loss: 1.4027366638183594
Validation loss: 2.040242373302419

Epoch: 6| Step: 7
Training loss: 2.190136671066284
Validation loss: 2.0600213773788942

Epoch: 6| Step: 8
Training loss: 2.372244358062744
Validation loss: 2.0718266143593738

Epoch: 6| Step: 9
Training loss: 2.738913059234619
Validation loss: 2.0772892916074364

Epoch: 6| Step: 10
Training loss: 1.8670268058776855
Validation loss: 2.0763592053485174

Epoch: 6| Step: 11
Training loss: 3.041332721710205
Validation loss: 2.1236265500386557

Epoch: 6| Step: 12
Training loss: 2.172496795654297
Validation loss: 2.151810707584504

Epoch: 6| Step: 13
Training loss: 1.5735615491867065
Validation loss: 2.151436772397769

Epoch: 136| Step: 0
Training loss: 2.2906172275543213
Validation loss: 2.1134568388744066

Epoch: 6| Step: 1
Training loss: 2.066535472869873
Validation loss: 2.087866093522759

Epoch: 6| Step: 2
Training loss: 2.274240016937256
Validation loss: 2.0584267698308474

Epoch: 6| Step: 3
Training loss: 2.520486831665039
Validation loss: 2.038975651546191

Epoch: 6| Step: 4
Training loss: 2.375627040863037
Validation loss: 1.9994811152899137

Epoch: 6| Step: 5
Training loss: 2.686656951904297
Validation loss: 1.9762225920154202

Epoch: 6| Step: 6
Training loss: 2.2641477584838867
Validation loss: 1.972504242773979

Epoch: 6| Step: 7
Training loss: 2.129462718963623
Validation loss: 1.9825412855353406

Epoch: 6| Step: 8
Training loss: 2.5795483589172363
Validation loss: 1.965435879204863

Epoch: 6| Step: 9
Training loss: 2.0314249992370605
Validation loss: 1.9652709243118123

Epoch: 6| Step: 10
Training loss: 2.5726256370544434
Validation loss: 1.9576743277170325

Epoch: 6| Step: 11
Training loss: 1.2895605564117432
Validation loss: 1.9670361113804642

Epoch: 6| Step: 12
Training loss: 1.8180979490280151
Validation loss: 1.9811912223856936

Epoch: 6| Step: 13
Training loss: 2.891594648361206
Validation loss: 2.054787569148566

Epoch: 137| Step: 0
Training loss: 2.3208558559417725
Validation loss: 2.1072333628131497

Epoch: 6| Step: 1
Training loss: 2.1505630016326904
Validation loss: 2.1829102385428643

Epoch: 6| Step: 2
Training loss: 2.512502431869507
Validation loss: 2.166161888389177

Epoch: 6| Step: 3
Training loss: 2.013822555541992
Validation loss: 2.0879974134506716

Epoch: 6| Step: 4
Training loss: 2.046757698059082
Validation loss: 2.028136517411919

Epoch: 6| Step: 5
Training loss: 2.58231520652771
Validation loss: 1.9692527568468483

Epoch: 6| Step: 6
Training loss: 1.4468436241149902
Validation loss: 1.9638974653777255

Epoch: 6| Step: 7
Training loss: 2.168837785720825
Validation loss: 1.9844880565520255

Epoch: 6| Step: 8
Training loss: 2.4298789501190186
Validation loss: 2.020487675102808

Epoch: 6| Step: 9
Training loss: 2.6999197006225586
Validation loss: 2.0416479033808552

Epoch: 6| Step: 10
Training loss: 2.2964420318603516
Validation loss: 2.074367038665279

Epoch: 6| Step: 11
Training loss: 2.5992178916931152
Validation loss: 2.0825027163310716

Epoch: 6| Step: 12
Training loss: 2.690520763397217
Validation loss: 2.081011305573166

Epoch: 6| Step: 13
Training loss: 3.031911849975586
Validation loss: 2.0652877797362623

Epoch: 138| Step: 0
Training loss: 2.2324488162994385
Validation loss: 2.0705176168872463

Epoch: 6| Step: 1
Training loss: 2.4045169353485107
Validation loss: 2.0714775887868737

Epoch: 6| Step: 2
Training loss: 1.9999873638153076
Validation loss: 2.0373274972361903

Epoch: 6| Step: 3
Training loss: 2.103294610977173
Validation loss: 2.0300236389201176

Epoch: 6| Step: 4
Training loss: 2.5644564628601074
Validation loss: 2.0527350261647213

Epoch: 6| Step: 5
Training loss: 2.5716052055358887
Validation loss: 2.094560969260431

Epoch: 6| Step: 6
Training loss: 1.7057592868804932
Validation loss: 2.1103061386334

Epoch: 6| Step: 7
Training loss: 2.3513150215148926
Validation loss: 2.118916224407893

Epoch: 6| Step: 8
Training loss: 1.8687257766723633
Validation loss: 2.1282916043394353

Epoch: 6| Step: 9
Training loss: 2.434967041015625
Validation loss: 2.1063605918679187

Epoch: 6| Step: 10
Training loss: 2.096672773361206
Validation loss: 2.079741984285334

Epoch: 6| Step: 11
Training loss: 2.801953077316284
Validation loss: 2.037673468230873

Epoch: 6| Step: 12
Training loss: 2.183973789215088
Validation loss: 2.00698975721995

Epoch: 6| Step: 13
Training loss: 1.965026617050171
Validation loss: 1.9872603185715214

Epoch: 139| Step: 0
Training loss: 2.2428829669952393
Validation loss: 1.9918958346048992

Epoch: 6| Step: 1
Training loss: 1.7795641422271729
Validation loss: 2.0056745698375087

Epoch: 6| Step: 2
Training loss: 1.9514808654785156
Validation loss: 2.006344585008519

Epoch: 6| Step: 3
Training loss: 2.2467305660247803
Validation loss: 2.0236904608306063

Epoch: 6| Step: 4
Training loss: 2.048189640045166
Validation loss: 2.0551804547668784

Epoch: 6| Step: 5
Training loss: 2.1541056632995605
Validation loss: 2.069969174682453

Epoch: 6| Step: 6
Training loss: 2.7314841747283936
Validation loss: 2.0656227142580095

Epoch: 6| Step: 7
Training loss: 1.4942598342895508
Validation loss: 2.06537369502488

Epoch: 6| Step: 8
Training loss: 2.411787271499634
Validation loss: 2.0741263692097

Epoch: 6| Step: 9
Training loss: 2.1278076171875
Validation loss: 2.0496811482214157

Epoch: 6| Step: 10
Training loss: 2.791266918182373
Validation loss: 2.031466878870482

Epoch: 6| Step: 11
Training loss: 2.670903205871582
Validation loss: 2.0212171129001084

Epoch: 6| Step: 12
Training loss: 1.8894095420837402
Validation loss: 2.002271031820646

Epoch: 6| Step: 13
Training loss: 2.2376179695129395
Validation loss: 2.0186665916955597

Epoch: 140| Step: 0
Training loss: 3.087984800338745
Validation loss: 2.0048333573085007

Epoch: 6| Step: 1
Training loss: 1.5695899724960327
Validation loss: 2.006257285353958

Epoch: 6| Step: 2
Training loss: 2.374037027359009
Validation loss: 2.0097024902220695

Epoch: 6| Step: 3
Training loss: 1.8783715963363647
Validation loss: 2.014730183027124

Epoch: 6| Step: 4
Training loss: 2.0326924324035645
Validation loss: 2.0320804683111047

Epoch: 6| Step: 5
Training loss: 2.6980388164520264
Validation loss: 2.0340377720453406

Epoch: 6| Step: 6
Training loss: 2.1878950595855713
Validation loss: 2.032663749110314

Epoch: 6| Step: 7
Training loss: 2.3330931663513184
Validation loss: 2.045958388236261

Epoch: 6| Step: 8
Training loss: 2.1324987411499023
Validation loss: 2.0352022391493603

Epoch: 6| Step: 9
Training loss: 2.2212507724761963
Validation loss: 2.0426239070071968

Epoch: 6| Step: 10
Training loss: 2.0801143646240234
Validation loss: 2.0502844766903947

Epoch: 6| Step: 11
Training loss: 2.322648525238037
Validation loss: 2.065853996943402

Epoch: 6| Step: 12
Training loss: 2.3848085403442383
Validation loss: 2.04674958157283

Epoch: 6| Step: 13
Training loss: 1.1017926931381226
Validation loss: 2.055134869390918

Epoch: 141| Step: 0
Training loss: 1.9620517492294312
Validation loss: 2.0414872361767675

Epoch: 6| Step: 1
Training loss: 1.9775731563568115
Validation loss: 2.0151890003553

Epoch: 6| Step: 2
Training loss: 2.7047929763793945
Validation loss: 2.0017862268673476

Epoch: 6| Step: 3
Training loss: 1.7502779960632324
Validation loss: 2.0105043098490727

Epoch: 6| Step: 4
Training loss: 2.666076183319092
Validation loss: 2.0195556904679988

Epoch: 6| Step: 5
Training loss: 2.06054949760437
Validation loss: 2.0201234176594722

Epoch: 6| Step: 6
Training loss: 2.2173099517822266
Validation loss: 2.026799319892801

Epoch: 6| Step: 7
Training loss: 1.9015109539031982
Validation loss: 2.0092146601728214

Epoch: 6| Step: 8
Training loss: 2.170261859893799
Validation loss: 2.019780179505707

Epoch: 6| Step: 9
Training loss: 2.148138999938965
Validation loss: 2.0201591625008533

Epoch: 6| Step: 10
Training loss: 2.8091535568237305
Validation loss: 2.02638525988466

Epoch: 6| Step: 11
Training loss: 1.8959331512451172
Validation loss: 2.042138994380992

Epoch: 6| Step: 12
Training loss: 2.2372117042541504
Validation loss: 2.0533643999407367

Epoch: 6| Step: 13
Training loss: 1.9506416320800781
Validation loss: 2.0459837964785996

Epoch: 142| Step: 0
Training loss: 2.036405563354492
Validation loss: 2.050118948823662

Epoch: 6| Step: 1
Training loss: 2.073782444000244
Validation loss: 2.0703271537698726

Epoch: 6| Step: 2
Training loss: 2.0731358528137207
Validation loss: 2.0893694329005417

Epoch: 6| Step: 3
Training loss: 1.5775172710418701
Validation loss: 2.1091296724093858

Epoch: 6| Step: 4
Training loss: 2.980234146118164
Validation loss: 2.144409566797236

Epoch: 6| Step: 5
Training loss: 2.0679333209991455
Validation loss: 2.102930902152933

Epoch: 6| Step: 6
Training loss: 1.704512119293213
Validation loss: 2.0572106902317335

Epoch: 6| Step: 7
Training loss: 1.9094867706298828
Validation loss: 2.0346658486191944

Epoch: 6| Step: 8
Training loss: 2.3743295669555664
Validation loss: 2.0287569966367496

Epoch: 6| Step: 9
Training loss: 2.155078887939453
Validation loss: 2.033171735784059

Epoch: 6| Step: 10
Training loss: 2.0691146850585938
Validation loss: 2.0232132686081754

Epoch: 6| Step: 11
Training loss: 2.504188299179077
Validation loss: 2.02941402312248

Epoch: 6| Step: 12
Training loss: 2.5305488109588623
Validation loss: 2.0280200127632386

Epoch: 6| Step: 13
Training loss: 2.636260747909546
Validation loss: 2.020731335045189

Epoch: 143| Step: 0
Training loss: 2.179821014404297
Validation loss: 2.028611385694114

Epoch: 6| Step: 1
Training loss: 2.1580944061279297
Validation loss: 2.04920538779228

Epoch: 6| Step: 2
Training loss: 1.864639163017273
Validation loss: 2.053296809555382

Epoch: 6| Step: 3
Training loss: 1.6959857940673828
Validation loss: 2.0584383036500666

Epoch: 6| Step: 4
Training loss: 2.5995025634765625
Validation loss: 2.0579631008127683

Epoch: 6| Step: 5
Training loss: 2.5297024250030518
Validation loss: 2.035512393520724

Epoch: 6| Step: 6
Training loss: 1.561021327972412
Validation loss: 2.0248913380407516

Epoch: 6| Step: 7
Training loss: 1.4971582889556885
Validation loss: 2.0179058531279206

Epoch: 6| Step: 8
Training loss: 2.418546199798584
Validation loss: 1.9928230854772753

Epoch: 6| Step: 9
Training loss: 2.9192771911621094
Validation loss: 2.0215208761153685

Epoch: 6| Step: 10
Training loss: 2.4363248348236084
Validation loss: 2.015790993167508

Epoch: 6| Step: 11
Training loss: 1.7668761014938354
Validation loss: 2.0503468334033923

Epoch: 6| Step: 12
Training loss: 2.1632723808288574
Validation loss: 2.0806265723320747

Epoch: 6| Step: 13
Training loss: 2.2461445331573486
Validation loss: 2.1063863410744617

Epoch: 144| Step: 0
Training loss: 2.1174700260162354
Validation loss: 2.1092872260719218

Epoch: 6| Step: 1
Training loss: 1.8775510787963867
Validation loss: 2.1120195747703634

Epoch: 6| Step: 2
Training loss: 2.420997142791748
Validation loss: 2.090156776930696

Epoch: 6| Step: 3
Training loss: 1.8816254138946533
Validation loss: 2.010853664849394

Epoch: 6| Step: 4
Training loss: 2.3933238983154297
Validation loss: 1.9825494481671242

Epoch: 6| Step: 5
Training loss: 2.135955333709717
Validation loss: 1.97312407852501

Epoch: 6| Step: 6
Training loss: 3.0719010829925537
Validation loss: 1.9900749421888781

Epoch: 6| Step: 7
Training loss: 2.2631187438964844
Validation loss: 1.9964414258157053

Epoch: 6| Step: 8
Training loss: 1.9671802520751953
Validation loss: 1.9907944125513877

Epoch: 6| Step: 9
Training loss: 2.1610100269317627
Validation loss: 1.9971180820977816

Epoch: 6| Step: 10
Training loss: 2.4022088050842285
Validation loss: 2.004848546879266

Epoch: 6| Step: 11
Training loss: 1.9524240493774414
Validation loss: 2.0197338135011735

Epoch: 6| Step: 12
Training loss: 1.9929803609848022
Validation loss: 2.0473830853739092

Epoch: 6| Step: 13
Training loss: 2.228879928588867
Validation loss: 2.070182687492781

Epoch: 145| Step: 0
Training loss: 1.9924066066741943
Validation loss: 2.1003509644539125

Epoch: 6| Step: 1
Training loss: 2.646899700164795
Validation loss: 2.105615844008743

Epoch: 6| Step: 2
Training loss: 2.926422119140625
Validation loss: 2.109839553474098

Epoch: 6| Step: 3
Training loss: 2.0328240394592285
Validation loss: 2.10935434602922

Epoch: 6| Step: 4
Training loss: 2.353330373764038
Validation loss: 2.0989395392838346

Epoch: 6| Step: 5
Training loss: 2.283668041229248
Validation loss: 2.073217575268079

Epoch: 6| Step: 6
Training loss: 1.6096265316009521
Validation loss: 2.0371407513977378

Epoch: 6| Step: 7
Training loss: 1.8159418106079102
Validation loss: 2.0142536035148044

Epoch: 6| Step: 8
Training loss: 2.6225876808166504
Validation loss: 2.006470336708971

Epoch: 6| Step: 9
Training loss: 2.1707282066345215
Validation loss: 2.0099250373019966

Epoch: 6| Step: 10
Training loss: 1.6370782852172852
Validation loss: 2.0275370690130416

Epoch: 6| Step: 11
Training loss: 2.2027931213378906
Validation loss: 2.0243576726605816

Epoch: 6| Step: 12
Training loss: 2.139526844024658
Validation loss: 2.027757501089445

Epoch: 6| Step: 13
Training loss: 1.7127914428710938
Validation loss: 2.0274710142484276

Epoch: 146| Step: 0
Training loss: 2.1199145317077637
Validation loss: 2.0542000673150502

Epoch: 6| Step: 1
Training loss: 2.094343662261963
Validation loss: 2.10348674046096

Epoch: 6| Step: 2
Training loss: 2.880789279937744
Validation loss: 2.159458996147238

Epoch: 6| Step: 3
Training loss: 1.9472993612289429
Validation loss: 2.2058134617344027

Epoch: 6| Step: 4
Training loss: 1.923864483833313
Validation loss: 2.2243216012113836

Epoch: 6| Step: 5
Training loss: 1.6968917846679688
Validation loss: 2.2234791658257924

Epoch: 6| Step: 6
Training loss: 2.564958095550537
Validation loss: 2.1936244631326325

Epoch: 6| Step: 7
Training loss: 2.0985803604125977
Validation loss: 2.110911456487512

Epoch: 6| Step: 8
Training loss: 2.0587425231933594
Validation loss: 2.0608734776896815

Epoch: 6| Step: 9
Training loss: 2.236771583557129
Validation loss: 2.0445849985204716

Epoch: 6| Step: 10
Training loss: 1.854382872581482
Validation loss: 2.0209341972104964

Epoch: 6| Step: 11
Training loss: 2.622939109802246
Validation loss: 1.9899395870906051

Epoch: 6| Step: 12
Training loss: 2.2971484661102295
Validation loss: 1.983164374546338

Epoch: 6| Step: 13
Training loss: 1.6160954236984253
Validation loss: 1.991769011302661

Epoch: 147| Step: 0
Training loss: 2.106228828430176
Validation loss: 2.003796326216831

Epoch: 6| Step: 1
Training loss: 1.898451805114746
Validation loss: 2.037347270596412

Epoch: 6| Step: 2
Training loss: 2.116929292678833
Validation loss: 2.0328265172179028

Epoch: 6| Step: 3
Training loss: 2.491053581237793
Validation loss: 2.0511916119565248

Epoch: 6| Step: 4
Training loss: 2.4629781246185303
Validation loss: 2.054142754565003

Epoch: 6| Step: 5
Training loss: 2.1451382637023926
Validation loss: 2.0667008353817846

Epoch: 6| Step: 6
Training loss: 1.7544457912445068
Validation loss: 2.1015251733923472

Epoch: 6| Step: 7
Training loss: 2.396367073059082
Validation loss: 2.1045243483717724

Epoch: 6| Step: 8
Training loss: 3.07745361328125
Validation loss: 2.104501801152383

Epoch: 6| Step: 9
Training loss: 1.516599178314209
Validation loss: 2.0877516513229697

Epoch: 6| Step: 10
Training loss: 2.0845189094543457
Validation loss: 2.077480875035768

Epoch: 6| Step: 11
Training loss: 1.8636844158172607
Validation loss: 2.050590702282485

Epoch: 6| Step: 12
Training loss: 1.8006666898727417
Validation loss: 2.029419281149423

Epoch: 6| Step: 13
Training loss: 1.511816143989563
Validation loss: 2.0169051129330873

Epoch: 148| Step: 0
Training loss: 1.8252034187316895
Validation loss: 2.024608471060312

Epoch: 6| Step: 1
Training loss: 2.430138111114502
Validation loss: 2.0435767237858107

Epoch: 6| Step: 2
Training loss: 1.9484868049621582
Validation loss: 2.116560218154743

Epoch: 6| Step: 3
Training loss: 2.265624523162842
Validation loss: 2.1756452706552323

Epoch: 6| Step: 4
Training loss: 2.259584903717041
Validation loss: 2.246968433421145

Epoch: 6| Step: 5
Training loss: 2.064204216003418
Validation loss: 2.242040195772725

Epoch: 6| Step: 6
Training loss: 1.4672268629074097
Validation loss: 2.121086048823531

Epoch: 6| Step: 7
Training loss: 2.213726043701172
Validation loss: 2.029257571825417

Epoch: 6| Step: 8
Training loss: 2.2191615104675293
Validation loss: 1.9786329807773713

Epoch: 6| Step: 9
Training loss: 1.9356582164764404
Validation loss: 1.9895393156236219

Epoch: 6| Step: 10
Training loss: 2.574220657348633
Validation loss: 1.9890847398388771

Epoch: 6| Step: 11
Training loss: 2.3287129402160645
Validation loss: 2.0033332070996686

Epoch: 6| Step: 12
Training loss: 2.7214558124542236
Validation loss: 2.0181761351964806

Epoch: 6| Step: 13
Training loss: 2.0824718475341797
Validation loss: 2.0172430661416825

Epoch: 149| Step: 0
Training loss: 1.8345332145690918
Validation loss: 2.013504451321017

Epoch: 6| Step: 1
Training loss: 3.2204818725585938
Validation loss: 2.0158341187302784

Epoch: 6| Step: 2
Training loss: 2.033639430999756
Validation loss: 2.0256742585089897

Epoch: 6| Step: 3
Training loss: 1.7618733644485474
Validation loss: 2.049291836318149

Epoch: 6| Step: 4
Training loss: 2.204824209213257
Validation loss: 2.0586898403783

Epoch: 6| Step: 5
Training loss: 2.1876068115234375
Validation loss: 2.0764763073254655

Epoch: 6| Step: 6
Training loss: 2.0119431018829346
Validation loss: 2.116962658461704

Epoch: 6| Step: 7
Training loss: 2.1633777618408203
Validation loss: 2.137492226016137

Epoch: 6| Step: 8
Training loss: 1.9282937049865723
Validation loss: 2.165116863866006

Epoch: 6| Step: 9
Training loss: 1.7401567697525024
Validation loss: 2.201160946199971

Epoch: 6| Step: 10
Training loss: 2.1432528495788574
Validation loss: 2.2543389028118503

Epoch: 6| Step: 11
Training loss: 2.4455959796905518
Validation loss: 2.2736808407691216

Epoch: 6| Step: 12
Training loss: 2.0754244327545166
Validation loss: 2.2322607732588247

Epoch: 6| Step: 13
Training loss: 2.671407461166382
Validation loss: 2.149402459462484

Epoch: 150| Step: 0
Training loss: 2.0081946849823
Validation loss: 2.112706045950613

Epoch: 6| Step: 1
Training loss: 1.9335271120071411
Validation loss: 2.086892330518333

Epoch: 6| Step: 2
Training loss: 2.222622871398926
Validation loss: 2.066427961472542

Epoch: 6| Step: 3
Training loss: 2.1760168075561523
Validation loss: 2.046272905923987

Epoch: 6| Step: 4
Training loss: 2.26983642578125
Validation loss: 2.0255731100677163

Epoch: 6| Step: 5
Training loss: 2.2884228229522705
Validation loss: 2.0129681492364533

Epoch: 6| Step: 6
Training loss: 1.6376421451568604
Validation loss: 2.027094502602854

Epoch: 6| Step: 7
Training loss: 1.8868098258972168
Validation loss: 2.059163321730911

Epoch: 6| Step: 8
Training loss: 2.1519198417663574
Validation loss: 2.058732678813319

Epoch: 6| Step: 9
Training loss: 2.4344587326049805
Validation loss: 2.0571400247594362

Epoch: 6| Step: 10
Training loss: 2.2505152225494385
Validation loss: 2.0656571054971344

Epoch: 6| Step: 11
Training loss: 1.6805102825164795
Validation loss: 2.070293088113108

Epoch: 6| Step: 12
Training loss: 2.4844136238098145
Validation loss: 2.067501894889339

Epoch: 6| Step: 13
Training loss: 1.7000666856765747
Validation loss: 2.0772718806420603

Epoch: 151| Step: 0
Training loss: 2.41029691696167
Validation loss: 2.0799403831522953

Epoch: 6| Step: 1
Training loss: 2.1546030044555664
Validation loss: 2.0691739025936333

Epoch: 6| Step: 2
Training loss: 1.648561954498291
Validation loss: 2.0615932967073176

Epoch: 6| Step: 3
Training loss: 2.594578742980957
Validation loss: 2.028422663288732

Epoch: 6| Step: 4
Training loss: 2.468932867050171
Validation loss: 2.0237299421782136

Epoch: 6| Step: 5
Training loss: 2.1036417484283447
Validation loss: 1.993812450798609

Epoch: 6| Step: 6
Training loss: 2.0514042377471924
Validation loss: 2.0050608534966745

Epoch: 6| Step: 7
Training loss: 1.7538058757781982
Validation loss: 2.0069324021698325

Epoch: 6| Step: 8
Training loss: 1.8870177268981934
Validation loss: 2.022161458128242

Epoch: 6| Step: 9
Training loss: 1.9674328565597534
Validation loss: 2.052602142416021

Epoch: 6| Step: 10
Training loss: 1.983715534210205
Validation loss: 2.0526060288952244

Epoch: 6| Step: 11
Training loss: 1.6209789514541626
Validation loss: 2.1135509193584485

Epoch: 6| Step: 12
Training loss: 2.184140682220459
Validation loss: 2.2126441950439126

Epoch: 6| Step: 13
Training loss: 2.6419055461883545
Validation loss: 2.2294410736330095

Epoch: 152| Step: 0
Training loss: 2.0420241355895996
Validation loss: 2.2255178984775337

Epoch: 6| Step: 1
Training loss: 1.3037734031677246
Validation loss: 2.1618944778237292

Epoch: 6| Step: 2
Training loss: 2.0560054779052734
Validation loss: 2.0639291040359007

Epoch: 6| Step: 3
Training loss: 2.6464972496032715
Validation loss: 1.9875028184665147

Epoch: 6| Step: 4
Training loss: 2.099132537841797
Validation loss: 1.9697208737814298

Epoch: 6| Step: 5
Training loss: 2.175746440887451
Validation loss: 1.9901941873693978

Epoch: 6| Step: 6
Training loss: 2.727905035018921
Validation loss: 2.013025955487323

Epoch: 6| Step: 7
Training loss: 3.1675546169281006
Validation loss: 2.0154952131291872

Epoch: 6| Step: 8
Training loss: 1.654891014099121
Validation loss: 2.0417306538551085

Epoch: 6| Step: 9
Training loss: 1.633207082748413
Validation loss: 2.0459011498317925

Epoch: 6| Step: 10
Training loss: 1.876021385192871
Validation loss: 2.055781319577207

Epoch: 6| Step: 11
Training loss: 2.3123767375946045
Validation loss: 2.104396426549522

Epoch: 6| Step: 12
Training loss: 2.021345853805542
Validation loss: 2.1845137790967057

Epoch: 6| Step: 13
Training loss: 1.8478635549545288
Validation loss: 2.218285446525902

Epoch: 153| Step: 0
Training loss: 2.0771217346191406
Validation loss: 2.272330907083327

Epoch: 6| Step: 1
Training loss: 1.7921781539916992
Validation loss: 2.2773506179932625

Epoch: 6| Step: 2
Training loss: 1.9647765159606934
Validation loss: 2.2742664455085673

Epoch: 6| Step: 3
Training loss: 1.869415521621704
Validation loss: 2.297888404579573

Epoch: 6| Step: 4
Training loss: 1.8920774459838867
Validation loss: 2.2792414849804294

Epoch: 6| Step: 5
Training loss: 1.9635186195373535
Validation loss: 2.2637853750618557

Epoch: 6| Step: 6
Training loss: 2.1582140922546387
Validation loss: 2.228888924403857

Epoch: 6| Step: 7
Training loss: 1.5865815877914429
Validation loss: 2.204172311290618

Epoch: 6| Step: 8
Training loss: 2.302515983581543
Validation loss: 2.172076074025964

Epoch: 6| Step: 9
Training loss: 2.281027317047119
Validation loss: 2.1331777136812926

Epoch: 6| Step: 10
Training loss: 2.6768178939819336
Validation loss: 2.041922171910604

Epoch: 6| Step: 11
Training loss: 1.9249987602233887
Validation loss: 2.0206178157560286

Epoch: 6| Step: 12
Training loss: 2.777731418609619
Validation loss: 2.0093063910802207

Epoch: 6| Step: 13
Training loss: 2.0883450508117676
Validation loss: 2.018872825048303

Epoch: 154| Step: 0
Training loss: 2.238218069076538
Validation loss: 2.0317146970379736

Epoch: 6| Step: 1
Training loss: 2.0025827884674072
Validation loss: 2.0388660225816952

Epoch: 6| Step: 2
Training loss: 2.1891965866088867
Validation loss: 2.049295215196507

Epoch: 6| Step: 3
Training loss: 1.716303825378418
Validation loss: 2.0570003717176375

Epoch: 6| Step: 4
Training loss: 1.8451433181762695
Validation loss: 2.0478103212130967

Epoch: 6| Step: 5
Training loss: 1.8929932117462158
Validation loss: 2.0375521811105872

Epoch: 6| Step: 6
Training loss: 2.91633677482605
Validation loss: 2.020523002070765

Epoch: 6| Step: 7
Training loss: 2.4002737998962402
Validation loss: 1.9976388023745628

Epoch: 6| Step: 8
Training loss: 2.128063201904297
Validation loss: 1.9901133301437541

Epoch: 6| Step: 9
Training loss: 1.8635900020599365
Validation loss: 1.9906800741790442

Epoch: 6| Step: 10
Training loss: 1.7788758277893066
Validation loss: 2.0050063492149435

Epoch: 6| Step: 11
Training loss: 1.818378210067749
Validation loss: 1.9979396250940138

Epoch: 6| Step: 12
Training loss: 1.9225908517837524
Validation loss: 2.0130357075763006

Epoch: 6| Step: 13
Training loss: 2.7675271034240723
Validation loss: 2.030265349213795

Epoch: 155| Step: 0
Training loss: 2.3934764862060547
Validation loss: 2.0454470008932133

Epoch: 6| Step: 1
Training loss: 1.8618009090423584
Validation loss: 2.0614010544233423

Epoch: 6| Step: 2
Training loss: 1.834197759628296
Validation loss: 2.0831513251027753

Epoch: 6| Step: 3
Training loss: 2.30574369430542
Validation loss: 2.119664725436959

Epoch: 6| Step: 4
Training loss: 2.1403980255126953
Validation loss: 2.119411855615595

Epoch: 6| Step: 5
Training loss: 1.5793547630310059
Validation loss: 2.077692162606024

Epoch: 6| Step: 6
Training loss: 2.1845545768737793
Validation loss: 2.062091089064075

Epoch: 6| Step: 7
Training loss: 1.9176321029663086
Validation loss: 2.0478280257153254

Epoch: 6| Step: 8
Training loss: 1.60541570186615
Validation loss: 2.034309103924741

Epoch: 6| Step: 9
Training loss: 2.1949820518493652
Validation loss: 2.030835977164648

Epoch: 6| Step: 10
Training loss: 2.660953998565674
Validation loss: 2.040130692143594

Epoch: 6| Step: 11
Training loss: 2.0011396408081055
Validation loss: 2.037889242172241

Epoch: 6| Step: 12
Training loss: 1.777972936630249
Validation loss: 2.017544960462919

Epoch: 6| Step: 13
Training loss: 2.4616873264312744
Validation loss: 1.9840464053615448

Epoch: 156| Step: 0
Training loss: 2.6354527473449707
Validation loss: 1.977023079831113

Epoch: 6| Step: 1
Training loss: 2.602355480194092
Validation loss: 1.961722497017153

Epoch: 6| Step: 2
Training loss: 1.901850700378418
Validation loss: 1.968006851852581

Epoch: 6| Step: 3
Training loss: 1.9474684000015259
Validation loss: 1.963020554152868

Epoch: 6| Step: 4
Training loss: 2.588306427001953
Validation loss: 1.9730510634760703

Epoch: 6| Step: 5
Training loss: 1.669584035873413
Validation loss: 1.9706923333547448

Epoch: 6| Step: 6
Training loss: 1.6414607763290405
Validation loss: 1.9836766386544833

Epoch: 6| Step: 7
Training loss: 1.6247713565826416
Validation loss: 2.027805869297315

Epoch: 6| Step: 8
Training loss: 2.504213333129883
Validation loss: 2.0945127266709522

Epoch: 6| Step: 9
Training loss: 1.8905539512634277
Validation loss: 2.181249018638365

Epoch: 6| Step: 10
Training loss: 2.5896048545837402
Validation loss: 2.240651827986522

Epoch: 6| Step: 11
Training loss: 2.142280340194702
Validation loss: 2.2290801079042497

Epoch: 6| Step: 12
Training loss: 1.6624728441238403
Validation loss: 2.153901776959819

Epoch: 6| Step: 13
Training loss: 1.2464070320129395
Validation loss: 2.096949518367808

Epoch: 157| Step: 0
Training loss: 2.295461893081665
Validation loss: 2.0435820036036993

Epoch: 6| Step: 1
Training loss: 1.5912346839904785
Validation loss: 1.9929135666098645

Epoch: 6| Step: 2
Training loss: 1.9388915300369263
Validation loss: 1.977603603434819

Epoch: 6| Step: 3
Training loss: 2.127779006958008
Validation loss: 1.963378757558843

Epoch: 6| Step: 4
Training loss: 1.39553964138031
Validation loss: 1.9612027522056334

Epoch: 6| Step: 5
Training loss: 2.0432684421539307
Validation loss: 1.9747242504550564

Epoch: 6| Step: 6
Training loss: 1.7955071926116943
Validation loss: 1.9666782758569206

Epoch: 6| Step: 7
Training loss: 2.4653210639953613
Validation loss: 1.9598990486514183

Epoch: 6| Step: 8
Training loss: 1.9715688228607178
Validation loss: 1.9905906031208653

Epoch: 6| Step: 9
Training loss: 2.222412586212158
Validation loss: 2.0441839874431653

Epoch: 6| Step: 10
Training loss: 1.8431528806686401
Validation loss: 2.068141773182859

Epoch: 6| Step: 11
Training loss: 2.4925670623779297
Validation loss: 2.0701280332380727

Epoch: 6| Step: 12
Training loss: 2.2614760398864746
Validation loss: 2.0960494997680827

Epoch: 6| Step: 13
Training loss: 1.733991265296936
Validation loss: 2.112186551094055

Epoch: 158| Step: 0
Training loss: 2.2545013427734375
Validation loss: 2.1290090955713743

Epoch: 6| Step: 1
Training loss: 1.6809751987457275
Validation loss: 2.109008119952294

Epoch: 6| Step: 2
Training loss: 2.536342144012451
Validation loss: 2.086901198151291

Epoch: 6| Step: 3
Training loss: 1.9015753269195557
Validation loss: 2.0662797663801458

Epoch: 6| Step: 4
Training loss: 1.7180508375167847
Validation loss: 2.0368704257472867

Epoch: 6| Step: 5
Training loss: 2.413102626800537
Validation loss: 2.030625153613347

Epoch: 6| Step: 6
Training loss: 1.8401044607162476
Validation loss: 2.0165649870390534

Epoch: 6| Step: 7
Training loss: 1.6450573205947876
Validation loss: 2.0152704408091884

Epoch: 6| Step: 8
Training loss: 1.7219667434692383
Validation loss: 2.0166920820871987

Epoch: 6| Step: 9
Training loss: 2.285276412963867
Validation loss: 2.0317705690219836

Epoch: 6| Step: 10
Training loss: 1.857262372970581
Validation loss: 2.0315170800814064

Epoch: 6| Step: 11
Training loss: 1.588228464126587
Validation loss: 2.0170154981715704

Epoch: 6| Step: 12
Training loss: 2.641988754272461
Validation loss: 2.009640832101145

Epoch: 6| Step: 13
Training loss: 1.739861249923706
Validation loss: 2.0181436897605978

Epoch: 159| Step: 0
Training loss: 1.2746450901031494
Validation loss: 2.0129221280415854

Epoch: 6| Step: 1
Training loss: 1.652832269668579
Validation loss: 2.036203363890289

Epoch: 6| Step: 2
Training loss: 2.4165074825286865
Validation loss: 2.0365600188573203

Epoch: 6| Step: 3
Training loss: 2.117825746536255
Validation loss: 2.031442347393241

Epoch: 6| Step: 4
Training loss: 1.2132158279418945
Validation loss: 2.0330417694584018

Epoch: 6| Step: 5
Training loss: 1.9298797845840454
Validation loss: 2.017158160927475

Epoch: 6| Step: 6
Training loss: 1.869617223739624
Validation loss: 2.0171820117581274

Epoch: 6| Step: 7
Training loss: 2.502312183380127
Validation loss: 2.019476245808345

Epoch: 6| Step: 8
Training loss: 2.560939311981201
Validation loss: 2.0104922991926952

Epoch: 6| Step: 9
Training loss: 2.111055612564087
Validation loss: 2.0256642654377925

Epoch: 6| Step: 10
Training loss: 1.7075836658477783
Validation loss: 2.027463509190467

Epoch: 6| Step: 11
Training loss: 1.876277208328247
Validation loss: 2.0263219187336583

Epoch: 6| Step: 12
Training loss: 1.8812670707702637
Validation loss: 2.080859330392653

Epoch: 6| Step: 13
Training loss: 2.9797091484069824
Validation loss: 2.10328181071948

Epoch: 160| Step: 0
Training loss: 1.7492570877075195
Validation loss: 2.1131776532819195

Epoch: 6| Step: 1
Training loss: 1.7400999069213867
Validation loss: 2.1254573060620214

Epoch: 6| Step: 2
Training loss: 1.8451762199401855
Validation loss: 2.125829424909366

Epoch: 6| Step: 3
Training loss: 1.5968507528305054
Validation loss: 2.0976068845359226

Epoch: 6| Step: 4
Training loss: 1.9214601516723633
Validation loss: 2.0750574091429352

Epoch: 6| Step: 5
Training loss: 1.96929132938385
Validation loss: 2.068486108574816

Epoch: 6| Step: 6
Training loss: 1.5609920024871826
Validation loss: 2.0599699686932307

Epoch: 6| Step: 7
Training loss: 2.2173526287078857
Validation loss: 2.049213804224486

Epoch: 6| Step: 8
Training loss: 1.7867203950881958
Validation loss: 2.052875872581236

Epoch: 6| Step: 9
Training loss: 2.6275863647460938
Validation loss: 2.0323645786572526

Epoch: 6| Step: 10
Training loss: 2.365288496017456
Validation loss: 2.0196835097446235

Epoch: 6| Step: 11
Training loss: 2.53452730178833
Validation loss: 2.004676362519623

Epoch: 6| Step: 12
Training loss: 2.1631546020507812
Validation loss: 1.99803130344678

Epoch: 6| Step: 13
Training loss: 0.8537057042121887
Validation loss: 2.0053836440527313

Epoch: 161| Step: 0
Training loss: 2.1862387657165527
Validation loss: 1.979811619686824

Epoch: 6| Step: 1
Training loss: 1.4986671209335327
Validation loss: 1.9817940778629755

Epoch: 6| Step: 2
Training loss: 2.120389938354492
Validation loss: 2.0114335488247614

Epoch: 6| Step: 3
Training loss: 1.8664379119873047
Validation loss: 2.0029298477275397

Epoch: 6| Step: 4
Training loss: 1.9059184789657593
Validation loss: 2.0505320038846744

Epoch: 6| Step: 5
Training loss: 1.8183000087738037
Validation loss: 2.0523058035040416

Epoch: 6| Step: 6
Training loss: 2.693401336669922
Validation loss: 2.0421145833948606

Epoch: 6| Step: 7
Training loss: 1.6307175159454346
Validation loss: 1.996078589911102

Epoch: 6| Step: 8
Training loss: 2.129415988922119
Validation loss: 1.983144429422194

Epoch: 6| Step: 9
Training loss: 1.560536503791809
Validation loss: 1.9767883131580968

Epoch: 6| Step: 10
Training loss: 1.9361941814422607
Validation loss: 1.9806945759763

Epoch: 6| Step: 11
Training loss: 1.4253147840499878
Validation loss: 1.9861982061016945

Epoch: 6| Step: 12
Training loss: 2.396315574645996
Validation loss: 1.9937444066488614

Epoch: 6| Step: 13
Training loss: 2.4372880458831787
Validation loss: 2.01341769003099

Epoch: 162| Step: 0
Training loss: 1.9873526096343994
Validation loss: 2.0225965310168523

Epoch: 6| Step: 1
Training loss: 1.4820376634597778
Validation loss: 2.0484977306858188

Epoch: 6| Step: 2
Training loss: 2.149717092514038
Validation loss: 2.0576365814414075

Epoch: 6| Step: 3
Training loss: 2.0199387073516846
Validation loss: 2.0476651755712365

Epoch: 6| Step: 4
Training loss: 1.9756383895874023
Validation loss: 2.0463266603408323

Epoch: 6| Step: 5
Training loss: 1.390025019645691
Validation loss: 2.0489687099251697

Epoch: 6| Step: 6
Training loss: 2.439873695373535
Validation loss: 2.04680658284054

Epoch: 6| Step: 7
Training loss: 2.0381219387054443
Validation loss: 2.0485980459438857

Epoch: 6| Step: 8
Training loss: 2.556424617767334
Validation loss: 2.0526818588215816

Epoch: 6| Step: 9
Training loss: 1.4258748292922974
Validation loss: 2.0654530332934473

Epoch: 6| Step: 10
Training loss: 2.1253085136413574
Validation loss: 2.091333957128627

Epoch: 6| Step: 11
Training loss: 1.8838489055633545
Validation loss: 2.115639804511942

Epoch: 6| Step: 12
Training loss: 1.4266669750213623
Validation loss: 2.1092784507300264

Epoch: 6| Step: 13
Training loss: 2.007388114929199
Validation loss: 2.121465177946193

Epoch: 163| Step: 0
Training loss: 1.8303465843200684
Validation loss: 2.1184752910367903

Epoch: 6| Step: 1
Training loss: 2.0073812007904053
Validation loss: 2.1016067356191654

Epoch: 6| Step: 2
Training loss: 1.2856353521347046
Validation loss: 2.0855922237519295

Epoch: 6| Step: 3
Training loss: 1.8206448554992676
Validation loss: 2.039605438068349

Epoch: 6| Step: 4
Training loss: 2.194690465927124
Validation loss: 2.04161044602753

Epoch: 6| Step: 5
Training loss: 2.4294588565826416
Validation loss: 2.0110558643135974

Epoch: 6| Step: 6
Training loss: 2.3743069171905518
Validation loss: 1.9906798562695902

Epoch: 6| Step: 7
Training loss: 1.854298710823059
Validation loss: 1.9733006544010614

Epoch: 6| Step: 8
Training loss: 2.036797046661377
Validation loss: 1.977747565956526

Epoch: 6| Step: 9
Training loss: 1.2762963771820068
Validation loss: 1.9763792227673274

Epoch: 6| Step: 10
Training loss: 1.404374361038208
Validation loss: 1.9712928456644858

Epoch: 6| Step: 11
Training loss: 2.2160582542419434
Validation loss: 1.9950351497178436

Epoch: 6| Step: 12
Training loss: 1.9816272258758545
Validation loss: 2.0094448545927643

Epoch: 6| Step: 13
Training loss: 2.6182801723480225
Validation loss: 2.0370655546906176

Epoch: 164| Step: 0
Training loss: 2.107229232788086
Validation loss: 2.0372068830715713

Epoch: 6| Step: 1
Training loss: 2.059739112854004
Validation loss: 2.0236070207370225

Epoch: 6| Step: 2
Training loss: 2.1001458168029785
Validation loss: 2.0000417411968274

Epoch: 6| Step: 3
Training loss: 1.8465898036956787
Validation loss: 2.0018830824923772

Epoch: 6| Step: 4
Training loss: 1.5112124681472778
Validation loss: 2.021216864226967

Epoch: 6| Step: 5
Training loss: 2.365199327468872
Validation loss: 2.01647662860091

Epoch: 6| Step: 6
Training loss: 1.665255069732666
Validation loss: 2.0567597253348238

Epoch: 6| Step: 7
Training loss: 2.1088528633117676
Validation loss: 2.051951228931386

Epoch: 6| Step: 8
Training loss: 2.1133809089660645
Validation loss: 2.068048163126874

Epoch: 6| Step: 9
Training loss: 1.0659549236297607
Validation loss: 2.0847864535547074

Epoch: 6| Step: 10
Training loss: 2.1419475078582764
Validation loss: 2.0680458494412

Epoch: 6| Step: 11
Training loss: 1.275132417678833
Validation loss: 2.075863721550152

Epoch: 6| Step: 12
Training loss: 2.4409422874450684
Validation loss: 2.0716804368521577

Epoch: 6| Step: 13
Training loss: 1.7829176187515259
Validation loss: 2.0513115877746255

Epoch: 165| Step: 0
Training loss: 2.521113157272339
Validation loss: 2.081001140738046

Epoch: 6| Step: 1
Training loss: 1.9574236869812012
Validation loss: 2.0768328302650043

Epoch: 6| Step: 2
Training loss: 2.2240591049194336
Validation loss: 2.081268056746452

Epoch: 6| Step: 3
Training loss: 1.8162882328033447
Validation loss: 2.05702212549025

Epoch: 6| Step: 4
Training loss: 2.1291635036468506
Validation loss: 2.0522197984880015

Epoch: 6| Step: 5
Training loss: 1.8527040481567383
Validation loss: 2.042645856898318

Epoch: 6| Step: 6
Training loss: 1.7034010887145996
Validation loss: 2.0419033470974175

Epoch: 6| Step: 7
Training loss: 1.3733441829681396
Validation loss: 2.042529503504435

Epoch: 6| Step: 8
Training loss: 1.9251044988632202
Validation loss: 2.045826881162582

Epoch: 6| Step: 9
Training loss: 2.153102397918701
Validation loss: 2.0136508518649685

Epoch: 6| Step: 10
Training loss: 1.943548560142517
Validation loss: 2.007916074927135

Epoch: 6| Step: 11
Training loss: 1.7844860553741455
Validation loss: 1.9988306158332414

Epoch: 6| Step: 12
Training loss: 1.5893621444702148
Validation loss: 1.9780773103878062

Epoch: 6| Step: 13
Training loss: 1.3152459859848022
Validation loss: 1.970288981673538

Epoch: 166| Step: 0
Training loss: 1.8559856414794922
Validation loss: 1.9941364808749127

Epoch: 6| Step: 1
Training loss: 1.8194947242736816
Validation loss: 1.9843649530923495

Epoch: 6| Step: 2
Training loss: 2.737501382827759
Validation loss: 2.009107010338896

Epoch: 6| Step: 3
Training loss: 1.863858938217163
Validation loss: 2.0521400077368623

Epoch: 6| Step: 4
Training loss: 1.4607250690460205
Validation loss: 2.049877761512674

Epoch: 6| Step: 5
Training loss: 2.192201614379883
Validation loss: 2.0612505251361477

Epoch: 6| Step: 6
Training loss: 2.1162705421447754
Validation loss: 2.0447215777571484

Epoch: 6| Step: 7
Training loss: 1.7256468534469604
Validation loss: 2.0376155145706667

Epoch: 6| Step: 8
Training loss: 1.9645494222640991
Validation loss: 2.030076506317303

Epoch: 6| Step: 9
Training loss: 1.5390424728393555
Validation loss: 2.0527838827461324

Epoch: 6| Step: 10
Training loss: 1.699131965637207
Validation loss: 2.0689961871793194

Epoch: 6| Step: 11
Training loss: 1.3583693504333496
Validation loss: 2.1160730879793883

Epoch: 6| Step: 12
Training loss: 1.8720476627349854
Validation loss: 2.1136617634886052

Epoch: 6| Step: 13
Training loss: 2.41218638420105
Validation loss: 2.137565217992311

Epoch: 167| Step: 0
Training loss: 2.1062049865722656
Validation loss: 2.1052927432521695

Epoch: 6| Step: 1
Training loss: 1.516279935836792
Validation loss: 2.056920656593897

Epoch: 6| Step: 2
Training loss: 1.3894410133361816
Validation loss: 2.0139634070857877

Epoch: 6| Step: 3
Training loss: 1.3832323551177979
Validation loss: 1.9998627631895003

Epoch: 6| Step: 4
Training loss: 1.9154882431030273
Validation loss: 1.9895574379992742

Epoch: 6| Step: 5
Training loss: 1.4328362941741943
Validation loss: 1.9907765080851894

Epoch: 6| Step: 6
Training loss: 2.3388137817382812
Validation loss: 1.995908014235958

Epoch: 6| Step: 7
Training loss: 1.7538096904754639
Validation loss: 2.0058878583292805

Epoch: 6| Step: 8
Training loss: 1.4675451517105103
Validation loss: 2.0482011789916665

Epoch: 6| Step: 9
Training loss: 1.8042818307876587
Validation loss: 2.0707193830961823

Epoch: 6| Step: 10
Training loss: 2.3646860122680664
Validation loss: 2.141693283152837

Epoch: 6| Step: 11
Training loss: 2.0289034843444824
Validation loss: 2.1880848074472077

Epoch: 6| Step: 12
Training loss: 2.875469207763672
Validation loss: 2.1616817648692797

Epoch: 6| Step: 13
Training loss: 2.2061574459075928
Validation loss: 2.122577187835529

Epoch: 168| Step: 0
Training loss: 2.3853437900543213
Validation loss: 2.0539470693116546

Epoch: 6| Step: 1
Training loss: 1.9850506782531738
Validation loss: 2.014102020571309

Epoch: 6| Step: 2
Training loss: 1.1097705364227295
Validation loss: 1.9930325092807892

Epoch: 6| Step: 3
Training loss: 1.978556752204895
Validation loss: 1.9755763135930544

Epoch: 6| Step: 4
Training loss: 2.513395071029663
Validation loss: 1.9970986548290457

Epoch: 6| Step: 5
Training loss: 1.9093332290649414
Validation loss: 1.9794287322669901

Epoch: 6| Step: 6
Training loss: 1.530329942703247
Validation loss: 2.0071522907544206

Epoch: 6| Step: 7
Training loss: 2.1479201316833496
Validation loss: 2.007578275536978

Epoch: 6| Step: 8
Training loss: 1.6334969997406006
Validation loss: 2.035335512571437

Epoch: 6| Step: 9
Training loss: 2.185929298400879
Validation loss: 2.0735290947780816

Epoch: 6| Step: 10
Training loss: 1.3124264478683472
Validation loss: 2.125520557485601

Epoch: 6| Step: 11
Training loss: 2.3839526176452637
Validation loss: 2.176003663770614

Epoch: 6| Step: 12
Training loss: 1.6866233348846436
Validation loss: 2.1761193967634633

Epoch: 6| Step: 13
Training loss: 1.0118075609207153
Validation loss: 2.1337313690493183

Epoch: 169| Step: 0
Training loss: 1.460558295249939
Validation loss: 2.108158588409424

Epoch: 6| Step: 1
Training loss: 1.740722894668579
Validation loss: 2.0694213759514595

Epoch: 6| Step: 2
Training loss: 1.8417062759399414
Validation loss: 2.0487227427062167

Epoch: 6| Step: 3
Training loss: 1.9090864658355713
Validation loss: 2.0637321984896095

Epoch: 6| Step: 4
Training loss: 1.2625977993011475
Validation loss: 2.059779337657395

Epoch: 6| Step: 5
Training loss: 2.1444873809814453
Validation loss: 2.0451294042730845

Epoch: 6| Step: 6
Training loss: 2.6604199409484863
Validation loss: 2.0352608132106003

Epoch: 6| Step: 7
Training loss: 1.9939403533935547
Validation loss: 2.0255584716796875

Epoch: 6| Step: 8
Training loss: 1.7377309799194336
Validation loss: 2.070252344172488

Epoch: 6| Step: 9
Training loss: 1.3985612392425537
Validation loss: 2.0582238858745945

Epoch: 6| Step: 10
Training loss: 1.4984405040740967
Validation loss: 2.0648673708720873

Epoch: 6| Step: 11
Training loss: 2.4817380905151367
Validation loss: 2.105709773237987

Epoch: 6| Step: 12
Training loss: 1.743042230606079
Validation loss: 2.1159754876167542

Epoch: 6| Step: 13
Training loss: 2.160731315612793
Validation loss: 2.0983576928415606

Epoch: 170| Step: 0
Training loss: 1.8387080430984497
Validation loss: 2.0546687572233138

Epoch: 6| Step: 1
Training loss: 1.5921838283538818
Validation loss: 2.0100012825381373

Epoch: 6| Step: 2
Training loss: 2.3177120685577393
Validation loss: 2.0267491443182832

Epoch: 6| Step: 3
Training loss: 2.079220771789551
Validation loss: 2.010620786297706

Epoch: 6| Step: 4
Training loss: 1.692805528640747
Validation loss: 2.0314623335356354

Epoch: 6| Step: 5
Training loss: 1.8864262104034424
Validation loss: 2.046358152102399

Epoch: 6| Step: 6
Training loss: 1.6522901058197021
Validation loss: 2.0249868746726745

Epoch: 6| Step: 7
Training loss: 2.2650485038757324
Validation loss: 2.0218213578706146

Epoch: 6| Step: 8
Training loss: 2.0200698375701904
Validation loss: 2.0340394012389647

Epoch: 6| Step: 9
Training loss: 1.8592050075531006
Validation loss: 2.0411136509269796

Epoch: 6| Step: 10
Training loss: 1.579783320426941
Validation loss: 2.056711845500495

Epoch: 6| Step: 11
Training loss: 1.3177552223205566
Validation loss: 2.0709117522803684

Epoch: 6| Step: 12
Training loss: 1.5531530380249023
Validation loss: 2.1021262497030277

Epoch: 6| Step: 13
Training loss: 1.876790165901184
Validation loss: 2.1431506808086107

Epoch: 171| Step: 0
Training loss: 1.6262226104736328
Validation loss: 2.142883910927721

Epoch: 6| Step: 1
Training loss: 2.093162775039673
Validation loss: 2.1802689413870535

Epoch: 6| Step: 2
Training loss: 1.8114397525787354
Validation loss: 2.1844408537751887

Epoch: 6| Step: 3
Training loss: 1.5339562892913818
Validation loss: 2.149664609662948

Epoch: 6| Step: 4
Training loss: 2.1927027702331543
Validation loss: 2.1405794389786257

Epoch: 6| Step: 5
Training loss: 1.7890408039093018
Validation loss: 2.1154123429329164

Epoch: 6| Step: 6
Training loss: 2.426438808441162
Validation loss: 2.071271860471336

Epoch: 6| Step: 7
Training loss: 1.936154842376709
Validation loss: 2.0303813334434264

Epoch: 6| Step: 8
Training loss: 1.9317290782928467
Validation loss: 2.008972558923947

Epoch: 6| Step: 9
Training loss: 2.157005786895752
Validation loss: 2.0225512372550143

Epoch: 6| Step: 10
Training loss: 1.2006968259811401
Validation loss: 2.0182392776653333

Epoch: 6| Step: 11
Training loss: 1.6979972124099731
Validation loss: 2.0000144281694965

Epoch: 6| Step: 12
Training loss: 1.7775616645812988
Validation loss: 2.0010739193167737

Epoch: 6| Step: 13
Training loss: 1.3847383260726929
Validation loss: 2.01542204810727

Epoch: 172| Step: 0
Training loss: 2.4662983417510986
Validation loss: 2.0111533082941526

Epoch: 6| Step: 1
Training loss: 2.0872795581817627
Validation loss: 1.9959569566993303

Epoch: 6| Step: 2
Training loss: 1.9786816835403442
Validation loss: 1.9891804623347458

Epoch: 6| Step: 3
Training loss: 1.4527277946472168
Validation loss: 1.9866597152525378

Epoch: 6| Step: 4
Training loss: 2.0925140380859375
Validation loss: 2.0034329250294673

Epoch: 6| Step: 5
Training loss: 1.707102656364441
Validation loss: 2.0169923600330146

Epoch: 6| Step: 6
Training loss: 1.9957600831985474
Validation loss: 2.0222370252814343

Epoch: 6| Step: 7
Training loss: 1.4728440046310425
Validation loss: 2.041128179078461

Epoch: 6| Step: 8
Training loss: 2.4174156188964844
Validation loss: 2.0553844436522453

Epoch: 6| Step: 9
Training loss: 1.5044797658920288
Validation loss: 2.0759317541635163

Epoch: 6| Step: 10
Training loss: 1.450992226600647
Validation loss: 2.074107427750864

Epoch: 6| Step: 11
Training loss: 1.2789342403411865
Validation loss: 2.0835900652793145

Epoch: 6| Step: 12
Training loss: 1.8700108528137207
Validation loss: 2.086002670308595

Epoch: 6| Step: 13
Training loss: 1.574554681777954
Validation loss: 2.0711281530318724

Epoch: 173| Step: 0
Training loss: 2.2494442462921143
Validation loss: 2.055556825412217

Epoch: 6| Step: 1
Training loss: 1.4383082389831543
Validation loss: 2.0427596902334564

Epoch: 6| Step: 2
Training loss: 1.2684601545333862
Validation loss: 2.0026489214230607

Epoch: 6| Step: 3
Training loss: 1.5339605808258057
Validation loss: 2.018267112393533

Epoch: 6| Step: 4
Training loss: 1.9244331121444702
Validation loss: 1.9966516661387619

Epoch: 6| Step: 5
Training loss: 2.183258533477783
Validation loss: 2.01622094902941

Epoch: 6| Step: 6
Training loss: 2.1345129013061523
Validation loss: 1.9900400292488836

Epoch: 6| Step: 7
Training loss: 1.1810003519058228
Validation loss: 1.9844999210808867

Epoch: 6| Step: 8
Training loss: 1.705306887626648
Validation loss: 1.9637619974792644

Epoch: 6| Step: 9
Training loss: 2.082810163497925
Validation loss: 1.9727332681737921

Epoch: 6| Step: 10
Training loss: 1.6701879501342773
Validation loss: 1.9860287110010784

Epoch: 6| Step: 11
Training loss: 1.7791075706481934
Validation loss: 2.006436432561567

Epoch: 6| Step: 12
Training loss: 1.7514528036117554
Validation loss: 2.0644053348930935

Epoch: 6| Step: 13
Training loss: 2.1148109436035156
Validation loss: 2.0852326769982614

Epoch: 174| Step: 0
Training loss: 1.6929439306259155
Validation loss: 2.0892990327650502

Epoch: 6| Step: 1
Training loss: 1.7319523096084595
Validation loss: 2.076249719947897

Epoch: 6| Step: 2
Training loss: 1.6255453824996948
Validation loss: 2.1189002734358593

Epoch: 6| Step: 3
Training loss: 1.7058675289154053
Validation loss: 2.1251509163969304

Epoch: 6| Step: 4
Training loss: 1.6401281356811523
Validation loss: 2.1321584050373366

Epoch: 6| Step: 5
Training loss: 2.2686195373535156
Validation loss: 2.0999106796838904

Epoch: 6| Step: 6
Training loss: 2.072620391845703
Validation loss: 2.0456848016349216

Epoch: 6| Step: 7
Training loss: 1.791203498840332
Validation loss: 2.017898787734329

Epoch: 6| Step: 8
Training loss: 1.592984676361084
Validation loss: 2.0168940892783542

Epoch: 6| Step: 9
Training loss: 1.9808459281921387
Validation loss: 1.9877089620918356

Epoch: 6| Step: 10
Training loss: 1.8778353929519653
Validation loss: 1.9848760981713571

Epoch: 6| Step: 11
Training loss: 1.4968270063400269
Validation loss: 1.9775496170084963

Epoch: 6| Step: 12
Training loss: 1.6482776403427124
Validation loss: 1.980535412347445

Epoch: 6| Step: 13
Training loss: 1.658644199371338
Validation loss: 2.016083662227918

Epoch: 175| Step: 0
Training loss: 1.0626205205917358
Validation loss: 2.041061116803077

Epoch: 6| Step: 1
Training loss: 1.9395158290863037
Validation loss: 2.0855278020264

Epoch: 6| Step: 2
Training loss: 2.4084677696228027
Validation loss: 2.1253533247978456

Epoch: 6| Step: 3
Training loss: 1.4481501579284668
Validation loss: 2.116489170699991

Epoch: 6| Step: 4
Training loss: 2.2314743995666504
Validation loss: 2.1123389133843045

Epoch: 6| Step: 5
Training loss: 1.3595025539398193
Validation loss: 2.0952468841306624

Epoch: 6| Step: 6
Training loss: 1.664151668548584
Validation loss: 2.0475391803249234

Epoch: 6| Step: 7
Training loss: 1.6814372539520264
Validation loss: 2.0040504009492937

Epoch: 6| Step: 8
Training loss: 2.0731163024902344
Validation loss: 2.0097585185881583

Epoch: 6| Step: 9
Training loss: 2.1420395374298096
Validation loss: 2.0008130304275022

Epoch: 6| Step: 10
Training loss: 1.2461557388305664
Validation loss: 1.9744783627089633

Epoch: 6| Step: 11
Training loss: 1.6681641340255737
Validation loss: 1.9833065348286782

Epoch: 6| Step: 12
Training loss: 1.8601789474487305
Validation loss: 1.988718601965135

Epoch: 6| Step: 13
Training loss: 1.5280072689056396
Validation loss: 1.9897576442328833

Epoch: 176| Step: 0
Training loss: 1.8654687404632568
Validation loss: 2.006958205212829

Epoch: 6| Step: 1
Training loss: 1.5767755508422852
Validation loss: 2.007030128150858

Epoch: 6| Step: 2
Training loss: 1.3027141094207764
Validation loss: 2.0422959096970095

Epoch: 6| Step: 3
Training loss: 1.0114431381225586
Validation loss: 2.044155154176938

Epoch: 6| Step: 4
Training loss: 2.1687827110290527
Validation loss: 2.0391805338603195

Epoch: 6| Step: 5
Training loss: 1.5471010208129883
Validation loss: 2.025102478201671

Epoch: 6| Step: 6
Training loss: 1.941176414489746
Validation loss: 2.0147885302061677

Epoch: 6| Step: 7
Training loss: 1.4052108526229858
Validation loss: 2.000611102709206

Epoch: 6| Step: 8
Training loss: 1.6805126667022705
Validation loss: 1.9851722678830546

Epoch: 6| Step: 9
Training loss: 2.105229139328003
Validation loss: 2.0014436501328663

Epoch: 6| Step: 10
Training loss: 1.935387372970581
Validation loss: 2.0036972991881834

Epoch: 6| Step: 11
Training loss: 1.449080467224121
Validation loss: 2.0387825119879937

Epoch: 6| Step: 12
Training loss: 2.1869843006134033
Validation loss: 2.0416565274679535

Epoch: 6| Step: 13
Training loss: 2.4511806964874268
Validation loss: 2.0421400249645276

Epoch: 177| Step: 0
Training loss: 1.5369081497192383
Validation loss: 2.0468145801175024

Epoch: 6| Step: 1
Training loss: 1.98422372341156
Validation loss: 2.0556930085664153

Epoch: 6| Step: 2
Training loss: 1.3576843738555908
Validation loss: 2.0783283825843566

Epoch: 6| Step: 3
Training loss: 1.979986548423767
Validation loss: 2.0257245340654926

Epoch: 6| Step: 4
Training loss: 1.294787883758545
Validation loss: 1.9932895142544982

Epoch: 6| Step: 5
Training loss: 1.7953736782073975
Validation loss: 1.9974462665537351

Epoch: 6| Step: 6
Training loss: 0.9897226691246033
Validation loss: 1.9713475268374208

Epoch: 6| Step: 7
Training loss: 1.6833760738372803
Validation loss: 1.970491886138916

Epoch: 6| Step: 8
Training loss: 2.579677104949951
Validation loss: 1.9713038526555544

Epoch: 6| Step: 9
Training loss: 1.6771430969238281
Validation loss: 1.9864893651777698

Epoch: 6| Step: 10
Training loss: 1.8572547435760498
Validation loss: 1.979415133435239

Epoch: 6| Step: 11
Training loss: 2.146124839782715
Validation loss: 2.0069950626742457

Epoch: 6| Step: 12
Training loss: 1.8910508155822754
Validation loss: 2.017840159836636

Epoch: 6| Step: 13
Training loss: 0.8545675277709961
Validation loss: 2.061533094734274

Epoch: 178| Step: 0
Training loss: 2.361259698867798
Validation loss: 2.0703294405373196

Epoch: 6| Step: 1
Training loss: 1.7023680210113525
Validation loss: 2.0697522368482364

Epoch: 6| Step: 2
Training loss: 1.5844595432281494
Validation loss: 2.080989637682515

Epoch: 6| Step: 3
Training loss: 1.4625850915908813
Validation loss: 2.0582325919981925

Epoch: 6| Step: 4
Training loss: 1.550039529800415
Validation loss: 2.0561398165200346

Epoch: 6| Step: 5
Training loss: 1.023999810218811
Validation loss: 2.018010885484757

Epoch: 6| Step: 6
Training loss: 1.7479710578918457
Validation loss: 2.005275185390185

Epoch: 6| Step: 7
Training loss: 1.3708900213241577
Validation loss: 1.9740671650055917

Epoch: 6| Step: 8
Training loss: 2.182842493057251
Validation loss: 2.000097733671947

Epoch: 6| Step: 9
Training loss: 1.47262442111969
Validation loss: 1.9919761585932907

Epoch: 6| Step: 10
Training loss: 2.5762107372283936
Validation loss: 2.0116024632607736

Epoch: 6| Step: 11
Training loss: 1.002310037612915
Validation loss: 2.024402715826547

Epoch: 6| Step: 12
Training loss: 1.9488154649734497
Validation loss: 2.0491954793212233

Epoch: 6| Step: 13
Training loss: 2.057286500930786
Validation loss: 2.090361643862981

Epoch: 179| Step: 0
Training loss: 1.4228781461715698
Validation loss: 2.1445117637675297

Epoch: 6| Step: 1
Training loss: 1.7016342878341675
Validation loss: 2.172382095808624

Epoch: 6| Step: 2
Training loss: 1.4091510772705078
Validation loss: 2.17564961987157

Epoch: 6| Step: 3
Training loss: 2.313547372817993
Validation loss: 2.1732498189454437

Epoch: 6| Step: 4
Training loss: 1.6090080738067627
Validation loss: 2.11128835011554

Epoch: 6| Step: 5
Training loss: 1.504002332687378
Validation loss: 2.0629476116549585

Epoch: 6| Step: 6
Training loss: 1.3124959468841553
Validation loss: 2.031975620536394

Epoch: 6| Step: 7
Training loss: 1.7158348560333252
Validation loss: 2.004368934580075

Epoch: 6| Step: 8
Training loss: 1.5409023761749268
Validation loss: 1.9814867601599744

Epoch: 6| Step: 9
Training loss: 1.418649673461914
Validation loss: 1.9585419662537114

Epoch: 6| Step: 10
Training loss: 2.1068997383117676
Validation loss: 1.9564685693351171

Epoch: 6| Step: 11
Training loss: 2.578052282333374
Validation loss: 1.9601518146453365

Epoch: 6| Step: 12
Training loss: 1.927846908569336
Validation loss: 1.970366883021529

Epoch: 6| Step: 13
Training loss: 1.5354561805725098
Validation loss: 1.9638876017703806

Epoch: 180| Step: 0
Training loss: 1.489600658416748
Validation loss: 1.970298744017078

Epoch: 6| Step: 1
Training loss: 1.8165961503982544
Validation loss: 1.9887188660201205

Epoch: 6| Step: 2
Training loss: 1.425321340560913
Validation loss: 1.9806431416542298

Epoch: 6| Step: 3
Training loss: 1.5458433628082275
Validation loss: 1.965216189302424

Epoch: 6| Step: 4
Training loss: 1.573398232460022
Validation loss: 1.964455105925119

Epoch: 6| Step: 5
Training loss: 1.5684876441955566
Validation loss: 1.955590562153888

Epoch: 6| Step: 6
Training loss: 1.413502812385559
Validation loss: 1.9478079426673152

Epoch: 6| Step: 7
Training loss: 1.7422311305999756
Validation loss: 1.9660777481653358

Epoch: 6| Step: 8
Training loss: 2.2261102199554443
Validation loss: 1.9914727095634706

Epoch: 6| Step: 9
Training loss: 2.179691791534424
Validation loss: 2.0094974348621983

Epoch: 6| Step: 10
Training loss: 1.8523759841918945
Validation loss: 2.005006895270399

Epoch: 6| Step: 11
Training loss: 1.8837604522705078
Validation loss: 2.0035715949150825

Epoch: 6| Step: 12
Training loss: 1.64524507522583
Validation loss: 1.9859660133238761

Epoch: 6| Step: 13
Training loss: 1.475789189338684
Validation loss: 1.9821584327246553

Epoch: 181| Step: 0
Training loss: 1.359863519668579
Validation loss: 1.9731800979183567

Epoch: 6| Step: 1
Training loss: 1.9026840925216675
Validation loss: 1.9451916781804894

Epoch: 6| Step: 2
Training loss: 1.6176645755767822
Validation loss: 1.9388384844667168

Epoch: 6| Step: 3
Training loss: 1.2821769714355469
Validation loss: 1.923787619477959

Epoch: 6| Step: 4
Training loss: 1.9016193151474
Validation loss: 1.9539579832425682

Epoch: 6| Step: 5
Training loss: 2.0686943531036377
Validation loss: 1.9634505779512468

Epoch: 6| Step: 6
Training loss: 1.5051251649856567
Validation loss: 1.9729560741814234

Epoch: 6| Step: 7
Training loss: 2.118716239929199
Validation loss: 1.989696769304173

Epoch: 6| Step: 8
Training loss: 1.6536813974380493
Validation loss: 2.0182019997668523

Epoch: 6| Step: 9
Training loss: 1.7640435695648193
Validation loss: 2.0667279753633725

Epoch: 6| Step: 10
Training loss: 2.0712475776672363
Validation loss: 2.089832059798702

Epoch: 6| Step: 11
Training loss: 2.146559476852417
Validation loss: 2.0882834208908903

Epoch: 6| Step: 12
Training loss: 1.3543528318405151
Validation loss: 2.076656013406733

Epoch: 6| Step: 13
Training loss: 0.8728201389312744
Validation loss: 2.0704970795621156

Epoch: 182| Step: 0
Training loss: 2.309157609939575
Validation loss: 2.042791912632604

Epoch: 6| Step: 1
Training loss: 1.4139755964279175
Validation loss: 2.027046331795313

Epoch: 6| Step: 2
Training loss: 1.580620527267456
Validation loss: 2.0150011483059136

Epoch: 6| Step: 3
Training loss: 1.9047484397888184
Validation loss: 1.959747064498163

Epoch: 6| Step: 4
Training loss: 1.2528071403503418
Validation loss: 1.9700350120503416

Epoch: 6| Step: 5
Training loss: 1.803688883781433
Validation loss: 1.961308676709411

Epoch: 6| Step: 6
Training loss: 2.0491738319396973
Validation loss: 1.960904775127288

Epoch: 6| Step: 7
Training loss: 1.5884956121444702
Validation loss: 1.9581198897413028

Epoch: 6| Step: 8
Training loss: 1.4654569625854492
Validation loss: 1.976493590621538

Epoch: 6| Step: 9
Training loss: 0.8169664144515991
Validation loss: 1.968391651748329

Epoch: 6| Step: 10
Training loss: 2.059887409210205
Validation loss: 1.985203686580863

Epoch: 6| Step: 11
Training loss: 1.6272718906402588
Validation loss: 2.011717568161667

Epoch: 6| Step: 12
Training loss: 1.5621867179870605
Validation loss: 2.021895800867388

Epoch: 6| Step: 13
Training loss: 2.004828453063965
Validation loss: 2.039551042741345

Epoch: 183| Step: 0
Training loss: 1.3777761459350586
Validation loss: 2.070119562969413

Epoch: 6| Step: 1
Training loss: 1.759097695350647
Validation loss: 2.0474443153668473

Epoch: 6| Step: 2
Training loss: 2.639787435531616
Validation loss: 2.0276510048938055

Epoch: 6| Step: 3
Training loss: 1.3496648073196411
Validation loss: 2.0550000436844362

Epoch: 6| Step: 4
Training loss: 1.2418677806854248
Validation loss: 2.0293860179121777

Epoch: 6| Step: 5
Training loss: 1.2746467590332031
Validation loss: 2.04905149116311

Epoch: 6| Step: 6
Training loss: 1.652321219444275
Validation loss: 2.0414027911360546

Epoch: 6| Step: 7
Training loss: 1.3201401233673096
Validation loss: 2.0283092529542985

Epoch: 6| Step: 8
Training loss: 1.6730797290802002
Validation loss: 2.0523070955789215

Epoch: 6| Step: 9
Training loss: 1.4483399391174316
Validation loss: 2.062527261754518

Epoch: 6| Step: 10
Training loss: 1.5712299346923828
Validation loss: 2.057223654562427

Epoch: 6| Step: 11
Training loss: 2.8321189880371094
Validation loss: 2.0234376999639694

Epoch: 6| Step: 12
Training loss: 1.3989777565002441
Validation loss: 2.012738404735442

Epoch: 6| Step: 13
Training loss: 1.544260025024414
Validation loss: 1.9716105256029355

Epoch: 184| Step: 0
Training loss: 1.3344178199768066
Validation loss: 1.93995447697178

Epoch: 6| Step: 1
Training loss: 1.4197015762329102
Validation loss: 1.964197345959243

Epoch: 6| Step: 2
Training loss: 1.4492473602294922
Validation loss: 1.968602584254357

Epoch: 6| Step: 3
Training loss: 1.8717436790466309
Validation loss: 1.965007862737102

Epoch: 6| Step: 4
Training loss: 1.4636671543121338
Validation loss: 1.9545405244314542

Epoch: 6| Step: 5
Training loss: 1.0481868982315063
Validation loss: 1.985779567431378

Epoch: 6| Step: 6
Training loss: 2.1214888095855713
Validation loss: 1.9436916253900016

Epoch: 6| Step: 7
Training loss: 2.7340335845947266
Validation loss: 1.968580299808133

Epoch: 6| Step: 8
Training loss: 1.2781563997268677
Validation loss: 1.9857593890159362

Epoch: 6| Step: 9
Training loss: 1.1705834865570068
Validation loss: 1.9787456732924267

Epoch: 6| Step: 10
Training loss: 1.5816690921783447
Validation loss: 1.9823587453493507

Epoch: 6| Step: 11
Training loss: 1.7940014600753784
Validation loss: 2.01161164622153

Epoch: 6| Step: 12
Training loss: 2.1904067993164062
Validation loss: 2.0349833311573153

Epoch: 6| Step: 13
Training loss: 1.3804389238357544
Validation loss: 2.013597111548147

Epoch: 185| Step: 0
Training loss: 1.4280309677124023
Validation loss: 2.0127555067821215

Epoch: 6| Step: 1
Training loss: 2.096226215362549
Validation loss: 1.982390119183448

Epoch: 6| Step: 2
Training loss: 1.2180278301239014
Validation loss: 1.9834940792411886

Epoch: 6| Step: 3
Training loss: 1.5661237239837646
Validation loss: 1.9584441197815763

Epoch: 6| Step: 4
Training loss: 0.9491757154464722
Validation loss: 1.9808650132148498

Epoch: 6| Step: 5
Training loss: 1.9875359535217285
Validation loss: 1.9873034543888544

Epoch: 6| Step: 6
Training loss: 1.748711347579956
Validation loss: 1.9909780615119523

Epoch: 6| Step: 7
Training loss: 1.679642677307129
Validation loss: 1.9634329029308852

Epoch: 6| Step: 8
Training loss: 1.7026326656341553
Validation loss: 1.9737178971690517

Epoch: 6| Step: 9
Training loss: 1.9227641820907593
Validation loss: 1.9874584392834735

Epoch: 6| Step: 10
Training loss: 1.358527660369873
Validation loss: 2.0021163161082933

Epoch: 6| Step: 11
Training loss: 1.5607984066009521
Validation loss: 1.9638189833651307

Epoch: 6| Step: 12
Training loss: 2.242158889770508
Validation loss: 1.9481021934939968

Epoch: 6| Step: 13
Training loss: 1.2244987487792969
Validation loss: 1.9246167623868553

Epoch: 186| Step: 0
Training loss: 1.8917183876037598
Validation loss: 1.9175257118799354

Epoch: 6| Step: 1
Training loss: 1.547102451324463
Validation loss: 1.9067000971045545

Epoch: 6| Step: 2
Training loss: 1.5623736381530762
Validation loss: 1.9171244329021824

Epoch: 6| Step: 3
Training loss: 0.9011375308036804
Validation loss: 1.9311084606314217

Epoch: 6| Step: 4
Training loss: 1.2575488090515137
Validation loss: 1.9219986033696

Epoch: 6| Step: 5
Training loss: 1.5580698251724243
Validation loss: 1.9256388384808776

Epoch: 6| Step: 6
Training loss: 1.4482122659683228
Validation loss: 1.9437622818895566

Epoch: 6| Step: 7
Training loss: 0.9307349920272827
Validation loss: 1.994371057838522

Epoch: 6| Step: 8
Training loss: 1.744489312171936
Validation loss: 1.9860801709595548

Epoch: 6| Step: 9
Training loss: 1.9475017786026
Validation loss: 2.0001543106571322

Epoch: 6| Step: 10
Training loss: 1.5067496299743652
Validation loss: 1.9965927318860126

Epoch: 6| Step: 11
Training loss: 2.4268476963043213
Validation loss: 1.9792578810004777

Epoch: 6| Step: 12
Training loss: 1.8265351057052612
Validation loss: 1.9785125204311904

Epoch: 6| Step: 13
Training loss: 2.0821962356567383
Validation loss: 1.9319442933605564

Epoch: 187| Step: 0
Training loss: 1.7575170993804932
Validation loss: 1.9355758851574314

Epoch: 6| Step: 1
Training loss: 1.391467571258545
Validation loss: 1.9304396901079404

Epoch: 6| Step: 2
Training loss: 1.2698276042938232
Validation loss: 1.9159632652036604

Epoch: 6| Step: 3
Training loss: 0.9936301708221436
Validation loss: 1.9311535794247863

Epoch: 6| Step: 4
Training loss: 2.275639057159424
Validation loss: 1.9533045637992121

Epoch: 6| Step: 5
Training loss: 1.7792105674743652
Validation loss: 1.9628254816096316

Epoch: 6| Step: 6
Training loss: 1.6645585298538208
Validation loss: 1.980932661282119

Epoch: 6| Step: 7
Training loss: 1.4649704694747925
Validation loss: 2.0409640881323043

Epoch: 6| Step: 8
Training loss: 2.0507309436798096
Validation loss: 2.0830397528986775

Epoch: 6| Step: 9
Training loss: 0.7371207475662231
Validation loss: 2.1141238545858734

Epoch: 6| Step: 10
Training loss: 2.2904281616210938
Validation loss: 2.097889264424642

Epoch: 6| Step: 11
Training loss: 1.7946319580078125
Validation loss: 2.037354915372787

Epoch: 6| Step: 12
Training loss: 1.3118228912353516
Validation loss: 1.9861351507966236

Epoch: 6| Step: 13
Training loss: 1.668528437614441
Validation loss: 1.9463967405339724

Epoch: 188| Step: 0
Training loss: 2.159388780593872
Validation loss: 1.9426993670002106

Epoch: 6| Step: 1
Training loss: 1.6386332511901855
Validation loss: 1.928706225528512

Epoch: 6| Step: 2
Training loss: 1.5157291889190674
Validation loss: 1.9470551424129035

Epoch: 6| Step: 3
Training loss: 2.1789422035217285
Validation loss: 1.9442047419086579

Epoch: 6| Step: 4
Training loss: 1.0770386457443237
Validation loss: 1.962780116706766

Epoch: 6| Step: 5
Training loss: 1.0002069473266602
Validation loss: 1.990796871082757

Epoch: 6| Step: 6
Training loss: 1.4883167743682861
Validation loss: 2.0342578682848202

Epoch: 6| Step: 7
Training loss: 1.6810340881347656
Validation loss: 2.0816772842919953

Epoch: 6| Step: 8
Training loss: 1.4449081420898438
Validation loss: 2.0748664909793484

Epoch: 6| Step: 9
Training loss: 1.8759353160858154
Validation loss: 2.083715849025275

Epoch: 6| Step: 10
Training loss: 1.665594220161438
Validation loss: 2.0521479383591683

Epoch: 6| Step: 11
Training loss: 1.3938478231430054
Validation loss: 2.0249778660394813

Epoch: 6| Step: 12
Training loss: 1.4961013793945312
Validation loss: 2.001996012144191

Epoch: 6| Step: 13
Training loss: 0.7960662841796875
Validation loss: 1.9800501664479573

Epoch: 189| Step: 0
Training loss: 1.64888334274292
Validation loss: 1.9520795986216555

Epoch: 6| Step: 1
Training loss: 1.528031349182129
Validation loss: 1.939259941859912

Epoch: 6| Step: 2
Training loss: 2.2288668155670166
Validation loss: 1.9425972046390656

Epoch: 6| Step: 3
Training loss: 1.393282175064087
Validation loss: 1.9514630558670207

Epoch: 6| Step: 4
Training loss: 1.9449894428253174
Validation loss: 1.9490646867341892

Epoch: 6| Step: 5
Training loss: 0.9178330302238464
Validation loss: 1.950472640734847

Epoch: 6| Step: 6
Training loss: 1.428055763244629
Validation loss: 1.9588270238650742

Epoch: 6| Step: 7
Training loss: 1.4357881546020508
Validation loss: 1.9647992657076927

Epoch: 6| Step: 8
Training loss: 1.5709856748580933
Validation loss: 1.9821273780638171

Epoch: 6| Step: 9
Training loss: 1.2891786098480225
Validation loss: 2.008957180925595

Epoch: 6| Step: 10
Training loss: 1.4868381023406982
Validation loss: 2.02742346384192

Epoch: 6| Step: 11
Training loss: 1.4103128910064697
Validation loss: 2.0265530950279644

Epoch: 6| Step: 12
Training loss: 1.723940134048462
Validation loss: 2.011378803560811

Epoch: 6| Step: 13
Training loss: 1.5921224355697632
Validation loss: 1.9853487527498634

Epoch: 190| Step: 0
Training loss: 1.5879408121109009
Validation loss: 1.95987650527749

Epoch: 6| Step: 1
Training loss: 1.8398795127868652
Validation loss: 1.9359403874284478

Epoch: 6| Step: 2
Training loss: 1.9992663860321045
Validation loss: 1.9007436921519618

Epoch: 6| Step: 3
Training loss: 0.9301165342330933
Validation loss: 1.8853225272188905

Epoch: 6| Step: 4
Training loss: 1.40414559841156
Validation loss: 1.9028805814763552

Epoch: 6| Step: 5
Training loss: 1.4941933155059814
Validation loss: 1.9047932701726114

Epoch: 6| Step: 6
Training loss: 1.527071475982666
Validation loss: 1.9273568455890944

Epoch: 6| Step: 7
Training loss: 1.1278252601623535
Validation loss: 1.9319624849545058

Epoch: 6| Step: 8
Training loss: 2.013296604156494
Validation loss: 1.9699021077925158

Epoch: 6| Step: 9
Training loss: 1.5873348712921143
Validation loss: 1.9949557089036511

Epoch: 6| Step: 10
Training loss: 1.519433617591858
Validation loss: 1.9753983456601378

Epoch: 6| Step: 11
Training loss: 1.5444424152374268
Validation loss: 1.9727688168966642

Epoch: 6| Step: 12
Training loss: 1.3237971067428589
Validation loss: 1.953443838704017

Epoch: 6| Step: 13
Training loss: 0.9171984195709229
Validation loss: 1.944031697447582

Epoch: 191| Step: 0
Training loss: 1.324617862701416
Validation loss: 1.9128388166427612

Epoch: 6| Step: 1
Training loss: 1.017474889755249
Validation loss: 1.9365287596179592

Epoch: 6| Step: 2
Training loss: 1.345753788948059
Validation loss: 1.929897726223033

Epoch: 6| Step: 3
Training loss: 1.5004616975784302
Validation loss: 1.9615607030930058

Epoch: 6| Step: 4
Training loss: 1.8351945877075195
Validation loss: 1.9576907132261543

Epoch: 6| Step: 5
Training loss: 1.9368066787719727
Validation loss: 1.985754971863121

Epoch: 6| Step: 6
Training loss: 1.5630667209625244
Validation loss: 2.0164214154725433

Epoch: 6| Step: 7
Training loss: 1.850203275680542
Validation loss: 1.9810421659100441

Epoch: 6| Step: 8
Training loss: 1.378332495689392
Validation loss: 1.967010744156376

Epoch: 6| Step: 9
Training loss: 1.5186407566070557
Validation loss: 1.9560734148948424

Epoch: 6| Step: 10
Training loss: 1.4084758758544922
Validation loss: 1.9133019575508692

Epoch: 6| Step: 11
Training loss: 1.6324849128723145
Validation loss: 1.880193466781288

Epoch: 6| Step: 12
Training loss: 1.3375390768051147
Validation loss: 1.8938452454023464

Epoch: 6| Step: 13
Training loss: 1.1514747142791748
Validation loss: 1.8951895108786962

Epoch: 192| Step: 0
Training loss: 1.9060076475143433
Validation loss: 1.8918154342200166

Epoch: 6| Step: 1
Training loss: 0.6946712732315063
Validation loss: 1.8957247541796776

Epoch: 6| Step: 2
Training loss: 1.4392378330230713
Validation loss: 1.9429258992595058

Epoch: 6| Step: 3
Training loss: 1.8996853828430176
Validation loss: 1.9546886208236858

Epoch: 6| Step: 4
Training loss: 1.6076953411102295
Validation loss: 1.9591693596173358

Epoch: 6| Step: 5
Training loss: 1.0684559345245361
Validation loss: 1.9674532964665403

Epoch: 6| Step: 6
Training loss: 2.416067600250244
Validation loss: 1.9856703460857432

Epoch: 6| Step: 7
Training loss: 1.284280776977539
Validation loss: 1.9810126699427122

Epoch: 6| Step: 8
Training loss: 1.684801697731018
Validation loss: 1.9087129972314323

Epoch: 6| Step: 9
Training loss: 1.7825629711151123
Validation loss: 1.8912018832340036

Epoch: 6| Step: 10
Training loss: 1.2598240375518799
Validation loss: 1.8956740005041963

Epoch: 6| Step: 11
Training loss: 1.7444782257080078
Validation loss: 1.8931675329003284

Epoch: 6| Step: 12
Training loss: 1.0158648490905762
Validation loss: 1.9011023698314544

Epoch: 6| Step: 13
Training loss: 1.162249207496643
Validation loss: 1.914007185607828

Epoch: 193| Step: 0
Training loss: 1.6363310813903809
Validation loss: 1.965388762053623

Epoch: 6| Step: 1
Training loss: 0.901172399520874
Validation loss: 1.9773279979664793

Epoch: 6| Step: 2
Training loss: 1.722296953201294
Validation loss: 1.9830472969239759

Epoch: 6| Step: 3
Training loss: 0.7387170791625977
Validation loss: 2.00175751409223

Epoch: 6| Step: 4
Training loss: 1.823150634765625
Validation loss: 1.9934961923988916

Epoch: 6| Step: 5
Training loss: 1.3746925592422485
Validation loss: 2.0053785923988587

Epoch: 6| Step: 6
Training loss: 1.2120158672332764
Validation loss: 1.977135096826861

Epoch: 6| Step: 7
Training loss: 1.9641927480697632
Validation loss: 1.9194771987135693

Epoch: 6| Step: 8
Training loss: 1.4505078792572021
Validation loss: 1.9015353892439155

Epoch: 6| Step: 9
Training loss: 2.2322797775268555
Validation loss: 1.8922916919954362

Epoch: 6| Step: 10
Training loss: 1.9338876008987427
Validation loss: 1.8800946358711488

Epoch: 6| Step: 11
Training loss: 1.1622921228408813
Validation loss: 1.883212674048639

Epoch: 6| Step: 12
Training loss: 1.3207893371582031
Validation loss: 1.8708804602264075

Epoch: 6| Step: 13
Training loss: 1.5313096046447754
Validation loss: 1.860851635215103

Epoch: 194| Step: 0
Training loss: 1.0478222370147705
Validation loss: 1.8696862933456257

Epoch: 6| Step: 1
Training loss: 1.5558114051818848
Validation loss: 1.898846177644627

Epoch: 6| Step: 2
Training loss: 2.1055614948272705
Validation loss: 1.9380875813063754

Epoch: 6| Step: 3
Training loss: 0.9993445873260498
Validation loss: 1.9656813349775089

Epoch: 6| Step: 4
Training loss: 0.6368747353553772
Validation loss: 1.9860125587832542

Epoch: 6| Step: 5
Training loss: 1.1202867031097412
Validation loss: 1.9661888460959158

Epoch: 6| Step: 6
Training loss: 1.8490257263183594
Validation loss: 1.9455434276211647

Epoch: 6| Step: 7
Training loss: 1.2618110179901123
Validation loss: 1.8972277000386228

Epoch: 6| Step: 8
Training loss: 1.7394741773605347
Validation loss: 1.8902141009607623

Epoch: 6| Step: 9
Training loss: 1.6905001401901245
Validation loss: 1.9164131790079095

Epoch: 6| Step: 10
Training loss: 2.203444480895996
Validation loss: 1.9219788941003944

Epoch: 6| Step: 11
Training loss: 1.4620932340621948
Validation loss: 1.9551059020462858

Epoch: 6| Step: 12
Training loss: 1.5602624416351318
Validation loss: 1.9682959100251556

Epoch: 6| Step: 13
Training loss: 1.6256496906280518
Validation loss: 1.9643000479667418

Epoch: 195| Step: 0
Training loss: 1.417337417602539
Validation loss: 1.9791296630777337

Epoch: 6| Step: 1
Training loss: 1.2704179286956787
Validation loss: 1.9827599269087597

Epoch: 6| Step: 2
Training loss: 1.8406356573104858
Validation loss: 1.9982729278584963

Epoch: 6| Step: 3
Training loss: 1.044938087463379
Validation loss: 2.015779790057931

Epoch: 6| Step: 4
Training loss: 1.8238226175308228
Validation loss: 2.016495300877479

Epoch: 6| Step: 5
Training loss: 1.623686671257019
Validation loss: 2.0068006387320896

Epoch: 6| Step: 6
Training loss: 2.0117506980895996
Validation loss: 1.9563546539634786

Epoch: 6| Step: 7
Training loss: 1.12160062789917
Validation loss: 1.9512595643279373

Epoch: 6| Step: 8
Training loss: 1.338895559310913
Validation loss: 1.9225410312734625

Epoch: 6| Step: 9
Training loss: 1.5665642023086548
Validation loss: 1.9089619754463114

Epoch: 6| Step: 10
Training loss: 0.716528594493866
Validation loss: 1.9128015361806399

Epoch: 6| Step: 11
Training loss: 1.9687154293060303
Validation loss: 1.9309634764989216

Epoch: 6| Step: 12
Training loss: 1.157182216644287
Validation loss: 1.9683537893397833

Epoch: 6| Step: 13
Training loss: 1.8276171684265137
Validation loss: 1.9600379941284016

Epoch: 196| Step: 0
Training loss: 1.5133121013641357
Validation loss: 1.9540450970331829

Epoch: 6| Step: 1
Training loss: 1.0491275787353516
Validation loss: 1.9249703845670145

Epoch: 6| Step: 2
Training loss: 0.9056784510612488
Validation loss: 1.9099290499123194

Epoch: 6| Step: 3
Training loss: 1.8644590377807617
Validation loss: 1.8864272191960325

Epoch: 6| Step: 4
Training loss: 1.5544745922088623
Validation loss: 1.8980985059533069

Epoch: 6| Step: 5
Training loss: 2.091242551803589
Validation loss: 1.8978071725496681

Epoch: 6| Step: 6
Training loss: 1.1659965515136719
Validation loss: 1.8939546718392322

Epoch: 6| Step: 7
Training loss: 1.0505261421203613
Validation loss: 1.9155491308499408

Epoch: 6| Step: 8
Training loss: 1.1996407508850098
Validation loss: 1.9259398611642982

Epoch: 6| Step: 9
Training loss: 1.603568196296692
Validation loss: 1.9599746914320095

Epoch: 6| Step: 10
Training loss: 1.4950261116027832
Validation loss: 2.005142173459453

Epoch: 6| Step: 11
Training loss: 0.9438380002975464
Validation loss: 2.0149916859083277

Epoch: 6| Step: 12
Training loss: 2.313455104827881
Validation loss: 2.0098755898014193

Epoch: 6| Step: 13
Training loss: 1.6274144649505615
Validation loss: 1.9942498002001035

Epoch: 197| Step: 0
Training loss: 1.9351316690444946
Validation loss: 1.9261439000406573

Epoch: 6| Step: 1
Training loss: 0.9918402433395386
Validation loss: 1.9220958050861154

Epoch: 6| Step: 2
Training loss: 1.4808082580566406
Validation loss: 1.9083424768140238

Epoch: 6| Step: 3
Training loss: 1.3373897075653076
Validation loss: 1.9081133924504763

Epoch: 6| Step: 4
Training loss: 1.7081103324890137
Validation loss: 1.8836739281172394

Epoch: 6| Step: 5
Training loss: 1.6328964233398438
Validation loss: 1.881417824376014

Epoch: 6| Step: 6
Training loss: 1.2098361253738403
Validation loss: 1.893811260500262

Epoch: 6| Step: 7
Training loss: 1.2114276885986328
Validation loss: 1.8581067105775237

Epoch: 6| Step: 8
Training loss: 1.5906667709350586
Validation loss: 1.9131111534692908

Epoch: 6| Step: 9
Training loss: 1.4964439868927002
Validation loss: 1.891465446000458

Epoch: 6| Step: 10
Training loss: 1.4594526290893555
Validation loss: 1.9158955607362973

Epoch: 6| Step: 11
Training loss: 1.163470983505249
Validation loss: 1.8983473829043809

Epoch: 6| Step: 12
Training loss: 1.4308490753173828
Validation loss: 1.9309876400937316

Epoch: 6| Step: 13
Training loss: 1.0449483394622803
Validation loss: 1.9516119764697166

Epoch: 198| Step: 0
Training loss: 1.3145537376403809
Validation loss: 1.9845450860197826

Epoch: 6| Step: 1
Training loss: 1.4052746295928955
Validation loss: 2.05761613897098

Epoch: 6| Step: 2
Training loss: 1.6890501976013184
Validation loss: 2.0576276830447617

Epoch: 6| Step: 3
Training loss: 1.5333421230316162
Validation loss: 2.0683292868316814

Epoch: 6| Step: 4
Training loss: 1.3997939825057983
Validation loss: 2.010911164745208

Epoch: 6| Step: 5
Training loss: 1.5686235427856445
Validation loss: 1.953002986087594

Epoch: 6| Step: 6
Training loss: 1.2083767652511597
Validation loss: 1.8861491859600108

Epoch: 6| Step: 7
Training loss: 1.0680205821990967
Validation loss: 1.8605100826550556

Epoch: 6| Step: 8
Training loss: 2.2361888885498047
Validation loss: 1.875833660043696

Epoch: 6| Step: 9
Training loss: 1.7305209636688232
Validation loss: 1.8583768055003176

Epoch: 6| Step: 10
Training loss: 1.4106696844100952
Validation loss: 1.8818789656444261

Epoch: 6| Step: 11
Training loss: 1.3789074420928955
Validation loss: 1.8907349968469271

Epoch: 6| Step: 12
Training loss: 1.345064401626587
Validation loss: 1.8753230533292216

Epoch: 6| Step: 13
Training loss: 0.3609609007835388
Validation loss: 1.8440000190529773

Epoch: 199| Step: 0
Training loss: 1.4981552362442017
Validation loss: 1.925054996244369

Epoch: 6| Step: 1
Training loss: 1.8328849077224731
Validation loss: 1.9416845665183118

Epoch: 6| Step: 2
Training loss: 1.621582269668579
Validation loss: 2.017537639987084

Epoch: 6| Step: 3
Training loss: 1.3211004734039307
Validation loss: 2.031465922632525

Epoch: 6| Step: 4
Training loss: 1.6198114156723022
Validation loss: 2.014443178330698

Epoch: 6| Step: 5
Training loss: 1.3828084468841553
Validation loss: 2.0052811689274286

Epoch: 6| Step: 6
Training loss: 1.5833971500396729
Validation loss: 1.975388357716222

Epoch: 6| Step: 7
Training loss: 1.2113535404205322
Validation loss: 1.9338618055466683

Epoch: 6| Step: 8
Training loss: 1.4553074836730957
Validation loss: 1.9173630206815657

Epoch: 6| Step: 9
Training loss: 1.3738899230957031
Validation loss: 1.8857352400338778

Epoch: 6| Step: 10
Training loss: 1.5441678762435913
Validation loss: 1.9141150623239496

Epoch: 6| Step: 11
Training loss: 1.092749834060669
Validation loss: 1.9253329871803202

Epoch: 6| Step: 12
Training loss: 1.2002873420715332
Validation loss: 1.934602040116505

Epoch: 6| Step: 13
Training loss: 1.1002540588378906
Validation loss: 1.9444538790692565

Epoch: 200| Step: 0
Training loss: 1.2208514213562012
Validation loss: 1.9357387199196765

Epoch: 6| Step: 1
Training loss: 1.4981516599655151
Validation loss: 1.970958068806638

Epoch: 6| Step: 2
Training loss: 1.7453572750091553
Validation loss: 1.9572728526207708

Epoch: 6| Step: 3
Training loss: 1.4218735694885254
Validation loss: 1.9354998245034167

Epoch: 6| Step: 4
Training loss: 1.0808488130569458
Validation loss: 1.9192625245740336

Epoch: 6| Step: 5
Training loss: 1.1941133737564087
Validation loss: 1.912872245234828

Epoch: 6| Step: 6
Training loss: 1.4610859155654907
Validation loss: 1.877692896832702

Epoch: 6| Step: 7
Training loss: 1.5536136627197266
Validation loss: 1.8649509645277453

Epoch: 6| Step: 8
Training loss: 1.8383591175079346
Validation loss: 1.8557675551342707

Epoch: 6| Step: 9
Training loss: 1.3784000873565674
Validation loss: 1.8364691426677089

Epoch: 6| Step: 10
Training loss: 1.9118971824645996
Validation loss: 1.8402553707040765

Epoch: 6| Step: 11
Training loss: 0.7676117420196533
Validation loss: 1.8468347698129632

Epoch: 6| Step: 12
Training loss: 1.2567470073699951
Validation loss: 1.868591062484249

Epoch: 6| Step: 13
Training loss: 1.0098741054534912
Validation loss: 1.8938994176926152

Epoch: 201| Step: 0
Training loss: 1.1621594429016113
Validation loss: 1.9537367846376152

Epoch: 6| Step: 1
Training loss: 2.063098192214966
Validation loss: 2.012650864098662

Epoch: 6| Step: 2
Training loss: 1.9270713329315186
Validation loss: 2.0900572705012497

Epoch: 6| Step: 3
Training loss: 0.8700692653656006
Validation loss: 2.0812242287461475

Epoch: 6| Step: 4
Training loss: 2.0888760089874268
Validation loss: 1.992246804698821

Epoch: 6| Step: 5
Training loss: 1.722280740737915
Validation loss: 1.9638742246935446

Epoch: 6| Step: 6
Training loss: 1.093933343887329
Validation loss: 1.9276689316636773

Epoch: 6| Step: 7
Training loss: 0.8214550614356995
Validation loss: 1.8630996404155609

Epoch: 6| Step: 8
Training loss: 1.6680597066879272
Validation loss: 1.898755508084451

Epoch: 6| Step: 9
Training loss: 1.777185320854187
Validation loss: 1.8841340798203663

Epoch: 6| Step: 10
Training loss: 1.7634222507476807
Validation loss: 1.8511510625962289

Epoch: 6| Step: 11
Training loss: 1.14653480052948
Validation loss: 1.8492533545340262

Epoch: 6| Step: 12
Training loss: 1.1607098579406738
Validation loss: 1.8400247635379914

Epoch: 6| Step: 13
Training loss: 0.822603702545166
Validation loss: 1.829671226521974

Epoch: 202| Step: 0
Training loss: 1.1976617574691772
Validation loss: 1.8435312676173385

Epoch: 6| Step: 1
Training loss: 1.213780403137207
Validation loss: 1.8131571251858947

Epoch: 6| Step: 2
Training loss: 1.4112510681152344
Validation loss: 1.8412249780470324

Epoch: 6| Step: 3
Training loss: 0.8756983280181885
Validation loss: 1.8445745693740023

Epoch: 6| Step: 4
Training loss: 1.578282117843628
Validation loss: 1.866393966059531

Epoch: 6| Step: 5
Training loss: 1.6471824645996094
Validation loss: 1.8531111017350228

Epoch: 6| Step: 6
Training loss: 1.4986464977264404
Validation loss: 1.8513327055079962

Epoch: 6| Step: 7
Training loss: 1.5591083765029907
Validation loss: 1.8603671443077825

Epoch: 6| Step: 8
Training loss: 1.598514437675476
Validation loss: 1.8928855913941578

Epoch: 6| Step: 9
Training loss: 1.5753209590911865
Validation loss: 1.8737182553096483

Epoch: 6| Step: 10
Training loss: 1.7801990509033203
Validation loss: 1.9023428732349026

Epoch: 6| Step: 11
Training loss: 1.4317853450775146
Validation loss: 1.8843114581159366

Epoch: 6| Step: 12
Training loss: 0.8996987342834473
Validation loss: 1.9316344184260215

Epoch: 6| Step: 13
Training loss: 1.7359623908996582
Validation loss: 1.9494490238928026

Epoch: 203| Step: 0
Training loss: 1.2895480394363403
Validation loss: 1.950959445327841

Epoch: 6| Step: 1
Training loss: 0.9500620365142822
Validation loss: 1.9317754571155836

Epoch: 6| Step: 2
Training loss: 1.966968297958374
Validation loss: 1.9355925821488904

Epoch: 6| Step: 3
Training loss: 1.5788722038269043
Validation loss: 1.9343459798443703

Epoch: 6| Step: 4
Training loss: 1.51393723487854
Validation loss: 1.9290227787469023

Epoch: 6| Step: 5
Training loss: 1.4184285402297974
Validation loss: 1.9298438551605388

Epoch: 6| Step: 6
Training loss: 1.4043394327163696
Validation loss: 1.9027053053661058

Epoch: 6| Step: 7
Training loss: 1.3733665943145752
Validation loss: 1.909972624112201

Epoch: 6| Step: 8
Training loss: 0.8501735925674438
Validation loss: 1.931980497093611

Epoch: 6| Step: 9
Training loss: 1.9156005382537842
Validation loss: 1.9613035725009056

Epoch: 6| Step: 10
Training loss: 1.574755072593689
Validation loss: 1.982319680593347

Epoch: 6| Step: 11
Training loss: 1.1672673225402832
Validation loss: 1.957806384691628

Epoch: 6| Step: 12
Training loss: 1.2400996685028076
Validation loss: 1.9292503736352409

Epoch: 6| Step: 13
Training loss: 0.843902051448822
Validation loss: 1.9138514944302139

Epoch: 204| Step: 0
Training loss: 1.4732134342193604
Validation loss: 1.9154824890116209

Epoch: 6| Step: 1
Training loss: 0.8416316509246826
Validation loss: 1.8862152343155236

Epoch: 6| Step: 2
Training loss: 1.2274836301803589
Validation loss: 1.8830391694140691

Epoch: 6| Step: 3
Training loss: 1.1338152885437012
Validation loss: 1.857346696238364

Epoch: 6| Step: 4
Training loss: 1.5896539688110352
Validation loss: 1.8656870293360885

Epoch: 6| Step: 5
Training loss: 1.5090237855911255
Validation loss: 1.8651152323651057

Epoch: 6| Step: 6
Training loss: 0.8196092844009399
Validation loss: 1.9041938781738281

Epoch: 6| Step: 7
Training loss: 1.1860852241516113
Validation loss: 1.8982685971003708

Epoch: 6| Step: 8
Training loss: 1.221725344657898
Validation loss: 1.9080651998519897

Epoch: 6| Step: 9
Training loss: 1.821326494216919
Validation loss: 1.9470020788972096

Epoch: 6| Step: 10
Training loss: 1.241119623184204
Validation loss: 1.9659181205175256

Epoch: 6| Step: 11
Training loss: 1.6356462240219116
Validation loss: 1.9868904057369436

Epoch: 6| Step: 12
Training loss: 1.5174716711044312
Validation loss: 1.9481448717014764

Epoch: 6| Step: 13
Training loss: 1.6439014673233032
Validation loss: 1.9155455545712543

Epoch: 205| Step: 0
Training loss: 1.01260244846344
Validation loss: 1.8878282923852243

Epoch: 6| Step: 1
Training loss: 2.1418099403381348
Validation loss: 1.8783963598230833

Epoch: 6| Step: 2
Training loss: 1.1836053133010864
Validation loss: 1.9084034658247424

Epoch: 6| Step: 3
Training loss: 1.1627388000488281
Validation loss: 1.8907973163871354

Epoch: 6| Step: 4
Training loss: 1.0780210494995117
Validation loss: 1.8925471139210526

Epoch: 6| Step: 5
Training loss: 0.9618088603019714
Validation loss: 1.8865879235729095

Epoch: 6| Step: 6
Training loss: 1.4346613883972168
Validation loss: 1.897620137019824

Epoch: 6| Step: 7
Training loss: 1.5064642429351807
Validation loss: 1.9434930970591884

Epoch: 6| Step: 8
Training loss: 1.082764744758606
Validation loss: 1.9607844878268499

Epoch: 6| Step: 9
Training loss: 1.2888243198394775
Validation loss: 2.019061338516974

Epoch: 6| Step: 10
Training loss: 1.5060842037200928
Validation loss: 2.0957074396071897

Epoch: 6| Step: 11
Training loss: 1.5021474361419678
Validation loss: 2.0563593000494023

Epoch: 6| Step: 12
Training loss: 1.201723337173462
Validation loss: 2.000107278106033

Epoch: 6| Step: 13
Training loss: 2.192586660385132
Validation loss: 1.9402396986561437

Epoch: 206| Step: 0
Training loss: 1.7557026147842407
Validation loss: 1.9169850733972364

Epoch: 6| Step: 1
Training loss: 1.3220326900482178
Validation loss: 1.918580448755654

Epoch: 6| Step: 2
Training loss: 1.6054999828338623
Validation loss: 1.901220017863858

Epoch: 6| Step: 3
Training loss: 1.4120395183563232
Validation loss: 1.8877153345333633

Epoch: 6| Step: 4
Training loss: 1.0898511409759521
Validation loss: 1.8939902038984402

Epoch: 6| Step: 5
Training loss: 1.6406269073486328
Validation loss: 1.8766688749354372

Epoch: 6| Step: 6
Training loss: 0.9876751899719238
Validation loss: 1.9066271910103418

Epoch: 6| Step: 7
Training loss: 1.2969915866851807
Validation loss: 1.9776469661343483

Epoch: 6| Step: 8
Training loss: 1.1986870765686035
Validation loss: 1.983986367461502

Epoch: 6| Step: 9
Training loss: 1.3751338720321655
Validation loss: 1.9378289625208864

Epoch: 6| Step: 10
Training loss: 1.5661804676055908
Validation loss: 1.9374335658165716

Epoch: 6| Step: 11
Training loss: 1.5475234985351562
Validation loss: 1.8914781949853385

Epoch: 6| Step: 12
Training loss: 1.0337918996810913
Validation loss: 1.8651853428092053

Epoch: 6| Step: 13
Training loss: 0.7643746137619019
Validation loss: 1.8768960660503757

Epoch: 207| Step: 0
Training loss: 1.1315832138061523
Validation loss: 1.8975833872313141

Epoch: 6| Step: 1
Training loss: 0.868131160736084
Validation loss: 1.8983429811334098

Epoch: 6| Step: 2
Training loss: 1.4705514907836914
Validation loss: 1.9170963379644579

Epoch: 6| Step: 3
Training loss: 1.2598681449890137
Validation loss: 1.92019574616545

Epoch: 6| Step: 4
Training loss: 1.690732717514038
Validation loss: 1.9249034953373734

Epoch: 6| Step: 5
Training loss: 1.571816325187683
Validation loss: 1.9292165438334148

Epoch: 6| Step: 6
Training loss: 1.533849835395813
Validation loss: 1.9884797501307663

Epoch: 6| Step: 7
Training loss: 1.5141315460205078
Validation loss: 1.9794920695725309

Epoch: 6| Step: 8
Training loss: 1.041113018989563
Validation loss: 1.9360209908536685

Epoch: 6| Step: 9
Training loss: 1.1706254482269287
Validation loss: 1.8495276102455713

Epoch: 6| Step: 10
Training loss: 1.84494149684906
Validation loss: 1.8249212464978617

Epoch: 6| Step: 11
Training loss: 0.7689321041107178
Validation loss: 1.8349869071796376

Epoch: 6| Step: 12
Training loss: 0.8574998378753662
Validation loss: 1.8478615514693721

Epoch: 6| Step: 13
Training loss: 1.5698151588439941
Validation loss: 1.861457129960419

Epoch: 208| Step: 0
Training loss: 1.8391121625900269
Validation loss: 1.8886616332556612

Epoch: 6| Step: 1
Training loss: 1.027347445487976
Validation loss: 1.8646085313571397

Epoch: 6| Step: 2
Training loss: 1.1278562545776367
Validation loss: 1.8653050507268598

Epoch: 6| Step: 3
Training loss: 1.296312689781189
Validation loss: 1.8734536734960412

Epoch: 6| Step: 4
Training loss: 1.639662504196167
Validation loss: 1.9066414140885877

Epoch: 6| Step: 5
Training loss: 0.9418694376945496
Validation loss: 1.955952113674533

Epoch: 6| Step: 6
Training loss: 0.9245930314064026
Validation loss: 1.9397507598323207

Epoch: 6| Step: 7
Training loss: 1.5036842823028564
Validation loss: 1.9437955066721926

Epoch: 6| Step: 8
Training loss: 1.6536921262741089
Validation loss: 1.896597017524063

Epoch: 6| Step: 9
Training loss: 1.336104154586792
Validation loss: 1.8609662440515333

Epoch: 6| Step: 10
Training loss: 1.2146034240722656
Validation loss: 1.8589299468583957

Epoch: 6| Step: 11
Training loss: 1.0266095399856567
Validation loss: 1.8259830615853752

Epoch: 6| Step: 12
Training loss: 1.3459486961364746
Validation loss: 1.8112429290689447

Epoch: 6| Step: 13
Training loss: 1.0876333713531494
Validation loss: 1.8256899708060808

Epoch: 209| Step: 0
Training loss: 1.2161524295806885
Validation loss: 1.8245194983738724

Epoch: 6| Step: 1
Training loss: 1.038811206817627
Validation loss: 1.847139912266885

Epoch: 6| Step: 2
Training loss: 1.0922164916992188
Validation loss: 1.886475250285159

Epoch: 6| Step: 3
Training loss: 1.4560626745224
Validation loss: 1.8800773569332656

Epoch: 6| Step: 4
Training loss: 1.4652771949768066
Validation loss: 1.905299553307154

Epoch: 6| Step: 5
Training loss: 1.0072792768478394
Validation loss: 1.8624583187923636

Epoch: 6| Step: 6
Training loss: 1.6609628200531006
Validation loss: 1.870728354300222

Epoch: 6| Step: 7
Training loss: 1.5342729091644287
Validation loss: 1.853270843464841

Epoch: 6| Step: 8
Training loss: 1.7087621688842773
Validation loss: 1.8494176069895427

Epoch: 6| Step: 9
Training loss: 1.0412391424179077
Validation loss: 1.8287546173218758

Epoch: 6| Step: 10
Training loss: 1.361225962638855
Validation loss: 1.8433628915458597

Epoch: 6| Step: 11
Training loss: 1.1346452236175537
Validation loss: 1.8380197735242947

Epoch: 6| Step: 12
Training loss: 0.750185489654541
Validation loss: 1.8456545376008557

Epoch: 6| Step: 13
Training loss: 1.088691234588623
Validation loss: 1.866262032139686

Epoch: 210| Step: 0
Training loss: 1.409523367881775
Validation loss: 1.9098899851563156

Epoch: 6| Step: 1
Training loss: 1.348172903060913
Validation loss: 1.9176973578750447

Epoch: 6| Step: 2
Training loss: 1.2477540969848633
Validation loss: 1.905196637235662

Epoch: 6| Step: 3
Training loss: 1.0316259860992432
Validation loss: 1.8522847621671614

Epoch: 6| Step: 4
Training loss: 1.6604275703430176
Validation loss: 1.8699393900491859

Epoch: 6| Step: 5
Training loss: 1.0494431257247925
Validation loss: 1.8164422076235536

Epoch: 6| Step: 6
Training loss: 1.0885144472122192
Validation loss: 1.8126393133594143

Epoch: 6| Step: 7
Training loss: 1.0964607000350952
Validation loss: 1.8355764394165368

Epoch: 6| Step: 8
Training loss: 1.0566728115081787
Validation loss: 1.8152037551326137

Epoch: 6| Step: 9
Training loss: 1.02576744556427
Validation loss: 1.829802591313598

Epoch: 6| Step: 10
Training loss: 0.8593341708183289
Validation loss: 1.8489937743832987

Epoch: 6| Step: 11
Training loss: 1.4282679557800293
Validation loss: 1.901344947917487

Epoch: 6| Step: 12
Training loss: 1.4152133464813232
Validation loss: 1.980748281683973

Epoch: 6| Step: 13
Training loss: 1.8525753021240234
Validation loss: 2.012122510581888

Epoch: 211| Step: 0
Training loss: 0.9079864025115967
Validation loss: 2.0088085897507204

Epoch: 6| Step: 1
Training loss: 1.5109554529190063
Validation loss: 1.9876982319739558

Epoch: 6| Step: 2
Training loss: 1.1783366203308105
Validation loss: 1.949172632668608

Epoch: 6| Step: 3
Training loss: 1.4575655460357666
Validation loss: 1.891785389633589

Epoch: 6| Step: 4
Training loss: 1.0824977159500122
Validation loss: 1.8652548674614198

Epoch: 6| Step: 5
Training loss: 1.4551657438278198
Validation loss: 1.866815887471681

Epoch: 6| Step: 6
Training loss: 1.4768710136413574
Validation loss: 1.8659510535578574

Epoch: 6| Step: 7
Training loss: 1.1198065280914307
Validation loss: 1.867114051695793

Epoch: 6| Step: 8
Training loss: 1.1538078784942627
Validation loss: 1.8774357252223517

Epoch: 6| Step: 9
Training loss: 1.1145164966583252
Validation loss: 1.8664185077913347

Epoch: 6| Step: 10
Training loss: 1.3423519134521484
Validation loss: 1.8815666655058503

Epoch: 6| Step: 11
Training loss: 1.1490594148635864
Validation loss: 1.8855251009746263

Epoch: 6| Step: 12
Training loss: 1.671590805053711
Validation loss: 1.8671175677289245

Epoch: 6| Step: 13
Training loss: 0.879278302192688
Validation loss: 1.9035841482941822

Epoch: 212| Step: 0
Training loss: 1.2471539974212646
Validation loss: 1.9196332962282243

Epoch: 6| Step: 1
Training loss: 1.4060702323913574
Validation loss: 1.9225220013690252

Epoch: 6| Step: 2
Training loss: 1.7818007469177246
Validation loss: 1.9539323276089084

Epoch: 6| Step: 3
Training loss: 0.9199403524398804
Validation loss: 1.9436491503510425

Epoch: 6| Step: 4
Training loss: 1.2083759307861328
Validation loss: 1.9474777444716422

Epoch: 6| Step: 5
Training loss: 0.8608356714248657
Validation loss: 1.918844901105409

Epoch: 6| Step: 6
Training loss: 1.023252010345459
Validation loss: 1.8872798745350172

Epoch: 6| Step: 7
Training loss: 1.5566409826278687
Validation loss: 1.8659841937403525

Epoch: 6| Step: 8
Training loss: 1.3888121843338013
Validation loss: 1.8338223452209144

Epoch: 6| Step: 9
Training loss: 0.6318464875221252
Validation loss: 1.8403113618973763

Epoch: 6| Step: 10
Training loss: 1.1510915756225586
Validation loss: 1.8345250237372615

Epoch: 6| Step: 11
Training loss: 1.0747038125991821
Validation loss: 1.8382617863275672

Epoch: 6| Step: 12
Training loss: 1.5181655883789062
Validation loss: 1.8193387216137302

Epoch: 6| Step: 13
Training loss: 1.4666043519973755
Validation loss: 1.828407943889659

Epoch: 213| Step: 0
Training loss: 1.0078996419906616
Validation loss: 1.8159911068536903

Epoch: 6| Step: 1
Training loss: 1.327224612236023
Validation loss: 1.8599848862617248

Epoch: 6| Step: 2
Training loss: 1.8670544624328613
Validation loss: 1.887266719213096

Epoch: 6| Step: 3
Training loss: 1.1866294145584106
Validation loss: 1.9238592937428465

Epoch: 6| Step: 4
Training loss: 1.2563307285308838
Validation loss: 1.910515180198095

Epoch: 6| Step: 5
Training loss: 1.107015609741211
Validation loss: 1.8781109804748206

Epoch: 6| Step: 6
Training loss: 1.298142433166504
Validation loss: 1.8173032729856429

Epoch: 6| Step: 7
Training loss: 0.978703498840332
Validation loss: 1.8368087724972797

Epoch: 6| Step: 8
Training loss: 1.4839084148406982
Validation loss: 1.8590448876862884

Epoch: 6| Step: 9
Training loss: 1.2604141235351562
Validation loss: 1.8544171189749112

Epoch: 6| Step: 10
Training loss: 1.1389615535736084
Validation loss: 1.8515979987318798

Epoch: 6| Step: 11
Training loss: 0.849880576133728
Validation loss: 1.860698797369516

Epoch: 6| Step: 12
Training loss: 1.0003068447113037
Validation loss: 1.8519558342554236

Epoch: 6| Step: 13
Training loss: 1.6948574781417847
Validation loss: 1.8586414091048702

Epoch: 214| Step: 0
Training loss: 1.8476346731185913
Validation loss: 1.8915275873676423

Epoch: 6| Step: 1
Training loss: 1.1755707263946533
Validation loss: 1.9373501218775266

Epoch: 6| Step: 2
Training loss: 1.3300031423568726
Validation loss: 1.9687765849533903

Epoch: 6| Step: 3
Training loss: 1.2761746644973755
Validation loss: 1.96569215097735

Epoch: 6| Step: 4
Training loss: 1.5049015283584595
Validation loss: 1.9382259140732467

Epoch: 6| Step: 5
Training loss: 1.392230749130249
Validation loss: 1.9076804807109218

Epoch: 6| Step: 6
Training loss: 0.9518654346466064
Validation loss: 1.8563954061077488

Epoch: 6| Step: 7
Training loss: 1.1253104209899902
Validation loss: 1.8417935332944315

Epoch: 6| Step: 8
Training loss: 1.2776787281036377
Validation loss: 1.833451037765831

Epoch: 6| Step: 9
Training loss: 1.0076282024383545
Validation loss: 1.8367266462695213

Epoch: 6| Step: 10
Training loss: 1.1778478622436523
Validation loss: 1.8457919038752073

Epoch: 6| Step: 11
Training loss: 1.1528031826019287
Validation loss: 1.850546831725746

Epoch: 6| Step: 12
Training loss: 0.8187158107757568
Validation loss: 1.8796938016850462

Epoch: 6| Step: 13
Training loss: 1.1235754489898682
Validation loss: 1.8977633189129572

Epoch: 215| Step: 0
Training loss: 0.7538944482803345
Validation loss: 1.970390777434072

Epoch: 6| Step: 1
Training loss: 1.3773200511932373
Validation loss: 2.004248906207341

Epoch: 6| Step: 2
Training loss: 1.388580322265625
Validation loss: 1.9488354575249456

Epoch: 6| Step: 3
Training loss: 0.9235969185829163
Validation loss: 1.8944350404124106

Epoch: 6| Step: 4
Training loss: 0.9269219636917114
Validation loss: 1.8345423924025668

Epoch: 6| Step: 5
Training loss: 1.6633243560791016
Validation loss: 1.8267757943881455

Epoch: 6| Step: 6
Training loss: 0.7475779056549072
Validation loss: 1.8303135325831752

Epoch: 6| Step: 7
Training loss: 0.9622975587844849
Validation loss: 1.830769911889107

Epoch: 6| Step: 8
Training loss: 1.3736563920974731
Validation loss: 1.8356102487092376

Epoch: 6| Step: 9
Training loss: 2.0816521644592285
Validation loss: 1.8580921170532063

Epoch: 6| Step: 10
Training loss: 1.4668853282928467
Validation loss: 1.8534634126129972

Epoch: 6| Step: 11
Training loss: 1.5630255937576294
Validation loss: 1.844995456357156

Epoch: 6| Step: 12
Training loss: 1.036528468132019
Validation loss: 1.852092186609904

Epoch: 6| Step: 13
Training loss: 1.7468923330307007
Validation loss: 1.855511885817333

Epoch: 216| Step: 0
Training loss: 1.4648996591567993
Validation loss: 1.8695030673857658

Epoch: 6| Step: 1
Training loss: 1.9035773277282715
Validation loss: 1.8620056439471502

Epoch: 6| Step: 2
Training loss: 1.185957908630371
Validation loss: 1.904465906081661

Epoch: 6| Step: 3
Training loss: 0.950995683670044
Validation loss: 1.8987680071143693

Epoch: 6| Step: 4
Training loss: 1.3331429958343506
Validation loss: 1.843877060438997

Epoch: 6| Step: 5
Training loss: 1.207460641860962
Validation loss: 1.8191691521675355

Epoch: 6| Step: 6
Training loss: 1.464274525642395
Validation loss: 1.8006837227011239

Epoch: 6| Step: 7
Training loss: 1.4455351829528809
Validation loss: 1.8009837083919074

Epoch: 6| Step: 8
Training loss: 1.2494133710861206
Validation loss: 1.7870133743491223

Epoch: 6| Step: 9
Training loss: 0.7196992039680481
Validation loss: 1.8049938614650438

Epoch: 6| Step: 10
Training loss: 0.8776094913482666
Validation loss: 1.8537525310311267

Epoch: 6| Step: 11
Training loss: 1.0430521965026855
Validation loss: 1.8628855046405588

Epoch: 6| Step: 12
Training loss: 1.149247169494629
Validation loss: 1.8734755849325528

Epoch: 6| Step: 13
Training loss: 0.5905404686927795
Validation loss: 1.895331198169339

Epoch: 217| Step: 0
Training loss: 1.262738823890686
Validation loss: 1.9022802755396853

Epoch: 6| Step: 1
Training loss: 0.9756201505661011
Validation loss: 1.9011770192012991

Epoch: 6| Step: 2
Training loss: 1.0967178344726562
Validation loss: 1.8980136943119827

Epoch: 6| Step: 3
Training loss: 1.1477614641189575
Validation loss: 1.8546170214171052

Epoch: 6| Step: 4
Training loss: 1.1063034534454346
Validation loss: 1.8584459238154913

Epoch: 6| Step: 5
Training loss: 0.6492829322814941
Validation loss: 1.8215686198203795

Epoch: 6| Step: 6
Training loss: 1.1024556159973145
Validation loss: 1.8501866222709737

Epoch: 6| Step: 7
Training loss: 1.1323533058166504
Validation loss: 1.8663490459483156

Epoch: 6| Step: 8
Training loss: 1.2815375328063965
Validation loss: 1.8797448873519897

Epoch: 6| Step: 9
Training loss: 1.606239676475525
Validation loss: 1.8714490923830258

Epoch: 6| Step: 10
Training loss: 1.784785270690918
Validation loss: 1.8891007977147256

Epoch: 6| Step: 11
Training loss: 1.0820212364196777
Validation loss: 1.9132124634199246

Epoch: 6| Step: 12
Training loss: 0.7381142377853394
Validation loss: 1.9037541163864957

Epoch: 6| Step: 13
Training loss: 0.9989905953407288
Validation loss: 1.9091876617041967

Epoch: 218| Step: 0
Training loss: 1.2776652574539185
Validation loss: 1.8994737773813226

Epoch: 6| Step: 1
Training loss: 1.1597342491149902
Validation loss: 1.901764992744692

Epoch: 6| Step: 2
Training loss: 1.4711408615112305
Validation loss: 1.8749224319252917

Epoch: 6| Step: 3
Training loss: 0.8523287773132324
Validation loss: 1.851958893960522

Epoch: 6| Step: 4
Training loss: 1.4290878772735596
Validation loss: 1.8289028431779595

Epoch: 6| Step: 5
Training loss: 0.9181341528892517
Validation loss: 1.7961975682166316

Epoch: 6| Step: 6
Training loss: 1.0180078744888306
Validation loss: 1.7614749182936966

Epoch: 6| Step: 7
Training loss: 1.189605712890625
Validation loss: 1.8086705643643615

Epoch: 6| Step: 8
Training loss: 1.2156485319137573
Validation loss: 1.7863523960113525

Epoch: 6| Step: 9
Training loss: 0.7586202621459961
Validation loss: 1.783991224022322

Epoch: 6| Step: 10
Training loss: 1.12582528591156
Validation loss: 1.8121221603885773

Epoch: 6| Step: 11
Training loss: 0.7970948219299316
Validation loss: 1.8182334387174217

Epoch: 6| Step: 12
Training loss: 1.5084257125854492
Validation loss: 1.8590633830716532

Epoch: 6| Step: 13
Training loss: 1.0632809400558472
Validation loss: 1.8767605789246098

Epoch: 219| Step: 0
Training loss: 1.1531985998153687
Validation loss: 1.9006918220109836

Epoch: 6| Step: 1
Training loss: 1.1066076755523682
Validation loss: 1.9661895741698563

Epoch: 6| Step: 2
Training loss: 1.009513258934021
Validation loss: 1.9356288166456326

Epoch: 6| Step: 3
Training loss: 0.7685965299606323
Validation loss: 1.9427772824482252

Epoch: 6| Step: 4
Training loss: 1.8608657121658325
Validation loss: 1.9471891823635306

Epoch: 6| Step: 5
Training loss: 0.9827057123184204
Validation loss: 1.8605369483270953

Epoch: 6| Step: 6
Training loss: 1.1907953023910522
Validation loss: 1.8414094755726476

Epoch: 6| Step: 7
Training loss: 1.6635819673538208
Validation loss: 1.8036216689694313

Epoch: 6| Step: 8
Training loss: 1.1380460262298584
Validation loss: 1.8102163601947088

Epoch: 6| Step: 9
Training loss: 1.0540956258773804
Validation loss: 1.8292624232589558

Epoch: 6| Step: 10
Training loss: 1.2860599756240845
Validation loss: 1.8345522944645216

Epoch: 6| Step: 11
Training loss: 1.1122734546661377
Validation loss: 1.8987980696462816

Epoch: 6| Step: 12
Training loss: 0.7113844156265259
Validation loss: 1.9288052846026678

Epoch: 6| Step: 13
Training loss: 1.4530280828475952
Validation loss: 1.8860630450710174

Epoch: 220| Step: 0
Training loss: 0.9020395874977112
Validation loss: 1.8575816385207637

Epoch: 6| Step: 1
Training loss: 0.9123747944831848
Validation loss: 1.8291791799247905

Epoch: 6| Step: 2
Training loss: 1.0345947742462158
Validation loss: 1.8539921904122958

Epoch: 6| Step: 3
Training loss: 1.0435705184936523
Validation loss: 1.8345366690748481

Epoch: 6| Step: 4
Training loss: 0.8740713000297546
Validation loss: 1.8416470289230347

Epoch: 6| Step: 5
Training loss: 1.3805314302444458
Validation loss: 1.8902590210719774

Epoch: 6| Step: 6
Training loss: 1.263841986656189
Validation loss: 1.9046369957667526

Epoch: 6| Step: 7
Training loss: 0.864136815071106
Validation loss: 1.8888216044313164

Epoch: 6| Step: 8
Training loss: 1.8718948364257812
Validation loss: 1.894341681593208

Epoch: 6| Step: 9
Training loss: 1.2554118633270264
Validation loss: 1.869946228560581

Epoch: 6| Step: 10
Training loss: 1.2404698133468628
Validation loss: 1.9029201922878143

Epoch: 6| Step: 11
Training loss: 1.5280249118804932
Validation loss: 1.9165832009366763

Epoch: 6| Step: 12
Training loss: 0.9633773565292358
Validation loss: 1.9609757777183288

Epoch: 6| Step: 13
Training loss: 0.7789997458457947
Validation loss: 1.9922898161795832

Epoch: 221| Step: 0
Training loss: 1.2222213745117188
Validation loss: 1.969709232289304

Epoch: 6| Step: 1
Training loss: 1.1635518074035645
Validation loss: 1.9269767217738654

Epoch: 6| Step: 2
Training loss: 1.539768099784851
Validation loss: 1.8661847742654945

Epoch: 6| Step: 3
Training loss: 1.250219702720642
Validation loss: 1.8072619233080136

Epoch: 6| Step: 4
Training loss: 1.1559091806411743
Validation loss: 1.7783242323065316

Epoch: 6| Step: 5
Training loss: 1.2668002843856812
Validation loss: 1.8022166029099496

Epoch: 6| Step: 6
Training loss: 1.0103580951690674
Validation loss: 1.791842742632794

Epoch: 6| Step: 7
Training loss: 1.2074363231658936
Validation loss: 1.807147890008906

Epoch: 6| Step: 8
Training loss: 1.3759784698486328
Validation loss: 1.8044093616547123

Epoch: 6| Step: 9
Training loss: 0.9600784778594971
Validation loss: 1.800378135455552

Epoch: 6| Step: 10
Training loss: 1.0858263969421387
Validation loss: 1.8059936223491546

Epoch: 6| Step: 11
Training loss: 1.011667251586914
Validation loss: 1.8271789364917304

Epoch: 6| Step: 12
Training loss: 0.36117902398109436
Validation loss: 1.8122245022045669

Epoch: 6| Step: 13
Training loss: 0.9772014617919922
Validation loss: 1.8399966762911888

Epoch: 222| Step: 0
Training loss: 0.9611510038375854
Validation loss: 1.823256746415169

Epoch: 6| Step: 1
Training loss: 0.9145897626876831
Validation loss: 1.789049684360463

Epoch: 6| Step: 2
Training loss: 0.9644906520843506
Validation loss: 1.7966706445140224

Epoch: 6| Step: 3
Training loss: 0.7732463479042053
Validation loss: 1.801464989621152

Epoch: 6| Step: 4
Training loss: 1.0434846878051758
Validation loss: 1.8225937607467815

Epoch: 6| Step: 5
Training loss: 1.0039716958999634
Validation loss: 1.854141786534299

Epoch: 6| Step: 6
Training loss: 0.9075487852096558
Validation loss: 1.8916959839482461

Epoch: 6| Step: 7
Training loss: 1.2969318628311157
Validation loss: 1.8556350559316657

Epoch: 6| Step: 8
Training loss: 1.2196327447891235
Validation loss: 1.8256628051880868

Epoch: 6| Step: 9
Training loss: 0.9876288175582886
Validation loss: 1.8160121927979171

Epoch: 6| Step: 10
Training loss: 1.3106553554534912
Validation loss: 1.8425956464582873

Epoch: 6| Step: 11
Training loss: 1.628056526184082
Validation loss: 1.8632801296890422

Epoch: 6| Step: 12
Training loss: 1.4765737056732178
Validation loss: 1.8587524890899658

Epoch: 6| Step: 13
Training loss: 0.812673807144165
Validation loss: 1.7950048062109178

Epoch: 223| Step: 0
Training loss: 1.1823673248291016
Validation loss: 1.7860696341401787

Epoch: 6| Step: 1
Training loss: 0.496334433555603
Validation loss: 1.7781718738617436

Epoch: 6| Step: 2
Training loss: 0.8919618129730225
Validation loss: 1.7628362960712884

Epoch: 6| Step: 3
Training loss: 0.8399271965026855
Validation loss: 1.8113825782652824

Epoch: 6| Step: 4
Training loss: 0.9241828918457031
Validation loss: 1.808960953066426

Epoch: 6| Step: 5
Training loss: 1.2993332147598267
Validation loss: 1.826116866962884

Epoch: 6| Step: 6
Training loss: 1.2396833896636963
Validation loss: 1.875434357632873

Epoch: 6| Step: 7
Training loss: 1.565894365310669
Validation loss: 1.892406448241203

Epoch: 6| Step: 8
Training loss: 1.0541706085205078
Validation loss: 1.9097769760316419

Epoch: 6| Step: 9
Training loss: 1.6100025177001953
Validation loss: 1.9072886038851995

Epoch: 6| Step: 10
Training loss: 1.4327664375305176
Validation loss: 1.926956622831283

Epoch: 6| Step: 11
Training loss: 1.448908805847168
Validation loss: 1.8058138175677227

Epoch: 6| Step: 12
Training loss: 0.5120247006416321
Validation loss: 1.7812554400454286

Epoch: 6| Step: 13
Training loss: 0.9067423939704895
Validation loss: 1.7580827205411849

Epoch: 224| Step: 0
Training loss: 0.9328039884567261
Validation loss: 1.7590767363066315

Epoch: 6| Step: 1
Training loss: 1.2129230499267578
Validation loss: 1.7532231166798582

Epoch: 6| Step: 2
Training loss: 0.9185189008712769
Validation loss: 1.768400405042915

Epoch: 6| Step: 3
Training loss: 1.1977688074111938
Validation loss: 1.8103917234687394

Epoch: 6| Step: 4
Training loss: 0.9689421057701111
Validation loss: 1.8255609568729196

Epoch: 6| Step: 5
Training loss: 1.639902949333191
Validation loss: 1.8422759271437121

Epoch: 6| Step: 6
Training loss: 0.9501470327377319
Validation loss: 1.8547341067303893

Epoch: 6| Step: 7
Training loss: 1.2188953161239624
Validation loss: 1.8144741840260004

Epoch: 6| Step: 8
Training loss: 1.2333753108978271
Validation loss: 1.8037749541703092

Epoch: 6| Step: 9
Training loss: 0.6486333608627319
Validation loss: 1.770760590030301

Epoch: 6| Step: 10
Training loss: 0.7648234367370605
Validation loss: 1.7634024273964666

Epoch: 6| Step: 11
Training loss: 0.8208740949630737
Validation loss: 1.779213225328794

Epoch: 6| Step: 12
Training loss: 1.2483525276184082
Validation loss: 1.784973685459424

Epoch: 6| Step: 13
Training loss: 0.7507693767547607
Validation loss: 1.826509629526446

Epoch: 225| Step: 0
Training loss: 1.7013392448425293
Validation loss: 1.8287910889553767

Epoch: 6| Step: 1
Training loss: 0.6368406414985657
Validation loss: 1.847517728805542

Epoch: 6| Step: 2
Training loss: 0.6519966125488281
Validation loss: 1.8277656314193562

Epoch: 6| Step: 3
Training loss: 1.1888166666030884
Validation loss: 1.798103799102127

Epoch: 6| Step: 4
Training loss: 0.636513352394104
Validation loss: 1.7993710425592238

Epoch: 6| Step: 5
Training loss: 0.8077403903007507
Validation loss: 1.7881715054153113

Epoch: 6| Step: 6
Training loss: 1.3969985246658325
Validation loss: 1.7961053822630195

Epoch: 6| Step: 7
Training loss: 1.2051767110824585
Validation loss: 1.7865148923730338

Epoch: 6| Step: 8
Training loss: 0.8137311935424805
Validation loss: 1.77562302671453

Epoch: 6| Step: 9
Training loss: 1.0568439960479736
Validation loss: 1.7746464167871783

Epoch: 6| Step: 10
Training loss: 1.4821223020553589
Validation loss: 1.7813159573462702

Epoch: 6| Step: 11
Training loss: 0.8389325141906738
Validation loss: 1.828551676965529

Epoch: 6| Step: 12
Training loss: 0.869208574295044
Validation loss: 1.8201569139316518

Epoch: 6| Step: 13
Training loss: 0.8452932238578796
Validation loss: 1.8328558039921585

Epoch: 226| Step: 0
Training loss: 1.6832969188690186
Validation loss: 1.8056725507141442

Epoch: 6| Step: 1
Training loss: 1.1315269470214844
Validation loss: 1.8087023535082418

Epoch: 6| Step: 2
Training loss: 0.9743974208831787
Validation loss: 1.8043956102863434

Epoch: 6| Step: 3
Training loss: 0.9364981651306152
Validation loss: 1.8047534509371685

Epoch: 6| Step: 4
Training loss: 0.8305151462554932
Validation loss: 1.7949064675197806

Epoch: 6| Step: 5
Training loss: 1.0631548166275024
Validation loss: 1.7479652512458064

Epoch: 6| Step: 6
Training loss: 1.2516295909881592
Validation loss: 1.7746028528418591

Epoch: 6| Step: 7
Training loss: 1.281658411026001
Validation loss: 1.776951592455628

Epoch: 6| Step: 8
Training loss: 0.7825260162353516
Validation loss: 1.7871352164976058

Epoch: 6| Step: 9
Training loss: 0.7019921541213989
Validation loss: 1.7909344909011677

Epoch: 6| Step: 10
Training loss: 0.8664180040359497
Validation loss: 1.775970289784093

Epoch: 6| Step: 11
Training loss: 0.6165629625320435
Validation loss: 1.796484217848829

Epoch: 6| Step: 12
Training loss: 0.9275140762329102
Validation loss: 1.8269415286279493

Epoch: 6| Step: 13
Training loss: 1.1649508476257324
Validation loss: 1.8375071005154682

Epoch: 227| Step: 0
Training loss: 0.9987916946411133
Validation loss: 1.8338957153340822

Epoch: 6| Step: 1
Training loss: 1.2734436988830566
Validation loss: 1.8694121824797763

Epoch: 6| Step: 2
Training loss: 1.2113646268844604
Validation loss: 1.8105168932227678

Epoch: 6| Step: 3
Training loss: 1.0769667625427246
Validation loss: 1.7530099563701178

Epoch: 6| Step: 4
Training loss: 0.6993229985237122
Validation loss: 1.7420846185376566

Epoch: 6| Step: 5
Training loss: 1.100259780883789
Validation loss: 1.7433069316289758

Epoch: 6| Step: 6
Training loss: 0.581329345703125
Validation loss: 1.7035472290490263

Epoch: 6| Step: 7
Training loss: 1.3622901439666748
Validation loss: 1.7304339408874512

Epoch: 6| Step: 8
Training loss: 0.45347240567207336
Validation loss: 1.7440859489543463

Epoch: 6| Step: 9
Training loss: 0.6637890934944153
Validation loss: 1.7461153935360652

Epoch: 6| Step: 10
Training loss: 1.0980908870697021
Validation loss: 1.7574512932890205

Epoch: 6| Step: 11
Training loss: 1.2283108234405518
Validation loss: 1.75107208887736

Epoch: 6| Step: 12
Training loss: 1.155125379562378
Validation loss: 1.7488486241268855

Epoch: 6| Step: 13
Training loss: 1.4572995901107788
Validation loss: 1.7284695832960066

Epoch: 228| Step: 0
Training loss: 0.8723447322845459
Validation loss: 1.7415438377729027

Epoch: 6| Step: 1
Training loss: 0.6837471723556519
Validation loss: 1.7369629580487487

Epoch: 6| Step: 2
Training loss: 1.1870241165161133
Validation loss: 1.7239887214476062

Epoch: 6| Step: 3
Training loss: 1.088913917541504
Validation loss: 1.7318393491929578

Epoch: 6| Step: 4
Training loss: 0.8404707908630371
Validation loss: 1.7080610182977491

Epoch: 6| Step: 5
Training loss: 1.3009562492370605
Validation loss: 1.7239587704340618

Epoch: 6| Step: 6
Training loss: 1.0549499988555908
Validation loss: 1.7393448891178254

Epoch: 6| Step: 7
Training loss: 1.0764323472976685
Validation loss: 1.752760423127041

Epoch: 6| Step: 8
Training loss: 1.0450644493103027
Validation loss: 1.7830149191682056

Epoch: 6| Step: 9
Training loss: 0.7632713317871094
Validation loss: 1.7770747728245233

Epoch: 6| Step: 10
Training loss: 1.5613396167755127
Validation loss: 1.7865214950294905

Epoch: 6| Step: 11
Training loss: 0.6281118988990784
Validation loss: 1.7793110942327848

Epoch: 6| Step: 12
Training loss: 1.0648441314697266
Validation loss: 1.803700279164058

Epoch: 6| Step: 13
Training loss: 0.8690199255943298
Validation loss: 1.8222015403932141

Epoch: 229| Step: 0
Training loss: 1.2485688924789429
Validation loss: 1.817281872995438

Epoch: 6| Step: 1
Training loss: 1.1732571125030518
Validation loss: 1.8069603045781453

Epoch: 6| Step: 2
Training loss: 0.9613152742385864
Validation loss: 1.7819666965033418

Epoch: 6| Step: 3
Training loss: 0.788770318031311
Validation loss: 1.7973806934971963

Epoch: 6| Step: 4
Training loss: 1.2463462352752686
Validation loss: 1.7742355331297843

Epoch: 6| Step: 5
Training loss: 0.7459378242492676
Validation loss: 1.768797864196121

Epoch: 6| Step: 6
Training loss: 1.0488355159759521
Validation loss: 1.7525720186130975

Epoch: 6| Step: 7
Training loss: 0.5867733955383301
Validation loss: 1.7597858931428643

Epoch: 6| Step: 8
Training loss: 1.526842713356018
Validation loss: 1.7426430127953971

Epoch: 6| Step: 9
Training loss: 0.9142196178436279
Validation loss: 1.7716525216256418

Epoch: 6| Step: 10
Training loss: 1.008591651916504
Validation loss: 1.7805958537645237

Epoch: 6| Step: 11
Training loss: 0.980135440826416
Validation loss: 1.8044064532044113

Epoch: 6| Step: 12
Training loss: 0.7132701873779297
Validation loss: 1.7892763512108916

Epoch: 6| Step: 13
Training loss: 1.240388035774231
Validation loss: 1.769541916026864

Epoch: 230| Step: 0
Training loss: 1.1314506530761719
Validation loss: 1.7231941838418283

Epoch: 6| Step: 1
Training loss: 0.7941316366195679
Validation loss: 1.7055751431372859

Epoch: 6| Step: 2
Training loss: 0.9587596654891968
Validation loss: 1.723217861626738

Epoch: 6| Step: 3
Training loss: 0.847076416015625
Validation loss: 1.7093920182156306

Epoch: 6| Step: 4
Training loss: 1.7905579805374146
Validation loss: 1.773287946178067

Epoch: 6| Step: 5
Training loss: 1.080442190170288
Validation loss: 1.7621084387584398

Epoch: 6| Step: 6
Training loss: 0.653883695602417
Validation loss: 1.7909300045300556

Epoch: 6| Step: 7
Training loss: 0.7376737594604492
Validation loss: 1.8306408556558753

Epoch: 6| Step: 8
Training loss: 1.3392829895019531
Validation loss: 1.855267688792239

Epoch: 6| Step: 9
Training loss: 1.200953483581543
Validation loss: 1.8609681244819396

Epoch: 6| Step: 10
Training loss: 1.0316131114959717
Validation loss: 1.8098433030548917

Epoch: 6| Step: 11
Training loss: 0.7999533414840698
Validation loss: 1.7679616200026644

Epoch: 6| Step: 12
Training loss: 1.2416895627975464
Validation loss: 1.7291833751945085

Epoch: 6| Step: 13
Training loss: 0.39842092990875244
Validation loss: 1.712591645538166

Epoch: 231| Step: 0
Training loss: 1.2003751993179321
Validation loss: 1.6992932442695863

Epoch: 6| Step: 1
Training loss: 0.8678799271583557
Validation loss: 1.7198251921643493

Epoch: 6| Step: 2
Training loss: 1.1687901020050049
Validation loss: 1.7067031616805701

Epoch: 6| Step: 3
Training loss: 0.9438336491584778
Validation loss: 1.6997420813447686

Epoch: 6| Step: 4
Training loss: 0.8513994216918945
Validation loss: 1.724854697463333

Epoch: 6| Step: 5
Training loss: 0.7459592223167419
Validation loss: 1.7215928557098552

Epoch: 6| Step: 6
Training loss: 0.9820312261581421
Validation loss: 1.7075424630154845

Epoch: 6| Step: 7
Training loss: 1.3743562698364258
Validation loss: 1.7377997277885355

Epoch: 6| Step: 8
Training loss: 0.7010133862495422
Validation loss: 1.735039461043573

Epoch: 6| Step: 9
Training loss: 1.179600477218628
Validation loss: 1.7497710156184372

Epoch: 6| Step: 10
Training loss: 0.8479347825050354
Validation loss: 1.7310507143697431

Epoch: 6| Step: 11
Training loss: 0.9854427576065063
Validation loss: 1.7649725406400618

Epoch: 6| Step: 12
Training loss: 1.2473640441894531
Validation loss: 1.747406554478471

Epoch: 6| Step: 13
Training loss: 0.5320531725883484
Validation loss: 1.7848110647611721

Epoch: 232| Step: 0
Training loss: 1.2173384428024292
Validation loss: 1.7814163501544664

Epoch: 6| Step: 1
Training loss: 0.8989224433898926
Validation loss: 1.8261053395527664

Epoch: 6| Step: 2
Training loss: 0.5110767483711243
Validation loss: 1.81224270789854

Epoch: 6| Step: 3
Training loss: 0.7933332920074463
Validation loss: 1.8611158965736307

Epoch: 6| Step: 4
Training loss: 0.8988966941833496
Validation loss: 1.8058052319352345

Epoch: 6| Step: 5
Training loss: 1.0413602590560913
Validation loss: 1.779854941111739

Epoch: 6| Step: 6
Training loss: 0.8674735426902771
Validation loss: 1.8122896020130446

Epoch: 6| Step: 7
Training loss: 0.9046154022216797
Validation loss: 1.7732649810852543

Epoch: 6| Step: 8
Training loss: 0.9982947707176208
Validation loss: 1.781128245015298

Epoch: 6| Step: 9
Training loss: 0.9151242971420288
Validation loss: 1.7375540092427244

Epoch: 6| Step: 10
Training loss: 0.895193874835968
Validation loss: 1.7304683372538576

Epoch: 6| Step: 11
Training loss: 1.6304041147232056
Validation loss: 1.749077667472183

Epoch: 6| Step: 12
Training loss: 0.8777467608451843
Validation loss: 1.7179320114915089

Epoch: 6| Step: 13
Training loss: 0.9358727335929871
Validation loss: 1.7312308652426607

Epoch: 233| Step: 0
Training loss: 0.9522275328636169
Validation loss: 1.6740679176904822

Epoch: 6| Step: 1
Training loss: 0.571212112903595
Validation loss: 1.7036139862511748

Epoch: 6| Step: 2
Training loss: 1.310001254081726
Validation loss: 1.6770864161111976

Epoch: 6| Step: 3
Training loss: 0.8756225109100342
Validation loss: 1.7019029394272835

Epoch: 6| Step: 4
Training loss: 1.2776819467544556
Validation loss: 1.728363649819487

Epoch: 6| Step: 5
Training loss: 1.2654821872711182
Validation loss: 1.7613382044658865

Epoch: 6| Step: 6
Training loss: 0.6415544748306274
Validation loss: 1.781373639260569

Epoch: 6| Step: 7
Training loss: 0.7766113877296448
Validation loss: 1.784472647533622

Epoch: 6| Step: 8
Training loss: 0.3141705393791199
Validation loss: 1.7718657960173905

Epoch: 6| Step: 9
Training loss: 0.7066580057144165
Validation loss: 1.7471633790641703

Epoch: 6| Step: 10
Training loss: 1.389610767364502
Validation loss: 1.7403772338744132

Epoch: 6| Step: 11
Training loss: 1.1344267129898071
Validation loss: 1.7538937214882142

Epoch: 6| Step: 12
Training loss: 1.233721137046814
Validation loss: 1.745151291611374

Epoch: 6| Step: 13
Training loss: 0.8164363503456116
Validation loss: 1.7537895274418656

Epoch: 234| Step: 0
Training loss: 0.7896919250488281
Validation loss: 1.7648614632186068

Epoch: 6| Step: 1
Training loss: 1.0367932319641113
Validation loss: 1.727956170676857

Epoch: 6| Step: 2
Training loss: 0.8577139377593994
Validation loss: 1.7205778911549559

Epoch: 6| Step: 3
Training loss: 0.9272508025169373
Validation loss: 1.7559890759888517

Epoch: 6| Step: 4
Training loss: 0.7462033033370972
Validation loss: 1.7440292155870827

Epoch: 6| Step: 5
Training loss: 1.1554040908813477
Validation loss: 1.7312704939996042

Epoch: 6| Step: 6
Training loss: 0.9303015470504761
Validation loss: 1.745336022428287

Epoch: 6| Step: 7
Training loss: 1.0366158485412598
Validation loss: 1.716669169805383

Epoch: 6| Step: 8
Training loss: 1.2609150409698486
Validation loss: 1.739759934845791

Epoch: 6| Step: 9
Training loss: 1.0214711427688599
Validation loss: 1.7173412025615733

Epoch: 6| Step: 10
Training loss: 1.5876375436782837
Validation loss: 1.7780247452438518

Epoch: 6| Step: 11
Training loss: 0.7099891901016235
Validation loss: 1.85486336036395

Epoch: 6| Step: 12
Training loss: 0.5782991051673889
Validation loss: 1.8563965341096282

Epoch: 6| Step: 13
Training loss: 1.0775734186172485
Validation loss: 1.8995312311316048

Epoch: 235| Step: 0
Training loss: 0.9157938361167908
Validation loss: 1.8200717702988656

Epoch: 6| Step: 1
Training loss: 0.5822093486785889
Validation loss: 1.767366914338963

Epoch: 6| Step: 2
Training loss: 0.6133899688720703
Validation loss: 1.6939257614074215

Epoch: 6| Step: 3
Training loss: 0.910419225692749
Validation loss: 1.6897689296353249

Epoch: 6| Step: 4
Training loss: 0.9329466223716736
Validation loss: 1.7442413235223422

Epoch: 6| Step: 5
Training loss: 1.2385979890823364
Validation loss: 1.730178007515528

Epoch: 6| Step: 6
Training loss: 0.678954005241394
Validation loss: 1.77448445622639

Epoch: 6| Step: 7
Training loss: 1.014219880104065
Validation loss: 1.7803227645094677

Epoch: 6| Step: 8
Training loss: 1.0756248235702515
Validation loss: 1.7902143719375774

Epoch: 6| Step: 9
Training loss: 1.2011033296585083
Validation loss: 1.820746583323325

Epoch: 6| Step: 10
Training loss: 1.2564027309417725
Validation loss: 1.8360045468935402

Epoch: 6| Step: 11
Training loss: 0.5716789960861206
Validation loss: 1.8682169016971384

Epoch: 6| Step: 12
Training loss: 1.712198257446289
Validation loss: 1.8530851333372054

Epoch: 6| Step: 13
Training loss: 0.9004929065704346
Validation loss: 1.8374383026553738

Epoch: 236| Step: 0
Training loss: 0.9697726964950562
Validation loss: 1.8271273374557495

Epoch: 6| Step: 1
Training loss: 0.5585508346557617
Validation loss: 1.7812984681898547

Epoch: 6| Step: 2
Training loss: 0.8219652771949768
Validation loss: 1.765870342972458

Epoch: 6| Step: 3
Training loss: 0.8907930254936218
Validation loss: 1.7232182948820052

Epoch: 6| Step: 4
Training loss: 0.8076796531677246
Validation loss: 1.7137978128207627

Epoch: 6| Step: 5
Training loss: 1.0555620193481445
Validation loss: 1.6773416624274304

Epoch: 6| Step: 6
Training loss: 0.9814401865005493
Validation loss: 1.6929102943789573

Epoch: 6| Step: 7
Training loss: 1.3737397193908691
Validation loss: 1.6557283670671525

Epoch: 6| Step: 8
Training loss: 1.2206237316131592
Validation loss: 1.6682960371817313

Epoch: 6| Step: 9
Training loss: 0.7047611474990845
Validation loss: 1.6521156334107923

Epoch: 6| Step: 10
Training loss: 1.401800274848938
Validation loss: 1.668663759385386

Epoch: 6| Step: 11
Training loss: 0.9042350649833679
Validation loss: 1.6619969632035942

Epoch: 6| Step: 12
Training loss: 0.7979961633682251
Validation loss: 1.6809249193437639

Epoch: 6| Step: 13
Training loss: 0.9702987670898438
Validation loss: 1.7261304393891366

Epoch: 237| Step: 0
Training loss: 0.9583553671836853
Validation loss: 1.7335969722399147

Epoch: 6| Step: 1
Training loss: 0.47499045729637146
Validation loss: 1.7130986503375474

Epoch: 6| Step: 2
Training loss: 0.9403581619262695
Validation loss: 1.7660076643830986

Epoch: 6| Step: 3
Training loss: 1.2365024089813232
Validation loss: 1.8118676780372538

Epoch: 6| Step: 4
Training loss: 1.0685847997665405
Validation loss: 1.8423793495342295

Epoch: 6| Step: 5
Training loss: 1.1912468671798706
Validation loss: 1.8448781813344648

Epoch: 6| Step: 6
Training loss: 1.2047150135040283
Validation loss: 1.7959549837214972

Epoch: 6| Step: 7
Training loss: 0.8749099373817444
Validation loss: 1.8051064245162471

Epoch: 6| Step: 8
Training loss: 0.7345113754272461
Validation loss: 1.766596491618823

Epoch: 6| Step: 9
Training loss: 1.060999870300293
Validation loss: 1.8123550466311875

Epoch: 6| Step: 10
Training loss: 0.9444993138313293
Validation loss: 1.792185664176941

Epoch: 6| Step: 11
Training loss: 0.819657564163208
Validation loss: 1.7553818789861535

Epoch: 6| Step: 12
Training loss: 0.7622820138931274
Validation loss: 1.7287340920458558

Epoch: 6| Step: 13
Training loss: 0.7131044864654541
Validation loss: 1.7665678685711277

Epoch: 238| Step: 0
Training loss: 1.2004672288894653
Validation loss: 1.8094635009765625

Epoch: 6| Step: 1
Training loss: 0.8848069906234741
Validation loss: 1.8388373928685342

Epoch: 6| Step: 2
Training loss: 1.061298131942749
Validation loss: 1.8622658329625283

Epoch: 6| Step: 3
Training loss: 1.3349158763885498
Validation loss: 1.8366298649900703

Epoch: 6| Step: 4
Training loss: 1.3874292373657227
Validation loss: 1.7719817879379436

Epoch: 6| Step: 5
Training loss: 0.8943103551864624
Validation loss: 1.7492652682847873

Epoch: 6| Step: 6
Training loss: 0.46393293142318726
Validation loss: 1.7368808715574202

Epoch: 6| Step: 7
Training loss: 0.7083615064620972
Validation loss: 1.748014368036742

Epoch: 6| Step: 8
Training loss: 0.9899617433547974
Validation loss: 1.7398038756462835

Epoch: 6| Step: 9
Training loss: 1.1837817430496216
Validation loss: 1.7334064796406736

Epoch: 6| Step: 10
Training loss: 0.7085069417953491
Validation loss: 1.7558810146906043

Epoch: 6| Step: 11
Training loss: 0.5165245532989502
Validation loss: 1.7500909502788256

Epoch: 6| Step: 12
Training loss: 1.3248400688171387
Validation loss: 1.7606167613819081

Epoch: 6| Step: 13
Training loss: 0.6595996022224426
Validation loss: 1.755820523026169

Epoch: 239| Step: 0
Training loss: 0.5188189148902893
Validation loss: 1.7709248232585129

Epoch: 6| Step: 1
Training loss: 1.3733102083206177
Validation loss: 1.7739297574566257

Epoch: 6| Step: 2
Training loss: 1.1368863582611084
Validation loss: 1.7981298328727804

Epoch: 6| Step: 3
Training loss: 1.0122568607330322
Validation loss: 1.7742729648467033

Epoch: 6| Step: 4
Training loss: 0.8880647420883179
Validation loss: 1.7612613337014311

Epoch: 6| Step: 5
Training loss: 1.1240506172180176
Validation loss: 1.7630797099041682

Epoch: 6| Step: 6
Training loss: 0.8570864796638489
Validation loss: 1.7768631314718595

Epoch: 6| Step: 7
Training loss: 0.8994391560554504
Validation loss: 1.7727392950365621

Epoch: 6| Step: 8
Training loss: 1.2897331714630127
Validation loss: 1.7602520873469691

Epoch: 6| Step: 9
Training loss: 0.629873514175415
Validation loss: 1.7382305155518234

Epoch: 6| Step: 10
Training loss: 0.6718654632568359
Validation loss: 1.752479035367248

Epoch: 6| Step: 11
Training loss: 0.9129825234413147
Validation loss: 1.7533400520201652

Epoch: 6| Step: 12
Training loss: 0.48694178462028503
Validation loss: 1.7812103199702438

Epoch: 6| Step: 13
Training loss: 1.0036141872406006
Validation loss: 1.789210202873394

Epoch: 240| Step: 0
Training loss: 1.0677554607391357
Validation loss: 1.7706345563293786

Epoch: 6| Step: 1
Training loss: 1.066812515258789
Validation loss: 1.7764917240347913

Epoch: 6| Step: 2
Training loss: 0.9334770441055298
Validation loss: 1.7269608410455848

Epoch: 6| Step: 3
Training loss: 1.014176607131958
Validation loss: 1.7245334502189391

Epoch: 6| Step: 4
Training loss: 1.1968945264816284
Validation loss: 1.7256153834763395

Epoch: 6| Step: 5
Training loss: 1.1175042390823364
Validation loss: 1.7233712711641866

Epoch: 6| Step: 6
Training loss: 0.3684805929660797
Validation loss: 1.7318470196057392

Epoch: 6| Step: 7
Training loss: 0.5709165334701538
Validation loss: 1.7635723724160144

Epoch: 6| Step: 8
Training loss: 0.5724419355392456
Validation loss: 1.7839320628873763

Epoch: 6| Step: 9
Training loss: 1.0261118412017822
Validation loss: 1.7580369146921302

Epoch: 6| Step: 10
Training loss: 0.983591616153717
Validation loss: 1.7297084216148622

Epoch: 6| Step: 11
Training loss: 0.581535816192627
Validation loss: 1.723466541177483

Epoch: 6| Step: 12
Training loss: 1.0165369510650635
Validation loss: 1.7180016002347391

Epoch: 6| Step: 13
Training loss: 1.002958059310913
Validation loss: 1.7169072397293583

Epoch: 241| Step: 0
Training loss: 0.6990275979042053
Validation loss: 1.6955245694806498

Epoch: 6| Step: 1
Training loss: 0.799357533454895
Validation loss: 1.7058125900965866

Epoch: 6| Step: 2
Training loss: 0.7508508563041687
Validation loss: 1.709489433996139

Epoch: 6| Step: 3
Training loss: 0.6883114576339722
Validation loss: 1.7505284022259455

Epoch: 6| Step: 4
Training loss: 0.8588832020759583
Validation loss: 1.7474503132604784

Epoch: 6| Step: 5
Training loss: 1.0014159679412842
Validation loss: 1.7022023367625412

Epoch: 6| Step: 6
Training loss: 1.008042573928833
Validation loss: 1.6953592633688321

Epoch: 6| Step: 7
Training loss: 0.8485446572303772
Validation loss: 1.678121696236313

Epoch: 6| Step: 8
Training loss: 1.0466212034225464
Validation loss: 1.7242018202299714

Epoch: 6| Step: 9
Training loss: 1.1060298681259155
Validation loss: 1.7197587002990067

Epoch: 6| Step: 10
Training loss: 0.8353230357170105
Validation loss: 1.7268221942327355

Epoch: 6| Step: 11
Training loss: 0.8583385944366455
Validation loss: 1.69057253355621

Epoch: 6| Step: 12
Training loss: 1.0200400352478027
Validation loss: 1.7236444040011334

Epoch: 6| Step: 13
Training loss: 0.581525981426239
Validation loss: 1.7321311966065438

Epoch: 242| Step: 0
Training loss: 1.5627621412277222
Validation loss: 1.757275604432629

Epoch: 6| Step: 1
Training loss: 0.8954557180404663
Validation loss: 1.7342161029897711

Epoch: 6| Step: 2
Training loss: 0.7308953404426575
Validation loss: 1.741395502962092

Epoch: 6| Step: 3
Training loss: 1.0028959512710571
Validation loss: 1.773660216280209

Epoch: 6| Step: 4
Training loss: 0.5241360664367676
Validation loss: 1.8052931062636837

Epoch: 6| Step: 5
Training loss: 0.7222903966903687
Validation loss: 1.7849778308663318

Epoch: 6| Step: 6
Training loss: 0.7858648300170898
Validation loss: 1.735168977450299

Epoch: 6| Step: 7
Training loss: 0.8288629055023193
Validation loss: 1.7575271808972923

Epoch: 6| Step: 8
Training loss: 0.7468178868293762
Validation loss: 1.742556014368611

Epoch: 6| Step: 9
Training loss: 0.7544072866439819
Validation loss: 1.7701666226951025

Epoch: 6| Step: 10
Training loss: 1.0491821765899658
Validation loss: 1.7570276619285665

Epoch: 6| Step: 11
Training loss: 0.824165940284729
Validation loss: 1.8141214232290945

Epoch: 6| Step: 12
Training loss: 0.7327285408973694
Validation loss: 1.7586727757607736

Epoch: 6| Step: 13
Training loss: 0.6134037375450134
Validation loss: 1.7637550407840359

Epoch: 243| Step: 0
Training loss: 0.9493259787559509
Validation loss: 1.7922015728489045

Epoch: 6| Step: 1
Training loss: 0.995538592338562
Validation loss: 1.7841851877909836

Epoch: 6| Step: 2
Training loss: 0.7019907236099243
Validation loss: 1.7870392235376502

Epoch: 6| Step: 3
Training loss: 1.3466670513153076
Validation loss: 1.798653656436551

Epoch: 6| Step: 4
Training loss: 0.6318479776382446
Validation loss: 1.7570159877500227

Epoch: 6| Step: 5
Training loss: 0.48020488023757935
Validation loss: 1.7236370501979705

Epoch: 6| Step: 6
Training loss: 0.7123008370399475
Validation loss: 1.7047102656415714

Epoch: 6| Step: 7
Training loss: 0.7122846841812134
Validation loss: 1.698913929282978

Epoch: 6| Step: 8
Training loss: 0.7550960779190063
Validation loss: 1.6966569910767257

Epoch: 6| Step: 9
Training loss: 0.9810026288032532
Validation loss: 1.721158496795162

Epoch: 6| Step: 10
Training loss: 0.9286710023880005
Validation loss: 1.667410332669494

Epoch: 6| Step: 11
Training loss: 0.7741776704788208
Validation loss: 1.7072727013659734

Epoch: 6| Step: 12
Training loss: 0.9601233005523682
Validation loss: 1.7505068266263573

Epoch: 6| Step: 13
Training loss: 1.1374541521072388
Validation loss: 1.7557271334432787

Epoch: 244| Step: 0
Training loss: 0.5596159100532532
Validation loss: 1.720770235984556

Epoch: 6| Step: 1
Training loss: 0.5166494846343994
Validation loss: 1.7159002980878275

Epoch: 6| Step: 2
Training loss: 0.9470528364181519
Validation loss: 1.7074804152211835

Epoch: 6| Step: 3
Training loss: 0.7200762033462524
Validation loss: 1.714118129463606

Epoch: 6| Step: 4
Training loss: 0.9035384058952332
Validation loss: 1.7555486950823056

Epoch: 6| Step: 5
Training loss: 0.8010926246643066
Validation loss: 1.7808400482259772

Epoch: 6| Step: 6
Training loss: 0.5197551250457764
Validation loss: 1.7560120423634846

Epoch: 6| Step: 7
Training loss: 1.1052355766296387
Validation loss: 1.7793102187495078

Epoch: 6| Step: 8
Training loss: 0.5746689438819885
Validation loss: 1.7694828843557706

Epoch: 6| Step: 9
Training loss: 0.9508333802223206
Validation loss: 1.757095996410616

Epoch: 6| Step: 10
Training loss: 1.2013616561889648
Validation loss: 1.7582416636969453

Epoch: 6| Step: 11
Training loss: 1.2380273342132568
Validation loss: 1.7274918517758768

Epoch: 6| Step: 12
Training loss: 0.7999740242958069
Validation loss: 1.746987594071255

Epoch: 6| Step: 13
Training loss: 1.4689925909042358
Validation loss: 1.7423961803477297

Epoch: 245| Step: 0
Training loss: 0.7510828971862793
Validation loss: 1.7081057230631511

Epoch: 6| Step: 1
Training loss: 1.1506483554840088
Validation loss: 1.691339587652555

Epoch: 6| Step: 2
Training loss: 0.7622818946838379
Validation loss: 1.7486115347954534

Epoch: 6| Step: 3
Training loss: 0.9862185120582581
Validation loss: 1.7556502806243075

Epoch: 6| Step: 4
Training loss: 0.9781873822212219
Validation loss: 1.7887002832146102

Epoch: 6| Step: 5
Training loss: 0.8650786876678467
Validation loss: 1.8005794684092205

Epoch: 6| Step: 6
Training loss: 0.49036064743995667
Validation loss: 1.7444532148299678

Epoch: 6| Step: 7
Training loss: 0.5691521167755127
Validation loss: 1.7739594918425365

Epoch: 6| Step: 8
Training loss: 0.7820171117782593
Validation loss: 1.7445879213271602

Epoch: 6| Step: 9
Training loss: 0.8648555874824524
Validation loss: 1.7553193351273895

Epoch: 6| Step: 10
Training loss: 0.9898527264595032
Validation loss: 1.7626829172975274

Epoch: 6| Step: 11
Training loss: 0.9086003303527832
Validation loss: 1.735837407009576

Epoch: 6| Step: 12
Training loss: 0.8377459049224854
Validation loss: 1.7475478162047684

Epoch: 6| Step: 13
Training loss: 1.0645718574523926
Validation loss: 1.7310439066220356

Epoch: 246| Step: 0
Training loss: 0.5793957710266113
Validation loss: 1.7564312206801547

Epoch: 6| Step: 1
Training loss: 0.9031822085380554
Validation loss: 1.8060479779397287

Epoch: 6| Step: 2
Training loss: 0.67872154712677
Validation loss: 1.792079189772247

Epoch: 6| Step: 3
Training loss: 1.1378872394561768
Validation loss: 1.8116638532248877

Epoch: 6| Step: 4
Training loss: 0.7547085881233215
Validation loss: 1.7651850561941824

Epoch: 6| Step: 5
Training loss: 0.8370978832244873
Validation loss: 1.7239176509200886

Epoch: 6| Step: 6
Training loss: 0.8313373327255249
Validation loss: 1.7198224862416585

Epoch: 6| Step: 7
Training loss: 1.0413594245910645
Validation loss: 1.7074922412954352

Epoch: 6| Step: 8
Training loss: 0.6849325895309448
Validation loss: 1.7057849079050043

Epoch: 6| Step: 9
Training loss: 0.9399491548538208
Validation loss: 1.714575280425369

Epoch: 6| Step: 10
Training loss: 0.635796070098877
Validation loss: 1.6797980608478669

Epoch: 6| Step: 11
Training loss: 0.8693337440490723
Validation loss: 1.690734758171984

Epoch: 6| Step: 12
Training loss: 1.435185194015503
Validation loss: 1.7118070125579834

Epoch: 6| Step: 13
Training loss: 0.823219358921051
Validation loss: 1.7053995286264727

Epoch: 247| Step: 0
Training loss: 0.5599236488342285
Validation loss: 1.768901317350326

Epoch: 6| Step: 1
Training loss: 1.220211148262024
Validation loss: 1.8151306439471502

Epoch: 6| Step: 2
Training loss: 1.2818944454193115
Validation loss: 1.7928081071504982

Epoch: 6| Step: 3
Training loss: 0.9188226461410522
Validation loss: 1.7811228972609325

Epoch: 6| Step: 4
Training loss: 0.9136554002761841
Validation loss: 1.7498439614490797

Epoch: 6| Step: 5
Training loss: 1.0773109197616577
Validation loss: 1.7386560670791134

Epoch: 6| Step: 6
Training loss: 0.8990193605422974
Validation loss: 1.7125845865536762

Epoch: 6| Step: 7
Training loss: 0.8666703701019287
Validation loss: 1.7261933626667145

Epoch: 6| Step: 8
Training loss: 0.6587013006210327
Validation loss: 1.7377139906729422

Epoch: 6| Step: 9
Training loss: 0.7688814997673035
Validation loss: 1.7565984136314803

Epoch: 6| Step: 10
Training loss: 0.8558961153030396
Validation loss: 1.744231044605214

Epoch: 6| Step: 11
Training loss: 0.7670553922653198
Validation loss: 1.7456829368427236

Epoch: 6| Step: 12
Training loss: 0.40783676505088806
Validation loss: 1.7587286874812136

Epoch: 6| Step: 13
Training loss: 0.7612097263336182
Validation loss: 1.766135907942249

Epoch: 248| Step: 0
Training loss: 1.2418779134750366
Validation loss: 1.7480785487800516

Epoch: 6| Step: 1
Training loss: 0.7111814618110657
Validation loss: 1.7484098378048147

Epoch: 6| Step: 2
Training loss: 0.9739395380020142
Validation loss: 1.7172686746043544

Epoch: 6| Step: 3
Training loss: 0.47358426451683044
Validation loss: 1.6899703676982591

Epoch: 6| Step: 4
Training loss: 0.6006726026535034
Validation loss: 1.7021439421561457

Epoch: 6| Step: 5
Training loss: 1.00752854347229
Validation loss: 1.6696395617659374

Epoch: 6| Step: 6
Training loss: 0.5978378653526306
Validation loss: 1.7014060199901622

Epoch: 6| Step: 7
Training loss: 0.5276694297790527
Validation loss: 1.717081057128086

Epoch: 6| Step: 8
Training loss: 0.9521857500076294
Validation loss: 1.735221516701483

Epoch: 6| Step: 9
Training loss: 1.0919272899627686
Validation loss: 1.7195843573539489

Epoch: 6| Step: 10
Training loss: 0.9321303367614746
Validation loss: 1.7424200504056868

Epoch: 6| Step: 11
Training loss: 0.918453574180603
Validation loss: 1.7493604665161462

Epoch: 6| Step: 12
Training loss: 0.8992900252342224
Validation loss: 1.7716238831961026

Epoch: 6| Step: 13
Training loss: 0.6588099598884583
Validation loss: 1.7725951312690653

Epoch: 249| Step: 0
Training loss: 1.1173559427261353
Validation loss: 1.7845587615043885

Epoch: 6| Step: 1
Training loss: 0.6847889423370361
Validation loss: 1.7756654536852272

Epoch: 6| Step: 2
Training loss: 0.8977439999580383
Validation loss: 1.7594866932079356

Epoch: 6| Step: 3
Training loss: 0.7772756814956665
Validation loss: 1.7352485464465233

Epoch: 6| Step: 4
Training loss: 0.4913831651210785
Validation loss: 1.6821589982637795

Epoch: 6| Step: 5
Training loss: 0.980276882648468
Validation loss: 1.7129333083347609

Epoch: 6| Step: 6
Training loss: 0.8346003293991089
Validation loss: 1.6650004104901386

Epoch: 6| Step: 7
Training loss: 0.43016594648361206
Validation loss: 1.6708894083576817

Epoch: 6| Step: 8
Training loss: 1.0663610696792603
Validation loss: 1.650671528231713

Epoch: 6| Step: 9
Training loss: 0.6752565503120422
Validation loss: 1.6799777271927043

Epoch: 6| Step: 10
Training loss: 0.5981718301773071
Validation loss: 1.7219738127082906

Epoch: 6| Step: 11
Training loss: 1.1628187894821167
Validation loss: 1.7310329303946546

Epoch: 6| Step: 12
Training loss: 0.8799071311950684
Validation loss: 1.6897731839969594

Epoch: 6| Step: 13
Training loss: 0.9102137684822083
Validation loss: 1.726233151651198

Epoch: 250| Step: 0
Training loss: 0.9510676860809326
Validation loss: 1.727199654425344

Epoch: 6| Step: 1
Training loss: 0.9379845261573792
Validation loss: 1.783999910918615

Epoch: 6| Step: 2
Training loss: 1.1924424171447754
Validation loss: 1.783661296290736

Epoch: 6| Step: 3
Training loss: 0.6280112862586975
Validation loss: 1.8618254943560528

Epoch: 6| Step: 4
Training loss: 0.44692182540893555
Validation loss: 1.8479499739985312

Epoch: 6| Step: 5
Training loss: 0.7532912492752075
Validation loss: 1.848681680617794

Epoch: 6| Step: 6
Training loss: 1.0205166339874268
Validation loss: 1.8015765169615388

Epoch: 6| Step: 7
Training loss: 0.642227053642273
Validation loss: 1.8138739908895185

Epoch: 6| Step: 8
Training loss: 1.0372154712677002
Validation loss: 1.7885003320632442

Epoch: 6| Step: 9
Training loss: 0.5386394262313843
Validation loss: 1.7525389220124932

Epoch: 6| Step: 10
Training loss: 0.9320486783981323
Validation loss: 1.7268070431165798

Epoch: 6| Step: 11
Training loss: 0.8613478541374207
Validation loss: 1.6998156270673197

Epoch: 6| Step: 12
Training loss: 0.6747144460678101
Validation loss: 1.6764544504944996

Epoch: 6| Step: 13
Training loss: 0.764085054397583
Validation loss: 1.6572079581599082

Epoch: 251| Step: 0
Training loss: 0.8801723122596741
Validation loss: 1.6825190987638248

Epoch: 6| Step: 1
Training loss: 0.8394504189491272
Validation loss: 1.658794190293999

Epoch: 6| Step: 2
Training loss: 0.9692851901054382
Validation loss: 1.6800291743329776

Epoch: 6| Step: 3
Training loss: 0.8685051798820496
Validation loss: 1.7125182369703889

Epoch: 6| Step: 4
Training loss: 0.7932471632957458
Validation loss: 1.763182314493323

Epoch: 6| Step: 5
Training loss: 0.6347708106040955
Validation loss: 1.742430733096215

Epoch: 6| Step: 6
Training loss: 1.2354850769042969
Validation loss: 1.7012498494117492

Epoch: 6| Step: 7
Training loss: 0.8088264465332031
Validation loss: 1.6915614425495107

Epoch: 6| Step: 8
Training loss: 0.5747071504592896
Validation loss: 1.6758494530954668

Epoch: 6| Step: 9
Training loss: 0.8721785545349121
Validation loss: 1.6549374313764675

Epoch: 6| Step: 10
Training loss: 0.9471889734268188
Validation loss: 1.6718334228761735

Epoch: 6| Step: 11
Training loss: 0.9078487157821655
Validation loss: 1.7129320047234977

Epoch: 6| Step: 12
Training loss: 0.526103675365448
Validation loss: 1.7065109514421033

Epoch: 6| Step: 13
Training loss: 0.6556527614593506
Validation loss: 1.7025671415431525

Epoch: 252| Step: 0
Training loss: 0.5817540884017944
Validation loss: 1.6753120935091408

Epoch: 6| Step: 1
Training loss: 0.5790254473686218
Validation loss: 1.6976310835089734

Epoch: 6| Step: 2
Training loss: 0.721251904964447
Validation loss: 1.7058076281701364

Epoch: 6| Step: 3
Training loss: 0.9887813329696655
Validation loss: 1.7755330608737083

Epoch: 6| Step: 4
Training loss: 1.0886352062225342
Validation loss: 1.8040839959216375

Epoch: 6| Step: 5
Training loss: 0.76072758436203
Validation loss: 1.8230834443082091

Epoch: 6| Step: 6
Training loss: 0.8746176958084106
Validation loss: 1.7998102249637726

Epoch: 6| Step: 7
Training loss: 0.9817696809768677
Validation loss: 1.7948312938854258

Epoch: 6| Step: 8
Training loss: 1.0168273448944092
Validation loss: 1.7818186731748684

Epoch: 6| Step: 9
Training loss: 0.7998422980308533
Validation loss: 1.738317971588463

Epoch: 6| Step: 10
Training loss: 0.7773550748825073
Validation loss: 1.7301536619022329

Epoch: 6| Step: 11
Training loss: 0.6378911137580872
Validation loss: 1.7122761780215847

Epoch: 6| Step: 12
Training loss: 0.4307769536972046
Validation loss: 1.6851065338298838

Epoch: 6| Step: 13
Training loss: 0.9655129909515381
Validation loss: 1.6726180584199968

Epoch: 253| Step: 0
Training loss: 0.7479263544082642
Validation loss: 1.7115876802834131

Epoch: 6| Step: 1
Training loss: 0.6654342412948608
Validation loss: 1.7230436007181804

Epoch: 6| Step: 2
Training loss: 0.683646023273468
Validation loss: 1.7472095002410233

Epoch: 6| Step: 3
Training loss: 0.8101121187210083
Validation loss: 1.7515248752409411

Epoch: 6| Step: 4
Training loss: 1.2033185958862305
Validation loss: 1.7205857115407144

Epoch: 6| Step: 5
Training loss: 1.042792558670044
Validation loss: 1.7086605923150175

Epoch: 6| Step: 6
Training loss: 0.666504442691803
Validation loss: 1.6918028926336637

Epoch: 6| Step: 7
Training loss: 0.5855847597122192
Validation loss: 1.6544657676450667

Epoch: 6| Step: 8
Training loss: 0.8556841015815735
Validation loss: 1.6665988122263262

Epoch: 6| Step: 9
Training loss: 0.7736002206802368
Validation loss: 1.678756074238849

Epoch: 6| Step: 10
Training loss: 0.35676348209381104
Validation loss: 1.6514711559459727

Epoch: 6| Step: 11
Training loss: 0.8168268203735352
Validation loss: 1.6609952526707803

Epoch: 6| Step: 12
Training loss: 0.7448290586471558
Validation loss: 1.700936117479878

Epoch: 6| Step: 13
Training loss: 0.9840876460075378
Validation loss: 1.693053122489683

Epoch: 254| Step: 0
Training loss: 0.7658716440200806
Validation loss: 1.7226001844611218

Epoch: 6| Step: 1
Training loss: 0.6275572776794434
Validation loss: 1.7229956567928355

Epoch: 6| Step: 2
Training loss: 1.0353586673736572
Validation loss: 1.7449636305532148

Epoch: 6| Step: 3
Training loss: 0.6128991842269897
Validation loss: 1.7309290491124636

Epoch: 6| Step: 4
Training loss: 0.7291866540908813
Validation loss: 1.692534669753044

Epoch: 6| Step: 5
Training loss: 0.9480629563331604
Validation loss: 1.684228060066059

Epoch: 6| Step: 6
Training loss: 0.6607411503791809
Validation loss: 1.6779611725961008

Epoch: 6| Step: 7
Training loss: 0.6750171184539795
Validation loss: 1.658892875076622

Epoch: 6| Step: 8
Training loss: 0.756170392036438
Validation loss: 1.7023234854462326

Epoch: 6| Step: 9
Training loss: 0.8725117444992065
Validation loss: 1.7122109179855676

Epoch: 6| Step: 10
Training loss: 0.9702178239822388
Validation loss: 1.7265550321148289

Epoch: 6| Step: 11
Training loss: 0.5629225969314575
Validation loss: 1.7222942229240172

Epoch: 6| Step: 12
Training loss: 0.7708836197853088
Validation loss: 1.7003438959839523

Epoch: 6| Step: 13
Training loss: 0.790439784526825
Validation loss: 1.6737890884440432

Epoch: 255| Step: 0
Training loss: 1.063351035118103
Validation loss: 1.6628268662319388

Epoch: 6| Step: 1
Training loss: 0.7717273235321045
Validation loss: 1.6900667875043807

Epoch: 6| Step: 2
Training loss: 0.8933447599411011
Validation loss: 1.6832498337632866

Epoch: 6| Step: 3
Training loss: 0.6366045475006104
Validation loss: 1.6988054885659167

Epoch: 6| Step: 4
Training loss: 0.8339573740959167
Validation loss: 1.659880058739775

Epoch: 6| Step: 5
Training loss: 0.4636278748512268
Validation loss: 1.6944583808222125

Epoch: 6| Step: 6
Training loss: 0.6892644166946411
Validation loss: 1.702175780009198

Epoch: 6| Step: 7
Training loss: 0.6630629301071167
Validation loss: 1.7126648502965127

Epoch: 6| Step: 8
Training loss: 0.761374831199646
Validation loss: 1.7196756229605725

Epoch: 6| Step: 9
Training loss: 0.8060128092765808
Validation loss: 1.7110592049937094

Epoch: 6| Step: 10
Training loss: 0.8263102769851685
Validation loss: 1.739057405020601

Epoch: 6| Step: 11
Training loss: 0.6039166450500488
Validation loss: 1.7428038684270715

Epoch: 6| Step: 12
Training loss: 0.735334575176239
Validation loss: 1.7397712251191497

Epoch: 6| Step: 13
Training loss: 1.0059287548065186
Validation loss: 1.7107645209117601

Epoch: 256| Step: 0
Training loss: 0.6271153688430786
Validation loss: 1.7030250551880046

Epoch: 6| Step: 1
Training loss: 0.625413179397583
Validation loss: 1.6718969601456837

Epoch: 6| Step: 2
Training loss: 0.9596807360649109
Validation loss: 1.6803098981098463

Epoch: 6| Step: 3
Training loss: 0.7177768349647522
Validation loss: 1.7088397202953216

Epoch: 6| Step: 4
Training loss: 0.8399097919464111
Validation loss: 1.7326138814290364

Epoch: 6| Step: 5
Training loss: 0.48064124584198
Validation loss: 1.7491513465040474

Epoch: 6| Step: 6
Training loss: 0.4785494804382324
Validation loss: 1.75909254371479

Epoch: 6| Step: 7
Training loss: 0.7844768166542053
Validation loss: 1.7707644970186296

Epoch: 6| Step: 8
Training loss: 1.0999881029129028
Validation loss: 1.8060701854767338

Epoch: 6| Step: 9
Training loss: 0.6325116157531738
Validation loss: 1.7704784600965437

Epoch: 6| Step: 10
Training loss: 0.39888399839401245
Validation loss: 1.756175817981843

Epoch: 6| Step: 11
Training loss: 0.9252730011940002
Validation loss: 1.7119107566854006

Epoch: 6| Step: 12
Training loss: 1.2729474306106567
Validation loss: 1.728088968543596

Epoch: 6| Step: 13
Training loss: 0.7685341238975525
Validation loss: 1.6932765283892233

Epoch: 257| Step: 0
Training loss: 0.9996331930160522
Validation loss: 1.7199180215917609

Epoch: 6| Step: 1
Training loss: 0.7000130414962769
Validation loss: 1.7192671516890168

Epoch: 6| Step: 2
Training loss: 0.6182531118392944
Validation loss: 1.7311083898749402

Epoch: 6| Step: 3
Training loss: 0.9139211177825928
Validation loss: 1.737767009324925

Epoch: 6| Step: 4
Training loss: 0.7439342737197876
Validation loss: 1.7335465620922785

Epoch: 6| Step: 5
Training loss: 0.8409064412117004
Validation loss: 1.713529465019062

Epoch: 6| Step: 6
Training loss: 0.4992561340332031
Validation loss: 1.7197074146680935

Epoch: 6| Step: 7
Training loss: 0.6113492250442505
Validation loss: 1.7338365867573728

Epoch: 6| Step: 8
Training loss: 0.7843464612960815
Validation loss: 1.7125394293057021

Epoch: 6| Step: 9
Training loss: 0.4948650002479553
Validation loss: 1.6969495716915335

Epoch: 6| Step: 10
Training loss: 0.9286160469055176
Validation loss: 1.7628370702907603

Epoch: 6| Step: 11
Training loss: 0.8698546886444092
Validation loss: 1.7580059869315035

Epoch: 6| Step: 12
Training loss: 0.568828821182251
Validation loss: 1.7476352760868687

Epoch: 6| Step: 13
Training loss: 0.24060222506523132
Validation loss: 1.745664354293577

Epoch: 258| Step: 0
Training loss: 0.7883391380310059
Validation loss: 1.7433901615040277

Epoch: 6| Step: 1
Training loss: 0.6187293529510498
Validation loss: 1.7230707676179948

Epoch: 6| Step: 2
Training loss: 0.9909018278121948
Validation loss: 1.7101028414182766

Epoch: 6| Step: 3
Training loss: 1.0546954870224
Validation loss: 1.68288847707933

Epoch: 6| Step: 4
Training loss: 0.5618542432785034
Validation loss: 1.7237462830799881

Epoch: 6| Step: 5
Training loss: 0.821033239364624
Validation loss: 1.702861326996998

Epoch: 6| Step: 6
Training loss: 0.9086991548538208
Validation loss: 1.7182492004927767

Epoch: 6| Step: 7
Training loss: 0.5443931818008423
Validation loss: 1.7397846047596266

Epoch: 6| Step: 8
Training loss: 1.1589088439941406
Validation loss: 1.7745764806706419

Epoch: 6| Step: 9
Training loss: 0.4778449833393097
Validation loss: 1.7571965827736804

Epoch: 6| Step: 10
Training loss: 0.8596978187561035
Validation loss: 1.767263650894165

Epoch: 6| Step: 11
Training loss: 0.4913454055786133
Validation loss: 1.76396926500464

Epoch: 6| Step: 12
Training loss: 0.6060841083526611
Validation loss: 1.7371887622341033

Epoch: 6| Step: 13
Training loss: 0.23830707371234894
Validation loss: 1.7090502964553012

Epoch: 259| Step: 0
Training loss: 0.6181219220161438
Validation loss: 1.7203239663954704

Epoch: 6| Step: 1
Training loss: 0.38767385482788086
Validation loss: 1.6933228828573739

Epoch: 6| Step: 2
Training loss: 0.6141259670257568
Validation loss: 1.7073520793709704

Epoch: 6| Step: 3
Training loss: 0.9118528366088867
Validation loss: 1.6437984346061625

Epoch: 6| Step: 4
Training loss: 0.6953445076942444
Validation loss: 1.6723402238661242

Epoch: 6| Step: 5
Training loss: 0.748808741569519
Validation loss: 1.6369357121888028

Epoch: 6| Step: 6
Training loss: 0.653240978717804
Validation loss: 1.6257742322901243

Epoch: 6| Step: 7
Training loss: 0.8444969058036804
Validation loss: 1.6235560140302103

Epoch: 6| Step: 8
Training loss: 0.6638875007629395
Validation loss: 1.649854479297515

Epoch: 6| Step: 9
Training loss: 1.0767912864685059
Validation loss: 1.7111712424985823

Epoch: 6| Step: 10
Training loss: 0.908372163772583
Validation loss: 1.7290033960855136

Epoch: 6| Step: 11
Training loss: 0.7840956449508667
Validation loss: 1.8068967570540726

Epoch: 6| Step: 12
Training loss: 0.5940410494804382
Validation loss: 1.7937625351772513

Epoch: 6| Step: 13
Training loss: 0.8466896414756775
Validation loss: 1.789772274673626

Epoch: 260| Step: 0
Training loss: 0.7492684125900269
Validation loss: 1.74568021938365

Epoch: 6| Step: 1
Training loss: 1.117697834968567
Validation loss: 1.7258343658139628

Epoch: 6| Step: 2
Training loss: 0.8248230814933777
Validation loss: 1.719743779910508

Epoch: 6| Step: 3
Training loss: 0.8307476043701172
Validation loss: 1.7282411949608916

Epoch: 6| Step: 4
Training loss: 0.7182347178459167
Validation loss: 1.7304420945464924

Epoch: 6| Step: 5
Training loss: 0.3445468246936798
Validation loss: 1.7425398711235291

Epoch: 6| Step: 6
Training loss: 0.5849444270133972
Validation loss: 1.676606887130327

Epoch: 6| Step: 7
Training loss: 0.6170042753219604
Validation loss: 1.6813284530434558

Epoch: 6| Step: 8
Training loss: 1.109788417816162
Validation loss: 1.6613267237140286

Epoch: 6| Step: 9
Training loss: 0.6479851007461548
Validation loss: 1.658666908100087

Epoch: 6| Step: 10
Training loss: 0.5535733699798584
Validation loss: 1.6488950790897492

Epoch: 6| Step: 11
Training loss: 0.5903753042221069
Validation loss: 1.6405107334095945

Epoch: 6| Step: 12
Training loss: 0.4816528260707855
Validation loss: 1.6500272033035115

Epoch: 6| Step: 13
Training loss: 0.5233428478240967
Validation loss: 1.671011701706917

Epoch: 261| Step: 0
Training loss: 0.6573542952537537
Validation loss: 1.6546504048890964

Epoch: 6| Step: 1
Training loss: 1.1266268491744995
Validation loss: 1.6462341380375687

Epoch: 6| Step: 2
Training loss: 0.8352595567703247
Validation loss: 1.6361380469414495

Epoch: 6| Step: 3
Training loss: 0.6430466175079346
Validation loss: 1.6645655503837011

Epoch: 6| Step: 4
Training loss: 0.37319743633270264
Validation loss: 1.6745747173986127

Epoch: 6| Step: 5
Training loss: 0.6193212270736694
Validation loss: 1.6792998006266933

Epoch: 6| Step: 6
Training loss: 0.6394815444946289
Validation loss: 1.6667512924440446

Epoch: 6| Step: 7
Training loss: 0.535114049911499
Validation loss: 1.6740184842899282

Epoch: 6| Step: 8
Training loss: 0.7561665773391724
Validation loss: 1.6636131937785814

Epoch: 6| Step: 9
Training loss: 0.8826008439064026
Validation loss: 1.6989485397133777

Epoch: 6| Step: 10
Training loss: 0.8483492136001587
Validation loss: 1.6885749383639264

Epoch: 6| Step: 11
Training loss: 0.5177154541015625
Validation loss: 1.681292071778287

Epoch: 6| Step: 12
Training loss: 0.6865695714950562
Validation loss: 1.7185132785509991

Epoch: 6| Step: 13
Training loss: 0.8780122995376587
Validation loss: 1.7087476458600772

Epoch: 262| Step: 0
Training loss: 0.9044359922409058
Validation loss: 1.6924563800134966

Epoch: 6| Step: 1
Training loss: 0.6636391878128052
Validation loss: 1.6665887896732619

Epoch: 6| Step: 2
Training loss: 0.7617354989051819
Validation loss: 1.6381846858609108

Epoch: 6| Step: 3
Training loss: 0.7708070874214172
Validation loss: 1.6561040891114103

Epoch: 6| Step: 4
Training loss: 0.6649869680404663
Validation loss: 1.672752934117471

Epoch: 6| Step: 5
Training loss: 0.74590665102005
Validation loss: 1.6610666244260726

Epoch: 6| Step: 6
Training loss: 0.6413583755493164
Validation loss: 1.6928792768909084

Epoch: 6| Step: 7
Training loss: 0.4897712469100952
Validation loss: 1.6830772443484234

Epoch: 6| Step: 8
Training loss: 0.948505163192749
Validation loss: 1.7026453928280902

Epoch: 6| Step: 9
Training loss: 0.27144864201545715
Validation loss: 1.6895078600093882

Epoch: 6| Step: 10
Training loss: 1.066941499710083
Validation loss: 1.6944114956804501

Epoch: 6| Step: 11
Training loss: 0.6739948987960815
Validation loss: 1.6782666662687897

Epoch: 6| Step: 12
Training loss: 0.5377559065818787
Validation loss: 1.7005018431653258

Epoch: 6| Step: 13
Training loss: 0.4125947654247284
Validation loss: 1.6860320926994405

Epoch: 263| Step: 0
Training loss: 0.5651736259460449
Validation loss: 1.7213277637317617

Epoch: 6| Step: 1
Training loss: 0.647363007068634
Validation loss: 1.7062251106385262

Epoch: 6| Step: 2
Training loss: 0.7000351548194885
Validation loss: 1.6810127048082248

Epoch: 6| Step: 3
Training loss: 0.3371676504611969
Validation loss: 1.644343239004894

Epoch: 6| Step: 4
Training loss: 0.7786745429039001
Validation loss: 1.6454036889537689

Epoch: 6| Step: 5
Training loss: 0.9988523125648499
Validation loss: 1.6527712383577902

Epoch: 6| Step: 6
Training loss: 0.2930057644844055
Validation loss: 1.6793668026565223

Epoch: 6| Step: 7
Training loss: 0.6986163854598999
Validation loss: 1.662266840216934

Epoch: 6| Step: 8
Training loss: 0.8064473271369934
Validation loss: 1.6346580264388875

Epoch: 6| Step: 9
Training loss: 0.8640404939651489
Validation loss: 1.6675836629765008

Epoch: 6| Step: 10
Training loss: 0.8320069313049316
Validation loss: 1.6971597171598864

Epoch: 6| Step: 11
Training loss: 0.5850218534469604
Validation loss: 1.6838003153442054

Epoch: 6| Step: 12
Training loss: 0.7285239100456238
Validation loss: 1.6785356972807197

Epoch: 6| Step: 13
Training loss: 0.4100461006164551
Validation loss: 1.7210709600038425

Epoch: 264| Step: 0
Training loss: 0.707944393157959
Validation loss: 1.723146310416601

Epoch: 6| Step: 1
Training loss: 0.4850361943244934
Validation loss: 1.7588824072191793

Epoch: 6| Step: 2
Training loss: 0.39842236042022705
Validation loss: 1.7590694196762577

Epoch: 6| Step: 3
Training loss: 0.8248391151428223
Validation loss: 1.7388008691931283

Epoch: 6| Step: 4
Training loss: 0.8448135256767273
Validation loss: 1.7152886723959317

Epoch: 6| Step: 5
Training loss: 1.0003440380096436
Validation loss: 1.7143540151657597

Epoch: 6| Step: 6
Training loss: 0.7347511053085327
Validation loss: 1.707054821393823

Epoch: 6| Step: 7
Training loss: 0.8412756323814392
Validation loss: 1.707450419343928

Epoch: 6| Step: 8
Training loss: 0.6894199848175049
Validation loss: 1.6958985713220411

Epoch: 6| Step: 9
Training loss: 0.46629536151885986
Validation loss: 1.694624311180525

Epoch: 6| Step: 10
Training loss: 0.5238049030303955
Validation loss: 1.6788332487947197

Epoch: 6| Step: 11
Training loss: 0.4409710466861725
Validation loss: 1.6885120881501066

Epoch: 6| Step: 12
Training loss: 0.6186553239822388
Validation loss: 1.6910772464608634

Epoch: 6| Step: 13
Training loss: 0.6018669605255127
Validation loss: 1.7115926870735743

Epoch: 265| Step: 0
Training loss: 0.5830594301223755
Validation loss: 1.71595666357266

Epoch: 6| Step: 1
Training loss: 0.5024386644363403
Validation loss: 1.694226400826567

Epoch: 6| Step: 2
Training loss: 0.9727849364280701
Validation loss: 1.707634308004892

Epoch: 6| Step: 3
Training loss: 0.708638608455658
Validation loss: 1.7023486283517653

Epoch: 6| Step: 4
Training loss: 0.5793427228927612
Validation loss: 1.7125338995328514

Epoch: 6| Step: 5
Training loss: 0.6215192079544067
Validation loss: 1.7313135452167963

Epoch: 6| Step: 6
Training loss: 0.41224950551986694
Validation loss: 1.7355397285953644

Epoch: 6| Step: 7
Training loss: 0.8074405789375305
Validation loss: 1.719491543308381

Epoch: 6| Step: 8
Training loss: 0.6829900145530701
Validation loss: 1.7233416572693856

Epoch: 6| Step: 9
Training loss: 0.8206835985183716
Validation loss: 1.726884203572427

Epoch: 6| Step: 10
Training loss: 0.5785977840423584
Validation loss: 1.6962113726523615

Epoch: 6| Step: 11
Training loss: 0.35967886447906494
Validation loss: 1.7069873335540935

Epoch: 6| Step: 12
Training loss: 0.7057012915611267
Validation loss: 1.7321533105706657

Epoch: 6| Step: 13
Training loss: 0.7919629812240601
Validation loss: 1.725462741749261

Epoch: 266| Step: 0
Training loss: 0.6371917128562927
Validation loss: 1.7246506970415834

Epoch: 6| Step: 1
Training loss: 0.6806182265281677
Validation loss: 1.7231158543658514

Epoch: 6| Step: 2
Training loss: 0.5427677035331726
Validation loss: 1.6956438428612166

Epoch: 6| Step: 3
Training loss: 0.507429838180542
Validation loss: 1.7014558071731238

Epoch: 6| Step: 4
Training loss: 0.4527696967124939
Validation loss: 1.7334483003103605

Epoch: 6| Step: 5
Training loss: 0.6686196327209473
Validation loss: 1.7306010274476902

Epoch: 6| Step: 6
Training loss: 0.7362161874771118
Validation loss: 1.7476654629553519

Epoch: 6| Step: 7
Training loss: 0.5240375995635986
Validation loss: 1.7479680853505288

Epoch: 6| Step: 8
Training loss: 0.9328094720840454
Validation loss: 1.712861289260208

Epoch: 6| Step: 9
Training loss: 0.730353593826294
Validation loss: 1.710330879816445

Epoch: 6| Step: 10
Training loss: 0.6453632116317749
Validation loss: 1.6727558528223345

Epoch: 6| Step: 11
Training loss: 0.4745255708694458
Validation loss: 1.656149297632197

Epoch: 6| Step: 12
Training loss: 0.9942632913589478
Validation loss: 1.6519866835686468

Epoch: 6| Step: 13
Training loss: 0.8267134428024292
Validation loss: 1.6835018409195768

Epoch: 267| Step: 0
Training loss: 0.46799924969673157
Validation loss: 1.6662076698836459

Epoch: 6| Step: 1
Training loss: 0.4510533809661865
Validation loss: 1.6685307064364034

Epoch: 6| Step: 2
Training loss: 0.9825641512870789
Validation loss: 1.6448258699909333

Epoch: 6| Step: 3
Training loss: 0.3321564793586731
Validation loss: 1.6937923790306173

Epoch: 6| Step: 4
Training loss: 0.5910502672195435
Validation loss: 1.7249853264900945

Epoch: 6| Step: 5
Training loss: 0.6250174641609192
Validation loss: 1.7238256610849851

Epoch: 6| Step: 6
Training loss: 0.5496820211410522
Validation loss: 1.7114336106085009

Epoch: 6| Step: 7
Training loss: 0.7480476498603821
Validation loss: 1.7421290643753544

Epoch: 6| Step: 8
Training loss: 0.6880653500556946
Validation loss: 1.7239350964946132

Epoch: 6| Step: 9
Training loss: 0.9135708808898926
Validation loss: 1.6732623397663076

Epoch: 6| Step: 10
Training loss: 0.6222245693206787
Validation loss: 1.6449861244488788

Epoch: 6| Step: 11
Training loss: 0.39926984906196594
Validation loss: 1.6433434858117053

Epoch: 6| Step: 12
Training loss: 0.656764030456543
Validation loss: 1.6723084154949392

Epoch: 6| Step: 13
Training loss: 0.6658928394317627
Validation loss: 1.667191005522205

Epoch: 268| Step: 0
Training loss: 0.5173237323760986
Validation loss: 1.672275491940078

Epoch: 6| Step: 1
Training loss: 0.6106704473495483
Validation loss: 1.666880912678216

Epoch: 6| Step: 2
Training loss: 0.43720608949661255
Validation loss: 1.647427729381028

Epoch: 6| Step: 3
Training loss: 0.5899519324302673
Validation loss: 1.6639342602863108

Epoch: 6| Step: 4
Training loss: 0.6348933577537537
Validation loss: 1.684473006956039

Epoch: 6| Step: 5
Training loss: 0.8804289698600769
Validation loss: 1.7079859830999886

Epoch: 6| Step: 6
Training loss: 0.8448501825332642
Validation loss: 1.7138019787367953

Epoch: 6| Step: 7
Training loss: 0.8143891096115112
Validation loss: 1.7159081928191646

Epoch: 6| Step: 8
Training loss: 0.8256368637084961
Validation loss: 1.7166473480962938

Epoch: 6| Step: 9
Training loss: 1.074162244796753
Validation loss: 1.714933471013141

Epoch: 6| Step: 10
Training loss: 0.5368442535400391
Validation loss: 1.7064529695818502

Epoch: 6| Step: 11
Training loss: 0.39459699392318726
Validation loss: 1.7299945303188857

Epoch: 6| Step: 12
Training loss: 0.3870096206665039
Validation loss: 1.7143708236755864

Epoch: 6| Step: 13
Training loss: 0.3480469286441803
Validation loss: 1.704935049497953

Epoch: 269| Step: 0
Training loss: 0.606634259223938
Validation loss: 1.7352962429805467

Epoch: 6| Step: 1
Training loss: 0.530093252658844
Validation loss: 1.7108648259152648

Epoch: 6| Step: 2
Training loss: 0.8533164262771606
Validation loss: 1.710864367023591

Epoch: 6| Step: 3
Training loss: 0.681416928768158
Validation loss: 1.7141990097620154

Epoch: 6| Step: 4
Training loss: 0.8032885193824768
Validation loss: 1.7292382819678194

Epoch: 6| Step: 5
Training loss: 0.9239280819892883
Validation loss: 1.7241929192696848

Epoch: 6| Step: 6
Training loss: 0.5761339068412781
Validation loss: 1.737137927803942

Epoch: 6| Step: 7
Training loss: 0.4383380711078644
Validation loss: 1.722671261397741

Epoch: 6| Step: 8
Training loss: 0.631182074546814
Validation loss: 1.7766369388949486

Epoch: 6| Step: 9
Training loss: 0.6090070605278015
Validation loss: 1.7514043866947133

Epoch: 6| Step: 10
Training loss: 0.4333007335662842
Validation loss: 1.7578562626274683

Epoch: 6| Step: 11
Training loss: 0.6244251132011414
Validation loss: 1.75331409259509

Epoch: 6| Step: 12
Training loss: 0.620850145816803
Validation loss: 1.7602210224315684

Epoch: 6| Step: 13
Training loss: 0.49786219000816345
Validation loss: 1.7187502307276572

Epoch: 270| Step: 0
Training loss: 0.7955063581466675
Validation loss: 1.719367145210184

Epoch: 6| Step: 1
Training loss: 0.3354331851005554
Validation loss: 1.739141256578507

Epoch: 6| Step: 2
Training loss: 0.6709380745887756
Validation loss: 1.7269356801945677

Epoch: 6| Step: 3
Training loss: 0.46775856614112854
Validation loss: 1.7130749840890207

Epoch: 6| Step: 4
Training loss: 0.9828139543533325
Validation loss: 1.7287935121085054

Epoch: 6| Step: 5
Training loss: 0.6874526739120483
Validation loss: 1.7159675680181032

Epoch: 6| Step: 6
Training loss: 0.6303892135620117
Validation loss: 1.7158386848306144

Epoch: 6| Step: 7
Training loss: 0.9103140830993652
Validation loss: 1.66516496545525

Epoch: 6| Step: 8
Training loss: 0.30475813150405884
Validation loss: 1.6671808868326166

Epoch: 6| Step: 9
Training loss: 0.3050852417945862
Validation loss: 1.6893447355557514

Epoch: 6| Step: 10
Training loss: 0.6422386169433594
Validation loss: 1.7291102896454513

Epoch: 6| Step: 11
Training loss: 0.7231214642524719
Validation loss: 1.6910529431476389

Epoch: 6| Step: 12
Training loss: 0.8986993432044983
Validation loss: 1.689024971377465

Epoch: 6| Step: 13
Training loss: 0.269441157579422
Validation loss: 1.704546409268533

Epoch: 271| Step: 0
Training loss: 0.5471504926681519
Validation loss: 1.7176174374036892

Epoch: 6| Step: 1
Training loss: 0.5384250283241272
Validation loss: 1.7073233819776965

Epoch: 6| Step: 2
Training loss: 0.5839561223983765
Validation loss: 1.7313837197519117

Epoch: 6| Step: 3
Training loss: 0.5423460602760315
Validation loss: 1.6728062347699237

Epoch: 6| Step: 4
Training loss: 1.0291193723678589
Validation loss: 1.700183513343975

Epoch: 6| Step: 5
Training loss: 0.4309941232204437
Validation loss: 1.7005791817941973

Epoch: 6| Step: 6
Training loss: 0.7253743410110474
Validation loss: 1.6739514771328177

Epoch: 6| Step: 7
Training loss: 0.5593593120574951
Validation loss: 1.6363590071278233

Epoch: 6| Step: 8
Training loss: 0.5066385865211487
Validation loss: 1.6655883571153045

Epoch: 6| Step: 9
Training loss: 0.5776634812355042
Validation loss: 1.6745389815299743

Epoch: 6| Step: 10
Training loss: 0.4603736400604248
Validation loss: 1.678301295926494

Epoch: 6| Step: 11
Training loss: 0.6673717498779297
Validation loss: 1.6512208754016506

Epoch: 6| Step: 12
Training loss: 0.450945645570755
Validation loss: 1.663559603434737

Epoch: 6| Step: 13
Training loss: 1.0260227918624878
Validation loss: 1.660938488539829

Epoch: 272| Step: 0
Training loss: 0.9061017632484436
Validation loss: 1.66675325106549

Epoch: 6| Step: 1
Training loss: 0.6442224383354187
Validation loss: 1.6564609184060046

Epoch: 6| Step: 2
Training loss: 0.7478345036506653
Validation loss: 1.6923901804031865

Epoch: 6| Step: 3
Training loss: 0.4679282307624817
Validation loss: 1.6906917659185265

Epoch: 6| Step: 4
Training loss: 0.5228744745254517
Validation loss: 1.725558598836263

Epoch: 6| Step: 5
Training loss: 0.6052160859107971
Validation loss: 1.7387980825157576

Epoch: 6| Step: 6
Training loss: 0.8180105686187744
Validation loss: 1.712930146084037

Epoch: 6| Step: 7
Training loss: 0.39151614904403687
Validation loss: 1.6887578387414255

Epoch: 6| Step: 8
Training loss: 0.49586936831474304
Validation loss: 1.7020122146093717

Epoch: 6| Step: 9
Training loss: 0.4162409007549286
Validation loss: 1.7001408710274646

Epoch: 6| Step: 10
Training loss: 0.7350099086761475
Validation loss: 1.6891190134068972

Epoch: 6| Step: 11
Training loss: 0.41636916995048523
Validation loss: 1.6779018550790765

Epoch: 6| Step: 12
Training loss: 0.9177910089492798
Validation loss: 1.67483889672064

Epoch: 6| Step: 13
Training loss: 0.49150434136390686
Validation loss: 1.677106095898536

Epoch: 273| Step: 0
Training loss: 0.8865965008735657
Validation loss: 1.663258538451246

Epoch: 6| Step: 1
Training loss: 0.4041358530521393
Validation loss: 1.6685831469874228

Epoch: 6| Step: 2
Training loss: 0.5042738318443298
Validation loss: 1.6886764790422173

Epoch: 6| Step: 3
Training loss: 0.5575509667396545
Validation loss: 1.6912684543158418

Epoch: 6| Step: 4
Training loss: 0.7401785850524902
Validation loss: 1.6853148501406434

Epoch: 6| Step: 5
Training loss: 0.3671155571937561
Validation loss: 1.643243681999945

Epoch: 6| Step: 6
Training loss: 0.6713778972625732
Validation loss: 1.7048646942261727

Epoch: 6| Step: 7
Training loss: 0.8313796520233154
Validation loss: 1.705226534156389

Epoch: 6| Step: 8
Training loss: 0.6140422821044922
Validation loss: 1.7117214638699767

Epoch: 6| Step: 9
Training loss: 0.42927783727645874
Validation loss: 1.7334318199465353

Epoch: 6| Step: 10
Training loss: 0.42642340064048767
Validation loss: 1.7241933063794208

Epoch: 6| Step: 11
Training loss: 0.8451732397079468
Validation loss: 1.7080779588350685

Epoch: 6| Step: 12
Training loss: 0.45643681287765503
Validation loss: 1.6889294937092771

Epoch: 6| Step: 13
Training loss: 0.28619998693466187
Validation loss: 1.710663116106423

Epoch: 274| Step: 0
Training loss: 0.9764736890792847
Validation loss: 1.696189203569966

Epoch: 6| Step: 1
Training loss: 0.5887969136238098
Validation loss: 1.6972356637318928

Epoch: 6| Step: 2
Training loss: 0.6796904802322388
Validation loss: 1.708881555065032

Epoch: 6| Step: 3
Training loss: 0.5712684988975525
Validation loss: 1.7462307612101238

Epoch: 6| Step: 4
Training loss: 0.4834442138671875
Validation loss: 1.7071270686323925

Epoch: 6| Step: 5
Training loss: 0.6344980001449585
Validation loss: 1.738891363143921

Epoch: 6| Step: 6
Training loss: 1.0012216567993164
Validation loss: 1.7289029449544928

Epoch: 6| Step: 7
Training loss: 0.6223518252372742
Validation loss: 1.7083783047173613

Epoch: 6| Step: 8
Training loss: 0.402621865272522
Validation loss: 1.6701470369933753

Epoch: 6| Step: 9
Training loss: 0.38608431816101074
Validation loss: 1.6663945772314583

Epoch: 6| Step: 10
Training loss: 0.3687257766723633
Validation loss: 1.6811928684993456

Epoch: 6| Step: 11
Training loss: 0.24433153867721558
Validation loss: 1.6815204774179766

Epoch: 6| Step: 12
Training loss: 0.1713670790195465
Validation loss: 1.6948392750114523

Epoch: 6| Step: 13
Training loss: 0.7441015839576721
Validation loss: 1.7399459615830453

Epoch: 275| Step: 0
Training loss: 0.6623880863189697
Validation loss: 1.7631796188251947

Epoch: 6| Step: 1
Training loss: 0.2054634839296341
Validation loss: 1.7705234865988455

Epoch: 6| Step: 2
Training loss: 0.3928075432777405
Validation loss: 1.7652273742101525

Epoch: 6| Step: 3
Training loss: 0.5225690007209778
Validation loss: 1.7558106530097224

Epoch: 6| Step: 4
Training loss: 0.5152679681777954
Validation loss: 1.7601031193169214

Epoch: 6| Step: 5
Training loss: 0.536340057849884
Validation loss: 1.780003386159097

Epoch: 6| Step: 6
Training loss: 0.6086457967758179
Validation loss: 1.754106165260397

Epoch: 6| Step: 7
Training loss: 0.41859257221221924
Validation loss: 1.710006977922173

Epoch: 6| Step: 8
Training loss: 0.7597441673278809
Validation loss: 1.736865653786608

Epoch: 6| Step: 9
Training loss: 0.3940359950065613
Validation loss: 1.7140859032189975

Epoch: 6| Step: 10
Training loss: 0.7500247955322266
Validation loss: 1.6980485429045975

Epoch: 6| Step: 11
Training loss: 0.8243821859359741
Validation loss: 1.686375561580863

Epoch: 6| Step: 12
Training loss: 0.7353132963180542
Validation loss: 1.6617414541141962

Epoch: 6| Step: 13
Training loss: 0.7574841380119324
Validation loss: 1.6381395388674993

Epoch: 276| Step: 0
Training loss: 0.3960588872432709
Validation loss: 1.6231655895069081

Epoch: 6| Step: 1
Training loss: 0.8123162388801575
Validation loss: 1.6339643168193039

Epoch: 6| Step: 2
Training loss: 0.5462116003036499
Validation loss: 1.6309192219088156

Epoch: 6| Step: 3
Training loss: 0.8238775730133057
Validation loss: 1.641699456399487

Epoch: 6| Step: 4
Training loss: 0.43098902702331543
Validation loss: 1.6825572342000983

Epoch: 6| Step: 5
Training loss: 0.6411635875701904
Validation loss: 1.67936312255039

Epoch: 6| Step: 6
Training loss: 0.5889337658882141
Validation loss: 1.7022344322614773

Epoch: 6| Step: 7
Training loss: 0.3774193823337555
Validation loss: 1.7253144800022084

Epoch: 6| Step: 8
Training loss: 0.6326490640640259
Validation loss: 1.7301315992109236

Epoch: 6| Step: 9
Training loss: 0.6993736028671265
Validation loss: 1.7431585327271493

Epoch: 6| Step: 10
Training loss: 0.471943736076355
Validation loss: 1.790229969127204

Epoch: 6| Step: 11
Training loss: 0.5901827216148376
Validation loss: 1.7832401567889797

Epoch: 6| Step: 12
Training loss: 0.676312267780304
Validation loss: 1.7788320305526897

Epoch: 6| Step: 13
Training loss: 0.843194305896759
Validation loss: 1.8024208558503019

Epoch: 277| Step: 0
Training loss: 0.21172630786895752
Validation loss: 1.7896913674569899

Epoch: 6| Step: 1
Training loss: 0.6886767148971558
Validation loss: 1.7566211902967064

Epoch: 6| Step: 2
Training loss: 0.6043927669525146
Validation loss: 1.7336497563187794

Epoch: 6| Step: 3
Training loss: 0.5182052850723267
Validation loss: 1.6980161205414803

Epoch: 6| Step: 4
Training loss: 0.7385768890380859
Validation loss: 1.6824441084297754

Epoch: 6| Step: 5
Training loss: 0.5558397769927979
Validation loss: 1.653146901438313

Epoch: 6| Step: 6
Training loss: 0.48475077748298645
Validation loss: 1.6430248496352986

Epoch: 6| Step: 7
Training loss: 0.6639404296875
Validation loss: 1.6697768370310466

Epoch: 6| Step: 8
Training loss: 0.3770909905433655
Validation loss: 1.6573360081641906

Epoch: 6| Step: 9
Training loss: 0.8381989002227783
Validation loss: 1.6857426820262786

Epoch: 6| Step: 10
Training loss: 0.8857566118240356
Validation loss: 1.6781921399536954

Epoch: 6| Step: 11
Training loss: 0.20977512001991272
Validation loss: 1.6696232967479254

Epoch: 6| Step: 12
Training loss: 0.8669039011001587
Validation loss: 1.6914068761692251

Epoch: 6| Step: 13
Training loss: 0.2936493158340454
Validation loss: 1.7159474895846458

Epoch: 278| Step: 0
Training loss: 0.7348041534423828
Validation loss: 1.6956666310628254

Epoch: 6| Step: 1
Training loss: 0.7956335544586182
Validation loss: 1.7104061624055267

Epoch: 6| Step: 2
Training loss: 0.7161718010902405
Validation loss: 1.724731287648601

Epoch: 6| Step: 3
Training loss: 0.5944008827209473
Validation loss: 1.7114015843278618

Epoch: 6| Step: 4
Training loss: 0.361020565032959
Validation loss: 1.7167062874763244

Epoch: 6| Step: 5
Training loss: 0.5555337071418762
Validation loss: 1.728622640332868

Epoch: 6| Step: 6
Training loss: 0.5458426475524902
Validation loss: 1.7022447124604256

Epoch: 6| Step: 7
Training loss: 0.43091484904289246
Validation loss: 1.7270288851953322

Epoch: 6| Step: 8
Training loss: 0.4147455096244812
Validation loss: 1.6912832708768948

Epoch: 6| Step: 9
Training loss: 0.5754870176315308
Validation loss: 1.7344608640158048

Epoch: 6| Step: 10
Training loss: 0.621200442314148
Validation loss: 1.7248514006214757

Epoch: 6| Step: 11
Training loss: 1.1531902551651
Validation loss: 1.6929365550318072

Epoch: 6| Step: 12
Training loss: 0.561107873916626
Validation loss: 1.6821704474828576

Epoch: 6| Step: 13
Training loss: 0.8292567729949951
Validation loss: 1.6813030063465078

Epoch: 279| Step: 0
Training loss: 0.9394357204437256
Validation loss: 1.684059081539031

Epoch: 6| Step: 1
Training loss: 0.4540122151374817
Validation loss: 1.642951109076059

Epoch: 6| Step: 2
Training loss: 0.5790266990661621
Validation loss: 1.6637527327383719

Epoch: 6| Step: 3
Training loss: 0.5166047811508179
Validation loss: 1.6434235752269786

Epoch: 6| Step: 4
Training loss: 0.5511857271194458
Validation loss: 1.6838827658725042

Epoch: 6| Step: 5
Training loss: 0.5480453968048096
Validation loss: 1.6986209897584812

Epoch: 6| Step: 6
Training loss: 0.3627873361110687
Validation loss: 1.6797941628322806

Epoch: 6| Step: 7
Training loss: 0.7256778478622437
Validation loss: 1.6668705235245407

Epoch: 6| Step: 8
Training loss: 0.7046883702278137
Validation loss: 1.6297633750464326

Epoch: 6| Step: 9
Training loss: 0.934821605682373
Validation loss: 1.6474660814449351

Epoch: 6| Step: 10
Training loss: 0.4346523582935333
Validation loss: 1.6476398321890062

Epoch: 6| Step: 11
Training loss: 0.3747875690460205
Validation loss: 1.670583390420483

Epoch: 6| Step: 12
Training loss: 0.717212438583374
Validation loss: 1.6844405871565624

Epoch: 6| Step: 13
Training loss: 0.5253685116767883
Validation loss: 1.675334313864349

Epoch: 280| Step: 0
Training loss: 0.7965813875198364
Validation loss: 1.6929521214577459

Epoch: 6| Step: 1
Training loss: 0.6741890907287598
Validation loss: 1.6636944881049536

Epoch: 6| Step: 2
Training loss: 0.6233282089233398
Validation loss: 1.6740527281197168

Epoch: 6| Step: 3
Training loss: 0.7502384185791016
Validation loss: 1.7298361127094557

Epoch: 6| Step: 4
Training loss: 0.516492486000061
Validation loss: 1.7199755701967465

Epoch: 6| Step: 5
Training loss: 0.535900354385376
Validation loss: 1.7488926546548003

Epoch: 6| Step: 6
Training loss: 0.2935107946395874
Validation loss: 1.733554591414749

Epoch: 6| Step: 7
Training loss: 0.42930442094802856
Validation loss: 1.723757759217293

Epoch: 6| Step: 8
Training loss: 0.5854578018188477
Validation loss: 1.7113882469874557

Epoch: 6| Step: 9
Training loss: 0.40213221311569214
Validation loss: 1.7021362999434113

Epoch: 6| Step: 10
Training loss: 0.8136710524559021
Validation loss: 1.697999818350679

Epoch: 6| Step: 11
Training loss: 0.6843105554580688
Validation loss: 1.7224621144674157

Epoch: 6| Step: 12
Training loss: 0.686254620552063
Validation loss: 1.7159375067680114

Epoch: 6| Step: 13
Training loss: 0.5088151097297668
Validation loss: 1.7152552258583806

Epoch: 281| Step: 0
Training loss: 0.4328725039958954
Validation loss: 1.716070117488984

Epoch: 6| Step: 1
Training loss: 0.46424275636672974
Validation loss: 1.6999929028172647

Epoch: 6| Step: 2
Training loss: 0.5269028544425964
Validation loss: 1.7366394983824862

Epoch: 6| Step: 3
Training loss: 0.5036194324493408
Validation loss: 1.7571772965051795

Epoch: 6| Step: 4
Training loss: 0.6353281140327454
Validation loss: 1.7463943163553874

Epoch: 6| Step: 5
Training loss: 0.5169360637664795
Validation loss: 1.7445960493497952

Epoch: 6| Step: 6
Training loss: 0.5243549346923828
Validation loss: 1.7293669331458308

Epoch: 6| Step: 7
Training loss: 0.5464845895767212
Validation loss: 1.7009694435263192

Epoch: 6| Step: 8
Training loss: 0.48659834265708923
Validation loss: 1.701465488761984

Epoch: 6| Step: 9
Training loss: 0.5018032193183899
Validation loss: 1.6471480643877419

Epoch: 6| Step: 10
Training loss: 0.7290939092636108
Validation loss: 1.6675308289066437

Epoch: 6| Step: 11
Training loss: 0.8713127970695496
Validation loss: 1.6857973747355963

Epoch: 6| Step: 12
Training loss: 0.7063236236572266
Validation loss: 1.6886847711378528

Epoch: 6| Step: 13
Training loss: 0.44903701543807983
Validation loss: 1.6978113369275165

Epoch: 282| Step: 0
Training loss: 0.47116953134536743
Validation loss: 1.6433359807537449

Epoch: 6| Step: 1
Training loss: 0.5811944007873535
Validation loss: 1.6771208983595653

Epoch: 6| Step: 2
Training loss: 0.47541484236717224
Validation loss: 1.642041007677714

Epoch: 6| Step: 3
Training loss: 0.5568076372146606
Validation loss: 1.6671870985338766

Epoch: 6| Step: 4
Training loss: 0.3189176321029663
Validation loss: 1.6564409630272978

Epoch: 6| Step: 5
Training loss: 0.3536146581172943
Validation loss: 1.666073638905761

Epoch: 6| Step: 6
Training loss: 0.680841863155365
Validation loss: 1.668125298715407

Epoch: 6| Step: 7
Training loss: 0.8779680728912354
Validation loss: 1.7330179727205666

Epoch: 6| Step: 8
Training loss: 0.49302399158477783
Validation loss: 1.7218725501850087

Epoch: 6| Step: 9
Training loss: 0.7348109483718872
Validation loss: 1.7152799226904427

Epoch: 6| Step: 10
Training loss: 0.5621426105499268
Validation loss: 1.7103919803455312

Epoch: 6| Step: 11
Training loss: 0.6121888756752014
Validation loss: 1.7017665268272482

Epoch: 6| Step: 12
Training loss: 0.5904091596603394
Validation loss: 1.722123461384927

Epoch: 6| Step: 13
Training loss: 0.3507155179977417
Validation loss: 1.7107063865148893

Epoch: 283| Step: 0
Training loss: 0.8530510663986206
Validation loss: 1.6941778698275167

Epoch: 6| Step: 1
Training loss: 0.5830587148666382
Validation loss: 1.7001716218968874

Epoch: 6| Step: 2
Training loss: 0.494113564491272
Validation loss: 1.7023855383678148

Epoch: 6| Step: 3
Training loss: 0.5363306403160095
Validation loss: 1.6641670414196548

Epoch: 6| Step: 4
Training loss: 0.24473245441913605
Validation loss: 1.6546481424762356

Epoch: 6| Step: 5
Training loss: 0.7253723740577698
Validation loss: 1.6289456608474895

Epoch: 6| Step: 6
Training loss: 0.37547558546066284
Validation loss: 1.6188404970271613

Epoch: 6| Step: 7
Training loss: 0.674635648727417
Validation loss: 1.6422419945398967

Epoch: 6| Step: 8
Training loss: 0.426037073135376
Validation loss: 1.6665608382994128

Epoch: 6| Step: 9
Training loss: 0.44990819692611694
Validation loss: 1.6714197666414323

Epoch: 6| Step: 10
Training loss: 0.4168630838394165
Validation loss: 1.6574399496919365

Epoch: 6| Step: 11
Training loss: 0.7663936018943787
Validation loss: 1.6883522989929363

Epoch: 6| Step: 12
Training loss: 0.34397751092910767
Validation loss: 1.6681802606069913

Epoch: 6| Step: 13
Training loss: 0.3284543454647064
Validation loss: 1.7262792664189492

Epoch: 284| Step: 0
Training loss: 0.6188644766807556
Validation loss: 1.6947139155480169

Epoch: 6| Step: 1
Training loss: 0.5881239175796509
Validation loss: 1.6942446783024778

Epoch: 6| Step: 2
Training loss: 0.3602833151817322
Validation loss: 1.7192082405090332

Epoch: 6| Step: 3
Training loss: 0.7316316366195679
Validation loss: 1.7189535992119902

Epoch: 6| Step: 4
Training loss: 0.31578442454338074
Validation loss: 1.7156854521843694

Epoch: 6| Step: 5
Training loss: 0.32677558064460754
Validation loss: 1.7449814004282798

Epoch: 6| Step: 6
Training loss: 0.4299164414405823
Validation loss: 1.725690314846654

Epoch: 6| Step: 7
Training loss: 0.45299965143203735
Validation loss: 1.730265789134528

Epoch: 6| Step: 8
Training loss: 0.41782891750335693
Validation loss: 1.7334624836521764

Epoch: 6| Step: 9
Training loss: 0.6010484099388123
Validation loss: 1.6934885888971307

Epoch: 6| Step: 10
Training loss: 0.5605606436729431
Validation loss: 1.7179428492822955

Epoch: 6| Step: 11
Training loss: 0.5737390518188477
Validation loss: 1.7047700856321601

Epoch: 6| Step: 12
Training loss: 0.7690057754516602
Validation loss: 1.7017441475263206

Epoch: 6| Step: 13
Training loss: 0.3143909275531769
Validation loss: 1.6676703217209026

Epoch: 285| Step: 0
Training loss: 0.449917733669281
Validation loss: 1.6376317290849582

Epoch: 6| Step: 1
Training loss: 0.2436237335205078
Validation loss: 1.6955845176532705

Epoch: 6| Step: 2
Training loss: 0.3506152629852295
Validation loss: 1.6595113123616865

Epoch: 6| Step: 3
Training loss: 0.5643585324287415
Validation loss: 1.6608639250519455

Epoch: 6| Step: 4
Training loss: 0.48855075240135193
Validation loss: 1.6677405577833935

Epoch: 6| Step: 5
Training loss: 0.6531175971031189
Validation loss: 1.7082101991099696

Epoch: 6| Step: 6
Training loss: 0.4612075090408325
Validation loss: 1.7141886218901603

Epoch: 6| Step: 7
Training loss: 0.5607108473777771
Validation loss: 1.7022637962013163

Epoch: 6| Step: 8
Training loss: 0.3698405623435974
Validation loss: 1.7546315321358301

Epoch: 6| Step: 9
Training loss: 0.5475583076477051
Validation loss: 1.7362551791693575

Epoch: 6| Step: 10
Training loss: 0.5350767970085144
Validation loss: 1.72109511334409

Epoch: 6| Step: 11
Training loss: 0.3847459554672241
Validation loss: 1.6902965409781343

Epoch: 6| Step: 12
Training loss: 0.7874282002449036
Validation loss: 1.6642273420928626

Epoch: 6| Step: 13
Training loss: 0.5287522077560425
Validation loss: 1.6595446483422351

Epoch: 286| Step: 0
Training loss: 0.6828413605690002
Validation loss: 1.6689201426762406

Epoch: 6| Step: 1
Training loss: 0.3805520832538605
Validation loss: 1.652189734161541

Epoch: 6| Step: 2
Training loss: 0.36479490995407104
Validation loss: 1.6499662655656055

Epoch: 6| Step: 3
Training loss: 0.7389897108078003
Validation loss: 1.6209780029071275

Epoch: 6| Step: 4
Training loss: 0.16480191051959991
Validation loss: 1.6405356276419856

Epoch: 6| Step: 5
Training loss: 0.4542214870452881
Validation loss: 1.6554122176221622

Epoch: 6| Step: 6
Training loss: 0.3728330731391907
Validation loss: 1.6579623914534045

Epoch: 6| Step: 7
Training loss: 0.5624215602874756
Validation loss: 1.6562180288376347

Epoch: 6| Step: 8
Training loss: 0.677463173866272
Validation loss: 1.663730118864326

Epoch: 6| Step: 9
Training loss: 0.7058933973312378
Validation loss: 1.7109508309313046

Epoch: 6| Step: 10
Training loss: 0.6043589115142822
Validation loss: 1.7084330281903666

Epoch: 6| Step: 11
Training loss: 0.41504836082458496
Validation loss: 1.7319924087934597

Epoch: 6| Step: 12
Training loss: 0.7631210088729858
Validation loss: 1.6979352658794773

Epoch: 6| Step: 13
Training loss: 0.7091147303581238
Validation loss: 1.6469455457502795

Epoch: 287| Step: 0
Training loss: 0.24377970397472382
Validation loss: 1.6663795158427248

Epoch: 6| Step: 1
Training loss: 0.2839471995830536
Validation loss: 1.6551143943622548

Epoch: 6| Step: 2
Training loss: 0.6725935935974121
Validation loss: 1.6549149354298909

Epoch: 6| Step: 3
Training loss: 0.5300900340080261
Validation loss: 1.629537231819604

Epoch: 6| Step: 4
Training loss: 0.6307557225227356
Validation loss: 1.6549989331153132

Epoch: 6| Step: 5
Training loss: 0.6721903085708618
Validation loss: 1.652673670040664

Epoch: 6| Step: 6
Training loss: 0.5125019550323486
Validation loss: 1.6546040568300473

Epoch: 6| Step: 7
Training loss: 0.42866161465644836
Validation loss: 1.7035601959433606

Epoch: 6| Step: 8
Training loss: 0.6046350002288818
Validation loss: 1.7803569673210062

Epoch: 6| Step: 9
Training loss: 0.5513200759887695
Validation loss: 1.8202048091478245

Epoch: 6| Step: 10
Training loss: 0.6665371656417847
Validation loss: 1.8832763587274859

Epoch: 6| Step: 11
Training loss: 0.868553102016449
Validation loss: 1.8517239004053094

Epoch: 6| Step: 12
Training loss: 0.5278594493865967
Validation loss: 1.827727529310411

Epoch: 6| Step: 13
Training loss: 0.36033669114112854
Validation loss: 1.776948505832303

Epoch: 288| Step: 0
Training loss: 0.619317889213562
Validation loss: 1.7738457290075158

Epoch: 6| Step: 1
Training loss: 0.5457950234413147
Validation loss: 1.7623351389361965

Epoch: 6| Step: 2
Training loss: 0.6474617719650269
Validation loss: 1.7271255908473846

Epoch: 6| Step: 3
Training loss: 0.41858047246932983
Validation loss: 1.7341954362007879

Epoch: 6| Step: 4
Training loss: 0.5741106271743774
Validation loss: 1.7187698451421594

Epoch: 6| Step: 5
Training loss: 0.2432611733675003
Validation loss: 1.6724531695406923

Epoch: 6| Step: 6
Training loss: 0.5148564577102661
Validation loss: 1.6891011602135115

Epoch: 6| Step: 7
Training loss: 0.524709939956665
Validation loss: 1.651006603753695

Epoch: 6| Step: 8
Training loss: 0.41510987281799316
Validation loss: 1.635234793027242

Epoch: 6| Step: 9
Training loss: 0.29629355669021606
Validation loss: 1.6751388901023454

Epoch: 6| Step: 10
Training loss: 0.5907496809959412
Validation loss: 1.6544738149130216

Epoch: 6| Step: 11
Training loss: 0.7277157306671143
Validation loss: 1.6593858324071413

Epoch: 6| Step: 12
Training loss: 0.4995523989200592
Validation loss: 1.6730489077106598

Epoch: 6| Step: 13
Training loss: 0.5154144763946533
Validation loss: 1.6803706583156381

Epoch: 289| Step: 0
Training loss: 0.6335470676422119
Validation loss: 1.6596881958746141

Epoch: 6| Step: 1
Training loss: 0.8064320087432861
Validation loss: 1.679761532814272

Epoch: 6| Step: 2
Training loss: 0.5382883548736572
Validation loss: 1.713607003611903

Epoch: 6| Step: 3
Training loss: 0.6845278739929199
Validation loss: 1.7341124447443153

Epoch: 6| Step: 4
Training loss: 0.6064872741699219
Validation loss: 1.7447786228631132

Epoch: 6| Step: 5
Training loss: 0.5442467331886292
Validation loss: 1.7171385365147744

Epoch: 6| Step: 6
Training loss: 0.4210609495639801
Validation loss: 1.7394180861852502

Epoch: 6| Step: 7
Training loss: 0.41681817173957825
Validation loss: 1.7468965989287182

Epoch: 6| Step: 8
Training loss: 0.4235014319419861
Validation loss: 1.735503735080842

Epoch: 6| Step: 9
Training loss: 0.5541267395019531
Validation loss: 1.7351329954721595

Epoch: 6| Step: 10
Training loss: 0.2595791220664978
Validation loss: 1.711314151363988

Epoch: 6| Step: 11
Training loss: 0.439908504486084
Validation loss: 1.7176415804893739

Epoch: 6| Step: 12
Training loss: 0.3216972351074219
Validation loss: 1.7222966135189097

Epoch: 6| Step: 13
Training loss: 0.264675498008728
Validation loss: 1.718479077021281

Epoch: 290| Step: 0
Training loss: 0.46585968136787415
Validation loss: 1.7488052768092002

Epoch: 6| Step: 1
Training loss: 0.3697012662887573
Validation loss: 1.7585460242404733

Epoch: 6| Step: 2
Training loss: 0.48098474740982056
Validation loss: 1.8008497081777102

Epoch: 6| Step: 3
Training loss: 0.42646753787994385
Validation loss: 1.7620243539092362

Epoch: 6| Step: 4
Training loss: 0.5979711413383484
Validation loss: 1.7567758842181134

Epoch: 6| Step: 5
Training loss: 0.5927180051803589
Validation loss: 1.73282834535004

Epoch: 6| Step: 6
Training loss: 0.348101943731308
Validation loss: 1.7201791194177443

Epoch: 6| Step: 7
Training loss: 0.3407815098762512
Validation loss: 1.7429184118906658

Epoch: 6| Step: 8
Training loss: 0.6045345664024353
Validation loss: 1.724697172000844

Epoch: 6| Step: 9
Training loss: 0.35065174102783203
Validation loss: 1.720133505841737

Epoch: 6| Step: 10
Training loss: 0.5288805961608887
Validation loss: 1.7310144734638993

Epoch: 6| Step: 11
Training loss: 0.8577698469161987
Validation loss: 1.7609600354266424

Epoch: 6| Step: 12
Training loss: 0.5728247761726379
Validation loss: 1.7433910357054843

Epoch: 6| Step: 13
Training loss: 0.5297878980636597
Validation loss: 1.7478075847830823

Epoch: 291| Step: 0
Training loss: 0.7280233502388
Validation loss: 1.7421828777559343

Epoch: 6| Step: 1
Training loss: 0.29219168424606323
Validation loss: 1.7413372583286737

Epoch: 6| Step: 2
Training loss: 0.5764936804771423
Validation loss: 1.7283163109133322

Epoch: 6| Step: 3
Training loss: 0.4216356873512268
Validation loss: 1.7336154791616625

Epoch: 6| Step: 4
Training loss: 0.6084184050559998
Validation loss: 1.737748848494663

Epoch: 6| Step: 5
Training loss: 0.4330739974975586
Validation loss: 1.7154377775807534

Epoch: 6| Step: 6
Training loss: 0.5412399768829346
Validation loss: 1.6912539069370558

Epoch: 6| Step: 7
Training loss: 0.48208022117614746
Validation loss: 1.6924253253526584

Epoch: 6| Step: 8
Training loss: 0.5975345373153687
Validation loss: 1.6917623089205833

Epoch: 6| Step: 9
Training loss: 0.4600974917411804
Validation loss: 1.7191327951287712

Epoch: 6| Step: 10
Training loss: 0.34347566962242126
Validation loss: 1.699071817500617

Epoch: 6| Step: 11
Training loss: 0.3370707631111145
Validation loss: 1.6835283451182868

Epoch: 6| Step: 12
Training loss: 0.49460723996162415
Validation loss: 1.6996252395773446

Epoch: 6| Step: 13
Training loss: 0.7830485105514526
Validation loss: 1.7163129032299083

Epoch: 292| Step: 0
Training loss: 0.535571277141571
Validation loss: 1.696116542303434

Epoch: 6| Step: 1
Training loss: 0.5653952360153198
Validation loss: 1.6857874265281103

Epoch: 6| Step: 2
Training loss: 0.5257629752159119
Validation loss: 1.6430219963032713

Epoch: 6| Step: 3
Training loss: 0.6874900460243225
Validation loss: 1.7176172374397196

Epoch: 6| Step: 4
Training loss: 0.3584383726119995
Validation loss: 1.680506484482878

Epoch: 6| Step: 5
Training loss: 0.4306691288948059
Validation loss: 1.6927236395497476

Epoch: 6| Step: 6
Training loss: 0.41456252336502075
Validation loss: 1.7128115674500823

Epoch: 6| Step: 7
Training loss: 0.8694378733634949
Validation loss: 1.7209605555380545

Epoch: 6| Step: 8
Training loss: 0.301839143037796
Validation loss: 1.6799523099776237

Epoch: 6| Step: 9
Training loss: 0.4040225148200989
Validation loss: 1.667102949593657

Epoch: 6| Step: 10
Training loss: 0.36384081840515137
Validation loss: 1.6517013029385639

Epoch: 6| Step: 11
Training loss: 0.6711325645446777
Validation loss: 1.6800069937141993

Epoch: 6| Step: 12
Training loss: 0.3448680639266968
Validation loss: 1.679695272958407

Epoch: 6| Step: 13
Training loss: 0.19802583754062653
Validation loss: 1.7172886774104128

Epoch: 293| Step: 0
Training loss: 0.5475149154663086
Validation loss: 1.754211594981532

Epoch: 6| Step: 1
Training loss: 0.6464576125144958
Validation loss: 1.796947302356843

Epoch: 6| Step: 2
Training loss: 0.4387866258621216
Validation loss: 1.781906412493798

Epoch: 6| Step: 3
Training loss: 0.46151062846183777
Validation loss: 1.7816176337580527

Epoch: 6| Step: 4
Training loss: 0.43981093168258667
Validation loss: 1.7712928223353561

Epoch: 6| Step: 5
Training loss: 0.4424683749675751
Validation loss: 1.7827454369555238

Epoch: 6| Step: 6
Training loss: 0.3949974775314331
Validation loss: 1.7788955011675436

Epoch: 6| Step: 7
Training loss: 0.5288435816764832
Validation loss: 1.7586967868189658

Epoch: 6| Step: 8
Training loss: 0.5325862765312195
Validation loss: 1.745952570310203

Epoch: 6| Step: 9
Training loss: 0.5063937902450562
Validation loss: 1.721245191430533

Epoch: 6| Step: 10
Training loss: 0.5946254730224609
Validation loss: 1.7298197618094824

Epoch: 6| Step: 11
Training loss: 0.47468817234039307
Validation loss: 1.736357528676269

Epoch: 6| Step: 12
Training loss: 0.38029617071151733
Validation loss: 1.7296494104528939

Epoch: 6| Step: 13
Training loss: 0.7043284177780151
Validation loss: 1.749837811275195

Epoch: 294| Step: 0
Training loss: 0.5672763586044312
Validation loss: 1.7409751569071124

Epoch: 6| Step: 1
Training loss: 0.5461769104003906
Validation loss: 1.7308613049086703

Epoch: 6| Step: 2
Training loss: 0.5311868190765381
Validation loss: 1.7018774837575934

Epoch: 6| Step: 3
Training loss: 0.34368062019348145
Validation loss: 1.666157869882481

Epoch: 6| Step: 4
Training loss: 0.4181067943572998
Validation loss: 1.6722838365903465

Epoch: 6| Step: 5
Training loss: 0.2820674777030945
Validation loss: 1.661665326805525

Epoch: 6| Step: 6
Training loss: 0.6719874143600464
Validation loss: 1.635658702542705

Epoch: 6| Step: 7
Training loss: 0.3888227343559265
Validation loss: 1.6444507965477564

Epoch: 6| Step: 8
Training loss: 0.6451153755187988
Validation loss: 1.6815212798374954

Epoch: 6| Step: 9
Training loss: 0.4685221314430237
Validation loss: 1.6553037525505148

Epoch: 6| Step: 10
Training loss: 0.6118523478507996
Validation loss: 1.7069888909657795

Epoch: 6| Step: 11
Training loss: 0.18613561987876892
Validation loss: 1.690580452642133

Epoch: 6| Step: 12
Training loss: 0.617233157157898
Validation loss: 1.684085892092797

Epoch: 6| Step: 13
Training loss: 0.40717098116874695
Validation loss: 1.7372805931234871

Epoch: 295| Step: 0
Training loss: 0.6162257194519043
Validation loss: 1.761000838330997

Epoch: 6| Step: 1
Training loss: 0.3620009124279022
Validation loss: 1.7367336673121299

Epoch: 6| Step: 2
Training loss: 0.5677037835121155
Validation loss: 1.6801004268789803

Epoch: 6| Step: 3
Training loss: 0.5006121397018433
Validation loss: 1.691348063048496

Epoch: 6| Step: 4
Training loss: 0.4197537302970886
Validation loss: 1.6802916129430134

Epoch: 6| Step: 5
Training loss: 0.13746780157089233
Validation loss: 1.7157693844969555

Epoch: 6| Step: 6
Training loss: 0.6018663644790649
Validation loss: 1.699990080248925

Epoch: 6| Step: 7
Training loss: 0.6117342114448547
Validation loss: 1.7050197432118077

Epoch: 6| Step: 8
Training loss: 0.3040398359298706
Validation loss: 1.6948861101622223

Epoch: 6| Step: 9
Training loss: 0.28863370418548584
Validation loss: 1.6864569110255088

Epoch: 6| Step: 10
Training loss: 0.24261201918125153
Validation loss: 1.703089456404409

Epoch: 6| Step: 11
Training loss: 0.5621045231819153
Validation loss: 1.7184956996671614

Epoch: 6| Step: 12
Training loss: 0.4216124415397644
Validation loss: 1.7247240210092196

Epoch: 6| Step: 13
Training loss: 1.0475493669509888
Validation loss: 1.736659211497153

Epoch: 296| Step: 0
Training loss: 0.5611804723739624
Validation loss: 1.6965648999778173

Epoch: 6| Step: 1
Training loss: 0.3967704772949219
Validation loss: 1.6867763098850046

Epoch: 6| Step: 2
Training loss: 0.4847361743450165
Validation loss: 1.686721770994125

Epoch: 6| Step: 3
Training loss: 0.3885684013366699
Validation loss: 1.6211342170674314

Epoch: 6| Step: 4
Training loss: 0.6037840843200684
Validation loss: 1.635272934872617

Epoch: 6| Step: 5
Training loss: 0.27624157071113586
Validation loss: 1.6352587387125979

Epoch: 6| Step: 6
Training loss: 0.38916313648223877
Validation loss: 1.66123269578462

Epoch: 6| Step: 7
Training loss: 0.5673826336860657
Validation loss: 1.639752189318339

Epoch: 6| Step: 8
Training loss: 0.2794468402862549
Validation loss: 1.6765323685061546

Epoch: 6| Step: 9
Training loss: 0.2811658978462219
Validation loss: 1.6836827467846613

Epoch: 6| Step: 10
Training loss: 0.3440258502960205
Validation loss: 1.7036436206551009

Epoch: 6| Step: 11
Training loss: 0.4588755667209625
Validation loss: 1.730358087888328

Epoch: 6| Step: 12
Training loss: 0.6215200424194336
Validation loss: 1.710607854268884

Epoch: 6| Step: 13
Training loss: 0.4656349718570709
Validation loss: 1.6886530999214417

Epoch: 297| Step: 0
Training loss: 0.3385668396949768
Validation loss: 1.6372950615421418

Epoch: 6| Step: 1
Training loss: 0.23023857176303864
Validation loss: 1.6491025865718882

Epoch: 6| Step: 2
Training loss: 0.5422492027282715
Validation loss: 1.6603567087522118

Epoch: 6| Step: 3
Training loss: 0.5359965562820435
Validation loss: 1.6476470437101138

Epoch: 6| Step: 4
Training loss: 0.23449188470840454
Validation loss: 1.645340718248839

Epoch: 6| Step: 5
Training loss: 0.45925450325012207
Validation loss: 1.6589630739663237

Epoch: 6| Step: 6
Training loss: 0.2694626748561859
Validation loss: 1.6645529065080868

Epoch: 6| Step: 7
Training loss: 0.4614216387271881
Validation loss: 1.6791099143284622

Epoch: 6| Step: 8
Training loss: 0.686288595199585
Validation loss: 1.6316633737215431

Epoch: 6| Step: 9
Training loss: 0.3593282103538513
Validation loss: 1.6799438256089405

Epoch: 6| Step: 10
Training loss: 0.24037058651447296
Validation loss: 1.6704416608297696

Epoch: 6| Step: 11
Training loss: 0.6850398778915405
Validation loss: 1.6711140037864767

Epoch: 6| Step: 12
Training loss: 0.3033817708492279
Validation loss: 1.67508912855579

Epoch: 6| Step: 13
Training loss: 0.5380853414535522
Validation loss: 1.6835183969108007

Epoch: 298| Step: 0
Training loss: 0.6205805540084839
Validation loss: 1.6896172954190163

Epoch: 6| Step: 1
Training loss: 0.3791675269603729
Validation loss: 1.678949317624492

Epoch: 6| Step: 2
Training loss: 0.28095686435699463
Validation loss: 1.6634947587085027

Epoch: 6| Step: 3
Training loss: 0.3257506489753723
Validation loss: 1.6654379521646807

Epoch: 6| Step: 4
Training loss: 0.35542887449264526
Validation loss: 1.684197824488404

Epoch: 6| Step: 5
Training loss: 0.3539508283138275
Validation loss: 1.671038709661012

Epoch: 6| Step: 6
Training loss: 0.4236190915107727
Validation loss: 1.6656001319167435

Epoch: 6| Step: 7
Training loss: 0.41664934158325195
Validation loss: 1.70624106032874

Epoch: 6| Step: 8
Training loss: 0.3973826766014099
Validation loss: 1.7041085599571146

Epoch: 6| Step: 9
Training loss: 0.36564984917640686
Validation loss: 1.7160636596782233

Epoch: 6| Step: 10
Training loss: 0.5704039335250854
Validation loss: 1.7007676657810007

Epoch: 6| Step: 11
Training loss: 0.5270912051200867
Validation loss: 1.6825826629515617

Epoch: 6| Step: 12
Training loss: 0.5190362930297852
Validation loss: 1.6793306591690227

Epoch: 6| Step: 13
Training loss: 0.4744729995727539
Validation loss: 1.6674205487774265

Epoch: 299| Step: 0
Training loss: 0.8210868239402771
Validation loss: 1.6638388620909823

Epoch: 6| Step: 1
Training loss: 0.42014941573143005
Validation loss: 1.6346026518011605

Epoch: 6| Step: 2
Training loss: 0.5402055978775024
Validation loss: 1.6359059323546707

Epoch: 6| Step: 3
Training loss: 0.26108378171920776
Validation loss: 1.651007479236972

Epoch: 6| Step: 4
Training loss: 0.45419636368751526
Validation loss: 1.671814359644408

Epoch: 6| Step: 5
Training loss: 0.1577969789505005
Validation loss: 1.6743081564544349

Epoch: 6| Step: 6
Training loss: 0.5078105926513672
Validation loss: 1.6473798380103162

Epoch: 6| Step: 7
Training loss: 0.285302072763443
Validation loss: 1.6497156530298211

Epoch: 6| Step: 8
Training loss: 0.44112831354141235
Validation loss: 1.6683294004009617

Epoch: 6| Step: 9
Training loss: 0.29497531056404114
Validation loss: 1.6542650115105413

Epoch: 6| Step: 10
Training loss: 0.4016337990760803
Validation loss: 1.6726336786823888

Epoch: 6| Step: 11
Training loss: 0.25616803765296936
Validation loss: 1.6673785486528951

Epoch: 6| Step: 12
Training loss: 0.44520458579063416
Validation loss: 1.6829878207175963

Epoch: 6| Step: 13
Training loss: 0.3404439091682434
Validation loss: 1.6872386522190546

Epoch: 300| Step: 0
Training loss: 0.5705827474594116
Validation loss: 1.687030005198653

Epoch: 6| Step: 1
Training loss: 0.26670193672180176
Validation loss: 1.6930893390409407

Epoch: 6| Step: 2
Training loss: 0.6372823119163513
Validation loss: 1.7444889622349893

Epoch: 6| Step: 3
Training loss: 0.4798195958137512
Validation loss: 1.7313396135965984

Epoch: 6| Step: 4
Training loss: 0.2502453327178955
Validation loss: 1.714033124267414

Epoch: 6| Step: 5
Training loss: 0.511913537979126
Validation loss: 1.7492694111280545

Epoch: 6| Step: 6
Training loss: 0.328570693731308
Validation loss: 1.7316550029221403

Epoch: 6| Step: 7
Training loss: 0.45279112458229065
Validation loss: 1.6873807958377305

Epoch: 6| Step: 8
Training loss: 0.4460342228412628
Validation loss: 1.6910617530986827

Epoch: 6| Step: 9
Training loss: 0.5596271753311157
Validation loss: 1.7179468344616633

Epoch: 6| Step: 10
Training loss: 0.6063176393508911
Validation loss: 1.7016339737881896

Epoch: 6| Step: 11
Training loss: 0.3332921266555786
Validation loss: 1.7414702484684605

Epoch: 6| Step: 12
Training loss: 0.36729300022125244
Validation loss: 1.7547596949403004

Epoch: 6| Step: 13
Training loss: 0.27593177556991577
Validation loss: 1.7590183083729078

Epoch: 301| Step: 0
Training loss: 0.5103120803833008
Validation loss: 1.7713347224779026

Epoch: 6| Step: 1
Training loss: 0.3737134039402008
Validation loss: 1.777709626382397

Epoch: 6| Step: 2
Training loss: 0.5102173089981079
Validation loss: 1.7826311255014071

Epoch: 6| Step: 3
Training loss: 0.43487468361854553
Validation loss: 1.7304629664267264

Epoch: 6| Step: 4
Training loss: 0.48174649477005005
Validation loss: 1.7332307651478758

Epoch: 6| Step: 5
Training loss: 0.43282434344291687
Validation loss: 1.7017483993243145

Epoch: 6| Step: 6
Training loss: 0.48014000058174133
Validation loss: 1.689783283459243

Epoch: 6| Step: 7
Training loss: 0.414262592792511
Validation loss: 1.6704853298843547

Epoch: 6| Step: 8
Training loss: 0.501197099685669
Validation loss: 1.6575937066026913

Epoch: 6| Step: 9
Training loss: 0.3429722785949707
Validation loss: 1.664898080210532

Epoch: 6| Step: 10
Training loss: 0.4663694500923157
Validation loss: 1.6554424903726066

Epoch: 6| Step: 11
Training loss: 0.28362488746643066
Validation loss: 1.633917800841793

Epoch: 6| Step: 12
Training loss: 0.43654853105545044
Validation loss: 1.6504985004343011

Epoch: 6| Step: 13
Training loss: 0.41544702649116516
Validation loss: 1.6526741366232596

Epoch: 302| Step: 0
Training loss: 0.5689882040023804
Validation loss: 1.709813315381286

Epoch: 6| Step: 1
Training loss: 0.5555131435394287
Validation loss: 1.6647874321988834

Epoch: 6| Step: 2
Training loss: 0.3633981943130493
Validation loss: 1.6538853004414549

Epoch: 6| Step: 3
Training loss: 0.7315821647644043
Validation loss: 1.6607059394159625

Epoch: 6| Step: 4
Training loss: 0.5068607330322266
Validation loss: 1.6364839897360852

Epoch: 6| Step: 5
Training loss: 0.26411011815071106
Validation loss: 1.690796249656267

Epoch: 6| Step: 6
Training loss: 0.2752866744995117
Validation loss: 1.6706007757494528

Epoch: 6| Step: 7
Training loss: 0.38508671522140503
Validation loss: 1.6512998291241225

Epoch: 6| Step: 8
Training loss: 0.2669413387775421
Validation loss: 1.6632669279652257

Epoch: 6| Step: 9
Training loss: 0.17307612299919128
Validation loss: 1.6696827155287548

Epoch: 6| Step: 10
Training loss: 0.46176761388778687
Validation loss: 1.651089540091894

Epoch: 6| Step: 11
Training loss: 0.38152432441711426
Validation loss: 1.657045852753424

Epoch: 6| Step: 12
Training loss: 0.25580888986587524
Validation loss: 1.6633069053772958

Epoch: 6| Step: 13
Training loss: 0.612957775592804
Validation loss: 1.667987694022476

Epoch: 303| Step: 0
Training loss: 0.28818994760513306
Validation loss: 1.6725053556503788

Epoch: 6| Step: 1
Training loss: 0.3988018333911896
Validation loss: 1.679097847271991

Epoch: 6| Step: 2
Training loss: 0.3829042315483093
Validation loss: 1.6925079220084733

Epoch: 6| Step: 3
Training loss: 0.4381862282752991
Validation loss: 1.6976089323720625

Epoch: 6| Step: 4
Training loss: 0.46942728757858276
Validation loss: 1.7598163068935435

Epoch: 6| Step: 5
Training loss: 0.8010178804397583
Validation loss: 1.7673953246044856

Epoch: 6| Step: 6
Training loss: 0.43082165718078613
Validation loss: 1.721728587663302

Epoch: 6| Step: 7
Training loss: 0.5714099407196045
Validation loss: 1.7618479946608185

Epoch: 6| Step: 8
Training loss: 0.44547039270401
Validation loss: 1.6671798049762685

Epoch: 6| Step: 9
Training loss: 0.1443079710006714
Validation loss: 1.6842466477424867

Epoch: 6| Step: 10
Training loss: 0.2377518266439438
Validation loss: 1.6763161715640817

Epoch: 6| Step: 11
Training loss: 0.2428479790687561
Validation loss: 1.693257430548309

Epoch: 6| Step: 12
Training loss: 0.5143312215805054
Validation loss: 1.6801138244649416

Epoch: 6| Step: 13
Training loss: 0.25757884979248047
Validation loss: 1.7150624182916456

Epoch: 304| Step: 0
Training loss: 0.39969730377197266
Validation loss: 1.7267487446467082

Epoch: 6| Step: 1
Training loss: 0.5266774892807007
Validation loss: 1.6731971694577126

Epoch: 6| Step: 2
Training loss: 0.41228342056274414
Validation loss: 1.690794393580447

Epoch: 6| Step: 3
Training loss: 0.33555981516838074
Validation loss: 1.6863805888801493

Epoch: 6| Step: 4
Training loss: 0.1837156116962433
Validation loss: 1.6276823692424323

Epoch: 6| Step: 5
Training loss: 0.36191391944885254
Validation loss: 1.6452807393125308

Epoch: 6| Step: 6
Training loss: 0.4422982335090637
Validation loss: 1.630631023837674

Epoch: 6| Step: 7
Training loss: 0.38283368945121765
Validation loss: 1.6402312709439186

Epoch: 6| Step: 8
Training loss: 0.49857139587402344
Validation loss: 1.632821850879218

Epoch: 6| Step: 9
Training loss: 0.5934548377990723
Validation loss: 1.7150160933053622

Epoch: 6| Step: 10
Training loss: 0.6350614428520203
Validation loss: 1.7487019954189178

Epoch: 6| Step: 11
Training loss: 0.15303944051265717
Validation loss: 1.7165097792943318

Epoch: 6| Step: 12
Training loss: 0.5070923566818237
Validation loss: 1.692405636592578

Epoch: 6| Step: 13
Training loss: 0.3559459447860718
Validation loss: 1.6869688790331605

Epoch: 305| Step: 0
Training loss: 0.4661101698875427
Validation loss: 1.706259430736624

Epoch: 6| Step: 1
Training loss: 0.6230107545852661
Validation loss: 1.6837973633120138

Epoch: 6| Step: 2
Training loss: 0.2435128390789032
Validation loss: 1.6982263390735914

Epoch: 6| Step: 3
Training loss: 0.3527693748474121
Validation loss: 1.7084698004107322

Epoch: 6| Step: 4
Training loss: 0.29290974140167236
Validation loss: 1.7132312226039108

Epoch: 6| Step: 5
Training loss: 0.4955102503299713
Validation loss: 1.6979980443113594

Epoch: 6| Step: 6
Training loss: 0.29400402307510376
Validation loss: 1.7196897947660057

Epoch: 6| Step: 7
Training loss: 0.4899020791053772
Validation loss: 1.7254044868612801

Epoch: 6| Step: 8
Training loss: 0.6127945780754089
Validation loss: 1.7439408558671192

Epoch: 6| Step: 9
Training loss: 0.5201560258865356
Validation loss: 1.7689704792473906

Epoch: 6| Step: 10
Training loss: 0.5387715101242065
Validation loss: 1.7408918821683494

Epoch: 6| Step: 11
Training loss: 0.4141519367694855
Validation loss: 1.7245489884448308

Epoch: 6| Step: 12
Training loss: 0.32085034251213074
Validation loss: 1.6924676600322928

Epoch: 6| Step: 13
Training loss: 0.28262078762054443
Validation loss: 1.7382788991415372

Epoch: 306| Step: 0
Training loss: 0.397253155708313
Validation loss: 1.7534501103944675

Epoch: 6| Step: 1
Training loss: 0.6334291100502014
Validation loss: 1.7603804270426433

Epoch: 6| Step: 2
Training loss: 0.3579828441143036
Validation loss: 1.7499405209736159

Epoch: 6| Step: 3
Training loss: 0.5594075918197632
Validation loss: 1.807601833856234

Epoch: 6| Step: 4
Training loss: 0.6250863075256348
Validation loss: 1.7551477327141711

Epoch: 6| Step: 5
Training loss: 0.3698425889015198
Validation loss: 1.7461536943271596

Epoch: 6| Step: 6
Training loss: 0.2425246238708496
Validation loss: 1.7095535570575344

Epoch: 6| Step: 7
Training loss: 0.4414544999599457
Validation loss: 1.6870122942873227

Epoch: 6| Step: 8
Training loss: 0.6733771562576294
Validation loss: 1.6793587169339579

Epoch: 6| Step: 9
Training loss: 0.3454746603965759
Validation loss: 1.6640753989578576

Epoch: 6| Step: 10
Training loss: 0.5563381910324097
Validation loss: 1.6599651280269827

Epoch: 6| Step: 11
Training loss: 0.36526310443878174
Validation loss: 1.6401590531872166

Epoch: 6| Step: 12
Training loss: 0.3447844684123993
Validation loss: 1.6575041278716056

Epoch: 6| Step: 13
Training loss: 0.1885477751493454
Validation loss: 1.6304582408679429

Epoch: 307| Step: 0
Training loss: 0.5277296304702759
Validation loss: 1.64511985804445

Epoch: 6| Step: 1
Training loss: 0.28587859869003296
Validation loss: 1.660910665348012

Epoch: 6| Step: 2
Training loss: 0.6493591666221619
Validation loss: 1.7032491571159774

Epoch: 6| Step: 3
Training loss: 0.4980419874191284
Validation loss: 1.7026651033791163

Epoch: 6| Step: 4
Training loss: 0.3795139789581299
Validation loss: 1.6664624534627444

Epoch: 6| Step: 5
Training loss: 0.48438167572021484
Validation loss: 1.6694299892712665

Epoch: 6| Step: 6
Training loss: 0.4237203598022461
Validation loss: 1.6327087507453015

Epoch: 6| Step: 7
Training loss: 0.3953108787536621
Validation loss: 1.6384597542465373

Epoch: 6| Step: 8
Training loss: 0.26650989055633545
Validation loss: 1.6279625661911503

Epoch: 6| Step: 9
Training loss: 0.3930133581161499
Validation loss: 1.6393041021080428

Epoch: 6| Step: 10
Training loss: 0.32410839200019836
Validation loss: 1.6253667467383928

Epoch: 6| Step: 11
Training loss: 0.4224494397640228
Validation loss: 1.6894544901386384

Epoch: 6| Step: 12
Training loss: 0.6047476530075073
Validation loss: 1.7024342129307408

Epoch: 6| Step: 13
Training loss: 0.515662670135498
Validation loss: 1.734222089090655

Epoch: 308| Step: 0
Training loss: 0.31268182396888733
Validation loss: 1.7221954279048468

Epoch: 6| Step: 1
Training loss: 0.44762304425239563
Validation loss: 1.8011969212562806

Epoch: 6| Step: 2
Training loss: 0.4701405167579651
Validation loss: 1.8005419700376448

Epoch: 6| Step: 3
Training loss: 0.41742295026779175
Validation loss: 1.7703651471804547

Epoch: 6| Step: 4
Training loss: 0.4990156292915344
Validation loss: 1.7365345006347985

Epoch: 6| Step: 5
Training loss: 0.3967549204826355
Validation loss: 1.7324398961118472

Epoch: 6| Step: 6
Training loss: 0.4756962060928345
Validation loss: 1.7214458565558157

Epoch: 6| Step: 7
Training loss: 0.4055551588535309
Validation loss: 1.7296967211590017

Epoch: 6| Step: 8
Training loss: 0.3846181631088257
Validation loss: 1.6940513887713033

Epoch: 6| Step: 9
Training loss: 0.5725707411766052
Validation loss: 1.718130951286644

Epoch: 6| Step: 10
Training loss: 0.2877776026725769
Validation loss: 1.7092385702235724

Epoch: 6| Step: 11
Training loss: 0.6156882047653198
Validation loss: 1.7115409399873467

Epoch: 6| Step: 12
Training loss: 0.5878822803497314
Validation loss: 1.7073759225107008

Epoch: 6| Step: 13
Training loss: 0.4833707809448242
Validation loss: 1.754010982410882

Epoch: 309| Step: 0
Training loss: 0.45198488235473633
Validation loss: 1.7261657484116093

Epoch: 6| Step: 1
Training loss: 0.45201757550239563
Validation loss: 1.7583909393638693

Epoch: 6| Step: 2
Training loss: 0.4626739025115967
Validation loss: 1.7591444112921273

Epoch: 6| Step: 3
Training loss: 0.15618327260017395
Validation loss: 1.7518555041282409

Epoch: 6| Step: 4
Training loss: 0.42369750142097473
Validation loss: 1.714476719979317

Epoch: 6| Step: 5
Training loss: 0.4107412099838257
Validation loss: 1.7626964007654498

Epoch: 6| Step: 6
Training loss: 0.23713816702365875
Validation loss: 1.7756130413342548

Epoch: 6| Step: 7
Training loss: 0.5897841453552246
Validation loss: 1.7804307347984725

Epoch: 6| Step: 8
Training loss: 0.42876675724983215
Validation loss: 1.7665706270484514

Epoch: 6| Step: 9
Training loss: 0.384579062461853
Validation loss: 1.766105826183032

Epoch: 6| Step: 10
Training loss: 0.5115286707878113
Validation loss: 1.7708642598121398

Epoch: 6| Step: 11
Training loss: 0.4864147901535034
Validation loss: 1.7268969371754637

Epoch: 6| Step: 12
Training loss: 0.3330402374267578
Validation loss: 1.7189483232395624

Epoch: 6| Step: 13
Training loss: 0.43853673338890076
Validation loss: 1.7139502904748405

Epoch: 310| Step: 0
Training loss: 0.42888617515563965
Validation loss: 1.7027952260868524

Epoch: 6| Step: 1
Training loss: 0.37793606519699097
Validation loss: 1.6899069983472106

Epoch: 6| Step: 2
Training loss: 0.3288745880126953
Validation loss: 1.7061921832382039

Epoch: 6| Step: 3
Training loss: 0.4479145407676697
Validation loss: 1.6927420939168623

Epoch: 6| Step: 4
Training loss: 0.30487704277038574
Validation loss: 1.6634677892090173

Epoch: 6| Step: 5
Training loss: 0.5219419598579407
Validation loss: 1.7263728508385279

Epoch: 6| Step: 6
Training loss: 0.3314065933227539
Validation loss: 1.6594955767354658

Epoch: 6| Step: 7
Training loss: 0.35892757773399353
Validation loss: 1.6714175888287124

Epoch: 6| Step: 8
Training loss: 0.5363905429840088
Validation loss: 1.6748123374036563

Epoch: 6| Step: 9
Training loss: 0.3456307053565979
Validation loss: 1.6687345946988752

Epoch: 6| Step: 10
Training loss: 0.482408732175827
Validation loss: 1.680698961339971

Epoch: 6| Step: 11
Training loss: 0.4979955554008484
Validation loss: 1.6585690539370301

Epoch: 6| Step: 12
Training loss: 0.3104769289493561
Validation loss: 1.6649366591566352

Epoch: 6| Step: 13
Training loss: 0.2681224048137665
Validation loss: 1.665488314884965

Epoch: 311| Step: 0
Training loss: 0.28964293003082275
Validation loss: 1.6942731026680238

Epoch: 6| Step: 1
Training loss: 0.4062139391899109
Validation loss: 1.6925071439435404

Epoch: 6| Step: 2
Training loss: 0.4571029543876648
Validation loss: 1.6833623839962868

Epoch: 6| Step: 3
Training loss: 0.3981110751628876
Validation loss: 1.6860391888567197

Epoch: 6| Step: 4
Training loss: 0.29493778944015503
Validation loss: 1.6818236913732303

Epoch: 6| Step: 5
Training loss: 0.44825056195259094
Validation loss: 1.6899500444371214

Epoch: 6| Step: 6
Training loss: 0.4715275764465332
Validation loss: 1.696958944361697

Epoch: 6| Step: 7
Training loss: 0.22585807740688324
Validation loss: 1.6857395800211097

Epoch: 6| Step: 8
Training loss: 0.30814236402511597
Validation loss: 1.664914587492584

Epoch: 6| Step: 9
Training loss: 0.41749808192253113
Validation loss: 1.6987075216026717

Epoch: 6| Step: 10
Training loss: 0.19602739810943604
Validation loss: 1.6781843836589525

Epoch: 6| Step: 11
Training loss: 0.5495374202728271
Validation loss: 1.6665882628451112

Epoch: 6| Step: 12
Training loss: 0.293544203042984
Validation loss: 1.6607543114692933

Epoch: 6| Step: 13
Training loss: 0.6902227401733398
Validation loss: 1.6665221375803794

Epoch: 312| Step: 0
Training loss: 0.4533998966217041
Validation loss: 1.7108444116448844

Epoch: 6| Step: 1
Training loss: 0.30134567618370056
Validation loss: 1.67189500921516

Epoch: 6| Step: 2
Training loss: 0.5881097316741943
Validation loss: 1.6581673596494941

Epoch: 6| Step: 3
Training loss: 0.3848591446876526
Validation loss: 1.6544978157166512

Epoch: 6| Step: 4
Training loss: 0.36833781003952026
Validation loss: 1.6127981332040602

Epoch: 6| Step: 5
Training loss: 0.3060755729675293
Validation loss: 1.6452696733577277

Epoch: 6| Step: 6
Training loss: 0.46997159719467163
Validation loss: 1.5889866339263095

Epoch: 6| Step: 7
Training loss: 0.30966708064079285
Validation loss: 1.5910850583866079

Epoch: 6| Step: 8
Training loss: 0.3303421437740326
Validation loss: 1.6173804716397358

Epoch: 6| Step: 9
Training loss: 0.6153640747070312
Validation loss: 1.6412883881599671

Epoch: 6| Step: 10
Training loss: 0.37153372168540955
Validation loss: 1.6851062569566952

Epoch: 6| Step: 11
Training loss: 0.5148792862892151
Validation loss: 1.7146329315759803

Epoch: 6| Step: 12
Training loss: 0.29117703437805176
Validation loss: 1.6624500482313094

Epoch: 6| Step: 13
Training loss: 0.289081335067749
Validation loss: 1.6914873879442933

Epoch: 313| Step: 0
Training loss: 0.4256288707256317
Validation loss: 1.6835417824406778

Epoch: 6| Step: 1
Training loss: 0.5497491359710693
Validation loss: 1.674198454426181

Epoch: 6| Step: 2
Training loss: 0.3586016297340393
Validation loss: 1.6850927273432414

Epoch: 6| Step: 3
Training loss: 0.44908303022384644
Validation loss: 1.6556640145599202

Epoch: 6| Step: 4
Training loss: 0.3304706811904907
Validation loss: 1.6567874518773889

Epoch: 6| Step: 5
Training loss: 0.5189847350120544
Validation loss: 1.6420335679925897

Epoch: 6| Step: 6
Training loss: 0.4207422733306885
Validation loss: 1.6641966335235103

Epoch: 6| Step: 7
Training loss: 0.37048786878585815
Validation loss: 1.6524739701260802

Epoch: 6| Step: 8
Training loss: 0.3591795861721039
Validation loss: 1.6754419034527195

Epoch: 6| Step: 9
Training loss: 0.2838834524154663
Validation loss: 1.6489346719557239

Epoch: 6| Step: 10
Training loss: 0.37825679779052734
Validation loss: 1.7047368672586256

Epoch: 6| Step: 11
Training loss: 0.36913803219795227
Validation loss: 1.6856187030833254

Epoch: 6| Step: 12
Training loss: 0.36233916878700256
Validation loss: 1.7054394598930114

Epoch: 6| Step: 13
Training loss: 0.2520115077495575
Validation loss: 1.715217339095249

Epoch: 314| Step: 0
Training loss: 0.464703232049942
Validation loss: 1.7132276437615837

Epoch: 6| Step: 1
Training loss: 0.31885892152786255
Validation loss: 1.6573048458304456

Epoch: 6| Step: 2
Training loss: 0.3686390519142151
Validation loss: 1.6320784373949933

Epoch: 6| Step: 3
Training loss: 0.42632442712783813
Validation loss: 1.6029902478700042

Epoch: 6| Step: 4
Training loss: 0.2832021713256836
Validation loss: 1.613351301480365

Epoch: 6| Step: 5
Training loss: 0.4951750636100769
Validation loss: 1.6338252854603592

Epoch: 6| Step: 6
Training loss: 0.1864366978406906
Validation loss: 1.6058962607896456

Epoch: 6| Step: 7
Training loss: 0.4288845658302307
Validation loss: 1.6386462052663167

Epoch: 6| Step: 8
Training loss: 0.29774630069732666
Validation loss: 1.6561784590444257

Epoch: 6| Step: 9
Training loss: 0.49352791905403137
Validation loss: 1.6440108796601653

Epoch: 6| Step: 10
Training loss: 0.4009974002838135
Validation loss: 1.6645328562746766

Epoch: 6| Step: 11
Training loss: 0.2045619934797287
Validation loss: 1.6737161387679398

Epoch: 6| Step: 12
Training loss: 0.4846629500389099
Validation loss: 1.6647797489678988

Epoch: 6| Step: 13
Training loss: 0.23156744241714478
Validation loss: 1.6702712787094938

Epoch: 315| Step: 0
Training loss: 0.25368526577949524
Validation loss: 1.6444197752142464

Epoch: 6| Step: 1
Training loss: 0.346805214881897
Validation loss: 1.6766716767382879

Epoch: 6| Step: 2
Training loss: 0.2618010938167572
Validation loss: 1.6473570831360356

Epoch: 6| Step: 3
Training loss: 0.36305326223373413
Validation loss: 1.6624988279035013

Epoch: 6| Step: 4
Training loss: 0.4795086979866028
Validation loss: 1.613031937230018

Epoch: 6| Step: 5
Training loss: 0.2802542448043823
Validation loss: 1.653392853275422

Epoch: 6| Step: 6
Training loss: 0.3555179834365845
Validation loss: 1.6087489346022248

Epoch: 6| Step: 7
Training loss: 0.28654322028160095
Validation loss: 1.5988368885491484

Epoch: 6| Step: 8
Training loss: 0.40063998103141785
Validation loss: 1.622658488571003

Epoch: 6| Step: 9
Training loss: 0.21330851316452026
Validation loss: 1.6123183517045871

Epoch: 6| Step: 10
Training loss: 0.42945778369903564
Validation loss: 1.624712158274907

Epoch: 6| Step: 11
Training loss: 0.442099392414093
Validation loss: 1.6218925342764905

Epoch: 6| Step: 12
Training loss: 0.5102497339248657
Validation loss: 1.605564163577172

Epoch: 6| Step: 13
Training loss: 0.3407529592514038
Validation loss: 1.6390863285269788

Epoch: 316| Step: 0
Training loss: 0.12635403871536255
Validation loss: 1.6695034785937237

Epoch: 6| Step: 1
Training loss: 0.4174659252166748
Validation loss: 1.6267344541447137

Epoch: 6| Step: 2
Training loss: 0.513863205909729
Validation loss: 1.6611609728105607

Epoch: 6| Step: 3
Training loss: 0.34577807784080505
Validation loss: 1.6886202250757525

Epoch: 6| Step: 4
Training loss: 0.26213985681533813
Validation loss: 1.683840411965565

Epoch: 6| Step: 5
Training loss: 0.3163685202598572
Validation loss: 1.6504617057820803

Epoch: 6| Step: 6
Training loss: 0.2455756515264511
Validation loss: 1.6330052204029535

Epoch: 6| Step: 7
Training loss: 0.48459741473197937
Validation loss: 1.6267443036520353

Epoch: 6| Step: 8
Training loss: 0.35753917694091797
Validation loss: 1.5833841517407408

Epoch: 6| Step: 9
Training loss: 0.36171478033065796
Validation loss: 1.5738203974180325

Epoch: 6| Step: 10
Training loss: 0.3467863202095032
Validation loss: 1.587133260183437

Epoch: 6| Step: 11
Training loss: 0.45832255482673645
Validation loss: 1.5963736759719027

Epoch: 6| Step: 12
Training loss: 0.4050575792789459
Validation loss: 1.5355514646858297

Epoch: 6| Step: 13
Training loss: 0.31537994742393494
Validation loss: 1.5636861208946473

Epoch: 317| Step: 0
Training loss: 0.41653114557266235
Validation loss: 1.5667445608364639

Epoch: 6| Step: 1
Training loss: 0.26538705825805664
Validation loss: 1.5480250056071947

Epoch: 6| Step: 2
Training loss: 0.22746169567108154
Validation loss: 1.5899637758090932

Epoch: 6| Step: 3
Training loss: 0.28730857372283936
Validation loss: 1.608421774320705

Epoch: 6| Step: 4
Training loss: 0.3743443191051483
Validation loss: 1.576230702861663

Epoch: 6| Step: 5
Training loss: 0.22710540890693665
Validation loss: 1.5982829204169653

Epoch: 6| Step: 6
Training loss: 0.32982945442199707
Validation loss: 1.6475980768921554

Epoch: 6| Step: 7
Training loss: 0.5879571437835693
Validation loss: 1.6326025083500852

Epoch: 6| Step: 8
Training loss: 0.42939573526382446
Validation loss: 1.6710615363172305

Epoch: 6| Step: 9
Training loss: 0.2565282881259918
Validation loss: 1.6704188700645202

Epoch: 6| Step: 10
Training loss: 0.39204519987106323
Validation loss: 1.6640454787080006

Epoch: 6| Step: 11
Training loss: 0.44258010387420654
Validation loss: 1.6252820773791241

Epoch: 6| Step: 12
Training loss: 0.2850261926651001
Validation loss: 1.6423809348895986

Epoch: 6| Step: 13
Training loss: 0.2960096299648285
Validation loss: 1.6530575598439863

Epoch: 318| Step: 0
Training loss: 0.23863855004310608
Validation loss: 1.66512555204412

Epoch: 6| Step: 1
Training loss: 0.27902790904045105
Validation loss: 1.6834639118563743

Epoch: 6| Step: 2
Training loss: 0.30443981289863586
Validation loss: 1.6964123800236692

Epoch: 6| Step: 3
Training loss: 0.3137579560279846
Validation loss: 1.6713490819418302

Epoch: 6| Step: 4
Training loss: 0.33885326981544495
Validation loss: 1.6709414605171449

Epoch: 6| Step: 5
Training loss: 0.180603489279747
Validation loss: 1.679571988762066

Epoch: 6| Step: 6
Training loss: 0.3519182801246643
Validation loss: 1.674697837521953

Epoch: 6| Step: 7
Training loss: 0.5603217482566833
Validation loss: 1.6393183200590071

Epoch: 6| Step: 8
Training loss: 0.4369669556617737
Validation loss: 1.6237908230032971

Epoch: 6| Step: 9
Training loss: 0.32476288080215454
Validation loss: 1.636030170225328

Epoch: 6| Step: 10
Training loss: 0.2426459640264511
Validation loss: 1.6212484900669386

Epoch: 6| Step: 11
Training loss: 0.41667234897613525
Validation loss: 1.6252052796784269

Epoch: 6| Step: 12
Training loss: 0.2841334044933319
Validation loss: 1.6196294394872521

Epoch: 6| Step: 13
Training loss: 0.7087327241897583
Validation loss: 1.6508964639838024

Epoch: 319| Step: 0
Training loss: 0.33195433020591736
Validation loss: 1.6727522021980696

Epoch: 6| Step: 1
Training loss: 0.368755578994751
Validation loss: 1.6843521774456065

Epoch: 6| Step: 2
Training loss: 0.5340085029602051
Validation loss: 1.6602945686668478

Epoch: 6| Step: 3
Training loss: 0.3604016602039337
Validation loss: 1.5943974448788552

Epoch: 6| Step: 4
Training loss: 0.25667932629585266
Validation loss: 1.570219530854174

Epoch: 6| Step: 5
Training loss: 0.35223188996315
Validation loss: 1.6062064709201935

Epoch: 6| Step: 6
Training loss: 0.48486536741256714
Validation loss: 1.577899327842138

Epoch: 6| Step: 7
Training loss: 0.4938802719116211
Validation loss: 1.6127411857728036

Epoch: 6| Step: 8
Training loss: 0.3915686011314392
Validation loss: 1.585208644149124

Epoch: 6| Step: 9
Training loss: 0.36690962314605713
Validation loss: 1.5830526813384025

Epoch: 6| Step: 10
Training loss: 0.47234082221984863
Validation loss: 1.5985090027573288

Epoch: 6| Step: 11
Training loss: 0.3765465021133423
Validation loss: 1.5972041545375701

Epoch: 6| Step: 12
Training loss: 0.18558070063591003
Validation loss: 1.5861055568982196

Epoch: 6| Step: 13
Training loss: 0.270883709192276
Validation loss: 1.6062995310752624

Epoch: 320| Step: 0
Training loss: 0.3060096800327301
Validation loss: 1.637141986559796

Epoch: 6| Step: 1
Training loss: 0.44694268703460693
Validation loss: 1.6312665375330115

Epoch: 6| Step: 2
Training loss: 0.25318023562431335
Validation loss: 1.6486141720125753

Epoch: 6| Step: 3
Training loss: 0.4486848711967468
Validation loss: 1.679929667903531

Epoch: 6| Step: 4
Training loss: 0.464543879032135
Validation loss: 1.6492748491225704

Epoch: 6| Step: 5
Training loss: 0.5240970849990845
Validation loss: 1.632781550448428

Epoch: 6| Step: 6
Training loss: 0.4451816976070404
Validation loss: 1.570226236056256

Epoch: 6| Step: 7
Training loss: 0.3257254958152771
Validation loss: 1.5868814888820852

Epoch: 6| Step: 8
Training loss: 0.23739184439182281
Validation loss: 1.5844025983605334

Epoch: 6| Step: 9
Training loss: 0.2246021330356598
Validation loss: 1.607489696113012

Epoch: 6| Step: 10
Training loss: 0.2309338003396988
Validation loss: 1.5990862948920137

Epoch: 6| Step: 11
Training loss: 0.483672171831131
Validation loss: 1.6286333158452024

Epoch: 6| Step: 12
Training loss: 0.32040345668792725
Validation loss: 1.6426725438846055

Epoch: 6| Step: 13
Training loss: 0.22663821280002594
Validation loss: 1.6780009590169436

Epoch: 321| Step: 0
Training loss: 0.4065496027469635
Validation loss: 1.6942540650726647

Epoch: 6| Step: 1
Training loss: 0.2925516366958618
Validation loss: 1.674491556100948

Epoch: 6| Step: 2
Training loss: 0.30796074867248535
Validation loss: 1.7382787735231462

Epoch: 6| Step: 3
Training loss: 0.367088258266449
Validation loss: 1.8493140858988608

Epoch: 6| Step: 4
Training loss: 0.9085052013397217
Validation loss: 1.9180348227100987

Epoch: 6| Step: 5
Training loss: 0.6669342517852783
Validation loss: 1.9415172658940798

Epoch: 6| Step: 6
Training loss: 0.5879737138748169
Validation loss: 1.8626193128606325

Epoch: 6| Step: 7
Training loss: 0.43760451674461365
Validation loss: 1.7365571324543287

Epoch: 6| Step: 8
Training loss: 0.3453846573829651
Validation loss: 1.687382589104355

Epoch: 6| Step: 9
Training loss: 0.4644901156425476
Validation loss: 1.6166920392744002

Epoch: 6| Step: 10
Training loss: 0.3753729462623596
Validation loss: 1.6165966487699939

Epoch: 6| Step: 11
Training loss: 0.6135026216506958
Validation loss: 1.6234145779763498

Epoch: 6| Step: 12
Training loss: 0.6691589951515198
Validation loss: 1.625822740216409

Epoch: 6| Step: 13
Training loss: 0.324948251247406
Validation loss: 1.6878466721503966

Epoch: 322| Step: 0
Training loss: 0.7647029161453247
Validation loss: 1.6378297728876914

Epoch: 6| Step: 1
Training loss: 0.5612032413482666
Validation loss: 1.612918056467528

Epoch: 6| Step: 2
Training loss: 0.5157012939453125
Validation loss: 1.5959904411787629

Epoch: 6| Step: 3
Training loss: 0.18593204021453857
Validation loss: 1.6307404220745128

Epoch: 6| Step: 4
Training loss: 0.1460159420967102
Validation loss: 1.6756679165747859

Epoch: 6| Step: 5
Training loss: 0.34801021218299866
Validation loss: 1.735655387242635

Epoch: 6| Step: 6
Training loss: 0.35505232214927673
Validation loss: 1.7852494216734363

Epoch: 6| Step: 7
Training loss: 0.515113115310669
Validation loss: 1.8060789877368557

Epoch: 6| Step: 8
Training loss: 0.3337802290916443
Validation loss: 1.7848265709415558

Epoch: 6| Step: 9
Training loss: 0.21899980306625366
Validation loss: 1.7162067518439343

Epoch: 6| Step: 10
Training loss: 0.7304140329360962
Validation loss: 1.7154630999411307

Epoch: 6| Step: 11
Training loss: 0.45909637212753296
Validation loss: 1.6330668298147057

Epoch: 6| Step: 12
Training loss: 0.30824539065361023
Validation loss: 1.5886502458203224

Epoch: 6| Step: 13
Training loss: 0.19426241517066956
Validation loss: 1.597668227329049

Epoch: 323| Step: 0
Training loss: 0.3797805607318878
Validation loss: 1.6007035598959973

Epoch: 6| Step: 1
Training loss: 0.39048802852630615
Validation loss: 1.6259370157795567

Epoch: 6| Step: 2
Training loss: 0.31906044483184814
Validation loss: 1.6696615424207462

Epoch: 6| Step: 3
Training loss: 0.49657875299453735
Validation loss: 1.6482164449589227

Epoch: 6| Step: 4
Training loss: 0.4856950044631958
Validation loss: 1.6204642224055466

Epoch: 6| Step: 5
Training loss: 0.3793034553527832
Validation loss: 1.646376273965323

Epoch: 6| Step: 6
Training loss: 0.31970179080963135
Validation loss: 1.595134671016406

Epoch: 6| Step: 7
Training loss: 0.39960482716560364
Validation loss: 1.6383167364264046

Epoch: 6| Step: 8
Training loss: 0.4092899262905121
Validation loss: 1.6389109511529245

Epoch: 6| Step: 9
Training loss: 0.20567376911640167
Validation loss: 1.6517442676328844

Epoch: 6| Step: 10
Training loss: 0.6475976705551147
Validation loss: 1.663067046032157

Epoch: 6| Step: 11
Training loss: 0.37980443239212036
Validation loss: 1.6663622163957166

Epoch: 6| Step: 12
Training loss: 0.46674269437789917
Validation loss: 1.6264098485310872

Epoch: 6| Step: 13
Training loss: 0.19018882513046265
Validation loss: 1.6057125246652992

Epoch: 324| Step: 0
Training loss: 0.26091453433036804
Validation loss: 1.5785030523935955

Epoch: 6| Step: 1
Training loss: 0.5372113585472107
Validation loss: 1.5818586041850429

Epoch: 6| Step: 2
Training loss: 0.49394935369491577
Validation loss: 1.567388048735998

Epoch: 6| Step: 3
Training loss: 0.4705392122268677
Validation loss: 1.5580240039415256

Epoch: 6| Step: 4
Training loss: 0.4235769808292389
Validation loss: 1.590035266773675

Epoch: 6| Step: 5
Training loss: 0.37427520751953125
Validation loss: 1.5642618440812635

Epoch: 6| Step: 6
Training loss: 0.3027374744415283
Validation loss: 1.6383309274591424

Epoch: 6| Step: 7
Training loss: 0.30085575580596924
Validation loss: 1.5962979716639365

Epoch: 6| Step: 8
Training loss: 0.18044552206993103
Validation loss: 1.6127932533141105

Epoch: 6| Step: 9
Training loss: 0.1875411719083786
Validation loss: 1.6526705808536981

Epoch: 6| Step: 10
Training loss: 0.3296689987182617
Validation loss: 1.6859638793494112

Epoch: 6| Step: 11
Training loss: 0.372666597366333
Validation loss: 1.6603159314842635

Epoch: 6| Step: 12
Training loss: 0.5168977975845337
Validation loss: 1.640395325358196

Epoch: 6| Step: 13
Training loss: 0.49626296758651733
Validation loss: 1.6183508839658511

Epoch: 325| Step: 0
Training loss: 0.3390811085700989
Validation loss: 1.6280355145854335

Epoch: 6| Step: 1
Training loss: 0.36539000272750854
Validation loss: 1.577414015287994

Epoch: 6| Step: 2
Training loss: 0.24127410352230072
Validation loss: 1.5678690800102808

Epoch: 6| Step: 3
Training loss: 0.45616888999938965
Validation loss: 1.5753510395685832

Epoch: 6| Step: 4
Training loss: 0.5231970548629761
Validation loss: 1.5729947397785802

Epoch: 6| Step: 5
Training loss: 0.3125934302806854
Validation loss: 1.57710773457763

Epoch: 6| Step: 6
Training loss: 0.5615983009338379
Validation loss: 1.5682039722319572

Epoch: 6| Step: 7
Training loss: 0.43130338191986084
Validation loss: 1.6007188097123177

Epoch: 6| Step: 8
Training loss: 0.4409319758415222
Validation loss: 1.6149416110848869

Epoch: 6| Step: 9
Training loss: 0.3363252282142639
Validation loss: 1.6822467183554044

Epoch: 6| Step: 10
Training loss: 0.23948454856872559
Validation loss: 1.6905786100254263

Epoch: 6| Step: 11
Training loss: 0.2685886025428772
Validation loss: 1.6795791323466966

Epoch: 6| Step: 12
Training loss: 0.13826261460781097
Validation loss: 1.6493966951165149

Epoch: 6| Step: 13
Training loss: 0.3400585353374481
Validation loss: 1.6788081494710778

Epoch: 326| Step: 0
Training loss: 0.3271218240261078
Validation loss: 1.6908841094663065

Epoch: 6| Step: 1
Training loss: 0.19930097460746765
Validation loss: 1.6456728366113478

Epoch: 6| Step: 2
Training loss: 0.47971630096435547
Validation loss: 1.6661860019929948

Epoch: 6| Step: 3
Training loss: 0.22303247451782227
Validation loss: 1.6653298998391757

Epoch: 6| Step: 4
Training loss: 0.4149264991283417
Validation loss: 1.6370841674907233

Epoch: 6| Step: 5
Training loss: 0.3513988256454468
Validation loss: 1.6234340975361485

Epoch: 6| Step: 6
Training loss: 0.32248520851135254
Validation loss: 1.6192781527837117

Epoch: 6| Step: 7
Training loss: 0.4195476174354553
Validation loss: 1.652067768958307

Epoch: 6| Step: 8
Training loss: 0.47654592990875244
Validation loss: 1.6602959748237365

Epoch: 6| Step: 9
Training loss: 0.3639007806777954
Validation loss: 1.6349305337475193

Epoch: 6| Step: 10
Training loss: 0.24571532011032104
Validation loss: 1.6423749372523317

Epoch: 6| Step: 11
Training loss: 0.38172775506973267
Validation loss: 1.6506124029877365

Epoch: 6| Step: 12
Training loss: 0.27778708934783936
Validation loss: 1.6230062900050994

Epoch: 6| Step: 13
Training loss: 0.2196889966726303
Validation loss: 1.6117455062045847

Epoch: 327| Step: 0
Training loss: 0.33410584926605225
Validation loss: 1.6415017830428256

Epoch: 6| Step: 1
Training loss: 0.3885239362716675
Validation loss: 1.6788491299075465

Epoch: 6| Step: 2
Training loss: 0.3318301737308502
Validation loss: 1.6733606118027882

Epoch: 6| Step: 3
Training loss: 0.33078086376190186
Validation loss: 1.7107051572492045

Epoch: 6| Step: 4
Training loss: 0.32772889733314514
Validation loss: 1.6868623892466228

Epoch: 6| Step: 5
Training loss: 0.4267955422401428
Validation loss: 1.7005869791071901

Epoch: 6| Step: 6
Training loss: 0.39491593837738037
Validation loss: 1.6826628818306872

Epoch: 6| Step: 7
Training loss: 0.2972562313079834
Validation loss: 1.6988270052017704

Epoch: 6| Step: 8
Training loss: 0.18800383806228638
Validation loss: 1.7092568489813036

Epoch: 6| Step: 9
Training loss: 0.42689454555511475
Validation loss: 1.6729664751278457

Epoch: 6| Step: 10
Training loss: 0.36534395813941956
Validation loss: 1.6519467202566003

Epoch: 6| Step: 11
Training loss: 0.4445556402206421
Validation loss: 1.666561383073048

Epoch: 6| Step: 12
Training loss: 0.37431371212005615
Validation loss: 1.6830001056835215

Epoch: 6| Step: 13
Training loss: 0.1639643907546997
Validation loss: 1.6672592034903906

Epoch: 328| Step: 0
Training loss: 0.2830401659011841
Validation loss: 1.6669464502283322

Epoch: 6| Step: 1
Training loss: 0.3597753643989563
Validation loss: 1.6931340540609052

Epoch: 6| Step: 2
Training loss: 0.31594520807266235
Validation loss: 1.6608493981822845

Epoch: 6| Step: 3
Training loss: 0.5040562748908997
Validation loss: 1.6547892606386574

Epoch: 6| Step: 4
Training loss: 0.26972514390945435
Validation loss: 1.6248542877935594

Epoch: 6| Step: 5
Training loss: 0.1882459670305252
Validation loss: 1.628025879142105

Epoch: 6| Step: 6
Training loss: 0.29656708240509033
Validation loss: 1.581199562677773

Epoch: 6| Step: 7
Training loss: 0.3505825400352478
Validation loss: 1.6120930384564143

Epoch: 6| Step: 8
Training loss: 0.36023467779159546
Validation loss: 1.6319315638593448

Epoch: 6| Step: 9
Training loss: 0.47346585988998413
Validation loss: 1.6605866967990834

Epoch: 6| Step: 10
Training loss: 0.2993801534175873
Validation loss: 1.6565422742597518

Epoch: 6| Step: 11
Training loss: 0.2300044745206833
Validation loss: 1.6612146054544756

Epoch: 6| Step: 12
Training loss: 0.5275946855545044
Validation loss: 1.6688528586459417

Epoch: 6| Step: 13
Training loss: 0.05087899789214134
Validation loss: 1.6323912233434699

Epoch: 329| Step: 0
Training loss: 0.4709208309650421
Validation loss: 1.6832996863190846

Epoch: 6| Step: 1
Training loss: 0.3704208731651306
Validation loss: 1.6770486139482068

Epoch: 6| Step: 2
Training loss: 0.3429005444049835
Validation loss: 1.6989973591219993

Epoch: 6| Step: 3
Training loss: 0.3159574270248413
Validation loss: 1.7204453445249988

Epoch: 6| Step: 4
Training loss: 0.28359735012054443
Validation loss: 1.6764231202422932

Epoch: 6| Step: 5
Training loss: 0.3128798007965088
Validation loss: 1.6918180757953274

Epoch: 6| Step: 6
Training loss: 0.42787742614746094
Validation loss: 1.6388773405423729

Epoch: 6| Step: 7
Training loss: 0.31915295124053955
Validation loss: 1.6455502856162287

Epoch: 6| Step: 8
Training loss: 0.3370157480239868
Validation loss: 1.6430819444758917

Epoch: 6| Step: 9
Training loss: 0.3645917773246765
Validation loss: 1.628176309088225

Epoch: 6| Step: 10
Training loss: 0.3614010512828827
Validation loss: 1.6029080831876366

Epoch: 6| Step: 11
Training loss: 0.2808877229690552
Validation loss: 1.6523327929999239

Epoch: 6| Step: 12
Training loss: 0.19005186855793
Validation loss: 1.6663272021919169

Epoch: 6| Step: 13
Training loss: 0.38409698009490967
Validation loss: 1.6440910857210878

Epoch: 330| Step: 0
Training loss: 0.3024282157421112
Validation loss: 1.6662202778682913

Epoch: 6| Step: 1
Training loss: 0.38446044921875
Validation loss: 1.675324365656863

Epoch: 6| Step: 2
Training loss: 0.32407546043395996
Validation loss: 1.691706863782739

Epoch: 6| Step: 3
Training loss: 0.44248658418655396
Validation loss: 1.6927618326679352

Epoch: 6| Step: 4
Training loss: 0.2797779440879822
Validation loss: 1.6611666038472166

Epoch: 6| Step: 5
Training loss: 0.3571963310241699
Validation loss: 1.6856181006277762

Epoch: 6| Step: 6
Training loss: 0.31841346621513367
Validation loss: 1.7132200002670288

Epoch: 6| Step: 7
Training loss: 0.18200534582138062
Validation loss: 1.6942894035770046

Epoch: 6| Step: 8
Training loss: 0.2637045681476593
Validation loss: 1.6794193457531672

Epoch: 6| Step: 9
Training loss: 0.37325847148895264
Validation loss: 1.6992013531346475

Epoch: 6| Step: 10
Training loss: 0.3076510429382324
Validation loss: 1.7118707497914631

Epoch: 6| Step: 11
Training loss: 0.4491230845451355
Validation loss: 1.6783825864074051

Epoch: 6| Step: 12
Training loss: 0.16562512516975403
Validation loss: 1.670261235647304

Epoch: 6| Step: 13
Training loss: 0.27612540125846863
Validation loss: 1.6901918085672523

Epoch: 331| Step: 0
Training loss: 0.2629459500312805
Validation loss: 1.6956970153316375

Epoch: 6| Step: 1
Training loss: 0.30031177401542664
Validation loss: 1.6808621652664677

Epoch: 6| Step: 2
Training loss: 0.3785076141357422
Validation loss: 1.647773906748782

Epoch: 6| Step: 3
Training loss: 0.19538617134094238
Validation loss: 1.661255936468801

Epoch: 6| Step: 4
Training loss: 0.139970064163208
Validation loss: 1.6457453004775509

Epoch: 6| Step: 5
Training loss: 0.21204712986946106
Validation loss: 1.6579831236152238

Epoch: 6| Step: 6
Training loss: 0.5128495693206787
Validation loss: 1.6936568271729253

Epoch: 6| Step: 7
Training loss: 0.2619893550872803
Validation loss: 1.6994348392691663

Epoch: 6| Step: 8
Training loss: 0.20774227380752563
Validation loss: 1.6653610083364672

Epoch: 6| Step: 9
Training loss: 0.3846600353717804
Validation loss: 1.6629433734442598

Epoch: 6| Step: 10
Training loss: 0.20617198944091797
Validation loss: 1.638365113607017

Epoch: 6| Step: 11
Training loss: 0.5351530313491821
Validation loss: 1.6298293541836482

Epoch: 6| Step: 12
Training loss: 0.28524211049079895
Validation loss: 1.6247296333312988

Epoch: 6| Step: 13
Training loss: 0.43073272705078125
Validation loss: 1.6111211430641912

Epoch: 332| Step: 0
Training loss: 0.17481423914432526
Validation loss: 1.6363224803760488

Epoch: 6| Step: 1
Training loss: 0.5566744804382324
Validation loss: 1.6158399120453866

Epoch: 6| Step: 2
Training loss: 0.34650009870529175
Validation loss: 1.6022907739044518

Epoch: 6| Step: 3
Training loss: 0.275604248046875
Validation loss: 1.5748084283644153

Epoch: 6| Step: 4
Training loss: 0.22694429755210876
Validation loss: 1.5967333188620947

Epoch: 6| Step: 5
Training loss: 0.28211450576782227
Validation loss: 1.6435036633604316

Epoch: 6| Step: 6
Training loss: 0.45309770107269287
Validation loss: 1.6510551988437612

Epoch: 6| Step: 7
Training loss: 0.2984705865383148
Validation loss: 1.682036776696482

Epoch: 6| Step: 8
Training loss: 0.3483507037162781
Validation loss: 1.693630164669406

Epoch: 6| Step: 9
Training loss: 0.12862077355384827
Validation loss: 1.717870102133802

Epoch: 6| Step: 10
Training loss: 0.39268025755882263
Validation loss: 1.7464966838077833

Epoch: 6| Step: 11
Training loss: 0.4907243251800537
Validation loss: 1.726733374339278

Epoch: 6| Step: 12
Training loss: 0.3281356692314148
Validation loss: 1.6907622557814403

Epoch: 6| Step: 13
Training loss: 0.2640916109085083
Validation loss: 1.6292210868609849

Epoch: 333| Step: 0
Training loss: 0.20880189538002014
Validation loss: 1.6507490027335383

Epoch: 6| Step: 1
Training loss: 0.2647573947906494
Validation loss: 1.622559501278785

Epoch: 6| Step: 2
Training loss: 0.528807520866394
Validation loss: 1.6400763437312136

Epoch: 6| Step: 3
Training loss: 0.3310670852661133
Validation loss: 1.6135576681424213

Epoch: 6| Step: 4
Training loss: 0.38751333951950073
Validation loss: 1.6240045114230084

Epoch: 6| Step: 5
Training loss: 0.2126857340335846
Validation loss: 1.6124551360325148

Epoch: 6| Step: 6
Training loss: 0.23929235339164734
Validation loss: 1.5819033281777495

Epoch: 6| Step: 7
Training loss: 0.2032020390033722
Validation loss: 1.594129418814054

Epoch: 6| Step: 8
Training loss: 0.24690628051757812
Validation loss: 1.6687754213169057

Epoch: 6| Step: 9
Training loss: 0.2648252844810486
Validation loss: 1.6420032535829852

Epoch: 6| Step: 10
Training loss: 0.5620526075363159
Validation loss: 1.6490258465531051

Epoch: 6| Step: 11
Training loss: 0.19784823060035706
Validation loss: 1.6212816699858634

Epoch: 6| Step: 12
Training loss: 0.3130553364753723
Validation loss: 1.615931434016074

Epoch: 6| Step: 13
Training loss: 0.5071918964385986
Validation loss: 1.6311781585857432

Epoch: 334| Step: 0
Training loss: 0.24162694811820984
Validation loss: 1.6300972213027298

Epoch: 6| Step: 1
Training loss: 0.2206375002861023
Validation loss: 1.6778470444422897

Epoch: 6| Step: 2
Training loss: 0.20398634672164917
Validation loss: 1.6442970563006658

Epoch: 6| Step: 3
Training loss: 0.32708480954170227
Validation loss: 1.6706489004114622

Epoch: 6| Step: 4
Training loss: 0.2450036108493805
Validation loss: 1.6326562153395785

Epoch: 6| Step: 5
Training loss: 0.3315208852291107
Validation loss: 1.660148637269133

Epoch: 6| Step: 6
Training loss: 0.26702791452407837
Validation loss: 1.6214049349548996

Epoch: 6| Step: 7
Training loss: 0.2268749326467514
Validation loss: 1.6389359569036832

Epoch: 6| Step: 8
Training loss: 0.4182385206222534
Validation loss: 1.5989938589834398

Epoch: 6| Step: 9
Training loss: 0.38423603773117065
Validation loss: 1.6147824602742349

Epoch: 6| Step: 10
Training loss: 0.2794707417488098
Validation loss: 1.5844743841437883

Epoch: 6| Step: 11
Training loss: 0.1356876641511917
Validation loss: 1.6324648100842711

Epoch: 6| Step: 12
Training loss: 0.331432044506073
Validation loss: 1.6563327876470422

Epoch: 6| Step: 13
Training loss: 0.522922933101654
Validation loss: 1.6481404176322363

Epoch: 335| Step: 0
Training loss: 0.2658993601799011
Validation loss: 1.6554852788166334

Epoch: 6| Step: 1
Training loss: 0.4102556109428406
Validation loss: 1.652520824504155

Epoch: 6| Step: 2
Training loss: 0.2633291482925415
Validation loss: 1.6383766692171815

Epoch: 6| Step: 3
Training loss: 0.2802584171295166
Validation loss: 1.6239641430557414

Epoch: 6| Step: 4
Training loss: 0.20635972917079926
Validation loss: 1.5973759030783048

Epoch: 6| Step: 5
Training loss: 0.2558554410934448
Validation loss: 1.5974346706944127

Epoch: 6| Step: 6
Training loss: 0.2564876973628998
Validation loss: 1.5903565960545694

Epoch: 6| Step: 7
Training loss: 0.38465359807014465
Validation loss: 1.641695814747964

Epoch: 6| Step: 8
Training loss: 0.15725542604923248
Validation loss: 1.6145197063364007

Epoch: 6| Step: 9
Training loss: 0.2450462430715561
Validation loss: 1.6238484574902443

Epoch: 6| Step: 10
Training loss: 0.2969217896461487
Validation loss: 1.6432910183424592

Epoch: 6| Step: 11
Training loss: 0.40486228466033936
Validation loss: 1.660888082237654

Epoch: 6| Step: 12
Training loss: 0.2810075283050537
Validation loss: 1.6178035941175235

Epoch: 6| Step: 13
Training loss: 0.2231057733297348
Validation loss: 1.5853569610144502

Epoch: 336| Step: 0
Training loss: 0.21500611305236816
Validation loss: 1.6396013254760413

Epoch: 6| Step: 1
Training loss: 0.33552733063697815
Validation loss: 1.6199513045690392

Epoch: 6| Step: 2
Training loss: 0.38153237104415894
Validation loss: 1.6082626427373579

Epoch: 6| Step: 3
Training loss: 0.261502742767334
Validation loss: 1.646634836350718

Epoch: 6| Step: 4
Training loss: 0.2723550796508789
Validation loss: 1.6694733647889988

Epoch: 6| Step: 5
Training loss: 0.3264177441596985
Validation loss: 1.7221866012901388

Epoch: 6| Step: 6
Training loss: 0.2734472155570984
Validation loss: 1.6743024113357707

Epoch: 6| Step: 7
Training loss: 0.30288782715797424
Validation loss: 1.6589670553002307

Epoch: 6| Step: 8
Training loss: 0.2344619482755661
Validation loss: 1.59426922182883

Epoch: 6| Step: 9
Training loss: 0.13591960072517395
Validation loss: 1.5386084311751909

Epoch: 6| Step: 10
Training loss: 0.192206472158432
Validation loss: 1.5814178489869641

Epoch: 6| Step: 11
Training loss: 0.377014696598053
Validation loss: 1.5079233672029229

Epoch: 6| Step: 12
Training loss: 0.15900395810604095
Validation loss: 1.5719296791220223

Epoch: 6| Step: 13
Training loss: 0.3931001126766205
Validation loss: 1.5925277958634079

Epoch: 337| Step: 0
Training loss: 0.2534435987472534
Validation loss: 1.5595418304525397

Epoch: 6| Step: 1
Training loss: 0.2757048010826111
Validation loss: 1.5914878479896053

Epoch: 6| Step: 2
Training loss: 0.4073337912559509
Validation loss: 1.5760907844830585

Epoch: 6| Step: 3
Training loss: 0.20651541650295258
Validation loss: 1.614200912496095

Epoch: 6| Step: 4
Training loss: 0.4156048893928528
Validation loss: 1.633734590263777

Epoch: 6| Step: 5
Training loss: 0.2083277404308319
Validation loss: 1.6101235369200348

Epoch: 6| Step: 6
Training loss: 0.33623701333999634
Validation loss: 1.6121341771976923

Epoch: 6| Step: 7
Training loss: 0.34636440873146057
Validation loss: 1.6120551081113919

Epoch: 6| Step: 8
Training loss: 0.2632691264152527
Validation loss: 1.6226145285432056

Epoch: 6| Step: 9
Training loss: 0.179048091173172
Validation loss: 1.6026402827232116

Epoch: 6| Step: 10
Training loss: 0.38900071382522583
Validation loss: 1.6394887431975333

Epoch: 6| Step: 11
Training loss: 0.3582710027694702
Validation loss: 1.6524574551531064

Epoch: 6| Step: 12
Training loss: 0.12440034747123718
Validation loss: 1.6501587058908196

Epoch: 6| Step: 13
Training loss: 0.19843637943267822
Validation loss: 1.656669444935296

Epoch: 338| Step: 0
Training loss: 0.30524542927742004
Validation loss: 1.6695104209325646

Epoch: 6| Step: 1
Training loss: 0.2798386812210083
Validation loss: 1.660049864040908

Epoch: 6| Step: 2
Training loss: 0.3326806426048279
Validation loss: 1.7004893672081731

Epoch: 6| Step: 3
Training loss: 0.3084302544593811
Validation loss: 1.6780199363667478

Epoch: 6| Step: 4
Training loss: 0.3723684847354889
Validation loss: 1.67000582397625

Epoch: 6| Step: 5
Training loss: 0.2701859772205353
Validation loss: 1.6475082443606468

Epoch: 6| Step: 6
Training loss: 0.30125129222869873
Validation loss: 1.6092297543761551

Epoch: 6| Step: 7
Training loss: 0.14703595638275146
Validation loss: 1.613438803662536

Epoch: 6| Step: 8
Training loss: 0.2652677595615387
Validation loss: 1.6028446548728532

Epoch: 6| Step: 9
Training loss: 0.4700477421283722
Validation loss: 1.6187123290954097

Epoch: 6| Step: 10
Training loss: 0.23813292384147644
Validation loss: 1.6305298343781502

Epoch: 6| Step: 11
Training loss: 0.514024019241333
Validation loss: 1.6489382738708167

Epoch: 6| Step: 12
Training loss: 0.34029674530029297
Validation loss: 1.6548044848185715

Epoch: 6| Step: 13
Training loss: 0.25370118021965027
Validation loss: 1.6527642255188317

Epoch: 339| Step: 0
Training loss: 0.21489283442497253
Validation loss: 1.6666866258908344

Epoch: 6| Step: 1
Training loss: 0.42437562346458435
Validation loss: 1.6524569834432294

Epoch: 6| Step: 2
Training loss: 0.3916822075843811
Validation loss: 1.6602815940815916

Epoch: 6| Step: 3
Training loss: 0.3863843083381653
Validation loss: 1.6790149404156594

Epoch: 6| Step: 4
Training loss: 0.1994398832321167
Validation loss: 1.6749096993477113

Epoch: 6| Step: 5
Training loss: 0.38083621859550476
Validation loss: 1.6663878502384308

Epoch: 6| Step: 6
Training loss: 0.20409910380840302
Validation loss: 1.644058560812345

Epoch: 6| Step: 7
Training loss: 0.1699317842721939
Validation loss: 1.635556194090074

Epoch: 6| Step: 8
Training loss: 0.32551857829093933
Validation loss: 1.633307828698107

Epoch: 6| Step: 9
Training loss: 0.11663977056741714
Validation loss: 1.6408086720333304

Epoch: 6| Step: 10
Training loss: 0.21792082488536835
Validation loss: 1.6681261242076915

Epoch: 6| Step: 11
Training loss: 0.19047407805919647
Validation loss: 1.6732562921380485

Epoch: 6| Step: 12
Training loss: 0.3584870398044586
Validation loss: 1.6830909111166512

Epoch: 6| Step: 13
Training loss: 0.2940637767314911
Validation loss: 1.6936154980813303

Epoch: 340| Step: 0
Training loss: 0.4399890899658203
Validation loss: 1.635935350130963

Epoch: 6| Step: 1
Training loss: 0.21411412954330444
Validation loss: 1.631900841189969

Epoch: 6| Step: 2
Training loss: 0.19927693903446198
Validation loss: 1.6214443432387484

Epoch: 6| Step: 3
Training loss: 0.21145379543304443
Validation loss: 1.6409396676607029

Epoch: 6| Step: 4
Training loss: 0.20573976635932922
Validation loss: 1.5962602810193134

Epoch: 6| Step: 5
Training loss: 0.2287825644016266
Validation loss: 1.6128690076130692

Epoch: 6| Step: 6
Training loss: 0.3613266348838806
Validation loss: 1.6052225328260852

Epoch: 6| Step: 7
Training loss: 0.1906064748764038
Validation loss: 1.6250037762426561

Epoch: 6| Step: 8
Training loss: 0.3328327536582947
Validation loss: 1.6401208677599508

Epoch: 6| Step: 9
Training loss: 0.3627084493637085
Validation loss: 1.6571560047006095

Epoch: 6| Step: 10
Training loss: 0.26707300543785095
Validation loss: 1.632445332824543

Epoch: 6| Step: 11
Training loss: 0.2588011920452118
Validation loss: 1.6562020214655067

Epoch: 6| Step: 12
Training loss: 0.3203652501106262
Validation loss: 1.661413827890991

Epoch: 6| Step: 13
Training loss: 0.19081304967403412
Validation loss: 1.644881115164808

Epoch: 341| Step: 0
Training loss: 0.3438045382499695
Validation loss: 1.6408317242899249

Epoch: 6| Step: 1
Training loss: 0.2960667014122009
Validation loss: 1.6374887042148139

Epoch: 6| Step: 2
Training loss: 0.32067710161209106
Validation loss: 1.6350888334294802

Epoch: 6| Step: 3
Training loss: 0.20618842542171478
Validation loss: 1.6002708353022093

Epoch: 6| Step: 4
Training loss: 0.2303362488746643
Validation loss: 1.6151167090221117

Epoch: 6| Step: 5
Training loss: 0.21326445043087006
Validation loss: 1.5967277781937712

Epoch: 6| Step: 6
Training loss: 0.11049121618270874
Validation loss: 1.5998919856163762

Epoch: 6| Step: 7
Training loss: 0.20750164985656738
Validation loss: 1.6038821294743528

Epoch: 6| Step: 8
Training loss: 0.2812155783176422
Validation loss: 1.621748471772799

Epoch: 6| Step: 9
Training loss: 0.2760995924472809
Validation loss: 1.6076621047912105

Epoch: 6| Step: 10
Training loss: 0.35484039783477783
Validation loss: 1.6410010514720794

Epoch: 6| Step: 11
Training loss: 0.23705974221229553
Validation loss: 1.6458032720832414

Epoch: 6| Step: 12
Training loss: 0.19158169627189636
Validation loss: 1.6330602476673741

Epoch: 6| Step: 13
Training loss: 0.2661227881908417
Validation loss: 1.605471496940941

Epoch: 342| Step: 0
Training loss: 0.3211585283279419
Validation loss: 1.5965177935938681

Epoch: 6| Step: 1
Training loss: 0.20801058411598206
Validation loss: 1.6078953768617363

Epoch: 6| Step: 2
Training loss: 0.28131040930747986
Validation loss: 1.5980966885884602

Epoch: 6| Step: 3
Training loss: 0.14360786974430084
Validation loss: 1.6153569881634047

Epoch: 6| Step: 4
Training loss: 0.2879520654678345
Validation loss: 1.624365004160071

Epoch: 6| Step: 5
Training loss: 0.2826058864593506
Validation loss: 1.646683903150661

Epoch: 6| Step: 6
Training loss: 0.2877928912639618
Validation loss: 1.6496863698446622

Epoch: 6| Step: 7
Training loss: 0.3294624388217926
Validation loss: 1.6899053447990007

Epoch: 6| Step: 8
Training loss: 0.3138130009174347
Validation loss: 1.6908940845920193

Epoch: 6| Step: 9
Training loss: 0.19628623127937317
Validation loss: 1.720216299897881

Epoch: 6| Step: 10
Training loss: 0.33355712890625
Validation loss: 1.6842111977197791

Epoch: 6| Step: 11
Training loss: 0.2718740701675415
Validation loss: 1.7100187527236117

Epoch: 6| Step: 12
Training loss: 0.19560670852661133
Validation loss: 1.6992249360648535

Epoch: 6| Step: 13
Training loss: 0.2922569513320923
Validation loss: 1.6967585176549933

Epoch: 343| Step: 0
Training loss: 0.19063887000083923
Validation loss: 1.6887891907845773

Epoch: 6| Step: 1
Training loss: 0.16380664706230164
Validation loss: 1.6867112087947067

Epoch: 6| Step: 2
Training loss: 0.33023157715797424
Validation loss: 1.6727502903630656

Epoch: 6| Step: 3
Training loss: 0.2069394290447235
Validation loss: 1.6273432521409885

Epoch: 6| Step: 4
Training loss: 0.22573286294937134
Validation loss: 1.6543103982043523

Epoch: 6| Step: 5
Training loss: 0.4302031993865967
Validation loss: 1.6237033451757124

Epoch: 6| Step: 6
Training loss: 0.24413374066352844
Validation loss: 1.610730658295334

Epoch: 6| Step: 7
Training loss: 0.20268592238426208
Validation loss: 1.6388055727046023

Epoch: 6| Step: 8
Training loss: 0.25336408615112305
Validation loss: 1.638786095444874

Epoch: 6| Step: 9
Training loss: 0.2179643213748932
Validation loss: 1.6353597987082698

Epoch: 6| Step: 10
Training loss: 0.36481308937072754
Validation loss: 1.6258674603636547

Epoch: 6| Step: 11
Training loss: 0.14396259188652039
Validation loss: 1.6639592660370695

Epoch: 6| Step: 12
Training loss: 0.31340447068214417
Validation loss: 1.6703601383393811

Epoch: 6| Step: 13
Training loss: 0.3127366602420807
Validation loss: 1.6802766015452724

Epoch: 344| Step: 0
Training loss: 0.3331151008605957
Validation loss: 1.656914303379674

Epoch: 6| Step: 1
Training loss: 0.30439454317092896
Validation loss: 1.6114548367838706

Epoch: 6| Step: 2
Training loss: 0.17057301104068756
Validation loss: 1.591353266469894

Epoch: 6| Step: 3
Training loss: 0.4116615653038025
Validation loss: 1.5905053295114988

Epoch: 6| Step: 4
Training loss: 0.23031708598136902
Validation loss: 1.588697664199337

Epoch: 6| Step: 5
Training loss: 0.24126417934894562
Validation loss: 1.5969181829883206

Epoch: 6| Step: 6
Training loss: 0.18760156631469727
Validation loss: 1.615013732705065

Epoch: 6| Step: 7
Training loss: 0.34468960762023926
Validation loss: 1.6427495133492254

Epoch: 6| Step: 8
Training loss: 0.3090038001537323
Validation loss: 1.6172269339202552

Epoch: 6| Step: 9
Training loss: 0.20859605073928833
Validation loss: 1.6161215151509931

Epoch: 6| Step: 10
Training loss: 0.3088230490684509
Validation loss: 1.6460402152871574

Epoch: 6| Step: 11
Training loss: 0.2277725487947464
Validation loss: 1.6525742751295849

Epoch: 6| Step: 12
Training loss: 0.2209416925907135
Validation loss: 1.6579361461823987

Epoch: 6| Step: 13
Training loss: 0.3397027850151062
Validation loss: 1.6356577334865448

Epoch: 345| Step: 0
Training loss: 0.46856194734573364
Validation loss: 1.6672588535534438

Epoch: 6| Step: 1
Training loss: 0.1689419001340866
Validation loss: 1.6797603817396267

Epoch: 6| Step: 2
Training loss: 0.2722092866897583
Validation loss: 1.6788218867394231

Epoch: 6| Step: 3
Training loss: 0.2903061807155609
Validation loss: 1.6665934452446558

Epoch: 6| Step: 4
Training loss: 0.18387670814990997
Validation loss: 1.6851648874180292

Epoch: 6| Step: 5
Training loss: 0.3197175860404968
Validation loss: 1.6797424516370218

Epoch: 6| Step: 6
Training loss: 0.24802574515342712
Validation loss: 1.66324193375085

Epoch: 6| Step: 7
Training loss: 0.2522249221801758
Validation loss: 1.6552944452531877

Epoch: 6| Step: 8
Training loss: 0.3391505479812622
Validation loss: 1.639223878101636

Epoch: 6| Step: 9
Training loss: 0.3164021968841553
Validation loss: 1.6336471957545127

Epoch: 6| Step: 10
Training loss: 0.2276417315006256
Validation loss: 1.6731353844365766

Epoch: 6| Step: 11
Training loss: 0.1899956464767456
Validation loss: 1.6847918712964622

Epoch: 6| Step: 12
Training loss: 0.4149664640426636
Validation loss: 1.6989688668199765

Epoch: 6| Step: 13
Training loss: 0.44701555371284485
Validation loss: 1.749049009815339

Epoch: 346| Step: 0
Training loss: 0.49512362480163574
Validation loss: 1.6971358368473668

Epoch: 6| Step: 1
Training loss: 0.21958962082862854
Validation loss: 1.6593936028019074

Epoch: 6| Step: 2
Training loss: 0.2265891283750534
Validation loss: 1.6535835766023206

Epoch: 6| Step: 3
Training loss: 0.2533966302871704
Validation loss: 1.6557023038146317

Epoch: 6| Step: 4
Training loss: 0.38627105951309204
Validation loss: 1.6388203251746394

Epoch: 6| Step: 5
Training loss: 0.3313961625099182
Validation loss: 1.648577836252028

Epoch: 6| Step: 6
Training loss: 0.27230969071388245
Validation loss: 1.6760479057988813

Epoch: 6| Step: 7
Training loss: 0.26785874366760254
Validation loss: 1.6503165319401731

Epoch: 6| Step: 8
Training loss: 0.2959171533584595
Validation loss: 1.6712004933305966

Epoch: 6| Step: 9
Training loss: 0.28485190868377686
Validation loss: 1.6646785928357033

Epoch: 6| Step: 10
Training loss: 0.1504231095314026
Validation loss: 1.6788204805825346

Epoch: 6| Step: 11
Training loss: 0.31740933656692505
Validation loss: 1.6758541419941893

Epoch: 6| Step: 12
Training loss: 0.28826671838760376
Validation loss: 1.671562308906227

Epoch: 6| Step: 13
Training loss: 0.3783597946166992
Validation loss: 1.6654430704732095

Epoch: 347| Step: 0
Training loss: 0.26185187697410583
Validation loss: 1.647005409322759

Epoch: 6| Step: 1
Training loss: 0.3236510455608368
Validation loss: 1.6395190326116418

Epoch: 6| Step: 2
Training loss: 0.34863996505737305
Validation loss: 1.6414900729733128

Epoch: 6| Step: 3
Training loss: 0.26011165976524353
Validation loss: 1.6480270931797643

Epoch: 6| Step: 4
Training loss: 0.3549092411994934
Validation loss: 1.631124299059632

Epoch: 6| Step: 5
Training loss: 0.34394994378089905
Validation loss: 1.6382829168791413

Epoch: 6| Step: 6
Training loss: 0.21717557311058044
Validation loss: 1.6449686122196976

Epoch: 6| Step: 7
Training loss: 0.4727530777454376
Validation loss: 1.6588874337493733

Epoch: 6| Step: 8
Training loss: 0.2822273373603821
Validation loss: 1.6329345876170742

Epoch: 6| Step: 9
Training loss: 0.35569053888320923
Validation loss: 1.661547274999721

Epoch: 6| Step: 10
Training loss: 0.1486937403678894
Validation loss: 1.678422224137091

Epoch: 6| Step: 11
Training loss: 0.4127991795539856
Validation loss: 1.6604217431878532

Epoch: 6| Step: 12
Training loss: 0.23954147100448608
Validation loss: 1.6438036400784728

Epoch: 6| Step: 13
Training loss: 0.20592086017131805
Validation loss: 1.6366258269997054

Epoch: 348| Step: 0
Training loss: 0.35370171070098877
Validation loss: 1.649844483662677

Epoch: 6| Step: 1
Training loss: 0.3940085470676422
Validation loss: 1.6659720508001183

Epoch: 6| Step: 2
Training loss: 0.24160899221897125
Validation loss: 1.6371127174746605

Epoch: 6| Step: 3
Training loss: 0.2875787019729614
Validation loss: 1.6135089166702763

Epoch: 6| Step: 4
Training loss: 0.2519957423210144
Validation loss: 1.5627043080586258

Epoch: 6| Step: 5
Training loss: 0.2729780673980713
Validation loss: 1.6098089679594962

Epoch: 6| Step: 6
Training loss: 0.22363924980163574
Validation loss: 1.6404232312274236

Epoch: 6| Step: 7
Training loss: 0.27474039793014526
Validation loss: 1.6302842632416756

Epoch: 6| Step: 8
Training loss: 0.20464864373207092
Validation loss: 1.6672129182405369

Epoch: 6| Step: 9
Training loss: 0.3327059745788574
Validation loss: 1.6432731190035421

Epoch: 6| Step: 10
Training loss: 0.17778626084327698
Validation loss: 1.6497609692235147

Epoch: 6| Step: 11
Training loss: 0.18892186880111694
Validation loss: 1.6508854422518002

Epoch: 6| Step: 12
Training loss: 0.39178383350372314
Validation loss: 1.6779780003332323

Epoch: 6| Step: 13
Training loss: 0.2072177529335022
Validation loss: 1.6546952275819675

Epoch: 349| Step: 0
Training loss: 0.2698323428630829
Validation loss: 1.6592799771216609

Epoch: 6| Step: 1
Training loss: 0.1846233308315277
Validation loss: 1.6377336414911414

Epoch: 6| Step: 2
Training loss: 0.21311461925506592
Validation loss: 1.6340695427310081

Epoch: 6| Step: 3
Training loss: 0.205484539270401
Validation loss: 1.6482737807817356

Epoch: 6| Step: 4
Training loss: 0.3204876780509949
Validation loss: 1.6177586522153629

Epoch: 6| Step: 5
Training loss: 0.18664301931858063
Validation loss: 1.6397468005457232

Epoch: 6| Step: 6
Training loss: 0.31703123450279236
Validation loss: 1.6209168600779709

Epoch: 6| Step: 7
Training loss: 0.2484937310218811
Validation loss: 1.6337320381595242

Epoch: 6| Step: 8
Training loss: 0.18882793188095093
Validation loss: 1.6431629875654816

Epoch: 6| Step: 9
Training loss: 0.31575584411621094
Validation loss: 1.6584922639272546

Epoch: 6| Step: 10
Training loss: 0.3679482638835907
Validation loss: 1.6540236062900995

Epoch: 6| Step: 11
Training loss: 0.194242462515831
Validation loss: 1.6256985625913065

Epoch: 6| Step: 12
Training loss: 0.2946716248989105
Validation loss: 1.6137343773277857

Epoch: 6| Step: 13
Training loss: 0.28220322728157043
Validation loss: 1.6170981789147982

Epoch: 350| Step: 0
Training loss: 0.3574918508529663
Validation loss: 1.6081454779512139

Epoch: 6| Step: 1
Training loss: 0.2864971458911896
Validation loss: 1.6413133708379601

Epoch: 6| Step: 2
Training loss: 0.2873256206512451
Validation loss: 1.6499591694083264

Epoch: 6| Step: 3
Training loss: 0.2117135226726532
Validation loss: 1.644127111281118

Epoch: 6| Step: 4
Training loss: 0.13852077722549438
Validation loss: 1.6461011312341178

Epoch: 6| Step: 5
Training loss: 0.23485814034938812
Validation loss: 1.6316686727667367

Epoch: 6| Step: 6
Training loss: 0.24692973494529724
Validation loss: 1.6705320022439445

Epoch: 6| Step: 7
Training loss: 0.325418084859848
Validation loss: 1.6552684948008547

Epoch: 6| Step: 8
Training loss: 0.35719966888427734
Validation loss: 1.6647696072055447

Epoch: 6| Step: 9
Training loss: 0.18135660886764526
Validation loss: 1.6366551230030675

Epoch: 6| Step: 10
Training loss: 0.2607688307762146
Validation loss: 1.6429602843458935

Epoch: 6| Step: 11
Training loss: 0.20418745279312134
Validation loss: 1.5871446337751163

Epoch: 6| Step: 12
Training loss: 0.19817791879177094
Validation loss: 1.588549760080153

Epoch: 6| Step: 13
Training loss: 0.4154590368270874
Validation loss: 1.6338151321616223

Epoch: 351| Step: 0
Training loss: 0.23763686418533325
Validation loss: 1.5946079108022875

Epoch: 6| Step: 1
Training loss: 0.2971936762332916
Validation loss: 1.6311847112512077

Epoch: 6| Step: 2
Training loss: 0.2854223847389221
Validation loss: 1.6177148947151758

Epoch: 6| Step: 3
Training loss: 0.24420449137687683
Validation loss: 1.6367564291082404

Epoch: 6| Step: 4
Training loss: 0.2870948612689972
Validation loss: 1.6388291966530584

Epoch: 6| Step: 5
Training loss: 0.17035003006458282
Validation loss: 1.6590619805038616

Epoch: 6| Step: 6
Training loss: 0.19290342926979065
Validation loss: 1.69303878917489

Epoch: 6| Step: 7
Training loss: 0.26217928528785706
Validation loss: 1.6800429821014404

Epoch: 6| Step: 8
Training loss: 0.13603943586349487
Validation loss: 1.6375647411551526

Epoch: 6| Step: 9
Training loss: 0.25383466482162476
Validation loss: 1.6596124133756083

Epoch: 6| Step: 10
Training loss: 0.4915917217731476
Validation loss: 1.6438753040887977

Epoch: 6| Step: 11
Training loss: 0.23759174346923828
Validation loss: 1.6429140490870322

Epoch: 6| Step: 12
Training loss: 0.34759727120399475
Validation loss: 1.6329008661290652

Epoch: 6| Step: 13
Training loss: 0.35581445693969727
Validation loss: 1.6166050818658644

Epoch: 352| Step: 0
Training loss: 0.20832788944244385
Validation loss: 1.5879479633864535

Epoch: 6| Step: 1
Training loss: 0.22152799367904663
Validation loss: 1.6140702232237785

Epoch: 6| Step: 2
Training loss: 0.25639277696609497
Validation loss: 1.5803003464975665

Epoch: 6| Step: 3
Training loss: 0.2649981677532196
Validation loss: 1.591543387341243

Epoch: 6| Step: 4
Training loss: 0.3629920482635498
Validation loss: 1.6273044655399937

Epoch: 6| Step: 5
Training loss: 0.17897705733776093
Validation loss: 1.614049570534819

Epoch: 6| Step: 6
Training loss: 0.3238598108291626
Validation loss: 1.6622674984316672

Epoch: 6| Step: 7
Training loss: 0.25892388820648193
Validation loss: 1.664184925376728

Epoch: 6| Step: 8
Training loss: 0.2546236515045166
Validation loss: 1.5963551126500612

Epoch: 6| Step: 9
Training loss: 0.3227962851524353
Validation loss: 1.6284437935839418

Epoch: 6| Step: 10
Training loss: 0.1771078109741211
Validation loss: 1.614849994900406

Epoch: 6| Step: 11
Training loss: 0.25176459550857544
Validation loss: 1.6140016163549116

Epoch: 6| Step: 12
Training loss: 0.1874839961528778
Validation loss: 1.615560011197162

Epoch: 6| Step: 13
Training loss: 0.3232952654361725
Validation loss: 1.5837583695688555

Epoch: 353| Step: 0
Training loss: 0.41748395562171936
Validation loss: 1.5997867007409372

Epoch: 6| Step: 1
Training loss: 0.37710678577423096
Validation loss: 1.5989439513093682

Epoch: 6| Step: 2
Training loss: 0.3205059766769409
Validation loss: 1.595499025878086

Epoch: 6| Step: 3
Training loss: 0.3935778737068176
Validation loss: 1.5733722832895094

Epoch: 6| Step: 4
Training loss: 0.2874380648136139
Validation loss: 1.5705266485932052

Epoch: 6| Step: 5
Training loss: 0.14169684052467346
Validation loss: 1.5715255000258004

Epoch: 6| Step: 6
Training loss: 0.16186250746250153
Validation loss: 1.5811596890931487

Epoch: 6| Step: 7
Training loss: 0.14229784905910492
Validation loss: 1.5653797490622408

Epoch: 6| Step: 8
Training loss: 0.25910842418670654
Validation loss: 1.5678771875237907

Epoch: 6| Step: 9
Training loss: 0.25767460465431213
Validation loss: 1.638120093653279

Epoch: 6| Step: 10
Training loss: 0.18504367768764496
Validation loss: 1.6220290096857215

Epoch: 6| Step: 11
Training loss: 0.12854664027690887
Validation loss: 1.69299957829137

Epoch: 6| Step: 12
Training loss: 0.21736684441566467
Validation loss: 1.6617711615818802

Epoch: 6| Step: 13
Training loss: 0.17044703662395477
Validation loss: 1.6866473805519842

Epoch: 354| Step: 0
Training loss: 0.30298739671707153
Validation loss: 1.7409985808915989

Epoch: 6| Step: 1
Training loss: 0.2931515574455261
Validation loss: 1.7293714348987868

Epoch: 6| Step: 2
Training loss: 0.23822049796581268
Validation loss: 1.6934063883237942

Epoch: 6| Step: 3
Training loss: 0.25788575410842896
Validation loss: 1.7144005016614032

Epoch: 6| Step: 4
Training loss: 0.2475569248199463
Validation loss: 1.6542265915101575

Epoch: 6| Step: 5
Training loss: 0.2633136510848999
Validation loss: 1.6430088858450613

Epoch: 6| Step: 6
Training loss: 0.35368141531944275
Validation loss: 1.6154533336239476

Epoch: 6| Step: 7
Training loss: 0.1691236048936844
Validation loss: 1.6071470886148431

Epoch: 6| Step: 8
Training loss: 0.31989872455596924
Validation loss: 1.5986948308124338

Epoch: 6| Step: 9
Training loss: 0.17242762446403503
Validation loss: 1.5726624816976569

Epoch: 6| Step: 10
Training loss: 0.33641424775123596
Validation loss: 1.5547942487142419

Epoch: 6| Step: 11
Training loss: 0.1862563192844391
Validation loss: 1.5845560450707712

Epoch: 6| Step: 12
Training loss: 0.22571438550949097
Validation loss: 1.599550151055859

Epoch: 6| Step: 13
Training loss: 0.33867180347442627
Validation loss: 1.62075375997892

Epoch: 355| Step: 0
Training loss: 0.2441934049129486
Validation loss: 1.6169741845900012

Epoch: 6| Step: 1
Training loss: 0.2877543568611145
Validation loss: 1.6436443956949378

Epoch: 6| Step: 2
Training loss: 0.4225112795829773
Validation loss: 1.6508695771617274

Epoch: 6| Step: 3
Training loss: 0.23824524879455566
Validation loss: 1.6621467836441532

Epoch: 6| Step: 4
Training loss: 0.20394277572631836
Validation loss: 1.6648741768252464

Epoch: 6| Step: 5
Training loss: 0.23680350184440613
Validation loss: 1.6582378136214388

Epoch: 6| Step: 6
Training loss: 0.20055800676345825
Validation loss: 1.6722367053390832

Epoch: 6| Step: 7
Training loss: 0.31146520376205444
Validation loss: 1.6622112297242688

Epoch: 6| Step: 8
Training loss: 0.1594347059726715
Validation loss: 1.657112067745578

Epoch: 6| Step: 9
Training loss: 0.23313431441783905
Validation loss: 1.6494243798717376

Epoch: 6| Step: 10
Training loss: 0.3119845986366272
Validation loss: 1.650886353626046

Epoch: 6| Step: 11
Training loss: 0.23293495178222656
Validation loss: 1.6598419117671188

Epoch: 6| Step: 12
Training loss: 0.19007766246795654
Validation loss: 1.6296279282980068

Epoch: 6| Step: 13
Training loss: 0.22740991413593292
Validation loss: 1.7084412126130955

Epoch: 356| Step: 0
Training loss: 0.2877747714519501
Validation loss: 1.6744417913498417

Epoch: 6| Step: 1
Training loss: 0.44496414065361023
Validation loss: 1.6697462681801087

Epoch: 6| Step: 2
Training loss: 0.2117399424314499
Validation loss: 1.6493187437775314

Epoch: 6| Step: 3
Training loss: 0.09527282416820526
Validation loss: 1.6511862047256962

Epoch: 6| Step: 4
Training loss: 0.23329412937164307
Validation loss: 1.6188101845402871

Epoch: 6| Step: 5
Training loss: 0.29204657673835754
Validation loss: 1.597482177519029

Epoch: 6| Step: 6
Training loss: 0.23625990748405457
Validation loss: 1.6161790291468303

Epoch: 6| Step: 7
Training loss: 0.16356030106544495
Validation loss: 1.608449484712334

Epoch: 6| Step: 8
Training loss: 0.22735825181007385
Validation loss: 1.6121561155524304

Epoch: 6| Step: 9
Training loss: 0.17057177424430847
Validation loss: 1.571999631902223

Epoch: 6| Step: 10
Training loss: 0.270233690738678
Validation loss: 1.5635251755355506

Epoch: 6| Step: 11
Training loss: 0.38873445987701416
Validation loss: 1.6019706123618669

Epoch: 6| Step: 12
Training loss: 0.302473783493042
Validation loss: 1.5642598021414973

Epoch: 6| Step: 13
Training loss: 0.226675346493721
Validation loss: 1.5638142196081017

Epoch: 357| Step: 0
Training loss: 0.15841254591941833
Validation loss: 1.5608863702384375

Epoch: 6| Step: 1
Training loss: 0.1943090856075287
Validation loss: 1.55456837402877

Epoch: 6| Step: 2
Training loss: 0.4349029064178467
Validation loss: 1.545554434099505

Epoch: 6| Step: 3
Training loss: 0.2622298300266266
Validation loss: 1.5664029852036507

Epoch: 6| Step: 4
Training loss: 0.23029816150665283
Validation loss: 1.6161524993117138

Epoch: 6| Step: 5
Training loss: 0.2950485944747925
Validation loss: 1.6296707250738656

Epoch: 6| Step: 6
Training loss: 0.3950697183609009
Validation loss: 1.6159772296105661

Epoch: 6| Step: 7
Training loss: 0.25727033615112305
Validation loss: 1.6490872688190912

Epoch: 6| Step: 8
Training loss: 0.2521589398384094
Validation loss: 1.6782092407185545

Epoch: 6| Step: 9
Training loss: 0.2518468499183655
Validation loss: 1.6649393670020565

Epoch: 6| Step: 10
Training loss: 0.19080296158790588
Validation loss: 1.6611997542842742

Epoch: 6| Step: 11
Training loss: 0.24066226184368134
Validation loss: 1.6400611682604718

Epoch: 6| Step: 12
Training loss: 0.20776963233947754
Validation loss: 1.6326799373472891

Epoch: 6| Step: 13
Training loss: 0.1047673225402832
Validation loss: 1.6545821594935592

Epoch: 358| Step: 0
Training loss: 0.22583088278770447
Validation loss: 1.626622885786077

Epoch: 6| Step: 1
Training loss: 0.17237114906311035
Validation loss: 1.6443211827226865

Epoch: 6| Step: 2
Training loss: 0.072389617562294
Validation loss: 1.651408016040761

Epoch: 6| Step: 3
Training loss: 0.21830105781555176
Validation loss: 1.639967454377041

Epoch: 6| Step: 4
Training loss: 0.2513312101364136
Validation loss: 1.636679276343315

Epoch: 6| Step: 5
Training loss: 0.2180003821849823
Validation loss: 1.6230146884918213

Epoch: 6| Step: 6
Training loss: 0.3050694465637207
Validation loss: 1.6651567771870603

Epoch: 6| Step: 7
Training loss: 0.2981654405593872
Validation loss: 1.653278140611546

Epoch: 6| Step: 8
Training loss: 0.25531479716300964
Validation loss: 1.6441069315838557

Epoch: 6| Step: 9
Training loss: 0.2205708771944046
Validation loss: 1.6139004230499268

Epoch: 6| Step: 10
Training loss: 0.2767665982246399
Validation loss: 1.6185097309850878

Epoch: 6| Step: 11
Training loss: 0.23237746953964233
Validation loss: 1.6073670207813222

Epoch: 6| Step: 12
Training loss: 0.261870801448822
Validation loss: 1.6060643696015882

Epoch: 6| Step: 13
Training loss: 0.2523420751094818
Validation loss: 1.6190349542966453

Epoch: 359| Step: 0
Training loss: 0.25665855407714844
Validation loss: 1.594941040521027

Epoch: 6| Step: 1
Training loss: 0.2989192008972168
Validation loss: 1.6378878124298588

Epoch: 6| Step: 2
Training loss: 0.15674933791160583
Validation loss: 1.6448509539327314

Epoch: 6| Step: 3
Training loss: 0.12817201018333435
Validation loss: 1.6457740465799968

Epoch: 6| Step: 4
Training loss: 0.2600201666355133
Validation loss: 1.6170938950712963

Epoch: 6| Step: 5
Training loss: 0.17355868220329285
Validation loss: 1.6206438272230086

Epoch: 6| Step: 6
Training loss: 0.16741997003555298
Validation loss: 1.6133033050003873

Epoch: 6| Step: 7
Training loss: 0.31950652599334717
Validation loss: 1.6045445024326284

Epoch: 6| Step: 8
Training loss: 0.247014582157135
Validation loss: 1.5877774569296068

Epoch: 6| Step: 9
Training loss: 0.22068846225738525
Validation loss: 1.5970317048411216

Epoch: 6| Step: 10
Training loss: 0.2821885049343109
Validation loss: 1.5702545578761766

Epoch: 6| Step: 11
Training loss: 0.20880652964115143
Validation loss: 1.580106173792193

Epoch: 6| Step: 12
Training loss: 0.24870744347572327
Validation loss: 1.5864568141198927

Epoch: 6| Step: 13
Training loss: 0.07707013934850693
Validation loss: 1.5907849240046676

Epoch: 360| Step: 0
Training loss: 0.2546832859516144
Validation loss: 1.6207630236943562

Epoch: 6| Step: 1
Training loss: 0.24367868900299072
Validation loss: 1.629794600189373

Epoch: 6| Step: 2
Training loss: 0.24351491034030914
Validation loss: 1.6230102828753892

Epoch: 6| Step: 3
Training loss: 0.23987548053264618
Validation loss: 1.639385413098079

Epoch: 6| Step: 4
Training loss: 0.20785388350486755
Validation loss: 1.5917131298331804

Epoch: 6| Step: 5
Training loss: 0.2623302936553955
Validation loss: 1.640957058116954

Epoch: 6| Step: 6
Training loss: 0.22001363337039948
Validation loss: 1.6190461253607145

Epoch: 6| Step: 7
Training loss: 0.19624724984169006
Validation loss: 1.642946659877736

Epoch: 6| Step: 8
Training loss: 0.24492879211902618
Validation loss: 1.6678389323654996

Epoch: 6| Step: 9
Training loss: 0.20043623447418213
Validation loss: 1.61503295488255

Epoch: 6| Step: 10
Training loss: 0.18565090000629425
Validation loss: 1.6255176349352765

Epoch: 6| Step: 11
Training loss: 0.15996377170085907
Validation loss: 1.648054979180777

Epoch: 6| Step: 12
Training loss: 0.1669827401638031
Validation loss: 1.6518332035310808

Epoch: 6| Step: 13
Training loss: 0.3139943480491638
Validation loss: 1.667431995432864

Epoch: 361| Step: 0
Training loss: 0.2115541696548462
Validation loss: 1.6429692327335317

Epoch: 6| Step: 1
Training loss: 0.27336180210113525
Validation loss: 1.642049438209944

Epoch: 6| Step: 2
Training loss: 0.2985558807849884
Validation loss: 1.65704684616417

Epoch: 6| Step: 3
Training loss: 0.07985363900661469
Validation loss: 1.6447108932720718

Epoch: 6| Step: 4
Training loss: 0.31206297874450684
Validation loss: 1.6457306813168269

Epoch: 6| Step: 5
Training loss: 0.23636417090892792
Validation loss: 1.6233721035783009

Epoch: 6| Step: 6
Training loss: 0.143124058842659
Validation loss: 1.6593557596206665

Epoch: 6| Step: 7
Training loss: 0.1739397943019867
Validation loss: 1.6362783152570006

Epoch: 6| Step: 8
Training loss: 0.26329392194747925
Validation loss: 1.6357887816685501

Epoch: 6| Step: 9
Training loss: 0.19790790975093842
Validation loss: 1.6255836044588396

Epoch: 6| Step: 10
Training loss: 0.30219346284866333
Validation loss: 1.6150313141525432

Epoch: 6| Step: 11
Training loss: 0.269359827041626
Validation loss: 1.582384891407464

Epoch: 6| Step: 12
Training loss: 0.28946709632873535
Validation loss: 1.618538429660182

Epoch: 6| Step: 13
Training loss: 0.25440406799316406
Validation loss: 1.6115118906062136

Epoch: 362| Step: 0
Training loss: 0.2412954568862915
Validation loss: 1.6507220588704592

Epoch: 6| Step: 1
Training loss: 0.10396517068147659
Validation loss: 1.6353762559993292

Epoch: 6| Step: 2
Training loss: 0.3258155584335327
Validation loss: 1.6399252683885637

Epoch: 6| Step: 3
Training loss: 0.16421593725681305
Validation loss: 1.6533442620308167

Epoch: 6| Step: 4
Training loss: 0.2950727939605713
Validation loss: 1.6946789961989208

Epoch: 6| Step: 5
Training loss: 0.391784131526947
Validation loss: 1.6525078460734377

Epoch: 6| Step: 6
Training loss: 0.29304447770118713
Validation loss: 1.6156574590231783

Epoch: 6| Step: 7
Training loss: 0.1254163384437561
Validation loss: 1.5959129000222811

Epoch: 6| Step: 8
Training loss: 0.18668590486049652
Validation loss: 1.5745106512500393

Epoch: 6| Step: 9
Training loss: 0.2769877314567566
Validation loss: 1.5529723257146857

Epoch: 6| Step: 10
Training loss: 0.13960979878902435
Validation loss: 1.5843109174441266

Epoch: 6| Step: 11
Training loss: 0.1711808443069458
Validation loss: 1.5756427395728327

Epoch: 6| Step: 12
Training loss: 0.1658349633216858
Validation loss: 1.5872555343053674

Epoch: 6| Step: 13
Training loss: 0.3649359941482544
Validation loss: 1.564921058634276

Epoch: 363| Step: 0
Training loss: 0.14633560180664062
Validation loss: 1.5833797531743203

Epoch: 6| Step: 1
Training loss: 0.2173786163330078
Validation loss: 1.6068399542121476

Epoch: 6| Step: 2
Training loss: 0.1189214289188385
Validation loss: 1.6149647652461965

Epoch: 6| Step: 3
Training loss: 0.3975110650062561
Validation loss: 1.6080069964931858

Epoch: 6| Step: 4
Training loss: 0.14226269721984863
Validation loss: 1.6060142952908751

Epoch: 6| Step: 5
Training loss: 0.1771162748336792
Validation loss: 1.624603194575156

Epoch: 6| Step: 6
Training loss: 0.269675076007843
Validation loss: 1.6206419660199074

Epoch: 6| Step: 7
Training loss: 0.16548073291778564
Validation loss: 1.6462339239735757

Epoch: 6| Step: 8
Training loss: 0.16778577864170074
Validation loss: 1.6575460331414336

Epoch: 6| Step: 9
Training loss: 0.18832367658615112
Validation loss: 1.640352577291509

Epoch: 6| Step: 10
Training loss: 0.214781254529953
Validation loss: 1.638389197728967

Epoch: 6| Step: 11
Training loss: 0.22661785781383514
Validation loss: 1.6655837464076217

Epoch: 6| Step: 12
Training loss: 0.29845255613327026
Validation loss: 1.6544488847896617

Epoch: 6| Step: 13
Training loss: 0.11338785290718079
Validation loss: 1.6224710499086687

Epoch: 364| Step: 0
Training loss: 0.13404521346092224
Validation loss: 1.6624867916107178

Epoch: 6| Step: 1
Training loss: 0.1693369448184967
Validation loss: 1.5949149106138496

Epoch: 6| Step: 2
Training loss: 0.26384246349334717
Validation loss: 1.622895989366757

Epoch: 6| Step: 3
Training loss: 0.20078414678573608
Validation loss: 1.6399127949950516

Epoch: 6| Step: 4
Training loss: 0.23878701031208038
Validation loss: 1.6080663896376086

Epoch: 6| Step: 5
Training loss: 0.16592185199260712
Validation loss: 1.637266723058557

Epoch: 6| Step: 6
Training loss: 0.18350589275360107
Validation loss: 1.6194450150253952

Epoch: 6| Step: 7
Training loss: 0.2244744598865509
Validation loss: 1.6206838559078913

Epoch: 6| Step: 8
Training loss: 0.27839145064353943
Validation loss: 1.6717458989030571

Epoch: 6| Step: 9
Training loss: 0.21933969855308533
Validation loss: 1.6507478785771195

Epoch: 6| Step: 10
Training loss: 0.23244808614253998
Validation loss: 1.6347774638924548

Epoch: 6| Step: 11
Training loss: 0.1735648810863495
Validation loss: 1.632005254427592

Epoch: 6| Step: 12
Training loss: 0.16752851009368896
Validation loss: 1.6002214031834756

Epoch: 6| Step: 13
Training loss: 0.11543643474578857
Validation loss: 1.612922118556115

Epoch: 365| Step: 0
Training loss: 0.14653579890727997
Validation loss: 1.6036409370360836

Epoch: 6| Step: 1
Training loss: 0.25370875000953674
Validation loss: 1.611228536534053

Epoch: 6| Step: 2
Training loss: 0.1923862099647522
Validation loss: 1.5822750445335143

Epoch: 6| Step: 3
Training loss: 0.2252577543258667
Validation loss: 1.569463849067688

Epoch: 6| Step: 4
Training loss: 0.31217867136001587
Validation loss: 1.5422504204575733

Epoch: 6| Step: 5
Training loss: 0.22604413330554962
Validation loss: 1.5780394615665558

Epoch: 6| Step: 6
Training loss: 0.1593562513589859
Validation loss: 1.570458391661285

Epoch: 6| Step: 7
Training loss: 0.2653942108154297
Validation loss: 1.5315033915222331

Epoch: 6| Step: 8
Training loss: 0.23080693185329437
Validation loss: 1.5177409738622687

Epoch: 6| Step: 9
Training loss: 0.17671528458595276
Validation loss: 1.579991684165052

Epoch: 6| Step: 10
Training loss: 0.13597461581230164
Validation loss: 1.5626760349478772

Epoch: 6| Step: 11
Training loss: 0.19187073409557343
Validation loss: 1.5596864197843818

Epoch: 6| Step: 12
Training loss: 0.16809052228927612
Validation loss: 1.567859527885273

Epoch: 6| Step: 13
Training loss: 0.24696043133735657
Validation loss: 1.5718470350388558

Epoch: 366| Step: 0
Training loss: 0.21262210607528687
Validation loss: 1.5191880438917427

Epoch: 6| Step: 1
Training loss: 0.14698636531829834
Validation loss: 1.557472223876625

Epoch: 6| Step: 2
Training loss: 0.4071296453475952
Validation loss: 1.5590320902486001

Epoch: 6| Step: 3
Training loss: 0.20513905584812164
Validation loss: 1.5616211186173141

Epoch: 6| Step: 4
Training loss: 0.33300620317459106
Validation loss: 1.5812084649198799

Epoch: 6| Step: 5
Training loss: 0.11049532890319824
Validation loss: 1.5972021651524368

Epoch: 6| Step: 6
Training loss: 0.15055911242961884
Validation loss: 1.6171716118371615

Epoch: 6| Step: 7
Training loss: 0.12102152407169342
Validation loss: 1.6317120175207815

Epoch: 6| Step: 8
Training loss: 0.26096001267433167
Validation loss: 1.6658575009274226

Epoch: 6| Step: 9
Training loss: 0.183654323220253
Validation loss: 1.6488522457820114

Epoch: 6| Step: 10
Training loss: 0.25814956426620483
Validation loss: 1.6479036320922196

Epoch: 6| Step: 11
Training loss: 0.18483500182628632
Validation loss: 1.6289836693835515

Epoch: 6| Step: 12
Training loss: 0.2975654900074005
Validation loss: 1.6136756943118187

Epoch: 6| Step: 13
Training loss: 0.23112890124320984
Validation loss: 1.6459542102711175

Epoch: 367| Step: 0
Training loss: 0.23559017479419708
Validation loss: 1.612411646432774

Epoch: 6| Step: 1
Training loss: 0.19380566477775574
Validation loss: 1.5902861254189604

Epoch: 6| Step: 2
Training loss: 0.302150696516037
Validation loss: 1.5908506224232335

Epoch: 6| Step: 3
Training loss: 0.266046941280365
Validation loss: 1.578656409376411

Epoch: 6| Step: 4
Training loss: 0.09963694959878922
Validation loss: 1.554235278919179

Epoch: 6| Step: 5
Training loss: 0.1838020533323288
Validation loss: 1.5277103954745876

Epoch: 6| Step: 6
Training loss: 0.2963992953300476
Validation loss: 1.540210295748967

Epoch: 6| Step: 7
Training loss: 0.23438948392868042
Validation loss: 1.5649974769161594

Epoch: 6| Step: 8
Training loss: 0.13564220070838928
Validation loss: 1.616417605389831

Epoch: 6| Step: 9
Training loss: 0.29374632239341736
Validation loss: 1.6021065506883847

Epoch: 6| Step: 10
Training loss: 0.25073570013046265
Validation loss: 1.636100056350872

Epoch: 6| Step: 11
Training loss: 0.31395798921585083
Validation loss: 1.654025859730218

Epoch: 6| Step: 12
Training loss: 0.36700689792633057
Validation loss: 1.6169960857719503

Epoch: 6| Step: 13
Training loss: 0.24512630701065063
Validation loss: 1.5745348199721305

Epoch: 368| Step: 0
Training loss: 0.2757894992828369
Validation loss: 1.5321466166486022

Epoch: 6| Step: 1
Training loss: 0.15917620062828064
Validation loss: 1.555128348770962

Epoch: 6| Step: 2
Training loss: 0.1843767762184143
Validation loss: 1.5563186701907907

Epoch: 6| Step: 3
Training loss: 0.1617785543203354
Validation loss: 1.5558702176617039

Epoch: 6| Step: 4
Training loss: 0.21531224250793457
Validation loss: 1.5727449014622679

Epoch: 6| Step: 5
Training loss: 0.2971668243408203
Validation loss: 1.5477953662154496

Epoch: 6| Step: 6
Training loss: 0.19467324018478394
Validation loss: 1.5713689096512333

Epoch: 6| Step: 7
Training loss: 0.20825263857841492
Validation loss: 1.5658424131331905

Epoch: 6| Step: 8
Training loss: 0.2015262246131897
Validation loss: 1.593720446350754

Epoch: 6| Step: 9
Training loss: 0.15608136355876923
Validation loss: 1.5971023574952157

Epoch: 6| Step: 10
Training loss: 0.15194089710712433
Validation loss: 1.5989543404630435

Epoch: 6| Step: 11
Training loss: 0.2556312680244446
Validation loss: 1.6338613802386868

Epoch: 6| Step: 12
Training loss: 0.4577957093715668
Validation loss: 1.6470694939295452

Epoch: 6| Step: 13
Training loss: 0.26880383491516113
Validation loss: 1.6283968443511634

Epoch: 369| Step: 0
Training loss: 0.1301809847354889
Validation loss: 1.6328129101825017

Epoch: 6| Step: 1
Training loss: 0.15542086958885193
Validation loss: 1.5992841643671836

Epoch: 6| Step: 2
Training loss: 0.20459479093551636
Validation loss: 1.5974413105236587

Epoch: 6| Step: 3
Training loss: 0.2876429259777069
Validation loss: 1.5718984962791525

Epoch: 6| Step: 4
Training loss: 0.20866918563842773
Validation loss: 1.599983576805361

Epoch: 6| Step: 5
Training loss: 0.22544923424720764
Validation loss: 1.5616956910779398

Epoch: 6| Step: 6
Training loss: 0.35651880502700806
Validation loss: 1.5905373474603057

Epoch: 6| Step: 7
Training loss: 0.17485973238945007
Validation loss: 1.5742518235278387

Epoch: 6| Step: 8
Training loss: 0.12363708019256592
Validation loss: 1.5587688325553812

Epoch: 6| Step: 9
Training loss: 0.17699271440505981
Validation loss: 1.5467643814702188

Epoch: 6| Step: 10
Training loss: 0.21103529632091522
Validation loss: 1.556072477371462

Epoch: 6| Step: 11
Training loss: 0.2528412342071533
Validation loss: 1.5794748337038103

Epoch: 6| Step: 12
Training loss: 0.26724591851234436
Validation loss: 1.589920623328096

Epoch: 6| Step: 13
Training loss: 0.21906831860542297
Validation loss: 1.6099009770219044

Epoch: 370| Step: 0
Training loss: 0.20161136984825134
Validation loss: 1.6624769767125447

Epoch: 6| Step: 1
Training loss: 0.4091840982437134
Validation loss: 1.6826046910337222

Epoch: 6| Step: 2
Training loss: 0.37635019421577454
Validation loss: 1.680859556762121

Epoch: 6| Step: 3
Training loss: 0.3442443609237671
Validation loss: 1.5943266922427761

Epoch: 6| Step: 4
Training loss: 0.25061801075935364
Validation loss: 1.5735293114057152

Epoch: 6| Step: 5
Training loss: 0.16854774951934814
Validation loss: 1.5332564769252655

Epoch: 6| Step: 6
Training loss: 0.1725127100944519
Validation loss: 1.4862320359035204

Epoch: 6| Step: 7
Training loss: 0.34556013345718384
Validation loss: 1.4841260153760192

Epoch: 6| Step: 8
Training loss: 0.2236696481704712
Validation loss: 1.5037934844211867

Epoch: 6| Step: 9
Training loss: 0.23009200394153595
Validation loss: 1.464007160996878

Epoch: 6| Step: 10
Training loss: 0.11407870799303055
Validation loss: 1.4924725024930892

Epoch: 6| Step: 11
Training loss: 0.27315303683280945
Validation loss: 1.5349083728687738

Epoch: 6| Step: 12
Training loss: 0.34611082077026367
Validation loss: 1.5465096863367225

Epoch: 6| Step: 13
Training loss: 0.1479746252298355
Validation loss: 1.564537823841136

Epoch: 371| Step: 0
Training loss: 0.1317419856786728
Validation loss: 1.5749015795287264

Epoch: 6| Step: 1
Training loss: 0.27734875679016113
Validation loss: 1.5915139157284972

Epoch: 6| Step: 2
Training loss: 0.26952487230300903
Validation loss: 1.5704007969107678

Epoch: 6| Step: 3
Training loss: 0.15860521793365479
Validation loss: 1.6088328784511936

Epoch: 6| Step: 4
Training loss: 0.3737875521183014
Validation loss: 1.6156647256625596

Epoch: 6| Step: 5
Training loss: 0.14378947019577026
Validation loss: 1.5647984294481174

Epoch: 6| Step: 6
Training loss: 0.14825643599033356
Validation loss: 1.5896144861816077

Epoch: 6| Step: 7
Training loss: 0.1163998395204544
Validation loss: 1.5269186573643838

Epoch: 6| Step: 8
Training loss: 0.2739933431148529
Validation loss: 1.509561095186459

Epoch: 6| Step: 9
Training loss: 0.15142425894737244
Validation loss: 1.5339025899928103

Epoch: 6| Step: 10
Training loss: 0.20448926091194153
Validation loss: 1.506804342551898

Epoch: 6| Step: 11
Training loss: 0.151023268699646
Validation loss: 1.504200671308784

Epoch: 6| Step: 12
Training loss: 0.12094603478908539
Validation loss: 1.4912944980846938

Epoch: 6| Step: 13
Training loss: 0.15245559811592102
Validation loss: 1.5183170303221671

Epoch: 372| Step: 0
Training loss: 0.1369597315788269
Validation loss: 1.5367367998246224

Epoch: 6| Step: 1
Training loss: 0.24858161807060242
Validation loss: 1.495584875024775

Epoch: 6| Step: 2
Training loss: 0.20933640003204346
Validation loss: 1.554771723285798

Epoch: 6| Step: 3
Training loss: 0.23958566784858704
Validation loss: 1.5495032930886874

Epoch: 6| Step: 4
Training loss: 0.18520325422286987
Validation loss: 1.5963123703515658

Epoch: 6| Step: 5
Training loss: 0.11497749388217926
Validation loss: 1.5916867666347052

Epoch: 6| Step: 6
Training loss: 0.14412008225917816
Validation loss: 1.6267660151245773

Epoch: 6| Step: 7
Training loss: 0.12671509385108948
Validation loss: 1.6018573199549029

Epoch: 6| Step: 8
Training loss: 0.2097873091697693
Validation loss: 1.6385227249514671

Epoch: 6| Step: 9
Training loss: 0.3530162572860718
Validation loss: 1.6325784255099554

Epoch: 6| Step: 10
Training loss: 0.2162686586380005
Validation loss: 1.6218024069263088

Epoch: 6| Step: 11
Training loss: 0.1685008406639099
Validation loss: 1.6068607030376312

Epoch: 6| Step: 12
Training loss: 0.2765830159187317
Validation loss: 1.5674520025971115

Epoch: 6| Step: 13
Training loss: 0.2963755130767822
Validation loss: 1.6059466869600358

Epoch: 373| Step: 0
Training loss: 0.23966190218925476
Validation loss: 1.5889669246571039

Epoch: 6| Step: 1
Training loss: 0.2601461708545685
Validation loss: 1.6071438353548768

Epoch: 6| Step: 2
Training loss: 0.25240468978881836
Validation loss: 1.6127359187731178

Epoch: 6| Step: 3
Training loss: 0.1754509061574936
Validation loss: 1.5993676698336037

Epoch: 6| Step: 4
Training loss: 0.19094465672969818
Validation loss: 1.6233867047935404

Epoch: 6| Step: 5
Training loss: 0.21007411181926727
Validation loss: 1.6310768511987501

Epoch: 6| Step: 6
Training loss: 0.1279570311307907
Validation loss: 1.591844335679085

Epoch: 6| Step: 7
Training loss: 0.2252124845981598
Validation loss: 1.6055429186872257

Epoch: 6| Step: 8
Training loss: 0.3866303563117981
Validation loss: 1.6026323277463195

Epoch: 6| Step: 9
Training loss: 0.18865105509757996
Validation loss: 1.6489644230052989

Epoch: 6| Step: 10
Training loss: 0.16953197121620178
Validation loss: 1.6575745139070737

Epoch: 6| Step: 11
Training loss: 0.2211352288722992
Validation loss: 1.653083638478351

Epoch: 6| Step: 12
Training loss: 0.16522493958473206
Validation loss: 1.6393687513566786

Epoch: 6| Step: 13
Training loss: 0.1682329773902893
Validation loss: 1.6243961370119484

Epoch: 374| Step: 0
Training loss: 0.1977483332157135
Validation loss: 1.63563851323179

Epoch: 6| Step: 1
Training loss: 0.2446085512638092
Validation loss: 1.6156446478700126

Epoch: 6| Step: 2
Training loss: 0.3159042000770569
Validation loss: 1.600759663889485

Epoch: 6| Step: 3
Training loss: 0.19157660007476807
Validation loss: 1.5903950929641724

Epoch: 6| Step: 4
Training loss: 0.19875068962574005
Validation loss: 1.614381633138144

Epoch: 6| Step: 5
Training loss: 0.1400713175535202
Validation loss: 1.5615638968765095

Epoch: 6| Step: 6
Training loss: 0.1961209774017334
Validation loss: 1.5606963378126903

Epoch: 6| Step: 7
Training loss: 0.25156429409980774
Validation loss: 1.5594431982245496

Epoch: 6| Step: 8
Training loss: 0.22754639387130737
Validation loss: 1.5543290261299378

Epoch: 6| Step: 9
Training loss: 0.15075844526290894
Validation loss: 1.5429628414492453

Epoch: 6| Step: 10
Training loss: 0.3410874605178833
Validation loss: 1.5244899219082249

Epoch: 6| Step: 11
Training loss: 0.2571900188922882
Validation loss: 1.5152464912783714

Epoch: 6| Step: 12
Training loss: 0.1727292537689209
Validation loss: 1.5304384231567383

Epoch: 6| Step: 13
Training loss: 0.2861500382423401
Validation loss: 1.5449268035991217

Epoch: 375| Step: 0
Training loss: 0.29617607593536377
Validation loss: 1.5480840295873664

Epoch: 6| Step: 1
Training loss: 0.266873836517334
Validation loss: 1.590938893697595

Epoch: 6| Step: 2
Training loss: 0.15775062143802643
Validation loss: 1.5906794942835325

Epoch: 6| Step: 3
Training loss: 0.1889474242925644
Validation loss: 1.5752262556424705

Epoch: 6| Step: 4
Training loss: 0.16057348251342773
Validation loss: 1.5466861250579997

Epoch: 6| Step: 5
Training loss: 0.1835610270500183
Validation loss: 1.5749593216885802

Epoch: 6| Step: 6
Training loss: 0.16962549090385437
Validation loss: 1.5746852326136764

Epoch: 6| Step: 7
Training loss: 0.2009960263967514
Validation loss: 1.5974776078295965

Epoch: 6| Step: 8
Training loss: 0.1670825481414795
Validation loss: 1.598357564659529

Epoch: 6| Step: 9
Training loss: 0.2781222462654114
Validation loss: 1.603667671962451

Epoch: 6| Step: 10
Training loss: 0.3439676761627197
Validation loss: 1.6045800921737507

Epoch: 6| Step: 11
Training loss: 0.26939061284065247
Validation loss: 1.6104549823268768

Epoch: 6| Step: 12
Training loss: 0.08593034744262695
Validation loss: 1.5848853677831671

Epoch: 6| Step: 13
Training loss: 0.1881566345691681
Validation loss: 1.612230916177073

Epoch: 376| Step: 0
Training loss: 0.16838522255420685
Validation loss: 1.6413366820222588

Epoch: 6| Step: 1
Training loss: 0.29426321387290955
Validation loss: 1.6211862897360196

Epoch: 6| Step: 2
Training loss: 0.10550297796726227
Validation loss: 1.6001486368076776

Epoch: 6| Step: 3
Training loss: 0.22129090130329132
Validation loss: 1.6065631515236312

Epoch: 6| Step: 4
Training loss: 0.25211042165756226
Validation loss: 1.5772875810182223

Epoch: 6| Step: 5
Training loss: 0.1705106943845749
Validation loss: 1.5478709282413605

Epoch: 6| Step: 6
Training loss: 0.16033640503883362
Validation loss: 1.5227053511527278

Epoch: 6| Step: 7
Training loss: 0.12924039363861084
Validation loss: 1.5388363022958078

Epoch: 6| Step: 8
Training loss: 0.218833327293396
Validation loss: 1.515826835427233

Epoch: 6| Step: 9
Training loss: 0.16671225428581238
Validation loss: 1.5333582803767214

Epoch: 6| Step: 10
Training loss: 0.12606246769428253
Validation loss: 1.53188354738297

Epoch: 6| Step: 11
Training loss: 0.1180606409907341
Validation loss: 1.5510634888884842

Epoch: 6| Step: 12
Training loss: 0.2330152988433838
Validation loss: 1.5748536945671163

Epoch: 6| Step: 13
Training loss: 0.1741938591003418
Validation loss: 1.5592164672831053

Epoch: 377| Step: 0
Training loss: 0.13558505475521088
Validation loss: 1.5471485314830657

Epoch: 6| Step: 1
Training loss: 0.16006779670715332
Validation loss: 1.5849873827349754

Epoch: 6| Step: 2
Training loss: 0.19947069883346558
Validation loss: 1.5780690549522318

Epoch: 6| Step: 3
Training loss: 0.21318697929382324
Validation loss: 1.5761955239439522

Epoch: 6| Step: 4
Training loss: 0.18429015576839447
Validation loss: 1.6218650161579091

Epoch: 6| Step: 5
Training loss: 0.1641213595867157
Validation loss: 1.5946196650946012

Epoch: 6| Step: 6
Training loss: 0.22509604692459106
Validation loss: 1.579766546526263

Epoch: 6| Step: 7
Training loss: 0.15887489914894104
Validation loss: 1.5620622378523632

Epoch: 6| Step: 8
Training loss: 0.2560449540615082
Validation loss: 1.5925687871953493

Epoch: 6| Step: 9
Training loss: 0.16329744458198547
Validation loss: 1.590167651894272

Epoch: 6| Step: 10
Training loss: 0.22047525644302368
Validation loss: 1.5933552339512815

Epoch: 6| Step: 11
Training loss: 0.266735315322876
Validation loss: 1.6116882729273971

Epoch: 6| Step: 12
Training loss: 0.24333976209163666
Validation loss: 1.5850435418467368

Epoch: 6| Step: 13
Training loss: 0.16800814867019653
Validation loss: 1.6148964922915223

Epoch: 378| Step: 0
Training loss: 0.19633996486663818
Validation loss: 1.6088753900220316

Epoch: 6| Step: 1
Training loss: 0.17920799553394318
Validation loss: 1.5839026576729232

Epoch: 6| Step: 2
Training loss: 0.23388239741325378
Validation loss: 1.614972383745255

Epoch: 6| Step: 3
Training loss: 0.24196560680866241
Validation loss: 1.589358312468375

Epoch: 6| Step: 4
Training loss: 0.10889200866222382
Validation loss: 1.6310222917987454

Epoch: 6| Step: 5
Training loss: 0.10095652937889099
Validation loss: 1.6052880633261897

Epoch: 6| Step: 6
Training loss: 0.2852044105529785
Validation loss: 1.6144919895356702

Epoch: 6| Step: 7
Training loss: 0.2793198823928833
Validation loss: 1.586365976641255

Epoch: 6| Step: 8
Training loss: 0.28637057542800903
Validation loss: 1.6096184766420754

Epoch: 6| Step: 9
Training loss: 0.21010196208953857
Validation loss: 1.6113787248570433

Epoch: 6| Step: 10
Training loss: 0.3058180510997772
Validation loss: 1.5776697589505104

Epoch: 6| Step: 11
Training loss: 0.13699951767921448
Validation loss: 1.5714387547585271

Epoch: 6| Step: 12
Training loss: 0.1578163355588913
Validation loss: 1.5572298111454133

Epoch: 6| Step: 13
Training loss: 0.15683600306510925
Validation loss: 1.585401996489494

Epoch: 379| Step: 0
Training loss: 0.13470804691314697
Validation loss: 1.5669447132336196

Epoch: 6| Step: 1
Training loss: 0.15564459562301636
Validation loss: 1.5813573406588646

Epoch: 6| Step: 2
Training loss: 0.22321148216724396
Validation loss: 1.551952568433618

Epoch: 6| Step: 3
Training loss: 0.2006101757287979
Validation loss: 1.557064374287923

Epoch: 6| Step: 4
Training loss: 0.23197954893112183
Validation loss: 1.5670611845549716

Epoch: 6| Step: 5
Training loss: 0.1628122329711914
Validation loss: 1.5949562313736125

Epoch: 6| Step: 6
Training loss: 0.15030145645141602
Validation loss: 1.5768271812828638

Epoch: 6| Step: 7
Training loss: 0.1873839944601059
Validation loss: 1.5961494497073594

Epoch: 6| Step: 8
Training loss: 0.19220152497291565
Validation loss: 1.6035014044853948

Epoch: 6| Step: 9
Training loss: 0.16377264261245728
Validation loss: 1.5731943589384838

Epoch: 6| Step: 10
Training loss: 0.24865536391735077
Validation loss: 1.571127067330063

Epoch: 6| Step: 11
Training loss: 0.27053728699684143
Validation loss: 1.6031758182792253

Epoch: 6| Step: 12
Training loss: 0.24454063177108765
Validation loss: 1.5562450834499892

Epoch: 6| Step: 13
Training loss: 0.20234933495521545
Validation loss: 1.5969589756381126

Epoch: 380| Step: 0
Training loss: 0.1679474413394928
Validation loss: 1.5712468893297258

Epoch: 6| Step: 1
Training loss: 0.1890287846326828
Validation loss: 1.5620161564119401

Epoch: 6| Step: 2
Training loss: 0.09271824359893799
Validation loss: 1.5601616559490081

Epoch: 6| Step: 3
Training loss: 0.09569355845451355
Validation loss: 1.5415310680225331

Epoch: 6| Step: 4
Training loss: 0.23613955080509186
Validation loss: 1.5437727910216137

Epoch: 6| Step: 5
Training loss: 0.18482692539691925
Validation loss: 1.5544609677407049

Epoch: 6| Step: 6
Training loss: 0.25213804841041565
Validation loss: 1.5356301184623473

Epoch: 6| Step: 7
Training loss: 0.17131850123405457
Validation loss: 1.544846547547207

Epoch: 6| Step: 8
Training loss: 0.17120973765850067
Validation loss: 1.5160366514677643

Epoch: 6| Step: 9
Training loss: 0.20598319172859192
Validation loss: 1.5348914874497281

Epoch: 6| Step: 10
Training loss: 0.12390989065170288
Validation loss: 1.5191331832639632

Epoch: 6| Step: 11
Training loss: 0.19516810774803162
Validation loss: 1.5222161335329856

Epoch: 6| Step: 12
Training loss: 0.24922141432762146
Validation loss: 1.4968117808782926

Epoch: 6| Step: 13
Training loss: 0.10541001707315445
Validation loss: 1.4975536459235734

Epoch: 381| Step: 0
Training loss: 0.12316835671663284
Validation loss: 1.4741293935365574

Epoch: 6| Step: 1
Training loss: 0.10397209972143173
Validation loss: 1.5146427192995626

Epoch: 6| Step: 2
Training loss: 0.16947640478610992
Validation loss: 1.5250582079733572

Epoch: 6| Step: 3
Training loss: 0.16154706478118896
Validation loss: 1.5399234589710031

Epoch: 6| Step: 4
Training loss: 0.27870234847068787
Validation loss: 1.5396724465072795

Epoch: 6| Step: 5
Training loss: 0.3403815031051636
Validation loss: 1.532456487737676

Epoch: 6| Step: 6
Training loss: 0.06385176628828049
Validation loss: 1.5275631104746172

Epoch: 6| Step: 7
Training loss: 0.13712021708488464
Validation loss: 1.5430963295762257

Epoch: 6| Step: 8
Training loss: 0.0816783457994461
Validation loss: 1.5472326458141368

Epoch: 6| Step: 9
Training loss: 0.20930418372154236
Validation loss: 1.5520322874028196

Epoch: 6| Step: 10
Training loss: 0.1345745027065277
Validation loss: 1.504389742369293

Epoch: 6| Step: 11
Training loss: 0.16011613607406616
Validation loss: 1.5293866831769225

Epoch: 6| Step: 12
Training loss: 0.2555274963378906
Validation loss: 1.5247707418216172

Epoch: 6| Step: 13
Training loss: 0.23928096890449524
Validation loss: 1.5110487822563416

Epoch: 382| Step: 0
Training loss: 0.1519479751586914
Validation loss: 1.4886470199913107

Epoch: 6| Step: 1
Training loss: 0.2694336175918579
Validation loss: 1.5229988585236252

Epoch: 6| Step: 2
Training loss: 0.21052034199237823
Validation loss: 1.4969499867449525

Epoch: 6| Step: 3
Training loss: 0.134253591299057
Validation loss: 1.5030733270029868

Epoch: 6| Step: 4
Training loss: 0.1351008117198944
Validation loss: 1.4971981785630668

Epoch: 6| Step: 5
Training loss: 0.2940060496330261
Validation loss: 1.5284508876903082

Epoch: 6| Step: 6
Training loss: 0.13034994900226593
Validation loss: 1.5127549530357443

Epoch: 6| Step: 7
Training loss: 0.15032100677490234
Validation loss: 1.4805221942163282

Epoch: 6| Step: 8
Training loss: 0.23412445187568665
Validation loss: 1.5258621682402909

Epoch: 6| Step: 9
Training loss: 0.11087557673454285
Validation loss: 1.5072393391721992

Epoch: 6| Step: 10
Training loss: 0.17248347401618958
Validation loss: 1.532269714340087

Epoch: 6| Step: 11
Training loss: 0.16816926002502441
Validation loss: 1.5098684103258195

Epoch: 6| Step: 12
Training loss: 0.17362192273139954
Validation loss: 1.5233649643518592

Epoch: 6| Step: 13
Training loss: 0.21450085937976837
Validation loss: 1.520296130129086

Epoch: 383| Step: 0
Training loss: 0.20278650522232056
Validation loss: 1.584518583871985

Epoch: 6| Step: 1
Training loss: 0.1359555870294571
Validation loss: 1.5764258241140714

Epoch: 6| Step: 2
Training loss: 0.18571755290031433
Validation loss: 1.575490136300364

Epoch: 6| Step: 3
Training loss: 0.23536285758018494
Validation loss: 1.5490780773983206

Epoch: 6| Step: 4
Training loss: 0.1209559515118599
Validation loss: 1.5765022949505878

Epoch: 6| Step: 5
Training loss: 0.1453324854373932
Validation loss: 1.5512987003531507

Epoch: 6| Step: 6
Training loss: 0.26451921463012695
Validation loss: 1.5567065964462936

Epoch: 6| Step: 7
Training loss: 0.15892766416072845
Validation loss: 1.551562472056317

Epoch: 6| Step: 8
Training loss: 0.23241041600704193
Validation loss: 1.529001619226189

Epoch: 6| Step: 9
Training loss: 0.13577131927013397
Validation loss: 1.5426649034664195

Epoch: 6| Step: 10
Training loss: 0.19998382031917572
Validation loss: 1.5523701431930705

Epoch: 6| Step: 11
Training loss: 0.1450883150100708
Validation loss: 1.5274641411278838

Epoch: 6| Step: 12
Training loss: 0.14954763650894165
Validation loss: 1.5548858027304373

Epoch: 6| Step: 13
Training loss: 0.22790111601352692
Validation loss: 1.5461660835050768

Epoch: 384| Step: 0
Training loss: 0.1738540679216385
Validation loss: 1.5954021266711655

Epoch: 6| Step: 1
Training loss: 0.19310346245765686
Validation loss: 1.56326457377403

Epoch: 6| Step: 2
Training loss: 0.1675477772951126
Validation loss: 1.596068209858351

Epoch: 6| Step: 3
Training loss: 0.09873059391975403
Validation loss: 1.5818300067737538

Epoch: 6| Step: 4
Training loss: 0.35388320684432983
Validation loss: 1.600616455078125

Epoch: 6| Step: 5
Training loss: 0.24561858177185059
Validation loss: 1.6117190186695387

Epoch: 6| Step: 6
Training loss: 0.10338161140680313
Validation loss: 1.5823790360522527

Epoch: 6| Step: 7
Training loss: 0.22951170802116394
Validation loss: 1.5816195780231106

Epoch: 6| Step: 8
Training loss: 0.09077899903059006
Validation loss: 1.5767165614712624

Epoch: 6| Step: 9
Training loss: 0.14785140752792358
Validation loss: 1.5815777547897831

Epoch: 6| Step: 10
Training loss: 0.11598566919565201
Validation loss: 1.6127790481813493

Epoch: 6| Step: 11
Training loss: 0.14946556091308594
Validation loss: 1.5766195648459977

Epoch: 6| Step: 12
Training loss: 0.20335653424263
Validation loss: 1.6005754881007697

Epoch: 6| Step: 13
Training loss: 0.17784170806407928
Validation loss: 1.5992348758123254

Epoch: 385| Step: 0
Training loss: 0.2012939602136612
Validation loss: 1.624920432285596

Epoch: 6| Step: 1
Training loss: 0.24229560792446136
Validation loss: 1.6003831426302593

Epoch: 6| Step: 2
Training loss: 0.29231202602386475
Validation loss: 1.5852527349225936

Epoch: 6| Step: 3
Training loss: 0.11170841753482819
Validation loss: 1.5546032100595453

Epoch: 6| Step: 4
Training loss: 0.18990087509155273
Validation loss: 1.5537654225544264

Epoch: 6| Step: 5
Training loss: 0.17351537942886353
Validation loss: 1.5439075603280017

Epoch: 6| Step: 6
Training loss: 0.24524401128292084
Validation loss: 1.5844052812104583

Epoch: 6| Step: 7
Training loss: 0.19362929463386536
Validation loss: 1.5597938613225055

Epoch: 6| Step: 8
Training loss: 0.13274264335632324
Validation loss: 1.578292800534156

Epoch: 6| Step: 9
Training loss: 0.13790836930274963
Validation loss: 1.6152350056555964

Epoch: 6| Step: 10
Training loss: 0.17963823676109314
Validation loss: 1.5447713995492587

Epoch: 6| Step: 11
Training loss: 0.1646302044391632
Validation loss: 1.5580463024877733

Epoch: 6| Step: 12
Training loss: 0.2794422209262848
Validation loss: 1.5623565848155687

Epoch: 6| Step: 13
Training loss: 0.1067204624414444
Validation loss: 1.5962814349000172

Epoch: 386| Step: 0
Training loss: 0.1677224040031433
Validation loss: 1.589189543518969

Epoch: 6| Step: 1
Training loss: 0.17838209867477417
Validation loss: 1.5747458319510184

Epoch: 6| Step: 2
Training loss: 0.26710963249206543
Validation loss: 1.586292605246267

Epoch: 6| Step: 3
Training loss: 0.19266155362129211
Validation loss: 1.5482706126346384

Epoch: 6| Step: 4
Training loss: 0.16925765573978424
Validation loss: 1.5373973397798435

Epoch: 6| Step: 5
Training loss: 0.1283905804157257
Validation loss: 1.561738864068062

Epoch: 6| Step: 6
Training loss: 0.20863884687423706
Validation loss: 1.5540907895693215

Epoch: 6| Step: 7
Training loss: 0.23851346969604492
Validation loss: 1.5139790734937113

Epoch: 6| Step: 8
Training loss: 0.10632888227701187
Validation loss: 1.4746962670356996

Epoch: 6| Step: 9
Training loss: 0.18593065440654755
Validation loss: 1.5036432999436573

Epoch: 6| Step: 10
Training loss: 0.24093224108219147
Validation loss: 1.550953281823025

Epoch: 6| Step: 11
Training loss: 0.12509480118751526
Validation loss: 1.5816167528911302

Epoch: 6| Step: 12
Training loss: 0.2818475067615509
Validation loss: 1.602828336018388

Epoch: 6| Step: 13
Training loss: 0.1664183884859085
Validation loss: 1.5865593110361407

Epoch: 387| Step: 0
Training loss: 0.159505695104599
Validation loss: 1.553898819031254

Epoch: 6| Step: 1
Training loss: 0.17854414880275726
Validation loss: 1.5960705229031142

Epoch: 6| Step: 2
Training loss: 0.1495526134967804
Validation loss: 1.5952835006098594

Epoch: 6| Step: 3
Training loss: 0.22658590972423553
Validation loss: 1.6208910403713104

Epoch: 6| Step: 4
Training loss: 0.12103880941867828
Validation loss: 1.594515960703614

Epoch: 6| Step: 5
Training loss: 0.15108723938465118
Validation loss: 1.60531827967654

Epoch: 6| Step: 6
Training loss: 0.2134026736021042
Validation loss: 1.582842871706973

Epoch: 6| Step: 7
Training loss: 0.2821780741214752
Validation loss: 1.5964983304341633

Epoch: 6| Step: 8
Training loss: 0.24743306636810303
Validation loss: 1.5498558462307017

Epoch: 6| Step: 9
Training loss: 0.2731388509273529
Validation loss: 1.539181616998488

Epoch: 6| Step: 10
Training loss: 0.12431858479976654
Validation loss: 1.4966765026892386

Epoch: 6| Step: 11
Training loss: 0.13596627116203308
Validation loss: 1.4525847614452403

Epoch: 6| Step: 12
Training loss: 0.09540268033742905
Validation loss: 1.4836358511319725

Epoch: 6| Step: 13
Training loss: 0.14606036245822906
Validation loss: 1.4608756290969027

Epoch: 388| Step: 0
Training loss: 0.24884459376335144
Validation loss: 1.4652195784353441

Epoch: 6| Step: 1
Training loss: 0.20379488170146942
Validation loss: 1.493477152880802

Epoch: 6| Step: 2
Training loss: 0.19220274686813354
Validation loss: 1.5132552833967312

Epoch: 6| Step: 3
Training loss: 0.19105371832847595
Validation loss: 1.481543694773028

Epoch: 6| Step: 4
Training loss: 0.10776547342538834
Validation loss: 1.526047009293751

Epoch: 6| Step: 5
Training loss: 0.22158803045749664
Validation loss: 1.5103816216991794

Epoch: 6| Step: 6
Training loss: 0.17068251967430115
Validation loss: 1.5381657743966708

Epoch: 6| Step: 7
Training loss: 0.18232528865337372
Validation loss: 1.5564283632463025

Epoch: 6| Step: 8
Training loss: 0.1817030906677246
Validation loss: 1.5835375824282247

Epoch: 6| Step: 9
Training loss: 0.23798306286334991
Validation loss: 1.5547728743604434

Epoch: 6| Step: 10
Training loss: 0.1264839917421341
Validation loss: 1.5820011887499081

Epoch: 6| Step: 11
Training loss: 0.1345253884792328
Validation loss: 1.6004247639768867

Epoch: 6| Step: 12
Training loss: 0.16479013860225677
Validation loss: 1.5801702596807992

Epoch: 6| Step: 13
Training loss: 0.15650473535060883
Validation loss: 1.5947133853871336

Epoch: 389| Step: 0
Training loss: 0.13673309981822968
Validation loss: 1.6045605873548856

Epoch: 6| Step: 1
Training loss: 0.2686288356781006
Validation loss: 1.61398898401568

Epoch: 6| Step: 2
Training loss: 0.29586660861968994
Validation loss: 1.6045419669920398

Epoch: 6| Step: 3
Training loss: 0.2139800786972046
Validation loss: 1.5883482553625619

Epoch: 6| Step: 4
Training loss: 0.18623137474060059
Validation loss: 1.5856819524559924

Epoch: 6| Step: 5
Training loss: 0.179080992937088
Validation loss: 1.5353654238485521

Epoch: 6| Step: 6
Training loss: 0.16045108437538147
Validation loss: 1.5863224101322952

Epoch: 6| Step: 7
Training loss: 0.13934636116027832
Validation loss: 1.589235064803913

Epoch: 6| Step: 8
Training loss: 0.1514667421579361
Validation loss: 1.5610178196302025

Epoch: 6| Step: 9
Training loss: 0.14734429121017456
Validation loss: 1.5568984785387594

Epoch: 6| Step: 10
Training loss: 0.3005051016807556
Validation loss: 1.5713244010043401

Epoch: 6| Step: 11
Training loss: 0.1779349148273468
Validation loss: 1.5228859814264442

Epoch: 6| Step: 12
Training loss: 0.17070746421813965
Validation loss: 1.5479024142347357

Epoch: 6| Step: 13
Training loss: 0.2210347056388855
Validation loss: 1.5497399235284457

Epoch: 390| Step: 0
Training loss: 0.19093754887580872
Validation loss: 1.5687986843047603

Epoch: 6| Step: 1
Training loss: 0.1334952414035797
Validation loss: 1.5692430298815492

Epoch: 6| Step: 2
Training loss: 0.09826714545488358
Validation loss: 1.574186533369044

Epoch: 6| Step: 3
Training loss: 0.13769939541816711
Validation loss: 1.5558101541252547

Epoch: 6| Step: 4
Training loss: 0.18059998750686646
Validation loss: 1.5533407144649054

Epoch: 6| Step: 5
Training loss: 0.10223699361085892
Validation loss: 1.5234543764463035

Epoch: 6| Step: 6
Training loss: 0.15546604990959167
Validation loss: 1.5552041504972725

Epoch: 6| Step: 7
Training loss: 0.26978814601898193
Validation loss: 1.5347299063077537

Epoch: 6| Step: 8
Training loss: 0.17336192727088928
Validation loss: 1.5201869100652716

Epoch: 6| Step: 9
Training loss: 0.22729769349098206
Validation loss: 1.508033025008376

Epoch: 6| Step: 10
Training loss: 0.22495897114276886
Validation loss: 1.5152024325504099

Epoch: 6| Step: 11
Training loss: 0.17371755838394165
Validation loss: 1.5180294295792938

Epoch: 6| Step: 12
Training loss: 0.22965705394744873
Validation loss: 1.5016168599487634

Epoch: 6| Step: 13
Training loss: 0.17978473007678986
Validation loss: 1.5105241133320717

Epoch: 391| Step: 0
Training loss: 0.16900071501731873
Validation loss: 1.483553901795418

Epoch: 6| Step: 1
Training loss: 0.16806530952453613
Validation loss: 1.5035518151457592

Epoch: 6| Step: 2
Training loss: 0.21580183506011963
Validation loss: 1.5373572649494294

Epoch: 6| Step: 3
Training loss: 0.1344202160835266
Validation loss: 1.5716996827433187

Epoch: 6| Step: 4
Training loss: 0.15886807441711426
Validation loss: 1.54639519030048

Epoch: 6| Step: 5
Training loss: 0.15172383189201355
Validation loss: 1.5942654199497674

Epoch: 6| Step: 6
Training loss: 0.20657168328762054
Validation loss: 1.576581980592461

Epoch: 6| Step: 7
Training loss: 0.148650661110878
Validation loss: 1.5965425711806103

Epoch: 6| Step: 8
Training loss: 0.16104336082935333
Validation loss: 1.61953523594846

Epoch: 6| Step: 9
Training loss: 0.14506569504737854
Validation loss: 1.5837506273741364

Epoch: 6| Step: 10
Training loss: 0.16857221722602844
Validation loss: 1.5821070465990292

Epoch: 6| Step: 11
Training loss: 0.17845764756202698
Validation loss: 1.5945844342631679

Epoch: 6| Step: 12
Training loss: 0.23390108346939087
Validation loss: 1.5913633422185016

Epoch: 6| Step: 13
Training loss: 0.15802280604839325
Validation loss: 1.5929052855378838

Epoch: 392| Step: 0
Training loss: 0.17094773054122925
Validation loss: 1.570930710402868

Epoch: 6| Step: 1
Training loss: 0.19873817265033722
Validation loss: 1.6015645829580163

Epoch: 6| Step: 2
Training loss: 0.10447657108306885
Validation loss: 1.552721478605783

Epoch: 6| Step: 3
Training loss: 0.24417707324028015
Validation loss: 1.5779081352295414

Epoch: 6| Step: 4
Training loss: 0.08540267497301102
Validation loss: 1.5437470456605316

Epoch: 6| Step: 5
Training loss: 0.2274809330701828
Validation loss: 1.5375728530268515

Epoch: 6| Step: 6
Training loss: 0.12110400199890137
Validation loss: 1.495023928662782

Epoch: 6| Step: 7
Training loss: 0.09540243446826935
Validation loss: 1.4953352174451273

Epoch: 6| Step: 8
Training loss: 0.13512563705444336
Validation loss: 1.5149786869684856

Epoch: 6| Step: 9
Training loss: 0.14772191643714905
Validation loss: 1.515903263963679

Epoch: 6| Step: 10
Training loss: 0.18670709431171417
Validation loss: 1.544569315448884

Epoch: 6| Step: 11
Training loss: 0.18572822213172913
Validation loss: 1.5021276243271366

Epoch: 6| Step: 12
Training loss: 0.16138145327568054
Validation loss: 1.53392622804129

Epoch: 6| Step: 13
Training loss: 0.267448365688324
Validation loss: 1.5246574782556104

Epoch: 393| Step: 0
Training loss: 0.1976916491985321
Validation loss: 1.5068114611410326

Epoch: 6| Step: 1
Training loss: 0.1093260645866394
Validation loss: 1.5279322990807154

Epoch: 6| Step: 2
Training loss: 0.14361447095870972
Validation loss: 1.5211146006020166

Epoch: 6| Step: 3
Training loss: 0.19127415120601654
Validation loss: 1.5466687320381083

Epoch: 6| Step: 4
Training loss: 0.15363629162311554
Validation loss: 1.568601308330413

Epoch: 6| Step: 5
Training loss: 0.2331872433423996
Validation loss: 1.5691232796638244

Epoch: 6| Step: 6
Training loss: 0.09902077913284302
Validation loss: 1.575478599917504

Epoch: 6| Step: 7
Training loss: 0.15164750814437866
Validation loss: 1.6124555090422272

Epoch: 6| Step: 8
Training loss: 0.17504924535751343
Validation loss: 1.5979837730366697

Epoch: 6| Step: 9
Training loss: 0.20295853912830353
Validation loss: 1.6305167598109092

Epoch: 6| Step: 10
Training loss: 0.1696908175945282
Validation loss: 1.6153117046561292

Epoch: 6| Step: 11
Training loss: 0.15024714171886444
Validation loss: 1.5831446686098654

Epoch: 6| Step: 12
Training loss: 0.25044941902160645
Validation loss: 1.568252968531783

Epoch: 6| Step: 13
Training loss: 0.12482431530952454
Validation loss: 1.5584937513515513

Epoch: 394| Step: 0
Training loss: 0.10726633667945862
Validation loss: 1.5286608037128244

Epoch: 6| Step: 1
Training loss: 0.18986395001411438
Validation loss: 1.5343636594792849

Epoch: 6| Step: 2
Training loss: 0.1520499587059021
Validation loss: 1.5242032748396679

Epoch: 6| Step: 3
Training loss: 0.13639353215694427
Validation loss: 1.5042537104698919

Epoch: 6| Step: 4
Training loss: 0.16374725103378296
Validation loss: 1.5685203280500186

Epoch: 6| Step: 5
Training loss: 0.2339572161436081
Validation loss: 1.543584822326578

Epoch: 6| Step: 6
Training loss: 0.18865108489990234
Validation loss: 1.5788324622697727

Epoch: 6| Step: 7
Training loss: 0.1601015031337738
Validation loss: 1.5817712686395133

Epoch: 6| Step: 8
Training loss: 0.15563741326332092
Validation loss: 1.6105095929996942

Epoch: 6| Step: 9
Training loss: 0.167531356215477
Validation loss: 1.6031037222954534

Epoch: 6| Step: 10
Training loss: 0.17421939969062805
Validation loss: 1.5963712494860414

Epoch: 6| Step: 11
Training loss: 0.12423853576183319
Validation loss: 1.611213816109524

Epoch: 6| Step: 12
Training loss: 0.2597230076789856
Validation loss: 1.626540050711683

Epoch: 6| Step: 13
Training loss: 0.19990451633930206
Validation loss: 1.6242048419931883

Epoch: 395| Step: 0
Training loss: 0.21344420313835144
Validation loss: 1.600357182564274

Epoch: 6| Step: 1
Training loss: 0.24667464196681976
Validation loss: 1.6080352080765592

Epoch: 6| Step: 2
Training loss: 0.18201394379138947
Validation loss: 1.6035661633296678

Epoch: 6| Step: 3
Training loss: 0.20641770958900452
Validation loss: 1.6106409334367322

Epoch: 6| Step: 4
Training loss: 0.11979076266288757
Validation loss: 1.59390886111926

Epoch: 6| Step: 5
Training loss: 0.16368906199932098
Validation loss: 1.6123044054995301

Epoch: 6| Step: 6
Training loss: 0.1344006210565567
Validation loss: 1.5936113326780257

Epoch: 6| Step: 7
Training loss: 0.12292226403951645
Validation loss: 1.5860993708333662

Epoch: 6| Step: 8
Training loss: 0.23615217208862305
Validation loss: 1.5688495866713985

Epoch: 6| Step: 9
Training loss: 0.160038560628891
Validation loss: 1.5913970572974092

Epoch: 6| Step: 10
Training loss: 0.09966279566287994
Validation loss: 1.570670324628071

Epoch: 6| Step: 11
Training loss: 0.1971670389175415
Validation loss: 1.547227410859959

Epoch: 6| Step: 12
Training loss: 0.17739081382751465
Validation loss: 1.534516724207068

Epoch: 6| Step: 13
Training loss: 0.18841955065727234
Validation loss: 1.5260914628223707

Epoch: 396| Step: 0
Training loss: 0.1996629238128662
Validation loss: 1.5055279603568457

Epoch: 6| Step: 1
Training loss: 0.0536169558763504
Validation loss: 1.5262721302688762

Epoch: 6| Step: 2
Training loss: 0.11297570168972015
Validation loss: 1.522871535311463

Epoch: 6| Step: 3
Training loss: 0.15646733343601227
Validation loss: 1.534120520596863

Epoch: 6| Step: 4
Training loss: 0.16905353963375092
Validation loss: 1.5486634726165442

Epoch: 6| Step: 5
Training loss: 0.16736361384391785
Validation loss: 1.5348163548336233

Epoch: 6| Step: 6
Training loss: 0.13835780322551727
Validation loss: 1.506748867291276

Epoch: 6| Step: 7
Training loss: 0.23625656962394714
Validation loss: 1.5314423525205223

Epoch: 6| Step: 8
Training loss: 0.1216253936290741
Validation loss: 1.5202681518370105

Epoch: 6| Step: 9
Training loss: 0.2375141680240631
Validation loss: 1.5156390923325733

Epoch: 6| Step: 10
Training loss: 0.2009740173816681
Validation loss: 1.5486961462164437

Epoch: 6| Step: 11
Training loss: 0.10669727623462677
Validation loss: 1.5152496791655017

Epoch: 6| Step: 12
Training loss: 0.23913607001304626
Validation loss: 1.5409284727547758

Epoch: 6| Step: 13
Training loss: 0.09394601732492447
Validation loss: 1.5264502545838714

Epoch: 397| Step: 0
Training loss: 0.10725748538970947
Validation loss: 1.5574767384477841

Epoch: 6| Step: 1
Training loss: 0.12844562530517578
Validation loss: 1.5147731188804872

Epoch: 6| Step: 2
Training loss: 0.21580743789672852
Validation loss: 1.5202153344308176

Epoch: 6| Step: 3
Training loss: 0.1604202389717102
Validation loss: 1.5246215904912641

Epoch: 6| Step: 4
Training loss: 0.15700775384902954
Validation loss: 1.5021371187702302

Epoch: 6| Step: 5
Training loss: 0.21081684529781342
Validation loss: 1.5145549351169216

Epoch: 6| Step: 6
Training loss: 0.1812719702720642
Validation loss: 1.5524501569809452

Epoch: 6| Step: 7
Training loss: 0.1602681428194046
Validation loss: 1.5535633281994892

Epoch: 6| Step: 8
Training loss: 0.14852821826934814
Validation loss: 1.540065691035281

Epoch: 6| Step: 9
Training loss: 0.14136333763599396
Validation loss: 1.5267151107070267

Epoch: 6| Step: 10
Training loss: 0.15601053833961487
Validation loss: 1.5199122069984354

Epoch: 6| Step: 11
Training loss: 0.12644720077514648
Validation loss: 1.5404789986148957

Epoch: 6| Step: 12
Training loss: 0.13989920914173126
Validation loss: 1.5418208786236343

Epoch: 6| Step: 13
Training loss: 0.21750608086585999
Validation loss: 1.5082267509993685

Epoch: 398| Step: 0
Training loss: 0.17386525869369507
Validation loss: 1.4735057264245965

Epoch: 6| Step: 1
Training loss: 0.09025134146213531
Validation loss: 1.5003071228663127

Epoch: 6| Step: 2
Training loss: 0.17731183767318726
Validation loss: 1.4700405418231923

Epoch: 6| Step: 3
Training loss: 0.10296348482370377
Validation loss: 1.4581823887363556

Epoch: 6| Step: 4
Training loss: 0.16699746251106262
Validation loss: 1.4693497855176207

Epoch: 6| Step: 5
Training loss: 0.10446672141551971
Validation loss: 1.4944714923058786

Epoch: 6| Step: 6
Training loss: 0.14411601424217224
Validation loss: 1.462913167092108

Epoch: 6| Step: 7
Training loss: 0.18174542486667633
Validation loss: 1.5093577805385794

Epoch: 6| Step: 8
Training loss: 0.11544644832611084
Validation loss: 1.5249885923119002

Epoch: 6| Step: 9
Training loss: 0.13978606462478638
Validation loss: 1.5140053277374597

Epoch: 6| Step: 10
Training loss: 0.13402679562568665
Validation loss: 1.4799507318004486

Epoch: 6| Step: 11
Training loss: 0.1434553563594818
Validation loss: 1.505676466931579

Epoch: 6| Step: 12
Training loss: 0.18892064690589905
Validation loss: 1.5423808161930372

Epoch: 6| Step: 13
Training loss: 0.16404187679290771
Validation loss: 1.5351390671986405

Epoch: 399| Step: 0
Training loss: 0.11379072070121765
Validation loss: 1.5433028333930559

Epoch: 6| Step: 1
Training loss: 0.15051613748073578
Validation loss: 1.572991160936253

Epoch: 6| Step: 2
Training loss: 0.08898632228374481
Validation loss: 1.5728565416028422

Epoch: 6| Step: 3
Training loss: 0.15446197986602783
Validation loss: 1.5300665952826058

Epoch: 6| Step: 4
Training loss: 0.1722821444272995
Validation loss: 1.5547466508803829

Epoch: 6| Step: 5
Training loss: 0.17571236193180084
Validation loss: 1.5599323113759358

Epoch: 6| Step: 6
Training loss: 0.20257127285003662
Validation loss: 1.5486183448504376

Epoch: 6| Step: 7
Training loss: 0.11049917340278625
Validation loss: 1.5264685153961182

Epoch: 6| Step: 8
Training loss: 0.18535566329956055
Validation loss: 1.5388253529866536

Epoch: 6| Step: 9
Training loss: 0.10585512220859528
Validation loss: 1.53912107406124

Epoch: 6| Step: 10
Training loss: 0.09664005041122437
Validation loss: 1.5158937938751713

Epoch: 6| Step: 11
Training loss: 0.12239964306354523
Validation loss: 1.5127595663070679

Epoch: 6| Step: 12
Training loss: 0.25301721692085266
Validation loss: 1.5198746522267659

Epoch: 6| Step: 13
Training loss: 0.11436481028795242
Validation loss: 1.5068630326178767

Epoch: 400| Step: 0
Training loss: 0.18771375715732574
Validation loss: 1.5103030435500606

Epoch: 6| Step: 1
Training loss: 0.17094114422798157
Validation loss: 1.5504123344216296

Epoch: 6| Step: 2
Training loss: 0.17160624265670776
Validation loss: 1.5579403215839016

Epoch: 6| Step: 3
Training loss: 0.14271309971809387
Validation loss: 1.5024253565778014

Epoch: 6| Step: 4
Training loss: 0.17328009009361267
Validation loss: 1.5240243147778254

Epoch: 6| Step: 5
Training loss: 0.12322180718183517
Validation loss: 1.509831759237474

Epoch: 6| Step: 6
Training loss: 0.17984090745449066
Validation loss: 1.528487015795964

Epoch: 6| Step: 7
Training loss: 0.11631400883197784
Validation loss: 1.526861313850649

Epoch: 6| Step: 8
Training loss: 0.20636625587940216
Validation loss: 1.5020884518982263

Epoch: 6| Step: 9
Training loss: 0.12229704856872559
Validation loss: 1.5207797981077624

Epoch: 6| Step: 10
Training loss: 0.15243884921073914
Validation loss: 1.519656471026841

Epoch: 6| Step: 11
Training loss: 0.0633908212184906
Validation loss: 1.5050147451380247

Epoch: 6| Step: 12
Training loss: 0.21239139139652252
Validation loss: 1.53887737694607

Epoch: 6| Step: 13
Training loss: 0.1175060123205185
Validation loss: 1.5477872907474477

Epoch: 401| Step: 0
Training loss: 0.1559244990348816
Validation loss: 1.5615216839698054

Epoch: 6| Step: 1
Training loss: 0.16893473267555237
Validation loss: 1.5638239255515478

Epoch: 6| Step: 2
Training loss: 0.15598297119140625
Validation loss: 1.5847060565025575

Epoch: 6| Step: 3
Training loss: 0.14000993967056274
Validation loss: 1.5717655529258072

Epoch: 6| Step: 4
Training loss: 0.12657132744789124
Validation loss: 1.5870899718294862

Epoch: 6| Step: 5
Training loss: 0.18005208671092987
Validation loss: 1.5810627988589707

Epoch: 6| Step: 6
Training loss: 0.18481948971748352
Validation loss: 1.5675984332638402

Epoch: 6| Step: 7
Training loss: 0.16426774859428406
Validation loss: 1.5668783418593868

Epoch: 6| Step: 8
Training loss: 0.17673271894454956
Validation loss: 1.5635304245897519

Epoch: 6| Step: 9
Training loss: 0.11906971037387848
Validation loss: 1.50666646675397

Epoch: 6| Step: 10
Training loss: 0.11612991988658905
Validation loss: 1.5050609304058937

Epoch: 6| Step: 11
Training loss: 0.09716208279132843
Validation loss: 1.5145803125955726

Epoch: 6| Step: 12
Training loss: 0.09805724024772644
Validation loss: 1.4746257874273485

Epoch: 6| Step: 13
Training loss: 0.09534769505262375
Validation loss: 1.491142028121538

Epoch: 402| Step: 0
Training loss: 0.09701550006866455
Validation loss: 1.461633707887383

Epoch: 6| Step: 1
Training loss: 0.09736339747905731
Validation loss: 1.4914553870436966

Epoch: 6| Step: 2
Training loss: 0.1177075058221817
Validation loss: 1.4677118037336616

Epoch: 6| Step: 3
Training loss: 0.13375499844551086
Validation loss: 1.5098169452400618

Epoch: 6| Step: 4
Training loss: 0.13225078582763672
Validation loss: 1.5272389342707973

Epoch: 6| Step: 5
Training loss: 0.2011023461818695
Validation loss: 1.5185561257023965

Epoch: 6| Step: 6
Training loss: 0.22367200255393982
Validation loss: 1.5449430686171337

Epoch: 6| Step: 7
Training loss: 0.08504246175289154
Validation loss: 1.5619917236348635

Epoch: 6| Step: 8
Training loss: 0.18338608741760254
Validation loss: 1.5583849965885122

Epoch: 6| Step: 9
Training loss: 0.1847069412469864
Validation loss: 1.5657054403776764

Epoch: 6| Step: 10
Training loss: 0.13710841536521912
Validation loss: 1.5609523186119654

Epoch: 6| Step: 11
Training loss: 0.20049479603767395
Validation loss: 1.5633920161954817

Epoch: 6| Step: 12
Training loss: 0.12857365608215332
Validation loss: 1.5412084492303992

Epoch: 6| Step: 13
Training loss: 0.08815008401870728
Validation loss: 1.5095203973913704

Epoch: 403| Step: 0
Training loss: 0.08401460945606232
Validation loss: 1.5264718904290149

Epoch: 6| Step: 1
Training loss: 0.11385608464479446
Validation loss: 1.5297412654404998

Epoch: 6| Step: 2
Training loss: 0.22337624430656433
Validation loss: 1.549337556285243

Epoch: 6| Step: 3
Training loss: 0.16769611835479736
Validation loss: 1.530904136678224

Epoch: 6| Step: 4
Training loss: 0.1247473806142807
Validation loss: 1.5638761289658085

Epoch: 6| Step: 5
Training loss: 0.20931752026081085
Validation loss: 1.5230866221971409

Epoch: 6| Step: 6
Training loss: 0.12752512097358704
Validation loss: 1.5613977832178916

Epoch: 6| Step: 7
Training loss: 0.1302308440208435
Validation loss: 1.578390782879245

Epoch: 6| Step: 8
Training loss: 0.14945027232170105
Validation loss: 1.588619706451252

Epoch: 6| Step: 9
Training loss: 0.19843119382858276
Validation loss: 1.580421902800119

Epoch: 6| Step: 10
Training loss: 0.17152637243270874
Validation loss: 1.5788141348028695

Epoch: 6| Step: 11
Training loss: 0.12398543208837509
Validation loss: 1.5946585209138933

Epoch: 6| Step: 12
Training loss: 0.13347125053405762
Validation loss: 1.60102589156038

Epoch: 6| Step: 13
Training loss: 0.15631169080734253
Validation loss: 1.5809539082229778

Epoch: 404| Step: 0
Training loss: 0.16806289553642273
Validation loss: 1.5912683497193039

Epoch: 6| Step: 1
Training loss: 0.15825676918029785
Validation loss: 1.5964531283224783

Epoch: 6| Step: 2
Training loss: 0.06893431395292282
Validation loss: 1.60979369378859

Epoch: 6| Step: 3
Training loss: 0.1522320806980133
Validation loss: 1.6089611015012186

Epoch: 6| Step: 4
Training loss: 0.1925777643918991
Validation loss: 1.5935877721796754

Epoch: 6| Step: 5
Training loss: 0.14140737056732178
Validation loss: 1.6007671074200702

Epoch: 6| Step: 6
Training loss: 0.116539865732193
Validation loss: 1.6003027096871407

Epoch: 6| Step: 7
Training loss: 0.10642539709806442
Validation loss: 1.609860038244596

Epoch: 6| Step: 8
Training loss: 0.18132881820201874
Validation loss: 1.6303789974540792

Epoch: 6| Step: 9
Training loss: 0.1585172712802887
Validation loss: 1.6006546264053674

Epoch: 6| Step: 10
Training loss: 0.10669651627540588
Validation loss: 1.5944115384932487

Epoch: 6| Step: 11
Training loss: 0.19632798433303833
Validation loss: 1.5927258447934223

Epoch: 6| Step: 12
Training loss: 0.19448129832744598
Validation loss: 1.563394695199946

Epoch: 6| Step: 13
Training loss: 0.2418278008699417
Validation loss: 1.5794185848646267

Epoch: 405| Step: 0
Training loss: 0.13354308903217316
Validation loss: 1.5915278350153277

Epoch: 6| Step: 1
Training loss: 0.22455190122127533
Validation loss: 1.5684452287612423

Epoch: 6| Step: 2
Training loss: 0.1435157060623169
Validation loss: 1.5321994866094282

Epoch: 6| Step: 3
Training loss: 0.1370762437582016
Validation loss: 1.5460461006369641

Epoch: 6| Step: 4
Training loss: 0.10476890951395035
Validation loss: 1.5234369359990603

Epoch: 6| Step: 5
Training loss: 0.15583689510822296
Validation loss: 1.5229513593899306

Epoch: 6| Step: 6
Training loss: 0.251268208026886
Validation loss: 1.5671631392612253

Epoch: 6| Step: 7
Training loss: 0.2570543885231018
Validation loss: 1.526396495039745

Epoch: 6| Step: 8
Training loss: 0.1711515188217163
Validation loss: 1.5198229564133512

Epoch: 6| Step: 9
Training loss: 0.1621396541595459
Validation loss: 1.5324625917660293

Epoch: 6| Step: 10
Training loss: 0.22392010688781738
Validation loss: 1.5460517406463623

Epoch: 6| Step: 11
Training loss: 0.2104329764842987
Validation loss: 1.5667797288587015

Epoch: 6| Step: 12
Training loss: 0.1470424383878708
Validation loss: 1.550076566075766

Epoch: 6| Step: 13
Training loss: 0.07195021212100983
Validation loss: 1.5761582210499754

Epoch: 406| Step: 0
Training loss: 0.16304586827754974
Validation loss: 1.565818041883489

Epoch: 6| Step: 1
Training loss: 0.1113848015666008
Validation loss: 1.5442142204571796

Epoch: 6| Step: 2
Training loss: 0.18575628101825714
Validation loss: 1.5178112470975487

Epoch: 6| Step: 3
Training loss: 0.12677903473377228
Validation loss: 1.556803390543948

Epoch: 6| Step: 4
Training loss: 0.12966388463974
Validation loss: 1.5672108793771395

Epoch: 6| Step: 5
Training loss: 0.13087187707424164
Validation loss: 1.5710946475305865

Epoch: 6| Step: 6
Training loss: 0.18375682830810547
Validation loss: 1.5996203102091306

Epoch: 6| Step: 7
Training loss: 0.13358627259731293
Validation loss: 1.6237278433256253

Epoch: 6| Step: 8
Training loss: 0.12545841932296753
Validation loss: 1.6023729937050932

Epoch: 6| Step: 9
Training loss: 0.16352730989456177
Validation loss: 1.5973186069919216

Epoch: 6| Step: 10
Training loss: 0.13369989395141602
Validation loss: 1.6242026398258824

Epoch: 6| Step: 11
Training loss: 0.14867983758449554
Validation loss: 1.5688047409057617

Epoch: 6| Step: 12
Training loss: 0.14683517813682556
Validation loss: 1.6060889792698685

Epoch: 6| Step: 13
Training loss: 0.2503020167350769
Validation loss: 1.60092366767186

Epoch: 407| Step: 0
Training loss: 0.0903516337275505
Validation loss: 1.5826756133828113

Epoch: 6| Step: 1
Training loss: 0.08329588919878006
Validation loss: 1.597289627598178

Epoch: 6| Step: 2
Training loss: 0.13225717842578888
Validation loss: 1.5952151308777511

Epoch: 6| Step: 3
Training loss: 0.07029001414775848
Validation loss: 1.5911052483384327

Epoch: 6| Step: 4
Training loss: 0.1229240745306015
Validation loss: 1.5997438084694646

Epoch: 6| Step: 5
Training loss: 0.09290726482868195
Validation loss: 1.6032477181444886

Epoch: 6| Step: 6
Training loss: 0.12402462959289551
Validation loss: 1.6062241587587582

Epoch: 6| Step: 7
Training loss: 0.14814208447933197
Validation loss: 1.59952510300503

Epoch: 6| Step: 8
Training loss: 0.13707426190376282
Validation loss: 1.5846641396963468

Epoch: 6| Step: 9
Training loss: 0.1665624976158142
Validation loss: 1.5825267735347952

Epoch: 6| Step: 10
Training loss: 0.2137531340122223
Validation loss: 1.5852698702966013

Epoch: 6| Step: 11
Training loss: 0.21282532811164856
Validation loss: 1.549228992513431

Epoch: 6| Step: 12
Training loss: 0.15619012713432312
Validation loss: 1.5725692497786654

Epoch: 6| Step: 13
Training loss: 0.10162776708602905
Validation loss: 1.5496887673613846

Epoch: 408| Step: 0
Training loss: 0.09312625974416733
Validation loss: 1.5498397747675579

Epoch: 6| Step: 1
Training loss: 0.17960882186889648
Validation loss: 1.5443257369020933

Epoch: 6| Step: 2
Training loss: 0.15382319688796997
Validation loss: 1.5422961058155182

Epoch: 6| Step: 3
Training loss: 0.13424575328826904
Validation loss: 1.533329697065456

Epoch: 6| Step: 4
Training loss: 0.11633269488811493
Validation loss: 1.5405517380724671

Epoch: 6| Step: 5
Training loss: 0.0897679403424263
Validation loss: 1.545954538929847

Epoch: 6| Step: 6
Training loss: 0.18206074833869934
Validation loss: 1.540882195195844

Epoch: 6| Step: 7
Training loss: 0.0930260568857193
Validation loss: 1.570196302988196

Epoch: 6| Step: 8
Training loss: 0.1396017074584961
Validation loss: 1.5800395184947598

Epoch: 6| Step: 9
Training loss: 0.16364020109176636
Validation loss: 1.6045106328943723

Epoch: 6| Step: 10
Training loss: 0.23896868526935577
Validation loss: 1.6236827758050734

Epoch: 6| Step: 11
Training loss: 0.18655608594417572
Validation loss: 1.610955911297952

Epoch: 6| Step: 12
Training loss: 0.14442414045333862
Validation loss: 1.6116024896662722

Epoch: 6| Step: 13
Training loss: 0.15098239481449127
Validation loss: 1.6045464161903626

Epoch: 409| Step: 0
Training loss: 0.14931264519691467
Validation loss: 1.5890035860000118

Epoch: 6| Step: 1
Training loss: 0.16820760071277618
Validation loss: 1.5910985739000383

Epoch: 6| Step: 2
Training loss: 0.10086165368556976
Validation loss: 1.5799508658788537

Epoch: 6| Step: 3
Training loss: 0.11886727064847946
Validation loss: 1.5835706162196335

Epoch: 6| Step: 4
Training loss: 0.1926284283399582
Validation loss: 1.5515304970484909

Epoch: 6| Step: 5
Training loss: 0.13820356130599976
Validation loss: 1.5613943979304323

Epoch: 6| Step: 6
Training loss: 0.10253829509019852
Validation loss: 1.544508755847972

Epoch: 6| Step: 7
Training loss: 0.16097474098205566
Validation loss: 1.5541797376448108

Epoch: 6| Step: 8
Training loss: 0.14299266040325165
Validation loss: 1.533947907468324

Epoch: 6| Step: 9
Training loss: 0.16790489852428436
Validation loss: 1.5579835663559616

Epoch: 6| Step: 10
Training loss: 0.14922548830509186
Validation loss: 1.5262239453613118

Epoch: 6| Step: 11
Training loss: 0.16962887346744537
Validation loss: 1.5339255691856466

Epoch: 6| Step: 12
Training loss: 0.1957564353942871
Validation loss: 1.5061733184322235

Epoch: 6| Step: 13
Training loss: 0.12578196823596954
Validation loss: 1.517844012988511

Epoch: 410| Step: 0
Training loss: 0.2319214940071106
Validation loss: 1.5514084062268656

Epoch: 6| Step: 1
Training loss: 0.18518348038196564
Validation loss: 1.540780367389802

Epoch: 6| Step: 2
Training loss: 0.1307743489742279
Validation loss: 1.5199176444802234

Epoch: 6| Step: 3
Training loss: 0.15393579006195068
Validation loss: 1.560263922137599

Epoch: 6| Step: 4
Training loss: 0.1267327070236206
Validation loss: 1.556124294957807

Epoch: 6| Step: 5
Training loss: 0.16711685061454773
Validation loss: 1.5486849661796325

Epoch: 6| Step: 6
Training loss: 0.1706806719303131
Validation loss: 1.5797321514416767

Epoch: 6| Step: 7
Training loss: 0.1939810812473297
Validation loss: 1.5617398702970116

Epoch: 6| Step: 8
Training loss: 0.13975223898887634
Validation loss: 1.5662482348821496

Epoch: 6| Step: 9
Training loss: 0.09029041230678558
Validation loss: 1.5435294117978824

Epoch: 6| Step: 10
Training loss: 0.18209470808506012
Validation loss: 1.560631191217771

Epoch: 6| Step: 11
Training loss: 0.0964818000793457
Validation loss: 1.535903061589887

Epoch: 6| Step: 12
Training loss: 0.12507963180541992
Validation loss: 1.5474292283417077

Epoch: 6| Step: 13
Training loss: 0.09953127801418304
Validation loss: 1.5379582643508911

Epoch: 411| Step: 0
Training loss: 0.05988550931215286
Validation loss: 1.5465056255299559

Epoch: 6| Step: 1
Training loss: 0.10338220000267029
Validation loss: 1.5227152250146354

Epoch: 6| Step: 2
Training loss: 0.11887068301439285
Validation loss: 1.493500708251871

Epoch: 6| Step: 3
Training loss: 0.09554827958345413
Validation loss: 1.463395998042117

Epoch: 6| Step: 4
Training loss: 0.13128715753555298
Validation loss: 1.5129857793931039

Epoch: 6| Step: 5
Training loss: 0.10425442457199097
Validation loss: 1.5036848270764915

Epoch: 6| Step: 6
Training loss: 0.20493459701538086
Validation loss: 1.5109829966739943

Epoch: 6| Step: 7
Training loss: 0.0910419449210167
Validation loss: 1.5174912560370661

Epoch: 6| Step: 8
Training loss: 0.19755007326602936
Validation loss: 1.5367684466864473

Epoch: 6| Step: 9
Training loss: 0.197459876537323
Validation loss: 1.5681357768274122

Epoch: 6| Step: 10
Training loss: 0.1813879907131195
Validation loss: 1.5751839914629537

Epoch: 6| Step: 11
Training loss: 0.0861206129193306
Validation loss: 1.5949060968173447

Epoch: 6| Step: 12
Training loss: 0.09937165677547455
Validation loss: 1.6053125717306649

Epoch: 6| Step: 13
Training loss: 0.12252286076545715
Validation loss: 1.6395521010121992

Epoch: 412| Step: 0
Training loss: 0.1221388578414917
Validation loss: 1.602845388074075

Epoch: 6| Step: 1
Training loss: 0.2584514021873474
Validation loss: 1.6033583559015745

Epoch: 6| Step: 2
Training loss: 0.12789030373096466
Validation loss: 1.6148504877603183

Epoch: 6| Step: 3
Training loss: 0.17293056845664978
Validation loss: 1.5775136281085271

Epoch: 6| Step: 4
Training loss: 0.08148016780614853
Validation loss: 1.598024627213837

Epoch: 6| Step: 5
Training loss: 0.18547794222831726
Validation loss: 1.576640304698739

Epoch: 6| Step: 6
Training loss: 0.10217461735010147
Validation loss: 1.5475237651537823

Epoch: 6| Step: 7
Training loss: 0.19529536366462708
Validation loss: 1.5417794540364256

Epoch: 6| Step: 8
Training loss: 0.11457984149456024
Validation loss: 1.5645427191129295

Epoch: 6| Step: 9
Training loss: 0.1787884682416916
Validation loss: 1.5258170276559808

Epoch: 6| Step: 10
Training loss: 0.1091076135635376
Validation loss: 1.5365461072614115

Epoch: 6| Step: 11
Training loss: 0.13134142756462097
Validation loss: 1.5125746265534432

Epoch: 6| Step: 12
Training loss: 0.15271921455860138
Validation loss: 1.5015692198148338

Epoch: 6| Step: 13
Training loss: 0.09701360017061234
Validation loss: 1.487567170973747

Epoch: 413| Step: 0
Training loss: 0.09939725697040558
Validation loss: 1.5284009800162366

Epoch: 6| Step: 1
Training loss: 0.11815536022186279
Validation loss: 1.529865216183406

Epoch: 6| Step: 2
Training loss: 0.13649196922779083
Validation loss: 1.5068315434199508

Epoch: 6| Step: 3
Training loss: 0.11854097992181778
Validation loss: 1.5354249669659523

Epoch: 6| Step: 4
Training loss: 0.17243623733520508
Validation loss: 1.5235518947724374

Epoch: 6| Step: 5
Training loss: 0.11052541434764862
Validation loss: 1.5092397819283188

Epoch: 6| Step: 6
Training loss: 0.13363109529018402
Validation loss: 1.4869075000927012

Epoch: 6| Step: 7
Training loss: 0.283397912979126
Validation loss: 1.46739016232952

Epoch: 6| Step: 8
Training loss: 0.12687866389751434
Validation loss: 1.4669459744166302

Epoch: 6| Step: 9
Training loss: 0.07171007245779037
Validation loss: 1.484313532870303

Epoch: 6| Step: 10
Training loss: 0.15108919143676758
Validation loss: 1.4745029198226107

Epoch: 6| Step: 11
Training loss: 0.0810711458325386
Validation loss: 1.4953881809788365

Epoch: 6| Step: 12
Training loss: 0.135708287358284
Validation loss: 1.5127290718017086

Epoch: 6| Step: 13
Training loss: 0.15731306374073029
Validation loss: 1.5130658252264864

Epoch: 414| Step: 0
Training loss: 0.14759168028831482
Validation loss: 1.519281598829454

Epoch: 6| Step: 1
Training loss: 0.18337348103523254
Validation loss: 1.5631131523398942

Epoch: 6| Step: 2
Training loss: 0.11392731219530106
Validation loss: 1.54027436881937

Epoch: 6| Step: 3
Training loss: 0.13431844115257263
Validation loss: 1.5581199866469189

Epoch: 6| Step: 4
Training loss: 0.13638943433761597
Validation loss: 1.5044886719795965

Epoch: 6| Step: 5
Training loss: 0.13295014202594757
Validation loss: 1.516131199816222

Epoch: 6| Step: 6
Training loss: 0.17636600136756897
Validation loss: 1.5224071939786274

Epoch: 6| Step: 7
Training loss: 0.1551532745361328
Validation loss: 1.547616143380442

Epoch: 6| Step: 8
Training loss: 0.09538768231868744
Validation loss: 1.5485159902162449

Epoch: 6| Step: 9
Training loss: 0.12426532059907913
Validation loss: 1.5466167734515281

Epoch: 6| Step: 10
Training loss: 0.06973537057638168
Validation loss: 1.538920723622845

Epoch: 6| Step: 11
Training loss: 0.05527251213788986
Validation loss: 1.5261463016592047

Epoch: 6| Step: 12
Training loss: 0.13462793827056885
Validation loss: 1.5368295113245647

Epoch: 6| Step: 13
Training loss: 0.2401384562253952
Validation loss: 1.5362657116305443

Epoch: 415| Step: 0
Training loss: 0.17161202430725098
Validation loss: 1.5821928670329433

Epoch: 6| Step: 1
Training loss: 0.19426307082176208
Validation loss: 1.5742773086793962

Epoch: 6| Step: 2
Training loss: 0.17850473523139954
Validation loss: 1.6049920922966414

Epoch: 6| Step: 3
Training loss: 0.1887303590774536
Validation loss: 1.62697345723388

Epoch: 6| Step: 4
Training loss: 0.11420571804046631
Validation loss: 1.6313810066510273

Epoch: 6| Step: 5
Training loss: 0.16456544399261475
Validation loss: 1.6368220743312631

Epoch: 6| Step: 6
Training loss: 0.09770790487527847
Validation loss: 1.5808374625380321

Epoch: 6| Step: 7
Training loss: 0.07295407354831696
Validation loss: 1.5839108414547418

Epoch: 6| Step: 8
Training loss: 0.11105101555585861
Validation loss: 1.5626023725796772

Epoch: 6| Step: 9
Training loss: 0.18250207602977753
Validation loss: 1.5519730839678036

Epoch: 6| Step: 10
Training loss: 0.10634883493185043
Validation loss: 1.5166865177051996

Epoch: 6| Step: 11
Training loss: 0.11886955052614212
Validation loss: 1.548110403040404

Epoch: 6| Step: 12
Training loss: 0.10785376280546188
Validation loss: 1.541429110752639

Epoch: 6| Step: 13
Training loss: 0.049290843307971954
Validation loss: 1.5559967730634956

Epoch: 416| Step: 0
Training loss: 0.13745775818824768
Validation loss: 1.5668418497167609

Epoch: 6| Step: 1
Training loss: 0.10181957483291626
Validation loss: 1.5679656561984812

Epoch: 6| Step: 2
Training loss: 0.06688962876796722
Validation loss: 1.5883575229234592

Epoch: 6| Step: 3
Training loss: 0.18446120619773865
Validation loss: 1.5685088185853855

Epoch: 6| Step: 4
Training loss: 0.12279212474822998
Validation loss: 1.580536655200425

Epoch: 6| Step: 5
Training loss: 0.17963671684265137
Validation loss: 1.607703024341214

Epoch: 6| Step: 6
Training loss: 0.1375376135110855
Validation loss: 1.6157764747578611

Epoch: 6| Step: 7
Training loss: 0.1489923596382141
Validation loss: 1.6136115097230481

Epoch: 6| Step: 8
Training loss: 0.12504349648952484
Validation loss: 1.623943131457093

Epoch: 6| Step: 9
Training loss: 0.1561860293149948
Validation loss: 1.6082727216905164

Epoch: 6| Step: 10
Training loss: 0.17004920542240143
Validation loss: 1.6426498120830906

Epoch: 6| Step: 11
Training loss: 0.11476495862007141
Validation loss: 1.6288997332255046

Epoch: 6| Step: 12
Training loss: 0.20304763317108154
Validation loss: 1.6379590983031898

Epoch: 6| Step: 13
Training loss: 0.17909878492355347
Validation loss: 1.6071468066143733

Epoch: 417| Step: 0
Training loss: 0.13020235300064087
Validation loss: 1.5701861971168107

Epoch: 6| Step: 1
Training loss: 0.07567619532346725
Validation loss: 1.579282993911415

Epoch: 6| Step: 2
Training loss: 0.0630129724740982
Validation loss: 1.5810457416760024

Epoch: 6| Step: 3
Training loss: 0.12760937213897705
Validation loss: 1.5610839013130433

Epoch: 6| Step: 4
Training loss: 0.13127508759498596
Validation loss: 1.5326466021999237

Epoch: 6| Step: 5
Training loss: 0.1747869849205017
Validation loss: 1.5132221329596736

Epoch: 6| Step: 6
Training loss: 0.13050022721290588
Validation loss: 1.5006760230628393

Epoch: 6| Step: 7
Training loss: 0.09656987339258194
Validation loss: 1.4865297168813727

Epoch: 6| Step: 8
Training loss: 0.18967126309871674
Validation loss: 1.4792089321280038

Epoch: 6| Step: 9
Training loss: 0.16090881824493408
Validation loss: 1.4847314037302488

Epoch: 6| Step: 10
Training loss: 0.10043002665042877
Validation loss: 1.4944068180617465

Epoch: 6| Step: 11
Training loss: 0.14539329707622528
Validation loss: 1.4865687508736887

Epoch: 6| Step: 12
Training loss: 0.11175905168056488
Validation loss: 1.4802146483493108

Epoch: 6| Step: 13
Training loss: 0.11173117160797119
Validation loss: 1.475949961652038

Epoch: 418| Step: 0
Training loss: 0.1267690807580948
Validation loss: 1.5145011832637172

Epoch: 6| Step: 1
Training loss: 0.11104250699281693
Validation loss: 1.4759999135489106

Epoch: 6| Step: 2
Training loss: 0.12406828254461288
Validation loss: 1.5241308468644337

Epoch: 6| Step: 3
Training loss: 0.12924548983573914
Validation loss: 1.5068310076190579

Epoch: 6| Step: 4
Training loss: 0.23533037304878235
Validation loss: 1.5160533805047312

Epoch: 6| Step: 5
Training loss: 0.14700591564178467
Validation loss: 1.5166342617363058

Epoch: 6| Step: 6
Training loss: 0.17506390810012817
Validation loss: 1.5172092286489343

Epoch: 6| Step: 7
Training loss: 0.11067871749401093
Validation loss: 1.5723173541407431

Epoch: 6| Step: 8
Training loss: 0.15687814354896545
Validation loss: 1.562691310400604

Epoch: 6| Step: 9
Training loss: 0.14239397644996643
Validation loss: 1.578068785129055

Epoch: 6| Step: 10
Training loss: 0.25015658140182495
Validation loss: 1.5868592172540643

Epoch: 6| Step: 11
Training loss: 0.3422715365886688
Validation loss: 1.588841458802582

Epoch: 6| Step: 12
Training loss: 0.1360311061143875
Validation loss: 1.5408133422174761

Epoch: 6| Step: 13
Training loss: 0.37550461292266846
Validation loss: 1.5130885788189468

Epoch: 419| Step: 0
Training loss: 0.17304469645023346
Validation loss: 1.487551389201995

Epoch: 6| Step: 1
Training loss: 0.0723978728055954
Validation loss: 1.5094137255863478

Epoch: 6| Step: 2
Training loss: 0.10880813002586365
Validation loss: 1.475799440055765

Epoch: 6| Step: 3
Training loss: 0.20740091800689697
Validation loss: 1.4663688931413876

Epoch: 6| Step: 4
Training loss: 0.19396352767944336
Validation loss: 1.4877029759909517

Epoch: 6| Step: 5
Training loss: 0.08402955532073975
Validation loss: 1.5116715738850255

Epoch: 6| Step: 6
Training loss: 0.16702952980995178
Validation loss: 1.5102339521531136

Epoch: 6| Step: 7
Training loss: 0.2708454132080078
Validation loss: 1.5445321682960755

Epoch: 6| Step: 8
Training loss: 0.33954793214797974
Validation loss: 1.553406834602356

Epoch: 6| Step: 9
Training loss: 0.1701369434595108
Validation loss: 1.5593306069732995

Epoch: 6| Step: 10
Training loss: 0.1198810338973999
Validation loss: 1.5532175674233386

Epoch: 6| Step: 11
Training loss: 0.16763341426849365
Validation loss: 1.5513242701048493

Epoch: 6| Step: 12
Training loss: 0.13280490040779114
Validation loss: 1.5346200145700926

Epoch: 6| Step: 13
Training loss: 0.12775684893131256
Validation loss: 1.4992750280646867

Epoch: 420| Step: 0
Training loss: 0.16061599552631378
Validation loss: 1.4982125105396393

Epoch: 6| Step: 1
Training loss: 0.1553158015012741
Validation loss: 1.4828786773066367

Epoch: 6| Step: 2
Training loss: 0.3401440978050232
Validation loss: 1.4880737335451188

Epoch: 6| Step: 3
Training loss: 0.08139500021934509
Validation loss: 1.5019568333061792

Epoch: 6| Step: 4
Training loss: 0.12991420924663544
Validation loss: 1.52452673322411

Epoch: 6| Step: 5
Training loss: 0.1336539387702942
Validation loss: 1.4849562311685214

Epoch: 6| Step: 6
Training loss: 0.11051568388938904
Validation loss: 1.4697703905003046

Epoch: 6| Step: 7
Training loss: 0.1622142493724823
Validation loss: 1.5104457812924539

Epoch: 6| Step: 8
Training loss: 0.10844390839338303
Validation loss: 1.5035637783747848

Epoch: 6| Step: 9
Training loss: 0.10590262711048126
Validation loss: 1.504762690554383

Epoch: 6| Step: 10
Training loss: 0.06585104763507843
Validation loss: 1.506569948247684

Epoch: 6| Step: 11
Training loss: 0.20750349760055542
Validation loss: 1.5319791327240646

Epoch: 6| Step: 12
Training loss: 0.15676532685756683
Validation loss: 1.5370708537358109

Epoch: 6| Step: 13
Training loss: 0.06865843385457993
Validation loss: 1.5346235434214275

Epoch: 421| Step: 0
Training loss: 0.10881006717681885
Validation loss: 1.5608061077774211

Epoch: 6| Step: 1
Training loss: 0.19082365930080414
Validation loss: 1.5426268218665995

Epoch: 6| Step: 2
Training loss: 0.12099765241146088
Validation loss: 1.5215709196623934

Epoch: 6| Step: 3
Training loss: 0.19512107968330383
Validation loss: 1.5624018612728323

Epoch: 6| Step: 4
Training loss: 0.15273317694664001
Validation loss: 1.5649287931380733

Epoch: 6| Step: 5
Training loss: 0.1095641553401947
Validation loss: 1.5644280666946082

Epoch: 6| Step: 6
Training loss: 0.0970553606748581
Validation loss: 1.562048077583313

Epoch: 6| Step: 7
Training loss: 0.1164022833108902
Validation loss: 1.5421420720315748

Epoch: 6| Step: 8
Training loss: 0.11079134047031403
Validation loss: 1.551635911387782

Epoch: 6| Step: 9
Training loss: 0.1497345268726349
Validation loss: 1.5348764831019985

Epoch: 6| Step: 10
Training loss: 0.11334894597530365
Validation loss: 1.5684824066777383

Epoch: 6| Step: 11
Training loss: 0.14421160519123077
Validation loss: 1.559904106201664

Epoch: 6| Step: 12
Training loss: 0.14826302230358124
Validation loss: 1.5429759717756701

Epoch: 6| Step: 13
Training loss: 0.1465887576341629
Validation loss: 1.528053504164501

Epoch: 422| Step: 0
Training loss: 0.09370619058609009
Validation loss: 1.5107532214092951

Epoch: 6| Step: 1
Training loss: 0.08468414843082428
Validation loss: 1.5286451026957522

Epoch: 6| Step: 2
Training loss: 0.09497430920600891
Validation loss: 1.527088753638729

Epoch: 6| Step: 3
Training loss: 0.1690618097782135
Validation loss: 1.525855443810904

Epoch: 6| Step: 4
Training loss: 0.17698396742343903
Validation loss: 1.5434238397946922

Epoch: 6| Step: 5
Training loss: 0.11778497695922852
Validation loss: 1.5239937010631766

Epoch: 6| Step: 6
Training loss: 0.16435910761356354
Validation loss: 1.511056101450356

Epoch: 6| Step: 7
Training loss: 0.11554379016160965
Validation loss: 1.5204474823449248

Epoch: 6| Step: 8
Training loss: 0.13302084803581238
Validation loss: 1.481999264609429

Epoch: 6| Step: 9
Training loss: 0.08160091936588287
Validation loss: 1.491725887662621

Epoch: 6| Step: 10
Training loss: 0.10436753183603287
Validation loss: 1.5029108549958916

Epoch: 6| Step: 11
Training loss: 0.12449053674936295
Validation loss: 1.4933446697009507

Epoch: 6| Step: 12
Training loss: 0.21195852756500244
Validation loss: 1.5030796143316454

Epoch: 6| Step: 13
Training loss: 0.11838968843221664
Validation loss: 1.5233659500716834

Epoch: 423| Step: 0
Training loss: 0.10249519348144531
Validation loss: 1.507178771880365

Epoch: 6| Step: 1
Training loss: 0.13167980313301086
Validation loss: 1.5191367608244701

Epoch: 6| Step: 2
Training loss: 0.09646999835968018
Validation loss: 1.5338477691014607

Epoch: 6| Step: 3
Training loss: 0.1199817955493927
Validation loss: 1.5287931734515774

Epoch: 6| Step: 4
Training loss: 0.12036502361297607
Validation loss: 1.512327290350391

Epoch: 6| Step: 5
Training loss: 0.18400773406028748
Validation loss: 1.5628635293693953

Epoch: 6| Step: 6
Training loss: 0.12119287252426147
Validation loss: 1.5459341772140995

Epoch: 6| Step: 7
Training loss: 0.08538783341646194
Validation loss: 1.5551764042146745

Epoch: 6| Step: 8
Training loss: 0.17795291543006897
Validation loss: 1.5515046863145725

Epoch: 6| Step: 9
Training loss: 0.1326328068971634
Validation loss: 1.5557770447064472

Epoch: 6| Step: 10
Training loss: 0.08665833622217178
Validation loss: 1.5361808474345873

Epoch: 6| Step: 11
Training loss: 0.10099124908447266
Validation loss: 1.5561894434754566

Epoch: 6| Step: 12
Training loss: 0.16433840990066528
Validation loss: 1.5386439779753327

Epoch: 6| Step: 13
Training loss: 0.07182174175977707
Validation loss: 1.553393929876307

Epoch: 424| Step: 0
Training loss: 0.15035077929496765
Validation loss: 1.5585997873736965

Epoch: 6| Step: 1
Training loss: 0.06867223978042603
Validation loss: 1.543281925621853

Epoch: 6| Step: 2
Training loss: 0.13908447325229645
Validation loss: 1.5251985134616974

Epoch: 6| Step: 3
Training loss: 0.13188403844833374
Validation loss: 1.5307646771912933

Epoch: 6| Step: 4
Training loss: 0.09562210738658905
Validation loss: 1.5305940387069539

Epoch: 6| Step: 5
Training loss: 0.1345498114824295
Validation loss: 1.558850715237279

Epoch: 6| Step: 6
Training loss: 0.1437995433807373
Validation loss: 1.5380339737861388

Epoch: 6| Step: 7
Training loss: 0.143887460231781
Validation loss: 1.5355145886380186

Epoch: 6| Step: 8
Training loss: 0.1268872320652008
Validation loss: 1.5220763862773936

Epoch: 6| Step: 9
Training loss: 0.12933743000030518
Validation loss: 1.5121567492843957

Epoch: 6| Step: 10
Training loss: 0.1773650050163269
Validation loss: 1.5341849916724748

Epoch: 6| Step: 11
Training loss: 0.14272765815258026
Validation loss: 1.524741590663951

Epoch: 6| Step: 12
Training loss: 0.13603660464286804
Validation loss: 1.5182967653838537

Epoch: 6| Step: 13
Training loss: 0.13385751843452454
Validation loss: 1.5418809857419742

Epoch: 425| Step: 0
Training loss: 0.0812527984380722
Validation loss: 1.5281060459793254

Epoch: 6| Step: 1
Training loss: 0.14295358955860138
Validation loss: 1.5210394526040683

Epoch: 6| Step: 2
Training loss: 0.1746882051229477
Validation loss: 1.5547714387216875

Epoch: 6| Step: 3
Training loss: 0.11837505549192429
Validation loss: 1.544136094790633

Epoch: 6| Step: 4
Training loss: 0.09516187012195587
Validation loss: 1.5057731379744828

Epoch: 6| Step: 5
Training loss: 0.16670376062393188
Validation loss: 1.5393507698530793

Epoch: 6| Step: 6
Training loss: 0.08744186162948608
Validation loss: 1.4988089235880042

Epoch: 6| Step: 7
Training loss: 0.15162557363510132
Validation loss: 1.5139957730488112

Epoch: 6| Step: 8
Training loss: 0.12897659838199615
Validation loss: 1.5013051879021428

Epoch: 6| Step: 9
Training loss: 0.1355845332145691
Validation loss: 1.5444342667056667

Epoch: 6| Step: 10
Training loss: 0.1096935048699379
Validation loss: 1.5520053973761938

Epoch: 6| Step: 11
Training loss: 0.17452402412891388
Validation loss: 1.5841673445957962

Epoch: 6| Step: 12
Training loss: 0.1656031310558319
Validation loss: 1.610942930303594

Epoch: 6| Step: 13
Training loss: 0.12439070641994476
Validation loss: 1.5736300483826668

Epoch: 426| Step: 0
Training loss: 0.07849636673927307
Validation loss: 1.5277772718860256

Epoch: 6| Step: 1
Training loss: 0.10551473498344421
Validation loss: 1.5311693606838104

Epoch: 6| Step: 2
Training loss: 0.18208158016204834
Validation loss: 1.5364364975242204

Epoch: 6| Step: 3
Training loss: 0.0681014209985733
Validation loss: 1.5344243459804083

Epoch: 6| Step: 4
Training loss: 0.11034111678600311
Validation loss: 1.5526612266417472

Epoch: 6| Step: 5
Training loss: 0.1607968509197235
Validation loss: 1.540309896392207

Epoch: 6| Step: 6
Training loss: 0.19692161679267883
Validation loss: 1.562793827825977

Epoch: 6| Step: 7
Training loss: 0.0957246869802475
Validation loss: 1.5652006178773858

Epoch: 6| Step: 8
Training loss: 0.12420004606246948
Validation loss: 1.5806855386303318

Epoch: 6| Step: 9
Training loss: 0.10834178328514099
Validation loss: 1.5550352693885885

Epoch: 6| Step: 10
Training loss: 0.11449946463108063
Validation loss: 1.5461820376816617

Epoch: 6| Step: 11
Training loss: 0.09350986033678055
Validation loss: 1.522202964751951

Epoch: 6| Step: 12
Training loss: 0.1333196610212326
Validation loss: 1.5685751797050558

Epoch: 6| Step: 13
Training loss: 0.16514956951141357
Validation loss: 1.5664018713017946

Epoch: 427| Step: 0
Training loss: 0.061060354113578796
Validation loss: 1.5535394453233289

Epoch: 6| Step: 1
Training loss: 0.1579485833644867
Validation loss: 1.5481173184610182

Epoch: 6| Step: 2
Training loss: 0.10529078543186188
Validation loss: 1.5449747026607554

Epoch: 6| Step: 3
Training loss: 0.1442602127790451
Validation loss: 1.532548895446203

Epoch: 6| Step: 4
Training loss: 0.12617021799087524
Validation loss: 1.530565470777532

Epoch: 6| Step: 5
Training loss: 0.10005776584148407
Validation loss: 1.5065471408187703

Epoch: 6| Step: 6
Training loss: 0.0921894758939743
Validation loss: 1.5179444436104066

Epoch: 6| Step: 7
Training loss: 0.1069430261850357
Validation loss: 1.5101341162958453

Epoch: 6| Step: 8
Training loss: 0.13590586185455322
Validation loss: 1.5265903645946133

Epoch: 6| Step: 9
Training loss: 0.11939649283885956
Validation loss: 1.502079088200805

Epoch: 6| Step: 10
Training loss: 0.16580241918563843
Validation loss: 1.4946740609343334

Epoch: 6| Step: 11
Training loss: 0.12911111116409302
Validation loss: 1.494636244671319

Epoch: 6| Step: 12
Training loss: 0.14752019941806793
Validation loss: 1.5189037720362346

Epoch: 6| Step: 13
Training loss: 0.05775135010480881
Validation loss: 1.4894573021960515

Epoch: 428| Step: 0
Training loss: 0.12272807210683823
Validation loss: 1.497445753825608

Epoch: 6| Step: 1
Training loss: 0.09277860820293427
Validation loss: 1.517719204066902

Epoch: 6| Step: 2
Training loss: 0.12257447838783264
Validation loss: 1.5313376547187887

Epoch: 6| Step: 3
Training loss: 0.1322464793920517
Validation loss: 1.5480089456804338

Epoch: 6| Step: 4
Training loss: 0.15681076049804688
Validation loss: 1.5804796141962851

Epoch: 6| Step: 5
Training loss: 0.1372290551662445
Validation loss: 1.55377524001624

Epoch: 6| Step: 6
Training loss: 0.16723205149173737
Validation loss: 1.5066378770336029

Epoch: 6| Step: 7
Training loss: 0.12005675584077835
Validation loss: 1.4783461965540403

Epoch: 6| Step: 8
Training loss: 0.2022111415863037
Validation loss: 1.4546779176240325

Epoch: 6| Step: 9
Training loss: 0.11374498158693314
Validation loss: 1.47338475847757

Epoch: 6| Step: 10
Training loss: 0.1484721601009369
Validation loss: 1.473754696948554

Epoch: 6| Step: 11
Training loss: 0.11276095360517502
Validation loss: 1.4889131592166038

Epoch: 6| Step: 12
Training loss: 0.08443106710910797
Validation loss: 1.51640538630947

Epoch: 6| Step: 13
Training loss: 0.08635006844997406
Validation loss: 1.5356325154663415

Epoch: 429| Step: 0
Training loss: 0.12442880868911743
Validation loss: 1.512766739373566

Epoch: 6| Step: 1
Training loss: 0.13306888937950134
Validation loss: 1.5506920635059316

Epoch: 6| Step: 2
Training loss: 0.1596047580242157
Validation loss: 1.541511309403245

Epoch: 6| Step: 3
Training loss: 0.11169098317623138
Validation loss: 1.553158793398129

Epoch: 6| Step: 4
Training loss: 0.09321558475494385
Validation loss: 1.5525225195833432

Epoch: 6| Step: 5
Training loss: 0.12346155941486359
Validation loss: 1.556105173403217

Epoch: 6| Step: 6
Training loss: 0.09473639726638794
Validation loss: 1.5648721520618727

Epoch: 6| Step: 7
Training loss: 0.10347072780132294
Validation loss: 1.5598241923957743

Epoch: 6| Step: 8
Training loss: 0.09609749913215637
Validation loss: 1.557169682236128

Epoch: 6| Step: 9
Training loss: 0.1633257120847702
Validation loss: 1.538349166993172

Epoch: 6| Step: 10
Training loss: 0.12913410365581512
Validation loss: 1.5274254070815219

Epoch: 6| Step: 11
Training loss: 0.13200324773788452
Validation loss: 1.5380056776026243

Epoch: 6| Step: 12
Training loss: 0.12604360282421112
Validation loss: 1.5212667936919837

Epoch: 6| Step: 13
Training loss: 0.09424599260091782
Validation loss: 1.489808342790091

Epoch: 430| Step: 0
Training loss: 0.198020800948143
Validation loss: 1.5173696753799275

Epoch: 6| Step: 1
Training loss: 0.08838068693876266
Validation loss: 1.496071022043946

Epoch: 6| Step: 2
Training loss: 0.16984853148460388
Validation loss: 1.4781291036195652

Epoch: 6| Step: 3
Training loss: 0.1805804818868637
Validation loss: 1.4982710173053126

Epoch: 6| Step: 4
Training loss: 0.08222787082195282
Validation loss: 1.48294940751086

Epoch: 6| Step: 5
Training loss: 0.13616575300693512
Validation loss: 1.4786988060961488

Epoch: 6| Step: 6
Training loss: 0.11614112555980682
Validation loss: 1.4488711869844826

Epoch: 6| Step: 7
Training loss: 0.1453578770160675
Validation loss: 1.4483205221032585

Epoch: 6| Step: 8
Training loss: 0.14884424209594727
Validation loss: 1.5043876760749406

Epoch: 6| Step: 9
Training loss: 0.07505446672439575
Validation loss: 1.4688999665680753

Epoch: 6| Step: 10
Training loss: 0.11387372761964798
Validation loss: 1.5396205936708758

Epoch: 6| Step: 11
Training loss: 0.077066570520401
Validation loss: 1.550099520273106

Epoch: 6| Step: 12
Training loss: 0.11475905776023865
Validation loss: 1.5514764606311757

Epoch: 6| Step: 13
Training loss: 0.19409054517745972
Validation loss: 1.5977028480140112

Epoch: 431| Step: 0
Training loss: 0.09910546988248825
Validation loss: 1.5997332219154603

Epoch: 6| Step: 1
Training loss: 0.16816481947898865
Validation loss: 1.5965669321757492

Epoch: 6| Step: 2
Training loss: 0.21164435148239136
Validation loss: 1.6142776909694876

Epoch: 6| Step: 3
Training loss: 0.18189996480941772
Validation loss: 1.5570962326501006

Epoch: 6| Step: 4
Training loss: 0.1032133549451828
Validation loss: 1.5238330659045969

Epoch: 6| Step: 5
Training loss: 0.13491299748420715
Validation loss: 1.5192522662942127

Epoch: 6| Step: 6
Training loss: 0.07838401198387146
Validation loss: 1.5221656753170876

Epoch: 6| Step: 7
Training loss: 0.12526914477348328
Validation loss: 1.5303717492729105

Epoch: 6| Step: 8
Training loss: 0.12344837188720703
Validation loss: 1.515055037313892

Epoch: 6| Step: 9
Training loss: 0.21876388788223267
Validation loss: 1.5083609755321215

Epoch: 6| Step: 10
Training loss: 0.08695165812969208
Validation loss: 1.492074643411944

Epoch: 6| Step: 11
Training loss: 0.09666711837053299
Validation loss: 1.5443841654767272

Epoch: 6| Step: 12
Training loss: 0.0907348170876503
Validation loss: 1.521057709570854

Epoch: 6| Step: 13
Training loss: 0.06447935104370117
Validation loss: 1.571120100636636

Epoch: 432| Step: 0
Training loss: 0.18593943119049072
Validation loss: 1.544080598379976

Epoch: 6| Step: 1
Training loss: 0.26739737391471863
Validation loss: 1.5918828466887116

Epoch: 6| Step: 2
Training loss: 0.08476073294878006
Validation loss: 1.6051888760700022

Epoch: 6| Step: 3
Training loss: 0.17068803310394287
Validation loss: 1.6001714339820288

Epoch: 6| Step: 4
Training loss: 0.12530404329299927
Validation loss: 1.578989936459449

Epoch: 6| Step: 5
Training loss: 0.1300259679555893
Validation loss: 1.5597723350729993

Epoch: 6| Step: 6
Training loss: 0.1387891173362732
Validation loss: 1.53678443226763

Epoch: 6| Step: 7
Training loss: 0.12377047538757324
Validation loss: 1.5332585278377737

Epoch: 6| Step: 8
Training loss: 0.06242186576128006
Validation loss: 1.5231742640977264

Epoch: 6| Step: 9
Training loss: 0.05806255340576172
Validation loss: 1.5368039300364833

Epoch: 6| Step: 10
Training loss: 0.16463541984558105
Validation loss: 1.5142664229998024

Epoch: 6| Step: 11
Training loss: 0.16636133193969727
Validation loss: 1.5270520948594617

Epoch: 6| Step: 12
Training loss: 0.12315282225608826
Validation loss: 1.5134454978409635

Epoch: 6| Step: 13
Training loss: 0.12370100617408752
Validation loss: 1.5607062411564652

Epoch: 433| Step: 0
Training loss: 0.15599311888217926
Validation loss: 1.5629820259668494

Epoch: 6| Step: 1
Training loss: 0.1512906402349472
Validation loss: 1.567177467448737

Epoch: 6| Step: 2
Training loss: 0.1413712501525879
Validation loss: 1.5665661519573582

Epoch: 6| Step: 3
Training loss: 0.060907237231731415
Validation loss: 1.6131786095198763

Epoch: 6| Step: 4
Training loss: 0.11669005453586578
Validation loss: 1.5769870050491825

Epoch: 6| Step: 5
Training loss: 0.1502973586320877
Validation loss: 1.5937454905561221

Epoch: 6| Step: 6
Training loss: 0.2033195197582245
Validation loss: 1.6049213358151015

Epoch: 6| Step: 7
Training loss: 0.24128291010856628
Validation loss: 1.5837602743538477

Epoch: 6| Step: 8
Training loss: 0.11612759530544281
Validation loss: 1.567577406924258

Epoch: 6| Step: 9
Training loss: 0.07196945697069168
Validation loss: 1.5328775830166315

Epoch: 6| Step: 10
Training loss: 0.12793006002902985
Validation loss: 1.5417250074366087

Epoch: 6| Step: 11
Training loss: 0.12507566809654236
Validation loss: 1.5204177236044278

Epoch: 6| Step: 12
Training loss: 0.09873946011066437
Validation loss: 1.5254609482262724

Epoch: 6| Step: 13
Training loss: 0.10462066531181335
Validation loss: 1.5223954140499074

Epoch: 434| Step: 0
Training loss: 0.14846259355545044
Validation loss: 1.5159828893599971

Epoch: 6| Step: 1
Training loss: 0.1459311544895172
Validation loss: 1.5158702814450828

Epoch: 6| Step: 2
Training loss: 0.1329546868801117
Validation loss: 1.509683221899053

Epoch: 6| Step: 3
Training loss: 0.19137181341648102
Validation loss: 1.5014108996237479

Epoch: 6| Step: 4
Training loss: 0.09638045728206635
Validation loss: 1.518028038804249

Epoch: 6| Step: 5
Training loss: 0.10121776163578033
Validation loss: 1.5467626587037118

Epoch: 6| Step: 6
Training loss: 0.05688153952360153
Validation loss: 1.5116864763280398

Epoch: 6| Step: 7
Training loss: 0.11386971175670624
Validation loss: 1.5249570441502396

Epoch: 6| Step: 8
Training loss: 0.10041838884353638
Validation loss: 1.5273314047885198

Epoch: 6| Step: 9
Training loss: 0.11687926203012466
Validation loss: 1.509709035196612

Epoch: 6| Step: 10
Training loss: 0.07590620219707489
Validation loss: 1.522256879396336

Epoch: 6| Step: 11
Training loss: 0.11006107181310654
Validation loss: 1.5548614596807828

Epoch: 6| Step: 12
Training loss: 0.1452832669019699
Validation loss: 1.506917538181428

Epoch: 6| Step: 13
Training loss: 0.07110194861888885
Validation loss: 1.5275000667059293

Epoch: 435| Step: 0
Training loss: 0.13030186295509338
Validation loss: 1.5294027174672773

Epoch: 6| Step: 1
Training loss: 0.15752610564231873
Validation loss: 1.5306365156686434

Epoch: 6| Step: 2
Training loss: 0.12281123548746109
Validation loss: 1.4991009543018956

Epoch: 6| Step: 3
Training loss: 0.18639372289180756
Validation loss: 1.4995847325171194

Epoch: 6| Step: 4
Training loss: 0.13629963994026184
Validation loss: 1.499859530438659

Epoch: 6| Step: 5
Training loss: 0.10752878338098526
Validation loss: 1.5218027971124137

Epoch: 6| Step: 6
Training loss: 0.09353071451187134
Validation loss: 1.5348936832079323

Epoch: 6| Step: 7
Training loss: 0.13026632368564606
Validation loss: 1.5304930299840949

Epoch: 6| Step: 8
Training loss: 0.09263355284929276
Validation loss: 1.5378998069353

Epoch: 6| Step: 9
Training loss: 0.06920389086008072
Validation loss: 1.5652219505720242

Epoch: 6| Step: 10
Training loss: 0.10263632237911224
Validation loss: 1.5668680328194813

Epoch: 6| Step: 11
Training loss: 0.13606885075569153
Validation loss: 1.57914867965124

Epoch: 6| Step: 12
Training loss: 0.15900535881519318
Validation loss: 1.5892888320389615

Epoch: 6| Step: 13
Training loss: 0.15293465554714203
Validation loss: 1.6592320646009138

Epoch: 436| Step: 0
Training loss: 0.2263169288635254
Validation loss: 1.5908792172708819

Epoch: 6| Step: 1
Training loss: 0.13428205251693726
Validation loss: 1.5979377672236452

Epoch: 6| Step: 2
Training loss: 0.08893908560276031
Validation loss: 1.567836271819248

Epoch: 6| Step: 3
Training loss: 0.08523162454366684
Validation loss: 1.5764085349216257

Epoch: 6| Step: 4
Training loss: 0.15832723677158356
Validation loss: 1.522999648124941

Epoch: 6| Step: 5
Training loss: 0.13396355509757996
Validation loss: 1.5040487371465212

Epoch: 6| Step: 6
Training loss: 0.1118396669626236
Validation loss: 1.4683214579859087

Epoch: 6| Step: 7
Training loss: 0.06761428713798523
Validation loss: 1.4692026940725182

Epoch: 6| Step: 8
Training loss: 0.119902603328228
Validation loss: 1.4603307477889522

Epoch: 6| Step: 9
Training loss: 0.15873661637306213
Validation loss: 1.4611918400692683

Epoch: 6| Step: 10
Training loss: 0.18511144816875458
Validation loss: 1.4332753407057894

Epoch: 6| Step: 11
Training loss: 0.09144795686006546
Validation loss: 1.4447228254810456

Epoch: 6| Step: 12
Training loss: 0.20128881931304932
Validation loss: 1.4816547555308188

Epoch: 6| Step: 13
Training loss: 0.1724814772605896
Validation loss: 1.4938998030078026

Epoch: 437| Step: 0
Training loss: 0.10064409673213959
Validation loss: 1.5380288964958602

Epoch: 6| Step: 1
Training loss: 0.14723873138427734
Validation loss: 1.5802098576740553

Epoch: 6| Step: 2
Training loss: 0.14731259644031525
Validation loss: 1.6044582679707518

Epoch: 6| Step: 3
Training loss: 0.08739139139652252
Validation loss: 1.6111843009148874

Epoch: 6| Step: 4
Training loss: 0.1416589319705963
Validation loss: 1.639069616153676

Epoch: 6| Step: 5
Training loss: 0.1403072476387024
Validation loss: 1.638844887415568

Epoch: 6| Step: 6
Training loss: 0.21642771363258362
Validation loss: 1.6074701688622917

Epoch: 6| Step: 7
Training loss: 0.0909646600484848
Validation loss: 1.5700798432032268

Epoch: 6| Step: 8
Training loss: 0.24946483969688416
Validation loss: 1.5642330185059579

Epoch: 6| Step: 9
Training loss: 0.11312073469161987
Validation loss: 1.5238831966154036

Epoch: 6| Step: 10
Training loss: 0.11134947836399078
Validation loss: 1.5329363192281416

Epoch: 6| Step: 11
Training loss: 0.12487393617630005
Validation loss: 1.5381468765197261

Epoch: 6| Step: 12
Training loss: 0.1820637285709381
Validation loss: 1.5018542415352278

Epoch: 6| Step: 13
Training loss: 0.1675533652305603
Validation loss: 1.5340819198598143

Epoch: 438| Step: 0
Training loss: 0.13771259784698486
Validation loss: 1.4816462660348544

Epoch: 6| Step: 1
Training loss: 0.13424012064933777
Validation loss: 1.531879243030343

Epoch: 6| Step: 2
Training loss: 0.11510630697011948
Validation loss: 1.5322994916669783

Epoch: 6| Step: 3
Training loss: 0.09136973321437836
Validation loss: 1.5290560594169043

Epoch: 6| Step: 4
Training loss: 0.13706740736961365
Validation loss: 1.537699612238074

Epoch: 6| Step: 5
Training loss: 0.14124466478824615
Validation loss: 1.5326256521286503

Epoch: 6| Step: 6
Training loss: 0.12186183035373688
Validation loss: 1.5506028206117692

Epoch: 6| Step: 7
Training loss: 0.15659499168395996
Validation loss: 1.5444479847467074

Epoch: 6| Step: 8
Training loss: 0.18822847306728363
Validation loss: 1.5416588911446192

Epoch: 6| Step: 9
Training loss: 0.11916491389274597
Validation loss: 1.5435793220355947

Epoch: 6| Step: 10
Training loss: 0.14206790924072266
Validation loss: 1.5297427792702951

Epoch: 6| Step: 11
Training loss: 0.0846148431301117
Validation loss: 1.5379568056393695

Epoch: 6| Step: 12
Training loss: 0.14357903599739075
Validation loss: 1.5230299772754792

Epoch: 6| Step: 13
Training loss: 0.21343965828418732
Validation loss: 1.520677013422853

Epoch: 439| Step: 0
Training loss: 0.09732039272785187
Validation loss: 1.5378475137936172

Epoch: 6| Step: 1
Training loss: 0.09612388908863068
Validation loss: 1.521363398080231

Epoch: 6| Step: 2
Training loss: 0.13290631771087646
Validation loss: 1.5404342682130876

Epoch: 6| Step: 3
Training loss: 0.1271820366382599
Validation loss: 1.5574796815072336

Epoch: 6| Step: 4
Training loss: 0.12302474677562714
Validation loss: 1.5121440451632264

Epoch: 6| Step: 5
Training loss: 0.12215539813041687
Validation loss: 1.515816327064268

Epoch: 6| Step: 6
Training loss: 0.13127240538597107
Validation loss: 1.5232828394059212

Epoch: 6| Step: 7
Training loss: 0.16136513650417328
Validation loss: 1.5416134172870266

Epoch: 6| Step: 8
Training loss: 0.20081138610839844
Validation loss: 1.533442243452995

Epoch: 6| Step: 9
Training loss: 0.13232983648777008
Validation loss: 1.541189125789109

Epoch: 6| Step: 10
Training loss: 0.16764183342456818
Validation loss: 1.564828468907264

Epoch: 6| Step: 11
Training loss: 0.12780115008354187
Validation loss: 1.5489736449333928

Epoch: 6| Step: 12
Training loss: 0.11823631823062897
Validation loss: 1.5340441337195776

Epoch: 6| Step: 13
Training loss: 0.0539870522916317
Validation loss: 1.5514585837241142

Epoch: 440| Step: 0
Training loss: 0.13886034488677979
Validation loss: 1.56891006295399

Epoch: 6| Step: 1
Training loss: 0.1485689878463745
Validation loss: 1.5458636886330062

Epoch: 6| Step: 2
Training loss: 0.1450294554233551
Validation loss: 1.5113475886724328

Epoch: 6| Step: 3
Training loss: 0.09579931944608688
Validation loss: 1.5277035005630986

Epoch: 6| Step: 4
Training loss: 0.1212242990732193
Validation loss: 1.483920830552296

Epoch: 6| Step: 5
Training loss: 0.16444247961044312
Validation loss: 1.4933220212177565

Epoch: 6| Step: 6
Training loss: 0.1578769087791443
Validation loss: 1.4992090329047172

Epoch: 6| Step: 7
Training loss: 0.11604372411966324
Validation loss: 1.4896880695896764

Epoch: 6| Step: 8
Training loss: 0.07951328158378601
Validation loss: 1.4753603525059198

Epoch: 6| Step: 9
Training loss: 0.11325643211603165
Validation loss: 1.4980079820079188

Epoch: 6| Step: 10
Training loss: 0.15862132608890533
Validation loss: 1.5131252017072452

Epoch: 6| Step: 11
Training loss: 0.1959933638572693
Validation loss: 1.529669274565994

Epoch: 6| Step: 12
Training loss: 0.14021386206150055
Validation loss: 1.5459208962737874

Epoch: 6| Step: 13
Training loss: 0.17207951843738556
Validation loss: 1.5207355612067766

Epoch: 441| Step: 0
Training loss: 0.13344211876392365
Validation loss: 1.5081286584177325

Epoch: 6| Step: 1
Training loss: 0.08958417922258377
Validation loss: 1.5289579431215923

Epoch: 6| Step: 2
Training loss: 0.12721438705921173
Validation loss: 1.51096890177778

Epoch: 6| Step: 3
Training loss: 0.12007901072502136
Validation loss: 1.5256795293541365

Epoch: 6| Step: 4
Training loss: 0.11725076287984848
Validation loss: 1.5032350658088602

Epoch: 6| Step: 5
Training loss: 0.098573699593544
Validation loss: 1.5280209049101798

Epoch: 6| Step: 6
Training loss: 0.08447468280792236
Validation loss: 1.5205052360411613

Epoch: 6| Step: 7
Training loss: 0.11056527495384216
Validation loss: 1.543459556436026

Epoch: 6| Step: 8
Training loss: 0.06706635653972626
Validation loss: 1.5520032503271615

Epoch: 6| Step: 9
Training loss: 0.11579685658216476
Validation loss: 1.5829349487058577

Epoch: 6| Step: 10
Training loss: 0.15486297011375427
Validation loss: 1.601369623214968

Epoch: 6| Step: 11
Training loss: 0.14997027814388275
Validation loss: 1.5495738701153827

Epoch: 6| Step: 12
Training loss: 0.11817943304777145
Validation loss: 1.5856122432216522

Epoch: 6| Step: 13
Training loss: 0.15014426410198212
Validation loss: 1.6037077878111152

Epoch: 442| Step: 0
Training loss: 0.07869483530521393
Validation loss: 1.6077478598522883

Epoch: 6| Step: 1
Training loss: 0.15254288911819458
Validation loss: 1.5846903683036886

Epoch: 6| Step: 2
Training loss: 0.14821746945381165
Validation loss: 1.5948609869967225

Epoch: 6| Step: 3
Training loss: 0.14464548230171204
Validation loss: 1.566526460391219

Epoch: 6| Step: 4
Training loss: 0.15635444223880768
Validation loss: 1.570141932015778

Epoch: 6| Step: 5
Training loss: 0.07209008932113647
Validation loss: 1.562582488982908

Epoch: 6| Step: 6
Training loss: 0.12999936938285828
Validation loss: 1.5497927511892011

Epoch: 6| Step: 7
Training loss: 0.09504396468400955
Validation loss: 1.523007567210864

Epoch: 6| Step: 8
Training loss: 0.1096840500831604
Validation loss: 1.5467902293769262

Epoch: 6| Step: 9
Training loss: 0.11224239319562912
Validation loss: 1.5093503895626272

Epoch: 6| Step: 10
Training loss: 0.08101613819599152
Validation loss: 1.4996833237268592

Epoch: 6| Step: 11
Training loss: 0.15788069367408752
Validation loss: 1.51442204752276

Epoch: 6| Step: 12
Training loss: 0.0961894765496254
Validation loss: 1.5120784204493287

Epoch: 6| Step: 13
Training loss: 0.11597803235054016
Validation loss: 1.5238995436699159

Epoch: 443| Step: 0
Training loss: 0.1653386801481247
Validation loss: 1.540887200704185

Epoch: 6| Step: 1
Training loss: 0.12546643614768982
Validation loss: 1.5131055501199537

Epoch: 6| Step: 2
Training loss: 0.14349587261676788
Validation loss: 1.5124470841500066

Epoch: 6| Step: 3
Training loss: 0.0922173410654068
Validation loss: 1.4728521557264431

Epoch: 6| Step: 4
Training loss: 0.08539236336946487
Validation loss: 1.4866020602564658

Epoch: 6| Step: 5
Training loss: 0.12612350285053253
Validation loss: 1.5040534375816264

Epoch: 6| Step: 6
Training loss: 0.13225489854812622
Validation loss: 1.4955403253596316

Epoch: 6| Step: 7
Training loss: 0.19847740232944489
Validation loss: 1.5056099366116267

Epoch: 6| Step: 8
Training loss: 0.13779079914093018
Validation loss: 1.4990532096996103

Epoch: 6| Step: 9
Training loss: 0.10519925504922867
Validation loss: 1.5024788956488333

Epoch: 6| Step: 10
Training loss: 0.13034296035766602
Validation loss: 1.4873247954153246

Epoch: 6| Step: 11
Training loss: 0.0996042788028717
Validation loss: 1.4918313654520179

Epoch: 6| Step: 12
Training loss: 0.09657829999923706
Validation loss: 1.5372402296271375

Epoch: 6| Step: 13
Training loss: 0.19111312925815582
Validation loss: 1.5030561339470647

Epoch: 444| Step: 0
Training loss: 0.13394123315811157
Validation loss: 1.5248417206989822

Epoch: 6| Step: 1
Training loss: 0.1504644900560379
Validation loss: 1.5273207554253199

Epoch: 6| Step: 2
Training loss: 0.17397277057170868
Validation loss: 1.513053838924695

Epoch: 6| Step: 3
Training loss: 0.17481108009815216
Validation loss: 1.5163283489083732

Epoch: 6| Step: 4
Training loss: 0.1126287430524826
Validation loss: 1.5254510628279818

Epoch: 6| Step: 5
Training loss: 0.08694325387477875
Validation loss: 1.4999609313985354

Epoch: 6| Step: 6
Training loss: 0.0895676538348198
Validation loss: 1.5520547871948571

Epoch: 6| Step: 7
Training loss: 0.09344500303268433
Validation loss: 1.5353106465390933

Epoch: 6| Step: 8
Training loss: 0.06564624607563019
Validation loss: 1.5646715497457853

Epoch: 6| Step: 9
Training loss: 0.16424530744552612
Validation loss: 1.5745620701902656

Epoch: 6| Step: 10
Training loss: 0.09958330541849136
Validation loss: 1.59443465868632

Epoch: 6| Step: 11
Training loss: 0.2007211446762085
Validation loss: 1.6046901249116468

Epoch: 6| Step: 12
Training loss: 0.15764081478118896
Validation loss: 1.5716135758225636

Epoch: 6| Step: 13
Training loss: 0.05330363288521767
Validation loss: 1.604033681654161

Epoch: 445| Step: 0
Training loss: 0.12332005053758621
Validation loss: 1.6040360081580378

Epoch: 6| Step: 1
Training loss: 0.09916456043720245
Validation loss: 1.5965244577777

Epoch: 6| Step: 2
Training loss: 0.14886723458766937
Validation loss: 1.5702474072415342

Epoch: 6| Step: 3
Training loss: 0.05413854122161865
Validation loss: 1.5602084680270123

Epoch: 6| Step: 4
Training loss: 0.07438408583402634
Validation loss: 1.572136116284196

Epoch: 6| Step: 5
Training loss: 0.0773085504770279
Validation loss: 1.5601751374942001

Epoch: 6| Step: 6
Training loss: 0.06874454021453857
Validation loss: 1.5211830959525159

Epoch: 6| Step: 7
Training loss: 0.08886093646287918
Validation loss: 1.537209765885466

Epoch: 6| Step: 8
Training loss: 0.08938255161046982
Validation loss: 1.5031915063499122

Epoch: 6| Step: 9
Training loss: 0.1315310150384903
Validation loss: 1.5178391856531943

Epoch: 6| Step: 10
Training loss: 0.2196301370859146
Validation loss: 1.5172536168047177

Epoch: 6| Step: 11
Training loss: 0.08625346422195435
Validation loss: 1.5342279121439943

Epoch: 6| Step: 12
Training loss: 0.06724075973033905
Validation loss: 1.5258024578453393

Epoch: 6| Step: 13
Training loss: 0.052878592163324356
Validation loss: 1.5650817937748407

Epoch: 446| Step: 0
Training loss: 0.07528913021087646
Validation loss: 1.5423424449018253

Epoch: 6| Step: 1
Training loss: 0.13471847772598267
Validation loss: 1.561669009988026

Epoch: 6| Step: 2
Training loss: 0.12540073692798615
Validation loss: 1.5762119472667735

Epoch: 6| Step: 3
Training loss: 0.20792394876480103
Validation loss: 1.5704846535959551

Epoch: 6| Step: 4
Training loss: 0.09187716245651245
Validation loss: 1.5788010820265739

Epoch: 6| Step: 5
Training loss: 0.13114023208618164
Validation loss: 1.5766716772510159

Epoch: 6| Step: 6
Training loss: 0.0957166850566864
Validation loss: 1.5714248880263297

Epoch: 6| Step: 7
Training loss: 0.1932051181793213
Validation loss: 1.5815927995148527

Epoch: 6| Step: 8
Training loss: 0.10493810474872589
Validation loss: 1.5711579713770139

Epoch: 6| Step: 9
Training loss: 0.09561391174793243
Validation loss: 1.5879889085728636

Epoch: 6| Step: 10
Training loss: 0.11964554339647293
Validation loss: 1.5495420694351196

Epoch: 6| Step: 11
Training loss: 0.08508874475955963
Validation loss: 1.529481723744382

Epoch: 6| Step: 12
Training loss: 0.06650608777999878
Validation loss: 1.5572263476669148

Epoch: 6| Step: 13
Training loss: 0.06707891821861267
Validation loss: 1.5639279055339035

Epoch: 447| Step: 0
Training loss: 0.1456417739391327
Validation loss: 1.5563745050020115

Epoch: 6| Step: 1
Training loss: 0.06012843921780586
Validation loss: 1.5437133440407373

Epoch: 6| Step: 2
Training loss: 0.17155668139457703
Validation loss: 1.5095165288576515

Epoch: 6| Step: 3
Training loss: 0.12410588562488556
Validation loss: 1.5637358183501868

Epoch: 6| Step: 4
Training loss: 0.13004650175571442
Validation loss: 1.5107153500280073

Epoch: 6| Step: 5
Training loss: 0.07957402616739273
Validation loss: 1.5547646976286364

Epoch: 6| Step: 6
Training loss: 0.10232464969158173
Validation loss: 1.5234899174782537

Epoch: 6| Step: 7
Training loss: 0.12871521711349487
Validation loss: 1.559387432631626

Epoch: 6| Step: 8
Training loss: 0.16946741938591003
Validation loss: 1.5627449045899093

Epoch: 6| Step: 9
Training loss: 0.10200386494398117
Validation loss: 1.5544643773827502

Epoch: 6| Step: 10
Training loss: 0.1413474678993225
Validation loss: 1.5613552472924674

Epoch: 6| Step: 11
Training loss: 0.12456735968589783
Validation loss: 1.610511322175303

Epoch: 6| Step: 12
Training loss: 0.13687223196029663
Validation loss: 1.6546703846223894

Epoch: 6| Step: 13
Training loss: 0.07517126947641373
Validation loss: 1.6173766351515246

Epoch: 448| Step: 0
Training loss: 0.15578071773052216
Validation loss: 1.6266908402084022

Epoch: 6| Step: 1
Training loss: 0.1297915279865265
Validation loss: 1.6397510100436468

Epoch: 6| Step: 2
Training loss: 0.18646231293678284
Validation loss: 1.6096015322592951

Epoch: 6| Step: 3
Training loss: 0.14510580897331238
Validation loss: 1.5793668544420632

Epoch: 6| Step: 4
Training loss: 0.17583395540714264
Validation loss: 1.5618310154125254

Epoch: 6| Step: 5
Training loss: 0.08781735599040985
Validation loss: 1.5356127036515104

Epoch: 6| Step: 6
Training loss: 0.09949113428592682
Validation loss: 1.5027988200546594

Epoch: 6| Step: 7
Training loss: 0.06612987071275711
Validation loss: 1.4711344831733293

Epoch: 6| Step: 8
Training loss: 0.11549915373325348
Validation loss: 1.4810846544081164

Epoch: 6| Step: 9
Training loss: 0.17010462284088135
Validation loss: 1.42169701796706

Epoch: 6| Step: 10
Training loss: 0.11648231744766235
Validation loss: 1.4654476790017978

Epoch: 6| Step: 11
Training loss: 0.14007717370986938
Validation loss: 1.4702787098064218

Epoch: 6| Step: 12
Training loss: 0.13551315665245056
Validation loss: 1.4955343674587946

Epoch: 6| Step: 13
Training loss: 0.25392839312553406
Validation loss: 1.4871315110114314

Epoch: 449| Step: 0
Training loss: 0.11224927753210068
Validation loss: 1.5032735588730022

Epoch: 6| Step: 1
Training loss: 0.14156727492809296
Validation loss: 1.526843350420716

Epoch: 6| Step: 2
Training loss: 0.19371384382247925
Validation loss: 1.5112579637958157

Epoch: 6| Step: 3
Training loss: 0.13539831340312958
Validation loss: 1.528428743282954

Epoch: 6| Step: 4
Training loss: 0.10317093133926392
Validation loss: 1.5090180135542346

Epoch: 6| Step: 5
Training loss: 0.13866467773914337
Validation loss: 1.524201048317776

Epoch: 6| Step: 6
Training loss: 0.10072463005781174
Validation loss: 1.504544190181199

Epoch: 6| Step: 7
Training loss: 0.09688875079154968
Validation loss: 1.4925530969455678

Epoch: 6| Step: 8
Training loss: 0.10125254839658737
Validation loss: 1.5307651591557327

Epoch: 6| Step: 9
Training loss: 0.10809385776519775
Validation loss: 1.549259872846706

Epoch: 6| Step: 10
Training loss: 0.09598444402217865
Validation loss: 1.5579866427247242

Epoch: 6| Step: 11
Training loss: 0.0705149918794632
Validation loss: 1.5667103516158236

Epoch: 6| Step: 12
Training loss: 0.09767492860555649
Validation loss: 1.5734029187951037

Epoch: 6| Step: 13
Training loss: 0.28474971652030945
Validation loss: 1.5636622880094795

Epoch: 450| Step: 0
Training loss: 0.12250717729330063
Validation loss: 1.5755013022371518

Epoch: 6| Step: 1
Training loss: 0.08375896513462067
Validation loss: 1.549410027842368

Epoch: 6| Step: 2
Training loss: 0.0842037945985794
Validation loss: 1.5747910109899377

Epoch: 6| Step: 3
Training loss: 0.1140875518321991
Validation loss: 1.5453863041375273

Epoch: 6| Step: 4
Training loss: 0.10167168080806732
Validation loss: 1.5703703331690964

Epoch: 6| Step: 5
Training loss: 0.19130930304527283
Validation loss: 1.5370186637806635

Epoch: 6| Step: 6
Training loss: 0.11830797791481018
Validation loss: 1.5290732627273889

Epoch: 6| Step: 7
Training loss: 0.12069406360387802
Validation loss: 1.533771889184111

Epoch: 6| Step: 8
Training loss: 0.08267180621623993
Validation loss: 1.5146297459961267

Epoch: 6| Step: 9
Training loss: 0.11859501898288727
Validation loss: 1.4898308028456986

Epoch: 6| Step: 10
Training loss: 0.16700167953968048
Validation loss: 1.5046141980796732

Epoch: 6| Step: 11
Training loss: 0.12592849135398865
Validation loss: 1.4885886856304702

Epoch: 6| Step: 12
Training loss: 0.15859855711460114
Validation loss: 1.4855870508378552

Epoch: 6| Step: 13
Training loss: 0.06425020098686218
Validation loss: 1.4962634425009451

Epoch: 451| Step: 0
Training loss: 0.127486914396286
Validation loss: 1.5073871561276015

Epoch: 6| Step: 1
Training loss: 0.07606881856918335
Validation loss: 1.462725124051494

Epoch: 6| Step: 2
Training loss: 0.14168088138103485
Validation loss: 1.4763519815219346

Epoch: 6| Step: 3
Training loss: 0.10431070625782013
Validation loss: 1.50541357199351

Epoch: 6| Step: 4
Training loss: 0.0762527659535408
Validation loss: 1.4974692303647277

Epoch: 6| Step: 5
Training loss: 0.10292373597621918
Validation loss: 1.4991870605817406

Epoch: 6| Step: 6
Training loss: 0.16859170794487
Validation loss: 1.5179046719304976

Epoch: 6| Step: 7
Training loss: 0.24711191654205322
Validation loss: 1.5164301754325948

Epoch: 6| Step: 8
Training loss: 0.12727558612823486
Validation loss: 1.5530352618104668

Epoch: 6| Step: 9
Training loss: 0.12837053835391998
Validation loss: 1.5680516765963646

Epoch: 6| Step: 10
Training loss: 0.1479783058166504
Validation loss: 1.5523616472880046

Epoch: 6| Step: 11
Training loss: 0.11271633207798004
Validation loss: 1.546889389714887

Epoch: 6| Step: 12
Training loss: 0.08393704146146774
Validation loss: 1.5545734154280795

Epoch: 6| Step: 13
Training loss: 0.08860638737678528
Validation loss: 1.5665010329215758

Epoch: 452| Step: 0
Training loss: 0.08948103338479996
Validation loss: 1.5687466488089612

Epoch: 6| Step: 1
Training loss: 0.05799524486064911
Validation loss: 1.5477513279966129

Epoch: 6| Step: 2
Training loss: 0.06299638748168945
Validation loss: 1.549760135271216

Epoch: 6| Step: 3
Training loss: 0.14614993333816528
Validation loss: 1.5598456141769246

Epoch: 6| Step: 4
Training loss: 0.06842118501663208
Validation loss: 1.5510421094074045

Epoch: 6| Step: 5
Training loss: 0.1233719065785408
Validation loss: 1.509158649752217

Epoch: 6| Step: 6
Training loss: 0.11539649963378906
Validation loss: 1.5311175315610823

Epoch: 6| Step: 7
Training loss: 0.08873141556978226
Validation loss: 1.5305738526005899

Epoch: 6| Step: 8
Training loss: 0.09731403738260269
Validation loss: 1.5571231611313359

Epoch: 6| Step: 9
Training loss: 0.12608768045902252
Validation loss: 1.506991993996405

Epoch: 6| Step: 10
Training loss: 0.07939501851797104
Validation loss: 1.5205061358790244

Epoch: 6| Step: 11
Training loss: 0.12074561417102814
Validation loss: 1.5579299542211718

Epoch: 6| Step: 12
Training loss: 0.10593459010124207
Validation loss: 1.5485115294815393

Epoch: 6| Step: 13
Training loss: 0.18540708720684052
Validation loss: 1.525005921881686

Epoch: 453| Step: 0
Training loss: 0.17543165385723114
Validation loss: 1.4976918684538973

Epoch: 6| Step: 1
Training loss: 0.07865128666162491
Validation loss: 1.5173887693753807

Epoch: 6| Step: 2
Training loss: 0.06398850679397583
Validation loss: 1.4933613948924567

Epoch: 6| Step: 3
Training loss: 0.09070895612239838
Validation loss: 1.5067204057529409

Epoch: 6| Step: 4
Training loss: 0.07049065083265305
Validation loss: 1.5064540601545764

Epoch: 6| Step: 5
Training loss: 0.09053793549537659
Validation loss: 1.5204482104188652

Epoch: 6| Step: 6
Training loss: 0.0955742597579956
Validation loss: 1.512134764784126

Epoch: 6| Step: 7
Training loss: 0.08783857524394989
Validation loss: 1.5094185567671252

Epoch: 6| Step: 8
Training loss: 0.12593530118465424
Validation loss: 1.5082797837513748

Epoch: 6| Step: 9
Training loss: 0.12043525278568268
Validation loss: 1.5269888408722416

Epoch: 6| Step: 10
Training loss: 0.10538258403539658
Validation loss: 1.5157586425863288

Epoch: 6| Step: 11
Training loss: 0.19810664653778076
Validation loss: 1.5135350150446738

Epoch: 6| Step: 12
Training loss: 0.06455126404762268
Validation loss: 1.5132069074979393

Epoch: 6| Step: 13
Training loss: 0.08166380971670151
Validation loss: 1.52357151046876

Epoch: 454| Step: 0
Training loss: 0.05606071650981903
Validation loss: 1.5355064484380907

Epoch: 6| Step: 1
Training loss: 0.07741596549749374
Validation loss: 1.4992591258018249

Epoch: 6| Step: 2
Training loss: 0.06402234733104706
Validation loss: 1.5083254498820151

Epoch: 6| Step: 3
Training loss: 0.0825190544128418
Validation loss: 1.4955051688737766

Epoch: 6| Step: 4
Training loss: 0.07434456050395966
Validation loss: 1.5081728222549602

Epoch: 6| Step: 5
Training loss: 0.13310746848583221
Validation loss: 1.5045659631811164

Epoch: 6| Step: 6
Training loss: 0.08070438355207443
Validation loss: 1.4982293004630713

Epoch: 6| Step: 7
Training loss: 0.08833034336566925
Validation loss: 1.511273330257785

Epoch: 6| Step: 8
Training loss: 0.19326172769069672
Validation loss: 1.5071053043488534

Epoch: 6| Step: 9
Training loss: 0.21262863278388977
Validation loss: 1.4908059886706773

Epoch: 6| Step: 10
Training loss: 0.08410681039094925
Validation loss: 1.502230127652486

Epoch: 6| Step: 11
Training loss: 0.07923765480518341
Validation loss: 1.5105771044249177

Epoch: 6| Step: 12
Training loss: 0.0792158916592598
Validation loss: 1.4910620835519606

Epoch: 6| Step: 13
Training loss: 0.09104499965906143
Validation loss: 1.523482161183511

Epoch: 455| Step: 0
Training loss: 0.14317920804023743
Validation loss: 1.4842166823725547

Epoch: 6| Step: 1
Training loss: 0.0736139565706253
Validation loss: 1.5078663928534395

Epoch: 6| Step: 2
Training loss: 0.09099045395851135
Validation loss: 1.5103190175948604

Epoch: 6| Step: 3
Training loss: 0.10801051557064056
Validation loss: 1.5173954899593065

Epoch: 6| Step: 4
Training loss: 0.10654935240745544
Validation loss: 1.527728174322395

Epoch: 6| Step: 5
Training loss: 0.10327461361885071
Validation loss: 1.57393717381262

Epoch: 6| Step: 6
Training loss: 0.15934956073760986
Validation loss: 1.5581244178997573

Epoch: 6| Step: 7
Training loss: 0.0832955464720726
Validation loss: 1.5537573586228073

Epoch: 6| Step: 8
Training loss: 0.19877105951309204
Validation loss: 1.5527608356168192

Epoch: 6| Step: 9
Training loss: 0.11894920468330383
Validation loss: 1.6076266611776044

Epoch: 6| Step: 10
Training loss: 0.11052209883928299
Validation loss: 1.5735875733437077

Epoch: 6| Step: 11
Training loss: 0.09404195845127106
Validation loss: 1.5771622311684392

Epoch: 6| Step: 12
Training loss: 0.06938482820987701
Validation loss: 1.5458559374655447

Epoch: 6| Step: 13
Training loss: 0.09029427915811539
Validation loss: 1.535245168593622

Epoch: 456| Step: 0
Training loss: 0.12732455134391785
Validation loss: 1.4729583776125343

Epoch: 6| Step: 1
Training loss: 0.20839610695838928
Validation loss: 1.4823824180069791

Epoch: 6| Step: 2
Training loss: 0.08453869819641113
Validation loss: 1.4969608822176534

Epoch: 6| Step: 3
Training loss: 0.12148183584213257
Validation loss: 1.4919287184233307

Epoch: 6| Step: 4
Training loss: 0.13862156867980957
Validation loss: 1.4938297540910783

Epoch: 6| Step: 5
Training loss: 0.1081656664609909
Validation loss: 1.51330780213879

Epoch: 6| Step: 6
Training loss: 0.12032286822795868
Validation loss: 1.4807046203203098

Epoch: 6| Step: 7
Training loss: 0.13505849242210388
Validation loss: 1.5328728114404986

Epoch: 6| Step: 8
Training loss: 0.09094163775444031
Validation loss: 1.5125460547785605

Epoch: 6| Step: 9
Training loss: 0.10494755208492279
Validation loss: 1.5290601074054677

Epoch: 6| Step: 10
Training loss: 0.0822063684463501
Validation loss: 1.5724796954021658

Epoch: 6| Step: 11
Training loss: 0.14144012331962585
Validation loss: 1.5757583097745014

Epoch: 6| Step: 12
Training loss: 0.18015776574611664
Validation loss: 1.5829587110909082

Epoch: 6| Step: 13
Training loss: 0.1735815405845642
Validation loss: 1.5931303770311418

Epoch: 457| Step: 0
Training loss: 0.11259995400905609
Validation loss: 1.5546408776314027

Epoch: 6| Step: 1
Training loss: 0.16170208156108856
Validation loss: 1.5529117853410783

Epoch: 6| Step: 2
Training loss: 0.10331408679485321
Validation loss: 1.5498542247279998

Epoch: 6| Step: 3
Training loss: 0.1425953358411789
Validation loss: 1.5294014202651156

Epoch: 6| Step: 4
Training loss: 0.13085156679153442
Validation loss: 1.5440326480455295

Epoch: 6| Step: 5
Training loss: 0.1505899429321289
Validation loss: 1.525898733446675

Epoch: 6| Step: 6
Training loss: 0.12567348778247833
Validation loss: 1.494682531202993

Epoch: 6| Step: 7
Training loss: 0.08261172473430634
Validation loss: 1.5208886977164977

Epoch: 6| Step: 8
Training loss: 0.16439703106880188
Validation loss: 1.521465810396338

Epoch: 6| Step: 9
Training loss: 0.06583757698535919
Validation loss: 1.5274809509195306

Epoch: 6| Step: 10
Training loss: 0.07601609081029892
Validation loss: 1.5023218841962918

Epoch: 6| Step: 11
Training loss: 0.07584398984909058
Validation loss: 1.497609834517202

Epoch: 6| Step: 12
Training loss: 0.04832154139876366
Validation loss: 1.47262781025261

Epoch: 6| Step: 13
Training loss: 0.1518278270959854
Validation loss: 1.5118139200313117

Epoch: 458| Step: 0
Training loss: 0.10046951472759247
Validation loss: 1.506334074081913

Epoch: 6| Step: 1
Training loss: 0.11478260159492493
Validation loss: 1.498650400869308

Epoch: 6| Step: 2
Training loss: 0.07117803394794464
Validation loss: 1.5303579081771195

Epoch: 6| Step: 3
Training loss: 0.1288178265094757
Validation loss: 1.524182613818876

Epoch: 6| Step: 4
Training loss: 0.06481567770242691
Validation loss: 1.487953015553054

Epoch: 6| Step: 5
Training loss: 0.11127603054046631
Validation loss: 1.5065000416130148

Epoch: 6| Step: 6
Training loss: 0.14037001132965088
Validation loss: 1.5192894807425879

Epoch: 6| Step: 7
Training loss: 0.20269867777824402
Validation loss: 1.5225032837160173

Epoch: 6| Step: 8
Training loss: 0.10674553364515305
Validation loss: 1.5375236618903376

Epoch: 6| Step: 9
Training loss: 0.1241111308336258
Validation loss: 1.5343294887132541

Epoch: 6| Step: 10
Training loss: 0.2078622579574585
Validation loss: 1.539826170090706

Epoch: 6| Step: 11
Training loss: 0.09469006210565567
Validation loss: 1.519247523559037

Epoch: 6| Step: 12
Training loss: 0.07412675023078918
Validation loss: 1.511605348638309

Epoch: 6| Step: 13
Training loss: 0.0750741958618164
Validation loss: 1.5023623769001295

Epoch: 459| Step: 0
Training loss: 0.07125543802976608
Validation loss: 1.513184461542355

Epoch: 6| Step: 1
Training loss: 0.08162584900856018
Validation loss: 1.520069013359726

Epoch: 6| Step: 2
Training loss: 0.16969405114650726
Validation loss: 1.5214670678620696

Epoch: 6| Step: 3
Training loss: 0.05868956819176674
Validation loss: 1.5349519566823078

Epoch: 6| Step: 4
Training loss: 0.1379789412021637
Validation loss: 1.5706375081052062

Epoch: 6| Step: 5
Training loss: 0.08650658279657364
Validation loss: 1.5185572639588387

Epoch: 6| Step: 6
Training loss: 0.09149732440710068
Validation loss: 1.5316629063698552

Epoch: 6| Step: 7
Training loss: 0.12699753046035767
Validation loss: 1.499213299443645

Epoch: 6| Step: 8
Training loss: 0.09395818412303925
Validation loss: 1.5037744199076006

Epoch: 6| Step: 9
Training loss: 0.08893273770809174
Validation loss: 1.4981561604366507

Epoch: 6| Step: 10
Training loss: 0.17372912168502808
Validation loss: 1.513471027856232

Epoch: 6| Step: 11
Training loss: 0.09831462055444717
Validation loss: 1.528039978396508

Epoch: 6| Step: 12
Training loss: 0.11353506147861481
Validation loss: 1.5044071853801768

Epoch: 6| Step: 13
Training loss: 0.1296529918909073
Validation loss: 1.5345172958989297

Epoch: 460| Step: 0
Training loss: 0.11733640730381012
Validation loss: 1.5485214494889783

Epoch: 6| Step: 1
Training loss: 0.09605720639228821
Validation loss: 1.5266386308977682

Epoch: 6| Step: 2
Training loss: 0.08252009749412537
Validation loss: 1.5520690179640246

Epoch: 6| Step: 3
Training loss: 0.13155291974544525
Validation loss: 1.5483995624767837

Epoch: 6| Step: 4
Training loss: 0.20001816749572754
Validation loss: 1.5869891412796513

Epoch: 6| Step: 5
Training loss: 0.08729810267686844
Validation loss: 1.5820567787334483

Epoch: 6| Step: 6
Training loss: 0.06919167935848236
Validation loss: 1.6054095209285777

Epoch: 6| Step: 7
Training loss: 0.09887869656085968
Validation loss: 1.5820052393021122

Epoch: 6| Step: 8
Training loss: 0.07945442199707031
Validation loss: 1.569136437549386

Epoch: 6| Step: 9
Training loss: 0.08366955071687698
Validation loss: 1.5736033211472213

Epoch: 6| Step: 10
Training loss: 0.12377938628196716
Validation loss: 1.5519352677047893

Epoch: 6| Step: 11
Training loss: 0.08322673290967941
Validation loss: 1.5351305341207853

Epoch: 6| Step: 12
Training loss: 0.12128573656082153
Validation loss: 1.5085856959383974

Epoch: 6| Step: 13
Training loss: 0.14418931305408478
Validation loss: 1.4971138290179673

Epoch: 461| Step: 0
Training loss: 0.19555044174194336
Validation loss: 1.5093105710962766

Epoch: 6| Step: 1
Training loss: 0.1415838599205017
Validation loss: 1.5079293161310174

Epoch: 6| Step: 2
Training loss: 0.08209025114774704
Validation loss: 1.5241554167962843

Epoch: 6| Step: 3
Training loss: 0.09077775478363037
Validation loss: 1.4922700441011818

Epoch: 6| Step: 4
Training loss: 0.08669624477624893
Validation loss: 1.5360636582938574

Epoch: 6| Step: 5
Training loss: 0.10378805547952652
Validation loss: 1.5403587343872234

Epoch: 6| Step: 6
Training loss: 0.11176027357578278
Validation loss: 1.5247327076491488

Epoch: 6| Step: 7
Training loss: 0.1504615843296051
Validation loss: 1.5732708515659455

Epoch: 6| Step: 8
Training loss: 0.1329445093870163
Validation loss: 1.5879924822879095

Epoch: 6| Step: 9
Training loss: 0.10206961631774902
Validation loss: 1.5706913317403486

Epoch: 6| Step: 10
Training loss: 0.15517976880073547
Validation loss: 1.5768784451228317

Epoch: 6| Step: 11
Training loss: 0.11416164040565491
Validation loss: 1.5683513584957327

Epoch: 6| Step: 12
Training loss: 0.0701325461268425
Validation loss: 1.5457169650703348

Epoch: 6| Step: 13
Training loss: 0.10020069032907486
Validation loss: 1.5284128464678282

Epoch: 462| Step: 0
Training loss: 0.07310594618320465
Validation loss: 1.5124900943489485

Epoch: 6| Step: 1
Training loss: 0.09591824561357498
Validation loss: 1.480427857368223

Epoch: 6| Step: 2
Training loss: 0.1816171109676361
Validation loss: 1.4793731551016531

Epoch: 6| Step: 3
Training loss: 0.0841091126203537
Validation loss: 1.4616749209742392

Epoch: 6| Step: 4
Training loss: 0.1332382708787918
Validation loss: 1.4872929306440457

Epoch: 6| Step: 5
Training loss: 0.10427466034889221
Validation loss: 1.4769120267642442

Epoch: 6| Step: 6
Training loss: 0.1610059291124344
Validation loss: 1.45982829729716

Epoch: 6| Step: 7
Training loss: 0.07032407820224762
Validation loss: 1.491616795139928

Epoch: 6| Step: 8
Training loss: 0.16816121339797974
Validation loss: 1.5126106482680126

Epoch: 6| Step: 9
Training loss: 0.1267971396446228
Validation loss: 1.5174518964623893

Epoch: 6| Step: 10
Training loss: 0.09513809531927109
Validation loss: 1.4899099757594447

Epoch: 6| Step: 11
Training loss: 0.13992394506931305
Validation loss: 1.5306525525226389

Epoch: 6| Step: 12
Training loss: 0.11567272245883942
Validation loss: 1.5080867890388734

Epoch: 6| Step: 13
Training loss: 0.171607106924057
Validation loss: 1.5549354745495705

Epoch: 463| Step: 0
Training loss: 0.05577029287815094
Validation loss: 1.548536217340859

Epoch: 6| Step: 1
Training loss: 0.11035773158073425
Validation loss: 1.5462636011903004

Epoch: 6| Step: 2
Training loss: 0.07567869871854782
Validation loss: 1.5669998584255096

Epoch: 6| Step: 3
Training loss: 0.12875613570213318
Validation loss: 1.5623398903877503

Epoch: 6| Step: 4
Training loss: 0.11891220510005951
Validation loss: 1.5608889050381158

Epoch: 6| Step: 5
Training loss: 0.14395251870155334
Validation loss: 1.551603292906156

Epoch: 6| Step: 6
Training loss: 0.05682988464832306
Validation loss: 1.5615976933510072

Epoch: 6| Step: 7
Training loss: 0.1671968400478363
Validation loss: 1.5514135219717538

Epoch: 6| Step: 8
Training loss: 0.15435239672660828
Validation loss: 1.5421171675446212

Epoch: 6| Step: 9
Training loss: 0.10867516696453094
Validation loss: 1.5554854485296434

Epoch: 6| Step: 10
Training loss: 0.18285639584064484
Validation loss: 1.5349028636050481

Epoch: 6| Step: 11
Training loss: 0.10487549751996994
Validation loss: 1.5408533157840851

Epoch: 6| Step: 12
Training loss: 0.09971556067466736
Validation loss: 1.5143783169407998

Epoch: 6| Step: 13
Training loss: 0.09457631409168243
Validation loss: 1.5353436752032208

Epoch: 464| Step: 0
Training loss: 0.0825246125459671
Validation loss: 1.5560529078206708

Epoch: 6| Step: 1
Training loss: 0.08717627078294754
Validation loss: 1.5291927655537922

Epoch: 6| Step: 2
Training loss: 0.12337759137153625
Validation loss: 1.5598712640423928

Epoch: 6| Step: 3
Training loss: 0.17430207133293152
Validation loss: 1.5489830791309316

Epoch: 6| Step: 4
Training loss: 0.11842860281467438
Validation loss: 1.5198472802357008

Epoch: 6| Step: 5
Training loss: 0.12143200635910034
Validation loss: 1.523381721268418

Epoch: 6| Step: 6
Training loss: 0.07259336113929749
Validation loss: 1.5284605513336837

Epoch: 6| Step: 7
Training loss: 0.0879410058259964
Validation loss: 1.505726743769902

Epoch: 6| Step: 8
Training loss: 0.07057195156812668
Validation loss: 1.502067401844968

Epoch: 6| Step: 9
Training loss: 0.06429702788591385
Validation loss: 1.486199709676927

Epoch: 6| Step: 10
Training loss: 0.10411525517702103
Validation loss: 1.5050141862643662

Epoch: 6| Step: 11
Training loss: 0.10131464898586273
Validation loss: 1.5110208706189228

Epoch: 6| Step: 12
Training loss: 0.17155878245830536
Validation loss: 1.503508202491268

Epoch: 6| Step: 13
Training loss: 0.10578823834657669
Validation loss: 1.535587336427422

Epoch: 465| Step: 0
Training loss: 0.08242441713809967
Validation loss: 1.5433002043795843

Epoch: 6| Step: 1
Training loss: 0.1485687792301178
Validation loss: 1.5278408283828406

Epoch: 6| Step: 2
Training loss: 0.1326381415128708
Validation loss: 1.5451118535892938

Epoch: 6| Step: 3
Training loss: 0.1277492344379425
Validation loss: 1.5773578984763033

Epoch: 6| Step: 4
Training loss: 0.09882263839244843
Validation loss: 1.5683408526964084

Epoch: 6| Step: 5
Training loss: 0.12577365338802338
Validation loss: 1.5907076725395777

Epoch: 6| Step: 6
Training loss: 0.10637767612934113
Validation loss: 1.562372830606276

Epoch: 6| Step: 7
Training loss: 0.10283127427101135
Validation loss: 1.5650147097085112

Epoch: 6| Step: 8
Training loss: 0.10019136965274811
Validation loss: 1.5450808437921668

Epoch: 6| Step: 9
Training loss: 0.07787760347127914
Validation loss: 1.5068170485957977

Epoch: 6| Step: 10
Training loss: 0.09760492295026779
Validation loss: 1.4997277990464242

Epoch: 6| Step: 11
Training loss: 0.077096126973629
Validation loss: 1.5186474977001068

Epoch: 6| Step: 12
Training loss: 0.054187629371881485
Validation loss: 1.4642849609416018

Epoch: 6| Step: 13
Training loss: 0.2027854174375534
Validation loss: 1.4702649577971427

Epoch: 466| Step: 0
Training loss: 0.07481034845113754
Validation loss: 1.4729184540369178

Epoch: 6| Step: 1
Training loss: 0.11209595203399658
Validation loss: 1.4396347268935172

Epoch: 6| Step: 2
Training loss: 0.17807382345199585
Validation loss: 1.4452353536441762

Epoch: 6| Step: 3
Training loss: 0.10255075991153717
Validation loss: 1.4531753037565498

Epoch: 6| Step: 4
Training loss: 0.1516648530960083
Validation loss: 1.45064970754808

Epoch: 6| Step: 5
Training loss: 0.13281431794166565
Validation loss: 1.4697449707215833

Epoch: 6| Step: 6
Training loss: 0.18069690465927124
Validation loss: 1.5207828680674236

Epoch: 6| Step: 7
Training loss: 0.13735496997833252
Validation loss: 1.4915951375038392

Epoch: 6| Step: 8
Training loss: 0.14291594922542572
Validation loss: 1.5136447016910841

Epoch: 6| Step: 9
Training loss: 0.30120983719825745
Validation loss: 1.5305582554109636

Epoch: 6| Step: 10
Training loss: 0.12249763309955597
Validation loss: 1.5175252934937835

Epoch: 6| Step: 11
Training loss: 0.11936932802200317
Validation loss: 1.5092937279773015

Epoch: 6| Step: 12
Training loss: 0.11159883439540863
Validation loss: 1.4978886817091255

Epoch: 6| Step: 13
Training loss: 0.10984484851360321
Validation loss: 1.4977184444345453

Epoch: 467| Step: 0
Training loss: 0.0846724584698677
Validation loss: 1.5187849049927087

Epoch: 6| Step: 1
Training loss: 0.11749191582202911
Validation loss: 1.515440204130706

Epoch: 6| Step: 2
Training loss: 0.0823277086019516
Validation loss: 1.537321344498665

Epoch: 6| Step: 3
Training loss: 0.20520003139972687
Validation loss: 1.5466426501991928

Epoch: 6| Step: 4
Training loss: 0.12419895827770233
Validation loss: 1.5399345505622126

Epoch: 6| Step: 5
Training loss: 0.1090894341468811
Validation loss: 1.531627453783507

Epoch: 6| Step: 6
Training loss: 0.10896490514278412
Validation loss: 1.5306286581100956

Epoch: 6| Step: 7
Training loss: 0.13312551379203796
Validation loss: 1.5404125759678502

Epoch: 6| Step: 8
Training loss: 0.1262611746788025
Validation loss: 1.5422021060861566

Epoch: 6| Step: 9
Training loss: 0.16071075201034546
Validation loss: 1.5513553414293515

Epoch: 6| Step: 10
Training loss: 0.19599968194961548
Validation loss: 1.5483324822559152

Epoch: 6| Step: 11
Training loss: 0.16797785460948944
Validation loss: 1.5678228242422945

Epoch: 6| Step: 12
Training loss: 0.15168148279190063
Validation loss: 1.5461205256882535

Epoch: 6| Step: 13
Training loss: 0.13290633261203766
Validation loss: 1.564462306678936

Epoch: 468| Step: 0
Training loss: 0.1985025703907013
Validation loss: 1.5421418156675113

Epoch: 6| Step: 1
Training loss: 0.11301121115684509
Validation loss: 1.5339487521879134

Epoch: 6| Step: 2
Training loss: 0.1252007931470871
Validation loss: 1.5465321092195408

Epoch: 6| Step: 3
Training loss: 0.12713399529457092
Validation loss: 1.5654555007975588

Epoch: 6| Step: 4
Training loss: 0.15435972809791565
Validation loss: 1.5754480887484807

Epoch: 6| Step: 5
Training loss: 0.11538301408290863
Validation loss: 1.5502555677967687

Epoch: 6| Step: 6
Training loss: 0.20005199313163757
Validation loss: 1.5666065895429222

Epoch: 6| Step: 7
Training loss: 0.18999463319778442
Validation loss: 1.542313318098745

Epoch: 6| Step: 8
Training loss: 0.17415152490139008
Validation loss: 1.5515943381094164

Epoch: 6| Step: 9
Training loss: 0.15718811750411987
Validation loss: 1.5693944525975052

Epoch: 6| Step: 10
Training loss: 0.19504855573177338
Validation loss: 1.5781134251625306

Epoch: 6| Step: 11
Training loss: 0.08549073338508606
Validation loss: 1.566755376836305

Epoch: 6| Step: 12
Training loss: 0.18603608012199402
Validation loss: 1.550246315617715

Epoch: 6| Step: 13
Training loss: 0.0647708848118782
Validation loss: 1.5606869830880115

Epoch: 469| Step: 0
Training loss: 0.08095327019691467
Validation loss: 1.5345086756572928

Epoch: 6| Step: 1
Training loss: 0.08073476701974869
Validation loss: 1.5540801581516062

Epoch: 6| Step: 2
Training loss: 0.1060616746544838
Validation loss: 1.5369237699816305

Epoch: 6| Step: 3
Training loss: 0.10565901547670364
Validation loss: 1.5225440981567546

Epoch: 6| Step: 4
Training loss: 0.09309536218643188
Validation loss: 1.527427666930742

Epoch: 6| Step: 5
Training loss: 0.12628397345542908
Validation loss: 1.5312580870043846

Epoch: 6| Step: 6
Training loss: 0.11729244142770767
Validation loss: 1.4850175746025578

Epoch: 6| Step: 7
Training loss: 0.0773027092218399
Validation loss: 1.5040215734512574

Epoch: 6| Step: 8
Training loss: 0.0971193015575409
Validation loss: 1.5286266092331178

Epoch: 6| Step: 9
Training loss: 0.1536393165588379
Validation loss: 1.5453770545221144

Epoch: 6| Step: 10
Training loss: 0.08498112857341766
Validation loss: 1.518752254465575

Epoch: 6| Step: 11
Training loss: 0.17593041062355042
Validation loss: 1.541603301161079

Epoch: 6| Step: 12
Training loss: 0.15867428481578827
Validation loss: 1.5394445516729867

Epoch: 6| Step: 13
Training loss: 0.1787877380847931
Validation loss: 1.5462077343335716

Epoch: 470| Step: 0
Training loss: 0.05375663936138153
Validation loss: 1.5840692981596916

Epoch: 6| Step: 1
Training loss: 0.09130817651748657
Validation loss: 1.5663473336927352

Epoch: 6| Step: 2
Training loss: 0.07592611014842987
Validation loss: 1.5552676499530833

Epoch: 6| Step: 3
Training loss: 0.08616577088832855
Validation loss: 1.5522775944843088

Epoch: 6| Step: 4
Training loss: 0.10267555713653564
Validation loss: 1.5401390701211908

Epoch: 6| Step: 5
Training loss: 0.127995565533638
Validation loss: 1.5426878903501777

Epoch: 6| Step: 6
Training loss: 0.1590225100517273
Validation loss: 1.5425091161522815

Epoch: 6| Step: 7
Training loss: 0.1385502815246582
Validation loss: 1.5687270004262206

Epoch: 6| Step: 8
Training loss: 0.16062632203102112
Validation loss: 1.5173186236812222

Epoch: 6| Step: 9
Training loss: 0.14597712457180023
Validation loss: 1.5367009985831477

Epoch: 6| Step: 10
Training loss: 0.11965255439281464
Validation loss: 1.5322610562847507

Epoch: 6| Step: 11
Training loss: 0.10959229618310928
Validation loss: 1.5122832534133748

Epoch: 6| Step: 12
Training loss: 0.13005997240543365
Validation loss: 1.5106076143121208

Epoch: 6| Step: 13
Training loss: 0.10583417862653732
Validation loss: 1.5076046348899923

Epoch: 471| Step: 0
Training loss: 0.1013430505990982
Validation loss: 1.5033978717301482

Epoch: 6| Step: 1
Training loss: 0.12458718568086624
Validation loss: 1.5169257463947419

Epoch: 6| Step: 2
Training loss: 0.0984511598944664
Validation loss: 1.545634347905395

Epoch: 6| Step: 3
Training loss: 0.09467674791812897
Validation loss: 1.5104352043521019

Epoch: 6| Step: 4
Training loss: 0.18255260586738586
Validation loss: 1.5401310151623142

Epoch: 6| Step: 5
Training loss: 0.08998405188322067
Validation loss: 1.5278960812476374

Epoch: 6| Step: 6
Training loss: 0.10440938919782639
Validation loss: 1.544183035691579

Epoch: 6| Step: 7
Training loss: 0.08956789970397949
Validation loss: 1.5367545004813903

Epoch: 6| Step: 8
Training loss: 0.1356312781572342
Validation loss: 1.5311091202561573

Epoch: 6| Step: 9
Training loss: 0.1358492076396942
Validation loss: 1.5405034839466054

Epoch: 6| Step: 10
Training loss: 0.11821682751178741
Validation loss: 1.5484315400482507

Epoch: 6| Step: 11
Training loss: 0.14424830675125122
Validation loss: 1.5311145218469764

Epoch: 6| Step: 12
Training loss: 0.12775179743766785
Validation loss: 1.520758451954011

Epoch: 6| Step: 13
Training loss: 0.1331944763660431
Validation loss: 1.5362963778998262

Epoch: 472| Step: 0
Training loss: 0.13241006433963776
Validation loss: 1.5392950516875072

Epoch: 6| Step: 1
Training loss: 0.09682262688875198
Validation loss: 1.5193214839504612

Epoch: 6| Step: 2
Training loss: 0.11440832167863846
Validation loss: 1.5302669514891922

Epoch: 6| Step: 3
Training loss: 0.13919731974601746
Validation loss: 1.5484465514459917

Epoch: 6| Step: 4
Training loss: 0.09633170813322067
Validation loss: 1.5308382844412198

Epoch: 6| Step: 5
Training loss: 0.16104371845722198
Validation loss: 1.5676457664018035

Epoch: 6| Step: 6
Training loss: 0.10307641327381134
Validation loss: 1.568316682692497

Epoch: 6| Step: 7
Training loss: 0.10403329133987427
Validation loss: 1.5512410286934144

Epoch: 6| Step: 8
Training loss: 0.11410374939441681
Validation loss: 1.538981378719371

Epoch: 6| Step: 9
Training loss: 0.08503670245409012
Validation loss: 1.5763190010542512

Epoch: 6| Step: 10
Training loss: 0.11203388124704361
Validation loss: 1.5500911076863606

Epoch: 6| Step: 11
Training loss: 0.07764898985624313
Validation loss: 1.5579673128743325

Epoch: 6| Step: 12
Training loss: 0.16887204349040985
Validation loss: 1.5352599902819561

Epoch: 6| Step: 13
Training loss: 0.09643663465976715
Validation loss: 1.5544278416582333

Epoch: 473| Step: 0
Training loss: 0.15790536999702454
Validation loss: 1.5208013410209327

Epoch: 6| Step: 1
Training loss: 0.08728071302175522
Validation loss: 1.5194592322072675

Epoch: 6| Step: 2
Training loss: 0.12245821952819824
Validation loss: 1.5144265262029504

Epoch: 6| Step: 3
Training loss: 0.12688632309436798
Validation loss: 1.5520085224541285

Epoch: 6| Step: 4
Training loss: 0.1416211575269699
Validation loss: 1.5338367980013612

Epoch: 6| Step: 5
Training loss: 0.05957772210240364
Validation loss: 1.5374716507491244

Epoch: 6| Step: 6
Training loss: 0.12410341203212738
Validation loss: 1.5390795046283352

Epoch: 6| Step: 7
Training loss: 0.06554985046386719
Validation loss: 1.5368747736818047

Epoch: 6| Step: 8
Training loss: 0.08602572977542877
Validation loss: 1.5743168592453003

Epoch: 6| Step: 9
Training loss: 0.08966529369354248
Validation loss: 1.533858130055089

Epoch: 6| Step: 10
Training loss: 0.12072043120861053
Validation loss: 1.5329576359000257

Epoch: 6| Step: 11
Training loss: 0.09077052772045135
Validation loss: 1.5220378175858529

Epoch: 6| Step: 12
Training loss: 0.10963744670152664
Validation loss: 1.5319368557263446

Epoch: 6| Step: 13
Training loss: 0.09888532757759094
Validation loss: 1.545960908935916

Epoch: 474| Step: 0
Training loss: 0.11371170729398727
Validation loss: 1.4928484527013635

Epoch: 6| Step: 1
Training loss: 0.11286181211471558
Validation loss: 1.5002530608125912

Epoch: 6| Step: 2
Training loss: 0.08457542955875397
Validation loss: 1.518325492899905

Epoch: 6| Step: 3
Training loss: 0.0667053833603859
Validation loss: 1.5341772199958883

Epoch: 6| Step: 4
Training loss: 0.10886313021183014
Validation loss: 1.5027840291300127

Epoch: 6| Step: 5
Training loss: 0.08939236402511597
Validation loss: 1.5272130684186054

Epoch: 6| Step: 6
Training loss: 0.13274213671684265
Validation loss: 1.5169196359572872

Epoch: 6| Step: 7
Training loss: 0.08427445590496063
Validation loss: 1.5157167411619616

Epoch: 6| Step: 8
Training loss: 0.1382480412721634
Validation loss: 1.5196575631377518

Epoch: 6| Step: 9
Training loss: 0.11427942663431168
Validation loss: 1.5125366795447566

Epoch: 6| Step: 10
Training loss: 0.15297409892082214
Validation loss: 1.4972751743050032

Epoch: 6| Step: 11
Training loss: 0.08610373735427856
Validation loss: 1.505741875658753

Epoch: 6| Step: 12
Training loss: 0.09929656982421875
Validation loss: 1.4966193437576294

Epoch: 6| Step: 13
Training loss: 0.09061162918806076
Validation loss: 1.5062613333425214

Epoch: 475| Step: 0
Training loss: 0.0838376134634018
Validation loss: 1.480661025611303

Epoch: 6| Step: 1
Training loss: 0.200191468000412
Validation loss: 1.4963750608505741

Epoch: 6| Step: 2
Training loss: 0.09893123805522919
Validation loss: 1.4896767100980204

Epoch: 6| Step: 3
Training loss: 0.11501846462488174
Validation loss: 1.485790894877526

Epoch: 6| Step: 4
Training loss: 0.09858076274394989
Validation loss: 1.513774093761239

Epoch: 6| Step: 5
Training loss: 0.08283459395170212
Validation loss: 1.5155949156771424

Epoch: 6| Step: 6
Training loss: 0.14113323390483856
Validation loss: 1.5127000731806601

Epoch: 6| Step: 7
Training loss: 0.1137242391705513
Validation loss: 1.5217440615418136

Epoch: 6| Step: 8
Training loss: 0.07777154445648193
Validation loss: 1.5145600893164193

Epoch: 6| Step: 9
Training loss: 0.07533043622970581
Validation loss: 1.5304472343896025

Epoch: 6| Step: 10
Training loss: 0.11120026558637619
Validation loss: 1.5108167888015829

Epoch: 6| Step: 11
Training loss: 0.1601131111383438
Validation loss: 1.5292600047203802

Epoch: 6| Step: 12
Training loss: 0.1627172827720642
Validation loss: 1.5315913128596481

Epoch: 6| Step: 13
Training loss: 0.08458733558654785
Validation loss: 1.548481164440032

Epoch: 476| Step: 0
Training loss: 0.1222965270280838
Validation loss: 1.5334180965218493

Epoch: 6| Step: 1
Training loss: 0.1415937840938568
Validation loss: 1.5390386158420193

Epoch: 6| Step: 2
Training loss: 0.06556679308414459
Validation loss: 1.5703019679233592

Epoch: 6| Step: 3
Training loss: 0.08976031839847565
Validation loss: 1.5889682410865702

Epoch: 6| Step: 4
Training loss: 0.11528904736042023
Validation loss: 1.5753177788949781

Epoch: 6| Step: 5
Training loss: 0.1621328741312027
Validation loss: 1.6064752186498334

Epoch: 6| Step: 6
Training loss: 0.13529783487319946
Validation loss: 1.5967368464316092

Epoch: 6| Step: 7
Training loss: 0.09126187860965729
Validation loss: 1.5206148303965086

Epoch: 6| Step: 8
Training loss: 0.10415852814912796
Validation loss: 1.533348862201937

Epoch: 6| Step: 9
Training loss: 0.06984850764274597
Validation loss: 1.4929298341915171

Epoch: 6| Step: 10
Training loss: 0.171683669090271
Validation loss: 1.5054220448258102

Epoch: 6| Step: 11
Training loss: 0.12000575661659241
Validation loss: 1.5143239254592566

Epoch: 6| Step: 12
Training loss: 0.09668944776058197
Validation loss: 1.51581895671865

Epoch: 6| Step: 13
Training loss: 0.13460256159305573
Validation loss: 1.4996247342837754

Epoch: 477| Step: 0
Training loss: 0.10082988440990448
Validation loss: 1.503333120576797

Epoch: 6| Step: 1
Training loss: 0.13447901606559753
Validation loss: 1.507700881650371

Epoch: 6| Step: 2
Training loss: 0.14400571584701538
Validation loss: 1.5011717952707762

Epoch: 6| Step: 3
Training loss: 0.06885461509227753
Validation loss: 1.5214702365218953

Epoch: 6| Step: 4
Training loss: 0.09076068550348282
Validation loss: 1.5235819175679197

Epoch: 6| Step: 5
Training loss: 0.08667510747909546
Validation loss: 1.5169733467922415

Epoch: 6| Step: 6
Training loss: 0.1509234607219696
Validation loss: 1.5102701212770195

Epoch: 6| Step: 7
Training loss: 0.09891433268785477
Validation loss: 1.5168868040525785

Epoch: 6| Step: 8
Training loss: 0.07831107825040817
Validation loss: 1.5149843013414772

Epoch: 6| Step: 9
Training loss: 0.1003914624452591
Validation loss: 1.5306567863751483

Epoch: 6| Step: 10
Training loss: 0.12455286085605621
Validation loss: 1.5181886226900163

Epoch: 6| Step: 11
Training loss: 0.1261332929134369
Validation loss: 1.474447545184884

Epoch: 6| Step: 12
Training loss: 0.12314768880605698
Validation loss: 1.5312808047058761

Epoch: 6| Step: 13
Training loss: 0.08279462903738022
Validation loss: 1.5099558881534043

Epoch: 478| Step: 0
Training loss: 0.08722235262393951
Validation loss: 1.4856376583858202

Epoch: 6| Step: 1
Training loss: 0.07871394604444504
Validation loss: 1.5263084262929938

Epoch: 6| Step: 2
Training loss: 0.0974646657705307
Validation loss: 1.5150247017542522

Epoch: 6| Step: 3
Training loss: 0.08198396116495132
Validation loss: 1.5488554380273307

Epoch: 6| Step: 4
Training loss: 0.17159703373908997
Validation loss: 1.5424038287132018

Epoch: 6| Step: 5
Training loss: 0.12031951546669006
Validation loss: 1.5426413935999717

Epoch: 6| Step: 6
Training loss: 0.07463236898183823
Validation loss: 1.5505549471865419

Epoch: 6| Step: 7
Training loss: 0.14306220412254333
Validation loss: 1.5899279418812002

Epoch: 6| Step: 8
Training loss: 0.1286134272813797
Validation loss: 1.5584157025942238

Epoch: 6| Step: 9
Training loss: 0.17176319658756256
Validation loss: 1.5586496553113383

Epoch: 6| Step: 10
Training loss: 0.13662441074848175
Validation loss: 1.5581013893568387

Epoch: 6| Step: 11
Training loss: 0.09462638199329376
Validation loss: 1.5580242500510266

Epoch: 6| Step: 12
Training loss: 0.07693444937467575
Validation loss: 1.5404946688682801

Epoch: 6| Step: 13
Training loss: 0.09953693300485611
Validation loss: 1.5392807196545344

Epoch: 479| Step: 0
Training loss: 0.1434442102909088
Validation loss: 1.542549631928885

Epoch: 6| Step: 1
Training loss: 0.16302984952926636
Validation loss: 1.5341015861880394

Epoch: 6| Step: 2
Training loss: 0.09668050706386566
Validation loss: 1.5644559168046521

Epoch: 6| Step: 3
Training loss: 0.24346697330474854
Validation loss: 1.5874997236395394

Epoch: 6| Step: 4
Training loss: 0.09421002864837646
Validation loss: 1.5386195259709512

Epoch: 6| Step: 5
Training loss: 0.12174725532531738
Validation loss: 1.5184258030306907

Epoch: 6| Step: 6
Training loss: 0.09312498569488525
Validation loss: 1.5291092491918994

Epoch: 6| Step: 7
Training loss: 0.11343955993652344
Validation loss: 1.514326867236886

Epoch: 6| Step: 8
Training loss: 0.03812205046415329
Validation loss: 1.5235743099643337

Epoch: 6| Step: 9
Training loss: 0.08403299748897552
Validation loss: 1.5301894654509842

Epoch: 6| Step: 10
Training loss: 0.11218550056219101
Validation loss: 1.554944331927966

Epoch: 6| Step: 11
Training loss: 0.10734567791223526
Validation loss: 1.5645142665473364

Epoch: 6| Step: 12
Training loss: 0.12741369009017944
Validation loss: 1.5359183088425667

Epoch: 6| Step: 13
Training loss: 0.11170493066310883
Validation loss: 1.5377666809225594

Epoch: 480| Step: 0
Training loss: 0.1307254582643509
Validation loss: 1.5190601989787111

Epoch: 6| Step: 1
Training loss: 0.12704604864120483
Validation loss: 1.538106692734585

Epoch: 6| Step: 2
Training loss: 0.06952974200248718
Validation loss: 1.5058888222581597

Epoch: 6| Step: 3
Training loss: 0.11895861476659775
Validation loss: 1.531422439441886

Epoch: 6| Step: 4
Training loss: 0.0921718180179596
Validation loss: 1.507081517609217

Epoch: 6| Step: 5
Training loss: 0.10657546669244766
Validation loss: 1.4953571698998893

Epoch: 6| Step: 6
Training loss: 0.09614258259534836
Validation loss: 1.5283153441644484

Epoch: 6| Step: 7
Training loss: 0.08155211806297302
Validation loss: 1.4787492303438083

Epoch: 6| Step: 8
Training loss: 0.1024802103638649
Validation loss: 1.494076277620049

Epoch: 6| Step: 9
Training loss: 0.15478633344173431
Validation loss: 1.4766250733406312

Epoch: 6| Step: 10
Training loss: 0.09953634440898895
Validation loss: 1.5037291280684932

Epoch: 6| Step: 11
Training loss: 0.09383267909288406
Validation loss: 1.5307305384707708

Epoch: 6| Step: 12
Training loss: 0.1373823881149292
Validation loss: 1.5139938785183815

Epoch: 6| Step: 13
Training loss: 0.08714143931865692
Validation loss: 1.545896400687515

Epoch: 481| Step: 0
Training loss: 0.10461951792240143
Validation loss: 1.529388072670147

Epoch: 6| Step: 1
Training loss: 0.15515148639678955
Validation loss: 1.5446762795089393

Epoch: 6| Step: 2
Training loss: 0.15428778529167175
Validation loss: 1.5517054488581996

Epoch: 6| Step: 3
Training loss: 0.1260068118572235
Validation loss: 1.5636791593285018

Epoch: 6| Step: 4
Training loss: 0.12695351243019104
Validation loss: 1.5131560230767855

Epoch: 6| Step: 5
Training loss: 0.07634636014699936
Validation loss: 1.5036269785255514

Epoch: 6| Step: 6
Training loss: 0.11587194353342056
Validation loss: 1.5341648837571502

Epoch: 6| Step: 7
Training loss: 0.12995874881744385
Validation loss: 1.5084837649458198

Epoch: 6| Step: 8
Training loss: 0.08797856420278549
Validation loss: 1.525178300437107

Epoch: 6| Step: 9
Training loss: 0.10443208366632462
Validation loss: 1.5355018261940248

Epoch: 6| Step: 10
Training loss: 0.12279918789863586
Validation loss: 1.5608330824041878

Epoch: 6| Step: 11
Training loss: 0.12937763333320618
Validation loss: 1.5351798354938466

Epoch: 6| Step: 12
Training loss: 0.05937197059392929
Validation loss: 1.5427150136681014

Epoch: 6| Step: 13
Training loss: 0.10343870520591736
Validation loss: 1.5400868654251099

Epoch: 482| Step: 0
Training loss: 0.08495347946882248
Validation loss: 1.5361502670472669

Epoch: 6| Step: 1
Training loss: 0.12439795583486557
Validation loss: 1.5403788846026185

Epoch: 6| Step: 2
Training loss: 0.10145576298236847
Validation loss: 1.5149887011897178

Epoch: 6| Step: 3
Training loss: 0.09506992995738983
Validation loss: 1.5619455127305881

Epoch: 6| Step: 4
Training loss: 0.13319315016269684
Validation loss: 1.5514814738304383

Epoch: 6| Step: 5
Training loss: 0.08583959192037582
Validation loss: 1.5791215960697462

Epoch: 6| Step: 6
Training loss: 0.1039416715502739
Validation loss: 1.5656305974529636

Epoch: 6| Step: 7
Training loss: 0.10596063733100891
Validation loss: 1.5661380842167845

Epoch: 6| Step: 8
Training loss: 0.05941779166460037
Validation loss: 1.5246926930642897

Epoch: 6| Step: 9
Training loss: 0.09183300286531448
Validation loss: 1.5659789167424685

Epoch: 6| Step: 10
Training loss: 0.14735369384288788
Validation loss: 1.5436588618704068

Epoch: 6| Step: 11
Training loss: 0.05376163497567177
Validation loss: 1.5377815820837533

Epoch: 6| Step: 12
Training loss: 0.06244366616010666
Validation loss: 1.555120200239202

Epoch: 6| Step: 13
Training loss: 0.11919382214546204
Validation loss: 1.5466278496608938

Epoch: 483| Step: 0
Training loss: 0.08722575753927231
Validation loss: 1.5697541217650137

Epoch: 6| Step: 1
Training loss: 0.10669025033712387
Validation loss: 1.5594988561445666

Epoch: 6| Step: 2
Training loss: 0.12995827198028564
Validation loss: 1.5069221988801034

Epoch: 6| Step: 3
Training loss: 0.13896706700325012
Validation loss: 1.5388418474505026

Epoch: 6| Step: 4
Training loss: 0.09510792791843414
Validation loss: 1.52894381553896

Epoch: 6| Step: 5
Training loss: 0.07196371257305145
Validation loss: 1.5162869461121098

Epoch: 6| Step: 6
Training loss: 0.08039963990449905
Validation loss: 1.5112322953439528

Epoch: 6| Step: 7
Training loss: 0.10529973357915878
Validation loss: 1.5013009130313832

Epoch: 6| Step: 8
Training loss: 0.10063093900680542
Validation loss: 1.4909495371644215

Epoch: 6| Step: 9
Training loss: 0.1253405660390854
Validation loss: 1.4982633706062072

Epoch: 6| Step: 10
Training loss: 0.09387484192848206
Validation loss: 1.5027949425481981

Epoch: 6| Step: 11
Training loss: 0.10673897713422775
Validation loss: 1.5144062529328048

Epoch: 6| Step: 12
Training loss: 0.22312398254871368
Validation loss: 1.510022735082975

Epoch: 6| Step: 13
Training loss: 0.069467693567276
Validation loss: 1.4983450969060261

Epoch: 484| Step: 0
Training loss: 0.09520142525434494
Validation loss: 1.512144911673761

Epoch: 6| Step: 1
Training loss: 0.03909244015812874
Validation loss: 1.490933196519011

Epoch: 6| Step: 2
Training loss: 0.05863907188177109
Validation loss: 1.4881503159000027

Epoch: 6| Step: 3
Training loss: 0.07809579372406006
Validation loss: 1.5130171673272246

Epoch: 6| Step: 4
Training loss: 0.09750586748123169
Validation loss: 1.494606379539736

Epoch: 6| Step: 5
Training loss: 0.09776349365711212
Validation loss: 1.4919678639340144

Epoch: 6| Step: 6
Training loss: 0.1209062859416008
Validation loss: 1.5176672185620954

Epoch: 6| Step: 7
Training loss: 0.07055237144231796
Validation loss: 1.5037054297744588

Epoch: 6| Step: 8
Training loss: 0.12152712792158127
Validation loss: 1.4831564516149542

Epoch: 6| Step: 9
Training loss: 0.0913371592760086
Validation loss: 1.4987961925486082

Epoch: 6| Step: 10
Training loss: 0.1098800003528595
Validation loss: 1.5084719939898419

Epoch: 6| Step: 11
Training loss: 0.13434404134750366
Validation loss: 1.500274573602984

Epoch: 6| Step: 12
Training loss: 0.07576318085193634
Validation loss: 1.5165125939153856

Epoch: 6| Step: 13
Training loss: 0.09428252279758453
Validation loss: 1.526771564317006

Epoch: 485| Step: 0
Training loss: 0.10192261636257172
Validation loss: 1.5158823190196868

Epoch: 6| Step: 1
Training loss: 0.06707266718149185
Validation loss: 1.5711084001807756

Epoch: 6| Step: 2
Training loss: 0.08354426920413971
Validation loss: 1.5307009489305559

Epoch: 6| Step: 3
Training loss: 0.07576388865709305
Validation loss: 1.534780466428367

Epoch: 6| Step: 4
Training loss: 0.07353731989860535
Validation loss: 1.5264034207149217

Epoch: 6| Step: 5
Training loss: 0.08633409440517426
Validation loss: 1.518507388330275

Epoch: 6| Step: 6
Training loss: 0.06808464229106903
Validation loss: 1.5076264771082069

Epoch: 6| Step: 7
Training loss: 0.07207229733467102
Validation loss: 1.540277358024351

Epoch: 6| Step: 8
Training loss: 0.08131608366966248
Validation loss: 1.5180958727354645

Epoch: 6| Step: 9
Training loss: 0.08371439576148987
Validation loss: 1.5377923404016802

Epoch: 6| Step: 10
Training loss: 0.15361903607845306
Validation loss: 1.5274378971386982

Epoch: 6| Step: 11
Training loss: 0.10911828279495239
Validation loss: 1.530822273864541

Epoch: 6| Step: 12
Training loss: 0.14439119398593903
Validation loss: 1.518000106657705

Epoch: 6| Step: 13
Training loss: 0.11534188687801361
Validation loss: 1.5307456665141608

Epoch: 486| Step: 0
Training loss: 0.11734567582607269
Validation loss: 1.5280017468237108

Epoch: 6| Step: 1
Training loss: 0.09901697933673859
Validation loss: 1.5520356547447942

Epoch: 6| Step: 2
Training loss: 0.11740925908088684
Validation loss: 1.550501943916403

Epoch: 6| Step: 3
Training loss: 0.14167717099189758
Validation loss: 1.5225388721753192

Epoch: 6| Step: 4
Training loss: 0.1038009449839592
Validation loss: 1.5335519672721944

Epoch: 6| Step: 5
Training loss: 0.12052732706069946
Validation loss: 1.538737416267395

Epoch: 6| Step: 6
Training loss: 0.15380555391311646
Validation loss: 1.5077553615775159

Epoch: 6| Step: 7
Training loss: 0.08605948835611343
Validation loss: 1.5045516157662997

Epoch: 6| Step: 8
Training loss: 0.05085693299770355
Validation loss: 1.4917045370224984

Epoch: 6| Step: 9
Training loss: 0.10216499119997025
Validation loss: 1.5050818317679948

Epoch: 6| Step: 10
Training loss: 0.11284131556749344
Validation loss: 1.515519134459957

Epoch: 6| Step: 11
Training loss: 0.07385103404521942
Validation loss: 1.521618907169629

Epoch: 6| Step: 12
Training loss: 0.08501353859901428
Validation loss: 1.5180956971260808

Epoch: 6| Step: 13
Training loss: 0.08891672641038895
Validation loss: 1.5178663704984932

Epoch: 487| Step: 0
Training loss: 0.0935385674238205
Validation loss: 1.5081448862629552

Epoch: 6| Step: 1
Training loss: 0.08918777853250504
Validation loss: 1.5287351569821757

Epoch: 6| Step: 2
Training loss: 0.07138081640005112
Validation loss: 1.5253894687980734

Epoch: 6| Step: 3
Training loss: 0.08672234416007996
Validation loss: 1.5024615346744497

Epoch: 6| Step: 4
Training loss: 0.09721650928258896
Validation loss: 1.4939960638682048

Epoch: 6| Step: 5
Training loss: 0.12517747282981873
Validation loss: 1.5256654062578756

Epoch: 6| Step: 6
Training loss: 0.0827130451798439
Validation loss: 1.5165466646994314

Epoch: 6| Step: 7
Training loss: 0.13386109471321106
Validation loss: 1.5054836632103048

Epoch: 6| Step: 8
Training loss: 0.06106739863753319
Validation loss: 1.542032636621947

Epoch: 6| Step: 9
Training loss: 0.06576749682426453
Validation loss: 1.5073242738682737

Epoch: 6| Step: 10
Training loss: 0.1287548840045929
Validation loss: 1.5096656455788562

Epoch: 6| Step: 11
Training loss: 0.08678360283374786
Validation loss: 1.529636929112096

Epoch: 6| Step: 12
Training loss: 0.10776293277740479
Validation loss: 1.5185183876304216

Epoch: 6| Step: 13
Training loss: 0.13436508178710938
Validation loss: 1.530804503989476

Epoch: 488| Step: 0
Training loss: 0.06678873300552368
Validation loss: 1.5539432084688576

Epoch: 6| Step: 1
Training loss: 0.1050063818693161
Validation loss: 1.534659258780941

Epoch: 6| Step: 2
Training loss: 0.0917685478925705
Validation loss: 1.542521930509998

Epoch: 6| Step: 3
Training loss: 0.08854074776172638
Validation loss: 1.5750663536851124

Epoch: 6| Step: 4
Training loss: 0.04731243476271629
Validation loss: 1.5779320610466825

Epoch: 6| Step: 5
Training loss: 0.08691968023777008
Validation loss: 1.5572856831294235

Epoch: 6| Step: 6
Training loss: 0.09372267127037048
Validation loss: 1.5498651650644117

Epoch: 6| Step: 7
Training loss: 0.08774793893098831
Validation loss: 1.5628006791555753

Epoch: 6| Step: 8
Training loss: 0.13382267951965332
Validation loss: 1.5178794642930389

Epoch: 6| Step: 9
Training loss: 0.11234577745199203
Validation loss: 1.5273301332227645

Epoch: 6| Step: 10
Training loss: 0.09049281477928162
Validation loss: 1.51682081273807

Epoch: 6| Step: 11
Training loss: 0.08201313018798828
Validation loss: 1.5100469076505272

Epoch: 6| Step: 12
Training loss: 0.10091928392648697
Validation loss: 1.5054455444376955

Epoch: 6| Step: 13
Training loss: 0.06360363960266113
Validation loss: 1.487643967392624

Epoch: 489| Step: 0
Training loss: 0.11887826770544052
Validation loss: 1.495420411068906

Epoch: 6| Step: 1
Training loss: 0.06320326775312424
Validation loss: 1.492146724013872

Epoch: 6| Step: 2
Training loss: 0.11421290785074234
Validation loss: 1.489327556984399

Epoch: 6| Step: 3
Training loss: 0.09091033786535263
Validation loss: 1.485894803077944

Epoch: 6| Step: 4
Training loss: 0.11145526170730591
Validation loss: 1.4812800589428152

Epoch: 6| Step: 5
Training loss: 0.07328452169895172
Validation loss: 1.4715295837771507

Epoch: 6| Step: 6
Training loss: 0.10798042267560959
Validation loss: 1.4589603793236516

Epoch: 6| Step: 7
Training loss: 0.09144790470600128
Validation loss: 1.4611683660937893

Epoch: 6| Step: 8
Training loss: 0.10880289226770401
Validation loss: 1.476725983363326

Epoch: 6| Step: 9
Training loss: 0.09023936092853546
Validation loss: 1.4559048042502454

Epoch: 6| Step: 10
Training loss: 0.1053934097290039
Validation loss: 1.458659016957847

Epoch: 6| Step: 11
Training loss: 0.12534604966640472
Validation loss: 1.4586433877227127

Epoch: 6| Step: 12
Training loss: 0.08294525742530823
Validation loss: 1.4510739452095442

Epoch: 6| Step: 13
Training loss: 0.10517676919698715
Validation loss: 1.4840740849894862

Epoch: 490| Step: 0
Training loss: 0.11795622110366821
Validation loss: 1.4763491333171885

Epoch: 6| Step: 1
Training loss: 0.04457847774028778
Validation loss: 1.488955545169051

Epoch: 6| Step: 2
Training loss: 0.08926762640476227
Validation loss: 1.5016321905197636

Epoch: 6| Step: 3
Training loss: 0.07703986018896103
Validation loss: 1.533285140991211

Epoch: 6| Step: 4
Training loss: 0.09828685224056244
Validation loss: 1.5189523850717852

Epoch: 6| Step: 5
Training loss: 0.12519384920597076
Validation loss: 1.5068184829527331

Epoch: 6| Step: 6
Training loss: 0.11353640258312225
Validation loss: 1.5357978946419173

Epoch: 6| Step: 7
Training loss: 0.07484322041273117
Validation loss: 1.5088099894985076

Epoch: 6| Step: 8
Training loss: 0.09924549609422684
Validation loss: 1.5216324137103172

Epoch: 6| Step: 9
Training loss: 0.09166854619979858
Validation loss: 1.4954812731794132

Epoch: 6| Step: 10
Training loss: 0.08073531836271286
Validation loss: 1.4714071443003993

Epoch: 6| Step: 11
Training loss: 0.09079933166503906
Validation loss: 1.4671016175259826

Epoch: 6| Step: 12
Training loss: 0.08520182222127914
Validation loss: 1.4370116315862185

Epoch: 6| Step: 13
Training loss: 0.07522691786289215
Validation loss: 1.480855639262866

Epoch: 491| Step: 0
Training loss: 0.13570059835910797
Validation loss: 1.4691535157542075

Epoch: 6| Step: 1
Training loss: 0.13072578608989716
Validation loss: 1.475102759176685

Epoch: 6| Step: 2
Training loss: 0.12089082598686218
Validation loss: 1.4879583979165683

Epoch: 6| Step: 3
Training loss: 0.09143581986427307
Validation loss: 1.4677630201462777

Epoch: 6| Step: 4
Training loss: 0.12056919932365417
Validation loss: 1.5021418993191054

Epoch: 6| Step: 5
Training loss: 0.07349713891744614
Validation loss: 1.4660675012937157

Epoch: 6| Step: 6
Training loss: 0.1328076869249344
Validation loss: 1.4466953123769453

Epoch: 6| Step: 7
Training loss: 0.10330955684185028
Validation loss: 1.4878673361193748

Epoch: 6| Step: 8
Training loss: 0.11302971839904785
Validation loss: 1.4929046015585623

Epoch: 6| Step: 9
Training loss: 0.04189794510602951
Validation loss: 1.486120403453868

Epoch: 6| Step: 10
Training loss: 0.14703921973705292
Validation loss: 1.495898736420498

Epoch: 6| Step: 11
Training loss: 0.04444243386387825
Validation loss: 1.522257162037716

Epoch: 6| Step: 12
Training loss: 0.16118666529655457
Validation loss: 1.536224551098321

Epoch: 6| Step: 13
Training loss: 0.13980048894882202
Validation loss: 1.509257447975938

Epoch: 492| Step: 0
Training loss: 0.10053165256977081
Validation loss: 1.5141206518296273

Epoch: 6| Step: 1
Training loss: 0.07935293018817902
Validation loss: 1.5466236529811737

Epoch: 6| Step: 2
Training loss: 0.13969850540161133
Validation loss: 1.5251780274093791

Epoch: 6| Step: 3
Training loss: 0.12570849061012268
Validation loss: 1.5263275446430329

Epoch: 6| Step: 4
Training loss: 0.0991838127374649
Validation loss: 1.5492958112429547

Epoch: 6| Step: 5
Training loss: 0.12217863649129868
Validation loss: 1.5348723806360716

Epoch: 6| Step: 6
Training loss: 0.06241790950298309
Validation loss: 1.5120557354342552

Epoch: 6| Step: 7
Training loss: 0.07710203528404236
Validation loss: 1.5231551380567654

Epoch: 6| Step: 8
Training loss: 0.08536313474178314
Validation loss: 1.5126145206471926

Epoch: 6| Step: 9
Training loss: 0.21171952784061432
Validation loss: 1.5159275685587237

Epoch: 6| Step: 10
Training loss: 0.08980780094861984
Validation loss: 1.5180046737834971

Epoch: 6| Step: 11
Training loss: 0.07360845804214478
Validation loss: 1.5098196998719247

Epoch: 6| Step: 12
Training loss: 0.0986180305480957
Validation loss: 1.4789359133730653

Epoch: 6| Step: 13
Training loss: 0.10813543200492859
Validation loss: 1.4834860153095697

Epoch: 493| Step: 0
Training loss: 0.1662096083164215
Validation loss: 1.485879357143115

Epoch: 6| Step: 1
Training loss: 0.09808802604675293
Validation loss: 1.5070079782957673

Epoch: 6| Step: 2
Training loss: 0.0831555426120758
Validation loss: 1.4879851238701933

Epoch: 6| Step: 3
Training loss: 0.14274786412715912
Validation loss: 1.4867574194426179

Epoch: 6| Step: 4
Training loss: 0.05168473720550537
Validation loss: 1.5095826195132347

Epoch: 6| Step: 5
Training loss: 0.08905422687530518
Validation loss: 1.5072757197964577

Epoch: 6| Step: 6
Training loss: 0.08787913620471954
Validation loss: 1.5250863958430547

Epoch: 6| Step: 7
Training loss: 0.08485237509012222
Validation loss: 1.5340989161563177

Epoch: 6| Step: 8
Training loss: 0.11797389388084412
Validation loss: 1.5502380876130955

Epoch: 6| Step: 9
Training loss: 0.11656787246465683
Validation loss: 1.5389585379631288

Epoch: 6| Step: 10
Training loss: 0.09942582249641418
Validation loss: 1.5314721189519411

Epoch: 6| Step: 11
Training loss: 0.10809054970741272
Validation loss: 1.5381214926319737

Epoch: 6| Step: 12
Training loss: 0.11808811128139496
Validation loss: 1.552353270592228

Epoch: 6| Step: 13
Training loss: 0.1320411115884781
Validation loss: 1.5577463731970838

Epoch: 494| Step: 0
Training loss: 0.10531780868768692
Validation loss: 1.5295342899137927

Epoch: 6| Step: 1
Training loss: 0.10814350843429565
Validation loss: 1.5363514513097785

Epoch: 6| Step: 2
Training loss: 0.10379742085933685
Validation loss: 1.5741361033531927

Epoch: 6| Step: 3
Training loss: 0.10101434588432312
Validation loss: 1.5531832710389168

Epoch: 6| Step: 4
Training loss: 0.14762677252292633
Validation loss: 1.5502072713708366

Epoch: 6| Step: 5
Training loss: 0.0949486494064331
Validation loss: 1.528360495003321

Epoch: 6| Step: 6
Training loss: 0.12082226574420929
Validation loss: 1.5206653405261297

Epoch: 6| Step: 7
Training loss: 0.11017338931560516
Validation loss: 1.5163294474283855

Epoch: 6| Step: 8
Training loss: 0.050485238432884216
Validation loss: 1.4942400622111496

Epoch: 6| Step: 9
Training loss: 0.07043804228305817
Validation loss: 1.5374204394637898

Epoch: 6| Step: 10
Training loss: 0.060931336134672165
Validation loss: 1.531209639323655

Epoch: 6| Step: 11
Training loss: 0.059529442340135574
Validation loss: 1.4998259044462634

Epoch: 6| Step: 12
Training loss: 0.09712974727153778
Validation loss: 1.5201342208411104

Epoch: 6| Step: 13
Training loss: 0.11901216953992844
Validation loss: 1.5387249947876058

Epoch: 495| Step: 0
Training loss: 0.09809471666812897
Validation loss: 1.4951880913908764

Epoch: 6| Step: 1
Training loss: 0.0732986107468605
Validation loss: 1.4625377167937577

Epoch: 6| Step: 2
Training loss: 0.09642497450113297
Validation loss: 1.4571732513366207

Epoch: 6| Step: 3
Training loss: 0.15205392241477966
Validation loss: 1.4614046619784447

Epoch: 6| Step: 4
Training loss: 0.14057764410972595
Validation loss: 1.4528618461342269

Epoch: 6| Step: 5
Training loss: 0.058721043169498444
Validation loss: 1.4688949405506093

Epoch: 6| Step: 6
Training loss: 0.11332579702138901
Validation loss: 1.4606472715254752

Epoch: 6| Step: 7
Training loss: 0.05346444994211197
Validation loss: 1.4795883496602376

Epoch: 6| Step: 8
Training loss: 0.09436285495758057
Validation loss: 1.509063140038521

Epoch: 6| Step: 9
Training loss: 0.10348270833492279
Validation loss: 1.5208623024725145

Epoch: 6| Step: 10
Training loss: 0.12824147939682007
Validation loss: 1.5315319030515608

Epoch: 6| Step: 11
Training loss: 0.09708510339260101
Validation loss: 1.5372263180312289

Epoch: 6| Step: 12
Training loss: 0.11256097257137299
Validation loss: 1.5500562601192023

Epoch: 6| Step: 13
Training loss: 0.15883514285087585
Validation loss: 1.551982250264896

Epoch: 496| Step: 0
Training loss: 0.08852916955947876
Validation loss: 1.549403646940826

Epoch: 6| Step: 1
Training loss: 0.1319873183965683
Validation loss: 1.5262961938817015

Epoch: 6| Step: 2
Training loss: 0.0831080824136734
Validation loss: 1.5215325240165956

Epoch: 6| Step: 3
Training loss: 0.08664596080780029
Validation loss: 1.526763750660804

Epoch: 6| Step: 4
Training loss: 0.1731797456741333
Validation loss: 1.5030434951987317

Epoch: 6| Step: 5
Training loss: 0.10415497422218323
Validation loss: 1.4812987081466182

Epoch: 6| Step: 6
Training loss: 0.12608972191810608
Validation loss: 1.5235165075589252

Epoch: 6| Step: 7
Training loss: 0.044759124517440796
Validation loss: 1.514571310371481

Epoch: 6| Step: 8
Training loss: 0.08719925582408905
Validation loss: 1.4969618666556574

Epoch: 6| Step: 9
Training loss: 0.054531656205654144
Validation loss: 1.502126862925868

Epoch: 6| Step: 10
Training loss: 0.08889880031347275
Validation loss: 1.4966334322447419

Epoch: 6| Step: 11
Training loss: 0.0713854432106018
Validation loss: 1.5126035239106865

Epoch: 6| Step: 12
Training loss: 0.10204519331455231
Validation loss: 1.5106822982911141

Epoch: 6| Step: 13
Training loss: 0.0776558443903923
Validation loss: 1.5119482278823853

Epoch: 497| Step: 0
Training loss: 0.06304655969142914
Validation loss: 1.5178774966988513

Epoch: 6| Step: 1
Training loss: 0.10122854262590408
Validation loss: 1.5088222398552844

Epoch: 6| Step: 2
Training loss: 0.07185417413711548
Validation loss: 1.527789887561593

Epoch: 6| Step: 3
Training loss: 0.14341138303279877
Validation loss: 1.5458328634180047

Epoch: 6| Step: 4
Training loss: 0.13775651156902313
Validation loss: 1.5390090532200311

Epoch: 6| Step: 5
Training loss: 0.07791651040315628
Validation loss: 1.5337563009672268

Epoch: 6| Step: 6
Training loss: 0.07117600739002228
Validation loss: 1.5209524105953913

Epoch: 6| Step: 7
Training loss: 0.11919313669204712
Validation loss: 1.5345318650686612

Epoch: 6| Step: 8
Training loss: 0.10538291186094284
Validation loss: 1.5344643977380568

Epoch: 6| Step: 9
Training loss: 0.12355954945087433
Validation loss: 1.547662313266467

Epoch: 6| Step: 10
Training loss: 0.08522100746631622
Validation loss: 1.5161434514548189

Epoch: 6| Step: 11
Training loss: 0.10519417375326157
Validation loss: 1.5366645833497405

Epoch: 6| Step: 12
Training loss: 0.10720759630203247
Validation loss: 1.5490312217384257

Epoch: 6| Step: 13
Training loss: 0.23486797511577606
Validation loss: 1.5341756190023115

Epoch: 498| Step: 0
Training loss: 0.15197208523750305
Validation loss: 1.5517444572141093

Epoch: 6| Step: 1
Training loss: 0.07923869788646698
Validation loss: 1.5537100876531293

Epoch: 6| Step: 2
Training loss: 0.08627185970544815
Validation loss: 1.5371206268187492

Epoch: 6| Step: 3
Training loss: 0.08632352948188782
Validation loss: 1.5524741295845277

Epoch: 6| Step: 4
Training loss: 0.08699053525924683
Validation loss: 1.5313411694701

Epoch: 6| Step: 5
Training loss: 0.12107239663600922
Validation loss: 1.5388566524751726

Epoch: 6| Step: 6
Training loss: 0.06354120373725891
Validation loss: 1.5165099379836873

Epoch: 6| Step: 7
Training loss: 0.083970807492733
Validation loss: 1.514161463706724

Epoch: 6| Step: 8
Training loss: 0.08831265568733215
Validation loss: 1.5329373664753412

Epoch: 6| Step: 9
Training loss: 0.08863508701324463
Validation loss: 1.549126435351628

Epoch: 6| Step: 10
Training loss: 0.11506278067827225
Validation loss: 1.5118733477848831

Epoch: 6| Step: 11
Training loss: 0.12076260149478912
Validation loss: 1.5130348423475861

Epoch: 6| Step: 12
Training loss: 0.0774933323264122
Validation loss: 1.5393181923897035

Epoch: 6| Step: 13
Training loss: 0.1379438042640686
Validation loss: 1.5432888692425144

Epoch: 499| Step: 0
Training loss: 0.08293330669403076
Validation loss: 1.5129313584296935

Epoch: 6| Step: 1
Training loss: 0.11677329987287521
Validation loss: 1.5125384446113341

Epoch: 6| Step: 2
Training loss: 0.04580025374889374
Validation loss: 1.5150611298058623

Epoch: 6| Step: 3
Training loss: 0.052499476820230484
Validation loss: 1.5502857521016111

Epoch: 6| Step: 4
Training loss: 0.14716364443302155
Validation loss: 1.5284865389588058

Epoch: 6| Step: 5
Training loss: 0.07281625270843506
Validation loss: 1.5670647826246036

Epoch: 6| Step: 6
Training loss: 0.06607413291931152
Validation loss: 1.5573944417379235

Epoch: 6| Step: 7
Training loss: 0.08093475550413132
Validation loss: 1.5281708176418016

Epoch: 6| Step: 8
Training loss: 0.11410975456237793
Validation loss: 1.5163887610999487

Epoch: 6| Step: 9
Training loss: 0.12935645878314972
Validation loss: 1.510036696669876

Epoch: 6| Step: 10
Training loss: 0.1113346666097641
Validation loss: 1.522221593446629

Epoch: 6| Step: 11
Training loss: 0.08378328382968903
Validation loss: 1.4999701335865965

Epoch: 6| Step: 12
Training loss: 0.10430527478456497
Validation loss: 1.4928483732285038

Epoch: 6| Step: 13
Training loss: 0.14694295823574066
Validation loss: 1.5107480056824223

Epoch: 500| Step: 0
Training loss: 0.10896074771881104
Validation loss: 1.4977573040992982

Epoch: 6| Step: 1
Training loss: 0.07796350866556168
Validation loss: 1.543057753193763

Epoch: 6| Step: 2
Training loss: 0.06923505663871765
Validation loss: 1.5507923813276394

Epoch: 6| Step: 3
Training loss: 0.12433439493179321
Validation loss: 1.5609518507475495

Epoch: 6| Step: 4
Training loss: 0.15205837786197662
Validation loss: 1.5851084045184556

Epoch: 6| Step: 5
Training loss: 0.09958138316869736
Validation loss: 1.5686777535305227

Epoch: 6| Step: 6
Training loss: 0.08896125853061676
Validation loss: 1.5512152468004534

Epoch: 6| Step: 7
Training loss: 0.10660342127084732
Validation loss: 1.5209388713682852

Epoch: 6| Step: 8
Training loss: 0.13457006216049194
Validation loss: 1.5157966947042814

Epoch: 6| Step: 9
Training loss: 0.08311210572719574
Validation loss: 1.4975721297725555

Epoch: 6| Step: 10
Training loss: 0.09590335190296173
Validation loss: 1.4794184559135026

Epoch: 6| Step: 11
Training loss: 0.1464434564113617
Validation loss: 1.4912143894421157

Epoch: 6| Step: 12
Training loss: 0.06851986795663834
Validation loss: 1.4911181901090889

Epoch: 6| Step: 13
Training loss: 0.07824365049600601
Validation loss: 1.4935142353016844

Epoch: 501| Step: 0
Training loss: 0.13322480022907257
Validation loss: 1.475502687115823

Epoch: 6| Step: 1
Training loss: 0.13469387590885162
Validation loss: 1.5317046821758311

Epoch: 6| Step: 2
Training loss: 0.11725116521120071
Validation loss: 1.5407563217224614

Epoch: 6| Step: 3
Training loss: 0.16463974118232727
Validation loss: 1.5362152668737596

Epoch: 6| Step: 4
Training loss: 0.12133029103279114
Validation loss: 1.5368203937366445

Epoch: 6| Step: 5
Training loss: 0.15779434144496918
Validation loss: 1.5305942745618923

Epoch: 6| Step: 6
Training loss: 0.06817247718572617
Validation loss: 1.5326701953846922

Epoch: 6| Step: 7
Training loss: 0.09144166111946106
Validation loss: 1.5264440428826116

Epoch: 6| Step: 8
Training loss: 0.06758691370487213
Validation loss: 1.5034206298089796

Epoch: 6| Step: 9
Training loss: 0.1719384342432022
Validation loss: 1.5275250852748912

Epoch: 6| Step: 10
Training loss: 0.09268346428871155
Validation loss: 1.5320529886471328

Epoch: 6| Step: 11
Training loss: 0.07790249586105347
Validation loss: 1.5192773278041551

Epoch: 6| Step: 12
Training loss: 0.14344650506973267
Validation loss: 1.535115684232404

Epoch: 6| Step: 13
Training loss: 0.0517292283475399
Validation loss: 1.504206269659022

Epoch: 502| Step: 0
Training loss: 0.08685465157032013
Validation loss: 1.528503320550406

Epoch: 6| Step: 1
Training loss: 0.0831991583108902
Validation loss: 1.5207039617723035

Epoch: 6| Step: 2
Training loss: 0.09099621325731277
Validation loss: 1.4934008441945559

Epoch: 6| Step: 3
Training loss: 0.07879477739334106
Validation loss: 1.5122031486162575

Epoch: 6| Step: 4
Training loss: 0.06739182770252228
Validation loss: 1.5249149414800829

Epoch: 6| Step: 5
Training loss: 0.11243344843387604
Validation loss: 1.5352299687682942

Epoch: 6| Step: 6
Training loss: 0.14815282821655273
Validation loss: 1.5202094636937624

Epoch: 6| Step: 7
Training loss: 0.09728436917066574
Validation loss: 1.5494088434403943

Epoch: 6| Step: 8
Training loss: 0.18018168210983276
Validation loss: 1.5324442489172823

Epoch: 6| Step: 9
Training loss: 0.11393715441226959
Validation loss: 1.499036713313031

Epoch: 6| Step: 10
Training loss: 0.0723637044429779
Validation loss: 1.4723505589269823

Epoch: 6| Step: 11
Training loss: 0.10924191772937775
Validation loss: 1.5193207366492159

Epoch: 6| Step: 12
Training loss: 0.07881850749254227
Validation loss: 1.5204862151094662

Epoch: 6| Step: 13
Training loss: 0.18587510287761688
Validation loss: 1.5152888362125685

Epoch: 503| Step: 0
Training loss: 0.08461128175258636
Validation loss: 1.527965953273158

Epoch: 6| Step: 1
Training loss: 0.12909016013145447
Validation loss: 1.5195977059743737

Epoch: 6| Step: 2
Training loss: 0.07984868437051773
Validation loss: 1.5179871641179568

Epoch: 6| Step: 3
Training loss: 0.09999796748161316
Validation loss: 1.525266110256154

Epoch: 6| Step: 4
Training loss: 0.08964189141988754
Validation loss: 1.5080954656806043

Epoch: 6| Step: 5
Training loss: 0.08607779443264008
Validation loss: 1.5104052623112996

Epoch: 6| Step: 6
Training loss: 0.08991220593452454
Validation loss: 1.5328705413367159

Epoch: 6| Step: 7
Training loss: 0.0683361142873764
Validation loss: 1.5258930831827142

Epoch: 6| Step: 8
Training loss: 0.07024463266134262
Validation loss: 1.5520476923193982

Epoch: 6| Step: 9
Training loss: 0.1071760505437851
Validation loss: 1.5561740090770106

Epoch: 6| Step: 10
Training loss: 0.07448865473270416
Validation loss: 1.5316616437768424

Epoch: 6| Step: 11
Training loss: 0.1279170960187912
Validation loss: 1.5419698697264477

Epoch: 6| Step: 12
Training loss: 0.10232605040073395
Validation loss: 1.5449814751584043

Epoch: 6| Step: 13
Training loss: 0.09322777390480042
Validation loss: 1.5359940221232753

Epoch: 504| Step: 0
Training loss: 0.11633981764316559
Validation loss: 1.5286145594812208

Epoch: 6| Step: 1
Training loss: 0.11334585398435593
Validation loss: 1.5124974878885413

Epoch: 6| Step: 2
Training loss: 0.07328340411186218
Validation loss: 1.5645856549662929

Epoch: 6| Step: 3
Training loss: 0.0949663370847702
Validation loss: 1.531997296117967

Epoch: 6| Step: 4
Training loss: 0.10505485534667969
Validation loss: 1.5215859182419316

Epoch: 6| Step: 5
Training loss: 0.13973844051361084
Validation loss: 1.5280855317269602

Epoch: 6| Step: 6
Training loss: 0.12593470513820648
Validation loss: 1.5149597839642597

Epoch: 6| Step: 7
Training loss: 0.126653790473938
Validation loss: 1.5137704034005441

Epoch: 6| Step: 8
Training loss: 0.09275314211845398
Validation loss: 1.5148937548360517

Epoch: 6| Step: 9
Training loss: 0.07364269345998764
Validation loss: 1.4917569673189552

Epoch: 6| Step: 10
Training loss: 0.106387197971344
Validation loss: 1.5214988262422624

Epoch: 6| Step: 11
Training loss: 0.04346618801355362
Validation loss: 1.5006606373735654

Epoch: 6| Step: 12
Training loss: 0.16515202820301056
Validation loss: 1.5702709831217283

Epoch: 6| Step: 13
Training loss: 0.1076422780752182
Validation loss: 1.5373146098147157

Epoch: 505| Step: 0
Training loss: 0.12382306158542633
Validation loss: 1.5382308703596874

Epoch: 6| Step: 1
Training loss: 0.08840499818325043
Validation loss: 1.532145623237856

Epoch: 6| Step: 2
Training loss: 0.1673601269721985
Validation loss: 1.5052774157575382

Epoch: 6| Step: 3
Training loss: 0.09836839139461517
Validation loss: 1.5298993202947802

Epoch: 6| Step: 4
Training loss: 0.1626286655664444
Validation loss: 1.530752460802755

Epoch: 6| Step: 5
Training loss: 0.10840018093585968
Validation loss: 1.500334680721324

Epoch: 6| Step: 6
Training loss: 0.09570948779582977
Validation loss: 1.534709676619499

Epoch: 6| Step: 7
Training loss: 0.08062778413295746
Validation loss: 1.529655247606257

Epoch: 6| Step: 8
Training loss: 0.08724526315927505
Validation loss: 1.5262128717155867

Epoch: 6| Step: 9
Training loss: 0.10399223119020462
Validation loss: 1.557050287082631

Epoch: 6| Step: 10
Training loss: 0.06711433827877045
Validation loss: 1.5615813437328543

Epoch: 6| Step: 11
Training loss: 0.08694577217102051
Validation loss: 1.5820194739167408

Epoch: 6| Step: 12
Training loss: 0.13761577010154724
Validation loss: 1.5495896544507755

Epoch: 6| Step: 13
Training loss: 0.05047846958041191
Validation loss: 1.577905535697937

Epoch: 506| Step: 0
Training loss: 0.07783995568752289
Validation loss: 1.5476291301429912

Epoch: 6| Step: 1
Training loss: 0.10883615911006927
Validation loss: 1.5697767837073213

Epoch: 6| Step: 2
Training loss: 0.05928719788789749
Validation loss: 1.5633369184309436

Epoch: 6| Step: 3
Training loss: 0.11562735587358475
Validation loss: 1.5255676456677016

Epoch: 6| Step: 4
Training loss: 0.08284112066030502
Validation loss: 1.5240361421338973

Epoch: 6| Step: 5
Training loss: 0.12641523778438568
Validation loss: 1.5247927570855746

Epoch: 6| Step: 6
Training loss: 0.12072820216417313
Validation loss: 1.5363441994113307

Epoch: 6| Step: 7
Training loss: 0.14820978045463562
Validation loss: 1.5089443755406204

Epoch: 6| Step: 8
Training loss: 0.10365387797355652
Validation loss: 1.4959676675899054

Epoch: 6| Step: 9
Training loss: 0.07101236283779144
Validation loss: 1.5161551455015778

Epoch: 6| Step: 10
Training loss: 0.08192777633666992
Validation loss: 1.5089870319571546

Epoch: 6| Step: 11
Training loss: 0.043083902448415756
Validation loss: 1.5063154940964074

Epoch: 6| Step: 12
Training loss: 0.11533868312835693
Validation loss: 1.5222256811716224

Epoch: 6| Step: 13
Training loss: 0.1531405746936798
Validation loss: 1.526700904292445

Epoch: 507| Step: 0
Training loss: 0.09212030470371246
Validation loss: 1.5158828881479078

Epoch: 6| Step: 1
Training loss: 0.12106970697641373
Validation loss: 1.527168296998547

Epoch: 6| Step: 2
Training loss: 0.07423755526542664
Validation loss: 1.5542904600020377

Epoch: 6| Step: 3
Training loss: 0.13623572885990143
Validation loss: 1.5456614712233185

Epoch: 6| Step: 4
Training loss: 0.14287003874778748
Validation loss: 1.5319070585312382

Epoch: 6| Step: 5
Training loss: 0.09517812728881836
Validation loss: 1.5632727287148918

Epoch: 6| Step: 6
Training loss: 0.11018283665180206
Validation loss: 1.5664828105639386

Epoch: 6| Step: 7
Training loss: 0.08943969011306763
Validation loss: 1.5640415453141736

Epoch: 6| Step: 8
Training loss: 0.1598181426525116
Validation loss: 1.567104334472328

Epoch: 6| Step: 9
Training loss: 0.08571229875087738
Validation loss: 1.5754403375810193

Epoch: 6| Step: 10
Training loss: 0.08823005855083466
Validation loss: 1.5583854926529752

Epoch: 6| Step: 11
Training loss: 0.08889219909906387
Validation loss: 1.5633134265099802

Epoch: 6| Step: 12
Training loss: 0.12692216038703918
Validation loss: 1.532611664905343

Epoch: 6| Step: 13
Training loss: 0.04550130292773247
Validation loss: 1.5409323105248072

Epoch: 508| Step: 0
Training loss: 0.08373073488473892
Validation loss: 1.5372639945758286

Epoch: 6| Step: 1
Training loss: 0.0889534205198288
Validation loss: 1.5376099912069177

Epoch: 6| Step: 2
Training loss: 0.12186658382415771
Validation loss: 1.529887286565637

Epoch: 6| Step: 3
Training loss: 0.07218946516513824
Validation loss: 1.535458404530761

Epoch: 6| Step: 4
Training loss: 0.0691697895526886
Validation loss: 1.5293590214944655

Epoch: 6| Step: 5
Training loss: 0.07328477501869202
Validation loss: 1.5244632203091857

Epoch: 6| Step: 6
Training loss: 0.09332951158285141
Validation loss: 1.5671418982167398

Epoch: 6| Step: 7
Training loss: 0.09426222741603851
Validation loss: 1.543538487085732

Epoch: 6| Step: 8
Training loss: 0.06158062070608139
Validation loss: 1.516840946289801

Epoch: 6| Step: 9
Training loss: 0.10464033484458923
Validation loss: 1.5377702648921678

Epoch: 6| Step: 10
Training loss: 0.10386276245117188
Validation loss: 1.5455032292232718

Epoch: 6| Step: 11
Training loss: 0.08373002707958221
Validation loss: 1.5432499172866985

Epoch: 6| Step: 12
Training loss: 0.11205881088972092
Validation loss: 1.5646493281087568

Epoch: 6| Step: 13
Training loss: 0.061056654900312424
Validation loss: 1.552052722182325

Epoch: 509| Step: 0
Training loss: 0.08083970099687576
Validation loss: 1.56924823663568

Epoch: 6| Step: 1
Training loss: 0.09947226196527481
Validation loss: 1.536648351659057

Epoch: 6| Step: 2
Training loss: 0.08225707709789276
Validation loss: 1.5557623678638088

Epoch: 6| Step: 3
Training loss: 0.10024401545524597
Validation loss: 1.5252191520506335

Epoch: 6| Step: 4
Training loss: 0.06229787319898605
Validation loss: 1.5426373840660177

Epoch: 6| Step: 5
Training loss: 0.07535184919834137
Validation loss: 1.5108917567037767

Epoch: 6| Step: 6
Training loss: 0.17768867313861847
Validation loss: 1.5001366125640048

Epoch: 6| Step: 7
Training loss: 0.09382786601781845
Validation loss: 1.5002993088896557

Epoch: 6| Step: 8
Training loss: 0.12599080801010132
Validation loss: 1.4795645590751403

Epoch: 6| Step: 9
Training loss: 0.16288679838180542
Validation loss: 1.4760394827012093

Epoch: 6| Step: 10
Training loss: 0.09948655962944031
Validation loss: 1.5117554940203184

Epoch: 6| Step: 11
Training loss: 0.10434119403362274
Validation loss: 1.5055436190738474

Epoch: 6| Step: 12
Training loss: 0.12121295928955078
Validation loss: 1.5110097867186352

Epoch: 6| Step: 13
Training loss: 0.13259267807006836
Validation loss: 1.5321636828043128

Epoch: 510| Step: 0
Training loss: 0.08281392604112625
Validation loss: 1.5144745380647722

Epoch: 6| Step: 1
Training loss: 0.13275660574436188
Validation loss: 1.4789505979066253

Epoch: 6| Step: 2
Training loss: 0.1146111860871315
Validation loss: 1.5035293294537453

Epoch: 6| Step: 3
Training loss: 0.15466468036174774
Validation loss: 1.5102151863036617

Epoch: 6| Step: 4
Training loss: 0.0956590324640274
Validation loss: 1.5037046895232251

Epoch: 6| Step: 5
Training loss: 0.09186584502458572
Validation loss: 1.5076115567197081

Epoch: 6| Step: 6
Training loss: 0.07491765171289444
Validation loss: 1.523719419715225

Epoch: 6| Step: 7
Training loss: 0.13611052930355072
Validation loss: 1.530181372037498

Epoch: 6| Step: 8
Training loss: 0.09471000730991364
Validation loss: 1.496641529503689

Epoch: 6| Step: 9
Training loss: 0.08928335458040237
Validation loss: 1.5178807986679899

Epoch: 6| Step: 10
Training loss: 0.11876064538955688
Validation loss: 1.5123129339628323

Epoch: 6| Step: 11
Training loss: 0.10883225500583649
Validation loss: 1.5174990084863478

Epoch: 6| Step: 12
Training loss: 0.08352036029100418
Validation loss: 1.496737039858295

Epoch: 6| Step: 13
Training loss: 0.1540793776512146
Validation loss: 1.4980973236022457

Epoch: 511| Step: 0
Training loss: 0.07849550247192383
Validation loss: 1.5137788672601022

Epoch: 6| Step: 1
Training loss: 0.1098020076751709
Validation loss: 1.524965141729642

Epoch: 6| Step: 2
Training loss: 0.13370966911315918
Validation loss: 1.5265323833752704

Epoch: 6| Step: 3
Training loss: 0.07694021612405777
Validation loss: 1.4787377336973786

Epoch: 6| Step: 4
Training loss: 0.1404445618391037
Validation loss: 1.5219549120113414

Epoch: 6| Step: 5
Training loss: 0.08823191374540329
Validation loss: 1.493219885774838

Epoch: 6| Step: 6
Training loss: 0.08725468814373016
Validation loss: 1.5175241667737243

Epoch: 6| Step: 7
Training loss: 0.07444765418767929
Validation loss: 1.5033731159343515

Epoch: 6| Step: 8
Training loss: 0.1077781394124031
Validation loss: 1.4903588384710333

Epoch: 6| Step: 9
Training loss: 0.061517491936683655
Validation loss: 1.4774651553041191

Epoch: 6| Step: 10
Training loss: 0.09298621118068695
Validation loss: 1.4674867571041148

Epoch: 6| Step: 11
Training loss: 0.06038352847099304
Validation loss: 1.4769609384639288

Epoch: 6| Step: 12
Training loss: 0.0831482857465744
Validation loss: 1.5123213427041167

Epoch: 6| Step: 13
Training loss: 0.07465710490942001
Validation loss: 1.4955095001446304

Epoch: 512| Step: 0
Training loss: 0.13923464715480804
Validation loss: 1.4920933195339736

Epoch: 6| Step: 1
Training loss: 0.09855709224939346
Validation loss: 1.5030740473860054

Epoch: 6| Step: 2
Training loss: 0.11917826533317566
Validation loss: 1.4920389036978445

Epoch: 6| Step: 3
Training loss: 0.08097997307777405
Validation loss: 1.5148447636635072

Epoch: 6| Step: 4
Training loss: 0.10822312533855438
Validation loss: 1.5299127037807176

Epoch: 6| Step: 5
Training loss: 0.10103294253349304
Validation loss: 1.5282790096857215

Epoch: 6| Step: 6
Training loss: 0.09862519800662994
Validation loss: 1.5299171632336033

Epoch: 6| Step: 7
Training loss: 0.06312363594770432
Validation loss: 1.5178599998515139

Epoch: 6| Step: 8
Training loss: 0.07327285408973694
Validation loss: 1.5266547690155685

Epoch: 6| Step: 9
Training loss: 0.08010068535804749
Validation loss: 1.5161514416817696

Epoch: 6| Step: 10
Training loss: 0.1389503926038742
Validation loss: 1.5169823746527396

Epoch: 6| Step: 11
Training loss: 0.13960835337638855
Validation loss: 1.543968459611298

Epoch: 6| Step: 12
Training loss: 0.09678369760513306
Validation loss: 1.5040836616228985

Epoch: 6| Step: 13
Training loss: 0.13769514858722687
Validation loss: 1.5225390426574215

Epoch: 513| Step: 0
Training loss: 0.0658435970544815
Validation loss: 1.5432410099173104

Epoch: 6| Step: 1
Training loss: 0.0792774111032486
Validation loss: 1.527231590722197

Epoch: 6| Step: 2
Training loss: 0.17064820230007172
Validation loss: 1.543284753317474

Epoch: 6| Step: 3
Training loss: 0.05378148332238197
Validation loss: 1.5317823989416963

Epoch: 6| Step: 4
Training loss: 0.11359196901321411
Validation loss: 1.539772415673861

Epoch: 6| Step: 5
Training loss: 0.12463255971670151
Validation loss: 1.564468640153126

Epoch: 6| Step: 6
Training loss: 0.12705114483833313
Validation loss: 1.5675026485996861

Epoch: 6| Step: 7
Training loss: 0.11866485327482224
Validation loss: 1.5286269816019202

Epoch: 6| Step: 8
Training loss: 0.06504163146018982
Validation loss: 1.5547252797311353

Epoch: 6| Step: 9
Training loss: 0.06584310531616211
Validation loss: 1.5365679507614465

Epoch: 6| Step: 10
Training loss: 0.11176136136054993
Validation loss: 1.5473390881733229

Epoch: 6| Step: 11
Training loss: 0.1913263201713562
Validation loss: 1.5520192294992425

Epoch: 6| Step: 12
Training loss: 0.06437935680150986
Validation loss: 1.5167663687018937

Epoch: 6| Step: 13
Training loss: 0.08618107438087463
Validation loss: 1.5094508092890504

Epoch: 514| Step: 0
Training loss: 0.07712271809577942
Validation loss: 1.5453106152114047

Epoch: 6| Step: 1
Training loss: 0.04357897490262985
Validation loss: 1.5282414203049035

Epoch: 6| Step: 2
Training loss: 0.0764545425772667
Validation loss: 1.5340501569932508

Epoch: 6| Step: 3
Training loss: 0.052470043301582336
Validation loss: 1.5267625354951428

Epoch: 6| Step: 4
Training loss: 0.052483417093753815
Validation loss: 1.4901149657464796

Epoch: 6| Step: 5
Training loss: 0.07960565388202667
Validation loss: 1.4895291405339395

Epoch: 6| Step: 6
Training loss: 0.07199622690677643
Validation loss: 1.5095823477673274

Epoch: 6| Step: 7
Training loss: 0.11980005353689194
Validation loss: 1.5125006405256127

Epoch: 6| Step: 8
Training loss: 0.08299625664949417
Validation loss: 1.4867525651890745

Epoch: 6| Step: 9
Training loss: 0.0672205314040184
Validation loss: 1.4896351829651864

Epoch: 6| Step: 10
Training loss: 0.09912419319152832
Validation loss: 1.493584381636753

Epoch: 6| Step: 11
Training loss: 0.05375077575445175
Validation loss: 1.4961936845574328

Epoch: 6| Step: 12
Training loss: 0.12328740954399109
Validation loss: 1.5140461870419082

Epoch: 6| Step: 13
Training loss: 0.1960335075855255
Validation loss: 1.5130125309831353

Epoch: 515| Step: 0
Training loss: 0.10223545134067535
Validation loss: 1.500775114182503

Epoch: 6| Step: 1
Training loss: 0.12612009048461914
Validation loss: 1.5219568488418416

Epoch: 6| Step: 2
Training loss: 0.10936085879802704
Validation loss: 1.5333099435734492

Epoch: 6| Step: 3
Training loss: 0.10792917758226395
Validation loss: 1.5336886849454654

Epoch: 6| Step: 4
Training loss: 0.0756642147898674
Validation loss: 1.5340021425677883

Epoch: 6| Step: 5
Training loss: 0.1162869930267334
Validation loss: 1.563506999323445

Epoch: 6| Step: 6
Training loss: 0.14159369468688965
Validation loss: 1.5672472420559134

Epoch: 6| Step: 7
Training loss: 0.18523147702217102
Validation loss: 1.5807840580581336

Epoch: 6| Step: 8
Training loss: 0.11643088608980179
Validation loss: 1.609730661556285

Epoch: 6| Step: 9
Training loss: 0.14558492600917816
Validation loss: 1.606794035562905

Epoch: 6| Step: 10
Training loss: 0.08068181574344635
Validation loss: 1.5884780191606092

Epoch: 6| Step: 11
Training loss: 0.07535967230796814
Validation loss: 1.608105306984276

Epoch: 6| Step: 12
Training loss: 0.11535419523715973
Validation loss: 1.5872900626992668

Epoch: 6| Step: 13
Training loss: 0.0468984954059124
Validation loss: 1.5797484561961184

Epoch: 516| Step: 0
Training loss: 0.11458231508731842
Validation loss: 1.5858962388448818

Epoch: 6| Step: 1
Training loss: 0.11998853087425232
Validation loss: 1.5573800994503884

Epoch: 6| Step: 2
Training loss: 0.14011722803115845
Validation loss: 1.5214598101954306

Epoch: 6| Step: 3
Training loss: 0.09404933452606201
Validation loss: 1.5223108741544908

Epoch: 6| Step: 4
Training loss: 0.10078182071447372
Validation loss: 1.5099293134545768

Epoch: 6| Step: 5
Training loss: 0.11160454154014587
Validation loss: 1.4885031330970027

Epoch: 6| Step: 6
Training loss: 0.11542344093322754
Validation loss: 1.483366039491469

Epoch: 6| Step: 7
Training loss: 0.0905267521739006
Validation loss: 1.4899017964639971

Epoch: 6| Step: 8
Training loss: 0.16455763578414917
Validation loss: 1.5001334695405857

Epoch: 6| Step: 9
Training loss: 0.08601623773574829
Validation loss: 1.5100119447195401

Epoch: 6| Step: 10
Training loss: 0.0771508514881134
Validation loss: 1.5236848413303334

Epoch: 6| Step: 11
Training loss: 0.12652896344661713
Validation loss: 1.512893904921829

Epoch: 6| Step: 12
Training loss: 0.11483211815357208
Validation loss: 1.553316475242697

Epoch: 6| Step: 13
Training loss: 0.17696624994277954
Validation loss: 1.549351434553823

Epoch: 517| Step: 0
Training loss: 0.12205588817596436
Validation loss: 1.5666291893169444

Epoch: 6| Step: 1
Training loss: 0.07979397475719452
Validation loss: 1.5898179546479256

Epoch: 6| Step: 2
Training loss: 0.1295415163040161
Validation loss: 1.616112735963637

Epoch: 6| Step: 3
Training loss: 0.10113973915576935
Validation loss: 1.5741164351022372

Epoch: 6| Step: 4
Training loss: 0.08135709166526794
Validation loss: 1.594775669036373

Epoch: 6| Step: 5
Training loss: 0.09822500497102737
Validation loss: 1.5736650818137712

Epoch: 6| Step: 6
Training loss: 0.06408784538507462
Validation loss: 1.5410525221978464

Epoch: 6| Step: 7
Training loss: 0.050350889563560486
Validation loss: 1.5211687498195197

Epoch: 6| Step: 8
Training loss: 0.080919548869133
Validation loss: 1.5193847251194779

Epoch: 6| Step: 9
Training loss: 0.11511626839637756
Validation loss: 1.5359024681070799

Epoch: 6| Step: 10
Training loss: 0.12265802919864655
Validation loss: 1.5432743987729471

Epoch: 6| Step: 11
Training loss: 0.05239441990852356
Validation loss: 1.5576817438166628

Epoch: 6| Step: 12
Training loss: 0.09673123061656952
Validation loss: 1.5599454295250677

Epoch: 6| Step: 13
Training loss: 0.142283633351326
Validation loss: 1.5750792539247902

Epoch: 518| Step: 0
Training loss: 0.1380074918270111
Validation loss: 1.5550420181725615

Epoch: 6| Step: 1
Training loss: 0.08259613811969757
Validation loss: 1.557641480558662

Epoch: 6| Step: 2
Training loss: 0.10956978797912598
Validation loss: 1.57553017908527

Epoch: 6| Step: 3
Training loss: 0.14625199139118195
Validation loss: 1.576813106895775

Epoch: 6| Step: 4
Training loss: 0.07195068150758743
Validation loss: 1.5991861563856884

Epoch: 6| Step: 5
Training loss: 0.1579345464706421
Validation loss: 1.5797210560050061

Epoch: 6| Step: 6
Training loss: 0.11769765615463257
Validation loss: 1.5565844287154496

Epoch: 6| Step: 7
Training loss: 0.10873634368181229
Validation loss: 1.5247956091357815

Epoch: 6| Step: 8
Training loss: 0.14413771033287048
Validation loss: 1.521180679721217

Epoch: 6| Step: 9
Training loss: 0.08654771745204926
Validation loss: 1.5376900780585505

Epoch: 6| Step: 10
Training loss: 0.07942693680524826
Validation loss: 1.5140806782630183

Epoch: 6| Step: 11
Training loss: 0.06750932335853577
Validation loss: 1.5209741515498008

Epoch: 6| Step: 12
Training loss: 0.097564697265625
Validation loss: 1.5266279123162712

Epoch: 6| Step: 13
Training loss: 0.10235297679901123
Validation loss: 1.5089227627682429

Epoch: 519| Step: 0
Training loss: 0.06725762039422989
Validation loss: 1.5063562495734102

Epoch: 6| Step: 1
Training loss: 0.13814875483512878
Validation loss: 1.5075324511015287

Epoch: 6| Step: 2
Training loss: 0.07891916483640671
Validation loss: 1.489807439747677

Epoch: 6| Step: 3
Training loss: 0.16414956748485565
Validation loss: 1.5141316101115236

Epoch: 6| Step: 4
Training loss: 0.1204485148191452
Validation loss: 1.5307696346313722

Epoch: 6| Step: 5
Training loss: 0.09227965772151947
Validation loss: 1.523334103245889

Epoch: 6| Step: 6
Training loss: 0.07974869757890701
Validation loss: 1.5022311492632794

Epoch: 6| Step: 7
Training loss: 0.07906049489974976
Validation loss: 1.5257959006935038

Epoch: 6| Step: 8
Training loss: 0.07735083997249603
Validation loss: 1.5228117524936635

Epoch: 6| Step: 9
Training loss: 0.07717052847146988
Validation loss: 1.5012287811566425

Epoch: 6| Step: 10
Training loss: 0.113687664270401
Validation loss: 1.472044844781199

Epoch: 6| Step: 11
Training loss: 0.08833493292331696
Validation loss: 1.494001079631108

Epoch: 6| Step: 12
Training loss: 0.08017557114362717
Validation loss: 1.4786491022315076

Epoch: 6| Step: 13
Training loss: 0.05901690199971199
Validation loss: 1.4661938926225067

Epoch: 520| Step: 0
Training loss: 0.0786777213215828
Validation loss: 1.4576671123504639

Epoch: 6| Step: 1
Training loss: 0.07319929450750351
Validation loss: 1.4582165454023628

Epoch: 6| Step: 2
Training loss: 0.06402818113565445
Validation loss: 1.4522063674465302

Epoch: 6| Step: 3
Training loss: 0.06653989106416702
Validation loss: 1.4564784393515637

Epoch: 6| Step: 4
Training loss: 0.1190321147441864
Validation loss: 1.4466724998207503

Epoch: 6| Step: 5
Training loss: 0.07403302192687988
Validation loss: 1.465050684508457

Epoch: 6| Step: 6
Training loss: 0.09581026434898376
Validation loss: 1.4660497762823617

Epoch: 6| Step: 7
Training loss: 0.09311878681182861
Validation loss: 1.492714705646679

Epoch: 6| Step: 8
Training loss: 0.10500127077102661
Validation loss: 1.4908281577530729

Epoch: 6| Step: 9
Training loss: 0.1286192238330841
Validation loss: 1.5065005338320168

Epoch: 6| Step: 10
Training loss: 0.06338504701852798
Validation loss: 1.5561453360383228

Epoch: 6| Step: 11
Training loss: 0.09006456285715103
Validation loss: 1.5768163614375617

Epoch: 6| Step: 12
Training loss: 0.08855210989713669
Validation loss: 1.561220903550425

Epoch: 6| Step: 13
Training loss: 0.07135169953107834
Validation loss: 1.5636114266610914

Epoch: 521| Step: 0
Training loss: 0.08608114719390869
Validation loss: 1.567413717187861

Epoch: 6| Step: 1
Training loss: 0.08735135197639465
Validation loss: 1.551267659792336

Epoch: 6| Step: 2
Training loss: 0.060036562383174896
Validation loss: 1.5731574617406374

Epoch: 6| Step: 3
Training loss: 0.11151177436113358
Validation loss: 1.552198012669881

Epoch: 6| Step: 4
Training loss: 0.12933005392551422
Validation loss: 1.5283670451051445

Epoch: 6| Step: 5
Training loss: 0.11439159512519836
Validation loss: 1.5236757006696475

Epoch: 6| Step: 6
Training loss: 0.07283417135477066
Validation loss: 1.4945592290611678

Epoch: 6| Step: 7
Training loss: 0.08481603860855103
Validation loss: 1.522169832901288

Epoch: 6| Step: 8
Training loss: 0.09404172003269196
Validation loss: 1.5249314705530803

Epoch: 6| Step: 9
Training loss: 0.05517250671982765
Validation loss: 1.5131972323181808

Epoch: 6| Step: 10
Training loss: 0.10497169196605682
Validation loss: 1.4950045372850151

Epoch: 6| Step: 11
Training loss: 0.09955141693353653
Validation loss: 1.5028075095145934

Epoch: 6| Step: 12
Training loss: 0.11343871057033539
Validation loss: 1.4765782266534784

Epoch: 6| Step: 13
Training loss: 0.0828469842672348
Validation loss: 1.4766412332493772

Epoch: 522| Step: 0
Training loss: 0.08306373655796051
Validation loss: 1.4893818401521253

Epoch: 6| Step: 1
Training loss: 0.09664081782102585
Validation loss: 1.469266555642569

Epoch: 6| Step: 2
Training loss: 0.1143825501203537
Validation loss: 1.4851625222031788

Epoch: 6| Step: 3
Training loss: 0.059147901833057404
Validation loss: 1.4965150843384445

Epoch: 6| Step: 4
Training loss: 0.09426671266555786
Validation loss: 1.5198988991398965

Epoch: 6| Step: 5
Training loss: 0.09738189727067947
Validation loss: 1.538131337012014

Epoch: 6| Step: 6
Training loss: 0.11478190124034882
Validation loss: 1.5098461579251032

Epoch: 6| Step: 7
Training loss: 0.11042483150959015
Validation loss: 1.4970492650103826

Epoch: 6| Step: 8
Training loss: 0.076118603348732
Validation loss: 1.4906999661076454

Epoch: 6| Step: 9
Training loss: 0.08097120374441147
Validation loss: 1.5164549273829306

Epoch: 6| Step: 10
Training loss: 0.0662197545170784
Validation loss: 1.522732045701755

Epoch: 6| Step: 11
Training loss: 0.08155722916126251
Validation loss: 1.5578194202915314

Epoch: 6| Step: 12
Training loss: 0.1021999940276146
Validation loss: 1.542040083997993

Epoch: 6| Step: 13
Training loss: 0.06950315088033676
Validation loss: 1.5370691694239134

Epoch: 523| Step: 0
Training loss: 0.11312422156333923
Validation loss: 1.5452799284329979

Epoch: 6| Step: 1
Training loss: 0.10104229301214218
Validation loss: 1.5282083929225962

Epoch: 6| Step: 2
Training loss: 0.07317468523979187
Validation loss: 1.53176075156017

Epoch: 6| Step: 3
Training loss: 0.07367455214262009
Validation loss: 1.5112063115642917

Epoch: 6| Step: 4
Training loss: 0.11375550180673599
Validation loss: 1.5252122725209882

Epoch: 6| Step: 5
Training loss: 0.13007164001464844
Validation loss: 1.5288033793049474

Epoch: 6| Step: 6
Training loss: 0.08482013642787933
Validation loss: 1.508472381099578

Epoch: 6| Step: 7
Training loss: 0.06953562796115875
Validation loss: 1.4957698698966735

Epoch: 6| Step: 8
Training loss: 0.11015589535236359
Validation loss: 1.4871293774215124

Epoch: 6| Step: 9
Training loss: 0.09030542522668839
Validation loss: 1.4968142323596503

Epoch: 6| Step: 10
Training loss: 0.04129929840564728
Validation loss: 1.4974770058867752

Epoch: 6| Step: 11
Training loss: 0.126900315284729
Validation loss: 1.5064008082112958

Epoch: 6| Step: 12
Training loss: 0.051332030445337296
Validation loss: 1.4861550215751893

Epoch: 6| Step: 13
Training loss: 0.05561363697052002
Validation loss: 1.4733862082163494

Epoch: 524| Step: 0
Training loss: 0.10063748061656952
Validation loss: 1.465666728634988

Epoch: 6| Step: 1
Training loss: 0.11707785725593567
Validation loss: 1.455903762130327

Epoch: 6| Step: 2
Training loss: 0.07457547634840012
Validation loss: 1.4743710987029537

Epoch: 6| Step: 3
Training loss: 0.053504206240177155
Validation loss: 1.4997926655636038

Epoch: 6| Step: 4
Training loss: 0.08586318790912628
Validation loss: 1.485909854212115

Epoch: 6| Step: 5
Training loss: 0.13008251786231995
Validation loss: 1.502881396201349

Epoch: 6| Step: 6
Training loss: 0.08952666074037552
Validation loss: 1.500203372329794

Epoch: 6| Step: 7
Training loss: 0.06690564006567001
Validation loss: 1.5433437747340049

Epoch: 6| Step: 8
Training loss: 0.06721696257591248
Validation loss: 1.5295673160142795

Epoch: 6| Step: 9
Training loss: 0.10296394675970078
Validation loss: 1.5446516057496429

Epoch: 6| Step: 10
Training loss: 0.10045778751373291
Validation loss: 1.5272599484330864

Epoch: 6| Step: 11
Training loss: 0.05453471839427948
Validation loss: 1.535848512444445

Epoch: 6| Step: 12
Training loss: 0.05585261434316635
Validation loss: 1.544582063151944

Epoch: 6| Step: 13
Training loss: 0.1311451941728592
Validation loss: 1.5443273975003151

Epoch: 525| Step: 0
Training loss: 0.07026323676109314
Validation loss: 1.5715846771834998

Epoch: 6| Step: 1
Training loss: 0.08239495754241943
Validation loss: 1.5682968183230328

Epoch: 6| Step: 2
Training loss: 0.045522384345531464
Validation loss: 1.5607696886985534

Epoch: 6| Step: 3
Training loss: 0.09141445904970169
Validation loss: 1.5285474741330711

Epoch: 6| Step: 4
Training loss: 0.08687739074230194
Validation loss: 1.5281388874976867

Epoch: 6| Step: 5
Training loss: 0.06577356159687042
Validation loss: 1.5361208326073104

Epoch: 6| Step: 6
Training loss: 0.11294738203287125
Validation loss: 1.5305351839270642

Epoch: 6| Step: 7
Training loss: 0.09299855679273605
Validation loss: 1.5290064683524511

Epoch: 6| Step: 8
Training loss: 0.09864058345556259
Validation loss: 1.512800233979379

Epoch: 6| Step: 9
Training loss: 0.13833999633789062
Validation loss: 1.5361723989568732

Epoch: 6| Step: 10
Training loss: 0.06920957565307617
Validation loss: 1.5019044453097927

Epoch: 6| Step: 11
Training loss: 0.09166964888572693
Validation loss: 1.538414357810892

Epoch: 6| Step: 12
Training loss: 0.04596620798110962
Validation loss: 1.5529542892209944

Epoch: 6| Step: 13
Training loss: 0.11577990651130676
Validation loss: 1.565382521639588

Epoch: 526| Step: 0
Training loss: 0.09097272157669067
Validation loss: 1.549888841567501

Epoch: 6| Step: 1
Training loss: 0.04872249811887741
Validation loss: 1.5270603920823784

Epoch: 6| Step: 2
Training loss: 0.1048906221985817
Validation loss: 1.5386317353094778

Epoch: 6| Step: 3
Training loss: 0.12937301397323608
Validation loss: 1.5561132507939492

Epoch: 6| Step: 4
Training loss: 0.14927828311920166
Validation loss: 1.5461255927239694

Epoch: 6| Step: 5
Training loss: 0.0682784914970398
Validation loss: 1.5293734073638916

Epoch: 6| Step: 6
Training loss: 0.07644212990999222
Validation loss: 1.5306675523839972

Epoch: 6| Step: 7
Training loss: 0.09232941269874573
Validation loss: 1.4949807018362067

Epoch: 6| Step: 8
Training loss: 0.09754651039838791
Validation loss: 1.489709605452835

Epoch: 6| Step: 9
Training loss: 0.09362810850143433
Validation loss: 1.4650330107699159

Epoch: 6| Step: 10
Training loss: 0.09635820984840393
Validation loss: 1.4590988441180157

Epoch: 6| Step: 11
Training loss: 0.08448773622512817
Validation loss: 1.4883361811278968

Epoch: 6| Step: 12
Training loss: 0.08700641244649887
Validation loss: 1.464507177311887

Epoch: 6| Step: 13
Training loss: 0.10122224688529968
Validation loss: 1.4929002895150134

Epoch: 527| Step: 0
Training loss: 0.11199337244033813
Validation loss: 1.4538184699191843

Epoch: 6| Step: 1
Training loss: 0.16647744178771973
Validation loss: 1.4783825284691268

Epoch: 6| Step: 2
Training loss: 0.09320424497127533
Validation loss: 1.4831977044382403

Epoch: 6| Step: 3
Training loss: 0.07410996407270432
Validation loss: 1.5003806262887933

Epoch: 6| Step: 4
Training loss: 0.05630062520503998
Validation loss: 1.4953681730454969

Epoch: 6| Step: 5
Training loss: 0.07218985259532928
Validation loss: 1.492538498293969

Epoch: 6| Step: 6
Training loss: 0.09420010447502136
Validation loss: 1.4919428120377243

Epoch: 6| Step: 7
Training loss: 0.08166360855102539
Validation loss: 1.4872308584951586

Epoch: 6| Step: 8
Training loss: 0.06232224404811859
Validation loss: 1.5004041541007258

Epoch: 6| Step: 9
Training loss: 0.08978702127933502
Validation loss: 1.51393864680362

Epoch: 6| Step: 10
Training loss: 0.08547186106443405
Validation loss: 1.517021321481274

Epoch: 6| Step: 11
Training loss: 0.10556517541408539
Validation loss: 1.5406436715074765

Epoch: 6| Step: 12
Training loss: 0.12629996240139008
Validation loss: 1.5214203634569723

Epoch: 6| Step: 13
Training loss: 0.06192480027675629
Validation loss: 1.4913962323178527

Epoch: 528| Step: 0
Training loss: 0.054000258445739746
Validation loss: 1.4926012959531558

Epoch: 6| Step: 1
Training loss: 0.11289413273334503
Validation loss: 1.4654760540172618

Epoch: 6| Step: 2
Training loss: 0.13989341259002686
Validation loss: 1.4892921588754142

Epoch: 6| Step: 3
Training loss: 0.14684376120567322
Validation loss: 1.4939426529792048

Epoch: 6| Step: 4
Training loss: 0.12153003364801407
Validation loss: 1.4854787652210524

Epoch: 6| Step: 5
Training loss: 0.10780122131109238
Validation loss: 1.4884454383645007

Epoch: 6| Step: 6
Training loss: 0.07823359966278076
Validation loss: 1.5074181851520334

Epoch: 6| Step: 7
Training loss: 0.06127066910266876
Validation loss: 1.5161154975173294

Epoch: 6| Step: 8
Training loss: 0.07875359058380127
Validation loss: 1.4924991310283702

Epoch: 6| Step: 9
Training loss: 0.08783242851495743
Validation loss: 1.5330856718042845

Epoch: 6| Step: 10
Training loss: 0.0649365559220314
Validation loss: 1.528199908553913

Epoch: 6| Step: 11
Training loss: 0.04376371204853058
Validation loss: 1.5121891139655985

Epoch: 6| Step: 12
Training loss: 0.09640433639287949
Validation loss: 1.537360199677047

Epoch: 6| Step: 13
Training loss: 0.08477749675512314
Validation loss: 1.5415854172040058

Epoch: 529| Step: 0
Training loss: 0.03167896345257759
Validation loss: 1.52417040640308

Epoch: 6| Step: 1
Training loss: 0.09781084954738617
Validation loss: 1.5043742349070888

Epoch: 6| Step: 2
Training loss: 0.10971314460039139
Validation loss: 1.5283898217703706

Epoch: 6| Step: 3
Training loss: 0.10935872793197632
Validation loss: 1.5374959079168176

Epoch: 6| Step: 4
Training loss: 0.09878067672252655
Validation loss: 1.5083303823265979

Epoch: 6| Step: 5
Training loss: 0.11786460876464844
Validation loss: 1.5137116665481238

Epoch: 6| Step: 6
Training loss: 0.06464693695306778
Validation loss: 1.5424442880897111

Epoch: 6| Step: 7
Training loss: 0.06317960470914841
Validation loss: 1.519053723222466

Epoch: 6| Step: 8
Training loss: 0.09105740487575531
Validation loss: 1.5371306660354778

Epoch: 6| Step: 9
Training loss: 0.06520754098892212
Validation loss: 1.5282780060204126

Epoch: 6| Step: 10
Training loss: 0.057342685759067535
Validation loss: 1.532754385343162

Epoch: 6| Step: 11
Training loss: 0.08832146972417831
Validation loss: 1.5057612452455746

Epoch: 6| Step: 12
Training loss: 0.07220196723937988
Validation loss: 1.5114977750726926

Epoch: 6| Step: 13
Training loss: 0.07670741528272629
Validation loss: 1.5378329894875968

Epoch: 530| Step: 0
Training loss: 0.10359524190425873
Validation loss: 1.5438892456793016

Epoch: 6| Step: 1
Training loss: 0.0724588930606842
Validation loss: 1.5224300071757326

Epoch: 6| Step: 2
Training loss: 0.06311559677124023
Validation loss: 1.5677933244295017

Epoch: 6| Step: 3
Training loss: 0.06494034826755524
Validation loss: 1.5608101237204768

Epoch: 6| Step: 4
Training loss: 0.06967972218990326
Validation loss: 1.5345190109745148

Epoch: 6| Step: 5
Training loss: 0.08113102614879608
Validation loss: 1.536485945024798

Epoch: 6| Step: 6
Training loss: 0.07890985906124115
Validation loss: 1.5309942153192335

Epoch: 6| Step: 7
Training loss: 0.08078424632549286
Validation loss: 1.5317215047856814

Epoch: 6| Step: 8
Training loss: 0.13251519203186035
Validation loss: 1.5395352122604207

Epoch: 6| Step: 9
Training loss: 0.04731021821498871
Validation loss: 1.5156741475546232

Epoch: 6| Step: 10
Training loss: 0.06284855306148529
Validation loss: 1.494773760918648

Epoch: 6| Step: 11
Training loss: 0.07832217961549759
Validation loss: 1.5192251090080506

Epoch: 6| Step: 12
Training loss: 0.040937598794698715
Validation loss: 1.4943534558819187

Epoch: 6| Step: 13
Training loss: 0.1577044278383255
Validation loss: 1.502288410740514

Epoch: 531| Step: 0
Training loss: 0.07671375572681427
Validation loss: 1.5032990465882003

Epoch: 6| Step: 1
Training loss: 0.08958202600479126
Validation loss: 1.490012575221318

Epoch: 6| Step: 2
Training loss: 0.08791284263134003
Validation loss: 1.5239664431541198

Epoch: 6| Step: 3
Training loss: 0.07631032913923264
Validation loss: 1.5181111161426832

Epoch: 6| Step: 4
Training loss: 0.06887710839509964
Validation loss: 1.4883134672718663

Epoch: 6| Step: 5
Training loss: 0.10968022793531418
Validation loss: 1.493492437947181

Epoch: 6| Step: 6
Training loss: 0.14011716842651367
Validation loss: 1.5225251964343491

Epoch: 6| Step: 7
Training loss: 0.07592203468084335
Validation loss: 1.5308394867886779

Epoch: 6| Step: 8
Training loss: 0.059795185923576355
Validation loss: 1.5037373419730895

Epoch: 6| Step: 9
Training loss: 0.09215579181909561
Validation loss: 1.498677686978412

Epoch: 6| Step: 10
Training loss: 0.09122498333454132
Validation loss: 1.4988783982492262

Epoch: 6| Step: 11
Training loss: 0.09114938229322433
Validation loss: 1.5320628253362512

Epoch: 6| Step: 12
Training loss: 0.11949923634529114
Validation loss: 1.5270918210347493

Epoch: 6| Step: 13
Training loss: 0.10071202367544174
Validation loss: 1.5463292624360772

Epoch: 532| Step: 0
Training loss: 0.13575764000415802
Validation loss: 1.5020991525342386

Epoch: 6| Step: 1
Training loss: 0.1138409972190857
Validation loss: 1.5356435339937928

Epoch: 6| Step: 2
Training loss: 0.048419706523418427
Validation loss: 1.5469636545386365

Epoch: 6| Step: 3
Training loss: 0.06098908931016922
Validation loss: 1.512571281002414

Epoch: 6| Step: 4
Training loss: 0.14579549431800842
Validation loss: 1.535164426731807

Epoch: 6| Step: 5
Training loss: 0.07173468917608261
Validation loss: 1.5199674739632556

Epoch: 6| Step: 6
Training loss: 0.04290011152625084
Validation loss: 1.53964989800607

Epoch: 6| Step: 7
Training loss: 0.0847659558057785
Validation loss: 1.520002922704143

Epoch: 6| Step: 8
Training loss: 0.06172110140323639
Validation loss: 1.5244816310944096

Epoch: 6| Step: 9
Training loss: 0.08185858279466629
Validation loss: 1.5252734538047545

Epoch: 6| Step: 10
Training loss: 0.07158692926168442
Validation loss: 1.5159296592076619

Epoch: 6| Step: 11
Training loss: 0.0964386910200119
Validation loss: 1.5184043940677439

Epoch: 6| Step: 12
Training loss: 0.06432037055492401
Validation loss: 1.5102744179387246

Epoch: 6| Step: 13
Training loss: 0.048880498856306076
Validation loss: 1.5146933678657777

Epoch: 533| Step: 0
Training loss: 0.10714178532361984
Validation loss: 1.5106787912307247

Epoch: 6| Step: 1
Training loss: 0.07395770400762558
Validation loss: 1.4708692335313367

Epoch: 6| Step: 2
Training loss: 0.04991302639245987
Validation loss: 1.4986407423532138

Epoch: 6| Step: 3
Training loss: 0.09658452123403549
Validation loss: 1.5060072650191605

Epoch: 6| Step: 4
Training loss: 0.05893486365675926
Validation loss: 1.5072706848062494

Epoch: 6| Step: 5
Training loss: 0.06154964491724968
Validation loss: 1.514651636923513

Epoch: 6| Step: 6
Training loss: 0.07602040469646454
Validation loss: 1.5019284256042973

Epoch: 6| Step: 7
Training loss: 0.061543334275484085
Validation loss: 1.5107715424670969

Epoch: 6| Step: 8
Training loss: 0.09023986011743546
Validation loss: 1.5275198919798738

Epoch: 6| Step: 9
Training loss: 0.06239064782857895
Validation loss: 1.537626390816063

Epoch: 6| Step: 10
Training loss: 0.0640328973531723
Validation loss: 1.511518810385017

Epoch: 6| Step: 11
Training loss: 0.1061806008219719
Validation loss: 1.506132633455338

Epoch: 6| Step: 12
Training loss: 0.12030161917209625
Validation loss: 1.510083734348256

Epoch: 6| Step: 13
Training loss: 0.12079867720603943
Validation loss: 1.486034902193213

Epoch: 534| Step: 0
Training loss: 0.05848389491438866
Validation loss: 1.4851361064500705

Epoch: 6| Step: 1
Training loss: 0.09618525207042694
Validation loss: 1.480542484150138

Epoch: 6| Step: 2
Training loss: 0.06953874230384827
Validation loss: 1.4944846066095496

Epoch: 6| Step: 3
Training loss: 0.0834197998046875
Validation loss: 1.4759630413465603

Epoch: 6| Step: 4
Training loss: 0.04935692250728607
Validation loss: 1.5115055332901657

Epoch: 6| Step: 5
Training loss: 0.07484942674636841
Validation loss: 1.501977938477711

Epoch: 6| Step: 6
Training loss: 0.08659031987190247
Validation loss: 1.4991087432830565

Epoch: 6| Step: 7
Training loss: 0.10847491025924683
Validation loss: 1.491406488162215

Epoch: 6| Step: 8
Training loss: 0.1163705363869667
Validation loss: 1.5034731357328353

Epoch: 6| Step: 9
Training loss: 0.07236839085817337
Validation loss: 1.4937315057682734

Epoch: 6| Step: 10
Training loss: 0.06718006730079651
Validation loss: 1.4686722704159316

Epoch: 6| Step: 11
Training loss: 0.057097114622592926
Validation loss: 1.4874294419442453

Epoch: 6| Step: 12
Training loss: 0.06537395715713501
Validation loss: 1.4885547481557375

Epoch: 6| Step: 13
Training loss: 0.06734509021043777
Validation loss: 1.484721222231465

Epoch: 535| Step: 0
Training loss: 0.07049128413200378
Validation loss: 1.4931166915483371

Epoch: 6| Step: 1
Training loss: 0.04097840189933777
Validation loss: 1.469496448834737

Epoch: 6| Step: 2
Training loss: 0.055093914270401
Validation loss: 1.5022281292946107

Epoch: 6| Step: 3
Training loss: 0.0669141635298729
Validation loss: 1.5195688483535603

Epoch: 6| Step: 4
Training loss: 0.10462790727615356
Validation loss: 1.50759082968517

Epoch: 6| Step: 5
Training loss: 0.06362149119377136
Validation loss: 1.5464579533505183

Epoch: 6| Step: 6
Training loss: 0.10994550585746765
Validation loss: 1.5199850887380622

Epoch: 6| Step: 7
Training loss: 0.03725266456604004
Validation loss: 1.530526356030536

Epoch: 6| Step: 8
Training loss: 0.0926341861486435
Validation loss: 1.5539467514202159

Epoch: 6| Step: 9
Training loss: 0.06780026108026505
Validation loss: 1.5704210894082182

Epoch: 6| Step: 10
Training loss: 0.12471196800470352
Validation loss: 1.5752717884637977

Epoch: 6| Step: 11
Training loss: 0.09504562616348267
Validation loss: 1.588625374660697

Epoch: 6| Step: 12
Training loss: 0.11447145789861679
Validation loss: 1.5716066257928007

Epoch: 6| Step: 13
Training loss: 0.0615043118596077
Validation loss: 1.5576329538899083

Epoch: 536| Step: 0
Training loss: 0.06262589991092682
Validation loss: 1.5286162566113215

Epoch: 6| Step: 1
Training loss: 0.07705195993185043
Validation loss: 1.5117386656422769

Epoch: 6| Step: 2
Training loss: 0.13468819856643677
Validation loss: 1.5087840140506785

Epoch: 6| Step: 3
Training loss: 0.08532465994358063
Validation loss: 1.5182672546755882

Epoch: 6| Step: 4
Training loss: 0.0429072305560112
Validation loss: 1.4879684884061095

Epoch: 6| Step: 5
Training loss: 0.08345358818769455
Validation loss: 1.4794580942840987

Epoch: 6| Step: 6
Training loss: 0.0597495436668396
Validation loss: 1.4791278557110858

Epoch: 6| Step: 7
Training loss: 0.07432518899440765
Validation loss: 1.459779045915091

Epoch: 6| Step: 8
Training loss: 0.10657989233732224
Validation loss: 1.4597734571785055

Epoch: 6| Step: 9
Training loss: 0.1146722286939621
Validation loss: 1.4864088091799008

Epoch: 6| Step: 10
Training loss: 0.08980955183506012
Validation loss: 1.4908728689275763

Epoch: 6| Step: 11
Training loss: 0.13041216135025024
Validation loss: 1.5154828025448708

Epoch: 6| Step: 12
Training loss: 0.09569031745195389
Validation loss: 1.5248007799989434

Epoch: 6| Step: 13
Training loss: 0.15686431527137756
Validation loss: 1.5232838033348002

Epoch: 537| Step: 0
Training loss: 0.08161552250385284
Validation loss: 1.5288701954708304

Epoch: 6| Step: 1
Training loss: 0.10811585187911987
Validation loss: 1.5088025754497898

Epoch: 6| Step: 2
Training loss: 0.08202250301837921
Validation loss: 1.4733073301212762

Epoch: 6| Step: 3
Training loss: 0.047676265239715576
Validation loss: 1.4894340371572843

Epoch: 6| Step: 4
Training loss: 0.09666009247303009
Validation loss: 1.4555344555967598

Epoch: 6| Step: 5
Training loss: 0.07457376271486282
Validation loss: 1.5141919351393176

Epoch: 6| Step: 6
Training loss: 0.15478895604610443
Validation loss: 1.506117941230856

Epoch: 6| Step: 7
Training loss: 0.06913627684116364
Validation loss: 1.4998997847239177

Epoch: 6| Step: 8
Training loss: 0.08232389390468597
Validation loss: 1.5000237457213863

Epoch: 6| Step: 9
Training loss: 0.12353260815143585
Validation loss: 1.502423241574277

Epoch: 6| Step: 10
Training loss: 0.08449836820363998
Validation loss: 1.4906450484388618

Epoch: 6| Step: 11
Training loss: 0.0731412023305893
Validation loss: 1.4976790028233682

Epoch: 6| Step: 12
Training loss: 0.06934478878974915
Validation loss: 1.4947409834913028

Epoch: 6| Step: 13
Training loss: 0.07751771807670593
Validation loss: 1.4878650301246232

Epoch: 538| Step: 0
Training loss: 0.056404683738946915
Validation loss: 1.5075685984344893

Epoch: 6| Step: 1
Training loss: 0.05320082977414131
Validation loss: 1.5162297910259617

Epoch: 6| Step: 2
Training loss: 0.08177138864994049
Validation loss: 1.4859054460320422

Epoch: 6| Step: 3
Training loss: 0.06236448138952255
Validation loss: 1.5010630366622761

Epoch: 6| Step: 4
Training loss: 0.0863967314362526
Validation loss: 1.4994130160218926

Epoch: 6| Step: 5
Training loss: 0.08060848712921143
Validation loss: 1.4772595026159798

Epoch: 6| Step: 6
Training loss: 0.07670958340167999
Validation loss: 1.518064373282976

Epoch: 6| Step: 7
Training loss: 0.1636621356010437
Validation loss: 1.5228079724055466

Epoch: 6| Step: 8
Training loss: 0.08157159388065338
Validation loss: 1.521600245147623

Epoch: 6| Step: 9
Training loss: 0.05319878086447716
Validation loss: 1.4990007659440399

Epoch: 6| Step: 10
Training loss: 0.07311058789491653
Validation loss: 1.5193919276678434

Epoch: 6| Step: 11
Training loss: 0.13514497876167297
Validation loss: 1.5039909917821166

Epoch: 6| Step: 12
Training loss: 0.10216394066810608
Validation loss: 1.5227625780208136

Epoch: 6| Step: 13
Training loss: 0.06971099227666855
Validation loss: 1.554819901784261

Epoch: 539| Step: 0
Training loss: 0.0755314826965332
Validation loss: 1.5536488422783472

Epoch: 6| Step: 1
Training loss: 0.06195933371782303
Validation loss: 1.5674486749915666

Epoch: 6| Step: 2
Training loss: 0.08784995228052139
Validation loss: 1.5336394848362092

Epoch: 6| Step: 3
Training loss: 0.09665019810199738
Validation loss: 1.538828037118399

Epoch: 6| Step: 4
Training loss: 0.09797300398349762
Validation loss: 1.5432134700077835

Epoch: 6| Step: 5
Training loss: 0.05726247653365135
Validation loss: 1.5213793413613432

Epoch: 6| Step: 6
Training loss: 0.10371507704257965
Validation loss: 1.5392467860252625

Epoch: 6| Step: 7
Training loss: 0.09695985913276672
Validation loss: 1.5170447454657605

Epoch: 6| Step: 8
Training loss: 0.10697309672832489
Validation loss: 1.490170874903279

Epoch: 6| Step: 9
Training loss: 0.08628804981708527
Validation loss: 1.5123223739285623

Epoch: 6| Step: 10
Training loss: 0.049909111112356186
Validation loss: 1.5249415636062622

Epoch: 6| Step: 11
Training loss: 0.10438403487205505
Validation loss: 1.5149640831896054

Epoch: 6| Step: 12
Training loss: 0.08740261197090149
Validation loss: 1.4938727937718874

Epoch: 6| Step: 13
Training loss: 0.06854002922773361
Validation loss: 1.5214863220850627

Epoch: 540| Step: 0
Training loss: 0.08091137558221817
Validation loss: 1.5265988624224098

Epoch: 6| Step: 1
Training loss: 0.043336112052202225
Validation loss: 1.5038557001339492

Epoch: 6| Step: 2
Training loss: 0.11527781933546066
Validation loss: 1.506602079637589

Epoch: 6| Step: 3
Training loss: 0.07287152111530304
Validation loss: 1.509526450146911

Epoch: 6| Step: 4
Training loss: 0.08148642629384995
Validation loss: 1.4952156684731925

Epoch: 6| Step: 5
Training loss: 0.05535357445478439
Validation loss: 1.4909756209260674

Epoch: 6| Step: 6
Training loss: 0.08341000974178314
Validation loss: 1.5039468593494867

Epoch: 6| Step: 7
Training loss: 0.10649032890796661
Validation loss: 1.539165235334827

Epoch: 6| Step: 8
Training loss: 0.08126555383205414
Validation loss: 1.5389939226130003

Epoch: 6| Step: 9
Training loss: 0.10543450713157654
Validation loss: 1.4983625245350662

Epoch: 6| Step: 10
Training loss: 0.04477943480014801
Validation loss: 1.5425700013355543

Epoch: 6| Step: 11
Training loss: 0.08000294864177704
Validation loss: 1.5542832664264146

Epoch: 6| Step: 12
Training loss: 0.10243386030197144
Validation loss: 1.5431262241896762

Epoch: 6| Step: 13
Training loss: 0.10433488339185715
Validation loss: 1.5488297964936943

Epoch: 541| Step: 0
Training loss: 0.11646273732185364
Validation loss: 1.5412679410749865

Epoch: 6| Step: 1
Training loss: 0.058967407792806625
Validation loss: 1.5434801886158604

Epoch: 6| Step: 2
Training loss: 0.12835153937339783
Validation loss: 1.4873299214147753

Epoch: 6| Step: 3
Training loss: 0.04427932947874069
Validation loss: 1.5159415211728824

Epoch: 6| Step: 4
Training loss: 0.07685482501983643
Validation loss: 1.4736090007648672

Epoch: 6| Step: 5
Training loss: 0.07520639896392822
Validation loss: 1.4951150930056007

Epoch: 6| Step: 6
Training loss: 0.05103028565645218
Validation loss: 1.4902146682944348

Epoch: 6| Step: 7
Training loss: 0.09633400291204453
Validation loss: 1.4635635716940767

Epoch: 6| Step: 8
Training loss: 0.09269213676452637
Validation loss: 1.5149664596844745

Epoch: 6| Step: 9
Training loss: 0.0780312642455101
Validation loss: 1.5253334801684144

Epoch: 6| Step: 10
Training loss: 0.07395856082439423
Validation loss: 1.5057109773799937

Epoch: 6| Step: 11
Training loss: 0.11036159098148346
Validation loss: 1.5280053718115694

Epoch: 6| Step: 12
Training loss: 0.076536163687706
Validation loss: 1.5453157117289882

Epoch: 6| Step: 13
Training loss: 0.0687626302242279
Validation loss: 1.5319259384626984

Epoch: 542| Step: 0
Training loss: 0.12872055172920227
Validation loss: 1.5408771781511204

Epoch: 6| Step: 1
Training loss: 0.08928913623094559
Validation loss: 1.519955340893038

Epoch: 6| Step: 2
Training loss: 0.09174613654613495
Validation loss: 1.5362835725148518

Epoch: 6| Step: 3
Training loss: 0.06785504519939423
Validation loss: 1.524133748905633

Epoch: 6| Step: 4
Training loss: 0.09373504668474197
Validation loss: 1.534234675027991

Epoch: 6| Step: 5
Training loss: 0.07952937483787537
Validation loss: 1.5283951297883065

Epoch: 6| Step: 6
Training loss: 0.08377447724342346
Validation loss: 1.547350751456394

Epoch: 6| Step: 7
Training loss: 0.07970741391181946
Validation loss: 1.5373968437153807

Epoch: 6| Step: 8
Training loss: 0.06630681455135345
Validation loss: 1.5123706056225685

Epoch: 6| Step: 9
Training loss: 0.11177137494087219
Validation loss: 1.5239683075617718

Epoch: 6| Step: 10
Training loss: 0.06458019465208054
Validation loss: 1.513229323971656

Epoch: 6| Step: 11
Training loss: 0.06785865873098373
Validation loss: 1.5364684917593514

Epoch: 6| Step: 12
Training loss: 0.12010278552770615
Validation loss: 1.5215225886273127

Epoch: 6| Step: 13
Training loss: 0.08719714730978012
Validation loss: 1.4960776887914187

Epoch: 543| Step: 0
Training loss: 0.07643537223339081
Validation loss: 1.501623910601421

Epoch: 6| Step: 1
Training loss: 0.0843389555811882
Validation loss: 1.4880394576698222

Epoch: 6| Step: 2
Training loss: 0.0749589055776596
Validation loss: 1.5133041720236502

Epoch: 6| Step: 3
Training loss: 0.06545737385749817
Validation loss: 1.526149344700639

Epoch: 6| Step: 4
Training loss: 0.08070871978998184
Validation loss: 1.5268838943973664

Epoch: 6| Step: 5
Training loss: 0.20744554698467255
Validation loss: 1.5088227192560832

Epoch: 6| Step: 6
Training loss: 0.0876179039478302
Validation loss: 1.5319518825059295

Epoch: 6| Step: 7
Training loss: 0.06978064775466919
Validation loss: 1.5385267170526649

Epoch: 6| Step: 8
Training loss: 0.11970704048871994
Validation loss: 1.5236646462512273

Epoch: 6| Step: 9
Training loss: 0.09305649995803833
Validation loss: 1.5616260190163889

Epoch: 6| Step: 10
Training loss: 0.07922345399856567
Validation loss: 1.5541530552730765

Epoch: 6| Step: 11
Training loss: 0.061010971665382385
Validation loss: 1.5424789779929704

Epoch: 6| Step: 12
Training loss: 0.11871789395809174
Validation loss: 1.5331488770823325

Epoch: 6| Step: 13
Training loss: 0.16020157933235168
Validation loss: 1.5466555933798514

Epoch: 544| Step: 0
Training loss: 0.12721090018749237
Validation loss: 1.5579046587790213

Epoch: 6| Step: 1
Training loss: 0.11634988337755203
Validation loss: 1.548629032668247

Epoch: 6| Step: 2
Training loss: 0.09067993611097336
Validation loss: 1.531625924571868

Epoch: 6| Step: 3
Training loss: 0.09837564826011658
Validation loss: 1.4970708483008928

Epoch: 6| Step: 4
Training loss: 0.0832192599773407
Validation loss: 1.4984742646576257

Epoch: 6| Step: 5
Training loss: 0.03644412010908127
Validation loss: 1.5087271877514419

Epoch: 6| Step: 6
Training loss: 0.060914672911167145
Validation loss: 1.5037355461428243

Epoch: 6| Step: 7
Training loss: 0.09522874653339386
Validation loss: 1.4758006680396296

Epoch: 6| Step: 8
Training loss: 0.11116108298301697
Validation loss: 1.4807506158787718

Epoch: 6| Step: 9
Training loss: 0.08366429060697556
Validation loss: 1.4761174891584663

Epoch: 6| Step: 10
Training loss: 0.042733073234558105
Validation loss: 1.4803972859536447

Epoch: 6| Step: 11
Training loss: 0.07242190092802048
Validation loss: 1.4687696349236272

Epoch: 6| Step: 12
Training loss: 0.057716116309165955
Validation loss: 1.4892662802050192

Epoch: 6| Step: 13
Training loss: 0.08886358141899109
Validation loss: 1.480742169964698

Epoch: 545| Step: 0
Training loss: 0.06226503103971481
Validation loss: 1.502822983649469

Epoch: 6| Step: 1
Training loss: 0.1024426817893982
Validation loss: 1.5126369050754014

Epoch: 6| Step: 2
Training loss: 0.049143094569444656
Validation loss: 1.5385156478933109

Epoch: 6| Step: 3
Training loss: 0.10941004008054733
Validation loss: 1.542772860937221

Epoch: 6| Step: 4
Training loss: 0.08532682061195374
Validation loss: 1.5394506492922384

Epoch: 6| Step: 5
Training loss: 0.06839413940906525
Validation loss: 1.5492048699368712

Epoch: 6| Step: 6
Training loss: 0.07322489470243454
Validation loss: 1.580226799493195

Epoch: 6| Step: 7
Training loss: 0.05702473595738411
Validation loss: 1.5366033610477243

Epoch: 6| Step: 8
Training loss: 0.11024616658687592
Validation loss: 1.556697739067898

Epoch: 6| Step: 9
Training loss: 0.043381184339523315
Validation loss: 1.5357275098882697

Epoch: 6| Step: 10
Training loss: 0.0748385488986969
Validation loss: 1.55659701619097

Epoch: 6| Step: 11
Training loss: 0.13448522984981537
Validation loss: 1.5511192237177203

Epoch: 6| Step: 12
Training loss: 0.03844311088323593
Validation loss: 1.5581386704598703

Epoch: 6| Step: 13
Training loss: 0.09702089428901672
Validation loss: 1.5411140662367626

Epoch: 546| Step: 0
Training loss: 0.06560365110635757
Validation loss: 1.5424208551324823

Epoch: 6| Step: 1
Training loss: 0.053837645798921585
Validation loss: 1.5573666339279504

Epoch: 6| Step: 2
Training loss: 0.10845468193292618
Validation loss: 1.574845819063084

Epoch: 6| Step: 3
Training loss: 0.061190854758024216
Validation loss: 1.5378393614163963

Epoch: 6| Step: 4
Training loss: 0.09900974482297897
Validation loss: 1.5301520093794791

Epoch: 6| Step: 5
Training loss: 0.071745365858078
Validation loss: 1.5447163248574862

Epoch: 6| Step: 6
Training loss: 0.08206097781658173
Validation loss: 1.5472895688908075

Epoch: 6| Step: 7
Training loss: 0.10652660578489304
Validation loss: 1.5339794863936722

Epoch: 6| Step: 8
Training loss: 0.14443205296993256
Validation loss: 1.5378615663897606

Epoch: 6| Step: 9
Training loss: 0.09000833332538605
Validation loss: 1.5467491918994534

Epoch: 6| Step: 10
Training loss: 0.09847556054592133
Validation loss: 1.5544864689150164

Epoch: 6| Step: 11
Training loss: 0.07165573537349701
Validation loss: 1.5431268535634524

Epoch: 6| Step: 12
Training loss: 0.08495451509952545
Validation loss: 1.5578366171929143

Epoch: 6| Step: 13
Training loss: 0.035201601684093475
Validation loss: 1.5157652401155042

Epoch: 547| Step: 0
Training loss: 0.0721997618675232
Validation loss: 1.526400560973793

Epoch: 6| Step: 1
Training loss: 0.04363008588552475
Validation loss: 1.5171270511483634

Epoch: 6| Step: 2
Training loss: 0.11256876587867737
Validation loss: 1.5148989282628542

Epoch: 6| Step: 3
Training loss: 0.042122408747673035
Validation loss: 1.532245139921865

Epoch: 6| Step: 4
Training loss: 0.10697279125452042
Validation loss: 1.5243595274545814

Epoch: 6| Step: 5
Training loss: 0.051286086440086365
Validation loss: 1.4903846735595374

Epoch: 6| Step: 6
Training loss: 0.041040755808353424
Validation loss: 1.5109204579425115

Epoch: 6| Step: 7
Training loss: 0.09723319858312607
Validation loss: 1.5057381045433782

Epoch: 6| Step: 8
Training loss: 0.0908789113163948
Validation loss: 1.4981594072875155

Epoch: 6| Step: 9
Training loss: 0.07328210771083832
Validation loss: 1.5141694481654833

Epoch: 6| Step: 10
Training loss: 0.039611540734767914
Validation loss: 1.5399826367696126

Epoch: 6| Step: 11
Training loss: 0.07804195582866669
Validation loss: 1.510116469475531

Epoch: 6| Step: 12
Training loss: 0.06915442645549774
Validation loss: 1.53737291982097

Epoch: 6| Step: 13
Training loss: 0.10565061122179031
Validation loss: 1.5289010732404646

Epoch: 548| Step: 0
Training loss: 0.0705908015370369
Validation loss: 1.521648624891876

Epoch: 6| Step: 1
Training loss: 0.07040819525718689
Validation loss: 1.548786376112251

Epoch: 6| Step: 2
Training loss: 0.053248465061187744
Validation loss: 1.5185800290876819

Epoch: 6| Step: 3
Training loss: 0.0973663330078125
Validation loss: 1.5450582337635819

Epoch: 6| Step: 4
Training loss: 0.05852174758911133
Validation loss: 1.5322506479037705

Epoch: 6| Step: 5
Training loss: 0.07105390727519989
Validation loss: 1.510041089468105

Epoch: 6| Step: 6
Training loss: 0.08174757659435272
Validation loss: 1.5155450156939927

Epoch: 6| Step: 7
Training loss: 0.05655404180288315
Validation loss: 1.5191570533219205

Epoch: 6| Step: 8
Training loss: 0.059297312051057816
Validation loss: 1.5101757485379455

Epoch: 6| Step: 9
Training loss: 0.11831185221672058
Validation loss: 1.522581983638066

Epoch: 6| Step: 10
Training loss: 0.1131756603717804
Validation loss: 1.5297516315214095

Epoch: 6| Step: 11
Training loss: 0.08471640199422836
Validation loss: 1.514655836166874

Epoch: 6| Step: 12
Training loss: 0.08654914796352386
Validation loss: 1.4962084524093135

Epoch: 6| Step: 13
Training loss: 0.054195065051317215
Validation loss: 1.4991126406577326

Epoch: 549| Step: 0
Training loss: 0.06516247242689133
Validation loss: 1.525596543024945

Epoch: 6| Step: 1
Training loss: 0.0649942085146904
Validation loss: 1.544477411495742

Epoch: 6| Step: 2
Training loss: 0.04274175316095352
Validation loss: 1.5346908492426719

Epoch: 6| Step: 3
Training loss: 0.058632828295230865
Validation loss: 1.5283626856342438

Epoch: 6| Step: 4
Training loss: 0.07998856157064438
Validation loss: 1.577705830656072

Epoch: 6| Step: 5
Training loss: 0.09452301263809204
Validation loss: 1.557545236361924

Epoch: 6| Step: 6
Training loss: 0.11093446612358093
Validation loss: 1.5502581032373572

Epoch: 6| Step: 7
Training loss: 0.06646402925252914
Validation loss: 1.5691695187681465

Epoch: 6| Step: 8
Training loss: 0.10403921455144882
Validation loss: 1.5281295737912577

Epoch: 6| Step: 9
Training loss: 0.06300049275159836
Validation loss: 1.5294228164098596

Epoch: 6| Step: 10
Training loss: 0.10203345119953156
Validation loss: 1.5384558887891873

Epoch: 6| Step: 11
Training loss: 0.05912188068032265
Validation loss: 1.516612006771949

Epoch: 6| Step: 12
Training loss: 0.11477352678775787
Validation loss: 1.5382344857338937

Epoch: 6| Step: 13
Training loss: 0.054920654743909836
Validation loss: 1.5145270914159796

Epoch: 550| Step: 0
Training loss: 0.05758289247751236
Validation loss: 1.5277130039789344

Epoch: 6| Step: 1
Training loss: 0.09320925176143646
Validation loss: 1.5564930131358485

Epoch: 6| Step: 2
Training loss: 0.07174801826477051
Validation loss: 1.564946174621582

Epoch: 6| Step: 3
Training loss: 0.12547023594379425
Validation loss: 1.5361154233255694

Epoch: 6| Step: 4
Training loss: 0.12049813568592072
Validation loss: 1.5332720215602587

Epoch: 6| Step: 5
Training loss: 0.10023718327283859
Validation loss: 1.5289156488192979

Epoch: 6| Step: 6
Training loss: 0.0819426029920578
Validation loss: 1.5308108291318339

Epoch: 6| Step: 7
Training loss: 0.09459421783685684
Validation loss: 1.5382256533509941

Epoch: 6| Step: 8
Training loss: 0.2264271378517151
Validation loss: 1.561306498383963

Epoch: 6| Step: 9
Training loss: 0.10996721684932709
Validation loss: 1.5251589487957697

Epoch: 6| Step: 10
Training loss: 0.07488204538822174
Validation loss: 1.5357071994453348

Epoch: 6| Step: 11
Training loss: 0.07784473896026611
Validation loss: 1.4914765986063148

Epoch: 6| Step: 12
Training loss: 0.07576067745685577
Validation loss: 1.4758306036713302

Epoch: 6| Step: 13
Training loss: 0.08746273070573807
Validation loss: 1.5213581362078268

Testing loss: 2.419605286916097
