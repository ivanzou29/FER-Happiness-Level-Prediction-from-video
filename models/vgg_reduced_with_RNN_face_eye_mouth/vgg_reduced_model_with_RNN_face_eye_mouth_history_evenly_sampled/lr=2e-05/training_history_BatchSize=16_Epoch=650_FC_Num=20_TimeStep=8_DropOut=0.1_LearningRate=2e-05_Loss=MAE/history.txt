Epoch: 1| Step: 0
Training loss: 6.242513656616211
Validation loss: 5.266711993884015

Epoch: 6| Step: 1
Training loss: 5.563557147979736
Validation loss: 5.246067877738707

Epoch: 6| Step: 2
Training loss: 5.106739521026611
Validation loss: 5.22781765332786

Epoch: 6| Step: 3
Training loss: 4.715383052825928
Validation loss: 5.209553487839237

Epoch: 6| Step: 4
Training loss: 3.2039294242858887
Validation loss: 5.1901121395890435

Epoch: 6| Step: 5
Training loss: 4.784481048583984
Validation loss: 5.168932771170011

Epoch: 6| Step: 6
Training loss: 4.347984313964844
Validation loss: 5.145098957964169

Epoch: 6| Step: 7
Training loss: 5.012104511260986
Validation loss: 5.117540503060946

Epoch: 6| Step: 8
Training loss: 4.7501678466796875
Validation loss: 5.086469475940992

Epoch: 6| Step: 9
Training loss: 5.70362663269043
Validation loss: 5.050065953244445

Epoch: 6| Step: 10
Training loss: 5.448822975158691
Validation loss: 5.010389866367463

Epoch: 6| Step: 11
Training loss: 4.754234790802002
Validation loss: 4.966302225666661

Epoch: 6| Step: 12
Training loss: 4.569160461425781
Validation loss: 4.919696366915139

Epoch: 6| Step: 13
Training loss: 4.166970729827881
Validation loss: 4.869792379358763

Epoch: 2| Step: 0
Training loss: 5.599985122680664
Validation loss: 4.817992148860808

Epoch: 6| Step: 1
Training loss: 5.038459300994873
Validation loss: 4.766733266974009

Epoch: 6| Step: 2
Training loss: 5.838535785675049
Validation loss: 4.719848186739029

Epoch: 6| Step: 3
Training loss: 3.784425735473633
Validation loss: 4.676941451206003

Epoch: 6| Step: 4
Training loss: 4.572863578796387
Validation loss: 4.638373136520386

Epoch: 6| Step: 5
Training loss: 4.631640434265137
Validation loss: 4.6066350988162466

Epoch: 6| Step: 6
Training loss: 3.8529977798461914
Validation loss: 4.578186763230191

Epoch: 6| Step: 7
Training loss: 3.240504264831543
Validation loss: 4.5537294162217

Epoch: 6| Step: 8
Training loss: 4.029474258422852
Validation loss: 4.5291772657825105

Epoch: 6| Step: 9
Training loss: 4.011488914489746
Validation loss: 4.505324030435213

Epoch: 6| Step: 10
Training loss: 3.4399943351745605
Validation loss: 4.480222799444712

Epoch: 6| Step: 11
Training loss: 4.959316730499268
Validation loss: 4.4542629539325675

Epoch: 6| Step: 12
Training loss: 4.300412654876709
Validation loss: 4.429566542307536

Epoch: 6| Step: 13
Training loss: 4.003477096557617
Validation loss: 4.404867131222961

Epoch: 3| Step: 0
Training loss: 3.4482688903808594
Validation loss: 4.3796193676610145

Epoch: 6| Step: 1
Training loss: 4.049895286560059
Validation loss: 4.354660428980345

Epoch: 6| Step: 2
Training loss: 4.047581672668457
Validation loss: 4.328531798496042

Epoch: 6| Step: 3
Training loss: 4.2306976318359375
Validation loss: 4.304859586941299

Epoch: 6| Step: 4
Training loss: 4.446310043334961
Validation loss: 4.280982109808153

Epoch: 6| Step: 5
Training loss: 4.519312858581543
Validation loss: 4.2558030979607695

Epoch: 6| Step: 6
Training loss: 3.679436206817627
Validation loss: 4.230352063332835

Epoch: 6| Step: 7
Training loss: 4.691007614135742
Validation loss: 4.206417596468362

Epoch: 6| Step: 8
Training loss: 2.5605533123016357
Validation loss: 4.182211060677806

Epoch: 6| Step: 9
Training loss: 3.7304515838623047
Validation loss: 4.1572540498548936

Epoch: 6| Step: 10
Training loss: 4.488997936248779
Validation loss: 4.133277862302719

Epoch: 6| Step: 11
Training loss: 5.341818809509277
Validation loss: 4.1063099061289146

Epoch: 6| Step: 12
Training loss: 3.2045979499816895
Validation loss: 4.0785113714074575

Epoch: 6| Step: 13
Training loss: 4.254921913146973
Validation loss: 4.049088452451972

Epoch: 4| Step: 0
Training loss: 3.8709280490875244
Validation loss: 4.022337139293712

Epoch: 6| Step: 1
Training loss: 3.9389827251434326
Validation loss: 4.000268923339023

Epoch: 6| Step: 2
Training loss: 3.963563919067383
Validation loss: 3.9815714897647982

Epoch: 6| Step: 3
Training loss: 3.989555597305298
Validation loss: 3.9599560614555114

Epoch: 6| Step: 4
Training loss: 3.448615789413452
Validation loss: 3.938736187514438

Epoch: 6| Step: 5
Training loss: 3.8599495887756348
Validation loss: 3.9225484709585867

Epoch: 6| Step: 6
Training loss: 2.8897652626037598
Validation loss: 3.9036952962157545

Epoch: 6| Step: 7
Training loss: 4.3158063888549805
Validation loss: 3.882012874849381

Epoch: 6| Step: 8
Training loss: 3.436457395553589
Validation loss: 3.8636155487388693

Epoch: 6| Step: 9
Training loss: 3.801905393600464
Validation loss: 3.8472336440958004

Epoch: 6| Step: 10
Training loss: 3.3496909141540527
Validation loss: 3.8291060796347995

Epoch: 6| Step: 11
Training loss: 3.4191741943359375
Validation loss: 3.81685632787725

Epoch: 6| Step: 12
Training loss: 4.5298075675964355
Validation loss: 3.7990129378534134

Epoch: 6| Step: 13
Training loss: 4.058794975280762
Validation loss: 3.7804627213426816

Epoch: 5| Step: 0
Training loss: 3.839050769805908
Validation loss: 3.7666379200514926

Epoch: 6| Step: 1
Training loss: 4.006880760192871
Validation loss: 3.755262928624307

Epoch: 6| Step: 2
Training loss: 3.188366413116455
Validation loss: 3.746636667559224

Epoch: 6| Step: 3
Training loss: 4.539525985717773
Validation loss: 3.7319839641612065

Epoch: 6| Step: 4
Training loss: 2.8266353607177734
Validation loss: 3.7140326141029276

Epoch: 6| Step: 5
Training loss: 4.21818733215332
Validation loss: 3.706544306970412

Epoch: 6| Step: 6
Training loss: 3.8408308029174805
Validation loss: 3.691994220979752

Epoch: 6| Step: 7
Training loss: 3.941376209259033
Validation loss: 3.6843559511246218

Epoch: 6| Step: 8
Training loss: 3.9854907989501953
Validation loss: 3.668486064480197

Epoch: 6| Step: 9
Training loss: 2.5360937118530273
Validation loss: 3.6569865621546263

Epoch: 6| Step: 10
Training loss: 1.8946577310562134
Validation loss: 3.6507426026046916

Epoch: 6| Step: 11
Training loss: 4.064608097076416
Validation loss: 3.6388228016514934

Epoch: 6| Step: 12
Training loss: 3.5580105781555176
Validation loss: 3.627821086555399

Epoch: 6| Step: 13
Training loss: 4.0925164222717285
Validation loss: 3.6183426841612785

Epoch: 6| Step: 0
Training loss: 3.5293920040130615
Validation loss: 3.6046149576863935

Epoch: 6| Step: 1
Training loss: 4.069779396057129
Validation loss: 3.592496431002053

Epoch: 6| Step: 2
Training loss: 4.067654132843018
Validation loss: 3.5794572599472536

Epoch: 6| Step: 3
Training loss: 3.7767887115478516
Validation loss: 3.5708375771840415

Epoch: 6| Step: 4
Training loss: 3.132791519165039
Validation loss: 3.561508370983985

Epoch: 6| Step: 5
Training loss: 3.089158296585083
Validation loss: 3.548526156333185

Epoch: 6| Step: 6
Training loss: 2.9517102241516113
Validation loss: 3.5383234331684728

Epoch: 6| Step: 7
Training loss: 3.8756167888641357
Validation loss: 3.5263900474835466

Epoch: 6| Step: 8
Training loss: 4.12933349609375
Validation loss: 3.5237889238583144

Epoch: 6| Step: 9
Training loss: 3.8100008964538574
Validation loss: 3.511165652223813

Epoch: 6| Step: 10
Training loss: 2.7353944778442383
Validation loss: 3.4947917743395736

Epoch: 6| Step: 11
Training loss: 3.2101950645446777
Validation loss: 3.4841660786700506

Epoch: 6| Step: 12
Training loss: 2.9112162590026855
Validation loss: 3.4786294121896066

Epoch: 6| Step: 13
Training loss: 3.100435495376587
Validation loss: 3.4666710720267346

Epoch: 7| Step: 0
Training loss: 3.2704458236694336
Validation loss: 3.456015953453638

Epoch: 6| Step: 1
Training loss: 4.459598541259766
Validation loss: 3.4455593478295112

Epoch: 6| Step: 2
Training loss: 3.3800487518310547
Validation loss: 3.4339362062433714

Epoch: 6| Step: 3
Training loss: 2.917059898376465
Validation loss: 3.427832939291513

Epoch: 6| Step: 4
Training loss: 3.8243746757507324
Validation loss: 3.4178202152252197

Epoch: 6| Step: 5
Training loss: 3.668628215789795
Validation loss: 3.405948746588922

Epoch: 6| Step: 6
Training loss: 3.6594600677490234
Validation loss: 3.3981025834237375

Epoch: 6| Step: 7
Training loss: 3.6168787479400635
Validation loss: 3.387993376742127

Epoch: 6| Step: 8
Training loss: 3.963435173034668
Validation loss: 3.3812681910812215

Epoch: 6| Step: 9
Training loss: 3.3711321353912354
Validation loss: 3.373293463901807

Epoch: 6| Step: 10
Training loss: 2.197911262512207
Validation loss: 3.372803416303409

Epoch: 6| Step: 11
Training loss: 2.4021615982055664
Validation loss: 3.364077780836372

Epoch: 6| Step: 12
Training loss: 2.5884835720062256
Validation loss: 3.3518827576791086

Epoch: 6| Step: 13
Training loss: 3.794233560562134
Validation loss: 3.3400769515704085

Epoch: 8| Step: 0
Training loss: 4.657968044281006
Validation loss: 3.3334222326996508

Epoch: 6| Step: 1
Training loss: 3.322918653488159
Validation loss: 3.3201446943385626

Epoch: 6| Step: 2
Training loss: 4.513832092285156
Validation loss: 3.313115078915832

Epoch: 6| Step: 3
Training loss: 3.479078769683838
Validation loss: 3.3004869927642164

Epoch: 6| Step: 4
Training loss: 3.1901297569274902
Validation loss: 3.2983603400568806

Epoch: 6| Step: 5
Training loss: 3.1451363563537598
Validation loss: 3.2913528898710847

Epoch: 6| Step: 6
Training loss: 2.4580330848693848
Validation loss: 3.273364269605247

Epoch: 6| Step: 7
Training loss: 2.9772768020629883
Validation loss: 3.272159114960701

Epoch: 6| Step: 8
Training loss: 2.1689419746398926
Validation loss: 3.2765628317350983

Epoch: 6| Step: 9
Training loss: 3.3460311889648438
Validation loss: 3.2649149074349353

Epoch: 6| Step: 10
Training loss: 3.7251386642456055
Validation loss: 3.2595167826580744

Epoch: 6| Step: 11
Training loss: 2.6523444652557373
Validation loss: 3.25158445296749

Epoch: 6| Step: 12
Training loss: 2.725837469100952
Validation loss: 3.246550885579919

Epoch: 6| Step: 13
Training loss: 3.4265527725219727
Validation loss: 3.237937229935841

Epoch: 9| Step: 0
Training loss: 4.061886787414551
Validation loss: 3.232339976936258

Epoch: 6| Step: 1
Training loss: 4.334114074707031
Validation loss: 3.2165746368387693

Epoch: 6| Step: 2
Training loss: 3.4986443519592285
Validation loss: 3.209313597730411

Epoch: 6| Step: 3
Training loss: 3.3485870361328125
Validation loss: 3.2025703999304

Epoch: 6| Step: 4
Training loss: 4.024371147155762
Validation loss: 3.1861168722952566

Epoch: 6| Step: 5
Training loss: 3.6982688903808594
Validation loss: 3.179519345683436

Epoch: 6| Step: 6
Training loss: 2.8139638900756836
Validation loss: 3.1738574427943074

Epoch: 6| Step: 7
Training loss: 2.4805376529693604
Validation loss: 3.1680274317341466

Epoch: 6| Step: 8
Training loss: 3.2296628952026367
Validation loss: 3.1631931028058453

Epoch: 6| Step: 9
Training loss: 2.7343125343322754
Validation loss: 3.153777189152215

Epoch: 6| Step: 10
Training loss: 1.4181561470031738
Validation loss: 3.1468240317477973

Epoch: 6| Step: 11
Training loss: 4.072869777679443
Validation loss: 3.1394568720171527

Epoch: 6| Step: 12
Training loss: 1.7413287162780762
Validation loss: 3.1330627164533063

Epoch: 6| Step: 13
Training loss: 3.2655656337738037
Validation loss: 3.1286419335231987

Epoch: 10| Step: 0
Training loss: 2.8708744049072266
Validation loss: 3.1248552876134075

Epoch: 6| Step: 1
Training loss: 3.2041990756988525
Validation loss: 3.1213525008129817

Epoch: 6| Step: 2
Training loss: 2.72653865814209
Validation loss: 3.115790936254686

Epoch: 6| Step: 3
Training loss: 2.532805919647217
Validation loss: 3.109177997035365

Epoch: 6| Step: 4
Training loss: 2.6070656776428223
Validation loss: 3.1064744072575725

Epoch: 6| Step: 5
Training loss: 2.7103123664855957
Validation loss: 3.10080551075679

Epoch: 6| Step: 6
Training loss: 3.645385265350342
Validation loss: 3.0944047897092757

Epoch: 6| Step: 7
Training loss: 3.657719612121582
Validation loss: 3.088196118672689

Epoch: 6| Step: 8
Training loss: 3.8368592262268066
Validation loss: 3.083612242052632

Epoch: 6| Step: 9
Training loss: 3.046250343322754
Validation loss: 3.0772338759514595

Epoch: 6| Step: 10
Training loss: 2.466481924057007
Validation loss: 3.0739272948234313

Epoch: 6| Step: 11
Training loss: 3.107497215270996
Validation loss: 3.0618411648658013

Epoch: 6| Step: 12
Training loss: 3.7425320148468018
Validation loss: 3.0616200816246772

Epoch: 6| Step: 13
Training loss: 3.905531167984009
Validation loss: 3.06335925286816

Epoch: 11| Step: 0
Training loss: 2.637129306793213
Validation loss: 3.0561063546006397

Epoch: 6| Step: 1
Training loss: 3.07098388671875
Validation loss: 3.0527217413789485

Epoch: 6| Step: 2
Training loss: 3.438199281692505
Validation loss: 3.0438406287982898

Epoch: 6| Step: 3
Training loss: 3.909369707107544
Validation loss: 3.033718033503461

Epoch: 6| Step: 4
Training loss: 4.025395393371582
Validation loss: 3.0305135583364837

Epoch: 6| Step: 5
Training loss: 2.785203456878662
Validation loss: 3.0269221336610856

Epoch: 6| Step: 6
Training loss: 2.6550824642181396
Validation loss: 3.0183537903652398

Epoch: 6| Step: 7
Training loss: 2.689866065979004
Validation loss: 3.0143619391225998

Epoch: 6| Step: 8
Training loss: 3.2141470909118652
Validation loss: 3.008624053770496

Epoch: 6| Step: 9
Training loss: 2.901597499847412
Validation loss: 3.0044217519862677

Epoch: 6| Step: 10
Training loss: 2.9202799797058105
Validation loss: 3.0004909166725735

Epoch: 6| Step: 11
Training loss: 3.444816827774048
Validation loss: 2.9959114110598

Epoch: 6| Step: 12
Training loss: 2.184555768966675
Validation loss: 2.984079478889383

Epoch: 6| Step: 13
Training loss: 3.3700242042541504
Validation loss: 2.9858069112223964

Epoch: 12| Step: 0
Training loss: 1.9813389778137207
Validation loss: 2.9866991760910198

Epoch: 6| Step: 1
Training loss: 4.068507671356201
Validation loss: 2.9730844061861754

Epoch: 6| Step: 2
Training loss: 4.304250717163086
Validation loss: 2.9779724049311813

Epoch: 6| Step: 3
Training loss: 2.217385768890381
Validation loss: 2.9782579227160384

Epoch: 6| Step: 4
Training loss: 2.5413124561309814
Validation loss: 2.974674637599658

Epoch: 6| Step: 5
Training loss: 2.799290418624878
Validation loss: 2.9627627198414137

Epoch: 6| Step: 6
Training loss: 3.0609748363494873
Validation loss: 2.9565216110598658

Epoch: 6| Step: 7
Training loss: 4.045650959014893
Validation loss: 2.949992133725074

Epoch: 6| Step: 8
Training loss: 2.6895055770874023
Validation loss: 2.9462740831477667

Epoch: 6| Step: 9
Training loss: 3.3491153717041016
Validation loss: 2.9543048643296763

Epoch: 6| Step: 10
Training loss: 2.7257673740386963
Validation loss: 2.9404075863540813

Epoch: 6| Step: 11
Training loss: 3.0112719535827637
Validation loss: 2.9399698267700853

Epoch: 6| Step: 12
Training loss: 3.152838706970215
Validation loss: 2.9730491202364684

Epoch: 6| Step: 13
Training loss: 2.286835193634033
Validation loss: 2.9677646621581046

Epoch: 13| Step: 0
Training loss: 2.969827175140381
Validation loss: 2.961191172240883

Epoch: 6| Step: 1
Training loss: 3.4142544269561768
Validation loss: 2.9573337980495986

Epoch: 6| Step: 2
Training loss: 2.5258231163024902
Validation loss: 2.941011127605233

Epoch: 6| Step: 3
Training loss: 3.2454028129577637
Validation loss: 2.936111903959705

Epoch: 6| Step: 4
Training loss: 2.450115203857422
Validation loss: 2.9231654213320826

Epoch: 6| Step: 5
Training loss: 3.044086217880249
Validation loss: 2.923775444748581

Epoch: 6| Step: 6
Training loss: 2.5692975521087646
Validation loss: 2.9272476447525846

Epoch: 6| Step: 7
Training loss: 3.5179247856140137
Validation loss: 2.9484537929616947

Epoch: 6| Step: 8
Training loss: 3.2469944953918457
Validation loss: 2.9117636398602555

Epoch: 6| Step: 9
Training loss: 3.4427027702331543
Validation loss: 2.9016524130298245

Epoch: 6| Step: 10
Training loss: 3.501720905303955
Validation loss: 2.9082171532415573

Epoch: 6| Step: 11
Training loss: 2.917670965194702
Validation loss: 2.909017344956757

Epoch: 6| Step: 12
Training loss: 2.7390785217285156
Validation loss: 2.907006299623879

Epoch: 6| Step: 13
Training loss: 2.4303746223449707
Validation loss: 2.9081828594207764

Epoch: 14| Step: 0
Training loss: 2.8051347732543945
Validation loss: 2.915055690273162

Epoch: 6| Step: 1
Training loss: 3.678912878036499
Validation loss: 2.9005154794262302

Epoch: 6| Step: 2
Training loss: 2.767915725708008
Validation loss: 2.8823085087601856

Epoch: 6| Step: 3
Training loss: 3.121325969696045
Validation loss: 2.863984433553552

Epoch: 6| Step: 4
Training loss: 3.191084384918213
Validation loss: 2.8517303312978437

Epoch: 6| Step: 5
Training loss: 2.886214256286621
Validation loss: 2.8607081623487574

Epoch: 6| Step: 6
Training loss: 2.897054672241211
Validation loss: 2.847228470668998

Epoch: 6| Step: 7
Training loss: 3.1663293838500977
Validation loss: 2.873776205124394

Epoch: 6| Step: 8
Training loss: 2.55714750289917
Validation loss: 2.8520917097727456

Epoch: 6| Step: 9
Training loss: 3.2557883262634277
Validation loss: 2.8449682881755214

Epoch: 6| Step: 10
Training loss: 3.3926453590393066
Validation loss: 2.842976600893082

Epoch: 6| Step: 11
Training loss: 2.9262964725494385
Validation loss: 2.8422416692139

Epoch: 6| Step: 12
Training loss: 2.038113594055176
Validation loss: 2.8442105529128865

Epoch: 6| Step: 13
Training loss: 2.97468638420105
Validation loss: 2.842349595921014

Epoch: 15| Step: 0
Training loss: 2.7262306213378906
Validation loss: 2.845713505180933

Epoch: 6| Step: 1
Training loss: 2.9946036338806152
Validation loss: 2.8419750531514487

Epoch: 6| Step: 2
Training loss: 2.6126151084899902
Validation loss: 2.843181474234468

Epoch: 6| Step: 3
Training loss: 3.1690683364868164
Validation loss: 2.834575440293999

Epoch: 6| Step: 4
Training loss: 2.942371368408203
Validation loss: 2.8368857445255404

Epoch: 6| Step: 5
Training loss: 3.6641793251037598
Validation loss: 2.837630133475027

Epoch: 6| Step: 6
Training loss: 2.2030701637268066
Validation loss: 2.834678578120406

Epoch: 6| Step: 7
Training loss: 3.0556888580322266
Validation loss: 2.827119404269803

Epoch: 6| Step: 8
Training loss: 2.765273332595825
Validation loss: 2.820685096966323

Epoch: 6| Step: 9
Training loss: 3.86061954498291
Validation loss: 2.8093513622078845

Epoch: 6| Step: 10
Training loss: 2.7318215370178223
Validation loss: 2.8047444307675926

Epoch: 6| Step: 11
Training loss: 3.371724843978882
Validation loss: 2.8037230045564714

Epoch: 6| Step: 12
Training loss: 2.1087112426757812
Validation loss: 2.802155786944974

Epoch: 6| Step: 13
Training loss: 3.11334490776062
Validation loss: 2.790311905645555

Epoch: 16| Step: 0
Training loss: 3.2339587211608887
Validation loss: 2.7879990659734255

Epoch: 6| Step: 1
Training loss: 2.798863410949707
Validation loss: 2.777781263474495

Epoch: 6| Step: 2
Training loss: 2.90598726272583
Validation loss: 2.778302707979756

Epoch: 6| Step: 3
Training loss: 3.6102042198181152
Validation loss: 2.777189900798182

Epoch: 6| Step: 4
Training loss: 2.870255708694458
Validation loss: 2.774608330060077

Epoch: 6| Step: 5
Training loss: 2.5568315982818604
Validation loss: 2.771480183447561

Epoch: 6| Step: 6
Training loss: 1.8726081848144531
Validation loss: 2.766926873114801

Epoch: 6| Step: 7
Training loss: 2.677762508392334
Validation loss: 2.765653012901224

Epoch: 6| Step: 8
Training loss: 2.7978224754333496
Validation loss: 2.7563847444390737

Epoch: 6| Step: 9
Training loss: 3.0353784561157227
Validation loss: 2.75285364479147

Epoch: 6| Step: 10
Training loss: 2.8129286766052246
Validation loss: 2.751758139620545

Epoch: 6| Step: 11
Training loss: 3.7167789936065674
Validation loss: 2.7561483049905426

Epoch: 6| Step: 12
Training loss: 3.4953529834747314
Validation loss: 2.7523202870481756

Epoch: 6| Step: 13
Training loss: 1.935194492340088
Validation loss: 2.7530189047577562

Epoch: 17| Step: 0
Training loss: 2.3955867290496826
Validation loss: 2.7765229209776847

Epoch: 6| Step: 1
Training loss: 3.0356390476226807
Validation loss: 2.7563273188888386

Epoch: 6| Step: 2
Training loss: 2.6165103912353516
Validation loss: 2.740107515806793

Epoch: 6| Step: 3
Training loss: 2.6258156299591064
Validation loss: 2.7445234585833806

Epoch: 6| Step: 4
Training loss: 2.289217710494995
Validation loss: 2.753952551913518

Epoch: 6| Step: 5
Training loss: 3.4545490741729736
Validation loss: 2.7589347618882374

Epoch: 6| Step: 6
Training loss: 3.6720266342163086
Validation loss: 2.763318254101661

Epoch: 6| Step: 7
Training loss: 3.889888286590576
Validation loss: 2.766198406937302

Epoch: 6| Step: 8
Training loss: 2.8922934532165527
Validation loss: 2.762029911882134

Epoch: 6| Step: 9
Training loss: 2.652759075164795
Validation loss: 2.7556945611071844

Epoch: 6| Step: 10
Training loss: 2.1997976303100586
Validation loss: 2.7506900013134046

Epoch: 6| Step: 11
Training loss: 3.7380213737487793
Validation loss: 2.7461317328996557

Epoch: 6| Step: 12
Training loss: 2.652895450592041
Validation loss: 2.743699848010976

Epoch: 6| Step: 13
Training loss: 2.3619532585144043
Validation loss: 2.7450872339228147

Epoch: 18| Step: 0
Training loss: 2.7891387939453125
Validation loss: 2.7412820298184633

Epoch: 6| Step: 1
Training loss: 3.028310537338257
Validation loss: 2.7403147835885324

Epoch: 6| Step: 2
Training loss: 2.5106992721557617
Validation loss: 2.7367175009942826

Epoch: 6| Step: 3
Training loss: 3.0294344425201416
Validation loss: 2.7336865599437425

Epoch: 6| Step: 4
Training loss: 3.171621561050415
Validation loss: 2.730944541192824

Epoch: 6| Step: 5
Training loss: 2.341856002807617
Validation loss: 2.7228460850254184

Epoch: 6| Step: 6
Training loss: 2.793943166732788
Validation loss: 2.720697349117648

Epoch: 6| Step: 7
Training loss: 3.401827335357666
Validation loss: 2.714461959818358

Epoch: 6| Step: 8
Training loss: 3.2277445793151855
Validation loss: 2.7140283148775817

Epoch: 6| Step: 9
Training loss: 3.139430284500122
Validation loss: 2.70810612299109

Epoch: 6| Step: 10
Training loss: 2.551722526550293
Validation loss: 2.7016524602008123

Epoch: 6| Step: 11
Training loss: 3.239805221557617
Validation loss: 2.6978015104929605

Epoch: 6| Step: 12
Training loss: 2.7724204063415527
Validation loss: 2.6953142073846634

Epoch: 6| Step: 13
Training loss: 1.9485918283462524
Validation loss: 2.6934341435791342

Epoch: 19| Step: 0
Training loss: 2.6529788970947266
Validation loss: 2.691816222283148

Epoch: 6| Step: 1
Training loss: 3.1329925060272217
Validation loss: 2.6921605756205897

Epoch: 6| Step: 2
Training loss: 3.2221996784210205
Validation loss: 2.6931828068148707

Epoch: 6| Step: 3
Training loss: 3.2918953895568848
Validation loss: 2.6838947931925454

Epoch: 6| Step: 4
Training loss: 2.930912494659424
Validation loss: 2.676848575633059

Epoch: 6| Step: 5
Training loss: 2.4866697788238525
Validation loss: 2.67738760927672

Epoch: 6| Step: 6
Training loss: 3.2383275032043457
Validation loss: 2.6772727581762497

Epoch: 6| Step: 7
Training loss: 2.969642162322998
Validation loss: 2.6709950072790987

Epoch: 6| Step: 8
Training loss: 2.616936683654785
Validation loss: 2.6704485185684694

Epoch: 6| Step: 9
Training loss: 2.459834575653076
Validation loss: 2.6689168740344305

Epoch: 6| Step: 10
Training loss: 2.602515697479248
Validation loss: 2.667745356918663

Epoch: 6| Step: 11
Training loss: 2.4949769973754883
Validation loss: 2.666233193489813

Epoch: 6| Step: 12
Training loss: 3.0129470825195312
Validation loss: 2.6657359471885105

Epoch: 6| Step: 13
Training loss: 2.835981607437134
Validation loss: 2.66479504236611

Epoch: 20| Step: 0
Training loss: 3.636881113052368
Validation loss: 2.6610048022321475

Epoch: 6| Step: 1
Training loss: 2.838813304901123
Validation loss: 2.6549187501271567

Epoch: 6| Step: 2
Training loss: 1.91672945022583
Validation loss: 2.651737666899158

Epoch: 6| Step: 3
Training loss: 2.6771469116210938
Validation loss: 2.654273384360857

Epoch: 6| Step: 4
Training loss: 2.634967565536499
Validation loss: 2.6511811184626755

Epoch: 6| Step: 5
Training loss: 2.604726791381836
Validation loss: 2.649206475545001

Epoch: 6| Step: 6
Training loss: 2.555575370788574
Validation loss: 2.649815038968158

Epoch: 6| Step: 7
Training loss: 3.494980812072754
Validation loss: 2.6448954971887733

Epoch: 6| Step: 8
Training loss: 2.9643571376800537
Validation loss: 2.6419011085264144

Epoch: 6| Step: 9
Training loss: 2.282158851623535
Validation loss: 2.6438121667472263

Epoch: 6| Step: 10
Training loss: 2.978148937225342
Validation loss: 2.6482811948304534

Epoch: 6| Step: 11
Training loss: 3.292476177215576
Validation loss: 2.6751937379119215

Epoch: 6| Step: 12
Training loss: 3.5229105949401855
Validation loss: 2.7010210098758822

Epoch: 6| Step: 13
Training loss: 1.8483788967132568
Validation loss: 2.6444327574904247

Epoch: 21| Step: 0
Training loss: 2.2749240398406982
Validation loss: 2.6368189242578324

Epoch: 6| Step: 1
Training loss: 3.632902145385742
Validation loss: 2.6378278783572617

Epoch: 6| Step: 2
Training loss: 3.409083366394043
Validation loss: 2.6427999388787056

Epoch: 6| Step: 3
Training loss: 3.316899299621582
Validation loss: 2.6450145577871673

Epoch: 6| Step: 4
Training loss: 2.174685001373291
Validation loss: 2.639870748724989

Epoch: 6| Step: 5
Training loss: 2.2821717262268066
Validation loss: 2.6395555029633226

Epoch: 6| Step: 6
Training loss: 3.2457275390625
Validation loss: 2.643434370717695

Epoch: 6| Step: 7
Training loss: 3.210047721862793
Validation loss: 2.6408252767337266

Epoch: 6| Step: 8
Training loss: 2.9499552249908447
Validation loss: 2.6532659915185746

Epoch: 6| Step: 9
Training loss: 2.4995687007904053
Validation loss: 2.656203641686388

Epoch: 6| Step: 10
Training loss: 2.08322811126709
Validation loss: 2.662982392054732

Epoch: 6| Step: 11
Training loss: 2.774913787841797
Validation loss: 2.642360802619688

Epoch: 6| Step: 12
Training loss: 2.9007649421691895
Validation loss: 2.6301189648207797

Epoch: 6| Step: 13
Training loss: 2.8158090114593506
Validation loss: 2.6426482713350685

Epoch: 22| Step: 0
Training loss: 2.1664819717407227
Validation loss: 2.632680341761599

Epoch: 6| Step: 1
Training loss: 2.924886703491211
Validation loss: 2.624122747810938

Epoch: 6| Step: 2
Training loss: 3.295039176940918
Validation loss: 2.6259544254631124

Epoch: 6| Step: 3
Training loss: 2.736175537109375
Validation loss: 2.62938960905998

Epoch: 6| Step: 4
Training loss: 2.525435209274292
Validation loss: 2.621431032816569

Epoch: 6| Step: 5
Training loss: 3.051002264022827
Validation loss: 2.614088894218527

Epoch: 6| Step: 6
Training loss: 2.922170639038086
Validation loss: 2.6150441349193616

Epoch: 6| Step: 7
Training loss: 2.6094770431518555
Validation loss: 2.6144393259479153

Epoch: 6| Step: 8
Training loss: 3.70261549949646
Validation loss: 2.615009856480424

Epoch: 6| Step: 9
Training loss: 2.5005998611450195
Validation loss: 2.613561266212053

Epoch: 6| Step: 10
Training loss: 3.1101419925689697
Validation loss: 2.608257867956674

Epoch: 6| Step: 11
Training loss: 2.5651166439056396
Validation loss: 2.6043335776175223

Epoch: 6| Step: 12
Training loss: 2.583749294281006
Validation loss: 2.6071012276475147

Epoch: 6| Step: 13
Training loss: 2.4281530380249023
Validation loss: 2.6008329801661993

Epoch: 23| Step: 0
Training loss: 3.3016469478607178
Validation loss: 2.5972017113880446

Epoch: 6| Step: 1
Training loss: 2.91719913482666
Validation loss: 2.595679021650745

Epoch: 6| Step: 2
Training loss: 2.4005513191223145
Validation loss: 2.5965082337779384

Epoch: 6| Step: 3
Training loss: 2.650315284729004
Validation loss: 2.596060532395558

Epoch: 6| Step: 4
Training loss: 3.1312308311462402
Validation loss: 2.5873328998524654

Epoch: 6| Step: 5
Training loss: 2.892577648162842
Validation loss: 2.585183625580162

Epoch: 6| Step: 6
Training loss: 2.9909815788269043
Validation loss: 2.5908323641746276

Epoch: 6| Step: 7
Training loss: 2.906599998474121
Validation loss: 2.58815267521848

Epoch: 6| Step: 8
Training loss: 1.9768202304840088
Validation loss: 2.591804265975952

Epoch: 6| Step: 9
Training loss: 3.8701348304748535
Validation loss: 2.58664878209432

Epoch: 6| Step: 10
Training loss: 2.057746648788452
Validation loss: 2.5829651894107943

Epoch: 6| Step: 11
Training loss: 2.649596691131592
Validation loss: 2.5724971653312765

Epoch: 6| Step: 12
Training loss: 2.678652763366699
Validation loss: 2.5711796206812703

Epoch: 6| Step: 13
Training loss: 2.3325581550598145
Validation loss: 2.57567863054173

Epoch: 24| Step: 0
Training loss: 3.1628305912017822
Validation loss: 2.606342138782624

Epoch: 6| Step: 1
Training loss: 3.160569190979004
Validation loss: 2.5798680731045303

Epoch: 6| Step: 2
Training loss: 2.9000797271728516
Validation loss: 2.573180280705934

Epoch: 6| Step: 3
Training loss: 2.900865316390991
Validation loss: 2.5690168411500993

Epoch: 6| Step: 4
Training loss: 2.9411661624908447
Validation loss: 2.566421380607031

Epoch: 6| Step: 5
Training loss: 3.8480353355407715
Validation loss: 2.5645408989280782

Epoch: 6| Step: 6
Training loss: 3.0806198120117188
Validation loss: 2.563138005554035

Epoch: 6| Step: 7
Training loss: 2.5401062965393066
Validation loss: 2.562698156602921

Epoch: 6| Step: 8
Training loss: 2.0156517028808594
Validation loss: 2.5649733979214906

Epoch: 6| Step: 9
Training loss: 2.2219135761260986
Validation loss: 2.5647878685305194

Epoch: 6| Step: 10
Training loss: 2.368720531463623
Validation loss: 2.559263301152055

Epoch: 6| Step: 11
Training loss: 2.492527961730957
Validation loss: 2.5620902994627595

Epoch: 6| Step: 12
Training loss: 2.241652011871338
Validation loss: 2.5706726094727874

Epoch: 6| Step: 13
Training loss: 3.063014030456543
Validation loss: 2.5780339523028304

Epoch: 25| Step: 0
Training loss: 2.67130708694458
Validation loss: 2.5555675388664327

Epoch: 6| Step: 1
Training loss: 2.335071563720703
Validation loss: 2.560983814218993

Epoch: 6| Step: 2
Training loss: 2.1632986068725586
Validation loss: 2.596184484420284

Epoch: 6| Step: 3
Training loss: 2.8710989952087402
Validation loss: 2.672305002007433

Epoch: 6| Step: 4
Training loss: 3.707428216934204
Validation loss: 2.707437415276804

Epoch: 6| Step: 5
Training loss: 2.478501319885254
Validation loss: 2.625381618417719

Epoch: 6| Step: 6
Training loss: 3.062793493270874
Validation loss: 2.5709726477182038

Epoch: 6| Step: 7
Training loss: 2.2588417530059814
Validation loss: 2.568391410253381

Epoch: 6| Step: 8
Training loss: 2.3818578720092773
Validation loss: 2.578401022059943

Epoch: 6| Step: 9
Training loss: 3.377890110015869
Validation loss: 2.5955093932408158

Epoch: 6| Step: 10
Training loss: 2.601841688156128
Validation loss: 2.607846083179597

Epoch: 6| Step: 11
Training loss: 3.193481922149658
Validation loss: 2.5756448648309194

Epoch: 6| Step: 12
Training loss: 3.444369316101074
Validation loss: 2.554320876316358

Epoch: 6| Step: 13
Training loss: 2.261714220046997
Validation loss: 2.5447238055608605

Epoch: 26| Step: 0
Training loss: 1.8437608480453491
Validation loss: 2.5476054017261793

Epoch: 6| Step: 1
Training loss: 3.021169424057007
Validation loss: 2.5749832199465845

Epoch: 6| Step: 2
Training loss: 2.775484323501587
Validation loss: 2.6252109260969263

Epoch: 6| Step: 3
Training loss: 2.008104085922241
Validation loss: 2.638995588466685

Epoch: 6| Step: 4
Training loss: 2.4730992317199707
Validation loss: 2.614597164174562

Epoch: 6| Step: 5
Training loss: 2.7640440464019775
Validation loss: 2.626683949142374

Epoch: 6| Step: 6
Training loss: 3.2403745651245117
Validation loss: 2.6304336388905845

Epoch: 6| Step: 7
Training loss: 2.6861283779144287
Validation loss: 2.59243373076121

Epoch: 6| Step: 8
Training loss: 2.9183545112609863
Validation loss: 2.5813548949456986

Epoch: 6| Step: 9
Training loss: 2.779359817504883
Validation loss: 2.559747137049193

Epoch: 6| Step: 10
Training loss: 2.548459053039551
Validation loss: 2.5426336232052056

Epoch: 6| Step: 11
Training loss: 2.841048002243042
Validation loss: 2.5625315917435514

Epoch: 6| Step: 12
Training loss: 3.544858694076538
Validation loss: 2.6089097915157193

Epoch: 6| Step: 13
Training loss: 3.8531064987182617
Validation loss: 2.605008368851036

Epoch: 27| Step: 0
Training loss: 2.3763699531555176
Validation loss: 2.5556434431383686

Epoch: 6| Step: 1
Training loss: 2.780457019805908
Validation loss: 2.540631330141457

Epoch: 6| Step: 2
Training loss: 2.8847837448120117
Validation loss: 2.5771873792012534

Epoch: 6| Step: 3
Training loss: 3.443344831466675
Validation loss: 2.6346034747298046

Epoch: 6| Step: 4
Training loss: 2.7793726921081543
Validation loss: 2.6522573501833024

Epoch: 6| Step: 5
Training loss: 2.292281150817871
Validation loss: 2.5938788819056686

Epoch: 6| Step: 6
Training loss: 3.1253533363342285
Validation loss: 2.5520217495579876

Epoch: 6| Step: 7
Training loss: 2.779247760772705
Validation loss: 2.5303314706330657

Epoch: 6| Step: 8
Training loss: 2.7588181495666504
Validation loss: 2.536355633889475

Epoch: 6| Step: 9
Training loss: 3.3804333209991455
Validation loss: 2.5443268386266564

Epoch: 6| Step: 10
Training loss: 1.7546926736831665
Validation loss: 2.5461366996970227

Epoch: 6| Step: 11
Training loss: 2.542008876800537
Validation loss: 2.5564104408346195

Epoch: 6| Step: 12
Training loss: 2.7058463096618652
Validation loss: 2.559690672864196

Epoch: 6| Step: 13
Training loss: 3.4405064582824707
Validation loss: 2.5491146861865954

Epoch: 28| Step: 0
Training loss: 2.587038993835449
Validation loss: 2.5286771558946177

Epoch: 6| Step: 1
Training loss: 2.0349977016448975
Validation loss: 2.5199122633985294

Epoch: 6| Step: 2
Training loss: 3.531731605529785
Validation loss: 2.522000297423332

Epoch: 6| Step: 3
Training loss: 1.643572449684143
Validation loss: 2.531393112674836

Epoch: 6| Step: 4
Training loss: 2.626215934753418
Validation loss: 2.5463566856999553

Epoch: 6| Step: 5
Training loss: 2.9379727840423584
Validation loss: 2.550897195775022

Epoch: 6| Step: 6
Training loss: 3.2307682037353516
Validation loss: 2.544203183984244

Epoch: 6| Step: 7
Training loss: 2.286949634552002
Validation loss: 2.542446849166706

Epoch: 6| Step: 8
Training loss: 2.6506025791168213
Validation loss: 2.5487615011071645

Epoch: 6| Step: 9
Training loss: 2.2411792278289795
Validation loss: 2.5495032982159684

Epoch: 6| Step: 10
Training loss: 3.103372097015381
Validation loss: 2.548298376862721

Epoch: 6| Step: 11
Training loss: 3.332986354827881
Validation loss: 2.522213446196689

Epoch: 6| Step: 12
Training loss: 3.054332733154297
Validation loss: 2.513528723870554

Epoch: 6| Step: 13
Training loss: 2.833693504333496
Validation loss: 2.5119529975357877

Epoch: 29| Step: 0
Training loss: 2.294605255126953
Validation loss: 2.5074973285839124

Epoch: 6| Step: 1
Training loss: 2.9159679412841797
Validation loss: 2.5022966784815632

Epoch: 6| Step: 2
Training loss: 2.3207054138183594
Validation loss: 2.503914645923081

Epoch: 6| Step: 3
Training loss: 3.4229536056518555
Validation loss: 2.502679717156195

Epoch: 6| Step: 4
Training loss: 2.7147045135498047
Validation loss: 2.5002226726983183

Epoch: 6| Step: 5
Training loss: 2.8549036979675293
Validation loss: 2.5039676286840953

Epoch: 6| Step: 6
Training loss: 2.5669186115264893
Validation loss: 2.5051649488428587

Epoch: 6| Step: 7
Training loss: 2.3762359619140625
Validation loss: 2.5009785570124143

Epoch: 6| Step: 8
Training loss: 3.3646438121795654
Validation loss: 2.4994130032036894

Epoch: 6| Step: 9
Training loss: 2.8658695220947266
Validation loss: 2.5125162140015633

Epoch: 6| Step: 10
Training loss: 2.2626476287841797
Validation loss: 2.5269980430603027

Epoch: 6| Step: 11
Training loss: 2.895547389984131
Validation loss: 2.5407448084123674

Epoch: 6| Step: 12
Training loss: 2.9095568656921387
Validation loss: 2.5363466714018132

Epoch: 6| Step: 13
Training loss: 1.9154820442199707
Validation loss: 2.5159363695370254

Epoch: 30| Step: 0
Training loss: 2.900496244430542
Validation loss: 2.5086604472129577

Epoch: 6| Step: 1
Training loss: 2.881161689758301
Validation loss: 2.497672119448262

Epoch: 6| Step: 2
Training loss: 3.275261878967285
Validation loss: 2.4948896938754666

Epoch: 6| Step: 3
Training loss: 2.350155830383301
Validation loss: 2.494923771068614

Epoch: 6| Step: 4
Training loss: 2.7837557792663574
Validation loss: 2.501322272003338

Epoch: 6| Step: 5
Training loss: 3.019543170928955
Validation loss: 2.509268537644417

Epoch: 6| Step: 6
Training loss: 3.3062915802001953
Validation loss: 2.4928017585508284

Epoch: 6| Step: 7
Training loss: 3.0274596214294434
Validation loss: 2.4920413917110813

Epoch: 6| Step: 8
Training loss: 2.772996425628662
Validation loss: 2.503331263860067

Epoch: 6| Step: 9
Training loss: 2.52107572555542
Validation loss: 2.539063210128456

Epoch: 6| Step: 10
Training loss: 2.1150219440460205
Validation loss: 2.5997656109512493

Epoch: 6| Step: 11
Training loss: 1.8703070878982544
Validation loss: 2.601936965860346

Epoch: 6| Step: 12
Training loss: 2.58091402053833
Validation loss: 2.564320907797865

Epoch: 6| Step: 13
Training loss: 2.4571447372436523
Validation loss: 2.528899851665702

Epoch: 31| Step: 0
Training loss: 2.998748302459717
Validation loss: 2.512336782229844

Epoch: 6| Step: 1
Training loss: 2.2854995727539062
Validation loss: 2.5001325017662457

Epoch: 6| Step: 2
Training loss: 3.4377079010009766
Validation loss: 2.4902912288583736

Epoch: 6| Step: 3
Training loss: 3.0093135833740234
Validation loss: 2.4834627182252946

Epoch: 6| Step: 4
Training loss: 3.0672216415405273
Validation loss: 2.4770383014473865

Epoch: 6| Step: 5
Training loss: 2.576397180557251
Validation loss: 2.481183700664069

Epoch: 6| Step: 6
Training loss: 2.2669777870178223
Validation loss: 2.4842699984068513

Epoch: 6| Step: 7
Training loss: 2.5706050395965576
Validation loss: 2.4836330926546486

Epoch: 6| Step: 8
Training loss: 2.8158035278320312
Validation loss: 2.480550294281334

Epoch: 6| Step: 9
Training loss: 2.3943095207214355
Validation loss: 2.4792662935872234

Epoch: 6| Step: 10
Training loss: 2.79573917388916
Validation loss: 2.473167597606618

Epoch: 6| Step: 11
Training loss: 2.2764692306518555
Validation loss: 2.4828303014078448

Epoch: 6| Step: 12
Training loss: 2.9538955688476562
Validation loss: 2.492251847379951

Epoch: 6| Step: 13
Training loss: 2.2301623821258545
Validation loss: 2.503166616603892

Epoch: 32| Step: 0
Training loss: 2.5298378467559814
Validation loss: 2.5027404882574595

Epoch: 6| Step: 1
Training loss: 2.76395583152771
Validation loss: 2.5124271787622923

Epoch: 6| Step: 2
Training loss: 2.3596417903900146
Validation loss: 2.5162108380307435

Epoch: 6| Step: 3
Training loss: 2.893697738647461
Validation loss: 2.540409526517314

Epoch: 6| Step: 4
Training loss: 2.8110721111297607
Validation loss: 2.483665448363109

Epoch: 6| Step: 5
Training loss: 2.823885679244995
Validation loss: 2.4726761028330815

Epoch: 6| Step: 6
Training loss: 2.44525146484375
Validation loss: 2.473334845676217

Epoch: 6| Step: 7
Training loss: 2.325408458709717
Validation loss: 2.478400153498496

Epoch: 6| Step: 8
Training loss: 3.228731155395508
Validation loss: 2.490574795712707

Epoch: 6| Step: 9
Training loss: 2.9461123943328857
Validation loss: 2.4829311960486957

Epoch: 6| Step: 10
Training loss: 3.0147650241851807
Validation loss: 2.4766393656371744

Epoch: 6| Step: 11
Training loss: 2.422405481338501
Validation loss: 2.4645033036508868

Epoch: 6| Step: 12
Training loss: 2.3602209091186523
Validation loss: 2.467622785158055

Epoch: 6| Step: 13
Training loss: 3.2134897708892822
Validation loss: 2.49044402440389

Epoch: 33| Step: 0
Training loss: 2.2014498710632324
Validation loss: 2.501977579568022

Epoch: 6| Step: 1
Training loss: 2.322066307067871
Validation loss: 2.515304639775266

Epoch: 6| Step: 2
Training loss: 3.146862268447876
Validation loss: 2.4995217220757597

Epoch: 6| Step: 3
Training loss: 3.0314903259277344
Validation loss: 2.4862744269832486

Epoch: 6| Step: 4
Training loss: 2.4613566398620605
Validation loss: 2.4747063344524753

Epoch: 6| Step: 5
Training loss: 1.9415476322174072
Validation loss: 2.4700263956541657

Epoch: 6| Step: 6
Training loss: 2.878829002380371
Validation loss: 2.458648681640625

Epoch: 6| Step: 7
Training loss: 2.341526985168457
Validation loss: 2.456633029445525

Epoch: 6| Step: 8
Training loss: 3.0353217124938965
Validation loss: 2.4614529250770487

Epoch: 6| Step: 9
Training loss: 2.9260034561157227
Validation loss: 2.4661719593950497

Epoch: 6| Step: 10
Training loss: 3.001519203186035
Validation loss: 2.4517719771272395

Epoch: 6| Step: 11
Training loss: 3.025162696838379
Validation loss: 2.450842195941556

Epoch: 6| Step: 12
Training loss: 2.3818373680114746
Validation loss: 2.4556051761873308

Epoch: 6| Step: 13
Training loss: 3.1876018047332764
Validation loss: 2.45307695481085

Epoch: 34| Step: 0
Training loss: 3.2922255992889404
Validation loss: 2.4541772668079664

Epoch: 6| Step: 1
Training loss: 3.098621129989624
Validation loss: 2.4515902457698697

Epoch: 6| Step: 2
Training loss: 2.418651580810547
Validation loss: 2.451842531081169

Epoch: 6| Step: 3
Training loss: 2.9813220500946045
Validation loss: 2.4492914574120634

Epoch: 6| Step: 4
Training loss: 3.2061681747436523
Validation loss: 2.451894303803803

Epoch: 6| Step: 5
Training loss: 2.2060208320617676
Validation loss: 2.453784276080388

Epoch: 6| Step: 6
Training loss: 1.7800729274749756
Validation loss: 2.4518956702242614

Epoch: 6| Step: 7
Training loss: 3.0566163063049316
Validation loss: 2.4534601498675603

Epoch: 6| Step: 8
Training loss: 2.46799635887146
Validation loss: 2.458979391282605

Epoch: 6| Step: 9
Training loss: 1.6527736186981201
Validation loss: 2.4549435389939176

Epoch: 6| Step: 10
Training loss: 2.557189702987671
Validation loss: 2.462152857934275

Epoch: 6| Step: 11
Training loss: 3.4000027179718018
Validation loss: 2.4862008402424474

Epoch: 6| Step: 12
Training loss: 2.611414909362793
Validation loss: 2.500233175934002

Epoch: 6| Step: 13
Training loss: 2.8420262336730957
Validation loss: 2.4801919434660222

Epoch: 35| Step: 0
Training loss: 2.5736329555511475
Validation loss: 2.4559281410709506

Epoch: 6| Step: 1
Training loss: 2.452557325363159
Validation loss: 2.4452826233320337

Epoch: 6| Step: 2
Training loss: 2.377791404724121
Validation loss: 2.4539040083526285

Epoch: 6| Step: 3
Training loss: 2.9729809761047363
Validation loss: 2.461568065868911

Epoch: 6| Step: 4
Training loss: 2.312988758087158
Validation loss: 2.4588964305898195

Epoch: 6| Step: 5
Training loss: 3.0072154998779297
Validation loss: 2.4493216083895777

Epoch: 6| Step: 6
Training loss: 2.751474380493164
Validation loss: 2.444426272505073

Epoch: 6| Step: 7
Training loss: 2.7709410190582275
Validation loss: 2.436922602756049

Epoch: 6| Step: 8
Training loss: 2.1696882247924805
Validation loss: 2.4383395897444857

Epoch: 6| Step: 9
Training loss: 2.930929660797119
Validation loss: 2.442109477135443

Epoch: 6| Step: 10
Training loss: 2.343190908432007
Validation loss: 2.4494058111662507

Epoch: 6| Step: 11
Training loss: 2.8202714920043945
Validation loss: 2.4565271459599978

Epoch: 6| Step: 12
Training loss: 2.941446304321289
Validation loss: 2.4699245729754047

Epoch: 6| Step: 13
Training loss: 3.5326473712921143
Validation loss: 2.4679745397260113

Epoch: 36| Step: 0
Training loss: 2.552126407623291
Validation loss: 2.4548626433136644

Epoch: 6| Step: 1
Training loss: 2.9582080841064453
Validation loss: 2.442678528447305

Epoch: 6| Step: 2
Training loss: 2.6506786346435547
Validation loss: 2.4332901047122095

Epoch: 6| Step: 3
Training loss: 2.806262254714966
Validation loss: 2.4333774710214264

Epoch: 6| Step: 4
Training loss: 3.205247402191162
Validation loss: 2.4326722698826946

Epoch: 6| Step: 5
Training loss: 2.0958731174468994
Validation loss: 2.437908454607892

Epoch: 6| Step: 6
Training loss: 2.822721004486084
Validation loss: 2.4540577575724614

Epoch: 6| Step: 7
Training loss: 2.679403305053711
Validation loss: 2.438993964143979

Epoch: 6| Step: 8
Training loss: 2.545243263244629
Validation loss: 2.435478735995549

Epoch: 6| Step: 9
Training loss: 2.42653226852417
Validation loss: 2.4237799695743028

Epoch: 6| Step: 10
Training loss: 2.5213069915771484
Validation loss: 2.421449015217443

Epoch: 6| Step: 11
Training loss: 3.3283441066741943
Validation loss: 2.431222992558633

Epoch: 6| Step: 12
Training loss: 2.563554286956787
Validation loss: 2.428489238985123

Epoch: 6| Step: 13
Training loss: 1.9487395286560059
Validation loss: 2.4284354307318248

Epoch: 37| Step: 0
Training loss: 2.234471082687378
Validation loss: 2.431803129052603

Epoch: 6| Step: 1
Training loss: 2.5643110275268555
Validation loss: 2.4273937850870113

Epoch: 6| Step: 2
Training loss: 3.2464599609375
Validation loss: 2.4312788773608465

Epoch: 6| Step: 3
Training loss: 3.0693564414978027
Validation loss: 2.4279900955897507

Epoch: 6| Step: 4
Training loss: 1.9171509742736816
Validation loss: 2.4319914643482496

Epoch: 6| Step: 5
Training loss: 2.658109188079834
Validation loss: 2.427549236564226

Epoch: 6| Step: 6
Training loss: 3.0546703338623047
Validation loss: 2.4269655161006476

Epoch: 6| Step: 7
Training loss: 2.2053372859954834
Validation loss: 2.4210159188957623

Epoch: 6| Step: 8
Training loss: 3.0282039642333984
Validation loss: 2.423447573056785

Epoch: 6| Step: 9
Training loss: 2.5055575370788574
Validation loss: 2.427260137373401

Epoch: 6| Step: 10
Training loss: 2.880303382873535
Validation loss: 2.4302875534180672

Epoch: 6| Step: 11
Training loss: 2.9199373722076416
Validation loss: 2.4386306655022407

Epoch: 6| Step: 12
Training loss: 2.7593441009521484
Validation loss: 2.440348358564479

Epoch: 6| Step: 13
Training loss: 1.9038969278335571
Validation loss: 2.4371686853388304

Epoch: 38| Step: 0
Training loss: 2.3748257160186768
Validation loss: 2.4409432334284626

Epoch: 6| Step: 1
Training loss: 2.8093371391296387
Validation loss: 2.467268682295276

Epoch: 6| Step: 2
Training loss: 2.7712831497192383
Validation loss: 2.4690778896372807

Epoch: 6| Step: 3
Training loss: 3.0951571464538574
Validation loss: 2.4848902994586575

Epoch: 6| Step: 4
Training loss: 2.0735387802124023
Validation loss: 2.462020827877906

Epoch: 6| Step: 5
Training loss: 3.278724193572998
Validation loss: 2.4405671550381567

Epoch: 6| Step: 6
Training loss: 3.0332584381103516
Validation loss: 2.4220681831400883

Epoch: 6| Step: 7
Training loss: 2.7971134185791016
Validation loss: 2.414228034275834

Epoch: 6| Step: 8
Training loss: 2.0914382934570312
Validation loss: 2.414677261024393

Epoch: 6| Step: 9
Training loss: 2.7389557361602783
Validation loss: 2.4154138488154255

Epoch: 6| Step: 10
Training loss: 2.8469841480255127
Validation loss: 2.420025248681345

Epoch: 6| Step: 11
Training loss: 2.4437930583953857
Validation loss: 2.4217093477966967

Epoch: 6| Step: 12
Training loss: 3.104203701019287
Validation loss: 2.414426629261304

Epoch: 6| Step: 13
Training loss: 1.4952629804611206
Validation loss: 2.4120176633199057

Epoch: 39| Step: 0
Training loss: 2.88492488861084
Validation loss: 2.413573488112419

Epoch: 6| Step: 1
Training loss: 2.8159637451171875
Validation loss: 2.41019174873188

Epoch: 6| Step: 2
Training loss: 1.904097080230713
Validation loss: 2.417237507399692

Epoch: 6| Step: 3
Training loss: 3.291574478149414
Validation loss: 2.433283628955964

Epoch: 6| Step: 4
Training loss: 2.813243865966797
Validation loss: 2.4626015027364097

Epoch: 6| Step: 5
Training loss: 2.271631956100464
Validation loss: 2.4695277547323577

Epoch: 6| Step: 6
Training loss: 2.974226713180542
Validation loss: 2.450500403681109

Epoch: 6| Step: 7
Training loss: 2.6472208499908447
Validation loss: 2.4531142557820966

Epoch: 6| Step: 8
Training loss: 2.234652280807495
Validation loss: 2.4275700584534676

Epoch: 6| Step: 9
Training loss: 2.585252046585083
Validation loss: 2.416634390431066

Epoch: 6| Step: 10
Training loss: 2.9186508655548096
Validation loss: 2.4115276182851484

Epoch: 6| Step: 11
Training loss: 2.4493956565856934
Validation loss: 2.406038309938164

Epoch: 6| Step: 12
Training loss: 2.913499355316162
Validation loss: 2.4046688438743673

Epoch: 6| Step: 13
Training loss: 2.3222477436065674
Validation loss: 2.4084632063424714

Epoch: 40| Step: 0
Training loss: 2.2155609130859375
Validation loss: 2.403631141108851

Epoch: 6| Step: 1
Training loss: 2.399444341659546
Validation loss: 2.4043251929744596

Epoch: 6| Step: 2
Training loss: 2.174833059310913
Validation loss: 2.409385722170594

Epoch: 6| Step: 3
Training loss: 2.0374979972839355
Validation loss: 2.4119048862047094

Epoch: 6| Step: 4
Training loss: 2.8893022537231445
Validation loss: 2.4333254803893385

Epoch: 6| Step: 5
Training loss: 2.7001795768737793
Validation loss: 2.433844725290934

Epoch: 6| Step: 6
Training loss: 2.5334391593933105
Validation loss: 2.4229903964586157

Epoch: 6| Step: 7
Training loss: 3.6443533897399902
Validation loss: 2.4201972561497844

Epoch: 6| Step: 8
Training loss: 2.559744358062744
Validation loss: 2.4124879324308006

Epoch: 6| Step: 9
Training loss: 2.8062472343444824
Validation loss: 2.4039318728190597

Epoch: 6| Step: 10
Training loss: 2.4008326530456543
Validation loss: 2.405871263114355

Epoch: 6| Step: 11
Training loss: 2.939913749694824
Validation loss: 2.3986639899592244

Epoch: 6| Step: 12
Training loss: 2.9865643978118896
Validation loss: 2.3970759299493607

Epoch: 6| Step: 13
Training loss: 3.0919179916381836
Validation loss: 2.394742727279663

Epoch: 41| Step: 0
Training loss: 2.9585325717926025
Validation loss: 2.3954913795635266

Epoch: 6| Step: 1
Training loss: 2.491755247116089
Validation loss: 2.3958146597749446

Epoch: 6| Step: 2
Training loss: 3.6133761405944824
Validation loss: 2.3963750229086926

Epoch: 6| Step: 3
Training loss: 2.3919315338134766
Validation loss: 2.3931425822678434

Epoch: 6| Step: 4
Training loss: 2.21281361579895
Validation loss: 2.396108906756165

Epoch: 6| Step: 5
Training loss: 3.2748031616210938
Validation loss: 2.39285982296031

Epoch: 6| Step: 6
Training loss: 2.6398353576660156
Validation loss: 2.397929829935874

Epoch: 6| Step: 7
Training loss: 2.6967883110046387
Validation loss: 2.394841663299068

Epoch: 6| Step: 8
Training loss: 2.602710247039795
Validation loss: 2.3896142872430945

Epoch: 6| Step: 9
Training loss: 2.122507095336914
Validation loss: 2.3892292950742986

Epoch: 6| Step: 10
Training loss: 2.9299018383026123
Validation loss: 2.396968754388953

Epoch: 6| Step: 11
Training loss: 1.691703200340271
Validation loss: 2.398462897987776

Epoch: 6| Step: 12
Training loss: 2.7105212211608887
Validation loss: 2.420922789522397

Epoch: 6| Step: 13
Training loss: 2.5251619815826416
Validation loss: 2.441639854061988

Epoch: 42| Step: 0
Training loss: 3.007084369659424
Validation loss: 2.472432736427553

Epoch: 6| Step: 1
Training loss: 2.7239532470703125
Validation loss: 2.4671525903927383

Epoch: 6| Step: 2
Training loss: 1.9127559661865234
Validation loss: 2.4518118289209183

Epoch: 6| Step: 3
Training loss: 2.3349647521972656
Validation loss: 2.419557463738226

Epoch: 6| Step: 4
Training loss: 2.5868279933929443
Validation loss: 2.4057075849143406

Epoch: 6| Step: 5
Training loss: 2.9052019119262695
Validation loss: 2.4047691719506377

Epoch: 6| Step: 6
Training loss: 2.286538600921631
Validation loss: 2.3984459984687065

Epoch: 6| Step: 7
Training loss: 2.69561767578125
Validation loss: 2.3976013327157624

Epoch: 6| Step: 8
Training loss: 2.6569294929504395
Validation loss: 2.3943199778115876

Epoch: 6| Step: 9
Training loss: 2.1688859462738037
Validation loss: 2.3880193694945304

Epoch: 6| Step: 10
Training loss: 1.9984068870544434
Validation loss: 2.382023437048799

Epoch: 6| Step: 11
Training loss: 4.339726448059082
Validation loss: 2.3841950342219365

Epoch: 6| Step: 12
Training loss: 2.408595085144043
Validation loss: 2.3864385235694145

Epoch: 6| Step: 13
Training loss: 3.2368886470794678
Validation loss: 2.3815933478775846

Epoch: 43| Step: 0
Training loss: 2.297532558441162
Validation loss: 2.379887916708505

Epoch: 6| Step: 1
Training loss: 2.9737610816955566
Validation loss: 2.377195906895463

Epoch: 6| Step: 2
Training loss: 2.159960985183716
Validation loss: 2.377549381666286

Epoch: 6| Step: 3
Training loss: 3.1431684494018555
Validation loss: 2.376917367340416

Epoch: 6| Step: 4
Training loss: 2.4974308013916016
Validation loss: 2.3751843385798956

Epoch: 6| Step: 5
Training loss: 2.449112892150879
Validation loss: 2.3792279638269895

Epoch: 6| Step: 6
Training loss: 3.221426010131836
Validation loss: 2.377456554802515

Epoch: 6| Step: 7
Training loss: 2.5605382919311523
Validation loss: 2.3729933974563435

Epoch: 6| Step: 8
Training loss: 2.6407971382141113
Validation loss: 2.3715478886840162

Epoch: 6| Step: 9
Training loss: 3.1998915672302246
Validation loss: 2.3709224013872046

Epoch: 6| Step: 10
Training loss: 2.9370527267456055
Validation loss: 2.365963428251205

Epoch: 6| Step: 11
Training loss: 2.519243001937866
Validation loss: 2.365508794784546

Epoch: 6| Step: 12
Training loss: 1.7079176902770996
Validation loss: 2.371494309876555

Epoch: 6| Step: 13
Training loss: 2.4576079845428467
Validation loss: 2.3840381227513796

Epoch: 44| Step: 0
Training loss: 2.5068535804748535
Validation loss: 2.4071246731665825

Epoch: 6| Step: 1
Training loss: 2.170344829559326
Validation loss: 2.432508537846227

Epoch: 6| Step: 2
Training loss: 2.5256028175354004
Validation loss: 2.459907465083625

Epoch: 6| Step: 3
Training loss: 3.326432943344116
Validation loss: 2.4448540800361225

Epoch: 6| Step: 4
Training loss: 2.275202751159668
Validation loss: 2.3975149687900337

Epoch: 6| Step: 5
Training loss: 3.46356201171875
Validation loss: 2.3689019910750853

Epoch: 6| Step: 6
Training loss: 2.1885197162628174
Validation loss: 2.3607374621975805

Epoch: 6| Step: 7
Training loss: 2.2240872383117676
Validation loss: 2.364369184740128

Epoch: 6| Step: 8
Training loss: 2.2541005611419678
Validation loss: 2.3767557503074728

Epoch: 6| Step: 9
Training loss: 2.9197590351104736
Validation loss: 2.37574674237159

Epoch: 6| Step: 10
Training loss: 2.2656679153442383
Validation loss: 2.3569115977133475

Epoch: 6| Step: 11
Training loss: 3.0988352298736572
Validation loss: 2.3585857934849237

Epoch: 6| Step: 12
Training loss: 3.3709559440612793
Validation loss: 2.372323379721693

Epoch: 6| Step: 13
Training loss: 2.171696662902832
Validation loss: 2.382521947224935

Epoch: 45| Step: 0
Training loss: 2.9670920372009277
Validation loss: 2.428167473885321

Epoch: 6| Step: 1
Training loss: 2.6615824699401855
Validation loss: 2.4997118185925227

Epoch: 6| Step: 2
Training loss: 2.919079542160034
Validation loss: 2.5190061715341385

Epoch: 6| Step: 3
Training loss: 2.3873088359832764
Validation loss: 2.413536763960315

Epoch: 6| Step: 4
Training loss: 2.3405098915100098
Validation loss: 2.3697225560424147

Epoch: 6| Step: 5
Training loss: 3.447861671447754
Validation loss: 2.355555795854138

Epoch: 6| Step: 6
Training loss: 2.269266128540039
Validation loss: 2.3644929547463693

Epoch: 6| Step: 7
Training loss: 3.104437828063965
Validation loss: 2.3819179573366718

Epoch: 6| Step: 8
Training loss: 3.280170440673828
Validation loss: 2.411999797308317

Epoch: 6| Step: 9
Training loss: 1.9748541116714478
Validation loss: 2.4102777383660756

Epoch: 6| Step: 10
Training loss: 2.280829429626465
Validation loss: 2.408095828948482

Epoch: 6| Step: 11
Training loss: 2.451319932937622
Validation loss: 2.383220700807469

Epoch: 6| Step: 12
Training loss: 2.5881917476654053
Validation loss: 2.3718682976179224

Epoch: 6| Step: 13
Training loss: 2.655247211456299
Validation loss: 2.362408909746396

Epoch: 46| Step: 0
Training loss: 2.5752151012420654
Validation loss: 2.3561408417199248

Epoch: 6| Step: 1
Training loss: 2.579035758972168
Validation loss: 2.3536365596196984

Epoch: 6| Step: 2
Training loss: 2.3858437538146973
Validation loss: 2.3549729265192503

Epoch: 6| Step: 3
Training loss: 3.090210437774658
Validation loss: 2.360320888539796

Epoch: 6| Step: 4
Training loss: 1.9273455142974854
Validation loss: 2.3772891516326577

Epoch: 6| Step: 5
Training loss: 1.9364057779312134
Validation loss: 2.378984010347756

Epoch: 6| Step: 6
Training loss: 2.809262990951538
Validation loss: 2.383756511954851

Epoch: 6| Step: 7
Training loss: 3.3699488639831543
Validation loss: 2.386143643368957

Epoch: 6| Step: 8
Training loss: 2.4991707801818848
Validation loss: 2.3708331687476045

Epoch: 6| Step: 9
Training loss: 2.807361125946045
Validation loss: 2.3545115865686888

Epoch: 6| Step: 10
Training loss: 2.779160499572754
Validation loss: 2.3492293665485997

Epoch: 6| Step: 11
Training loss: 2.137026786804199
Validation loss: 2.3477723393388974

Epoch: 6| Step: 12
Training loss: 3.0241446495056152
Validation loss: 2.351684593385266

Epoch: 6| Step: 13
Training loss: 2.975480079650879
Validation loss: 2.3545369743019022

Epoch: 47| Step: 0
Training loss: 2.934232473373413
Validation loss: 2.352604901918801

Epoch: 6| Step: 1
Training loss: 2.2056968212127686
Validation loss: 2.3499068444774998

Epoch: 6| Step: 2
Training loss: 2.9289941787719727
Validation loss: 2.3483564417849303

Epoch: 6| Step: 3
Training loss: 2.6171340942382812
Validation loss: 2.355162746162825

Epoch: 6| Step: 4
Training loss: 2.5559122562408447
Validation loss: 2.363744871590727

Epoch: 6| Step: 5
Training loss: 2.2109062671661377
Validation loss: 2.3718268948216594

Epoch: 6| Step: 6
Training loss: 3.069641590118408
Validation loss: 2.363788548336234

Epoch: 6| Step: 7
Training loss: 2.2560086250305176
Validation loss: 2.3649818820338093

Epoch: 6| Step: 8
Training loss: 3.573777675628662
Validation loss: 2.366268050286078

Epoch: 6| Step: 9
Training loss: 2.8570032119750977
Validation loss: 2.3795589452148764

Epoch: 6| Step: 10
Training loss: 1.888530969619751
Validation loss: 2.3688123508166243

Epoch: 6| Step: 11
Training loss: 2.731536388397217
Validation loss: 2.3681369032911075

Epoch: 6| Step: 12
Training loss: 2.4459056854248047
Validation loss: 2.350487188626361

Epoch: 6| Step: 13
Training loss: 2.0786099433898926
Validation loss: 2.351355550109699

Epoch: 48| Step: 0
Training loss: 2.5462193489074707
Validation loss: 2.348219435702088

Epoch: 6| Step: 1
Training loss: 2.3802027702331543
Validation loss: 2.363725180267006

Epoch: 6| Step: 2
Training loss: 2.232534885406494
Validation loss: 2.350051792719031

Epoch: 6| Step: 3
Training loss: 1.7211992740631104
Validation loss: 2.344226316739154

Epoch: 6| Step: 4
Training loss: 2.1188907623291016
Validation loss: 2.3468309910066667

Epoch: 6| Step: 5
Training loss: 2.7109761238098145
Validation loss: 2.3401975054894724

Epoch: 6| Step: 6
Training loss: 2.7610344886779785
Validation loss: 2.3387076393250497

Epoch: 6| Step: 7
Training loss: 3.17568039894104
Validation loss: 2.333593390321219

Epoch: 6| Step: 8
Training loss: 3.1841843128204346
Validation loss: 2.3351470014100433

Epoch: 6| Step: 9
Training loss: 2.990185260772705
Validation loss: 2.3344804394629692

Epoch: 6| Step: 10
Training loss: 2.0017096996307373
Validation loss: 2.335544822036579

Epoch: 6| Step: 11
Training loss: 2.689882755279541
Validation loss: 2.3406227224616596

Epoch: 6| Step: 12
Training loss: 2.9858102798461914
Validation loss: 2.3429138378430436

Epoch: 6| Step: 13
Training loss: 3.2781805992126465
Validation loss: 2.371755699957571

Epoch: 49| Step: 0
Training loss: 2.974039077758789
Validation loss: 2.403092030555971

Epoch: 6| Step: 1
Training loss: 3.4336817264556885
Validation loss: 2.3910252407032955

Epoch: 6| Step: 2
Training loss: 2.4058361053466797
Validation loss: 2.342875034578385

Epoch: 6| Step: 3
Training loss: 2.5831246376037598
Validation loss: 2.329586636635565

Epoch: 6| Step: 4
Training loss: 2.3811516761779785
Validation loss: 2.326170236833634

Epoch: 6| Step: 5
Training loss: 2.5238919258117676
Validation loss: 2.323423562511321

Epoch: 6| Step: 6
Training loss: 2.184499740600586
Validation loss: 2.3218710255879227

Epoch: 6| Step: 7
Training loss: 2.528381824493408
Validation loss: 2.323871038293326

Epoch: 6| Step: 8
Training loss: 3.046776294708252
Validation loss: 2.3215065797170005

Epoch: 6| Step: 9
Training loss: 2.7554101943969727
Validation loss: 2.3201375648539555

Epoch: 6| Step: 10
Training loss: 2.1407599449157715
Validation loss: 2.3205471551546486

Epoch: 6| Step: 11
Training loss: 2.1479694843292236
Validation loss: 2.3234837388479583

Epoch: 6| Step: 12
Training loss: 2.8453760147094727
Validation loss: 2.3277780343127508

Epoch: 6| Step: 13
Training loss: 2.9164483547210693
Validation loss: 2.331901909202658

Epoch: 50| Step: 0
Training loss: 2.6933646202087402
Validation loss: 2.343043129931214

Epoch: 6| Step: 1
Training loss: 2.393794059753418
Validation loss: 2.3609273074775614

Epoch: 6| Step: 2
Training loss: 2.6798300743103027
Validation loss: 2.4061657151868268

Epoch: 6| Step: 3
Training loss: 2.626217842102051
Validation loss: 2.4141195153677337

Epoch: 6| Step: 4
Training loss: 2.7394039630889893
Validation loss: 2.406511927163729

Epoch: 6| Step: 5
Training loss: 1.4673676490783691
Validation loss: 2.365280815350112

Epoch: 6| Step: 6
Training loss: 3.013705253601074
Validation loss: 2.336623640470607

Epoch: 6| Step: 7
Training loss: 2.2549378871917725
Validation loss: 2.328451907762917

Epoch: 6| Step: 8
Training loss: 2.793149948120117
Validation loss: 2.3222834294842136

Epoch: 6| Step: 9
Training loss: 3.0166051387786865
Validation loss: 2.3166345473258727

Epoch: 6| Step: 10
Training loss: 3.407658338546753
Validation loss: 2.3152546600628923

Epoch: 6| Step: 11
Training loss: 2.379471778869629
Validation loss: 2.3285159013604604

Epoch: 6| Step: 12
Training loss: 2.2371206283569336
Validation loss: 2.3510073820749917

Epoch: 6| Step: 13
Training loss: 2.7789716720581055
Validation loss: 2.3677220549634708

Epoch: 51| Step: 0
Training loss: 1.9599770307540894
Validation loss: 2.3474572525229505

Epoch: 6| Step: 1
Training loss: 2.0725553035736084
Validation loss: 2.3284179549063406

Epoch: 6| Step: 2
Training loss: 2.667818069458008
Validation loss: 2.3143811110527284

Epoch: 6| Step: 3
Training loss: 2.550367593765259
Validation loss: 2.326809044807188

Epoch: 6| Step: 4
Training loss: 2.0806033611297607
Validation loss: 2.3786422514146373

Epoch: 6| Step: 5
Training loss: 3.6990997791290283
Validation loss: 2.629407295616724

Epoch: 6| Step: 6
Training loss: 3.716252326965332
Validation loss: 2.5456441166580364

Epoch: 6| Step: 7
Training loss: 2.4262568950653076
Validation loss: 2.3828261334408998

Epoch: 6| Step: 8
Training loss: 2.206029176712036
Validation loss: 2.333060969588577

Epoch: 6| Step: 9
Training loss: 2.7665233612060547
Validation loss: 2.327428166584302

Epoch: 6| Step: 10
Training loss: 2.8153529167175293
Validation loss: 2.333947717502553

Epoch: 6| Step: 11
Training loss: 2.913705348968506
Validation loss: 2.3513715138999363

Epoch: 6| Step: 12
Training loss: 2.637485980987549
Validation loss: 2.3647383874462498

Epoch: 6| Step: 13
Training loss: 2.539303779602051
Validation loss: 2.387914631956367

Epoch: 52| Step: 0
Training loss: 2.1651644706726074
Validation loss: 2.3739281264684533

Epoch: 6| Step: 1
Training loss: 2.1257402896881104
Validation loss: 2.369593761300528

Epoch: 6| Step: 2
Training loss: 2.3603265285491943
Validation loss: 2.3418429846404702

Epoch: 6| Step: 3
Training loss: 2.632359027862549
Validation loss: 2.346175545005388

Epoch: 6| Step: 4
Training loss: 2.723235845565796
Validation loss: 2.3554211790843675

Epoch: 6| Step: 5
Training loss: 2.477062225341797
Validation loss: 2.364920675113637

Epoch: 6| Step: 6
Training loss: 3.154583215713501
Validation loss: 2.3682392950980895

Epoch: 6| Step: 7
Training loss: 2.52378511428833
Validation loss: 2.3368988601110314

Epoch: 6| Step: 8
Training loss: 2.3708691596984863
Validation loss: 2.3216374176804737

Epoch: 6| Step: 9
Training loss: 3.0421204566955566
Validation loss: 2.325067038177162

Epoch: 6| Step: 10
Training loss: 2.2741312980651855
Validation loss: 2.3281859813197965

Epoch: 6| Step: 11
Training loss: 3.126331329345703
Validation loss: 2.32225195054085

Epoch: 6| Step: 12
Training loss: 2.3576297760009766
Validation loss: 2.3231987594276347

Epoch: 6| Step: 13
Training loss: 3.3458950519561768
Validation loss: 2.3278610257692236

Epoch: 53| Step: 0
Training loss: 2.6173486709594727
Validation loss: 2.320332673288161

Epoch: 6| Step: 1
Training loss: 2.2743608951568604
Validation loss: 2.315274028367894

Epoch: 6| Step: 2
Training loss: 2.3337831497192383
Validation loss: 2.323729327929917

Epoch: 6| Step: 3
Training loss: 2.6542325019836426
Validation loss: 2.33659960890329

Epoch: 6| Step: 4
Training loss: 2.6703617572784424
Validation loss: 2.3332243093880276

Epoch: 6| Step: 5
Training loss: 2.3676347732543945
Validation loss: 2.3273970773143153

Epoch: 6| Step: 6
Training loss: 2.6366090774536133
Validation loss: 2.3076905242858397

Epoch: 6| Step: 7
Training loss: 2.5214462280273438
Validation loss: 2.3023336420777025

Epoch: 6| Step: 8
Training loss: 2.3805723190307617
Validation loss: 2.3008768558502197

Epoch: 6| Step: 9
Training loss: 2.6390931606292725
Validation loss: 2.2987039755749445

Epoch: 6| Step: 10
Training loss: 2.239591121673584
Validation loss: 2.3011330122588785

Epoch: 6| Step: 11
Training loss: 2.874399185180664
Validation loss: 2.300116903038435

Epoch: 6| Step: 12
Training loss: 2.817850112915039
Validation loss: 2.2996188286812074

Epoch: 6| Step: 13
Training loss: 3.436204433441162
Validation loss: 2.3078899998818674

Epoch: 54| Step: 0
Training loss: 2.918456554412842
Validation loss: 2.307118441468926

Epoch: 6| Step: 1
Training loss: 1.823920488357544
Validation loss: 2.299787836690103

Epoch: 6| Step: 2
Training loss: 3.143284797668457
Validation loss: 2.2968951117607856

Epoch: 6| Step: 3
Training loss: 2.649540901184082
Validation loss: 2.295405739097185

Epoch: 6| Step: 4
Training loss: 2.706979513168335
Validation loss: 2.2883398148321334

Epoch: 6| Step: 5
Training loss: 2.7515974044799805
Validation loss: 2.290344771518502

Epoch: 6| Step: 6
Training loss: 3.3127598762512207
Validation loss: 2.28955901053644

Epoch: 6| Step: 7
Training loss: 2.252963066101074
Validation loss: 2.29474167541791

Epoch: 6| Step: 8
Training loss: 2.2724013328552246
Validation loss: 2.295636782082178

Epoch: 6| Step: 9
Training loss: 2.4369215965270996
Validation loss: 2.2976430923708024

Epoch: 6| Step: 10
Training loss: 1.6905755996704102
Validation loss: 2.2966534450489986

Epoch: 6| Step: 11
Training loss: 2.608823776245117
Validation loss: 2.296944664370629

Epoch: 6| Step: 12
Training loss: 2.9124915599823
Validation loss: 2.2970775199192826

Epoch: 6| Step: 13
Training loss: 3.0134496688842773
Validation loss: 2.2899744664469073

Epoch: 55| Step: 0
Training loss: 2.8996920585632324
Validation loss: 2.2914158246850453

Epoch: 6| Step: 1
Training loss: 1.8842954635620117
Validation loss: 2.296149830664358

Epoch: 6| Step: 2
Training loss: 2.386467456817627
Validation loss: 2.3152901434129283

Epoch: 6| Step: 3
Training loss: 2.0234932899475098
Validation loss: 2.3216069641933648

Epoch: 6| Step: 4
Training loss: 2.2125213146209717
Validation loss: 2.320807974825623

Epoch: 6| Step: 5
Training loss: 3.4412543773651123
Validation loss: 2.340018005781276

Epoch: 6| Step: 6
Training loss: 2.3400936126708984
Validation loss: 2.3313627294314805

Epoch: 6| Step: 7
Training loss: 2.6763551235198975
Validation loss: 2.316434737174742

Epoch: 6| Step: 8
Training loss: 1.8537044525146484
Validation loss: 2.306095702673799

Epoch: 6| Step: 9
Training loss: 3.2290003299713135
Validation loss: 2.289112085937172

Epoch: 6| Step: 10
Training loss: 2.509021282196045
Validation loss: 2.2839801644766204

Epoch: 6| Step: 11
Training loss: 2.532227039337158
Validation loss: 2.2801991073034142

Epoch: 6| Step: 12
Training loss: 2.962925672531128
Validation loss: 2.277606402674029

Epoch: 6| Step: 13
Training loss: 3.3928418159484863
Validation loss: 2.277534305408437

Epoch: 56| Step: 0
Training loss: 2.4552083015441895
Validation loss: 2.276924487083189

Epoch: 6| Step: 1
Training loss: 2.3499627113342285
Validation loss: 2.2777653022478987

Epoch: 6| Step: 2
Training loss: 2.6754722595214844
Validation loss: 2.2767537793805523

Epoch: 6| Step: 3
Training loss: 2.891669273376465
Validation loss: 2.2841843969078472

Epoch: 6| Step: 4
Training loss: 2.3640356063842773
Validation loss: 2.3065053532200475

Epoch: 6| Step: 5
Training loss: 2.741722822189331
Validation loss: 2.3430812538311048

Epoch: 6| Step: 6
Training loss: 2.6120996475219727
Validation loss: 2.3697319543489845

Epoch: 6| Step: 7
Training loss: 2.497102975845337
Validation loss: 2.347867645243163

Epoch: 6| Step: 8
Training loss: 2.195866346359253
Validation loss: 2.33936430305563

Epoch: 6| Step: 9
Training loss: 3.07452392578125
Validation loss: 2.2941056169489378

Epoch: 6| Step: 10
Training loss: 1.8817389011383057
Validation loss: 2.2878858350938365

Epoch: 6| Step: 11
Training loss: 2.8201780319213867
Validation loss: 2.2825487480368665

Epoch: 6| Step: 12
Training loss: 3.2377099990844727
Validation loss: 2.2905907297647126

Epoch: 6| Step: 13
Training loss: 2.3600473403930664
Validation loss: 2.2918973917602212

Epoch: 57| Step: 0
Training loss: 2.749498128890991
Validation loss: 2.2963552064793085

Epoch: 6| Step: 1
Training loss: 1.5106260776519775
Validation loss: 2.2985445914729947

Epoch: 6| Step: 2
Training loss: 2.1903738975524902
Validation loss: 2.2950121177140104

Epoch: 6| Step: 3
Training loss: 2.4269521236419678
Validation loss: 2.290604732369864

Epoch: 6| Step: 4
Training loss: 2.4834046363830566
Validation loss: 2.2859782095878356

Epoch: 6| Step: 5
Training loss: 2.8663671016693115
Validation loss: 2.287031673615979

Epoch: 6| Step: 6
Training loss: 2.9640302658081055
Validation loss: 2.286968054309968

Epoch: 6| Step: 7
Training loss: 2.293360948562622
Validation loss: 2.301544245853219

Epoch: 6| Step: 8
Training loss: 3.3862345218658447
Validation loss: 2.31997989326395

Epoch: 6| Step: 9
Training loss: 2.4701781272888184
Validation loss: 2.341784606697739

Epoch: 6| Step: 10
Training loss: 2.9865121841430664
Validation loss: 2.3627610462968067

Epoch: 6| Step: 11
Training loss: 1.7812705039978027
Validation loss: 2.369288936738045

Epoch: 6| Step: 12
Training loss: 2.896411418914795
Validation loss: 2.3352180527102564

Epoch: 6| Step: 13
Training loss: 3.61968731880188
Validation loss: 2.3003799812768095

Epoch: 58| Step: 0
Training loss: 2.5156137943267822
Validation loss: 2.2925980142367783

Epoch: 6| Step: 1
Training loss: 2.2483105659484863
Validation loss: 2.279543125501243

Epoch: 6| Step: 2
Training loss: 1.9182968139648438
Validation loss: 2.2787210095313286

Epoch: 6| Step: 3
Training loss: 2.4293529987335205
Validation loss: 2.280165853038911

Epoch: 6| Step: 4
Training loss: 2.746126174926758
Validation loss: 2.277953786234702

Epoch: 6| Step: 5
Training loss: 2.7072653770446777
Validation loss: 2.2880721707497873

Epoch: 6| Step: 6
Training loss: 2.6427366733551025
Validation loss: 2.2846825084378644

Epoch: 6| Step: 7
Training loss: 2.8362350463867188
Validation loss: 2.284763043926608

Epoch: 6| Step: 8
Training loss: 2.739955425262451
Validation loss: 2.301188381769324

Epoch: 6| Step: 9
Training loss: 2.568588972091675
Validation loss: 2.320070502578571

Epoch: 6| Step: 10
Training loss: 2.355651617050171
Validation loss: 2.3290612364328034

Epoch: 6| Step: 11
Training loss: 2.682471990585327
Validation loss: 2.3154295798270934

Epoch: 6| Step: 12
Training loss: 3.099453926086426
Validation loss: 2.3040650557446223

Epoch: 6| Step: 13
Training loss: 1.9446296691894531
Validation loss: 2.293826817184366

Epoch: 59| Step: 0
Training loss: 3.1429495811462402
Validation loss: 2.275470869515532

Epoch: 6| Step: 1
Training loss: 2.3927900791168213
Validation loss: 2.2717090781017015

Epoch: 6| Step: 2
Training loss: 1.8201208114624023
Validation loss: 2.2665770028227117

Epoch: 6| Step: 3
Training loss: 1.7641061544418335
Validation loss: 2.2738447214967463

Epoch: 6| Step: 4
Training loss: 2.5953867435455322
Validation loss: 2.286039959999823

Epoch: 6| Step: 5
Training loss: 2.9452273845672607
Validation loss: 2.293007994210848

Epoch: 6| Step: 6
Training loss: 2.787731647491455
Validation loss: 2.3348490794499717

Epoch: 6| Step: 7
Training loss: 3.0510945320129395
Validation loss: 2.3228413699775614

Epoch: 6| Step: 8
Training loss: 2.3786966800689697
Validation loss: 2.320619980494181

Epoch: 6| Step: 9
Training loss: 2.7018349170684814
Validation loss: 2.324238492596534

Epoch: 6| Step: 10
Training loss: 2.0355825424194336
Validation loss: 2.2983631459615563

Epoch: 6| Step: 11
Training loss: 2.4549686908721924
Validation loss: 2.286249094111945

Epoch: 6| Step: 12
Training loss: 2.630328416824341
Validation loss: 2.27265578187922

Epoch: 6| Step: 13
Training loss: 3.3357439041137695
Validation loss: 2.264510218815137

Epoch: 60| Step: 0
Training loss: 3.0415830612182617
Validation loss: 2.258584401940787

Epoch: 6| Step: 1
Training loss: 2.827791690826416
Validation loss: 2.263697926716138

Epoch: 6| Step: 2
Training loss: 1.7335572242736816
Validation loss: 2.2540574163518925

Epoch: 6| Step: 3
Training loss: 1.9762333631515503
Validation loss: 2.2553038725288967

Epoch: 6| Step: 4
Training loss: 3.0692076683044434
Validation loss: 2.2613129513238066

Epoch: 6| Step: 5
Training loss: 2.4487736225128174
Validation loss: 2.2697075925847536

Epoch: 6| Step: 6
Training loss: 2.590529441833496
Validation loss: 2.291085950789913

Epoch: 6| Step: 7
Training loss: 2.509993553161621
Validation loss: 2.306470230061521

Epoch: 6| Step: 8
Training loss: 2.8687734603881836
Validation loss: 2.3527621505081013

Epoch: 6| Step: 9
Training loss: 1.9722933769226074
Validation loss: 2.4093974713356263

Epoch: 6| Step: 10
Training loss: 2.2403624057769775
Validation loss: 2.415919929422358

Epoch: 6| Step: 11
Training loss: 2.667990207672119
Validation loss: 2.42865663959134

Epoch: 6| Step: 12
Training loss: 3.1331958770751953
Validation loss: 2.427007043233482

Epoch: 6| Step: 13
Training loss: 3.1718297004699707
Validation loss: 2.343887936684393

Epoch: 61| Step: 0
Training loss: 2.5405445098876953
Validation loss: 2.2765121690688597

Epoch: 6| Step: 1
Training loss: 2.1060385704040527
Validation loss: 2.2500496577191096

Epoch: 6| Step: 2
Training loss: 2.1015186309814453
Validation loss: 2.2526414163651003

Epoch: 6| Step: 3
Training loss: 2.8212358951568604
Validation loss: 2.264437835703614

Epoch: 6| Step: 4
Training loss: 2.5419411659240723
Validation loss: 2.268148637587024

Epoch: 6| Step: 5
Training loss: 3.3092105388641357
Validation loss: 2.2645520702485116

Epoch: 6| Step: 6
Training loss: 2.6575207710266113
Validation loss: 2.2611247775375203

Epoch: 6| Step: 7
Training loss: 2.1851820945739746
Validation loss: 2.2531428132005917

Epoch: 6| Step: 8
Training loss: 2.568819046020508
Validation loss: 2.247583984046854

Epoch: 6| Step: 9
Training loss: 3.6143851280212402
Validation loss: 2.244798262914022

Epoch: 6| Step: 10
Training loss: 2.1256933212280273
Validation loss: 2.245547599689935

Epoch: 6| Step: 11
Training loss: 2.4808521270751953
Validation loss: 2.258789365009595

Epoch: 6| Step: 12
Training loss: 2.466116189956665
Validation loss: 2.281825439904326

Epoch: 6| Step: 13
Training loss: 1.663703203201294
Validation loss: 2.3048350759731826

Epoch: 62| Step: 0
Training loss: 2.7562925815582275
Validation loss: 2.3355514926295124

Epoch: 6| Step: 1
Training loss: 2.689329147338867
Validation loss: 2.3255486513978694

Epoch: 6| Step: 2
Training loss: 2.3911867141723633
Validation loss: 2.310725255679059

Epoch: 6| Step: 3
Training loss: 3.233109712600708
Validation loss: 2.287659319498206

Epoch: 6| Step: 4
Training loss: 2.8866357803344727
Validation loss: 2.2805051752316055

Epoch: 6| Step: 5
Training loss: 2.7422595024108887
Validation loss: 2.2604781530236684

Epoch: 6| Step: 6
Training loss: 1.7553564310073853
Validation loss: 2.274695914278748

Epoch: 6| Step: 7
Training loss: 2.420625686645508
Validation loss: 2.2923676788166003

Epoch: 6| Step: 8
Training loss: 3.036590814590454
Validation loss: 2.3214040315279396

Epoch: 6| Step: 9
Training loss: 3.009181022644043
Validation loss: 2.3612147864475044

Epoch: 6| Step: 10
Training loss: 2.5087320804595947
Validation loss: 2.3565038288793256

Epoch: 6| Step: 11
Training loss: 2.110427141189575
Validation loss: 2.3158621480388026

Epoch: 6| Step: 12
Training loss: 1.5886355638504028
Validation loss: 2.2660411301479546

Epoch: 6| Step: 13
Training loss: 2.476362943649292
Validation loss: 2.244572554865191

Epoch: 63| Step: 0
Training loss: 2.4865596294403076
Validation loss: 2.2430785061210714

Epoch: 6| Step: 1
Training loss: 2.6588406562805176
Validation loss: 2.2426678160185456

Epoch: 6| Step: 2
Training loss: 2.674309015274048
Validation loss: 2.253702873824745

Epoch: 6| Step: 3
Training loss: 2.331022262573242
Validation loss: 2.252426216679235

Epoch: 6| Step: 4
Training loss: 1.665418267250061
Validation loss: 2.2526187845455703

Epoch: 6| Step: 5
Training loss: 2.1546237468719482
Validation loss: 2.248737565932735

Epoch: 6| Step: 6
Training loss: 3.1467490196228027
Validation loss: 2.244933530848513

Epoch: 6| Step: 7
Training loss: 2.2430167198181152
Validation loss: 2.2419422108639955

Epoch: 6| Step: 8
Training loss: 2.867638111114502
Validation loss: 2.234902443424348

Epoch: 6| Step: 9
Training loss: 2.7722270488739014
Validation loss: 2.2314631503115416

Epoch: 6| Step: 10
Training loss: 2.864802837371826
Validation loss: 2.2379869030367945

Epoch: 6| Step: 11
Training loss: 2.3660483360290527
Validation loss: 2.2408255505305466

Epoch: 6| Step: 12
Training loss: 2.926434278488159
Validation loss: 2.255907881644464

Epoch: 6| Step: 13
Training loss: 2.314152717590332
Validation loss: 2.270726814064928

Epoch: 64| Step: 0
Training loss: 1.9397739171981812
Validation loss: 2.2866292204908145

Epoch: 6| Step: 1
Training loss: 2.1025805473327637
Validation loss: 2.3092549257380988

Epoch: 6| Step: 2
Training loss: 2.9726603031158447
Validation loss: 2.2975818367414576

Epoch: 6| Step: 3
Training loss: 2.981912136077881
Validation loss: 2.2824462177932903

Epoch: 6| Step: 4
Training loss: 2.291037082672119
Validation loss: 2.258914537327264

Epoch: 6| Step: 5
Training loss: 2.8138599395751953
Validation loss: 2.266797870718023

Epoch: 6| Step: 6
Training loss: 2.2332282066345215
Validation loss: 2.290652523758591

Epoch: 6| Step: 7
Training loss: 2.6062769889831543
Validation loss: 2.3042000673150502

Epoch: 6| Step: 8
Training loss: 2.352993965148926
Validation loss: 2.335266641391221

Epoch: 6| Step: 9
Training loss: 2.854978084564209
Validation loss: 2.324148952320058

Epoch: 6| Step: 10
Training loss: 2.664541006088257
Validation loss: 2.340556293405512

Epoch: 6| Step: 11
Training loss: 3.1745331287384033
Validation loss: 2.3479153635681316

Epoch: 6| Step: 12
Training loss: 2.1694350242614746
Validation loss: 2.292892353509062

Epoch: 6| Step: 13
Training loss: 1.8522372245788574
Validation loss: 2.262222851476362

Epoch: 65| Step: 0
Training loss: 2.7889597415924072
Validation loss: 2.238403848422471

Epoch: 6| Step: 1
Training loss: 2.243501663208008
Validation loss: 2.2172826131184897

Epoch: 6| Step: 2
Training loss: 2.797049045562744
Validation loss: 2.2094289846317743

Epoch: 6| Step: 3
Training loss: 2.4981493949890137
Validation loss: 2.2247678669550086

Epoch: 6| Step: 4
Training loss: 2.341294765472412
Validation loss: 2.229758883035311

Epoch: 6| Step: 5
Training loss: 2.501948595046997
Validation loss: 2.2351670111379316

Epoch: 6| Step: 6
Training loss: 2.1185128688812256
Validation loss: 2.233963656169112

Epoch: 6| Step: 7
Training loss: 2.908432960510254
Validation loss: 2.2227078432677896

Epoch: 6| Step: 8
Training loss: 2.609854221343994
Validation loss: 2.215281378838324

Epoch: 6| Step: 9
Training loss: 1.9578964710235596
Validation loss: 2.2059196336295015

Epoch: 6| Step: 10
Training loss: 3.4313669204711914
Validation loss: 2.210033659012087

Epoch: 6| Step: 11
Training loss: 2.5138258934020996
Validation loss: 2.2168434973685973

Epoch: 6| Step: 12
Training loss: 2.2337136268615723
Validation loss: 2.2240113327580113

Epoch: 6| Step: 13
Training loss: 2.5667612552642822
Validation loss: 2.254500578808528

Epoch: 66| Step: 0
Training loss: 3.5717341899871826
Validation loss: 2.3359212567729335

Epoch: 6| Step: 1
Training loss: 2.4385833740234375
Validation loss: 2.3462687115515433

Epoch: 6| Step: 2
Training loss: 3.234476089477539
Validation loss: 2.3181804098108763

Epoch: 6| Step: 3
Training loss: 2.6446828842163086
Validation loss: 2.2925409937417633

Epoch: 6| Step: 4
Training loss: 2.2324771881103516
Validation loss: 2.2392032889909643

Epoch: 6| Step: 5
Training loss: 2.6161975860595703
Validation loss: 2.222515444601736

Epoch: 6| Step: 6
Training loss: 2.4454541206359863
Validation loss: 2.2142687151508946

Epoch: 6| Step: 7
Training loss: 2.127661943435669
Validation loss: 2.209908554630895

Epoch: 6| Step: 8
Training loss: 2.7782347202301025
Validation loss: 2.2183604342963106

Epoch: 6| Step: 9
Training loss: 2.4081130027770996
Validation loss: 2.2190161751162623

Epoch: 6| Step: 10
Training loss: 1.807997226715088
Validation loss: 2.2177339471796507

Epoch: 6| Step: 11
Training loss: 1.8654465675354004
Validation loss: 2.222151812686715

Epoch: 6| Step: 12
Training loss: 2.248290538787842
Validation loss: 2.228083546443652

Epoch: 6| Step: 13
Training loss: 3.3964879512786865
Validation loss: 2.23770974784769

Epoch: 67| Step: 0
Training loss: 2.5021252632141113
Validation loss: 2.247678792604836

Epoch: 6| Step: 1
Training loss: 2.721473217010498
Validation loss: 2.2476835507218555

Epoch: 6| Step: 2
Training loss: 2.3915584087371826
Validation loss: 2.2531338609674925

Epoch: 6| Step: 3
Training loss: 2.4755654335021973
Validation loss: 2.2703796843046784

Epoch: 6| Step: 4
Training loss: 2.2697339057922363
Validation loss: 2.2815762283981487

Epoch: 6| Step: 5
Training loss: 2.6075539588928223
Validation loss: 2.282645684416576

Epoch: 6| Step: 6
Training loss: 2.1898880004882812
Validation loss: 2.286615876741307

Epoch: 6| Step: 7
Training loss: 2.591046094894409
Validation loss: 2.277620292478992

Epoch: 6| Step: 8
Training loss: 2.3539018630981445
Validation loss: 2.2337434676385697

Epoch: 6| Step: 9
Training loss: 3.1479640007019043
Validation loss: 2.2249755731192966

Epoch: 6| Step: 10
Training loss: 2.1500163078308105
Validation loss: 2.211822214946952

Epoch: 6| Step: 11
Training loss: 2.4483842849731445
Validation loss: 2.2127458075041413

Epoch: 6| Step: 12
Training loss: 2.8286964893341064
Validation loss: 2.2148664587287494

Epoch: 6| Step: 13
Training loss: 2.3840079307556152
Validation loss: 2.2119754181113294

Epoch: 68| Step: 0
Training loss: 2.3373918533325195
Validation loss: 2.2113806714293776

Epoch: 6| Step: 1
Training loss: 2.324976921081543
Validation loss: 2.2012477331264044

Epoch: 6| Step: 2
Training loss: 2.4838762283325195
Validation loss: 2.1975429519530265

Epoch: 6| Step: 3
Training loss: 2.988816738128662
Validation loss: 2.2003905106616277

Epoch: 6| Step: 4
Training loss: 2.5071473121643066
Validation loss: 2.1943071247428976

Epoch: 6| Step: 5
Training loss: 2.619018077850342
Validation loss: 2.2021231625669744

Epoch: 6| Step: 6
Training loss: 2.121202230453491
Validation loss: 2.1937492278314408

Epoch: 6| Step: 7
Training loss: 1.9525468349456787
Validation loss: 2.195728184074484

Epoch: 6| Step: 8
Training loss: 2.397864818572998
Validation loss: 2.199833731497488

Epoch: 6| Step: 9
Training loss: 2.2467212677001953
Validation loss: 2.2151191208952214

Epoch: 6| Step: 10
Training loss: 3.0546953678131104
Validation loss: 2.2138058088159047

Epoch: 6| Step: 11
Training loss: 2.2338709831237793
Validation loss: 2.225789644384897

Epoch: 6| Step: 12
Training loss: 2.9298009872436523
Validation loss: 2.2331524113173127

Epoch: 6| Step: 13
Training loss: 3.003955841064453
Validation loss: 2.248906586759834

Epoch: 69| Step: 0
Training loss: 2.477682113647461
Validation loss: 2.216409467881726

Epoch: 6| Step: 1
Training loss: 2.024568796157837
Validation loss: 2.198977147379229

Epoch: 6| Step: 2
Training loss: 2.66896390914917
Validation loss: 2.1876178326145297

Epoch: 6| Step: 3
Training loss: 2.441711902618408
Validation loss: 2.1915910231169833

Epoch: 6| Step: 4
Training loss: 2.5980517864227295
Validation loss: 2.18525295360114

Epoch: 6| Step: 5
Training loss: 2.8181629180908203
Validation loss: 2.188361483235513

Epoch: 6| Step: 6
Training loss: 2.4486796855926514
Validation loss: 2.1869783965490197

Epoch: 6| Step: 7
Training loss: 2.71846866607666
Validation loss: 2.1847365953589

Epoch: 6| Step: 8
Training loss: 2.509572982788086
Validation loss: 2.1875228035834526

Epoch: 6| Step: 9
Training loss: 2.908879280090332
Validation loss: 2.1829971754422752

Epoch: 6| Step: 10
Training loss: 2.561828136444092
Validation loss: 2.1849583066919798

Epoch: 6| Step: 11
Training loss: 2.1487388610839844
Validation loss: 2.1926967328594578

Epoch: 6| Step: 12
Training loss: 1.7714521884918213
Validation loss: 2.2190749875960813

Epoch: 6| Step: 13
Training loss: 2.8917791843414307
Validation loss: 2.248208366414552

Epoch: 70| Step: 0
Training loss: 2.137266159057617
Validation loss: 2.264408829391644

Epoch: 6| Step: 1
Training loss: 2.1759912967681885
Validation loss: 2.2805950897996143

Epoch: 6| Step: 2
Training loss: 2.471512794494629
Validation loss: 2.299508128114926

Epoch: 6| Step: 3
Training loss: 2.5076558589935303
Validation loss: 2.3193277671772945

Epoch: 6| Step: 4
Training loss: 3.0060596466064453
Validation loss: 2.2898246139608402

Epoch: 6| Step: 5
Training loss: 3.2022392749786377
Validation loss: 2.244148264649094

Epoch: 6| Step: 6
Training loss: 2.1737301349639893
Validation loss: 2.2068520156286096

Epoch: 6| Step: 7
Training loss: 2.5016160011291504
Validation loss: 2.1829207635694936

Epoch: 6| Step: 8
Training loss: 1.6288622617721558
Validation loss: 2.1795204249761437

Epoch: 6| Step: 9
Training loss: 2.544963836669922
Validation loss: 2.1828936915243826

Epoch: 6| Step: 10
Training loss: 1.9706149101257324
Validation loss: 2.176776965459188

Epoch: 6| Step: 11
Training loss: 3.4510409832000732
Validation loss: 2.177459760378766

Epoch: 6| Step: 12
Training loss: 2.4746928215026855
Validation loss: 2.187375919793242

Epoch: 6| Step: 13
Training loss: 3.007052421569824
Validation loss: 2.189747284817439

Epoch: 71| Step: 0
Training loss: 2.2296512126922607
Validation loss: 2.2030618806039133

Epoch: 6| Step: 1
Training loss: 2.335512638092041
Validation loss: 2.2083505917620916

Epoch: 6| Step: 2
Training loss: 2.35932993888855
Validation loss: 2.2077050516682286

Epoch: 6| Step: 3
Training loss: 2.674555778503418
Validation loss: 2.22321077059674

Epoch: 6| Step: 4
Training loss: 2.533653736114502
Validation loss: 2.2235327702696606

Epoch: 6| Step: 5
Training loss: 1.9220669269561768
Validation loss: 2.205566144758655

Epoch: 6| Step: 6
Training loss: 2.572364330291748
Validation loss: 2.2135479501498643

Epoch: 6| Step: 7
Training loss: 3.4869937896728516
Validation loss: 2.2249568457244546

Epoch: 6| Step: 8
Training loss: 2.315528154373169
Validation loss: 2.2291071286765476

Epoch: 6| Step: 9
Training loss: 2.3790881633758545
Validation loss: 2.2454868208977485

Epoch: 6| Step: 10
Training loss: 1.9797569513320923
Validation loss: 2.2342859621970885

Epoch: 6| Step: 11
Training loss: 2.2289552688598633
Validation loss: 2.224762212845587

Epoch: 6| Step: 12
Training loss: 2.8284976482391357
Validation loss: 2.2237107215389127

Epoch: 6| Step: 13
Training loss: 2.836611032485962
Validation loss: 2.2250710943693757

Epoch: 72| Step: 0
Training loss: 2.4967520236968994
Validation loss: 2.2189232123795377

Epoch: 6| Step: 1
Training loss: 2.7092390060424805
Validation loss: 2.22003480439545

Epoch: 6| Step: 2
Training loss: 2.4356515407562256
Validation loss: 2.2142616548845844

Epoch: 6| Step: 3
Training loss: 3.36138653755188
Validation loss: 2.210750613161313

Epoch: 6| Step: 4
Training loss: 2.5247139930725098
Validation loss: 2.2025728776890743

Epoch: 6| Step: 5
Training loss: 2.348858594894409
Validation loss: 2.19900954410594

Epoch: 6| Step: 6
Training loss: 2.2686500549316406
Validation loss: 2.1969099967710433

Epoch: 6| Step: 7
Training loss: 2.136202812194824
Validation loss: 2.196164946402273

Epoch: 6| Step: 8
Training loss: 2.708141803741455
Validation loss: 2.2041766130796043

Epoch: 6| Step: 9
Training loss: 2.4427108764648438
Validation loss: 2.2101095389294367

Epoch: 6| Step: 10
Training loss: 2.2074904441833496
Validation loss: 2.2217580797851726

Epoch: 6| Step: 11
Training loss: 2.1970269680023193
Validation loss: 2.207542760397798

Epoch: 6| Step: 12
Training loss: 3.0488665103912354
Validation loss: 2.2084846470945623

Epoch: 6| Step: 13
Training loss: 0.9405619502067566
Validation loss: 2.1957427006895824

Epoch: 73| Step: 0
Training loss: 2.3276596069335938
Validation loss: 2.219569197265051

Epoch: 6| Step: 1
Training loss: 1.7497522830963135
Validation loss: 2.2119132498259186

Epoch: 6| Step: 2
Training loss: 1.4161522388458252
Validation loss: 2.2143358338263726

Epoch: 6| Step: 3
Training loss: 2.994119644165039
Validation loss: 2.256114862298453

Epoch: 6| Step: 4
Training loss: 2.8530211448669434
Validation loss: 2.2844317959200953

Epoch: 6| Step: 5
Training loss: 2.1288063526153564
Validation loss: 2.2467610297664518

Epoch: 6| Step: 6
Training loss: 2.6203513145446777
Validation loss: 2.215097147931335

Epoch: 6| Step: 7
Training loss: 2.9788472652435303
Validation loss: 2.1835225666722944

Epoch: 6| Step: 8
Training loss: 2.673008680343628
Validation loss: 2.1571959757035777

Epoch: 6| Step: 9
Training loss: 2.7492971420288086
Validation loss: 2.15947530346532

Epoch: 6| Step: 10
Training loss: 2.912271738052368
Validation loss: 2.157917668742518

Epoch: 6| Step: 11
Training loss: 2.279026508331299
Validation loss: 2.1569583569803545

Epoch: 6| Step: 12
Training loss: 2.604691982269287
Validation loss: 2.165795467233145

Epoch: 6| Step: 13
Training loss: 1.9714617729187012
Validation loss: 2.175486074980869

Epoch: 74| Step: 0
Training loss: 1.9306325912475586
Validation loss: 2.164788084645425

Epoch: 6| Step: 1
Training loss: 2.1370925903320312
Validation loss: 2.1525038673031713

Epoch: 6| Step: 2
Training loss: 2.897721767425537
Validation loss: 2.1475816349829397

Epoch: 6| Step: 3
Training loss: 2.399102210998535
Validation loss: 2.163586055078814

Epoch: 6| Step: 4
Training loss: 2.4762203693389893
Validation loss: 2.1658834295888103

Epoch: 6| Step: 5
Training loss: 2.5291574001312256
Validation loss: 2.1731050001677645

Epoch: 6| Step: 6
Training loss: 3.1675169467926025
Validation loss: 2.182346870822291

Epoch: 6| Step: 7
Training loss: 2.1810081005096436
Validation loss: 2.212989976329188

Epoch: 6| Step: 8
Training loss: 2.563363552093506
Validation loss: 2.209711600375432

Epoch: 6| Step: 9
Training loss: 2.5440902709960938
Validation loss: 2.2044654405245216

Epoch: 6| Step: 10
Training loss: 2.81240177154541
Validation loss: 2.2038084127569713

Epoch: 6| Step: 11
Training loss: 2.329219102859497
Validation loss: 2.1831461998724166

Epoch: 6| Step: 12
Training loss: 2.261875629425049
Validation loss: 2.1788644636830976

Epoch: 6| Step: 13
Training loss: 2.2084341049194336
Validation loss: 2.1836415221614223

Epoch: 75| Step: 0
Training loss: 2.7884278297424316
Validation loss: 2.2007912153838785

Epoch: 6| Step: 1
Training loss: 2.3735456466674805
Validation loss: 2.184294375040198

Epoch: 6| Step: 2
Training loss: 2.9111127853393555
Validation loss: 2.1887172358010405

Epoch: 6| Step: 3
Training loss: 2.7463631629943848
Validation loss: 2.174073060353597

Epoch: 6| Step: 4
Training loss: 1.6308636665344238
Validation loss: 2.173138080104705

Epoch: 6| Step: 5
Training loss: 2.713693141937256
Validation loss: 2.2137145239819764

Epoch: 6| Step: 6
Training loss: 2.2927379608154297
Validation loss: 2.2250887552897134

Epoch: 6| Step: 7
Training loss: 1.9661242961883545
Validation loss: 2.2107078926537627

Epoch: 6| Step: 8
Training loss: 2.356370449066162
Validation loss: 2.187294578039518

Epoch: 6| Step: 9
Training loss: 2.5541672706604004
Validation loss: 2.159155853333012

Epoch: 6| Step: 10
Training loss: 2.5414888858795166
Validation loss: 2.1515115922497166

Epoch: 6| Step: 11
Training loss: 2.746307611465454
Validation loss: 2.1374103125705513

Epoch: 6| Step: 12
Training loss: 2.2422561645507812
Validation loss: 2.1312243656445573

Epoch: 6| Step: 13
Training loss: 2.2618470191955566
Validation loss: 2.139538893135645

Epoch: 76| Step: 0
Training loss: 2.3994264602661133
Validation loss: 2.1499929223009335

Epoch: 6| Step: 1
Training loss: 3.0185317993164062
Validation loss: 2.1513142149935485

Epoch: 6| Step: 2
Training loss: 2.117321491241455
Validation loss: 2.155382904955136

Epoch: 6| Step: 3
Training loss: 2.4396605491638184
Validation loss: 2.16014914999726

Epoch: 6| Step: 4
Training loss: 2.2407989501953125
Validation loss: 2.1628112536604687

Epoch: 6| Step: 5
Training loss: 2.5840773582458496
Validation loss: 2.159810550751225

Epoch: 6| Step: 6
Training loss: 2.146728038787842
Validation loss: 2.1552436608140186

Epoch: 6| Step: 7
Training loss: 2.6160221099853516
Validation loss: 2.147944173505229

Epoch: 6| Step: 8
Training loss: 2.6751303672790527
Validation loss: 2.138147774563041

Epoch: 6| Step: 9
Training loss: 2.5666637420654297
Validation loss: 2.129227207553002

Epoch: 6| Step: 10
Training loss: 1.824984073638916
Validation loss: 2.127901236216227

Epoch: 6| Step: 11
Training loss: 2.6462864875793457
Validation loss: 2.12786429671831

Epoch: 6| Step: 12
Training loss: 2.8849639892578125
Validation loss: 2.1709288832961873

Epoch: 6| Step: 13
Training loss: 2.374931812286377
Validation loss: 2.2212433507365565

Epoch: 77| Step: 0
Training loss: 2.398120641708374
Validation loss: 2.23596005798668

Epoch: 6| Step: 1
Training loss: 2.0508527755737305
Validation loss: 2.2441453344078472

Epoch: 6| Step: 2
Training loss: 2.652895450592041
Validation loss: 2.190826092996905

Epoch: 6| Step: 3
Training loss: 2.847724199295044
Validation loss: 2.1548984589115268

Epoch: 6| Step: 4
Training loss: 2.013056755065918
Validation loss: 2.1288751376572477

Epoch: 6| Step: 5
Training loss: 2.2845380306243896
Validation loss: 2.124372237472124

Epoch: 6| Step: 6
Training loss: 2.7418012619018555
Validation loss: 2.1363178594138033

Epoch: 6| Step: 7
Training loss: 3.0945816040039062
Validation loss: 2.1314033821064937

Epoch: 6| Step: 8
Training loss: 3.1707327365875244
Validation loss: 2.135677276119109

Epoch: 6| Step: 9
Training loss: 2.7513628005981445
Validation loss: 2.136942953191778

Epoch: 6| Step: 10
Training loss: 2.207146406173706
Validation loss: 2.1301373179240892

Epoch: 6| Step: 11
Training loss: 1.7995717525482178
Validation loss: 2.1284952714879024

Epoch: 6| Step: 12
Training loss: 2.553405284881592
Validation loss: 2.145454740011564

Epoch: 6| Step: 13
Training loss: 1.118231177330017
Validation loss: 2.1682180230335524

Epoch: 78| Step: 0
Training loss: 2.310831069946289
Validation loss: 2.1999153680698846

Epoch: 6| Step: 1
Training loss: 2.3678386211395264
Validation loss: 2.2286789929994972

Epoch: 6| Step: 2
Training loss: 1.9832572937011719
Validation loss: 2.2153526762480378

Epoch: 6| Step: 3
Training loss: 2.9066805839538574
Validation loss: 2.1937068739245014

Epoch: 6| Step: 4
Training loss: 2.230703830718994
Validation loss: 2.194084164916828

Epoch: 6| Step: 5
Training loss: 2.382701873779297
Validation loss: 2.178836376436295

Epoch: 6| Step: 6
Training loss: 2.3101646900177
Validation loss: 2.1510874443156744

Epoch: 6| Step: 7
Training loss: 2.8614675998687744
Validation loss: 2.1286601686990387

Epoch: 6| Step: 8
Training loss: 2.756483793258667
Validation loss: 2.120417905110185

Epoch: 6| Step: 9
Training loss: 2.911594867706299
Validation loss: 2.132172502497191

Epoch: 6| Step: 10
Training loss: 1.7411093711853027
Validation loss: 2.1419623846648843

Epoch: 6| Step: 11
Training loss: 2.606335163116455
Validation loss: 2.1497409036082606

Epoch: 6| Step: 12
Training loss: 2.364886522293091
Validation loss: 2.155063321513514

Epoch: 6| Step: 13
Training loss: 2.801429510116577
Validation loss: 2.153869410996796

Epoch: 79| Step: 0
Training loss: 2.7043511867523193
Validation loss: 2.14597596404373

Epoch: 6| Step: 1
Training loss: 2.676547050476074
Validation loss: 2.1361514676001763

Epoch: 6| Step: 2
Training loss: 2.4337356090545654
Validation loss: 2.1316405432198637

Epoch: 6| Step: 3
Training loss: 2.7501916885375977
Validation loss: 2.122886706424016

Epoch: 6| Step: 4
Training loss: 2.544820785522461
Validation loss: 2.113804796690582

Epoch: 6| Step: 5
Training loss: 2.0098655223846436
Validation loss: 2.1203824730329615

Epoch: 6| Step: 6
Training loss: 2.332015037536621
Validation loss: 2.1669811689725487

Epoch: 6| Step: 7
Training loss: 2.166670322418213
Validation loss: 2.2333281783647436

Epoch: 6| Step: 8
Training loss: 3.288602352142334
Validation loss: 2.3311147330909647

Epoch: 6| Step: 9
Training loss: 2.1159141063690186
Validation loss: 2.4186718310079267

Epoch: 6| Step: 10
Training loss: 2.954859495162964
Validation loss: 2.469725731880434

Epoch: 6| Step: 11
Training loss: 3.0437397956848145
Validation loss: 2.462786013080228

Epoch: 6| Step: 12
Training loss: 1.5230450630187988
Validation loss: 2.3425233966560772

Epoch: 6| Step: 13
Training loss: 2.193361759185791
Validation loss: 2.209815658548827

Epoch: 80| Step: 0
Training loss: 2.2675766944885254
Validation loss: 2.1395376523335776

Epoch: 6| Step: 1
Training loss: 2.668713092803955
Validation loss: 2.122643393854941

Epoch: 6| Step: 2
Training loss: 1.9780075550079346
Validation loss: 2.132265248606282

Epoch: 6| Step: 3
Training loss: 2.095644950866699
Validation loss: 2.127083679681183

Epoch: 6| Step: 4
Training loss: 2.2263848781585693
Validation loss: 2.126793328151908

Epoch: 6| Step: 5
Training loss: 1.9893828630447388
Validation loss: 2.1265722731108307

Epoch: 6| Step: 6
Training loss: 2.8356733322143555
Validation loss: 2.1193942895499607

Epoch: 6| Step: 7
Training loss: 2.630899429321289
Validation loss: 2.113875704426919

Epoch: 6| Step: 8
Training loss: 2.446207284927368
Validation loss: 2.1067979117875457

Epoch: 6| Step: 9
Training loss: 3.1292169094085693
Validation loss: 2.1068688464421097

Epoch: 6| Step: 10
Training loss: 2.7604660987854004
Validation loss: 2.1022493634172665

Epoch: 6| Step: 11
Training loss: 2.8245325088500977
Validation loss: 2.1038755985998336

Epoch: 6| Step: 12
Training loss: 2.1773626804351807
Validation loss: 2.1087458800244074

Epoch: 6| Step: 13
Training loss: 2.172645330429077
Validation loss: 2.1244191508139334

Epoch: 81| Step: 0
Training loss: 1.7705601453781128
Validation loss: 2.154558515035978

Epoch: 6| Step: 1
Training loss: 2.823413372039795
Validation loss: 2.177448823887815

Epoch: 6| Step: 2
Training loss: 2.6217753887176514
Validation loss: 2.2109084642061623

Epoch: 6| Step: 3
Training loss: 2.0793399810791016
Validation loss: 2.2066552382643505

Epoch: 6| Step: 4
Training loss: 2.743335247039795
Validation loss: 2.2076537224554245

Epoch: 6| Step: 5
Training loss: 2.2919840812683105
Validation loss: 2.222300419243433

Epoch: 6| Step: 6
Training loss: 2.6164073944091797
Validation loss: 2.191047014728669

Epoch: 6| Step: 7
Training loss: 1.9500370025634766
Validation loss: 2.147844649130298

Epoch: 6| Step: 8
Training loss: 2.6705775260925293
Validation loss: 2.1269162047293877

Epoch: 6| Step: 9
Training loss: 2.4782814979553223
Validation loss: 2.124186715772075

Epoch: 6| Step: 10
Training loss: 2.9409265518188477
Validation loss: 2.1040275968531126

Epoch: 6| Step: 11
Training loss: 2.4114608764648438
Validation loss: 2.109038991312827

Epoch: 6| Step: 12
Training loss: 2.4459409713745117
Validation loss: 2.10150174684422

Epoch: 6| Step: 13
Training loss: 2.330583095550537
Validation loss: 2.107484799559398

Epoch: 82| Step: 0
Training loss: 1.8910707235336304
Validation loss: 2.1096361375624135

Epoch: 6| Step: 1
Training loss: 1.7999718189239502
Validation loss: 2.114847885665073

Epoch: 6| Step: 2
Training loss: 2.326301336288452
Validation loss: 2.1198681310940812

Epoch: 6| Step: 3
Training loss: 2.9770095348358154
Validation loss: 2.121411205619894

Epoch: 6| Step: 4
Training loss: 2.5765466690063477
Validation loss: 2.1397693772469797

Epoch: 6| Step: 5
Training loss: 2.0937716960906982
Validation loss: 2.1606468897993847

Epoch: 6| Step: 6
Training loss: 2.593339443206787
Validation loss: 2.197000398430773

Epoch: 6| Step: 7
Training loss: 3.135382890701294
Validation loss: 2.2382149004167124

Epoch: 6| Step: 8
Training loss: 2.6450798511505127
Validation loss: 2.260168203743555

Epoch: 6| Step: 9
Training loss: 2.4431002140045166
Validation loss: 2.246308475412348

Epoch: 6| Step: 10
Training loss: 2.5020294189453125
Validation loss: 2.204118877328852

Epoch: 6| Step: 11
Training loss: 1.8571949005126953
Validation loss: 2.1725906108015325

Epoch: 6| Step: 12
Training loss: 2.3989784717559814
Validation loss: 2.1378671251317507

Epoch: 6| Step: 13
Training loss: 2.964189291000366
Validation loss: 2.12742555269631

Epoch: 83| Step: 0
Training loss: 1.8427423238754272
Validation loss: 2.117144805128856

Epoch: 6| Step: 1
Training loss: 2.1006627082824707
Validation loss: 2.1150478752710486

Epoch: 6| Step: 2
Training loss: 2.8878750801086426
Validation loss: 2.1116746446137786

Epoch: 6| Step: 3
Training loss: 3.0647788047790527
Validation loss: 2.1102386059299594

Epoch: 6| Step: 4
Training loss: 2.420138359069824
Validation loss: 2.1096028127977924

Epoch: 6| Step: 5
Training loss: 1.7478506565093994
Validation loss: 2.109941695326118

Epoch: 6| Step: 6
Training loss: 3.2978100776672363
Validation loss: 2.122258468340802

Epoch: 6| Step: 7
Training loss: 2.6579999923706055
Validation loss: 2.119939440040178

Epoch: 6| Step: 8
Training loss: 2.4033827781677246
Validation loss: 2.116419733211558

Epoch: 6| Step: 9
Training loss: 2.725043535232544
Validation loss: 2.1248863666288313

Epoch: 6| Step: 10
Training loss: 1.5532902479171753
Validation loss: 2.123330291881356

Epoch: 6| Step: 11
Training loss: 2.250153064727783
Validation loss: 2.1390444001843854

Epoch: 6| Step: 12
Training loss: 2.35551118850708
Validation loss: 2.1538266289618706

Epoch: 6| Step: 13
Training loss: 2.282819986343384
Validation loss: 2.1704318138860885

Epoch: 84| Step: 0
Training loss: 2.0318684577941895
Validation loss: 2.1832787862388034

Epoch: 6| Step: 1
Training loss: 1.8816537857055664
Validation loss: 2.187670846139231

Epoch: 6| Step: 2
Training loss: 2.4574356079101562
Validation loss: 2.1678333974653676

Epoch: 6| Step: 3
Training loss: 2.731555938720703
Validation loss: 2.1560715680481284

Epoch: 6| Step: 4
Training loss: 2.1879570484161377
Validation loss: 2.141683916891775

Epoch: 6| Step: 5
Training loss: 2.375969171524048
Validation loss: 2.130872130393982

Epoch: 6| Step: 6
Training loss: 2.8841614723205566
Validation loss: 2.1299884832033547

Epoch: 6| Step: 7
Training loss: 2.1656877994537354
Validation loss: 2.13423559229861

Epoch: 6| Step: 8
Training loss: 2.8145103454589844
Validation loss: 2.135124057851812

Epoch: 6| Step: 9
Training loss: 1.6032800674438477
Validation loss: 2.144355886725969

Epoch: 6| Step: 10
Training loss: 1.9942054748535156
Validation loss: 2.1524426270556707

Epoch: 6| Step: 11
Training loss: 2.5723824501037598
Validation loss: 2.163665743284328

Epoch: 6| Step: 12
Training loss: 2.878026008605957
Validation loss: 2.173194710926343

Epoch: 6| Step: 13
Training loss: 3.281540870666504
Validation loss: 2.1774974535870295

Epoch: 85| Step: 0
Training loss: 2.4801154136657715
Validation loss: 2.1697440967764905

Epoch: 6| Step: 1
Training loss: 2.2856605052948
Validation loss: 2.172801965026445

Epoch: 6| Step: 2
Training loss: 2.3645708560943604
Validation loss: 2.1598672559184413

Epoch: 6| Step: 3
Training loss: 2.9369044303894043
Validation loss: 2.1454225906761746

Epoch: 6| Step: 4
Training loss: 2.208655834197998
Validation loss: 2.118787811648461

Epoch: 6| Step: 5
Training loss: 1.5052732229232788
Validation loss: 2.1050013393484135

Epoch: 6| Step: 6
Training loss: 2.1989669799804688
Validation loss: 2.101405237310676

Epoch: 6| Step: 7
Training loss: 2.1531319618225098
Validation loss: 2.1095660630092827

Epoch: 6| Step: 8
Training loss: 2.222576141357422
Validation loss: 2.118364113633351

Epoch: 6| Step: 9
Training loss: 2.5171003341674805
Validation loss: 2.1176190389099943

Epoch: 6| Step: 10
Training loss: 2.754093647003174
Validation loss: 2.1226012155573857

Epoch: 6| Step: 11
Training loss: 2.3906829357147217
Validation loss: 2.131832242012024

Epoch: 6| Step: 12
Training loss: 2.601839065551758
Validation loss: 2.1452514022909184

Epoch: 6| Step: 13
Training loss: 2.8620545864105225
Validation loss: 2.1802218960177515

Epoch: 86| Step: 0
Training loss: 2.9010252952575684
Validation loss: 2.2177837189807685

Epoch: 6| Step: 1
Training loss: 3.0248327255249023
Validation loss: 2.244088657440678

Epoch: 6| Step: 2
Training loss: 2.189164876937866
Validation loss: 2.256440926623601

Epoch: 6| Step: 3
Training loss: 2.9112329483032227
Validation loss: 2.2359664542700655

Epoch: 6| Step: 4
Training loss: 1.8388071060180664
Validation loss: 2.1968161085600495

Epoch: 6| Step: 5
Training loss: 2.1669530868530273
Validation loss: 2.1732975898250455

Epoch: 6| Step: 6
Training loss: 2.471770763397217
Validation loss: 2.1379430909310617

Epoch: 6| Step: 7
Training loss: 2.1552109718322754
Validation loss: 2.148276931496077

Epoch: 6| Step: 8
Training loss: 2.441216468811035
Validation loss: 2.1302551172112905

Epoch: 6| Step: 9
Training loss: 2.1722278594970703
Validation loss: 2.130545177767354

Epoch: 6| Step: 10
Training loss: 1.806715488433838
Validation loss: 2.1596289245031213

Epoch: 6| Step: 11
Training loss: 2.344743013381958
Validation loss: 2.1730090982170513

Epoch: 6| Step: 12
Training loss: 2.6087565422058105
Validation loss: 2.14002880742473

Epoch: 6| Step: 13
Training loss: 2.061725616455078
Validation loss: 2.1202074558504167

Epoch: 87| Step: 0
Training loss: 2.852374792098999
Validation loss: 2.1147797223060363

Epoch: 6| Step: 1
Training loss: 2.165398597717285
Validation loss: 2.0915478749941756

Epoch: 6| Step: 2
Training loss: 2.7895219326019287
Validation loss: 2.0925010173551497

Epoch: 6| Step: 3
Training loss: 2.1795291900634766
Validation loss: 2.107109938898394

Epoch: 6| Step: 4
Training loss: 2.718174695968628
Validation loss: 2.1134885562363492

Epoch: 6| Step: 5
Training loss: 2.957508087158203
Validation loss: 2.145432992648053

Epoch: 6| Step: 6
Training loss: 2.37111234664917
Validation loss: 2.176031715126448

Epoch: 6| Step: 7
Training loss: 2.364407539367676
Validation loss: 2.181307920845606

Epoch: 6| Step: 8
Training loss: 2.3780202865600586
Validation loss: 2.196926598907799

Epoch: 6| Step: 9
Training loss: 2.105273962020874
Validation loss: 2.1912904593252365

Epoch: 6| Step: 10
Training loss: 2.122363567352295
Validation loss: 2.1571489277706353

Epoch: 6| Step: 11
Training loss: 2.029507875442505
Validation loss: 2.1228850631303686

Epoch: 6| Step: 12
Training loss: 2.0430445671081543
Validation loss: 2.1092082146675355

Epoch: 6| Step: 13
Training loss: 1.9899893999099731
Validation loss: 2.1082034444296234

Epoch: 88| Step: 0
Training loss: 3.317356586456299
Validation loss: 2.1367408434549966

Epoch: 6| Step: 1
Training loss: 2.4205210208892822
Validation loss: 2.1714826758189867

Epoch: 6| Step: 2
Training loss: 2.490720272064209
Validation loss: 2.1776753907562583

Epoch: 6| Step: 3
Training loss: 1.5954558849334717
Validation loss: 2.1596293372492634

Epoch: 6| Step: 4
Training loss: 1.6723294258117676
Validation loss: 2.1315998736248223

Epoch: 6| Step: 5
Training loss: 2.779275894165039
Validation loss: 2.1252718356347855

Epoch: 6| Step: 6
Training loss: 1.7014966011047363
Validation loss: 2.124201766906246

Epoch: 6| Step: 7
Training loss: 2.7810254096984863
Validation loss: 2.1138666791300618

Epoch: 6| Step: 8
Training loss: 2.1684815883636475
Validation loss: 2.0963192985903834

Epoch: 6| Step: 9
Training loss: 2.7074060440063477
Validation loss: 2.0945092631924536

Epoch: 6| Step: 10
Training loss: 2.2076549530029297
Validation loss: 2.0950948281954695

Epoch: 6| Step: 11
Training loss: 2.8117125034332275
Validation loss: 2.1175434179203485

Epoch: 6| Step: 12
Training loss: 2.198474407196045
Validation loss: 2.133297276753251

Epoch: 6| Step: 13
Training loss: 1.8597115278244019
Validation loss: 2.159502849783949

Epoch: 89| Step: 0
Training loss: 2.5114898681640625
Validation loss: 2.157509162861814

Epoch: 6| Step: 1
Training loss: 2.607954740524292
Validation loss: 2.187499682108561

Epoch: 6| Step: 2
Training loss: 2.92128849029541
Validation loss: 2.2265999509442236

Epoch: 6| Step: 3
Training loss: 2.8612265586853027
Validation loss: 2.2349019127507366

Epoch: 6| Step: 4
Training loss: 2.606388568878174
Validation loss: 2.2570435283004597

Epoch: 6| Step: 5
Training loss: 2.2445313930511475
Validation loss: 2.249154931755476

Epoch: 6| Step: 6
Training loss: 2.231689214706421
Validation loss: 2.161557644926092

Epoch: 6| Step: 7
Training loss: 2.224008321762085
Validation loss: 2.1072622806795183

Epoch: 6| Step: 8
Training loss: 1.8733261823654175
Validation loss: 2.1132162796553744

Epoch: 6| Step: 9
Training loss: 2.3821067810058594
Validation loss: 2.133047244882071

Epoch: 6| Step: 10
Training loss: 1.7856385707855225
Validation loss: 2.132523126499627

Epoch: 6| Step: 11
Training loss: 3.1210360527038574
Validation loss: 2.124524524134974

Epoch: 6| Step: 12
Training loss: 2.1479334831237793
Validation loss: 2.0960575047359673

Epoch: 6| Step: 13
Training loss: 2.0762176513671875
Validation loss: 2.0729108087478147

Epoch: 90| Step: 0
Training loss: 2.251570224761963
Validation loss: 2.069065927177347

Epoch: 6| Step: 1
Training loss: 1.647958517074585
Validation loss: 2.061867360145815

Epoch: 6| Step: 2
Training loss: 2.5611085891723633
Validation loss: 2.070690498557142

Epoch: 6| Step: 3
Training loss: 3.3902363777160645
Validation loss: 2.0958400990373347

Epoch: 6| Step: 4
Training loss: 3.453312635421753
Validation loss: 2.1041403278227775

Epoch: 6| Step: 5
Training loss: 2.7223639488220215
Validation loss: 2.1209298974724224

Epoch: 6| Step: 6
Training loss: 2.32124662399292
Validation loss: 2.118916755081505

Epoch: 6| Step: 7
Training loss: 2.1929728984832764
Validation loss: 2.1080492952818513

Epoch: 6| Step: 8
Training loss: 2.3865084648132324
Validation loss: 2.0821775544074272

Epoch: 6| Step: 9
Training loss: 2.064413070678711
Validation loss: 2.0638456434331913

Epoch: 6| Step: 10
Training loss: 2.00485897064209
Validation loss: 2.0546704223079066

Epoch: 6| Step: 11
Training loss: 2.2001187801361084
Validation loss: 2.045354066356536

Epoch: 6| Step: 12
Training loss: 1.829309344291687
Validation loss: 2.0496220563047673

Epoch: 6| Step: 13
Training loss: 2.1512699127197266
Validation loss: 2.046828519913458

Epoch: 91| Step: 0
Training loss: 3.0157289505004883
Validation loss: 2.057057560131114

Epoch: 6| Step: 1
Training loss: 2.492652177810669
Validation loss: 2.0630018454726025

Epoch: 6| Step: 2
Training loss: 1.8138630390167236
Validation loss: 2.0660138924916587

Epoch: 6| Step: 3
Training loss: 2.3857340812683105
Validation loss: 2.0658992490460797

Epoch: 6| Step: 4
Training loss: 2.651907444000244
Validation loss: 2.0689314001349994

Epoch: 6| Step: 5
Training loss: 2.704753875732422
Validation loss: 2.0584931271050566

Epoch: 6| Step: 6
Training loss: 2.1722354888916016
Validation loss: 2.057618066828738

Epoch: 6| Step: 7
Training loss: 2.362592935562134
Validation loss: 2.052940942907846

Epoch: 6| Step: 8
Training loss: 1.5471876859664917
Validation loss: 2.0595823616109867

Epoch: 6| Step: 9
Training loss: 2.800107002258301
Validation loss: 2.062812489847983

Epoch: 6| Step: 10
Training loss: 1.848022222518921
Validation loss: 2.063218398760724

Epoch: 6| Step: 11
Training loss: 1.8431065082550049
Validation loss: 2.087388410363146

Epoch: 6| Step: 12
Training loss: 2.6210837364196777
Validation loss: 2.0696790705444994

Epoch: 6| Step: 13
Training loss: 2.421114921569824
Validation loss: 2.0596153402841217

Epoch: 92| Step: 0
Training loss: 1.8157846927642822
Validation loss: 2.0753953790151947

Epoch: 6| Step: 1
Training loss: 2.006922721862793
Validation loss: 2.072328198340631

Epoch: 6| Step: 2
Training loss: 3.129647970199585
Validation loss: 2.0961781112096642

Epoch: 6| Step: 3
Training loss: 2.116687774658203
Validation loss: 2.1451425783095823

Epoch: 6| Step: 4
Training loss: 2.678823232650757
Validation loss: 2.1699460373129895

Epoch: 6| Step: 5
Training loss: 1.821582555770874
Validation loss: 2.194828087283719

Epoch: 6| Step: 6
Training loss: 2.5828139781951904
Validation loss: 2.1367691409203315

Epoch: 6| Step: 7
Training loss: 2.5566868782043457
Validation loss: 2.0919724113197735

Epoch: 6| Step: 8
Training loss: 2.4489262104034424
Validation loss: 2.048186316285082

Epoch: 6| Step: 9
Training loss: 3.175689697265625
Validation loss: 2.0439012947902886

Epoch: 6| Step: 10
Training loss: 1.1395390033721924
Validation loss: 2.0490547790322253

Epoch: 6| Step: 11
Training loss: 2.812100887298584
Validation loss: 2.0622109110637377

Epoch: 6| Step: 12
Training loss: 2.4868428707122803
Validation loss: 2.0832798814260833

Epoch: 6| Step: 13
Training loss: 2.188271999359131
Validation loss: 2.1152372411502305

Epoch: 93| Step: 0
Training loss: 2.3735978603363037
Validation loss: 2.098101903033513

Epoch: 6| Step: 1
Training loss: 2.412456512451172
Validation loss: 2.1012953968458277

Epoch: 6| Step: 2
Training loss: 2.5981454849243164
Validation loss: 2.120546956216135

Epoch: 6| Step: 3
Training loss: 2.5041251182556152
Validation loss: 2.143010039483347

Epoch: 6| Step: 4
Training loss: 2.575371742248535
Validation loss: 2.101396717051024

Epoch: 6| Step: 5
Training loss: 2.228337049484253
Validation loss: 2.0707731016220583

Epoch: 6| Step: 6
Training loss: 1.679258942604065
Validation loss: 2.0486618793138893

Epoch: 6| Step: 7
Training loss: 1.9895508289337158
Validation loss: 2.0346721782479236

Epoch: 6| Step: 8
Training loss: 2.0725769996643066
Validation loss: 2.0382693224055792

Epoch: 6| Step: 9
Training loss: 2.9457645416259766
Validation loss: 2.042829341785882

Epoch: 6| Step: 10
Training loss: 2.1643543243408203
Validation loss: 2.0752909427048056

Epoch: 6| Step: 11
Training loss: 2.56626033782959
Validation loss: 2.1049654560704387

Epoch: 6| Step: 12
Training loss: 2.442662477493286
Validation loss: 2.134128934593611

Epoch: 6| Step: 13
Training loss: 2.4305410385131836
Validation loss: 2.1283202850690452

Epoch: 94| Step: 0
Training loss: 1.4915887117385864
Validation loss: 2.0742474345750708

Epoch: 6| Step: 1
Training loss: 2.7401134967803955
Validation loss: 2.041380875854082

Epoch: 6| Step: 2
Training loss: 1.7896029949188232
Validation loss: 2.0353993600414646

Epoch: 6| Step: 3
Training loss: 1.8039891719818115
Validation loss: 2.0354225866256224

Epoch: 6| Step: 4
Training loss: 2.6015665531158447
Validation loss: 2.0296878968515704

Epoch: 6| Step: 5
Training loss: 1.9347590208053589
Validation loss: 2.03395333597737

Epoch: 6| Step: 6
Training loss: 2.346825122833252
Validation loss: 2.0328067720577283

Epoch: 6| Step: 7
Training loss: 3.1633996963500977
Validation loss: 2.058448312103107

Epoch: 6| Step: 8
Training loss: 2.26760196685791
Validation loss: 2.1185630393284622

Epoch: 6| Step: 9
Training loss: 2.122387170791626
Validation loss: 2.1719702289950464

Epoch: 6| Step: 10
Training loss: 2.967996835708618
Validation loss: 2.1661216546130437

Epoch: 6| Step: 11
Training loss: 2.1050209999084473
Validation loss: 2.161675291676675

Epoch: 6| Step: 12
Training loss: 2.499912738800049
Validation loss: 2.1786104761144167

Epoch: 6| Step: 13
Training loss: 2.8556225299835205
Validation loss: 2.1676961350184616

Epoch: 95| Step: 0
Training loss: 1.6155412197113037
Validation loss: 2.1279769815424436

Epoch: 6| Step: 1
Training loss: 2.095991611480713
Validation loss: 2.0899634873995216

Epoch: 6| Step: 2
Training loss: 1.4990997314453125
Validation loss: 2.056546882916522

Epoch: 6| Step: 3
Training loss: 2.7139031887054443
Validation loss: 2.0468985662665418

Epoch: 6| Step: 4
Training loss: 2.7747950553894043
Validation loss: 2.044192461557286

Epoch: 6| Step: 5
Training loss: 2.403223752975464
Validation loss: 2.0472991235794558

Epoch: 6| Step: 6
Training loss: 2.3956754207611084
Validation loss: 2.0468955834706626

Epoch: 6| Step: 7
Training loss: 2.428886890411377
Validation loss: 2.0463003317515054

Epoch: 6| Step: 8
Training loss: 2.532381772994995
Validation loss: 2.044754553866643

Epoch: 6| Step: 9
Training loss: 2.322091817855835
Validation loss: 2.0456190416889806

Epoch: 6| Step: 10
Training loss: 2.0370612144470215
Validation loss: 2.0342398458911526

Epoch: 6| Step: 11
Training loss: 2.212782382965088
Validation loss: 2.0365176739231234

Epoch: 6| Step: 12
Training loss: 2.729217052459717
Validation loss: 2.0341164027490923

Epoch: 6| Step: 13
Training loss: 3.216998815536499
Validation loss: 2.038599307819079

Epoch: 96| Step: 0
Training loss: 2.029155731201172
Validation loss: 2.0396834265801216

Epoch: 6| Step: 1
Training loss: 2.3341622352600098
Validation loss: 2.0416212466455277

Epoch: 6| Step: 2
Training loss: 2.4687676429748535
Validation loss: 2.044476821858396

Epoch: 6| Step: 3
Training loss: 2.1153717041015625
Validation loss: 2.038797147812382

Epoch: 6| Step: 4
Training loss: 2.474302291870117
Validation loss: 2.0541085273988786

Epoch: 6| Step: 5
Training loss: 1.8877267837524414
Validation loss: 2.070887509212699

Epoch: 6| Step: 6
Training loss: 2.1598949432373047
Validation loss: 2.1266530867545836

Epoch: 6| Step: 7
Training loss: 3.0121374130249023
Validation loss: 2.193394563531363

Epoch: 6| Step: 8
Training loss: 2.2287797927856445
Validation loss: 2.2335894748728764

Epoch: 6| Step: 9
Training loss: 2.576169967651367
Validation loss: 2.211373890599897

Epoch: 6| Step: 10
Training loss: 1.797169804573059
Validation loss: 2.1826358995129986

Epoch: 6| Step: 11
Training loss: 1.8910017013549805
Validation loss: 2.110679018882013

Epoch: 6| Step: 12
Training loss: 2.8922557830810547
Validation loss: 2.0334972091900405

Epoch: 6| Step: 13
Training loss: 3.05745267868042
Validation loss: 2.018016892094766

Epoch: 97| Step: 0
Training loss: 2.4976799488067627
Validation loss: 2.0315322952885784

Epoch: 6| Step: 1
Training loss: 1.8323545455932617
Validation loss: 2.0373973077343357

Epoch: 6| Step: 2
Training loss: 2.8150787353515625
Validation loss: 2.0422311957164476

Epoch: 6| Step: 3
Training loss: 2.3143749237060547
Validation loss: 2.049840386195849

Epoch: 6| Step: 4
Training loss: 1.7016053199768066
Validation loss: 2.0392733209876606

Epoch: 6| Step: 5
Training loss: 1.9057204723358154
Validation loss: 2.033275527338828

Epoch: 6| Step: 6
Training loss: 2.758850574493408
Validation loss: 2.0425874956192507

Epoch: 6| Step: 7
Training loss: 2.6171674728393555
Validation loss: 2.0449514030128397

Epoch: 6| Step: 8
Training loss: 2.3915205001831055
Validation loss: 2.0652532436514415

Epoch: 6| Step: 9
Training loss: 2.3799972534179688
Validation loss: 2.080197439398817

Epoch: 6| Step: 10
Training loss: 2.6642439365386963
Validation loss: 2.1110388360997683

Epoch: 6| Step: 11
Training loss: 2.7520008087158203
Validation loss: 2.103315873812604

Epoch: 6| Step: 12
Training loss: 2.0931668281555176
Validation loss: 2.1116750547962804

Epoch: 6| Step: 13
Training loss: 1.515259861946106
Validation loss: 2.1323433819637505

Epoch: 98| Step: 0
Training loss: 2.1009292602539062
Validation loss: 2.1141119926206526

Epoch: 6| Step: 1
Training loss: 1.8854683637619019
Validation loss: 2.0759767178566224

Epoch: 6| Step: 2
Training loss: 3.0441482067108154
Validation loss: 2.0594706945521857

Epoch: 6| Step: 3
Training loss: 2.6162185668945312
Validation loss: 2.0406526519406225

Epoch: 6| Step: 4
Training loss: 2.1170167922973633
Validation loss: 2.0196521038650186

Epoch: 6| Step: 5
Training loss: 1.9889709949493408
Validation loss: 2.0175387936253704

Epoch: 6| Step: 6
Training loss: 2.5573482513427734
Validation loss: 2.0211551227877216

Epoch: 6| Step: 7
Training loss: 1.8608381748199463
Validation loss: 2.0277401349877797

Epoch: 6| Step: 8
Training loss: 2.016911506652832
Validation loss: 2.056590700662264

Epoch: 6| Step: 9
Training loss: 2.796395778656006
Validation loss: 2.0915805755123014

Epoch: 6| Step: 10
Training loss: 2.8995707035064697
Validation loss: 2.101026911889353

Epoch: 6| Step: 11
Training loss: 2.262460708618164
Validation loss: 2.1009298704003774

Epoch: 6| Step: 12
Training loss: 1.9201633930206299
Validation loss: 2.104383478882492

Epoch: 6| Step: 13
Training loss: 1.9877387285232544
Validation loss: 2.1046658344166254

Epoch: 99| Step: 0
Training loss: 2.130826950073242
Validation loss: 2.1205903791612193

Epoch: 6| Step: 1
Training loss: 2.982637405395508
Validation loss: 2.134018362209361

Epoch: 6| Step: 2
Training loss: 2.031710624694824
Validation loss: 2.1400247081633537

Epoch: 6| Step: 3
Training loss: 2.566951274871826
Validation loss: 2.1609768047127673

Epoch: 6| Step: 4
Training loss: 1.7556836605072021
Validation loss: 2.136854910081433

Epoch: 6| Step: 5
Training loss: 2.03385066986084
Validation loss: 2.0832740542709187

Epoch: 6| Step: 6
Training loss: 2.1079421043395996
Validation loss: 2.0692076683044434

Epoch: 6| Step: 7
Training loss: 2.2492308616638184
Validation loss: 2.0348945843276156

Epoch: 6| Step: 8
Training loss: 1.6824302673339844
Validation loss: 2.0245184975285686

Epoch: 6| Step: 9
Training loss: 2.3985414505004883
Validation loss: 2.0332225804687827

Epoch: 6| Step: 10
Training loss: 2.6422183513641357
Validation loss: 2.0325821420197845

Epoch: 6| Step: 11
Training loss: 2.9481985569000244
Validation loss: 2.0557229134344284

Epoch: 6| Step: 12
Training loss: 2.332188606262207
Validation loss: 2.0764063917180544

Epoch: 6| Step: 13
Training loss: 2.455030679702759
Validation loss: 2.0899430218563286

Epoch: 100| Step: 0
Training loss: 1.9415466785430908
Validation loss: 2.0889155454533075

Epoch: 6| Step: 1
Training loss: 1.7637112140655518
Validation loss: 2.075347815790484

Epoch: 6| Step: 2
Training loss: 2.9108269214630127
Validation loss: 2.0537593236533542

Epoch: 6| Step: 3
Training loss: 2.1283674240112305
Validation loss: 2.0482515160755446

Epoch: 6| Step: 4
Training loss: 2.6098508834838867
Validation loss: 2.0675465214637017

Epoch: 6| Step: 5
Training loss: 2.9263336658477783
Validation loss: 2.0653924480561288

Epoch: 6| Step: 6
Training loss: 2.2556920051574707
Validation loss: 2.0601850799334946

Epoch: 6| Step: 7
Training loss: 2.473358392715454
Validation loss: 2.070213461434969

Epoch: 6| Step: 8
Training loss: 1.9901924133300781
Validation loss: 2.0498398657768004

Epoch: 6| Step: 9
Training loss: 1.912397027015686
Validation loss: 2.0284633649292814

Epoch: 6| Step: 10
Training loss: 2.6401164531707764
Validation loss: 2.030637659052367

Epoch: 6| Step: 11
Training loss: 1.6154160499572754
Validation loss: 2.062457497401904

Epoch: 6| Step: 12
Training loss: 2.5660033226013184
Validation loss: 2.116618089778449

Epoch: 6| Step: 13
Training loss: 3.1467533111572266
Validation loss: 2.161316866515785

Epoch: 101| Step: 0
Training loss: 2.76104474067688
Validation loss: 2.1586446736448552

Epoch: 6| Step: 1
Training loss: 2.107274293899536
Validation loss: 2.169747019326815

Epoch: 6| Step: 2
Training loss: 2.0014195442199707
Validation loss: 2.1373095191935056

Epoch: 6| Step: 3
Training loss: 2.3070740699768066
Validation loss: 2.110285128316572

Epoch: 6| Step: 4
Training loss: 2.1846365928649902
Validation loss: 2.0749164922263033

Epoch: 6| Step: 5
Training loss: 3.348722457885742
Validation loss: 2.0114032940198014

Epoch: 6| Step: 6
Training loss: 2.2284035682678223
Validation loss: 2.0131345615592053

Epoch: 6| Step: 7
Training loss: 2.7250328063964844
Validation loss: 2.0294971748064925

Epoch: 6| Step: 8
Training loss: 2.667652130126953
Validation loss: 2.0418792668209282

Epoch: 6| Step: 9
Training loss: 1.5290082693099976
Validation loss: 2.048138274941393

Epoch: 6| Step: 10
Training loss: 2.5272207260131836
Validation loss: 2.0577217712197253

Epoch: 6| Step: 11
Training loss: 2.618673324584961
Validation loss: 2.0460419988119476

Epoch: 6| Step: 12
Training loss: 1.832719326019287
Validation loss: 2.0348698669864285

Epoch: 6| Step: 13
Training loss: 1.5973854064941406
Validation loss: 2.0304202341264292

Epoch: 102| Step: 0
Training loss: 1.749952793121338
Validation loss: 2.03234891481297

Epoch: 6| Step: 1
Training loss: 1.9619731903076172
Validation loss: 2.0255095715163858

Epoch: 6| Step: 2
Training loss: 2.18635630607605
Validation loss: 2.034674923907044

Epoch: 6| Step: 3
Training loss: 2.339503765106201
Validation loss: 2.052357845408942

Epoch: 6| Step: 4
Training loss: 2.283069133758545
Validation loss: 2.0611986652497323

Epoch: 6| Step: 5
Training loss: 2.2999467849731445
Validation loss: 2.0605392994419223

Epoch: 6| Step: 6
Training loss: 2.733980178833008
Validation loss: 2.0481255233928723

Epoch: 6| Step: 7
Training loss: 2.7082085609436035
Validation loss: 2.0581195175006823

Epoch: 6| Step: 8
Training loss: 2.8358278274536133
Validation loss: 2.033081805834206

Epoch: 6| Step: 9
Training loss: 1.8258237838745117
Validation loss: 2.043870787466726

Epoch: 6| Step: 10
Training loss: 2.751821517944336
Validation loss: 2.018375145491733

Epoch: 6| Step: 11
Training loss: 2.041733741760254
Validation loss: 2.0191164221814883

Epoch: 6| Step: 12
Training loss: 1.7488468885421753
Validation loss: 2.013475407836258

Epoch: 6| Step: 13
Training loss: 2.6283583641052246
Validation loss: 2.015882795856845

Epoch: 103| Step: 0
Training loss: 2.0995900630950928
Validation loss: 2.0187416486842658

Epoch: 6| Step: 1
Training loss: 2.5659451484680176
Validation loss: 2.0234754752087336

Epoch: 6| Step: 2
Training loss: 2.0809032917022705
Validation loss: 2.050165348155524

Epoch: 6| Step: 3
Training loss: 2.0468108654022217
Validation loss: 2.066122290908649

Epoch: 6| Step: 4
Training loss: 1.8457077741622925
Validation loss: 2.0670151915601505

Epoch: 6| Step: 5
Training loss: 1.7936508655548096
Validation loss: 2.0581906175100677

Epoch: 6| Step: 6
Training loss: 2.9173827171325684
Validation loss: 2.0471220913753716

Epoch: 6| Step: 7
Training loss: 2.8222060203552246
Validation loss: 2.0344715349135862

Epoch: 6| Step: 8
Training loss: 1.9481183290481567
Validation loss: 2.043433000964503

Epoch: 6| Step: 9
Training loss: 1.8251049518585205
Validation loss: 2.0564488928805114

Epoch: 6| Step: 10
Training loss: 2.4295265674591064
Validation loss: 2.0669133393995223

Epoch: 6| Step: 11
Training loss: 2.8696365356445312
Validation loss: 2.0667124076556136

Epoch: 6| Step: 12
Training loss: 2.031343460083008
Validation loss: 2.054449027584445

Epoch: 6| Step: 13
Training loss: 2.357725143432617
Validation loss: 2.028435271273377

Epoch: 104| Step: 0
Training loss: 2.127143383026123
Validation loss: 2.006617192299135

Epoch: 6| Step: 1
Training loss: 2.603411912918091
Validation loss: 2.014062314905146

Epoch: 6| Step: 2
Training loss: 2.01021671295166
Validation loss: 2.0154864659873386

Epoch: 6| Step: 3
Training loss: 2.6644845008850098
Validation loss: 2.020600954691569

Epoch: 6| Step: 4
Training loss: 2.6046760082244873
Validation loss: 2.004993082374655

Epoch: 6| Step: 5
Training loss: 2.040501594543457
Validation loss: 2.005608930382677

Epoch: 6| Step: 6
Training loss: 3.416327476501465
Validation loss: 2.0165268746755456

Epoch: 6| Step: 7
Training loss: 2.6893928050994873
Validation loss: 2.027560431470153

Epoch: 6| Step: 8
Training loss: 2.4470582008361816
Validation loss: 2.0593689385280816

Epoch: 6| Step: 9
Training loss: 2.461961269378662
Validation loss: 2.0678769721779773

Epoch: 6| Step: 10
Training loss: 1.8617899417877197
Validation loss: 2.0903704986777356

Epoch: 6| Step: 11
Training loss: 1.4355828762054443
Validation loss: 2.080714620569701

Epoch: 6| Step: 12
Training loss: 1.6316044330596924
Validation loss: 2.0385571859216176

Epoch: 6| Step: 13
Training loss: 1.628758192062378
Validation loss: 1.9933052498807189

Epoch: 105| Step: 0
Training loss: 2.4664254188537598
Validation loss: 2.020226773395333

Epoch: 6| Step: 1
Training loss: 2.0183491706848145
Validation loss: 2.024092433273151

Epoch: 6| Step: 2
Training loss: 2.116942882537842
Validation loss: 2.0213998056227163

Epoch: 6| Step: 3
Training loss: 2.1248385906219482
Validation loss: 2.0068954908719627

Epoch: 6| Step: 4
Training loss: 2.207099199295044
Validation loss: 2.0213487353376163

Epoch: 6| Step: 5
Training loss: 2.318270444869995
Validation loss: 2.054524408873691

Epoch: 6| Step: 6
Training loss: 2.206012487411499
Validation loss: 2.0964094208132837

Epoch: 6| Step: 7
Training loss: 2.248652935028076
Validation loss: 2.144437082352177

Epoch: 6| Step: 8
Training loss: 2.5695319175720215
Validation loss: 2.170171101888021

Epoch: 6| Step: 9
Training loss: 1.9585447311401367
Validation loss: 2.1596230999115975

Epoch: 6| Step: 10
Training loss: 2.6260595321655273
Validation loss: 2.143315794647381

Epoch: 6| Step: 11
Training loss: 2.3019986152648926
Validation loss: 2.1410294553285003

Epoch: 6| Step: 12
Training loss: 2.4633514881134033
Validation loss: 2.1218819618225098

Epoch: 6| Step: 13
Training loss: 2.1951208114624023
Validation loss: 2.0613868749269875

Epoch: 106| Step: 0
Training loss: 1.964102864265442
Validation loss: 2.02163315011609

Epoch: 6| Step: 1
Training loss: 1.4142630100250244
Validation loss: 2.0054178981370825

Epoch: 6| Step: 2
Training loss: 2.708000898361206
Validation loss: 2.00923994792405

Epoch: 6| Step: 3
Training loss: 2.6122865676879883
Validation loss: 2.018882087481919

Epoch: 6| Step: 4
Training loss: 2.1718482971191406
Validation loss: 2.0281644918585338

Epoch: 6| Step: 5
Training loss: 1.1507916450500488
Validation loss: 2.048242336960249

Epoch: 6| Step: 6
Training loss: 2.4697437286376953
Validation loss: 2.0463028530920706

Epoch: 6| Step: 7
Training loss: 2.1054415702819824
Validation loss: 2.080052525766434

Epoch: 6| Step: 8
Training loss: 2.4516940116882324
Validation loss: 2.0991480965768137

Epoch: 6| Step: 9
Training loss: 3.3229193687438965
Validation loss: 2.1098654859809467

Epoch: 6| Step: 10
Training loss: 2.220494270324707
Validation loss: 2.1348550576035694

Epoch: 6| Step: 11
Training loss: 2.268620491027832
Validation loss: 2.1715183309329453

Epoch: 6| Step: 12
Training loss: 2.700969696044922
Validation loss: 2.1610779505904003

Epoch: 6| Step: 13
Training loss: 2.136662244796753
Validation loss: 2.1074588773071126

Epoch: 107| Step: 0
Training loss: 2.442312240600586
Validation loss: 2.103555558830179

Epoch: 6| Step: 1
Training loss: 2.077108860015869
Validation loss: 2.0947257908441688

Epoch: 6| Step: 2
Training loss: 2.501246690750122
Validation loss: 2.089458429685203

Epoch: 6| Step: 3
Training loss: 2.784715175628662
Validation loss: 2.0657559274345316

Epoch: 6| Step: 4
Training loss: 2.2198333740234375
Validation loss: 2.046356024280671

Epoch: 6| Step: 5
Training loss: 2.5069828033447266
Validation loss: 2.03269818264951

Epoch: 6| Step: 6
Training loss: 2.1137309074401855
Validation loss: 2.0354683617109894

Epoch: 6| Step: 7
Training loss: 2.4705069065093994
Validation loss: 2.037219247510356

Epoch: 6| Step: 8
Training loss: 2.556325912475586
Validation loss: 2.053907540536696

Epoch: 6| Step: 9
Training loss: 1.3547382354736328
Validation loss: 2.0614549447131414

Epoch: 6| Step: 10
Training loss: 1.7359635829925537
Validation loss: 2.079884768814169

Epoch: 6| Step: 11
Training loss: 2.048464298248291
Validation loss: 2.065512490528886

Epoch: 6| Step: 12
Training loss: 1.8343710899353027
Validation loss: 2.063769825043217

Epoch: 6| Step: 13
Training loss: 2.594536304473877
Validation loss: 2.049088836998068

Epoch: 108| Step: 0
Training loss: 2.8454184532165527
Validation loss: 2.0419213720547256

Epoch: 6| Step: 1
Training loss: 2.318911552429199
Validation loss: 2.047294939717939

Epoch: 6| Step: 2
Training loss: 1.7823430299758911
Validation loss: 2.0253673855976393

Epoch: 6| Step: 3
Training loss: 2.495568037033081
Validation loss: 2.0170624076679187

Epoch: 6| Step: 4
Training loss: 1.9293692111968994
Validation loss: 2.010887643342377

Epoch: 6| Step: 5
Training loss: 2.3111438751220703
Validation loss: 2.004305789547582

Epoch: 6| Step: 6
Training loss: 2.334866523742676
Validation loss: 2.040217100933034

Epoch: 6| Step: 7
Training loss: 2.1897470951080322
Validation loss: 2.0853851610614407

Epoch: 6| Step: 8
Training loss: 2.2901651859283447
Validation loss: 2.0992474145786737

Epoch: 6| Step: 9
Training loss: 2.0721628665924072
Validation loss: 2.082528744974444

Epoch: 6| Step: 10
Training loss: 2.3267953395843506
Validation loss: 2.0507328830739504

Epoch: 6| Step: 11
Training loss: 2.12391996383667
Validation loss: 2.02708129600812

Epoch: 6| Step: 12
Training loss: 2.384603500366211
Validation loss: 2.0151545642524638

Epoch: 6| Step: 13
Training loss: 2.263906717300415
Validation loss: 2.02389326659582

Epoch: 109| Step: 0
Training loss: 1.438891887664795
Validation loss: 2.0024097529790734

Epoch: 6| Step: 1
Training loss: 1.9656920433044434
Validation loss: 2.017556203308926

Epoch: 6| Step: 2
Training loss: 2.38712215423584
Validation loss: 2.039294755587014

Epoch: 6| Step: 3
Training loss: 2.1200780868530273
Validation loss: 2.0705343228514477

Epoch: 6| Step: 4
Training loss: 2.374689817428589
Validation loss: 2.0631562074025473

Epoch: 6| Step: 5
Training loss: 2.6915078163146973
Validation loss: 2.0764088374312206

Epoch: 6| Step: 6
Training loss: 2.1921329498291016
Validation loss: 2.055156406535897

Epoch: 6| Step: 7
Training loss: 1.7855666875839233
Validation loss: 2.0575540322129444

Epoch: 6| Step: 8
Training loss: 2.043217897415161
Validation loss: 2.023468743088425

Epoch: 6| Step: 9
Training loss: 3.166328191757202
Validation loss: 2.015828045465613

Epoch: 6| Step: 10
Training loss: 2.3879101276397705
Validation loss: 2.010889273817821

Epoch: 6| Step: 11
Training loss: 1.9165679216384888
Validation loss: 2.015404744814801

Epoch: 6| Step: 12
Training loss: 2.776160478591919
Validation loss: 2.014356069667365

Epoch: 6| Step: 13
Training loss: 2.116267204284668
Validation loss: 2.007926889645156

Epoch: 110| Step: 0
Training loss: 1.409915804862976
Validation loss: 2.024240573247274

Epoch: 6| Step: 1
Training loss: 2.8770341873168945
Validation loss: 2.039624365427161

Epoch: 6| Step: 2
Training loss: 2.3456311225891113
Validation loss: 2.0575078264359505

Epoch: 6| Step: 3
Training loss: 1.7249367237091064
Validation loss: 2.0714628106804303

Epoch: 6| Step: 4
Training loss: 2.8152217864990234
Validation loss: 2.1055572981475503

Epoch: 6| Step: 5
Training loss: 2.899343490600586
Validation loss: 2.119634123258693

Epoch: 6| Step: 6
Training loss: 1.5520758628845215
Validation loss: 2.1249014587812525

Epoch: 6| Step: 7
Training loss: 2.756537914276123
Validation loss: 2.123276436200706

Epoch: 6| Step: 8
Training loss: 1.878913402557373
Validation loss: 2.139649483465379

Epoch: 6| Step: 9
Training loss: 1.2630267143249512
Validation loss: 2.1107703921615437

Epoch: 6| Step: 10
Training loss: 2.3615100383758545
Validation loss: 2.0829158226648965

Epoch: 6| Step: 11
Training loss: 2.142124891281128
Validation loss: 2.0760420535200383

Epoch: 6| Step: 12
Training loss: 2.018799304962158
Validation loss: 2.080420632516184

Epoch: 6| Step: 13
Training loss: 3.9620988368988037
Validation loss: 2.055628990614286

Epoch: 111| Step: 0
Training loss: 2.0845532417297363
Validation loss: 2.059388347851333

Epoch: 6| Step: 1
Training loss: 2.347130060195923
Validation loss: 2.049096599701912

Epoch: 6| Step: 2
Training loss: 2.2438883781433105
Validation loss: 2.046067460890739

Epoch: 6| Step: 3
Training loss: 2.468973159790039
Validation loss: 2.0352628025957333

Epoch: 6| Step: 4
Training loss: 1.8014943599700928
Validation loss: 2.041473073344077

Epoch: 6| Step: 5
Training loss: 2.137833595275879
Validation loss: 2.04363174592295

Epoch: 6| Step: 6
Training loss: 2.1094045639038086
Validation loss: 2.06732875557356

Epoch: 6| Step: 7
Training loss: 2.154448986053467
Validation loss: 2.0640075463120655

Epoch: 6| Step: 8
Training loss: 1.751899003982544
Validation loss: 2.073645314862651

Epoch: 6| Step: 9
Training loss: 2.9316680431365967
Validation loss: 2.078689670050016

Epoch: 6| Step: 10
Training loss: 2.4548721313476562
Validation loss: 2.065000641730524

Epoch: 6| Step: 11
Training loss: 1.8580838441848755
Validation loss: 2.059416295379721

Epoch: 6| Step: 12
Training loss: 2.2481017112731934
Validation loss: 2.0244601695768294

Epoch: 6| Step: 13
Training loss: 1.9415231943130493
Validation loss: 2.0226029760094097

Epoch: 112| Step: 0
Training loss: 2.532804489135742
Validation loss: 2.039218518041795

Epoch: 6| Step: 1
Training loss: 1.739546537399292
Validation loss: 2.0624720422170495

Epoch: 6| Step: 2
Training loss: 2.566509962081909
Validation loss: 2.0541822013034614

Epoch: 6| Step: 3
Training loss: 2.547785758972168
Validation loss: 2.038828585737495

Epoch: 6| Step: 4
Training loss: 2.2450437545776367
Validation loss: 2.033326264350645

Epoch: 6| Step: 5
Training loss: 1.7330620288848877
Validation loss: 2.0342985327525804

Epoch: 6| Step: 6
Training loss: 1.7058895826339722
Validation loss: 2.0487090938834736

Epoch: 6| Step: 7
Training loss: 2.270740509033203
Validation loss: 2.0424381404794674

Epoch: 6| Step: 8
Training loss: 2.0324089527130127
Validation loss: 2.0527661897802867

Epoch: 6| Step: 9
Training loss: 1.6891244649887085
Validation loss: 2.062255644029187

Epoch: 6| Step: 10
Training loss: 1.95463228225708
Validation loss: 2.056606218379031

Epoch: 6| Step: 11
Training loss: 2.7986526489257812
Validation loss: 2.0435373116565008

Epoch: 6| Step: 12
Training loss: 2.327460765838623
Validation loss: 2.038874195468041

Epoch: 6| Step: 13
Training loss: 2.4082021713256836
Validation loss: 2.037455097321541

Epoch: 113| Step: 0
Training loss: 2.2597951889038086
Validation loss: 2.059571612265802

Epoch: 6| Step: 1
Training loss: 2.361769914627075
Validation loss: 2.0437383523551365

Epoch: 6| Step: 2
Training loss: 1.8577909469604492
Validation loss: 2.0408204435020365

Epoch: 6| Step: 3
Training loss: 2.201042890548706
Validation loss: 2.058554567316527

Epoch: 6| Step: 4
Training loss: 1.7427489757537842
Validation loss: 2.0713917363074517

Epoch: 6| Step: 5
Training loss: 2.5444600582122803
Validation loss: 2.1034392054362963

Epoch: 6| Step: 6
Training loss: 2.714383602142334
Validation loss: 2.1472350141053558

Epoch: 6| Step: 7
Training loss: 2.8235554695129395
Validation loss: 2.1790079250130603

Epoch: 6| Step: 8
Training loss: 1.3685983419418335
Validation loss: 2.1986427230219685

Epoch: 6| Step: 9
Training loss: 1.8552942276000977
Validation loss: 2.183072097839848

Epoch: 6| Step: 10
Training loss: 2.4455320835113525
Validation loss: 2.1522217694149224

Epoch: 6| Step: 11
Training loss: 1.2783344984054565
Validation loss: 2.1312274381678593

Epoch: 6| Step: 12
Training loss: 2.7347865104675293
Validation loss: 2.0949331432260494

Epoch: 6| Step: 13
Training loss: 2.3580873012542725
Validation loss: 2.0690735770810034

Epoch: 114| Step: 0
Training loss: 2.230848789215088
Validation loss: 2.053065576860982

Epoch: 6| Step: 1
Training loss: 2.0800132751464844
Validation loss: 2.049822667593597

Epoch: 6| Step: 2
Training loss: 2.1308629512786865
Validation loss: 2.044950746720837

Epoch: 6| Step: 3
Training loss: 1.7480236291885376
Validation loss: 2.0258554694473103

Epoch: 6| Step: 4
Training loss: 2.3189055919647217
Validation loss: 2.0234365873439337

Epoch: 6| Step: 5
Training loss: 1.8943753242492676
Validation loss: 2.0340553637473815

Epoch: 6| Step: 6
Training loss: 1.7268967628479004
Validation loss: 2.0168444918048

Epoch: 6| Step: 7
Training loss: 2.935410976409912
Validation loss: 2.009702162076068

Epoch: 6| Step: 8
Training loss: 2.388139486312866
Validation loss: 1.994003067734421

Epoch: 6| Step: 9
Training loss: 2.2065324783325195
Validation loss: 2.0003477245248775

Epoch: 6| Step: 10
Training loss: 2.40584659576416
Validation loss: 2.032776647998441

Epoch: 6| Step: 11
Training loss: 1.6389762163162231
Validation loss: 2.063045004362701

Epoch: 6| Step: 12
Training loss: 2.64329195022583
Validation loss: 2.1225374142328897

Epoch: 6| Step: 13
Training loss: 2.713332176208496
Validation loss: 2.1394556132696008

Epoch: 115| Step: 0
Training loss: 2.7301197052001953
Validation loss: 2.1292269793889855

Epoch: 6| Step: 1
Training loss: 2.317910671234131
Validation loss: 2.072669275345341

Epoch: 6| Step: 2
Training loss: 1.9904450178146362
Validation loss: 2.013017490345945

Epoch: 6| Step: 3
Training loss: 2.5591256618499756
Validation loss: 2.0135089300012075

Epoch: 6| Step: 4
Training loss: 2.353156089782715
Validation loss: 2.0153628510813557

Epoch: 6| Step: 5
Training loss: 1.7979258298873901
Validation loss: 2.017578842819378

Epoch: 6| Step: 6
Training loss: 1.856706976890564
Validation loss: 2.011301394431822

Epoch: 6| Step: 7
Training loss: 2.2904860973358154
Validation loss: 2.0041699255666425

Epoch: 6| Step: 8
Training loss: 2.2255804538726807
Validation loss: 2.0173278470193186

Epoch: 6| Step: 9
Training loss: 1.7892553806304932
Validation loss: 2.04962061297509

Epoch: 6| Step: 10
Training loss: 2.6995792388916016
Validation loss: 2.0957706423215967

Epoch: 6| Step: 11
Training loss: 1.796665072441101
Validation loss: 2.145133328694169

Epoch: 6| Step: 12
Training loss: 2.7432689666748047
Validation loss: 2.158041731003792

Epoch: 6| Step: 13
Training loss: 1.7396498918533325
Validation loss: 2.18938272999179

Epoch: 116| Step: 0
Training loss: 2.81807804107666
Validation loss: 2.2113647717301563

Epoch: 6| Step: 1
Training loss: 2.3243818283081055
Validation loss: 2.2269311694688696

Epoch: 6| Step: 2
Training loss: 2.353506326675415
Validation loss: 2.267572292717554

Epoch: 6| Step: 3
Training loss: 1.8394529819488525
Validation loss: 2.229529280816355

Epoch: 6| Step: 4
Training loss: 2.4595909118652344
Validation loss: 2.1924789464601906

Epoch: 6| Step: 5
Training loss: 2.417421817779541
Validation loss: 2.130509980263249

Epoch: 6| Step: 6
Training loss: 2.2888400554656982
Validation loss: 2.0980469411419285

Epoch: 6| Step: 7
Training loss: 1.872015118598938
Validation loss: 2.0670130663020636

Epoch: 6| Step: 8
Training loss: 2.5944554805755615
Validation loss: 2.0676004450808287

Epoch: 6| Step: 9
Training loss: 1.9703718423843384
Validation loss: 2.054581038413509

Epoch: 6| Step: 10
Training loss: 1.1897227764129639
Validation loss: 2.0638747984363186

Epoch: 6| Step: 11
Training loss: 2.3535757064819336
Validation loss: 2.072384839416832

Epoch: 6| Step: 12
Training loss: 1.8160004615783691
Validation loss: 2.085514960750457

Epoch: 6| Step: 13
Training loss: 2.3800761699676514
Validation loss: 2.1041584194347425

Epoch: 117| Step: 0
Training loss: 2.1489131450653076
Validation loss: 2.0866933817504556

Epoch: 6| Step: 1
Training loss: 2.1370038986206055
Validation loss: 2.081686255752399

Epoch: 6| Step: 2
Training loss: 2.0267229080200195
Validation loss: 2.0541200099452848

Epoch: 6| Step: 3
Training loss: 2.5232481956481934
Validation loss: 2.066838023483112

Epoch: 6| Step: 4
Training loss: 2.753675699234009
Validation loss: 2.04257531063531

Epoch: 6| Step: 5
Training loss: 2.2444872856140137
Validation loss: 2.0393193819189586

Epoch: 6| Step: 6
Training loss: 2.3522017002105713
Validation loss: 2.044067085430186

Epoch: 6| Step: 7
Training loss: 2.389094829559326
Validation loss: 2.0759968680720173

Epoch: 6| Step: 8
Training loss: 1.4918670654296875
Validation loss: 2.100418672766737

Epoch: 6| Step: 9
Training loss: 2.1921472549438477
Validation loss: 2.1024601395412157

Epoch: 6| Step: 10
Training loss: 2.138112783432007
Validation loss: 2.095395172795942

Epoch: 6| Step: 11
Training loss: 1.9040944576263428
Validation loss: 2.0753035673531155

Epoch: 6| Step: 12
Training loss: 2.3237271308898926
Validation loss: 2.057162812961045

Epoch: 6| Step: 13
Training loss: 1.2977185249328613
Validation loss: 2.035406989435996

Epoch: 118| Step: 0
Training loss: 2.3007287979125977
Validation loss: 2.0258018406488563

Epoch: 6| Step: 1
Training loss: 1.6119027137756348
Validation loss: 2.022430463503766

Epoch: 6| Step: 2
Training loss: 2.220039129257202
Validation loss: 2.0314006254237187

Epoch: 6| Step: 3
Training loss: 2.0516748428344727
Validation loss: 2.0576188871937413

Epoch: 6| Step: 4
Training loss: 2.5835022926330566
Validation loss: 2.106529515276673

Epoch: 6| Step: 5
Training loss: 2.437406063079834
Validation loss: 2.1420564318215973

Epoch: 6| Step: 6
Training loss: 1.9204225540161133
Validation loss: 2.1554578606800368

Epoch: 6| Step: 7
Training loss: 2.609797477722168
Validation loss: 2.138241065445767

Epoch: 6| Step: 8
Training loss: 2.310746669769287
Validation loss: 2.108630149595199

Epoch: 6| Step: 9
Training loss: 2.0630240440368652
Validation loss: 2.0647121180770216

Epoch: 6| Step: 10
Training loss: 2.1770572662353516
Validation loss: 2.044461883524413

Epoch: 6| Step: 11
Training loss: 1.6546028852462769
Validation loss: 2.0467984086723736

Epoch: 6| Step: 12
Training loss: 1.5453312397003174
Validation loss: 2.045337683411055

Epoch: 6| Step: 13
Training loss: 3.675426483154297
Validation loss: 2.0433280250077606

Epoch: 119| Step: 0
Training loss: 2.040731430053711
Validation loss: 2.0341553329139628

Epoch: 6| Step: 1
Training loss: 1.772295355796814
Validation loss: 2.036302665228485

Epoch: 6| Step: 2
Training loss: 2.344996929168701
Validation loss: 2.034246475465836

Epoch: 6| Step: 3
Training loss: 2.5917084217071533
Validation loss: 2.030884749145918

Epoch: 6| Step: 4
Training loss: 2.6052136421203613
Validation loss: 2.02683380598663

Epoch: 6| Step: 5
Training loss: 2.1187543869018555
Validation loss: 2.037288732426141

Epoch: 6| Step: 6
Training loss: 2.180673837661743
Validation loss: 2.0472773095612884

Epoch: 6| Step: 7
Training loss: 2.1753475666046143
Validation loss: 2.059216013518713

Epoch: 6| Step: 8
Training loss: 2.539950132369995
Validation loss: 2.0851234389889624

Epoch: 6| Step: 9
Training loss: 2.675280809402466
Validation loss: 2.1357280669673795

Epoch: 6| Step: 10
Training loss: 1.7737501859664917
Validation loss: 2.168701094965781

Epoch: 6| Step: 11
Training loss: 1.47633957862854
Validation loss: 2.193346095341508

Epoch: 6| Step: 12
Training loss: 2.273204803466797
Validation loss: 2.1762847874754216

Epoch: 6| Step: 13
Training loss: 1.9873526096343994
Validation loss: 2.1497578415819394

Epoch: 120| Step: 0
Training loss: 2.218701124191284
Validation loss: 2.138540114125898

Epoch: 6| Step: 1
Training loss: 2.1617379188537598
Validation loss: 2.1169507324054675

Epoch: 6| Step: 2
Training loss: 2.9291534423828125
Validation loss: 2.1072973948653027

Epoch: 6| Step: 3
Training loss: 1.5814051628112793
Validation loss: 2.093733263272111

Epoch: 6| Step: 4
Training loss: 1.2027546167373657
Validation loss: 2.099731135111983

Epoch: 6| Step: 5
Training loss: 1.5738555192947388
Validation loss: 2.087628565808778

Epoch: 6| Step: 6
Training loss: 2.2947452068328857
Validation loss: 2.093577306757691

Epoch: 6| Step: 7
Training loss: 2.479991912841797
Validation loss: 2.094163728016679

Epoch: 6| Step: 8
Training loss: 2.353672504425049
Validation loss: 2.0760858674203195

Epoch: 6| Step: 9
Training loss: 2.2072105407714844
Validation loss: 2.0733962469203497

Epoch: 6| Step: 10
Training loss: 1.9070887565612793
Validation loss: 2.0834728876749673

Epoch: 6| Step: 11
Training loss: 2.409407615661621
Validation loss: 2.0852185218564925

Epoch: 6| Step: 12
Training loss: 2.1677744388580322
Validation loss: 2.078748833748602

Epoch: 6| Step: 13
Training loss: 2.256347417831421
Validation loss: 2.0787345337611374

Epoch: 121| Step: 0
Training loss: 1.1851754188537598
Validation loss: 2.069490901885494

Epoch: 6| Step: 1
Training loss: 1.9097613096237183
Validation loss: 2.0535217356938187

Epoch: 6| Step: 2
Training loss: 2.0605239868164062
Validation loss: 2.0492597433828537

Epoch: 6| Step: 3
Training loss: 2.056093692779541
Validation loss: 2.0396025039816417

Epoch: 6| Step: 4
Training loss: 2.487182855606079
Validation loss: 2.030153129690437

Epoch: 6| Step: 5
Training loss: 1.8027061223983765
Validation loss: 2.036335534946893

Epoch: 6| Step: 6
Training loss: 2.3659772872924805
Validation loss: 2.048939848458895

Epoch: 6| Step: 7
Training loss: 1.7676429748535156
Validation loss: 2.0575727185895367

Epoch: 6| Step: 8
Training loss: 2.692657947540283
Validation loss: 2.0744996583589943

Epoch: 6| Step: 9
Training loss: 2.2342946529388428
Validation loss: 2.0821525948022

Epoch: 6| Step: 10
Training loss: 2.2116949558258057
Validation loss: 2.074839336897737

Epoch: 6| Step: 11
Training loss: 2.006632089614868
Validation loss: 2.076397975285848

Epoch: 6| Step: 12
Training loss: 2.5529069900512695
Validation loss: 2.064418920906641

Epoch: 6| Step: 13
Training loss: 2.2625269889831543
Validation loss: 2.061368820487812

Epoch: 122| Step: 0
Training loss: 1.948256254196167
Validation loss: 2.083588125885174

Epoch: 6| Step: 1
Training loss: 1.8150787353515625
Validation loss: 2.059753284659437

Epoch: 6| Step: 2
Training loss: 1.4858589172363281
Validation loss: 2.080444815338299

Epoch: 6| Step: 3
Training loss: 1.6290075778961182
Validation loss: 2.091648724771315

Epoch: 6| Step: 4
Training loss: 2.9858148097991943
Validation loss: 2.1173892559543734

Epoch: 6| Step: 5
Training loss: 1.7046318054199219
Validation loss: 2.1054156288023917

Epoch: 6| Step: 6
Training loss: 2.1082403659820557
Validation loss: 2.082136692539338

Epoch: 6| Step: 7
Training loss: 3.0196423530578613
Validation loss: 2.0816888450294413

Epoch: 6| Step: 8
Training loss: 2.5763514041900635
Validation loss: 2.0643713961365404

Epoch: 6| Step: 9
Training loss: 1.7418442964553833
Validation loss: 2.069720414377028

Epoch: 6| Step: 10
Training loss: 1.8668699264526367
Validation loss: 2.075371224393127

Epoch: 6| Step: 11
Training loss: 2.9234352111816406
Validation loss: 2.097633828399002

Epoch: 6| Step: 12
Training loss: 1.574207067489624
Validation loss: 2.09625151336834

Epoch: 6| Step: 13
Training loss: 1.7271333932876587
Validation loss: 2.1424636610092653

Epoch: 123| Step: 0
Training loss: 1.777923583984375
Validation loss: 2.124497732808513

Epoch: 6| Step: 1
Training loss: 1.7441489696502686
Validation loss: 2.1150806437256517

Epoch: 6| Step: 2
Training loss: 2.5904102325439453
Validation loss: 2.1269166033755065

Epoch: 6| Step: 3
Training loss: 2.5863349437713623
Validation loss: 2.114589309179655

Epoch: 6| Step: 4
Training loss: 1.817133903503418
Validation loss: 2.0867048950605493

Epoch: 6| Step: 5
Training loss: 1.7408479452133179
Validation loss: 2.1087293804332776

Epoch: 6| Step: 6
Training loss: 2.201835870742798
Validation loss: 2.1099035996262745

Epoch: 6| Step: 7
Training loss: 2.0426101684570312
Validation loss: 2.1053462912959438

Epoch: 6| Step: 8
Training loss: 2.7303121089935303
Validation loss: 2.1086320518165507

Epoch: 6| Step: 9
Training loss: 2.6415061950683594
Validation loss: 2.1022510656746487

Epoch: 6| Step: 10
Training loss: 2.1806445121765137
Validation loss: 2.0871278368016726

Epoch: 6| Step: 11
Training loss: 1.3870368003845215
Validation loss: 2.0738107773565475

Epoch: 6| Step: 12
Training loss: 1.6580685377120972
Validation loss: 2.0542342124446744

Epoch: 6| Step: 13
Training loss: 2.2060012817382812
Validation loss: 2.0417509489161993

Epoch: 124| Step: 0
Training loss: 2.128741502761841
Validation loss: 2.0289318792281614

Epoch: 6| Step: 1
Training loss: 2.526428699493408
Validation loss: 2.027824224964265

Epoch: 6| Step: 2
Training loss: 2.4812355041503906
Validation loss: 2.0238359692276164

Epoch: 6| Step: 3
Training loss: 1.8245421648025513
Validation loss: 2.021526341797203

Epoch: 6| Step: 4
Training loss: 1.965384602546692
Validation loss: 2.020175862055953

Epoch: 6| Step: 5
Training loss: 1.0480730533599854
Validation loss: 2.0383127940598356

Epoch: 6| Step: 6
Training loss: 1.9828219413757324
Validation loss: 2.0670993020457606

Epoch: 6| Step: 7
Training loss: 2.350581645965576
Validation loss: 2.082592777026597

Epoch: 6| Step: 8
Training loss: 2.119382619857788
Validation loss: 2.076699641443068

Epoch: 6| Step: 9
Training loss: 2.605489730834961
Validation loss: 2.0752187851936585

Epoch: 6| Step: 10
Training loss: 1.953466534614563
Validation loss: 2.0631063535649288

Epoch: 6| Step: 11
Training loss: 2.003675699234009
Validation loss: 2.0358140160960536

Epoch: 6| Step: 12
Training loss: 1.974275827407837
Validation loss: 2.058151073353265

Epoch: 6| Step: 13
Training loss: 2.5922579765319824
Validation loss: 2.0337252591245916

Epoch: 125| Step: 0
Training loss: 2.188960313796997
Validation loss: 2.0333070601186445

Epoch: 6| Step: 1
Training loss: 2.1884217262268066
Validation loss: 2.0440466814143683

Epoch: 6| Step: 2
Training loss: 1.9977134466171265
Validation loss: 2.0666260744935725

Epoch: 6| Step: 3
Training loss: 1.6395041942596436
Validation loss: 2.065007896833522

Epoch: 6| Step: 4
Training loss: 1.6314418315887451
Validation loss: 2.0773548567166893

Epoch: 6| Step: 5
Training loss: 2.621713638305664
Validation loss: 2.099661309231994

Epoch: 6| Step: 6
Training loss: 1.8028647899627686
Validation loss: 2.1388405035900813

Epoch: 6| Step: 7
Training loss: 2.2870876789093018
Validation loss: 2.1681008262019

Epoch: 6| Step: 8
Training loss: 2.78214955329895
Validation loss: 2.202175672336291

Epoch: 6| Step: 9
Training loss: 2.801098585128784
Validation loss: 2.1765030763482534

Epoch: 6| Step: 10
Training loss: 1.81437349319458
Validation loss: 2.158352248130306

Epoch: 6| Step: 11
Training loss: 1.8475555181503296
Validation loss: 2.1052180477367934

Epoch: 6| Step: 12
Training loss: 1.9277218580245972
Validation loss: 2.0582841186113257

Epoch: 6| Step: 13
Training loss: 1.9079813957214355
Validation loss: 2.0477712744025776

Epoch: 126| Step: 0
Training loss: 2.308041572570801
Validation loss: 2.048239723328621

Epoch: 6| Step: 1
Training loss: 2.4901480674743652
Validation loss: 2.0655798924866544

Epoch: 6| Step: 2
Training loss: 2.325000047683716
Validation loss: 2.0745404279360207

Epoch: 6| Step: 3
Training loss: 1.9623112678527832
Validation loss: 2.10254168510437

Epoch: 6| Step: 4
Training loss: 2.067256450653076
Validation loss: 2.129860676744933

Epoch: 6| Step: 5
Training loss: 1.520137071609497
Validation loss: 2.1581287435306016

Epoch: 6| Step: 6
Training loss: 2.55721378326416
Validation loss: 2.1271333143275273

Epoch: 6| Step: 7
Training loss: 2.125871419906616
Validation loss: 2.119911111811156

Epoch: 6| Step: 8
Training loss: 2.6467678546905518
Validation loss: 2.087277184250534

Epoch: 6| Step: 9
Training loss: 2.0381829738616943
Validation loss: 2.106832170999178

Epoch: 6| Step: 10
Training loss: 2.3029849529266357
Validation loss: 2.1277848187313286

Epoch: 6| Step: 11
Training loss: 1.7176405191421509
Validation loss: 2.173380042916985

Epoch: 6| Step: 12
Training loss: 1.6697940826416016
Validation loss: 2.2195103194123957

Epoch: 6| Step: 13
Training loss: 1.5706778764724731
Validation loss: 2.2424725691477456

Epoch: 127| Step: 0
Training loss: 2.2137036323547363
Validation loss: 2.222715118879913

Epoch: 6| Step: 1
Training loss: 2.062922477722168
Validation loss: 2.1747291805923625

Epoch: 6| Step: 2
Training loss: 2.0671863555908203
Validation loss: 2.132183356951642

Epoch: 6| Step: 3
Training loss: 1.913993239402771
Validation loss: 2.093161262491698

Epoch: 6| Step: 4
Training loss: 2.203894853591919
Validation loss: 2.07391115414199

Epoch: 6| Step: 5
Training loss: 2.022162437438965
Validation loss: 2.077854937122714

Epoch: 6| Step: 6
Training loss: 1.9080101251602173
Validation loss: 2.075659521164433

Epoch: 6| Step: 7
Training loss: 1.782829999923706
Validation loss: 2.0810888813387964

Epoch: 6| Step: 8
Training loss: 2.548173189163208
Validation loss: 2.1010867549527075

Epoch: 6| Step: 9
Training loss: 2.310729503631592
Validation loss: 2.098569587994647

Epoch: 6| Step: 10
Training loss: 0.9662764668464661
Validation loss: 2.0999892347602436

Epoch: 6| Step: 11
Training loss: 2.4254889488220215
Validation loss: 2.0708677076524302

Epoch: 6| Step: 12
Training loss: 1.983154058456421
Validation loss: 2.0826373843736548

Epoch: 6| Step: 13
Training loss: 2.8816440105438232
Validation loss: 2.0735991347220635

Epoch: 128| Step: 0
Training loss: 1.9650648832321167
Validation loss: 2.063776144417383

Epoch: 6| Step: 1
Training loss: 1.7126104831695557
Validation loss: 2.060165821865041

Epoch: 6| Step: 2
Training loss: 2.7176339626312256
Validation loss: 2.059346052908128

Epoch: 6| Step: 3
Training loss: 2.8811416625976562
Validation loss: 2.053843564884637

Epoch: 6| Step: 4
Training loss: 2.259594440460205
Validation loss: 2.0720198436449935

Epoch: 6| Step: 5
Training loss: 1.9008866548538208
Validation loss: 2.069042814675198

Epoch: 6| Step: 6
Training loss: 2.5293071269989014
Validation loss: 2.101213127054194

Epoch: 6| Step: 7
Training loss: 1.2562048435211182
Validation loss: 2.112938363065002

Epoch: 6| Step: 8
Training loss: 1.140724539756775
Validation loss: 2.1251177569871307

Epoch: 6| Step: 9
Training loss: 1.9332001209259033
Validation loss: 2.081980687315746

Epoch: 6| Step: 10
Training loss: 1.5325411558151245
Validation loss: 2.0822085898409606

Epoch: 6| Step: 11
Training loss: 2.551319122314453
Validation loss: 2.0928764497080157

Epoch: 6| Step: 12
Training loss: 2.3445851802825928
Validation loss: 2.090198346363601

Epoch: 6| Step: 13
Training loss: 1.8434480428695679
Validation loss: 2.1174516447128786

Epoch: 129| Step: 0
Training loss: 2.321944236755371
Validation loss: 2.138064384460449

Epoch: 6| Step: 1
Training loss: 1.9173774719238281
Validation loss: 2.1458170362698135

Epoch: 6| Step: 2
Training loss: 1.8849895000457764
Validation loss: 2.1841247543211906

Epoch: 6| Step: 3
Training loss: 2.1066250801086426
Validation loss: 2.130852069906009

Epoch: 6| Step: 4
Training loss: 2.126300811767578
Validation loss: 2.0892662873832126

Epoch: 6| Step: 5
Training loss: 2.412276268005371
Validation loss: 2.0730345172266804

Epoch: 6| Step: 6
Training loss: 2.585631847381592
Validation loss: 2.045377569813882

Epoch: 6| Step: 7
Training loss: 1.2018322944641113
Validation loss: 2.0388179953380297

Epoch: 6| Step: 8
Training loss: 1.51472806930542
Validation loss: 2.035764822395899

Epoch: 6| Step: 9
Training loss: 2.7789788246154785
Validation loss: 2.0452600871362994

Epoch: 6| Step: 10
Training loss: 1.5571362972259521
Validation loss: 2.041488810252118

Epoch: 6| Step: 11
Training loss: 2.2180237770080566
Validation loss: 2.049231440790238

Epoch: 6| Step: 12
Training loss: 1.9859329462051392
Validation loss: 2.077203002027286

Epoch: 6| Step: 13
Training loss: 2.080319404602051
Validation loss: 2.110180039559641

Epoch: 130| Step: 0
Training loss: 2.3296689987182617
Validation loss: 2.1604635459120556

Epoch: 6| Step: 1
Training loss: 2.375021457672119
Validation loss: 2.134182835137972

Epoch: 6| Step: 2
Training loss: 2.563293933868408
Validation loss: 2.1051178183606876

Epoch: 6| Step: 3
Training loss: 1.6738649606704712
Validation loss: 2.0681338617878575

Epoch: 6| Step: 4
Training loss: 1.8095295429229736
Validation loss: 2.0723028964893793

Epoch: 6| Step: 5
Training loss: 2.4030251502990723
Validation loss: 2.070103087732869

Epoch: 6| Step: 6
Training loss: 2.0039658546447754
Validation loss: 2.0751087075920513

Epoch: 6| Step: 7
Training loss: 1.935670256614685
Validation loss: 2.0671145223802134

Epoch: 6| Step: 8
Training loss: 1.5453872680664062
Validation loss: 2.042144730526914

Epoch: 6| Step: 9
Training loss: 1.8749030828475952
Validation loss: 2.054826855659485

Epoch: 6| Step: 10
Training loss: 2.090824842453003
Validation loss: 2.081142747274009

Epoch: 6| Step: 11
Training loss: 2.0371410846710205
Validation loss: 2.110187033171295

Epoch: 6| Step: 12
Training loss: 2.028301239013672
Validation loss: 2.2143699943378405

Epoch: 6| Step: 13
Training loss: 2.0444717407226562
Validation loss: 2.310329221910046

Epoch: 131| Step: 0
Training loss: 2.2698967456817627
Validation loss: 2.3199292177795083

Epoch: 6| Step: 1
Training loss: 2.227470874786377
Validation loss: 2.220868338820755

Epoch: 6| Step: 2
Training loss: 1.5708205699920654
Validation loss: 2.109337378573674

Epoch: 6| Step: 3
Training loss: 2.104670524597168
Validation loss: 2.0638603625759

Epoch: 6| Step: 4
Training loss: 2.0525217056274414
Validation loss: 2.0699998153153287

Epoch: 6| Step: 5
Training loss: 2.849517345428467
Validation loss: 2.060740163249354

Epoch: 6| Step: 6
Training loss: 2.326571464538574
Validation loss: 2.05874268726636

Epoch: 6| Step: 7
Training loss: 1.9535082578659058
Validation loss: 2.061603517942531

Epoch: 6| Step: 8
Training loss: 1.474156141281128
Validation loss: 2.050300072598201

Epoch: 6| Step: 9
Training loss: 2.502136707305908
Validation loss: 2.0438915247558267

Epoch: 6| Step: 10
Training loss: 2.2328710556030273
Validation loss: 2.046327342269241

Epoch: 6| Step: 11
Training loss: 1.929586410522461
Validation loss: 2.0544807731464343

Epoch: 6| Step: 12
Training loss: 1.3794502019882202
Validation loss: 2.07684511779457

Epoch: 6| Step: 13
Training loss: 1.8868244886398315
Validation loss: 2.0941651380190285

Epoch: 132| Step: 0
Training loss: 1.9882298707962036
Validation loss: 2.134734058892855

Epoch: 6| Step: 1
Training loss: 1.5998033285140991
Validation loss: 2.1644061996090795

Epoch: 6| Step: 2
Training loss: 1.452929139137268
Validation loss: 2.198928858644219

Epoch: 6| Step: 3
Training loss: 1.7105274200439453
Validation loss: 2.237955735575768

Epoch: 6| Step: 4
Training loss: 2.3626770973205566
Validation loss: 2.272938402750159

Epoch: 6| Step: 5
Training loss: 1.963089942932129
Validation loss: 2.2845358028206775

Epoch: 6| Step: 6
Training loss: 2.8464527130126953
Validation loss: 2.231177327453449

Epoch: 6| Step: 7
Training loss: 2.027836322784424
Validation loss: 2.1845556664210495

Epoch: 6| Step: 8
Training loss: 2.0254690647125244
Validation loss: 2.137765094798098

Epoch: 6| Step: 9
Training loss: 1.7077833414077759
Validation loss: 2.095185024763948

Epoch: 6| Step: 10
Training loss: 2.108802556991577
Validation loss: 2.09264878560138

Epoch: 6| Step: 11
Training loss: 2.4108526706695557
Validation loss: 2.084473829115591

Epoch: 6| Step: 12
Training loss: 2.352947235107422
Validation loss: 2.062753286412967

Epoch: 6| Step: 13
Training loss: 1.6337602138519287
Validation loss: 2.078939466066258

Epoch: 133| Step: 0
Training loss: 2.1262564659118652
Validation loss: 2.0788671098729616

Epoch: 6| Step: 1
Training loss: 1.9299477338790894
Validation loss: 2.0873579312396306

Epoch: 6| Step: 2
Training loss: 2.5389840602874756
Validation loss: 2.088173971381239

Epoch: 6| Step: 3
Training loss: 2.6482901573181152
Validation loss: 2.11534801349845

Epoch: 6| Step: 4
Training loss: 1.3746278285980225
Validation loss: 2.118331427215248

Epoch: 6| Step: 5
Training loss: 1.6378146409988403
Validation loss: 2.1181032952441963

Epoch: 6| Step: 6
Training loss: 1.9523124694824219
Validation loss: 2.131080896623673

Epoch: 6| Step: 7
Training loss: 1.8638888597488403
Validation loss: 2.1405445593659596

Epoch: 6| Step: 8
Training loss: 1.6756269931793213
Validation loss: 2.178789907886136

Epoch: 6| Step: 9
Training loss: 1.88021719455719
Validation loss: 2.2029697074685046

Epoch: 6| Step: 10
Training loss: 2.2239670753479004
Validation loss: 2.2006879391208773

Epoch: 6| Step: 11
Training loss: 2.430673837661743
Validation loss: 2.1724198761806695

Epoch: 6| Step: 12
Training loss: 2.3568410873413086
Validation loss: 2.1235401245855514

Epoch: 6| Step: 13
Training loss: 1.880149245262146
Validation loss: 2.086878186912947

Epoch: 134| Step: 0
Training loss: 2.3412461280822754
Validation loss: 2.108330439495784

Epoch: 6| Step: 1
Training loss: 2.2224111557006836
Validation loss: 2.107477713656682

Epoch: 6| Step: 2
Training loss: 1.6799445152282715
Validation loss: 2.141936557267302

Epoch: 6| Step: 3
Training loss: 2.215489625930786
Validation loss: 2.1505958623783563

Epoch: 6| Step: 4
Training loss: 2.1434149742126465
Validation loss: 2.1443912265121297

Epoch: 6| Step: 5
Training loss: 1.1701610088348389
Validation loss: 2.128238376750741

Epoch: 6| Step: 6
Training loss: 3.0043516159057617
Validation loss: 2.1293389797210693

Epoch: 6| Step: 7
Training loss: 2.3004398345947266
Validation loss: 2.1427656783852527

Epoch: 6| Step: 8
Training loss: 1.8675923347473145
Validation loss: 2.179736984673367

Epoch: 6| Step: 9
Training loss: 1.4501876831054688
Validation loss: 2.186985105596563

Epoch: 6| Step: 10
Training loss: 1.9055540561676025
Validation loss: 2.1768970335683515

Epoch: 6| Step: 11
Training loss: 1.8715636730194092
Validation loss: 2.182392474143736

Epoch: 6| Step: 12
Training loss: 1.9530028104782104
Validation loss: 2.1582425179020053

Epoch: 6| Step: 13
Training loss: 2.317359209060669
Validation loss: 2.1103654087230725

Epoch: 135| Step: 0
Training loss: 2.4780726432800293
Validation loss: 2.107205185838925

Epoch: 6| Step: 1
Training loss: 2.0395007133483887
Validation loss: 2.1056674449674544

Epoch: 6| Step: 2
Training loss: 1.8096554279327393
Validation loss: 2.1146657133615143

Epoch: 6| Step: 3
Training loss: 2.8089141845703125
Validation loss: 2.1019930031991776

Epoch: 6| Step: 4
Training loss: 1.5127065181732178
Validation loss: 2.096149818871611

Epoch: 6| Step: 5
Training loss: 1.9831347465515137
Validation loss: 2.1078995453414096

Epoch: 6| Step: 6
Training loss: 1.476224660873413
Validation loss: 2.102770201621517

Epoch: 6| Step: 7
Training loss: 2.4826819896698
Validation loss: 2.1033921049487208

Epoch: 6| Step: 8
Training loss: 1.3567705154418945
Validation loss: 2.1131531141137563

Epoch: 6| Step: 9
Training loss: 2.1663665771484375
Validation loss: 2.1150781172578053

Epoch: 6| Step: 10
Training loss: 2.4340832233428955
Validation loss: 2.1137728921828733

Epoch: 6| Step: 11
Training loss: 1.6841665506362915
Validation loss: 2.1103955058641333

Epoch: 6| Step: 12
Training loss: 1.3116642236709595
Validation loss: 2.1211805651264806

Epoch: 6| Step: 13
Training loss: 1.8085427284240723
Validation loss: 2.1254281279861287

Epoch: 136| Step: 0
Training loss: 2.4608235359191895
Validation loss: 2.1058849339844077

Epoch: 6| Step: 1
Training loss: 2.013261318206787
Validation loss: 2.095217171535697

Epoch: 6| Step: 2
Training loss: 3.0052804946899414
Validation loss: 2.091311252245339

Epoch: 6| Step: 3
Training loss: 2.3890857696533203
Validation loss: 2.1027386060325046

Epoch: 6| Step: 4
Training loss: 1.4355971813201904
Validation loss: 2.123207384540189

Epoch: 6| Step: 5
Training loss: 1.836440086364746
Validation loss: 2.0817516913978

Epoch: 6| Step: 6
Training loss: 1.4959371089935303
Validation loss: 2.0463421831848803

Epoch: 6| Step: 7
Training loss: 2.0721161365509033
Validation loss: 2.032742549014348

Epoch: 6| Step: 8
Training loss: 2.151681661605835
Validation loss: 2.054350096692321

Epoch: 6| Step: 9
Training loss: 1.6097935438156128
Validation loss: 2.0708713839131017

Epoch: 6| Step: 10
Training loss: 2.209125280380249
Validation loss: 2.0963557151056107

Epoch: 6| Step: 11
Training loss: 0.9541625380516052
Validation loss: 2.1181777882319626

Epoch: 6| Step: 12
Training loss: 2.145150661468506
Validation loss: 2.150648458029634

Epoch: 6| Step: 13
Training loss: 1.0705229043960571
Validation loss: 2.170944377940188

Epoch: 137| Step: 0
Training loss: 1.8803989887237549
Validation loss: 2.1960815204087125

Epoch: 6| Step: 1
Training loss: 2.0026233196258545
Validation loss: 2.201571203047229

Epoch: 6| Step: 2
Training loss: 2.1571707725524902
Validation loss: 2.1756118882086968

Epoch: 6| Step: 3
Training loss: 1.5466228723526
Validation loss: 2.136415681531352

Epoch: 6| Step: 4
Training loss: 2.022357702255249
Validation loss: 2.075610463337232

Epoch: 6| Step: 5
Training loss: 1.4860382080078125
Validation loss: 2.068969429180186

Epoch: 6| Step: 6
Training loss: 2.146595001220703
Validation loss: 2.046647915276148

Epoch: 6| Step: 7
Training loss: 1.7558938264846802
Validation loss: 2.0632076917156095

Epoch: 6| Step: 8
Training loss: 1.236005187034607
Validation loss: 2.084486863946402

Epoch: 6| Step: 9
Training loss: 2.072035312652588
Validation loss: 2.071322294973558

Epoch: 6| Step: 10
Training loss: 2.773808240890503
Validation loss: 2.070882481913413

Epoch: 6| Step: 11
Training loss: 2.1454672813415527
Validation loss: 2.0881504897148377

Epoch: 6| Step: 12
Training loss: 2.4697465896606445
Validation loss: 2.0998530413514827

Epoch: 6| Step: 13
Training loss: 1.60084867477417
Validation loss: 2.127477263891569

Epoch: 138| Step: 0
Training loss: 1.9239418506622314
Validation loss: 2.137594155085984

Epoch: 6| Step: 1
Training loss: 1.4264885187149048
Validation loss: 2.102049958321356

Epoch: 6| Step: 2
Training loss: 2.2154834270477295
Validation loss: 2.066492954889933

Epoch: 6| Step: 3
Training loss: 2.0212340354919434
Validation loss: 2.0436572438927105

Epoch: 6| Step: 4
Training loss: 1.7436429262161255
Validation loss: 2.035867393657725

Epoch: 6| Step: 5
Training loss: 2.040928840637207
Validation loss: 2.0292570539700088

Epoch: 6| Step: 6
Training loss: 2.6146655082702637
Validation loss: 2.033265524013068

Epoch: 6| Step: 7
Training loss: 2.071317195892334
Validation loss: 2.0267501287562872

Epoch: 6| Step: 8
Training loss: 1.303991675376892
Validation loss: 2.0497222344080606

Epoch: 6| Step: 9
Training loss: 1.8579885959625244
Validation loss: 2.069172211872634

Epoch: 6| Step: 10
Training loss: 1.912766933441162
Validation loss: 2.1277009748643443

Epoch: 6| Step: 11
Training loss: 1.7343194484710693
Validation loss: 2.1859189105290238

Epoch: 6| Step: 12
Training loss: 1.937084674835205
Validation loss: 2.2154577983322965

Epoch: 6| Step: 13
Training loss: 2.800548553466797
Validation loss: 2.210621157000142

Epoch: 139| Step: 0
Training loss: 2.242027759552002
Validation loss: 2.178414075605331

Epoch: 6| Step: 1
Training loss: 2.4575910568237305
Validation loss: 2.1509850076449815

Epoch: 6| Step: 2
Training loss: 1.4880385398864746
Validation loss: 2.1354211889287478

Epoch: 6| Step: 3
Training loss: 2.735694646835327
Validation loss: 2.146900000110749

Epoch: 6| Step: 4
Training loss: 1.2375973463058472
Validation loss: 2.1376623415177867

Epoch: 6| Step: 5
Training loss: 2.209847927093506
Validation loss: 2.1139286718060895

Epoch: 6| Step: 6
Training loss: 1.8290261030197144
Validation loss: 2.1102946432687903

Epoch: 6| Step: 7
Training loss: 1.626554012298584
Validation loss: 2.0921354114368396

Epoch: 6| Step: 8
Training loss: 1.5012767314910889
Validation loss: 2.0765894048957416

Epoch: 6| Step: 9
Training loss: 1.9037439823150635
Validation loss: 2.0787700171111734

Epoch: 6| Step: 10
Training loss: 1.9736473560333252
Validation loss: 2.07491103295357

Epoch: 6| Step: 11
Training loss: 1.907217264175415
Validation loss: 2.0684702127210555

Epoch: 6| Step: 12
Training loss: 1.9428688287734985
Validation loss: 2.0713549442188715

Epoch: 6| Step: 13
Training loss: 1.6354900598526
Validation loss: 2.059245296703872

Epoch: 140| Step: 0
Training loss: 1.8142976760864258
Validation loss: 2.097617264716856

Epoch: 6| Step: 1
Training loss: 1.9328420162200928
Validation loss: 2.107498207399922

Epoch: 6| Step: 2
Training loss: 3.012012481689453
Validation loss: 2.119742689594146

Epoch: 6| Step: 3
Training loss: 1.7230007648468018
Validation loss: 2.1312203189378143

Epoch: 6| Step: 4
Training loss: 1.619768500328064
Validation loss: 2.127270670347316

Epoch: 6| Step: 5
Training loss: 2.1006107330322266
Validation loss: 2.1229595676545174

Epoch: 6| Step: 6
Training loss: 2.3914413452148438
Validation loss: 2.1385732914811824

Epoch: 6| Step: 7
Training loss: 1.3528308868408203
Validation loss: 2.1132458935501757

Epoch: 6| Step: 8
Training loss: 1.0717873573303223
Validation loss: 2.1021391576336277

Epoch: 6| Step: 9
Training loss: 1.7505779266357422
Validation loss: 2.1000220878149873

Epoch: 6| Step: 10
Training loss: 1.5679863691329956
Validation loss: 2.1180001971542195

Epoch: 6| Step: 11
Training loss: 2.597407579421997
Validation loss: 2.116083816815448

Epoch: 6| Step: 12
Training loss: 2.0581183433532715
Validation loss: 2.1021861696756012

Epoch: 6| Step: 13
Training loss: 1.648364782333374
Validation loss: 2.1106845550639655

Epoch: 141| Step: 0
Training loss: 1.8081331253051758
Validation loss: 2.086744357180852

Epoch: 6| Step: 1
Training loss: 2.0369343757629395
Validation loss: 2.0889960565874652

Epoch: 6| Step: 2
Training loss: 1.6668217182159424
Validation loss: 2.0670742129766815

Epoch: 6| Step: 3
Training loss: 1.4119150638580322
Validation loss: 2.0565532817635486

Epoch: 6| Step: 4
Training loss: 2.0804080963134766
Validation loss: 2.0427543014608402

Epoch: 6| Step: 5
Training loss: 2.133570909500122
Validation loss: 2.029843076582878

Epoch: 6| Step: 6
Training loss: 1.4792371988296509
Validation loss: 2.0698621555041243

Epoch: 6| Step: 7
Training loss: 2.196310043334961
Validation loss: 2.070689132136683

Epoch: 6| Step: 8
Training loss: 1.516035795211792
Validation loss: 2.086707874010968

Epoch: 6| Step: 9
Training loss: 1.9566924571990967
Validation loss: 2.110021557859195

Epoch: 6| Step: 10
Training loss: 1.673537015914917
Validation loss: 2.121361024918095

Epoch: 6| Step: 11
Training loss: 1.788465142250061
Validation loss: 2.12379317386176

Epoch: 6| Step: 12
Training loss: 2.716296911239624
Validation loss: 2.1107940904555784

Epoch: 6| Step: 13
Training loss: 1.466016173362732
Validation loss: 2.0970939205538843

Epoch: 142| Step: 0
Training loss: 2.42261004447937
Validation loss: 2.0701723226936917

Epoch: 6| Step: 1
Training loss: 2.0391905307769775
Validation loss: 2.0662380687652098

Epoch: 6| Step: 2
Training loss: 1.395493745803833
Validation loss: 2.0516134846595024

Epoch: 6| Step: 3
Training loss: 1.7155675888061523
Validation loss: 2.0657308229836087

Epoch: 6| Step: 4
Training loss: 2.0441668033599854
Validation loss: 2.058300828420988

Epoch: 6| Step: 5
Training loss: 2.4173052310943604
Validation loss: 2.0872926173671598

Epoch: 6| Step: 6
Training loss: 1.7558200359344482
Validation loss: 2.08027587526588

Epoch: 6| Step: 7
Training loss: 1.6607310771942139
Validation loss: 2.0990976172108806

Epoch: 6| Step: 8
Training loss: 2.178703784942627
Validation loss: 2.0902518738982496

Epoch: 6| Step: 9
Training loss: 1.6979533433914185
Validation loss: 2.086804989845522

Epoch: 6| Step: 10
Training loss: 1.9312841892242432
Validation loss: 2.0843273849897486

Epoch: 6| Step: 11
Training loss: 1.3960527181625366
Validation loss: 2.0788908466216056

Epoch: 6| Step: 12
Training loss: 1.5765507221221924
Validation loss: 2.0653212506283998

Epoch: 6| Step: 13
Training loss: 1.3714364767074585
Validation loss: 2.062084787635393

Epoch: 143| Step: 0
Training loss: 1.5673084259033203
Validation loss: 2.0827397838715584

Epoch: 6| Step: 1
Training loss: 1.2322885990142822
Validation loss: 2.0600092282859226

Epoch: 6| Step: 2
Training loss: 2.1918342113494873
Validation loss: 2.079917956424016

Epoch: 6| Step: 3
Training loss: 2.514737129211426
Validation loss: 2.078066242638455

Epoch: 6| Step: 4
Training loss: 1.9185967445373535
Validation loss: 2.0769389547327513

Epoch: 6| Step: 5
Training loss: 2.280810832977295
Validation loss: 2.089235600604806

Epoch: 6| Step: 6
Training loss: 1.6609082221984863
Validation loss: 2.113259418036348

Epoch: 6| Step: 7
Training loss: 2.5189757347106934
Validation loss: 2.1433408119345225

Epoch: 6| Step: 8
Training loss: 1.8884084224700928
Validation loss: 2.175725080633676

Epoch: 6| Step: 9
Training loss: 1.510087251663208
Validation loss: 2.186365489036806

Epoch: 6| Step: 10
Training loss: 1.7356553077697754
Validation loss: 2.1777996516996816

Epoch: 6| Step: 11
Training loss: 1.5339345932006836
Validation loss: 2.1390618560134724

Epoch: 6| Step: 12
Training loss: 1.893761396408081
Validation loss: 2.1210113571536158

Epoch: 6| Step: 13
Training loss: 1.4166048765182495
Validation loss: 2.0910585298333118

Epoch: 144| Step: 0
Training loss: 2.0857653617858887
Validation loss: 2.0537409141499507

Epoch: 6| Step: 1
Training loss: 1.9538211822509766
Validation loss: 2.0558502481829737

Epoch: 6| Step: 2
Training loss: 2.081758737564087
Validation loss: 2.0579635725226453

Epoch: 6| Step: 3
Training loss: 1.2102491855621338
Validation loss: 2.055974943663484

Epoch: 6| Step: 4
Training loss: 2.120816230773926
Validation loss: 2.059171312598772

Epoch: 6| Step: 5
Training loss: 2.0836234092712402
Validation loss: 2.079701274953863

Epoch: 6| Step: 6
Training loss: 1.2823567390441895
Validation loss: 2.084103589416832

Epoch: 6| Step: 7
Training loss: 1.7387702465057373
Validation loss: 2.1026717001391995

Epoch: 6| Step: 8
Training loss: 2.349808692932129
Validation loss: 2.11680454720733

Epoch: 6| Step: 9
Training loss: 1.1667370796203613
Validation loss: 2.1254459375976236

Epoch: 6| Step: 10
Training loss: 2.427133798599243
Validation loss: 2.100551876970517

Epoch: 6| Step: 11
Training loss: 1.1458494663238525
Validation loss: 2.1011140884891635

Epoch: 6| Step: 12
Training loss: 1.8706631660461426
Validation loss: 2.0863262966114986

Epoch: 6| Step: 13
Training loss: 2.121091604232788
Validation loss: 2.0618860311405633

Epoch: 145| Step: 0
Training loss: 1.185438871383667
Validation loss: 2.0566223372695265

Epoch: 6| Step: 1
Training loss: 1.9347528219223022
Validation loss: 2.0692439668922016

Epoch: 6| Step: 2
Training loss: 2.187502384185791
Validation loss: 2.0665082162426365

Epoch: 6| Step: 3
Training loss: 2.6791844367980957
Validation loss: 2.0540462552860217

Epoch: 6| Step: 4
Training loss: 1.0996208190917969
Validation loss: 2.0580353224149315

Epoch: 6| Step: 5
Training loss: 1.4978046417236328
Validation loss: 2.06241008030471

Epoch: 6| Step: 6
Training loss: 1.888694167137146
Validation loss: 2.066989298789732

Epoch: 6| Step: 7
Training loss: 1.5408133268356323
Validation loss: 2.0681573972907117

Epoch: 6| Step: 8
Training loss: 1.8726171255111694
Validation loss: 2.0715687903024818

Epoch: 6| Step: 9
Training loss: 1.9161763191223145
Validation loss: 2.0877885087843864

Epoch: 6| Step: 10
Training loss: 1.625448226928711
Validation loss: 2.1179196014199206

Epoch: 6| Step: 11
Training loss: 1.4060471057891846
Validation loss: 2.087283576688459

Epoch: 6| Step: 12
Training loss: 2.5366947650909424
Validation loss: 2.0730894919364684

Epoch: 6| Step: 13
Training loss: 1.9050328731536865
Validation loss: 2.061745507742769

Epoch: 146| Step: 0
Training loss: 1.2705333232879639
Validation loss: 2.0515277718984954

Epoch: 6| Step: 1
Training loss: 1.7375150918960571
Validation loss: 2.028250071310228

Epoch: 6| Step: 2
Training loss: 2.2132039070129395
Validation loss: 2.0166374432143344

Epoch: 6| Step: 3
Training loss: 1.9578955173492432
Validation loss: 2.022038141886393

Epoch: 6| Step: 4
Training loss: 1.5541352033615112
Validation loss: 2.0276864331255675

Epoch: 6| Step: 5
Training loss: 1.719831943511963
Validation loss: 2.0229316847298735

Epoch: 6| Step: 6
Training loss: 1.8330491781234741
Validation loss: 2.011320975518996

Epoch: 6| Step: 7
Training loss: 1.4925190210342407
Validation loss: 2.0517236776249383

Epoch: 6| Step: 8
Training loss: 2.227005958557129
Validation loss: 2.062716469969801

Epoch: 6| Step: 9
Training loss: 2.5489559173583984
Validation loss: 2.077922954354235

Epoch: 6| Step: 10
Training loss: 1.5420887470245361
Validation loss: 2.063499671156688

Epoch: 6| Step: 11
Training loss: 1.621732473373413
Validation loss: 2.0666587506571124

Epoch: 6| Step: 12
Training loss: 1.591165542602539
Validation loss: 2.0711994645416096

Epoch: 6| Step: 13
Training loss: 2.406947612762451
Validation loss: 2.0683534222264446

Epoch: 147| Step: 0
Training loss: 1.8161544799804688
Validation loss: 2.1021549342780985

Epoch: 6| Step: 1
Training loss: 1.740738868713379
Validation loss: 2.0921873251597085

Epoch: 6| Step: 2
Training loss: 1.7285130023956299
Validation loss: 2.0828464492674796

Epoch: 6| Step: 3
Training loss: 1.4471615552902222
Validation loss: 2.0943213893521215

Epoch: 6| Step: 4
Training loss: 1.587627649307251
Validation loss: 2.091596734139227

Epoch: 6| Step: 5
Training loss: 2.187955617904663
Validation loss: 2.087070898343158

Epoch: 6| Step: 6
Training loss: 1.4546418190002441
Validation loss: 2.0790995218420543

Epoch: 6| Step: 7
Training loss: 1.8451029062271118
Validation loss: 2.0464015865838654

Epoch: 6| Step: 8
Training loss: 1.8038197755813599
Validation loss: 2.0379632801137944

Epoch: 6| Step: 9
Training loss: 2.416187286376953
Validation loss: 2.0166152241409465

Epoch: 6| Step: 10
Training loss: 2.101041555404663
Validation loss: 2.025623970134284

Epoch: 6| Step: 11
Training loss: 1.8403356075286865
Validation loss: 2.031578756147815

Epoch: 6| Step: 12
Training loss: 1.8504376411437988
Validation loss: 2.054711082930206

Epoch: 6| Step: 13
Training loss: 1.2696207761764526
Validation loss: 2.067991925824073

Epoch: 148| Step: 0
Training loss: 1.5371586084365845
Validation loss: 2.0924899629367295

Epoch: 6| Step: 1
Training loss: 1.449664831161499
Validation loss: 2.1150548855463662

Epoch: 6| Step: 2
Training loss: 2.2100794315338135
Validation loss: 2.1358600713873424

Epoch: 6| Step: 3
Training loss: 1.162184238433838
Validation loss: 2.1494203562377603

Epoch: 6| Step: 4
Training loss: 2.2427468299865723
Validation loss: 2.14382283021045

Epoch: 6| Step: 5
Training loss: 1.4081441164016724
Validation loss: 2.110264132099767

Epoch: 6| Step: 6
Training loss: 1.9255623817443848
Validation loss: 2.093151120729344

Epoch: 6| Step: 7
Training loss: 2.4684410095214844
Validation loss: 2.0747420531447216

Epoch: 6| Step: 8
Training loss: 1.513657808303833
Validation loss: 2.0484253565470376

Epoch: 6| Step: 9
Training loss: 1.9449183940887451
Validation loss: 2.030939599519135

Epoch: 6| Step: 10
Training loss: 1.8407409191131592
Validation loss: 2.023320169859035

Epoch: 6| Step: 11
Training loss: 2.3981752395629883
Validation loss: 2.0191788250400173

Epoch: 6| Step: 12
Training loss: 1.4701879024505615
Validation loss: 2.0003092724789857

Epoch: 6| Step: 13
Training loss: 1.584136962890625
Validation loss: 2.005837402036113

Epoch: 149| Step: 0
Training loss: 1.3284666538238525
Validation loss: 2.0773857588409097

Epoch: 6| Step: 1
Training loss: 1.9359896183013916
Validation loss: 2.174174734341201

Epoch: 6| Step: 2
Training loss: 1.3238232135772705
Validation loss: 2.2472056932346796

Epoch: 6| Step: 3
Training loss: 2.4794859886169434
Validation loss: 2.2839730119192474

Epoch: 6| Step: 4
Training loss: 1.1540583372116089
Validation loss: 2.249402835804929

Epoch: 6| Step: 5
Training loss: 1.3053162097930908
Validation loss: 2.1923322036702144

Epoch: 6| Step: 6
Training loss: 2.072794198989868
Validation loss: 2.1757054328918457

Epoch: 6| Step: 7
Training loss: 1.8173083066940308
Validation loss: 2.150352698500438

Epoch: 6| Step: 8
Training loss: 1.8136237859725952
Validation loss: 2.1266008820585025

Epoch: 6| Step: 9
Training loss: 2.1461453437805176
Validation loss: 2.0896757674473587

Epoch: 6| Step: 10
Training loss: 2.4290521144866943
Validation loss: 2.0653386936392835

Epoch: 6| Step: 11
Training loss: 1.4562677145004272
Validation loss: 2.0347828557414394

Epoch: 6| Step: 12
Training loss: 2.617340087890625
Validation loss: 2.0113391671129452

Epoch: 6| Step: 13
Training loss: 1.5612152814865112
Validation loss: 1.9974439310771164

Epoch: 150| Step: 0
Training loss: 1.8820096254348755
Validation loss: 1.9877387682596843

Epoch: 6| Step: 1
Training loss: 1.3055278062820435
Validation loss: 1.9840580417263893

Epoch: 6| Step: 2
Training loss: 1.7846741676330566
Validation loss: 1.98671051250991

Epoch: 6| Step: 3
Training loss: 1.4394780397415161
Validation loss: 2.0041302224641204

Epoch: 6| Step: 4
Training loss: 1.1215736865997314
Validation loss: 2.0159120931420276

Epoch: 6| Step: 5
Training loss: 1.821677565574646
Validation loss: 2.02517080947917

Epoch: 6| Step: 6
Training loss: 2.0291972160339355
Validation loss: 2.0743623061846663

Epoch: 6| Step: 7
Training loss: 1.6986693143844604
Validation loss: 2.1101633656409478

Epoch: 6| Step: 8
Training loss: 2.3014473915100098
Validation loss: 2.0474141592620523

Epoch: 6| Step: 9
Training loss: 1.8881232738494873
Validation loss: 2.035044485522855

Epoch: 6| Step: 10
Training loss: 1.981186866760254
Validation loss: 2.004353689891036

Epoch: 6| Step: 11
Training loss: 1.9441711902618408
Validation loss: 1.9848531856331775

Epoch: 6| Step: 12
Training loss: 2.07924747467041
Validation loss: 1.9942540686617616

Epoch: 6| Step: 13
Training loss: 1.6543737649917603
Validation loss: 2.010769832518793

Epoch: 151| Step: 0
Training loss: 2.1610171794891357
Validation loss: 2.044866710580805

Epoch: 6| Step: 1
Training loss: 2.0662832260131836
Validation loss: 2.093102685866817

Epoch: 6| Step: 2
Training loss: 1.22919499874115
Validation loss: 2.101324983822402

Epoch: 6| Step: 3
Training loss: 1.799917459487915
Validation loss: 2.0801270110632784

Epoch: 6| Step: 4
Training loss: 1.2881178855895996
Validation loss: 2.0731341826018466

Epoch: 6| Step: 5
Training loss: 1.956451416015625
Validation loss: 2.086040163552889

Epoch: 6| Step: 6
Training loss: 2.1939754486083984
Validation loss: 2.1153933925013386

Epoch: 6| Step: 7
Training loss: 2.092451810836792
Validation loss: 2.124486200271114

Epoch: 6| Step: 8
Training loss: 1.1717499494552612
Validation loss: 2.1647971266059467

Epoch: 6| Step: 9
Training loss: 1.7518184185028076
Validation loss: 2.1915925395104194

Epoch: 6| Step: 10
Training loss: 1.9329140186309814
Validation loss: 2.194154004896841

Epoch: 6| Step: 11
Training loss: 1.6555633544921875
Validation loss: 2.2123233887457077

Epoch: 6| Step: 12
Training loss: 2.06455659866333
Validation loss: 2.155407290304861

Epoch: 6| Step: 13
Training loss: 1.62234365940094
Validation loss: 2.1218664658966886

Epoch: 152| Step: 0
Training loss: 1.3493921756744385
Validation loss: 2.092267382529474

Epoch: 6| Step: 1
Training loss: 1.362779140472412
Validation loss: 2.045633605731431

Epoch: 6| Step: 2
Training loss: 1.5812029838562012
Validation loss: 2.0035606507332093

Epoch: 6| Step: 3
Training loss: 1.749851942062378
Validation loss: 2.0046271124193744

Epoch: 6| Step: 4
Training loss: 1.5521999597549438
Validation loss: 2.0052302704062512

Epoch: 6| Step: 5
Training loss: 1.9748820066452026
Validation loss: 2.0493933693055184

Epoch: 6| Step: 6
Training loss: 1.8250761032104492
Validation loss: 2.0510577488971014

Epoch: 6| Step: 7
Training loss: 1.8245145082473755
Validation loss: 2.0505374503392044

Epoch: 6| Step: 8
Training loss: 1.850649118423462
Validation loss: 2.0381490248505787

Epoch: 6| Step: 9
Training loss: 2.1318540573120117
Validation loss: 2.0513389059292373

Epoch: 6| Step: 10
Training loss: 2.038494110107422
Validation loss: 2.071855893699072

Epoch: 6| Step: 11
Training loss: 1.539476752281189
Validation loss: 2.064393487027896

Epoch: 6| Step: 12
Training loss: 1.9627103805541992
Validation loss: 2.048513109965991

Epoch: 6| Step: 13
Training loss: 1.986306071281433
Validation loss: 2.043087487579674

Epoch: 153| Step: 0
Training loss: 1.8586164712905884
Validation loss: 2.043846475180759

Epoch: 6| Step: 1
Training loss: 1.0099107027053833
Validation loss: 2.0134062344028103

Epoch: 6| Step: 2
Training loss: 1.6677000522613525
Validation loss: 2.028225847469863

Epoch: 6| Step: 3
Training loss: 1.1556293964385986
Validation loss: 2.0308996015979397

Epoch: 6| Step: 4
Training loss: 1.4217685461044312
Validation loss: 2.030237364512618

Epoch: 6| Step: 5
Training loss: 1.6813011169433594
Validation loss: 2.0656429759917723

Epoch: 6| Step: 6
Training loss: 2.133599042892456
Validation loss: 2.0901211923168552

Epoch: 6| Step: 7
Training loss: 2.1915431022644043
Validation loss: 2.109326493355536

Epoch: 6| Step: 8
Training loss: 2.0992746353149414
Validation loss: 2.104199817103724

Epoch: 6| Step: 9
Training loss: 1.8989052772521973
Validation loss: 2.09207615160173

Epoch: 6| Step: 10
Training loss: 1.9090209007263184
Validation loss: 2.0955190376568864

Epoch: 6| Step: 11
Training loss: 2.1860475540161133
Validation loss: 2.081771368621498

Epoch: 6| Step: 12
Training loss: 1.8787330389022827
Validation loss: 2.085692133954776

Epoch: 6| Step: 13
Training loss: 0.6931671500205994
Validation loss: 2.075048241564023

Epoch: 154| Step: 0
Training loss: 2.422816276550293
Validation loss: 2.083615060775511

Epoch: 6| Step: 1
Training loss: 1.2338201999664307
Validation loss: 2.0580367554900465

Epoch: 6| Step: 2
Training loss: 1.579671025276184
Validation loss: 2.072877807001914

Epoch: 6| Step: 3
Training loss: 1.6420838832855225
Validation loss: 2.048746165408883

Epoch: 6| Step: 4
Training loss: 1.6684606075286865
Validation loss: 2.0503003366531862

Epoch: 6| Step: 5
Training loss: 2.1498751640319824
Validation loss: 2.0369678697278424

Epoch: 6| Step: 6
Training loss: 1.1312397718429565
Validation loss: 2.02557869367702

Epoch: 6| Step: 7
Training loss: 1.6202751398086548
Validation loss: 2.0207922394557665

Epoch: 6| Step: 8
Training loss: 1.8561065196990967
Validation loss: 2.024634171557683

Epoch: 6| Step: 9
Training loss: 1.093554139137268
Validation loss: 2.0098171452040314

Epoch: 6| Step: 10
Training loss: 2.0560929775238037
Validation loss: 2.0176019745488323

Epoch: 6| Step: 11
Training loss: 1.5785553455352783
Validation loss: 2.0452536895710933

Epoch: 6| Step: 12
Training loss: 1.7541879415512085
Validation loss: 2.054356398121003

Epoch: 6| Step: 13
Training loss: 1.8708515167236328
Validation loss: 2.090974125810849

Epoch: 155| Step: 0
Training loss: 1.025612473487854
Validation loss: 2.1232558988755748

Epoch: 6| Step: 1
Training loss: 0.9869745373725891
Validation loss: 2.1450997347472818

Epoch: 6| Step: 2
Training loss: 2.1152796745300293
Validation loss: 2.175277784306516

Epoch: 6| Step: 3
Training loss: 2.186838388442993
Validation loss: 2.166197512739448

Epoch: 6| Step: 4
Training loss: 1.3736238479614258
Validation loss: 2.1305402581409743

Epoch: 6| Step: 5
Training loss: 2.609462261199951
Validation loss: 2.0559861147275535

Epoch: 6| Step: 6
Training loss: 2.0454368591308594
Validation loss: 1.9880029437362507

Epoch: 6| Step: 7
Training loss: 1.7696752548217773
Validation loss: 1.9990155684050692

Epoch: 6| Step: 8
Training loss: 1.2418463230133057
Validation loss: 2.008892651527159

Epoch: 6| Step: 9
Training loss: 1.258604884147644
Validation loss: 2.009324235300864

Epoch: 6| Step: 10
Training loss: 1.7674678564071655
Validation loss: 2.008230524678384

Epoch: 6| Step: 11
Training loss: 2.029752731323242
Validation loss: 2.0080601810127177

Epoch: 6| Step: 12
Training loss: 2.4424867630004883
Validation loss: 2.0006026606405936

Epoch: 6| Step: 13
Training loss: 1.17886483669281
Validation loss: 2.0037592354641167

Epoch: 156| Step: 0
Training loss: 1.4705411195755005
Validation loss: 2.00585054069437

Epoch: 6| Step: 1
Training loss: 2.083683729171753
Validation loss: 2.0046775494852374

Epoch: 6| Step: 2
Training loss: 1.3072971105575562
Validation loss: 2.0208794147737565

Epoch: 6| Step: 3
Training loss: 1.5943810939788818
Validation loss: 2.0508336226145425

Epoch: 6| Step: 4
Training loss: 1.3108683824539185
Validation loss: 2.10058924459642

Epoch: 6| Step: 5
Training loss: 1.9903725385665894
Validation loss: 2.126073004097067

Epoch: 6| Step: 6
Training loss: 1.7048498392105103
Validation loss: 2.1685682676171743

Epoch: 6| Step: 7
Training loss: 1.8623145818710327
Validation loss: 2.1684280236562095

Epoch: 6| Step: 8
Training loss: 1.9064537286758423
Validation loss: 2.159761063514217

Epoch: 6| Step: 9
Training loss: 1.9319593906402588
Validation loss: 2.0851676720444874

Epoch: 6| Step: 10
Training loss: 1.0134003162384033
Validation loss: 2.06060629506265

Epoch: 6| Step: 11
Training loss: 1.9640116691589355
Validation loss: 2.040047099513392

Epoch: 6| Step: 12
Training loss: 1.8000129461288452
Validation loss: 2.0339879194895425

Epoch: 6| Step: 13
Training loss: 1.666999340057373
Validation loss: 2.0163955329566874

Epoch: 157| Step: 0
Training loss: 1.3980375528335571
Validation loss: 2.037269087247951

Epoch: 6| Step: 1
Training loss: 1.2762432098388672
Validation loss: 2.0136893769746185

Epoch: 6| Step: 2
Training loss: 2.0686686038970947
Validation loss: 2.03345839951628

Epoch: 6| Step: 3
Training loss: 2.2059054374694824
Validation loss: 2.0548156845954155

Epoch: 6| Step: 4
Training loss: 1.7817103862762451
Validation loss: 2.0611107016122467

Epoch: 6| Step: 5
Training loss: 1.466977596282959
Validation loss: 2.0344301346809632

Epoch: 6| Step: 6
Training loss: 2.2069244384765625
Validation loss: 2.009283317032681

Epoch: 6| Step: 7
Training loss: 1.3459100723266602
Validation loss: 2.0191880041553127

Epoch: 6| Step: 8
Training loss: 1.8970258235931396
Validation loss: 2.0027257524510866

Epoch: 6| Step: 9
Training loss: 1.9995046854019165
Validation loss: 2.039283061540255

Epoch: 6| Step: 10
Training loss: 1.3141484260559082
Validation loss: 2.0536408270559003

Epoch: 6| Step: 11
Training loss: 1.5757859945297241
Validation loss: 2.0783552700473416

Epoch: 6| Step: 12
Training loss: 1.3733144998550415
Validation loss: 2.1008376280466714

Epoch: 6| Step: 13
Training loss: 1.6774920225143433
Validation loss: 2.149783775370608

Epoch: 158| Step: 0
Training loss: 1.5377185344696045
Validation loss: 2.1331713584161576

Epoch: 6| Step: 1
Training loss: 1.4510022401809692
Validation loss: 2.0990386432217014

Epoch: 6| Step: 2
Training loss: 1.320557951927185
Validation loss: 2.0418002297801356

Epoch: 6| Step: 3
Training loss: 1.7160546779632568
Validation loss: 2.043150335229853

Epoch: 6| Step: 4
Training loss: 1.6707706451416016
Validation loss: 2.0292734151245444

Epoch: 6| Step: 5
Training loss: 1.396299958229065
Validation loss: 2.008476323978875

Epoch: 6| Step: 6
Training loss: 1.5581965446472168
Validation loss: 2.032461574000697

Epoch: 6| Step: 7
Training loss: 2.3756825923919678
Validation loss: 2.0500321695881505

Epoch: 6| Step: 8
Training loss: 1.8458057641983032
Validation loss: 2.075400149950417

Epoch: 6| Step: 9
Training loss: 1.7927863597869873
Validation loss: 2.0764321934792305

Epoch: 6| Step: 10
Training loss: 1.5117992162704468
Validation loss: 2.094834448188864

Epoch: 6| Step: 11
Training loss: 1.8382034301757812
Validation loss: 2.1000270676869217

Epoch: 6| Step: 12
Training loss: 1.7039631605148315
Validation loss: 2.094912403373308

Epoch: 6| Step: 13
Training loss: 0.8814225792884827
Validation loss: 2.1406641365379415

Epoch: 159| Step: 0
Training loss: 1.9995439052581787
Validation loss: 2.095537103632445

Epoch: 6| Step: 1
Training loss: 1.5770894289016724
Validation loss: 2.0955986053712907

Epoch: 6| Step: 2
Training loss: 1.4707056283950806
Validation loss: 2.084736185689126

Epoch: 6| Step: 3
Training loss: 1.319610357284546
Validation loss: 2.066659008302996

Epoch: 6| Step: 4
Training loss: 1.4075660705566406
Validation loss: 2.0567350028663554

Epoch: 6| Step: 5
Training loss: 1.8114063739776611
Validation loss: 2.045486955232518

Epoch: 6| Step: 6
Training loss: 1.0279030799865723
Validation loss: 2.0781846328448226

Epoch: 6| Step: 7
Training loss: 1.5648224353790283
Validation loss: 2.0532325980483845

Epoch: 6| Step: 8
Training loss: 1.7184600830078125
Validation loss: 2.0816276893820813

Epoch: 6| Step: 9
Training loss: 1.5312221050262451
Validation loss: 2.0338768292498846

Epoch: 6| Step: 10
Training loss: 1.3545374870300293
Validation loss: 2.022472744346947

Epoch: 6| Step: 11
Training loss: 2.4858598709106445
Validation loss: 2.0368259850368706

Epoch: 6| Step: 12
Training loss: 1.810817003250122
Validation loss: 2.0343811614539034

Epoch: 6| Step: 13
Training loss: 1.7371008396148682
Validation loss: 2.0228769984296573

Epoch: 160| Step: 0
Training loss: 2.1055378913879395
Validation loss: 2.014389230358985

Epoch: 6| Step: 1
Training loss: 1.104641318321228
Validation loss: 2.00471406854609

Epoch: 6| Step: 2
Training loss: 1.402288556098938
Validation loss: 2.0422037955253356

Epoch: 6| Step: 3
Training loss: 1.4650428295135498
Validation loss: 2.0357476267763364

Epoch: 6| Step: 4
Training loss: 1.656578779220581
Validation loss: 2.0490558813976985

Epoch: 6| Step: 5
Training loss: 2.2814781665802
Validation loss: 2.083939572816254

Epoch: 6| Step: 6
Training loss: 1.456179141998291
Validation loss: 2.101868124418361

Epoch: 6| Step: 7
Training loss: 0.7675498723983765
Validation loss: 2.1247053146362305

Epoch: 6| Step: 8
Training loss: 1.9471409320831299
Validation loss: 2.124987781688731

Epoch: 6| Step: 9
Training loss: 2.151528835296631
Validation loss: 2.073238544566657

Epoch: 6| Step: 10
Training loss: 1.4983913898468018
Validation loss: 2.0525998377030894

Epoch: 6| Step: 11
Training loss: 1.3961002826690674
Validation loss: 2.0484513595540035

Epoch: 6| Step: 12
Training loss: 1.5861536264419556
Validation loss: 2.046726898480487

Epoch: 6| Step: 13
Training loss: 1.7693064212799072
Validation loss: 2.039877155775665

Epoch: 161| Step: 0
Training loss: 1.3192657232284546
Validation loss: 2.052244068473898

Epoch: 6| Step: 1
Training loss: 1.4750070571899414
Validation loss: 2.050508978546307

Epoch: 6| Step: 2
Training loss: 1.3106651306152344
Validation loss: 2.0433977188602572

Epoch: 6| Step: 3
Training loss: 0.8615334033966064
Validation loss: 2.051958337906868

Epoch: 6| Step: 4
Training loss: 1.5143187046051025
Validation loss: 2.1045448946696457

Epoch: 6| Step: 5
Training loss: 1.7797458171844482
Validation loss: 2.1354676600425475

Epoch: 6| Step: 6
Training loss: 1.9584453105926514
Validation loss: 2.2112828352118052

Epoch: 6| Step: 7
Training loss: 1.8632924556732178
Validation loss: 2.2540327836108465

Epoch: 6| Step: 8
Training loss: 2.1393094062805176
Validation loss: 2.3014338849693217

Epoch: 6| Step: 9
Training loss: 1.5246100425720215
Validation loss: 2.2978030712373796

Epoch: 6| Step: 10
Training loss: 1.3889399766921997
Validation loss: 2.294406798578078

Epoch: 6| Step: 11
Training loss: 1.7294049263000488
Validation loss: 2.260905135062433

Epoch: 6| Step: 12
Training loss: 2.1391751766204834
Validation loss: 2.176492021929833

Epoch: 6| Step: 13
Training loss: 2.1973278522491455
Validation loss: 2.1164374582229124

Epoch: 162| Step: 0
Training loss: 1.492830753326416
Validation loss: 2.0522763588095225

Epoch: 6| Step: 1
Training loss: 0.7382100820541382
Validation loss: 2.020096468669112

Epoch: 6| Step: 2
Training loss: 1.4455854892730713
Validation loss: 1.996077911828154

Epoch: 6| Step: 3
Training loss: 1.2148628234863281
Validation loss: 2.0044839356535222

Epoch: 6| Step: 4
Training loss: 1.5761101245880127
Validation loss: 2.002198403881442

Epoch: 6| Step: 5
Training loss: 1.6054879426956177
Validation loss: 1.9957251907676778

Epoch: 6| Step: 6
Training loss: 1.7018301486968994
Validation loss: 2.016132636736798

Epoch: 6| Step: 7
Training loss: 1.7734969854354858
Validation loss: 2.0251088283395253

Epoch: 6| Step: 8
Training loss: 2.7323150634765625
Validation loss: 2.072585759624358

Epoch: 6| Step: 9
Training loss: 2.0482187271118164
Validation loss: 2.121066124208512

Epoch: 6| Step: 10
Training loss: 1.7663543224334717
Validation loss: 2.138982544663132

Epoch: 6| Step: 11
Training loss: 1.5851857662200928
Validation loss: 2.1193687967074815

Epoch: 6| Step: 12
Training loss: 1.907573938369751
Validation loss: 2.1625777470168246

Epoch: 6| Step: 13
Training loss: 0.973670244216919
Validation loss: 2.1380612363097486

Epoch: 163| Step: 0
Training loss: 1.992647647857666
Validation loss: 2.1249877509250434

Epoch: 6| Step: 1
Training loss: 1.894482970237732
Validation loss: 2.087186881290969

Epoch: 6| Step: 2
Training loss: 1.6961777210235596
Validation loss: 2.11693815518451

Epoch: 6| Step: 3
Training loss: 1.1582908630371094
Validation loss: 2.1197621335265455

Epoch: 6| Step: 4
Training loss: 1.8373234272003174
Validation loss: 2.137159808989494

Epoch: 6| Step: 5
Training loss: 1.3172799348831177
Validation loss: 2.161371969407605

Epoch: 6| Step: 6
Training loss: 1.0975923538208008
Validation loss: 2.185561539024435

Epoch: 6| Step: 7
Training loss: 1.2258894443511963
Validation loss: 2.158670369014945

Epoch: 6| Step: 8
Training loss: 1.664286732673645
Validation loss: 2.161196986834208

Epoch: 6| Step: 9
Training loss: 1.9485173225402832
Validation loss: 2.130628703742899

Epoch: 6| Step: 10
Training loss: 1.2488646507263184
Validation loss: 2.124436109296737

Epoch: 6| Step: 11
Training loss: 1.9796088933944702
Validation loss: 2.0744674026325183

Epoch: 6| Step: 12
Training loss: 1.61093008518219
Validation loss: 2.1148660029134443

Epoch: 6| Step: 13
Training loss: 1.2161059379577637
Validation loss: 2.0825660677366358

Epoch: 164| Step: 0
Training loss: 0.8537192344665527
Validation loss: 2.096368608936187

Epoch: 6| Step: 1
Training loss: 1.4502733945846558
Validation loss: 2.091856828299902

Epoch: 6| Step: 2
Training loss: 1.2620880603790283
Validation loss: 2.085380910545267

Epoch: 6| Step: 3
Training loss: 1.292191505432129
Validation loss: 2.097969880668066

Epoch: 6| Step: 4
Training loss: 1.8425225019454956
Validation loss: 2.069761536454642

Epoch: 6| Step: 5
Training loss: 1.5992909669876099
Validation loss: 2.0761300517666723

Epoch: 6| Step: 6
Training loss: 2.0423405170440674
Validation loss: 2.0477136770884194

Epoch: 6| Step: 7
Training loss: 1.4445745944976807
Validation loss: 2.07053368835039

Epoch: 6| Step: 8
Training loss: 1.4432939291000366
Validation loss: 2.070072968800863

Epoch: 6| Step: 9
Training loss: 1.4219903945922852
Validation loss: 2.0740552153638614

Epoch: 6| Step: 10
Training loss: 2.661897659301758
Validation loss: 2.0933756392489196

Epoch: 6| Step: 11
Training loss: 1.5667632818222046
Validation loss: 2.0673206416509484

Epoch: 6| Step: 12
Training loss: 1.3436461687088013
Validation loss: 2.059187909608246

Epoch: 6| Step: 13
Training loss: 1.2920341491699219
Validation loss: 2.062459655987319

Epoch: 165| Step: 0
Training loss: 2.203212022781372
Validation loss: 2.07942142153299

Epoch: 6| Step: 1
Training loss: 1.153998851776123
Validation loss: 2.0789003500374417

Epoch: 6| Step: 2
Training loss: 1.4482903480529785
Validation loss: 2.069794390791206

Epoch: 6| Step: 3
Training loss: 0.912325382232666
Validation loss: 2.076331592375232

Epoch: 6| Step: 4
Training loss: 1.9314751625061035
Validation loss: 2.0799091887730423

Epoch: 6| Step: 5
Training loss: 1.1472368240356445
Validation loss: 2.0682537812058643

Epoch: 6| Step: 6
Training loss: 1.9078189134597778
Validation loss: 2.098502944874507

Epoch: 6| Step: 7
Training loss: 1.9980088472366333
Validation loss: 2.0737139307042605

Epoch: 6| Step: 8
Training loss: 1.446225881576538
Validation loss: 2.072419569056521

Epoch: 6| Step: 9
Training loss: 1.6207307577133179
Validation loss: 2.0725681807405207

Epoch: 6| Step: 10
Training loss: 1.473252296447754
Validation loss: 2.038443657659715

Epoch: 6| Step: 11
Training loss: 0.9839209318161011
Validation loss: 2.001464428440217

Epoch: 6| Step: 12
Training loss: 1.8088507652282715
Validation loss: 2.0104206710733394

Epoch: 6| Step: 13
Training loss: 1.252030372619629
Validation loss: 2.041497104911394

Epoch: 166| Step: 0
Training loss: 1.9192602634429932
Validation loss: 2.035710088668331

Epoch: 6| Step: 1
Training loss: 0.7481467723846436
Validation loss: 2.028748873741396

Epoch: 6| Step: 2
Training loss: 2.10215425491333
Validation loss: 1.9985028646325553

Epoch: 6| Step: 3
Training loss: 1.1080894470214844
Validation loss: 1.9828910853273125

Epoch: 6| Step: 4
Training loss: 1.247819423675537
Validation loss: 1.9846399112414288

Epoch: 6| Step: 5
Training loss: 1.5620685815811157
Validation loss: 1.981196948277053

Epoch: 6| Step: 6
Training loss: 1.256774663925171
Validation loss: 1.9481467444409606

Epoch: 6| Step: 7
Training loss: 2.167545795440674
Validation loss: 1.9647648578049035

Epoch: 6| Step: 8
Training loss: 1.841153860092163
Validation loss: 1.9924680186856178

Epoch: 6| Step: 9
Training loss: 1.125117540359497
Validation loss: 2.0026907741382556

Epoch: 6| Step: 10
Training loss: 1.7749788761138916
Validation loss: 1.9913749387187343

Epoch: 6| Step: 11
Training loss: 1.5405768156051636
Validation loss: 1.9667842131789013

Epoch: 6| Step: 12
Training loss: 1.289569616317749
Validation loss: 1.9561671172418902

Epoch: 6| Step: 13
Training loss: 1.9004244804382324
Validation loss: 2.000451336624802

Epoch: 167| Step: 0
Training loss: 1.3921630382537842
Validation loss: 2.026738518027849

Epoch: 6| Step: 1
Training loss: 1.5721721649169922
Validation loss: 2.0665142356708484

Epoch: 6| Step: 2
Training loss: 2.4001331329345703
Validation loss: 2.077303296776228

Epoch: 6| Step: 3
Training loss: 1.179933786392212
Validation loss: 2.079549927865305

Epoch: 6| Step: 4
Training loss: 0.7804611921310425
Validation loss: 2.079644609523076

Epoch: 6| Step: 5
Training loss: 1.5597312450408936
Validation loss: 2.1007964611053467

Epoch: 6| Step: 6
Training loss: 1.8994534015655518
Validation loss: 2.095666952030633

Epoch: 6| Step: 7
Training loss: 1.181949257850647
Validation loss: 2.109020471572876

Epoch: 6| Step: 8
Training loss: 1.064697265625
Validation loss: 2.1214578254248506

Epoch: 6| Step: 9
Training loss: 2.0013890266418457
Validation loss: 2.104793665229633

Epoch: 6| Step: 10
Training loss: 1.0533819198608398
Validation loss: 2.097026437841436

Epoch: 6| Step: 11
Training loss: 1.431873083114624
Validation loss: 2.110308060082056

Epoch: 6| Step: 12
Training loss: 2.0301220417022705
Validation loss: 2.097819624408599

Epoch: 6| Step: 13
Training loss: 1.3845491409301758
Validation loss: 2.1004901342494513

Epoch: 168| Step: 0
Training loss: 1.0074586868286133
Validation loss: 2.0575853599015104

Epoch: 6| Step: 1
Training loss: 2.211548328399658
Validation loss: 2.014124983100481

Epoch: 6| Step: 2
Training loss: 2.0484211444854736
Validation loss: 2.0026686140286025

Epoch: 6| Step: 3
Training loss: 1.4086893796920776
Validation loss: 1.9912151085433138

Epoch: 6| Step: 4
Training loss: 1.5301251411437988
Validation loss: 1.9931321810650569

Epoch: 6| Step: 5
Training loss: 1.1153186559677124
Validation loss: 2.012504736582438

Epoch: 6| Step: 6
Training loss: 1.2373889684677124
Validation loss: 2.0215628788035405

Epoch: 6| Step: 7
Training loss: 1.0747618675231934
Validation loss: 2.022150306291478

Epoch: 6| Step: 8
Training loss: 1.1206004619598389
Validation loss: 2.061010827300369

Epoch: 6| Step: 9
Training loss: 1.8224234580993652
Validation loss: 2.0677128696954377

Epoch: 6| Step: 10
Training loss: 1.7576026916503906
Validation loss: 2.0759266679004957

Epoch: 6| Step: 11
Training loss: 1.6795637607574463
Validation loss: 2.076313740463667

Epoch: 6| Step: 12
Training loss: 1.8887603282928467
Validation loss: 2.0842694915750974

Epoch: 6| Step: 13
Training loss: 0.873853862285614
Validation loss: 2.100388865317068

Epoch: 169| Step: 0
Training loss: 1.1880661249160767
Validation loss: 2.162293444397629

Epoch: 6| Step: 1
Training loss: 1.7333046197891235
Validation loss: 2.1728167738965762

Epoch: 6| Step: 2
Training loss: 1.3147122859954834
Validation loss: 2.1866709160548385

Epoch: 6| Step: 3
Training loss: 1.3477413654327393
Validation loss: 2.1488281885782876

Epoch: 6| Step: 4
Training loss: 1.422102451324463
Validation loss: 2.1393321867912047

Epoch: 6| Step: 5
Training loss: 1.2314298152923584
Validation loss: 2.0930434221862466

Epoch: 6| Step: 6
Training loss: 1.7761225700378418
Validation loss: 2.0891715788072154

Epoch: 6| Step: 7
Training loss: 2.1757678985595703
Validation loss: 2.067224084690053

Epoch: 6| Step: 8
Training loss: 1.7922818660736084
Validation loss: 2.0155375888270717

Epoch: 6| Step: 9
Training loss: 1.8266860246658325
Validation loss: 2.0183655895212644

Epoch: 6| Step: 10
Training loss: 0.9385451078414917
Validation loss: 2.005292018254598

Epoch: 6| Step: 11
Training loss: 1.0883328914642334
Validation loss: 2.00480701205551

Epoch: 6| Step: 12
Training loss: 1.201570749282837
Validation loss: 2.0194917455796273

Epoch: 6| Step: 13
Training loss: 2.125401496887207
Validation loss: 2.05181973467591

Epoch: 170| Step: 0
Training loss: 1.1470215320587158
Validation loss: 2.070659079859334

Epoch: 6| Step: 1
Training loss: 1.1642780303955078
Validation loss: 2.059122029171195

Epoch: 6| Step: 2
Training loss: 0.7895852327346802
Validation loss: 2.0808765349849576

Epoch: 6| Step: 3
Training loss: 1.3972511291503906
Validation loss: 2.0924427842581146

Epoch: 6| Step: 4
Training loss: 1.5250625610351562
Validation loss: 2.0846363395772953

Epoch: 6| Step: 5
Training loss: 2.4039506912231445
Validation loss: 2.091952041913104

Epoch: 6| Step: 6
Training loss: 1.0648307800292969
Validation loss: 2.0900932909339986

Epoch: 6| Step: 7
Training loss: 1.896484136581421
Validation loss: 2.085247652505034

Epoch: 6| Step: 8
Training loss: 1.6671069860458374
Validation loss: 2.1188146068203833

Epoch: 6| Step: 9
Training loss: 2.0028018951416016
Validation loss: 2.159640307067543

Epoch: 6| Step: 10
Training loss: 1.245042324066162
Validation loss: 2.18152985008814

Epoch: 6| Step: 11
Training loss: 2.1098995208740234
Validation loss: 2.199736684881231

Epoch: 6| Step: 12
Training loss: 1.298693060874939
Validation loss: 2.199355806073835

Epoch: 6| Step: 13
Training loss: 0.4980981647968292
Validation loss: 2.1178970670187347

Epoch: 171| Step: 0
Training loss: 1.8550719022750854
Validation loss: 2.0921809557945497

Epoch: 6| Step: 1
Training loss: 1.1923295259475708
Validation loss: 2.046289277333085

Epoch: 6| Step: 2
Training loss: 1.4573054313659668
Validation loss: 2.0450438299486713

Epoch: 6| Step: 3
Training loss: 1.955082893371582
Validation loss: 2.059161243900176

Epoch: 6| Step: 4
Training loss: 1.6941567659378052
Validation loss: 2.0494229819184993

Epoch: 6| Step: 5
Training loss: 0.9302476048469543
Validation loss: 2.1178761912930395

Epoch: 6| Step: 6
Training loss: 1.6868243217468262
Validation loss: 2.097597934866464

Epoch: 6| Step: 7
Training loss: 1.4215404987335205
Validation loss: 2.1269919821011123

Epoch: 6| Step: 8
Training loss: 1.2304223775863647
Validation loss: 2.1399890453584733

Epoch: 6| Step: 9
Training loss: 1.4529056549072266
Validation loss: 2.1760165537557294

Epoch: 6| Step: 10
Training loss: 1.4703590869903564
Validation loss: 2.1566162237557034

Epoch: 6| Step: 11
Training loss: 1.3999910354614258
Validation loss: 2.1333324255481845

Epoch: 6| Step: 12
Training loss: 1.362577199935913
Validation loss: 2.120960568868986

Epoch: 6| Step: 13
Training loss: 1.495041012763977
Validation loss: 2.1065501166928198

Epoch: 172| Step: 0
Training loss: 0.671177864074707
Validation loss: 2.0687723185426448

Epoch: 6| Step: 1
Training loss: 1.3151600360870361
Validation loss: 2.0351522994297806

Epoch: 6| Step: 2
Training loss: 1.623246431350708
Validation loss: 2.0318187872568765

Epoch: 6| Step: 3
Training loss: 1.0759968757629395
Validation loss: 2.023971919090517

Epoch: 6| Step: 4
Training loss: 1.3774574995040894
Validation loss: 2.0575900526456934

Epoch: 6| Step: 5
Training loss: 1.7781236171722412
Validation loss: 2.0601389049201884

Epoch: 6| Step: 6
Training loss: 1.3850191831588745
Validation loss: 2.108189421315347

Epoch: 6| Step: 7
Training loss: 1.5432100296020508
Validation loss: 2.1121526661739556

Epoch: 6| Step: 8
Training loss: 1.599567174911499
Validation loss: 2.133675757274833

Epoch: 6| Step: 9
Training loss: 1.7802965641021729
Validation loss: 2.1464535241485923

Epoch: 6| Step: 10
Training loss: 2.029783248901367
Validation loss: 2.167049951450799

Epoch: 6| Step: 11
Training loss: 1.3576253652572632
Validation loss: 2.1708283514104862

Epoch: 6| Step: 12
Training loss: 1.2863554954528809
Validation loss: 2.1442318988102738

Epoch: 6| Step: 13
Training loss: 1.3790949583053589
Validation loss: 2.1004003581180366

Epoch: 173| Step: 0
Training loss: 1.8578848838806152
Validation loss: 2.100682394478911

Epoch: 6| Step: 1
Training loss: 1.8510724306106567
Validation loss: 2.101100185865997

Epoch: 6| Step: 2
Training loss: 1.0281263589859009
Validation loss: 2.118154287338257

Epoch: 6| Step: 3
Training loss: 1.1202247142791748
Validation loss: 2.1182576302559144

Epoch: 6| Step: 4
Training loss: 0.6541136503219604
Validation loss: 2.0764107050434237

Epoch: 6| Step: 5
Training loss: 1.4320999383926392
Validation loss: 2.085272144245845

Epoch: 6| Step: 6
Training loss: 1.5418670177459717
Validation loss: 2.073295875262189

Epoch: 6| Step: 7
Training loss: 2.006450653076172
Validation loss: 2.0882312854131064

Epoch: 6| Step: 8
Training loss: 2.3423349857330322
Validation loss: 2.07890223944059

Epoch: 6| Step: 9
Training loss: 1.457977056503296
Validation loss: 2.0591435445252286

Epoch: 6| Step: 10
Training loss: 1.2024524211883545
Validation loss: 2.046341655074909

Epoch: 6| Step: 11
Training loss: 1.1399444341659546
Validation loss: 2.007025170069869

Epoch: 6| Step: 12
Training loss: 1.4276869297027588
Validation loss: 1.983606788419908

Epoch: 6| Step: 13
Training loss: 0.9818609952926636
Validation loss: 2.0109423911699684

Epoch: 174| Step: 0
Training loss: 0.9423174262046814
Validation loss: 2.016648959088069

Epoch: 6| Step: 1
Training loss: 0.8380745649337769
Validation loss: 2.0781064648782053

Epoch: 6| Step: 2
Training loss: 1.0129445791244507
Validation loss: 2.1365507264291086

Epoch: 6| Step: 3
Training loss: 1.5212428569793701
Validation loss: 2.169346829896332

Epoch: 6| Step: 4
Training loss: 1.4418550729751587
Validation loss: 2.180894549174975

Epoch: 6| Step: 5
Training loss: 2.2205252647399902
Validation loss: 2.156504802806403

Epoch: 6| Step: 6
Training loss: 2.0385499000549316
Validation loss: 2.149142929302749

Epoch: 6| Step: 7
Training loss: 1.2780319452285767
Validation loss: 2.1521047776745212

Epoch: 6| Step: 8
Training loss: 1.5307098627090454
Validation loss: 2.151687014487482

Epoch: 6| Step: 9
Training loss: 1.713413953781128
Validation loss: 2.1806964746085544

Epoch: 6| Step: 10
Training loss: 0.976290762424469
Validation loss: 2.167662952535896

Epoch: 6| Step: 11
Training loss: 1.4109017848968506
Validation loss: 2.122552397430584

Epoch: 6| Step: 12
Training loss: 1.5963033437728882
Validation loss: 2.1068496037555

Epoch: 6| Step: 13
Training loss: 1.6433066129684448
Validation loss: 2.0957842026987383

Epoch: 175| Step: 0
Training loss: 1.3170835971832275
Validation loss: 2.1114009452122513

Epoch: 6| Step: 1
Training loss: 1.3490827083587646
Validation loss: 2.1079169960432154

Epoch: 6| Step: 2
Training loss: 1.0889031887054443
Validation loss: 2.136827366326445

Epoch: 6| Step: 3
Training loss: 1.3742692470550537
Validation loss: 2.176534675782727

Epoch: 6| Step: 4
Training loss: 1.1890909671783447
Validation loss: 2.2463959558035738

Epoch: 6| Step: 5
Training loss: 0.9647713899612427
Validation loss: 2.289206067721049

Epoch: 6| Step: 6
Training loss: 1.6610488891601562
Validation loss: 2.2943220753823557

Epoch: 6| Step: 7
Training loss: 1.3522517681121826
Validation loss: 2.2716966085536505

Epoch: 6| Step: 8
Training loss: 1.987902045249939
Validation loss: 2.2275665396003315

Epoch: 6| Step: 9
Training loss: 1.743215799331665
Validation loss: 2.1641638894234934

Epoch: 6| Step: 10
Training loss: 1.4505820274353027
Validation loss: 2.110229580633102

Epoch: 6| Step: 11
Training loss: 1.6239430904388428
Validation loss: 2.0287524384836995

Epoch: 6| Step: 12
Training loss: 1.463026762008667
Validation loss: 1.9924745700692619

Epoch: 6| Step: 13
Training loss: 2.262885570526123
Validation loss: 1.9690411847124818

Epoch: 176| Step: 0
Training loss: 1.2824070453643799
Validation loss: 2.0040133563421105

Epoch: 6| Step: 1
Training loss: 1.3952008485794067
Validation loss: 1.979952173848306

Epoch: 6| Step: 2
Training loss: 1.6781240701675415
Validation loss: 1.9806759331815986

Epoch: 6| Step: 3
Training loss: 1.1789714097976685
Validation loss: 2.004090375797723

Epoch: 6| Step: 4
Training loss: 1.3947784900665283
Validation loss: 2.009493371491791

Epoch: 6| Step: 5
Training loss: 1.2844350337982178
Validation loss: 2.023571211804626

Epoch: 6| Step: 6
Training loss: 1.4228687286376953
Validation loss: 2.0844887789859565

Epoch: 6| Step: 7
Training loss: 1.3211445808410645
Validation loss: 2.1276362006382277

Epoch: 6| Step: 8
Training loss: 1.6677451133728027
Validation loss: 2.178047328866938

Epoch: 6| Step: 9
Training loss: 1.7821341753005981
Validation loss: 2.1766399593763452

Epoch: 6| Step: 10
Training loss: 1.5641419887542725
Validation loss: 2.173512533146848

Epoch: 6| Step: 11
Training loss: 1.2268307209014893
Validation loss: 2.155527731423737

Epoch: 6| Step: 12
Training loss: 1.035326600074768
Validation loss: 2.1563963736257246

Epoch: 6| Step: 13
Training loss: 1.976006031036377
Validation loss: 2.1200797506558

Epoch: 177| Step: 0
Training loss: 0.7374241352081299
Validation loss: 2.0519666287206833

Epoch: 6| Step: 1
Training loss: 1.6966590881347656
Validation loss: 2.0205061435699463

Epoch: 6| Step: 2
Training loss: 1.4051291942596436
Validation loss: 2.00705785136069

Epoch: 6| Step: 3
Training loss: 1.3023576736450195
Validation loss: 2.011921321192095

Epoch: 6| Step: 4
Training loss: 1.6891403198242188
Validation loss: 2.014751552253641

Epoch: 6| Step: 5
Training loss: 1.2864251136779785
Validation loss: 1.9845484302889915

Epoch: 6| Step: 6
Training loss: 1.0517115592956543
Validation loss: 2.0056335259509344

Epoch: 6| Step: 7
Training loss: 0.9498032331466675
Validation loss: 2.0212598257167365

Epoch: 6| Step: 8
Training loss: 1.5533952713012695
Validation loss: 2.027314278387254

Epoch: 6| Step: 9
Training loss: 2.1886253356933594
Validation loss: 2.0846931319082938

Epoch: 6| Step: 10
Training loss: 1.8959177732467651
Validation loss: 2.1529525877327047

Epoch: 6| Step: 11
Training loss: 1.205296277999878
Validation loss: 2.1421685141901814

Epoch: 6| Step: 12
Training loss: 1.2881228923797607
Validation loss: 2.1461792530552035

Epoch: 6| Step: 13
Training loss: 1.407365083694458
Validation loss: 2.1427377013749975

Epoch: 178| Step: 0
Training loss: 1.5698459148406982
Validation loss: 2.1081889034599386

Epoch: 6| Step: 1
Training loss: 1.7137298583984375
Validation loss: 2.051510303251205

Epoch: 6| Step: 2
Training loss: 1.1625580787658691
Validation loss: 2.0355635304604807

Epoch: 6| Step: 3
Training loss: 1.1026842594146729
Validation loss: 2.0509717310628583

Epoch: 6| Step: 4
Training loss: 1.3227249383926392
Validation loss: 2.113923539397537

Epoch: 6| Step: 5
Training loss: 0.9282699823379517
Validation loss: 2.1369453732685377

Epoch: 6| Step: 6
Training loss: 1.192168951034546
Validation loss: 2.1370186472451813

Epoch: 6| Step: 7
Training loss: 1.5435428619384766
Validation loss: 2.133521577363373

Epoch: 6| Step: 8
Training loss: 1.4268200397491455
Validation loss: 2.186187505722046

Epoch: 6| Step: 9
Training loss: 1.842660665512085
Validation loss: 2.215355693653066

Epoch: 6| Step: 10
Training loss: 1.2393105030059814
Validation loss: 2.2013915020932435

Epoch: 6| Step: 11
Training loss: 1.046047329902649
Validation loss: 2.175496450034521

Epoch: 6| Step: 12
Training loss: 2.024951934814453
Validation loss: 2.184838584674302

Epoch: 6| Step: 13
Training loss: 0.8887901902198792
Validation loss: 2.161434886276081

Epoch: 179| Step: 0
Training loss: 1.029870629310608
Validation loss: 2.1317338905026837

Epoch: 6| Step: 1
Training loss: 1.3107287883758545
Validation loss: 2.1202101220366774

Epoch: 6| Step: 2
Training loss: 1.6779837608337402
Validation loss: 2.130184227420438

Epoch: 6| Step: 3
Training loss: 1.1275568008422852
Validation loss: 2.095691031025302

Epoch: 6| Step: 4
Training loss: 1.3374303579330444
Validation loss: 2.0920364984902005

Epoch: 6| Step: 5
Training loss: 1.8154664039611816
Validation loss: 2.1188633275288407

Epoch: 6| Step: 6
Training loss: 1.4705208539962769
Validation loss: 2.0823863091007357

Epoch: 6| Step: 7
Training loss: 0.8991184830665588
Validation loss: 2.1044324623641146

Epoch: 6| Step: 8
Training loss: 0.993349552154541
Validation loss: 2.06741423760691

Epoch: 6| Step: 9
Training loss: 1.1481692790985107
Validation loss: 2.0872942298971195

Epoch: 6| Step: 10
Training loss: 1.7676714658737183
Validation loss: 2.0938074665684856

Epoch: 6| Step: 11
Training loss: 1.7369847297668457
Validation loss: 2.116143108696066

Epoch: 6| Step: 12
Training loss: 1.1618015766143799
Validation loss: 2.1353247473316808

Epoch: 6| Step: 13
Training loss: 1.2267853021621704
Validation loss: 2.122397406126863

Epoch: 180| Step: 0
Training loss: 0.9140781164169312
Validation loss: 2.149229035582594

Epoch: 6| Step: 1
Training loss: 1.4813387393951416
Validation loss: 2.1221245642631286

Epoch: 6| Step: 2
Training loss: 2.156796932220459
Validation loss: 2.1427816524300525

Epoch: 6| Step: 3
Training loss: 1.5921272039413452
Validation loss: 2.1445399330508326

Epoch: 6| Step: 4
Training loss: 0.8186841011047363
Validation loss: 2.143021563048004

Epoch: 6| Step: 5
Training loss: 1.1947802305221558
Validation loss: 2.1294018863349833

Epoch: 6| Step: 6
Training loss: 1.2696141004562378
Validation loss: 2.120340980509276

Epoch: 6| Step: 7
Training loss: 1.293903112411499
Validation loss: 2.143708085501066

Epoch: 6| Step: 8
Training loss: 0.9949095249176025
Validation loss: 2.0946057970805834

Epoch: 6| Step: 9
Training loss: 1.9160710573196411
Validation loss: 2.0782436888705016

Epoch: 6| Step: 10
Training loss: 0.634506106376648
Validation loss: 2.0883107903183147

Epoch: 6| Step: 11
Training loss: 1.485170602798462
Validation loss: 2.0965798747154976

Epoch: 6| Step: 12
Training loss: 1.5401798486709595
Validation loss: 2.0893601448305192

Epoch: 6| Step: 13
Training loss: 1.2817602157592773
Validation loss: 2.1118054595044864

Epoch: 181| Step: 0
Training loss: 1.1952595710754395
Validation loss: 2.143541843660416

Epoch: 6| Step: 1
Training loss: 1.2611395120620728
Validation loss: 2.1342456186971357

Epoch: 6| Step: 2
Training loss: 1.6567175388336182
Validation loss: 2.126579112904046

Epoch: 6| Step: 3
Training loss: 0.7305825352668762
Validation loss: 2.110738661981398

Epoch: 6| Step: 4
Training loss: 1.623523473739624
Validation loss: 2.086755714108867

Epoch: 6| Step: 5
Training loss: 1.129770278930664
Validation loss: 2.034093044137442

Epoch: 6| Step: 6
Training loss: 1.5958690643310547
Validation loss: 2.004770965986354

Epoch: 6| Step: 7
Training loss: 1.276315450668335
Validation loss: 2.0302063265154437

Epoch: 6| Step: 8
Training loss: 1.3635553121566772
Validation loss: 2.0460550810701106

Epoch: 6| Step: 9
Training loss: 1.1979362964630127
Validation loss: 2.077363924313617

Epoch: 6| Step: 10
Training loss: 1.2000253200531006
Validation loss: 2.1351695599094516

Epoch: 6| Step: 11
Training loss: 1.2432997226715088
Validation loss: 2.164534358568089

Epoch: 6| Step: 12
Training loss: 2.105377674102783
Validation loss: 2.2071890266992713

Epoch: 6| Step: 13
Training loss: 1.0450938940048218
Validation loss: 2.2035359054483394

Epoch: 182| Step: 0
Training loss: 1.4708516597747803
Validation loss: 2.1742004143294467

Epoch: 6| Step: 1
Training loss: 1.3516874313354492
Validation loss: 2.1575431772457656

Epoch: 6| Step: 2
Training loss: 1.86410653591156
Validation loss: 2.117087156541886

Epoch: 6| Step: 3
Training loss: 1.4220304489135742
Validation loss: 2.1199316837454356

Epoch: 6| Step: 4
Training loss: 1.0322840213775635
Validation loss: 2.0944325847010457

Epoch: 6| Step: 5
Training loss: 1.6425137519836426
Validation loss: 2.059987486049693

Epoch: 6| Step: 6
Training loss: 1.5762255191802979
Validation loss: 2.0574107503378265

Epoch: 6| Step: 7
Training loss: 0.8325250744819641
Validation loss: 2.036720383551813

Epoch: 6| Step: 8
Training loss: 1.1622090339660645
Validation loss: 2.087718217603622

Epoch: 6| Step: 9
Training loss: 0.9060282707214355
Validation loss: 2.1447712939272643

Epoch: 6| Step: 10
Training loss: 1.641495943069458
Validation loss: 2.1381588238541798

Epoch: 6| Step: 11
Training loss: 0.9342314004898071
Validation loss: 2.19225618403445

Epoch: 6| Step: 12
Training loss: 1.4323348999023438
Validation loss: 2.232416090144906

Epoch: 6| Step: 13
Training loss: 1.6455252170562744
Validation loss: 2.2140246104168635

Epoch: 183| Step: 0
Training loss: 1.5215163230895996
Validation loss: 2.1361578741381244

Epoch: 6| Step: 1
Training loss: 1.1531391143798828
Validation loss: 2.0867600120523924

Epoch: 6| Step: 2
Training loss: 1.7329275608062744
Validation loss: 2.0390221867510068

Epoch: 6| Step: 3
Training loss: 1.31180739402771
Validation loss: 1.9804489048578406

Epoch: 6| Step: 4
Training loss: 1.318990707397461
Validation loss: 2.0103484635711997

Epoch: 6| Step: 5
Training loss: 1.8617069721221924
Validation loss: 2.0230255562772035

Epoch: 6| Step: 6
Training loss: 1.4726837873458862
Validation loss: 2.070188727430118

Epoch: 6| Step: 7
Training loss: 0.9402430653572083
Validation loss: 2.1268648383437947

Epoch: 6| Step: 8
Training loss: 0.6698445677757263
Validation loss: 2.165079532131072

Epoch: 6| Step: 9
Training loss: 1.223116397857666
Validation loss: 2.2636574596487065

Epoch: 6| Step: 10
Training loss: 0.912468433380127
Validation loss: 2.275378188779277

Epoch: 6| Step: 11
Training loss: 1.1584867238998413
Validation loss: 2.246971199589391

Epoch: 6| Step: 12
Training loss: 1.8384814262390137
Validation loss: 2.2105185421564246

Epoch: 6| Step: 13
Training loss: 1.3281073570251465
Validation loss: 2.1659062472722863

Epoch: 184| Step: 0
Training loss: 1.996222734451294
Validation loss: 2.1278231733588764

Epoch: 6| Step: 1
Training loss: 1.391672968864441
Validation loss: 2.11387913585991

Epoch: 6| Step: 2
Training loss: 0.8938060402870178
Validation loss: 2.0918383521418416

Epoch: 6| Step: 3
Training loss: 1.3520736694335938
Validation loss: 2.1127637791377243

Epoch: 6| Step: 4
Training loss: 1.7539317607879639
Validation loss: 2.1201539962522444

Epoch: 6| Step: 5
Training loss: 0.977590024471283
Validation loss: 2.1314198970794678

Epoch: 6| Step: 6
Training loss: 0.8714206218719482
Validation loss: 2.1573160245854366

Epoch: 6| Step: 7
Training loss: 1.2294244766235352
Validation loss: 2.178118023821103

Epoch: 6| Step: 8
Training loss: 1.4965101480484009
Validation loss: 2.1906431464738745

Epoch: 6| Step: 9
Training loss: 1.3335871696472168
Validation loss: 2.158085979441161

Epoch: 6| Step: 10
Training loss: 1.4882373809814453
Validation loss: 2.168099216235581

Epoch: 6| Step: 11
Training loss: 1.184105396270752
Validation loss: 2.169242860168539

Epoch: 6| Step: 12
Training loss: 0.7541075348854065
Validation loss: 2.1415616594335085

Epoch: 6| Step: 13
Training loss: 1.5335055589675903
Validation loss: 2.1085318826859996

Epoch: 185| Step: 0
Training loss: 0.7256568670272827
Validation loss: 2.0929359184798373

Epoch: 6| Step: 1
Training loss: 1.129610300064087
Validation loss: 2.1083398621569396

Epoch: 6| Step: 2
Training loss: 1.4477063417434692
Validation loss: 2.1383346383289625

Epoch: 6| Step: 3
Training loss: 1.3169713020324707
Validation loss: 2.1545389570215696

Epoch: 6| Step: 4
Training loss: 1.4510780572891235
Validation loss: 2.1691294857250747

Epoch: 6| Step: 5
Training loss: 0.8869634866714478
Validation loss: 2.1829979317162627

Epoch: 6| Step: 6
Training loss: 1.6229157447814941
Validation loss: 2.1930918308996383

Epoch: 6| Step: 7
Training loss: 1.8963364362716675
Validation loss: 2.1420913768071

Epoch: 6| Step: 8
Training loss: 1.706676959991455
Validation loss: 2.120341880347139

Epoch: 6| Step: 9
Training loss: 1.2045308351516724
Validation loss: 2.098780790964762

Epoch: 6| Step: 10
Training loss: 0.7630636692047119
Validation loss: 2.1094458205725557

Epoch: 6| Step: 11
Training loss: 1.020207166671753
Validation loss: 2.1444740808138283

Epoch: 6| Step: 12
Training loss: 1.385646104812622
Validation loss: 2.1611831431747763

Epoch: 6| Step: 13
Training loss: 1.05294930934906
Validation loss: 2.174199342727661

Epoch: 186| Step: 0
Training loss: 0.951702892780304
Validation loss: 2.1001446875192786

Epoch: 6| Step: 1
Training loss: 0.8616924285888672
Validation loss: 2.0577428417821086

Epoch: 6| Step: 2
Training loss: 1.1710104942321777
Validation loss: 2.0143393316576557

Epoch: 6| Step: 3
Training loss: 1.6585174798965454
Validation loss: 2.0122894061509

Epoch: 6| Step: 4
Training loss: 0.6133948564529419
Validation loss: 2.027924350512925

Epoch: 6| Step: 5
Training loss: 1.1274876594543457
Validation loss: 2.011883465192651

Epoch: 6| Step: 6
Training loss: 1.3792877197265625
Validation loss: 2.037358812106553

Epoch: 6| Step: 7
Training loss: 1.595729112625122
Validation loss: 2.068308030405352

Epoch: 6| Step: 8
Training loss: 1.573500633239746
Validation loss: 2.1332273957549885

Epoch: 6| Step: 9
Training loss: 1.3950774669647217
Validation loss: 2.1490822146015782

Epoch: 6| Step: 10
Training loss: 1.4203464984893799
Validation loss: 2.1814890958929576

Epoch: 6| Step: 11
Training loss: 1.3858411312103271
Validation loss: 2.201506906940091

Epoch: 6| Step: 12
Training loss: 0.8290104866027832
Validation loss: 2.171781183570944

Epoch: 6| Step: 13
Training loss: 1.7646794319152832
Validation loss: 2.147622157168645

Epoch: 187| Step: 0
Training loss: 1.2372480630874634
Validation loss: 2.094501115942514

Epoch: 6| Step: 1
Training loss: 1.0339598655700684
Validation loss: 2.064126499237553

Epoch: 6| Step: 2
Training loss: 0.9061461687088013
Validation loss: 2.06648172614395

Epoch: 6| Step: 3
Training loss: 1.9647042751312256
Validation loss: 2.04471613771172

Epoch: 6| Step: 4
Training loss: 1.1641747951507568
Validation loss: 2.089566339728653

Epoch: 6| Step: 5
Training loss: 1.7217175960540771
Validation loss: 2.0964712712072555

Epoch: 6| Step: 6
Training loss: 0.9749210476875305
Validation loss: 2.1409458062982045

Epoch: 6| Step: 7
Training loss: 1.6767886877059937
Validation loss: 2.16412442217591

Epoch: 6| Step: 8
Training loss: 1.599332332611084
Validation loss: 2.2045796891694427

Epoch: 6| Step: 9
Training loss: 0.6708526015281677
Validation loss: 2.1666066800394366

Epoch: 6| Step: 10
Training loss: 1.4417827129364014
Validation loss: 2.182801486343466

Epoch: 6| Step: 11
Training loss: 0.6499093770980835
Validation loss: 2.15370681465313

Epoch: 6| Step: 12
Training loss: 1.14642333984375
Validation loss: 2.1068274513367684

Epoch: 6| Step: 13
Training loss: 1.1457915306091309
Validation loss: 2.11392387267082

Epoch: 188| Step: 0
Training loss: 1.1575231552124023
Validation loss: 2.059313756163402

Epoch: 6| Step: 1
Training loss: 0.8552990555763245
Validation loss: 2.015294567231209

Epoch: 6| Step: 2
Training loss: 1.222217082977295
Validation loss: 1.9964422077260993

Epoch: 6| Step: 3
Training loss: 1.6242307424545288
Validation loss: 2.0201585959362727

Epoch: 6| Step: 4
Training loss: 0.9921767115592957
Validation loss: 2.0433161130515476

Epoch: 6| Step: 5
Training loss: 1.271306037902832
Validation loss: 2.059111428517167

Epoch: 6| Step: 6
Training loss: 1.3861007690429688
Validation loss: 2.0952518909208235

Epoch: 6| Step: 7
Training loss: 1.4921596050262451
Validation loss: 2.084791383435649

Epoch: 6| Step: 8
Training loss: 1.0939749479293823
Validation loss: 2.1086748620515228

Epoch: 6| Step: 9
Training loss: 1.5654082298278809
Validation loss: 2.141060085706813

Epoch: 6| Step: 10
Training loss: 1.7086236476898193
Validation loss: 2.18709800833015

Epoch: 6| Step: 11
Training loss: 1.572547197341919
Validation loss: 2.172617745655839

Epoch: 6| Step: 12
Training loss: 0.43207791447639465
Validation loss: 2.1754732362685667

Epoch: 6| Step: 13
Training loss: 0.9718027114868164
Validation loss: 2.205890022298341

Epoch: 189| Step: 0
Training loss: 0.9380618333816528
Validation loss: 2.1944481301051315

Epoch: 6| Step: 1
Training loss: 1.0630919933319092
Validation loss: 2.2285721314850675

Epoch: 6| Step: 2
Training loss: 1.4779527187347412
Validation loss: 2.2224420719249274

Epoch: 6| Step: 3
Training loss: 0.9748101234436035
Validation loss: 2.1883485201866395

Epoch: 6| Step: 4
Training loss: 1.261350393295288
Validation loss: 2.156641052615258

Epoch: 6| Step: 5
Training loss: 1.1987895965576172
Validation loss: 2.108999257446617

Epoch: 6| Step: 6
Training loss: 0.9848138093948364
Validation loss: 2.103652513155373

Epoch: 6| Step: 7
Training loss: 1.039204716682434
Validation loss: 2.0693130980255785

Epoch: 6| Step: 8
Training loss: 1.672157883644104
Validation loss: 2.069470464542348

Epoch: 6| Step: 9
Training loss: 1.675838828086853
Validation loss: 2.1135748253073743

Epoch: 6| Step: 10
Training loss: 1.0650839805603027
Validation loss: 2.1278862722458376

Epoch: 6| Step: 11
Training loss: 1.0817885398864746
Validation loss: 2.1249619478820474

Epoch: 6| Step: 12
Training loss: 1.3522193431854248
Validation loss: 2.1431597163600307

Epoch: 6| Step: 13
Training loss: 1.3279964923858643
Validation loss: 2.1386658940263974

Epoch: 190| Step: 0
Training loss: 1.3983936309814453
Validation loss: 2.0940587635963195

Epoch: 6| Step: 1
Training loss: 1.2169731855392456
Validation loss: 2.090268620880701

Epoch: 6| Step: 2
Training loss: 1.1599271297454834
Validation loss: 2.0495377996916413

Epoch: 6| Step: 3
Training loss: 1.4076491594314575
Validation loss: 2.094894693743798

Epoch: 6| Step: 4
Training loss: 1.2460556030273438
Validation loss: 2.1235742658697148

Epoch: 6| Step: 5
Training loss: 0.4949266016483307
Validation loss: 2.133495847384135

Epoch: 6| Step: 6
Training loss: 1.3587024211883545
Validation loss: 2.1488964198738016

Epoch: 6| Step: 7
Training loss: 0.8713088035583496
Validation loss: 2.1290167403477493

Epoch: 6| Step: 8
Training loss: 0.9683168530464172
Validation loss: 2.0932230949401855

Epoch: 6| Step: 9
Training loss: 0.9623970985412598
Validation loss: 2.077959391378587

Epoch: 6| Step: 10
Training loss: 1.6225306987762451
Validation loss: 2.0953326763645297

Epoch: 6| Step: 11
Training loss: 1.179734230041504
Validation loss: 2.0953200376161965

Epoch: 6| Step: 12
Training loss: 0.9414085149765015
Validation loss: 2.1084525123719247

Epoch: 6| Step: 13
Training loss: 1.8393546342849731
Validation loss: 2.1230803510194183

Epoch: 191| Step: 0
Training loss: 0.8727753162384033
Validation loss: 2.090922758143435

Epoch: 6| Step: 1
Training loss: 1.1719613075256348
Validation loss: 2.1060849928086802

Epoch: 6| Step: 2
Training loss: 1.386077880859375
Validation loss: 2.126433466070442

Epoch: 6| Step: 3
Training loss: 2.0315606594085693
Validation loss: 2.1233803187647173

Epoch: 6| Step: 4
Training loss: 1.3649414777755737
Validation loss: 2.164329703136157

Epoch: 6| Step: 5
Training loss: 1.0507991313934326
Validation loss: 2.17660125096639

Epoch: 6| Step: 6
Training loss: 0.8213127255439758
Validation loss: 2.1600801944732666

Epoch: 6| Step: 7
Training loss: 0.7275906205177307
Validation loss: 2.1281899098427064

Epoch: 6| Step: 8
Training loss: 0.9788639545440674
Validation loss: 2.069164240232078

Epoch: 6| Step: 9
Training loss: 1.1021792888641357
Validation loss: 2.071443949976275

Epoch: 6| Step: 10
Training loss: 1.111899733543396
Validation loss: 2.0432263574292584

Epoch: 6| Step: 11
Training loss: 1.0802223682403564
Validation loss: 2.008252905261132

Epoch: 6| Step: 12
Training loss: 1.0699505805969238
Validation loss: 2.0471620405873945

Epoch: 6| Step: 13
Training loss: 1.8281561136245728
Validation loss: 2.089257094167894

Epoch: 192| Step: 0
Training loss: 1.4073007106781006
Validation loss: 2.1091056767330376

Epoch: 6| Step: 1
Training loss: 1.2789908647537231
Validation loss: 2.1570693856926373

Epoch: 6| Step: 2
Training loss: 0.7795267701148987
Validation loss: 2.164316233768258

Epoch: 6| Step: 3
Training loss: 1.2691068649291992
Validation loss: 2.225199104637228

Epoch: 6| Step: 4
Training loss: 1.1280964612960815
Validation loss: 2.2492282364958074

Epoch: 6| Step: 5
Training loss: 1.152967929840088
Validation loss: 2.23054438765331

Epoch: 6| Step: 6
Training loss: 1.0677289962768555
Validation loss: 2.191505644911079

Epoch: 6| Step: 7
Training loss: 1.2818024158477783
Validation loss: 2.1552264792944795

Epoch: 6| Step: 8
Training loss: 0.8682293891906738
Validation loss: 2.0957563102886243

Epoch: 6| Step: 9
Training loss: 1.0565167665481567
Validation loss: 2.10454850171202

Epoch: 6| Step: 10
Training loss: 1.2852811813354492
Validation loss: 2.11523861013433

Epoch: 6| Step: 11
Training loss: 0.9871364235877991
Validation loss: 2.09798127348705

Epoch: 6| Step: 12
Training loss: 1.338169813156128
Validation loss: 2.1057700111019995

Epoch: 6| Step: 13
Training loss: 1.2158632278442383
Validation loss: 2.088338791683156

Epoch: 193| Step: 0
Training loss: 1.288506269454956
Validation loss: 2.098290720293599

Epoch: 6| Step: 1
Training loss: 1.2308769226074219
Validation loss: 2.0899119428409043

Epoch: 6| Step: 2
Training loss: 0.7671381235122681
Validation loss: 2.083454789653901

Epoch: 6| Step: 3
Training loss: 1.3676609992980957
Validation loss: 2.0929643428453835

Epoch: 6| Step: 4
Training loss: 1.2711248397827148
Validation loss: 2.077840269252818

Epoch: 6| Step: 5
Training loss: 1.477302074432373
Validation loss: 2.0949362554857807

Epoch: 6| Step: 6
Training loss: 0.5678282976150513
Validation loss: 2.0845122234795683

Epoch: 6| Step: 7
Training loss: 1.2696017026901245
Validation loss: 2.081955340600783

Epoch: 6| Step: 8
Training loss: 1.0110723972320557
Validation loss: 2.1030676211080244

Epoch: 6| Step: 9
Training loss: 1.1797422170639038
Validation loss: 2.0982418085939143

Epoch: 6| Step: 10
Training loss: 1.5550265312194824
Validation loss: 2.1096625122972714

Epoch: 6| Step: 11
Training loss: 1.210082769393921
Validation loss: 2.1165253577693814

Epoch: 6| Step: 12
Training loss: 0.5617867708206177
Validation loss: 2.141964404813705

Epoch: 6| Step: 13
Training loss: 0.834916889667511
Validation loss: 2.133022327576914

Epoch: 194| Step: 0
Training loss: 1.462907075881958
Validation loss: 2.1307756182967976

Epoch: 6| Step: 1
Training loss: 0.6981046199798584
Validation loss: 2.169118071115145

Epoch: 6| Step: 2
Training loss: 0.9959771633148193
Validation loss: 2.170897319752683

Epoch: 6| Step: 3
Training loss: 0.8719204664230347
Validation loss: 2.2088895972057054

Epoch: 6| Step: 4
Training loss: 1.0868395566940308
Validation loss: 2.1589050421150784

Epoch: 6| Step: 5
Training loss: 1.2100520133972168
Validation loss: 2.0856759522550847

Epoch: 6| Step: 6
Training loss: 1.4855422973632812
Validation loss: 2.0313344706771193

Epoch: 6| Step: 7
Training loss: 0.5718981027603149
Validation loss: 2.030465869493382

Epoch: 6| Step: 8
Training loss: 1.8638560771942139
Validation loss: 1.9938919967220676

Epoch: 6| Step: 9
Training loss: 1.3377249240875244
Validation loss: 1.9690682888031006

Epoch: 6| Step: 10
Training loss: 1.6015729904174805
Validation loss: 1.968134731374761

Epoch: 6| Step: 11
Training loss: 0.8885261416435242
Validation loss: 1.9899700059685657

Epoch: 6| Step: 12
Training loss: 1.2943800687789917
Validation loss: 2.0237202234165643

Epoch: 6| Step: 13
Training loss: 0.9016115665435791
Validation loss: 2.073754284971504

Epoch: 195| Step: 0
Training loss: 1.1489555835723877
Validation loss: 2.118307025201859

Epoch: 6| Step: 1
Training loss: 1.2762200832366943
Validation loss: 2.1718283109767462

Epoch: 6| Step: 2
Training loss: 1.2351953983306885
Validation loss: 2.2085318052640526

Epoch: 6| Step: 3
Training loss: 1.2952160835266113
Validation loss: 2.202025895477623

Epoch: 6| Step: 4
Training loss: 1.1777280569076538
Validation loss: 2.179545887054936

Epoch: 6| Step: 5
Training loss: 0.8993598222732544
Validation loss: 2.1072423253008115

Epoch: 6| Step: 6
Training loss: 1.0033764839172363
Validation loss: 2.054210833323899

Epoch: 6| Step: 7
Training loss: 1.5644629001617432
Validation loss: 2.0208552268243607

Epoch: 6| Step: 8
Training loss: 1.1772137880325317
Validation loss: 2.001556028601944

Epoch: 6| Step: 9
Training loss: 1.0175917148590088
Validation loss: 2.0278093750758837

Epoch: 6| Step: 10
Training loss: 0.8944133520126343
Validation loss: 2.036985824185033

Epoch: 6| Step: 11
Training loss: 0.8635528087615967
Validation loss: 2.08582837863635

Epoch: 6| Step: 12
Training loss: 1.193114995956421
Validation loss: 2.0978714163585375

Epoch: 6| Step: 13
Training loss: 0.8240049481391907
Validation loss: 2.1640514327633764

Epoch: 196| Step: 0
Training loss: 1.1086509227752686
Validation loss: 2.168606541490042

Epoch: 6| Step: 1
Training loss: 0.7447504997253418
Validation loss: 2.163046124160931

Epoch: 6| Step: 2
Training loss: 1.0946002006530762
Validation loss: 2.1012822363966253

Epoch: 6| Step: 3
Training loss: 1.0427935123443604
Validation loss: 2.0474178021953953

Epoch: 6| Step: 4
Training loss: 1.1823053359985352
Validation loss: 2.0036647781249015

Epoch: 6| Step: 5
Training loss: 0.9082455635070801
Validation loss: 1.9783623731264504

Epoch: 6| Step: 6
Training loss: 1.5124447345733643
Validation loss: 2.0022136139613327

Epoch: 6| Step: 7
Training loss: 1.606987714767456
Validation loss: 2.0094032159415622

Epoch: 6| Step: 8
Training loss: 0.8279252052307129
Validation loss: 2.058811326180735

Epoch: 6| Step: 9
Training loss: 0.9095422029495239
Validation loss: 2.04475381681996

Epoch: 6| Step: 10
Training loss: 0.9805599451065063
Validation loss: 2.100380313011908

Epoch: 6| Step: 11
Training loss: 1.9343795776367188
Validation loss: 2.1550528336596746

Epoch: 6| Step: 12
Training loss: 1.377608299255371
Validation loss: 2.168012647218602

Epoch: 6| Step: 13
Training loss: 1.0209447145462036
Validation loss: 2.1663104590549263

Epoch: 197| Step: 0
Training loss: 0.9230520725250244
Validation loss: 2.1410113637165358

Epoch: 6| Step: 1
Training loss: 1.167016863822937
Validation loss: 2.1215338553151777

Epoch: 6| Step: 2
Training loss: 1.5519059896469116
Validation loss: 2.1169209634104083

Epoch: 6| Step: 3
Training loss: 1.156965732574463
Validation loss: 2.0748022858814528

Epoch: 6| Step: 4
Training loss: 0.8508753776550293
Validation loss: 2.0574471540348505

Epoch: 6| Step: 5
Training loss: 1.0578258037567139
Validation loss: 2.0805518216984247

Epoch: 6| Step: 6
Training loss: 1.7459337711334229
Validation loss: 2.0507144235795542

Epoch: 6| Step: 7
Training loss: 0.8233561515808105
Validation loss: 2.0734249494409047

Epoch: 6| Step: 8
Training loss: 1.849036455154419
Validation loss: 2.1161753439134166

Epoch: 6| Step: 9
Training loss: 1.0410125255584717
Validation loss: 2.1506253237365396

Epoch: 6| Step: 10
Training loss: 0.8056426644325256
Validation loss: 2.1892553247431272

Epoch: 6| Step: 11
Training loss: 1.2952872514724731
Validation loss: 2.213494325196871

Epoch: 6| Step: 12
Training loss: 1.3298101425170898
Validation loss: 2.190004630755353

Epoch: 6| Step: 13
Training loss: 1.6427357196807861
Validation loss: 2.220713496208191

Epoch: 198| Step: 0
Training loss: 1.001871943473816
Validation loss: 2.1799847848953737

Epoch: 6| Step: 1
Training loss: 1.4324185848236084
Validation loss: 2.185485916752969

Epoch: 6| Step: 2
Training loss: 1.1280171871185303
Validation loss: 2.16516633700299

Epoch: 6| Step: 3
Training loss: 1.517420768737793
Validation loss: 2.1515077929342947

Epoch: 6| Step: 4
Training loss: 0.8985214233398438
Validation loss: 2.130094620489305

Epoch: 6| Step: 5
Training loss: 1.0889065265655518
Validation loss: 2.0991931525609826

Epoch: 6| Step: 6
Training loss: 1.2174934148788452
Validation loss: 2.0632129458970923

Epoch: 6| Step: 7
Training loss: 1.2856152057647705
Validation loss: 2.052532813882315

Epoch: 6| Step: 8
Training loss: 1.1262884140014648
Validation loss: 1.9923080577645251

Epoch: 6| Step: 9
Training loss: 0.7703719735145569
Validation loss: 1.9943606674030263

Epoch: 6| Step: 10
Training loss: 0.9789370894432068
Validation loss: 2.0135164004500195

Epoch: 6| Step: 11
Training loss: 1.4389824867248535
Validation loss: 2.046134776966546

Epoch: 6| Step: 12
Training loss: 1.3966073989868164
Validation loss: 2.077937479942076

Epoch: 6| Step: 13
Training loss: 0.5777587294578552
Validation loss: 2.0944136163239837

Epoch: 199| Step: 0
Training loss: 1.132021188735962
Validation loss: 2.1365175452283633

Epoch: 6| Step: 1
Training loss: 1.3196260929107666
Validation loss: 2.104159246208847

Epoch: 6| Step: 2
Training loss: 1.440636396408081
Validation loss: 2.0862510614497687

Epoch: 6| Step: 3
Training loss: 0.9921022057533264
Validation loss: 2.070188069856295

Epoch: 6| Step: 4
Training loss: 1.4790332317352295
Validation loss: 2.027791700055522

Epoch: 6| Step: 5
Training loss: 0.6896509528160095
Validation loss: 2.0284881155977965

Epoch: 6| Step: 6
Training loss: 1.2684166431427002
Validation loss: 2.020098650327293

Epoch: 6| Step: 7
Training loss: 0.5709379315376282
Validation loss: 2.024956718567879

Epoch: 6| Step: 8
Training loss: 1.2821474075317383
Validation loss: 2.0697183993554886

Epoch: 6| Step: 9
Training loss: 1.2000929117202759
Validation loss: 2.064329634430588

Epoch: 6| Step: 10
Training loss: 0.9763500690460205
Validation loss: 2.109816425590105

Epoch: 6| Step: 11
Training loss: 1.091503381729126
Validation loss: 2.164713182756978

Epoch: 6| Step: 12
Training loss: 0.8951610326766968
Validation loss: 2.1533118665859265

Epoch: 6| Step: 13
Training loss: 1.0985674858093262
Validation loss: 2.0930900496821248

Epoch: 200| Step: 0
Training loss: 1.3845174312591553
Validation loss: 2.0868367123347458

Epoch: 6| Step: 1
Training loss: 0.8404058218002319
Validation loss: 2.0251893561373473

Epoch: 6| Step: 2
Training loss: 1.1604177951812744
Validation loss: 2.0308802832839308

Epoch: 6| Step: 3
Training loss: 1.0203511714935303
Validation loss: 1.998298354046319

Epoch: 6| Step: 4
Training loss: 1.2652437686920166
Validation loss: 1.9881011991090671

Epoch: 6| Step: 5
Training loss: 1.23607337474823
Validation loss: 1.986295215545162

Epoch: 6| Step: 6
Training loss: 1.1814720630645752
Validation loss: 1.998092092493529

Epoch: 6| Step: 7
Training loss: 0.9584261178970337
Validation loss: 2.0423979336215603

Epoch: 6| Step: 8
Training loss: 0.8947572708129883
Validation loss: 2.0695445229930263

Epoch: 6| Step: 9
Training loss: 1.0929787158966064
Validation loss: 2.108883306544314

Epoch: 6| Step: 10
Training loss: 1.0620224475860596
Validation loss: 2.1608553496740197

Epoch: 6| Step: 11
Training loss: 1.031692385673523
Validation loss: 2.200195174063406

Epoch: 6| Step: 12
Training loss: 1.3806817531585693
Validation loss: 2.1956282456715903

Epoch: 6| Step: 13
Training loss: 0.941736102104187
Validation loss: 2.2086188357363463

Epoch: 201| Step: 0
Training loss: 0.6440534591674805
Validation loss: 2.154581239146571

Epoch: 6| Step: 1
Training loss: 1.145918607711792
Validation loss: 2.1333669283056773

Epoch: 6| Step: 2
Training loss: 1.1376746892929077
Validation loss: 2.086378215461649

Epoch: 6| Step: 3
Training loss: 0.8744256496429443
Validation loss: 2.0869673913524998

Epoch: 6| Step: 4
Training loss: 1.1233913898468018
Validation loss: 2.074982084253783

Epoch: 6| Step: 5
Training loss: 1.6723943948745728
Validation loss: 2.068638878483926

Epoch: 6| Step: 6
Training loss: 1.3746662139892578
Validation loss: 2.0476325916987594

Epoch: 6| Step: 7
Training loss: 1.3063198328018188
Validation loss: 2.048692011064099

Epoch: 6| Step: 8
Training loss: 0.900328516960144
Validation loss: 2.0616213493449713

Epoch: 6| Step: 9
Training loss: 0.926784873008728
Validation loss: 2.0531137425412416

Epoch: 6| Step: 10
Training loss: 0.7752145528793335
Validation loss: 2.034091285479966

Epoch: 6| Step: 11
Training loss: 0.7484927773475647
Validation loss: 2.0273656255455426

Epoch: 6| Step: 12
Training loss: 0.8996449708938599
Validation loss: 2.0568322135556127

Epoch: 6| Step: 13
Training loss: 1.3008654117584229
Validation loss: 2.04848962829959

Epoch: 202| Step: 0
Training loss: 0.9130365252494812
Validation loss: 2.1332682460866947

Epoch: 6| Step: 1
Training loss: 0.8843356370925903
Validation loss: 2.157315105520269

Epoch: 6| Step: 2
Training loss: 1.777672529220581
Validation loss: 2.1735801542958906

Epoch: 6| Step: 3
Training loss: 1.21278977394104
Validation loss: 2.1803729341876124

Epoch: 6| Step: 4
Training loss: 1.0387837886810303
Validation loss: 2.1699390667741016

Epoch: 6| Step: 5
Training loss: 1.5646662712097168
Validation loss: 2.1875811546079573

Epoch: 6| Step: 6
Training loss: 1.1240317821502686
Validation loss: 2.12238327405786

Epoch: 6| Step: 7
Training loss: 1.2140753269195557
Validation loss: 2.1031803520776893

Epoch: 6| Step: 8
Training loss: 1.2715585231781006
Validation loss: 2.0694648681148404

Epoch: 6| Step: 9
Training loss: 0.6345598101615906
Validation loss: 2.0531257173066497

Epoch: 6| Step: 10
Training loss: 0.7276411056518555
Validation loss: 2.0430135778201524

Epoch: 6| Step: 11
Training loss: 0.9814269542694092
Validation loss: 2.0392555600853375

Epoch: 6| Step: 12
Training loss: 0.8568545579910278
Validation loss: 2.0445044335498603

Epoch: 6| Step: 13
Training loss: 1.4330874681472778
Validation loss: 2.0505069673702283

Epoch: 203| Step: 0
Training loss: 1.0946696996688843
Validation loss: 2.0798493046914377

Epoch: 6| Step: 1
Training loss: 1.0852677822113037
Validation loss: 2.059163990841117

Epoch: 6| Step: 2
Training loss: 1.1972426176071167
Validation loss: 2.0900658099882063

Epoch: 6| Step: 3
Training loss: 1.3419047594070435
Validation loss: 2.0985316614950857

Epoch: 6| Step: 4
Training loss: 1.366260290145874
Validation loss: 2.0741780522049114

Epoch: 6| Step: 5
Training loss: 1.2609738111495972
Validation loss: 2.112939562848819

Epoch: 6| Step: 6
Training loss: 1.055397868156433
Validation loss: 2.1494018057341218

Epoch: 6| Step: 7
Training loss: 0.787537693977356
Validation loss: 2.176519637466759

Epoch: 6| Step: 8
Training loss: 0.6582546234130859
Validation loss: 2.1723940782649542

Epoch: 6| Step: 9
Training loss: 1.0658671855926514
Validation loss: 2.1492962298854703

Epoch: 6| Step: 10
Training loss: 1.4457614421844482
Validation loss: 2.089422451552524

Epoch: 6| Step: 11
Training loss: 0.8461214303970337
Validation loss: 2.0750196056981243

Epoch: 6| Step: 12
Training loss: 0.8406435251235962
Validation loss: 2.007592115350949

Epoch: 6| Step: 13
Training loss: 0.8973689675331116
Validation loss: 1.967544832537251

Epoch: 204| Step: 0
Training loss: 0.8701345324516296
Validation loss: 1.903023273714127

Epoch: 6| Step: 1
Training loss: 1.033948302268982
Validation loss: 1.9465022305006623

Epoch: 6| Step: 2
Training loss: 1.085096836090088
Validation loss: 1.988675650729928

Epoch: 6| Step: 3
Training loss: 1.2275891304016113
Validation loss: 2.0273264582439134

Epoch: 6| Step: 4
Training loss: 0.9687471985816956
Validation loss: 2.0425070549852107

Epoch: 6| Step: 5
Training loss: 0.9405190944671631
Validation loss: 2.086742757469095

Epoch: 6| Step: 6
Training loss: 1.065023422241211
Validation loss: 2.076230587497834

Epoch: 6| Step: 7
Training loss: 0.9954779744148254
Validation loss: 2.0463988793793546

Epoch: 6| Step: 8
Training loss: 1.5960772037506104
Validation loss: 2.0436116008348364

Epoch: 6| Step: 9
Training loss: 1.2068421840667725
Validation loss: 2.0568327365383023

Epoch: 6| Step: 10
Training loss: 1.2086430788040161
Validation loss: 2.058589222610638

Epoch: 6| Step: 11
Training loss: 1.0113768577575684
Validation loss: 2.0478394749344035

Epoch: 6| Step: 12
Training loss: 0.618669867515564
Validation loss: 2.0511280516142487

Epoch: 6| Step: 13
Training loss: 1.0173227787017822
Validation loss: 2.0678330826502975

Epoch: 205| Step: 0
Training loss: 1.2247743606567383
Validation loss: 2.076369734220607

Epoch: 6| Step: 1
Training loss: 1.1885170936584473
Validation loss: 2.092900804294053

Epoch: 6| Step: 2
Training loss: 0.6161818504333496
Validation loss: 2.1125688629765667

Epoch: 6| Step: 3
Training loss: 0.8608332276344299
Validation loss: 2.1481840302867274

Epoch: 6| Step: 4
Training loss: 1.3452767133712769
Validation loss: 2.1335005657647246

Epoch: 6| Step: 5
Training loss: 0.6136739253997803
Validation loss: 2.1265029881590154

Epoch: 6| Step: 6
Training loss: 1.1729495525360107
Validation loss: 2.1032975771093882

Epoch: 6| Step: 7
Training loss: 0.9883908629417419
Validation loss: 2.07457112496899

Epoch: 6| Step: 8
Training loss: 1.3777439594268799
Validation loss: 2.057716355528883

Epoch: 6| Step: 9
Training loss: 0.812400758266449
Validation loss: 2.059429448138001

Epoch: 6| Step: 10
Training loss: 0.9363552927970886
Validation loss: 2.101406757549573

Epoch: 6| Step: 11
Training loss: 0.9546362161636353
Validation loss: 2.093214691326182

Epoch: 6| Step: 12
Training loss: 0.7315269112586975
Validation loss: 2.119126528821966

Epoch: 6| Step: 13
Training loss: 2.1714351177215576
Validation loss: 2.134381055831909

Epoch: 206| Step: 0
Training loss: 0.837325930595398
Validation loss: 2.117108937232725

Epoch: 6| Step: 1
Training loss: 1.0528970956802368
Validation loss: 2.0906163133600706

Epoch: 6| Step: 2
Training loss: 1.3646025657653809
Validation loss: 2.085034465277067

Epoch: 6| Step: 3
Training loss: 0.47159144282341003
Validation loss: 2.0764879077993412

Epoch: 6| Step: 4
Training loss: 1.0093998908996582
Validation loss: 2.067160637147965

Epoch: 6| Step: 5
Training loss: 1.5703643560409546
Validation loss: 2.071386919226698

Epoch: 6| Step: 6
Training loss: 0.5128771066665649
Validation loss: 2.0719538645077775

Epoch: 6| Step: 7
Training loss: 0.593777060508728
Validation loss: 2.078098125355218

Epoch: 6| Step: 8
Training loss: 0.6963739395141602
Validation loss: 2.090525580990699

Epoch: 6| Step: 9
Training loss: 0.9285509586334229
Validation loss: 2.1041398971311507

Epoch: 6| Step: 10
Training loss: 1.105912685394287
Validation loss: 2.14232700614519

Epoch: 6| Step: 11
Training loss: 1.0850753784179688
Validation loss: 2.1679759922847954

Epoch: 6| Step: 12
Training loss: 1.7451897859573364
Validation loss: 2.182962440675305

Epoch: 6| Step: 13
Training loss: 1.1123182773590088
Validation loss: 2.1936750258168867

Epoch: 207| Step: 0
Training loss: 1.131029486656189
Validation loss: 2.1483087437127226

Epoch: 6| Step: 1
Training loss: 0.8570173978805542
Validation loss: 2.1224090822281374

Epoch: 6| Step: 2
Training loss: 1.0241706371307373
Validation loss: 2.0933674689262145

Epoch: 6| Step: 3
Training loss: 0.643200159072876
Validation loss: 2.05338385540952

Epoch: 6| Step: 4
Training loss: 1.2036744356155396
Validation loss: 2.021265188852946

Epoch: 6| Step: 5
Training loss: 0.7795196771621704
Validation loss: 2.021798292795817

Epoch: 6| Step: 6
Training loss: 0.7608330249786377
Validation loss: 1.9808026744473366

Epoch: 6| Step: 7
Training loss: 1.4063581228256226
Validation loss: 2.008826050707089

Epoch: 6| Step: 8
Training loss: 0.81955885887146
Validation loss: 2.000132337693245

Epoch: 6| Step: 9
Training loss: 0.7466266751289368
Validation loss: 2.017316567000522

Epoch: 6| Step: 10
Training loss: 1.1917906999588013
Validation loss: 2.099754184804937

Epoch: 6| Step: 11
Training loss: 1.114029049873352
Validation loss: 2.101661379619311

Epoch: 6| Step: 12
Training loss: 1.537704586982727
Validation loss: 2.177051805680798

Epoch: 6| Step: 13
Training loss: 1.2109665870666504
Validation loss: 2.1633677136513496

Epoch: 208| Step: 0
Training loss: 0.8251975774765015
Validation loss: 2.202448232199556

Epoch: 6| Step: 1
Training loss: 0.9830194115638733
Validation loss: 2.2149251353356147

Epoch: 6| Step: 2
Training loss: 1.2733403444290161
Validation loss: 2.1739996299948743

Epoch: 6| Step: 3
Training loss: 0.8166636824607849
Validation loss: 2.1418961094271753

Epoch: 6| Step: 4
Training loss: 1.3068854808807373
Validation loss: 2.080749329700265

Epoch: 6| Step: 5
Training loss: 0.7870925664901733
Validation loss: 2.001365798775868

Epoch: 6| Step: 6
Training loss: 0.9597173929214478
Validation loss: 1.943378670241243

Epoch: 6| Step: 7
Training loss: 1.6615850925445557
Validation loss: 1.935047488058767

Epoch: 6| Step: 8
Training loss: 1.0103092193603516
Validation loss: 1.9593079397755284

Epoch: 6| Step: 9
Training loss: 0.8137352466583252
Validation loss: 1.9367587463830107

Epoch: 6| Step: 10
Training loss: 1.388343334197998
Validation loss: 1.9937908405898719

Epoch: 6| Step: 11
Training loss: 0.7839152216911316
Validation loss: 2.02737602110832

Epoch: 6| Step: 12
Training loss: 1.1728322505950928
Validation loss: 2.0648129832360054

Epoch: 6| Step: 13
Training loss: 0.836972713470459
Validation loss: 2.1133999414341424

Epoch: 209| Step: 0
Training loss: 0.9357286691665649
Validation loss: 2.0928083542854554

Epoch: 6| Step: 1
Training loss: 0.9439215064048767
Validation loss: 2.0370444072190153

Epoch: 6| Step: 2
Training loss: 0.5603399276733398
Validation loss: 1.9983398657973095

Epoch: 6| Step: 3
Training loss: 0.822046160697937
Validation loss: 1.948487207453738

Epoch: 6| Step: 4
Training loss: 0.6653808951377869
Validation loss: 1.9513700764666322

Epoch: 6| Step: 5
Training loss: 1.218775987625122
Validation loss: 2.0028277981665825

Epoch: 6| Step: 6
Training loss: 1.4392502307891846
Validation loss: 2.037300728982495

Epoch: 6| Step: 7
Training loss: 1.3461700677871704
Validation loss: 2.10319608770391

Epoch: 6| Step: 8
Training loss: 0.713485836982727
Validation loss: 2.1792267907050347

Epoch: 6| Step: 9
Training loss: 0.7124624252319336
Validation loss: 2.183738318822717

Epoch: 6| Step: 10
Training loss: 1.26918363571167
Validation loss: 2.1984473274600123

Epoch: 6| Step: 11
Training loss: 1.4620110988616943
Validation loss: 2.1437046399680515

Epoch: 6| Step: 12
Training loss: 0.8700485229492188
Validation loss: 2.110542761382236

Epoch: 6| Step: 13
Training loss: 1.0726733207702637
Validation loss: 2.13432906007254

Epoch: 210| Step: 0
Training loss: 1.2376697063446045
Validation loss: 2.084615699706539

Epoch: 6| Step: 1
Training loss: 0.8153237104415894
Validation loss: 2.02242354167405

Epoch: 6| Step: 2
Training loss: 0.8075437545776367
Validation loss: 2.0247741206999748

Epoch: 6| Step: 3
Training loss: 0.9372817873954773
Validation loss: 1.99783581303012

Epoch: 6| Step: 4
Training loss: 0.936670184135437
Validation loss: 1.9934615473593436

Epoch: 6| Step: 5
Training loss: 1.0063045024871826
Validation loss: 2.022198456589894

Epoch: 6| Step: 6
Training loss: 1.2721295356750488
Validation loss: 2.0414897805900982

Epoch: 6| Step: 7
Training loss: 1.0401413440704346
Validation loss: 2.020954939626878

Epoch: 6| Step: 8
Training loss: 0.7014009356498718
Validation loss: 2.017847643103651

Epoch: 6| Step: 9
Training loss: 0.7527657747268677
Validation loss: 1.9864779928679108

Epoch: 6| Step: 10
Training loss: 0.9892475008964539
Validation loss: 1.98917930997828

Epoch: 6| Step: 11
Training loss: 1.0732309818267822
Validation loss: 1.9840914767275575

Epoch: 6| Step: 12
Training loss: 1.2314083576202393
Validation loss: 2.0126070335347164

Epoch: 6| Step: 13
Training loss: 0.9257335662841797
Validation loss: 2.022951816999784

Epoch: 211| Step: 0
Training loss: 0.8859028220176697
Validation loss: 1.9983200373188141

Epoch: 6| Step: 1
Training loss: 1.2372381687164307
Validation loss: 2.005016880650674

Epoch: 6| Step: 2
Training loss: 1.176577091217041
Validation loss: 2.0314917692574124

Epoch: 6| Step: 3
Training loss: 0.4120493531227112
Validation loss: 2.0238999051432454

Epoch: 6| Step: 4
Training loss: 1.0139191150665283
Validation loss: 2.0145943344280286

Epoch: 6| Step: 5
Training loss: 1.2411195039749146
Validation loss: 2.042823797913008

Epoch: 6| Step: 6
Training loss: 1.1142246723175049
Validation loss: 2.056125694705594

Epoch: 6| Step: 7
Training loss: 0.49217772483825684
Validation loss: 2.0641742085897796

Epoch: 6| Step: 8
Training loss: 1.1892292499542236
Validation loss: 1.9992862965471

Epoch: 6| Step: 9
Training loss: 1.4286314249038696
Validation loss: 2.014113688981661

Epoch: 6| Step: 10
Training loss: 1.05684494972229
Validation loss: 2.016260617522783

Epoch: 6| Step: 11
Training loss: 0.5317328572273254
Validation loss: 2.0271909493272022

Epoch: 6| Step: 12
Training loss: 0.7123910784721375
Validation loss: 1.9898769355589343

Epoch: 6| Step: 13
Training loss: 0.8326142430305481
Validation loss: 2.0094068511839835

Epoch: 212| Step: 0
Training loss: 0.9596033096313477
Validation loss: 2.045667379133163

Epoch: 6| Step: 1
Training loss: 0.8715491890907288
Validation loss: 2.0762604680112613

Epoch: 6| Step: 2
Training loss: 0.9781099557876587
Validation loss: 2.0689070122216338

Epoch: 6| Step: 3
Training loss: 1.2254701852798462
Validation loss: 2.0741230031495452

Epoch: 6| Step: 4
Training loss: 1.1156914234161377
Validation loss: 2.0794536811049267

Epoch: 6| Step: 5
Training loss: 1.0559029579162598
Validation loss: 2.041654645755727

Epoch: 6| Step: 6
Training loss: 0.6408680081367493
Validation loss: 1.9921197980962775

Epoch: 6| Step: 7
Training loss: 0.8423094749450684
Validation loss: 1.970377222184212

Epoch: 6| Step: 8
Training loss: 1.0430405139923096
Validation loss: 1.9807552586319626

Epoch: 6| Step: 9
Training loss: 0.6480134129524231
Validation loss: 1.9988859430436166

Epoch: 6| Step: 10
Training loss: 1.0231170654296875
Validation loss: 1.9911852869936215

Epoch: 6| Step: 11
Training loss: 0.8444626331329346
Validation loss: 2.0006560638386715

Epoch: 6| Step: 12
Training loss: 1.3114982843399048
Validation loss: 2.019655591698103

Epoch: 6| Step: 13
Training loss: 1.0745750665664673
Validation loss: 2.026321262441656

Epoch: 213| Step: 0
Training loss: 0.9738095998764038
Validation loss: 2.002614582738569

Epoch: 6| Step: 1
Training loss: 0.4739587903022766
Validation loss: 2.0144377934035433

Epoch: 6| Step: 2
Training loss: 0.7537899017333984
Validation loss: 2.0048737577212754

Epoch: 6| Step: 3
Training loss: 1.2277226448059082
Validation loss: 1.9698598487402803

Epoch: 6| Step: 4
Training loss: 1.2504308223724365
Validation loss: 1.9559843924737745

Epoch: 6| Step: 5
Training loss: 0.9210253953933716
Validation loss: 1.9815074115671136

Epoch: 6| Step: 6
Training loss: 1.2090191841125488
Validation loss: 1.9506092968807425

Epoch: 6| Step: 7
Training loss: 0.5526796579360962
Validation loss: 1.9435567766107538

Epoch: 6| Step: 8
Training loss: 0.823340654373169
Validation loss: 1.983878654818381

Epoch: 6| Step: 9
Training loss: 0.9467208385467529
Validation loss: 2.017022104673488

Epoch: 6| Step: 10
Training loss: 0.8591467142105103
Validation loss: 2.052088055559384

Epoch: 6| Step: 11
Training loss: 0.7282072901725769
Validation loss: 2.0644338925679526

Epoch: 6| Step: 12
Training loss: 1.2156316041946411
Validation loss: 2.086047121273574

Epoch: 6| Step: 13
Training loss: 1.011512279510498
Validation loss: 2.121667497901506

Epoch: 214| Step: 0
Training loss: 0.8425403833389282
Validation loss: 2.0514410849540465

Epoch: 6| Step: 1
Training loss: 0.9836791753768921
Validation loss: 1.9884137543298865

Epoch: 6| Step: 2
Training loss: 1.0470068454742432
Validation loss: 1.9163434890008741

Epoch: 6| Step: 3
Training loss: 0.6208727359771729
Validation loss: 1.9184078247316423

Epoch: 6| Step: 4
Training loss: 0.8662171363830566
Validation loss: 1.9288716482859787

Epoch: 6| Step: 5
Training loss: 1.073817491531372
Validation loss: 1.9317531483147734

Epoch: 6| Step: 6
Training loss: 0.8748080730438232
Validation loss: 1.9893412897663731

Epoch: 6| Step: 7
Training loss: 0.9244289994239807
Validation loss: 2.0264524490602556

Epoch: 6| Step: 8
Training loss: 1.0133256912231445
Validation loss: 2.086648392420943

Epoch: 6| Step: 9
Training loss: 1.2991943359375
Validation loss: 2.127982456197021

Epoch: 6| Step: 10
Training loss: 1.0371966361999512
Validation loss: 2.1766393799935617

Epoch: 6| Step: 11
Training loss: 0.9118707776069641
Validation loss: 2.1785713946947487

Epoch: 6| Step: 12
Training loss: 1.1240830421447754
Validation loss: 2.166787830732202

Epoch: 6| Step: 13
Training loss: 0.5154131054878235
Validation loss: 2.1094343982717043

Epoch: 215| Step: 0
Training loss: 0.825208842754364
Validation loss: 2.050694420773496

Epoch: 6| Step: 1
Training loss: 1.5799534320831299
Validation loss: 1.9948949429296678

Epoch: 6| Step: 2
Training loss: 0.932244598865509
Validation loss: 1.948647665721114

Epoch: 6| Step: 3
Training loss: 0.8379895687103271
Validation loss: 1.9421321576641453

Epoch: 6| Step: 4
Training loss: 0.7825452089309692
Validation loss: 1.8892456113651235

Epoch: 6| Step: 5
Training loss: 0.9422388076782227
Validation loss: 1.8730185147254699

Epoch: 6| Step: 6
Training loss: 0.827072262763977
Validation loss: 1.8624874853318738

Epoch: 6| Step: 7
Training loss: 1.1866450309753418
Validation loss: 1.8730849258361324

Epoch: 6| Step: 8
Training loss: 1.1234610080718994
Validation loss: 1.8774005661728561

Epoch: 6| Step: 9
Training loss: 1.1512467861175537
Validation loss: 1.9163246539331251

Epoch: 6| Step: 10
Training loss: 0.9304748773574829
Validation loss: 1.9414854113773634

Epoch: 6| Step: 11
Training loss: 0.5558552742004395
Validation loss: 1.9960528983864734

Epoch: 6| Step: 12
Training loss: 0.6464754343032837
Validation loss: 2.029370056685581

Epoch: 6| Step: 13
Training loss: 0.9249880313873291
Validation loss: 2.022147053031511

Epoch: 216| Step: 0
Training loss: 0.7938342690467834
Validation loss: 2.0466288238443355

Epoch: 6| Step: 1
Training loss: 0.6745336055755615
Validation loss: 2.008125417975969

Epoch: 6| Step: 2
Training loss: 0.9757830500602722
Validation loss: 1.971645934607393

Epoch: 6| Step: 3
Training loss: 0.8729105591773987
Validation loss: 1.9625465357175438

Epoch: 6| Step: 4
Training loss: 0.8413112163543701
Validation loss: 2.004173912027831

Epoch: 6| Step: 5
Training loss: 0.7860528230667114
Validation loss: 1.9999616479360929

Epoch: 6| Step: 6
Training loss: 0.7162203192710876
Validation loss: 2.038294517865745

Epoch: 6| Step: 7
Training loss: 0.9478269219398499
Validation loss: 2.0585922195065405

Epoch: 6| Step: 8
Training loss: 0.9221396446228027
Validation loss: 2.1098466432222756

Epoch: 6| Step: 9
Training loss: 1.016850233078003
Validation loss: 2.141068120156565

Epoch: 6| Step: 10
Training loss: 0.9509644508361816
Validation loss: 2.130323267752124

Epoch: 6| Step: 11
Training loss: 1.353403925895691
Validation loss: 2.1734879273240284

Epoch: 6| Step: 12
Training loss: 1.3058490753173828
Validation loss: 2.189760741367135

Epoch: 6| Step: 13
Training loss: 1.442758560180664
Validation loss: 2.14105232556661

Epoch: 217| Step: 0
Training loss: 1.1751960515975952
Validation loss: 2.138586841603761

Epoch: 6| Step: 1
Training loss: 1.080641269683838
Validation loss: 2.0740735582126084

Epoch: 6| Step: 2
Training loss: 0.6205081939697266
Validation loss: 2.0945820885319866

Epoch: 6| Step: 3
Training loss: 0.6484119892120361
Validation loss: 2.053925327075425

Epoch: 6| Step: 4
Training loss: 1.123341679573059
Validation loss: 2.0593830795698267

Epoch: 6| Step: 5
Training loss: 0.6878421306610107
Validation loss: 2.0506621278742307

Epoch: 6| Step: 6
Training loss: 1.0586614608764648
Validation loss: 2.014056864605155

Epoch: 6| Step: 7
Training loss: 0.9163964986801147
Validation loss: 2.0252084757692073

Epoch: 6| Step: 8
Training loss: 0.629893958568573
Validation loss: 2.0283036744722756

Epoch: 6| Step: 9
Training loss: 0.8371546268463135
Validation loss: 1.980036598379894

Epoch: 6| Step: 10
Training loss: 1.062300682067871
Validation loss: 1.9515455922772806

Epoch: 6| Step: 11
Training loss: 0.7519237399101257
Validation loss: 1.9292560956811393

Epoch: 6| Step: 12
Training loss: 1.118944764137268
Validation loss: 1.90008044627405

Epoch: 6| Step: 13
Training loss: 1.4979729652404785
Validation loss: 1.9056065364550518

Epoch: 218| Step: 0
Training loss: 0.7250338792800903
Validation loss: 1.8973514405629968

Epoch: 6| Step: 1
Training loss: 0.7626085877418518
Validation loss: 1.915304373669368

Epoch: 6| Step: 2
Training loss: 0.927047610282898
Validation loss: 1.9261031817364436

Epoch: 6| Step: 3
Training loss: 1.0825275182724
Validation loss: 1.9293361184417561

Epoch: 6| Step: 4
Training loss: 0.5638907551765442
Validation loss: 1.9840519646162629

Epoch: 6| Step: 5
Training loss: 0.8433026671409607
Validation loss: 1.9948813351251746

Epoch: 6| Step: 6
Training loss: 0.7380809783935547
Validation loss: 1.9853365126476492

Epoch: 6| Step: 7
Training loss: 0.5094631314277649
Validation loss: 1.9942943255106609

Epoch: 6| Step: 8
Training loss: 1.1525959968566895
Validation loss: 1.9901716645045946

Epoch: 6| Step: 9
Training loss: 0.6391329169273376
Validation loss: 2.008645237133067

Epoch: 6| Step: 10
Training loss: 1.5261824131011963
Validation loss: 2.018268158358912

Epoch: 6| Step: 11
Training loss: 0.789252758026123
Validation loss: 2.0155057958377305

Epoch: 6| Step: 12
Training loss: 1.0458564758300781
Validation loss: 2.000179539444626

Epoch: 6| Step: 13
Training loss: 1.3633246421813965
Validation loss: 1.980255675572221

Epoch: 219| Step: 0
Training loss: 0.9225916862487793
Validation loss: 1.9623972985052294

Epoch: 6| Step: 1
Training loss: 1.1433169841766357
Validation loss: 1.9369414301328762

Epoch: 6| Step: 2
Training loss: 0.7351816892623901
Validation loss: 1.9117265542348225

Epoch: 6| Step: 3
Training loss: 0.691506028175354
Validation loss: 1.9205941500202302

Epoch: 6| Step: 4
Training loss: 0.5440123081207275
Validation loss: 1.9035463794585197

Epoch: 6| Step: 5
Training loss: 0.8309556245803833
Validation loss: 1.928581419811454

Epoch: 6| Step: 6
Training loss: 0.9003498554229736
Validation loss: 1.9604142968372633

Epoch: 6| Step: 7
Training loss: 0.8921464085578918
Validation loss: 1.992276737766881

Epoch: 6| Step: 8
Training loss: 0.9701110124588013
Validation loss: 2.0058771705114715

Epoch: 6| Step: 9
Training loss: 0.6225920915603638
Validation loss: 2.053427885937434

Epoch: 6| Step: 10
Training loss: 1.2111032009124756
Validation loss: 2.048954717574581

Epoch: 6| Step: 11
Training loss: 0.5741986036300659
Validation loss: 2.040868177208849

Epoch: 6| Step: 12
Training loss: 1.2729971408843994
Validation loss: 2.0289927554386917

Epoch: 6| Step: 13
Training loss: 0.8323477506637573
Validation loss: 2.0458332082276702

Epoch: 220| Step: 0
Training loss: 0.34359288215637207
Validation loss: 2.041715186129334

Epoch: 6| Step: 1
Training loss: 1.2215359210968018
Validation loss: 1.984993657758159

Epoch: 6| Step: 2
Training loss: 1.3741755485534668
Validation loss: 2.0351674825914445

Epoch: 6| Step: 3
Training loss: 0.6631476283073425
Validation loss: 1.9696188408841369

Epoch: 6| Step: 4
Training loss: 1.070620059967041
Validation loss: 1.9321665866400606

Epoch: 6| Step: 5
Training loss: 0.5307519435882568
Validation loss: 1.9334620250168668

Epoch: 6| Step: 6
Training loss: 0.7947981357574463
Validation loss: 1.964303203808364

Epoch: 6| Step: 7
Training loss: 0.6195075511932373
Validation loss: 1.9565383388150124

Epoch: 6| Step: 8
Training loss: 0.8866126537322998
Validation loss: 1.9878240221290178

Epoch: 6| Step: 9
Training loss: 1.202574610710144
Validation loss: 2.00470091706963

Epoch: 6| Step: 10
Training loss: 0.666598379611969
Validation loss: 1.9890516381109915

Epoch: 6| Step: 11
Training loss: 0.7597166895866394
Validation loss: 1.98076763204349

Epoch: 6| Step: 12
Training loss: 0.8409541845321655
Validation loss: 1.9838520147467171

Epoch: 6| Step: 13
Training loss: 0.902822732925415
Validation loss: 2.004183271879791

Epoch: 221| Step: 0
Training loss: 0.9780778884887695
Validation loss: 2.0144654140677503

Epoch: 6| Step: 1
Training loss: 1.048426628112793
Validation loss: 2.003309699796861

Epoch: 6| Step: 2
Training loss: 0.7598320841789246
Validation loss: 2.0093266207684755

Epoch: 6| Step: 3
Training loss: 0.9740164279937744
Validation loss: 2.0240345860040314

Epoch: 6| Step: 4
Training loss: 0.6669328212738037
Validation loss: 2.0118297607667985

Epoch: 6| Step: 5
Training loss: 0.7078073620796204
Validation loss: 2.0302479433757004

Epoch: 6| Step: 6
Training loss: 0.9658240675926208
Validation loss: 2.043746602150702

Epoch: 6| Step: 7
Training loss: 0.5443440675735474
Validation loss: 2.0895627390953804

Epoch: 6| Step: 8
Training loss: 0.8346306681632996
Validation loss: 2.0905998868326985

Epoch: 6| Step: 9
Training loss: 0.9872103333473206
Validation loss: 2.0742876055420085

Epoch: 6| Step: 10
Training loss: 0.8981161117553711
Validation loss: 2.0684377301123833

Epoch: 6| Step: 11
Training loss: 1.0091195106506348
Validation loss: 2.069307724634806

Epoch: 6| Step: 12
Training loss: 0.6614804267883301
Validation loss: 2.0469467204104186

Epoch: 6| Step: 13
Training loss: 1.0247606039047241
Validation loss: 2.060593879351052

Epoch: 222| Step: 0
Training loss: 0.6972514390945435
Validation loss: 2.032527398037654

Epoch: 6| Step: 1
Training loss: 0.31758439540863037
Validation loss: 2.043205850867815

Epoch: 6| Step: 2
Training loss: 0.8264548778533936
Validation loss: 2.035509081297023

Epoch: 6| Step: 3
Training loss: 0.8620164394378662
Validation loss: 2.0456453984783542

Epoch: 6| Step: 4
Training loss: 0.6673367619514465
Validation loss: 2.026545327196839

Epoch: 6| Step: 5
Training loss: 1.0104422569274902
Validation loss: 1.995094286498203

Epoch: 6| Step: 6
Training loss: 1.2435365915298462
Validation loss: 1.9499648258250246

Epoch: 6| Step: 7
Training loss: 0.9198943376541138
Validation loss: 1.9348906829792967

Epoch: 6| Step: 8
Training loss: 0.7683765888214111
Validation loss: 1.920920325863746

Epoch: 6| Step: 9
Training loss: 0.854880690574646
Validation loss: 1.884703210605088

Epoch: 6| Step: 10
Training loss: 1.2602908611297607
Validation loss: 1.89697386628838

Epoch: 6| Step: 11
Training loss: 0.883754312992096
Validation loss: 1.9280391252169045

Epoch: 6| Step: 12
Training loss: 0.5231156945228577
Validation loss: 1.9565726813449655

Epoch: 6| Step: 13
Training loss: 1.042694091796875
Validation loss: 1.9641667335264144

Epoch: 223| Step: 0
Training loss: 0.9980741739273071
Validation loss: 2.0190133394733554

Epoch: 6| Step: 1
Training loss: 0.5849598050117493
Validation loss: 2.032051278698829

Epoch: 6| Step: 2
Training loss: 0.9704141020774841
Validation loss: 2.045401632144887

Epoch: 6| Step: 3
Training loss: 0.9624559879302979
Validation loss: 2.0521414203028523

Epoch: 6| Step: 4
Training loss: 0.8677794933319092
Validation loss: 2.0566854092382614

Epoch: 6| Step: 5
Training loss: 0.7293468713760376
Validation loss: 2.014562065883349

Epoch: 6| Step: 6
Training loss: 0.8562553524971008
Validation loss: 2.0279190822314193

Epoch: 6| Step: 7
Training loss: 0.5176591277122498
Validation loss: 1.985311964506744

Epoch: 6| Step: 8
Training loss: 0.581895649433136
Validation loss: 1.954918869080082

Epoch: 6| Step: 9
Training loss: 0.7666205167770386
Validation loss: 1.9222588564759941

Epoch: 6| Step: 10
Training loss: 0.9620054364204407
Validation loss: 1.926609669962237

Epoch: 6| Step: 11
Training loss: 0.846747636795044
Validation loss: 1.9427840812231905

Epoch: 6| Step: 12
Training loss: 0.6620321273803711
Validation loss: 1.9422894780353834

Epoch: 6| Step: 13
Training loss: 1.3797110319137573
Validation loss: 1.9591243087604482

Epoch: 224| Step: 0
Training loss: 0.9441925883293152
Validation loss: 2.0352539003536267

Epoch: 6| Step: 1
Training loss: 1.2288577556610107
Validation loss: 2.03614991711032

Epoch: 6| Step: 2
Training loss: 0.7674323320388794
Validation loss: 2.026696370493981

Epoch: 6| Step: 3
Training loss: 0.6330847144126892
Validation loss: 2.0255325891638316

Epoch: 6| Step: 4
Training loss: 0.5473521947860718
Validation loss: 2.0058395567760674

Epoch: 6| Step: 5
Training loss: 1.0467361211776733
Validation loss: 1.965102457231091

Epoch: 6| Step: 6
Training loss: 0.6098326444625854
Validation loss: 1.9409024266786472

Epoch: 6| Step: 7
Training loss: 0.8935158252716064
Validation loss: 1.9329739873127272

Epoch: 6| Step: 8
Training loss: 0.9859377145767212
Validation loss: 1.9465056029699181

Epoch: 6| Step: 9
Training loss: 0.5820286273956299
Validation loss: 1.934188909428094

Epoch: 6| Step: 10
Training loss: 0.6510477066040039
Validation loss: 1.9627868244724889

Epoch: 6| Step: 11
Training loss: 0.97894287109375
Validation loss: 1.9382218032754877

Epoch: 6| Step: 12
Training loss: 0.6141883730888367
Validation loss: 1.9456088786484094

Epoch: 6| Step: 13
Training loss: 0.9387566447257996
Validation loss: 1.938780282133369

Epoch: 225| Step: 0
Training loss: 0.6314743757247925
Validation loss: 1.9513757228851318

Epoch: 6| Step: 1
Training loss: 0.7218014001846313
Validation loss: 1.9332240268748293

Epoch: 6| Step: 2
Training loss: 0.8343770503997803
Validation loss: 1.9501810535307853

Epoch: 6| Step: 3
Training loss: 0.6763924360275269
Validation loss: 1.9549108782122213

Epoch: 6| Step: 4
Training loss: 1.211474895477295
Validation loss: 1.9757543738170336

Epoch: 6| Step: 5
Training loss: 0.7922110557556152
Validation loss: 1.9936691958417174

Epoch: 6| Step: 6
Training loss: 0.7235906720161438
Validation loss: 1.9868916875572615

Epoch: 6| Step: 7
Training loss: 0.7895992398262024
Validation loss: 2.0208014518983903

Epoch: 6| Step: 8
Training loss: 0.6535513401031494
Validation loss: 2.0075663571716635

Epoch: 6| Step: 9
Training loss: 1.0646694898605347
Validation loss: 2.021674108761613

Epoch: 6| Step: 10
Training loss: 0.7199528217315674
Validation loss: 1.9968468604549285

Epoch: 6| Step: 11
Training loss: 0.9179225564002991
Validation loss: 1.9669338516009751

Epoch: 6| Step: 12
Training loss: 0.6433073878288269
Validation loss: 1.9213247991377307

Epoch: 6| Step: 13
Training loss: 1.0865426063537598
Validation loss: 1.9226261236334359

Epoch: 226| Step: 0
Training loss: 1.160858154296875
Validation loss: 1.891925641285476

Epoch: 6| Step: 1
Training loss: 0.9439141750335693
Validation loss: 1.8971084035852903

Epoch: 6| Step: 2
Training loss: 0.5565093755722046
Validation loss: 1.9249911910744124

Epoch: 6| Step: 3
Training loss: 1.1290857791900635
Validation loss: 1.9196357150231638

Epoch: 6| Step: 4
Training loss: 0.7193800806999207
Validation loss: 1.9608682688846384

Epoch: 6| Step: 5
Training loss: 0.6374427080154419
Validation loss: 1.9739444460920108

Epoch: 6| Step: 6
Training loss: 0.7409736514091492
Validation loss: 1.9867333301933863

Epoch: 6| Step: 7
Training loss: 0.6585105657577515
Validation loss: 1.961784980630362

Epoch: 6| Step: 8
Training loss: 0.8602393865585327
Validation loss: 1.9483094856303225

Epoch: 6| Step: 9
Training loss: 0.7412963509559631
Validation loss: 1.9126962871961697

Epoch: 6| Step: 10
Training loss: 0.8221482038497925
Validation loss: 1.9228079601000714

Epoch: 6| Step: 11
Training loss: 0.6055821180343628
Validation loss: 1.9103637023638653

Epoch: 6| Step: 12
Training loss: 0.7189045548439026
Validation loss: 1.9220058584725985

Epoch: 6| Step: 13
Training loss: 0.737794041633606
Validation loss: 1.930033770940637

Epoch: 227| Step: 0
Training loss: 0.7818574905395508
Validation loss: 1.9315490286837342

Epoch: 6| Step: 1
Training loss: 0.9195040464401245
Validation loss: 1.940832050897742

Epoch: 6| Step: 2
Training loss: 1.016256332397461
Validation loss: 1.9694457131047403

Epoch: 6| Step: 3
Training loss: 0.7563285231590271
Validation loss: 1.9744909578754055

Epoch: 6| Step: 4
Training loss: 0.70396888256073
Validation loss: 2.028280972152628

Epoch: 6| Step: 5
Training loss: 0.9780744910240173
Validation loss: 2.0547062837949364

Epoch: 6| Step: 6
Training loss: 0.7111459374427795
Validation loss: 2.0279319004345964

Epoch: 6| Step: 7
Training loss: 0.5397943258285522
Validation loss: 2.026249900940926

Epoch: 6| Step: 8
Training loss: 0.758375883102417
Validation loss: 2.0356002994762954

Epoch: 6| Step: 9
Training loss: 0.4641434848308563
Validation loss: 1.9977291463523783

Epoch: 6| Step: 10
Training loss: 1.1553043127059937
Validation loss: 1.9702421490864088

Epoch: 6| Step: 11
Training loss: 0.7969990372657776
Validation loss: 1.921242779301059

Epoch: 6| Step: 12
Training loss: 0.838165819644928
Validation loss: 1.925738311582996

Epoch: 6| Step: 13
Training loss: 0.749316930770874
Validation loss: 1.8677501742557814

Epoch: 228| Step: 0
Training loss: 0.9303290247917175
Validation loss: 1.9083711729254773

Epoch: 6| Step: 1
Training loss: 0.9849308729171753
Validation loss: 1.945689873028827

Epoch: 6| Step: 2
Training loss: 0.8244743347167969
Validation loss: 1.936105517930882

Epoch: 6| Step: 3
Training loss: 0.6477260589599609
Validation loss: 1.9437541730942265

Epoch: 6| Step: 4
Training loss: 0.628034234046936
Validation loss: 1.938588539759318

Epoch: 6| Step: 5
Training loss: 0.8633084297180176
Validation loss: 1.9326065996641755

Epoch: 6| Step: 6
Training loss: 0.9733223915100098
Validation loss: 1.9529658825166765

Epoch: 6| Step: 7
Training loss: 1.2475217580795288
Validation loss: 2.009954644787696

Epoch: 6| Step: 8
Training loss: 0.5209165811538696
Validation loss: 2.0131934445391417

Epoch: 6| Step: 9
Training loss: 1.0345327854156494
Validation loss: 2.023046056429545

Epoch: 6| Step: 10
Training loss: 0.956508219242096
Validation loss: 2.024618339794938

Epoch: 6| Step: 11
Training loss: 0.666185736656189
Validation loss: 1.9954064430729035

Epoch: 6| Step: 12
Training loss: 0.7218810319900513
Validation loss: 2.015887580892091

Epoch: 6| Step: 13
Training loss: 0.48754751682281494
Validation loss: 2.008914221999466

Epoch: 229| Step: 0
Training loss: 0.959993302822113
Validation loss: 1.9788080466690885

Epoch: 6| Step: 1
Training loss: 0.6341770887374878
Validation loss: 1.962627072488108

Epoch: 6| Step: 2
Training loss: 0.7010390758514404
Validation loss: 1.9757912274329894

Epoch: 6| Step: 3
Training loss: 0.6262428760528564
Validation loss: 1.993495075933395

Epoch: 6| Step: 4
Training loss: 1.7797975540161133
Validation loss: 1.9964342424946446

Epoch: 6| Step: 5
Training loss: 0.6838409900665283
Validation loss: 1.9836551784187235

Epoch: 6| Step: 6
Training loss: 0.6538361310958862
Validation loss: 1.9803184809223298

Epoch: 6| Step: 7
Training loss: 0.6523782014846802
Validation loss: 2.0102897626097485

Epoch: 6| Step: 8
Training loss: 0.7152268886566162
Validation loss: 2.041111425686908

Epoch: 6| Step: 9
Training loss: 0.668110728263855
Validation loss: 2.0024232069651284

Epoch: 6| Step: 10
Training loss: 0.5693721771240234
Validation loss: 2.004490383209721

Epoch: 6| Step: 11
Training loss: 0.7534279823303223
Validation loss: 2.0151572663296937

Epoch: 6| Step: 12
Training loss: 0.5913792848587036
Validation loss: 2.01642079763515

Epoch: 6| Step: 13
Training loss: 0.37563249468803406
Validation loss: 1.971903976573739

Epoch: 230| Step: 0
Training loss: 0.7317423224449158
Validation loss: 1.9566241413034418

Epoch: 6| Step: 1
Training loss: 1.107192039489746
Validation loss: 1.953948123480684

Epoch: 6| Step: 2
Training loss: 0.48704761266708374
Validation loss: 1.9298443127703924

Epoch: 6| Step: 3
Training loss: 0.8826892375946045
Validation loss: 1.9057711683293825

Epoch: 6| Step: 4
Training loss: 0.4089476466178894
Validation loss: 1.9185341083875267

Epoch: 6| Step: 5
Training loss: 0.647150456905365
Validation loss: 1.9218816616201913

Epoch: 6| Step: 6
Training loss: 0.9925150871276855
Validation loss: 1.9473419548362814

Epoch: 6| Step: 7
Training loss: 0.7316620349884033
Validation loss: 1.919926340861987

Epoch: 6| Step: 8
Training loss: 0.3196706473827362
Validation loss: 1.9315877858028616

Epoch: 6| Step: 9
Training loss: 0.8089870810508728
Validation loss: 1.9578747249418689

Epoch: 6| Step: 10
Training loss: 0.9191529154777527
Validation loss: 1.9288560344326882

Epoch: 6| Step: 11
Training loss: 0.9208725690841675
Validation loss: 1.935267351006949

Epoch: 6| Step: 12
Training loss: 0.8923566937446594
Validation loss: 1.9324637625807075

Epoch: 6| Step: 13
Training loss: 1.0894914865493774
Validation loss: 1.9212753695826377

Epoch: 231| Step: 0
Training loss: 1.205183982849121
Validation loss: 1.8929069695934173

Epoch: 6| Step: 1
Training loss: 0.8277508616447449
Validation loss: 1.912466424767689

Epoch: 6| Step: 2
Training loss: 0.6381389498710632
Validation loss: 1.8915765131673505

Epoch: 6| Step: 3
Training loss: 0.6508255004882812
Validation loss: 1.911050203025982

Epoch: 6| Step: 4
Training loss: 0.5135654211044312
Validation loss: 1.8785111570871005

Epoch: 6| Step: 5
Training loss: 0.6884415149688721
Validation loss: 1.9206835467328307

Epoch: 6| Step: 6
Training loss: 0.6478167176246643
Validation loss: 1.9617940379727272

Epoch: 6| Step: 7
Training loss: 0.5374566316604614
Validation loss: 1.928979568583991

Epoch: 6| Step: 8
Training loss: 0.5858794450759888
Validation loss: 1.9797189709960774

Epoch: 6| Step: 9
Training loss: 0.8894320726394653
Validation loss: 1.926058397498182

Epoch: 6| Step: 10
Training loss: 1.1324636936187744
Validation loss: 1.9490980281624743

Epoch: 6| Step: 11
Training loss: 0.5896492600440979
Validation loss: 1.9414681593577068

Epoch: 6| Step: 12
Training loss: 1.002932071685791
Validation loss: 1.9338265080605783

Epoch: 6| Step: 13
Training loss: 0.5102071762084961
Validation loss: 1.9876673272860947

Epoch: 232| Step: 0
Training loss: 0.7432197332382202
Validation loss: 2.041293291635411

Epoch: 6| Step: 1
Training loss: 0.8081614375114441
Validation loss: 2.0720191488983812

Epoch: 6| Step: 2
Training loss: 0.7992951273918152
Validation loss: 2.064828336879771

Epoch: 6| Step: 3
Training loss: 0.7033592462539673
Validation loss: 2.0617034307090183

Epoch: 6| Step: 4
Training loss: 0.7898000478744507
Validation loss: 2.06576479634931

Epoch: 6| Step: 5
Training loss: 0.5190557241439819
Validation loss: 2.073008850056638

Epoch: 6| Step: 6
Training loss: 1.1299622058868408
Validation loss: 2.032287895038564

Epoch: 6| Step: 7
Training loss: 0.4093592166900635
Validation loss: 1.9948365329414286

Epoch: 6| Step: 8
Training loss: 0.945756196975708
Validation loss: 1.9515486737733245

Epoch: 6| Step: 9
Training loss: 0.7603020071983337
Validation loss: 1.9362234607819588

Epoch: 6| Step: 10
Training loss: 0.8813902139663696
Validation loss: 1.8785825775515648

Epoch: 6| Step: 11
Training loss: 0.843686044216156
Validation loss: 1.8534056422530965

Epoch: 6| Step: 12
Training loss: 0.668373167514801
Validation loss: 1.8538159247367614

Epoch: 6| Step: 13
Training loss: 0.9015501737594604
Validation loss: 1.8480642508434992

Epoch: 233| Step: 0
Training loss: 0.7710062265396118
Validation loss: 1.8812956399815057

Epoch: 6| Step: 1
Training loss: 0.888620138168335
Validation loss: 1.921241743590242

Epoch: 6| Step: 2
Training loss: 0.506994366645813
Validation loss: 1.924084944109763

Epoch: 6| Step: 3
Training loss: 0.7161082029342651
Validation loss: 1.9793122301819503

Epoch: 6| Step: 4
Training loss: 0.9656341671943665
Validation loss: 1.97314001283338

Epoch: 6| Step: 5
Training loss: 1.055750846862793
Validation loss: 1.9449060360590618

Epoch: 6| Step: 6
Training loss: 1.1150994300842285
Validation loss: 1.9192491141698693

Epoch: 6| Step: 7
Training loss: 0.5097712874412537
Validation loss: 1.941343266476867

Epoch: 6| Step: 8
Training loss: 0.5493670701980591
Validation loss: 1.907257245432946

Epoch: 6| Step: 9
Training loss: 0.7151921987533569
Validation loss: 1.9421274803018058

Epoch: 6| Step: 10
Training loss: 0.5373276472091675
Validation loss: 1.907530103960345

Epoch: 6| Step: 11
Training loss: 0.41637375950813293
Validation loss: 1.8916633667484406

Epoch: 6| Step: 12
Training loss: 0.8008464574813843
Validation loss: 1.8796728913502028

Epoch: 6| Step: 13
Training loss: 0.7988289594650269
Validation loss: 1.8819025024291007

Epoch: 234| Step: 0
Training loss: 0.6212655305862427
Validation loss: 1.9051530540630381

Epoch: 6| Step: 1
Training loss: 0.7955372333526611
Validation loss: 1.9312598654018935

Epoch: 6| Step: 2
Training loss: 0.6213788986206055
Validation loss: 1.9383867773958432

Epoch: 6| Step: 3
Training loss: 0.8656594753265381
Validation loss: 1.9411198862137333

Epoch: 6| Step: 4
Training loss: 0.34272462129592896
Validation loss: 1.9740501526863343

Epoch: 6| Step: 5
Training loss: 1.1394906044006348
Validation loss: 1.9949638202626219

Epoch: 6| Step: 6
Training loss: 0.8987196683883667
Validation loss: 2.0011886191624466

Epoch: 6| Step: 7
Training loss: 0.6390613913536072
Validation loss: 1.9891059603742374

Epoch: 6| Step: 8
Training loss: 0.5340753197669983
Validation loss: 1.9913921279291953

Epoch: 6| Step: 9
Training loss: 1.0528626441955566
Validation loss: 1.9487009612462853

Epoch: 6| Step: 10
Training loss: 0.5982120037078857
Validation loss: 1.9169373294358611

Epoch: 6| Step: 11
Training loss: 0.4296852946281433
Validation loss: 1.8790701153457805

Epoch: 6| Step: 12
Training loss: 0.48726022243499756
Validation loss: 1.8869883219401042

Epoch: 6| Step: 13
Training loss: 0.889520525932312
Validation loss: 1.8616082040212487

Epoch: 235| Step: 0
Training loss: 0.7338457107543945
Validation loss: 1.882273615047496

Epoch: 6| Step: 1
Training loss: 0.503247857093811
Validation loss: 1.9007847847477082

Epoch: 6| Step: 2
Training loss: 0.857367753982544
Validation loss: 1.921375419503899

Epoch: 6| Step: 3
Training loss: 0.695716917514801
Validation loss: 1.8981987917295067

Epoch: 6| Step: 4
Training loss: 0.4728121757507324
Validation loss: 1.955674462420966

Epoch: 6| Step: 5
Training loss: 0.5670113563537598
Validation loss: 1.9392127990722656

Epoch: 6| Step: 6
Training loss: 0.9699556827545166
Validation loss: 1.9779632783705188

Epoch: 6| Step: 7
Training loss: 0.7976572513580322
Validation loss: 1.9616663455963135

Epoch: 6| Step: 8
Training loss: 0.6998528838157654
Validation loss: 1.9727929869005758

Epoch: 6| Step: 9
Training loss: 0.4531365931034088
Validation loss: 1.9601862122935634

Epoch: 6| Step: 10
Training loss: 0.8609276413917542
Validation loss: 1.9621287763759654

Epoch: 6| Step: 11
Training loss: 0.9113791584968567
Validation loss: 1.9247696732962003

Epoch: 6| Step: 12
Training loss: 0.5959656238555908
Validation loss: 1.8840000526879424

Epoch: 6| Step: 13
Training loss: 0.39993008971214294
Validation loss: 1.9189250712753625

Epoch: 236| Step: 0
Training loss: 0.676538348197937
Validation loss: 1.884780127515075

Epoch: 6| Step: 1
Training loss: 0.5405333042144775
Validation loss: 1.8807541939520067

Epoch: 6| Step: 2
Training loss: 0.9092567563056946
Validation loss: 1.838503065929618

Epoch: 6| Step: 3
Training loss: 0.8966047167778015
Validation loss: 1.8481385643764208

Epoch: 6| Step: 4
Training loss: 0.6128310561180115
Validation loss: 1.869059322982706

Epoch: 6| Step: 5
Training loss: 0.8846112489700317
Validation loss: 1.8677290921570153

Epoch: 6| Step: 6
Training loss: 0.7529023885726929
Validation loss: 1.9136588599092217

Epoch: 6| Step: 7
Training loss: 0.8172940611839294
Validation loss: 1.9166766789651686

Epoch: 6| Step: 8
Training loss: 0.6489362120628357
Validation loss: 1.9447625965200446

Epoch: 6| Step: 9
Training loss: 0.4412671625614166
Validation loss: 1.9252910434558828

Epoch: 6| Step: 10
Training loss: 0.6709702610969543
Validation loss: 1.8779882038793256

Epoch: 6| Step: 11
Training loss: 0.4955495595932007
Validation loss: 1.8790346845503776

Epoch: 6| Step: 12
Training loss: 0.7807695865631104
Validation loss: 1.9021313472460675

Epoch: 6| Step: 13
Training loss: 0.4794112741947174
Validation loss: 1.8879898773726596

Epoch: 237| Step: 0
Training loss: 0.5289156436920166
Validation loss: 1.89702005668353

Epoch: 6| Step: 1
Training loss: 0.7105556726455688
Validation loss: 1.8748268132568688

Epoch: 6| Step: 2
Training loss: 0.45168352127075195
Validation loss: 1.894166309346435

Epoch: 6| Step: 3
Training loss: 0.6627573370933533
Validation loss: 1.9091126508610223

Epoch: 6| Step: 4
Training loss: 0.7352156639099121
Validation loss: 1.9318970057272142

Epoch: 6| Step: 5
Training loss: 0.2740449905395508
Validation loss: 1.9474280777797903

Epoch: 6| Step: 6
Training loss: 0.6127877235412598
Validation loss: 1.9964753363722114

Epoch: 6| Step: 7
Training loss: 1.0473129749298096
Validation loss: 1.9554317702529251

Epoch: 6| Step: 8
Training loss: 0.7195773720741272
Validation loss: 1.9934262383368708

Epoch: 6| Step: 9
Training loss: 0.6341223120689392
Validation loss: 1.9455219186762327

Epoch: 6| Step: 10
Training loss: 0.5174583196640015
Validation loss: 1.9417623807025213

Epoch: 6| Step: 11
Training loss: 0.9519956111907959
Validation loss: 1.9295176049714446

Epoch: 6| Step: 12
Training loss: 1.093841314315796
Validation loss: 1.9260014974942772

Epoch: 6| Step: 13
Training loss: 1.1428080797195435
Validation loss: 1.9089863915597238

Epoch: 238| Step: 0
Training loss: 0.5812445878982544
Validation loss: 1.9175611439571585

Epoch: 6| Step: 1
Training loss: 0.9490564465522766
Validation loss: 1.9138140883497012

Epoch: 6| Step: 2
Training loss: 0.8644008636474609
Validation loss: 1.9110600999606553

Epoch: 6| Step: 3
Training loss: 0.62882000207901
Validation loss: 1.9249076856079923

Epoch: 6| Step: 4
Training loss: 0.6833317875862122
Validation loss: 1.9240914480660551

Epoch: 6| Step: 5
Training loss: 0.6316804885864258
Validation loss: 1.9514926364344936

Epoch: 6| Step: 6
Training loss: 0.6917096376419067
Validation loss: 1.910934332878359

Epoch: 6| Step: 7
Training loss: 0.8528901934623718
Validation loss: 1.9305517519673994

Epoch: 6| Step: 8
Training loss: 0.3671276271343231
Validation loss: 1.9730626742045085

Epoch: 6| Step: 9
Training loss: 0.9470244646072388
Validation loss: 1.933143336285827

Epoch: 6| Step: 10
Training loss: 0.7166677713394165
Validation loss: 1.924423417737407

Epoch: 6| Step: 11
Training loss: 0.44387561082839966
Validation loss: 1.9517395598914034

Epoch: 6| Step: 12
Training loss: 0.6052297353744507
Validation loss: 1.9806109961643015

Epoch: 6| Step: 13
Training loss: 0.6187847852706909
Validation loss: 1.9774140440007693

Epoch: 239| Step: 0
Training loss: 0.7359696626663208
Validation loss: 1.9981076909649758

Epoch: 6| Step: 1
Training loss: 0.5773946046829224
Validation loss: 1.9710623423258464

Epoch: 6| Step: 2
Training loss: 1.0711257457733154
Validation loss: 1.9381568290854012

Epoch: 6| Step: 3
Training loss: 0.6160765290260315
Validation loss: 1.9025745109845233

Epoch: 6| Step: 4
Training loss: 0.5874789953231812
Validation loss: 1.8753951095765637

Epoch: 6| Step: 5
Training loss: 1.121229887008667
Validation loss: 1.8857864000463997

Epoch: 6| Step: 6
Training loss: 0.7364856004714966
Validation loss: 1.8592151698245798

Epoch: 6| Step: 7
Training loss: 0.663446843624115
Validation loss: 1.8329048951466878

Epoch: 6| Step: 8
Training loss: 0.32068222761154175
Validation loss: 1.8605157303553757

Epoch: 6| Step: 9
Training loss: 0.3146381378173828
Validation loss: 1.866519038395215

Epoch: 6| Step: 10
Training loss: 0.3949730098247528
Validation loss: 1.8502084234709382

Epoch: 6| Step: 11
Training loss: 0.9841145873069763
Validation loss: 1.8813228043176795

Epoch: 6| Step: 12
Training loss: 0.6396487355232239
Validation loss: 1.9043124491168606

Epoch: 6| Step: 13
Training loss: 0.7520790100097656
Validation loss: 1.9162592349513885

Epoch: 240| Step: 0
Training loss: 0.8728588819503784
Validation loss: 1.9242945871045511

Epoch: 6| Step: 1
Training loss: 0.7221506834030151
Validation loss: 1.9149601997867707

Epoch: 6| Step: 2
Training loss: 0.6546287536621094
Validation loss: 1.8891602152137346

Epoch: 6| Step: 3
Training loss: 0.3798455595970154
Validation loss: 1.8607140228312502

Epoch: 6| Step: 4
Training loss: 0.40727096796035767
Validation loss: 1.8780680856397074

Epoch: 6| Step: 5
Training loss: 0.35844820737838745
Validation loss: 1.8957202947267922

Epoch: 6| Step: 6
Training loss: 0.7351521253585815
Validation loss: 1.8694225395879438

Epoch: 6| Step: 7
Training loss: 0.8499338030815125
Validation loss: 1.8669880449130971

Epoch: 6| Step: 8
Training loss: 0.7555477619171143
Validation loss: 1.8574864454166864

Epoch: 6| Step: 9
Training loss: 1.1418962478637695
Validation loss: 1.8588265731770506

Epoch: 6| Step: 10
Training loss: 0.726538896560669
Validation loss: 1.8891292695076234

Epoch: 6| Step: 11
Training loss: 0.4336957633495331
Validation loss: 1.895786528946251

Epoch: 6| Step: 12
Training loss: 1.0144283771514893
Validation loss: 1.9125424764489616

Epoch: 6| Step: 13
Training loss: 0.6956688761711121
Validation loss: 1.9503940202856576

Epoch: 241| Step: 0
Training loss: 0.6325410604476929
Validation loss: 1.9416859098660049

Epoch: 6| Step: 1
Training loss: 1.0915017127990723
Validation loss: 1.9607637672014133

Epoch: 6| Step: 2
Training loss: 0.8670380115509033
Validation loss: 1.9417628370305544

Epoch: 6| Step: 3
Training loss: 0.3558851182460785
Validation loss: 1.947695965407997

Epoch: 6| Step: 4
Training loss: 0.8611426949501038
Validation loss: 1.9492046884311143

Epoch: 6| Step: 5
Training loss: 0.7605341672897339
Validation loss: 1.936234551091348

Epoch: 6| Step: 6
Training loss: 0.7403859496116638
Validation loss: 1.9368224438800608

Epoch: 6| Step: 7
Training loss: 0.7884345054626465
Validation loss: 1.9225998809260707

Epoch: 6| Step: 8
Training loss: 0.33553674817085266
Validation loss: 1.8845833161825776

Epoch: 6| Step: 9
Training loss: 0.6278288960456848
Validation loss: 1.9071443747448664

Epoch: 6| Step: 10
Training loss: 0.7161215543746948
Validation loss: 1.9198942210084649

Epoch: 6| Step: 11
Training loss: 0.8894753456115723
Validation loss: 1.9240951153539843

Epoch: 6| Step: 12
Training loss: 0.3156016170978546
Validation loss: 1.936165730158488

Epoch: 6| Step: 13
Training loss: 0.13465748727321625
Validation loss: 1.9320711358900993

Epoch: 242| Step: 0
Training loss: 0.5732647180557251
Validation loss: 1.9318585741904475

Epoch: 6| Step: 1
Training loss: 0.4776971638202667
Validation loss: 1.9317051441438737

Epoch: 6| Step: 2
Training loss: 0.497528612613678
Validation loss: 1.9432840257562616

Epoch: 6| Step: 3
Training loss: 0.4720037579536438
Validation loss: 1.903781037176809

Epoch: 6| Step: 4
Training loss: 0.8742849826812744
Validation loss: 1.8949765313056208

Epoch: 6| Step: 5
Training loss: 1.1562604904174805
Validation loss: 1.910368142589446

Epoch: 6| Step: 6
Training loss: 0.6205458045005798
Validation loss: 1.890693167204498

Epoch: 6| Step: 7
Training loss: 0.6513879299163818
Validation loss: 1.8378693032008346

Epoch: 6| Step: 8
Training loss: 0.5726339817047119
Validation loss: 1.8560181497245707

Epoch: 6| Step: 9
Training loss: 0.6920928955078125
Validation loss: 1.855536473694668

Epoch: 6| Step: 10
Training loss: 0.8378170132637024
Validation loss: 1.8299593502475369

Epoch: 6| Step: 11
Training loss: 0.7432997226715088
Validation loss: 1.881114132942692

Epoch: 6| Step: 12
Training loss: 0.4710972309112549
Validation loss: 1.8925630995022353

Epoch: 6| Step: 13
Training loss: 1.0946916341781616
Validation loss: 1.9192956827020133

Epoch: 243| Step: 0
Training loss: 0.536527156829834
Validation loss: 1.920794612617903

Epoch: 6| Step: 1
Training loss: 0.7638227939605713
Validation loss: 1.960349480311076

Epoch: 6| Step: 2
Training loss: 1.1216288805007935
Validation loss: 1.9777363295196204

Epoch: 6| Step: 3
Training loss: 0.5918173789978027
Validation loss: 2.012112899493146

Epoch: 6| Step: 4
Training loss: 0.48756033182144165
Validation loss: 1.9551726771939186

Epoch: 6| Step: 5
Training loss: 0.7766948938369751
Validation loss: 1.9254151377626645

Epoch: 6| Step: 6
Training loss: 0.7681647539138794
Validation loss: 1.903031813201084

Epoch: 6| Step: 7
Training loss: 0.64402836561203
Validation loss: 1.855016560964687

Epoch: 6| Step: 8
Training loss: 0.6576657891273499
Validation loss: 1.8843016457814041

Epoch: 6| Step: 9
Training loss: 0.525752604007721
Validation loss: 1.891705096408885

Epoch: 6| Step: 10
Training loss: 0.41817110776901245
Validation loss: 1.895096650687597

Epoch: 6| Step: 11
Training loss: 0.5686125159263611
Validation loss: 1.8784349990147415

Epoch: 6| Step: 12
Training loss: 0.6028799414634705
Validation loss: 1.903580689942965

Epoch: 6| Step: 13
Training loss: 0.7137038111686707
Validation loss: 1.9232628858217629

Epoch: 244| Step: 0
Training loss: 0.44465506076812744
Validation loss: 1.9465539173413349

Epoch: 6| Step: 1
Training loss: 0.3893769383430481
Validation loss: 1.8888700200665383

Epoch: 6| Step: 2
Training loss: 0.5533028244972229
Validation loss: 1.9333258264808244

Epoch: 6| Step: 3
Training loss: 0.583938717842102
Validation loss: 1.969602680975391

Epoch: 6| Step: 4
Training loss: 0.6715129613876343
Validation loss: 1.932962840603244

Epoch: 6| Step: 5
Training loss: 0.6695257425308228
Validation loss: 1.918609457631265

Epoch: 6| Step: 6
Training loss: 0.6025384664535522
Validation loss: 1.9381337883651897

Epoch: 6| Step: 7
Training loss: 0.9794533848762512
Validation loss: 1.9081328825284076

Epoch: 6| Step: 8
Training loss: 0.5949342250823975
Validation loss: 1.9059736203121882

Epoch: 6| Step: 9
Training loss: 1.0699148178100586
Validation loss: 1.9053815269982943

Epoch: 6| Step: 10
Training loss: 0.5667853355407715
Validation loss: 1.9058466329369494

Epoch: 6| Step: 11
Training loss: 0.3780994415283203
Validation loss: 1.913151051408501

Epoch: 6| Step: 12
Training loss: 0.6556437611579895
Validation loss: 1.8982752689751246

Epoch: 6| Step: 13
Training loss: 0.9699158072471619
Validation loss: 1.9187064939929592

Epoch: 245| Step: 0
Training loss: 0.44971945881843567
Validation loss: 1.9011892926308416

Epoch: 6| Step: 1
Training loss: 0.8764044642448425
Validation loss: 1.9578119554827291

Epoch: 6| Step: 2
Training loss: 0.6133379936218262
Validation loss: 1.957698969430821

Epoch: 6| Step: 3
Training loss: 0.7409627437591553
Validation loss: 1.9130243921792636

Epoch: 6| Step: 4
Training loss: 0.5787228345870972
Validation loss: 1.8886677654840613

Epoch: 6| Step: 5
Training loss: 0.6106934547424316
Validation loss: 1.864486627681281

Epoch: 6| Step: 6
Training loss: 0.6087740063667297
Validation loss: 1.8720159197366366

Epoch: 6| Step: 7
Training loss: 0.989432692527771
Validation loss: 1.8646453349821028

Epoch: 6| Step: 8
Training loss: 0.5925025939941406
Validation loss: 1.8364402760741532

Epoch: 6| Step: 9
Training loss: 0.7685201168060303
Validation loss: 1.862022671648251

Epoch: 6| Step: 10
Training loss: 0.39317864179611206
Validation loss: 1.8746558850811375

Epoch: 6| Step: 11
Training loss: 0.5641219019889832
Validation loss: 1.8898587739595802

Epoch: 6| Step: 12
Training loss: 0.5211156606674194
Validation loss: 1.9068104708066551

Epoch: 6| Step: 13
Training loss: 0.6130613088607788
Validation loss: 1.935518010970085

Epoch: 246| Step: 0
Training loss: 0.6263817548751831
Validation loss: 1.947101931418142

Epoch: 6| Step: 1
Training loss: 0.5536344051361084
Validation loss: 1.9779161419919742

Epoch: 6| Step: 2
Training loss: 0.3801466226577759
Validation loss: 1.9444411390571184

Epoch: 6| Step: 3
Training loss: 0.6084017753601074
Validation loss: 1.9345941953761603

Epoch: 6| Step: 4
Training loss: 0.6553025841712952
Validation loss: 1.9147181703198342

Epoch: 6| Step: 5
Training loss: 0.7743800282478333
Validation loss: 1.90230683870213

Epoch: 6| Step: 6
Training loss: 0.6978144645690918
Validation loss: 1.8697042926665275

Epoch: 6| Step: 7
Training loss: 0.44979068636894226
Validation loss: 1.8473694068129345

Epoch: 6| Step: 8
Training loss: 0.46420860290527344
Validation loss: 1.8466201443825998

Epoch: 6| Step: 9
Training loss: 1.166820764541626
Validation loss: 1.8761908251752135

Epoch: 6| Step: 10
Training loss: 0.8352090120315552
Validation loss: 1.8578707659116356

Epoch: 6| Step: 11
Training loss: 0.604938268661499
Validation loss: 1.859171099560235

Epoch: 6| Step: 12
Training loss: 0.4449928104877472
Validation loss: 1.8985063132419382

Epoch: 6| Step: 13
Training loss: 0.6644079685211182
Validation loss: 1.909691560652948

Epoch: 247| Step: 0
Training loss: 0.9775581955909729
Validation loss: 1.9257156207997312

Epoch: 6| Step: 1
Training loss: 0.4219479560852051
Validation loss: 1.8801424580235635

Epoch: 6| Step: 2
Training loss: 0.48195910453796387
Validation loss: 1.8634403905560892

Epoch: 6| Step: 3
Training loss: 0.6970943212509155
Validation loss: 1.8986682289390153

Epoch: 6| Step: 4
Training loss: 0.8293617963790894
Validation loss: 1.9000348185980191

Epoch: 6| Step: 5
Training loss: 0.8190758228302002
Validation loss: 1.8942336369586248

Epoch: 6| Step: 6
Training loss: 0.5590149760246277
Validation loss: 1.903389359033236

Epoch: 6| Step: 7
Training loss: 0.4988322854042053
Validation loss: 1.9209954636071318

Epoch: 6| Step: 8
Training loss: 0.5570882558822632
Validation loss: 1.9102280088650283

Epoch: 6| Step: 9
Training loss: 0.5445569753646851
Validation loss: 1.9036937067585606

Epoch: 6| Step: 10
Training loss: 0.6521451473236084
Validation loss: 1.8772604311666181

Epoch: 6| Step: 11
Training loss: 0.7103968858718872
Validation loss: 1.8260650275855936

Epoch: 6| Step: 12
Training loss: 0.4007432460784912
Validation loss: 1.823309882994621

Epoch: 6| Step: 13
Training loss: 0.8814963102340698
Validation loss: 1.8357234949706702

Epoch: 248| Step: 0
Training loss: 0.6139538884162903
Validation loss: 1.806865297338014

Epoch: 6| Step: 1
Training loss: 0.5742248892784119
Validation loss: 1.8154191893915976

Epoch: 6| Step: 2
Training loss: 0.5846437215805054
Validation loss: 1.8090460120990712

Epoch: 6| Step: 3
Training loss: 0.9668337106704712
Validation loss: 1.7798613245769213

Epoch: 6| Step: 4
Training loss: 0.7034517526626587
Validation loss: 1.806488533173838

Epoch: 6| Step: 5
Training loss: 0.4490387439727783
Validation loss: 1.8204276664282686

Epoch: 6| Step: 6
Training loss: 0.5271434783935547
Validation loss: 1.8322477084334179

Epoch: 6| Step: 7
Training loss: 0.4351145625114441
Validation loss: 1.8225083222953222

Epoch: 6| Step: 8
Training loss: 0.6164926290512085
Validation loss: 1.8809175234968945

Epoch: 6| Step: 9
Training loss: 0.5356574654579163
Validation loss: 1.8498830218468942

Epoch: 6| Step: 10
Training loss: 0.5782613754272461
Validation loss: 1.9082780230429865

Epoch: 6| Step: 11
Training loss: 0.7455823421478271
Validation loss: 1.9104220072428386

Epoch: 6| Step: 12
Training loss: 0.6194762587547302
Validation loss: 1.9533302719875048

Epoch: 6| Step: 13
Training loss: 0.47409629821777344
Validation loss: 1.9691278139750164

Epoch: 249| Step: 0
Training loss: 0.5004677772521973
Validation loss: 1.9540453918518559

Epoch: 6| Step: 1
Training loss: 0.4118269979953766
Validation loss: 1.9552962254452448

Epoch: 6| Step: 2
Training loss: 0.6344937682151794
Validation loss: 1.895294358653407

Epoch: 6| Step: 3
Training loss: 0.6125752329826355
Validation loss: 1.8890645478361396

Epoch: 6| Step: 4
Training loss: 0.6692770719528198
Validation loss: 1.8558052355243313

Epoch: 6| Step: 5
Training loss: 0.3706628680229187
Validation loss: 1.858781289028865

Epoch: 6| Step: 6
Training loss: 0.8685380816459656
Validation loss: 1.844622194126088

Epoch: 6| Step: 7
Training loss: 0.7062480449676514
Validation loss: 1.8174231667672434

Epoch: 6| Step: 8
Training loss: 0.6097044348716736
Validation loss: 1.8514693488356888

Epoch: 6| Step: 9
Training loss: 1.0693199634552002
Validation loss: 1.8263129726532967

Epoch: 6| Step: 10
Training loss: 0.5083550214767456
Validation loss: 1.8177715373295609

Epoch: 6| Step: 11
Training loss: 0.4171169400215149
Validation loss: 1.8791923599858438

Epoch: 6| Step: 12
Training loss: 0.36982208490371704
Validation loss: 1.8522139941492388

Epoch: 6| Step: 13
Training loss: 0.5830352306365967
Validation loss: 1.8830156890294885

Epoch: 250| Step: 0
Training loss: 0.6935966610908508
Validation loss: 1.9229269514801681

Epoch: 6| Step: 1
Training loss: 0.5116006135940552
Validation loss: 1.9418810003547258

Epoch: 6| Step: 2
Training loss: 0.4573306739330292
Validation loss: 1.9275514887225242

Epoch: 6| Step: 3
Training loss: 0.4227069318294525
Validation loss: 1.8832035615880003

Epoch: 6| Step: 4
Training loss: 0.6180921792984009
Validation loss: 1.873928617405635

Epoch: 6| Step: 5
Training loss: 0.7947923541069031
Validation loss: 1.8856045763979676

Epoch: 6| Step: 6
Training loss: 0.7885727882385254
Validation loss: 1.8705832496766122

Epoch: 6| Step: 7
Training loss: 0.8126329183578491
Validation loss: 1.8668436427270212

Epoch: 6| Step: 8
Training loss: 0.5847413539886475
Validation loss: 1.8768064565556024

Epoch: 6| Step: 9
Training loss: 0.5651077628135681
Validation loss: 1.890285150979155

Epoch: 6| Step: 10
Training loss: 0.38318514823913574
Validation loss: 1.9190179865847352

Epoch: 6| Step: 11
Training loss: 0.5180649161338806
Validation loss: 1.9928245467524375

Epoch: 6| Step: 12
Training loss: 0.5990840196609497
Validation loss: 2.0228632957704606

Epoch: 6| Step: 13
Training loss: 0.4377947449684143
Validation loss: 1.9910652432390439

Epoch: 251| Step: 0
Training loss: 0.5654960870742798
Validation loss: 2.037311105317967

Epoch: 6| Step: 1
Training loss: 0.4495789706707001
Validation loss: 2.030237400403587

Epoch: 6| Step: 2
Training loss: 0.6437433362007141
Validation loss: 1.9607663000783613

Epoch: 6| Step: 3
Training loss: 0.8886478543281555
Validation loss: 1.9573309729176183

Epoch: 6| Step: 4
Training loss: 0.7212529182434082
Validation loss: 1.9273700291110623

Epoch: 6| Step: 5
Training loss: 0.5209001302719116
Validation loss: 1.905841778683406

Epoch: 6| Step: 6
Training loss: 0.7595294117927551
Validation loss: 1.8599673509597778

Epoch: 6| Step: 7
Training loss: 0.7731471061706543
Validation loss: 1.8432671434135848

Epoch: 6| Step: 8
Training loss: 0.42442917823791504
Validation loss: 1.8118501222261818

Epoch: 6| Step: 9
Training loss: 0.5595194101333618
Validation loss: 1.8031456265398251

Epoch: 6| Step: 10
Training loss: 0.6367214918136597
Validation loss: 1.818855006207702

Epoch: 6| Step: 11
Training loss: 0.8877508640289307
Validation loss: 1.8150242003061439

Epoch: 6| Step: 12
Training loss: 0.548977255821228
Validation loss: 1.8069928974233649

Epoch: 6| Step: 13
Training loss: 0.44112491607666016
Validation loss: 1.8378369308287097

Epoch: 252| Step: 0
Training loss: 0.5105147361755371
Validation loss: 1.8651889408788374

Epoch: 6| Step: 1
Training loss: 0.46663257479667664
Validation loss: 1.907635384990323

Epoch: 6| Step: 2
Training loss: 0.9384764432907104
Validation loss: 1.9541321544237034

Epoch: 6| Step: 3
Training loss: 0.8632559776306152
Validation loss: 1.944622702496026

Epoch: 6| Step: 4
Training loss: 0.4014012813568115
Validation loss: 1.9327033604345014

Epoch: 6| Step: 5
Training loss: 0.5218791365623474
Validation loss: 1.915555941161289

Epoch: 6| Step: 6
Training loss: 0.41052964329719543
Validation loss: 1.9146851019192768

Epoch: 6| Step: 7
Training loss: 0.5432097315788269
Validation loss: 1.9086284457996328

Epoch: 6| Step: 8
Training loss: 0.7771525382995605
Validation loss: 1.9060524381617063

Epoch: 6| Step: 9
Training loss: 0.8736039400100708
Validation loss: 1.8782214246770388

Epoch: 6| Step: 10
Training loss: 0.8615549802780151
Validation loss: 1.897321178067115

Epoch: 6| Step: 11
Training loss: 0.49568548798561096
Validation loss: 1.9146680742181756

Epoch: 6| Step: 12
Training loss: 0.7884464859962463
Validation loss: 1.8776205714030931

Epoch: 6| Step: 13
Training loss: 0.5453317165374756
Validation loss: 1.8945387396761166

Epoch: 253| Step: 0
Training loss: 0.773688018321991
Validation loss: 1.8675497654945619

Epoch: 6| Step: 1
Training loss: 0.6534253358840942
Validation loss: 1.8948196095805014

Epoch: 6| Step: 2
Training loss: 0.756812334060669
Validation loss: 1.9003670882153254

Epoch: 6| Step: 3
Training loss: 0.4231972396373749
Validation loss: 1.881640144573745

Epoch: 6| Step: 4
Training loss: 0.5166587233543396
Validation loss: 1.8966444833304292

Epoch: 6| Step: 5
Training loss: 0.36584845185279846
Validation loss: 1.8914859781983078

Epoch: 6| Step: 6
Training loss: 0.31236982345581055
Validation loss: 1.8731595521332116

Epoch: 6| Step: 7
Training loss: 0.1979413628578186
Validation loss: 1.9044114928091727

Epoch: 6| Step: 8
Training loss: 0.536733090877533
Validation loss: 1.8873272429230392

Epoch: 6| Step: 9
Training loss: 0.5089014768600464
Validation loss: 1.8839257750459897

Epoch: 6| Step: 10
Training loss: 0.5021743774414062
Validation loss: 1.9080494693530503

Epoch: 6| Step: 11
Training loss: 0.8349459171295166
Validation loss: 1.926312990086053

Epoch: 6| Step: 12
Training loss: 1.0460917949676514
Validation loss: 1.8617112252020067

Epoch: 6| Step: 13
Training loss: 0.4742065966129303
Validation loss: 1.8616700890243694

Epoch: 254| Step: 0
Training loss: 0.5827232599258423
Validation loss: 1.868062424403365

Epoch: 6| Step: 1
Training loss: 0.49219170212745667
Validation loss: 1.8374473253885906

Epoch: 6| Step: 2
Training loss: 0.6762630939483643
Validation loss: 1.8074184194687875

Epoch: 6| Step: 3
Training loss: 1.048219084739685
Validation loss: 1.8141465994619554

Epoch: 6| Step: 4
Training loss: 0.43258094787597656
Validation loss: 1.8261054267165482

Epoch: 6| Step: 5
Training loss: 0.43160051107406616
Validation loss: 1.8388143624028852

Epoch: 6| Step: 6
Training loss: 0.6215555667877197
Validation loss: 1.8643444456079954

Epoch: 6| Step: 7
Training loss: 0.8197099566459656
Validation loss: 1.901539735896613

Epoch: 6| Step: 8
Training loss: 0.37380945682525635
Validation loss: 1.9375678800767469

Epoch: 6| Step: 9
Training loss: 0.6544106602668762
Validation loss: 1.9219326203869236

Epoch: 6| Step: 10
Training loss: 0.6395539045333862
Validation loss: 1.927888924075711

Epoch: 6| Step: 11
Training loss: 0.4563247263431549
Validation loss: 1.8994174234328731

Epoch: 6| Step: 12
Training loss: 0.4535481333732605
Validation loss: 1.901993291352385

Epoch: 6| Step: 13
Training loss: 0.46562179923057556
Validation loss: 1.9509214124371927

Epoch: 255| Step: 0
Training loss: 0.6487851142883301
Validation loss: 1.973255471516681

Epoch: 6| Step: 1
Training loss: 0.7792556285858154
Validation loss: 1.9885115264564432

Epoch: 6| Step: 2
Training loss: 0.444059282541275
Validation loss: 1.9488365432267547

Epoch: 6| Step: 3
Training loss: 0.49123525619506836
Validation loss: 1.9321541401647753

Epoch: 6| Step: 4
Training loss: 0.6801666617393494
Validation loss: 1.913994481486659

Epoch: 6| Step: 5
Training loss: 0.935630202293396
Validation loss: 1.8981430351093251

Epoch: 6| Step: 6
Training loss: 0.45911163091659546
Validation loss: 1.8963073530504782

Epoch: 6| Step: 7
Training loss: 0.5361226797103882
Validation loss: 1.857823952551811

Epoch: 6| Step: 8
Training loss: 0.6089631915092468
Validation loss: 1.8478047488838114

Epoch: 6| Step: 9
Training loss: 0.5913854837417603
Validation loss: 1.838965231372464

Epoch: 6| Step: 10
Training loss: 0.8528594970703125
Validation loss: 1.862268385066781

Epoch: 6| Step: 11
Training loss: 0.5791439414024353
Validation loss: 1.9131349004724973

Epoch: 6| Step: 12
Training loss: 0.848919153213501
Validation loss: 1.9127588913004885

Epoch: 6| Step: 13
Training loss: 0.5272213816642761
Validation loss: 1.858767899133826

Epoch: 256| Step: 0
Training loss: 0.4008227586746216
Validation loss: 1.8898978925520373

Epoch: 6| Step: 1
Training loss: 0.5299738645553589
Validation loss: 1.891283118596641

Epoch: 6| Step: 2
Training loss: 0.41925328969955444
Validation loss: 1.9131828905433736

Epoch: 6| Step: 3
Training loss: 0.5870813727378845
Validation loss: 1.9693383991077382

Epoch: 6| Step: 4
Training loss: 0.8990532159805298
Validation loss: 1.9794855502343947

Epoch: 6| Step: 5
Training loss: 0.4789544343948364
Validation loss: 1.9761755081915087

Epoch: 6| Step: 6
Training loss: 0.8391091823577881
Validation loss: 1.9811794988570675

Epoch: 6| Step: 7
Training loss: 0.6116423606872559
Validation loss: 1.9439745705614808

Epoch: 6| Step: 8
Training loss: 0.887347400188446
Validation loss: 1.9229724086740965

Epoch: 6| Step: 9
Training loss: 0.4835386276245117
Validation loss: 1.8381572820807015

Epoch: 6| Step: 10
Training loss: 0.5874091982841492
Validation loss: 1.8397469315477597

Epoch: 6| Step: 11
Training loss: 0.5404559373855591
Validation loss: 1.8213237395850561

Epoch: 6| Step: 12
Training loss: 0.5547226667404175
Validation loss: 1.8199285294419976

Epoch: 6| Step: 13
Training loss: 0.5731564164161682
Validation loss: 1.7693835842993952

Epoch: 257| Step: 0
Training loss: 0.5728423595428467
Validation loss: 1.8338171602577291

Epoch: 6| Step: 1
Training loss: 0.7255812287330627
Validation loss: 1.8032656446579964

Epoch: 6| Step: 2
Training loss: 0.4495900869369507
Validation loss: 1.8134069904204337

Epoch: 6| Step: 3
Training loss: 0.690258264541626
Validation loss: 1.8446488072795253

Epoch: 6| Step: 4
Training loss: 0.9734320640563965
Validation loss: 1.8570108516241914

Epoch: 6| Step: 5
Training loss: 0.45409446954727173
Validation loss: 1.8996901178872714

Epoch: 6| Step: 6
Training loss: 0.3828144967556
Validation loss: 1.9346644698932607

Epoch: 6| Step: 7
Training loss: 0.8123167753219604
Validation loss: 1.9541141589482625

Epoch: 6| Step: 8
Training loss: 0.49228623509407043
Validation loss: 1.9452338128961542

Epoch: 6| Step: 9
Training loss: 0.6201087832450867
Validation loss: 1.961460405780423

Epoch: 6| Step: 10
Training loss: 0.4277575612068176
Validation loss: 1.9737126686239754

Epoch: 6| Step: 11
Training loss: 0.4505762755870819
Validation loss: 1.9129406316306001

Epoch: 6| Step: 12
Training loss: 0.7530584335327148
Validation loss: 1.8896214731277958

Epoch: 6| Step: 13
Training loss: 0.5938481092453003
Validation loss: 1.8449715606627926

Epoch: 258| Step: 0
Training loss: 0.444946825504303
Validation loss: 1.8531004023808304

Epoch: 6| Step: 1
Training loss: 0.9346613883972168
Validation loss: 1.8752970490404355

Epoch: 6| Step: 2
Training loss: 0.5836835503578186
Validation loss: 1.8424615116529568

Epoch: 6| Step: 3
Training loss: 0.6173869371414185
Validation loss: 1.939020695224885

Epoch: 6| Step: 4
Training loss: 0.4616278409957886
Validation loss: 1.9576688774170414

Epoch: 6| Step: 5
Training loss: 0.6562474370002747
Validation loss: 1.9455366621735275

Epoch: 6| Step: 6
Training loss: 0.519158661365509
Validation loss: 1.9683817368681713

Epoch: 6| Step: 7
Training loss: 0.6924881935119629
Validation loss: 1.9251036541436308

Epoch: 6| Step: 8
Training loss: 0.4388708472251892
Validation loss: 1.9272397025938957

Epoch: 6| Step: 9
Training loss: 0.581924557685852
Validation loss: 1.8908916955353112

Epoch: 6| Step: 10
Training loss: 0.6102334260940552
Validation loss: 1.9089007480170137

Epoch: 6| Step: 11
Training loss: 0.43067026138305664
Validation loss: 1.8989967607682752

Epoch: 6| Step: 12
Training loss: 0.6372065544128418
Validation loss: 1.8898223471897904

Epoch: 6| Step: 13
Training loss: 0.433743417263031
Validation loss: 1.8905577787788965

Epoch: 259| Step: 0
Training loss: 0.7421037554740906
Validation loss: 1.8867860955576743

Epoch: 6| Step: 1
Training loss: 0.98909991979599
Validation loss: 1.8859945599750807

Epoch: 6| Step: 2
Training loss: 0.9114230871200562
Validation loss: 1.8629827960844962

Epoch: 6| Step: 3
Training loss: 0.652155876159668
Validation loss: 1.8674140386683966

Epoch: 6| Step: 4
Training loss: 0.6051385998725891
Validation loss: 1.8479400501456311

Epoch: 6| Step: 5
Training loss: 0.594221293926239
Validation loss: 1.8465829459569787

Epoch: 6| Step: 6
Training loss: 0.5036729574203491
Validation loss: 1.8245952014000184

Epoch: 6| Step: 7
Training loss: 0.6798973083496094
Validation loss: 1.8768490411901986

Epoch: 6| Step: 8
Training loss: 0.3392881453037262
Validation loss: 1.8640858473316315

Epoch: 6| Step: 9
Training loss: 0.44541749358177185
Validation loss: 1.8722945669645905

Epoch: 6| Step: 10
Training loss: 0.8496730923652649
Validation loss: 1.8788595712313088

Epoch: 6| Step: 11
Training loss: 0.7395124435424805
Validation loss: 1.888532853895618

Epoch: 6| Step: 12
Training loss: 0.4521026909351349
Validation loss: 1.8824982040671892

Epoch: 6| Step: 13
Training loss: 0.3418949246406555
Validation loss: 1.9048700947915354

Epoch: 260| Step: 0
Training loss: 0.5840884447097778
Validation loss: 1.9437024157534364

Epoch: 6| Step: 1
Training loss: 0.49837106466293335
Validation loss: 1.8870265253128544

Epoch: 6| Step: 2
Training loss: 0.5412166118621826
Validation loss: 1.8744221938553678

Epoch: 6| Step: 3
Training loss: 0.39622804522514343
Validation loss: 1.8341721104037376

Epoch: 6| Step: 4
Training loss: 0.6902788281440735
Validation loss: 1.8518398679712766

Epoch: 6| Step: 5
Training loss: 0.5646266937255859
Validation loss: 1.8728569066652687

Epoch: 6| Step: 6
Training loss: 0.6429527997970581
Validation loss: 1.8793763396560506

Epoch: 6| Step: 7
Training loss: 0.5397889614105225
Validation loss: 1.919120180991388

Epoch: 6| Step: 8
Training loss: 0.9271960854530334
Validation loss: 1.9399246054310952

Epoch: 6| Step: 9
Training loss: 0.6623034477233887
Validation loss: 1.9236147371671533

Epoch: 6| Step: 10
Training loss: 0.6065036058425903
Validation loss: 1.9237484867854784

Epoch: 6| Step: 11
Training loss: 0.34022653102874756
Validation loss: 1.8743470573938021

Epoch: 6| Step: 12
Training loss: 0.43730002641677856
Validation loss: 1.8680563947205902

Epoch: 6| Step: 13
Training loss: 0.7914589643478394
Validation loss: 1.8667057944882302

Epoch: 261| Step: 0
Training loss: 0.3282126188278198
Validation loss: 1.8721545421948997

Epoch: 6| Step: 1
Training loss: 0.6867198944091797
Validation loss: 1.8776990393156647

Epoch: 6| Step: 2
Training loss: 0.972886860370636
Validation loss: 1.8671469842233965

Epoch: 6| Step: 3
Training loss: 0.3266493082046509
Validation loss: 1.8208866350112423

Epoch: 6| Step: 4
Training loss: 0.5586189031600952
Validation loss: 1.799367147107278

Epoch: 6| Step: 5
Training loss: 0.4363701641559601
Validation loss: 1.7715797847317112

Epoch: 6| Step: 6
Training loss: 0.36303916573524475
Validation loss: 1.8392272854364047

Epoch: 6| Step: 7
Training loss: 0.6367026567459106
Validation loss: 1.8569962645089755

Epoch: 6| Step: 8
Training loss: 0.5070804953575134
Validation loss: 1.8618670509707542

Epoch: 6| Step: 9
Training loss: 0.4555882513523102
Validation loss: 1.919027341309414

Epoch: 6| Step: 10
Training loss: 0.571438193321228
Validation loss: 1.8701125716650358

Epoch: 6| Step: 11
Training loss: 0.8640134334564209
Validation loss: 1.9028912359668362

Epoch: 6| Step: 12
Training loss: 0.9212230443954468
Validation loss: 1.911547665954918

Epoch: 6| Step: 13
Training loss: 0.4240352213382721
Validation loss: 1.863212949486189

Epoch: 262| Step: 0
Training loss: 0.5489130616188049
Validation loss: 1.8758995943172003

Epoch: 6| Step: 1
Training loss: 0.6279833912849426
Validation loss: 1.873737637714673

Epoch: 6| Step: 2
Training loss: 0.6435257196426392
Validation loss: 1.8659067692295197

Epoch: 6| Step: 3
Training loss: 0.46997523307800293
Validation loss: 1.8594424404123777

Epoch: 6| Step: 4
Training loss: 0.5802183151245117
Validation loss: 1.8458569767654582

Epoch: 6| Step: 5
Training loss: 0.3290313184261322
Validation loss: 1.856093789941521

Epoch: 6| Step: 6
Training loss: 0.6756936311721802
Validation loss: 1.845755115632088

Epoch: 6| Step: 7
Training loss: 0.3972046375274658
Validation loss: 1.865072766939799

Epoch: 6| Step: 8
Training loss: 0.5104516744613647
Validation loss: 1.8606166173053045

Epoch: 6| Step: 9
Training loss: 0.30960386991500854
Validation loss: 1.9208888264112576

Epoch: 6| Step: 10
Training loss: 0.7676460146903992
Validation loss: 1.9361116322137977

Epoch: 6| Step: 11
Training loss: 0.592170238494873
Validation loss: 1.9014589248165008

Epoch: 6| Step: 12
Training loss: 0.44315654039382935
Validation loss: 1.8932529559699438

Epoch: 6| Step: 13
Training loss: 0.4174376428127289
Validation loss: 1.8533182118528633

Epoch: 263| Step: 0
Training loss: 0.30959397554397583
Validation loss: 1.8792716854362077

Epoch: 6| Step: 1
Training loss: 0.28084665536880493
Validation loss: 1.8605866816736036

Epoch: 6| Step: 2
Training loss: 0.4328981041908264
Validation loss: 1.8752186888007707

Epoch: 6| Step: 3
Training loss: 0.4767751097679138
Validation loss: 1.9129168038727136

Epoch: 6| Step: 4
Training loss: 0.7324482798576355
Validation loss: 1.9408017589199928

Epoch: 6| Step: 5
Training loss: 0.5963013172149658
Validation loss: 1.9648346580484861

Epoch: 6| Step: 6
Training loss: 0.669939398765564
Validation loss: 1.9407059928422332

Epoch: 6| Step: 7
Training loss: 0.5353935956954956
Validation loss: 1.9458885359507736

Epoch: 6| Step: 8
Training loss: 0.31103700399398804
Validation loss: 1.929615084842969

Epoch: 6| Step: 9
Training loss: 0.7797731161117554
Validation loss: 1.9543706845211726

Epoch: 6| Step: 10
Training loss: 0.6314349174499512
Validation loss: 1.9384206533432007

Epoch: 6| Step: 11
Training loss: 0.9857335686683655
Validation loss: 1.9188192749536166

Epoch: 6| Step: 12
Training loss: 0.3977697789669037
Validation loss: 1.864924975620803

Epoch: 6| Step: 13
Training loss: 0.30006375908851624
Validation loss: 1.8298053715818672

Epoch: 264| Step: 0
Training loss: 0.5955947637557983
Validation loss: 1.8477760271359516

Epoch: 6| Step: 1
Training loss: 0.46387383341789246
Validation loss: 1.8331521813587477

Epoch: 6| Step: 2
Training loss: 0.32009977102279663
Validation loss: 1.8501143968233498

Epoch: 6| Step: 3
Training loss: 0.4269598126411438
Validation loss: 1.87220258866587

Epoch: 6| Step: 4
Training loss: 0.5480929613113403
Validation loss: 1.8766505692594795

Epoch: 6| Step: 5
Training loss: 0.7917720675468445
Validation loss: 1.8598643015789729

Epoch: 6| Step: 6
Training loss: 0.8896942734718323
Validation loss: 1.906925606471236

Epoch: 6| Step: 7
Training loss: 0.43838566541671753
Validation loss: 1.8704476548779396

Epoch: 6| Step: 8
Training loss: 0.552904486656189
Validation loss: 1.8657735701530211

Epoch: 6| Step: 9
Training loss: 0.5717624425888062
Validation loss: 1.8384708435304704

Epoch: 6| Step: 10
Training loss: 0.5846951603889465
Validation loss: 1.894367274417672

Epoch: 6| Step: 11
Training loss: 0.6548653244972229
Validation loss: 1.8476651842876146

Epoch: 6| Step: 12
Training loss: 0.4620271921157837
Validation loss: 1.8406756898408294

Epoch: 6| Step: 13
Training loss: 0.32108184695243835
Validation loss: 1.8502738680890811

Epoch: 265| Step: 0
Training loss: 0.4606737196445465
Validation loss: 1.8368070599853352

Epoch: 6| Step: 1
Training loss: 0.8180668354034424
Validation loss: 1.8900453108613209

Epoch: 6| Step: 2
Training loss: 0.48650020360946655
Validation loss: 1.8985183008255497

Epoch: 6| Step: 3
Training loss: 0.5968729853630066
Validation loss: 1.974422808616392

Epoch: 6| Step: 4
Training loss: 0.23703674972057343
Validation loss: 2.021335255715155

Epoch: 6| Step: 5
Training loss: 0.8024357557296753
Validation loss: 2.012557937252906

Epoch: 6| Step: 6
Training loss: 0.7084589004516602
Validation loss: 1.9988970538621307

Epoch: 6| Step: 7
Training loss: 0.237285777926445
Validation loss: 1.9811581386032926

Epoch: 6| Step: 8
Training loss: 0.676982045173645
Validation loss: 1.9067113284141786

Epoch: 6| Step: 9
Training loss: 0.45820799469947815
Validation loss: 1.8936757349198865

Epoch: 6| Step: 10
Training loss: 0.6193971633911133
Validation loss: 1.8701880311453214

Epoch: 6| Step: 11
Training loss: 0.684084415435791
Validation loss: 1.8299321987295663

Epoch: 6| Step: 12
Training loss: 0.2701694965362549
Validation loss: 1.8479838563549904

Epoch: 6| Step: 13
Training loss: 0.5646324157714844
Validation loss: 1.8293312659827612

Epoch: 266| Step: 0
Training loss: 0.42608875036239624
Validation loss: 1.8264843981753114

Epoch: 6| Step: 1
Training loss: 0.4729357659816742
Validation loss: 1.8738407883592831

Epoch: 6| Step: 2
Training loss: 0.30659234523773193
Validation loss: 1.8711891866499377

Epoch: 6| Step: 3
Training loss: 0.33039939403533936
Validation loss: 1.886333998813424

Epoch: 6| Step: 4
Training loss: 0.4986497461795807
Validation loss: 1.9497198135622087

Epoch: 6| Step: 5
Training loss: 0.4982479512691498
Validation loss: 1.9519596856127504

Epoch: 6| Step: 6
Training loss: 0.5163053274154663
Validation loss: 1.977002069514285

Epoch: 6| Step: 7
Training loss: 0.6140149235725403
Validation loss: 1.9449865702659852

Epoch: 6| Step: 8
Training loss: 0.9416348338127136
Validation loss: 1.9550262035862092

Epoch: 6| Step: 9
Training loss: 0.4449271261692047
Validation loss: 1.9206991118769492

Epoch: 6| Step: 10
Training loss: 0.5922823548316956
Validation loss: 1.8795806554055983

Epoch: 6| Step: 11
Training loss: 0.5252493619918823
Validation loss: 1.8726068158303537

Epoch: 6| Step: 12
Training loss: 0.41553425788879395
Validation loss: 1.838976767755324

Epoch: 6| Step: 13
Training loss: 0.6602902412414551
Validation loss: 1.8258998368376045

Epoch: 267| Step: 0
Training loss: 0.1845124363899231
Validation loss: 1.82968109397478

Epoch: 6| Step: 1
Training loss: 0.6868700385093689
Validation loss: 1.811263552276037

Epoch: 6| Step: 2
Training loss: 0.8933330774307251
Validation loss: 1.8340061518453783

Epoch: 6| Step: 3
Training loss: 0.3974711000919342
Validation loss: 1.8052827978646884

Epoch: 6| Step: 4
Training loss: 0.26302284002304077
Validation loss: 1.8779246063642605

Epoch: 6| Step: 5
Training loss: 0.3655604422092438
Validation loss: 1.8534366520502235

Epoch: 6| Step: 6
Training loss: 0.6748037934303284
Validation loss: 1.8696010907491047

Epoch: 6| Step: 7
Training loss: 0.3103235960006714
Validation loss: 1.8918182132064656

Epoch: 6| Step: 8
Training loss: 0.3563954532146454
Validation loss: 1.870286569800428

Epoch: 6| Step: 9
Training loss: 0.7188438177108765
Validation loss: 1.8944164988815144

Epoch: 6| Step: 10
Training loss: 0.5044265985488892
Validation loss: 1.8752424127312117

Epoch: 6| Step: 11
Training loss: 0.444904625415802
Validation loss: 1.897626143629833

Epoch: 6| Step: 12
Training loss: 0.37367767095565796
Validation loss: 1.8644416511699717

Epoch: 6| Step: 13
Training loss: 0.6564443111419678
Validation loss: 1.8856372794797343

Epoch: 268| Step: 0
Training loss: 0.4883079528808594
Validation loss: 1.8823018561127365

Epoch: 6| Step: 1
Training loss: 0.7071132063865662
Validation loss: 1.8877344093015116

Epoch: 6| Step: 2
Training loss: 0.779483437538147
Validation loss: 1.8986922271790043

Epoch: 6| Step: 3
Training loss: 0.40504196286201477
Validation loss: 1.911960796643329

Epoch: 6| Step: 4
Training loss: 0.38104891777038574
Validation loss: 1.9080886879274923

Epoch: 6| Step: 5
Training loss: 0.48293161392211914
Validation loss: 1.919974587296927

Epoch: 6| Step: 6
Training loss: 0.32531654834747314
Validation loss: 1.9285639178368352

Epoch: 6| Step: 7
Training loss: 0.5128594040870667
Validation loss: 1.9359270911062918

Epoch: 6| Step: 8
Training loss: 0.31566518545150757
Validation loss: 1.948557722953058

Epoch: 6| Step: 9
Training loss: 0.4232005774974823
Validation loss: 1.948514699935913

Epoch: 6| Step: 10
Training loss: 0.499462753534317
Validation loss: 1.9268305891303605

Epoch: 6| Step: 11
Training loss: 0.43720120191574097
Validation loss: 1.9414514867208337

Epoch: 6| Step: 12
Training loss: 0.4504404664039612
Validation loss: 1.9831919849559825

Epoch: 6| Step: 13
Training loss: 0.6568644046783447
Validation loss: 1.9414260720693937

Epoch: 269| Step: 0
Training loss: 0.4826137125492096
Validation loss: 1.9689404003081783

Epoch: 6| Step: 1
Training loss: 0.4905892312526703
Validation loss: 1.9599280126633183

Epoch: 6| Step: 2
Training loss: 0.44278597831726074
Validation loss: 1.9715484508904078

Epoch: 6| Step: 3
Training loss: 0.901530921459198
Validation loss: 1.9406769288483487

Epoch: 6| Step: 4
Training loss: 0.298175573348999
Validation loss: 1.9627156616539083

Epoch: 6| Step: 5
Training loss: 0.4866543412208557
Validation loss: 1.9416468835646106

Epoch: 6| Step: 6
Training loss: 0.45539945363998413
Validation loss: 1.9127066801953059

Epoch: 6| Step: 7
Training loss: 0.31982845067977905
Validation loss: 1.9188769504588137

Epoch: 6| Step: 8
Training loss: 0.4608069062232971
Validation loss: 1.905090166676429

Epoch: 6| Step: 9
Training loss: 0.3696090579032898
Validation loss: 1.869830116148918

Epoch: 6| Step: 10
Training loss: 0.46689778566360474
Validation loss: 1.8976894899081158

Epoch: 6| Step: 11
Training loss: 0.4216918349266052
Validation loss: 1.8421737455552625

Epoch: 6| Step: 12
Training loss: 0.39453867077827454
Validation loss: 1.8612888602800266

Epoch: 6| Step: 13
Training loss: 0.3257594108581543
Validation loss: 1.8959047563614384

Epoch: 270| Step: 0
Training loss: 0.44451066851615906
Validation loss: 1.8582909325117707

Epoch: 6| Step: 1
Training loss: 0.7369427680969238
Validation loss: 1.880130962658954

Epoch: 6| Step: 2
Training loss: 0.49546146392822266
Validation loss: 1.8958578904469807

Epoch: 6| Step: 3
Training loss: 0.1856924295425415
Validation loss: 1.9018294657430341

Epoch: 6| Step: 4
Training loss: 0.45707133412361145
Validation loss: 1.8810338935544413

Epoch: 6| Step: 5
Training loss: 0.25209590792655945
Validation loss: 1.8621862908845306

Epoch: 6| Step: 6
Training loss: 0.4008740186691284
Validation loss: 1.9135585420875139

Epoch: 6| Step: 7
Training loss: 0.4680536687374115
Validation loss: 1.8951810175372708

Epoch: 6| Step: 8
Training loss: 0.5999988317489624
Validation loss: 1.9055581554289787

Epoch: 6| Step: 9
Training loss: 0.3295838534832001
Validation loss: 1.8245407689002253

Epoch: 6| Step: 10
Training loss: 0.4049070477485657
Validation loss: 1.8280755781358289

Epoch: 6| Step: 11
Training loss: 0.8142935037612915
Validation loss: 1.8650255446792932

Epoch: 6| Step: 12
Training loss: 0.5168210864067078
Validation loss: 1.8551575246677603

Epoch: 6| Step: 13
Training loss: 0.3869115114212036
Validation loss: 1.8722617292916903

Epoch: 271| Step: 0
Training loss: 0.3374299705028534
Validation loss: 1.8715839962805472

Epoch: 6| Step: 1
Training loss: 0.6051275730133057
Validation loss: 1.8954292433236235

Epoch: 6| Step: 2
Training loss: 0.5976579785346985
Validation loss: 1.8931544673058294

Epoch: 6| Step: 3
Training loss: 0.335711270570755
Validation loss: 1.886939219249192

Epoch: 6| Step: 4
Training loss: 0.5232172012329102
Validation loss: 1.9405998004380094

Epoch: 6| Step: 5
Training loss: 0.6273012757301331
Validation loss: 1.9713808695475261

Epoch: 6| Step: 6
Training loss: 0.8180580735206604
Validation loss: 2.015580092706988

Epoch: 6| Step: 7
Training loss: 0.5834486484527588
Validation loss: 2.0310414247615363

Epoch: 6| Step: 8
Training loss: 0.4348483681678772
Validation loss: 2.0111790754461802

Epoch: 6| Step: 9
Training loss: 0.7353962659835815
Validation loss: 1.9743774821681361

Epoch: 6| Step: 10
Training loss: 0.40812814235687256
Validation loss: 1.9460779800209949

Epoch: 6| Step: 11
Training loss: 0.2875588536262512
Validation loss: 1.935751051031133

Epoch: 6| Step: 12
Training loss: 0.5618464946746826
Validation loss: 1.9061133451359247

Epoch: 6| Step: 13
Training loss: 0.5770632028579712
Validation loss: 1.8485646824682913

Epoch: 272| Step: 0
Training loss: 0.45375943183898926
Validation loss: 1.886610105473508

Epoch: 6| Step: 1
Training loss: 0.3349698781967163
Validation loss: 1.835482120513916

Epoch: 6| Step: 2
Training loss: 0.8414812088012695
Validation loss: 1.8936815979660198

Epoch: 6| Step: 3
Training loss: 0.765617847442627
Validation loss: 1.8964987301057386

Epoch: 6| Step: 4
Training loss: 0.2479275017976761
Validation loss: 1.9108012427565872

Epoch: 6| Step: 5
Training loss: 0.2518733739852905
Validation loss: 1.9743570922523417

Epoch: 6| Step: 6
Training loss: 0.3897874057292938
Validation loss: 2.035149146151799

Epoch: 6| Step: 7
Training loss: 0.6366935968399048
Validation loss: 2.054002611867843

Epoch: 6| Step: 8
Training loss: 0.4744497239589691
Validation loss: 2.0934113405084096

Epoch: 6| Step: 9
Training loss: 0.6820170283317566
Validation loss: 2.043587064230314

Epoch: 6| Step: 10
Training loss: 0.6745654344558716
Validation loss: 2.0427593364510486

Epoch: 6| Step: 11
Training loss: 0.4621496796607971
Validation loss: 2.0494700734333327

Epoch: 6| Step: 12
Training loss: 0.48766279220581055
Validation loss: 2.049285886108234

Epoch: 6| Step: 13
Training loss: 0.5486156940460205
Validation loss: 1.9879739181969756

Epoch: 273| Step: 0
Training loss: 0.2467554807662964
Validation loss: 1.9573351977973856

Epoch: 6| Step: 1
Training loss: 0.3400442600250244
Validation loss: 1.8977390719998268

Epoch: 6| Step: 2
Training loss: 0.6009047031402588
Validation loss: 1.897319136127349

Epoch: 6| Step: 3
Training loss: 0.5799645185470581
Validation loss: 1.8890264367544523

Epoch: 6| Step: 4
Training loss: 0.6574326753616333
Validation loss: 1.841220860840172

Epoch: 6| Step: 5
Training loss: 0.446866512298584
Validation loss: 1.90630143432207

Epoch: 6| Step: 6
Training loss: 0.4393979012966156
Validation loss: 1.8587269372837518

Epoch: 6| Step: 7
Training loss: 0.5110715627670288
Validation loss: 1.9166979212914743

Epoch: 6| Step: 8
Training loss: 0.4027702808380127
Validation loss: 1.9117772245919833

Epoch: 6| Step: 9
Training loss: 0.6747693419456482
Validation loss: 1.9486068961440877

Epoch: 6| Step: 10
Training loss: 0.5137195587158203
Validation loss: 2.0111793138647593

Epoch: 6| Step: 11
Training loss: 0.6939069032669067
Validation loss: 2.0028350507059405

Epoch: 6| Step: 12
Training loss: 0.5105476379394531
Validation loss: 1.9980614428879113

Epoch: 6| Step: 13
Training loss: 0.37324005365371704
Validation loss: 1.9981618312097364

Epoch: 274| Step: 0
Training loss: 0.24469707906246185
Validation loss: 1.908614271430559

Epoch: 6| Step: 1
Training loss: 0.2927871346473694
Validation loss: 1.8692785078479397

Epoch: 6| Step: 2
Training loss: 0.8714237809181213
Validation loss: 1.8376137274567799

Epoch: 6| Step: 3
Training loss: 0.3615700304508209
Validation loss: 1.837395063010595

Epoch: 6| Step: 4
Training loss: 0.6149019002914429
Validation loss: 1.8374892357856996

Epoch: 6| Step: 5
Training loss: 0.3630109429359436
Validation loss: 1.8219480988799885

Epoch: 6| Step: 6
Training loss: 0.43143415451049805
Validation loss: 1.830034004744663

Epoch: 6| Step: 7
Training loss: 0.40267840027809143
Validation loss: 1.799672601043537

Epoch: 6| Step: 8
Training loss: 0.5180730819702148
Validation loss: 1.809051836690595

Epoch: 6| Step: 9
Training loss: 0.669482409954071
Validation loss: 1.8146865854981125

Epoch: 6| Step: 10
Training loss: 0.4324619174003601
Validation loss: 1.8612051971497074

Epoch: 6| Step: 11
Training loss: 0.48703309893608093
Validation loss: 1.882247878659156

Epoch: 6| Step: 12
Training loss: 0.581915557384491
Validation loss: 1.8411831137954549

Epoch: 6| Step: 13
Training loss: 0.40705159306526184
Validation loss: 1.8511669751136535

Epoch: 275| Step: 0
Training loss: 0.2992362678050995
Validation loss: 1.8663503328959148

Epoch: 6| Step: 1
Training loss: 0.4489196538925171
Validation loss: 1.8907948001738517

Epoch: 6| Step: 2
Training loss: 0.3744823932647705
Validation loss: 1.9167489159491755

Epoch: 6| Step: 3
Training loss: 0.6043840646743774
Validation loss: 1.9072658400381766

Epoch: 6| Step: 4
Training loss: 0.5095317363739014
Validation loss: 1.9136699476549703

Epoch: 6| Step: 5
Training loss: 0.4565545916557312
Validation loss: 1.942892454003775

Epoch: 6| Step: 6
Training loss: 0.5794873237609863
Validation loss: 1.9024873959120883

Epoch: 6| Step: 7
Training loss: 0.43725186586380005
Validation loss: 1.910212368093511

Epoch: 6| Step: 8
Training loss: 0.299620658159256
Validation loss: 1.889733786224037

Epoch: 6| Step: 9
Training loss: 0.4150964617729187
Validation loss: 1.8899964004434564

Epoch: 6| Step: 10
Training loss: 0.6730963587760925
Validation loss: 1.889380242234917

Epoch: 6| Step: 11
Training loss: 0.8696269989013672
Validation loss: 1.9358527916733936

Epoch: 6| Step: 12
Training loss: 0.5116101503372192
Validation loss: 1.9197046667016961

Epoch: 6| Step: 13
Training loss: 0.19248978793621063
Validation loss: 1.8814269086366058

Epoch: 276| Step: 0
Training loss: 0.5492433309555054
Validation loss: 1.8990536787176644

Epoch: 6| Step: 1
Training loss: 0.4010951519012451
Validation loss: 1.922035127557734

Epoch: 6| Step: 2
Training loss: 0.39389199018478394
Validation loss: 1.9173201771192654

Epoch: 6| Step: 3
Training loss: 0.6105552911758423
Validation loss: 1.9231776037523824

Epoch: 6| Step: 4
Training loss: 0.4226645827293396
Validation loss: 1.935542465538107

Epoch: 6| Step: 5
Training loss: 0.21941566467285156
Validation loss: 1.9033904126895371

Epoch: 6| Step: 6
Training loss: 0.5241060256958008
Validation loss: 1.8962851442316526

Epoch: 6| Step: 7
Training loss: 0.554564893245697
Validation loss: 1.9069401589773034

Epoch: 6| Step: 8
Training loss: 0.3147667646408081
Validation loss: 1.9336780963405487

Epoch: 6| Step: 9
Training loss: 0.6277726292610168
Validation loss: 1.944209414143716

Epoch: 6| Step: 10
Training loss: 0.6124950647354126
Validation loss: 1.932364261278542

Epoch: 6| Step: 11
Training loss: 0.3843308687210083
Validation loss: 1.92698654308114

Epoch: 6| Step: 12
Training loss: 0.3128398060798645
Validation loss: 1.8979348546715193

Epoch: 6| Step: 13
Training loss: 0.5697529315948486
Validation loss: 1.8741060879922682

Epoch: 277| Step: 0
Training loss: 0.3322004973888397
Validation loss: 1.8761342597264115

Epoch: 6| Step: 1
Training loss: 0.5020655393600464
Validation loss: 1.8954693771177722

Epoch: 6| Step: 2
Training loss: 0.18801134824752808
Validation loss: 1.8988114915868288

Epoch: 6| Step: 3
Training loss: 0.42043766379356384
Validation loss: 1.9068133010659167

Epoch: 6| Step: 4
Training loss: 0.48863473534584045
Validation loss: 1.9140150239390712

Epoch: 6| Step: 5
Training loss: 0.5449539422988892
Validation loss: 1.9381238888668757

Epoch: 6| Step: 6
Training loss: 0.4530067443847656
Validation loss: 1.951491666096513

Epoch: 6| Step: 7
Training loss: 0.390207976102829
Validation loss: 1.9412751364451584

Epoch: 6| Step: 8
Training loss: 0.29956042766571045
Validation loss: 1.938954617387505

Epoch: 6| Step: 9
Training loss: 0.3443388044834137
Validation loss: 1.8793064804487332

Epoch: 6| Step: 10
Training loss: 0.4491281807422638
Validation loss: 1.8916928742521553

Epoch: 6| Step: 11
Training loss: 0.47514957189559937
Validation loss: 1.9252972718208068

Epoch: 6| Step: 12
Training loss: 0.8634467124938965
Validation loss: 1.8933677545157812

Epoch: 6| Step: 13
Training loss: 0.2888904809951782
Validation loss: 1.8892782503558743

Epoch: 278| Step: 0
Training loss: 0.20475128293037415
Validation loss: 1.878759204700429

Epoch: 6| Step: 1
Training loss: 0.5166581869125366
Validation loss: 1.8416985978362381

Epoch: 6| Step: 2
Training loss: 0.42379915714263916
Validation loss: 1.8942357583712506

Epoch: 6| Step: 3
Training loss: 0.6459925174713135
Validation loss: 1.8318446733618294

Epoch: 6| Step: 4
Training loss: 0.34776079654693604
Validation loss: 1.868877521125219

Epoch: 6| Step: 5
Training loss: 0.923445999622345
Validation loss: 1.8509690812838975

Epoch: 6| Step: 6
Training loss: 0.7351614236831665
Validation loss: 1.8457626258173296

Epoch: 6| Step: 7
Training loss: 0.5514847040176392
Validation loss: 1.8536972730390486

Epoch: 6| Step: 8
Training loss: 0.323026567697525
Validation loss: 1.8281086029544953

Epoch: 6| Step: 9
Training loss: 0.35085588693618774
Validation loss: 1.8564620556369904

Epoch: 6| Step: 10
Training loss: 0.23640312254428864
Validation loss: 1.8590837370964788

Epoch: 6| Step: 11
Training loss: 0.38586515188217163
Validation loss: 1.8745199826455885

Epoch: 6| Step: 12
Training loss: 0.3996260166168213
Validation loss: 1.8725320062329691

Epoch: 6| Step: 13
Training loss: 0.5292618870735168
Validation loss: 1.8647292980583765

Epoch: 279| Step: 0
Training loss: 0.4683248698711395
Validation loss: 1.8679782485449186

Epoch: 6| Step: 1
Training loss: 0.339365690946579
Validation loss: 1.8545983081222863

Epoch: 6| Step: 2
Training loss: 0.28674060106277466
Validation loss: 1.8829363802427888

Epoch: 6| Step: 3
Training loss: 0.7585525512695312
Validation loss: 1.9402276777452039

Epoch: 6| Step: 4
Training loss: 0.3592808246612549
Validation loss: 1.9295734436281267

Epoch: 6| Step: 5
Training loss: 0.4448412358760834
Validation loss: 1.940828659201181

Epoch: 6| Step: 6
Training loss: 0.5319951176643372
Validation loss: 1.9152524984011086

Epoch: 6| Step: 7
Training loss: 0.41847726702690125
Validation loss: 1.8453652602370068

Epoch: 6| Step: 8
Training loss: 0.5671386122703552
Validation loss: 1.843071195387071

Epoch: 6| Step: 9
Training loss: 0.6782472133636475
Validation loss: 1.8732683171508133

Epoch: 6| Step: 10
Training loss: 0.4398740530014038
Validation loss: 1.8362189505689888

Epoch: 6| Step: 11
Training loss: 0.45010316371917725
Validation loss: 1.8608974718278455

Epoch: 6| Step: 12
Training loss: 0.4311686158180237
Validation loss: 1.8539632494731615

Epoch: 6| Step: 13
Training loss: 0.1776018589735031
Validation loss: 1.9019929157790316

Epoch: 280| Step: 0
Training loss: 0.3817867636680603
Validation loss: 1.8676652972416212

Epoch: 6| Step: 1
Training loss: 0.43529191613197327
Validation loss: 1.930071198812095

Epoch: 6| Step: 2
Training loss: 0.4469289183616638
Validation loss: 1.927334672661238

Epoch: 6| Step: 3
Training loss: 0.3131521940231323
Validation loss: 1.8877803048779886

Epoch: 6| Step: 4
Training loss: 0.3189742863178253
Validation loss: 1.9195741453478414

Epoch: 6| Step: 5
Training loss: 0.4255524277687073
Validation loss: 1.8771139088497366

Epoch: 6| Step: 6
Training loss: 0.8131933212280273
Validation loss: 1.896983551722701

Epoch: 6| Step: 7
Training loss: 0.19179873168468475
Validation loss: 1.8776500583976827

Epoch: 6| Step: 8
Training loss: 0.24579593539237976
Validation loss: 1.8902093184891569

Epoch: 6| Step: 9
Training loss: 0.22698482871055603
Validation loss: 1.9045802341994418

Epoch: 6| Step: 10
Training loss: 0.5297250747680664
Validation loss: 1.9290137419136621

Epoch: 6| Step: 11
Training loss: 0.19741907715797424
Validation loss: 1.9201030103109216

Epoch: 6| Step: 12
Training loss: 0.4379051625728607
Validation loss: 1.9689439624868414

Epoch: 6| Step: 13
Training loss: 0.6593129634857178
Validation loss: 1.9637896758253857

Epoch: 281| Step: 0
Training loss: 0.24925009906291962
Validation loss: 1.975815470500659

Epoch: 6| Step: 1
Training loss: 0.30442023277282715
Validation loss: 1.9427756776091873

Epoch: 6| Step: 2
Training loss: 0.5342180728912354
Validation loss: 1.9118069397505892

Epoch: 6| Step: 3
Training loss: 0.4982580542564392
Validation loss: 1.92405883214807

Epoch: 6| Step: 4
Training loss: 0.2286064326763153
Validation loss: 1.8907208955416115

Epoch: 6| Step: 5
Training loss: 0.3474345803260803
Validation loss: 1.891230055080947

Epoch: 6| Step: 6
Training loss: 0.27732720971107483
Validation loss: 1.8691914632756224

Epoch: 6| Step: 7
Training loss: 0.21388868987560272
Validation loss: 1.8762781068842898

Epoch: 6| Step: 8
Training loss: 0.31637656688690186
Validation loss: 1.8530399837801534

Epoch: 6| Step: 9
Training loss: 0.5117313861846924
Validation loss: 1.8766630798257806

Epoch: 6| Step: 10
Training loss: 0.3022097945213318
Validation loss: 1.863843253863755

Epoch: 6| Step: 11
Training loss: 0.555138111114502
Validation loss: 1.9217304773228143

Epoch: 6| Step: 12
Training loss: 0.6351031064987183
Validation loss: 1.8611802618990663

Epoch: 6| Step: 13
Training loss: 0.41601547598838806
Validation loss: 1.883056482961101

Epoch: 282| Step: 0
Training loss: 0.25086429715156555
Validation loss: 1.8789779011921217

Epoch: 6| Step: 1
Training loss: 0.29676568508148193
Validation loss: 1.8852028000739314

Epoch: 6| Step: 2
Training loss: 0.5147520899772644
Validation loss: 1.853057869019047

Epoch: 6| Step: 3
Training loss: 0.21559187769889832
Validation loss: 1.8521463794092978

Epoch: 6| Step: 4
Training loss: 0.26087692379951477
Validation loss: 1.8371499712749193

Epoch: 6| Step: 5
Training loss: 0.35134977102279663
Validation loss: 1.880846837515472

Epoch: 6| Step: 6
Training loss: 0.34168434143066406
Validation loss: 1.856735014146374

Epoch: 6| Step: 7
Training loss: 0.6897885203361511
Validation loss: 1.8875649718828098

Epoch: 6| Step: 8
Training loss: 0.333058625459671
Validation loss: 1.9295522833383212

Epoch: 6| Step: 9
Training loss: 0.5632949471473694
Validation loss: 1.9493095464603876

Epoch: 6| Step: 10
Training loss: 0.5811386704444885
Validation loss: 1.926567623692174

Epoch: 6| Step: 11
Training loss: 0.37540289759635925
Validation loss: 1.9460396676935174

Epoch: 6| Step: 12
Training loss: 0.4241677522659302
Validation loss: 1.9028798739115398

Epoch: 6| Step: 13
Training loss: 0.6871710419654846
Validation loss: 1.9295891484906595

Epoch: 283| Step: 0
Training loss: 0.5312219262123108
Validation loss: 1.9264651421577699

Epoch: 6| Step: 1
Training loss: 0.4899227023124695
Validation loss: 1.895487372593213

Epoch: 6| Step: 2
Training loss: 0.5550026297569275
Validation loss: 1.8888573236362909

Epoch: 6| Step: 3
Training loss: 0.4517878293991089
Validation loss: 1.8892232910279305

Epoch: 6| Step: 4
Training loss: 0.4168930649757385
Validation loss: 1.8648489508577573

Epoch: 6| Step: 5
Training loss: 0.32320114970207214
Validation loss: 1.8479128268457228

Epoch: 6| Step: 6
Training loss: 0.3063563108444214
Validation loss: 1.8787354230880737

Epoch: 6| Step: 7
Training loss: 0.5505741834640503
Validation loss: 1.8761973278496855

Epoch: 6| Step: 8
Training loss: 0.6854649782180786
Validation loss: 1.8590953337248934

Epoch: 6| Step: 9
Training loss: 0.33316725492477417
Validation loss: 1.9130923004560574

Epoch: 6| Step: 10
Training loss: 0.19984745979309082
Validation loss: 1.8822460174560547

Epoch: 6| Step: 11
Training loss: 0.19827181100845337
Validation loss: 1.8899099749903525

Epoch: 6| Step: 12
Training loss: 0.3352094292640686
Validation loss: 1.906857584112434

Epoch: 6| Step: 13
Training loss: 0.38215020298957825
Validation loss: 1.9086853483671784

Epoch: 284| Step: 0
Training loss: 0.3686637282371521
Validation loss: 1.8938833718658776

Epoch: 6| Step: 1
Training loss: 0.3026323914527893
Validation loss: 1.9121774229952084

Epoch: 6| Step: 2
Training loss: 0.3240220546722412
Validation loss: 1.9301181070266231

Epoch: 6| Step: 3
Training loss: 0.33384940028190613
Validation loss: 1.9350380666794316

Epoch: 6| Step: 4
Training loss: 0.518121600151062
Validation loss: 1.8989657919893983

Epoch: 6| Step: 5
Training loss: 0.23834869265556335
Validation loss: 1.8908930683648715

Epoch: 6| Step: 6
Training loss: 0.3248424232006073
Validation loss: 1.857277125440618

Epoch: 6| Step: 7
Training loss: 0.29251155257225037
Validation loss: 1.8460609630871845

Epoch: 6| Step: 8
Training loss: 0.48850440979003906
Validation loss: 1.8388806312314925

Epoch: 6| Step: 9
Training loss: 0.35951679944992065
Validation loss: 1.8740217608790244

Epoch: 6| Step: 10
Training loss: 0.26010170578956604
Validation loss: 1.8367728520465154

Epoch: 6| Step: 11
Training loss: 0.5984090566635132
Validation loss: 1.8280971639899797

Epoch: 6| Step: 12
Training loss: 0.3941766321659088
Validation loss: 1.8723001736466602

Epoch: 6| Step: 13
Training loss: 0.5680067539215088
Validation loss: 1.8414333071759952

Epoch: 285| Step: 0
Training loss: 0.4063833951950073
Validation loss: 1.8430036960109588

Epoch: 6| Step: 1
Training loss: 0.3464202880859375
Validation loss: 1.884838511866908

Epoch: 6| Step: 2
Training loss: 0.2450743317604065
Validation loss: 1.8592778418653755

Epoch: 6| Step: 3
Training loss: 0.27216410636901855
Validation loss: 1.8522055008078133

Epoch: 6| Step: 4
Training loss: 0.417052686214447
Validation loss: 1.8359597421461535

Epoch: 6| Step: 5
Training loss: 0.4580790400505066
Validation loss: 1.8529916437723304

Epoch: 6| Step: 6
Training loss: 0.7396859526634216
Validation loss: 1.8484524616631128

Epoch: 6| Step: 7
Training loss: 0.48805922269821167
Validation loss: 1.812334123478141

Epoch: 6| Step: 8
Training loss: 0.5080925226211548
Validation loss: 1.8247970816909627

Epoch: 6| Step: 9
Training loss: 0.28470638394355774
Validation loss: 1.8389484728536298

Epoch: 6| Step: 10
Training loss: 0.29583412408828735
Validation loss: 1.815034907351258

Epoch: 6| Step: 11
Training loss: 0.42417511343955994
Validation loss: 1.8568338937656854

Epoch: 6| Step: 12
Training loss: 0.45262008905410767
Validation loss: 1.8268406224507157

Epoch: 6| Step: 13
Training loss: 0.24029476940631866
Validation loss: 1.8549221510528235

Epoch: 286| Step: 0
Training loss: 0.7113440036773682
Validation loss: 1.8707097832874586

Epoch: 6| Step: 1
Training loss: 0.388285756111145
Validation loss: 1.845132585494749

Epoch: 6| Step: 2
Training loss: 0.35647910833358765
Validation loss: 1.8901069971822924

Epoch: 6| Step: 3
Training loss: 0.47015756368637085
Validation loss: 1.8696861741363362

Epoch: 6| Step: 4
Training loss: 0.2402743101119995
Validation loss: 1.84135764773174

Epoch: 6| Step: 5
Training loss: 0.206888347864151
Validation loss: 1.8500497956429758

Epoch: 6| Step: 6
Training loss: 0.46700263023376465
Validation loss: 1.8642473951462777

Epoch: 6| Step: 7
Training loss: 0.2591797709465027
Validation loss: 1.8632022219319497

Epoch: 6| Step: 8
Training loss: 0.45310065150260925
Validation loss: 1.8206552920802948

Epoch: 6| Step: 9
Training loss: 0.19893145561218262
Validation loss: 1.8805947406317598

Epoch: 6| Step: 10
Training loss: 0.4837832450866699
Validation loss: 1.787160886231289

Epoch: 6| Step: 11
Training loss: 0.3215658366680145
Validation loss: 1.7880744677717968

Epoch: 6| Step: 12
Training loss: 0.4368419051170349
Validation loss: 1.8455883533723894

Epoch: 6| Step: 13
Training loss: 0.419292151927948
Validation loss: 1.820145942831552

Epoch: 287| Step: 0
Training loss: 0.29059037566185
Validation loss: 1.8300270547149002

Epoch: 6| Step: 1
Training loss: 0.5401683449745178
Validation loss: 1.848048379344325

Epoch: 6| Step: 2
Training loss: 0.6625674366950989
Validation loss: 1.9304385467242169

Epoch: 6| Step: 3
Training loss: 0.3306863307952881
Validation loss: 1.9033601219936083

Epoch: 6| Step: 4
Training loss: 0.6100069284439087
Validation loss: 1.8877811790794454

Epoch: 6| Step: 5
Training loss: 0.45514020323753357
Validation loss: 1.8768773309646114

Epoch: 6| Step: 6
Training loss: 0.47703057527542114
Validation loss: 1.860465980345203

Epoch: 6| Step: 7
Training loss: 0.14253026247024536
Validation loss: 1.876761846644904

Epoch: 6| Step: 8
Training loss: 0.23598387837409973
Validation loss: 1.8484338073320286

Epoch: 6| Step: 9
Training loss: 0.2685970067977905
Validation loss: 1.813503634545111

Epoch: 6| Step: 10
Training loss: 0.42123857140541077
Validation loss: 1.8585541902049896

Epoch: 6| Step: 11
Training loss: 0.3885034918785095
Validation loss: 1.8561709215564113

Epoch: 6| Step: 12
Training loss: 0.2530631422996521
Validation loss: 1.8519207700606315

Epoch: 6| Step: 13
Training loss: 0.27349287271499634
Validation loss: 1.818182272295798

Epoch: 288| Step: 0
Training loss: 0.6625617742538452
Validation loss: 1.8839754058468727

Epoch: 6| Step: 1
Training loss: 0.40441465377807617
Validation loss: 1.8878563091319094

Epoch: 6| Step: 2
Training loss: 0.44691479206085205
Validation loss: 1.8956824400091683

Epoch: 6| Step: 3
Training loss: 0.4085835814476013
Validation loss: 1.8897760529671945

Epoch: 6| Step: 4
Training loss: 0.3029444217681885
Validation loss: 1.9021384959579797

Epoch: 6| Step: 5
Training loss: 0.31176286935806274
Validation loss: 1.903560209017928

Epoch: 6| Step: 6
Training loss: 0.3531319200992584
Validation loss: 1.8697504830616776

Epoch: 6| Step: 7
Training loss: 0.371229350566864
Validation loss: 1.8358086065579486

Epoch: 6| Step: 8
Training loss: 0.4699751138687134
Validation loss: 1.8555719339719383

Epoch: 6| Step: 9
Training loss: 0.44773709774017334
Validation loss: 1.8648477587648618

Epoch: 6| Step: 10
Training loss: 0.4868343770503998
Validation loss: 1.8903728172343264

Epoch: 6| Step: 11
Training loss: 0.27000412344932556
Validation loss: 1.873914409709233

Epoch: 6| Step: 12
Training loss: 0.196681410074234
Validation loss: 1.9041435872354815

Epoch: 6| Step: 13
Training loss: 0.4603670835494995
Validation loss: 1.9154726510406823

Epoch: 289| Step: 0
Training loss: 0.2476046234369278
Validation loss: 1.9164095591473322

Epoch: 6| Step: 1
Training loss: 0.5002409219741821
Validation loss: 1.9723036712215793

Epoch: 6| Step: 2
Training loss: 0.41015782952308655
Validation loss: 1.9139509970141995

Epoch: 6| Step: 3
Training loss: 0.2966865599155426
Validation loss: 1.8913615929183138

Epoch: 6| Step: 4
Training loss: 0.45027703046798706
Validation loss: 1.8494225240522815

Epoch: 6| Step: 5
Training loss: 0.4633216857910156
Validation loss: 1.8289370203530917

Epoch: 6| Step: 6
Training loss: 0.2413204461336136
Validation loss: 1.8012308459128104

Epoch: 6| Step: 7
Training loss: 0.7038908004760742
Validation loss: 1.8141416580446306

Epoch: 6| Step: 8
Training loss: 0.546463131904602
Validation loss: 1.7925565294040147

Epoch: 6| Step: 9
Training loss: 0.37647098302841187
Validation loss: 1.8278610731965752

Epoch: 6| Step: 10
Training loss: 0.41377660632133484
Validation loss: 1.8667094489579559

Epoch: 6| Step: 11
Training loss: 0.30762213468551636
Validation loss: 1.857417957757109

Epoch: 6| Step: 12
Training loss: 0.49757736921310425
Validation loss: 1.9052109654231737

Epoch: 6| Step: 13
Training loss: 0.374958872795105
Validation loss: 1.9241553442452544

Epoch: 290| Step: 0
Training loss: 0.3540123701095581
Validation loss: 1.955150951621353

Epoch: 6| Step: 1
Training loss: 0.24976593255996704
Validation loss: 1.9503933704027565

Epoch: 6| Step: 2
Training loss: 0.6008323431015015
Validation loss: 1.9242258020626601

Epoch: 6| Step: 3
Training loss: 0.33327460289001465
Validation loss: 1.9152723909706197

Epoch: 6| Step: 4
Training loss: 0.22203466296195984
Validation loss: 1.909337858999929

Epoch: 6| Step: 5
Training loss: 0.32367265224456787
Validation loss: 1.8742155644201464

Epoch: 6| Step: 6
Training loss: 0.46825289726257324
Validation loss: 1.839073618253072

Epoch: 6| Step: 7
Training loss: 0.3444879651069641
Validation loss: 1.8198545338005148

Epoch: 6| Step: 8
Training loss: 0.38740241527557373
Validation loss: 1.8319755625981156

Epoch: 6| Step: 9
Training loss: 0.7613169550895691
Validation loss: 1.858222169260825

Epoch: 6| Step: 10
Training loss: 0.3228141963481903
Validation loss: 1.8363926513220674

Epoch: 6| Step: 11
Training loss: 0.42479273676872253
Validation loss: 1.8754396412962226

Epoch: 6| Step: 12
Training loss: 0.21956050395965576
Validation loss: 1.9299611365923317

Epoch: 6| Step: 13
Training loss: 0.18752676248550415
Validation loss: 1.9087041962531306

Epoch: 291| Step: 0
Training loss: 0.3621433675289154
Validation loss: 1.9402126932656893

Epoch: 6| Step: 1
Training loss: 0.31174400448799133
Validation loss: 1.9408182495383806

Epoch: 6| Step: 2
Training loss: 0.2446855902671814
Validation loss: 1.9323738018671672

Epoch: 6| Step: 3
Training loss: 0.3159742057323456
Validation loss: 1.9186628595475228

Epoch: 6| Step: 4
Training loss: 0.7098313570022583
Validation loss: 1.8987319482270109

Epoch: 6| Step: 5
Training loss: 0.2727377712726593
Validation loss: 1.92067628265709

Epoch: 6| Step: 6
Training loss: 0.3870389461517334
Validation loss: 1.9128549086150302

Epoch: 6| Step: 7
Training loss: 0.3757290542125702
Validation loss: 1.9297030023349229

Epoch: 6| Step: 8
Training loss: 0.47371456027030945
Validation loss: 1.8643593070327595

Epoch: 6| Step: 9
Training loss: 0.3545491695404053
Validation loss: 1.8536629010272283

Epoch: 6| Step: 10
Training loss: 0.182772696018219
Validation loss: 1.8234205694608792

Epoch: 6| Step: 11
Training loss: 0.2952064871788025
Validation loss: 1.8339191995641237

Epoch: 6| Step: 12
Training loss: 0.3491969704627991
Validation loss: 1.803623225099297

Epoch: 6| Step: 13
Training loss: 0.2801998555660248
Validation loss: 1.8455899428295832

Epoch: 292| Step: 0
Training loss: 0.239668071269989
Validation loss: 1.8323227974676317

Epoch: 6| Step: 1
Training loss: 0.7159528732299805
Validation loss: 1.820272732806462

Epoch: 6| Step: 2
Training loss: 0.268283486366272
Validation loss: 1.8094386259714763

Epoch: 6| Step: 3
Training loss: 0.20693594217300415
Validation loss: 1.8115181307638846

Epoch: 6| Step: 4
Training loss: 0.36848634481430054
Validation loss: 1.8156845338882939

Epoch: 6| Step: 5
Training loss: 0.6363030672073364
Validation loss: 1.8714196630703506

Epoch: 6| Step: 6
Training loss: 0.30713406205177307
Validation loss: 1.876093360685533

Epoch: 6| Step: 7
Training loss: 0.24836327135562897
Validation loss: 1.8895044275509414

Epoch: 6| Step: 8
Training loss: 0.28403809666633606
Validation loss: 1.8905814463092434

Epoch: 6| Step: 9
Training loss: 0.3186326026916504
Validation loss: 1.9119008112979192

Epoch: 6| Step: 10
Training loss: 0.23797035217285156
Validation loss: 1.8905544652733752

Epoch: 6| Step: 11
Training loss: 0.334672749042511
Validation loss: 1.8434596997435375

Epoch: 6| Step: 12
Training loss: 0.42746609449386597
Validation loss: 1.8475219511216687

Epoch: 6| Step: 13
Training loss: 0.28476566076278687
Validation loss: 1.8256776627673899

Epoch: 293| Step: 0
Training loss: 0.37380602955818176
Validation loss: 1.835754995704979

Epoch: 6| Step: 1
Training loss: 0.3644883632659912
Validation loss: 1.8505761725928194

Epoch: 6| Step: 2
Training loss: 0.7247176766395569
Validation loss: 1.8089420756986063

Epoch: 6| Step: 3
Training loss: 0.2847285866737366
Validation loss: 1.8102350119621522

Epoch: 6| Step: 4
Training loss: 0.2597503960132599
Validation loss: 1.834223170434275

Epoch: 6| Step: 5
Training loss: 0.3630785346031189
Validation loss: 1.8005016798614173

Epoch: 6| Step: 6
Training loss: 0.2451770156621933
Validation loss: 1.8457693092284664

Epoch: 6| Step: 7
Training loss: 0.3410356640815735
Validation loss: 1.8359732281777166

Epoch: 6| Step: 8
Training loss: 0.14882338047027588
Validation loss: 1.886273202075753

Epoch: 6| Step: 9
Training loss: 0.22321821749210358
Validation loss: 1.9006599854397517

Epoch: 6| Step: 10
Training loss: 0.25150245428085327
Validation loss: 1.910564632825954

Epoch: 6| Step: 11
Training loss: 0.42215508222579956
Validation loss: 1.9284523917782692

Epoch: 6| Step: 12
Training loss: 0.3346867859363556
Validation loss: 1.899857505675285

Epoch: 6| Step: 13
Training loss: 0.965936005115509
Validation loss: 1.92632080406271

Epoch: 294| Step: 0
Training loss: 0.33571499586105347
Validation loss: 1.9139285369585919

Epoch: 6| Step: 1
Training loss: 0.25952744483947754
Validation loss: 1.91044843581415

Epoch: 6| Step: 2
Training loss: 0.7772291898727417
Validation loss: 1.9287226309058487

Epoch: 6| Step: 3
Training loss: 0.3264327943325043
Validation loss: 1.8823362652973463

Epoch: 6| Step: 4
Training loss: 0.2430148869752884
Validation loss: 1.8676775193983508

Epoch: 6| Step: 5
Training loss: 0.39520263671875
Validation loss: 1.8890929888653498

Epoch: 6| Step: 6
Training loss: 0.30881503224372864
Validation loss: 1.8808205871171848

Epoch: 6| Step: 7
Training loss: 0.35029321908950806
Validation loss: 1.9042066271587084

Epoch: 6| Step: 8
Training loss: 0.23290547728538513
Validation loss: 1.8786446189367643

Epoch: 6| Step: 9
Training loss: 0.1904275119304657
Validation loss: 1.878772102376466

Epoch: 6| Step: 10
Training loss: 0.5358330607414246
Validation loss: 1.8712946266256354

Epoch: 6| Step: 11
Training loss: 0.25402137637138367
Validation loss: 1.8222821104911067

Epoch: 6| Step: 12
Training loss: 0.479931116104126
Validation loss: 1.8730925744579685

Epoch: 6| Step: 13
Training loss: 0.22104932367801666
Validation loss: 1.8623150074353783

Epoch: 295| Step: 0
Training loss: 0.25611698627471924
Validation loss: 1.9101979476149364

Epoch: 6| Step: 1
Training loss: 0.3580789566040039
Validation loss: 1.9240518795546664

Epoch: 6| Step: 2
Training loss: 0.4625135064125061
Validation loss: 1.947574802624282

Epoch: 6| Step: 3
Training loss: 0.3480384945869446
Validation loss: 1.9488835821869552

Epoch: 6| Step: 4
Training loss: 0.2426016628742218
Validation loss: 1.9027144678177372

Epoch: 6| Step: 5
Training loss: 0.25152283906936646
Validation loss: 1.8647966025978007

Epoch: 6| Step: 6
Training loss: 0.4634647071361542
Validation loss: 1.9200682998985372

Epoch: 6| Step: 7
Training loss: 0.4426867663860321
Validation loss: 1.8711393405032415

Epoch: 6| Step: 8
Training loss: 0.6967417001724243
Validation loss: 1.8376088244940645

Epoch: 6| Step: 9
Training loss: 0.7591328620910645
Validation loss: 1.850395679473877

Epoch: 6| Step: 10
Training loss: 0.4324514865875244
Validation loss: 1.860809826081799

Epoch: 6| Step: 11
Training loss: 0.3115987777709961
Validation loss: 1.8370261666595296

Epoch: 6| Step: 12
Training loss: 0.4116668105125427
Validation loss: 1.8431855414503364

Epoch: 6| Step: 13
Training loss: 0.10861387103796005
Validation loss: 1.8890249934247745

Epoch: 296| Step: 0
Training loss: 0.37605082988739014
Validation loss: 1.8922741387480049

Epoch: 6| Step: 1
Training loss: 0.4168166518211365
Validation loss: 1.9394224689852806

Epoch: 6| Step: 2
Training loss: 0.3974023461341858
Validation loss: 1.9426546071165351

Epoch: 6| Step: 3
Training loss: 0.5019208192825317
Validation loss: 1.9344120538362892

Epoch: 6| Step: 4
Training loss: 0.5527327060699463
Validation loss: 1.95068440001498

Epoch: 6| Step: 5
Training loss: 0.26578131318092346
Validation loss: 1.8843493038608181

Epoch: 6| Step: 6
Training loss: 0.3653198480606079
Validation loss: 1.900509734307566

Epoch: 6| Step: 7
Training loss: 0.5614796280860901
Validation loss: 1.8914708809186054

Epoch: 6| Step: 8
Training loss: 0.19957636296749115
Validation loss: 1.8365816429097166

Epoch: 6| Step: 9
Training loss: 0.2736555337905884
Validation loss: 1.8464589016411894

Epoch: 6| Step: 10
Training loss: 0.27494797110557556
Validation loss: 1.8285098409139982

Epoch: 6| Step: 11
Training loss: 0.4897223711013794
Validation loss: 1.821240698137591

Epoch: 6| Step: 12
Training loss: 0.3431217074394226
Validation loss: 1.8555054690248223

Epoch: 6| Step: 13
Training loss: 0.45818689465522766
Validation loss: 1.8258582943229265

Epoch: 297| Step: 0
Training loss: 0.2789466381072998
Validation loss: 1.860006441352188

Epoch: 6| Step: 1
Training loss: 0.2492431104183197
Validation loss: 1.886804373033585

Epoch: 6| Step: 2
Training loss: 0.3375842869281769
Validation loss: 1.899672439021449

Epoch: 6| Step: 3
Training loss: 0.27673855423927307
Validation loss: 1.894169412633424

Epoch: 6| Step: 4
Training loss: 0.3371617794036865
Validation loss: 1.9153456995564122

Epoch: 6| Step: 5
Training loss: 0.19440129399299622
Validation loss: 1.919241464266213

Epoch: 6| Step: 6
Training loss: 0.5671961903572083
Validation loss: 1.9098246405201573

Epoch: 6| Step: 7
Training loss: 0.24955597519874573
Validation loss: 1.9119504164623957

Epoch: 6| Step: 8
Training loss: 0.21335896849632263
Validation loss: 1.9402251781955842

Epoch: 6| Step: 9
Training loss: 0.45852553844451904
Validation loss: 1.967742112375075

Epoch: 6| Step: 10
Training loss: 0.41919228434562683
Validation loss: 1.9017827639015772

Epoch: 6| Step: 11
Training loss: 0.2878149747848511
Validation loss: 1.9173662149777977

Epoch: 6| Step: 12
Training loss: 0.7244446277618408
Validation loss: 1.856708465083953

Epoch: 6| Step: 13
Training loss: 0.44971567392349243
Validation loss: 1.8200817249154533

Epoch: 298| Step: 0
Training loss: 0.3333459496498108
Validation loss: 1.8391307297573294

Epoch: 6| Step: 1
Training loss: 0.3217511475086212
Validation loss: 1.8176903852852442

Epoch: 6| Step: 2
Training loss: 0.2535896301269531
Validation loss: 1.8189480214990594

Epoch: 6| Step: 3
Training loss: 0.4215216636657715
Validation loss: 1.8083789963876047

Epoch: 6| Step: 4
Training loss: 0.3267408013343811
Validation loss: 1.799272188576319

Epoch: 6| Step: 5
Training loss: 0.6945092678070068
Validation loss: 1.7683674584152878

Epoch: 6| Step: 6
Training loss: 0.28345173597335815
Validation loss: 1.7904518842697144

Epoch: 6| Step: 7
Training loss: 0.3801332116127014
Validation loss: 1.805486245821881

Epoch: 6| Step: 8
Training loss: 0.26588791608810425
Validation loss: 1.8765205939610798

Epoch: 6| Step: 9
Training loss: 0.3922169804573059
Validation loss: 1.8783894867025397

Epoch: 6| Step: 10
Training loss: 0.43584728240966797
Validation loss: 1.9117958263684345

Epoch: 6| Step: 11
Training loss: 0.23922497034072876
Validation loss: 1.9525834629612584

Epoch: 6| Step: 12
Training loss: 0.42569592595100403
Validation loss: 1.997750646324568

Epoch: 6| Step: 13
Training loss: 0.3927081227302551
Validation loss: 2.0131246312972038

Epoch: 299| Step: 0
Training loss: 0.4791806936264038
Validation loss: 2.000494836479105

Epoch: 6| Step: 1
Training loss: 0.3100559115409851
Validation loss: 1.9377307199662732

Epoch: 6| Step: 2
Training loss: 0.7220253944396973
Validation loss: 1.8972643562542495

Epoch: 6| Step: 3
Training loss: 0.407096803188324
Validation loss: 1.8281795311999578

Epoch: 6| Step: 4
Training loss: 0.382895290851593
Validation loss: 1.7800913908148324

Epoch: 6| Step: 5
Training loss: 0.28007781505584717
Validation loss: 1.8009530626317507

Epoch: 6| Step: 6
Training loss: 0.4866105914115906
Validation loss: 1.7890309620929021

Epoch: 6| Step: 7
Training loss: 0.37698298692703247
Validation loss: 1.8403122463533956

Epoch: 6| Step: 8
Training loss: 0.10421097278594971
Validation loss: 1.8249361245862898

Epoch: 6| Step: 9
Training loss: 0.35053354501724243
Validation loss: 1.8201681567776589

Epoch: 6| Step: 10
Training loss: 0.3417348563671112
Validation loss: 1.822239492529182

Epoch: 6| Step: 11
Training loss: 0.18534711003303528
Validation loss: 1.8341677419600948

Epoch: 6| Step: 12
Training loss: 0.19516386091709137
Validation loss: 1.8016326312095887

Epoch: 6| Step: 13
Training loss: 0.5274178385734558
Validation loss: 1.8565238239944621

Epoch: 300| Step: 0
Training loss: 0.22996041178703308
Validation loss: 1.8351322848309752

Epoch: 6| Step: 1
Training loss: 0.35168397426605225
Validation loss: 1.821340742931571

Epoch: 6| Step: 2
Training loss: 0.23536041378974915
Validation loss: 1.8267314716051983

Epoch: 6| Step: 3
Training loss: 0.2057419717311859
Validation loss: 1.838036407706558

Epoch: 6| Step: 4
Training loss: 0.5945215225219727
Validation loss: 1.8704669257645965

Epoch: 6| Step: 5
Training loss: 0.2066778540611267
Validation loss: 1.8540323447155695

Epoch: 6| Step: 6
Training loss: 0.37067508697509766
Validation loss: 1.8855843210733065

Epoch: 6| Step: 7
Training loss: 0.414389431476593
Validation loss: 1.8806623130716302

Epoch: 6| Step: 8
Training loss: 0.38538622856140137
Validation loss: 1.901666501516937

Epoch: 6| Step: 9
Training loss: 0.36556607484817505
Validation loss: 1.9035736873585691

Epoch: 6| Step: 10
Training loss: 0.3196643590927124
Validation loss: 1.887153620361

Epoch: 6| Step: 11
Training loss: 0.20177415013313293
Validation loss: 1.86726745482414

Epoch: 6| Step: 12
Training loss: 0.39849966764450073
Validation loss: 1.8475891915700768

Epoch: 6| Step: 13
Training loss: 0.27007511258125305
Validation loss: 1.8817677190226894

Epoch: 301| Step: 0
Training loss: 0.2690049409866333
Validation loss: 1.8046903225683397

Epoch: 6| Step: 1
Training loss: 0.5623857378959656
Validation loss: 1.8066515794364355

Epoch: 6| Step: 2
Training loss: 0.39335474371910095
Validation loss: 1.808249230025917

Epoch: 6| Step: 3
Training loss: 0.30818241834640503
Validation loss: 1.7934032204330608

Epoch: 6| Step: 4
Training loss: 0.259788453578949
Validation loss: 1.7992835903680453

Epoch: 6| Step: 5
Training loss: 0.3141244649887085
Validation loss: 1.8070815493983607

Epoch: 6| Step: 6
Training loss: 0.32223621010780334
Validation loss: 1.8169656004956973

Epoch: 6| Step: 7
Training loss: 0.4107632637023926
Validation loss: 1.863943928031511

Epoch: 6| Step: 8
Training loss: 0.22167927026748657
Validation loss: 1.8885808939574866

Epoch: 6| Step: 9
Training loss: 0.44905591011047363
Validation loss: 1.913508492131387

Epoch: 6| Step: 10
Training loss: 0.29195302724838257
Validation loss: 1.9313979379592403

Epoch: 6| Step: 11
Training loss: 0.19902940094470978
Validation loss: 1.9061035725378221

Epoch: 6| Step: 12
Training loss: 0.29548656940460205
Validation loss: 1.8897828914785897

Epoch: 6| Step: 13
Training loss: 0.7806556224822998
Validation loss: 1.8469059185315204

Epoch: 302| Step: 0
Training loss: 0.319347083568573
Validation loss: 1.8609350573632024

Epoch: 6| Step: 1
Training loss: 0.3318585753440857
Validation loss: 1.8705511246958086

Epoch: 6| Step: 2
Training loss: 0.3186824917793274
Validation loss: 1.8494491359238983

Epoch: 6| Step: 3
Training loss: 0.29803675413131714
Validation loss: 1.8284101537478867

Epoch: 6| Step: 4
Training loss: 0.3324589431285858
Validation loss: 1.823153898280154

Epoch: 6| Step: 5
Training loss: 0.25292640924453735
Validation loss: 1.8485505100219481

Epoch: 6| Step: 6
Training loss: 0.3040037751197815
Validation loss: 1.8428896281027025

Epoch: 6| Step: 7
Training loss: 0.23639436066150665
Validation loss: 1.8337556290370163

Epoch: 6| Step: 8
Training loss: 0.2617203891277313
Validation loss: 1.8413480097247708

Epoch: 6| Step: 9
Training loss: 0.3095410466194153
Validation loss: 1.8227850634564635

Epoch: 6| Step: 10
Training loss: 0.2662004828453064
Validation loss: 1.8522800258410874

Epoch: 6| Step: 11
Training loss: 0.7873901128768921
Validation loss: 1.8643206601501794

Epoch: 6| Step: 12
Training loss: 0.4205993115901947
Validation loss: 1.8467980994973132

Epoch: 6| Step: 13
Training loss: 0.4649832546710968
Validation loss: 1.8469244767260808

Epoch: 303| Step: 0
Training loss: 0.32154592871665955
Validation loss: 1.8051801073935725

Epoch: 6| Step: 1
Training loss: 0.38339823484420776
Validation loss: 1.7823560789067259

Epoch: 6| Step: 2
Training loss: 0.4196114242076874
Validation loss: 1.8163037966656428

Epoch: 6| Step: 3
Training loss: 0.44602370262145996
Validation loss: 1.822440544764201

Epoch: 6| Step: 4
Training loss: 0.30345261096954346
Validation loss: 1.8107386122467697

Epoch: 6| Step: 5
Training loss: 0.5433987379074097
Validation loss: 1.8370261961413967

Epoch: 6| Step: 6
Training loss: 0.41624653339385986
Validation loss: 1.8564384855249876

Epoch: 6| Step: 7
Training loss: 0.5285773277282715
Validation loss: 1.7948580352208947

Epoch: 6| Step: 8
Training loss: 0.28290873765945435
Validation loss: 1.8174036548983665

Epoch: 6| Step: 9
Training loss: 0.293127179145813
Validation loss: 1.8400930114971694

Epoch: 6| Step: 10
Training loss: 0.1989346742630005
Validation loss: 1.8452836851919852

Epoch: 6| Step: 11
Training loss: 0.23437929153442383
Validation loss: 1.847944826208135

Epoch: 6| Step: 12
Training loss: 0.2995750308036804
Validation loss: 1.8516843575303272

Epoch: 6| Step: 13
Training loss: 0.29986250400543213
Validation loss: 1.884807030359904

Epoch: 304| Step: 0
Training loss: 0.2745876610279083
Validation loss: 1.8954482604098577

Epoch: 6| Step: 1
Training loss: 0.2624613642692566
Validation loss: 1.8943356903650428

Epoch: 6| Step: 2
Training loss: 0.20228710770606995
Validation loss: 1.8888646120666175

Epoch: 6| Step: 3
Training loss: 0.21651147305965424
Validation loss: 1.9111490634179884

Epoch: 6| Step: 4
Training loss: 0.2938406467437744
Validation loss: 1.9401720749434603

Epoch: 6| Step: 5
Training loss: 0.23312364518642426
Validation loss: 1.9411758876615954

Epoch: 6| Step: 6
Training loss: 0.3470686674118042
Validation loss: 1.9428581127556421

Epoch: 6| Step: 7
Training loss: 0.3649718165397644
Validation loss: 1.928390137610897

Epoch: 6| Step: 8
Training loss: 0.7226648330688477
Validation loss: 1.8941454836117324

Epoch: 6| Step: 9
Training loss: 0.2469812035560608
Validation loss: 1.883095577198972

Epoch: 6| Step: 10
Training loss: 0.4295080304145813
Validation loss: 1.8274002498196018

Epoch: 6| Step: 11
Training loss: 0.22570857405662537
Validation loss: 1.7844245395352762

Epoch: 6| Step: 12
Training loss: 0.32829225063323975
Validation loss: 1.7801103463736914

Epoch: 6| Step: 13
Training loss: 0.27493900060653687
Validation loss: 1.8048950100457797

Epoch: 305| Step: 0
Training loss: 0.34862416982650757
Validation loss: 1.7863374179409397

Epoch: 6| Step: 1
Training loss: 0.5903923511505127
Validation loss: 1.8055428458798317

Epoch: 6| Step: 2
Training loss: 0.2797008752822876
Validation loss: 1.822575758862239

Epoch: 6| Step: 3
Training loss: 0.36261099576950073
Validation loss: 1.8383784153128182

Epoch: 6| Step: 4
Training loss: 0.3270992636680603
Validation loss: 1.8334482523702806

Epoch: 6| Step: 5
Training loss: 0.11521907150745392
Validation loss: 1.8222573341861847

Epoch: 6| Step: 6
Training loss: 0.2125854790210724
Validation loss: 1.8208353122075398

Epoch: 6| Step: 7
Training loss: 0.33431103825569153
Validation loss: 1.8468792541052705

Epoch: 6| Step: 8
Training loss: 0.4127348065376282
Validation loss: 1.7924471542399416

Epoch: 6| Step: 9
Training loss: 0.20879793167114258
Validation loss: 1.8110505111755864

Epoch: 6| Step: 10
Training loss: 0.36028197407722473
Validation loss: 1.8289863435170983

Epoch: 6| Step: 11
Training loss: 0.27781665325164795
Validation loss: 1.8205005750861218

Epoch: 6| Step: 12
Training loss: 0.3415699303150177
Validation loss: 1.8495519186860772

Epoch: 6| Step: 13
Training loss: 0.3342445194721222
Validation loss: 1.8142239291180846

Epoch: 306| Step: 0
Training loss: 0.4120672941207886
Validation loss: 1.7797380929352136

Epoch: 6| Step: 1
Training loss: 0.315706729888916
Validation loss: 1.7736898468386741

Epoch: 6| Step: 2
Training loss: 0.31097251176834106
Validation loss: 1.7855299390772337

Epoch: 6| Step: 3
Training loss: 0.20414960384368896
Validation loss: 1.7582594515174947

Epoch: 6| Step: 4
Training loss: 0.3567104637622833
Validation loss: 1.814337153588572

Epoch: 6| Step: 5
Training loss: 0.24284754693508148
Validation loss: 1.8430327087320306

Epoch: 6| Step: 6
Training loss: 0.20240212976932526
Validation loss: 1.8092243786781066

Epoch: 6| Step: 7
Training loss: 0.36441779136657715
Validation loss: 1.8544802242709744

Epoch: 6| Step: 8
Training loss: 0.507698118686676
Validation loss: 1.827607168946215

Epoch: 6| Step: 9
Training loss: 0.14509591460227966
Validation loss: 1.8264903035215152

Epoch: 6| Step: 10
Training loss: 0.32107558846473694
Validation loss: 1.8095219045557

Epoch: 6| Step: 11
Training loss: 0.2505466341972351
Validation loss: 1.847612621963665

Epoch: 6| Step: 12
Training loss: 0.22060611844062805
Validation loss: 1.8119069030207973

Epoch: 6| Step: 13
Training loss: 0.15922097861766815
Validation loss: 1.8347291254228162

Epoch: 307| Step: 0
Training loss: 0.19870544970035553
Validation loss: 1.7914510593619397

Epoch: 6| Step: 1
Training loss: 0.3120375871658325
Validation loss: 1.8146112747089838

Epoch: 6| Step: 2
Training loss: 0.6426976323127747
Validation loss: 1.8388310119669924

Epoch: 6| Step: 3
Training loss: 0.4275344908237457
Validation loss: 1.8535135484510852

Epoch: 6| Step: 4
Training loss: 0.47089147567749023
Validation loss: 1.8668226426647556

Epoch: 6| Step: 5
Training loss: 0.24933300912380219
Validation loss: 1.860705485907934

Epoch: 6| Step: 6
Training loss: 0.2901418209075928
Validation loss: 1.9159213714702155

Epoch: 6| Step: 7
Training loss: 0.1655326783657074
Validation loss: 1.8831667092538649

Epoch: 6| Step: 8
Training loss: 0.4304085969924927
Validation loss: 1.8945706249565206

Epoch: 6| Step: 9
Training loss: 0.2564850151538849
Validation loss: 1.8874807280878867

Epoch: 6| Step: 10
Training loss: 0.43721815943717957
Validation loss: 1.9043806317032024

Epoch: 6| Step: 11
Training loss: 0.39991435408592224
Validation loss: 1.9166419608618623

Epoch: 6| Step: 12
Training loss: 0.25380319356918335
Validation loss: 1.836709148140364

Epoch: 6| Step: 13
Training loss: 0.43879902362823486
Validation loss: 1.809232045245427

Epoch: 308| Step: 0
Training loss: 0.26072484254837036
Validation loss: 1.817868455763786

Epoch: 6| Step: 1
Training loss: 0.2851691246032715
Validation loss: 1.8114199792185137

Epoch: 6| Step: 2
Training loss: 0.31403300166130066
Validation loss: 1.7873566509574972

Epoch: 6| Step: 3
Training loss: 0.20862410962581635
Validation loss: 1.790770261518417

Epoch: 6| Step: 4
Training loss: 0.22741259634494781
Validation loss: 1.778991719727875

Epoch: 6| Step: 5
Training loss: 0.29604217410087585
Validation loss: 1.802428460890247

Epoch: 6| Step: 6
Training loss: 0.3296917974948883
Validation loss: 1.82810898493695

Epoch: 6| Step: 7
Training loss: 0.21485772728919983
Validation loss: 1.8478943852968113

Epoch: 6| Step: 8
Training loss: 0.3426373302936554
Validation loss: 1.8347425537724649

Epoch: 6| Step: 9
Training loss: 0.40696054697036743
Validation loss: 1.8289553132108463

Epoch: 6| Step: 10
Training loss: 0.15014970302581787
Validation loss: 1.8322255278146395

Epoch: 6| Step: 11
Training loss: 0.24047058820724487
Validation loss: 1.8409873131782777

Epoch: 6| Step: 12
Training loss: 0.6318691968917847
Validation loss: 1.826538831956925

Epoch: 6| Step: 13
Training loss: 0.43626123666763306
Validation loss: 1.809033586132911

Epoch: 309| Step: 0
Training loss: 0.3093593120574951
Validation loss: 1.823563124543877

Epoch: 6| Step: 1
Training loss: 0.28975582122802734
Validation loss: 1.7911229800152522

Epoch: 6| Step: 2
Training loss: 0.5556527376174927
Validation loss: 1.7681843465374363

Epoch: 6| Step: 3
Training loss: 0.25226545333862305
Validation loss: 1.7971865925737607

Epoch: 6| Step: 4
Training loss: 0.35312873125076294
Validation loss: 1.7588293270398212

Epoch: 6| Step: 5
Training loss: 0.41251784563064575
Validation loss: 1.7918446192177393

Epoch: 6| Step: 6
Training loss: 0.17283347249031067
Validation loss: 1.8276516314475768

Epoch: 6| Step: 7
Training loss: 0.2740935683250427
Validation loss: 1.8121091473487116

Epoch: 6| Step: 8
Training loss: 0.339183509349823
Validation loss: 1.7971286619863203

Epoch: 6| Step: 9
Training loss: 0.35209351778030396
Validation loss: 1.8380625094136884

Epoch: 6| Step: 10
Training loss: 0.2277308702468872
Validation loss: 1.8853024526308941

Epoch: 6| Step: 11
Training loss: 0.4008544683456421
Validation loss: 1.9099116030559744

Epoch: 6| Step: 12
Training loss: 0.3564349114894867
Validation loss: 1.9526873532161917

Epoch: 6| Step: 13
Training loss: 0.4614604711532593
Validation loss: 1.9559559411900018

Epoch: 310| Step: 0
Training loss: 0.32705119252204895
Validation loss: 1.9495847199552803

Epoch: 6| Step: 1
Training loss: 0.2256782054901123
Validation loss: 1.8963883025671846

Epoch: 6| Step: 2
Training loss: 0.2964170575141907
Validation loss: 1.8844603851277342

Epoch: 6| Step: 3
Training loss: 0.19107761979103088
Validation loss: 1.890257877047344

Epoch: 6| Step: 4
Training loss: 0.3402504324913025
Validation loss: 1.8336145518928446

Epoch: 6| Step: 5
Training loss: 0.4947175979614258
Validation loss: 1.817421386318822

Epoch: 6| Step: 6
Training loss: 0.4890492260456085
Validation loss: 1.7978210615855392

Epoch: 6| Step: 7
Training loss: 0.25510138273239136
Validation loss: 1.7804283365126579

Epoch: 6| Step: 8
Training loss: 0.4699419438838959
Validation loss: 1.7566674742647397

Epoch: 6| Step: 9
Training loss: 0.232447549700737
Validation loss: 1.8165561934953094

Epoch: 6| Step: 10
Training loss: 0.36215534806251526
Validation loss: 1.8498805863882906

Epoch: 6| Step: 11
Training loss: 0.5112768411636353
Validation loss: 1.8726685559877785

Epoch: 6| Step: 12
Training loss: 0.31858357787132263
Validation loss: 1.9142086018798172

Epoch: 6| Step: 13
Training loss: 0.16633068025112152
Validation loss: 1.8760148299637662

Epoch: 311| Step: 0
Training loss: 0.6689121127128601
Validation loss: 1.8829334012923702

Epoch: 6| Step: 1
Training loss: 0.3059632182121277
Validation loss: 1.914485244340794

Epoch: 6| Step: 2
Training loss: 0.232928067445755
Validation loss: 1.9097445895594936

Epoch: 6| Step: 3
Training loss: 0.30884140729904175
Validation loss: 1.9566683397498181

Epoch: 6| Step: 4
Training loss: 0.2577757239341736
Validation loss: 1.9385266227106894

Epoch: 6| Step: 5
Training loss: 0.2645057737827301
Validation loss: 1.965800639121763

Epoch: 6| Step: 6
Training loss: 0.3722885847091675
Validation loss: 1.8954816813110023

Epoch: 6| Step: 7
Training loss: 0.3593343496322632
Validation loss: 1.84660550086729

Epoch: 6| Step: 8
Training loss: 0.1916915774345398
Validation loss: 1.8544279990657684

Epoch: 6| Step: 9
Training loss: 0.31523680686950684
Validation loss: 1.8402632167262416

Epoch: 6| Step: 10
Training loss: 0.2194526046514511
Validation loss: 1.8004866569272933

Epoch: 6| Step: 11
Training loss: 0.46263742446899414
Validation loss: 1.8091935496176443

Epoch: 6| Step: 12
Training loss: 0.2590098977088928
Validation loss: 1.7830294088650775

Epoch: 6| Step: 13
Training loss: 0.30073216557502747
Validation loss: 1.8028658154190227

Epoch: 312| Step: 0
Training loss: 0.3734143376350403
Validation loss: 1.8169440351506716

Epoch: 6| Step: 1
Training loss: 0.46222203969955444
Validation loss: 1.8095737708512174

Epoch: 6| Step: 2
Training loss: 0.18656334280967712
Validation loss: 1.8158881382275653

Epoch: 6| Step: 3
Training loss: 0.3305726945400238
Validation loss: 1.832752038073796

Epoch: 6| Step: 4
Training loss: 0.23323214054107666
Validation loss: 1.8266629711274178

Epoch: 6| Step: 5
Training loss: 0.17905190587043762
Validation loss: 1.8187962526916175

Epoch: 6| Step: 6
Training loss: 0.24670828878879547
Validation loss: 1.8066608931428643

Epoch: 6| Step: 7
Training loss: 0.23861365020275116
Validation loss: 1.8379251021210865

Epoch: 6| Step: 8
Training loss: 0.29807955026626587
Validation loss: 1.91407912008224

Epoch: 6| Step: 9
Training loss: 0.2823922336101532
Validation loss: 1.8960972729549612

Epoch: 6| Step: 10
Training loss: 0.2162432074546814
Validation loss: 1.9070030066274828

Epoch: 6| Step: 11
Training loss: 0.6564429402351379
Validation loss: 1.8973947148169241

Epoch: 6| Step: 12
Training loss: 0.1259460747241974
Validation loss: 1.89452729686614

Epoch: 6| Step: 13
Training loss: 0.2386554628610611
Validation loss: 1.8969885559492214

Epoch: 313| Step: 0
Training loss: 0.5287230610847473
Validation loss: 1.91710542350687

Epoch: 6| Step: 1
Training loss: 0.38961607217788696
Validation loss: 1.964710517596173

Epoch: 6| Step: 2
Training loss: 0.2899285554885864
Validation loss: 1.9269650469544113

Epoch: 6| Step: 3
Training loss: 0.4854345917701721
Validation loss: 1.937856863903743

Epoch: 6| Step: 4
Training loss: 0.33418843150138855
Validation loss: 1.9399054152991182

Epoch: 6| Step: 5
Training loss: 0.17706091701984406
Validation loss: 1.8636435411309684

Epoch: 6| Step: 6
Training loss: 0.2599726617336273
Validation loss: 1.8240758654891804

Epoch: 6| Step: 7
Training loss: 0.2681666612625122
Validation loss: 1.8292154060897006

Epoch: 6| Step: 8
Training loss: 0.36574673652648926
Validation loss: 1.818657664842503

Epoch: 6| Step: 9
Training loss: 0.2992897927761078
Validation loss: 1.8223139291168542

Epoch: 6| Step: 10
Training loss: 0.5930213928222656
Validation loss: 1.7933075069099345

Epoch: 6| Step: 11
Training loss: 0.23093751072883606
Validation loss: 1.7890246683551418

Epoch: 6| Step: 12
Training loss: 0.281170129776001
Validation loss: 1.8237123489379883

Epoch: 6| Step: 13
Training loss: 0.3293565511703491
Validation loss: 1.8406391105344218

Epoch: 314| Step: 0
Training loss: 0.27150341868400574
Validation loss: 1.882186182083622

Epoch: 6| Step: 1
Training loss: 0.37581008672714233
Validation loss: 1.92415794890414

Epoch: 6| Step: 2
Training loss: 0.25470954179763794
Validation loss: 1.91240615998545

Epoch: 6| Step: 3
Training loss: 0.31625285744667053
Validation loss: 1.9246186107717536

Epoch: 6| Step: 4
Training loss: 0.2528137266635895
Validation loss: 1.8794408152180333

Epoch: 6| Step: 5
Training loss: 0.2562636733055115
Validation loss: 1.9141049154343144

Epoch: 6| Step: 6
Training loss: 0.34372514486312866
Validation loss: 1.8673484363863546

Epoch: 6| Step: 7
Training loss: 0.24791297316551208
Validation loss: 1.8310102916532947

Epoch: 6| Step: 8
Training loss: 0.16721028089523315
Validation loss: 1.815190689538115

Epoch: 6| Step: 9
Training loss: 0.31691253185272217
Validation loss: 1.809623210660873

Epoch: 6| Step: 10
Training loss: 0.5808033347129822
Validation loss: 1.8114778431512977

Epoch: 6| Step: 11
Training loss: 0.30370813608169556
Validation loss: 1.7865957829260057

Epoch: 6| Step: 12
Training loss: 0.2961001694202423
Validation loss: 1.8282325690792454

Epoch: 6| Step: 13
Training loss: 0.3389767110347748
Validation loss: 1.8132969807553034

Epoch: 315| Step: 0
Training loss: 0.2807464003562927
Validation loss: 1.8459809646811536

Epoch: 6| Step: 1
Training loss: 0.16436085104942322
Validation loss: 1.8682181399355653

Epoch: 6| Step: 2
Training loss: 0.364963561296463
Validation loss: 1.866407666155087

Epoch: 6| Step: 3
Training loss: 0.2061692178249359
Validation loss: 1.896505198171062

Epoch: 6| Step: 4
Training loss: 0.27232444286346436
Validation loss: 1.8917620540947042

Epoch: 6| Step: 5
Training loss: 0.18246930837631226
Validation loss: 1.9299889277386408

Epoch: 6| Step: 6
Training loss: 0.35051512718200684
Validation loss: 1.8815037063373032

Epoch: 6| Step: 7
Training loss: 0.2654578387737274
Validation loss: 1.8957947402872064

Epoch: 6| Step: 8
Training loss: 0.2573370933532715
Validation loss: 1.9087629292600898

Epoch: 6| Step: 9
Training loss: 0.258916437625885
Validation loss: 1.854045150100544

Epoch: 6| Step: 10
Training loss: 0.5424354076385498
Validation loss: 1.8621604673324093

Epoch: 6| Step: 11
Training loss: 0.36896923184394836
Validation loss: 1.85874044382444

Epoch: 6| Step: 12
Training loss: 0.280270516872406
Validation loss: 1.8679662160975958

Epoch: 6| Step: 13
Training loss: 0.4272083640098572
Validation loss: 1.901021880488242

Epoch: 316| Step: 0
Training loss: 0.3359578251838684
Validation loss: 1.8618144732649609

Epoch: 6| Step: 1
Training loss: 0.3063313961029053
Validation loss: 1.859438104014243

Epoch: 6| Step: 2
Training loss: 0.24316205084323883
Validation loss: 1.8986709181980421

Epoch: 6| Step: 3
Training loss: 0.5598371624946594
Validation loss: 1.868817331970379

Epoch: 6| Step: 4
Training loss: 0.2951129376888275
Validation loss: 1.8460528504463933

Epoch: 6| Step: 5
Training loss: 0.3720729947090149
Validation loss: 1.8293668223965553

Epoch: 6| Step: 6
Training loss: 0.13508690893650055
Validation loss: 1.7824351685021513

Epoch: 6| Step: 7
Training loss: 0.3965895175933838
Validation loss: 1.7958429821075932

Epoch: 6| Step: 8
Training loss: 0.22531643509864807
Validation loss: 1.7921355873025873

Epoch: 6| Step: 9
Training loss: 0.1553979068994522
Validation loss: 1.8117606627043856

Epoch: 6| Step: 10
Training loss: 0.3677945137023926
Validation loss: 1.8213821495732954

Epoch: 6| Step: 11
Training loss: 0.22041863203048706
Validation loss: 1.8399994975777083

Epoch: 6| Step: 12
Training loss: 0.3213847577571869
Validation loss: 1.8730697503653906

Epoch: 6| Step: 13
Training loss: 0.17899218201637268
Validation loss: 1.8793956964246687

Epoch: 317| Step: 0
Training loss: 0.30262863636016846
Validation loss: 1.9289268908962127

Epoch: 6| Step: 1
Training loss: 0.32395634055137634
Validation loss: 1.9582094274541384

Epoch: 6| Step: 2
Training loss: 0.21953774988651276
Validation loss: 1.9448789063320364

Epoch: 6| Step: 3
Training loss: 0.1359037160873413
Validation loss: 1.9118743993902718

Epoch: 6| Step: 4
Training loss: 0.2916867733001709
Validation loss: 1.9265526058853313

Epoch: 6| Step: 5
Training loss: 0.25427258014678955
Validation loss: 1.885612513429375

Epoch: 6| Step: 6
Training loss: 0.23201683163642883
Validation loss: 1.8827161148030271

Epoch: 6| Step: 7
Training loss: 0.5226447582244873
Validation loss: 1.8519673629473614

Epoch: 6| Step: 8
Training loss: 0.2003391683101654
Validation loss: 1.838735713753649

Epoch: 6| Step: 9
Training loss: 0.1943669319152832
Validation loss: 1.8281730195527435

Epoch: 6| Step: 10
Training loss: 0.3461035192012787
Validation loss: 1.8132904344989407

Epoch: 6| Step: 11
Training loss: 0.19292497634887695
Validation loss: 1.8536918317117999

Epoch: 6| Step: 12
Training loss: 0.45915520191192627
Validation loss: 1.8705035050710042

Epoch: 6| Step: 13
Training loss: 0.19643272459506989
Validation loss: 1.8839658165490756

Epoch: 318| Step: 0
Training loss: 0.2617027759552002
Validation loss: 1.8594407586641208

Epoch: 6| Step: 1
Training loss: 0.273288369178772
Validation loss: 1.878365598699098

Epoch: 6| Step: 2
Training loss: 0.3309928774833679
Validation loss: 1.8870292991720221

Epoch: 6| Step: 3
Training loss: 0.2372921258211136
Validation loss: 1.881231722011361

Epoch: 6| Step: 4
Training loss: 0.38771599531173706
Validation loss: 1.8479046924139864

Epoch: 6| Step: 5
Training loss: 0.3133091926574707
Validation loss: 1.8911599971914803

Epoch: 6| Step: 6
Training loss: 0.3385053873062134
Validation loss: 1.8760001197937997

Epoch: 6| Step: 7
Training loss: 0.5228681564331055
Validation loss: 1.8770413065469393

Epoch: 6| Step: 8
Training loss: 0.11775898933410645
Validation loss: 1.884416469963648

Epoch: 6| Step: 9
Training loss: 0.2304648458957672
Validation loss: 1.933097190754388

Epoch: 6| Step: 10
Training loss: 0.2259455919265747
Validation loss: 1.878592227094917

Epoch: 6| Step: 11
Training loss: 0.2086835652589798
Validation loss: 1.8834435709061161

Epoch: 6| Step: 12
Training loss: 0.21366038918495178
Validation loss: 1.8671689341145177

Epoch: 6| Step: 13
Training loss: 0.39819902181625366
Validation loss: 1.8746184328550934

Epoch: 319| Step: 0
Training loss: 0.28162968158721924
Validation loss: 1.835614651762029

Epoch: 6| Step: 1
Training loss: 0.3316985070705414
Validation loss: 1.8393178883419241

Epoch: 6| Step: 2
Training loss: 0.21788084506988525
Validation loss: 1.8113488407545193

Epoch: 6| Step: 3
Training loss: 0.25869664549827576
Validation loss: 1.7938213309934061

Epoch: 6| Step: 4
Training loss: 0.24905706942081451
Validation loss: 1.855929333676574

Epoch: 6| Step: 5
Training loss: 0.26897743344306946
Validation loss: 1.8302266161928895

Epoch: 6| Step: 6
Training loss: 0.5704292058944702
Validation loss: 1.8947195904229277

Epoch: 6| Step: 7
Training loss: 0.4631512761116028
Validation loss: 1.848955076227906

Epoch: 6| Step: 8
Training loss: 0.28810274600982666
Validation loss: 1.8322781747387302

Epoch: 6| Step: 9
Training loss: 0.2973402142524719
Validation loss: 1.8553160108545774

Epoch: 6| Step: 10
Training loss: 0.370013028383255
Validation loss: 1.8645366443100797

Epoch: 6| Step: 11
Training loss: 0.2525554299354553
Validation loss: 1.846760412698151

Epoch: 6| Step: 12
Training loss: 0.38912391662597656
Validation loss: 1.8400884789805259

Epoch: 6| Step: 13
Training loss: 0.26408377289772034
Validation loss: 1.8378131543436358

Epoch: 320| Step: 0
Training loss: 0.3929153382778168
Validation loss: 1.8289102533812165

Epoch: 6| Step: 1
Training loss: 0.2652292549610138
Validation loss: 1.8073090481501755

Epoch: 6| Step: 2
Training loss: 0.2835438847541809
Validation loss: 1.8157959163829844

Epoch: 6| Step: 3
Training loss: 0.325867235660553
Validation loss: 1.8194155244417087

Epoch: 6| Step: 4
Training loss: 0.3051505982875824
Validation loss: 1.7969937478342364

Epoch: 6| Step: 5
Training loss: 0.3086203336715698
Validation loss: 1.8089922487094838

Epoch: 6| Step: 6
Training loss: 0.20695769786834717
Validation loss: 1.775874255805887

Epoch: 6| Step: 7
Training loss: 0.2801826000213623
Validation loss: 1.7880566940512708

Epoch: 6| Step: 8
Training loss: 0.3756159245967865
Validation loss: 1.772170005306121

Epoch: 6| Step: 9
Training loss: 0.25864508748054504
Validation loss: 1.7884035674474572

Epoch: 6| Step: 10
Training loss: 0.190693199634552
Validation loss: 1.7934468394966536

Epoch: 6| Step: 11
Training loss: 0.24841171503067017
Validation loss: 1.8213260648071126

Epoch: 6| Step: 12
Training loss: 0.2568970322608948
Validation loss: 1.8515779228620632

Epoch: 6| Step: 13
Training loss: 0.19547563791275024
Validation loss: 1.8795626266028291

Epoch: 321| Step: 0
Training loss: 0.17486615478992462
Validation loss: 1.914405898381305

Epoch: 6| Step: 1
Training loss: 0.2408437430858612
Validation loss: 1.9314852914502543

Epoch: 6| Step: 2
Training loss: 0.2747080326080322
Validation loss: 1.904848455100931

Epoch: 6| Step: 3
Training loss: 0.3295341432094574
Validation loss: 1.9055243692090433

Epoch: 6| Step: 4
Training loss: 0.2686253488063812
Validation loss: 1.9054334984030774

Epoch: 6| Step: 5
Training loss: 0.49768587946891785
Validation loss: 1.89351071593582

Epoch: 6| Step: 6
Training loss: 0.187215194106102
Validation loss: 1.9046751658121746

Epoch: 6| Step: 7
Training loss: 0.20752951502799988
Validation loss: 1.8755552602070633

Epoch: 6| Step: 8
Training loss: 0.27946382761001587
Validation loss: 1.8840465930200392

Epoch: 6| Step: 9
Training loss: 0.18974566459655762
Validation loss: 1.8533412397548716

Epoch: 6| Step: 10
Training loss: 0.13987302780151367
Validation loss: 1.8326669341774398

Epoch: 6| Step: 11
Training loss: 0.26896899938583374
Validation loss: 1.8755717200617636

Epoch: 6| Step: 12
Training loss: 0.3452298939228058
Validation loss: 1.883735320901358

Epoch: 6| Step: 13
Training loss: 0.24733802676200867
Validation loss: 1.8976335179421209

Epoch: 322| Step: 0
Training loss: 0.23442834615707397
Validation loss: 1.8968883227276545

Epoch: 6| Step: 1
Training loss: 0.23591460287570953
Validation loss: 1.9006878829771472

Epoch: 6| Step: 2
Training loss: 0.33181387186050415
Validation loss: 1.9115762761844102

Epoch: 6| Step: 3
Training loss: 0.12321490049362183
Validation loss: 1.8972199898894115

Epoch: 6| Step: 4
Training loss: 0.2571166455745697
Validation loss: 1.9283741084478234

Epoch: 6| Step: 5
Training loss: 0.30351027846336365
Validation loss: 1.9167158296031337

Epoch: 6| Step: 6
Training loss: 0.22805656492710114
Validation loss: 1.90277474798182

Epoch: 6| Step: 7
Training loss: 0.26580312848091125
Validation loss: 1.8873664794429656

Epoch: 6| Step: 8
Training loss: 0.3593055009841919
Validation loss: 1.8801803229957499

Epoch: 6| Step: 9
Training loss: 0.25001242756843567
Validation loss: 1.8785483273126746

Epoch: 6| Step: 10
Training loss: 0.5706629753112793
Validation loss: 1.8468271814366823

Epoch: 6| Step: 11
Training loss: 0.1996147632598877
Validation loss: 1.827867187479491

Epoch: 6| Step: 12
Training loss: 0.20823414623737335
Validation loss: 1.8382769118073166

Epoch: 6| Step: 13
Training loss: 0.0849548876285553
Validation loss: 1.8304589538164036

Epoch: 323| Step: 0
Training loss: 0.13589739799499512
Validation loss: 1.806817663613186

Epoch: 6| Step: 1
Training loss: 0.14403098821640015
Validation loss: 1.8000109105981805

Epoch: 6| Step: 2
Training loss: 0.3012215495109558
Validation loss: 1.8066388836470983

Epoch: 6| Step: 3
Training loss: 0.49594199657440186
Validation loss: 1.7745105656244422

Epoch: 6| Step: 4
Training loss: 0.23033064603805542
Validation loss: 1.823440965785775

Epoch: 6| Step: 5
Training loss: 0.18397736549377441
Validation loss: 1.8005295043350549

Epoch: 6| Step: 6
Training loss: 0.24194292724132538
Validation loss: 1.8349607529178742

Epoch: 6| Step: 7
Training loss: 0.2912046015262604
Validation loss: 1.8012557414270216

Epoch: 6| Step: 8
Training loss: 0.26980793476104736
Validation loss: 1.7864135208950247

Epoch: 6| Step: 9
Training loss: 0.15055257081985474
Validation loss: 1.8226612537137923

Epoch: 6| Step: 10
Training loss: 0.28354722261428833
Validation loss: 1.828650789235228

Epoch: 6| Step: 11
Training loss: 0.27856704592704773
Validation loss: 1.8362528111345024

Epoch: 6| Step: 12
Training loss: 0.2194153070449829
Validation loss: 1.8114114820316274

Epoch: 6| Step: 13
Training loss: 0.36903655529022217
Validation loss: 1.8421719945887083

Epoch: 324| Step: 0
Training loss: 0.342535138130188
Validation loss: 1.872079917179641

Epoch: 6| Step: 1
Training loss: 0.19221360981464386
Validation loss: 1.858449823112898

Epoch: 6| Step: 2
Training loss: 0.25383663177490234
Validation loss: 1.843987521304879

Epoch: 6| Step: 3
Training loss: 0.19402971863746643
Validation loss: 1.8549926306611748

Epoch: 6| Step: 4
Training loss: 0.47177669405937195
Validation loss: 1.8871510285203175

Epoch: 6| Step: 5
Training loss: 0.16537761688232422
Validation loss: 1.8685017439626879

Epoch: 6| Step: 6
Training loss: 0.13825783133506775
Validation loss: 1.884458036832912

Epoch: 6| Step: 7
Training loss: 0.23195454478263855
Validation loss: 1.8562758007357198

Epoch: 6| Step: 8
Training loss: 0.20558060705661774
Validation loss: 1.8809927022585304

Epoch: 6| Step: 9
Training loss: 0.19567981362342834
Validation loss: 1.8740989533803796

Epoch: 6| Step: 10
Training loss: 0.12674523890018463
Validation loss: 1.8656274477640789

Epoch: 6| Step: 11
Training loss: 0.35376277565956116
Validation loss: 1.8729929565101542

Epoch: 6| Step: 12
Training loss: 0.31298401951789856
Validation loss: 1.8752003087792346

Epoch: 6| Step: 13
Training loss: 0.19715499877929688
Validation loss: 1.8184076791168542

Epoch: 325| Step: 0
Training loss: 0.3303353190422058
Validation loss: 1.8407405089306574

Epoch: 6| Step: 1
Training loss: 0.3652762472629547
Validation loss: 1.8125792472593245

Epoch: 6| Step: 2
Training loss: 0.1938161551952362
Validation loss: 1.8360557607425156

Epoch: 6| Step: 3
Training loss: 0.19580622017383575
Validation loss: 1.8202590134836012

Epoch: 6| Step: 4
Training loss: 0.21359622478485107
Validation loss: 1.7947677912250641

Epoch: 6| Step: 5
Training loss: 0.2830098867416382
Validation loss: 1.8057641034485192

Epoch: 6| Step: 6
Training loss: 0.19814710319042206
Validation loss: 1.813882089430286

Epoch: 6| Step: 7
Training loss: 0.13789036870002747
Validation loss: 1.816571497148083

Epoch: 6| Step: 8
Training loss: 0.2490527629852295
Validation loss: 1.8400022368277273

Epoch: 6| Step: 9
Training loss: 0.3317725956439972
Validation loss: 1.8539410227088517

Epoch: 6| Step: 10
Training loss: 0.1624680459499359
Validation loss: 1.8712547658592142

Epoch: 6| Step: 11
Training loss: 0.4700569212436676
Validation loss: 1.898729278195289

Epoch: 6| Step: 12
Training loss: 0.2892594039440155
Validation loss: 1.8662525146238265

Epoch: 6| Step: 13
Training loss: 0.31801801919937134
Validation loss: 1.8650054700912968

Epoch: 326| Step: 0
Training loss: 0.22153204679489136
Validation loss: 1.8965515013664

Epoch: 6| Step: 1
Training loss: 0.18018808960914612
Validation loss: 1.898193000465311

Epoch: 6| Step: 2
Training loss: 0.5628575086593628
Validation loss: 1.885477053221836

Epoch: 6| Step: 3
Training loss: 0.2435101568698883
Validation loss: 1.8613602063989128

Epoch: 6| Step: 4
Training loss: 0.2800600528717041
Validation loss: 1.860398296386965

Epoch: 6| Step: 5
Training loss: 0.2366601973772049
Validation loss: 1.8235928050933345

Epoch: 6| Step: 6
Training loss: 0.26816678047180176
Validation loss: 1.7954945666815645

Epoch: 6| Step: 7
Training loss: 0.24468430876731873
Validation loss: 1.7696911237573112

Epoch: 6| Step: 8
Training loss: 0.2084251344203949
Validation loss: 1.8113150981164747

Epoch: 6| Step: 9
Training loss: 0.408879816532135
Validation loss: 1.7997602813987321

Epoch: 6| Step: 10
Training loss: 0.2532002925872803
Validation loss: 1.7914846904816166

Epoch: 6| Step: 11
Training loss: 0.24002686142921448
Validation loss: 1.8139828174344954

Epoch: 6| Step: 12
Training loss: 0.28541842103004456
Validation loss: 1.8330486512953235

Epoch: 6| Step: 13
Training loss: 0.5025642514228821
Validation loss: 1.9003040739285049

Epoch: 327| Step: 0
Training loss: 0.4865036606788635
Validation loss: 1.9105780688665246

Epoch: 6| Step: 1
Training loss: 0.31448981165885925
Validation loss: 1.9062606019358481

Epoch: 6| Step: 2
Training loss: 0.33956775069236755
Validation loss: 1.893482897871284

Epoch: 6| Step: 3
Training loss: 0.3421365022659302
Validation loss: 1.9020863566347348

Epoch: 6| Step: 4
Training loss: 0.2285241186618805
Validation loss: 1.8797268457310174

Epoch: 6| Step: 5
Training loss: 0.35011225938796997
Validation loss: 1.847238084321381

Epoch: 6| Step: 6
Training loss: 0.15714944899082184
Validation loss: 1.8649015144635273

Epoch: 6| Step: 7
Training loss: 0.24380436539649963
Validation loss: 1.8519418226775302

Epoch: 6| Step: 8
Training loss: 0.2818039655685425
Validation loss: 1.8469787720711

Epoch: 6| Step: 9
Training loss: 0.31996628642082214
Validation loss: 1.8393801989093903

Epoch: 6| Step: 10
Training loss: 0.3402806520462036
Validation loss: 1.8363276579046761

Epoch: 6| Step: 11
Training loss: 0.3264275789260864
Validation loss: 1.864319634693925

Epoch: 6| Step: 12
Training loss: 0.5325634479522705
Validation loss: 1.8456394774939424

Epoch: 6| Step: 13
Training loss: 0.2641361951828003
Validation loss: 1.8779791298732962

Epoch: 328| Step: 0
Training loss: 0.22812187671661377
Validation loss: 1.8921828193049277

Epoch: 6| Step: 1
Training loss: 0.18979299068450928
Validation loss: 1.870864019599012

Epoch: 6| Step: 2
Training loss: 0.32354336977005005
Validation loss: 1.8362502462120467

Epoch: 6| Step: 3
Training loss: 0.24933212995529175
Validation loss: 1.804919236449785

Epoch: 6| Step: 4
Training loss: 0.3141695559024811
Validation loss: 1.7681645167771207

Epoch: 6| Step: 5
Training loss: 0.28623640537261963
Validation loss: 1.7881231769438712

Epoch: 6| Step: 6
Training loss: 0.19912567734718323
Validation loss: 1.7795811481373285

Epoch: 6| Step: 7
Training loss: 0.2629753053188324
Validation loss: 1.7517478889034641

Epoch: 6| Step: 8
Training loss: 0.5796340703964233
Validation loss: 1.7787607075065694

Epoch: 6| Step: 9
Training loss: 0.25451868772506714
Validation loss: 1.7911447081514584

Epoch: 6| Step: 10
Training loss: 0.35232967138290405
Validation loss: 1.8039673989818943

Epoch: 6| Step: 11
Training loss: 0.3294826149940491
Validation loss: 1.8000547693621727

Epoch: 6| Step: 12
Training loss: 0.2634832561016083
Validation loss: 1.7981973745489632

Epoch: 6| Step: 13
Training loss: 0.3307455778121948
Validation loss: 1.829700436643375

Epoch: 329| Step: 0
Training loss: 0.17448940873146057
Validation loss: 1.8693167227570728

Epoch: 6| Step: 1
Training loss: 0.32735803723335266
Validation loss: 1.8868535513518958

Epoch: 6| Step: 2
Training loss: 0.1728534698486328
Validation loss: 1.9002472918520692

Epoch: 6| Step: 3
Training loss: 0.2732458710670471
Validation loss: 1.8506113047240882

Epoch: 6| Step: 4
Training loss: 0.3617522716522217
Validation loss: 1.8650946745308496

Epoch: 6| Step: 5
Training loss: 0.1212119609117508
Validation loss: 1.873030747136762

Epoch: 6| Step: 6
Training loss: 0.190692737698555
Validation loss: 1.8529190273695095

Epoch: 6| Step: 7
Training loss: 0.1764601171016693
Validation loss: 1.8800483365212717

Epoch: 6| Step: 8
Training loss: 0.15083032846450806
Validation loss: 1.8958419048657982

Epoch: 6| Step: 9
Training loss: 0.3714878559112549
Validation loss: 1.8882495305871452

Epoch: 6| Step: 10
Training loss: 0.4708271920681
Validation loss: 1.8613046241062943

Epoch: 6| Step: 11
Training loss: 0.19983233511447906
Validation loss: 1.8893108342283516

Epoch: 6| Step: 12
Training loss: 0.2399073839187622
Validation loss: 1.9041218911447833

Epoch: 6| Step: 13
Training loss: 0.8080878853797913
Validation loss: 1.857665688760819

Epoch: 330| Step: 0
Training loss: 0.18686656653881073
Validation loss: 1.9082516136989798

Epoch: 6| Step: 1
Training loss: 0.2165735363960266
Validation loss: 1.895050730756534

Epoch: 6| Step: 2
Training loss: 0.4612637758255005
Validation loss: 1.9015875426671838

Epoch: 6| Step: 3
Training loss: 0.2965044379234314
Validation loss: 1.8946423543396818

Epoch: 6| Step: 4
Training loss: 0.20194685459136963
Validation loss: 1.8636864487842848

Epoch: 6| Step: 5
Training loss: 0.109164759516716
Validation loss: 1.8674974672255977

Epoch: 6| Step: 6
Training loss: 0.3248932361602783
Validation loss: 1.8201711895645305

Epoch: 6| Step: 7
Training loss: 0.19833865761756897
Validation loss: 1.793971880789726

Epoch: 6| Step: 8
Training loss: 0.21142242848873138
Validation loss: 1.7868918154829292

Epoch: 6| Step: 9
Training loss: 0.5505304932594299
Validation loss: 1.7934371809805594

Epoch: 6| Step: 10
Training loss: 0.20143015682697296
Validation loss: 1.7997944303738174

Epoch: 6| Step: 11
Training loss: 0.1852322518825531
Validation loss: 1.7656012940150436

Epoch: 6| Step: 12
Training loss: 0.24890229105949402
Validation loss: 1.8115969832225511

Epoch: 6| Step: 13
Training loss: 0.1489366888999939
Validation loss: 1.8115851674028622

Epoch: 331| Step: 0
Training loss: 0.18739110231399536
Validation loss: 1.8060810976130988

Epoch: 6| Step: 1
Training loss: 0.17459295690059662
Validation loss: 1.8288351130741898

Epoch: 6| Step: 2
Training loss: 0.5796598792076111
Validation loss: 1.8585770822340442

Epoch: 6| Step: 3
Training loss: 0.31084975600242615
Validation loss: 1.831355232064442

Epoch: 6| Step: 4
Training loss: 0.24709197878837585
Validation loss: 1.8718612501698155

Epoch: 6| Step: 5
Training loss: 0.2635231018066406
Validation loss: 1.8715130866214793

Epoch: 6| Step: 6
Training loss: 0.3162943124771118
Validation loss: 1.863868454451202

Epoch: 6| Step: 7
Training loss: 0.1630391776561737
Validation loss: 1.8254932831692439

Epoch: 6| Step: 8
Training loss: 0.19037175178527832
Validation loss: 1.8282370592958184

Epoch: 6| Step: 9
Training loss: 0.26663917303085327
Validation loss: 1.8102299449264363

Epoch: 6| Step: 10
Training loss: 0.49132049083709717
Validation loss: 1.826394304152458

Epoch: 6| Step: 11
Training loss: 0.3348545730113983
Validation loss: 1.851728432921953

Epoch: 6| Step: 12
Training loss: 0.25505155324935913
Validation loss: 1.8113205509801065

Epoch: 6| Step: 13
Training loss: 0.08927422016859055
Validation loss: 1.848649460782287

Epoch: 332| Step: 0
Training loss: 0.47005388140678406
Validation loss: 1.844646898649072

Epoch: 6| Step: 1
Training loss: 0.09310629218816757
Validation loss: 1.8937141433838875

Epoch: 6| Step: 2
Training loss: 0.25932836532592773
Validation loss: 1.8789732494661886

Epoch: 6| Step: 3
Training loss: 0.21082723140716553
Validation loss: 1.8770250133288804

Epoch: 6| Step: 4
Training loss: 0.24786269664764404
Validation loss: 1.8711077244051042

Epoch: 6| Step: 5
Training loss: 0.24036075174808502
Validation loss: 1.8511126451594855

Epoch: 6| Step: 6
Training loss: 0.1513059288263321
Validation loss: 1.7786665808769964

Epoch: 6| Step: 7
Training loss: 0.1670655906200409
Validation loss: 1.8232750033819547

Epoch: 6| Step: 8
Training loss: 0.2663092613220215
Validation loss: 1.8162658861888352

Epoch: 6| Step: 9
Training loss: 0.21053408086299896
Validation loss: 1.7863330430881952

Epoch: 6| Step: 10
Training loss: 0.23283585906028748
Validation loss: 1.824528814643942

Epoch: 6| Step: 11
Training loss: 0.16535210609436035
Validation loss: 1.8073795303221671

Epoch: 6| Step: 12
Training loss: 0.365319162607193
Validation loss: 1.8071568448056456

Epoch: 6| Step: 13
Training loss: 0.3055771589279175
Validation loss: 1.8230998528900968

Epoch: 333| Step: 0
Training loss: 0.3032548725605011
Validation loss: 1.8797373540939823

Epoch: 6| Step: 1
Training loss: 0.24494309723377228
Validation loss: 1.9154711474654496

Epoch: 6| Step: 2
Training loss: 0.3525948226451874
Validation loss: 1.9217834934111564

Epoch: 6| Step: 3
Training loss: 0.3661268949508667
Validation loss: 1.9346856712013163

Epoch: 6| Step: 4
Training loss: 0.32662898302078247
Validation loss: 1.9016298145376227

Epoch: 6| Step: 5
Training loss: 0.23553931713104248
Validation loss: 1.8631307412219305

Epoch: 6| Step: 6
Training loss: 0.1597004532814026
Validation loss: 1.828199650010755

Epoch: 6| Step: 7
Training loss: 0.21535366773605347
Validation loss: 1.818590038566179

Epoch: 6| Step: 8
Training loss: 0.3871609568595886
Validation loss: 1.8018821029252903

Epoch: 6| Step: 9
Training loss: 0.13034802675247192
Validation loss: 1.7638725106434157

Epoch: 6| Step: 10
Training loss: 0.2516290843486786
Validation loss: 1.7788790695128902

Epoch: 6| Step: 11
Training loss: 0.23498442769050598
Validation loss: 1.8069747058294152

Epoch: 6| Step: 12
Training loss: 0.24488990008831024
Validation loss: 1.7772813612414944

Epoch: 6| Step: 13
Training loss: 0.3525567054748535
Validation loss: 1.8109667762633292

Epoch: 334| Step: 0
Training loss: 0.11165430396795273
Validation loss: 1.8082260213872439

Epoch: 6| Step: 1
Training loss: 0.17469140887260437
Validation loss: 1.7883756622191398

Epoch: 6| Step: 2
Training loss: 0.5603786706924438
Validation loss: 1.8153886154133787

Epoch: 6| Step: 3
Training loss: 0.2693519592285156
Validation loss: 1.8365272270735873

Epoch: 6| Step: 4
Training loss: 0.24339479207992554
Validation loss: 1.8369746592737013

Epoch: 6| Step: 5
Training loss: 0.3217298984527588
Validation loss: 1.8070452649106261

Epoch: 6| Step: 6
Training loss: 0.20119798183441162
Validation loss: 1.8227456461998723

Epoch: 6| Step: 7
Training loss: 0.18434971570968628
Validation loss: 1.8043115497917257

Epoch: 6| Step: 8
Training loss: 0.43326136469841003
Validation loss: 1.8008842301625076

Epoch: 6| Step: 9
Training loss: 0.33563268184661865
Validation loss: 1.7769847377654044

Epoch: 6| Step: 10
Training loss: 0.3042289614677429
Validation loss: 1.7688903436865857

Epoch: 6| Step: 11
Training loss: 0.125570148229599
Validation loss: 1.7798898271335069

Epoch: 6| Step: 12
Training loss: 0.11027004569768906
Validation loss: 1.8044775737229215

Epoch: 6| Step: 13
Training loss: 0.1620209813117981
Validation loss: 1.7885691350506199

Epoch: 335| Step: 0
Training loss: 0.26865240931510925
Validation loss: 1.76474396387736

Epoch: 6| Step: 1
Training loss: 0.20642395317554474
Validation loss: 1.7719365730080554

Epoch: 6| Step: 2
Training loss: 0.2106305956840515
Validation loss: 1.7536302766492289

Epoch: 6| Step: 3
Training loss: 0.31768497824668884
Validation loss: 1.7644926091676116

Epoch: 6| Step: 4
Training loss: 0.4707523584365845
Validation loss: 1.7811497411420267

Epoch: 6| Step: 5
Training loss: 0.15350857377052307
Validation loss: 1.7327005094097507

Epoch: 6| Step: 6
Training loss: 0.3839717209339142
Validation loss: 1.772226256708945

Epoch: 6| Step: 7
Training loss: 0.21996138989925385
Validation loss: 1.800187103209957

Epoch: 6| Step: 8
Training loss: 0.201072096824646
Validation loss: 1.8279732299107376

Epoch: 6| Step: 9
Training loss: 0.17864003777503967
Validation loss: 1.805743496905091

Epoch: 6| Step: 10
Training loss: 0.170612633228302
Validation loss: 1.820002773756622

Epoch: 6| Step: 11
Training loss: 0.20741917192935944
Validation loss: 1.852037892546705

Epoch: 6| Step: 12
Training loss: 0.1826867163181305
Validation loss: 1.7978872342776226

Epoch: 6| Step: 13
Training loss: 0.13106489181518555
Validation loss: 1.8084012795520086

Epoch: 336| Step: 0
Training loss: 0.2670309245586395
Validation loss: 1.8218356870835828

Epoch: 6| Step: 1
Training loss: 0.18939045071601868
Validation loss: 1.8293670056968607

Epoch: 6| Step: 2
Training loss: 0.23392772674560547
Validation loss: 1.8122267197537165

Epoch: 6| Step: 3
Training loss: 0.2201422154903412
Validation loss: 1.8181387596232916

Epoch: 6| Step: 4
Training loss: 0.26838183403015137
Validation loss: 1.8067368204875658

Epoch: 6| Step: 5
Training loss: 0.313180536031723
Validation loss: 1.810666234262528

Epoch: 6| Step: 6
Training loss: 0.17298968136310577
Validation loss: 1.8309688337387577

Epoch: 6| Step: 7
Training loss: 0.2640218138694763
Validation loss: 1.8326985566846785

Epoch: 6| Step: 8
Training loss: 0.43079614639282227
Validation loss: 1.8434626517757293

Epoch: 6| Step: 9
Training loss: 0.25798991322517395
Validation loss: 1.8814942144578504

Epoch: 6| Step: 10
Training loss: 0.19115836918354034
Validation loss: 1.873914735291594

Epoch: 6| Step: 11
Training loss: 0.16619658470153809
Validation loss: 1.853624859163838

Epoch: 6| Step: 12
Training loss: 0.1525251567363739
Validation loss: 1.8635025473051174

Epoch: 6| Step: 13
Training loss: 0.2927497327327728
Validation loss: 1.841789202023578

Epoch: 337| Step: 0
Training loss: 0.20909322798252106
Validation loss: 1.8142495257880098

Epoch: 6| Step: 1
Training loss: 0.22457268834114075
Validation loss: 1.80411506852796

Epoch: 6| Step: 2
Training loss: 0.191060870885849
Validation loss: 1.8198566795677267

Epoch: 6| Step: 3
Training loss: 0.2941155433654785
Validation loss: 1.8426474345627653

Epoch: 6| Step: 4
Training loss: 0.30471259355545044
Validation loss: 1.8445280610874135

Epoch: 6| Step: 5
Training loss: 0.30592989921569824
Validation loss: 1.8162807123635405

Epoch: 6| Step: 6
Training loss: 0.26804521679878235
Validation loss: 1.8280944247399606

Epoch: 6| Step: 7
Training loss: 0.21739113330841064
Validation loss: 1.8248722425071142

Epoch: 6| Step: 8
Training loss: 0.13160687685012817
Validation loss: 1.8612004403145082

Epoch: 6| Step: 9
Training loss: 0.5655123591423035
Validation loss: 1.896951606196742

Epoch: 6| Step: 10
Training loss: 0.3492092490196228
Validation loss: 1.902099686284219

Epoch: 6| Step: 11
Training loss: 0.20679649710655212
Validation loss: 1.8937826387343868

Epoch: 6| Step: 12
Training loss: 0.3245519995689392
Validation loss: 1.8566738302989672

Epoch: 6| Step: 13
Training loss: 0.12766531109809875
Validation loss: 1.8297893219096686

Epoch: 338| Step: 0
Training loss: 0.16741928458213806
Validation loss: 1.80284753025219

Epoch: 6| Step: 1
Training loss: 0.341518759727478
Validation loss: 1.8090942200794016

Epoch: 6| Step: 2
Training loss: 0.22441375255584717
Validation loss: 1.7987176461886334

Epoch: 6| Step: 3
Training loss: 0.26215726137161255
Validation loss: 1.797525111065116

Epoch: 6| Step: 4
Training loss: 0.2720399796962738
Validation loss: 1.7892620742961924

Epoch: 6| Step: 5
Training loss: 0.2971453070640564
Validation loss: 1.7744565932981429

Epoch: 6| Step: 6
Training loss: 0.3372858464717865
Validation loss: 1.8291550323527346

Epoch: 6| Step: 7
Training loss: 0.2909862697124481
Validation loss: 1.839059563093288

Epoch: 6| Step: 8
Training loss: 0.4024302065372467
Validation loss: 1.897249266665469

Epoch: 6| Step: 9
Training loss: 0.25360989570617676
Validation loss: 1.8664726172724078

Epoch: 6| Step: 10
Training loss: 0.25346654653549194
Validation loss: 1.9222183163448046

Epoch: 6| Step: 11
Training loss: 0.1995769739151001
Validation loss: 1.9457550894829534

Epoch: 6| Step: 12
Training loss: 0.22576558589935303
Validation loss: 1.9273381053760488

Epoch: 6| Step: 13
Training loss: 0.32682499289512634
Validation loss: 1.9583966924298195

Epoch: 339| Step: 0
Training loss: 0.24524718523025513
Validation loss: 1.9344986510533158

Epoch: 6| Step: 1
Training loss: 0.39932680130004883
Validation loss: 1.9016148185217252

Epoch: 6| Step: 2
Training loss: 0.224692240357399
Validation loss: 1.9144891359472787

Epoch: 6| Step: 3
Training loss: 0.3363015651702881
Validation loss: 1.8808073741133495

Epoch: 6| Step: 4
Training loss: 0.37939226627349854
Validation loss: 1.8828366994857788

Epoch: 6| Step: 5
Training loss: 0.25724995136260986
Validation loss: 1.8531313878233715

Epoch: 6| Step: 6
Training loss: 0.15296129882335663
Validation loss: 1.8810909807041127

Epoch: 6| Step: 7
Training loss: 0.13958580791950226
Validation loss: 1.8792906768860356

Epoch: 6| Step: 8
Training loss: 0.19842416048049927
Validation loss: 1.877841877680953

Epoch: 6| Step: 9
Training loss: 0.17943203449249268
Validation loss: 1.8557346354248703

Epoch: 6| Step: 10
Training loss: 0.237987220287323
Validation loss: 1.9055738743915354

Epoch: 6| Step: 11
Training loss: 0.25166353583335876
Validation loss: 1.884663947166935

Epoch: 6| Step: 12
Training loss: 0.26343920826911926
Validation loss: 1.8594261343761156

Epoch: 6| Step: 13
Training loss: 0.2653459310531616
Validation loss: 1.8391281097166

Epoch: 340| Step: 0
Training loss: 0.2231215238571167
Validation loss: 1.8050682454980829

Epoch: 6| Step: 1
Training loss: 0.28332221508026123
Validation loss: 1.8160898775182746

Epoch: 6| Step: 2
Training loss: 0.2992005944252014
Validation loss: 1.8514670043863275

Epoch: 6| Step: 3
Training loss: 0.29944926500320435
Validation loss: 1.8376001875887635

Epoch: 6| Step: 4
Training loss: 0.29628485441207886
Validation loss: 1.8317153094917216

Epoch: 6| Step: 5
Training loss: 0.4338998794555664
Validation loss: 1.8389341395388368

Epoch: 6| Step: 6
Training loss: 0.23617999255657196
Validation loss: 1.8275438316406742

Epoch: 6| Step: 7
Training loss: 0.14073404669761658
Validation loss: 1.8130678605007868

Epoch: 6| Step: 8
Training loss: 0.18034732341766357
Validation loss: 1.7868317904010895

Epoch: 6| Step: 9
Training loss: 0.14241884648799896
Validation loss: 1.8285256637040006

Epoch: 6| Step: 10
Training loss: 0.2169284075498581
Validation loss: 1.8432914646722938

Epoch: 6| Step: 11
Training loss: 0.14685454964637756
Validation loss: 1.8386580726151824

Epoch: 6| Step: 12
Training loss: 0.12622790038585663
Validation loss: 1.836084936254768

Epoch: 6| Step: 13
Training loss: 0.2268187254667282
Validation loss: 1.840283811733287

Epoch: 341| Step: 0
Training loss: 0.40891385078430176
Validation loss: 1.8371379567730812

Epoch: 6| Step: 1
Training loss: 0.27873820066452026
Validation loss: 1.8838705939631308

Epoch: 6| Step: 2
Training loss: 0.2862589359283447
Validation loss: 1.8477475027884207

Epoch: 6| Step: 3
Training loss: 0.14172101020812988
Validation loss: 1.8701363058500393

Epoch: 6| Step: 4
Training loss: 0.17051729559898376
Validation loss: 1.8667286557535971

Epoch: 6| Step: 5
Training loss: 0.17514178156852722
Validation loss: 1.8505702031555997

Epoch: 6| Step: 6
Training loss: 0.2032681405544281
Validation loss: 1.8536097772659794

Epoch: 6| Step: 7
Training loss: 0.15712806582450867
Validation loss: 1.8548047234935146

Epoch: 6| Step: 8
Training loss: 0.13891294598579407
Validation loss: 1.8615958306097216

Epoch: 6| Step: 9
Training loss: 0.20562629401683807
Validation loss: 1.8354117934421827

Epoch: 6| Step: 10
Training loss: 0.2506601810455322
Validation loss: 1.8640020790920462

Epoch: 6| Step: 11
Training loss: 0.23156985640525818
Validation loss: 1.8370267960333055

Epoch: 6| Step: 12
Training loss: 0.29614681005477905
Validation loss: 1.8650306809333064

Epoch: 6| Step: 13
Training loss: 0.08678895235061646
Validation loss: 1.838941030604865

Epoch: 342| Step: 0
Training loss: 0.19886194169521332
Validation loss: 1.8296449543327413

Epoch: 6| Step: 1
Training loss: 0.15756776928901672
Validation loss: 1.8209750742040656

Epoch: 6| Step: 2
Training loss: 0.1891719102859497
Validation loss: 1.8525559825281943

Epoch: 6| Step: 3
Training loss: 0.16733399033546448
Validation loss: 1.8871892472749114

Epoch: 6| Step: 4
Training loss: 0.1692163050174713
Validation loss: 1.8131810131893362

Epoch: 6| Step: 5
Training loss: 0.20439499616622925
Validation loss: 1.8403027467830206

Epoch: 6| Step: 6
Training loss: 0.23871074616909027
Validation loss: 1.8859853475324568

Epoch: 6| Step: 7
Training loss: 0.28312093019485474
Validation loss: 1.8762472803874681

Epoch: 6| Step: 8
Training loss: 0.1972760558128357
Validation loss: 1.8539425621750534

Epoch: 6| Step: 9
Training loss: 0.36460989713668823
Validation loss: 1.8441955671515515

Epoch: 6| Step: 10
Training loss: 0.22635968029499054
Validation loss: 1.8807721009818457

Epoch: 6| Step: 11
Training loss: 0.13480186462402344
Validation loss: 1.893165583251625

Epoch: 6| Step: 12
Training loss: 0.2579613924026489
Validation loss: 1.906515072750789

Epoch: 6| Step: 13
Training loss: 0.08778023719787598
Validation loss: 1.9013206856225127

Epoch: 343| Step: 0
Training loss: 0.19961777329444885
Validation loss: 1.8803066938154158

Epoch: 6| Step: 1
Training loss: 0.1377951204776764
Validation loss: 1.8469090359185332

Epoch: 6| Step: 2
Training loss: 0.20260196924209595
Validation loss: 1.88926133032768

Epoch: 6| Step: 3
Training loss: 0.19355495274066925
Validation loss: 1.865905684809531

Epoch: 6| Step: 4
Training loss: 0.1738915592432022
Validation loss: 1.8668212531715311

Epoch: 6| Step: 5
Training loss: 0.20111380517482758
Validation loss: 1.8395895765673729

Epoch: 6| Step: 6
Training loss: 0.15767468512058258
Validation loss: 1.884061731317992

Epoch: 6| Step: 7
Training loss: 0.229816272854805
Validation loss: 1.848025305296785

Epoch: 6| Step: 8
Training loss: 0.2655068039894104
Validation loss: 1.853074344255591

Epoch: 6| Step: 9
Training loss: 0.18916520476341248
Validation loss: 1.868958552678426

Epoch: 6| Step: 10
Training loss: 0.25748157501220703
Validation loss: 1.8760078119975265

Epoch: 6| Step: 11
Training loss: 0.1774364411830902
Validation loss: 1.8965084680946924

Epoch: 6| Step: 12
Training loss: 0.22323718667030334
Validation loss: 1.9443842211077291

Epoch: 6| Step: 13
Training loss: 0.5182116031646729
Validation loss: 1.9392119863981843

Epoch: 344| Step: 0
Training loss: 0.17667904496192932
Validation loss: 1.98753967080065

Epoch: 6| Step: 1
Training loss: 0.28040504455566406
Validation loss: 1.971912166123749

Epoch: 6| Step: 2
Training loss: 0.17505720257759094
Validation loss: 1.9408801396687825

Epoch: 6| Step: 3
Training loss: 0.17519879341125488
Validation loss: 1.9539785231313398

Epoch: 6| Step: 4
Training loss: 0.23093178868293762
Validation loss: 1.9187263147805327

Epoch: 6| Step: 5
Training loss: 0.1678854525089264
Validation loss: 1.9057560774587816

Epoch: 6| Step: 6
Training loss: 0.13303054869174957
Validation loss: 1.8611974472640662

Epoch: 6| Step: 7
Training loss: 0.3719128966331482
Validation loss: 1.838674376087804

Epoch: 6| Step: 8
Training loss: 0.15393787622451782
Validation loss: 1.8211637030365646

Epoch: 6| Step: 9
Training loss: 0.25411689281463623
Validation loss: 1.8332057614480295

Epoch: 6| Step: 10
Training loss: 0.19364739954471588
Validation loss: 1.8360568169624574

Epoch: 6| Step: 11
Training loss: 0.17663143575191498
Validation loss: 1.8540496992808517

Epoch: 6| Step: 12
Training loss: 0.14652325212955475
Validation loss: 1.870414808232297

Epoch: 6| Step: 13
Training loss: 0.21403923630714417
Validation loss: 1.8804869292884745

Epoch: 345| Step: 0
Training loss: 0.21643966436386108
Validation loss: 1.9018324959662654

Epoch: 6| Step: 1
Training loss: 0.21625396609306335
Validation loss: 1.8960757755464124

Epoch: 6| Step: 2
Training loss: 0.1536962240934372
Validation loss: 1.860786045751264

Epoch: 6| Step: 3
Training loss: 0.1755884736776352
Validation loss: 1.8636087653457478

Epoch: 6| Step: 4
Training loss: 0.21720576286315918
Validation loss: 1.875747747318719

Epoch: 6| Step: 5
Training loss: 0.47193044424057007
Validation loss: 1.8205736708897415

Epoch: 6| Step: 6
Training loss: 0.09981115162372589
Validation loss: 1.8501217660083566

Epoch: 6| Step: 7
Training loss: 0.20600247383117676
Validation loss: 1.865483005200663

Epoch: 6| Step: 8
Training loss: 0.25200194120407104
Validation loss: 1.9003899417897707

Epoch: 6| Step: 9
Training loss: 0.22212530672550201
Validation loss: 1.890348570321196

Epoch: 6| Step: 10
Training loss: 0.2294444441795349
Validation loss: 1.891730341860043

Epoch: 6| Step: 11
Training loss: 0.22643499076366425
Validation loss: 1.9060991194940382

Epoch: 6| Step: 12
Training loss: 0.2228015959262848
Validation loss: 1.9323030043673772

Epoch: 6| Step: 13
Training loss: 0.09486323595046997
Validation loss: 1.84137390505883

Epoch: 346| Step: 0
Training loss: 0.19181334972381592
Validation loss: 1.8794399551166001

Epoch: 6| Step: 1
Training loss: 0.21543341875076294
Validation loss: 1.846056947144129

Epoch: 6| Step: 2
Training loss: 0.24206508696079254
Validation loss: 1.8425010737552439

Epoch: 6| Step: 3
Training loss: 0.19463548064231873
Validation loss: 1.819336240009595

Epoch: 6| Step: 4
Training loss: 0.29868704080581665
Validation loss: 1.8463615076516264

Epoch: 6| Step: 5
Training loss: 0.39807385206222534
Validation loss: 1.8297530745947233

Epoch: 6| Step: 6
Training loss: 0.11794424057006836
Validation loss: 1.781222379335793

Epoch: 6| Step: 7
Training loss: 0.4813591241836548
Validation loss: 1.8854586385911511

Epoch: 6| Step: 8
Training loss: 0.21082165837287903
Validation loss: 1.860586461200509

Epoch: 6| Step: 9
Training loss: 0.29751622676849365
Validation loss: 1.8643586661226006

Epoch: 6| Step: 10
Training loss: 0.24448975920677185
Validation loss: 1.8736750823195263

Epoch: 6| Step: 11
Training loss: 0.283019095659256
Validation loss: 1.8584997756506807

Epoch: 6| Step: 12
Training loss: 0.21379774808883667
Validation loss: 1.8811057998288063

Epoch: 6| Step: 13
Training loss: 0.17471098899841309
Validation loss: 1.8496290586327995

Epoch: 347| Step: 0
Training loss: 0.20292648673057556
Validation loss: 1.8605889902319959

Epoch: 6| Step: 1
Training loss: 0.2511966824531555
Validation loss: 1.8715865586393623

Epoch: 6| Step: 2
Training loss: 0.23907311260700226
Validation loss: 1.8338539408099266

Epoch: 6| Step: 3
Training loss: 0.089149609208107
Validation loss: 1.7741709011857227

Epoch: 6| Step: 4
Training loss: 0.20830106735229492
Validation loss: 1.7774822865763018

Epoch: 6| Step: 5
Training loss: 0.22115492820739746
Validation loss: 1.833254933998149

Epoch: 6| Step: 6
Training loss: 0.2731349468231201
Validation loss: 1.8321427760585662

Epoch: 6| Step: 7
Training loss: 0.34391674399375916
Validation loss: 1.8116351981316843

Epoch: 6| Step: 8
Training loss: 0.13897770643234253
Validation loss: 1.804067378403038

Epoch: 6| Step: 9
Training loss: 0.29095447063446045
Validation loss: 1.8324684814740253

Epoch: 6| Step: 10
Training loss: 0.2552465796470642
Validation loss: 1.8350443109389274

Epoch: 6| Step: 11
Training loss: 0.437590628862381
Validation loss: 1.861698264716774

Epoch: 6| Step: 12
Training loss: 0.13655656576156616
Validation loss: 1.8864981179596276

Epoch: 6| Step: 13
Training loss: 0.12435907870531082
Validation loss: 1.8757189550707418

Epoch: 348| Step: 0
Training loss: 0.17486391961574554
Validation loss: 1.8918793816720285

Epoch: 6| Step: 1
Training loss: 0.2451367825269699
Validation loss: 1.851816156859039

Epoch: 6| Step: 2
Training loss: 0.4027899503707886
Validation loss: 1.9057151630360594

Epoch: 6| Step: 3
Training loss: 0.28704553842544556
Validation loss: 1.8685790095278012

Epoch: 6| Step: 4
Training loss: 0.17678743600845337
Validation loss: 1.8953993987011653

Epoch: 6| Step: 5
Training loss: 0.23541757464408875
Validation loss: 1.840780968307167

Epoch: 6| Step: 6
Training loss: 0.22379449009895325
Validation loss: 1.85327317894146

Epoch: 6| Step: 7
Training loss: 0.14558759331703186
Validation loss: 1.8256006856118479

Epoch: 6| Step: 8
Training loss: 0.13110476732254028
Validation loss: 1.813250180213682

Epoch: 6| Step: 9
Training loss: 0.1893296241760254
Validation loss: 1.7902242220858091

Epoch: 6| Step: 10
Training loss: 0.16873061656951904
Validation loss: 1.7733064646361976

Epoch: 6| Step: 11
Training loss: 0.24282360076904297
Validation loss: 1.7819540859550558

Epoch: 6| Step: 12
Training loss: 0.28386664390563965
Validation loss: 1.7696343826991257

Epoch: 6| Step: 13
Training loss: 0.35372039675712585
Validation loss: 1.7829358141909364

Epoch: 349| Step: 0
Training loss: 0.1646278202533722
Validation loss: 1.7926596595394997

Epoch: 6| Step: 1
Training loss: 0.13381347060203552
Validation loss: 1.8224910177210325

Epoch: 6| Step: 2
Training loss: 0.40621912479400635
Validation loss: 1.7925368432075746

Epoch: 6| Step: 3
Training loss: 0.1631844937801361
Validation loss: 1.8434165677716654

Epoch: 6| Step: 4
Training loss: 0.25746387243270874
Validation loss: 1.8405952581795313

Epoch: 6| Step: 5
Training loss: 0.1823444664478302
Validation loss: 1.8467496607893257

Epoch: 6| Step: 6
Training loss: 0.15164582431316376
Validation loss: 1.8956321285616966

Epoch: 6| Step: 7
Training loss: 0.19547180831432343
Validation loss: 1.9054671436227777

Epoch: 6| Step: 8
Training loss: 0.24191442131996155
Validation loss: 1.8846660583249983

Epoch: 6| Step: 9
Training loss: 0.2642586827278137
Validation loss: 1.8887072955408404

Epoch: 6| Step: 10
Training loss: 0.2193823754787445
Validation loss: 1.8907710582979265

Epoch: 6| Step: 11
Training loss: 0.19298478960990906
Validation loss: 1.874517253650132

Epoch: 6| Step: 12
Training loss: 0.1989167034626007
Validation loss: 1.8488047866411106

Epoch: 6| Step: 13
Training loss: 0.16828177869319916
Validation loss: 1.8097811834786528

Epoch: 350| Step: 0
Training loss: 0.16684788465499878
Validation loss: 1.8448329740954983

Epoch: 6| Step: 1
Training loss: 0.24122530221939087
Validation loss: 1.8246307091046405

Epoch: 6| Step: 2
Training loss: 0.1814325898885727
Validation loss: 1.834163099206904

Epoch: 6| Step: 3
Training loss: 0.22835496068000793
Validation loss: 1.8474078024587324

Epoch: 6| Step: 4
Training loss: 0.200703963637352
Validation loss: 1.8175039458018478

Epoch: 6| Step: 5
Training loss: 0.3827677369117737
Validation loss: 1.8170806797601844

Epoch: 6| Step: 6
Training loss: 0.20462918281555176
Validation loss: 1.8206703829508957

Epoch: 6| Step: 7
Training loss: 0.15251818299293518
Validation loss: 1.8235615722594722

Epoch: 6| Step: 8
Training loss: 0.15447494387626648
Validation loss: 1.8490872126753612

Epoch: 6| Step: 9
Training loss: 0.20887267589569092
Validation loss: 1.807688202909244

Epoch: 6| Step: 10
Training loss: 0.10259733349084854
Validation loss: 1.8367399451553181

Epoch: 6| Step: 11
Training loss: 0.24130932986736298
Validation loss: 1.8397090076118388

Epoch: 6| Step: 12
Training loss: 0.16101758182048798
Validation loss: 1.8112948389463528

Epoch: 6| Step: 13
Training loss: 0.20401443541049957
Validation loss: 1.793654562324606

Epoch: 351| Step: 0
Training loss: 0.13346417248249054
Validation loss: 1.7924783499010148

Epoch: 6| Step: 1
Training loss: 0.21929243206977844
Validation loss: 1.825483359316344

Epoch: 6| Step: 2
Training loss: 0.23287802934646606
Validation loss: 1.804100009702867

Epoch: 6| Step: 3
Training loss: 0.1687803566455841
Validation loss: 1.7974685725345407

Epoch: 6| Step: 4
Training loss: 0.2478737235069275
Validation loss: 1.7997071191828737

Epoch: 6| Step: 5
Training loss: 0.18706318736076355
Validation loss: 1.8135530756365867

Epoch: 6| Step: 6
Training loss: 0.25082993507385254
Validation loss: 1.7957491310693885

Epoch: 6| Step: 7
Training loss: 0.2270076721906662
Validation loss: 1.816802643960522

Epoch: 6| Step: 8
Training loss: 0.17862333357334137
Validation loss: 1.8277907204884354

Epoch: 6| Step: 9
Training loss: 0.41806265711784363
Validation loss: 1.8371793890512118

Epoch: 6| Step: 10
Training loss: 0.11254093796014786
Validation loss: 1.8262405292962187

Epoch: 6| Step: 11
Training loss: 0.0945708304643631
Validation loss: 1.812651083033572

Epoch: 6| Step: 12
Training loss: 0.21625950932502747
Validation loss: 1.8141143065626903

Epoch: 6| Step: 13
Training loss: 0.19529758393764496
Validation loss: 1.8356289568767752

Epoch: 352| Step: 0
Training loss: 0.1774328649044037
Validation loss: 1.829685890546409

Epoch: 6| Step: 1
Training loss: 0.19144028425216675
Validation loss: 1.8261183859199606

Epoch: 6| Step: 2
Training loss: 0.34934067726135254
Validation loss: 1.8822263145959506

Epoch: 6| Step: 3
Training loss: 0.16818556189537048
Validation loss: 1.8527045173029746

Epoch: 6| Step: 4
Training loss: 0.16925519704818726
Validation loss: 1.8571183207214519

Epoch: 6| Step: 5
Training loss: 0.12248196452856064
Validation loss: 1.7853290432242936

Epoch: 6| Step: 6
Training loss: 0.17071381211280823
Validation loss: 1.8178111583955827

Epoch: 6| Step: 7
Training loss: 0.164189875125885
Validation loss: 1.7649896221776162

Epoch: 6| Step: 8
Training loss: 0.30819886922836304
Validation loss: 1.7762738325262581

Epoch: 6| Step: 9
Training loss: 0.22723954916000366
Validation loss: 1.7606114982276835

Epoch: 6| Step: 10
Training loss: 0.23670953512191772
Validation loss: 1.7661614289847754

Epoch: 6| Step: 11
Training loss: 0.1816062331199646
Validation loss: 1.838594449463711

Epoch: 6| Step: 12
Training loss: 0.1859251856803894
Validation loss: 1.8456195785153298

Epoch: 6| Step: 13
Training loss: 0.23677147924900055
Validation loss: 1.9005955085959485

Epoch: 353| Step: 0
Training loss: 0.15170609951019287
Validation loss: 1.902954650181596

Epoch: 6| Step: 1
Training loss: 0.14561200141906738
Validation loss: 1.8851493174029934

Epoch: 6| Step: 2
Training loss: 0.18515291810035706
Validation loss: 1.891113418404774

Epoch: 6| Step: 3
Training loss: 0.12058474123477936
Validation loss: 1.8979236566892235

Epoch: 6| Step: 4
Training loss: 0.2949061393737793
Validation loss: 1.8971518162758119

Epoch: 6| Step: 5
Training loss: 0.1579941064119339
Validation loss: 1.8413669845109344

Epoch: 6| Step: 6
Training loss: 0.27171653509140015
Validation loss: 1.8733726227155296

Epoch: 6| Step: 7
Training loss: 0.3806379437446594
Validation loss: 1.8263251858372842

Epoch: 6| Step: 8
Training loss: 0.24451132118701935
Validation loss: 1.8653067773388279

Epoch: 6| Step: 9
Training loss: 0.1194148138165474
Validation loss: 1.8219937201469176

Epoch: 6| Step: 10
Training loss: 0.23134322464466095
Validation loss: 1.8351320605124197

Epoch: 6| Step: 11
Training loss: 0.25510281324386597
Validation loss: 1.827497092626428

Epoch: 6| Step: 12
Training loss: 0.1025347113609314
Validation loss: 1.8519578723497288

Epoch: 6| Step: 13
Training loss: 0.18841885030269623
Validation loss: 1.8471640322798042

Epoch: 354| Step: 0
Training loss: 0.15822812914848328
Validation loss: 1.87359481985851

Epoch: 6| Step: 1
Training loss: 0.15573517978191376
Validation loss: 1.8292689579789356

Epoch: 6| Step: 2
Training loss: 0.08700355887413025
Validation loss: 1.8799180958860664

Epoch: 6| Step: 3
Training loss: 0.14928682148456573
Validation loss: 1.8611445824305217

Epoch: 6| Step: 4
Training loss: 0.14749404788017273
Validation loss: 1.8826986192375101

Epoch: 6| Step: 5
Training loss: 0.12797389924526215
Validation loss: 1.9135911208327099

Epoch: 6| Step: 6
Training loss: 0.1536162793636322
Validation loss: 1.9544741569026824

Epoch: 6| Step: 7
Training loss: 0.17596113681793213
Validation loss: 1.9063350039143716

Epoch: 6| Step: 8
Training loss: 0.2021423727273941
Validation loss: 1.9144486932344333

Epoch: 6| Step: 9
Training loss: 0.46001216769218445
Validation loss: 1.9514719452909244

Epoch: 6| Step: 10
Training loss: 0.21839188039302826
Validation loss: 1.8730740957362677

Epoch: 6| Step: 11
Training loss: 0.25782346725463867
Validation loss: 1.869702313535957

Epoch: 6| Step: 12
Training loss: 0.19463561475276947
Validation loss: 1.8528159600432201

Epoch: 6| Step: 13
Training loss: 0.2515205144882202
Validation loss: 1.798076492483898

Epoch: 355| Step: 0
Training loss: 0.41160959005355835
Validation loss: 1.8220122732141966

Epoch: 6| Step: 1
Training loss: 0.12809988856315613
Validation loss: 1.8216152767981253

Epoch: 6| Step: 2
Training loss: 0.22944775223731995
Validation loss: 1.8107499563565819

Epoch: 6| Step: 3
Training loss: 0.18809720873832703
Validation loss: 1.803098560661398

Epoch: 6| Step: 4
Training loss: 0.11707110702991486
Validation loss: 1.8019773690931258

Epoch: 6| Step: 5
Training loss: 0.14336054027080536
Validation loss: 1.7970487891986806

Epoch: 6| Step: 6
Training loss: 0.15327225625514984
Validation loss: 1.8783869128073416

Epoch: 6| Step: 7
Training loss: 0.1947380155324936
Validation loss: 1.8601104969619422

Epoch: 6| Step: 8
Training loss: 0.1200941950082779
Validation loss: 1.885711048239021

Epoch: 6| Step: 9
Training loss: 0.16499045491218567
Validation loss: 1.8738404768769459

Epoch: 6| Step: 10
Training loss: 0.1600944548845291
Validation loss: 1.8673843337643532

Epoch: 6| Step: 11
Training loss: 0.35380423069000244
Validation loss: 1.8798362721679032

Epoch: 6| Step: 12
Training loss: 0.14044630527496338
Validation loss: 1.9150538380428026

Epoch: 6| Step: 13
Training loss: 0.1511216014623642
Validation loss: 1.8565269157450686

Epoch: 356| Step: 0
Training loss: 0.19598233699798584
Validation loss: 1.8529986322567027

Epoch: 6| Step: 1
Training loss: 0.10983093082904816
Validation loss: 1.8585502088710826

Epoch: 6| Step: 2
Training loss: 0.21571853756904602
Validation loss: 1.8361256737862863

Epoch: 6| Step: 3
Training loss: 0.10815287381410599
Validation loss: 1.836668029908211

Epoch: 6| Step: 4
Training loss: 0.39169082045555115
Validation loss: 1.8442254681741037

Epoch: 6| Step: 5
Training loss: 0.21564720571041107
Validation loss: 1.845643816455718

Epoch: 6| Step: 6
Training loss: 0.21151842176914215
Validation loss: 1.8646084647024832

Epoch: 6| Step: 7
Training loss: 0.12983378767967224
Validation loss: 1.8692344145108295

Epoch: 6| Step: 8
Training loss: 0.23313242197036743
Validation loss: 1.8997755076295586

Epoch: 6| Step: 9
Training loss: 0.29097190499305725
Validation loss: 1.9166449218667962

Epoch: 6| Step: 10
Training loss: 0.2565031349658966
Validation loss: 1.921008308728536

Epoch: 6| Step: 11
Training loss: 0.20024873316287994
Validation loss: 1.891497823499864

Epoch: 6| Step: 12
Training loss: 0.12381559610366821
Validation loss: 1.8312091160846014

Epoch: 6| Step: 13
Training loss: 0.21048030257225037
Validation loss: 1.837410883236957

Epoch: 357| Step: 0
Training loss: 0.23140597343444824
Validation loss: 1.8107708346459173

Epoch: 6| Step: 1
Training loss: 0.2787878215312958
Validation loss: 1.7973812664708784

Epoch: 6| Step: 2
Training loss: 0.3792959451675415
Validation loss: 1.7951073813182052

Epoch: 6| Step: 3
Training loss: 0.12163867801427841
Validation loss: 1.8351279715056061

Epoch: 6| Step: 4
Training loss: 0.13476145267486572
Validation loss: 1.8930261622193039

Epoch: 6| Step: 5
Training loss: 0.20663709938526154
Validation loss: 1.8655893251460085

Epoch: 6| Step: 6
Training loss: 0.1722114533185959
Validation loss: 1.8586218908268919

Epoch: 6| Step: 7
Training loss: 0.2556104362010956
Validation loss: 1.8956673734931535

Epoch: 6| Step: 8
Training loss: 0.20463386178016663
Validation loss: 1.9134914272574968

Epoch: 6| Step: 9
Training loss: 0.14671052992343903
Validation loss: 1.8974992946911884

Epoch: 6| Step: 10
Training loss: 0.20334792137145996
Validation loss: 1.8741185331857333

Epoch: 6| Step: 11
Training loss: 0.2634735703468323
Validation loss: 1.863046056480818

Epoch: 6| Step: 12
Training loss: 0.22830405831336975
Validation loss: 1.8239022967635945

Epoch: 6| Step: 13
Training loss: 0.19890381395816803
Validation loss: 1.825091250481144

Epoch: 358| Step: 0
Training loss: 0.21104945242404938
Validation loss: 1.800881060220862

Epoch: 6| Step: 1
Training loss: 0.2665712237358093
Validation loss: 1.793338083451794

Epoch: 6| Step: 2
Training loss: 0.2704331576824188
Validation loss: 1.7976866293978948

Epoch: 6| Step: 3
Training loss: 0.17345663905143738
Validation loss: 1.8111156930205643

Epoch: 6| Step: 4
Training loss: 0.14764870703220367
Validation loss: 1.864392788179459

Epoch: 6| Step: 5
Training loss: 0.15416274964809418
Validation loss: 1.8787072294501848

Epoch: 6| Step: 6
Training loss: 0.19288977980613708
Validation loss: 1.8847647815622308

Epoch: 6| Step: 7
Training loss: 0.18508750200271606
Validation loss: 1.8466929363948044

Epoch: 6| Step: 8
Training loss: 0.3092081546783447
Validation loss: 1.9138589751335882

Epoch: 6| Step: 9
Training loss: 0.20892181992530823
Validation loss: 1.8931988695616364

Epoch: 6| Step: 10
Training loss: 0.15702074766159058
Validation loss: 1.8583802305242068

Epoch: 6| Step: 11
Training loss: 0.26221925020217896
Validation loss: 1.8828359496208928

Epoch: 6| Step: 12
Training loss: 0.12298440933227539
Validation loss: 1.8484009081317532

Epoch: 6| Step: 13
Training loss: 0.13676786422729492
Validation loss: 1.8256759861464142

Epoch: 359| Step: 0
Training loss: 0.13581816852092743
Validation loss: 1.8447121958578787

Epoch: 6| Step: 1
Training loss: 0.1522035002708435
Validation loss: 1.8089394864215647

Epoch: 6| Step: 2
Training loss: 0.1706782877445221
Validation loss: 1.8452563208918418

Epoch: 6| Step: 3
Training loss: 0.15609656274318695
Validation loss: 1.8051131592001965

Epoch: 6| Step: 4
Training loss: 0.34999656677246094
Validation loss: 1.7909580276858421

Epoch: 6| Step: 5
Training loss: 0.12515781819820404
Validation loss: 1.8181410194725118

Epoch: 6| Step: 6
Training loss: 0.08498283475637436
Validation loss: 1.8253638218807917

Epoch: 6| Step: 7
Training loss: 0.3120751976966858
Validation loss: 1.8239948172723093

Epoch: 6| Step: 8
Training loss: 0.19771960377693176
Validation loss: 1.8324251764564103

Epoch: 6| Step: 9
Training loss: 0.13125668466091156
Validation loss: 1.845450779443146

Epoch: 6| Step: 10
Training loss: 0.1908455491065979
Validation loss: 1.8454191325813212

Epoch: 6| Step: 11
Training loss: 0.2948262691497803
Validation loss: 1.8307917656437043

Epoch: 6| Step: 12
Training loss: 0.24408407509326935
Validation loss: 1.8350563895317815

Epoch: 6| Step: 13
Training loss: 0.3598255515098572
Validation loss: 1.8515091596111175

Epoch: 360| Step: 0
Training loss: 0.19227652251720428
Validation loss: 1.851116241947297

Epoch: 6| Step: 1
Training loss: 0.18142163753509521
Validation loss: 1.850341543074577

Epoch: 6| Step: 2
Training loss: 0.3329322338104248
Validation loss: 1.8901147509133944

Epoch: 6| Step: 3
Training loss: 0.22042542695999146
Validation loss: 1.902494804833525

Epoch: 6| Step: 4
Training loss: 0.4332161545753479
Validation loss: 1.9009826926774875

Epoch: 6| Step: 5
Training loss: 0.21740849316120148
Validation loss: 1.8818594691573933

Epoch: 6| Step: 6
Training loss: 0.20554693043231964
Validation loss: 1.8673110687604515

Epoch: 6| Step: 7
Training loss: 0.16518500447273254
Validation loss: 1.8704579094404816

Epoch: 6| Step: 8
Training loss: 0.2819066643714905
Validation loss: 1.8465444131564068

Epoch: 6| Step: 9
Training loss: 0.16925635933876038
Validation loss: 1.867350673162809

Epoch: 6| Step: 10
Training loss: 0.20075911283493042
Validation loss: 1.8805671661130843

Epoch: 6| Step: 11
Training loss: 0.19789758324623108
Validation loss: 1.8617099972181423

Epoch: 6| Step: 12
Training loss: 0.2039148509502411
Validation loss: 1.8370598759702457

Epoch: 6| Step: 13
Training loss: 0.13576653599739075
Validation loss: 1.8271706668279504

Epoch: 361| Step: 0
Training loss: 0.18794400990009308
Validation loss: 1.8449785004379928

Epoch: 6| Step: 1
Training loss: 0.18840143084526062
Validation loss: 1.8233712104059034

Epoch: 6| Step: 2
Training loss: 0.28838545083999634
Validation loss: 1.7815771359269337

Epoch: 6| Step: 3
Training loss: 0.2174394726753235
Validation loss: 1.7315512152128323

Epoch: 6| Step: 4
Training loss: 0.24199002981185913
Validation loss: 1.693169746347653

Epoch: 6| Step: 5
Training loss: 0.2867511510848999
Validation loss: 1.7206560091305805

Epoch: 6| Step: 6
Training loss: 0.2518097758293152
Validation loss: 1.7340962732991865

Epoch: 6| Step: 7
Training loss: 0.2618814706802368
Validation loss: 1.7720968954024776

Epoch: 6| Step: 8
Training loss: 0.2983451783657074
Validation loss: 1.7501186119612826

Epoch: 6| Step: 9
Training loss: 0.2346847951412201
Validation loss: 1.7608604559334375

Epoch: 6| Step: 10
Training loss: 0.21156534552574158
Validation loss: 1.7932418033640871

Epoch: 6| Step: 11
Training loss: 0.20488333702087402
Validation loss: 1.8359169844658143

Epoch: 6| Step: 12
Training loss: 0.4323950409889221
Validation loss: 1.898927939835415

Epoch: 6| Step: 13
Training loss: 0.3345542550086975
Validation loss: 1.9157702410092918

Epoch: 362| Step: 0
Training loss: 0.49445825815200806
Validation loss: 1.9182840701072448

Epoch: 6| Step: 1
Training loss: 0.2572096586227417
Validation loss: 1.8836827085864158

Epoch: 6| Step: 2
Training loss: 0.15615153312683105
Validation loss: 1.8631833214913645

Epoch: 6| Step: 3
Training loss: 0.17991694808006287
Validation loss: 1.813190488405125

Epoch: 6| Step: 4
Training loss: 0.16248688101768494
Validation loss: 1.746220491265738

Epoch: 6| Step: 5
Training loss: 0.18923796713352203
Validation loss: 1.7416592515924925

Epoch: 6| Step: 6
Training loss: 0.2415047287940979
Validation loss: 1.7291227553480415

Epoch: 6| Step: 7
Training loss: 0.294495552778244
Validation loss: 1.7166948664572932

Epoch: 6| Step: 8
Training loss: 0.28559979796409607
Validation loss: 1.7726161454313545

Epoch: 6| Step: 9
Training loss: 0.2278711199760437
Validation loss: 1.712209859201985

Epoch: 6| Step: 10
Training loss: 0.18399985134601593
Validation loss: 1.755630511109547

Epoch: 6| Step: 11
Training loss: 0.13393563032150269
Validation loss: 1.761351477715277

Epoch: 6| Step: 12
Training loss: 0.23292678594589233
Validation loss: 1.7865196838173816

Epoch: 6| Step: 13
Training loss: 0.1520567685365677
Validation loss: 1.839751781955842

Epoch: 363| Step: 0
Training loss: 0.20359444618225098
Validation loss: 1.8061816961534563

Epoch: 6| Step: 1
Training loss: 0.15053445100784302
Validation loss: 1.786543038583571

Epoch: 6| Step: 2
Training loss: 0.23266151547431946
Validation loss: 1.7987143788286435

Epoch: 6| Step: 3
Training loss: 0.2107274830341339
Validation loss: 1.8317067341137958

Epoch: 6| Step: 4
Training loss: 0.20917639136314392
Validation loss: 1.8502314847002748

Epoch: 6| Step: 5
Training loss: 0.13527441024780273
Validation loss: 1.823425882606096

Epoch: 6| Step: 6
Training loss: 0.13219726085662842
Validation loss: 1.8407675117574713

Epoch: 6| Step: 7
Training loss: 0.15428230166435242
Validation loss: 1.7909242850477978

Epoch: 6| Step: 8
Training loss: 0.12803027033805847
Validation loss: 1.7765173771048104

Epoch: 6| Step: 9
Training loss: 0.2152954488992691
Validation loss: 1.7622766366568945

Epoch: 6| Step: 10
Training loss: 0.16818422079086304
Validation loss: 1.8021237952734834

Epoch: 6| Step: 11
Training loss: 0.20583415031433105
Validation loss: 1.7860257176942722

Epoch: 6| Step: 12
Training loss: 0.47600802779197693
Validation loss: 1.8120156129201253

Epoch: 6| Step: 13
Training loss: 0.2330569177865982
Validation loss: 1.7757062835078086

Epoch: 364| Step: 0
Training loss: 0.16973626613616943
Validation loss: 1.7998779633993744

Epoch: 6| Step: 1
Training loss: 0.21064886450767517
Validation loss: 1.7909498881268244

Epoch: 6| Step: 2
Training loss: 0.1337490677833557
Validation loss: 1.7828279541384788

Epoch: 6| Step: 3
Training loss: 0.1441417932510376
Validation loss: 1.819286282985441

Epoch: 6| Step: 4
Training loss: 0.14824464917182922
Validation loss: 1.8111785163161576

Epoch: 6| Step: 5
Training loss: 0.1410895138978958
Validation loss: 1.7915751370050574

Epoch: 6| Step: 6
Training loss: 0.1764260232448578
Validation loss: 1.8335831895951302

Epoch: 6| Step: 7
Training loss: 0.19099098443984985
Validation loss: 1.8468782427490398

Epoch: 6| Step: 8
Training loss: 0.12653502821922302
Validation loss: 1.83251283502066

Epoch: 6| Step: 9
Training loss: 0.4803157150745392
Validation loss: 1.8527257929566086

Epoch: 6| Step: 10
Training loss: 0.15889708697795868
Validation loss: 1.8557150633104387

Epoch: 6| Step: 11
Training loss: 0.23150846362113953
Validation loss: 1.8814098860627861

Epoch: 6| Step: 12
Training loss: 0.1466490924358368
Validation loss: 1.8520346879959106

Epoch: 6| Step: 13
Training loss: 0.3298523724079132
Validation loss: 1.8545013358516078

Epoch: 365| Step: 0
Training loss: 0.23755834996700287
Validation loss: 1.8714006331659132

Epoch: 6| Step: 1
Training loss: 0.24860748648643494
Validation loss: 1.8811474820618987

Epoch: 6| Step: 2
Training loss: 0.20784658193588257
Validation loss: 1.8430134904000066

Epoch: 6| Step: 3
Training loss: 0.24232223629951477
Validation loss: 1.860047346802168

Epoch: 6| Step: 4
Training loss: 0.2881438434123993
Validation loss: 1.875513795883425

Epoch: 6| Step: 5
Training loss: 0.19324156641960144
Validation loss: 1.8493531788549116

Epoch: 6| Step: 6
Training loss: 0.15570515394210815
Validation loss: 1.8560684624538626

Epoch: 6| Step: 7
Training loss: 0.13340604305267334
Validation loss: 1.8916029122567946

Epoch: 6| Step: 8
Training loss: 0.10659027099609375
Validation loss: 1.8500462591007192

Epoch: 6| Step: 9
Training loss: 0.13788393139839172
Validation loss: 1.8365905182335966

Epoch: 6| Step: 10
Training loss: 0.4190380275249481
Validation loss: 1.8250964738989388

Epoch: 6| Step: 11
Training loss: 0.13276979327201843
Validation loss: 1.8323040034181328

Epoch: 6| Step: 12
Training loss: 0.22519418597221375
Validation loss: 1.8548746685827933

Epoch: 6| Step: 13
Training loss: 0.29975274205207825
Validation loss: 1.9045126271504227

Epoch: 366| Step: 0
Training loss: 0.23626141250133514
Validation loss: 1.88308516112707

Epoch: 6| Step: 1
Training loss: 0.18551550805568695
Validation loss: 1.900081047447779

Epoch: 6| Step: 2
Training loss: 0.1263829618692398
Validation loss: 1.8600736177095802

Epoch: 6| Step: 3
Training loss: 0.22080133855342865
Validation loss: 1.8810741247669343

Epoch: 6| Step: 4
Training loss: 0.16684049367904663
Validation loss: 1.877681762941422

Epoch: 6| Step: 5
Training loss: 0.42531245946884155
Validation loss: 1.838590911639634

Epoch: 6| Step: 6
Training loss: 0.141830176115036
Validation loss: 1.847919439756742

Epoch: 6| Step: 7
Training loss: 0.2220894992351532
Validation loss: 1.8121549749887118

Epoch: 6| Step: 8
Training loss: 0.2108386605978012
Validation loss: 1.7754632503755632

Epoch: 6| Step: 9
Training loss: 0.14394372701644897
Validation loss: 1.813334208662792

Epoch: 6| Step: 10
Training loss: 0.17643746733665466
Validation loss: 1.815304058854298

Epoch: 6| Step: 11
Training loss: 0.2305493801832199
Validation loss: 1.7866049787049652

Epoch: 6| Step: 12
Training loss: 0.21031996607780457
Validation loss: 1.7625199831942076

Epoch: 6| Step: 13
Training loss: 0.15626446902751923
Validation loss: 1.7912827486632972

Epoch: 367| Step: 0
Training loss: 0.14017657935619354
Validation loss: 1.7978328235687748

Epoch: 6| Step: 1
Training loss: 0.3586072325706482
Validation loss: 1.7779610374922394

Epoch: 6| Step: 2
Training loss: 0.265433669090271
Validation loss: 1.8087704591853644

Epoch: 6| Step: 3
Training loss: 0.20959971845149994
Validation loss: 1.7921392020358835

Epoch: 6| Step: 4
Training loss: 0.25154638290405273
Validation loss: 1.8022801760704286

Epoch: 6| Step: 5
Training loss: 0.11608991026878357
Validation loss: 1.755726606615128

Epoch: 6| Step: 6
Training loss: 0.10471715033054352
Validation loss: 1.7913330934380973

Epoch: 6| Step: 7
Training loss: 0.14950332045555115
Validation loss: 1.7813183825503114

Epoch: 6| Step: 8
Training loss: 0.12749113142490387
Validation loss: 1.782844598575305

Epoch: 6| Step: 9
Training loss: 0.0932919979095459
Validation loss: 1.858093164300406

Epoch: 6| Step: 10
Training loss: 0.16609618067741394
Validation loss: 1.79699331842443

Epoch: 6| Step: 11
Training loss: 0.26462608575820923
Validation loss: 1.8068839683327624

Epoch: 6| Step: 12
Training loss: 0.14953872561454773
Validation loss: 1.781734940826252

Epoch: 6| Step: 13
Training loss: 0.251631498336792
Validation loss: 1.8104935922930319

Epoch: 368| Step: 0
Training loss: 0.1636909693479538
Validation loss: 1.8237174890374626

Epoch: 6| Step: 1
Training loss: 0.1698228418827057
Validation loss: 1.787758546490823

Epoch: 6| Step: 2
Training loss: 0.17024289071559906
Validation loss: 1.7776507498115621

Epoch: 6| Step: 3
Training loss: 0.23991677165031433
Validation loss: 1.774904292116883

Epoch: 6| Step: 4
Training loss: 0.19043131172657013
Validation loss: 1.81529289291751

Epoch: 6| Step: 5
Training loss: 0.18371358513832092
Validation loss: 1.8098645402539162

Epoch: 6| Step: 6
Training loss: 0.2879914939403534
Validation loss: 1.8331324067167056

Epoch: 6| Step: 7
Training loss: 0.3941580057144165
Validation loss: 1.808180429602182

Epoch: 6| Step: 8
Training loss: 0.276686429977417
Validation loss: 1.7932483637204735

Epoch: 6| Step: 9
Training loss: 0.1805446594953537
Validation loss: 1.7639571966663483

Epoch: 6| Step: 10
Training loss: 0.138859823346138
Validation loss: 1.7694741372139222

Epoch: 6| Step: 11
Training loss: 0.1443352997303009
Validation loss: 1.7489262588562504

Epoch: 6| Step: 12
Training loss: 0.14868588745594025
Validation loss: 1.7882179342290407

Epoch: 6| Step: 13
Training loss: 0.1266762912273407
Validation loss: 1.762822288338856

Epoch: 369| Step: 0
Training loss: 0.10861630737781525
Validation loss: 1.778822316918322

Epoch: 6| Step: 1
Training loss: 0.16070927679538727
Validation loss: 1.7860467587747881

Epoch: 6| Step: 2
Training loss: 0.1951451599597931
Validation loss: 1.8162490283289263

Epoch: 6| Step: 3
Training loss: 0.09884673357009888
Validation loss: 1.793907521873392

Epoch: 6| Step: 4
Training loss: 0.19831211864948273
Validation loss: 1.7688145868239864

Epoch: 6| Step: 5
Training loss: 0.17191442847251892
Validation loss: 1.756829575825763

Epoch: 6| Step: 6
Training loss: 0.17048656940460205
Validation loss: 1.7580863788563719

Epoch: 6| Step: 7
Training loss: 0.17182353138923645
Validation loss: 1.7384920427876134

Epoch: 6| Step: 8
Training loss: 0.18200212717056274
Validation loss: 1.759805085838482

Epoch: 6| Step: 9
Training loss: 0.2376122921705246
Validation loss: 1.7561582185888802

Epoch: 6| Step: 10
Training loss: 0.3313169479370117
Validation loss: 1.7989273725017425

Epoch: 6| Step: 11
Training loss: 0.25018835067749023
Validation loss: 1.8091576894124348

Epoch: 6| Step: 12
Training loss: 0.1679365485906601
Validation loss: 1.8310890531027189

Epoch: 6| Step: 13
Training loss: 0.22415977716445923
Validation loss: 1.8239383979510235

Epoch: 370| Step: 0
Training loss: 0.2376895248889923
Validation loss: 1.815022341666683

Epoch: 6| Step: 1
Training loss: 0.16152240335941315
Validation loss: 1.827441232178801

Epoch: 6| Step: 2
Training loss: 0.15343327820301056
Validation loss: 1.7652000240100327

Epoch: 6| Step: 3
Training loss: 0.11933833360671997
Validation loss: 1.7865084499441168

Epoch: 6| Step: 4
Training loss: 0.20274677872657776
Validation loss: 1.7288078697778846

Epoch: 6| Step: 5
Training loss: 0.1624964475631714
Validation loss: 1.7820793294137525

Epoch: 6| Step: 6
Training loss: 0.17814520001411438
Validation loss: 1.7450277497691493

Epoch: 6| Step: 7
Training loss: 0.11391765624284744
Validation loss: 1.7934096577346965

Epoch: 6| Step: 8
Training loss: 0.378257691860199
Validation loss: 1.7920251764276975

Epoch: 6| Step: 9
Training loss: 0.16450627148151398
Validation loss: 1.7913707981827438

Epoch: 6| Step: 10
Training loss: 0.17339852452278137
Validation loss: 1.791380190080212

Epoch: 6| Step: 11
Training loss: 0.18151548504829407
Validation loss: 1.7723713074961016

Epoch: 6| Step: 12
Training loss: 0.16668136417865753
Validation loss: 1.7901405493418376

Epoch: 6| Step: 13
Training loss: 0.08753752708435059
Validation loss: 1.808059456527874

Epoch: 371| Step: 0
Training loss: 0.1719428151845932
Validation loss: 1.79421676358869

Epoch: 6| Step: 1
Training loss: 0.16396605968475342
Validation loss: 1.8156510463324926

Epoch: 6| Step: 2
Training loss: 0.22314953804016113
Validation loss: 1.8251687352375319

Epoch: 6| Step: 3
Training loss: 0.12339599430561066
Validation loss: 1.8552735082564815

Epoch: 6| Step: 4
Training loss: 0.22893711924552917
Validation loss: 1.8461273459978

Epoch: 6| Step: 5
Training loss: 0.12351217865943909
Validation loss: 1.8672860181459816

Epoch: 6| Step: 6
Training loss: 0.2004864364862442
Validation loss: 1.8858635733204503

Epoch: 6| Step: 7
Training loss: 0.3259463906288147
Validation loss: 1.8922025285741335

Epoch: 6| Step: 8
Training loss: 0.18929287791252136
Validation loss: 1.9072810603726296

Epoch: 6| Step: 9
Training loss: 0.18850275874137878
Validation loss: 1.8868115999365365

Epoch: 6| Step: 10
Training loss: 0.0954359620809555
Validation loss: 1.849524587713262

Epoch: 6| Step: 11
Training loss: 0.20824465155601501
Validation loss: 1.8589531247333815

Epoch: 6| Step: 12
Training loss: 0.2033335119485855
Validation loss: 1.82563728286374

Epoch: 6| Step: 13
Training loss: 0.10081116110086441
Validation loss: 1.8159104483101958

Epoch: 372| Step: 0
Training loss: 0.14722658693790436
Validation loss: 1.763988967864744

Epoch: 6| Step: 1
Training loss: 0.15953823924064636
Validation loss: 1.740840660628452

Epoch: 6| Step: 2
Training loss: 0.2446877360343933
Validation loss: 1.7735009321602442

Epoch: 6| Step: 3
Training loss: 0.16447153687477112
Validation loss: 1.7347457024358934

Epoch: 6| Step: 4
Training loss: 0.3018868565559387
Validation loss: 1.7427332324366416

Epoch: 6| Step: 5
Training loss: 0.14131790399551392
Validation loss: 1.7153555911074403

Epoch: 6| Step: 6
Training loss: 0.07339168339967728
Validation loss: 1.722056399109543

Epoch: 6| Step: 7
Training loss: 0.10462024807929993
Validation loss: 1.7514616289446432

Epoch: 6| Step: 8
Training loss: 0.15260368585586548
Validation loss: 1.7281997434554561

Epoch: 6| Step: 9
Training loss: 0.16193333268165588
Validation loss: 1.7522297751518987

Epoch: 6| Step: 10
Training loss: 0.11995555460453033
Validation loss: 1.8129798071358794

Epoch: 6| Step: 11
Training loss: 0.14881452918052673
Validation loss: 1.791542237804782

Epoch: 6| Step: 12
Training loss: 0.10661432147026062
Validation loss: 1.7901024549238143

Epoch: 6| Step: 13
Training loss: 0.3928670883178711
Validation loss: 1.8181171891509846

Epoch: 373| Step: 0
Training loss: 0.17498943209648132
Validation loss: 1.8383798535152147

Epoch: 6| Step: 1
Training loss: 0.3481445014476776
Validation loss: 1.8644479096576732

Epoch: 6| Step: 2
Training loss: 0.2319517433643341
Validation loss: 1.8489738382318968

Epoch: 6| Step: 3
Training loss: 0.14284411072731018
Validation loss: 1.8269414876096992

Epoch: 6| Step: 4
Training loss: 0.1963767111301422
Validation loss: 1.8171444375027892

Epoch: 6| Step: 5
Training loss: 0.1261676400899887
Validation loss: 1.8052007972553212

Epoch: 6| Step: 6
Training loss: 0.15181753039360046
Validation loss: 1.751841365650136

Epoch: 6| Step: 7
Training loss: 0.13822023570537567
Validation loss: 1.7610884263951292

Epoch: 6| Step: 8
Training loss: 0.17205817997455597
Validation loss: 1.75487563174258

Epoch: 6| Step: 9
Training loss: 0.1421617865562439
Validation loss: 1.7644440461230535

Epoch: 6| Step: 10
Training loss: 0.2560649812221527
Validation loss: 1.7719846643427366

Epoch: 6| Step: 11
Training loss: 0.20298896729946136
Validation loss: 1.8027110638157013

Epoch: 6| Step: 12
Training loss: 0.13494640588760376
Validation loss: 1.7888610350188388

Epoch: 6| Step: 13
Training loss: 0.1348666548728943
Validation loss: 1.7875783904906242

Epoch: 374| Step: 0
Training loss: 0.15374118089675903
Validation loss: 1.8040217532906482

Epoch: 6| Step: 1
Training loss: 0.13405929505825043
Validation loss: 1.8422556487462853

Epoch: 6| Step: 2
Training loss: 0.22109553217887878
Validation loss: 1.824800665660571

Epoch: 6| Step: 3
Training loss: 0.13368743658065796
Validation loss: 1.8358459536747267

Epoch: 6| Step: 4
Training loss: 0.19747836887836456
Validation loss: 1.8227471151659567

Epoch: 6| Step: 5
Training loss: 0.23455612361431122
Validation loss: 1.8274470490794028

Epoch: 6| Step: 6
Training loss: 0.17229843139648438
Validation loss: 1.817564574621057

Epoch: 6| Step: 7
Training loss: 0.1759902834892273
Validation loss: 1.8263164335681545

Epoch: 6| Step: 8
Training loss: 0.14771677553653717
Validation loss: 1.7767631969144266

Epoch: 6| Step: 9
Training loss: 0.17124134302139282
Validation loss: 1.7923369510199434

Epoch: 6| Step: 10
Training loss: 0.1820138543844223
Validation loss: 1.810126909645655

Epoch: 6| Step: 11
Training loss: 0.13793453574180603
Validation loss: 1.8115489508516045

Epoch: 6| Step: 12
Training loss: 0.3185863196849823
Validation loss: 1.8263690164012294

Epoch: 6| Step: 13
Training loss: 0.1554158329963684
Validation loss: 1.8442983268409647

Epoch: 375| Step: 0
Training loss: 0.16599762439727783
Validation loss: 1.837982512289478

Epoch: 6| Step: 1
Training loss: 0.1652403175830841
Validation loss: 1.8633535626114055

Epoch: 6| Step: 2
Training loss: 0.21120493113994598
Validation loss: 1.849182983880402

Epoch: 6| Step: 3
Training loss: 0.1359846591949463
Validation loss: 1.8069008845154957

Epoch: 6| Step: 4
Training loss: 0.20271483063697815
Validation loss: 1.8436062130876767

Epoch: 6| Step: 5
Training loss: 0.32142651081085205
Validation loss: 1.7838329756131737

Epoch: 6| Step: 6
Training loss: 0.1511162966489792
Validation loss: 1.7919255315616567

Epoch: 6| Step: 7
Training loss: 0.4434979557991028
Validation loss: 1.7472727503827823

Epoch: 6| Step: 8
Training loss: 0.09206283837556839
Validation loss: 1.7591362794240315

Epoch: 6| Step: 9
Training loss: 0.1712198555469513
Validation loss: 1.7344761920231644

Epoch: 6| Step: 10
Training loss: 0.15163128077983856
Validation loss: 1.7942219370154924

Epoch: 6| Step: 11
Training loss: 0.32626283168792725
Validation loss: 1.7556376303395917

Epoch: 6| Step: 12
Training loss: 0.39967817068099976
Validation loss: 1.7605521627651748

Epoch: 6| Step: 13
Training loss: 0.25261855125427246
Validation loss: 1.7430018955661404

Epoch: 376| Step: 0
Training loss: 0.19211454689502716
Validation loss: 1.6965454521999563

Epoch: 6| Step: 1
Training loss: 0.3920319974422455
Validation loss: 1.7209123257667787

Epoch: 6| Step: 2
Training loss: 0.16527792811393738
Validation loss: 1.766024802320747

Epoch: 6| Step: 3
Training loss: 0.334423303604126
Validation loss: 1.7601660643854449

Epoch: 6| Step: 4
Training loss: 0.5127798914909363
Validation loss: 1.7784849636016353

Epoch: 6| Step: 5
Training loss: 0.4149644374847412
Validation loss: 1.8021205650862826

Epoch: 6| Step: 6
Training loss: 0.3109542727470398
Validation loss: 1.8116509914398193

Epoch: 6| Step: 7
Training loss: 0.20003555715084076
Validation loss: 1.82209865508541

Epoch: 6| Step: 8
Training loss: 0.14373531937599182
Validation loss: 1.8345676814356158

Epoch: 6| Step: 9
Training loss: 0.19164611399173737
Validation loss: 1.8686094284057617

Epoch: 6| Step: 10
Training loss: 0.32444116473197937
Validation loss: 1.8441468387521722

Epoch: 6| Step: 11
Training loss: 0.2115129977464676
Validation loss: 1.8750764400728288

Epoch: 6| Step: 12
Training loss: 0.16842994093894958
Validation loss: 1.8094716687356271

Epoch: 6| Step: 13
Training loss: 0.17735610902309418
Validation loss: 1.8086131388141262

Epoch: 377| Step: 0
Training loss: 0.1607522964477539
Validation loss: 1.760088582192698

Epoch: 6| Step: 1
Training loss: 0.27263766527175903
Validation loss: 1.7520345193083569

Epoch: 6| Step: 2
Training loss: 0.20325778424739838
Validation loss: 1.727293574681846

Epoch: 6| Step: 3
Training loss: 0.1486421823501587
Validation loss: 1.7631261681997648

Epoch: 6| Step: 4
Training loss: 0.44011008739471436
Validation loss: 1.7543924149646555

Epoch: 6| Step: 5
Training loss: 0.17693379521369934
Validation loss: 1.7365087668100994

Epoch: 6| Step: 6
Training loss: 0.27542558312416077
Validation loss: 1.7583304348812308

Epoch: 6| Step: 7
Training loss: 0.15386320650577545
Validation loss: 1.7916949359319543

Epoch: 6| Step: 8
Training loss: 0.1705784946680069
Validation loss: 1.780855163451164

Epoch: 6| Step: 9
Training loss: 0.2563667893409729
Validation loss: 1.803705176999492

Epoch: 6| Step: 10
Training loss: 0.22419413924217224
Validation loss: 1.8424347959538943

Epoch: 6| Step: 11
Training loss: 0.15060842037200928
Validation loss: 1.8224568764368694

Epoch: 6| Step: 12
Training loss: 0.14364250004291534
Validation loss: 1.8080688855981315

Epoch: 6| Step: 13
Training loss: 0.1572982519865036
Validation loss: 1.8800525178191483

Epoch: 378| Step: 0
Training loss: 0.23093917965888977
Validation loss: 1.8893783771863548

Epoch: 6| Step: 1
Training loss: 0.1276261955499649
Validation loss: 1.8752139723429115

Epoch: 6| Step: 2
Training loss: 0.1119597926735878
Validation loss: 1.8574453566664009

Epoch: 6| Step: 3
Training loss: 0.12147010862827301
Validation loss: 1.829293752229342

Epoch: 6| Step: 4
Training loss: 0.11866606771945953
Validation loss: 1.7979574741855744

Epoch: 6| Step: 5
Training loss: 0.2868416905403137
Validation loss: 1.7830524752216954

Epoch: 6| Step: 6
Training loss: 0.08246564865112305
Validation loss: 1.7718016114286197

Epoch: 6| Step: 7
Training loss: 0.16160160303115845
Validation loss: 1.7689445275132374

Epoch: 6| Step: 8
Training loss: 0.18010880053043365
Validation loss: 1.758061493596723

Epoch: 6| Step: 9
Training loss: 0.2244887501001358
Validation loss: 1.7336993448195919

Epoch: 6| Step: 10
Training loss: 0.19204279780387878
Validation loss: 1.7640675639593473

Epoch: 6| Step: 11
Training loss: 0.15603238344192505
Validation loss: 1.7438517873005202

Epoch: 6| Step: 12
Training loss: 0.23018878698349
Validation loss: 1.7575337194627332

Epoch: 6| Step: 13
Training loss: 0.14888995885849
Validation loss: 1.7680092088637813

Epoch: 379| Step: 0
Training loss: 0.1300017535686493
Validation loss: 1.7866896711369997

Epoch: 6| Step: 1
Training loss: 0.28767648339271545
Validation loss: 1.7859025642436037

Epoch: 6| Step: 2
Training loss: 0.16118867695331573
Validation loss: 1.8023154338200886

Epoch: 6| Step: 3
Training loss: 0.1653619408607483
Validation loss: 1.7767855685244325

Epoch: 6| Step: 4
Training loss: 0.23058371245861053
Validation loss: 1.796295126279195

Epoch: 6| Step: 5
Training loss: 0.08547339588403702
Validation loss: 1.8140917901069886

Epoch: 6| Step: 6
Training loss: 0.14536525309085846
Validation loss: 1.797038915336773

Epoch: 6| Step: 7
Training loss: 0.14377498626708984
Validation loss: 1.7706579726229432

Epoch: 6| Step: 8
Training loss: 0.18762792646884918
Validation loss: 1.7669098556682628

Epoch: 6| Step: 9
Training loss: 0.22694742679595947
Validation loss: 1.769661093270907

Epoch: 6| Step: 10
Training loss: 0.20377150177955627
Validation loss: 1.8070112671903384

Epoch: 6| Step: 11
Training loss: 0.23548494279384613
Validation loss: 1.852583674974339

Epoch: 6| Step: 12
Training loss: 0.19027018547058105
Validation loss: 1.8380591202807683

Epoch: 6| Step: 13
Training loss: 0.167441725730896
Validation loss: 1.8341354041971185

Epoch: 380| Step: 0
Training loss: 0.21517503261566162
Validation loss: 1.8096903806091638

Epoch: 6| Step: 1
Training loss: 0.25708121061325073
Validation loss: 1.840778386721047

Epoch: 6| Step: 2
Training loss: 0.15790623426437378
Validation loss: 1.8402308597359607

Epoch: 6| Step: 3
Training loss: 0.18819659948349
Validation loss: 1.8164144023772208

Epoch: 6| Step: 4
Training loss: 0.23821014165878296
Validation loss: 1.8020001060219222

Epoch: 6| Step: 5
Training loss: 0.11830300837755203
Validation loss: 1.7699752469216623

Epoch: 6| Step: 6
Training loss: 0.10999848693609238
Validation loss: 1.7037194146904895

Epoch: 6| Step: 7
Training loss: 0.16111800074577332
Validation loss: 1.721808752705974

Epoch: 6| Step: 8
Training loss: 0.31864428520202637
Validation loss: 1.7038940165632515

Epoch: 6| Step: 9
Training loss: 0.3543797731399536
Validation loss: 1.7139624626405778

Epoch: 6| Step: 10
Training loss: 0.6049680709838867
Validation loss: 1.7210100479023431

Epoch: 6| Step: 11
Training loss: 0.18040476739406586
Validation loss: 1.7136621321401289

Epoch: 6| Step: 12
Training loss: 0.18119944632053375
Validation loss: 1.7037889060153757

Epoch: 6| Step: 13
Training loss: 0.19166816771030426
Validation loss: 1.7595610721136934

Epoch: 381| Step: 0
Training loss: 0.19718191027641296
Validation loss: 1.7987529077837545

Epoch: 6| Step: 1
Training loss: 0.33344072103500366
Validation loss: 1.8394784760731522

Epoch: 6| Step: 2
Training loss: 0.11924787610769272
Validation loss: 1.8068739444978776

Epoch: 6| Step: 3
Training loss: 0.17476752400398254
Validation loss: 1.8035878045584566

Epoch: 6| Step: 4
Training loss: 0.1015935093164444
Validation loss: 1.803474336542109

Epoch: 6| Step: 5
Training loss: 0.18080182373523712
Validation loss: 1.811107374006702

Epoch: 6| Step: 6
Training loss: 0.11977891623973846
Validation loss: 1.7845789591471355

Epoch: 6| Step: 7
Training loss: 0.12600070238113403
Validation loss: 1.7789599575022215

Epoch: 6| Step: 8
Training loss: 0.11475870013237
Validation loss: 1.7782782457208122

Epoch: 6| Step: 9
Training loss: 0.13089174032211304
Validation loss: 1.7788565697208527

Epoch: 6| Step: 10
Training loss: 0.3188653886318207
Validation loss: 1.777419441489763

Epoch: 6| Step: 11
Training loss: 0.18466736376285553
Validation loss: 1.718603076473359

Epoch: 6| Step: 12
Training loss: 0.1167801171541214
Validation loss: 1.6993251756955219

Epoch: 6| Step: 13
Training loss: 0.15887881815433502
Validation loss: 1.7294285284575595

Epoch: 382| Step: 0
Training loss: 0.23137430846691132
Validation loss: 1.6900195588347733

Epoch: 6| Step: 1
Training loss: 0.25065940618515015
Validation loss: 1.735013496491217

Epoch: 6| Step: 2
Training loss: 0.13755212724208832
Validation loss: 1.7857945247363018

Epoch: 6| Step: 3
Training loss: 0.1772565096616745
Validation loss: 1.7725601375743907

Epoch: 6| Step: 4
Training loss: 0.15450826287269592
Validation loss: 1.812387122902819

Epoch: 6| Step: 5
Training loss: 0.08848642557859421
Validation loss: 1.783411575901893

Epoch: 6| Step: 6
Training loss: 0.18847346305847168
Validation loss: 1.8343272747532013

Epoch: 6| Step: 7
Training loss: 0.23696202039718628
Validation loss: 1.8341494555114417

Epoch: 6| Step: 8
Training loss: 0.1928519606590271
Validation loss: 1.8230459344002508

Epoch: 6| Step: 9
Training loss: 0.12318514287471771
Validation loss: 1.8143567116029802

Epoch: 6| Step: 10
Training loss: 0.1531551033258438
Validation loss: 1.8028514039131902

Epoch: 6| Step: 11
Training loss: 0.1404590755701065
Validation loss: 1.8536062958419963

Epoch: 6| Step: 12
Training loss: 0.14080126583576202
Validation loss: 1.7980426460184076

Epoch: 6| Step: 13
Training loss: 0.24196916818618774
Validation loss: 1.7757687055936424

Epoch: 383| Step: 0
Training loss: 0.09665104746818542
Validation loss: 1.7574441868771788

Epoch: 6| Step: 1
Training loss: 0.21444134414196014
Validation loss: 1.7464493654107536

Epoch: 6| Step: 2
Training loss: 0.19109126925468445
Validation loss: 1.7127411724418722

Epoch: 6| Step: 3
Training loss: 0.17865757644176483
Validation loss: 1.7483183042977446

Epoch: 6| Step: 4
Training loss: 0.15772953629493713
Validation loss: 1.711948678057681

Epoch: 6| Step: 5
Training loss: 0.13706094026565552
Validation loss: 1.7610639564452633

Epoch: 6| Step: 6
Training loss: 0.10955386608839035
Validation loss: 1.7733960343945412

Epoch: 6| Step: 7
Training loss: 0.09959911555051804
Validation loss: 1.781738337650094

Epoch: 6| Step: 8
Training loss: 0.336236834526062
Validation loss: 1.7586733307889713

Epoch: 6| Step: 9
Training loss: 0.13277122378349304
Validation loss: 1.8298750692798245

Epoch: 6| Step: 10
Training loss: 0.12176527082920074
Validation loss: 1.859329072378015

Epoch: 6| Step: 11
Training loss: 0.21093860268592834
Validation loss: 1.8654678483163156

Epoch: 6| Step: 12
Training loss: 0.26405757665634155
Validation loss: 1.8710578731311265

Epoch: 6| Step: 13
Training loss: 0.22808705270290375
Validation loss: 1.837601259190549

Epoch: 384| Step: 0
Training loss: 0.09890948235988617
Validation loss: 1.8155685265858967

Epoch: 6| Step: 1
Training loss: 0.21541333198547363
Validation loss: 1.7837466309147496

Epoch: 6| Step: 2
Training loss: 0.14366209506988525
Validation loss: 1.773359690943072

Epoch: 6| Step: 3
Training loss: 0.16714492440223694
Validation loss: 1.7419785107335737

Epoch: 6| Step: 4
Training loss: 0.22585824131965637
Validation loss: 1.7449788175603396

Epoch: 6| Step: 5
Training loss: 0.144309401512146
Validation loss: 1.7444777155435214

Epoch: 6| Step: 6
Training loss: 0.16815131902694702
Validation loss: 1.7360385387174544

Epoch: 6| Step: 7
Training loss: 0.11964118480682373
Validation loss: 1.7188032352796165

Epoch: 6| Step: 8
Training loss: 0.18732589483261108
Validation loss: 1.7304806734925957

Epoch: 6| Step: 9
Training loss: 0.16723421216011047
Validation loss: 1.754431728393801

Epoch: 6| Step: 10
Training loss: 0.1472112387418747
Validation loss: 1.776254246311803

Epoch: 6| Step: 11
Training loss: 0.12924396991729736
Validation loss: 1.7842335060078611

Epoch: 6| Step: 12
Training loss: 0.18402665853500366
Validation loss: 1.806400384954227

Epoch: 6| Step: 13
Training loss: 0.2574431896209717
Validation loss: 1.830220373727942

Epoch: 385| Step: 0
Training loss: 0.11302238702774048
Validation loss: 1.8186923803821686

Epoch: 6| Step: 1
Training loss: 0.13084936141967773
Validation loss: 1.8213180931665565

Epoch: 6| Step: 2
Training loss: 0.21532981097698212
Validation loss: 1.8391543293511996

Epoch: 6| Step: 3
Training loss: 0.33153316378593445
Validation loss: 1.822387920912876

Epoch: 6| Step: 4
Training loss: 0.34248271584510803
Validation loss: 1.7904984489563973

Epoch: 6| Step: 5
Training loss: 0.21086007356643677
Validation loss: 1.7881442103334653

Epoch: 6| Step: 6
Training loss: 0.10570394992828369
Validation loss: 1.7500260696616223

Epoch: 6| Step: 7
Training loss: 0.12057560682296753
Validation loss: 1.7408571256104337

Epoch: 6| Step: 8
Training loss: 0.14503872394561768
Validation loss: 1.7174589736487276

Epoch: 6| Step: 9
Training loss: 0.10824988037347794
Validation loss: 1.7655478446714339

Epoch: 6| Step: 10
Training loss: 0.21010233461856842
Validation loss: 1.748611710404837

Epoch: 6| Step: 11
Training loss: 0.3640919625759125
Validation loss: 1.7798234698592976

Epoch: 6| Step: 12
Training loss: 0.1492561399936676
Validation loss: 1.7872412140651415

Epoch: 6| Step: 13
Training loss: 0.14701324701309204
Validation loss: 1.8072017392804545

Epoch: 386| Step: 0
Training loss: 0.21221157908439636
Validation loss: 1.7907212741913334

Epoch: 6| Step: 1
Training loss: 0.26278433203697205
Validation loss: 1.8015205603773876

Epoch: 6| Step: 2
Training loss: 0.3773185610771179
Validation loss: 1.785535317595287

Epoch: 6| Step: 3
Training loss: 0.1656620055437088
Validation loss: 1.8104803357073056

Epoch: 6| Step: 4
Training loss: 0.1575157195329666
Validation loss: 1.7804513964601743

Epoch: 6| Step: 5
Training loss: 0.1865045428276062
Validation loss: 1.7622978097649031

Epoch: 6| Step: 6
Training loss: 0.1397007703781128
Validation loss: 1.8060519708100187

Epoch: 6| Step: 7
Training loss: 0.11778807640075684
Validation loss: 1.8072047336127168

Epoch: 6| Step: 8
Training loss: 0.18415206670761108
Validation loss: 1.7937514551224247

Epoch: 6| Step: 9
Training loss: 0.1536058634519577
Validation loss: 1.8132695433914021

Epoch: 6| Step: 10
Training loss: 0.17684613168239594
Validation loss: 1.7938587793739893

Epoch: 6| Step: 11
Training loss: 0.17191386222839355
Validation loss: 1.778649151966136

Epoch: 6| Step: 12
Training loss: 0.12027687579393387
Validation loss: 1.745917607379216

Epoch: 6| Step: 13
Training loss: 0.2820526659488678
Validation loss: 1.750277344898511

Epoch: 387| Step: 0
Training loss: 0.12038065493106842
Validation loss: 1.741073469961843

Epoch: 6| Step: 1
Training loss: 0.1848745346069336
Validation loss: 1.7717743727468676

Epoch: 6| Step: 2
Training loss: 0.22235941886901855
Validation loss: 1.7903681391028947

Epoch: 6| Step: 3
Training loss: 0.15263895690441132
Validation loss: 1.8000366969775128

Epoch: 6| Step: 4
Training loss: 0.12748514115810394
Validation loss: 1.7741297803899294

Epoch: 6| Step: 5
Training loss: 0.15673412382602692
Validation loss: 1.812864467661868

Epoch: 6| Step: 6
Training loss: 0.3488466143608093
Validation loss: 1.7924559257363761

Epoch: 6| Step: 7
Training loss: 0.09130945056676865
Validation loss: 1.8482817321695306

Epoch: 6| Step: 8
Training loss: 0.13743501901626587
Validation loss: 1.8883690782772597

Epoch: 6| Step: 9
Training loss: 0.11181506514549255
Validation loss: 1.8700654442592333

Epoch: 6| Step: 10
Training loss: 0.25045889616012573
Validation loss: 1.832846071130486

Epoch: 6| Step: 11
Training loss: 0.20335669815540314
Validation loss: 1.8754406923888831

Epoch: 6| Step: 12
Training loss: 0.1860554814338684
Validation loss: 1.8762779171748827

Epoch: 6| Step: 13
Training loss: 0.09890609979629517
Validation loss: 1.8147917742370276

Epoch: 388| Step: 0
Training loss: 0.13197936117649078
Validation loss: 1.7797296367665774

Epoch: 6| Step: 1
Training loss: 0.1206299439072609
Validation loss: 1.7767604884280954

Epoch: 6| Step: 2
Training loss: 0.3709908127784729
Validation loss: 1.818066443166425

Epoch: 6| Step: 3
Training loss: 0.10523159056901932
Validation loss: 1.782529966805571

Epoch: 6| Step: 4
Training loss: 0.1021026000380516
Validation loss: 1.777698701427829

Epoch: 6| Step: 5
Training loss: 0.09333954751491547
Validation loss: 1.779086241158106

Epoch: 6| Step: 6
Training loss: 0.19720444083213806
Validation loss: 1.7561663389205933

Epoch: 6| Step: 7
Training loss: 0.16199110448360443
Validation loss: 1.7327153580163115

Epoch: 6| Step: 8
Training loss: 0.1775384396314621
Validation loss: 1.7586491646305207

Epoch: 6| Step: 9
Training loss: 0.16730010509490967
Validation loss: 1.7732878667052074

Epoch: 6| Step: 10
Training loss: 0.11354538798332214
Validation loss: 1.7688120526652182

Epoch: 6| Step: 11
Training loss: 0.1503484547138214
Validation loss: 1.8146982308356994

Epoch: 6| Step: 12
Training loss: 0.21673087775707245
Validation loss: 1.8526743996527888

Epoch: 6| Step: 13
Training loss: 0.14693382382392883
Validation loss: 1.8239299815188172

Epoch: 389| Step: 0
Training loss: 0.09394583851099014
Validation loss: 1.7783169451580252

Epoch: 6| Step: 1
Training loss: 0.14005832374095917
Validation loss: 1.7818491792166105

Epoch: 6| Step: 2
Training loss: 0.14419914782047272
Validation loss: 1.7480225755322365

Epoch: 6| Step: 3
Training loss: 0.08328758925199509
Validation loss: 1.789248292164136

Epoch: 6| Step: 4
Training loss: 0.2646089196205139
Validation loss: 1.7273457819415676

Epoch: 6| Step: 5
Training loss: 0.1876000463962555
Validation loss: 1.7219116085319108

Epoch: 6| Step: 6
Training loss: 0.15791358053684235
Validation loss: 1.7515258366061794

Epoch: 6| Step: 7
Training loss: 0.156303271651268
Validation loss: 1.7837446082022883

Epoch: 6| Step: 8
Training loss: 0.35252994298934937
Validation loss: 1.7912489944888699

Epoch: 6| Step: 9
Training loss: 0.11947043240070343
Validation loss: 1.7664291358763171

Epoch: 6| Step: 10
Training loss: 0.11976408958435059
Validation loss: 1.8440209639969694

Epoch: 6| Step: 11
Training loss: 0.14127659797668457
Validation loss: 1.8234360141138877

Epoch: 6| Step: 12
Training loss: 0.1731109917163849
Validation loss: 1.842274715823512

Epoch: 6| Step: 13
Training loss: 0.2839069962501526
Validation loss: 1.8136009862346034

Epoch: 390| Step: 0
Training loss: 0.16546693444252014
Validation loss: 1.857341138265466

Epoch: 6| Step: 1
Training loss: 0.20920699834823608
Validation loss: 1.8159030650251655

Epoch: 6| Step: 2
Training loss: 0.1420523226261139
Validation loss: 1.792838906729093

Epoch: 6| Step: 3
Training loss: 0.2629873752593994
Validation loss: 1.7350114853151384

Epoch: 6| Step: 4
Training loss: 0.11780958622694016
Validation loss: 1.7563381092522734

Epoch: 6| Step: 5
Training loss: 0.2058255672454834
Validation loss: 1.7408735367559618

Epoch: 6| Step: 6
Training loss: 0.15395483374595642
Validation loss: 1.763134120613016

Epoch: 6| Step: 7
Training loss: 0.2484140247106552
Validation loss: 1.72826692622195

Epoch: 6| Step: 8
Training loss: 0.13788935542106628
Validation loss: 1.7696879051064933

Epoch: 6| Step: 9
Training loss: 0.182059645652771
Validation loss: 1.7798590634458809

Epoch: 6| Step: 10
Training loss: 0.15201130509376526
Validation loss: 1.8008917095840618

Epoch: 6| Step: 11
Training loss: 0.1726817637681961
Validation loss: 1.775830154777855

Epoch: 6| Step: 12
Training loss: 0.3950450122356415
Validation loss: 1.7834594544544016

Epoch: 6| Step: 13
Training loss: 0.18308143317699432
Validation loss: 1.8219686080050725

Epoch: 391| Step: 0
Training loss: 0.14282909035682678
Validation loss: 1.830895653334997

Epoch: 6| Step: 1
Training loss: 0.19622138142585754
Validation loss: 1.8689669498833277

Epoch: 6| Step: 2
Training loss: 0.11003750562667847
Validation loss: 1.8285061467078425

Epoch: 6| Step: 3
Training loss: 0.2127017378807068
Validation loss: 1.8476155368230676

Epoch: 6| Step: 4
Training loss: 0.16855116188526154
Validation loss: 1.8263485739308019

Epoch: 6| Step: 5
Training loss: 0.1752842664718628
Validation loss: 1.8268374012362572

Epoch: 6| Step: 6
Training loss: 0.16297462582588196
Validation loss: 1.8066779939077233

Epoch: 6| Step: 7
Training loss: 0.27410656213760376
Validation loss: 1.7973934950367096

Epoch: 6| Step: 8
Training loss: 0.3334791362285614
Validation loss: 1.7695965228542205

Epoch: 6| Step: 9
Training loss: 0.10913672298192978
Validation loss: 1.7385919837541477

Epoch: 6| Step: 10
Training loss: 0.24341052770614624
Validation loss: 1.6927809074360838

Epoch: 6| Step: 11
Training loss: 0.2703591585159302
Validation loss: 1.6786568241734658

Epoch: 6| Step: 12
Training loss: 0.31490078568458557
Validation loss: 1.700770665240544

Epoch: 6| Step: 13
Training loss: 0.20114530622959137
Validation loss: 1.7159717621341828

Epoch: 392| Step: 0
Training loss: 0.12469218671321869
Validation loss: 1.7248539296529626

Epoch: 6| Step: 1
Training loss: 0.1502149999141693
Validation loss: 1.719718945923672

Epoch: 6| Step: 2
Training loss: 0.13721920549869537
Validation loss: 1.7119382017402238

Epoch: 6| Step: 3
Training loss: 0.25685757398605347
Validation loss: 1.7126424927865305

Epoch: 6| Step: 4
Training loss: 0.1427057683467865
Validation loss: 1.756401042784414

Epoch: 6| Step: 5
Training loss: 0.09244807809591293
Validation loss: 1.7563751641140188

Epoch: 6| Step: 6
Training loss: 0.1957998275756836
Validation loss: 1.7792718743765226

Epoch: 6| Step: 7
Training loss: 0.2835160791873932
Validation loss: 1.7684846744742444

Epoch: 6| Step: 8
Training loss: 0.17035198211669922
Validation loss: 1.7804613421040196

Epoch: 6| Step: 9
Training loss: 0.1378733217716217
Validation loss: 1.7906857318775629

Epoch: 6| Step: 10
Training loss: 0.21618184447288513
Validation loss: 1.7887025507547523

Epoch: 6| Step: 11
Training loss: 0.12556736171245575
Validation loss: 1.7845534598955544

Epoch: 6| Step: 12
Training loss: 0.08650363981723785
Validation loss: 1.787028125537339

Epoch: 6| Step: 13
Training loss: 0.4224431812763214
Validation loss: 1.7857799709484141

Epoch: 393| Step: 0
Training loss: 0.10933837294578552
Validation loss: 1.7884715987790016

Epoch: 6| Step: 1
Training loss: 0.2923038601875305
Validation loss: 1.7758101442808747

Epoch: 6| Step: 2
Training loss: 0.15852031111717224
Validation loss: 1.7698941371774162

Epoch: 6| Step: 3
Training loss: 0.13768044114112854
Validation loss: 1.7909294892382879

Epoch: 6| Step: 4
Training loss: 0.17703145742416382
Validation loss: 1.7762150969556583

Epoch: 6| Step: 5
Training loss: 0.14993959665298462
Validation loss: 1.7904004461021834

Epoch: 6| Step: 6
Training loss: 0.13491234183311462
Validation loss: 1.7877016195686914

Epoch: 6| Step: 7
Training loss: 0.1601528525352478
Validation loss: 1.8049461649310203

Epoch: 6| Step: 8
Training loss: 0.15982916951179504
Validation loss: 1.8243338023462603

Epoch: 6| Step: 9
Training loss: 0.1509656310081482
Validation loss: 1.7848566386007494

Epoch: 6| Step: 10
Training loss: 0.2440524399280548
Validation loss: 1.790380811178556

Epoch: 6| Step: 11
Training loss: 0.22247955203056335
Validation loss: 1.7848576038114485

Epoch: 6| Step: 12
Training loss: 0.20994043350219727
Validation loss: 1.7935146593278455

Epoch: 6| Step: 13
Training loss: 0.11185479164123535
Validation loss: 1.7496281836622505

Epoch: 394| Step: 0
Training loss: 0.15457691252231598
Validation loss: 1.7420779889629734

Epoch: 6| Step: 1
Training loss: 0.12879754602909088
Validation loss: 1.782070731603971

Epoch: 6| Step: 2
Training loss: 0.1568947434425354
Validation loss: 1.801462870772167

Epoch: 6| Step: 3
Training loss: 0.1601390838623047
Validation loss: 1.7899963471197313

Epoch: 6| Step: 4
Training loss: 0.12562572956085205
Validation loss: 1.7658701417266682

Epoch: 6| Step: 5
Training loss: 0.17699602246284485
Validation loss: 1.780028804655998

Epoch: 6| Step: 6
Training loss: 0.15540483593940735
Validation loss: 1.803055635062597

Epoch: 6| Step: 7
Training loss: 0.19345775246620178
Validation loss: 1.8275278204230851

Epoch: 6| Step: 8
Training loss: 0.2710576057434082
Validation loss: 1.8051791908920451

Epoch: 6| Step: 9
Training loss: 0.21580693125724792
Validation loss: 1.8119027409502255

Epoch: 6| Step: 10
Training loss: 0.146347314119339
Validation loss: 1.7573176160935433

Epoch: 6| Step: 11
Training loss: 0.17010191082954407
Validation loss: 1.783995274574526

Epoch: 6| Step: 12
Training loss: 0.2911110520362854
Validation loss: 1.8015062834626885

Epoch: 6| Step: 13
Training loss: 0.08886054158210754
Validation loss: 1.7916219593376241

Epoch: 395| Step: 0
Training loss: 0.13370868563652039
Validation loss: 1.7829826595962688

Epoch: 6| Step: 1
Training loss: 0.13002541661262512
Validation loss: 1.7651200345767442

Epoch: 6| Step: 2
Training loss: 0.19277483224868774
Validation loss: 1.7812718934910272

Epoch: 6| Step: 3
Training loss: 0.19993382692337036
Validation loss: 1.7934239679767239

Epoch: 6| Step: 4
Training loss: 0.14330926537513733
Validation loss: 1.8030922579508957

Epoch: 6| Step: 5
Training loss: 0.15295636653900146
Validation loss: 1.7709561547925394

Epoch: 6| Step: 6
Training loss: 0.08175824582576752
Validation loss: 1.7755616300849504

Epoch: 6| Step: 7
Training loss: 0.1993226408958435
Validation loss: 1.7919180226582352

Epoch: 6| Step: 8
Training loss: 0.2714954912662506
Validation loss: 1.766541088781049

Epoch: 6| Step: 9
Training loss: 0.11180400848388672
Validation loss: 1.7651016545552078

Epoch: 6| Step: 10
Training loss: 0.14283287525177002
Validation loss: 1.7688417921784103

Epoch: 6| Step: 11
Training loss: 0.08353769034147263
Validation loss: 1.744643521565263

Epoch: 6| Step: 12
Training loss: 0.09064210206270218
Validation loss: 1.750477393468221

Epoch: 6| Step: 13
Training loss: 0.1278865933418274
Validation loss: 1.726822591597034

Epoch: 396| Step: 0
Training loss: 0.12376118451356888
Validation loss: 1.757027655519465

Epoch: 6| Step: 1
Training loss: 0.21070460975170135
Validation loss: 1.7657001646616126

Epoch: 6| Step: 2
Training loss: 0.1764216125011444
Validation loss: 1.7734595806367937

Epoch: 6| Step: 3
Training loss: 0.16593925654888153
Validation loss: 1.7690070521446966

Epoch: 6| Step: 4
Training loss: 0.0874636247754097
Validation loss: 1.8008436541403494

Epoch: 6| Step: 5
Training loss: 0.13642677664756775
Validation loss: 1.8159814111648067

Epoch: 6| Step: 6
Training loss: 0.14230385422706604
Validation loss: 1.8019645021807762

Epoch: 6| Step: 7
Training loss: 0.3740512728691101
Validation loss: 1.7984365404293101

Epoch: 6| Step: 8
Training loss: 0.07656381279230118
Validation loss: 1.8048724077081169

Epoch: 6| Step: 9
Training loss: 0.12325732409954071
Validation loss: 1.828406298032371

Epoch: 6| Step: 10
Training loss: 0.12549656629562378
Validation loss: 1.8000751618416078

Epoch: 6| Step: 11
Training loss: 0.0669439509510994
Validation loss: 1.7762997265784972

Epoch: 6| Step: 12
Training loss: 0.14279460906982422
Validation loss: 1.8207333075102938

Epoch: 6| Step: 13
Training loss: 0.06817473471164703
Validation loss: 1.8009677228107248

Epoch: 397| Step: 0
Training loss: 0.1342041939496994
Validation loss: 1.7860795297930319

Epoch: 6| Step: 1
Training loss: 0.08810263872146606
Validation loss: 1.7809668369190668

Epoch: 6| Step: 2
Training loss: 0.07026053220033646
Validation loss: 1.7705915140849289

Epoch: 6| Step: 3
Training loss: 0.132320374250412
Validation loss: 1.7603655425451135

Epoch: 6| Step: 4
Training loss: 0.13443690538406372
Validation loss: 1.7218119367476432

Epoch: 6| Step: 5
Training loss: 0.1455383449792862
Validation loss: 1.721247250033963

Epoch: 6| Step: 6
Training loss: 0.1875826120376587
Validation loss: 1.7179451014405938

Epoch: 6| Step: 7
Training loss: 0.27485549449920654
Validation loss: 1.7322421317459435

Epoch: 6| Step: 8
Training loss: 0.12583211064338684
Validation loss: 1.7208794791211364

Epoch: 6| Step: 9
Training loss: 0.08620946854352951
Validation loss: 1.7247914832125428

Epoch: 6| Step: 10
Training loss: 0.08298829942941666
Validation loss: 1.7699140374378493

Epoch: 6| Step: 11
Training loss: 0.10798034071922302
Validation loss: 1.7745041231955252

Epoch: 6| Step: 12
Training loss: 0.1333683580160141
Validation loss: 1.777656009120326

Epoch: 6| Step: 13
Training loss: 0.18790502846240997
Validation loss: 1.8126572421801987

Epoch: 398| Step: 0
Training loss: 0.10099096596240997
Validation loss: 1.7887589880215224

Epoch: 6| Step: 1
Training loss: 0.10863648355007172
Validation loss: 1.8033260658223143

Epoch: 6| Step: 2
Training loss: 0.08622317016124725
Validation loss: 1.797707514096332

Epoch: 6| Step: 3
Training loss: 0.13738109171390533
Validation loss: 1.7810335159301758

Epoch: 6| Step: 4
Training loss: 0.15420973300933838
Validation loss: 1.8047606970674248

Epoch: 6| Step: 5
Training loss: 0.14859792590141296
Validation loss: 1.7788869616805867

Epoch: 6| Step: 6
Training loss: 0.18989068269729614
Validation loss: 1.7796881634701964

Epoch: 6| Step: 7
Training loss: 0.1469520628452301
Validation loss: 1.8151325538594236

Epoch: 6| Step: 8
Training loss: 0.23929160833358765
Validation loss: 1.7952243384494577

Epoch: 6| Step: 9
Training loss: 0.13578347861766815
Validation loss: 1.8113931007282709

Epoch: 6| Step: 10
Training loss: 0.14294950664043427
Validation loss: 1.7864384253819783

Epoch: 6| Step: 11
Training loss: 0.2768186628818512
Validation loss: 1.7948996482356903

Epoch: 6| Step: 12
Training loss: 0.14129005372524261
Validation loss: 1.7893075096991755

Epoch: 6| Step: 13
Training loss: 0.09234622120857239
Validation loss: 1.8029091896549347

Epoch: 399| Step: 0
Training loss: 0.08330348879098892
Validation loss: 1.7770055763183101

Epoch: 6| Step: 1
Training loss: 0.09706516563892365
Validation loss: 1.8136531640124578

Epoch: 6| Step: 2
Training loss: 0.12266608327627182
Validation loss: 1.8488378678598711

Epoch: 6| Step: 3
Training loss: 0.11172337085008621
Validation loss: 1.8774319541069768

Epoch: 6| Step: 4
Training loss: 0.19385859370231628
Validation loss: 1.8886178129462785

Epoch: 6| Step: 5
Training loss: 0.31818386912345886
Validation loss: 1.8921872646577897

Epoch: 6| Step: 6
Training loss: 0.1993180811405182
Validation loss: 1.8567214140328028

Epoch: 6| Step: 7
Training loss: 0.04867057502269745
Validation loss: 1.8555332640165925

Epoch: 6| Step: 8
Training loss: 0.17042753100395203
Validation loss: 1.8711702631365867

Epoch: 6| Step: 9
Training loss: 0.17243030667304993
Validation loss: 1.8199814352937924

Epoch: 6| Step: 10
Training loss: 0.2016734480857849
Validation loss: 1.7969350763546523

Epoch: 6| Step: 11
Training loss: 0.10372437536716461
Validation loss: 1.8219232623295119

Epoch: 6| Step: 12
Training loss: 0.1678355634212494
Validation loss: 1.8019844165412329

Epoch: 6| Step: 13
Training loss: 0.1483490765094757
Validation loss: 1.8102015064608665

Epoch: 400| Step: 0
Training loss: 0.22516348958015442
Validation loss: 1.8031453855576054

Epoch: 6| Step: 1
Training loss: 0.1082639992237091
Validation loss: 1.803588709523601

Epoch: 6| Step: 2
Training loss: 0.1258939951658249
Validation loss: 1.800079584121704

Epoch: 6| Step: 3
Training loss: 0.18064692616462708
Validation loss: 1.801101065451099

Epoch: 6| Step: 4
Training loss: 0.34022679924964905
Validation loss: 1.8093644854842976

Epoch: 6| Step: 5
Training loss: 0.13533717393875122
Validation loss: 1.8281743295731083

Epoch: 6| Step: 6
Training loss: 0.21316127479076385
Validation loss: 1.863971225676998

Epoch: 6| Step: 7
Training loss: 0.24704039096832275
Validation loss: 1.9053540422070412

Epoch: 6| Step: 8
Training loss: 0.15786421298980713
Validation loss: 1.90457288424174

Epoch: 6| Step: 9
Training loss: 0.21108925342559814
Validation loss: 1.8923337510837022

Epoch: 6| Step: 10
Training loss: 0.15380211174488068
Validation loss: 1.8428849148493942

Epoch: 6| Step: 11
Training loss: 0.14338992536067963
Validation loss: 1.8446241194202053

Epoch: 6| Step: 12
Training loss: 0.19079291820526123
Validation loss: 1.8385978475693734

Epoch: 6| Step: 13
Training loss: 0.18241292238235474
Validation loss: 1.8263061841328938

Epoch: 401| Step: 0
Training loss: 0.2920500636100769
Validation loss: 1.8225360531960764

Epoch: 6| Step: 1
Training loss: 0.35363948345184326
Validation loss: 1.826289246159215

Epoch: 6| Step: 2
Training loss: 0.40599915385246277
Validation loss: 1.801122042440599

Epoch: 6| Step: 3
Training loss: 0.17861001193523407
Validation loss: 1.7868095456912954

Epoch: 6| Step: 4
Training loss: 0.2619675397872925
Validation loss: 1.7577983628037155

Epoch: 6| Step: 5
Training loss: 0.13913993537425995
Validation loss: 1.7610268131379159

Epoch: 6| Step: 6
Training loss: 0.16418325901031494
Validation loss: 1.7891937186641078

Epoch: 6| Step: 7
Training loss: 0.1229759007692337
Validation loss: 1.7911348932532853

Epoch: 6| Step: 8
Training loss: 0.2573809325695038
Validation loss: 1.8333377376679452

Epoch: 6| Step: 9
Training loss: 0.1820792853832245
Validation loss: 1.806228107021701

Epoch: 6| Step: 10
Training loss: 0.16170158982276917
Validation loss: 1.8283672589127735

Epoch: 6| Step: 11
Training loss: 0.1821194291114807
Validation loss: 1.8065337211854997

Epoch: 6| Step: 12
Training loss: 0.14390693604946136
Validation loss: 1.778463496956774

Epoch: 6| Step: 13
Training loss: 0.24093839526176453
Validation loss: 1.728931562874907

Epoch: 402| Step: 0
Training loss: 0.10281840711832047
Validation loss: 1.7288347059680569

Epoch: 6| Step: 1
Training loss: 0.12319572269916534
Validation loss: 1.7507175694229782

Epoch: 6| Step: 2
Training loss: 0.14758490025997162
Validation loss: 1.751623971487886

Epoch: 6| Step: 3
Training loss: 0.17894820868968964
Validation loss: 1.723460985768226

Epoch: 6| Step: 4
Training loss: 0.17919689416885376
Validation loss: 1.7521417025596864

Epoch: 6| Step: 5
Training loss: 0.14988398551940918
Validation loss: 1.782231552626497

Epoch: 6| Step: 6
Training loss: 0.1339806169271469
Validation loss: 1.7800089133683072

Epoch: 6| Step: 7
Training loss: 0.25664079189300537
Validation loss: 1.790995685003137

Epoch: 6| Step: 8
Training loss: 0.24534794688224792
Validation loss: 1.768478593518657

Epoch: 6| Step: 9
Training loss: 0.16147327423095703
Validation loss: 1.8080262573816444

Epoch: 6| Step: 10
Training loss: 0.19150325655937195
Validation loss: 1.7729605808052966

Epoch: 6| Step: 11
Training loss: 0.14297543466091156
Validation loss: 1.7691351034307992

Epoch: 6| Step: 12
Training loss: 0.3045387864112854
Validation loss: 1.7690366250212475

Epoch: 6| Step: 13
Training loss: 0.11110891401767731
Validation loss: 1.7671915279921664

Epoch: 403| Step: 0
Training loss: 0.0728428065776825
Validation loss: 1.7620416302834787

Epoch: 6| Step: 1
Training loss: 0.10798144340515137
Validation loss: 1.7798136677793277

Epoch: 6| Step: 2
Training loss: 0.14141042530536652
Validation loss: 1.7799630472736974

Epoch: 6| Step: 3
Training loss: 0.06936412304639816
Validation loss: 1.7957882458163845

Epoch: 6| Step: 4
Training loss: 0.11580745130777359
Validation loss: 1.7603706935400605

Epoch: 6| Step: 5
Training loss: 0.1137818917632103
Validation loss: 1.7795831195769771

Epoch: 6| Step: 6
Training loss: 0.19418370723724365
Validation loss: 1.7991968662508073

Epoch: 6| Step: 7
Training loss: 0.15984097123146057
Validation loss: 1.80409590659603

Epoch: 6| Step: 8
Training loss: 0.16368132829666138
Validation loss: 1.7637094515626148

Epoch: 6| Step: 9
Training loss: 0.17723874747753143
Validation loss: 1.7862356234622259

Epoch: 6| Step: 10
Training loss: 0.21911871433258057
Validation loss: 1.7434895269332393

Epoch: 6| Step: 11
Training loss: 0.0716129019856453
Validation loss: 1.7704131346876903

Epoch: 6| Step: 12
Training loss: 0.11234517395496368
Validation loss: 1.775449308015967

Epoch: 6| Step: 13
Training loss: 0.36989450454711914
Validation loss: 1.7728523951704784

Epoch: 404| Step: 0
Training loss: 0.2048511803150177
Validation loss: 1.7548295554294382

Epoch: 6| Step: 1
Training loss: 0.11891424655914307
Validation loss: 1.7726300474136107

Epoch: 6| Step: 2
Training loss: 0.1317407637834549
Validation loss: 1.789317015678652

Epoch: 6| Step: 3
Training loss: 0.23350101709365845
Validation loss: 1.7983193218067128

Epoch: 6| Step: 4
Training loss: 0.12950429320335388
Validation loss: 1.796347855239786

Epoch: 6| Step: 5
Training loss: 0.174732506275177
Validation loss: 1.752352923475286

Epoch: 6| Step: 6
Training loss: 0.13385139405727386
Validation loss: 1.8242906549925446

Epoch: 6| Step: 7
Training loss: 0.12901176512241364
Validation loss: 1.7459974673486525

Epoch: 6| Step: 8
Training loss: 0.12496411055326462
Validation loss: 1.752584400997367

Epoch: 6| Step: 9
Training loss: 0.14539191126823425
Validation loss: 1.7606286271925895

Epoch: 6| Step: 10
Training loss: 0.1772584617137909
Validation loss: 1.7560020198104203

Epoch: 6| Step: 11
Training loss: 0.22658255696296692
Validation loss: 1.7430223111183412

Epoch: 6| Step: 12
Training loss: 0.15517160296440125
Validation loss: 1.7614621782815585

Epoch: 6| Step: 13
Training loss: 0.1856738030910492
Validation loss: 1.7469894040015437

Epoch: 405| Step: 0
Training loss: 0.09606102854013443
Validation loss: 1.8105008076596003

Epoch: 6| Step: 1
Training loss: 0.14250898361206055
Validation loss: 1.7931791108141664

Epoch: 6| Step: 2
Training loss: 0.2629939913749695
Validation loss: 1.7674808861106954

Epoch: 6| Step: 3
Training loss: 0.1211685836315155
Validation loss: 1.7812375112246441

Epoch: 6| Step: 4
Training loss: 0.14910253882408142
Validation loss: 1.7720640410659134

Epoch: 6| Step: 5
Training loss: 0.14307226240634918
Validation loss: 1.8133864389952792

Epoch: 6| Step: 6
Training loss: 0.14303666353225708
Validation loss: 1.8197461789654148

Epoch: 6| Step: 7
Training loss: 0.1662592887878418
Validation loss: 1.8158963700776458

Epoch: 6| Step: 8
Training loss: 0.1481277495622635
Validation loss: 1.8051647614407282

Epoch: 6| Step: 9
Training loss: 0.18987029790878296
Validation loss: 1.7564677423046482

Epoch: 6| Step: 10
Training loss: 0.11859826743602753
Validation loss: 1.7841355710901239

Epoch: 6| Step: 11
Training loss: 0.12176935374736786
Validation loss: 1.7900082231849752

Epoch: 6| Step: 12
Training loss: 0.0723346471786499
Validation loss: 1.7849491706458471

Epoch: 6| Step: 13
Training loss: 0.14386524260044098
Validation loss: 1.8258824053631033

Epoch: 406| Step: 0
Training loss: 0.14931079745292664
Validation loss: 1.818059935364672

Epoch: 6| Step: 1
Training loss: 0.08027542382478714
Validation loss: 1.7745086839122157

Epoch: 6| Step: 2
Training loss: 0.09997933357954025
Validation loss: 1.7654221878256848

Epoch: 6| Step: 3
Training loss: 0.10453549027442932
Validation loss: 1.777131695901194

Epoch: 6| Step: 4
Training loss: 0.09458364546298981
Validation loss: 1.7569102843602498

Epoch: 6| Step: 5
Training loss: 0.07685220241546631
Validation loss: 1.7562964577828684

Epoch: 6| Step: 6
Training loss: 0.1523856371641159
Validation loss: 1.7589440858492287

Epoch: 6| Step: 7
Training loss: 0.17983834445476532
Validation loss: 1.7646592099179503

Epoch: 6| Step: 8
Training loss: 0.20779305696487427
Validation loss: 1.7601346495330974

Epoch: 6| Step: 9
Training loss: 0.21858008205890656
Validation loss: 1.78032753416287

Epoch: 6| Step: 10
Training loss: 0.19986826181411743
Validation loss: 1.7590194081747403

Epoch: 6| Step: 11
Training loss: 0.21429821848869324
Validation loss: 1.760448419919578

Epoch: 6| Step: 12
Training loss: 0.13880887627601624
Validation loss: 1.7414117500346193

Epoch: 6| Step: 13
Training loss: 0.12016076594591141
Validation loss: 1.7286787366354337

Epoch: 407| Step: 0
Training loss: 0.1353718638420105
Validation loss: 1.7503080714133479

Epoch: 6| Step: 1
Training loss: 0.09111129492521286
Validation loss: 1.7485207242350425

Epoch: 6| Step: 2
Training loss: 0.11402156203985214
Validation loss: 1.732990813511674

Epoch: 6| Step: 3
Training loss: 0.28966963291168213
Validation loss: 1.7395955413900397

Epoch: 6| Step: 4
Training loss: 0.17397049069404602
Validation loss: 1.7284482973878101

Epoch: 6| Step: 5
Training loss: 0.16024771332740784
Validation loss: 1.7374896554536716

Epoch: 6| Step: 6
Training loss: 0.1779596209526062
Validation loss: 1.7272545240258659

Epoch: 6| Step: 7
Training loss: 0.09436634927988052
Validation loss: 1.7722431446916314

Epoch: 6| Step: 8
Training loss: 0.1417967975139618
Validation loss: 1.783803137399817

Epoch: 6| Step: 9
Training loss: 0.07703515887260437
Validation loss: 1.7757723895452355

Epoch: 6| Step: 10
Training loss: 0.21639370918273926
Validation loss: 1.78465703610451

Epoch: 6| Step: 11
Training loss: 0.15734365582466125
Validation loss: 1.7523916254761398

Epoch: 6| Step: 12
Training loss: 0.11990276724100113
Validation loss: 1.7812220178624636

Epoch: 6| Step: 13
Training loss: 0.26302823424339294
Validation loss: 1.7480234151245446

Epoch: 408| Step: 0
Training loss: 0.09713032841682434
Validation loss: 1.7498565514882405

Epoch: 6| Step: 1
Training loss: 0.17788070440292358
Validation loss: 1.7315588446073635

Epoch: 6| Step: 2
Training loss: 0.17842695116996765
Validation loss: 1.734275633288968

Epoch: 6| Step: 3
Training loss: 0.12188805639743805
Validation loss: 1.7101067907066756

Epoch: 6| Step: 4
Training loss: 0.22447171807289124
Validation loss: 1.7234298567618094

Epoch: 6| Step: 5
Training loss: 0.12847855687141418
Validation loss: 1.7452804811539189

Epoch: 6| Step: 6
Training loss: 0.35806795954704285
Validation loss: 1.77769148477944

Epoch: 6| Step: 7
Training loss: 0.1571333408355713
Validation loss: 1.760103089835054

Epoch: 6| Step: 8
Training loss: 0.071859210729599
Validation loss: 1.8268463688512002

Epoch: 6| Step: 9
Training loss: 0.18421773612499237
Validation loss: 1.8053398081051406

Epoch: 6| Step: 10
Training loss: 0.11225489526987076
Validation loss: 1.838199928242673

Epoch: 6| Step: 11
Training loss: 0.13773082196712494
Validation loss: 1.8260414715736144

Epoch: 6| Step: 12
Training loss: 0.20712432265281677
Validation loss: 1.8521834701620123

Epoch: 6| Step: 13
Training loss: 0.24925321340560913
Validation loss: 1.78514011444584

Epoch: 409| Step: 0
Training loss: 0.09647054970264435
Validation loss: 1.7719591856002808

Epoch: 6| Step: 1
Training loss: 0.10215304791927338
Validation loss: 1.7804335701850154

Epoch: 6| Step: 2
Training loss: 0.150919109582901
Validation loss: 1.7575965081491778

Epoch: 6| Step: 3
Training loss: 0.13791191577911377
Validation loss: 1.7611272693962179

Epoch: 6| Step: 4
Training loss: 0.17226505279541016
Validation loss: 1.738392012093657

Epoch: 6| Step: 5
Training loss: 0.16666841506958008
Validation loss: 1.7453388526875486

Epoch: 6| Step: 6
Training loss: 0.20110969245433807
Validation loss: 1.7175656710901568

Epoch: 6| Step: 7
Training loss: 0.1516839861869812
Validation loss: 1.7051393870384461

Epoch: 6| Step: 8
Training loss: 0.13900303840637207
Validation loss: 1.6978751587611374

Epoch: 6| Step: 9
Training loss: 0.12202168256044388
Validation loss: 1.7147339467079408

Epoch: 6| Step: 10
Training loss: 0.24685025215148926
Validation loss: 1.7179840200690812

Epoch: 6| Step: 11
Training loss: 0.19418787956237793
Validation loss: 1.7412791559773106

Epoch: 6| Step: 12
Training loss: 0.23574134707450867
Validation loss: 1.7314114724436114

Epoch: 6| Step: 13
Training loss: 0.1471763700246811
Validation loss: 1.6995113331784484

Epoch: 410| Step: 0
Training loss: 0.13072741031646729
Validation loss: 1.714237779699346

Epoch: 6| Step: 1
Training loss: 0.12228579819202423
Validation loss: 1.688334257371964

Epoch: 6| Step: 2
Training loss: 0.11453992128372192
Validation loss: 1.7367849824249104

Epoch: 6| Step: 3
Training loss: 0.19100740551948547
Validation loss: 1.7244340142896097

Epoch: 6| Step: 4
Training loss: 0.13227510452270508
Validation loss: 1.7226783460186375

Epoch: 6| Step: 5
Training loss: 0.09609167277812958
Validation loss: 1.7273433093101747

Epoch: 6| Step: 6
Training loss: 0.11429047584533691
Validation loss: 1.7432710188691334

Epoch: 6| Step: 7
Training loss: 0.10206063836812973
Validation loss: 1.7304071957065212

Epoch: 6| Step: 8
Training loss: 0.15430137515068054
Validation loss: 1.7460112622989121

Epoch: 6| Step: 9
Training loss: 0.09662771224975586
Validation loss: 1.7285764307104132

Epoch: 6| Step: 10
Training loss: 0.12436871230602264
Validation loss: 1.7320966951308712

Epoch: 6| Step: 11
Training loss: 0.25534263253211975
Validation loss: 1.7228662608772196

Epoch: 6| Step: 12
Training loss: 0.19285406172275543
Validation loss: 1.7534443332302956

Epoch: 6| Step: 13
Training loss: 0.18028463423252106
Validation loss: 1.7488687294785694

Epoch: 411| Step: 0
Training loss: 0.12927652895450592
Validation loss: 1.7826360528187086

Epoch: 6| Step: 1
Training loss: 0.09979125112295151
Validation loss: 1.7410128962609075

Epoch: 6| Step: 2
Training loss: 0.21387286484241486
Validation loss: 1.7524454337294384

Epoch: 6| Step: 3
Training loss: 0.09495076537132263
Validation loss: 1.7414844664194251

Epoch: 6| Step: 4
Training loss: 0.14449012279510498
Validation loss: 1.71540315176851

Epoch: 6| Step: 5
Training loss: 0.14853529632091522
Validation loss: 1.7597905333324144

Epoch: 6| Step: 6
Training loss: 0.16393481194972992
Validation loss: 1.7563947926285446

Epoch: 6| Step: 7
Training loss: 0.09817509353160858
Validation loss: 1.756456337949281

Epoch: 6| Step: 8
Training loss: 0.12836317718029022
Validation loss: 1.7683834850147206

Epoch: 6| Step: 9
Training loss: 0.11998807638883591
Validation loss: 1.7691362903964134

Epoch: 6| Step: 10
Training loss: 0.1360672414302826
Validation loss: 1.7683063578862015

Epoch: 6| Step: 11
Training loss: 0.1275528073310852
Validation loss: 1.7417948912548762

Epoch: 6| Step: 12
Training loss: 0.11420406401157379
Validation loss: 1.7613423562818957

Epoch: 6| Step: 13
Training loss: 0.1000279039144516
Validation loss: 1.7447117554244174

Epoch: 412| Step: 0
Training loss: 0.05648074671626091
Validation loss: 1.7754430104327459

Epoch: 6| Step: 1
Training loss: 0.12880808115005493
Validation loss: 1.8084382395590506

Epoch: 6| Step: 2
Training loss: 0.07970428466796875
Validation loss: 1.7908666454335695

Epoch: 6| Step: 3
Training loss: 0.15586206316947937
Validation loss: 1.7811229946792766

Epoch: 6| Step: 4
Training loss: 0.24640655517578125
Validation loss: 1.7865038289818713

Epoch: 6| Step: 5
Training loss: 0.09081993997097015
Validation loss: 1.7454760612980011

Epoch: 6| Step: 6
Training loss: 0.14086028933525085
Validation loss: 1.739495413277739

Epoch: 6| Step: 7
Training loss: 0.14819301664829254
Validation loss: 1.7252579953080864

Epoch: 6| Step: 8
Training loss: 0.36639612913131714
Validation loss: 1.6790375151941854

Epoch: 6| Step: 9
Training loss: 0.17864371836185455
Validation loss: 1.7246183631240681

Epoch: 6| Step: 10
Training loss: 0.12352238595485687
Validation loss: 1.7127893765767415

Epoch: 6| Step: 11
Training loss: 0.146953284740448
Validation loss: 1.7289309604193575

Epoch: 6| Step: 12
Training loss: 0.13287508487701416
Validation loss: 1.7297799638522569

Epoch: 6| Step: 13
Training loss: 0.1851361095905304
Validation loss: 1.7469389951357277

Epoch: 413| Step: 0
Training loss: 0.09511822462081909
Validation loss: 1.7655281430931502

Epoch: 6| Step: 1
Training loss: 0.09594905376434326
Validation loss: 1.7458242088235834

Epoch: 6| Step: 2
Training loss: 0.09737497568130493
Validation loss: 1.8041469973902549

Epoch: 6| Step: 3
Training loss: 0.1533922255039215
Validation loss: 1.758044840187155

Epoch: 6| Step: 4
Training loss: 0.21097718179225922
Validation loss: 1.7985288455922117

Epoch: 6| Step: 5
Training loss: 0.10201454162597656
Validation loss: 1.7889642343726209

Epoch: 6| Step: 6
Training loss: 0.1311752200126648
Validation loss: 1.7788545598265946

Epoch: 6| Step: 7
Training loss: 0.11955990642309189
Validation loss: 1.768465712506284

Epoch: 6| Step: 8
Training loss: 0.1134384498000145
Validation loss: 1.7603901624679565

Epoch: 6| Step: 9
Training loss: 0.1555139124393463
Validation loss: 1.7406491585957107

Epoch: 6| Step: 10
Training loss: 0.19265693426132202
Validation loss: 1.7260983118446924

Epoch: 6| Step: 11
Training loss: 0.4175013303756714
Validation loss: 1.7320076496370378

Epoch: 6| Step: 12
Training loss: 0.15958626568317413
Validation loss: 1.7446500460306804

Epoch: 6| Step: 13
Training loss: 0.20973581075668335
Validation loss: 1.7658808385172198

Epoch: 414| Step: 0
Training loss: 0.09495358169078827
Validation loss: 1.7434785507058586

Epoch: 6| Step: 1
Training loss: 0.1212555542588234
Validation loss: 1.7623501785339848

Epoch: 6| Step: 2
Training loss: 0.1507418304681778
Validation loss: 1.7793705232681767

Epoch: 6| Step: 3
Training loss: 0.23524576425552368
Validation loss: 1.79870988733025

Epoch: 6| Step: 4
Training loss: 0.24213317036628723
Validation loss: 1.7887975169766335

Epoch: 6| Step: 5
Training loss: 0.19120754301548004
Validation loss: 1.7690167119426112

Epoch: 6| Step: 6
Training loss: 0.12785880267620087
Validation loss: 1.768055582559237

Epoch: 6| Step: 7
Training loss: 0.19199693202972412
Validation loss: 1.7795088329622823

Epoch: 6| Step: 8
Training loss: 0.21417281031608582
Validation loss: 1.7405379485058528

Epoch: 6| Step: 9
Training loss: 0.08709268271923065
Validation loss: 1.7348299129034883

Epoch: 6| Step: 10
Training loss: 0.09069350361824036
Validation loss: 1.7568096986380957

Epoch: 6| Step: 11
Training loss: 0.22904634475708008
Validation loss: 1.741229546967373

Epoch: 6| Step: 12
Training loss: 0.2093605250120163
Validation loss: 1.7448453057196833

Epoch: 6| Step: 13
Training loss: 0.09880173206329346
Validation loss: 1.7403549660918534

Epoch: 415| Step: 0
Training loss: 0.13885486125946045
Validation loss: 1.7752750304437452

Epoch: 6| Step: 1
Training loss: 0.12531116604804993
Validation loss: 1.7979494128175961

Epoch: 6| Step: 2
Training loss: 0.07659836858510971
Validation loss: 1.8102107022398262

Epoch: 6| Step: 3
Training loss: 0.16433799266815186
Validation loss: 1.7764386887191443

Epoch: 6| Step: 4
Training loss: 0.13336335122585297
Validation loss: 1.8032149243098434

Epoch: 6| Step: 5
Training loss: 0.1984570324420929
Validation loss: 1.8140664113465177

Epoch: 6| Step: 6
Training loss: 0.10818468034267426
Validation loss: 1.7985789275938464

Epoch: 6| Step: 7
Training loss: 0.30442067980766296
Validation loss: 1.7450495535327541

Epoch: 6| Step: 8
Training loss: 0.1870950311422348
Validation loss: 1.7372720946547806

Epoch: 6| Step: 9
Training loss: 0.14144252240657806
Validation loss: 1.7595532209642473

Epoch: 6| Step: 10
Training loss: 0.0817096084356308
Validation loss: 1.764102292317216

Epoch: 6| Step: 11
Training loss: 0.1078893318772316
Validation loss: 1.7627971351787608

Epoch: 6| Step: 12
Training loss: 0.17048129439353943
Validation loss: 1.7610407170429025

Epoch: 6| Step: 13
Training loss: 0.14979039132595062
Validation loss: 1.7503655354181926

Epoch: 416| Step: 0
Training loss: 0.11726577579975128
Validation loss: 1.7655891321038688

Epoch: 6| Step: 1
Training loss: 0.09717147052288055
Validation loss: 1.7517241585639216

Epoch: 6| Step: 2
Training loss: 0.14529003202915192
Validation loss: 1.7483673146975938

Epoch: 6| Step: 3
Training loss: 0.15977641940116882
Validation loss: 1.7710127087049587

Epoch: 6| Step: 4
Training loss: 0.10286800563335419
Validation loss: 1.75356625997892

Epoch: 6| Step: 5
Training loss: 0.16369792819023132
Validation loss: 1.8051542287231774

Epoch: 6| Step: 6
Training loss: 0.0798659399151802
Validation loss: 1.7881514923546904

Epoch: 6| Step: 7
Training loss: 0.11904546618461609
Validation loss: 1.7895750281631306

Epoch: 6| Step: 8
Training loss: 0.24114204943180084
Validation loss: 1.7619924660651916

Epoch: 6| Step: 9
Training loss: 0.06976491212844849
Validation loss: 1.7693686895473029

Epoch: 6| Step: 10
Training loss: 0.1040276437997818
Validation loss: 1.7605436258418585

Epoch: 6| Step: 11
Training loss: 0.14237521588802338
Validation loss: 1.7678522717568181

Epoch: 6| Step: 12
Training loss: 0.16372722387313843
Validation loss: 1.7589397917511642

Epoch: 6| Step: 13
Training loss: 0.10622838884592056
Validation loss: 1.7883020972692838

Epoch: 417| Step: 0
Training loss: 0.11665816605091095
Validation loss: 1.7641593346031763

Epoch: 6| Step: 1
Training loss: 0.10466326773166656
Validation loss: 1.7844282170777679

Epoch: 6| Step: 2
Training loss: 0.22390905022621155
Validation loss: 1.8058665696010794

Epoch: 6| Step: 3
Training loss: 0.11150297522544861
Validation loss: 1.7799262231396091

Epoch: 6| Step: 4
Training loss: 0.23552343249320984
Validation loss: 1.7811191389637608

Epoch: 6| Step: 5
Training loss: 0.09518484026193619
Validation loss: 1.7592088599358835

Epoch: 6| Step: 6
Training loss: 0.14587844908237457
Validation loss: 1.7891939686190697

Epoch: 6| Step: 7
Training loss: 0.17547893524169922
Validation loss: 1.7672506019633303

Epoch: 6| Step: 8
Training loss: 0.1314913034439087
Validation loss: 1.7509104180079635

Epoch: 6| Step: 9
Training loss: 0.136199951171875
Validation loss: 1.748861018047538

Epoch: 6| Step: 10
Training loss: 0.16215349733829498
Validation loss: 1.7524216815989504

Epoch: 6| Step: 11
Training loss: 0.17003658413887024
Validation loss: 1.754259092833406

Epoch: 6| Step: 12
Training loss: 0.17502163350582123
Validation loss: 1.7758101647899998

Epoch: 6| Step: 13
Training loss: 0.07398782670497894
Validation loss: 1.753380888251848

Epoch: 418| Step: 0
Training loss: 0.07628278434276581
Validation loss: 1.7616581045171267

Epoch: 6| Step: 1
Training loss: 0.10954586416482925
Validation loss: 1.7688311581970544

Epoch: 6| Step: 2
Training loss: 0.12066376209259033
Validation loss: 1.7773997270932762

Epoch: 6| Step: 3
Training loss: 0.11569544672966003
Validation loss: 1.756229131452499

Epoch: 6| Step: 4
Training loss: 0.15286794304847717
Validation loss: 1.7695543471203055

Epoch: 6| Step: 5
Training loss: 0.3543316423892975
Validation loss: 1.7517519868830198

Epoch: 6| Step: 6
Training loss: 0.09155887365341187
Validation loss: 1.755277660585219

Epoch: 6| Step: 7
Training loss: 0.09489608556032181
Validation loss: 1.7060507497479838

Epoch: 6| Step: 8
Training loss: 0.06405747681856155
Validation loss: 1.746019906895135

Epoch: 6| Step: 9
Training loss: 0.13551181554794312
Validation loss: 1.7512438451090167

Epoch: 6| Step: 10
Training loss: 0.11251907795667648
Validation loss: 1.7135204153676187

Epoch: 6| Step: 11
Training loss: 0.13353607058525085
Validation loss: 1.7422377255655104

Epoch: 6| Step: 12
Training loss: 0.09759145975112915
Validation loss: 1.7537252082619617

Epoch: 6| Step: 13
Training loss: 0.10837098956108093
Validation loss: 1.739501686506374

Epoch: 419| Step: 0
Training loss: 0.13827291131019592
Validation loss: 1.7691095682882494

Epoch: 6| Step: 1
Training loss: 0.11132871359586716
Validation loss: 1.7557825657629198

Epoch: 6| Step: 2
Training loss: 0.08724571764469147
Validation loss: 1.7798322041829426

Epoch: 6| Step: 3
Training loss: 0.09819618612527847
Validation loss: 1.792194522837157

Epoch: 6| Step: 4
Training loss: 0.11695708334445953
Validation loss: 1.751490649356637

Epoch: 6| Step: 5
Training loss: 0.10671912878751755
Validation loss: 1.7120352893747308

Epoch: 6| Step: 6
Training loss: 0.19824671745300293
Validation loss: 1.7193929924759814

Epoch: 6| Step: 7
Training loss: 0.05140781030058861
Validation loss: 1.7038867114692606

Epoch: 6| Step: 8
Training loss: 0.12445449084043503
Validation loss: 1.6826121396915887

Epoch: 6| Step: 9
Training loss: 0.0988309383392334
Validation loss: 1.6841970310416272

Epoch: 6| Step: 10
Training loss: 0.23848141729831696
Validation loss: 1.6767421653193813

Epoch: 6| Step: 11
Training loss: 0.11900646239519119
Validation loss: 1.7353715550514959

Epoch: 6| Step: 12
Training loss: 0.2079395353794098
Validation loss: 1.7148498835102204

Epoch: 6| Step: 13
Training loss: 0.1483478844165802
Validation loss: 1.7169287243197042

Epoch: 420| Step: 0
Training loss: 0.15435302257537842
Validation loss: 1.7225815288482174

Epoch: 6| Step: 1
Training loss: 0.14403940737247467
Validation loss: 1.7153533607400873

Epoch: 6| Step: 2
Training loss: 0.1018269956111908
Validation loss: 1.7104878476870957

Epoch: 6| Step: 3
Training loss: 0.06580816954374313
Validation loss: 1.7162211607861262

Epoch: 6| Step: 4
Training loss: 0.1744777411222458
Validation loss: 1.721080804383883

Epoch: 6| Step: 5
Training loss: 0.16342708468437195
Validation loss: 1.7213997251244002

Epoch: 6| Step: 6
Training loss: 0.25855374336242676
Validation loss: 1.7573590099170644

Epoch: 6| Step: 7
Training loss: 0.1569400578737259
Validation loss: 1.760759868929463

Epoch: 6| Step: 8
Training loss: 0.13586878776550293
Validation loss: 1.7296126222097745

Epoch: 6| Step: 9
Training loss: 0.12121900916099548
Validation loss: 1.710256330428585

Epoch: 6| Step: 10
Training loss: 0.11410550028085709
Validation loss: 1.7352718422489781

Epoch: 6| Step: 11
Training loss: 0.13924309611320496
Validation loss: 1.718833759266843

Epoch: 6| Step: 12
Training loss: 0.14145371317863464
Validation loss: 1.6930818826921525

Epoch: 6| Step: 13
Training loss: 0.13895970582962036
Validation loss: 1.738397127838545

Epoch: 421| Step: 0
Training loss: 0.2224588245153427
Validation loss: 1.7201213272668983

Epoch: 6| Step: 1
Training loss: 0.1073644608259201
Validation loss: 1.7550987723053142

Epoch: 6| Step: 2
Training loss: 0.13016633689403534
Validation loss: 1.7361758139825636

Epoch: 6| Step: 3
Training loss: 0.21355149149894714
Validation loss: 1.7570127633310133

Epoch: 6| Step: 4
Training loss: 0.17882907390594482
Validation loss: 1.7363814923071093

Epoch: 6| Step: 5
Training loss: 0.18166282773017883
Validation loss: 1.724258404906078

Epoch: 6| Step: 6
Training loss: 0.11388207972049713
Validation loss: 1.7642197903766428

Epoch: 6| Step: 7
Training loss: 0.14027392864227295
Validation loss: 1.7462710039589995

Epoch: 6| Step: 8
Training loss: 0.13590222597122192
Validation loss: 1.7604992197405906

Epoch: 6| Step: 9
Training loss: 0.14675550162792206
Validation loss: 1.734546894668251

Epoch: 6| Step: 10
Training loss: 0.139041006565094
Validation loss: 1.7733696494051205

Epoch: 6| Step: 11
Training loss: 0.10581492632627487
Validation loss: 1.7731121278578235

Epoch: 6| Step: 12
Training loss: 0.17763414978981018
Validation loss: 1.7492750870284213

Epoch: 6| Step: 13
Training loss: 0.1402011662721634
Validation loss: 1.768239818593507

Epoch: 422| Step: 0
Training loss: 0.1323462724685669
Validation loss: 1.7357188027392152

Epoch: 6| Step: 1
Training loss: 0.15403345227241516
Validation loss: 1.7359364340382237

Epoch: 6| Step: 2
Training loss: 0.07520678639411926
Validation loss: 1.7242734983403196

Epoch: 6| Step: 3
Training loss: 0.10234872251749039
Validation loss: 1.7207202526830858

Epoch: 6| Step: 4
Training loss: 0.059145838022232056
Validation loss: 1.731351255088724

Epoch: 6| Step: 5
Training loss: 0.17749503254890442
Validation loss: 1.7126271378609441

Epoch: 6| Step: 6
Training loss: 0.07284202426671982
Validation loss: 1.699605066289184

Epoch: 6| Step: 7
Training loss: 0.18859368562698364
Validation loss: 1.7431902603436542

Epoch: 6| Step: 8
Training loss: 0.12969112396240234
Validation loss: 1.7135131897464875

Epoch: 6| Step: 9
Training loss: 0.14805227518081665
Validation loss: 1.6885837765150173

Epoch: 6| Step: 10
Training loss: 0.11051527410745621
Validation loss: 1.7422230230864657

Epoch: 6| Step: 11
Training loss: 0.11849585175514221
Validation loss: 1.7204728959709086

Epoch: 6| Step: 12
Training loss: 0.08020229637622833
Validation loss: 1.720853103104458

Epoch: 6| Step: 13
Training loss: 0.3349943161010742
Validation loss: 1.7122498020049064

Epoch: 423| Step: 0
Training loss: 0.07732102274894714
Validation loss: 1.7504343140509822

Epoch: 6| Step: 1
Training loss: 0.10335443913936615
Validation loss: 1.7574768220224688

Epoch: 6| Step: 2
Training loss: 0.060302481055259705
Validation loss: 1.7377297493719286

Epoch: 6| Step: 3
Training loss: 0.1500096172094345
Validation loss: 1.747183781798168

Epoch: 6| Step: 4
Training loss: 0.1408146470785141
Validation loss: 1.7679884510655557

Epoch: 6| Step: 5
Training loss: 0.18987661600112915
Validation loss: 1.7644059337595457

Epoch: 6| Step: 6
Training loss: 0.2453017234802246
Validation loss: 1.7909574841940274

Epoch: 6| Step: 7
Training loss: 0.14709073305130005
Validation loss: 1.745728672191661

Epoch: 6| Step: 8
Training loss: 0.08924572169780731
Validation loss: 1.7438886165618896

Epoch: 6| Step: 9
Training loss: 0.12387622147798538
Validation loss: 1.7218917877443376

Epoch: 6| Step: 10
Training loss: 0.15305431187152863
Validation loss: 1.7292663512691375

Epoch: 6| Step: 11
Training loss: 0.07354117929935455
Validation loss: 1.7242638167514597

Epoch: 6| Step: 12
Training loss: 0.1426599770784378
Validation loss: 1.7091004207570066

Epoch: 6| Step: 13
Training loss: 0.1351252943277359
Validation loss: 1.7540986909661243

Epoch: 424| Step: 0
Training loss: 0.1256323903799057
Validation loss: 1.7146124762873496

Epoch: 6| Step: 1
Training loss: 0.09785762429237366
Validation loss: 1.7082220508206276

Epoch: 6| Step: 2
Training loss: 0.14587029814720154
Validation loss: 1.7337278973671697

Epoch: 6| Step: 3
Training loss: 0.12287414073944092
Validation loss: 1.7346857581087338

Epoch: 6| Step: 4
Training loss: 0.10149587690830231
Validation loss: 1.768165010277943

Epoch: 6| Step: 5
Training loss: 0.13548316061496735
Validation loss: 1.7830016151551278

Epoch: 6| Step: 6
Training loss: 0.20088180899620056
Validation loss: 1.7793057682693645

Epoch: 6| Step: 7
Training loss: 0.10704725980758667
Validation loss: 1.7665904542451263

Epoch: 6| Step: 8
Training loss: 0.13773900270462036
Validation loss: 1.7714415647650277

Epoch: 6| Step: 9
Training loss: 0.09445834904909134
Validation loss: 1.7296094432953866

Epoch: 6| Step: 10
Training loss: 0.12539753317832947
Validation loss: 1.750288046816344

Epoch: 6| Step: 11
Training loss: 0.09426688402891159
Validation loss: 1.703272206808931

Epoch: 6| Step: 12
Training loss: 0.13654837012290955
Validation loss: 1.7079083637524677

Epoch: 6| Step: 13
Training loss: 0.4532833695411682
Validation loss: 1.6786449147808937

Epoch: 425| Step: 0
Training loss: 0.18695975840091705
Validation loss: 1.6824462375333231

Epoch: 6| Step: 1
Training loss: 0.10945487022399902
Validation loss: 1.667891243452667

Epoch: 6| Step: 2
Training loss: 0.12947142124176025
Validation loss: 1.6795419813484274

Epoch: 6| Step: 3
Training loss: 0.14209526777267456
Validation loss: 1.7024954941964918

Epoch: 6| Step: 4
Training loss: 0.18006661534309387
Validation loss: 1.7397741912513651

Epoch: 6| Step: 5
Training loss: 0.14621159434318542
Validation loss: 1.7080180939807688

Epoch: 6| Step: 6
Training loss: 0.1724766492843628
Validation loss: 1.753430333188785

Epoch: 6| Step: 7
Training loss: 0.10680033266544342
Validation loss: 1.7388432025909424

Epoch: 6| Step: 8
Training loss: 0.10536746680736542
Validation loss: 1.7221924092179985

Epoch: 6| Step: 9
Training loss: 0.09894953668117523
Validation loss: 1.6962082386016846

Epoch: 6| Step: 10
Training loss: 0.08246985822916031
Validation loss: 1.7038165971797

Epoch: 6| Step: 11
Training loss: 0.12441309541463852
Validation loss: 1.7639206378690657

Epoch: 6| Step: 12
Training loss: 0.14374332129955292
Validation loss: 1.731792421751125

Epoch: 6| Step: 13
Training loss: 0.1011141762137413
Validation loss: 1.743417396340319

Epoch: 426| Step: 0
Training loss: 0.09457273036241531
Validation loss: 1.7433586094969062

Epoch: 6| Step: 1
Training loss: 0.11873741447925568
Validation loss: 1.7738895441896172

Epoch: 6| Step: 2
Training loss: 0.09261998534202576
Validation loss: 1.7638234617889568

Epoch: 6| Step: 3
Training loss: 0.08370748162269592
Validation loss: 1.7380135854085286

Epoch: 6| Step: 4
Training loss: 0.14085853099822998
Validation loss: 1.7657168437075872

Epoch: 6| Step: 5
Training loss: 0.13824748992919922
Validation loss: 1.7640334329297465

Epoch: 6| Step: 6
Training loss: 0.24990741908550262
Validation loss: 1.7634066304852885

Epoch: 6| Step: 7
Training loss: 0.08529995381832123
Validation loss: 1.7679831584294636

Epoch: 6| Step: 8
Training loss: 0.07563410699367523
Validation loss: 1.7872842358004661

Epoch: 6| Step: 9
Training loss: 0.06332827359437943
Validation loss: 1.7520884275436401

Epoch: 6| Step: 10
Training loss: 0.17221471667289734
Validation loss: 1.760203165392722

Epoch: 6| Step: 11
Training loss: 0.10773559659719467
Validation loss: 1.7466523390944286

Epoch: 6| Step: 12
Training loss: 0.15881183743476868
Validation loss: 1.7281056514350317

Epoch: 6| Step: 13
Training loss: 0.15664230287075043
Validation loss: 1.7374639588017617

Epoch: 427| Step: 0
Training loss: 0.06472474336624146
Validation loss: 1.741983877715244

Epoch: 6| Step: 1
Training loss: 0.2086983323097229
Validation loss: 1.735392116731213

Epoch: 6| Step: 2
Training loss: 0.19692882895469666
Validation loss: 1.7560230416636313

Epoch: 6| Step: 3
Training loss: 0.06824616342782974
Validation loss: 1.7854503111172748

Epoch: 6| Step: 4
Training loss: 0.11919781565666199
Validation loss: 1.7441834442077144

Epoch: 6| Step: 5
Training loss: 0.1563025712966919
Validation loss: 1.7460327327892344

Epoch: 6| Step: 6
Training loss: 0.13505518436431885
Validation loss: 1.7444933152967883

Epoch: 6| Step: 7
Training loss: 0.08872050791978836
Validation loss: 1.7281308302315332

Epoch: 6| Step: 8
Training loss: 0.16811421513557434
Validation loss: 1.7301889414428382

Epoch: 6| Step: 9
Training loss: 0.1861867755651474
Validation loss: 1.6906514142149238

Epoch: 6| Step: 10
Training loss: 0.10154495388269424
Validation loss: 1.7439029806403703

Epoch: 6| Step: 11
Training loss: 0.13422682881355286
Validation loss: 1.685739113438514

Epoch: 6| Step: 12
Training loss: 0.0936763733625412
Validation loss: 1.7255864079280565

Epoch: 6| Step: 13
Training loss: 0.15815094113349915
Validation loss: 1.754986188744986

Epoch: 428| Step: 0
Training loss: 0.10306420922279358
Validation loss: 1.75896365668184

Epoch: 6| Step: 1
Training loss: 0.21642807126045227
Validation loss: 1.7949993020744734

Epoch: 6| Step: 2
Training loss: 0.23444391787052155
Validation loss: 1.8280152915626444

Epoch: 6| Step: 3
Training loss: 0.18734844028949738
Validation loss: 1.8108689041547879

Epoch: 6| Step: 4
Training loss: 0.11227042973041534
Validation loss: 1.8153632328074465

Epoch: 6| Step: 5
Training loss: 0.15387657284736633
Validation loss: 1.7692322513108611

Epoch: 6| Step: 6
Training loss: 0.12635406851768494
Validation loss: 1.7907295291141798

Epoch: 6| Step: 7
Training loss: 0.14373676478862762
Validation loss: 1.747129083961569

Epoch: 6| Step: 8
Training loss: 0.19465649127960205
Validation loss: 1.7349651513561126

Epoch: 6| Step: 9
Training loss: 0.12149854004383087
Validation loss: 1.7249811080194288

Epoch: 6| Step: 10
Training loss: 0.10667646676301956
Validation loss: 1.7290208839601087

Epoch: 6| Step: 11
Training loss: 0.13089771568775177
Validation loss: 1.6965728113728185

Epoch: 6| Step: 12
Training loss: 0.18729165196418762
Validation loss: 1.7367075579140776

Epoch: 6| Step: 13
Training loss: 0.33988213539123535
Validation loss: 1.7153447610075756

Epoch: 429| Step: 0
Training loss: 0.08883526921272278
Validation loss: 1.724004291719006

Epoch: 6| Step: 1
Training loss: 0.13618747889995575
Validation loss: 1.7435650979318926

Epoch: 6| Step: 2
Training loss: 0.1609387844800949
Validation loss: 1.7586078682253439

Epoch: 6| Step: 3
Training loss: 0.12722650170326233
Validation loss: 1.760591544130797

Epoch: 6| Step: 4
Training loss: 0.10140321403741837
Validation loss: 1.7729009646241383

Epoch: 6| Step: 5
Training loss: 0.08258059620857239
Validation loss: 1.7800880132182952

Epoch: 6| Step: 6
Training loss: 0.15280470252037048
Validation loss: 1.7498456906246882

Epoch: 6| Step: 7
Training loss: 0.13231608271598816
Validation loss: 1.7857951477009764

Epoch: 6| Step: 8
Training loss: 0.11006970703601837
Validation loss: 1.7808873384229598

Epoch: 6| Step: 9
Training loss: 0.09706257283687592
Validation loss: 1.7829997180610575

Epoch: 6| Step: 10
Training loss: 0.2419406622648239
Validation loss: 1.7743431663000455

Epoch: 6| Step: 11
Training loss: 0.13722014427185059
Validation loss: 1.7987195227735786

Epoch: 6| Step: 12
Training loss: 0.10586273670196533
Validation loss: 1.7721009677456272

Epoch: 6| Step: 13
Training loss: 0.16468918323516846
Validation loss: 1.7565888538155505

Epoch: 430| Step: 0
Training loss: 0.10579253733158112
Validation loss: 1.7187894057202082

Epoch: 6| Step: 1
Training loss: 0.09882218390703201
Validation loss: 1.729797286372031

Epoch: 6| Step: 2
Training loss: 0.07026344537734985
Validation loss: 1.6911240085478751

Epoch: 6| Step: 3
Training loss: 0.1822073757648468
Validation loss: 1.6958413406084942

Epoch: 6| Step: 4
Training loss: 0.16371244192123413
Validation loss: 1.7044876621615501

Epoch: 6| Step: 5
Training loss: 0.1323252022266388
Validation loss: 1.713504050367622

Epoch: 6| Step: 6
Training loss: 0.24679364264011383
Validation loss: 1.6845943504764187

Epoch: 6| Step: 7
Training loss: 0.12371499836444855
Validation loss: 1.695187069395537

Epoch: 6| Step: 8
Training loss: 0.18111631274223328
Validation loss: 1.694303281845585

Epoch: 6| Step: 9
Training loss: 0.1267240047454834
Validation loss: 1.6723430131071357

Epoch: 6| Step: 10
Training loss: 0.13437505066394806
Validation loss: 1.695776912473863

Epoch: 6| Step: 11
Training loss: 0.13863995671272278
Validation loss: 1.6908244086850075

Epoch: 6| Step: 12
Training loss: 0.12491188198328018
Validation loss: 1.690548768607519

Epoch: 6| Step: 13
Training loss: 0.07379945367574692
Validation loss: 1.7158487355837257

Epoch: 431| Step: 0
Training loss: 0.11395931243896484
Validation loss: 1.7276729652958531

Epoch: 6| Step: 1
Training loss: 0.1392701417207718
Validation loss: 1.717775180775632

Epoch: 6| Step: 2
Training loss: 0.12019316852092743
Validation loss: 1.738948743830445

Epoch: 6| Step: 3
Training loss: 0.12426179647445679
Validation loss: 1.757531871077835

Epoch: 6| Step: 4
Training loss: 0.12469518184661865
Validation loss: 1.7447605261238672

Epoch: 6| Step: 5
Training loss: 0.11942882835865021
Validation loss: 1.7978752607940345

Epoch: 6| Step: 6
Training loss: 0.16106021404266357
Validation loss: 1.736622159199048

Epoch: 6| Step: 7
Training loss: 0.08361388742923737
Validation loss: 1.7250195728835238

Epoch: 6| Step: 8
Training loss: 0.17924916744232178
Validation loss: 1.7472653132612987

Epoch: 6| Step: 9
Training loss: 0.066243976354599
Validation loss: 1.7263264579157676

Epoch: 6| Step: 10
Training loss: 0.07456672191619873
Validation loss: 1.7193136099846131

Epoch: 6| Step: 11
Training loss: 0.0963677242398262
Validation loss: 1.6873110314851165

Epoch: 6| Step: 12
Training loss: 0.09351465106010437
Validation loss: 1.6637783806811097

Epoch: 6| Step: 13
Training loss: 0.2798430323600769
Validation loss: 1.6994040768633607

Epoch: 432| Step: 0
Training loss: 0.10079630464315414
Validation loss: 1.681129365838984

Epoch: 6| Step: 1
Training loss: 0.11164066940546036
Validation loss: 1.7139675796672862

Epoch: 6| Step: 2
Training loss: 0.20907457172870636
Validation loss: 1.7264681170063634

Epoch: 6| Step: 3
Training loss: 0.08718501031398773
Validation loss: 1.7299573075386785

Epoch: 6| Step: 4
Training loss: 0.14218534529209137
Validation loss: 1.720715784257458

Epoch: 6| Step: 5
Training loss: 0.1188913956284523
Validation loss: 1.7453384002049763

Epoch: 6| Step: 6
Training loss: 0.12337136268615723
Validation loss: 1.7364374629912838

Epoch: 6| Step: 7
Training loss: 0.10645453631877899
Validation loss: 1.7434296095243065

Epoch: 6| Step: 8
Training loss: 0.13711202144622803
Validation loss: 1.767904971235542

Epoch: 6| Step: 9
Training loss: 0.20481973886489868
Validation loss: 1.7608526765659291

Epoch: 6| Step: 10
Training loss: 0.17392998933792114
Validation loss: 1.7438337482431883

Epoch: 6| Step: 11
Training loss: 0.08167806267738342
Validation loss: 1.7363696546964749

Epoch: 6| Step: 12
Training loss: 0.1521550714969635
Validation loss: 1.7554583882772794

Epoch: 6| Step: 13
Training loss: 0.10802020132541656
Validation loss: 1.7804765265475038

Epoch: 433| Step: 0
Training loss: 0.20686715841293335
Validation loss: 1.7548134942208566

Epoch: 6| Step: 1
Training loss: 0.18114110827445984
Validation loss: 1.7568439822043143

Epoch: 6| Step: 2
Training loss: 0.20483171939849854
Validation loss: 1.7713546188928748

Epoch: 6| Step: 3
Training loss: 0.07264257967472076
Validation loss: 1.7551066888275968

Epoch: 6| Step: 4
Training loss: 0.2187483161687851
Validation loss: 1.704676962667896

Epoch: 6| Step: 5
Training loss: 0.10955092310905457
Validation loss: 1.719013814003237

Epoch: 6| Step: 6
Training loss: 0.24310879409313202
Validation loss: 1.6845540128728396

Epoch: 6| Step: 7
Training loss: 0.1497722715139389
Validation loss: 1.6793667552291707

Epoch: 6| Step: 8
Training loss: 0.13971641659736633
Validation loss: 1.7278087536493938

Epoch: 6| Step: 9
Training loss: 0.2026204764842987
Validation loss: 1.7420353094736736

Epoch: 6| Step: 10
Training loss: 0.19852802157402039
Validation loss: 1.7461516959692842

Epoch: 6| Step: 11
Training loss: 0.125676229596138
Validation loss: 1.7251390834008493

Epoch: 6| Step: 12
Training loss: 0.13083431124687195
Validation loss: 1.736697491138212

Epoch: 6| Step: 13
Training loss: 0.17485351860523224
Validation loss: 1.737506684436593

Epoch: 434| Step: 0
Training loss: 0.1177743449807167
Validation loss: 1.7848530238674534

Epoch: 6| Step: 1
Training loss: 0.1459292322397232
Validation loss: 1.813906826639688

Epoch: 6| Step: 2
Training loss: 0.11173303425312042
Validation loss: 1.7773363128785165

Epoch: 6| Step: 3
Training loss: 0.13314804434776306
Validation loss: 1.7862799116360244

Epoch: 6| Step: 4
Training loss: 0.09443289786577225
Validation loss: 1.7798173068672098

Epoch: 6| Step: 5
Training loss: 0.19264161586761475
Validation loss: 1.7388493053374752

Epoch: 6| Step: 6
Training loss: 0.12052974104881287
Validation loss: 1.781312027285176

Epoch: 6| Step: 7
Training loss: 0.11276368796825409
Validation loss: 1.7970165398813063

Epoch: 6| Step: 8
Training loss: 0.15769824385643005
Validation loss: 1.7702381533961142

Epoch: 6| Step: 9
Training loss: 0.17888392508029938
Validation loss: 1.7674484252929688

Epoch: 6| Step: 10
Training loss: 0.11976000666618347
Validation loss: 1.784679365414445

Epoch: 6| Step: 11
Training loss: 0.21919472515583038
Validation loss: 1.772188909592167

Epoch: 6| Step: 12
Training loss: 0.1607804000377655
Validation loss: 1.7673131253129692

Epoch: 6| Step: 13
Training loss: 0.13896095752716064
Validation loss: 1.7309519860052294

Epoch: 435| Step: 0
Training loss: 0.076225645840168
Validation loss: 1.7633224969269128

Epoch: 6| Step: 1
Training loss: 0.0817304477095604
Validation loss: 1.7533770248454104

Epoch: 6| Step: 2
Training loss: 0.06877564638853073
Validation loss: 1.724429585600412

Epoch: 6| Step: 3
Training loss: 0.153575137257576
Validation loss: 1.7290496287807342

Epoch: 6| Step: 4
Training loss: 0.06912245601415634
Validation loss: 1.7304299813444897

Epoch: 6| Step: 5
Training loss: 0.10255837440490723
Validation loss: 1.7420167358972694

Epoch: 6| Step: 6
Training loss: 0.15956762433052063
Validation loss: 1.7123985059799687

Epoch: 6| Step: 7
Training loss: 0.062023453414440155
Validation loss: 1.7116412629363358

Epoch: 6| Step: 8
Training loss: 0.09972905367612839
Validation loss: 1.7371242456538702

Epoch: 6| Step: 9
Training loss: 0.21888506412506104
Validation loss: 1.7076983105751775

Epoch: 6| Step: 10
Training loss: 0.11104930937290192
Validation loss: 1.7356644125394924

Epoch: 6| Step: 11
Training loss: 0.08518339693546295
Validation loss: 1.7535076192630235

Epoch: 6| Step: 12
Training loss: 0.1490071713924408
Validation loss: 1.7259061413426553

Epoch: 6| Step: 13
Training loss: 0.09762211889028549
Validation loss: 1.7142461628042243

Epoch: 436| Step: 0
Training loss: 0.13899491727352142
Validation loss: 1.659135732599484

Epoch: 6| Step: 1
Training loss: 0.1257321983575821
Validation loss: 1.6964608648771882

Epoch: 6| Step: 2
Training loss: 0.08846951276063919
Validation loss: 1.7315133463951848

Epoch: 6| Step: 3
Training loss: 0.05674731731414795
Validation loss: 1.6875457225307342

Epoch: 6| Step: 4
Training loss: 0.12125163525342941
Validation loss: 1.7028160915579846

Epoch: 6| Step: 5
Training loss: 0.14554767310619354
Validation loss: 1.6999050699254519

Epoch: 6| Step: 6
Training loss: 0.11326172947883606
Validation loss: 1.703134516234039

Epoch: 6| Step: 7
Training loss: 0.12279850244522095
Validation loss: 1.7054926733816824

Epoch: 6| Step: 8
Training loss: 0.13765664398670197
Validation loss: 1.6927328545560119

Epoch: 6| Step: 9
Training loss: 0.12348751723766327
Validation loss: 1.7040068539240028

Epoch: 6| Step: 10
Training loss: 0.1561308205127716
Validation loss: 1.7352871612835956

Epoch: 6| Step: 11
Training loss: 0.09186911582946777
Validation loss: 1.7325741091082174

Epoch: 6| Step: 12
Training loss: 0.16122670471668243
Validation loss: 1.691304777258186

Epoch: 6| Step: 13
Training loss: 0.1133827343583107
Validation loss: 1.7039169457650953

Epoch: 437| Step: 0
Training loss: 0.058528833091259
Validation loss: 1.7114516304385277

Epoch: 6| Step: 1
Training loss: 0.12428635358810425
Validation loss: 1.7162190278371174

Epoch: 6| Step: 2
Training loss: 0.09606853127479553
Validation loss: 1.7409681293272203

Epoch: 6| Step: 3
Training loss: 0.08751484006643295
Validation loss: 1.7345637313781246

Epoch: 6| Step: 4
Training loss: 0.08620700240135193
Validation loss: 1.7223147897310154

Epoch: 6| Step: 5
Training loss: 0.05746191740036011
Validation loss: 1.7411347922458444

Epoch: 6| Step: 6
Training loss: 0.08577130734920502
Validation loss: 1.7335825376613165

Epoch: 6| Step: 7
Training loss: 0.10178668797016144
Validation loss: 1.7269278328905824

Epoch: 6| Step: 8
Training loss: 0.18779391050338745
Validation loss: 1.7434327948477961

Epoch: 6| Step: 9
Training loss: 0.23405054211616516
Validation loss: 1.76031828952092

Epoch: 6| Step: 10
Training loss: 0.09398020803928375
Validation loss: 1.7667843885319208

Epoch: 6| Step: 11
Training loss: 0.11132459342479706
Validation loss: 1.7401648439386839

Epoch: 6| Step: 12
Training loss: 0.1419200748205185
Validation loss: 1.7455344097588652

Epoch: 6| Step: 13
Training loss: 0.07803212851285934
Validation loss: 1.7591959071415726

Epoch: 438| Step: 0
Training loss: 0.13150402903556824
Validation loss: 1.7511158117683985

Epoch: 6| Step: 1
Training loss: 0.3281558156013489
Validation loss: 1.7038208425685923

Epoch: 6| Step: 2
Training loss: 0.08138588070869446
Validation loss: 1.6992246002279303

Epoch: 6| Step: 3
Training loss: 0.11671576648950577
Validation loss: 1.73466787158802

Epoch: 6| Step: 4
Training loss: 0.09503214806318283
Validation loss: 1.7015868848369968

Epoch: 6| Step: 5
Training loss: 0.13073629140853882
Validation loss: 1.7276878792752501

Epoch: 6| Step: 6
Training loss: 0.13068468868732452
Validation loss: 1.7445700847974388

Epoch: 6| Step: 7
Training loss: 0.09535843133926392
Validation loss: 1.7512141171322073

Epoch: 6| Step: 8
Training loss: 0.13016965985298157
Validation loss: 1.7389375830209384

Epoch: 6| Step: 9
Training loss: 0.1910441815853119
Validation loss: 1.7269731478024555

Epoch: 6| Step: 10
Training loss: 0.07411377131938934
Validation loss: 1.7635010057880032

Epoch: 6| Step: 11
Training loss: 0.10034158825874329
Validation loss: 1.7237236243422314

Epoch: 6| Step: 12
Training loss: 0.11591893434524536
Validation loss: 1.7297854756796232

Epoch: 6| Step: 13
Training loss: 0.10642912983894348
Validation loss: 1.7147140169656405

Epoch: 439| Step: 0
Training loss: 0.15580394864082336
Validation loss: 1.7261440651391142

Epoch: 6| Step: 1
Training loss: 0.13095635175704956
Validation loss: 1.7429975014860912

Epoch: 6| Step: 2
Training loss: 0.09614838659763336
Validation loss: 1.7627827775093816

Epoch: 6| Step: 3
Training loss: 0.14672636985778809
Validation loss: 1.7510245705163607

Epoch: 6| Step: 4
Training loss: 0.10564623773097992
Validation loss: 1.7580158531024892

Epoch: 6| Step: 5
Training loss: 0.1250506341457367
Validation loss: 1.7751802065039193

Epoch: 6| Step: 6
Training loss: 0.2098884880542755
Validation loss: 1.7813556707033547

Epoch: 6| Step: 7
Training loss: 0.16481941938400269
Validation loss: 1.7398090183093984

Epoch: 6| Step: 8
Training loss: 0.10688741505146027
Validation loss: 1.714940180060684

Epoch: 6| Step: 9
Training loss: 0.19345591962337494
Validation loss: 1.747389434486307

Epoch: 6| Step: 10
Training loss: 0.08979260921478271
Validation loss: 1.69462719527624

Epoch: 6| Step: 11
Training loss: 0.11099625378847122
Validation loss: 1.6809329537935154

Epoch: 6| Step: 12
Training loss: 0.17275424301624298
Validation loss: 1.6865932608163485

Epoch: 6| Step: 13
Training loss: 0.06416898220777512
Validation loss: 1.7130962840972408

Epoch: 440| Step: 0
Training loss: 0.11425106227397919
Validation loss: 1.7542993900596455

Epoch: 6| Step: 1
Training loss: 0.08661127090454102
Validation loss: 1.734682689430893

Epoch: 6| Step: 2
Training loss: 0.1691991239786148
Validation loss: 1.7838075045616395

Epoch: 6| Step: 3
Training loss: 0.18105316162109375
Validation loss: 1.782079917128368

Epoch: 6| Step: 4
Training loss: 0.12754732370376587
Validation loss: 1.7606383010905275

Epoch: 6| Step: 5
Training loss: 0.16259899735450745
Validation loss: 1.7390733060016428

Epoch: 6| Step: 6
Training loss: 0.1065138429403305
Validation loss: 1.7530173768279373

Epoch: 6| Step: 7
Training loss: 0.1326339840888977
Validation loss: 1.7338940135894283

Epoch: 6| Step: 8
Training loss: 0.21721817553043365
Validation loss: 1.7126171012078562

Epoch: 6| Step: 9
Training loss: 0.12811055779457092
Validation loss: 1.6926158089791574

Epoch: 6| Step: 10
Training loss: 0.12620499730110168
Validation loss: 1.644588324331468

Epoch: 6| Step: 11
Training loss: 0.15521706640720367
Validation loss: 1.6632845363309305

Epoch: 6| Step: 12
Training loss: 0.12360969185829163
Validation loss: 1.6762279900171424

Epoch: 6| Step: 13
Training loss: 0.2217945009469986
Validation loss: 1.7105569634386288

Epoch: 441| Step: 0
Training loss: 0.13168683648109436
Validation loss: 1.7052535754378124

Epoch: 6| Step: 1
Training loss: 0.1870451271533966
Validation loss: 1.7078660893183883

Epoch: 6| Step: 2
Training loss: 0.12230005860328674
Validation loss: 1.7325669321962582

Epoch: 6| Step: 3
Training loss: 0.27898386120796204
Validation loss: 1.7235128674455868

Epoch: 6| Step: 4
Training loss: 0.07691065967082977
Validation loss: 1.6959361837756248

Epoch: 6| Step: 5
Training loss: 0.07287496328353882
Validation loss: 1.6801428000132244

Epoch: 6| Step: 6
Training loss: 0.17469251155853271
Validation loss: 1.6683894203555198

Epoch: 6| Step: 7
Training loss: 0.2361810952425003
Validation loss: 1.6877466850383307

Epoch: 6| Step: 8
Training loss: 0.33861953020095825
Validation loss: 1.6709989988675682

Epoch: 6| Step: 9
Training loss: 0.10842027515172958
Validation loss: 1.6992202804934593

Epoch: 6| Step: 10
Training loss: 0.23228773474693298
Validation loss: 1.687183262199484

Epoch: 6| Step: 11
Training loss: 0.12215069681406021
Validation loss: 1.7134188157255932

Epoch: 6| Step: 12
Training loss: 0.11530496925115585
Validation loss: 1.70224961157768

Epoch: 6| Step: 13
Training loss: 0.1581760048866272
Validation loss: 1.72890059409603

Epoch: 442| Step: 0
Training loss: 0.1500854194164276
Validation loss: 1.724386187009914

Epoch: 6| Step: 1
Training loss: 0.17267338931560516
Validation loss: 1.7231262358286048

Epoch: 6| Step: 2
Training loss: 0.09073503315448761
Validation loss: 1.7054709593454997

Epoch: 6| Step: 3
Training loss: 0.13368448615074158
Validation loss: 1.7364763918743338

Epoch: 6| Step: 4
Training loss: 0.14870598912239075
Validation loss: 1.717498343477967

Epoch: 6| Step: 5
Training loss: 0.16733884811401367
Validation loss: 1.7395517902989541

Epoch: 6| Step: 6
Training loss: 0.1380905956029892
Validation loss: 1.699451788779228

Epoch: 6| Step: 7
Training loss: 0.11268074810504913
Validation loss: 1.6910294871176443

Epoch: 6| Step: 8
Training loss: 0.10184113681316376
Validation loss: 1.739548352456862

Epoch: 6| Step: 9
Training loss: 0.13026104867458344
Validation loss: 1.7170814391105407

Epoch: 6| Step: 10
Training loss: 0.07479718327522278
Validation loss: 1.7281375649154826

Epoch: 6| Step: 11
Training loss: 0.10415846109390259
Validation loss: 1.7212351342683196

Epoch: 6| Step: 12
Training loss: 0.06898175179958344
Validation loss: 1.7277330429323259

Epoch: 6| Step: 13
Training loss: 0.08833076059818268
Validation loss: 1.726522111123608

Epoch: 443| Step: 0
Training loss: 0.13903094828128815
Validation loss: 1.7480356770177041

Epoch: 6| Step: 1
Training loss: 0.09617459774017334
Validation loss: 1.7152571806343653

Epoch: 6| Step: 2
Training loss: 0.08237230777740479
Validation loss: 1.7539647368974582

Epoch: 6| Step: 3
Training loss: 0.05154091864824295
Validation loss: 1.7198584605288763

Epoch: 6| Step: 4
Training loss: 0.20992934703826904
Validation loss: 1.7546712044746644

Epoch: 6| Step: 5
Training loss: 0.13817846775054932
Validation loss: 1.75980043923983

Epoch: 6| Step: 6
Training loss: 0.09323674440383911
Validation loss: 1.7532700428398706

Epoch: 6| Step: 7
Training loss: 0.09080933034420013
Validation loss: 1.7549456498956169

Epoch: 6| Step: 8
Training loss: 0.1407819241285324
Validation loss: 1.7309732808861682

Epoch: 6| Step: 9
Training loss: 0.07177736610174179
Validation loss: 1.7477431002483572

Epoch: 6| Step: 10
Training loss: 0.0797317624092102
Validation loss: 1.7469034758947228

Epoch: 6| Step: 11
Training loss: 0.15608079731464386
Validation loss: 1.789750042782035

Epoch: 6| Step: 12
Training loss: 0.05194764584302902
Validation loss: 1.749725587906376

Epoch: 6| Step: 13
Training loss: 0.11768901348114014
Validation loss: 1.7958608186373146

Epoch: 444| Step: 0
Training loss: 0.12079274654388428
Validation loss: 1.82228599697031

Epoch: 6| Step: 1
Training loss: 0.1118713766336441
Validation loss: 1.7700365768965853

Epoch: 6| Step: 2
Training loss: 0.14263185858726501
Validation loss: 1.7554831017730057

Epoch: 6| Step: 3
Training loss: 0.06299770623445511
Validation loss: 1.7481345925279843

Epoch: 6| Step: 4
Training loss: 0.09206125140190125
Validation loss: 1.7183907647286691

Epoch: 6| Step: 5
Training loss: 0.11580003052949905
Validation loss: 1.7171932035876858

Epoch: 6| Step: 6
Training loss: 0.19889280200004578
Validation loss: 1.6692914078312535

Epoch: 6| Step: 7
Training loss: 0.09464829415082932
Validation loss: 1.714373400134425

Epoch: 6| Step: 8
Training loss: 0.12236059457063675
Validation loss: 1.7205807284642292

Epoch: 6| Step: 9
Training loss: 0.15746405720710754
Validation loss: 1.7128108175851966

Epoch: 6| Step: 10
Training loss: 0.12659436464309692
Validation loss: 1.7144254856212164

Epoch: 6| Step: 11
Training loss: 0.129846453666687
Validation loss: 1.7058052401388846

Epoch: 6| Step: 12
Training loss: 0.123628631234169
Validation loss: 1.7027982716919274

Epoch: 6| Step: 13
Training loss: 0.14532463252544403
Validation loss: 1.6980491479237874

Epoch: 445| Step: 0
Training loss: 0.0755171924829483
Validation loss: 1.6772413804966917

Epoch: 6| Step: 1
Training loss: 0.07965368032455444
Validation loss: 1.6638908245230233

Epoch: 6| Step: 2
Training loss: 0.06582386791706085
Validation loss: 1.720403730228383

Epoch: 6| Step: 3
Training loss: 0.18099528551101685
Validation loss: 1.6942611804572485

Epoch: 6| Step: 4
Training loss: 0.0960002914071083
Validation loss: 1.7221748982706377

Epoch: 6| Step: 5
Training loss: 0.2103208601474762
Validation loss: 1.717034073286159

Epoch: 6| Step: 6
Training loss: 0.07301898300647736
Validation loss: 1.7318179402300107

Epoch: 6| Step: 7
Training loss: 0.09775277972221375
Validation loss: 1.7309271122819634

Epoch: 6| Step: 8
Training loss: 0.09466911852359772
Validation loss: 1.7360416740499518

Epoch: 6| Step: 9
Training loss: 0.12411201745271683
Validation loss: 1.7838365301009147

Epoch: 6| Step: 10
Training loss: 0.26653850078582764
Validation loss: 1.7615295353756155

Epoch: 6| Step: 11
Training loss: 0.0714411586523056
Validation loss: 1.7596761231781335

Epoch: 6| Step: 12
Training loss: 0.05873274430632591
Validation loss: 1.7416327127846338

Epoch: 6| Step: 13
Training loss: 0.13305798172950745
Validation loss: 1.7615022326028476

Epoch: 446| Step: 0
Training loss: 0.2379755973815918
Validation loss: 1.731006096768123

Epoch: 6| Step: 1
Training loss: 0.07229231297969818
Validation loss: 1.720383874831661

Epoch: 6| Step: 2
Training loss: 0.1005571261048317
Validation loss: 1.7278686992583736

Epoch: 6| Step: 3
Training loss: 0.05733577907085419
Validation loss: 1.7135559756268737

Epoch: 6| Step: 4
Training loss: 0.0741923525929451
Validation loss: 1.6993855276415426

Epoch: 6| Step: 5
Training loss: 0.12288022041320801
Validation loss: 1.7065312195849676

Epoch: 6| Step: 6
Training loss: 0.09324823319911957
Validation loss: 1.7184015717557681

Epoch: 6| Step: 7
Training loss: 0.0884309709072113
Validation loss: 1.6808070264836794

Epoch: 6| Step: 8
Training loss: 0.10515109449625015
Validation loss: 1.6783030879112981

Epoch: 6| Step: 9
Training loss: 0.07797513902187347
Validation loss: 1.659838702089043

Epoch: 6| Step: 10
Training loss: 0.09512922167778015
Validation loss: 1.6910455342262023

Epoch: 6| Step: 11
Training loss: 0.10252347588539124
Validation loss: 1.6799643296067432

Epoch: 6| Step: 12
Training loss: 0.1196436733007431
Validation loss: 1.7031006313139392

Epoch: 6| Step: 13
Training loss: 0.13232344388961792
Validation loss: 1.6843297737900929

Epoch: 447| Step: 0
Training loss: 0.09887394309043884
Validation loss: 1.6797544007660241

Epoch: 6| Step: 1
Training loss: 0.1228240430355072
Validation loss: 1.678227355403285

Epoch: 6| Step: 2
Training loss: 0.08202528953552246
Validation loss: 1.6964098445830806

Epoch: 6| Step: 3
Training loss: 0.17005634307861328
Validation loss: 1.718986230511819

Epoch: 6| Step: 4
Training loss: 0.1149662435054779
Validation loss: 1.674194694847189

Epoch: 6| Step: 5
Training loss: 0.11200495809316635
Validation loss: 1.688590286880411

Epoch: 6| Step: 6
Training loss: 0.12112073600292206
Validation loss: 1.6954076854131555

Epoch: 6| Step: 7
Training loss: 0.084829181432724
Validation loss: 1.6807098260489843

Epoch: 6| Step: 8
Training loss: 0.1887793093919754
Validation loss: 1.689459850070297

Epoch: 6| Step: 9
Training loss: 0.10021719336509705
Validation loss: 1.67965869749746

Epoch: 6| Step: 10
Training loss: 0.07609157264232635
Validation loss: 1.7030574570419967

Epoch: 6| Step: 11
Training loss: 0.08789563179016113
Validation loss: 1.7246409641799105

Epoch: 6| Step: 12
Training loss: 0.0882730782032013
Validation loss: 1.6911558348645446

Epoch: 6| Step: 13
Training loss: 0.14874255657196045
Validation loss: 1.7076957738527687

Epoch: 448| Step: 0
Training loss: 0.15017691254615784
Validation loss: 1.6874289499816073

Epoch: 6| Step: 1
Training loss: 0.07801325619220734
Validation loss: 1.680049265584638

Epoch: 6| Step: 2
Training loss: 0.12913982570171356
Validation loss: 1.6898543668049637

Epoch: 6| Step: 3
Training loss: 0.14652693271636963
Validation loss: 1.6976401728968467

Epoch: 6| Step: 4
Training loss: 0.08340254426002502
Validation loss: 1.6855377843303065

Epoch: 6| Step: 5
Training loss: 0.19627918303012848
Validation loss: 1.6679545307672152

Epoch: 6| Step: 6
Training loss: 0.12215140461921692
Validation loss: 1.6576510795982935

Epoch: 6| Step: 7
Training loss: 0.1125311329960823
Validation loss: 1.6705909711058422

Epoch: 6| Step: 8
Training loss: 0.08242715895175934
Validation loss: 1.6546498524245394

Epoch: 6| Step: 9
Training loss: 0.04306521639227867
Validation loss: 1.7180808897941344

Epoch: 6| Step: 10
Training loss: 0.21279039978981018
Validation loss: 1.7348831289558

Epoch: 6| Step: 11
Training loss: 0.09509653598070145
Validation loss: 1.7797794534314064

Epoch: 6| Step: 12
Training loss: 0.15662673115730286
Validation loss: 1.7826916786932177

Epoch: 6| Step: 13
Training loss: 0.11730411648750305
Validation loss: 1.7671250348450036

Epoch: 449| Step: 0
Training loss: 0.09992662072181702
Validation loss: 1.779277596422421

Epoch: 6| Step: 1
Training loss: 0.16288569569587708
Validation loss: 1.7674375810930807

Epoch: 6| Step: 2
Training loss: 0.13858889043331146
Validation loss: 1.7593488077963553

Epoch: 6| Step: 3
Training loss: 0.13777288794517517
Validation loss: 1.760280309184905

Epoch: 6| Step: 4
Training loss: 0.07799799740314484
Validation loss: 1.747728737451697

Epoch: 6| Step: 5
Training loss: 0.21644410490989685
Validation loss: 1.7218442347741896

Epoch: 6| Step: 6
Training loss: 0.11680391430854797
Validation loss: 1.7644293218530633

Epoch: 6| Step: 7
Training loss: 0.07486695051193237
Validation loss: 1.7352686979437386

Epoch: 6| Step: 8
Training loss: 0.04363574832677841
Validation loss: 1.7457392164455947

Epoch: 6| Step: 9
Training loss: 0.11380311101675034
Validation loss: 1.7458308178891417

Epoch: 6| Step: 10
Training loss: 0.09975793957710266
Validation loss: 1.7457200468227427

Epoch: 6| Step: 11
Training loss: 0.07819277048110962
Validation loss: 1.7597478769158805

Epoch: 6| Step: 12
Training loss: 0.09842979162931442
Validation loss: 1.746094528064933

Epoch: 6| Step: 13
Training loss: 0.12102867662906647
Validation loss: 1.7154118860921552

Epoch: 450| Step: 0
Training loss: 0.04447676241397858
Validation loss: 1.7671230557144328

Epoch: 6| Step: 1
Training loss: 0.08400378376245499
Validation loss: 1.7655652082094582

Epoch: 6| Step: 2
Training loss: 0.07140173017978668
Validation loss: 1.7378506865552676

Epoch: 6| Step: 3
Training loss: 0.11897844821214676
Validation loss: 1.7674069109783377

Epoch: 6| Step: 4
Training loss: 0.11802370101213455
Validation loss: 1.7654294121649958

Epoch: 6| Step: 5
Training loss: 0.13135485351085663
Validation loss: 1.7886766361933883

Epoch: 6| Step: 6
Training loss: 0.1312253326177597
Validation loss: 1.7547596962221208

Epoch: 6| Step: 7
Training loss: 0.0955798551440239
Validation loss: 1.7538750158843173

Epoch: 6| Step: 8
Training loss: 0.06861540675163269
Validation loss: 1.7177943811621716

Epoch: 6| Step: 9
Training loss: 0.17382651567459106
Validation loss: 1.7375601004528742

Epoch: 6| Step: 10
Training loss: 0.13153347373008728
Validation loss: 1.6993912099510111

Epoch: 6| Step: 11
Training loss: 0.08368119597434998
Validation loss: 1.7282863368270218

Epoch: 6| Step: 12
Training loss: 0.12747448682785034
Validation loss: 1.7078067013012466

Epoch: 6| Step: 13
Training loss: 0.09072300046682358
Validation loss: 1.6919391526970813

Epoch: 451| Step: 0
Training loss: 0.11461895704269409
Validation loss: 1.7230435084271174

Epoch: 6| Step: 1
Training loss: 0.11603732407093048
Validation loss: 1.723182742313672

Epoch: 6| Step: 2
Training loss: 0.19434063136577606
Validation loss: 1.751863944915033

Epoch: 6| Step: 3
Training loss: 0.11662249267101288
Validation loss: 1.7225723189692344

Epoch: 6| Step: 4
Training loss: 0.0731053352355957
Validation loss: 1.742961993781469

Epoch: 6| Step: 5
Training loss: 0.07984374463558197
Validation loss: 1.705822140939774

Epoch: 6| Step: 6
Training loss: 0.1804981827735901
Validation loss: 1.7215911707570475

Epoch: 6| Step: 7
Training loss: 0.1150754764676094
Validation loss: 1.753382485399964

Epoch: 6| Step: 8
Training loss: 0.10197475552558899
Validation loss: 1.75395151235724

Epoch: 6| Step: 9
Training loss: 0.08204060792922974
Validation loss: 1.7212836947492374

Epoch: 6| Step: 10
Training loss: 0.07165562361478806
Validation loss: 1.7678532126129314

Epoch: 6| Step: 11
Training loss: 0.07464806735515594
Validation loss: 1.7274633889557214

Epoch: 6| Step: 12
Training loss: 0.1281701773405075
Validation loss: 1.7414844395011984

Epoch: 6| Step: 13
Training loss: 0.15503497421741486
Validation loss: 1.7067383130391438

Epoch: 452| Step: 0
Training loss: 0.10791470855474472
Validation loss: 1.731622161403779

Epoch: 6| Step: 1
Training loss: 0.2321656346321106
Validation loss: 1.7200393728030625

Epoch: 6| Step: 2
Training loss: 0.10768298804759979
Validation loss: 1.691260201956636

Epoch: 6| Step: 3
Training loss: 0.1021672785282135
Validation loss: 1.7275936372818486

Epoch: 6| Step: 4
Training loss: 0.0939539298415184
Validation loss: 1.7310146311277985

Epoch: 6| Step: 5
Training loss: 0.11095523834228516
Validation loss: 1.7456220144866614

Epoch: 6| Step: 6
Training loss: 0.1216903030872345
Validation loss: 1.7482053951550556

Epoch: 6| Step: 7
Training loss: 0.1221703290939331
Validation loss: 1.7578641060859925

Epoch: 6| Step: 8
Training loss: 0.15188932418823242
Validation loss: 1.7206690465250323

Epoch: 6| Step: 9
Training loss: 0.06831933557987213
Validation loss: 1.6592310051764212

Epoch: 6| Step: 10
Training loss: 0.13680705428123474
Validation loss: 1.7049442657860376

Epoch: 6| Step: 11
Training loss: 0.08195048570632935
Validation loss: 1.6694578509176932

Epoch: 6| Step: 12
Training loss: 0.11996699869632721
Validation loss: 1.6478428109999625

Epoch: 6| Step: 13
Training loss: 0.13440482318401337
Validation loss: 1.6904363580929336

Epoch: 453| Step: 0
Training loss: 0.08157940208911896
Validation loss: 1.7189213293854908

Epoch: 6| Step: 1
Training loss: 0.093703493475914
Validation loss: 1.7222675226067985

Epoch: 6| Step: 2
Training loss: 0.15837378799915314
Validation loss: 1.7783144930357575

Epoch: 6| Step: 3
Training loss: 0.18560421466827393
Validation loss: 1.7116268475850422

Epoch: 6| Step: 4
Training loss: 0.24911651015281677
Validation loss: 1.7442998988654024

Epoch: 6| Step: 5
Training loss: 0.16302672028541565
Validation loss: 1.721108518620973

Epoch: 6| Step: 6
Training loss: 0.22488343715667725
Validation loss: 1.7356456172081731

Epoch: 6| Step: 7
Training loss: 0.09314990043640137
Validation loss: 1.7027789700415827

Epoch: 6| Step: 8
Training loss: 0.1991557776927948
Validation loss: 1.7414963809392785

Epoch: 6| Step: 9
Training loss: 0.1603425294160843
Validation loss: 1.7343292851601877

Epoch: 6| Step: 10
Training loss: 0.17769652605056763
Validation loss: 1.7219799167366439

Epoch: 6| Step: 11
Training loss: 0.1749027967453003
Validation loss: 1.7220306204211326

Epoch: 6| Step: 12
Training loss: 0.10476206243038177
Validation loss: 1.7304102938662294

Epoch: 6| Step: 13
Training loss: 0.14658331871032715
Validation loss: 1.7151372355799521

Epoch: 454| Step: 0
Training loss: 0.0954851359128952
Validation loss: 1.703193926042126

Epoch: 6| Step: 1
Training loss: 0.10228980332612991
Validation loss: 1.7311111086158342

Epoch: 6| Step: 2
Training loss: 0.15030527114868164
Validation loss: 1.754516945090345

Epoch: 6| Step: 3
Training loss: 0.11516289412975311
Validation loss: 1.7642456728924987

Epoch: 6| Step: 4
Training loss: 0.12676605582237244
Validation loss: 1.731103454866717

Epoch: 6| Step: 5
Training loss: 0.2090548872947693
Validation loss: 1.7338464760011243

Epoch: 6| Step: 6
Training loss: 0.12493234872817993
Validation loss: 1.7486989651956866

Epoch: 6| Step: 7
Training loss: 0.09276655316352844
Validation loss: 1.7553117403420069

Epoch: 6| Step: 8
Training loss: 0.13311180472373962
Validation loss: 1.7559479846749255

Epoch: 6| Step: 9
Training loss: 0.22674880921840668
Validation loss: 1.7594669326659171

Epoch: 6| Step: 10
Training loss: 0.13332819938659668
Validation loss: 1.788927939630324

Epoch: 6| Step: 11
Training loss: 0.09463800489902496
Validation loss: 1.7662979851486862

Epoch: 6| Step: 12
Training loss: 0.10192607343196869
Validation loss: 1.7848946868732412

Epoch: 6| Step: 13
Training loss: 0.11352299153804779
Validation loss: 1.7594586008338517

Epoch: 455| Step: 0
Training loss: 0.14489921927452087
Validation loss: 1.7553343490887714

Epoch: 6| Step: 1
Training loss: 0.07653050124645233
Validation loss: 1.7367230025670861

Epoch: 6| Step: 2
Training loss: 0.07703044265508652
Validation loss: 1.7033438221100838

Epoch: 6| Step: 3
Training loss: 0.13201989233493805
Validation loss: 1.7028852880641978

Epoch: 6| Step: 4
Training loss: 0.07795257866382599
Validation loss: 1.7058567590610956

Epoch: 6| Step: 5
Training loss: 0.11886471509933472
Validation loss: 1.704859592581308

Epoch: 6| Step: 6
Training loss: 0.15926645696163177
Validation loss: 1.7057305100143596

Epoch: 6| Step: 7
Training loss: 0.10792598128318787
Validation loss: 1.713310823645643

Epoch: 6| Step: 8
Training loss: 0.07889480143785477
Validation loss: 1.6916168505145657

Epoch: 6| Step: 9
Training loss: 0.22977840900421143
Validation loss: 1.6662482561603669

Epoch: 6| Step: 10
Training loss: 0.0812818706035614
Validation loss: 1.6925100267574351

Epoch: 6| Step: 11
Training loss: 0.08218036592006683
Validation loss: 1.695539846215197

Epoch: 6| Step: 12
Training loss: 0.07249442487955093
Validation loss: 1.6556925004528416

Epoch: 6| Step: 13
Training loss: 0.09081951528787613
Validation loss: 1.713258122885099

Epoch: 456| Step: 0
Training loss: 0.12870846688747406
Validation loss: 1.7005528250048239

Epoch: 6| Step: 1
Training loss: 0.1158859133720398
Validation loss: 1.716928728165165

Epoch: 6| Step: 2
Training loss: 0.23762349784374237
Validation loss: 1.7490219390520485

Epoch: 6| Step: 3
Training loss: 0.1421973705291748
Validation loss: 1.6879461939616869

Epoch: 6| Step: 4
Training loss: 0.09221243858337402
Validation loss: 1.713298169515466

Epoch: 6| Step: 5
Training loss: 0.10008780658245087
Validation loss: 1.6992619845174974

Epoch: 6| Step: 6
Training loss: 0.13694122433662415
Validation loss: 1.687325249436081

Epoch: 6| Step: 7
Training loss: 0.13357402384281158
Validation loss: 1.6741523088947419

Epoch: 6| Step: 8
Training loss: 0.12034521996974945
Validation loss: 1.6641858393146145

Epoch: 6| Step: 9
Training loss: 0.1114843338727951
Validation loss: 1.6723982826355965

Epoch: 6| Step: 10
Training loss: 0.06270082294940948
Validation loss: 1.6175863973556026

Epoch: 6| Step: 11
Training loss: 0.09695389866828918
Validation loss: 1.6288583637565694

Epoch: 6| Step: 12
Training loss: 0.10753977298736572
Validation loss: 1.6364843332639305

Epoch: 6| Step: 13
Training loss: 0.0515962615609169
Validation loss: 1.641706221847124

Epoch: 457| Step: 0
Training loss: 0.06918960809707642
Validation loss: 1.663229570593885

Epoch: 6| Step: 1
Training loss: 0.22706694900989532
Validation loss: 1.6690053055363316

Epoch: 6| Step: 2
Training loss: 0.06826885044574738
Validation loss: 1.6815345030958935

Epoch: 6| Step: 3
Training loss: 0.11702373623847961
Validation loss: 1.709960849054398

Epoch: 6| Step: 4
Training loss: 0.09391637146472931
Validation loss: 1.7091850183343376

Epoch: 6| Step: 5
Training loss: 0.07890145480632782
Validation loss: 1.689405889921291

Epoch: 6| Step: 6
Training loss: 0.1406426727771759
Validation loss: 1.708792608271363

Epoch: 6| Step: 7
Training loss: 0.1197696402668953
Validation loss: 1.7178716492909256

Epoch: 6| Step: 8
Training loss: 0.12555064260959625
Validation loss: 1.7190358254217333

Epoch: 6| Step: 9
Training loss: 0.14844295382499695
Validation loss: 1.6950558834178473

Epoch: 6| Step: 10
Training loss: 0.14729246497154236
Validation loss: 1.7273763648925289

Epoch: 6| Step: 11
Training loss: 0.07572314888238907
Validation loss: 1.699426672791922

Epoch: 6| Step: 12
Training loss: 0.11076923459768295
Validation loss: 1.6982825507399857

Epoch: 6| Step: 13
Training loss: 0.08468416333198547
Validation loss: 1.6948646550537438

Epoch: 458| Step: 0
Training loss: 0.13435102999210358
Validation loss: 1.7018502207212551

Epoch: 6| Step: 1
Training loss: 0.07327872514724731
Validation loss: 1.6878402733033704

Epoch: 6| Step: 2
Training loss: 0.18787851929664612
Validation loss: 1.704895680950534

Epoch: 6| Step: 3
Training loss: 0.17449235916137695
Validation loss: 1.705227723685644

Epoch: 6| Step: 4
Training loss: 0.1799788922071457
Validation loss: 1.6967052785299157

Epoch: 6| Step: 5
Training loss: 0.12528812885284424
Validation loss: 1.709290172464104

Epoch: 6| Step: 6
Training loss: 0.07475155591964722
Validation loss: 1.6832989749088083

Epoch: 6| Step: 7
Training loss: 0.10746549814939499
Validation loss: 1.6721870719745595

Epoch: 6| Step: 8
Training loss: 0.08567864447832108
Validation loss: 1.6737607089422082

Epoch: 6| Step: 9
Training loss: 0.1672930121421814
Validation loss: 1.6546657982692923

Epoch: 6| Step: 10
Training loss: 0.204759418964386
Validation loss: 1.6813769853243263

Epoch: 6| Step: 11
Training loss: 0.1436258852481842
Validation loss: 1.67814314493569

Epoch: 6| Step: 12
Training loss: 0.07239389419555664
Validation loss: 1.6704544187873922

Epoch: 6| Step: 13
Training loss: 0.11054486781358719
Validation loss: 1.7007662814150575

Epoch: 459| Step: 0
Training loss: 0.12047955393791199
Validation loss: 1.687798971770912

Epoch: 6| Step: 1
Training loss: 0.1406574249267578
Validation loss: 1.724481540341531

Epoch: 6| Step: 2
Training loss: 0.15210875868797302
Validation loss: 1.6790282726287842

Epoch: 6| Step: 3
Training loss: 0.15889103710651398
Validation loss: 1.7125980366942704

Epoch: 6| Step: 4
Training loss: 0.10012418776750565
Validation loss: 1.691685450974331

Epoch: 6| Step: 5
Training loss: 0.14407017827033997
Validation loss: 1.6978144235508417

Epoch: 6| Step: 6
Training loss: 0.13354969024658203
Validation loss: 1.708899078830596

Epoch: 6| Step: 7
Training loss: 0.14287301898002625
Validation loss: 1.6646124816709948

Epoch: 6| Step: 8
Training loss: 0.06820744276046753
Validation loss: 1.7039087408332414

Epoch: 6| Step: 9
Training loss: 0.10022930800914764
Validation loss: 1.6886258663669709

Epoch: 6| Step: 10
Training loss: 0.07395032048225403
Validation loss: 1.7139200241334978

Epoch: 6| Step: 11
Training loss: 0.07089382410049438
Validation loss: 1.7022011613333097

Epoch: 6| Step: 12
Training loss: 0.08049364387989044
Validation loss: 1.7153460992279874

Epoch: 6| Step: 13
Training loss: 0.11360800266265869
Validation loss: 1.7364021398687874

Epoch: 460| Step: 0
Training loss: 0.07857814431190491
Validation loss: 1.6742838428866478

Epoch: 6| Step: 1
Training loss: 0.06254925578832626
Validation loss: 1.695934150808601

Epoch: 6| Step: 2
Training loss: 0.18904022872447968
Validation loss: 1.6656658623808174

Epoch: 6| Step: 3
Training loss: 0.1066654771566391
Validation loss: 1.6582168866229314

Epoch: 6| Step: 4
Training loss: 0.13146111369132996
Validation loss: 1.651615329968032

Epoch: 6| Step: 5
Training loss: 0.092317596077919
Validation loss: 1.6502310973341747

Epoch: 6| Step: 6
Training loss: 0.09803766012191772
Validation loss: 1.6480308989042878

Epoch: 6| Step: 7
Training loss: 0.10911772400140762
Validation loss: 1.6618363293268348

Epoch: 6| Step: 8
Training loss: 0.07057146728038788
Validation loss: 1.6512236864336076

Epoch: 6| Step: 9
Training loss: 0.2109958827495575
Validation loss: 1.6360436870205788

Epoch: 6| Step: 10
Training loss: 0.070186547935009
Validation loss: 1.6398330580803655

Epoch: 6| Step: 11
Training loss: 0.09889595210552216
Validation loss: 1.630746603012085

Epoch: 6| Step: 12
Training loss: 0.10853574424982071
Validation loss: 1.664054618086866

Epoch: 6| Step: 13
Training loss: 0.09499279409646988
Validation loss: 1.6484859181988625

Epoch: 461| Step: 0
Training loss: 0.16600245237350464
Validation loss: 1.6314580748158116

Epoch: 6| Step: 1
Training loss: 0.11853771656751633
Validation loss: 1.6400783895164408

Epoch: 6| Step: 2
Training loss: 0.1893918812274933
Validation loss: 1.634900354569958

Epoch: 6| Step: 3
Training loss: 0.0733354389667511
Validation loss: 1.6416931536889845

Epoch: 6| Step: 4
Training loss: 0.05699056386947632
Validation loss: 1.6532629254043743

Epoch: 6| Step: 5
Training loss: 0.14295870065689087
Validation loss: 1.6097686854741906

Epoch: 6| Step: 6
Training loss: 0.06984969973564148
Validation loss: 1.6523489849541777

Epoch: 6| Step: 7
Training loss: 0.10238724946975708
Validation loss: 1.6324051721121675

Epoch: 6| Step: 8
Training loss: 0.07265719771385193
Validation loss: 1.6482296259172502

Epoch: 6| Step: 9
Training loss: 0.11922204494476318
Validation loss: 1.6571749538503668

Epoch: 6| Step: 10
Training loss: 0.09803536534309387
Validation loss: 1.6218991997421428

Epoch: 6| Step: 11
Training loss: 0.09088315814733505
Validation loss: 1.6900767998028827

Epoch: 6| Step: 12
Training loss: 0.08801054954528809
Validation loss: 1.6507765323885026

Epoch: 6| Step: 13
Training loss: 0.08931808918714523
Validation loss: 1.663139445807344

Epoch: 462| Step: 0
Training loss: 0.08768320828676224
Validation loss: 1.6571178051733202

Epoch: 6| Step: 1
Training loss: 0.0985434502363205
Validation loss: 1.6597737073898315

Epoch: 6| Step: 2
Training loss: 0.10327886044979095
Validation loss: 1.6947820904434368

Epoch: 6| Step: 3
Training loss: 0.13675400614738464
Validation loss: 1.696778961407241

Epoch: 6| Step: 4
Training loss: 0.10447245091199875
Validation loss: 1.6866165771279285

Epoch: 6| Step: 5
Training loss: 0.07934358716011047
Validation loss: 1.7082214714378439

Epoch: 6| Step: 6
Training loss: 0.08296459913253784
Validation loss: 1.7073239895605272

Epoch: 6| Step: 7
Training loss: 0.07867292314767838
Validation loss: 1.7094622094144103

Epoch: 6| Step: 8
Training loss: 0.07783370465040207
Validation loss: 1.6882447286318707

Epoch: 6| Step: 9
Training loss: 0.12915313243865967
Validation loss: 1.7020621799653577

Epoch: 6| Step: 10
Training loss: 0.0876082181930542
Validation loss: 1.7008524312767932

Epoch: 6| Step: 11
Training loss: 0.06703463196754456
Validation loss: 1.693526461560239

Epoch: 6| Step: 12
Training loss: 0.14438921213150024
Validation loss: 1.6929016664463987

Epoch: 6| Step: 13
Training loss: 0.13546410202980042
Validation loss: 1.7225505664784422

Epoch: 463| Step: 0
Training loss: 0.12670686841011047
Validation loss: 1.7047530515219576

Epoch: 6| Step: 1
Training loss: 0.09901261329650879
Validation loss: 1.7344805335485807

Epoch: 6| Step: 2
Training loss: 0.07508044689893723
Validation loss: 1.6961467522446827

Epoch: 6| Step: 3
Training loss: 0.07807007431983948
Validation loss: 1.7075134067125217

Epoch: 6| Step: 4
Training loss: 0.14610207080841064
Validation loss: 1.6778350466041154

Epoch: 6| Step: 5
Training loss: 0.0701492577791214
Validation loss: 1.7056412184110252

Epoch: 6| Step: 6
Training loss: 0.06255064159631729
Validation loss: 1.7320702909141459

Epoch: 6| Step: 7
Training loss: 0.06568969786167145
Validation loss: 1.728567136231289

Epoch: 6| Step: 8
Training loss: 0.13710391521453857
Validation loss: 1.711515607372407

Epoch: 6| Step: 9
Training loss: 0.11971545964479446
Validation loss: 1.701815394945042

Epoch: 6| Step: 10
Training loss: 0.0483865812420845
Validation loss: 1.7085029566159813

Epoch: 6| Step: 11
Training loss: 0.14525139331817627
Validation loss: 1.672663611750449

Epoch: 6| Step: 12
Training loss: 0.0877181813120842
Validation loss: 1.7066440223365702

Epoch: 6| Step: 13
Training loss: 0.13343845307826996
Validation loss: 1.7013611870427285

Epoch: 464| Step: 0
Training loss: 0.1655234694480896
Validation loss: 1.661330557638599

Epoch: 6| Step: 1
Training loss: 0.07386571168899536
Validation loss: 1.671941598256429

Epoch: 6| Step: 2
Training loss: 0.12569190561771393
Validation loss: 1.6755043473294986

Epoch: 6| Step: 3
Training loss: 0.05443703010678291
Validation loss: 1.6649223066145373

Epoch: 6| Step: 4
Training loss: 0.07699549198150635
Validation loss: 1.679123793878863

Epoch: 6| Step: 5
Training loss: 0.1226777508854866
Validation loss: 1.6574513373836395

Epoch: 6| Step: 6
Training loss: 0.0536491721868515
Validation loss: 1.686275674450782

Epoch: 6| Step: 7
Training loss: 0.09524834156036377
Validation loss: 1.6715840126878472

Epoch: 6| Step: 8
Training loss: 0.10494581609964371
Validation loss: 1.6450341901471537

Epoch: 6| Step: 9
Training loss: 0.1285349577665329
Validation loss: 1.67451649455614

Epoch: 6| Step: 10
Training loss: 0.0949912965297699
Validation loss: 1.6625878349427254

Epoch: 6| Step: 11
Training loss: 0.07562252879142761
Validation loss: 1.6812397485138268

Epoch: 6| Step: 12
Training loss: 0.09637416154146194
Validation loss: 1.63637492861799

Epoch: 6| Step: 13
Training loss: 0.11250308156013489
Validation loss: 1.7126334777442358

Epoch: 465| Step: 0
Training loss: 0.15197956562042236
Validation loss: 1.693828723763907

Epoch: 6| Step: 1
Training loss: 0.12267345190048218
Validation loss: 1.7142967447157829

Epoch: 6| Step: 2
Training loss: 0.1299680918455124
Validation loss: 1.6900640328725178

Epoch: 6| Step: 3
Training loss: 0.10200665891170502
Validation loss: 1.681109454042168

Epoch: 6| Step: 4
Training loss: 0.09391386806964874
Validation loss: 1.6689482235139417

Epoch: 6| Step: 5
Training loss: 0.12917286157608032
Validation loss: 1.678605789779335

Epoch: 6| Step: 6
Training loss: 0.09662938117980957
Validation loss: 1.671792204662036

Epoch: 6| Step: 7
Training loss: 0.15097258985042572
Validation loss: 1.6691335401227396

Epoch: 6| Step: 8
Training loss: 0.08135360479354858
Validation loss: 1.6575734820417178

Epoch: 6| Step: 9
Training loss: 0.14573894441127777
Validation loss: 1.6430973365742674

Epoch: 6| Step: 10
Training loss: 0.15877628326416016
Validation loss: 1.6807642752124416

Epoch: 6| Step: 11
Training loss: 0.11769890040159225
Validation loss: 1.707658721554664

Epoch: 6| Step: 12
Training loss: 0.09546776115894318
Validation loss: 1.671032844051238

Epoch: 6| Step: 13
Training loss: 0.10525037348270416
Validation loss: 1.6715298660339848

Epoch: 466| Step: 0
Training loss: 0.09967370331287384
Validation loss: 1.6714428073616439

Epoch: 6| Step: 1
Training loss: 0.06967945396900177
Validation loss: 1.6668114328897128

Epoch: 6| Step: 2
Training loss: 0.1296108365058899
Validation loss: 1.6985460148062757

Epoch: 6| Step: 3
Training loss: 0.12406525015830994
Validation loss: 1.7048590888259232

Epoch: 6| Step: 4
Training loss: 0.06623828411102295
Validation loss: 1.6814920786888368

Epoch: 6| Step: 5
Training loss: 0.11014164984226227
Validation loss: 1.6758610202420143

Epoch: 6| Step: 6
Training loss: 0.1347855031490326
Validation loss: 1.6624221135211248

Epoch: 6| Step: 7
Training loss: 0.0923306792974472
Validation loss: 1.67261851474803

Epoch: 6| Step: 8
Training loss: 0.1016336977481842
Validation loss: 1.6666740960972284

Epoch: 6| Step: 9
Training loss: 0.17979994416236877
Validation loss: 1.7016097038022933

Epoch: 6| Step: 10
Training loss: 0.1338314414024353
Validation loss: 1.6976459385246359

Epoch: 6| Step: 11
Training loss: 0.15796083211898804
Validation loss: 1.6864398423061575

Epoch: 6| Step: 12
Training loss: 0.14417722821235657
Validation loss: 1.6718292031236874

Epoch: 6| Step: 13
Training loss: 0.10390061885118484
Validation loss: 1.6262054879178283

Epoch: 467| Step: 0
Training loss: 0.19061274826526642
Validation loss: 1.633199022662255

Epoch: 6| Step: 1
Training loss: 0.13587725162506104
Validation loss: 1.6367121614435667

Epoch: 6| Step: 2
Training loss: 0.15671885013580322
Validation loss: 1.6882338190591464

Epoch: 6| Step: 3
Training loss: 0.26040393114089966
Validation loss: 1.6771278304438437

Epoch: 6| Step: 4
Training loss: 0.22100834548473358
Validation loss: 1.6922955692455333

Epoch: 6| Step: 5
Training loss: 0.05976800620555878
Validation loss: 1.666964557863051

Epoch: 6| Step: 6
Training loss: 0.17122165858745575
Validation loss: 1.7237377243657266

Epoch: 6| Step: 7
Training loss: 0.0921708270907402
Validation loss: 1.7737029778060092

Epoch: 6| Step: 8
Training loss: 0.08827093243598938
Validation loss: 1.719474572007374

Epoch: 6| Step: 9
Training loss: 0.1759437471628189
Validation loss: 1.7703437343720467

Epoch: 6| Step: 10
Training loss: 0.1831946223974228
Validation loss: 1.7717943717074651

Epoch: 6| Step: 11
Training loss: 0.09371983259916306
Validation loss: 1.7707037618083339

Epoch: 6| Step: 12
Training loss: 0.09720849990844727
Validation loss: 1.7623951614543956

Epoch: 6| Step: 13
Training loss: 0.2963041067123413
Validation loss: 1.7034754599294355

Epoch: 468| Step: 0
Training loss: 0.07237353920936584
Validation loss: 1.7138855893124816

Epoch: 6| Step: 1
Training loss: 0.0693705603480339
Validation loss: 1.7074241074182654

Epoch: 6| Step: 2
Training loss: 0.12051788717508316
Validation loss: 1.7295519254540885

Epoch: 6| Step: 3
Training loss: 0.09386507421731949
Validation loss: 1.7145492633183796

Epoch: 6| Step: 4
Training loss: 0.19470247626304626
Validation loss: 1.7531021384782688

Epoch: 6| Step: 5
Training loss: 0.05922340601682663
Validation loss: 1.74101810942414

Epoch: 6| Step: 6
Training loss: 0.12408610433340073
Validation loss: 1.7704847602434055

Epoch: 6| Step: 7
Training loss: 0.09270504117012024
Validation loss: 1.8003779662552701

Epoch: 6| Step: 8
Training loss: 0.1185259222984314
Validation loss: 1.8120247074352798

Epoch: 6| Step: 9
Training loss: 0.17656344175338745
Validation loss: 1.773959962270593

Epoch: 6| Step: 10
Training loss: 0.10228358954191208
Validation loss: 1.768316981612995

Epoch: 6| Step: 11
Training loss: 0.17615537345409393
Validation loss: 1.77618424354061

Epoch: 6| Step: 12
Training loss: 0.135949045419693
Validation loss: 1.7447172005971272

Epoch: 6| Step: 13
Training loss: 0.1001407578587532
Validation loss: 1.6993649659618255

Epoch: 469| Step: 0
Training loss: 0.0852372869849205
Validation loss: 1.6763705053637106

Epoch: 6| Step: 1
Training loss: 0.1447504311800003
Validation loss: 1.6754107500917168

Epoch: 6| Step: 2
Training loss: 0.16070431470870972
Validation loss: 1.7138714264797907

Epoch: 6| Step: 3
Training loss: 0.29183048009872437
Validation loss: 1.7122676859619796

Epoch: 6| Step: 4
Training loss: 0.2825670540332794
Validation loss: 1.6783730022368892

Epoch: 6| Step: 5
Training loss: 0.10676949471235275
Validation loss: 1.7146259225824827

Epoch: 6| Step: 6
Training loss: 0.09367060661315918
Validation loss: 1.696271260579427

Epoch: 6| Step: 7
Training loss: 0.1519409716129303
Validation loss: 1.7459619365712649

Epoch: 6| Step: 8
Training loss: 0.1717062145471573
Validation loss: 1.7600629393772413

Epoch: 6| Step: 9
Training loss: 0.141871839761734
Validation loss: 1.7671565701884608

Epoch: 6| Step: 10
Training loss: 0.2240910679101944
Validation loss: 1.7783242438429145

Epoch: 6| Step: 11
Training loss: 0.18320602178573608
Validation loss: 1.7719568437145603

Epoch: 6| Step: 12
Training loss: 0.08585841208696365
Validation loss: 1.7289937350057787

Epoch: 6| Step: 13
Training loss: 0.08700421452522278
Validation loss: 1.7114935280174337

Epoch: 470| Step: 0
Training loss: 0.13533280789852142
Validation loss: 1.7369033918585828

Epoch: 6| Step: 1
Training loss: 0.1727471649646759
Validation loss: 1.6991148635905275

Epoch: 6| Step: 2
Training loss: 0.14015993475914001
Validation loss: 1.7440844799882622

Epoch: 6| Step: 3
Training loss: 0.12969468533992767
Validation loss: 1.748527680673907

Epoch: 6| Step: 4
Training loss: 0.22468550503253937
Validation loss: 1.7095701489397275

Epoch: 6| Step: 5
Training loss: 0.08028053492307663
Validation loss: 1.7143923582569245

Epoch: 6| Step: 6
Training loss: 0.12730185687541962
Validation loss: 1.7201253034735238

Epoch: 6| Step: 7
Training loss: 0.1070769727230072
Validation loss: 1.7522263488461893

Epoch: 6| Step: 8
Training loss: 0.12914900481700897
Validation loss: 1.7453786980721258

Epoch: 6| Step: 9
Training loss: 0.16409839689731598
Validation loss: 1.7429702358861123

Epoch: 6| Step: 10
Training loss: 0.07468751817941666
Validation loss: 1.7265875416417276

Epoch: 6| Step: 11
Training loss: 0.07542011141777039
Validation loss: 1.7231710521123742

Epoch: 6| Step: 12
Training loss: 0.1301942765712738
Validation loss: 1.6798077193639611

Epoch: 6| Step: 13
Training loss: 0.09625956416130066
Validation loss: 1.6698738567290767

Epoch: 471| Step: 0
Training loss: 0.14711949229240417
Validation loss: 1.6760124134761032

Epoch: 6| Step: 1
Training loss: 0.1658833920955658
Validation loss: 1.6664500749239357

Epoch: 6| Step: 2
Training loss: 0.17897048592567444
Validation loss: 1.6832803846687399

Epoch: 6| Step: 3
Training loss: 0.13450804352760315
Validation loss: 1.6416669391816663

Epoch: 6| Step: 4
Training loss: 0.1174425482749939
Validation loss: 1.6863889642941055

Epoch: 6| Step: 5
Training loss: 0.06446897238492966
Validation loss: 1.7087141647133777

Epoch: 6| Step: 6
Training loss: 0.05398116633296013
Validation loss: 1.6756973087146718

Epoch: 6| Step: 7
Training loss: 0.06994584202766418
Validation loss: 1.735293322993863

Epoch: 6| Step: 8
Training loss: 0.06638972461223602
Validation loss: 1.7049827973047893

Epoch: 6| Step: 9
Training loss: 0.07973363995552063
Validation loss: 1.7034244665535547

Epoch: 6| Step: 10
Training loss: 0.09131448715925217
Validation loss: 1.705848083701185

Epoch: 6| Step: 11
Training loss: 0.0732448473572731
Validation loss: 1.6881745182057863

Epoch: 6| Step: 12
Training loss: 0.07120949774980545
Validation loss: 1.6912334631848078

Epoch: 6| Step: 13
Training loss: 0.09584471583366394
Validation loss: 1.6805764398267191

Epoch: 472| Step: 0
Training loss: 0.10447701811790466
Validation loss: 1.731091712110786

Epoch: 6| Step: 1
Training loss: 0.07826878130435944
Validation loss: 1.7352197272803194

Epoch: 6| Step: 2
Training loss: 0.06760305911302567
Validation loss: 1.7514953792736094

Epoch: 6| Step: 3
Training loss: 0.09866711497306824
Validation loss: 1.7341331769061346

Epoch: 6| Step: 4
Training loss: 0.10655181854963303
Validation loss: 1.7155711548302763

Epoch: 6| Step: 5
Training loss: 0.1151258647441864
Validation loss: 1.7044398669273622

Epoch: 6| Step: 6
Training loss: 0.15558236837387085
Validation loss: 1.7146830751049904

Epoch: 6| Step: 7
Training loss: 0.12350299209356308
Validation loss: 1.7229335577257219

Epoch: 6| Step: 8
Training loss: 0.07732191681861877
Validation loss: 1.709045704974923

Epoch: 6| Step: 9
Training loss: 0.0717710331082344
Validation loss: 1.702345266137072

Epoch: 6| Step: 10
Training loss: 0.11677413433790207
Validation loss: 1.6845751885444886

Epoch: 6| Step: 11
Training loss: 0.08473333716392517
Validation loss: 1.6905226617731073

Epoch: 6| Step: 12
Training loss: 0.15293312072753906
Validation loss: 1.732540871507378

Epoch: 6| Step: 13
Training loss: 0.07790122926235199
Validation loss: 1.7267519479156823

Epoch: 473| Step: 0
Training loss: 0.12493693828582764
Validation loss: 1.7417392679440078

Epoch: 6| Step: 1
Training loss: 0.12356261163949966
Validation loss: 1.7065191653466993

Epoch: 6| Step: 2
Training loss: 0.08768640458583832
Validation loss: 1.7080638229206044

Epoch: 6| Step: 3
Training loss: 0.07836857438087463
Validation loss: 1.744310571301368

Epoch: 6| Step: 4
Training loss: 0.10265564918518066
Validation loss: 1.7365697289025912

Epoch: 6| Step: 5
Training loss: 0.10106894373893738
Validation loss: 1.7289581350100938

Epoch: 6| Step: 6
Training loss: 0.07794050872325897
Validation loss: 1.7255279992216377

Epoch: 6| Step: 7
Training loss: 0.10175114870071411
Validation loss: 1.721101539109343

Epoch: 6| Step: 8
Training loss: 0.12263337522745132
Validation loss: 1.7527227305596875

Epoch: 6| Step: 9
Training loss: 0.11051615327596664
Validation loss: 1.771439613834504

Epoch: 6| Step: 10
Training loss: 0.16280826926231384
Validation loss: 1.7587338532170942

Epoch: 6| Step: 11
Training loss: 0.09414072334766388
Validation loss: 1.7510297144612958

Epoch: 6| Step: 12
Training loss: 0.13180682063102722
Validation loss: 1.734623760305425

Epoch: 6| Step: 13
Training loss: 0.13472995162010193
Validation loss: 1.7443799908443163

Epoch: 474| Step: 0
Training loss: 0.09530439227819443
Validation loss: 1.7300328336736208

Epoch: 6| Step: 1
Training loss: 0.1093502938747406
Validation loss: 1.701669196928701

Epoch: 6| Step: 2
Training loss: 0.10281895101070404
Validation loss: 1.7372928280984201

Epoch: 6| Step: 3
Training loss: 0.1216658428311348
Validation loss: 1.7629998178892239

Epoch: 6| Step: 4
Training loss: 0.10985615849494934
Validation loss: 1.7378383169892013

Epoch: 6| Step: 5
Training loss: 0.11825942248106003
Validation loss: 1.715766890074617

Epoch: 6| Step: 6
Training loss: 0.11984913051128387
Validation loss: 1.722177477293117

Epoch: 6| Step: 7
Training loss: 0.06798951327800751
Validation loss: 1.7268746001746065

Epoch: 6| Step: 8
Training loss: 0.11776600033044815
Validation loss: 1.7611991346523326

Epoch: 6| Step: 9
Training loss: 0.11631997674703598
Validation loss: 1.7072601651632657

Epoch: 6| Step: 10
Training loss: 0.12604625523090363
Validation loss: 1.7331030266259306

Epoch: 6| Step: 11
Training loss: 0.1796102225780487
Validation loss: 1.7196238912561888

Epoch: 6| Step: 12
Training loss: 0.07954394072294235
Validation loss: 1.7121561983580231

Epoch: 6| Step: 13
Training loss: 0.062002286314964294
Validation loss: 1.7089796220102618

Epoch: 475| Step: 0
Training loss: 0.08605058491230011
Validation loss: 1.6876360293357604

Epoch: 6| Step: 1
Training loss: 0.16038575768470764
Validation loss: 1.6920868901796238

Epoch: 6| Step: 2
Training loss: 0.09894208610057831
Validation loss: 1.6737843892907585

Epoch: 6| Step: 3
Training loss: 0.07571285218000412
Validation loss: 1.677600738822773

Epoch: 6| Step: 4
Training loss: 0.17954713106155396
Validation loss: 1.6471425294876099

Epoch: 6| Step: 5
Training loss: 0.24773263931274414
Validation loss: 1.7026884184088757

Epoch: 6| Step: 6
Training loss: 0.08851823210716248
Validation loss: 1.6912492052201302

Epoch: 6| Step: 7
Training loss: 0.14811009168624878
Validation loss: 1.7023007331355926

Epoch: 6| Step: 8
Training loss: 0.08449017256498337
Validation loss: 1.6849309308554536

Epoch: 6| Step: 9
Training loss: 0.08947208523750305
Validation loss: 1.7260037109416018

Epoch: 6| Step: 10
Training loss: 0.07614177465438843
Validation loss: 1.6936184424226002

Epoch: 6| Step: 11
Training loss: 0.10551142692565918
Validation loss: 1.7231919855199835

Epoch: 6| Step: 12
Training loss: 0.12107779830694199
Validation loss: 1.706515630086263

Epoch: 6| Step: 13
Training loss: 0.07577291876077652
Validation loss: 1.705963833357698

Epoch: 476| Step: 0
Training loss: 0.13102513551712036
Validation loss: 1.6884870772720666

Epoch: 6| Step: 1
Training loss: 0.074385866522789
Validation loss: 1.708282745012673

Epoch: 6| Step: 2
Training loss: 0.11882179230451584
Validation loss: 1.7236675613669938

Epoch: 6| Step: 3
Training loss: 0.07522999495267868
Validation loss: 1.7017494786170222

Epoch: 6| Step: 4
Training loss: 0.10743033140897751
Validation loss: 1.6899043180609261

Epoch: 6| Step: 5
Training loss: 0.12690675258636475
Validation loss: 1.6893663842190978

Epoch: 6| Step: 6
Training loss: 0.07047834247350693
Validation loss: 1.704680274891597

Epoch: 6| Step: 7
Training loss: 0.10694438219070435
Validation loss: 1.695739576893468

Epoch: 6| Step: 8
Training loss: 0.08386848866939545
Validation loss: 1.6891031777986916

Epoch: 6| Step: 9
Training loss: 0.09676814079284668
Validation loss: 1.7208131487651537

Epoch: 6| Step: 10
Training loss: 0.10749051719903946
Validation loss: 1.7164262340914818

Epoch: 6| Step: 11
Training loss: 0.056102655827999115
Validation loss: 1.7080445392157442

Epoch: 6| Step: 12
Training loss: 0.059957366436719894
Validation loss: 1.7076375176829677

Epoch: 6| Step: 13
Training loss: 0.0531824454665184
Validation loss: 1.7161609562494422

Epoch: 477| Step: 0
Training loss: 0.11695761233568192
Validation loss: 1.7138438814429826

Epoch: 6| Step: 1
Training loss: 0.08239356428384781
Validation loss: 1.7267716264212003

Epoch: 6| Step: 2
Training loss: 0.10249428451061249
Validation loss: 1.7085225069394676

Epoch: 6| Step: 3
Training loss: 0.07185140252113342
Validation loss: 1.6931468838004655

Epoch: 6| Step: 4
Training loss: 0.07482777535915375
Validation loss: 1.725560777930803

Epoch: 6| Step: 5
Training loss: 0.13308295607566833
Validation loss: 1.7222558131781958

Epoch: 6| Step: 6
Training loss: 0.06801023334264755
Validation loss: 1.7081765756812146

Epoch: 6| Step: 7
Training loss: 0.12821422517299652
Validation loss: 1.733863558820499

Epoch: 6| Step: 8
Training loss: 0.10958091169595718
Validation loss: 1.7462710488227107

Epoch: 6| Step: 9
Training loss: 0.08211739361286163
Validation loss: 1.7140457168702157

Epoch: 6| Step: 10
Training loss: 0.05813434720039368
Validation loss: 1.7078169289455618

Epoch: 6| Step: 11
Training loss: 0.11078052222728729
Validation loss: 1.6805335270461215

Epoch: 6| Step: 12
Training loss: 0.07829874008893967
Validation loss: 1.6921132713235834

Epoch: 6| Step: 13
Training loss: 0.05135411024093628
Validation loss: 1.6818434961380497

Epoch: 478| Step: 0
Training loss: 0.12144412100315094
Validation loss: 1.715700675082463

Epoch: 6| Step: 1
Training loss: 0.10249753296375275
Validation loss: 1.7163982801539923

Epoch: 6| Step: 2
Training loss: 0.0905015841126442
Validation loss: 1.6974540910413187

Epoch: 6| Step: 3
Training loss: 0.1637941300868988
Validation loss: 1.7026726840644755

Epoch: 6| Step: 4
Training loss: 0.10700618475675583
Validation loss: 1.7144443014616608

Epoch: 6| Step: 5
Training loss: 0.06748680770397186
Validation loss: 1.7096328222623436

Epoch: 6| Step: 6
Training loss: 0.1311640441417694
Validation loss: 1.7213373120113085

Epoch: 6| Step: 7
Training loss: 0.14235347509384155
Validation loss: 1.7183967918478034

Epoch: 6| Step: 8
Training loss: 0.06716333329677582
Validation loss: 1.6980512424181866

Epoch: 6| Step: 9
Training loss: 0.16773441433906555
Validation loss: 1.6964486158022316

Epoch: 6| Step: 10
Training loss: 0.11796107143163681
Validation loss: 1.6579844849084013

Epoch: 6| Step: 11
Training loss: 0.0890498012304306
Validation loss: 1.6670033675368114

Epoch: 6| Step: 12
Training loss: 0.04792694374918938
Validation loss: 1.6821728150049846

Epoch: 6| Step: 13
Training loss: 0.1220327615737915
Validation loss: 1.6831664039242653

Epoch: 479| Step: 0
Training loss: 0.129871666431427
Validation loss: 1.6945755250992314

Epoch: 6| Step: 1
Training loss: 0.07141602039337158
Validation loss: 1.7019470443007767

Epoch: 6| Step: 2
Training loss: 0.12261714041233063
Validation loss: 1.6724383036295574

Epoch: 6| Step: 3
Training loss: 0.1775175780057907
Validation loss: 1.6850572683477913

Epoch: 6| Step: 4
Training loss: 0.13944435119628906
Validation loss: 1.669230463684246

Epoch: 6| Step: 5
Training loss: 0.10689094662666321
Validation loss: 1.661960422351796

Epoch: 6| Step: 6
Training loss: 0.12139450758695602
Validation loss: 1.6824056435656805

Epoch: 6| Step: 7
Training loss: 0.08300536125898361
Validation loss: 1.690104631967442

Epoch: 6| Step: 8
Training loss: 0.07643014192581177
Validation loss: 1.6829849853310535

Epoch: 6| Step: 9
Training loss: 0.15518051385879517
Validation loss: 1.7105272995528353

Epoch: 6| Step: 10
Training loss: 0.04444232955574989
Validation loss: 1.694642234874028

Epoch: 6| Step: 11
Training loss: 0.09674425423145294
Validation loss: 1.7075266530436854

Epoch: 6| Step: 12
Training loss: 0.074076347053051
Validation loss: 1.7225799714365313

Epoch: 6| Step: 13
Training loss: 0.06946171820163727
Validation loss: 1.705084067518993

Epoch: 480| Step: 0
Training loss: 0.09925951063632965
Validation loss: 1.7182270314103814

Epoch: 6| Step: 1
Training loss: 0.0467485636472702
Validation loss: 1.7344856531389299

Epoch: 6| Step: 2
Training loss: 0.0997110903263092
Validation loss: 1.740017270529142

Epoch: 6| Step: 3
Training loss: 0.10400264710187912
Validation loss: 1.7538563064349595

Epoch: 6| Step: 4
Training loss: 0.07648801803588867
Validation loss: 1.764256864465693

Epoch: 6| Step: 5
Training loss: 0.1225309893488884
Validation loss: 1.7609696183153378

Epoch: 6| Step: 6
Training loss: 0.07187028229236603
Validation loss: 1.7295963110462311

Epoch: 6| Step: 7
Training loss: 0.09682530164718628
Validation loss: 1.727248840434577

Epoch: 6| Step: 8
Training loss: 0.07656269520521164
Validation loss: 1.7536222255358132

Epoch: 6| Step: 9
Training loss: 0.1111089214682579
Validation loss: 1.7383484917302285

Epoch: 6| Step: 10
Training loss: 0.10542748868465424
Validation loss: 1.7286039731835807

Epoch: 6| Step: 11
Training loss: 0.07834845781326294
Validation loss: 1.7466553654721988

Epoch: 6| Step: 12
Training loss: 0.07764461636543274
Validation loss: 1.727443795050344

Epoch: 6| Step: 13
Training loss: 0.1394844800233841
Validation loss: 1.7379491361238624

Epoch: 481| Step: 0
Training loss: 0.08927065879106522
Validation loss: 1.7446864497277044

Epoch: 6| Step: 1
Training loss: 0.05924005061388016
Validation loss: 1.7162877359697897

Epoch: 6| Step: 2
Training loss: 0.0799817442893982
Validation loss: 1.7271884564430482

Epoch: 6| Step: 3
Training loss: 0.06767827272415161
Validation loss: 1.7282794726792203

Epoch: 6| Step: 4
Training loss: 0.06264284253120422
Validation loss: 1.7054552570466073

Epoch: 6| Step: 5
Training loss: 0.11483603715896606
Validation loss: 1.6906950736558566

Epoch: 6| Step: 6
Training loss: 0.06493307650089264
Validation loss: 1.645357185794461

Epoch: 6| Step: 7
Training loss: 0.1934787631034851
Validation loss: 1.6293220776383595

Epoch: 6| Step: 8
Training loss: 0.12312724441289902
Validation loss: 1.584349488699308

Epoch: 6| Step: 9
Training loss: 0.18343524634838104
Validation loss: 1.6383993356458602

Epoch: 6| Step: 10
Training loss: 0.10229797661304474
Validation loss: 1.6348741080171318

Epoch: 6| Step: 11
Training loss: 0.08979795128107071
Validation loss: 1.6662406985477736

Epoch: 6| Step: 12
Training loss: 0.0915801078081131
Validation loss: 1.652343532090546

Epoch: 6| Step: 13
Training loss: 0.07094359397888184
Validation loss: 1.6579234664158156

Epoch: 482| Step: 0
Training loss: 0.12072718143463135
Validation loss: 1.6841172652859842

Epoch: 6| Step: 1
Training loss: 0.1222461611032486
Validation loss: 1.6631463573824974

Epoch: 6| Step: 2
Training loss: 0.13063213229179382
Validation loss: 1.6808425726429108

Epoch: 6| Step: 3
Training loss: 0.10445191711187363
Validation loss: 1.6874158087597098

Epoch: 6| Step: 4
Training loss: 0.10770942270755768
Validation loss: 1.7115436125827093

Epoch: 6| Step: 5
Training loss: 0.11088579893112183
Validation loss: 1.6893559220016643

Epoch: 6| Step: 6
Training loss: 0.09266801923513412
Validation loss: 1.698859021227847

Epoch: 6| Step: 7
Training loss: 0.0930643379688263
Validation loss: 1.7066440915548673

Epoch: 6| Step: 8
Training loss: 0.10650889575481415
Validation loss: 1.6945850054423015

Epoch: 6| Step: 9
Training loss: 0.10530255734920502
Validation loss: 1.669464083128078

Epoch: 6| Step: 10
Training loss: 0.0674404501914978
Validation loss: 1.6377688787316764

Epoch: 6| Step: 11
Training loss: 0.11760004609823227
Validation loss: 1.6465823945178781

Epoch: 6| Step: 12
Training loss: 0.06695819646120071
Validation loss: 1.6533893718514392

Epoch: 6| Step: 13
Training loss: 0.18471486866474152
Validation loss: 1.6390237423681444

Epoch: 483| Step: 0
Training loss: 0.14577126502990723
Validation loss: 1.6505062157107937

Epoch: 6| Step: 1
Training loss: 0.12776817381381989
Validation loss: 1.6114870758466824

Epoch: 6| Step: 2
Training loss: 0.0798095166683197
Validation loss: 1.6506557323599373

Epoch: 6| Step: 3
Training loss: 0.08033067733049393
Validation loss: 1.6677454607461089

Epoch: 6| Step: 4
Training loss: 0.16005028784275055
Validation loss: 1.6837484580214306

Epoch: 6| Step: 5
Training loss: 0.11816783249378204
Validation loss: 1.7105094719958562

Epoch: 6| Step: 6
Training loss: 0.08486339449882507
Validation loss: 1.691608004672553

Epoch: 6| Step: 7
Training loss: 0.09521186351776123
Validation loss: 1.716951173479839

Epoch: 6| Step: 8
Training loss: 0.060994356870651245
Validation loss: 1.6887182894573416

Epoch: 6| Step: 9
Training loss: 0.10551337152719498
Validation loss: 1.73695759747618

Epoch: 6| Step: 10
Training loss: 0.045923296362161636
Validation loss: 1.7146564504151702

Epoch: 6| Step: 11
Training loss: 0.15171703696250916
Validation loss: 1.72175798877593

Epoch: 6| Step: 12
Training loss: 0.16001757979393005
Validation loss: 1.6938162401158323

Epoch: 6| Step: 13
Training loss: 0.08507699519395828
Validation loss: 1.726548792213522

Epoch: 484| Step: 0
Training loss: 0.10690896958112717
Validation loss: 1.7170004460119432

Epoch: 6| Step: 1
Training loss: 0.08510694652795792
Validation loss: 1.7066928526406646

Epoch: 6| Step: 2
Training loss: 0.052337221801280975
Validation loss: 1.7098152573390673

Epoch: 6| Step: 3
Training loss: 0.07012279331684113
Validation loss: 1.6783782461638093

Epoch: 6| Step: 4
Training loss: 0.08218152821063995
Validation loss: 1.656544428999706

Epoch: 6| Step: 5
Training loss: 0.060540683567523956
Validation loss: 1.6843578456550516

Epoch: 6| Step: 6
Training loss: 0.1369134783744812
Validation loss: 1.6555043330756567

Epoch: 6| Step: 7
Training loss: 0.1606445014476776
Validation loss: 1.6547224034545243

Epoch: 6| Step: 8
Training loss: 0.10751035064458847
Validation loss: 1.6730814659467308

Epoch: 6| Step: 9
Training loss: 0.1370500922203064
Validation loss: 1.649861135790425

Epoch: 6| Step: 10
Training loss: 0.13252010941505432
Validation loss: 1.6722806128122474

Epoch: 6| Step: 11
Training loss: 0.11593092978000641
Validation loss: 1.7034427286476217

Epoch: 6| Step: 12
Training loss: 0.20447257161140442
Validation loss: 1.697848145679761

Epoch: 6| Step: 13
Training loss: 0.05460546910762787
Validation loss: 1.6732435046985585

Epoch: 485| Step: 0
Training loss: 0.1320449560880661
Validation loss: 1.688687232232863

Epoch: 6| Step: 1
Training loss: 0.13300903141498566
Validation loss: 1.697513884113681

Epoch: 6| Step: 2
Training loss: 0.13033294677734375
Validation loss: 1.6680930814435404

Epoch: 6| Step: 3
Training loss: 0.13100236654281616
Validation loss: 1.6592451859545965

Epoch: 6| Step: 4
Training loss: 0.17404265701770782
Validation loss: 1.6945034316791001

Epoch: 6| Step: 5
Training loss: 0.11068254709243774
Validation loss: 1.695967189727291

Epoch: 6| Step: 6
Training loss: 0.09333492815494537
Validation loss: 1.7079161149199291

Epoch: 6| Step: 7
Training loss: 0.06171923130750656
Validation loss: 1.7455531756083171

Epoch: 6| Step: 8
Training loss: 0.10880818217992783
Validation loss: 1.7297987886654433

Epoch: 6| Step: 9
Training loss: 0.12957841157913208
Validation loss: 1.7453247385640298

Epoch: 6| Step: 10
Training loss: 0.09572045505046844
Validation loss: 1.7430984884180047

Epoch: 6| Step: 11
Training loss: 0.1736406832933426
Validation loss: 1.7361449862039218

Epoch: 6| Step: 12
Training loss: 0.07490716874599457
Validation loss: 1.6997122303132088

Epoch: 6| Step: 13
Training loss: 0.058823294937610626
Validation loss: 1.7021673340951242

Epoch: 486| Step: 0
Training loss: 0.19679859280586243
Validation loss: 1.6972736671406736

Epoch: 6| Step: 1
Training loss: 0.16728751361370087
Validation loss: 1.6717840445938932

Epoch: 6| Step: 2
Training loss: 0.11142649501562119
Validation loss: 1.6705546199634511

Epoch: 6| Step: 3
Training loss: 0.06924515962600708
Validation loss: 1.7185309215258526

Epoch: 6| Step: 4
Training loss: 0.10200873017311096
Validation loss: 1.68559435618821

Epoch: 6| Step: 5
Training loss: 0.1200157105922699
Validation loss: 1.6927795794702345

Epoch: 6| Step: 6
Training loss: 0.09513972699642181
Validation loss: 1.6883228427620345

Epoch: 6| Step: 7
Training loss: 0.12671086192131042
Validation loss: 1.7074395097712034

Epoch: 6| Step: 8
Training loss: 0.10423627495765686
Validation loss: 1.677141402357368

Epoch: 6| Step: 9
Training loss: 0.0680662989616394
Validation loss: 1.680308134325089

Epoch: 6| Step: 10
Training loss: 0.06602874398231506
Validation loss: 1.6684010054475518

Epoch: 6| Step: 11
Training loss: 0.10986838489770889
Validation loss: 1.6600698463378414

Epoch: 6| Step: 12
Training loss: 0.060980796813964844
Validation loss: 1.6832227578727148

Epoch: 6| Step: 13
Training loss: 0.05726280435919762
Validation loss: 1.6615844939344673

Epoch: 487| Step: 0
Training loss: 0.08399161696434021
Validation loss: 1.668211530613643

Epoch: 6| Step: 1
Training loss: 0.08922594785690308
Validation loss: 1.7026549616167623

Epoch: 6| Step: 2
Training loss: 0.08148765563964844
Validation loss: 1.731553077697754

Epoch: 6| Step: 3
Training loss: 0.13695572316646576
Validation loss: 1.6740926465680521

Epoch: 6| Step: 4
Training loss: 0.07892201840877533
Validation loss: 1.6664144941555556

Epoch: 6| Step: 5
Training loss: 0.0933946743607521
Validation loss: 1.6494262192838935

Epoch: 6| Step: 6
Training loss: 0.06347419321537018
Validation loss: 1.6323773373839676

Epoch: 6| Step: 7
Training loss: 0.0595620796084404
Validation loss: 1.647044119655445

Epoch: 6| Step: 8
Training loss: 0.12803149223327637
Validation loss: 1.6245913531190606

Epoch: 6| Step: 9
Training loss: 0.10783296823501587
Validation loss: 1.634216139393468

Epoch: 6| Step: 10
Training loss: 0.0827946662902832
Validation loss: 1.6233628385810441

Epoch: 6| Step: 11
Training loss: 0.05644209310412407
Validation loss: 1.6577054095524613

Epoch: 6| Step: 12
Training loss: 0.07889623194932938
Validation loss: 1.6645020118323706

Epoch: 6| Step: 13
Training loss: 0.18364901840686798
Validation loss: 1.6490475464892644

Epoch: 488| Step: 0
Training loss: 0.09214501082897186
Validation loss: 1.6993157991798975

Epoch: 6| Step: 1
Training loss: 0.14349204301834106
Validation loss: 1.70849811133518

Epoch: 6| Step: 2
Training loss: 0.09327919781208038
Validation loss: 1.7277248892732846

Epoch: 6| Step: 3
Training loss: 0.08795516937971115
Validation loss: 1.6471723407827399

Epoch: 6| Step: 4
Training loss: 0.23975275456905365
Validation loss: 1.6543205361212454

Epoch: 6| Step: 5
Training loss: 0.0702982172369957
Validation loss: 1.6860822605830368

Epoch: 6| Step: 6
Training loss: 0.13838455080986023
Validation loss: 1.642215359595514

Epoch: 6| Step: 7
Training loss: 0.12261386215686798
Validation loss: 1.6412091832007132

Epoch: 6| Step: 8
Training loss: 0.0724048912525177
Validation loss: 1.640865824555838

Epoch: 6| Step: 9
Training loss: 0.1049683541059494
Validation loss: 1.6878729610032932

Epoch: 6| Step: 10
Training loss: 0.09112416952848434
Validation loss: 1.6642835511956164

Epoch: 6| Step: 11
Training loss: 0.08143679797649384
Validation loss: 1.6536113780031922

Epoch: 6| Step: 12
Training loss: 0.07724055647850037
Validation loss: 1.6542345336688462

Epoch: 6| Step: 13
Training loss: 0.06211882829666138
Validation loss: 1.6659070958373368

Epoch: 489| Step: 0
Training loss: 0.08393196761608124
Validation loss: 1.694955321409369

Epoch: 6| Step: 1
Training loss: 0.11594287306070328
Validation loss: 1.642714301745097

Epoch: 6| Step: 2
Training loss: 0.13044977188110352
Validation loss: 1.6658444853239163

Epoch: 6| Step: 3
Training loss: 0.12471845000982285
Validation loss: 1.6980345249176025

Epoch: 6| Step: 4
Training loss: 0.12162017822265625
Validation loss: 1.6904993736615745

Epoch: 6| Step: 5
Training loss: 0.061607688665390015
Validation loss: 1.669991913662162

Epoch: 6| Step: 6
Training loss: 0.07033442705869675
Validation loss: 1.6665801079042497

Epoch: 6| Step: 7
Training loss: 0.09337568283081055
Validation loss: 1.6744638937775806

Epoch: 6| Step: 8
Training loss: 0.11073759198188782
Validation loss: 1.6529805416701941

Epoch: 6| Step: 9
Training loss: 0.11518365889787674
Validation loss: 1.6431543006691882

Epoch: 6| Step: 10
Training loss: 0.14086823165416718
Validation loss: 1.684351953127051

Epoch: 6| Step: 11
Training loss: 0.09467114508152008
Validation loss: 1.6424596450662101

Epoch: 6| Step: 12
Training loss: 0.12446993589401245
Validation loss: 1.6898645553537595

Epoch: 6| Step: 13
Training loss: 0.16617444157600403
Validation loss: 1.698958013647346

Epoch: 490| Step: 0
Training loss: 0.09162597358226776
Validation loss: 1.7238697134038454

Epoch: 6| Step: 1
Training loss: 0.06389668583869934
Validation loss: 1.7591457277215936

Epoch: 6| Step: 2
Training loss: 0.15132993459701538
Validation loss: 1.7363525782862017

Epoch: 6| Step: 3
Training loss: 0.10883760452270508
Validation loss: 1.7443332608028124

Epoch: 6| Step: 4
Training loss: 0.07950921356678009
Validation loss: 1.7215485111359627

Epoch: 6| Step: 5
Training loss: 0.06912831217050552
Validation loss: 1.69248019495318

Epoch: 6| Step: 6
Training loss: 0.06797102838754654
Validation loss: 1.6747967299594675

Epoch: 6| Step: 7
Training loss: 0.08099786937236786
Validation loss: 1.6947940972543531

Epoch: 6| Step: 8
Training loss: 0.1325913518667221
Validation loss: 1.6432269388629543

Epoch: 6| Step: 9
Training loss: 0.08513881266117096
Validation loss: 1.6349039167486212

Epoch: 6| Step: 10
Training loss: 0.0885578840970993
Validation loss: 1.6343874187879666

Epoch: 6| Step: 11
Training loss: 0.09518919885158539
Validation loss: 1.6105237712142288

Epoch: 6| Step: 12
Training loss: 0.07527938485145569
Validation loss: 1.6060116867865286

Epoch: 6| Step: 13
Training loss: 0.07640603184700012
Validation loss: 1.6148950489618445

Epoch: 491| Step: 0
Training loss: 0.09027083963155746
Validation loss: 1.6156838709308254

Epoch: 6| Step: 1
Training loss: 0.07996831834316254
Validation loss: 1.6185995558256745

Epoch: 6| Step: 2
Training loss: 0.06448328495025635
Validation loss: 1.6196620630961593

Epoch: 6| Step: 3
Training loss: 0.09237830340862274
Validation loss: 1.6251985872945478

Epoch: 6| Step: 4
Training loss: 0.08947061002254486
Validation loss: 1.6282369065028366

Epoch: 6| Step: 5
Training loss: 0.11569172143936157
Validation loss: 1.637859276545945

Epoch: 6| Step: 6
Training loss: 0.046364523470401764
Validation loss: 1.6581859127167733

Epoch: 6| Step: 7
Training loss: 0.10623116791248322
Validation loss: 1.6542376850240974

Epoch: 6| Step: 8
Training loss: 0.10252015292644501
Validation loss: 1.6711282473738476

Epoch: 6| Step: 9
Training loss: 0.056817129254341125
Validation loss: 1.7144861862223635

Epoch: 6| Step: 10
Training loss: 0.06923185288906097
Validation loss: 1.6718561392958446

Epoch: 6| Step: 11
Training loss: 0.07806200534105301
Validation loss: 1.6659480679419734

Epoch: 6| Step: 12
Training loss: 0.14632980525493622
Validation loss: 1.6937924559398363

Epoch: 6| Step: 13
Training loss: 0.18111099302768707
Validation loss: 1.7057355065499582

Epoch: 492| Step: 0
Training loss: 0.1559881865978241
Validation loss: 1.7308675012280863

Epoch: 6| Step: 1
Training loss: 0.0852230042219162
Validation loss: 1.6884859633702103

Epoch: 6| Step: 2
Training loss: 0.05126701295375824
Validation loss: 1.6992113936331965

Epoch: 6| Step: 3
Training loss: 0.08934393525123596
Validation loss: 1.672091539188098

Epoch: 6| Step: 4
Training loss: 0.09738022089004517
Validation loss: 1.688499463501797

Epoch: 6| Step: 5
Training loss: 0.07102788239717484
Validation loss: 1.674641461782558

Epoch: 6| Step: 6
Training loss: 0.10939668864011765
Validation loss: 1.6376571975728518

Epoch: 6| Step: 7
Training loss: 0.10954698920249939
Validation loss: 1.6262518718678465

Epoch: 6| Step: 8
Training loss: 0.07328587770462036
Validation loss: 1.6171885498108403

Epoch: 6| Step: 9
Training loss: 0.07733654975891113
Validation loss: 1.6203530591021302

Epoch: 6| Step: 10
Training loss: 0.08894241601228714
Validation loss: 1.631597944485244

Epoch: 6| Step: 11
Training loss: 0.05426232889294624
Validation loss: 1.6217505829308623

Epoch: 6| Step: 12
Training loss: 0.15585237741470337
Validation loss: 1.6263645746374642

Epoch: 6| Step: 13
Training loss: 0.0659865289926529
Validation loss: 1.642626964917747

Epoch: 493| Step: 0
Training loss: 0.12081454694271088
Validation loss: 1.6735929289171774

Epoch: 6| Step: 1
Training loss: 0.05978003144264221
Validation loss: 1.6872524356329313

Epoch: 6| Step: 2
Training loss: 0.11427189409732819
Validation loss: 1.6967221716398835

Epoch: 6| Step: 3
Training loss: 0.12595127522945404
Validation loss: 1.682196609435543

Epoch: 6| Step: 4
Training loss: 0.10904820263385773
Validation loss: 1.6812508734323646

Epoch: 6| Step: 5
Training loss: 0.06256050616502762
Validation loss: 1.6861335398048483

Epoch: 6| Step: 6
Training loss: 0.08966600894927979
Validation loss: 1.673714142973705

Epoch: 6| Step: 7
Training loss: 0.1357249617576599
Validation loss: 1.6788069817327684

Epoch: 6| Step: 8
Training loss: 0.11601083725690842
Validation loss: 1.6927522856702086

Epoch: 6| Step: 9
Training loss: 0.1385151594877243
Validation loss: 1.7206976836727512

Epoch: 6| Step: 10
Training loss: 0.06081894040107727
Validation loss: 1.708056103798651

Epoch: 6| Step: 11
Training loss: 0.10960591584444046
Validation loss: 1.779682990043394

Epoch: 6| Step: 12
Training loss: 0.10183530300855637
Validation loss: 1.7652842408867293

Epoch: 6| Step: 13
Training loss: 0.04309239611029625
Validation loss: 1.7813266682368454

Epoch: 494| Step: 0
Training loss: 0.18358522653579712
Validation loss: 1.7849809636351883

Epoch: 6| Step: 1
Training loss: 0.15875279903411865
Validation loss: 1.7628424526542745

Epoch: 6| Step: 2
Training loss: 0.1328757107257843
Validation loss: 1.7730153478601927

Epoch: 6| Step: 3
Training loss: 0.13698241114616394
Validation loss: 1.7411310339486727

Epoch: 6| Step: 4
Training loss: 0.11494535207748413
Validation loss: 1.702905075524443

Epoch: 6| Step: 5
Training loss: 0.14745476841926575
Validation loss: 1.6967407772617955

Epoch: 6| Step: 6
Training loss: 0.16851019859313965
Validation loss: 1.6949995204966555

Epoch: 6| Step: 7
Training loss: 0.07517950236797333
Validation loss: 1.688792646572154

Epoch: 6| Step: 8
Training loss: 0.039670106023550034
Validation loss: 1.65719138550502

Epoch: 6| Step: 9
Training loss: 0.08649387955665588
Validation loss: 1.6841650111700899

Epoch: 6| Step: 10
Training loss: 0.20442482829093933
Validation loss: 1.6647815422345233

Epoch: 6| Step: 11
Training loss: 0.11568047106266022
Validation loss: 1.6894973478009623

Epoch: 6| Step: 12
Training loss: 0.15791678428649902
Validation loss: 1.665813269153718

Epoch: 6| Step: 13
Training loss: 0.043210387229919434
Validation loss: 1.6495835806733818

Epoch: 495| Step: 0
Training loss: 0.11296653002500534
Validation loss: 1.6560054568834202

Epoch: 6| Step: 1
Training loss: 0.11629896610975266
Validation loss: 1.6391526217101722

Epoch: 6| Step: 2
Training loss: 0.09706934541463852
Validation loss: 1.6568210009605653

Epoch: 6| Step: 3
Training loss: 0.1057988777756691
Validation loss: 1.6337302243837746

Epoch: 6| Step: 4
Training loss: 0.06075376272201538
Validation loss: 1.628333987087332

Epoch: 6| Step: 5
Training loss: 0.04739860072731972
Validation loss: 1.647042130911222

Epoch: 6| Step: 6
Training loss: 0.13398662209510803
Validation loss: 1.6482197815372097

Epoch: 6| Step: 7
Training loss: 0.10561350733041763
Validation loss: 1.6236793386038912

Epoch: 6| Step: 8
Training loss: 0.13332854211330414
Validation loss: 1.6300861130478561

Epoch: 6| Step: 9
Training loss: 0.11988215148448944
Validation loss: 1.6305584651167675

Epoch: 6| Step: 10
Training loss: 0.06167685240507126
Validation loss: 1.6294415176555674

Epoch: 6| Step: 11
Training loss: 0.10737443715333939
Validation loss: 1.677454666424823

Epoch: 6| Step: 12
Training loss: 0.11016805469989777
Validation loss: 1.697803170450272

Epoch: 6| Step: 13
Training loss: 0.06061156094074249
Validation loss: 1.6979180535962504

Epoch: 496| Step: 0
Training loss: 0.09377485513687134
Validation loss: 1.7081039823511595

Epoch: 6| Step: 1
Training loss: 0.12802168726921082
Validation loss: 1.7018638887713033

Epoch: 6| Step: 2
Training loss: 0.08150121569633484
Validation loss: 1.7185189916241554

Epoch: 6| Step: 3
Training loss: 0.05068112909793854
Validation loss: 1.72357008277729

Epoch: 6| Step: 4
Training loss: 0.09828760474920273
Validation loss: 1.7164529856815134

Epoch: 6| Step: 5
Training loss: 0.13225620985031128
Validation loss: 1.7182795783524871

Epoch: 6| Step: 6
Training loss: 0.1221671849489212
Validation loss: 1.7237478443371352

Epoch: 6| Step: 7
Training loss: 0.14854469895362854
Validation loss: 1.7411785189823439

Epoch: 6| Step: 8
Training loss: 0.13662944734096527
Validation loss: 1.715928175116098

Epoch: 6| Step: 9
Training loss: 0.11420268565416336
Validation loss: 1.708786569615846

Epoch: 6| Step: 10
Training loss: 0.10591030865907669
Validation loss: 1.6706421336820048

Epoch: 6| Step: 11
Training loss: 0.08761671930551529
Validation loss: 1.7123339945270168

Epoch: 6| Step: 12
Training loss: 0.1470182240009308
Validation loss: 1.6813712543056858

Epoch: 6| Step: 13
Training loss: 0.16962145268917084
Validation loss: 1.668070536787792

Epoch: 497| Step: 0
Training loss: 0.08377547562122345
Validation loss: 1.686108636599715

Epoch: 6| Step: 1
Training loss: 0.13563114404678345
Validation loss: 1.6940413418636526

Epoch: 6| Step: 2
Training loss: 0.08014579117298126
Validation loss: 1.6692600878336097

Epoch: 6| Step: 3
Training loss: 0.06736031919717789
Validation loss: 1.688181879699871

Epoch: 6| Step: 4
Training loss: 0.16377809643745422
Validation loss: 1.641117459984236

Epoch: 6| Step: 5
Training loss: 0.07909893989562988
Validation loss: 1.6602665134655532

Epoch: 6| Step: 6
Training loss: 0.08390410989522934
Validation loss: 1.6577863129236365

Epoch: 6| Step: 7
Training loss: 0.0955522283911705
Validation loss: 1.665099956656015

Epoch: 6| Step: 8
Training loss: 0.13455206155776978
Validation loss: 1.6751964207618468

Epoch: 6| Step: 9
Training loss: 0.17400668561458588
Validation loss: 1.6527541452838528

Epoch: 6| Step: 10
Training loss: 0.13743801414966583
Validation loss: 1.7042413924330024

Epoch: 6| Step: 11
Training loss: 0.06583267450332642
Validation loss: 1.7309453795033116

Epoch: 6| Step: 12
Training loss: 0.16109436750411987
Validation loss: 1.7123516913383239

Epoch: 6| Step: 13
Training loss: 0.12292167544364929
Validation loss: 1.7353150998392413

Epoch: 498| Step: 0
Training loss: 0.17422516644001007
Validation loss: 1.709106247912171

Epoch: 6| Step: 1
Training loss: 0.09426578134298325
Validation loss: 1.7186317918121174

Epoch: 6| Step: 2
Training loss: 0.08328822255134583
Validation loss: 1.691142318069294

Epoch: 6| Step: 3
Training loss: 0.1170523539185524
Validation loss: 1.6896253119232834

Epoch: 6| Step: 4
Training loss: 0.1290442943572998
Validation loss: 1.6955738272718204

Epoch: 6| Step: 5
Training loss: 0.12116006761789322
Validation loss: 1.6822801879657212

Epoch: 6| Step: 6
Training loss: 0.194425567984581
Validation loss: 1.6899496534819245

Epoch: 6| Step: 7
Training loss: 0.18821360170841217
Validation loss: 1.6754352238870436

Epoch: 6| Step: 8
Training loss: 0.1353883147239685
Validation loss: 1.669670808699823

Epoch: 6| Step: 9
Training loss: 0.14852777123451233
Validation loss: 1.679500525997531

Epoch: 6| Step: 10
Training loss: 0.10615429282188416
Validation loss: 1.6962039086126512

Epoch: 6| Step: 11
Training loss: 0.21561941504478455
Validation loss: 1.7204988925687728

Epoch: 6| Step: 12
Training loss: 0.05815521255135536
Validation loss: 1.7145241998857068

Epoch: 6| Step: 13
Training loss: 0.1106010377407074
Validation loss: 1.7135321171052995

Epoch: 499| Step: 0
Training loss: 0.09806139022111893
Validation loss: 1.7138949824917702

Epoch: 6| Step: 1
Training loss: 0.1060345247387886
Validation loss: 1.7185876305385301

Epoch: 6| Step: 2
Training loss: 0.14002639055252075
Validation loss: 1.7251453732931485

Epoch: 6| Step: 3
Training loss: 0.10192616283893585
Validation loss: 1.7074683212464856

Epoch: 6| Step: 4
Training loss: 0.046147771179676056
Validation loss: 1.7333139232409898

Epoch: 6| Step: 5
Training loss: 0.08216436207294464
Validation loss: 1.6797180303963282

Epoch: 6| Step: 6
Training loss: 0.08252502977848053
Validation loss: 1.7015401778682586

Epoch: 6| Step: 7
Training loss: 0.07783293724060059
Validation loss: 1.744310232900804

Epoch: 6| Step: 8
Training loss: 0.11613182723522186
Validation loss: 1.7059231842717817

Epoch: 6| Step: 9
Training loss: 0.09157629311084747
Validation loss: 1.6898968591484973

Epoch: 6| Step: 10
Training loss: 0.09561053663492203
Validation loss: 1.6785733597252959

Epoch: 6| Step: 11
Training loss: 0.12745869159698486
Validation loss: 1.704546698959925

Epoch: 6| Step: 12
Training loss: 0.08214505016803741
Validation loss: 1.7023010510270313

Epoch: 6| Step: 13
Training loss: 0.08478311449289322
Validation loss: 1.7154074586847776

Epoch: 500| Step: 0
Training loss: 0.07788974046707153
Validation loss: 1.683826442687742

Epoch: 6| Step: 1
Training loss: 0.1175462007522583
Validation loss: 1.66400065857877

Epoch: 6| Step: 2
Training loss: 0.056363075971603394
Validation loss: 1.7029388130352061

Epoch: 6| Step: 3
Training loss: 0.12598852813243866
Validation loss: 1.6695946096092142

Epoch: 6| Step: 4
Training loss: 0.14434292912483215
Validation loss: 1.701791645378195

Epoch: 6| Step: 5
Training loss: 0.07144734263420105
Validation loss: 1.6808168542000554

Epoch: 6| Step: 6
Training loss: 0.0851927399635315
Validation loss: 1.6747888890645837

Epoch: 6| Step: 7
Training loss: 0.1602616012096405
Validation loss: 1.6739139787612423

Epoch: 6| Step: 8
Training loss: 0.15202400088310242
Validation loss: 1.6874509549910022

Epoch: 6| Step: 9
Training loss: 0.13014820218086243
Validation loss: 1.6860309852066862

Epoch: 6| Step: 10
Training loss: 0.11061322689056396
Validation loss: 1.7172172223367999

Epoch: 6| Step: 11
Training loss: 0.07537470757961273
Validation loss: 1.7183954843910791

Epoch: 6| Step: 12
Training loss: 0.09865006804466248
Validation loss: 1.730386003371208

Epoch: 6| Step: 13
Training loss: 0.09021338075399399
Validation loss: 1.7332731549457838

Epoch: 501| Step: 0
Training loss: 0.09704820066690445
Validation loss: 1.774149335840697

Epoch: 6| Step: 1
Training loss: 0.07980611175298691
Validation loss: 1.7677865105290567

Epoch: 6| Step: 2
Training loss: 0.11777059733867645
Validation loss: 1.7157867659804642

Epoch: 6| Step: 3
Training loss: 0.05233606696128845
Validation loss: 1.7673579723604265

Epoch: 6| Step: 4
Training loss: 0.07216399908065796
Validation loss: 1.7067245078343216

Epoch: 6| Step: 5
Training loss: 0.08456643670797348
Validation loss: 1.7224634315377922

Epoch: 6| Step: 6
Training loss: 0.0774247944355011
Validation loss: 1.7129582640945271

Epoch: 6| Step: 7
Training loss: 0.1037512943148613
Validation loss: 1.6810813052679903

Epoch: 6| Step: 8
Training loss: 0.12482321262359619
Validation loss: 1.6940300131356845

Epoch: 6| Step: 9
Training loss: 0.12271974980831146
Validation loss: 1.7211067932908253

Epoch: 6| Step: 10
Training loss: 0.06997577846050262
Validation loss: 1.7296478556048485

Epoch: 6| Step: 11
Training loss: 0.07400909066200256
Validation loss: 1.725199161037322

Epoch: 6| Step: 12
Training loss: 0.1046539694070816
Validation loss: 1.7212560997214368

Epoch: 6| Step: 13
Training loss: 0.1984545886516571
Validation loss: 1.722638036615105

Epoch: 502| Step: 0
Training loss: 0.10917901992797852
Validation loss: 1.7062678542188419

Epoch: 6| Step: 1
Training loss: 0.12329105287790298
Validation loss: 1.6564480053481234

Epoch: 6| Step: 2
Training loss: 0.09298715740442276
Validation loss: 1.6909140643253122

Epoch: 6| Step: 3
Training loss: 0.06932972371578217
Validation loss: 1.6791128343151462

Epoch: 6| Step: 4
Training loss: 0.0835065096616745
Validation loss: 1.680089154551106

Epoch: 6| Step: 5
Training loss: 0.09785506874322891
Validation loss: 1.6976949681517899

Epoch: 6| Step: 6
Training loss: 0.18095475435256958
Validation loss: 1.6861680528169036

Epoch: 6| Step: 7
Training loss: 0.14086104929447174
Validation loss: 1.694308598836263

Epoch: 6| Step: 8
Training loss: 0.08029820024967194
Validation loss: 1.7231360430358558

Epoch: 6| Step: 9
Training loss: 0.11180055886507034
Validation loss: 1.702107391049785

Epoch: 6| Step: 10
Training loss: 0.07695437222719193
Validation loss: 1.7260745404868998

Epoch: 6| Step: 11
Training loss: 0.06937291473150253
Validation loss: 1.7281788395297142

Epoch: 6| Step: 12
Training loss: 0.10731862485408783
Validation loss: 1.6912488834832304

Epoch: 6| Step: 13
Training loss: 0.06458558142185211
Validation loss: 1.696871046097048

Epoch: 503| Step: 0
Training loss: 0.08578342944383621
Validation loss: 1.687545305939131

Epoch: 6| Step: 1
Training loss: 0.06740251183509827
Validation loss: 1.6890482389798729

Epoch: 6| Step: 2
Training loss: 0.10798776149749756
Validation loss: 1.7044768820526779

Epoch: 6| Step: 3
Training loss: 0.14039134979248047
Validation loss: 1.7383339328150595

Epoch: 6| Step: 4
Training loss: 0.06237228959798813
Validation loss: 1.6982928168389104

Epoch: 6| Step: 5
Training loss: 0.12480302900075912
Validation loss: 1.6780221257158505

Epoch: 6| Step: 6
Training loss: 0.06487682461738586
Validation loss: 1.7042398747577463

Epoch: 6| Step: 7
Training loss: 0.0679166167974472
Validation loss: 1.6894837220509846

Epoch: 6| Step: 8
Training loss: 0.09790743887424469
Validation loss: 1.649415406488603

Epoch: 6| Step: 9
Training loss: 0.13964976370334625
Validation loss: 1.6771437583431121

Epoch: 6| Step: 10
Training loss: 0.09501141309738159
Validation loss: 1.662332897545189

Epoch: 6| Step: 11
Training loss: 0.13024109601974487
Validation loss: 1.6510356600566576

Epoch: 6| Step: 12
Training loss: 0.09535856544971466
Validation loss: 1.676941881897629

Epoch: 6| Step: 13
Training loss: 0.1137160211801529
Validation loss: 1.6966161881723711

Epoch: 504| Step: 0
Training loss: 0.09265675395727158
Validation loss: 1.7064070060688963

Epoch: 6| Step: 1
Training loss: 0.10735012590885162
Validation loss: 1.706248716641498

Epoch: 6| Step: 2
Training loss: 0.06793511658906937
Validation loss: 1.699245306753343

Epoch: 6| Step: 3
Training loss: 0.06983038783073425
Validation loss: 1.722751045739779

Epoch: 6| Step: 4
Training loss: 0.12843388319015503
Validation loss: 1.7120896911108365

Epoch: 6| Step: 5
Training loss: 0.06723563373088837
Validation loss: 1.718302737000168

Epoch: 6| Step: 6
Training loss: 0.06529071927070618
Validation loss: 1.695154393872907

Epoch: 6| Step: 7
Training loss: 0.11071724444627762
Validation loss: 1.7233903792596632

Epoch: 6| Step: 8
Training loss: 0.09529803693294525
Validation loss: 1.7142113254916282

Epoch: 6| Step: 9
Training loss: 0.10619626939296722
Validation loss: 1.7005043363058439

Epoch: 6| Step: 10
Training loss: 0.09046395123004913
Validation loss: 1.700215744715865

Epoch: 6| Step: 11
Training loss: 0.08186695724725723
Validation loss: 1.7009953965422928

Epoch: 6| Step: 12
Training loss: 0.09336638450622559
Validation loss: 1.7379992546573761

Epoch: 6| Step: 13
Training loss: 0.10264255106449127
Validation loss: 1.6903335868671376

Epoch: 505| Step: 0
Training loss: 0.09720730781555176
Validation loss: 1.6585573163083804

Epoch: 6| Step: 1
Training loss: 0.10413981974124908
Validation loss: 1.656425274828429

Epoch: 6| Step: 2
Training loss: 0.09933421015739441
Validation loss: 1.6590045741809312

Epoch: 6| Step: 3
Training loss: 0.08555100858211517
Validation loss: 1.6560358680704588

Epoch: 6| Step: 4
Training loss: 0.14395219087600708
Validation loss: 1.6689154550593386

Epoch: 6| Step: 5
Training loss: 0.16118159890174866
Validation loss: 1.6477774830274685

Epoch: 6| Step: 6
Training loss: 0.0880945548415184
Validation loss: 1.6455838975086008

Epoch: 6| Step: 7
Training loss: 0.07145493477582932
Validation loss: 1.6637369971121512

Epoch: 6| Step: 8
Training loss: 0.07651420682668686
Validation loss: 1.667063174709197

Epoch: 6| Step: 9
Training loss: 0.06063716858625412
Validation loss: 1.6897687373622772

Epoch: 6| Step: 10
Training loss: 0.07634322345256805
Validation loss: 1.7003847219610726

Epoch: 6| Step: 11
Training loss: 0.07956099510192871
Validation loss: 1.676710577421291

Epoch: 6| Step: 12
Training loss: 0.06085953861474991
Validation loss: 1.697055487222569

Epoch: 6| Step: 13
Training loss: 0.061592504382133484
Validation loss: 1.6915391529760053

Epoch: 506| Step: 0
Training loss: 0.0558866523206234
Validation loss: 1.6747770155629804

Epoch: 6| Step: 1
Training loss: 0.15392151474952698
Validation loss: 1.6751516057598976

Epoch: 6| Step: 2
Training loss: 0.12546513974666595
Validation loss: 1.675158291734675

Epoch: 6| Step: 3
Training loss: 0.09590663760900497
Validation loss: 1.6749732334126708

Epoch: 6| Step: 4
Training loss: 0.09105464816093445
Validation loss: 1.6514980741726455

Epoch: 6| Step: 5
Training loss: 0.12908321619033813
Validation loss: 1.6836639488897016

Epoch: 6| Step: 6
Training loss: 0.08642023056745529
Validation loss: 1.6984982041902439

Epoch: 6| Step: 7
Training loss: 0.11707059293985367
Validation loss: 1.6642591132912585

Epoch: 6| Step: 8
Training loss: 0.09502008557319641
Validation loss: 1.6789696754947785

Epoch: 6| Step: 9
Training loss: 0.14434796571731567
Validation loss: 1.7275189174118863

Epoch: 6| Step: 10
Training loss: 0.08569780737161636
Validation loss: 1.6941450924001715

Epoch: 6| Step: 11
Training loss: 0.08587273955345154
Validation loss: 1.6882295018883162

Epoch: 6| Step: 12
Training loss: 0.11310771852731705
Validation loss: 1.6479276508413336

Epoch: 6| Step: 13
Training loss: 0.14822234213352203
Validation loss: 1.696211911016895

Epoch: 507| Step: 0
Training loss: 0.08412176370620728
Validation loss: 1.6705050442808418

Epoch: 6| Step: 1
Training loss: 0.08662120997905731
Validation loss: 1.6712655149480349

Epoch: 6| Step: 2
Training loss: 0.07697687298059464
Validation loss: 1.645398437335927

Epoch: 6| Step: 3
Training loss: 0.07721075415611267
Validation loss: 1.6213028982121458

Epoch: 6| Step: 4
Training loss: 0.11311280727386475
Validation loss: 1.617061666263047

Epoch: 6| Step: 5
Training loss: 0.14906275272369385
Validation loss: 1.6225351492563884

Epoch: 6| Step: 6
Training loss: 0.07953214645385742
Validation loss: 1.63959333204454

Epoch: 6| Step: 7
Training loss: 0.11830512434244156
Validation loss: 1.6166841496703446

Epoch: 6| Step: 8
Training loss: 0.0995146706700325
Validation loss: 1.636360058220484

Epoch: 6| Step: 9
Training loss: 0.10062070935964584
Validation loss: 1.6706949472427368

Epoch: 6| Step: 10
Training loss: 0.08688223361968994
Validation loss: 1.695586230165215

Epoch: 6| Step: 11
Training loss: 0.16317693889141083
Validation loss: 1.6590261587532618

Epoch: 6| Step: 12
Training loss: 0.1426141858100891
Validation loss: 1.6844668362730293

Epoch: 6| Step: 13
Training loss: 0.09844691306352615
Validation loss: 1.6725178149438673

Epoch: 508| Step: 0
Training loss: 0.07522693276405334
Validation loss: 1.6774362607668805

Epoch: 6| Step: 1
Training loss: 0.07545405626296997
Validation loss: 1.6679852521547707

Epoch: 6| Step: 2
Training loss: 0.07684431225061417
Validation loss: 1.6992980087957075

Epoch: 6| Step: 3
Training loss: 0.09467723965644836
Validation loss: 1.689086175733997

Epoch: 6| Step: 4
Training loss: 0.053375471383333206
Validation loss: 1.7019942024702668

Epoch: 6| Step: 5
Training loss: 0.09607098996639252
Validation loss: 1.6768216599700272

Epoch: 6| Step: 6
Training loss: 0.07326790690422058
Validation loss: 1.67798702691191

Epoch: 6| Step: 7
Training loss: 0.08957458287477493
Validation loss: 1.6743801909108316

Epoch: 6| Step: 8
Training loss: 0.09421034157276154
Validation loss: 1.688183178183853

Epoch: 6| Step: 9
Training loss: 0.07045523822307587
Validation loss: 1.6750788278477167

Epoch: 6| Step: 10
Training loss: 0.10982018709182739
Validation loss: 1.6620493422272384

Epoch: 6| Step: 11
Training loss: 0.04905770719051361
Validation loss: 1.6649158052218858

Epoch: 6| Step: 12
Training loss: 0.08664615452289581
Validation loss: 1.6288770450058805

Epoch: 6| Step: 13
Training loss: 0.10491517186164856
Validation loss: 1.6755569698990032

Epoch: 509| Step: 0
Training loss: 0.049075447022914886
Validation loss: 1.672974694159723

Epoch: 6| Step: 1
Training loss: 0.09961279481649399
Validation loss: 1.6580436601433703

Epoch: 6| Step: 2
Training loss: 0.08555272221565247
Validation loss: 1.6708980683357484

Epoch: 6| Step: 3
Training loss: 0.10786149650812149
Validation loss: 1.6998608753245363

Epoch: 6| Step: 4
Training loss: 0.10655389726161957
Validation loss: 1.7022651158353335

Epoch: 6| Step: 5
Training loss: 0.08178701996803284
Validation loss: 1.7112100290995773

Epoch: 6| Step: 6
Training loss: 0.07231222093105316
Validation loss: 1.675817866479197

Epoch: 6| Step: 7
Training loss: 0.07970363646745682
Validation loss: 1.6795952063734814

Epoch: 6| Step: 8
Training loss: 0.08507296442985535
Validation loss: 1.692909966232956

Epoch: 6| Step: 9
Training loss: 0.11916246265172958
Validation loss: 1.6915987127570695

Epoch: 6| Step: 10
Training loss: 0.122272789478302
Validation loss: 1.724527298763234

Epoch: 6| Step: 11
Training loss: 0.10683044791221619
Validation loss: 1.7011390398907404

Epoch: 6| Step: 12
Training loss: 0.07657591998577118
Validation loss: 1.7063831385745798

Epoch: 6| Step: 13
Training loss: 0.09858410060405731
Validation loss: 1.685443491064092

Epoch: 510| Step: 0
Training loss: 0.05842531472444534
Validation loss: 1.6612646900197512

Epoch: 6| Step: 1
Training loss: 0.09928921610116959
Validation loss: 1.6816092255294963

Epoch: 6| Step: 2
Training loss: 0.1418188512325287
Validation loss: 1.6693606479193575

Epoch: 6| Step: 3
Training loss: 0.15139292180538177
Validation loss: 1.6530939122681976

Epoch: 6| Step: 4
Training loss: 0.07441617548465729
Validation loss: 1.6625927212417766

Epoch: 6| Step: 5
Training loss: 0.08980715274810791
Validation loss: 1.6362005741365495

Epoch: 6| Step: 6
Training loss: 0.060461726039648056
Validation loss: 1.6358199068295058

Epoch: 6| Step: 7
Training loss: 0.08044974505901337
Validation loss: 1.6738604294356478

Epoch: 6| Step: 8
Training loss: 0.13052885234355927
Validation loss: 1.6828842957814534

Epoch: 6| Step: 9
Training loss: 0.03449021652340889
Validation loss: 1.659510979088404

Epoch: 6| Step: 10
Training loss: 0.08233636617660522
Validation loss: 1.6732257117507279

Epoch: 6| Step: 11
Training loss: 0.15897731482982635
Validation loss: 1.7073422452454925

Epoch: 6| Step: 12
Training loss: 0.11183588206768036
Validation loss: 1.6742456331047961

Epoch: 6| Step: 13
Training loss: 0.1201024055480957
Validation loss: 1.6906657334296935

Epoch: 511| Step: 0
Training loss: 0.1422443687915802
Validation loss: 1.7004612145885345

Epoch: 6| Step: 1
Training loss: 0.117659792304039
Validation loss: 1.7021424539627568

Epoch: 6| Step: 2
Training loss: 0.1296970546245575
Validation loss: 1.6851209017538256

Epoch: 6| Step: 3
Training loss: 0.09767363965511322
Validation loss: 1.7188040697446434

Epoch: 6| Step: 4
Training loss: 0.12750087678432465
Validation loss: 1.6744930154533797

Epoch: 6| Step: 5
Training loss: 0.09241130948066711
Validation loss: 1.7203731511228828

Epoch: 6| Step: 6
Training loss: 0.05658917874097824
Validation loss: 1.7104929903502106

Epoch: 6| Step: 7
Training loss: 0.05878351628780365
Validation loss: 1.7076051645381476

Epoch: 6| Step: 8
Training loss: 0.11924488842487335
Validation loss: 1.7032412585391794

Epoch: 6| Step: 9
Training loss: 0.06076512113213539
Validation loss: 1.6772971025077246

Epoch: 6| Step: 10
Training loss: 0.08086568862199783
Validation loss: 1.671650166152626

Epoch: 6| Step: 11
Training loss: 0.09132523089647293
Validation loss: 1.6575869052640853

Epoch: 6| Step: 12
Training loss: 0.09783568978309631
Validation loss: 1.68585072025176

Epoch: 6| Step: 13
Training loss: 0.08484980463981628
Validation loss: 1.6561082383637786

Epoch: 512| Step: 0
Training loss: 0.0581103190779686
Validation loss: 1.6901651838774323

Epoch: 6| Step: 1
Training loss: 0.06881062686443329
Validation loss: 1.703149131549302

Epoch: 6| Step: 2
Training loss: 0.0664651095867157
Validation loss: 1.702469705253519

Epoch: 6| Step: 3
Training loss: 0.06948995590209961
Validation loss: 1.7229051743784258

Epoch: 6| Step: 4
Training loss: 0.06989489495754242
Validation loss: 1.70147826081963

Epoch: 6| Step: 5
Training loss: 0.07233656942844391
Validation loss: 1.7160449938107563

Epoch: 6| Step: 6
Training loss: 0.10711904615163803
Validation loss: 1.6921862248451478

Epoch: 6| Step: 7
Training loss: 0.07856297492980957
Validation loss: 1.6832318331605645

Epoch: 6| Step: 8
Training loss: 0.09611524641513824
Validation loss: 1.6595645886595531

Epoch: 6| Step: 9
Training loss: 0.11858904361724854
Validation loss: 1.6376564425806845

Epoch: 6| Step: 10
Training loss: 0.11848609894514084
Validation loss: 1.6101724896379697

Epoch: 6| Step: 11
Training loss: 0.18680612742900848
Validation loss: 1.6314507658763597

Epoch: 6| Step: 12
Training loss: 0.1452566683292389
Validation loss: 1.5946520913031794

Epoch: 6| Step: 13
Training loss: 0.16379642486572266
Validation loss: 1.6021561186800721

Epoch: 513| Step: 0
Training loss: 0.06906846165657043
Validation loss: 1.6200390297879455

Epoch: 6| Step: 1
Training loss: 0.09711974114179611
Validation loss: 1.6194217243502218

Epoch: 6| Step: 2
Training loss: 0.07856398820877075
Validation loss: 1.6533432481109456

Epoch: 6| Step: 3
Training loss: 0.0743548721075058
Validation loss: 1.6641240453207364

Epoch: 6| Step: 4
Training loss: 0.11257859319448471
Validation loss: 1.6774416187758088

Epoch: 6| Step: 5
Training loss: 0.1130543127655983
Validation loss: 1.6974865595499675

Epoch: 6| Step: 6
Training loss: 0.11683535575866699
Validation loss: 1.6553884065279396

Epoch: 6| Step: 7
Training loss: 0.06907695531845093
Validation loss: 1.6657265950274724

Epoch: 6| Step: 8
Training loss: 0.077254518866539
Validation loss: 1.6469429846732848

Epoch: 6| Step: 9
Training loss: 0.07029470801353455
Validation loss: 1.6304910131680068

Epoch: 6| Step: 10
Training loss: 0.1259848028421402
Validation loss: 1.6661491342770156

Epoch: 6| Step: 11
Training loss: 0.08584513515233994
Validation loss: 1.6590113806468185

Epoch: 6| Step: 12
Training loss: 0.08700964599847794
Validation loss: 1.6858292189977502

Epoch: 6| Step: 13
Training loss: 0.073942169547081
Validation loss: 1.6695248042383501

Epoch: 514| Step: 0
Training loss: 0.08235384523868561
Validation loss: 1.6508534903167396

Epoch: 6| Step: 1
Training loss: 0.06011992692947388
Validation loss: 1.7199411751121603

Epoch: 6| Step: 2
Training loss: 0.08714959025382996
Validation loss: 1.7065614115807317

Epoch: 6| Step: 3
Training loss: 0.07804913818836212
Validation loss: 1.7291409046419206

Epoch: 6| Step: 4
Training loss: 0.0754614993929863
Validation loss: 1.6953891400367982

Epoch: 6| Step: 5
Training loss: 0.11578788608312607
Validation loss: 1.682173696897363

Epoch: 6| Step: 6
Training loss: 0.08173799514770508
Validation loss: 1.6760250855517644

Epoch: 6| Step: 7
Training loss: 0.04368233308196068
Validation loss: 1.6657702384456512

Epoch: 6| Step: 8
Training loss: 0.09502292424440384
Validation loss: 1.6472371239815988

Epoch: 6| Step: 9
Training loss: 0.051088154315948486
Validation loss: 1.6275244861520746

Epoch: 6| Step: 10
Training loss: 0.08270621299743652
Validation loss: 1.6157009063228485

Epoch: 6| Step: 11
Training loss: 0.08181319385766983
Validation loss: 1.6284361526530275

Epoch: 6| Step: 12
Training loss: 0.07324231415987015
Validation loss: 1.6404136073204778

Epoch: 6| Step: 13
Training loss: 0.10070143640041351
Validation loss: 1.6267869780140538

Epoch: 515| Step: 0
Training loss: 0.06847713142633438
Validation loss: 1.643070161983531

Epoch: 6| Step: 1
Training loss: 0.07884971052408218
Validation loss: 1.6642890168774513

Epoch: 6| Step: 2
Training loss: 0.13856753706932068
Validation loss: 1.6718277264666814

Epoch: 6| Step: 3
Training loss: 0.0916220173239708
Validation loss: 1.7148541288991128

Epoch: 6| Step: 4
Training loss: 0.0664549469947815
Validation loss: 1.684706122644486

Epoch: 6| Step: 5
Training loss: 0.06307034939527512
Validation loss: 1.6552785429903256

Epoch: 6| Step: 6
Training loss: 0.06965331733226776
Validation loss: 1.6809248898618965

Epoch: 6| Step: 7
Training loss: 0.17176368832588196
Validation loss: 1.6924913826809134

Epoch: 6| Step: 8
Training loss: 0.08486542105674744
Validation loss: 1.6823390248001262

Epoch: 6| Step: 9
Training loss: 0.1064266711473465
Validation loss: 1.685660898044545

Epoch: 6| Step: 10
Training loss: 0.06722412258386612
Validation loss: 1.6649905981556061

Epoch: 6| Step: 11
Training loss: 0.10227668285369873
Validation loss: 1.7059548759973178

Epoch: 6| Step: 12
Training loss: 0.07987149059772491
Validation loss: 1.6922856133471254

Epoch: 6| Step: 13
Training loss: 0.14230860769748688
Validation loss: 1.7536076499569802

Epoch: 516| Step: 0
Training loss: 0.09549067914485931
Validation loss: 1.73213485235809

Epoch: 6| Step: 1
Training loss: 0.1231558620929718
Validation loss: 1.714553548443702

Epoch: 6| Step: 2
Training loss: 0.07524189352989197
Validation loss: 1.7381053829705844

Epoch: 6| Step: 3
Training loss: 0.12606415152549744
Validation loss: 1.6624881811039423

Epoch: 6| Step: 4
Training loss: 0.1527155488729477
Validation loss: 1.6248039596824235

Epoch: 6| Step: 5
Training loss: 0.10140480846166611
Validation loss: 1.6362505933289886

Epoch: 6| Step: 6
Training loss: 0.08553773164749146
Validation loss: 1.666952738197901

Epoch: 6| Step: 7
Training loss: 0.09154535830020905
Validation loss: 1.6792127393907117

Epoch: 6| Step: 8
Training loss: 0.05318811908364296
Validation loss: 1.6532250809413132

Epoch: 6| Step: 9
Training loss: 0.0710129588842392
Validation loss: 1.661431215142691

Epoch: 6| Step: 10
Training loss: 0.11713634431362152
Validation loss: 1.6840981488586755

Epoch: 6| Step: 11
Training loss: 0.09896975755691528
Validation loss: 1.6828658632052842

Epoch: 6| Step: 12
Training loss: 0.08760225772857666
Validation loss: 1.7059055438605688

Epoch: 6| Step: 13
Training loss: 0.0633242130279541
Validation loss: 1.7216822742134013

Epoch: 517| Step: 0
Training loss: 0.05301273614168167
Validation loss: 1.7145439681186472

Epoch: 6| Step: 1
Training loss: 0.1017826721072197
Validation loss: 1.722450497329876

Epoch: 6| Step: 2
Training loss: 0.07801738381385803
Validation loss: 1.7307260677378664

Epoch: 6| Step: 3
Training loss: 0.06500838696956635
Validation loss: 1.6973698395554737

Epoch: 6| Step: 4
Training loss: 0.10490842908620834
Validation loss: 1.7094083268155333

Epoch: 6| Step: 5
Training loss: 0.0538862943649292
Validation loss: 1.6657710806016

Epoch: 6| Step: 6
Training loss: 0.09069851040840149
Validation loss: 1.6475537541092082

Epoch: 6| Step: 7
Training loss: 0.06898006051778793
Validation loss: 1.6561937306516914

Epoch: 6| Step: 8
Training loss: 0.06300973892211914
Validation loss: 1.6611797066145046

Epoch: 6| Step: 9
Training loss: 0.11906850337982178
Validation loss: 1.6778431746267504

Epoch: 6| Step: 10
Training loss: 0.10095442831516266
Validation loss: 1.6665912610228344

Epoch: 6| Step: 11
Training loss: 0.08941812068223953
Validation loss: 1.6711444918827345

Epoch: 6| Step: 12
Training loss: 0.06721674650907516
Validation loss: 1.6751768730020011

Epoch: 6| Step: 13
Training loss: 0.22684328258037567
Validation loss: 1.6778915441164406

Epoch: 518| Step: 0
Training loss: 0.11347667872905731
Validation loss: 1.7003216051286267

Epoch: 6| Step: 1
Training loss: 0.06305248290300369
Validation loss: 1.6681155953356015

Epoch: 6| Step: 2
Training loss: 0.08478996157646179
Validation loss: 1.6737506825436828

Epoch: 6| Step: 3
Training loss: 0.04942377284169197
Validation loss: 1.6946186493801814

Epoch: 6| Step: 4
Training loss: 0.08326014131307602
Validation loss: 1.6970046002377746

Epoch: 6| Step: 5
Training loss: 0.11059022694826126
Validation loss: 1.6859757310600691

Epoch: 6| Step: 6
Training loss: 0.09852173179388046
Validation loss: 1.6823141882496495

Epoch: 6| Step: 7
Training loss: 0.06656716763973236
Validation loss: 1.6919196626191497

Epoch: 6| Step: 8
Training loss: 0.11302755773067474
Validation loss: 1.6654428051364036

Epoch: 6| Step: 9
Training loss: 0.08641921728849411
Validation loss: 1.6414272823641378

Epoch: 6| Step: 10
Training loss: 0.10734066367149353
Validation loss: 1.634967113053927

Epoch: 6| Step: 11
Training loss: 0.1069522500038147
Validation loss: 1.6605293737944735

Epoch: 6| Step: 12
Training loss: 0.06452295184135437
Validation loss: 1.6580151050321517

Epoch: 6| Step: 13
Training loss: 0.07014988362789154
Validation loss: 1.665506342405914

Epoch: 519| Step: 0
Training loss: 0.050287600606679916
Validation loss: 1.6832445847090853

Epoch: 6| Step: 1
Training loss: 0.07360448688268661
Validation loss: 1.7051795349326184

Epoch: 6| Step: 2
Training loss: 0.14338208734989166
Validation loss: 1.6985881969492922

Epoch: 6| Step: 3
Training loss: 0.07453589141368866
Validation loss: 1.6841968464595016

Epoch: 6| Step: 4
Training loss: 0.11371293663978577
Validation loss: 1.718187794890455

Epoch: 6| Step: 5
Training loss: 0.08848673850297928
Validation loss: 1.6786528505304807

Epoch: 6| Step: 6
Training loss: 0.05962542071938515
Validation loss: 1.6743426438300841

Epoch: 6| Step: 7
Training loss: 0.09112843126058578
Validation loss: 1.6791436877301944

Epoch: 6| Step: 8
Training loss: 0.04691845923662186
Validation loss: 1.6817988118817728

Epoch: 6| Step: 9
Training loss: 0.08924205601215363
Validation loss: 1.6427289426967662

Epoch: 6| Step: 10
Training loss: 0.07597966492176056
Validation loss: 1.6412871922216108

Epoch: 6| Step: 11
Training loss: 0.09532211720943451
Validation loss: 1.6523056991638676

Epoch: 6| Step: 12
Training loss: 0.1393452286720276
Validation loss: 1.6234366175948933

Epoch: 6| Step: 13
Training loss: 0.06948844343423843
Validation loss: 1.6518209467652023

Epoch: 520| Step: 0
Training loss: 0.059707678854465485
Validation loss: 1.6587808837172806

Epoch: 6| Step: 1
Training loss: 0.05587124824523926
Validation loss: 1.6611160155265563

Epoch: 6| Step: 2
Training loss: 0.06064693257212639
Validation loss: 1.6349542845961869

Epoch: 6| Step: 3
Training loss: 0.09018722176551819
Validation loss: 1.6677376659967567

Epoch: 6| Step: 4
Training loss: 0.07815373688936234
Validation loss: 1.6671611467997234

Epoch: 6| Step: 5
Training loss: 0.08294466882944107
Validation loss: 1.6600885718099532

Epoch: 6| Step: 6
Training loss: 0.06322373449802399
Validation loss: 1.6523918285164783

Epoch: 6| Step: 7
Training loss: 0.07435588538646698
Validation loss: 1.6498781763097292

Epoch: 6| Step: 8
Training loss: 0.09877534210681915
Validation loss: 1.6567340384247482

Epoch: 6| Step: 9
Training loss: 0.10898827016353607
Validation loss: 1.660844777220039

Epoch: 6| Step: 10
Training loss: 0.14682835340499878
Validation loss: 1.6720786197211153

Epoch: 6| Step: 11
Training loss: 0.09919285774230957
Validation loss: 1.6827338382761965

Epoch: 6| Step: 12
Training loss: 0.0904112458229065
Validation loss: 1.6905889254744335

Epoch: 6| Step: 13
Training loss: 0.08897187560796738
Validation loss: 1.6601760746330343

Epoch: 521| Step: 0
Training loss: 0.08129660785198212
Validation loss: 1.6797747432544667

Epoch: 6| Step: 1
Training loss: 0.09800863265991211
Validation loss: 1.6855804971469346

Epoch: 6| Step: 2
Training loss: 0.09050444513559341
Validation loss: 1.6917506456375122

Epoch: 6| Step: 3
Training loss: 0.07976183295249939
Validation loss: 1.6831032345371861

Epoch: 6| Step: 4
Training loss: 0.1011074036359787
Validation loss: 1.6627342944504113

Epoch: 6| Step: 5
Training loss: 0.10612697899341583
Validation loss: 1.6643517389092395

Epoch: 6| Step: 6
Training loss: 0.06789982318878174
Validation loss: 1.6428263007953603

Epoch: 6| Step: 7
Training loss: 0.06624381989240646
Validation loss: 1.6638367150419502

Epoch: 6| Step: 8
Training loss: 0.07595303654670715
Validation loss: 1.649659227299434

Epoch: 6| Step: 9
Training loss: 0.13696525990962982
Validation loss: 1.6693030275324339

Epoch: 6| Step: 10
Training loss: 0.09736477583646774
Validation loss: 1.665142830982003

Epoch: 6| Step: 11
Training loss: 0.06201491877436638
Validation loss: 1.6415908131548154

Epoch: 6| Step: 12
Training loss: 0.0731545016169548
Validation loss: 1.6708133092490576

Epoch: 6| Step: 13
Training loss: 0.09521564841270447
Validation loss: 1.6625452849172777

Epoch: 522| Step: 0
Training loss: 0.08679324388504028
Validation loss: 1.6402858418803061

Epoch: 6| Step: 1
Training loss: 0.07959115505218506
Validation loss: 1.6345429830653693

Epoch: 6| Step: 2
Training loss: 0.07055364549160004
Validation loss: 1.6391732840127842

Epoch: 6| Step: 3
Training loss: 0.059162549674510956
Validation loss: 1.6612828982773649

Epoch: 6| Step: 4
Training loss: 0.07558892667293549
Validation loss: 1.6485017679070915

Epoch: 6| Step: 5
Training loss: 0.1640201210975647
Validation loss: 1.6290427689911218

Epoch: 6| Step: 6
Training loss: 0.0714142769575119
Validation loss: 1.6549247029007121

Epoch: 6| Step: 7
Training loss: 0.0587872751057148
Validation loss: 1.643941496008186

Epoch: 6| Step: 8
Training loss: 0.0971711128950119
Validation loss: 1.6450223153637302

Epoch: 6| Step: 9
Training loss: 0.09639915078878403
Validation loss: 1.6402448864393337

Epoch: 6| Step: 10
Training loss: 0.09455466270446777
Validation loss: 1.6403866275664298

Epoch: 6| Step: 11
Training loss: 0.08143660426139832
Validation loss: 1.62350748303116

Epoch: 6| Step: 12
Training loss: 0.12982618808746338
Validation loss: 1.6661297146992018

Epoch: 6| Step: 13
Training loss: 0.06325007975101471
Validation loss: 1.6339380664210166

Epoch: 523| Step: 0
Training loss: 0.0528910830616951
Validation loss: 1.6402861251625964

Epoch: 6| Step: 1
Training loss: 0.07805908471345901
Validation loss: 1.6520236358847669

Epoch: 6| Step: 2
Training loss: 0.05337845906615257
Validation loss: 1.6267600482509983

Epoch: 6| Step: 3
Training loss: 0.08882296830415726
Validation loss: 1.6201378389071392

Epoch: 6| Step: 4
Training loss: 0.04353220760822296
Validation loss: 1.6296712608747586

Epoch: 6| Step: 5
Training loss: 0.07007402181625366
Validation loss: 1.629156530544322

Epoch: 6| Step: 6
Training loss: 0.112907275557518
Validation loss: 1.6426785940765052

Epoch: 6| Step: 7
Training loss: 0.13385853171348572
Validation loss: 1.6487085344970867

Epoch: 6| Step: 8
Training loss: 0.14025451242923737
Validation loss: 1.6406342188517253

Epoch: 6| Step: 9
Training loss: 0.07619381695985794
Validation loss: 1.6809225184943086

Epoch: 6| Step: 10
Training loss: 0.1255807876586914
Validation loss: 1.6631807460579822

Epoch: 6| Step: 11
Training loss: 0.1071992740035057
Validation loss: 1.7087928146444342

Epoch: 6| Step: 12
Training loss: 0.13122498989105225
Validation loss: 1.721676347076252

Epoch: 6| Step: 13
Training loss: 0.09327428787946701
Validation loss: 1.7016000632316834

Epoch: 524| Step: 0
Training loss: 0.10707662254571915
Validation loss: 1.6838350167838476

Epoch: 6| Step: 1
Training loss: 0.09033621847629547
Validation loss: 1.6914539349976407

Epoch: 6| Step: 2
Training loss: 0.09308918565511703
Validation loss: 1.7025789176264117

Epoch: 6| Step: 3
Training loss: 0.10303234308958054
Validation loss: 1.6938086812214186

Epoch: 6| Step: 4
Training loss: 0.0766497403383255
Validation loss: 1.6786112785339355

Epoch: 6| Step: 5
Training loss: 0.07290054857730865
Validation loss: 1.6929275271713093

Epoch: 6| Step: 6
Training loss: 0.08266081660985947
Validation loss: 1.7042831746480798

Epoch: 6| Step: 7
Training loss: 0.0841994434595108
Validation loss: 1.7040217025305635

Epoch: 6| Step: 8
Training loss: 0.07299107313156128
Validation loss: 1.7159622920456754

Epoch: 6| Step: 9
Training loss: 0.1067834347486496
Validation loss: 1.7355003856843518

Epoch: 6| Step: 10
Training loss: 0.04180281236767769
Validation loss: 1.7353982938233243

Epoch: 6| Step: 11
Training loss: 0.07369774580001831
Validation loss: 1.7346011977041922

Epoch: 6| Step: 12
Training loss: 0.10163742303848267
Validation loss: 1.734146382219048

Epoch: 6| Step: 13
Training loss: 0.12257496267557144
Validation loss: 1.721657560717675

Epoch: 525| Step: 0
Training loss: 0.08706191927194595
Validation loss: 1.6992897269546345

Epoch: 6| Step: 1
Training loss: 0.13711856305599213
Validation loss: 1.6572788543598627

Epoch: 6| Step: 2
Training loss: 0.11682311445474625
Validation loss: 1.6899778637834775

Epoch: 6| Step: 3
Training loss: 0.1099015548825264
Validation loss: 1.6682979470940047

Epoch: 6| Step: 4
Training loss: 0.10985617339611053
Validation loss: 1.6802235623841644

Epoch: 6| Step: 5
Training loss: 0.08121223747730255
Validation loss: 1.685264560484117

Epoch: 6| Step: 6
Training loss: 0.10796892642974854
Validation loss: 1.6961541662934005

Epoch: 6| Step: 7
Training loss: 0.05347951501607895
Validation loss: 1.6423179077845749

Epoch: 6| Step: 8
Training loss: 0.09121119976043701
Validation loss: 1.687844382819309

Epoch: 6| Step: 9
Training loss: 0.07743203639984131
Validation loss: 1.7294363103887087

Epoch: 6| Step: 10
Training loss: 0.07041916251182556
Validation loss: 1.6811378771258938

Epoch: 6| Step: 11
Training loss: 0.07262083142995834
Validation loss: 1.6869113253008934

Epoch: 6| Step: 12
Training loss: 0.07808353751897812
Validation loss: 1.6768483474690428

Epoch: 6| Step: 13
Training loss: 0.13778477907180786
Validation loss: 1.703059111872027

Epoch: 526| Step: 0
Training loss: 0.1019858717918396
Validation loss: 1.697769295784735

Epoch: 6| Step: 1
Training loss: 0.11679655313491821
Validation loss: 1.703602034558532

Epoch: 6| Step: 2
Training loss: 0.07528159022331238
Validation loss: 1.714084876480923

Epoch: 6| Step: 3
Training loss: 0.11468492448329926
Validation loss: 1.6981401981845978

Epoch: 6| Step: 4
Training loss: 0.10497544705867767
Validation loss: 1.708643828668902

Epoch: 6| Step: 5
Training loss: 0.13544073700904846
Validation loss: 1.6740307077284782

Epoch: 6| Step: 6
Training loss: 0.07203206419944763
Validation loss: 1.6746314264112903

Epoch: 6| Step: 7
Training loss: 0.05170884355902672
Validation loss: 1.6607290570453932

Epoch: 6| Step: 8
Training loss: 0.08167891949415207
Validation loss: 1.6445057802302863

Epoch: 6| Step: 9
Training loss: 0.08105592429637909
Validation loss: 1.613588995830987

Epoch: 6| Step: 10
Training loss: 0.12948356568813324
Validation loss: 1.615970310344491

Epoch: 6| Step: 11
Training loss: 0.09942983835935593
Validation loss: 1.6326253209062802

Epoch: 6| Step: 12
Training loss: 0.04510631412267685
Validation loss: 1.5836178564256238

Epoch: 6| Step: 13
Training loss: 0.18067313730716705
Validation loss: 1.6550395450284403

Epoch: 527| Step: 0
Training loss: 0.0906653180718422
Validation loss: 1.6374305127769389

Epoch: 6| Step: 1
Training loss: 0.05700173228979111
Validation loss: 1.711401144663493

Epoch: 6| Step: 2
Training loss: 0.15538954734802246
Validation loss: 1.7231656774397819

Epoch: 6| Step: 3
Training loss: 0.17104831337928772
Validation loss: 1.7105977701884445

Epoch: 6| Step: 4
Training loss: 0.10948408395051956
Validation loss: 1.7488861782576448

Epoch: 6| Step: 5
Training loss: 0.09472957253456116
Validation loss: 1.7559614027700117

Epoch: 6| Step: 6
Training loss: 0.10389292985200882
Validation loss: 1.7205499910539197

Epoch: 6| Step: 7
Training loss: 0.08962802588939667
Validation loss: 1.7240243265705724

Epoch: 6| Step: 8
Training loss: 0.18964017927646637
Validation loss: 1.7195772637603104

Epoch: 6| Step: 9
Training loss: 0.11962556838989258
Validation loss: 1.700415922749427

Epoch: 6| Step: 10
Training loss: 0.11318046599626541
Validation loss: 1.7120378978790776

Epoch: 6| Step: 11
Training loss: 0.09655092656612396
Validation loss: 1.6833933886661325

Epoch: 6| Step: 12
Training loss: 0.11488700658082962
Validation loss: 1.6854211226586373

Epoch: 6| Step: 13
Training loss: 0.08339685946702957
Validation loss: 1.6957879707377443

Epoch: 528| Step: 0
Training loss: 0.10892123728990555
Validation loss: 1.6687320624628375

Epoch: 6| Step: 1
Training loss: 0.0913536325097084
Validation loss: 1.693920373916626

Epoch: 6| Step: 2
Training loss: 0.13242129981517792
Validation loss: 1.7329681022192842

Epoch: 6| Step: 3
Training loss: 0.16641180217266083
Validation loss: 1.7202642553596086

Epoch: 6| Step: 4
Training loss: 0.18163788318634033
Validation loss: 1.7539984949173466

Epoch: 6| Step: 5
Training loss: 0.06119406968355179
Validation loss: 1.662943547771823

Epoch: 6| Step: 6
Training loss: 0.0856744721531868
Validation loss: 1.665140535241814

Epoch: 6| Step: 7
Training loss: 0.13446524739265442
Validation loss: 1.6240238425552205

Epoch: 6| Step: 8
Training loss: 0.09259220957756042
Validation loss: 1.6115581527833016

Epoch: 6| Step: 9
Training loss: 0.13239756226539612
Validation loss: 1.64347892807376

Epoch: 6| Step: 10
Training loss: 0.18678560853004456
Validation loss: 1.6164634073934248

Epoch: 6| Step: 11
Training loss: 0.14289367198944092
Validation loss: 1.6378263888820526

Epoch: 6| Step: 12
Training loss: 0.10125961899757385
Validation loss: 1.6461343419167302

Epoch: 6| Step: 13
Training loss: 0.09141281247138977
Validation loss: 1.6705670779751194

Epoch: 529| Step: 0
Training loss: 0.08201217651367188
Validation loss: 1.6676619873251965

Epoch: 6| Step: 1
Training loss: 0.09537022560834885
Validation loss: 1.6841615528188727

Epoch: 6| Step: 2
Training loss: 0.1405704766511917
Validation loss: 1.707348395419377

Epoch: 6| Step: 3
Training loss: 0.08958107978105545
Validation loss: 1.702753056762039

Epoch: 6| Step: 4
Training loss: 0.06580916047096252
Validation loss: 1.705812979769963

Epoch: 6| Step: 5
Training loss: 0.17066887021064758
Validation loss: 1.7103978510825866

Epoch: 6| Step: 6
Training loss: 0.05169492959976196
Validation loss: 1.678462387413107

Epoch: 6| Step: 7
Training loss: 0.08284406363964081
Validation loss: 1.6825619705261723

Epoch: 6| Step: 8
Training loss: 0.11250961571931839
Validation loss: 1.6665624136565833

Epoch: 6| Step: 9
Training loss: 0.09172503650188446
Validation loss: 1.6597510114792855

Epoch: 6| Step: 10
Training loss: 0.13284294307231903
Validation loss: 1.6431727024816698

Epoch: 6| Step: 11
Training loss: 0.09926950931549072
Validation loss: 1.6403871454218382

Epoch: 6| Step: 12
Training loss: 0.08688285201787949
Validation loss: 1.6572466140152307

Epoch: 6| Step: 13
Training loss: 0.09870897233486176
Validation loss: 1.6589662067351802

Epoch: 530| Step: 0
Training loss: 0.08071282505989075
Validation loss: 1.692346630557891

Epoch: 6| Step: 1
Training loss: 0.05661427974700928
Validation loss: 1.6707035431297876

Epoch: 6| Step: 2
Training loss: 0.10577971488237381
Validation loss: 1.7058883302955217

Epoch: 6| Step: 3
Training loss: 0.09893150627613068
Validation loss: 1.7288572634420087

Epoch: 6| Step: 4
Training loss: 0.07686640322208405
Validation loss: 1.7539303507856143

Epoch: 6| Step: 5
Training loss: 0.07346952706575394
Validation loss: 1.7342752974520448

Epoch: 6| Step: 6
Training loss: 0.10325229167938232
Validation loss: 1.7506813285171345

Epoch: 6| Step: 7
Training loss: 0.10824592411518097
Validation loss: 1.73793246540972

Epoch: 6| Step: 8
Training loss: 0.08133396506309509
Validation loss: 1.7324908138603292

Epoch: 6| Step: 9
Training loss: 0.09010258316993713
Validation loss: 1.7266282368731756

Epoch: 6| Step: 10
Training loss: 0.15194256603717804
Validation loss: 1.7208702692421534

Epoch: 6| Step: 11
Training loss: 0.1360502541065216
Validation loss: 1.7117457428286154

Epoch: 6| Step: 12
Training loss: 0.04259073734283447
Validation loss: 1.6851651425002723

Epoch: 6| Step: 13
Training loss: 0.10472844541072845
Validation loss: 1.6985369446457073

Epoch: 531| Step: 0
Training loss: 0.054781392216682434
Validation loss: 1.6627799887810983

Epoch: 6| Step: 1
Training loss: 0.11864304542541504
Validation loss: 1.680491711503716

Epoch: 6| Step: 2
Training loss: 0.09308275580406189
Validation loss: 1.6906990056396813

Epoch: 6| Step: 3
Training loss: 0.07597649842500687
Validation loss: 1.6664755459754699

Epoch: 6| Step: 4
Training loss: 0.08713477849960327
Validation loss: 1.6829963243135841

Epoch: 6| Step: 5
Training loss: 0.08498819172382355
Validation loss: 1.6362240686211535

Epoch: 6| Step: 6
Training loss: 0.08712398260831833
Validation loss: 1.6267023201911681

Epoch: 6| Step: 7
Training loss: 0.09043432027101517
Validation loss: 1.6368607949185114

Epoch: 6| Step: 8
Training loss: 0.07483156025409698
Validation loss: 1.623193234525701

Epoch: 6| Step: 9
Training loss: 0.054940611124038696
Validation loss: 1.6298957063305763

Epoch: 6| Step: 10
Training loss: 0.08799802511930466
Validation loss: 1.6259317782617384

Epoch: 6| Step: 11
Training loss: 0.052472326904535294
Validation loss: 1.6390115753296883

Epoch: 6| Step: 12
Training loss: 0.08903055638074875
Validation loss: 1.6412158255935998

Epoch: 6| Step: 13
Training loss: 0.14646928012371063
Validation loss: 1.6405556560844503

Epoch: 532| Step: 0
Training loss: 0.08236023038625717
Validation loss: 1.6652313227294593

Epoch: 6| Step: 1
Training loss: 0.11842581629753113
Validation loss: 1.6922691176014562

Epoch: 6| Step: 2
Training loss: 0.09849467873573303
Validation loss: 1.6741049315339775

Epoch: 6| Step: 3
Training loss: 0.08092416822910309
Validation loss: 1.6692772347440001

Epoch: 6| Step: 4
Training loss: 0.09853534400463104
Validation loss: 1.645598057777651

Epoch: 6| Step: 5
Training loss: 0.07188403606414795
Validation loss: 1.6412025215805217

Epoch: 6| Step: 6
Training loss: 0.06014972925186157
Validation loss: 1.6443355493648077

Epoch: 6| Step: 7
Training loss: 0.14664232730865479
Validation loss: 1.645818297581006

Epoch: 6| Step: 8
Training loss: 0.08481941372156143
Validation loss: 1.6233149779740201

Epoch: 6| Step: 9
Training loss: 0.10326080024242401
Validation loss: 1.6292218226258472

Epoch: 6| Step: 10
Training loss: 0.1418173611164093
Validation loss: 1.6242040870010213

Epoch: 6| Step: 11
Training loss: 0.1159285306930542
Validation loss: 1.6002745641175138

Epoch: 6| Step: 12
Training loss: 0.1278906762599945
Validation loss: 1.6231373356234642

Epoch: 6| Step: 13
Training loss: 0.08458856493234634
Validation loss: 1.6334218164925933

Epoch: 533| Step: 0
Training loss: 0.19546648859977722
Validation loss: 1.6234223432438348

Epoch: 6| Step: 1
Training loss: 0.07399857044219971
Validation loss: 1.643400288397266

Epoch: 6| Step: 2
Training loss: 0.08212186396121979
Validation loss: 1.6704928310968543

Epoch: 6| Step: 3
Training loss: 0.09557992219924927
Validation loss: 1.6773856224552277

Epoch: 6| Step: 4
Training loss: 0.13115143775939941
Validation loss: 1.6755856339649489

Epoch: 6| Step: 5
Training loss: 0.09075406193733215
Validation loss: 1.7142177025477092

Epoch: 6| Step: 6
Training loss: 0.04259101673960686
Validation loss: 1.7205003846076228

Epoch: 6| Step: 7
Training loss: 0.07855955511331558
Validation loss: 1.690944685730883

Epoch: 6| Step: 8
Training loss: 0.1221202164888382
Validation loss: 1.699271462296927

Epoch: 6| Step: 9
Training loss: 0.14472538232803345
Validation loss: 1.668356877501293

Epoch: 6| Step: 10
Training loss: 0.10879962891340256
Validation loss: 1.6648670332406157

Epoch: 6| Step: 11
Training loss: 0.09507115185260773
Validation loss: 1.6755915739203011

Epoch: 6| Step: 12
Training loss: 0.07677389681339264
Validation loss: 1.6944921593512259

Epoch: 6| Step: 13
Training loss: 0.06665713340044022
Validation loss: 1.6898399206899828

Epoch: 534| Step: 0
Training loss: 0.093329519033432
Validation loss: 1.6883067187442575

Epoch: 6| Step: 1
Training loss: 0.06624067574739456
Validation loss: 1.7009375633731965

Epoch: 6| Step: 2
Training loss: 0.09357580542564392
Validation loss: 1.6953981435427101

Epoch: 6| Step: 3
Training loss: 0.14055684208869934
Validation loss: 1.6889099946586035

Epoch: 6| Step: 4
Training loss: 0.11028458923101425
Validation loss: 1.684077824315717

Epoch: 6| Step: 5
Training loss: 0.06802336871623993
Validation loss: 1.675016260916187

Epoch: 6| Step: 6
Training loss: 0.07933817058801651
Validation loss: 1.6795677690095798

Epoch: 6| Step: 7
Training loss: 0.04694937914609909
Validation loss: 1.6582209083341783

Epoch: 6| Step: 8
Training loss: 0.052960895001888275
Validation loss: 1.6780020363869206

Epoch: 6| Step: 9
Training loss: 0.07528556138277054
Validation loss: 1.6573465562635852

Epoch: 6| Step: 10
Training loss: 0.07733580470085144
Validation loss: 1.6886566326182375

Epoch: 6| Step: 11
Training loss: 0.11243391782045364
Validation loss: 1.677645109033072

Epoch: 6| Step: 12
Training loss: 0.10407320410013199
Validation loss: 1.6737443311240083

Epoch: 6| Step: 13
Training loss: 0.12456255406141281
Validation loss: 1.6610983904971872

Epoch: 535| Step: 0
Training loss: 0.06278795003890991
Validation loss: 1.663565912554341

Epoch: 6| Step: 1
Training loss: 0.07923626154661179
Validation loss: 1.6824612732856505

Epoch: 6| Step: 2
Training loss: 0.12355255335569382
Validation loss: 1.64437392193784

Epoch: 6| Step: 3
Training loss: 0.08481523394584656
Validation loss: 1.6448532381365377

Epoch: 6| Step: 4
Training loss: 0.07678334414958954
Validation loss: 1.6567236838802215

Epoch: 6| Step: 5
Training loss: 0.07488933950662613
Validation loss: 1.6125928022528206

Epoch: 6| Step: 6
Training loss: 0.0948968231678009
Validation loss: 1.623681801621632

Epoch: 6| Step: 7
Training loss: 0.08689954876899719
Validation loss: 1.6395797832037813

Epoch: 6| Step: 8
Training loss: 0.07474762946367264
Validation loss: 1.6030812109670332

Epoch: 6| Step: 9
Training loss: 0.056161992251873016
Validation loss: 1.6460646378096713

Epoch: 6| Step: 10
Training loss: 0.041995882987976074
Validation loss: 1.6459923751892582

Epoch: 6| Step: 11
Training loss: 0.10945166647434235
Validation loss: 1.6450594496983353

Epoch: 6| Step: 12
Training loss: 0.09335112571716309
Validation loss: 1.637388410106782

Epoch: 6| Step: 13
Training loss: 0.09335409104824066
Validation loss: 1.6290950903328516

Epoch: 536| Step: 0
Training loss: 0.05576067417860031
Validation loss: 1.620096157955867

Epoch: 6| Step: 1
Training loss: 0.07146383076906204
Validation loss: 1.638008309948829

Epoch: 6| Step: 2
Training loss: 0.07445678114891052
Validation loss: 1.657410019187517

Epoch: 6| Step: 3
Training loss: 0.09855974465608597
Validation loss: 1.6435108838542816

Epoch: 6| Step: 4
Training loss: 0.11172392964363098
Validation loss: 1.696849646106843

Epoch: 6| Step: 5
Training loss: 0.08038623631000519
Validation loss: 1.679625782915341

Epoch: 6| Step: 6
Training loss: 0.09982862323522568
Validation loss: 1.7029776496271933

Epoch: 6| Step: 7
Training loss: 0.15993493795394897
Validation loss: 1.6999046302610827

Epoch: 6| Step: 8
Training loss: 0.08223913609981537
Validation loss: 1.6706153859374344

Epoch: 6| Step: 9
Training loss: 0.04267507791519165
Validation loss: 1.6342795741173528

Epoch: 6| Step: 10
Training loss: 0.11696526408195496
Validation loss: 1.6709041557004374

Epoch: 6| Step: 11
Training loss: 0.1376756876707077
Validation loss: 1.6513236530365483

Epoch: 6| Step: 12
Training loss: 0.07412200421094894
Validation loss: 1.620037148075719

Epoch: 6| Step: 13
Training loss: 0.10332828015089035
Validation loss: 1.5969604292223532

Epoch: 537| Step: 0
Training loss: 0.058441054075956345
Validation loss: 1.6164781560180008

Epoch: 6| Step: 1
Training loss: 0.10110067576169968
Validation loss: 1.6330723198511268

Epoch: 6| Step: 2
Training loss: 0.06925894320011139
Validation loss: 1.609047669236378

Epoch: 6| Step: 3
Training loss: 0.052528008818626404
Validation loss: 1.5821544893326298

Epoch: 6| Step: 4
Training loss: 0.07852223515510559
Validation loss: 1.5892631405143327

Epoch: 6| Step: 5
Training loss: 0.07132059335708618
Validation loss: 1.6144460401227396

Epoch: 6| Step: 6
Training loss: 0.10733840614557266
Validation loss: 1.6659788944387948

Epoch: 6| Step: 7
Training loss: 0.11531803011894226
Validation loss: 1.6700622753430439

Epoch: 6| Step: 8
Training loss: 0.09961932897567749
Validation loss: 1.62866009178982

Epoch: 6| Step: 9
Training loss: 0.09418082237243652
Validation loss: 1.6529014982203

Epoch: 6| Step: 10
Training loss: 0.10235485434532166
Validation loss: 1.6409959741818008

Epoch: 6| Step: 11
Training loss: 0.06591840088367462
Validation loss: 1.6492203294589955

Epoch: 6| Step: 12
Training loss: 0.08719243854284286
Validation loss: 1.6354144760357436

Epoch: 6| Step: 13
Training loss: 0.1301744431257248
Validation loss: 1.6509214203844789

Epoch: 538| Step: 0
Training loss: 0.11783567816019058
Validation loss: 1.6547067357647804

Epoch: 6| Step: 1
Training loss: 0.07064257562160492
Validation loss: 1.6293566047504384

Epoch: 6| Step: 2
Training loss: 0.06120923161506653
Validation loss: 1.6138143988065823

Epoch: 6| Step: 3
Training loss: 0.10310475528240204
Validation loss: 1.6112549766417472

Epoch: 6| Step: 4
Training loss: 0.06285326927900314
Validation loss: 1.6218520755408912

Epoch: 6| Step: 5
Training loss: 0.07813666015863419
Validation loss: 1.615521038732221

Epoch: 6| Step: 6
Training loss: 0.11094418168067932
Validation loss: 1.6102969390089794

Epoch: 6| Step: 7
Training loss: 0.06474220007658005
Validation loss: 1.5914696301183393

Epoch: 6| Step: 8
Training loss: 0.11772320419549942
Validation loss: 1.6011265913645427

Epoch: 6| Step: 9
Training loss: 0.12313363701105118
Validation loss: 1.6177240815213931

Epoch: 6| Step: 10
Training loss: 0.07402078062295914
Validation loss: 1.602528231118315

Epoch: 6| Step: 11
Training loss: 0.09044578671455383
Validation loss: 1.6095474625146517

Epoch: 6| Step: 12
Training loss: 0.07075562328100204
Validation loss: 1.60000951187585

Epoch: 6| Step: 13
Training loss: 0.056859612464904785
Validation loss: 1.611353866515621

Epoch: 539| Step: 0
Training loss: 0.08094051480293274
Validation loss: 1.6154422401100077

Epoch: 6| Step: 1
Training loss: 0.09809625148773193
Validation loss: 1.6594928464581888

Epoch: 6| Step: 2
Training loss: 0.06842325627803802
Validation loss: 1.653912905723818

Epoch: 6| Step: 3
Training loss: 0.0893278643488884
Validation loss: 1.643466511080342

Epoch: 6| Step: 4
Training loss: 0.11564341187477112
Validation loss: 1.67056643578314

Epoch: 6| Step: 5
Training loss: 0.08382542431354523
Validation loss: 1.6597325712121942

Epoch: 6| Step: 6
Training loss: 0.07288295030593872
Validation loss: 1.66137134644293

Epoch: 6| Step: 7
Training loss: 0.1041254848241806
Validation loss: 1.6515399666242703

Epoch: 6| Step: 8
Training loss: 0.07443170249462128
Validation loss: 1.6433479773100985

Epoch: 6| Step: 9
Training loss: 0.06976468861103058
Validation loss: 1.635326454716344

Epoch: 6| Step: 10
Training loss: 0.07303754985332489
Validation loss: 1.632289545510405

Epoch: 6| Step: 11
Training loss: 0.07108721137046814
Validation loss: 1.620983265420442

Epoch: 6| Step: 12
Training loss: 0.12396764755249023
Validation loss: 1.6067759003690494

Epoch: 6| Step: 13
Training loss: 0.05362663045525551
Validation loss: 1.6157123017054733

Epoch: 540| Step: 0
Training loss: 0.08698876947164536
Validation loss: 1.6171112547638595

Epoch: 6| Step: 1
Training loss: 0.0805138498544693
Validation loss: 1.6631148810027747

Epoch: 6| Step: 2
Training loss: 0.07651444524526596
Validation loss: 1.6205428800275248

Epoch: 6| Step: 3
Training loss: 0.09204889088869095
Validation loss: 1.6454892414872364

Epoch: 6| Step: 4
Training loss: 0.07997933030128479
Validation loss: 1.6499596026635939

Epoch: 6| Step: 5
Training loss: 0.08195237815380096
Validation loss: 1.652010961245465

Epoch: 6| Step: 6
Training loss: 0.053947702050209045
Validation loss: 1.6817460137028848

Epoch: 6| Step: 7
Training loss: 0.14299552142620087
Validation loss: 1.6838423282869401

Epoch: 6| Step: 8
Training loss: 0.1274881213903427
Validation loss: 1.6848064507207563

Epoch: 6| Step: 9
Training loss: 0.1085854023694992
Validation loss: 1.668543674612558

Epoch: 6| Step: 10
Training loss: 0.08876557648181915
Validation loss: 1.6303310766015002

Epoch: 6| Step: 11
Training loss: 0.08394116163253784
Validation loss: 1.697135079291559

Epoch: 6| Step: 12
Training loss: 0.1159132868051529
Validation loss: 1.6786447763442993

Epoch: 6| Step: 13
Training loss: 0.08790460228919983
Validation loss: 1.6959854274667718

Epoch: 541| Step: 0
Training loss: 0.06039317697286606
Validation loss: 1.6876544003845544

Epoch: 6| Step: 1
Training loss: 0.12473350018262863
Validation loss: 1.6959388538073468

Epoch: 6| Step: 2
Training loss: 0.0947268158197403
Validation loss: 1.7140617908970002

Epoch: 6| Step: 3
Training loss: 0.07414960861206055
Validation loss: 1.7046921278840752

Epoch: 6| Step: 4
Training loss: 0.07692816853523254
Validation loss: 1.7174082289459884

Epoch: 6| Step: 5
Training loss: 0.08995629847049713
Validation loss: 1.758204674208036

Epoch: 6| Step: 6
Training loss: 0.101302869617939
Validation loss: 1.698387457478431

Epoch: 6| Step: 7
Training loss: 0.07822757959365845
Validation loss: 1.6580933640080113

Epoch: 6| Step: 8
Training loss: 0.07907819747924805
Validation loss: 1.6711015419293476

Epoch: 6| Step: 9
Training loss: 0.08248112350702286
Validation loss: 1.6907413185283702

Epoch: 6| Step: 10
Training loss: 0.06374794244766235
Validation loss: 1.6554091617625246

Epoch: 6| Step: 11
Training loss: 0.04709276929497719
Validation loss: 1.674163487649733

Epoch: 6| Step: 12
Training loss: 0.11570966243743896
Validation loss: 1.6565989345632575

Epoch: 6| Step: 13
Training loss: 0.13530200719833374
Validation loss: 1.6516692394851356

Epoch: 542| Step: 0
Training loss: 0.08395744860172272
Validation loss: 1.6599226959290043

Epoch: 6| Step: 1
Training loss: 0.07936500012874603
Validation loss: 1.684683580552378

Epoch: 6| Step: 2
Training loss: 0.10849598050117493
Validation loss: 1.6975450003018944

Epoch: 6| Step: 3
Training loss: 0.1128857284784317
Validation loss: 1.723801218053346

Epoch: 6| Step: 4
Training loss: 0.17441405355930328
Validation loss: 1.6968250364385626

Epoch: 6| Step: 5
Training loss: 0.0988551452755928
Validation loss: 1.6970472463997461

Epoch: 6| Step: 6
Training loss: 0.13633039593696594
Validation loss: 1.6736723440949635

Epoch: 6| Step: 7
Training loss: 0.12459702789783478
Validation loss: 1.6770370442380187

Epoch: 6| Step: 8
Training loss: 0.11032521724700928
Validation loss: 1.6776556455960838

Epoch: 6| Step: 9
Training loss: 0.08871640264987946
Validation loss: 1.683641977207635

Epoch: 6| Step: 10
Training loss: 0.09179624170064926
Validation loss: 1.7393031966301702

Epoch: 6| Step: 11
Training loss: 0.050229545682668686
Validation loss: 1.7495427221380255

Epoch: 6| Step: 12
Training loss: 0.11078610271215439
Validation loss: 1.7707328757932108

Epoch: 6| Step: 13
Training loss: 0.12730342149734497
Validation loss: 1.7506558459292176

Epoch: 543| Step: 0
Training loss: 0.08995573222637177
Validation loss: 1.7678798078208842

Epoch: 6| Step: 1
Training loss: 0.06344641000032425
Validation loss: 1.7405178534087313

Epoch: 6| Step: 2
Training loss: 0.056655533611774445
Validation loss: 1.6967581202906947

Epoch: 6| Step: 3
Training loss: 0.059480518102645874
Validation loss: 1.7197303733518046

Epoch: 6| Step: 4
Training loss: 0.07551281154155731
Validation loss: 1.6912508305682932

Epoch: 6| Step: 5
Training loss: 0.18073907494544983
Validation loss: 1.66373997734439

Epoch: 6| Step: 6
Training loss: 0.07928687334060669
Validation loss: 1.696856608313899

Epoch: 6| Step: 7
Training loss: 0.06935672461986542
Validation loss: 1.6529443969008744

Epoch: 6| Step: 8
Training loss: 0.052661821246147156
Validation loss: 1.6947719999538955

Epoch: 6| Step: 9
Training loss: 0.12965066730976105
Validation loss: 1.6520315857343777

Epoch: 6| Step: 10
Training loss: 0.0785420835018158
Validation loss: 1.6218735261629986

Epoch: 6| Step: 11
Training loss: 0.09023417532444
Validation loss: 1.634449061527047

Epoch: 6| Step: 12
Training loss: 0.06899517774581909
Validation loss: 1.6209756315395396

Epoch: 6| Step: 13
Training loss: 0.12003571540117264
Validation loss: 1.5769196979461177

Epoch: 544| Step: 0
Training loss: 0.0922025591135025
Validation loss: 1.6140869919971754

Epoch: 6| Step: 1
Training loss: 0.13093790411949158
Validation loss: 1.6289954621304747

Epoch: 6| Step: 2
Training loss: 0.13841167092323303
Validation loss: 1.6576365732377576

Epoch: 6| Step: 3
Training loss: 0.15271279215812683
Validation loss: 1.6434892300636537

Epoch: 6| Step: 4
Training loss: 0.0771755576133728
Validation loss: 1.662519944611416

Epoch: 6| Step: 5
Training loss: 0.07640368491411209
Validation loss: 1.6721802103903987

Epoch: 6| Step: 6
Training loss: 0.1257023811340332
Validation loss: 1.6693315441890428

Epoch: 6| Step: 7
Training loss: 0.03644075244665146
Validation loss: 1.6937567303257604

Epoch: 6| Step: 8
Training loss: 0.06546662747859955
Validation loss: 1.7271005338238132

Epoch: 6| Step: 9
Training loss: 0.10713157802820206
Validation loss: 1.7471631534637944

Epoch: 6| Step: 10
Training loss: 0.07241450995206833
Validation loss: 1.6969505151112874

Epoch: 6| Step: 11
Training loss: 0.0786970853805542
Validation loss: 1.6893773848010647

Epoch: 6| Step: 12
Training loss: 0.07877855002880096
Validation loss: 1.6930851449248612

Epoch: 6| Step: 13
Training loss: 0.08426937460899353
Validation loss: 1.7098457685080908

Epoch: 545| Step: 0
Training loss: 0.06868505477905273
Validation loss: 1.6753819578437394

Epoch: 6| Step: 1
Training loss: 0.08804313838481903
Validation loss: 1.6579803548833376

Epoch: 6| Step: 2
Training loss: 0.05537334457039833
Validation loss: 1.6563930537111016

Epoch: 6| Step: 3
Training loss: 0.10186637938022614
Validation loss: 1.6493182195130216

Epoch: 6| Step: 4
Training loss: 0.09893564879894257
Validation loss: 1.675899302446714

Epoch: 6| Step: 5
Training loss: 0.09641031920909882
Validation loss: 1.6216726546646447

Epoch: 6| Step: 6
Training loss: 0.10443141311407089
Validation loss: 1.6316356658935547

Epoch: 6| Step: 7
Training loss: 0.08063452690839767
Validation loss: 1.6626584670876945

Epoch: 6| Step: 8
Training loss: 0.0958869680762291
Validation loss: 1.6409534677382438

Epoch: 6| Step: 9
Training loss: 0.11386971175670624
Validation loss: 1.6416387660529024

Epoch: 6| Step: 10
Training loss: 0.11824468523263931
Validation loss: 1.633496226802949

Epoch: 6| Step: 11
Training loss: 0.05930233746767044
Validation loss: 1.6848132648775656

Epoch: 6| Step: 12
Training loss: 0.09405429661273956
Validation loss: 1.6797233217505998

Epoch: 6| Step: 13
Training loss: 0.1001003161072731
Validation loss: 1.7036139324147215

Epoch: 546| Step: 0
Training loss: 0.09102904796600342
Validation loss: 1.7333907517053748

Epoch: 6| Step: 1
Training loss: 0.10399121046066284
Validation loss: 1.733629088247976

Epoch: 6| Step: 2
Training loss: 0.05281884968280792
Validation loss: 1.7390670417457499

Epoch: 6| Step: 3
Training loss: 0.10480399429798126
Validation loss: 1.7227262553348337

Epoch: 6| Step: 4
Training loss: 0.07579503208398819
Validation loss: 1.7458103882369174

Epoch: 6| Step: 5
Training loss: 0.05589400604367256
Validation loss: 1.7166820661996

Epoch: 6| Step: 6
Training loss: 0.11919622123241425
Validation loss: 1.7147552787616689

Epoch: 6| Step: 7
Training loss: 0.0858633741736412
Validation loss: 1.7146764083575177

Epoch: 6| Step: 8
Training loss: 0.12122540920972824
Validation loss: 1.733031311342793

Epoch: 6| Step: 9
Training loss: 0.04309309646487236
Validation loss: 1.679905927309426

Epoch: 6| Step: 10
Training loss: 0.09284336864948273
Validation loss: 1.7023531557411276

Epoch: 6| Step: 11
Training loss: 0.05986476317048073
Validation loss: 1.6710478131489088

Epoch: 6| Step: 12
Training loss: 0.0866190642118454
Validation loss: 1.6839828850120626

Epoch: 6| Step: 13
Training loss: 0.0754089429974556
Validation loss: 1.7288932877202188

Epoch: 547| Step: 0
Training loss: 0.06756393611431122
Validation loss: 1.711253785317944

Epoch: 6| Step: 1
Training loss: 0.06579694151878357
Validation loss: 1.6757043433445755

Epoch: 6| Step: 2
Training loss: 0.11764350533485413
Validation loss: 1.7126031639755412

Epoch: 6| Step: 3
Training loss: 0.09781699627637863
Validation loss: 1.7007629691913564

Epoch: 6| Step: 4
Training loss: 0.08019093424081802
Validation loss: 1.7211305351667507

Epoch: 6| Step: 5
Training loss: 0.0703384280204773
Validation loss: 1.7186060297873713

Epoch: 6| Step: 6
Training loss: 0.07150348275899887
Validation loss: 1.6982791385342997

Epoch: 6| Step: 7
Training loss: 0.08366638422012329
Validation loss: 1.7048293429036294

Epoch: 6| Step: 8
Training loss: 0.05263463407754898
Validation loss: 1.6828818987774592

Epoch: 6| Step: 9
Training loss: 0.07938067615032196
Validation loss: 1.7019421131380144

Epoch: 6| Step: 10
Training loss: 0.12390144169330597
Validation loss: 1.6967950879886586

Epoch: 6| Step: 11
Training loss: 0.06918870657682419
Validation loss: 1.6807623287682891

Epoch: 6| Step: 12
Training loss: 0.10356102883815765
Validation loss: 1.6880150623218988

Epoch: 6| Step: 13
Training loss: 0.06335948407649994
Validation loss: 1.6901783968812676

Epoch: 548| Step: 0
Training loss: 0.08427353948354721
Validation loss: 1.7014984546169158

Epoch: 6| Step: 1
Training loss: 0.05785812437534332
Validation loss: 1.7103904447247904

Epoch: 6| Step: 2
Training loss: 0.07963551580905914
Validation loss: 1.718831290480911

Epoch: 6| Step: 3
Training loss: 0.07743257284164429
Validation loss: 1.737350308766929

Epoch: 6| Step: 4
Training loss: 0.050973739475011826
Validation loss: 1.7544606501056301

Epoch: 6| Step: 5
Training loss: 0.10439886152744293
Validation loss: 1.7561991676207511

Epoch: 6| Step: 6
Training loss: 0.09103341400623322
Validation loss: 1.7770519923138361

Epoch: 6| Step: 7
Training loss: 0.10036273300647736
Validation loss: 1.7318963145696988

Epoch: 6| Step: 8
Training loss: 0.07575827091932297
Validation loss: 1.7471281610509402

Epoch: 6| Step: 9
Training loss: 0.10255441814661026
Validation loss: 1.7244868111866776

Epoch: 6| Step: 10
Training loss: 0.07202133536338806
Validation loss: 1.6960956281231296

Epoch: 6| Step: 11
Training loss: 0.07283785939216614
Validation loss: 1.7081458184026903

Epoch: 6| Step: 12
Training loss: 0.05943882092833519
Validation loss: 1.6799065848832488

Epoch: 6| Step: 13
Training loss: 0.06376548111438751
Validation loss: 1.6865287365451935

Epoch: 549| Step: 0
Training loss: 0.1388685405254364
Validation loss: 1.7039881675474104

Epoch: 6| Step: 1
Training loss: 0.1943657100200653
Validation loss: 1.678357994684609

Epoch: 6| Step: 2
Training loss: 0.11799242347478867
Validation loss: 1.6719686472287743

Epoch: 6| Step: 3
Training loss: 0.09163977205753326
Validation loss: 1.6706851477264075

Epoch: 6| Step: 4
Training loss: 0.08101851493120193
Validation loss: 1.6438568881762925

Epoch: 6| Step: 5
Training loss: 0.07369150221347809
Validation loss: 1.6451787820426367

Epoch: 6| Step: 6
Training loss: 0.06611549854278564
Validation loss: 1.6532205317610054

Epoch: 6| Step: 7
Training loss: 0.16479629278182983
Validation loss: 1.6311184603680846

Epoch: 6| Step: 8
Training loss: 0.1459614485502243
Validation loss: 1.6535407304763794

Epoch: 6| Step: 9
Training loss: 0.13897830247879028
Validation loss: 1.6495583429131457

Epoch: 6| Step: 10
Training loss: 0.06441541016101837
Validation loss: 1.6125477693414176

Epoch: 6| Step: 11
Training loss: 0.07410000264644623
Validation loss: 1.6206834828981789

Epoch: 6| Step: 12
Training loss: 0.09368526190519333
Validation loss: 1.6278009158308788

Epoch: 6| Step: 13
Training loss: 0.048964884132146835
Validation loss: 1.6155105252419748

Epoch: 550| Step: 0
Training loss: 0.08446989953517914
Validation loss: 1.6231795998029812

Epoch: 6| Step: 1
Training loss: 0.08905285596847534
Validation loss: 1.6315603333134805

Epoch: 6| Step: 2
Training loss: 0.12117046117782593
Validation loss: 1.621224126508159

Epoch: 6| Step: 3
Training loss: 0.10207915306091309
Validation loss: 1.6666193860833363

Epoch: 6| Step: 4
Training loss: 0.07651805877685547
Validation loss: 1.6702635800966652

Epoch: 6| Step: 5
Training loss: 0.09323664009571075
Validation loss: 1.669568193856106

Epoch: 6| Step: 6
Training loss: 0.12759262323379517
Validation loss: 1.6546322812316239

Epoch: 6| Step: 7
Training loss: 0.08038429915904999
Validation loss: 1.7018229743485809

Epoch: 6| Step: 8
Training loss: 0.06185143068432808
Validation loss: 1.6355037740481797

Epoch: 6| Step: 9
Training loss: 0.09706882387399673
Validation loss: 1.6675309173522457

Epoch: 6| Step: 10
Training loss: 0.11739356815814972
Validation loss: 1.6712677876154582

Epoch: 6| Step: 11
Training loss: 0.19897116720676422
Validation loss: 1.6374040085782287

Epoch: 6| Step: 12
Training loss: 0.08469024300575256
Validation loss: 1.6744669073371476

Epoch: 6| Step: 13
Training loss: 0.10908976942300797
Validation loss: 1.675327706080611

Epoch: 551| Step: 0
Training loss: 0.0840294361114502
Validation loss: 1.7045335692744101

Epoch: 6| Step: 1
Training loss: 0.07559976726770401
Validation loss: 1.7028359931002381

Epoch: 6| Step: 2
Training loss: 0.08676545321941376
Validation loss: 1.742280174327153

Epoch: 6| Step: 3
Training loss: 0.10617305338382721
Validation loss: 1.7232277034431376

Epoch: 6| Step: 4
Training loss: 0.12595102190971375
Validation loss: 1.742059237213545

Epoch: 6| Step: 5
Training loss: 0.1411687433719635
Validation loss: 1.724193508907031

Epoch: 6| Step: 6
Training loss: 0.06229764595627785
Validation loss: 1.7135655444155458

Epoch: 6| Step: 7
Training loss: 0.08606162667274475
Validation loss: 1.6874945932818997

Epoch: 6| Step: 8
Training loss: 0.05594104900956154
Validation loss: 1.6827376491280013

Epoch: 6| Step: 9
Training loss: 0.09526239335536957
Validation loss: 1.7027245131872033

Epoch: 6| Step: 10
Training loss: 0.07006937265396118
Validation loss: 1.676658486807218

Epoch: 6| Step: 11
Training loss: 0.13953028619289398
Validation loss: 1.6855785449345906

Epoch: 6| Step: 12
Training loss: 0.07921271026134491
Validation loss: 1.6704720335621988

Epoch: 6| Step: 13
Training loss: 0.10253405570983887
Validation loss: 1.6969132525946504

Epoch: 552| Step: 0
Training loss: 0.062422312796115875
Validation loss: 1.6864650710936515

Epoch: 6| Step: 1
Training loss: 0.09665010869503021
Validation loss: 1.6785029147260933

Epoch: 6| Step: 2
Training loss: 0.08458766341209412
Validation loss: 1.664897552100561

Epoch: 6| Step: 3
Training loss: 0.09058631956577301
Validation loss: 1.7316191811715402

Epoch: 6| Step: 4
Training loss: 0.07984643429517746
Validation loss: 1.7133706551726147

Epoch: 6| Step: 5
Training loss: 0.06423615664243698
Validation loss: 1.6729242250483523

Epoch: 6| Step: 6
Training loss: 0.06871351599693298
Validation loss: 1.6496670348669893

Epoch: 6| Step: 7
Training loss: 0.08012031763792038
Validation loss: 1.6566443180525174

Epoch: 6| Step: 8
Training loss: 0.0384574718773365
Validation loss: 1.6249997551723192

Epoch: 6| Step: 9
Training loss: 0.06822499632835388
Validation loss: 1.6466057223658408

Epoch: 6| Step: 10
Training loss: 0.07034943997859955
Validation loss: 1.6571149749140586

Epoch: 6| Step: 11
Training loss: 0.07423202693462372
Validation loss: 1.6662573968210528

Epoch: 6| Step: 12
Training loss: 0.07839083671569824
Validation loss: 1.6575291502860285

Epoch: 6| Step: 13
Training loss: 0.06027695909142494
Validation loss: 1.6523820418183521

Epoch: 553| Step: 0
Training loss: 0.1316506415605545
Validation loss: 1.68377782324309

Epoch: 6| Step: 1
Training loss: 0.06657341122627258
Validation loss: 1.6673490334582586

Epoch: 6| Step: 2
Training loss: 0.07394453883171082
Validation loss: 1.6953947979916808

Epoch: 6| Step: 3
Training loss: 0.06982900202274323
Validation loss: 1.6883561720130265

Epoch: 6| Step: 4
Training loss: 0.14905254542827606
Validation loss: 1.6421929533763597

Epoch: 6| Step: 5
Training loss: 0.10903878509998322
Validation loss: 1.6810542293774184

Epoch: 6| Step: 6
Training loss: 0.06736704707145691
Validation loss: 1.684531024707261

Epoch: 6| Step: 7
Training loss: 0.052540816366672516
Validation loss: 1.7084951118756366

Epoch: 6| Step: 8
Training loss: 0.05274521932005882
Validation loss: 1.6952586122738418

Epoch: 6| Step: 9
Training loss: 0.04765234887599945
Validation loss: 1.6994096617544852

Epoch: 6| Step: 10
Training loss: 0.06873045116662979
Validation loss: 1.7230300031682497

Epoch: 6| Step: 11
Training loss: 0.04998253285884857
Validation loss: 1.714025774309712

Epoch: 6| Step: 12
Training loss: 0.07396138459444046
Validation loss: 1.7232035718938357

Epoch: 6| Step: 13
Training loss: 0.12065175920724869
Validation loss: 1.6859963311943957

Epoch: 554| Step: 0
Training loss: 0.09052049368619919
Validation loss: 1.6857527840522029

Epoch: 6| Step: 1
Training loss: 0.07863771170377731
Validation loss: 1.669881941169821

Epoch: 6| Step: 2
Training loss: 0.06284203380346298
Validation loss: 1.683882010880337

Epoch: 6| Step: 3
Training loss: 0.05464724451303482
Validation loss: 1.6944194968028734

Epoch: 6| Step: 4
Training loss: 0.0913383960723877
Validation loss: 1.6558634388831355

Epoch: 6| Step: 5
Training loss: 0.11530594527721405
Validation loss: 1.6875370676799486

Epoch: 6| Step: 6
Training loss: 0.056642189621925354
Validation loss: 1.7050429979960124

Epoch: 6| Step: 7
Training loss: 0.06444109976291656
Validation loss: 1.7117606183534027

Epoch: 6| Step: 8
Training loss: 0.13101539015769958
Validation loss: 1.6873110827579294

Epoch: 6| Step: 9
Training loss: 0.05472542345523834
Validation loss: 1.7084323577983405

Epoch: 6| Step: 10
Training loss: 0.06349627673625946
Validation loss: 1.7071686919017504

Epoch: 6| Step: 11
Training loss: 0.056121714413166046
Validation loss: 1.7196373952332364

Epoch: 6| Step: 12
Training loss: 0.0525081530213356
Validation loss: 1.686342937971956

Epoch: 6| Step: 13
Training loss: 0.053719956427812576
Validation loss: 1.7036554223747664

Epoch: 555| Step: 0
Training loss: 0.07746397703886032
Validation loss: 1.6923413879127913

Epoch: 6| Step: 1
Training loss: 0.07090406119823456
Validation loss: 1.679337033661463

Epoch: 6| Step: 2
Training loss: 0.06407977640628815
Validation loss: 1.6752610578331897

Epoch: 6| Step: 3
Training loss: 0.03633011505007744
Validation loss: 1.6698327205514396

Epoch: 6| Step: 4
Training loss: 0.05848167836666107
Validation loss: 1.6677783778918687

Epoch: 6| Step: 5
Training loss: 0.07776965200901031
Validation loss: 1.667118691628979

Epoch: 6| Step: 6
Training loss: 0.056508660316467285
Validation loss: 1.6305442048657326

Epoch: 6| Step: 7
Training loss: 0.08733734488487244
Validation loss: 1.6795175754895775

Epoch: 6| Step: 8
Training loss: 0.09341558814048767
Validation loss: 1.6761557876422841

Epoch: 6| Step: 9
Training loss: 0.07414843887090683
Validation loss: 1.6969826875194427

Epoch: 6| Step: 10
Training loss: 0.05755913257598877
Validation loss: 1.6634222461331276

Epoch: 6| Step: 11
Training loss: 0.1102028489112854
Validation loss: 1.6583515033927014

Epoch: 6| Step: 12
Training loss: 0.049833204597234726
Validation loss: 1.6738912995143602

Epoch: 6| Step: 13
Training loss: 0.07995545864105225
Validation loss: 1.6450624671033633

Epoch: 556| Step: 0
Training loss: 0.06589701026678085
Validation loss: 1.6751846677513533

Epoch: 6| Step: 1
Training loss: 0.09425249695777893
Validation loss: 1.677511865092862

Epoch: 6| Step: 2
Training loss: 0.06843521445989609
Validation loss: 1.6500370053834812

Epoch: 6| Step: 3
Training loss: 0.09096046537160873
Validation loss: 1.6356408583220614

Epoch: 6| Step: 4
Training loss: 0.05247841775417328
Validation loss: 1.654956749049566

Epoch: 6| Step: 5
Training loss: 0.08677032589912415
Validation loss: 1.681150177473663

Epoch: 6| Step: 6
Training loss: 0.05643751472234726
Validation loss: 1.6995279212151804

Epoch: 6| Step: 7
Training loss: 0.11307330429553986
Validation loss: 1.725953927604101

Epoch: 6| Step: 8
Training loss: 0.15483467280864716
Validation loss: 1.727018646014634

Epoch: 6| Step: 9
Training loss: 0.10291785001754761
Validation loss: 1.7366944154103596

Epoch: 6| Step: 10
Training loss: 0.07897820323705673
Validation loss: 1.6895927177962435

Epoch: 6| Step: 11
Training loss: 0.056911639869213104
Validation loss: 1.6843084763455134

Epoch: 6| Step: 12
Training loss: 0.06817334145307541
Validation loss: 1.6595643515227942

Epoch: 6| Step: 13
Training loss: 0.07600931078195572
Validation loss: 1.6363513097968152

Epoch: 557| Step: 0
Training loss: 0.057421013712882996
Validation loss: 1.6027652012404574

Epoch: 6| Step: 1
Training loss: 0.06929217278957367
Validation loss: 1.6423431186265842

Epoch: 6| Step: 2
Training loss: 0.09944476932287216
Validation loss: 1.6426615099753104

Epoch: 6| Step: 3
Training loss: 0.05398815870285034
Validation loss: 1.62187889699013

Epoch: 6| Step: 4
Training loss: 0.06663551926612854
Validation loss: 1.6613466688381728

Epoch: 6| Step: 5
Training loss: 0.1186380609869957
Validation loss: 1.6416930088432886

Epoch: 6| Step: 6
Training loss: 0.08606211096048355
Validation loss: 1.627507048268472

Epoch: 6| Step: 7
Training loss: 0.059434060007333755
Validation loss: 1.6597529560007074

Epoch: 6| Step: 8
Training loss: 0.07254244387149811
Validation loss: 1.6818093792084725

Epoch: 6| Step: 9
Training loss: 0.14900538325309753
Validation loss: 1.681960637851428

Epoch: 6| Step: 10
Training loss: 0.04640951752662659
Validation loss: 1.720469977266045

Epoch: 6| Step: 11
Training loss: 0.17450512945652008
Validation loss: 1.6717113141090638

Epoch: 6| Step: 12
Training loss: 0.08374358713626862
Validation loss: 1.7082621692329325

Epoch: 6| Step: 13
Training loss: 0.14716599881649017
Validation loss: 1.7130046454809045

Epoch: 558| Step: 0
Training loss: 0.06559605896472931
Validation loss: 1.710053591318028

Epoch: 6| Step: 1
Training loss: 0.05557262897491455
Validation loss: 1.663919779562181

Epoch: 6| Step: 2
Training loss: 0.1264778971672058
Validation loss: 1.6449180251808577

Epoch: 6| Step: 3
Training loss: 0.13476374745368958
Validation loss: 1.6725200350566576

Epoch: 6| Step: 4
Training loss: 0.1144346073269844
Validation loss: 1.676240304464935

Epoch: 6| Step: 5
Training loss: 0.0889967828989029
Validation loss: 1.7061827618588683

Epoch: 6| Step: 6
Training loss: 0.08085291087627411
Validation loss: 1.713856602227816

Epoch: 6| Step: 7
Training loss: 0.1091352105140686
Validation loss: 1.6843822835594096

Epoch: 6| Step: 8
Training loss: 0.09197764098644257
Validation loss: 1.7085875400932886

Epoch: 6| Step: 9
Training loss: 0.09048329293727875
Validation loss: 1.6934123859610608

Epoch: 6| Step: 10
Training loss: 0.06929327547550201
Validation loss: 1.7064704638655468

Epoch: 6| Step: 11
Training loss: 0.08733181655406952
Validation loss: 1.6867642005284627

Epoch: 6| Step: 12
Training loss: 0.04205365478992462
Validation loss: 1.675377074108329

Epoch: 6| Step: 13
Training loss: 0.06312057375907898
Validation loss: 1.6798086986746839

Epoch: 559| Step: 0
Training loss: 0.05462142080068588
Validation loss: 1.6742576591430172

Epoch: 6| Step: 1
Training loss: 0.06673012673854828
Validation loss: 1.6563990808302356

Epoch: 6| Step: 2
Training loss: 0.05599784851074219
Validation loss: 1.6511597441088768

Epoch: 6| Step: 3
Training loss: 0.08894605934619904
Validation loss: 1.6446514693639611

Epoch: 6| Step: 4
Training loss: 0.06120205670595169
Validation loss: 1.6595878601074219

Epoch: 6| Step: 5
Training loss: 0.08326065540313721
Validation loss: 1.6461439062190313

Epoch: 6| Step: 6
Training loss: 0.09952855110168457
Validation loss: 1.6357409031160417

Epoch: 6| Step: 7
Training loss: 0.10165916383266449
Validation loss: 1.6133861323838592

Epoch: 6| Step: 8
Training loss: 0.08572480827569962
Validation loss: 1.635952611123362

Epoch: 6| Step: 9
Training loss: 0.09353827685117722
Validation loss: 1.6633199235444427

Epoch: 6| Step: 10
Training loss: 0.04250287264585495
Validation loss: 1.6687614302481375

Epoch: 6| Step: 11
Training loss: 0.053630225360393524
Validation loss: 1.6388714698053175

Epoch: 6| Step: 12
Training loss: 0.0563618429005146
Validation loss: 1.6449707349141438

Epoch: 6| Step: 13
Training loss: 0.1087191179394722
Validation loss: 1.684511669220463

Epoch: 560| Step: 0
Training loss: 0.04766542837023735
Validation loss: 1.658251964917747

Epoch: 6| Step: 1
Training loss: 0.13999806344509125
Validation loss: 1.6741722424825032

Epoch: 6| Step: 2
Training loss: 0.14377859234809875
Validation loss: 1.6884543946994248

Epoch: 6| Step: 3
Training loss: 0.15150782465934753
Validation loss: 1.6749372443845194

Epoch: 6| Step: 4
Training loss: 0.07388487458229065
Validation loss: 1.6655741840280511

Epoch: 6| Step: 5
Training loss: 0.07281353324651718
Validation loss: 1.6759190469659784

Epoch: 6| Step: 6
Training loss: 0.056526634842157364
Validation loss: 1.659828342417235

Epoch: 6| Step: 7
Training loss: 0.04941064864397049
Validation loss: 1.7123156337327854

Epoch: 6| Step: 8
Training loss: 0.05337408557534218
Validation loss: 1.7011473742864465

Epoch: 6| Step: 9
Training loss: 0.05202328413724899
Validation loss: 1.6929610095998293

Epoch: 6| Step: 10
Training loss: 0.07871563732624054
Validation loss: 1.718463634931913

Epoch: 6| Step: 11
Training loss: 0.06192183494567871
Validation loss: 1.7096482476880472

Epoch: 6| Step: 12
Training loss: 0.07032495737075806
Validation loss: 1.7127469329423801

Epoch: 6| Step: 13
Training loss: 0.07862893491983414
Validation loss: 1.68987657946925

Epoch: 561| Step: 0
Training loss: 0.09524831920862198
Validation loss: 1.7056325699693413

Epoch: 6| Step: 1
Training loss: 0.08965885639190674
Validation loss: 1.722181030499038

Epoch: 6| Step: 2
Training loss: 0.07242491841316223
Validation loss: 1.7259906274016186

Epoch: 6| Step: 3
Training loss: 0.05780481547117233
Validation loss: 1.7218179190030662

Epoch: 6| Step: 4
Training loss: 0.050360169261693954
Validation loss: 1.707426030148742

Epoch: 6| Step: 5
Training loss: 0.05809316784143448
Validation loss: 1.7341472512932234

Epoch: 6| Step: 6
Training loss: 0.030294813215732574
Validation loss: 1.6966403376671575

Epoch: 6| Step: 7
Training loss: 0.1213090792298317
Validation loss: 1.7436758959165184

Epoch: 6| Step: 8
Training loss: 0.127835214138031
Validation loss: 1.7080488204956055

Epoch: 6| Step: 9
Training loss: 0.10988663136959076
Validation loss: 1.7004786973358483

Epoch: 6| Step: 10
Training loss: 0.07487288117408752
Validation loss: 1.6762473006402292

Epoch: 6| Step: 11
Training loss: 0.1335536241531372
Validation loss: 1.664259720874089

Epoch: 6| Step: 12
Training loss: 0.09010094404220581
Validation loss: 1.671246502989082

Epoch: 6| Step: 13
Training loss: 0.08618983626365662
Validation loss: 1.6666453064128917

Epoch: 562| Step: 0
Training loss: 0.06631644070148468
Validation loss: 1.6625468743744718

Epoch: 6| Step: 1
Training loss: 0.09521353244781494
Validation loss: 1.6786146638213948

Epoch: 6| Step: 2
Training loss: 0.06284822523593903
Validation loss: 1.6684987166876435

Epoch: 6| Step: 3
Training loss: 0.1190626472234726
Validation loss: 1.6808099772340508

Epoch: 6| Step: 4
Training loss: 0.09953062981367111
Validation loss: 1.7037944396336873

Epoch: 6| Step: 5
Training loss: 0.10541808605194092
Validation loss: 1.6878683720865557

Epoch: 6| Step: 6
Training loss: 0.09238079935312271
Validation loss: 1.6872934654194822

Epoch: 6| Step: 7
Training loss: 0.09254875779151917
Validation loss: 1.6928088434280888

Epoch: 6| Step: 8
Training loss: 0.07303706556558609
Validation loss: 1.6952880633774625

Epoch: 6| Step: 9
Training loss: 0.0702219232916832
Validation loss: 1.6957880040650726

Epoch: 6| Step: 10
Training loss: 0.0986965000629425
Validation loss: 1.6691390570773874

Epoch: 6| Step: 11
Training loss: 0.05228204280138016
Validation loss: 1.6603419127002839

Epoch: 6| Step: 12
Training loss: 0.08664250373840332
Validation loss: 1.6763930359194357

Epoch: 6| Step: 13
Training loss: 0.052187271416187286
Validation loss: 1.6596046801536315

Epoch: 563| Step: 0
Training loss: 0.056961789727211
Validation loss: 1.7047363212031703

Epoch: 6| Step: 1
Training loss: 0.0742664784193039
Validation loss: 1.7213498661595006

Epoch: 6| Step: 2
Training loss: 0.08788559585809708
Validation loss: 1.704280008551895

Epoch: 6| Step: 3
Training loss: 0.10849723219871521
Validation loss: 1.7235200379484443

Epoch: 6| Step: 4
Training loss: 0.08602526783943176
Validation loss: 1.6947161600153933

Epoch: 6| Step: 5
Training loss: 0.10657337307929993
Validation loss: 1.6878061845738401

Epoch: 6| Step: 6
Training loss: 0.0837518721818924
Validation loss: 1.6723559729514583

Epoch: 6| Step: 7
Training loss: 0.056063003838062286
Validation loss: 1.6475445980666785

Epoch: 6| Step: 8
Training loss: 0.0471838116645813
Validation loss: 1.6688347003793205

Epoch: 6| Step: 9
Training loss: 0.0966968834400177
Validation loss: 1.6127245451814385

Epoch: 6| Step: 10
Training loss: 0.07109629362821579
Validation loss: 1.617563332280805

Epoch: 6| Step: 11
Training loss: 0.07829615473747253
Validation loss: 1.6327131281616867

Epoch: 6| Step: 12
Training loss: 0.10249390453100204
Validation loss: 1.6477716917632728

Epoch: 6| Step: 13
Training loss: 0.07652342319488525
Validation loss: 1.619671375841223

Epoch: 564| Step: 0
Training loss: 0.07967251539230347
Validation loss: 1.6339827199136057

Epoch: 6| Step: 1
Training loss: 0.04602561891078949
Validation loss: 1.6423653018090032

Epoch: 6| Step: 2
Training loss: 0.10511700809001923
Validation loss: 1.6402884093664025

Epoch: 6| Step: 3
Training loss: 0.09130187332630157
Validation loss: 1.6299416134434361

Epoch: 6| Step: 4
Training loss: 0.05453283339738846
Validation loss: 1.6512295225615143

Epoch: 6| Step: 5
Training loss: 0.04872599244117737
Validation loss: 1.6494569265714256

Epoch: 6| Step: 6
Training loss: 0.09064032137393951
Validation loss: 1.6642869531467397

Epoch: 6| Step: 7
Training loss: 0.07453493773937225
Validation loss: 1.6661540282669889

Epoch: 6| Step: 8
Training loss: 0.04309876263141632
Validation loss: 1.6780930719067972

Epoch: 6| Step: 9
Training loss: 0.05763370543718338
Validation loss: 1.6961212901658909

Epoch: 6| Step: 10
Training loss: 0.05634533613920212
Validation loss: 1.657919858091621

Epoch: 6| Step: 11
Training loss: 0.077364981174469
Validation loss: 1.7104044011844102

Epoch: 6| Step: 12
Training loss: 0.0840514749288559
Validation loss: 1.6811359723409016

Epoch: 6| Step: 13
Training loss: 0.07114091515541077
Validation loss: 1.686705530330699

Epoch: 565| Step: 0
Training loss: 0.06510769575834274
Validation loss: 1.6925349953354045

Epoch: 6| Step: 1
Training loss: 0.09892009198665619
Validation loss: 1.7106687048430085

Epoch: 6| Step: 2
Training loss: 0.11104864627122879
Validation loss: 1.7205290499553885

Epoch: 6| Step: 3
Training loss: 0.0612015500664711
Validation loss: 1.6954158685540641

Epoch: 6| Step: 4
Training loss: 0.0393502376973629
Validation loss: 1.7049919648837017

Epoch: 6| Step: 5
Training loss: 0.05652102455496788
Validation loss: 1.7162514014910626

Epoch: 6| Step: 6
Training loss: 0.05987877398729324
Validation loss: 1.7296544274976176

Epoch: 6| Step: 7
Training loss: 0.05910429358482361
Validation loss: 1.6983700747131019

Epoch: 6| Step: 8
Training loss: 0.0657271072268486
Validation loss: 1.669807203354374

Epoch: 6| Step: 9
Training loss: 0.0764312893152237
Validation loss: 1.6728885596798313

Epoch: 6| Step: 10
Training loss: 0.06918606162071228
Validation loss: 1.6773318847020466

Epoch: 6| Step: 11
Training loss: 0.05235975235700607
Validation loss: 1.6857486796635452

Epoch: 6| Step: 12
Training loss: 0.08603263646364212
Validation loss: 1.6820193183037542

Epoch: 6| Step: 13
Training loss: 0.058032963424921036
Validation loss: 1.688993550116016

Epoch: 566| Step: 0
Training loss: 0.07067188620567322
Validation loss: 1.6822492755869383

Epoch: 6| Step: 1
Training loss: 0.07285195589065552
Validation loss: 1.6699098105071692

Epoch: 6| Step: 2
Training loss: 0.08773086965084076
Validation loss: 1.6432413760051932

Epoch: 6| Step: 3
Training loss: 0.07480356842279434
Validation loss: 1.6330078160890968

Epoch: 6| Step: 4
Training loss: 0.0338749885559082
Validation loss: 1.672423408877465

Epoch: 6| Step: 5
Training loss: 0.049311790615320206
Validation loss: 1.6631187918365642

Epoch: 6| Step: 6
Training loss: 0.045989908277988434
Validation loss: 1.65449454322938

Epoch: 6| Step: 7
Training loss: 0.07426072657108307
Validation loss: 1.6619113132517824

Epoch: 6| Step: 8
Training loss: 0.04402966797351837
Validation loss: 1.6372956716886131

Epoch: 6| Step: 9
Training loss: 0.11302277445793152
Validation loss: 1.6790273971455072

Epoch: 6| Step: 10
Training loss: 0.07958813011646271
Validation loss: 1.6752910396104217

Epoch: 6| Step: 11
Training loss: 0.06187102943658829
Validation loss: 1.671285621581539

Epoch: 6| Step: 12
Training loss: 0.057139843702316284
Validation loss: 1.6889820675696097

Epoch: 6| Step: 13
Training loss: 0.06588122993707657
Validation loss: 1.6801203989213513

Epoch: 567| Step: 0
Training loss: 0.09717364609241486
Validation loss: 1.6554721914311892

Epoch: 6| Step: 1
Training loss: 0.07764298468828201
Validation loss: 1.6653843707935785

Epoch: 6| Step: 2
Training loss: 0.07630850374698639
Validation loss: 1.6706945127056492

Epoch: 6| Step: 3
Training loss: 0.09669272601604462
Validation loss: 1.6558400161804692

Epoch: 6| Step: 4
Training loss: 0.06034931540489197
Validation loss: 1.6703917236738308

Epoch: 6| Step: 5
Training loss: 0.06754196435213089
Validation loss: 1.6971374737319125

Epoch: 6| Step: 6
Training loss: 0.06346402317285538
Validation loss: 1.7097538991640973

Epoch: 6| Step: 7
Training loss: 0.13207875192165375
Validation loss: 1.6767438688585836

Epoch: 6| Step: 8
Training loss: 0.07337915897369385
Validation loss: 1.7165950062454387

Epoch: 6| Step: 9
Training loss: 0.06889744102954865
Validation loss: 1.6991069291227607

Epoch: 6| Step: 10
Training loss: 0.06566882878541946
Validation loss: 1.689486135718643

Epoch: 6| Step: 11
Training loss: 0.07936151325702667
Validation loss: 1.686053474744161

Epoch: 6| Step: 12
Training loss: 0.06319046020507812
Validation loss: 1.698329540991014

Epoch: 6| Step: 13
Training loss: 0.09452665597200394
Validation loss: 1.6958623419525802

Epoch: 568| Step: 0
Training loss: 0.07324450463056564
Validation loss: 1.6649581104196527

Epoch: 6| Step: 1
Training loss: 0.08492971956729889
Validation loss: 1.6420300577276497

Epoch: 6| Step: 2
Training loss: 0.06319199502468109
Validation loss: 1.6331004276070544

Epoch: 6| Step: 3
Training loss: 0.11839164048433304
Validation loss: 1.6204980445164505

Epoch: 6| Step: 4
Training loss: 0.07773569971323013
Validation loss: 1.6264892957543815

Epoch: 6| Step: 5
Training loss: 0.1954638957977295
Validation loss: 1.6155237549094743

Epoch: 6| Step: 6
Training loss: 0.09574875235557556
Validation loss: 1.6256975409805134

Epoch: 6| Step: 7
Training loss: 0.10740306973457336
Validation loss: 1.6566505919220627

Epoch: 6| Step: 8
Training loss: 0.05472509190440178
Validation loss: 1.6297628187364148

Epoch: 6| Step: 9
Training loss: 0.05933104455471039
Validation loss: 1.6847738322391306

Epoch: 6| Step: 10
Training loss: 0.0829714834690094
Validation loss: 1.6937696421018211

Epoch: 6| Step: 11
Training loss: 0.09168538451194763
Validation loss: 1.7427796753503944

Epoch: 6| Step: 12
Training loss: 0.1311931312084198
Validation loss: 1.7610478657548145

Epoch: 6| Step: 13
Training loss: 0.0462123304605484
Validation loss: 1.7574992269598029

Epoch: 569| Step: 0
Training loss: 0.058448344469070435
Validation loss: 1.74137827016974

Epoch: 6| Step: 1
Training loss: 0.07011301070451736
Validation loss: 1.7328155912378782

Epoch: 6| Step: 2
Training loss: 0.07100728899240494
Validation loss: 1.715363944089541

Epoch: 6| Step: 3
Training loss: 0.05610760673880577
Validation loss: 1.683187484741211

Epoch: 6| Step: 4
Training loss: 0.10137806832790375
Validation loss: 1.6630974610646565

Epoch: 6| Step: 5
Training loss: 0.08773242682218552
Validation loss: 1.6423607154559063

Epoch: 6| Step: 6
Training loss: 0.07969866693019867
Validation loss: 1.6238785456585627

Epoch: 6| Step: 7
Training loss: 0.12208569049835205
Validation loss: 1.6197561858802714

Epoch: 6| Step: 8
Training loss: 0.08130437880754471
Validation loss: 1.6547777037466727

Epoch: 6| Step: 9
Training loss: 0.07111051678657532
Validation loss: 1.6129432057821622

Epoch: 6| Step: 10
Training loss: 0.08181288838386536
Validation loss: 1.5972164792399253

Epoch: 6| Step: 11
Training loss: 0.08027275651693344
Validation loss: 1.6142734378896735

Epoch: 6| Step: 12
Training loss: 0.07827867567539215
Validation loss: 1.6232857204252673

Epoch: 6| Step: 13
Training loss: 0.04759599268436432
Validation loss: 1.6131832817549348

Epoch: 570| Step: 0
Training loss: 0.09785044938325882
Validation loss: 1.613598749201785

Epoch: 6| Step: 1
Training loss: 0.07410052418708801
Validation loss: 1.5939599749862507

Epoch: 6| Step: 2
Training loss: 0.10976694524288177
Validation loss: 1.6004395625924552

Epoch: 6| Step: 3
Training loss: 0.07250635325908661
Validation loss: 1.6023757175732685

Epoch: 6| Step: 4
Training loss: 0.09577089548110962
Validation loss: 1.6102004781846078

Epoch: 6| Step: 5
Training loss: 0.09584814310073853
Validation loss: 1.6003253306111982

Epoch: 6| Step: 6
Training loss: 0.06557251513004303
Validation loss: 1.592260314572242

Epoch: 6| Step: 7
Training loss: 0.08341768383979797
Validation loss: 1.592763098337317

Epoch: 6| Step: 8
Training loss: 0.09689779579639435
Validation loss: 1.591745671405587

Epoch: 6| Step: 9
Training loss: 0.05410759523510933
Validation loss: 1.622530028384219

Epoch: 6| Step: 10
Training loss: 0.06783878803253174
Validation loss: 1.6290315325542162

Epoch: 6| Step: 11
Training loss: 0.08272342383861542
Validation loss: 1.6144387440014911

Epoch: 6| Step: 12
Training loss: 0.05712825059890747
Validation loss: 1.6423693241611603

Epoch: 6| Step: 13
Training loss: 0.07859638333320618
Validation loss: 1.6530215124930105

Epoch: 571| Step: 0
Training loss: 0.08438120782375336
Validation loss: 1.654046501523705

Epoch: 6| Step: 1
Training loss: 0.06920717656612396
Validation loss: 1.665867450416729

Epoch: 6| Step: 2
Training loss: 0.06673554331064224
Validation loss: 1.6376210707490162

Epoch: 6| Step: 3
Training loss: 0.04661327973008156
Validation loss: 1.6480015811099802

Epoch: 6| Step: 4
Training loss: 0.05381549149751663
Validation loss: 1.6605219802548807

Epoch: 6| Step: 5
Training loss: 0.08859027177095413
Validation loss: 1.6475785714323803

Epoch: 6| Step: 6
Training loss: 0.07376375049352646
Validation loss: 1.6595672676640172

Epoch: 6| Step: 7
Training loss: 0.1045391857624054
Validation loss: 1.6242219517307896

Epoch: 6| Step: 8
Training loss: 0.06337977945804596
Validation loss: 1.7076780014140631

Epoch: 6| Step: 9
Training loss: 0.06541343033313751
Validation loss: 1.6613693416759532

Epoch: 6| Step: 10
Training loss: 0.06786362081766129
Validation loss: 1.6908691749777844

Epoch: 6| Step: 11
Training loss: 0.053441859781742096
Validation loss: 1.686263148502637

Epoch: 6| Step: 12
Training loss: 0.04995284974575043
Validation loss: 1.7053694955764278

Epoch: 6| Step: 13
Training loss: 0.060637909919023514
Validation loss: 1.6907980704820285

Epoch: 572| Step: 0
Training loss: 0.06431707739830017
Validation loss: 1.6652419323562293

Epoch: 6| Step: 1
Training loss: 0.06152726709842682
Validation loss: 1.677347957447011

Epoch: 6| Step: 2
Training loss: 0.057509295642375946
Validation loss: 1.7094542839193856

Epoch: 6| Step: 3
Training loss: 0.0975145548582077
Validation loss: 1.6943068491515292

Epoch: 6| Step: 4
Training loss: 0.04766739159822464
Validation loss: 1.6991874716615165

Epoch: 6| Step: 5
Training loss: 0.07734881341457367
Validation loss: 1.6958658695220947

Epoch: 6| Step: 6
Training loss: 0.05708424746990204
Validation loss: 1.6811712454724055

Epoch: 6| Step: 7
Training loss: 0.07342445850372314
Validation loss: 1.6891869716746832

Epoch: 6| Step: 8
Training loss: 0.17961019277572632
Validation loss: 1.694465998680361

Epoch: 6| Step: 9
Training loss: 0.03932025283575058
Validation loss: 1.6997508156684138

Epoch: 6| Step: 10
Training loss: 0.09761514514684677
Validation loss: 1.7045887170299407

Epoch: 6| Step: 11
Training loss: 0.058639802038669586
Validation loss: 1.7265489280864756

Epoch: 6| Step: 12
Training loss: 0.04924779757857323
Validation loss: 1.7280656906866259

Epoch: 6| Step: 13
Training loss: 0.12465082108974457
Validation loss: 1.721676465003721

Epoch: 573| Step: 0
Training loss: 0.11031736433506012
Validation loss: 1.6927448549578268

Epoch: 6| Step: 1
Training loss: 0.06586916744709015
Validation loss: 1.7251450592471707

Epoch: 6| Step: 2
Training loss: 0.04300011694431305
Validation loss: 1.70493890969984

Epoch: 6| Step: 3
Training loss: 0.05946408212184906
Validation loss: 1.698655733498194

Epoch: 6| Step: 4
Training loss: 0.05793025344610214
Validation loss: 1.689066344691861

Epoch: 6| Step: 5
Training loss: 0.059908926486968994
Validation loss: 1.6772242592227073

Epoch: 6| Step: 6
Training loss: 0.05391616374254227
Validation loss: 1.6743247983276204

Epoch: 6| Step: 7
Training loss: 0.06493622064590454
Validation loss: 1.6676813505029167

Epoch: 6| Step: 8
Training loss: 0.11228261888027191
Validation loss: 1.6514916804529005

Epoch: 6| Step: 9
Training loss: 0.04176662862300873
Validation loss: 1.6529024647128197

Epoch: 6| Step: 10
Training loss: 0.08307095617055893
Validation loss: 1.6729140409859278

Epoch: 6| Step: 11
Training loss: 0.07094806432723999
Validation loss: 1.670172816963606

Epoch: 6| Step: 12
Training loss: 0.08113586902618408
Validation loss: 1.6496495751924412

Epoch: 6| Step: 13
Training loss: 0.08431699872016907
Validation loss: 1.672572192325387

Epoch: 574| Step: 0
Training loss: 0.06690585613250732
Validation loss: 1.672634038873898

Epoch: 6| Step: 1
Training loss: 0.06288670748472214
Validation loss: 1.657170291869871

Epoch: 6| Step: 2
Training loss: 0.05695486068725586
Validation loss: 1.6909880779122795

Epoch: 6| Step: 3
Training loss: 0.10205554962158203
Validation loss: 1.6948929217553907

Epoch: 6| Step: 4
Training loss: 0.053802698850631714
Validation loss: 1.7198633468279274

Epoch: 6| Step: 5
Training loss: 0.047100264579057693
Validation loss: 1.7116784600801365

Epoch: 6| Step: 6
Training loss: 0.051540955901145935
Validation loss: 1.6999597446892851

Epoch: 6| Step: 7
Training loss: 0.087795689702034
Validation loss: 1.7080927074596446

Epoch: 6| Step: 8
Training loss: 0.057865746319293976
Validation loss: 1.6996473766142322

Epoch: 6| Step: 9
Training loss: 0.09233079850673676
Validation loss: 1.7043993011597665

Epoch: 6| Step: 10
Training loss: 0.0519406720995903
Validation loss: 1.6861296046164729

Epoch: 6| Step: 11
Training loss: 0.10442940145730972
Validation loss: 1.6912737533610354

Epoch: 6| Step: 12
Training loss: 0.05547456443309784
Validation loss: 1.6852014154516242

Epoch: 6| Step: 13
Training loss: 0.046412453055381775
Validation loss: 1.690023895232908

Epoch: 575| Step: 0
Training loss: 0.05314091593027115
Validation loss: 1.6804105504866569

Epoch: 6| Step: 1
Training loss: 0.05438762158155441
Validation loss: 1.709469561935753

Epoch: 6| Step: 2
Training loss: 0.05692349374294281
Validation loss: 1.7118311261618009

Epoch: 6| Step: 3
Training loss: 0.04664641618728638
Validation loss: 1.680127852706499

Epoch: 6| Step: 4
Training loss: 0.07100261002779007
Validation loss: 1.6945636118611982

Epoch: 6| Step: 5
Training loss: 0.10273480415344238
Validation loss: 1.7097989974483367

Epoch: 6| Step: 6
Training loss: 0.08959189057350159
Validation loss: 1.7346314909637615

Epoch: 6| Step: 7
Training loss: 0.056046225130558014
Validation loss: 1.6948479478077223

Epoch: 6| Step: 8
Training loss: 0.07588610053062439
Validation loss: 1.696245975391839

Epoch: 6| Step: 9
Training loss: 0.06684841215610504
Validation loss: 1.6909603329115017

Epoch: 6| Step: 10
Training loss: 0.09099605679512024
Validation loss: 1.7061415333901682

Epoch: 6| Step: 11
Training loss: 0.10212048888206482
Validation loss: 1.6911609403548702

Epoch: 6| Step: 12
Training loss: 0.08126774430274963
Validation loss: 1.6866551189012424

Epoch: 6| Step: 13
Training loss: 0.09490619599819183
Validation loss: 1.7102821924353158

Epoch: 576| Step: 0
Training loss: 0.07633594423532486
Validation loss: 1.6926842947160043

Epoch: 6| Step: 1
Training loss: 0.05580122396349907
Validation loss: 1.7135643164316814

Epoch: 6| Step: 2
Training loss: 0.06891568750143051
Validation loss: 1.70965955334325

Epoch: 6| Step: 3
Training loss: 0.04441000521183014
Validation loss: 1.704792042252838

Epoch: 6| Step: 4
Training loss: 0.05184517800807953
Validation loss: 1.7015501773485573

Epoch: 6| Step: 5
Training loss: 0.08283179253339767
Validation loss: 1.6914900759214997

Epoch: 6| Step: 6
Training loss: 0.10644801706075668
Validation loss: 1.6909198273894608

Epoch: 6| Step: 7
Training loss: 0.05208193510770798
Validation loss: 1.7089470253195813

Epoch: 6| Step: 8
Training loss: 0.04376727342605591
Validation loss: 1.6577613943366594

Epoch: 6| Step: 9
Training loss: 0.11789995431900024
Validation loss: 1.6991762089472946

Epoch: 6| Step: 10
Training loss: 0.06978751718997955
Validation loss: 1.684730267011991

Epoch: 6| Step: 11
Training loss: 0.06943582743406296
Validation loss: 1.6613229243986067

Epoch: 6| Step: 12
Training loss: 0.07810700684785843
Validation loss: 1.6643951208360734

Epoch: 6| Step: 13
Training loss: 0.06888768821954727
Validation loss: 1.6678056511827695

Epoch: 577| Step: 0
Training loss: 0.06404657661914825
Validation loss: 1.6573809500663512

Epoch: 6| Step: 1
Training loss: 0.056058645248413086
Validation loss: 1.686077937003105

Epoch: 6| Step: 2
Training loss: 0.077066570520401
Validation loss: 1.6863443646379697

Epoch: 6| Step: 3
Training loss: 0.09952057898044586
Validation loss: 1.6971185297094367

Epoch: 6| Step: 4
Training loss: 0.07117187231779099
Validation loss: 1.7102638611229517

Epoch: 6| Step: 5
Training loss: 0.06499305367469788
Validation loss: 1.6967190427164878

Epoch: 6| Step: 6
Training loss: 0.06391695886850357
Validation loss: 1.6844947286831435

Epoch: 6| Step: 7
Training loss: 0.06641995161771774
Validation loss: 1.7009504200309835

Epoch: 6| Step: 8
Training loss: 0.048514224588871
Validation loss: 1.68988710834134

Epoch: 6| Step: 9
Training loss: 0.07209175825119019
Validation loss: 1.7125194252178233

Epoch: 6| Step: 10
Training loss: 0.10575985908508301
Validation loss: 1.697516551581762

Epoch: 6| Step: 11
Training loss: 0.049918755888938904
Validation loss: 1.6884713736913537

Epoch: 6| Step: 12
Training loss: 0.08928877115249634
Validation loss: 1.698809185335713

Epoch: 6| Step: 13
Training loss: 0.11332215368747711
Validation loss: 1.699324833449497

Epoch: 578| Step: 0
Training loss: 0.05870131403207779
Validation loss: 1.6854370082578352

Epoch: 6| Step: 1
Training loss: 0.06023883819580078
Validation loss: 1.7389323275576356

Epoch: 6| Step: 2
Training loss: 0.10117007791996002
Validation loss: 1.7220357156568957

Epoch: 6| Step: 3
Training loss: 0.03548097610473633
Validation loss: 1.718991885903061

Epoch: 6| Step: 4
Training loss: 0.07516178488731384
Validation loss: 1.7068439119605607

Epoch: 6| Step: 5
Training loss: 0.059643376618623734
Validation loss: 1.7068127188631284

Epoch: 6| Step: 6
Training loss: 0.04942953586578369
Validation loss: 1.6681713506739626

Epoch: 6| Step: 7
Training loss: 0.06836600601673126
Validation loss: 1.6843745041919012

Epoch: 6| Step: 8
Training loss: 0.07297603785991669
Validation loss: 1.6685286260420276

Epoch: 6| Step: 9
Training loss: 0.09065540134906769
Validation loss: 1.6781798960060201

Epoch: 6| Step: 10
Training loss: 0.06661127507686615
Validation loss: 1.6860474988978396

Epoch: 6| Step: 11
Training loss: 0.07110615074634552
Validation loss: 1.655261379416271

Epoch: 6| Step: 12
Training loss: 0.06913350522518158
Validation loss: 1.67402349364373

Epoch: 6| Step: 13
Training loss: 0.03884054347872734
Validation loss: 1.6422954092743576

Epoch: 579| Step: 0
Training loss: 0.056491635739803314
Validation loss: 1.643915068718695

Epoch: 6| Step: 1
Training loss: 0.06149817258119583
Validation loss: 1.6478117294208978

Epoch: 6| Step: 2
Training loss: 0.07106785476207733
Validation loss: 1.6668419376496346

Epoch: 6| Step: 3
Training loss: 0.048446156084537506
Validation loss: 1.6624783751785115

Epoch: 6| Step: 4
Training loss: 0.05163341760635376
Validation loss: 1.6481699930724276

Epoch: 6| Step: 5
Training loss: 0.0558643564581871
Validation loss: 1.6651757551777748

Epoch: 6| Step: 6
Training loss: 0.09707360714673996
Validation loss: 1.6308881877571024

Epoch: 6| Step: 7
Training loss: 0.04140573740005493
Validation loss: 1.6401464426389305

Epoch: 6| Step: 8
Training loss: 0.0352015346288681
Validation loss: 1.6525137693651262

Epoch: 6| Step: 9
Training loss: 0.055885858833789825
Validation loss: 1.6573834085977206

Epoch: 6| Step: 10
Training loss: 0.0651126354932785
Validation loss: 1.6932697642234065

Epoch: 6| Step: 11
Training loss: 0.07281315326690674
Validation loss: 1.6682408445624894

Epoch: 6| Step: 12
Training loss: 0.0647927075624466
Validation loss: 1.667604043919553

Epoch: 6| Step: 13
Training loss: 0.052278175950050354
Validation loss: 1.6870489210210822

Epoch: 580| Step: 0
Training loss: 0.09329621493816376
Validation loss: 1.6797102587197417

Epoch: 6| Step: 1
Training loss: 0.0683910995721817
Validation loss: 1.687192834833617

Epoch: 6| Step: 2
Training loss: 0.06697873771190643
Validation loss: 1.6532108078720749

Epoch: 6| Step: 3
Training loss: 0.0750356912612915
Validation loss: 1.6788957606079757

Epoch: 6| Step: 4
Training loss: 0.0970388650894165
Validation loss: 1.658939964027815

Epoch: 6| Step: 5
Training loss: 0.10979197919368744
Validation loss: 1.6882054741664598

Epoch: 6| Step: 6
Training loss: 0.0963226854801178
Validation loss: 1.7015290350042365

Epoch: 6| Step: 7
Training loss: 0.0884057804942131
Validation loss: 1.7035101767509215

Epoch: 6| Step: 8
Training loss: 0.06799313426017761
Validation loss: 1.6938717570356143

Epoch: 6| Step: 9
Training loss: 0.0961984321475029
Validation loss: 1.7247083046103036

Epoch: 6| Step: 10
Training loss: 0.06028946861624718
Validation loss: 1.7046757218658284

Epoch: 6| Step: 11
Training loss: 0.13148830831050873
Validation loss: 1.7344926980233961

Epoch: 6| Step: 12
Training loss: 0.07502191513776779
Validation loss: 1.696144292431493

Epoch: 6| Step: 13
Training loss: 0.05574040859937668
Validation loss: 1.6485788187673014

Epoch: 581| Step: 0
Training loss: 0.03618156537413597
Validation loss: 1.6650109803804787

Epoch: 6| Step: 1
Training loss: 0.05344100296497345
Validation loss: 1.655615798888668

Epoch: 6| Step: 2
Training loss: 0.1549689620733261
Validation loss: 1.6524914836370816

Epoch: 6| Step: 3
Training loss: 0.08095325529575348
Validation loss: 1.64717577093391

Epoch: 6| Step: 4
Training loss: 0.07724344730377197
Validation loss: 1.6417183786310174

Epoch: 6| Step: 5
Training loss: 0.047898903489112854
Validation loss: 1.661426628789594

Epoch: 6| Step: 6
Training loss: 0.06864875555038452
Validation loss: 1.636398539748243

Epoch: 6| Step: 7
Training loss: 0.08694964647293091
Validation loss: 1.63333333564061

Epoch: 6| Step: 8
Training loss: 0.06816289573907852
Validation loss: 1.671133146491102

Epoch: 6| Step: 9
Training loss: 0.05860922485589981
Validation loss: 1.6463332573572795

Epoch: 6| Step: 10
Training loss: 0.06409861147403717
Validation loss: 1.6470932345236502

Epoch: 6| Step: 11
Training loss: 0.0761706680059433
Validation loss: 1.6597591446292015

Epoch: 6| Step: 12
Training loss: 0.09487590938806534
Validation loss: 1.6473514969630907

Epoch: 6| Step: 13
Training loss: 0.15890586376190186
Validation loss: 1.634827644594254

Epoch: 582| Step: 0
Training loss: 0.09570462256669998
Validation loss: 1.6409855863099456

Epoch: 6| Step: 1
Training loss: 0.04072287306189537
Validation loss: 1.641689053145788

Epoch: 6| Step: 2
Training loss: 0.06962674856185913
Validation loss: 1.6461697925803482

Epoch: 6| Step: 3
Training loss: 0.10767307877540588
Validation loss: 1.634500781695048

Epoch: 6| Step: 4
Training loss: 0.12566831707954407
Validation loss: 1.6526804406155822

Epoch: 6| Step: 5
Training loss: 0.11492827534675598
Validation loss: 1.6475293533776396

Epoch: 6| Step: 6
Training loss: 0.041620489209890366
Validation loss: 1.6884200265330653

Epoch: 6| Step: 7
Training loss: 0.06122679263353348
Validation loss: 1.6397613658699939

Epoch: 6| Step: 8
Training loss: 0.10207603126764297
Validation loss: 1.6775070454484673

Epoch: 6| Step: 9
Training loss: 0.059501126408576965
Validation loss: 1.6631072362263997

Epoch: 6| Step: 10
Training loss: 0.0720829963684082
Validation loss: 1.6609606358312792

Epoch: 6| Step: 11
Training loss: 0.0673154816031456
Validation loss: 1.6710059796610186

Epoch: 6| Step: 12
Training loss: 0.07736284285783768
Validation loss: 1.694493834690381

Epoch: 6| Step: 13
Training loss: 0.05739356577396393
Validation loss: 1.6659846690393263

Epoch: 583| Step: 0
Training loss: 0.09134511649608612
Validation loss: 1.6672485502817298

Epoch: 6| Step: 1
Training loss: 0.05573663115501404
Validation loss: 1.6579606930414836

Epoch: 6| Step: 2
Training loss: 0.05540291219949722
Validation loss: 1.6489811533240861

Epoch: 6| Step: 3
Training loss: 0.044417768716812134
Validation loss: 1.6356611892741213

Epoch: 6| Step: 4
Training loss: 0.12343107163906097
Validation loss: 1.6095284582466207

Epoch: 6| Step: 5
Training loss: 0.09673687815666199
Validation loss: 1.638176243792298

Epoch: 6| Step: 6
Training loss: 0.057194117456674576
Validation loss: 1.6273762654232722

Epoch: 6| Step: 7
Training loss: 0.06507674604654312
Validation loss: 1.632357552487363

Epoch: 6| Step: 8
Training loss: 0.054475121200084686
Validation loss: 1.6311949562000971

Epoch: 6| Step: 9
Training loss: 0.08305121958255768
Validation loss: 1.6299048841640513

Epoch: 6| Step: 10
Training loss: 0.06307502090930939
Validation loss: 1.6158212231051536

Epoch: 6| Step: 11
Training loss: 0.06394052505493164
Validation loss: 1.6174306920779649

Epoch: 6| Step: 12
Training loss: 0.04074189066886902
Validation loss: 1.6143579585577852

Epoch: 6| Step: 13
Training loss: 0.15541613101959229
Validation loss: 1.6160851678540629

Epoch: 584| Step: 0
Training loss: 0.06548456847667694
Validation loss: 1.6286050965709071

Epoch: 6| Step: 1
Training loss: 0.07965777069330215
Validation loss: 1.637104457424533

Epoch: 6| Step: 2
Training loss: 0.08354752510786057
Validation loss: 1.6420873980368338

Epoch: 6| Step: 3
Training loss: 0.10717205703258514
Validation loss: 1.6065617607485863

Epoch: 6| Step: 4
Training loss: 0.04137521609663963
Validation loss: 1.6116183457836029

Epoch: 6| Step: 5
Training loss: 0.12352325022220612
Validation loss: 1.6198019648110995

Epoch: 6| Step: 6
Training loss: 0.056830890476703644
Validation loss: 1.630897351490554

Epoch: 6| Step: 7
Training loss: 0.0959242731332779
Validation loss: 1.5997400405586406

Epoch: 6| Step: 8
Training loss: 0.053064025938510895
Validation loss: 1.5844919335457586

Epoch: 6| Step: 9
Training loss: 0.054794732481241226
Validation loss: 1.600133329309443

Epoch: 6| Step: 10
Training loss: 0.06332362443208694
Validation loss: 1.6224631699182654

Epoch: 6| Step: 11
Training loss: 0.06440849602222443
Validation loss: 1.607716735973153

Epoch: 6| Step: 12
Training loss: 0.08888208866119385
Validation loss: 1.6149690907488587

Epoch: 6| Step: 13
Training loss: 0.08548232913017273
Validation loss: 1.6360950290515859

Epoch: 585| Step: 0
Training loss: 0.09239210188388824
Validation loss: 1.6077749421519618

Epoch: 6| Step: 1
Training loss: 0.07311244308948517
Validation loss: 1.6394630709002096

Epoch: 6| Step: 2
Training loss: 0.10250929743051529
Validation loss: 1.6533891770147509

Epoch: 6| Step: 3
Training loss: 0.048600535839796066
Validation loss: 1.6582877046318465

Epoch: 6| Step: 4
Training loss: 0.046206034719944
Validation loss: 1.678870415815743

Epoch: 6| Step: 5
Training loss: 0.05189110338687897
Validation loss: 1.6678003303466304

Epoch: 6| Step: 6
Training loss: 0.07465723156929016
Validation loss: 1.6622163672601022

Epoch: 6| Step: 7
Training loss: 0.12142933160066605
Validation loss: 1.6573642671749156

Epoch: 6| Step: 8
Training loss: 0.03406309336423874
Validation loss: 1.6946326263489262

Epoch: 6| Step: 9
Training loss: 0.043921567499637604
Validation loss: 1.6630485480831516

Epoch: 6| Step: 10
Training loss: 0.09484848380088806
Validation loss: 1.6763491425462949

Epoch: 6| Step: 11
Training loss: 0.10404086858034134
Validation loss: 1.690545234628903

Epoch: 6| Step: 12
Training loss: 0.11559849232435226
Validation loss: 1.6795377904368984

Epoch: 6| Step: 13
Training loss: 0.027684517204761505
Validation loss: 1.6199656468565746

Epoch: 586| Step: 0
Training loss: 0.06581781059503555
Validation loss: 1.644693786098111

Epoch: 6| Step: 1
Training loss: 0.1059945672750473
Validation loss: 1.6547350768120057

Epoch: 6| Step: 2
Training loss: 0.13061505556106567
Validation loss: 1.6562554797818583

Epoch: 6| Step: 3
Training loss: 0.09645549207925797
Validation loss: 1.6402959477516912

Epoch: 6| Step: 4
Training loss: 0.045632876455783844
Validation loss: 1.6303810355483845

Epoch: 6| Step: 5
Training loss: 0.07253587245941162
Validation loss: 1.6398371547781012

Epoch: 6| Step: 6
Training loss: 0.05161787196993828
Validation loss: 1.6460843445152364

Epoch: 6| Step: 7
Training loss: 0.08508260548114777
Validation loss: 1.6408126008126043

Epoch: 6| Step: 8
Training loss: 0.059219442307949066
Validation loss: 1.635586420694987

Epoch: 6| Step: 9
Training loss: 0.07061342149972916
Validation loss: 1.658847419164514

Epoch: 6| Step: 10
Training loss: 0.04996119439601898
Validation loss: 1.6819338426795056

Epoch: 6| Step: 11
Training loss: 0.0942796915769577
Validation loss: 1.7017013616459344

Epoch: 6| Step: 12
Training loss: 0.08903136104345322
Validation loss: 1.6608990571832145

Epoch: 6| Step: 13
Training loss: 0.10603754967451096
Validation loss: 1.6588358148451774

Epoch: 587| Step: 0
Training loss: 0.04348444193601608
Validation loss: 1.6493534298353298

Epoch: 6| Step: 1
Training loss: 0.08698828518390656
Validation loss: 1.6286494834448701

Epoch: 6| Step: 2
Training loss: 0.06472055613994598
Validation loss: 1.6286822044721214

Epoch: 6| Step: 3
Training loss: 0.047521356493234634
Validation loss: 1.5973308663214407

Epoch: 6| Step: 4
Training loss: 0.055288881063461304
Validation loss: 1.6176724638990176

Epoch: 6| Step: 5
Training loss: 0.05224259942770004
Validation loss: 1.6181555486494494

Epoch: 6| Step: 6
Training loss: 0.039421312510967255
Validation loss: 1.6177565743846278

Epoch: 6| Step: 7
Training loss: 0.05904332548379898
Validation loss: 1.6165592785804503

Epoch: 6| Step: 8
Training loss: 0.07328496873378754
Validation loss: 1.6163276216035247

Epoch: 6| Step: 9
Training loss: 0.09146745502948761
Validation loss: 1.6332059521828928

Epoch: 6| Step: 10
Training loss: 0.08679354190826416
Validation loss: 1.6354310102360223

Epoch: 6| Step: 11
Training loss: 0.08045942336320877
Validation loss: 1.5959688232791038

Epoch: 6| Step: 12
Training loss: 0.05616074055433273
Validation loss: 1.6202464975336546

Epoch: 6| Step: 13
Training loss: 0.060927849262952805
Validation loss: 1.6077867451534475

Epoch: 588| Step: 0
Training loss: 0.05526804178953171
Validation loss: 1.6121201002469627

Epoch: 6| Step: 1
Training loss: 0.0890890508890152
Validation loss: 1.6249757992324008

Epoch: 6| Step: 2
Training loss: 0.07526043802499771
Validation loss: 1.6460494123479372

Epoch: 6| Step: 3
Training loss: 0.06696207821369171
Validation loss: 1.6332536025713849

Epoch: 6| Step: 4
Training loss: 0.051019951701164246
Validation loss: 1.6277968255422448

Epoch: 6| Step: 5
Training loss: 0.05560857802629471
Validation loss: 1.657920898929719

Epoch: 6| Step: 6
Training loss: 0.07503694295883179
Validation loss: 1.6577833596096243

Epoch: 6| Step: 7
Training loss: 0.056620094925165176
Validation loss: 1.6738253562681136

Epoch: 6| Step: 8
Training loss: 0.048028796911239624
Validation loss: 1.6479792479545838

Epoch: 6| Step: 9
Training loss: 0.05565502494573593
Validation loss: 1.6784231496113602

Epoch: 6| Step: 10
Training loss: 0.039359789341688156
Validation loss: 1.6540960060652865

Epoch: 6| Step: 11
Training loss: 0.03320963680744171
Validation loss: 1.6629464908312726

Epoch: 6| Step: 12
Training loss: 0.053563669323921204
Validation loss: 1.6426545048272738

Epoch: 6| Step: 13
Training loss: 0.05578241124749184
Validation loss: 1.6744283450547086

Epoch: 589| Step: 0
Training loss: 0.05021298676729202
Validation loss: 1.6615773952135475

Epoch: 6| Step: 1
Training loss: 0.10269756615161896
Validation loss: 1.6316003626392734

Epoch: 6| Step: 2
Training loss: 0.057652514427900314
Validation loss: 1.6422780777818413

Epoch: 6| Step: 3
Training loss: 0.06975430250167847
Validation loss: 1.6606507916604318

Epoch: 6| Step: 4
Training loss: 0.03669171780347824
Validation loss: 1.6680306106485345

Epoch: 6| Step: 5
Training loss: 0.09348487108945847
Validation loss: 1.6699547178001815

Epoch: 6| Step: 6
Training loss: 0.06512078642845154
Validation loss: 1.6908823725997761

Epoch: 6| Step: 7
Training loss: 0.07104838639497757
Validation loss: 1.6826617615197295

Epoch: 6| Step: 8
Training loss: 0.06871214509010315
Validation loss: 1.668240060088455

Epoch: 6| Step: 9
Training loss: 0.056383147835731506
Validation loss: 1.6861247836902578

Epoch: 6| Step: 10
Training loss: 0.051976777613162994
Validation loss: 1.6855037699463546

Epoch: 6| Step: 11
Training loss: 0.07553109526634216
Validation loss: 1.6826072610834593

Epoch: 6| Step: 12
Training loss: 0.055309467017650604
Validation loss: 1.671753934634629

Epoch: 6| Step: 13
Training loss: 0.06294504553079605
Validation loss: 1.6881235286753664

Epoch: 590| Step: 0
Training loss: 0.059524908661842346
Validation loss: 1.685845285333613

Epoch: 6| Step: 1
Training loss: 0.06950445473194122
Validation loss: 1.6735778918830297

Epoch: 6| Step: 2
Training loss: 0.04801154509186745
Validation loss: 1.6570119896242697

Epoch: 6| Step: 3
Training loss: 0.06850834935903549
Validation loss: 1.6543889327715802

Epoch: 6| Step: 4
Training loss: 0.04511667788028717
Validation loss: 1.6806976103013562

Epoch: 6| Step: 5
Training loss: 0.046241920441389084
Validation loss: 1.680269156732867

Epoch: 6| Step: 6
Training loss: 0.07681707292795181
Validation loss: 1.6669267005817865

Epoch: 6| Step: 7
Training loss: 0.08720166981220245
Validation loss: 1.6481075658593127

Epoch: 6| Step: 8
Training loss: 0.045368656516075134
Validation loss: 1.6297422083475257

Epoch: 6| Step: 9
Training loss: 0.04403173178434372
Validation loss: 1.6027850053643669

Epoch: 6| Step: 10
Training loss: 0.06763066351413727
Validation loss: 1.6117749060353925

Epoch: 6| Step: 11
Training loss: 0.08307385444641113
Validation loss: 1.6032509496135097

Epoch: 6| Step: 12
Training loss: 0.09168139100074768
Validation loss: 1.6316861439776678

Epoch: 6| Step: 13
Training loss: 0.03989816829562187
Validation loss: 1.6350506415931128

Epoch: 591| Step: 0
Training loss: 0.0788290873169899
Validation loss: 1.6265365872331845

Epoch: 6| Step: 1
Training loss: 0.04711936414241791
Validation loss: 1.6398717241902505

Epoch: 6| Step: 2
Training loss: 0.048062317073345184
Validation loss: 1.664339264233907

Epoch: 6| Step: 3
Training loss: 0.09231385588645935
Validation loss: 1.6583303982211697

Epoch: 6| Step: 4
Training loss: 0.09839709848165512
Validation loss: 1.6483633351582352

Epoch: 6| Step: 5
Training loss: 0.03461393713951111
Validation loss: 1.6738167988356722

Epoch: 6| Step: 6
Training loss: 0.08338978886604309
Validation loss: 1.677675070301179

Epoch: 6| Step: 7
Training loss: 0.07690039277076721
Validation loss: 1.6550118769368818

Epoch: 6| Step: 8
Training loss: 0.06276442110538483
Validation loss: 1.658290078563075

Epoch: 6| Step: 9
Training loss: 0.05412166565656662
Validation loss: 1.6412443486593102

Epoch: 6| Step: 10
Training loss: 0.07346317172050476
Validation loss: 1.6643011813522668

Epoch: 6| Step: 11
Training loss: 0.07336600124835968
Validation loss: 1.621189349441118

Epoch: 6| Step: 12
Training loss: 0.07531611621379852
Validation loss: 1.6226675189951414

Epoch: 6| Step: 13
Training loss: 0.09231376647949219
Validation loss: 1.5940028339303949

Epoch: 592| Step: 0
Training loss: 0.08594772219657898
Validation loss: 1.5942474680562173

Epoch: 6| Step: 1
Training loss: 0.09825529158115387
Validation loss: 1.59725066666962

Epoch: 6| Step: 2
Training loss: 0.06586629152297974
Validation loss: 1.6376717962244505

Epoch: 6| Step: 3
Training loss: 0.051162153482437134
Validation loss: 1.5972504192782986

Epoch: 6| Step: 4
Training loss: 0.049633853137493134
Validation loss: 1.6413093254130373

Epoch: 6| Step: 5
Training loss: 0.058220185339450836
Validation loss: 1.6408663116475588

Epoch: 6| Step: 6
Training loss: 0.06803330034017563
Validation loss: 1.6346752028311453

Epoch: 6| Step: 7
Training loss: 0.04834399372339249
Validation loss: 1.6588405114348217

Epoch: 6| Step: 8
Training loss: 0.10130003094673157
Validation loss: 1.7007437034319806

Epoch: 6| Step: 9
Training loss: 0.11645741760730743
Validation loss: 1.6867088861362909

Epoch: 6| Step: 10
Training loss: 0.0855453759431839
Validation loss: 1.6863207663259199

Epoch: 6| Step: 11
Training loss: 0.08004655689001083
Validation loss: 1.675217789988364

Epoch: 6| Step: 12
Training loss: 0.07986386120319366
Validation loss: 1.661759800808404

Epoch: 6| Step: 13
Training loss: 0.039606597274541855
Validation loss: 1.6466554557123492

Epoch: 593| Step: 0
Training loss: 0.04701877757906914
Validation loss: 1.6667649707486552

Epoch: 6| Step: 1
Training loss: 0.0503653883934021
Validation loss: 1.6222848187210739

Epoch: 6| Step: 2
Training loss: 0.04096025228500366
Validation loss: 1.6548807621002197

Epoch: 6| Step: 3
Training loss: 0.07965491712093353
Validation loss: 1.6615237241150231

Epoch: 6| Step: 4
Training loss: 0.06807473301887512
Validation loss: 1.6226572605871386

Epoch: 6| Step: 5
Training loss: 0.053210705518722534
Validation loss: 1.6262487698626775

Epoch: 6| Step: 6
Training loss: 0.06458337604999542
Validation loss: 1.6252982078060028

Epoch: 6| Step: 7
Training loss: 0.06958431750535965
Validation loss: 1.6193413760072441

Epoch: 6| Step: 8
Training loss: 0.04275607317686081
Validation loss: 1.6461453873624083

Epoch: 6| Step: 9
Training loss: 0.0623260997235775
Validation loss: 1.6502975699722127

Epoch: 6| Step: 10
Training loss: 0.06414949893951416
Validation loss: 1.6417055181277695

Epoch: 6| Step: 11
Training loss: 0.04345666244626045
Validation loss: 1.6678858931346605

Epoch: 6| Step: 12
Training loss: 0.0813988447189331
Validation loss: 1.641571121831094

Epoch: 6| Step: 13
Training loss: 0.072564035654068
Validation loss: 1.648193508066157

Epoch: 594| Step: 0
Training loss: 0.06946034729480743
Validation loss: 1.6282370385303293

Epoch: 6| Step: 1
Training loss: 0.1696910560131073
Validation loss: 1.641271839859665

Epoch: 6| Step: 2
Training loss: 0.06492067128419876
Validation loss: 1.6097457511450655

Epoch: 6| Step: 3
Training loss: 0.05593153089284897
Validation loss: 1.6236071810927442

Epoch: 6| Step: 4
Training loss: 0.057527486234903336
Validation loss: 1.6112956359822264

Epoch: 6| Step: 5
Training loss: 0.09649945795536041
Validation loss: 1.607679796475236

Epoch: 6| Step: 6
Training loss: 0.04275808855891228
Validation loss: 1.620725776559563

Epoch: 6| Step: 7
Training loss: 0.07589145749807358
Validation loss: 1.6160219805214995

Epoch: 6| Step: 8
Training loss: 0.05623534321784973
Validation loss: 1.6486306164854316

Epoch: 6| Step: 9
Training loss: 0.05324527993798256
Validation loss: 1.6172622724245953

Epoch: 6| Step: 10
Training loss: 0.07419566810131073
Validation loss: 1.5922679285849295

Epoch: 6| Step: 11
Training loss: 0.07921622693538666
Validation loss: 1.5986880051192416

Epoch: 6| Step: 12
Training loss: 0.060860857367515564
Validation loss: 1.585905413473806

Epoch: 6| Step: 13
Training loss: 0.07018620520830154
Validation loss: 1.6178413129621936

Epoch: 595| Step: 0
Training loss: 0.05709930881857872
Validation loss: 1.603040313207975

Epoch: 6| Step: 1
Training loss: 0.03501018136739731
Validation loss: 1.5983307541057628

Epoch: 6| Step: 2
Training loss: 0.038356103003025055
Validation loss: 1.6050138717056603

Epoch: 6| Step: 3
Training loss: 0.10337089747190475
Validation loss: 1.599114776298564

Epoch: 6| Step: 4
Training loss: 0.04563364386558533
Validation loss: 1.6350194267047349

Epoch: 6| Step: 5
Training loss: 0.05038301274180412
Validation loss: 1.638704797273041

Epoch: 6| Step: 6
Training loss: 0.0633476972579956
Validation loss: 1.629057430451916

Epoch: 6| Step: 7
Training loss: 0.03774285316467285
Validation loss: 1.6388056752502278

Epoch: 6| Step: 8
Training loss: 0.10141244530677795
Validation loss: 1.6240959141844062

Epoch: 6| Step: 9
Training loss: 0.0628262460231781
Validation loss: 1.6392562363737373

Epoch: 6| Step: 10
Training loss: 0.04626922309398651
Validation loss: 1.6407536370779878

Epoch: 6| Step: 11
Training loss: 0.0589001439511776
Validation loss: 1.624909561167481

Epoch: 6| Step: 12
Training loss: 0.08035343140363693
Validation loss: 1.6269416437354138

Epoch: 6| Step: 13
Training loss: 0.057648666203022
Validation loss: 1.647889316722911

Epoch: 596| Step: 0
Training loss: 0.08375558257102966
Validation loss: 1.636036608808784

Epoch: 6| Step: 1
Training loss: 0.047963954508304596
Validation loss: 1.6458090889838435

Epoch: 6| Step: 2
Training loss: 0.06726516783237457
Validation loss: 1.660153894014256

Epoch: 6| Step: 3
Training loss: 0.06869633495807648
Validation loss: 1.6668994619000344

Epoch: 6| Step: 4
Training loss: 0.06886464357376099
Validation loss: 1.6846452669430805

Epoch: 6| Step: 5
Training loss: 0.1278405338525772
Validation loss: 1.650764037204045

Epoch: 6| Step: 6
Training loss: 0.04121836647391319
Validation loss: 1.6465378858709847

Epoch: 6| Step: 7
Training loss: 0.09755135327577591
Validation loss: 1.6283188058483986

Epoch: 6| Step: 8
Training loss: 0.05382835865020752
Validation loss: 1.6101675764206917

Epoch: 6| Step: 9
Training loss: 0.0690336599946022
Validation loss: 1.6053472577884633

Epoch: 6| Step: 10
Training loss: 0.06349106878042221
Validation loss: 1.618240644854884

Epoch: 6| Step: 11
Training loss: 0.06477990001440048
Validation loss: 1.627995156472729

Epoch: 6| Step: 12
Training loss: 0.06235261261463165
Validation loss: 1.6256900448952951

Epoch: 6| Step: 13
Training loss: 0.11183217912912369
Validation loss: 1.6418505458421604

Epoch: 597| Step: 0
Training loss: 0.07963944971561432
Validation loss: 1.654642460166767

Epoch: 6| Step: 1
Training loss: 0.033570386469364166
Validation loss: 1.6573766713501306

Epoch: 6| Step: 2
Training loss: 0.04390250891447067
Validation loss: 1.6653296421932917

Epoch: 6| Step: 3
Training loss: 0.054487165063619614
Validation loss: 1.6755994724970993

Epoch: 6| Step: 4
Training loss: 0.07206769287586212
Validation loss: 1.6805167172544746

Epoch: 6| Step: 5
Training loss: 0.07518887519836426
Validation loss: 1.6967208282921904

Epoch: 6| Step: 6
Training loss: 0.06289295107126236
Validation loss: 1.6729580394683345

Epoch: 6| Step: 7
Training loss: 0.07021500170230865
Validation loss: 1.6867942015329997

Epoch: 6| Step: 8
Training loss: 0.049689196050167084
Validation loss: 1.6591212326480496

Epoch: 6| Step: 9
Training loss: 0.06198786199092865
Validation loss: 1.6646802950930852

Epoch: 6| Step: 10
Training loss: 0.1000630110502243
Validation loss: 1.6450552350731307

Epoch: 6| Step: 11
Training loss: 0.07004615664482117
Validation loss: 1.653855355837012

Epoch: 6| Step: 12
Training loss: 0.07730787992477417
Validation loss: 1.6249666047352616

Epoch: 6| Step: 13
Training loss: 0.09137649834156036
Validation loss: 1.6277938683827717

Epoch: 598| Step: 0
Training loss: 0.07405632734298706
Validation loss: 1.6242883487414288

Epoch: 6| Step: 1
Training loss: 0.08684037625789642
Validation loss: 1.605375632163017

Epoch: 6| Step: 2
Training loss: 0.04708375781774521
Validation loss: 1.6181464656706779

Epoch: 6| Step: 3
Training loss: 0.09800481796264648
Validation loss: 1.6097576964286067

Epoch: 6| Step: 4
Training loss: 0.054704900830984116
Validation loss: 1.632131548338039

Epoch: 6| Step: 5
Training loss: 0.06736832112073898
Validation loss: 1.6321632772363641

Epoch: 6| Step: 6
Training loss: 0.11647752672433853
Validation loss: 1.637405058389069

Epoch: 6| Step: 7
Training loss: 0.0860832929611206
Validation loss: 1.6667259457290813

Epoch: 6| Step: 8
Training loss: 0.1016155406832695
Validation loss: 1.675628694154883

Epoch: 6| Step: 9
Training loss: 0.05538362264633179
Validation loss: 1.7153886223352084

Epoch: 6| Step: 10
Training loss: 0.11100813746452332
Validation loss: 1.7370288346403389

Epoch: 6| Step: 11
Training loss: 0.17021605372428894
Validation loss: 1.7412081444135277

Epoch: 6| Step: 12
Training loss: 0.12588295340538025
Validation loss: 1.743659730880491

Epoch: 6| Step: 13
Training loss: 0.06858588755130768
Validation loss: 1.6995719337976107

Epoch: 599| Step: 0
Training loss: 0.1326650083065033
Validation loss: 1.6839312520078433

Epoch: 6| Step: 1
Training loss: 0.07860726118087769
Validation loss: 1.646001482522616

Epoch: 6| Step: 2
Training loss: 0.09672968089580536
Validation loss: 1.6432180994300432

Epoch: 6| Step: 3
Training loss: 0.08051791787147522
Validation loss: 1.6507114902619393

Epoch: 6| Step: 4
Training loss: 0.12013071030378342
Validation loss: 1.6159118452379782

Epoch: 6| Step: 5
Training loss: 0.0756601095199585
Validation loss: 1.6078606536311488

Epoch: 6| Step: 6
Training loss: 0.11125648021697998
Validation loss: 1.6139514189894482

Epoch: 6| Step: 7
Training loss: 0.09044566750526428
Validation loss: 1.6270358818833546

Epoch: 6| Step: 8
Training loss: 0.07323075830936432
Validation loss: 1.6275736836976902

Epoch: 6| Step: 9
Training loss: 0.1126590445637703
Validation loss: 1.6317100460811327

Epoch: 6| Step: 10
Training loss: 0.07371380925178528
Validation loss: 1.6686408083925965

Epoch: 6| Step: 11
Training loss: 0.06787841022014618
Validation loss: 1.7365602088230911

Epoch: 6| Step: 12
Training loss: 0.11484260857105255
Validation loss: 1.7352837029323782

Epoch: 6| Step: 13
Training loss: 0.19276273250579834
Validation loss: 1.750106898687219

Epoch: 600| Step: 0
Training loss: 0.07584408670663834
Validation loss: 1.7222662818047307

Epoch: 6| Step: 1
Training loss: 0.0697510838508606
Validation loss: 1.6888661282036894

Epoch: 6| Step: 2
Training loss: 0.10844101756811142
Validation loss: 1.6840088072643484

Epoch: 6| Step: 3
Training loss: 0.05998712778091431
Validation loss: 1.686801759145593

Epoch: 6| Step: 4
Training loss: 0.09367001056671143
Validation loss: 1.6777259329313874

Epoch: 6| Step: 5
Training loss: 0.058340176939964294
Validation loss: 1.6785623411978445

Epoch: 6| Step: 6
Training loss: 0.06600919365882874
Validation loss: 1.6834474097016037

Epoch: 6| Step: 7
Training loss: 0.037037745118141174
Validation loss: 1.6660677579141432

Epoch: 6| Step: 8
Training loss: 0.0677664577960968
Validation loss: 1.6904252998290523

Epoch: 6| Step: 9
Training loss: 0.07624609768390656
Validation loss: 1.6826078558480868

Epoch: 6| Step: 10
Training loss: 0.11817534267902374
Validation loss: 1.6751915024172874

Epoch: 6| Step: 11
Training loss: 0.10900739580392838
Validation loss: 1.670843017998562

Epoch: 6| Step: 12
Training loss: 0.08636613190174103
Validation loss: 1.6177480547658858

Epoch: 6| Step: 13
Training loss: 0.04987509921193123
Validation loss: 1.6460560829408708

Epoch: 601| Step: 0
Training loss: 0.08870179951190948
Validation loss: 1.633561376602419

Epoch: 6| Step: 1
Training loss: 0.07437266409397125
Validation loss: 1.6560624863511773

Epoch: 6| Step: 2
Training loss: 0.10123938322067261
Validation loss: 1.6244532908162763

Epoch: 6| Step: 3
Training loss: 0.12793751060962677
Validation loss: 1.6454455032143542

Epoch: 6| Step: 4
Training loss: 0.14148575067520142
Validation loss: 1.655759411473428

Epoch: 6| Step: 5
Training loss: 0.04380644112825394
Validation loss: 1.6698351342190978

Epoch: 6| Step: 6
Training loss: 0.096612349152565
Validation loss: 1.673810266679333

Epoch: 6| Step: 7
Training loss: 0.061902835965156555
Validation loss: 1.6586672670097762

Epoch: 6| Step: 8
Training loss: 0.051832105964422226
Validation loss: 1.6468488503527898

Epoch: 6| Step: 9
Training loss: 0.07385098934173584
Validation loss: 1.6558440372508059

Epoch: 6| Step: 10
Training loss: 0.06370647996664047
Validation loss: 1.6608435543634559

Epoch: 6| Step: 11
Training loss: 0.13047029078006744
Validation loss: 1.6286591829792145

Epoch: 6| Step: 12
Training loss: 0.09032747894525528
Validation loss: 1.6480827613543438

Epoch: 6| Step: 13
Training loss: 0.09956270456314087
Validation loss: 1.619324343178862

Epoch: 602| Step: 0
Training loss: 0.055346425622701645
Validation loss: 1.6249169252252067

Epoch: 6| Step: 1
Training loss: 0.0745253711938858
Validation loss: 1.621446031396107

Epoch: 6| Step: 2
Training loss: 0.07902126759290695
Validation loss: 1.636092924302624

Epoch: 6| Step: 3
Training loss: 0.07326681911945343
Validation loss: 1.6471429024973223

Epoch: 6| Step: 4
Training loss: 0.06020559370517731
Validation loss: 1.6400825387688094

Epoch: 6| Step: 5
Training loss: 0.07345941662788391
Validation loss: 1.6526321941806423

Epoch: 6| Step: 6
Training loss: 0.042287617921829224
Validation loss: 1.6642327949564943

Epoch: 6| Step: 7
Training loss: 0.09519627690315247
Validation loss: 1.6627106487110097

Epoch: 6| Step: 8
Training loss: 0.08910714089870453
Validation loss: 1.6602966682885283

Epoch: 6| Step: 9
Training loss: 0.06312301754951477
Validation loss: 1.655495426988089

Epoch: 6| Step: 10
Training loss: 0.07074957340955734
Validation loss: 1.6792487534143592

Epoch: 6| Step: 11
Training loss: 0.09803985804319382
Validation loss: 1.667031208674113

Epoch: 6| Step: 12
Training loss: 0.06324069201946259
Validation loss: 1.6586497624715169

Epoch: 6| Step: 13
Training loss: 0.04568476229906082
Validation loss: 1.6658884402244323

Epoch: 603| Step: 0
Training loss: 0.04378596693277359
Validation loss: 1.6269016214596328

Epoch: 6| Step: 1
Training loss: 0.09966236352920532
Validation loss: 1.6482009342921677

Epoch: 6| Step: 2
Training loss: 0.09884098172187805
Validation loss: 1.6262030575865059

Epoch: 6| Step: 3
Training loss: 0.08554890006780624
Validation loss: 1.6309525223188504

Epoch: 6| Step: 4
Training loss: 0.07400405406951904
Validation loss: 1.6462480855244461

Epoch: 6| Step: 5
Training loss: 0.0832393541932106
Validation loss: 1.6297942297433012

Epoch: 6| Step: 6
Training loss: 0.11613665521144867
Validation loss: 1.648687748498814

Epoch: 6| Step: 7
Training loss: 0.08526881784200668
Validation loss: 1.669242666613671

Epoch: 6| Step: 8
Training loss: 0.11512969434261322
Validation loss: 1.6743042853570753

Epoch: 6| Step: 9
Training loss: 0.09731261432170868
Validation loss: 1.6510302815386044

Epoch: 6| Step: 10
Training loss: 0.10026074200868607
Validation loss: 1.6796610073376728

Epoch: 6| Step: 11
Training loss: 0.09319231659173965
Validation loss: 1.660277525583903

Epoch: 6| Step: 12
Training loss: 0.042651452124118805
Validation loss: 1.6627544408203454

Epoch: 6| Step: 13
Training loss: 0.04636726155877113
Validation loss: 1.62069486289896

Epoch: 604| Step: 0
Training loss: 0.07183203101158142
Validation loss: 1.6716234991627354

Epoch: 6| Step: 1
Training loss: 0.04344109073281288
Validation loss: 1.6216835257827595

Epoch: 6| Step: 2
Training loss: 0.09201132506132126
Validation loss: 1.609887840927288

Epoch: 6| Step: 3
Training loss: 0.0807306319475174
Validation loss: 1.6349986714701499

Epoch: 6| Step: 4
Training loss: 0.06893665343523026
Validation loss: 1.6452814545682681

Epoch: 6| Step: 5
Training loss: 0.08335600793361664
Validation loss: 1.615946098040509

Epoch: 6| Step: 6
Training loss: 0.07284581661224365
Validation loss: 1.6020391359124133

Epoch: 6| Step: 7
Training loss: 0.07286714017391205
Validation loss: 1.6152918787412747

Epoch: 6| Step: 8
Training loss: 0.10641895979642868
Validation loss: 1.5757502073882728

Epoch: 6| Step: 9
Training loss: 0.07329726219177246
Validation loss: 1.5831139113313408

Epoch: 6| Step: 10
Training loss: 0.05877853184938431
Validation loss: 1.5915691544932704

Epoch: 6| Step: 11
Training loss: 0.10082997381687164
Validation loss: 1.5924371198941303

Epoch: 6| Step: 12
Training loss: 0.08979552984237671
Validation loss: 1.6050579278699812

Epoch: 6| Step: 13
Training loss: 0.10385790467262268
Validation loss: 1.6171373116072787

Epoch: 605| Step: 0
Training loss: 0.07453811168670654
Validation loss: 1.614037570133004

Epoch: 6| Step: 1
Training loss: 0.1313336342573166
Validation loss: 1.6120649409550492

Epoch: 6| Step: 2
Training loss: 0.06143195554614067
Validation loss: 1.6103117312154462

Epoch: 6| Step: 3
Training loss: 0.061154961585998535
Validation loss: 1.6350968980020093

Epoch: 6| Step: 4
Training loss: 0.04789484292268753
Validation loss: 1.6637354127822384

Epoch: 6| Step: 5
Training loss: 0.08105818927288055
Validation loss: 1.6888868924110167

Epoch: 6| Step: 6
Training loss: 0.07410719990730286
Validation loss: 1.6847701893057874

Epoch: 6| Step: 7
Training loss: 0.1484335958957672
Validation loss: 1.6692611709717782

Epoch: 6| Step: 8
Training loss: 0.08360002189874649
Validation loss: 1.6518494288126628

Epoch: 6| Step: 9
Training loss: 0.07349161803722382
Validation loss: 1.6618946803513395

Epoch: 6| Step: 10
Training loss: 0.06883926689624786
Validation loss: 1.6247705195539741

Epoch: 6| Step: 11
Training loss: 0.08464391529560089
Validation loss: 1.6448199005537136

Epoch: 6| Step: 12
Training loss: 0.10731415450572968
Validation loss: 1.6560535238635155

Epoch: 6| Step: 13
Training loss: 0.09685202687978745
Validation loss: 1.639994736640684

Epoch: 606| Step: 0
Training loss: 0.09713225066661835
Validation loss: 1.665274513665066

Epoch: 6| Step: 1
Training loss: 0.10603068768978119
Validation loss: 1.659694670349039

Epoch: 6| Step: 2
Training loss: 0.09732447564601898
Validation loss: 1.6672975658088602

Epoch: 6| Step: 3
Training loss: 0.14175564050674438
Validation loss: 1.7009929546745874

Epoch: 6| Step: 4
Training loss: 0.09454123675823212
Validation loss: 1.7060458108942995

Epoch: 6| Step: 5
Training loss: 0.08830437064170837
Validation loss: 1.7230415203238045

Epoch: 6| Step: 6
Training loss: 0.0632224902510643
Validation loss: 1.7162551931155625

Epoch: 6| Step: 7
Training loss: 0.07184869050979614
Validation loss: 1.7077075435269264

Epoch: 6| Step: 8
Training loss: 0.07352283596992493
Validation loss: 1.7168136912007486

Epoch: 6| Step: 9
Training loss: 0.08687269687652588
Validation loss: 1.6637618080262215

Epoch: 6| Step: 10
Training loss: 0.05739337205886841
Validation loss: 1.6804263591766357

Epoch: 6| Step: 11
Training loss: 0.11060713231563568
Validation loss: 1.6678996368121075

Epoch: 6| Step: 12
Training loss: 0.0434299111366272
Validation loss: 1.6808847355586227

Epoch: 6| Step: 13
Training loss: 0.06104503199458122
Validation loss: 1.705646502074375

Epoch: 607| Step: 0
Training loss: 0.11296012997627258
Validation loss: 1.6839787601142802

Epoch: 6| Step: 1
Training loss: 0.0403200127184391
Validation loss: 1.696285306766469

Epoch: 6| Step: 2
Training loss: 0.06464244425296783
Validation loss: 1.697568428131842

Epoch: 6| Step: 3
Training loss: 0.06538350135087967
Validation loss: 1.7166538482071252

Epoch: 6| Step: 4
Training loss: 0.06732753664255142
Validation loss: 1.7209442777018393

Epoch: 6| Step: 5
Training loss: 0.06474140286445618
Validation loss: 1.6998959420829691

Epoch: 6| Step: 6
Training loss: 0.07469810545444489
Validation loss: 1.6967663175316268

Epoch: 6| Step: 7
Training loss: 0.06511758267879486
Validation loss: 1.678269406800629

Epoch: 6| Step: 8
Training loss: 0.05804966390132904
Validation loss: 1.6747391326453096

Epoch: 6| Step: 9
Training loss: 0.09871986508369446
Validation loss: 1.687749993416571

Epoch: 6| Step: 10
Training loss: 0.04595121368765831
Validation loss: 1.6571566597107918

Epoch: 6| Step: 11
Training loss: 0.05205346643924713
Validation loss: 1.6759958933758479

Epoch: 6| Step: 12
Training loss: 0.07385855168104172
Validation loss: 1.683540673666103

Epoch: 6| Step: 13
Training loss: 0.13464123010635376
Validation loss: 1.6533051075473908

Epoch: 608| Step: 0
Training loss: 0.06427797675132751
Validation loss: 1.676080928053907

Epoch: 6| Step: 1
Training loss: 0.09429788589477539
Validation loss: 1.6664256511196014

Epoch: 6| Step: 2
Training loss: 0.05908036231994629
Validation loss: 1.6643185525812128

Epoch: 6| Step: 3
Training loss: 0.08606430888175964
Validation loss: 1.6885502287136611

Epoch: 6| Step: 4
Training loss: 0.051431939005851746
Validation loss: 1.6857922846271145

Epoch: 6| Step: 5
Training loss: 0.09067991375923157
Validation loss: 1.7007504432432112

Epoch: 6| Step: 6
Training loss: 0.05809666961431503
Validation loss: 1.6722984852329377

Epoch: 6| Step: 7
Training loss: 0.07111653685569763
Validation loss: 1.656720648529709

Epoch: 6| Step: 8
Training loss: 0.0806824266910553
Validation loss: 1.6745116133843698

Epoch: 6| Step: 9
Training loss: 0.1096409261226654
Validation loss: 1.6650699280923413

Epoch: 6| Step: 10
Training loss: 0.12002436816692352
Validation loss: 1.6591437068036807

Epoch: 6| Step: 11
Training loss: 0.0720185711979866
Validation loss: 1.6315800425826863

Epoch: 6| Step: 12
Training loss: 0.07193371653556824
Validation loss: 1.6340033213297527

Epoch: 6| Step: 13
Training loss: 0.10287652909755707
Validation loss: 1.6378751557360414

Epoch: 609| Step: 0
Training loss: 0.07108771800994873
Validation loss: 1.6673946316524217

Epoch: 6| Step: 1
Training loss: 0.08345711976289749
Validation loss: 1.690459382149481

Epoch: 6| Step: 2
Training loss: 0.06374508887529373
Validation loss: 1.6640815145225936

Epoch: 6| Step: 3
Training loss: 0.14615213871002197
Validation loss: 1.693517199126623

Epoch: 6| Step: 4
Training loss: 0.09315092861652374
Validation loss: 1.6672534352989608

Epoch: 6| Step: 5
Training loss: 0.061311304569244385
Validation loss: 1.6083673008026615

Epoch: 6| Step: 6
Training loss: 0.06804060935974121
Validation loss: 1.6029896428508144

Epoch: 6| Step: 7
Training loss: 0.12998536229133606
Validation loss: 1.6291533708572388

Epoch: 6| Step: 8
Training loss: 0.17921337485313416
Validation loss: 1.6364895041270922

Epoch: 6| Step: 9
Training loss: 0.07160045206546783
Validation loss: 1.6559247432216522

Epoch: 6| Step: 10
Training loss: 0.12421189248561859
Validation loss: 1.664047125847109

Epoch: 6| Step: 11
Training loss: 0.14593161642551422
Validation loss: 1.6619152868947675

Epoch: 6| Step: 12
Training loss: 0.06643657386302948
Validation loss: 1.6634331621149534

Epoch: 6| Step: 13
Training loss: 0.05197375267744064
Validation loss: 1.6486101432513165

Epoch: 610| Step: 0
Training loss: 0.0768846720457077
Validation loss: 1.689477051458051

Epoch: 6| Step: 1
Training loss: 0.07192791253328323
Validation loss: 1.7182924170647897

Epoch: 6| Step: 2
Training loss: 0.08742935210466385
Validation loss: 1.6717165234268352

Epoch: 6| Step: 3
Training loss: 0.1005939394235611
Validation loss: 1.6672509280584191

Epoch: 6| Step: 4
Training loss: 0.0652293711900711
Validation loss: 1.680271339672868

Epoch: 6| Step: 5
Training loss: 0.06738647073507309
Validation loss: 1.673788316788212

Epoch: 6| Step: 6
Training loss: 0.06564192473888397
Validation loss: 1.6517148645975257

Epoch: 6| Step: 7
Training loss: 0.035060472786426544
Validation loss: 1.6463662796123053

Epoch: 6| Step: 8
Training loss: 0.06155547499656677
Validation loss: 1.611557391382033

Epoch: 6| Step: 9
Training loss: 0.11508417129516602
Validation loss: 1.6232541863636305

Epoch: 6| Step: 10
Training loss: 0.09892403334379196
Validation loss: 1.6142158636482813

Epoch: 6| Step: 11
Training loss: 0.06997169554233551
Validation loss: 1.6387745821347801

Epoch: 6| Step: 12
Training loss: 0.0872860997915268
Validation loss: 1.625814103311108

Epoch: 6| Step: 13
Training loss: 0.06955020874738693
Validation loss: 1.6403303787272463

Epoch: 611| Step: 0
Training loss: 0.10747846961021423
Validation loss: 1.6231329992253294

Epoch: 6| Step: 1
Training loss: 0.06383924186229706
Validation loss: 1.676461660733787

Epoch: 6| Step: 2
Training loss: 0.0643395483493805
Validation loss: 1.6753607667902464

Epoch: 6| Step: 3
Training loss: 0.07691122591495514
Validation loss: 1.7005757484384763

Epoch: 6| Step: 4
Training loss: 0.046053580939769745
Validation loss: 1.6572230400577668

Epoch: 6| Step: 5
Training loss: 0.08531060814857483
Validation loss: 1.6531757468818336

Epoch: 6| Step: 6
Training loss: 0.08006273210048676
Validation loss: 1.6508786729587022

Epoch: 6| Step: 7
Training loss: 0.06850428134202957
Validation loss: 1.6676529428010345

Epoch: 6| Step: 8
Training loss: 0.07775203883647919
Validation loss: 1.654477072018449

Epoch: 6| Step: 9
Training loss: 0.11477316915988922
Validation loss: 1.657853803967917

Epoch: 6| Step: 10
Training loss: 0.056583963334560394
Validation loss: 1.6361042402123893

Epoch: 6| Step: 11
Training loss: 0.05354710668325424
Validation loss: 1.6259521630502516

Epoch: 6| Step: 12
Training loss: 0.07085385173559189
Validation loss: 1.6406041217106644

Epoch: 6| Step: 13
Training loss: 0.06467436254024506
Validation loss: 1.6235964131611649

Epoch: 612| Step: 0
Training loss: 0.05398476496338844
Validation loss: 1.6276912458481327

Epoch: 6| Step: 1
Training loss: 0.06834226846694946
Validation loss: 1.6502851837424821

Epoch: 6| Step: 2
Training loss: 0.10163769125938416
Validation loss: 1.6289858023325603

Epoch: 6| Step: 3
Training loss: 0.1368773877620697
Validation loss: 1.617393143715397

Epoch: 6| Step: 4
Training loss: 0.09686408191919327
Validation loss: 1.6083538557893486

Epoch: 6| Step: 5
Training loss: 0.10636796057224274
Validation loss: 1.6344602992457729

Epoch: 6| Step: 6
Training loss: 0.05938936769962311
Validation loss: 1.6240983265702442

Epoch: 6| Step: 7
Training loss: 0.05287003144621849
Validation loss: 1.628426254436534

Epoch: 6| Step: 8
Training loss: 0.06131012737751007
Validation loss: 1.6271362368778517

Epoch: 6| Step: 9
Training loss: 0.07030396908521652
Validation loss: 1.637256806896579

Epoch: 6| Step: 10
Training loss: 0.15103121101856232
Validation loss: 1.6313073135191394

Epoch: 6| Step: 11
Training loss: 0.06568603217601776
Validation loss: 1.643081126674529

Epoch: 6| Step: 12
Training loss: 0.04507439583539963
Validation loss: 1.6606861160647484

Epoch: 6| Step: 13
Training loss: 0.057150986045598984
Validation loss: 1.6714754181523477

Epoch: 613| Step: 0
Training loss: 0.05012240260839462
Validation loss: 1.6718854634992537

Epoch: 6| Step: 1
Training loss: 0.06278872489929199
Validation loss: 1.6705633158324866

Epoch: 6| Step: 2
Training loss: 0.0718098059296608
Validation loss: 1.687592114171674

Epoch: 6| Step: 3
Training loss: 0.05525873228907585
Validation loss: 1.696796598613903

Epoch: 6| Step: 4
Training loss: 0.10346516221761703
Validation loss: 1.6759904648668023

Epoch: 6| Step: 5
Training loss: 0.04980095475912094
Validation loss: 1.6442432967565392

Epoch: 6| Step: 6
Training loss: 0.05326399207115173
Validation loss: 1.6532780047385924

Epoch: 6| Step: 7
Training loss: 0.051200397312641144
Validation loss: 1.6568721776367517

Epoch: 6| Step: 8
Training loss: 0.06777159869670868
Validation loss: 1.631045332518957

Epoch: 6| Step: 9
Training loss: 0.05467350035905838
Validation loss: 1.6366170426850677

Epoch: 6| Step: 10
Training loss: 0.03970857709646225
Validation loss: 1.6508372522169543

Epoch: 6| Step: 11
Training loss: 0.05989110469818115
Validation loss: 1.6366306556168424

Epoch: 6| Step: 12
Training loss: 0.08047980815172195
Validation loss: 1.6368739425495107

Epoch: 6| Step: 13
Training loss: 0.056235287338495255
Validation loss: 1.6514749091158631

Epoch: 614| Step: 0
Training loss: 0.06210628151893616
Validation loss: 1.6672193901513213

Epoch: 6| Step: 1
Training loss: 0.04236820712685585
Validation loss: 1.669609082642422

Epoch: 6| Step: 2
Training loss: 0.0735468864440918
Validation loss: 1.6637399888807727

Epoch: 6| Step: 3
Training loss: 0.04990328475832939
Validation loss: 1.6921600795561267

Epoch: 6| Step: 4
Training loss: 0.07690812647342682
Validation loss: 1.7065414209519663

Epoch: 6| Step: 5
Training loss: 0.05516591668128967
Validation loss: 1.6854549723286782

Epoch: 6| Step: 6
Training loss: 0.04191325977444649
Validation loss: 1.7095204668660318

Epoch: 6| Step: 7
Training loss: 0.058365967124700546
Validation loss: 1.6758199635372366

Epoch: 6| Step: 8
Training loss: 0.04163499176502228
Validation loss: 1.6531643149673299

Epoch: 6| Step: 9
Training loss: 0.07631488889455795
Validation loss: 1.6639111400932394

Epoch: 6| Step: 10
Training loss: 0.06787963211536407
Validation loss: 1.6467663677789832

Epoch: 6| Step: 11
Training loss: 0.09608379751443863
Validation loss: 1.6465339724735548

Epoch: 6| Step: 12
Training loss: 0.07630565762519836
Validation loss: 1.6350558368108605

Epoch: 6| Step: 13
Training loss: 0.11248954385519028
Validation loss: 1.6246613033356205

Epoch: 615| Step: 0
Training loss: 0.04357742518186569
Validation loss: 1.6379756171216246

Epoch: 6| Step: 1
Training loss: 0.07073225826025009
Validation loss: 1.6338853579695507

Epoch: 6| Step: 2
Training loss: 0.061902835965156555
Validation loss: 1.6209888906889065

Epoch: 6| Step: 3
Training loss: 0.07757299393415451
Validation loss: 1.618002534553569

Epoch: 6| Step: 4
Training loss: 0.056557152420282364
Validation loss: 1.626379487335041

Epoch: 6| Step: 5
Training loss: 0.07182475924491882
Validation loss: 1.6406026937628304

Epoch: 6| Step: 6
Training loss: 0.07291708886623383
Validation loss: 1.633440012572914

Epoch: 6| Step: 7
Training loss: 0.05842559039592743
Validation loss: 1.638903110258041

Epoch: 6| Step: 8
Training loss: 0.052764393389225006
Validation loss: 1.599723324980787

Epoch: 6| Step: 9
Training loss: 0.07966683059930801
Validation loss: 1.6364306813927108

Epoch: 6| Step: 10
Training loss: 0.058816149830818176
Validation loss: 1.637892238555416

Epoch: 6| Step: 11
Training loss: 0.11415714025497437
Validation loss: 1.621771417638307

Epoch: 6| Step: 12
Training loss: 0.07667861878871918
Validation loss: 1.643199272053216

Epoch: 6| Step: 13
Training loss: 0.03921744227409363
Validation loss: 1.6545995627680132

Epoch: 616| Step: 0
Training loss: 0.060043107718229294
Validation loss: 1.6701106666236796

Epoch: 6| Step: 1
Training loss: 0.07708205282688141
Validation loss: 1.6753967385138235

Epoch: 6| Step: 2
Training loss: 0.08092115819454193
Validation loss: 1.658259678912419

Epoch: 6| Step: 3
Training loss: 0.09925587475299835
Validation loss: 1.6497007762232134

Epoch: 6| Step: 4
Training loss: 0.06516581773757935
Validation loss: 1.665698112980012

Epoch: 6| Step: 5
Training loss: 0.07042134553194046
Validation loss: 1.66745384406018

Epoch: 6| Step: 6
Training loss: 0.03451588749885559
Validation loss: 1.6486487516792871

Epoch: 6| Step: 7
Training loss: 0.08373142778873444
Validation loss: 1.6534666809984433

Epoch: 6| Step: 8
Training loss: 0.036184825003147125
Validation loss: 1.6407106448245306

Epoch: 6| Step: 9
Training loss: 0.05104679986834526
Validation loss: 1.645925352650304

Epoch: 6| Step: 10
Training loss: 0.06960249692201614
Validation loss: 1.6485599843404626

Epoch: 6| Step: 11
Training loss: 0.06939709186553955
Validation loss: 1.629982699630081

Epoch: 6| Step: 12
Training loss: 0.0899258553981781
Validation loss: 1.634724029930689

Epoch: 6| Step: 13
Training loss: 0.03229302912950516
Validation loss: 1.6699624253857521

Epoch: 617| Step: 0
Training loss: 0.06665325164794922
Validation loss: 1.6562359794493644

Epoch: 6| Step: 1
Training loss: 0.06543285399675369
Validation loss: 1.654849567720967

Epoch: 6| Step: 2
Training loss: 0.08835911750793457
Validation loss: 1.6689303600659935

Epoch: 6| Step: 3
Training loss: 0.0729610025882721
Validation loss: 1.6663819192558207

Epoch: 6| Step: 4
Training loss: 0.07400521636009216
Validation loss: 1.6500837238886024

Epoch: 6| Step: 5
Training loss: 0.03723513334989548
Validation loss: 1.632621770264

Epoch: 6| Step: 6
Training loss: 0.05524212121963501
Validation loss: 1.6690381547456146

Epoch: 6| Step: 7
Training loss: 0.054944541305303574
Validation loss: 1.6327789701441282

Epoch: 6| Step: 8
Training loss: 0.06266768276691437
Validation loss: 1.621756270367612

Epoch: 6| Step: 9
Training loss: 0.08253753930330276
Validation loss: 1.6353513848397039

Epoch: 6| Step: 10
Training loss: 0.0671411007642746
Validation loss: 1.661260998377236

Epoch: 6| Step: 11
Training loss: 0.05093708634376526
Validation loss: 1.6567106528948712

Epoch: 6| Step: 12
Training loss: 0.10791970789432526
Validation loss: 1.640042979230163

Epoch: 6| Step: 13
Training loss: 0.0312217865139246
Validation loss: 1.6349396718445646

Epoch: 618| Step: 0
Training loss: 0.07352564483880997
Validation loss: 1.6333872054212837

Epoch: 6| Step: 1
Training loss: 0.05606171488761902
Validation loss: 1.6472324427737985

Epoch: 6| Step: 2
Training loss: 0.07900921255350113
Validation loss: 1.6111837433230491

Epoch: 6| Step: 3
Training loss: 0.06182359158992767
Validation loss: 1.5887950094797278

Epoch: 6| Step: 4
Training loss: 0.0716564804315567
Validation loss: 1.584795387842322

Epoch: 6| Step: 5
Training loss: 0.06862492859363556
Validation loss: 1.5743907190138293

Epoch: 6| Step: 6
Training loss: 0.0997539758682251
Validation loss: 1.5759066112579838

Epoch: 6| Step: 7
Training loss: 0.0779896080493927
Validation loss: 1.5877974533265637

Epoch: 6| Step: 8
Training loss: 0.06322474777698517
Validation loss: 1.5875348903799569

Epoch: 6| Step: 9
Training loss: 0.05979204177856445
Validation loss: 1.5988512295548634

Epoch: 6| Step: 10
Training loss: 0.03984168544411659
Validation loss: 1.6483816151977868

Epoch: 6| Step: 11
Training loss: 0.05949484184384346
Validation loss: 1.6262753394342238

Epoch: 6| Step: 12
Training loss: 0.05557488650083542
Validation loss: 1.618618897212449

Epoch: 6| Step: 13
Training loss: 0.05821589007973671
Validation loss: 1.6192495951088526

Epoch: 619| Step: 0
Training loss: 0.04559404030442238
Validation loss: 1.6574397689552718

Epoch: 6| Step: 1
Training loss: 0.05440981686115265
Validation loss: 1.6727900017974198

Epoch: 6| Step: 2
Training loss: 0.10128737986087799
Validation loss: 1.6412281246595486

Epoch: 6| Step: 3
Training loss: 0.05956505611538887
Validation loss: 1.6431187058007846

Epoch: 6| Step: 4
Training loss: 0.059008173644542694
Validation loss: 1.6452657202238679

Epoch: 6| Step: 5
Training loss: 0.048747532069683075
Validation loss: 1.619970324218914

Epoch: 6| Step: 6
Training loss: 0.06421194970607758
Validation loss: 1.6238051210680315

Epoch: 6| Step: 7
Training loss: 0.06461785733699799
Validation loss: 1.6127962899464432

Epoch: 6| Step: 8
Training loss: 0.04549982026219368
Validation loss: 1.6152002247430945

Epoch: 6| Step: 9
Training loss: 0.05082719027996063
Validation loss: 1.583523340122674

Epoch: 6| Step: 10
Training loss: 0.060011811554431915
Validation loss: 1.6093845841705159

Epoch: 6| Step: 11
Training loss: 0.11470982432365417
Validation loss: 1.5973555580262215

Epoch: 6| Step: 12
Training loss: 0.07038377225399017
Validation loss: 1.611872535879894

Epoch: 6| Step: 13
Training loss: 0.07210610806941986
Validation loss: 1.6226799231703564

Epoch: 620| Step: 0
Training loss: 0.07094201445579529
Validation loss: 1.6213067987913727

Epoch: 6| Step: 1
Training loss: 0.059591732919216156
Validation loss: 1.6349931365700179

Epoch: 6| Step: 2
Training loss: 0.07396712154150009
Validation loss: 1.6562537326607654

Epoch: 6| Step: 3
Training loss: 0.13337665796279907
Validation loss: 1.6575388203385055

Epoch: 6| Step: 4
Training loss: 0.07364574819803238
Validation loss: 1.6650217707439134

Epoch: 6| Step: 5
Training loss: 0.0823076143860817
Validation loss: 1.648144510484511

Epoch: 6| Step: 6
Training loss: 0.06525745987892151
Validation loss: 1.6811104230983283

Epoch: 6| Step: 7
Training loss: 0.06790478527545929
Validation loss: 1.640253900199808

Epoch: 6| Step: 8
Training loss: 0.039235420525074005
Validation loss: 1.6027993694428475

Epoch: 6| Step: 9
Training loss: 0.07980188727378845
Validation loss: 1.5982961577753867

Epoch: 6| Step: 10
Training loss: 0.03881628066301346
Validation loss: 1.6255235287450975

Epoch: 6| Step: 11
Training loss: 0.055230364203453064
Validation loss: 1.6503430079388361

Epoch: 6| Step: 12
Training loss: 0.11637212336063385
Validation loss: 1.6356397726202523

Epoch: 6| Step: 13
Training loss: 0.058222394436597824
Validation loss: 1.658473655741702

Epoch: 621| Step: 0
Training loss: 0.1009073555469513
Validation loss: 1.6406670783155708

Epoch: 6| Step: 1
Training loss: 0.06322913616895676
Validation loss: 1.6183715392184514

Epoch: 6| Step: 2
Training loss: 0.07159136980772018
Validation loss: 1.6268071179748864

Epoch: 6| Step: 3
Training loss: 0.05165613070130348
Validation loss: 1.6340458444369736

Epoch: 6| Step: 4
Training loss: 0.07749002426862717
Validation loss: 1.6118526715104298

Epoch: 6| Step: 5
Training loss: 0.06155664846301079
Validation loss: 1.6103863011124313

Epoch: 6| Step: 6
Training loss: 0.07001731544733047
Validation loss: 1.60952514730474

Epoch: 6| Step: 7
Training loss: 0.054211679846048355
Validation loss: 1.6153672049122472

Epoch: 6| Step: 8
Training loss: 0.05149926617741585
Validation loss: 1.634692422805294

Epoch: 6| Step: 9
Training loss: 0.06598007678985596
Validation loss: 1.63026011631053

Epoch: 6| Step: 10
Training loss: 0.04847218841314316
Validation loss: 1.647343054894478

Epoch: 6| Step: 11
Training loss: 0.08256421983242035
Validation loss: 1.660350803406008

Epoch: 6| Step: 12
Training loss: 0.0685979500412941
Validation loss: 1.6214849538700555

Epoch: 6| Step: 13
Training loss: 0.060408275574445724
Validation loss: 1.6420020108581872

Epoch: 622| Step: 0
Training loss: 0.08727124333381653
Validation loss: 1.6284127555867678

Epoch: 6| Step: 1
Training loss: 0.07774224877357483
Validation loss: 1.6045883560693392

Epoch: 6| Step: 2
Training loss: 0.050585925579071045
Validation loss: 1.6188221016237814

Epoch: 6| Step: 3
Training loss: 0.042425379157066345
Validation loss: 1.588315479217037

Epoch: 6| Step: 4
Training loss: 0.07932745665311813
Validation loss: 1.6094759433500228

Epoch: 6| Step: 5
Training loss: 0.07197144627571106
Validation loss: 1.5706419303853025

Epoch: 6| Step: 6
Training loss: 0.06609845161437988
Validation loss: 1.616715177412956

Epoch: 6| Step: 7
Training loss: 0.07016407698392868
Validation loss: 1.604396834168383

Epoch: 6| Step: 8
Training loss: 0.06263703852891922
Validation loss: 1.5797799466758646

Epoch: 6| Step: 9
Training loss: 0.054037727415561676
Validation loss: 1.619354127555765

Epoch: 6| Step: 10
Training loss: 0.06991724669933319
Validation loss: 1.6138531315711238

Epoch: 6| Step: 11
Training loss: 0.049315933138132095
Validation loss: 1.5789216141546927

Epoch: 6| Step: 12
Training loss: 0.05323013663291931
Validation loss: 1.5726850019988192

Epoch: 6| Step: 13
Training loss: 0.057706937193870544
Validation loss: 1.6057470075545772

Epoch: 623| Step: 0
Training loss: 0.063449926674366
Validation loss: 1.572685778781932

Epoch: 6| Step: 1
Training loss: 0.06944740563631058
Validation loss: 1.5745803438207155

Epoch: 6| Step: 2
Training loss: 0.06447743624448776
Validation loss: 1.5818959051562893

Epoch: 6| Step: 3
Training loss: 0.07439015805721283
Validation loss: 1.5699900209262807

Epoch: 6| Step: 4
Training loss: 0.08267481625080109
Validation loss: 1.5894702108957435

Epoch: 6| Step: 5
Training loss: 0.055857717990875244
Validation loss: 1.5995221317455333

Epoch: 6| Step: 6
Training loss: 0.05980118364095688
Validation loss: 1.578609940826252

Epoch: 6| Step: 7
Training loss: 0.07127366214990616
Validation loss: 1.5776949556924964

Epoch: 6| Step: 8
Training loss: 0.07488381862640381
Validation loss: 1.5870547794526624

Epoch: 6| Step: 9
Training loss: 0.03279717639088631
Validation loss: 1.5709467921205746

Epoch: 6| Step: 10
Training loss: 0.08148360997438431
Validation loss: 1.6009895872044306

Epoch: 6| Step: 11
Training loss: 0.03925071656703949
Validation loss: 1.6219265896786925

Epoch: 6| Step: 12
Training loss: 0.06732705235481262
Validation loss: 1.620265587683647

Epoch: 6| Step: 13
Training loss: 0.0817880630493164
Validation loss: 1.6330862763107463

Epoch: 624| Step: 0
Training loss: 0.1588779091835022
Validation loss: 1.6419290599002634

Epoch: 6| Step: 1
Training loss: 0.06415196508169174
Validation loss: 1.6405793845012624

Epoch: 6| Step: 2
Training loss: 0.0625067725777626
Validation loss: 1.6285889930622552

Epoch: 6| Step: 3
Training loss: 0.0460953451693058
Validation loss: 1.6323851859697731

Epoch: 6| Step: 4
Training loss: 0.06672617793083191
Validation loss: 1.6076819973607217

Epoch: 6| Step: 5
Training loss: 0.05509139224886894
Validation loss: 1.5899909311725247

Epoch: 6| Step: 6
Training loss: 0.16033151745796204
Validation loss: 1.623018939007995

Epoch: 6| Step: 7
Training loss: 0.07386934012174606
Validation loss: 1.573087130823443

Epoch: 6| Step: 8
Training loss: 0.05559967830777168
Validation loss: 1.5851670875344226

Epoch: 6| Step: 9
Training loss: 0.09194985032081604
Validation loss: 1.6220737003510999

Epoch: 6| Step: 10
Training loss: 0.13148640096187592
Validation loss: 1.6443726183265768

Epoch: 6| Step: 11
Training loss: 0.08337050676345825
Validation loss: 1.6414683249688917

Epoch: 6| Step: 12
Training loss: 0.15731710195541382
Validation loss: 1.6567868295536246

Epoch: 6| Step: 13
Training loss: 0.08917474746704102
Validation loss: 1.6435813032170778

Epoch: 625| Step: 0
Training loss: 0.0533577986061573
Validation loss: 1.645262804082645

Epoch: 6| Step: 1
Training loss: 0.07694989442825317
Validation loss: 1.6017403307781424

Epoch: 6| Step: 2
Training loss: 0.11282913386821747
Validation loss: 1.605953408825782

Epoch: 6| Step: 3
Training loss: 0.15976953506469727
Validation loss: 1.6031491525711552

Epoch: 6| Step: 4
Training loss: 0.10062284767627716
Validation loss: 1.5975256286641604

Epoch: 6| Step: 5
Training loss: 0.05836355313658714
Validation loss: 1.6126968347898094

Epoch: 6| Step: 6
Training loss: 0.10038426518440247
Validation loss: 1.6587086531423754

Epoch: 6| Step: 7
Training loss: 0.06714149564504623
Validation loss: 1.6707369960764402

Epoch: 6| Step: 8
Training loss: 0.1456773579120636
Validation loss: 1.6834962560284523

Epoch: 6| Step: 9
Training loss: 0.11438577622175217
Validation loss: 1.6751761564644434

Epoch: 6| Step: 10
Training loss: 0.12912636995315552
Validation loss: 1.6720952436488161

Epoch: 6| Step: 11
Training loss: 0.11029167473316193
Validation loss: 1.6718860915912095

Epoch: 6| Step: 12
Training loss: 0.0897112563252449
Validation loss: 1.6423252955559762

Epoch: 6| Step: 13
Training loss: 0.03149718791246414
Validation loss: 1.6339395776871712

Epoch: 626| Step: 0
Training loss: 0.053855136036872864
Validation loss: 1.6390171192025627

Epoch: 6| Step: 1
Training loss: 0.0991351380944252
Validation loss: 1.6361371496672272

Epoch: 6| Step: 2
Training loss: 0.08691832423210144
Validation loss: 1.6243146798943962

Epoch: 6| Step: 3
Training loss: 0.09808774292469025
Validation loss: 1.6294215750950638

Epoch: 6| Step: 4
Training loss: 0.04223313182592392
Validation loss: 1.635735587407184

Epoch: 6| Step: 5
Training loss: 0.11971515417098999
Validation loss: 1.6364618552628385

Epoch: 6| Step: 6
Training loss: 0.06548483669757843
Validation loss: 1.6502835596761396

Epoch: 6| Step: 7
Training loss: 0.08602583408355713
Validation loss: 1.6283394572555379

Epoch: 6| Step: 8
Training loss: 0.08502798527479172
Validation loss: 1.6701790440467097

Epoch: 6| Step: 9
Training loss: 0.1714886724948883
Validation loss: 1.6619205782490392

Epoch: 6| Step: 10
Training loss: 0.1218012273311615
Validation loss: 1.6543639526572278

Epoch: 6| Step: 11
Training loss: 0.12119421362876892
Validation loss: 1.7106206109446864

Epoch: 6| Step: 12
Training loss: 0.05966556444764137
Validation loss: 1.7205746532768331

Epoch: 6| Step: 13
Training loss: 0.06817547976970673
Validation loss: 1.6698703112140778

Epoch: 627| Step: 0
Training loss: 0.0626591295003891
Validation loss: 1.6653245597757318

Epoch: 6| Step: 1
Training loss: 0.07631877064704895
Validation loss: 1.6663896652960009

Epoch: 6| Step: 2
Training loss: 0.12962816655635834
Validation loss: 1.651876430357656

Epoch: 6| Step: 3
Training loss: 0.08891712874174118
Validation loss: 1.6652128632350633

Epoch: 6| Step: 4
Training loss: 0.09545496106147766
Validation loss: 1.6172427772193827

Epoch: 6| Step: 5
Training loss: 0.1434834748506546
Validation loss: 1.6214274155196322

Epoch: 6| Step: 6
Training loss: 0.08201906830072403
Validation loss: 1.6231170905533658

Epoch: 6| Step: 7
Training loss: 0.10004762560129166
Validation loss: 1.6100211835676623

Epoch: 6| Step: 8
Training loss: 0.11194661259651184
Validation loss: 1.6413956893387662

Epoch: 6| Step: 9
Training loss: 0.09997137635946274
Validation loss: 1.6187802424994848

Epoch: 6| Step: 10
Training loss: 0.08157270401716232
Validation loss: 1.6255393053895684

Epoch: 6| Step: 11
Training loss: 0.0903371274471283
Validation loss: 1.634009434330848

Epoch: 6| Step: 12
Training loss: 0.08496402204036713
Validation loss: 1.6567790879998157

Epoch: 6| Step: 13
Training loss: 0.11170656234025955
Validation loss: 1.6109936211698799

Epoch: 628| Step: 0
Training loss: 0.06879308074712753
Validation loss: 1.6278386103209628

Epoch: 6| Step: 1
Training loss: 0.08388080447912216
Validation loss: 1.6390286363581175

Epoch: 6| Step: 2
Training loss: 0.12818193435668945
Validation loss: 1.6426121342566706

Epoch: 6| Step: 3
Training loss: 0.060751136392354965
Validation loss: 1.6372551110482985

Epoch: 6| Step: 4
Training loss: 0.11991949379444122
Validation loss: 1.6606947004154164

Epoch: 6| Step: 5
Training loss: 0.10182644426822662
Validation loss: 1.6864423521103398

Epoch: 6| Step: 6
Training loss: 0.09168998897075653
Validation loss: 1.7084489304532287

Epoch: 6| Step: 7
Training loss: 0.06227453798055649
Validation loss: 1.7236692213243054

Epoch: 6| Step: 8
Training loss: 0.10588271915912628
Validation loss: 1.7063163736815095

Epoch: 6| Step: 9
Training loss: 0.1035841703414917
Validation loss: 1.7356561832530524

Epoch: 6| Step: 10
Training loss: 0.19932697713375092
Validation loss: 1.7591143769602622

Epoch: 6| Step: 11
Training loss: 0.1482047736644745
Validation loss: 1.7442766492084791

Epoch: 6| Step: 12
Training loss: 0.09620768576860428
Validation loss: 1.6882188230432489

Epoch: 6| Step: 13
Training loss: 0.04087067395448685
Validation loss: 1.658001035772344

Epoch: 629| Step: 0
Training loss: 0.06261648237705231
Validation loss: 1.6490414988610052

Epoch: 6| Step: 1
Training loss: 0.08805601298809052
Validation loss: 1.6109305620193481

Epoch: 6| Step: 2
Training loss: 0.16254429519176483
Validation loss: 1.6315508709158948

Epoch: 6| Step: 3
Training loss: 0.1078844740986824
Validation loss: 1.6069827374591623

Epoch: 6| Step: 4
Training loss: 0.12927734851837158
Validation loss: 1.629583583083204

Epoch: 6| Step: 5
Training loss: 0.1245371550321579
Validation loss: 1.63480423086433

Epoch: 6| Step: 6
Training loss: 0.07980988174676895
Validation loss: 1.6000658940243464

Epoch: 6| Step: 7
Training loss: 0.08420637249946594
Validation loss: 1.638902726993766

Epoch: 6| Step: 8
Training loss: 0.08353522419929504
Validation loss: 1.6455844063912668

Epoch: 6| Step: 9
Training loss: 0.09261072427034378
Validation loss: 1.6578948305499168

Epoch: 6| Step: 10
Training loss: 0.10195452719926834
Validation loss: 1.6927601675833426

Epoch: 6| Step: 11
Training loss: 0.06034808233380318
Validation loss: 1.6648418531622937

Epoch: 6| Step: 12
Training loss: 0.0380806103348732
Validation loss: 1.705047067134611

Epoch: 6| Step: 13
Training loss: 0.15727415680885315
Validation loss: 1.68047756789833

Epoch: 630| Step: 0
Training loss: 0.060156211256980896
Validation loss: 1.7160226222007506

Epoch: 6| Step: 1
Training loss: 0.09776851534843445
Validation loss: 1.7015901329696819

Epoch: 6| Step: 2
Training loss: 0.05877629294991493
Validation loss: 1.7022798420280538

Epoch: 6| Step: 3
Training loss: 0.08557021617889404
Validation loss: 1.686080801871515

Epoch: 6| Step: 4
Training loss: 0.055759310722351074
Validation loss: 1.6994230619040869

Epoch: 6| Step: 5
Training loss: 0.08417285978794098
Validation loss: 1.65780008351931

Epoch: 6| Step: 6
Training loss: 0.10452122986316681
Validation loss: 1.6404162837613014

Epoch: 6| Step: 7
Training loss: 0.14985349774360657
Validation loss: 1.6782648871021886

Epoch: 6| Step: 8
Training loss: 0.0894898995757103
Validation loss: 1.6800940100864699

Epoch: 6| Step: 9
Training loss: 0.07063281536102295
Validation loss: 1.6795379910417783

Epoch: 6| Step: 10
Training loss: 0.03780076652765274
Validation loss: 1.6771616807547949

Epoch: 6| Step: 11
Training loss: 0.06701155751943588
Validation loss: 1.6538460267487394

Epoch: 6| Step: 12
Training loss: 0.09178474545478821
Validation loss: 1.6646861043027652

Epoch: 6| Step: 13
Training loss: 0.09328127652406693
Validation loss: 1.663537069033551

Epoch: 631| Step: 0
Training loss: 0.06502231955528259
Validation loss: 1.6277269330075992

Epoch: 6| Step: 1
Training loss: 0.056811586022377014
Validation loss: 1.6118096869478944

Epoch: 6| Step: 2
Training loss: 0.07789214700460434
Validation loss: 1.6023242242874638

Epoch: 6| Step: 3
Training loss: 0.06113341450691223
Validation loss: 1.5715629951928252

Epoch: 6| Step: 4
Training loss: 0.10831356048583984
Validation loss: 1.5972665747006733

Epoch: 6| Step: 5
Training loss: 0.10936236381530762
Validation loss: 1.5997535259492937

Epoch: 6| Step: 6
Training loss: 0.048750441521406174
Validation loss: 1.602620409381005

Epoch: 6| Step: 7
Training loss: 0.06772398203611374
Validation loss: 1.6203411163822297

Epoch: 6| Step: 8
Training loss: 0.07275155931711197
Validation loss: 1.617391606812836

Epoch: 6| Step: 9
Training loss: 0.06427089869976044
Validation loss: 1.619402103526618

Epoch: 6| Step: 10
Training loss: 0.05176139622926712
Validation loss: 1.6308173364208591

Epoch: 6| Step: 11
Training loss: 0.1255466490983963
Validation loss: 1.6795142953113844

Epoch: 6| Step: 12
Training loss: 0.05345744267106056
Validation loss: 1.6455101031129078

Epoch: 6| Step: 13
Training loss: 0.025406518951058388
Validation loss: 1.6603477719009563

Epoch: 632| Step: 0
Training loss: 0.07248027622699738
Validation loss: 1.6233371188563686

Epoch: 6| Step: 1
Training loss: 0.0659780204296112
Validation loss: 1.6454082958159908

Epoch: 6| Step: 2
Training loss: 0.0920150950551033
Validation loss: 1.6715501252041067

Epoch: 6| Step: 3
Training loss: 0.0683915913105011
Validation loss: 1.6778578348057245

Epoch: 6| Step: 4
Training loss: 0.0492529422044754
Validation loss: 1.6524470711267123

Epoch: 6| Step: 5
Training loss: 0.05092116445302963
Validation loss: 1.6527737507256128

Epoch: 6| Step: 6
Training loss: 0.06350258737802505
Validation loss: 1.6860992344476844

Epoch: 6| Step: 7
Training loss: 0.105044424533844
Validation loss: 1.667945287560904

Epoch: 6| Step: 8
Training loss: 0.07595910131931305
Validation loss: 1.700882637372581

Epoch: 6| Step: 9
Training loss: 0.04943316802382469
Validation loss: 1.6780719385352185

Epoch: 6| Step: 10
Training loss: 0.0755612850189209
Validation loss: 1.6981788758308656

Epoch: 6| Step: 11
Training loss: 0.03695134073495865
Validation loss: 1.7086347187719038

Epoch: 6| Step: 12
Training loss: 0.05414801090955734
Validation loss: 1.6933009880845264

Epoch: 6| Step: 13
Training loss: 0.03081788681447506
Validation loss: 1.6662449298366424

Epoch: 633| Step: 0
Training loss: 0.06747283041477203
Validation loss: 1.6583100044599144

Epoch: 6| Step: 1
Training loss: 0.043820571154356
Validation loss: 1.6752799300737278

Epoch: 6| Step: 2
Training loss: 0.07061968743801117
Validation loss: 1.6880638202031453

Epoch: 6| Step: 3
Training loss: 0.03877473250031471
Validation loss: 1.6589000058430496

Epoch: 6| Step: 4
Training loss: 0.047490205615758896
Validation loss: 1.6701568890643377

Epoch: 6| Step: 5
Training loss: 0.048491302877664566
Validation loss: 1.6653115108448973

Epoch: 6| Step: 6
Training loss: 0.06552983820438385
Validation loss: 1.6375720936764953

Epoch: 6| Step: 7
Training loss: 0.04759238660335541
Validation loss: 1.6721639043541365

Epoch: 6| Step: 8
Training loss: 0.06479324400424957
Validation loss: 1.6389947873289867

Epoch: 6| Step: 9
Training loss: 0.0413983091711998
Validation loss: 1.6765624938472625

Epoch: 6| Step: 10
Training loss: 0.06118445098400116
Validation loss: 1.6637940637526973

Epoch: 6| Step: 11
Training loss: 0.05770273879170418
Validation loss: 1.6657507355495165

Epoch: 6| Step: 12
Training loss: 0.04744546860456467
Validation loss: 1.649517156744516

Epoch: 6| Step: 13
Training loss: 0.08353548496961594
Validation loss: 1.6616841721278366

Epoch: 634| Step: 0
Training loss: 0.04001534730195999
Validation loss: 1.6522821610973728

Epoch: 6| Step: 1
Training loss: 0.06263096630573273
Validation loss: 1.65625282385016

Epoch: 6| Step: 2
Training loss: 0.055677056312561035
Validation loss: 1.6543772348793604

Epoch: 6| Step: 3
Training loss: 0.07854534685611725
Validation loss: 1.6737040627387263

Epoch: 6| Step: 4
Training loss: 0.08015461266040802
Validation loss: 1.6576012578061832

Epoch: 6| Step: 5
Training loss: 0.052499838173389435
Validation loss: 1.6792504274716942

Epoch: 6| Step: 6
Training loss: 0.0941859781742096
Validation loss: 1.6570896499900407

Epoch: 6| Step: 7
Training loss: 0.05670985206961632
Validation loss: 1.650008661772615

Epoch: 6| Step: 8
Training loss: 0.07506565749645233
Validation loss: 1.6652402980353243

Epoch: 6| Step: 9
Training loss: 0.10752789676189423
Validation loss: 1.66286894582933

Epoch: 6| Step: 10
Training loss: 0.09039758145809174
Validation loss: 1.6385797223737162

Epoch: 6| Step: 11
Training loss: 0.08842664957046509
Validation loss: 1.6257376145291071

Epoch: 6| Step: 12
Training loss: 0.05633091181516647
Validation loss: 1.5930090104379961

Epoch: 6| Step: 13
Training loss: 0.046976760029792786
Validation loss: 1.632229426855682

Epoch: 635| Step: 0
Training loss: 0.0676536113023758
Validation loss: 1.6552392462248444

Epoch: 6| Step: 1
Training loss: 0.11135640740394592
Validation loss: 1.6520198660512124

Epoch: 6| Step: 2
Training loss: 0.08122599124908447
Validation loss: 1.648385509367912

Epoch: 6| Step: 3
Training loss: 0.0963933914899826
Validation loss: 1.6184694228633758

Epoch: 6| Step: 4
Training loss: 0.08637751638889313
Validation loss: 1.611964423169372

Epoch: 6| Step: 5
Training loss: 0.07480230182409286
Validation loss: 1.657611116286247

Epoch: 6| Step: 6
Training loss: 0.06180422753095627
Validation loss: 1.6313523912942538

Epoch: 6| Step: 7
Training loss: 0.0614369660615921
Validation loss: 1.6218536874299407

Epoch: 6| Step: 8
Training loss: 0.07863613963127136
Validation loss: 1.6344212998626053

Epoch: 6| Step: 9
Training loss: 0.0752350464463234
Validation loss: 1.6345092622182702

Epoch: 6| Step: 10
Training loss: 0.07420332729816437
Validation loss: 1.6348204228185839

Epoch: 6| Step: 11
Training loss: 0.07043174654245377
Validation loss: 1.6417399362851215

Epoch: 6| Step: 12
Training loss: 0.07410003989934921
Validation loss: 1.639161035578738

Epoch: 6| Step: 13
Training loss: 0.0879460796713829
Validation loss: 1.6305058694654895

Epoch: 636| Step: 0
Training loss: 0.038879044353961945
Validation loss: 1.617528711595843

Epoch: 6| Step: 1
Training loss: 0.04753779619932175
Validation loss: 1.6384313465446554

Epoch: 6| Step: 2
Training loss: 0.053809747099876404
Validation loss: 1.6159503447112216

Epoch: 6| Step: 3
Training loss: 0.0542675219476223
Validation loss: 1.637406692709974

Epoch: 6| Step: 4
Training loss: 0.10406513512134552
Validation loss: 1.610853938646214

Epoch: 6| Step: 5
Training loss: 0.0604388453066349
Validation loss: 1.6077181805846512

Epoch: 6| Step: 6
Training loss: 0.11360607296228409
Validation loss: 1.6206322094445587

Epoch: 6| Step: 7
Training loss: 0.0872739627957344
Validation loss: 1.6203021990355624

Epoch: 6| Step: 8
Training loss: 0.06868201494216919
Validation loss: 1.5984011888504028

Epoch: 6| Step: 9
Training loss: 0.14050251245498657
Validation loss: 1.5730327175509544

Epoch: 6| Step: 10
Training loss: 0.06391909718513489
Validation loss: 1.5946115204083022

Epoch: 6| Step: 11
Training loss: 0.06856489181518555
Validation loss: 1.5850054397377917

Epoch: 6| Step: 12
Training loss: 0.03958328813314438
Validation loss: 1.5803762712786276

Epoch: 6| Step: 13
Training loss: 0.0884266272187233
Validation loss: 1.579885463560781

Epoch: 637| Step: 0
Training loss: 0.06504076719284058
Validation loss: 1.574219572928644

Epoch: 6| Step: 1
Training loss: 0.035138241946697235
Validation loss: 1.5832530593359342

Epoch: 6| Step: 2
Training loss: 0.04520558565855026
Validation loss: 1.606450250071864

Epoch: 6| Step: 3
Training loss: 0.050886351615190506
Validation loss: 1.6061116674894929

Epoch: 6| Step: 4
Training loss: 0.052935950458049774
Validation loss: 1.5973360897392355

Epoch: 6| Step: 5
Training loss: 0.06453167647123337
Validation loss: 1.620915307793566

Epoch: 6| Step: 6
Training loss: 0.07187152653932571
Validation loss: 1.609252546423225

Epoch: 6| Step: 7
Training loss: 0.05822470039129257
Validation loss: 1.6331269228330223

Epoch: 6| Step: 8
Training loss: 0.0601496659219265
Validation loss: 1.611621836180328

Epoch: 6| Step: 9
Training loss: 0.09018214792013168
Validation loss: 1.6249407311921478

Epoch: 6| Step: 10
Training loss: 0.09794443845748901
Validation loss: 1.6079092230848087

Epoch: 6| Step: 11
Training loss: 0.06966587156057358
Validation loss: 1.6397047517120198

Epoch: 6| Step: 12
Training loss: 0.06929326057434082
Validation loss: 1.6028396698736376

Epoch: 6| Step: 13
Training loss: 0.04548442363739014
Validation loss: 1.65365864769105

Epoch: 638| Step: 0
Training loss: 0.060103464871644974
Validation loss: 1.6303985157320577

Epoch: 6| Step: 1
Training loss: 0.044059477746486664
Validation loss: 1.6448188315155685

Epoch: 6| Step: 2
Training loss: 0.042363762855529785
Validation loss: 1.6689689005574873

Epoch: 6| Step: 3
Training loss: 0.03256528079509735
Validation loss: 1.6836959033884027

Epoch: 6| Step: 4
Training loss: 0.09675900638103485
Validation loss: 1.7034886114058956

Epoch: 6| Step: 5
Training loss: 0.07660780847072601
Validation loss: 1.711986682748282

Epoch: 6| Step: 6
Training loss: 0.08325985074043274
Validation loss: 1.696275964219083

Epoch: 6| Step: 7
Training loss: 0.0545356422662735
Validation loss: 1.7047434417150353

Epoch: 6| Step: 8
Training loss: 0.04937712475657463
Validation loss: 1.6634869152499783

Epoch: 6| Step: 9
Training loss: 0.04636544734239578
Validation loss: 1.6726359551952732

Epoch: 6| Step: 10
Training loss: 0.06342121213674545
Validation loss: 1.6392779363098966

Epoch: 6| Step: 11
Training loss: 0.11688227206468582
Validation loss: 1.6427263341924196

Epoch: 6| Step: 12
Training loss: 0.09092280268669128
Validation loss: 1.6250921385262602

Epoch: 6| Step: 13
Training loss: 0.07549379765987396
Validation loss: 1.672357154148881

Epoch: 639| Step: 0
Training loss: 0.06714866310358047
Validation loss: 1.7014109255165182

Epoch: 6| Step: 1
Training loss: 0.0678292065858841
Validation loss: 1.6691289691514866

Epoch: 6| Step: 2
Training loss: 0.09832829236984253
Validation loss: 1.7325226247951548

Epoch: 6| Step: 3
Training loss: 0.0886884331703186
Validation loss: 1.702918392355724

Epoch: 6| Step: 4
Training loss: 0.0660625472664833
Validation loss: 1.6876428486198507

Epoch: 6| Step: 5
Training loss: 0.07627526670694351
Validation loss: 1.6610506516630932

Epoch: 6| Step: 6
Training loss: 0.09354410320520401
Validation loss: 1.6758472419554187

Epoch: 6| Step: 7
Training loss: 0.07866407930850983
Validation loss: 1.6582868708077299

Epoch: 6| Step: 8
Training loss: 0.08760152757167816
Validation loss: 1.5906577315381778

Epoch: 6| Step: 9
Training loss: 0.07117807865142822
Validation loss: 1.6215558141790412

Epoch: 6| Step: 10
Training loss: 0.1033443808555603
Validation loss: 1.607141787006009

Epoch: 6| Step: 11
Training loss: 0.13966146111488342
Validation loss: 1.5906457042181363

Epoch: 6| Step: 12
Training loss: 0.08198662847280502
Validation loss: 1.5997881248433103

Epoch: 6| Step: 13
Training loss: 0.1271807849407196
Validation loss: 1.5889101156624414

Epoch: 640| Step: 0
Training loss: 0.07483328133821487
Validation loss: 1.6198130346113635

Epoch: 6| Step: 1
Training loss: 0.058849893510341644
Validation loss: 1.6665765546983289

Epoch: 6| Step: 2
Training loss: 0.07816790044307709
Validation loss: 1.66890965225876

Epoch: 6| Step: 3
Training loss: 0.07682856917381287
Validation loss: 1.6531877889428088

Epoch: 6| Step: 4
Training loss: 0.10244005918502808
Validation loss: 1.6735480459787513

Epoch: 6| Step: 5
Training loss: 0.1209799125790596
Validation loss: 1.6778035535607287

Epoch: 6| Step: 6
Training loss: 0.09321285784244537
Validation loss: 1.6546305046286633

Epoch: 6| Step: 7
Training loss: 0.08435256779193878
Validation loss: 1.6047230830756567

Epoch: 6| Step: 8
Training loss: 0.05382061377167702
Validation loss: 1.5874102935996106

Epoch: 6| Step: 9
Training loss: 0.10304472595453262
Validation loss: 1.5679510434468586

Epoch: 6| Step: 10
Training loss: 0.05884195864200592
Validation loss: 1.5832666427858415

Epoch: 6| Step: 11
Training loss: 0.057506002485752106
Validation loss: 1.572087090502503

Epoch: 6| Step: 12
Training loss: 0.06576144695281982
Validation loss: 1.6218114104322208

Epoch: 6| Step: 13
Training loss: 0.07378053665161133
Validation loss: 1.6248148679733276

Epoch: 641| Step: 0
Training loss: 0.04224272072315216
Validation loss: 1.6482731373079362

Epoch: 6| Step: 1
Training loss: 0.08856885135173798
Validation loss: 1.6599035122061288

Epoch: 6| Step: 2
Training loss: 0.0681656002998352
Validation loss: 1.667227416910151

Epoch: 6| Step: 3
Training loss: 0.07667642831802368
Validation loss: 1.6427720426231303

Epoch: 6| Step: 4
Training loss: 0.06258471310138702
Validation loss: 1.6435775628653906

Epoch: 6| Step: 5
Training loss: 0.05479806289076805
Validation loss: 1.641336009066592

Epoch: 6| Step: 6
Training loss: 0.04854366183280945
Validation loss: 1.607935728565339

Epoch: 6| Step: 7
Training loss: 0.07375340163707733
Validation loss: 1.6519403675551056

Epoch: 6| Step: 8
Training loss: 0.07274024188518524
Validation loss: 1.5849388645541282

Epoch: 6| Step: 9
Training loss: 0.03992614895105362
Validation loss: 1.5856545548285208

Epoch: 6| Step: 10
Training loss: 0.06724727153778076
Validation loss: 1.5904670812750374

Epoch: 6| Step: 11
Training loss: 0.04522678256034851
Validation loss: 1.5911116048853884

Epoch: 6| Step: 12
Training loss: 0.09019047021865845
Validation loss: 1.5729873052207373

Epoch: 6| Step: 13
Training loss: 0.06374149024486542
Validation loss: 1.611063987978043

Epoch: 642| Step: 0
Training loss: 0.05932127684354782
Validation loss: 1.5990072347784554

Epoch: 6| Step: 1
Training loss: 0.08502990007400513
Validation loss: 1.6067847744111092

Epoch: 6| Step: 2
Training loss: 0.10974409431219101
Validation loss: 1.6138192479328444

Epoch: 6| Step: 3
Training loss: 0.10446707904338837
Validation loss: 1.5904679439401115

Epoch: 6| Step: 4
Training loss: 0.059836387634277344
Validation loss: 1.5734837965298725

Epoch: 6| Step: 5
Training loss: 0.03741224482655525
Validation loss: 1.5875120944874261

Epoch: 6| Step: 6
Training loss: 0.08201552927494049
Validation loss: 1.57493471330212

Epoch: 6| Step: 7
Training loss: 0.07889864593744278
Validation loss: 1.5691236424189743

Epoch: 6| Step: 8
Training loss: 0.049407005310058594
Validation loss: 1.61145322040845

Epoch: 6| Step: 9
Training loss: 0.046305157244205475
Validation loss: 1.621944715899806

Epoch: 6| Step: 10
Training loss: 0.06972026824951172
Validation loss: 1.620023053179505

Epoch: 6| Step: 11
Training loss: 0.06055055931210518
Validation loss: 1.6154836864881619

Epoch: 6| Step: 12
Training loss: 0.051477786153554916
Validation loss: 1.6556559685737855

Epoch: 6| Step: 13
Training loss: 0.08133657276630402
Validation loss: 1.6412603752587431

Epoch: 643| Step: 0
Training loss: 0.05902724713087082
Validation loss: 1.6437326105692054

Epoch: 6| Step: 1
Training loss: 0.07169369608163834
Validation loss: 1.6382740018188313

Epoch: 6| Step: 2
Training loss: 0.07249636948108673
Validation loss: 1.6640631075828307

Epoch: 6| Step: 3
Training loss: 0.08750544488430023
Validation loss: 1.6361012407528457

Epoch: 6| Step: 4
Training loss: 0.06719152629375458
Validation loss: 1.6293966847081338

Epoch: 6| Step: 5
Training loss: 0.054445333778858185
Validation loss: 1.6267269490867533

Epoch: 6| Step: 6
Training loss: 0.08304023742675781
Validation loss: 1.6430549685673048

Epoch: 6| Step: 7
Training loss: 0.10258514434099197
Validation loss: 1.6416517521745415

Epoch: 6| Step: 8
Training loss: 0.09367366880178452
Validation loss: 1.66756062481993

Epoch: 6| Step: 9
Training loss: 0.06083217263221741
Validation loss: 1.6080095498792586

Epoch: 6| Step: 10
Training loss: 0.04554380103945732
Validation loss: 1.6171295174988367

Epoch: 6| Step: 11
Training loss: 0.06440247595310211
Validation loss: 1.614672746709598

Epoch: 6| Step: 12
Training loss: 0.06386164575815201
Validation loss: 1.6069435355483845

Epoch: 6| Step: 13
Training loss: 0.09934738278388977
Validation loss: 1.5992992437014015

Epoch: 644| Step: 0
Training loss: 0.10406014323234558
Validation loss: 1.6205207583724812

Epoch: 6| Step: 1
Training loss: 0.09056085348129272
Validation loss: 1.6057140942542785

Epoch: 6| Step: 2
Training loss: 0.05868034437298775
Validation loss: 1.6363557320769115

Epoch: 6| Step: 3
Training loss: 0.09630636125802994
Validation loss: 1.6733237569050123

Epoch: 6| Step: 4
Training loss: 0.057112857699394226
Validation loss: 1.6304484721153014

Epoch: 6| Step: 5
Training loss: 0.07379105687141418
Validation loss: 1.6639168006117626

Epoch: 6| Step: 6
Training loss: 0.06756620854139328
Validation loss: 1.6721298835610832

Epoch: 6| Step: 7
Training loss: 0.07543623447418213
Validation loss: 1.67715714311087

Epoch: 6| Step: 8
Training loss: 0.07572611421346664
Validation loss: 1.6902940529648975

Epoch: 6| Step: 9
Training loss: 0.04664243012666702
Validation loss: 1.7009665799397293

Epoch: 6| Step: 10
Training loss: 0.10544102638959885
Validation loss: 1.684919552136493

Epoch: 6| Step: 11
Training loss: 0.07364284992218018
Validation loss: 1.6908227077094458

Epoch: 6| Step: 12
Training loss: 0.10797707736492157
Validation loss: 1.665152649725637

Epoch: 6| Step: 13
Training loss: 0.07402178645133972
Validation loss: 1.6466011590855096

Epoch: 645| Step: 0
Training loss: 0.08584242314100266
Validation loss: 1.6254364085453812

Epoch: 6| Step: 1
Training loss: 0.054705943912267685
Validation loss: 1.6368833344469789

Epoch: 6| Step: 2
Training loss: 0.0757455825805664
Validation loss: 1.5958979514337355

Epoch: 6| Step: 3
Training loss: 0.08189461380243301
Validation loss: 1.616409065902874

Epoch: 6| Step: 4
Training loss: 0.05230442434549332
Validation loss: 1.613462576302149

Epoch: 6| Step: 5
Training loss: 0.14016860723495483
Validation loss: 1.5690740975000526

Epoch: 6| Step: 6
Training loss: 0.10591086745262146
Validation loss: 1.5938007344481766

Epoch: 6| Step: 7
Training loss: 0.1176944449543953
Validation loss: 1.6297879142145957

Epoch: 6| Step: 8
Training loss: 0.046755291521549225
Validation loss: 1.648151336177703

Epoch: 6| Step: 9
Training loss: 0.07472987473011017
Validation loss: 1.6792676974368352

Epoch: 6| Step: 10
Training loss: 0.05755937844514847
Validation loss: 1.6807976717590003

Epoch: 6| Step: 11
Training loss: 0.0739535242319107
Validation loss: 1.7141254102030108

Epoch: 6| Step: 12
Training loss: 0.0766742080450058
Validation loss: 1.7210804557287565

Epoch: 6| Step: 13
Training loss: 0.07202383130788803
Validation loss: 1.7027767935106832

Epoch: 646| Step: 0
Training loss: 0.06761466711759567
Validation loss: 1.742040732855438

Epoch: 6| Step: 1
Training loss: 0.07292105257511139
Validation loss: 1.722641816703222

Epoch: 6| Step: 2
Training loss: 0.07807338237762451
Validation loss: 1.6978716523416582

Epoch: 6| Step: 3
Training loss: 0.12418431788682938
Validation loss: 1.6906885818768573

Epoch: 6| Step: 4
Training loss: 0.0635715126991272
Validation loss: 1.6595132838013351

Epoch: 6| Step: 5
Training loss: 0.06111845746636391
Validation loss: 1.6656889966739121

Epoch: 6| Step: 6
Training loss: 0.047472041100263596
Validation loss: 1.6623278779368247

Epoch: 6| Step: 7
Training loss: 0.05587630346417427
Validation loss: 1.6716036386387323

Epoch: 6| Step: 8
Training loss: 0.06818577647209167
Validation loss: 1.6182433097593245

Epoch: 6| Step: 9
Training loss: 0.10846757143735886
Validation loss: 1.6310169389170985

Epoch: 6| Step: 10
Training loss: 0.07022087275981903
Validation loss: 1.6415734790986585

Epoch: 6| Step: 11
Training loss: 0.08918018639087677
Validation loss: 1.639405450513286

Epoch: 6| Step: 12
Training loss: 0.05115291848778725
Validation loss: 1.6032602043562039

Epoch: 6| Step: 13
Training loss: 0.07949671149253845
Validation loss: 1.6125441212807932

Epoch: 647| Step: 0
Training loss: 0.06403748691082001
Validation loss: 1.6463315589453584

Epoch: 6| Step: 1
Training loss: 0.04841304570436478
Validation loss: 1.6301749726777435

Epoch: 6| Step: 2
Training loss: 0.06251729279756546
Validation loss: 1.6252649112414288

Epoch: 6| Step: 3
Training loss: 0.08414851129055023
Validation loss: 1.655009881142647

Epoch: 6| Step: 4
Training loss: 0.15204015374183655
Validation loss: 1.6496885412482805

Epoch: 6| Step: 5
Training loss: 0.09260541945695877
Validation loss: 1.6485501194512973

Epoch: 6| Step: 6
Training loss: 0.06326142698526382
Validation loss: 1.6937151391019103

Epoch: 6| Step: 7
Training loss: 0.045059219002723694
Validation loss: 1.686578216091279

Epoch: 6| Step: 8
Training loss: 0.0706632137298584
Validation loss: 1.714793392406997

Epoch: 6| Step: 9
Training loss: 0.16982953250408173
Validation loss: 1.7051273392092796

Epoch: 6| Step: 10
Training loss: 0.049948737025260925
Validation loss: 1.7002246123488232

Epoch: 6| Step: 11
Training loss: 0.10476537048816681
Validation loss: 1.6992905703924035

Epoch: 6| Step: 12
Training loss: 0.0523417666554451
Validation loss: 1.6546798239472091

Epoch: 6| Step: 13
Training loss: 0.05932573974132538
Validation loss: 1.6434190888558664

Epoch: 648| Step: 0
Training loss: 0.07624910771846771
Validation loss: 1.6511296354314333

Epoch: 6| Step: 1
Training loss: 0.053569942712783813
Validation loss: 1.6122606620993665

Epoch: 6| Step: 2
Training loss: 0.06504198908805847
Validation loss: 1.6251359806265882

Epoch: 6| Step: 3
Training loss: 0.05137164518237114
Validation loss: 1.6211620876866002

Epoch: 6| Step: 4
Training loss: 0.07265986502170563
Validation loss: 1.6107043861061014

Epoch: 6| Step: 5
Training loss: 0.08041850477457047
Validation loss: 1.6073163734969271

Epoch: 6| Step: 6
Training loss: 0.0819588378071785
Validation loss: 1.6178845461978708

Epoch: 6| Step: 7
Training loss: 0.12802189588546753
Validation loss: 1.6292406653845182

Epoch: 6| Step: 8
Training loss: 0.07339530438184738
Validation loss: 1.6260675973789667

Epoch: 6| Step: 9
Training loss: 0.0775197371840477
Validation loss: 1.6132431696820002

Epoch: 6| Step: 10
Training loss: 0.05297383666038513
Validation loss: 1.6616599931511828

Epoch: 6| Step: 11
Training loss: 0.08148405700922012
Validation loss: 1.6657970618176203

Epoch: 6| Step: 12
Training loss: 0.055391717702150345
Validation loss: 1.6363056282843313

Epoch: 6| Step: 13
Training loss: 0.043529435992240906
Validation loss: 1.6516576415749007

Epoch: 649| Step: 0
Training loss: 0.13148483633995056
Validation loss: 1.6415560514696184

Epoch: 6| Step: 1
Training loss: 0.11703899502754211
Validation loss: 1.645651812194496

Epoch: 6| Step: 2
Training loss: 0.05159176141023636
Validation loss: 1.6269109146569365

Epoch: 6| Step: 3
Training loss: 0.08230432122945786
Validation loss: 1.6307326619343092

Epoch: 6| Step: 4
Training loss: 0.07197505235671997
Validation loss: 1.6016657647266184

Epoch: 6| Step: 5
Training loss: 0.11900057643651962
Validation loss: 1.593707702493155

Epoch: 6| Step: 6
Training loss: 0.22360742092132568
Validation loss: 1.580706456656097

Epoch: 6| Step: 7
Training loss: 0.12213283777236938
Validation loss: 1.5825757288163709

Epoch: 6| Step: 8
Training loss: 0.08522301912307739
Validation loss: 1.5990319123832129

Epoch: 6| Step: 9
Training loss: 0.11324073374271393
Validation loss: 1.6155137644019177

Epoch: 6| Step: 10
Training loss: 0.05870779603719711
Validation loss: 1.665070192788237

Epoch: 6| Step: 11
Training loss: 0.07251105457544327
Validation loss: 1.692321474834155

Epoch: 6| Step: 12
Training loss: 0.10108289122581482
Validation loss: 1.6867632481359667

Epoch: 6| Step: 13
Training loss: 0.07821124792098999
Validation loss: 1.6888084591075938

Epoch: 650| Step: 0
Training loss: 0.08849126845598221
Validation loss: 1.7352490284109627

Epoch: 6| Step: 1
Training loss: 0.052347905933856964
Validation loss: 1.7065470705750168

Epoch: 6| Step: 2
Training loss: 0.07540763914585114
Validation loss: 1.6931547323862712

Epoch: 6| Step: 3
Training loss: 0.06334911286830902
Validation loss: 1.6366741964893956

Epoch: 6| Step: 4
Training loss: 0.06366269290447235
Validation loss: 1.6571728837105535

Epoch: 6| Step: 5
Training loss: 0.05197310447692871
Validation loss: 1.6472393415307487

Epoch: 6| Step: 6
Training loss: 0.07649638503789902
Validation loss: 1.6398480323053175

Epoch: 6| Step: 7
Training loss: 0.06303849071264267
Validation loss: 1.6157512267430623

Epoch: 6| Step: 8
Training loss: 0.06588080525398254
Validation loss: 1.642413459798341

Epoch: 6| Step: 9
Training loss: 0.0953894555568695
Validation loss: 1.6106067677979827

Epoch: 6| Step: 10
Training loss: 0.10512766242027283
Validation loss: 1.644522286230518

Epoch: 6| Step: 11
Training loss: 0.06871593743562698
Validation loss: 1.6487538365907566

Epoch: 6| Step: 12
Training loss: 0.037294939160346985
Validation loss: 1.6521323425795442

Epoch: 6| Step: 13
Training loss: 0.03951858729124069
Validation loss: 1.6635978426984561

Testing loss: 2.100198147031996
