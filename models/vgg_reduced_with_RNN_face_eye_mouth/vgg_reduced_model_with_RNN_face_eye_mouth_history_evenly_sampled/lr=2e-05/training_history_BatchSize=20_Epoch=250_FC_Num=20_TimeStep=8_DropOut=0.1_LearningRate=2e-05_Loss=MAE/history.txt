Epoch: 1| Step: 0
Training loss: 4.8149895668029785
Validation loss: 5.192049344380696

Epoch: 5| Step: 1
Training loss: 5.470951080322266
Validation loss: 5.175521783931281

Epoch: 5| Step: 2
Training loss: 4.737141132354736
Validation loss: 5.161087195078532

Epoch: 5| Step: 3
Training loss: 4.378005027770996
Validation loss: 5.14396273192539

Epoch: 5| Step: 4
Training loss: 4.997032165527344
Validation loss: 5.1247386778554604

Epoch: 5| Step: 5
Training loss: 4.515922546386719
Validation loss: 5.102834896374774

Epoch: 5| Step: 6
Training loss: 4.795981407165527
Validation loss: 5.077720072961623

Epoch: 5| Step: 7
Training loss: 5.168365478515625
Validation loss: 5.05004418793545

Epoch: 5| Step: 8
Training loss: 5.3345627784729
Validation loss: 5.019036467357348

Epoch: 5| Step: 9
Training loss: 5.0480732917785645
Validation loss: 4.984968564843618

Epoch: 5| Step: 10
Training loss: 4.443805694580078
Validation loss: 4.946817146834507

Epoch: 2| Step: 0
Training loss: 3.2818045616149902
Validation loss: 4.906152191982474

Epoch: 5| Step: 1
Training loss: 5.175756931304932
Validation loss: 4.8601558439193235

Epoch: 5| Step: 2
Training loss: 4.899855136871338
Validation loss: 4.809718824202014

Epoch: 5| Step: 3
Training loss: 5.37897253036499
Validation loss: 4.755098999187511

Epoch: 5| Step: 4
Training loss: 3.8684868812561035
Validation loss: 4.69657866672803

Epoch: 5| Step: 5
Training loss: 4.839664459228516
Validation loss: 4.635612918484595

Epoch: 5| Step: 6
Training loss: 3.655625820159912
Validation loss: 4.57112988092566

Epoch: 5| Step: 7
Training loss: 4.4901580810546875
Validation loss: 4.50679293499198

Epoch: 5| Step: 8
Training loss: 3.4727981090545654
Validation loss: 4.442100494138656

Epoch: 5| Step: 9
Training loss: 5.585259437561035
Validation loss: 4.381648058532386

Epoch: 5| Step: 10
Training loss: 3.939225673675537
Validation loss: 4.325821422761487

Epoch: 3| Step: 0
Training loss: 3.8934197425842285
Validation loss: 4.273570324784966

Epoch: 5| Step: 1
Training loss: 5.020724296569824
Validation loss: 4.218312863380678

Epoch: 5| Step: 2
Training loss: 3.2036948204040527
Validation loss: 4.167254004427182

Epoch: 5| Step: 3
Training loss: 3.979177474975586
Validation loss: 4.121653156895792

Epoch: 5| Step: 4
Training loss: 3.9769222736358643
Validation loss: 4.08417550722758

Epoch: 5| Step: 5
Training loss: 3.9129631519317627
Validation loss: 4.048414691801994

Epoch: 5| Step: 6
Training loss: 3.243086338043213
Validation loss: 4.018417481453188

Epoch: 5| Step: 7
Training loss: 4.102334022521973
Validation loss: 3.9948477437419276

Epoch: 5| Step: 8
Training loss: 3.555309295654297
Validation loss: 3.9728696884647494

Epoch: 5| Step: 9
Training loss: 3.7033486366271973
Validation loss: 3.949255589515932

Epoch: 5| Step: 10
Training loss: 4.535762786865234
Validation loss: 3.92640447103849

Epoch: 4| Step: 0
Training loss: 2.769453287124634
Validation loss: 3.901656412309216

Epoch: 5| Step: 1
Training loss: 4.288625240325928
Validation loss: 3.8701167619356545

Epoch: 5| Step: 2
Training loss: 3.1882896423339844
Validation loss: 3.832243868099746

Epoch: 5| Step: 3
Training loss: 3.7195115089416504
Validation loss: 3.795079349189676

Epoch: 5| Step: 4
Training loss: 3.820946216583252
Validation loss: 3.7633095146507345

Epoch: 5| Step: 5
Training loss: 4.186891078948975
Validation loss: 3.7372919128787134

Epoch: 5| Step: 6
Training loss: 3.8439724445343018
Validation loss: 3.7184843350482244

Epoch: 5| Step: 7
Training loss: 4.165138244628906
Validation loss: 3.6908698363970687

Epoch: 5| Step: 8
Training loss: 2.450995922088623
Validation loss: 3.67807254996351

Epoch: 5| Step: 9
Training loss: 4.04990291595459
Validation loss: 3.6677723135999454

Epoch: 5| Step: 10
Training loss: 3.6398584842681885
Validation loss: 3.6445691354813112

Epoch: 5| Step: 0
Training loss: 3.8969314098358154
Validation loss: 3.6183241721122497

Epoch: 5| Step: 1
Training loss: 3.7756123542785645
Validation loss: 3.5938412450974986

Epoch: 5| Step: 2
Training loss: 4.062957286834717
Validation loss: 3.5706440761525142

Epoch: 5| Step: 3
Training loss: 2.664682626724243
Validation loss: 3.54947074767082

Epoch: 5| Step: 4
Training loss: 4.258177757263184
Validation loss: 3.5267177192113732

Epoch: 5| Step: 5
Training loss: 2.639179229736328
Validation loss: 3.5005671747269167

Epoch: 5| Step: 6
Training loss: 3.3826942443847656
Validation loss: 3.4895541796120266

Epoch: 5| Step: 7
Training loss: 3.393787384033203
Validation loss: 3.469327752308179

Epoch: 5| Step: 8
Training loss: 3.637575149536133
Validation loss: 3.4422457628352667

Epoch: 5| Step: 9
Training loss: 2.9421849250793457
Validation loss: 3.4371055095426497

Epoch: 5| Step: 10
Training loss: 3.2275283336639404
Validation loss: 3.427725099748181

Epoch: 6| Step: 0
Training loss: 3.877349853515625
Validation loss: 3.408984758520639

Epoch: 5| Step: 1
Training loss: 2.439270496368408
Validation loss: 3.3790105183919272

Epoch: 5| Step: 2
Training loss: 4.51605224609375
Validation loss: 3.3821800549825034

Epoch: 5| Step: 3
Training loss: 2.5444085597991943
Validation loss: 3.368968535495061

Epoch: 5| Step: 4
Training loss: 3.4119720458984375
Validation loss: 3.3464925058426394

Epoch: 5| Step: 5
Training loss: 3.7876598834991455
Validation loss: 3.326473920576034

Epoch: 5| Step: 6
Training loss: 2.9676413536071777
Validation loss: 3.318123068860782

Epoch: 5| Step: 7
Training loss: 3.413616180419922
Validation loss: 3.2986277534115698

Epoch: 5| Step: 8
Training loss: 3.1339821815490723
Validation loss: 3.278317159222018

Epoch: 5| Step: 9
Training loss: 2.90240216255188
Validation loss: 3.2681891892545964

Epoch: 5| Step: 10
Training loss: 3.3593149185180664
Validation loss: 3.262196522887035

Epoch: 7| Step: 0
Training loss: 3.1629676818847656
Validation loss: 3.2556817095766784

Epoch: 5| Step: 1
Training loss: 3.2453818321228027
Validation loss: 3.252256924106229

Epoch: 5| Step: 2
Training loss: 2.379526138305664
Validation loss: 3.2433079160669798

Epoch: 5| Step: 3
Training loss: 2.740288496017456
Validation loss: 3.2290263893783733

Epoch: 5| Step: 4
Training loss: 2.9963464736938477
Validation loss: 3.2166112340906614

Epoch: 5| Step: 5
Training loss: 3.5308425426483154
Validation loss: 3.20422855500252

Epoch: 5| Step: 6
Training loss: 3.4555068016052246
Validation loss: 3.19224371961368

Epoch: 5| Step: 7
Training loss: 3.063077211380005
Validation loss: 3.1962067183627876

Epoch: 5| Step: 8
Training loss: 4.169612407684326
Validation loss: 3.1733865455914567

Epoch: 5| Step: 9
Training loss: 2.44657826423645
Validation loss: 3.1705140682958786

Epoch: 5| Step: 10
Training loss: 4.200629234313965
Validation loss: 3.1734473654018935

Epoch: 8| Step: 0
Training loss: 2.9824929237365723
Validation loss: 3.1648671370680614

Epoch: 5| Step: 1
Training loss: 2.942603826522827
Validation loss: 3.1546473067293883

Epoch: 5| Step: 2
Training loss: 3.6366546154022217
Validation loss: 3.155417296194261

Epoch: 5| Step: 3
Training loss: 2.7745699882507324
Validation loss: 3.1364584789481214

Epoch: 5| Step: 4
Training loss: 3.459304094314575
Validation loss: 3.1270133013366372

Epoch: 5| Step: 5
Training loss: 3.230292558670044
Validation loss: 3.1211882099028556

Epoch: 5| Step: 6
Training loss: 3.3021953105926514
Validation loss: 3.111412427758658

Epoch: 5| Step: 7
Training loss: 3.143423557281494
Validation loss: 3.108690813023557

Epoch: 5| Step: 8
Training loss: 3.265956163406372
Validation loss: 3.100944221660655

Epoch: 5| Step: 9
Training loss: 3.0797219276428223
Validation loss: 3.0950950550776657

Epoch: 5| Step: 10
Training loss: 2.7175915241241455
Validation loss: 3.0900202874214417

Epoch: 9| Step: 0
Training loss: 3.7065834999084473
Validation loss: 3.085765861695813

Epoch: 5| Step: 1
Training loss: 3.447854995727539
Validation loss: 3.0811818543300835

Epoch: 5| Step: 2
Training loss: 3.32722544670105
Validation loss: 3.073546019933557

Epoch: 5| Step: 3
Training loss: 4.1476898193359375
Validation loss: 3.069165252870129

Epoch: 5| Step: 4
Training loss: 2.754056453704834
Validation loss: 3.0666705562222387

Epoch: 5| Step: 5
Training loss: 2.7805495262145996
Validation loss: 3.0602780772793676

Epoch: 5| Step: 6
Training loss: 2.2495386600494385
Validation loss: 3.055272897084554

Epoch: 5| Step: 7
Training loss: 1.8748477697372437
Validation loss: 3.0529103663659867

Epoch: 5| Step: 8
Training loss: 3.214407444000244
Validation loss: 3.049057350363783

Epoch: 5| Step: 9
Training loss: 2.915510892868042
Validation loss: 3.0455469290415444

Epoch: 5| Step: 10
Training loss: 3.8942387104034424
Validation loss: 3.0424723189364196

Epoch: 10| Step: 0
Training loss: 3.37164568901062
Validation loss: 3.0398991902669272

Epoch: 5| Step: 1
Training loss: 3.5041980743408203
Validation loss: 3.039654613823019

Epoch: 5| Step: 2
Training loss: 2.857591152191162
Validation loss: 3.0528603010280158

Epoch: 5| Step: 3
Training loss: 2.8391616344451904
Validation loss: 3.032723693437474

Epoch: 5| Step: 4
Training loss: 3.6877264976501465
Validation loss: 3.026131542780066

Epoch: 5| Step: 5
Training loss: 3.579864501953125
Validation loss: 3.024454370621712

Epoch: 5| Step: 6
Training loss: 2.6992602348327637
Validation loss: 3.022834603504468

Epoch: 5| Step: 7
Training loss: 3.1265032291412354
Validation loss: 3.018088356141121

Epoch: 5| Step: 8
Training loss: 2.643775224685669
Validation loss: 3.0141431182943363

Epoch: 5| Step: 9
Training loss: 2.7861456871032715
Validation loss: 3.014794367615895

Epoch: 5| Step: 10
Training loss: 2.7556309700012207
Validation loss: 3.012212207240443

Epoch: 11| Step: 0
Training loss: 2.6447722911834717
Validation loss: 3.0082021785038773

Epoch: 5| Step: 1
Training loss: 3.2679336071014404
Validation loss: 3.0055120119484524

Epoch: 5| Step: 2
Training loss: 3.2544188499450684
Validation loss: 3.0029218068686863

Epoch: 5| Step: 3
Training loss: 2.5356457233428955
Validation loss: 2.994063141525433

Epoch: 5| Step: 4
Training loss: 2.744908571243286
Validation loss: 2.991835319867698

Epoch: 5| Step: 5
Training loss: 3.9752612113952637
Validation loss: 2.9865778748707106

Epoch: 5| Step: 6
Training loss: 2.6954686641693115
Validation loss: 2.9843701034463863

Epoch: 5| Step: 7
Training loss: 3.3532919883728027
Validation loss: 2.981341077435401

Epoch: 5| Step: 8
Training loss: 3.1736674308776855
Validation loss: 2.978751038992277

Epoch: 5| Step: 9
Training loss: 3.25093150138855
Validation loss: 2.975158791388235

Epoch: 5| Step: 10
Training loss: 2.69620943069458
Validation loss: 2.9733872644362913

Epoch: 12| Step: 0
Training loss: 3.5394370555877686
Validation loss: 2.9703871434734714

Epoch: 5| Step: 1
Training loss: 2.9165825843811035
Validation loss: 2.96645164233382

Epoch: 5| Step: 2
Training loss: 3.658263683319092
Validation loss: 2.9641370029859644

Epoch: 5| Step: 3
Training loss: 3.0216221809387207
Validation loss: 2.957956139759351

Epoch: 5| Step: 4
Training loss: 2.8297278881073
Validation loss: 2.9551779018935336

Epoch: 5| Step: 5
Training loss: 3.3467299938201904
Validation loss: 2.9519784963259132

Epoch: 5| Step: 6
Training loss: 3.236262559890747
Validation loss: 2.9467605929220877

Epoch: 5| Step: 7
Training loss: 3.253676652908325
Validation loss: 2.9450031506117953

Epoch: 5| Step: 8
Training loss: 2.8115763664245605
Validation loss: 2.9479781786600747

Epoch: 5| Step: 9
Training loss: 2.491995334625244
Validation loss: 2.94918159515627

Epoch: 5| Step: 10
Training loss: 2.193814277648926
Validation loss: 3.0044111615868023

Epoch: 13| Step: 0
Training loss: 2.5263404846191406
Validation loss: 3.012463205604143

Epoch: 5| Step: 1
Training loss: 3.001136541366577
Validation loss: 3.014357095123619

Epoch: 5| Step: 2
Training loss: 3.0853216648101807
Validation loss: 3.014887058606712

Epoch: 5| Step: 3
Training loss: 2.5472612380981445
Validation loss: 3.0119644211184595

Epoch: 5| Step: 4
Training loss: 3.674193859100342
Validation loss: 3.007974032432802

Epoch: 5| Step: 5
Training loss: 2.6451892852783203
Validation loss: 3.004679513233964

Epoch: 5| Step: 6
Training loss: 3.1489028930664062
Validation loss: 3.0023068945894957

Epoch: 5| Step: 7
Training loss: 3.240016460418701
Validation loss: 2.9996719847443285

Epoch: 5| Step: 8
Training loss: 3.4315733909606934
Validation loss: 2.9971730632166707

Epoch: 5| Step: 9
Training loss: 3.547597885131836
Validation loss: 2.9949350587783323

Epoch: 5| Step: 10
Training loss: 2.8946950435638428
Validation loss: 2.9930346729934856

Epoch: 14| Step: 0
Training loss: 3.6882290840148926
Validation loss: 2.991324396543605

Epoch: 5| Step: 1
Training loss: 3.688566207885742
Validation loss: 2.9873441188566145

Epoch: 5| Step: 2
Training loss: 3.185986042022705
Validation loss: 2.986124938534152

Epoch: 5| Step: 3
Training loss: 2.6551270484924316
Validation loss: 2.9845061661094747

Epoch: 5| Step: 4
Training loss: 3.2699406147003174
Validation loss: 2.979950527991018

Epoch: 5| Step: 5
Training loss: 2.8298556804656982
Validation loss: 2.979001986083164

Epoch: 5| Step: 6
Training loss: 3.0254502296447754
Validation loss: 2.975483686693253

Epoch: 5| Step: 7
Training loss: 2.821317434310913
Validation loss: 2.9737013283596245

Epoch: 5| Step: 8
Training loss: 2.8715946674346924
Validation loss: 2.9715243821503012

Epoch: 5| Step: 9
Training loss: 2.619905948638916
Validation loss: 2.9723952816378687

Epoch: 5| Step: 10
Training loss: 2.9151365756988525
Validation loss: 2.967627981657623

Epoch: 15| Step: 0
Training loss: 3.2204749584198
Validation loss: 2.9649572167345273

Epoch: 5| Step: 1
Training loss: 3.404191493988037
Validation loss: 2.960526740679177

Epoch: 5| Step: 2
Training loss: 2.681854724884033
Validation loss: 2.9606390127571682

Epoch: 5| Step: 3
Training loss: 2.6886801719665527
Validation loss: 2.960488163014894

Epoch: 5| Step: 4
Training loss: 2.987326145172119
Validation loss: 2.9579553963035665

Epoch: 5| Step: 5
Training loss: 3.1389224529266357
Validation loss: 2.9555424823555896

Epoch: 5| Step: 6
Training loss: 3.015820264816284
Validation loss: 2.952460571001935

Epoch: 5| Step: 7
Training loss: 3.147585391998291
Validation loss: 2.9530733734048824

Epoch: 5| Step: 8
Training loss: 3.426715135574341
Validation loss: 2.9522994590061966

Epoch: 5| Step: 9
Training loss: 3.1485214233398438
Validation loss: 2.9466013959659043

Epoch: 5| Step: 10
Training loss: 2.4700815677642822
Validation loss: 2.9441302386663293

Epoch: 16| Step: 0
Training loss: 2.950888156890869
Validation loss: 2.943163089854743

Epoch: 5| Step: 1
Training loss: 2.849756956100464
Validation loss: 2.9416746247199272

Epoch: 5| Step: 2
Training loss: 2.4819300174713135
Validation loss: 2.939624232630576

Epoch: 5| Step: 3
Training loss: 3.9172275066375732
Validation loss: 2.9393812405165805

Epoch: 5| Step: 4
Training loss: 3.2876219749450684
Validation loss: 2.9386138480196715

Epoch: 5| Step: 5
Training loss: 2.774275302886963
Validation loss: 2.9366991032836256

Epoch: 5| Step: 6
Training loss: 3.6141083240509033
Validation loss: 2.9350815947337816

Epoch: 5| Step: 7
Training loss: 2.5354080200195312
Validation loss: 2.9323452262468237

Epoch: 5| Step: 8
Training loss: 2.6264140605926514
Validation loss: 2.930664493191627

Epoch: 5| Step: 9
Training loss: 3.3837852478027344
Validation loss: 2.9298137951922674

Epoch: 5| Step: 10
Training loss: 2.8179893493652344
Validation loss: 2.928409989162158

Epoch: 17| Step: 0
Training loss: 2.684931993484497
Validation loss: 2.9277306628483597

Epoch: 5| Step: 1
Training loss: 2.316148042678833
Validation loss: 2.9263838414222962

Epoch: 5| Step: 2
Training loss: 3.4082183837890625
Validation loss: 2.924494448528495

Epoch: 5| Step: 3
Training loss: 2.6742167472839355
Validation loss: 2.922985262768243

Epoch: 5| Step: 4
Training loss: 3.008596897125244
Validation loss: 2.921581983566284

Epoch: 5| Step: 5
Training loss: 3.4603848457336426
Validation loss: 2.9202035703966693

Epoch: 5| Step: 6
Training loss: 3.2297871112823486
Validation loss: 2.9191196451904955

Epoch: 5| Step: 7
Training loss: 3.550389051437378
Validation loss: 2.9177016135184997

Epoch: 5| Step: 8
Training loss: 2.526817798614502
Validation loss: 2.9162871068523777

Epoch: 5| Step: 9
Training loss: 3.3609766960144043
Validation loss: 2.914780757760489

Epoch: 5| Step: 10
Training loss: 2.919069290161133
Validation loss: 2.913741288646575

Epoch: 18| Step: 0
Training loss: 2.772125720977783
Validation loss: 2.912086291979718

Epoch: 5| Step: 1
Training loss: 3.504570484161377
Validation loss: 2.9099452777575423

Epoch: 5| Step: 2
Training loss: 2.507737159729004
Validation loss: 2.908822436486521

Epoch: 5| Step: 3
Training loss: 2.910857677459717
Validation loss: 2.9080999564099055

Epoch: 5| Step: 4
Training loss: 2.988393545150757
Validation loss: 2.90711554404228

Epoch: 5| Step: 5
Training loss: 2.631289005279541
Validation loss: 2.907474669077063

Epoch: 5| Step: 6
Training loss: 2.809746742248535
Validation loss: 2.9048501958129225

Epoch: 5| Step: 7
Training loss: 3.9686717987060547
Validation loss: 2.9026665892652286

Epoch: 5| Step: 8
Training loss: 2.6161108016967773
Validation loss: 2.9013501982535086

Epoch: 5| Step: 9
Training loss: 3.245769500732422
Validation loss: 2.903541588014172

Epoch: 5| Step: 10
Training loss: 3.111361265182495
Validation loss: 2.899415087956254

Epoch: 19| Step: 0
Training loss: 2.698106288909912
Validation loss: 2.8990906541065504

Epoch: 5| Step: 1
Training loss: 3.6805267333984375
Validation loss: 2.8992900310024137

Epoch: 5| Step: 2
Training loss: 2.8144235610961914
Validation loss: 2.9027523891900175

Epoch: 5| Step: 3
Training loss: 3.1558520793914795
Validation loss: 2.8957426214730866

Epoch: 5| Step: 4
Training loss: 3.0911307334899902
Validation loss: 2.8959802863418416

Epoch: 5| Step: 5
Training loss: 2.9134764671325684
Validation loss: 2.8930505219326226

Epoch: 5| Step: 6
Training loss: 3.1463623046875
Validation loss: 2.891529562652752

Epoch: 5| Step: 7
Training loss: 3.271134853363037
Validation loss: 2.890601235051309

Epoch: 5| Step: 8
Training loss: 2.6360983848571777
Validation loss: 2.889500279580393

Epoch: 5| Step: 9
Training loss: 2.593534231185913
Validation loss: 2.8877050774071806

Epoch: 5| Step: 10
Training loss: 2.9655659198760986
Validation loss: 2.887709750924059

Epoch: 20| Step: 0
Training loss: 3.1923162937164307
Validation loss: 2.8840018164726997

Epoch: 5| Step: 1
Training loss: 2.966569185256958
Validation loss: 2.882673595541267

Epoch: 5| Step: 2
Training loss: 2.785987138748169
Validation loss: 2.881139632194273

Epoch: 5| Step: 3
Training loss: 2.7893567085266113
Validation loss: 2.8805902286242415

Epoch: 5| Step: 4
Training loss: 3.3633720874786377
Validation loss: 2.8792510135199434

Epoch: 5| Step: 5
Training loss: 2.807188034057617
Validation loss: 2.8780392011006675

Epoch: 5| Step: 6
Training loss: 2.0409178733825684
Validation loss: 2.876924258406444

Epoch: 5| Step: 7
Training loss: 3.1323392391204834
Validation loss: 2.875855356134394

Epoch: 5| Step: 8
Training loss: 3.948681592941284
Validation loss: 2.875235762647403

Epoch: 5| Step: 9
Training loss: 2.5579848289489746
Validation loss: 2.8722365697224936

Epoch: 5| Step: 10
Training loss: 3.3200130462646484
Validation loss: 2.8712895326716925

Epoch: 21| Step: 0
Training loss: 3.6227524280548096
Validation loss: 2.8686566865572365

Epoch: 5| Step: 1
Training loss: 2.650024175643921
Validation loss: 2.867159999826903

Epoch: 5| Step: 2
Training loss: 2.2621071338653564
Validation loss: 2.8682606681700675

Epoch: 5| Step: 3
Training loss: 3.636918544769287
Validation loss: 2.8659626796681392

Epoch: 5| Step: 4
Training loss: 2.4953830242156982
Validation loss: 2.866255839665731

Epoch: 5| Step: 5
Training loss: 2.595811367034912
Validation loss: 2.8633453692159345

Epoch: 5| Step: 6
Training loss: 3.675593137741089
Validation loss: 2.8625774511726956

Epoch: 5| Step: 7
Training loss: 2.690793991088867
Validation loss: 2.8603806546939317

Epoch: 5| Step: 8
Training loss: 3.643996477127075
Validation loss: 2.8586097840339906

Epoch: 5| Step: 9
Training loss: 2.6488735675811768
Validation loss: 2.8567859408675984

Epoch: 5| Step: 10
Training loss: 2.7962048053741455
Validation loss: 2.8533235493526665

Epoch: 22| Step: 0
Training loss: 2.845973491668701
Validation loss: 2.8518784071809504

Epoch: 5| Step: 1
Training loss: 3.2723631858825684
Validation loss: 2.8477280139923096

Epoch: 5| Step: 2
Training loss: 2.0119693279266357
Validation loss: 2.8462571636323006

Epoch: 5| Step: 3
Training loss: 2.643173933029175
Validation loss: 2.844029449647473

Epoch: 5| Step: 4
Training loss: 2.912217378616333
Validation loss: 2.8471948510857037

Epoch: 5| Step: 5
Training loss: 2.704991579055786
Validation loss: 2.8437005012266097

Epoch: 5| Step: 6
Training loss: 2.9281952381134033
Validation loss: 2.8424883247703634

Epoch: 5| Step: 7
Training loss: 3.418661117553711
Validation loss: 2.844803099991173

Epoch: 5| Step: 8
Training loss: 2.979714870452881
Validation loss: 2.8420196528075845

Epoch: 5| Step: 9
Training loss: 3.681447982788086
Validation loss: 2.8359379819644395

Epoch: 5| Step: 10
Training loss: 3.2440714836120605
Validation loss: 2.835456648180562

Epoch: 23| Step: 0
Training loss: 2.9500961303710938
Validation loss: 2.8353433429553943

Epoch: 5| Step: 1
Training loss: 2.877201795578003
Validation loss: 2.8344970364724436

Epoch: 5| Step: 2
Training loss: 3.1803154945373535
Validation loss: 2.8326973504917596

Epoch: 5| Step: 3
Training loss: 2.7912700176239014
Validation loss: 2.83178614031884

Epoch: 5| Step: 4
Training loss: 2.0633492469787598
Validation loss: 2.8314015326961393

Epoch: 5| Step: 5
Training loss: 3.265911817550659
Validation loss: 2.830350498999319

Epoch: 5| Step: 6
Training loss: 2.637716770172119
Validation loss: 2.8286182572764735

Epoch: 5| Step: 7
Training loss: 3.323673963546753
Validation loss: 2.827690739785471

Epoch: 5| Step: 8
Training loss: 2.860027313232422
Validation loss: 2.8262322333551224

Epoch: 5| Step: 9
Training loss: 3.3861923217773438
Validation loss: 2.8255797355405745

Epoch: 5| Step: 10
Training loss: 3.2111291885375977
Validation loss: 2.8242778675530547

Epoch: 24| Step: 0
Training loss: 3.0137836933135986
Validation loss: 2.8231111880271667

Epoch: 5| Step: 1
Training loss: 2.7834267616271973
Validation loss: 2.8222259321520404

Epoch: 5| Step: 2
Training loss: 2.4383907318115234
Validation loss: 2.821331777880269

Epoch: 5| Step: 3
Training loss: 2.306091547012329
Validation loss: 2.8202750554648777

Epoch: 5| Step: 4
Training loss: 3.670846939086914
Validation loss: 2.8192563672219553

Epoch: 5| Step: 5
Training loss: 3.1671855449676514
Validation loss: 2.817680666523595

Epoch: 5| Step: 6
Training loss: 3.2948689460754395
Validation loss: 2.8169277739781204

Epoch: 5| Step: 7
Training loss: 3.0543415546417236
Validation loss: 2.8160437922323904

Epoch: 5| Step: 8
Training loss: 2.889674663543701
Validation loss: 2.815178358426658

Epoch: 5| Step: 9
Training loss: 3.1563291549682617
Validation loss: 2.8144101045464955

Epoch: 5| Step: 10
Training loss: 2.5949461460113525
Validation loss: 2.8136159373867895

Epoch: 25| Step: 0
Training loss: 3.3874778747558594
Validation loss: 2.8128403104761595

Epoch: 5| Step: 1
Training loss: 3.9686942100524902
Validation loss: 2.8119845749229513

Epoch: 5| Step: 2
Training loss: 3.2434887886047363
Validation loss: 2.8112297006832656

Epoch: 5| Step: 3
Training loss: 2.1884822845458984
Validation loss: 2.8097130970288346

Epoch: 5| Step: 4
Training loss: 2.5749921798706055
Validation loss: 2.8091404771292083

Epoch: 5| Step: 5
Training loss: 3.139047622680664
Validation loss: 2.808073043823242

Epoch: 5| Step: 6
Training loss: 2.053598403930664
Validation loss: 2.8073064665640555

Epoch: 5| Step: 7
Training loss: 3.5252749919891357
Validation loss: 2.806737228106427

Epoch: 5| Step: 8
Training loss: 3.1275973320007324
Validation loss: 2.810001314327281

Epoch: 5| Step: 9
Training loss: 2.082825183868408
Validation loss: 2.80855586964597

Epoch: 5| Step: 10
Training loss: 3.087306499481201
Validation loss: 2.8047035278812533

Epoch: 26| Step: 0
Training loss: 2.8667168617248535
Validation loss: 2.8033670943270446

Epoch: 5| Step: 1
Training loss: 3.246401309967041
Validation loss: 2.8028995272933797

Epoch: 5| Step: 2
Training loss: 3.164957284927368
Validation loss: 2.8019462862322406

Epoch: 5| Step: 3
Training loss: 3.2063522338867188
Validation loss: 2.8001953991510535

Epoch: 5| Step: 4
Training loss: 2.982844591140747
Validation loss: 2.800781383309313

Epoch: 5| Step: 5
Training loss: 3.523836851119995
Validation loss: 2.798186453439856

Epoch: 5| Step: 6
Training loss: 2.8016128540039062
Validation loss: 2.7972074144630024

Epoch: 5| Step: 7
Training loss: 2.549046516418457
Validation loss: 2.7994385150171097

Epoch: 5| Step: 8
Training loss: 1.9702295064926147
Validation loss: 2.797032217825613

Epoch: 5| Step: 9
Training loss: 2.693258762359619
Validation loss: 2.79744488962235

Epoch: 5| Step: 10
Training loss: 3.3632211685180664
Validation loss: 2.7970648273344962

Epoch: 27| Step: 0
Training loss: 3.2598443031311035
Validation loss: 2.7976700029065533

Epoch: 5| Step: 1
Training loss: 3.2570278644561768
Validation loss: 2.7961512534849104

Epoch: 5| Step: 2
Training loss: 3.148621082305908
Validation loss: 2.795024574443858

Epoch: 5| Step: 3
Training loss: 2.976266622543335
Validation loss: 2.7944478296464488

Epoch: 5| Step: 4
Training loss: 2.530963659286499
Validation loss: 2.7935647785022693

Epoch: 5| Step: 5
Training loss: 2.659061908721924
Validation loss: 2.7927039515587593

Epoch: 5| Step: 6
Training loss: 2.9678735733032227
Validation loss: 2.7918381665342595

Epoch: 5| Step: 7
Training loss: 3.1436350345611572
Validation loss: 2.7909453581738215

Epoch: 5| Step: 8
Training loss: 3.1602649688720703
Validation loss: 2.790744532820999

Epoch: 5| Step: 9
Training loss: 2.933138847351074
Validation loss: 2.790041877377418

Epoch: 5| Step: 10
Training loss: 2.0797109603881836
Validation loss: 2.7898036049258326

Epoch: 28| Step: 0
Training loss: 3.0442745685577393
Validation loss: 2.7896220735324326

Epoch: 5| Step: 1
Training loss: 3.3441529273986816
Validation loss: 2.788259357534429

Epoch: 5| Step: 2
Training loss: 2.8355772495269775
Validation loss: 2.787367033702071

Epoch: 5| Step: 3
Training loss: 2.9544179439544678
Validation loss: 2.786589281533354

Epoch: 5| Step: 4
Training loss: 2.7554304599761963
Validation loss: 2.7859348968792985

Epoch: 5| Step: 5
Training loss: 2.607323169708252
Validation loss: 2.7855983754639984

Epoch: 5| Step: 6
Training loss: 2.7354557514190674
Validation loss: 2.784394277039395

Epoch: 5| Step: 7
Training loss: 3.357603073120117
Validation loss: 2.7837287149121686

Epoch: 5| Step: 8
Training loss: 3.1253371238708496
Validation loss: 2.7832284691513225

Epoch: 5| Step: 9
Training loss: 2.768016815185547
Validation loss: 2.7832117388325353

Epoch: 5| Step: 10
Training loss: 2.6179473400115967
Validation loss: 2.782131879560409

Epoch: 29| Step: 0
Training loss: 2.2952468395233154
Validation loss: 2.7820487124945528

Epoch: 5| Step: 1
Training loss: 3.169036865234375
Validation loss: 2.780815342421173

Epoch: 5| Step: 2
Training loss: 3.4645354747772217
Validation loss: 2.78058059113

Epoch: 5| Step: 3
Training loss: 2.9864110946655273
Validation loss: 2.779598133538359

Epoch: 5| Step: 4
Training loss: 3.117352247238159
Validation loss: 2.7794787973485966

Epoch: 5| Step: 5
Training loss: 3.246607542037964
Validation loss: 2.778421337886523

Epoch: 5| Step: 6
Training loss: 3.0408363342285156
Validation loss: 2.777237243549798

Epoch: 5| Step: 7
Training loss: 2.91890025138855
Validation loss: 2.777068107358871

Epoch: 5| Step: 8
Training loss: 2.349752902984619
Validation loss: 2.776667384691136

Epoch: 5| Step: 9
Training loss: 2.9198226928710938
Validation loss: 2.775893921493202

Epoch: 5| Step: 10
Training loss: 2.581197738647461
Validation loss: 2.7750552879866732

Epoch: 30| Step: 0
Training loss: 2.953075408935547
Validation loss: 2.774322453365531

Epoch: 5| Step: 1
Training loss: 2.746182918548584
Validation loss: 2.7737339030029955

Epoch: 5| Step: 2
Training loss: 3.5560126304626465
Validation loss: 2.7736509000101397

Epoch: 5| Step: 3
Training loss: 2.6141512393951416
Validation loss: 2.7731611010848836

Epoch: 5| Step: 4
Training loss: 2.916043281555176
Validation loss: 2.7723885633612193

Epoch: 5| Step: 5
Training loss: 2.5671496391296387
Validation loss: 2.7715487044344664

Epoch: 5| Step: 6
Training loss: 2.725594997406006
Validation loss: 2.7705291958265406

Epoch: 5| Step: 7
Training loss: 3.121473550796509
Validation loss: 2.770212273443899

Epoch: 5| Step: 8
Training loss: 2.8161137104034424
Validation loss: 2.769914222019975

Epoch: 5| Step: 9
Training loss: 3.0683553218841553
Validation loss: 2.769747826360887

Epoch: 5| Step: 10
Training loss: 3.0152812004089355
Validation loss: 2.7683225754768617

Epoch: 31| Step: 0
Training loss: 2.498119831085205
Validation loss: 2.767801220699023

Epoch: 5| Step: 1
Training loss: 2.677719831466675
Validation loss: 2.767329390330981

Epoch: 5| Step: 2
Training loss: 3.5847811698913574
Validation loss: 2.767309714389104

Epoch: 5| Step: 3
Training loss: 2.947715997695923
Validation loss: 2.766662025964388

Epoch: 5| Step: 4
Training loss: 2.8586249351501465
Validation loss: 2.766012604518603

Epoch: 5| Step: 5
Training loss: 3.254187822341919
Validation loss: 2.765223382621683

Epoch: 5| Step: 6
Training loss: 2.9112846851348877
Validation loss: 2.764542107941002

Epoch: 5| Step: 7
Training loss: 2.4030327796936035
Validation loss: 2.7640926889193955

Epoch: 5| Step: 8
Training loss: 2.3123726844787598
Validation loss: 2.763155873103808

Epoch: 5| Step: 9
Training loss: 3.0452003479003906
Validation loss: 2.762916813614548

Epoch: 5| Step: 10
Training loss: 3.6516759395599365
Validation loss: 2.7620801797477146

Epoch: 32| Step: 0
Training loss: 2.8340556621551514
Validation loss: 2.761418560499786

Epoch: 5| Step: 1
Training loss: 1.973109483718872
Validation loss: 2.760940913231142

Epoch: 5| Step: 2
Training loss: 3.4065184593200684
Validation loss: 2.7604436387297926

Epoch: 5| Step: 3
Training loss: 3.322396755218506
Validation loss: 2.759676951234059

Epoch: 5| Step: 4
Training loss: 2.7519006729125977
Validation loss: 2.7588764108637327

Epoch: 5| Step: 5
Training loss: 3.0425643920898438
Validation loss: 2.7589796666176087

Epoch: 5| Step: 6
Training loss: 2.4585158824920654
Validation loss: 2.758735243992139

Epoch: 5| Step: 7
Training loss: 2.617056369781494
Validation loss: 2.758055353677401

Epoch: 5| Step: 8
Training loss: 3.6330981254577637
Validation loss: 2.7569475814860356

Epoch: 5| Step: 9
Training loss: 3.13783597946167
Validation loss: 2.756308368457261

Epoch: 5| Step: 10
Training loss: 2.7857658863067627
Validation loss: 2.7557280448175248

Epoch: 33| Step: 0
Training loss: 3.121363401412964
Validation loss: 2.7538622040902414

Epoch: 5| Step: 1
Training loss: 2.701319456100464
Validation loss: 2.75465960912807

Epoch: 5| Step: 2
Training loss: 2.3133678436279297
Validation loss: 2.7527767355724047

Epoch: 5| Step: 3
Training loss: 2.811359167098999
Validation loss: 2.7533458509752826

Epoch: 5| Step: 4
Training loss: 2.894315004348755
Validation loss: 2.7530205570241457

Epoch: 5| Step: 5
Training loss: 2.772852659225464
Validation loss: 2.7513092692180345

Epoch: 5| Step: 6
Training loss: 3.2282681465148926
Validation loss: 2.7513434579295497

Epoch: 5| Step: 7
Training loss: 2.622992753982544
Validation loss: 2.750101791915073

Epoch: 5| Step: 8
Training loss: 3.467348575592041
Validation loss: 2.7498206861557497

Epoch: 5| Step: 9
Training loss: 3.104158401489258
Validation loss: 2.749110137262652

Epoch: 5| Step: 10
Training loss: 2.8942437171936035
Validation loss: 2.7493957242658063

Epoch: 34| Step: 0
Training loss: 2.7822184562683105
Validation loss: 2.748534530721685

Epoch: 5| Step: 1
Training loss: 3.1978461742401123
Validation loss: 2.748162564410958

Epoch: 5| Step: 2
Training loss: 3.083510637283325
Validation loss: 2.747556486437398

Epoch: 5| Step: 3
Training loss: 3.0991690158843994
Validation loss: 2.7466659904808126

Epoch: 5| Step: 4
Training loss: 2.3758544921875
Validation loss: 2.745952331891624

Epoch: 5| Step: 5
Training loss: 2.109926462173462
Validation loss: 2.7461463405239965

Epoch: 5| Step: 6
Training loss: 3.1641957759857178
Validation loss: 2.7452967192537043

Epoch: 5| Step: 7
Training loss: 2.487353801727295
Validation loss: 2.7444173802611647

Epoch: 5| Step: 8
Training loss: 3.2403812408447266
Validation loss: 2.7438676716178976

Epoch: 5| Step: 9
Training loss: 3.069455862045288
Validation loss: 2.7424612122197307

Epoch: 5| Step: 10
Training loss: 3.3426623344421387
Validation loss: 2.741383955042849

Epoch: 35| Step: 0
Training loss: 2.3904964923858643
Validation loss: 2.7422400905239965

Epoch: 5| Step: 1
Training loss: 2.5851292610168457
Validation loss: 2.741190892393871

Epoch: 5| Step: 2
Training loss: 3.678847551345825
Validation loss: 2.740734964288691

Epoch: 5| Step: 3
Training loss: 2.613149881362915
Validation loss: 2.7405037059578845

Epoch: 5| Step: 4
Training loss: 2.9728686809539795
Validation loss: 2.7395273408582135

Epoch: 5| Step: 5
Training loss: 2.5069682598114014
Validation loss: 2.7396230851450274

Epoch: 5| Step: 6
Training loss: 3.2272465229034424
Validation loss: 2.739407347094628

Epoch: 5| Step: 7
Training loss: 2.780097723007202
Validation loss: 2.7390539748694307

Epoch: 5| Step: 8
Training loss: 2.897160768508911
Validation loss: 2.7388216731368855

Epoch: 5| Step: 9
Training loss: 2.8636813163757324
Validation loss: 2.738080591283819

Epoch: 5| Step: 10
Training loss: 3.4059994220733643
Validation loss: 2.7373687426249185

Epoch: 36| Step: 0
Training loss: 2.900146007537842
Validation loss: 2.7369979453343216

Epoch: 5| Step: 1
Training loss: 2.9163155555725098
Validation loss: 2.735979151982133

Epoch: 5| Step: 2
Training loss: 2.6563143730163574
Validation loss: 2.735967436144429

Epoch: 5| Step: 3
Training loss: 2.4524173736572266
Validation loss: 2.734598908373105

Epoch: 5| Step: 4
Training loss: 3.329620838165283
Validation loss: 2.733861833490351

Epoch: 5| Step: 5
Training loss: 2.5549423694610596
Validation loss: 2.733570568023189

Epoch: 5| Step: 6
Training loss: 3.2377846240997314
Validation loss: 2.7329876961246615

Epoch: 5| Step: 7
Training loss: 2.8120510578155518
Validation loss: 2.7321020146851898

Epoch: 5| Step: 8
Training loss: 2.809816837310791
Validation loss: 2.732064426586192

Epoch: 5| Step: 9
Training loss: 3.4153778553009033
Validation loss: 2.731832465817851

Epoch: 5| Step: 10
Training loss: 2.6870453357696533
Validation loss: 2.73067730985662

Epoch: 37| Step: 0
Training loss: 2.3120150566101074
Validation loss: 2.730731935911281

Epoch: 5| Step: 1
Training loss: 2.5387942790985107
Validation loss: 2.7298716063140542

Epoch: 5| Step: 2
Training loss: 2.996203899383545
Validation loss: 2.729718562095396

Epoch: 5| Step: 3
Training loss: 3.383883237838745
Validation loss: 2.7293549763259066

Epoch: 5| Step: 4
Training loss: 2.6781418323516846
Validation loss: 2.727688912422426

Epoch: 5| Step: 5
Training loss: 2.9300665855407715
Validation loss: 2.728089596635552

Epoch: 5| Step: 6
Training loss: 3.292537212371826
Validation loss: 2.7270351481694046

Epoch: 5| Step: 7
Training loss: 2.976433753967285
Validation loss: 2.7264204050904963

Epoch: 5| Step: 8
Training loss: 3.135723829269409
Validation loss: 2.7261605262756348

Epoch: 5| Step: 9
Training loss: 2.565556764602661
Validation loss: 2.7251681204765075

Epoch: 5| Step: 10
Training loss: 2.9633946418762207
Validation loss: 2.7249456323603147

Epoch: 38| Step: 0
Training loss: 3.1254525184631348
Validation loss: 2.7241116595524613

Epoch: 5| Step: 1
Training loss: 2.814469814300537
Validation loss: 2.7241503064350416

Epoch: 5| Step: 2
Training loss: 2.9256956577301025
Validation loss: 2.724157153919179

Epoch: 5| Step: 3
Training loss: 3.0583910942077637
Validation loss: 2.7223871754061792

Epoch: 5| Step: 4
Training loss: 3.4576315879821777
Validation loss: 2.7212661235563216

Epoch: 5| Step: 5
Training loss: 2.494758367538452
Validation loss: 2.7218373231990363

Epoch: 5| Step: 6
Training loss: 2.576202392578125
Validation loss: 2.720569451649984

Epoch: 5| Step: 7
Training loss: 2.571211576461792
Validation loss: 2.7199376526699273

Epoch: 5| Step: 8
Training loss: 2.558931827545166
Validation loss: 2.7177762959593084

Epoch: 5| Step: 9
Training loss: 2.1775450706481934
Validation loss: 2.7192581058830343

Epoch: 5| Step: 10
Training loss: 4.143811225891113
Validation loss: 2.718964297284362

Epoch: 39| Step: 0
Training loss: 2.503274440765381
Validation loss: 2.718380202529251

Epoch: 5| Step: 1
Training loss: 2.9499287605285645
Validation loss: 2.717048252782514

Epoch: 5| Step: 2
Training loss: 3.5778777599334717
Validation loss: 2.716003530768938

Epoch: 5| Step: 3
Training loss: 2.7309937477111816
Validation loss: 2.7156798173022527

Epoch: 5| Step: 4
Training loss: 3.1950364112854004
Validation loss: 2.7147486235505793

Epoch: 5| Step: 5
Training loss: 2.57378888130188
Validation loss: 2.711893814866261

Epoch: 5| Step: 6
Training loss: 2.140347957611084
Validation loss: 2.7089303975464194

Epoch: 5| Step: 7
Training loss: 3.660027265548706
Validation loss: 2.7095147819929224

Epoch: 5| Step: 8
Training loss: 2.4947876930236816
Validation loss: 2.7114469825580554

Epoch: 5| Step: 9
Training loss: 2.6641666889190674
Validation loss: 2.7134409950625513

Epoch: 5| Step: 10
Training loss: 3.2366526126861572
Validation loss: 2.7120115756988525

Epoch: 40| Step: 0
Training loss: 2.9358177185058594
Validation loss: 2.7127871026274977

Epoch: 5| Step: 1
Training loss: 2.2644238471984863
Validation loss: 2.7132231753359557

Epoch: 5| Step: 2
Training loss: 2.913936138153076
Validation loss: 2.7141110435608895

Epoch: 5| Step: 3
Training loss: 3.457223415374756
Validation loss: 2.717301571240989

Epoch: 5| Step: 4
Training loss: 3.1394848823547363
Validation loss: 2.7096868945706274

Epoch: 5| Step: 5
Training loss: 3.031606912612915
Validation loss: 2.709490288970291

Epoch: 5| Step: 6
Training loss: 3.1525027751922607
Validation loss: 2.709023206464706

Epoch: 5| Step: 7
Training loss: 2.6531434059143066
Validation loss: 2.708520602154475

Epoch: 5| Step: 8
Training loss: 2.861532688140869
Validation loss: 2.7082903026252665

Epoch: 5| Step: 9
Training loss: 2.210385799407959
Validation loss: 2.707691090081328

Epoch: 5| Step: 10
Training loss: 3.0387542247772217
Validation loss: 2.707598473436089

Epoch: 41| Step: 0
Training loss: 3.4493889808654785
Validation loss: 2.7072083719315065

Epoch: 5| Step: 1
Training loss: 2.2639660835266113
Validation loss: 2.702862749817551

Epoch: 5| Step: 2
Training loss: 3.0074100494384766
Validation loss: 2.7053451922632035

Epoch: 5| Step: 3
Training loss: 3.317396640777588
Validation loss: 2.7042934048560356

Epoch: 5| Step: 4
Training loss: 3.3850631713867188
Validation loss: 2.7029845150568153

Epoch: 5| Step: 5
Training loss: 2.43585205078125
Validation loss: 2.699806818398096

Epoch: 5| Step: 6
Training loss: 2.3599820137023926
Validation loss: 2.698564903710478

Epoch: 5| Step: 7
Training loss: 2.866495132446289
Validation loss: 2.698306396443357

Epoch: 5| Step: 8
Training loss: 2.842869281768799
Validation loss: 2.6968120272441576

Epoch: 5| Step: 9
Training loss: 2.755587100982666
Validation loss: 2.770628982974637

Epoch: 5| Step: 10
Training loss: 2.944504499435425
Validation loss: 2.7045657378371044

Epoch: 42| Step: 0
Training loss: 2.6592915058135986
Validation loss: 2.6983497681156283

Epoch: 5| Step: 1
Training loss: 3.5026443004608154
Validation loss: 2.7037767133405133

Epoch: 5| Step: 2
Training loss: 2.8690786361694336
Validation loss: 2.7223646435686337

Epoch: 5| Step: 3
Training loss: 2.7825865745544434
Validation loss: 2.8902166607559368

Epoch: 5| Step: 4
Training loss: 2.7927494049072266
Validation loss: 2.7152495973853656

Epoch: 5| Step: 5
Training loss: 3.255915880203247
Validation loss: 2.728444468590521

Epoch: 5| Step: 6
Training loss: 2.758711099624634
Validation loss: 2.7516885649773384

Epoch: 5| Step: 7
Training loss: 3.7873268127441406
Validation loss: 2.6993918444520686

Epoch: 5| Step: 8
Training loss: 2.3901214599609375
Validation loss: 2.7193383478349253

Epoch: 5| Step: 9
Training loss: 2.717341184616089
Validation loss: 2.7955178958113476

Epoch: 5| Step: 10
Training loss: 2.2987821102142334
Validation loss: 2.8222993804562475

Epoch: 43| Step: 0
Training loss: 3.3711769580841064
Validation loss: 2.78546283834724

Epoch: 5| Step: 1
Training loss: 3.0361626148223877
Validation loss: 2.740358142442601

Epoch: 5| Step: 2
Training loss: 2.925234317779541
Validation loss: 2.7344539139860418

Epoch: 5| Step: 3
Training loss: 2.4791817665100098
Validation loss: 2.7691476319425847

Epoch: 5| Step: 4
Training loss: 3.301286220550537
Validation loss: 2.8248445167336413

Epoch: 5| Step: 5
Training loss: 2.536534547805786
Validation loss: 2.7492265470566286

Epoch: 5| Step: 6
Training loss: 3.5307819843292236
Validation loss: 2.7950564276787544

Epoch: 5| Step: 7
Training loss: 2.9438066482543945
Validation loss: 2.767432789648733

Epoch: 5| Step: 8
Training loss: 2.6317389011383057
Validation loss: 2.7657830125542096

Epoch: 5| Step: 9
Training loss: 2.40114426612854
Validation loss: 2.7510711172575593

Epoch: 5| Step: 10
Training loss: 2.9414145946502686
Validation loss: 2.71875520419049

Epoch: 44| Step: 0
Training loss: 2.623378038406372
Validation loss: 2.710596369158837

Epoch: 5| Step: 1
Training loss: 3.4133191108703613
Validation loss: 2.711780599368516

Epoch: 5| Step: 2
Training loss: 2.5376172065734863
Validation loss: 2.7250948823908323

Epoch: 5| Step: 3
Training loss: 2.979530096054077
Validation loss: 2.7241771400615735

Epoch: 5| Step: 4
Training loss: 2.608931064605713
Validation loss: 2.7134440175948606

Epoch: 5| Step: 5
Training loss: 2.8466298580169678
Validation loss: 2.7371634001372964

Epoch: 5| Step: 6
Training loss: 3.0479989051818848
Validation loss: 2.7484641664771625

Epoch: 5| Step: 7
Training loss: 2.5391721725463867
Validation loss: 2.7604483609558432

Epoch: 5| Step: 8
Training loss: 3.6087894439697266
Validation loss: 2.7401080234076387

Epoch: 5| Step: 9
Training loss: 3.156191349029541
Validation loss: 2.7115827324569866

Epoch: 5| Step: 10
Training loss: 2.2070302963256836
Validation loss: 2.646906611739948

Epoch: 45| Step: 0
Training loss: 3.3360843658447266
Validation loss: 2.6976616818417787

Epoch: 5| Step: 1
Training loss: 3.308037519454956
Validation loss: 2.7350091062566286

Epoch: 5| Step: 2
Training loss: 3.2829532623291016
Validation loss: 2.79243367461748

Epoch: 5| Step: 3
Training loss: 2.7502453327178955
Validation loss: 2.9786604450594996

Epoch: 5| Step: 4
Training loss: 3.0387046337127686
Validation loss: 3.0458647999712216

Epoch: 5| Step: 5
Training loss: 2.901519536972046
Validation loss: 3.095601584321709

Epoch: 5| Step: 6
Training loss: 3.0689964294433594
Validation loss: 3.1820106455074844

Epoch: 5| Step: 7
Training loss: 4.3523640632629395
Validation loss: 3.1309357868727816

Epoch: 5| Step: 8
Training loss: 3.095790147781372
Validation loss: 3.06664692201922

Epoch: 5| Step: 9
Training loss: 1.996665596961975
Validation loss: 3.025229912932201

Epoch: 5| Step: 10
Training loss: 2.5950491428375244
Validation loss: 2.9963987617082495

Epoch: 46| Step: 0
Training loss: 2.6831891536712646
Validation loss: 2.969325970577937

Epoch: 5| Step: 1
Training loss: 3.053077220916748
Validation loss: 2.8972742967708136

Epoch: 5| Step: 2
Training loss: 1.9556947946548462
Validation loss: 2.8890213786914782

Epoch: 5| Step: 3
Training loss: 3.3646721839904785
Validation loss: 2.8964200583837365

Epoch: 5| Step: 4
Training loss: 3.1937899589538574
Validation loss: 2.869957488070252

Epoch: 5| Step: 5
Training loss: 2.4574882984161377
Validation loss: 2.802042499665291

Epoch: 5| Step: 6
Training loss: 2.7571160793304443
Validation loss: 2.7745666452633437

Epoch: 5| Step: 7
Training loss: 2.184697389602661
Validation loss: 2.754270230570147

Epoch: 5| Step: 8
Training loss: 3.5966956615448
Validation loss: 2.722451648404521

Epoch: 5| Step: 9
Training loss: 4.352473735809326
Validation loss: 2.708634025307112

Epoch: 5| Step: 10
Training loss: 2.702285051345825
Validation loss: 2.6985398107959377

Epoch: 47| Step: 0
Training loss: 2.6185734272003174
Validation loss: 2.7136965259428947

Epoch: 5| Step: 1
Training loss: 3.818195343017578
Validation loss: 2.7017068683460193

Epoch: 5| Step: 2
Training loss: 2.8767223358154297
Validation loss: 2.674652435446298

Epoch: 5| Step: 3
Training loss: 2.9085922241210938
Validation loss: 2.6530597722658547

Epoch: 5| Step: 4
Training loss: 2.479753017425537
Validation loss: 2.6630657693391204

Epoch: 5| Step: 5
Training loss: 2.126856565475464
Validation loss: 2.6949535313472954

Epoch: 5| Step: 6
Training loss: 2.5039138793945312
Validation loss: 2.7062307557752057

Epoch: 5| Step: 7
Training loss: 3.314337968826294
Validation loss: 2.7189309263742096

Epoch: 5| Step: 8
Training loss: 3.3995375633239746
Validation loss: 2.7350876972239506

Epoch: 5| Step: 9
Training loss: 2.8723349571228027
Validation loss: 2.698283344186762

Epoch: 5| Step: 10
Training loss: 2.578669786453247
Validation loss: 2.6653490399801605

Epoch: 48| Step: 0
Training loss: 2.5357823371887207
Validation loss: 2.6433475043184016

Epoch: 5| Step: 1
Training loss: 3.107598066329956
Validation loss: 2.626664189882176

Epoch: 5| Step: 2
Training loss: 2.385765314102173
Validation loss: 2.6146374492235083

Epoch: 5| Step: 3
Training loss: 2.1684765815734863
Validation loss: 2.6174621043666715

Epoch: 5| Step: 4
Training loss: 3.1780171394348145
Validation loss: 2.677373381071193

Epoch: 5| Step: 5
Training loss: 3.1054635047912598
Validation loss: 2.6844683129300355

Epoch: 5| Step: 6
Training loss: 2.5226597785949707
Validation loss: 2.692109095152988

Epoch: 5| Step: 7
Training loss: 3.2267043590545654
Validation loss: 2.7025362701826197

Epoch: 5| Step: 8
Training loss: 2.6785621643066406
Validation loss: 2.690950906404885

Epoch: 5| Step: 9
Training loss: 3.064816474914551
Validation loss: 2.716390045740271

Epoch: 5| Step: 10
Training loss: 3.4598026275634766
Validation loss: 2.675619004875101

Epoch: 49| Step: 0
Training loss: 2.7599170207977295
Validation loss: 2.663779371528215

Epoch: 5| Step: 1
Training loss: 2.9121856689453125
Validation loss: 2.6632850272681123

Epoch: 5| Step: 2
Training loss: 2.854562997817993
Validation loss: 2.6286955495034494

Epoch: 5| Step: 3
Training loss: 3.4512763023376465
Validation loss: 2.6223245487418225

Epoch: 5| Step: 4
Training loss: 3.4502499103546143
Validation loss: 2.698250027113063

Epoch: 5| Step: 5
Training loss: 2.73405122756958
Validation loss: 2.8038889515784478

Epoch: 5| Step: 6
Training loss: 2.277333974838257
Validation loss: 2.690957102724301

Epoch: 5| Step: 7
Training loss: 2.2540576457977295
Validation loss: 2.662092747226838

Epoch: 5| Step: 8
Training loss: 3.5235671997070312
Validation loss: 2.6730398901047243

Epoch: 5| Step: 9
Training loss: 2.850724220275879
Validation loss: 2.669411995077646

Epoch: 5| Step: 10
Training loss: 2.141214370727539
Validation loss: 2.6688791039169475

Epoch: 50| Step: 0
Training loss: 2.7641844749450684
Validation loss: 2.679164876220047

Epoch: 5| Step: 1
Training loss: 3.5653107166290283
Validation loss: 2.701587446274296

Epoch: 5| Step: 2
Training loss: 3.1391444206237793
Validation loss: 2.7131071500880743

Epoch: 5| Step: 3
Training loss: 2.750898599624634
Validation loss: 2.719509765666018

Epoch: 5| Step: 4
Training loss: 2.487870216369629
Validation loss: 2.7174507033440376

Epoch: 5| Step: 5
Training loss: 2.8422422409057617
Validation loss: 2.7229856675670994

Epoch: 5| Step: 6
Training loss: 3.1365418434143066
Validation loss: 2.7293271890250583

Epoch: 5| Step: 7
Training loss: 2.83503794670105
Validation loss: 2.718540871015159

Epoch: 5| Step: 8
Training loss: 3.119403839111328
Validation loss: 2.7130440717102378

Epoch: 5| Step: 9
Training loss: 2.6465389728546143
Validation loss: 2.7010361404829126

Epoch: 5| Step: 10
Training loss: 2.2560007572174072
Validation loss: 2.6892529610664613

Epoch: 51| Step: 0
Training loss: 2.9695425033569336
Validation loss: 2.678092723251671

Epoch: 5| Step: 1
Training loss: 2.516892910003662
Validation loss: 2.668227618740451

Epoch: 5| Step: 2
Training loss: 2.4602324962615967
Validation loss: 2.659375565026396

Epoch: 5| Step: 3
Training loss: 3.002934455871582
Validation loss: 2.651615814496112

Epoch: 5| Step: 4
Training loss: 2.063988208770752
Validation loss: 2.6491942815883185

Epoch: 5| Step: 5
Training loss: 3.645153760910034
Validation loss: 2.651342794459353

Epoch: 5| Step: 6
Training loss: 2.7359347343444824
Validation loss: 2.6550213470253894

Epoch: 5| Step: 7
Training loss: 2.7166457176208496
Validation loss: 2.6456173876280427

Epoch: 5| Step: 8
Training loss: 2.3628334999084473
Validation loss: 2.6438092006150113

Epoch: 5| Step: 9
Training loss: 2.9822659492492676
Validation loss: 2.6508445662836873

Epoch: 5| Step: 10
Training loss: 3.9293689727783203
Validation loss: 2.6461842803544897

Epoch: 52| Step: 0
Training loss: 2.6507041454315186
Validation loss: 2.6720893870117846

Epoch: 5| Step: 1
Training loss: 2.607463836669922
Validation loss: 2.6900967885089178

Epoch: 5| Step: 2
Training loss: 3.111128091812134
Validation loss: 2.692271896587905

Epoch: 5| Step: 3
Training loss: 2.8926868438720703
Validation loss: 2.6840387723779164

Epoch: 5| Step: 4
Training loss: 3.1470377445220947
Validation loss: 2.688439502510973

Epoch: 5| Step: 5
Training loss: 2.837172269821167
Validation loss: 2.6855646948660574

Epoch: 5| Step: 6
Training loss: 2.262302875518799
Validation loss: 2.6809835075050272

Epoch: 5| Step: 7
Training loss: 2.9378821849823
Validation loss: 2.681085405811187

Epoch: 5| Step: 8
Training loss: 2.833604335784912
Validation loss: 2.6691171238499303

Epoch: 5| Step: 9
Training loss: 2.9008548259735107
Validation loss: 2.6596333801105456

Epoch: 5| Step: 10
Training loss: 3.2755589485168457
Validation loss: 2.648496504752867

Epoch: 53| Step: 0
Training loss: 2.8787875175476074
Validation loss: 2.6293076315233783

Epoch: 5| Step: 1
Training loss: 2.5092082023620605
Validation loss: 2.6146809183141237

Epoch: 5| Step: 2
Training loss: 3.528507947921753
Validation loss: 2.608753522237142

Epoch: 5| Step: 3
Training loss: 2.7409591674804688
Validation loss: 2.6129932839383363

Epoch: 5| Step: 4
Training loss: 2.8502306938171387
Validation loss: 2.6152161423878004

Epoch: 5| Step: 5
Training loss: 3.318833112716675
Validation loss: 2.6191755776764243

Epoch: 5| Step: 6
Training loss: 2.296349048614502
Validation loss: 2.620698267413724

Epoch: 5| Step: 7
Training loss: 2.6490867137908936
Validation loss: 2.6166495405217653

Epoch: 5| Step: 8
Training loss: 3.0261669158935547
Validation loss: 2.620556721123316

Epoch: 5| Step: 9
Training loss: 1.9263412952423096
Validation loss: 2.624250481205602

Epoch: 5| Step: 10
Training loss: 3.367319107055664
Validation loss: 2.6467158384220575

Epoch: 54| Step: 0
Training loss: 2.611393451690674
Validation loss: 2.603521436773321

Epoch: 5| Step: 1
Training loss: 2.985018491744995
Validation loss: 2.5916142361138457

Epoch: 5| Step: 2
Training loss: 2.3412108421325684
Validation loss: 2.5863445984419955

Epoch: 5| Step: 3
Training loss: 2.9314708709716797
Validation loss: 2.5857276634503434

Epoch: 5| Step: 4
Training loss: 2.190978527069092
Validation loss: 2.601711698757705

Epoch: 5| Step: 5
Training loss: 2.758273124694824
Validation loss: 2.612352978798651

Epoch: 5| Step: 6
Training loss: 3.3318965435028076
Validation loss: 2.63580838582849

Epoch: 5| Step: 7
Training loss: 2.6898465156555176
Validation loss: 2.6481946309407554

Epoch: 5| Step: 8
Training loss: 3.221592664718628
Validation loss: 2.6726635604776363

Epoch: 5| Step: 9
Training loss: 3.391439437866211
Validation loss: 2.679966054936891

Epoch: 5| Step: 10
Training loss: 2.5139317512512207
Validation loss: 2.6688555927686792

Epoch: 55| Step: 0
Training loss: 2.9069368839263916
Validation loss: 2.6609373810470744

Epoch: 5| Step: 1
Training loss: 2.9323012828826904
Validation loss: 2.6361461967550297

Epoch: 5| Step: 2
Training loss: 2.8895604610443115
Validation loss: 2.62133353499956

Epoch: 5| Step: 3
Training loss: 2.9689972400665283
Validation loss: 2.6000662695976997

Epoch: 5| Step: 4
Training loss: 2.829664945602417
Validation loss: 2.584723318776777

Epoch: 5| Step: 5
Training loss: 2.9632408618927
Validation loss: 2.5834705906529583

Epoch: 5| Step: 6
Training loss: 2.4316368103027344
Validation loss: 2.5746358645859586

Epoch: 5| Step: 7
Training loss: 2.693427324295044
Validation loss: 2.578435444062756

Epoch: 5| Step: 8
Training loss: 2.7217178344726562
Validation loss: 2.5755896055570213

Epoch: 5| Step: 9
Training loss: 2.731733798980713
Validation loss: 2.580197398380567

Epoch: 5| Step: 10
Training loss: 2.7008111476898193
Validation loss: 2.584006101854386

Epoch: 56| Step: 0
Training loss: 2.846992015838623
Validation loss: 2.5900217025510726

Epoch: 5| Step: 1
Training loss: 2.8177483081817627
Validation loss: 2.582061726559875

Epoch: 5| Step: 2
Training loss: 3.1238536834716797
Validation loss: 2.585884827439503

Epoch: 5| Step: 3
Training loss: 2.6913106441497803
Validation loss: 2.5750718257760488

Epoch: 5| Step: 4
Training loss: 2.3938519954681396
Validation loss: 2.5665762039922897

Epoch: 5| Step: 5
Training loss: 3.239720106124878
Validation loss: 2.553672518781436

Epoch: 5| Step: 6
Training loss: 3.079393148422241
Validation loss: 2.5481835206349692

Epoch: 5| Step: 7
Training loss: 2.7521495819091797
Validation loss: 2.54749539590651

Epoch: 5| Step: 8
Training loss: 2.6348729133605957
Validation loss: 2.5397674293928247

Epoch: 5| Step: 9
Training loss: 2.183027744293213
Validation loss: 2.5364014128203034

Epoch: 5| Step: 10
Training loss: 2.718658924102783
Validation loss: 2.53267752996055

Epoch: 57| Step: 0
Training loss: 2.2865548133850098
Validation loss: 2.5439650781692995

Epoch: 5| Step: 1
Training loss: 2.6993675231933594
Validation loss: 2.5884079138437905

Epoch: 5| Step: 2
Training loss: 2.090916395187378
Validation loss: 2.5958929728436213

Epoch: 5| Step: 3
Training loss: 2.904937267303467
Validation loss: 2.5787189750261206

Epoch: 5| Step: 4
Training loss: 3.236102342605591
Validation loss: 2.555846788549936

Epoch: 5| Step: 5
Training loss: 3.2871041297912598
Validation loss: 2.537317673365275

Epoch: 5| Step: 6
Training loss: 2.127960205078125
Validation loss: 2.5217363885653916

Epoch: 5| Step: 7
Training loss: 2.992810010910034
Validation loss: 2.5187857176667903

Epoch: 5| Step: 8
Training loss: 2.3943867683410645
Validation loss: 2.525946661990176

Epoch: 5| Step: 9
Training loss: 3.0372848510742188
Validation loss: 2.5249317281989643

Epoch: 5| Step: 10
Training loss: 3.2361316680908203
Validation loss: 2.5302298479182745

Epoch: 58| Step: 0
Training loss: 2.1886913776397705
Validation loss: 2.5248696855319444

Epoch: 5| Step: 1
Training loss: 2.9192214012145996
Validation loss: 2.5246071584763063

Epoch: 5| Step: 2
Training loss: 2.778496026992798
Validation loss: 2.517706442904729

Epoch: 5| Step: 3
Training loss: 2.3386197090148926
Validation loss: 2.510598559533396

Epoch: 5| Step: 4
Training loss: 3.0350430011749268
Validation loss: 2.5130738263489096

Epoch: 5| Step: 5
Training loss: 3.1478772163391113
Validation loss: 2.5075307840942056

Epoch: 5| Step: 6
Training loss: 2.4852538108825684
Validation loss: 2.5048564275105796

Epoch: 5| Step: 7
Training loss: 2.281747817993164
Validation loss: 2.503698620744931

Epoch: 5| Step: 8
Training loss: 3.3643813133239746
Validation loss: 2.5092405273068334

Epoch: 5| Step: 9
Training loss: 2.4642913341522217
Validation loss: 2.513807905617581

Epoch: 5| Step: 10
Training loss: 3.0369815826416016
Validation loss: 2.520359403343611

Epoch: 59| Step: 0
Training loss: 4.006497383117676
Validation loss: 2.5141740742550103

Epoch: 5| Step: 1
Training loss: 2.61039400100708
Validation loss: 2.5100270817356725

Epoch: 5| Step: 2
Training loss: 2.282304048538208
Validation loss: 2.5057711370529665

Epoch: 5| Step: 3
Training loss: 3.175743818283081
Validation loss: 2.502611162841961

Epoch: 5| Step: 4
Training loss: 3.212783098220825
Validation loss: 2.501051666916058

Epoch: 5| Step: 5
Training loss: 2.7740085124969482
Validation loss: 2.4956836341529764

Epoch: 5| Step: 6
Training loss: 2.5673635005950928
Validation loss: 2.501613886125626

Epoch: 5| Step: 7
Training loss: 2.784515619277954
Validation loss: 2.498066138195735

Epoch: 5| Step: 8
Training loss: 2.319113254547119
Validation loss: 2.5011185830639255

Epoch: 5| Step: 9
Training loss: 2.014112949371338
Validation loss: 2.5081949900555354

Epoch: 5| Step: 10
Training loss: 2.000267505645752
Validation loss: 2.536456815658077

Epoch: 60| Step: 0
Training loss: 2.630274772644043
Validation loss: 2.544506142216344

Epoch: 5| Step: 1
Training loss: 2.1683685779571533
Validation loss: 2.524596421949325

Epoch: 5| Step: 2
Training loss: 2.7235822677612305
Validation loss: 2.5074230342782955

Epoch: 5| Step: 3
Training loss: 2.837218999862671
Validation loss: 2.4953237771987915

Epoch: 5| Step: 4
Training loss: 2.1161155700683594
Validation loss: 2.5008903652109127

Epoch: 5| Step: 5
Training loss: 2.743323802947998
Validation loss: 2.525393975678311

Epoch: 5| Step: 6
Training loss: 2.6142759323120117
Validation loss: 2.5772689798826813

Epoch: 5| Step: 7
Training loss: 3.238219738006592
Validation loss: 2.59846503503861

Epoch: 5| Step: 8
Training loss: 3.5929336547851562
Validation loss: 2.5680163239920013

Epoch: 5| Step: 9
Training loss: 2.4909188747406006
Validation loss: 2.5283440210485972

Epoch: 5| Step: 10
Training loss: 3.15087628364563
Validation loss: 2.499591124955044

Epoch: 61| Step: 0
Training loss: 2.1464130878448486
Validation loss: 2.4958775376760833

Epoch: 5| Step: 1
Training loss: 2.879164218902588
Validation loss: 2.52216189394715

Epoch: 5| Step: 2
Training loss: 2.9556400775909424
Validation loss: 2.527577128461612

Epoch: 5| Step: 3
Training loss: 2.28121018409729
Validation loss: 2.5207421933451006

Epoch: 5| Step: 4
Training loss: 3.024477243423462
Validation loss: 2.509884049815516

Epoch: 5| Step: 5
Training loss: 3.106905460357666
Validation loss: 2.498438524943526

Epoch: 5| Step: 6
Training loss: 2.518862247467041
Validation loss: 2.4993462998379945

Epoch: 5| Step: 7
Training loss: 2.6873936653137207
Validation loss: 2.499375266413535

Epoch: 5| Step: 8
Training loss: 2.4522995948791504
Validation loss: 2.5058448853031283

Epoch: 5| Step: 9
Training loss: 2.6321592330932617
Validation loss: 2.5059713061137865

Epoch: 5| Step: 10
Training loss: 3.2830588817596436
Validation loss: 2.5052978325915594

Epoch: 62| Step: 0
Training loss: 2.382403612136841
Validation loss: 2.504832472852481

Epoch: 5| Step: 1
Training loss: 2.3783862590789795
Validation loss: 2.51510626013561

Epoch: 5| Step: 2
Training loss: 2.758613109588623
Validation loss: 2.5240004447198685

Epoch: 5| Step: 3
Training loss: 2.1201298236846924
Validation loss: 2.5186152406918105

Epoch: 5| Step: 4
Training loss: 2.9890010356903076
Validation loss: 2.4968194730820192

Epoch: 5| Step: 5
Training loss: 2.3972041606903076
Validation loss: 2.486732852074408

Epoch: 5| Step: 6
Training loss: 2.714392900466919
Validation loss: 2.4819360522813696

Epoch: 5| Step: 7
Training loss: 3.2578818798065186
Validation loss: 2.4921796065504833

Epoch: 5| Step: 8
Training loss: 2.889482259750366
Validation loss: 2.488094281124812

Epoch: 5| Step: 9
Training loss: 3.1816246509552
Validation loss: 2.480056583240468

Epoch: 5| Step: 10
Training loss: 2.741201877593994
Validation loss: 2.479148321254279

Epoch: 63| Step: 0
Training loss: 2.1528282165527344
Validation loss: 2.4750601142965336

Epoch: 5| Step: 1
Training loss: 2.9063124656677246
Validation loss: 2.4807642300923667

Epoch: 5| Step: 2
Training loss: 3.450669527053833
Validation loss: 2.4840831141318045

Epoch: 5| Step: 3
Training loss: 2.6782474517822266
Validation loss: 2.4821747759337067

Epoch: 5| Step: 4
Training loss: 2.4761767387390137
Validation loss: 2.4794663998388473

Epoch: 5| Step: 5
Training loss: 2.9616122245788574
Validation loss: 2.4789131892624723

Epoch: 5| Step: 6
Training loss: 2.3022918701171875
Validation loss: 2.4868452754071964

Epoch: 5| Step: 7
Training loss: 2.632488250732422
Validation loss: 2.4961718564392417

Epoch: 5| Step: 8
Training loss: 3.0562102794647217
Validation loss: 2.5004338525956675

Epoch: 5| Step: 9
Training loss: 2.1813361644744873
Validation loss: 2.491599252147059

Epoch: 5| Step: 10
Training loss: 2.829054832458496
Validation loss: 2.4755052494746383

Epoch: 64| Step: 0
Training loss: 2.8374428749084473
Validation loss: 2.475437528343611

Epoch: 5| Step: 1
Training loss: 2.8382861614227295
Validation loss: 2.479044865536433

Epoch: 5| Step: 2
Training loss: 3.119673490524292
Validation loss: 2.4864710543745305

Epoch: 5| Step: 3
Training loss: 2.5298898220062256
Validation loss: 2.491163384529852

Epoch: 5| Step: 4
Training loss: 2.266732692718506
Validation loss: 2.4931730403695056

Epoch: 5| Step: 5
Training loss: 2.555434465408325
Validation loss: 2.4909044132437757

Epoch: 5| Step: 6
Training loss: 2.6223678588867188
Validation loss: 2.4708498908627416

Epoch: 5| Step: 7
Training loss: 2.8134706020355225
Validation loss: 2.477999897413356

Epoch: 5| Step: 8
Training loss: 3.2752575874328613
Validation loss: 2.4937234053047757

Epoch: 5| Step: 9
Training loss: 2.5635955333709717
Validation loss: 2.5083482111653974

Epoch: 5| Step: 10
Training loss: 2.429307699203491
Validation loss: 2.520285593566074

Epoch: 65| Step: 0
Training loss: 2.089686155319214
Validation loss: 2.4963637116134807

Epoch: 5| Step: 1
Training loss: 2.877488613128662
Validation loss: 2.4926315981854676

Epoch: 5| Step: 2
Training loss: 2.208801746368408
Validation loss: 2.472962579419536

Epoch: 5| Step: 3
Training loss: 2.9523203372955322
Validation loss: 2.4636108093364264

Epoch: 5| Step: 4
Training loss: 2.9316346645355225
Validation loss: 2.4616291035888014

Epoch: 5| Step: 5
Training loss: 2.402329921722412
Validation loss: 2.4658326231023318

Epoch: 5| Step: 6
Training loss: 2.0462558269500732
Validation loss: 2.471587924547093

Epoch: 5| Step: 7
Training loss: 3.211982011795044
Validation loss: 2.4750058356151787

Epoch: 5| Step: 8
Training loss: 2.6120524406433105
Validation loss: 2.4684387278813187

Epoch: 5| Step: 9
Training loss: 3.2152600288391113
Validation loss: 2.4616175646423013

Epoch: 5| Step: 10
Training loss: 3.17885160446167
Validation loss: 2.4586852442833687

Epoch: 66| Step: 0
Training loss: 2.7116169929504395
Validation loss: 2.466003797387564

Epoch: 5| Step: 1
Training loss: 2.3521361351013184
Validation loss: 2.4643968074552474

Epoch: 5| Step: 2
Training loss: 3.048346996307373
Validation loss: 2.4678283583733345

Epoch: 5| Step: 3
Training loss: 2.9109253883361816
Validation loss: 2.468257104196856

Epoch: 5| Step: 4
Training loss: 2.613328456878662
Validation loss: 2.473076187154298

Epoch: 5| Step: 5
Training loss: 2.8263442516326904
Validation loss: 2.4754218542447655

Epoch: 5| Step: 6
Training loss: 3.1011626720428467
Validation loss: 2.4786599246404504

Epoch: 5| Step: 7
Training loss: 2.46958589553833
Validation loss: 2.482964943814021

Epoch: 5| Step: 8
Training loss: 2.5592596530914307
Validation loss: 2.50217935346788

Epoch: 5| Step: 9
Training loss: 2.447675943374634
Validation loss: 2.4864901304244995

Epoch: 5| Step: 10
Training loss: 2.402742624282837
Validation loss: 2.485696961802821

Epoch: 67| Step: 0
Training loss: 2.931633472442627
Validation loss: 2.5119324473924536

Epoch: 5| Step: 1
Training loss: 2.429234027862549
Validation loss: 2.4760223152816936

Epoch: 5| Step: 2
Training loss: 2.30625319480896
Validation loss: 2.4598129333988314

Epoch: 5| Step: 3
Training loss: 2.9180209636688232
Validation loss: 2.455900702425229

Epoch: 5| Step: 4
Training loss: 2.3099427223205566
Validation loss: 2.457173402591418

Epoch: 5| Step: 5
Training loss: 2.5006794929504395
Validation loss: 2.455448871017784

Epoch: 5| Step: 6
Training loss: 3.0698142051696777
Validation loss: 2.4585474127082416

Epoch: 5| Step: 7
Training loss: 2.571040153503418
Validation loss: 2.4595586728024226

Epoch: 5| Step: 8
Training loss: 3.017502546310425
Validation loss: 2.4596519162577968

Epoch: 5| Step: 9
Training loss: 2.8256077766418457
Validation loss: 2.4561575023076867

Epoch: 5| Step: 10
Training loss: 2.9033899307250977
Validation loss: 2.453027730347008

Epoch: 68| Step: 0
Training loss: 2.6891160011291504
Validation loss: 2.4583930507782967

Epoch: 5| Step: 1
Training loss: 3.082947254180908
Validation loss: 2.4626791143930085

Epoch: 5| Step: 2
Training loss: 3.419619083404541
Validation loss: 2.454553117034256

Epoch: 5| Step: 3
Training loss: 2.7222073078155518
Validation loss: 2.4565833589082122

Epoch: 5| Step: 4
Training loss: 2.0511136054992676
Validation loss: 2.453863743812807

Epoch: 5| Step: 5
Training loss: 2.911058187484741
Validation loss: 2.454589015694075

Epoch: 5| Step: 6
Training loss: 1.9739501476287842
Validation loss: 2.454354916849444

Epoch: 5| Step: 7
Training loss: 2.6607041358947754
Validation loss: 2.4530281969296035

Epoch: 5| Step: 8
Training loss: 2.4777328968048096
Validation loss: 2.4705430384605163

Epoch: 5| Step: 9
Training loss: 2.0852038860321045
Validation loss: 2.471842445353026

Epoch: 5| Step: 10
Training loss: 3.4667398929595947
Validation loss: 2.4892928318310807

Epoch: 69| Step: 0
Training loss: 2.9541091918945312
Validation loss: 2.4846666961587887

Epoch: 5| Step: 1
Training loss: 2.9407999515533447
Validation loss: 2.4979321725906862

Epoch: 5| Step: 2
Training loss: 3.234264373779297
Validation loss: 2.497073527305357

Epoch: 5| Step: 3
Training loss: 3.1552834510803223
Validation loss: 2.4986890131427395

Epoch: 5| Step: 4
Training loss: 2.4429473876953125
Validation loss: 2.4742135027403473

Epoch: 5| Step: 5
Training loss: 2.1845223903656006
Validation loss: 2.443852242603097

Epoch: 5| Step: 6
Training loss: 2.856369733810425
Validation loss: 2.4115836235784713

Epoch: 5| Step: 7
Training loss: 2.710531711578369
Validation loss: 2.3911617366216515

Epoch: 5| Step: 8
Training loss: 2.203409194946289
Validation loss: 2.3888938068061747

Epoch: 5| Step: 9
Training loss: 2.3147521018981934
Validation loss: 2.396414400428854

Epoch: 5| Step: 10
Training loss: 2.396329879760742
Validation loss: 2.4073994108425674

Epoch: 70| Step: 0
Training loss: 3.1644058227539062
Validation loss: 2.4192110723064792

Epoch: 5| Step: 1
Training loss: 1.8909199237823486
Validation loss: 2.4028440547245804

Epoch: 5| Step: 2
Training loss: 2.800142765045166
Validation loss: 2.391761677239531

Epoch: 5| Step: 3
Training loss: 3.1062798500061035
Validation loss: 2.3895598867888093

Epoch: 5| Step: 4
Training loss: 2.9850850105285645
Validation loss: 2.3932114519098753

Epoch: 5| Step: 5
Training loss: 2.8908703327178955
Validation loss: 2.4228131540359987

Epoch: 5| Step: 6
Training loss: 2.6481995582580566
Validation loss: 2.497213811002752

Epoch: 5| Step: 7
Training loss: 2.4583702087402344
Validation loss: 2.5153826821234917

Epoch: 5| Step: 8
Training loss: 2.256835460662842
Validation loss: 2.512307510581068

Epoch: 5| Step: 9
Training loss: 2.7646336555480957
Validation loss: 2.4682281530031593

Epoch: 5| Step: 10
Training loss: 2.3930506706237793
Validation loss: 2.4001541188968125

Epoch: 71| Step: 0
Training loss: 1.7486200332641602
Validation loss: 2.3881418679350164

Epoch: 5| Step: 1
Training loss: 3.510202407836914
Validation loss: 2.4348024950232556

Epoch: 5| Step: 2
Training loss: 3.7502353191375732
Validation loss: 2.467503055449455

Epoch: 5| Step: 3
Training loss: 2.249438524246216
Validation loss: 2.4448286230846117

Epoch: 5| Step: 4
Training loss: 3.0112454891204834
Validation loss: 2.428182066127818

Epoch: 5| Step: 5
Training loss: 3.1313631534576416
Validation loss: 2.4039137517252276

Epoch: 5| Step: 6
Training loss: 2.8140804767608643
Validation loss: 2.3812811579755557

Epoch: 5| Step: 7
Training loss: 1.8831079006195068
Validation loss: 2.3925308668485252

Epoch: 5| Step: 8
Training loss: 2.290875196456909
Validation loss: 2.4439527296250865

Epoch: 5| Step: 9
Training loss: 2.8676247596740723
Validation loss: 2.5045501826911845

Epoch: 5| Step: 10
Training loss: 2.1148388385772705
Validation loss: 2.492725328732562

Epoch: 72| Step: 0
Training loss: 2.596465826034546
Validation loss: 2.517309514425134

Epoch: 5| Step: 1
Training loss: 2.1700375080108643
Validation loss: 2.483739053049395

Epoch: 5| Step: 2
Training loss: 2.8207099437713623
Validation loss: 2.4542739006780807

Epoch: 5| Step: 3
Training loss: 3.059732437133789
Validation loss: 2.4142588543635544

Epoch: 5| Step: 4
Training loss: 2.643533229827881
Validation loss: 2.394301117107432

Epoch: 5| Step: 5
Training loss: 2.4407901763916016
Validation loss: 2.3892724308916318

Epoch: 5| Step: 6
Training loss: 2.467313289642334
Validation loss: 2.394339787062778

Epoch: 5| Step: 7
Training loss: 2.4164509773254395
Validation loss: 2.3825710845249954

Epoch: 5| Step: 8
Training loss: 3.119992256164551
Validation loss: 2.3779272405050134

Epoch: 5| Step: 9
Training loss: 2.852534770965576
Validation loss: 2.3804606263355543

Epoch: 5| Step: 10
Training loss: 2.4173457622528076
Validation loss: 2.3855688469384306

Epoch: 73| Step: 0
Training loss: 2.8903985023498535
Validation loss: 2.390633234413721

Epoch: 5| Step: 1
Training loss: 2.523594379425049
Validation loss: 2.3892247958849837

Epoch: 5| Step: 2
Training loss: 2.8424627780914307
Validation loss: 2.402371875701412

Epoch: 5| Step: 3
Training loss: 2.2950279712677
Validation loss: 2.3998509119915705

Epoch: 5| Step: 4
Training loss: 2.028372049331665
Validation loss: 2.3876196697194088

Epoch: 5| Step: 5
Training loss: 2.8961739540100098
Validation loss: 2.3808826861842984

Epoch: 5| Step: 6
Training loss: 2.58695650100708
Validation loss: 2.38108971939292

Epoch: 5| Step: 7
Training loss: 2.4666881561279297
Validation loss: 2.3887344329587874

Epoch: 5| Step: 8
Training loss: 2.720998764038086
Validation loss: 2.393855764019874

Epoch: 5| Step: 9
Training loss: 3.012380838394165
Validation loss: 2.388434221667628

Epoch: 5| Step: 10
Training loss: 2.759192943572998
Validation loss: 2.3779026821095455

Epoch: 74| Step: 0
Training loss: 2.63179087638855
Validation loss: 2.380433417135669

Epoch: 5| Step: 1
Training loss: 3.0400617122650146
Validation loss: 2.3677421641606156

Epoch: 5| Step: 2
Training loss: 2.503039836883545
Validation loss: 2.3597794630194224

Epoch: 5| Step: 3
Training loss: 2.3387584686279297
Validation loss: 2.3646057113524406

Epoch: 5| Step: 4
Training loss: 2.7832694053649902
Validation loss: 2.362889130910238

Epoch: 5| Step: 5
Training loss: 2.896810531616211
Validation loss: 2.3673923835959485

Epoch: 5| Step: 6
Training loss: 2.8555519580841064
Validation loss: 2.36597502616144

Epoch: 5| Step: 7
Training loss: 2.216940402984619
Validation loss: 2.364918760074082

Epoch: 5| Step: 8
Training loss: 2.6865625381469727
Validation loss: 2.3780428030157603

Epoch: 5| Step: 9
Training loss: 2.5234146118164062
Validation loss: 2.40622208451712

Epoch: 5| Step: 10
Training loss: 2.3515069484710693
Validation loss: 2.4400235299141175

Epoch: 75| Step: 0
Training loss: 2.88057279586792
Validation loss: 2.4778554465181086

Epoch: 5| Step: 1
Training loss: 2.5647385120391846
Validation loss: 2.483412027359009

Epoch: 5| Step: 2
Training loss: 2.436704635620117
Validation loss: 2.431109730915357

Epoch: 5| Step: 3
Training loss: 2.565392017364502
Validation loss: 2.403087972312845

Epoch: 5| Step: 4
Training loss: 2.8134899139404297
Validation loss: 2.3748078397525254

Epoch: 5| Step: 5
Training loss: 2.9536895751953125
Validation loss: 2.374478006875643

Epoch: 5| Step: 6
Training loss: 2.179616689682007
Validation loss: 2.379498089513471

Epoch: 5| Step: 7
Training loss: 2.2246572971343994
Validation loss: 2.386765562078004

Epoch: 5| Step: 8
Training loss: 2.6658895015716553
Validation loss: 2.3884628421516827

Epoch: 5| Step: 9
Training loss: 3.039846897125244
Validation loss: 2.3869713147481284

Epoch: 5| Step: 10
Training loss: 3.0726325511932373
Validation loss: 2.3897059373958136

Epoch: 76| Step: 0
Training loss: 2.13250470161438
Validation loss: 2.4029095429246143

Epoch: 5| Step: 1
Training loss: 2.62701416015625
Validation loss: 2.444761678736697

Epoch: 5| Step: 2
Training loss: 2.707733154296875
Validation loss: 2.4794663152387066

Epoch: 5| Step: 3
Training loss: 2.5208358764648438
Validation loss: 2.5073940292481454

Epoch: 5| Step: 4
Training loss: 3.7694125175476074
Validation loss: 2.4917584157759145

Epoch: 5| Step: 5
Training loss: 2.78096342086792
Validation loss: 2.4348514618412143

Epoch: 5| Step: 6
Training loss: 2.939415454864502
Validation loss: 2.3818831084876932

Epoch: 5| Step: 7
Training loss: 2.422114849090576
Validation loss: 2.36290309762442

Epoch: 5| Step: 8
Training loss: 2.28200101852417
Validation loss: 2.3459196065061834

Epoch: 5| Step: 9
Training loss: 3.24096941947937
Validation loss: 2.3595170333821285

Epoch: 5| Step: 10
Training loss: 2.28291654586792
Validation loss: 2.3731709834068053

Epoch: 77| Step: 0
Training loss: 2.5006775856018066
Validation loss: 2.396558177086615

Epoch: 5| Step: 1
Training loss: 2.637526273727417
Validation loss: 2.460224707921346

Epoch: 5| Step: 2
Training loss: 2.5266833305358887
Validation loss: 2.5018955892132175

Epoch: 5| Step: 3
Training loss: 2.9060988426208496
Validation loss: 2.5014404250729467

Epoch: 5| Step: 4
Training loss: 3.0702691078186035
Validation loss: 2.5012463036403862

Epoch: 5| Step: 5
Training loss: 2.9875214099884033
Validation loss: 2.482292813639487

Epoch: 5| Step: 6
Training loss: 2.7313599586486816
Validation loss: 2.4104722904902633

Epoch: 5| Step: 7
Training loss: 2.309920072555542
Validation loss: 2.365291949241392

Epoch: 5| Step: 8
Training loss: 2.258481979370117
Validation loss: 2.344707917141658

Epoch: 5| Step: 9
Training loss: 2.4759345054626465
Validation loss: 2.344607214773855

Epoch: 5| Step: 10
Training loss: 2.9079270362854004
Validation loss: 2.356444702353529

Epoch: 78| Step: 0
Training loss: 2.5515780448913574
Validation loss: 2.3673053326145297

Epoch: 5| Step: 1
Training loss: 2.5273537635803223
Validation loss: 2.3746871050967964

Epoch: 5| Step: 2
Training loss: 3.222987413406372
Validation loss: 2.38281657362497

Epoch: 5| Step: 3
Training loss: 2.6282386779785156
Validation loss: 2.3906868683394564

Epoch: 5| Step: 4
Training loss: 2.628483295440674
Validation loss: 2.4113566901094172

Epoch: 5| Step: 5
Training loss: 3.1689770221710205
Validation loss: 2.4036376604469876

Epoch: 5| Step: 6
Training loss: 2.709423542022705
Validation loss: 2.399768538372491

Epoch: 5| Step: 7
Training loss: 2.6756763458251953
Validation loss: 2.403547999679401

Epoch: 5| Step: 8
Training loss: 2.6623311042785645
Validation loss: 2.3751129386245564

Epoch: 5| Step: 9
Training loss: 2.3384997844696045
Validation loss: 2.3542318600480274

Epoch: 5| Step: 10
Training loss: 2.2381339073181152
Validation loss: 2.38095748296348

Epoch: 79| Step: 0
Training loss: 2.5940866470336914
Validation loss: 2.457664671764579

Epoch: 5| Step: 1
Training loss: 3.561361312866211
Validation loss: 2.5351587982587915

Epoch: 5| Step: 2
Training loss: 2.862164258956909
Validation loss: 2.622355079138151

Epoch: 5| Step: 3
Training loss: 3.237679958343506
Validation loss: 2.68342496502784

Epoch: 5| Step: 4
Training loss: 2.8310093879699707
Validation loss: 2.621448081026795

Epoch: 5| Step: 5
Training loss: 2.749401569366455
Validation loss: 2.491144800698885

Epoch: 5| Step: 6
Training loss: 2.22060227394104
Validation loss: 2.4169545763282367

Epoch: 5| Step: 7
Training loss: 2.539905309677124
Validation loss: 2.3600503577980945

Epoch: 5| Step: 8
Training loss: 1.9835407733917236
Validation loss: 2.332080416781928

Epoch: 5| Step: 9
Training loss: 2.7714242935180664
Validation loss: 2.3553916485078874

Epoch: 5| Step: 10
Training loss: 2.2276036739349365
Validation loss: 2.3616469303766885

Epoch: 80| Step: 0
Training loss: 3.0321691036224365
Validation loss: 2.3872636800171225

Epoch: 5| Step: 1
Training loss: 2.598936080932617
Validation loss: 2.422446638025263

Epoch: 5| Step: 2
Training loss: 2.4544575214385986
Validation loss: 2.404504136372638

Epoch: 5| Step: 3
Training loss: 2.7898988723754883
Validation loss: 2.372115631257334

Epoch: 5| Step: 4
Training loss: 2.276841640472412
Validation loss: 2.3473793793750066

Epoch: 5| Step: 5
Training loss: 2.0934414863586426
Validation loss: 2.33349339167277

Epoch: 5| Step: 6
Training loss: 2.6892647743225098
Validation loss: 2.327771356028895

Epoch: 5| Step: 7
Training loss: 2.5795340538024902
Validation loss: 2.3292329490825696

Epoch: 5| Step: 8
Training loss: 2.943711757659912
Validation loss: 2.344047038785873

Epoch: 5| Step: 9
Training loss: 2.902841806411743
Validation loss: 2.369788941516671

Epoch: 5| Step: 10
Training loss: 2.6496074199676514
Validation loss: 2.3869073672961165

Epoch: 81| Step: 0
Training loss: 2.6541061401367188
Validation loss: 2.394720095460133

Epoch: 5| Step: 1
Training loss: 2.799530267715454
Validation loss: 2.3782290848352576

Epoch: 5| Step: 2
Training loss: 2.4776861667633057
Validation loss: 2.3678919640920495

Epoch: 5| Step: 3
Training loss: 3.153506278991699
Validation loss: 2.3554154211475002

Epoch: 5| Step: 4
Training loss: 2.1457600593566895
Validation loss: 2.3411445989403674

Epoch: 5| Step: 5
Training loss: 2.2025952339172363
Validation loss: 2.3290373509930027

Epoch: 5| Step: 6
Training loss: 2.845012903213501
Validation loss: 2.329706391980571

Epoch: 5| Step: 7
Training loss: 2.0985593795776367
Validation loss: 2.3254725984347764

Epoch: 5| Step: 8
Training loss: 2.8755035400390625
Validation loss: 2.3254742981285177

Epoch: 5| Step: 9
Training loss: 2.4797189235687256
Validation loss: 2.321413747725948

Epoch: 5| Step: 10
Training loss: 3.07053542137146
Validation loss: 2.326197954916185

Epoch: 82| Step: 0
Training loss: 2.9725520610809326
Validation loss: 2.3380203913616877

Epoch: 5| Step: 1
Training loss: 2.5627670288085938
Validation loss: 2.3406655890967256

Epoch: 5| Step: 2
Training loss: 2.733966827392578
Validation loss: 2.346917370314239

Epoch: 5| Step: 3
Training loss: 2.856463670730591
Validation loss: 2.3356671487131426

Epoch: 5| Step: 4
Training loss: 2.537668228149414
Validation loss: 2.325663394825433

Epoch: 5| Step: 5
Training loss: 2.823613405227661
Validation loss: 2.325442297484285

Epoch: 5| Step: 6
Training loss: 2.1764028072357178
Validation loss: 2.3212775235534995

Epoch: 5| Step: 7
Training loss: 2.5092437267303467
Validation loss: 2.324171663612448

Epoch: 5| Step: 8
Training loss: 2.5719738006591797
Validation loss: 2.318724050316759

Epoch: 5| Step: 9
Training loss: 2.5312817096710205
Validation loss: 2.3251781463623047

Epoch: 5| Step: 10
Training loss: 2.620079278945923
Validation loss: 2.3365789075051584

Epoch: 83| Step: 0
Training loss: 2.4246227741241455
Validation loss: 2.338934770194433

Epoch: 5| Step: 1
Training loss: 2.592578172683716
Validation loss: 2.3415170228609474

Epoch: 5| Step: 2
Training loss: 2.3559978008270264
Validation loss: 2.350681794587002

Epoch: 5| Step: 3
Training loss: 2.9417903423309326
Validation loss: 2.346143284151631

Epoch: 5| Step: 4
Training loss: 2.5259296894073486
Validation loss: 2.359140375609039

Epoch: 5| Step: 5
Training loss: 2.6415486335754395
Validation loss: 2.3406936019979496

Epoch: 5| Step: 6
Training loss: 2.809748888015747
Validation loss: 2.3378877793588946

Epoch: 5| Step: 7
Training loss: 2.71246075630188
Validation loss: 2.3232200299539874

Epoch: 5| Step: 8
Training loss: 3.058086633682251
Validation loss: 2.3242618473627235

Epoch: 5| Step: 9
Training loss: 2.3716659545898438
Validation loss: 2.3363160984490507

Epoch: 5| Step: 10
Training loss: 2.2365100383758545
Validation loss: 2.336105836335049

Epoch: 84| Step: 0
Training loss: 2.816394090652466
Validation loss: 2.3349884274185344

Epoch: 5| Step: 1
Training loss: 2.5592780113220215
Validation loss: 2.3196885073056785

Epoch: 5| Step: 2
Training loss: 2.585559844970703
Validation loss: 2.3103214463879986

Epoch: 5| Step: 3
Training loss: 2.218705654144287
Validation loss: 2.3071606877029582

Epoch: 5| Step: 4
Training loss: 3.0840868949890137
Validation loss: 2.31402563792403

Epoch: 5| Step: 5
Training loss: 2.3842108249664307
Validation loss: 2.3061228003553165

Epoch: 5| Step: 6
Training loss: 2.562866687774658
Validation loss: 2.3124162843150478

Epoch: 5| Step: 7
Training loss: 2.418816328048706
Validation loss: 2.3092151085535684

Epoch: 5| Step: 8
Training loss: 2.9176621437072754
Validation loss: 2.309310900267734

Epoch: 5| Step: 9
Training loss: 2.498091459274292
Validation loss: 2.3134630636502336

Epoch: 5| Step: 10
Training loss: 2.5722389221191406
Validation loss: 2.310977012880387

Epoch: 85| Step: 0
Training loss: 2.431302785873413
Validation loss: 2.3003822398442093

Epoch: 5| Step: 1
Training loss: 2.453587055206299
Validation loss: 2.318927154746107

Epoch: 5| Step: 2
Training loss: 2.6284403800964355
Validation loss: 2.324074083758939

Epoch: 5| Step: 3
Training loss: 3.5258095264434814
Validation loss: 2.3327371023034535

Epoch: 5| Step: 4
Training loss: 3.086686372756958
Validation loss: 2.3309610146348194

Epoch: 5| Step: 5
Training loss: 1.858559012413025
Validation loss: 2.3051633142655894

Epoch: 5| Step: 6
Training loss: 2.6881346702575684
Validation loss: 2.3074099889365574

Epoch: 5| Step: 7
Training loss: 1.8568423986434937
Validation loss: 2.3106033981487317

Epoch: 5| Step: 8
Training loss: 2.9787375926971436
Validation loss: 2.315865844808599

Epoch: 5| Step: 9
Training loss: 3.073969841003418
Validation loss: 2.309480790169008

Epoch: 5| Step: 10
Training loss: 2.063715696334839
Validation loss: 2.312414671785088

Epoch: 86| Step: 0
Training loss: 3.1077189445495605
Validation loss: 2.306747426268875

Epoch: 5| Step: 1
Training loss: 2.6823678016662598
Validation loss: 2.3094772882359003

Epoch: 5| Step: 2
Training loss: 2.1807093620300293
Validation loss: 2.3134001352453746

Epoch: 5| Step: 3
Training loss: 2.6058316230773926
Validation loss: 2.309482938499861

Epoch: 5| Step: 4
Training loss: 2.841818332672119
Validation loss: 2.3076838921475153

Epoch: 5| Step: 5
Training loss: 2.6275265216827393
Validation loss: 2.3143430461165724

Epoch: 5| Step: 6
Training loss: 3.379420757293701
Validation loss: 2.315819445476737

Epoch: 5| Step: 7
Training loss: 2.747439384460449
Validation loss: 2.304475656119726

Epoch: 5| Step: 8
Training loss: 1.7066913843154907
Validation loss: 2.3199819595583024

Epoch: 5| Step: 9
Training loss: 2.521592617034912
Validation loss: 2.346238528528521

Epoch: 5| Step: 10
Training loss: 1.917127251625061
Validation loss: 2.4005160613726546

Epoch: 87| Step: 0
Training loss: 2.60620379447937
Validation loss: 2.459131749727393

Epoch: 5| Step: 1
Training loss: 3.1649773120880127
Validation loss: 2.5174640609372045

Epoch: 5| Step: 2
Training loss: 2.8115432262420654
Validation loss: 2.465705569072436

Epoch: 5| Step: 3
Training loss: 2.9109561443328857
Validation loss: 2.4127489187384166

Epoch: 5| Step: 4
Training loss: 2.197582244873047
Validation loss: 2.359959407519269

Epoch: 5| Step: 5
Training loss: 2.3019111156463623
Validation loss: 2.334637454760972

Epoch: 5| Step: 6
Training loss: 2.25443959236145
Validation loss: 2.3033323672509964

Epoch: 5| Step: 7
Training loss: 2.4508602619171143
Validation loss: 2.3010924836640716

Epoch: 5| Step: 8
Training loss: 2.9500069618225098
Validation loss: 2.311687510500672

Epoch: 5| Step: 9
Training loss: 2.620532274246216
Validation loss: 2.3328300342764905

Epoch: 5| Step: 10
Training loss: 2.7922229766845703
Validation loss: 2.3583096688793552

Epoch: 88| Step: 0
Training loss: 2.9826748371124268
Validation loss: 2.3792356880762244

Epoch: 5| Step: 1
Training loss: 3.0393261909484863
Validation loss: 2.374504430319673

Epoch: 5| Step: 2
Training loss: 2.5403923988342285
Validation loss: 2.353355940952096

Epoch: 5| Step: 3
Training loss: 1.9072911739349365
Validation loss: 2.32973297180668

Epoch: 5| Step: 4
Training loss: 2.316969633102417
Validation loss: 2.299620879593716

Epoch: 5| Step: 5
Training loss: 2.8749732971191406
Validation loss: 2.2943335630560435

Epoch: 5| Step: 6
Training loss: 2.5837275981903076
Validation loss: 2.2983555357943297

Epoch: 5| Step: 7
Training loss: 3.043555498123169
Validation loss: 2.3058244387308755

Epoch: 5| Step: 8
Training loss: 2.817833423614502
Validation loss: 2.316063392546869

Epoch: 5| Step: 9
Training loss: 2.2947964668273926
Validation loss: 2.3383801137247393

Epoch: 5| Step: 10
Training loss: 2.2315545082092285
Validation loss: 2.384691748567807

Epoch: 89| Step: 0
Training loss: 2.7715976238250732
Validation loss: 2.370300039168327

Epoch: 5| Step: 1
Training loss: 2.8616814613342285
Validation loss: 2.343299091503184

Epoch: 5| Step: 2
Training loss: 3.1561789512634277
Validation loss: 2.3350694461535384

Epoch: 5| Step: 3
Training loss: 3.078434944152832
Validation loss: 2.3100945206098658

Epoch: 5| Step: 4
Training loss: 2.6531624794006348
Validation loss: 2.299412678646785

Epoch: 5| Step: 5
Training loss: 2.911869764328003
Validation loss: 2.2880518872250795

Epoch: 5| Step: 6
Training loss: 2.253117084503174
Validation loss: 2.2914033423187914

Epoch: 5| Step: 7
Training loss: 1.9356807470321655
Validation loss: 2.2948508442089124

Epoch: 5| Step: 8
Training loss: 2.0780749320983887
Validation loss: 2.294428594650761

Epoch: 5| Step: 9
Training loss: 2.712190628051758
Validation loss: 2.292181622597479

Epoch: 5| Step: 10
Training loss: 2.261091470718384
Validation loss: 2.288968457970568

Epoch: 90| Step: 0
Training loss: 2.6488847732543945
Validation loss: 2.290304424942181

Epoch: 5| Step: 1
Training loss: 3.1571364402770996
Validation loss: 2.2939159383055983

Epoch: 5| Step: 2
Training loss: 3.1854946613311768
Validation loss: 2.306495580621945

Epoch: 5| Step: 3
Training loss: 2.1005892753601074
Validation loss: 2.308946463369554

Epoch: 5| Step: 4
Training loss: 2.629176378250122
Validation loss: 2.308963837162141

Epoch: 5| Step: 5
Training loss: 2.2523961067199707
Validation loss: 2.316825612898796

Epoch: 5| Step: 6
Training loss: 1.902745246887207
Validation loss: 2.330875719747236

Epoch: 5| Step: 7
Training loss: 2.684055805206299
Validation loss: 2.345468836445962

Epoch: 5| Step: 8
Training loss: 2.7202212810516357
Validation loss: 2.3384114619224303

Epoch: 5| Step: 9
Training loss: 2.3381948471069336
Validation loss: 2.318304410544775

Epoch: 5| Step: 10
Training loss: 2.8264262676239014
Validation loss: 2.2959884392317904

Epoch: 91| Step: 0
Training loss: 2.587430477142334
Validation loss: 2.2847813201206986

Epoch: 5| Step: 1
Training loss: 2.9130942821502686
Validation loss: 2.2944969874556347

Epoch: 5| Step: 2
Training loss: 2.6815528869628906
Validation loss: 2.3109600556794034

Epoch: 5| Step: 3
Training loss: 2.056035280227661
Validation loss: 2.3294576932025213

Epoch: 5| Step: 4
Training loss: 2.75892972946167
Validation loss: 2.2909224366628997

Epoch: 5| Step: 5
Training loss: 2.6530215740203857
Validation loss: 2.2914022014987085

Epoch: 5| Step: 6
Training loss: 2.3995420932769775
Validation loss: 2.2811118197697464

Epoch: 5| Step: 7
Training loss: 2.0683035850524902
Validation loss: 2.2814653355588197

Epoch: 5| Step: 8
Training loss: 2.6813459396362305
Validation loss: 2.2826775017605034

Epoch: 5| Step: 9
Training loss: 2.981527090072632
Validation loss: 2.2842708505609983

Epoch: 5| Step: 10
Training loss: 2.7871158123016357
Validation loss: 2.277241676084457

Epoch: 92| Step: 0
Training loss: 2.3005192279815674
Validation loss: 2.2802576095827165

Epoch: 5| Step: 1
Training loss: 2.602959394454956
Validation loss: 2.2943595634993685

Epoch: 5| Step: 2
Training loss: 2.30647611618042
Validation loss: 2.309722897826984

Epoch: 5| Step: 3
Training loss: 2.786280632019043
Validation loss: 2.321593584552888

Epoch: 5| Step: 4
Training loss: 2.9100475311279297
Validation loss: 2.3173292785562496

Epoch: 5| Step: 5
Training loss: 2.433864116668701
Validation loss: 2.3258420831413678

Epoch: 5| Step: 6
Training loss: 2.2946231365203857
Validation loss: 2.3160865691400345

Epoch: 5| Step: 7
Training loss: 2.2406604290008545
Validation loss: 2.3093840422168856

Epoch: 5| Step: 8
Training loss: 2.992250442504883
Validation loss: 2.298052433998354

Epoch: 5| Step: 9
Training loss: 2.8885068893432617
Validation loss: 2.282029987663351

Epoch: 5| Step: 10
Training loss: 2.7244372367858887
Validation loss: 2.2762541232570523

Epoch: 93| Step: 0
Training loss: 2.8154072761535645
Validation loss: 2.2690936493617233

Epoch: 5| Step: 1
Training loss: 2.395242214202881
Validation loss: 2.268966749150266

Epoch: 5| Step: 2
Training loss: 2.259507656097412
Validation loss: 2.2709958066222486

Epoch: 5| Step: 3
Training loss: 2.9372565746307373
Validation loss: 2.2697169870458622

Epoch: 5| Step: 4
Training loss: 2.5167202949523926
Validation loss: 2.273724017604705

Epoch: 5| Step: 5
Training loss: 2.9747233390808105
Validation loss: 2.2737351617505475

Epoch: 5| Step: 6
Training loss: 2.705928087234497
Validation loss: 2.269462844376923

Epoch: 5| Step: 7
Training loss: 2.495448589324951
Validation loss: 2.2637388065297115

Epoch: 5| Step: 8
Training loss: 2.523756504058838
Validation loss: 2.267723406514814

Epoch: 5| Step: 9
Training loss: 2.587653636932373
Validation loss: 2.267082573265158

Epoch: 5| Step: 10
Training loss: 2.1798551082611084
Validation loss: 2.281290561922135

Epoch: 94| Step: 0
Training loss: 2.8821470737457275
Validation loss: 2.2955645822709605

Epoch: 5| Step: 1
Training loss: 3.2610034942626953
Validation loss: 2.3229295387062976

Epoch: 5| Step: 2
Training loss: 3.0097668170928955
Validation loss: 2.3430671948258595

Epoch: 5| Step: 3
Training loss: 2.8333277702331543
Validation loss: 2.3554261038380284

Epoch: 5| Step: 4
Training loss: 2.958174228668213
Validation loss: 2.362552527458437

Epoch: 5| Step: 5
Training loss: 2.216890335083008
Validation loss: 2.325468470973353

Epoch: 5| Step: 6
Training loss: 2.481527090072632
Validation loss: 2.2910775369213474

Epoch: 5| Step: 7
Training loss: 1.6892359256744385
Validation loss: 2.2830308547583957

Epoch: 5| Step: 8
Training loss: 3.037360906600952
Validation loss: 2.2658149221892

Epoch: 5| Step: 9
Training loss: 1.7225290536880493
Validation loss: 2.2606696095517886

Epoch: 5| Step: 10
Training loss: 2.1020348072052
Validation loss: 2.2658493313738095

Epoch: 95| Step: 0
Training loss: 2.5948503017425537
Validation loss: 2.2667551091922227

Epoch: 5| Step: 1
Training loss: 2.2896690368652344
Validation loss: 2.2632807839301323

Epoch: 5| Step: 2
Training loss: 2.7062697410583496
Validation loss: 2.2626575270006732

Epoch: 5| Step: 3
Training loss: 2.0046181678771973
Validation loss: 2.2586305782359135

Epoch: 5| Step: 4
Training loss: 2.412642478942871
Validation loss: 2.259424195494703

Epoch: 5| Step: 5
Training loss: 2.8767528533935547
Validation loss: 2.258960098348638

Epoch: 5| Step: 6
Training loss: 2.4485931396484375
Validation loss: 2.261498917815506

Epoch: 5| Step: 7
Training loss: 2.469712972640991
Validation loss: 2.2601491353845082

Epoch: 5| Step: 8
Training loss: 2.852288007736206
Validation loss: 2.2774132451703473

Epoch: 5| Step: 9
Training loss: 2.995809555053711
Validation loss: 2.2803615498286423

Epoch: 5| Step: 10
Training loss: 2.698629856109619
Validation loss: 2.285789451291484

Epoch: 96| Step: 0
Training loss: 2.2420341968536377
Validation loss: 2.2906085829580984

Epoch: 5| Step: 1
Training loss: 2.6034722328186035
Validation loss: 2.2823548880956506

Epoch: 5| Step: 2
Training loss: 3.205282211303711
Validation loss: 2.2595408090981106

Epoch: 5| Step: 3
Training loss: 3.076552391052246
Validation loss: 2.251172152898645

Epoch: 5| Step: 4
Training loss: 2.9642996788024902
Validation loss: 2.251101058016541

Epoch: 5| Step: 5
Training loss: 2.1343283653259277
Validation loss: 2.2503993383017917

Epoch: 5| Step: 6
Training loss: 2.573829174041748
Validation loss: 2.243637664343721

Epoch: 5| Step: 7
Training loss: 2.242676258087158
Validation loss: 2.2439247690221316

Epoch: 5| Step: 8
Training loss: 2.6447157859802246
Validation loss: 2.2421558492927143

Epoch: 5| Step: 9
Training loss: 2.0931284427642822
Validation loss: 2.241898713573333

Epoch: 5| Step: 10
Training loss: 2.551244020462036
Validation loss: 2.242449425881909

Epoch: 97| Step: 0
Training loss: 2.9421021938323975
Validation loss: 2.250032655654415

Epoch: 5| Step: 1
Training loss: 2.459881067276001
Validation loss: 2.2709150750149965

Epoch: 5| Step: 2
Training loss: 2.616579294204712
Validation loss: 2.2970750306242254

Epoch: 5| Step: 3
Training loss: 2.418929100036621
Validation loss: 2.2874141662351546

Epoch: 5| Step: 4
Training loss: 2.662019729614258
Validation loss: 2.2828559542214997

Epoch: 5| Step: 5
Training loss: 2.087947368621826
Validation loss: 2.2830444228264595

Epoch: 5| Step: 6
Training loss: 2.7159998416900635
Validation loss: 2.2787887562987623

Epoch: 5| Step: 7
Training loss: 2.2374181747436523
Validation loss: 2.2790429656223585

Epoch: 5| Step: 8
Training loss: 3.0939581394195557
Validation loss: 2.2726067548157065

Epoch: 5| Step: 9
Training loss: 2.2884557247161865
Validation loss: 2.2800091440959642

Epoch: 5| Step: 10
Training loss: 2.6156530380249023
Validation loss: 2.2805980431136263

Epoch: 98| Step: 0
Training loss: 2.5577893257141113
Validation loss: 2.28254004960419

Epoch: 5| Step: 1
Training loss: 2.4861645698547363
Validation loss: 2.281462651427074

Epoch: 5| Step: 2
Training loss: 2.690446376800537
Validation loss: 2.277887189260093

Epoch: 5| Step: 3
Training loss: 3.3581440448760986
Validation loss: 2.256342003422399

Epoch: 5| Step: 4
Training loss: 2.7725985050201416
Validation loss: 2.251638691912415

Epoch: 5| Step: 5
Training loss: 1.9668538570404053
Validation loss: 2.234068565471198

Epoch: 5| Step: 6
Training loss: 2.5495266914367676
Validation loss: 2.2441312190025084

Epoch: 5| Step: 7
Training loss: 2.4579825401306152
Validation loss: 2.2392888915154243

Epoch: 5| Step: 8
Training loss: 2.0286812782287598
Validation loss: 2.240469253191384

Epoch: 5| Step: 9
Training loss: 2.2558321952819824
Validation loss: 2.2335660662702335

Epoch: 5| Step: 10
Training loss: 3.114241361618042
Validation loss: 2.2378091760860976

Epoch: 99| Step: 0
Training loss: 2.723963499069214
Validation loss: 2.233562628428141

Epoch: 5| Step: 1
Training loss: 2.6185407638549805
Validation loss: 2.2353314353573706

Epoch: 5| Step: 2
Training loss: 2.516974449157715
Validation loss: 2.2360991380547963

Epoch: 5| Step: 3
Training loss: 2.644305944442749
Validation loss: 2.235282051947809

Epoch: 5| Step: 4
Training loss: 2.6265811920166016
Validation loss: 2.233043916763798

Epoch: 5| Step: 5
Training loss: 2.4989190101623535
Validation loss: 2.233757706098659

Epoch: 5| Step: 6
Training loss: 2.8229317665100098
Validation loss: 2.2252603064301195

Epoch: 5| Step: 7
Training loss: 3.1100125312805176
Validation loss: 2.2330452549842095

Epoch: 5| Step: 8
Training loss: 1.9019699096679688
Validation loss: 2.238878286013039

Epoch: 5| Step: 9
Training loss: 2.188530921936035
Validation loss: 2.2691430276440037

Epoch: 5| Step: 10
Training loss: 2.3776721954345703
Validation loss: 2.2921348976832565

Epoch: 100| Step: 0
Training loss: 2.352874517440796
Validation loss: 2.3133273945059827

Epoch: 5| Step: 1
Training loss: 2.771739959716797
Validation loss: 2.318612637058381

Epoch: 5| Step: 2
Training loss: 2.3646697998046875
Validation loss: 2.3089425127993346

Epoch: 5| Step: 3
Training loss: 2.7849907875061035
Validation loss: 2.330059530914471

Epoch: 5| Step: 4
Training loss: 2.121182918548584
Validation loss: 2.338035393786687

Epoch: 5| Step: 5
Training loss: 2.444735050201416
Validation loss: 2.3289154985899567

Epoch: 5| Step: 6
Training loss: 3.384124755859375
Validation loss: 2.295092898030435

Epoch: 5| Step: 7
Training loss: 2.1904056072235107
Validation loss: 2.267437332419939

Epoch: 5| Step: 8
Training loss: 2.1653456687927246
Validation loss: 2.2435156837586434

Epoch: 5| Step: 9
Training loss: 3.0685267448425293
Validation loss: 2.2298946611342894

Epoch: 5| Step: 10
Training loss: 2.387568712234497
Validation loss: 2.2222691659004457

Epoch: 101| Step: 0
Training loss: 2.525285243988037
Validation loss: 2.2239649206079464

Epoch: 5| Step: 1
Training loss: 2.651472806930542
Validation loss: 2.2176717737669587

Epoch: 5| Step: 2
Training loss: 3.2420852184295654
Validation loss: 2.2147298628284084

Epoch: 5| Step: 3
Training loss: 2.702965021133423
Validation loss: 2.217358608399668

Epoch: 5| Step: 4
Training loss: 1.9407691955566406
Validation loss: 2.223277399616857

Epoch: 5| Step: 5
Training loss: 2.5876212120056152
Validation loss: 2.2221826148289505

Epoch: 5| Step: 6
Training loss: 3.266934871673584
Validation loss: 2.219552957883445

Epoch: 5| Step: 7
Training loss: 2.5496623516082764
Validation loss: 2.214797019958496

Epoch: 5| Step: 8
Training loss: 1.9964065551757812
Validation loss: 2.2147151949585124

Epoch: 5| Step: 9
Training loss: 2.4696555137634277
Validation loss: 2.217293567554925

Epoch: 5| Step: 10
Training loss: 1.9539390802383423
Validation loss: 2.22341243169641

Epoch: 102| Step: 0
Training loss: 2.6904139518737793
Validation loss: 2.238171910726896

Epoch: 5| Step: 1
Training loss: 2.1899662017822266
Validation loss: 2.267632366508566

Epoch: 5| Step: 2
Training loss: 3.1793200969696045
Validation loss: 2.312906765168713

Epoch: 5| Step: 3
Training loss: 2.3952503204345703
Validation loss: 2.290440967006068

Epoch: 5| Step: 4
Training loss: 2.3223626613616943
Validation loss: 2.250263052601968

Epoch: 5| Step: 5
Training loss: 2.1124725341796875
Validation loss: 2.2478749290589364

Epoch: 5| Step: 6
Training loss: 2.2652041912078857
Validation loss: 2.2454323537888063

Epoch: 5| Step: 7
Training loss: 2.561344623565674
Validation loss: 2.2451285559643983

Epoch: 5| Step: 8
Training loss: 2.787153720855713
Validation loss: 2.2455362837801696

Epoch: 5| Step: 9
Training loss: 2.510402202606201
Validation loss: 2.2358940903858473

Epoch: 5| Step: 10
Training loss: 2.9422616958618164
Validation loss: 2.2447849012190297

Epoch: 103| Step: 0
Training loss: 2.754395008087158
Validation loss: 2.221030801855108

Epoch: 5| Step: 1
Training loss: 2.4294066429138184
Validation loss: 2.2176505083678872

Epoch: 5| Step: 2
Training loss: 2.7960824966430664
Validation loss: 2.2186693042837162

Epoch: 5| Step: 3
Training loss: 1.8900973796844482
Validation loss: 2.209251962682252

Epoch: 5| Step: 4
Training loss: 2.210096836090088
Validation loss: 2.207560763564161

Epoch: 5| Step: 5
Training loss: 3.0062360763549805
Validation loss: 2.2177850687375633

Epoch: 5| Step: 6
Training loss: 2.6779205799102783
Validation loss: 2.221055976806148

Epoch: 5| Step: 7
Training loss: 2.452268123626709
Validation loss: 2.2197093630349762

Epoch: 5| Step: 8
Training loss: 2.6198761463165283
Validation loss: 2.2125293054888324

Epoch: 5| Step: 9
Training loss: 2.448850154876709
Validation loss: 2.2237340532323366

Epoch: 5| Step: 10
Training loss: 2.507869243621826
Validation loss: 2.2090325714439474

Epoch: 104| Step: 0
Training loss: 2.800485134124756
Validation loss: 2.2170952109880346

Epoch: 5| Step: 1
Training loss: 2.8548951148986816
Validation loss: 2.221591511080342

Epoch: 5| Step: 2
Training loss: 2.4012489318847656
Validation loss: 2.2088805014087307

Epoch: 5| Step: 3
Training loss: 2.7477798461914062
Validation loss: 2.2206422116166804

Epoch: 5| Step: 4
Training loss: 2.1478536128997803
Validation loss: 2.228537195472307

Epoch: 5| Step: 5
Training loss: 2.2105178833007812
Validation loss: 2.2312912376978065

Epoch: 5| Step: 6
Training loss: 2.446692943572998
Validation loss: 2.2257894828755367

Epoch: 5| Step: 7
Training loss: 2.2509207725524902
Validation loss: 2.2380241194079

Epoch: 5| Step: 8
Training loss: 2.099984645843506
Validation loss: 2.2742535080961

Epoch: 5| Step: 9
Training loss: 3.4185802936553955
Validation loss: 2.3243277008815477

Epoch: 5| Step: 10
Training loss: 2.602656602859497
Validation loss: 2.3137198648145123

Epoch: 105| Step: 0
Training loss: 2.410693645477295
Validation loss: 2.2487607540622836

Epoch: 5| Step: 1
Training loss: 2.8861184120178223
Validation loss: 2.214343394002607

Epoch: 5| Step: 2
Training loss: 2.6846561431884766
Validation loss: 2.1927541917370212

Epoch: 5| Step: 3
Training loss: 2.371824264526367
Validation loss: 2.1999730986933552

Epoch: 5| Step: 4
Training loss: 2.0781028270721436
Validation loss: 2.2079339104314006

Epoch: 5| Step: 5
Training loss: 3.266885280609131
Validation loss: 2.2183658076870825

Epoch: 5| Step: 6
Training loss: 2.863354444503784
Validation loss: 2.221663987764748

Epoch: 5| Step: 7
Training loss: 2.284820079803467
Validation loss: 2.2230463438136603

Epoch: 5| Step: 8
Training loss: 2.52571964263916
Validation loss: 2.2186771541513424

Epoch: 5| Step: 9
Training loss: 2.360774517059326
Validation loss: 2.203071568601875

Epoch: 5| Step: 10
Training loss: 2.3989627361297607
Validation loss: 2.2048028848504506

Epoch: 106| Step: 0
Training loss: 2.4476027488708496
Validation loss: 2.2012776431216987

Epoch: 5| Step: 1
Training loss: 2.618654251098633
Validation loss: 2.1936722775941253

Epoch: 5| Step: 2
Training loss: 2.678896427154541
Validation loss: 2.1998163718049244

Epoch: 5| Step: 3
Training loss: 2.3894588947296143
Validation loss: 2.207213906831639

Epoch: 5| Step: 4
Training loss: 2.6028330326080322
Validation loss: 2.243008639222832

Epoch: 5| Step: 5
Training loss: 2.3304357528686523
Validation loss: 2.248127498934346

Epoch: 5| Step: 6
Training loss: 2.444133996963501
Validation loss: 2.2800459836118963

Epoch: 5| Step: 7
Training loss: 2.978839635848999
Validation loss: 2.2831544453097927

Epoch: 5| Step: 8
Training loss: 2.5710508823394775
Validation loss: 2.289037964677298

Epoch: 5| Step: 9
Training loss: 2.5622262954711914
Validation loss: 2.3244905625620196

Epoch: 5| Step: 10
Training loss: 2.3169007301330566
Validation loss: 2.3561506553362777

Epoch: 107| Step: 0
Training loss: 2.7059292793273926
Validation loss: 2.340264597246724

Epoch: 5| Step: 1
Training loss: 2.6360394954681396
Validation loss: 2.2671045257199194

Epoch: 5| Step: 2
Training loss: 2.348365545272827
Validation loss: 2.230308184059717

Epoch: 5| Step: 3
Training loss: 2.4339981079101562
Validation loss: 2.2084057100357546

Epoch: 5| Step: 4
Training loss: 2.359699249267578
Validation loss: 2.2084653403169368

Epoch: 5| Step: 5
Training loss: 2.808349132537842
Validation loss: 2.2090761482074694

Epoch: 5| Step: 6
Training loss: 2.6945929527282715
Validation loss: 2.205543020720123

Epoch: 5| Step: 7
Training loss: 2.3021976947784424
Validation loss: 2.200021856574602

Epoch: 5| Step: 8
Training loss: 2.7580599784851074
Validation loss: 2.1975566828122703

Epoch: 5| Step: 9
Training loss: 2.431671142578125
Validation loss: 2.1978660783460064

Epoch: 5| Step: 10
Training loss: 2.1479313373565674
Validation loss: 2.188979220646684

Epoch: 108| Step: 0
Training loss: 2.597032070159912
Validation loss: 2.190014580244659

Epoch: 5| Step: 1
Training loss: 3.2600200176239014
Validation loss: 2.1853158858514603

Epoch: 5| Step: 2
Training loss: 2.2288737297058105
Validation loss: 2.1888087795626734

Epoch: 5| Step: 3
Training loss: 2.862931489944458
Validation loss: 2.1930024726416475

Epoch: 5| Step: 4
Training loss: 2.5287299156188965
Validation loss: 2.1822801687384166

Epoch: 5| Step: 5
Training loss: 2.76973295211792
Validation loss: 2.1925227411331667

Epoch: 5| Step: 6
Training loss: 1.7776695489883423
Validation loss: 2.1902211045706146

Epoch: 5| Step: 7
Training loss: 2.0867934226989746
Validation loss: 2.195181051890055

Epoch: 5| Step: 8
Training loss: 2.317617654800415
Validation loss: 2.1901979254138086

Epoch: 5| Step: 9
Training loss: 2.955674409866333
Validation loss: 2.201013581727141

Epoch: 5| Step: 10
Training loss: 2.3443617820739746
Validation loss: 2.2190445597453783

Epoch: 109| Step: 0
Training loss: 3.040616750717163
Validation loss: 2.22487195076481

Epoch: 5| Step: 1
Training loss: 2.2494633197784424
Validation loss: 2.236481302527971

Epoch: 5| Step: 2
Training loss: 2.0246894359588623
Validation loss: 2.238439452263617

Epoch: 5| Step: 3
Training loss: 2.1093711853027344
Validation loss: 2.2314943190543883

Epoch: 5| Step: 4
Training loss: 2.4313361644744873
Validation loss: 2.2455662168482298

Epoch: 5| Step: 5
Training loss: 2.939512014389038
Validation loss: 2.240456888752599

Epoch: 5| Step: 6
Training loss: 3.352407455444336
Validation loss: 2.2737873318374797

Epoch: 5| Step: 7
Training loss: 2.1778860092163086
Validation loss: 2.286170841545187

Epoch: 5| Step: 8
Training loss: 2.1344475746154785
Validation loss: 2.258411536934555

Epoch: 5| Step: 9
Training loss: 2.382740020751953
Validation loss: 2.229525596864762

Epoch: 5| Step: 10
Training loss: 2.9729292392730713
Validation loss: 2.1972972987800516

Epoch: 110| Step: 0
Training loss: 2.813838243484497
Validation loss: 2.189578305008591

Epoch: 5| Step: 1
Training loss: 2.4150023460388184
Validation loss: 2.178289008396928

Epoch: 5| Step: 2
Training loss: 2.2720119953155518
Validation loss: 2.178703615742345

Epoch: 5| Step: 3
Training loss: 2.2521376609802246
Validation loss: 2.1794571568889003

Epoch: 5| Step: 4
Training loss: 2.295048713684082
Validation loss: 2.1818790640882266

Epoch: 5| Step: 5
Training loss: 2.702786922454834
Validation loss: 2.189924032457413

Epoch: 5| Step: 6
Training loss: 2.304494619369507
Validation loss: 2.204854796009679

Epoch: 5| Step: 7
Training loss: 2.8341732025146484
Validation loss: 2.2012560059947353

Epoch: 5| Step: 8
Training loss: 2.774278163909912
Validation loss: 2.202430127769388

Epoch: 5| Step: 9
Training loss: 2.760525941848755
Validation loss: 2.179951108911986

Epoch: 5| Step: 10
Training loss: 2.472357988357544
Validation loss: 2.182075967070877

Epoch: 111| Step: 0
Training loss: 2.094581365585327
Validation loss: 2.168903919958299

Epoch: 5| Step: 1
Training loss: 2.6850528717041016
Validation loss: 2.178216386866826

Epoch: 5| Step: 2
Training loss: 2.6160387992858887
Validation loss: 2.199260709106281

Epoch: 5| Step: 3
Training loss: 2.7832741737365723
Validation loss: 2.2008451236191617

Epoch: 5| Step: 4
Training loss: 2.2022316455841064
Validation loss: 2.211039927697951

Epoch: 5| Step: 5
Training loss: 2.6757559776306152
Validation loss: 2.221665600294708

Epoch: 5| Step: 6
Training loss: 2.4955077171325684
Validation loss: 2.222757239495554

Epoch: 5| Step: 7
Training loss: 2.0902609825134277
Validation loss: 2.2445813199525237

Epoch: 5| Step: 8
Training loss: 2.9412941932678223
Validation loss: 2.2655115871019262

Epoch: 5| Step: 9
Training loss: 2.9961931705474854
Validation loss: 2.2513118584950766

Epoch: 5| Step: 10
Training loss: 1.8047254085540771
Validation loss: 2.2292714016411894

Epoch: 112| Step: 0
Training loss: 2.632664203643799
Validation loss: 2.2151910951060634

Epoch: 5| Step: 1
Training loss: 2.293374538421631
Validation loss: 2.227652665107481

Epoch: 5| Step: 2
Training loss: 2.7543113231658936
Validation loss: 2.2149558374958653

Epoch: 5| Step: 3
Training loss: 2.8079593181610107
Validation loss: 2.2023405182746147

Epoch: 5| Step: 4
Training loss: 2.3460183143615723
Validation loss: 2.1938337766995994

Epoch: 5| Step: 5
Training loss: 2.356266736984253
Validation loss: 2.17332725627448

Epoch: 5| Step: 6
Training loss: 2.3976688385009766
Validation loss: 2.166120442011023

Epoch: 5| Step: 7
Training loss: 2.6997270584106445
Validation loss: 2.170429206663562

Epoch: 5| Step: 8
Training loss: 2.5227856636047363
Validation loss: 2.160939362741286

Epoch: 5| Step: 9
Training loss: 2.5637309551239014
Validation loss: 2.1722450974167034

Epoch: 5| Step: 10
Training loss: 2.0263166427612305
Validation loss: 2.16731527415655

Epoch: 113| Step: 0
Training loss: 1.7595866918563843
Validation loss: 2.1672330825559554

Epoch: 5| Step: 1
Training loss: 3.104203701019287
Validation loss: 2.1768073881826093

Epoch: 5| Step: 2
Training loss: 1.954334020614624
Validation loss: 2.1702298195131364

Epoch: 5| Step: 3
Training loss: 2.2906911373138428
Validation loss: 2.17300275833376

Epoch: 5| Step: 4
Training loss: 2.363962173461914
Validation loss: 2.1869525858151015

Epoch: 5| Step: 5
Training loss: 2.7292449474334717
Validation loss: 2.1908418722050165

Epoch: 5| Step: 6
Training loss: 2.8644776344299316
Validation loss: 2.2127441795923377

Epoch: 5| Step: 7
Training loss: 2.970747470855713
Validation loss: 2.229258519346996

Epoch: 5| Step: 8
Training loss: 2.3131346702575684
Validation loss: 2.2133635090243433

Epoch: 5| Step: 9
Training loss: 2.7034287452697754
Validation loss: 2.2071768494062525

Epoch: 5| Step: 10
Training loss: 2.4056971073150635
Validation loss: 2.1865626996563328

Epoch: 114| Step: 0
Training loss: 2.4110915660858154
Validation loss: 2.1770125563426683

Epoch: 5| Step: 1
Training loss: 2.438803195953369
Validation loss: 2.1669773478661813

Epoch: 5| Step: 2
Training loss: 2.1686630249023438
Validation loss: 2.165962649929908

Epoch: 5| Step: 3
Training loss: 2.8027167320251465
Validation loss: 2.169086633190032

Epoch: 5| Step: 4
Training loss: 3.1012046337127686
Validation loss: 2.1648009823214625

Epoch: 5| Step: 5
Training loss: 2.7723822593688965
Validation loss: 2.169401479023759

Epoch: 5| Step: 6
Training loss: 1.9866641759872437
Validation loss: 2.1709187658884193

Epoch: 5| Step: 7
Training loss: 2.330172061920166
Validation loss: 2.168332883106765

Epoch: 5| Step: 8
Training loss: 2.3040928840637207
Validation loss: 2.1720530858603855

Epoch: 5| Step: 9
Training loss: 2.4618499279022217
Validation loss: 2.171627685587893

Epoch: 5| Step: 10
Training loss: 2.493154764175415
Validation loss: 2.1713254913207023

Epoch: 115| Step: 0
Training loss: 2.2479705810546875
Validation loss: 2.161337326931697

Epoch: 5| Step: 1
Training loss: 3.102694511413574
Validation loss: 2.1571358634579565

Epoch: 5| Step: 2
Training loss: 2.0938923358917236
Validation loss: 2.158738656710553

Epoch: 5| Step: 3
Training loss: 2.8271117210388184
Validation loss: 2.1604246170290056

Epoch: 5| Step: 4
Training loss: 2.9269680976867676
Validation loss: 2.1571585465502996

Epoch: 5| Step: 5
Training loss: 2.3812673091888428
Validation loss: 2.1684051457271782

Epoch: 5| Step: 6
Training loss: 2.0960400104522705
Validation loss: 2.17536925244075

Epoch: 5| Step: 7
Training loss: 2.653839588165283
Validation loss: 2.2106461678781817

Epoch: 5| Step: 8
Training loss: 2.149367094039917
Validation loss: 2.191957580145969

Epoch: 5| Step: 9
Training loss: 2.3339009284973145
Validation loss: 2.1918981562378588

Epoch: 5| Step: 10
Training loss: 2.5156009197235107
Validation loss: 2.159744926678237

Epoch: 116| Step: 0
Training loss: 2.1524767875671387
Validation loss: 2.1598511895825787

Epoch: 5| Step: 1
Training loss: 2.207052707672119
Validation loss: 2.152445744442683

Epoch: 5| Step: 2
Training loss: 2.0990428924560547
Validation loss: 2.155176975393808

Epoch: 5| Step: 3
Training loss: 2.607797145843506
Validation loss: 2.1551218468655824

Epoch: 5| Step: 4
Training loss: 1.7831575870513916
Validation loss: 2.1584738069964993

Epoch: 5| Step: 5
Training loss: 3.1430325508117676
Validation loss: 2.150719396529659

Epoch: 5| Step: 6
Training loss: 2.5586295127868652
Validation loss: 2.1526321108623216

Epoch: 5| Step: 7
Training loss: 2.617647409439087
Validation loss: 2.1535461230944564

Epoch: 5| Step: 8
Training loss: 2.920048475265503
Validation loss: 2.160935527534895

Epoch: 5| Step: 9
Training loss: 2.4955623149871826
Validation loss: 2.173599745637627

Epoch: 5| Step: 10
Training loss: 2.8223958015441895
Validation loss: 2.186384671477861

Epoch: 117| Step: 0
Training loss: 2.756472587585449
Validation loss: 2.179515395113217

Epoch: 5| Step: 1
Training loss: 2.266777515411377
Validation loss: 2.1559376408976894

Epoch: 5| Step: 2
Training loss: 3.0591015815734863
Validation loss: 2.1492348717105005

Epoch: 5| Step: 3
Training loss: 2.454617977142334
Validation loss: 2.141331664977535

Epoch: 5| Step: 4
Training loss: 3.0617709159851074
Validation loss: 2.151006979327048

Epoch: 5| Step: 5
Training loss: 1.9981534481048584
Validation loss: 2.1537136544463453

Epoch: 5| Step: 6
Training loss: 2.7519752979278564
Validation loss: 2.161046073000918

Epoch: 5| Step: 7
Training loss: 2.1911518573760986
Validation loss: 2.166769350728681

Epoch: 5| Step: 8
Training loss: 1.9542557001113892
Validation loss: 2.210342994300268

Epoch: 5| Step: 9
Training loss: 2.0611565113067627
Validation loss: 2.2460149385595836

Epoch: 5| Step: 10
Training loss: 2.646615982055664
Validation loss: 2.2554169188263598

Epoch: 118| Step: 0
Training loss: 2.171973705291748
Validation loss: 2.18318340598896

Epoch: 5| Step: 1
Training loss: 2.324774742126465
Validation loss: 2.1485706695946316

Epoch: 5| Step: 2
Training loss: 2.8391144275665283
Validation loss: 2.1426253293150213

Epoch: 5| Step: 3
Training loss: 1.9626715183258057
Validation loss: 2.143473090664033

Epoch: 5| Step: 4
Training loss: 2.2941837310791016
Validation loss: 2.147269815526983

Epoch: 5| Step: 5
Training loss: 3.4742934703826904
Validation loss: 2.1369420930903447

Epoch: 5| Step: 6
Training loss: 1.8794466257095337
Validation loss: 2.1347866160895235

Epoch: 5| Step: 7
Training loss: 1.985796570777893
Validation loss: 2.1507153331592517

Epoch: 5| Step: 8
Training loss: 2.510457754135132
Validation loss: 2.1607126241089194

Epoch: 5| Step: 9
Training loss: 3.0806221961975098
Validation loss: 2.216687020435128

Epoch: 5| Step: 10
Training loss: 3.1004176139831543
Validation loss: 2.283120414262177

Epoch: 119| Step: 0
Training loss: 3.140573501586914
Validation loss: 2.3146939662195023

Epoch: 5| Step: 1
Training loss: 2.10925030708313
Validation loss: 2.324291052356843

Epoch: 5| Step: 2
Training loss: 2.064732789993286
Validation loss: 2.2788417441870576

Epoch: 5| Step: 3
Training loss: 2.2085578441619873
Validation loss: 2.238505050700198

Epoch: 5| Step: 4
Training loss: 2.778752326965332
Validation loss: 2.185002629474927

Epoch: 5| Step: 5
Training loss: 1.8890899419784546
Validation loss: 2.1656889172010523

Epoch: 5| Step: 6
Training loss: 2.542661428451538
Validation loss: 2.15342487442878

Epoch: 5| Step: 7
Training loss: 2.5583739280700684
Validation loss: 2.1336891446062314

Epoch: 5| Step: 8
Training loss: 2.196967601776123
Validation loss: 2.134383673308998

Epoch: 5| Step: 9
Training loss: 2.962233781814575
Validation loss: 2.157010127139348

Epoch: 5| Step: 10
Training loss: 3.0554168224334717
Validation loss: 2.1561123401887956

Epoch: 120| Step: 0
Training loss: 2.196138620376587
Validation loss: 2.1516026732742146

Epoch: 5| Step: 1
Training loss: 3.1769282817840576
Validation loss: 2.159599093980687

Epoch: 5| Step: 2
Training loss: 1.8366912603378296
Validation loss: 2.140981392193866

Epoch: 5| Step: 3
Training loss: 2.0655527114868164
Validation loss: 2.1380105095524944

Epoch: 5| Step: 4
Training loss: 2.9360413551330566
Validation loss: 2.129061245149182

Epoch: 5| Step: 5
Training loss: 2.1012167930603027
Validation loss: 2.147390211782148

Epoch: 5| Step: 6
Training loss: 2.6186747550964355
Validation loss: 2.1768582456855365

Epoch: 5| Step: 7
Training loss: 2.1997170448303223
Validation loss: 2.209078670829855

Epoch: 5| Step: 8
Training loss: 2.528057813644409
Validation loss: 2.2574414130180114

Epoch: 5| Step: 9
Training loss: 2.791804790496826
Validation loss: 2.2826864386117585

Epoch: 5| Step: 10
Training loss: 3.1886510848999023
Validation loss: 2.279802812043057

Epoch: 121| Step: 0
Training loss: 2.2480883598327637
Validation loss: 2.2505427483589417

Epoch: 5| Step: 1
Training loss: 2.1859593391418457
Validation loss: 2.208410229734195

Epoch: 5| Step: 2
Training loss: 2.5541036128997803
Validation loss: 2.178794127638622

Epoch: 5| Step: 3
Training loss: 2.984959602355957
Validation loss: 2.153777504480013

Epoch: 5| Step: 4
Training loss: 2.3674652576446533
Validation loss: 2.1510636486032957

Epoch: 5| Step: 5
Training loss: 2.1929450035095215
Validation loss: 2.1487142732066493

Epoch: 5| Step: 6
Training loss: 2.6542277336120605
Validation loss: 2.1436067537594865

Epoch: 5| Step: 7
Training loss: 2.8049302101135254
Validation loss: 2.139990602770159

Epoch: 5| Step: 8
Training loss: 2.357041120529175
Validation loss: 2.149798059976229

Epoch: 5| Step: 9
Training loss: 2.0696239471435547
Validation loss: 2.146476076495263

Epoch: 5| Step: 10
Training loss: 2.6977410316467285
Validation loss: 2.173776157440678

Epoch: 122| Step: 0
Training loss: 3.315570116043091
Validation loss: 2.173286900725416

Epoch: 5| Step: 1
Training loss: 2.6365678310394287
Validation loss: 2.1722824124879736

Epoch: 5| Step: 2
Training loss: 2.4997305870056152
Validation loss: 2.144555048276019

Epoch: 5| Step: 3
Training loss: 2.7588729858398438
Validation loss: 2.148737692063855

Epoch: 5| Step: 4
Training loss: 1.601332426071167
Validation loss: 2.133565079781317

Epoch: 5| Step: 5
Training loss: 2.1444363594055176
Validation loss: 2.1317830060117986

Epoch: 5| Step: 6
Training loss: 2.381730794906616
Validation loss: 2.1305204360715804

Epoch: 5| Step: 7
Training loss: 2.203343391418457
Validation loss: 2.135950441001564

Epoch: 5| Step: 8
Training loss: 2.36972713470459
Validation loss: 2.134526421946864

Epoch: 5| Step: 9
Training loss: 2.088193416595459
Validation loss: 2.136828291800714

Epoch: 5| Step: 10
Training loss: 3.0320661067962646
Validation loss: 2.129823846201743

Epoch: 123| Step: 0
Training loss: 2.475750207901001
Validation loss: 2.1343920692320792

Epoch: 5| Step: 1
Training loss: 2.1248364448547363
Validation loss: 2.1398826888812486

Epoch: 5| Step: 2
Training loss: 2.6050174236297607
Validation loss: 2.1294980664407053

Epoch: 5| Step: 3
Training loss: 2.5118069648742676
Validation loss: 2.1436618989513767

Epoch: 5| Step: 4
Training loss: 2.67531418800354
Validation loss: 2.1469656062382523

Epoch: 5| Step: 5
Training loss: 2.5300183296203613
Validation loss: 2.1686459279829458

Epoch: 5| Step: 6
Training loss: 2.4471912384033203
Validation loss: 2.1588134278533277

Epoch: 5| Step: 7
Training loss: 2.140681743621826
Validation loss: 2.148065476007359

Epoch: 5| Step: 8
Training loss: 2.1964550018310547
Validation loss: 2.1391338802153066

Epoch: 5| Step: 9
Training loss: 2.6750683784484863
Validation loss: 2.1438314658339306

Epoch: 5| Step: 10
Training loss: 2.3521015644073486
Validation loss: 2.142875871350688

Epoch: 124| Step: 0
Training loss: 2.8744354248046875
Validation loss: 2.1417963607336885

Epoch: 5| Step: 1
Training loss: 2.5523247718811035
Validation loss: 2.1286385482357395

Epoch: 5| Step: 2
Training loss: 2.2714743614196777
Validation loss: 2.1269534044368292

Epoch: 5| Step: 3
Training loss: 2.176729440689087
Validation loss: 2.134454955336868

Epoch: 5| Step: 4
Training loss: 2.4446358680725098
Validation loss: 2.1404483677238546

Epoch: 5| Step: 5
Training loss: 2.653411388397217
Validation loss: 2.156556216619348

Epoch: 5| Step: 6
Training loss: 1.981269121170044
Validation loss: 2.1313452233550367

Epoch: 5| Step: 7
Training loss: 2.5297045707702637
Validation loss: 2.1173452177355365

Epoch: 5| Step: 8
Training loss: 2.444707155227661
Validation loss: 2.118970663316788

Epoch: 5| Step: 9
Training loss: 2.8456270694732666
Validation loss: 2.116664776238062

Epoch: 5| Step: 10
Training loss: 1.9526420831680298
Validation loss: 2.111557150399813

Epoch: 125| Step: 0
Training loss: 2.146355390548706
Validation loss: 2.1054676207163

Epoch: 5| Step: 1
Training loss: 2.2847931385040283
Validation loss: 2.1099890637141403

Epoch: 5| Step: 2
Training loss: 2.7068417072296143
Validation loss: 2.1109754500850553

Epoch: 5| Step: 3
Training loss: 2.4779715538024902
Validation loss: 2.1189455934750137

Epoch: 5| Step: 4
Training loss: 2.558309555053711
Validation loss: 2.134195227776804

Epoch: 5| Step: 5
Training loss: 2.9627814292907715
Validation loss: 2.173327584420481

Epoch: 5| Step: 6
Training loss: 2.8119711875915527
Validation loss: 2.2142841995403333

Epoch: 5| Step: 7
Training loss: 2.2221837043762207
Validation loss: 2.199333272954469

Epoch: 5| Step: 8
Training loss: 2.286140203475952
Validation loss: 2.185790882315687

Epoch: 5| Step: 9
Training loss: 2.292142868041992
Validation loss: 2.1657443046569824

Epoch: 5| Step: 10
Training loss: 2.3363471031188965
Validation loss: 2.1201009917002853

Epoch: 126| Step: 0
Training loss: 2.408473253250122
Validation loss: 2.1119036366862636

Epoch: 5| Step: 1
Training loss: 2.680602550506592
Validation loss: 2.113606574714825

Epoch: 5| Step: 2
Training loss: 2.066758632659912
Validation loss: 2.1138488631094656

Epoch: 5| Step: 3
Training loss: 2.477734327316284
Validation loss: 2.1176551490701656

Epoch: 5| Step: 4
Training loss: 1.8588476181030273
Validation loss: 2.118438290011498

Epoch: 5| Step: 5
Training loss: 2.4431846141815186
Validation loss: 2.1422295416555097

Epoch: 5| Step: 6
Training loss: 2.806441068649292
Validation loss: 2.1677963964400755

Epoch: 5| Step: 7
Training loss: 2.4236342906951904
Validation loss: 2.1856722447179977

Epoch: 5| Step: 8
Training loss: 2.476902723312378
Validation loss: 2.183497669876263

Epoch: 5| Step: 9
Training loss: 2.6474456787109375
Validation loss: 2.169008739532963

Epoch: 5| Step: 10
Training loss: 2.7494921684265137
Validation loss: 2.1493567215499056

Epoch: 127| Step: 0
Training loss: 2.110856533050537
Validation loss: 2.1264853272386777

Epoch: 5| Step: 1
Training loss: 2.6853318214416504
Validation loss: 2.1210022690475627

Epoch: 5| Step: 2
Training loss: 2.4907195568084717
Validation loss: 2.1223945463857343

Epoch: 5| Step: 3
Training loss: 3.0749471187591553
Validation loss: 2.12428213960381

Epoch: 5| Step: 4
Training loss: 2.102869749069214
Validation loss: 2.1161399246543966

Epoch: 5| Step: 5
Training loss: 2.5016729831695557
Validation loss: 2.1075195125354234

Epoch: 5| Step: 6
Training loss: 2.011141300201416
Validation loss: 2.1133269007487963

Epoch: 5| Step: 7
Training loss: 2.4153378009796143
Validation loss: 2.118611499827395

Epoch: 5| Step: 8
Training loss: 2.669908046722412
Validation loss: 2.126662936261905

Epoch: 5| Step: 9
Training loss: 2.5262610912323
Validation loss: 2.1232270707366285

Epoch: 5| Step: 10
Training loss: 2.047394037246704
Validation loss: 2.1235198205517185

Epoch: 128| Step: 0
Training loss: 2.8145346641540527
Validation loss: 2.1297976688672136

Epoch: 5| Step: 1
Training loss: 2.637063503265381
Validation loss: 2.124585695164178

Epoch: 5| Step: 2
Training loss: 2.8949687480926514
Validation loss: 2.1137051531063613

Epoch: 5| Step: 3
Training loss: 2.6567068099975586
Validation loss: 2.101767942469607

Epoch: 5| Step: 4
Training loss: 2.1188507080078125
Validation loss: 2.10188485986443

Epoch: 5| Step: 5
Training loss: 2.2633755207061768
Validation loss: 2.091440168760156

Epoch: 5| Step: 6
Training loss: 2.4781432151794434
Validation loss: 2.095724839036183

Epoch: 5| Step: 7
Training loss: 1.8029483556747437
Validation loss: 2.099004271209881

Epoch: 5| Step: 8
Training loss: 2.539712905883789
Validation loss: 2.103129898348162

Epoch: 5| Step: 9
Training loss: 2.098433494567871
Validation loss: 2.1269025648793867

Epoch: 5| Step: 10
Training loss: 2.4420249462127686
Validation loss: 2.1604779074268956

Epoch: 129| Step: 0
Training loss: 2.453585386276245
Validation loss: 2.1741156936973653

Epoch: 5| Step: 1
Training loss: 2.072500705718994
Validation loss: 2.186231384995163

Epoch: 5| Step: 2
Training loss: 2.979854106903076
Validation loss: 2.169556184481549

Epoch: 5| Step: 3
Training loss: 2.7332189083099365
Validation loss: 2.1487273362375077

Epoch: 5| Step: 4
Training loss: 2.2672576904296875
Validation loss: 2.1013838424477527

Epoch: 5| Step: 5
Training loss: 1.1648037433624268
Validation loss: 2.0914882267675092

Epoch: 5| Step: 6
Training loss: 2.7528765201568604
Validation loss: 2.0875616701700355

Epoch: 5| Step: 7
Training loss: 2.8604636192321777
Validation loss: 2.091402397360853

Epoch: 5| Step: 8
Training loss: 2.959446907043457
Validation loss: 2.0925165273809947

Epoch: 5| Step: 9
Training loss: 1.9426475763320923
Validation loss: 2.0921018149263118

Epoch: 5| Step: 10
Training loss: 2.4954299926757812
Validation loss: 2.085123413352556

Epoch: 130| Step: 0
Training loss: 2.3261427879333496
Validation loss: 2.0857330637593425

Epoch: 5| Step: 1
Training loss: 2.278237819671631
Validation loss: 2.1167381091784407

Epoch: 5| Step: 2
Training loss: 2.3228087425231934
Validation loss: 2.163246964895597

Epoch: 5| Step: 3
Training loss: 2.4137134552001953
Validation loss: 2.1746862498662805

Epoch: 5| Step: 4
Training loss: 2.9708361625671387
Validation loss: 2.172483721087056

Epoch: 5| Step: 5
Training loss: 3.415041446685791
Validation loss: 2.1675375738451557

Epoch: 5| Step: 6
Training loss: 2.4549145698547363
Validation loss: 2.1307173211087465

Epoch: 5| Step: 7
Training loss: 1.5340607166290283
Validation loss: 2.1169075876153927

Epoch: 5| Step: 8
Training loss: 2.928124189376831
Validation loss: 2.0987784080607916

Epoch: 5| Step: 9
Training loss: 1.7844537496566772
Validation loss: 2.0860874601589736

Epoch: 5| Step: 10
Training loss: 2.055516004562378
Validation loss: 2.087594670634116

Epoch: 131| Step: 0
Training loss: 1.8547089099884033
Validation loss: 2.0957839335164716

Epoch: 5| Step: 1
Training loss: 2.5984625816345215
Validation loss: 2.092948013736356

Epoch: 5| Step: 2
Training loss: 2.639662504196167
Validation loss: 2.090571181748503

Epoch: 5| Step: 3
Training loss: 2.3440864086151123
Validation loss: 2.1131446233359714

Epoch: 5| Step: 4
Training loss: 1.7353508472442627
Validation loss: 2.1384040360809653

Epoch: 5| Step: 5
Training loss: 3.227574110031128
Validation loss: 2.158163824389058

Epoch: 5| Step: 6
Training loss: 2.60492205619812
Validation loss: 2.175880762838548

Epoch: 5| Step: 7
Training loss: 2.7536540031433105
Validation loss: 2.1446081720372683

Epoch: 5| Step: 8
Training loss: 1.7895183563232422
Validation loss: 2.099067355996819

Epoch: 5| Step: 9
Training loss: 2.5494797229766846
Validation loss: 2.0862329467650382

Epoch: 5| Step: 10
Training loss: 2.277799606323242
Validation loss: 2.0853610115666545

Epoch: 132| Step: 0
Training loss: 2.7747790813446045
Validation loss: 2.088784968981179

Epoch: 5| Step: 1
Training loss: 2.348161220550537
Validation loss: 2.0844306035708358

Epoch: 5| Step: 2
Training loss: 1.996991753578186
Validation loss: 2.089571596473776

Epoch: 5| Step: 3
Training loss: 2.4996752738952637
Validation loss: 2.0892065366109214

Epoch: 5| Step: 4
Training loss: 2.5453295707702637
Validation loss: 2.0818848327923845

Epoch: 5| Step: 5
Training loss: 2.80112624168396
Validation loss: 2.07969864209493

Epoch: 5| Step: 6
Training loss: 1.8614652156829834
Validation loss: 2.1234402771919005

Epoch: 5| Step: 7
Training loss: 2.6771113872528076
Validation loss: 2.174771742154193

Epoch: 5| Step: 8
Training loss: 2.111311435699463
Validation loss: 2.192127355965235

Epoch: 5| Step: 9
Training loss: 2.5237293243408203
Validation loss: 2.170085694200249

Epoch: 5| Step: 10
Training loss: 2.8303158283233643
Validation loss: 2.1323398338851107

Epoch: 133| Step: 0
Training loss: 2.1813149452209473
Validation loss: 2.1036151519385715

Epoch: 5| Step: 1
Training loss: 2.6056418418884277
Validation loss: 2.091440286687625

Epoch: 5| Step: 2
Training loss: 2.694871187210083
Validation loss: 2.088935705923265

Epoch: 5| Step: 3
Training loss: 2.2342472076416016
Validation loss: 2.0735413310348347

Epoch: 5| Step: 4
Training loss: 2.3725407123565674
Validation loss: 2.082200284927122

Epoch: 5| Step: 5
Training loss: 2.3248181343078613
Validation loss: 2.0833469936924596

Epoch: 5| Step: 6
Training loss: 2.235564947128296
Validation loss: 2.0986161155085408

Epoch: 5| Step: 7
Training loss: 2.5179522037506104
Validation loss: 2.125017698093127

Epoch: 5| Step: 8
Training loss: 2.50761342048645
Validation loss: 2.1310181861282675

Epoch: 5| Step: 9
Training loss: 2.464338779449463
Validation loss: 2.1473460594813027

Epoch: 5| Step: 10
Training loss: 2.216639280319214
Validation loss: 2.1389909059770646

Epoch: 134| Step: 0
Training loss: 2.957771062850952
Validation loss: 2.1239850995361165

Epoch: 5| Step: 1
Training loss: 2.5264134407043457
Validation loss: 2.113336101655037

Epoch: 5| Step: 2
Training loss: 2.2884819507598877
Validation loss: 2.1070884196988997

Epoch: 5| Step: 3
Training loss: 1.584486961364746
Validation loss: 2.118441274089198

Epoch: 5| Step: 4
Training loss: 2.3615665435791016
Validation loss: 2.107018368218535

Epoch: 5| Step: 5
Training loss: 2.4232230186462402
Validation loss: 2.1052162365246843

Epoch: 5| Step: 6
Training loss: 1.8300220966339111
Validation loss: 2.0892458167127383

Epoch: 5| Step: 7
Training loss: 2.901515483856201
Validation loss: 2.068336867517041

Epoch: 5| Step: 8
Training loss: 2.3683888912200928
Validation loss: 2.0655549905633412

Epoch: 5| Step: 9
Training loss: 2.8905301094055176
Validation loss: 2.0682868239700154

Epoch: 5| Step: 10
Training loss: 2.1365270614624023
Validation loss: 2.066667828508603

Epoch: 135| Step: 0
Training loss: 2.365635395050049
Validation loss: 2.067632839243899

Epoch: 5| Step: 1
Training loss: 1.7453778982162476
Validation loss: 2.060574928919474

Epoch: 5| Step: 2
Training loss: 2.4257988929748535
Validation loss: 2.077896007927515

Epoch: 5| Step: 3
Training loss: 2.3757026195526123
Validation loss: 2.0678569450173327

Epoch: 5| Step: 4
Training loss: 1.855952501296997
Validation loss: 2.067212761089366

Epoch: 5| Step: 5
Training loss: 2.751492977142334
Validation loss: 2.084376250543902

Epoch: 5| Step: 6
Training loss: 2.5891671180725098
Validation loss: 2.1062737434141097

Epoch: 5| Step: 7
Training loss: 2.7751636505126953
Validation loss: 2.135122335085305

Epoch: 5| Step: 8
Training loss: 2.4994492530822754
Validation loss: 2.1779246202079197

Epoch: 5| Step: 9
Training loss: 1.8745553493499756
Validation loss: 2.1859409398930048

Epoch: 5| Step: 10
Training loss: 2.9998602867126465
Validation loss: 2.171474220932171

Epoch: 136| Step: 0
Training loss: 2.2778022289276123
Validation loss: 2.1362774859192553

Epoch: 5| Step: 1
Training loss: 3.1036744117736816
Validation loss: 2.1011832324407433

Epoch: 5| Step: 2
Training loss: 2.562556028366089
Validation loss: 2.083877258403327

Epoch: 5| Step: 3
Training loss: 2.5740599632263184
Validation loss: 2.0682447366817023

Epoch: 5| Step: 4
Training loss: 2.2113125324249268
Validation loss: 2.069221878564486

Epoch: 5| Step: 5
Training loss: 1.450877070426941
Validation loss: 2.0530548454612814

Epoch: 5| Step: 6
Training loss: 2.5130810737609863
Validation loss: 2.060342963023852

Epoch: 5| Step: 7
Training loss: 2.6669020652770996
Validation loss: 2.0622877997736775

Epoch: 5| Step: 8
Training loss: 2.4275968074798584
Validation loss: 2.053335597438197

Epoch: 5| Step: 9
Training loss: 1.9412330389022827
Validation loss: 2.056825669862891

Epoch: 5| Step: 10
Training loss: 2.4669477939605713
Validation loss: 2.0547211426560597

Epoch: 137| Step: 0
Training loss: 2.905881881713867
Validation loss: 2.0625248673141643

Epoch: 5| Step: 1
Training loss: 2.5645925998687744
Validation loss: 2.0557102900679394

Epoch: 5| Step: 2
Training loss: 2.2716028690338135
Validation loss: 2.0576847343034643

Epoch: 5| Step: 3
Training loss: 2.1822240352630615
Validation loss: 2.0676158935792985

Epoch: 5| Step: 4
Training loss: 1.8168102502822876
Validation loss: 2.063725474060223

Epoch: 5| Step: 5
Training loss: 2.806898832321167
Validation loss: 2.060146144641343

Epoch: 5| Step: 6
Training loss: 2.853449821472168
Validation loss: 2.07395964412279

Epoch: 5| Step: 7
Training loss: 2.163346529006958
Validation loss: 2.0749661076453423

Epoch: 5| Step: 8
Training loss: 2.1845645904541016
Validation loss: 2.0651657606965754

Epoch: 5| Step: 9
Training loss: 2.4557907581329346
Validation loss: 2.0629459017066547

Epoch: 5| Step: 10
Training loss: 1.6608994007110596
Validation loss: 2.062068393153529

Epoch: 138| Step: 0
Training loss: 2.7441184520721436
Validation loss: 2.0720804083731865

Epoch: 5| Step: 1
Training loss: 2.571514129638672
Validation loss: 2.0629836154240433

Epoch: 5| Step: 2
Training loss: 1.736325979232788
Validation loss: 2.0623960328358475

Epoch: 5| Step: 3
Training loss: 2.091325283050537
Validation loss: 2.0754093457293767

Epoch: 5| Step: 4
Training loss: 3.2670090198516846
Validation loss: 2.084408885689192

Epoch: 5| Step: 5
Training loss: 1.584649682044983
Validation loss: 2.087552550018475

Epoch: 5| Step: 6
Training loss: 2.580940008163452
Validation loss: 2.083847058716641

Epoch: 5| Step: 7
Training loss: 2.3672962188720703
Validation loss: 2.070316094224171

Epoch: 5| Step: 8
Training loss: 2.3038387298583984
Validation loss: 2.0589277385383524

Epoch: 5| Step: 9
Training loss: 2.1968350410461426
Validation loss: 2.0579477561417447

Epoch: 5| Step: 10
Training loss: 2.4847936630249023
Validation loss: 2.0654033640379548

Epoch: 139| Step: 0
Training loss: 2.355274200439453
Validation loss: 2.0656149079722743

Epoch: 5| Step: 1
Training loss: 2.4082095623016357
Validation loss: 2.0527551648437337

Epoch: 5| Step: 2
Training loss: 2.185575008392334
Validation loss: 2.0531766414642334

Epoch: 5| Step: 3
Training loss: 2.5433876514434814
Validation loss: 2.054157257080078

Epoch: 5| Step: 4
Training loss: 2.094320297241211
Validation loss: 2.0563767110147784

Epoch: 5| Step: 5
Training loss: 2.1918158531188965
Validation loss: 2.0638669716414584

Epoch: 5| Step: 6
Training loss: 2.47343373298645
Validation loss: 2.0986869668447845

Epoch: 5| Step: 7
Training loss: 3.4951515197753906
Validation loss: 2.080004345986151

Epoch: 5| Step: 8
Training loss: 2.0229439735412598
Validation loss: 2.0919686671226256

Epoch: 5| Step: 9
Training loss: 2.10790753364563
Validation loss: 2.0902688785265853

Epoch: 5| Step: 10
Training loss: 2.118608236312866
Validation loss: 2.0796442006223943

Epoch: 140| Step: 0
Training loss: 1.8663909435272217
Validation loss: 2.0703555704444967

Epoch: 5| Step: 1
Training loss: 1.9549534320831299
Validation loss: 2.0508584463468162

Epoch: 5| Step: 2
Training loss: 2.512040376663208
Validation loss: 2.050628626218406

Epoch: 5| Step: 3
Training loss: 2.550717830657959
Validation loss: 2.03828082289747

Epoch: 5| Step: 4
Training loss: 2.5799155235290527
Validation loss: 2.036365975615799

Epoch: 5| Step: 5
Training loss: 2.6699507236480713
Validation loss: 2.036803294253606

Epoch: 5| Step: 6
Training loss: 2.7444615364074707
Validation loss: 2.0430101322871383

Epoch: 5| Step: 7
Training loss: 2.2512423992156982
Validation loss: 2.054526577713669

Epoch: 5| Step: 8
Training loss: 2.5695881843566895
Validation loss: 2.051981965700785

Epoch: 5| Step: 9
Training loss: 1.700640082359314
Validation loss: 2.0530947459641324

Epoch: 5| Step: 10
Training loss: 2.662970542907715
Validation loss: 2.032968051971928

Epoch: 141| Step: 0
Training loss: 2.597921371459961
Validation loss: 2.062121802760709

Epoch: 5| Step: 1
Training loss: 2.473026990890503
Validation loss: 2.1098888381834953

Epoch: 5| Step: 2
Training loss: 2.2982375621795654
Validation loss: 2.153505350953789

Epoch: 5| Step: 3
Training loss: 2.3677055835723877
Validation loss: 2.1720857838148713

Epoch: 5| Step: 4
Training loss: 2.4009594917297363
Validation loss: 2.161678078354046

Epoch: 5| Step: 5
Training loss: 2.5803377628326416
Validation loss: 2.11867077888981

Epoch: 5| Step: 6
Training loss: 2.106238842010498
Validation loss: 2.0691114805077993

Epoch: 5| Step: 7
Training loss: 2.6369521617889404
Validation loss: 2.038975037554259

Epoch: 5| Step: 8
Training loss: 2.4540135860443115
Validation loss: 2.0347197568544777

Epoch: 5| Step: 9
Training loss: 1.908290147781372
Validation loss: 2.037889253708624

Epoch: 5| Step: 10
Training loss: 2.272949695587158
Validation loss: 2.0299996919529413

Epoch: 142| Step: 0
Training loss: 2.337310791015625
Validation loss: 2.0344506002241567

Epoch: 5| Step: 1
Training loss: 2.214090585708618
Validation loss: 2.0379273301811627

Epoch: 5| Step: 2
Training loss: 2.55715274810791
Validation loss: 2.0385728728386665

Epoch: 5| Step: 3
Training loss: 2.035524606704712
Validation loss: 2.0430369120772167

Epoch: 5| Step: 4
Training loss: 1.7746334075927734
Validation loss: 2.046570618947347

Epoch: 5| Step: 5
Training loss: 1.9046283960342407
Validation loss: 2.056964202593732

Epoch: 5| Step: 6
Training loss: 2.984302043914795
Validation loss: 2.057766237566548

Epoch: 5| Step: 7
Training loss: 2.7656421661376953
Validation loss: 2.0742641110574045

Epoch: 5| Step: 8
Training loss: 2.418302059173584
Validation loss: 2.0803382588971044

Epoch: 5| Step: 9
Training loss: 2.2007250785827637
Validation loss: 2.089532047189692

Epoch: 5| Step: 10
Training loss: 2.5817806720733643
Validation loss: 2.0930519501368203

Epoch: 143| Step: 0
Training loss: 2.703660726547241
Validation loss: 2.0742521337283555

Epoch: 5| Step: 1
Training loss: 2.893916606903076
Validation loss: 2.0512817072611984

Epoch: 5| Step: 2
Training loss: 2.690433979034424
Validation loss: 2.0462664660587104

Epoch: 5| Step: 3
Training loss: 2.1772971153259277
Validation loss: 2.0449173553015596

Epoch: 5| Step: 4
Training loss: 1.880358099937439
Validation loss: 2.0387987065058883

Epoch: 5| Step: 5
Training loss: 2.027550458908081
Validation loss: 2.0380627006612797

Epoch: 5| Step: 6
Training loss: 1.861772894859314
Validation loss: 2.045029212069768

Epoch: 5| Step: 7
Training loss: 2.2006325721740723
Validation loss: 2.0589109364376275

Epoch: 5| Step: 8
Training loss: 2.5348143577575684
Validation loss: 2.065215333815544

Epoch: 5| Step: 9
Training loss: 2.53828763961792
Validation loss: 2.036275943120321

Epoch: 5| Step: 10
Training loss: 2.415381908416748
Validation loss: 2.0405726842982794

Epoch: 144| Step: 0
Training loss: 2.167017698287964
Validation loss: 2.0271893162881174

Epoch: 5| Step: 1
Training loss: 2.6742351055145264
Validation loss: 2.0360774558077575

Epoch: 5| Step: 2
Training loss: 1.4586784839630127
Validation loss: 2.0317367776747672

Epoch: 5| Step: 3
Training loss: 2.8060262203216553
Validation loss: 2.0348614518360426

Epoch: 5| Step: 4
Training loss: 2.0131919384002686
Validation loss: 2.0381325778140815

Epoch: 5| Step: 5
Training loss: 2.295015811920166
Validation loss: 2.0396412713553316

Epoch: 5| Step: 6
Training loss: 2.460777759552002
Validation loss: 2.039153263133059

Epoch: 5| Step: 7
Training loss: 2.3899083137512207
Validation loss: 2.0480198193621892

Epoch: 5| Step: 8
Training loss: 2.4660229682922363
Validation loss: 2.0394499237819383

Epoch: 5| Step: 9
Training loss: 2.7706923484802246
Validation loss: 2.03424862892397

Epoch: 5| Step: 10
Training loss: 2.2932372093200684
Validation loss: 2.043415751508487

Epoch: 145| Step: 0
Training loss: 1.84164559841156
Validation loss: 2.0388928792809926

Epoch: 5| Step: 1
Training loss: 2.372127056121826
Validation loss: 2.0409958952216694

Epoch: 5| Step: 2
Training loss: 2.8218765258789062
Validation loss: 2.0418727808101202

Epoch: 5| Step: 3
Training loss: 2.4617598056793213
Validation loss: 2.0375182961904876

Epoch: 5| Step: 4
Training loss: 2.1901676654815674
Validation loss: 2.0397713081811064

Epoch: 5| Step: 5
Training loss: 2.0642037391662598
Validation loss: 2.0433295696012435

Epoch: 5| Step: 6
Training loss: 2.124074697494507
Validation loss: 2.029665147104571

Epoch: 5| Step: 7
Training loss: 2.059234142303467
Validation loss: 2.0251309461491083

Epoch: 5| Step: 8
Training loss: 2.735400438308716
Validation loss: 2.0389935649851316

Epoch: 5| Step: 9
Training loss: 2.7350637912750244
Validation loss: 2.0468663566855976

Epoch: 5| Step: 10
Training loss: 2.1813974380493164
Validation loss: 2.0757956658640215

Epoch: 146| Step: 0
Training loss: 2.1775081157684326
Validation loss: 2.07086020131265

Epoch: 5| Step: 1
Training loss: 2.5007214546203613
Validation loss: 2.0749515320665095

Epoch: 5| Step: 2
Training loss: 2.5255794525146484
Validation loss: 2.0445305506388345

Epoch: 5| Step: 3
Training loss: 2.460793972015381
Validation loss: 2.0353555704957698

Epoch: 5| Step: 4
Training loss: 2.0557258129119873
Validation loss: 2.0250378539485316

Epoch: 5| Step: 5
Training loss: 2.554239511489868
Validation loss: 2.0248045998234905

Epoch: 5| Step: 6
Training loss: 1.7797458171844482
Validation loss: 2.0120795003829466

Epoch: 5| Step: 7
Training loss: 2.532235622406006
Validation loss: 2.0147184223257084

Epoch: 5| Step: 8
Training loss: 2.61708664894104
Validation loss: 2.018620767901021

Epoch: 5| Step: 9
Training loss: 2.03999400138855
Validation loss: 2.013363197285642

Epoch: 5| Step: 10
Training loss: 2.3007445335388184
Validation loss: 2.0149344859584684

Epoch: 147| Step: 0
Training loss: 2.936776638031006
Validation loss: 2.0032769685150473

Epoch: 5| Step: 1
Training loss: 2.8044865131378174
Validation loss: 2.0070356220327397

Epoch: 5| Step: 2
Training loss: 2.449545383453369
Validation loss: 2.0099919778044506

Epoch: 5| Step: 3
Training loss: 1.8876292705535889
Validation loss: 2.0148840642744497

Epoch: 5| Step: 4
Training loss: 2.2729439735412598
Validation loss: 2.003221196513022

Epoch: 5| Step: 5
Training loss: 1.5164151191711426
Validation loss: 2.013822861897048

Epoch: 5| Step: 6
Training loss: 2.0475873947143555
Validation loss: 2.0150240775077575

Epoch: 5| Step: 7
Training loss: 2.3001656532287598
Validation loss: 2.0249185818497852

Epoch: 5| Step: 8
Training loss: 1.8562263250350952
Validation loss: 2.018032407247892

Epoch: 5| Step: 9
Training loss: 2.8989932537078857
Validation loss: 2.0194841943761355

Epoch: 5| Step: 10
Training loss: 2.5706145763397217
Validation loss: 2.0211124984166955

Epoch: 148| Step: 0
Training loss: 2.0852744579315186
Validation loss: 2.030583045815909

Epoch: 5| Step: 1
Training loss: 2.869764566421509
Validation loss: 2.030712901905019

Epoch: 5| Step: 2
Training loss: 2.0886662006378174
Validation loss: 2.0419630555696386

Epoch: 5| Step: 3
Training loss: 2.6737170219421387
Validation loss: 2.0476314008876844

Epoch: 5| Step: 4
Training loss: 2.5827579498291016
Validation loss: 2.060608204974923

Epoch: 5| Step: 5
Training loss: 2.6524131298065186
Validation loss: 2.0580067762764553

Epoch: 5| Step: 6
Training loss: 2.37115478515625
Validation loss: 2.0569618286625033

Epoch: 5| Step: 7
Training loss: 1.946353554725647
Validation loss: 2.0505841291078957

Epoch: 5| Step: 8
Training loss: 2.0961990356445312
Validation loss: 2.035099737105831

Epoch: 5| Step: 9
Training loss: 1.975959062576294
Validation loss: 2.0257121324539185

Epoch: 5| Step: 10
Training loss: 2.1134538650512695
Validation loss: 2.031946773170143

Epoch: 149| Step: 0
Training loss: 1.7150036096572876
Validation loss: 2.0317555114787114

Epoch: 5| Step: 1
Training loss: 2.0290894508361816
Validation loss: 2.032766256281125

Epoch: 5| Step: 2
Training loss: 1.9853980541229248
Validation loss: 2.032471526053644

Epoch: 5| Step: 3
Training loss: 2.738966226577759
Validation loss: 2.0301167785480456

Epoch: 5| Step: 4
Training loss: 2.3090388774871826
Validation loss: 2.0299295853543025

Epoch: 5| Step: 5
Training loss: 2.5325703620910645
Validation loss: 2.0412367774594213

Epoch: 5| Step: 6
Training loss: 2.526336908340454
Validation loss: 2.0532360910087504

Epoch: 5| Step: 7
Training loss: 2.825512409210205
Validation loss: 2.0689187536957445

Epoch: 5| Step: 8
Training loss: 2.2000913619995117
Validation loss: 2.0663888569801085

Epoch: 5| Step: 9
Training loss: 2.834587812423706
Validation loss: 2.0434972163169616

Epoch: 5| Step: 10
Training loss: 1.7386077642440796
Validation loss: 2.0457867717230194

Epoch: 150| Step: 0
Training loss: 2.1297812461853027
Validation loss: 2.028461646008235

Epoch: 5| Step: 1
Training loss: 2.368539810180664
Validation loss: 2.0290034355655795

Epoch: 5| Step: 2
Training loss: 2.7735652923583984
Validation loss: 2.0247198407367994

Epoch: 5| Step: 3
Training loss: 2.0941662788391113
Validation loss: 2.033168308196529

Epoch: 5| Step: 4
Training loss: 2.532148838043213
Validation loss: 2.0290339736528296

Epoch: 5| Step: 5
Training loss: 2.5961153507232666
Validation loss: 2.0167835348395893

Epoch: 5| Step: 6
Training loss: 2.155918836593628
Validation loss: 2.027768142761723

Epoch: 5| Step: 7
Training loss: 2.424246072769165
Validation loss: 2.0688657145346365

Epoch: 5| Step: 8
Training loss: 1.7506816387176514
Validation loss: 2.054491922419558

Epoch: 5| Step: 9
Training loss: 2.328697681427002
Validation loss: 2.0239463237024125

Epoch: 5| Step: 10
Training loss: 2.282639265060425
Validation loss: 2.0056338438423733

Epoch: 151| Step: 0
Training loss: 2.965170383453369
Validation loss: 2.009655729416878

Epoch: 5| Step: 1
Training loss: 2.473978042602539
Validation loss: 2.007193147495229

Epoch: 5| Step: 2
Training loss: 1.8275283575057983
Validation loss: 1.9998292602518553

Epoch: 5| Step: 3
Training loss: 2.1726789474487305
Validation loss: 2.0039657392809467

Epoch: 5| Step: 4
Training loss: 2.719651699066162
Validation loss: 2.0249863555354457

Epoch: 5| Step: 5
Training loss: 1.5297268629074097
Validation loss: 2.007321060344737

Epoch: 5| Step: 6
Training loss: 2.5573959350585938
Validation loss: 2.0052188827145483

Epoch: 5| Step: 7
Training loss: 2.764066219329834
Validation loss: 2.0082090439334994

Epoch: 5| Step: 8
Training loss: 1.9636733531951904
Validation loss: 2.0197305140956754

Epoch: 5| Step: 9
Training loss: 2.295579195022583
Validation loss: 2.036518132814797

Epoch: 5| Step: 10
Training loss: 2.2631921768188477
Validation loss: 2.06388589771845

Epoch: 152| Step: 0
Training loss: 2.5064384937286377
Validation loss: 2.100728424646521

Epoch: 5| Step: 1
Training loss: 2.1766819953918457
Validation loss: 2.076695029453565

Epoch: 5| Step: 2
Training loss: 2.256807804107666
Validation loss: 2.089885316869264

Epoch: 5| Step: 3
Training loss: 1.6524040699005127
Validation loss: 2.0406318685059905

Epoch: 5| Step: 4
Training loss: 2.204360246658325
Validation loss: 2.0243951556503132

Epoch: 5| Step: 5
Training loss: 2.2600159645080566
Validation loss: 2.0059725635795185

Epoch: 5| Step: 6
Training loss: 2.5475728511810303
Validation loss: 1.9915888540206417

Epoch: 5| Step: 7
Training loss: 2.6405177116394043
Validation loss: 1.997354338246007

Epoch: 5| Step: 8
Training loss: 2.705456256866455
Validation loss: 1.9956589386027346

Epoch: 5| Step: 9
Training loss: 2.3849260807037354
Validation loss: 2.002022030533001

Epoch: 5| Step: 10
Training loss: 2.2764980792999268
Validation loss: 2.023823117697111

Epoch: 153| Step: 0
Training loss: 1.9703350067138672
Validation loss: 2.0175336355804117

Epoch: 5| Step: 1
Training loss: 2.6207680702209473
Validation loss: 2.0184009280256046

Epoch: 5| Step: 2
Training loss: 2.8958263397216797
Validation loss: 2.0012520333772064

Epoch: 5| Step: 3
Training loss: 2.314347505569458
Validation loss: 1.9960254687134937

Epoch: 5| Step: 4
Training loss: 2.2563347816467285
Validation loss: 2.007655874375374

Epoch: 5| Step: 5
Training loss: 2.3372700214385986
Validation loss: 2.018575378643569

Epoch: 5| Step: 6
Training loss: 2.4994235038757324
Validation loss: 2.0486273163108417

Epoch: 5| Step: 7
Training loss: 1.9128220081329346
Validation loss: 2.072515368461609

Epoch: 5| Step: 8
Training loss: 1.7713581323623657
Validation loss: 2.10679486361883

Epoch: 5| Step: 9
Training loss: 2.918567180633545
Validation loss: 2.1346332565430672

Epoch: 5| Step: 10
Training loss: 2.11675763130188
Validation loss: 2.118529704309279

Epoch: 154| Step: 0
Training loss: 2.4580159187316895
Validation loss: 2.053653427349624

Epoch: 5| Step: 1
Training loss: 2.1841254234313965
Validation loss: 2.0265956335170294

Epoch: 5| Step: 2
Training loss: 2.078707218170166
Validation loss: 2.0238452355066934

Epoch: 5| Step: 3
Training loss: 2.2759623527526855
Validation loss: 2.030639466419015

Epoch: 5| Step: 4
Training loss: 2.293727397918701
Validation loss: 2.0537706216176352

Epoch: 5| Step: 5
Training loss: 2.4738643169403076
Validation loss: 2.0763669065249863

Epoch: 5| Step: 6
Training loss: 2.7822296619415283
Validation loss: 2.051490887518852

Epoch: 5| Step: 7
Training loss: 1.9767799377441406
Validation loss: 2.046280173845189

Epoch: 5| Step: 8
Training loss: 2.4775028228759766
Validation loss: 2.03797968100476

Epoch: 5| Step: 9
Training loss: 2.3875808715820312
Validation loss: 2.016025886740736

Epoch: 5| Step: 10
Training loss: 1.9784581661224365
Validation loss: 2.015753302522885

Epoch: 155| Step: 0
Training loss: 2.632361888885498
Validation loss: 2.0432670398425032

Epoch: 5| Step: 1
Training loss: 2.3920247554779053
Validation loss: 2.0597439683893675

Epoch: 5| Step: 2
Training loss: 2.0328593254089355
Validation loss: 2.050554734404369

Epoch: 5| Step: 3
Training loss: 2.7654240131378174
Validation loss: 2.0354254245758057

Epoch: 5| Step: 4
Training loss: 1.8890132904052734
Validation loss: 2.0113803058542232

Epoch: 5| Step: 5
Training loss: 2.1926045417785645
Validation loss: 1.9965337296967864

Epoch: 5| Step: 6
Training loss: 1.4411845207214355
Validation loss: 1.9829442372886084

Epoch: 5| Step: 7
Training loss: 2.621556043624878
Validation loss: 1.9878061099718976

Epoch: 5| Step: 8
Training loss: 2.5227153301239014
Validation loss: 1.9967802532257573

Epoch: 5| Step: 9
Training loss: 2.974388599395752
Validation loss: 2.0099395782716813

Epoch: 5| Step: 10
Training loss: 2.2637829780578613
Validation loss: 2.0057448264091247

Epoch: 156| Step: 0
Training loss: 2.1369032859802246
Validation loss: 1.9934616204231017

Epoch: 5| Step: 1
Training loss: 2.8945305347442627
Validation loss: 1.9831171253676056

Epoch: 5| Step: 2
Training loss: 2.5842208862304688
Validation loss: 1.986049303444483

Epoch: 5| Step: 3
Training loss: 2.1272575855255127
Validation loss: 1.9957136005483649

Epoch: 5| Step: 4
Training loss: 1.7412465810775757
Validation loss: 2.0072288282455935

Epoch: 5| Step: 5
Training loss: 2.488287925720215
Validation loss: 2.017515000476632

Epoch: 5| Step: 6
Training loss: 1.9338552951812744
Validation loss: 2.0267017387574717

Epoch: 5| Step: 7
Training loss: 2.9145357608795166
Validation loss: 2.0571052976833877

Epoch: 5| Step: 8
Training loss: 2.8129467964172363
Validation loss: 2.059713173938054

Epoch: 5| Step: 9
Training loss: 2.4264883995056152
Validation loss: 2.061304748699229

Epoch: 5| Step: 10
Training loss: 1.295750379562378
Validation loss: 2.0488754369879283

Epoch: 157| Step: 0
Training loss: 2.470350980758667
Validation loss: 2.010879442255984

Epoch: 5| Step: 1
Training loss: 2.3286657333374023
Validation loss: 1.9989948144523046

Epoch: 5| Step: 2
Training loss: 2.38716459274292
Validation loss: 1.9854967953056417

Epoch: 5| Step: 3
Training loss: 2.1370246410369873
Validation loss: 1.9865975251761816

Epoch: 5| Step: 4
Training loss: 2.27228045463562
Validation loss: 1.973529936164938

Epoch: 5| Step: 5
Training loss: 2.2019283771514893
Validation loss: 1.988593061765035

Epoch: 5| Step: 6
Training loss: 2.0903093814849854
Validation loss: 1.9817451443723453

Epoch: 5| Step: 7
Training loss: 2.085955858230591
Validation loss: 1.9816957724991666

Epoch: 5| Step: 8
Training loss: 2.8490424156188965
Validation loss: 1.9905043584044262

Epoch: 5| Step: 9
Training loss: 2.2470948696136475
Validation loss: 2.0000526289786063

Epoch: 5| Step: 10
Training loss: 2.1201179027557373
Validation loss: 2.0046384232018584

Epoch: 158| Step: 0
Training loss: 1.9640430212020874
Validation loss: 2.010959550898562

Epoch: 5| Step: 1
Training loss: 2.6561145782470703
Validation loss: 1.9997462777681247

Epoch: 5| Step: 2
Training loss: 2.2505295276641846
Validation loss: 1.9954541549887708

Epoch: 5| Step: 3
Training loss: 1.9092037677764893
Validation loss: 2.0001199424907727

Epoch: 5| Step: 4
Training loss: 2.3496482372283936
Validation loss: 1.9958767455111268

Epoch: 5| Step: 5
Training loss: 2.0774316787719727
Validation loss: 1.9761336054853214

Epoch: 5| Step: 6
Training loss: 2.9146475791931152
Validation loss: 1.9790449603911369

Epoch: 5| Step: 7
Training loss: 2.1970677375793457
Validation loss: 1.9764254926353373

Epoch: 5| Step: 8
Training loss: 2.3712241649627686
Validation loss: 1.9812610803111907

Epoch: 5| Step: 9
Training loss: 2.1162266731262207
Validation loss: 1.983688997965987

Epoch: 5| Step: 10
Training loss: 2.22668194770813
Validation loss: 1.9849329225478634

Epoch: 159| Step: 0
Training loss: 2.0961155891418457
Validation loss: 1.980294055836175

Epoch: 5| Step: 1
Training loss: 2.2077999114990234
Validation loss: 1.9963160958341373

Epoch: 5| Step: 2
Training loss: 1.9246330261230469
Validation loss: 1.9919800989089473

Epoch: 5| Step: 3
Training loss: 2.766552448272705
Validation loss: 1.999365178487634

Epoch: 5| Step: 4
Training loss: 1.658678650856018
Validation loss: 2.0002182452909407

Epoch: 5| Step: 5
Training loss: 1.9767863750457764
Validation loss: 1.9822289892422256

Epoch: 5| Step: 6
Training loss: 2.687836170196533
Validation loss: 1.969755345775235

Epoch: 5| Step: 7
Training loss: 2.4754066467285156
Validation loss: 1.9644636505393571

Epoch: 5| Step: 8
Training loss: 2.298912525177002
Validation loss: 1.9736811653260262

Epoch: 5| Step: 9
Training loss: 2.4944469928741455
Validation loss: 1.9785928418559413

Epoch: 5| Step: 10
Training loss: 2.646333694458008
Validation loss: 1.9813930193583171

Epoch: 160| Step: 0
Training loss: 1.9558708667755127
Validation loss: 1.9810179164332729

Epoch: 5| Step: 1
Training loss: 2.185340404510498
Validation loss: 1.9930227289917648

Epoch: 5| Step: 2
Training loss: 2.1655211448669434
Validation loss: 2.000921071216624

Epoch: 5| Step: 3
Training loss: 2.21663498878479
Validation loss: 1.9972157234786658

Epoch: 5| Step: 4
Training loss: 2.6100306510925293
Validation loss: 1.9819620681065384

Epoch: 5| Step: 5
Training loss: 2.4611783027648926
Validation loss: 1.97813759439735

Epoch: 5| Step: 6
Training loss: 1.8260383605957031
Validation loss: 1.9814926975516862

Epoch: 5| Step: 7
Training loss: 2.5323143005371094
Validation loss: 1.9846976931377123

Epoch: 5| Step: 8
Training loss: 2.414034128189087
Validation loss: 1.9823473615031089

Epoch: 5| Step: 9
Training loss: 2.3368353843688965
Validation loss: 1.9757375178798553

Epoch: 5| Step: 10
Training loss: 2.286299228668213
Validation loss: 1.9836696963156424

Epoch: 161| Step: 0
Training loss: 2.555211305618286
Validation loss: 1.9812957740599109

Epoch: 5| Step: 1
Training loss: 2.838780164718628
Validation loss: 1.9749912997727752

Epoch: 5| Step: 2
Training loss: 2.007965564727783
Validation loss: 1.9953842650177658

Epoch: 5| Step: 3
Training loss: 2.0868141651153564
Validation loss: 1.9935017670354536

Epoch: 5| Step: 4
Training loss: 2.5889017581939697
Validation loss: 1.9917268060868787

Epoch: 5| Step: 5
Training loss: 2.471055507659912
Validation loss: 1.9933482780251452

Epoch: 5| Step: 6
Training loss: 1.9724559783935547
Validation loss: 2.0099921713593187

Epoch: 5| Step: 7
Training loss: 2.1121654510498047
Validation loss: 2.0104527678540958

Epoch: 5| Step: 8
Training loss: 2.4599952697753906
Validation loss: 2.035605743367185

Epoch: 5| Step: 9
Training loss: 1.8261511325836182
Validation loss: 2.018698650021707

Epoch: 5| Step: 10
Training loss: 1.9086308479309082
Validation loss: 1.9994464048775293

Epoch: 162| Step: 0
Training loss: 1.7085317373275757
Validation loss: 1.979753384026148

Epoch: 5| Step: 1
Training loss: 2.7169477939605713
Validation loss: 2.0213954756336827

Epoch: 5| Step: 2
Training loss: 2.639282703399658
Validation loss: 2.0514764683220976

Epoch: 5| Step: 3
Training loss: 2.8209595680236816
Validation loss: 2.0597341945094447

Epoch: 5| Step: 4
Training loss: 2.4824681282043457
Validation loss: 2.0495063925302155

Epoch: 5| Step: 5
Training loss: 3.2890372276306152
Validation loss: 2.014512433800646

Epoch: 5| Step: 6
Training loss: 1.8110549449920654
Validation loss: 1.98806885750063

Epoch: 5| Step: 7
Training loss: 2.0458664894104004
Validation loss: 1.9679481188456218

Epoch: 5| Step: 8
Training loss: 2.0653343200683594
Validation loss: 1.9688252415708316

Epoch: 5| Step: 9
Training loss: 1.4685781002044678
Validation loss: 1.9704048018301688

Epoch: 5| Step: 10
Training loss: 2.1605398654937744
Validation loss: 1.9755230847225393

Epoch: 163| Step: 0
Training loss: 2.451904058456421
Validation loss: 1.977310760046846

Epoch: 5| Step: 1
Training loss: 1.8549188375473022
Validation loss: 1.9662168897608274

Epoch: 5| Step: 2
Training loss: 2.3495943546295166
Validation loss: 1.9652444572858914

Epoch: 5| Step: 3
Training loss: 2.5006022453308105
Validation loss: 1.971280259470786

Epoch: 5| Step: 4
Training loss: 2.1330466270446777
Validation loss: 1.9974416507187711

Epoch: 5| Step: 5
Training loss: 2.495128631591797
Validation loss: 2.013905353443597

Epoch: 5| Step: 6
Training loss: 2.4061083793640137
Validation loss: 2.041901371812308

Epoch: 5| Step: 7
Training loss: 2.0541462898254395
Validation loss: 2.053408161286385

Epoch: 5| Step: 8
Training loss: 2.4617252349853516
Validation loss: 2.0266589400588826

Epoch: 5| Step: 9
Training loss: 2.3318397998809814
Validation loss: 1.989802655353341

Epoch: 5| Step: 10
Training loss: 2.4672439098358154
Validation loss: 1.9767901705157371

Epoch: 164| Step: 0
Training loss: 2.478311061859131
Validation loss: 1.969688811609822

Epoch: 5| Step: 1
Training loss: 2.5815300941467285
Validation loss: 1.9624036922249743

Epoch: 5| Step: 2
Training loss: 2.334636688232422
Validation loss: 1.9675998303198046

Epoch: 5| Step: 3
Training loss: 2.263852596282959
Validation loss: 1.9673024377515238

Epoch: 5| Step: 4
Training loss: 2.471540689468384
Validation loss: 1.9733576402869275

Epoch: 5| Step: 5
Training loss: 2.1920828819274902
Validation loss: 1.9730536142985027

Epoch: 5| Step: 6
Training loss: 2.4296345710754395
Validation loss: 1.9729646751957555

Epoch: 5| Step: 7
Training loss: 1.992322325706482
Validation loss: 1.9760752775335824

Epoch: 5| Step: 8
Training loss: 2.3170268535614014
Validation loss: 1.971879683515077

Epoch: 5| Step: 9
Training loss: 2.173210382461548
Validation loss: 1.9839690846781577

Epoch: 5| Step: 10
Training loss: 1.6852521896362305
Validation loss: 1.9732698496951853

Epoch: 165| Step: 0
Training loss: 2.235090494155884
Validation loss: 1.968335360609075

Epoch: 5| Step: 1
Training loss: 2.286935329437256
Validation loss: 1.9777655165682557

Epoch: 5| Step: 2
Training loss: 2.3856303691864014
Validation loss: 1.978224685115199

Epoch: 5| Step: 3
Training loss: 2.839339017868042
Validation loss: 1.9648160165356052

Epoch: 5| Step: 4
Training loss: 2.3007659912109375
Validation loss: 1.9686745879470662

Epoch: 5| Step: 5
Training loss: 2.1189849376678467
Validation loss: 1.9764085379979943

Epoch: 5| Step: 6
Training loss: 1.598339319229126
Validation loss: 1.982501970824375

Epoch: 5| Step: 7
Training loss: 2.509899616241455
Validation loss: 1.9992050009389077

Epoch: 5| Step: 8
Training loss: 2.0550811290740967
Validation loss: 2.015585817316527

Epoch: 5| Step: 9
Training loss: 1.532252550125122
Validation loss: 2.0024776099830546

Epoch: 5| Step: 10
Training loss: 3.070100784301758
Validation loss: 2.0235927207495576

Epoch: 166| Step: 0
Training loss: 2.456678867340088
Validation loss: 2.0246585146073373

Epoch: 5| Step: 1
Training loss: 1.8716208934783936
Validation loss: 2.0219125722044256

Epoch: 5| Step: 2
Training loss: 2.398632049560547
Validation loss: 2.0220025944453415

Epoch: 5| Step: 3
Training loss: 2.526303768157959
Validation loss: 2.0256600687580724

Epoch: 5| Step: 4
Training loss: 1.4763842821121216
Validation loss: 2.027057304177233

Epoch: 5| Step: 5
Training loss: 2.486694812774658
Validation loss: 2.027685160277992

Epoch: 5| Step: 6
Training loss: 2.4778828620910645
Validation loss: 2.0343212158449235

Epoch: 5| Step: 7
Training loss: 2.3143510818481445
Validation loss: 2.0263907396665184

Epoch: 5| Step: 8
Training loss: 2.2204527854919434
Validation loss: 2.0135669900525

Epoch: 5| Step: 9
Training loss: 2.1163768768310547
Validation loss: 2.017780247554984

Epoch: 5| Step: 10
Training loss: 2.428511619567871
Validation loss: 2.01293525644528

Epoch: 167| Step: 0
Training loss: 2.3460655212402344
Validation loss: 2.0130508792015815

Epoch: 5| Step: 1
Training loss: 2.7633018493652344
Validation loss: 2.0157578401668097

Epoch: 5| Step: 2
Training loss: 1.8536241054534912
Validation loss: 1.99126975382528

Epoch: 5| Step: 3
Training loss: 2.2421011924743652
Validation loss: 1.9719528716097596

Epoch: 5| Step: 4
Training loss: 2.720244884490967
Validation loss: 1.974091209391112

Epoch: 5| Step: 5
Training loss: 2.2964305877685547
Validation loss: 1.975295497525123

Epoch: 5| Step: 6
Training loss: 2.220798969268799
Validation loss: 1.9792286401153893

Epoch: 5| Step: 7
Training loss: 2.0528993606567383
Validation loss: 1.9753617701991912

Epoch: 5| Step: 8
Training loss: 1.7172647714614868
Validation loss: 1.9729624435465822

Epoch: 5| Step: 9
Training loss: 2.2686474323272705
Validation loss: 1.9676154326367121

Epoch: 5| Step: 10
Training loss: 2.1985392570495605
Validation loss: 1.9747758065500567

Epoch: 168| Step: 0
Training loss: 2.842989921569824
Validation loss: 1.9731488509844708

Epoch: 5| Step: 1
Training loss: 1.9962600469589233
Validation loss: 1.975941736211059

Epoch: 5| Step: 2
Training loss: 2.262913703918457
Validation loss: 1.9907929794762724

Epoch: 5| Step: 3
Training loss: 2.5181639194488525
Validation loss: 1.9967168992565525

Epoch: 5| Step: 4
Training loss: 2.0290322303771973
Validation loss: 2.006966548581277

Epoch: 5| Step: 5
Training loss: 2.292008876800537
Validation loss: 2.001016116911365

Epoch: 5| Step: 6
Training loss: 2.41760516166687
Validation loss: 1.9889495859863937

Epoch: 5| Step: 7
Training loss: 2.8054654598236084
Validation loss: 1.9850762556957942

Epoch: 5| Step: 8
Training loss: 1.742680311203003
Validation loss: 1.9745911885333318

Epoch: 5| Step: 9
Training loss: 2.1181674003601074
Validation loss: 1.981168418802241

Epoch: 5| Step: 10
Training loss: 1.8113667964935303
Validation loss: 2.009249042439204

Epoch: 169| Step: 0
Training loss: 2.2850050926208496
Validation loss: 2.0115715137092014

Epoch: 5| Step: 1
Training loss: 2.086454391479492
Validation loss: 1.9998954829349314

Epoch: 5| Step: 2
Training loss: 2.001138210296631
Validation loss: 1.9916429673471758

Epoch: 5| Step: 3
Training loss: 2.6313631534576416
Validation loss: 1.9864320575550038

Epoch: 5| Step: 4
Training loss: 2.202108144760132
Validation loss: 1.9917244808648222

Epoch: 5| Step: 5
Training loss: 2.423128604888916
Validation loss: 1.9954947604927966

Epoch: 5| Step: 6
Training loss: 2.0378448963165283
Validation loss: 1.9847470778290943

Epoch: 5| Step: 7
Training loss: 2.4532923698425293
Validation loss: 1.985051498618177

Epoch: 5| Step: 8
Training loss: 1.7080886363983154
Validation loss: 1.9789962973645938

Epoch: 5| Step: 9
Training loss: 2.104404926300049
Validation loss: 1.9942684288947814

Epoch: 5| Step: 10
Training loss: 2.800908327102661
Validation loss: 2.005931290247107

Epoch: 170| Step: 0
Training loss: 2.4977283477783203
Validation loss: 2.020226614449614

Epoch: 5| Step: 1
Training loss: 2.427445411682129
Validation loss: 2.020122666512766

Epoch: 5| Step: 2
Training loss: 1.8343420028686523
Validation loss: 2.002753967879921

Epoch: 5| Step: 3
Training loss: 2.7249252796173096
Validation loss: 2.0006184783033145

Epoch: 5| Step: 4
Training loss: 2.855956792831421
Validation loss: 2.0326135901994604

Epoch: 5| Step: 5
Training loss: 2.8412859439849854
Validation loss: 2.0434549636738275

Epoch: 5| Step: 6
Training loss: 1.5684373378753662
Validation loss: 2.0346738881962274

Epoch: 5| Step: 7
Training loss: 2.201054096221924
Validation loss: 2.0152424073988393

Epoch: 5| Step: 8
Training loss: 2.150385618209839
Validation loss: 1.9853263606307328

Epoch: 5| Step: 9
Training loss: 2.3260529041290283
Validation loss: 1.9921586064882175

Epoch: 5| Step: 10
Training loss: 1.3621294498443604
Validation loss: 1.9970238772771691

Epoch: 171| Step: 0
Training loss: 1.9582817554473877
Validation loss: 2.018494881609435

Epoch: 5| Step: 1
Training loss: 2.6904587745666504
Validation loss: 2.0457558452442126

Epoch: 5| Step: 2
Training loss: 1.9901355504989624
Validation loss: 2.041887446116376

Epoch: 5| Step: 3
Training loss: 2.236258029937744
Validation loss: 2.033486908481967

Epoch: 5| Step: 4
Training loss: 2.422325849533081
Validation loss: 2.018160032969649

Epoch: 5| Step: 5
Training loss: 2.281343460083008
Validation loss: 1.983755987177613

Epoch: 5| Step: 6
Training loss: 2.1298110485076904
Validation loss: 1.9820127641001055

Epoch: 5| Step: 7
Training loss: 1.728173017501831
Validation loss: 1.9882977201092629

Epoch: 5| Step: 8
Training loss: 2.4936392307281494
Validation loss: 2.0054660202354513

Epoch: 5| Step: 9
Training loss: 2.4316954612731934
Validation loss: 2.0045033757404616

Epoch: 5| Step: 10
Training loss: 2.501070022583008
Validation loss: 2.007117808506053

Epoch: 172| Step: 0
Training loss: 2.0173633098602295
Validation loss: 2.004071520220849

Epoch: 5| Step: 1
Training loss: 2.7449851036071777
Validation loss: 1.9985940917845695

Epoch: 5| Step: 2
Training loss: 2.6096060276031494
Validation loss: 1.9917352891737414

Epoch: 5| Step: 3
Training loss: 2.509351968765259
Validation loss: 2.0076345833398963

Epoch: 5| Step: 4
Training loss: 1.8645401000976562
Validation loss: 2.0016611006952103

Epoch: 5| Step: 5
Training loss: 1.9689559936523438
Validation loss: 1.9850964443657988

Epoch: 5| Step: 6
Training loss: 2.283256769180298
Validation loss: 1.9682999067409064

Epoch: 5| Step: 7
Training loss: 2.0519416332244873
Validation loss: 1.9607901675726778

Epoch: 5| Step: 8
Training loss: 2.0870471000671387
Validation loss: 1.958097634776946

Epoch: 5| Step: 9
Training loss: 1.9682985544204712
Validation loss: 1.965236460008929

Epoch: 5| Step: 10
Training loss: 2.370905876159668
Validation loss: 1.9482481928281887

Epoch: 173| Step: 0
Training loss: 2.5620932579040527
Validation loss: 1.9610299500085975

Epoch: 5| Step: 1
Training loss: 1.9273563623428345
Validation loss: 1.966390464895515

Epoch: 5| Step: 2
Training loss: 2.6806557178497314
Validation loss: 1.9673730634873914

Epoch: 5| Step: 3
Training loss: 1.8451519012451172
Validation loss: 1.9733996288750761

Epoch: 5| Step: 4
Training loss: 2.3467438220977783
Validation loss: 1.9669116684185561

Epoch: 5| Step: 5
Training loss: 2.3325610160827637
Validation loss: 1.972228757796749

Epoch: 5| Step: 6
Training loss: 1.966827154159546
Validation loss: 1.989071310207408

Epoch: 5| Step: 7
Training loss: 2.16068959236145
Validation loss: 1.9924893302302207

Epoch: 5| Step: 8
Training loss: 2.069693088531494
Validation loss: 2.0106067272924606

Epoch: 5| Step: 9
Training loss: 2.4231410026550293
Validation loss: 2.027293941026093

Epoch: 5| Step: 10
Training loss: 2.1033663749694824
Validation loss: 2.000427781894643

Epoch: 174| Step: 0
Training loss: 2.315162181854248
Validation loss: 1.9938428004582722

Epoch: 5| Step: 1
Training loss: 2.3946380615234375
Validation loss: 1.9820101491866573

Epoch: 5| Step: 2
Training loss: 2.4586548805236816
Validation loss: 1.982035731756559

Epoch: 5| Step: 3
Training loss: 2.2629923820495605
Validation loss: 1.9915077737582627

Epoch: 5| Step: 4
Training loss: 2.1161115169525146
Validation loss: 2.0188417601329025

Epoch: 5| Step: 5
Training loss: 1.7288042306900024
Validation loss: 2.0212400626110774

Epoch: 5| Step: 6
Training loss: 2.5433924198150635
Validation loss: 2.0460654561237623

Epoch: 5| Step: 7
Training loss: 1.8828299045562744
Validation loss: 2.0624406055737565

Epoch: 5| Step: 8
Training loss: 1.9280906915664673
Validation loss: 2.035314157444944

Epoch: 5| Step: 9
Training loss: 2.2234578132629395
Validation loss: 2.021567001137682

Epoch: 5| Step: 10
Training loss: 2.5981874465942383
Validation loss: 1.9769739053582633

Epoch: 175| Step: 0
Training loss: 1.9002647399902344
Validation loss: 1.9728000753669328

Epoch: 5| Step: 1
Training loss: 2.152952194213867
Validation loss: 1.981940677089076

Epoch: 5| Step: 2
Training loss: 2.53190279006958
Validation loss: 1.9827206621887863

Epoch: 5| Step: 3
Training loss: 1.8827975988388062
Validation loss: 1.955879238344008

Epoch: 5| Step: 4
Training loss: 2.2289862632751465
Validation loss: 1.928891267827762

Epoch: 5| Step: 5
Training loss: 2.484862804412842
Validation loss: 1.9207513024730067

Epoch: 5| Step: 6
Training loss: 1.7301177978515625
Validation loss: 1.9441869335789834

Epoch: 5| Step: 7
Training loss: 2.6283669471740723
Validation loss: 1.9620177745819092

Epoch: 5| Step: 8
Training loss: 2.4791131019592285
Validation loss: 1.9703176534304054

Epoch: 5| Step: 9
Training loss: 2.370622158050537
Validation loss: 1.9546170157770957

Epoch: 5| Step: 10
Training loss: 2.1825363636016846
Validation loss: 1.9399097414426907

Epoch: 176| Step: 0
Training loss: 2.4750874042510986
Validation loss: 1.9217726953567997

Epoch: 5| Step: 1
Training loss: 2.0328927040100098
Validation loss: 1.9135558310375418

Epoch: 5| Step: 2
Training loss: 2.4029488563537598
Validation loss: 1.9106253065088743

Epoch: 5| Step: 3
Training loss: 1.5250928401947021
Validation loss: 1.9313216311957246

Epoch: 5| Step: 4
Training loss: 2.174985408782959
Validation loss: 1.9518964072709442

Epoch: 5| Step: 5
Training loss: 2.159453868865967
Validation loss: 1.9749389181854904

Epoch: 5| Step: 6
Training loss: 1.8260695934295654
Validation loss: 1.9584872338079637

Epoch: 5| Step: 7
Training loss: 2.479120969772339
Validation loss: 1.9414327759896555

Epoch: 5| Step: 8
Training loss: 2.4728550910949707
Validation loss: 1.9476118292859805

Epoch: 5| Step: 9
Training loss: 2.408052682876587
Validation loss: 1.9644569145735873

Epoch: 5| Step: 10
Training loss: 2.6129233837127686
Validation loss: 2.0159370591563563

Epoch: 177| Step: 0
Training loss: 2.3149571418762207
Validation loss: 2.004087837793494

Epoch: 5| Step: 1
Training loss: 1.9924280643463135
Validation loss: 1.9850245009186447

Epoch: 5| Step: 2
Training loss: 2.097534418106079
Validation loss: 1.9604285737519622

Epoch: 5| Step: 3
Training loss: 2.4439244270324707
Validation loss: 1.9467022765067317

Epoch: 5| Step: 4
Training loss: 1.7556499242782593
Validation loss: 1.9580278204333397

Epoch: 5| Step: 5
Training loss: 2.0540289878845215
Validation loss: 1.9839770883642218

Epoch: 5| Step: 6
Training loss: 2.191481351852417
Validation loss: 1.9969089851584485

Epoch: 5| Step: 7
Training loss: 2.6156716346740723
Validation loss: 2.0063444158082366

Epoch: 5| Step: 8
Training loss: 2.433479070663452
Validation loss: 1.9994317575167584

Epoch: 5| Step: 9
Training loss: 2.2420732975006104
Validation loss: 2.014110929222517

Epoch: 5| Step: 10
Training loss: 2.291518449783325
Validation loss: 2.038075030490916

Epoch: 178| Step: 0
Training loss: 2.271667957305908
Validation loss: 2.0447990317498483

Epoch: 5| Step: 1
Training loss: 2.418783664703369
Validation loss: 2.038260280445058

Epoch: 5| Step: 2
Training loss: 2.4014134407043457
Validation loss: 2.0318159659703574

Epoch: 5| Step: 3
Training loss: 2.114426374435425
Validation loss: 2.0198629274163196

Epoch: 5| Step: 4
Training loss: 2.251035690307617
Validation loss: 1.9825226517133816

Epoch: 5| Step: 5
Training loss: 2.4547019004821777
Validation loss: 1.9620941531273626

Epoch: 5| Step: 6
Training loss: 1.8934299945831299
Validation loss: 1.9434226700054702

Epoch: 5| Step: 7
Training loss: 2.1875593662261963
Validation loss: 1.942331894751518

Epoch: 5| Step: 8
Training loss: 2.034144639968872
Validation loss: 1.9652012189229329

Epoch: 5| Step: 9
Training loss: 2.0201268196105957
Validation loss: 2.004854363779868

Epoch: 5| Step: 10
Training loss: 2.318152666091919
Validation loss: 2.0435849940905007

Epoch: 179| Step: 0
Training loss: 2.219134569168091
Validation loss: 2.04075115214112

Epoch: 5| Step: 1
Training loss: 1.3349173069000244
Validation loss: 2.033461486139605

Epoch: 5| Step: 2
Training loss: 2.660135507583618
Validation loss: 2.0046598757466962

Epoch: 5| Step: 3
Training loss: 2.8893423080444336
Validation loss: 1.9706281462023336

Epoch: 5| Step: 4
Training loss: 2.4718525409698486
Validation loss: 1.9887496373986686

Epoch: 5| Step: 5
Training loss: 2.3417067527770996
Validation loss: 1.9570679331338534

Epoch: 5| Step: 6
Training loss: 2.462702751159668
Validation loss: 1.9898784237523233

Epoch: 5| Step: 7
Training loss: 1.6510463953018188
Validation loss: 2.0079380209727953

Epoch: 5| Step: 8
Training loss: 2.5907535552978516
Validation loss: 2.0438441320132186

Epoch: 5| Step: 9
Training loss: 2.0352416038513184
Validation loss: 2.0477967185358845

Epoch: 5| Step: 10
Training loss: 1.654322624206543
Validation loss: 2.0288435387355026

Epoch: 180| Step: 0
Training loss: 2.114210844039917
Validation loss: 2.0112804597423923

Epoch: 5| Step: 1
Training loss: 2.463176965713501
Validation loss: 2.025790427320747

Epoch: 5| Step: 2
Training loss: 2.7532901763916016
Validation loss: 2.041454271603656

Epoch: 5| Step: 3
Training loss: 2.1290550231933594
Validation loss: 2.065410428149726

Epoch: 5| Step: 4
Training loss: 1.7700821161270142
Validation loss: 2.075444452224239

Epoch: 5| Step: 5
Training loss: 2.591742753982544
Validation loss: 2.0620707158119447

Epoch: 5| Step: 6
Training loss: 2.4588987827301025
Validation loss: 2.036196880443122

Epoch: 5| Step: 7
Training loss: 1.783916711807251
Validation loss: 2.001977769277429

Epoch: 5| Step: 8
Training loss: 2.625955104827881
Validation loss: 1.9865123712888328

Epoch: 5| Step: 9
Training loss: 2.052031993865967
Validation loss: 1.9746989973129765

Epoch: 5| Step: 10
Training loss: 1.4282935857772827
Validation loss: 1.9519226345964658

Epoch: 181| Step: 0
Training loss: 1.9742759466171265
Validation loss: 1.9559109095604188

Epoch: 5| Step: 1
Training loss: 2.768291473388672
Validation loss: 1.9561460274522022

Epoch: 5| Step: 2
Training loss: 2.6828839778900146
Validation loss: 1.9638922329871886

Epoch: 5| Step: 3
Training loss: 1.8241134881973267
Validation loss: 1.960925591889248

Epoch: 5| Step: 4
Training loss: 2.4368772506713867
Validation loss: 1.9770361223528463

Epoch: 5| Step: 5
Training loss: 2.0112273693084717
Validation loss: 1.9633354499775877

Epoch: 5| Step: 6
Training loss: 2.1855592727661133
Validation loss: 1.9814237369004117

Epoch: 5| Step: 7
Training loss: 1.9186912775039673
Validation loss: 1.9920989826161375

Epoch: 5| Step: 8
Training loss: 2.1046836376190186
Validation loss: 2.0038724535255024

Epoch: 5| Step: 9
Training loss: 2.291595458984375
Validation loss: 2.00401480479907

Epoch: 5| Step: 10
Training loss: 1.6861953735351562
Validation loss: 2.005768342684674

Epoch: 182| Step: 0
Training loss: 2.3878204822540283
Validation loss: 2.003481945683879

Epoch: 5| Step: 1
Training loss: 2.6338388919830322
Validation loss: 1.9954407086936377

Epoch: 5| Step: 2
Training loss: 2.356548309326172
Validation loss: 1.9866437553077616

Epoch: 5| Step: 3
Training loss: 1.9820502996444702
Validation loss: 1.9835157266227148

Epoch: 5| Step: 4
Training loss: 1.6099830865859985
Validation loss: 1.9661413879804714

Epoch: 5| Step: 5
Training loss: 1.4741427898406982
Validation loss: 1.956864497994864

Epoch: 5| Step: 6
Training loss: 2.7137887477874756
Validation loss: 1.9448532340347127

Epoch: 5| Step: 7
Training loss: 1.793230414390564
Validation loss: 1.9220296875123055

Epoch: 5| Step: 8
Training loss: 2.3416473865509033
Validation loss: 1.9139015033680906

Epoch: 5| Step: 9
Training loss: 2.81748628616333
Validation loss: 1.9117095983156593

Epoch: 5| Step: 10
Training loss: 1.6539738178253174
Validation loss: 1.9227094855359805

Epoch: 183| Step: 0
Training loss: 2.6074938774108887
Validation loss: 1.902784098861038

Epoch: 5| Step: 1
Training loss: 1.665869116783142
Validation loss: 1.9098316738682408

Epoch: 5| Step: 2
Training loss: 2.4071521759033203
Validation loss: 1.909011927984094

Epoch: 5| Step: 3
Training loss: 1.7795689105987549
Validation loss: 1.9306063895584435

Epoch: 5| Step: 4
Training loss: 2.2101645469665527
Validation loss: 1.9389911210665138

Epoch: 5| Step: 5
Training loss: 2.2431843280792236
Validation loss: 1.9185572349896995

Epoch: 5| Step: 6
Training loss: 2.395646333694458
Validation loss: 1.9184649913541731

Epoch: 5| Step: 7
Training loss: 2.169473648071289
Validation loss: 1.921573232578975

Epoch: 5| Step: 8
Training loss: 2.2090790271759033
Validation loss: 1.9354532790440384

Epoch: 5| Step: 9
Training loss: 2.4177613258361816
Validation loss: 1.9327236785683581

Epoch: 5| Step: 10
Training loss: 1.7957546710968018
Validation loss: 1.946382358510007

Epoch: 184| Step: 0
Training loss: 2.116323709487915
Validation loss: 1.9561971028645833

Epoch: 5| Step: 1
Training loss: 2.4705944061279297
Validation loss: 1.9472250451323807

Epoch: 5| Step: 2
Training loss: 1.7725282907485962
Validation loss: 1.9523432357336885

Epoch: 5| Step: 3
Training loss: 2.1743507385253906
Validation loss: 1.9797516445959769

Epoch: 5| Step: 4
Training loss: 2.3880882263183594
Validation loss: 1.9744147485302341

Epoch: 5| Step: 5
Training loss: 2.3282554149627686
Validation loss: 1.9816414861268894

Epoch: 5| Step: 6
Training loss: 2.004077434539795
Validation loss: 1.9813534239287018

Epoch: 5| Step: 7
Training loss: 2.8411049842834473
Validation loss: 1.9820561716633458

Epoch: 5| Step: 8
Training loss: 2.040297746658325
Validation loss: 1.9575397212018248

Epoch: 5| Step: 9
Training loss: 2.3909919261932373
Validation loss: 1.9559994320715628

Epoch: 5| Step: 10
Training loss: 1.3306427001953125
Validation loss: 1.94916949477247

Epoch: 185| Step: 0
Training loss: 1.9801641702651978
Validation loss: 1.940470717286551

Epoch: 5| Step: 1
Training loss: 1.7001965045928955
Validation loss: 1.9566794146773636

Epoch: 5| Step: 2
Training loss: 2.2609875202178955
Validation loss: 1.985254535111048

Epoch: 5| Step: 3
Training loss: 2.040961742401123
Validation loss: 1.990507169436383

Epoch: 5| Step: 4
Training loss: 2.4348227977752686
Validation loss: 2.0368900017071794

Epoch: 5| Step: 5
Training loss: 2.2424304485321045
Validation loss: 2.06968161623965

Epoch: 5| Step: 6
Training loss: 2.246370553970337
Validation loss: 2.0345888906909573

Epoch: 5| Step: 7
Training loss: 2.618819236755371
Validation loss: 1.9746858009728052

Epoch: 5| Step: 8
Training loss: 1.8577415943145752
Validation loss: 1.9662131776091873

Epoch: 5| Step: 9
Training loss: 2.5605826377868652
Validation loss: 1.9677448259886874

Epoch: 5| Step: 10
Training loss: 2.1104369163513184
Validation loss: 1.9589814511678552

Epoch: 186| Step: 0
Training loss: 2.3595619201660156
Validation loss: 1.9686509498985865

Epoch: 5| Step: 1
Training loss: 1.6243095397949219
Validation loss: 1.9553411340200773

Epoch: 5| Step: 2
Training loss: 2.282458782196045
Validation loss: 1.9505426729879072

Epoch: 5| Step: 3
Training loss: 2.1119701862335205
Validation loss: 1.9438998263369325

Epoch: 5| Step: 4
Training loss: 1.9349257946014404
Validation loss: 1.9399351355850056

Epoch: 5| Step: 5
Training loss: 2.9358298778533936
Validation loss: 1.9493147327053932

Epoch: 5| Step: 6
Training loss: 1.6365013122558594
Validation loss: 1.9643240500521917

Epoch: 5| Step: 7
Training loss: 2.260315179824829
Validation loss: 1.9492349188814881

Epoch: 5| Step: 8
Training loss: 2.6605021953582764
Validation loss: 1.962416551446402

Epoch: 5| Step: 9
Training loss: 1.9455385208129883
Validation loss: 1.9472763499905985

Epoch: 5| Step: 10
Training loss: 1.9358080625534058
Validation loss: 1.928422648419616

Epoch: 187| Step: 0
Training loss: 2.1274797916412354
Validation loss: 1.931505895430042

Epoch: 5| Step: 1
Training loss: 1.972650170326233
Validation loss: 1.9263525188610118

Epoch: 5| Step: 2
Training loss: 1.874914526939392
Validation loss: 1.9427468943339523

Epoch: 5| Step: 3
Training loss: 1.8189518451690674
Validation loss: 1.9457641288798342

Epoch: 5| Step: 4
Training loss: 2.123133420944214
Validation loss: 1.9449824594682263

Epoch: 5| Step: 5
Training loss: 2.5896754264831543
Validation loss: 1.9846456717419367

Epoch: 5| Step: 6
Training loss: 2.196711301803589
Validation loss: 1.982794173302189

Epoch: 5| Step: 7
Training loss: 2.5244393348693848
Validation loss: 1.9942399455655007

Epoch: 5| Step: 8
Training loss: 2.213583469390869
Validation loss: 1.9962840977535452

Epoch: 5| Step: 9
Training loss: 2.0008742809295654
Validation loss: 2.0058970066808883

Epoch: 5| Step: 10
Training loss: 2.0437211990356445
Validation loss: 2.024550255908761

Epoch: 188| Step: 0
Training loss: 1.5344817638397217
Validation loss: 2.030931272814351

Epoch: 5| Step: 1
Training loss: 2.6247425079345703
Validation loss: 2.052030460808867

Epoch: 5| Step: 2
Training loss: 1.8737434148788452
Validation loss: 2.061189261815881

Epoch: 5| Step: 3
Training loss: 2.319979429244995
Validation loss: 2.035950235141221

Epoch: 5| Step: 4
Training loss: 1.7790921926498413
Validation loss: 1.9904390881138463

Epoch: 5| Step: 5
Training loss: 2.1308207511901855
Validation loss: 1.9689817044042772

Epoch: 5| Step: 6
Training loss: 2.40332293510437
Validation loss: 1.950961789777202

Epoch: 5| Step: 7
Training loss: 2.331146001815796
Validation loss: 1.9554664293924968

Epoch: 5| Step: 8
Training loss: 2.026982069015503
Validation loss: 1.9430120375848585

Epoch: 5| Step: 9
Training loss: 1.6462256908416748
Validation loss: 1.9274096386407011

Epoch: 5| Step: 10
Training loss: 2.797710657119751
Validation loss: 1.9354413786242086

Epoch: 189| Step: 0
Training loss: 1.8598483800888062
Validation loss: 1.9262352233291955

Epoch: 5| Step: 1
Training loss: 1.7769981622695923
Validation loss: 1.9188071630334342

Epoch: 5| Step: 2
Training loss: 1.6734187602996826
Validation loss: 1.9151318714182863

Epoch: 5| Step: 3
Training loss: 1.9534965753555298
Validation loss: 1.9219373451766146

Epoch: 5| Step: 4
Training loss: 2.4939894676208496
Validation loss: 1.9245381329649238

Epoch: 5| Step: 5
Training loss: 1.8869549036026
Validation loss: 1.938831337036625

Epoch: 5| Step: 6
Training loss: 2.264563798904419
Validation loss: 1.9414755272608932

Epoch: 5| Step: 7
Training loss: 1.8884410858154297
Validation loss: 1.9637873762397355

Epoch: 5| Step: 8
Training loss: 2.8030686378479004
Validation loss: 1.9453380992335658

Epoch: 5| Step: 9
Training loss: 2.3831424713134766
Validation loss: 1.9681401188655565

Epoch: 5| Step: 10
Training loss: 2.1835696697235107
Validation loss: 1.9698101000119281

Epoch: 190| Step: 0
Training loss: 1.638737440109253
Validation loss: 2.001894521456893

Epoch: 5| Step: 1
Training loss: 2.3060860633850098
Validation loss: 2.00634963281693

Epoch: 5| Step: 2
Training loss: 2.108755588531494
Validation loss: 2.008451807883478

Epoch: 5| Step: 3
Training loss: 2.1173408031463623
Validation loss: 2.018581457035516

Epoch: 5| Step: 4
Training loss: 2.1117517948150635
Validation loss: 2.015061959143608

Epoch: 5| Step: 5
Training loss: 1.850736379623413
Validation loss: 2.0054642308142876

Epoch: 5| Step: 6
Training loss: 2.308321475982666
Validation loss: 1.9819613938690515

Epoch: 5| Step: 7
Training loss: 2.0995097160339355
Validation loss: 1.9654837692937543

Epoch: 5| Step: 8
Training loss: 2.303164005279541
Validation loss: 1.975081254077214

Epoch: 5| Step: 9
Training loss: 2.1945340633392334
Validation loss: 1.9729258398855887

Epoch: 5| Step: 10
Training loss: 2.2470176219940186
Validation loss: 1.9614999243008193

Epoch: 191| Step: 0
Training loss: 2.4974591732025146
Validation loss: 1.9646537201378935

Epoch: 5| Step: 1
Training loss: 1.5865377187728882
Validation loss: 1.9780460288447719

Epoch: 5| Step: 2
Training loss: 2.3898074626922607
Validation loss: 1.983366794483636

Epoch: 5| Step: 3
Training loss: 1.7720779180526733
Validation loss: 1.977172782344203

Epoch: 5| Step: 4
Training loss: 2.4566242694854736
Validation loss: 1.9650768926066737

Epoch: 5| Step: 5
Training loss: 2.421750068664551
Validation loss: 1.9484538109071794

Epoch: 5| Step: 6
Training loss: 1.8332990407943726
Validation loss: 1.9639791173319663

Epoch: 5| Step: 7
Training loss: 2.076803684234619
Validation loss: 1.9465697426949777

Epoch: 5| Step: 8
Training loss: 2.1435070037841797
Validation loss: 1.9470894695610128

Epoch: 5| Step: 9
Training loss: 1.8824068307876587
Validation loss: 1.942817634151828

Epoch: 5| Step: 10
Training loss: 1.8932965993881226
Validation loss: 1.9629607162167948

Epoch: 192| Step: 0
Training loss: 1.923611044883728
Validation loss: 1.9942528124778502

Epoch: 5| Step: 1
Training loss: 2.2201507091522217
Validation loss: 2.0048494005715973

Epoch: 5| Step: 2
Training loss: 1.9374382495880127
Validation loss: 2.024316515973819

Epoch: 5| Step: 3
Training loss: 2.4539694786071777
Validation loss: 2.0221735636393228

Epoch: 5| Step: 4
Training loss: 2.099031448364258
Validation loss: 1.984745212780532

Epoch: 5| Step: 5
Training loss: 2.185995578765869
Validation loss: 1.973769135372613

Epoch: 5| Step: 6
Training loss: 2.1335630416870117
Validation loss: 1.9421315539267756

Epoch: 5| Step: 7
Training loss: 2.1610260009765625
Validation loss: 1.940952721462455

Epoch: 5| Step: 8
Training loss: 1.986759901046753
Validation loss: 1.9257008644842333

Epoch: 5| Step: 9
Training loss: 2.234123706817627
Validation loss: 1.906875459096765

Epoch: 5| Step: 10
Training loss: 1.8176685571670532
Validation loss: 1.899524547720468

Epoch: 193| Step: 0
Training loss: 2.06520938873291
Validation loss: 1.9200547228577316

Epoch: 5| Step: 1
Training loss: 2.1649856567382812
Validation loss: 1.9449835849064652

Epoch: 5| Step: 2
Training loss: 2.32694673538208
Validation loss: 1.9664315664640037

Epoch: 5| Step: 3
Training loss: 2.0798795223236084
Validation loss: 1.9565780008992841

Epoch: 5| Step: 4
Training loss: 1.0811102390289307
Validation loss: 1.9978589588595974

Epoch: 5| Step: 5
Training loss: 2.9071619510650635
Validation loss: 2.04260616917764

Epoch: 5| Step: 6
Training loss: 2.645392894744873
Validation loss: 2.0213702571007515

Epoch: 5| Step: 7
Training loss: 2.0324764251708984
Validation loss: 1.996979994158591

Epoch: 5| Step: 8
Training loss: 1.6959717273712158
Validation loss: 1.9486968440394248

Epoch: 5| Step: 9
Training loss: 2.7183241844177246
Validation loss: 1.9559114889432025

Epoch: 5| Step: 10
Training loss: 1.5966112613677979
Validation loss: 1.9495661604788996

Epoch: 194| Step: 0
Training loss: 2.65312123298645
Validation loss: 1.9439284365664247

Epoch: 5| Step: 1
Training loss: 1.977551817893982
Validation loss: 1.9465528060031194

Epoch: 5| Step: 2
Training loss: 1.7859218120574951
Validation loss: 1.9416357842824792

Epoch: 5| Step: 3
Training loss: 1.8622337579727173
Validation loss: 1.9591564132321266

Epoch: 5| Step: 4
Training loss: 2.3380212783813477
Validation loss: 1.9489848139465495

Epoch: 5| Step: 5
Training loss: 2.471517324447632
Validation loss: 1.9572381537447694

Epoch: 5| Step: 6
Training loss: 1.8294875621795654
Validation loss: 1.9895169901591476

Epoch: 5| Step: 7
Training loss: 2.3238439559936523
Validation loss: 2.002779068485383

Epoch: 5| Step: 8
Training loss: 2.076064109802246
Validation loss: 2.009008821620736

Epoch: 5| Step: 9
Training loss: 1.8827149868011475
Validation loss: 2.0182269465538765

Epoch: 5| Step: 10
Training loss: 1.5893610715866089
Validation loss: 2.0189776189865603

Epoch: 195| Step: 0
Training loss: 2.6411080360412598
Validation loss: 1.9829419223211144

Epoch: 5| Step: 1
Training loss: 1.6599667072296143
Validation loss: 1.9526959901214929

Epoch: 5| Step: 2
Training loss: 1.9499982595443726
Validation loss: 1.9426621724200506

Epoch: 5| Step: 3
Training loss: 1.8845913410186768
Validation loss: 1.9468333490433232

Epoch: 5| Step: 4
Training loss: 1.4856977462768555
Validation loss: 1.9266670468033

Epoch: 5| Step: 5
Training loss: 2.833683490753174
Validation loss: 1.9244829698275494

Epoch: 5| Step: 6
Training loss: 1.584336519241333
Validation loss: 1.9287666607928533

Epoch: 5| Step: 7
Training loss: 2.3727059364318848
Validation loss: 1.95283983343391

Epoch: 5| Step: 8
Training loss: 1.8425239324569702
Validation loss: 1.963889439900716

Epoch: 5| Step: 9
Training loss: 2.3607590198516846
Validation loss: 1.990702224034135

Epoch: 5| Step: 10
Training loss: 2.3042540550231934
Validation loss: 1.9846234295957832

Epoch: 196| Step: 0
Training loss: 1.4697389602661133
Validation loss: 1.9432052604613765

Epoch: 5| Step: 1
Training loss: 1.8806778192520142
Validation loss: 1.939186703774237

Epoch: 5| Step: 2
Training loss: 2.2321791648864746
Validation loss: 1.9664511706239434

Epoch: 5| Step: 3
Training loss: 2.327003002166748
Validation loss: 1.9971644686114403

Epoch: 5| Step: 4
Training loss: 1.7219852209091187
Validation loss: 2.0069826238898822

Epoch: 5| Step: 5
Training loss: 2.5538907051086426
Validation loss: 2.0235126928616594

Epoch: 5| Step: 6
Training loss: 1.595705270767212
Validation loss: 2.004625262752656

Epoch: 5| Step: 7
Training loss: 1.8395798206329346
Validation loss: 1.9944085357009724

Epoch: 5| Step: 8
Training loss: 2.488987445831299
Validation loss: 1.9948292240019767

Epoch: 5| Step: 9
Training loss: 2.5125973224639893
Validation loss: 2.0350491795488583

Epoch: 5| Step: 10
Training loss: 2.248490333557129
Validation loss: 2.0842098074574626

Epoch: 197| Step: 0
Training loss: 1.6551929712295532
Validation loss: 2.131873551235404

Epoch: 5| Step: 1
Training loss: 2.3376078605651855
Validation loss: 2.125285686985139

Epoch: 5| Step: 2
Training loss: 1.8280019760131836
Validation loss: 2.044731558010142

Epoch: 5| Step: 3
Training loss: 2.313567638397217
Validation loss: 1.9915238298395628

Epoch: 5| Step: 4
Training loss: 2.270524263381958
Validation loss: 1.914368514091738

Epoch: 5| Step: 5
Training loss: 1.4876387119293213
Validation loss: 1.8984215233915596

Epoch: 5| Step: 6
Training loss: 2.0533363819122314
Validation loss: 1.9247175339729554

Epoch: 5| Step: 7
Training loss: 2.588634967803955
Validation loss: 1.9244731139111262

Epoch: 5| Step: 8
Training loss: 2.6742749214172363
Validation loss: 1.8981581067526212

Epoch: 5| Step: 9
Training loss: 2.4334959983825684
Validation loss: 1.886813784158358

Epoch: 5| Step: 10
Training loss: 2.0394840240478516
Validation loss: 1.8807214178064817

Epoch: 198| Step: 0
Training loss: 2.0547759532928467
Validation loss: 1.8639796549274075

Epoch: 5| Step: 1
Training loss: 1.8745098114013672
Validation loss: 1.872781575367015

Epoch: 5| Step: 2
Training loss: 2.941542387008667
Validation loss: 1.8965273569988947

Epoch: 5| Step: 3
Training loss: 1.4731005430221558
Validation loss: 1.9309707200655373

Epoch: 5| Step: 4
Training loss: 1.9531892538070679
Validation loss: 1.9429137514483543

Epoch: 5| Step: 5
Training loss: 2.636369228363037
Validation loss: 1.9027943957236506

Epoch: 5| Step: 6
Training loss: 1.8182659149169922
Validation loss: 1.909700297540234

Epoch: 5| Step: 7
Training loss: 2.281421184539795
Validation loss: 1.9315827482490129

Epoch: 5| Step: 8
Training loss: 1.3026933670043945
Validation loss: 1.9457977100085186

Epoch: 5| Step: 9
Training loss: 1.9783254861831665
Validation loss: 1.9354061939383065

Epoch: 5| Step: 10
Training loss: 2.8827669620513916
Validation loss: 1.9490152866609636

Epoch: 199| Step: 0
Training loss: 1.7687187194824219
Validation loss: 1.9529978357335573

Epoch: 5| Step: 1
Training loss: 2.187788248062134
Validation loss: 1.9538729601008917

Epoch: 5| Step: 2
Training loss: 2.2256338596343994
Validation loss: 1.953635968187804

Epoch: 5| Step: 3
Training loss: 2.1417908668518066
Validation loss: 1.9865260688207482

Epoch: 5| Step: 4
Training loss: 1.9042730331420898
Validation loss: 1.9655554538132043

Epoch: 5| Step: 5
Training loss: 1.7256873846054077
Validation loss: 1.967326016836269

Epoch: 5| Step: 6
Training loss: 1.8196872472763062
Validation loss: 1.9532982303250221

Epoch: 5| Step: 7
Training loss: 1.86294686794281
Validation loss: 1.9710035785551994

Epoch: 5| Step: 8
Training loss: 2.0197339057922363
Validation loss: 1.9818543259815504

Epoch: 5| Step: 9
Training loss: 2.764756679534912
Validation loss: 2.023806571960449

Epoch: 5| Step: 10
Training loss: 2.1043012142181396
Validation loss: 2.0222194297339326

Epoch: 200| Step: 0
Training loss: 1.5849493741989136
Validation loss: 2.013057538258132

Epoch: 5| Step: 1
Training loss: 1.3497847318649292
Validation loss: 2.033522993005732

Epoch: 5| Step: 2
Training loss: 1.9742584228515625
Validation loss: 2.0295295164149296

Epoch: 5| Step: 3
Training loss: 2.0938034057617188
Validation loss: 2.041793611741835

Epoch: 5| Step: 4
Training loss: 2.5399487018585205
Validation loss: 2.0497275334532543

Epoch: 5| Step: 5
Training loss: 2.1218113899230957
Validation loss: 2.0294686261043755

Epoch: 5| Step: 6
Training loss: 1.9319394826889038
Validation loss: 2.0621384023338236

Epoch: 5| Step: 7
Training loss: 1.9532740116119385
Validation loss: 2.0469349750908474

Epoch: 5| Step: 8
Training loss: 2.8276584148406982
Validation loss: 2.0011180472630326

Epoch: 5| Step: 9
Training loss: 2.1997387409210205
Validation loss: 1.9890590931779595

Epoch: 5| Step: 10
Training loss: 2.027456760406494
Validation loss: 1.965935234100588

Epoch: 201| Step: 0
Training loss: 2.0062766075134277
Validation loss: 1.9493903716405232

Epoch: 5| Step: 1
Training loss: 2.0061469078063965
Validation loss: 1.9631736201624717

Epoch: 5| Step: 2
Training loss: 1.9916965961456299
Validation loss: 1.9823484446412774

Epoch: 5| Step: 3
Training loss: 2.4724509716033936
Validation loss: 1.9748329513816423

Epoch: 5| Step: 4
Training loss: 1.9628684520721436
Validation loss: 1.974009285690964

Epoch: 5| Step: 5
Training loss: 1.9026371240615845
Validation loss: 1.9568688202929754

Epoch: 5| Step: 6
Training loss: 1.4603503942489624
Validation loss: 1.9350013348364061

Epoch: 5| Step: 7
Training loss: 2.2057740688323975
Validation loss: 1.9382218481391988

Epoch: 5| Step: 8
Training loss: 2.2817766666412354
Validation loss: 1.9306717098400157

Epoch: 5| Step: 9
Training loss: 2.1792044639587402
Validation loss: 1.9349828048418927

Epoch: 5| Step: 10
Training loss: 2.234640121459961
Validation loss: 1.9446507320609143

Epoch: 202| Step: 0
Training loss: 1.8708908557891846
Validation loss: 1.946890397738385

Epoch: 5| Step: 1
Training loss: 1.9923709630966187
Validation loss: 1.959532242949291

Epoch: 5| Step: 2
Training loss: 1.845285415649414
Validation loss: 1.9598761630314652

Epoch: 5| Step: 3
Training loss: 2.09564208984375
Validation loss: 1.9780957160457489

Epoch: 5| Step: 4
Training loss: 1.9427015781402588
Validation loss: 1.9719064543324132

Epoch: 5| Step: 5
Training loss: 2.0966649055480957
Validation loss: 1.9755814049833564

Epoch: 5| Step: 6
Training loss: 2.024813413619995
Validation loss: 1.9743744596358268

Epoch: 5| Step: 7
Training loss: 2.3188419342041016
Validation loss: 1.9923495848973591

Epoch: 5| Step: 8
Training loss: 2.3247909545898438
Validation loss: 1.9956523154371528

Epoch: 5| Step: 9
Training loss: 1.4697439670562744
Validation loss: 1.9920582899483301

Epoch: 5| Step: 10
Training loss: 1.7941409349441528
Validation loss: 1.9966282254906111

Epoch: 203| Step: 0
Training loss: 2.181629180908203
Validation loss: 1.9867816766103108

Epoch: 5| Step: 1
Training loss: 1.633599042892456
Validation loss: 1.9879021080591346

Epoch: 5| Step: 2
Training loss: 1.499009370803833
Validation loss: 1.9709908116248347

Epoch: 5| Step: 3
Training loss: 1.5718679428100586
Validation loss: 1.9707257106739988

Epoch: 5| Step: 4
Training loss: 2.0632991790771484
Validation loss: 1.9654036503966137

Epoch: 5| Step: 5
Training loss: 1.570265293121338
Validation loss: 1.9736104652445803

Epoch: 5| Step: 6
Training loss: 2.450089931488037
Validation loss: 1.975719085303686

Epoch: 5| Step: 7
Training loss: 2.3755075931549072
Validation loss: 1.9550253601484402

Epoch: 5| Step: 8
Training loss: 2.3033337593078613
Validation loss: 1.9396588610064598

Epoch: 5| Step: 9
Training loss: 2.1569368839263916
Validation loss: 1.9399847830495527

Epoch: 5| Step: 10
Training loss: 2.324831008911133
Validation loss: 1.9388837557966991

Epoch: 204| Step: 0
Training loss: 1.6676464080810547
Validation loss: 1.9329867414248887

Epoch: 5| Step: 1
Training loss: 1.9462535381317139
Validation loss: 1.9065137858031898

Epoch: 5| Step: 2
Training loss: 1.9409122467041016
Validation loss: 1.9224054364747898

Epoch: 5| Step: 3
Training loss: 1.8408619165420532
Validation loss: 1.9492490676141554

Epoch: 5| Step: 4
Training loss: 2.64990234375
Validation loss: 2.015412531873231

Epoch: 5| Step: 5
Training loss: 1.5038766860961914
Validation loss: 2.048904581736493

Epoch: 5| Step: 6
Training loss: 2.2887675762176514
Validation loss: 1.9855318389913088

Epoch: 5| Step: 7
Training loss: 1.9302022457122803
Validation loss: 1.9148973777729978

Epoch: 5| Step: 8
Training loss: 2.1832900047302246
Validation loss: 1.933744199814335

Epoch: 5| Step: 9
Training loss: 2.4415576457977295
Validation loss: 1.9350347518920898

Epoch: 5| Step: 10
Training loss: 1.7489365339279175
Validation loss: 1.9015565136427521

Epoch: 205| Step: 0
Training loss: 2.2363884449005127
Validation loss: 1.908421419000113

Epoch: 5| Step: 1
Training loss: 2.1922669410705566
Validation loss: 1.8995862007141113

Epoch: 5| Step: 2
Training loss: 2.118560552597046
Validation loss: 1.8981983866742862

Epoch: 5| Step: 3
Training loss: 1.6624176502227783
Validation loss: 1.9214418280509211

Epoch: 5| Step: 4
Training loss: 1.3424468040466309
Validation loss: 1.953314891425512

Epoch: 5| Step: 5
Training loss: 2.1914076805114746
Validation loss: 1.9352143208185832

Epoch: 5| Step: 6
Training loss: 2.3283910751342773
Validation loss: 1.9443464535538868

Epoch: 5| Step: 7
Training loss: 2.330514669418335
Validation loss: 1.936045826122325

Epoch: 5| Step: 8
Training loss: 1.7078819274902344
Validation loss: 1.9429000359709545

Epoch: 5| Step: 9
Training loss: 2.000002861022949
Validation loss: 1.9717459576104277

Epoch: 5| Step: 10
Training loss: 1.8174211978912354
Validation loss: 1.9911497869799215

Epoch: 206| Step: 0
Training loss: 2.537820339202881
Validation loss: 2.001370049292041

Epoch: 5| Step: 1
Training loss: 1.758587121963501
Validation loss: 2.0140173101937897

Epoch: 5| Step: 2
Training loss: 1.8223823308944702
Validation loss: 2.012542493881718

Epoch: 5| Step: 3
Training loss: 2.2232022285461426
Validation loss: 2.0430756794509066

Epoch: 5| Step: 4
Training loss: 2.178694248199463
Validation loss: 2.046638911770236

Epoch: 5| Step: 5
Training loss: 2.3284833431243896
Validation loss: 2.032884173495795

Epoch: 5| Step: 6
Training loss: 1.5007799863815308
Validation loss: 2.0168023519618536

Epoch: 5| Step: 7
Training loss: 1.6397380828857422
Validation loss: 1.9998619876882082

Epoch: 5| Step: 8
Training loss: 2.3509018421173096
Validation loss: 2.010765767866565

Epoch: 5| Step: 9
Training loss: 1.7178452014923096
Validation loss: 1.9957495620173793

Epoch: 5| Step: 10
Training loss: 1.749047875404358
Validation loss: 1.9728340282235095

Epoch: 207| Step: 0
Training loss: 1.7225490808486938
Validation loss: 1.956217917062903

Epoch: 5| Step: 1
Training loss: 1.9469082355499268
Validation loss: 1.9459393896082395

Epoch: 5| Step: 2
Training loss: 2.4999256134033203
Validation loss: 1.9444138337207097

Epoch: 5| Step: 3
Training loss: 1.906958818435669
Validation loss: 1.9331560493797384

Epoch: 5| Step: 4
Training loss: 1.7925193309783936
Validation loss: 1.9316300205005112

Epoch: 5| Step: 5
Training loss: 1.6331068277359009
Validation loss: 1.928016713870469

Epoch: 5| Step: 6
Training loss: 2.41788649559021
Validation loss: 1.9395539504225536

Epoch: 5| Step: 7
Training loss: 1.8230273723602295
Validation loss: 1.9514207532328944

Epoch: 5| Step: 8
Training loss: 2.430161237716675
Validation loss: 1.9895780124971945

Epoch: 5| Step: 9
Training loss: 1.4846227169036865
Validation loss: 1.9779230061397757

Epoch: 5| Step: 10
Training loss: 1.8896143436431885
Validation loss: 1.986869086501419

Epoch: 208| Step: 0
Training loss: 2.298483371734619
Validation loss: 1.9565073238906039

Epoch: 5| Step: 1
Training loss: 1.6879937648773193
Validation loss: 1.9493708225988573

Epoch: 5| Step: 2
Training loss: 1.7799876928329468
Validation loss: 1.946285355475641

Epoch: 5| Step: 3
Training loss: 2.2376058101654053
Validation loss: 1.9520893853197816

Epoch: 5| Step: 4
Training loss: 1.9559402465820312
Validation loss: 1.9338465813667542

Epoch: 5| Step: 5
Training loss: 2.116147756576538
Validation loss: 1.9559286794354838

Epoch: 5| Step: 6
Training loss: 1.7897357940673828
Validation loss: 1.9476064071860364

Epoch: 5| Step: 7
Training loss: 1.464206337928772
Validation loss: 1.9454594453175862

Epoch: 5| Step: 8
Training loss: 1.8291505575180054
Validation loss: 1.941583014303638

Epoch: 5| Step: 9
Training loss: 2.02251935005188
Validation loss: 1.9513554983241583

Epoch: 5| Step: 10
Training loss: 2.0058202743530273
Validation loss: 1.9620087262122863

Epoch: 209| Step: 0
Training loss: 2.1996872425079346
Validation loss: 1.960801362991333

Epoch: 5| Step: 1
Training loss: 1.8871591091156006
Validation loss: 1.9619600901039698

Epoch: 5| Step: 2
Training loss: 1.8508809804916382
Validation loss: 1.9675572943943802

Epoch: 5| Step: 3
Training loss: 1.8744938373565674
Validation loss: 1.9732929993701238

Epoch: 5| Step: 4
Training loss: 1.877294898033142
Validation loss: 1.9539829684842018

Epoch: 5| Step: 5
Training loss: 1.8413410186767578
Validation loss: 1.9683576553098616

Epoch: 5| Step: 6
Training loss: 1.9002799987792969
Validation loss: 1.9923447639711442

Epoch: 5| Step: 7
Training loss: 1.8074884414672852
Validation loss: 1.9902818305518037

Epoch: 5| Step: 8
Training loss: 2.2509703636169434
Validation loss: 1.9829412096290178

Epoch: 5| Step: 9
Training loss: 1.6577609777450562
Validation loss: 1.981695213625508

Epoch: 5| Step: 10
Training loss: 2.032691478729248
Validation loss: 1.9862160964678692

Epoch: 210| Step: 0
Training loss: 1.8977940082550049
Validation loss: 1.9846439592299923

Epoch: 5| Step: 1
Training loss: 1.6642627716064453
Validation loss: 2.0187910000483194

Epoch: 5| Step: 2
Training loss: 1.964529275894165
Validation loss: 2.001619541516868

Epoch: 5| Step: 3
Training loss: 2.3991665840148926
Validation loss: 1.9665158205134894

Epoch: 5| Step: 4
Training loss: 2.22920823097229
Validation loss: 1.9458921801659368

Epoch: 5| Step: 5
Training loss: 1.4393174648284912
Validation loss: 1.917231471307816

Epoch: 5| Step: 6
Training loss: 2.0178611278533936
Validation loss: 1.8952951008273708

Epoch: 5| Step: 7
Training loss: 1.7719577550888062
Validation loss: 1.9001016680912306

Epoch: 5| Step: 8
Training loss: 1.2596843242645264
Validation loss: 1.890586236471771

Epoch: 5| Step: 9
Training loss: 2.108257293701172
Validation loss: 1.8820961277971986

Epoch: 5| Step: 10
Training loss: 2.4030213356018066
Validation loss: 1.912545532308599

Epoch: 211| Step: 0
Training loss: 2.2265594005584717
Validation loss: 1.91916670081436

Epoch: 5| Step: 1
Training loss: 1.3328678607940674
Validation loss: 1.9595849052552254

Epoch: 5| Step: 2
Training loss: 1.8500293493270874
Validation loss: 1.955491667152733

Epoch: 5| Step: 3
Training loss: 1.829108476638794
Validation loss: 1.9506479437633226

Epoch: 5| Step: 4
Training loss: 2.4579966068267822
Validation loss: 1.9442680497323312

Epoch: 5| Step: 5
Training loss: 1.639501929283142
Validation loss: 1.9558411054713751

Epoch: 5| Step: 6
Training loss: 2.0766184329986572
Validation loss: 2.017446933254119

Epoch: 5| Step: 7
Training loss: 1.880641222000122
Validation loss: 2.0289014872684272

Epoch: 5| Step: 8
Training loss: 1.7364848852157593
Validation loss: 2.0062917740114274

Epoch: 5| Step: 9
Training loss: 2.1642627716064453
Validation loss: 2.010048217670892

Epoch: 5| Step: 10
Training loss: 2.2696309089660645
Validation loss: 2.0300261205242527

Epoch: 212| Step: 0
Training loss: 2.203850269317627
Validation loss: 2.064907948176066

Epoch: 5| Step: 1
Training loss: 1.836120367050171
Validation loss: 2.105810805033612

Epoch: 5| Step: 2
Training loss: 2.3015990257263184
Validation loss: 2.1062252803515364

Epoch: 5| Step: 3
Training loss: 2.6307759284973145
Validation loss: 2.1256907832237983

Epoch: 5| Step: 4
Training loss: 1.8259683847427368
Validation loss: 2.0987848094714585

Epoch: 5| Step: 5
Training loss: 1.7554031610488892
Validation loss: 2.063366077279532

Epoch: 5| Step: 6
Training loss: 1.3186124563217163
Validation loss: 2.0230982457437823

Epoch: 5| Step: 7
Training loss: 1.6766170263290405
Validation loss: 2.0128758876554427

Epoch: 5| Step: 8
Training loss: 1.7677539587020874
Validation loss: 1.9916037718454997

Epoch: 5| Step: 9
Training loss: 1.822369933128357
Validation loss: 1.9853624605363416

Epoch: 5| Step: 10
Training loss: 2.0498178005218506
Validation loss: 1.9741376061593332

Epoch: 213| Step: 0
Training loss: 1.762786865234375
Validation loss: 1.957059807674859

Epoch: 5| Step: 1
Training loss: 2.3312265872955322
Validation loss: 1.9401824435880106

Epoch: 5| Step: 2
Training loss: 2.3886265754699707
Validation loss: 1.9457908189424904

Epoch: 5| Step: 3
Training loss: 1.7984157800674438
Validation loss: 1.9593349579841859

Epoch: 5| Step: 4
Training loss: 1.9880897998809814
Validation loss: 1.9748373005979805

Epoch: 5| Step: 5
Training loss: 1.6721832752227783
Validation loss: 1.9769840407115158

Epoch: 5| Step: 6
Training loss: 1.8265588283538818
Validation loss: 2.021741641465054

Epoch: 5| Step: 7
Training loss: 1.4789609909057617
Validation loss: 2.019028671326176

Epoch: 5| Step: 8
Training loss: 2.0144028663635254
Validation loss: 1.996486351054202

Epoch: 5| Step: 9
Training loss: 2.18072247505188
Validation loss: 2.0013875628030426

Epoch: 5| Step: 10
Training loss: 1.5051639080047607
Validation loss: 1.975622918016167

Epoch: 214| Step: 0
Training loss: 1.6429611444473267
Validation loss: 1.992839010812903

Epoch: 5| Step: 1
Training loss: 2.3581862449645996
Validation loss: 1.97706740133224

Epoch: 5| Step: 2
Training loss: 2.0643997192382812
Validation loss: 1.9508981858530352

Epoch: 5| Step: 3
Training loss: 1.9395071268081665
Validation loss: 1.9307394437892462

Epoch: 5| Step: 4
Training loss: 1.7209272384643555
Validation loss: 1.9467453520785096

Epoch: 5| Step: 5
Training loss: 1.4465153217315674
Validation loss: 1.9746795495351155

Epoch: 5| Step: 6
Training loss: 1.3838542699813843
Validation loss: 2.0049245716423116

Epoch: 5| Step: 7
Training loss: 1.9079933166503906
Validation loss: 2.021590277712832

Epoch: 5| Step: 8
Training loss: 2.082080364227295
Validation loss: 2.0009699483071604

Epoch: 5| Step: 9
Training loss: 2.5452189445495605
Validation loss: 1.9625262893656248

Epoch: 5| Step: 10
Training loss: 1.948204517364502
Validation loss: 1.9380204549399755

Epoch: 215| Step: 0
Training loss: 1.6745035648345947
Validation loss: 1.9312450821681688

Epoch: 5| Step: 1
Training loss: 1.6836793422698975
Validation loss: 1.9286443930800243

Epoch: 5| Step: 2
Training loss: 1.9957857131958008
Validation loss: 1.9017468472962737

Epoch: 5| Step: 3
Training loss: 2.133096694946289
Validation loss: 1.8879734469998268

Epoch: 5| Step: 4
Training loss: 1.671309232711792
Validation loss: 1.9413226189151886

Epoch: 5| Step: 5
Training loss: 1.6694797277450562
Validation loss: 2.0003337347379295

Epoch: 5| Step: 6
Training loss: 1.7884105443954468
Validation loss: 2.0519563869763444

Epoch: 5| Step: 7
Training loss: 2.278610944747925
Validation loss: 2.090608157137389

Epoch: 5| Step: 8
Training loss: 1.8099696636199951
Validation loss: 2.087893783405263

Epoch: 5| Step: 9
Training loss: 2.492178440093994
Validation loss: 2.0669866864399244

Epoch: 5| Step: 10
Training loss: 1.898853063583374
Validation loss: 2.0469528270024124

Epoch: 216| Step: 0
Training loss: 1.5881028175354004
Validation loss: 2.0263331423523607

Epoch: 5| Step: 1
Training loss: 1.3001298904418945
Validation loss: 2.0050673074619745

Epoch: 5| Step: 2
Training loss: 1.9380779266357422
Validation loss: 2.033344481581001

Epoch: 5| Step: 3
Training loss: 2.1499669551849365
Validation loss: 2.0410140663064937

Epoch: 5| Step: 4
Training loss: 1.9214378595352173
Validation loss: 2.031515823897495

Epoch: 5| Step: 5
Training loss: 1.9658215045928955
Validation loss: 2.0156280763687624

Epoch: 5| Step: 6
Training loss: 1.6764099597930908
Validation loss: 2.031311809375722

Epoch: 5| Step: 7
Training loss: 2.1871538162231445
Validation loss: 2.0293166406692995

Epoch: 5| Step: 8
Training loss: 1.3657686710357666
Validation loss: 2.030745167886057

Epoch: 5| Step: 9
Training loss: 2.1431899070739746
Validation loss: 2.021069383108488

Epoch: 5| Step: 10
Training loss: 2.5319578647613525
Validation loss: 1.9956304924462431

Epoch: 217| Step: 0
Training loss: 2.2805638313293457
Validation loss: 1.9830355926226544

Epoch: 5| Step: 1
Training loss: 1.726732611656189
Validation loss: 1.9568477958761237

Epoch: 5| Step: 2
Training loss: 2.012303113937378
Validation loss: 1.9201466729564052

Epoch: 5| Step: 3
Training loss: 1.7360109090805054
Validation loss: 1.908319365593695

Epoch: 5| Step: 4
Training loss: 1.5948336124420166
Validation loss: 1.909128499287431

Epoch: 5| Step: 5
Training loss: 1.395019769668579
Validation loss: 1.9510378940131075

Epoch: 5| Step: 6
Training loss: 2.0233983993530273
Validation loss: 1.9794771030385008

Epoch: 5| Step: 7
Training loss: 2.256108045578003
Validation loss: 1.9845171308004728

Epoch: 5| Step: 8
Training loss: 2.030122995376587
Validation loss: 1.9735968805128528

Epoch: 5| Step: 9
Training loss: 2.0109806060791016
Validation loss: 1.9654019596756145

Epoch: 5| Step: 10
Training loss: 1.4252715110778809
Validation loss: 1.983710870947889

Epoch: 218| Step: 0
Training loss: 1.727071762084961
Validation loss: 1.9980304228362216

Epoch: 5| Step: 1
Training loss: 2.0199990272521973
Validation loss: 1.9990219505884315

Epoch: 5| Step: 2
Training loss: 1.403054118156433
Validation loss: 2.012494638401975

Epoch: 5| Step: 3
Training loss: 1.3605401515960693
Validation loss: 2.013710783373925

Epoch: 5| Step: 4
Training loss: 2.0104804039001465
Validation loss: 2.0372222213334936

Epoch: 5| Step: 5
Training loss: 1.8124370574951172
Validation loss: 2.0464085122590423

Epoch: 5| Step: 6
Training loss: 1.728451132774353
Validation loss: 2.012125967651285

Epoch: 5| Step: 7
Training loss: 1.519131064414978
Validation loss: 1.9885822150015062

Epoch: 5| Step: 8
Training loss: 2.7993035316467285
Validation loss: 1.9918987007551296

Epoch: 5| Step: 9
Training loss: 1.897080421447754
Validation loss: 1.976202816091558

Epoch: 5| Step: 10
Training loss: 1.961352825164795
Validation loss: 1.9563137356952955

Epoch: 219| Step: 0
Training loss: 1.4617862701416016
Validation loss: 1.9360812607631888

Epoch: 5| Step: 1
Training loss: 1.847381830215454
Validation loss: 1.9192528109396658

Epoch: 5| Step: 2
Training loss: 1.7982361316680908
Validation loss: 1.9388009207223051

Epoch: 5| Step: 3
Training loss: 1.8244110345840454
Validation loss: 1.9108092246517059

Epoch: 5| Step: 4
Training loss: 1.7105464935302734
Validation loss: 1.9034347649543517

Epoch: 5| Step: 5
Training loss: 1.4594368934631348
Validation loss: 1.924631558438783

Epoch: 5| Step: 6
Training loss: 2.3392839431762695
Validation loss: 1.93156188021424

Epoch: 5| Step: 7
Training loss: 2.1181492805480957
Validation loss: 1.939668788704821

Epoch: 5| Step: 8
Training loss: 1.8038065433502197
Validation loss: 1.965624564437456

Epoch: 5| Step: 9
Training loss: 2.176405429840088
Validation loss: 1.97455898920695

Epoch: 5| Step: 10
Training loss: 1.7456344366073608
Validation loss: 1.9672697974789528

Epoch: 220| Step: 0
Training loss: 2.386018753051758
Validation loss: 1.9431748518379786

Epoch: 5| Step: 1
Training loss: 2.285170316696167
Validation loss: 1.9546490766668831

Epoch: 5| Step: 2
Training loss: 2.141566038131714
Validation loss: 1.9744843206098002

Epoch: 5| Step: 3
Training loss: 1.374782919883728
Validation loss: 1.9510358764279274

Epoch: 5| Step: 4
Training loss: 1.467246413230896
Validation loss: 1.9379569202341058

Epoch: 5| Step: 5
Training loss: 2.004934072494507
Validation loss: 1.9520233010733

Epoch: 5| Step: 6
Training loss: 1.9177749156951904
Validation loss: 1.9872340694550545

Epoch: 5| Step: 7
Training loss: 1.4890105724334717
Validation loss: 2.0271314600462556

Epoch: 5| Step: 8
Training loss: 1.6136605739593506
Validation loss: 2.0245063676629016

Epoch: 5| Step: 9
Training loss: 1.9808824062347412
Validation loss: 2.0017024727277857

Epoch: 5| Step: 10
Training loss: 2.0634069442749023
Validation loss: 1.9828569132794616

Epoch: 221| Step: 0
Training loss: 2.3028645515441895
Validation loss: 1.9761854038443616

Epoch: 5| Step: 1
Training loss: 1.7096054553985596
Validation loss: 1.9723460623013076

Epoch: 5| Step: 2
Training loss: 1.8448536396026611
Validation loss: 1.9737447077228176

Epoch: 5| Step: 3
Training loss: 1.9030773639678955
Validation loss: 1.9635886351267497

Epoch: 5| Step: 4
Training loss: 1.5979586839675903
Validation loss: 1.9685181853591756

Epoch: 5| Step: 5
Training loss: 1.6937898397445679
Validation loss: 1.965962113872651

Epoch: 5| Step: 6
Training loss: 1.5882351398468018
Validation loss: 1.9498561915530954

Epoch: 5| Step: 7
Training loss: 1.8404920101165771
Validation loss: 1.9398928797373207

Epoch: 5| Step: 8
Training loss: 1.5764822959899902
Validation loss: 1.9401911971389607

Epoch: 5| Step: 9
Training loss: 1.9164111614227295
Validation loss: 1.9301742635747439

Epoch: 5| Step: 10
Training loss: 2.083115577697754
Validation loss: 1.91048974503753

Epoch: 222| Step: 0
Training loss: 1.685106873512268
Validation loss: 1.926999238229567

Epoch: 5| Step: 1
Training loss: 1.6074132919311523
Validation loss: 1.9191955135714622

Epoch: 5| Step: 2
Training loss: 2.1040406227111816
Validation loss: 1.965002111209336

Epoch: 5| Step: 3
Training loss: 2.0345077514648438
Validation loss: 2.006069824259768

Epoch: 5| Step: 4
Training loss: 2.091346025466919
Validation loss: 2.0192908189629994

Epoch: 5| Step: 5
Training loss: 2.199178695678711
Validation loss: 2.0241345936252224

Epoch: 5| Step: 6
Training loss: 1.693563461303711
Validation loss: 2.0204043106366227

Epoch: 5| Step: 7
Training loss: 1.6437736749649048
Validation loss: 2.0233832277277464

Epoch: 5| Step: 8
Training loss: 1.31845223903656
Validation loss: 1.9864686701887397

Epoch: 5| Step: 9
Training loss: 1.792406678199768
Validation loss: 1.974613925462128

Epoch: 5| Step: 10
Training loss: 1.7308260202407837
Validation loss: 1.953134911034697

Epoch: 223| Step: 0
Training loss: 2.2781858444213867
Validation loss: 1.9478010874922558

Epoch: 5| Step: 1
Training loss: 1.367728590965271
Validation loss: 1.9520432936247958

Epoch: 5| Step: 2
Training loss: 1.526127815246582
Validation loss: 1.9282413092992639

Epoch: 5| Step: 3
Training loss: 1.8252416849136353
Validation loss: 1.928830401871794

Epoch: 5| Step: 4
Training loss: 1.5019807815551758
Validation loss: 1.907333985451729

Epoch: 5| Step: 5
Training loss: 1.8921029567718506
Validation loss: 1.8752180863452215

Epoch: 5| Step: 6
Training loss: 1.3601425886154175
Validation loss: 1.87147758981233

Epoch: 5| Step: 7
Training loss: 2.450751543045044
Validation loss: 1.900667094415234

Epoch: 5| Step: 8
Training loss: 1.650860071182251
Validation loss: 1.9263437922282884

Epoch: 5| Step: 9
Training loss: 2.3064448833465576
Validation loss: 1.9594434435649584

Epoch: 5| Step: 10
Training loss: 1.5043601989746094
Validation loss: 1.9927233278110463

Epoch: 224| Step: 0
Training loss: 2.4129185676574707
Validation loss: 1.999030129883879

Epoch: 5| Step: 1
Training loss: 2.1178455352783203
Validation loss: 1.9999249109657862

Epoch: 5| Step: 2
Training loss: 1.7869755029678345
Validation loss: 2.0073128079855316

Epoch: 5| Step: 3
Training loss: 1.3474500179290771
Validation loss: 2.0208157544494956

Epoch: 5| Step: 4
Training loss: 1.8600208759307861
Validation loss: 2.0295658342299925

Epoch: 5| Step: 5
Training loss: 1.6539013385772705
Validation loss: 2.016753613307912

Epoch: 5| Step: 6
Training loss: 1.905337929725647
Validation loss: 2.0186651060658116

Epoch: 5| Step: 7
Training loss: 1.7437164783477783
Validation loss: 2.0321475305864887

Epoch: 5| Step: 8
Training loss: 2.0256152153015137
Validation loss: 2.0042169376086165

Epoch: 5| Step: 9
Training loss: 1.4687817096710205
Validation loss: 1.9732865389957224

Epoch: 5| Step: 10
Training loss: 1.1349983215332031
Validation loss: 1.9756953331731981

Epoch: 225| Step: 0
Training loss: 2.5889973640441895
Validation loss: 1.9683092845383512

Epoch: 5| Step: 1
Training loss: 1.3894363641738892
Validation loss: 1.942252456500966

Epoch: 5| Step: 2
Training loss: 1.561417818069458
Validation loss: 1.9333347223138297

Epoch: 5| Step: 3
Training loss: 1.7778701782226562
Validation loss: 1.9419834152344735

Epoch: 5| Step: 4
Training loss: 2.1879782676696777
Validation loss: 1.9473574981894544

Epoch: 5| Step: 5
Training loss: 1.0162224769592285
Validation loss: 1.9255218582768594

Epoch: 5| Step: 6
Training loss: 1.8045406341552734
Validation loss: 1.9100962172272384

Epoch: 5| Step: 7
Training loss: 1.3296891450881958
Validation loss: 1.9033791301071004

Epoch: 5| Step: 8
Training loss: 1.5787159204483032
Validation loss: 1.9196374134350849

Epoch: 5| Step: 9
Training loss: 2.0917487144470215
Validation loss: 1.95161804076164

Epoch: 5| Step: 10
Training loss: 1.8336516618728638
Validation loss: 1.985347290192881

Epoch: 226| Step: 0
Training loss: 1.9947001934051514
Validation loss: 2.034269304685695

Epoch: 5| Step: 1
Training loss: 1.6960697174072266
Validation loss: 2.0559664516038794

Epoch: 5| Step: 2
Training loss: 1.6362091302871704
Validation loss: 2.0277184260788785

Epoch: 5| Step: 3
Training loss: 1.4443498849868774
Validation loss: 2.0085844685954433

Epoch: 5| Step: 4
Training loss: 1.2202680110931396
Validation loss: 2.0026086286831926

Epoch: 5| Step: 5
Training loss: 1.8698009252548218
Validation loss: 2.0538018749606226

Epoch: 5| Step: 6
Training loss: 2.2641055583953857
Validation loss: 2.0683484308181272

Epoch: 5| Step: 7
Training loss: 2.331940174102783
Validation loss: 2.0529417760910524

Epoch: 5| Step: 8
Training loss: 1.5317444801330566
Validation loss: 1.9862177987252512

Epoch: 5| Step: 9
Training loss: 2.124361515045166
Validation loss: 1.9769227274002568

Epoch: 5| Step: 10
Training loss: 2.420206069946289
Validation loss: 2.0106507988386255

Epoch: 227| Step: 0
Training loss: 1.6873620748519897
Validation loss: 2.0496604032413934

Epoch: 5| Step: 1
Training loss: 1.6522868871688843
Validation loss: 2.0426094147466842

Epoch: 5| Step: 2
Training loss: 1.4684251546859741
Validation loss: 1.984189461636287

Epoch: 5| Step: 3
Training loss: 1.7322051525115967
Validation loss: 1.9255181204888128

Epoch: 5| Step: 4
Training loss: 2.038104295730591
Validation loss: 1.9312295221513318

Epoch: 5| Step: 5
Training loss: 2.0737388134002686
Validation loss: 1.9244181417649793

Epoch: 5| Step: 6
Training loss: 1.4149138927459717
Validation loss: 1.937264834680865

Epoch: 5| Step: 7
Training loss: 2.0123648643493652
Validation loss: 1.9555820534306187

Epoch: 5| Step: 8
Training loss: 1.951452612876892
Validation loss: 1.9763650509618944

Epoch: 5| Step: 9
Training loss: 1.752554178237915
Validation loss: 1.97218910724886

Epoch: 5| Step: 10
Training loss: 1.9551645517349243
Validation loss: 1.9886284669240315

Epoch: 228| Step: 0
Training loss: 1.504373550415039
Validation loss: 1.9764637113899313

Epoch: 5| Step: 1
Training loss: 1.6470439434051514
Validation loss: 1.9799698809141755

Epoch: 5| Step: 2
Training loss: 1.6474195718765259
Validation loss: 1.9792055827315136

Epoch: 5| Step: 3
Training loss: 1.8975419998168945
Validation loss: 1.9703955522147558

Epoch: 5| Step: 4
Training loss: 1.8543736934661865
Validation loss: 1.9691007303935226

Epoch: 5| Step: 5
Training loss: 1.871506929397583
Validation loss: 1.9626537753689675

Epoch: 5| Step: 6
Training loss: 1.7336227893829346
Validation loss: 1.9663254419962566

Epoch: 5| Step: 7
Training loss: 1.3995040655136108
Validation loss: 1.958230851798929

Epoch: 5| Step: 8
Training loss: 1.718428373336792
Validation loss: 1.9689419026015906

Epoch: 5| Step: 9
Training loss: 1.8012440204620361
Validation loss: 1.9484144923507527

Epoch: 5| Step: 10
Training loss: 1.9094648361206055
Validation loss: 1.9612972697904032

Epoch: 229| Step: 0
Training loss: 1.848393201828003
Validation loss: 1.9377018046635452

Epoch: 5| Step: 1
Training loss: 1.7959922552108765
Validation loss: 1.936929698913328

Epoch: 5| Step: 2
Training loss: 0.9629814028739929
Validation loss: 1.9175981167824037

Epoch: 5| Step: 3
Training loss: 1.9607700109481812
Validation loss: 1.9175234584398166

Epoch: 5| Step: 4
Training loss: 1.8316805362701416
Validation loss: 1.9201542882509128

Epoch: 5| Step: 5
Training loss: 1.7769954204559326
Validation loss: 1.9303449738410212

Epoch: 5| Step: 6
Training loss: 1.671199083328247
Validation loss: 1.9363826590199624

Epoch: 5| Step: 7
Training loss: 1.3693344593048096
Validation loss: 1.9426196262400637

Epoch: 5| Step: 8
Training loss: 1.8648436069488525
Validation loss: 1.9586336651156027

Epoch: 5| Step: 9
Training loss: 1.6215541362762451
Validation loss: 1.945578085478916

Epoch: 5| Step: 10
Training loss: 2.139861822128296
Validation loss: 1.9464462739165111

Epoch: 230| Step: 0
Training loss: 1.4669463634490967
Validation loss: 1.9466862460618377

Epoch: 5| Step: 1
Training loss: 1.8601963520050049
Validation loss: 1.9608316088235507

Epoch: 5| Step: 2
Training loss: 1.6737830638885498
Validation loss: 1.964835492513513

Epoch: 5| Step: 3
Training loss: 1.7149988412857056
Validation loss: 1.938768756005072

Epoch: 5| Step: 4
Training loss: 1.7870547771453857
Validation loss: 1.9544338051990797

Epoch: 5| Step: 5
Training loss: 2.095892906188965
Validation loss: 1.9413941906344505

Epoch: 5| Step: 6
Training loss: 1.6785099506378174
Validation loss: 1.9639222263008036

Epoch: 5| Step: 7
Training loss: 1.3981989622116089
Validation loss: 1.9606849634519188

Epoch: 5| Step: 8
Training loss: 1.719541311264038
Validation loss: 1.9450391389990365

Epoch: 5| Step: 9
Training loss: 1.5458946228027344
Validation loss: 1.9176342756517473

Epoch: 5| Step: 10
Training loss: 1.5725748538970947
Validation loss: 1.9094714118588356

Epoch: 231| Step: 0
Training loss: 1.8143762350082397
Validation loss: 1.8962686164404756

Epoch: 5| Step: 1
Training loss: 1.2924448251724243
Validation loss: 1.910388401759568

Epoch: 5| Step: 2
Training loss: 2.408853769302368
Validation loss: 1.9108195048506542

Epoch: 5| Step: 3
Training loss: 2.359443426132202
Validation loss: 1.9165106204248243

Epoch: 5| Step: 4
Training loss: 2.0968806743621826
Validation loss: 1.9244247431396155

Epoch: 5| Step: 5
Training loss: 1.7190021276474
Validation loss: 1.9573818381114672

Epoch: 5| Step: 6
Training loss: 1.3297500610351562
Validation loss: 1.970119563482141

Epoch: 5| Step: 7
Training loss: 1.299809217453003
Validation loss: 1.9596185684204102

Epoch: 5| Step: 8
Training loss: 0.9144851565361023
Validation loss: 1.9741345887543054

Epoch: 5| Step: 9
Training loss: 1.4308749437332153
Validation loss: 1.966571500224452

Epoch: 5| Step: 10
Training loss: 1.7448914051055908
Validation loss: 1.9386932414065126

Epoch: 232| Step: 0
Training loss: 1.3006048202514648
Validation loss: 1.954729603182885

Epoch: 5| Step: 1
Training loss: 2.0519602298736572
Validation loss: 1.9533600268825408

Epoch: 5| Step: 2
Training loss: 1.7204501628875732
Validation loss: 1.963749885559082

Epoch: 5| Step: 3
Training loss: 1.8137643337249756
Validation loss: 1.9523364420860045

Epoch: 5| Step: 4
Training loss: 1.923632025718689
Validation loss: 1.9538690095306726

Epoch: 5| Step: 5
Training loss: 1.5755302906036377
Validation loss: 1.9702537700694094

Epoch: 5| Step: 6
Training loss: 1.5679895877838135
Validation loss: 1.967381920865787

Epoch: 5| Step: 7
Training loss: 1.7028051614761353
Validation loss: 1.973758118126982

Epoch: 5| Step: 8
Training loss: 1.7749319076538086
Validation loss: 1.95252856644251

Epoch: 5| Step: 9
Training loss: 1.450969934463501
Validation loss: 1.9281338132837766

Epoch: 5| Step: 10
Training loss: 1.4221410751342773
Validation loss: 1.936846347265346

Epoch: 233| Step: 0
Training loss: 2.0896811485290527
Validation loss: 1.9378999164027553

Epoch: 5| Step: 1
Training loss: 1.9688427448272705
Validation loss: 1.9335626068935599

Epoch: 5| Step: 2
Training loss: 1.5471696853637695
Validation loss: 1.95398800347441

Epoch: 5| Step: 3
Training loss: 1.5894728899002075
Validation loss: 1.9498680599274174

Epoch: 5| Step: 4
Training loss: 1.644518494606018
Validation loss: 1.9609023729960124

Epoch: 5| Step: 5
Training loss: 1.6628520488739014
Validation loss: 1.9801133114804503

Epoch: 5| Step: 6
Training loss: 1.8169082403182983
Validation loss: 1.9603989278116534

Epoch: 5| Step: 7
Training loss: 1.749869704246521
Validation loss: 1.9441768277075984

Epoch: 5| Step: 8
Training loss: 1.8368980884552002
Validation loss: 1.9295011156348771

Epoch: 5| Step: 9
Training loss: 1.3635808229446411
Validation loss: 1.9337986848687614

Epoch: 5| Step: 10
Training loss: 1.130565881729126
Validation loss: 1.9253058228441464

Epoch: 234| Step: 0
Training loss: 1.6721305847167969
Validation loss: 1.9198610359622585

Epoch: 5| Step: 1
Training loss: 1.7676788568496704
Validation loss: 1.9111373821894329

Epoch: 5| Step: 2
Training loss: 2.0184011459350586
Validation loss: 1.921087235532781

Epoch: 5| Step: 3
Training loss: 1.579074501991272
Validation loss: 1.9352548712043351

Epoch: 5| Step: 4
Training loss: 1.7988744974136353
Validation loss: 1.941889839787637

Epoch: 5| Step: 5
Training loss: 1.925061583518982
Validation loss: 1.9925475735818186

Epoch: 5| Step: 6
Training loss: 1.9305652379989624
Validation loss: 2.0071852437911497

Epoch: 5| Step: 7
Training loss: 1.4107186794281006
Validation loss: 1.9384768034822197

Epoch: 5| Step: 8
Training loss: 1.6969211101531982
Validation loss: 1.917670367866434

Epoch: 5| Step: 9
Training loss: 1.7453529834747314
Validation loss: 1.9235305427223124

Epoch: 5| Step: 10
Training loss: 0.9080071449279785
Validation loss: 1.911911520906674

Epoch: 235| Step: 0
Training loss: 1.5266810655593872
Validation loss: 1.9240938143063617

Epoch: 5| Step: 1
Training loss: 1.531853437423706
Validation loss: 1.9444711003252255

Epoch: 5| Step: 2
Training loss: 1.4952791929244995
Validation loss: 1.942356559538072

Epoch: 5| Step: 3
Training loss: 1.5540196895599365
Validation loss: 1.9729662838802542

Epoch: 5| Step: 4
Training loss: 1.787268877029419
Validation loss: 1.9394253402627923

Epoch: 5| Step: 5
Training loss: 1.3428351879119873
Validation loss: 1.915362294002246

Epoch: 5| Step: 6
Training loss: 1.7763248682022095
Validation loss: 1.9015561726785475

Epoch: 5| Step: 7
Training loss: 1.7349884510040283
Validation loss: 1.9123751681338075

Epoch: 5| Step: 8
Training loss: 1.5292491912841797
Validation loss: 1.9207009935891757

Epoch: 5| Step: 9
Training loss: 1.809117317199707
Validation loss: 1.9134029496100642

Epoch: 5| Step: 10
Training loss: 2.155081272125244
Validation loss: 1.9220855236053467

Epoch: 236| Step: 0
Training loss: 2.423299789428711
Validation loss: 1.9477429236135175

Epoch: 5| Step: 1
Training loss: 1.5905824899673462
Validation loss: 1.9669045812340193

Epoch: 5| Step: 2
Training loss: 1.5784528255462646
Validation loss: 1.9511553010632914

Epoch: 5| Step: 3
Training loss: 1.4634854793548584
Validation loss: 1.9391058311667493

Epoch: 5| Step: 4
Training loss: 1.8370946645736694
Validation loss: 1.9327977818827475

Epoch: 5| Step: 5
Training loss: 1.7487452030181885
Validation loss: 1.9568586605851368

Epoch: 5| Step: 6
Training loss: 1.4056739807128906
Validation loss: 1.9516086668096564

Epoch: 5| Step: 7
Training loss: 1.3941190242767334
Validation loss: 1.9510711457139702

Epoch: 5| Step: 8
Training loss: 1.4916435480117798
Validation loss: 1.958033541197418

Epoch: 5| Step: 9
Training loss: 1.6580047607421875
Validation loss: 1.9234884861976869

Epoch: 5| Step: 10
Training loss: 1.6004067659378052
Validation loss: 1.9277981660699333

Epoch: 237| Step: 0
Training loss: 1.2013789415359497
Validation loss: 1.9487194168952204

Epoch: 5| Step: 1
Training loss: 2.0106253623962402
Validation loss: 1.9526688693672098

Epoch: 5| Step: 2
Training loss: 2.0183300971984863
Validation loss: 1.92658221080739

Epoch: 5| Step: 3
Training loss: 1.5968679189682007
Validation loss: 1.9400501930585472

Epoch: 5| Step: 4
Training loss: 1.663190245628357
Validation loss: 1.939016334472164

Epoch: 5| Step: 5
Training loss: 1.7142603397369385
Validation loss: 1.9503744212529992

Epoch: 5| Step: 6
Training loss: 1.9688243865966797
Validation loss: 1.9351334905111661

Epoch: 5| Step: 7
Training loss: 1.6007881164550781
Validation loss: 1.947092943294074

Epoch: 5| Step: 8
Training loss: 1.3736412525177002
Validation loss: 1.9446827519324519

Epoch: 5| Step: 9
Training loss: 0.9266782999038696
Validation loss: 1.969856225034242

Epoch: 5| Step: 10
Training loss: 2.1326870918273926
Validation loss: 1.956272053462203

Epoch: 238| Step: 0
Training loss: 2.307152271270752
Validation loss: 1.9401800632476807

Epoch: 5| Step: 1
Training loss: 0.9711378216743469
Validation loss: 1.9300398877871934

Epoch: 5| Step: 2
Training loss: 1.6243116855621338
Validation loss: 1.8926526154241254

Epoch: 5| Step: 3
Training loss: 1.9567197561264038
Validation loss: 1.8893658627745926

Epoch: 5| Step: 4
Training loss: 1.422958493232727
Validation loss: 1.9218868106924079

Epoch: 5| Step: 5
Training loss: 1.4255456924438477
Validation loss: 1.8971356550852458

Epoch: 5| Step: 6
Training loss: 1.6597259044647217
Validation loss: 1.9115919349014119

Epoch: 5| Step: 7
Training loss: 1.8444902896881104
Validation loss: 1.951859857446404

Epoch: 5| Step: 8
Training loss: 1.4540315866470337
Validation loss: 1.9688573998789634

Epoch: 5| Step: 9
Training loss: 1.5658519268035889
Validation loss: 1.9633375034537366

Epoch: 5| Step: 10
Training loss: 2.0324714183807373
Validation loss: 1.9511703957793534

Epoch: 239| Step: 0
Training loss: 1.7181847095489502
Validation loss: 1.9736127802120742

Epoch: 5| Step: 1
Training loss: 1.7062444686889648
Validation loss: 1.960717531942552

Epoch: 5| Step: 2
Training loss: 1.1912345886230469
Validation loss: 1.9627495863104378

Epoch: 5| Step: 3
Training loss: 1.3158025741577148
Validation loss: 1.9412351308330413

Epoch: 5| Step: 4
Training loss: 2.1906704902648926
Validation loss: 1.9577588278760192

Epoch: 5| Step: 5
Training loss: 1.5268282890319824
Validation loss: 1.99745604812458

Epoch: 5| Step: 6
Training loss: 1.915693998336792
Validation loss: 2.007146830199867

Epoch: 5| Step: 7
Training loss: 1.9145511388778687
Validation loss: 1.9832004372791578

Epoch: 5| Step: 8
Training loss: 1.1482839584350586
Validation loss: 1.9522858678653676

Epoch: 5| Step: 9
Training loss: 1.9064905643463135
Validation loss: 1.94291841342885

Epoch: 5| Step: 10
Training loss: 1.5028882026672363
Validation loss: 1.9658605706307195

Epoch: 240| Step: 0
Training loss: 2.2560477256774902
Validation loss: 1.9406762661472443

Epoch: 5| Step: 1
Training loss: 1.7223495244979858
Validation loss: 1.9374307227391068

Epoch: 5| Step: 2
Training loss: 1.2371938228607178
Validation loss: 1.9556489888057913

Epoch: 5| Step: 3
Training loss: 1.388672113418579
Validation loss: 1.9611121172546058

Epoch: 5| Step: 4
Training loss: 1.5642331838607788
Validation loss: 1.9792055673496698

Epoch: 5| Step: 5
Training loss: 1.4225085973739624
Validation loss: 1.9857996279193508

Epoch: 5| Step: 6
Training loss: 1.291002631187439
Validation loss: 1.9461993658414452

Epoch: 5| Step: 7
Training loss: 1.7182945013046265
Validation loss: 1.919964623707597

Epoch: 5| Step: 8
Training loss: 2.0243782997131348
Validation loss: 1.9340837693983508

Epoch: 5| Step: 9
Training loss: 1.4355437755584717
Validation loss: 1.9059566528566423

Epoch: 5| Step: 10
Training loss: 2.0886495113372803
Validation loss: 1.9029868777080248

Epoch: 241| Step: 0
Training loss: 1.513976812362671
Validation loss: 1.886035147533622

Epoch: 5| Step: 1
Training loss: 0.7434861660003662
Validation loss: 1.901372968509633

Epoch: 5| Step: 2
Training loss: 2.0053505897521973
Validation loss: 1.9218862543823898

Epoch: 5| Step: 3
Training loss: 2.056790590286255
Validation loss: 1.9745124578475952

Epoch: 5| Step: 4
Training loss: 1.3571748733520508
Validation loss: 1.9665119750525362

Epoch: 5| Step: 5
Training loss: 1.6586517095565796
Validation loss: 1.9032587492337791

Epoch: 5| Step: 6
Training loss: 1.538455843925476
Validation loss: 1.864610456651257

Epoch: 5| Step: 7
Training loss: 1.9645493030548096
Validation loss: 1.8741391089654738

Epoch: 5| Step: 8
Training loss: 1.7551615238189697
Validation loss: 1.900114420921572

Epoch: 5| Step: 9
Training loss: 1.9606386423110962
Validation loss: 1.8855065902074177

Epoch: 5| Step: 10
Training loss: 1.830452799797058
Validation loss: 1.89129630596407

Epoch: 242| Step: 0
Training loss: 1.3603756427764893
Validation loss: 1.9166177780397478

Epoch: 5| Step: 1
Training loss: 1.2824623584747314
Validation loss: 1.9548092503701486

Epoch: 5| Step: 2
Training loss: 1.7828670740127563
Validation loss: 2.004262283284177

Epoch: 5| Step: 3
Training loss: 1.509678602218628
Validation loss: 1.97991015577829

Epoch: 5| Step: 4
Training loss: 1.3798909187316895
Validation loss: 1.927165888970898

Epoch: 5| Step: 5
Training loss: 1.582625150680542
Validation loss: 1.8991647202481505

Epoch: 5| Step: 6
Training loss: 2.03147554397583
Validation loss: 1.9286729097366333

Epoch: 5| Step: 7
Training loss: 2.0163209438323975
Validation loss: 1.9289935878528062

Epoch: 5| Step: 8
Training loss: 2.161886692047119
Validation loss: 1.9400051627107846

Epoch: 5| Step: 9
Training loss: 1.3775317668914795
Validation loss: 1.913331498381912

Epoch: 5| Step: 10
Training loss: 1.7077504396438599
Validation loss: 1.9322015162437194

Epoch: 243| Step: 0
Training loss: 1.671534776687622
Validation loss: 1.9852189005062144

Epoch: 5| Step: 1
Training loss: 1.57668137550354
Validation loss: 2.02297366434528

Epoch: 5| Step: 2
Training loss: 1.2715181112289429
Validation loss: 2.005625081318681

Epoch: 5| Step: 3
Training loss: 1.8666326999664307
Validation loss: 1.9755077272333124

Epoch: 5| Step: 4
Training loss: 1.1450707912445068
Validation loss: 1.9301467531470842

Epoch: 5| Step: 5
Training loss: 1.529149055480957
Validation loss: 1.9032597554627286

Epoch: 5| Step: 6
Training loss: 0.9864060282707214
Validation loss: 1.9001231578088575

Epoch: 5| Step: 7
Training loss: 1.9435144662857056
Validation loss: 1.8943264176768642

Epoch: 5| Step: 8
Training loss: 2.0983593463897705
Validation loss: 1.8857875677847094

Epoch: 5| Step: 9
Training loss: 2.186599016189575
Validation loss: 1.9061746828017696

Epoch: 5| Step: 10
Training loss: 1.6263562440872192
Validation loss: 1.8754624948706677

Epoch: 244| Step: 0
Training loss: 2.0640079975128174
Validation loss: 1.8895753455418411

Epoch: 5| Step: 1
Training loss: 1.3417840003967285
Validation loss: 1.874254447157665

Epoch: 5| Step: 2
Training loss: 1.7393182516098022
Validation loss: 1.899761357615071

Epoch: 5| Step: 3
Training loss: 1.979705572128296
Validation loss: 1.9460639594703593

Epoch: 5| Step: 4
Training loss: 1.4844146966934204
Validation loss: 1.9311476586967387

Epoch: 5| Step: 5
Training loss: 1.4701608419418335
Validation loss: 1.9395421679301927

Epoch: 5| Step: 6
Training loss: 1.2751379013061523
Validation loss: 1.89064662302694

Epoch: 5| Step: 7
Training loss: 1.672682523727417
Validation loss: 1.8758995379171064

Epoch: 5| Step: 8
Training loss: 1.6140434741973877
Validation loss: 1.8767602341149443

Epoch: 5| Step: 9
Training loss: 1.3922770023345947
Validation loss: 1.8677730432120703

Epoch: 5| Step: 10
Training loss: 1.3924667835235596
Validation loss: 1.8908539715633597

Epoch: 245| Step: 0
Training loss: 1.811171531677246
Validation loss: 1.8951167124573902

Epoch: 5| Step: 1
Training loss: 1.378556251525879
Validation loss: 1.8907631635665894

Epoch: 5| Step: 2
Training loss: 1.8382608890533447
Validation loss: 1.9135430846163022

Epoch: 5| Step: 3
Training loss: 1.5966229438781738
Validation loss: 1.9117888968477967

Epoch: 5| Step: 4
Training loss: 0.9938188791275024
Validation loss: 1.8789267847614903

Epoch: 5| Step: 5
Training loss: 1.8402007818222046
Validation loss: 1.8594914328667425

Epoch: 5| Step: 6
Training loss: 1.7578357458114624
Validation loss: 1.8663480281829834

Epoch: 5| Step: 7
Training loss: 1.4115139245986938
Validation loss: 1.886205957781884

Epoch: 5| Step: 8
Training loss: 1.5999946594238281
Validation loss: 1.9093782427490398

Epoch: 5| Step: 9
Training loss: 1.616480827331543
Validation loss: 1.945576988240724

Epoch: 5| Step: 10
Training loss: 1.5181525945663452
Validation loss: 1.972885299754399

Epoch: 246| Step: 0
Training loss: 1.9496681690216064
Validation loss: 1.9509537348183252

Epoch: 5| Step: 1
Training loss: 1.173949122428894
Validation loss: 1.945844824596118

Epoch: 5| Step: 2
Training loss: 1.492527961730957
Validation loss: 1.9339849692518993

Epoch: 5| Step: 3
Training loss: 1.333599328994751
Validation loss: 1.9106255449274534

Epoch: 5| Step: 4
Training loss: 1.7083187103271484
Validation loss: 1.9135185236571937

Epoch: 5| Step: 5
Training loss: 1.7923762798309326
Validation loss: 1.907574776680239

Epoch: 5| Step: 6
Training loss: 1.180908203125
Validation loss: 1.9206280708312988

Epoch: 5| Step: 7
Training loss: 2.0536484718322754
Validation loss: 1.8919454518184866

Epoch: 5| Step: 8
Training loss: 1.6543235778808594
Validation loss: 1.9362251656029814

Epoch: 5| Step: 9
Training loss: 1.5251729488372803
Validation loss: 1.9150668113462386

Epoch: 5| Step: 10
Training loss: 1.3333520889282227
Validation loss: 1.9031778804717525

Epoch: 247| Step: 0
Training loss: 1.6267967224121094
Validation loss: 1.883711696952902

Epoch: 5| Step: 1
Training loss: 1.5155278444290161
Validation loss: 1.8733838617160756

Epoch: 5| Step: 2
Training loss: 1.2630006074905396
Validation loss: 1.8588961965294295

Epoch: 5| Step: 3
Training loss: 1.4779919385910034
Validation loss: 1.8580898072129937

Epoch: 5| Step: 4
Training loss: 1.595583200454712
Validation loss: 1.8621475465836064

Epoch: 5| Step: 5
Training loss: 2.0916013717651367
Validation loss: 1.870890712225309

Epoch: 5| Step: 6
Training loss: 1.1781556606292725
Validation loss: 1.8953326363717355

Epoch: 5| Step: 7
Training loss: 1.3714711666107178
Validation loss: 1.8887369068720008

Epoch: 5| Step: 8
Training loss: 1.6250295639038086
Validation loss: 1.894578855524781

Epoch: 5| Step: 9
Training loss: 1.5376287698745728
Validation loss: 1.8750918654985325

Epoch: 5| Step: 10
Training loss: 1.8311525583267212
Validation loss: 1.8910668562817317

Epoch: 248| Step: 0
Training loss: 1.0739402770996094
Validation loss: 1.9118884404500325

Epoch: 5| Step: 1
Training loss: 1.765162706375122
Validation loss: 1.916930098687449

Epoch: 5| Step: 2
Training loss: 1.7061723470687866
Validation loss: 1.9286740197930285

Epoch: 5| Step: 3
Training loss: 1.4965916872024536
Validation loss: 1.9243032252916725

Epoch: 5| Step: 4
Training loss: 1.767921805381775
Validation loss: 1.923159744149895

Epoch: 5| Step: 5
Training loss: 1.246688723564148
Validation loss: 1.942519800637358

Epoch: 5| Step: 6
Training loss: 1.2635765075683594
Validation loss: 1.9277460267466884

Epoch: 5| Step: 7
Training loss: 1.024023175239563
Validation loss: 1.9423631416854037

Epoch: 5| Step: 8
Training loss: 1.9677200317382812
Validation loss: 1.9302186889033164

Epoch: 5| Step: 9
Training loss: 1.7317718267440796
Validation loss: 1.9241093794504802

Epoch: 5| Step: 10
Training loss: 1.9976074695587158
Validation loss: 1.9235347676020798

Epoch: 249| Step: 0
Training loss: 1.5356577634811401
Validation loss: 1.9011775473112702

Epoch: 5| Step: 1
Training loss: 0.997908890247345
Validation loss: 1.8983305526036087

Epoch: 5| Step: 2
Training loss: 1.5988961458206177
Validation loss: 1.9043453739535423

Epoch: 5| Step: 3
Training loss: 1.5607779026031494
Validation loss: 1.916360475683725

Epoch: 5| Step: 4
Training loss: 2.1284496784210205
Validation loss: 1.897292552455779

Epoch: 5| Step: 5
Training loss: 1.834436058998108
Validation loss: 1.8945306270353255

Epoch: 5| Step: 6
Training loss: 1.9799699783325195
Validation loss: 1.888752184888368

Epoch: 5| Step: 7
Training loss: 1.2172178030014038
Validation loss: 1.8655160037420129

Epoch: 5| Step: 8
Training loss: 1.1411325931549072
Validation loss: 1.8767557785075197

Epoch: 5| Step: 9
Training loss: 1.1717149019241333
Validation loss: 1.872106139377881

Epoch: 5| Step: 10
Training loss: 1.7692009210586548
Validation loss: 1.8683407588671612

Epoch: 250| Step: 0
Training loss: 1.4473341703414917
Validation loss: 1.9257758830183296

Epoch: 5| Step: 1
Training loss: 1.2514793872833252
Validation loss: 1.9670618080323743

Epoch: 5| Step: 2
Training loss: 1.788295030593872
Validation loss: 1.951859240890831

Epoch: 5| Step: 3
Training loss: 1.9150307178497314
Validation loss: 1.9465884329170309

Epoch: 5| Step: 4
Training loss: 1.2259525060653687
Validation loss: 1.9069356585061679

Epoch: 5| Step: 5
Training loss: 1.4708855152130127
Validation loss: 1.9021272069664412

Epoch: 5| Step: 6
Training loss: 2.162236452102661
Validation loss: 1.9085449608423377

Epoch: 5| Step: 7
Training loss: 1.7654603719711304
Validation loss: 1.8996865890359367

Epoch: 5| Step: 8
Training loss: 1.6813745498657227
Validation loss: 1.8866521748163367

Epoch: 5| Step: 9
Training loss: 1.1397202014923096
Validation loss: 1.8885862263300086

Epoch: 5| Step: 10
Training loss: 1.7181050777435303
Validation loss: 1.9282016279876872

Testing loss: 2.282410052087572
