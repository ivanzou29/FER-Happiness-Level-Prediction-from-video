Epoch: 1| Step: 0
Training loss: 6.742208434389574
Validation loss: 5.839099204889629

Epoch: 6| Step: 1
Training loss: 6.029958952452472
Validation loss: 5.820413450048486

Epoch: 6| Step: 2
Training loss: 5.611208135355634
Validation loss: 5.80170441542668

Epoch: 6| Step: 3
Training loss: 5.3643619034878505
Validation loss: 5.782475475918989

Epoch: 6| Step: 4
Training loss: 4.474284126519484
Validation loss: 5.761175729320486

Epoch: 6| Step: 5
Training loss: 6.191271008479555
Validation loss: 5.738123298132577

Epoch: 6| Step: 6
Training loss: 6.640696805677956
Validation loss: 5.711963123174114

Epoch: 6| Step: 7
Training loss: 5.638259856786178
Validation loss: 5.682859994338295

Epoch: 6| Step: 8
Training loss: 5.163743740753023
Validation loss: 5.6517422442896725

Epoch: 6| Step: 9
Training loss: 5.955648212914051
Validation loss: 5.616274268921767

Epoch: 6| Step: 10
Training loss: 4.636412278598471
Validation loss: 5.5774992520624025

Epoch: 6| Step: 11
Training loss: 4.816586827515122
Validation loss: 5.534146148062862

Epoch: 6| Step: 12
Training loss: 6.118012159551812
Validation loss: 5.487311586095209

Epoch: 6| Step: 13
Training loss: 6.294275850150135
Validation loss: 5.4364762710380266

Epoch: 2| Step: 0
Training loss: 6.9211463975308805
Validation loss: 5.383978792186784

Epoch: 6| Step: 1
Training loss: 4.3502837516054536
Validation loss: 5.328608863470242

Epoch: 6| Step: 2
Training loss: 4.5865336717870635
Validation loss: 5.271304566891246

Epoch: 6| Step: 3
Training loss: 4.84123588041871
Validation loss: 5.216478715771461

Epoch: 6| Step: 4
Training loss: 4.348476555306557
Validation loss: 5.162301357326656

Epoch: 6| Step: 5
Training loss: 3.884365699861277
Validation loss: 5.111170295496317

Epoch: 6| Step: 6
Training loss: 6.797312194092959
Validation loss: 5.060862343288947

Epoch: 6| Step: 7
Training loss: 5.51764311355532
Validation loss: 5.015483588547426

Epoch: 6| Step: 8
Training loss: 4.443472912354384
Validation loss: 4.970591218346537

Epoch: 6| Step: 9
Training loss: 5.402393884212422
Validation loss: 4.930269354328853

Epoch: 6| Step: 10
Training loss: 4.064895393179893
Validation loss: 4.893273815275786

Epoch: 6| Step: 11
Training loss: 5.270497046235761
Validation loss: 4.8611421679995495

Epoch: 6| Step: 12
Training loss: 4.8519882531334435
Validation loss: 4.834219709484855

Epoch: 6| Step: 13
Training loss: 5.6466179709528515
Validation loss: 4.81124750828591

Epoch: 3| Step: 0
Training loss: 4.010644102046609
Validation loss: 4.788189791939475

Epoch: 6| Step: 1
Training loss: 5.4577463237202615
Validation loss: 4.7653931565208385

Epoch: 6| Step: 2
Training loss: 5.351801110955599
Validation loss: 4.742510356563644

Epoch: 6| Step: 3
Training loss: 5.463840918865585
Validation loss: 4.719450300700967

Epoch: 6| Step: 4
Training loss: 5.1624594550584195
Validation loss: 4.684122891799554

Epoch: 6| Step: 5
Training loss: 4.987104188897398
Validation loss: 4.6533752010511815

Epoch: 6| Step: 6
Training loss: 3.9224040977760057
Validation loss: 4.630061492128857

Epoch: 6| Step: 7
Training loss: 4.182036522303093
Validation loss: 4.614125299894339

Epoch: 6| Step: 8
Training loss: 2.8988928424338254
Validation loss: 4.603950440101255

Epoch: 6| Step: 9
Training loss: 4.3092767583922855
Validation loss: 4.589911755869877

Epoch: 6| Step: 10
Training loss: 4.532854729987917
Validation loss: 4.572168214641871

Epoch: 6| Step: 11
Training loss: 5.3796705313843445
Validation loss: 4.552604227423043

Epoch: 6| Step: 12
Training loss: 5.550380576891989
Validation loss: 4.529416906641444

Epoch: 6| Step: 13
Training loss: 4.005030330014486
Validation loss: 4.511357426044123

Epoch: 4| Step: 0
Training loss: 5.003950846917777
Validation loss: 4.489961232748087

Epoch: 6| Step: 1
Training loss: 4.372358778280979
Validation loss: 4.470713958249011

Epoch: 6| Step: 2
Training loss: 5.006369158104184
Validation loss: 4.45482832307509

Epoch: 6| Step: 3
Training loss: 4.723557404394732
Validation loss: 4.435028855522794

Epoch: 6| Step: 4
Training loss: 3.6300836630183464
Validation loss: 4.425836134902257

Epoch: 6| Step: 5
Training loss: 4.280716688811938
Validation loss: 4.401553086474796

Epoch: 6| Step: 6
Training loss: 3.7134328062019324
Validation loss: 4.392062081671484

Epoch: 6| Step: 7
Training loss: 4.958602043158143
Validation loss: 4.380436165302758

Epoch: 6| Step: 8
Training loss: 4.646028910855262
Validation loss: 4.36614458970561

Epoch: 6| Step: 9
Training loss: 4.671294823794635
Validation loss: 4.350535212240717

Epoch: 6| Step: 10
Training loss: 4.423634748463913
Validation loss: 4.345793045217908

Epoch: 6| Step: 11
Training loss: 4.504367192710059
Validation loss: 4.318485922628945

Epoch: 6| Step: 12
Training loss: 4.513148912599695
Validation loss: 4.310137964573983

Epoch: 6| Step: 13
Training loss: 4.43041706300579
Validation loss: 4.303475287818935

Epoch: 5| Step: 0
Training loss: 4.752553554596375
Validation loss: 4.283023221199332

Epoch: 6| Step: 1
Training loss: 3.36503741307312
Validation loss: 4.265238325516596

Epoch: 6| Step: 2
Training loss: 4.474932468693269
Validation loss: 4.266484290565451

Epoch: 6| Step: 3
Training loss: 4.454339326962157
Validation loss: 4.245464846481294

Epoch: 6| Step: 4
Training loss: 4.401320926752394
Validation loss: 4.235235202463181

Epoch: 6| Step: 5
Training loss: 3.4753660050444406
Validation loss: 4.226952153292287

Epoch: 6| Step: 6
Training loss: 4.745951483207243
Validation loss: 4.219470289474159

Epoch: 6| Step: 7
Training loss: 5.138762812170464
Validation loss: 4.210628634490353

Epoch: 6| Step: 8
Training loss: 4.167866470526341
Validation loss: 4.194734644592091

Epoch: 6| Step: 9
Training loss: 4.394824208985026
Validation loss: 4.181951758980614

Epoch: 6| Step: 10
Training loss: 4.179875506869754
Validation loss: 4.176215846173085

Epoch: 6| Step: 11
Training loss: 5.005294857276279
Validation loss: 4.1599718777768535

Epoch: 6| Step: 12
Training loss: 4.700839986207543
Validation loss: 4.1538873631643325

Epoch: 6| Step: 13
Training loss: 1.2266142524443542
Validation loss: 4.1519222372605435

Epoch: 6| Step: 0
Training loss: 3.888753540469072
Validation loss: 4.141736039979817

Epoch: 6| Step: 1
Training loss: 4.581505058234992
Validation loss: 4.124779002663844

Epoch: 6| Step: 2
Training loss: 4.7386306420028275
Validation loss: 4.1115091640734835

Epoch: 6| Step: 3
Training loss: 4.19634076522285
Validation loss: 4.110647259670096

Epoch: 6| Step: 4
Training loss: 5.016631693839577
Validation loss: 4.097516172744866

Epoch: 6| Step: 5
Training loss: 4.583309427834793
Validation loss: 4.087287745139596

Epoch: 6| Step: 6
Training loss: 3.972713863889009
Validation loss: 4.0808008618546445

Epoch: 6| Step: 7
Training loss: 3.941645786049978
Validation loss: 4.075433226425533

Epoch: 6| Step: 8
Training loss: 5.212516854165179
Validation loss: 4.0596495555521

Epoch: 6| Step: 9
Training loss: 4.635262110273012
Validation loss: 4.065569804610336

Epoch: 6| Step: 10
Training loss: 2.3722376570049333
Validation loss: 4.043936893695974

Epoch: 6| Step: 11
Training loss: 2.750855399521601
Validation loss: 4.043663918424875

Epoch: 6| Step: 12
Training loss: 4.043413839856944
Validation loss: 4.043262145632236

Epoch: 6| Step: 13
Training loss: 4.345054595217971
Validation loss: 4.039774661292462

Epoch: 7| Step: 0
Training loss: 4.166081094920396
Validation loss: 4.026818587946831

Epoch: 6| Step: 1
Training loss: 3.3645619646620113
Validation loss: 4.018512705006958

Epoch: 6| Step: 2
Training loss: 3.6837508976122666
Validation loss: 4.009021464669295

Epoch: 6| Step: 3
Training loss: 3.7916020957283405
Validation loss: 3.999430736416587

Epoch: 6| Step: 4
Training loss: 4.466027771155748
Validation loss: 3.990887388325808

Epoch: 6| Step: 5
Training loss: 4.775384633815261
Validation loss: 3.979629841843345

Epoch: 6| Step: 6
Training loss: 3.4004540084198913
Validation loss: 3.9684970120402197

Epoch: 6| Step: 7
Training loss: 3.0831923237766903
Validation loss: 3.965018105170144

Epoch: 6| Step: 8
Training loss: 5.851387133345165
Validation loss: 3.955416545884878

Epoch: 6| Step: 9
Training loss: 4.614768386930665
Validation loss: 3.953660588783478

Epoch: 6| Step: 10
Training loss: 3.524119782627936
Validation loss: 3.9438621737891504

Epoch: 6| Step: 11
Training loss: 4.748150113928006
Validation loss: 3.937953630507317

Epoch: 6| Step: 12
Training loss: 3.4600933759140005
Validation loss: 3.925980235304358

Epoch: 6| Step: 13
Training loss: 3.752077163163103
Validation loss: 3.9159820436544477

Epoch: 8| Step: 0
Training loss: 2.992732464039905
Validation loss: 3.9090980185423025

Epoch: 6| Step: 1
Training loss: 3.8048070618566325
Validation loss: 3.8993542978865228

Epoch: 6| Step: 2
Training loss: 3.2559434391329662
Validation loss: 3.8922047563050124

Epoch: 6| Step: 3
Training loss: 4.5042505322934705
Validation loss: 3.8878758731789085

Epoch: 6| Step: 4
Training loss: 4.029809738855182
Validation loss: 3.8836094934243732

Epoch: 6| Step: 5
Training loss: 3.9627571816723766
Validation loss: 3.862731393451923

Epoch: 6| Step: 6
Training loss: 5.088645202562131
Validation loss: 3.857905980100831

Epoch: 6| Step: 7
Training loss: 3.4911097286466335
Validation loss: 3.8483062639827574

Epoch: 6| Step: 8
Training loss: 4.628327487222516
Validation loss: 3.8435854112475916

Epoch: 6| Step: 9
Training loss: 4.055121190980013
Validation loss: 3.831480532599559

Epoch: 6| Step: 10
Training loss: 3.560982631984864
Validation loss: 3.8236486290743805

Epoch: 6| Step: 11
Training loss: 3.7537453068142725
Validation loss: 3.82217589068713

Epoch: 6| Step: 12
Training loss: 4.578159162895146
Validation loss: 3.8336251929319114

Epoch: 6| Step: 13
Training loss: 4.156940144768445
Validation loss: 3.80227332602011

Epoch: 9| Step: 0
Training loss: 3.359943714351602
Validation loss: 3.8063587315912204

Epoch: 6| Step: 1
Training loss: 3.040087529478329
Validation loss: 3.8067020687905733

Epoch: 6| Step: 2
Training loss: 4.366472270996781
Validation loss: 3.8165937286069367

Epoch: 6| Step: 3
Training loss: 4.4153294728295975
Validation loss: 3.813976497515421

Epoch: 6| Step: 4
Training loss: 3.5857114367400453
Validation loss: 3.7956101997230274

Epoch: 6| Step: 5
Training loss: 4.555226210704412
Validation loss: 3.784553204391651

Epoch: 6| Step: 6
Training loss: 4.740989169150458
Validation loss: 3.7750112413199477

Epoch: 6| Step: 7
Training loss: 3.6121169735290333
Validation loss: 3.768957222148931

Epoch: 6| Step: 8
Training loss: 4.316913281518563
Validation loss: 3.761962341620877

Epoch: 6| Step: 9
Training loss: 4.0511268460941245
Validation loss: 3.751460974162202

Epoch: 6| Step: 10
Training loss: 3.9639384020610704
Validation loss: 3.737185516554321

Epoch: 6| Step: 11
Training loss: 3.7063624398735704
Validation loss: 3.7317167330464787

Epoch: 6| Step: 12
Training loss: 3.619576705294791
Validation loss: 3.7272663665508756

Epoch: 6| Step: 13
Training loss: 3.3306829087915313
Validation loss: 3.7209364131291354

Epoch: 10| Step: 0
Training loss: 3.877576156252019
Validation loss: 3.7129088506088217

Epoch: 6| Step: 1
Training loss: 4.395737030758221
Validation loss: 3.7084746412781313

Epoch: 6| Step: 2
Training loss: 4.969255913463916
Validation loss: 3.7003552565323554

Epoch: 6| Step: 3
Training loss: 3.5946041253174212
Validation loss: 3.690728197112588

Epoch: 6| Step: 4
Training loss: 3.332974192027547
Validation loss: 3.685266480530799

Epoch: 6| Step: 5
Training loss: 4.545258014938567
Validation loss: 3.6755388254550363

Epoch: 6| Step: 6
Training loss: 3.2902289200191484
Validation loss: 3.672290350698763

Epoch: 6| Step: 7
Training loss: 4.103948106448814
Validation loss: 3.6681525393068473

Epoch: 6| Step: 8
Training loss: 3.112256425878948
Validation loss: 3.6652215144799545

Epoch: 6| Step: 9
Training loss: 2.397159894700497
Validation loss: 3.660948160990085

Epoch: 6| Step: 10
Training loss: 4.794639837046385
Validation loss: 3.6579259525408174

Epoch: 6| Step: 11
Training loss: 3.663623645260431
Validation loss: 3.649807430137173

Epoch: 6| Step: 12
Training loss: 3.605002789542591
Validation loss: 3.6451646496884966

Epoch: 6| Step: 13
Training loss: 3.4690117264717393
Validation loss: 3.6344673451497003

Epoch: 11| Step: 0
Training loss: 4.218862574452875
Validation loss: 3.6302606037431677

Epoch: 6| Step: 1
Training loss: 3.971744639060431
Validation loss: 3.6238349793504887

Epoch: 6| Step: 2
Training loss: 3.6305110737661
Validation loss: 3.6208347071659635

Epoch: 6| Step: 3
Training loss: 3.1086503147636244
Validation loss: 3.615480254539134

Epoch: 6| Step: 4
Training loss: 3.6053882064998035
Validation loss: 3.612437629693535

Epoch: 6| Step: 5
Training loss: 4.113252500196298
Validation loss: 3.611934412669003

Epoch: 6| Step: 6
Training loss: 3.4494050991917544
Validation loss: 3.6114164709743397

Epoch: 6| Step: 7
Training loss: 3.472955577123587
Validation loss: 3.607259814493827

Epoch: 6| Step: 8
Training loss: 3.915842104751322
Validation loss: 3.5921244507671615

Epoch: 6| Step: 9
Training loss: 4.698645603555614
Validation loss: 3.582096848540433

Epoch: 6| Step: 10
Training loss: 4.158124228643256
Validation loss: 3.5791622065905355

Epoch: 6| Step: 11
Training loss: 3.3569412286844993
Validation loss: 3.5738826524425917

Epoch: 6| Step: 12
Training loss: 3.1436851358263174
Validation loss: 3.5698988067104

Epoch: 6| Step: 13
Training loss: 4.145013750557357
Validation loss: 3.56395176608057

Epoch: 12| Step: 0
Training loss: 3.618766160049329
Validation loss: 3.5599510920189466

Epoch: 6| Step: 1
Training loss: 3.648848647286657
Validation loss: 3.55733596273792

Epoch: 6| Step: 2
Training loss: 4.334022442726574
Validation loss: 3.548717834444549

Epoch: 6| Step: 3
Training loss: 4.096347829042234
Validation loss: 3.54476213390495

Epoch: 6| Step: 4
Training loss: 2.4806604987094016
Validation loss: 3.5380197048258673

Epoch: 6| Step: 5
Training loss: 3.0495199607424768
Validation loss: 3.537302837778683

Epoch: 6| Step: 6
Training loss: 3.9359750368055493
Validation loss: 3.5334095857471706

Epoch: 6| Step: 7
Training loss: 2.817948721869238
Validation loss: 3.524268603805129

Epoch: 6| Step: 8
Training loss: 3.4049087823645356
Validation loss: 3.521563574685707

Epoch: 6| Step: 9
Training loss: 4.62325191969768
Validation loss: 3.5191611998580474

Epoch: 6| Step: 10
Training loss: 4.004318766859239
Validation loss: 3.504855754659403

Epoch: 6| Step: 11
Training loss: 3.2130203360024705
Validation loss: 3.502041928637304

Epoch: 6| Step: 12
Training loss: 3.9492209233580815
Validation loss: 3.510364411704776

Epoch: 6| Step: 13
Training loss: 4.921697510440614
Validation loss: 3.4885027624631664

Epoch: 13| Step: 0
Training loss: 4.439744838221632
Validation loss: 3.4754149669230747

Epoch: 6| Step: 1
Training loss: 3.207610771425036
Validation loss: 3.4827931523166926

Epoch: 6| Step: 2
Training loss: 3.5484067323426673
Validation loss: 3.4791149695327466

Epoch: 6| Step: 3
Training loss: 3.3592072201016427
Validation loss: 3.468322798550275

Epoch: 6| Step: 4
Training loss: 3.611718279990979
Validation loss: 3.449496893620057

Epoch: 6| Step: 5
Training loss: 3.7718407706008867
Validation loss: 3.455702986105208

Epoch: 6| Step: 6
Training loss: 4.151806284301242
Validation loss: 3.439785542264764

Epoch: 6| Step: 7
Training loss: 4.405254928018918
Validation loss: 3.4282872969909906

Epoch: 6| Step: 8
Training loss: 1.5673399161770227
Validation loss: 3.433142769380785

Epoch: 6| Step: 9
Training loss: 3.533992006578888
Validation loss: 3.4351068752320697

Epoch: 6| Step: 10
Training loss: 3.541013201098867
Validation loss: 3.4245760552065914

Epoch: 6| Step: 11
Training loss: 4.305473685084384
Validation loss: 3.41801950537152

Epoch: 6| Step: 12
Training loss: 3.4330501538376406
Validation loss: 3.4098804939693976

Epoch: 6| Step: 13
Training loss: 3.3660573810892833
Validation loss: 3.410062915429817

Epoch: 14| Step: 0
Training loss: 3.830572474750212
Validation loss: 3.4114538735507174

Epoch: 6| Step: 1
Training loss: 3.2578196719888832
Validation loss: 3.4088438765540667

Epoch: 6| Step: 2
Training loss: 3.1009442460289383
Validation loss: 3.409743179002813

Epoch: 6| Step: 3
Training loss: 4.719447608564001
Validation loss: 3.4128743521645672

Epoch: 6| Step: 4
Training loss: 3.8393534505451425
Validation loss: 3.398086874128771

Epoch: 6| Step: 5
Training loss: 3.139476812960824
Validation loss: 3.397044714592986

Epoch: 6| Step: 6
Training loss: 3.789657451680062
Validation loss: 3.399053948202156

Epoch: 6| Step: 7
Training loss: 3.219445903325365
Validation loss: 3.3946732281400736

Epoch: 6| Step: 8
Training loss: 4.071672852915247
Validation loss: 3.3909389531394134

Epoch: 6| Step: 9
Training loss: 3.6721939273064126
Validation loss: 3.3841803149222174

Epoch: 6| Step: 10
Training loss: 2.689381317975218
Validation loss: 3.3820982182279735

Epoch: 6| Step: 11
Training loss: 3.9656446427865077
Validation loss: 3.3830725529098205

Epoch: 6| Step: 12
Training loss: 3.191598837374915
Validation loss: 3.395592589947724

Epoch: 6| Step: 13
Training loss: 3.8901412234131225
Validation loss: 3.3770692468321704

Epoch: 15| Step: 0
Training loss: 3.712781331612411
Validation loss: 3.375271987134086

Epoch: 6| Step: 1
Training loss: 2.671076962155218
Validation loss: 3.3771548834040446

Epoch: 6| Step: 2
Training loss: 3.7898240415445597
Validation loss: 3.375760142088661

Epoch: 6| Step: 3
Training loss: 4.022659493195187
Validation loss: 3.374814159422271

Epoch: 6| Step: 4
Training loss: 3.6645983729108993
Validation loss: 3.3736210082965665

Epoch: 6| Step: 5
Training loss: 3.064186410377793
Validation loss: 3.373343142676335

Epoch: 6| Step: 6
Training loss: 4.226310454519805
Validation loss: 3.372935869760591

Epoch: 6| Step: 7
Training loss: 4.400753190858422
Validation loss: 3.3682440207129565

Epoch: 6| Step: 8
Training loss: 3.0469030134429347
Validation loss: 3.369117243422451

Epoch: 6| Step: 9
Training loss: 3.4047284008718837
Validation loss: 3.368027445955614

Epoch: 6| Step: 10
Training loss: 3.334491210742875
Validation loss: 3.365723522673394

Epoch: 6| Step: 11
Training loss: 3.2392043763963754
Validation loss: 3.3617805135107264

Epoch: 6| Step: 12
Training loss: 3.906373533202912
Validation loss: 3.3595297806137445

Epoch: 6| Step: 13
Training loss: 3.5314892713115626
Validation loss: 3.3595808671514193

Epoch: 16| Step: 0
Training loss: 3.3593094220525175
Validation loss: 3.358027215631306

Epoch: 6| Step: 1
Training loss: 3.7857828005531258
Validation loss: 3.357145129041978

Epoch: 6| Step: 2
Training loss: 4.043023710752635
Validation loss: 3.3541411929627216

Epoch: 6| Step: 3
Training loss: 4.323290607257936
Validation loss: 3.3511608145145817

Epoch: 6| Step: 4
Training loss: 3.3126571905878692
Validation loss: 3.3523829940437566

Epoch: 6| Step: 5
Training loss: 3.7896940668476518
Validation loss: 3.3499736427931803

Epoch: 6| Step: 6
Training loss: 3.723976245472474
Validation loss: 3.347689252824658

Epoch: 6| Step: 7
Training loss: 3.1259745794764875
Validation loss: 3.347298923201906

Epoch: 6| Step: 8
Training loss: 3.1436883211247224
Validation loss: 3.3464949906882477

Epoch: 6| Step: 9
Training loss: 3.487339007855831
Validation loss: 3.342457635501072

Epoch: 6| Step: 10
Training loss: 3.788281547057049
Validation loss: 3.3407273153386714

Epoch: 6| Step: 11
Training loss: 3.3840359420220367
Validation loss: 3.3382908131729425

Epoch: 6| Step: 12
Training loss: 3.3175189305033435
Validation loss: 3.3370039900024318

Epoch: 6| Step: 13
Training loss: 3.2251881034464183
Validation loss: 3.3341707982396063

Epoch: 17| Step: 0
Training loss: 3.757611370453941
Validation loss: 3.3336089656039465

Epoch: 6| Step: 1
Training loss: 2.91640445802165
Validation loss: 3.3306190011778063

Epoch: 6| Step: 2
Training loss: 4.521924123121545
Validation loss: 3.329665556984751

Epoch: 6| Step: 3
Training loss: 3.1510598594623747
Validation loss: 3.329330026675072

Epoch: 6| Step: 4
Training loss: 2.9596756231572954
Validation loss: 3.3261938196673633

Epoch: 6| Step: 5
Training loss: 3.4784871121094194
Validation loss: 3.329613768919411

Epoch: 6| Step: 6
Training loss: 2.8728701124137674
Validation loss: 3.323732820871938

Epoch: 6| Step: 7
Training loss: 3.4155242374561463
Validation loss: 3.323259121834806

Epoch: 6| Step: 8
Training loss: 3.7070044947664615
Validation loss: 3.3219301066475

Epoch: 6| Step: 9
Training loss: 3.598476055566488
Validation loss: 3.3195159408300534

Epoch: 6| Step: 10
Training loss: 3.955900522136526
Validation loss: 3.3194856389833785

Epoch: 6| Step: 11
Training loss: 3.6726400674034565
Validation loss: 3.3167800324531007

Epoch: 6| Step: 12
Training loss: 3.9332632856004617
Validation loss: 3.313964708759039

Epoch: 6| Step: 13
Training loss: 3.594613411057046
Validation loss: 3.3126426754278824

Epoch: 18| Step: 0
Training loss: 3.768374377205288
Validation loss: 3.3092149065529823

Epoch: 6| Step: 1
Training loss: 3.5861611556239974
Validation loss: 3.3073264003509455

Epoch: 6| Step: 2
Training loss: 3.580732969339837
Validation loss: 3.3040881470991965

Epoch: 6| Step: 3
Training loss: 3.17122549538473
Validation loss: 3.3033769896286103

Epoch: 6| Step: 4
Training loss: 3.5935039933632162
Validation loss: 3.2997826108430806

Epoch: 6| Step: 5
Training loss: 3.2128205729445187
Validation loss: 3.296208034107638

Epoch: 6| Step: 6
Training loss: 3.0866437272880303
Validation loss: 3.291174925219853

Epoch: 6| Step: 7
Training loss: 3.1721597177286447
Validation loss: 3.293186008962225

Epoch: 6| Step: 8
Training loss: 3.847448415032416
Validation loss: 3.288043162654676

Epoch: 6| Step: 9
Training loss: 3.6584532530528455
Validation loss: 3.2855710557639664

Epoch: 6| Step: 10
Training loss: 3.563868744904644
Validation loss: 3.286564383625527

Epoch: 6| Step: 11
Training loss: 3.5974346345287542
Validation loss: 3.2859092607229194

Epoch: 6| Step: 12
Training loss: 4.482986075603262
Validation loss: 3.282784545652594

Epoch: 6| Step: 13
Training loss: 2.3961128624650403
Validation loss: 3.2810415331613103

Epoch: 19| Step: 0
Training loss: 3.5878462355208605
Validation loss: 3.275081164592589

Epoch: 6| Step: 1
Training loss: 3.554127944669764
Validation loss: 3.274863351142379

Epoch: 6| Step: 2
Training loss: 2.784522884735853
Validation loss: 3.2735942435255345

Epoch: 6| Step: 3
Training loss: 3.779531545524297
Validation loss: 3.2754690143651652

Epoch: 6| Step: 4
Training loss: 3.9850969445894133
Validation loss: 3.2718852316202023

Epoch: 6| Step: 5
Training loss: 3.2531274273338386
Validation loss: 3.268437089308892

Epoch: 6| Step: 6
Training loss: 3.941206383528825
Validation loss: 3.2660838736629505

Epoch: 6| Step: 7
Training loss: 3.8117630042970583
Validation loss: 3.262321300875025

Epoch: 6| Step: 8
Training loss: 4.257473377406625
Validation loss: 3.263228167879206

Epoch: 6| Step: 9
Training loss: 3.7292007927780513
Validation loss: 3.2602821719959443

Epoch: 6| Step: 10
Training loss: 2.881734672377883
Validation loss: 3.2605992789960165

Epoch: 6| Step: 11
Training loss: 3.6071848644308764
Validation loss: 3.261348449818128

Epoch: 6| Step: 12
Training loss: 2.1185320986885774
Validation loss: 3.2580816646060873

Epoch: 6| Step: 13
Training loss: 3.2515802209711273
Validation loss: 3.263767769988873

Epoch: 20| Step: 0
Training loss: 4.023434892672092
Validation loss: 3.2654946198096964

Epoch: 6| Step: 1
Training loss: 3.2546321430159413
Validation loss: 3.2567605222800853

Epoch: 6| Step: 2
Training loss: 3.9745736235339257
Validation loss: 3.256858565818633

Epoch: 6| Step: 3
Training loss: 3.197298733697695
Validation loss: 3.2554625032029234

Epoch: 6| Step: 4
Training loss: 3.4101224113262405
Validation loss: 3.250674285861101

Epoch: 6| Step: 5
Training loss: 3.83665978493779
Validation loss: 3.254636064133547

Epoch: 6| Step: 6
Training loss: 3.671278495223394
Validation loss: 3.255052077482918

Epoch: 6| Step: 7
Training loss: 3.067228442718967
Validation loss: 3.249051590667662

Epoch: 6| Step: 8
Training loss: 3.7158937143702837
Validation loss: 3.245835895187953

Epoch: 6| Step: 9
Training loss: 3.361049500908696
Validation loss: 3.2445167213407933

Epoch: 6| Step: 10
Training loss: 3.0324371215641444
Validation loss: 3.2488451468515906

Epoch: 6| Step: 11
Training loss: 3.182713074364843
Validation loss: 3.24941029968863

Epoch: 6| Step: 12
Training loss: 3.0466065899903065
Validation loss: 3.2453349024517695

Epoch: 6| Step: 13
Training loss: 4.311641220609478
Validation loss: 3.241953970243638

Epoch: 21| Step: 0
Training loss: 3.0313166974782026
Validation loss: 3.243260247672259

Epoch: 6| Step: 1
Training loss: 3.4598800387010744
Validation loss: 3.239585956917584

Epoch: 6| Step: 2
Training loss: 3.8658385727398654
Validation loss: 3.240342125357744

Epoch: 6| Step: 3
Training loss: 2.7998332995791246
Validation loss: 3.241290292692024

Epoch: 6| Step: 4
Training loss: 3.6938552402536984
Validation loss: 3.2384170497221

Epoch: 6| Step: 5
Training loss: 3.7927921147964345
Validation loss: 3.236068104099595

Epoch: 6| Step: 6
Training loss: 3.815277838632714
Validation loss: 3.230751338404956

Epoch: 6| Step: 7
Training loss: 2.967616778472596
Validation loss: 3.2332422794435183

Epoch: 6| Step: 8
Training loss: 3.7497619553352566
Validation loss: 3.2367643788748963

Epoch: 6| Step: 9
Training loss: 3.6179086448307824
Validation loss: 3.2380995873948284

Epoch: 6| Step: 10
Training loss: 3.537799803629584
Validation loss: 3.236345918108558

Epoch: 6| Step: 11
Training loss: 3.737786175542896
Validation loss: 3.2341643971245033

Epoch: 6| Step: 12
Training loss: 3.524178234654748
Validation loss: 3.2293360818859838

Epoch: 6| Step: 13
Training loss: 2.4997639544631904
Validation loss: 3.229594938132529

Epoch: 22| Step: 0
Training loss: 3.979499017440458
Validation loss: 3.2265837745965253

Epoch: 6| Step: 1
Training loss: 3.3713264252426747
Validation loss: 3.226401637707837

Epoch: 6| Step: 2
Training loss: 3.650913354176205
Validation loss: 3.2236341580872003

Epoch: 6| Step: 3
Training loss: 3.0289529178419756
Validation loss: 3.2209263982276175

Epoch: 6| Step: 4
Training loss: 3.102127907669507
Validation loss: 3.222043561868046

Epoch: 6| Step: 5
Training loss: 3.4067080128568814
Validation loss: 3.2192622939023248

Epoch: 6| Step: 6
Training loss: 3.903947441489899
Validation loss: 3.2202843763160063

Epoch: 6| Step: 7
Training loss: 3.3746881694141297
Validation loss: 3.218933291403005

Epoch: 6| Step: 8
Training loss: 3.9239355502654116
Validation loss: 3.219393896636239

Epoch: 6| Step: 9
Training loss: 4.194224864834607
Validation loss: 3.215611716086679

Epoch: 6| Step: 10
Training loss: 2.7956808087453773
Validation loss: 3.2139880195344

Epoch: 6| Step: 11
Training loss: 2.984666740178333
Validation loss: 3.2103383453100474

Epoch: 6| Step: 12
Training loss: 3.337002800757102
Validation loss: 3.21498314722691

Epoch: 6| Step: 13
Training loss: 3.1562300577572344
Validation loss: 3.211122618509831

Epoch: 23| Step: 0
Training loss: 3.6144186343323574
Validation loss: 3.2105431544713743

Epoch: 6| Step: 1
Training loss: 3.4325976006286836
Validation loss: 3.209309618911247

Epoch: 6| Step: 2
Training loss: 3.822242046706467
Validation loss: 3.2106114340643104

Epoch: 6| Step: 3
Training loss: 3.6813466083693
Validation loss: 3.2103939963188055

Epoch: 6| Step: 4
Training loss: 3.85259587351173
Validation loss: 3.2074454466265783

Epoch: 6| Step: 5
Training loss: 2.800452134548625
Validation loss: 3.207681247353669

Epoch: 6| Step: 6
Training loss: 3.599542344991067
Validation loss: 3.2047147321945695

Epoch: 6| Step: 7
Training loss: 3.563364425989807
Validation loss: 3.205625463388953

Epoch: 6| Step: 8
Training loss: 3.115056200821639
Validation loss: 3.202782858306784

Epoch: 6| Step: 9
Training loss: 3.4910419812700955
Validation loss: 3.203815501630477

Epoch: 6| Step: 10
Training loss: 2.9817693230015734
Validation loss: 3.203124555001977

Epoch: 6| Step: 11
Training loss: 2.463104843757974
Validation loss: 3.2055482547513106

Epoch: 6| Step: 12
Training loss: 3.874572607281882
Validation loss: 3.201050029007563

Epoch: 6| Step: 13
Training loss: 4.146932842710758
Validation loss: 3.2003792420103094

Epoch: 24| Step: 0
Training loss: 3.1569746337586877
Validation loss: 3.200835941579532

Epoch: 6| Step: 1
Training loss: 3.6705567935924646
Validation loss: 3.197144422368005

Epoch: 6| Step: 2
Training loss: 3.5399101539029316
Validation loss: 3.1973749147938535

Epoch: 6| Step: 3
Training loss: 3.071059585028021
Validation loss: 3.197112567787232

Epoch: 6| Step: 4
Training loss: 3.6064837877466323
Validation loss: 3.1969557359200467

Epoch: 6| Step: 5
Training loss: 3.3646888047133685
Validation loss: 3.1936208117648146

Epoch: 6| Step: 6
Training loss: 2.846044934859644
Validation loss: 3.1932199602820965

Epoch: 6| Step: 7
Training loss: 3.6854971926301565
Validation loss: 3.193605245032477

Epoch: 6| Step: 8
Training loss: 3.5388605258057226
Validation loss: 3.1949374239552206

Epoch: 6| Step: 9
Training loss: 4.087345150688815
Validation loss: 3.1905945425062385

Epoch: 6| Step: 10
Training loss: 3.1427435111274034
Validation loss: 3.1887091278235125

Epoch: 6| Step: 11
Training loss: 3.7533254501594255
Validation loss: 3.1874770248714284

Epoch: 6| Step: 12
Training loss: 3.71144347907445
Validation loss: 3.188745344254445

Epoch: 6| Step: 13
Training loss: 2.4008960362510465
Validation loss: 3.186512909456684

Epoch: 25| Step: 0
Training loss: 3.5744703527393122
Validation loss: 3.1857190989099764

Epoch: 6| Step: 1
Training loss: 3.907797056927952
Validation loss: 3.1921558113150152

Epoch: 6| Step: 2
Training loss: 3.7401662954802797
Validation loss: 3.2010028202873424

Epoch: 6| Step: 3
Training loss: 3.0543206426327765
Validation loss: 3.182508281842662

Epoch: 6| Step: 4
Training loss: 2.992612962877267
Validation loss: 3.181739877041703

Epoch: 6| Step: 5
Training loss: 3.4314844381431704
Validation loss: 3.1821799272320153

Epoch: 6| Step: 6
Training loss: 3.5938075848817115
Validation loss: 3.182100297550385

Epoch: 6| Step: 7
Training loss: 3.6664631671499026
Validation loss: 3.1863599101968

Epoch: 6| Step: 8
Training loss: 2.9080522753019196
Validation loss: 3.1881191497632044

Epoch: 6| Step: 9
Training loss: 3.0907166377754485
Validation loss: 3.196959807166662

Epoch: 6| Step: 10
Training loss: 3.2432834473472134
Validation loss: 3.1968742072530514

Epoch: 6| Step: 11
Training loss: 2.6916822671192127
Validation loss: 3.197257234714689

Epoch: 6| Step: 12
Training loss: 3.9603651487212708
Validation loss: 3.181975820670552

Epoch: 6| Step: 13
Training loss: 4.545467198094184
Validation loss: 3.21514888179547

Epoch: 26| Step: 0
Training loss: 3.3001446894512787
Validation loss: 3.1782415211861306

Epoch: 6| Step: 1
Training loss: 2.951464635338249
Validation loss: 3.2054353231129187

Epoch: 6| Step: 2
Training loss: 3.0990028869674546
Validation loss: 3.2290811618013007

Epoch: 6| Step: 3
Training loss: 3.943571223878521
Validation loss: 3.2162625156834985

Epoch: 6| Step: 4
Training loss: 3.644998829112761
Validation loss: 3.2164277156664

Epoch: 6| Step: 5
Training loss: 3.3580549618538194
Validation loss: 3.2116775939218423

Epoch: 6| Step: 6
Training loss: 3.4799533038459356
Validation loss: 3.22204842014436

Epoch: 6| Step: 7
Training loss: 3.67631282063975
Validation loss: 3.1955760585661466

Epoch: 6| Step: 8
Training loss: 2.9442152817836336
Validation loss: 3.2655400750245995

Epoch: 6| Step: 9
Training loss: 2.7959025306685024
Validation loss: 3.3312708678039544

Epoch: 6| Step: 10
Training loss: 3.1608511746546104
Validation loss: 3.3640109484930916

Epoch: 6| Step: 11
Training loss: 4.412050798153099
Validation loss: 3.344905481501444

Epoch: 6| Step: 12
Training loss: 4.185333830395203
Validation loss: 3.261911667420382

Epoch: 6| Step: 13
Training loss: 3.6334472101780135
Validation loss: 3.220449334962564

Epoch: 27| Step: 0
Training loss: 3.4469419332803173
Validation loss: 3.232298745137237

Epoch: 6| Step: 1
Training loss: 2.116825875229529
Validation loss: 3.283135945935364

Epoch: 6| Step: 2
Training loss: 3.6586802956027915
Validation loss: 3.3492091867080966

Epoch: 6| Step: 3
Training loss: 3.1961644909176576
Validation loss: 3.2971048652589645

Epoch: 6| Step: 4
Training loss: 4.322777925892335
Validation loss: 3.2297236210684064

Epoch: 6| Step: 5
Training loss: 3.2976327902061757
Validation loss: 3.1865726741046725

Epoch: 6| Step: 6
Training loss: 2.882362061746004
Validation loss: 3.1782393078136395

Epoch: 6| Step: 7
Training loss: 4.098382789051763
Validation loss: 3.1755311743342336

Epoch: 6| Step: 8
Training loss: 3.3383134514960475
Validation loss: 3.177089437918982

Epoch: 6| Step: 9
Training loss: 3.644903722048824
Validation loss: 3.178019618084843

Epoch: 6| Step: 10
Training loss: 3.346343273733892
Validation loss: 3.160810123386278

Epoch: 6| Step: 11
Training loss: 3.874566330792258
Validation loss: 3.1591676384833214

Epoch: 6| Step: 12
Training loss: 3.1960651285460693
Validation loss: 3.1518241117653383

Epoch: 6| Step: 13
Training loss: 3.640941033132848
Validation loss: 3.1532861274077577

Epoch: 28| Step: 0
Training loss: 3.2374721570088023
Validation loss: 3.15634178207678

Epoch: 6| Step: 1
Training loss: 3.677123129884163
Validation loss: 3.176097407173214

Epoch: 6| Step: 2
Training loss: 3.350665775016102
Validation loss: 3.1651260620127277

Epoch: 6| Step: 3
Training loss: 2.7740333454352912
Validation loss: 3.1519327054927957

Epoch: 6| Step: 4
Training loss: 4.248082345397892
Validation loss: 3.1515292848118746

Epoch: 6| Step: 5
Training loss: 3.746409413837968
Validation loss: 3.146864611929737

Epoch: 6| Step: 6
Training loss: 2.894180008842571
Validation loss: 3.1453524371850854

Epoch: 6| Step: 7
Training loss: 3.8058244389000664
Validation loss: 3.1450782890610953

Epoch: 6| Step: 8
Training loss: 3.0628724163707575
Validation loss: 3.142201016322674

Epoch: 6| Step: 9
Training loss: 3.4018187090400342
Validation loss: 3.141129522318173

Epoch: 6| Step: 10
Training loss: 3.334603179017142
Validation loss: 3.1391982334093567

Epoch: 6| Step: 11
Training loss: 3.593378462452023
Validation loss: 3.1399668334135225

Epoch: 6| Step: 12
Training loss: 2.9380065805817224
Validation loss: 3.1374648530131553

Epoch: 6| Step: 13
Training loss: 3.5563408328827126
Validation loss: 3.1373259468599177

Epoch: 29| Step: 0
Training loss: 3.7345100921073646
Validation loss: 3.1376450817590085

Epoch: 6| Step: 1
Training loss: 3.2977904002601273
Validation loss: 3.1368800171502444

Epoch: 6| Step: 2
Training loss: 3.549347003464296
Validation loss: 3.1337217972674924

Epoch: 6| Step: 3
Training loss: 2.9193780194811842
Validation loss: 3.1329325205788057

Epoch: 6| Step: 4
Training loss: 3.2333962254126383
Validation loss: 3.131168499065785

Epoch: 6| Step: 5
Training loss: 3.140100084155469
Validation loss: 3.12706311448979

Epoch: 6| Step: 6
Training loss: 4.118484900688269
Validation loss: 3.1280538391730635

Epoch: 6| Step: 7
Training loss: 2.7788553966280167
Validation loss: 3.128218339393307

Epoch: 6| Step: 8
Training loss: 3.8749959391911055
Validation loss: 3.128353963901439

Epoch: 6| Step: 9
Training loss: 4.33868815833804
Validation loss: 3.129600053160583

Epoch: 6| Step: 10
Training loss: 2.604183308866094
Validation loss: 3.1258151478148357

Epoch: 6| Step: 11
Training loss: 3.1823943892078987
Validation loss: 3.1237365678956066

Epoch: 6| Step: 12
Training loss: 3.4432801634039896
Validation loss: 3.1238096320366933

Epoch: 6| Step: 13
Training loss: 2.51917523374961
Validation loss: 3.122920646030927

Epoch: 30| Step: 0
Training loss: 3.1217440618753494
Validation loss: 3.12077318869574

Epoch: 6| Step: 1
Training loss: 3.6800135247355175
Validation loss: 3.121159994541063

Epoch: 6| Step: 2
Training loss: 3.581159745655221
Validation loss: 3.122815976452921

Epoch: 6| Step: 3
Training loss: 3.3671968464378694
Validation loss: 3.1246052014756382

Epoch: 6| Step: 4
Training loss: 2.9055499802733062
Validation loss: 3.1178730836212902

Epoch: 6| Step: 5
Training loss: 3.4441760344846712
Validation loss: 3.1158221572094416

Epoch: 6| Step: 6
Training loss: 4.292420453782548
Validation loss: 3.1163628052396186

Epoch: 6| Step: 7
Training loss: 3.5236743246872235
Validation loss: 3.1148455444239573

Epoch: 6| Step: 8
Training loss: 3.9053531685331198
Validation loss: 3.112249786655589

Epoch: 6| Step: 9
Training loss: 2.970065498015153
Validation loss: 3.1120749113320163

Epoch: 6| Step: 10
Training loss: 3.417554662416604
Validation loss: 3.1100415975479803

Epoch: 6| Step: 11
Training loss: 3.372140874270785
Validation loss: 3.106911134723202

Epoch: 6| Step: 12
Training loss: 2.4133989230704156
Validation loss: 3.1086484856236356

Epoch: 6| Step: 13
Training loss: 2.6573816020784333
Validation loss: 3.1098796393546997

Epoch: 31| Step: 0
Training loss: 3.1482056184480443
Validation loss: 3.1167065982477054

Epoch: 6| Step: 1
Training loss: 3.1913718848555224
Validation loss: 3.114784548376145

Epoch: 6| Step: 2
Training loss: 3.168895656390615
Validation loss: 3.116016157273584

Epoch: 6| Step: 3
Training loss: 4.626640029046351
Validation loss: 3.1074902639166475

Epoch: 6| Step: 4
Training loss: 2.579307885892464
Validation loss: 3.1011201483097066

Epoch: 6| Step: 5
Training loss: 3.0786363206042147
Validation loss: 3.098331342834177

Epoch: 6| Step: 6
Training loss: 3.2207937326172265
Validation loss: 3.0993807412315637

Epoch: 6| Step: 7
Training loss: 3.7120732225891344
Validation loss: 3.0989531177377936

Epoch: 6| Step: 8
Training loss: 3.6909362816737947
Validation loss: 3.0966873022163908

Epoch: 6| Step: 9
Training loss: 2.448673169272901
Validation loss: 3.0961353150798905

Epoch: 6| Step: 10
Training loss: 3.319796030604057
Validation loss: 3.0943502616746383

Epoch: 6| Step: 11
Training loss: 3.2268453478665275
Validation loss: 3.0960728756375824

Epoch: 6| Step: 12
Training loss: 3.645355033381107
Validation loss: 3.0935969492506508

Epoch: 6| Step: 13
Training loss: 3.8119661551511155
Validation loss: 3.0969096282823965

Epoch: 32| Step: 0
Training loss: 3.1448281473775457
Validation loss: 3.0926469510528394

Epoch: 6| Step: 1
Training loss: 3.7512927052483147
Validation loss: 3.09386925225628

Epoch: 6| Step: 2
Training loss: 2.7094990104621393
Validation loss: 3.0947297004398493

Epoch: 6| Step: 3
Training loss: 3.581297688058501
Validation loss: 3.095222060779435

Epoch: 6| Step: 4
Training loss: 3.2249057016706657
Validation loss: 3.09383836447869

Epoch: 6| Step: 5
Training loss: 3.806088418772437
Validation loss: 3.0894616615473165

Epoch: 6| Step: 6
Training loss: 3.4591038929362132
Validation loss: 3.090033264060758

Epoch: 6| Step: 7
Training loss: 3.3350683147519633
Validation loss: 3.08893111544776

Epoch: 6| Step: 8
Training loss: 3.332394149713231
Validation loss: 3.088381734789415

Epoch: 6| Step: 9
Training loss: 3.4348944759679525
Validation loss: 3.0880941377229907

Epoch: 6| Step: 10
Training loss: 2.972096053284815
Validation loss: 3.084021394800669

Epoch: 6| Step: 11
Training loss: 2.8463356084936997
Validation loss: 3.084283895616466

Epoch: 6| Step: 12
Training loss: 3.751672753140294
Validation loss: 3.084116493434512

Epoch: 6| Step: 13
Training loss: 3.554260630705273
Validation loss: 3.0816148765497715

Epoch: 33| Step: 0
Training loss: 3.718906687793423
Validation loss: 3.081196960832724

Epoch: 6| Step: 1
Training loss: 3.347381901043062
Validation loss: 3.081790625159876

Epoch: 6| Step: 2
Training loss: 3.1786402821928594
Validation loss: 3.078613685538338

Epoch: 6| Step: 3
Training loss: 2.6978773214841634
Validation loss: 3.0798693762851372

Epoch: 6| Step: 4
Training loss: 3.3214333471214075
Validation loss: 3.0786664066143605

Epoch: 6| Step: 5
Training loss: 2.9967349086313697
Validation loss: 3.0810384039267102

Epoch: 6| Step: 6
Training loss: 3.9969387261125044
Validation loss: 3.0792887105601454

Epoch: 6| Step: 7
Training loss: 3.388891524086294
Validation loss: 3.078769799322787

Epoch: 6| Step: 8
Training loss: 3.612774985647989
Validation loss: 3.078897535309146

Epoch: 6| Step: 9
Training loss: 3.577460481330772
Validation loss: 3.078778851411184

Epoch: 6| Step: 10
Training loss: 3.186502637219501
Validation loss: 3.075872211226653

Epoch: 6| Step: 11
Training loss: 3.5499316249226514
Validation loss: 3.0792448851783543

Epoch: 6| Step: 12
Training loss: 2.9011605932946796
Validation loss: 3.0776054627237026

Epoch: 6| Step: 13
Training loss: 2.9472475045002926
Validation loss: 3.0787773317679945

Epoch: 34| Step: 0
Training loss: 3.681676630709214
Validation loss: 3.0776638387027013

Epoch: 6| Step: 1
Training loss: 3.4075662012309436
Validation loss: 3.081747354450184

Epoch: 6| Step: 2
Training loss: 3.2670752120641757
Validation loss: 3.0742192636923

Epoch: 6| Step: 3
Training loss: 3.1154449870028222
Validation loss: 3.0700405058507223

Epoch: 6| Step: 4
Training loss: 3.126073729111146
Validation loss: 3.0661177221009575

Epoch: 6| Step: 5
Training loss: 2.823239991838043
Validation loss: 3.0658036461749596

Epoch: 6| Step: 6
Training loss: 3.534885796586598
Validation loss: 3.0710102561677672

Epoch: 6| Step: 7
Training loss: 2.750134291404341
Validation loss: 3.0687508342659835

Epoch: 6| Step: 8
Training loss: 2.9503858669530016
Validation loss: 3.068834784337152

Epoch: 6| Step: 9
Training loss: 3.5218411570076342
Validation loss: 3.0677968724208666

Epoch: 6| Step: 10
Training loss: 2.9296962890493163
Validation loss: 3.0662771140959366

Epoch: 6| Step: 11
Training loss: 4.150852226168888
Validation loss: 3.0634645103023392

Epoch: 6| Step: 12
Training loss: 3.5933712967074496
Validation loss: 3.0600088047946743

Epoch: 6| Step: 13
Training loss: 3.745592197100803
Validation loss: 3.061310835890105

Epoch: 35| Step: 0
Training loss: 3.2057430825859785
Validation loss: 3.060253510560579

Epoch: 6| Step: 1
Training loss: 2.978530033264331
Validation loss: 3.0635276068223223

Epoch: 6| Step: 2
Training loss: 3.6762094440836774
Validation loss: 3.06613839926501

Epoch: 6| Step: 3
Training loss: 3.056754815159371
Validation loss: 3.0683075045168673

Epoch: 6| Step: 4
Training loss: 2.918300625109275
Validation loss: 3.063902548193583

Epoch: 6| Step: 5
Training loss: 3.080376281046995
Validation loss: 3.0660083941904426

Epoch: 6| Step: 6
Training loss: 4.30628962394744
Validation loss: 3.057495295442555

Epoch: 6| Step: 7
Training loss: 4.271153706265316
Validation loss: 3.056315861883615

Epoch: 6| Step: 8
Training loss: 3.6931591251983233
Validation loss: 3.0553130635021826

Epoch: 6| Step: 9
Training loss: 2.830062455475513
Validation loss: 3.0504164962252713

Epoch: 6| Step: 10
Training loss: 3.0160827289335077
Validation loss: 3.051796730262602

Epoch: 6| Step: 11
Training loss: 3.1157142006550558
Validation loss: 3.0519893964550113

Epoch: 6| Step: 12
Training loss: 2.8458782239047773
Validation loss: 3.049210317771123

Epoch: 6| Step: 13
Training loss: 2.9928028878237556
Validation loss: 3.0503456342840254

Epoch: 36| Step: 0
Training loss: 2.8232823847017303
Validation loss: 3.0486332828741

Epoch: 6| Step: 1
Training loss: 2.7117606460645063
Validation loss: 3.0486117906996597

Epoch: 6| Step: 2
Training loss: 3.3387158011709785
Validation loss: 3.046314084589153

Epoch: 6| Step: 3
Training loss: 3.227280950108406
Validation loss: 3.046308096078387

Epoch: 6| Step: 4
Training loss: 3.273543545045429
Validation loss: 3.046672142644367

Epoch: 6| Step: 5
Training loss: 3.7661869373732912
Validation loss: 3.0451821461694735

Epoch: 6| Step: 6
Training loss: 3.912308046549841
Validation loss: 3.0440658303395156

Epoch: 6| Step: 7
Training loss: 3.4626148025815877
Validation loss: 3.043728236969434

Epoch: 6| Step: 8
Training loss: 3.1741796680310026
Validation loss: 3.0433219380240577

Epoch: 6| Step: 9
Training loss: 3.5926222648866357
Validation loss: 3.0430738206198877

Epoch: 6| Step: 10
Training loss: 2.989555296727656
Validation loss: 3.0417984835428706

Epoch: 6| Step: 11
Training loss: 3.1853696398427043
Validation loss: 3.039350875195947

Epoch: 6| Step: 12
Training loss: 3.3654724143176695
Validation loss: 3.0380659875077507

Epoch: 6| Step: 13
Training loss: 3.6175204756130257
Validation loss: 3.041150463251274

Epoch: 37| Step: 0
Training loss: 3.1460989698883473
Validation loss: 3.0456076199779183

Epoch: 6| Step: 1
Training loss: 2.824982641386191
Validation loss: 3.053493275022928

Epoch: 6| Step: 2
Training loss: 3.5658263354415913
Validation loss: 3.0584466700009463

Epoch: 6| Step: 3
Training loss: 3.2776478204629234
Validation loss: 3.0578428145038474

Epoch: 6| Step: 4
Training loss: 3.0066990760810177
Validation loss: 3.0651149221417975

Epoch: 6| Step: 5
Training loss: 3.0312792589800845
Validation loss: 3.0504891348139687

Epoch: 6| Step: 6
Training loss: 2.86141278138418
Validation loss: 3.033357160808883

Epoch: 6| Step: 7
Training loss: 3.481304509337119
Validation loss: 3.032037190240049

Epoch: 6| Step: 8
Training loss: 3.527693586437876
Validation loss: 3.0316112266288524

Epoch: 6| Step: 9
Training loss: 3.588852439382962
Validation loss: 3.0309560041381456

Epoch: 6| Step: 10
Training loss: 3.898674539151921
Validation loss: 3.032738294343079

Epoch: 6| Step: 11
Training loss: 3.8692463644214836
Validation loss: 3.029846429717143

Epoch: 6| Step: 12
Training loss: 2.630846325134672
Validation loss: 3.030205185747132

Epoch: 6| Step: 13
Training loss: 3.6183050748499714
Validation loss: 3.031468371606662

Epoch: 38| Step: 0
Training loss: 3.8505030910200655
Validation loss: 3.0265636595732164

Epoch: 6| Step: 1
Training loss: 3.7529445531760612
Validation loss: 3.0266243879741577

Epoch: 6| Step: 2
Training loss: 3.772213565577401
Validation loss: 3.025879126108342

Epoch: 6| Step: 3
Training loss: 3.577394635816839
Validation loss: 3.0249242751588565

Epoch: 6| Step: 4
Training loss: 3.299808878132512
Validation loss: 3.023334880983625

Epoch: 6| Step: 5
Training loss: 3.396326852209035
Validation loss: 3.0227883507379385

Epoch: 6| Step: 6
Training loss: 2.817133414140194
Validation loss: 3.021046907529181

Epoch: 6| Step: 7
Training loss: 2.68111139397168
Validation loss: 3.0203559410574696

Epoch: 6| Step: 8
Training loss: 3.0572592599809485
Validation loss: 3.018890395632463

Epoch: 6| Step: 9
Training loss: 2.78297370902064
Validation loss: 3.019780447289894

Epoch: 6| Step: 10
Training loss: 2.8997543099344467
Validation loss: 3.0180116356848856

Epoch: 6| Step: 11
Training loss: 2.8751930503714522
Validation loss: 3.0207461170905994

Epoch: 6| Step: 12
Training loss: 4.0227095158307025
Validation loss: 3.020295710489647

Epoch: 6| Step: 13
Training loss: 2.9051355665815812
Validation loss: 3.0193065673327015

Epoch: 39| Step: 0
Training loss: 3.445990048173293
Validation loss: 3.01946393814202

Epoch: 6| Step: 1
Training loss: 3.005414051086678
Validation loss: 3.0155324988141756

Epoch: 6| Step: 2
Training loss: 2.828235602982284
Validation loss: 3.017717270988674

Epoch: 6| Step: 3
Training loss: 3.5225570492155307
Validation loss: 3.0178465411638045

Epoch: 6| Step: 4
Training loss: 3.3244821016056747
Validation loss: 3.018174388720772

Epoch: 6| Step: 5
Training loss: 2.692976937587278
Validation loss: 3.0190209767844967

Epoch: 6| Step: 6
Training loss: 4.017085778199672
Validation loss: 3.016402726452699

Epoch: 6| Step: 7
Training loss: 4.1370412612565115
Validation loss: 3.0275022280915613

Epoch: 6| Step: 8
Training loss: 3.5701069511827375
Validation loss: 3.0112598826625074

Epoch: 6| Step: 9
Training loss: 3.3083144321109907
Validation loss: 3.013484068405602

Epoch: 6| Step: 10
Training loss: 3.365763422847646
Validation loss: 3.021671971963391

Epoch: 6| Step: 11
Training loss: 2.891397074097589
Validation loss: 3.0248002604942483

Epoch: 6| Step: 12
Training loss: 2.6556436183148406
Validation loss: 3.042494336059927

Epoch: 6| Step: 13
Training loss: 2.708868022859548
Validation loss: 3.0513155980008104

Epoch: 40| Step: 0
Training loss: 3.104245656350461
Validation loss: 3.0801220483920355

Epoch: 6| Step: 1
Training loss: 2.938550071519481
Validation loss: 3.056687664629436

Epoch: 6| Step: 2
Training loss: 3.3911429154685186
Validation loss: 3.026987939223039

Epoch: 6| Step: 3
Training loss: 3.918171262213925
Validation loss: 3.0177274194541486

Epoch: 6| Step: 4
Training loss: 3.128248433698873
Validation loss: 3.012922656236023

Epoch: 6| Step: 5
Training loss: 2.789313638957988
Validation loss: 3.008638351417056

Epoch: 6| Step: 6
Training loss: 3.214216873400569
Validation loss: 3.0068028460477443

Epoch: 6| Step: 7
Training loss: 3.4688668446149595
Validation loss: 3.0072687325267906

Epoch: 6| Step: 8
Training loss: 2.6540246954475406
Validation loss: 3.0123629776827747

Epoch: 6| Step: 9
Training loss: 3.6409854301196742
Validation loss: 3.0103738563668077

Epoch: 6| Step: 10
Training loss: 3.3525599704871634
Validation loss: 2.9977835120502863

Epoch: 6| Step: 11
Training loss: 3.5738905458943764
Validation loss: 3.0028009413785752

Epoch: 6| Step: 12
Training loss: 3.544022408700885
Validation loss: 3.0016461901050486

Epoch: 6| Step: 13
Training loss: 3.100025324564213
Validation loss: 3.002440123337078

Epoch: 41| Step: 0
Training loss: 3.726677147083411
Validation loss: 2.9997166804041324

Epoch: 6| Step: 1
Training loss: 3.111011630314589
Validation loss: 2.996492897834867

Epoch: 6| Step: 2
Training loss: 2.9644387512622608
Validation loss: 2.997462158005309

Epoch: 6| Step: 3
Training loss: 3.3014260649755585
Validation loss: 2.994883895388371

Epoch: 6| Step: 4
Training loss: 3.5259059201832654
Validation loss: 2.9946230313981674

Epoch: 6| Step: 5
Training loss: 3.0438344015525396
Validation loss: 2.991208719433617

Epoch: 6| Step: 6
Training loss: 3.0945704749707263
Validation loss: 2.990281446755443

Epoch: 6| Step: 7
Training loss: 3.6042639805586845
Validation loss: 2.9909261047797697

Epoch: 6| Step: 8
Training loss: 3.442560251410965
Validation loss: 2.989318764489123

Epoch: 6| Step: 9
Training loss: 3.4494682731535127
Validation loss: 2.990005407344604

Epoch: 6| Step: 10
Training loss: 3.211676371041249
Validation loss: 2.988816177046488

Epoch: 6| Step: 11
Training loss: 3.3254532813388296
Validation loss: 2.986778967437337

Epoch: 6| Step: 12
Training loss: 2.7435589699947
Validation loss: 2.9861725784567583

Epoch: 6| Step: 13
Training loss: 3.1588002090479153
Validation loss: 2.9852309835305286

Epoch: 42| Step: 0
Training loss: 2.8519873733669017
Validation loss: 2.9857684825452204

Epoch: 6| Step: 1
Training loss: 3.502928870748441
Validation loss: 2.9834815274218176

Epoch: 6| Step: 2
Training loss: 4.088996048803886
Validation loss: 2.9851904903145057

Epoch: 6| Step: 3
Training loss: 3.154940191750929
Validation loss: 2.985688662442699

Epoch: 6| Step: 4
Training loss: 3.8652785396510447
Validation loss: 2.9890227117837957

Epoch: 6| Step: 5
Training loss: 2.9502048485963885
Validation loss: 2.9831130805501602

Epoch: 6| Step: 6
Training loss: 3.3937712104935427
Validation loss: 2.987467247828943

Epoch: 6| Step: 7
Training loss: 3.6005540209546223
Validation loss: 2.9872366777966066

Epoch: 6| Step: 8
Training loss: 3.689970062051709
Validation loss: 2.9873451778032614

Epoch: 6| Step: 9
Training loss: 1.9722172314695632
Validation loss: 2.994079731785037

Epoch: 6| Step: 10
Training loss: 2.4740346046870907
Validation loss: 3.0122894358871566

Epoch: 6| Step: 11
Training loss: 2.872122942128722
Validation loss: 2.99812018640965

Epoch: 6| Step: 12
Training loss: 3.0914705144002665
Validation loss: 3.019575162662533

Epoch: 6| Step: 13
Training loss: 3.6204072204763977
Validation loss: 3.051333285324361

Epoch: 43| Step: 0
Training loss: 3.6384254982342528
Validation loss: 3.012112761604412

Epoch: 6| Step: 1
Training loss: 3.0432254159044536
Validation loss: 2.9773722963782014

Epoch: 6| Step: 2
Training loss: 3.3039122770177354
Validation loss: 2.9737461813877726

Epoch: 6| Step: 3
Training loss: 2.988300079086921
Validation loss: 2.9729907520964196

Epoch: 6| Step: 4
Training loss: 2.654006189817729
Validation loss: 2.9729857851847714

Epoch: 6| Step: 5
Training loss: 3.025729313726502
Validation loss: 2.97506577103751

Epoch: 6| Step: 6
Training loss: 2.5192019225175293
Validation loss: 2.9749930669080387

Epoch: 6| Step: 7
Training loss: 4.07775362742725
Validation loss: 2.977524051908179

Epoch: 6| Step: 8
Training loss: 2.7257802983482144
Validation loss: 2.9800955011941386

Epoch: 6| Step: 9
Training loss: 3.4871590615159067
Validation loss: 2.974324253955185

Epoch: 6| Step: 10
Training loss: 3.6847834521658758
Validation loss: 2.9723733928000384

Epoch: 6| Step: 11
Training loss: 4.005511301765883
Validation loss: 2.9702743804792293

Epoch: 6| Step: 12
Training loss: 2.794033802475156
Validation loss: 2.968051543700537

Epoch: 6| Step: 13
Training loss: 3.3371509783836353
Validation loss: 2.968044988730052

Epoch: 44| Step: 0
Training loss: 2.8708133897979105
Validation loss: 2.96809189760764

Epoch: 6| Step: 1
Training loss: 3.4289210686197222
Validation loss: 2.9666331923825657

Epoch: 6| Step: 2
Training loss: 2.7107690764335297
Validation loss: 2.965772761742693

Epoch: 6| Step: 3
Training loss: 4.132256569635991
Validation loss: 2.9656448973374805

Epoch: 6| Step: 4
Training loss: 3.4358348628141036
Validation loss: 2.964158892886004

Epoch: 6| Step: 5
Training loss: 4.283940938362585
Validation loss: 2.967372969995665

Epoch: 6| Step: 6
Training loss: 2.590636625367368
Validation loss: 2.963499372151551

Epoch: 6| Step: 7
Training loss: 2.8963686404832356
Validation loss: 2.962791702795575

Epoch: 6| Step: 8
Training loss: 2.004404701272159
Validation loss: 2.9590615296746448

Epoch: 6| Step: 9
Training loss: 3.8461965822633224
Validation loss: 2.9612495478067413

Epoch: 6| Step: 10
Training loss: 3.8920536711972487
Validation loss: 2.9617635325971134

Epoch: 6| Step: 11
Training loss: 2.4485172806469446
Validation loss: 2.963257026998898

Epoch: 6| Step: 12
Training loss: 2.9866199937080053
Validation loss: 2.96178549398881

Epoch: 6| Step: 13
Training loss: 2.863364849457435
Validation loss: 2.9721254564225816

Epoch: 45| Step: 0
Training loss: 3.0603278105430793
Validation loss: 2.9879983661783487

Epoch: 6| Step: 1
Training loss: 2.8722418118105404
Validation loss: 2.9903009816807513

Epoch: 6| Step: 2
Training loss: 3.239303887551046
Validation loss: 2.978421480683733

Epoch: 6| Step: 3
Training loss: 3.0302503058152728
Validation loss: 2.9682273866741644

Epoch: 6| Step: 4
Training loss: 3.11022170917126
Validation loss: 2.957459018276218

Epoch: 6| Step: 5
Training loss: 3.7086666828873014
Validation loss: 2.9545690067579344

Epoch: 6| Step: 6
Training loss: 3.2301437048344823
Validation loss: 2.9553128331134544

Epoch: 6| Step: 7
Training loss: 3.497172030599708
Validation loss: 2.954438628727954

Epoch: 6| Step: 8
Training loss: 2.9555631392086066
Validation loss: 2.9541587827980447

Epoch: 6| Step: 9
Training loss: 3.1714008145977157
Validation loss: 2.9523308180842327

Epoch: 6| Step: 10
Training loss: 3.1876853440197053
Validation loss: 2.951486742849314

Epoch: 6| Step: 11
Training loss: 3.5160284870456198
Validation loss: 2.9522929111240486

Epoch: 6| Step: 12
Training loss: 3.048054784607833
Validation loss: 2.9539201339540027

Epoch: 6| Step: 13
Training loss: 4.092647025345854
Validation loss: 2.9529349643625373

Epoch: 46| Step: 0
Training loss: 3.3172992991125443
Validation loss: 2.952996571453413

Epoch: 6| Step: 1
Training loss: 3.1983681690359145
Validation loss: 2.9490995719184028

Epoch: 6| Step: 2
Training loss: 3.0810248178524393
Validation loss: 2.953013159127276

Epoch: 6| Step: 3
Training loss: 3.3540247695636047
Validation loss: 2.949787906261737

Epoch: 6| Step: 4
Training loss: 4.029504205766152
Validation loss: 2.9489494111100387

Epoch: 6| Step: 5
Training loss: 2.814693866839852
Validation loss: 2.9466651710350926

Epoch: 6| Step: 6
Training loss: 3.202843928216863
Validation loss: 2.945814870444721

Epoch: 6| Step: 7
Training loss: 3.6781753056925846
Validation loss: 2.943217992284038

Epoch: 6| Step: 8
Training loss: 3.2585509856003227
Validation loss: 2.9420713951577495

Epoch: 6| Step: 9
Training loss: 2.8270362739516237
Validation loss: 2.942648126347624

Epoch: 6| Step: 10
Training loss: 3.2738252469300377
Validation loss: 2.9413712031010086

Epoch: 6| Step: 11
Training loss: 2.891047101518874
Validation loss: 2.940345858787994

Epoch: 6| Step: 12
Training loss: 2.9895627932668103
Validation loss: 2.9395371954574183

Epoch: 6| Step: 13
Training loss: 3.3124776875446207
Validation loss: 2.936396342395547

Epoch: 47| Step: 0
Training loss: 3.089020167182746
Validation loss: 2.9396090139830386

Epoch: 6| Step: 1
Training loss: 3.023185147737399
Validation loss: 2.938943459827314

Epoch: 6| Step: 2
Training loss: 3.365243868557053
Validation loss: 2.9388125019867553

Epoch: 6| Step: 3
Training loss: 3.987350848526576
Validation loss: 2.9373627462374534

Epoch: 6| Step: 4
Training loss: 2.4754734472716473
Validation loss: 2.9353075505270327

Epoch: 6| Step: 5
Training loss: 2.698063339507911
Validation loss: 2.9360970319387594

Epoch: 6| Step: 6
Training loss: 2.643552522971962
Validation loss: 2.93670660862523

Epoch: 6| Step: 7
Training loss: 3.5165566799326173
Validation loss: 2.940847384749585

Epoch: 6| Step: 8
Training loss: 3.595491733584492
Validation loss: 2.943113199896309

Epoch: 6| Step: 9
Training loss: 2.9999755222593523
Validation loss: 2.933177091216715

Epoch: 6| Step: 10
Training loss: 3.3010194590912847
Validation loss: 2.9374491535115754

Epoch: 6| Step: 11
Training loss: 2.862623693467304
Validation loss: 2.937780994737676

Epoch: 6| Step: 12
Training loss: 3.2790287310338275
Validation loss: 2.9375161367098395

Epoch: 6| Step: 13
Training loss: 4.3892644219889165
Validation loss: 2.9337216533671033

Epoch: 48| Step: 0
Training loss: 3.2869486415321907
Validation loss: 2.9298594854592435

Epoch: 6| Step: 1
Training loss: 3.1668331872089364
Validation loss: 2.927289313899294

Epoch: 6| Step: 2
Training loss: 2.974728317036812
Validation loss: 2.927863571045211

Epoch: 6| Step: 3
Training loss: 2.748066656045544
Validation loss: 2.931715220097602

Epoch: 6| Step: 4
Training loss: 3.404344218062226
Validation loss: 2.927156926447612

Epoch: 6| Step: 5
Training loss: 3.259108178252712
Validation loss: 2.924558586271153

Epoch: 6| Step: 6
Training loss: 2.9395944149494255
Validation loss: 2.927780253785935

Epoch: 6| Step: 7
Training loss: 3.281697270018351
Validation loss: 2.9267555788727124

Epoch: 6| Step: 8
Training loss: 3.8794128148660554
Validation loss: 2.9264347790049996

Epoch: 6| Step: 9
Training loss: 2.856550812688476
Validation loss: 2.9267017821014845

Epoch: 6| Step: 10
Training loss: 3.109693961341393
Validation loss: 2.9273493063551377

Epoch: 6| Step: 11
Training loss: 3.226596046993809
Validation loss: 2.933777686015876

Epoch: 6| Step: 12
Training loss: 3.460556112592084
Validation loss: 2.930550778318712

Epoch: 6| Step: 13
Training loss: 3.460208307952547
Validation loss: 2.924954175384172

Epoch: 49| Step: 0
Training loss: 2.7850821165515134
Validation loss: 2.920522862488157

Epoch: 6| Step: 1
Training loss: 3.189093696258488
Validation loss: 2.9186791949309105

Epoch: 6| Step: 2
Training loss: 2.731259036540221
Validation loss: 2.9203078053839735

Epoch: 6| Step: 3
Training loss: 3.1105657243283273
Validation loss: 2.921226061333783

Epoch: 6| Step: 4
Training loss: 3.275655864241905
Validation loss: 2.920389923381084

Epoch: 6| Step: 5
Training loss: 3.455092754085056
Validation loss: 2.922057355746716

Epoch: 6| Step: 6
Training loss: 3.4097571560032014
Validation loss: 2.9217520023235832

Epoch: 6| Step: 7
Training loss: 2.7811402717118567
Validation loss: 2.918856218787351

Epoch: 6| Step: 8
Training loss: 3.0077757201485027
Validation loss: 2.92008330432259

Epoch: 6| Step: 9
Training loss: 3.2816429266225113
Validation loss: 2.9202625966607294

Epoch: 6| Step: 10
Training loss: 3.091063440773297
Validation loss: 2.917893448526417

Epoch: 6| Step: 11
Training loss: 3.7855446127118277
Validation loss: 2.9160438476174364

Epoch: 6| Step: 12
Training loss: 3.035770309957078
Validation loss: 2.9160908606764555

Epoch: 6| Step: 13
Training loss: 4.263991270102892
Validation loss: 2.9145593393115385

Epoch: 50| Step: 0
Training loss: 3.4952684845623527
Validation loss: 2.9137663265847484

Epoch: 6| Step: 1
Training loss: 2.84213412141928
Validation loss: 2.9138552363184997

Epoch: 6| Step: 2
Training loss: 3.5725161640290075
Validation loss: 2.913499049633724

Epoch: 6| Step: 3
Training loss: 3.315559845337239
Validation loss: 2.910916064712671

Epoch: 6| Step: 4
Training loss: 2.826574416844524
Validation loss: 2.910211756798283

Epoch: 6| Step: 5
Training loss: 3.3962587585448603
Validation loss: 2.9098584120909603

Epoch: 6| Step: 6
Training loss: 4.055182807084898
Validation loss: 2.90854406656114

Epoch: 6| Step: 7
Training loss: 3.131196249616635
Validation loss: 2.90782426865657

Epoch: 6| Step: 8
Training loss: 2.600138323112139
Validation loss: 2.9073940269940826

Epoch: 6| Step: 9
Training loss: 3.1097871900159824
Validation loss: 2.9070928760300867

Epoch: 6| Step: 10
Training loss: 3.676597123605163
Validation loss: 2.906375490201281

Epoch: 6| Step: 11
Training loss: 2.832838314420612
Validation loss: 2.9036262004241347

Epoch: 6| Step: 12
Training loss: 3.079744019708247
Validation loss: 2.9026931439547594

Epoch: 6| Step: 13
Training loss: 1.9822123600030663
Validation loss: 2.903084767184683

Epoch: 51| Step: 0
Training loss: 2.362807852250215
Validation loss: 2.9016594562110027

Epoch: 6| Step: 1
Training loss: 3.7531117562116716
Validation loss: 2.9031209571254166

Epoch: 6| Step: 2
Training loss: 3.0086759046394005
Validation loss: 2.902234981916088

Epoch: 6| Step: 3
Training loss: 2.933738410318934
Validation loss: 2.897178042592402

Epoch: 6| Step: 4
Training loss: 3.3961822392931498
Validation loss: 2.896801009954909

Epoch: 6| Step: 5
Training loss: 2.6507298274270568
Validation loss: 2.8957665318341315

Epoch: 6| Step: 6
Training loss: 3.919953745744255
Validation loss: 2.8973136854567016

Epoch: 6| Step: 7
Training loss: 3.050638701055076
Validation loss: 2.9089158598108975

Epoch: 6| Step: 8
Training loss: 2.948329685425285
Validation loss: 2.913092662780181

Epoch: 6| Step: 9
Training loss: 3.3046635475823747
Validation loss: 2.900952451999945

Epoch: 6| Step: 10
Training loss: 3.4195498575144865
Validation loss: 2.902207794558225

Epoch: 6| Step: 11
Training loss: 3.0240730189433864
Validation loss: 2.895051507293441

Epoch: 6| Step: 12
Training loss: 3.257556054430055
Validation loss: 2.8911810856937774

Epoch: 6| Step: 13
Training loss: 3.5696045822722855
Validation loss: 2.8928085536369985

Epoch: 52| Step: 0
Training loss: 2.4299043515693945
Validation loss: 2.8947329433817437

Epoch: 6| Step: 1
Training loss: 3.3970767749985242
Validation loss: 2.8939626008194446

Epoch: 6| Step: 2
Training loss: 3.017232199781764
Validation loss: 2.900481060186123

Epoch: 6| Step: 3
Training loss: 3.6632430536902896
Validation loss: 2.909629762811007

Epoch: 6| Step: 4
Training loss: 2.9441835379816705
Validation loss: 2.8983480801620214

Epoch: 6| Step: 5
Training loss: 2.9664394020155003
Validation loss: 2.891794323731311

Epoch: 6| Step: 6
Training loss: 3.5323033745017716
Validation loss: 2.8888772342921136

Epoch: 6| Step: 7
Training loss: 3.3371721256665325
Validation loss: 2.885894473431398

Epoch: 6| Step: 8
Training loss: 3.74115753334861
Validation loss: 2.8857040774489198

Epoch: 6| Step: 9
Training loss: 3.3740183497609975
Validation loss: 2.8851262440243257

Epoch: 6| Step: 10
Training loss: 2.5062012056466685
Validation loss: 2.8865769679077973

Epoch: 6| Step: 11
Training loss: 3.1669834547366493
Validation loss: 2.8873438515162495

Epoch: 6| Step: 12
Training loss: 3.2733499519822336
Validation loss: 2.8891988218721725

Epoch: 6| Step: 13
Training loss: 2.7702702019351353
Validation loss: 2.8888580873055267

Epoch: 53| Step: 0
Training loss: 2.8595857803117113
Validation loss: 2.888342906209239

Epoch: 6| Step: 1
Training loss: 2.7788873130790144
Validation loss: 2.8879789001716225

Epoch: 6| Step: 2
Training loss: 3.5509658950117533
Validation loss: 2.886322199838013

Epoch: 6| Step: 3
Training loss: 2.8901766042636576
Validation loss: 2.884066728434575

Epoch: 6| Step: 4
Training loss: 2.2304625502732356
Validation loss: 2.8851718415934284

Epoch: 6| Step: 5
Training loss: 3.1409764638830837
Validation loss: 2.8817340033856955

Epoch: 6| Step: 6
Training loss: 2.8673335149936876
Validation loss: 2.8818045545175033

Epoch: 6| Step: 7
Training loss: 3.1824736514502825
Validation loss: 2.882824325681777

Epoch: 6| Step: 8
Training loss: 3.3760555170927193
Validation loss: 2.885604698268248

Epoch: 6| Step: 9
Training loss: 4.120018002368892
Validation loss: 2.8911608251744987

Epoch: 6| Step: 10
Training loss: 3.8190273003173005
Validation loss: 2.897260389666276

Epoch: 6| Step: 11
Training loss: 3.1954793350203334
Validation loss: 2.878478554496277

Epoch: 6| Step: 12
Training loss: 2.7270755667657225
Validation loss: 2.877810518261155

Epoch: 6| Step: 13
Training loss: 3.468142344544336
Validation loss: 2.876276992607233

Epoch: 54| Step: 0
Training loss: 3.4906903840500956
Validation loss: 2.8765554888250606

Epoch: 6| Step: 1
Training loss: 3.418176053981237
Validation loss: 2.879431363052029

Epoch: 6| Step: 2
Training loss: 3.231993457258797
Validation loss: 2.881145423132176

Epoch: 6| Step: 3
Training loss: 3.318577643047848
Validation loss: 2.8925469383322286

Epoch: 6| Step: 4
Training loss: 2.755462596292657
Validation loss: 2.8874422155034685

Epoch: 6| Step: 5
Training loss: 3.572231853611211
Validation loss: 2.883846451142009

Epoch: 6| Step: 6
Training loss: 2.509839056105975
Validation loss: 2.878287168284919

Epoch: 6| Step: 7
Training loss: 3.9368281926656254
Validation loss: 2.8779985058084585

Epoch: 6| Step: 8
Training loss: 3.2739486113228042
Validation loss: 2.8760658203928693

Epoch: 6| Step: 9
Training loss: 3.227553245524813
Validation loss: 2.8751815330187624

Epoch: 6| Step: 10
Training loss: 2.830019321712679
Validation loss: 2.8737463373459007

Epoch: 6| Step: 11
Training loss: 3.0850420847886326
Validation loss: 2.8714588483684715

Epoch: 6| Step: 12
Training loss: 2.794637029755792
Validation loss: 2.8719343325403783

Epoch: 6| Step: 13
Training loss: 2.48136796646847
Validation loss: 2.866717817542231

Epoch: 55| Step: 0
Training loss: 2.815309943419134
Validation loss: 2.8651976868342617

Epoch: 6| Step: 1
Training loss: 3.2299358477289197
Validation loss: 2.8683944789980202

Epoch: 6| Step: 2
Training loss: 3.272283746788262
Validation loss: 2.867688739886786

Epoch: 6| Step: 3
Training loss: 2.8592235754389166
Validation loss: 2.8682934436285152

Epoch: 6| Step: 4
Training loss: 3.4953366957037213
Validation loss: 2.8704429185134814

Epoch: 6| Step: 5
Training loss: 3.634788189243503
Validation loss: 2.8685308778941287

Epoch: 6| Step: 6
Training loss: 3.7658343118451216
Validation loss: 2.8703260991454944

Epoch: 6| Step: 7
Training loss: 2.355481807236042
Validation loss: 2.8711193001822464

Epoch: 6| Step: 8
Training loss: 2.995936343597797
Validation loss: 2.8817673638441064

Epoch: 6| Step: 9
Training loss: 3.483991114249214
Validation loss: 2.859684826558745

Epoch: 6| Step: 10
Training loss: 2.997859031930886
Validation loss: 2.8565688156831595

Epoch: 6| Step: 11
Training loss: 3.1032584139599906
Validation loss: 2.8575039430691076

Epoch: 6| Step: 12
Training loss: 2.7551415669092103
Validation loss: 2.8575861729569865

Epoch: 6| Step: 13
Training loss: 3.3418847701766548
Validation loss: 2.8611299116780216

Epoch: 56| Step: 0
Training loss: 2.4099255517880906
Validation loss: 2.8574606134607063

Epoch: 6| Step: 1
Training loss: 3.2163248648086418
Validation loss: 2.857633068511217

Epoch: 6| Step: 2
Training loss: 4.062801878056792
Validation loss: 2.8607993995674637

Epoch: 6| Step: 3
Training loss: 2.709806970569864
Validation loss: 2.8648853978767983

Epoch: 6| Step: 4
Training loss: 2.393405469198697
Validation loss: 2.868874024925894

Epoch: 6| Step: 5
Training loss: 3.8117992820293534
Validation loss: 2.879439975189516

Epoch: 6| Step: 6
Training loss: 3.4493094375110975
Validation loss: 2.8614129802818034

Epoch: 6| Step: 7
Training loss: 2.8828586481634035
Validation loss: 2.854237251914929

Epoch: 6| Step: 8
Training loss: 2.509362048047988
Validation loss: 2.8513176808862095

Epoch: 6| Step: 9
Training loss: 2.9853522014024505
Validation loss: 2.8516830358176097

Epoch: 6| Step: 10
Training loss: 3.120367966007556
Validation loss: 2.8505748882102813

Epoch: 6| Step: 11
Training loss: 3.2870351020277973
Validation loss: 2.848260599295665

Epoch: 6| Step: 12
Training loss: 3.453775750201252
Validation loss: 2.850361852301057

Epoch: 6| Step: 13
Training loss: 3.6363758617975894
Validation loss: 2.852293668386772

Epoch: 57| Step: 0
Training loss: 3.6572694579844214
Validation loss: 2.854031248737215

Epoch: 6| Step: 1
Training loss: 3.0822998239285293
Validation loss: 2.8568770343020398

Epoch: 6| Step: 2
Training loss: 2.5612815192960823
Validation loss: 2.8593733198202536

Epoch: 6| Step: 3
Training loss: 3.5595980419444615
Validation loss: 2.8573553595023715

Epoch: 6| Step: 4
Training loss: 3.14835359447362
Validation loss: 2.8599645100066797

Epoch: 6| Step: 5
Training loss: 3.0245933196291874
Validation loss: 2.8602833736427398

Epoch: 6| Step: 6
Training loss: 3.0229646377034687
Validation loss: 2.8617093698644385

Epoch: 6| Step: 7
Training loss: 3.2679961872522156
Validation loss: 2.8516833630507303

Epoch: 6| Step: 8
Training loss: 3.1033618233503515
Validation loss: 2.8492478039906013

Epoch: 6| Step: 9
Training loss: 3.343994131712807
Validation loss: 2.8513651039081176

Epoch: 6| Step: 10
Training loss: 3.0807505607130845
Validation loss: 2.848039956012229

Epoch: 6| Step: 11
Training loss: 3.0444551688915746
Validation loss: 2.8575789267882223

Epoch: 6| Step: 12
Training loss: 2.691691124709491
Validation loss: 2.861456547487457

Epoch: 6| Step: 13
Training loss: 3.5545989643850713
Validation loss: 2.875713837591134

Epoch: 58| Step: 0
Training loss: 3.7847594061997367
Validation loss: 2.8562921834673096

Epoch: 6| Step: 1
Training loss: 3.1029905783743494
Validation loss: 2.8468175730240786

Epoch: 6| Step: 2
Training loss: 2.909015611194253
Validation loss: 2.839784533247516

Epoch: 6| Step: 3
Training loss: 3.0703716709171873
Validation loss: 2.835974243978262

Epoch: 6| Step: 4
Training loss: 3.2625247530527988
Validation loss: 2.8366291311612946

Epoch: 6| Step: 5
Training loss: 3.107942797660973
Validation loss: 2.8340868198324625

Epoch: 6| Step: 6
Training loss: 2.7183749060742826
Validation loss: 2.8349642779632855

Epoch: 6| Step: 7
Training loss: 3.324052494970386
Validation loss: 2.8328131615046144

Epoch: 6| Step: 8
Training loss: 3.7384815062774246
Validation loss: 2.835249452566192

Epoch: 6| Step: 9
Training loss: 3.020457926257135
Validation loss: 2.8321144711293385

Epoch: 6| Step: 10
Training loss: 3.5334486066860102
Validation loss: 2.8305815381724786

Epoch: 6| Step: 11
Training loss: 1.7940417966194595
Validation loss: 2.82996308812587

Epoch: 6| Step: 12
Training loss: 3.087668867551139
Validation loss: 2.8288454425240133

Epoch: 6| Step: 13
Training loss: 2.992226383763343
Validation loss: 2.827155262928589

Epoch: 59| Step: 0
Training loss: 2.780339638525157
Validation loss: 2.8292134575073

Epoch: 6| Step: 1
Training loss: 3.154846181369321
Validation loss: 2.827589302586872

Epoch: 6| Step: 2
Training loss: 2.4633499189170354
Validation loss: 2.8270453386074066

Epoch: 6| Step: 3
Training loss: 3.1404336899521264
Validation loss: 2.825928314406663

Epoch: 6| Step: 4
Training loss: 3.573773932788791
Validation loss: 2.824933291704033

Epoch: 6| Step: 5
Training loss: 2.396101419680982
Validation loss: 2.8247106647343116

Epoch: 6| Step: 6
Training loss: 3.2949065347708997
Validation loss: 2.8260498120297153

Epoch: 6| Step: 7
Training loss: 2.7220407499000103
Validation loss: 2.8215989952194955

Epoch: 6| Step: 8
Training loss: 3.6680906882853037
Validation loss: 2.821319712010569

Epoch: 6| Step: 9
Training loss: 3.2635032660478345
Validation loss: 2.823831601048589

Epoch: 6| Step: 10
Training loss: 3.4684813799249006
Validation loss: 2.8206834987379628

Epoch: 6| Step: 11
Training loss: 2.3184427762154693
Validation loss: 2.819272513564028

Epoch: 6| Step: 12
Training loss: 3.8433953098308002
Validation loss: 2.818727727675193

Epoch: 6| Step: 13
Training loss: 3.4283909182486876
Validation loss: 2.818227991647818

Epoch: 60| Step: 0
Training loss: 3.1455117539171207
Validation loss: 2.819673980132671

Epoch: 6| Step: 1
Training loss: 2.977957491251705
Validation loss: 2.8172434858835262

Epoch: 6| Step: 2
Training loss: 3.154135118240214
Validation loss: 2.8183428316629464

Epoch: 6| Step: 3
Training loss: 3.308612773890113
Validation loss: 2.8239735384959816

Epoch: 6| Step: 4
Training loss: 3.036025228523706
Validation loss: 2.8256859766775526

Epoch: 6| Step: 5
Training loss: 3.2235912469393124
Validation loss: 2.826286295176152

Epoch: 6| Step: 6
Training loss: 2.608730030869887
Validation loss: 2.829308845313125

Epoch: 6| Step: 7
Training loss: 2.871764643129263
Validation loss: 2.828604328112339

Epoch: 6| Step: 8
Training loss: 3.2151872490775495
Validation loss: 2.8197368413496133

Epoch: 6| Step: 9
Training loss: 2.9706167676263022
Validation loss: 2.8180209044805964

Epoch: 6| Step: 10
Training loss: 3.3711807398882745
Validation loss: 2.8157001505864163

Epoch: 6| Step: 11
Training loss: 2.94868191513108
Validation loss: 2.8144152884414253

Epoch: 6| Step: 12
Training loss: 3.7941621107217496
Validation loss: 2.8146096661009286

Epoch: 6| Step: 13
Training loss: 2.8490830602779544
Validation loss: 2.8164839644598403

Epoch: 61| Step: 0
Training loss: 3.485443772421304
Validation loss: 2.8128762288640576

Epoch: 6| Step: 1
Training loss: 2.892115358249453
Validation loss: 2.810019113773938

Epoch: 6| Step: 2
Training loss: 3.3005308880180517
Validation loss: 2.806608217597921

Epoch: 6| Step: 3
Training loss: 3.433967856379477
Validation loss: 2.806350086801726

Epoch: 6| Step: 4
Training loss: 2.661903468542047
Validation loss: 2.8090356489441763

Epoch: 6| Step: 5
Training loss: 3.363961429025559
Validation loss: 2.809769255233118

Epoch: 6| Step: 6
Training loss: 3.4362806064745506
Validation loss: 2.8052455668979004

Epoch: 6| Step: 7
Training loss: 2.4532468729056576
Validation loss: 2.804371959358158

Epoch: 6| Step: 8
Training loss: 3.2973308519271027
Validation loss: 2.805660678014035

Epoch: 6| Step: 9
Training loss: 3.0376288555427373
Validation loss: 2.805754930401414

Epoch: 6| Step: 10
Training loss: 2.540031177900104
Validation loss: 2.8027077216430696

Epoch: 6| Step: 11
Training loss: 3.02474087953095
Validation loss: 2.804523233893448

Epoch: 6| Step: 12
Training loss: 2.856282046616156
Validation loss: 2.803712782706305

Epoch: 6| Step: 13
Training loss: 3.8934545071134967
Validation loss: 2.806817262009813

Epoch: 62| Step: 0
Training loss: 3.419162737882624
Validation loss: 2.804498653387943

Epoch: 6| Step: 1
Training loss: 2.961902310240862
Validation loss: 2.8060848619145817

Epoch: 6| Step: 2
Training loss: 3.2346242909948666
Validation loss: 2.8064817750045696

Epoch: 6| Step: 3
Training loss: 3.231749865238225
Validation loss: 2.80406986121831

Epoch: 6| Step: 4
Training loss: 2.6862090802881413
Validation loss: 2.8031306247899623

Epoch: 6| Step: 5
Training loss: 3.23160541284228
Validation loss: 2.8041269541612563

Epoch: 6| Step: 6
Training loss: 3.1445509631563766
Validation loss: 2.7997171316959575

Epoch: 6| Step: 7
Training loss: 3.415862632365851
Validation loss: 2.801031844393938

Epoch: 6| Step: 8
Training loss: 2.339054337501936
Validation loss: 2.799574846300564

Epoch: 6| Step: 9
Training loss: 3.046705661860799
Validation loss: 2.8059214597010476

Epoch: 6| Step: 10
Training loss: 2.9093839094146445
Validation loss: 2.799947653411511

Epoch: 6| Step: 11
Training loss: 3.46491104628312
Validation loss: 2.799025374785761

Epoch: 6| Step: 12
Training loss: 3.2922233561485497
Validation loss: 2.7969303094699116

Epoch: 6| Step: 13
Training loss: 2.9681839252662536
Validation loss: 2.797795828665913

Epoch: 63| Step: 0
Training loss: 3.3150705404241823
Validation loss: 2.799110051646758

Epoch: 6| Step: 1
Training loss: 2.89112462030425
Validation loss: 2.7978350765795796

Epoch: 6| Step: 2
Training loss: 3.6143793200579677
Validation loss: 2.8028731103236306

Epoch: 6| Step: 3
Training loss: 2.6534065735195904
Validation loss: 2.789839264164285

Epoch: 6| Step: 4
Training loss: 3.1809425969921064
Validation loss: 2.7924539098553964

Epoch: 6| Step: 5
Training loss: 2.6823075278594044
Validation loss: 2.7929675365479496

Epoch: 6| Step: 6
Training loss: 2.9555102207018082
Validation loss: 2.798403000521182

Epoch: 6| Step: 7
Training loss: 3.141209941689048
Validation loss: 2.8087901925943504

Epoch: 6| Step: 8
Training loss: 3.3577503622846
Validation loss: 2.814780873900918

Epoch: 6| Step: 9
Training loss: 3.117009284486916
Validation loss: 2.8184959022606444

Epoch: 6| Step: 10
Training loss: 3.1168922533070638
Validation loss: 2.7956193268553413

Epoch: 6| Step: 11
Training loss: 3.052733906399916
Validation loss: 2.788705628962572

Epoch: 6| Step: 12
Training loss: 3.2054977932608373
Validation loss: 2.801681845384858

Epoch: 6| Step: 13
Training loss: 3.3487878798577593
Validation loss: 2.8768910078284904

Epoch: 64| Step: 0
Training loss: 2.5753165004251537
Validation loss: 2.963900616469068

Epoch: 6| Step: 1
Training loss: 4.126954049337331
Validation loss: 2.9935018087808816

Epoch: 6| Step: 2
Training loss: 3.044759475654424
Validation loss: 2.8441839039239

Epoch: 6| Step: 3
Training loss: 2.8369854968953803
Validation loss: 2.782659266006708

Epoch: 6| Step: 4
Training loss: 3.4691123429485597
Validation loss: 2.7920254219843055

Epoch: 6| Step: 5
Training loss: 2.7886832698018003
Validation loss: 2.821913643414995

Epoch: 6| Step: 6
Training loss: 3.3761871510559183
Validation loss: 2.842066752009786

Epoch: 6| Step: 7
Training loss: 2.3189030229196326
Validation loss: 2.8266097542980426

Epoch: 6| Step: 8
Training loss: 2.585304666860272
Validation loss: 2.874200348576536

Epoch: 6| Step: 9
Training loss: 3.471464177778255
Validation loss: 2.8895267882557234

Epoch: 6| Step: 10
Training loss: 3.962064263005098
Validation loss: 2.864466241287391

Epoch: 6| Step: 11
Training loss: 2.915066707103004
Validation loss: 2.810346014193084

Epoch: 6| Step: 12
Training loss: 3.107160690331608
Validation loss: 2.798333177528474

Epoch: 6| Step: 13
Training loss: 3.2255945116068303
Validation loss: 2.8273226616761553

Epoch: 65| Step: 0
Training loss: 3.3460896230347537
Validation loss: 2.8710024569916195

Epoch: 6| Step: 1
Training loss: 3.222992998504372
Validation loss: 2.893273158867018

Epoch: 6| Step: 2
Training loss: 2.3729912143035046
Validation loss: 2.8883333327359297

Epoch: 6| Step: 3
Training loss: 3.4531015248601094
Validation loss: 2.8644388726614234

Epoch: 6| Step: 4
Training loss: 3.3382924542818206
Validation loss: 2.8460442349588817

Epoch: 6| Step: 5
Training loss: 3.281414064211224
Validation loss: 2.8471233612539857

Epoch: 6| Step: 6
Training loss: 2.8746367515300206
Validation loss: 2.851996790188031

Epoch: 6| Step: 7
Training loss: 3.7915748054080223
Validation loss: 2.808380587578788

Epoch: 6| Step: 8
Training loss: 2.9781283367574596
Validation loss: 2.8106481856865395

Epoch: 6| Step: 9
Training loss: 3.031854313654209
Validation loss: 2.808069770163797

Epoch: 6| Step: 10
Training loss: 2.925860456099938
Validation loss: 2.7993247378147785

Epoch: 6| Step: 11
Training loss: 3.449123912643689
Validation loss: 2.800674934169708

Epoch: 6| Step: 12
Training loss: 2.6906977414389956
Validation loss: 2.7957772718633707

Epoch: 6| Step: 13
Training loss: 2.76090877153166
Validation loss: 2.7861443004618103

Epoch: 66| Step: 0
Training loss: 2.894074727040717
Validation loss: 2.784450271992372

Epoch: 6| Step: 1
Training loss: 3.2694650367586
Validation loss: 2.78459586062394

Epoch: 6| Step: 2
Training loss: 3.3438917468677882
Validation loss: 2.7818424118870277

Epoch: 6| Step: 3
Training loss: 2.417394024361472
Validation loss: 2.7798101337375796

Epoch: 6| Step: 4
Training loss: 2.4071677303282364
Validation loss: 2.7761231257154595

Epoch: 6| Step: 5
Training loss: 3.79943121116587
Validation loss: 2.7805502549244405

Epoch: 6| Step: 6
Training loss: 2.844229018560561
Validation loss: 2.778684954396637

Epoch: 6| Step: 7
Training loss: 2.678848624645646
Validation loss: 2.776476886514775

Epoch: 6| Step: 8
Training loss: 3.2965711119110157
Validation loss: 2.7762041000338904

Epoch: 6| Step: 9
Training loss: 3.3186318126833982
Validation loss: 2.773362376657143

Epoch: 6| Step: 10
Training loss: 2.697980273661739
Validation loss: 2.772826319426307

Epoch: 6| Step: 11
Training loss: 3.083322851489697
Validation loss: 2.773244391834159

Epoch: 6| Step: 12
Training loss: 3.770947126213616
Validation loss: 2.7718863314094913

Epoch: 6| Step: 13
Training loss: 3.1144856381271206
Validation loss: 2.772837811666856

Epoch: 67| Step: 0
Training loss: 3.573167056252709
Validation loss: 2.775982037649767

Epoch: 6| Step: 1
Training loss: 3.246781736471842
Validation loss: 2.7723505746827337

Epoch: 6| Step: 2
Training loss: 2.6510792387952296
Validation loss: 2.7779788240532697

Epoch: 6| Step: 3
Training loss: 2.850369640271528
Validation loss: 2.7766407067457557

Epoch: 6| Step: 4
Training loss: 3.8967272842909098
Validation loss: 2.7848853290574653

Epoch: 6| Step: 5
Training loss: 2.817665696776373
Validation loss: 2.781456256079641

Epoch: 6| Step: 6
Training loss: 2.943988856771361
Validation loss: 2.78350332855001

Epoch: 6| Step: 7
Training loss: 3.6165346417449684
Validation loss: 2.7765294427037372

Epoch: 6| Step: 8
Training loss: 3.183991090282837
Validation loss: 2.7669640584232895

Epoch: 6| Step: 9
Training loss: 3.260382573901143
Validation loss: 2.7623402303719415

Epoch: 6| Step: 10
Training loss: 3.0143654520262038
Validation loss: 2.7653369043221767

Epoch: 6| Step: 11
Training loss: 2.985039921530344
Validation loss: 2.7634131716003463

Epoch: 6| Step: 12
Training loss: 2.073954132499892
Validation loss: 2.760745669768777

Epoch: 6| Step: 13
Training loss: 2.4463290213178586
Validation loss: 2.761525388653253

Epoch: 68| Step: 0
Training loss: 3.5310682401888127
Validation loss: 2.760742776235883

Epoch: 6| Step: 1
Training loss: 2.911791368975537
Validation loss: 2.7609961410919017

Epoch: 6| Step: 2
Training loss: 3.150510498339354
Validation loss: 2.760448192030227

Epoch: 6| Step: 3
Training loss: 3.927487677172992
Validation loss: 2.759808873050048

Epoch: 6| Step: 4
Training loss: 2.842257600646468
Validation loss: 2.7623257190565633

Epoch: 6| Step: 5
Training loss: 3.2193419273305466
Validation loss: 2.774044786467776

Epoch: 6| Step: 6
Training loss: 3.1247625642220678
Validation loss: 2.782529836266076

Epoch: 6| Step: 7
Training loss: 2.747967055299557
Validation loss: 2.767551984353871

Epoch: 6| Step: 8
Training loss: 2.327554722520638
Validation loss: 2.7646032111695598

Epoch: 6| Step: 9
Training loss: 2.187666532444498
Validation loss: 2.762502080756678

Epoch: 6| Step: 10
Training loss: 3.259512697787596
Validation loss: 2.7604931465338134

Epoch: 6| Step: 11
Training loss: 2.52170042357843
Validation loss: 2.758982928759886

Epoch: 6| Step: 12
Training loss: 3.5690485680744684
Validation loss: 2.758605800171402

Epoch: 6| Step: 13
Training loss: 3.436620426354063
Validation loss: 2.754622271098917

Epoch: 69| Step: 0
Training loss: 2.920090400655097
Validation loss: 2.753000030674082

Epoch: 6| Step: 1
Training loss: 2.872479038411045
Validation loss: 2.753503561676698

Epoch: 6| Step: 2
Training loss: 3.0266298301348495
Validation loss: 2.759793678669843

Epoch: 6| Step: 3
Training loss: 2.685866813328693
Validation loss: 2.76947169248028

Epoch: 6| Step: 4
Training loss: 2.3231609084931004
Validation loss: 2.773799694074016

Epoch: 6| Step: 5
Training loss: 3.785005580237847
Validation loss: 2.7620621438846173

Epoch: 6| Step: 6
Training loss: 3.1300345492665174
Validation loss: 2.750643787183938

Epoch: 6| Step: 7
Training loss: 3.8616467172247053
Validation loss: 2.7526123125608852

Epoch: 6| Step: 8
Training loss: 2.5846152252766625
Validation loss: 2.7463550724814114

Epoch: 6| Step: 9
Training loss: 2.7307969579601203
Validation loss: 2.746528783926058

Epoch: 6| Step: 10
Training loss: 2.9106441626430946
Validation loss: 2.746676269197967

Epoch: 6| Step: 11
Training loss: 3.2602420227922
Validation loss: 2.744349750433817

Epoch: 6| Step: 12
Training loss: 3.7124064218563193
Validation loss: 2.748381331277566

Epoch: 6| Step: 13
Training loss: 2.486536297470132
Validation loss: 2.7445984310606684

Epoch: 70| Step: 0
Training loss: 2.842525344239098
Validation loss: 2.74357815920862

Epoch: 6| Step: 1
Training loss: 3.4159927323775516
Validation loss: 2.7440595416110414

Epoch: 6| Step: 2
Training loss: 2.773351361723525
Validation loss: 2.7429314790155446

Epoch: 6| Step: 3
Training loss: 3.341943270555082
Validation loss: 2.742649915020932

Epoch: 6| Step: 4
Training loss: 3.0467645087137303
Validation loss: 2.7399723415147954

Epoch: 6| Step: 5
Training loss: 2.7970846939329848
Validation loss: 2.742676543516055

Epoch: 6| Step: 6
Training loss: 3.3839984603319206
Validation loss: 2.7432786254677

Epoch: 6| Step: 7
Training loss: 3.236227343595254
Validation loss: 2.738752891406567

Epoch: 6| Step: 8
Training loss: 3.130326271480014
Validation loss: 2.740404996253263

Epoch: 6| Step: 9
Training loss: 3.1627589425085763
Validation loss: 2.740994697239351

Epoch: 6| Step: 10
Training loss: 2.837456750750208
Validation loss: 2.7408958393744745

Epoch: 6| Step: 11
Training loss: 2.7489461613528117
Validation loss: 2.748188089364872

Epoch: 6| Step: 12
Training loss: 2.8005185396424976
Validation loss: 2.745003679089511

Epoch: 6| Step: 13
Training loss: 3.367915028440288
Validation loss: 2.7460193387352674

Epoch: 71| Step: 0
Training loss: 2.862002973425685
Validation loss: 2.7396996249346066

Epoch: 6| Step: 1
Training loss: 3.1232532960237225
Validation loss: 2.7503418015495673

Epoch: 6| Step: 2
Training loss: 2.997960987165511
Validation loss: 2.7512056154144515

Epoch: 6| Step: 3
Training loss: 3.1192243991176367
Validation loss: 2.748595211733632

Epoch: 6| Step: 4
Training loss: 2.885271052646737
Validation loss: 2.7460882877406445

Epoch: 6| Step: 5
Training loss: 3.128185632139035
Validation loss: 2.7468787954781297

Epoch: 6| Step: 6
Training loss: 3.039673260898286
Validation loss: 2.7456121219998653

Epoch: 6| Step: 7
Training loss: 2.418527171987246
Validation loss: 2.7406348878031963

Epoch: 6| Step: 8
Training loss: 3.187424303539756
Validation loss: 2.7338650848231483

Epoch: 6| Step: 9
Training loss: 3.4079077650044804
Validation loss: 2.7307581434759283

Epoch: 6| Step: 10
Training loss: 3.103052506843784
Validation loss: 2.734779527218499

Epoch: 6| Step: 11
Training loss: 3.2670725849216273
Validation loss: 2.7342301150141317

Epoch: 6| Step: 12
Training loss: 3.0969154270585944
Validation loss: 2.734564836185173

Epoch: 6| Step: 13
Training loss: 3.0743958786924135
Validation loss: 2.73546871502575

Epoch: 72| Step: 0
Training loss: 3.5528334257254657
Validation loss: 2.7367685425318125

Epoch: 6| Step: 1
Training loss: 3.228496867619815
Validation loss: 2.7346119673984934

Epoch: 6| Step: 2
Training loss: 2.625334037235618
Validation loss: 2.7385445499314103

Epoch: 6| Step: 3
Training loss: 2.723078822177124
Validation loss: 2.7348794104484218

Epoch: 6| Step: 4
Training loss: 2.2671378510794438
Validation loss: 2.739017782076809

Epoch: 6| Step: 5
Training loss: 3.2584997682593277
Validation loss: 2.7362404006347925

Epoch: 6| Step: 6
Training loss: 3.146189907320021
Validation loss: 2.736692590596585

Epoch: 6| Step: 7
Training loss: 3.528326394049215
Validation loss: 2.7341902550606823

Epoch: 6| Step: 8
Training loss: 3.1527648417636445
Validation loss: 2.7330578572407003

Epoch: 6| Step: 9
Training loss: 3.8175429464046693
Validation loss: 2.734538964953048

Epoch: 6| Step: 10
Training loss: 2.8661903081668174
Validation loss: 2.733550417278387

Epoch: 6| Step: 11
Training loss: 2.852292821717348
Validation loss: 2.7281216390762157

Epoch: 6| Step: 12
Training loss: 2.7980620353316783
Validation loss: 2.729467643242792

Epoch: 6| Step: 13
Training loss: 2.5127177053996355
Validation loss: 2.7239549916379695

Epoch: 73| Step: 0
Training loss: 3.335063739493501
Validation loss: 2.72342361462564

Epoch: 6| Step: 1
Training loss: 2.598671988471845
Validation loss: 2.7194510784044024

Epoch: 6| Step: 2
Training loss: 2.2943024014319273
Validation loss: 2.7177632707325756

Epoch: 6| Step: 3
Training loss: 3.716965447520534
Validation loss: 2.720481723681756

Epoch: 6| Step: 4
Training loss: 2.7923213608583644
Validation loss: 2.7235010068631964

Epoch: 6| Step: 5
Training loss: 3.001525173322534
Validation loss: 2.726094558436371

Epoch: 6| Step: 6
Training loss: 3.4181994899794685
Validation loss: 2.743685917569986

Epoch: 6| Step: 7
Training loss: 3.436624311401356
Validation loss: 2.75038836972585

Epoch: 6| Step: 8
Training loss: 2.7641719298321727
Validation loss: 2.734545978409885

Epoch: 6| Step: 9
Training loss: 2.9236573683541884
Validation loss: 2.7193504587902915

Epoch: 6| Step: 10
Training loss: 2.4891172049833337
Validation loss: 2.714301536335684

Epoch: 6| Step: 11
Training loss: 3.0580190457236838
Validation loss: 2.716012641489065

Epoch: 6| Step: 12
Training loss: 3.4763138242786145
Validation loss: 2.715452252408629

Epoch: 6| Step: 13
Training loss: 3.1170969402572224
Validation loss: 2.714133280906301

Epoch: 74| Step: 0
Training loss: 3.296784458453863
Validation loss: 2.7164093963492424

Epoch: 6| Step: 1
Training loss: 3.289413034783458
Validation loss: 2.7188554643621567

Epoch: 6| Step: 2
Training loss: 3.0608201382673963
Validation loss: 2.716791603899089

Epoch: 6| Step: 3
Training loss: 2.649847594862953
Validation loss: 2.7179670534874734

Epoch: 6| Step: 4
Training loss: 2.73871359901491
Validation loss: 2.7205941529039017

Epoch: 6| Step: 5
Training loss: 3.0623919409547193
Validation loss: 2.7211477521774223

Epoch: 6| Step: 6
Training loss: 3.42442220004701
Validation loss: 2.715479476150359

Epoch: 6| Step: 7
Training loss: 2.848165416853497
Validation loss: 2.711945937732246

Epoch: 6| Step: 8
Training loss: 2.3574005353541714
Validation loss: 2.7058390532354872

Epoch: 6| Step: 9
Training loss: 3.2053301408194304
Validation loss: 2.7052085140473863

Epoch: 6| Step: 10
Training loss: 3.1930599713904524
Validation loss: 2.7055606342853746

Epoch: 6| Step: 11
Training loss: 3.42707088819909
Validation loss: 2.7069115872348193

Epoch: 6| Step: 12
Training loss: 3.1512571823359057
Validation loss: 2.7091981237588567

Epoch: 6| Step: 13
Training loss: 2.6347454457680275
Validation loss: 2.709232070138478

Epoch: 75| Step: 0
Training loss: 2.3307335084558605
Validation loss: 2.7044737381195345

Epoch: 6| Step: 1
Training loss: 3.885726848149228
Validation loss: 2.7080149315903324

Epoch: 6| Step: 2
Training loss: 2.3427496237456844
Validation loss: 2.7030287775338926

Epoch: 6| Step: 3
Training loss: 2.9052296149531083
Validation loss: 2.7060143632546936

Epoch: 6| Step: 4
Training loss: 2.9939052342443544
Validation loss: 2.704318456767821

Epoch: 6| Step: 5
Training loss: 3.1086018430149585
Validation loss: 2.700483721885716

Epoch: 6| Step: 6
Training loss: 2.811849900451818
Validation loss: 2.7003415394183627

Epoch: 6| Step: 7
Training loss: 3.3271133246331077
Validation loss: 2.702287774637757

Epoch: 6| Step: 8
Training loss: 2.855929607560355
Validation loss: 2.698222282515315

Epoch: 6| Step: 9
Training loss: 4.096527787894547
Validation loss: 2.700162397534613

Epoch: 6| Step: 10
Training loss: 2.8577449300462554
Validation loss: 2.699953801433231

Epoch: 6| Step: 11
Training loss: 3.00756200762949
Validation loss: 2.6973192987917796

Epoch: 6| Step: 12
Training loss: 2.675696779574544
Validation loss: 2.701298094608659

Epoch: 6| Step: 13
Training loss: 2.5056026621598564
Validation loss: 2.7001310174298174

Epoch: 76| Step: 0
Training loss: 4.080230520131443
Validation loss: 2.7013023406114276

Epoch: 6| Step: 1
Training loss: 3.4983005484949543
Validation loss: 2.699819702211423

Epoch: 6| Step: 2
Training loss: 2.836576531663285
Validation loss: 2.7006218985119723

Epoch: 6| Step: 3
Training loss: 3.7105991570676498
Validation loss: 2.696414981101169

Epoch: 6| Step: 4
Training loss: 2.955943059814206
Validation loss: 2.6982513446937584

Epoch: 6| Step: 5
Training loss: 2.6036467579972684
Validation loss: 2.695359888621743

Epoch: 6| Step: 6
Training loss: 2.9541593486083677
Validation loss: 2.69445031018879

Epoch: 6| Step: 7
Training loss: 3.077854667449857
Validation loss: 2.694601697201867

Epoch: 6| Step: 8
Training loss: 2.690702083249958
Validation loss: 2.695607041073298

Epoch: 6| Step: 9
Training loss: 2.498805523666254
Validation loss: 2.696477852155049

Epoch: 6| Step: 10
Training loss: 2.823867375001723
Validation loss: 2.6941857601932875

Epoch: 6| Step: 11
Training loss: 2.388972091211593
Validation loss: 2.695799308663956

Epoch: 6| Step: 12
Training loss: 2.9066183205471496
Validation loss: 2.6970420278345473

Epoch: 6| Step: 13
Training loss: 2.892820771811186
Validation loss: 2.6975653831407898

Epoch: 77| Step: 0
Training loss: 3.053927978375871
Validation loss: 2.6939261098975895

Epoch: 6| Step: 1
Training loss: 2.935046530879491
Validation loss: 2.6956122965367713

Epoch: 6| Step: 2
Training loss: 2.7190276256306904
Validation loss: 2.6984162372714007

Epoch: 6| Step: 3
Training loss: 3.3271637723909153
Validation loss: 2.7038977236517208

Epoch: 6| Step: 4
Training loss: 2.6528219204925354
Validation loss: 2.7181723658426167

Epoch: 6| Step: 5
Training loss: 3.218045648339968
Validation loss: 2.7135581879172577

Epoch: 6| Step: 6
Training loss: 3.0070068865825017
Validation loss: 2.7074087080706195

Epoch: 6| Step: 7
Training loss: 3.26607178182495
Validation loss: 2.7030058045016148

Epoch: 6| Step: 8
Training loss: 3.202207257055463
Validation loss: 2.7002459592537815

Epoch: 6| Step: 9
Training loss: 2.6324310479186153
Validation loss: 2.6936798348853435

Epoch: 6| Step: 10
Training loss: 3.40554830340522
Validation loss: 2.6933336562261365

Epoch: 6| Step: 11
Training loss: 3.1559061297440167
Validation loss: 2.689163633649192

Epoch: 6| Step: 12
Training loss: 2.8353299417530007
Validation loss: 2.687996555404414

Epoch: 6| Step: 13
Training loss: 2.7579789151996414
Validation loss: 2.6867387250955486

Epoch: 78| Step: 0
Training loss: 2.7743942115017126
Validation loss: 2.685447659954014

Epoch: 6| Step: 1
Training loss: 2.894881789671536
Validation loss: 2.6864559685943847

Epoch: 6| Step: 2
Training loss: 3.762521184817267
Validation loss: 2.682631373117372

Epoch: 6| Step: 3
Training loss: 3.337156265216923
Validation loss: 2.6855573470134293

Epoch: 6| Step: 4
Training loss: 3.1927091630661817
Validation loss: 2.680593856267842

Epoch: 6| Step: 5
Training loss: 2.6124415851979883
Validation loss: 2.6839508331589577

Epoch: 6| Step: 6
Training loss: 2.9481985184328
Validation loss: 2.6805793394821364

Epoch: 6| Step: 7
Training loss: 3.506948385876412
Validation loss: 2.6820589491264424

Epoch: 6| Step: 8
Training loss: 2.550136607381768
Validation loss: 2.6834021727681194

Epoch: 6| Step: 9
Training loss: 2.9624740921368464
Validation loss: 2.6806507118855416

Epoch: 6| Step: 10
Training loss: 2.2698749538043286
Validation loss: 2.685654024583787

Epoch: 6| Step: 11
Training loss: 2.924164390211577
Validation loss: 2.681957868209229

Epoch: 6| Step: 12
Training loss: 3.075912377447601
Validation loss: 2.68207604058976

Epoch: 6| Step: 13
Training loss: 3.2617072008122627
Validation loss: 2.681058600521673

Epoch: 79| Step: 0
Training loss: 3.140830417576711
Validation loss: 2.6776648052291914

Epoch: 6| Step: 1
Training loss: 3.7642708397289883
Validation loss: 2.680528183420309

Epoch: 6| Step: 2
Training loss: 2.8941042195122204
Validation loss: 2.677322868878728

Epoch: 6| Step: 3
Training loss: 2.0633090195381354
Validation loss: 2.6769598345885237

Epoch: 6| Step: 4
Training loss: 2.538903240197613
Validation loss: 2.678202391407837

Epoch: 6| Step: 5
Training loss: 2.7002680680749704
Validation loss: 2.6760218933126265

Epoch: 6| Step: 6
Training loss: 3.4022079423150293
Validation loss: 2.6748388422608467

Epoch: 6| Step: 7
Training loss: 3.891962641067215
Validation loss: 2.6751882795627333

Epoch: 6| Step: 8
Training loss: 3.1675034638756987
Validation loss: 2.6755733592765694

Epoch: 6| Step: 9
Training loss: 2.7604730756262277
Validation loss: 2.6733893292673145

Epoch: 6| Step: 10
Training loss: 3.0927924013173733
Validation loss: 2.6730634273178357

Epoch: 6| Step: 11
Training loss: 2.768357817901178
Validation loss: 2.6708420759399067

Epoch: 6| Step: 12
Training loss: 2.713969445266713
Validation loss: 2.67273320287999

Epoch: 6| Step: 13
Training loss: 2.5258042895808726
Validation loss: 2.6824953146276034

Epoch: 80| Step: 0
Training loss: 3.1042597882599665
Validation loss: 2.68796182390882

Epoch: 6| Step: 1
Training loss: 2.7226140417168585
Validation loss: 2.702071460253738

Epoch: 6| Step: 2
Training loss: 3.0146079448406207
Validation loss: 2.7099392417003023

Epoch: 6| Step: 3
Training loss: 2.592323922309145
Validation loss: 2.7018262493628438

Epoch: 6| Step: 4
Training loss: 3.178691136171044
Validation loss: 2.6848428100176607

Epoch: 6| Step: 5
Training loss: 2.4888653750765886
Validation loss: 2.679987591370526

Epoch: 6| Step: 6
Training loss: 2.829007343044035
Validation loss: 2.6750186181572944

Epoch: 6| Step: 7
Training loss: 3.527710347436444
Validation loss: 2.6751550933281236

Epoch: 6| Step: 8
Training loss: 3.316303876143708
Validation loss: 2.669695649676149

Epoch: 6| Step: 9
Training loss: 3.084691513193399
Validation loss: 2.670265866993054

Epoch: 6| Step: 10
Training loss: 2.8545291048651897
Validation loss: 2.6772447354418594

Epoch: 6| Step: 11
Training loss: 2.8843272295102946
Validation loss: 2.6717020288357083

Epoch: 6| Step: 12
Training loss: 3.1598233683027397
Validation loss: 2.6715049149126706

Epoch: 6| Step: 13
Training loss: 3.5129615018946545
Validation loss: 2.6711545014862454

Epoch: 81| Step: 0
Training loss: 2.5079450245479435
Validation loss: 2.6757556142492898

Epoch: 6| Step: 1
Training loss: 2.648312996157451
Validation loss: 2.672124224859442

Epoch: 6| Step: 2
Training loss: 3.1777244713083226
Validation loss: 2.669837441962861

Epoch: 6| Step: 3
Training loss: 2.837912132144931
Validation loss: 2.668219099720209

Epoch: 6| Step: 4
Training loss: 3.146845943009935
Validation loss: 2.678937037899162

Epoch: 6| Step: 5
Training loss: 2.7248661043361486
Validation loss: 2.690455862822853

Epoch: 6| Step: 6
Training loss: 2.8997005373800127
Validation loss: 2.7063176917327034

Epoch: 6| Step: 7
Training loss: 2.999279889464583
Validation loss: 2.713973900040268

Epoch: 6| Step: 8
Training loss: 2.6852199730014226
Validation loss: 2.6976223505279653

Epoch: 6| Step: 9
Training loss: 3.4542258048584067
Validation loss: 2.6754263708181116

Epoch: 6| Step: 10
Training loss: 3.433620135972991
Validation loss: 2.6672160796527016

Epoch: 6| Step: 11
Training loss: 3.268713991393517
Validation loss: 2.664073497198719

Epoch: 6| Step: 12
Training loss: 3.410073190837715
Validation loss: 2.66156451405976

Epoch: 6| Step: 13
Training loss: 2.62991553965085
Validation loss: 2.6606580627064917

Epoch: 82| Step: 0
Training loss: 2.9890100724786635
Validation loss: 2.663009896069231

Epoch: 6| Step: 1
Training loss: 3.2016148426548763
Validation loss: 2.677270048600169

Epoch: 6| Step: 2
Training loss: 3.1287776239557226
Validation loss: 2.7253709116740796

Epoch: 6| Step: 3
Training loss: 3.3232770543002688
Validation loss: 2.6652640074916905

Epoch: 6| Step: 4
Training loss: 2.8138102552350293
Validation loss: 2.6600668144963637

Epoch: 6| Step: 5
Training loss: 3.2290286783248514
Validation loss: 2.659644523346824

Epoch: 6| Step: 6
Training loss: 2.875987671084234
Validation loss: 2.656610993014399

Epoch: 6| Step: 7
Training loss: 3.0900826343733687
Validation loss: 2.659915630519317

Epoch: 6| Step: 8
Training loss: 2.4844951480626944
Validation loss: 2.6628676506951034

Epoch: 6| Step: 9
Training loss: 3.235248539853472
Validation loss: 2.66765795889726

Epoch: 6| Step: 10
Training loss: 2.9985258931245333
Validation loss: 2.676753349423339

Epoch: 6| Step: 11
Training loss: 2.5088172872402676
Validation loss: 2.67669977851429

Epoch: 6| Step: 12
Training loss: 2.7469001985854473
Validation loss: 2.684955335633491

Epoch: 6| Step: 13
Training loss: 3.5485263290944267
Validation loss: 2.67546484489454

Epoch: 83| Step: 0
Training loss: 2.639219011326285
Validation loss: 2.667496118319068

Epoch: 6| Step: 1
Training loss: 2.9440921916624507
Validation loss: 2.6636677813670664

Epoch: 6| Step: 2
Training loss: 3.0254502016608193
Validation loss: 2.660859783910795

Epoch: 6| Step: 3
Training loss: 2.7360417109260236
Validation loss: 2.6635160856829505

Epoch: 6| Step: 4
Training loss: 2.9018197696909165
Validation loss: 2.6572019643399862

Epoch: 6| Step: 5
Training loss: 3.1166393591624564
Validation loss: 2.658225380969352

Epoch: 6| Step: 6
Training loss: 2.952018409361463
Validation loss: 2.656113238737848

Epoch: 6| Step: 7
Training loss: 2.8963156282499365
Validation loss: 2.6574393980834046

Epoch: 6| Step: 8
Training loss: 3.232207673227556
Validation loss: 2.652146907288951

Epoch: 6| Step: 9
Training loss: 3.7082491804425617
Validation loss: 2.6575756714758043

Epoch: 6| Step: 10
Training loss: 2.741728567644006
Validation loss: 2.6553602529647375

Epoch: 6| Step: 11
Training loss: 2.7528069649115743
Validation loss: 2.6555821186541544

Epoch: 6| Step: 12
Training loss: 2.9275868119709068
Validation loss: 2.6567890911056846

Epoch: 6| Step: 13
Training loss: 3.476760687161752
Validation loss: 2.653805425675067

Epoch: 84| Step: 0
Training loss: 3.335829436005841
Validation loss: 2.648289623990822

Epoch: 6| Step: 1
Training loss: 2.812257544345386
Validation loss: 2.6503671512124516

Epoch: 6| Step: 2
Training loss: 2.971813668983016
Validation loss: 2.650318884590657

Epoch: 6| Step: 3
Training loss: 2.757057929619291
Validation loss: 2.6488227589436457

Epoch: 6| Step: 4
Training loss: 2.9213982667460416
Validation loss: 2.649041080474847

Epoch: 6| Step: 5
Training loss: 2.7983403123500086
Validation loss: 2.660403954486334

Epoch: 6| Step: 6
Training loss: 3.488848769273796
Validation loss: 2.679730986167534

Epoch: 6| Step: 7
Training loss: 2.9333226145924174
Validation loss: 2.6790322558283917

Epoch: 6| Step: 8
Training loss: 2.5030041764301076
Validation loss: 2.686257113362165

Epoch: 6| Step: 9
Training loss: 2.9499905214319053
Validation loss: 2.6703235492616786

Epoch: 6| Step: 10
Training loss: 2.7927423558812237
Validation loss: 2.6441267105258115

Epoch: 6| Step: 11
Training loss: 3.507057839418375
Validation loss: 2.643978018435375

Epoch: 6| Step: 12
Training loss: 3.0094969157304376
Validation loss: 2.6465243101881417

Epoch: 6| Step: 13
Training loss: 3.0512247972021864
Validation loss: 2.659766186390327

Epoch: 85| Step: 0
Training loss: 3.243111278882042
Validation loss: 2.6666819343847648

Epoch: 6| Step: 1
Training loss: 2.965495524177782
Validation loss: 2.6621079478173018

Epoch: 6| Step: 2
Training loss: 3.1974802288908606
Validation loss: 2.6544762409326648

Epoch: 6| Step: 3
Training loss: 2.505581823306697
Validation loss: 2.6516504922921653

Epoch: 6| Step: 4
Training loss: 3.345936853336248
Validation loss: 2.6505660276217795

Epoch: 6| Step: 5
Training loss: 2.5142480149941653
Validation loss: 2.6533519302718607

Epoch: 6| Step: 6
Training loss: 3.0877182856319294
Validation loss: 2.651477216982725

Epoch: 6| Step: 7
Training loss: 3.6145372342001725
Validation loss: 2.6548799324421215

Epoch: 6| Step: 8
Training loss: 2.435358525069745
Validation loss: 2.6502286334480654

Epoch: 6| Step: 9
Training loss: 2.1850578845145496
Validation loss: 2.6527582428536896

Epoch: 6| Step: 10
Training loss: 3.399038678193005
Validation loss: 2.6565390895820538

Epoch: 6| Step: 11
Training loss: 3.340642322748731
Validation loss: 2.665276533910629

Epoch: 6| Step: 12
Training loss: 2.677990968570765
Validation loss: 2.6663138456769295

Epoch: 6| Step: 13
Training loss: 3.1529566134810896
Validation loss: 2.6634479184653963

Epoch: 86| Step: 0
Training loss: 2.4347324799329253
Validation loss: 2.6527118259827525

Epoch: 6| Step: 1
Training loss: 2.70952804819539
Validation loss: 2.665108685779008

Epoch: 6| Step: 2
Training loss: 2.772529732877529
Validation loss: 2.6617836551200447

Epoch: 6| Step: 3
Training loss: 3.222993590298539
Validation loss: 2.6725362954701106

Epoch: 6| Step: 4
Training loss: 3.4241033118161366
Validation loss: 2.6809441451659337

Epoch: 6| Step: 5
Training loss: 2.767814330020406
Validation loss: 2.6806772217798422

Epoch: 6| Step: 6
Training loss: 2.9535887016072024
Validation loss: 2.665989954002702

Epoch: 6| Step: 7
Training loss: 2.9542427975018906
Validation loss: 2.650272533335755

Epoch: 6| Step: 8
Training loss: 3.336441323606873
Validation loss: 2.6401013241400504

Epoch: 6| Step: 9
Training loss: 2.2546991444456865
Validation loss: 2.6389294242516144

Epoch: 6| Step: 10
Training loss: 3.00415831700054
Validation loss: 2.6415780998960514

Epoch: 6| Step: 11
Training loss: 3.7824276438043376
Validation loss: 2.64722072227664

Epoch: 6| Step: 12
Training loss: 3.103058192522209
Validation loss: 2.6453459057110145

Epoch: 6| Step: 13
Training loss: 2.6035665405514608
Validation loss: 2.650119210903492

Epoch: 87| Step: 0
Training loss: 3.420364813058212
Validation loss: 2.6510340719132164

Epoch: 6| Step: 1
Training loss: 2.9900637427842716
Validation loss: 2.651129329840574

Epoch: 6| Step: 2
Training loss: 2.8821855395683795
Validation loss: 2.651968082731288

Epoch: 6| Step: 3
Training loss: 3.056855585991657
Validation loss: 2.6529257601236034

Epoch: 6| Step: 4
Training loss: 2.6839877398817777
Validation loss: 2.654450914191475

Epoch: 6| Step: 5
Training loss: 3.058011717001084
Validation loss: 2.658841024081504

Epoch: 6| Step: 6
Training loss: 3.1001612959707687
Validation loss: 2.717895340474983

Epoch: 6| Step: 7
Training loss: 2.472710727856869
Validation loss: 2.800996558590186

Epoch: 6| Step: 8
Training loss: 3.48530573025168
Validation loss: 2.813185583890377

Epoch: 6| Step: 9
Training loss: 2.445308112484832
Validation loss: 2.7001860660063177

Epoch: 6| Step: 10
Training loss: 3.202604819137615
Validation loss: 2.6384765842257965

Epoch: 6| Step: 11
Training loss: 3.0292430408055004
Validation loss: 2.640410698373383

Epoch: 6| Step: 12
Training loss: 3.4909499192198354
Validation loss: 2.6636215295841468

Epoch: 6| Step: 13
Training loss: 2.649470845059364
Validation loss: 2.698027118476486

Epoch: 88| Step: 0
Training loss: 2.555651468283116
Validation loss: 2.7786177055121635

Epoch: 6| Step: 1
Training loss: 3.067381568867147
Validation loss: 2.857058587329433

Epoch: 6| Step: 2
Training loss: 3.520346357688172
Validation loss: 2.8272261985317138

Epoch: 6| Step: 3
Training loss: 2.646256080155557
Validation loss: 2.7012624199498636

Epoch: 6| Step: 4
Training loss: 3.0758613744584222
Validation loss: 2.6782950424250727

Epoch: 6| Step: 5
Training loss: 3.4958152276450427
Validation loss: 2.6715780540652054

Epoch: 6| Step: 6
Training loss: 3.1425620411140613
Validation loss: 2.7234597440473927

Epoch: 6| Step: 7
Training loss: 3.3006171371923956
Validation loss: 2.7424971719393842

Epoch: 6| Step: 8
Training loss: 3.175991450223777
Validation loss: 2.6931821922235493

Epoch: 6| Step: 9
Training loss: 2.753570233129723
Validation loss: 2.70215424758732

Epoch: 6| Step: 10
Training loss: 3.1140028668870023
Validation loss: 2.6775586572231074

Epoch: 6| Step: 11
Training loss: 2.6184873171505196
Validation loss: 2.6545864196819458

Epoch: 6| Step: 12
Training loss: 2.9627609073656056
Validation loss: 2.6418680254497637

Epoch: 6| Step: 13
Training loss: 2.6038082842591845
Validation loss: 2.633508627648944

Epoch: 89| Step: 0
Training loss: 2.351334570297177
Validation loss: 2.6355300723926405

Epoch: 6| Step: 1
Training loss: 3.300496936719814
Validation loss: 2.641838075182634

Epoch: 6| Step: 2
Training loss: 3.3093616805920734
Validation loss: 2.6389473672405885

Epoch: 6| Step: 3
Training loss: 3.080136798694083
Validation loss: 2.6416416879610813

Epoch: 6| Step: 4
Training loss: 3.4129685803321532
Validation loss: 2.647407868097699

Epoch: 6| Step: 5
Training loss: 3.076275419884308
Validation loss: 2.6479122952600345

Epoch: 6| Step: 6
Training loss: 3.0697263201767893
Validation loss: 2.653236713543473

Epoch: 6| Step: 7
Training loss: 2.592806173286751
Validation loss: 2.6457781338200195

Epoch: 6| Step: 8
Training loss: 3.2800255807018632
Validation loss: 2.6484311480924987

Epoch: 6| Step: 9
Training loss: 2.892215765305392
Validation loss: 2.636524280105092

Epoch: 6| Step: 10
Training loss: 2.659532919295401
Validation loss: 2.630488585303307

Epoch: 6| Step: 11
Training loss: 2.8804048237795565
Validation loss: 2.6275213724024673

Epoch: 6| Step: 12
Training loss: 2.6905331018861243
Validation loss: 2.623392689257994

Epoch: 6| Step: 13
Training loss: 2.9749415031259834
Validation loss: 2.6225360746874347

Epoch: 90| Step: 0
Training loss: 3.4147334017932156
Validation loss: 2.622052365479919

Epoch: 6| Step: 1
Training loss: 2.9826879076666764
Validation loss: 2.6216059148405577

Epoch: 6| Step: 2
Training loss: 3.0896684329213424
Validation loss: 2.6221280059208336

Epoch: 6| Step: 3
Training loss: 3.393040512980871
Validation loss: 2.6219605459149604

Epoch: 6| Step: 4
Training loss: 2.8685176580748983
Validation loss: 2.6200835825900017

Epoch: 6| Step: 5
Training loss: 3.178453960666746
Validation loss: 2.616353254187811

Epoch: 6| Step: 6
Training loss: 2.538424367676977
Validation loss: 2.620076180547971

Epoch: 6| Step: 7
Training loss: 3.1136128286118976
Validation loss: 2.622948557390154

Epoch: 6| Step: 8
Training loss: 2.691390836142818
Validation loss: 2.621683460323116

Epoch: 6| Step: 9
Training loss: 3.1856842853372536
Validation loss: 2.632497112354116

Epoch: 6| Step: 10
Training loss: 2.587975566117801
Validation loss: 2.646370783189178

Epoch: 6| Step: 11
Training loss: 2.768829988654594
Validation loss: 2.6494661376579614

Epoch: 6| Step: 12
Training loss: 2.257039924623398
Validation loss: 2.6495577693758334

Epoch: 6| Step: 13
Training loss: 3.5041733791968923
Validation loss: 2.6462520238695277

Epoch: 91| Step: 0
Training loss: 3.0375596279994808
Validation loss: 2.654273522685293

Epoch: 6| Step: 1
Training loss: 3.0438840613323315
Validation loss: 2.635141584897445

Epoch: 6| Step: 2
Training loss: 3.0288893169080295
Validation loss: 2.6219097000953377

Epoch: 6| Step: 3
Training loss: 3.3848228207624254
Validation loss: 2.6230097979048743

Epoch: 6| Step: 4
Training loss: 3.332073895627594
Validation loss: 2.615050144061834

Epoch: 6| Step: 5
Training loss: 2.6051857950505943
Validation loss: 2.6137928486994033

Epoch: 6| Step: 6
Training loss: 2.8260805106009776
Validation loss: 2.6141378836016913

Epoch: 6| Step: 7
Training loss: 2.5201778558002057
Validation loss: 2.616356915894553

Epoch: 6| Step: 8
Training loss: 2.5286633497129745
Validation loss: 2.6193164055194655

Epoch: 6| Step: 9
Training loss: 2.9629574128823046
Validation loss: 2.6179770148008172

Epoch: 6| Step: 10
Training loss: 2.978403878539022
Validation loss: 2.6193631841788876

Epoch: 6| Step: 11
Training loss: 2.9751804777907584
Validation loss: 2.618701014392326

Epoch: 6| Step: 12
Training loss: 3.1499462062541514
Validation loss: 2.617256316209458

Epoch: 6| Step: 13
Training loss: 3.2271834323266764
Validation loss: 2.6143164829247603

Epoch: 92| Step: 0
Training loss: 3.153996786954086
Validation loss: 2.614542140880514

Epoch: 6| Step: 1
Training loss: 2.8244020183610585
Validation loss: 2.614245820250005

Epoch: 6| Step: 2
Training loss: 3.3661775069960225
Validation loss: 2.613421900186037

Epoch: 6| Step: 3
Training loss: 3.1073485245310466
Validation loss: 2.611313858341158

Epoch: 6| Step: 4
Training loss: 2.971543774362764
Validation loss: 2.6118935837732216

Epoch: 6| Step: 5
Training loss: 3.2075667683408025
Validation loss: 2.61086185687173

Epoch: 6| Step: 6
Training loss: 3.0882680084461884
Validation loss: 2.6088978261890574

Epoch: 6| Step: 7
Training loss: 2.9809214796840915
Validation loss: 2.6116778615298846

Epoch: 6| Step: 8
Training loss: 2.8598940852367196
Validation loss: 2.6118622989269804

Epoch: 6| Step: 9
Training loss: 2.250346686886632
Validation loss: 2.6221015435027466

Epoch: 6| Step: 10
Training loss: 2.5693510628533796
Validation loss: 2.6483838751733857

Epoch: 6| Step: 11
Training loss: 2.9123441728155375
Validation loss: 2.6851587917602475

Epoch: 6| Step: 12
Training loss: 3.319350302907279
Validation loss: 2.724555303529802

Epoch: 6| Step: 13
Training loss: 2.6069456201287733
Validation loss: 2.7044151708330957

Epoch: 93| Step: 0
Training loss: 2.685215888694331
Validation loss: 2.683359209457039

Epoch: 6| Step: 1
Training loss: 2.8995405293549648
Validation loss: 2.641504823044809

Epoch: 6| Step: 2
Training loss: 2.9489275453811534
Validation loss: 2.608178851774488

Epoch: 6| Step: 3
Training loss: 2.9747905112487216
Validation loss: 2.6055661991764714

Epoch: 6| Step: 4
Training loss: 2.851481899010713
Validation loss: 2.601715933786468

Epoch: 6| Step: 5
Training loss: 2.675281427855993
Validation loss: 2.6049555263360635

Epoch: 6| Step: 6
Training loss: 2.9079686487284047
Validation loss: 2.611730959044423

Epoch: 6| Step: 7
Training loss: 3.3315416448155255
Validation loss: 2.6135943384475007

Epoch: 6| Step: 8
Training loss: 3.122015176094701
Validation loss: 2.6230118562368956

Epoch: 6| Step: 9
Training loss: 3.502757757097574
Validation loss: 2.6223338250629693

Epoch: 6| Step: 10
Training loss: 2.7773513901145352
Validation loss: 2.6118852756358586

Epoch: 6| Step: 11
Training loss: 2.8354244556268635
Validation loss: 2.607827158628008

Epoch: 6| Step: 12
Training loss: 2.929983708984081
Validation loss: 2.606025655100996

Epoch: 6| Step: 13
Training loss: 2.945247740501584
Validation loss: 2.599933938716687

Epoch: 94| Step: 0
Training loss: 2.87852858572703
Validation loss: 2.605663295433705

Epoch: 6| Step: 1
Training loss: 3.3513795318100503
Validation loss: 2.594200246422345

Epoch: 6| Step: 2
Training loss: 2.981952582849007
Validation loss: 2.5962442640647563

Epoch: 6| Step: 3
Training loss: 2.840059673595779
Validation loss: 2.596938311425526

Epoch: 6| Step: 4
Training loss: 3.2675067645282376
Validation loss: 2.6057765593335502

Epoch: 6| Step: 5
Training loss: 2.8492720092448205
Validation loss: 2.612190478909193

Epoch: 6| Step: 6
Training loss: 3.2103368935316903
Validation loss: 2.608446380037903

Epoch: 6| Step: 7
Training loss: 2.5120095756494036
Validation loss: 2.6076837297345388

Epoch: 6| Step: 8
Training loss: 2.303836781879633
Validation loss: 2.6092178428069235

Epoch: 6| Step: 9
Training loss: 3.030455180307657
Validation loss: 2.610434868270037

Epoch: 6| Step: 10
Training loss: 3.7600211713073106
Validation loss: 2.6029617550879034

Epoch: 6| Step: 11
Training loss: 2.422941895799386
Validation loss: 2.596427882286412

Epoch: 6| Step: 12
Training loss: 2.949317051341876
Validation loss: 2.595759939808988

Epoch: 6| Step: 13
Training loss: 2.6141249316889548
Validation loss: 2.592044715014956

Epoch: 95| Step: 0
Training loss: 3.07421875
Validation loss: 2.592812176978071

Epoch: 6| Step: 1
Training loss: 2.8949379577313517
Validation loss: 2.5922039537698125

Epoch: 6| Step: 2
Training loss: 2.7560578294397793
Validation loss: 2.591106971321089

Epoch: 6| Step: 3
Training loss: 2.9024791249552133
Validation loss: 2.5889077064679626

Epoch: 6| Step: 4
Training loss: 3.2724666202669996
Validation loss: 2.590589248820425

Epoch: 6| Step: 5
Training loss: 2.7464871077346933
Validation loss: 2.5889391305616014

Epoch: 6| Step: 6
Training loss: 2.8188376334835024
Validation loss: 2.5889392860274305

Epoch: 6| Step: 7
Training loss: 3.152103684370793
Validation loss: 2.588228045070866

Epoch: 6| Step: 8
Training loss: 2.6444278398183045
Validation loss: 2.589978890162927

Epoch: 6| Step: 9
Training loss: 3.1274265786265403
Validation loss: 2.5904701311999774

Epoch: 6| Step: 10
Training loss: 3.149914719168935
Validation loss: 2.5983470806474407

Epoch: 6| Step: 11
Training loss: 3.4886861226580357
Validation loss: 2.60022944423208

Epoch: 6| Step: 12
Training loss: 2.5681789088213547
Validation loss: 2.611836764105649

Epoch: 6| Step: 13
Training loss: 2.415412500665334
Validation loss: 2.6187736552257177

Epoch: 96| Step: 0
Training loss: 3.363225389253729
Validation loss: 2.6249471972614615

Epoch: 6| Step: 1
Training loss: 3.349654216855459
Validation loss: 2.6397393232726776

Epoch: 6| Step: 2
Training loss: 3.281234305208
Validation loss: 2.6447948801174705

Epoch: 6| Step: 3
Training loss: 2.7709591390019286
Validation loss: 2.6220750534415926

Epoch: 6| Step: 4
Training loss: 2.8289181771984304
Validation loss: 2.6145928064075097

Epoch: 6| Step: 5
Training loss: 2.9614460289523192
Validation loss: 2.6133579241859897

Epoch: 6| Step: 6
Training loss: 2.4794283389524465
Validation loss: 2.608028140653933

Epoch: 6| Step: 7
Training loss: 2.766130304242081
Validation loss: 2.6054672927755207

Epoch: 6| Step: 8
Training loss: 3.398988736050093
Validation loss: 2.6046394722895534

Epoch: 6| Step: 9
Training loss: 2.8546645758115026
Validation loss: 2.5947642443049546

Epoch: 6| Step: 10
Training loss: 2.731306523277217
Validation loss: 2.591431939084612

Epoch: 6| Step: 11
Training loss: 2.7630516191949246
Validation loss: 2.5925836867745775

Epoch: 6| Step: 12
Training loss: 2.986816366338176
Validation loss: 2.597311631402214

Epoch: 6| Step: 13
Training loss: 2.92192428465704
Validation loss: 2.6246727545580195

Epoch: 97| Step: 0
Training loss: 3.2038350132480695
Validation loss: 2.6126387749496613

Epoch: 6| Step: 1
Training loss: 2.6136620305425686
Validation loss: 2.6077413054429903

Epoch: 6| Step: 2
Training loss: 2.8687517020692117
Validation loss: 2.600157352131778

Epoch: 6| Step: 3
Training loss: 3.555706037542339
Validation loss: 2.5972636955462

Epoch: 6| Step: 4
Training loss: 2.4283025296189935
Validation loss: 2.591311032924179

Epoch: 6| Step: 5
Training loss: 3.210130873296889
Validation loss: 2.5892637199034696

Epoch: 6| Step: 6
Training loss: 2.7638420780462747
Validation loss: 2.5888417378019644

Epoch: 6| Step: 7
Training loss: 2.950345138791101
Validation loss: 2.5873270401135526

Epoch: 6| Step: 8
Training loss: 3.3155763843650297
Validation loss: 2.588450350342998

Epoch: 6| Step: 9
Training loss: 2.7940791983660636
Validation loss: 2.5911401021498985

Epoch: 6| Step: 10
Training loss: 2.9526486290094867
Validation loss: 2.5901496946667226

Epoch: 6| Step: 11
Training loss: 2.5435218502521186
Validation loss: 2.5871126559228315

Epoch: 6| Step: 12
Training loss: 2.822305160298347
Validation loss: 2.5877907567287353

Epoch: 6| Step: 13
Training loss: 3.0209906876896233
Validation loss: 2.588176766362753

Epoch: 98| Step: 0
Training loss: 3.043937479938591
Validation loss: 2.5889591628013706

Epoch: 6| Step: 1
Training loss: 3.1013241923758663
Validation loss: 2.589018561986595

Epoch: 6| Step: 2
Training loss: 2.6477184838764183
Validation loss: 2.587133012462876

Epoch: 6| Step: 3
Training loss: 2.936933584592961
Validation loss: 2.5856600778255827

Epoch: 6| Step: 4
Training loss: 2.6323926460714064
Validation loss: 2.5864736211121233

Epoch: 6| Step: 5
Training loss: 2.791963922037975
Validation loss: 2.588395944282097

Epoch: 6| Step: 6
Training loss: 2.941301848039282
Validation loss: 2.5881617401319947

Epoch: 6| Step: 7
Training loss: 2.9289559633559397
Validation loss: 2.5907969965888893

Epoch: 6| Step: 8
Training loss: 3.2151110179949036
Validation loss: 2.6065127988042476

Epoch: 6| Step: 9
Training loss: 3.4910548205916183
Validation loss: 2.634061826400925

Epoch: 6| Step: 10
Training loss: 3.12136950366825
Validation loss: 2.610590652992128

Epoch: 6| Step: 11
Training loss: 2.9967439783948677
Validation loss: 2.588665852753792

Epoch: 6| Step: 12
Training loss: 2.647476967341272
Validation loss: 2.581481197862302

Epoch: 6| Step: 13
Training loss: 2.4567497346861797
Validation loss: 2.582991896687555

Epoch: 99| Step: 0
Training loss: 2.986976967200767
Validation loss: 2.5794805409268595

Epoch: 6| Step: 1
Training loss: 2.934932154532534
Validation loss: 2.5823587368130654

Epoch: 6| Step: 2
Training loss: 2.8717616543490596
Validation loss: 2.586762854745879

Epoch: 6| Step: 3
Training loss: 2.9917675550303904
Validation loss: 2.580892616278829

Epoch: 6| Step: 4
Training loss: 3.1103435905510084
Validation loss: 2.582391929247779

Epoch: 6| Step: 5
Training loss: 2.7073406356447522
Validation loss: 2.5804118236807074

Epoch: 6| Step: 6
Training loss: 3.0888454208547804
Validation loss: 2.576127097484312

Epoch: 6| Step: 7
Training loss: 2.591767254152044
Validation loss: 2.577226129961785

Epoch: 6| Step: 8
Training loss: 3.362248243245365
Validation loss: 2.5790128102152536

Epoch: 6| Step: 9
Training loss: 2.2904684806941717
Validation loss: 2.580753223530615

Epoch: 6| Step: 10
Training loss: 2.6333914553187494
Validation loss: 2.5873572428813265

Epoch: 6| Step: 11
Training loss: 3.467017075973283
Validation loss: 2.5885875469473114

Epoch: 6| Step: 12
Training loss: 2.842337792162617
Validation loss: 2.5867241257612963

Epoch: 6| Step: 13
Training loss: 3.382206040921675
Validation loss: 2.583221104301478

Epoch: 100| Step: 0
Training loss: 2.308713545168083
Validation loss: 2.5806531555426253

Epoch: 6| Step: 1
Training loss: 2.946499289452509
Validation loss: 2.5818959966896085

Epoch: 6| Step: 2
Training loss: 2.790701504776788
Validation loss: 2.5775570141547073

Epoch: 6| Step: 3
Training loss: 2.925064386164518
Validation loss: 2.5782690540588065

Epoch: 6| Step: 4
Training loss: 2.741916132266904
Validation loss: 2.578405038509861

Epoch: 6| Step: 5
Training loss: 3.04364797432919
Validation loss: 2.584430029776297

Epoch: 6| Step: 6
Training loss: 3.1891415426877616
Validation loss: 2.584947590464753

Epoch: 6| Step: 7
Training loss: 2.663591091476692
Validation loss: 2.5991728257636004

Epoch: 6| Step: 8
Training loss: 2.5922703946444696
Validation loss: 2.597195993587547

Epoch: 6| Step: 9
Training loss: 3.4789808455924307
Validation loss: 2.6021114520227693

Epoch: 6| Step: 10
Training loss: 2.9397759244476296
Validation loss: 2.6100587529278783

Epoch: 6| Step: 11
Training loss: 3.2795843347150413
Validation loss: 2.5958899535972946

Epoch: 6| Step: 12
Training loss: 3.1915652213313326
Validation loss: 2.586270666685816

Epoch: 6| Step: 13
Training loss: 2.676608972541269
Validation loss: 2.579977627398301

Epoch: 101| Step: 0
Training loss: 3.1655483948306093
Validation loss: 2.5813331528437464

Epoch: 6| Step: 1
Training loss: 3.1654851281915315
Validation loss: 2.579000555667034

Epoch: 6| Step: 2
Training loss: 2.8354473268382057
Validation loss: 2.573173377290042

Epoch: 6| Step: 3
Training loss: 3.063323241152516
Validation loss: 2.581410646861094

Epoch: 6| Step: 4
Training loss: 2.9236906397723215
Validation loss: 2.575636842442656

Epoch: 6| Step: 5
Training loss: 3.379951236079652
Validation loss: 2.574219656260421

Epoch: 6| Step: 6
Training loss: 2.9989196103506512
Validation loss: 2.5768727074912667

Epoch: 6| Step: 7
Training loss: 3.0470275840700056
Validation loss: 2.571173425885076

Epoch: 6| Step: 8
Training loss: 2.9472274423885185
Validation loss: 2.5765520096942436

Epoch: 6| Step: 9
Training loss: 2.8919509733273325
Validation loss: 2.57248245234708

Epoch: 6| Step: 10
Training loss: 2.7632084002934247
Validation loss: 2.5746606385921176

Epoch: 6| Step: 11
Training loss: 2.4975083332094576
Validation loss: 2.5749823345737632

Epoch: 6| Step: 12
Training loss: 2.674446162707651
Validation loss: 2.5825126990538445

Epoch: 6| Step: 13
Training loss: 2.2485988280717644
Validation loss: 2.5721524054104603

Epoch: 102| Step: 0
Training loss: 3.0680676667013875
Validation loss: 2.5683184919250364

Epoch: 6| Step: 1
Training loss: 2.8794501320120376
Validation loss: 2.5685417657960876

Epoch: 6| Step: 2
Training loss: 3.5772474787084247
Validation loss: 2.5690240104904447

Epoch: 6| Step: 3
Training loss: 2.883386404912491
Validation loss: 2.568305023465457

Epoch: 6| Step: 4
Training loss: 2.35356941636531
Validation loss: 2.566782150925338

Epoch: 6| Step: 5
Training loss: 2.899816796665547
Validation loss: 2.5666689501436473

Epoch: 6| Step: 6
Training loss: 2.8121143500518135
Validation loss: 2.5648576029014167

Epoch: 6| Step: 7
Training loss: 3.142935894313882
Validation loss: 2.5674358145843246

Epoch: 6| Step: 8
Training loss: 3.5703750037266855
Validation loss: 2.5676282784388684

Epoch: 6| Step: 9
Training loss: 2.27351720086884
Validation loss: 2.5691416278083965

Epoch: 6| Step: 10
Training loss: 2.758272559503902
Validation loss: 2.574501794474546

Epoch: 6| Step: 11
Training loss: 3.2029409960487754
Validation loss: 2.569085292073142

Epoch: 6| Step: 12
Training loss: 2.2134540375960583
Validation loss: 2.5707624654780874

Epoch: 6| Step: 13
Training loss: 3.0370633725917187
Validation loss: 2.575367318475356

Epoch: 103| Step: 0
Training loss: 2.793722752517173
Validation loss: 2.568893462303919

Epoch: 6| Step: 1
Training loss: 3.0326267537344287
Validation loss: 2.577003469237795

Epoch: 6| Step: 2
Training loss: 2.8776450221871115
Validation loss: 2.591132931062151

Epoch: 6| Step: 3
Training loss: 3.5557729551953856
Validation loss: 2.6015737456278485

Epoch: 6| Step: 4
Training loss: 2.348865267537486
Validation loss: 2.6562633304152876

Epoch: 6| Step: 5
Training loss: 3.1389105373149917
Validation loss: 2.7073132883968607

Epoch: 6| Step: 6
Training loss: 3.0685948039354667
Validation loss: 2.6804210383901172

Epoch: 6| Step: 7
Training loss: 2.6933860196572286
Validation loss: 2.6532217900574646

Epoch: 6| Step: 8
Training loss: 3.541948434429587
Validation loss: 2.6366173796193504

Epoch: 6| Step: 9
Training loss: 2.5983389280045697
Validation loss: 2.576479283934584

Epoch: 6| Step: 10
Training loss: 2.931481221723979
Validation loss: 2.5622975029059427

Epoch: 6| Step: 11
Training loss: 2.4239346513846756
Validation loss: 2.560607461398779

Epoch: 6| Step: 12
Training loss: 2.6998567613824296
Validation loss: 2.559081225316782

Epoch: 6| Step: 13
Training loss: 3.421314768458618
Validation loss: 2.564669261389272

Epoch: 104| Step: 0
Training loss: 2.84953641634669
Validation loss: 2.5668558116024363

Epoch: 6| Step: 1
Training loss: 3.106522521684717
Validation loss: 2.5756696845521154

Epoch: 6| Step: 2
Training loss: 3.310153345894997
Validation loss: 2.5696374549273497

Epoch: 6| Step: 3
Training loss: 2.574343688433613
Validation loss: 2.5711394893766966

Epoch: 6| Step: 4
Training loss: 3.0992606050334968
Validation loss: 2.571980596092632

Epoch: 6| Step: 5
Training loss: 3.0064719643604447
Validation loss: 2.570311641234789

Epoch: 6| Step: 6
Training loss: 2.841283881694068
Validation loss: 2.5680809004468017

Epoch: 6| Step: 7
Training loss: 2.977908173200224
Validation loss: 2.570231398782768

Epoch: 6| Step: 8
Training loss: 2.882168498898439
Validation loss: 2.567796181773447

Epoch: 6| Step: 9
Training loss: 3.0244012917977874
Validation loss: 2.5607294247987418

Epoch: 6| Step: 10
Training loss: 2.430611192581144
Validation loss: 2.5576860724243464

Epoch: 6| Step: 11
Training loss: 2.832708196303112
Validation loss: 2.557631063064031

Epoch: 6| Step: 12
Training loss: 2.910381211156107
Validation loss: 2.5581679223330562

Epoch: 6| Step: 13
Training loss: 3.389109751968601
Validation loss: 2.561833775010384

Epoch: 105| Step: 0
Training loss: 3.0957314667472344
Validation loss: 2.5746305577205386

Epoch: 6| Step: 1
Training loss: 3.174861610580513
Validation loss: 2.578891351631465

Epoch: 6| Step: 2
Training loss: 3.5299796460999437
Validation loss: 2.5762789931616785

Epoch: 6| Step: 3
Training loss: 2.7997790555974866
Validation loss: 2.571359222223758

Epoch: 6| Step: 4
Training loss: 2.466397480409853
Validation loss: 2.5732149722841475

Epoch: 6| Step: 5
Training loss: 2.7751078129350373
Validation loss: 2.562903527782327

Epoch: 6| Step: 6
Training loss: 2.74336239242768
Validation loss: 2.564883562446914

Epoch: 6| Step: 7
Training loss: 2.9739482142359224
Validation loss: 2.559673376063574

Epoch: 6| Step: 8
Training loss: 2.9257832057319897
Validation loss: 2.56151418784443

Epoch: 6| Step: 9
Training loss: 2.513035264574955
Validation loss: 2.5585965024170405

Epoch: 6| Step: 10
Training loss: 2.9535575428825918
Validation loss: 2.5604755739635228

Epoch: 6| Step: 11
Training loss: 2.9142156565817854
Validation loss: 2.554863570855129

Epoch: 6| Step: 12
Training loss: 2.630864812424782
Validation loss: 2.557188771109692

Epoch: 6| Step: 13
Training loss: 3.5069092265124353
Validation loss: 2.5571375276340946

Epoch: 106| Step: 0
Training loss: 3.5062943127665793
Validation loss: 2.554831967460677

Epoch: 6| Step: 1
Training loss: 2.771804285706424
Validation loss: 2.550102308482189

Epoch: 6| Step: 2
Training loss: 2.876383407131563
Validation loss: 2.551054773419412

Epoch: 6| Step: 3
Training loss: 2.6700730521677407
Validation loss: 2.5497520106623353

Epoch: 6| Step: 4
Training loss: 2.9503301080178903
Validation loss: 2.5458131437885863

Epoch: 6| Step: 5
Training loss: 2.580631217034414
Validation loss: 2.5502776082289995

Epoch: 6| Step: 6
Training loss: 2.879284030345875
Validation loss: 2.5517679072707606

Epoch: 6| Step: 7
Training loss: 3.16820234573419
Validation loss: 2.550267582952446

Epoch: 6| Step: 8
Training loss: 3.793053230264135
Validation loss: 2.546881113976748

Epoch: 6| Step: 9
Training loss: 3.3569706318979455
Validation loss: 2.549659598349357

Epoch: 6| Step: 10
Training loss: 2.427745668687277
Validation loss: 2.5493369926931893

Epoch: 6| Step: 11
Training loss: 2.258650152451555
Validation loss: 2.552211572582307

Epoch: 6| Step: 12
Training loss: 2.4335798382552807
Validation loss: 2.5521214582564347

Epoch: 6| Step: 13
Training loss: 2.7400884609839395
Validation loss: 2.5598515215559003

Epoch: 107| Step: 0
Training loss: 2.771272743968006
Validation loss: 2.5698473932476253

Epoch: 6| Step: 1
Training loss: 2.864603900257607
Validation loss: 2.5661055028005575

Epoch: 6| Step: 2
Training loss: 2.811056656827298
Validation loss: 2.564513494656361

Epoch: 6| Step: 3
Training loss: 3.1105835066088345
Validation loss: 2.561403506649117

Epoch: 6| Step: 4
Training loss: 2.3607745535342306
Validation loss: 2.559180978786621

Epoch: 6| Step: 5
Training loss: 2.930835549797787
Validation loss: 2.5520488047738707

Epoch: 6| Step: 6
Training loss: 3.165794520155668
Validation loss: 2.5560077427983297

Epoch: 6| Step: 7
Training loss: 2.895168218913731
Validation loss: 2.549124040698768

Epoch: 6| Step: 8
Training loss: 2.7231066644562163
Validation loss: 2.547687692009172

Epoch: 6| Step: 9
Training loss: 3.182113584206725
Validation loss: 2.550807367875895

Epoch: 6| Step: 10
Training loss: 3.3324043091917033
Validation loss: 2.5469739340978435

Epoch: 6| Step: 11
Training loss: 3.310225515606507
Validation loss: 2.549522563354611

Epoch: 6| Step: 12
Training loss: 2.514206290771004
Validation loss: 2.5507279762217907

Epoch: 6| Step: 13
Training loss: 2.57902058160445
Validation loss: 2.5477674450534136

Epoch: 108| Step: 0
Training loss: 2.7869767797055065
Validation loss: 2.5474091566165544

Epoch: 6| Step: 1
Training loss: 2.8089210627251693
Validation loss: 2.5474358172776985

Epoch: 6| Step: 2
Training loss: 2.8834791782368887
Validation loss: 2.572153272531309

Epoch: 6| Step: 3
Training loss: 2.4730629247549207
Validation loss: 2.5567936121660333

Epoch: 6| Step: 4
Training loss: 3.1396446405984038
Validation loss: 2.5456186881743346

Epoch: 6| Step: 5
Training loss: 3.854815550472113
Validation loss: 2.5475699989307707

Epoch: 6| Step: 6
Training loss: 2.677421657295883
Validation loss: 2.5484507517927395

Epoch: 6| Step: 7
Training loss: 3.073407891445538
Validation loss: 2.544546039236357

Epoch: 6| Step: 8
Training loss: 2.9851154786844583
Validation loss: 2.54538084111756

Epoch: 6| Step: 9
Training loss: 2.853542027491646
Validation loss: 2.5468456146580336

Epoch: 6| Step: 10
Training loss: 2.673064920581076
Validation loss: 2.546793331606167

Epoch: 6| Step: 11
Training loss: 2.819707155646401
Validation loss: 2.5511501317955267

Epoch: 6| Step: 12
Training loss: 2.629242874064759
Validation loss: 2.543572219038453

Epoch: 6| Step: 13
Training loss: 2.9275658007360246
Validation loss: 2.5467928474242556

Epoch: 109| Step: 0
Training loss: 2.3644507170695963
Validation loss: 2.5479932482054246

Epoch: 6| Step: 1
Training loss: 3.3222209875840947
Validation loss: 2.5454787214114867

Epoch: 6| Step: 2
Training loss: 2.8530847953980345
Validation loss: 2.545635007846847

Epoch: 6| Step: 3
Training loss: 2.8721284208674565
Validation loss: 2.541438962142821

Epoch: 6| Step: 4
Training loss: 2.9532457760934276
Validation loss: 2.5462883019925195

Epoch: 6| Step: 5
Training loss: 2.914039264003373
Validation loss: 2.547643250072052

Epoch: 6| Step: 6
Training loss: 2.6416118515857843
Validation loss: 2.545009106447845

Epoch: 6| Step: 7
Training loss: 2.803915018369283
Validation loss: 2.5490968867962036

Epoch: 6| Step: 8
Training loss: 3.0225578033750904
Validation loss: 2.556054353150621

Epoch: 6| Step: 9
Training loss: 3.266808400355581
Validation loss: 2.572279393640473

Epoch: 6| Step: 10
Training loss: 2.768224238298299
Validation loss: 2.564359913846697

Epoch: 6| Step: 11
Training loss: 2.8736535941633687
Validation loss: 2.573467290543374

Epoch: 6| Step: 12
Training loss: 3.037338591631635
Validation loss: 2.568602059817843

Epoch: 6| Step: 13
Training loss: 2.92512339796299
Validation loss: 2.5605622875532927

Epoch: 110| Step: 0
Training loss: 2.1528984227437076
Validation loss: 2.548446745049164

Epoch: 6| Step: 1
Training loss: 2.522137380798447
Validation loss: 2.5560620479092733

Epoch: 6| Step: 2
Training loss: 3.0242775235566173
Validation loss: 2.5624335315646567

Epoch: 6| Step: 3
Training loss: 2.958009585722892
Validation loss: 2.5724693335592934

Epoch: 6| Step: 4
Training loss: 2.481468756038412
Validation loss: 2.5559724875883028

Epoch: 6| Step: 5
Training loss: 3.091602543442655
Validation loss: 2.541711483753074

Epoch: 6| Step: 6
Training loss: 3.272654583152625
Validation loss: 2.550721347827028

Epoch: 6| Step: 7
Training loss: 3.117860802617248
Validation loss: 2.547343182055151

Epoch: 6| Step: 8
Training loss: 2.7189627377817813
Validation loss: 2.550552873275495

Epoch: 6| Step: 9
Training loss: 3.031251887684657
Validation loss: 2.552888662729339

Epoch: 6| Step: 10
Training loss: 2.755418381259011
Validation loss: 2.5536373905772005

Epoch: 6| Step: 11
Training loss: 3.421214418794185
Validation loss: 2.5547006990617915

Epoch: 6| Step: 12
Training loss: 3.371596987260909
Validation loss: 2.552583181332279

Epoch: 6| Step: 13
Training loss: 2.531835135186317
Validation loss: 2.5521566139801983

Epoch: 111| Step: 0
Training loss: 2.247215985778194
Validation loss: 2.544452343657541

Epoch: 6| Step: 1
Training loss: 3.2322652081558054
Validation loss: 2.539669469282679

Epoch: 6| Step: 2
Training loss: 3.0907575218246772
Validation loss: 2.540067800912564

Epoch: 6| Step: 3
Training loss: 2.867405688224004
Validation loss: 2.5414749485401034

Epoch: 6| Step: 4
Training loss: 2.936910691905943
Validation loss: 2.540924010836532

Epoch: 6| Step: 5
Training loss: 2.8389661185784734
Validation loss: 2.545638262705148

Epoch: 6| Step: 6
Training loss: 2.950196120644957
Validation loss: 2.5420698783768767

Epoch: 6| Step: 7
Training loss: 3.3601680795318973
Validation loss: 2.5500920884910783

Epoch: 6| Step: 8
Training loss: 3.275615249965738
Validation loss: 2.5547395813574063

Epoch: 6| Step: 9
Training loss: 1.7715823515491207
Validation loss: 2.5530001157433775

Epoch: 6| Step: 10
Training loss: 2.9697639741457214
Validation loss: 2.562848392336683

Epoch: 6| Step: 11
Training loss: 3.1169597188765725
Validation loss: 2.558446404695803

Epoch: 6| Step: 12
Training loss: 2.600457125606088
Validation loss: 2.564403377283764

Epoch: 6| Step: 13
Training loss: 2.912591721559859
Validation loss: 2.562936539061317

Epoch: 112| Step: 0
Training loss: 3.0057470586959534
Validation loss: 2.5555523906091913

Epoch: 6| Step: 1
Training loss: 2.8769637325839748
Validation loss: 2.548531312861109

Epoch: 6| Step: 2
Training loss: 3.1104377195681017
Validation loss: 2.5442529414203805

Epoch: 6| Step: 3
Training loss: 2.1754546819274627
Validation loss: 2.5453670649584335

Epoch: 6| Step: 4
Training loss: 3.2145947050502053
Validation loss: 2.544357812368564

Epoch: 6| Step: 5
Training loss: 2.409450730693391
Validation loss: 2.536632826884759

Epoch: 6| Step: 6
Training loss: 2.376252396294892
Validation loss: 2.5399506520448276

Epoch: 6| Step: 7
Training loss: 3.402511925378624
Validation loss: 2.5416509451969143

Epoch: 6| Step: 8
Training loss: 2.5548205793056873
Validation loss: 2.537584871846585

Epoch: 6| Step: 9
Training loss: 2.7351422786492012
Validation loss: 2.538585712607309

Epoch: 6| Step: 10
Training loss: 2.433862955991936
Validation loss: 2.5422871684712907

Epoch: 6| Step: 11
Training loss: 3.4622896536823857
Validation loss: 2.554237119551516

Epoch: 6| Step: 12
Training loss: 3.1872016916745456
Validation loss: 2.5433311626939163

Epoch: 6| Step: 13
Training loss: 3.453545178011984
Validation loss: 2.5510651412982064

Epoch: 113| Step: 0
Training loss: 2.484063374870358
Validation loss: 2.5433248637854593

Epoch: 6| Step: 1
Training loss: 3.0012751094684478
Validation loss: 2.5448471905940924

Epoch: 6| Step: 2
Training loss: 2.9588884898346337
Validation loss: 2.5400305914996717

Epoch: 6| Step: 3
Training loss: 2.46328332902728
Validation loss: 2.543908840038684

Epoch: 6| Step: 4
Training loss: 2.9905636517043104
Validation loss: 2.5388118466830303

Epoch: 6| Step: 5
Training loss: 2.7489420849974127
Validation loss: 2.5433853695541657

Epoch: 6| Step: 6
Training loss: 3.374474378557788
Validation loss: 2.5416804511148503

Epoch: 6| Step: 7
Training loss: 2.8961248091047644
Validation loss: 2.5317612575680166

Epoch: 6| Step: 8
Training loss: 3.238679095264687
Validation loss: 2.5303297650148937

Epoch: 6| Step: 9
Training loss: 3.0298131309773177
Validation loss: 2.5278864046541343

Epoch: 6| Step: 10
Training loss: 2.8765496762894838
Validation loss: 2.5332602344106796

Epoch: 6| Step: 11
Training loss: 2.496549704969305
Validation loss: 2.534473458639106

Epoch: 6| Step: 12
Training loss: 2.953962580666606
Validation loss: 2.5274133322242114

Epoch: 6| Step: 13
Training loss: 2.828056966901185
Validation loss: 2.531586819461027

Epoch: 114| Step: 0
Training loss: 2.8441653105580444
Validation loss: 2.526460919581964

Epoch: 6| Step: 1
Training loss: 3.0648170580881886
Validation loss: 2.5205848860916564

Epoch: 6| Step: 2
Training loss: 2.844733770212719
Validation loss: 2.5300107312731797

Epoch: 6| Step: 3
Training loss: 2.5581615286762713
Validation loss: 2.5253580858024214

Epoch: 6| Step: 4
Training loss: 2.683566030833917
Validation loss: 2.5356582141367383

Epoch: 6| Step: 5
Training loss: 2.9615365179857704
Validation loss: 2.5313099912651564

Epoch: 6| Step: 6
Training loss: 2.1302815046233747
Validation loss: 2.5441429331153502

Epoch: 6| Step: 7
Training loss: 3.3567382400544212
Validation loss: 2.5454239860587906

Epoch: 6| Step: 8
Training loss: 3.172848556766043
Validation loss: 2.5470585256475173

Epoch: 6| Step: 9
Training loss: 2.923805292788273
Validation loss: 2.543904932963784

Epoch: 6| Step: 10
Training loss: 3.0366629809103522
Validation loss: 2.5425728974861523

Epoch: 6| Step: 11
Training loss: 2.9631112606854106
Validation loss: 2.552726736492822

Epoch: 6| Step: 12
Training loss: 2.806649544528494
Validation loss: 2.5441045750974776

Epoch: 6| Step: 13
Training loss: 2.96440545462355
Validation loss: 2.5430451630166426

Epoch: 115| Step: 0
Training loss: 2.3260510314762
Validation loss: 2.5378717717224433

Epoch: 6| Step: 1
Training loss: 3.1984764048302528
Validation loss: 2.5502915850453296

Epoch: 6| Step: 2
Training loss: 2.8577305802356294
Validation loss: 2.571569284164985

Epoch: 6| Step: 3
Training loss: 2.8011448835594717
Validation loss: 2.5388096191080605

Epoch: 6| Step: 4
Training loss: 2.9617271477558336
Validation loss: 2.5276705115756686

Epoch: 6| Step: 5
Training loss: 2.816265044462112
Validation loss: 2.521653768900645

Epoch: 6| Step: 6
Training loss: 2.6540976387122366
Validation loss: 2.522929260382889

Epoch: 6| Step: 7
Training loss: 3.315683957941069
Validation loss: 2.5221836341858785

Epoch: 6| Step: 8
Training loss: 2.6024014606564374
Validation loss: 2.5225469537336727

Epoch: 6| Step: 9
Training loss: 2.7427155510652534
Validation loss: 2.5247356327163923

Epoch: 6| Step: 10
Training loss: 2.3836654387239604
Validation loss: 2.5219688529301476

Epoch: 6| Step: 11
Training loss: 3.3290627461344426
Validation loss: 2.528624225620998

Epoch: 6| Step: 12
Training loss: 3.2527237262645436
Validation loss: 2.546408543039813

Epoch: 6| Step: 13
Training loss: 3.1568687512311944
Validation loss: 2.5411579450731665

Epoch: 116| Step: 0
Training loss: 2.687001914065907
Validation loss: 2.5445046415625354

Epoch: 6| Step: 1
Training loss: 2.702368216887694
Validation loss: 2.5509879223511147

Epoch: 6| Step: 2
Training loss: 3.2857492753055424
Validation loss: 2.542685356193773

Epoch: 6| Step: 3
Training loss: 2.42984047558392
Validation loss: 2.552775021596851

Epoch: 6| Step: 4
Training loss: 3.2767864567335216
Validation loss: 2.5429803938637123

Epoch: 6| Step: 5
Training loss: 2.5299933811146396
Validation loss: 2.544552003653797

Epoch: 6| Step: 6
Training loss: 3.0000190734256957
Validation loss: 2.5385357134691313

Epoch: 6| Step: 7
Training loss: 2.8194582165745543
Validation loss: 2.535071984346857

Epoch: 6| Step: 8
Training loss: 2.4927424945926813
Validation loss: 2.5313573713481285

Epoch: 6| Step: 9
Training loss: 3.2652608129948644
Validation loss: 2.5219341048675554

Epoch: 6| Step: 10
Training loss: 2.655356402712684
Validation loss: 2.528317623450457

Epoch: 6| Step: 11
Training loss: 3.403408860487242
Validation loss: 2.51844078988811

Epoch: 6| Step: 12
Training loss: 2.870428680411024
Validation loss: 2.5211813217084877

Epoch: 6| Step: 13
Training loss: 2.7264225877426127
Validation loss: 2.5233311865835066

Epoch: 117| Step: 0
Training loss: 2.715490557785349
Validation loss: 2.5228551941186774

Epoch: 6| Step: 1
Training loss: 2.7208271203741745
Validation loss: 2.5251461923653347

Epoch: 6| Step: 2
Training loss: 2.6555806831366353
Validation loss: 2.525930858973063

Epoch: 6| Step: 3
Training loss: 3.3984638783099834
Validation loss: 2.5219890521879633

Epoch: 6| Step: 4
Training loss: 1.5910452536735278
Validation loss: 2.522677467979587

Epoch: 6| Step: 5
Training loss: 2.4291803253819295
Validation loss: 2.521747176004511

Epoch: 6| Step: 6
Training loss: 3.1647752500648214
Validation loss: 2.523770350164463

Epoch: 6| Step: 7
Training loss: 2.9505841662800005
Validation loss: 2.522660001328965

Epoch: 6| Step: 8
Training loss: 2.987448981579686
Validation loss: 2.5493098129014764

Epoch: 6| Step: 9
Training loss: 3.155865183117953
Validation loss: 2.5572540004412305

Epoch: 6| Step: 10
Training loss: 3.195582744483901
Validation loss: 2.5402972191623627

Epoch: 6| Step: 11
Training loss: 2.7508527127284084
Validation loss: 2.536650923467358

Epoch: 6| Step: 12
Training loss: 3.170434483737809
Validation loss: 2.526110656391577

Epoch: 6| Step: 13
Training loss: 3.3103891520780153
Validation loss: 2.5234477740983157

Epoch: 118| Step: 0
Training loss: 2.98549994392248
Validation loss: 2.5317009428328534

Epoch: 6| Step: 1
Training loss: 2.9184886872577334
Validation loss: 2.533297332776112

Epoch: 6| Step: 2
Training loss: 3.4559127118778825
Validation loss: 2.537818683548078

Epoch: 6| Step: 3
Training loss: 2.7859501930927544
Validation loss: 2.562083296730832

Epoch: 6| Step: 4
Training loss: 2.9090428212916355
Validation loss: 2.569995631067447

Epoch: 6| Step: 5
Training loss: 3.1165789246745517
Validation loss: 2.556786005839619

Epoch: 6| Step: 6
Training loss: 3.232273321973545
Validation loss: 2.5596438922675633

Epoch: 6| Step: 7
Training loss: 2.348857350233429
Validation loss: 2.5484996762090426

Epoch: 6| Step: 8
Training loss: 2.4593749883668696
Validation loss: 2.530866060316392

Epoch: 6| Step: 9
Training loss: 2.761430738827573
Validation loss: 2.5243109080459827

Epoch: 6| Step: 10
Training loss: 2.8211514818046504
Validation loss: 2.526034226875441

Epoch: 6| Step: 11
Training loss: 2.8795504839088832
Validation loss: 2.5199414744012905

Epoch: 6| Step: 12
Training loss: 2.6098973099833733
Validation loss: 2.5164933231811117

Epoch: 6| Step: 13
Training loss: 2.936493559147133
Validation loss: 2.5158440452438153

Epoch: 119| Step: 0
Training loss: 2.7898684921171655
Validation loss: 2.516642725449729

Epoch: 6| Step: 1
Training loss: 2.940970136473325
Validation loss: 2.5145904481443604

Epoch: 6| Step: 2
Training loss: 2.683188861804016
Validation loss: 2.515226520724775

Epoch: 6| Step: 3
Training loss: 2.8654006254490367
Validation loss: 2.5211138630630305

Epoch: 6| Step: 4
Training loss: 3.0597768081349637
Validation loss: 2.528596084085229

Epoch: 6| Step: 5
Training loss: 2.914523745280556
Validation loss: 2.5209645167928034

Epoch: 6| Step: 6
Training loss: 3.0339739643506207
Validation loss: 2.5235328962334056

Epoch: 6| Step: 7
Training loss: 3.3715070380531023
Validation loss: 2.5220936372528584

Epoch: 6| Step: 8
Training loss: 2.9763303651177195
Validation loss: 2.52119059934906

Epoch: 6| Step: 9
Training loss: 2.695571665812242
Validation loss: 2.5216729337069204

Epoch: 6| Step: 10
Training loss: 2.8382479921130725
Validation loss: 2.5296491074777796

Epoch: 6| Step: 11
Training loss: 2.0445242625471685
Validation loss: 2.521784413242417

Epoch: 6| Step: 12
Training loss: 2.938296595571135
Validation loss: 2.523718663806175

Epoch: 6| Step: 13
Training loss: 3.062732298468163
Validation loss: 2.535912885250675

Epoch: 120| Step: 0
Training loss: 2.720316468509275
Validation loss: 2.5426639924770638

Epoch: 6| Step: 1
Training loss: 2.5965682196247104
Validation loss: 2.5347550731700355

Epoch: 6| Step: 2
Training loss: 3.3051776206898595
Validation loss: 2.5379392349527556

Epoch: 6| Step: 3
Training loss: 3.119443913323197
Validation loss: 2.5686143879295553

Epoch: 6| Step: 4
Training loss: 2.1093327270793085
Validation loss: 2.556249167239126

Epoch: 6| Step: 5
Training loss: 2.935506428270509
Validation loss: 2.5492535819522177

Epoch: 6| Step: 6
Training loss: 2.8088764159848467
Validation loss: 2.5456155601831933

Epoch: 6| Step: 7
Training loss: 3.4946680326618007
Validation loss: 2.521798494100051

Epoch: 6| Step: 8
Training loss: 3.128903506845708
Validation loss: 2.5117234450861443

Epoch: 6| Step: 9
Training loss: 3.0455153341450596
Validation loss: 2.510461755700897

Epoch: 6| Step: 10
Training loss: 2.7987644909734435
Validation loss: 2.514020447442504

Epoch: 6| Step: 11
Training loss: 2.9395611613244235
Validation loss: 2.5154768815405704

Epoch: 6| Step: 12
Training loss: 2.4844164574960743
Validation loss: 2.517615800665038

Epoch: 6| Step: 13
Training loss: 2.391861240655394
Validation loss: 2.5213274568506057

Epoch: 121| Step: 0
Training loss: 3.765841149422411
Validation loss: 2.5250199658995345

Epoch: 6| Step: 1
Training loss: 2.276174883286475
Validation loss: 2.513932018340255

Epoch: 6| Step: 2
Training loss: 2.6591235605649395
Validation loss: 2.5130746231983068

Epoch: 6| Step: 3
Training loss: 2.702510344902798
Validation loss: 2.5175044705470104

Epoch: 6| Step: 4
Training loss: 2.5358255734190696
Validation loss: 2.5511336112513274

Epoch: 6| Step: 5
Training loss: 3.2673978966752357
Validation loss: 2.556037069948199

Epoch: 6| Step: 6
Training loss: 3.066000980882183
Validation loss: 2.575684632370765

Epoch: 6| Step: 7
Training loss: 3.1981047203281285
Validation loss: 2.5424792522084356

Epoch: 6| Step: 8
Training loss: 2.594100376960589
Validation loss: 2.564517381829923

Epoch: 6| Step: 9
Training loss: 3.2299885514000346
Validation loss: 2.525129716924792

Epoch: 6| Step: 10
Training loss: 2.683111200161645
Validation loss: 2.524831564755907

Epoch: 6| Step: 11
Training loss: 2.5991645277609123
Validation loss: 2.506229169025235

Epoch: 6| Step: 12
Training loss: 2.9671247350111916
Validation loss: 2.5097282492751947

Epoch: 6| Step: 13
Training loss: 2.0131180424349435
Validation loss: 2.5036818464392203

Epoch: 122| Step: 0
Training loss: 3.272177806639884
Validation loss: 2.5021280296709016

Epoch: 6| Step: 1
Training loss: 2.7703942163660944
Validation loss: 2.5064344111045616

Epoch: 6| Step: 2
Training loss: 2.682907971931212
Validation loss: 2.5055488738889413

Epoch: 6| Step: 3
Training loss: 3.1619174043700298
Validation loss: 2.5092171807574752

Epoch: 6| Step: 4
Training loss: 2.6968133700546044
Validation loss: 2.5064190615415924

Epoch: 6| Step: 5
Training loss: 2.551412834267849
Validation loss: 2.5071838089727767

Epoch: 6| Step: 6
Training loss: 3.144303174958593
Validation loss: 2.5202255418031823

Epoch: 6| Step: 7
Training loss: 3.0135706095267647
Validation loss: 2.5528050486864062

Epoch: 6| Step: 8
Training loss: 3.0107056018191476
Validation loss: 2.5442734443934207

Epoch: 6| Step: 9
Training loss: 3.3056431463980083
Validation loss: 2.5415253891623584

Epoch: 6| Step: 10
Training loss: 1.8447714093857166
Validation loss: 2.5501615034011613

Epoch: 6| Step: 11
Training loss: 3.0148519997781658
Validation loss: 2.55016026790486

Epoch: 6| Step: 12
Training loss: 2.776494106809248
Validation loss: 2.532212925358341

Epoch: 6| Step: 13
Training loss: 2.7114765609693245
Validation loss: 2.514164556678291

Epoch: 123| Step: 0
Training loss: 2.5049414436364303
Validation loss: 2.511029890859659

Epoch: 6| Step: 1
Training loss: 3.095119905136609
Validation loss: 2.5046550716366154

Epoch: 6| Step: 2
Training loss: 2.705746476549739
Validation loss: 2.500665604779682

Epoch: 6| Step: 3
Training loss: 2.5444429170843628
Validation loss: 2.503924216569025

Epoch: 6| Step: 4
Training loss: 3.0438389445944547
Validation loss: 2.5098199337247795

Epoch: 6| Step: 5
Training loss: 3.530616906052636
Validation loss: 2.5053824370492026

Epoch: 6| Step: 6
Training loss: 3.2993220066295703
Validation loss: 2.5107195257956945

Epoch: 6| Step: 7
Training loss: 2.742900005925277
Validation loss: 2.510073115484175

Epoch: 6| Step: 8
Training loss: 2.377422302131731
Validation loss: 2.514038878108431

Epoch: 6| Step: 9
Training loss: 2.7686532892770024
Validation loss: 2.521113182269647

Epoch: 6| Step: 10
Training loss: 2.5835179191190885
Validation loss: 2.5302572345585697

Epoch: 6| Step: 11
Training loss: 2.7977415479297676
Validation loss: 2.5267568249317716

Epoch: 6| Step: 12
Training loss: 3.239453148551489
Validation loss: 2.5316776697745915

Epoch: 6| Step: 13
Training loss: 2.5038581641187605
Validation loss: 2.534273681946008

Epoch: 124| Step: 0
Training loss: 2.5998683602680073
Validation loss: 2.5423024083644377

Epoch: 6| Step: 1
Training loss: 3.0032940899327527
Validation loss: 2.5448046594555476

Epoch: 6| Step: 2
Training loss: 2.7651397796673196
Validation loss: 2.5501347078753764

Epoch: 6| Step: 3
Training loss: 3.1634780155561737
Validation loss: 2.5669889991063344

Epoch: 6| Step: 4
Training loss: 3.0276815902721266
Validation loss: 2.5384057363493673

Epoch: 6| Step: 5
Training loss: 3.000006357822039
Validation loss: 2.558905124074057

Epoch: 6| Step: 6
Training loss: 2.684921269461279
Validation loss: 2.529427917154449

Epoch: 6| Step: 7
Training loss: 2.8812882029882396
Validation loss: 2.518034189831403

Epoch: 6| Step: 8
Training loss: 2.3998850079644725
Validation loss: 2.5124749790081027

Epoch: 6| Step: 9
Training loss: 3.2986855981458794
Validation loss: 2.5042505779263338

Epoch: 6| Step: 10
Training loss: 2.798964928999127
Validation loss: 2.5063821841570957

Epoch: 6| Step: 11
Training loss: 3.1637060647518993
Validation loss: 2.501485836294726

Epoch: 6| Step: 12
Training loss: 2.1947725656985106
Validation loss: 2.4994945425331045

Epoch: 6| Step: 13
Training loss: 2.966082529001453
Validation loss: 2.492876169933499

Epoch: 125| Step: 0
Training loss: 2.814479555089293
Validation loss: 2.4939269915189968

Epoch: 6| Step: 1
Training loss: 3.2053820589723676
Validation loss: 2.4994487754646104

Epoch: 6| Step: 2
Training loss: 2.7555229906325036
Validation loss: 2.497240315344848

Epoch: 6| Step: 3
Training loss: 2.871934998459397
Validation loss: 2.497283694533127

Epoch: 6| Step: 4
Training loss: 2.576152069732911
Validation loss: 2.4947149742050136

Epoch: 6| Step: 5
Training loss: 2.8226406811776563
Validation loss: 2.5014110582294284

Epoch: 6| Step: 6
Training loss: 3.222575756570501
Validation loss: 2.4947662266585446

Epoch: 6| Step: 7
Training loss: 2.8776297773829684
Validation loss: 2.504419524219291

Epoch: 6| Step: 8
Training loss: 2.8448571366037956
Validation loss: 2.5169868286233537

Epoch: 6| Step: 9
Training loss: 2.7722773314786915
Validation loss: 2.5324105514422497

Epoch: 6| Step: 10
Training loss: 2.8182165753411046
Validation loss: 2.5359367583454477

Epoch: 6| Step: 11
Training loss: 3.323286237264994
Validation loss: 2.5718297812828568

Epoch: 6| Step: 12
Training loss: 2.6130776090779344
Validation loss: 2.566814640905854

Epoch: 6| Step: 13
Training loss: 2.324338457887574
Validation loss: 2.547120870145387

Epoch: 126| Step: 0
Training loss: 3.0382750601593864
Validation loss: 2.534970942365889

Epoch: 6| Step: 1
Training loss: 2.5081100525019684
Validation loss: 2.5114051432839317

Epoch: 6| Step: 2
Training loss: 2.742811778593148
Validation loss: 2.5045422891994003

Epoch: 6| Step: 3
Training loss: 3.4330072346851934
Validation loss: 2.4994812181014248

Epoch: 6| Step: 4
Training loss: 3.014804392427006
Validation loss: 2.493473987867396

Epoch: 6| Step: 5
Training loss: 2.8343289439908244
Validation loss: 2.499167075917984

Epoch: 6| Step: 6
Training loss: 2.624203697404451
Validation loss: 2.5035015216352874

Epoch: 6| Step: 7
Training loss: 3.0963208854732533
Validation loss: 2.4957686557949517

Epoch: 6| Step: 8
Training loss: 2.8102591170444837
Validation loss: 2.4955957667552937

Epoch: 6| Step: 9
Training loss: 2.983808693406408
Validation loss: 2.49829207910899

Epoch: 6| Step: 10
Training loss: 2.319735368565945
Validation loss: 2.5019887074545966

Epoch: 6| Step: 11
Training loss: 2.9755447530071595
Validation loss: 2.5117645287568515

Epoch: 6| Step: 12
Training loss: 2.810694644905749
Validation loss: 2.5077916478194284

Epoch: 6| Step: 13
Training loss: 2.621640644352566
Validation loss: 2.5422646679578373

Epoch: 127| Step: 0
Training loss: 2.2945657137190896
Validation loss: 2.5931858359004596

Epoch: 6| Step: 1
Training loss: 2.706904420730209
Validation loss: 2.636086527913437

Epoch: 6| Step: 2
Training loss: 2.6195866306729743
Validation loss: 2.6444375469035886

Epoch: 6| Step: 3
Training loss: 3.3574737136504886
Validation loss: 2.6761162962709193

Epoch: 6| Step: 4
Training loss: 2.67676484901369
Validation loss: 2.56913940956728

Epoch: 6| Step: 5
Training loss: 3.0045198724082836
Validation loss: 2.518655237876216

Epoch: 6| Step: 6
Training loss: 2.7729299161400056
Validation loss: 2.4988032788944308

Epoch: 6| Step: 7
Training loss: 2.929666666592592
Validation loss: 2.5036924350656427

Epoch: 6| Step: 8
Training loss: 2.8515285542178987
Validation loss: 2.5124083069875165

Epoch: 6| Step: 9
Training loss: 2.9363288979873765
Validation loss: 2.525056838105868

Epoch: 6| Step: 10
Training loss: 2.841092890949263
Validation loss: 2.53046975111358

Epoch: 6| Step: 11
Training loss: 3.1769610438757665
Validation loss: 2.538073990381758

Epoch: 6| Step: 12
Training loss: 3.1681544840936984
Validation loss: 2.5410226994244685

Epoch: 6| Step: 13
Training loss: 3.110669810543551
Validation loss: 2.5311080850297305

Epoch: 128| Step: 0
Training loss: 3.110176481532335
Validation loss: 2.5283190957358554

Epoch: 6| Step: 1
Training loss: 2.9534877978102374
Validation loss: 2.5261305875935247

Epoch: 6| Step: 2
Training loss: 3.3715685601762924
Validation loss: 2.545133116706137

Epoch: 6| Step: 3
Training loss: 2.936841200954526
Validation loss: 2.525868517708562

Epoch: 6| Step: 4
Training loss: 2.4377010947196265
Validation loss: 2.5350802029196635

Epoch: 6| Step: 5
Training loss: 2.179145773014928
Validation loss: 2.52834961605962

Epoch: 6| Step: 6
Training loss: 3.142500284296598
Validation loss: 2.5461100492688313

Epoch: 6| Step: 7
Training loss: 3.101527446865836
Validation loss: 2.528488593452239

Epoch: 6| Step: 8
Training loss: 2.7134037287841335
Validation loss: 2.5524632683209423

Epoch: 6| Step: 9
Training loss: 2.2942015990694564
Validation loss: 2.544632785878038

Epoch: 6| Step: 10
Training loss: 2.9297696928574495
Validation loss: 2.526505118200346

Epoch: 6| Step: 11
Training loss: 3.1498883787693264
Validation loss: 2.52238874180573

Epoch: 6| Step: 12
Training loss: 2.9425694975833467
Validation loss: 2.518329851520514

Epoch: 6| Step: 13
Training loss: 2.975816688316567
Validation loss: 2.525350919275485

Epoch: 129| Step: 0
Training loss: 2.6486531847785026
Validation loss: 2.526449151891651

Epoch: 6| Step: 1
Training loss: 3.0490408217767975
Validation loss: 2.5429555011336906

Epoch: 6| Step: 2
Training loss: 3.1336300513276907
Validation loss: 2.536987918159241

Epoch: 6| Step: 3
Training loss: 2.1075026502852783
Validation loss: 2.543893727677519

Epoch: 6| Step: 4
Training loss: 3.121159138668915
Validation loss: 2.54770648488401

Epoch: 6| Step: 5
Training loss: 2.6280968881162687
Validation loss: 2.5490604266957226

Epoch: 6| Step: 6
Training loss: 2.5992924864674807
Validation loss: 2.559084153522896

Epoch: 6| Step: 7
Training loss: 3.2831418351098147
Validation loss: 2.5669094737407265

Epoch: 6| Step: 8
Training loss: 2.8218910259074796
Validation loss: 2.5560493543533904

Epoch: 6| Step: 9
Training loss: 2.8736540919656623
Validation loss: 2.5510966044421273

Epoch: 6| Step: 10
Training loss: 3.10612663162215
Validation loss: 2.554490322805088

Epoch: 6| Step: 11
Training loss: 2.642344981169514
Validation loss: 2.534955879874865

Epoch: 6| Step: 12
Training loss: 2.8781881484933263
Validation loss: 2.529527082635996

Epoch: 6| Step: 13
Training loss: 3.100620539915187
Validation loss: 2.513600639026558

Epoch: 130| Step: 0
Training loss: 2.4492282897666087
Validation loss: 2.501852330658323

Epoch: 6| Step: 1
Training loss: 2.257537930699044
Validation loss: 2.500829844003898

Epoch: 6| Step: 2
Training loss: 2.5332691945773993
Validation loss: 2.4893360215043865

Epoch: 6| Step: 3
Training loss: 3.3046279072179328
Validation loss: 2.4846264420482043

Epoch: 6| Step: 4
Training loss: 2.773864541286795
Validation loss: 2.493452189145368

Epoch: 6| Step: 5
Training loss: 2.3189341757291744
Validation loss: 2.496046015854818

Epoch: 6| Step: 6
Training loss: 3.524683019576196
Validation loss: 2.494917074374027

Epoch: 6| Step: 7
Training loss: 2.3350726411617164
Validation loss: 2.4951115261723484

Epoch: 6| Step: 8
Training loss: 2.734129627662488
Validation loss: 2.4939156387762274

Epoch: 6| Step: 9
Training loss: 3.371321474872795
Validation loss: 2.496412646460045

Epoch: 6| Step: 10
Training loss: 3.673033446332333
Validation loss: 2.5036055140296516

Epoch: 6| Step: 11
Training loss: 2.878150374873297
Validation loss: 2.5011238115371297

Epoch: 6| Step: 12
Training loss: 2.5359305916984134
Validation loss: 2.4949492656233216

Epoch: 6| Step: 13
Training loss: 2.8044770993341515
Validation loss: 2.496803280546299

Epoch: 131| Step: 0
Training loss: 2.6655600357636393
Validation loss: 2.4928438866099603

Epoch: 6| Step: 1
Training loss: 2.4926495258319754
Validation loss: 2.494074495380509

Epoch: 6| Step: 2
Training loss: 3.8240783478599507
Validation loss: 2.498282535827944

Epoch: 6| Step: 3
Training loss: 2.6687645011704424
Validation loss: 2.508277960019483

Epoch: 6| Step: 4
Training loss: 3.1290085069803455
Validation loss: 2.515420600557975

Epoch: 6| Step: 5
Training loss: 2.4069258496250487
Validation loss: 2.520647633145978

Epoch: 6| Step: 6
Training loss: 3.1734567090368286
Validation loss: 2.53631165119851

Epoch: 6| Step: 7
Training loss: 2.7100997641805593
Validation loss: 2.537510664560985

Epoch: 6| Step: 8
Training loss: 3.351442703916007
Validation loss: 2.5271447386053354

Epoch: 6| Step: 9
Training loss: 2.603880162055456
Validation loss: 2.487465509142677

Epoch: 6| Step: 10
Training loss: 2.3505576385201907
Validation loss: 2.4799028242753476

Epoch: 6| Step: 11
Training loss: 2.748164691582021
Validation loss: 2.4853668348450477

Epoch: 6| Step: 12
Training loss: 2.27983551067824
Validation loss: 2.4922760176120504

Epoch: 6| Step: 13
Training loss: 3.6856290305744532
Validation loss: 2.5022743769861724

Epoch: 132| Step: 0
Training loss: 2.42403841912319
Validation loss: 2.4932106796187936

Epoch: 6| Step: 1
Training loss: 2.8821119165338236
Validation loss: 2.486407816544143

Epoch: 6| Step: 2
Training loss: 2.7680431074964305
Validation loss: 2.479641675920814

Epoch: 6| Step: 3
Training loss: 2.33111441783026
Validation loss: 2.4828998057872367

Epoch: 6| Step: 4
Training loss: 2.862860218021426
Validation loss: 2.4800199958466203

Epoch: 6| Step: 5
Training loss: 2.6147878093223476
Validation loss: 2.4880950070381345

Epoch: 6| Step: 6
Training loss: 2.71013275426608
Validation loss: 2.4880347388402018

Epoch: 6| Step: 7
Training loss: 3.0345353089090303
Validation loss: 2.4976703577132255

Epoch: 6| Step: 8
Training loss: 3.3758258515589503
Validation loss: 2.507834617556315

Epoch: 6| Step: 9
Training loss: 2.8992958134673423
Validation loss: 2.5074542227994567

Epoch: 6| Step: 10
Training loss: 3.2138234184481607
Validation loss: 2.5119107534920158

Epoch: 6| Step: 11
Training loss: 3.1513912458893403
Validation loss: 2.5121899479557315

Epoch: 6| Step: 12
Training loss: 2.9246292596596786
Validation loss: 2.50061340087558

Epoch: 6| Step: 13
Training loss: 2.179236799561822
Validation loss: 2.50518779444765

Epoch: 133| Step: 0
Training loss: 3.0744368246786973
Validation loss: 2.5100058255718163

Epoch: 6| Step: 1
Training loss: 2.032531803346804
Validation loss: 2.5044633236287974

Epoch: 6| Step: 2
Training loss: 2.623715767748412
Validation loss: 2.5120004079989

Epoch: 6| Step: 3
Training loss: 2.4572916787408814
Validation loss: 2.512508507456381

Epoch: 6| Step: 4
Training loss: 2.4379051067482664
Validation loss: 2.522426910702553

Epoch: 6| Step: 5
Training loss: 3.1891567935862213
Validation loss: 2.5386789592275503

Epoch: 6| Step: 6
Training loss: 3.1958487883736635
Validation loss: 2.535393138098227

Epoch: 6| Step: 7
Training loss: 2.5040790658905325
Validation loss: 2.5464893972446814

Epoch: 6| Step: 8
Training loss: 3.339492511684328
Validation loss: 2.52969134009577

Epoch: 6| Step: 9
Training loss: 3.0977045851564693
Validation loss: 2.5083932113191554

Epoch: 6| Step: 10
Training loss: 2.5883282906736373
Validation loss: 2.487130685442908

Epoch: 6| Step: 11
Training loss: 3.3497964256264363
Validation loss: 2.477923793062778

Epoch: 6| Step: 12
Training loss: 2.620799745992385
Validation loss: 2.487944662769147

Epoch: 6| Step: 13
Training loss: 2.838433630517634
Validation loss: 2.497870273356484

Epoch: 134| Step: 0
Training loss: 2.536304466599
Validation loss: 2.5031643058879376

Epoch: 6| Step: 1
Training loss: 3.066152768683146
Validation loss: 2.5096026233314204

Epoch: 6| Step: 2
Training loss: 2.7489039230792174
Validation loss: 2.5075742812675523

Epoch: 6| Step: 3
Training loss: 3.430869348531701
Validation loss: 2.511582517232974

Epoch: 6| Step: 4
Training loss: 2.4552097088034825
Validation loss: 2.502603633301309

Epoch: 6| Step: 5
Training loss: 2.810077726164777
Validation loss: 2.513434303916297

Epoch: 6| Step: 6
Training loss: 2.414869253911849
Validation loss: 2.5017307504764617

Epoch: 6| Step: 7
Training loss: 2.5159376435853718
Validation loss: 2.4978535374408866

Epoch: 6| Step: 8
Training loss: 3.334753751113627
Validation loss: 2.495952272440943

Epoch: 6| Step: 9
Training loss: 3.2013738544043964
Validation loss: 2.5045260119155084

Epoch: 6| Step: 10
Training loss: 2.597708014639307
Validation loss: 2.5247686282336335

Epoch: 6| Step: 11
Training loss: 2.6301270324429407
Validation loss: 2.5494833259724983

Epoch: 6| Step: 12
Training loss: 2.8760529953234832
Validation loss: 2.5694820038425394

Epoch: 6| Step: 13
Training loss: 3.4449743680180362
Validation loss: 2.588448780534391

Epoch: 135| Step: 0
Training loss: 3.3381463271536282
Validation loss: 2.6457688037333846

Epoch: 6| Step: 1
Training loss: 3.1070667689736493
Validation loss: 2.5978162155100817

Epoch: 6| Step: 2
Training loss: 2.709282801554243
Validation loss: 2.5570692755927134

Epoch: 6| Step: 3
Training loss: 2.355212449131074
Validation loss: 2.5241372032944303

Epoch: 6| Step: 4
Training loss: 2.8967523740227175
Validation loss: 2.5023719220823097

Epoch: 6| Step: 5
Training loss: 2.515880879722279
Validation loss: 2.491060839434559

Epoch: 6| Step: 6
Training loss: 2.8296326048996074
Validation loss: 2.4894172938144843

Epoch: 6| Step: 7
Training loss: 2.736136343291542
Validation loss: 2.4821437888640143

Epoch: 6| Step: 8
Training loss: 3.0426304130846127
Validation loss: 2.480231142311082

Epoch: 6| Step: 9
Training loss: 3.356660819883536
Validation loss: 2.479171965598481

Epoch: 6| Step: 10
Training loss: 3.022421496107761
Validation loss: 2.4672895976790765

Epoch: 6| Step: 11
Training loss: 2.576457090980286
Validation loss: 2.4712518632179368

Epoch: 6| Step: 12
Training loss: 2.70691622314913
Validation loss: 2.473115598775

Epoch: 6| Step: 13
Training loss: 2.7147644470488053
Validation loss: 2.4767691405470917

Epoch: 136| Step: 0
Training loss: 2.9906636234607538
Validation loss: 2.4778017112792723

Epoch: 6| Step: 1
Training loss: 2.45358534460153
Validation loss: 2.491917906791868

Epoch: 6| Step: 2
Training loss: 3.5230494790935185
Validation loss: 2.5056856741142135

Epoch: 6| Step: 3
Training loss: 3.6368443583134926
Validation loss: 2.5405223199514744

Epoch: 6| Step: 4
Training loss: 2.792115407908549
Validation loss: 2.5184936289553055

Epoch: 6| Step: 5
Training loss: 2.499188482179367
Validation loss: 2.5163555813022276

Epoch: 6| Step: 6
Training loss: 3.183101236826551
Validation loss: 2.540993175779616

Epoch: 6| Step: 7
Training loss: 2.379755980219532
Validation loss: 2.544092207823623

Epoch: 6| Step: 8
Training loss: 2.8184644397971175
Validation loss: 2.5474890431669612

Epoch: 6| Step: 9
Training loss: 2.558369634000057
Validation loss: 2.530260009694534

Epoch: 6| Step: 10
Training loss: 2.229867723929638
Validation loss: 2.5240283608177196

Epoch: 6| Step: 11
Training loss: 2.7673936781063158
Validation loss: 2.5103208468864087

Epoch: 6| Step: 12
Training loss: 3.139483951513612
Validation loss: 2.499789685457666

Epoch: 6| Step: 13
Training loss: 2.086882987748288
Validation loss: 2.499462058529323

Epoch: 137| Step: 0
Training loss: 2.2512885748371714
Validation loss: 2.493721218633362

Epoch: 6| Step: 1
Training loss: 2.5785885480818904
Validation loss: 2.4893329432833142

Epoch: 6| Step: 2
Training loss: 2.8489265695831745
Validation loss: 2.489643508781825

Epoch: 6| Step: 3
Training loss: 3.1710315202958737
Validation loss: 2.4958547219377487

Epoch: 6| Step: 4
Training loss: 2.901438349798366
Validation loss: 2.493775424441647

Epoch: 6| Step: 5
Training loss: 2.7969411490519005
Validation loss: 2.493950161480145

Epoch: 6| Step: 6
Training loss: 3.059404326659746
Validation loss: 2.5006012265400175

Epoch: 6| Step: 7
Training loss: 3.517613369999719
Validation loss: 2.5052044481089535

Epoch: 6| Step: 8
Training loss: 2.869535477425078
Validation loss: 2.5124276984369427

Epoch: 6| Step: 9
Training loss: 2.5155596043397264
Validation loss: 2.519968811232151

Epoch: 6| Step: 10
Training loss: 2.3953514499072988
Validation loss: 2.517836839427164

Epoch: 6| Step: 11
Training loss: 2.424868401171595
Validation loss: 2.5075584970203466

Epoch: 6| Step: 12
Training loss: 3.466693440358381
Validation loss: 2.5105283323695464

Epoch: 6| Step: 13
Training loss: 2.4184076899904374
Validation loss: 2.519876425773804

Epoch: 138| Step: 0
Training loss: 3.009636343346062
Validation loss: 2.5345273229003302

Epoch: 6| Step: 1
Training loss: 2.812810414456214
Validation loss: 2.5287146967572625

Epoch: 6| Step: 2
Training loss: 2.899573419700793
Validation loss: 2.513865662858413

Epoch: 6| Step: 3
Training loss: 2.7806124867358992
Validation loss: 2.499124791140125

Epoch: 6| Step: 4
Training loss: 3.2264028883796474
Validation loss: 2.49282354683192

Epoch: 6| Step: 5
Training loss: 3.216247771136701
Validation loss: 2.490703964016104

Epoch: 6| Step: 6
Training loss: 2.4717641851419976
Validation loss: 2.4922231545053073

Epoch: 6| Step: 7
Training loss: 2.757396461292967
Validation loss: 2.4834141719412357

Epoch: 6| Step: 8
Training loss: 2.8723407554475973
Validation loss: 2.4870879108861943

Epoch: 6| Step: 9
Training loss: 2.6972294721452483
Validation loss: 2.484353161684438

Epoch: 6| Step: 10
Training loss: 2.7097281361153693
Validation loss: 2.4962921261458013

Epoch: 6| Step: 11
Training loss: 2.3145301773830043
Validation loss: 2.5086387438806783

Epoch: 6| Step: 12
Training loss: 2.3803499097615064
Validation loss: 2.518849870802614

Epoch: 6| Step: 13
Training loss: 3.590735722122006
Validation loss: 2.5048670870290066

Epoch: 139| Step: 0
Training loss: 2.730081206011729
Validation loss: 2.5062239419624146

Epoch: 6| Step: 1
Training loss: 2.752036121164623
Validation loss: 2.5108464466754765

Epoch: 6| Step: 2
Training loss: 2.7820828508810194
Validation loss: 2.4989226942622578

Epoch: 6| Step: 3
Training loss: 2.8364711290944817
Validation loss: 2.493520272763635

Epoch: 6| Step: 4
Training loss: 3.1110488756706354
Validation loss: 2.4920942482140904

Epoch: 6| Step: 5
Training loss: 3.2087940199076077
Validation loss: 2.4854827204787577

Epoch: 6| Step: 6
Training loss: 2.7781468771383144
Validation loss: 2.483159942489709

Epoch: 6| Step: 7
Training loss: 2.9490234310322703
Validation loss: 2.4819779526503885

Epoch: 6| Step: 8
Training loss: 2.1167823995154045
Validation loss: 2.4810901238532233

Epoch: 6| Step: 9
Training loss: 2.9818647922332353
Validation loss: 2.4775967058418575

Epoch: 6| Step: 10
Training loss: 2.8140595244921975
Validation loss: 2.474807973318955

Epoch: 6| Step: 11
Training loss: 2.866870332476665
Validation loss: 2.4806227288946148

Epoch: 6| Step: 12
Training loss: 2.8050428925089004
Validation loss: 2.48589213669113

Epoch: 6| Step: 13
Training loss: 2.716856549263752
Validation loss: 2.4874873386851717

Epoch: 140| Step: 0
Training loss: 2.2870938425163754
Validation loss: 2.5045699844958462

Epoch: 6| Step: 1
Training loss: 3.232678249368537
Validation loss: 2.52024777828009

Epoch: 6| Step: 2
Training loss: 3.076946981960749
Validation loss: 2.5553198729753364

Epoch: 6| Step: 3
Training loss: 3.00876322991791
Validation loss: 2.5080260505742946

Epoch: 6| Step: 4
Training loss: 3.309956131612726
Validation loss: 2.509246541896124

Epoch: 6| Step: 5
Training loss: 2.4752143535846356
Validation loss: 2.494923469294809

Epoch: 6| Step: 6
Training loss: 2.8753748110385677
Validation loss: 2.487803221568568

Epoch: 6| Step: 7
Training loss: 3.30896786642972
Validation loss: 2.4995274538108596

Epoch: 6| Step: 8
Training loss: 2.5707962833086246
Validation loss: 2.486930060077672

Epoch: 6| Step: 9
Training loss: 2.595076623862159
Validation loss: 2.498831490235776

Epoch: 6| Step: 10
Training loss: 2.5808396352662877
Validation loss: 2.494329723464071

Epoch: 6| Step: 11
Training loss: 2.6719929630049823
Validation loss: 2.502393304001855

Epoch: 6| Step: 12
Training loss: 2.369601589307181
Validation loss: 2.5116317647969586

Epoch: 6| Step: 13
Training loss: 2.724854642158428
Validation loss: 2.5094262301375116

Epoch: 141| Step: 0
Training loss: 3.525785150405346
Validation loss: 2.5112072065808633

Epoch: 6| Step: 1
Training loss: 2.5496316980407774
Validation loss: 2.5107322831126293

Epoch: 6| Step: 2
Training loss: 3.1429490936749405
Validation loss: 2.509253048951435

Epoch: 6| Step: 3
Training loss: 2.4991385883188366
Validation loss: 2.52205345472998

Epoch: 6| Step: 4
Training loss: 2.860145340007531
Validation loss: 2.514836441436824

Epoch: 6| Step: 5
Training loss: 1.5549466477836509
Validation loss: 2.5128867782057034

Epoch: 6| Step: 6
Training loss: 3.0788968275575024
Validation loss: 2.506930476536173

Epoch: 6| Step: 7
Training loss: 3.2147725538896506
Validation loss: 2.5045267581220703

Epoch: 6| Step: 8
Training loss: 2.7605396651209886
Validation loss: 2.4968605859296704

Epoch: 6| Step: 9
Training loss: 2.4480391343236185
Validation loss: 2.5029879669852924

Epoch: 6| Step: 10
Training loss: 2.6910788194332667
Validation loss: 2.5074893913346847

Epoch: 6| Step: 11
Training loss: 2.7956219642054694
Validation loss: 2.5049070156133637

Epoch: 6| Step: 12
Training loss: 2.8307877118964995
Validation loss: 2.492079078819958

Epoch: 6| Step: 13
Training loss: 3.063896794874317
Validation loss: 2.4905892302232617

Epoch: 142| Step: 0
Training loss: 3.0167787548619027
Validation loss: 2.486454562909549

Epoch: 6| Step: 1
Training loss: 2.5929971544549515
Validation loss: 2.4764166467118516

Epoch: 6| Step: 2
Training loss: 2.3044473813936523
Validation loss: 2.466503882198692

Epoch: 6| Step: 3
Training loss: 2.7679755787626568
Validation loss: 2.47801719842476

Epoch: 6| Step: 4
Training loss: 2.555320544655308
Validation loss: 2.489829897443275

Epoch: 6| Step: 5
Training loss: 2.628477517887919
Validation loss: 2.5175841125754648

Epoch: 6| Step: 6
Training loss: 2.8504034325676697
Validation loss: 2.5284115012224424

Epoch: 6| Step: 7
Training loss: 3.277090433399603
Validation loss: 2.523300867684478

Epoch: 6| Step: 8
Training loss: 3.0207172941524014
Validation loss: 2.5304993980430615

Epoch: 6| Step: 9
Training loss: 3.216284539118432
Validation loss: 2.536394030052007

Epoch: 6| Step: 10
Training loss: 3.0855553499040944
Validation loss: 2.517665058514032

Epoch: 6| Step: 11
Training loss: 2.96978003050149
Validation loss: 2.5029785839773866

Epoch: 6| Step: 12
Training loss: 2.4464865111808094
Validation loss: 2.4840180366379063

Epoch: 6| Step: 13
Training loss: 2.227430208014044
Validation loss: 2.473199765930352

Epoch: 143| Step: 0
Training loss: 2.9187919139915777
Validation loss: 2.4632663700898063

Epoch: 6| Step: 1
Training loss: 3.091071308183522
Validation loss: 2.462974008584124

Epoch: 6| Step: 2
Training loss: 2.9102978153487036
Validation loss: 2.4675921269922276

Epoch: 6| Step: 3
Training loss: 2.741251293900476
Validation loss: 2.4671329640256574

Epoch: 6| Step: 4
Training loss: 2.308666144202527
Validation loss: 2.4665424679277517

Epoch: 6| Step: 5
Training loss: 2.737376195468273
Validation loss: 2.477985751946

Epoch: 6| Step: 6
Training loss: 2.8054836492692554
Validation loss: 2.4719052445880263

Epoch: 6| Step: 7
Training loss: 2.353631209071772
Validation loss: 2.479771803306732

Epoch: 6| Step: 8
Training loss: 2.9211028195587505
Validation loss: 2.4824412652289802

Epoch: 6| Step: 9
Training loss: 2.228532742594206
Validation loss: 2.518923833986822

Epoch: 6| Step: 10
Training loss: 2.9653318302450327
Validation loss: 2.5541071274405964

Epoch: 6| Step: 11
Training loss: 2.9613709950234224
Validation loss: 2.575582758948513

Epoch: 6| Step: 12
Training loss: 2.924706866582039
Validation loss: 2.581534964135074

Epoch: 6| Step: 13
Training loss: 3.8505807364281384
Validation loss: 2.5422236465881496

Epoch: 144| Step: 0
Training loss: 3.2178780569107883
Validation loss: 2.5368778141054635

Epoch: 6| Step: 1
Training loss: 3.232789023946977
Validation loss: 2.5050383005203996

Epoch: 6| Step: 2
Training loss: 2.5546181578951686
Validation loss: 2.502853873998842

Epoch: 6| Step: 3
Training loss: 3.2466912666448904
Validation loss: 2.5078891602766906

Epoch: 6| Step: 4
Training loss: 2.943092865702661
Validation loss: 2.499916961275274

Epoch: 6| Step: 5
Training loss: 2.997948103778112
Validation loss: 2.492451653818595

Epoch: 6| Step: 6
Training loss: 2.7460161309376225
Validation loss: 2.4983829693378277

Epoch: 6| Step: 7
Training loss: 2.1829865896151204
Validation loss: 2.5019984994187725

Epoch: 6| Step: 8
Training loss: 1.9405940792059073
Validation loss: 2.494877775075806

Epoch: 6| Step: 9
Training loss: 2.727790708914789
Validation loss: 2.4968643427890167

Epoch: 6| Step: 10
Training loss: 2.6973379292558155
Validation loss: 2.4798515664977985

Epoch: 6| Step: 11
Training loss: 2.6450337280545946
Validation loss: 2.466528812698077

Epoch: 6| Step: 12
Training loss: 3.1589452736157395
Validation loss: 2.460616496021252

Epoch: 6| Step: 13
Training loss: 2.658688850506692
Validation loss: 2.457920335589328

Epoch: 145| Step: 0
Training loss: 3.3635009977391106
Validation loss: 2.4695418803711635

Epoch: 6| Step: 1
Training loss: 2.993846304027425
Validation loss: 2.477185795451695

Epoch: 6| Step: 2
Training loss: 2.694469198351367
Validation loss: 2.480749242644601

Epoch: 6| Step: 3
Training loss: 2.6102045077007827
Validation loss: 2.481853040636877

Epoch: 6| Step: 4
Training loss: 2.2996914781053164
Validation loss: 2.485354725077603

Epoch: 6| Step: 5
Training loss: 2.494922058478152
Validation loss: 2.5179742416695556

Epoch: 6| Step: 6
Training loss: 2.610228986962616
Validation loss: 2.5461187628388133

Epoch: 6| Step: 7
Training loss: 3.7142339901938235
Validation loss: 2.561240804506165

Epoch: 6| Step: 8
Training loss: 2.8917395839970226
Validation loss: 2.5631468701999562

Epoch: 6| Step: 9
Training loss: 3.0013949012333274
Validation loss: 2.5215487040130156

Epoch: 6| Step: 10
Training loss: 2.194995137689371
Validation loss: 2.5003820578575864

Epoch: 6| Step: 11
Training loss: 2.978812261099622
Validation loss: 2.475681761009053

Epoch: 6| Step: 12
Training loss: 2.7009519099926185
Validation loss: 2.461259624535066

Epoch: 6| Step: 13
Training loss: 2.225028490034144
Validation loss: 2.452072176803925

Epoch: 146| Step: 0
Training loss: 3.0902509842948125
Validation loss: 2.4557119826130775

Epoch: 6| Step: 1
Training loss: 3.2577835191494233
Validation loss: 2.4582598861045177

Epoch: 6| Step: 2
Training loss: 2.9853914936403725
Validation loss: 2.459993407456296

Epoch: 6| Step: 3
Training loss: 2.5290086029618366
Validation loss: 2.45725710214729

Epoch: 6| Step: 4
Training loss: 2.7999477449718153
Validation loss: 2.4588249852293256

Epoch: 6| Step: 5
Training loss: 3.2880457668042897
Validation loss: 2.452842254573796

Epoch: 6| Step: 6
Training loss: 2.6496865357033825
Validation loss: 2.4614003996345737

Epoch: 6| Step: 7
Training loss: 2.655895882731642
Validation loss: 2.4749539483406684

Epoch: 6| Step: 8
Training loss: 1.9554339379485957
Validation loss: 2.485059337817433

Epoch: 6| Step: 9
Training loss: 3.106305164484382
Validation loss: 2.4859851601613716

Epoch: 6| Step: 10
Training loss: 2.6383489245951903
Validation loss: 2.48676543066561

Epoch: 6| Step: 11
Training loss: 2.800194416789675
Validation loss: 2.510360041780397

Epoch: 6| Step: 12
Training loss: 2.63095162845166
Validation loss: 2.5193110518670614

Epoch: 6| Step: 13
Training loss: 2.7344078715937097
Validation loss: 2.5029903775143922

Epoch: 147| Step: 0
Training loss: 3.101012519867739
Validation loss: 2.5085930041447737

Epoch: 6| Step: 1
Training loss: 2.992141285033929
Validation loss: 2.486810414179532

Epoch: 6| Step: 2
Training loss: 1.6102944867699522
Validation loss: 2.475517049440445

Epoch: 6| Step: 3
Training loss: 2.845442383601966
Validation loss: 2.4826013290058038

Epoch: 6| Step: 4
Training loss: 3.4115472602416497
Validation loss: 2.478267400762585

Epoch: 6| Step: 5
Training loss: 2.7714107361164855
Validation loss: 2.494236363677143

Epoch: 6| Step: 6
Training loss: 3.0242064136518603
Validation loss: 2.519858379642669

Epoch: 6| Step: 7
Training loss: 2.79233049689356
Validation loss: 2.5586594615201648

Epoch: 6| Step: 8
Training loss: 2.566029327908828
Validation loss: 2.5495505593769687

Epoch: 6| Step: 9
Training loss: 2.858377084499164
Validation loss: 2.5571852702968747

Epoch: 6| Step: 10
Training loss: 2.9899232429680085
Validation loss: 2.524711021100117

Epoch: 6| Step: 11
Training loss: 2.8562533322237638
Validation loss: 2.4811104420281085

Epoch: 6| Step: 12
Training loss: 2.5256685486087918
Validation loss: 2.4659089293019916

Epoch: 6| Step: 13
Training loss: 2.3465439482953943
Validation loss: 2.451869466950294

Epoch: 148| Step: 0
Training loss: 2.6508808399473747
Validation loss: 2.460202127446891

Epoch: 6| Step: 1
Training loss: 2.8119434229828304
Validation loss: 2.4598283488732986

Epoch: 6| Step: 2
Training loss: 2.2983832564912845
Validation loss: 2.4556557402042856

Epoch: 6| Step: 3
Training loss: 3.1875857173389552
Validation loss: 2.457197581525911

Epoch: 6| Step: 4
Training loss: 2.9569894845651064
Validation loss: 2.4616929886441303

Epoch: 6| Step: 5
Training loss: 2.8775921621403073
Validation loss: 2.4810931751031835

Epoch: 6| Step: 6
Training loss: 2.577873541388686
Validation loss: 2.4818340796563136

Epoch: 6| Step: 7
Training loss: 2.9836066889775736
Validation loss: 2.5275445856316208

Epoch: 6| Step: 8
Training loss: 3.197053840534648
Validation loss: 2.584864462014974

Epoch: 6| Step: 9
Training loss: 3.0110633621871785
Validation loss: 2.6225724566141775

Epoch: 6| Step: 10
Training loss: 2.115887457430907
Validation loss: 2.6209007930487576

Epoch: 6| Step: 11
Training loss: 3.152401532443627
Validation loss: 2.5666783320440585

Epoch: 6| Step: 12
Training loss: 2.629856793671189
Validation loss: 2.5476651969287896

Epoch: 6| Step: 13
Training loss: 3.073151418910999
Validation loss: 2.5069172090116325

Epoch: 149| Step: 0
Training loss: 2.7888886213196944
Validation loss: 2.491935391911766

Epoch: 6| Step: 1
Training loss: 2.6913070328228765
Validation loss: 2.471730054221589

Epoch: 6| Step: 2
Training loss: 2.928915751216168
Validation loss: 2.4680518205021182

Epoch: 6| Step: 3
Training loss: 2.7433479657561235
Validation loss: 2.4606978505986614

Epoch: 6| Step: 4
Training loss: 2.6297216185398073
Validation loss: 2.459750577409225

Epoch: 6| Step: 5
Training loss: 2.9722840806776865
Validation loss: 2.4613975489449893

Epoch: 6| Step: 6
Training loss: 2.2999823693968033
Validation loss: 2.459470141570205

Epoch: 6| Step: 7
Training loss: 2.7533554067334958
Validation loss: 2.4604460517711138

Epoch: 6| Step: 8
Training loss: 2.642288496635196
Validation loss: 2.453727044774268

Epoch: 6| Step: 9
Training loss: 2.7588424704454217
Validation loss: 2.4547610846874783

Epoch: 6| Step: 10
Training loss: 2.991280440651057
Validation loss: 2.470301161439963

Epoch: 6| Step: 11
Training loss: 3.188739610368707
Validation loss: 2.476398674160004

Epoch: 6| Step: 12
Training loss: 2.7612233452742996
Validation loss: 2.4767929047090473

Epoch: 6| Step: 13
Training loss: 3.1192824893380555
Validation loss: 2.480622693756752

Epoch: 150| Step: 0
Training loss: 3.596313623655131
Validation loss: 2.4965785886989247

Epoch: 6| Step: 1
Training loss: 2.2621671400169703
Validation loss: 2.500882718927163

Epoch: 6| Step: 2
Training loss: 2.1796339021608033
Validation loss: 2.5162800632985864

Epoch: 6| Step: 3
Training loss: 2.750829571530015
Validation loss: 2.52752988764185

Epoch: 6| Step: 4
Training loss: 2.5841000762432804
Validation loss: 2.497326761922073

Epoch: 6| Step: 5
Training loss: 2.5948834987354013
Validation loss: 2.5459532270971077

Epoch: 6| Step: 6
Training loss: 3.4102516117286497
Validation loss: 2.5439127692781915

Epoch: 6| Step: 7
Training loss: 1.9407209879406795
Validation loss: 2.5258462647416566

Epoch: 6| Step: 8
Training loss: 3.0247347313454322
Validation loss: 2.507495343702067

Epoch: 6| Step: 9
Training loss: 2.7260855446125327
Validation loss: 2.4775395633203345

Epoch: 6| Step: 10
Training loss: 2.670421093227626
Validation loss: 2.4656163144716046

Epoch: 6| Step: 11
Training loss: 3.410711883338647
Validation loss: 2.4561756541418336

Epoch: 6| Step: 12
Training loss: 2.9716458301451967
Validation loss: 2.461969188328412

Epoch: 6| Step: 13
Training loss: 1.8737161055356484
Validation loss: 2.4499011494222653

Epoch: 151| Step: 0
Training loss: 2.7991145879820736
Validation loss: 2.4540406908576884

Epoch: 6| Step: 1
Training loss: 3.3109295559149183
Validation loss: 2.4547292494246817

Epoch: 6| Step: 2
Training loss: 2.5997394211109355
Validation loss: 2.4481669318761092

Epoch: 6| Step: 3
Training loss: 2.8515487879593264
Validation loss: 2.4494747083006474

Epoch: 6| Step: 4
Training loss: 2.6134180053144407
Validation loss: 2.4534286270364536

Epoch: 6| Step: 5
Training loss: 2.488832900670211
Validation loss: 2.461905036320694

Epoch: 6| Step: 6
Training loss: 2.9784322157890872
Validation loss: 2.466634299410398

Epoch: 6| Step: 7
Training loss: 2.576480502830096
Validation loss: 2.4704632362925896

Epoch: 6| Step: 8
Training loss: 2.7425375168910953
Validation loss: 2.4692857004550093

Epoch: 6| Step: 9
Training loss: 2.0176484353295168
Validation loss: 2.490488309481987

Epoch: 6| Step: 10
Training loss: 2.9986345044530496
Validation loss: 2.5008975212451374

Epoch: 6| Step: 11
Training loss: 2.9761163171884024
Validation loss: 2.5362151941299196

Epoch: 6| Step: 12
Training loss: 3.167008448443453
Validation loss: 2.5345250632380725

Epoch: 6| Step: 13
Training loss: 2.530142742095718
Validation loss: 2.5583043970388433

Epoch: 152| Step: 0
Training loss: 3.0028515614837135
Validation loss: 2.5308255774480823

Epoch: 6| Step: 1
Training loss: 3.0272629462502505
Validation loss: 2.526455660302812

Epoch: 6| Step: 2
Training loss: 2.364187725655967
Validation loss: 2.4918056631037695

Epoch: 6| Step: 3
Training loss: 2.1769318474688566
Validation loss: 2.4857760793492565

Epoch: 6| Step: 4
Training loss: 2.6683052710876907
Validation loss: 2.472109865420129

Epoch: 6| Step: 5
Training loss: 3.038291068342004
Validation loss: 2.4659596680752354

Epoch: 6| Step: 6
Training loss: 2.752556133061689
Validation loss: 2.452744079657084

Epoch: 6| Step: 7
Training loss: 3.1482281863773753
Validation loss: 2.447019922709904

Epoch: 6| Step: 8
Training loss: 2.6241288328991836
Validation loss: 2.4456198968689926

Epoch: 6| Step: 9
Training loss: 3.1480655119112684
Validation loss: 2.445605681400864

Epoch: 6| Step: 10
Training loss: 2.6982112610763846
Validation loss: 2.450563760452313

Epoch: 6| Step: 11
Training loss: 2.503129240453893
Validation loss: 2.4456433012134946

Epoch: 6| Step: 12
Training loss: 2.6806676201023754
Validation loss: 2.4551465726389594

Epoch: 6| Step: 13
Training loss: 3.091126842274399
Validation loss: 2.4697461842294506

Epoch: 153| Step: 0
Training loss: 2.4891127988973833
Validation loss: 2.490294272377831

Epoch: 6| Step: 1
Training loss: 2.8757117675744235
Validation loss: 2.4974540072274998

Epoch: 6| Step: 2
Training loss: 2.554140364826268
Validation loss: 2.5480495653229145

Epoch: 6| Step: 3
Training loss: 2.506320497658111
Validation loss: 2.5866896519381313

Epoch: 6| Step: 4
Training loss: 3.403903257777116
Validation loss: 2.734580737927728

Epoch: 6| Step: 5
Training loss: 2.7165411383836546
Validation loss: 2.701552893257259

Epoch: 6| Step: 6
Training loss: 3.408546163789423
Validation loss: 2.6933576426550703

Epoch: 6| Step: 7
Training loss: 2.156639837877392
Validation loss: 2.613163781882447

Epoch: 6| Step: 8
Training loss: 2.676291312727797
Validation loss: 2.6216465106268014

Epoch: 6| Step: 9
Training loss: 2.6781113329330566
Validation loss: 2.5596792751857373

Epoch: 6| Step: 10
Training loss: 3.474436729391953
Validation loss: 2.504776176212614

Epoch: 6| Step: 11
Training loss: 2.697122159839794
Validation loss: 2.470963624432014

Epoch: 6| Step: 12
Training loss: 3.045941958249517
Validation loss: 2.4703657056132964

Epoch: 6| Step: 13
Training loss: 2.8315725652256685
Validation loss: 2.4621932225131005

Epoch: 154| Step: 0
Training loss: 3.4061062283753056
Validation loss: 2.4619898933869027

Epoch: 6| Step: 1
Training loss: 3.453988083907768
Validation loss: 2.4582878582730068

Epoch: 6| Step: 2
Training loss: 2.973743615803033
Validation loss: 2.4630510881116923

Epoch: 6| Step: 3
Training loss: 3.0894412466976733
Validation loss: 2.459830036199476

Epoch: 6| Step: 4
Training loss: 2.852531205858318
Validation loss: 2.4622933757839394

Epoch: 6| Step: 5
Training loss: 2.1399232034183657
Validation loss: 2.4635340755903905

Epoch: 6| Step: 6
Training loss: 2.846709670993467
Validation loss: 2.4668483884478603

Epoch: 6| Step: 7
Training loss: 2.0582102467212264
Validation loss: 2.4678517986117807

Epoch: 6| Step: 8
Training loss: 2.8182984660778008
Validation loss: 2.498473619235133

Epoch: 6| Step: 9
Training loss: 2.632725835896296
Validation loss: 2.493805294290981

Epoch: 6| Step: 10
Training loss: 2.48626924671301
Validation loss: 2.5191599587651288

Epoch: 6| Step: 11
Training loss: 2.915718324073317
Validation loss: 2.516017422837987

Epoch: 6| Step: 12
Training loss: 2.1136179883126465
Validation loss: 2.4890386893815437

Epoch: 6| Step: 13
Training loss: 3.346554729621138
Validation loss: 2.4847102105148897

Epoch: 155| Step: 0
Training loss: 2.9099312714525816
Validation loss: 2.47822970102529

Epoch: 6| Step: 1
Training loss: 2.8772126680915955
Validation loss: 2.4822196709957938

Epoch: 6| Step: 2
Training loss: 2.6606190372729093
Validation loss: 2.481152099759287

Epoch: 6| Step: 3
Training loss: 2.669155767178163
Validation loss: 2.480058617307647

Epoch: 6| Step: 4
Training loss: 2.4027285880147957
Validation loss: 2.4691793510535343

Epoch: 6| Step: 5
Training loss: 3.1124246488588634
Validation loss: 2.4737460579767894

Epoch: 6| Step: 6
Training loss: 2.6414780000849643
Validation loss: 2.480199963708063

Epoch: 6| Step: 7
Training loss: 3.4033647268891705
Validation loss: 2.4553419673574832

Epoch: 6| Step: 8
Training loss: 2.4059559035473725
Validation loss: 2.4660383228059146

Epoch: 6| Step: 9
Training loss: 2.388037284591955
Validation loss: 2.4616178911616684

Epoch: 6| Step: 10
Training loss: 2.5350862796102933
Validation loss: 2.455851450378719

Epoch: 6| Step: 11
Training loss: 3.2839690069113763
Validation loss: 2.453877032984842

Epoch: 6| Step: 12
Training loss: 2.6997181144786286
Validation loss: 2.455033112458373

Epoch: 6| Step: 13
Training loss: 2.6527252147675373
Validation loss: 2.4562684681211224

Epoch: 156| Step: 0
Training loss: 2.542794545384393
Validation loss: 2.4596628070641353

Epoch: 6| Step: 1
Training loss: 2.6701345742704348
Validation loss: 2.450923396005797

Epoch: 6| Step: 2
Training loss: 2.6834882024139994
Validation loss: 2.458376367010511

Epoch: 6| Step: 3
Training loss: 3.412778704653801
Validation loss: 2.456256471648504

Epoch: 6| Step: 4
Training loss: 2.7937794182442492
Validation loss: 2.4561119833416085

Epoch: 6| Step: 5
Training loss: 3.35112398564468
Validation loss: 2.4476452350785927

Epoch: 6| Step: 6
Training loss: 2.726324732340793
Validation loss: 2.460886320150666

Epoch: 6| Step: 7
Training loss: 2.1464392784872603
Validation loss: 2.4581797565551993

Epoch: 6| Step: 8
Training loss: 2.413538014740226
Validation loss: 2.464244454463761

Epoch: 6| Step: 9
Training loss: 2.745909683331495
Validation loss: 2.463374422386108

Epoch: 6| Step: 10
Training loss: 2.4973185463973504
Validation loss: 2.47329887542866

Epoch: 6| Step: 11
Training loss: 2.814900624094757
Validation loss: 2.4725934763764768

Epoch: 6| Step: 12
Training loss: 2.800841688623955
Validation loss: 2.4706149717382324

Epoch: 6| Step: 13
Training loss: 2.8758684588129233
Validation loss: 2.48908613562834

Epoch: 157| Step: 0
Training loss: 2.0921814010337494
Validation loss: 2.501898718262516

Epoch: 6| Step: 1
Training loss: 3.0647181049295718
Validation loss: 2.564863317182463

Epoch: 6| Step: 2
Training loss: 2.902301854772067
Validation loss: 2.627017242726308

Epoch: 6| Step: 3
Training loss: 3.2034504050602477
Validation loss: 2.651890295621354

Epoch: 6| Step: 4
Training loss: 3.2597801066466072
Validation loss: 2.6490115209949927

Epoch: 6| Step: 5
Training loss: 3.264815380724436
Validation loss: 2.5604282270720047

Epoch: 6| Step: 6
Training loss: 2.4556723810927465
Validation loss: 2.497939579472439

Epoch: 6| Step: 7
Training loss: 2.186863070812761
Validation loss: 2.4718247634480806

Epoch: 6| Step: 8
Training loss: 2.6461637295664633
Validation loss: 2.4627611889495022

Epoch: 6| Step: 9
Training loss: 2.6966283267690327
Validation loss: 2.460736050737583

Epoch: 6| Step: 10
Training loss: 3.4230442226895463
Validation loss: 2.4590169381273808

Epoch: 6| Step: 11
Training loss: 2.188541709274105
Validation loss: 2.4605483714161602

Epoch: 6| Step: 12
Training loss: 2.803302220894994
Validation loss: 2.447124838197281

Epoch: 6| Step: 13
Training loss: 2.598544916718605
Validation loss: 2.4512601480840117

Epoch: 158| Step: 0
Training loss: 3.064792786854436
Validation loss: 2.458667647577484

Epoch: 6| Step: 1
Training loss: 2.088243674108952
Validation loss: 2.453741540210993

Epoch: 6| Step: 2
Training loss: 2.6809134389925022
Validation loss: 2.468196276676412

Epoch: 6| Step: 3
Training loss: 2.236745790350762
Validation loss: 2.4761134810333596

Epoch: 6| Step: 4
Training loss: 3.0335335536174397
Validation loss: 2.47686126822923

Epoch: 6| Step: 5
Training loss: 2.1730790128496587
Validation loss: 2.4975457368090215

Epoch: 6| Step: 6
Training loss: 3.1597544033847744
Validation loss: 2.5222870748529074

Epoch: 6| Step: 7
Training loss: 2.6056358363895447
Validation loss: 2.539938277666322

Epoch: 6| Step: 8
Training loss: 3.1959129459522937
Validation loss: 2.5429140332078823

Epoch: 6| Step: 9
Training loss: 2.85929745428276
Validation loss: 2.51687549512965

Epoch: 6| Step: 10
Training loss: 2.6940617852209496
Validation loss: 2.487811877616477

Epoch: 6| Step: 11
Training loss: 2.508054917642289
Validation loss: 2.4610346865926997

Epoch: 6| Step: 12
Training loss: 3.096417134732597
Validation loss: 2.4438700521611443

Epoch: 6| Step: 13
Training loss: 3.396339347599161
Validation loss: 2.4492162315959005

Epoch: 159| Step: 0
Training loss: 3.249372568454262
Validation loss: 2.4624185840279145

Epoch: 6| Step: 1
Training loss: 2.8917066045489457
Validation loss: 2.479883177463868

Epoch: 6| Step: 2
Training loss: 2.808540184560697
Validation loss: 2.5032388707909874

Epoch: 6| Step: 3
Training loss: 2.750061207870416
Validation loss: 2.5021585907792776

Epoch: 6| Step: 4
Training loss: 2.706395194231097
Validation loss: 2.504030548210578

Epoch: 6| Step: 5
Training loss: 2.6420592977957265
Validation loss: 2.5457793747370534

Epoch: 6| Step: 6
Training loss: 2.888358717548392
Validation loss: 2.5401063854090404

Epoch: 6| Step: 7
Training loss: 3.5827257986845114
Validation loss: 2.5554676759360784

Epoch: 6| Step: 8
Training loss: 2.991013418582672
Validation loss: 2.4644842494594883

Epoch: 6| Step: 9
Training loss: 2.7453739096428302
Validation loss: 2.4689133811877437

Epoch: 6| Step: 10
Training loss: 2.649982733040462
Validation loss: 2.4612407048944824

Epoch: 6| Step: 11
Training loss: 2.404068589703002
Validation loss: 2.4853537255549796

Epoch: 6| Step: 12
Training loss: 2.509617046307307
Validation loss: 2.5445618952869027

Epoch: 6| Step: 13
Training loss: 2.6201602279648357
Validation loss: 2.6244149686585296

Epoch: 160| Step: 0
Training loss: 3.0985904934767756
Validation loss: 2.622814532454144

Epoch: 6| Step: 1
Training loss: 3.1080994409783234
Validation loss: 2.625378827966069

Epoch: 6| Step: 2
Training loss: 2.816188004882702
Validation loss: 2.605171042087752

Epoch: 6| Step: 3
Training loss: 2.5107532027665793
Validation loss: 2.5336391042081274

Epoch: 6| Step: 4
Training loss: 3.2811481278363828
Validation loss: 2.5181316161672567

Epoch: 6| Step: 5
Training loss: 2.5609841864416785
Validation loss: 2.484770935419085

Epoch: 6| Step: 6
Training loss: 2.547090298966424
Validation loss: 2.472799408232072

Epoch: 6| Step: 7
Training loss: 3.1600328192636296
Validation loss: 2.4688587759261766

Epoch: 6| Step: 8
Training loss: 2.5960817082481973
Validation loss: 2.4589306387458087

Epoch: 6| Step: 9
Training loss: 3.2187941464850294
Validation loss: 2.4521318186978873

Epoch: 6| Step: 10
Training loss: 2.5340623655706107
Validation loss: 2.461084148766356

Epoch: 6| Step: 11
Training loss: 3.0038906935349785
Validation loss: 2.4600066195846697

Epoch: 6| Step: 12
Training loss: 2.0399414740376205
Validation loss: 2.4519508853881415

Epoch: 6| Step: 13
Training loss: 1.75126159696803
Validation loss: 2.464609293872513

Epoch: 161| Step: 0
Training loss: 3.006870032944479
Validation loss: 2.4671225551653357

Epoch: 6| Step: 1
Training loss: 2.899888490308823
Validation loss: 2.465884597608012

Epoch: 6| Step: 2
Training loss: 2.7498108191875312
Validation loss: 2.4760583915920225

Epoch: 6| Step: 3
Training loss: 2.620371416279175
Validation loss: 2.474550570123469

Epoch: 6| Step: 4
Training loss: 2.8606201129160653
Validation loss: 2.481392844744434

Epoch: 6| Step: 5
Training loss: 2.6967628004796382
Validation loss: 2.495688531258426

Epoch: 6| Step: 6
Training loss: 2.4046958759600714
Validation loss: 2.4989686858873608

Epoch: 6| Step: 7
Training loss: 2.7480043626220367
Validation loss: 2.4932526729419773

Epoch: 6| Step: 8
Training loss: 2.8064681752104796
Validation loss: 2.5253588091032877

Epoch: 6| Step: 9
Training loss: 2.702765644861293
Validation loss: 2.5217489327109393

Epoch: 6| Step: 10
Training loss: 2.6873012735392408
Validation loss: 2.5598084415207523

Epoch: 6| Step: 11
Training loss: 2.3718234452385576
Validation loss: 2.5487302425745506

Epoch: 6| Step: 12
Training loss: 3.5673203900147024
Validation loss: 2.5692882150744345

Epoch: 6| Step: 13
Training loss: 2.3016386911661115
Validation loss: 2.5496081552839875

Epoch: 162| Step: 0
Training loss: 2.5839816069642203
Validation loss: 2.542374284612188

Epoch: 6| Step: 1
Training loss: 2.657041454211468
Validation loss: 2.5399716681635587

Epoch: 6| Step: 2
Training loss: 2.8574297181945503
Validation loss: 2.499618216044801

Epoch: 6| Step: 3
Training loss: 2.807032887569537
Validation loss: 2.4811275238799975

Epoch: 6| Step: 4
Training loss: 2.442452607802969
Validation loss: 2.4728481566422893

Epoch: 6| Step: 5
Training loss: 2.992632242721003
Validation loss: 2.471910708083835

Epoch: 6| Step: 6
Training loss: 2.7281349697564465
Validation loss: 2.4689545884777098

Epoch: 6| Step: 7
Training loss: 2.7843554015492042
Validation loss: 2.4669858133485656

Epoch: 6| Step: 8
Training loss: 2.8201282895443827
Validation loss: 2.465280992027389

Epoch: 6| Step: 9
Training loss: 2.9052516083738746
Validation loss: 2.4725432843249604

Epoch: 6| Step: 10
Training loss: 2.7709279916603826
Validation loss: 2.4760274327510974

Epoch: 6| Step: 11
Training loss: 2.646446807707302
Validation loss: 2.4688698986258943

Epoch: 6| Step: 12
Training loss: 3.162466140987996
Validation loss: 2.481649665305149

Epoch: 6| Step: 13
Training loss: 3.045059367385687
Validation loss: 2.504250516503391

Epoch: 163| Step: 0
Training loss: 2.4230335048889047
Validation loss: 2.531882698837831

Epoch: 6| Step: 1
Training loss: 2.607361890695792
Validation loss: 2.5394365760500768

Epoch: 6| Step: 2
Training loss: 3.0130240336769054
Validation loss: 2.5361451710775507

Epoch: 6| Step: 3
Training loss: 3.0655477500460666
Validation loss: 2.5376006986547432

Epoch: 6| Step: 4
Training loss: 3.193237227690666
Validation loss: 2.496228373530368

Epoch: 6| Step: 5
Training loss: 3.0497588765871746
Validation loss: 2.482510606571477

Epoch: 6| Step: 6
Training loss: 2.9535031354095467
Validation loss: 2.4733053640780858

Epoch: 6| Step: 7
Training loss: 1.7892364017640892
Validation loss: 2.471380804786172

Epoch: 6| Step: 8
Training loss: 2.5054118707550583
Validation loss: 2.4664729229613047

Epoch: 6| Step: 9
Training loss: 2.6655749728840257
Validation loss: 2.470606675689869

Epoch: 6| Step: 10
Training loss: 2.507797003487217
Validation loss: 2.4942426817147028

Epoch: 6| Step: 11
Training loss: 2.698542597170309
Validation loss: 2.5265557064960182

Epoch: 6| Step: 12
Training loss: 3.3230468979590335
Validation loss: 2.543075866494748

Epoch: 6| Step: 13
Training loss: 2.910152809089828
Validation loss: 2.568003070068773

Epoch: 164| Step: 0
Training loss: 2.4886186930851326
Validation loss: 2.551036634303597

Epoch: 6| Step: 1
Training loss: 2.441018523899603
Validation loss: 2.499947120763553

Epoch: 6| Step: 2
Training loss: 2.93672186102148
Validation loss: 2.497184781369469

Epoch: 6| Step: 3
Training loss: 3.3570574195912433
Validation loss: 2.492092595077629

Epoch: 6| Step: 4
Training loss: 3.045858203735956
Validation loss: 2.4775398571900706

Epoch: 6| Step: 5
Training loss: 3.0592992755686907
Validation loss: 2.4647754416410006

Epoch: 6| Step: 6
Training loss: 2.5714325942658944
Validation loss: 2.455026960840365

Epoch: 6| Step: 7
Training loss: 2.146920851394126
Validation loss: 2.453100781869515

Epoch: 6| Step: 8
Training loss: 3.110003077269378
Validation loss: 2.4483281463687834

Epoch: 6| Step: 9
Training loss: 2.176720791309789
Validation loss: 2.463403884505923

Epoch: 6| Step: 10
Training loss: 2.742153591370212
Validation loss: 2.4720831712060845

Epoch: 6| Step: 11
Training loss: 2.489678342488032
Validation loss: 2.4783800207089053

Epoch: 6| Step: 12
Training loss: 2.462128172555613
Validation loss: 2.478855590937665

Epoch: 6| Step: 13
Training loss: 3.5950130730870096
Validation loss: 2.490520292915281

Epoch: 165| Step: 0
Training loss: 3.053403618710183
Validation loss: 2.4863878999551012

Epoch: 6| Step: 1
Training loss: 2.5355803571367166
Validation loss: 2.476327277502166

Epoch: 6| Step: 2
Training loss: 2.3346511207700584
Validation loss: 2.482104284743522

Epoch: 6| Step: 3
Training loss: 3.0500984551219816
Validation loss: 2.47368149733179

Epoch: 6| Step: 4
Training loss: 2.3107942011872193
Validation loss: 2.4885419769287602

Epoch: 6| Step: 5
Training loss: 2.601231734410123
Validation loss: 2.5034036488194875

Epoch: 6| Step: 6
Training loss: 3.012790276562462
Validation loss: 2.4892280909715936

Epoch: 6| Step: 7
Training loss: 3.416176566972345
Validation loss: 2.483013685865095

Epoch: 6| Step: 8
Training loss: 3.0880700577413323
Validation loss: 2.4822180949399364

Epoch: 6| Step: 9
Training loss: 2.0664443245104063
Validation loss: 2.4728707797499374

Epoch: 6| Step: 10
Training loss: 2.71663197415283
Validation loss: 2.4707440886951573

Epoch: 6| Step: 11
Training loss: 3.0442170898984338
Validation loss: 2.4682529333798175

Epoch: 6| Step: 12
Training loss: 2.513931936758394
Validation loss: 2.474345643964979

Epoch: 6| Step: 13
Training loss: 2.318029751439431
Validation loss: 2.4731063040509826

Epoch: 166| Step: 0
Training loss: 2.184007963634127
Validation loss: 2.489867636731482

Epoch: 6| Step: 1
Training loss: 2.6874980482937136
Validation loss: 2.48396739375019

Epoch: 6| Step: 2
Training loss: 2.7121231168860054
Validation loss: 2.4900203271022883

Epoch: 6| Step: 3
Training loss: 2.8742435952989767
Validation loss: 2.497948047476711

Epoch: 6| Step: 4
Training loss: 2.504392008446404
Validation loss: 2.4941203656923894

Epoch: 6| Step: 5
Training loss: 2.6310434255811326
Validation loss: 2.490832594377851

Epoch: 6| Step: 6
Training loss: 3.044661906597887
Validation loss: 2.489934487604278

Epoch: 6| Step: 7
Training loss: 2.547400765475002
Validation loss: 2.457596646762755

Epoch: 6| Step: 8
Training loss: 2.636155177039402
Validation loss: 2.479116158209172

Epoch: 6| Step: 9
Training loss: 2.7079086753287855
Validation loss: 2.4779831820818936

Epoch: 6| Step: 10
Training loss: 3.165350155135172
Validation loss: 2.4696935333266157

Epoch: 6| Step: 11
Training loss: 2.489469666592913
Validation loss: 2.47621816705911

Epoch: 6| Step: 12
Training loss: 3.0665234974598894
Validation loss: 2.478974163647085

Epoch: 6| Step: 13
Training loss: 2.599845617552593
Validation loss: 2.4863541301123924

Epoch: 167| Step: 0
Training loss: 2.5261682432781805
Validation loss: 2.468292694499518

Epoch: 6| Step: 1
Training loss: 3.8621801151291764
Validation loss: 2.4647361282430196

Epoch: 6| Step: 2
Training loss: 2.84584823165129
Validation loss: 2.4655530631917584

Epoch: 6| Step: 3
Training loss: 2.7911757896387988
Validation loss: 2.4652362718505847

Epoch: 6| Step: 4
Training loss: 2.7137120364857754
Validation loss: 2.462955547609482

Epoch: 6| Step: 5
Training loss: 2.527576559625941
Validation loss: 2.4650067712867654

Epoch: 6| Step: 6
Training loss: 2.896449967924012
Validation loss: 2.457213014250361

Epoch: 6| Step: 7
Training loss: 2.7554073922853837
Validation loss: 2.4483138356322853

Epoch: 6| Step: 8
Training loss: 2.315660121718299
Validation loss: 2.4419589606633236

Epoch: 6| Step: 9
Training loss: 2.4019481302166925
Validation loss: 2.4458888556494363

Epoch: 6| Step: 10
Training loss: 2.1400622442587407
Validation loss: 2.444974776176753

Epoch: 6| Step: 11
Training loss: 2.856065846856832
Validation loss: 2.44501759743034

Epoch: 6| Step: 12
Training loss: 2.387731059612265
Validation loss: 2.4485514414511975

Epoch: 6| Step: 13
Training loss: 2.75034676879713
Validation loss: 2.4441639971068647

Epoch: 168| Step: 0
Training loss: 2.5791942806542547
Validation loss: 2.451511175922316

Epoch: 6| Step: 1
Training loss: 2.1413212221752453
Validation loss: 2.4653488995475645

Epoch: 6| Step: 2
Training loss: 3.2617833662199907
Validation loss: 2.467823912513403

Epoch: 6| Step: 3
Training loss: 2.5780856042799676
Validation loss: 2.4846921235831747

Epoch: 6| Step: 4
Training loss: 2.4924626213492633
Validation loss: 2.498113382818041

Epoch: 6| Step: 5
Training loss: 2.872602707211104
Validation loss: 2.4946754995925335

Epoch: 6| Step: 6
Training loss: 2.9624369103518378
Validation loss: 2.497721099963626

Epoch: 6| Step: 7
Training loss: 2.031291550431401
Validation loss: 2.483122098158531

Epoch: 6| Step: 8
Training loss: 2.8280816680792094
Validation loss: 2.445163072632543

Epoch: 6| Step: 9
Training loss: 3.334634924127298
Validation loss: 2.442396466274504

Epoch: 6| Step: 10
Training loss: 2.5144970183477136
Validation loss: 2.444657312242231

Epoch: 6| Step: 11
Training loss: 3.063824425629508
Validation loss: 2.439044018478109

Epoch: 6| Step: 12
Training loss: 2.5479284810758984
Validation loss: 2.4380322961871874

Epoch: 6| Step: 13
Training loss: 2.4018470808992847
Validation loss: 2.4308097554855626

Epoch: 169| Step: 0
Training loss: 3.177233149430467
Validation loss: 2.4387752656159845

Epoch: 6| Step: 1
Training loss: 2.2007034737599125
Validation loss: 2.446548811966353

Epoch: 6| Step: 2
Training loss: 2.9320810534838935
Validation loss: 2.4401292642784567

Epoch: 6| Step: 3
Training loss: 2.485861759242793
Validation loss: 2.4526466272627974

Epoch: 6| Step: 4
Training loss: 2.5448106696072164
Validation loss: 2.4585111173815997

Epoch: 6| Step: 5
Training loss: 3.092826936751127
Validation loss: 2.469497671290041

Epoch: 6| Step: 6
Training loss: 2.9001015875551066
Validation loss: 2.452788235339009

Epoch: 6| Step: 7
Training loss: 2.597774738104769
Validation loss: 2.453360729179374

Epoch: 6| Step: 8
Training loss: 2.91605732320111
Validation loss: 2.458074431623709

Epoch: 6| Step: 9
Training loss: 2.6275195790876174
Validation loss: 2.444701756602272

Epoch: 6| Step: 10
Training loss: 2.6084121480943483
Validation loss: 2.463013421927204

Epoch: 6| Step: 11
Training loss: 3.033588883530896
Validation loss: 2.4705756225916318

Epoch: 6| Step: 12
Training loss: 2.006209865655867
Validation loss: 2.498427074662811

Epoch: 6| Step: 13
Training loss: 2.4510328762568534
Validation loss: 2.5188810239062045

Epoch: 170| Step: 0
Training loss: 2.472932001680702
Validation loss: 2.525695132221648

Epoch: 6| Step: 1
Training loss: 2.914635650477881
Validation loss: 2.506421619638144

Epoch: 6| Step: 2
Training loss: 2.3835672152632355
Validation loss: 2.501132903230633

Epoch: 6| Step: 3
Training loss: 2.759664200243919
Validation loss: 2.4935869357542932

Epoch: 6| Step: 4
Training loss: 2.888464042610131
Validation loss: 2.4642621499844894

Epoch: 6| Step: 5
Training loss: 2.1872222724087504
Validation loss: 2.455184759431394

Epoch: 6| Step: 6
Training loss: 2.199757484594116
Validation loss: 2.463724656419759

Epoch: 6| Step: 7
Training loss: 2.948484619928528
Validation loss: 2.455675397111212

Epoch: 6| Step: 8
Training loss: 2.317436516642256
Validation loss: 2.452045958668701

Epoch: 6| Step: 9
Training loss: 3.354499721379822
Validation loss: 2.4666911728292087

Epoch: 6| Step: 10
Training loss: 2.911598779956527
Validation loss: 2.4633074147848815

Epoch: 6| Step: 11
Training loss: 2.775987511274185
Validation loss: 2.448489626138967

Epoch: 6| Step: 12
Training loss: 2.5184021778235417
Validation loss: 2.457859362432077

Epoch: 6| Step: 13
Training loss: 2.820119835356772
Validation loss: 2.4652981045285665

Epoch: 171| Step: 0
Training loss: 2.7011748760038463
Validation loss: 2.469425875783437

Epoch: 6| Step: 1
Training loss: 2.907622966708084
Validation loss: 2.495011455205366

Epoch: 6| Step: 2
Training loss: 2.138504537367539
Validation loss: 2.5198262120781565

Epoch: 6| Step: 3
Training loss: 2.493927829300846
Validation loss: 2.5126112087899757

Epoch: 6| Step: 4
Training loss: 2.7156097868217786
Validation loss: 2.516213503817946

Epoch: 6| Step: 5
Training loss: 2.7818945662856613
Validation loss: 2.510447717460214

Epoch: 6| Step: 6
Training loss: 2.4265011810985295
Validation loss: 2.5144855229615484

Epoch: 6| Step: 7
Training loss: 3.158376449518803
Validation loss: 2.5312641335329147

Epoch: 6| Step: 8
Training loss: 2.1078646303464845
Validation loss: 2.516992720844778

Epoch: 6| Step: 9
Training loss: 2.9481705375423277
Validation loss: 2.519298911918543

Epoch: 6| Step: 10
Training loss: 2.8605482685648833
Validation loss: 2.53262948158524

Epoch: 6| Step: 11
Training loss: 2.981242668094856
Validation loss: 2.5317939731844232

Epoch: 6| Step: 12
Training loss: 2.239095223634249
Validation loss: 2.4921775650771223

Epoch: 6| Step: 13
Training loss: 3.5318447726172466
Validation loss: 2.4761828732658353

Epoch: 172| Step: 0
Training loss: 2.6653091332960788
Validation loss: 2.4481867839954568

Epoch: 6| Step: 1
Training loss: 2.479242938067884
Validation loss: 2.463216623893485

Epoch: 6| Step: 2
Training loss: 2.3938401486625276
Validation loss: 2.4620477924863775

Epoch: 6| Step: 3
Training loss: 2.694115768346712
Validation loss: 2.4676460112350855

Epoch: 6| Step: 4
Training loss: 2.8648003143438205
Validation loss: 2.4726639917452014

Epoch: 6| Step: 5
Training loss: 2.815283182376625
Validation loss: 2.4760369116788277

Epoch: 6| Step: 6
Training loss: 3.129001649314224
Validation loss: 2.4880025688947893

Epoch: 6| Step: 7
Training loss: 2.8295692423349474
Validation loss: 2.4993055168615586

Epoch: 6| Step: 8
Training loss: 2.745446683744948
Validation loss: 2.4476521949793

Epoch: 6| Step: 9
Training loss: 2.730683630699994
Validation loss: 2.43910152261692

Epoch: 6| Step: 10
Training loss: 2.767521698133529
Validation loss: 2.448512679000361

Epoch: 6| Step: 11
Training loss: 2.8824833214203687
Validation loss: 2.4517289256945767

Epoch: 6| Step: 12
Training loss: 2.7343715122745613
Validation loss: 2.4959136658109737

Epoch: 6| Step: 13
Training loss: 2.7395031606645865
Validation loss: 2.537826751801866

Epoch: 173| Step: 0
Training loss: 2.907002013340618
Validation loss: 2.5462419417782245

Epoch: 6| Step: 1
Training loss: 2.132440667349989
Validation loss: 2.5539839875582246

Epoch: 6| Step: 2
Training loss: 2.861968318419973
Validation loss: 2.5315171899205358

Epoch: 6| Step: 3
Training loss: 3.288969568674881
Validation loss: 2.514119871910942

Epoch: 6| Step: 4
Training loss: 2.7884348101561782
Validation loss: 2.512782461873363

Epoch: 6| Step: 5
Training loss: 2.9170412277221858
Validation loss: 2.494320262663207

Epoch: 6| Step: 6
Training loss: 2.791633425462488
Validation loss: 2.4523478553863396

Epoch: 6| Step: 7
Training loss: 2.7871574499291927
Validation loss: 2.4395093342649066

Epoch: 6| Step: 8
Training loss: 2.166145506560171
Validation loss: 2.448879107376085

Epoch: 6| Step: 9
Training loss: 3.1250268553533562
Validation loss: 2.441671221130126

Epoch: 6| Step: 10
Training loss: 2.442211976419851
Validation loss: 2.441486436015167

Epoch: 6| Step: 11
Training loss: 2.4744623467198834
Validation loss: 2.4484711904993204

Epoch: 6| Step: 12
Training loss: 2.9756516392073653
Validation loss: 2.429374226988528

Epoch: 6| Step: 13
Training loss: 1.9192076991414575
Validation loss: 2.4221972581576026

Epoch: 174| Step: 0
Training loss: 3.1245525802751817
Validation loss: 2.434863934525388

Epoch: 6| Step: 1
Training loss: 3.268181926897553
Validation loss: 2.4744440325825607

Epoch: 6| Step: 2
Training loss: 2.3328324416088178
Validation loss: 2.501978308862078

Epoch: 6| Step: 3
Training loss: 1.9228917355503792
Validation loss: 2.585960194517523

Epoch: 6| Step: 4
Training loss: 2.553122878336404
Validation loss: 2.6684099368094287

Epoch: 6| Step: 5
Training loss: 2.734251531810668
Validation loss: 2.5998394614841986

Epoch: 6| Step: 6
Training loss: 3.045691157482981
Validation loss: 2.505200680220099

Epoch: 6| Step: 7
Training loss: 2.6063248401755046
Validation loss: 2.4298821249890583

Epoch: 6| Step: 8
Training loss: 2.9662802612458647
Validation loss: 2.4027264476709256

Epoch: 6| Step: 9
Training loss: 2.7005113965086944
Validation loss: 2.4220574057882414

Epoch: 6| Step: 10
Training loss: 2.90554423632908
Validation loss: 2.4282508181796354

Epoch: 6| Step: 11
Training loss: 2.6763432490331853
Validation loss: 2.417642892316621

Epoch: 6| Step: 12
Training loss: 2.6457500494717534
Validation loss: 2.4095426111900062

Epoch: 6| Step: 13
Training loss: 3.0105868140759355
Validation loss: 2.4042221695761894

Epoch: 175| Step: 0
Training loss: 3.238411416450551
Validation loss: 2.408707589853523

Epoch: 6| Step: 1
Training loss: 2.817827731063104
Validation loss: 2.4076951056638225

Epoch: 6| Step: 2
Training loss: 2.244094728642944
Validation loss: 2.4329872174144924

Epoch: 6| Step: 3
Training loss: 2.8660720193656037
Validation loss: 2.4374096046179603

Epoch: 6| Step: 4
Training loss: 2.486524503733276
Validation loss: 2.449921386174062

Epoch: 6| Step: 5
Training loss: 2.690853510600128
Validation loss: 2.460479162362545

Epoch: 6| Step: 6
Training loss: 2.3470122966403593
Validation loss: 2.5007327656866414

Epoch: 6| Step: 7
Training loss: 1.7691612277828543
Validation loss: 2.5069253664920645

Epoch: 6| Step: 8
Training loss: 2.8500338702949852
Validation loss: 2.487838496836041

Epoch: 6| Step: 9
Training loss: 2.6953289529049465
Validation loss: 2.471520408518708

Epoch: 6| Step: 10
Training loss: 2.8664109012444374
Validation loss: 2.4601140387035976

Epoch: 6| Step: 11
Training loss: 2.8058440392696595
Validation loss: 2.438386521885307

Epoch: 6| Step: 12
Training loss: 2.7005348806037337
Validation loss: 2.427825580451483

Epoch: 6| Step: 13
Training loss: 3.003702104673192
Validation loss: 2.4323455564967142

Epoch: 176| Step: 0
Training loss: 2.7327297819780525
Validation loss: 2.422828389276718

Epoch: 6| Step: 1
Training loss: 2.5631804144412267
Validation loss: 2.4143242592368472

Epoch: 6| Step: 2
Training loss: 3.0627774482700887
Validation loss: 2.4172153217845174

Epoch: 6| Step: 3
Training loss: 2.933378696813362
Validation loss: 2.42228658501951

Epoch: 6| Step: 4
Training loss: 2.721103219807937
Validation loss: 2.43012271662054

Epoch: 6| Step: 5
Training loss: 2.597601914375335
Validation loss: 2.4321065761447906

Epoch: 6| Step: 6
Training loss: 2.1028201512857834
Validation loss: 2.460750914318938

Epoch: 6| Step: 7
Training loss: 2.5221555305641292
Validation loss: 2.471645625425125

Epoch: 6| Step: 8
Training loss: 2.8953128227978944
Validation loss: 2.518059597704409

Epoch: 6| Step: 9
Training loss: 2.5923147251945413
Validation loss: 2.535164598748617

Epoch: 6| Step: 10
Training loss: 2.5481419132841867
Validation loss: 2.5456614977608414

Epoch: 6| Step: 11
Training loss: 2.7686657757144153
Validation loss: 2.482227058615186

Epoch: 6| Step: 12
Training loss: 2.473086254943335
Validation loss: 2.445281970699011

Epoch: 6| Step: 13
Training loss: 3.2120801836886503
Validation loss: 2.4219813212048074

Epoch: 177| Step: 0
Training loss: 2.7149356085516176
Validation loss: 2.418737512570946

Epoch: 6| Step: 1
Training loss: 2.734381626666077
Validation loss: 2.4225200110393925

Epoch: 6| Step: 2
Training loss: 3.242059985491312
Validation loss: 2.4098734300556077

Epoch: 6| Step: 3
Training loss: 2.526554414810521
Validation loss: 2.4152791563082316

Epoch: 6| Step: 4
Training loss: 1.918951648963775
Validation loss: 2.4134143660574656

Epoch: 6| Step: 5
Training loss: 3.0144284102872754
Validation loss: 2.422013636659007

Epoch: 6| Step: 6
Training loss: 2.760798666571641
Validation loss: 2.4213466717693395

Epoch: 6| Step: 7
Training loss: 2.7259712343272513
Validation loss: 2.432243519723456

Epoch: 6| Step: 8
Training loss: 2.5374023644215686
Validation loss: 2.449179600351404

Epoch: 6| Step: 9
Training loss: 2.7990385243993656
Validation loss: 2.4691474172027683

Epoch: 6| Step: 10
Training loss: 3.1297680909649928
Validation loss: 2.501136259051429

Epoch: 6| Step: 11
Training loss: 2.3219337835867173
Validation loss: 2.466629376111548

Epoch: 6| Step: 12
Training loss: 2.517725949797251
Validation loss: 2.4396135933631675

Epoch: 6| Step: 13
Training loss: 1.8517111545555358
Validation loss: 2.416481906509915

Epoch: 178| Step: 0
Training loss: 3.004035460789805
Validation loss: 2.4185962215709305

Epoch: 6| Step: 1
Training loss: 2.2245218127453006
Validation loss: 2.408814923278015

Epoch: 6| Step: 2
Training loss: 2.594785736293644
Validation loss: 2.4151272455168704

Epoch: 6| Step: 3
Training loss: 2.9976533612875382
Validation loss: 2.4129700926737043

Epoch: 6| Step: 4
Training loss: 2.427693913706475
Validation loss: 2.4144282096018967

Epoch: 6| Step: 5
Training loss: 3.1465465082513666
Validation loss: 2.4132854229002336

Epoch: 6| Step: 6
Training loss: 2.461641047591277
Validation loss: 2.4105176919396016

Epoch: 6| Step: 7
Training loss: 2.7229720032450837
Validation loss: 2.4121769630953778

Epoch: 6| Step: 8
Training loss: 1.863819228587313
Validation loss: 2.4183713267146225

Epoch: 6| Step: 9
Training loss: 2.5953467176778013
Validation loss: 2.4197334573014504

Epoch: 6| Step: 10
Training loss: 2.5628313920267014
Validation loss: 2.4255885820715473

Epoch: 6| Step: 11
Training loss: 2.871584480542762
Validation loss: 2.4203133620345194

Epoch: 6| Step: 12
Training loss: 2.467211666556555
Validation loss: 2.4305225925192895

Epoch: 6| Step: 13
Training loss: 3.0624749318867996
Validation loss: 2.438007724660993

Epoch: 179| Step: 0
Training loss: 2.646414104809703
Validation loss: 2.4410178706539707

Epoch: 6| Step: 1
Training loss: 2.2538402422093595
Validation loss: 2.4525311395683334

Epoch: 6| Step: 2
Training loss: 2.5044278034596443
Validation loss: 2.4565447809553547

Epoch: 6| Step: 3
Training loss: 2.364546104731855
Validation loss: 2.4674018729373945

Epoch: 6| Step: 4
Training loss: 3.25084675248685
Validation loss: 2.4793945249840905

Epoch: 6| Step: 5
Training loss: 2.3206572099993616
Validation loss: 2.5065113717844305

Epoch: 6| Step: 6
Training loss: 2.7520220864984344
Validation loss: 2.5333843684547435

Epoch: 6| Step: 7
Training loss: 2.9940049351592277
Validation loss: 2.47648537517233

Epoch: 6| Step: 8
Training loss: 3.103315112848876
Validation loss: 2.440596808020095

Epoch: 6| Step: 9
Training loss: 2.8102979728758477
Validation loss: 2.4125635160730337

Epoch: 6| Step: 10
Training loss: 2.6655600357636393
Validation loss: 2.408235540177594

Epoch: 6| Step: 11
Training loss: 2.0366918587674427
Validation loss: 2.4224383262380145

Epoch: 6| Step: 12
Training loss: 2.447506928477938
Validation loss: 2.4173492921575366

Epoch: 6| Step: 13
Training loss: 2.978162600749238
Validation loss: 2.420348379544081

Epoch: 180| Step: 0
Training loss: 2.9615761261944824
Validation loss: 2.429236313278032

Epoch: 6| Step: 1
Training loss: 2.8877370893896352
Validation loss: 2.421698426668183

Epoch: 6| Step: 2
Training loss: 3.2265654556962855
Validation loss: 2.4273590641781

Epoch: 6| Step: 3
Training loss: 2.134977813533955
Validation loss: 2.436407521211982

Epoch: 6| Step: 4
Training loss: 2.783918236666372
Validation loss: 2.465811814218694

Epoch: 6| Step: 5
Training loss: 2.67120950899331
Validation loss: 2.4925228087103593

Epoch: 6| Step: 6
Training loss: 3.015691094341272
Validation loss: 2.5413314750282043

Epoch: 6| Step: 7
Training loss: 2.5753947279515703
Validation loss: 2.564633368539526

Epoch: 6| Step: 8
Training loss: 2.899492179869269
Validation loss: 2.5426580861424752

Epoch: 6| Step: 9
Training loss: 1.8524023798911422
Validation loss: 2.484360844277764

Epoch: 6| Step: 10
Training loss: 2.7772061384959277
Validation loss: 2.4571811241587413

Epoch: 6| Step: 11
Training loss: 2.714170611242704
Validation loss: 2.434622136113549

Epoch: 6| Step: 12
Training loss: 1.9350171331391337
Validation loss: 2.4120858280845505

Epoch: 6| Step: 13
Training loss: 2.4608209491559787
Validation loss: 2.419171600512538

Epoch: 181| Step: 0
Training loss: 3.002741355882919
Validation loss: 2.4237655865989405

Epoch: 6| Step: 1
Training loss: 2.44185015495633
Validation loss: 2.4383677086405284

Epoch: 6| Step: 2
Training loss: 3.064128831829183
Validation loss: 2.4431948736229137

Epoch: 6| Step: 3
Training loss: 2.8436985220808593
Validation loss: 2.4361171423033627

Epoch: 6| Step: 4
Training loss: 2.608180520778285
Validation loss: 2.4270087360098924

Epoch: 6| Step: 5
Training loss: 2.7032940762072624
Validation loss: 2.420763988947922

Epoch: 6| Step: 6
Training loss: 2.5565481147319433
Validation loss: 2.402394123884851

Epoch: 6| Step: 7
Training loss: 2.517514295338536
Validation loss: 2.401621793948131

Epoch: 6| Step: 8
Training loss: 2.1145067874477483
Validation loss: 2.4155925332159645

Epoch: 6| Step: 9
Training loss: 3.0540552289824108
Validation loss: 2.4352765329519044

Epoch: 6| Step: 10
Training loss: 2.6043150490767073
Validation loss: 2.459586230059772

Epoch: 6| Step: 11
Training loss: 2.895352842870243
Validation loss: 2.4570913954522386

Epoch: 6| Step: 12
Training loss: 2.554822445726319
Validation loss: 2.474247441046663

Epoch: 6| Step: 13
Training loss: 1.9102559755968482
Validation loss: 2.5040946775518096

Epoch: 182| Step: 0
Training loss: 2.616301338140461
Validation loss: 2.5413291548365207

Epoch: 6| Step: 1
Training loss: 3.0050916379136097
Validation loss: 2.603043099142293

Epoch: 6| Step: 2
Training loss: 2.4788644002657314
Validation loss: 2.628340685847253

Epoch: 6| Step: 3
Training loss: 2.774001115294042
Validation loss: 2.6728712823594076

Epoch: 6| Step: 4
Training loss: 2.6019457285658083
Validation loss: 2.592041989214253

Epoch: 6| Step: 5
Training loss: 2.282766386867951
Validation loss: 2.5055405768660615

Epoch: 6| Step: 6
Training loss: 2.6366267887609105
Validation loss: 2.430937220721119

Epoch: 6| Step: 7
Training loss: 2.2337972254102403
Validation loss: 2.4226610150011774

Epoch: 6| Step: 8
Training loss: 3.1484056949192243
Validation loss: 2.411564762269874

Epoch: 6| Step: 9
Training loss: 3.198239652909301
Validation loss: 2.4278181782936032

Epoch: 6| Step: 10
Training loss: 3.2301076851010144
Validation loss: 2.4549310443556367

Epoch: 6| Step: 11
Training loss: 2.9727829694368917
Validation loss: 2.4744959245309874

Epoch: 6| Step: 12
Training loss: 2.5767919619825994
Validation loss: 2.4850185327257064

Epoch: 6| Step: 13
Training loss: 2.126639799329
Validation loss: 2.4856845765334015

Epoch: 183| Step: 0
Training loss: 3.115813829827378
Validation loss: 2.4846657203472144

Epoch: 6| Step: 1
Training loss: 2.066357675136485
Validation loss: 2.465431760140294

Epoch: 6| Step: 2
Training loss: 2.960454332692371
Validation loss: 2.4675447204356056

Epoch: 6| Step: 3
Training loss: 3.001624303416786
Validation loss: 2.4659418345108635

Epoch: 6| Step: 4
Training loss: 2.335007294147216
Validation loss: 2.445653958727424

Epoch: 6| Step: 5
Training loss: 2.8409455272765505
Validation loss: 2.4562621285969555

Epoch: 6| Step: 6
Training loss: 2.777951545578378
Validation loss: 2.464412167461601

Epoch: 6| Step: 7
Training loss: 2.4416915848885035
Validation loss: 2.5113568232837844

Epoch: 6| Step: 8
Training loss: 2.4612409132154744
Validation loss: 2.5060660007598887

Epoch: 6| Step: 9
Training loss: 3.1280952383601535
Validation loss: 2.5477209266049607

Epoch: 6| Step: 10
Training loss: 1.8367457132700935
Validation loss: 2.554391751081452

Epoch: 6| Step: 11
Training loss: 3.189152906109226
Validation loss: 2.5767119690934384

Epoch: 6| Step: 12
Training loss: 2.6958067509924164
Validation loss: 2.5298933745991525

Epoch: 6| Step: 13
Training loss: 2.4080284779280943
Validation loss: 2.5109083139900195

Epoch: 184| Step: 0
Training loss: 2.5377402281149792
Validation loss: 2.467603184235381

Epoch: 6| Step: 1
Training loss: 2.4755364347244897
Validation loss: 2.4170886941741134

Epoch: 6| Step: 2
Training loss: 3.2975366299136932
Validation loss: 2.420633915397797

Epoch: 6| Step: 3
Training loss: 2.672548265012402
Validation loss: 2.426309729429532

Epoch: 6| Step: 4
Training loss: 2.5348857623662395
Validation loss: 2.402989143032463

Epoch: 6| Step: 5
Training loss: 2.2873007598991766
Validation loss: 2.4091187087681347

Epoch: 6| Step: 6
Training loss: 2.6475274877228925
Validation loss: 2.412962933929268

Epoch: 6| Step: 7
Training loss: 2.5309446174172017
Validation loss: 2.4077503963865037

Epoch: 6| Step: 8
Training loss: 1.733116242984696
Validation loss: 2.413587527247636

Epoch: 6| Step: 9
Training loss: 2.5588663902329807
Validation loss: 2.415792531657379

Epoch: 6| Step: 10
Training loss: 3.251451608287467
Validation loss: 2.4185632923033493

Epoch: 6| Step: 11
Training loss: 2.8509492397599767
Validation loss: 2.420653688307231

Epoch: 6| Step: 12
Training loss: 2.8380890558315057
Validation loss: 2.437413479405594

Epoch: 6| Step: 13
Training loss: 2.672232353004432
Validation loss: 2.4529252324652315

Epoch: 185| Step: 0
Training loss: 2.773559739548657
Validation loss: 2.460558614294911

Epoch: 6| Step: 1
Training loss: 2.497531625969386
Validation loss: 2.463247315993646

Epoch: 6| Step: 2
Training loss: 2.8392877467337545
Validation loss: 2.454728332469421

Epoch: 6| Step: 3
Training loss: 2.2344697518698893
Validation loss: 2.437444512193454

Epoch: 6| Step: 4
Training loss: 2.830574787121563
Validation loss: 2.4422890383549

Epoch: 6| Step: 5
Training loss: 3.4476141820952044
Validation loss: 2.4314853598051407

Epoch: 6| Step: 6
Training loss: 2.185455456714616
Validation loss: 2.4425350150198373

Epoch: 6| Step: 7
Training loss: 2.5535496035318666
Validation loss: 2.435013622264277

Epoch: 6| Step: 8
Training loss: 2.532956901825198
Validation loss: 2.442806044022607

Epoch: 6| Step: 9
Training loss: 2.1444640991592765
Validation loss: 2.423665235361105

Epoch: 6| Step: 10
Training loss: 2.3771642561390838
Validation loss: 2.4231287605756493

Epoch: 6| Step: 11
Training loss: 2.9579665444669985
Validation loss: 2.417369382512929

Epoch: 6| Step: 12
Training loss: 2.786760935291639
Validation loss: 2.4100882978232616

Epoch: 6| Step: 13
Training loss: 2.2005510377033644
Validation loss: 2.4244538432501925

Epoch: 186| Step: 0
Training loss: 2.7626706307995215
Validation loss: 2.4250363023174284

Epoch: 6| Step: 1
Training loss: 2.5359333181669927
Validation loss: 2.4216304606638466

Epoch: 6| Step: 2
Training loss: 2.469054191294379
Validation loss: 2.4270404669468775

Epoch: 6| Step: 3
Training loss: 3.0009131631258628
Validation loss: 2.448656354659865

Epoch: 6| Step: 4
Training loss: 2.730263196114278
Validation loss: 2.4726705670774534

Epoch: 6| Step: 5
Training loss: 2.579566876036428
Validation loss: 2.481888059604655

Epoch: 6| Step: 6
Training loss: 3.264000301398469
Validation loss: 2.503389213599421

Epoch: 6| Step: 7
Training loss: 2.210263638198348
Validation loss: 2.514195512920476

Epoch: 6| Step: 8
Training loss: 2.854904265126435
Validation loss: 2.494100147335495

Epoch: 6| Step: 9
Training loss: 2.5112614667753133
Validation loss: 2.4864473950908996

Epoch: 6| Step: 10
Training loss: 2.577089783874514
Validation loss: 2.4656886565496325

Epoch: 6| Step: 11
Training loss: 1.7952583670028732
Validation loss: 2.4727914445302095

Epoch: 6| Step: 12
Training loss: 2.726069102418291
Validation loss: 2.453253035257277

Epoch: 6| Step: 13
Training loss: 2.3112202789227725
Validation loss: 2.4373994727133668

Epoch: 187| Step: 0
Training loss: 2.3795955767945824
Validation loss: 2.421550410097152

Epoch: 6| Step: 1
Training loss: 2.5801307043338975
Validation loss: 2.4041720174025856

Epoch: 6| Step: 2
Training loss: 2.396787790554612
Validation loss: 2.4104667295131623

Epoch: 6| Step: 3
Training loss: 2.543207441574782
Validation loss: 2.408907173901626

Epoch: 6| Step: 4
Training loss: 2.513925487703852
Validation loss: 2.4243797409716406

Epoch: 6| Step: 5
Training loss: 2.740035122555796
Validation loss: 2.412982848317966

Epoch: 6| Step: 6
Training loss: 2.5867109265752086
Validation loss: 2.4125385698536634

Epoch: 6| Step: 7
Training loss: 2.4487450246482885
Validation loss: 2.4107275482996147

Epoch: 6| Step: 8
Training loss: 2.3141106847141946
Validation loss: 2.4312521175952404

Epoch: 6| Step: 9
Training loss: 3.137999694668601
Validation loss: 2.429666447918383

Epoch: 6| Step: 10
Training loss: 3.1200138749523245
Validation loss: 2.475807575639632

Epoch: 6| Step: 11
Training loss: 2.525518073386422
Validation loss: 2.477878631666988

Epoch: 6| Step: 12
Training loss: 2.4845168355124554
Validation loss: 2.54798802431567

Epoch: 6| Step: 13
Training loss: 2.9212456499686805
Validation loss: 2.559105266961886

Epoch: 188| Step: 0
Training loss: 2.4640535517731466
Validation loss: 2.5784224422201274

Epoch: 6| Step: 1
Training loss: 2.6365435054610735
Validation loss: 2.5955808276103953

Epoch: 6| Step: 2
Training loss: 2.277079702678647
Validation loss: 2.567244441747215

Epoch: 6| Step: 3
Training loss: 2.7812884038781154
Validation loss: 2.5128958620272104

Epoch: 6| Step: 4
Training loss: 2.159302361642612
Validation loss: 2.441439246038787

Epoch: 6| Step: 5
Training loss: 2.0589373480966953
Validation loss: 2.408345627166996

Epoch: 6| Step: 6
Training loss: 2.3828199042533527
Validation loss: 2.400266403705602

Epoch: 6| Step: 7
Training loss: 3.119192296163277
Validation loss: 2.4014321496545104

Epoch: 6| Step: 8
Training loss: 3.1712666947673798
Validation loss: 2.42085774228846

Epoch: 6| Step: 9
Training loss: 2.7231714535634604
Validation loss: 2.4145901064243476

Epoch: 6| Step: 10
Training loss: 2.432064549518055
Validation loss: 2.408696212755943

Epoch: 6| Step: 11
Training loss: 3.3696949555297664
Validation loss: 2.4095091868675715

Epoch: 6| Step: 12
Training loss: 2.778230463864627
Validation loss: 2.40402414594676

Epoch: 6| Step: 13
Training loss: 2.695828861034365
Validation loss: 2.4258153938531404

Epoch: 189| Step: 0
Training loss: 3.1219418630227165
Validation loss: 2.442293200362877

Epoch: 6| Step: 1
Training loss: 2.748381745432743
Validation loss: 2.46993901654446

Epoch: 6| Step: 2
Training loss: 2.550676095381102
Validation loss: 2.4996176581113327

Epoch: 6| Step: 3
Training loss: 2.1419512128002256
Validation loss: 2.5326175578213523

Epoch: 6| Step: 4
Training loss: 2.56390937566465
Validation loss: 2.5342745195406646

Epoch: 6| Step: 5
Training loss: 2.5473564956571737
Validation loss: 2.565739909240198

Epoch: 6| Step: 6
Training loss: 2.647487954030356
Validation loss: 2.5743037603202654

Epoch: 6| Step: 7
Training loss: 2.355253548225376
Validation loss: 2.5445777985907476

Epoch: 6| Step: 8
Training loss: 2.3768066762352147
Validation loss: 2.5455164947354016

Epoch: 6| Step: 9
Training loss: 1.7161575880405435
Validation loss: 2.512037916265436

Epoch: 6| Step: 10
Training loss: 2.8550068159406177
Validation loss: 2.489907623093326

Epoch: 6| Step: 11
Training loss: 3.1612201498303403
Validation loss: 2.460998501064744

Epoch: 6| Step: 12
Training loss: 3.283072120099765
Validation loss: 2.409036721737218

Epoch: 6| Step: 13
Training loss: 2.002430869062894
Validation loss: 2.4043041427165384

Epoch: 190| Step: 0
Training loss: 2.731023336472149
Validation loss: 2.3938881843115403

Epoch: 6| Step: 1
Training loss: 2.6565881850433857
Validation loss: 2.4016505816316402

Epoch: 6| Step: 2
Training loss: 2.042059205395339
Validation loss: 2.4238314630437294

Epoch: 6| Step: 3
Training loss: 2.4832064201473534
Validation loss: 2.4270184792684995

Epoch: 6| Step: 4
Training loss: 2.9695179799221716
Validation loss: 2.424783774875284

Epoch: 6| Step: 5
Training loss: 2.5363702673901503
Validation loss: 2.4148071162286846

Epoch: 6| Step: 6
Training loss: 3.128366869132088
Validation loss: 2.402767722041819

Epoch: 6| Step: 7
Training loss: 2.7477449361042807
Validation loss: 2.4222762935475384

Epoch: 6| Step: 8
Training loss: 2.098402860104193
Validation loss: 2.4366067701658474

Epoch: 6| Step: 9
Training loss: 2.756634944408824
Validation loss: 2.4714551989918285

Epoch: 6| Step: 10
Training loss: 2.653103928768744
Validation loss: 2.497746437344864

Epoch: 6| Step: 11
Training loss: 2.093044332895931
Validation loss: 2.5317227382837233

Epoch: 6| Step: 12
Training loss: 3.0652563964239388
Validation loss: 2.5334877393613957

Epoch: 6| Step: 13
Training loss: 2.926900366950785
Validation loss: 2.5316706867015033

Epoch: 191| Step: 0
Training loss: 2.6841476290845963
Validation loss: 2.529389817416453

Epoch: 6| Step: 1
Training loss: 2.179208791798517
Validation loss: 2.516350627935092

Epoch: 6| Step: 2
Training loss: 3.224981405515072
Validation loss: 2.4812076464457884

Epoch: 6| Step: 3
Training loss: 2.5510794916512087
Validation loss: 2.4715178117051515

Epoch: 6| Step: 4
Training loss: 2.3054448322023697
Validation loss: 2.4830786346944955

Epoch: 6| Step: 5
Training loss: 2.4581888016277844
Validation loss: 2.461409013134012

Epoch: 6| Step: 6
Training loss: 2.6048928329184657
Validation loss: 2.4593353989216578

Epoch: 6| Step: 7
Training loss: 2.44908236621248
Validation loss: 2.440068409697225

Epoch: 6| Step: 8
Training loss: 2.3023211211097925
Validation loss: 2.430824055371045

Epoch: 6| Step: 9
Training loss: 2.9320148633239294
Validation loss: 2.438330415006731

Epoch: 6| Step: 10
Training loss: 2.200485379687737
Validation loss: 2.446496526861225

Epoch: 6| Step: 11
Training loss: 2.726159183436033
Validation loss: 2.4384006700983307

Epoch: 6| Step: 12
Training loss: 2.709542126984342
Validation loss: 2.4431803093167814

Epoch: 6| Step: 13
Training loss: 3.0132845161782273
Validation loss: 2.436846796759356

Epoch: 192| Step: 0
Training loss: 2.4654675644965343
Validation loss: 2.4115228539119196

Epoch: 6| Step: 1
Training loss: 2.574783564239807
Validation loss: 2.405033620763465

Epoch: 6| Step: 2
Training loss: 2.2346318237384866
Validation loss: 2.405088409863544

Epoch: 6| Step: 3
Training loss: 2.674916906046644
Validation loss: 2.4281323805709376

Epoch: 6| Step: 4
Training loss: 2.01820716763884
Validation loss: 2.4214163460698654

Epoch: 6| Step: 5
Training loss: 2.558186971928265
Validation loss: 2.4296564198378197

Epoch: 6| Step: 6
Training loss: 3.0901354086628743
Validation loss: 2.419900922297138

Epoch: 6| Step: 7
Training loss: 3.0931975516849874
Validation loss: 2.4315005708890203

Epoch: 6| Step: 8
Training loss: 3.237541086532695
Validation loss: 2.4431460807569785

Epoch: 6| Step: 9
Training loss: 2.3425573747869444
Validation loss: 2.4450947093405415

Epoch: 6| Step: 10
Training loss: 2.2379013724459376
Validation loss: 2.444270594799917

Epoch: 6| Step: 11
Training loss: 2.593999184278185
Validation loss: 2.448642546813866

Epoch: 6| Step: 12
Training loss: 2.160099077071724
Validation loss: 2.457307810910036

Epoch: 6| Step: 13
Training loss: 2.8087014720138597
Validation loss: 2.4586255859412605

Epoch: 193| Step: 0
Training loss: 2.109523626672154
Validation loss: 2.448189152667794

Epoch: 6| Step: 1
Training loss: 2.6762247650795508
Validation loss: 2.442516311398085

Epoch: 6| Step: 2
Training loss: 2.5196372312981388
Validation loss: 2.4337290561624148

Epoch: 6| Step: 3
Training loss: 2.4718386487060227
Validation loss: 2.431897517330026

Epoch: 6| Step: 4
Training loss: 1.8916495833556797
Validation loss: 2.4269405331607348

Epoch: 6| Step: 5
Training loss: 2.3531462446776086
Validation loss: 2.430410972158418

Epoch: 6| Step: 6
Training loss: 3.209086606329569
Validation loss: 2.430804567682727

Epoch: 6| Step: 7
Training loss: 2.4416781098636857
Validation loss: 2.43788334535323

Epoch: 6| Step: 8
Training loss: 2.6906409428176223
Validation loss: 2.447299314075072

Epoch: 6| Step: 9
Training loss: 2.8140430879744116
Validation loss: 2.456848659441535

Epoch: 6| Step: 10
Training loss: 2.6670427851869154
Validation loss: 2.4896227134596542

Epoch: 6| Step: 11
Training loss: 2.7818064615158
Validation loss: 2.4932719419235703

Epoch: 6| Step: 12
Training loss: 2.8514646748524086
Validation loss: 2.4893549083515905

Epoch: 6| Step: 13
Training loss: 2.3302819417878724
Validation loss: 2.485687215787378

Epoch: 194| Step: 0
Training loss: 2.334792146600714
Validation loss: 2.467698846072597

Epoch: 6| Step: 1
Training loss: 1.9644626983573155
Validation loss: 2.4898779463881726

Epoch: 6| Step: 2
Training loss: 2.0544322040184735
Validation loss: 2.4825289489771953

Epoch: 6| Step: 3
Training loss: 2.991732649930008
Validation loss: 2.442010864733656

Epoch: 6| Step: 4
Training loss: 2.829163587191165
Validation loss: 2.4226944134285717

Epoch: 6| Step: 5
Training loss: 2.401400348299404
Validation loss: 2.41913871934685

Epoch: 6| Step: 6
Training loss: 2.8473010685452573
Validation loss: 2.4149433937717495

Epoch: 6| Step: 7
Training loss: 2.8866034498920543
Validation loss: 2.411884996661925

Epoch: 6| Step: 8
Training loss: 2.9036515627862944
Validation loss: 2.4066740508561777

Epoch: 6| Step: 9
Training loss: 2.860008294687047
Validation loss: 2.4140843561238885

Epoch: 6| Step: 10
Training loss: 2.2727097857409415
Validation loss: 2.413543648599721

Epoch: 6| Step: 11
Training loss: 3.072302564046052
Validation loss: 2.399311534517048

Epoch: 6| Step: 12
Training loss: 2.4262782277308172
Validation loss: 2.4222106203532863

Epoch: 6| Step: 13
Training loss: 1.7706989536535014
Validation loss: 2.4227729432092096

Epoch: 195| Step: 0
Training loss: 1.7809223743766311
Validation loss: 2.4403182177363023

Epoch: 6| Step: 1
Training loss: 2.593200809292812
Validation loss: 2.4474351697827417

Epoch: 6| Step: 2
Training loss: 2.141562040967125
Validation loss: 2.446898408097126

Epoch: 6| Step: 3
Training loss: 2.500712674603064
Validation loss: 2.460536795901211

Epoch: 6| Step: 4
Training loss: 2.9510566693988474
Validation loss: 2.4915834118366464

Epoch: 6| Step: 5
Training loss: 2.764422138941169
Validation loss: 2.4957495560613823

Epoch: 6| Step: 6
Training loss: 2.259355591918825
Validation loss: 2.4902367541217156

Epoch: 6| Step: 7
Training loss: 2.92005137280775
Validation loss: 2.474945721735976

Epoch: 6| Step: 8
Training loss: 3.0068440252915747
Validation loss: 2.4546212792437014

Epoch: 6| Step: 9
Training loss: 2.2221901242269237
Validation loss: 2.437729517856355

Epoch: 6| Step: 10
Training loss: 2.7142863847258463
Validation loss: 2.4361402727812367

Epoch: 6| Step: 11
Training loss: 2.633364656318409
Validation loss: 2.4284926334104617

Epoch: 6| Step: 12
Training loss: 2.900359552390374
Validation loss: 2.435649875404575

Epoch: 6| Step: 13
Training loss: 2.5364598477233082
Validation loss: 2.441614626944083

Epoch: 196| Step: 0
Training loss: 3.3539602243775257
Validation loss: 2.446871412644935

Epoch: 6| Step: 1
Training loss: 2.947997147143367
Validation loss: 2.446835124529685

Epoch: 6| Step: 2
Training loss: 2.264175056308127
Validation loss: 2.4485274544956237

Epoch: 6| Step: 3
Training loss: 2.648507716505589
Validation loss: 2.4624291913212994

Epoch: 6| Step: 4
Training loss: 2.0042511343917693
Validation loss: 2.4707846097014485

Epoch: 6| Step: 5
Training loss: 1.9070937993825985
Validation loss: 2.4731205770589777

Epoch: 6| Step: 6
Training loss: 3.166467275532631
Validation loss: 2.4675964094331606

Epoch: 6| Step: 7
Training loss: 2.76996379966355
Validation loss: 2.4552419925638405

Epoch: 6| Step: 8
Training loss: 2.453693882771264
Validation loss: 2.4432711427901386

Epoch: 6| Step: 9
Training loss: 2.532758663483106
Validation loss: 2.4410771892655903

Epoch: 6| Step: 10
Training loss: 1.939933171940113
Validation loss: 2.4346130677189333

Epoch: 6| Step: 11
Training loss: 2.1033649868807576
Validation loss: 2.411200339721891

Epoch: 6| Step: 12
Training loss: 2.620506982745639
Validation loss: 2.4181037981878073

Epoch: 6| Step: 13
Training loss: 2.754185872051859
Validation loss: 2.4301571803048123

Epoch: 197| Step: 0
Training loss: 2.667488468220318
Validation loss: 2.4252824611844113

Epoch: 6| Step: 1
Training loss: 2.2060190225785714
Validation loss: 2.4420333378533936

Epoch: 6| Step: 2
Training loss: 1.765147051642474
Validation loss: 2.451724258971871

Epoch: 6| Step: 3
Training loss: 2.9769538361824206
Validation loss: 2.4455500598752717

Epoch: 6| Step: 4
Training loss: 2.7645396888658875
Validation loss: 2.4413763292017325

Epoch: 6| Step: 5
Training loss: 1.8597029709272617
Validation loss: 2.462299816389428

Epoch: 6| Step: 6
Training loss: 2.907761867600976
Validation loss: 2.447195541648098

Epoch: 6| Step: 7
Training loss: 2.5335113408474967
Validation loss: 2.4614611194760028

Epoch: 6| Step: 8
Training loss: 2.524207408127471
Validation loss: 2.475042974571905

Epoch: 6| Step: 9
Training loss: 2.417355461178537
Validation loss: 2.481302938766783

Epoch: 6| Step: 10
Training loss: 2.9565801843368926
Validation loss: 2.4961040924832165

Epoch: 6| Step: 11
Training loss: 2.465359834788876
Validation loss: 2.5094179163079193

Epoch: 6| Step: 12
Training loss: 2.688854674532336
Validation loss: 2.4882453762229697

Epoch: 6| Step: 13
Training loss: 2.580493186121243
Validation loss: 2.4563337797144307

Epoch: 198| Step: 0
Training loss: 2.8026746577370663
Validation loss: 2.420135792371927

Epoch: 6| Step: 1
Training loss: 2.3784941017153125
Validation loss: 2.4211195938321497

Epoch: 6| Step: 2
Training loss: 2.141463734948735
Validation loss: 2.4217057776634014

Epoch: 6| Step: 3
Training loss: 2.856681013245614
Validation loss: 2.413677975714505

Epoch: 6| Step: 4
Training loss: 2.7315329468423144
Validation loss: 2.4014415782072374

Epoch: 6| Step: 5
Training loss: 2.6593130066366473
Validation loss: 2.4200440322773957

Epoch: 6| Step: 6
Training loss: 1.8471178234048955
Validation loss: 2.4168163998574896

Epoch: 6| Step: 7
Training loss: 2.3388906330374977
Validation loss: 2.399860372207509

Epoch: 6| Step: 8
Training loss: 2.231460484425993
Validation loss: 2.4227235491117276

Epoch: 6| Step: 9
Training loss: 2.6570996888927345
Validation loss: 2.414262406975016

Epoch: 6| Step: 10
Training loss: 2.8006870993480493
Validation loss: 2.4397422746387605

Epoch: 6| Step: 11
Training loss: 2.69329882602807
Validation loss: 2.4554568384069864

Epoch: 6| Step: 12
Training loss: 2.232328745050012
Validation loss: 2.487847597922268

Epoch: 6| Step: 13
Training loss: 3.2805234558820464
Validation loss: 2.4836608423681636

Epoch: 199| Step: 0
Training loss: 3.1137498912099164
Validation loss: 2.5282897167878184

Epoch: 6| Step: 1
Training loss: 2.747257425639602
Validation loss: 2.5766026372167588

Epoch: 6| Step: 2
Training loss: 2.286484239528518
Validation loss: 2.585403556288421

Epoch: 6| Step: 3
Training loss: 2.793031064918908
Validation loss: 2.6006019694097873

Epoch: 6| Step: 4
Training loss: 2.8447066154788994
Validation loss: 2.5593496897213464

Epoch: 6| Step: 5
Training loss: 2.9875019727883947
Validation loss: 2.4969717563887737

Epoch: 6| Step: 6
Training loss: 2.529681249449408
Validation loss: 2.4799649042821175

Epoch: 6| Step: 7
Training loss: 2.3057734630308726
Validation loss: 2.453997235708763

Epoch: 6| Step: 8
Training loss: 2.0470179151189947
Validation loss: 2.4378289199836143

Epoch: 6| Step: 9
Training loss: 2.4392910759202078
Validation loss: 2.4255184293896384

Epoch: 6| Step: 10
Training loss: 2.7340302168230446
Validation loss: 2.403673010636816

Epoch: 6| Step: 11
Training loss: 2.4162995180126763
Validation loss: 2.409980174358253

Epoch: 6| Step: 12
Training loss: 1.9032765946669141
Validation loss: 2.404663277671107

Epoch: 6| Step: 13
Training loss: 2.4361227986620735
Validation loss: 2.4248214692751273

Epoch: 200| Step: 0
Training loss: 2.1368144849011346
Validation loss: 2.4416479377808047

Epoch: 6| Step: 1
Training loss: 2.2546744004554387
Validation loss: 2.4326805274162657

Epoch: 6| Step: 2
Training loss: 2.404560437231984
Validation loss: 2.466416563180057

Epoch: 6| Step: 3
Training loss: 2.3610136897115552
Validation loss: 2.510082433161004

Epoch: 6| Step: 4
Training loss: 2.269752478527502
Validation loss: 2.538481049580161

Epoch: 6| Step: 5
Training loss: 2.6587845322734216
Validation loss: 2.5269052135454984

Epoch: 6| Step: 6
Training loss: 2.469742394423356
Validation loss: 2.546025705122551

Epoch: 6| Step: 7
Training loss: 2.1671174998622544
Validation loss: 2.529145439829097

Epoch: 6| Step: 8
Training loss: 3.085381489170475
Validation loss: 2.5086364241098673

Epoch: 6| Step: 9
Training loss: 2.0221766958712957
Validation loss: 2.4852841943088486

Epoch: 6| Step: 10
Training loss: 2.7910766167780308
Validation loss: 2.458512293616242

Epoch: 6| Step: 11
Training loss: 2.740150847354898
Validation loss: 2.4289496619453588

Epoch: 6| Step: 12
Training loss: 2.8094745045523615
Validation loss: 2.422629812949345

Epoch: 6| Step: 13
Training loss: 3.0780016879249987
Validation loss: 2.4116598990444533

Epoch: 201| Step: 0
Training loss: 2.3421621411600433
Validation loss: 2.4031421134144475

Epoch: 6| Step: 1
Training loss: 2.92082252518581
Validation loss: 2.4030087229398602

Epoch: 6| Step: 2
Training loss: 2.6736262421503203
Validation loss: 2.3928005092553617

Epoch: 6| Step: 3
Training loss: 2.1118624114389255
Validation loss: 2.3969707605025405

Epoch: 6| Step: 4
Training loss: 2.798327191520102
Validation loss: 2.4218587387232384

Epoch: 6| Step: 5
Training loss: 2.745993730397579
Validation loss: 2.4147131789277325

Epoch: 6| Step: 6
Training loss: 2.7773774006839758
Validation loss: 2.43983221898741

Epoch: 6| Step: 7
Training loss: 2.357638092365483
Validation loss: 2.452029052700101

Epoch: 6| Step: 8
Training loss: 3.223077919856394
Validation loss: 2.4742651867720826

Epoch: 6| Step: 9
Training loss: 2.4459288189091706
Validation loss: 2.4790457488101962

Epoch: 6| Step: 10
Training loss: 2.0178943249620054
Validation loss: 2.492265811481474

Epoch: 6| Step: 11
Training loss: 2.492353666978274
Validation loss: 2.524423888327333

Epoch: 6| Step: 12
Training loss: 1.5131775276429313
Validation loss: 2.528706931961258

Epoch: 6| Step: 13
Training loss: 2.7313950349546836
Validation loss: 2.559393177140459

Epoch: 202| Step: 0
Training loss: 3.1156133439162605
Validation loss: 2.537689669827124

Epoch: 6| Step: 1
Training loss: 2.458791323742655
Validation loss: 2.505346296508207

Epoch: 6| Step: 2
Training loss: 2.244165485134822
Validation loss: 2.472634802740528

Epoch: 6| Step: 3
Training loss: 2.2826098216984025
Validation loss: 2.4565759122743565

Epoch: 6| Step: 4
Training loss: 2.3474216439167064
Validation loss: 2.462155004895182

Epoch: 6| Step: 5
Training loss: 2.1927632908642836
Validation loss: 2.44592493664883

Epoch: 6| Step: 6
Training loss: 2.140754305978543
Validation loss: 2.4571962168644332

Epoch: 6| Step: 7
Training loss: 2.9724035970264406
Validation loss: 2.457814940086614

Epoch: 6| Step: 8
Training loss: 2.806202598800146
Validation loss: 2.4603944407458056

Epoch: 6| Step: 9
Training loss: 2.6929751669173982
Validation loss: 2.468772191292822

Epoch: 6| Step: 10
Training loss: 2.256100120744152
Validation loss: 2.4875109726256777

Epoch: 6| Step: 11
Training loss: 3.0155494166572296
Validation loss: 2.487291964111938

Epoch: 6| Step: 12
Training loss: 2.056208638525995
Validation loss: 2.511908305086206

Epoch: 6| Step: 13
Training loss: 2.3191338316548222
Validation loss: 2.58803155504091

Epoch: 203| Step: 0
Training loss: 2.5947177414462406
Validation loss: 2.607358141630959

Epoch: 6| Step: 1
Training loss: 2.5444811470831
Validation loss: 2.6262035189195836

Epoch: 6| Step: 2
Training loss: 2.5003119274091548
Validation loss: 2.68974809420677

Epoch: 6| Step: 3
Training loss: 2.8449610552275963
Validation loss: 2.689567730110926

Epoch: 6| Step: 4
Training loss: 2.999276868769315
Validation loss: 2.571312713828958

Epoch: 6| Step: 5
Training loss: 2.704796423170494
Validation loss: 2.5101512315365473

Epoch: 6| Step: 6
Training loss: 2.6327098067996113
Validation loss: 2.4516400326677967

Epoch: 6| Step: 7
Training loss: 2.0564371644151307
Validation loss: 2.4188806309716386

Epoch: 6| Step: 8
Training loss: 2.585846683255877
Validation loss: 2.421412388511496

Epoch: 6| Step: 9
Training loss: 2.5571762235006625
Validation loss: 2.412277775243731

Epoch: 6| Step: 10
Training loss: 2.5471183800986417
Validation loss: 2.4084430316896377

Epoch: 6| Step: 11
Training loss: 2.4452545841658853
Validation loss: 2.4033524340587276

Epoch: 6| Step: 12
Training loss: 2.732015932698518
Validation loss: 2.3993507873169784

Epoch: 6| Step: 13
Training loss: 2.062283360056403
Validation loss: 2.4198524670202035

Epoch: 204| Step: 0
Training loss: 2.7857475348643725
Validation loss: 2.4384025499320043

Epoch: 6| Step: 1
Training loss: 2.2913806621216644
Validation loss: 2.4958604144486447

Epoch: 6| Step: 2
Training loss: 2.023506899788689
Validation loss: 2.515794997323778

Epoch: 6| Step: 3
Training loss: 2.949455928739016
Validation loss: 2.5011420932899373

Epoch: 6| Step: 4
Training loss: 2.9496573620968203
Validation loss: 2.494507663086887

Epoch: 6| Step: 5
Training loss: 2.6912063059291826
Validation loss: 2.51199844546623

Epoch: 6| Step: 6
Training loss: 1.941873106671636
Validation loss: 2.499570533821645

Epoch: 6| Step: 7
Training loss: 2.467054823242688
Validation loss: 2.5297645551082177

Epoch: 6| Step: 8
Training loss: 2.1960789981592206
Validation loss: 2.53222925954738

Epoch: 6| Step: 9
Training loss: 2.1388177969981697
Validation loss: 2.547757160353421

Epoch: 6| Step: 10
Training loss: 3.130124582364582
Validation loss: 2.5392322306227597

Epoch: 6| Step: 11
Training loss: 2.9179756133829926
Validation loss: 2.4939380224621286

Epoch: 6| Step: 12
Training loss: 2.1678544847773313
Validation loss: 2.465032786050384

Epoch: 6| Step: 13
Training loss: 2.2312917710783333
Validation loss: 2.4326909903813063

Epoch: 205| Step: 0
Training loss: 2.3953418946375504
Validation loss: 2.417567588717407

Epoch: 6| Step: 1
Training loss: 2.7073007424703786
Validation loss: 2.4297063129278222

Epoch: 6| Step: 2
Training loss: 2.8983226660835055
Validation loss: 2.4338481220174084

Epoch: 6| Step: 3
Training loss: 2.2797543574066803
Validation loss: 2.459561511656966

Epoch: 6| Step: 4
Training loss: 2.611570063177562
Validation loss: 2.457010847476785

Epoch: 6| Step: 5
Training loss: 2.903771769211709
Validation loss: 2.464291961960255

Epoch: 6| Step: 6
Training loss: 2.336735719793258
Validation loss: 2.4852127568623823

Epoch: 6| Step: 7
Training loss: 2.7696738051728307
Validation loss: 2.48764372540418

Epoch: 6| Step: 8
Training loss: 2.687494499733198
Validation loss: 2.4988014167992727

Epoch: 6| Step: 9
Training loss: 2.2516846178281855
Validation loss: 2.489247333433412

Epoch: 6| Step: 10
Training loss: 2.229897126874164
Validation loss: 2.4932665416882522

Epoch: 6| Step: 11
Training loss: 2.0365984414010865
Validation loss: 2.479869691318572

Epoch: 6| Step: 12
Training loss: 2.2743726557053625
Validation loss: 2.472587185966157

Epoch: 6| Step: 13
Training loss: 2.2299997668415856
Validation loss: 2.4692597408799837

Epoch: 206| Step: 0
Training loss: 2.1807462793782255
Validation loss: 2.468165596260737

Epoch: 6| Step: 1
Training loss: 2.45417442471671
Validation loss: 2.4652820059276763

Epoch: 6| Step: 2
Training loss: 2.9377876303246753
Validation loss: 2.478979392323355

Epoch: 6| Step: 3
Training loss: 2.598570423316267
Validation loss: 2.4902219347609886

Epoch: 6| Step: 4
Training loss: 2.095180876578109
Validation loss: 2.5182772289078645

Epoch: 6| Step: 5
Training loss: 2.40353825343215
Validation loss: 2.5264185040918727

Epoch: 6| Step: 6
Training loss: 2.409056772870268
Validation loss: 2.5459705858018093

Epoch: 6| Step: 7
Training loss: 2.783161149628646
Validation loss: 2.561520235853902

Epoch: 6| Step: 8
Training loss: 2.167176687905336
Validation loss: 2.545391562458999

Epoch: 6| Step: 9
Training loss: 3.0750461419838224
Validation loss: 2.496907694627163

Epoch: 6| Step: 10
Training loss: 2.09246581821028
Validation loss: 2.4835804985641046

Epoch: 6| Step: 11
Training loss: 2.3593637832476024
Validation loss: 2.4738386293389873

Epoch: 6| Step: 12
Training loss: 1.9296561172960498
Validation loss: 2.4473498237727767

Epoch: 6| Step: 13
Training loss: 3.1768741392877056
Validation loss: 2.4562155100475276

Epoch: 207| Step: 0
Training loss: 2.543524849789957
Validation loss: 2.4356003756311724

Epoch: 6| Step: 1
Training loss: 2.773468103374288
Validation loss: 2.4281884760368784

Epoch: 6| Step: 2
Training loss: 2.549501153359505
Validation loss: 2.4359546345073246

Epoch: 6| Step: 3
Training loss: 2.0636595731964635
Validation loss: 2.444808362306299

Epoch: 6| Step: 4
Training loss: 2.285859558904411
Validation loss: 2.4650403884580485

Epoch: 6| Step: 5
Training loss: 2.673917112687845
Validation loss: 2.47902636408056

Epoch: 6| Step: 6
Training loss: 2.836968016644851
Validation loss: 2.483436419044636

Epoch: 6| Step: 7
Training loss: 2.114008582668873
Validation loss: 2.502291061307025

Epoch: 6| Step: 8
Training loss: 1.6987875204875988
Validation loss: 2.5029309985472783

Epoch: 6| Step: 9
Training loss: 2.8561384717673737
Validation loss: 2.488323586140587

Epoch: 6| Step: 10
Training loss: 2.5263689805692806
Validation loss: 2.4715183998393173

Epoch: 6| Step: 11
Training loss: 2.468919772334476
Validation loss: 2.4675724185256076

Epoch: 6| Step: 12
Training loss: 2.044280059858425
Validation loss: 2.469889339350997

Epoch: 6| Step: 13
Training loss: 2.6411237076454626
Validation loss: 2.459806942971483

Epoch: 208| Step: 0
Training loss: 2.1261280655924866
Validation loss: 2.4894364977407584

Epoch: 6| Step: 1
Training loss: 2.6832392429259513
Validation loss: 2.487091189408874

Epoch: 6| Step: 2
Training loss: 2.579411688419612
Validation loss: 2.4882133223353993

Epoch: 6| Step: 3
Training loss: 1.8368537077654523
Validation loss: 2.516389119681277

Epoch: 6| Step: 4
Training loss: 2.4167063041154924
Validation loss: 2.53075581857292

Epoch: 6| Step: 5
Training loss: 2.480232383700072
Validation loss: 2.5185014629031137

Epoch: 6| Step: 6
Training loss: 2.4317562213675763
Validation loss: 2.5505843316822725

Epoch: 6| Step: 7
Training loss: 2.059953446834418
Validation loss: 2.4922781057388366

Epoch: 6| Step: 8
Training loss: 2.3275562590162022
Validation loss: 2.4596603535517882

Epoch: 6| Step: 9
Training loss: 2.76779046923236
Validation loss: 2.432876188532691

Epoch: 6| Step: 10
Training loss: 2.2561900503378274
Validation loss: 2.4319076927133594

Epoch: 6| Step: 11
Training loss: 3.0128178155806853
Validation loss: 2.4348920759709793

Epoch: 6| Step: 12
Training loss: 2.4575277290836595
Validation loss: 2.4172681251672827

Epoch: 6| Step: 13
Training loss: 2.0715617315590458
Validation loss: 2.4417999724527113

Epoch: 209| Step: 0
Training loss: 2.0946418798442283
Validation loss: 2.431560939829526

Epoch: 6| Step: 1
Training loss: 2.0540902897974416
Validation loss: 2.4474195235163774

Epoch: 6| Step: 2
Training loss: 2.849856684243532
Validation loss: 2.454565430662744

Epoch: 6| Step: 3
Training loss: 2.27367638450432
Validation loss: 2.4698166376484147

Epoch: 6| Step: 4
Training loss: 2.3574514063239373
Validation loss: 2.485553429206208

Epoch: 6| Step: 5
Training loss: 2.3785311899664183
Validation loss: 2.551160667103736

Epoch: 6| Step: 6
Training loss: 2.1134891654522696
Validation loss: 2.613609337147146

Epoch: 6| Step: 7
Training loss: 2.4648243076627723
Validation loss: 2.6836080169095493

Epoch: 6| Step: 8
Training loss: 2.290621490267658
Validation loss: 2.6886110444053806

Epoch: 6| Step: 9
Training loss: 2.8916797260205733
Validation loss: 2.72401285176753

Epoch: 6| Step: 10
Training loss: 2.759118481438718
Validation loss: 2.6276565465720054

Epoch: 6| Step: 11
Training loss: 2.0228780908438995
Validation loss: 2.502770947375447

Epoch: 6| Step: 12
Training loss: 2.8852784896064105
Validation loss: 2.4442309316705315

Epoch: 6| Step: 13
Training loss: 2.0339604999979124
Validation loss: 2.4159685688826538

Epoch: 210| Step: 0
Training loss: 2.1073122464462206
Validation loss: 2.42602606943835

Epoch: 6| Step: 1
Training loss: 2.525015228527716
Validation loss: 2.4070376793099006

Epoch: 6| Step: 2
Training loss: 2.6535530311197557
Validation loss: 2.402513850596451

Epoch: 6| Step: 3
Training loss: 2.1777634965121266
Validation loss: 2.412919472096321

Epoch: 6| Step: 4
Training loss: 2.4929263176769205
Validation loss: 2.4128743206626106

Epoch: 6| Step: 5
Training loss: 2.471778750082938
Validation loss: 2.4158603615902825

Epoch: 6| Step: 6
Training loss: 1.6907144942367824
Validation loss: 2.433009271272783

Epoch: 6| Step: 7
Training loss: 2.6081676316770706
Validation loss: 2.4340553186365526

Epoch: 6| Step: 8
Training loss: 2.754056539560454
Validation loss: 2.4562776736572145

Epoch: 6| Step: 9
Training loss: 2.8324346426067226
Validation loss: 2.4831862615935476

Epoch: 6| Step: 10
Training loss: 2.511844708975955
Validation loss: 2.5224575231531547

Epoch: 6| Step: 11
Training loss: 2.6807065755394834
Validation loss: 2.6279796383826963

Epoch: 6| Step: 12
Training loss: 2.445420917874093
Validation loss: 2.7038897138560922

Epoch: 6| Step: 13
Training loss: 2.463305783958708
Validation loss: 2.7526586122866035

Epoch: 211| Step: 0
Training loss: 2.527989866514056
Validation loss: 2.7481966286384423

Epoch: 6| Step: 1
Training loss: 3.086117973361973
Validation loss: 2.6563741752654977

Epoch: 6| Step: 2
Training loss: 2.3037430201904403
Validation loss: 2.5784101271982673

Epoch: 6| Step: 3
Training loss: 2.1840103652764027
Validation loss: 2.528549522168546

Epoch: 6| Step: 4
Training loss: 2.595532276050619
Validation loss: 2.498382727173505

Epoch: 6| Step: 5
Training loss: 2.268398507793799
Validation loss: 2.486201561047231

Epoch: 6| Step: 6
Training loss: 1.980086852201373
Validation loss: 2.478835611083568

Epoch: 6| Step: 7
Training loss: 2.1456434912791784
Validation loss: 2.461917267681229

Epoch: 6| Step: 8
Training loss: 2.399357224855912
Validation loss: 2.4739857765493394

Epoch: 6| Step: 9
Training loss: 1.8161407604826771
Validation loss: 2.473413231753243

Epoch: 6| Step: 10
Training loss: 2.5627167772851163
Validation loss: 2.4718143069303133

Epoch: 6| Step: 11
Training loss: 2.2640330015884254
Validation loss: 2.4819242432175654

Epoch: 6| Step: 12
Training loss: 2.7421024667972436
Validation loss: 2.5160299739619565

Epoch: 6| Step: 13
Training loss: 2.09864758130855
Validation loss: 2.5336905244483736

Epoch: 212| Step: 0
Training loss: 2.663466042787853
Validation loss: 2.5342267337159057

Epoch: 6| Step: 1
Training loss: 2.9003084216044486
Validation loss: 2.5226920260546564

Epoch: 6| Step: 2
Training loss: 2.120750441614456
Validation loss: 2.56646006637889

Epoch: 6| Step: 3
Training loss: 2.206692019698219
Validation loss: 2.583047909272955

Epoch: 6| Step: 4
Training loss: 1.3141655118393325
Validation loss: 2.561639386635197

Epoch: 6| Step: 5
Training loss: 2.1346419875350318
Validation loss: 2.5835846101601487

Epoch: 6| Step: 6
Training loss: 2.70122500992795
Validation loss: 2.6079568342784

Epoch: 6| Step: 7
Training loss: 2.453724781748236
Validation loss: 2.5861237790988967

Epoch: 6| Step: 8
Training loss: 2.3005911938028927
Validation loss: 2.5741124862639446

Epoch: 6| Step: 9
Training loss: 2.0522527737705047
Validation loss: 2.5857556035628924

Epoch: 6| Step: 10
Training loss: 2.5597223253457657
Validation loss: 2.5742784151150144

Epoch: 6| Step: 11
Training loss: 2.5661155501206574
Validation loss: 2.5992826936350264

Epoch: 6| Step: 12
Training loss: 2.484193039474398
Validation loss: 2.572267646199178

Epoch: 6| Step: 13
Training loss: 1.7263117129090426
Validation loss: 2.5358054227081106

Epoch: 213| Step: 0
Training loss: 1.7994419504412507
Validation loss: 2.490669277947994

Epoch: 6| Step: 1
Training loss: 1.9141267726772653
Validation loss: 2.4840101419286427

Epoch: 6| Step: 2
Training loss: 2.3207118657192636
Validation loss: 2.4855205422758857

Epoch: 6| Step: 3
Training loss: 2.4956037013451233
Validation loss: 2.5164185255034424

Epoch: 6| Step: 4
Training loss: 2.536288204140387
Validation loss: 2.540881649115945

Epoch: 6| Step: 5
Training loss: 1.674989028439245
Validation loss: 2.573415357082769

Epoch: 6| Step: 6
Training loss: 2.900094188607572
Validation loss: 2.594728588927357

Epoch: 6| Step: 7
Training loss: 1.9342036971010248
Validation loss: 2.5800742587863805

Epoch: 6| Step: 8
Training loss: 2.0389254586072627
Validation loss: 2.5544429101382864

Epoch: 6| Step: 9
Training loss: 2.250489817391399
Validation loss: 2.524286486266408

Epoch: 6| Step: 10
Training loss: 1.8789477432967088
Validation loss: 2.5213954451028684

Epoch: 6| Step: 11
Training loss: 2.9138320954490067
Validation loss: 2.5169653455792513

Epoch: 6| Step: 12
Training loss: 2.6269529434828005
Validation loss: 2.541736568200462

Epoch: 6| Step: 13
Training loss: 2.724560721451796
Validation loss: 2.5524629690159677

Epoch: 214| Step: 0
Training loss: 2.811367569869696
Validation loss: 2.5614560709798373

Epoch: 6| Step: 1
Training loss: 2.1832098171249643
Validation loss: 2.5880868305443223

Epoch: 6| Step: 2
Training loss: 2.144615519106509
Validation loss: 2.571626634155466

Epoch: 6| Step: 3
Training loss: 2.0079448968006184
Validation loss: 2.5862814167690416

Epoch: 6| Step: 4
Training loss: 1.8527355743410756
Validation loss: 2.5275034866283805

Epoch: 6| Step: 5
Training loss: 2.335050995165719
Validation loss: 2.5154952821717678

Epoch: 6| Step: 6
Training loss: 2.184981722198786
Validation loss: 2.48464897442144

Epoch: 6| Step: 7
Training loss: 2.0889596370232493
Validation loss: 2.4902880935939207

Epoch: 6| Step: 8
Training loss: 1.9544542595797187
Validation loss: 2.4965414632693053

Epoch: 6| Step: 9
Training loss: 2.445735809444096
Validation loss: 2.5537998101883495

Epoch: 6| Step: 10
Training loss: 2.811330679367196
Validation loss: 2.5656085574345004

Epoch: 6| Step: 11
Training loss: 2.2595752843616967
Validation loss: 2.592570190113971

Epoch: 6| Step: 12
Training loss: 2.5941261110731233
Validation loss: 2.611083034331556

Epoch: 6| Step: 13
Training loss: 1.910232448813271
Validation loss: 2.5603862541335847

Epoch: 215| Step: 0
Training loss: 2.3119889803033113
Validation loss: 2.5495617971163003

Epoch: 6| Step: 1
Training loss: 2.0511903191345455
Validation loss: 2.531094327408871

Epoch: 6| Step: 2
Training loss: 2.441305857310884
Validation loss: 2.532486867988953

Epoch: 6| Step: 3
Training loss: 2.604135060436456
Validation loss: 2.5291163745753478

Epoch: 6| Step: 4
Training loss: 2.180600539092405
Validation loss: 2.502396726772165

Epoch: 6| Step: 5
Training loss: 1.6786914799901307
Validation loss: 2.493769550352224

Epoch: 6| Step: 6
Training loss: 2.3735961780657466
Validation loss: 2.523530673457475

Epoch: 6| Step: 7
Training loss: 2.1973853049003806
Validation loss: 2.522213970072377

Epoch: 6| Step: 8
Training loss: 1.7346290196158254
Validation loss: 2.538462723664

Epoch: 6| Step: 9
Training loss: 2.6076864844080387
Validation loss: 2.586208534393433

Epoch: 6| Step: 10
Training loss: 2.497922129196884
Validation loss: 2.537564479506323

Epoch: 6| Step: 11
Training loss: 2.276156029057701
Validation loss: 2.5146904184286085

Epoch: 6| Step: 12
Training loss: 2.490684319032662
Validation loss: 2.4887763344277243

Epoch: 6| Step: 13
Training loss: 1.8830502308543913
Validation loss: 2.4875820627258145

Epoch: 216| Step: 0
Training loss: 2.707547225328946
Validation loss: 2.496400976402085

Epoch: 6| Step: 1
Training loss: 2.5848292254884004
Validation loss: 2.5353730759649316

Epoch: 6| Step: 2
Training loss: 1.8308578019148618
Validation loss: 2.5586699759281806

Epoch: 6| Step: 3
Training loss: 2.208265111577193
Validation loss: 2.5378942616854294

Epoch: 6| Step: 4
Training loss: 2.1293493527188234
Validation loss: 2.561420744633674

Epoch: 6| Step: 5
Training loss: 1.6362430727981798
Validation loss: 2.577653852650965

Epoch: 6| Step: 6
Training loss: 2.0103628385252232
Validation loss: 2.570876804293474

Epoch: 6| Step: 7
Training loss: 2.559856912518186
Validation loss: 2.5841841657775904

Epoch: 6| Step: 8
Training loss: 2.4240709747209586
Validation loss: 2.5216062461405615

Epoch: 6| Step: 9
Training loss: 2.3535889673478843
Validation loss: 2.529099287407429

Epoch: 6| Step: 10
Training loss: 2.5904316644805565
Validation loss: 2.530106435436489

Epoch: 6| Step: 11
Training loss: 1.5603908035858072
Validation loss: 2.5291810416236316

Epoch: 6| Step: 12
Training loss: 1.9976150478609005
Validation loss: 2.532298556683945

Epoch: 6| Step: 13
Training loss: 1.9798602311095104
Validation loss: 2.523757977715648

Epoch: 217| Step: 0
Training loss: 2.2348224752016668
Validation loss: 2.530087706378995

Epoch: 6| Step: 1
Training loss: 2.5502721678652236
Validation loss: 2.540840713377845

Epoch: 6| Step: 2
Training loss: 2.0873065698971582
Validation loss: 2.5769530445776168

Epoch: 6| Step: 3
Training loss: 2.4739071061034013
Validation loss: 2.6065396279951054

Epoch: 6| Step: 4
Training loss: 2.071128943341063
Validation loss: 2.647265416752932

Epoch: 6| Step: 5
Training loss: 2.3746197044673756
Validation loss: 2.667513786503489

Epoch: 6| Step: 6
Training loss: 2.0978299145406893
Validation loss: 2.606500162098706

Epoch: 6| Step: 7
Training loss: 2.2229541116389226
Validation loss: 2.6323877883419535

Epoch: 6| Step: 8
Training loss: 1.895208304639586
Validation loss: 2.5880286516625093

Epoch: 6| Step: 9
Training loss: 2.1637861715783
Validation loss: 2.546977166107699

Epoch: 6| Step: 10
Training loss: 1.966093602444606
Validation loss: 2.533441999978248

Epoch: 6| Step: 11
Training loss: 2.0109403122628087
Validation loss: 2.4830814171305993

Epoch: 6| Step: 12
Training loss: 2.36746506275473
Validation loss: 2.509453123726686

Epoch: 6| Step: 13
Training loss: 1.9798875064875117
Validation loss: 2.4934069933574254

Epoch: 218| Step: 0
Training loss: 1.9777022984325994
Validation loss: 2.5049889243536887

Epoch: 6| Step: 1
Training loss: 1.7539859065465062
Validation loss: 2.5184479541927867

Epoch: 6| Step: 2
Training loss: 2.2410798742996025
Validation loss: 2.544628908123897

Epoch: 6| Step: 3
Training loss: 2.253205770666452
Validation loss: 2.5700612326087784

Epoch: 6| Step: 4
Training loss: 2.2101719477808337
Validation loss: 2.6133560446358604

Epoch: 6| Step: 5
Training loss: 1.8240294266343142
Validation loss: 2.5694750506762065

Epoch: 6| Step: 6
Training loss: 2.016810815036319
Validation loss: 2.493355559763873

Epoch: 6| Step: 7
Training loss: 2.1486592126366477
Validation loss: 2.4906986559951445

Epoch: 6| Step: 8
Training loss: 2.4680385288711917
Validation loss: 2.4613387247439995

Epoch: 6| Step: 9
Training loss: 2.0465318231967307
Validation loss: 2.4520583165757155

Epoch: 6| Step: 10
Training loss: 2.561466753060143
Validation loss: 2.4625254414278315

Epoch: 6| Step: 11
Training loss: 2.6167879169662127
Validation loss: 2.4567498734728823

Epoch: 6| Step: 12
Training loss: 1.9609385334635288
Validation loss: 2.51634358602739

Epoch: 6| Step: 13
Training loss: 2.0784151261954613
Validation loss: 2.6335251191460913

Epoch: 219| Step: 0
Training loss: 1.8350213544886729
Validation loss: 2.7339539712670287

Epoch: 6| Step: 1
Training loss: 2.605272643159739
Validation loss: 2.8217039430250797

Epoch: 6| Step: 2
Training loss: 1.4346116944869578
Validation loss: 2.8217631403696974

Epoch: 6| Step: 3
Training loss: 2.349877853465685
Validation loss: 2.87991934118299

Epoch: 6| Step: 4
Training loss: 2.3417506527574496
Validation loss: 2.8306518662470896

Epoch: 6| Step: 5
Training loss: 2.526524972725418
Validation loss: 2.6717291936529834

Epoch: 6| Step: 6
Training loss: 1.7421665618048823
Validation loss: 2.4948210335057506

Epoch: 6| Step: 7
Training loss: 1.6397406965045025
Validation loss: 2.430642242604631

Epoch: 6| Step: 8
Training loss: 2.3005125345453656
Validation loss: 2.413951647824086

Epoch: 6| Step: 9
Training loss: 2.595208918222892
Validation loss: 2.395130027133854

Epoch: 6| Step: 10
Training loss: 2.8242354649725803
Validation loss: 2.4138393875774815

Epoch: 6| Step: 11
Training loss: 1.5914888236000657
Validation loss: 2.430146564542066

Epoch: 6| Step: 12
Training loss: 2.4506408359334064
Validation loss: 2.4480866044402814

Epoch: 6| Step: 13
Training loss: 1.6018318508020806
Validation loss: 2.470181070231912

Epoch: 220| Step: 0
Training loss: 1.8914743202436652
Validation loss: 2.531048263193818

Epoch: 6| Step: 1
Training loss: 2.5218918734793125
Validation loss: 2.6080637587067663

Epoch: 6| Step: 2
Training loss: 2.161082395162864
Validation loss: 2.6758434609682107

Epoch: 6| Step: 3
Training loss: 2.4131841450447804
Validation loss: 2.7301455525974347

Epoch: 6| Step: 4
Training loss: 1.74274473302404
Validation loss: 2.6773300992447493

Epoch: 6| Step: 5
Training loss: 2.886429830295926
Validation loss: 2.61554580254741

Epoch: 6| Step: 6
Training loss: 1.9323160284790986
Validation loss: 2.5997796276449057

Epoch: 6| Step: 7
Training loss: 2.292382862422254
Validation loss: 2.5629224701587296

Epoch: 6| Step: 8
Training loss: 2.000990860582152
Validation loss: 2.549715185898235

Epoch: 6| Step: 9
Training loss: 2.07846984296683
Validation loss: 2.498008404395698

Epoch: 6| Step: 10
Training loss: 2.314364635208413
Validation loss: 2.4556924251750507

Epoch: 6| Step: 11
Training loss: 2.4963894521149657
Validation loss: 2.420934377361146

Epoch: 6| Step: 12
Training loss: 1.7308139844145642
Validation loss: 2.4011575236115883

Epoch: 6| Step: 13
Training loss: 0.880011850732423
Validation loss: 2.4161655435451688

Epoch: 221| Step: 0
Training loss: 2.246681627380335
Validation loss: 2.4100359796282285

Epoch: 6| Step: 1
Training loss: 1.935851534088573
Validation loss: 2.428953599834895

Epoch: 6| Step: 2
Training loss: 2.3327643745297544
Validation loss: 2.4971589701493913

Epoch: 6| Step: 3
Training loss: 1.981105604234821
Validation loss: 2.5559374545610662

Epoch: 6| Step: 4
Training loss: 2.406349180084919
Validation loss: 2.6423916480606833

Epoch: 6| Step: 5
Training loss: 2.3751624202403447
Validation loss: 2.7157834494537085

Epoch: 6| Step: 6
Training loss: 2.157074259350281
Validation loss: 2.8057471291519396

Epoch: 6| Step: 7
Training loss: 2.524288352920519
Validation loss: 2.7966333091105877

Epoch: 6| Step: 8
Training loss: 1.4370693722772414
Validation loss: 2.649241740209725

Epoch: 6| Step: 9
Training loss: 2.1269727413509445
Validation loss: 2.579945650971056

Epoch: 6| Step: 10
Training loss: 2.157379960028171
Validation loss: 2.522670954393893

Epoch: 6| Step: 11
Training loss: 1.7641542098311767
Validation loss: 2.4912672375074427

Epoch: 6| Step: 12
Training loss: 1.9708127311721166
Validation loss: 2.463207636832803

Epoch: 6| Step: 13
Training loss: 1.9315994613164837
Validation loss: 2.464830192488459

Epoch: 222| Step: 0
Training loss: 1.7183003617733028
Validation loss: 2.460745998001657

Epoch: 6| Step: 1
Training loss: 1.5566715634668566
Validation loss: 2.444171973844613

Epoch: 6| Step: 2
Training loss: 1.7137622246838375
Validation loss: 2.454174297275008

Epoch: 6| Step: 3
Training loss: 2.156768957519698
Validation loss: 2.454132819872456

Epoch: 6| Step: 4
Training loss: 2.3181666460407713
Validation loss: 2.4617419283498667

Epoch: 6| Step: 5
Training loss: 2.553592178763456
Validation loss: 2.5003052945514357

Epoch: 6| Step: 6
Training loss: 1.5038968965313841
Validation loss: 2.513992148551076

Epoch: 6| Step: 7
Training loss: 2.227091408534408
Validation loss: 2.5450818672118403

Epoch: 6| Step: 8
Training loss: 1.7736674424382257
Validation loss: 2.5656407894896542

Epoch: 6| Step: 9
Training loss: 2.097291598600573
Validation loss: 2.5928158135946098

Epoch: 6| Step: 10
Training loss: 1.8668035647170038
Validation loss: 2.575560166092523

Epoch: 6| Step: 11
Training loss: 2.748868015699702
Validation loss: 2.601530238022368

Epoch: 6| Step: 12
Training loss: 2.362025609903932
Validation loss: 2.5685194852948015

Epoch: 6| Step: 13
Training loss: 1.7531267570717994
Validation loss: 2.5803653353829494

Epoch: 223| Step: 0
Training loss: 2.158991301214691
Validation loss: 2.585503975853113

Epoch: 6| Step: 1
Training loss: 2.0315983400233293
Validation loss: 2.5569588150703977

Epoch: 6| Step: 2
Training loss: 1.83147853167441
Validation loss: 2.5539814148661915

Epoch: 6| Step: 3
Training loss: 2.0284933311196696
Validation loss: 2.5380133968795073

Epoch: 6| Step: 4
Training loss: 2.1522923513599763
Validation loss: 2.515677213397657

Epoch: 6| Step: 5
Training loss: 2.2786509719064085
Validation loss: 2.516075640654368

Epoch: 6| Step: 6
Training loss: 1.6022682681781004
Validation loss: 2.504911219420135

Epoch: 6| Step: 7
Training loss: 1.1861602855398352
Validation loss: 2.5178821577148245

Epoch: 6| Step: 8
Training loss: 1.7010363449259494
Validation loss: 2.5176872045793988

Epoch: 6| Step: 9
Training loss: 2.125909274170559
Validation loss: 2.5378279432990465

Epoch: 6| Step: 10
Training loss: 2.067419254520573
Validation loss: 2.5070115721656565

Epoch: 6| Step: 11
Training loss: 2.4456957434491207
Validation loss: 2.51199862406391

Epoch: 6| Step: 12
Training loss: 2.011090760218793
Validation loss: 2.5411956141477687

Epoch: 6| Step: 13
Training loss: 2.6128820733118485
Validation loss: 2.51762593865145

Epoch: 224| Step: 0
Training loss: 1.947151693456607
Validation loss: 2.5670045946895517

Epoch: 6| Step: 1
Training loss: 2.203240898817339
Validation loss: 2.5782075492741607

Epoch: 6| Step: 2
Training loss: 1.3357726324421233
Validation loss: 2.6155210201877024

Epoch: 6| Step: 3
Training loss: 1.9541213279079093
Validation loss: 2.593656008188984

Epoch: 6| Step: 4
Training loss: 2.266789735463673
Validation loss: 2.5806225057538064

Epoch: 6| Step: 5
Training loss: 1.386450814165361
Validation loss: 2.537591507277725

Epoch: 6| Step: 6
Training loss: 2.22289597973289
Validation loss: 2.522710937047073

Epoch: 6| Step: 7
Training loss: 2.2296181575094645
Validation loss: 2.515292668057629

Epoch: 6| Step: 8
Training loss: 1.8770788112957077
Validation loss: 2.4892478154199487

Epoch: 6| Step: 9
Training loss: 1.9953182976144848
Validation loss: 2.4995985990702834

Epoch: 6| Step: 10
Training loss: 2.103161171861405
Validation loss: 2.5269791215370208

Epoch: 6| Step: 11
Training loss: 2.146568123152961
Validation loss: 2.516625120649501

Epoch: 6| Step: 12
Training loss: 2.295523213270202
Validation loss: 2.530835832696583

Epoch: 6| Step: 13
Training loss: 1.532810817021526
Validation loss: 2.5497048436995446

Epoch: 225| Step: 0
Training loss: 1.7174158640413903
Validation loss: 2.5386743675148136

Epoch: 6| Step: 1
Training loss: 1.8253683188847156
Validation loss: 2.5309949083212735

Epoch: 6| Step: 2
Training loss: 2.4965790230613356
Validation loss: 2.5133552107355626

Epoch: 6| Step: 3
Training loss: 1.9436612148798333
Validation loss: 2.5523833516419

Epoch: 6| Step: 4
Training loss: 2.295717531619548
Validation loss: 2.563590867267258

Epoch: 6| Step: 5
Training loss: 2.6980062541054983
Validation loss: 2.6472894758435417

Epoch: 6| Step: 6
Training loss: 1.8040369355719514
Validation loss: 2.7012272440282334

Epoch: 6| Step: 7
Training loss: 2.369143845319328
Validation loss: 2.7691491663555228

Epoch: 6| Step: 8
Training loss: 2.5070360354255707
Validation loss: 2.7938558663364197

Epoch: 6| Step: 9
Training loss: 1.345181789095932
Validation loss: 2.6938229304513084

Epoch: 6| Step: 10
Training loss: 1.9377182253103966
Validation loss: 2.605495670624332

Epoch: 6| Step: 11
Training loss: 1.24638353762975
Validation loss: 2.4742577867775726

Epoch: 6| Step: 12
Training loss: 1.8223909619108078
Validation loss: 2.428324512005063

Epoch: 6| Step: 13
Training loss: 1.469698579338048
Validation loss: 2.4074353804995208

Epoch: 226| Step: 0
Training loss: 1.8577550675455607
Validation loss: 2.3975852250232177

Epoch: 6| Step: 1
Training loss: 1.958068390097047
Validation loss: 2.4088627481127567

Epoch: 6| Step: 2
Training loss: 2.19700584401815
Validation loss: 2.412399983786247

Epoch: 6| Step: 3
Training loss: 2.2916586673481363
Validation loss: 2.462075879369287

Epoch: 6| Step: 4
Training loss: 1.62636450186295
Validation loss: 2.524993314260044

Epoch: 6| Step: 5
Training loss: 2.0063014894337057
Validation loss: 2.5838336893357794

Epoch: 6| Step: 6
Training loss: 2.1763249099871476
Validation loss: 2.5970193140486337

Epoch: 6| Step: 7
Training loss: 2.0006470825540132
Validation loss: 2.608034568355075

Epoch: 6| Step: 8
Training loss: 1.915264888600493
Validation loss: 2.5919070584965485

Epoch: 6| Step: 9
Training loss: 1.755866028430456
Validation loss: 2.6081925065138702

Epoch: 6| Step: 10
Training loss: 1.9109680073533868
Validation loss: 2.5792823001278036

Epoch: 6| Step: 11
Training loss: 1.416374382085567
Validation loss: 2.572458487886816

Epoch: 6| Step: 12
Training loss: 2.5598959368178282
Validation loss: 2.50394496376188

Epoch: 6| Step: 13
Training loss: 1.286236572714547
Validation loss: 2.4867847880574514

Epoch: 227| Step: 0
Training loss: 1.7065546343708933
Validation loss: 2.4796315304803396

Epoch: 6| Step: 1
Training loss: 2.2220023589512263
Validation loss: 2.486361465235076

Epoch: 6| Step: 2
Training loss: 2.243227727349425
Validation loss: 2.486147398401319

Epoch: 6| Step: 3
Training loss: 2.06228347566543
Validation loss: 2.501128624398839

Epoch: 6| Step: 4
Training loss: 1.4281389365152701
Validation loss: 2.510571961383732

Epoch: 6| Step: 5
Training loss: 1.7908593362323044
Validation loss: 2.553322079854142

Epoch: 6| Step: 6
Training loss: 1.7963686685777716
Validation loss: 2.573362842772957

Epoch: 6| Step: 7
Training loss: 2.157944939130988
Validation loss: 2.556097686014279

Epoch: 6| Step: 8
Training loss: 2.013718287231864
Validation loss: 2.621357742145145

Epoch: 6| Step: 9
Training loss: 2.058665902250441
Validation loss: 2.6777912549508995

Epoch: 6| Step: 10
Training loss: 2.065515336950499
Validation loss: 2.673947160008951

Epoch: 6| Step: 11
Training loss: 1.9389245118649079
Validation loss: 2.6538579469327

Epoch: 6| Step: 12
Training loss: 1.6059227368829947
Validation loss: 2.5812729367076805

Epoch: 6| Step: 13
Training loss: 2.059272784415597
Validation loss: 2.5383052926760263

Epoch: 228| Step: 0
Training loss: 1.587074961795028
Validation loss: 2.495191732938222

Epoch: 6| Step: 1
Training loss: 1.6449236548891315
Validation loss: 2.4672117476051203

Epoch: 6| Step: 2
Training loss: 2.126881495759266
Validation loss: 2.4623669138778244

Epoch: 6| Step: 3
Training loss: 1.947197364827444
Validation loss: 2.442945753268874

Epoch: 6| Step: 4
Training loss: 1.9497505028375886
Validation loss: 2.503991565483018

Epoch: 6| Step: 5
Training loss: 1.9992055507163071
Validation loss: 2.534638446437257

Epoch: 6| Step: 6
Training loss: 2.1444231850333995
Validation loss: 2.5383131099185072

Epoch: 6| Step: 7
Training loss: 1.7178414457650293
Validation loss: 2.6012272353762738

Epoch: 6| Step: 8
Training loss: 1.8645273836006746
Validation loss: 2.6025311820587684

Epoch: 6| Step: 9
Training loss: 2.1889852658573616
Validation loss: 2.6039184448732047

Epoch: 6| Step: 10
Training loss: 1.946315399619533
Validation loss: 2.5723391436033776

Epoch: 6| Step: 11
Training loss: 1.6060985063292603
Validation loss: 2.5715176503345147

Epoch: 6| Step: 12
Training loss: 1.823976161600238
Validation loss: 2.5241359063087008

Epoch: 6| Step: 13
Training loss: 2.412897217617876
Validation loss: 2.5162120723352395

Epoch: 229| Step: 0
Training loss: 1.4716523085023723
Validation loss: 2.482005363659189

Epoch: 6| Step: 1
Training loss: 1.7966360182026508
Validation loss: 2.502281565037583

Epoch: 6| Step: 2
Training loss: 1.832694187882312
Validation loss: 2.4959378300753317

Epoch: 6| Step: 3
Training loss: 1.8390069504275135
Validation loss: 2.5236659199160005

Epoch: 6| Step: 4
Training loss: 1.6852040389725396
Validation loss: 2.5303364235241212

Epoch: 6| Step: 5
Training loss: 1.7488068873087477
Validation loss: 2.605675036942466

Epoch: 6| Step: 6
Training loss: 1.2335749580638262
Validation loss: 2.560732531324558

Epoch: 6| Step: 7
Training loss: 1.8602273093553146
Validation loss: 2.567778606202411

Epoch: 6| Step: 8
Training loss: 1.9965364745314627
Validation loss: 2.543856029019574

Epoch: 6| Step: 9
Training loss: 1.9771756514074703
Validation loss: 2.510161625379119

Epoch: 6| Step: 10
Training loss: 1.85723484513645
Validation loss: 2.494560232163332

Epoch: 6| Step: 11
Training loss: 2.453833993882074
Validation loss: 2.4630332896935148

Epoch: 6| Step: 12
Training loss: 2.289134157901431
Validation loss: 2.4853037602579953

Epoch: 6| Step: 13
Training loss: 2.1136261099811833
Validation loss: 2.4955980051668645

Epoch: 230| Step: 0
Training loss: 2.2443525647513596
Validation loss: 2.511434235895738

Epoch: 6| Step: 1
Training loss: 2.021547355223622
Validation loss: 2.563445466321251

Epoch: 6| Step: 2
Training loss: 1.6378001280187944
Validation loss: 2.5917772781555177

Epoch: 6| Step: 3
Training loss: 1.6484609303910964
Validation loss: 2.643088733905562

Epoch: 6| Step: 4
Training loss: 2.1456276014152778
Validation loss: 2.6287373893236015

Epoch: 6| Step: 5
Training loss: 2.0972428296264782
Validation loss: 2.531483627145805

Epoch: 6| Step: 6
Training loss: 1.6076614738985298
Validation loss: 2.500462237048601

Epoch: 6| Step: 7
Training loss: 1.2531563961823946
Validation loss: 2.4593831033999636

Epoch: 6| Step: 8
Training loss: 1.7182918978461177
Validation loss: 2.429882194622181

Epoch: 6| Step: 9
Training loss: 2.1217644686555617
Validation loss: 2.4446645097833795

Epoch: 6| Step: 10
Training loss: 2.2829051871677484
Validation loss: 2.4542476576828305

Epoch: 6| Step: 11
Training loss: 1.866674951410074
Validation loss: 2.4851303247420318

Epoch: 6| Step: 12
Training loss: 1.403230009843544
Validation loss: 2.543747700719436

Epoch: 6| Step: 13
Training loss: 2.1654613394499997
Validation loss: 2.6290821079458047

Epoch: 231| Step: 0
Training loss: 1.7076100081923669
Validation loss: 2.7250885629275388

Epoch: 6| Step: 1
Training loss: 1.6596459176556206
Validation loss: 2.7836707478831384

Epoch: 6| Step: 2
Training loss: 1.5190742021057746
Validation loss: 2.755127931427358

Epoch: 6| Step: 3
Training loss: 2.088333182896849
Validation loss: 2.6871048993882027

Epoch: 6| Step: 4
Training loss: 1.918742410352775
Validation loss: 2.59089156014358

Epoch: 6| Step: 5
Training loss: 1.986824206254657
Validation loss: 2.5386406782067956

Epoch: 6| Step: 6
Training loss: 1.262451809256088
Validation loss: 2.478585834320558

Epoch: 6| Step: 7
Training loss: 1.7050788241425399
Validation loss: 2.4568530691293526

Epoch: 6| Step: 8
Training loss: 2.284395635801277
Validation loss: 2.4487446357174023

Epoch: 6| Step: 9
Training loss: 2.2215994147586016
Validation loss: 2.441392551834891

Epoch: 6| Step: 10
Training loss: 2.142402300927292
Validation loss: 2.43433340509596

Epoch: 6| Step: 11
Training loss: 2.2020513204402805
Validation loss: 2.4474210172326756

Epoch: 6| Step: 12
Training loss: 1.6894742225696777
Validation loss: 2.5149235635049534

Epoch: 6| Step: 13
Training loss: 1.5384947218434044
Validation loss: 2.574674769809066

Epoch: 232| Step: 0
Training loss: 1.5519083765061081
Validation loss: 2.664179919791736

Epoch: 6| Step: 1
Training loss: 1.8051985640425647
Validation loss: 2.7479797989930494

Epoch: 6| Step: 2
Training loss: 1.9363889892813526
Validation loss: 2.7383103233005115

Epoch: 6| Step: 3
Training loss: 2.119670467676645
Validation loss: 2.7083408380850913

Epoch: 6| Step: 4
Training loss: 1.8592179175949766
Validation loss: 2.625456476832012

Epoch: 6| Step: 5
Training loss: 1.2963414301028815
Validation loss: 2.594762472810978

Epoch: 6| Step: 6
Training loss: 2.079743063719672
Validation loss: 2.5217979065097014

Epoch: 6| Step: 7
Training loss: 1.6573715730973049
Validation loss: 2.4966158044523747

Epoch: 6| Step: 8
Training loss: 1.659943762251752
Validation loss: 2.5102501198980294

Epoch: 6| Step: 9
Training loss: 1.8137598591910518
Validation loss: 2.474881154058866

Epoch: 6| Step: 10
Training loss: 2.118195916477575
Validation loss: 2.4790050226054183

Epoch: 6| Step: 11
Training loss: 2.1026345393875716
Validation loss: 2.4592269637965627

Epoch: 6| Step: 12
Training loss: 1.645938950381012
Validation loss: 2.512071761298085

Epoch: 6| Step: 13
Training loss: 2.0423800201849276
Validation loss: 2.50247593119706

Epoch: 233| Step: 0
Training loss: 1.742891998858173
Validation loss: 2.511126688502557

Epoch: 6| Step: 1
Training loss: 2.266106074329334
Validation loss: 2.520609381875633

Epoch: 6| Step: 2
Training loss: 1.4448167105193135
Validation loss: 2.547917651681352

Epoch: 6| Step: 3
Training loss: 1.814060723092772
Validation loss: 2.5723608568377823

Epoch: 6| Step: 4
Training loss: 1.3658140422644933
Validation loss: 2.582775768240703

Epoch: 6| Step: 5
Training loss: 1.9284024921479468
Validation loss: 2.5684927400540056

Epoch: 6| Step: 6
Training loss: 2.110727286442845
Validation loss: 2.5773598622863356

Epoch: 6| Step: 7
Training loss: 1.586452081191663
Validation loss: 2.5713308798999086

Epoch: 6| Step: 8
Training loss: 1.6785968166970628
Validation loss: 2.5867097243934025

Epoch: 6| Step: 9
Training loss: 2.0223036722867156
Validation loss: 2.568054282411462

Epoch: 6| Step: 10
Training loss: 1.7044766163652947
Validation loss: 2.609821474193682

Epoch: 6| Step: 11
Training loss: 2.0278210381316217
Validation loss: 2.6017412940099303

Epoch: 6| Step: 12
Training loss: 1.3406432855243808
Validation loss: 2.5676422267049404

Epoch: 6| Step: 13
Training loss: 1.6437253449770277
Validation loss: 2.52648957703225

Epoch: 234| Step: 0
Training loss: 1.6971911028797593
Validation loss: 2.48899933486293

Epoch: 6| Step: 1
Training loss: 2.471161835197133
Validation loss: 2.476582115185978

Epoch: 6| Step: 2
Training loss: 1.6486723673766028
Validation loss: 2.4823266442227045

Epoch: 6| Step: 3
Training loss: 1.1299863090360913
Validation loss: 2.4845598672768885

Epoch: 6| Step: 4
Training loss: 1.779653402509248
Validation loss: 2.4880265719731125

Epoch: 6| Step: 5
Training loss: 1.650533780542425
Validation loss: 2.510328077256814

Epoch: 6| Step: 6
Training loss: 2.0687972371681096
Validation loss: 2.5704017397008294

Epoch: 6| Step: 7
Training loss: 2.086310078354124
Validation loss: 2.6033023080669153

Epoch: 6| Step: 8
Training loss: 1.384936237451176
Validation loss: 2.609752004660787

Epoch: 6| Step: 9
Training loss: 1.2935902464637536
Validation loss: 2.6007949104189736

Epoch: 6| Step: 10
Training loss: 1.6386909347353271
Validation loss: 2.604779010930432

Epoch: 6| Step: 11
Training loss: 1.9009043047325482
Validation loss: 2.6016647967656317

Epoch: 6| Step: 12
Training loss: 2.05841943918531
Validation loss: 2.6274124453305636

Epoch: 6| Step: 13
Training loss: 0.9082209103391278
Validation loss: 2.6636163476713057

Epoch: 235| Step: 0
Training loss: 2.0023077525081887
Validation loss: 2.7055089471032816

Epoch: 6| Step: 1
Training loss: 1.4249377956533131
Validation loss: 2.706308685453074

Epoch: 6| Step: 2
Training loss: 1.781047541841098
Validation loss: 2.695433317796413

Epoch: 6| Step: 3
Training loss: 1.2829641645129128
Validation loss: 2.6451375409930207

Epoch: 6| Step: 4
Training loss: 1.5987672557003976
Validation loss: 2.5714421113219794

Epoch: 6| Step: 5
Training loss: 1.490649964065559
Validation loss: 2.5173711090587134

Epoch: 6| Step: 6
Training loss: 1.851378226466127
Validation loss: 2.451691503828603

Epoch: 6| Step: 7
Training loss: 1.5445316945655658
Validation loss: 2.435710634085455

Epoch: 6| Step: 8
Training loss: 2.1569044806102475
Validation loss: 2.42386999828921

Epoch: 6| Step: 9
Training loss: 1.4252558327960168
Validation loss: 2.447633349261093

Epoch: 6| Step: 10
Training loss: 2.2580156597881764
Validation loss: 2.4954365046282985

Epoch: 6| Step: 11
Training loss: 2.176141732999496
Validation loss: 2.5263089480801737

Epoch: 6| Step: 12
Training loss: 1.7988843215299015
Validation loss: 2.5708343208558264

Epoch: 6| Step: 13
Training loss: 1.5981077568189153
Validation loss: 2.662626650406051

Epoch: 236| Step: 0
Training loss: 1.9701274110285445
Validation loss: 2.6747183737651916

Epoch: 6| Step: 1
Training loss: 1.4117850832193126
Validation loss: 2.669706786916484

Epoch: 6| Step: 2
Training loss: 2.2013141955016087
Validation loss: 2.7074269263321353

Epoch: 6| Step: 3
Training loss: 1.5506718594575388
Validation loss: 2.6503540194199475

Epoch: 6| Step: 4
Training loss: 1.8970294016005944
Validation loss: 2.6204104169373004

Epoch: 6| Step: 5
Training loss: 1.7221695608202523
Validation loss: 2.578974638815507

Epoch: 6| Step: 6
Training loss: 1.8099177151095929
Validation loss: 2.5373992318585947

Epoch: 6| Step: 7
Training loss: 1.6012057767742394
Validation loss: 2.5017223044988994

Epoch: 6| Step: 8
Training loss: 1.1507413423433388
Validation loss: 2.5062577673101973

Epoch: 6| Step: 9
Training loss: 1.8754985146614525
Validation loss: 2.4978023575731707

Epoch: 6| Step: 10
Training loss: 1.3972950962916193
Validation loss: 2.528800472899598

Epoch: 6| Step: 11
Training loss: 1.8251296062694826
Validation loss: 2.5423953638859293

Epoch: 6| Step: 12
Training loss: 1.7671715368870367
Validation loss: 2.584165816750394

Epoch: 6| Step: 13
Training loss: 1.6497627463417033
Validation loss: 2.57582452334551

Epoch: 237| Step: 0
Training loss: 1.9361419840679823
Validation loss: 2.5940676708476684

Epoch: 6| Step: 1
Training loss: 2.071458377059951
Validation loss: 2.609403766652569

Epoch: 6| Step: 2
Training loss: 2.004472143271299
Validation loss: 2.58078936602068

Epoch: 6| Step: 3
Training loss: 1.9628390025472426
Validation loss: 2.5345100223730537

Epoch: 6| Step: 4
Training loss: 1.5789545730376255
Validation loss: 2.4849872996757436

Epoch: 6| Step: 5
Training loss: 1.6396522908168316
Validation loss: 2.4633866495728483

Epoch: 6| Step: 6
Training loss: 1.8333221637501174
Validation loss: 2.470026870105772

Epoch: 6| Step: 7
Training loss: 1.6609077458125414
Validation loss: 2.4887226810625602

Epoch: 6| Step: 8
Training loss: 1.3341221661426346
Validation loss: 2.5090682978022425

Epoch: 6| Step: 9
Training loss: 1.3688566645339242
Validation loss: 2.525852738167712

Epoch: 6| Step: 10
Training loss: 1.4417462865346067
Validation loss: 2.526990592553392

Epoch: 6| Step: 11
Training loss: 1.6011517253798178
Validation loss: 2.52165810389477

Epoch: 6| Step: 12
Training loss: 1.4840845727393601
Validation loss: 2.528455535962522

Epoch: 6| Step: 13
Training loss: 1.6093078895575992
Validation loss: 2.5369872067631607

Epoch: 238| Step: 0
Training loss: 1.6740768052031658
Validation loss: 2.5942969182334106

Epoch: 6| Step: 1
Training loss: 1.6794768445303068
Validation loss: 2.602539137364077

Epoch: 6| Step: 2
Training loss: 2.1185171308799435
Validation loss: 2.647527508057508

Epoch: 6| Step: 3
Training loss: 1.1872337444362937
Validation loss: 2.6503411429261687

Epoch: 6| Step: 4
Training loss: 1.3779545166027978
Validation loss: 2.65299256365504

Epoch: 6| Step: 5
Training loss: 1.935848147198336
Validation loss: 2.622300398136751

Epoch: 6| Step: 6
Training loss: 1.438540372449701
Validation loss: 2.5594051789971286

Epoch: 6| Step: 7
Training loss: 1.4330655405958195
Validation loss: 2.5083426256804544

Epoch: 6| Step: 8
Training loss: 1.1307846334527223
Validation loss: 2.4447634993856138

Epoch: 6| Step: 9
Training loss: 2.0755484534084694
Validation loss: 2.4585875271468893

Epoch: 6| Step: 10
Training loss: 1.8836023723669173
Validation loss: 2.4896820916504705

Epoch: 6| Step: 11
Training loss: 1.4039740476546323
Validation loss: 2.5260151428582502

Epoch: 6| Step: 12
Training loss: 1.6886384444023819
Validation loss: 2.55837966660808

Epoch: 6| Step: 13
Training loss: 2.3296374842022725
Validation loss: 2.620091921970664

Epoch: 239| Step: 0
Training loss: 1.669427095697905
Validation loss: 2.6861520292795498

Epoch: 6| Step: 1
Training loss: 1.9579577051919264
Validation loss: 2.778937328250785

Epoch: 6| Step: 2
Training loss: 1.6628014169376328
Validation loss: 2.7975922700166653

Epoch: 6| Step: 3
Training loss: 1.8707814762373733
Validation loss: 2.800109651867868

Epoch: 6| Step: 4
Training loss: 1.540156096932217
Validation loss: 2.7402887021544005

Epoch: 6| Step: 5
Training loss: 2.0301530663797025
Validation loss: 2.6280270442129576

Epoch: 6| Step: 6
Training loss: 1.1920507470087898
Validation loss: 2.5398119112201676

Epoch: 6| Step: 7
Training loss: 2.1148488546703725
Validation loss: 2.4511116648294107

Epoch: 6| Step: 8
Training loss: 1.4560317633171929
Validation loss: 2.4420853904607696

Epoch: 6| Step: 9
Training loss: 1.2926959069715511
Validation loss: 2.447769394325693

Epoch: 6| Step: 10
Training loss: 1.4349120520513416
Validation loss: 2.454367848522529

Epoch: 6| Step: 11
Training loss: 1.4577544107751481
Validation loss: 2.4580319301349904

Epoch: 6| Step: 12
Training loss: 1.4100754310505668
Validation loss: 2.51386067807023

Epoch: 6| Step: 13
Training loss: 2.1204209077202614
Validation loss: 2.5571303213439935

Epoch: 240| Step: 0
Training loss: 1.3816087300094915
Validation loss: 2.651257045152235

Epoch: 6| Step: 1
Training loss: 1.6300417375194103
Validation loss: 2.6522972988111158

Epoch: 6| Step: 2
Training loss: 1.9506172865959868
Validation loss: 2.679100014077205

Epoch: 6| Step: 3
Training loss: 1.8010163060688684
Validation loss: 2.63045428837982

Epoch: 6| Step: 4
Training loss: 1.7110606806756157
Validation loss: 2.5805734631489465

Epoch: 6| Step: 5
Training loss: 1.7233934274054747
Validation loss: 2.5260381260703193

Epoch: 6| Step: 6
Training loss: 1.7692228136872516
Validation loss: 2.483703343969757

Epoch: 6| Step: 7
Training loss: 2.01269045574226
Validation loss: 2.4506428251113466

Epoch: 6| Step: 8
Training loss: 0.9629466444824106
Validation loss: 2.492969064427813

Epoch: 6| Step: 9
Training loss: 1.5063235189769966
Validation loss: 2.51526378009373

Epoch: 6| Step: 10
Training loss: 1.411573252861815
Validation loss: 2.548038549304083

Epoch: 6| Step: 11
Training loss: 1.618955226540627
Validation loss: 2.5838734518297835

Epoch: 6| Step: 12
Training loss: 1.6045385482879164
Validation loss: 2.594718730457009

Epoch: 6| Step: 13
Training loss: 1.342295413847106
Validation loss: 2.620790822926163

Epoch: 241| Step: 0
Training loss: 1.445722284733761
Validation loss: 2.6908026098879585

Epoch: 6| Step: 1
Training loss: 1.3028646744245087
Validation loss: 2.6988489539882456

Epoch: 6| Step: 2
Training loss: 1.7078065137417957
Validation loss: 2.690324246108559

Epoch: 6| Step: 3
Training loss: 1.7433930062364986
Validation loss: 2.680866020687013

Epoch: 6| Step: 4
Training loss: 1.958356884212784
Validation loss: 2.5850902914751157

Epoch: 6| Step: 5
Training loss: 1.5011396846848701
Validation loss: 2.528397820183314

Epoch: 6| Step: 6
Training loss: 1.8012519932774906
Validation loss: 2.5051401353429568

Epoch: 6| Step: 7
Training loss: 1.5670710268410533
Validation loss: 2.49453598055978

Epoch: 6| Step: 8
Training loss: 1.4442071760556396
Validation loss: 2.4931760839513206

Epoch: 6| Step: 9
Training loss: 1.4195007791224776
Validation loss: 2.510871392014545

Epoch: 6| Step: 10
Training loss: 1.5388052478481653
Validation loss: 2.509489988673708

Epoch: 6| Step: 11
Training loss: 1.1271574737551493
Validation loss: 2.597092627457548

Epoch: 6| Step: 12
Training loss: 1.7752579407583524
Validation loss: 2.675804767186433

Epoch: 6| Step: 13
Training loss: 2.3539767118353745
Validation loss: 2.7115262699494798

Epoch: 242| Step: 0
Training loss: 1.5459613606508698
Validation loss: 2.770257496002472

Epoch: 6| Step: 1
Training loss: 2.0263926014972595
Validation loss: 2.7125990814974457

Epoch: 6| Step: 2
Training loss: 1.1592632928793214
Validation loss: 2.674199478988635

Epoch: 6| Step: 3
Training loss: 1.3594221786555334
Validation loss: 2.6036040274597

Epoch: 6| Step: 4
Training loss: 1.6971371583420898
Validation loss: 2.5873601916006055

Epoch: 6| Step: 5
Training loss: 1.5856677798468486
Validation loss: 2.5345931769082837

Epoch: 6| Step: 6
Training loss: 1.4259285628627891
Validation loss: 2.53413962276946

Epoch: 6| Step: 7
Training loss: 1.3559945265819846
Validation loss: 2.504885847560826

Epoch: 6| Step: 8
Training loss: 1.428208800680655
Validation loss: 2.4990243771848166

Epoch: 6| Step: 9
Training loss: 1.361295198893419
Validation loss: 2.4989449233285477

Epoch: 6| Step: 10
Training loss: 1.4073126274861367
Validation loss: 2.5076318895018903

Epoch: 6| Step: 11
Training loss: 2.0717921313806156
Validation loss: 2.5435426413307916

Epoch: 6| Step: 12
Training loss: 1.7300723205179638
Validation loss: 2.5791788999232357

Epoch: 6| Step: 13
Training loss: 1.653308631779101
Validation loss: 2.629743746079818

Epoch: 243| Step: 0
Training loss: 1.779487206070331
Validation loss: 2.6822798508358865

Epoch: 6| Step: 1
Training loss: 1.8710718969928521
Validation loss: 2.6944620586947594

Epoch: 6| Step: 2
Training loss: 1.2020822936019941
Validation loss: 2.661361582446173

Epoch: 6| Step: 3
Training loss: 1.5739514145193092
Validation loss: 2.691766685436678

Epoch: 6| Step: 4
Training loss: 1.6190905592003189
Validation loss: 2.5665537766058937

Epoch: 6| Step: 5
Training loss: 1.6907344479486495
Validation loss: 2.533578009506852

Epoch: 6| Step: 6
Training loss: 1.3877929395445208
Validation loss: 2.4801657137200652

Epoch: 6| Step: 7
Training loss: 1.1460325010194712
Validation loss: 2.4762353903304106

Epoch: 6| Step: 8
Training loss: 1.7173460341382742
Validation loss: 2.479098321047223

Epoch: 6| Step: 9
Training loss: 1.1344882015356188
Validation loss: 2.5046031177278896

Epoch: 6| Step: 10
Training loss: 1.3362793958979413
Validation loss: 2.5283777116691977

Epoch: 6| Step: 11
Training loss: 1.9012670583668236
Validation loss: 2.58589756501724

Epoch: 6| Step: 12
Training loss: 1.864244895638528
Validation loss: 2.663788739033764

Epoch: 6| Step: 13
Training loss: 1.6101987637862991
Validation loss: 2.695562179008139

Epoch: 244| Step: 0
Training loss: 1.874912132747474
Validation loss: 2.6804859831664447

Epoch: 6| Step: 1
Training loss: 1.7450190229936582
Validation loss: 2.6697197774240222

Epoch: 6| Step: 2
Training loss: 1.6012156785537093
Validation loss: 2.647129546672145

Epoch: 6| Step: 3
Training loss: 1.3211551663263261
Validation loss: 2.566254386330085

Epoch: 6| Step: 4
Training loss: 1.3650840054327893
Validation loss: 2.5206934567110153

Epoch: 6| Step: 5
Training loss: 1.0459844872617199
Validation loss: 2.491281110103149

Epoch: 6| Step: 6
Training loss: 1.4527331408387472
Validation loss: 2.482368293937129

Epoch: 6| Step: 7
Training loss: 1.5401328765219415
Validation loss: 2.4687773481177993

Epoch: 6| Step: 8
Training loss: 1.5309150485159864
Validation loss: 2.4825085938760987

Epoch: 6| Step: 9
Training loss: 1.3713786380765811
Validation loss: 2.534150427076916

Epoch: 6| Step: 10
Training loss: 1.388131896460868
Validation loss: 2.5373700211920456

Epoch: 6| Step: 11
Training loss: 1.4530702806240101
Validation loss: 2.589503542704259

Epoch: 6| Step: 12
Training loss: 1.8231535258135896
Validation loss: 2.562260304147035

Epoch: 6| Step: 13
Training loss: 1.9863072997195241
Validation loss: 2.5618748196101553

Epoch: 245| Step: 0
Training loss: 1.5231520947851094
Validation loss: 2.5431666894408247

Epoch: 6| Step: 1
Training loss: 1.1866637849415567
Validation loss: 2.508694880658325

Epoch: 6| Step: 2
Training loss: 1.402738085375101
Validation loss: 2.513022328182445

Epoch: 6| Step: 3
Training loss: 1.3336446617165216
Validation loss: 2.5350661695413406

Epoch: 6| Step: 4
Training loss: 1.7022013828362061
Validation loss: 2.523257121449162

Epoch: 6| Step: 5
Training loss: 2.0501266161266427
Validation loss: 2.50528841468648

Epoch: 6| Step: 6
Training loss: 1.3143880978238693
Validation loss: 2.5210973455095447

Epoch: 6| Step: 7
Training loss: 1.675516031970053
Validation loss: 2.5174169001033273

Epoch: 6| Step: 8
Training loss: 1.4648430175779419
Validation loss: 2.5571308787594784

Epoch: 6| Step: 9
Training loss: 1.2783143441896578
Validation loss: 2.5866592064843887

Epoch: 6| Step: 10
Training loss: 1.0729874646182522
Validation loss: 2.619037576808516

Epoch: 6| Step: 11
Training loss: 1.6330619511950673
Validation loss: 2.6612643113827485

Epoch: 6| Step: 12
Training loss: 2.0267210722614335
Validation loss: 2.6500727129832073

Epoch: 6| Step: 13
Training loss: 1.271770392387706
Validation loss: 2.6628103354693806

Epoch: 246| Step: 0
Training loss: 1.4118731500310375
Validation loss: 2.675416236689583

Epoch: 6| Step: 1
Training loss: 1.4674623404614537
Validation loss: 2.6612220676789073

Epoch: 6| Step: 2
Training loss: 1.4735663963402592
Validation loss: 2.652744854235602

Epoch: 6| Step: 3
Training loss: 1.384582249130818
Validation loss: 2.652101681258379

Epoch: 6| Step: 4
Training loss: 1.2365571061586205
Validation loss: 2.621284998836135

Epoch: 6| Step: 5
Training loss: 1.6875333429503951
Validation loss: 2.586136543126523

Epoch: 6| Step: 6
Training loss: 1.3346739923128141
Validation loss: 2.6113235132806207

Epoch: 6| Step: 7
Training loss: 1.789258521389787
Validation loss: 2.6021370990272765

Epoch: 6| Step: 8
Training loss: 1.4178564274124805
Validation loss: 2.613502915240105

Epoch: 6| Step: 9
Training loss: 1.7379708345114853
Validation loss: 2.6037623387314457

Epoch: 6| Step: 10
Training loss: 1.7160716602772703
Validation loss: 2.5897114171658573

Epoch: 6| Step: 11
Training loss: 1.3449912437522646
Validation loss: 2.5624776599629544

Epoch: 6| Step: 12
Training loss: 1.5586741338283954
Validation loss: 2.552257781170108

Epoch: 6| Step: 13
Training loss: 1.5998424690897914
Validation loss: 2.495563446703689

Epoch: 247| Step: 0
Training loss: 1.478485792456212
Validation loss: 2.5003875585837

Epoch: 6| Step: 1
Training loss: 0.7593659671199114
Validation loss: 2.5392957808968064

Epoch: 6| Step: 2
Training loss: 1.0417411523255125
Validation loss: 2.5504415203842883

Epoch: 6| Step: 3
Training loss: 1.472734686991249
Validation loss: 2.5546801262376215

Epoch: 6| Step: 4
Training loss: 2.0293135582657578
Validation loss: 2.544023407278341

Epoch: 6| Step: 5
Training loss: 1.3947010524603285
Validation loss: 2.5422700024318217

Epoch: 6| Step: 6
Training loss: 1.7602658931413984
Validation loss: 2.5244060884761024

Epoch: 6| Step: 7
Training loss: 1.690126282753467
Validation loss: 2.5747617280583244

Epoch: 6| Step: 8
Training loss: 0.9842385697053546
Validation loss: 2.5877183507878954

Epoch: 6| Step: 9
Training loss: 1.7400488620781411
Validation loss: 2.6430706056425266

Epoch: 6| Step: 10
Training loss: 1.6581092331615126
Validation loss: 2.6827386123904335

Epoch: 6| Step: 11
Training loss: 1.6283303393073199
Validation loss: 2.6686540076527656

Epoch: 6| Step: 12
Training loss: 1.340512700923865
Validation loss: 2.7128238581613164

Epoch: 6| Step: 13
Training loss: 1.233420473749109
Validation loss: 2.650153929515145

Epoch: 248| Step: 0
Training loss: 1.257820934954491
Validation loss: 2.6330082215907593

Epoch: 6| Step: 1
Training loss: 1.48697699320067
Validation loss: 2.6020728647848785

Epoch: 6| Step: 2
Training loss: 1.0206909599411402
Validation loss: 2.553401536432511

Epoch: 6| Step: 3
Training loss: 1.7451114494344668
Validation loss: 2.5016158060838354

Epoch: 6| Step: 4
Training loss: 1.5767215493524862
Validation loss: 2.4951870077725

Epoch: 6| Step: 5
Training loss: 1.6283739715992258
Validation loss: 2.457180299670334

Epoch: 6| Step: 6
Training loss: 1.7159962181280828
Validation loss: 2.5203868220001047

Epoch: 6| Step: 7
Training loss: 1.48338365076567
Validation loss: 2.550478779947458

Epoch: 6| Step: 8
Training loss: 1.324880519014336
Validation loss: 2.570037606670698

Epoch: 6| Step: 9
Training loss: 1.2561117485228859
Validation loss: 2.6185740638194406

Epoch: 6| Step: 10
Training loss: 1.982522114441571
Validation loss: 2.6794267882347342

Epoch: 6| Step: 11
Training loss: 1.267415887122126
Validation loss: 2.7108104912829503

Epoch: 6| Step: 12
Training loss: 0.980448962008127
Validation loss: 2.7076352165477444

Epoch: 6| Step: 13
Training loss: 1.7131933381939068
Validation loss: 2.668951909511202

Epoch: 249| Step: 0
Training loss: 1.4387448766966808
Validation loss: 2.626993912377413

Epoch: 6| Step: 1
Training loss: 1.4492714761771746
Validation loss: 2.5616101216230827

Epoch: 6| Step: 2
Training loss: 1.6114149035581438
Validation loss: 2.5496433758270935

Epoch: 6| Step: 3
Training loss: 1.4886946617110188
Validation loss: 2.549244893176415

Epoch: 6| Step: 4
Training loss: 1.7840426454493346
Validation loss: 2.555757124365819

Epoch: 6| Step: 5
Training loss: 1.7476541600153044
Validation loss: 2.5259264719383863

Epoch: 6| Step: 6
Training loss: 1.1415439196311183
Validation loss: 2.5182573999595985

Epoch: 6| Step: 7
Training loss: 0.8329749330066821
Validation loss: 2.5221208043862373

Epoch: 6| Step: 8
Training loss: 1.4179967451878737
Validation loss: 2.5384031902862256

Epoch: 6| Step: 9
Training loss: 1.1309446523397526
Validation loss: 2.585979991088254

Epoch: 6| Step: 10
Training loss: 1.7052902316973817
Validation loss: 2.602593092132555

Epoch: 6| Step: 11
Training loss: 1.5016071134324591
Validation loss: 2.616878978535651

Epoch: 6| Step: 12
Training loss: 1.4149376284598698
Validation loss: 2.609602263630774

Epoch: 6| Step: 13
Training loss: 1.3426450577833986
Validation loss: 2.601878560292607

Epoch: 250| Step: 0
Training loss: 1.71045151867441
Validation loss: 2.566277903245633

Epoch: 6| Step: 1
Training loss: 1.6631202716609654
Validation loss: 2.5117479308388213

Epoch: 6| Step: 2
Training loss: 1.2073380657470512
Validation loss: 2.5200717716028045

Epoch: 6| Step: 3
Training loss: 1.197797896537265
Validation loss: 2.5543677814939594

Epoch: 6| Step: 4
Training loss: 1.4362979507077902
Validation loss: 2.548711731847464

Epoch: 6| Step: 5
Training loss: 1.5485226881996728
Validation loss: 2.5684891348748553

Epoch: 6| Step: 6
Training loss: 1.6291825679903864
Validation loss: 2.5521638373275515

Epoch: 6| Step: 7
Training loss: 1.6669774560439443
Validation loss: 2.5459757886575307

Epoch: 6| Step: 8
Training loss: 0.8659127635031431
Validation loss: 2.5313772425034413

Epoch: 6| Step: 9
Training loss: 1.319841063713374
Validation loss: 2.5293325709515875

Epoch: 6| Step: 10
Training loss: 1.2551414609114
Validation loss: 2.52384381972598

Epoch: 6| Step: 11
Training loss: 1.3835968551730136
Validation loss: 2.518266913354253

Epoch: 6| Step: 12
Training loss: 1.266725038555417
Validation loss: 2.5434562264133755

Epoch: 6| Step: 13
Training loss: 1.859099295555475
Validation loss: 2.518465289730609

Epoch: 251| Step: 0
Training loss: 1.5540058424359915
Validation loss: 2.5138162122616956

Epoch: 6| Step: 1
Training loss: 1.4694309685098583
Validation loss: 2.489220169530648

Epoch: 6| Step: 2
Training loss: 1.5087522434322236
Validation loss: 2.5121956585576317

Epoch: 6| Step: 3
Training loss: 1.2274533092374766
Validation loss: 2.56027660059019

Epoch: 6| Step: 4
Training loss: 1.4559681468193637
Validation loss: 2.5881148383166646

Epoch: 6| Step: 5
Training loss: 1.5512304928495995
Validation loss: 2.6193875132537365

Epoch: 6| Step: 6
Training loss: 1.452822335830054
Validation loss: 2.616905159215771

Epoch: 6| Step: 7
Training loss: 1.1883717399015576
Validation loss: 2.6382522791646337

Epoch: 6| Step: 8
Training loss: 1.4283687992804284
Validation loss: 2.6952466188915434

Epoch: 6| Step: 9
Training loss: 1.6957729435071154
Validation loss: 2.6826044438893075

Epoch: 6| Step: 10
Training loss: 1.4515185757038742
Validation loss: 2.64240820539201

Epoch: 6| Step: 11
Training loss: 1.269258158728371
Validation loss: 2.5936531130835467

Epoch: 6| Step: 12
Training loss: 1.4045483784422108
Validation loss: 2.537507883210492

Epoch: 6| Step: 13
Training loss: 1.1527671424089145
Validation loss: 2.530622017766212

Epoch: 252| Step: 0
Training loss: 1.6948943435462023
Validation loss: 2.475857465431625

Epoch: 6| Step: 1
Training loss: 1.4015797523618965
Validation loss: 2.466332754428592

Epoch: 6| Step: 2
Training loss: 1.8559125188895613
Validation loss: 2.4893463107061793

Epoch: 6| Step: 3
Training loss: 1.4282775764013291
Validation loss: 2.554232775614134

Epoch: 6| Step: 4
Training loss: 1.6335724152859818
Validation loss: 2.618857575092335

Epoch: 6| Step: 5
Training loss: 1.8048196719431646
Validation loss: 2.647385822350076

Epoch: 6| Step: 6
Training loss: 1.7710934915361523
Validation loss: 2.6980265521626903

Epoch: 6| Step: 7
Training loss: 1.1932276077071615
Validation loss: 2.6922016250580425

Epoch: 6| Step: 8
Training loss: 1.1288578326656304
Validation loss: 2.635293756261762

Epoch: 6| Step: 9
Training loss: 1.2405917876672081
Validation loss: 2.59424771414881

Epoch: 6| Step: 10
Training loss: 0.9570321219304063
Validation loss: 2.5556144887758157

Epoch: 6| Step: 11
Training loss: 1.0810968103102236
Validation loss: 2.532879832235285

Epoch: 6| Step: 12
Training loss: 0.9842939797619312
Validation loss: 2.509853005822303

Epoch: 6| Step: 13
Training loss: 1.374226525974882
Validation loss: 2.554463028238247

Epoch: 253| Step: 0
Training loss: 1.334823366902817
Validation loss: 2.545195937454051

Epoch: 6| Step: 1
Training loss: 1.540136359605801
Validation loss: 2.58651295944467

Epoch: 6| Step: 2
Training loss: 1.6397907134007965
Validation loss: 2.606097650775764

Epoch: 6| Step: 3
Training loss: 1.4114180649459558
Validation loss: 2.6140852861001154

Epoch: 6| Step: 4
Training loss: 1.4629660002537856
Validation loss: 2.6443293660985203

Epoch: 6| Step: 5
Training loss: 1.2561793179341643
Validation loss: 2.64619051229571

Epoch: 6| Step: 6
Training loss: 1.3328756301793965
Validation loss: 2.7114303125329746

Epoch: 6| Step: 7
Training loss: 1.3410887869643398
Validation loss: 2.632094231616601

Epoch: 6| Step: 8
Training loss: 1.3456018240882266
Validation loss: 2.5761617604207574

Epoch: 6| Step: 9
Training loss: 1.5180073527533737
Validation loss: 2.54563058326717

Epoch: 6| Step: 10
Training loss: 0.9815433889700685
Validation loss: 2.510706513143111

Epoch: 6| Step: 11
Training loss: 1.509882874272573
Validation loss: 2.508498206862704

Epoch: 6| Step: 12
Training loss: 1.3328908344964228
Validation loss: 2.5016270224280017

Epoch: 6| Step: 13
Training loss: 1.5979229021344463
Validation loss: 2.55786893964763

Epoch: 254| Step: 0
Training loss: 1.5176262768110944
Validation loss: 2.546918731622016

Epoch: 6| Step: 1
Training loss: 0.992180831766624
Validation loss: 2.588715568962315

Epoch: 6| Step: 2
Training loss: 1.4521653482854444
Validation loss: 2.6156215870441293

Epoch: 6| Step: 3
Training loss: 1.009376436120302
Validation loss: 2.577299229045825

Epoch: 6| Step: 4
Training loss: 1.4758080871306687
Validation loss: 2.5736748864053385

Epoch: 6| Step: 5
Training loss: 1.3333011961083914
Validation loss: 2.5492013704113656

Epoch: 6| Step: 6
Training loss: 1.3200962408700745
Validation loss: 2.5315119624124325

Epoch: 6| Step: 7
Training loss: 1.4045948884877772
Validation loss: 2.5488463401811483

Epoch: 6| Step: 8
Training loss: 1.5635648532124966
Validation loss: 2.5565585335352403

Epoch: 6| Step: 9
Training loss: 1.4735539379208473
Validation loss: 2.6067896716649774

Epoch: 6| Step: 10
Training loss: 1.1752849557981415
Validation loss: 2.6208651724056393

Epoch: 6| Step: 11
Training loss: 1.4169787268916139
Validation loss: 2.6356403700602096

Epoch: 6| Step: 12
Training loss: 1.9476784409147474
Validation loss: 2.647552422685583

Epoch: 6| Step: 13
Training loss: 0.5750519811934603
Validation loss: 2.706190628188263

Epoch: 255| Step: 0
Training loss: 1.430817287949783
Validation loss: 2.6975341771535906

Epoch: 6| Step: 1
Training loss: 1.4594205436706598
Validation loss: 2.6441260449224915

Epoch: 6| Step: 2
Training loss: 1.651668473726138
Validation loss: 2.6192504040542177

Epoch: 6| Step: 3
Training loss: 1.4291289025183935
Validation loss: 2.5711638968666493

Epoch: 6| Step: 4
Training loss: 0.9967455059358749
Validation loss: 2.488284301189285

Epoch: 6| Step: 5
Training loss: 1.4356916912499769
Validation loss: 2.4725157632326

Epoch: 6| Step: 6
Training loss: 1.8898852453765913
Validation loss: 2.4715770175463856

Epoch: 6| Step: 7
Training loss: 1.1230912440284315
Validation loss: 2.5071295341510895

Epoch: 6| Step: 8
Training loss: 1.5185823983856277
Validation loss: 2.5480681432392975

Epoch: 6| Step: 9
Training loss: 1.4219418185117645
Validation loss: 2.606737728403897

Epoch: 6| Step: 10
Training loss: 1.1617558302153284
Validation loss: 2.5927779971804656

Epoch: 6| Step: 11
Training loss: 1.239571173258316
Validation loss: 2.627880329780628

Epoch: 6| Step: 12
Training loss: 1.2888657853277434
Validation loss: 2.589748075113087

Epoch: 6| Step: 13
Training loss: 1.0208010311595348
Validation loss: 2.5635174012884017

Epoch: 256| Step: 0
Training loss: 1.3909928338985842
Validation loss: 2.4927102362777345

Epoch: 6| Step: 1
Training loss: 1.7988525786586027
Validation loss: 2.466274145130695

Epoch: 6| Step: 2
Training loss: 1.1471512526748018
Validation loss: 2.4810467312215274

Epoch: 6| Step: 3
Training loss: 1.094899363835828
Validation loss: 2.4940378075691663

Epoch: 6| Step: 4
Training loss: 1.5945399701386067
Validation loss: 2.5037735833537775

Epoch: 6| Step: 5
Training loss: 1.371905746636783
Validation loss: 2.5157715967380785

Epoch: 6| Step: 6
Training loss: 0.9063013654161286
Validation loss: 2.5717904894931793

Epoch: 6| Step: 7
Training loss: 1.4901552591783547
Validation loss: 2.636416458187124

Epoch: 6| Step: 8
Training loss: 1.1403710069436979
Validation loss: 2.705293518567713

Epoch: 6| Step: 9
Training loss: 1.625254097659196
Validation loss: 2.731611894369018

Epoch: 6| Step: 10
Training loss: 1.1706719899357034
Validation loss: 2.7089222352166784

Epoch: 6| Step: 11
Training loss: 1.4123258095070368
Validation loss: 2.667523408618239

Epoch: 6| Step: 12
Training loss: 1.666815973587705
Validation loss: 2.64085244392607

Epoch: 6| Step: 13
Training loss: 1.0993152177527554
Validation loss: 2.6064375855046977

Epoch: 257| Step: 0
Training loss: 1.3491054096338824
Validation loss: 2.6058069329339952

Epoch: 6| Step: 1
Training loss: 1.1064799506210692
Validation loss: 2.6486822255953166

Epoch: 6| Step: 2
Training loss: 1.473746222700693
Validation loss: 2.6064817164115355

Epoch: 6| Step: 3
Training loss: 0.9186781394518473
Validation loss: 2.619259732683259

Epoch: 6| Step: 4
Training loss: 1.503301563321962
Validation loss: 2.5981824807094682

Epoch: 6| Step: 5
Training loss: 1.5846936087997427
Validation loss: 2.5981547393395705

Epoch: 6| Step: 6
Training loss: 1.289118817573044
Validation loss: 2.650250735835717

Epoch: 6| Step: 7
Training loss: 1.081423151341361
Validation loss: 2.733034275521252

Epoch: 6| Step: 8
Training loss: 1.033332109963298
Validation loss: 2.7151047726382656

Epoch: 6| Step: 9
Training loss: 1.2235623253372425
Validation loss: 2.703780912730107

Epoch: 6| Step: 10
Training loss: 1.5581457120312159
Validation loss: 2.552255422697136

Epoch: 6| Step: 11
Training loss: 1.6057446467812073
Validation loss: 2.472236812213288

Epoch: 6| Step: 12
Training loss: 1.516575308902272
Validation loss: 2.427595887629611

Epoch: 6| Step: 13
Training loss: 1.5997494739854117
Validation loss: 2.3921173443568677

Epoch: 258| Step: 0
Training loss: 1.6673700120123331
Validation loss: 2.410102686616979

Epoch: 6| Step: 1
Training loss: 1.289065505515554
Validation loss: 2.4075885667162225

Epoch: 6| Step: 2
Training loss: 1.5105196512125285
Validation loss: 2.4988433274547757

Epoch: 6| Step: 3
Training loss: 1.5558679594338953
Validation loss: 2.557027232980475

Epoch: 6| Step: 4
Training loss: 1.2218647793003337
Validation loss: 2.6347458252429314

Epoch: 6| Step: 5
Training loss: 1.3267989775719555
Validation loss: 2.6506382304237865

Epoch: 6| Step: 6
Training loss: 1.2077883719221687
Validation loss: 2.6220245637819444

Epoch: 6| Step: 7
Training loss: 1.4652175629804793
Validation loss: 2.557960346809123

Epoch: 6| Step: 8
Training loss: 1.6089826679706896
Validation loss: 2.5381696420107747

Epoch: 6| Step: 9
Training loss: 0.5989294017493854
Validation loss: 2.5617508091933727

Epoch: 6| Step: 10
Training loss: 1.0992571468194687
Validation loss: 2.609261391219705

Epoch: 6| Step: 11
Training loss: 1.3077221145296718
Validation loss: 2.6288013738112763

Epoch: 6| Step: 12
Training loss: 1.5250445375036195
Validation loss: 2.706346839381482

Epoch: 6| Step: 13
Training loss: 1.4908535572184964
Validation loss: 2.7365057518559017

Epoch: 259| Step: 0
Training loss: 1.460560959214738
Validation loss: 2.7709611901289573

Epoch: 6| Step: 1
Training loss: 1.1700496444603148
Validation loss: 2.7327081431137166

Epoch: 6| Step: 2
Training loss: 1.3083500877247096
Validation loss: 2.71429005410178

Epoch: 6| Step: 3
Training loss: 0.9883185820633924
Validation loss: 2.662691084691772

Epoch: 6| Step: 4
Training loss: 1.3927231294487479
Validation loss: 2.623889530974991

Epoch: 6| Step: 5
Training loss: 1.0330005007185927
Validation loss: 2.5434910301990956

Epoch: 6| Step: 6
Training loss: 1.1540631414226254
Validation loss: 2.486047879223058

Epoch: 6| Step: 7
Training loss: 1.523241861937393
Validation loss: 2.507686110513752

Epoch: 6| Step: 8
Training loss: 1.337345920137128
Validation loss: 2.475277372487298

Epoch: 6| Step: 9
Training loss: 1.3811687031292017
Validation loss: 2.489620803823565

Epoch: 6| Step: 10
Training loss: 1.4490230459008855
Validation loss: 2.4982764455537256

Epoch: 6| Step: 11
Training loss: 1.194987184224379
Validation loss: 2.497225106375396

Epoch: 6| Step: 12
Training loss: 1.5674854090496722
Validation loss: 2.528158347931799

Epoch: 6| Step: 13
Training loss: 1.8372873741186557
Validation loss: 2.5684415294668406

Epoch: 260| Step: 0
Training loss: 1.5614423605534757
Validation loss: 2.554770690179629

Epoch: 6| Step: 1
Training loss: 0.9430994027053451
Validation loss: 2.5446153878229136

Epoch: 6| Step: 2
Training loss: 0.7860050452994988
Validation loss: 2.51496650822732

Epoch: 6| Step: 3
Training loss: 1.3223955775177167
Validation loss: 2.4956501629779937

Epoch: 6| Step: 4
Training loss: 1.0097825069233732
Validation loss: 2.52925348536443

Epoch: 6| Step: 5
Training loss: 1.1767861770440429
Validation loss: 2.5276096281042744

Epoch: 6| Step: 6
Training loss: 1.5415406390391018
Validation loss: 2.540362253512475

Epoch: 6| Step: 7
Training loss: 1.4066576896549774
Validation loss: 2.563797199469581

Epoch: 6| Step: 8
Training loss: 1.435367827375869
Validation loss: 2.6232710172411933

Epoch: 6| Step: 9
Training loss: 1.3813797160554748
Validation loss: 2.672417417297229

Epoch: 6| Step: 10
Training loss: 1.3214190659494112
Validation loss: 2.7219925062829224

Epoch: 6| Step: 11
Training loss: 1.245286734014098
Validation loss: 2.70058721072612

Epoch: 6| Step: 12
Training loss: 1.4257421200752058
Validation loss: 2.6290144706163097

Epoch: 6| Step: 13
Training loss: 1.5699642421513653
Validation loss: 2.5689201255330643

Epoch: 261| Step: 0
Training loss: 1.2243449094384153
Validation loss: 2.536797702538584

Epoch: 6| Step: 1
Training loss: 1.5128418055428077
Validation loss: 2.48190203420612

Epoch: 6| Step: 2
Training loss: 1.0820459027451577
Validation loss: 2.4788535308038324

Epoch: 6| Step: 3
Training loss: 0.9363040289167482
Validation loss: 2.4923914338816195

Epoch: 6| Step: 4
Training loss: 1.2179775235274226
Validation loss: 2.502259229350138

Epoch: 6| Step: 5
Training loss: 1.2016891234191445
Validation loss: 2.5434264699580535

Epoch: 6| Step: 6
Training loss: 1.4464534895296277
Validation loss: 2.5351346124962886

Epoch: 6| Step: 7
Training loss: 1.2160500673194843
Validation loss: 2.557713077005605

Epoch: 6| Step: 8
Training loss: 1.248061679997037
Validation loss: 2.6004624619649865

Epoch: 6| Step: 9
Training loss: 1.3679841690458077
Validation loss: 2.6294119509004736

Epoch: 6| Step: 10
Training loss: 1.110513559566949
Validation loss: 2.6333154715382276

Epoch: 6| Step: 11
Training loss: 1.923363334161737
Validation loss: 2.6449709504148555

Epoch: 6| Step: 12
Training loss: 0.9883909503831242
Validation loss: 2.6113580560634357

Epoch: 6| Step: 13
Training loss: 1.3590670708223986
Validation loss: 2.611086580700463

Epoch: 262| Step: 0
Training loss: 0.8785937961861254
Validation loss: 2.569514408801607

Epoch: 6| Step: 1
Training loss: 1.82479620540313
Validation loss: 2.515221645654899

Epoch: 6| Step: 2
Training loss: 1.6344778520887047
Validation loss: 2.534362507924346

Epoch: 6| Step: 3
Training loss: 1.0368838882295273
Validation loss: 2.5330150744220847

Epoch: 6| Step: 4
Training loss: 0.9529283039186961
Validation loss: 2.5210454355447363

Epoch: 6| Step: 5
Training loss: 0.9874198687913543
Validation loss: 2.5265376076186876

Epoch: 6| Step: 6
Training loss: 1.419734475468903
Validation loss: 2.550371591395391

Epoch: 6| Step: 7
Training loss: 1.4440138472529789
Validation loss: 2.535939613194669

Epoch: 6| Step: 8
Training loss: 1.0538073222541793
Validation loss: 2.5190338185548256

Epoch: 6| Step: 9
Training loss: 0.8797981992083532
Validation loss: 2.533193373200601

Epoch: 6| Step: 10
Training loss: 1.3146232506222686
Validation loss: 2.532979747154871

Epoch: 6| Step: 11
Training loss: 1.1079676660681164
Validation loss: 2.525892209163787

Epoch: 6| Step: 12
Training loss: 1.6621450920167238
Validation loss: 2.5512137941792914

Epoch: 6| Step: 13
Training loss: 0.9526325266798141
Validation loss: 2.5706857893388313

Epoch: 263| Step: 0
Training loss: 1.2356453647970989
Validation loss: 2.6075479498243515

Epoch: 6| Step: 1
Training loss: 1.2596951250561423
Validation loss: 2.643188304252882

Epoch: 6| Step: 2
Training loss: 1.2523897216126558
Validation loss: 2.6844535076490947

Epoch: 6| Step: 3
Training loss: 1.0107580506190263
Validation loss: 2.6739140667105037

Epoch: 6| Step: 4
Training loss: 1.3891021448234293
Validation loss: 2.6136382778909257

Epoch: 6| Step: 5
Training loss: 1.3718589103989132
Validation loss: 2.6087005649481454

Epoch: 6| Step: 6
Training loss: 1.5992401404876697
Validation loss: 2.5507352413045887

Epoch: 6| Step: 7
Training loss: 1.3694808471944833
Validation loss: 2.533329807947207

Epoch: 6| Step: 8
Training loss: 0.7743624156455847
Validation loss: 2.5024860173172487

Epoch: 6| Step: 9
Training loss: 1.1440299957751174
Validation loss: 2.5180852313373214

Epoch: 6| Step: 10
Training loss: 0.9717553497453763
Validation loss: 2.51223836010053

Epoch: 6| Step: 11
Training loss: 1.3308486387168525
Validation loss: 2.508038080518829

Epoch: 6| Step: 12
Training loss: 1.2609898023382078
Validation loss: 2.526562272469194

Epoch: 6| Step: 13
Training loss: 1.227629810702538
Validation loss: 2.520463612460736

Epoch: 264| Step: 0
Training loss: 1.287231809960608
Validation loss: 2.5204664644932904

Epoch: 6| Step: 1
Training loss: 1.454515427718395
Validation loss: 2.5450275030813145

Epoch: 6| Step: 2
Training loss: 0.8959095094510988
Validation loss: 2.5829430251214966

Epoch: 6| Step: 3
Training loss: 1.2505111602870898
Validation loss: 2.585941373309568

Epoch: 6| Step: 4
Training loss: 1.0000642517429246
Validation loss: 2.575992409954992

Epoch: 6| Step: 5
Training loss: 1.2012358857753693
Validation loss: 2.513304613274682

Epoch: 6| Step: 6
Training loss: 1.5876113251827833
Validation loss: 2.545160542553012

Epoch: 6| Step: 7
Training loss: 1.1150646180728843
Validation loss: 2.5494339236799664

Epoch: 6| Step: 8
Training loss: 1.208582008467529
Validation loss: 2.563841951845899

Epoch: 6| Step: 9
Training loss: 0.8993123977643047
Validation loss: 2.563917615787615

Epoch: 6| Step: 10
Training loss: 0.7627162954885106
Validation loss: 2.584305974777043

Epoch: 6| Step: 11
Training loss: 1.558665491427285
Validation loss: 2.5892566366890204

Epoch: 6| Step: 12
Training loss: 1.4301948689352308
Validation loss: 2.5290287307881454

Epoch: 6| Step: 13
Training loss: 0.8937486781930819
Validation loss: 2.535630877609773

Epoch: 265| Step: 0
Training loss: 1.1663865820420347
Validation loss: 2.5111314934226607

Epoch: 6| Step: 1
Training loss: 1.3033904521081423
Validation loss: 2.5801962647920096

Epoch: 6| Step: 2
Training loss: 1.1360640590430584
Validation loss: 2.5671891069362576

Epoch: 6| Step: 3
Training loss: 1.2405223121712197
Validation loss: 2.5684443481867136

Epoch: 6| Step: 4
Training loss: 0.7103902366248647
Validation loss: 2.581618714187893

Epoch: 6| Step: 5
Training loss: 1.3583292830393185
Validation loss: 2.5850553079392293

Epoch: 6| Step: 6
Training loss: 1.2236153737596636
Validation loss: 2.606949037401961

Epoch: 6| Step: 7
Training loss: 0.9664931619799921
Validation loss: 2.6125294074273624

Epoch: 6| Step: 8
Training loss: 1.366743527941524
Validation loss: 2.6314887553693262

Epoch: 6| Step: 9
Training loss: 1.380470965847273
Validation loss: 2.652231272310995

Epoch: 6| Step: 10
Training loss: 1.3443326352306255
Validation loss: 2.6516225126803588

Epoch: 6| Step: 11
Training loss: 1.1460118010281146
Validation loss: 2.6190823910395515

Epoch: 6| Step: 12
Training loss: 0.9101990456404488
Validation loss: 2.5661682267259684

Epoch: 6| Step: 13
Training loss: 1.2389939239882533
Validation loss: 2.5289158447194717

Epoch: 266| Step: 0
Training loss: 0.9305671249132267
Validation loss: 2.500311290680185

Epoch: 6| Step: 1
Training loss: 1.091523875053593
Validation loss: 2.489623156758628

Epoch: 6| Step: 2
Training loss: 1.2853498689842922
Validation loss: 2.4774208619304785

Epoch: 6| Step: 3
Training loss: 1.465778673001179
Validation loss: 2.514151937100131

Epoch: 6| Step: 4
Training loss: 1.3325108981805125
Validation loss: 2.575224275794881

Epoch: 6| Step: 5
Training loss: 1.0656777153512293
Validation loss: 2.60864241339171

Epoch: 6| Step: 6
Training loss: 1.0056095146281405
Validation loss: 2.6738902653988537

Epoch: 6| Step: 7
Training loss: 1.44665860562049
Validation loss: 2.6637166694061873

Epoch: 6| Step: 8
Training loss: 0.8306700626661564
Validation loss: 2.6341267005385784

Epoch: 6| Step: 9
Training loss: 1.512125911637005
Validation loss: 2.5866938303675697

Epoch: 6| Step: 10
Training loss: 0.9858544751499055
Validation loss: 2.523641211520195

Epoch: 6| Step: 11
Training loss: 1.1638273475256684
Validation loss: 2.494573220106293

Epoch: 6| Step: 12
Training loss: 1.0797682691911157
Validation loss: 2.4822893459173634

Epoch: 6| Step: 13
Training loss: 1.3937421430699883
Validation loss: 2.521260676768015

Epoch: 267| Step: 0
Training loss: 1.3772725052780443
Validation loss: 2.538711408979178

Epoch: 6| Step: 1
Training loss: 1.2491074236325417
Validation loss: 2.5524891259286395

Epoch: 6| Step: 2
Training loss: 0.9164399748155252
Validation loss: 2.564080792964503

Epoch: 6| Step: 3
Training loss: 0.9547150278571082
Validation loss: 2.6223983587854542

Epoch: 6| Step: 4
Training loss: 0.6134809181134055
Validation loss: 2.620084738148146

Epoch: 6| Step: 5
Training loss: 1.1292840662005186
Validation loss: 2.7186838136546125

Epoch: 6| Step: 6
Training loss: 1.3791767751932167
Validation loss: 2.721855042508987

Epoch: 6| Step: 7
Training loss: 1.4449749526654663
Validation loss: 2.7281853881943805

Epoch: 6| Step: 8
Training loss: 1.4359502316513415
Validation loss: 2.634266447455497

Epoch: 6| Step: 9
Training loss: 1.0075979078252195
Validation loss: 2.5177841342172567

Epoch: 6| Step: 10
Training loss: 1.3525961743357242
Validation loss: 2.445787481375825

Epoch: 6| Step: 11
Training loss: 1.0877699725159267
Validation loss: 2.43469444092624

Epoch: 6| Step: 12
Training loss: 1.3457991035682935
Validation loss: 2.451131464859555

Epoch: 6| Step: 13
Training loss: 1.3105794842865783
Validation loss: 2.4224525464300166

Epoch: 268| Step: 0
Training loss: 1.1101754215740751
Validation loss: 2.4707763995640444

Epoch: 6| Step: 1
Training loss: 1.053685029765781
Validation loss: 2.515477145499621

Epoch: 6| Step: 2
Training loss: 1.602803861044757
Validation loss: 2.5904353559011364

Epoch: 6| Step: 3
Training loss: 1.1652580624563151
Validation loss: 2.668567945535812

Epoch: 6| Step: 4
Training loss: 1.1027231257071284
Validation loss: 2.7648528629304594

Epoch: 6| Step: 5
Training loss: 1.2430831271523004
Validation loss: 2.809816501777176

Epoch: 6| Step: 6
Training loss: 1.2235993961481135
Validation loss: 2.88604966935177

Epoch: 6| Step: 7
Training loss: 1.0729750768570234
Validation loss: 2.847484461962105

Epoch: 6| Step: 8
Training loss: 1.3804057238039804
Validation loss: 2.7581288582908416

Epoch: 6| Step: 9
Training loss: 1.2303994779918044
Validation loss: 2.6062541865730315

Epoch: 6| Step: 10
Training loss: 1.0388438059181382
Validation loss: 2.499883621850033

Epoch: 6| Step: 11
Training loss: 1.1801908316104366
Validation loss: 2.4436225575265627

Epoch: 6| Step: 12
Training loss: 1.4865329516082182
Validation loss: 2.4335228683780112

Epoch: 6| Step: 13
Training loss: 1.3798854042239461
Validation loss: 2.4090458342646626

Epoch: 269| Step: 0
Training loss: 1.487876696933284
Validation loss: 2.4493941149935083

Epoch: 6| Step: 1
Training loss: 1.3974642643599027
Validation loss: 2.460533570167451

Epoch: 6| Step: 2
Training loss: 1.1023605918543948
Validation loss: 2.4975958267205005

Epoch: 6| Step: 3
Training loss: 1.1200475829098413
Validation loss: 2.562383651593155

Epoch: 6| Step: 4
Training loss: 1.5810368933333132
Validation loss: 2.576966453910896

Epoch: 6| Step: 5
Training loss: 0.6739093234025059
Validation loss: 2.5956478981071247

Epoch: 6| Step: 6
Training loss: 0.9070358157967084
Validation loss: 2.5893866592015673

Epoch: 6| Step: 7
Training loss: 1.1899003314104908
Validation loss: 2.6182461767810246

Epoch: 6| Step: 8
Training loss: 1.5153372579932978
Validation loss: 2.603908608396944

Epoch: 6| Step: 9
Training loss: 0.7976127650020949
Validation loss: 2.598699170888457

Epoch: 6| Step: 10
Training loss: 0.8990773120411788
Validation loss: 2.5896530728309775

Epoch: 6| Step: 11
Training loss: 0.7956398011274465
Validation loss: 2.577519009177912

Epoch: 6| Step: 12
Training loss: 1.172416002644339
Validation loss: 2.543638743938394

Epoch: 6| Step: 13
Training loss: 0.9502196823398067
Validation loss: 2.5780032887695383

Epoch: 270| Step: 0
Training loss: 1.0898026215917818
Validation loss: 2.6009829838142795

Epoch: 6| Step: 1
Training loss: 1.0224772600476029
Validation loss: 2.6291724063291966

Epoch: 6| Step: 2
Training loss: 1.303094771146643
Validation loss: 2.624854564788566

Epoch: 6| Step: 3
Training loss: 1.509771310023255
Validation loss: 2.616052103644447

Epoch: 6| Step: 4
Training loss: 1.0522872173301108
Validation loss: 2.589905563455994

Epoch: 6| Step: 5
Training loss: 0.9247526095751315
Validation loss: 2.5805316986628775

Epoch: 6| Step: 6
Training loss: 1.0299840728676453
Validation loss: 2.5886963568041783

Epoch: 6| Step: 7
Training loss: 0.9697380871966704
Validation loss: 2.5675235981278175

Epoch: 6| Step: 8
Training loss: 0.7570708273353517
Validation loss: 2.547091330626401

Epoch: 6| Step: 9
Training loss: 0.8115070217414029
Validation loss: 2.5723718683584558

Epoch: 6| Step: 10
Training loss: 1.2486787488922764
Validation loss: 2.5681460198319734

Epoch: 6| Step: 11
Training loss: 1.2274902139805803
Validation loss: 2.5644549404239987

Epoch: 6| Step: 12
Training loss: 1.294191824985152
Validation loss: 2.5838363950224426

Epoch: 6| Step: 13
Training loss: 1.4478476894424117
Validation loss: 2.608691475689737

Epoch: 271| Step: 0
Training loss: 1.2460257293408195
Validation loss: 2.6280170999461583

Epoch: 6| Step: 1
Training loss: 1.1829789078638746
Validation loss: 2.5972808653012502

Epoch: 6| Step: 2
Training loss: 1.1596972652549435
Validation loss: 2.5863711071003337

Epoch: 6| Step: 3
Training loss: 0.8649060593017782
Validation loss: 2.5713354357295755

Epoch: 6| Step: 4
Training loss: 0.7602666463011092
Validation loss: 2.5472113978960196

Epoch: 6| Step: 5
Training loss: 0.9666595053133479
Validation loss: 2.544780316735386

Epoch: 6| Step: 6
Training loss: 1.0822389589214845
Validation loss: 2.539106277328225

Epoch: 6| Step: 7
Training loss: 1.4281406059497603
Validation loss: 2.5684957333868916

Epoch: 6| Step: 8
Training loss: 0.8120482362574779
Validation loss: 2.5820912086773538

Epoch: 6| Step: 9
Training loss: 0.8173969591163054
Validation loss: 2.6290016641540994

Epoch: 6| Step: 10
Training loss: 1.606877509418963
Validation loss: 2.6280918249127025

Epoch: 6| Step: 11
Training loss: 1.0142257441478022
Validation loss: 2.642952040438515

Epoch: 6| Step: 12
Training loss: 1.1466208901435124
Validation loss: 2.688708423589333

Epoch: 6| Step: 13
Training loss: 1.0191553233948398
Validation loss: 2.671655690642973

Epoch: 272| Step: 0
Training loss: 1.0490684873190192
Validation loss: 2.664655233180235

Epoch: 6| Step: 1
Training loss: 0.9744350300343405
Validation loss: 2.6179388788097366

Epoch: 6| Step: 2
Training loss: 1.023624723359179
Validation loss: 2.5979277679905883

Epoch: 6| Step: 3
Training loss: 1.015991262270683
Validation loss: 2.5420369233780407

Epoch: 6| Step: 4
Training loss: 0.9924261151637388
Validation loss: 2.5018736709075124

Epoch: 6| Step: 5
Training loss: 1.2669678146019752
Validation loss: 2.436044956541812

Epoch: 6| Step: 6
Training loss: 1.2230905364828721
Validation loss: 2.4405834498500463

Epoch: 6| Step: 7
Training loss: 1.3344950780509777
Validation loss: 2.424791412550435

Epoch: 6| Step: 8
Training loss: 1.4120599044217412
Validation loss: 2.431555343498408

Epoch: 6| Step: 9
Training loss: 0.8757042094637516
Validation loss: 2.4636068253332666

Epoch: 6| Step: 10
Training loss: 0.9054586309570265
Validation loss: 2.515354217078211

Epoch: 6| Step: 11
Training loss: 1.2922036480154109
Validation loss: 2.5972600809503636

Epoch: 6| Step: 12
Training loss: 1.0108506886207569
Validation loss: 2.6421357539543417

Epoch: 6| Step: 13
Training loss: 1.0232514073902539
Validation loss: 2.7199542196071773

Epoch: 273| Step: 0
Training loss: 0.7731435197787687
Validation loss: 2.6838881166422883

Epoch: 6| Step: 1
Training loss: 1.1937801537025758
Validation loss: 2.6395526389813604

Epoch: 6| Step: 2
Training loss: 1.7042139054569936
Validation loss: 2.6214113917316104

Epoch: 6| Step: 3
Training loss: 1.1378436208825846
Validation loss: 2.5641668697407236

Epoch: 6| Step: 4
Training loss: 1.243564586141669
Validation loss: 2.570210769734182

Epoch: 6| Step: 5
Training loss: 1.0459790737436652
Validation loss: 2.5601390253711918

Epoch: 6| Step: 6
Training loss: 1.0501383122673236
Validation loss: 2.556357787109994

Epoch: 6| Step: 7
Training loss: 0.6185932567774654
Validation loss: 2.5706468879487887

Epoch: 6| Step: 8
Training loss: 0.7951446520963439
Validation loss: 2.5957915584705664

Epoch: 6| Step: 9
Training loss: 0.9403935917693976
Validation loss: 2.59374843438728

Epoch: 6| Step: 10
Training loss: 1.105617014509467
Validation loss: 2.6070491659430948

Epoch: 6| Step: 11
Training loss: 0.8278260321139312
Validation loss: 2.600073259574163

Epoch: 6| Step: 12
Training loss: 1.0811159965959727
Validation loss: 2.5869942245141457

Epoch: 6| Step: 13
Training loss: 1.3618770680230219
Validation loss: 2.599446094678052

Epoch: 274| Step: 0
Training loss: 0.6807922943038875
Validation loss: 2.5937637148851698

Epoch: 6| Step: 1
Training loss: 0.8402775553413145
Validation loss: 2.6145776456810164

Epoch: 6| Step: 2
Training loss: 1.1019737071346691
Validation loss: 2.599670527283561

Epoch: 6| Step: 3
Training loss: 1.2022932075451394
Validation loss: 2.594207243998913

Epoch: 6| Step: 4
Training loss: 0.8580155457153139
Validation loss: 2.593179783643784

Epoch: 6| Step: 5
Training loss: 1.4005419703891537
Validation loss: 2.5815137382051625

Epoch: 6| Step: 6
Training loss: 1.3154998284821524
Validation loss: 2.5365033581699876

Epoch: 6| Step: 7
Training loss: 0.7992256499856795
Validation loss: 2.593012832871806

Epoch: 6| Step: 8
Training loss: 1.015024917559767
Validation loss: 2.558360257704675

Epoch: 6| Step: 9
Training loss: 0.7544545763927513
Validation loss: 2.54223554798636

Epoch: 6| Step: 10
Training loss: 0.7015555349569217
Validation loss: 2.5342534177358336

Epoch: 6| Step: 11
Training loss: 1.127899195931878
Validation loss: 2.5304647787717465

Epoch: 6| Step: 12
Training loss: 1.1137589885207675
Validation loss: 2.5186768357736145

Epoch: 6| Step: 13
Training loss: 1.6296130506237312
Validation loss: 2.509843436020865

Epoch: 275| Step: 0
Training loss: 0.9943178689634153
Validation loss: 2.5238962673632552

Epoch: 6| Step: 1
Training loss: 0.7400270035688207
Validation loss: 2.5142424711777163

Epoch: 6| Step: 2
Training loss: 1.294987971717618
Validation loss: 2.520122608568856

Epoch: 6| Step: 3
Training loss: 1.031367844292905
Validation loss: 2.51487127635476

Epoch: 6| Step: 4
Training loss: 1.442712372958958
Validation loss: 2.5531115327642238

Epoch: 6| Step: 5
Training loss: 1.182565626537149
Validation loss: 2.5866354417544293

Epoch: 6| Step: 6
Training loss: 0.7882441819155019
Validation loss: 2.58722141782036

Epoch: 6| Step: 7
Training loss: 0.9118053901777451
Validation loss: 2.6226694266759365

Epoch: 6| Step: 8
Training loss: 0.8984461244915533
Validation loss: 2.646503645212956

Epoch: 6| Step: 9
Training loss: 0.9638757830915806
Validation loss: 2.6280734190783783

Epoch: 6| Step: 10
Training loss: 1.1276894317645927
Validation loss: 2.599396657177404

Epoch: 6| Step: 11
Training loss: 1.0917253010172314
Validation loss: 2.577004321793753

Epoch: 6| Step: 12
Training loss: 0.9254150310114306
Validation loss: 2.583086243786389

Epoch: 6| Step: 13
Training loss: 0.7251507569466455
Validation loss: 2.576369918302162

Epoch: 276| Step: 0
Training loss: 0.8866274614438425
Validation loss: 2.569772541376627

Epoch: 6| Step: 1
Training loss: 1.0309818959686263
Validation loss: 2.5645878257707784

Epoch: 6| Step: 2
Training loss: 0.949025075486727
Validation loss: 2.5729662448815507

Epoch: 6| Step: 3
Training loss: 1.2647190383586935
Validation loss: 2.585134187824121

Epoch: 6| Step: 4
Training loss: 1.0365485275104265
Validation loss: 2.599726863899075

Epoch: 6| Step: 5
Training loss: 0.9615184609460451
Validation loss: 2.5672575532823068

Epoch: 6| Step: 6
Training loss: 1.1346585720601312
Validation loss: 2.58503160681058

Epoch: 6| Step: 7
Training loss: 1.1712027083613135
Validation loss: 2.5590463515569386

Epoch: 6| Step: 8
Training loss: 0.7261532276831216
Validation loss: 2.5146130285767803

Epoch: 6| Step: 9
Training loss: 0.6871515171124489
Validation loss: 2.552816252014364

Epoch: 6| Step: 10
Training loss: 1.2008957956514148
Validation loss: 2.520849188871122

Epoch: 6| Step: 11
Training loss: 1.0026770759263706
Validation loss: 2.5622218161351693

Epoch: 6| Step: 12
Training loss: 1.149859009268388
Validation loss: 2.58267743804608

Epoch: 6| Step: 13
Training loss: 1.0386587520141932
Validation loss: 2.586521960126464

Epoch: 277| Step: 0
Training loss: 1.0663288353847675
Validation loss: 2.5573962147862237

Epoch: 6| Step: 1
Training loss: 0.8567918274383723
Validation loss: 2.558784195845459

Epoch: 6| Step: 2
Training loss: 0.8200445555002949
Validation loss: 2.555966637082081

Epoch: 6| Step: 3
Training loss: 0.9807548561452439
Validation loss: 2.553440651357878

Epoch: 6| Step: 4
Training loss: 1.1247966900538042
Validation loss: 2.5419653467046497

Epoch: 6| Step: 5
Training loss: 1.1218725815430821
Validation loss: 2.553592515081668

Epoch: 6| Step: 6
Training loss: 1.4445793973203251
Validation loss: 2.5527647399991937

Epoch: 6| Step: 7
Training loss: 0.9549811378333887
Validation loss: 2.5716272218247496

Epoch: 6| Step: 8
Training loss: 1.0627627328393934
Validation loss: 2.5822358908144505

Epoch: 6| Step: 9
Training loss: 1.0083639129751722
Validation loss: 2.5944819202843195

Epoch: 6| Step: 10
Training loss: 0.7985681982996257
Validation loss: 2.5827453692102456

Epoch: 6| Step: 11
Training loss: 0.848473712857875
Validation loss: 2.583962788210822

Epoch: 6| Step: 12
Training loss: 1.149882335448274
Validation loss: 2.5876930879321867

Epoch: 6| Step: 13
Training loss: 0.31562107291469593
Validation loss: 2.567451245693876

Epoch: 278| Step: 0
Training loss: 0.9396876559877408
Validation loss: 2.5590037443467684

Epoch: 6| Step: 1
Training loss: 1.2464759742695213
Validation loss: 2.5575533457044406

Epoch: 6| Step: 2
Training loss: 0.9923947335638175
Validation loss: 2.544965426628029

Epoch: 6| Step: 3
Training loss: 1.0939576633044252
Validation loss: 2.50893353863574

Epoch: 6| Step: 4
Training loss: 1.0775624894787723
Validation loss: 2.4822002841998323

Epoch: 6| Step: 5
Training loss: 1.1840544958944
Validation loss: 2.482732350377481

Epoch: 6| Step: 6
Training loss: 0.6949003691237662
Validation loss: 2.4866150240506326

Epoch: 6| Step: 7
Training loss: 1.013692749043716
Validation loss: 2.515550006310912

Epoch: 6| Step: 8
Training loss: 0.6590899371047312
Validation loss: 2.582991249075874

Epoch: 6| Step: 9
Training loss: 0.9551660228137556
Validation loss: 2.600597030117364

Epoch: 6| Step: 10
Training loss: 0.9610957813939168
Validation loss: 2.640590350273294

Epoch: 6| Step: 11
Training loss: 0.9107729087522235
Validation loss: 2.641131891291177

Epoch: 6| Step: 12
Training loss: 1.1484175699801282
Validation loss: 2.636267960394832

Epoch: 6| Step: 13
Training loss: 1.2089370940150117
Validation loss: 2.603177429009232

Epoch: 279| Step: 0
Training loss: 1.0416661961872309
Validation loss: 2.5549591237160443

Epoch: 6| Step: 1
Training loss: 0.9766201154878933
Validation loss: 2.55595333322381

Epoch: 6| Step: 2
Training loss: 1.0349945517871115
Validation loss: 2.50854525133037

Epoch: 6| Step: 3
Training loss: 1.134488884539768
Validation loss: 2.489355518017599

Epoch: 6| Step: 4
Training loss: 0.9974919696953096
Validation loss: 2.4731264514730125

Epoch: 6| Step: 5
Training loss: 1.198914977128536
Validation loss: 2.4929836623041406

Epoch: 6| Step: 6
Training loss: 1.054784360605778
Validation loss: 2.5006261062052686

Epoch: 6| Step: 7
Training loss: 0.8374739457817666
Validation loss: 2.5412350117766227

Epoch: 6| Step: 8
Training loss: 0.9611653623784304
Validation loss: 2.5912310049489844

Epoch: 6| Step: 9
Training loss: 0.6954084823024699
Validation loss: 2.621453334228822

Epoch: 6| Step: 10
Training loss: 0.8666100512560178
Validation loss: 2.607856286420302

Epoch: 6| Step: 11
Training loss: 1.187463659433149
Validation loss: 2.625561665314422

Epoch: 6| Step: 12
Training loss: 0.9775128737379968
Validation loss: 2.6088197237790443

Epoch: 6| Step: 13
Training loss: 0.732386351677601
Validation loss: 2.5951399016534724

Epoch: 280| Step: 0
Training loss: 0.6000856874791735
Validation loss: 2.560175674166871

Epoch: 6| Step: 1
Training loss: 0.9691015036519617
Validation loss: 2.565614744677534

Epoch: 6| Step: 2
Training loss: 1.2415021529223196
Validation loss: 2.57677419008977

Epoch: 6| Step: 3
Training loss: 0.864700945166147
Validation loss: 2.5508597196579

Epoch: 6| Step: 4
Training loss: 0.9300739863406547
Validation loss: 2.5734590336793475

Epoch: 6| Step: 5
Training loss: 1.0385514917294716
Validation loss: 2.574498104106559

Epoch: 6| Step: 6
Training loss: 0.765423261572167
Validation loss: 2.5886383406679596

Epoch: 6| Step: 7
Training loss: 0.8367390577628294
Validation loss: 2.592092615846024

Epoch: 6| Step: 8
Training loss: 1.1314974287697526
Validation loss: 2.5869828065015703

Epoch: 6| Step: 9
Training loss: 1.2582214827857823
Validation loss: 2.613527242955644

Epoch: 6| Step: 10
Training loss: 1.1342703022206637
Validation loss: 2.600531037096364

Epoch: 6| Step: 11
Training loss: 0.5458871093011362
Validation loss: 2.57265173890032

Epoch: 6| Step: 12
Training loss: 1.1816243824748858
Validation loss: 2.5746851690288195

Epoch: 6| Step: 13
Training loss: 0.8175521183024035
Validation loss: 2.5641184542217217

Epoch: 281| Step: 0
Training loss: 0.9866677181188892
Validation loss: 2.598150466856138

Epoch: 6| Step: 1
Training loss: 0.9166514258129176
Validation loss: 2.5590155476684227

Epoch: 6| Step: 2
Training loss: 1.1191674141065915
Validation loss: 2.5637280382604155

Epoch: 6| Step: 3
Training loss: 1.0459223725815185
Validation loss: 2.572537245782803

Epoch: 6| Step: 4
Training loss: 0.6969448174369661
Validation loss: 2.566550316035907

Epoch: 6| Step: 5
Training loss: 1.1915739347928171
Validation loss: 2.5576407988677827

Epoch: 6| Step: 6
Training loss: 0.4672184082319847
Validation loss: 2.609321778891701

Epoch: 6| Step: 7
Training loss: 1.1956281058335432
Validation loss: 2.5822911543670375

Epoch: 6| Step: 8
Training loss: 0.8466927814461123
Validation loss: 2.5498448258119306

Epoch: 6| Step: 9
Training loss: 1.2264097082133287
Validation loss: 2.5605722314743895

Epoch: 6| Step: 10
Training loss: 0.44817632719068856
Validation loss: 2.5576854279272934

Epoch: 6| Step: 11
Training loss: 1.126154836683892
Validation loss: 2.5401912611644244

Epoch: 6| Step: 12
Training loss: 1.052454867086194
Validation loss: 2.5392979868439816

Epoch: 6| Step: 13
Training loss: 0.1973447640937368
Validation loss: 2.5620656439464904

Epoch: 282| Step: 0
Training loss: 0.8666500797579588
Validation loss: 2.5983322888553464

Epoch: 6| Step: 1
Training loss: 1.0485793516614048
Validation loss: 2.590962111230579

Epoch: 6| Step: 2
Training loss: 0.6747895168691437
Validation loss: 2.586348599316373

Epoch: 6| Step: 3
Training loss: 1.1275596110620552
Validation loss: 2.621929596785659

Epoch: 6| Step: 4
Training loss: 0.5582871028872001
Validation loss: 2.570550887513874

Epoch: 6| Step: 5
Training loss: 0.9708929049070073
Validation loss: 2.5916262097210225

Epoch: 6| Step: 6
Training loss: 0.9758289481264567
Validation loss: 2.567350135990044

Epoch: 6| Step: 7
Training loss: 0.8575404613057562
Validation loss: 2.5702187582486586

Epoch: 6| Step: 8
Training loss: 1.00861970970023
Validation loss: 2.584901686570672

Epoch: 6| Step: 9
Training loss: 0.9416930209047573
Validation loss: 2.585396395070488

Epoch: 6| Step: 10
Training loss: 0.6290134788700391
Validation loss: 2.604399642039285

Epoch: 6| Step: 11
Training loss: 1.612762737308432
Validation loss: 2.616058769360838

Epoch: 6| Step: 12
Training loss: 0.91626253033614
Validation loss: 2.6067935552960346

Epoch: 6| Step: 13
Training loss: 0.3599609904876521
Validation loss: 2.585716315178827

Epoch: 283| Step: 0
Training loss: 0.46167918518230155
Validation loss: 2.603996403860484

Epoch: 6| Step: 1
Training loss: 1.0520667398988601
Validation loss: 2.5694442206547743

Epoch: 6| Step: 2
Training loss: 0.9902974546908064
Validation loss: 2.586855533176986

Epoch: 6| Step: 3
Training loss: 1.0040460630199963
Validation loss: 2.5518570294641956

Epoch: 6| Step: 4
Training loss: 1.0474749881243728
Validation loss: 2.585727442337973

Epoch: 6| Step: 5
Training loss: 0.8421861850254077
Validation loss: 2.5859206009214017

Epoch: 6| Step: 6
Training loss: 0.9906839106519217
Validation loss: 2.574971017615682

Epoch: 6| Step: 7
Training loss: 1.0178661561150986
Validation loss: 2.543762586182089

Epoch: 6| Step: 8
Training loss: 1.0361537517765191
Validation loss: 2.5533364114984036

Epoch: 6| Step: 9
Training loss: 0.8525792972120044
Validation loss: 2.5509646574227234

Epoch: 6| Step: 10
Training loss: 0.8326927027326125
Validation loss: 2.5518460524857334

Epoch: 6| Step: 11
Training loss: 1.1048331977988786
Validation loss: 2.5657557791957375

Epoch: 6| Step: 12
Training loss: 0.6600225866310978
Validation loss: 2.551474571995009

Epoch: 6| Step: 13
Training loss: 1.1571723764344528
Validation loss: 2.575767479814387

Epoch: 284| Step: 0
Training loss: 1.0489127979162263
Validation loss: 2.5883647740817235

Epoch: 6| Step: 1
Training loss: 0.8527738372436945
Validation loss: 2.5588713664954006

Epoch: 6| Step: 2
Training loss: 0.8910338818436956
Validation loss: 2.563817771630678

Epoch: 6| Step: 3
Training loss: 1.0903132258090542
Validation loss: 2.5445175418225516

Epoch: 6| Step: 4
Training loss: 0.9023958992028737
Validation loss: 2.5090185983662896

Epoch: 6| Step: 5
Training loss: 0.8904574052496643
Validation loss: 2.5527204748280936

Epoch: 6| Step: 6
Training loss: 1.0189961750306882
Validation loss: 2.495782231164774

Epoch: 6| Step: 7
Training loss: 0.915956670169396
Validation loss: 2.5559480142689375

Epoch: 6| Step: 8
Training loss: 1.2527150232612343
Validation loss: 2.550575907766474

Epoch: 6| Step: 9
Training loss: 0.8040136460171058
Validation loss: 2.5867996644839

Epoch: 6| Step: 10
Training loss: 0.6641352894102794
Validation loss: 2.5909844154310986

Epoch: 6| Step: 11
Training loss: 0.9320484284498964
Validation loss: 2.577266237108353

Epoch: 6| Step: 12
Training loss: 0.9141575364485983
Validation loss: 2.596138155328582

Epoch: 6| Step: 13
Training loss: 0.7331198659783752
Validation loss: 2.555862061412495

Epoch: 285| Step: 0
Training loss: 0.8009508651112431
Validation loss: 2.5644439573890807

Epoch: 6| Step: 1
Training loss: 0.8571277365883518
Validation loss: 2.582877661430306

Epoch: 6| Step: 2
Training loss: 0.7250194777141372
Validation loss: 2.5898410119839532

Epoch: 6| Step: 3
Training loss: 1.1994415970800363
Validation loss: 2.544891769000295

Epoch: 6| Step: 4
Training loss: 0.9099701457838075
Validation loss: 2.5675499131353052

Epoch: 6| Step: 5
Training loss: 0.6913471519946224
Validation loss: 2.5741613282908355

Epoch: 6| Step: 6
Training loss: 0.914138106129202
Validation loss: 2.525696588780361

Epoch: 6| Step: 7
Training loss: 0.9732046151836886
Validation loss: 2.5498763894722614

Epoch: 6| Step: 8
Training loss: 1.1162290396436507
Validation loss: 2.5549506715798

Epoch: 6| Step: 9
Training loss: 0.9384824055977049
Validation loss: 2.590291769123773

Epoch: 6| Step: 10
Training loss: 0.9147103450986276
Validation loss: 2.6135459822342386

Epoch: 6| Step: 11
Training loss: 0.8165109740627636
Validation loss: 2.607882719389042

Epoch: 6| Step: 12
Training loss: 1.1282692138131312
Validation loss: 2.6401935712077615

Epoch: 6| Step: 13
Training loss: 0.6394382043960833
Validation loss: 2.637062677082269

Epoch: 286| Step: 0
Training loss: 0.7742228133540532
Validation loss: 2.6132706374718966

Epoch: 6| Step: 1
Training loss: 0.9143544570377827
Validation loss: 2.5937035076206327

Epoch: 6| Step: 2
Training loss: 0.8336866503987944
Validation loss: 2.604024070199162

Epoch: 6| Step: 3
Training loss: 0.937960066760717
Validation loss: 2.577350478983557

Epoch: 6| Step: 4
Training loss: 0.6721007389275113
Validation loss: 2.5703704585080547

Epoch: 6| Step: 5
Training loss: 1.1118363490470968
Validation loss: 2.614572936248469

Epoch: 6| Step: 6
Training loss: 0.7320940021337459
Validation loss: 2.598776687652109

Epoch: 6| Step: 7
Training loss: 0.907606326670933
Validation loss: 2.582953589557048

Epoch: 6| Step: 8
Training loss: 0.9086341081415444
Validation loss: 2.595666521524593

Epoch: 6| Step: 9
Training loss: 0.979925362216499
Validation loss: 2.6106534658795844

Epoch: 6| Step: 10
Training loss: 1.1605451041368284
Validation loss: 2.58688359788505

Epoch: 6| Step: 11
Training loss: 0.9422020931600416
Validation loss: 2.5621288825176056

Epoch: 6| Step: 12
Training loss: 0.49331851466847565
Validation loss: 2.5639568252515113

Epoch: 6| Step: 13
Training loss: 1.3435982019603767
Validation loss: 2.5524601622768373

Epoch: 287| Step: 0
Training loss: 1.0049829312673284
Validation loss: 2.5646621622278842

Epoch: 6| Step: 1
Training loss: 1.1341227878955553
Validation loss: 2.531453559820197

Epoch: 6| Step: 2
Training loss: 0.9567266797028836
Validation loss: 2.569312118305307

Epoch: 6| Step: 3
Training loss: 0.45886202865718123
Validation loss: 2.579793711817061

Epoch: 6| Step: 4
Training loss: 0.7150313334501864
Validation loss: 2.5932660366065368

Epoch: 6| Step: 5
Training loss: 1.173507976828316
Validation loss: 2.6047150111272805

Epoch: 6| Step: 6
Training loss: 0.9416823239557985
Validation loss: 2.638363123770837

Epoch: 6| Step: 7
Training loss: 0.6430501160987777
Validation loss: 2.6297818746563344

Epoch: 6| Step: 8
Training loss: 0.7455230047743232
Validation loss: 2.6344927120991555

Epoch: 6| Step: 9
Training loss: 0.9513871656218157
Validation loss: 2.650875874902115

Epoch: 6| Step: 10
Training loss: 1.099487243699777
Validation loss: 2.6652663967786303

Epoch: 6| Step: 11
Training loss: 1.0130782842484924
Validation loss: 2.6426834235714867

Epoch: 6| Step: 12
Training loss: 0.6907027162003341
Validation loss: 2.6210765513763983

Epoch: 6| Step: 13
Training loss: 0.7264021009366495
Validation loss: 2.5977872938974262

Epoch: 288| Step: 0
Training loss: 0.532254699523232
Validation loss: 2.5649544081199847

Epoch: 6| Step: 1
Training loss: 0.8661247477179408
Validation loss: 2.552099163984899

Epoch: 6| Step: 2
Training loss: 0.9319748508883131
Validation loss: 2.5453731956505328

Epoch: 6| Step: 3
Training loss: 0.806178073484005
Validation loss: 2.5331785410020213

Epoch: 6| Step: 4
Training loss: 0.9198000557942797
Validation loss: 2.5749956775090985

Epoch: 6| Step: 5
Training loss: 1.137161850185296
Validation loss: 2.5611979029869656

Epoch: 6| Step: 6
Training loss: 0.7813541342952226
Validation loss: 2.5790195040686408

Epoch: 6| Step: 7
Training loss: 0.8789483293420773
Validation loss: 2.6044689939832164

Epoch: 6| Step: 8
Training loss: 0.7650227416155051
Validation loss: 2.6206247614872287

Epoch: 6| Step: 9
Training loss: 0.6488169972879659
Validation loss: 2.6162461080475605

Epoch: 6| Step: 10
Training loss: 0.6034170520860087
Validation loss: 2.6047893775576836

Epoch: 6| Step: 11
Training loss: 1.4001866063004151
Validation loss: 2.617555106923442

Epoch: 6| Step: 12
Training loss: 1.0574820336152606
Validation loss: 2.590569280150378

Epoch: 6| Step: 13
Training loss: 0.6345050218126407
Validation loss: 2.600036033336505

Epoch: 289| Step: 0
Training loss: 1.0318920564310436
Validation loss: 2.569549699700745

Epoch: 6| Step: 1
Training loss: 1.125539809100421
Validation loss: 2.5893153048035407

Epoch: 6| Step: 2
Training loss: 0.7758026181569462
Validation loss: 2.600664816539843

Epoch: 6| Step: 3
Training loss: 0.8111643450032133
Validation loss: 2.6102391787301085

Epoch: 6| Step: 4
Training loss: 0.5989580873129519
Validation loss: 2.587470759212246

Epoch: 6| Step: 5
Training loss: 0.8519075726937899
Validation loss: 2.595712337762885

Epoch: 6| Step: 6
Training loss: 0.9939826285189416
Validation loss: 2.555143297285786

Epoch: 6| Step: 7
Training loss: 1.1132126636459216
Validation loss: 2.559480510347198

Epoch: 6| Step: 8
Training loss: 0.9978909006688075
Validation loss: 2.533546468445409

Epoch: 6| Step: 9
Training loss: 0.9311759637678383
Validation loss: 2.5069813575678626

Epoch: 6| Step: 10
Training loss: 0.9844688794616356
Validation loss: 2.500043778395095

Epoch: 6| Step: 11
Training loss: 0.599462012656727
Validation loss: 2.496566455273005

Epoch: 6| Step: 12
Training loss: 0.5993341566058238
Validation loss: 2.5450068465226034

Epoch: 6| Step: 13
Training loss: 0.6573064112231188
Validation loss: 2.59770608527724

Epoch: 290| Step: 0
Training loss: 0.6996649698205368
Validation loss: 2.6268575886169625

Epoch: 6| Step: 1
Training loss: 1.004208886510766
Validation loss: 2.708276827264537

Epoch: 6| Step: 2
Training loss: 0.8520672903128422
Validation loss: 2.680379022000083

Epoch: 6| Step: 3
Training loss: 0.8376595772120524
Validation loss: 2.6497046641761735

Epoch: 6| Step: 4
Training loss: 0.8347080137644811
Validation loss: 2.5566384981918766

Epoch: 6| Step: 5
Training loss: 1.0715020801668185
Validation loss: 2.536582688186117

Epoch: 6| Step: 6
Training loss: 0.915831980566866
Validation loss: 2.4999164690398734

Epoch: 6| Step: 7
Training loss: 0.620072394728212
Validation loss: 2.4641192989420175

Epoch: 6| Step: 8
Training loss: 0.9069649737028794
Validation loss: 2.4653600697982845

Epoch: 6| Step: 9
Training loss: 0.9290593694024024
Validation loss: 2.516228767142707

Epoch: 6| Step: 10
Training loss: 0.8824762362233511
Validation loss: 2.51434305763017

Epoch: 6| Step: 11
Training loss: 0.6591530123364227
Validation loss: 2.580966598350107

Epoch: 6| Step: 12
Training loss: 1.2109684109588028
Validation loss: 2.5889360133212294

Epoch: 6| Step: 13
Training loss: 0.7071811664616279
Validation loss: 2.6121010430716836

Epoch: 291| Step: 0
Training loss: 0.6132302232641085
Validation loss: 2.637462357185999

Epoch: 6| Step: 1
Training loss: 0.9896364231257416
Validation loss: 2.6007945259903833

Epoch: 6| Step: 2
Training loss: 0.692500396342801
Validation loss: 2.5948233668521636

Epoch: 6| Step: 3
Training loss: 1.172056158686255
Validation loss: 2.6044062839320468

Epoch: 6| Step: 4
Training loss: 0.9999994933603911
Validation loss: 2.6187427232544147

Epoch: 6| Step: 5
Training loss: 1.0855455308640247
Validation loss: 2.594505775192388

Epoch: 6| Step: 6
Training loss: 0.494243535720701
Validation loss: 2.6042516058738983

Epoch: 6| Step: 7
Training loss: 0.6901289353634162
Validation loss: 2.590200157365781

Epoch: 6| Step: 8
Training loss: 0.8317920896281967
Validation loss: 2.612555679777538

Epoch: 6| Step: 9
Training loss: 0.5298286947475506
Validation loss: 2.599471771924471

Epoch: 6| Step: 10
Training loss: 1.1475550576425713
Validation loss: 2.6324530358208547

Epoch: 6| Step: 11
Training loss: 0.8589567727324484
Validation loss: 2.6057173060343146

Epoch: 6| Step: 12
Training loss: 0.8990018979180896
Validation loss: 2.6031318116205724

Epoch: 6| Step: 13
Training loss: 0.8430587268003689
Validation loss: 2.5690911062184747

Epoch: 292| Step: 0
Training loss: 0.567419500691319
Validation loss: 2.544521950706168

Epoch: 6| Step: 1
Training loss: 0.7276814366249961
Validation loss: 2.5433973431291457

Epoch: 6| Step: 2
Training loss: 0.6882541161859916
Validation loss: 2.532963504847024

Epoch: 6| Step: 3
Training loss: 1.1099580119327868
Validation loss: 2.5191402039309945

Epoch: 6| Step: 4
Training loss: 0.8368234663260498
Validation loss: 2.5515973416735678

Epoch: 6| Step: 5
Training loss: 0.8783106163122513
Validation loss: 2.5468266714868166

Epoch: 6| Step: 6
Training loss: 0.9028946817136452
Validation loss: 2.5621034669042912

Epoch: 6| Step: 7
Training loss: 1.1768841307656097
Validation loss: 2.5754168683439915

Epoch: 6| Step: 8
Training loss: 0.7606936085460188
Validation loss: 2.578480691695199

Epoch: 6| Step: 9
Training loss: 0.8645257049719169
Validation loss: 2.610287536292807

Epoch: 6| Step: 10
Training loss: 0.9308660394107452
Validation loss: 2.619813924395722

Epoch: 6| Step: 11
Training loss: 1.051325773939662
Validation loss: 2.6414938284544807

Epoch: 6| Step: 12
Training loss: 0.7553261544410282
Validation loss: 2.577909091275152

Epoch: 6| Step: 13
Training loss: 0.32341222526094243
Validation loss: 2.556049380430608

Epoch: 293| Step: 0
Training loss: 0.8335999936385713
Validation loss: 2.603764022381295

Epoch: 6| Step: 1
Training loss: 0.9001734010227554
Validation loss: 2.5709908448644434

Epoch: 6| Step: 2
Training loss: 0.36036049436339046
Validation loss: 2.5611375682878297

Epoch: 6| Step: 3
Training loss: 0.7042245109395255
Validation loss: 2.5982993030135715

Epoch: 6| Step: 4
Training loss: 0.9146329289908953
Validation loss: 2.619973395186762

Epoch: 6| Step: 5
Training loss: 0.9946080516039008
Validation loss: 2.641446058691896

Epoch: 6| Step: 6
Training loss: 0.7210660191387499
Validation loss: 2.6017794614833325

Epoch: 6| Step: 7
Training loss: 0.923347751496826
Validation loss: 2.573940450217169

Epoch: 6| Step: 8
Training loss: 0.9622595152212261
Validation loss: 2.5273815245464215

Epoch: 6| Step: 9
Training loss: 0.9314844732357281
Validation loss: 2.5251284194335972

Epoch: 6| Step: 10
Training loss: 0.8970349518102038
Validation loss: 2.48246366459661

Epoch: 6| Step: 11
Training loss: 0.8845398132632082
Validation loss: 2.4768416733672596

Epoch: 6| Step: 12
Training loss: 0.9459593900347465
Validation loss: 2.5091785371011324

Epoch: 6| Step: 13
Training loss: 0.8782624323806784
Validation loss: 2.5185354170237195

Epoch: 294| Step: 0
Training loss: 1.040258020983858
Validation loss: 2.576590916451229

Epoch: 6| Step: 1
Training loss: 1.1555568576361175
Validation loss: 2.5886521861254317

Epoch: 6| Step: 2
Training loss: 0.8774456179034287
Validation loss: 2.632461448983695

Epoch: 6| Step: 3
Training loss: 0.6385068534417543
Validation loss: 2.6347520778138698

Epoch: 6| Step: 4
Training loss: 0.8450829255873249
Validation loss: 2.649353763262481

Epoch: 6| Step: 5
Training loss: 0.6711970168786259
Validation loss: 2.617327919212672

Epoch: 6| Step: 6
Training loss: 1.111348344722831
Validation loss: 2.5809096227774457

Epoch: 6| Step: 7
Training loss: 0.8525241706307831
Validation loss: 2.5650787413887035

Epoch: 6| Step: 8
Training loss: 0.9173705404141773
Validation loss: 2.538854091474607

Epoch: 6| Step: 9
Training loss: 0.7019601285539427
Validation loss: 2.5372231529697675

Epoch: 6| Step: 10
Training loss: 0.5945038777891439
Validation loss: 2.5511700990014736

Epoch: 6| Step: 11
Training loss: 0.9696216046253087
Validation loss: 2.5593423454181496

Epoch: 6| Step: 12
Training loss: 0.5112308768167844
Validation loss: 2.558220697451141

Epoch: 6| Step: 13
Training loss: 0.39510634026037217
Validation loss: 2.576177476612838

Epoch: 295| Step: 0
Training loss: 0.6045463180340267
Validation loss: 2.5716400612934174

Epoch: 6| Step: 1
Training loss: 0.7298494049094928
Validation loss: 2.5574143929995925

Epoch: 6| Step: 2
Training loss: 1.0433369533081955
Validation loss: 2.560321236773651

Epoch: 6| Step: 3
Training loss: 1.1210717920153366
Validation loss: 2.52480381248446

Epoch: 6| Step: 4
Training loss: 0.5846462517791343
Validation loss: 2.5486343842607715

Epoch: 6| Step: 5
Training loss: 0.7992442569782874
Validation loss: 2.5327329273326735

Epoch: 6| Step: 6
Training loss: 0.9630698449285934
Validation loss: 2.551961759710676

Epoch: 6| Step: 7
Training loss: 0.7206157021365205
Validation loss: 2.587659094636897

Epoch: 6| Step: 8
Training loss: 0.23937924475927683
Validation loss: 2.6141983577013406

Epoch: 6| Step: 9
Training loss: 1.0253549333445986
Validation loss: 2.644040212685749

Epoch: 6| Step: 10
Training loss: 0.9690909247241408
Validation loss: 2.587757148109838

Epoch: 6| Step: 11
Training loss: 0.8454745294263764
Validation loss: 2.5164521363937387

Epoch: 6| Step: 12
Training loss: 0.5632887714111331
Validation loss: 2.4927726318696837

Epoch: 6| Step: 13
Training loss: 1.2287129787948987
Validation loss: 2.5575720340111627

Epoch: 296| Step: 0
Training loss: 0.8958563505956507
Validation loss: 2.5864068122724526

Epoch: 6| Step: 1
Training loss: 1.0270685908024901
Validation loss: 2.635583334273312

Epoch: 6| Step: 2
Training loss: 0.3702429605532163
Validation loss: 2.6670706722360795

Epoch: 6| Step: 3
Training loss: 0.6552503556167237
Validation loss: 2.7248970744607837

Epoch: 6| Step: 4
Training loss: 0.6799453816146862
Validation loss: 2.7691400635457915

Epoch: 6| Step: 5
Training loss: 0.7649422540249675
Validation loss: 2.7029427372035295

Epoch: 6| Step: 6
Training loss: 0.7454954214767792
Validation loss: 2.669011275154612

Epoch: 6| Step: 7
Training loss: 1.1577809482656338
Validation loss: 2.566009338456227

Epoch: 6| Step: 8
Training loss: 1.1437807714773378
Validation loss: 2.5249350685340897

Epoch: 6| Step: 9
Training loss: 0.7884678252168126
Validation loss: 2.474074333506732

Epoch: 6| Step: 10
Training loss: 1.0458008108870163
Validation loss: 2.463648486627429

Epoch: 6| Step: 11
Training loss: 0.6333185221379055
Validation loss: 2.44264822450245

Epoch: 6| Step: 12
Training loss: 0.5314957106588547
Validation loss: 2.4630128036590637

Epoch: 6| Step: 13
Training loss: 0.9318166762380004
Validation loss: 2.4849191901483465

Epoch: 297| Step: 0
Training loss: 0.6478721958079842
Validation loss: 2.509135031496945

Epoch: 6| Step: 1
Training loss: 0.873082205038339
Validation loss: 2.559377481087074

Epoch: 6| Step: 2
Training loss: 0.928416208378094
Validation loss: 2.625161610837293

Epoch: 6| Step: 3
Training loss: 1.036875495473641
Validation loss: 2.695750593523569

Epoch: 6| Step: 4
Training loss: 0.9667285317048931
Validation loss: 2.750804934341278

Epoch: 6| Step: 5
Training loss: 0.7681096689853049
Validation loss: 2.787225770348367

Epoch: 6| Step: 6
Training loss: 0.9038773422432433
Validation loss: 2.7629561670925833

Epoch: 6| Step: 7
Training loss: 0.7884691481375141
Validation loss: 2.6857928925681667

Epoch: 6| Step: 8
Training loss: 0.9342950078602831
Validation loss: 2.587702302463542

Epoch: 6| Step: 9
Training loss: 0.7637150354701269
Validation loss: 2.506757819382307

Epoch: 6| Step: 10
Training loss: 0.9376009568850742
Validation loss: 2.482086599195312

Epoch: 6| Step: 11
Training loss: 0.7783365475290766
Validation loss: 2.4582953876829494

Epoch: 6| Step: 12
Training loss: 1.0629089353891588
Validation loss: 2.456515602355966

Epoch: 6| Step: 13
Training loss: 0.7356094374262351
Validation loss: 2.477186498148985

Epoch: 298| Step: 0
Training loss: 0.8906921227575887
Validation loss: 2.5811403452214323

Epoch: 6| Step: 1
Training loss: 0.8287664843914929
Validation loss: 2.631986873026887

Epoch: 6| Step: 2
Training loss: 1.0649077678196865
Validation loss: 2.691032592928958

Epoch: 6| Step: 3
Training loss: 0.7414683019559777
Validation loss: 2.7453959986832546

Epoch: 6| Step: 4
Training loss: 0.7667561952174615
Validation loss: 2.7805885559857524

Epoch: 6| Step: 5
Training loss: 0.8669025537227711
Validation loss: 2.737155031974342

Epoch: 6| Step: 6
Training loss: 0.7743542565129818
Validation loss: 2.731212787051304

Epoch: 6| Step: 7
Training loss: 0.9680384206752868
Validation loss: 2.6728954763947814

Epoch: 6| Step: 8
Training loss: 0.9076870015734043
Validation loss: 2.612099443311396

Epoch: 6| Step: 9
Training loss: 0.7853206633186405
Validation loss: 2.593797354396248

Epoch: 6| Step: 10
Training loss: 1.021876301895852
Validation loss: 2.598056695422758

Epoch: 6| Step: 11
Training loss: 0.9233302252564525
Validation loss: 2.5534430574298126

Epoch: 6| Step: 12
Training loss: 0.8102701840898353
Validation loss: 2.5984230332792007

Epoch: 6| Step: 13
Training loss: 0.7531191813770463
Validation loss: 2.5535820199247006

Epoch: 299| Step: 0
Training loss: 0.905061830811075
Validation loss: 2.561975393912141

Epoch: 6| Step: 1
Training loss: 0.7524757451682398
Validation loss: 2.591915372810346

Epoch: 6| Step: 2
Training loss: 0.8758827593026767
Validation loss: 2.5989689128967095

Epoch: 6| Step: 3
Training loss: 0.7949685872667585
Validation loss: 2.636537263944981

Epoch: 6| Step: 4
Training loss: 1.0901970512865324
Validation loss: 2.6235631241806647

Epoch: 6| Step: 5
Training loss: 0.8784893827475254
Validation loss: 2.592536661747559

Epoch: 6| Step: 6
Training loss: 0.8689754029009468
Validation loss: 2.5857748950741763

Epoch: 6| Step: 7
Training loss: 0.6835969761363605
Validation loss: 2.5906385352549046

Epoch: 6| Step: 8
Training loss: 0.8466228039210499
Validation loss: 2.592047830494833

Epoch: 6| Step: 9
Training loss: 0.7120576773839871
Validation loss: 2.5940689333629647

Epoch: 6| Step: 10
Training loss: 0.6431776224300337
Validation loss: 2.5667388426300235

Epoch: 6| Step: 11
Training loss: 0.8283200304228328
Validation loss: 2.6065616710403585

Epoch: 6| Step: 12
Training loss: 0.6925993931705704
Validation loss: 2.6458472271794182

Epoch: 6| Step: 13
Training loss: 0.8073068965992942
Validation loss: 2.645319274335841

Epoch: 300| Step: 0
Training loss: 0.4131201871917675
Validation loss: 2.6336869894733934

Epoch: 6| Step: 1
Training loss: 0.7327166155000945
Validation loss: 2.6273770505486698

Epoch: 6| Step: 2
Training loss: 0.9973872145370853
Validation loss: 2.5887009548609834

Epoch: 6| Step: 3
Training loss: 0.8759871772454699
Validation loss: 2.567959073558173

Epoch: 6| Step: 4
Training loss: 0.8301146734830658
Validation loss: 2.562396767990729

Epoch: 6| Step: 5
Training loss: 0.5250472183791758
Validation loss: 2.568029439561349

Epoch: 6| Step: 6
Training loss: 0.7621885367085756
Validation loss: 2.589710146091651

Epoch: 6| Step: 7
Training loss: 1.0433502071182061
Validation loss: 2.6072013574614337

Epoch: 6| Step: 8
Training loss: 1.1349691973300153
Validation loss: 2.625427999826279

Epoch: 6| Step: 9
Training loss: 0.6220034289372859
Validation loss: 2.6690964057090136

Epoch: 6| Step: 10
Training loss: 0.5672195120781071
Validation loss: 2.689095564596263

Epoch: 6| Step: 11
Training loss: 0.5123324899695476
Validation loss: 2.729803238566751

Epoch: 6| Step: 12
Training loss: 0.9801339113452847
Validation loss: 2.6559218414490493

Epoch: 6| Step: 13
Training loss: 0.8827246563173278
Validation loss: 2.6344414172369075

Testing loss: 2.702900673752459
