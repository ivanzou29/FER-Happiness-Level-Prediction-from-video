Epoch: 1| Step: 0
Training loss: 5.457468509674072
Validation loss: 5.2584123406358945

Epoch: 5| Step: 1
Training loss: 5.452816486358643
Validation loss: 5.234392237919633

Epoch: 5| Step: 2
Training loss: 5.717283248901367
Validation loss: 5.213632404163319

Epoch: 5| Step: 3
Training loss: 4.793424129486084
Validation loss: 5.193269201504287

Epoch: 5| Step: 4
Training loss: 4.704646587371826
Validation loss: 5.171422430264053

Epoch: 5| Step: 5
Training loss: 4.644017696380615
Validation loss: 5.146440634163477

Epoch: 5| Step: 6
Training loss: 4.795533180236816
Validation loss: 5.118768527943601

Epoch: 5| Step: 7
Training loss: 5.187997341156006
Validation loss: 5.086828354866274

Epoch: 5| Step: 8
Training loss: 4.088723182678223
Validation loss: 5.050165830119964

Epoch: 5| Step: 9
Training loss: 5.315784931182861
Validation loss: 5.009210227638163

Epoch: 5| Step: 10
Training loss: 3.9000630378723145
Validation loss: 4.9630920963902625

Epoch: 2| Step: 0
Training loss: 3.6794636249542236
Validation loss: 4.9130982019568

Epoch: 5| Step: 1
Training loss: 4.742918014526367
Validation loss: 4.856337906211935

Epoch: 5| Step: 2
Training loss: 5.475061893463135
Validation loss: 4.7928634920427875

Epoch: 5| Step: 3
Training loss: 3.9476051330566406
Validation loss: 4.726726772964642

Epoch: 5| Step: 4
Training loss: 4.090855121612549
Validation loss: 4.657311593332598

Epoch: 5| Step: 5
Training loss: 5.463875770568848
Validation loss: 4.587095650293493

Epoch: 5| Step: 6
Training loss: 5.428561210632324
Validation loss: 4.514668100623674

Epoch: 5| Step: 7
Training loss: 2.934778928756714
Validation loss: 4.443901482448783

Epoch: 5| Step: 8
Training loss: 3.9397990703582764
Validation loss: 4.378826746376612

Epoch: 5| Step: 9
Training loss: 4.610123634338379
Validation loss: 4.319671784677813

Epoch: 5| Step: 10
Training loss: 3.891735792160034
Validation loss: 4.263386357215143

Epoch: 3| Step: 0
Training loss: 3.4572479724884033
Validation loss: 4.208048410313104

Epoch: 5| Step: 1
Training loss: 4.603135108947754
Validation loss: 4.155036808342062

Epoch: 5| Step: 2
Training loss: 3.795928478240967
Validation loss: 4.10431973139445

Epoch: 5| Step: 3
Training loss: 4.495278358459473
Validation loss: 4.052986780802409

Epoch: 5| Step: 4
Training loss: 4.078032493591309
Validation loss: 4.0056329850227606

Epoch: 5| Step: 5
Training loss: 3.7430572509765625
Validation loss: 3.9675604092177523

Epoch: 5| Step: 6
Training loss: 2.9994759559631348
Validation loss: 3.929528877299319

Epoch: 5| Step: 7
Training loss: 4.109501838684082
Validation loss: 3.8993768999653478

Epoch: 5| Step: 8
Training loss: 4.133378505706787
Validation loss: 3.869474667374806

Epoch: 5| Step: 9
Training loss: 3.5819251537323
Validation loss: 3.8413312306968113

Epoch: 5| Step: 10
Training loss: 3.313537359237671
Validation loss: 3.8142618107539352

Epoch: 4| Step: 0
Training loss: 3.537126064300537
Validation loss: 3.791855025035079

Epoch: 5| Step: 1
Training loss: 3.1976280212402344
Validation loss: 3.772292362746372

Epoch: 5| Step: 2
Training loss: 3.381415843963623
Validation loss: 3.7584319037775837

Epoch: 5| Step: 3
Training loss: 3.454848051071167
Validation loss: 3.7434499930309992

Epoch: 5| Step: 4
Training loss: 2.9493517875671387
Validation loss: 3.7307894819526264

Epoch: 5| Step: 5
Training loss: 4.110991954803467
Validation loss: 3.715303421020508

Epoch: 5| Step: 6
Training loss: 4.230469703674316
Validation loss: 3.696582830080422

Epoch: 5| Step: 7
Training loss: 3.4932899475097656
Validation loss: 3.6757268572366364

Epoch: 5| Step: 8
Training loss: 4.523829936981201
Validation loss: 3.655113463760704

Epoch: 5| Step: 9
Training loss: 3.7597813606262207
Validation loss: 3.6333699508379866

Epoch: 5| Step: 10
Training loss: 2.8802459239959717
Validation loss: 3.6070133127192014

Epoch: 5| Step: 0
Training loss: 3.249621629714966
Validation loss: 3.573341202992265

Epoch: 5| Step: 1
Training loss: 3.312049150466919
Validation loss: 3.543123363166727

Epoch: 5| Step: 2
Training loss: 3.3453071117401123
Validation loss: 3.51570007365237

Epoch: 5| Step: 3
Training loss: 3.5173072814941406
Validation loss: 3.488756392591743

Epoch: 5| Step: 4
Training loss: 3.3448657989501953
Validation loss: 3.459502976427796

Epoch: 5| Step: 5
Training loss: 3.3578667640686035
Validation loss: 3.435169630153205

Epoch: 5| Step: 6
Training loss: 4.019438743591309
Validation loss: 3.4117730381668254

Epoch: 5| Step: 7
Training loss: 2.7935917377471924
Validation loss: 3.3969215834012596

Epoch: 5| Step: 8
Training loss: 3.9612374305725098
Validation loss: 3.3904845688932683

Epoch: 5| Step: 9
Training loss: 3.0982978343963623
Validation loss: 3.376675000754736

Epoch: 5| Step: 10
Training loss: 3.4354286193847656
Validation loss: 3.3576188010554158

Epoch: 6| Step: 0
Training loss: 3.055515766143799
Validation loss: 3.338277365571709

Epoch: 5| Step: 1
Training loss: 2.735524892807007
Validation loss: 3.3278272639038744

Epoch: 5| Step: 2
Training loss: 3.600419282913208
Validation loss: 3.313577982687181

Epoch: 5| Step: 3
Training loss: 3.259376049041748
Validation loss: 3.3050482580738683

Epoch: 5| Step: 4
Training loss: 3.3987135887145996
Validation loss: 3.2938098753652265

Epoch: 5| Step: 5
Training loss: 3.994182586669922
Validation loss: 3.2844535663563716

Epoch: 5| Step: 6
Training loss: 3.3078200817108154
Validation loss: 3.2747139238542124

Epoch: 5| Step: 7
Training loss: 3.326533794403076
Validation loss: 3.2629473004289853

Epoch: 5| Step: 8
Training loss: 3.111888885498047
Validation loss: 3.2530979828167985

Epoch: 5| Step: 9
Training loss: 2.955204486846924
Validation loss: 3.2400896626134075

Epoch: 5| Step: 10
Training loss: 3.1278700828552246
Validation loss: 3.2305028284749677

Epoch: 7| Step: 0
Training loss: 3.3870437145233154
Validation loss: 3.217760552642166

Epoch: 5| Step: 1
Training loss: 3.751244306564331
Validation loss: 3.211080492183726

Epoch: 5| Step: 2
Training loss: 2.712151288986206
Validation loss: 3.196291741504464

Epoch: 5| Step: 3
Training loss: 3.0508475303649902
Validation loss: 3.188333624152727

Epoch: 5| Step: 4
Training loss: 2.650057077407837
Validation loss: 3.181287419411444

Epoch: 5| Step: 5
Training loss: 2.4303581714630127
Validation loss: 3.1707461623735327

Epoch: 5| Step: 6
Training loss: 3.4365925788879395
Validation loss: 3.1636954148610434

Epoch: 5| Step: 7
Training loss: 3.6685149669647217
Validation loss: 3.1564182132802983

Epoch: 5| Step: 8
Training loss: 3.213258743286133
Validation loss: 3.1461466640554447

Epoch: 5| Step: 9
Training loss: 3.2877612113952637
Validation loss: 3.1390179664857927

Epoch: 5| Step: 10
Training loss: 3.436793327331543
Validation loss: 3.125803760302964

Epoch: 8| Step: 0
Training loss: 2.6384365558624268
Validation loss: 3.121852769646593

Epoch: 5| Step: 1
Training loss: 3.2074694633483887
Validation loss: 3.1313201868405907

Epoch: 5| Step: 2
Training loss: 3.7739880084991455
Validation loss: 3.1225979866520053

Epoch: 5| Step: 3
Training loss: 2.4226036071777344
Validation loss: 3.094923286027806

Epoch: 5| Step: 4
Training loss: 3.503932476043701
Validation loss: 3.1043204953593593

Epoch: 5| Step: 5
Training loss: 2.1142325401306152
Validation loss: 3.1031737583939747

Epoch: 5| Step: 6
Training loss: 2.0912814140319824
Validation loss: 3.100000589124618

Epoch: 5| Step: 7
Training loss: 3.3180477619171143
Validation loss: 3.0813362085691063

Epoch: 5| Step: 8
Training loss: 3.1055290699005127
Validation loss: 3.071616698336858

Epoch: 5| Step: 9
Training loss: 3.8577709197998047
Validation loss: 3.068787561949863

Epoch: 5| Step: 10
Training loss: 4.567912578582764
Validation loss: 3.065362876461398

Epoch: 9| Step: 0
Training loss: 4.131450653076172
Validation loss: 3.0440371574894076

Epoch: 5| Step: 1
Training loss: 3.049592971801758
Validation loss: 3.035564663589642

Epoch: 5| Step: 2
Training loss: 2.3955085277557373
Validation loss: 3.0349185030947448

Epoch: 5| Step: 3
Training loss: 2.8475799560546875
Validation loss: 3.03110073971492

Epoch: 5| Step: 4
Training loss: 3.420367479324341
Validation loss: 3.009575359282955

Epoch: 5| Step: 5
Training loss: 3.190514087677002
Validation loss: 3.0041761526497464

Epoch: 5| Step: 6
Training loss: 2.7688791751861572
Validation loss: 3.0116884528949694

Epoch: 5| Step: 7
Training loss: 3.8166587352752686
Validation loss: 3.0077335808866765

Epoch: 5| Step: 8
Training loss: 2.7222769260406494
Validation loss: 2.9871349283443984

Epoch: 5| Step: 9
Training loss: 2.4743258953094482
Validation loss: 2.9743764836301088

Epoch: 5| Step: 10
Training loss: 2.9509029388427734
Validation loss: 2.9813400417245846

Epoch: 10| Step: 0
Training loss: 2.360159397125244
Validation loss: 2.9697689702433925

Epoch: 5| Step: 1
Training loss: 3.4313788414001465
Validation loss: 2.9617865598329933

Epoch: 5| Step: 2
Training loss: 2.8218495845794678
Validation loss: 2.9479063146857807

Epoch: 5| Step: 3
Training loss: 4.247837066650391
Validation loss: 2.941540038713845

Epoch: 5| Step: 4
Training loss: 2.6435365676879883
Validation loss: 2.9414634320043747

Epoch: 5| Step: 5
Training loss: 2.8849215507507324
Validation loss: 2.9368981674153316

Epoch: 5| Step: 6
Training loss: 2.1323859691619873
Validation loss: 2.9323694552144697

Epoch: 5| Step: 7
Training loss: 2.9981789588928223
Validation loss: 2.920685334872174

Epoch: 5| Step: 8
Training loss: 3.0421957969665527
Validation loss: 2.908997335741597

Epoch: 5| Step: 9
Training loss: 3.1577746868133545
Validation loss: 2.8975226956029094

Epoch: 5| Step: 10
Training loss: 3.6105170249938965
Validation loss: 2.8927308615817817

Epoch: 11| Step: 0
Training loss: 2.8913722038269043
Validation loss: 2.8899328913739932

Epoch: 5| Step: 1
Training loss: 3.9503560066223145
Validation loss: 2.887314716974894

Epoch: 5| Step: 2
Training loss: 3.3768157958984375
Validation loss: 2.86748605902477

Epoch: 5| Step: 3
Training loss: 4.192220211029053
Validation loss: 2.8646801876765426

Epoch: 5| Step: 4
Training loss: 2.419682264328003
Validation loss: 2.8649317269684165

Epoch: 5| Step: 5
Training loss: 2.595972776412964
Validation loss: 2.8496169608126403

Epoch: 5| Step: 6
Training loss: 2.2266030311584473
Validation loss: 2.8446904433670865

Epoch: 5| Step: 7
Training loss: 2.435753583908081
Validation loss: 2.8463132330166396

Epoch: 5| Step: 8
Training loss: 2.818941831588745
Validation loss: 2.8455141718669603

Epoch: 5| Step: 9
Training loss: 2.560492753982544
Validation loss: 2.846760695980441

Epoch: 5| Step: 10
Training loss: 3.302990198135376
Validation loss: 2.8433273761503157

Epoch: 12| Step: 0
Training loss: 3.0169684886932373
Validation loss: 2.8252488105527815

Epoch: 5| Step: 1
Training loss: 3.3694815635681152
Validation loss: 2.8172613036247993

Epoch: 5| Step: 2
Training loss: 2.5620663166046143
Validation loss: 2.8147738390071417

Epoch: 5| Step: 3
Training loss: 2.9545159339904785
Validation loss: 2.815918125132079

Epoch: 5| Step: 4
Training loss: 2.409712314605713
Validation loss: 2.811422594131962

Epoch: 5| Step: 5
Training loss: 2.9733686447143555
Validation loss: 2.8024838022006455

Epoch: 5| Step: 6
Training loss: 2.8667778968811035
Validation loss: 2.7951928082332818

Epoch: 5| Step: 7
Training loss: 3.4205169677734375
Validation loss: 2.7902711181230444

Epoch: 5| Step: 8
Training loss: 3.4966073036193848
Validation loss: 2.7838176245330484

Epoch: 5| Step: 9
Training loss: 2.4225101470947266
Validation loss: 2.7816374609547276

Epoch: 5| Step: 10
Training loss: 2.760160207748413
Validation loss: 2.795865381917646

Epoch: 13| Step: 0
Training loss: 2.2487990856170654
Validation loss: 2.792557603569441

Epoch: 5| Step: 1
Training loss: 3.0444858074188232
Validation loss: 2.765967094770042

Epoch: 5| Step: 2
Training loss: 2.7597432136535645
Validation loss: 2.760227862224784

Epoch: 5| Step: 3
Training loss: 3.453329086303711
Validation loss: 2.7626150526026243

Epoch: 5| Step: 4
Training loss: 1.9832082986831665
Validation loss: 2.7619401972780944

Epoch: 5| Step: 5
Training loss: 3.1136162281036377
Validation loss: 2.7633949684840378

Epoch: 5| Step: 6
Training loss: 3.5857994556427
Validation loss: 2.7543697408450547

Epoch: 5| Step: 7
Training loss: 2.7788093090057373
Validation loss: 2.7481590804233345

Epoch: 5| Step: 8
Training loss: 3.5475897789001465
Validation loss: 2.742559304801367

Epoch: 5| Step: 9
Training loss: 2.715928554534912
Validation loss: 2.736577031432941

Epoch: 5| Step: 10
Training loss: 2.7334303855895996
Validation loss: 2.7393783728281655

Epoch: 14| Step: 0
Training loss: 2.945960283279419
Validation loss: 2.737438976123769

Epoch: 5| Step: 1
Training loss: 2.9236087799072266
Validation loss: 2.7309608382563435

Epoch: 5| Step: 2
Training loss: 2.9490723609924316
Validation loss: 2.7274852183557328

Epoch: 5| Step: 3
Training loss: 3.8290295600891113
Validation loss: 2.7223206925135788

Epoch: 5| Step: 4
Training loss: 2.9857730865478516
Validation loss: 2.7212997867215063

Epoch: 5| Step: 5
Training loss: 2.794872522354126
Validation loss: 2.7195719108786633

Epoch: 5| Step: 6
Training loss: 2.432500123977661
Validation loss: 2.7134094058826403

Epoch: 5| Step: 7
Training loss: 2.97743821144104
Validation loss: 2.706148898729714

Epoch: 5| Step: 8
Training loss: 2.1977527141571045
Validation loss: 2.7040857884191696

Epoch: 5| Step: 9
Training loss: 3.3345751762390137
Validation loss: 2.703591567213817

Epoch: 5| Step: 10
Training loss: 2.217036008834839
Validation loss: 2.6960412456143286

Epoch: 15| Step: 0
Training loss: 2.673368453979492
Validation loss: 2.6940811731482066

Epoch: 5| Step: 1
Training loss: 2.30900502204895
Validation loss: 2.690821288734354

Epoch: 5| Step: 2
Training loss: 2.593975067138672
Validation loss: 2.6885598551842476

Epoch: 5| Step: 3
Training loss: 3.101156234741211
Validation loss: 2.682337996780231

Epoch: 5| Step: 4
Training loss: 3.042025566101074
Validation loss: 2.680390614335255

Epoch: 5| Step: 5
Training loss: 3.065143346786499
Validation loss: 2.690895449730658

Epoch: 5| Step: 6
Training loss: 3.0730690956115723
Validation loss: 2.690457372255223

Epoch: 5| Step: 7
Training loss: 2.7446093559265137
Validation loss: 2.6740833841344362

Epoch: 5| Step: 8
Training loss: 3.138817548751831
Validation loss: 2.6678061844200216

Epoch: 5| Step: 9
Training loss: 2.6095433235168457
Validation loss: 2.668257728699715

Epoch: 5| Step: 10
Training loss: 3.115565776824951
Validation loss: 2.673599120109312

Epoch: 16| Step: 0
Training loss: 2.5953383445739746
Validation loss: 2.669530940312211

Epoch: 5| Step: 1
Training loss: 3.1667699813842773
Validation loss: 2.665394631765222

Epoch: 5| Step: 2
Training loss: 3.049459457397461
Validation loss: 2.66107742504407

Epoch: 5| Step: 3
Training loss: 2.7817001342773438
Validation loss: 2.656774925929244

Epoch: 5| Step: 4
Training loss: 3.4017302989959717
Validation loss: 2.663869596296741

Epoch: 5| Step: 5
Training loss: 2.5539541244506836
Validation loss: 2.6732867815161265

Epoch: 5| Step: 6
Training loss: 2.648451089859009
Validation loss: 2.6702635877875873

Epoch: 5| Step: 7
Training loss: 2.63602614402771
Validation loss: 2.6701452578267744

Epoch: 5| Step: 8
Training loss: 2.579942226409912
Validation loss: 2.655398545726653

Epoch: 5| Step: 9
Training loss: 2.9852421283721924
Validation loss: 2.648848174720682

Epoch: 5| Step: 10
Training loss: 2.815567970275879
Validation loss: 2.64976845249053

Epoch: 17| Step: 0
Training loss: 2.6871485710144043
Validation loss: 2.651298394767187

Epoch: 5| Step: 1
Training loss: 3.103856325149536
Validation loss: 2.6488418271464687

Epoch: 5| Step: 2
Training loss: 3.2017123699188232
Validation loss: 2.638489520677956

Epoch: 5| Step: 3
Training loss: 2.973123073577881
Validation loss: 2.6346278446976856

Epoch: 5| Step: 4
Training loss: 3.0372493267059326
Validation loss: 2.641962230846446

Epoch: 5| Step: 5
Training loss: 2.860161304473877
Validation loss: 2.650942094864384

Epoch: 5| Step: 6
Training loss: 1.9826806783676147
Validation loss: 2.642960374073316

Epoch: 5| Step: 7
Training loss: 2.5784964561462402
Validation loss: 2.6349521298562326

Epoch: 5| Step: 8
Training loss: 2.654287338256836
Validation loss: 2.6278377732922955

Epoch: 5| Step: 9
Training loss: 3.154409170150757
Validation loss: 2.6267277848336006

Epoch: 5| Step: 10
Training loss: 2.817786455154419
Validation loss: 2.6216132922839095

Epoch: 18| Step: 0
Training loss: 2.7595489025115967
Validation loss: 2.6179198065111713

Epoch: 5| Step: 1
Training loss: 3.1950113773345947
Validation loss: 2.6233326337670766

Epoch: 5| Step: 2
Training loss: 3.427780866622925
Validation loss: 2.618068097740091

Epoch: 5| Step: 3
Training loss: 2.0740065574645996
Validation loss: 2.609849875973117

Epoch: 5| Step: 4
Training loss: 2.9630331993103027
Validation loss: 2.6116086949584303

Epoch: 5| Step: 5
Training loss: 3.296806812286377
Validation loss: 2.6173208964768278

Epoch: 5| Step: 6
Training loss: 2.4513299465179443
Validation loss: 2.61317285414665

Epoch: 5| Step: 7
Training loss: 3.1100049018859863
Validation loss: 2.6092420329329786

Epoch: 5| Step: 8
Training loss: 2.7499308586120605
Validation loss: 2.6059399574033675

Epoch: 5| Step: 9
Training loss: 2.3521921634674072
Validation loss: 2.605013111586212

Epoch: 5| Step: 10
Training loss: 2.4414331912994385
Validation loss: 2.603007936990389

Epoch: 19| Step: 0
Training loss: 2.7769861221313477
Validation loss: 2.606992265229584

Epoch: 5| Step: 1
Training loss: 2.671320676803589
Validation loss: 2.6009420297479116

Epoch: 5| Step: 2
Training loss: 2.8496451377868652
Validation loss: 2.6127129318893596

Epoch: 5| Step: 3
Training loss: 2.4855082035064697
Validation loss: 2.6118977659492084

Epoch: 5| Step: 4
Training loss: 2.958519697189331
Validation loss: 2.6182906935291905

Epoch: 5| Step: 5
Training loss: 3.0892255306243896
Validation loss: 2.6284803369993806

Epoch: 5| Step: 6
Training loss: 2.8567612171173096
Validation loss: 2.6100813265769713

Epoch: 5| Step: 7
Training loss: 3.1374449729919434
Validation loss: 2.607121916227443

Epoch: 5| Step: 8
Training loss: 3.173076868057251
Validation loss: 2.6175567129606843

Epoch: 5| Step: 9
Training loss: 2.3749654293060303
Validation loss: 2.5958573408024286

Epoch: 5| Step: 10
Training loss: 2.2896368503570557
Validation loss: 2.5932889394862677

Epoch: 20| Step: 0
Training loss: 2.5817654132843018
Validation loss: 2.5969145964550715

Epoch: 5| Step: 1
Training loss: 3.2409043312072754
Validation loss: 2.599389330033333

Epoch: 5| Step: 2
Training loss: 3.3534512519836426
Validation loss: 2.5909570135096067

Epoch: 5| Step: 3
Training loss: 2.7888448238372803
Validation loss: 2.5811181940058225

Epoch: 5| Step: 4
Training loss: 2.949622392654419
Validation loss: 2.5794294059917493

Epoch: 5| Step: 5
Training loss: 3.0775771141052246
Validation loss: 2.579324206998271

Epoch: 5| Step: 6
Training loss: 3.011491060256958
Validation loss: 2.585637643773069

Epoch: 5| Step: 7
Training loss: 2.5497663021087646
Validation loss: 2.5749036291594147

Epoch: 5| Step: 8
Training loss: 2.2582554817199707
Validation loss: 2.5650440236573577

Epoch: 5| Step: 9
Training loss: 2.024949550628662
Validation loss: 2.560355007007558

Epoch: 5| Step: 10
Training loss: 2.6734445095062256
Validation loss: 2.561581378342003

Epoch: 21| Step: 0
Training loss: 2.6023385524749756
Validation loss: 2.5641002962666173

Epoch: 5| Step: 1
Training loss: 3.2264914512634277
Validation loss: 2.5657063684155865

Epoch: 5| Step: 2
Training loss: 3.047712802886963
Validation loss: 2.560267330497824

Epoch: 5| Step: 3
Training loss: 2.842353105545044
Validation loss: 2.5601329982921643

Epoch: 5| Step: 4
Training loss: 2.585188150405884
Validation loss: 2.568573172374438

Epoch: 5| Step: 5
Training loss: 2.7429306507110596
Validation loss: 2.6292020582383677

Epoch: 5| Step: 6
Training loss: 2.826882839202881
Validation loss: 2.5992289256024104

Epoch: 5| Step: 7
Training loss: 2.499838352203369
Validation loss: 2.5586860077355498

Epoch: 5| Step: 8
Training loss: 2.7975566387176514
Validation loss: 2.5524317910594325

Epoch: 5| Step: 9
Training loss: 2.0154361724853516
Validation loss: 2.578434254533501

Epoch: 5| Step: 10
Training loss: 3.2979021072387695
Validation loss: 2.568610822000811

Epoch: 22| Step: 0
Training loss: 2.7691903114318848
Validation loss: 2.5583574336062194

Epoch: 5| Step: 1
Training loss: 2.8972134590148926
Validation loss: 2.5472075810996433

Epoch: 5| Step: 2
Training loss: 2.5797646045684814
Validation loss: 2.546026909223167

Epoch: 5| Step: 3
Training loss: 2.532085418701172
Validation loss: 2.5588632373399633

Epoch: 5| Step: 4
Training loss: 2.494950294494629
Validation loss: 2.570276911540698

Epoch: 5| Step: 5
Training loss: 3.2140870094299316
Validation loss: 2.5748400995808263

Epoch: 5| Step: 6
Training loss: 2.449939727783203
Validation loss: 2.5478301355915685

Epoch: 5| Step: 7
Training loss: 2.3430724143981934
Validation loss: 2.5370307378871466

Epoch: 5| Step: 8
Training loss: 2.736325263977051
Validation loss: 2.536158420706308

Epoch: 5| Step: 9
Training loss: 3.247218370437622
Validation loss: 2.539193784036944

Epoch: 5| Step: 10
Training loss: 3.0178771018981934
Validation loss: 2.5339343509366437

Epoch: 23| Step: 0
Training loss: 2.976290225982666
Validation loss: 2.5294252031592914

Epoch: 5| Step: 1
Training loss: 3.195070743560791
Validation loss: 2.525493429553124

Epoch: 5| Step: 2
Training loss: 1.9791921377182007
Validation loss: 2.529370971905288

Epoch: 5| Step: 3
Training loss: 3.0906260013580322
Validation loss: 2.5344915338741836

Epoch: 5| Step: 4
Training loss: 3.513803005218506
Validation loss: 2.530497602237168

Epoch: 5| Step: 5
Training loss: 2.9993577003479004
Validation loss: 2.5236932359715945

Epoch: 5| Step: 6
Training loss: 2.4490694999694824
Validation loss: 2.519846418852447

Epoch: 5| Step: 7
Training loss: 2.9047489166259766
Validation loss: 2.5248559931273102

Epoch: 5| Step: 8
Training loss: 2.9061179161071777
Validation loss: 2.5272584756215415

Epoch: 5| Step: 9
Training loss: 1.7460788488388062
Validation loss: 2.543008760739398

Epoch: 5| Step: 10
Training loss: 2.2716474533081055
Validation loss: 2.565464024902672

Epoch: 24| Step: 0
Training loss: 2.970181703567505
Validation loss: 2.557610939907771

Epoch: 5| Step: 1
Training loss: 2.2537384033203125
Validation loss: 2.5284250551654446

Epoch: 5| Step: 2
Training loss: 1.9051529169082642
Validation loss: 2.514116894814276

Epoch: 5| Step: 3
Training loss: 3.021893262863159
Validation loss: 2.5195544919660016

Epoch: 5| Step: 4
Training loss: 2.7987875938415527
Validation loss: 2.516027504397977

Epoch: 5| Step: 5
Training loss: 2.3928306102752686
Validation loss: 2.519255381758495

Epoch: 5| Step: 6
Training loss: 2.9718596935272217
Validation loss: 2.5203607569458666

Epoch: 5| Step: 7
Training loss: 3.038815975189209
Validation loss: 2.514342600299466

Epoch: 5| Step: 8
Training loss: 3.117767572402954
Validation loss: 2.5841343184953094

Epoch: 5| Step: 9
Training loss: 3.3788344860076904
Validation loss: 2.6098729051569456

Epoch: 5| Step: 10
Training loss: 2.207247257232666
Validation loss: 2.577113354077903

Epoch: 25| Step: 0
Training loss: 2.980799674987793
Validation loss: 2.571241342893211

Epoch: 5| Step: 1
Training loss: 3.333637237548828
Validation loss: 2.5674252792071273

Epoch: 5| Step: 2
Training loss: 2.155521869659424
Validation loss: 2.574808589873775

Epoch: 5| Step: 3
Training loss: 2.728041172027588
Validation loss: 2.5736554207340365

Epoch: 5| Step: 4
Training loss: 3.6551051139831543
Validation loss: 2.5716461391859156

Epoch: 5| Step: 5
Training loss: 2.4558968544006348
Validation loss: 2.570922323452529

Epoch: 5| Step: 6
Training loss: 2.4231460094451904
Validation loss: 2.564814712411614

Epoch: 5| Step: 7
Training loss: 2.660278081893921
Validation loss: 2.55946470076038

Epoch: 5| Step: 8
Training loss: 2.6439545154571533
Validation loss: 2.5588345963467836

Epoch: 5| Step: 9
Training loss: 2.4300341606140137
Validation loss: 2.555849234263102

Epoch: 5| Step: 10
Training loss: 2.8891489505767822
Validation loss: 2.55358870567814

Epoch: 26| Step: 0
Training loss: 2.4816575050354004
Validation loss: 2.5494100996243056

Epoch: 5| Step: 1
Training loss: 2.4844908714294434
Validation loss: 2.547434699150824

Epoch: 5| Step: 2
Training loss: 2.4373087882995605
Validation loss: 2.546348520504531

Epoch: 5| Step: 3
Training loss: 2.4518465995788574
Validation loss: 2.5474473737901255

Epoch: 5| Step: 4
Training loss: 2.200572967529297
Validation loss: 2.5357176103899555

Epoch: 5| Step: 5
Training loss: 3.7230095863342285
Validation loss: 2.516491154188751

Epoch: 5| Step: 6
Training loss: 3.141169309616089
Validation loss: 2.5211541216860534

Epoch: 5| Step: 7
Training loss: 3.0398521423339844
Validation loss: 2.541278085400981

Epoch: 5| Step: 8
Training loss: 2.436023235321045
Validation loss: 2.5239160804338354

Epoch: 5| Step: 9
Training loss: 2.8110644817352295
Validation loss: 2.496039390563965

Epoch: 5| Step: 10
Training loss: 2.6829323768615723
Validation loss: 2.4843498250489593

Epoch: 27| Step: 0
Training loss: 2.707165002822876
Validation loss: 2.5104267827926146

Epoch: 5| Step: 1
Training loss: 2.868539333343506
Validation loss: 2.496049032416395

Epoch: 5| Step: 2
Training loss: 2.7679598331451416
Validation loss: 2.4910377943387596

Epoch: 5| Step: 3
Training loss: 3.0431418418884277
Validation loss: 2.4814184916916715

Epoch: 5| Step: 4
Training loss: 2.6810302734375
Validation loss: 2.4778565283744567

Epoch: 5| Step: 5
Training loss: 2.48502779006958
Validation loss: 2.479001519500568

Epoch: 5| Step: 6
Training loss: 2.7427799701690674
Validation loss: 2.487887441471059

Epoch: 5| Step: 7
Training loss: 2.8307766914367676
Validation loss: 2.4893884863904727

Epoch: 5| Step: 8
Training loss: 3.2699928283691406
Validation loss: 2.4884098524688394

Epoch: 5| Step: 9
Training loss: 2.398533344268799
Validation loss: 2.4826260971766647

Epoch: 5| Step: 10
Training loss: 1.8534181118011475
Validation loss: 2.4988757487266295

Epoch: 28| Step: 0
Training loss: 3.036085605621338
Validation loss: 2.4810167743313696

Epoch: 5| Step: 1
Training loss: 3.167463779449463
Validation loss: 2.4767375146189043

Epoch: 5| Step: 2
Training loss: 3.425199508666992
Validation loss: 2.471502255367976

Epoch: 5| Step: 3
Training loss: 3.2467474937438965
Validation loss: 2.466377640283236

Epoch: 5| Step: 4
Training loss: 1.983694076538086
Validation loss: 2.462430751451882

Epoch: 5| Step: 5
Training loss: 2.6297590732574463
Validation loss: 2.4581132883666665

Epoch: 5| Step: 6
Training loss: 2.1625499725341797
Validation loss: 2.46407784569648

Epoch: 5| Step: 7
Training loss: 1.9401811361312866
Validation loss: 2.4733407061587096

Epoch: 5| Step: 8
Training loss: 2.9482803344726562
Validation loss: 2.4692230198972966

Epoch: 5| Step: 9
Training loss: 2.4854819774627686
Validation loss: 2.464512255883986

Epoch: 5| Step: 10
Training loss: 2.469911575317383
Validation loss: 2.461421553806592

Epoch: 29| Step: 0
Training loss: 2.2778377532958984
Validation loss: 2.4607513668716594

Epoch: 5| Step: 1
Training loss: 3.1142361164093018
Validation loss: 2.4577764490599274

Epoch: 5| Step: 2
Training loss: 2.284177303314209
Validation loss: 2.4594847233064714

Epoch: 5| Step: 3
Training loss: 2.187157154083252
Validation loss: 2.4487465991768786

Epoch: 5| Step: 4
Training loss: 2.5738184452056885
Validation loss: 2.4525862624568324

Epoch: 5| Step: 5
Training loss: 2.0468039512634277
Validation loss: 2.4643967715642785

Epoch: 5| Step: 6
Training loss: 3.4858856201171875
Validation loss: 2.46148488085757

Epoch: 5| Step: 7
Training loss: 3.8145031929016113
Validation loss: 2.469557874946184

Epoch: 5| Step: 8
Training loss: 2.5718376636505127
Validation loss: 2.4555926861301547

Epoch: 5| Step: 9
Training loss: 2.608039379119873
Validation loss: 2.443169932211599

Epoch: 5| Step: 10
Training loss: 2.4635441303253174
Validation loss: 2.442219211209205

Epoch: 30| Step: 0
Training loss: 2.5574803352355957
Validation loss: 2.443420548592844

Epoch: 5| Step: 1
Training loss: 2.915910243988037
Validation loss: 2.441086487103534

Epoch: 5| Step: 2
Training loss: 2.16586971282959
Validation loss: 2.4417445762183076

Epoch: 5| Step: 3
Training loss: 3.6189045906066895
Validation loss: 2.445027429570434

Epoch: 5| Step: 4
Training loss: 2.348813533782959
Validation loss: 2.4470380506207867

Epoch: 5| Step: 5
Training loss: 3.090226173400879
Validation loss: 2.4593957726673414

Epoch: 5| Step: 6
Training loss: 2.8657004833221436
Validation loss: 2.4753626905461794

Epoch: 5| Step: 7
Training loss: 2.3611855506896973
Validation loss: 2.4751758178075156

Epoch: 5| Step: 8
Training loss: 2.607374429702759
Validation loss: 2.454945166905721

Epoch: 5| Step: 9
Training loss: 2.6305251121520996
Validation loss: 2.452689447710591

Epoch: 5| Step: 10
Training loss: 2.15462327003479
Validation loss: 2.4524593609635548

Epoch: 31| Step: 0
Training loss: 1.982172966003418
Validation loss: 2.471816301345825

Epoch: 5| Step: 1
Training loss: 2.589231014251709
Validation loss: 2.4723467288478727

Epoch: 5| Step: 2
Training loss: 2.8752245903015137
Validation loss: 2.4723595598692536

Epoch: 5| Step: 3
Training loss: 3.0479252338409424
Validation loss: 2.4564673003330024

Epoch: 5| Step: 4
Training loss: 2.929295778274536
Validation loss: 2.4319010139793478

Epoch: 5| Step: 5
Training loss: 2.8210599422454834
Validation loss: 2.4269666005206365

Epoch: 5| Step: 6
Training loss: 2.395454168319702
Validation loss: 2.4304452250080724

Epoch: 5| Step: 7
Training loss: 2.5652356147766113
Validation loss: 2.443707399470832

Epoch: 5| Step: 8
Training loss: 2.834538221359253
Validation loss: 2.443166176478068

Epoch: 5| Step: 9
Training loss: 2.5229532718658447
Validation loss: 2.42911797185098

Epoch: 5| Step: 10
Training loss: 2.9275319576263428
Validation loss: 2.4190810982899

Epoch: 32| Step: 0
Training loss: 1.802075743675232
Validation loss: 2.4723877624798845

Epoch: 5| Step: 1
Training loss: 2.5344669818878174
Validation loss: 2.56223887525579

Epoch: 5| Step: 2
Training loss: 2.7297658920288086
Validation loss: 2.6310920612786406

Epoch: 5| Step: 3
Training loss: 2.564746379852295
Validation loss: 2.6419372904685234

Epoch: 5| Step: 4
Training loss: 3.0815582275390625
Validation loss: 2.5790536198564755

Epoch: 5| Step: 5
Training loss: 3.032759189605713
Validation loss: 2.518521390935426

Epoch: 5| Step: 6
Training loss: 2.8137917518615723
Validation loss: 2.490156712070588

Epoch: 5| Step: 7
Training loss: 2.6402268409729004
Validation loss: 2.4839317055158716

Epoch: 5| Step: 8
Training loss: 2.9059903621673584
Validation loss: 2.482910651032643

Epoch: 5| Step: 9
Training loss: 2.4705753326416016
Validation loss: 2.4550370375315347

Epoch: 5| Step: 10
Training loss: 3.6600289344787598
Validation loss: 2.476942095705258

Epoch: 33| Step: 0
Training loss: 2.605135440826416
Validation loss: 2.4535698916322444

Epoch: 5| Step: 1
Training loss: 2.6127490997314453
Validation loss: 2.4221990159762803

Epoch: 5| Step: 2
Training loss: 2.351091146469116
Validation loss: 2.411986986796061

Epoch: 5| Step: 3
Training loss: 2.363029718399048
Validation loss: 2.4179159184937835

Epoch: 5| Step: 4
Training loss: 2.9429521560668945
Validation loss: 2.4489486294408

Epoch: 5| Step: 5
Training loss: 2.1350059509277344
Validation loss: 2.511773306836364

Epoch: 5| Step: 6
Training loss: 2.8061490058898926
Validation loss: 2.5744215826834402

Epoch: 5| Step: 7
Training loss: 3.002201557159424
Validation loss: 2.6035246592695995

Epoch: 5| Step: 8
Training loss: 2.9381937980651855
Validation loss: 2.5780717942022506

Epoch: 5| Step: 9
Training loss: 2.7916905879974365
Validation loss: 2.5016143527082217

Epoch: 5| Step: 10
Training loss: 3.2408456802368164
Validation loss: 2.445056794792093

Epoch: 34| Step: 0
Training loss: 2.0851993560791016
Validation loss: 2.426305527328163

Epoch: 5| Step: 1
Training loss: 3.030390977859497
Validation loss: 2.4280028112473024

Epoch: 5| Step: 2
Training loss: 2.676499843597412
Validation loss: 2.4425470290645475

Epoch: 5| Step: 3
Training loss: 3.340256929397583
Validation loss: 2.45089558375779

Epoch: 5| Step: 4
Training loss: 2.5075936317443848
Validation loss: 2.4397850062257502

Epoch: 5| Step: 5
Training loss: 2.9436194896698
Validation loss: 2.4243375742307274

Epoch: 5| Step: 6
Training loss: 3.002026081085205
Validation loss: 2.406903402779692

Epoch: 5| Step: 7
Training loss: 2.2493972778320312
Validation loss: 2.4053725324651247

Epoch: 5| Step: 8
Training loss: 2.1703600883483887
Validation loss: 2.4099032853239324

Epoch: 5| Step: 9
Training loss: 3.1190078258514404
Validation loss: 2.4414421025142876

Epoch: 5| Step: 10
Training loss: 2.345874547958374
Validation loss: 2.4387988300733667

Epoch: 35| Step: 0
Training loss: 2.503073215484619
Validation loss: 2.4239864349365234

Epoch: 5| Step: 1
Training loss: 3.039565324783325
Validation loss: 2.4077825443719023

Epoch: 5| Step: 2
Training loss: 2.9691412448883057
Validation loss: 2.398287332186135

Epoch: 5| Step: 3
Training loss: 2.646256923675537
Validation loss: 2.4110228771804483

Epoch: 5| Step: 4
Training loss: 3.0363566875457764
Validation loss: 2.4664355234433244

Epoch: 5| Step: 5
Training loss: 2.674257278442383
Validation loss: 2.4208794434865317

Epoch: 5| Step: 6
Training loss: 2.623969316482544
Validation loss: 2.409175120374208

Epoch: 5| Step: 7
Training loss: 2.064120292663574
Validation loss: 2.4138497306454565

Epoch: 5| Step: 8
Training loss: 2.196730136871338
Validation loss: 2.4166781671585573

Epoch: 5| Step: 9
Training loss: 2.8413808345794678
Validation loss: 2.434393172623009

Epoch: 5| Step: 10
Training loss: 2.660207509994507
Validation loss: 2.4178171978201917

Epoch: 36| Step: 0
Training loss: 3.0000879764556885
Validation loss: 2.410729815883021

Epoch: 5| Step: 1
Training loss: 3.152794599533081
Validation loss: 2.4079712411408782

Epoch: 5| Step: 2
Training loss: 2.451349973678589
Validation loss: 2.4070612256244948

Epoch: 5| Step: 3
Training loss: 2.5789947509765625
Validation loss: 2.405807392571562

Epoch: 5| Step: 4
Training loss: 2.799936294555664
Validation loss: 2.4143159722769134

Epoch: 5| Step: 5
Training loss: 2.6413357257843018
Validation loss: 2.4095785335827897

Epoch: 5| Step: 6
Training loss: 2.0164036750793457
Validation loss: 2.4164165989045174

Epoch: 5| Step: 7
Training loss: 2.3146026134490967
Validation loss: 2.4178661556654077

Epoch: 5| Step: 8
Training loss: 3.439493179321289
Validation loss: 2.413184235172887

Epoch: 5| Step: 9
Training loss: 2.845022678375244
Validation loss: 2.4130660308304654

Epoch: 5| Step: 10
Training loss: 1.7786414623260498
Validation loss: 2.4050601220900014

Epoch: 37| Step: 0
Training loss: 2.236191987991333
Validation loss: 2.4103699550833753

Epoch: 5| Step: 1
Training loss: 2.835282325744629
Validation loss: 2.4005056299189085

Epoch: 5| Step: 2
Training loss: 2.433304786682129
Validation loss: 2.3910473521037767

Epoch: 5| Step: 3
Training loss: 2.983211040496826
Validation loss: 2.3866036322809037

Epoch: 5| Step: 4
Training loss: 2.587721824645996
Validation loss: 2.3829954747230775

Epoch: 5| Step: 5
Training loss: 2.894981861114502
Validation loss: 2.3829462912774857

Epoch: 5| Step: 6
Training loss: 2.7988650798797607
Validation loss: 2.378791255335654

Epoch: 5| Step: 7
Training loss: 2.6848771572113037
Validation loss: 2.382219483775477

Epoch: 5| Step: 8
Training loss: 2.5109996795654297
Validation loss: 2.3899699052174888

Epoch: 5| Step: 9
Training loss: 3.028719902038574
Validation loss: 2.4066130858595653

Epoch: 5| Step: 10
Training loss: 1.9791959524154663
Validation loss: 2.4669783551205873

Epoch: 38| Step: 0
Training loss: 2.578693389892578
Validation loss: 2.478159127696868

Epoch: 5| Step: 1
Training loss: 2.2588515281677246
Validation loss: 2.417343903613347

Epoch: 5| Step: 2
Training loss: 2.4565305709838867
Validation loss: 2.407761746837247

Epoch: 5| Step: 3
Training loss: 2.497737407684326
Validation loss: 2.3972627667970556

Epoch: 5| Step: 4
Training loss: 1.9131278991699219
Validation loss: 2.3942747423725743

Epoch: 5| Step: 5
Training loss: 2.7047977447509766
Validation loss: 2.399780701565486

Epoch: 5| Step: 6
Training loss: 3.0543861389160156
Validation loss: 2.4108508222846576

Epoch: 5| Step: 7
Training loss: 3.3245887756347656
Validation loss: 2.43073776460463

Epoch: 5| Step: 8
Training loss: 2.815753698348999
Validation loss: 2.4504911027928835

Epoch: 5| Step: 9
Training loss: 2.705220937728882
Validation loss: 2.4063098020451044

Epoch: 5| Step: 10
Training loss: 2.9807002544403076
Validation loss: 2.3944623470306396

Epoch: 39| Step: 0
Training loss: 2.635789394378662
Validation loss: 2.380844428975095

Epoch: 5| Step: 1
Training loss: 2.8244469165802
Validation loss: 2.380430375376055

Epoch: 5| Step: 2
Training loss: 2.611950159072876
Validation loss: 2.3771887594653713

Epoch: 5| Step: 3
Training loss: 2.8791539669036865
Validation loss: 2.3779963857384137

Epoch: 5| Step: 4
Training loss: 2.2290000915527344
Validation loss: 2.3963395472495788

Epoch: 5| Step: 5
Training loss: 2.5430092811584473
Validation loss: 2.3889786992021786

Epoch: 5| Step: 6
Training loss: 2.363670587539673
Validation loss: 2.3803815482765116

Epoch: 5| Step: 7
Training loss: 3.214639663696289
Validation loss: 2.3955687361378826

Epoch: 5| Step: 8
Training loss: 2.909823417663574
Validation loss: 2.409507748901203

Epoch: 5| Step: 9
Training loss: 2.4743971824645996
Validation loss: 2.421240137469384

Epoch: 5| Step: 10
Training loss: 2.2802698612213135
Validation loss: 2.4337942010612896

Epoch: 40| Step: 0
Training loss: 2.913419246673584
Validation loss: 2.4493516337487007

Epoch: 5| Step: 1
Training loss: 3.0283522605895996
Validation loss: 2.419372789321407

Epoch: 5| Step: 2
Training loss: 2.5850424766540527
Validation loss: 2.3867863224398707

Epoch: 5| Step: 3
Training loss: 1.8867286443710327
Validation loss: 2.3716430728153517

Epoch: 5| Step: 4
Training loss: 2.773585796356201
Validation loss: 2.362112340106759

Epoch: 5| Step: 5
Training loss: 2.948697328567505
Validation loss: 2.356224859914472

Epoch: 5| Step: 6
Training loss: 2.3893446922302246
Validation loss: 2.358607594684888

Epoch: 5| Step: 7
Training loss: 2.7583301067352295
Validation loss: 2.356996087617772

Epoch: 5| Step: 8
Training loss: 2.5578842163085938
Validation loss: 2.3560028153081096

Epoch: 5| Step: 9
Training loss: 2.4980387687683105
Validation loss: 2.3596641017544653

Epoch: 5| Step: 10
Training loss: 2.6047916412353516
Validation loss: 2.351495571033929

Epoch: 41| Step: 0
Training loss: 2.8225655555725098
Validation loss: 2.352789835263324

Epoch: 5| Step: 1
Training loss: 2.3359391689300537
Validation loss: 2.3520390359304284

Epoch: 5| Step: 2
Training loss: 2.7571353912353516
Validation loss: 2.353768999858569

Epoch: 5| Step: 3
Training loss: 2.2478575706481934
Validation loss: 2.3550464312235513

Epoch: 5| Step: 4
Training loss: 2.2894175052642822
Validation loss: 2.348536617012434

Epoch: 5| Step: 5
Training loss: 2.6274545192718506
Validation loss: 2.347491228452293

Epoch: 5| Step: 6
Training loss: 3.044696569442749
Validation loss: 2.3487885639231694

Epoch: 5| Step: 7
Training loss: 2.549349546432495
Validation loss: 2.352824339302637

Epoch: 5| Step: 8
Training loss: 2.6534066200256348
Validation loss: 2.3564983337156233

Epoch: 5| Step: 9
Training loss: 2.5545032024383545
Validation loss: 2.3597069478804067

Epoch: 5| Step: 10
Training loss: 3.0326480865478516
Validation loss: 2.3637500450175297

Epoch: 42| Step: 0
Training loss: 2.473034381866455
Validation loss: 2.3546882265357563

Epoch: 5| Step: 1
Training loss: 1.979434609413147
Validation loss: 2.3462884310753114

Epoch: 5| Step: 2
Training loss: 2.4754621982574463
Validation loss: 2.3359949063229304

Epoch: 5| Step: 3
Training loss: 2.215524435043335
Validation loss: 2.3372011671784105

Epoch: 5| Step: 4
Training loss: 2.4759016036987305
Validation loss: 2.333965511732204

Epoch: 5| Step: 5
Training loss: 2.672816514968872
Validation loss: 2.3330649816861717

Epoch: 5| Step: 6
Training loss: 3.333798885345459
Validation loss: 2.331573035127373

Epoch: 5| Step: 7
Training loss: 2.4314348697662354
Validation loss: 2.3383784358219435

Epoch: 5| Step: 8
Training loss: 2.708085536956787
Validation loss: 2.3498060241822274

Epoch: 5| Step: 9
Training loss: 2.9094347953796387
Validation loss: 2.3610118127638295

Epoch: 5| Step: 10
Training loss: 3.116752862930298
Validation loss: 2.3676023919095277

Epoch: 43| Step: 0
Training loss: 2.4729318618774414
Validation loss: 2.382911987202142

Epoch: 5| Step: 1
Training loss: 3.1197633743286133
Validation loss: 2.408947983095723

Epoch: 5| Step: 2
Training loss: 1.919630765914917
Validation loss: 2.389262722384545

Epoch: 5| Step: 3
Training loss: 2.1748223304748535
Validation loss: 2.3647234414213445

Epoch: 5| Step: 4
Training loss: 2.988147258758545
Validation loss: 2.3495795854958157

Epoch: 5| Step: 5
Training loss: 3.1348557472229004
Validation loss: 2.337320081649288

Epoch: 5| Step: 6
Training loss: 2.913583278656006
Validation loss: 2.325830195539741

Epoch: 5| Step: 7
Training loss: 2.742661237716675
Validation loss: 2.3247072030139226

Epoch: 5| Step: 8
Training loss: 2.6074461936950684
Validation loss: 2.319503063796669

Epoch: 5| Step: 9
Training loss: 2.00044322013855
Validation loss: 2.320752771951819

Epoch: 5| Step: 10
Training loss: 2.558415174484253
Validation loss: 2.3191591488417758

Epoch: 44| Step: 0
Training loss: 2.308063507080078
Validation loss: 2.315190343446629

Epoch: 5| Step: 1
Training loss: 2.491820812225342
Validation loss: 2.3120225860226538

Epoch: 5| Step: 2
Training loss: 2.3198840618133545
Validation loss: 2.3080990570847706

Epoch: 5| Step: 3
Training loss: 2.4050545692443848
Validation loss: 2.3146268090894146

Epoch: 5| Step: 4
Training loss: 3.138733386993408
Validation loss: 2.3296886515873734

Epoch: 5| Step: 5
Training loss: 2.537015438079834
Validation loss: 2.3395970739344114

Epoch: 5| Step: 6
Training loss: 2.949988603591919
Validation loss: 2.3503972920038367

Epoch: 5| Step: 7
Training loss: 2.312788486480713
Validation loss: 2.3524512347354682

Epoch: 5| Step: 8
Training loss: 3.040695905685425
Validation loss: 2.364418347676595

Epoch: 5| Step: 9
Training loss: 2.131638288497925
Validation loss: 2.354525181554979

Epoch: 5| Step: 10
Training loss: 2.935741424560547
Validation loss: 2.3466691560642694

Epoch: 45| Step: 0
Training loss: 2.921255588531494
Validation loss: 2.3388336345713627

Epoch: 5| Step: 1
Training loss: 2.9232699871063232
Validation loss: 2.3173760367978002

Epoch: 5| Step: 2
Training loss: 2.06630277633667
Validation loss: 2.3002577366367465

Epoch: 5| Step: 3
Training loss: 2.000861883163452
Validation loss: 2.290311421117475

Epoch: 5| Step: 4
Training loss: 2.67692232131958
Validation loss: 2.29322600236503

Epoch: 5| Step: 5
Training loss: 2.4802258014678955
Validation loss: 2.295602479288655

Epoch: 5| Step: 6
Training loss: 2.595534086227417
Validation loss: 2.297865080577071

Epoch: 5| Step: 7
Training loss: 2.6154227256774902
Validation loss: 2.2909189142206663

Epoch: 5| Step: 8
Training loss: 3.213331937789917
Validation loss: 2.285096632537021

Epoch: 5| Step: 9
Training loss: 2.391986846923828
Validation loss: 2.283154328664144

Epoch: 5| Step: 10
Training loss: 2.5180768966674805
Validation loss: 2.280164485336632

Epoch: 46| Step: 0
Training loss: 3.0658462047576904
Validation loss: 2.276301316035691

Epoch: 5| Step: 1
Training loss: 3.041461944580078
Validation loss: 2.2783490534751647

Epoch: 5| Step: 2
Training loss: 2.797887086868286
Validation loss: 2.2826118751238753

Epoch: 5| Step: 3
Training loss: 2.091911554336548
Validation loss: 2.2886066218858123

Epoch: 5| Step: 4
Training loss: 2.2050881385803223
Validation loss: 2.2951505414901243

Epoch: 5| Step: 5
Training loss: 2.6882615089416504
Validation loss: 2.2876893448573288

Epoch: 5| Step: 6
Training loss: 2.2501296997070312
Validation loss: 2.305036924218619

Epoch: 5| Step: 7
Training loss: 2.33355975151062
Validation loss: 2.3160254109290337

Epoch: 5| Step: 8
Training loss: 2.5750582218170166
Validation loss: 2.323298497866559

Epoch: 5| Step: 9
Training loss: 3.0485575199127197
Validation loss: 2.3188309259312128

Epoch: 5| Step: 10
Training loss: 2.0862090587615967
Validation loss: 2.307561764153101

Epoch: 47| Step: 0
Training loss: 2.8674263954162598
Validation loss: 2.29168346107647

Epoch: 5| Step: 1
Training loss: 2.8581032752990723
Validation loss: 2.274145339124946

Epoch: 5| Step: 2
Training loss: 2.8247218132019043
Validation loss: 2.271285544159592

Epoch: 5| Step: 3
Training loss: 2.535459518432617
Validation loss: 2.2665853551639024

Epoch: 5| Step: 4
Training loss: 2.673306703567505
Validation loss: 2.2704289215867237

Epoch: 5| Step: 5
Training loss: 2.598259687423706
Validation loss: 2.2747827447870725

Epoch: 5| Step: 6
Training loss: 2.0297203063964844
Validation loss: 2.272698171677128

Epoch: 5| Step: 7
Training loss: 2.7663967609405518
Validation loss: 2.273317306272445

Epoch: 5| Step: 8
Training loss: 2.468057155609131
Validation loss: 2.2798362342260217

Epoch: 5| Step: 9
Training loss: 2.336298704147339
Validation loss: 2.302205357500302

Epoch: 5| Step: 10
Training loss: 2.183539867401123
Validation loss: 2.3198157125903713

Epoch: 48| Step: 0
Training loss: 2.2650461196899414
Validation loss: 2.335621928655973

Epoch: 5| Step: 1
Training loss: 3.292719602584839
Validation loss: 2.366097040073846

Epoch: 5| Step: 2
Training loss: 2.2290456295013428
Validation loss: 2.3744425978711856

Epoch: 5| Step: 3
Training loss: 2.887392997741699
Validation loss: 2.366254004099036

Epoch: 5| Step: 4
Training loss: 2.109152317047119
Validation loss: 2.337138573328654

Epoch: 5| Step: 5
Training loss: 2.5634570121765137
Validation loss: 2.3123313842281217

Epoch: 5| Step: 6
Training loss: 2.6318211555480957
Validation loss: 2.276298963895408

Epoch: 5| Step: 7
Training loss: 2.675349473953247
Validation loss: 2.2580809670109905

Epoch: 5| Step: 8
Training loss: 2.806331157684326
Validation loss: 2.2635364942653204

Epoch: 5| Step: 9
Training loss: 2.0463643074035645
Validation loss: 2.2669918998595207

Epoch: 5| Step: 10
Training loss: 2.789060592651367
Validation loss: 2.280168964016822

Epoch: 49| Step: 0
Training loss: 2.96964955329895
Validation loss: 2.3045696545672674

Epoch: 5| Step: 1
Training loss: 3.3428237438201904
Validation loss: 2.290910323460897

Epoch: 5| Step: 2
Training loss: 2.4215750694274902
Validation loss: 2.2644302909092238

Epoch: 5| Step: 3
Training loss: 2.090289831161499
Validation loss: 2.260874027846962

Epoch: 5| Step: 4
Training loss: 2.1474506855010986
Validation loss: 2.2946335833559752

Epoch: 5| Step: 5
Training loss: 2.7606754302978516
Validation loss: 2.3550843243957846

Epoch: 5| Step: 6
Training loss: 2.525416851043701
Validation loss: 2.3882356023275726

Epoch: 5| Step: 7
Training loss: 3.0491058826446533
Validation loss: 2.327623946692354

Epoch: 5| Step: 8
Training loss: 2.2258334159851074
Validation loss: 2.2860279698525705

Epoch: 5| Step: 9
Training loss: 2.8047373294830322
Validation loss: 2.254646449960688

Epoch: 5| Step: 10
Training loss: 2.279285192489624
Validation loss: 2.2477354695720058

Epoch: 50| Step: 0
Training loss: 2.223212480545044
Validation loss: 2.257941786960889

Epoch: 5| Step: 1
Training loss: 2.761735200881958
Validation loss: 2.2609460302578506

Epoch: 5| Step: 2
Training loss: 2.8482871055603027
Validation loss: 2.2617679308819514

Epoch: 5| Step: 3
Training loss: 2.2897584438323975
Validation loss: 2.2590487567327355

Epoch: 5| Step: 4
Training loss: 2.5734758377075195
Validation loss: 2.2621536626610705

Epoch: 5| Step: 5
Training loss: 2.9378418922424316
Validation loss: 2.2558681554691766

Epoch: 5| Step: 6
Training loss: 2.8008875846862793
Validation loss: 2.2490713083615868

Epoch: 5| Step: 7
Training loss: 2.3768815994262695
Validation loss: 2.2442780669017504

Epoch: 5| Step: 8
Training loss: 2.1617445945739746
Validation loss: 2.239758817098474

Epoch: 5| Step: 9
Training loss: 2.5652096271514893
Validation loss: 2.2612454968114055

Epoch: 5| Step: 10
Training loss: 2.7463696002960205
Validation loss: 2.3029372948472218

Epoch: 51| Step: 0
Training loss: 2.8627090454101562
Validation loss: 2.3173371335511566

Epoch: 5| Step: 1
Training loss: 2.5247414112091064
Validation loss: 2.2950626573254986

Epoch: 5| Step: 2
Training loss: 2.5688273906707764
Validation loss: 2.2813444547755743

Epoch: 5| Step: 3
Training loss: 2.421034574508667
Validation loss: 2.2754374986053794

Epoch: 5| Step: 4
Training loss: 2.461275100708008
Validation loss: 2.2823747396469116

Epoch: 5| Step: 5
Training loss: 2.62520432472229
Validation loss: 2.2785416315960627

Epoch: 5| Step: 6
Training loss: 2.854142427444458
Validation loss: 2.283364580523583

Epoch: 5| Step: 7
Training loss: 2.280411958694458
Validation loss: 2.2800571815941924

Epoch: 5| Step: 8
Training loss: 2.4470949172973633
Validation loss: 2.256537566902817

Epoch: 5| Step: 9
Training loss: 2.7602486610412598
Validation loss: 2.2428108389659593

Epoch: 5| Step: 10
Training loss: 2.193707227706909
Validation loss: 2.2397578429150324

Epoch: 52| Step: 0
Training loss: 2.427577257156372
Validation loss: 2.2366646002697688

Epoch: 5| Step: 1
Training loss: 2.42581844329834
Validation loss: 2.2479710322554394

Epoch: 5| Step: 2
Training loss: 2.595247983932495
Validation loss: 2.2511888883447133

Epoch: 5| Step: 3
Training loss: 2.1130881309509277
Validation loss: 2.2448310467504684

Epoch: 5| Step: 4
Training loss: 2.7747089862823486
Validation loss: 2.235022552551762

Epoch: 5| Step: 5
Training loss: 3.132209300994873
Validation loss: 2.2383354697176205

Epoch: 5| Step: 6
Training loss: 1.9851369857788086
Validation loss: 2.2381608921994447

Epoch: 5| Step: 7
Training loss: 2.565645217895508
Validation loss: 2.244071283648091

Epoch: 5| Step: 8
Training loss: 2.628051280975342
Validation loss: 2.2466167147441576

Epoch: 5| Step: 9
Training loss: 2.309321403503418
Validation loss: 2.2462239906352055

Epoch: 5| Step: 10
Training loss: 3.0059356689453125
Validation loss: 2.2538809942942795

Epoch: 53| Step: 0
Training loss: 2.6058807373046875
Validation loss: 2.2753881498049666

Epoch: 5| Step: 1
Training loss: 3.1255106925964355
Validation loss: 2.2729471755284134

Epoch: 5| Step: 2
Training loss: 3.410700559616089
Validation loss: 2.241020523091798

Epoch: 5| Step: 3
Training loss: 2.7559752464294434
Validation loss: 2.230708824690952

Epoch: 5| Step: 4
Training loss: 2.0897114276885986
Validation loss: 2.2264966785266833

Epoch: 5| Step: 5
Training loss: 2.615055799484253
Validation loss: 2.2223591445594706

Epoch: 5| Step: 6
Training loss: 2.985785961151123
Validation loss: 2.2224239841584237

Epoch: 5| Step: 7
Training loss: 1.9226024150848389
Validation loss: 2.218718067292244

Epoch: 5| Step: 8
Training loss: 1.816306471824646
Validation loss: 2.224486676595544

Epoch: 5| Step: 9
Training loss: 2.4740777015686035
Validation loss: 2.226308468849428

Epoch: 5| Step: 10
Training loss: 2.1480627059936523
Validation loss: 2.2234277238128004

Epoch: 54| Step: 0
Training loss: 2.7633094787597656
Validation loss: 2.2241023689187984

Epoch: 5| Step: 1
Training loss: 3.0213398933410645
Validation loss: 2.2310719631051503

Epoch: 5| Step: 2
Training loss: 2.0825133323669434
Validation loss: 2.243286976250269

Epoch: 5| Step: 3
Training loss: 3.2232558727264404
Validation loss: 2.2518242110488234

Epoch: 5| Step: 4
Training loss: 1.7950493097305298
Validation loss: 2.248596501606767

Epoch: 5| Step: 5
Training loss: 2.672630786895752
Validation loss: 2.2485363765429427

Epoch: 5| Step: 6
Training loss: 2.4667725563049316
Validation loss: 2.233436369126843

Epoch: 5| Step: 7
Training loss: 2.8993287086486816
Validation loss: 2.2197103782366683

Epoch: 5| Step: 8
Training loss: 2.57631254196167
Validation loss: 2.2150744392025854

Epoch: 5| Step: 9
Training loss: 2.096088171005249
Validation loss: 2.2177294146630073

Epoch: 5| Step: 10
Training loss: 2.2647504806518555
Validation loss: 2.2183896700541177

Epoch: 55| Step: 0
Training loss: 2.592728853225708
Validation loss: 2.220792757567539

Epoch: 5| Step: 1
Training loss: 2.743940830230713
Validation loss: 2.2219793360720397

Epoch: 5| Step: 2
Training loss: 2.9688708782196045
Validation loss: 2.2213730581345095

Epoch: 5| Step: 3
Training loss: 2.341723680496216
Validation loss: 2.218561557031447

Epoch: 5| Step: 4
Training loss: 2.3260321617126465
Validation loss: 2.21690006666286

Epoch: 5| Step: 5
Training loss: 2.7614283561706543
Validation loss: 2.2130587946984077

Epoch: 5| Step: 6
Training loss: 2.368055582046509
Validation loss: 2.2112221128197125

Epoch: 5| Step: 7
Training loss: 2.454681873321533
Validation loss: 2.213824672083701

Epoch: 5| Step: 8
Training loss: 2.534278154373169
Validation loss: 2.2221564118580153

Epoch: 5| Step: 9
Training loss: 2.214043378829956
Validation loss: 2.256788302493352

Epoch: 5| Step: 10
Training loss: 2.514852523803711
Validation loss: 2.27728396461856

Epoch: 56| Step: 0
Training loss: 2.5761911869049072
Validation loss: 2.2944876070945495

Epoch: 5| Step: 1
Training loss: 2.040038585662842
Validation loss: 2.297294242407686

Epoch: 5| Step: 2
Training loss: 2.956923246383667
Validation loss: 2.3488983441424627

Epoch: 5| Step: 3
Training loss: 2.5601587295532227
Validation loss: 2.311423276060371

Epoch: 5| Step: 4
Training loss: 2.65362548828125
Validation loss: 2.2838950592984437

Epoch: 5| Step: 5
Training loss: 2.588688373565674
Validation loss: 2.2407550478494294

Epoch: 5| Step: 6
Training loss: 2.441378116607666
Validation loss: 2.2273089821620653

Epoch: 5| Step: 7
Training loss: 2.7384326457977295
Validation loss: 2.2164105074380034

Epoch: 5| Step: 8
Training loss: 2.436408519744873
Validation loss: 2.2125766354222454

Epoch: 5| Step: 9
Training loss: 2.286288261413574
Validation loss: 2.209568864555769

Epoch: 5| Step: 10
Training loss: 2.4591119289398193
Validation loss: 2.209577070769443

Epoch: 57| Step: 0
Training loss: 2.022724151611328
Validation loss: 2.2075961443685714

Epoch: 5| Step: 1
Training loss: 2.6588072776794434
Validation loss: 2.2131569821347474

Epoch: 5| Step: 2
Training loss: 2.5466837882995605
Validation loss: 2.2196277495353454

Epoch: 5| Step: 3
Training loss: 2.6687519550323486
Validation loss: 2.2270425699090444

Epoch: 5| Step: 4
Training loss: 2.487990617752075
Validation loss: 2.2470517491781585

Epoch: 5| Step: 5
Training loss: 2.8234944343566895
Validation loss: 2.2721322172431537

Epoch: 5| Step: 6
Training loss: 2.065725803375244
Validation loss: 2.3323221591211136

Epoch: 5| Step: 7
Training loss: 2.8428633213043213
Validation loss: 2.3940448658440703

Epoch: 5| Step: 8
Training loss: 2.5895583629608154
Validation loss: 2.345243251451882

Epoch: 5| Step: 9
Training loss: 2.575070858001709
Validation loss: 2.2339882453282676

Epoch: 5| Step: 10
Training loss: 2.5720081329345703
Validation loss: 2.1914558949009066

Epoch: 58| Step: 0
Training loss: 2.25815749168396
Validation loss: 2.1995576607283724

Epoch: 5| Step: 1
Training loss: 2.2801625728607178
Validation loss: 2.205091327749273

Epoch: 5| Step: 2
Training loss: 2.4086740016937256
Validation loss: 2.213417091677266

Epoch: 5| Step: 3
Training loss: 2.1539509296417236
Validation loss: 2.222945305608934

Epoch: 5| Step: 4
Training loss: 2.621417760848999
Validation loss: 2.2406736676410963

Epoch: 5| Step: 5
Training loss: 2.678809404373169
Validation loss: 2.2461944523678032

Epoch: 5| Step: 6
Training loss: 3.2264456748962402
Validation loss: 2.2339807633430726

Epoch: 5| Step: 7
Training loss: 2.3151330947875977
Validation loss: 2.218252202515961

Epoch: 5| Step: 8
Training loss: 3.193204879760742
Validation loss: 2.2032986379438833

Epoch: 5| Step: 9
Training loss: 2.753469944000244
Validation loss: 2.202713374168642

Epoch: 5| Step: 10
Training loss: 2.0983290672302246
Validation loss: 2.2068990840706775

Epoch: 59| Step: 0
Training loss: 2.14375376701355
Validation loss: 2.221426998415301

Epoch: 5| Step: 1
Training loss: 2.811319351196289
Validation loss: 2.244168330264348

Epoch: 5| Step: 2
Training loss: 2.5196785926818848
Validation loss: 2.2698583577268865

Epoch: 5| Step: 3
Training loss: 2.177475690841675
Validation loss: 2.314396176286923

Epoch: 5| Step: 4
Training loss: 2.4649059772491455
Validation loss: 2.349888196555517

Epoch: 5| Step: 5
Training loss: 2.0772271156311035
Validation loss: 2.340860906467643

Epoch: 5| Step: 6
Training loss: 2.650681257247925
Validation loss: 2.289686208130211

Epoch: 5| Step: 7
Training loss: 3.048142671585083
Validation loss: 2.2139831076386156

Epoch: 5| Step: 8
Training loss: 2.1558403968811035
Validation loss: 2.1943487275031304

Epoch: 5| Step: 9
Training loss: 3.072662830352783
Validation loss: 2.1947742995395454

Epoch: 5| Step: 10
Training loss: 2.920384407043457
Validation loss: 2.1955881093138006

Epoch: 60| Step: 0
Training loss: 2.8933417797088623
Validation loss: 2.1956082851656022

Epoch: 5| Step: 1
Training loss: 2.421555519104004
Validation loss: 2.1972546192907516

Epoch: 5| Step: 2
Training loss: 2.129566192626953
Validation loss: 2.1954374646627777

Epoch: 5| Step: 3
Training loss: 2.4537606239318848
Validation loss: 2.1917645495424987

Epoch: 5| Step: 4
Training loss: 2.2411093711853027
Validation loss: 2.19089521643936

Epoch: 5| Step: 5
Training loss: 2.321807861328125
Validation loss: 2.198817717131748

Epoch: 5| Step: 6
Training loss: 3.275843858718872
Validation loss: 2.2075392764101744

Epoch: 5| Step: 7
Training loss: 3.169724225997925
Validation loss: 2.227039756313447

Epoch: 5| Step: 8
Training loss: 2.4268155097961426
Validation loss: 2.2709702368705504

Epoch: 5| Step: 9
Training loss: 2.4478039741516113
Validation loss: 2.2845982300337924

Epoch: 5| Step: 10
Training loss: 1.9814834594726562
Validation loss: 2.2795541004468034

Epoch: 61| Step: 0
Training loss: 2.540285110473633
Validation loss: 2.291456937789917

Epoch: 5| Step: 1
Training loss: 2.181720495223999
Validation loss: 2.2657725939186673

Epoch: 5| Step: 2
Training loss: 2.3232641220092773
Validation loss: 2.2286385566957536

Epoch: 5| Step: 3
Training loss: 2.760895013809204
Validation loss: 2.2021092599438084

Epoch: 5| Step: 4
Training loss: 2.631258726119995
Validation loss: 2.196965871318694

Epoch: 5| Step: 5
Training loss: 2.8242475986480713
Validation loss: 2.2066037603603896

Epoch: 5| Step: 6
Training loss: 2.548198699951172
Validation loss: 2.199532716504989

Epoch: 5| Step: 7
Training loss: 2.369448661804199
Validation loss: 2.20412076416836

Epoch: 5| Step: 8
Training loss: 2.6402883529663086
Validation loss: 2.2043184618796072

Epoch: 5| Step: 9
Training loss: 2.231863498687744
Validation loss: 2.200474823674848

Epoch: 5| Step: 10
Training loss: 2.566807270050049
Validation loss: 2.1960558070931384

Epoch: 62| Step: 0
Training loss: 2.8979525566101074
Validation loss: 2.1845039654803533

Epoch: 5| Step: 1
Training loss: 2.8912417888641357
Validation loss: 2.1820487873528593

Epoch: 5| Step: 2
Training loss: 2.631991386413574
Validation loss: 2.1870006066496654

Epoch: 5| Step: 3
Training loss: 2.3141591548919678
Validation loss: 2.2002246610579954

Epoch: 5| Step: 4
Training loss: 2.437009572982788
Validation loss: 2.1980814344139508

Epoch: 5| Step: 5
Training loss: 2.5167150497436523
Validation loss: 2.2155825322674167

Epoch: 5| Step: 6
Training loss: 3.0753860473632812
Validation loss: 2.2272737692761164

Epoch: 5| Step: 7
Training loss: 1.9577758312225342
Validation loss: 2.2181754983881468

Epoch: 5| Step: 8
Training loss: 2.1668639183044434
Validation loss: 2.1889665229346162

Epoch: 5| Step: 9
Training loss: 2.3333139419555664
Validation loss: 2.1843173401330107

Epoch: 5| Step: 10
Training loss: 2.23191499710083
Validation loss: 2.168500313194849

Epoch: 63| Step: 0
Training loss: 2.0747039318084717
Validation loss: 2.173897284333424

Epoch: 5| Step: 1
Training loss: 2.5909435749053955
Validation loss: 2.1660607271297003

Epoch: 5| Step: 2
Training loss: 2.3547916412353516
Validation loss: 2.1694940982326383

Epoch: 5| Step: 3
Training loss: 2.196995735168457
Validation loss: 2.1733089852076706

Epoch: 5| Step: 4
Training loss: 2.177838087081909
Validation loss: 2.174075357375606

Epoch: 5| Step: 5
Training loss: 2.378135919570923
Validation loss: 2.175798403319492

Epoch: 5| Step: 6
Training loss: 2.6643102169036865
Validation loss: 2.1750153597965034

Epoch: 5| Step: 7
Training loss: 2.710331439971924
Validation loss: 2.1779871345848165

Epoch: 5| Step: 8
Training loss: 2.424572467803955
Validation loss: 2.196506546389672

Epoch: 5| Step: 9
Training loss: 2.6557912826538086
Validation loss: 2.237695014604958

Epoch: 5| Step: 10
Training loss: 3.2950267791748047
Validation loss: 2.2494594948266142

Epoch: 64| Step: 0
Training loss: 2.513636350631714
Validation loss: 2.2495796526632

Epoch: 5| Step: 1
Training loss: 2.5472779273986816
Validation loss: 2.225778305402366

Epoch: 5| Step: 2
Training loss: 2.0341196060180664
Validation loss: 2.2053244780468684

Epoch: 5| Step: 3
Training loss: 2.5375816822052
Validation loss: 2.17985616448105

Epoch: 5| Step: 4
Training loss: 2.8477656841278076
Validation loss: 2.176716337921799

Epoch: 5| Step: 5
Training loss: 2.1071295738220215
Validation loss: 2.1744200375772293

Epoch: 5| Step: 6
Training loss: 2.0876832008361816
Validation loss: 2.175410306581887

Epoch: 5| Step: 7
Training loss: 3.046243906021118
Validation loss: 2.1815075643600954

Epoch: 5| Step: 8
Training loss: 2.737104892730713
Validation loss: 2.1813337213249615

Epoch: 5| Step: 9
Training loss: 2.2971246242523193
Validation loss: 2.18382687722483

Epoch: 5| Step: 10
Training loss: 2.66081166267395
Validation loss: 2.1788953965710056

Epoch: 65| Step: 0
Training loss: 2.432213306427002
Validation loss: 2.180782671897642

Epoch: 5| Step: 1
Training loss: 2.0193679332733154
Validation loss: 2.178185643688325

Epoch: 5| Step: 2
Training loss: 2.656172513961792
Validation loss: 2.1854539763542915

Epoch: 5| Step: 3
Training loss: 2.3720202445983887
Validation loss: 2.182159875028877

Epoch: 5| Step: 4
Training loss: 2.4525058269500732
Validation loss: 2.180208380504321

Epoch: 5| Step: 5
Training loss: 2.5541229248046875
Validation loss: 2.19713351034349

Epoch: 5| Step: 6
Training loss: 2.414973497390747
Validation loss: 2.2267724672953286

Epoch: 5| Step: 7
Training loss: 1.6528654098510742
Validation loss: 2.245634014888476

Epoch: 5| Step: 8
Training loss: 2.766470432281494
Validation loss: 2.246270687349381

Epoch: 5| Step: 9
Training loss: 3.0610594749450684
Validation loss: 2.2353249249919767

Epoch: 5| Step: 10
Training loss: 2.8458845615386963
Validation loss: 2.209657412703319

Epoch: 66| Step: 0
Training loss: 2.6632513999938965
Validation loss: 2.1726439383722123

Epoch: 5| Step: 1
Training loss: 2.6115171909332275
Validation loss: 2.1480139865670154

Epoch: 5| Step: 2
Training loss: 2.327802896499634
Validation loss: 2.143273788113748

Epoch: 5| Step: 3
Training loss: 2.2545228004455566
Validation loss: 2.1465999285380044

Epoch: 5| Step: 4
Training loss: 3.1740336418151855
Validation loss: 2.1423031142962876

Epoch: 5| Step: 5
Training loss: 2.0120608806610107
Validation loss: 2.1443738757923083

Epoch: 5| Step: 6
Training loss: 2.960404634475708
Validation loss: 2.1453510548478816

Epoch: 5| Step: 7
Training loss: 1.9423294067382812
Validation loss: 2.147748183178645

Epoch: 5| Step: 8
Training loss: 2.3728690147399902
Validation loss: 2.165100597566174

Epoch: 5| Step: 9
Training loss: 2.530202865600586
Validation loss: 2.1912967158902075

Epoch: 5| Step: 10
Training loss: 2.374176502227783
Validation loss: 2.253535765473561

Epoch: 67| Step: 0
Training loss: 1.7716033458709717
Validation loss: 2.276987386006181

Epoch: 5| Step: 1
Training loss: 3.516843795776367
Validation loss: 2.312240764658938

Epoch: 5| Step: 2
Training loss: 2.653871774673462
Validation loss: 2.2550228000969015

Epoch: 5| Step: 3
Training loss: 2.2498114109039307
Validation loss: 2.2073562401597218

Epoch: 5| Step: 4
Training loss: 2.7013320922851562
Validation loss: 2.156205823344569

Epoch: 5| Step: 5
Training loss: 2.2972540855407715
Validation loss: 2.1392082168209936

Epoch: 5| Step: 6
Training loss: 2.717750072479248
Validation loss: 2.1522524485024075

Epoch: 5| Step: 7
Training loss: 2.6594507694244385
Validation loss: 2.173663677707795

Epoch: 5| Step: 8
Training loss: 2.287752151489258
Validation loss: 2.184809902662872

Epoch: 5| Step: 9
Training loss: 2.136245012283325
Validation loss: 2.172660719963812

Epoch: 5| Step: 10
Training loss: 2.669015884399414
Validation loss: 2.153750575998778

Epoch: 68| Step: 0
Training loss: 2.5971741676330566
Validation loss: 2.133968073834655

Epoch: 5| Step: 1
Training loss: 2.11501145362854
Validation loss: 2.1346615719538864

Epoch: 5| Step: 2
Training loss: 2.5052828788757324
Validation loss: 2.154994226271106

Epoch: 5| Step: 3
Training loss: 2.372631549835205
Validation loss: 2.1694100685017084

Epoch: 5| Step: 4
Training loss: 2.1969902515411377
Validation loss: 2.193913221359253

Epoch: 5| Step: 5
Training loss: 3.113792657852173
Validation loss: 2.198224380452146

Epoch: 5| Step: 6
Training loss: 2.3167724609375
Validation loss: 2.20078436405428

Epoch: 5| Step: 7
Training loss: 2.9143240451812744
Validation loss: 2.200248492661343

Epoch: 5| Step: 8
Training loss: 2.7469356060028076
Validation loss: 2.2058395506233297

Epoch: 5| Step: 9
Training loss: 2.2560009956359863
Validation loss: 2.209912533401161

Epoch: 5| Step: 10
Training loss: 1.9351611137390137
Validation loss: 2.157854687783026

Epoch: 69| Step: 0
Training loss: 2.4443917274475098
Validation loss: 2.14254415932522

Epoch: 5| Step: 1
Training loss: 2.5186119079589844
Validation loss: 2.136651287796677

Epoch: 5| Step: 2
Training loss: 2.475998640060425
Validation loss: 2.1334147568671935

Epoch: 5| Step: 3
Training loss: 2.3375604152679443
Validation loss: 2.1321704028755106

Epoch: 5| Step: 4
Training loss: 2.472478151321411
Validation loss: 2.1429329110730078

Epoch: 5| Step: 5
Training loss: 2.873631238937378
Validation loss: 2.145130770180815

Epoch: 5| Step: 6
Training loss: 2.6897406578063965
Validation loss: 2.145140569697144

Epoch: 5| Step: 7
Training loss: 2.291639804840088
Validation loss: 2.1340049005323842

Epoch: 5| Step: 8
Training loss: 2.452810049057007
Validation loss: 2.1417760079906834

Epoch: 5| Step: 9
Training loss: 2.4385056495666504
Validation loss: 2.162107329214773

Epoch: 5| Step: 10
Training loss: 2.335247039794922
Validation loss: 2.1888515487793954

Epoch: 70| Step: 0
Training loss: 2.3584084510803223
Validation loss: 2.2356841153995965

Epoch: 5| Step: 1
Training loss: 2.6399121284484863
Validation loss: 2.255894522513113

Epoch: 5| Step: 2
Training loss: 2.5325005054473877
Validation loss: 2.2294924425822433

Epoch: 5| Step: 3
Training loss: 2.095256805419922
Validation loss: 2.2022732765443864

Epoch: 5| Step: 4
Training loss: 2.6115128993988037
Validation loss: 2.1676424293107885

Epoch: 5| Step: 5
Training loss: 2.8368659019470215
Validation loss: 2.157571743893367

Epoch: 5| Step: 6
Training loss: 2.182109832763672
Validation loss: 2.1441476729608353

Epoch: 5| Step: 7
Training loss: 2.149101734161377
Validation loss: 2.14542362125971

Epoch: 5| Step: 8
Training loss: 2.496762275695801
Validation loss: 2.137078610799646

Epoch: 5| Step: 9
Training loss: 2.1038272380828857
Validation loss: 2.139064081253544

Epoch: 5| Step: 10
Training loss: 3.1123886108398438
Validation loss: 2.1275808003640946

Epoch: 71| Step: 0
Training loss: 2.6221327781677246
Validation loss: 2.1369443555032053

Epoch: 5| Step: 1
Training loss: 2.7434921264648438
Validation loss: 2.1289254311592347

Epoch: 5| Step: 2
Training loss: 2.270461320877075
Validation loss: 2.1387223992296445

Epoch: 5| Step: 3
Training loss: 2.5280961990356445
Validation loss: 2.146211580563617

Epoch: 5| Step: 4
Training loss: 2.398577928543091
Validation loss: 2.143383220959735

Epoch: 5| Step: 5
Training loss: 1.8679882287979126
Validation loss: 2.1441516965948124

Epoch: 5| Step: 6
Training loss: 2.692897319793701
Validation loss: 2.1530691987724713

Epoch: 5| Step: 7
Training loss: 1.9499324560165405
Validation loss: 2.1593803872344313

Epoch: 5| Step: 8
Training loss: 2.268118381500244
Validation loss: 2.165597887449367

Epoch: 5| Step: 9
Training loss: 3.3378214836120605
Validation loss: 2.2117153752234673

Epoch: 5| Step: 10
Training loss: 2.337378978729248
Validation loss: 2.2182895650145826

Epoch: 72| Step: 0
Training loss: 3.567849636077881
Validation loss: 2.2219005746226155

Epoch: 5| Step: 1
Training loss: 2.6389777660369873
Validation loss: 2.2102594503792385

Epoch: 5| Step: 2
Training loss: 2.6307194232940674
Validation loss: 2.190055142166794

Epoch: 5| Step: 3
Training loss: 2.4965951442718506
Validation loss: 2.1495626793112805

Epoch: 5| Step: 4
Training loss: 2.063023805618286
Validation loss: 2.124335463329028

Epoch: 5| Step: 5
Training loss: 1.7744388580322266
Validation loss: 2.1161488435601674

Epoch: 5| Step: 6
Training loss: 2.464540958404541
Validation loss: 2.1116711221715456

Epoch: 5| Step: 7
Training loss: 1.685524582862854
Validation loss: 2.107009792840609

Epoch: 5| Step: 8
Training loss: 2.538679838180542
Validation loss: 2.1051578880638204

Epoch: 5| Step: 9
Training loss: 2.411194324493408
Validation loss: 2.103445810656394

Epoch: 5| Step: 10
Training loss: 2.84844708442688
Validation loss: 2.1061556018808836

Epoch: 73| Step: 0
Training loss: 2.5081584453582764
Validation loss: 2.1119002629351873

Epoch: 5| Step: 1
Training loss: 2.025970935821533
Validation loss: 2.1401583148587133

Epoch: 5| Step: 2
Training loss: 2.0821824073791504
Validation loss: 2.170678610442787

Epoch: 5| Step: 3
Training loss: 2.302600622177124
Validation loss: 2.242294778106033

Epoch: 5| Step: 4
Training loss: 2.5482630729675293
Validation loss: 2.240427895258832

Epoch: 5| Step: 5
Training loss: 2.938265323638916
Validation loss: 2.2446223920391453

Epoch: 5| Step: 6
Training loss: 2.389853000640869
Validation loss: 2.200323704750307

Epoch: 5| Step: 7
Training loss: 2.556565523147583
Validation loss: 2.1597241688800115

Epoch: 5| Step: 8
Training loss: 3.185488224029541
Validation loss: 2.1230758620846655

Epoch: 5| Step: 9
Training loss: 2.0989692211151123
Validation loss: 2.1146986074345087

Epoch: 5| Step: 10
Training loss: 2.505504608154297
Validation loss: 2.1187858760997815

Epoch: 74| Step: 0
Training loss: 2.457965850830078
Validation loss: 2.1131965896134735

Epoch: 5| Step: 1
Training loss: 3.1533687114715576
Validation loss: 2.103750496782282

Epoch: 5| Step: 2
Training loss: 2.134411096572876
Validation loss: 2.109555054736394

Epoch: 5| Step: 3
Training loss: 2.389770984649658
Validation loss: 2.1075537755925167

Epoch: 5| Step: 4
Training loss: 1.9025369882583618
Validation loss: 2.1253685348777362

Epoch: 5| Step: 5
Training loss: 2.0472640991210938
Validation loss: 2.158377503836027

Epoch: 5| Step: 6
Training loss: 2.362578868865967
Validation loss: 2.1771964078308432

Epoch: 5| Step: 7
Training loss: 2.414738178253174
Validation loss: 2.210100176513836

Epoch: 5| Step: 8
Training loss: 2.6954457759857178
Validation loss: 2.2895688318437144

Epoch: 5| Step: 9
Training loss: 2.5693023204803467
Validation loss: 2.2753815907304005

Epoch: 5| Step: 10
Training loss: 3.197782516479492
Validation loss: 2.257899938091155

Epoch: 75| Step: 0
Training loss: 2.922452211380005
Validation loss: 2.1890429681347263

Epoch: 5| Step: 1
Training loss: 2.2308950424194336
Validation loss: 2.167434984637845

Epoch: 5| Step: 2
Training loss: 2.3199658393859863
Validation loss: 2.146612234013055

Epoch: 5| Step: 3
Training loss: 1.7797539234161377
Validation loss: 2.1218118795784573

Epoch: 5| Step: 4
Training loss: 2.4258439540863037
Validation loss: 2.126148141840453

Epoch: 5| Step: 5
Training loss: 3.189178943634033
Validation loss: 2.126483599344889

Epoch: 5| Step: 6
Training loss: 2.1259379386901855
Validation loss: 2.1327424151923067

Epoch: 5| Step: 7
Training loss: 2.6395819187164307
Validation loss: 2.1286269900619343

Epoch: 5| Step: 8
Training loss: 2.5347330570220947
Validation loss: 2.130275172571982

Epoch: 5| Step: 9
Training loss: 2.1072745323181152
Validation loss: 2.1343768873522357

Epoch: 5| Step: 10
Training loss: 2.5168707370758057
Validation loss: 2.14346815693763

Epoch: 76| Step: 0
Training loss: 2.043039321899414
Validation loss: 2.1241041255253617

Epoch: 5| Step: 1
Training loss: 2.6143500804901123
Validation loss: 2.109021935411679

Epoch: 5| Step: 2
Training loss: 2.5467610359191895
Validation loss: 2.11132130827955

Epoch: 5| Step: 3
Training loss: 2.324531078338623
Validation loss: 2.1129074250498125

Epoch: 5| Step: 4
Training loss: 2.1721270084381104
Validation loss: 2.110835588106545

Epoch: 5| Step: 5
Training loss: 2.4340946674346924
Validation loss: 2.1216630576759257

Epoch: 5| Step: 6
Training loss: 2.7023818492889404
Validation loss: 2.1355060890156734

Epoch: 5| Step: 7
Training loss: 2.621483087539673
Validation loss: 2.1319595267695766

Epoch: 5| Step: 8
Training loss: 2.2550201416015625
Validation loss: 2.1275468769893853

Epoch: 5| Step: 9
Training loss: 2.4863970279693604
Validation loss: 2.1219335691903227

Epoch: 5| Step: 10
Training loss: 2.5990118980407715
Validation loss: 2.123960973114096

Epoch: 77| Step: 0
Training loss: 2.4739978313446045
Validation loss: 2.1207384088987946

Epoch: 5| Step: 1
Training loss: 2.365609645843506
Validation loss: 2.132236497376555

Epoch: 5| Step: 2
Training loss: 2.623322010040283
Validation loss: 2.1527321928290912

Epoch: 5| Step: 3
Training loss: 2.016399383544922
Validation loss: 2.173983822586716

Epoch: 5| Step: 4
Training loss: 2.112852096557617
Validation loss: 2.218240855842508

Epoch: 5| Step: 5
Training loss: 2.931626796722412
Validation loss: 2.2069574133042367

Epoch: 5| Step: 6
Training loss: 2.5203919410705566
Validation loss: 2.196773685434813

Epoch: 5| Step: 7
Training loss: 2.0013298988342285
Validation loss: 2.1545698053093365

Epoch: 5| Step: 8
Training loss: 2.89959454536438
Validation loss: 2.1295652927890902

Epoch: 5| Step: 9
Training loss: 2.137138843536377
Validation loss: 2.122439205005605

Epoch: 5| Step: 10
Training loss: 2.679262638092041
Validation loss: 2.108997901280721

Epoch: 78| Step: 0
Training loss: 2.343924045562744
Validation loss: 2.1080057928639073

Epoch: 5| Step: 1
Training loss: 2.6321611404418945
Validation loss: 2.1088323311139177

Epoch: 5| Step: 2
Training loss: 2.516202211380005
Validation loss: 2.1074288070842786

Epoch: 5| Step: 3
Training loss: 2.410315990447998
Validation loss: 2.111837911349471

Epoch: 5| Step: 4
Training loss: 2.8293395042419434
Validation loss: 2.116281840109056

Epoch: 5| Step: 5
Training loss: 2.148346185684204
Validation loss: 2.1176886584169123

Epoch: 5| Step: 6
Training loss: 1.762250542640686
Validation loss: 2.138755606066796

Epoch: 5| Step: 7
Training loss: 1.9901959896087646
Validation loss: 2.1612337878955308

Epoch: 5| Step: 8
Training loss: 3.081284999847412
Validation loss: 2.2125216773761216

Epoch: 5| Step: 9
Training loss: 2.93232798576355
Validation loss: 2.2339453274203884

Epoch: 5| Step: 10
Training loss: 2.0612494945526123
Validation loss: 2.193907383949526

Epoch: 79| Step: 0
Training loss: 2.002678632736206
Validation loss: 2.1614275709275277

Epoch: 5| Step: 1
Training loss: 2.5533926486968994
Validation loss: 2.136622413512199

Epoch: 5| Step: 2
Training loss: 2.7324373722076416
Validation loss: 2.118626715034567

Epoch: 5| Step: 3
Training loss: 1.9818847179412842
Validation loss: 2.1041938874029342

Epoch: 5| Step: 4
Training loss: 2.5583267211914062
Validation loss: 2.1043840557016353

Epoch: 5| Step: 5
Training loss: 2.675523042678833
Validation loss: 2.114188760839483

Epoch: 5| Step: 6
Training loss: 2.2244904041290283
Validation loss: 2.116684426543533

Epoch: 5| Step: 7
Training loss: 2.4405064582824707
Validation loss: 2.1326796623968307

Epoch: 5| Step: 8
Training loss: 2.1271138191223145
Validation loss: 2.1405372773447344

Epoch: 5| Step: 9
Training loss: 2.9476029872894287
Validation loss: 2.1333753601197274

Epoch: 5| Step: 10
Training loss: 2.165339231491089
Validation loss: 2.1398453494553924

Epoch: 80| Step: 0
Training loss: 2.286437511444092
Validation loss: 2.1453776564649356

Epoch: 5| Step: 1
Training loss: 2.2322213649749756
Validation loss: 2.1246037585760957

Epoch: 5| Step: 2
Training loss: 2.791217565536499
Validation loss: 2.132346281441309

Epoch: 5| Step: 3
Training loss: 2.8763201236724854
Validation loss: 2.1495641226409585

Epoch: 5| Step: 4
Training loss: 2.540116786956787
Validation loss: 2.1437774447984594

Epoch: 5| Step: 5
Training loss: 2.282226085662842
Validation loss: 2.1459482844157884

Epoch: 5| Step: 6
Training loss: 2.732482433319092
Validation loss: 2.1491979270853023

Epoch: 5| Step: 7
Training loss: 2.4965569972991943
Validation loss: 2.1972079277038574

Epoch: 5| Step: 8
Training loss: 1.637109398841858
Validation loss: 2.1839740942883235

Epoch: 5| Step: 9
Training loss: 2.5828442573547363
Validation loss: 2.1350103321895806

Epoch: 5| Step: 10
Training loss: 2.0687029361724854
Validation loss: 2.113528654139529

Epoch: 81| Step: 0
Training loss: 2.3926703929901123
Validation loss: 2.1044388227565314

Epoch: 5| Step: 1
Training loss: 2.353999614715576
Validation loss: 2.1055952272107525

Epoch: 5| Step: 2
Training loss: 2.4709999561309814
Validation loss: 2.11304211103788

Epoch: 5| Step: 3
Training loss: 3.12784481048584
Validation loss: 2.1368930826904955

Epoch: 5| Step: 4
Training loss: 1.9738725423812866
Validation loss: 2.1536052867930424

Epoch: 5| Step: 5
Training loss: 2.542790651321411
Validation loss: 2.1500098051563388

Epoch: 5| Step: 6
Training loss: 3.02032208442688
Validation loss: 2.14675558510647

Epoch: 5| Step: 7
Training loss: 2.1375603675842285
Validation loss: 2.1471203527142926

Epoch: 5| Step: 8
Training loss: 2.035086154937744
Validation loss: 2.144473778304233

Epoch: 5| Step: 9
Training loss: 2.324284076690674
Validation loss: 2.126555355646277

Epoch: 5| Step: 10
Training loss: 2.106663942337036
Validation loss: 2.1173017383903585

Epoch: 82| Step: 0
Training loss: 2.2650985717773438
Validation loss: 2.114251805889991

Epoch: 5| Step: 1
Training loss: 2.2605979442596436
Validation loss: 2.118976728890532

Epoch: 5| Step: 2
Training loss: 2.0151774883270264
Validation loss: 2.119354404428954

Epoch: 5| Step: 3
Training loss: 2.555934429168701
Validation loss: 2.1199123782496296

Epoch: 5| Step: 4
Training loss: 2.6695556640625
Validation loss: 2.124998049069476

Epoch: 5| Step: 5
Training loss: 2.592865228652954
Validation loss: 2.1030382828045915

Epoch: 5| Step: 6
Training loss: 1.455160140991211
Validation loss: 2.080299649187314

Epoch: 5| Step: 7
Training loss: 2.7409298419952393
Validation loss: 2.07578291175186

Epoch: 5| Step: 8
Training loss: 2.315290689468384
Validation loss: 2.072022722613427

Epoch: 5| Step: 9
Training loss: 2.9643261432647705
Validation loss: 2.085487893832627

Epoch: 5| Step: 10
Training loss: 2.555706262588501
Validation loss: 2.0886319478352866

Epoch: 83| Step: 0
Training loss: 2.7815189361572266
Validation loss: 2.1092461911580895

Epoch: 5| Step: 1
Training loss: 2.9086251258850098
Validation loss: 2.1247743932149743

Epoch: 5| Step: 2
Training loss: 2.0967659950256348
Validation loss: 2.156093902485345

Epoch: 5| Step: 3
Training loss: 1.8283685445785522
Validation loss: 2.1700175680140013

Epoch: 5| Step: 4
Training loss: 2.254666566848755
Validation loss: 2.1908373858339045

Epoch: 5| Step: 5
Training loss: 2.3944239616394043
Validation loss: 2.177974044635732

Epoch: 5| Step: 6
Training loss: 2.5092949867248535
Validation loss: 2.1444483815982776

Epoch: 5| Step: 7
Training loss: 2.725268602371216
Validation loss: 2.125965165835555

Epoch: 5| Step: 8
Training loss: 2.5934646129608154
Validation loss: 2.116065932858375

Epoch: 5| Step: 9
Training loss: 1.9412609338760376
Validation loss: 2.1038877720473916

Epoch: 5| Step: 10
Training loss: 2.324225425720215
Validation loss: 2.1010488720350367

Epoch: 84| Step: 0
Training loss: 2.1234755516052246
Validation loss: 2.0999389053672872

Epoch: 5| Step: 1
Training loss: 2.706279754638672
Validation loss: 2.0903669121444866

Epoch: 5| Step: 2
Training loss: 2.3531947135925293
Validation loss: 2.0950627173146894

Epoch: 5| Step: 3
Training loss: 1.9423253536224365
Validation loss: 2.120181042660949

Epoch: 5| Step: 4
Training loss: 2.4120709896087646
Validation loss: 2.1668147604952575

Epoch: 5| Step: 5
Training loss: 1.6949650049209595
Validation loss: 2.1469935588939215

Epoch: 5| Step: 6
Training loss: 2.4580554962158203
Validation loss: 2.0945064995878484

Epoch: 5| Step: 7
Training loss: 2.609851360321045
Validation loss: 2.0832236325868996

Epoch: 5| Step: 8
Training loss: 2.810427665710449
Validation loss: 2.0826749032543552

Epoch: 5| Step: 9
Training loss: 2.9130797386169434
Validation loss: 2.097794380239261

Epoch: 5| Step: 10
Training loss: 2.5316860675811768
Validation loss: 2.1158602558156496

Epoch: 85| Step: 0
Training loss: 2.386706590652466
Validation loss: 2.1206209903122275

Epoch: 5| Step: 1
Training loss: 2.4240355491638184
Validation loss: 2.1198666390552314

Epoch: 5| Step: 2
Training loss: 2.0787508487701416
Validation loss: 2.118584659791762

Epoch: 5| Step: 3
Training loss: 2.4562344551086426
Validation loss: 2.110786299551687

Epoch: 5| Step: 4
Training loss: 2.164149522781372
Validation loss: 2.1010895544482815

Epoch: 5| Step: 5
Training loss: 2.2103142738342285
Validation loss: 2.1078223810401013

Epoch: 5| Step: 6
Training loss: 2.3510918617248535
Validation loss: 2.0987951242795555

Epoch: 5| Step: 7
Training loss: 2.7454967498779297
Validation loss: 2.0960719431600263

Epoch: 5| Step: 8
Training loss: 2.964655876159668
Validation loss: 2.1049731675014702

Epoch: 5| Step: 9
Training loss: 2.6044762134552
Validation loss: 2.121696659313735

Epoch: 5| Step: 10
Training loss: 2.6733145713806152
Validation loss: 2.1502566286312637

Epoch: 86| Step: 0
Training loss: 2.209562301635742
Validation loss: 2.1462767893268215

Epoch: 5| Step: 1
Training loss: 2.520848512649536
Validation loss: 2.145001688311177

Epoch: 5| Step: 2
Training loss: 2.356621265411377
Validation loss: 2.129320252326227

Epoch: 5| Step: 3
Training loss: 2.3694024085998535
Validation loss: 2.107933444361533

Epoch: 5| Step: 4
Training loss: 3.085355520248413
Validation loss: 2.1130950309896983

Epoch: 5| Step: 5
Training loss: 2.4729883670806885
Validation loss: 2.1308319542997625

Epoch: 5| Step: 6
Training loss: 1.8342822790145874
Validation loss: 2.1497751730744556

Epoch: 5| Step: 7
Training loss: 2.735809326171875
Validation loss: 2.1477642905327583

Epoch: 5| Step: 8
Training loss: 2.3653125762939453
Validation loss: 2.15494954457847

Epoch: 5| Step: 9
Training loss: 2.2428715229034424
Validation loss: 2.145133638894686

Epoch: 5| Step: 10
Training loss: 2.2857775688171387
Validation loss: 2.1018360635285736

Epoch: 87| Step: 0
Training loss: 2.1689343452453613
Validation loss: 2.0790357487176054

Epoch: 5| Step: 1
Training loss: 2.5791027545928955
Validation loss: 2.073712302792457

Epoch: 5| Step: 2
Training loss: 2.43611478805542
Validation loss: 2.0722830577563216

Epoch: 5| Step: 3
Training loss: 2.830469846725464
Validation loss: 2.0751085896645822

Epoch: 5| Step: 4
Training loss: 2.8694045543670654
Validation loss: 2.0949065595544796

Epoch: 5| Step: 5
Training loss: 2.2320072650909424
Validation loss: 2.1102220550660165

Epoch: 5| Step: 6
Training loss: 3.3111209869384766
Validation loss: 2.1733826386031283

Epoch: 5| Step: 7
Training loss: 1.8900312185287476
Validation loss: 2.2423230909532115

Epoch: 5| Step: 8
Training loss: 2.558952808380127
Validation loss: 2.2218865348446752

Epoch: 5| Step: 9
Training loss: 1.8252232074737549
Validation loss: 2.203895204810686

Epoch: 5| Step: 10
Training loss: 1.6849641799926758
Validation loss: 2.1507250057753695

Epoch: 88| Step: 0
Training loss: 2.3545405864715576
Validation loss: 2.134890535826324

Epoch: 5| Step: 1
Training loss: 2.4368743896484375
Validation loss: 2.0951240844624017

Epoch: 5| Step: 2
Training loss: 2.236057758331299
Validation loss: 2.087544569405176

Epoch: 5| Step: 3
Training loss: 2.3136162757873535
Validation loss: 2.075751207208121

Epoch: 5| Step: 4
Training loss: 1.9884322881698608
Validation loss: 2.0712006348435597

Epoch: 5| Step: 5
Training loss: 3.1251702308654785
Validation loss: 2.0729957524166314

Epoch: 5| Step: 6
Training loss: 1.9299523830413818
Validation loss: 2.0787746649916454

Epoch: 5| Step: 7
Training loss: 2.0866801738739014
Validation loss: 2.0818350879094933

Epoch: 5| Step: 8
Training loss: 2.5464377403259277
Validation loss: 2.1113606422178206

Epoch: 5| Step: 9
Training loss: 2.7354443073272705
Validation loss: 2.1196150395178024

Epoch: 5| Step: 10
Training loss: 2.3051342964172363
Validation loss: 2.1065371651803293

Epoch: 89| Step: 0
Training loss: 2.7353734970092773
Validation loss: 2.0978135601166756

Epoch: 5| Step: 1
Training loss: 2.3578953742980957
Validation loss: 2.087247851074383

Epoch: 5| Step: 2
Training loss: 3.13667893409729
Validation loss: 2.090314875366867

Epoch: 5| Step: 3
Training loss: 2.7673680782318115
Validation loss: 2.0896936975499636

Epoch: 5| Step: 4
Training loss: 1.6883985996246338
Validation loss: 2.078320928799209

Epoch: 5| Step: 5
Training loss: 1.8995872735977173
Validation loss: 2.106265124454293

Epoch: 5| Step: 6
Training loss: 2.542259693145752
Validation loss: 2.1343560936630412

Epoch: 5| Step: 7
Training loss: 2.166853189468384
Validation loss: 2.1559982536941447

Epoch: 5| Step: 8
Training loss: 2.462062120437622
Validation loss: 2.132028638675649

Epoch: 5| Step: 9
Training loss: 1.8830745220184326
Validation loss: 2.1326255439430155

Epoch: 5| Step: 10
Training loss: 2.3411214351654053
Validation loss: 2.1438546014088455

Epoch: 90| Step: 0
Training loss: 2.723079204559326
Validation loss: 2.1171634222871516

Epoch: 5| Step: 1
Training loss: 1.684674859046936
Validation loss: 2.098139283477619

Epoch: 5| Step: 2
Training loss: 1.850303292274475
Validation loss: 2.0785893009554957

Epoch: 5| Step: 3
Training loss: 2.6526451110839844
Validation loss: 2.070751349131266

Epoch: 5| Step: 4
Training loss: 2.7421326637268066
Validation loss: 2.075111412232922

Epoch: 5| Step: 5
Training loss: 2.3259623050689697
Validation loss: 2.0780471114702124

Epoch: 5| Step: 6
Training loss: 2.673959970474243
Validation loss: 2.072721001922443

Epoch: 5| Step: 7
Training loss: 2.306561231613159
Validation loss: 2.0824107726415

Epoch: 5| Step: 8
Training loss: 2.536632776260376
Validation loss: 2.0804649706809752

Epoch: 5| Step: 9
Training loss: 2.2036712169647217
Validation loss: 2.0830776358163483

Epoch: 5| Step: 10
Training loss: 2.3468761444091797
Validation loss: 2.086922178986252

Epoch: 91| Step: 0
Training loss: 2.506720781326294
Validation loss: 2.093717434073007

Epoch: 5| Step: 1
Training loss: 2.184328317642212
Validation loss: 2.142119756308935

Epoch: 5| Step: 2
Training loss: 2.674243927001953
Validation loss: 2.179130146580358

Epoch: 5| Step: 3
Training loss: 2.3479628562927246
Validation loss: 2.1749148317562637

Epoch: 5| Step: 4
Training loss: 2.2570526599884033
Validation loss: 2.189163415662704

Epoch: 5| Step: 5
Training loss: 2.0318615436553955
Validation loss: 2.136776283223142

Epoch: 5| Step: 6
Training loss: 2.589205503463745
Validation loss: 2.092538809263578

Epoch: 5| Step: 7
Training loss: 2.158564329147339
Validation loss: 2.0580868887644943

Epoch: 5| Step: 8
Training loss: 2.4281532764434814
Validation loss: 2.0576327321349934

Epoch: 5| Step: 9
Training loss: 2.488842487335205
Validation loss: 2.0577627740880495

Epoch: 5| Step: 10
Training loss: 2.492758274078369
Validation loss: 2.0731758456076346

Epoch: 92| Step: 0
Training loss: 2.4813950061798096
Validation loss: 2.071060767737768

Epoch: 5| Step: 1
Training loss: 2.3859145641326904
Validation loss: 2.073387486960298

Epoch: 5| Step: 2
Training loss: 2.4697823524475098
Validation loss: 2.094118805341823

Epoch: 5| Step: 3
Training loss: 2.5130748748779297
Validation loss: 2.140801324639269

Epoch: 5| Step: 4
Training loss: 2.379286289215088
Validation loss: 2.1360555900040494

Epoch: 5| Step: 5
Training loss: 2.873044490814209
Validation loss: 2.153312761296508

Epoch: 5| Step: 6
Training loss: 2.4921412467956543
Validation loss: 2.173913622415194

Epoch: 5| Step: 7
Training loss: 1.8239303827285767
Validation loss: 2.177275739690309

Epoch: 5| Step: 8
Training loss: 2.7580344676971436
Validation loss: 2.137457516885573

Epoch: 5| Step: 9
Training loss: 2.052757740020752
Validation loss: 2.1125731442564275

Epoch: 5| Step: 10
Training loss: 1.8881932497024536
Validation loss: 2.106589953104655

Epoch: 93| Step: 0
Training loss: 1.9189220666885376
Validation loss: 2.080386184876965

Epoch: 5| Step: 1
Training loss: 2.7715375423431396
Validation loss: 2.0824987939608994

Epoch: 5| Step: 2
Training loss: 2.3284201622009277
Validation loss: 2.077874893783241

Epoch: 5| Step: 3
Training loss: 1.8954699039459229
Validation loss: 2.079549430519022

Epoch: 5| Step: 4
Training loss: 2.348932981491089
Validation loss: 2.08821504346786

Epoch: 5| Step: 5
Training loss: 2.6556308269500732
Validation loss: 2.074000479072653

Epoch: 5| Step: 6
Training loss: 2.1894733905792236
Validation loss: 2.1017202023536927

Epoch: 5| Step: 7
Training loss: 2.491720676422119
Validation loss: 2.085847816159648

Epoch: 5| Step: 8
Training loss: 2.680365800857544
Validation loss: 2.08085492221258

Epoch: 5| Step: 9
Training loss: 2.2849838733673096
Validation loss: 2.056681074121947

Epoch: 5| Step: 10
Training loss: 2.291887044906616
Validation loss: 2.0538323566477787

Epoch: 94| Step: 0
Training loss: 2.5943524837493896
Validation loss: 2.0395571570242605

Epoch: 5| Step: 1
Training loss: 1.9065790176391602
Validation loss: 2.0331274796557683

Epoch: 5| Step: 2
Training loss: 2.984067440032959
Validation loss: 2.0371403309606735

Epoch: 5| Step: 3
Training loss: 2.0569372177124023
Validation loss: 2.0437373512534687

Epoch: 5| Step: 4
Training loss: 2.033229351043701
Validation loss: 2.040402412414551

Epoch: 5| Step: 5
Training loss: 1.7143014669418335
Validation loss: 2.048448206276022

Epoch: 5| Step: 6
Training loss: 2.0086171627044678
Validation loss: 2.066554423301451

Epoch: 5| Step: 7
Training loss: 2.75337553024292
Validation loss: 2.076560133246965

Epoch: 5| Step: 8
Training loss: 2.281984567642212
Validation loss: 2.0997379620869956

Epoch: 5| Step: 9
Training loss: 2.663421869277954
Validation loss: 2.0952134337476505

Epoch: 5| Step: 10
Training loss: 2.624936103820801
Validation loss: 2.073331586776241

Epoch: 95| Step: 0
Training loss: 2.7021095752716064
Validation loss: 2.0894926235239994

Epoch: 5| Step: 1
Training loss: 2.146960735321045
Validation loss: 2.084529539590241

Epoch: 5| Step: 2
Training loss: 2.441105365753174
Validation loss: 2.090057546092618

Epoch: 5| Step: 3
Training loss: 2.2176780700683594
Validation loss: 2.09269824335652

Epoch: 5| Step: 4
Training loss: 2.191565752029419
Validation loss: 2.0795918933806883

Epoch: 5| Step: 5
Training loss: 2.6995255947113037
Validation loss: 2.050933899418

Epoch: 5| Step: 6
Training loss: 1.9202487468719482
Validation loss: 2.0411777829611175

Epoch: 5| Step: 7
Training loss: 2.225152015686035
Validation loss: 2.0380677382151284

Epoch: 5| Step: 8
Training loss: 2.3751468658447266
Validation loss: 2.0582724437918714

Epoch: 5| Step: 9
Training loss: 1.9337354898452759
Validation loss: 2.0761923238795292

Epoch: 5| Step: 10
Training loss: 2.672426223754883
Validation loss: 2.0878525575002036

Epoch: 96| Step: 0
Training loss: 2.6022610664367676
Validation loss: 2.087128039329283

Epoch: 5| Step: 1
Training loss: 2.4339330196380615
Validation loss: 2.0795876723463818

Epoch: 5| Step: 2
Training loss: 2.611368417739868
Validation loss: 2.0620041611374065

Epoch: 5| Step: 3
Training loss: 2.480642795562744
Validation loss: 2.0456523356899137

Epoch: 5| Step: 4
Training loss: 2.0396766662597656
Validation loss: 2.0618846954837924

Epoch: 5| Step: 5
Training loss: 2.3504233360290527
Validation loss: 2.0795664069473103

Epoch: 5| Step: 6
Training loss: 1.8089679479599
Validation loss: 2.096358165946058

Epoch: 5| Step: 7
Training loss: 2.1628060340881348
Validation loss: 2.1316061917171685

Epoch: 5| Step: 8
Training loss: 1.9824539422988892
Validation loss: 2.096645268060828

Epoch: 5| Step: 9
Training loss: 2.5848731994628906
Validation loss: 2.0625752813072613

Epoch: 5| Step: 10
Training loss: 2.272613763809204
Validation loss: 2.0367535570616364

Epoch: 97| Step: 0
Training loss: 2.5111427307128906
Validation loss: 2.028388282304169

Epoch: 5| Step: 1
Training loss: 2.200822591781616
Validation loss: 2.006996535485791

Epoch: 5| Step: 2
Training loss: 2.592339038848877
Validation loss: 2.015070531957893

Epoch: 5| Step: 3
Training loss: 2.064788818359375
Validation loss: 2.017150189286919

Epoch: 5| Step: 4
Training loss: 2.2918498516082764
Validation loss: 2.02684417334936

Epoch: 5| Step: 5
Training loss: 2.5947248935699463
Validation loss: 2.0291081884855866

Epoch: 5| Step: 6
Training loss: 2.2031445503234863
Validation loss: 2.0783095923803185

Epoch: 5| Step: 7
Training loss: 2.3558712005615234
Validation loss: 2.12289878501687

Epoch: 5| Step: 8
Training loss: 2.4308383464813232
Validation loss: 2.1540632324834026

Epoch: 5| Step: 9
Training loss: 2.1334285736083984
Validation loss: 2.149907230049051

Epoch: 5| Step: 10
Training loss: 2.116736650466919
Validation loss: 2.1566027877151326

Epoch: 98| Step: 0
Training loss: 2.1773993968963623
Validation loss: 2.1037810105149464

Epoch: 5| Step: 1
Training loss: 1.8413082361221313
Validation loss: 2.0582844826482956

Epoch: 5| Step: 2
Training loss: 2.449181318283081
Validation loss: 2.0573193360400457

Epoch: 5| Step: 3
Training loss: 2.7256579399108887
Validation loss: 2.0387376393041303

Epoch: 5| Step: 4
Training loss: 2.490579843521118
Validation loss: 2.0267171065012612

Epoch: 5| Step: 5
Training loss: 2.361318349838257
Validation loss: 2.0151926240613385

Epoch: 5| Step: 6
Training loss: 2.458967447280884
Validation loss: 2.0315399528831564

Epoch: 5| Step: 7
Training loss: 2.291369676589966
Validation loss: 2.0285441234547603

Epoch: 5| Step: 8
Training loss: 1.979714035987854
Validation loss: 2.062942842001556

Epoch: 5| Step: 9
Training loss: 2.0668578147888184
Validation loss: 2.0989535380435247

Epoch: 5| Step: 10
Training loss: 2.2266666889190674
Validation loss: 2.118502296427245

Epoch: 99| Step: 0
Training loss: 2.397569179534912
Validation loss: 2.1560654563288533

Epoch: 5| Step: 1
Training loss: 2.3764595985412598
Validation loss: 2.133807546348982

Epoch: 5| Step: 2
Training loss: 1.9722259044647217
Validation loss: 2.1022159450797626

Epoch: 5| Step: 3
Training loss: 2.3738555908203125
Validation loss: 2.079634897170528

Epoch: 5| Step: 4
Training loss: 2.2004456520080566
Validation loss: 2.0613193999054613

Epoch: 5| Step: 5
Training loss: 2.562230348587036
Validation loss: 2.0390178759892783

Epoch: 5| Step: 6
Training loss: 2.423959255218506
Validation loss: 2.049324873955019

Epoch: 5| Step: 7
Training loss: 2.189655065536499
Validation loss: 2.062007616924983

Epoch: 5| Step: 8
Training loss: 1.738466501235962
Validation loss: 2.068207238310127

Epoch: 5| Step: 9
Training loss: 2.6056811809539795
Validation loss: 2.085572100454761

Epoch: 5| Step: 10
Training loss: 2.3721165657043457
Validation loss: 2.115050890112436

Epoch: 100| Step: 0
Training loss: 2.107301712036133
Validation loss: 2.106796092884515

Epoch: 5| Step: 1
Training loss: 2.141763687133789
Validation loss: 2.0952003950713785

Epoch: 5| Step: 2
Training loss: 2.106069803237915
Validation loss: 2.088915906926637

Epoch: 5| Step: 3
Training loss: 2.324871778488159
Validation loss: 2.053923301799323

Epoch: 5| Step: 4
Training loss: 2.9117588996887207
Validation loss: 2.042470693588257

Epoch: 5| Step: 5
Training loss: 2.2504048347473145
Validation loss: 2.026186966126965

Epoch: 5| Step: 6
Training loss: 1.8027160167694092
Validation loss: 2.010055124118764

Epoch: 5| Step: 7
Training loss: 2.034437894821167
Validation loss: 2.0290284951527915

Epoch: 5| Step: 8
Training loss: 2.4721527099609375
Validation loss: 2.038245701020764

Epoch: 5| Step: 9
Training loss: 2.2644684314727783
Validation loss: 2.0522394257207073

Epoch: 5| Step: 10
Training loss: 2.6925411224365234
Validation loss: 2.065019540889289

Epoch: 101| Step: 0
Training loss: 1.651431679725647
Validation loss: 2.0772113671866794

Epoch: 5| Step: 1
Training loss: 2.4733662605285645
Validation loss: 2.0740078610758625

Epoch: 5| Step: 2
Training loss: 2.1851658821105957
Validation loss: 2.094429931332988

Epoch: 5| Step: 3
Training loss: 3.054985523223877
Validation loss: 2.1236408064442296

Epoch: 5| Step: 4
Training loss: 2.5390305519104004
Validation loss: 2.1296344111042638

Epoch: 5| Step: 5
Training loss: 2.674915313720703
Validation loss: 2.120024214508713

Epoch: 5| Step: 6
Training loss: 1.8157389163970947
Validation loss: 2.1210079423842894

Epoch: 5| Step: 7
Training loss: 2.5785324573516846
Validation loss: 2.1002037499540593

Epoch: 5| Step: 8
Training loss: 2.0932958126068115
Validation loss: 2.07855309209516

Epoch: 5| Step: 9
Training loss: 2.0037319660186768
Validation loss: 2.0733630605923232

Epoch: 5| Step: 10
Training loss: 1.8024095296859741
Validation loss: 2.049750663900888

Epoch: 102| Step: 0
Training loss: 2.1559500694274902
Validation loss: 2.0410820361106627

Epoch: 5| Step: 1
Training loss: 1.9908860921859741
Validation loss: 2.028143241841306

Epoch: 5| Step: 2
Training loss: 2.293290138244629
Validation loss: 2.0402365397381526

Epoch: 5| Step: 3
Training loss: 1.4414482116699219
Validation loss: 2.0418623903746247

Epoch: 5| Step: 4
Training loss: 1.9681205749511719
Validation loss: 2.064567856891181

Epoch: 5| Step: 5
Training loss: 3.2197105884552
Validation loss: 2.0879889457456526

Epoch: 5| Step: 6
Training loss: 1.783637285232544
Validation loss: 2.0543027142042756

Epoch: 5| Step: 7
Training loss: 2.2815299034118652
Validation loss: 2.0282390374009327

Epoch: 5| Step: 8
Training loss: 2.299884557723999
Validation loss: 2.036623695845245

Epoch: 5| Step: 9
Training loss: 2.720149278640747
Validation loss: 2.0501230762850855

Epoch: 5| Step: 10
Training loss: 2.5950093269348145
Validation loss: 2.0499132910082416

Epoch: 103| Step: 0
Training loss: 2.7183279991149902
Validation loss: 2.054183376732693

Epoch: 5| Step: 1
Training loss: 2.9000465869903564
Validation loss: 2.051352693188575

Epoch: 5| Step: 2
Training loss: 2.464184045791626
Validation loss: 2.052546811360185

Epoch: 5| Step: 3
Training loss: 2.3811607360839844
Validation loss: 2.063876546839232

Epoch: 5| Step: 4
Training loss: 1.6406404972076416
Validation loss: 2.0578676398082445

Epoch: 5| Step: 5
Training loss: 1.6344077587127686
Validation loss: 2.0890764318486696

Epoch: 5| Step: 6
Training loss: 2.1136982440948486
Validation loss: 2.0723289097509077

Epoch: 5| Step: 7
Training loss: 2.104445219039917
Validation loss: 2.0530659383343113

Epoch: 5| Step: 8
Training loss: 1.9604238271713257
Validation loss: 2.044355459110711

Epoch: 5| Step: 9
Training loss: 2.245842218399048
Validation loss: 2.027983796211981

Epoch: 5| Step: 10
Training loss: 2.335847854614258
Validation loss: 2.040185997563024

Epoch: 104| Step: 0
Training loss: 2.5825226306915283
Validation loss: 2.026336513539796

Epoch: 5| Step: 1
Training loss: 2.378476858139038
Validation loss: 2.0412516952842794

Epoch: 5| Step: 2
Training loss: 2.0046041011810303
Validation loss: 2.05798630304234

Epoch: 5| Step: 3
Training loss: 1.778501272201538
Validation loss: 2.0844809188637683

Epoch: 5| Step: 4
Training loss: 2.2994065284729004
Validation loss: 2.1101533238605787

Epoch: 5| Step: 5
Training loss: 2.312391757965088
Validation loss: 2.113351829590336

Epoch: 5| Step: 6
Training loss: 1.995931625366211
Validation loss: 2.1184955822524203

Epoch: 5| Step: 7
Training loss: 2.195528507232666
Validation loss: 2.0809682928105837

Epoch: 5| Step: 8
Training loss: 2.1577067375183105
Validation loss: 2.064117923859627

Epoch: 5| Step: 9
Training loss: 2.3792271614074707
Validation loss: 2.0388177569194506

Epoch: 5| Step: 10
Training loss: 2.3650379180908203
Validation loss: 2.019361442135226

Epoch: 105| Step: 0
Training loss: 2.381168842315674
Validation loss: 2.0199547813784693

Epoch: 5| Step: 1
Training loss: 2.3479297161102295
Validation loss: 2.019178967322073

Epoch: 5| Step: 2
Training loss: 1.7787511348724365
Validation loss: 2.0311237355714202

Epoch: 5| Step: 3
Training loss: 2.322791337966919
Validation loss: 2.0488259369327175

Epoch: 5| Step: 4
Training loss: 2.3623604774475098
Validation loss: 2.088093711483863

Epoch: 5| Step: 5
Training loss: 2.1169819831848145
Validation loss: 2.1145927290762625

Epoch: 5| Step: 6
Training loss: 2.2069485187530518
Validation loss: 2.1198890157925185

Epoch: 5| Step: 7
Training loss: 2.331155300140381
Validation loss: 2.111752522889004

Epoch: 5| Step: 8
Training loss: 2.1251511573791504
Validation loss: 2.05353485127931

Epoch: 5| Step: 9
Training loss: 2.5164666175842285
Validation loss: 2.016466280465485

Epoch: 5| Step: 10
Training loss: 1.9284945726394653
Validation loss: 2.024751640135242

Epoch: 106| Step: 0
Training loss: 2.410642147064209
Validation loss: 2.0097267012442313

Epoch: 5| Step: 1
Training loss: 2.2940750122070312
Validation loss: 2.0440969582526916

Epoch: 5| Step: 2
Training loss: 2.916832685470581
Validation loss: 2.10466020594361

Epoch: 5| Step: 3
Training loss: 2.1727631092071533
Validation loss: 2.130405254261468

Epoch: 5| Step: 4
Training loss: 1.8354839086532593
Validation loss: 2.146174666702106

Epoch: 5| Step: 5
Training loss: 1.823652982711792
Validation loss: 2.093915994449328

Epoch: 5| Step: 6
Training loss: 2.1579043865203857
Validation loss: 2.079706632962791

Epoch: 5| Step: 7
Training loss: 2.682931423187256
Validation loss: 2.053933389725224

Epoch: 5| Step: 8
Training loss: 1.387536883354187
Validation loss: 2.032136822259554

Epoch: 5| Step: 9
Training loss: 2.346937656402588
Validation loss: 2.0293936703794744

Epoch: 5| Step: 10
Training loss: 2.2284510135650635
Validation loss: 2.036570497738418

Epoch: 107| Step: 0
Training loss: 2.77398681640625
Validation loss: 2.044697287262127

Epoch: 5| Step: 1
Training loss: 1.8425655364990234
Validation loss: 2.067807815408194

Epoch: 5| Step: 2
Training loss: 2.8111701011657715
Validation loss: 2.0750694210811327

Epoch: 5| Step: 3
Training loss: 1.6088793277740479
Validation loss: 2.0772827209964877

Epoch: 5| Step: 4
Training loss: 2.3270599842071533
Validation loss: 2.0956861511353524

Epoch: 5| Step: 5
Training loss: 2.103764057159424
Validation loss: 2.0887151431011897

Epoch: 5| Step: 6
Training loss: 2.00467586517334
Validation loss: 2.059817273129699

Epoch: 5| Step: 7
Training loss: 1.9342952966690063
Validation loss: 2.046817136067216

Epoch: 5| Step: 8
Training loss: 1.4584230184555054
Validation loss: 2.05192966358636

Epoch: 5| Step: 9
Training loss: 2.4933524131774902
Validation loss: 2.0755950866207

Epoch: 5| Step: 10
Training loss: 2.733980417251587
Validation loss: 2.1006979660321305

Epoch: 108| Step: 0
Training loss: 2.1906635761260986
Validation loss: 2.0748880088970227

Epoch: 5| Step: 1
Training loss: 1.4674336910247803
Validation loss: 2.0645133936277

Epoch: 5| Step: 2
Training loss: 2.9809093475341797
Validation loss: 2.0612470026939147

Epoch: 5| Step: 3
Training loss: 2.4201550483703613
Validation loss: 2.0463731019727645

Epoch: 5| Step: 4
Training loss: 2.037122964859009
Validation loss: 2.042791913914424

Epoch: 5| Step: 5
Training loss: 1.6482645273208618
Validation loss: 2.040633534872404

Epoch: 5| Step: 6
Training loss: 2.5849227905273438
Validation loss: 2.0492527305438952

Epoch: 5| Step: 7
Training loss: 1.8240289688110352
Validation loss: 2.083955535324671

Epoch: 5| Step: 8
Training loss: 2.2472221851348877
Validation loss: 2.098945379257202

Epoch: 5| Step: 9
Training loss: 2.2720680236816406
Validation loss: 2.060373507520204

Epoch: 5| Step: 10
Training loss: 2.0217018127441406
Validation loss: 2.046905388114273

Epoch: 109| Step: 0
Training loss: 2.4270501136779785
Validation loss: 2.051723341788015

Epoch: 5| Step: 1
Training loss: 1.499328851699829
Validation loss: 2.049283801868398

Epoch: 5| Step: 2
Training loss: 1.4431731700897217
Validation loss: 2.0509641888321086

Epoch: 5| Step: 3
Training loss: 2.418494462966919
Validation loss: 2.048163160201042

Epoch: 5| Step: 4
Training loss: 2.5768160820007324
Validation loss: 2.040731353144492

Epoch: 5| Step: 5
Training loss: 2.0222487449645996
Validation loss: 2.0368824825491956

Epoch: 5| Step: 6
Training loss: 1.8641084432601929
Validation loss: 2.042557385659987

Epoch: 5| Step: 7
Training loss: 2.2001781463623047
Validation loss: 2.0517462607352965

Epoch: 5| Step: 8
Training loss: 1.7153518199920654
Validation loss: 2.0691791554932952

Epoch: 5| Step: 9
Training loss: 2.2324371337890625
Validation loss: 2.0769663062146915

Epoch: 5| Step: 10
Training loss: 3.056083917617798
Validation loss: 2.0962638162797496

Epoch: 110| Step: 0
Training loss: 2.5146572589874268
Validation loss: 2.1048447419238347

Epoch: 5| Step: 1
Training loss: 1.775820016860962
Validation loss: 2.0629721021139495

Epoch: 5| Step: 2
Training loss: 2.3247859477996826
Validation loss: 2.03493344911965

Epoch: 5| Step: 3
Training loss: 2.646479606628418
Validation loss: 2.015134255091349

Epoch: 5| Step: 4
Training loss: 1.9669597148895264
Validation loss: 2.015709159194782

Epoch: 5| Step: 5
Training loss: 2.034353017807007
Validation loss: 2.0204226034943775

Epoch: 5| Step: 6
Training loss: 2.4911961555480957
Validation loss: 2.0340924173273067

Epoch: 5| Step: 7
Training loss: 2.6299190521240234
Validation loss: 2.057854534477316

Epoch: 5| Step: 8
Training loss: 1.598677396774292
Validation loss: 2.086779917440107

Epoch: 5| Step: 9
Training loss: 1.9101669788360596
Validation loss: 2.1047380175641788

Epoch: 5| Step: 10
Training loss: 1.5829591751098633
Validation loss: 2.117567741742698

Epoch: 111| Step: 0
Training loss: 1.9346721172332764
Validation loss: 2.1463050611557497

Epoch: 5| Step: 1
Training loss: 2.4485554695129395
Validation loss: 2.1392728039013442

Epoch: 5| Step: 2
Training loss: 1.5466722249984741
Validation loss: 2.1230630182450816

Epoch: 5| Step: 3
Training loss: 1.8832294940948486
Validation loss: 2.096831249934371

Epoch: 5| Step: 4
Training loss: 2.4665231704711914
Validation loss: 2.071851476546257

Epoch: 5| Step: 5
Training loss: 2.5780069828033447
Validation loss: 2.061202305619435

Epoch: 5| Step: 6
Training loss: 2.5193729400634766
Validation loss: 2.0461881955464682

Epoch: 5| Step: 7
Training loss: 2.1673550605773926
Validation loss: 2.0516176159663866

Epoch: 5| Step: 8
Training loss: 1.2609161138534546
Validation loss: 2.0660507973804267

Epoch: 5| Step: 9
Training loss: 2.3668618202209473
Validation loss: 2.0889267280537593

Epoch: 5| Step: 10
Training loss: 2.14663028717041
Validation loss: 2.088126249210809

Epoch: 112| Step: 0
Training loss: 1.9944350719451904
Validation loss: 2.0852471500314693

Epoch: 5| Step: 1
Training loss: 2.2198383808135986
Validation loss: 2.059029156161893

Epoch: 5| Step: 2
Training loss: 2.412748336791992
Validation loss: 2.0404998256314184

Epoch: 5| Step: 3
Training loss: 1.9115369319915771
Validation loss: 2.01458078558727

Epoch: 5| Step: 4
Training loss: 1.2088205814361572
Validation loss: 2.007618465731221

Epoch: 5| Step: 5
Training loss: 2.314732789993286
Validation loss: 1.9970525195521693

Epoch: 5| Step: 6
Training loss: 1.7850167751312256
Validation loss: 1.9985593749630837

Epoch: 5| Step: 7
Training loss: 1.9128233194351196
Validation loss: 2.0060356201664096

Epoch: 5| Step: 8
Training loss: 2.763202428817749
Validation loss: 2.0929114357117684

Epoch: 5| Step: 9
Training loss: 2.4807357788085938
Validation loss: 2.0953338889665503

Epoch: 5| Step: 10
Training loss: 1.9007611274719238
Validation loss: 2.1238739746873097

Epoch: 113| Step: 0
Training loss: 1.7655999660491943
Validation loss: 2.1361221151967205

Epoch: 5| Step: 1
Training loss: 1.4980756044387817
Validation loss: 2.114192510163912

Epoch: 5| Step: 2
Training loss: 2.36335825920105
Validation loss: 2.0584341377340336

Epoch: 5| Step: 3
Training loss: 2.110072374343872
Validation loss: 2.028770372431765

Epoch: 5| Step: 4
Training loss: 2.26300048828125
Validation loss: 2.024995526959819

Epoch: 5| Step: 5
Training loss: 1.8999477624893188
Validation loss: 2.017947648161201

Epoch: 5| Step: 6
Training loss: 1.9971697330474854
Validation loss: 2.0242580688127907

Epoch: 5| Step: 7
Training loss: 2.4795520305633545
Validation loss: 2.0341958538178475

Epoch: 5| Step: 8
Training loss: 2.2155094146728516
Validation loss: 2.0296598762594242

Epoch: 5| Step: 9
Training loss: 2.314431667327881
Validation loss: 2.0342074235280356

Epoch: 5| Step: 10
Training loss: 2.006913900375366
Validation loss: 2.0289884767224713

Epoch: 114| Step: 0
Training loss: 2.074799060821533
Validation loss: 2.057989776775401

Epoch: 5| Step: 1
Training loss: 1.980650544166565
Validation loss: 2.0782865375600834

Epoch: 5| Step: 2
Training loss: 2.0412635803222656
Validation loss: 2.1075234618238223

Epoch: 5| Step: 3
Training loss: 1.9846502542495728
Validation loss: 2.0959848806422245

Epoch: 5| Step: 4
Training loss: 2.637521743774414
Validation loss: 2.0746103691798385

Epoch: 5| Step: 5
Training loss: 1.7574005126953125
Validation loss: 2.0510486723274313

Epoch: 5| Step: 6
Training loss: 2.3015100955963135
Validation loss: 2.021197977886405

Epoch: 5| Step: 7
Training loss: 2.11617374420166
Validation loss: 2.000364895789854

Epoch: 5| Step: 8
Training loss: 1.9623216390609741
Validation loss: 2.0120395511709233

Epoch: 5| Step: 9
Training loss: 1.657640814781189
Validation loss: 2.0123075054537867

Epoch: 5| Step: 10
Training loss: 2.242898941040039
Validation loss: 2.05656115470394

Epoch: 115| Step: 0
Training loss: 2.308022975921631
Validation loss: 2.077411199128756

Epoch: 5| Step: 1
Training loss: 2.0978128910064697
Validation loss: 2.1025065017002884

Epoch: 5| Step: 2
Training loss: 1.5402958393096924
Validation loss: 2.091980508578721

Epoch: 5| Step: 3
Training loss: 2.3739562034606934
Validation loss: 2.0613971012894825

Epoch: 5| Step: 4
Training loss: 1.8154510259628296
Validation loss: 2.0279745927420993

Epoch: 5| Step: 5
Training loss: 2.383561134338379
Validation loss: 2.012463485040972

Epoch: 5| Step: 6
Training loss: 2.023052453994751
Validation loss: 2.0073869587272726

Epoch: 5| Step: 7
Training loss: 2.306384801864624
Validation loss: 2.0060834500097458

Epoch: 5| Step: 8
Training loss: 1.7629508972167969
Validation loss: 2.0059307518825737

Epoch: 5| Step: 9
Training loss: 2.069533586502075
Validation loss: 2.0172367954766877

Epoch: 5| Step: 10
Training loss: 1.9179503917694092
Validation loss: 2.038244133354515

Epoch: 116| Step: 0
Training loss: 1.6903743743896484
Validation loss: 2.0936261633391022

Epoch: 5| Step: 1
Training loss: 1.656449556350708
Validation loss: 2.10818241488549

Epoch: 5| Step: 2
Training loss: 2.054927110671997
Validation loss: 2.1219524286126576

Epoch: 5| Step: 3
Training loss: 1.8683141469955444
Validation loss: 2.1283289271016277

Epoch: 5| Step: 4
Training loss: 1.9073349237442017
Validation loss: 2.1039496211595434

Epoch: 5| Step: 5
Training loss: 2.393589496612549
Validation loss: 2.078446694599685

Epoch: 5| Step: 6
Training loss: 1.6559957265853882
Validation loss: 2.0699598712305867

Epoch: 5| Step: 7
Training loss: 2.8138749599456787
Validation loss: 2.0561493763359646

Epoch: 5| Step: 8
Training loss: 1.950108528137207
Validation loss: 2.0364073745666014

Epoch: 5| Step: 9
Training loss: 2.654038906097412
Validation loss: 2.039803651071364

Epoch: 5| Step: 10
Training loss: 1.7500120401382446
Validation loss: 2.03584643589553

Epoch: 117| Step: 0
Training loss: 1.5733532905578613
Validation loss: 2.0258042209891864

Epoch: 5| Step: 1
Training loss: 2.452185869216919
Validation loss: 2.029636654802548

Epoch: 5| Step: 2
Training loss: 1.7835161685943604
Validation loss: 2.032498595535114

Epoch: 5| Step: 3
Training loss: 2.111696720123291
Validation loss: 2.0627308942938365

Epoch: 5| Step: 4
Training loss: 1.9435055255889893
Validation loss: 2.080704661466742

Epoch: 5| Step: 5
Training loss: 1.4924285411834717
Validation loss: 2.072729874682683

Epoch: 5| Step: 6
Training loss: 2.263089656829834
Validation loss: 2.084386820434242

Epoch: 5| Step: 7
Training loss: 1.826377511024475
Validation loss: 2.0534973272713284

Epoch: 5| Step: 8
Training loss: 1.8631172180175781
Validation loss: 2.0327862642144643

Epoch: 5| Step: 9
Training loss: 1.833770751953125
Validation loss: 2.007536700976792

Epoch: 5| Step: 10
Training loss: 3.4472553730010986
Validation loss: 2.022400112562282

Epoch: 118| Step: 0
Training loss: 1.6531784534454346
Validation loss: 2.013751742660358

Epoch: 5| Step: 1
Training loss: 1.5246398448944092
Validation loss: 2.0209934532001452

Epoch: 5| Step: 2
Training loss: 2.0802865028381348
Validation loss: 2.0270656847184703

Epoch: 5| Step: 3
Training loss: 2.1720757484436035
Validation loss: 2.0828615593653854

Epoch: 5| Step: 4
Training loss: 2.1354029178619385
Validation loss: 2.094785950517142

Epoch: 5| Step: 5
Training loss: 2.0967371463775635
Validation loss: 2.100141532959477

Epoch: 5| Step: 6
Training loss: 2.1445202827453613
Validation loss: 2.057055611764231

Epoch: 5| Step: 7
Training loss: 2.102731704711914
Validation loss: 2.012453016414437

Epoch: 5| Step: 8
Training loss: 2.652782917022705
Validation loss: 1.9923835928722093

Epoch: 5| Step: 9
Training loss: 1.8248450756072998
Validation loss: 1.9917949758550173

Epoch: 5| Step: 10
Training loss: 1.7660120725631714
Validation loss: 1.9953783083987493

Epoch: 119| Step: 0
Training loss: 1.5581735372543335
Validation loss: 2.021914730789841

Epoch: 5| Step: 1
Training loss: 2.2713046073913574
Validation loss: 2.0524681819382535

Epoch: 5| Step: 2
Training loss: 1.4956153631210327
Validation loss: 2.0810222036095074

Epoch: 5| Step: 3
Training loss: 2.4494965076446533
Validation loss: 2.0881565873340895

Epoch: 5| Step: 4
Training loss: 1.9816672801971436
Validation loss: 2.086039868734216

Epoch: 5| Step: 5
Training loss: 2.10888409614563
Validation loss: 2.121560424886724

Epoch: 5| Step: 6
Training loss: 1.9488213062286377
Validation loss: 2.168683800646054

Epoch: 5| Step: 7
Training loss: 2.2796084880828857
Validation loss: 2.155934185110113

Epoch: 5| Step: 8
Training loss: 2.285756826400757
Validation loss: 2.1349996084808023

Epoch: 5| Step: 9
Training loss: 1.7855198383331299
Validation loss: 2.075147295510897

Epoch: 5| Step: 10
Training loss: 2.1511106491088867
Validation loss: 2.0093743237116004

Epoch: 120| Step: 0
Training loss: 1.991360068321228
Validation loss: 1.9761246147976126

Epoch: 5| Step: 1
Training loss: 2.1244900226593018
Validation loss: 1.9756440270331599

Epoch: 5| Step: 2
Training loss: 1.566821575164795
Validation loss: 1.9771416366741221

Epoch: 5| Step: 3
Training loss: 2.5463576316833496
Validation loss: 1.9658345868510585

Epoch: 5| Step: 4
Training loss: 1.5668185949325562
Validation loss: 1.967856607129497

Epoch: 5| Step: 5
Training loss: 1.6859464645385742
Validation loss: 1.996482164629044

Epoch: 5| Step: 6
Training loss: 2.7260937690734863
Validation loss: 2.03334229992282

Epoch: 5| Step: 7
Training loss: 1.7665542364120483
Validation loss: 2.1022631711857294

Epoch: 5| Step: 8
Training loss: 2.1627187728881836
Validation loss: 2.1671560566912413

Epoch: 5| Step: 9
Training loss: 2.292036533355713
Validation loss: 2.1741204543780257

Epoch: 5| Step: 10
Training loss: 2.059781789779663
Validation loss: 2.1698788007100425

Epoch: 121| Step: 0
Training loss: 2.504970073699951
Validation loss: 2.121735067777736

Epoch: 5| Step: 1
Training loss: 1.8782379627227783
Validation loss: 2.091525529020576

Epoch: 5| Step: 2
Training loss: 1.9476372003555298
Validation loss: 2.0630253566208707

Epoch: 5| Step: 3
Training loss: 1.8205242156982422
Validation loss: 2.042108223002444

Epoch: 5| Step: 4
Training loss: 2.226187229156494
Validation loss: 2.03689972559611

Epoch: 5| Step: 5
Training loss: 1.3191182613372803
Validation loss: 2.045110329504936

Epoch: 5| Step: 6
Training loss: 2.3004631996154785
Validation loss: 2.0450568404248965

Epoch: 5| Step: 7
Training loss: 1.7537482976913452
Validation loss: 2.069669218473537

Epoch: 5| Step: 8
Training loss: 2.1197826862335205
Validation loss: 2.0841243420877764

Epoch: 5| Step: 9
Training loss: 2.4797515869140625
Validation loss: 2.0965505248756817

Epoch: 5| Step: 10
Training loss: 1.4174127578735352
Validation loss: 2.1177333375459075

Epoch: 122| Step: 0
Training loss: 1.5382211208343506
Validation loss: 2.137402405021011

Epoch: 5| Step: 1
Training loss: 1.8051105737686157
Validation loss: 2.140804952190768

Epoch: 5| Step: 2
Training loss: 1.5528608560562134
Validation loss: 2.1388913816021335

Epoch: 5| Step: 3
Training loss: 1.6312131881713867
Validation loss: 2.111595845991565

Epoch: 5| Step: 4
Training loss: 2.8322551250457764
Validation loss: 2.038457016791067

Epoch: 5| Step: 5
Training loss: 1.5490309000015259
Validation loss: 1.9983085816906345

Epoch: 5| Step: 6
Training loss: 1.7649482488632202
Validation loss: 1.9846663193036151

Epoch: 5| Step: 7
Training loss: 2.4270381927490234
Validation loss: 1.9839075124391945

Epoch: 5| Step: 8
Training loss: 1.996677041053772
Validation loss: 1.9837817940660702

Epoch: 5| Step: 9
Training loss: 2.575890302658081
Validation loss: 1.987437100820644

Epoch: 5| Step: 10
Training loss: 2.314771890640259
Validation loss: 1.9890158535331808

Epoch: 123| Step: 0
Training loss: 1.7233247756958008
Validation loss: 2.0090549530521518

Epoch: 5| Step: 1
Training loss: 2.2709572315216064
Validation loss: 2.0603259686500794

Epoch: 5| Step: 2
Training loss: 1.6615301370620728
Validation loss: 2.1093182794509397

Epoch: 5| Step: 3
Training loss: 1.9755394458770752
Validation loss: 2.175078748374857

Epoch: 5| Step: 4
Training loss: 3.1467044353485107
Validation loss: 2.2139603681461786

Epoch: 5| Step: 5
Training loss: 2.067361354827881
Validation loss: 2.171817987195907

Epoch: 5| Step: 6
Training loss: 2.069117307662964
Validation loss: 2.125960842255623

Epoch: 5| Step: 7
Training loss: 1.8657957315444946
Validation loss: 2.087037688942366

Epoch: 5| Step: 8
Training loss: 1.7998902797698975
Validation loss: 2.0319969115718717

Epoch: 5| Step: 9
Training loss: 1.630867600440979
Validation loss: 1.9997512166218092

Epoch: 5| Step: 10
Training loss: 1.5649670362472534
Validation loss: 1.9954712172990203

Epoch: 124| Step: 0
Training loss: 1.5376099348068237
Validation loss: 1.9888319123175837

Epoch: 5| Step: 1
Training loss: 1.823507308959961
Validation loss: 1.9984951685833674

Epoch: 5| Step: 2
Training loss: 1.5142265558242798
Validation loss: 2.002339809171615

Epoch: 5| Step: 3
Training loss: 2.4794363975524902
Validation loss: 2.021509867842479

Epoch: 5| Step: 4
Training loss: 2.337038516998291
Validation loss: 2.049961474633986

Epoch: 5| Step: 5
Training loss: 1.1642961502075195
Validation loss: 2.0691653707975983

Epoch: 5| Step: 6
Training loss: 1.982459306716919
Validation loss: 2.081692103416689

Epoch: 5| Step: 7
Training loss: 1.9615201950073242
Validation loss: 2.1054066932329567

Epoch: 5| Step: 8
Training loss: 2.5146918296813965
Validation loss: 2.1243576272841422

Epoch: 5| Step: 9
Training loss: 2.2854549884796143
Validation loss: 2.138404264244982

Epoch: 5| Step: 10
Training loss: 1.9095380306243896
Validation loss: 2.12175408230033

Epoch: 125| Step: 0
Training loss: 2.5636985301971436
Validation loss: 2.104653436650512

Epoch: 5| Step: 1
Training loss: 2.2815029621124268
Validation loss: 2.063150990393854

Epoch: 5| Step: 2
Training loss: 1.3056341409683228
Validation loss: 2.0313483848366687

Epoch: 5| Step: 3
Training loss: 2.1231000423431396
Validation loss: 2.017920914516654

Epoch: 5| Step: 4
Training loss: 2.4347736835479736
Validation loss: 2.0158142607699157

Epoch: 5| Step: 5
Training loss: 1.9547771215438843
Validation loss: 1.986852894547165

Epoch: 5| Step: 6
Training loss: 2.305105686187744
Validation loss: 1.991393712259108

Epoch: 5| Step: 7
Training loss: 1.2363438606262207
Validation loss: 1.9992006747953353

Epoch: 5| Step: 8
Training loss: 1.9070173501968384
Validation loss: 2.005543675473941

Epoch: 5| Step: 9
Training loss: 1.849570631980896
Validation loss: 2.032428151817732

Epoch: 5| Step: 10
Training loss: 1.249272346496582
Validation loss: 2.0890902639717184

Epoch: 126| Step: 0
Training loss: 2.3552374839782715
Validation loss: 2.188790011149581

Epoch: 5| Step: 1
Training loss: 2.124363422393799
Validation loss: 2.2893769612876316

Epoch: 5| Step: 2
Training loss: 2.14802885055542
Validation loss: 2.283589852753506

Epoch: 5| Step: 3
Training loss: 1.6448570489883423
Validation loss: 2.1868306449664536

Epoch: 5| Step: 4
Training loss: 2.25124192237854
Validation loss: 2.12444906850015

Epoch: 5| Step: 5
Training loss: 2.093792676925659
Validation loss: 2.0735007383490123

Epoch: 5| Step: 6
Training loss: 2.7738382816314697
Validation loss: 2.0421156857603338

Epoch: 5| Step: 7
Training loss: 1.391721487045288
Validation loss: 2.040943702061971

Epoch: 5| Step: 8
Training loss: 1.7311735153198242
Validation loss: 2.0348717679259596

Epoch: 5| Step: 9
Training loss: 1.5004221200942993
Validation loss: 2.017680119442683

Epoch: 5| Step: 10
Training loss: 1.7020093202590942
Validation loss: 2.018743532960133

Epoch: 127| Step: 0
Training loss: 1.81757390499115
Validation loss: 2.024922050455565

Epoch: 5| Step: 1
Training loss: 1.7190265655517578
Validation loss: 2.030894205134402

Epoch: 5| Step: 2
Training loss: 1.248606562614441
Validation loss: 2.043225993392288

Epoch: 5| Step: 3
Training loss: 1.9360630512237549
Validation loss: 2.075035930961691

Epoch: 5| Step: 4
Training loss: 1.9235080480575562
Validation loss: 2.070682165443256

Epoch: 5| Step: 5
Training loss: 2.060009479522705
Validation loss: 2.0893421814005864

Epoch: 5| Step: 6
Training loss: 2.155212879180908
Validation loss: 2.0971137810778875

Epoch: 5| Step: 7
Training loss: 1.7169911861419678
Validation loss: 2.11139016894884

Epoch: 5| Step: 8
Training loss: 2.301567792892456
Validation loss: 2.0954673008252214

Epoch: 5| Step: 9
Training loss: 2.6175780296325684
Validation loss: 2.08317813052926

Epoch: 5| Step: 10
Training loss: 1.441357135772705
Validation loss: 2.0681155548300794

Epoch: 128| Step: 0
Training loss: 2.1322262287139893
Validation loss: 2.0667013840008805

Epoch: 5| Step: 1
Training loss: 1.710777997970581
Validation loss: 2.0699319147294566

Epoch: 5| Step: 2
Training loss: 1.7141468524932861
Validation loss: 2.0757344576620285

Epoch: 5| Step: 3
Training loss: 2.3599464893341064
Validation loss: 2.0839437618050525

Epoch: 5| Step: 4
Training loss: 2.107125759124756
Validation loss: 2.0627351717282365

Epoch: 5| Step: 5
Training loss: 1.8476203680038452
Validation loss: 2.0534938150836575

Epoch: 5| Step: 6
Training loss: 1.648159384727478
Validation loss: 2.0299108002775457

Epoch: 5| Step: 7
Training loss: 2.1807267665863037
Validation loss: 2.0378445297159176

Epoch: 5| Step: 8
Training loss: 1.1950156688690186
Validation loss: 2.028384485552388

Epoch: 5| Step: 9
Training loss: 1.7171428203582764
Validation loss: 2.0357819577699066

Epoch: 5| Step: 10
Training loss: 2.084688186645508
Validation loss: 2.0412110282528784

Epoch: 129| Step: 0
Training loss: 2.9231674671173096
Validation loss: 2.035597385898713

Epoch: 5| Step: 1
Training loss: 1.8644012212753296
Validation loss: 2.0280075316788047

Epoch: 5| Step: 2
Training loss: 1.1654818058013916
Validation loss: 2.0212783864749375

Epoch: 5| Step: 3
Training loss: 1.940721869468689
Validation loss: 2.0241028108904437

Epoch: 5| Step: 4
Training loss: 0.8524304628372192
Validation loss: 2.034892069396152

Epoch: 5| Step: 5
Training loss: 1.9921693801879883
Validation loss: 2.0545344660359044

Epoch: 5| Step: 6
Training loss: 1.9298820495605469
Validation loss: 2.0793289112788376

Epoch: 5| Step: 7
Training loss: 2.2587711811065674
Validation loss: 2.079800562192035

Epoch: 5| Step: 8
Training loss: 1.3092037439346313
Validation loss: 2.072333352540129

Epoch: 5| Step: 9
Training loss: 1.9744634628295898
Validation loss: 2.0455839736487276

Epoch: 5| Step: 10
Training loss: 2.3045706748962402
Validation loss: 2.029526336218721

Epoch: 130| Step: 0
Training loss: 1.8587207794189453
Validation loss: 2.0242063153174614

Epoch: 5| Step: 1
Training loss: 1.5936330556869507
Validation loss: 2.0284643621854883

Epoch: 5| Step: 2
Training loss: 2.016617774963379
Validation loss: 2.0006324527084187

Epoch: 5| Step: 3
Training loss: 2.4777441024780273
Validation loss: 2.0161095998620473

Epoch: 5| Step: 4
Training loss: 1.8629112243652344
Validation loss: 2.0174638635368756

Epoch: 5| Step: 5
Training loss: 1.5802215337753296
Validation loss: 2.0342100140868977

Epoch: 5| Step: 6
Training loss: 1.6003704071044922
Validation loss: 2.0397406367845434

Epoch: 5| Step: 7
Training loss: 1.6291658878326416
Validation loss: 2.0640163242176013

Epoch: 5| Step: 8
Training loss: 1.5569461584091187
Validation loss: 2.0645809993948987

Epoch: 5| Step: 9
Training loss: 1.7072101831436157
Validation loss: 2.0749071349379835

Epoch: 5| Step: 10
Training loss: 2.6482739448547363
Validation loss: 2.0591942776915846

Epoch: 131| Step: 0
Training loss: 2.0262911319732666
Validation loss: 2.0443406181950725

Epoch: 5| Step: 1
Training loss: 2.1807286739349365
Validation loss: 2.0045105564978813

Epoch: 5| Step: 2
Training loss: 1.9774585962295532
Validation loss: 1.9948390709456576

Epoch: 5| Step: 3
Training loss: 1.834020972251892
Validation loss: 1.9903261956348215

Epoch: 5| Step: 4
Training loss: 2.091432571411133
Validation loss: 2.0179815394904024

Epoch: 5| Step: 5
Training loss: 1.7403767108917236
Validation loss: 2.02901594485006

Epoch: 5| Step: 6
Training loss: 1.5702276229858398
Validation loss: 2.0545951422824653

Epoch: 5| Step: 7
Training loss: 2.048711061477661
Validation loss: 2.0563656873600458

Epoch: 5| Step: 8
Training loss: 1.0361473560333252
Validation loss: 2.0498056847562074

Epoch: 5| Step: 9
Training loss: 1.7919228076934814
Validation loss: 2.08100458370742

Epoch: 5| Step: 10
Training loss: 2.283463478088379
Validation loss: 2.086012560834167

Epoch: 132| Step: 0
Training loss: 1.35267174243927
Validation loss: 2.0965984893101517

Epoch: 5| Step: 1
Training loss: 1.8402525186538696
Validation loss: 2.0787521626359675

Epoch: 5| Step: 2
Training loss: 2.128352403640747
Validation loss: 2.0920254594536236

Epoch: 5| Step: 3
Training loss: 1.298753261566162
Validation loss: 2.087491694317069

Epoch: 5| Step: 4
Training loss: 1.3283498287200928
Validation loss: 2.0669783135896087

Epoch: 5| Step: 5
Training loss: 2.168750524520874
Validation loss: 2.0218951689299716

Epoch: 5| Step: 6
Training loss: 2.535536289215088
Validation loss: 1.9902933156618507

Epoch: 5| Step: 7
Training loss: 2.361431360244751
Validation loss: 1.9695947939349758

Epoch: 5| Step: 8
Training loss: 1.4863083362579346
Validation loss: 1.9798406195896927

Epoch: 5| Step: 9
Training loss: 2.400404214859009
Validation loss: 1.9670648190283007

Epoch: 5| Step: 10
Training loss: 1.4947853088378906
Validation loss: 1.9759682788643786

Epoch: 133| Step: 0
Training loss: 2.2290215492248535
Validation loss: 2.0061788725596603

Epoch: 5| Step: 1
Training loss: 1.6583197116851807
Validation loss: 2.0363651116689048

Epoch: 5| Step: 2
Training loss: 2.058596134185791
Validation loss: 2.0643764516358734

Epoch: 5| Step: 3
Training loss: 1.1117103099822998
Validation loss: 2.0483229749946186

Epoch: 5| Step: 4
Training loss: 2.0389599800109863
Validation loss: 2.0361255522697204

Epoch: 5| Step: 5
Training loss: 1.7051551342010498
Validation loss: 2.0166819967249388

Epoch: 5| Step: 6
Training loss: 1.8576900959014893
Validation loss: 2.0304729118142077

Epoch: 5| Step: 7
Training loss: 2.340819835662842
Validation loss: 2.0493913824840257

Epoch: 5| Step: 8
Training loss: 1.6043850183486938
Validation loss: 2.039658660529762

Epoch: 5| Step: 9
Training loss: 1.7849754095077515
Validation loss: 2.0363439295881536

Epoch: 5| Step: 10
Training loss: 2.0255661010742188
Validation loss: 2.0460488206596783

Epoch: 134| Step: 0
Training loss: 1.6306654214859009
Validation loss: 2.0730333225701445

Epoch: 5| Step: 1
Training loss: 2.226274013519287
Validation loss: 2.0631859430702786

Epoch: 5| Step: 2
Training loss: 2.0996670722961426
Validation loss: 2.0736112722786526

Epoch: 5| Step: 3
Training loss: 1.5083500146865845
Validation loss: 2.0361920915624148

Epoch: 5| Step: 4
Training loss: 1.6871322393417358
Validation loss: 2.020118973588431

Epoch: 5| Step: 5
Training loss: 1.3917529582977295
Validation loss: 2.020952137567664

Epoch: 5| Step: 6
Training loss: 1.644643783569336
Validation loss: 2.0240379456550843

Epoch: 5| Step: 7
Training loss: 2.3122668266296387
Validation loss: 2.086691397492604

Epoch: 5| Step: 8
Training loss: 1.2203364372253418
Validation loss: 2.1045306216004076

Epoch: 5| Step: 9
Training loss: 2.53256893157959
Validation loss: 2.1354471791175103

Epoch: 5| Step: 10
Training loss: 1.9842554330825806
Validation loss: 2.0910481945160897

Epoch: 135| Step: 0
Training loss: 2.1312625408172607
Validation loss: 2.054415754092637

Epoch: 5| Step: 1
Training loss: 1.6759121417999268
Validation loss: 2.014195878018615

Epoch: 5| Step: 2
Training loss: 0.8903192281723022
Validation loss: 1.9951889335468251

Epoch: 5| Step: 3
Training loss: 1.4758734703063965
Validation loss: 2.003210408713228

Epoch: 5| Step: 4
Training loss: 1.8265478610992432
Validation loss: 2.0137427109543995

Epoch: 5| Step: 5
Training loss: 1.921587586402893
Validation loss: 2.007492193611719

Epoch: 5| Step: 6
Training loss: 1.848929762840271
Validation loss: 2.0004973283378025

Epoch: 5| Step: 7
Training loss: 2.1116039752960205
Validation loss: 2.000718080869285

Epoch: 5| Step: 8
Training loss: 1.8812192678451538
Validation loss: 2.011865282571444

Epoch: 5| Step: 9
Training loss: 2.0398190021514893
Validation loss: 2.027566320152693

Epoch: 5| Step: 10
Training loss: 1.9041976928710938
Validation loss: 2.034832704451776

Epoch: 136| Step: 0
Training loss: 1.9696013927459717
Validation loss: 2.0393008096243745

Epoch: 5| Step: 1
Training loss: 2.084935426712036
Validation loss: 2.0510093371073403

Epoch: 5| Step: 2
Training loss: 1.7780269384384155
Validation loss: 2.037382712928198

Epoch: 5| Step: 3
Training loss: 1.5517208576202393
Validation loss: 2.014162387899173

Epoch: 5| Step: 4
Training loss: 1.6148388385772705
Validation loss: 2.0132936264878962

Epoch: 5| Step: 5
Training loss: 2.4045119285583496
Validation loss: 2.023404678990764

Epoch: 5| Step: 6
Training loss: 1.953082799911499
Validation loss: 2.0723902871531825

Epoch: 5| Step: 7
Training loss: 1.5097007751464844
Validation loss: 2.048009551981444

Epoch: 5| Step: 8
Training loss: 1.9384596347808838
Validation loss: 2.0574353382151616

Epoch: 5| Step: 9
Training loss: 1.3519690036773682
Validation loss: 2.0467759255440003

Epoch: 5| Step: 10
Training loss: 1.57965886592865
Validation loss: 2.039861963641259

Epoch: 137| Step: 0
Training loss: 1.4432401657104492
Validation loss: 2.0260865919051634

Epoch: 5| Step: 1
Training loss: 1.8087904453277588
Validation loss: 2.008381856385098

Epoch: 5| Step: 2
Training loss: 2.2522330284118652
Validation loss: 1.988199726227791

Epoch: 5| Step: 3
Training loss: 1.795440912246704
Validation loss: 2.0092852564268213

Epoch: 5| Step: 4
Training loss: 1.9156261682510376
Validation loss: 1.9974801912102649

Epoch: 5| Step: 5
Training loss: 1.5038315057754517
Validation loss: 2.0057933727900186

Epoch: 5| Step: 6
Training loss: 2.0209031105041504
Validation loss: 1.9882802104437223

Epoch: 5| Step: 7
Training loss: 1.3351178169250488
Validation loss: 1.97848008524987

Epoch: 5| Step: 8
Training loss: 2.266831159591675
Validation loss: 1.9787203599047918

Epoch: 5| Step: 9
Training loss: 1.3988606929779053
Validation loss: 1.976159300855411

Epoch: 5| Step: 10
Training loss: 1.9380102157592773
Validation loss: 1.9795995425152522

Epoch: 138| Step: 0
Training loss: 1.9331119060516357
Validation loss: 1.9701972905025686

Epoch: 5| Step: 1
Training loss: 2.136335849761963
Validation loss: 1.987184347644929

Epoch: 5| Step: 2
Training loss: 1.8898203372955322
Validation loss: 2.00651309310749

Epoch: 5| Step: 3
Training loss: 1.5246074199676514
Validation loss: 2.011057439670768

Epoch: 5| Step: 4
Training loss: 2.0279698371887207
Validation loss: 2.032377794224729

Epoch: 5| Step: 5
Training loss: 1.824436902999878
Validation loss: 2.050088192826958

Epoch: 5| Step: 6
Training loss: 1.5064127445220947
Validation loss: 2.0797888822452997

Epoch: 5| Step: 7
Training loss: 1.5397307872772217
Validation loss: 2.0643727651206394

Epoch: 5| Step: 8
Training loss: 1.891108512878418
Validation loss: 2.068183036260707

Epoch: 5| Step: 9
Training loss: 2.008084535598755
Validation loss: 2.0428271857641076

Epoch: 5| Step: 10
Training loss: 1.2531626224517822
Validation loss: 2.0149327375555552

Epoch: 139| Step: 0
Training loss: 1.8336169719696045
Validation loss: 2.0212811744341286

Epoch: 5| Step: 1
Training loss: 1.7105724811553955
Validation loss: 2.030685119731452

Epoch: 5| Step: 2
Training loss: 1.4873160123825073
Validation loss: 2.0414737321997203

Epoch: 5| Step: 3
Training loss: 1.408573865890503
Validation loss: 2.065051260814872

Epoch: 5| Step: 4
Training loss: 1.1826999187469482
Validation loss: 2.03098157400726

Epoch: 5| Step: 5
Training loss: 2.172489881515503
Validation loss: 2.016656844846664

Epoch: 5| Step: 6
Training loss: 1.9373400211334229
Validation loss: 1.97394226443383

Epoch: 5| Step: 7
Training loss: 1.5510432720184326
Validation loss: 1.9729910524942542

Epoch: 5| Step: 8
Training loss: 2.5638692378997803
Validation loss: 1.9824406972495459

Epoch: 5| Step: 9
Training loss: 1.9492104053497314
Validation loss: 1.971423420854794

Epoch: 5| Step: 10
Training loss: 1.4817386865615845
Validation loss: 1.9942287065649544

Epoch: 140| Step: 0
Training loss: 1.5805625915527344
Validation loss: 2.020174500762775

Epoch: 5| Step: 1
Training loss: 1.3917982578277588
Validation loss: 2.0645681773462603

Epoch: 5| Step: 2
Training loss: 2.3380630016326904
Validation loss: 2.075192109231026

Epoch: 5| Step: 3
Training loss: 2.111142635345459
Validation loss: 2.0807388854283158

Epoch: 5| Step: 4
Training loss: 1.5609737634658813
Validation loss: 2.0818690510206324

Epoch: 5| Step: 5
Training loss: 1.495945692062378
Validation loss: 2.0577417881258073

Epoch: 5| Step: 6
Training loss: 1.7803751230239868
Validation loss: 2.016412563221429

Epoch: 5| Step: 7
Training loss: 1.4681650400161743
Validation loss: 1.9708730354103992

Epoch: 5| Step: 8
Training loss: 1.7806984186172485
Validation loss: 1.9685026266241585

Epoch: 5| Step: 9
Training loss: 1.424391269683838
Validation loss: 1.9602774304728354

Epoch: 5| Step: 10
Training loss: 2.431600570678711
Validation loss: 1.940796313747283

Epoch: 141| Step: 0
Training loss: 1.8548762798309326
Validation loss: 1.9709588404624694

Epoch: 5| Step: 1
Training loss: 1.6608009338378906
Validation loss: 2.007145135633407

Epoch: 5| Step: 2
Training loss: 1.5101325511932373
Validation loss: 2.0593958259910665

Epoch: 5| Step: 3
Training loss: 1.9765174388885498
Validation loss: 2.0744819974386566

Epoch: 5| Step: 4
Training loss: 1.432263970375061
Validation loss: 2.0603973711690595

Epoch: 5| Step: 5
Training loss: 1.4378873109817505
Validation loss: 2.035302278816059

Epoch: 5| Step: 6
Training loss: 2.017585277557373
Validation loss: 2.03198980516003

Epoch: 5| Step: 7
Training loss: 1.520390510559082
Validation loss: 2.0185943649661158

Epoch: 5| Step: 8
Training loss: 1.8999255895614624
Validation loss: 2.028169006429693

Epoch: 5| Step: 9
Training loss: 2.416062355041504
Validation loss: 2.032868310969363

Epoch: 5| Step: 10
Training loss: 1.437124252319336
Validation loss: 2.0418506796642015

Epoch: 142| Step: 0
Training loss: 2.2582879066467285
Validation loss: 2.0041450608161187

Epoch: 5| Step: 1
Training loss: 1.7686325311660767
Validation loss: 1.9918753664980653

Epoch: 5| Step: 2
Training loss: 1.6224302053451538
Validation loss: 1.9996364783215266

Epoch: 5| Step: 3
Training loss: 1.1714086532592773
Validation loss: 1.959726322081781

Epoch: 5| Step: 4
Training loss: 1.340205192565918
Validation loss: 1.9997356924959409

Epoch: 5| Step: 5
Training loss: 1.8221864700317383
Validation loss: 2.0273472339876237

Epoch: 5| Step: 6
Training loss: 2.5581979751586914
Validation loss: 2.0358840547582155

Epoch: 5| Step: 7
Training loss: 1.792349100112915
Validation loss: 2.0092014010234545

Epoch: 5| Step: 8
Training loss: 1.8566067218780518
Validation loss: 1.9866083078486945

Epoch: 5| Step: 9
Training loss: 1.526529312133789
Validation loss: 1.9860685358765304

Epoch: 5| Step: 10
Training loss: 1.0908435583114624
Validation loss: 2.0055970953356836

Epoch: 143| Step: 0
Training loss: 1.9220249652862549
Validation loss: 2.026666816844735

Epoch: 5| Step: 1
Training loss: 1.8652007579803467
Validation loss: 2.033632478406352

Epoch: 5| Step: 2
Training loss: 1.379092812538147
Validation loss: 2.0239100738238265

Epoch: 5| Step: 3
Training loss: 1.3357471227645874
Validation loss: 2.0088990093559347

Epoch: 5| Step: 4
Training loss: 2.0587010383605957
Validation loss: 2.0177632544630315

Epoch: 5| Step: 5
Training loss: 1.2489056587219238
Validation loss: 2.008214335287771

Epoch: 5| Step: 6
Training loss: 1.7523281574249268
Validation loss: 2.0163526470943163

Epoch: 5| Step: 7
Training loss: 1.9891865253448486
Validation loss: 2.0285944413113337

Epoch: 5| Step: 8
Training loss: 2.4004695415496826
Validation loss: 2.032661203415163

Epoch: 5| Step: 9
Training loss: 1.2254537343978882
Validation loss: 2.0611056768766014

Epoch: 5| Step: 10
Training loss: 1.6156790256500244
Validation loss: 2.0825623825032222

Epoch: 144| Step: 0
Training loss: 1.3777334690093994
Validation loss: 2.0689560687670143

Epoch: 5| Step: 1
Training loss: 1.7824386358261108
Validation loss: 2.0464333411185973

Epoch: 5| Step: 2
Training loss: 1.3079259395599365
Validation loss: 2.025047386846235

Epoch: 5| Step: 3
Training loss: 1.9987268447875977
Validation loss: 2.0119953104244765

Epoch: 5| Step: 4
Training loss: 1.4878780841827393
Validation loss: 1.994763958838678

Epoch: 5| Step: 5
Training loss: 1.2813594341278076
Validation loss: 2.0056673711346042

Epoch: 5| Step: 6
Training loss: 1.745566964149475
Validation loss: 2.016038897216961

Epoch: 5| Step: 7
Training loss: 1.4795873165130615
Validation loss: 2.061603484615203

Epoch: 5| Step: 8
Training loss: 2.220888614654541
Validation loss: 2.1144443891381703

Epoch: 5| Step: 9
Training loss: 2.311117172241211
Validation loss: 2.1428729077821136

Epoch: 5| Step: 10
Training loss: 1.784830093383789
Validation loss: 2.160950360759612

Epoch: 145| Step: 0
Training loss: 1.6836521625518799
Validation loss: 2.1022502222368793

Epoch: 5| Step: 1
Training loss: 1.2789649963378906
Validation loss: 2.0922164429900465

Epoch: 5| Step: 2
Training loss: 2.2586843967437744
Validation loss: 2.0525115241286573

Epoch: 5| Step: 3
Training loss: 0.8436905145645142
Validation loss: 2.0214827188881497

Epoch: 5| Step: 4
Training loss: 1.6541820764541626
Validation loss: 1.9799709614887033

Epoch: 5| Step: 5
Training loss: 1.8230880498886108
Validation loss: 1.978316568559216

Epoch: 5| Step: 6
Training loss: 1.977982521057129
Validation loss: 1.980450484060472

Epoch: 5| Step: 7
Training loss: 1.9004783630371094
Validation loss: 1.9837098403643536

Epoch: 5| Step: 8
Training loss: 2.140568971633911
Validation loss: 1.9898931236677273

Epoch: 5| Step: 9
Training loss: 1.6549882888793945
Validation loss: 2.0185897837403

Epoch: 5| Step: 10
Training loss: 1.51996910572052
Validation loss: 2.036659321477336

Epoch: 146| Step: 0
Training loss: 1.3716272115707397
Validation loss: 2.03115261754682

Epoch: 5| Step: 1
Training loss: 1.842199683189392
Validation loss: 2.023896155818816

Epoch: 5| Step: 2
Training loss: 1.8823299407958984
Validation loss: 1.9945497102634882

Epoch: 5| Step: 3
Training loss: 1.8043264150619507
Validation loss: 1.9708653573066957

Epoch: 5| Step: 4
Training loss: 1.7520904541015625
Validation loss: 1.9572799103234404

Epoch: 5| Step: 5
Training loss: 1.63991379737854
Validation loss: 1.9623321666512439

Epoch: 5| Step: 6
Training loss: 2.0900416374206543
Validation loss: 1.973772677042151

Epoch: 5| Step: 7
Training loss: 1.4457440376281738
Validation loss: 1.9959094614110968

Epoch: 5| Step: 8
Training loss: 1.3123729228973389
Validation loss: 1.9915100528347878

Epoch: 5| Step: 9
Training loss: 1.904894471168518
Validation loss: 2.024473487689931

Epoch: 5| Step: 10
Training loss: 1.6396712064743042
Validation loss: 2.0435525525000786

Epoch: 147| Step: 0
Training loss: 1.6389793157577515
Validation loss: 2.0830155675129225

Epoch: 5| Step: 1
Training loss: 1.8479400873184204
Validation loss: 2.0553865740376134

Epoch: 5| Step: 2
Training loss: 1.429297924041748
Validation loss: 2.0158860503986316

Epoch: 5| Step: 3
Training loss: 1.016606330871582
Validation loss: 1.9781771423996135

Epoch: 5| Step: 4
Training loss: 1.4000499248504639
Validation loss: 1.9564431636564192

Epoch: 5| Step: 5
Training loss: 1.866358995437622
Validation loss: 1.9465733241009455

Epoch: 5| Step: 6
Training loss: 1.8517001867294312
Validation loss: 1.9593829301095778

Epoch: 5| Step: 7
Training loss: 2.0543346405029297
Validation loss: 1.9654986358457995

Epoch: 5| Step: 8
Training loss: 1.9408104419708252
Validation loss: 1.9892536722203737

Epoch: 5| Step: 9
Training loss: 1.5368201732635498
Validation loss: 2.0337750450257333

Epoch: 5| Step: 10
Training loss: 1.8269927501678467
Validation loss: 2.073054341859715

Epoch: 148| Step: 0
Training loss: 2.0049643516540527
Validation loss: 2.076590356006417

Epoch: 5| Step: 1
Training loss: 1.5973365306854248
Validation loss: 2.0586734279509513

Epoch: 5| Step: 2
Training loss: 1.3744299411773682
Validation loss: 2.042789020845967

Epoch: 5| Step: 3
Training loss: 1.581176519393921
Validation loss: 2.04367450616693

Epoch: 5| Step: 4
Training loss: 1.770433783531189
Validation loss: 2.023665726825755

Epoch: 5| Step: 5
Training loss: 1.9566729068756104
Validation loss: 2.0209322937073244

Epoch: 5| Step: 6
Training loss: 1.9029518365859985
Validation loss: 2.0041482704941944

Epoch: 5| Step: 7
Training loss: 1.4477999210357666
Validation loss: 1.9862668885979602

Epoch: 5| Step: 8
Training loss: 1.7226793766021729
Validation loss: 2.0047538665033158

Epoch: 5| Step: 9
Training loss: 1.0559380054473877
Validation loss: 1.995647092019358

Epoch: 5| Step: 10
Training loss: 1.6390151977539062
Validation loss: 2.0156761523216002

Epoch: 149| Step: 0
Training loss: 1.5069541931152344
Validation loss: 2.026498056227161

Epoch: 5| Step: 1
Training loss: 1.6937329769134521
Validation loss: 2.0342426338503437

Epoch: 5| Step: 2
Training loss: 1.7628345489501953
Validation loss: 2.066348801376999

Epoch: 5| Step: 3
Training loss: 1.5780532360076904
Validation loss: 2.0482729083748272

Epoch: 5| Step: 4
Training loss: 1.819728136062622
Validation loss: 2.032894798504409

Epoch: 5| Step: 5
Training loss: 1.2547636032104492
Validation loss: 2.0106858899516444

Epoch: 5| Step: 6
Training loss: 1.6807054281234741
Validation loss: 1.9765591365034862

Epoch: 5| Step: 7
Training loss: 1.4474236965179443
Validation loss: 1.979111712466004

Epoch: 5| Step: 8
Training loss: 1.4955713748931885
Validation loss: 1.9614535531690043

Epoch: 5| Step: 9
Training loss: 1.9858512878417969
Validation loss: 1.9700710247921687

Epoch: 5| Step: 10
Training loss: 1.8402540683746338
Validation loss: 1.9838463926828036

Epoch: 150| Step: 0
Training loss: 1.6929458379745483
Validation loss: 2.0359775943140828

Epoch: 5| Step: 1
Training loss: 1.7424945831298828
Validation loss: 2.0558220827451317

Epoch: 5| Step: 2
Training loss: 1.4328073263168335
Validation loss: 2.0686854085614605

Epoch: 5| Step: 3
Training loss: 0.9592664837837219
Validation loss: 2.0671597475646646

Epoch: 5| Step: 4
Training loss: 1.5046392679214478
Validation loss: 2.0565489146017257

Epoch: 5| Step: 5
Training loss: 1.3441736698150635
Validation loss: 2.074023821020639

Epoch: 5| Step: 6
Training loss: 2.1885180473327637
Validation loss: 2.0588416822494997

Epoch: 5| Step: 7
Training loss: 1.7685238122940063
Validation loss: 2.070163224333076

Epoch: 5| Step: 8
Training loss: 1.7250255346298218
Validation loss: 2.064153504628007

Epoch: 5| Step: 9
Training loss: 1.2850831747055054
Validation loss: 2.0356630330444663

Epoch: 5| Step: 10
Training loss: 2.3456099033355713
Validation loss: 2.017304787071802

Epoch: 151| Step: 0
Training loss: 1.2851083278656006
Validation loss: 2.0096978064506286

Epoch: 5| Step: 1
Training loss: 1.4152724742889404
Validation loss: 2.0050671459526144

Epoch: 5| Step: 2
Training loss: 2.030869722366333
Validation loss: 2.0113818158385572

Epoch: 5| Step: 3
Training loss: 1.4093986749649048
Validation loss: 2.0322346302770797

Epoch: 5| Step: 4
Training loss: 1.567218542098999
Validation loss: 2.0406481655695106

Epoch: 5| Step: 5
Training loss: 1.7660331726074219
Validation loss: 2.0501739978790283

Epoch: 5| Step: 6
Training loss: 1.4792648553848267
Validation loss: 2.047204720076694

Epoch: 5| Step: 7
Training loss: 1.8591673374176025
Validation loss: 2.039102251811694

Epoch: 5| Step: 8
Training loss: 1.3247296810150146
Validation loss: 2.036764065424601

Epoch: 5| Step: 9
Training loss: 1.9519180059432983
Validation loss: 2.01701779519358

Epoch: 5| Step: 10
Training loss: 1.8429003953933716
Validation loss: 2.0072888635819957

Epoch: 152| Step: 0
Training loss: 1.2311971187591553
Validation loss: 2.0036793729310394

Epoch: 5| Step: 1
Training loss: 1.7364095449447632
Validation loss: 2.0114322580317014

Epoch: 5| Step: 2
Training loss: 1.505433440208435
Validation loss: 2.0087242152101252

Epoch: 5| Step: 3
Training loss: 1.2005560398101807
Validation loss: 2.0168495947314846

Epoch: 5| Step: 4
Training loss: 1.6251897811889648
Validation loss: 2.028593594028104

Epoch: 5| Step: 5
Training loss: 1.8772863149642944
Validation loss: 2.08150892103872

Epoch: 5| Step: 6
Training loss: 1.6758296489715576
Validation loss: 2.103018719662902

Epoch: 5| Step: 7
Training loss: 2.0269622802734375
Validation loss: 2.0950239678864837

Epoch: 5| Step: 8
Training loss: 1.216242790222168
Validation loss: 2.084692532016385

Epoch: 5| Step: 9
Training loss: 1.5746006965637207
Validation loss: 2.0458934614735265

Epoch: 5| Step: 10
Training loss: 2.124789237976074
Validation loss: 2.0128859307176326

Epoch: 153| Step: 0
Training loss: 1.2967922687530518
Validation loss: 2.0276177672929663

Epoch: 5| Step: 1
Training loss: 1.9551098346710205
Validation loss: 2.044321201180899

Epoch: 5| Step: 2
Training loss: 1.3246610164642334
Validation loss: 2.034232111387355

Epoch: 5| Step: 3
Training loss: 1.0690391063690186
Validation loss: 2.032078419962237

Epoch: 5| Step: 4
Training loss: 1.7890307903289795
Validation loss: 2.016980104548957

Epoch: 5| Step: 5
Training loss: 1.915527582168579
Validation loss: 2.0423744711824643

Epoch: 5| Step: 6
Training loss: 1.6679699420928955
Validation loss: 2.098369757334391

Epoch: 5| Step: 7
Training loss: 1.947505235671997
Validation loss: 2.118258768512357

Epoch: 5| Step: 8
Training loss: 2.0183444023132324
Validation loss: 2.137921989604991

Epoch: 5| Step: 9
Training loss: 1.682472586631775
Validation loss: 2.145729741742534

Epoch: 5| Step: 10
Training loss: 1.615597128868103
Validation loss: 2.089900529512795

Epoch: 154| Step: 0
Training loss: 1.9409840106964111
Validation loss: 2.048032114582677

Epoch: 5| Step: 1
Training loss: 1.8242638111114502
Validation loss: 2.035507053457281

Epoch: 5| Step: 2
Training loss: 2.1351428031921387
Validation loss: 2.041291590659849

Epoch: 5| Step: 3
Training loss: 1.666032075881958
Validation loss: 2.0332644742022277

Epoch: 5| Step: 4
Training loss: 1.9941189289093018
Validation loss: 2.007886209795552

Epoch: 5| Step: 5
Training loss: 1.2300745248794556
Validation loss: 2.000683597339097

Epoch: 5| Step: 6
Training loss: 0.8055146336555481
Validation loss: 1.9900920890992688

Epoch: 5| Step: 7
Training loss: 1.382289171218872
Validation loss: 1.9923167497880998

Epoch: 5| Step: 8
Training loss: 1.5368987321853638
Validation loss: 2.0604267709998676

Epoch: 5| Step: 9
Training loss: 2.0143823623657227
Validation loss: 2.1189519102855394

Epoch: 5| Step: 10
Training loss: 1.488362431526184
Validation loss: 2.1486282604996876

Epoch: 155| Step: 0
Training loss: 2.389191150665283
Validation loss: 2.1630495530302807

Epoch: 5| Step: 1
Training loss: 1.3518823385238647
Validation loss: 2.150979454799365

Epoch: 5| Step: 2
Training loss: 1.084535837173462
Validation loss: 2.1224902906725482

Epoch: 5| Step: 3
Training loss: 1.5644426345825195
Validation loss: 2.1195461647484892

Epoch: 5| Step: 4
Training loss: 1.7260185480117798
Validation loss: 2.100186747889365

Epoch: 5| Step: 5
Training loss: 1.5488057136535645
Validation loss: 2.083113331948557

Epoch: 5| Step: 6
Training loss: 1.354736566543579
Validation loss: 2.0526956691536853

Epoch: 5| Step: 7
Training loss: 1.7229773998260498
Validation loss: 2.0197306140776603

Epoch: 5| Step: 8
Training loss: 1.7627780437469482
Validation loss: 1.9761475209266908

Epoch: 5| Step: 9
Training loss: 1.4596506357192993
Validation loss: 1.9656507584356493

Epoch: 5| Step: 10
Training loss: 1.6752907037734985
Validation loss: 1.9497725784137685

Epoch: 156| Step: 0
Training loss: 1.7467387914657593
Validation loss: 1.9335373358059955

Epoch: 5| Step: 1
Training loss: 1.389844536781311
Validation loss: 1.9560745646876674

Epoch: 5| Step: 2
Training loss: 1.940818428993225
Validation loss: 1.954268866969693

Epoch: 5| Step: 3
Training loss: 1.3966437578201294
Validation loss: 1.9660399363886925

Epoch: 5| Step: 4
Training loss: 1.6509946584701538
Validation loss: 2.0035302703098585

Epoch: 5| Step: 5
Training loss: 1.6694233417510986
Validation loss: 2.0534608723014913

Epoch: 5| Step: 6
Training loss: 1.5786817073822021
Validation loss: 2.0455416274327103

Epoch: 5| Step: 7
Training loss: 1.3649190664291382
Validation loss: 2.0713010372654086

Epoch: 5| Step: 8
Training loss: 1.7540252208709717
Validation loss: 2.062367573861153

Epoch: 5| Step: 9
Training loss: 1.4823238849639893
Validation loss: 2.038779345891809

Epoch: 5| Step: 10
Training loss: 1.1989271640777588
Validation loss: 1.996074048421716

Epoch: 157| Step: 0
Training loss: 1.3716065883636475
Validation loss: 2.0036597995347876

Epoch: 5| Step: 1
Training loss: 1.8922656774520874
Validation loss: 2.013406567676093

Epoch: 5| Step: 2
Training loss: 1.6447042226791382
Validation loss: 2.02113155652118

Epoch: 5| Step: 3
Training loss: 1.4869375228881836
Validation loss: 2.0687006417141167

Epoch: 5| Step: 4
Training loss: 2.017094850540161
Validation loss: 2.1035100362634145

Epoch: 5| Step: 5
Training loss: 1.8329570293426514
Validation loss: 2.124951354918941

Epoch: 5| Step: 6
Training loss: 2.084554672241211
Validation loss: 2.109144321051977

Epoch: 5| Step: 7
Training loss: 1.0034743547439575
Validation loss: 2.107357518647307

Epoch: 5| Step: 8
Training loss: 1.1015040874481201
Validation loss: 2.1018229248703166

Epoch: 5| Step: 9
Training loss: 1.4280349016189575
Validation loss: 2.0858414749945364

Epoch: 5| Step: 10
Training loss: 1.1937741041183472
Validation loss: 2.0475778861712386

Epoch: 158| Step: 0
Training loss: 1.446840763092041
Validation loss: 1.9925906670990812

Epoch: 5| Step: 1
Training loss: 2.078244209289551
Validation loss: 1.9811438565613122

Epoch: 5| Step: 2
Training loss: 1.034230351448059
Validation loss: 1.9904425580014464

Epoch: 5| Step: 3
Training loss: 1.6289303302764893
Validation loss: 1.9850966904752998

Epoch: 5| Step: 4
Training loss: 1.5240685939788818
Validation loss: 1.9967194141880158

Epoch: 5| Step: 5
Training loss: 1.7779213190078735
Validation loss: 1.995101236527966

Epoch: 5| Step: 6
Training loss: 0.9851258993148804
Validation loss: 2.0091585164429038

Epoch: 5| Step: 7
Training loss: 1.2604796886444092
Validation loss: 2.040292860359274

Epoch: 5| Step: 8
Training loss: 2.137991428375244
Validation loss: 2.112494639171067

Epoch: 5| Step: 9
Training loss: 1.629184365272522
Validation loss: 2.1885661412310857

Epoch: 5| Step: 10
Training loss: 1.349349021911621
Validation loss: 2.1984099893159765

Epoch: 159| Step: 0
Training loss: 1.5028102397918701
Validation loss: 2.195498889492404

Epoch: 5| Step: 1
Training loss: 2.0016067028045654
Validation loss: 2.162646973004905

Epoch: 5| Step: 2
Training loss: 1.0561745166778564
Validation loss: 2.125849016251103

Epoch: 5| Step: 3
Training loss: 1.3188775777816772
Validation loss: 2.078316993610833

Epoch: 5| Step: 4
Training loss: 1.465216875076294
Validation loss: 2.0299197499470045

Epoch: 5| Step: 5
Training loss: 1.1539041996002197
Validation loss: 2.0095153431738577

Epoch: 5| Step: 6
Training loss: 2.0685386657714844
Validation loss: 2.00804925862179

Epoch: 5| Step: 7
Training loss: 1.5809696912765503
Validation loss: 1.999800020648587

Epoch: 5| Step: 8
Training loss: 1.1436331272125244
Validation loss: 1.9813977697844147

Epoch: 5| Step: 9
Training loss: 1.8139667510986328
Validation loss: 1.9901771968410862

Epoch: 5| Step: 10
Training loss: 1.6634893417358398
Validation loss: 1.991306754850572

Epoch: 160| Step: 0
Training loss: 1.8110240697860718
Validation loss: 2.005197209696616

Epoch: 5| Step: 1
Training loss: 1.1742346286773682
Validation loss: 2.0144472455465667

Epoch: 5| Step: 2
Training loss: 1.666907548904419
Validation loss: 2.0468608640855357

Epoch: 5| Step: 3
Training loss: 1.6069221496582031
Validation loss: 2.078746763608789

Epoch: 5| Step: 4
Training loss: 1.5539382696151733
Validation loss: 2.108037328207365

Epoch: 5| Step: 5
Training loss: 1.4185312986373901
Validation loss: 2.1237580648032566

Epoch: 5| Step: 6
Training loss: 1.0987789630889893
Validation loss: 2.1351560136323333

Epoch: 5| Step: 7
Training loss: 1.7653114795684814
Validation loss: 2.1352992698710453

Epoch: 5| Step: 8
Training loss: 1.7180202007293701
Validation loss: 2.10445660673162

Epoch: 5| Step: 9
Training loss: 0.9075158834457397
Validation loss: 2.0495565796411164

Epoch: 5| Step: 10
Training loss: 1.8661723136901855
Validation loss: 2.0173959526964413

Epoch: 161| Step: 0
Training loss: 1.9135310649871826
Validation loss: 1.9704193402362127

Epoch: 5| Step: 1
Training loss: 1.7026294469833374
Validation loss: 1.9602808593421854

Epoch: 5| Step: 2
Training loss: 1.4134953022003174
Validation loss: 1.9841125113989717

Epoch: 5| Step: 3
Training loss: 1.4410748481750488
Validation loss: 1.9723477312313613

Epoch: 5| Step: 4
Training loss: 1.0611846446990967
Validation loss: 1.996913322838404

Epoch: 5| Step: 5
Training loss: 0.9938518404960632
Validation loss: 2.02224087971513

Epoch: 5| Step: 6
Training loss: 1.8533833026885986
Validation loss: 2.051570564187983

Epoch: 5| Step: 7
Training loss: 1.2856900691986084
Validation loss: 2.0555511238754436

Epoch: 5| Step: 8
Training loss: 1.938669204711914
Validation loss: 2.0730470713748725

Epoch: 5| Step: 9
Training loss: 1.2228949069976807
Validation loss: 2.0451533589311826

Epoch: 5| Step: 10
Training loss: 1.130894660949707
Validation loss: 2.032001708143501

Epoch: 162| Step: 0
Training loss: 0.896980881690979
Validation loss: 1.9975329624709262

Epoch: 5| Step: 1
Training loss: 1.2174450159072876
Validation loss: 1.963496611964318

Epoch: 5| Step: 2
Training loss: 1.6970304250717163
Validation loss: 1.9751283725102742

Epoch: 5| Step: 3
Training loss: 1.537776231765747
Validation loss: 1.9606322973005232

Epoch: 5| Step: 4
Training loss: 1.9429872035980225
Validation loss: 1.9559133129735147

Epoch: 5| Step: 5
Training loss: 1.7094228267669678
Validation loss: 1.9866375397610407

Epoch: 5| Step: 6
Training loss: 1.628152847290039
Validation loss: 2.002701017164415

Epoch: 5| Step: 7
Training loss: 1.170435905456543
Validation loss: 2.0177681048711142

Epoch: 5| Step: 8
Training loss: 1.510927438735962
Validation loss: 2.0078221239069456

Epoch: 5| Step: 9
Training loss: 1.5793604850769043
Validation loss: 2.0364660665553105

Epoch: 5| Step: 10
Training loss: 0.9116041660308838
Validation loss: 2.0492546917289816

Epoch: 163| Step: 0
Training loss: 1.485876441001892
Validation loss: 2.0319286648945143

Epoch: 5| Step: 1
Training loss: 1.643437385559082
Validation loss: 2.023326184159966

Epoch: 5| Step: 2
Training loss: 1.122185468673706
Validation loss: 2.015546232141474

Epoch: 5| Step: 3
Training loss: 1.5988801717758179
Validation loss: 2.051235875775737

Epoch: 5| Step: 4
Training loss: 1.593746304512024
Validation loss: 2.096302419580439

Epoch: 5| Step: 5
Training loss: 1.7945973873138428
Validation loss: 2.091746079024448

Epoch: 5| Step: 6
Training loss: 1.52820885181427
Validation loss: 2.120317530888383

Epoch: 5| Step: 7
Training loss: 1.282052755355835
Validation loss: 2.0716233304751817

Epoch: 5| Step: 8
Training loss: 1.0670826435089111
Validation loss: 2.076714143958143

Epoch: 5| Step: 9
Training loss: 1.0997995138168335
Validation loss: 2.047807849863524

Epoch: 5| Step: 10
Training loss: 1.3236737251281738
Validation loss: 2.0428921227814048

Epoch: 164| Step: 0
Training loss: 1.8461635112762451
Validation loss: 2.0324704159972486

Epoch: 5| Step: 1
Training loss: 1.3124717473983765
Validation loss: 2.0327660191443657

Epoch: 5| Step: 2
Training loss: 1.8764644861221313
Validation loss: 2.0361988390645673

Epoch: 5| Step: 3
Training loss: 1.2622783184051514
Validation loss: 2.029650454880089

Epoch: 5| Step: 4
Training loss: 0.8475791811943054
Validation loss: 2.018246063622095

Epoch: 5| Step: 5
Training loss: 1.2706807851791382
Validation loss: 2.0138668911431425

Epoch: 5| Step: 6
Training loss: 1.4870588779449463
Validation loss: 2.000978559576055

Epoch: 5| Step: 7
Training loss: 1.066515564918518
Validation loss: 2.0075890889731784

Epoch: 5| Step: 8
Training loss: 1.2797656059265137
Validation loss: 2.0175651734875095

Epoch: 5| Step: 9
Training loss: 1.42191481590271
Validation loss: 1.988151358019921

Epoch: 5| Step: 10
Training loss: 1.575535535812378
Validation loss: 2.0211224568787443

Epoch: 165| Step: 0
Training loss: 1.053410530090332
Validation loss: 2.0381203825755785

Epoch: 5| Step: 1
Training loss: 1.461232304573059
Validation loss: 2.054447853437034

Epoch: 5| Step: 2
Training loss: 1.4791061878204346
Validation loss: 2.0288937732737553

Epoch: 5| Step: 3
Training loss: 1.3045194149017334
Validation loss: 1.9961769901296145

Epoch: 5| Step: 4
Training loss: 1.777966856956482
Validation loss: 1.9649747494728333

Epoch: 5| Step: 5
Training loss: 1.2667114734649658
Validation loss: 1.9679908470440937

Epoch: 5| Step: 6
Training loss: 1.042052984237671
Validation loss: 1.9754625494762132

Epoch: 5| Step: 7
Training loss: 1.310247540473938
Validation loss: 1.9974634801187823

Epoch: 5| Step: 8
Training loss: 1.2695916891098022
Validation loss: 2.0197991401918474

Epoch: 5| Step: 9
Training loss: 1.3494746685028076
Validation loss: 2.0651322590407504

Epoch: 5| Step: 10
Training loss: 2.0134592056274414
Validation loss: 2.057004354333365

Epoch: 166| Step: 0
Training loss: 1.6664148569107056
Validation loss: 2.0696194094996296

Epoch: 5| Step: 1
Training loss: 1.6333534717559814
Validation loss: 2.0791068692361154

Epoch: 5| Step: 2
Training loss: 1.5079656839370728
Validation loss: 2.073165744863531

Epoch: 5| Step: 3
Training loss: 1.1942437887191772
Validation loss: 2.0445213548598753

Epoch: 5| Step: 4
Training loss: 1.3765558004379272
Validation loss: 2.0398482814911874

Epoch: 5| Step: 5
Training loss: 0.7942337393760681
Validation loss: 2.0537487909358036

Epoch: 5| Step: 6
Training loss: 1.3718125820159912
Validation loss: 2.0653991955582813

Epoch: 5| Step: 7
Training loss: 1.3757152557373047
Validation loss: 2.0475488657592447

Epoch: 5| Step: 8
Training loss: 1.4855754375457764
Validation loss: 1.999133874011296

Epoch: 5| Step: 9
Training loss: 1.2215501070022583
Validation loss: 1.9797010972935667

Epoch: 5| Step: 10
Training loss: 1.561213493347168
Validation loss: 1.9656566727545954

Epoch: 167| Step: 0
Training loss: 1.9852173328399658
Validation loss: 1.957388029303602

Epoch: 5| Step: 1
Training loss: 1.578673005104065
Validation loss: 1.9546056268035725

Epoch: 5| Step: 2
Training loss: 1.749713659286499
Validation loss: 1.9721868781633274

Epoch: 5| Step: 3
Training loss: 1.3298393487930298
Validation loss: 1.9856730814903014

Epoch: 5| Step: 4
Training loss: 1.063145637512207
Validation loss: 1.9983840334799983

Epoch: 5| Step: 5
Training loss: 1.179158329963684
Validation loss: 2.04115584845184

Epoch: 5| Step: 6
Training loss: 1.323448896408081
Validation loss: 2.0589919743999356

Epoch: 5| Step: 7
Training loss: 1.2533369064331055
Validation loss: 2.041625069033715

Epoch: 5| Step: 8
Training loss: 1.194032907485962
Validation loss: 2.0214310628111645

Epoch: 5| Step: 9
Training loss: 1.3991960287094116
Validation loss: 2.0157764124613937

Epoch: 5| Step: 10
Training loss: 0.8857779502868652
Validation loss: 1.9986755822294502

Epoch: 168| Step: 0
Training loss: 1.796200156211853
Validation loss: 1.9950517839001072

Epoch: 5| Step: 1
Training loss: 1.0208494663238525
Validation loss: 1.986575113829746

Epoch: 5| Step: 2
Training loss: 0.8177710771560669
Validation loss: 1.9814926424334127

Epoch: 5| Step: 3
Training loss: 1.5466243028640747
Validation loss: 1.9944489386773878

Epoch: 5| Step: 4
Training loss: 1.0059421062469482
Validation loss: 1.991196863112911

Epoch: 5| Step: 5
Training loss: 1.4910120964050293
Validation loss: 1.9929583764845324

Epoch: 5| Step: 6
Training loss: 1.2740826606750488
Validation loss: 2.0211247872280818

Epoch: 5| Step: 7
Training loss: 1.222259521484375
Validation loss: 1.9904066952325965

Epoch: 5| Step: 8
Training loss: 1.938117265701294
Validation loss: 1.9897751115983533

Epoch: 5| Step: 9
Training loss: 1.071722149848938
Validation loss: 1.980204184850057

Epoch: 5| Step: 10
Training loss: 1.6086312532424927
Validation loss: 1.9777749469203334

Epoch: 169| Step: 0
Training loss: 1.2159219980239868
Validation loss: 1.98972652932649

Epoch: 5| Step: 1
Training loss: 2.1142685413360596
Validation loss: 2.016435800060149

Epoch: 5| Step: 2
Training loss: 1.2905032634735107
Validation loss: 2.040081675334643

Epoch: 5| Step: 3
Training loss: 1.6017671823501587
Validation loss: 2.0739759898954824

Epoch: 5| Step: 4
Training loss: 1.345157265663147
Validation loss: 2.0918870408047914

Epoch: 5| Step: 5
Training loss: 1.3792136907577515
Validation loss: 2.109176076868529

Epoch: 5| Step: 6
Training loss: 1.4531195163726807
Validation loss: 2.104388525409083

Epoch: 5| Step: 7
Training loss: 1.5316097736358643
Validation loss: 2.070970002041068

Epoch: 5| Step: 8
Training loss: 1.1012855768203735
Validation loss: 2.040423595777122

Epoch: 5| Step: 9
Training loss: 0.9433571100234985
Validation loss: 1.9916880207677041

Epoch: 5| Step: 10
Training loss: 0.7006139159202576
Validation loss: 1.9740002924396145

Epoch: 170| Step: 0
Training loss: 1.123546838760376
Validation loss: 1.9396330618089246

Epoch: 5| Step: 1
Training loss: 1.1423993110656738
Validation loss: 1.9287732583220287

Epoch: 5| Step: 2
Training loss: 1.156794786453247
Validation loss: 1.9273402537069013

Epoch: 5| Step: 3
Training loss: 1.5356338024139404
Validation loss: 1.9357069128303117

Epoch: 5| Step: 4
Training loss: 1.2858994007110596
Validation loss: 1.9561077074338031

Epoch: 5| Step: 5
Training loss: 0.9872308969497681
Validation loss: 1.9643176755597513

Epoch: 5| Step: 6
Training loss: 1.0673576593399048
Validation loss: 1.977624390714912

Epoch: 5| Step: 7
Training loss: 1.450761079788208
Validation loss: 1.9632481528866677

Epoch: 5| Step: 8
Training loss: 1.792536973953247
Validation loss: 1.9722328339853594

Epoch: 5| Step: 9
Training loss: 1.831189751625061
Validation loss: 1.9606182934135519

Epoch: 5| Step: 10
Training loss: 0.9976833462715149
Validation loss: 1.981345897079796

Epoch: 171| Step: 0
Training loss: 1.3349136114120483
Validation loss: 1.971577420029589

Epoch: 5| Step: 1
Training loss: 1.27414870262146
Validation loss: 2.0148949443653064

Epoch: 5| Step: 2
Training loss: 0.5388230681419373
Validation loss: 2.001552156222764

Epoch: 5| Step: 3
Training loss: 1.6669952869415283
Validation loss: 2.004761343361229

Epoch: 5| Step: 4
Training loss: 1.2583205699920654
Validation loss: 2.020446044142528

Epoch: 5| Step: 5
Training loss: 1.2642567157745361
Validation loss: 2.0162601547856487

Epoch: 5| Step: 6
Training loss: 1.3152047395706177
Validation loss: 2.040802689008815

Epoch: 5| Step: 7
Training loss: 1.1859692335128784
Validation loss: 2.0519426791898665

Epoch: 5| Step: 8
Training loss: 1.7045364379882812
Validation loss: 2.0709612331082745

Epoch: 5| Step: 9
Training loss: 1.4469281435012817
Validation loss: 2.0683827951390255

Epoch: 5| Step: 10
Training loss: 1.3394018411636353
Validation loss: 2.057113943561431

Epoch: 172| Step: 0
Training loss: 0.7660192847251892
Validation loss: 2.0226951158174904

Epoch: 5| Step: 1
Training loss: 0.9920547604560852
Validation loss: 2.0178997029540358

Epoch: 5| Step: 2
Training loss: 1.1822779178619385
Validation loss: 2.00412808310601

Epoch: 5| Step: 3
Training loss: 1.0417277812957764
Validation loss: 2.02092808036394

Epoch: 5| Step: 4
Training loss: 1.3033748865127563
Validation loss: 2.039261858950379

Epoch: 5| Step: 5
Training loss: 1.663727045059204
Validation loss: 2.0343138838327057

Epoch: 5| Step: 6
Training loss: 1.120140790939331
Validation loss: 1.9965927805951846

Epoch: 5| Step: 7
Training loss: 1.139707326889038
Validation loss: 2.007023747249316

Epoch: 5| Step: 8
Training loss: 1.4673362970352173
Validation loss: 1.989522828850695

Epoch: 5| Step: 9
Training loss: 1.5582776069641113
Validation loss: 1.9916192575167584

Epoch: 5| Step: 10
Training loss: 1.9394721984863281
Validation loss: 1.9934070853776829

Epoch: 173| Step: 0
Training loss: 1.3938924074172974
Validation loss: 2.0033969750968357

Epoch: 5| Step: 1
Training loss: 1.5006721019744873
Validation loss: 2.008106780308549

Epoch: 5| Step: 2
Training loss: 1.3871262073516846
Validation loss: 2.0100640353336128

Epoch: 5| Step: 3
Training loss: 1.4158248901367188
Validation loss: 1.9957798398951048

Epoch: 5| Step: 4
Training loss: 1.2106636762619019
Validation loss: 1.9855512201145131

Epoch: 5| Step: 5
Training loss: 0.8750752210617065
Validation loss: 1.995797130369371

Epoch: 5| Step: 6
Training loss: 1.1910099983215332
Validation loss: 2.0511999617340746

Epoch: 5| Step: 7
Training loss: 1.2845412492752075
Validation loss: 2.0944119602121334

Epoch: 5| Step: 8
Training loss: 1.3388946056365967
Validation loss: 2.125489050342191

Epoch: 5| Step: 9
Training loss: 1.495352029800415
Validation loss: 2.1095839238935903

Epoch: 5| Step: 10
Training loss: 0.7987374663352966
Validation loss: 2.0489834662406676

Epoch: 174| Step: 0
Training loss: 1.334263563156128
Validation loss: 1.9887429680875552

Epoch: 5| Step: 1
Training loss: 1.011303186416626
Validation loss: 2.007416740540535

Epoch: 5| Step: 2
Training loss: 1.1197373867034912
Validation loss: 2.002002928846626

Epoch: 5| Step: 3
Training loss: 1.3573973178863525
Validation loss: 2.0028937862765406

Epoch: 5| Step: 4
Training loss: 1.3822286128997803
Validation loss: 2.002146710631668

Epoch: 5| Step: 5
Training loss: 1.2173959016799927
Validation loss: 1.9964458352775984

Epoch: 5| Step: 6
Training loss: 0.8064433932304382
Validation loss: 2.067841053009033

Epoch: 5| Step: 7
Training loss: 1.4116599559783936
Validation loss: 2.119121910423361

Epoch: 5| Step: 8
Training loss: 1.4356688261032104
Validation loss: 2.1135227346933014

Epoch: 5| Step: 9
Training loss: 1.2114512920379639
Validation loss: 2.1259575402864845

Epoch: 5| Step: 10
Training loss: 2.028660535812378
Validation loss: 2.0271475110002743

Epoch: 175| Step: 0
Training loss: 1.301371455192566
Validation loss: 1.9672743838320497

Epoch: 5| Step: 1
Training loss: 1.347370982170105
Validation loss: 1.9440560930518693

Epoch: 5| Step: 2
Training loss: 1.0181771516799927
Validation loss: 1.959668481221763

Epoch: 5| Step: 3
Training loss: 1.1741631031036377
Validation loss: 1.9668784526086622

Epoch: 5| Step: 4
Training loss: 1.392686128616333
Validation loss: 1.9681684893946494

Epoch: 5| Step: 5
Training loss: 1.087824821472168
Validation loss: 1.9834335875767533

Epoch: 5| Step: 6
Training loss: 1.3411802053451538
Validation loss: 1.995129510920535

Epoch: 5| Step: 7
Training loss: 1.325402855873108
Validation loss: 2.010686424470717

Epoch: 5| Step: 8
Training loss: 1.2990176677703857
Validation loss: 1.9917568032459547

Epoch: 5| Step: 9
Training loss: 0.8107141256332397
Validation loss: 2.0223054027044647

Epoch: 5| Step: 10
Training loss: 1.9829020500183105
Validation loss: 2.0427043643049014

Epoch: 176| Step: 0
Training loss: 1.6955959796905518
Validation loss: 2.079230308532715

Epoch: 5| Step: 1
Training loss: 1.5523861646652222
Validation loss: 2.074769776354554

Epoch: 5| Step: 2
Training loss: 0.9668607711791992
Validation loss: 2.051564734469178

Epoch: 5| Step: 3
Training loss: 0.8053907155990601
Validation loss: 2.038048373755588

Epoch: 5| Step: 4
Training loss: 1.3387072086334229
Validation loss: 2.0204291497507403

Epoch: 5| Step: 5
Training loss: 1.1878979206085205
Validation loss: 2.0154469551578647

Epoch: 5| Step: 6
Training loss: 1.6856781244277954
Validation loss: 2.0329529623831473

Epoch: 5| Step: 7
Training loss: 0.6739696264266968
Validation loss: 1.9847045406218498

Epoch: 5| Step: 8
Training loss: 1.2282230854034424
Validation loss: 1.9886773029963176

Epoch: 5| Step: 9
Training loss: 1.3771389722824097
Validation loss: 2.002563980317885

Epoch: 5| Step: 10
Training loss: 1.2646998167037964
Validation loss: 1.9704150179381013

Epoch: 177| Step: 0
Training loss: 0.9394142031669617
Validation loss: 1.99957150284962

Epoch: 5| Step: 1
Training loss: 1.0421054363250732
Validation loss: 2.012280284717519

Epoch: 5| Step: 2
Training loss: 0.9089304804801941
Validation loss: 2.012006059769661

Epoch: 5| Step: 3
Training loss: 0.9909290075302124
Validation loss: 2.027497215937543

Epoch: 5| Step: 4
Training loss: 1.2621548175811768
Validation loss: 2.04118840412427

Epoch: 5| Step: 5
Training loss: 0.8906718492507935
Validation loss: 2.0017677276365218

Epoch: 5| Step: 6
Training loss: 1.989877700805664
Validation loss: 1.9875278485718595

Epoch: 5| Step: 7
Training loss: 1.402670979499817
Validation loss: 1.972729835458981

Epoch: 5| Step: 8
Training loss: 1.3758481740951538
Validation loss: 1.9818299944682787

Epoch: 5| Step: 9
Training loss: 1.3614479303359985
Validation loss: 2.00791415860576

Epoch: 5| Step: 10
Training loss: 1.5717326402664185
Validation loss: 2.054975780107642

Epoch: 178| Step: 0
Training loss: 1.05429208278656
Validation loss: 2.037965597644929

Epoch: 5| Step: 1
Training loss: 1.3631283044815063
Validation loss: 1.9963203309684672

Epoch: 5| Step: 2
Training loss: 0.8094173669815063
Validation loss: 1.9751277405728576

Epoch: 5| Step: 3
Training loss: 0.9349623918533325
Validation loss: 1.9477426608403523

Epoch: 5| Step: 4
Training loss: 1.1824411153793335
Validation loss: 1.9538378600151307

Epoch: 5| Step: 5
Training loss: 1.490531325340271
Validation loss: 1.9441257574224984

Epoch: 5| Step: 6
Training loss: 0.8496643900871277
Validation loss: 1.9580462260912823

Epoch: 5| Step: 7
Training loss: 1.491187334060669
Validation loss: 1.9755414660258959

Epoch: 5| Step: 8
Training loss: 1.5130245685577393
Validation loss: 1.9853043812577442

Epoch: 5| Step: 9
Training loss: 1.4994986057281494
Validation loss: 2.018613851198586

Epoch: 5| Step: 10
Training loss: 1.1727944612503052
Validation loss: 2.0430193921571136

Epoch: 179| Step: 0
Training loss: 1.307813048362732
Validation loss: 2.104971367825744

Epoch: 5| Step: 1
Training loss: 0.9968467950820923
Validation loss: 2.0776149201136764

Epoch: 5| Step: 2
Training loss: 0.8194138407707214
Validation loss: 2.0543841264581166

Epoch: 5| Step: 3
Training loss: 1.058821678161621
Validation loss: 1.998392387103009

Epoch: 5| Step: 4
Training loss: 1.6647907495498657
Validation loss: 1.974202061212191

Epoch: 5| Step: 5
Training loss: 1.190878987312317
Validation loss: 1.9831364641907394

Epoch: 5| Step: 6
Training loss: 1.1025969982147217
Validation loss: 1.9772829548005135

Epoch: 5| Step: 7
Training loss: 1.3646783828735352
Validation loss: 1.9851199657686296

Epoch: 5| Step: 8
Training loss: 1.7904475927352905
Validation loss: 2.0296449635618474

Epoch: 5| Step: 9
Training loss: 1.215720534324646
Validation loss: 2.0801059507554576

Epoch: 5| Step: 10
Training loss: 1.101688027381897
Validation loss: 2.140671060931298

Epoch: 180| Step: 0
Training loss: 1.0402846336364746
Validation loss: 2.1673259876107656

Epoch: 5| Step: 1
Training loss: 1.3993852138519287
Validation loss: 2.2020376689972414

Epoch: 5| Step: 2
Training loss: 1.5331230163574219
Validation loss: 2.13803752135205

Epoch: 5| Step: 3
Training loss: 1.3242636919021606
Validation loss: 2.0597890525735836

Epoch: 5| Step: 4
Training loss: 0.5739396214485168
Validation loss: 2.0146748660713114

Epoch: 5| Step: 5
Training loss: 1.1501051187515259
Validation loss: 1.9736434439177155

Epoch: 5| Step: 6
Training loss: 1.0018107891082764
Validation loss: 1.9519254289647585

Epoch: 5| Step: 7
Training loss: 0.9799356460571289
Validation loss: 1.9733571480679255

Epoch: 5| Step: 8
Training loss: 1.3191096782684326
Validation loss: 1.9696145519133537

Epoch: 5| Step: 9
Training loss: 1.3410141468048096
Validation loss: 1.9747380274598316

Epoch: 5| Step: 10
Training loss: 1.578737735748291
Validation loss: 2.0106877998639177

Epoch: 181| Step: 0
Training loss: 1.479775071144104
Validation loss: 2.010231899958785

Epoch: 5| Step: 1
Training loss: 1.449908971786499
Validation loss: 2.006152537561232

Epoch: 5| Step: 2
Training loss: 1.2007800340652466
Validation loss: 2.001931123836066

Epoch: 5| Step: 3
Training loss: 1.3660023212432861
Validation loss: 1.9904872166213168

Epoch: 5| Step: 4
Training loss: 1.2717069387435913
Validation loss: 1.9714668155998312

Epoch: 5| Step: 5
Training loss: 1.4101829528808594
Validation loss: 1.93525513269568

Epoch: 5| Step: 6
Training loss: 0.7446273565292358
Validation loss: 1.9538572142201085

Epoch: 5| Step: 7
Training loss: 1.0793358087539673
Validation loss: 1.980520377876938

Epoch: 5| Step: 8
Training loss: 0.9721754789352417
Validation loss: 2.016435223241006

Epoch: 5| Step: 9
Training loss: 1.0109055042266846
Validation loss: 2.0453652284478627

Epoch: 5| Step: 10
Training loss: 1.1245266199111938
Validation loss: 2.051868905303299

Epoch: 182| Step: 0
Training loss: 1.633643388748169
Validation loss: 2.068715900503179

Epoch: 5| Step: 1
Training loss: 1.3384149074554443
Validation loss: 2.0646262655976

Epoch: 5| Step: 2
Training loss: 1.2480905055999756
Validation loss: 2.0541483945744012

Epoch: 5| Step: 3
Training loss: 1.139474868774414
Validation loss: 2.039878959296852

Epoch: 5| Step: 4
Training loss: 0.977887749671936
Validation loss: 2.0525588835439375

Epoch: 5| Step: 5
Training loss: 0.8304397463798523
Validation loss: 2.0311442549510668

Epoch: 5| Step: 6
Training loss: 1.243635654449463
Validation loss: 2.0031610868310414

Epoch: 5| Step: 7
Training loss: 0.9473759531974792
Validation loss: 2.034619131395894

Epoch: 5| Step: 8
Training loss: 1.04317307472229
Validation loss: 2.0449267382262857

Epoch: 5| Step: 9
Training loss: 0.9755752682685852
Validation loss: 2.0432998416244343

Epoch: 5| Step: 10
Training loss: 1.4555332660675049
Validation loss: 2.0526067556873446

Epoch: 183| Step: 0
Training loss: 1.2753210067749023
Validation loss: 2.0194723990655716

Epoch: 5| Step: 1
Training loss: 1.1099202632904053
Validation loss: 2.0020729534087645

Epoch: 5| Step: 2
Training loss: 0.8016929626464844
Validation loss: 1.99023953817224

Epoch: 5| Step: 3
Training loss: 1.4158724546432495
Validation loss: 1.9947499895608554

Epoch: 5| Step: 4
Training loss: 1.4480865001678467
Validation loss: 2.010476038020144

Epoch: 5| Step: 5
Training loss: 1.343640923500061
Validation loss: 2.0239079434384584

Epoch: 5| Step: 6
Training loss: 1.5690968036651611
Validation loss: 2.0158707557186

Epoch: 5| Step: 7
Training loss: 1.1630377769470215
Validation loss: 2.048186990522569

Epoch: 5| Step: 8
Training loss: 0.6655899286270142
Validation loss: 2.085520690487277

Epoch: 5| Step: 9
Training loss: 0.9423999786376953
Validation loss: 2.057918799820767

Epoch: 5| Step: 10
Training loss: 1.1241055727005005
Validation loss: 2.012815826682634

Epoch: 184| Step: 0
Training loss: 1.3846533298492432
Validation loss: 2.0145439832441268

Epoch: 5| Step: 1
Training loss: 1.309988021850586
Validation loss: 1.9782326747012395

Epoch: 5| Step: 2
Training loss: 0.6967946290969849
Validation loss: 1.9767731851147068

Epoch: 5| Step: 3
Training loss: 1.0453957319259644
Validation loss: 1.9571209953677269

Epoch: 5| Step: 4
Training loss: 1.6165144443511963
Validation loss: 1.9559471696935675

Epoch: 5| Step: 5
Training loss: 1.2355220317840576
Validation loss: 1.9635677453010314

Epoch: 5| Step: 6
Training loss: 0.9675722122192383
Validation loss: 1.973951724267775

Epoch: 5| Step: 7
Training loss: 1.232946753501892
Validation loss: 2.010840259572511

Epoch: 5| Step: 8
Training loss: 1.027497410774231
Validation loss: 2.0573244915213635

Epoch: 5| Step: 9
Training loss: 1.0838290452957153
Validation loss: 2.0901263170344855

Epoch: 5| Step: 10
Training loss: 0.9993029236793518
Validation loss: 2.1385264588940527

Epoch: 185| Step: 0
Training loss: 0.9589608907699585
Validation loss: 2.1082417734207644

Epoch: 5| Step: 1
Training loss: 1.3587414026260376
Validation loss: 2.0326379652946227

Epoch: 5| Step: 2
Training loss: 1.1686547994613647
Validation loss: 2.0076918512262325

Epoch: 5| Step: 3
Training loss: 1.4125078916549683
Validation loss: 1.9521926282554545

Epoch: 5| Step: 4
Training loss: 1.0606104135513306
Validation loss: 1.9099112967009186

Epoch: 5| Step: 5
Training loss: 0.9772672653198242
Validation loss: 1.894104496125252

Epoch: 5| Step: 6
Training loss: 1.2119505405426025
Validation loss: 1.9112229295956191

Epoch: 5| Step: 7
Training loss: 1.2877910137176514
Validation loss: 1.9801196103454919

Epoch: 5| Step: 8
Training loss: 0.8110335469245911
Validation loss: 2.0055522687973513

Epoch: 5| Step: 9
Training loss: 1.0492370128631592
Validation loss: 2.014648360590781

Epoch: 5| Step: 10
Training loss: 1.2044100761413574
Validation loss: 2.0053771106145715

Epoch: 186| Step: 0
Training loss: 0.8216094970703125
Validation loss: 2.0224021839839157

Epoch: 5| Step: 1
Training loss: 1.1178672313690186
Validation loss: 2.0142193584031958

Epoch: 5| Step: 2
Training loss: 1.185154676437378
Validation loss: 2.041343265964139

Epoch: 5| Step: 3
Training loss: 1.2637888193130493
Validation loss: 2.0232952538356987

Epoch: 5| Step: 4
Training loss: 0.9960201382637024
Validation loss: 2.0252912134252568

Epoch: 5| Step: 5
Training loss: 0.7467418909072876
Validation loss: 1.9921910762786865

Epoch: 5| Step: 6
Training loss: 0.9952322244644165
Validation loss: 1.981863025696047

Epoch: 5| Step: 7
Training loss: 1.183472752571106
Validation loss: 1.938907782236735

Epoch: 5| Step: 8
Training loss: 1.5561256408691406
Validation loss: 1.933017639703648

Epoch: 5| Step: 9
Training loss: 1.0087497234344482
Validation loss: 1.9287863815984418

Epoch: 5| Step: 10
Training loss: 1.5032743215560913
Validation loss: 1.9482494323484358

Epoch: 187| Step: 0
Training loss: 0.743416965007782
Validation loss: 1.9533680203140422

Epoch: 5| Step: 1
Training loss: 1.2441434860229492
Validation loss: 1.9695650890309324

Epoch: 5| Step: 2
Training loss: 1.1332406997680664
Validation loss: 1.9685778079494354

Epoch: 5| Step: 3
Training loss: 0.7474426031112671
Validation loss: 1.9858878222844933

Epoch: 5| Step: 4
Training loss: 0.9601430892944336
Validation loss: 1.9964760913643786

Epoch: 5| Step: 5
Training loss: 1.220996618270874
Validation loss: 2.0279078060580837

Epoch: 5| Step: 6
Training loss: 1.3372251987457275
Validation loss: 2.045507069556944

Epoch: 5| Step: 7
Training loss: 1.1595370769500732
Validation loss: 2.028557586413558

Epoch: 5| Step: 8
Training loss: 1.230710744857788
Validation loss: 2.0631231287474274

Epoch: 5| Step: 9
Training loss: 1.0569088459014893
Validation loss: 2.07944482116289

Epoch: 5| Step: 10
Training loss: 1.711661696434021
Validation loss: 2.0569785333448842

Epoch: 188| Step: 0
Training loss: 1.2905491590499878
Validation loss: 2.0269453602452434

Epoch: 5| Step: 1
Training loss: 0.7226696014404297
Validation loss: 2.002248212855349

Epoch: 5| Step: 2
Training loss: 1.3292886018753052
Validation loss: 1.9873272924013035

Epoch: 5| Step: 3
Training loss: 1.0683917999267578
Validation loss: 1.9846994248769616

Epoch: 5| Step: 4
Training loss: 0.7983099222183228
Validation loss: 1.9841312618665798

Epoch: 5| Step: 5
Training loss: 1.2419707775115967
Validation loss: 1.9807626919079853

Epoch: 5| Step: 6
Training loss: 1.367086410522461
Validation loss: 1.9755327073476647

Epoch: 5| Step: 7
Training loss: 1.2083876132965088
Validation loss: 1.9648298499404744

Epoch: 5| Step: 8
Training loss: 1.3815891742706299
Validation loss: 1.9575917259339364

Epoch: 5| Step: 9
Training loss: 1.1545944213867188
Validation loss: 1.9551638736519763

Epoch: 5| Step: 10
Training loss: 0.64121413230896
Validation loss: 1.9941915786394508

Epoch: 189| Step: 0
Training loss: 1.4882423877716064
Validation loss: 1.989756916799853

Epoch: 5| Step: 1
Training loss: 0.8091716766357422
Validation loss: 1.980851468219552

Epoch: 5| Step: 2
Training loss: 1.0744285583496094
Validation loss: 1.986661118845786

Epoch: 5| Step: 3
Training loss: 1.586421012878418
Validation loss: 2.001088785868819

Epoch: 5| Step: 4
Training loss: 1.1380906105041504
Validation loss: 2.0012147503514446

Epoch: 5| Step: 5
Training loss: 1.1895726919174194
Validation loss: 1.9758173804129324

Epoch: 5| Step: 6
Training loss: 0.5732814073562622
Validation loss: 1.953708634581617

Epoch: 5| Step: 7
Training loss: 0.9900681376457214
Validation loss: 1.9515085797156058

Epoch: 5| Step: 8
Training loss: 1.3294919729232788
Validation loss: 1.9496972330154911

Epoch: 5| Step: 9
Training loss: 0.9842430949211121
Validation loss: 1.945548967648578

Epoch: 5| Step: 10
Training loss: 0.7726633548736572
Validation loss: 1.9497960664892708

Epoch: 190| Step: 0
Training loss: 0.9490038752555847
Validation loss: 2.005925686128678

Epoch: 5| Step: 1
Training loss: 0.9805909395217896
Validation loss: 2.054572456626482

Epoch: 5| Step: 2
Training loss: 0.7543050050735474
Validation loss: 2.117774869806023

Epoch: 5| Step: 3
Training loss: 0.7745392322540283
Validation loss: 2.133824025430987

Epoch: 5| Step: 4
Training loss: 1.493120551109314
Validation loss: 2.119872162418981

Epoch: 5| Step: 5
Training loss: 0.7851713299751282
Validation loss: 2.0524731323283207

Epoch: 5| Step: 6
Training loss: 1.1731535196304321
Validation loss: 2.055771889225129

Epoch: 5| Step: 7
Training loss: 1.2617181539535522
Validation loss: 2.0472539368496148

Epoch: 5| Step: 8
Training loss: 1.3519500494003296
Validation loss: 2.0407810544454925

Epoch: 5| Step: 9
Training loss: 0.8474866151809692
Validation loss: 2.0230983662348923

Epoch: 5| Step: 10
Training loss: 1.476501703262329
Validation loss: 2.01138949137862

Epoch: 191| Step: 0
Training loss: 1.0509837865829468
Validation loss: 1.992694313808154

Epoch: 5| Step: 1
Training loss: 0.8673003911972046
Validation loss: 1.9758816303745392

Epoch: 5| Step: 2
Training loss: 1.5430892705917358
Validation loss: 1.95918047043585

Epoch: 5| Step: 3
Training loss: 1.0222886800765991
Validation loss: 1.980057539478425

Epoch: 5| Step: 4
Training loss: 1.0921155214309692
Validation loss: 2.0107776977682628

Epoch: 5| Step: 5
Training loss: 0.810615062713623
Validation loss: 2.05271981352119

Epoch: 5| Step: 6
Training loss: 1.0547058582305908
Validation loss: 2.0577616037860995

Epoch: 5| Step: 7
Training loss: 0.8222661018371582
Validation loss: 2.0392649276282198

Epoch: 5| Step: 8
Training loss: 1.3622088432312012
Validation loss: 2.010050888984434

Epoch: 5| Step: 9
Training loss: 1.2736012935638428
Validation loss: 1.9659017337265836

Epoch: 5| Step: 10
Training loss: 0.9998990297317505
Validation loss: 1.9609125596220776

Epoch: 192| Step: 0
Training loss: 1.3352787494659424
Validation loss: 1.9977588153654529

Epoch: 5| Step: 1
Training loss: 0.8878777623176575
Validation loss: 2.016828578005555

Epoch: 5| Step: 2
Training loss: 0.9216820001602173
Validation loss: 2.043564683647566

Epoch: 5| Step: 3
Training loss: 1.470363736152649
Validation loss: 2.0704347907855944

Epoch: 5| Step: 4
Training loss: 0.8355829119682312
Validation loss: 2.1215219984772387

Epoch: 5| Step: 5
Training loss: 0.7759512662887573
Validation loss: 2.101608282776289

Epoch: 5| Step: 6
Training loss: 1.2364108562469482
Validation loss: 2.065118366672147

Epoch: 5| Step: 7
Training loss: 0.7029587030410767
Validation loss: 1.989146024950089

Epoch: 5| Step: 8
Training loss: 1.3332087993621826
Validation loss: 1.954981477029862

Epoch: 5| Step: 9
Training loss: 1.1971527338027954
Validation loss: 1.9167033805642077

Epoch: 5| Step: 10
Training loss: 1.2639859914779663
Validation loss: 1.9076373474572295

Epoch: 193| Step: 0
Training loss: 1.1025190353393555
Validation loss: 1.916659744836951

Epoch: 5| Step: 1
Training loss: 0.7371867895126343
Validation loss: 1.9087044590262956

Epoch: 5| Step: 2
Training loss: 1.2249568700790405
Validation loss: 1.920263574969384

Epoch: 5| Step: 3
Training loss: 0.9184816479682922
Validation loss: 1.9494533410636328

Epoch: 5| Step: 4
Training loss: 0.5620242357254028
Validation loss: 2.0323775968244

Epoch: 5| Step: 5
Training loss: 1.525796890258789
Validation loss: 2.0849136075665875

Epoch: 5| Step: 6
Training loss: 1.563033103942871
Validation loss: 2.1338339723566526

Epoch: 5| Step: 7
Training loss: 0.9478508234024048
Validation loss: 2.1150660155921854

Epoch: 5| Step: 8
Training loss: 1.180755853652954
Validation loss: 2.0726031346987654

Epoch: 5| Step: 9
Training loss: 0.9786775708198547
Validation loss: 2.013137427709436

Epoch: 5| Step: 10
Training loss: 1.190808653831482
Validation loss: 1.9795016216975387

Epoch: 194| Step: 0
Training loss: 1.3827983140945435
Validation loss: 1.9412580907985728

Epoch: 5| Step: 1
Training loss: 0.9604321718215942
Validation loss: 1.9583792122461463

Epoch: 5| Step: 2
Training loss: 1.1439560651779175
Validation loss: 1.9624381065368652

Epoch: 5| Step: 3
Training loss: 0.7286221981048584
Validation loss: 1.9885368411258986

Epoch: 5| Step: 4
Training loss: 1.2394723892211914
Validation loss: 2.0772812084485124

Epoch: 5| Step: 5
Training loss: 1.107356071472168
Validation loss: 2.13473948355644

Epoch: 5| Step: 6
Training loss: 0.9658882021903992
Validation loss: 2.1119478851236324

Epoch: 5| Step: 7
Training loss: 1.1363284587860107
Validation loss: 2.0326669985248196

Epoch: 5| Step: 8
Training loss: 0.7277417182922363
Validation loss: 1.9602458195019794

Epoch: 5| Step: 9
Training loss: 1.0230119228363037
Validation loss: 1.920380271891112

Epoch: 5| Step: 10
Training loss: 1.1470392942428589
Validation loss: 1.9112611816775413

Epoch: 195| Step: 0
Training loss: 0.8961107134819031
Validation loss: 1.9454402513401483

Epoch: 5| Step: 1
Training loss: 1.1029536724090576
Validation loss: 1.949372806856709

Epoch: 5| Step: 2
Training loss: 1.08663010597229
Validation loss: 1.980917066656133

Epoch: 5| Step: 3
Training loss: 1.2183663845062256
Validation loss: 2.0601153142990603

Epoch: 5| Step: 4
Training loss: 1.0418473482131958
Validation loss: 2.0796091197639384

Epoch: 5| Step: 5
Training loss: 1.0098527669906616
Validation loss: 2.0869129152708155

Epoch: 5| Step: 6
Training loss: 1.582765817642212
Validation loss: 2.1016114552815757

Epoch: 5| Step: 7
Training loss: 0.5064083933830261
Validation loss: 2.0643338798194804

Epoch: 5| Step: 8
Training loss: 0.7238953113555908
Validation loss: 2.033313367956428

Epoch: 5| Step: 9
Training loss: 1.0368131399154663
Validation loss: 1.9616481950206142

Epoch: 5| Step: 10
Training loss: 1.2430943250656128
Validation loss: 1.9456426840956493

Epoch: 196| Step: 0
Training loss: 0.849144458770752
Validation loss: 1.9202118689014065

Epoch: 5| Step: 1
Training loss: 0.8717445135116577
Validation loss: 1.9361682950809438

Epoch: 5| Step: 2
Training loss: 1.257935643196106
Validation loss: 1.9745888876658615

Epoch: 5| Step: 3
Training loss: 0.9801534414291382
Validation loss: 2.0388999523655063

Epoch: 5| Step: 4
Training loss: 1.3762738704681396
Validation loss: 2.0696063451869513

Epoch: 5| Step: 5
Training loss: 0.6690760254859924
Validation loss: 2.0814535951101654

Epoch: 5| Step: 6
Training loss: 1.027052402496338
Validation loss: 2.040327079834477

Epoch: 5| Step: 7
Training loss: 0.5566234588623047
Validation loss: 1.9995112521674043

Epoch: 5| Step: 8
Training loss: 1.0219106674194336
Validation loss: 1.9831033893810806

Epoch: 5| Step: 9
Training loss: 1.277918815612793
Validation loss: 1.9479860157094977

Epoch: 5| Step: 10
Training loss: 1.2823153734207153
Validation loss: 1.9525254849464662

Epoch: 197| Step: 0
Training loss: 1.1987111568450928
Validation loss: 1.9609571144145022

Epoch: 5| Step: 1
Training loss: 1.3425886631011963
Validation loss: 1.9792163090039325

Epoch: 5| Step: 2
Training loss: 1.065920352935791
Validation loss: 1.9937279365395988

Epoch: 5| Step: 3
Training loss: 0.9593707323074341
Validation loss: 2.0020740391105734

Epoch: 5| Step: 4
Training loss: 0.8442734479904175
Validation loss: 2.022417673500635

Epoch: 5| Step: 5
Training loss: 1.023864984512329
Validation loss: 2.0389123591043616

Epoch: 5| Step: 6
Training loss: 1.069801688194275
Validation loss: 2.046898361175291

Epoch: 5| Step: 7
Training loss: 1.0213367938995361
Validation loss: 2.0281702433862994

Epoch: 5| Step: 8
Training loss: 0.6895672082901001
Validation loss: 2.0145951727385163

Epoch: 5| Step: 9
Training loss: 0.8492738008499146
Validation loss: 1.9693899795573244

Epoch: 5| Step: 10
Training loss: 1.016871452331543
Validation loss: 1.9405437707901

Epoch: 198| Step: 0
Training loss: 0.9383567571640015
Validation loss: 1.9072166078834123

Epoch: 5| Step: 1
Training loss: 0.9303568601608276
Validation loss: 1.900275658535701

Epoch: 5| Step: 2
Training loss: 0.8049423098564148
Validation loss: 1.89838501714891

Epoch: 5| Step: 3
Training loss: 0.9245044589042664
Validation loss: 1.9146712108324933

Epoch: 5| Step: 4
Training loss: 1.004905343055725
Validation loss: 1.9718677766861454

Epoch: 5| Step: 5
Training loss: 0.8758312463760376
Validation loss: 1.9885601177010486

Epoch: 5| Step: 6
Training loss: 0.8273579478263855
Validation loss: 2.0063381707796486

Epoch: 5| Step: 7
Training loss: 0.8671096563339233
Validation loss: 2.002804289581955

Epoch: 5| Step: 8
Training loss: 1.333622932434082
Validation loss: 1.9461039650824763

Epoch: 5| Step: 9
Training loss: 1.1972044706344604
Validation loss: 1.9231296021451232

Epoch: 5| Step: 10
Training loss: 1.0441277027130127
Validation loss: 1.9378711421002623

Epoch: 199| Step: 0
Training loss: 1.2814940214157104
Validation loss: 1.9363196844695716

Epoch: 5| Step: 1
Training loss: 1.0940988063812256
Validation loss: 1.9677934454333397

Epoch: 5| Step: 2
Training loss: 0.8234584927558899
Validation loss: 1.9788749358987296

Epoch: 5| Step: 3
Training loss: 0.6543235778808594
Validation loss: 1.9799897222108738

Epoch: 5| Step: 4
Training loss: 0.8088523745536804
Validation loss: 1.9945090919412591

Epoch: 5| Step: 5
Training loss: 0.6132739186286926
Validation loss: 1.9999193196655602

Epoch: 5| Step: 6
Training loss: 1.2389824390411377
Validation loss: 2.0307747522989907

Epoch: 5| Step: 7
Training loss: 0.809282124042511
Validation loss: 2.0646814428349978

Epoch: 5| Step: 8
Training loss: 1.4425581693649292
Validation loss: 2.0371858714729227

Epoch: 5| Step: 9
Training loss: 0.4927382469177246
Validation loss: 2.000260122360722

Epoch: 5| Step: 10
Training loss: 1.4286112785339355
Validation loss: 1.970268605857767

Epoch: 200| Step: 0
Training loss: 1.124921441078186
Validation loss: 1.9564611475954774

Epoch: 5| Step: 1
Training loss: 0.8507835268974304
Validation loss: 1.9245369588175127

Epoch: 5| Step: 2
Training loss: 1.203094244003296
Validation loss: 1.922812847680943

Epoch: 5| Step: 3
Training loss: 1.170714020729065
Validation loss: 1.923458787702745

Epoch: 5| Step: 4
Training loss: 0.8577252626419067
Validation loss: 1.949344241490928

Epoch: 5| Step: 5
Training loss: 1.0705674886703491
Validation loss: 1.9797101507904709

Epoch: 5| Step: 6
Training loss: 0.8012339472770691
Validation loss: 1.9965414385641775

Epoch: 5| Step: 7
Training loss: 0.5871917605400085
Validation loss: 2.039264581536734

Epoch: 5| Step: 8
Training loss: 1.0687267780303955
Validation loss: 2.033194435540066

Epoch: 5| Step: 9
Training loss: 0.7510624527931213
Validation loss: 2.02238037765667

Epoch: 5| Step: 10
Training loss: 0.9499881863594055
Validation loss: 2.001356759378987

Epoch: 201| Step: 0
Training loss: 0.7774327397346497
Validation loss: 1.9831079641977947

Epoch: 5| Step: 1
Training loss: 0.9367942810058594
Validation loss: 1.9646564914334206

Epoch: 5| Step: 2
Training loss: 0.8258352279663086
Validation loss: 1.9711772652082546

Epoch: 5| Step: 3
Training loss: 0.7220664024353027
Validation loss: 1.9758751110364032

Epoch: 5| Step: 4
Training loss: 1.2964931726455688
Validation loss: 1.9982273911917081

Epoch: 5| Step: 5
Training loss: 1.0369778871536255
Validation loss: 1.968747179995301

Epoch: 5| Step: 6
Training loss: 0.8685399293899536
Validation loss: 2.0134630985157465

Epoch: 5| Step: 7
Training loss: 1.1153205633163452
Validation loss: 2.025128678608966

Epoch: 5| Step: 8
Training loss: 0.5055714249610901
Validation loss: 2.0562616932776665

Epoch: 5| Step: 9
Training loss: 0.9380303621292114
Validation loss: 2.068629152031355

Epoch: 5| Step: 10
Training loss: 1.3916676044464111
Validation loss: 2.066779144348637

Epoch: 202| Step: 0
Training loss: 0.746374785900116
Validation loss: 2.0233119136543682

Epoch: 5| Step: 1
Training loss: 0.8886272311210632
Validation loss: 1.9754903598498272

Epoch: 5| Step: 2
Training loss: 0.7619233131408691
Validation loss: 1.9288928303667294

Epoch: 5| Step: 3
Training loss: 0.8388110399246216
Validation loss: 1.931543545056415

Epoch: 5| Step: 4
Training loss: 0.9781444668769836
Validation loss: 1.9429389840813094

Epoch: 5| Step: 5
Training loss: 1.1425025463104248
Validation loss: 1.9706813263636764

Epoch: 5| Step: 6
Training loss: 0.8275011777877808
Validation loss: 1.9928568204243977

Epoch: 5| Step: 7
Training loss: 1.0043340921401978
Validation loss: 1.9766885413918445

Epoch: 5| Step: 8
Training loss: 1.3928003311157227
Validation loss: 2.0169355189928444

Epoch: 5| Step: 9
Training loss: 0.9392843246459961
Validation loss: 1.981772530463434

Epoch: 5| Step: 10
Training loss: 0.6506012678146362
Validation loss: 1.9646859912462131

Epoch: 203| Step: 0
Training loss: 0.6800041198730469
Validation loss: 1.9823280457527406

Epoch: 5| Step: 1
Training loss: 1.3710172176361084
Validation loss: 1.9959221834777503

Epoch: 5| Step: 2
Training loss: 0.8169616460800171
Validation loss: 1.9592030791826145

Epoch: 5| Step: 3
Training loss: 0.872378945350647
Validation loss: 1.932722972285363

Epoch: 5| Step: 4
Training loss: 0.8320488929748535
Validation loss: 1.9336955803696827

Epoch: 5| Step: 5
Training loss: 0.9262216687202454
Validation loss: 1.944498885062433

Epoch: 5| Step: 6
Training loss: 1.1870800256729126
Validation loss: 1.9793672241190428

Epoch: 5| Step: 7
Training loss: 0.7577860355377197
Validation loss: 1.9978467341392272

Epoch: 5| Step: 8
Training loss: 1.13799250125885
Validation loss: 2.045630205062128

Epoch: 5| Step: 9
Training loss: 0.7483946084976196
Validation loss: 2.0248947938283286

Epoch: 5| Step: 10
Training loss: 0.8739357590675354
Validation loss: 2.0134118539030834

Epoch: 204| Step: 0
Training loss: 1.1607061624526978
Validation loss: 2.035738903989074

Epoch: 5| Step: 1
Training loss: 0.825273334980011
Validation loss: 2.0087830546081706

Epoch: 5| Step: 2
Training loss: 0.8303691744804382
Validation loss: 2.0158515655866234

Epoch: 5| Step: 3
Training loss: 1.0801316499710083
Validation loss: 2.016049361998035

Epoch: 5| Step: 4
Training loss: 0.9570072889328003
Validation loss: 2.018761670717629

Epoch: 5| Step: 5
Training loss: 1.0619370937347412
Validation loss: 1.9549251987088112

Epoch: 5| Step: 6
Training loss: 0.692838728427887
Validation loss: 1.8743943270816599

Epoch: 5| Step: 7
Training loss: 0.8472204208374023
Validation loss: 1.8635915530625211

Epoch: 5| Step: 8
Training loss: 0.8466863632202148
Validation loss: 1.8549623181743007

Epoch: 5| Step: 9
Training loss: 0.8653804659843445
Validation loss: 1.8785558592888616

Epoch: 5| Step: 10
Training loss: 1.1470462083816528
Validation loss: 1.894962808137299

Epoch: 205| Step: 0
Training loss: 0.7096291780471802
Validation loss: 1.9247415104219991

Epoch: 5| Step: 1
Training loss: 1.0885175466537476
Validation loss: 1.9452457979161253

Epoch: 5| Step: 2
Training loss: 0.6960142850875854
Validation loss: 1.981786424113858

Epoch: 5| Step: 3
Training loss: 0.9026535749435425
Validation loss: 2.002743646662722

Epoch: 5| Step: 4
Training loss: 1.3345333337783813
Validation loss: 2.016185865607313

Epoch: 5| Step: 5
Training loss: 0.7597060203552246
Validation loss: 2.0075636858581216

Epoch: 5| Step: 6
Training loss: 0.7525379657745361
Validation loss: 2.0112535261338755

Epoch: 5| Step: 7
Training loss: 0.9408213496208191
Validation loss: 2.042974228500038

Epoch: 5| Step: 8
Training loss: 1.2595058679580688
Validation loss: 2.06424436261577

Epoch: 5| Step: 9
Training loss: 0.7401387095451355
Validation loss: 2.014328222120962

Epoch: 5| Step: 10
Training loss: 0.8349452018737793
Validation loss: 1.9992689804364276

Epoch: 206| Step: 0
Training loss: 0.66371089220047
Validation loss: 1.9378632268598002

Epoch: 5| Step: 1
Training loss: 0.5374873280525208
Validation loss: 1.9305101427980649

Epoch: 5| Step: 2
Training loss: 0.7135671377182007
Validation loss: 1.9344011224726194

Epoch: 5| Step: 3
Training loss: 0.9338735342025757
Validation loss: 1.9541159188875588

Epoch: 5| Step: 4
Training loss: 0.9085672497749329
Validation loss: 1.9713758294300368

Epoch: 5| Step: 5
Training loss: 1.2527601718902588
Validation loss: 2.0313639666444514

Epoch: 5| Step: 6
Training loss: 0.9332030415534973
Validation loss: 1.9695703303942116

Epoch: 5| Step: 7
Training loss: 1.1995995044708252
Validation loss: 1.9232619077928605

Epoch: 5| Step: 8
Training loss: 0.9665576815605164
Validation loss: 1.914130300603887

Epoch: 5| Step: 9
Training loss: 0.5611395835876465
Validation loss: 1.8931549569611907

Epoch: 5| Step: 10
Training loss: 1.1324266195297241
Validation loss: 1.8834131238281087

Epoch: 207| Step: 0
Training loss: 0.6921324729919434
Validation loss: 1.8991153919568626

Epoch: 5| Step: 1
Training loss: 0.6085756421089172
Validation loss: 1.898776819629054

Epoch: 5| Step: 2
Training loss: 1.160452127456665
Validation loss: 1.8999435773459814

Epoch: 5| Step: 3
Training loss: 0.8431528210639954
Validation loss: 1.9261438295405398

Epoch: 5| Step: 4
Training loss: 0.8805710077285767
Validation loss: 1.9654049975897676

Epoch: 5| Step: 5
Training loss: 1.2531335353851318
Validation loss: 1.9621971550808157

Epoch: 5| Step: 6
Training loss: 0.6817971467971802
Validation loss: 1.9620931533075148

Epoch: 5| Step: 7
Training loss: 0.6189031004905701
Validation loss: 1.9782373379635554

Epoch: 5| Step: 8
Training loss: 1.166080117225647
Validation loss: 1.9628776093964935

Epoch: 5| Step: 9
Training loss: 0.9068028330802917
Validation loss: 1.9366451232664046

Epoch: 5| Step: 10
Training loss: 0.9692508578300476
Validation loss: 1.9181282007566063

Epoch: 208| Step: 0
Training loss: 0.8110917806625366
Validation loss: 1.9337017715618174

Epoch: 5| Step: 1
Training loss: 0.6096295118331909
Validation loss: 1.9414552744998728

Epoch: 5| Step: 2
Training loss: 0.8454629778862
Validation loss: 1.992194426956997

Epoch: 5| Step: 3
Training loss: 0.6217771768569946
Validation loss: 2.011258864915499

Epoch: 5| Step: 4
Training loss: 1.1364847421646118
Validation loss: 2.0175902279474403

Epoch: 5| Step: 5
Training loss: 0.9657910466194153
Validation loss: 1.9816125926151071

Epoch: 5| Step: 6
Training loss: 0.6851170063018799
Validation loss: 1.9922651539566696

Epoch: 5| Step: 7
Training loss: 0.9128549695014954
Validation loss: 2.0069980082973355

Epoch: 5| Step: 8
Training loss: 0.8575623631477356
Validation loss: 1.9825953642527263

Epoch: 5| Step: 9
Training loss: 1.2314305305480957
Validation loss: 1.9690809583151212

Epoch: 5| Step: 10
Training loss: 0.8936229944229126
Validation loss: 1.9682285247310516

Epoch: 209| Step: 0
Training loss: 0.532892107963562
Validation loss: 1.958645502726237

Epoch: 5| Step: 1
Training loss: 1.2985095977783203
Validation loss: 1.9308573469038932

Epoch: 5| Step: 2
Training loss: 0.5824400186538696
Validation loss: 1.918874438090991

Epoch: 5| Step: 3
Training loss: 1.048656702041626
Validation loss: 1.908539132405353

Epoch: 5| Step: 4
Training loss: 0.8246331214904785
Validation loss: 1.89876688039431

Epoch: 5| Step: 5
Training loss: 1.0399210453033447
Validation loss: 1.8727605330046786

Epoch: 5| Step: 6
Training loss: 0.7408548593521118
Validation loss: 1.9062570884663572

Epoch: 5| Step: 7
Training loss: 0.6547980308532715
Validation loss: 1.9229616811198573

Epoch: 5| Step: 8
Training loss: 0.6903408765792847
Validation loss: 1.9365360429210048

Epoch: 5| Step: 9
Training loss: 0.9062367677688599
Validation loss: 1.985565629056705

Epoch: 5| Step: 10
Training loss: 1.0156588554382324
Validation loss: 2.017520740468015

Epoch: 210| Step: 0
Training loss: 0.9256264567375183
Validation loss: 2.016375664741762

Epoch: 5| Step: 1
Training loss: 1.2946836948394775
Validation loss: 1.9819685874446746

Epoch: 5| Step: 2
Training loss: 0.7140059471130371
Validation loss: 1.9659305900655768

Epoch: 5| Step: 3
Training loss: 0.804072380065918
Validation loss: 1.9329481868333713

Epoch: 5| Step: 4
Training loss: 0.9453627467155457
Validation loss: 1.9316039854480374

Epoch: 5| Step: 5
Training loss: 0.4669896960258484
Validation loss: 1.91719860928033

Epoch: 5| Step: 6
Training loss: 0.8641318082809448
Validation loss: 1.9377100672773135

Epoch: 5| Step: 7
Training loss: 0.596245288848877
Validation loss: 1.948010278004472

Epoch: 5| Step: 8
Training loss: 0.8159696459770203
Validation loss: 1.9567687613989717

Epoch: 5| Step: 9
Training loss: 0.7686160802841187
Validation loss: 1.9708486872334634

Epoch: 5| Step: 10
Training loss: 1.0628137588500977
Validation loss: 1.9999368036946943

Epoch: 211| Step: 0
Training loss: 0.8818967938423157
Validation loss: 1.9530383489465202

Epoch: 5| Step: 1
Training loss: 0.8133406639099121
Validation loss: 1.9150692519321237

Epoch: 5| Step: 2
Training loss: 0.9372385144233704
Validation loss: 1.9305133473488592

Epoch: 5| Step: 3
Training loss: 0.9435645341873169
Validation loss: 1.9140628691642516

Epoch: 5| Step: 4
Training loss: 0.50007563829422
Validation loss: 1.9138926113805463

Epoch: 5| Step: 5
Training loss: 0.9182968139648438
Validation loss: 1.913441211946549

Epoch: 5| Step: 6
Training loss: 0.5880530476570129
Validation loss: 1.922198941630702

Epoch: 5| Step: 7
Training loss: 1.3449037075042725
Validation loss: 1.9226363115413214

Epoch: 5| Step: 8
Training loss: 0.8291290402412415
Validation loss: 2.0081039410765453

Epoch: 5| Step: 9
Training loss: 0.9465129971504211
Validation loss: 1.9717522308390627

Epoch: 5| Step: 10
Training loss: 0.44184762239456177
Validation loss: 1.9537443345592869

Epoch: 212| Step: 0
Training loss: 0.675067663192749
Validation loss: 1.9114770838009414

Epoch: 5| Step: 1
Training loss: 0.5910831093788147
Validation loss: 1.8978246386333177

Epoch: 5| Step: 2
Training loss: 1.057131052017212
Validation loss: 1.8615558403794483

Epoch: 5| Step: 3
Training loss: 0.6363075375556946
Validation loss: 1.836001907625506

Epoch: 5| Step: 4
Training loss: 0.7527391910552979
Validation loss: 1.838266036843741

Epoch: 5| Step: 5
Training loss: 1.0298383235931396
Validation loss: 1.8445701394029843

Epoch: 5| Step: 6
Training loss: 1.102523684501648
Validation loss: 1.846906606869031

Epoch: 5| Step: 7
Training loss: 0.6575561761856079
Validation loss: 1.874955875899202

Epoch: 5| Step: 8
Training loss: 0.6370139718055725
Validation loss: 1.9357073665947042

Epoch: 5| Step: 9
Training loss: 1.2189403772354126
Validation loss: 1.945889598579817

Epoch: 5| Step: 10
Training loss: 0.754065752029419
Validation loss: 1.9515154169451805

Epoch: 213| Step: 0
Training loss: 0.46819406747817993
Validation loss: 1.9472216970177108

Epoch: 5| Step: 1
Training loss: 0.8993293642997742
Validation loss: 1.9271969231226111

Epoch: 5| Step: 2
Training loss: 1.222125768661499
Validation loss: 1.914319743392288

Epoch: 5| Step: 3
Training loss: 0.7789500951766968
Validation loss: 1.8983906981765584

Epoch: 5| Step: 4
Training loss: 1.0903470516204834
Validation loss: 1.8877128952292985

Epoch: 5| Step: 5
Training loss: 0.7734991908073425
Validation loss: 1.886793585233791

Epoch: 5| Step: 6
Training loss: 0.7464956641197205
Validation loss: 1.9019883896714898

Epoch: 5| Step: 7
Training loss: 0.7657400369644165
Validation loss: 1.924593674239292

Epoch: 5| Step: 8
Training loss: 0.8530319333076477
Validation loss: 1.9494212353101341

Epoch: 5| Step: 9
Training loss: 0.56485515832901
Validation loss: 1.9655456325059295

Epoch: 5| Step: 10
Training loss: 0.6982882618904114
Validation loss: 1.981657958799793

Epoch: 214| Step: 0
Training loss: 0.6648195385932922
Validation loss: 1.9662329778876355

Epoch: 5| Step: 1
Training loss: 0.6741050481796265
Validation loss: 1.90481383826143

Epoch: 5| Step: 2
Training loss: 1.044501543045044
Validation loss: 1.8766255045449862

Epoch: 5| Step: 3
Training loss: 0.9761784672737122
Validation loss: 1.8600817457322152

Epoch: 5| Step: 4
Training loss: 0.6527584195137024
Validation loss: 1.8411783556784354

Epoch: 5| Step: 5
Training loss: 0.7791152000427246
Validation loss: 1.8562695390434676

Epoch: 5| Step: 6
Training loss: 0.890259861946106
Validation loss: 1.86175327275389

Epoch: 5| Step: 7
Training loss: 0.6405807733535767
Validation loss: 1.8680873404267013

Epoch: 5| Step: 8
Training loss: 0.6863888502120972
Validation loss: 1.8649805873952887

Epoch: 5| Step: 9
Training loss: 0.7002533078193665
Validation loss: 1.904465509999183

Epoch: 5| Step: 10
Training loss: 1.2329639196395874
Validation loss: 1.962816676785869

Epoch: 215| Step: 0
Training loss: 0.931395411491394
Validation loss: 1.991871710746519

Epoch: 5| Step: 1
Training loss: 0.7416208982467651
Validation loss: 1.98938109285088

Epoch: 5| Step: 2
Training loss: 0.694660484790802
Validation loss: 1.95585915734691

Epoch: 5| Step: 3
Training loss: 0.932927131652832
Validation loss: 1.9180690780762704

Epoch: 5| Step: 4
Training loss: 0.5763238668441772
Validation loss: 1.878371274599465

Epoch: 5| Step: 5
Training loss: 0.7514997124671936
Validation loss: 1.8689867399072135

Epoch: 5| Step: 6
Training loss: 0.7676328420639038
Validation loss: 1.850077611143871

Epoch: 5| Step: 7
Training loss: 0.4951690137386322
Validation loss: 1.8618112802505493

Epoch: 5| Step: 8
Training loss: 1.0378507375717163
Validation loss: 1.8992104068879159

Epoch: 5| Step: 9
Training loss: 0.9995971918106079
Validation loss: 1.9241176215551232

Epoch: 5| Step: 10
Training loss: 0.8898998498916626
Validation loss: 1.930623448023232

Epoch: 216| Step: 0
Training loss: 0.5783075094223022
Validation loss: 1.9528385311044671

Epoch: 5| Step: 1
Training loss: 0.5460917353630066
Validation loss: 1.9797895928864837

Epoch: 5| Step: 2
Training loss: 0.9757553339004517
Validation loss: 1.9801892824070428

Epoch: 5| Step: 3
Training loss: 0.5868560075759888
Validation loss: 1.9966537414058563

Epoch: 5| Step: 4
Training loss: 0.6225078701972961
Validation loss: 1.9761829735130392

Epoch: 5| Step: 5
Training loss: 0.584309458732605
Validation loss: 1.9317750212966756

Epoch: 5| Step: 6
Training loss: 0.7672343254089355
Validation loss: 1.914437843907264

Epoch: 5| Step: 7
Training loss: 1.0537384748458862
Validation loss: 1.8940898449190202

Epoch: 5| Step: 8
Training loss: 1.3597482442855835
Validation loss: 1.877688648880169

Epoch: 5| Step: 9
Training loss: 0.8767145276069641
Validation loss: 1.8407036912056707

Epoch: 5| Step: 10
Training loss: 0.8215187191963196
Validation loss: 1.848757887399325

Epoch: 217| Step: 0
Training loss: 0.9879239797592163
Validation loss: 1.8787297715422928

Epoch: 5| Step: 1
Training loss: 0.582405686378479
Validation loss: 1.8644194949057795

Epoch: 5| Step: 2
Training loss: 0.7949081659317017
Validation loss: 1.8831051523967455

Epoch: 5| Step: 3
Training loss: 0.568649411201477
Validation loss: 1.897048299030591

Epoch: 5| Step: 4
Training loss: 0.608482837677002
Validation loss: 1.9132716501912763

Epoch: 5| Step: 5
Training loss: 0.7341358661651611
Validation loss: 1.9483949394636257

Epoch: 5| Step: 6
Training loss: 0.7737118005752563
Validation loss: 1.953220372558922

Epoch: 5| Step: 7
Training loss: 0.747939944267273
Validation loss: 1.952218355671052

Epoch: 5| Step: 8
Training loss: 1.0945765972137451
Validation loss: 1.9189550530525945

Epoch: 5| Step: 9
Training loss: 0.8304013013839722
Validation loss: 1.9097756275566675

Epoch: 5| Step: 10
Training loss: 0.9708207249641418
Validation loss: 1.915612918074413

Epoch: 218| Step: 0
Training loss: 0.8211910128593445
Validation loss: 1.9159158019609348

Epoch: 5| Step: 1
Training loss: 0.8199737668037415
Validation loss: 1.913112485280601

Epoch: 5| Step: 2
Training loss: 0.8309470415115356
Validation loss: 1.9336964571347801

Epoch: 5| Step: 3
Training loss: 0.7567089796066284
Validation loss: 1.9303260567367717

Epoch: 5| Step: 4
Training loss: 0.5057193040847778
Validation loss: 1.9181596361180788

Epoch: 5| Step: 5
Training loss: 0.6909445524215698
Validation loss: 1.9291162516481133

Epoch: 5| Step: 6
Training loss: 0.4635368883609772
Validation loss: 1.9479151387368479

Epoch: 5| Step: 7
Training loss: 0.7459216117858887
Validation loss: 1.9850701426946988

Epoch: 5| Step: 8
Training loss: 1.1408476829528809
Validation loss: 2.0033344581562984

Epoch: 5| Step: 9
Training loss: 0.9127006530761719
Validation loss: 1.9725908874183573

Epoch: 5| Step: 10
Training loss: 0.7499394416809082
Validation loss: 1.9589818062320832

Epoch: 219| Step: 0
Training loss: 0.5058284997940063
Validation loss: 1.9380603464700843

Epoch: 5| Step: 1
Training loss: 0.615925669670105
Validation loss: 1.9377047784866825

Epoch: 5| Step: 2
Training loss: 0.7177205681800842
Validation loss: 1.9218628970525597

Epoch: 5| Step: 3
Training loss: 0.6965478658676147
Validation loss: 1.9171759851517216

Epoch: 5| Step: 4
Training loss: 0.9028645753860474
Validation loss: 1.8697915115664083

Epoch: 5| Step: 5
Training loss: 0.8876758813858032
Validation loss: 1.8405239684607393

Epoch: 5| Step: 6
Training loss: 0.8903969526290894
Validation loss: 1.8460089006731588

Epoch: 5| Step: 7
Training loss: 0.6122652292251587
Validation loss: 1.8272693990379252

Epoch: 5| Step: 8
Training loss: 0.8962782025337219
Validation loss: 1.8521320358399422

Epoch: 5| Step: 9
Training loss: 1.1925171613693237
Validation loss: 1.8505617418596823

Epoch: 5| Step: 10
Training loss: 0.7002268433570862
Validation loss: 1.891023717900758

Epoch: 220| Step: 0
Training loss: 1.0762964487075806
Validation loss: 1.9281926372999787

Epoch: 5| Step: 1
Training loss: 0.5171703100204468
Validation loss: 1.974035483534618

Epoch: 5| Step: 2
Training loss: 0.5420225858688354
Validation loss: 2.003043915635796

Epoch: 5| Step: 3
Training loss: 0.7610658407211304
Validation loss: 1.9677284891887377

Epoch: 5| Step: 4
Training loss: 0.49048489332199097
Validation loss: 1.9369307525696293

Epoch: 5| Step: 5
Training loss: 1.0149667263031006
Validation loss: 1.883132557715139

Epoch: 5| Step: 6
Training loss: 0.5924025774002075
Validation loss: 1.8390117550408969

Epoch: 5| Step: 7
Training loss: 0.6159486770629883
Validation loss: 1.8238891504144157

Epoch: 5| Step: 8
Training loss: 0.8552457690238953
Validation loss: 1.865544572953255

Epoch: 5| Step: 9
Training loss: 0.8388720750808716
Validation loss: 1.8539486854307112

Epoch: 5| Step: 10
Training loss: 1.1944663524627686
Validation loss: 1.8653389433378815

Epoch: 221| Step: 0
Training loss: 1.0526387691497803
Validation loss: 1.8678949802152571

Epoch: 5| Step: 1
Training loss: 0.6024619340896606
Validation loss: 1.891068766194005

Epoch: 5| Step: 2
Training loss: 0.692520260810852
Validation loss: 1.9207446421346357

Epoch: 5| Step: 3
Training loss: 0.6619741320610046
Validation loss: 1.959479021769698

Epoch: 5| Step: 4
Training loss: 0.7373684644699097
Validation loss: 1.999021686533446

Epoch: 5| Step: 5
Training loss: 0.9028779864311218
Validation loss: 2.026777950666284

Epoch: 5| Step: 6
Training loss: 0.7602128982543945
Validation loss: 2.04315605214847

Epoch: 5| Step: 7
Training loss: 0.8212958574295044
Validation loss: 1.9740021933791458

Epoch: 5| Step: 8
Training loss: 0.48949700593948364
Validation loss: 1.8960311592266124

Epoch: 5| Step: 9
Training loss: 0.8373914957046509
Validation loss: 1.8582798870660926

Epoch: 5| Step: 10
Training loss: 0.7756227850914001
Validation loss: 1.8211788772254862

Epoch: 222| Step: 0
Training loss: 0.6895794868469238
Validation loss: 1.8224954297465663

Epoch: 5| Step: 1
Training loss: 0.9044920206069946
Validation loss: 1.842465712178138

Epoch: 5| Step: 2
Training loss: 0.6266940832138062
Validation loss: 1.8347033505798669

Epoch: 5| Step: 3
Training loss: 1.1791789531707764
Validation loss: 1.8455258633500786

Epoch: 5| Step: 4
Training loss: 0.6968153715133667
Validation loss: 1.8388372877592682

Epoch: 5| Step: 5
Training loss: 0.7783597707748413
Validation loss: 1.8627295224897322

Epoch: 5| Step: 6
Training loss: 0.7859246730804443
Validation loss: 1.8612307015285696

Epoch: 5| Step: 7
Training loss: 0.7670930027961731
Validation loss: 1.848984411967698

Epoch: 5| Step: 8
Training loss: 0.6163164377212524
Validation loss: 1.8633063762418685

Epoch: 5| Step: 9
Training loss: 0.7076830863952637
Validation loss: 1.8789011368187525

Epoch: 5| Step: 10
Training loss: 0.5141091346740723
Validation loss: 1.8737354675928752

Epoch: 223| Step: 0
Training loss: 0.7607046961784363
Validation loss: 1.8670467779200564

Epoch: 5| Step: 1
Training loss: 1.0535061359405518
Validation loss: 1.9132676778301116

Epoch: 5| Step: 2
Training loss: 0.6014595627784729
Validation loss: 1.9158936546694847

Epoch: 5| Step: 3
Training loss: 0.4753456115722656
Validation loss: 1.9392577858381375

Epoch: 5| Step: 4
Training loss: 0.6615132093429565
Validation loss: 1.9529366083042596

Epoch: 5| Step: 5
Training loss: 0.9816415905952454
Validation loss: 1.9345024580596595

Epoch: 5| Step: 6
Training loss: 0.6258500814437866
Validation loss: 1.8627622281351397

Epoch: 5| Step: 7
Training loss: 0.4138391613960266
Validation loss: 1.864306349908152

Epoch: 5| Step: 8
Training loss: 0.5185607671737671
Validation loss: 1.88604320761978

Epoch: 5| Step: 9
Training loss: 0.9191164970397949
Validation loss: 1.8348398618800665

Epoch: 5| Step: 10
Training loss: 0.9513112306594849
Validation loss: 1.854675095568421

Epoch: 224| Step: 0
Training loss: 0.9223781824111938
Validation loss: 1.8508441102120183

Epoch: 5| Step: 1
Training loss: 0.46768125891685486
Validation loss: 1.8528716102723153

Epoch: 5| Step: 2
Training loss: 0.5515430569648743
Validation loss: 1.8654708375212967

Epoch: 5| Step: 3
Training loss: 0.9225251078605652
Validation loss: 1.8904675335012457

Epoch: 5| Step: 4
Training loss: 0.7323482632637024
Validation loss: 1.9131429169767646

Epoch: 5| Step: 5
Training loss: 0.4746931195259094
Validation loss: 1.9408649039524857

Epoch: 5| Step: 6
Training loss: 0.8013556599617004
Validation loss: 1.9873622437959075

Epoch: 5| Step: 7
Training loss: 0.577141523361206
Validation loss: 2.0259028878263248

Epoch: 5| Step: 8
Training loss: 0.6680924892425537
Validation loss: 1.9923917811403993

Epoch: 5| Step: 9
Training loss: 0.9748852849006653
Validation loss: 1.9356038070494128

Epoch: 5| Step: 10
Training loss: 1.195030927658081
Validation loss: 1.9168692673406293

Epoch: 225| Step: 0
Training loss: 0.6461986303329468
Validation loss: 1.8943442016519525

Epoch: 5| Step: 1
Training loss: 0.7073618769645691
Validation loss: 1.891082573962468

Epoch: 5| Step: 2
Training loss: 0.7043781876564026
Validation loss: 1.9001984570616035

Epoch: 5| Step: 3
Training loss: 0.4855808615684509
Validation loss: 1.9330526897984166

Epoch: 5| Step: 4
Training loss: 0.7680579423904419
Validation loss: 1.9214404347122356

Epoch: 5| Step: 5
Training loss: 0.746927797794342
Validation loss: 1.9974075863438268

Epoch: 5| Step: 6
Training loss: 0.4286244809627533
Validation loss: 1.9715127509127381

Epoch: 5| Step: 7
Training loss: 0.8298147320747375
Validation loss: 1.9575041699153122

Epoch: 5| Step: 8
Training loss: 0.777405858039856
Validation loss: 1.9509534246178084

Epoch: 5| Step: 9
Training loss: 1.0367263555526733
Validation loss: 1.894629677136739

Epoch: 5| Step: 10
Training loss: 0.9483726620674133
Validation loss: 1.8622706461978216

Epoch: 226| Step: 0
Training loss: 0.5082833766937256
Validation loss: 1.8502155221918577

Epoch: 5| Step: 1
Training loss: 0.7050928473472595
Validation loss: 1.8351235389709473

Epoch: 5| Step: 2
Training loss: 0.7378703951835632
Validation loss: 1.8275412154454056

Epoch: 5| Step: 3
Training loss: 0.8848726153373718
Validation loss: 1.8170423597417853

Epoch: 5| Step: 4
Training loss: 0.8358901739120483
Validation loss: 1.8348109670864639

Epoch: 5| Step: 5
Training loss: 0.6788474917411804
Validation loss: 1.8669107114115069

Epoch: 5| Step: 6
Training loss: 0.5866133570671082
Validation loss: 1.9022036188392228

Epoch: 5| Step: 7
Training loss: 0.8886610865592957
Validation loss: 1.9568554047615296

Epoch: 5| Step: 8
Training loss: 0.8915554285049438
Validation loss: 2.0088009488198066

Epoch: 5| Step: 9
Training loss: 0.8984452486038208
Validation loss: 2.0325280235659693

Epoch: 5| Step: 10
Training loss: 0.5735462307929993
Validation loss: 2.0035796037284275

Epoch: 227| Step: 0
Training loss: 0.8446007966995239
Validation loss: 1.9746287663777669

Epoch: 5| Step: 1
Training loss: 0.6488659977912903
Validation loss: 1.9503598725923927

Epoch: 5| Step: 2
Training loss: 0.4925183355808258
Validation loss: 1.9385953782707133

Epoch: 5| Step: 3
Training loss: 0.6449981927871704
Validation loss: 1.886044071566674

Epoch: 5| Step: 4
Training loss: 0.6922417879104614
Validation loss: 1.8836638350640573

Epoch: 5| Step: 5
Training loss: 0.9156699180603027
Validation loss: 1.8657226408681562

Epoch: 5| Step: 6
Training loss: 0.7609158754348755
Validation loss: 1.839559906272478

Epoch: 5| Step: 7
Training loss: 0.8439583778381348
Validation loss: 1.863628036232405

Epoch: 5| Step: 8
Training loss: 0.6576234698295593
Validation loss: 1.903480891258486

Epoch: 5| Step: 9
Training loss: 0.5953404307365417
Validation loss: 1.9201832625173754

Epoch: 5| Step: 10
Training loss: 0.8965211510658264
Validation loss: 1.9843698637459868

Epoch: 228| Step: 0
Training loss: 0.7554154396057129
Validation loss: 1.9529198651672692

Epoch: 5| Step: 1
Training loss: 0.6428016424179077
Validation loss: 2.0066586463682112

Epoch: 5| Step: 2
Training loss: 0.9022960662841797
Validation loss: 1.9955866183004072

Epoch: 5| Step: 3
Training loss: 0.3977554440498352
Validation loss: 1.9621767177376697

Epoch: 5| Step: 4
Training loss: 0.42910605669021606
Validation loss: 1.91163464771804

Epoch: 5| Step: 5
Training loss: 0.9991652369499207
Validation loss: 1.8751046542198426

Epoch: 5| Step: 6
Training loss: 1.0202990770339966
Validation loss: 1.8414323201743505

Epoch: 5| Step: 7
Training loss: 0.6757456064224243
Validation loss: 1.8336270804046302

Epoch: 5| Step: 8
Training loss: 0.7068424224853516
Validation loss: 1.8099657515043854

Epoch: 5| Step: 9
Training loss: 0.7558315992355347
Validation loss: 1.8330493678328812

Epoch: 5| Step: 10
Training loss: 0.9044010043144226
Validation loss: 1.834072429646728

Epoch: 229| Step: 0
Training loss: 0.638533890247345
Validation loss: 1.8802729229773245

Epoch: 5| Step: 1
Training loss: 0.8464597463607788
Validation loss: 1.9276057879130046

Epoch: 5| Step: 2
Training loss: 0.4631519913673401
Validation loss: 1.9686250404645038

Epoch: 5| Step: 3
Training loss: 1.075727939605713
Validation loss: 2.001338061466012

Epoch: 5| Step: 4
Training loss: 0.9326130747795105
Validation loss: 2.0014252239657986

Epoch: 5| Step: 5
Training loss: 0.5813541412353516
Validation loss: 1.9618652328368156

Epoch: 5| Step: 6
Training loss: 0.7829554677009583
Validation loss: 1.919070150262566

Epoch: 5| Step: 7
Training loss: 0.6713582873344421
Validation loss: 1.8941475934879755

Epoch: 5| Step: 8
Training loss: 0.3767731189727783
Validation loss: 1.894578492769631

Epoch: 5| Step: 9
Training loss: 0.8125817179679871
Validation loss: 1.8670478841309905

Epoch: 5| Step: 10
Training loss: 0.3802812993526459
Validation loss: 1.8551646124932073

Epoch: 230| Step: 0
Training loss: 0.6563857197761536
Validation loss: 1.796476189808179

Epoch: 5| Step: 1
Training loss: 0.674251139163971
Validation loss: 1.8166241145903064

Epoch: 5| Step: 2
Training loss: 0.7780014276504517
Validation loss: 1.8518401371535433

Epoch: 5| Step: 3
Training loss: 0.9239923357963562
Validation loss: 1.8817672614128358

Epoch: 5| Step: 4
Training loss: 0.31883031129837036
Validation loss: 1.866525468005929

Epoch: 5| Step: 5
Training loss: 0.9614142179489136
Validation loss: 1.8550796790789532

Epoch: 5| Step: 6
Training loss: 0.40630245208740234
Validation loss: 1.8491160151779011

Epoch: 5| Step: 7
Training loss: 0.5855184197425842
Validation loss: 1.8356208057813748

Epoch: 5| Step: 8
Training loss: 0.6631602644920349
Validation loss: 1.8087492078863165

Epoch: 5| Step: 9
Training loss: 0.5309476852416992
Validation loss: 1.832017239703927

Epoch: 5| Step: 10
Training loss: 1.1322720050811768
Validation loss: 1.8519075993568666

Epoch: 231| Step: 0
Training loss: 0.7625985145568848
Validation loss: 1.9033778329049387

Epoch: 5| Step: 1
Training loss: 0.816386342048645
Validation loss: 1.8950501077918596

Epoch: 5| Step: 2
Training loss: 0.6385678648948669
Validation loss: 1.9237251948284846

Epoch: 5| Step: 3
Training loss: 0.6841424107551575
Validation loss: 1.900407898810602

Epoch: 5| Step: 4
Training loss: 0.4036884307861328
Validation loss: 1.906435420436244

Epoch: 5| Step: 5
Training loss: 0.43990764021873474
Validation loss: 1.8560298360804075

Epoch: 5| Step: 6
Training loss: 0.5782997012138367
Validation loss: 1.8413698314338602

Epoch: 5| Step: 7
Training loss: 1.0142704248428345
Validation loss: 1.8451392048148698

Epoch: 5| Step: 8
Training loss: 0.6154657602310181
Validation loss: 1.8134823576096566

Epoch: 5| Step: 9
Training loss: 0.9286127090454102
Validation loss: 1.8621381841680056

Epoch: 5| Step: 10
Training loss: 0.6748738884925842
Validation loss: 1.8486292567304385

Epoch: 232| Step: 0
Training loss: 0.8996505737304688
Validation loss: 1.8993151508351809

Epoch: 5| Step: 1
Training loss: 0.5120733976364136
Validation loss: 1.9117732829945062

Epoch: 5| Step: 2
Training loss: 0.790678858757019
Validation loss: 1.9117177481292396

Epoch: 5| Step: 3
Training loss: 0.6281355023384094
Validation loss: 1.9207036636208976

Epoch: 5| Step: 4
Training loss: 0.7605653405189514
Validation loss: 1.9245583985441475

Epoch: 5| Step: 5
Training loss: 0.8699464797973633
Validation loss: 1.8987595855548818

Epoch: 5| Step: 6
Training loss: 0.8616145849227905
Validation loss: 1.8907585656771095

Epoch: 5| Step: 7
Training loss: 0.5204907655715942
Validation loss: 1.8560853350547053

Epoch: 5| Step: 8
Training loss: 0.6068124175071716
Validation loss: 1.8380729126673874

Epoch: 5| Step: 9
Training loss: 0.7128170728683472
Validation loss: 1.8444665452485443

Epoch: 5| Step: 10
Training loss: 0.46732401847839355
Validation loss: 1.8495149407335507

Epoch: 233| Step: 0
Training loss: 0.9071527719497681
Validation loss: 1.8585128091996717

Epoch: 5| Step: 1
Training loss: 0.7608218789100647
Validation loss: 1.8854976290015764

Epoch: 5| Step: 2
Training loss: 0.7794592976570129
Validation loss: 1.913270974671969

Epoch: 5| Step: 3
Training loss: 0.61961829662323
Validation loss: 1.8791506662163684

Epoch: 5| Step: 4
Training loss: 0.3715366721153259
Validation loss: 1.8436184519080705

Epoch: 5| Step: 5
Training loss: 0.8917838335037231
Validation loss: 1.8027426747865574

Epoch: 5| Step: 6
Training loss: 0.428290992975235
Validation loss: 1.7931695189527286

Epoch: 5| Step: 7
Training loss: 0.6154415011405945
Validation loss: 1.7901296500236756

Epoch: 5| Step: 8
Training loss: 0.6567996740341187
Validation loss: 1.7778132423277824

Epoch: 5| Step: 9
Training loss: 0.6690356135368347
Validation loss: 1.8031655998640164

Epoch: 5| Step: 10
Training loss: 0.9532117247581482
Validation loss: 1.837679034920149

Epoch: 234| Step: 0
Training loss: 0.5499064922332764
Validation loss: 1.8558016733456684

Epoch: 5| Step: 1
Training loss: 0.6343698501586914
Validation loss: 1.9121078650156658

Epoch: 5| Step: 2
Training loss: 0.8567164540290833
Validation loss: 1.9097796947725358

Epoch: 5| Step: 3
Training loss: 1.127941370010376
Validation loss: 1.9189743559847596

Epoch: 5| Step: 4
Training loss: 0.48178744316101074
Validation loss: 1.929690872469256

Epoch: 5| Step: 5
Training loss: 0.6345227360725403
Validation loss: 1.9587141634315572

Epoch: 5| Step: 6
Training loss: 0.7923520803451538
Validation loss: 1.9592855540654992

Epoch: 5| Step: 7
Training loss: 0.760651707649231
Validation loss: 1.9528892578617219

Epoch: 5| Step: 8
Training loss: 0.3230302929878235
Validation loss: 1.9398643611579813

Epoch: 5| Step: 9
Training loss: 0.48750776052474976
Validation loss: 1.9511299581937893

Epoch: 5| Step: 10
Training loss: 0.7461308836936951
Validation loss: 1.9271523990938741

Epoch: 235| Step: 0
Training loss: 0.5970569849014282
Validation loss: 1.911940340072878

Epoch: 5| Step: 1
Training loss: 0.7288520336151123
Validation loss: 1.913753265975624

Epoch: 5| Step: 2
Training loss: 0.5112634897232056
Validation loss: 1.8947310383601854

Epoch: 5| Step: 3
Training loss: 0.5955910682678223
Validation loss: 1.9067752104933544

Epoch: 5| Step: 4
Training loss: 0.5631535053253174
Validation loss: 1.8768984681816512

Epoch: 5| Step: 5
Training loss: 0.6270524263381958
Validation loss: 1.8968965366322508

Epoch: 5| Step: 6
Training loss: 0.4831903576850891
Validation loss: 1.8635776747939408

Epoch: 5| Step: 7
Training loss: 0.6403111219406128
Validation loss: 1.8600251123469362

Epoch: 5| Step: 8
Training loss: 0.5237014293670654
Validation loss: 1.853249426810972

Epoch: 5| Step: 9
Training loss: 0.9376238584518433
Validation loss: 1.842936518371746

Epoch: 5| Step: 10
Training loss: 1.0791280269622803
Validation loss: 1.8385111875431512

Epoch: 236| Step: 0
Training loss: 0.5387124419212341
Validation loss: 1.816194644538305

Epoch: 5| Step: 1
Training loss: 0.7044456601142883
Validation loss: 1.8285592461145053

Epoch: 5| Step: 2
Training loss: 0.5425547361373901
Validation loss: 1.82645236292193

Epoch: 5| Step: 3
Training loss: 0.7257832884788513
Validation loss: 1.8460643573473858

Epoch: 5| Step: 4
Training loss: 0.7399052977561951
Validation loss: 1.8597279774245394

Epoch: 5| Step: 5
Training loss: 0.6174789667129517
Validation loss: 1.882687258464034

Epoch: 5| Step: 6
Training loss: 0.91863614320755
Validation loss: 1.9347779033004597

Epoch: 5| Step: 7
Training loss: 0.5756931304931641
Validation loss: 1.94901595833481

Epoch: 5| Step: 8
Training loss: 0.5842450857162476
Validation loss: 1.980337458272134

Epoch: 5| Step: 9
Training loss: 0.7491236329078674
Validation loss: 1.9453135895472702

Epoch: 5| Step: 10
Training loss: 0.47702014446258545
Validation loss: 1.8847601157362743

Epoch: 237| Step: 0
Training loss: 0.4298606812953949
Validation loss: 1.8483121395111084

Epoch: 5| Step: 1
Training loss: 0.5740883946418762
Validation loss: 1.8559501273657686

Epoch: 5| Step: 2
Training loss: 0.5991367101669312
Validation loss: 1.844884833981914

Epoch: 5| Step: 3
Training loss: 0.40948277711868286
Validation loss: 1.889108706546086

Epoch: 5| Step: 4
Training loss: 0.6545320749282837
Validation loss: 1.8992165211708314

Epoch: 5| Step: 5
Training loss: 0.8341080546379089
Validation loss: 1.9124726403144099

Epoch: 5| Step: 6
Training loss: 1.1784001588821411
Validation loss: 1.9444049507059076

Epoch: 5| Step: 7
Training loss: 0.6027141809463501
Validation loss: 1.937085118345035

Epoch: 5| Step: 8
Training loss: 0.3856666684150696
Validation loss: 1.9358099929748043

Epoch: 5| Step: 9
Training loss: 0.5863145589828491
Validation loss: 1.9204349569095078

Epoch: 5| Step: 10
Training loss: 0.7298250794410706
Validation loss: 1.8934004563157276

Epoch: 238| Step: 0
Training loss: 0.46623021364212036
Validation loss: 1.8625937828453638

Epoch: 5| Step: 1
Training loss: 0.7268732786178589
Validation loss: 1.8458327836887811

Epoch: 5| Step: 2
Training loss: 0.5653029680252075
Validation loss: 1.8218815531781924

Epoch: 5| Step: 3
Training loss: 0.5838473439216614
Validation loss: 1.8722860108139694

Epoch: 5| Step: 4
Training loss: 0.5813981294631958
Validation loss: 1.9075799642070648

Epoch: 5| Step: 5
Training loss: 0.6880785226821899
Validation loss: 1.8851731131153722

Epoch: 5| Step: 6
Training loss: 0.5219821333885193
Validation loss: 1.8970473415108138

Epoch: 5| Step: 7
Training loss: 0.520908772945404
Validation loss: 1.87695723964322

Epoch: 5| Step: 8
Training loss: 0.7162911891937256
Validation loss: 1.8315338934621503

Epoch: 5| Step: 9
Training loss: 0.7946480512619019
Validation loss: 1.8232409954071045

Epoch: 5| Step: 10
Training loss: 0.7114940881729126
Validation loss: 1.8212676548188733

Epoch: 239| Step: 0
Training loss: 0.8690059781074524
Validation loss: 1.8351274651865805

Epoch: 5| Step: 1
Training loss: 0.6411895155906677
Validation loss: 1.8399160882478118

Epoch: 5| Step: 2
Training loss: 0.5728601217269897
Validation loss: 1.8534006457174979

Epoch: 5| Step: 3
Training loss: 0.601657509803772
Validation loss: 1.8916828247808641

Epoch: 5| Step: 4
Training loss: 0.6466751098632812
Validation loss: 1.8933483951835222

Epoch: 5| Step: 5
Training loss: 0.5640155076980591
Validation loss: 1.9279618801609162

Epoch: 5| Step: 6
Training loss: 0.3903035521507263
Validation loss: 1.9230848063704788

Epoch: 5| Step: 7
Training loss: 0.504211962223053
Validation loss: 1.906543077961091

Epoch: 5| Step: 8
Training loss: 0.6656737327575684
Validation loss: 1.9015761677936842

Epoch: 5| Step: 9
Training loss: 0.5893764495849609
Validation loss: 1.8847034003144951

Epoch: 5| Step: 10
Training loss: 0.8663892149925232
Validation loss: 1.8658033570935648

Epoch: 240| Step: 0
Training loss: 0.5050939321517944
Validation loss: 1.854654408270313

Epoch: 5| Step: 1
Training loss: 0.6942790746688843
Validation loss: 1.858652586578041

Epoch: 5| Step: 2
Training loss: 0.45114248991012573
Validation loss: 1.8333798749472505

Epoch: 5| Step: 3
Training loss: 0.6402032971382141
Validation loss: 1.881609824395949

Epoch: 5| Step: 4
Training loss: 0.6550348401069641
Validation loss: 1.8981603781382244

Epoch: 5| Step: 5
Training loss: 0.7176696062088013
Validation loss: 1.9104312055854387

Epoch: 5| Step: 6
Training loss: 0.6158701777458191
Validation loss: 1.9362194127933954

Epoch: 5| Step: 7
Training loss: 0.6053417921066284
Validation loss: 1.9404433542682278

Epoch: 5| Step: 8
Training loss: 0.5198792219161987
Validation loss: 1.9435984498711043

Epoch: 5| Step: 9
Training loss: 0.8563327789306641
Validation loss: 1.8767671072354881

Epoch: 5| Step: 10
Training loss: 0.40752190351486206
Validation loss: 1.8591425572672198

Epoch: 241| Step: 0
Training loss: 0.8039752840995789
Validation loss: 1.8474684338415823

Epoch: 5| Step: 1
Training loss: 0.6655862927436829
Validation loss: 1.8345624387905162

Epoch: 5| Step: 2
Training loss: 0.40581732988357544
Validation loss: 1.841649333635966

Epoch: 5| Step: 3
Training loss: 0.7102254629135132
Validation loss: 1.8579801103120208

Epoch: 5| Step: 4
Training loss: 0.6327223777770996
Validation loss: 1.8634949627742972

Epoch: 5| Step: 5
Training loss: 0.3714234232902527
Validation loss: 1.9184063737110426

Epoch: 5| Step: 6
Training loss: 0.6745103597640991
Validation loss: 1.9456463167744298

Epoch: 5| Step: 7
Training loss: 0.5189050436019897
Validation loss: 1.9088255846372215

Epoch: 5| Step: 8
Training loss: 0.7624870538711548
Validation loss: 1.9263958418241112

Epoch: 5| Step: 9
Training loss: 0.4938797950744629
Validation loss: 1.894892813057028

Epoch: 5| Step: 10
Training loss: 0.7696011662483215
Validation loss: 1.8377186649589128

Epoch: 242| Step: 0
Training loss: 0.27753859758377075
Validation loss: 1.8104863615446194

Epoch: 5| Step: 1
Training loss: 0.43706196546554565
Validation loss: 1.8082658654900008

Epoch: 5| Step: 2
Training loss: 0.900112509727478
Validation loss: 1.7851061564619823

Epoch: 5| Step: 3
Training loss: 0.5314112901687622
Validation loss: 1.7846864948990524

Epoch: 5| Step: 4
Training loss: 0.4965832829475403
Validation loss: 1.7954310627393826

Epoch: 5| Step: 5
Training loss: 0.41775378584861755
Validation loss: 1.8210993069474415

Epoch: 5| Step: 6
Training loss: 0.799620509147644
Validation loss: 1.8630620253983365

Epoch: 5| Step: 7
Training loss: 0.63444983959198
Validation loss: 1.9058602010050127

Epoch: 5| Step: 8
Training loss: 0.7839396595954895
Validation loss: 1.899622122446696

Epoch: 5| Step: 9
Training loss: 0.691034197807312
Validation loss: 1.9299381753449798

Epoch: 5| Step: 10
Training loss: 0.45404505729675293
Validation loss: 1.9208012024561565

Epoch: 243| Step: 0
Training loss: 0.48742786049842834
Validation loss: 1.933623412603973

Epoch: 5| Step: 1
Training loss: 0.6186711192131042
Validation loss: 1.8875354771972985

Epoch: 5| Step: 2
Training loss: 0.5948116779327393
Validation loss: 1.8436351514631701

Epoch: 5| Step: 3
Training loss: 0.5783379673957825
Validation loss: 1.837625511230961

Epoch: 5| Step: 4
Training loss: 0.609846830368042
Validation loss: 1.8469800500459568

Epoch: 5| Step: 5
Training loss: 0.671698808670044
Validation loss: 1.8294383043883948

Epoch: 5| Step: 6
Training loss: 0.656266987323761
Validation loss: 1.8499183372784687

Epoch: 5| Step: 7
Training loss: 0.6699565649032593
Validation loss: 1.8711840491141043

Epoch: 5| Step: 8
Training loss: 0.38698631525039673
Validation loss: 1.8794927430409256

Epoch: 5| Step: 9
Training loss: 0.6435651183128357
Validation loss: 1.8661104325325257

Epoch: 5| Step: 10
Training loss: 0.6139044761657715
Validation loss: 1.8403557526168002

Epoch: 244| Step: 0
Training loss: 0.692005455493927
Validation loss: 1.8290194990814372

Epoch: 5| Step: 1
Training loss: 0.4409792423248291
Validation loss: 1.8381249161176785

Epoch: 5| Step: 2
Training loss: 0.5786505341529846
Validation loss: 1.8531241301567323

Epoch: 5| Step: 3
Training loss: 0.48921436071395874
Validation loss: 1.8576075261639011

Epoch: 5| Step: 4
Training loss: 0.46951690316200256
Validation loss: 1.857890454671716

Epoch: 5| Step: 5
Training loss: 0.45488062500953674
Validation loss: 1.8587314377548874

Epoch: 5| Step: 6
Training loss: 0.726699948310852
Validation loss: 1.883139282144526

Epoch: 5| Step: 7
Training loss: 0.9007588624954224
Validation loss: 1.9064523712281258

Epoch: 5| Step: 8
Training loss: 0.6864555478096008
Validation loss: 1.8657857346278366

Epoch: 5| Step: 9
Training loss: 0.4626224637031555
Validation loss: 1.905842302947916

Epoch: 5| Step: 10
Training loss: 0.43912631273269653
Validation loss: 1.8763215439293974

Epoch: 245| Step: 0
Training loss: 0.5057827234268188
Validation loss: 1.87011424315873

Epoch: 5| Step: 1
Training loss: 0.5607739686965942
Validation loss: 1.8682818464053574

Epoch: 5| Step: 2
Training loss: 0.40439891815185547
Validation loss: 1.8580258789882864

Epoch: 5| Step: 3
Training loss: 0.6270274519920349
Validation loss: 1.8470223424255208

Epoch: 5| Step: 4
Training loss: 0.5487555265426636
Validation loss: 1.8474790050137428

Epoch: 5| Step: 5
Training loss: 0.7071245908737183
Validation loss: 1.8333297878183343

Epoch: 5| Step: 6
Training loss: 0.7146326303482056
Validation loss: 1.8010173459206857

Epoch: 5| Step: 7
Training loss: 0.5236529111862183
Validation loss: 1.8078025233361028

Epoch: 5| Step: 8
Training loss: 0.7197328805923462
Validation loss: 1.8003076302107943

Epoch: 5| Step: 9
Training loss: 0.6703709363937378
Validation loss: 1.8229717721221268

Epoch: 5| Step: 10
Training loss: 0.46926894783973694
Validation loss: 1.8414618610053934

Epoch: 246| Step: 0
Training loss: 0.6617771983146667
Validation loss: 1.83445345458164

Epoch: 5| Step: 1
Training loss: 0.5090540647506714
Validation loss: 1.8188274265617452

Epoch: 5| Step: 2
Training loss: 0.7605994939804077
Validation loss: 1.8517562586774108

Epoch: 5| Step: 3
Training loss: 0.7889145612716675
Validation loss: 1.870327784810015

Epoch: 5| Step: 4
Training loss: 0.5696691274642944
Validation loss: 1.8831021760099678

Epoch: 5| Step: 5
Training loss: 0.4132256507873535
Validation loss: 1.9093282402202647

Epoch: 5| Step: 6
Training loss: 0.6866174936294556
Validation loss: 1.8969776553492392

Epoch: 5| Step: 7
Training loss: 0.6218103766441345
Validation loss: 1.9003213400481849

Epoch: 5| Step: 8
Training loss: 0.3562425673007965
Validation loss: 1.8750055733547415

Epoch: 5| Step: 9
Training loss: 0.6929575204849243
Validation loss: 1.868397219206697

Epoch: 5| Step: 10
Training loss: 0.34564435482025146
Validation loss: 1.818521548342961

Epoch: 247| Step: 0
Training loss: 0.4933597445487976
Validation loss: 1.8236302816739647

Epoch: 5| Step: 1
Training loss: 0.6022174954414368
Validation loss: 1.8231574758406608

Epoch: 5| Step: 2
Training loss: 0.528599739074707
Validation loss: 1.8430337008609567

Epoch: 5| Step: 3
Training loss: 0.3938978314399719
Validation loss: 1.8371560727396319

Epoch: 5| Step: 4
Training loss: 0.6039665937423706
Validation loss: 1.8647144686791204

Epoch: 5| Step: 5
Training loss: 0.5120834112167358
Validation loss: 1.8909089924186788

Epoch: 5| Step: 6
Training loss: 0.6374591588973999
Validation loss: 1.8791567458901355

Epoch: 5| Step: 7
Training loss: 0.7364981770515442
Validation loss: 1.8648661080227102

Epoch: 5| Step: 8
Training loss: 0.4585924744606018
Validation loss: 1.875971774901113

Epoch: 5| Step: 9
Training loss: 0.6861897706985474
Validation loss: 1.87076985707847

Epoch: 5| Step: 10
Training loss: 0.5915485620498657
Validation loss: 1.881056321564541

Epoch: 248| Step: 0
Training loss: 0.43278980255126953
Validation loss: 1.8706675396170667

Epoch: 5| Step: 1
Training loss: 0.41617685556411743
Validation loss: 1.8712732920082666

Epoch: 5| Step: 2
Training loss: 0.654563844203949
Validation loss: 1.8520526001530309

Epoch: 5| Step: 3
Training loss: 0.6037237048149109
Validation loss: 1.8744708889274186

Epoch: 5| Step: 4
Training loss: 0.7483844757080078
Validation loss: 1.878531922576248

Epoch: 5| Step: 5
Training loss: 0.5459080934524536
Validation loss: 1.9069864890908683

Epoch: 5| Step: 6
Training loss: 0.49485141038894653
Validation loss: 1.897681087575933

Epoch: 5| Step: 7
Training loss: 0.6284334063529968
Validation loss: 1.9137967812117709

Epoch: 5| Step: 8
Training loss: 0.6382278800010681
Validation loss: 1.8957819169567478

Epoch: 5| Step: 9
Training loss: 0.6723100543022156
Validation loss: 1.8919630717205744

Epoch: 5| Step: 10
Training loss: 0.600769579410553
Validation loss: 1.8554898051805393

Epoch: 249| Step: 0
Training loss: 0.663986086845398
Validation loss: 1.840905071586691

Epoch: 5| Step: 1
Training loss: 0.3843441605567932
Validation loss: 1.7810011909854027

Epoch: 5| Step: 2
Training loss: 0.5639328360557556
Validation loss: 1.764100428550474

Epoch: 5| Step: 3
Training loss: 0.696153461933136
Validation loss: 1.7365461677633307

Epoch: 5| Step: 4
Training loss: 0.7599011659622192
Validation loss: 1.7417246680105887

Epoch: 5| Step: 5
Training loss: 0.6856158971786499
Validation loss: 1.7651462465204217

Epoch: 5| Step: 6
Training loss: 0.5097824931144714
Validation loss: 1.8014913964015182

Epoch: 5| Step: 7
Training loss: 0.4544094204902649
Validation loss: 1.8629941414761286

Epoch: 5| Step: 8
Training loss: 0.5712705254554749
Validation loss: 1.865124265352885

Epoch: 5| Step: 9
Training loss: 0.6307843327522278
Validation loss: 1.9155295061808761

Epoch: 5| Step: 10
Training loss: 0.688533365726471
Validation loss: 1.9054263355911418

Epoch: 250| Step: 0
Training loss: 0.34625720977783203
Validation loss: 1.8414854490628807

Epoch: 5| Step: 1
Training loss: 0.492145299911499
Validation loss: 1.850528077412677

Epoch: 5| Step: 2
Training loss: 0.5783538818359375
Validation loss: 1.841602874058549

Epoch: 5| Step: 3
Training loss: 0.7804919481277466
Validation loss: 1.8771759156257875

Epoch: 5| Step: 4
Training loss: 0.4906110167503357
Validation loss: 1.8569828130865609

Epoch: 5| Step: 5
Training loss: 0.5683154463768005
Validation loss: 1.8756574430773336

Epoch: 5| Step: 6
Training loss: 0.6876291036605835
Validation loss: 1.8583478235429334

Epoch: 5| Step: 7
Training loss: 0.7350009679794312
Validation loss: 1.8581421913639191

Epoch: 5| Step: 8
Training loss: 0.5853093266487122
Validation loss: 1.8829041655345629

Epoch: 5| Step: 9
Training loss: 0.5169972777366638
Validation loss: 1.8677079908309444

Epoch: 5| Step: 10
Training loss: 0.3915077745914459
Validation loss: 1.8788675338991228

Epoch: 251| Step: 0
Training loss: 0.31316250562667847
Validation loss: 1.8506750977167519

Epoch: 5| Step: 1
Training loss: 0.6390045285224915
Validation loss: 1.838055121001377

Epoch: 5| Step: 2
Training loss: 0.6249147057533264
Validation loss: 1.8219444726103096

Epoch: 5| Step: 3
Training loss: 0.5339753031730652
Validation loss: 1.8278075571983092

Epoch: 5| Step: 4
Training loss: 0.33708101511001587
Validation loss: 1.820504826884116

Epoch: 5| Step: 5
Training loss: 0.5190850496292114
Validation loss: 1.802251080031036

Epoch: 5| Step: 6
Training loss: 0.43546825647354126
Validation loss: 1.7773616301116122

Epoch: 5| Step: 7
Training loss: 0.7875005602836609
Validation loss: 1.7743520070147771

Epoch: 5| Step: 8
Training loss: 0.648445725440979
Validation loss: 1.7527801118871218

Epoch: 5| Step: 9
Training loss: 0.5989904403686523
Validation loss: 1.7682410632410357

Epoch: 5| Step: 10
Training loss: 0.7800820469856262
Validation loss: 1.7733211709607033

Epoch: 252| Step: 0
Training loss: 0.5209435224533081
Validation loss: 1.7951198790663032

Epoch: 5| Step: 1
Training loss: 0.7241430282592773
Validation loss: 1.7959356692529493

Epoch: 5| Step: 2
Training loss: 0.4615857005119324
Validation loss: 1.8174509220225836

Epoch: 5| Step: 3
Training loss: 0.49828529357910156
Validation loss: 1.8132519850166895

Epoch: 5| Step: 4
Training loss: 0.5517514944076538
Validation loss: 1.8561200890489804

Epoch: 5| Step: 5
Training loss: 0.33610647916793823
Validation loss: 1.8904916189050163

Epoch: 5| Step: 6
Training loss: 0.5634294152259827
Validation loss: 1.9220783864298174

Epoch: 5| Step: 7
Training loss: 0.4041471481323242
Validation loss: 1.9146162156135804

Epoch: 5| Step: 8
Training loss: 0.6499233245849609
Validation loss: 1.8991348653711297

Epoch: 5| Step: 9
Training loss: 0.590480625629425
Validation loss: 1.849235314194874

Epoch: 5| Step: 10
Training loss: 0.5864409804344177
Validation loss: 1.83741884334113

Epoch: 253| Step: 0
Training loss: 0.7429490089416504
Validation loss: 1.8305799832908056

Epoch: 5| Step: 1
Training loss: 0.5594446063041687
Validation loss: 1.8201386826012724

Epoch: 5| Step: 2
Training loss: 0.476832777261734
Validation loss: 1.8312275601971535

Epoch: 5| Step: 3
Training loss: 0.7039374709129333
Validation loss: 1.8540152683052966

Epoch: 5| Step: 4
Training loss: 0.479747474193573
Validation loss: 1.833607888990833

Epoch: 5| Step: 5
Training loss: 0.5325857400894165
Validation loss: 1.8108147293008783

Epoch: 5| Step: 6
Training loss: 0.5477930903434753
Validation loss: 1.8383938663749284

Epoch: 5| Step: 7
Training loss: 0.42590466141700745
Validation loss: 1.8522967548780545

Epoch: 5| Step: 8
Training loss: 0.63727867603302
Validation loss: 1.8806887544611448

Epoch: 5| Step: 9
Training loss: 0.36408495903015137
Validation loss: 1.8810315350050568

Epoch: 5| Step: 10
Training loss: 0.4294821619987488
Validation loss: 1.8748318546561784

Epoch: 254| Step: 0
Training loss: 0.40629929304122925
Validation loss: 1.857489461539894

Epoch: 5| Step: 1
Training loss: 0.18552729487419128
Validation loss: 1.8453899891145769

Epoch: 5| Step: 2
Training loss: 0.5480901002883911
Validation loss: 1.8185219969800723

Epoch: 5| Step: 3
Training loss: 0.5333347916603088
Validation loss: 1.8076965911414034

Epoch: 5| Step: 4
Training loss: 0.544660747051239
Validation loss: 1.7911308401374406

Epoch: 5| Step: 5
Training loss: 0.45344409346580505
Validation loss: 1.7951541459688576

Epoch: 5| Step: 6
Training loss: 0.9276958703994751
Validation loss: 1.8393128789881223

Epoch: 5| Step: 7
Training loss: 0.37027692794799805
Validation loss: 1.799232530337508

Epoch: 5| Step: 8
Training loss: 0.6464014649391174
Validation loss: 1.812489756973841

Epoch: 5| Step: 9
Training loss: 0.7309057116508484
Validation loss: 1.8005664258874872

Epoch: 5| Step: 10
Training loss: 0.3444240391254425
Validation loss: 1.801049691374584

Epoch: 255| Step: 0
Training loss: 0.6093167066574097
Validation loss: 1.7762092762095953

Epoch: 5| Step: 1
Training loss: 0.4798698425292969
Validation loss: 1.7952373425165813

Epoch: 5| Step: 2
Training loss: 0.6005483865737915
Validation loss: 1.808312149458034

Epoch: 5| Step: 3
Training loss: 0.5203677415847778
Validation loss: 1.7934358555783507

Epoch: 5| Step: 4
Training loss: 0.5745959877967834
Validation loss: 1.824837984577302

Epoch: 5| Step: 5
Training loss: 0.7851711511611938
Validation loss: 1.8698951467390983

Epoch: 5| Step: 6
Training loss: 0.7070532441139221
Validation loss: 1.8750881994924238

Epoch: 5| Step: 7
Training loss: 0.28372105956077576
Validation loss: 1.8366356665088284

Epoch: 5| Step: 8
Training loss: 0.2809616029262543
Validation loss: 1.8597900534188876

Epoch: 5| Step: 9
Training loss: 0.35902026295661926
Validation loss: 1.8833640980464157

Epoch: 5| Step: 10
Training loss: 0.3735956847667694
Validation loss: 1.8779450578074302

Epoch: 256| Step: 0
Training loss: 0.4250759184360504
Validation loss: 1.866129344509494

Epoch: 5| Step: 1
Training loss: 0.5299839973449707
Validation loss: 1.8444614910310315

Epoch: 5| Step: 2
Training loss: 0.29258614778518677
Validation loss: 1.8469165807129235

Epoch: 5| Step: 3
Training loss: 0.6628232002258301
Validation loss: 1.806643586004934

Epoch: 5| Step: 4
Training loss: 0.6957471966743469
Validation loss: 1.7870334566280406

Epoch: 5| Step: 5
Training loss: 0.505437970161438
Validation loss: 1.7901962367437219

Epoch: 5| Step: 6
Training loss: 0.5560464859008789
Validation loss: 1.8029840941070228

Epoch: 5| Step: 7
Training loss: 0.3509015738964081
Validation loss: 1.785780656722284

Epoch: 5| Step: 8
Training loss: 0.5616896152496338
Validation loss: 1.8005543319127892

Epoch: 5| Step: 9
Training loss: 0.4315565228462219
Validation loss: 1.8326205335637575

Epoch: 5| Step: 10
Training loss: 0.5760941505432129
Validation loss: 1.8289257108524282

Epoch: 257| Step: 0
Training loss: 0.5065901279449463
Validation loss: 1.8501077980123541

Epoch: 5| Step: 1
Training loss: 0.6394389867782593
Validation loss: 1.8854410789346183

Epoch: 5| Step: 2
Training loss: 0.40545958280563354
Validation loss: 1.8859298383035967

Epoch: 5| Step: 3
Training loss: 0.5363690853118896
Validation loss: 1.8336600026776713

Epoch: 5| Step: 4
Training loss: 0.452275812625885
Validation loss: 1.8044208685557048

Epoch: 5| Step: 5
Training loss: 0.25017476081848145
Validation loss: 1.7416466179714407

Epoch: 5| Step: 6
Training loss: 0.5765419006347656
Validation loss: 1.7369666253366778

Epoch: 5| Step: 7
Training loss: 0.6904438138008118
Validation loss: 1.7482248993330105

Epoch: 5| Step: 8
Training loss: 0.7086328268051147
Validation loss: 1.7267006930484567

Epoch: 5| Step: 9
Training loss: 0.2520348131656647
Validation loss: 1.7621713325541506

Epoch: 5| Step: 10
Training loss: 0.49862074851989746
Validation loss: 1.7634039207171368

Epoch: 258| Step: 0
Training loss: 0.36302709579467773
Validation loss: 1.8065799590080016

Epoch: 5| Step: 1
Training loss: 0.5363404154777527
Validation loss: 1.8375078760167605

Epoch: 5| Step: 2
Training loss: 0.563453733921051
Validation loss: 1.87561019005314

Epoch: 5| Step: 3
Training loss: 0.5178535580635071
Validation loss: 1.866219566714379

Epoch: 5| Step: 4
Training loss: 0.7992631196975708
Validation loss: 1.8514755387460031

Epoch: 5| Step: 5
Training loss: 0.4155398905277252
Validation loss: 1.7690735222190939

Epoch: 5| Step: 6
Training loss: 0.39732909202575684
Validation loss: 1.7241026355374245

Epoch: 5| Step: 7
Training loss: 0.583133339881897
Validation loss: 1.730833730389995

Epoch: 5| Step: 8
Training loss: 0.3831537365913391
Validation loss: 1.7214863325959893

Epoch: 5| Step: 9
Training loss: 0.6902285814285278
Validation loss: 1.7190738108850294

Epoch: 5| Step: 10
Training loss: 0.44368526339530945
Validation loss: 1.7438017860535653

Epoch: 259| Step: 0
Training loss: 0.4892806112766266
Validation loss: 1.7939747110489876

Epoch: 5| Step: 1
Training loss: 0.668133556842804
Validation loss: 1.8034033724056777

Epoch: 5| Step: 2
Training loss: 0.5021350979804993
Validation loss: 1.8257147624928465

Epoch: 5| Step: 3
Training loss: 0.4185146391391754
Validation loss: 1.8113472487336846

Epoch: 5| Step: 4
Training loss: 0.5038678646087646
Validation loss: 1.8181753504660823

Epoch: 5| Step: 5
Training loss: 0.4124276041984558
Validation loss: 1.7982259476056663

Epoch: 5| Step: 6
Training loss: 0.5401862263679504
Validation loss: 1.8469555865051925

Epoch: 5| Step: 7
Training loss: 0.361000120639801
Validation loss: 1.8049848720591555

Epoch: 5| Step: 8
Training loss: 0.5985248684883118
Validation loss: 1.7871420152725712

Epoch: 5| Step: 9
Training loss: 0.4792073667049408
Validation loss: 1.7748788659290602

Epoch: 5| Step: 10
Training loss: 0.7441035509109497
Validation loss: 1.7442212104797363

Epoch: 260| Step: 0
Training loss: 0.5736368894577026
Validation loss: 1.762834995023666

Epoch: 5| Step: 1
Training loss: 0.23746779561042786
Validation loss: 1.7390952597382248

Epoch: 5| Step: 2
Training loss: 0.7837530970573425
Validation loss: 1.773424162659594

Epoch: 5| Step: 3
Training loss: 0.3133257031440735
Validation loss: 1.8287560632151942

Epoch: 5| Step: 4
Training loss: 0.6236903667449951
Validation loss: 1.7985660132541452

Epoch: 5| Step: 5
Training loss: 0.6174367666244507
Validation loss: 1.8311362830541467

Epoch: 5| Step: 6
Training loss: 0.6396462321281433
Validation loss: 1.8537075263197704

Epoch: 5| Step: 7
Training loss: 0.48297953605651855
Validation loss: 1.83404706370446

Epoch: 5| Step: 8
Training loss: 0.5937622785568237
Validation loss: 1.8467851454211819

Epoch: 5| Step: 9
Training loss: 0.24574975669384003
Validation loss: 1.851822785151902

Epoch: 5| Step: 10
Training loss: 0.6530003547668457
Validation loss: 1.826972790943679

Epoch: 261| Step: 0
Training loss: 0.5417405962944031
Validation loss: 1.808117397369877

Epoch: 5| Step: 1
Training loss: 0.35147127509117126
Validation loss: 1.8152639378783524

Epoch: 5| Step: 2
Training loss: 0.39126724004745483
Validation loss: 1.7825432490277033

Epoch: 5| Step: 3
Training loss: 0.4920404553413391
Validation loss: 1.7980908911715272

Epoch: 5| Step: 4
Training loss: 0.37043511867523193
Validation loss: 1.7931949771860594

Epoch: 5| Step: 5
Training loss: 0.38027483224868774
Validation loss: 1.8026685791630899

Epoch: 5| Step: 6
Training loss: 0.28182482719421387
Validation loss: 1.808746446845352

Epoch: 5| Step: 7
Training loss: 0.6533163785934448
Validation loss: 1.8317418867541897

Epoch: 5| Step: 8
Training loss: 0.7112129330635071
Validation loss: 1.8194650373151224

Epoch: 5| Step: 9
Training loss: 0.732755720615387
Validation loss: 1.7854106580057452

Epoch: 5| Step: 10
Training loss: 0.5357782244682312
Validation loss: 1.779756244792733

Epoch: 262| Step: 0
Training loss: 0.4244874119758606
Validation loss: 1.7542393720278175

Epoch: 5| Step: 1
Training loss: 0.5691213607788086
Validation loss: 1.754891534005442

Epoch: 5| Step: 2
Training loss: 0.5908864140510559
Validation loss: 1.7685205449340164

Epoch: 5| Step: 3
Training loss: 0.48662739992141724
Validation loss: 1.7723121950703282

Epoch: 5| Step: 4
Training loss: 0.6065752506256104
Validation loss: 1.7994022113020702

Epoch: 5| Step: 5
Training loss: 0.6474621891975403
Validation loss: 1.7557421794501684

Epoch: 5| Step: 6
Training loss: 0.379610151052475
Validation loss: 1.7505863943407614

Epoch: 5| Step: 7
Training loss: 0.3703233599662781
Validation loss: 1.7407729907702374

Epoch: 5| Step: 8
Training loss: 0.6761030554771423
Validation loss: 1.7362146454472696

Epoch: 5| Step: 9
Training loss: 0.43063193559646606
Validation loss: 1.7333474210513535

Epoch: 5| Step: 10
Training loss: 0.6899757385253906
Validation loss: 1.7120165376253025

Epoch: 263| Step: 0
Training loss: 0.3860502243041992
Validation loss: 1.7626688275285947

Epoch: 5| Step: 1
Training loss: 0.4409632682800293
Validation loss: 1.7610595969743625

Epoch: 5| Step: 2
Training loss: 0.3197029232978821
Validation loss: 1.7709601399719075

Epoch: 5| Step: 3
Training loss: 0.8049719929695129
Validation loss: 1.7751477687589583

Epoch: 5| Step: 4
Training loss: 0.33223825693130493
Validation loss: 1.7947209368469894

Epoch: 5| Step: 5
Training loss: 0.39882221817970276
Validation loss: 1.7777043388735863

Epoch: 5| Step: 6
Training loss: 0.42683714628219604
Validation loss: 1.7604982224843835

Epoch: 5| Step: 7
Training loss: 0.5560196042060852
Validation loss: 1.7490798709213093

Epoch: 5| Step: 8
Training loss: 0.7062098979949951
Validation loss: 1.7472267368788361

Epoch: 5| Step: 9
Training loss: 0.3906516432762146
Validation loss: 1.7305814348241335

Epoch: 5| Step: 10
Training loss: 0.5680184960365295
Validation loss: 1.7278952598571777

Epoch: 264| Step: 0
Training loss: 0.36981093883514404
Validation loss: 1.7492671269242481

Epoch: 5| Step: 1
Training loss: 0.33850714564323425
Validation loss: 1.7687431958413893

Epoch: 5| Step: 2
Training loss: 0.5682157874107361
Validation loss: 1.8260115244055306

Epoch: 5| Step: 3
Training loss: 0.5030468702316284
Validation loss: 1.872807313037175

Epoch: 5| Step: 4
Training loss: 0.3927036225795746
Validation loss: 1.8895220602712324

Epoch: 5| Step: 5
Training loss: 0.4902464747428894
Validation loss: 1.8880508586924563

Epoch: 5| Step: 6
Training loss: 0.5909891128540039
Validation loss: 1.8846518019194245

Epoch: 5| Step: 7
Training loss: 0.568256139755249
Validation loss: 1.850376857224331

Epoch: 5| Step: 8
Training loss: 0.6237137913703918
Validation loss: 1.8422567024025867

Epoch: 5| Step: 9
Training loss: 0.42625802755355835
Validation loss: 1.808725933874807

Epoch: 5| Step: 10
Training loss: 0.44527456164360046
Validation loss: 1.7776763400723856

Epoch: 265| Step: 0
Training loss: 0.44238343834877014
Validation loss: 1.7932286416330645

Epoch: 5| Step: 1
Training loss: 0.4900141656398773
Validation loss: 1.7823560212248115

Epoch: 5| Step: 2
Training loss: 0.5685344934463501
Validation loss: 1.7937989222106112

Epoch: 5| Step: 3
Training loss: 0.7522767186164856
Validation loss: 1.7938823597405547

Epoch: 5| Step: 4
Training loss: 0.4263269007205963
Validation loss: 1.8032190876622354

Epoch: 5| Step: 5
Training loss: 0.3201372027397156
Validation loss: 1.8249600882171302

Epoch: 5| Step: 6
Training loss: 0.7242330312728882
Validation loss: 1.813652987121254

Epoch: 5| Step: 7
Training loss: 0.435706228017807
Validation loss: 1.8434567630931895

Epoch: 5| Step: 8
Training loss: 0.2633175551891327
Validation loss: 1.8364249596031763

Epoch: 5| Step: 9
Training loss: 0.3742353320121765
Validation loss: 1.7943478694526098

Epoch: 5| Step: 10
Training loss: 0.5074220895767212
Validation loss: 1.7465046272482923

Epoch: 266| Step: 0
Training loss: 0.42309027910232544
Validation loss: 1.6990572252581198

Epoch: 5| Step: 1
Training loss: 0.7356678247451782
Validation loss: 1.6597944010970413

Epoch: 5| Step: 2
Training loss: 0.5062748193740845
Validation loss: 1.6896230328467585

Epoch: 5| Step: 3
Training loss: 0.5804427862167358
Validation loss: 1.6900351355152745

Epoch: 5| Step: 4
Training loss: 0.4020431935787201
Validation loss: 1.6809964743993615

Epoch: 5| Step: 5
Training loss: 0.47312623262405396
Validation loss: 1.6870683418807162

Epoch: 5| Step: 6
Training loss: 0.3044466972351074
Validation loss: 1.7214415150303994

Epoch: 5| Step: 7
Training loss: 0.5606778264045715
Validation loss: 1.735798881899926

Epoch: 5| Step: 8
Training loss: 0.27082300186157227
Validation loss: 1.8214804510916434

Epoch: 5| Step: 9
Training loss: 0.5067501664161682
Validation loss: 1.8414933091850691

Epoch: 5| Step: 10
Training loss: 0.4004795551300049
Validation loss: 1.8204660877104728

Epoch: 267| Step: 0
Training loss: 0.7878168225288391
Validation loss: 1.8336772944337578

Epoch: 5| Step: 1
Training loss: 0.3820358216762543
Validation loss: 1.7959443112855316

Epoch: 5| Step: 2
Training loss: 0.41632914543151855
Validation loss: 1.7737456271725316

Epoch: 5| Step: 3
Training loss: 0.40095824003219604
Validation loss: 1.760226898295905

Epoch: 5| Step: 4
Training loss: 0.3497176468372345
Validation loss: 1.7592282192681425

Epoch: 5| Step: 5
Training loss: 0.3531038761138916
Validation loss: 1.7503577945052937

Epoch: 5| Step: 6
Training loss: 0.36497512459754944
Validation loss: 1.7833349038195867

Epoch: 5| Step: 7
Training loss: 0.593706488609314
Validation loss: 1.74801129423162

Epoch: 5| Step: 8
Training loss: 0.22974486649036407
Validation loss: 1.7656833599972468

Epoch: 5| Step: 9
Training loss: 0.6622104644775391
Validation loss: 1.782549363310619

Epoch: 5| Step: 10
Training loss: 0.4074573516845703
Validation loss: 1.79936388743821

Epoch: 268| Step: 0
Training loss: 0.6037369966506958
Validation loss: 1.8567989692893079

Epoch: 5| Step: 1
Training loss: 0.5265058875083923
Validation loss: 1.8899730354227045

Epoch: 5| Step: 2
Training loss: 0.6733008623123169
Validation loss: 1.9121700051010295

Epoch: 5| Step: 3
Training loss: 0.41166096925735474
Validation loss: 1.8837664563168761

Epoch: 5| Step: 4
Training loss: 0.5755435824394226
Validation loss: 1.8250664511034567

Epoch: 5| Step: 5
Training loss: 0.3551223874092102
Validation loss: 1.7820220557592248

Epoch: 5| Step: 6
Training loss: 0.26024967432022095
Validation loss: 1.764864799796894

Epoch: 5| Step: 7
Training loss: 0.4367765486240387
Validation loss: 1.7255109753659976

Epoch: 5| Step: 8
Training loss: 0.5532718896865845
Validation loss: 1.7645910042588429

Epoch: 5| Step: 9
Training loss: 0.49879294633865356
Validation loss: 1.748878188030694

Epoch: 5| Step: 10
Training loss: 0.34438830614089966
Validation loss: 1.7564624483867357

Epoch: 269| Step: 0
Training loss: 0.2241380214691162
Validation loss: 1.7682966468154744

Epoch: 5| Step: 1
Training loss: 0.5167404413223267
Validation loss: 1.7800231159374278

Epoch: 5| Step: 2
Training loss: 0.33744657039642334
Validation loss: 1.7924683247843096

Epoch: 5| Step: 3
Training loss: 0.297701895236969
Validation loss: 1.8232286783956713

Epoch: 5| Step: 4
Training loss: 0.5182722806930542
Validation loss: 1.8256271436650267

Epoch: 5| Step: 5
Training loss: 0.49262648820877075
Validation loss: 1.8612396409434657

Epoch: 5| Step: 6
Training loss: 0.4384693205356598
Validation loss: 1.8682293584269862

Epoch: 5| Step: 7
Training loss: 0.38952672481536865
Validation loss: 1.888896321737638

Epoch: 5| Step: 8
Training loss: 0.5795732736587524
Validation loss: 1.8397829417259461

Epoch: 5| Step: 9
Training loss: 0.5107710957527161
Validation loss: 1.8332286739862094

Epoch: 5| Step: 10
Training loss: 0.488442599773407
Validation loss: 1.8005397588975969

Epoch: 270| Step: 0
Training loss: 0.586495041847229
Validation loss: 1.8001000048011861

Epoch: 5| Step: 1
Training loss: 0.6260350942611694
Validation loss: 1.796674616875187

Epoch: 5| Step: 2
Training loss: 0.34637758135795593
Validation loss: 1.7942617426636398

Epoch: 5| Step: 3
Training loss: 0.62481689453125
Validation loss: 1.78513377968983

Epoch: 5| Step: 4
Training loss: 0.31163135170936584
Validation loss: 1.7933882372353667

Epoch: 5| Step: 5
Training loss: 0.32769775390625
Validation loss: 1.7766343598724694

Epoch: 5| Step: 6
Training loss: 0.5908997654914856
Validation loss: 1.7961141050502818

Epoch: 5| Step: 7
Training loss: 0.2974260747432709
Validation loss: 1.7896151824664044

Epoch: 5| Step: 8
Training loss: 0.5263202786445618
Validation loss: 1.7713474458263767

Epoch: 5| Step: 9
Training loss: 0.1599597930908203
Validation loss: 1.768058958873954

Epoch: 5| Step: 10
Training loss: 0.4251410663127899
Validation loss: 1.7975940717163907

Epoch: 271| Step: 0
Training loss: 0.6466156840324402
Validation loss: 1.7411883633623841

Epoch: 5| Step: 1
Training loss: 0.39454519748687744
Validation loss: 1.7501864369197557

Epoch: 5| Step: 2
Training loss: 0.4672475755214691
Validation loss: 1.7657011580723587

Epoch: 5| Step: 3
Training loss: 0.4185091555118561
Validation loss: 1.7610607993218206

Epoch: 5| Step: 4
Training loss: 0.6135881543159485
Validation loss: 1.7407729741065734

Epoch: 5| Step: 5
Training loss: 0.43261775374412537
Validation loss: 1.7466112157349944

Epoch: 5| Step: 6
Training loss: 0.32715877890586853
Validation loss: 1.7714776223705662

Epoch: 5| Step: 7
Training loss: 0.2437082827091217
Validation loss: 1.7497619659669938

Epoch: 5| Step: 8
Training loss: 0.3063475489616394
Validation loss: 1.7572734073926044

Epoch: 5| Step: 9
Training loss: 0.5087045431137085
Validation loss: 1.7543491548107517

Epoch: 5| Step: 10
Training loss: 0.29915010929107666
Validation loss: 1.75255504474845

Epoch: 272| Step: 0
Training loss: 0.3590436577796936
Validation loss: 1.7217839520464662

Epoch: 5| Step: 1
Training loss: 0.4884353578090668
Validation loss: 1.711393287104945

Epoch: 5| Step: 2
Training loss: 0.279738187789917
Validation loss: 1.7362046216123848

Epoch: 5| Step: 3
Training loss: 0.3330603539943695
Validation loss: 1.7136269166905393

Epoch: 5| Step: 4
Training loss: 0.5213035345077515
Validation loss: 1.7191669684584423

Epoch: 5| Step: 5
Training loss: 0.42431893944740295
Validation loss: 1.7020793659712679

Epoch: 5| Step: 6
Training loss: 0.5789048671722412
Validation loss: 1.7264108696291525

Epoch: 5| Step: 7
Training loss: 0.4995911717414856
Validation loss: 1.7280528891471125

Epoch: 5| Step: 8
Training loss: 0.37022262811660767
Validation loss: 1.7232865454048238

Epoch: 5| Step: 9
Training loss: 0.4674542546272278
Validation loss: 1.746080449832383

Epoch: 5| Step: 10
Training loss: 0.3277614414691925
Validation loss: 1.7573882341384888

Epoch: 273| Step: 0
Training loss: 0.5145038366317749
Validation loss: 1.782781898334462

Epoch: 5| Step: 1
Training loss: 0.4195193350315094
Validation loss: 1.7947099131922568

Epoch: 5| Step: 2
Training loss: 0.4302092492580414
Validation loss: 1.8274612003757107

Epoch: 5| Step: 3
Training loss: 0.5171720385551453
Validation loss: 1.7927591236688758

Epoch: 5| Step: 4
Training loss: 0.413557231426239
Validation loss: 1.7744774113419235

Epoch: 5| Step: 5
Training loss: 0.26845937967300415
Validation loss: 1.782567172922114

Epoch: 5| Step: 6
Training loss: 0.27788740396499634
Validation loss: 1.7542141342675814

Epoch: 5| Step: 7
Training loss: 0.34169358015060425
Validation loss: 1.722302459901379

Epoch: 5| Step: 8
Training loss: 0.43010377883911133
Validation loss: 1.7314454240183677

Epoch: 5| Step: 9
Training loss: 0.5394261479377747
Validation loss: 1.7214964153946086

Epoch: 5| Step: 10
Training loss: 0.4931451678276062
Validation loss: 1.7260610993190477

Epoch: 274| Step: 0
Training loss: 0.3267447054386139
Validation loss: 1.7609167304090274

Epoch: 5| Step: 1
Training loss: 0.3147800862789154
Validation loss: 1.7310640837556572

Epoch: 5| Step: 2
Training loss: 0.5224831700325012
Validation loss: 1.8082448718368367

Epoch: 5| Step: 3
Training loss: 0.4512051045894623
Validation loss: 1.8159838338052072

Epoch: 5| Step: 4
Training loss: 0.49116644263267517
Validation loss: 1.8322999272295224

Epoch: 5| Step: 5
Training loss: 0.37760305404663086
Validation loss: 1.8471210336172452

Epoch: 5| Step: 6
Training loss: 0.41295331716537476
Validation loss: 1.8367049155696746

Epoch: 5| Step: 7
Training loss: 0.37635254859924316
Validation loss: 1.8092724956491941

Epoch: 5| Step: 8
Training loss: 0.51731938123703
Validation loss: 1.7703638999692854

Epoch: 5| Step: 9
Training loss: 0.5757181644439697
Validation loss: 1.7314236176911222

Epoch: 5| Step: 10
Training loss: 0.3994673490524292
Validation loss: 1.7245103889896023

Epoch: 275| Step: 0
Training loss: 0.32711267471313477
Validation loss: 1.6915687271343764

Epoch: 5| Step: 1
Training loss: 0.4305295944213867
Validation loss: 1.7019387419505785

Epoch: 5| Step: 2
Training loss: 0.4348476529121399
Validation loss: 1.7011482536151845

Epoch: 5| Step: 3
Training loss: 0.4001917243003845
Validation loss: 1.6946125209972422

Epoch: 5| Step: 4
Training loss: 0.2655431032180786
Validation loss: 1.767313886714238

Epoch: 5| Step: 5
Training loss: 0.5067251920700073
Validation loss: 1.8015101930146575

Epoch: 5| Step: 6
Training loss: 0.3892626166343689
Validation loss: 1.8388143226664553

Epoch: 5| Step: 7
Training loss: 0.6182619333267212
Validation loss: 1.8747146667972687

Epoch: 5| Step: 8
Training loss: 0.3583122193813324
Validation loss: 1.8459161045730754

Epoch: 5| Step: 9
Training loss: 0.40585917234420776
Validation loss: 1.8204818669185843

Epoch: 5| Step: 10
Training loss: 0.530219554901123
Validation loss: 1.8129029056077361

Epoch: 276| Step: 0
Training loss: 0.3512023985385895
Validation loss: 1.7734587500172276

Epoch: 5| Step: 1
Training loss: 0.6132606267929077
Validation loss: 1.762855468257781

Epoch: 5| Step: 2
Training loss: 0.35814937949180603
Validation loss: 1.7306236913127284

Epoch: 5| Step: 3
Training loss: 0.21139535307884216
Validation loss: 1.7167382547932286

Epoch: 5| Step: 4
Training loss: 0.42804208397865295
Validation loss: 1.7208175659179688

Epoch: 5| Step: 5
Training loss: 0.4445444941520691
Validation loss: 1.7185494322930612

Epoch: 5| Step: 6
Training loss: 0.36336979269981384
Validation loss: 1.7205221140256493

Epoch: 5| Step: 7
Training loss: 0.42126888036727905
Validation loss: 1.7242870958902503

Epoch: 5| Step: 8
Training loss: 0.4031313359737396
Validation loss: 1.7742360727761382

Epoch: 5| Step: 9
Training loss: 0.5489338636398315
Validation loss: 1.8275234160884735

Epoch: 5| Step: 10
Training loss: 0.6020627021789551
Validation loss: 1.8223952439523512

Epoch: 277| Step: 0
Training loss: 0.4949131906032562
Validation loss: 1.8004963192888486

Epoch: 5| Step: 1
Training loss: 0.36222684383392334
Validation loss: 1.7403637568155925

Epoch: 5| Step: 2
Training loss: 0.28598904609680176
Validation loss: 1.7217465869842037

Epoch: 5| Step: 3
Training loss: 0.4345018267631531
Validation loss: 1.662489850033996

Epoch: 5| Step: 4
Training loss: 0.586061954498291
Validation loss: 1.6747221997989121

Epoch: 5| Step: 5
Training loss: 0.2980796992778778
Validation loss: 1.6550329244264992

Epoch: 5| Step: 6
Training loss: 0.3805076479911804
Validation loss: 1.68753271589997

Epoch: 5| Step: 7
Training loss: 0.3059885501861572
Validation loss: 1.6928190723542245

Epoch: 5| Step: 8
Training loss: 0.3375694751739502
Validation loss: 1.6966453982937721

Epoch: 5| Step: 9
Training loss: 0.448615163564682
Validation loss: 1.705786524280425

Epoch: 5| Step: 10
Training loss: 0.522555947303772
Validation loss: 1.7418905509415494

Epoch: 278| Step: 0
Training loss: 0.5319363474845886
Validation loss: 1.779485015458958

Epoch: 5| Step: 1
Training loss: 0.25147852301597595
Validation loss: 1.7783812643379293

Epoch: 5| Step: 2
Training loss: 0.36178821325302124
Validation loss: 1.7676919890988259

Epoch: 5| Step: 3
Training loss: 0.430097758769989
Validation loss: 1.765917392187221

Epoch: 5| Step: 4
Training loss: 0.41777390241622925
Validation loss: 1.7257556274373045

Epoch: 5| Step: 5
Training loss: 0.1639661341905594
Validation loss: 1.7010580775558308

Epoch: 5| Step: 6
Training loss: 0.5707592368125916
Validation loss: 1.7101514159992177

Epoch: 5| Step: 7
Training loss: 0.43842068314552307
Validation loss: 1.7161118240766629

Epoch: 5| Step: 8
Training loss: 0.45020779967308044
Validation loss: 1.7330647604439848

Epoch: 5| Step: 9
Training loss: 0.38608986139297485
Validation loss: 1.7147570989465202

Epoch: 5| Step: 10
Training loss: 0.3851498067378998
Validation loss: 1.7211880478807675

Epoch: 279| Step: 0
Training loss: 0.5645725131034851
Validation loss: 1.738925418546123

Epoch: 5| Step: 1
Training loss: 0.3630542755126953
Validation loss: 1.7289157631576701

Epoch: 5| Step: 2
Training loss: 0.45466774702072144
Validation loss: 1.780391844370032

Epoch: 5| Step: 3
Training loss: 0.3799978196620941
Validation loss: 1.78609210957763

Epoch: 5| Step: 4
Training loss: 0.46618223190307617
Validation loss: 1.7995796536886564

Epoch: 5| Step: 5
Training loss: 0.3201523423194885
Validation loss: 1.8228726579296974

Epoch: 5| Step: 6
Training loss: 0.294782429933548
Validation loss: 1.8122011820475261

Epoch: 5| Step: 7
Training loss: 0.5585583448410034
Validation loss: 1.797892661504848

Epoch: 5| Step: 8
Training loss: 0.3259355425834656
Validation loss: 1.7964605246820757

Epoch: 5| Step: 9
Training loss: 0.27804234623908997
Validation loss: 1.7736594279607136

Epoch: 5| Step: 10
Training loss: 0.30350035429000854
Validation loss: 1.764552350967161

Epoch: 280| Step: 0
Training loss: 0.29048028588294983
Validation loss: 1.7724880685088455

Epoch: 5| Step: 1
Training loss: 0.325522243976593
Validation loss: 1.7624223591178976

Epoch: 5| Step: 2
Training loss: 0.3503677546977997
Validation loss: 1.716087504099774

Epoch: 5| Step: 3
Training loss: 0.3600831925868988
Validation loss: 1.7268965218656807

Epoch: 5| Step: 4
Training loss: 0.41137805581092834
Validation loss: 1.7172952185394943

Epoch: 5| Step: 5
Training loss: 0.48506155610084534
Validation loss: 1.7576747543068343

Epoch: 5| Step: 6
Training loss: 0.5235694646835327
Validation loss: 1.7597221123274935

Epoch: 5| Step: 7
Training loss: 0.4077323377132416
Validation loss: 1.730530773439715

Epoch: 5| Step: 8
Training loss: 0.43545398116111755
Validation loss: 1.763715228726787

Epoch: 5| Step: 9
Training loss: 0.23378291726112366
Validation loss: 1.7398275662493963

Epoch: 5| Step: 10
Training loss: 0.44310784339904785
Validation loss: 1.7374334719873243

Epoch: 281| Step: 0
Training loss: 0.30591607093811035
Validation loss: 1.7585768263827088

Epoch: 5| Step: 1
Training loss: 0.37623921036720276
Validation loss: 1.7405632977844567

Epoch: 5| Step: 2
Training loss: 0.20429396629333496
Validation loss: 1.7310152540924728

Epoch: 5| Step: 3
Training loss: 0.41927021741867065
Validation loss: 1.7196819974530129

Epoch: 5| Step: 4
Training loss: 0.5044878125190735
Validation loss: 1.7105298913935179

Epoch: 5| Step: 5
Training loss: 0.30007439851760864
Validation loss: 1.7043422652829079

Epoch: 5| Step: 6
Training loss: 0.38388484716415405
Validation loss: 1.7309633378059632

Epoch: 5| Step: 7
Training loss: 0.6336652040481567
Validation loss: 1.7404618058153378

Epoch: 5| Step: 8
Training loss: 0.4266796112060547
Validation loss: 1.7763517800197806

Epoch: 5| Step: 9
Training loss: 0.42072010040283203
Validation loss: 1.7813268387189476

Epoch: 5| Step: 10
Training loss: 0.37639978528022766
Validation loss: 1.790821054930328

Epoch: 282| Step: 0
Training loss: 0.6114128828048706
Validation loss: 1.7929153891019924

Epoch: 5| Step: 1
Training loss: 0.43507009744644165
Validation loss: 1.7719180455771826

Epoch: 5| Step: 2
Training loss: 0.3101373612880707
Validation loss: 1.7349612917951358

Epoch: 5| Step: 3
Training loss: 0.3095352053642273
Validation loss: 1.7071031588380055

Epoch: 5| Step: 4
Training loss: 0.5032528638839722
Validation loss: 1.7029676668105587

Epoch: 5| Step: 5
Training loss: 0.35436487197875977
Validation loss: 1.702983840819328

Epoch: 5| Step: 6
Training loss: 0.40989041328430176
Validation loss: 1.6763443921201973

Epoch: 5| Step: 7
Training loss: 0.24267177283763885
Validation loss: 1.7189137974093038

Epoch: 5| Step: 8
Training loss: 0.3702083230018616
Validation loss: 1.7393343769093996

Epoch: 5| Step: 9
Training loss: 0.36867156624794006
Validation loss: 1.7538974067216277

Epoch: 5| Step: 10
Training loss: 0.4154233932495117
Validation loss: 1.8087670098068893

Epoch: 283| Step: 0
Training loss: 0.48435187339782715
Validation loss: 1.809360924587455

Epoch: 5| Step: 1
Training loss: 0.3687146306037903
Validation loss: 1.7964874544451315

Epoch: 5| Step: 2
Training loss: 0.4096708297729492
Validation loss: 1.7840732451408141

Epoch: 5| Step: 3
Training loss: 0.4111245274543762
Validation loss: 1.7853921100657473

Epoch: 5| Step: 4
Training loss: 0.35007548332214355
Validation loss: 1.755033250777952

Epoch: 5| Step: 5
Training loss: 0.5186492800712585
Validation loss: 1.7509648440986552

Epoch: 5| Step: 6
Training loss: 0.506437361240387
Validation loss: 1.692617259999757

Epoch: 5| Step: 7
Training loss: 0.4281091094017029
Validation loss: 1.6908062170910578

Epoch: 5| Step: 8
Training loss: 0.5289173722267151
Validation loss: 1.7106230848578996

Epoch: 5| Step: 9
Training loss: 0.39430665969848633
Validation loss: 1.718551694705922

Epoch: 5| Step: 10
Training loss: 0.3455640971660614
Validation loss: 1.786447698070157

Epoch: 284| Step: 0
Training loss: 0.18655696511268616
Validation loss: 1.8228683253770233

Epoch: 5| Step: 1
Training loss: 0.43153220415115356
Validation loss: 1.8389684064413911

Epoch: 5| Step: 2
Training loss: 0.4068235456943512
Validation loss: 1.8605710973021805

Epoch: 5| Step: 3
Training loss: 0.4525645673274994
Validation loss: 1.8456777949487009

Epoch: 5| Step: 4
Training loss: 0.38565319776535034
Validation loss: 1.8241436673748879

Epoch: 5| Step: 5
Training loss: 0.3109516501426697
Validation loss: 1.8126907758815314

Epoch: 5| Step: 6
Training loss: 0.3909382224082947
Validation loss: 1.7874801376814484

Epoch: 5| Step: 7
Training loss: 0.4406605660915375
Validation loss: 1.7703399530021093

Epoch: 5| Step: 8
Training loss: 0.5692585706710815
Validation loss: 1.7503075753488848

Epoch: 5| Step: 9
Training loss: 0.4096793234348297
Validation loss: 1.7157179540203464

Epoch: 5| Step: 10
Training loss: 0.3797479569911957
Validation loss: 1.742195458822353

Epoch: 285| Step: 0
Training loss: 0.4819253981113434
Validation loss: 1.77443681481064

Epoch: 5| Step: 1
Training loss: 0.3333897590637207
Validation loss: 1.78288237766553

Epoch: 5| Step: 2
Training loss: 0.37262779474258423
Validation loss: 1.7912496328353882

Epoch: 5| Step: 3
Training loss: 0.3881573975086212
Validation loss: 1.803599328123113

Epoch: 5| Step: 4
Training loss: 0.48668092489242554
Validation loss: 1.8328941688742688

Epoch: 5| Step: 5
Training loss: 0.34528234601020813
Validation loss: 1.8527654345317552

Epoch: 5| Step: 6
Training loss: 0.23674102127552032
Validation loss: 1.7994469532402613

Epoch: 5| Step: 7
Training loss: 0.45737189054489136
Validation loss: 1.8154061353334816

Epoch: 5| Step: 8
Training loss: 0.42889276146888733
Validation loss: 1.792124862952899

Epoch: 5| Step: 9
Training loss: 0.2051793336868286
Validation loss: 1.7744800083098873

Epoch: 5| Step: 10
Training loss: 0.2962305545806885
Validation loss: 1.741799231498472

Epoch: 286| Step: 0
Training loss: 0.20238995552062988
Validation loss: 1.7748590682142524

Epoch: 5| Step: 1
Training loss: 0.3341967463493347
Validation loss: 1.7546896575599589

Epoch: 5| Step: 2
Training loss: 0.5214695930480957
Validation loss: 1.768198699079534

Epoch: 5| Step: 3
Training loss: 0.40502220392227173
Validation loss: 1.7411606363070908

Epoch: 5| Step: 4
Training loss: 0.31333017349243164
Validation loss: 1.7314794717296478

Epoch: 5| Step: 5
Training loss: 0.4028104841709137
Validation loss: 1.734887598663248

Epoch: 5| Step: 6
Training loss: 0.5152090787887573
Validation loss: 1.7268332845421248

Epoch: 5| Step: 7
Training loss: 0.5202203989028931
Validation loss: 1.7114763182978476

Epoch: 5| Step: 8
Training loss: 0.2346966713666916
Validation loss: 1.706388363274195

Epoch: 5| Step: 9
Training loss: 0.3868376612663269
Validation loss: 1.6855689684549968

Epoch: 5| Step: 10
Training loss: 0.23326702415943146
Validation loss: 1.6731975770765735

Epoch: 287| Step: 0
Training loss: 0.4643741250038147
Validation loss: 1.6931573806270477

Epoch: 5| Step: 1
Training loss: 0.41766685247421265
Validation loss: 1.68570928547972

Epoch: 5| Step: 2
Training loss: 0.3736798167228699
Validation loss: 1.7215463064050163

Epoch: 5| Step: 3
Training loss: 0.6078486442565918
Validation loss: 1.7527150492514334

Epoch: 5| Step: 4
Training loss: 0.208614781498909
Validation loss: 1.7389317174111643

Epoch: 5| Step: 5
Training loss: 0.40543627738952637
Validation loss: 1.7290439439076248

Epoch: 5| Step: 6
Training loss: 0.6125270128250122
Validation loss: 1.6975209636072959

Epoch: 5| Step: 7
Training loss: 0.37466445565223694
Validation loss: 1.7213191216991794

Epoch: 5| Step: 8
Training loss: 0.2224338948726654
Validation loss: 1.7206962403430734

Epoch: 5| Step: 9
Training loss: 0.2753363847732544
Validation loss: 1.7042561141393517

Epoch: 5| Step: 10
Training loss: 0.2104617804288864
Validation loss: 1.7168046556493288

Epoch: 288| Step: 0
Training loss: 0.22329862415790558
Validation loss: 1.7309822587556736

Epoch: 5| Step: 1
Training loss: 0.4259948134422302
Validation loss: 1.710373044013977

Epoch: 5| Step: 2
Training loss: 0.27470341324806213
Validation loss: 1.712459978236947

Epoch: 5| Step: 3
Training loss: 0.30507606267929077
Validation loss: 1.725720372251285

Epoch: 5| Step: 4
Training loss: 0.42486295104026794
Validation loss: 1.725092605877948

Epoch: 5| Step: 5
Training loss: 0.3673464357852936
Validation loss: 1.734351009450933

Epoch: 5| Step: 6
Training loss: 0.4965185523033142
Validation loss: 1.726979301821801

Epoch: 5| Step: 7
Training loss: 0.38824641704559326
Validation loss: 1.747052816934483

Epoch: 5| Step: 8
Training loss: 0.3597021996974945
Validation loss: 1.7570372140535744

Epoch: 5| Step: 9
Training loss: 0.348247230052948
Validation loss: 1.7316012305598105

Epoch: 5| Step: 10
Training loss: 0.4597364366054535
Validation loss: 1.750281871006053

Epoch: 289| Step: 0
Training loss: 0.5145827531814575
Validation loss: 1.7470325552007204

Epoch: 5| Step: 1
Training loss: 0.4922265410423279
Validation loss: 1.7520424435215611

Epoch: 5| Step: 2
Training loss: 0.344967246055603
Validation loss: 1.7639463255482335

Epoch: 5| Step: 3
Training loss: 0.39684590697288513
Validation loss: 1.7870163391995173

Epoch: 5| Step: 4
Training loss: 0.348514586687088
Validation loss: 1.7846452702758133

Epoch: 5| Step: 5
Training loss: 0.3233581781387329
Validation loss: 1.7774669278052546

Epoch: 5| Step: 6
Training loss: 0.39907267689704895
Validation loss: 1.757898446052305

Epoch: 5| Step: 7
Training loss: 0.20375995337963104
Validation loss: 1.745575766409597

Epoch: 5| Step: 8
Training loss: 0.3066321015357971
Validation loss: 1.73685852173836

Epoch: 5| Step: 9
Training loss: 0.3392939865589142
Validation loss: 1.7034451512880222

Epoch: 5| Step: 10
Training loss: 0.28215575218200684
Validation loss: 1.7109170588113929

Epoch: 290| Step: 0
Training loss: 0.33768248558044434
Validation loss: 1.705563569581637

Epoch: 5| Step: 1
Training loss: 0.3408902585506439
Validation loss: 1.729231272974322

Epoch: 5| Step: 2
Training loss: 0.31164467334747314
Validation loss: 1.7109266583637526

Epoch: 5| Step: 3
Training loss: 0.3909127116203308
Validation loss: 1.7047609821442635

Epoch: 5| Step: 4
Training loss: 0.3774338662624359
Validation loss: 1.7137416434544388

Epoch: 5| Step: 5
Training loss: 0.2561365067958832
Validation loss: 1.7254278262456257

Epoch: 5| Step: 6
Training loss: 0.44565290212631226
Validation loss: 1.7464587970446515

Epoch: 5| Step: 7
Training loss: 0.7183119058609009
Validation loss: 1.7323876837248444

Epoch: 5| Step: 8
Training loss: 0.23083582520484924
Validation loss: 1.7414176848626906

Epoch: 5| Step: 9
Training loss: 0.2255188524723053
Validation loss: 1.7402280927986227

Epoch: 5| Step: 10
Training loss: 0.2822524905204773
Validation loss: 1.756977750409034

Epoch: 291| Step: 0
Training loss: 0.11900787055492401
Validation loss: 1.7380695368653984

Epoch: 5| Step: 1
Training loss: 0.2291976511478424
Validation loss: 1.7323588491767965

Epoch: 5| Step: 2
Training loss: 0.27933719754219055
Validation loss: 1.7390036095855057

Epoch: 5| Step: 3
Training loss: 0.6381556391716003
Validation loss: 1.7340404525879891

Epoch: 5| Step: 4
Training loss: 0.38324615359306335
Validation loss: 1.7449414460889754

Epoch: 5| Step: 5
Training loss: 0.4863344728946686
Validation loss: 1.7074391636797177

Epoch: 5| Step: 6
Training loss: 0.5140508413314819
Validation loss: 1.7360351611209173

Epoch: 5| Step: 7
Training loss: 0.25587981939315796
Validation loss: 1.7925691014976912

Epoch: 5| Step: 8
Training loss: 0.2704361379146576
Validation loss: 1.8002953439630487

Epoch: 5| Step: 9
Training loss: 0.1951073706150055
Validation loss: 1.8158416671137656

Epoch: 5| Step: 10
Training loss: 0.3705001771450043
Validation loss: 1.8422310736871534

Epoch: 292| Step: 0
Training loss: 0.2665392756462097
Validation loss: 1.8412248191013132

Epoch: 5| Step: 1
Training loss: 0.2144179791212082
Validation loss: 1.8208268906480523

Epoch: 5| Step: 2
Training loss: 0.305836945772171
Validation loss: 1.8067845324034333

Epoch: 5| Step: 3
Training loss: 0.46515727043151855
Validation loss: 1.784847164666781

Epoch: 5| Step: 4
Training loss: 0.47847357392311096
Validation loss: 1.741499239398587

Epoch: 5| Step: 5
Training loss: 0.3241042494773865
Validation loss: 1.776535867362894

Epoch: 5| Step: 6
Training loss: 0.46046990156173706
Validation loss: 1.7486499509503763

Epoch: 5| Step: 7
Training loss: 0.21227602660655975
Validation loss: 1.7402966778765443

Epoch: 5| Step: 8
Training loss: 0.3237771987915039
Validation loss: 1.756803697155368

Epoch: 5| Step: 9
Training loss: 0.4310879707336426
Validation loss: 1.7582619908035442

Epoch: 5| Step: 10
Training loss: 0.40508008003234863
Validation loss: 1.7562012826242754

Epoch: 293| Step: 0
Training loss: 0.3043208718299866
Validation loss: 1.7757398031091178

Epoch: 5| Step: 1
Training loss: 0.41095948219299316
Validation loss: 1.7639302361396052

Epoch: 5| Step: 2
Training loss: 0.24512562155723572
Validation loss: 1.7686728078831908

Epoch: 5| Step: 3
Training loss: 0.5320514440536499
Validation loss: 1.8094982818890644

Epoch: 5| Step: 4
Training loss: 0.42808961868286133
Validation loss: 1.7988987276631017

Epoch: 5| Step: 5
Training loss: 0.5039974451065063
Validation loss: 1.7582957795871201

Epoch: 5| Step: 6
Training loss: 0.39436861872673035
Validation loss: 1.7361088491255237

Epoch: 5| Step: 7
Training loss: 0.3835194706916809
Validation loss: 1.6888833135686896

Epoch: 5| Step: 8
Training loss: 0.3515792489051819
Validation loss: 1.6665491698890604

Epoch: 5| Step: 9
Training loss: 0.2901538908481598
Validation loss: 1.6677252656670027

Epoch: 5| Step: 10
Training loss: 0.22340621054172516
Validation loss: 1.6642513544328752

Epoch: 294| Step: 0
Training loss: 0.3062501847743988
Validation loss: 1.6402906166609896

Epoch: 5| Step: 1
Training loss: 0.3858843743801117
Validation loss: 1.6762388918989448

Epoch: 5| Step: 2
Training loss: 0.3189203441143036
Validation loss: 1.683760896805794

Epoch: 5| Step: 3
Training loss: 0.42208999395370483
Validation loss: 1.715926867659374

Epoch: 5| Step: 4
Training loss: 0.4922330975532532
Validation loss: 1.7204384098770797

Epoch: 5| Step: 5
Training loss: 0.21134062111377716
Validation loss: 1.738487773044135

Epoch: 5| Step: 6
Training loss: 0.329831063747406
Validation loss: 1.725612457080554

Epoch: 5| Step: 7
Training loss: 0.2622089087963104
Validation loss: 1.7385854464705273

Epoch: 5| Step: 8
Training loss: 0.3601107597351074
Validation loss: 1.7360615576467207

Epoch: 5| Step: 9
Training loss: 0.31938621401786804
Validation loss: 1.7083216751775434

Epoch: 5| Step: 10
Training loss: 0.4895440340042114
Validation loss: 1.740636441015428

Epoch: 295| Step: 0
Training loss: 0.35643160343170166
Validation loss: 1.730388120938373

Epoch: 5| Step: 1
Training loss: 0.2553481459617615
Validation loss: 1.7066644763433805

Epoch: 5| Step: 2
Training loss: 0.3123014271259308
Validation loss: 1.724309713609757

Epoch: 5| Step: 3
Training loss: 0.46673160791397095
Validation loss: 1.727816491998652

Epoch: 5| Step: 4
Training loss: 0.34646135568618774
Validation loss: 1.743327538172404

Epoch: 5| Step: 5
Training loss: 0.22789497673511505
Validation loss: 1.6990480320428007

Epoch: 5| Step: 6
Training loss: 0.4936264157295227
Validation loss: 1.7435630688103296

Epoch: 5| Step: 7
Training loss: 0.4592971205711365
Validation loss: 1.7039540031904816

Epoch: 5| Step: 8
Training loss: 0.20711834728717804
Validation loss: 1.7424113417184481

Epoch: 5| Step: 9
Training loss: 0.2782590389251709
Validation loss: 1.7676661501648605

Epoch: 5| Step: 10
Training loss: 0.3291819393634796
Validation loss: 1.7800411101310485

Epoch: 296| Step: 0
Training loss: 0.3254988193511963
Validation loss: 1.7906824081174788

Epoch: 5| Step: 1
Training loss: 0.41484713554382324
Validation loss: 1.765315786484749

Epoch: 5| Step: 2
Training loss: 0.20421266555786133
Validation loss: 1.7707254719990555

Epoch: 5| Step: 3
Training loss: 0.30313199758529663
Validation loss: 1.7817119052333217

Epoch: 5| Step: 4
Training loss: 0.5015749931335449
Validation loss: 1.7244426896495204

Epoch: 5| Step: 5
Training loss: 0.2764379382133484
Validation loss: 1.720308059005327

Epoch: 5| Step: 6
Training loss: 0.3236599564552307
Validation loss: 1.7261714794302498

Epoch: 5| Step: 7
Training loss: 0.4683268964290619
Validation loss: 1.745000377778084

Epoch: 5| Step: 8
Training loss: 0.29310211539268494
Validation loss: 1.760497680274389

Epoch: 5| Step: 9
Training loss: 0.3432740569114685
Validation loss: 1.74198027067287

Epoch: 5| Step: 10
Training loss: 0.388374388217926
Validation loss: 1.7577694769828551

Epoch: 297| Step: 0
Training loss: 0.2680135667324066
Validation loss: 1.751975869619718

Epoch: 5| Step: 1
Training loss: 0.5584198236465454
Validation loss: 1.7593833336266138

Epoch: 5| Step: 2
Training loss: 0.3977206349372864
Validation loss: 1.7717116173877512

Epoch: 5| Step: 3
Training loss: 0.26828113198280334
Validation loss: 1.7471823884594826

Epoch: 5| Step: 4
Training loss: 0.45805567502975464
Validation loss: 1.728062323344651

Epoch: 5| Step: 5
Training loss: 0.1515391618013382
Validation loss: 1.7329799065025904

Epoch: 5| Step: 6
Training loss: 0.22170023620128632
Validation loss: 1.7412980435996928

Epoch: 5| Step: 7
Training loss: 0.3218362629413605
Validation loss: 1.7227218163910734

Epoch: 5| Step: 8
Training loss: 0.23927438259124756
Validation loss: 1.7305230914905507

Epoch: 5| Step: 9
Training loss: 0.3135312795639038
Validation loss: 1.7412378185538835

Epoch: 5| Step: 10
Training loss: 0.5401444435119629
Validation loss: 1.7751045739778908

Epoch: 298| Step: 0
Training loss: 0.2586211860179901
Validation loss: 1.762010666631883

Epoch: 5| Step: 1
Training loss: 0.4518463611602783
Validation loss: 1.8047795744352444

Epoch: 5| Step: 2
Training loss: 0.29957959055900574
Validation loss: 1.846888147374635

Epoch: 5| Step: 3
Training loss: 0.35515496134757996
Validation loss: 1.7748332702985374

Epoch: 5| Step: 4
Training loss: 0.3649657368659973
Validation loss: 1.7558861752992034

Epoch: 5| Step: 5
Training loss: 0.3601020276546478
Validation loss: 1.720406069550463

Epoch: 5| Step: 6
Training loss: 0.19432565569877625
Validation loss: 1.6964459957615021

Epoch: 5| Step: 7
Training loss: 0.18386247754096985
Validation loss: 1.7011628817486506

Epoch: 5| Step: 8
Training loss: 0.5431042313575745
Validation loss: 1.6720783518206688

Epoch: 5| Step: 9
Training loss: 0.41472458839416504
Validation loss: 1.700963653543944

Epoch: 5| Step: 10
Training loss: 0.28867727518081665
Validation loss: 1.6782762299301803

Epoch: 299| Step: 0
Training loss: 0.4108005464076996
Validation loss: 1.6606252988179524

Epoch: 5| Step: 1
Training loss: 0.38286277651786804
Validation loss: 1.6756767201167282

Epoch: 5| Step: 2
Training loss: 0.2762545943260193
Validation loss: 1.703516370506697

Epoch: 5| Step: 3
Training loss: 0.2916550636291504
Validation loss: 1.7111838427923058

Epoch: 5| Step: 4
Training loss: 0.295519083738327
Validation loss: 1.7262811442857147

Epoch: 5| Step: 5
Training loss: 0.31619375944137573
Validation loss: 1.7368812689217188

Epoch: 5| Step: 6
Training loss: 0.2963474690914154
Validation loss: 1.7327625854040987

Epoch: 5| Step: 7
Training loss: 0.34412989020347595
Validation loss: 1.7153146061846005

Epoch: 5| Step: 8
Training loss: 0.1502784639596939
Validation loss: 1.7004279013602965

Epoch: 5| Step: 9
Training loss: 0.369793176651001
Validation loss: 1.674967518416784

Epoch: 5| Step: 10
Training loss: 0.517547070980072
Validation loss: 1.6679069213969733

Epoch: 300| Step: 0
Training loss: 0.25995582342147827
Validation loss: 1.6478321731731456

Epoch: 5| Step: 1
Training loss: 0.43078961968421936
Validation loss: 1.6663739963244366

Epoch: 5| Step: 2
Training loss: 0.4112655520439148
Validation loss: 1.6566193296063332

Epoch: 5| Step: 3
Training loss: 0.20928987860679626
Validation loss: 1.661223151350534

Epoch: 5| Step: 4
Training loss: 0.3703674376010895
Validation loss: 1.671279235552716

Epoch: 5| Step: 5
Training loss: 0.2773652970790863
Validation loss: 1.698398357437503

Epoch: 5| Step: 6
Training loss: 0.29585886001586914
Validation loss: 1.7307470011454757

Epoch: 5| Step: 7
Training loss: 0.2627200186252594
Validation loss: 1.7487330769979825

Epoch: 5| Step: 8
Training loss: 0.28229421377182007
Validation loss: 1.7378344356372792

Epoch: 5| Step: 9
Training loss: 0.4966122508049011
Validation loss: 1.7692491187844226

Epoch: 5| Step: 10
Training loss: 0.2013644278049469
Validation loss: 1.695176039972613

Epoch: 301| Step: 0
Training loss: 0.2932867109775543
Validation loss: 1.705862734907417

Epoch: 5| Step: 1
Training loss: 0.23512844741344452
Validation loss: 1.6882034758085847

Epoch: 5| Step: 2
Training loss: 0.25164470076560974
Validation loss: 1.6899316951792727

Epoch: 5| Step: 3
Training loss: 0.4047471880912781
Validation loss: 1.6836251417795818

Epoch: 5| Step: 4
Training loss: 0.16357265412807465
Validation loss: 1.6784232726661108

Epoch: 5| Step: 5
Training loss: 0.46780043840408325
Validation loss: 1.7023967504501343

Epoch: 5| Step: 6
Training loss: 0.39103588461875916
Validation loss: 1.709846059481303

Epoch: 5| Step: 7
Training loss: 0.28058239817619324
Validation loss: 1.6870013808691373

Epoch: 5| Step: 8
Training loss: 0.42244046926498413
Validation loss: 1.6928304574822868

Epoch: 5| Step: 9
Training loss: 0.1538313925266266
Validation loss: 1.7172559551013413

Epoch: 5| Step: 10
Training loss: 0.394003301858902
Validation loss: 1.7397599592003772

Epoch: 302| Step: 0
Training loss: 0.1979568749666214
Validation loss: 1.7549984852472942

Epoch: 5| Step: 1
Training loss: 0.1676265150308609
Validation loss: 1.7708420227932673

Epoch: 5| Step: 2
Training loss: 0.46072325110435486
Validation loss: 1.798675024381248

Epoch: 5| Step: 3
Training loss: 0.41272419691085815
Validation loss: 1.785274153114647

Epoch: 5| Step: 4
Training loss: 0.4017179608345032
Validation loss: 1.8176582282589329

Epoch: 5| Step: 5
Training loss: 0.27302175760269165
Validation loss: 1.8077700881547825

Epoch: 5| Step: 6
Training loss: 0.46093493700027466
Validation loss: 1.802876805746427

Epoch: 5| Step: 7
Training loss: 0.2948216497898102
Validation loss: 1.7447563384168892

Epoch: 5| Step: 8
Training loss: 0.2864077687263489
Validation loss: 1.7512038433423607

Epoch: 5| Step: 9
Training loss: 0.26539212465286255
Validation loss: 1.7521767398362518

Epoch: 5| Step: 10
Training loss: 0.2863138020038605
Validation loss: 1.7836167863620225

Epoch: 303| Step: 0
Training loss: 0.3414400815963745
Validation loss: 1.7676767636370916

Epoch: 5| Step: 1
Training loss: 0.3010266423225403
Validation loss: 1.7699781233264553

Epoch: 5| Step: 2
Training loss: 0.5007475018501282
Validation loss: 1.7618395308012604

Epoch: 5| Step: 3
Training loss: 0.2433677613735199
Validation loss: 1.777564384604013

Epoch: 5| Step: 4
Training loss: 0.3037445545196533
Validation loss: 1.7337913179910311

Epoch: 5| Step: 5
Training loss: 0.1930117905139923
Validation loss: 1.7236366489882111

Epoch: 5| Step: 6
Training loss: 0.3310898542404175
Validation loss: 1.708180558296942

Epoch: 5| Step: 7
Training loss: 0.34753313660621643
Validation loss: 1.691588153121292

Epoch: 5| Step: 8
Training loss: 0.33197250962257385
Validation loss: 1.6873569193706717

Epoch: 5| Step: 9
Training loss: 0.3691873550415039
Validation loss: 1.6543119568978586

Epoch: 5| Step: 10
Training loss: 0.17694759368896484
Validation loss: 1.648971535826242

Epoch: 304| Step: 0
Training loss: 0.1908338963985443
Validation loss: 1.6577315958597327

Epoch: 5| Step: 1
Training loss: 0.3413698077201843
Validation loss: 1.6750860009142148

Epoch: 5| Step: 2
Training loss: 0.17322666943073273
Validation loss: 1.694925396673141

Epoch: 5| Step: 3
Training loss: 0.395681232213974
Validation loss: 1.7021757248909242

Epoch: 5| Step: 4
Training loss: 0.4016776978969574
Validation loss: 1.7011461360480196

Epoch: 5| Step: 5
Training loss: 0.2906608283519745
Validation loss: 1.710447447274321

Epoch: 5| Step: 6
Training loss: 0.30880847573280334
Validation loss: 1.6987423986516974

Epoch: 5| Step: 7
Training loss: 0.4196137487888336
Validation loss: 1.7255215119290095

Epoch: 5| Step: 8
Training loss: 0.22566533088684082
Validation loss: 1.704461548918037

Epoch: 5| Step: 9
Training loss: 0.5118040442466736
Validation loss: 1.7078445893461986

Epoch: 5| Step: 10
Training loss: 0.17476806044578552
Validation loss: 1.6910985785145913

Epoch: 305| Step: 0
Training loss: 0.19966650009155273
Validation loss: 1.6868542637876285

Epoch: 5| Step: 1
Training loss: 0.25078773498535156
Validation loss: 1.7267048781917942

Epoch: 5| Step: 2
Training loss: 0.2506232261657715
Validation loss: 1.7334874906847555

Epoch: 5| Step: 3
Training loss: 0.3027747571468353
Validation loss: 1.7462172956876858

Epoch: 5| Step: 4
Training loss: 0.2751457691192627
Validation loss: 1.7482687363060572

Epoch: 5| Step: 5
Training loss: 0.27320465445518494
Validation loss: 1.748319008017099

Epoch: 5| Step: 6
Training loss: 0.292366087436676
Validation loss: 1.7599571802282845

Epoch: 5| Step: 7
Training loss: 0.31867915391921997
Validation loss: 1.7667528493430025

Epoch: 5| Step: 8
Training loss: 0.4570314884185791
Validation loss: 1.7440601023294593

Epoch: 5| Step: 9
Training loss: 0.4550742208957672
Validation loss: 1.7676620752580705

Epoch: 5| Step: 10
Training loss: 0.20797693729400635
Validation loss: 1.7285128588317542

Epoch: 306| Step: 0
Training loss: 0.2245866358280182
Validation loss: 1.7356815773953673

Epoch: 5| Step: 1
Training loss: 0.24718721210956573
Validation loss: 1.6945744124791955

Epoch: 5| Step: 2
Training loss: 0.17934006452560425
Validation loss: 1.6986598135322653

Epoch: 5| Step: 3
Training loss: 0.3675176501274109
Validation loss: 1.7153265860772902

Epoch: 5| Step: 4
Training loss: 0.39081722497940063
Validation loss: 1.6894741212168047

Epoch: 5| Step: 5
Training loss: 0.3821963369846344
Validation loss: 1.7300207512353056

Epoch: 5| Step: 6
Training loss: 0.39008739590644836
Validation loss: 1.7134905310087307

Epoch: 5| Step: 7
Training loss: 0.29102638363838196
Validation loss: 1.7386928758313578

Epoch: 5| Step: 8
Training loss: 0.3030799925327301
Validation loss: 1.7802097989666847

Epoch: 5| Step: 9
Training loss: 0.40447014570236206
Validation loss: 1.7436692919782413

Epoch: 5| Step: 10
Training loss: 0.2345871776342392
Validation loss: 1.7379699189175841

Epoch: 307| Step: 0
Training loss: 0.20583710074424744
Validation loss: 1.720662046504277

Epoch: 5| Step: 1
Training loss: 0.573081374168396
Validation loss: 1.6574643722144506

Epoch: 5| Step: 2
Training loss: 0.3356403112411499
Validation loss: 1.6916882145789363

Epoch: 5| Step: 3
Training loss: 0.47453075647354126
Validation loss: 1.703071940329767

Epoch: 5| Step: 4
Training loss: 0.27727460861206055
Validation loss: 1.6693003690370949

Epoch: 5| Step: 5
Training loss: 0.20072011649608612
Validation loss: 1.6785365554594225

Epoch: 5| Step: 6
Training loss: 0.3153458833694458
Validation loss: 1.7072174946467082

Epoch: 5| Step: 7
Training loss: 0.29226207733154297
Validation loss: 1.701205870156647

Epoch: 5| Step: 8
Training loss: 0.5004084706306458
Validation loss: 1.7164079296973445

Epoch: 5| Step: 9
Training loss: 0.2733277678489685
Validation loss: 1.7174691782202771

Epoch: 5| Step: 10
Training loss: 0.40108442306518555
Validation loss: 1.7230480294073782

Epoch: 308| Step: 0
Training loss: 0.24662692844867706
Validation loss: 1.7174726596442602

Epoch: 5| Step: 1
Training loss: 0.2168215811252594
Validation loss: 1.7203311676620154

Epoch: 5| Step: 2
Training loss: 0.3138337731361389
Validation loss: 1.684266241647864

Epoch: 5| Step: 3
Training loss: 0.15203365683555603
Validation loss: 1.6862071502593257

Epoch: 5| Step: 4
Training loss: 0.19968768954277039
Validation loss: 1.6742734101510817

Epoch: 5| Step: 5
Training loss: 0.3074205815792084
Validation loss: 1.6912283910218107

Epoch: 5| Step: 6
Training loss: 0.343178927898407
Validation loss: 1.69897743322516

Epoch: 5| Step: 7
Training loss: 0.5486510992050171
Validation loss: 1.7306556240204842

Epoch: 5| Step: 8
Training loss: 0.3239322602748871
Validation loss: 1.7084555831006778

Epoch: 5| Step: 9
Training loss: 0.3700372576713562
Validation loss: 1.7108335725722774

Epoch: 5| Step: 10
Training loss: 0.32004496455192566
Validation loss: 1.7093927629532353

Epoch: 309| Step: 0
Training loss: 0.3478732705116272
Validation loss: 1.693278428046934

Epoch: 5| Step: 1
Training loss: 0.2890496850013733
Validation loss: 1.7126865733054377

Epoch: 5| Step: 2
Training loss: 0.2349669486284256
Validation loss: 1.7313439730674989

Epoch: 5| Step: 3
Training loss: 0.28013694286346436
Validation loss: 1.7267471923623035

Epoch: 5| Step: 4
Training loss: 0.5343126058578491
Validation loss: 1.7166372934977214

Epoch: 5| Step: 5
Training loss: 0.31598398089408875
Validation loss: 1.738319658464001

Epoch: 5| Step: 6
Training loss: 0.1789080798625946
Validation loss: 1.7096007216361262

Epoch: 5| Step: 7
Training loss: 0.3687483072280884
Validation loss: 1.7178526770684026

Epoch: 5| Step: 8
Training loss: 0.27214315533638
Validation loss: 1.6828541845403693

Epoch: 5| Step: 9
Training loss: 0.2877040505409241
Validation loss: 1.677729155427666

Epoch: 5| Step: 10
Training loss: 0.18450462818145752
Validation loss: 1.6798641938035206

Epoch: 310| Step: 0
Training loss: 0.3020542562007904
Validation loss: 1.6775959332784016

Epoch: 5| Step: 1
Training loss: 0.2597087621688843
Validation loss: 1.7073840864243046

Epoch: 5| Step: 2
Training loss: 0.39131659269332886
Validation loss: 1.7276127517864268

Epoch: 5| Step: 3
Training loss: 0.3193208575248718
Validation loss: 1.710220452277891

Epoch: 5| Step: 4
Training loss: 0.2707834243774414
Validation loss: 1.6908524369680753

Epoch: 5| Step: 5
Training loss: 0.18324576318264008
Validation loss: 1.7087290338290635

Epoch: 5| Step: 6
Training loss: 0.3825909197330475
Validation loss: 1.701384275190292

Epoch: 5| Step: 7
Training loss: 0.247001051902771
Validation loss: 1.7148981184087775

Epoch: 5| Step: 8
Training loss: 0.232479527592659
Validation loss: 1.688437980990256

Epoch: 5| Step: 9
Training loss: 0.2557465434074402
Validation loss: 1.7031189049443891

Epoch: 5| Step: 10
Training loss: 0.3369481563568115
Validation loss: 1.7129049890784807

Epoch: 311| Step: 0
Training loss: 0.29036304354667664
Validation loss: 1.7269900063032746

Epoch: 5| Step: 1
Training loss: 0.1728821098804474
Validation loss: 1.7411228584986862

Epoch: 5| Step: 2
Training loss: 0.23772045969963074
Validation loss: 1.7426210962316042

Epoch: 5| Step: 3
Training loss: 0.3052043914794922
Validation loss: 1.806852917517385

Epoch: 5| Step: 4
Training loss: 0.4991334080696106
Validation loss: 1.7849346988944597

Epoch: 5| Step: 5
Training loss: 0.2808518707752228
Validation loss: 1.781053404654226

Epoch: 5| Step: 6
Training loss: 0.3062232434749603
Validation loss: 1.758570965900216

Epoch: 5| Step: 7
Training loss: 0.37739449739456177
Validation loss: 1.715607012471845

Epoch: 5| Step: 8
Training loss: 0.1952981799840927
Validation loss: 1.7228548475491103

Epoch: 5| Step: 9
Training loss: 0.27242445945739746
Validation loss: 1.70812895477459

Epoch: 5| Step: 10
Training loss: 0.3278345465660095
Validation loss: 1.7226515072648243

Epoch: 312| Step: 0
Training loss: 0.15732607245445251
Validation loss: 1.724794924900096

Epoch: 5| Step: 1
Training loss: 0.2954222559928894
Validation loss: 1.722620415431197

Epoch: 5| Step: 2
Training loss: 0.4446273744106293
Validation loss: 1.7429411270285164

Epoch: 5| Step: 3
Training loss: 0.2020348608493805
Validation loss: 1.7363225913816882

Epoch: 5| Step: 4
Training loss: 0.3280639946460724
Validation loss: 1.7962764206752981

Epoch: 5| Step: 5
Training loss: 0.34927019476890564
Validation loss: 1.8040215161538893

Epoch: 5| Step: 6
Training loss: 0.2501220703125
Validation loss: 1.8301171000285814

Epoch: 5| Step: 7
Training loss: 0.39749929308891296
Validation loss: 1.8312921934230353

Epoch: 5| Step: 8
Training loss: 0.284440279006958
Validation loss: 1.8322747240784347

Epoch: 5| Step: 9
Training loss: 0.29405003786087036
Validation loss: 1.777564553804295

Epoch: 5| Step: 10
Training loss: 0.2698152959346771
Validation loss: 1.7630110479170276

Epoch: 313| Step: 0
Training loss: 0.20519372820854187
Validation loss: 1.728279681615932

Epoch: 5| Step: 1
Training loss: 0.20290152728557587
Validation loss: 1.7448555167003343

Epoch: 5| Step: 2
Training loss: 0.3491087853908539
Validation loss: 1.7172266526888775

Epoch: 5| Step: 3
Training loss: 0.266221284866333
Validation loss: 1.7043371764562463

Epoch: 5| Step: 4
Training loss: 0.4060364365577698
Validation loss: 1.6858319890114568

Epoch: 5| Step: 5
Training loss: 0.37832963466644287
Validation loss: 1.6970037132181146

Epoch: 5| Step: 6
Training loss: 0.32423457503318787
Validation loss: 1.7193610360545497

Epoch: 5| Step: 7
Training loss: 0.26208898425102234
Validation loss: 1.712418133212674

Epoch: 5| Step: 8
Training loss: 0.44891732931137085
Validation loss: 1.7242024867765364

Epoch: 5| Step: 9
Training loss: 0.3467388451099396
Validation loss: 1.7753649783390824

Epoch: 5| Step: 10
Training loss: 0.13603471219539642
Validation loss: 1.7951483803410684

Epoch: 314| Step: 0
Training loss: 0.24386639893054962
Validation loss: 1.8162744416985461

Epoch: 5| Step: 1
Training loss: 0.15323910117149353
Validation loss: 1.8116234489666518

Epoch: 5| Step: 2
Training loss: 0.27640873193740845
Validation loss: 1.7951257126305693

Epoch: 5| Step: 3
Training loss: 0.39422914385795593
Validation loss: 1.786922203597202

Epoch: 5| Step: 4
Training loss: 0.38827258348464966
Validation loss: 1.7711209661217147

Epoch: 5| Step: 5
Training loss: 0.2446492612361908
Validation loss: 1.761755386988322

Epoch: 5| Step: 6
Training loss: 0.39657658338546753
Validation loss: 1.7484331412981915

Epoch: 5| Step: 7
Training loss: 0.39035946130752563
Validation loss: 1.7562405819533973

Epoch: 5| Step: 8
Training loss: 0.3016890585422516
Validation loss: 1.7412018211939002

Epoch: 5| Step: 9
Training loss: 0.1768731027841568
Validation loss: 1.7161937067585606

Epoch: 5| Step: 10
Training loss: 0.2994295656681061
Validation loss: 1.7053133928647606

Epoch: 315| Step: 0
Training loss: 0.20124264061450958
Validation loss: 1.748634184560468

Epoch: 5| Step: 1
Training loss: 0.24822945892810822
Validation loss: 1.734901599986579

Epoch: 5| Step: 2
Training loss: 0.3118303418159485
Validation loss: 1.7254939284375919

Epoch: 5| Step: 3
Training loss: 0.3256158232688904
Validation loss: 1.7172533786425026

Epoch: 5| Step: 4
Training loss: 0.27446311712265015
Validation loss: 1.6921924327009468

Epoch: 5| Step: 5
Training loss: 0.2981942296028137
Validation loss: 1.701933394196213

Epoch: 5| Step: 6
Training loss: 0.32725587487220764
Validation loss: 1.690683259758898

Epoch: 5| Step: 7
Training loss: 0.35075536370277405
Validation loss: 1.6923224451721355

Epoch: 5| Step: 8
Training loss: 0.16532059013843536
Validation loss: 1.7008606618450535

Epoch: 5| Step: 9
Training loss: 0.34990862011909485
Validation loss: 1.736620988897098

Epoch: 5| Step: 10
Training loss: 0.32399800419807434
Validation loss: 1.7410513611250027

Epoch: 316| Step: 0
Training loss: 0.20815542340278625
Validation loss: 1.731147909677157

Epoch: 5| Step: 1
Training loss: 0.2088804990053177
Validation loss: 1.7404520921809699

Epoch: 5| Step: 2
Training loss: 0.17754848301410675
Validation loss: 1.7372419423954462

Epoch: 5| Step: 3
Training loss: 0.4136998653411865
Validation loss: 1.7548881397452405

Epoch: 5| Step: 4
Training loss: 0.28967276215553284
Validation loss: 1.7290021450288835

Epoch: 5| Step: 5
Training loss: 0.27602165937423706
Validation loss: 1.7296946382009855

Epoch: 5| Step: 6
Training loss: 0.17588075995445251
Validation loss: 1.725353511430884

Epoch: 5| Step: 7
Training loss: 0.26992544531822205
Validation loss: 1.7182595076099518

Epoch: 5| Step: 8
Training loss: 0.22063612937927246
Validation loss: 1.7164726770052345

Epoch: 5| Step: 9
Training loss: 0.2858126163482666
Validation loss: 1.7045436315639044

Epoch: 5| Step: 10
Training loss: 0.2809690237045288
Validation loss: 1.7668350704254643

Epoch: 317| Step: 0
Training loss: 0.29890212416648865
Validation loss: 1.7661707939640168

Epoch: 5| Step: 1
Training loss: 0.33485227823257446
Validation loss: 1.7413864058832969

Epoch: 5| Step: 2
Training loss: 0.3673485517501831
Validation loss: 1.7055470969087334

Epoch: 5| Step: 3
Training loss: 0.2073807269334793
Validation loss: 1.6763037097069524

Epoch: 5| Step: 4
Training loss: 0.17073515057563782
Validation loss: 1.6911969864240257

Epoch: 5| Step: 5
Training loss: 0.29517263174057007
Validation loss: 1.6628872732962332

Epoch: 5| Step: 6
Training loss: 0.3064810037612915
Validation loss: 1.703374763970734

Epoch: 5| Step: 7
Training loss: 0.27815496921539307
Validation loss: 1.679560520315683

Epoch: 5| Step: 8
Training loss: 0.1221824511885643
Validation loss: 1.6908985453267251

Epoch: 5| Step: 9
Training loss: 0.43308597803115845
Validation loss: 1.7236356837775118

Epoch: 5| Step: 10
Training loss: 0.24015410244464874
Validation loss: 1.7764238157579977

Epoch: 318| Step: 0
Training loss: 0.20524299144744873
Validation loss: 1.8108614913878902

Epoch: 5| Step: 1
Training loss: 0.2954137921333313
Validation loss: 1.8266918172118485

Epoch: 5| Step: 2
Training loss: 0.49111175537109375
Validation loss: 1.7735179880613923

Epoch: 5| Step: 3
Training loss: 0.1875494420528412
Validation loss: 1.7577650213754306

Epoch: 5| Step: 4
Training loss: 0.293241947889328
Validation loss: 1.7195203124835927

Epoch: 5| Step: 5
Training loss: 0.2959606647491455
Validation loss: 1.693775342356774

Epoch: 5| Step: 6
Training loss: 0.37564557790756226
Validation loss: 1.6592963908308296

Epoch: 5| Step: 7
Training loss: 0.3654429018497467
Validation loss: 1.6669868038546654

Epoch: 5| Step: 8
Training loss: 0.28558024764060974
Validation loss: 1.6626854147962344

Epoch: 5| Step: 9
Training loss: 0.21434804797172546
Validation loss: 1.714542160751999

Epoch: 5| Step: 10
Training loss: 0.23529259860515594
Validation loss: 1.668396653667573

Epoch: 319| Step: 0
Training loss: 0.20936599373817444
Validation loss: 1.674319226254699

Epoch: 5| Step: 1
Training loss: 0.22442980110645294
Validation loss: 1.7241846079467444

Epoch: 5| Step: 2
Training loss: 0.26104310154914856
Validation loss: 1.742714435823502

Epoch: 5| Step: 3
Training loss: 0.3519428074359894
Validation loss: 1.732359173477337

Epoch: 5| Step: 4
Training loss: 0.36291012167930603
Validation loss: 1.7554437152801021

Epoch: 5| Step: 5
Training loss: 0.2200569361448288
Validation loss: 1.7288963845981065

Epoch: 5| Step: 6
Training loss: 0.3321722447872162
Validation loss: 1.7228367162007157

Epoch: 5| Step: 7
Training loss: 0.2262253314256668
Validation loss: 1.7364905752161497

Epoch: 5| Step: 8
Training loss: 0.2335737645626068
Validation loss: 1.7050296811647312

Epoch: 5| Step: 9
Training loss: 0.35535991191864014
Validation loss: 1.6739617791227115

Epoch: 5| Step: 10
Training loss: 0.1909037083387375
Validation loss: 1.643235022021878

Epoch: 320| Step: 0
Training loss: 0.24151349067687988
Validation loss: 1.6345254144360941

Epoch: 5| Step: 1
Training loss: 0.2614375650882721
Validation loss: 1.607806788336846

Epoch: 5| Step: 2
Training loss: 0.15309737622737885
Validation loss: 1.6497663028778569

Epoch: 5| Step: 3
Training loss: 0.262123703956604
Validation loss: 1.658500268895139

Epoch: 5| Step: 4
Training loss: 0.3697921633720398
Validation loss: 1.692267774253763

Epoch: 5| Step: 5
Training loss: 0.3343562185764313
Validation loss: 1.7158557445772233

Epoch: 5| Step: 6
Training loss: 0.30966025590896606
Validation loss: 1.7564740039969002

Epoch: 5| Step: 7
Training loss: 0.18626545369625092
Validation loss: 1.7488200318428777

Epoch: 5| Step: 8
Training loss: 0.3089175820350647
Validation loss: 1.7298598686854045

Epoch: 5| Step: 9
Training loss: 0.26461607217788696
Validation loss: 1.6904703955496512

Epoch: 5| Step: 10
Training loss: 0.3261360228061676
Validation loss: 1.6964074885973366

Epoch: 321| Step: 0
Training loss: 0.2954634726047516
Validation loss: 1.655160939821633

Epoch: 5| Step: 1
Training loss: 0.21342524886131287
Validation loss: 1.6891303882803967

Epoch: 5| Step: 2
Training loss: 0.4546473026275635
Validation loss: 1.6686227116533505

Epoch: 5| Step: 3
Training loss: 0.4636879861354828
Validation loss: 1.6581912886711858

Epoch: 5| Step: 4
Training loss: 0.39436274766921997
Validation loss: 1.6875417411968272

Epoch: 5| Step: 5
Training loss: 0.2390386164188385
Validation loss: 1.681428805474312

Epoch: 5| Step: 6
Training loss: 0.14429250359535217
Validation loss: 1.7091449191493373

Epoch: 5| Step: 7
Training loss: 0.2462095022201538
Validation loss: 1.76623490805267

Epoch: 5| Step: 8
Training loss: 0.30091577768325806
Validation loss: 1.8245061866698726

Epoch: 5| Step: 9
Training loss: 0.41505783796310425
Validation loss: 1.8025426377532303

Epoch: 5| Step: 10
Training loss: 0.27511775493621826
Validation loss: 1.807893055741505

Epoch: 322| Step: 0
Training loss: 0.26047462224960327
Validation loss: 1.7550620955805625

Epoch: 5| Step: 1
Training loss: 0.25651484727859497
Validation loss: 1.7378653941615936

Epoch: 5| Step: 2
Training loss: 0.24493777751922607
Validation loss: 1.7076855705630394

Epoch: 5| Step: 3
Training loss: 0.21799464523792267
Validation loss: 1.697671437776217

Epoch: 5| Step: 4
Training loss: 0.21547551453113556
Validation loss: 1.682371577908916

Epoch: 5| Step: 5
Training loss: 0.3421329855918884
Validation loss: 1.697200781555586

Epoch: 5| Step: 6
Training loss: 0.2696644961833954
Validation loss: 1.6923450385370562

Epoch: 5| Step: 7
Training loss: 0.27849283814430237
Validation loss: 1.6875709846455564

Epoch: 5| Step: 8
Training loss: 0.4695955812931061
Validation loss: 1.6953389003712644

Epoch: 5| Step: 9
Training loss: 0.2875369191169739
Validation loss: 1.7154712856456797

Epoch: 5| Step: 10
Training loss: 0.3404918909072876
Validation loss: 1.7225103262932069

Epoch: 323| Step: 0
Training loss: 0.2978714108467102
Validation loss: 1.7071983211783952

Epoch: 5| Step: 1
Training loss: 0.32680439949035645
Validation loss: 1.7061236519967355

Epoch: 5| Step: 2
Training loss: 0.16639500856399536
Validation loss: 1.6451684351890319

Epoch: 5| Step: 3
Training loss: 0.33767586946487427
Validation loss: 1.6448645899372716

Epoch: 5| Step: 4
Training loss: 0.29615432024002075
Validation loss: 1.6236327489217122

Epoch: 5| Step: 5
Training loss: 0.26458126306533813
Validation loss: 1.6326943700031569

Epoch: 5| Step: 6
Training loss: 0.3338819444179535
Validation loss: 1.6383162403619418

Epoch: 5| Step: 7
Training loss: 0.1463242620229721
Validation loss: 1.6509108902305685

Epoch: 5| Step: 8
Training loss: 0.3422262966632843
Validation loss: 1.6825748066748343

Epoch: 5| Step: 9
Training loss: 0.20528993010520935
Validation loss: 1.7074590242037209

Epoch: 5| Step: 10
Training loss: 0.16947536170482635
Validation loss: 1.7377043501023324

Epoch: 324| Step: 0
Training loss: 0.2919601500034332
Validation loss: 1.7853833090874456

Epoch: 5| Step: 1
Training loss: 0.420480340719223
Validation loss: 1.7763605143434258

Epoch: 5| Step: 2
Training loss: 0.2995670437812805
Validation loss: 1.81798642681491

Epoch: 5| Step: 3
Training loss: 0.32047322392463684
Validation loss: 1.7760307737576064

Epoch: 5| Step: 4
Training loss: 0.46438997983932495
Validation loss: 1.72947108873757

Epoch: 5| Step: 5
Training loss: 0.1927366405725479
Validation loss: 1.6959904432296753

Epoch: 5| Step: 6
Training loss: 0.22390392422676086
Validation loss: 1.6440026183282175

Epoch: 5| Step: 7
Training loss: 0.30484431982040405
Validation loss: 1.6408138544328752

Epoch: 5| Step: 8
Training loss: 0.30219024419784546
Validation loss: 1.6131342764823668

Epoch: 5| Step: 9
Training loss: 0.28939324617385864
Validation loss: 1.6466388702392578

Epoch: 5| Step: 10
Training loss: 0.3021772801876068
Validation loss: 1.6440278983885241

Epoch: 325| Step: 0
Training loss: 0.2298898696899414
Validation loss: 1.6660858514488384

Epoch: 5| Step: 1
Training loss: 0.5535598993301392
Validation loss: 1.6636349321693502

Epoch: 5| Step: 2
Training loss: 0.24238669872283936
Validation loss: 1.6983605187426332

Epoch: 5| Step: 3
Training loss: 0.22140204906463623
Validation loss: 1.7207947238799064

Epoch: 5| Step: 4
Training loss: 0.3154689073562622
Validation loss: 1.735342232129907

Epoch: 5| Step: 5
Training loss: 0.37453493475914
Validation loss: 1.7407423475737214

Epoch: 5| Step: 6
Training loss: 0.2840837836265564
Validation loss: 1.7290186869200839

Epoch: 5| Step: 7
Training loss: 0.21882763504981995
Validation loss: 1.708612608653243

Epoch: 5| Step: 8
Training loss: 0.15860256552696228
Validation loss: 1.7187076621158148

Epoch: 5| Step: 9
Training loss: 0.11192920058965683
Validation loss: 1.688515055564142

Epoch: 5| Step: 10
Training loss: 0.30885300040245056
Validation loss: 1.678317989072492

Epoch: 326| Step: 0
Training loss: 0.24989700317382812
Validation loss: 1.6877894696368967

Epoch: 5| Step: 1
Training loss: 0.3630477786064148
Validation loss: 1.689453399309548

Epoch: 5| Step: 2
Training loss: 0.3440457284450531
Validation loss: 1.688722099027326

Epoch: 5| Step: 3
Training loss: 0.35513532161712646
Validation loss: 1.7002653614167245

Epoch: 5| Step: 4
Training loss: 0.29647162556648254
Validation loss: 1.7088316948183122

Epoch: 5| Step: 5
Training loss: 0.3590978980064392
Validation loss: 1.7424567925032748

Epoch: 5| Step: 6
Training loss: 0.23833143711090088
Validation loss: 1.7259643180395967

Epoch: 5| Step: 7
Training loss: 0.28650110960006714
Validation loss: 1.7453198074012675

Epoch: 5| Step: 8
Training loss: 0.3055897355079651
Validation loss: 1.7511716478614396

Epoch: 5| Step: 9
Training loss: 0.23560862243175507
Validation loss: 1.725656911890994

Epoch: 5| Step: 10
Training loss: 0.2672841250896454
Validation loss: 1.7407313123826058

Epoch: 327| Step: 0
Training loss: 0.16787485778331757
Validation loss: 1.7249529130997197

Epoch: 5| Step: 1
Training loss: 0.3077167868614197
Validation loss: 1.723415433719594

Epoch: 5| Step: 2
Training loss: 0.4498198628425598
Validation loss: 1.6833627531605382

Epoch: 5| Step: 3
Training loss: 0.2557757794857025
Validation loss: 1.6874082729380617

Epoch: 5| Step: 4
Training loss: 0.3303411602973938
Validation loss: 1.6785183773245862

Epoch: 5| Step: 5
Training loss: 0.15489701926708221
Validation loss: 1.661852813536121

Epoch: 5| Step: 6
Training loss: 0.25892382860183716
Validation loss: 1.618645506520425

Epoch: 5| Step: 7
Training loss: 0.38905206322669983
Validation loss: 1.6444260792065692

Epoch: 5| Step: 8
Training loss: 0.20827630162239075
Validation loss: 1.6731920306400587

Epoch: 5| Step: 9
Training loss: 0.2780023217201233
Validation loss: 1.7153933842976887

Epoch: 5| Step: 10
Training loss: 0.3138691782951355
Validation loss: 1.692857951246282

Epoch: 328| Step: 0
Training loss: 0.2991669774055481
Validation loss: 1.7281561410555275

Epoch: 5| Step: 1
Training loss: 0.24688443541526794
Validation loss: 1.740151746298677

Epoch: 5| Step: 2
Training loss: 0.3308349847793579
Validation loss: 1.6989192001281246

Epoch: 5| Step: 3
Training loss: 0.2415819615125656
Validation loss: 1.7520095635485906

Epoch: 5| Step: 4
Training loss: 0.2193920612335205
Validation loss: 1.7248666876105851

Epoch: 5| Step: 5
Training loss: 0.2116648256778717
Validation loss: 1.689265792087842

Epoch: 5| Step: 6
Training loss: 0.21523074805736542
Validation loss: 1.6965125427451184

Epoch: 5| Step: 7
Training loss: 0.21107855439186096
Validation loss: 1.6648154656092327

Epoch: 5| Step: 8
Training loss: 0.3550207018852234
Validation loss: 1.6645558713584818

Epoch: 5| Step: 9
Training loss: 0.24819383025169373
Validation loss: 1.6599561232392506

Epoch: 5| Step: 10
Training loss: 0.2905758321285248
Validation loss: 1.6866420674067673

Epoch: 329| Step: 0
Training loss: 0.20984521508216858
Validation loss: 1.6898080559187039

Epoch: 5| Step: 1
Training loss: 0.4151793420314789
Validation loss: 1.6900359815166843

Epoch: 5| Step: 2
Training loss: 0.24385540187358856
Validation loss: 1.6906764712384952

Epoch: 5| Step: 3
Training loss: 0.194930762052536
Validation loss: 1.703174074490865

Epoch: 5| Step: 4
Training loss: 0.18891029059886932
Validation loss: 1.6976149082183838

Epoch: 5| Step: 5
Training loss: 0.18164584040641785
Validation loss: 1.688861959724016

Epoch: 5| Step: 6
Training loss: 0.2791287302970886
Validation loss: 1.6725982953143377

Epoch: 5| Step: 7
Training loss: 0.17806926369667053
Validation loss: 1.6574325587159844

Epoch: 5| Step: 8
Training loss: 0.14685392379760742
Validation loss: 1.6631867539498113

Epoch: 5| Step: 9
Training loss: 0.3083752989768982
Validation loss: 1.6573585874290877

Epoch: 5| Step: 10
Training loss: 0.32101312279701233
Validation loss: 1.6682651068574639

Epoch: 330| Step: 0
Training loss: 0.2786998450756073
Validation loss: 1.6906267616056627

Epoch: 5| Step: 1
Training loss: 0.24904374778270721
Validation loss: 1.7034705377394153

Epoch: 5| Step: 2
Training loss: 0.30139994621276855
Validation loss: 1.7096911104776527

Epoch: 5| Step: 3
Training loss: 0.13155201077461243
Validation loss: 1.721400300661723

Epoch: 5| Step: 4
Training loss: 0.2395775020122528
Validation loss: 1.7194189768965527

Epoch: 5| Step: 5
Training loss: 0.1986027956008911
Validation loss: 1.6800205887004893

Epoch: 5| Step: 6
Training loss: 0.3150853216648102
Validation loss: 1.6927941614581692

Epoch: 5| Step: 7
Training loss: 0.19669130444526672
Validation loss: 1.6895601416146884

Epoch: 5| Step: 8
Training loss: 0.31282395124435425
Validation loss: 1.6727482682915145

Epoch: 5| Step: 9
Training loss: 0.24603846669197083
Validation loss: 1.6401266923514746

Epoch: 5| Step: 10
Training loss: 0.13572435081005096
Validation loss: 1.6557704735827703

Epoch: 331| Step: 0
Training loss: 0.3587948679924011
Validation loss: 1.6181757924377278

Epoch: 5| Step: 1
Training loss: 0.17113319039344788
Validation loss: 1.6785593366110196

Epoch: 5| Step: 2
Training loss: 0.20314133167266846
Validation loss: 1.6500298758988738

Epoch: 5| Step: 3
Training loss: 0.2685667872428894
Validation loss: 1.6969297265493741

Epoch: 5| Step: 4
Training loss: 0.20093145966529846
Validation loss: 1.7150166931972708

Epoch: 5| Step: 5
Training loss: 0.2793535590171814
Validation loss: 1.7508416009205643

Epoch: 5| Step: 6
Training loss: 0.37688660621643066
Validation loss: 1.7440575066433157

Epoch: 5| Step: 7
Training loss: 0.2410397082567215
Validation loss: 1.7183353477908718

Epoch: 5| Step: 8
Training loss: 0.24509617686271667
Validation loss: 1.7001947933627712

Epoch: 5| Step: 9
Training loss: 0.3168817162513733
Validation loss: 1.6746479695843113

Epoch: 5| Step: 10
Training loss: 0.1645631492137909
Validation loss: 1.666276716416882

Epoch: 332| Step: 0
Training loss: 0.22697973251342773
Validation loss: 1.6796729718485186

Epoch: 5| Step: 1
Training loss: 0.190586119890213
Validation loss: 1.6841274717802643

Epoch: 5| Step: 2
Training loss: 0.23733587563037872
Validation loss: 1.708533517775997

Epoch: 5| Step: 3
Training loss: 0.2101099044084549
Validation loss: 1.7444927525776688

Epoch: 5| Step: 4
Training loss: 0.5014106035232544
Validation loss: 1.770730072452176

Epoch: 5| Step: 5
Training loss: 0.2765669822692871
Validation loss: 1.8067733921030515

Epoch: 5| Step: 6
Training loss: 0.21363845467567444
Validation loss: 1.792452666067308

Epoch: 5| Step: 7
Training loss: 0.27514001727104187
Validation loss: 1.7714055045958488

Epoch: 5| Step: 8
Training loss: 0.28413766622543335
Validation loss: 1.7590508255907285

Epoch: 5| Step: 9
Training loss: 0.33314090967178345
Validation loss: 1.7123693702041463

Epoch: 5| Step: 10
Training loss: 0.21836026012897491
Validation loss: 1.7048975165172289

Epoch: 333| Step: 0
Training loss: 0.33810558915138245
Validation loss: 1.6786650714053903

Epoch: 5| Step: 1
Training loss: 0.34239310026168823
Validation loss: 1.6680305478393391

Epoch: 5| Step: 2
Training loss: 0.3129296898841858
Validation loss: 1.6876207449102913

Epoch: 5| Step: 3
Training loss: 0.2043033093214035
Validation loss: 1.6909683571066907

Epoch: 5| Step: 4
Training loss: 0.18953664600849152
Validation loss: 1.6985140282620665

Epoch: 5| Step: 5
Training loss: 0.2809808552265167
Validation loss: 1.7177210789854809

Epoch: 5| Step: 6
Training loss: 0.2132652997970581
Validation loss: 1.720443341039842

Epoch: 5| Step: 7
Training loss: 0.3773495554924011
Validation loss: 1.7077015420441986

Epoch: 5| Step: 8
Training loss: 0.2146047055721283
Validation loss: 1.7171261156758955

Epoch: 5| Step: 9
Training loss: 0.21740250289440155
Validation loss: 1.7327913443247478

Epoch: 5| Step: 10
Training loss: 0.217337965965271
Validation loss: 1.75376094284878

Epoch: 334| Step: 0
Training loss: 0.28858286142349243
Validation loss: 1.7325154555741178

Epoch: 5| Step: 1
Training loss: 0.22855643928050995
Validation loss: 1.7382342930763

Epoch: 5| Step: 2
Training loss: 0.1827457845211029
Validation loss: 1.755570964146686

Epoch: 5| Step: 3
Training loss: 0.20074984431266785
Validation loss: 1.7339012751015284

Epoch: 5| Step: 4
Training loss: 0.1410897672176361
Validation loss: 1.7514127249358802

Epoch: 5| Step: 5
Training loss: 0.21309764683246613
Validation loss: 1.7551669049006637

Epoch: 5| Step: 6
Training loss: 0.23691196739673615
Validation loss: 1.7445710576990598

Epoch: 5| Step: 7
Training loss: 0.2164352387189865
Validation loss: 1.7535839772993518

Epoch: 5| Step: 8
Training loss: 0.41865915060043335
Validation loss: 1.7544399256347327

Epoch: 5| Step: 9
Training loss: 0.31287556886672974
Validation loss: 1.7534776951677056

Epoch: 5| Step: 10
Training loss: 0.3353913128376007
Validation loss: 1.7187517445574525

Epoch: 335| Step: 0
Training loss: 0.2598194479942322
Validation loss: 1.730035222986693

Epoch: 5| Step: 1
Training loss: 0.3680045008659363
Validation loss: 1.703044718311679

Epoch: 5| Step: 2
Training loss: 0.09885100275278091
Validation loss: 1.679774453563075

Epoch: 5| Step: 3
Training loss: 0.2107674777507782
Validation loss: 1.6830966690535187

Epoch: 5| Step: 4
Training loss: 0.1651429831981659
Validation loss: 1.7068397280990437

Epoch: 5| Step: 5
Training loss: 0.20686551928520203
Validation loss: 1.7313448434234948

Epoch: 5| Step: 6
Training loss: 0.1413852423429489
Validation loss: 1.7367987568660448

Epoch: 5| Step: 7
Training loss: 0.195943683385849
Validation loss: 1.7815116861815095

Epoch: 5| Step: 8
Training loss: 0.35720235109329224
Validation loss: 1.7895459513510428

Epoch: 5| Step: 9
Training loss: 0.42441311478614807
Validation loss: 1.7644890175070813

Epoch: 5| Step: 10
Training loss: 0.26628565788269043
Validation loss: 1.730089141476539

Epoch: 336| Step: 0
Training loss: 0.16699519753456116
Validation loss: 1.6671607814809328

Epoch: 5| Step: 1
Training loss: 0.2349427193403244
Validation loss: 1.660004823438583

Epoch: 5| Step: 2
Training loss: 0.27912411093711853
Validation loss: 1.6397792882816766

Epoch: 5| Step: 3
Training loss: 0.28881415724754333
Validation loss: 1.6477041167597617

Epoch: 5| Step: 4
Training loss: 0.2687614858150482
Validation loss: 1.6096619072780813

Epoch: 5| Step: 5
Training loss: 0.20384304225444794
Validation loss: 1.6232021060041202

Epoch: 5| Step: 6
Training loss: 0.3120266795158386
Validation loss: 1.629720785284555

Epoch: 5| Step: 7
Training loss: 0.22406482696533203
Validation loss: 1.646302576987974

Epoch: 5| Step: 8
Training loss: 0.15247149765491486
Validation loss: 1.6762270876156387

Epoch: 5| Step: 9
Training loss: 0.24569693207740784
Validation loss: 1.700957896888897

Epoch: 5| Step: 10
Training loss: 0.204229474067688
Validation loss: 1.7315383931641937

Epoch: 337| Step: 0
Training loss: 0.19412264227867126
Validation loss: 1.7360337126639582

Epoch: 5| Step: 1
Training loss: 0.14148035645484924
Validation loss: 1.7590050261507753

Epoch: 5| Step: 2
Training loss: 0.3268675208091736
Validation loss: 1.7591203258883568

Epoch: 5| Step: 3
Training loss: 0.2216159552335739
Validation loss: 1.7437397562047487

Epoch: 5| Step: 4
Training loss: 0.31907910108566284
Validation loss: 1.7079755554917038

Epoch: 5| Step: 5
Training loss: 0.23036901652812958
Validation loss: 1.6998877871421076

Epoch: 5| Step: 6
Training loss: 0.239634707570076
Validation loss: 1.680368185043335

Epoch: 5| Step: 7
Training loss: 0.2144249677658081
Validation loss: 1.6861771793775662

Epoch: 5| Step: 8
Training loss: 0.3030117452144623
Validation loss: 1.7128975493933565

Epoch: 5| Step: 9
Training loss: 0.24688775837421417
Validation loss: 1.6872168407645276

Epoch: 5| Step: 10
Training loss: 0.23848673701286316
Validation loss: 1.7013714057143017

Epoch: 338| Step: 0
Training loss: 0.19571612775325775
Validation loss: 1.68123830902961

Epoch: 5| Step: 1
Training loss: 0.30250415205955505
Validation loss: 1.6946646705750497

Epoch: 5| Step: 2
Training loss: 0.32685986161231995
Validation loss: 1.7026592352057015

Epoch: 5| Step: 3
Training loss: 0.21816687285900116
Validation loss: 1.7302367853861984

Epoch: 5| Step: 4
Training loss: 0.22170579433441162
Validation loss: 1.7286340369973132

Epoch: 5| Step: 5
Training loss: 0.2875124216079712
Validation loss: 1.7331002014939503

Epoch: 5| Step: 6
Training loss: 0.2575444281101227
Validation loss: 1.7405774080625145

Epoch: 5| Step: 7
Training loss: 0.2943989038467407
Validation loss: 1.7393648150146648

Epoch: 5| Step: 8
Training loss: 0.12001460790634155
Validation loss: 1.7433031579499603

Epoch: 5| Step: 9
Training loss: 0.18238338828086853
Validation loss: 1.7660840172921457

Epoch: 5| Step: 10
Training loss: 0.12861761450767517
Validation loss: 1.7442287257922593

Epoch: 339| Step: 0
Training loss: 0.1476587951183319
Validation loss: 1.7738954649176648

Epoch: 5| Step: 1
Training loss: 0.27701956033706665
Validation loss: 1.7281705115431099

Epoch: 5| Step: 2
Training loss: 0.18983440101146698
Validation loss: 1.7399723286269813

Epoch: 5| Step: 3
Training loss: 0.18806472420692444
Validation loss: 1.7110934718962638

Epoch: 5| Step: 4
Training loss: 0.21755222976207733
Validation loss: 1.7060802969881284

Epoch: 5| Step: 5
Training loss: 0.15313181281089783
Validation loss: 1.7051353134134764

Epoch: 5| Step: 6
Training loss: 0.20755144953727722
Validation loss: 1.703628541320883

Epoch: 5| Step: 7
Training loss: 0.3526425361633301
Validation loss: 1.700458562502297

Epoch: 5| Step: 8
Training loss: 0.20641286671161652
Validation loss: 1.6995603666510632

Epoch: 5| Step: 9
Training loss: 0.3171974718570709
Validation loss: 1.7159282994526688

Epoch: 5| Step: 10
Training loss: 0.3108518719673157
Validation loss: 1.7156515441915041

Epoch: 340| Step: 0
Training loss: 0.23094472289085388
Validation loss: 1.741799872408631

Epoch: 5| Step: 1
Training loss: 0.2748754918575287
Validation loss: 1.723219907411965

Epoch: 5| Step: 2
Training loss: 0.22135838866233826
Validation loss: 1.7197728567225958

Epoch: 5| Step: 3
Training loss: 0.2253660410642624
Validation loss: 1.6909107931198613

Epoch: 5| Step: 4
Training loss: 0.19540752470493317
Validation loss: 1.6724116930397608

Epoch: 5| Step: 5
Training loss: 0.21221891045570374
Validation loss: 1.6502137132870254

Epoch: 5| Step: 6
Training loss: 0.19631646573543549
Validation loss: 1.6599232253207956

Epoch: 5| Step: 7
Training loss: 0.3017804026603699
Validation loss: 1.6404173143448368

Epoch: 5| Step: 8
Training loss: 0.29384762048721313
Validation loss: 1.658950686454773

Epoch: 5| Step: 9
Training loss: 0.2397232949733734
Validation loss: 1.6746027623453448

Epoch: 5| Step: 10
Training loss: 0.15069103240966797
Validation loss: 1.7012532987902242

Epoch: 341| Step: 0
Training loss: 0.22205571830272675
Validation loss: 1.7285455785771853

Epoch: 5| Step: 1
Training loss: 0.3196417987346649
Validation loss: 1.7115016086127168

Epoch: 5| Step: 2
Training loss: 0.2429419457912445
Validation loss: 1.7512133916219075

Epoch: 5| Step: 3
Training loss: 0.24320411682128906
Validation loss: 1.7554930922805623

Epoch: 5| Step: 4
Training loss: 0.33855852484703064
Validation loss: 1.7697416838779245

Epoch: 5| Step: 5
Training loss: 0.11548218876123428
Validation loss: 1.7703330029723465

Epoch: 5| Step: 6
Training loss: 0.24840006232261658
Validation loss: 1.7529654759232716

Epoch: 5| Step: 7
Training loss: 0.12814685702323914
Validation loss: 1.747887312725026

Epoch: 5| Step: 8
Training loss: 0.2176387757062912
Validation loss: 1.7409114606918827

Epoch: 5| Step: 9
Training loss: 0.2366749793291092
Validation loss: 1.7526005544970114

Epoch: 5| Step: 10
Training loss: 0.16164731979370117
Validation loss: 1.7726141278461744

Epoch: 342| Step: 0
Training loss: 0.29655522108078003
Validation loss: 1.775749360361407

Epoch: 5| Step: 1
Training loss: 0.27528345584869385
Validation loss: 1.7763007738256966

Epoch: 5| Step: 2
Training loss: 0.15040931105613708
Validation loss: 1.7668251632362284

Epoch: 5| Step: 3
Training loss: 0.11895714700222015
Validation loss: 1.771285185249903

Epoch: 5| Step: 4
Training loss: 0.12819643318653107
Validation loss: 1.774029290804299

Epoch: 5| Step: 5
Training loss: 0.30655303597450256
Validation loss: 1.7559253746463406

Epoch: 5| Step: 6
Training loss: 0.2580753266811371
Validation loss: 1.7979706038710892

Epoch: 5| Step: 7
Training loss: 0.2140323668718338
Validation loss: 1.792423245727375

Epoch: 5| Step: 8
Training loss: 0.18750043213367462
Validation loss: 1.7587714554161153

Epoch: 5| Step: 9
Training loss: 0.2830323278903961
Validation loss: 1.7763192243473505

Epoch: 5| Step: 10
Training loss: 0.1940724402666092
Validation loss: 1.7616810747372207

Epoch: 343| Step: 0
Training loss: 0.20894961059093475
Validation loss: 1.7392709178309287

Epoch: 5| Step: 1
Training loss: 0.23404736816883087
Validation loss: 1.7552432693460935

Epoch: 5| Step: 2
Training loss: 0.2272966206073761
Validation loss: 1.7234398652148504

Epoch: 5| Step: 3
Training loss: 0.21738286316394806
Validation loss: 1.7217139761934999

Epoch: 5| Step: 4
Training loss: 0.16065426170825958
Validation loss: 1.7267256539355043

Epoch: 5| Step: 5
Training loss: 0.34958526492118835
Validation loss: 1.729067934456692

Epoch: 5| Step: 6
Training loss: 0.2079848349094391
Validation loss: 1.7320176734719226

Epoch: 5| Step: 7
Training loss: 0.25972601771354675
Validation loss: 1.7232684268746326

Epoch: 5| Step: 8
Training loss: 0.3701285719871521
Validation loss: 1.72055346222334

Epoch: 5| Step: 9
Training loss: 0.183615580201149
Validation loss: 1.717476003913469

Epoch: 5| Step: 10
Training loss: 0.09189294278621674
Validation loss: 1.704505314109146

Epoch: 344| Step: 0
Training loss: 0.23453941941261292
Validation loss: 1.679133847195615

Epoch: 5| Step: 1
Training loss: 0.12057578563690186
Validation loss: 1.6534324858778267

Epoch: 5| Step: 2
Training loss: 0.2568138539791107
Validation loss: 1.6824917319000408

Epoch: 5| Step: 3
Training loss: 0.16423915326595306
Validation loss: 1.697609309227236

Epoch: 5| Step: 4
Training loss: 0.16775307059288025
Validation loss: 1.6715761743566042

Epoch: 5| Step: 5
Training loss: 0.14314135909080505
Validation loss: 1.6979912660455192

Epoch: 5| Step: 6
Training loss: 0.22527220845222473
Validation loss: 1.669299489708357

Epoch: 5| Step: 7
Training loss: 0.14015617966651917
Validation loss: 1.6513535514954598

Epoch: 5| Step: 8
Training loss: 0.29155078530311584
Validation loss: 1.6741271211254982

Epoch: 5| Step: 9
Training loss: 0.35425108671188354
Validation loss: 1.6611000581454205

Epoch: 5| Step: 10
Training loss: 0.20842768251895905
Validation loss: 1.674945581343866

Epoch: 345| Step: 0
Training loss: 0.23914186656475067
Validation loss: 1.6493327399735809

Epoch: 5| Step: 1
Training loss: 0.13874518871307373
Validation loss: 1.6820519637036067

Epoch: 5| Step: 2
Training loss: 0.22702021896839142
Validation loss: 1.6769537066900602

Epoch: 5| Step: 3
Training loss: 0.22901353240013123
Validation loss: 1.7222055107034662

Epoch: 5| Step: 4
Training loss: 0.14554212987422943
Validation loss: 1.7366943128647343

Epoch: 5| Step: 5
Training loss: 0.2752683758735657
Validation loss: 1.7548572094209733

Epoch: 5| Step: 6
Training loss: 0.16892150044441223
Validation loss: 1.7220950024102324

Epoch: 5| Step: 7
Training loss: 0.2972497045993805
Validation loss: 1.7147065900987195

Epoch: 5| Step: 8
Training loss: 0.26078179478645325
Validation loss: 1.6747113991809148

Epoch: 5| Step: 9
Training loss: 0.18674184381961823
Validation loss: 1.636396381162828

Epoch: 5| Step: 10
Training loss: 0.2792168855667114
Validation loss: 1.658472268812118

Epoch: 346| Step: 0
Training loss: 0.28084349632263184
Validation loss: 1.6435900388225433

Epoch: 5| Step: 1
Training loss: 0.1635766178369522
Validation loss: 1.665770262800237

Epoch: 5| Step: 2
Training loss: 0.1994052231311798
Validation loss: 1.6305742661158245

Epoch: 5| Step: 3
Training loss: 0.18357613682746887
Validation loss: 1.646850476982773

Epoch: 5| Step: 4
Training loss: 0.15525007247924805
Validation loss: 1.6591713402860908

Epoch: 5| Step: 5
Training loss: 0.29393142461776733
Validation loss: 1.6740790490181214

Epoch: 5| Step: 6
Training loss: 0.10416903346776962
Validation loss: 1.688342543058498

Epoch: 5| Step: 7
Training loss: 0.1416342556476593
Validation loss: 1.6983451715079687

Epoch: 5| Step: 8
Training loss: 0.1970723420381546
Validation loss: 1.6698638162305277

Epoch: 5| Step: 9
Training loss: 0.2818336486816406
Validation loss: 1.6775748704069404

Epoch: 5| Step: 10
Training loss: 0.17500929534435272
Validation loss: 1.6421706830301592

Epoch: 347| Step: 0
Training loss: 0.14638221263885498
Validation loss: 1.6349775919350245

Epoch: 5| Step: 1
Training loss: 0.17059548199176788
Validation loss: 1.6600208961835472

Epoch: 5| Step: 2
Training loss: 0.3078553378582001
Validation loss: 1.6406247397904754

Epoch: 5| Step: 3
Training loss: 0.15586578845977783
Validation loss: 1.6473672107983661

Epoch: 5| Step: 4
Training loss: 0.2728342115879059
Validation loss: 1.6388292581804338

Epoch: 5| Step: 5
Training loss: 0.24201855063438416
Validation loss: 1.6545137218249741

Epoch: 5| Step: 6
Training loss: 0.1963423192501068
Validation loss: 1.6422953733833887

Epoch: 5| Step: 7
Training loss: 0.16964109241962433
Validation loss: 1.66617000743907

Epoch: 5| Step: 8
Training loss: 0.23323385417461395
Validation loss: 1.6705016339978864

Epoch: 5| Step: 9
Training loss: 0.15919245779514313
Validation loss: 1.6744473403499973

Epoch: 5| Step: 10
Training loss: 0.19518697261810303
Validation loss: 1.6482907085008518

Epoch: 348| Step: 0
Training loss: 0.23990626633167267
Validation loss: 1.6713514456184961

Epoch: 5| Step: 1
Training loss: 0.25014528632164
Validation loss: 1.6989115822699763

Epoch: 5| Step: 2
Training loss: 0.3800719380378723
Validation loss: 1.67722184940051

Epoch: 5| Step: 3
Training loss: 0.1575135737657547
Validation loss: 1.6526975439440819

Epoch: 5| Step: 4
Training loss: 0.1474578082561493
Validation loss: 1.6492227174902474

Epoch: 5| Step: 5
Training loss: 0.14699235558509827
Validation loss: 1.6354136620798418

Epoch: 5| Step: 6
Training loss: 0.1459663212299347
Validation loss: 1.6134454704100085

Epoch: 5| Step: 7
Training loss: 0.17210149765014648
Validation loss: 1.611083439601365

Epoch: 5| Step: 8
Training loss: 0.27745121717453003
Validation loss: 1.6726803497601581

Epoch: 5| Step: 9
Training loss: 0.19027763605117798
Validation loss: 1.6645221992205548

Epoch: 5| Step: 10
Training loss: 0.19614306092262268
Validation loss: 1.677383284414968

Epoch: 349| Step: 0
Training loss: 0.23588359355926514
Validation loss: 1.6795793169288225

Epoch: 5| Step: 1
Training loss: 0.13778825104236603
Validation loss: 1.6841064306997484

Epoch: 5| Step: 2
Training loss: 0.19727595150470734
Validation loss: 1.6477567201019616

Epoch: 5| Step: 3
Training loss: 0.15342703461647034
Validation loss: 1.6539742382623817

Epoch: 5| Step: 4
Training loss: 0.16631245613098145
Validation loss: 1.638884545654379

Epoch: 5| Step: 5
Training loss: 0.20324638485908508
Validation loss: 1.6573515028081915

Epoch: 5| Step: 6
Training loss: 0.17355504631996155
Validation loss: 1.6736171745484876

Epoch: 5| Step: 7
Training loss: 0.3227616548538208
Validation loss: 1.6644960334224086

Epoch: 5| Step: 8
Training loss: 0.2249709665775299
Validation loss: 1.6764657228223738

Epoch: 5| Step: 9
Training loss: 0.27678751945495605
Validation loss: 1.6840006074597758

Epoch: 5| Step: 10
Training loss: 0.1333935707807541
Validation loss: 1.701354604895397

Epoch: 350| Step: 0
Training loss: 0.24138259887695312
Validation loss: 1.716709570218158

Epoch: 5| Step: 1
Training loss: 0.28835776448249817
Validation loss: 1.7228751426102014

Epoch: 5| Step: 2
Training loss: 0.11874552071094513
Validation loss: 1.717372840450656

Epoch: 5| Step: 3
Training loss: 0.19768820703029633
Validation loss: 1.703367248658211

Epoch: 5| Step: 4
Training loss: 0.12391761690378189
Validation loss: 1.7146930592034453

Epoch: 5| Step: 5
Training loss: 0.12444911897182465
Validation loss: 1.6996613382011332

Epoch: 5| Step: 6
Training loss: 0.26047372817993164
Validation loss: 1.7095599507772794

Epoch: 5| Step: 7
Training loss: 0.1284555047750473
Validation loss: 1.6751699883450744

Epoch: 5| Step: 8
Training loss: 0.2125939428806305
Validation loss: 1.6468307023407311

Epoch: 5| Step: 9
Training loss: 0.13871127367019653
Validation loss: 1.6813633185560986

Epoch: 5| Step: 10
Training loss: 0.20048339664936066
Validation loss: 1.6597468968360656

Testing loss: 2.179939773347643
