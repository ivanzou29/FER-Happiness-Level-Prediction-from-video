Epoch: 1| Step: 0
Training loss: 6.5937245445302475
Validation loss: 5.857853149979902

Epoch: 6| Step: 1
Training loss: 5.527246783049624
Validation loss: 5.840965496839198

Epoch: 6| Step: 2
Training loss: 5.513275770066003
Validation loss: 5.825406539414609

Epoch: 6| Step: 3
Training loss: 5.193358089565937
Validation loss: 5.8090719063496765

Epoch: 6| Step: 4
Training loss: 4.577650026022324
Validation loss: 5.791795947666009

Epoch: 6| Step: 5
Training loss: 5.538756368810341
Validation loss: 5.772474391525891

Epoch: 6| Step: 6
Training loss: 5.633139252940369
Validation loss: 5.749897827981288

Epoch: 6| Step: 7
Training loss: 5.529777373925263
Validation loss: 5.725555729406493

Epoch: 6| Step: 8
Training loss: 6.352762069130436
Validation loss: 5.697223064180909

Epoch: 6| Step: 9
Training loss: 5.717212574568374
Validation loss: 5.664511606801074

Epoch: 6| Step: 10
Training loss: 5.705583601580047
Validation loss: 5.629292021706935

Epoch: 6| Step: 11
Training loss: 6.448209871970555
Validation loss: 5.588615594138349

Epoch: 6| Step: 12
Training loss: 6.980305623356257
Validation loss: 5.543017260820546

Epoch: 6| Step: 13
Training loss: 3.6563256410778724
Validation loss: 5.494881275610589

Epoch: 2| Step: 0
Training loss: 7.051802103209649
Validation loss: 5.442858465751687

Epoch: 6| Step: 1
Training loss: 5.140191613570329
Validation loss: 5.389215633183114

Epoch: 6| Step: 2
Training loss: 4.8438799440735165
Validation loss: 5.330554537553311

Epoch: 6| Step: 3
Training loss: 5.976808550388581
Validation loss: 5.273440580196233

Epoch: 6| Step: 4
Training loss: 5.3893011706671485
Validation loss: 5.215815144735511

Epoch: 6| Step: 5
Training loss: 3.377194432936014
Validation loss: 5.159977828891797

Epoch: 6| Step: 6
Training loss: 4.4337701300268115
Validation loss: 5.109616503728409

Epoch: 6| Step: 7
Training loss: 4.628605442494009
Validation loss: 5.063568207121306

Epoch: 6| Step: 8
Training loss: 4.554343051874252
Validation loss: 5.021754393481587

Epoch: 6| Step: 9
Training loss: 5.595988587559371
Validation loss: 4.980804307231188

Epoch: 6| Step: 10
Training loss: 4.84587001551583
Validation loss: 4.939610827712052

Epoch: 6| Step: 11
Training loss: 5.896553921107756
Validation loss: 4.903740535738232

Epoch: 6| Step: 12
Training loss: 5.397074238821944
Validation loss: 4.870687924645051

Epoch: 6| Step: 13
Training loss: 3.922429870017446
Validation loss: 4.842907370565827

Epoch: 3| Step: 0
Training loss: 4.898101843812895
Validation loss: 4.814822304250654

Epoch: 6| Step: 1
Training loss: 4.545283192959403
Validation loss: 4.787831140041054

Epoch: 6| Step: 2
Training loss: 5.057204691344927
Validation loss: 4.760138657851937

Epoch: 6| Step: 3
Training loss: 4.843578704758441
Validation loss: 4.735826722763718

Epoch: 6| Step: 4
Training loss: 5.424783503699638
Validation loss: 4.713685447536349

Epoch: 6| Step: 5
Training loss: 4.588970578513114
Validation loss: 4.695748460762261

Epoch: 6| Step: 6
Training loss: 4.777069657854197
Validation loss: 4.676755572692303

Epoch: 6| Step: 7
Training loss: 4.329297068849811
Validation loss: 4.658886144742428

Epoch: 6| Step: 8
Training loss: 4.867699267085546
Validation loss: 4.6441252607311165

Epoch: 6| Step: 9
Training loss: 5.001797353038631
Validation loss: 4.621961064728433

Epoch: 6| Step: 10
Training loss: 5.337297972668178
Validation loss: 4.59944832620482

Epoch: 6| Step: 11
Training loss: 3.5825900408443103
Validation loss: 4.573470919513337

Epoch: 6| Step: 12
Training loss: 4.33560800761027
Validation loss: 4.558009715057413

Epoch: 6| Step: 13
Training loss: 5.017197026873643
Validation loss: 4.5483636911476975

Epoch: 4| Step: 0
Training loss: 4.287474624959076
Validation loss: 4.525090820202413

Epoch: 6| Step: 1
Training loss: 4.339713217405751
Validation loss: 4.507161151943643

Epoch: 6| Step: 2
Training loss: 4.406713583076564
Validation loss: 4.49436931341375

Epoch: 6| Step: 3
Training loss: 5.091736939856307
Validation loss: 4.485178414667208

Epoch: 6| Step: 4
Training loss: 5.438169942340653
Validation loss: 4.46461501231035

Epoch: 6| Step: 5
Training loss: 3.984810719320434
Validation loss: 4.4463110174529366

Epoch: 6| Step: 6
Training loss: 5.838120303799899
Validation loss: 4.43405802423892

Epoch: 6| Step: 7
Training loss: 3.742708874660035
Validation loss: 4.421878339435078

Epoch: 6| Step: 8
Training loss: 4.927739019765944
Validation loss: 4.404942532857389

Epoch: 6| Step: 9
Training loss: 4.662969259829539
Validation loss: 4.391394683646764

Epoch: 6| Step: 10
Training loss: 4.381932025669487
Validation loss: 4.382765742747446

Epoch: 6| Step: 11
Training loss: 3.8787182842092665
Validation loss: 4.371839353769719

Epoch: 6| Step: 12
Training loss: 4.163160043800018
Validation loss: 4.359175715553946

Epoch: 6| Step: 13
Training loss: 3.511947132190597
Validation loss: 4.3419422546775435

Epoch: 5| Step: 0
Training loss: 4.623425808627813
Validation loss: 4.33324381086643

Epoch: 6| Step: 1
Training loss: 5.164114762819406
Validation loss: 4.319519906638405

Epoch: 6| Step: 2
Training loss: 5.392996180825319
Validation loss: 4.305601926128927

Epoch: 6| Step: 3
Training loss: 4.066010352365925
Validation loss: 4.2925824626764575

Epoch: 6| Step: 4
Training loss: 4.649090889281663
Validation loss: 4.279743132689614

Epoch: 6| Step: 5
Training loss: 4.089666062132196
Validation loss: 4.267522819500275

Epoch: 6| Step: 6
Training loss: 4.448641477516861
Validation loss: 4.254723305097176

Epoch: 6| Step: 7
Training loss: 4.038127385103188
Validation loss: 4.2436622883254405

Epoch: 6| Step: 8
Training loss: 4.0242992478237944
Validation loss: 4.234475287979961

Epoch: 6| Step: 9
Training loss: 3.767717468627508
Validation loss: 4.240310957629839

Epoch: 6| Step: 10
Training loss: 4.697580307156813
Validation loss: 4.209297468544506

Epoch: 6| Step: 11
Training loss: 4.6073175526023356
Validation loss: 4.201469827716042

Epoch: 6| Step: 12
Training loss: 3.160418486589391
Validation loss: 4.191268170738625

Epoch: 6| Step: 13
Training loss: 4.1164943973054156
Validation loss: 4.183302356007327

Epoch: 6| Step: 0
Training loss: 4.27464642763572
Validation loss: 4.172524593707464

Epoch: 6| Step: 1
Training loss: 3.66338805801387
Validation loss: 4.1646195450638706

Epoch: 6| Step: 2
Training loss: 4.245614650336895
Validation loss: 4.1548950518141545

Epoch: 6| Step: 3
Training loss: 4.627425923633023
Validation loss: 4.141057445366957

Epoch: 6| Step: 4
Training loss: 4.319892849123144
Validation loss: 4.131859367259716

Epoch: 6| Step: 5
Training loss: 4.959074184089775
Validation loss: 4.127422703943015

Epoch: 6| Step: 6
Training loss: 3.8320700733889614
Validation loss: 4.110143089309618

Epoch: 6| Step: 7
Training loss: 3.4450174149071686
Validation loss: 4.094930020800838

Epoch: 6| Step: 8
Training loss: 3.217827525863693
Validation loss: 4.0824509701777085

Epoch: 6| Step: 9
Training loss: 4.150707938237741
Validation loss: 4.082388517219784

Epoch: 6| Step: 10
Training loss: 5.246529840109478
Validation loss: 4.0703203301481095

Epoch: 6| Step: 11
Training loss: 2.5706156172188126
Validation loss: 4.058105684486939

Epoch: 6| Step: 12
Training loss: 5.581819053765055
Validation loss: 4.055881237030805

Epoch: 6| Step: 13
Training loss: 4.465817429578941
Validation loss: 4.050428674845446

Epoch: 7| Step: 0
Training loss: 4.036868652489954
Validation loss: 4.041476623377018

Epoch: 6| Step: 1
Training loss: 4.834799094853648
Validation loss: 4.028474562509874

Epoch: 6| Step: 2
Training loss: 4.324154571635872
Validation loss: 4.019323462198525

Epoch: 6| Step: 3
Training loss: 2.8546403552141535
Validation loss: 4.006601003988166

Epoch: 6| Step: 4
Training loss: 4.267181671373262
Validation loss: 3.997622665356577

Epoch: 6| Step: 5
Training loss: 3.9458890890165454
Validation loss: 3.989565989537135

Epoch: 6| Step: 6
Training loss: 4.836929737160399
Validation loss: 3.9853590025060943

Epoch: 6| Step: 7
Training loss: 4.24236711715451
Validation loss: 3.979543050368849

Epoch: 6| Step: 8
Training loss: 3.906487175416909
Validation loss: 3.967426702460974

Epoch: 6| Step: 9
Training loss: 4.1865292463002035
Validation loss: 3.958655892891423

Epoch: 6| Step: 10
Training loss: 3.902649463672559
Validation loss: 3.951008745275437

Epoch: 6| Step: 11
Training loss: 4.783718892861792
Validation loss: 3.943558244340367

Epoch: 6| Step: 12
Training loss: 3.6664396273518025
Validation loss: 3.934997570743158

Epoch: 6| Step: 13
Training loss: 3.278715335431464
Validation loss: 3.927272360029894

Epoch: 8| Step: 0
Training loss: 3.779616326130723
Validation loss: 3.9200801496848294

Epoch: 6| Step: 1
Training loss: 2.955812230672504
Validation loss: 3.91309453562007

Epoch: 6| Step: 2
Training loss: 3.5978997196813727
Validation loss: 3.905013029744225

Epoch: 6| Step: 3
Training loss: 4.450677995788101
Validation loss: 3.899525401432221

Epoch: 6| Step: 4
Training loss: 2.9457188333563726
Validation loss: 3.8939003001876773

Epoch: 6| Step: 5
Training loss: 3.991788780770857
Validation loss: 3.890175315151344

Epoch: 6| Step: 6
Training loss: 4.341444762276882
Validation loss: 3.8821533578567626

Epoch: 6| Step: 7
Training loss: 4.542200786202404
Validation loss: 3.8736850414094897

Epoch: 6| Step: 8
Training loss: 3.3433479709120992
Validation loss: 3.865459172516977

Epoch: 6| Step: 9
Training loss: 4.601016985385371
Validation loss: 3.8576294358012815

Epoch: 6| Step: 10
Training loss: 4.19180327256699
Validation loss: 3.8529821707012206

Epoch: 6| Step: 11
Training loss: 4.488589124354167
Validation loss: 3.845754758734999

Epoch: 6| Step: 12
Training loss: 4.34093136897446
Validation loss: 3.836869227922996

Epoch: 6| Step: 13
Training loss: 4.695657777706126
Validation loss: 3.8289300838374385

Epoch: 9| Step: 0
Training loss: 3.4343258160860564
Validation loss: 3.8218816041270975

Epoch: 6| Step: 1
Training loss: 3.134819168156437
Validation loss: 3.8166484107074243

Epoch: 6| Step: 2
Training loss: 4.332954439079942
Validation loss: 3.811631106206066

Epoch: 6| Step: 3
Training loss: 4.3251277309365115
Validation loss: 3.8049974755128995

Epoch: 6| Step: 4
Training loss: 3.929611053633287
Validation loss: 3.797781218956274

Epoch: 6| Step: 5
Training loss: 4.242619107877968
Validation loss: 3.794331329730745

Epoch: 6| Step: 6
Training loss: 4.64956389812518
Validation loss: 3.79529312423283

Epoch: 6| Step: 7
Training loss: 3.6959981463704272
Validation loss: 3.7910798261116487

Epoch: 6| Step: 8
Training loss: 4.287611418852826
Validation loss: 3.788394643055035

Epoch: 6| Step: 9
Training loss: 4.537333436541276
Validation loss: 3.785495362357269

Epoch: 6| Step: 10
Training loss: 3.6004782676893794
Validation loss: 3.781762940123505

Epoch: 6| Step: 11
Training loss: 3.29379244058617
Validation loss: 3.7772517322610817

Epoch: 6| Step: 12
Training loss: 3.907551052860716
Validation loss: 3.7678598675288337

Epoch: 6| Step: 13
Training loss: 3.7120796453711904
Validation loss: 3.763655976829066

Epoch: 10| Step: 0
Training loss: 2.9328574972303136
Validation loss: 3.7577197304112158

Epoch: 6| Step: 1
Training loss: 3.8453393147016857
Validation loss: 3.7553559137561234

Epoch: 6| Step: 2
Training loss: 4.2018466976766735
Validation loss: 3.7513627587581753

Epoch: 6| Step: 3
Training loss: 4.813654773436919
Validation loss: 3.744238084976903

Epoch: 6| Step: 4
Training loss: 3.459758480220126
Validation loss: 3.7394758788274807

Epoch: 6| Step: 5
Training loss: 5.137216290067754
Validation loss: 3.73542826328809

Epoch: 6| Step: 6
Training loss: 3.9475707587869633
Validation loss: 3.7350355310627013

Epoch: 6| Step: 7
Training loss: 3.0492902524023515
Validation loss: 3.7285639090766725

Epoch: 6| Step: 8
Training loss: 3.0568441987421116
Validation loss: 3.7252363946044116

Epoch: 6| Step: 9
Training loss: 4.1884413842440305
Validation loss: 3.722838621711731

Epoch: 6| Step: 10
Training loss: 4.314259488072075
Validation loss: 3.7185693926034493

Epoch: 6| Step: 11
Training loss: 4.777511431542119
Validation loss: 3.7160623595956084

Epoch: 6| Step: 12
Training loss: 2.41750941435471
Validation loss: 3.710675001548171

Epoch: 6| Step: 13
Training loss: 3.3914665900475405
Validation loss: 3.707941720177815

Epoch: 11| Step: 0
Training loss: 3.6929336859303605
Validation loss: 3.707374652543123

Epoch: 6| Step: 1
Training loss: 4.24898157820251
Validation loss: 3.7046078884057936

Epoch: 6| Step: 2
Training loss: 4.318364233517167
Validation loss: 3.700420571248049

Epoch: 6| Step: 3
Training loss: 2.7334085554921703
Validation loss: 3.696451435111676

Epoch: 6| Step: 4
Training loss: 4.306843904641229
Validation loss: 3.692492434722824

Epoch: 6| Step: 5
Training loss: 4.224275488496218
Validation loss: 3.690339997221997

Epoch: 6| Step: 6
Training loss: 3.38551867209105
Validation loss: 3.6878434666597157

Epoch: 6| Step: 7
Training loss: 4.205343915775638
Validation loss: 3.6843818814295326

Epoch: 6| Step: 8
Training loss: 3.6197714093782696
Validation loss: 3.682815178739621

Epoch: 6| Step: 9
Training loss: 4.132333882818739
Validation loss: 3.6807786473149973

Epoch: 6| Step: 10
Training loss: 3.148591068583389
Validation loss: 3.669596538135679

Epoch: 6| Step: 11
Training loss: 3.8525677775387397
Validation loss: 3.667328069180621

Epoch: 6| Step: 12
Training loss: 2.7100907028334364
Validation loss: 3.661048348197916

Epoch: 6| Step: 13
Training loss: 5.661766776134791
Validation loss: 3.660070891820907

Epoch: 12| Step: 0
Training loss: 3.583872880162882
Validation loss: 3.6701867126231438

Epoch: 6| Step: 1
Training loss: 3.2299305330252763
Validation loss: 3.699791158665062

Epoch: 6| Step: 2
Training loss: 2.9779277083702516
Validation loss: 3.706243036270482

Epoch: 6| Step: 3
Training loss: 4.464968274933988
Validation loss: 3.672721424173628

Epoch: 6| Step: 4
Training loss: 4.1366986930728356
Validation loss: 3.639666400169549

Epoch: 6| Step: 5
Training loss: 4.577987095965876
Validation loss: 3.6469215580810004

Epoch: 6| Step: 6
Training loss: 4.268092074315406
Validation loss: 3.655492713458219

Epoch: 6| Step: 7
Training loss: 3.4789128620214225
Validation loss: 3.636176382554452

Epoch: 6| Step: 8
Training loss: 4.590806290362281
Validation loss: 3.624476710800224

Epoch: 6| Step: 9
Training loss: 2.792944165101587
Validation loss: 3.6150055569235975

Epoch: 6| Step: 10
Training loss: 3.823695769509985
Validation loss: 3.614490583141851

Epoch: 6| Step: 11
Training loss: 4.103577676455522
Validation loss: 3.616994262911674

Epoch: 6| Step: 12
Training loss: 3.3847360406057065
Validation loss: 3.6124868563661914

Epoch: 6| Step: 13
Training loss: 3.6960149182105266
Validation loss: 3.6026877895369425

Epoch: 13| Step: 0
Training loss: 4.203847830068203
Validation loss: 3.599095846675271

Epoch: 6| Step: 1
Training loss: 4.080568480436906
Validation loss: 3.593035948992002

Epoch: 6| Step: 2
Training loss: 3.889094898277441
Validation loss: 3.5878525934449925

Epoch: 6| Step: 3
Training loss: 3.5274659533787274
Validation loss: 3.5848766765543383

Epoch: 6| Step: 4
Training loss: 3.106958111311502
Validation loss: 3.5814873637882947

Epoch: 6| Step: 5
Training loss: 3.492200881283787
Validation loss: 3.5791559306416834

Epoch: 6| Step: 6
Training loss: 3.2236233456578653
Validation loss: 3.574932060339051

Epoch: 6| Step: 7
Training loss: 3.426271166508178
Validation loss: 3.5718887406495616

Epoch: 6| Step: 8
Training loss: 4.479608534671458
Validation loss: 3.569263697603937

Epoch: 6| Step: 9
Training loss: 3.1630010637636716
Validation loss: 3.5707739540357353

Epoch: 6| Step: 10
Training loss: 4.369567986614745
Validation loss: 3.567664455392204

Epoch: 6| Step: 11
Training loss: 4.1458826621234355
Validation loss: 3.5634236386047893

Epoch: 6| Step: 12
Training loss: 3.4853708529078804
Validation loss: 3.5615295674455827

Epoch: 6| Step: 13
Training loss: 4.123748589475262
Validation loss: 3.560179197131995

Epoch: 14| Step: 0
Training loss: 4.012689489721073
Validation loss: 3.5571399312178547

Epoch: 6| Step: 1
Training loss: 3.7140714562628654
Validation loss: 3.5552871575132863

Epoch: 6| Step: 2
Training loss: 3.544324857181873
Validation loss: 3.553998987336864

Epoch: 6| Step: 3
Training loss: 3.8957085546954664
Validation loss: 3.552714783601427

Epoch: 6| Step: 4
Training loss: 3.1248005612628234
Validation loss: 3.551465486532439

Epoch: 6| Step: 5
Training loss: 3.331520032405382
Validation loss: 3.548680995514203

Epoch: 6| Step: 6
Training loss: 4.051298691487272
Validation loss: 3.5471190223668616

Epoch: 6| Step: 7
Training loss: 3.487065256018511
Validation loss: 3.557274741883814

Epoch: 6| Step: 8
Training loss: 3.6774344704376163
Validation loss: 3.5470195041710033

Epoch: 6| Step: 9
Training loss: 3.7294186696979468
Validation loss: 3.535895699897558

Epoch: 6| Step: 10
Training loss: 4.311755129851959
Validation loss: 3.5543872863789945

Epoch: 6| Step: 11
Training loss: 3.047426770451531
Validation loss: 3.527555151090569

Epoch: 6| Step: 12
Training loss: 4.531313560303139
Validation loss: 3.5430266580702834

Epoch: 6| Step: 13
Training loss: 3.8973565753144124
Validation loss: 3.5368108049835025

Epoch: 15| Step: 0
Training loss: 3.8074077931170414
Validation loss: 3.546900842487645

Epoch: 6| Step: 1
Training loss: 4.436166482345093
Validation loss: 3.544506408776062

Epoch: 6| Step: 2
Training loss: 3.6766004956799407
Validation loss: 3.526142741941698

Epoch: 6| Step: 3
Training loss: 3.123969709310566
Validation loss: 3.5253472680111884

Epoch: 6| Step: 4
Training loss: 3.3873177848879004
Validation loss: 3.5357744926238444

Epoch: 6| Step: 5
Training loss: 4.238771303033914
Validation loss: 3.537991051946403

Epoch: 6| Step: 6
Training loss: 3.585677659005616
Validation loss: 3.5286555449885637

Epoch: 6| Step: 7
Training loss: 3.345684026963151
Validation loss: 3.521694431679916

Epoch: 6| Step: 8
Training loss: 3.396573101198782
Validation loss: 3.51854567900185

Epoch: 6| Step: 9
Training loss: 4.094376610709165
Validation loss: 3.520411752614531

Epoch: 6| Step: 10
Training loss: 3.3299632838519044
Validation loss: 3.5197038658602073

Epoch: 6| Step: 11
Training loss: 3.832712841954356
Validation loss: 3.5183813419945826

Epoch: 6| Step: 12
Training loss: 3.939724732673373
Validation loss: 3.5146033257515286

Epoch: 6| Step: 13
Training loss: 4.0050296156570475
Validation loss: 3.5116370870527076

Epoch: 16| Step: 0
Training loss: 3.3703674736367595
Validation loss: 3.509123346707923

Epoch: 6| Step: 1
Training loss: 4.067245294231375
Validation loss: 3.5070104282447185

Epoch: 6| Step: 2
Training loss: 4.290425068530711
Validation loss: 3.505075159111837

Epoch: 6| Step: 3
Training loss: 4.406464916425908
Validation loss: 3.5033401074139143

Epoch: 6| Step: 4
Training loss: 3.2095726063781127
Validation loss: 3.501605130196423

Epoch: 6| Step: 5
Training loss: 3.1581659827941166
Validation loss: 3.499932670824622

Epoch: 6| Step: 6
Training loss: 3.6900235609010523
Validation loss: 3.4968416742247816

Epoch: 6| Step: 7
Training loss: 3.6126770504130388
Validation loss: 3.4976066633501186

Epoch: 6| Step: 8
Training loss: 3.933427672682642
Validation loss: 3.494847948876659

Epoch: 6| Step: 9
Training loss: 3.216757296403831
Validation loss: 3.493872879887336

Epoch: 6| Step: 10
Training loss: 4.162052091493412
Validation loss: 3.4943972598654063

Epoch: 6| Step: 11
Training loss: 3.4623833041030063
Validation loss: 3.490647173315995

Epoch: 6| Step: 12
Training loss: 3.683126927687139
Validation loss: 3.4897591960575864

Epoch: 6| Step: 13
Training loss: 3.1781785088369725
Validation loss: 3.4863796190918253

Epoch: 17| Step: 0
Training loss: 3.6357396955991326
Validation loss: 3.4848490342498026

Epoch: 6| Step: 1
Training loss: 4.0316909430599415
Validation loss: 3.483243047932999

Epoch: 6| Step: 2
Training loss: 3.5581719057390995
Validation loss: 3.483714695908005

Epoch: 6| Step: 3
Training loss: 3.4779403870592005
Validation loss: 3.4833245846398606

Epoch: 6| Step: 4
Training loss: 4.304310195366334
Validation loss: 3.48123724422871

Epoch: 6| Step: 5
Training loss: 3.2741188669409054
Validation loss: 3.4815272315056016

Epoch: 6| Step: 6
Training loss: 2.8565468064233777
Validation loss: 3.4798890286777695

Epoch: 6| Step: 7
Training loss: 3.3220167386381414
Validation loss: 3.479461321929952

Epoch: 6| Step: 8
Training loss: 4.4210219352297075
Validation loss: 3.4782792457206164

Epoch: 6| Step: 9
Training loss: 3.522264644863385
Validation loss: 3.4757695660650256

Epoch: 6| Step: 10
Training loss: 4.113850640196329
Validation loss: 3.474552993193842

Epoch: 6| Step: 11
Training loss: 3.905785861097485
Validation loss: 3.471279616904294

Epoch: 6| Step: 12
Training loss: 3.442777985961354
Validation loss: 3.4712647709627555

Epoch: 6| Step: 13
Training loss: 3.455386150769221
Validation loss: 3.4705216394505785

Epoch: 18| Step: 0
Training loss: 4.265932847536678
Validation loss: 3.4719183665122832

Epoch: 6| Step: 1
Training loss: 3.3889320471539484
Validation loss: 3.467726559711012

Epoch: 6| Step: 2
Training loss: 4.209377700589566
Validation loss: 3.4675121617106326

Epoch: 6| Step: 3
Training loss: 3.8011259920414435
Validation loss: 3.46758863878638

Epoch: 6| Step: 4
Training loss: 3.406830064571344
Validation loss: 3.4728155119543715

Epoch: 6| Step: 5
Training loss: 3.401550270517678
Validation loss: 3.496548494851945

Epoch: 6| Step: 6
Training loss: 4.018248417285519
Validation loss: 3.47296244950366

Epoch: 6| Step: 7
Training loss: 3.355285710592621
Validation loss: 3.465055346286722

Epoch: 6| Step: 8
Training loss: 3.6406758186166157
Validation loss: 3.462127672754772

Epoch: 6| Step: 9
Training loss: 4.422435280179129
Validation loss: 3.4615378914022665

Epoch: 6| Step: 10
Training loss: 3.731390490674553
Validation loss: 3.46223479355845

Epoch: 6| Step: 11
Training loss: 3.4998648481160135
Validation loss: 3.462688087290921

Epoch: 6| Step: 12
Training loss: 3.025047011837688
Validation loss: 3.4633517473314734

Epoch: 6| Step: 13
Training loss: 2.702191230151082
Validation loss: 3.4602686886415124

Epoch: 19| Step: 0
Training loss: 4.213323875931697
Validation loss: 3.458405043363465

Epoch: 6| Step: 1
Training loss: 4.04790822393244
Validation loss: 3.4555715590240075

Epoch: 6| Step: 2
Training loss: 4.374547444506492
Validation loss: 3.4536622044891363

Epoch: 6| Step: 3
Training loss: 2.871125969738431
Validation loss: 3.452545950451637

Epoch: 6| Step: 4
Training loss: 4.197371505033779
Validation loss: 3.451067545651002

Epoch: 6| Step: 5
Training loss: 3.711291872471215
Validation loss: 3.4506676989470115

Epoch: 6| Step: 6
Training loss: 3.6990010279035004
Validation loss: 3.4493626496112295

Epoch: 6| Step: 7
Training loss: 3.5480312529760396
Validation loss: 3.4486178537823884

Epoch: 6| Step: 8
Training loss: 3.324111596071529
Validation loss: 3.4479962493324194

Epoch: 6| Step: 9
Training loss: 3.6118846276784184
Validation loss: 3.4474569639472725

Epoch: 6| Step: 10
Training loss: 3.0630584519027626
Validation loss: 3.4467444101738307

Epoch: 6| Step: 11
Training loss: 3.316551465920382
Validation loss: 3.445345573386534

Epoch: 6| Step: 12
Training loss: 3.698895062602218
Validation loss: 3.444135108897401

Epoch: 6| Step: 13
Training loss: 3.169051393399733
Validation loss: 3.444173201522542

Epoch: 20| Step: 0
Training loss: 3.698126658893295
Validation loss: 3.4421850173504285

Epoch: 6| Step: 1
Training loss: 3.9787862439411827
Validation loss: 3.4409677161996175

Epoch: 6| Step: 2
Training loss: 4.007450793863148
Validation loss: 3.4399324255180175

Epoch: 6| Step: 3
Training loss: 3.689853628300018
Validation loss: 3.438657235817688

Epoch: 6| Step: 4
Training loss: 3.479024294074033
Validation loss: 3.437516402786214

Epoch: 6| Step: 5
Training loss: 3.16068583083872
Validation loss: 3.4368091757928583

Epoch: 6| Step: 6
Training loss: 3.595431523215922
Validation loss: 3.435580422961111

Epoch: 6| Step: 7
Training loss: 3.6722252212053044
Validation loss: 3.434515821730772

Epoch: 6| Step: 8
Training loss: 4.307030346595452
Validation loss: 3.4332037410736205

Epoch: 6| Step: 9
Training loss: 3.6020698107319795
Validation loss: 3.432557342109839

Epoch: 6| Step: 10
Training loss: 3.290945931893739
Validation loss: 3.4315571863746923

Epoch: 6| Step: 11
Training loss: 3.055809966005714
Validation loss: 3.430628622175161

Epoch: 6| Step: 12
Training loss: 4.03573855309599
Validation loss: 3.4295867674155978

Epoch: 6| Step: 13
Training loss: 3.2566299304692756
Validation loss: 3.4285153355944313

Epoch: 21| Step: 0
Training loss: 3.5319904462570637
Validation loss: 3.4273963847829285

Epoch: 6| Step: 1
Training loss: 3.547160536242058
Validation loss: 3.42661615224424

Epoch: 6| Step: 2
Training loss: 3.4998359641736134
Validation loss: 3.425554943763222

Epoch: 6| Step: 3
Training loss: 3.358496688643506
Validation loss: 3.4244728537805877

Epoch: 6| Step: 4
Training loss: 3.7337165794754172
Validation loss: 3.423735889460443

Epoch: 6| Step: 5
Training loss: 2.847986775121094
Validation loss: 3.4229485702583196

Epoch: 6| Step: 6
Training loss: 4.1216069918851606
Validation loss: 3.421617101987207

Epoch: 6| Step: 7
Training loss: 3.7707421448080796
Validation loss: 3.4211726235495723

Epoch: 6| Step: 8
Training loss: 3.4915960779694855
Validation loss: 3.4199621773133355

Epoch: 6| Step: 9
Training loss: 4.293510534724701
Validation loss: 3.419013900606159

Epoch: 6| Step: 10
Training loss: 3.949556572083614
Validation loss: 3.4180397863081904

Epoch: 6| Step: 11
Training loss: 3.469054200176499
Validation loss: 3.417279381865759

Epoch: 6| Step: 12
Training loss: 3.748075881694687
Validation loss: 3.4165389359491756

Epoch: 6| Step: 13
Training loss: 3.3673958061201663
Validation loss: 3.415386217131275

Epoch: 22| Step: 0
Training loss: 3.070750430957963
Validation loss: 3.4141195473678088

Epoch: 6| Step: 1
Training loss: 3.660803933989805
Validation loss: 3.412982990303113

Epoch: 6| Step: 2
Training loss: 2.4802763135860166
Validation loss: 3.4123704918382805

Epoch: 6| Step: 3
Training loss: 3.5533093138760274
Validation loss: 3.411435142850955

Epoch: 6| Step: 4
Training loss: 3.5336193136926286
Validation loss: 3.410899933434462

Epoch: 6| Step: 5
Training loss: 3.9852728336992183
Validation loss: 3.4097274320651016

Epoch: 6| Step: 6
Training loss: 4.22083982346021
Validation loss: 3.4087730381829

Epoch: 6| Step: 7
Training loss: 3.337207418468597
Validation loss: 3.4082006645622744

Epoch: 6| Step: 8
Training loss: 3.2138477511471684
Validation loss: 3.4070817229808306

Epoch: 6| Step: 9
Training loss: 4.149106418968756
Validation loss: 3.406072745368547

Epoch: 6| Step: 10
Training loss: 4.037235045818554
Validation loss: 3.405227978953151

Epoch: 6| Step: 11
Training loss: 3.6378594237310233
Validation loss: 3.404602897397946

Epoch: 6| Step: 12
Training loss: 3.4131806585568802
Validation loss: 3.4031754121935784

Epoch: 6| Step: 13
Training loss: 4.564786991025704
Validation loss: 3.402971872722642

Epoch: 23| Step: 0
Training loss: 3.9816720208863488
Validation loss: 3.401256802029273

Epoch: 6| Step: 1
Training loss: 3.568914427702175
Validation loss: 3.40031327439673

Epoch: 6| Step: 2
Training loss: 4.393248076549898
Validation loss: 3.3993644426163323

Epoch: 6| Step: 3
Training loss: 3.965250590079581
Validation loss: 3.398617634556615

Epoch: 6| Step: 4
Training loss: 2.9324352348961353
Validation loss: 3.3976034119410414

Epoch: 6| Step: 5
Training loss: 3.1716521988213158
Validation loss: 3.39691792122581

Epoch: 6| Step: 6
Training loss: 3.2881971657104043
Validation loss: 3.395916911644981

Epoch: 6| Step: 7
Training loss: 2.9609387883407488
Validation loss: 3.3946963627083653

Epoch: 6| Step: 8
Training loss: 3.6806424272629585
Validation loss: 3.3938017736713837

Epoch: 6| Step: 9
Training loss: 4.557505133579395
Validation loss: 3.393041007871659

Epoch: 6| Step: 10
Training loss: 3.341109900257785
Validation loss: 3.392114431512759

Epoch: 6| Step: 11
Training loss: 3.6874789221209694
Validation loss: 3.3910700418679363

Epoch: 6| Step: 12
Training loss: 3.0523529107273912
Validation loss: 3.3906391934189957

Epoch: 6| Step: 13
Training loss: 3.7910432966854586
Validation loss: 3.389308612849355

Epoch: 24| Step: 0
Training loss: 3.4512799196973933
Validation loss: 3.3883526819026537

Epoch: 6| Step: 1
Training loss: 2.974758131950145
Validation loss: 3.387603679351304

Epoch: 6| Step: 2
Training loss: 2.3580713775871276
Validation loss: 3.3867707790980544

Epoch: 6| Step: 3
Training loss: 3.6167541639815974
Validation loss: 3.386423183152541

Epoch: 6| Step: 4
Training loss: 3.1963211370316276
Validation loss: 3.3848442443090545

Epoch: 6| Step: 5
Training loss: 3.3808455530299493
Validation loss: 3.3841425363583686

Epoch: 6| Step: 6
Training loss: 3.679829783027425
Validation loss: 3.383034937783534

Epoch: 6| Step: 7
Training loss: 3.3805695249181276
Validation loss: 3.382124167603529

Epoch: 6| Step: 8
Training loss: 4.490897615422992
Validation loss: 3.3816413950532387

Epoch: 6| Step: 9
Training loss: 4.529704073572646
Validation loss: 3.380384720100185

Epoch: 6| Step: 10
Training loss: 3.6365721577765813
Validation loss: 3.3794390017814253

Epoch: 6| Step: 11
Training loss: 3.586359535265047
Validation loss: 3.3786697307760254

Epoch: 6| Step: 12
Training loss: 4.179725832184039
Validation loss: 3.377804058086416

Epoch: 6| Step: 13
Training loss: 3.523729942348591
Validation loss: 3.376542662855404

Epoch: 25| Step: 0
Training loss: 2.821459338898207
Validation loss: 3.375813369850108

Epoch: 6| Step: 1
Training loss: 3.465721939423497
Validation loss: 3.374893581789366

Epoch: 6| Step: 2
Training loss: 4.150273895417316
Validation loss: 3.374141416794197

Epoch: 6| Step: 3
Training loss: 3.033760997122003
Validation loss: 3.3729594209618203

Epoch: 6| Step: 4
Training loss: 3.1102345874295034
Validation loss: 3.372494880278742

Epoch: 6| Step: 5
Training loss: 4.233656931446334
Validation loss: 3.3717048705272608

Epoch: 6| Step: 6
Training loss: 2.628963112747544
Validation loss: 3.3706316127055738

Epoch: 6| Step: 7
Training loss: 3.0417628512568387
Validation loss: 3.369530679560012

Epoch: 6| Step: 8
Training loss: 3.9197994986658706
Validation loss: 3.369253954260185

Epoch: 6| Step: 9
Training loss: 3.931213931841572
Validation loss: 3.367888275368765

Epoch: 6| Step: 10
Training loss: 3.573549101587597
Validation loss: 3.366832887214876

Epoch: 6| Step: 11
Training loss: 3.9552119479674825
Validation loss: 3.3663523539371814

Epoch: 6| Step: 12
Training loss: 3.8044644080833567
Validation loss: 3.3655035346114626

Epoch: 6| Step: 13
Training loss: 4.685889819475972
Validation loss: 3.365040931276579

Epoch: 26| Step: 0
Training loss: 3.3567247449237767
Validation loss: 3.363392674492873

Epoch: 6| Step: 1
Training loss: 3.6629915604094503
Validation loss: 3.3631959538253695

Epoch: 6| Step: 2
Training loss: 3.6719759014145024
Validation loss: 3.3619606699585285

Epoch: 6| Step: 3
Training loss: 3.9579876932855913
Validation loss: 3.360821722299475

Epoch: 6| Step: 4
Training loss: 3.3869433125070505
Validation loss: 3.3598500531393154

Epoch: 6| Step: 5
Training loss: 3.3895056498573712
Validation loss: 3.3593183538912794

Epoch: 6| Step: 6
Training loss: 4.009421458759351
Validation loss: 3.358302869032363

Epoch: 6| Step: 7
Training loss: 4.261598356313874
Validation loss: 3.357547405774642

Epoch: 6| Step: 8
Training loss: 3.389727495656843
Validation loss: 3.3565180312339264

Epoch: 6| Step: 9
Training loss: 3.0758109907360076
Validation loss: 3.355680319952992

Epoch: 6| Step: 10
Training loss: 3.07562929242677
Validation loss: 3.354763116824986

Epoch: 6| Step: 11
Training loss: 3.1266270788597077
Validation loss: 3.3540264817016934

Epoch: 6| Step: 12
Training loss: 4.009445006665462
Validation loss: 3.352850740258607

Epoch: 6| Step: 13
Training loss: 3.751536245385276
Validation loss: 3.3521740043333135

Epoch: 27| Step: 0
Training loss: 3.987156753355714
Validation loss: 3.3511364583312524

Epoch: 6| Step: 1
Training loss: 3.910785209077339
Validation loss: 3.3502026555856497

Epoch: 6| Step: 2
Training loss: 3.423276570662681
Validation loss: 3.349766527800037

Epoch: 6| Step: 3
Training loss: 3.4561676843370694
Validation loss: 3.3487350990896543

Epoch: 6| Step: 4
Training loss: 3.760920581533924
Validation loss: 3.347280803883703

Epoch: 6| Step: 5
Training loss: 4.415205707877164
Validation loss: 3.346618000462393

Epoch: 6| Step: 6
Training loss: 2.77943841462548
Validation loss: 3.3459071723363447

Epoch: 6| Step: 7
Training loss: 4.396405850170575
Validation loss: 3.3443486733197525

Epoch: 6| Step: 8
Training loss: 3.1573729075559265
Validation loss: 3.344533902577613

Epoch: 6| Step: 9
Training loss: 3.2042407069851637
Validation loss: 3.3435554497631963

Epoch: 6| Step: 10
Training loss: 3.4724153965090476
Validation loss: 3.3415702260191193

Epoch: 6| Step: 11
Training loss: 3.447928959727582
Validation loss: 3.3406757616826783

Epoch: 6| Step: 12
Training loss: 3.221133932584224
Validation loss: 3.340547472658347

Epoch: 6| Step: 13
Training loss: 2.7034169298535238
Validation loss: 3.339382155228484

Epoch: 28| Step: 0
Training loss: 3.891517751214816
Validation loss: 3.3388245672145414

Epoch: 6| Step: 1
Training loss: 3.1197587883458135
Validation loss: 3.3381811135439774

Epoch: 6| Step: 2
Training loss: 3.9970371478895323
Validation loss: 3.3369041933287575

Epoch: 6| Step: 3
Training loss: 3.2512650595275505
Validation loss: 3.335381728075889

Epoch: 6| Step: 4
Training loss: 2.7580113325764484
Validation loss: 3.3353114862417677

Epoch: 6| Step: 5
Training loss: 3.5819629591960114
Validation loss: 3.3343727034692647

Epoch: 6| Step: 6
Training loss: 3.740399469063617
Validation loss: 3.3343450754107233

Epoch: 6| Step: 7
Training loss: 4.231484190011512
Validation loss: 3.333236758053392

Epoch: 6| Step: 8
Training loss: 3.1704164355421605
Validation loss: 3.3323271560780654

Epoch: 6| Step: 9
Training loss: 3.3857592287121614
Validation loss: 3.3308480539706524

Epoch: 6| Step: 10
Training loss: 3.7340569141220694
Validation loss: 3.32981778129972

Epoch: 6| Step: 11
Training loss: 3.2881804889694775
Validation loss: 3.329118667246864

Epoch: 6| Step: 12
Training loss: 4.294570138223282
Validation loss: 3.328783500770545

Epoch: 6| Step: 13
Training loss: 2.890832182186715
Validation loss: 3.3279196420535047

Epoch: 29| Step: 0
Training loss: 3.916417918862279
Validation loss: 3.3289323399769373

Epoch: 6| Step: 1
Training loss: 3.220595340070283
Validation loss: 3.3267602536757117

Epoch: 6| Step: 2
Training loss: 4.009572733807236
Validation loss: 3.3251145820141

Epoch: 6| Step: 3
Training loss: 3.156001015086428
Validation loss: 3.3251325808009637

Epoch: 6| Step: 4
Training loss: 3.516373889420776
Validation loss: 3.3240170486132636

Epoch: 6| Step: 5
Training loss: 3.681032748846918
Validation loss: 3.3221073749921555

Epoch: 6| Step: 6
Training loss: 2.4287266441239206
Validation loss: 3.32195233091884

Epoch: 6| Step: 7
Training loss: 2.981870069337797
Validation loss: 3.3218467770396263

Epoch: 6| Step: 8
Training loss: 3.6939138463274093
Validation loss: 3.320612096908522

Epoch: 6| Step: 9
Training loss: 3.5852249534609326
Validation loss: 3.320236800101143

Epoch: 6| Step: 10
Training loss: 3.9415087199808476
Validation loss: 3.318580730003863

Epoch: 6| Step: 11
Training loss: 3.56089666325586
Validation loss: 3.319011676726475

Epoch: 6| Step: 12
Training loss: 3.8241817172539787
Validation loss: 3.3186442097284448

Epoch: 6| Step: 13
Training loss: 4.301099884952326
Validation loss: 3.3164786685968077

Epoch: 30| Step: 0
Training loss: 4.042853636646242
Validation loss: 3.315563822752859

Epoch: 6| Step: 1
Training loss: 3.349736923591969
Validation loss: 3.316272496693302

Epoch: 6| Step: 2
Training loss: 3.8767670324906733
Validation loss: 3.3134768069895553

Epoch: 6| Step: 3
Training loss: 3.2597521672505305
Validation loss: 3.312798636548123

Epoch: 6| Step: 4
Training loss: 3.1775723107106346
Validation loss: 3.311995235842936

Epoch: 6| Step: 5
Training loss: 3.469983955368194
Validation loss: 3.3096275219225046

Epoch: 6| Step: 6
Training loss: 2.779302794074205
Validation loss: 3.3096390309234667

Epoch: 6| Step: 7
Training loss: 4.102842062312568
Validation loss: 3.3090899377337326

Epoch: 6| Step: 8
Training loss: 3.6075827372177596
Validation loss: 3.3100708505782745

Epoch: 6| Step: 9
Training loss: 3.0246333633056874
Validation loss: 3.307020165607956

Epoch: 6| Step: 10
Training loss: 3.5212349446292732
Validation loss: 3.307072318337242

Epoch: 6| Step: 11
Training loss: 4.039309466428163
Validation loss: 3.3049842020357536

Epoch: 6| Step: 12
Training loss: 3.9710616941056904
Validation loss: 3.306093495806953

Epoch: 6| Step: 13
Training loss: 2.8689011278424097
Validation loss: 3.304526127354714

Epoch: 31| Step: 0
Training loss: 2.964185880467006
Validation loss: 3.3042073991621943

Epoch: 6| Step: 1
Training loss: 3.419098864509198
Validation loss: 3.3015013156249706

Epoch: 6| Step: 2
Training loss: 3.7076784620078262
Validation loss: 3.299690930848414

Epoch: 6| Step: 3
Training loss: 3.4139147274762873
Validation loss: 3.2987496348066805

Epoch: 6| Step: 4
Training loss: 3.3282378987966483
Validation loss: 3.297949529485427

Epoch: 6| Step: 5
Training loss: 3.764781050071899
Validation loss: 3.2992998210673923

Epoch: 6| Step: 6
Training loss: 2.8648971848072664
Validation loss: 3.297503450113809

Epoch: 6| Step: 7
Training loss: 3.523626961023147
Validation loss: 3.298216910145849

Epoch: 6| Step: 8
Training loss: 3.4851832799455487
Validation loss: 3.2954836737482474

Epoch: 6| Step: 9
Training loss: 4.251448216246413
Validation loss: 3.2946868775141662

Epoch: 6| Step: 10
Training loss: 3.4677423611674296
Validation loss: 3.2963539547327687

Epoch: 6| Step: 11
Training loss: 3.4536728920545587
Validation loss: 3.295186953398279

Epoch: 6| Step: 12
Training loss: 4.232280818628931
Validation loss: 3.296435040385635

Epoch: 6| Step: 13
Training loss: 3.394571003390282
Validation loss: 3.297444679113218

Epoch: 32| Step: 0
Training loss: 3.810302851697654
Validation loss: 3.2933211077929476

Epoch: 6| Step: 1
Training loss: 3.6756201292231743
Validation loss: 3.293368940798177

Epoch: 6| Step: 2
Training loss: 3.463777844782747
Validation loss: 3.2901226444813108

Epoch: 6| Step: 3
Training loss: 4.001933345866813
Validation loss: 3.2895104145143135

Epoch: 6| Step: 4
Training loss: 3.884917458107834
Validation loss: 3.2908240771966186

Epoch: 6| Step: 5
Training loss: 3.501732806005238
Validation loss: 3.28606742683276

Epoch: 6| Step: 6
Training loss: 2.2346664985498865
Validation loss: 3.2889189528677685

Epoch: 6| Step: 7
Training loss: 3.154010242394729
Validation loss: 3.285604244485755

Epoch: 6| Step: 8
Training loss: 3.2456265881125157
Validation loss: 3.2858010135196167

Epoch: 6| Step: 9
Training loss: 3.7636229705404713
Validation loss: 3.2853103197139664

Epoch: 6| Step: 10
Training loss: 3.673663154398463
Validation loss: 3.284059369388857

Epoch: 6| Step: 11
Training loss: 3.4272009801334296
Validation loss: 3.2946773207091886

Epoch: 6| Step: 12
Training loss: 3.8637387705812203
Validation loss: 3.3062691451856963

Epoch: 6| Step: 13
Training loss: 3.325382732649509
Validation loss: 3.2821919391553545

Epoch: 33| Step: 0
Training loss: 3.2066743863568665
Validation loss: 3.279979142886302

Epoch: 6| Step: 1
Training loss: 4.079493033757453
Validation loss: 3.284902527546563

Epoch: 6| Step: 2
Training loss: 3.8552055539596393
Validation loss: 3.302224366851811

Epoch: 6| Step: 3
Training loss: 3.605040089758655
Validation loss: 3.34094457018802

Epoch: 6| Step: 4
Training loss: 2.8984766543640736
Validation loss: 3.2861147459894773

Epoch: 6| Step: 5
Training loss: 4.005042712189827
Validation loss: 3.2918524050435707

Epoch: 6| Step: 6
Training loss: 3.4411371582685573
Validation loss: 3.381272583951403

Epoch: 6| Step: 7
Training loss: 3.622469577911664
Validation loss: 3.2920492242516493

Epoch: 6| Step: 8
Training loss: 3.402232609542027
Validation loss: 3.2992365278347955

Epoch: 6| Step: 9
Training loss: 2.602461742519351
Validation loss: 3.3947921979832314

Epoch: 6| Step: 10
Training loss: 3.952800028715923
Validation loss: 3.4891442032536397

Epoch: 6| Step: 11
Training loss: 3.6132590793238735
Validation loss: 3.4411769871263393

Epoch: 6| Step: 12
Training loss: 3.6801973868382807
Validation loss: 3.4165751437202685

Epoch: 6| Step: 13
Training loss: 4.175173937435051
Validation loss: 3.464941421447134

Epoch: 34| Step: 0
Training loss: 3.8688136525379413
Validation loss: 3.4759064395827752

Epoch: 6| Step: 1
Training loss: 2.948922694422189
Validation loss: 3.3099079000995446

Epoch: 6| Step: 2
Training loss: 2.5457317384051565
Validation loss: 3.303043472904937

Epoch: 6| Step: 3
Training loss: 3.0395799211078094
Validation loss: 3.3235269585852487

Epoch: 6| Step: 4
Training loss: 4.501062903442051
Validation loss: 3.3549031023877225

Epoch: 6| Step: 5
Training loss: 4.126154420168041
Validation loss: 3.306224352281994

Epoch: 6| Step: 6
Training loss: 3.1038460960675436
Validation loss: 3.3051424295418523

Epoch: 6| Step: 7
Training loss: 3.7462458574681357
Validation loss: 3.3180011786093395

Epoch: 6| Step: 8
Training loss: 4.02913900298149
Validation loss: 3.3168942247935997

Epoch: 6| Step: 9
Training loss: 2.942427540213478
Validation loss: 3.3025155954732592

Epoch: 6| Step: 10
Training loss: 3.8475618147516437
Validation loss: 3.297386090549612

Epoch: 6| Step: 11
Training loss: 3.750989147702462
Validation loss: 3.2951669821931646

Epoch: 6| Step: 12
Training loss: 3.429364651928044
Validation loss: 3.2895134180817913

Epoch: 6| Step: 13
Training loss: 3.3148438420633974
Validation loss: 3.2858691734251466

Epoch: 35| Step: 0
Training loss: 3.54036622949384
Validation loss: 3.281954342924254

Epoch: 6| Step: 1
Training loss: 3.621522748404587
Validation loss: 3.278396188908812

Epoch: 6| Step: 2
Training loss: 3.404535684619011
Validation loss: 3.2823184350649695

Epoch: 6| Step: 3
Training loss: 3.456097182470449
Validation loss: 3.2797193982000947

Epoch: 6| Step: 4
Training loss: 3.7208021896670815
Validation loss: 3.2771528440368782

Epoch: 6| Step: 5
Training loss: 3.74160768480831
Validation loss: 3.2745086204223894

Epoch: 6| Step: 6
Training loss: 3.767705951774645
Validation loss: 3.272581457206301

Epoch: 6| Step: 7
Training loss: 3.1845249428978377
Validation loss: 3.2729441254579603

Epoch: 6| Step: 8
Training loss: 3.6192988583950063
Validation loss: 3.268569542764158

Epoch: 6| Step: 9
Training loss: 3.827102836070503
Validation loss: 3.2680873490853215

Epoch: 6| Step: 10
Training loss: 3.1444191859398676
Validation loss: 3.2634822886888513

Epoch: 6| Step: 11
Training loss: 3.4568424151727544
Validation loss: 3.2544018773795287

Epoch: 6| Step: 12
Training loss: 3.5644611515320586
Validation loss: 3.2492037350647047

Epoch: 6| Step: 13
Training loss: 2.7741844353451044
Validation loss: 3.2490563470139397

Epoch: 36| Step: 0
Training loss: 3.887464718183257
Validation loss: 3.249295280541573

Epoch: 6| Step: 1
Training loss: 3.672888563152831
Validation loss: 3.248879514821935

Epoch: 6| Step: 2
Training loss: 3.876997648122811
Validation loss: 3.2479197199806324

Epoch: 6| Step: 3
Training loss: 3.9067788948586517
Validation loss: 3.2503413107138974

Epoch: 6| Step: 4
Training loss: 3.739927497405805
Validation loss: 3.2473657106011835

Epoch: 6| Step: 5
Training loss: 3.1258467480758
Validation loss: 3.2427127203672796

Epoch: 6| Step: 6
Training loss: 3.157535102510182
Validation loss: 3.2412000176052698

Epoch: 6| Step: 7
Training loss: 3.5867238231864853
Validation loss: 3.241392413076228

Epoch: 6| Step: 8
Training loss: 3.2136916625857017
Validation loss: 3.238923100135719

Epoch: 6| Step: 9
Training loss: 3.004330370741956
Validation loss: 3.240054750930665

Epoch: 6| Step: 10
Training loss: 3.767639507705318
Validation loss: 3.238100980806743

Epoch: 6| Step: 11
Training loss: 2.8273461887067666
Validation loss: 3.2384704069889256

Epoch: 6| Step: 12
Training loss: 3.424543341940656
Validation loss: 3.237858830065632

Epoch: 6| Step: 13
Training loss: 3.5833904054813375
Validation loss: 3.236411394194691

Epoch: 37| Step: 0
Training loss: 3.7428133447179057
Validation loss: 3.2386022155079326

Epoch: 6| Step: 1
Training loss: 3.35024137623735
Validation loss: 3.235640989976994

Epoch: 6| Step: 2
Training loss: 3.030631720027447
Validation loss: 3.233171177654376

Epoch: 6| Step: 3
Training loss: 3.224626232636887
Validation loss: 3.234852664458765

Epoch: 6| Step: 4
Training loss: 3.419829850453775
Validation loss: 3.231397191201578

Epoch: 6| Step: 5
Training loss: 4.0881593691523195
Validation loss: 3.2316198667814073

Epoch: 6| Step: 6
Training loss: 3.1734652737294753
Validation loss: 3.2303929985715545

Epoch: 6| Step: 7
Training loss: 2.9973344086761626
Validation loss: 3.2282106575493588

Epoch: 6| Step: 8
Training loss: 3.754689780880302
Validation loss: 3.2279527926444542

Epoch: 6| Step: 9
Training loss: 3.092182417330967
Validation loss: 3.225193465708958

Epoch: 6| Step: 10
Training loss: 4.537768075973928
Validation loss: 3.2230530157428725

Epoch: 6| Step: 11
Training loss: 3.008890964326404
Validation loss: 3.220472240441161

Epoch: 6| Step: 12
Training loss: 3.636898376421183
Validation loss: 3.21606288864565

Epoch: 6| Step: 13
Training loss: 3.205899260672437
Validation loss: 3.214375587531229

Epoch: 38| Step: 0
Training loss: 2.544917940267008
Validation loss: 3.2131282026982704

Epoch: 6| Step: 1
Training loss: 3.6929429826670734
Validation loss: 3.2107511028705433

Epoch: 6| Step: 2
Training loss: 3.1747043562084034
Validation loss: 3.210097192568089

Epoch: 6| Step: 3
Training loss: 3.7392139447185206
Validation loss: 3.210686210969274

Epoch: 6| Step: 4
Training loss: 2.711593504584794
Validation loss: 3.2092269222504717

Epoch: 6| Step: 5
Training loss: 3.0971814786305734
Validation loss: 3.2091634853905813

Epoch: 6| Step: 6
Training loss: 3.9267671628137246
Validation loss: 3.2118945824012584

Epoch: 6| Step: 7
Training loss: 3.0270715603443064
Validation loss: 3.2121278265930675

Epoch: 6| Step: 8
Training loss: 3.548558579213862
Validation loss: 3.2138598328732138

Epoch: 6| Step: 9
Training loss: 3.1957470288284124
Validation loss: 3.2106469043843964

Epoch: 6| Step: 10
Training loss: 3.640307105596873
Validation loss: 3.207544621108214

Epoch: 6| Step: 11
Training loss: 4.1149254507772195
Validation loss: 3.2056797519230518

Epoch: 6| Step: 12
Training loss: 4.049673637144457
Validation loss: 3.2013730552119903

Epoch: 6| Step: 13
Training loss: 3.74494084187984
Validation loss: 3.2019278501400477

Epoch: 39| Step: 0
Training loss: 2.829721916743522
Validation loss: 3.2006907315558406

Epoch: 6| Step: 1
Training loss: 3.3745653790973935
Validation loss: 3.198427815558439

Epoch: 6| Step: 2
Training loss: 3.477311163025177
Validation loss: 3.1989798523940003

Epoch: 6| Step: 3
Training loss: 3.837261771595412
Validation loss: 3.2000347750835383

Epoch: 6| Step: 4
Training loss: 3.5218319501843576
Validation loss: 3.1972989774493077

Epoch: 6| Step: 5
Training loss: 3.488431886707585
Validation loss: 3.1961393321785243

Epoch: 6| Step: 6
Training loss: 3.851419380422818
Validation loss: 3.194107450627409

Epoch: 6| Step: 7
Training loss: 3.286342919081835
Validation loss: 3.194486887113213

Epoch: 6| Step: 8
Training loss: 2.675909910798196
Validation loss: 3.1936631703602467

Epoch: 6| Step: 9
Training loss: 3.378529433920068
Validation loss: 3.19097142732801

Epoch: 6| Step: 10
Training loss: 3.8278492108086595
Validation loss: 3.1913241521965716

Epoch: 6| Step: 11
Training loss: 4.049541287288126
Validation loss: 3.1899833391456363

Epoch: 6| Step: 12
Training loss: 3.579597669828865
Validation loss: 3.1898118606395136

Epoch: 6| Step: 13
Training loss: 2.358223337185101
Validation loss: 3.1883554583454683

Epoch: 40| Step: 0
Training loss: 3.880768450903925
Validation loss: 3.191056606344243

Epoch: 6| Step: 1
Training loss: 3.215937598690602
Validation loss: 3.1892040852164985

Epoch: 6| Step: 2
Training loss: 3.9293131412996516
Validation loss: 3.187504706639662

Epoch: 6| Step: 3
Training loss: 3.905128256905381
Validation loss: 3.190396067173004

Epoch: 6| Step: 4
Training loss: 3.3054781209244384
Validation loss: 3.185677860303998

Epoch: 6| Step: 5
Training loss: 3.426007845092984
Validation loss: 3.1870339986142024

Epoch: 6| Step: 6
Training loss: 3.955009403338147
Validation loss: 3.189856058818757

Epoch: 6| Step: 7
Training loss: 3.0485622331605966
Validation loss: 3.1932637548341236

Epoch: 6| Step: 8
Training loss: 3.483160243380556
Validation loss: 3.1920666251077967

Epoch: 6| Step: 9
Training loss: 3.644610535964344
Validation loss: 3.190175042469002

Epoch: 6| Step: 10
Training loss: 2.9948708874825356
Validation loss: 3.1902119028140934

Epoch: 6| Step: 11
Training loss: 2.74305750421597
Validation loss: 3.1853091121767716

Epoch: 6| Step: 12
Training loss: 2.8896718696244945
Validation loss: 3.185393521902133

Epoch: 6| Step: 13
Training loss: 3.421105145811975
Validation loss: 3.1833691098299286

Epoch: 41| Step: 0
Training loss: 3.9138240779663365
Validation loss: 3.183232327597092

Epoch: 6| Step: 1
Training loss: 4.051784762616746
Validation loss: 3.1882171869587896

Epoch: 6| Step: 2
Training loss: 3.621498126482291
Validation loss: 3.193191847957621

Epoch: 6| Step: 3
Training loss: 3.5421358283960034
Validation loss: 3.1934162932731627

Epoch: 6| Step: 4
Training loss: 3.5798273159980387
Validation loss: 3.195603139094048

Epoch: 6| Step: 5
Training loss: 1.97191111777912
Validation loss: 3.1935270233015625

Epoch: 6| Step: 6
Training loss: 3.1636594915989584
Validation loss: 3.1901112106811356

Epoch: 6| Step: 7
Training loss: 2.5561356945643317
Validation loss: 3.185402555091124

Epoch: 6| Step: 8
Training loss: 3.884013368279093
Validation loss: 3.1827118854627345

Epoch: 6| Step: 9
Training loss: 3.178307386058025
Validation loss: 3.181009402054323

Epoch: 6| Step: 10
Training loss: 3.6495820890539856
Validation loss: 3.1746268703867444

Epoch: 6| Step: 11
Training loss: 3.890468609588987
Validation loss: 3.1748895283081193

Epoch: 6| Step: 12
Training loss: 3.3162598774198866
Validation loss: 3.174227991249906

Epoch: 6| Step: 13
Training loss: 2.8249910810211634
Validation loss: 3.173638378646171

Epoch: 42| Step: 0
Training loss: 3.4281208048736582
Validation loss: 3.1714362756337784

Epoch: 6| Step: 1
Training loss: 3.496073564012953
Validation loss: 3.1747461193080286

Epoch: 6| Step: 2
Training loss: 3.434700536875833
Validation loss: 3.170615928701627

Epoch: 6| Step: 3
Training loss: 3.638957939431113
Validation loss: 3.1666804255611383

Epoch: 6| Step: 4
Training loss: 3.35832872287885
Validation loss: 3.167133745893935

Epoch: 6| Step: 5
Training loss: 3.170920994299196
Validation loss: 3.168025687472687

Epoch: 6| Step: 6
Training loss: 3.644759421448057
Validation loss: 3.1674068073868575

Epoch: 6| Step: 7
Training loss: 3.306017308258516
Validation loss: 3.1661958495574587

Epoch: 6| Step: 8
Training loss: 2.7330308498702998
Validation loss: 3.1633545555895686

Epoch: 6| Step: 9
Training loss: 3.320818837771175
Validation loss: 3.166124204038574

Epoch: 6| Step: 10
Training loss: 3.5761190730331838
Validation loss: 3.1613019719515054

Epoch: 6| Step: 11
Training loss: 3.411178103675133
Validation loss: 3.164010072367711

Epoch: 6| Step: 12
Training loss: 3.990606722868286
Validation loss: 3.159583433639208

Epoch: 6| Step: 13
Training loss: 3.231669303207017
Validation loss: 3.1602950539270758

Epoch: 43| Step: 0
Training loss: 3.067980319769453
Validation loss: 3.165308536957948

Epoch: 6| Step: 1
Training loss: 2.861221467722049
Validation loss: 3.1612473332786797

Epoch: 6| Step: 2
Training loss: 3.6151198869297545
Validation loss: 3.1620049194772766

Epoch: 6| Step: 3
Training loss: 2.908076706925355
Validation loss: 3.1616663099691755

Epoch: 6| Step: 4
Training loss: 3.865874343021919
Validation loss: 3.161068239357512

Epoch: 6| Step: 5
Training loss: 2.872546268419185
Validation loss: 3.1594323601630854

Epoch: 6| Step: 6
Training loss: 3.481887682273829
Validation loss: 3.159336663778115

Epoch: 6| Step: 7
Training loss: 4.046846721064323
Validation loss: 3.1558033275714465

Epoch: 6| Step: 8
Training loss: 2.418311074818507
Validation loss: 3.1576456537602455

Epoch: 6| Step: 9
Training loss: 3.9475179720874753
Validation loss: 3.1576686965557363

Epoch: 6| Step: 10
Training loss: 4.0488389599770604
Validation loss: 3.157441123921621

Epoch: 6| Step: 11
Training loss: 3.859495091596898
Validation loss: 3.1532179057077867

Epoch: 6| Step: 12
Training loss: 2.689546559912472
Validation loss: 3.1536599303023003

Epoch: 6| Step: 13
Training loss: 3.573506935822783
Validation loss: 3.1532849583048703

Epoch: 44| Step: 0
Training loss: 3.49837428892411
Validation loss: 3.1526798381672045

Epoch: 6| Step: 1
Training loss: 3.0556317599263343
Validation loss: 3.1534106075560064

Epoch: 6| Step: 2
Training loss: 3.466229597073585
Validation loss: 3.1727113403628326

Epoch: 6| Step: 3
Training loss: 4.156252294554113
Validation loss: 3.1713061766026462

Epoch: 6| Step: 4
Training loss: 3.659867542975962
Validation loss: 3.158038666199429

Epoch: 6| Step: 5
Training loss: 3.2473287608611057
Validation loss: 3.151345130154309

Epoch: 6| Step: 6
Training loss: 2.6174378232666755
Validation loss: 3.1488612081307354

Epoch: 6| Step: 7
Training loss: 4.0949348889811565
Validation loss: 3.148708774673725

Epoch: 6| Step: 8
Training loss: 3.338771786349106
Validation loss: 3.1469613364400075

Epoch: 6| Step: 9
Training loss: 2.630412924083229
Validation loss: 3.1483196225384003

Epoch: 6| Step: 10
Training loss: 3.5752872058236074
Validation loss: 3.147013182147512

Epoch: 6| Step: 11
Training loss: 2.765641724271908
Validation loss: 3.14607289578395

Epoch: 6| Step: 12
Training loss: 3.096519694650811
Validation loss: 3.1450219355133404

Epoch: 6| Step: 13
Training loss: 4.364170076141764
Validation loss: 3.1443985897985756

Epoch: 45| Step: 0
Training loss: 3.533854106695989
Validation loss: 3.1437622426272362

Epoch: 6| Step: 1
Training loss: 2.8842108418379855
Validation loss: 3.1439016635315835

Epoch: 6| Step: 2
Training loss: 3.488200187809171
Validation loss: 3.141850773026353

Epoch: 6| Step: 3
Training loss: 2.661573931329196
Validation loss: 3.140355990386274

Epoch: 6| Step: 4
Training loss: 3.7241607539864874
Validation loss: 3.139368034171932

Epoch: 6| Step: 5
Training loss: 4.053762106134839
Validation loss: 3.1414030292220874

Epoch: 6| Step: 6
Training loss: 2.932990650909954
Validation loss: 3.1390995015838357

Epoch: 6| Step: 7
Training loss: 3.181567786631713
Validation loss: 3.138794848725252

Epoch: 6| Step: 8
Training loss: 3.865734713700487
Validation loss: 3.140105910123468

Epoch: 6| Step: 9
Training loss: 3.4007379572483423
Validation loss: 3.141875842638608

Epoch: 6| Step: 10
Training loss: 3.066298328614402
Validation loss: 3.1357807496810546

Epoch: 6| Step: 11
Training loss: 3.1880618329531223
Validation loss: 3.1348636984342373

Epoch: 6| Step: 12
Training loss: 3.622496694243445
Validation loss: 3.1387493483550313

Epoch: 6| Step: 13
Training loss: 3.87578402555459
Validation loss: 3.142767736682522

Epoch: 46| Step: 0
Training loss: 3.699888078182455
Validation loss: 3.1356132515741097

Epoch: 6| Step: 1
Training loss: 2.7587975317900972
Validation loss: 3.1330742791964283

Epoch: 6| Step: 2
Training loss: 3.3141564600033346
Validation loss: 3.131771760611692

Epoch: 6| Step: 3
Training loss: 3.6979509092366305
Validation loss: 3.1324878477662494

Epoch: 6| Step: 4
Training loss: 3.3135616112814037
Validation loss: 3.1308654638117113

Epoch: 6| Step: 5
Training loss: 4.03777477167951
Validation loss: 3.1438363850094158

Epoch: 6| Step: 6
Training loss: 2.6545419025516144
Validation loss: 3.133350602590884

Epoch: 6| Step: 7
Training loss: 3.446831124131092
Validation loss: 3.131689176773633

Epoch: 6| Step: 8
Training loss: 3.3066613905874838
Validation loss: 3.1287118553499806

Epoch: 6| Step: 9
Training loss: 3.115788884573212
Validation loss: 3.1260363257114236

Epoch: 6| Step: 10
Training loss: 3.9187135150190513
Validation loss: 3.1272114793946835

Epoch: 6| Step: 11
Training loss: 3.0709824158821273
Validation loss: 3.123751867288066

Epoch: 6| Step: 12
Training loss: 3.401163765943733
Validation loss: 3.1249924378662493

Epoch: 6| Step: 13
Training loss: 3.3446403102473727
Validation loss: 3.123054195581889

Epoch: 47| Step: 0
Training loss: 3.6143434355147592
Validation loss: 3.122319178690691

Epoch: 6| Step: 1
Training loss: 3.7843044334277387
Validation loss: 3.119767342681016

Epoch: 6| Step: 2
Training loss: 2.6869188611891075
Validation loss: 3.1195525338402765

Epoch: 6| Step: 3
Training loss: 4.125081610594799
Validation loss: 3.119069718356764

Epoch: 6| Step: 4
Training loss: 3.363116784233716
Validation loss: 3.1194088605965664

Epoch: 6| Step: 5
Training loss: 3.308333457607264
Validation loss: 3.1200800339620134

Epoch: 6| Step: 6
Training loss: 3.8317800083684004
Validation loss: 3.117670319168939

Epoch: 6| Step: 7
Training loss: 2.9557738358179333
Validation loss: 3.1167965754695985

Epoch: 6| Step: 8
Training loss: 3.430037426313399
Validation loss: 3.1160225630444347

Epoch: 6| Step: 9
Training loss: 3.1190712191910177
Validation loss: 3.114387146878413

Epoch: 6| Step: 10
Training loss: 3.5181907954783624
Validation loss: 3.1136403330069196

Epoch: 6| Step: 11
Training loss: 2.2682924550129124
Validation loss: 3.1127700825540967

Epoch: 6| Step: 12
Training loss: 3.2439768805567826
Validation loss: 3.113107402699643

Epoch: 6| Step: 13
Training loss: 3.717966461982512
Validation loss: 3.1103693146843843

Epoch: 48| Step: 0
Training loss: 2.5696374070393677
Validation loss: 3.112752395124171

Epoch: 6| Step: 1
Training loss: 3.856680605200195
Validation loss: 3.110780749919233

Epoch: 6| Step: 2
Training loss: 3.094249646462578
Validation loss: 3.110826422853481

Epoch: 6| Step: 3
Training loss: 3.6106254756452403
Validation loss: 3.1105951916282475

Epoch: 6| Step: 4
Training loss: 3.964397296292535
Validation loss: 3.106850784954021

Epoch: 6| Step: 5
Training loss: 3.5744679515243396
Validation loss: 3.109653515049014

Epoch: 6| Step: 6
Training loss: 4.2184608642961985
Validation loss: 3.1098369771119163

Epoch: 6| Step: 7
Training loss: 2.8691090477542454
Validation loss: 3.111273777120545

Epoch: 6| Step: 8
Training loss: 3.0828950587652795
Validation loss: 3.1121708760126143

Epoch: 6| Step: 9
Training loss: 3.2288231123423126
Validation loss: 3.1097549715019133

Epoch: 6| Step: 10
Training loss: 3.897823797628728
Validation loss: 3.1091666236048696

Epoch: 6| Step: 11
Training loss: 2.633425677969971
Validation loss: 3.1064107518594763

Epoch: 6| Step: 12
Training loss: 2.499541240561764
Validation loss: 3.10398583973914

Epoch: 6| Step: 13
Training loss: 3.482468977527777
Validation loss: 3.1091971628673245

Epoch: 49| Step: 0
Training loss: 3.3861576306265904
Validation loss: 3.109954435359425

Epoch: 6| Step: 1
Training loss: 3.3706374052906276
Validation loss: 3.1091600684835123

Epoch: 6| Step: 2
Training loss: 3.652602373238136
Validation loss: 3.109577769478576

Epoch: 6| Step: 3
Training loss: 3.1552531868353557
Validation loss: 3.1055994096231365

Epoch: 6| Step: 4
Training loss: 3.284450895265546
Validation loss: 3.101921651122192

Epoch: 6| Step: 5
Training loss: 2.811652670484197
Validation loss: 3.102652561550159

Epoch: 6| Step: 6
Training loss: 3.220757608317211
Validation loss: 3.1003794262253828

Epoch: 6| Step: 7
Training loss: 3.5148149023252167
Validation loss: 3.0972853797815225

Epoch: 6| Step: 8
Training loss: 3.858666729512068
Validation loss: 3.0977907000440412

Epoch: 6| Step: 9
Training loss: 3.464926046707963
Validation loss: 3.1122656861715474

Epoch: 6| Step: 10
Training loss: 3.345145959107305
Validation loss: 3.1235368769513348

Epoch: 6| Step: 11
Training loss: 2.8715401438690638
Validation loss: 3.100479440666403

Epoch: 6| Step: 12
Training loss: 3.1234914571768306
Validation loss: 3.097994154915233

Epoch: 6| Step: 13
Training loss: 4.131772117689882
Validation loss: 3.0892865236085396

Epoch: 50| Step: 0
Training loss: 3.051880778772624
Validation loss: 3.0914125309916987

Epoch: 6| Step: 1
Training loss: 2.7149482542273846
Validation loss: 3.0874657560809866

Epoch: 6| Step: 2
Training loss: 3.2042200217167984
Validation loss: 3.092538101755141

Epoch: 6| Step: 3
Training loss: 2.863147685642465
Validation loss: 3.0944062489174935

Epoch: 6| Step: 4
Training loss: 3.956778666050121
Validation loss: 3.0954119048100055

Epoch: 6| Step: 5
Training loss: 3.1167654263221807
Validation loss: 3.1196155363133986

Epoch: 6| Step: 6
Training loss: 4.262380183261478
Validation loss: 3.148118100842958

Epoch: 6| Step: 7
Training loss: 3.718001218150218
Validation loss: 3.0873402155325635

Epoch: 6| Step: 8
Training loss: 3.311298944349866
Validation loss: 3.081583499896189

Epoch: 6| Step: 9
Training loss: 3.6420229082135984
Validation loss: 3.0886680235338293

Epoch: 6| Step: 10
Training loss: 3.493213886762016
Validation loss: 3.0907780573741506

Epoch: 6| Step: 11
Training loss: 3.7264670433758313
Validation loss: 3.081781870576697

Epoch: 6| Step: 12
Training loss: 2.245475883087663
Validation loss: 3.0796437480877445

Epoch: 6| Step: 13
Training loss: 3.2165241137394847
Validation loss: 3.0775261419213953

Epoch: 51| Step: 0
Training loss: 1.953720246208642
Validation loss: 3.079941315251011

Epoch: 6| Step: 1
Training loss: 3.127244524747932
Validation loss: 3.084444667767728

Epoch: 6| Step: 2
Training loss: 3.427953746764039
Validation loss: 3.0843175305605284

Epoch: 6| Step: 3
Training loss: 3.8885355168207183
Validation loss: 3.0961497555948774

Epoch: 6| Step: 4
Training loss: 3.380866991163432
Validation loss: 3.094394375179812

Epoch: 6| Step: 5
Training loss: 2.9386852389347036
Validation loss: 3.0865656861196133

Epoch: 6| Step: 6
Training loss: 3.9133008874547834
Validation loss: 3.083501888236543

Epoch: 6| Step: 7
Training loss: 4.294937862350872
Validation loss: 3.081911326731469

Epoch: 6| Step: 8
Training loss: 3.4390675525203545
Validation loss: 3.0801283207331487

Epoch: 6| Step: 9
Training loss: 4.222160938442814
Validation loss: 3.078971801699135

Epoch: 6| Step: 10
Training loss: 3.195492765009877
Validation loss: 3.0801266777405725

Epoch: 6| Step: 11
Training loss: 2.886436933871546
Validation loss: 3.076899805466086

Epoch: 6| Step: 12
Training loss: 2.819587508665879
Validation loss: 3.080374889526051

Epoch: 6| Step: 13
Training loss: 1.8887449011743318
Validation loss: 3.0760049681235677

Epoch: 52| Step: 0
Training loss: 3.9435609460848755
Validation loss: 3.075277592784661

Epoch: 6| Step: 1
Training loss: 2.5515080536676558
Validation loss: 3.07592902320533

Epoch: 6| Step: 2
Training loss: 2.8703824985298056
Validation loss: 3.0757972665504165

Epoch: 6| Step: 3
Training loss: 2.3125806227367978
Validation loss: 3.0712773781846696

Epoch: 6| Step: 4
Training loss: 3.2743949855450096
Validation loss: 3.07384537973487

Epoch: 6| Step: 5
Training loss: 3.202983425082012
Validation loss: 3.0715456454697136

Epoch: 6| Step: 6
Training loss: 2.6530132544251486
Validation loss: 3.0741928117629365

Epoch: 6| Step: 7
Training loss: 3.421017055867042
Validation loss: 3.0756025408801575

Epoch: 6| Step: 8
Training loss: 3.670089222501688
Validation loss: 3.0749691329115136

Epoch: 6| Step: 9
Training loss: 3.527794151234781
Validation loss: 3.07577208676973

Epoch: 6| Step: 10
Training loss: 3.866344259786066
Validation loss: 3.07189473296136

Epoch: 6| Step: 11
Training loss: 3.743895457503629
Validation loss: 3.072771429707522

Epoch: 6| Step: 12
Training loss: 3.7161400876694737
Validation loss: 3.0718284625357217

Epoch: 6| Step: 13
Training loss: 3.6173535961797985
Validation loss: 3.073316183480348

Epoch: 53| Step: 0
Training loss: 3.0599728492080818
Validation loss: 3.072238515389505

Epoch: 6| Step: 1
Training loss: 3.7429254556826104
Validation loss: 3.0711303413250914

Epoch: 6| Step: 2
Training loss: 3.5305378963876866
Validation loss: 3.0694981916471487

Epoch: 6| Step: 3
Training loss: 3.1732256038662343
Validation loss: 3.0666806037335568

Epoch: 6| Step: 4
Training loss: 3.3313534260738624
Validation loss: 3.0612723841062124

Epoch: 6| Step: 5
Training loss: 3.217382047754189
Validation loss: 3.0814617854725923

Epoch: 6| Step: 6
Training loss: 3.202399641574341
Validation loss: 3.0705308086919585

Epoch: 6| Step: 7
Training loss: 3.046060306495606
Validation loss: 3.0557090432356397

Epoch: 6| Step: 8
Training loss: 3.2110724873256697
Validation loss: 3.0571776586819768

Epoch: 6| Step: 9
Training loss: 3.366949015445203
Validation loss: 3.057978258837102

Epoch: 6| Step: 10
Training loss: 3.6428746161589443
Validation loss: 3.0596579430903375

Epoch: 6| Step: 11
Training loss: 2.446473939651972
Validation loss: 3.058197216639405

Epoch: 6| Step: 12
Training loss: 4.035432759917386
Validation loss: 3.057046906910072

Epoch: 6| Step: 13
Training loss: 3.4834219822410066
Validation loss: 3.0623659251474757

Epoch: 54| Step: 0
Training loss: 3.476825009839847
Validation loss: 3.076307873197823

Epoch: 6| Step: 1
Training loss: 4.001305367141239
Validation loss: 3.1356132605675806

Epoch: 6| Step: 2
Training loss: 3.189212862438912
Validation loss: 3.124617328799333

Epoch: 6| Step: 3
Training loss: 3.57545431491502
Validation loss: 3.066377894710219

Epoch: 6| Step: 4
Training loss: 3.7989255289569113
Validation loss: 3.0577736731899687

Epoch: 6| Step: 5
Training loss: 3.4399832339210903
Validation loss: 3.056416845977565

Epoch: 6| Step: 6
Training loss: 3.2735926334156518
Validation loss: 3.0575317253906

Epoch: 6| Step: 7
Training loss: 2.82212775398536
Validation loss: 3.057766352263301

Epoch: 6| Step: 8
Training loss: 3.1375285964209754
Validation loss: 3.0650087142834104

Epoch: 6| Step: 9
Training loss: 3.6909657371913003
Validation loss: 3.059063892186163

Epoch: 6| Step: 10
Training loss: 2.60957637169746
Validation loss: 3.046320084869893

Epoch: 6| Step: 11
Training loss: 3.3997619152857514
Validation loss: 3.0520201802540305

Epoch: 6| Step: 12
Training loss: 2.9158121946371187
Validation loss: 3.0478749895741544

Epoch: 6| Step: 13
Training loss: 2.9036300499092236
Validation loss: 3.0484132857564195

Epoch: 55| Step: 0
Training loss: 3.8720465448907997
Validation loss: 3.0473151062390027

Epoch: 6| Step: 1
Training loss: 3.60673261087411
Validation loss: 3.0462512685984424

Epoch: 6| Step: 2
Training loss: 3.6651878987398243
Validation loss: 3.045357574568914

Epoch: 6| Step: 3
Training loss: 3.2412743442973166
Validation loss: 3.0467302555677027

Epoch: 6| Step: 4
Training loss: 3.6310897187726394
Validation loss: 3.0457632404511528

Epoch: 6| Step: 5
Training loss: 2.5320390954818577
Validation loss: 3.049453933788109

Epoch: 6| Step: 6
Training loss: 3.686590438132871
Validation loss: 3.102450765696514

Epoch: 6| Step: 7
Training loss: 2.9872895234475374
Validation loss: 3.0420766653291635

Epoch: 6| Step: 8
Training loss: 3.062785388338852
Validation loss: 3.041995479281927

Epoch: 6| Step: 9
Training loss: 3.239432540933035
Validation loss: 3.0407521955994166

Epoch: 6| Step: 10
Training loss: 2.83986960796773
Validation loss: 3.0419986615029533

Epoch: 6| Step: 11
Training loss: 2.936749463886093
Validation loss: 3.041165163167604

Epoch: 6| Step: 12
Training loss: 3.477778052945138
Validation loss: 3.0446119092227457

Epoch: 6| Step: 13
Training loss: 3.339162656703744
Validation loss: 3.04801102151413

Epoch: 56| Step: 0
Training loss: 2.585005577863508
Validation loss: 3.056428920094387

Epoch: 6| Step: 1
Training loss: 3.3302339131448058
Validation loss: 3.060729336328296

Epoch: 6| Step: 2
Training loss: 3.118703067403474
Validation loss: 3.066065893963256

Epoch: 6| Step: 3
Training loss: 3.515265688018594
Validation loss: 3.0600201953479154

Epoch: 6| Step: 4
Training loss: 3.1656975183342912
Validation loss: 3.053767973716517

Epoch: 6| Step: 5
Training loss: 2.8969773884510692
Validation loss: 3.0542427668501357

Epoch: 6| Step: 6
Training loss: 3.374858005503641
Validation loss: 3.0507690442888498

Epoch: 6| Step: 7
Training loss: 2.736080052242005
Validation loss: 3.0455058338503096

Epoch: 6| Step: 8
Training loss: 3.3182618035335234
Validation loss: 3.041695742286235

Epoch: 6| Step: 9
Training loss: 3.847915996943183
Validation loss: 3.0389306296859435

Epoch: 6| Step: 10
Training loss: 4.177537596902648
Validation loss: 3.0363319168169203

Epoch: 6| Step: 11
Training loss: 3.222432224694419
Validation loss: 3.0348900067567532

Epoch: 6| Step: 12
Training loss: 3.880820793954552
Validation loss: 3.035884916942978

Epoch: 6| Step: 13
Training loss: 2.2887304279984346
Validation loss: 3.034119612212404

Epoch: 57| Step: 0
Training loss: 2.971425828172654
Validation loss: 3.033021638139216

Epoch: 6| Step: 1
Training loss: 3.1599163251977065
Validation loss: 3.0379079659793247

Epoch: 6| Step: 2
Training loss: 2.6615782310716973
Validation loss: 3.0351470855482887

Epoch: 6| Step: 3
Training loss: 3.3173993424393147
Validation loss: 3.040873839017472

Epoch: 6| Step: 4
Training loss: 4.5633803262977555
Validation loss: 3.0401063868150127

Epoch: 6| Step: 5
Training loss: 3.0604882931534467
Validation loss: 3.036782225993638

Epoch: 6| Step: 6
Training loss: 3.0746392201237756
Validation loss: 3.0286567301310754

Epoch: 6| Step: 7
Training loss: 3.3804187366302623
Validation loss: 3.027280167763082

Epoch: 6| Step: 8
Training loss: 3.4621342985746795
Validation loss: 3.0247174402482813

Epoch: 6| Step: 9
Training loss: 3.1035620251998663
Validation loss: 3.0261109741490597

Epoch: 6| Step: 10
Training loss: 3.7896977157624945
Validation loss: 3.025344215605431

Epoch: 6| Step: 11
Training loss: 2.6623606685663024
Validation loss: 3.0274988672037524

Epoch: 6| Step: 12
Training loss: 3.6497937444650526
Validation loss: 3.026123802021057

Epoch: 6| Step: 13
Training loss: 2.1636865612935856
Validation loss: 3.026018866364026

Epoch: 58| Step: 0
Training loss: 3.762619908852236
Validation loss: 3.0262296523394627

Epoch: 6| Step: 1
Training loss: 2.9175302770983618
Validation loss: 3.0224850668962744

Epoch: 6| Step: 2
Training loss: 2.4593919532899235
Validation loss: 3.02356252188955

Epoch: 6| Step: 3
Training loss: 3.363656371992058
Validation loss: 3.02159812561409

Epoch: 6| Step: 4
Training loss: 3.1638641672021666
Validation loss: 3.0211773301337104

Epoch: 6| Step: 5
Training loss: 3.1042694655087124
Validation loss: 3.0191855061065533

Epoch: 6| Step: 6
Training loss: 3.8064304252668877
Validation loss: 3.021093982035788

Epoch: 6| Step: 7
Training loss: 3.214714260900312
Validation loss: 3.0199850999697793

Epoch: 6| Step: 8
Training loss: 3.1819295640746703
Validation loss: 3.019527059237292

Epoch: 6| Step: 9
Training loss: 3.2864341835710533
Validation loss: 3.0175503796501504

Epoch: 6| Step: 10
Training loss: 3.23198962130627
Validation loss: 3.0143593541186204

Epoch: 6| Step: 11
Training loss: 3.194638654545718
Validation loss: 3.0141979549451676

Epoch: 6| Step: 12
Training loss: 3.3668934988020323
Validation loss: 3.0118232867342094

Epoch: 6| Step: 13
Training loss: 4.1484375
Validation loss: 3.010516959585291

Epoch: 59| Step: 0
Training loss: 3.604192009691577
Validation loss: 3.0118857142291158

Epoch: 6| Step: 1
Training loss: 3.660604508511786
Validation loss: 3.012558611752066

Epoch: 6| Step: 2
Training loss: 3.0566829008158725
Validation loss: 3.0065731935105124

Epoch: 6| Step: 3
Training loss: 3.4272107194378476
Validation loss: 3.00597482047385

Epoch: 6| Step: 4
Training loss: 3.461229161357867
Validation loss: 3.007818202064073

Epoch: 6| Step: 5
Training loss: 3.486060585848032
Validation loss: 3.006353527803252

Epoch: 6| Step: 6
Training loss: 3.3447811640160032
Validation loss: 3.0061558508455204

Epoch: 6| Step: 7
Training loss: 3.08845235986019
Validation loss: 3.006347224335856

Epoch: 6| Step: 8
Training loss: 3.1907617672293247
Validation loss: 3.007188971605046

Epoch: 6| Step: 9
Training loss: 3.176228359228256
Validation loss: 3.007450318368241

Epoch: 6| Step: 10
Training loss: 3.2133008144310793
Validation loss: 3.004288436835964

Epoch: 6| Step: 11
Training loss: 3.4960580152677907
Validation loss: 3.01174865923164

Epoch: 6| Step: 12
Training loss: 2.6514195221008943
Validation loss: 3.0117333807646465

Epoch: 6| Step: 13
Training loss: 2.500410427735596
Validation loss: 3.0067580425808433

Epoch: 60| Step: 0
Training loss: 3.136825312684365
Validation loss: 3.0135741110006284

Epoch: 6| Step: 1
Training loss: 3.599978415106596
Validation loss: 3.0022476272480385

Epoch: 6| Step: 2
Training loss: 2.896792868033213
Validation loss: 3.0005648211162375

Epoch: 6| Step: 3
Training loss: 3.453393157627359
Validation loss: 2.9962035635229096

Epoch: 6| Step: 4
Training loss: 3.0625158815556
Validation loss: 2.9962307921018483

Epoch: 6| Step: 5
Training loss: 3.2553400038474343
Validation loss: 3.0007977040377605

Epoch: 6| Step: 6
Training loss: 2.844417116494165
Validation loss: 3.009575934023974

Epoch: 6| Step: 7
Training loss: 3.3195354674418667
Validation loss: 3.015393050514972

Epoch: 6| Step: 8
Training loss: 3.183154715941039
Validation loss: 3.0013923866154775

Epoch: 6| Step: 9
Training loss: 3.6379148685839877
Validation loss: 2.997185966497491

Epoch: 6| Step: 10
Training loss: 3.8012198247091313
Validation loss: 2.997324222809642

Epoch: 6| Step: 11
Training loss: 2.6214882202756873
Validation loss: 2.9956295213541795

Epoch: 6| Step: 12
Training loss: 3.473098640884178
Validation loss: 2.9931405823570567

Epoch: 6| Step: 13
Training loss: 3.4488576352231632
Validation loss: 2.9903529853171986

Epoch: 61| Step: 0
Training loss: 2.8293327998137743
Validation loss: 2.9908700481942114

Epoch: 6| Step: 1
Training loss: 2.9501890089617366
Validation loss: 2.990893740734842

Epoch: 6| Step: 2
Training loss: 3.4056614358555706
Validation loss: 2.9868257056904235

Epoch: 6| Step: 3
Training loss: 3.268969124037597
Validation loss: 2.9884010616387937

Epoch: 6| Step: 4
Training loss: 3.9483468954471452
Validation loss: 2.98664054142367

Epoch: 6| Step: 5
Training loss: 3.1211679996448183
Validation loss: 2.9873447023787825

Epoch: 6| Step: 6
Training loss: 3.2189252490880103
Validation loss: 2.9872408314721897

Epoch: 6| Step: 7
Training loss: 3.500206804977715
Validation loss: 2.9855451110569384

Epoch: 6| Step: 8
Training loss: 2.809709139123153
Validation loss: 2.9884870886828825

Epoch: 6| Step: 9
Training loss: 3.023245714201461
Validation loss: 2.989338228521909

Epoch: 6| Step: 10
Training loss: 3.2171621016861103
Validation loss: 2.992999408547007

Epoch: 6| Step: 11
Training loss: 2.966951488009561
Validation loss: 2.9905043778865825

Epoch: 6| Step: 12
Training loss: 3.7205788098490604
Validation loss: 2.9901983494531987

Epoch: 6| Step: 13
Training loss: 3.6499920622856887
Validation loss: 2.9884203566456673

Epoch: 62| Step: 0
Training loss: 3.2583775750658326
Validation loss: 2.982110398968714

Epoch: 6| Step: 1
Training loss: 3.116711879001096
Validation loss: 2.981369450800315

Epoch: 6| Step: 2
Training loss: 3.6316571110854556
Validation loss: 2.980453570090749

Epoch: 6| Step: 3
Training loss: 3.3532969292951837
Validation loss: 2.98114338999337

Epoch: 6| Step: 4
Training loss: 2.905685862270764
Validation loss: 2.9795332847337286

Epoch: 6| Step: 5
Training loss: 3.7259947146318333
Validation loss: 2.976663642181009

Epoch: 6| Step: 6
Training loss: 3.0102453128045426
Validation loss: 2.9743277171626894

Epoch: 6| Step: 7
Training loss: 3.424193550450568
Validation loss: 2.9755802348404288

Epoch: 6| Step: 8
Training loss: 3.1881424499524744
Validation loss: 2.974820235913597

Epoch: 6| Step: 9
Training loss: 2.9846018759885373
Validation loss: 2.973780784668113

Epoch: 6| Step: 10
Training loss: 3.664531100307327
Validation loss: 2.974032165554491

Epoch: 6| Step: 11
Training loss: 2.3604119655722804
Validation loss: 2.972486582032803

Epoch: 6| Step: 12
Training loss: 3.183465536145196
Validation loss: 2.9719015063495013

Epoch: 6| Step: 13
Training loss: 3.654663263300086
Validation loss: 2.971762849726509

Epoch: 63| Step: 0
Training loss: 3.53298124562438
Validation loss: 2.9716305879119362

Epoch: 6| Step: 1
Training loss: 3.4183290825688273
Validation loss: 2.9726565397688596

Epoch: 6| Step: 2
Training loss: 2.7378817496779746
Validation loss: 2.9726017695028726

Epoch: 6| Step: 3
Training loss: 3.256908117406675
Validation loss: 2.9737779147982697

Epoch: 6| Step: 4
Training loss: 3.7457494169742835
Validation loss: 2.973667190363545

Epoch: 6| Step: 5
Training loss: 2.939949150943233
Validation loss: 2.973215799676222

Epoch: 6| Step: 6
Training loss: 2.8593426478489103
Validation loss: 2.9764963894737804

Epoch: 6| Step: 7
Training loss: 2.9308181412033467
Validation loss: 2.9815675742052448

Epoch: 6| Step: 8
Training loss: 3.824717098570068
Validation loss: 2.977090631266199

Epoch: 6| Step: 9
Training loss: 3.2831868586003945
Validation loss: 2.9737692198257495

Epoch: 6| Step: 10
Training loss: 3.0712053781822513
Validation loss: 2.9682463740656706

Epoch: 6| Step: 11
Training loss: 3.432631912308389
Validation loss: 2.9693869580472003

Epoch: 6| Step: 12
Training loss: 2.7816296436214656
Validation loss: 2.967263088254852

Epoch: 6| Step: 13
Training loss: 3.4932867790595084
Validation loss: 2.966789353771781

Epoch: 64| Step: 0
Training loss: 3.1313421361467992
Validation loss: 2.965679291725767

Epoch: 6| Step: 1
Training loss: 3.828898698121761
Validation loss: 2.9634287918082824

Epoch: 6| Step: 2
Training loss: 2.571604209911172
Validation loss: 2.9640182592577315

Epoch: 6| Step: 3
Training loss: 3.8758197040491833
Validation loss: 2.9638991754537

Epoch: 6| Step: 4
Training loss: 2.2672201920616337
Validation loss: 2.9637858226091716

Epoch: 6| Step: 5
Training loss: 3.631248875944453
Validation loss: 2.9636697760758786

Epoch: 6| Step: 6
Training loss: 2.9523062403552958
Validation loss: 2.962807874810862

Epoch: 6| Step: 7
Training loss: 3.391018752338438
Validation loss: 2.9632381477914413

Epoch: 6| Step: 8
Training loss: 3.4790880266694106
Validation loss: 2.9629091559978464

Epoch: 6| Step: 9
Training loss: 3.170818885907324
Validation loss: 2.9614889174907866

Epoch: 6| Step: 10
Training loss: 2.473107849632338
Validation loss: 2.960465385809328

Epoch: 6| Step: 11
Training loss: 3.3437351689945625
Validation loss: 2.9603739945856433

Epoch: 6| Step: 12
Training loss: 3.700358455924445
Validation loss: 2.95919042878573

Epoch: 6| Step: 13
Training loss: 2.961244431341884
Validation loss: 2.958568675137386

Epoch: 65| Step: 0
Training loss: 3.2825460145140912
Validation loss: 2.956381416569409

Epoch: 6| Step: 1
Training loss: 3.390515303705058
Validation loss: 2.9572518980628844

Epoch: 6| Step: 2
Training loss: 3.346919188933455
Validation loss: 2.9556284567985642

Epoch: 6| Step: 3
Training loss: 3.9053961469140432
Validation loss: 2.957335939322185

Epoch: 6| Step: 4
Training loss: 2.7563354167548226
Validation loss: 2.9560540596103926

Epoch: 6| Step: 5
Training loss: 3.2382964167222483
Validation loss: 2.954665231661198

Epoch: 6| Step: 6
Training loss: 2.4608435234412593
Validation loss: 2.9554090060404543

Epoch: 6| Step: 7
Training loss: 3.0941890828822083
Validation loss: 2.9555122140104944

Epoch: 6| Step: 8
Training loss: 2.870771532726914
Validation loss: 2.9568643165068496

Epoch: 6| Step: 9
Training loss: 3.6193217825596067
Validation loss: 2.957806276972359

Epoch: 6| Step: 10
Training loss: 3.0339342011248975
Validation loss: 2.9632072834628205

Epoch: 6| Step: 11
Training loss: 3.371471114271222
Validation loss: 2.9612555853970486

Epoch: 6| Step: 12
Training loss: 3.392525979422579
Validation loss: 2.958541216920135

Epoch: 6| Step: 13
Training loss: 3.3168470541303474
Validation loss: 2.951617220001229

Epoch: 66| Step: 0
Training loss: 3.541743528242641
Validation loss: 2.9504182626101745

Epoch: 6| Step: 1
Training loss: 3.2280692584089583
Validation loss: 2.9470008051509224

Epoch: 6| Step: 2
Training loss: 3.074193001897415
Validation loss: 2.943940190552932

Epoch: 6| Step: 3
Training loss: 3.762319293070791
Validation loss: 2.9458307153234973

Epoch: 6| Step: 4
Training loss: 3.5544295332649094
Validation loss: 2.947110188861123

Epoch: 6| Step: 5
Training loss: 2.990779854363752
Validation loss: 2.9466244619179616

Epoch: 6| Step: 6
Training loss: 3.378710931854804
Validation loss: 2.9451857406519064

Epoch: 6| Step: 7
Training loss: 3.235203143998004
Validation loss: 2.9429862987811837

Epoch: 6| Step: 8
Training loss: 3.517501398125583
Validation loss: 2.9434869985996253

Epoch: 6| Step: 9
Training loss: 3.117085008203058
Validation loss: 2.941830177112152

Epoch: 6| Step: 10
Training loss: 3.2284900735812094
Validation loss: 2.9445853744908357

Epoch: 6| Step: 11
Training loss: 2.8585195460336026
Validation loss: 2.9423024322949938

Epoch: 6| Step: 12
Training loss: 2.4621865629757704
Validation loss: 2.944327651883436

Epoch: 6| Step: 13
Training loss: 2.8092089577426806
Validation loss: 2.9423621979322223

Epoch: 67| Step: 0
Training loss: 3.067039084280935
Validation loss: 2.938898478456805

Epoch: 6| Step: 1
Training loss: 2.3952542033507496
Validation loss: 2.9393535884561306

Epoch: 6| Step: 2
Training loss: 3.8283414818413095
Validation loss: 2.939788164559112

Epoch: 6| Step: 3
Training loss: 3.069586670477914
Validation loss: 2.9403411279413696

Epoch: 6| Step: 4
Training loss: 3.0987794626796523
Validation loss: 2.9408737528823568

Epoch: 6| Step: 5
Training loss: 3.352253306939486
Validation loss: 2.937292346059846

Epoch: 6| Step: 6
Training loss: 3.3918191942664393
Validation loss: 2.9384327544096283

Epoch: 6| Step: 7
Training loss: 2.8054548398647423
Validation loss: 2.932662340391853

Epoch: 6| Step: 8
Training loss: 4.001448607397276
Validation loss: 2.931554328983177

Epoch: 6| Step: 9
Training loss: 2.858534725942462
Validation loss: 2.932560596793753

Epoch: 6| Step: 10
Training loss: 2.939794415402884
Validation loss: 2.9313210462816395

Epoch: 6| Step: 11
Training loss: 3.3897196180584452
Validation loss: 2.9310822155468736

Epoch: 6| Step: 12
Training loss: 3.1958520708856932
Validation loss: 2.9292626680104252

Epoch: 6| Step: 13
Training loss: 3.465033662530669
Validation loss: 2.932804697002882

Epoch: 68| Step: 0
Training loss: 3.134397186778872
Validation loss: 2.953487486196613

Epoch: 6| Step: 1
Training loss: 3.992984102503625
Validation loss: 2.9861151671773563

Epoch: 6| Step: 2
Training loss: 2.614094560589594
Validation loss: 3.0047626666435345

Epoch: 6| Step: 3
Training loss: 3.173047379931943
Validation loss: 3.004060728118939

Epoch: 6| Step: 4
Training loss: 3.0058105147507117
Validation loss: 3.003590117392378

Epoch: 6| Step: 5
Training loss: 2.387625214653551
Validation loss: 2.9991575257934704

Epoch: 6| Step: 6
Training loss: 3.6001317953780245
Validation loss: 2.9980332497484903

Epoch: 6| Step: 7
Training loss: 3.2875439543015763
Validation loss: 3.000951115433208

Epoch: 6| Step: 8
Training loss: 3.5531410290734806
Validation loss: 2.9970904789231994

Epoch: 6| Step: 9
Training loss: 2.9002577831531173
Validation loss: 2.994159629580641

Epoch: 6| Step: 10
Training loss: 2.900165053307446
Validation loss: 2.9694458712089995

Epoch: 6| Step: 11
Training loss: 3.5577765488514896
Validation loss: 2.9363600614252756

Epoch: 6| Step: 12
Training loss: 3.5845630812583713
Validation loss: 2.9486909692486

Epoch: 6| Step: 13
Training loss: 3.7105268070438484
Validation loss: 2.9623228698005915

Epoch: 69| Step: 0
Training loss: 3.4473599602000413
Validation loss: 2.925075122523108

Epoch: 6| Step: 1
Training loss: 2.8772045473662895
Validation loss: 2.9279981110716506

Epoch: 6| Step: 2
Training loss: 2.856341143933929
Validation loss: 2.9308418967101244

Epoch: 6| Step: 3
Training loss: 3.5505682584462086
Validation loss: 2.9274859612218673

Epoch: 6| Step: 4
Training loss: 3.30853811890583
Validation loss: 2.922346371346916

Epoch: 6| Step: 5
Training loss: 2.983982080288177
Validation loss: 2.9300359362059805

Epoch: 6| Step: 6
Training loss: 3.259927552477187
Validation loss: 2.922137436578462

Epoch: 6| Step: 7
Training loss: 3.2634955220999022
Validation loss: 2.9238087597185394

Epoch: 6| Step: 8
Training loss: 2.5415696193323782
Validation loss: 2.922545081528926

Epoch: 6| Step: 9
Training loss: 3.9399125715905607
Validation loss: 2.933669933064336

Epoch: 6| Step: 10
Training loss: 3.409405987368847
Validation loss: 2.927577443013875

Epoch: 6| Step: 11
Training loss: 2.9315719850600406
Validation loss: 2.933760845399641

Epoch: 6| Step: 12
Training loss: 3.0913252142406815
Validation loss: 2.934111980904596

Epoch: 6| Step: 13
Training loss: 3.269586086383035
Validation loss: 2.933424071325993

Epoch: 70| Step: 0
Training loss: 2.7379975654920035
Validation loss: 2.9149011152316917

Epoch: 6| Step: 1
Training loss: 2.5242270542434393
Validation loss: 2.911738762558291

Epoch: 6| Step: 2
Training loss: 2.869093757594576
Validation loss: 2.911165379900311

Epoch: 6| Step: 3
Training loss: 2.9637542451709864
Validation loss: 2.913081681609362

Epoch: 6| Step: 4
Training loss: 3.549988308739551
Validation loss: 2.9114227078478763

Epoch: 6| Step: 5
Training loss: 3.0344565823526137
Validation loss: 2.9127503859727875

Epoch: 6| Step: 6
Training loss: 3.653795119172418
Validation loss: 2.9131770821186773

Epoch: 6| Step: 7
Training loss: 3.143768862597565
Validation loss: 2.912341723911554

Epoch: 6| Step: 8
Training loss: 3.3042896653541014
Validation loss: 2.913311761839246

Epoch: 6| Step: 9
Training loss: 3.51143847949989
Validation loss: 2.91339104120091

Epoch: 6| Step: 10
Training loss: 3.29674598477571
Validation loss: 2.910842421498798

Epoch: 6| Step: 11
Training loss: 3.0952067943010375
Validation loss: 2.9078222550007577

Epoch: 6| Step: 12
Training loss: 3.5885567999282157
Validation loss: 2.9067200787639824

Epoch: 6| Step: 13
Training loss: 3.518570136831195
Validation loss: 2.9043107722919554

Epoch: 71| Step: 0
Training loss: 2.978035309632833
Validation loss: 2.9051543362599377

Epoch: 6| Step: 1
Training loss: 3.208889867559949
Validation loss: 2.9037386041704845

Epoch: 6| Step: 2
Training loss: 3.3953652712657267
Validation loss: 2.9034548967026206

Epoch: 6| Step: 3
Training loss: 2.459428597124346
Validation loss: 2.901612422257713

Epoch: 6| Step: 4
Training loss: 3.5041664392665526
Validation loss: 2.9019539075678145

Epoch: 6| Step: 5
Training loss: 2.8605512690611308
Validation loss: 2.8989826053884684

Epoch: 6| Step: 6
Training loss: 2.624329980989642
Validation loss: 2.8982472327575177

Epoch: 6| Step: 7
Training loss: 3.6452029019201375
Validation loss: 2.9059865247486862

Epoch: 6| Step: 8
Training loss: 3.371384980494892
Validation loss: 2.906254117700132

Epoch: 6| Step: 9
Training loss: 3.95929510913628
Validation loss: 2.9077893142501856

Epoch: 6| Step: 10
Training loss: 3.276208401284549
Validation loss: 2.9074501896428324

Epoch: 6| Step: 11
Training loss: 2.7017535661123375
Validation loss: 2.8983050356653464

Epoch: 6| Step: 12
Training loss: 3.594209724543957
Validation loss: 2.901124313507795

Epoch: 6| Step: 13
Training loss: 2.394022503274625
Validation loss: 2.899102278519907

Epoch: 72| Step: 0
Training loss: 3.1643867985812286
Validation loss: 2.8966434482016004

Epoch: 6| Step: 1
Training loss: 2.926149882380476
Validation loss: 2.895562169347239

Epoch: 6| Step: 2
Training loss: 2.657131273270772
Validation loss: 2.8973055679814506

Epoch: 6| Step: 3
Training loss: 2.609307933562246
Validation loss: 2.893025568981124

Epoch: 6| Step: 4
Training loss: 3.351452094262533
Validation loss: 2.897287784490407

Epoch: 6| Step: 5
Training loss: 3.305526879308214
Validation loss: 2.896877907506628

Epoch: 6| Step: 6
Training loss: 3.4926956796952573
Validation loss: 2.8973985769228228

Epoch: 6| Step: 7
Training loss: 3.0225742103168547
Validation loss: 2.898598166796883

Epoch: 6| Step: 8
Training loss: 2.7609095487275352
Validation loss: 2.89793560013369

Epoch: 6| Step: 9
Training loss: 3.4218900497314597
Validation loss: 2.899502086080023

Epoch: 6| Step: 10
Training loss: 3.3710003925007537
Validation loss: 2.896173788404176

Epoch: 6| Step: 11
Training loss: 3.1661871664180765
Validation loss: 2.8953348384218764

Epoch: 6| Step: 12
Training loss: 3.7475080475520377
Validation loss: 2.8948310403530217

Epoch: 6| Step: 13
Training loss: 3.764530893511908
Validation loss: 2.8935790395298064

Epoch: 73| Step: 0
Training loss: 3.3216383497144815
Validation loss: 2.8923404675156257

Epoch: 6| Step: 1
Training loss: 3.20270874296061
Validation loss: 2.8912083527998833

Epoch: 6| Step: 2
Training loss: 3.1911686746983428
Validation loss: 2.889067895006279

Epoch: 6| Step: 3
Training loss: 3.158851986239887
Validation loss: 2.887673448150142

Epoch: 6| Step: 4
Training loss: 3.5521762570991635
Validation loss: 2.8883287918487497

Epoch: 6| Step: 5
Training loss: 3.0484677577704535
Validation loss: 2.8881459832578216

Epoch: 6| Step: 6
Training loss: 3.2117050255974244
Validation loss: 2.8847269528345056

Epoch: 6| Step: 7
Training loss: 2.9589518227376104
Validation loss: 2.8825663399715267

Epoch: 6| Step: 8
Training loss: 3.1578718494121274
Validation loss: 2.883507557941802

Epoch: 6| Step: 9
Training loss: 2.7272803118629185
Validation loss: 2.8832649787152

Epoch: 6| Step: 10
Training loss: 3.547115905915678
Validation loss: 2.8847420339387404

Epoch: 6| Step: 11
Training loss: 2.3034149277289724
Validation loss: 2.8847935286058637

Epoch: 6| Step: 12
Training loss: 3.557589174548304
Validation loss: 2.893770614795464

Epoch: 6| Step: 13
Training loss: 3.676982298301351
Validation loss: 2.8956700955731103

Epoch: 74| Step: 0
Training loss: 2.562470133537602
Validation loss: 2.8789710325047606

Epoch: 6| Step: 1
Training loss: 3.0757674275291866
Validation loss: 2.882788284679824

Epoch: 6| Step: 2
Training loss: 2.7577462769248853
Validation loss: 2.8818502847057896

Epoch: 6| Step: 3
Training loss: 3.4752865625138534
Validation loss: 2.8826879672366115

Epoch: 6| Step: 4
Training loss: 3.722754109908657
Validation loss: 2.88311185498896

Epoch: 6| Step: 5
Training loss: 2.9984115527900412
Validation loss: 2.886368231490379

Epoch: 6| Step: 6
Training loss: 2.5517198783895845
Validation loss: 2.8980339549267673

Epoch: 6| Step: 7
Training loss: 3.6896186819740033
Validation loss: 2.895632645623167

Epoch: 6| Step: 8
Training loss: 2.9931288550641413
Validation loss: 2.8831092176436246

Epoch: 6| Step: 9
Training loss: 3.4740126270510525
Validation loss: 2.8793364168247044

Epoch: 6| Step: 10
Training loss: 3.659682529209277
Validation loss: 2.877305772342573

Epoch: 6| Step: 11
Training loss: 3.082375317455071
Validation loss: 2.878329392570773

Epoch: 6| Step: 12
Training loss: 3.3052716832301967
Validation loss: 2.8756439456213565

Epoch: 6| Step: 13
Training loss: 2.7094417260213075
Validation loss: 2.8740035189798454

Epoch: 75| Step: 0
Training loss: 3.018062732881299
Validation loss: 2.874644451439789

Epoch: 6| Step: 1
Training loss: 3.6133050041448915
Validation loss: 2.8916074210250398

Epoch: 6| Step: 2
Training loss: 3.6949916966490823
Validation loss: 2.90098769203865

Epoch: 6| Step: 3
Training loss: 3.5168090182836975
Validation loss: 2.8780484474010266

Epoch: 6| Step: 4
Training loss: 3.093915376192682
Validation loss: 2.8774177021280942

Epoch: 6| Step: 5
Training loss: 2.7778009180588614
Validation loss: 2.8735030282070735

Epoch: 6| Step: 6
Training loss: 3.037753963449979
Validation loss: 2.8707202419803

Epoch: 6| Step: 7
Training loss: 3.237598379400445
Validation loss: 2.8714209612255694

Epoch: 6| Step: 8
Training loss: 3.3320378329177354
Validation loss: 2.871005629615217

Epoch: 6| Step: 9
Training loss: 3.41712029089678
Validation loss: 2.8665717103727166

Epoch: 6| Step: 10
Training loss: 2.6840556051290294
Validation loss: 2.867404511637174

Epoch: 6| Step: 11
Training loss: 3.0201398031452107
Validation loss: 2.8739928469492417

Epoch: 6| Step: 12
Training loss: 2.6893683747766914
Validation loss: 2.8729965145204917

Epoch: 6| Step: 13
Training loss: 2.9470332858636463
Validation loss: 2.874387378882033

Epoch: 76| Step: 0
Training loss: 2.8461134594452915
Validation loss: 2.875908376852492

Epoch: 6| Step: 1
Training loss: 3.547009167255249
Validation loss: 2.878309241990054

Epoch: 6| Step: 2
Training loss: 3.207439215449107
Validation loss: 2.8699505117348045

Epoch: 6| Step: 3
Training loss: 3.932563351304582
Validation loss: 2.8638525323542154

Epoch: 6| Step: 4
Training loss: 3.154510925399815
Validation loss: 2.860350497733808

Epoch: 6| Step: 5
Training loss: 3.4275117894254414
Validation loss: 2.8644450337575194

Epoch: 6| Step: 6
Training loss: 3.8536529748552026
Validation loss: 2.860519819258885

Epoch: 6| Step: 7
Training loss: 2.9099891153767787
Validation loss: 2.863331722260167

Epoch: 6| Step: 8
Training loss: 1.8895053543212808
Validation loss: 2.862141859756021

Epoch: 6| Step: 9
Training loss: 2.7372621824875067
Validation loss: 2.8600946286620674

Epoch: 6| Step: 10
Training loss: 3.074151121992803
Validation loss: 2.858668688775613

Epoch: 6| Step: 11
Training loss: 3.107730296310234
Validation loss: 2.859129177594726

Epoch: 6| Step: 12
Training loss: 2.983099380213714
Validation loss: 2.8610008266743825

Epoch: 6| Step: 13
Training loss: 3.1911785366664867
Validation loss: 2.863948566587914

Epoch: 77| Step: 0
Training loss: 2.518456518146614
Validation loss: 2.8621599744780304

Epoch: 6| Step: 1
Training loss: 3.9565077470221253
Validation loss: 2.8584790569139895

Epoch: 6| Step: 2
Training loss: 2.910048432881121
Validation loss: 2.8578453767031475

Epoch: 6| Step: 3
Training loss: 3.03624039266424
Validation loss: 2.8628731451746368

Epoch: 6| Step: 4
Training loss: 3.218085359265133
Validation loss: 2.872322576407522

Epoch: 6| Step: 5
Training loss: 2.8209105304051274
Validation loss: 2.8704912660881794

Epoch: 6| Step: 6
Training loss: 3.0070987003062917
Validation loss: 2.8726423100884393

Epoch: 6| Step: 7
Training loss: 3.4913408247254423
Validation loss: 2.855948656642079

Epoch: 6| Step: 8
Training loss: 3.279658631029148
Validation loss: 2.854310729904

Epoch: 6| Step: 9
Training loss: 3.721696727976929
Validation loss: 2.8520617192043516

Epoch: 6| Step: 10
Training loss: 3.1087908172075216
Validation loss: 2.8559134604893655

Epoch: 6| Step: 11
Training loss: 2.487971743223899
Validation loss: 2.855337567592577

Epoch: 6| Step: 12
Training loss: 3.1109670272644423
Validation loss: 2.8554945167517025

Epoch: 6| Step: 13
Training loss: 3.366850019567289
Validation loss: 2.8555724009563934

Epoch: 78| Step: 0
Training loss: 3.5137531637953088
Validation loss: 2.856390069455926

Epoch: 6| Step: 1
Training loss: 2.779666835800308
Validation loss: 2.856490053987436

Epoch: 6| Step: 2
Training loss: 2.8805011694676828
Validation loss: 2.8556969365746383

Epoch: 6| Step: 3
Training loss: 3.5190529620040745
Validation loss: 2.8563909409386774

Epoch: 6| Step: 4
Training loss: 2.833551585449318
Validation loss: 2.8545014918777856

Epoch: 6| Step: 5
Training loss: 3.374773229821845
Validation loss: 2.855858941457653

Epoch: 6| Step: 6
Training loss: 2.9254440296630047
Validation loss: 2.851791863032568

Epoch: 6| Step: 7
Training loss: 2.625364732380502
Validation loss: 2.85442974230564

Epoch: 6| Step: 8
Training loss: 3.7658714118839383
Validation loss: 2.855353836434659

Epoch: 6| Step: 9
Training loss: 3.607774520019882
Validation loss: 2.855306631397409

Epoch: 6| Step: 10
Training loss: 3.156700479822488
Validation loss: 2.8632059070449634

Epoch: 6| Step: 11
Training loss: 2.756734231984189
Validation loss: 2.8674321702405834

Epoch: 6| Step: 12
Training loss: 2.906995288080019
Validation loss: 2.8776200488893027

Epoch: 6| Step: 13
Training loss: 3.271003637719413
Validation loss: 2.862059980212174

Epoch: 79| Step: 0
Training loss: 3.066033174209634
Validation loss: 2.86354360257224

Epoch: 6| Step: 1
Training loss: 2.443946627538256
Validation loss: 2.853208079247904

Epoch: 6| Step: 2
Training loss: 3.3302980590862306
Validation loss: 2.849328763290405

Epoch: 6| Step: 3
Training loss: 3.5003023017031123
Validation loss: 2.8461278957510983

Epoch: 6| Step: 4
Training loss: 2.990885239522107
Validation loss: 2.845875965533506

Epoch: 6| Step: 5
Training loss: 3.5722319870955896
Validation loss: 2.843181430213708

Epoch: 6| Step: 6
Training loss: 3.155345522766404
Validation loss: 2.84254883472731

Epoch: 6| Step: 7
Training loss: 3.270357781765162
Validation loss: 2.8449874361845975

Epoch: 6| Step: 8
Training loss: 3.622507751330184
Validation loss: 2.843032609398277

Epoch: 6| Step: 9
Training loss: 2.527666734578305
Validation loss: 2.8438042589645898

Epoch: 6| Step: 10
Training loss: 2.6950702945409586
Validation loss: 2.8442367394985495

Epoch: 6| Step: 11
Training loss: 3.5483844250867524
Validation loss: 2.84280115899474

Epoch: 6| Step: 12
Training loss: 3.12082484761516
Validation loss: 2.8416479311522607

Epoch: 6| Step: 13
Training loss: 2.907258053763772
Validation loss: 2.8416734822076375

Epoch: 80| Step: 0
Training loss: 3.474975772471327
Validation loss: 2.83798614662564

Epoch: 6| Step: 1
Training loss: 2.82026152419414
Validation loss: 2.839152212073974

Epoch: 6| Step: 2
Training loss: 2.749033931624064
Validation loss: 2.8386401623453446

Epoch: 6| Step: 3
Training loss: 3.6345578174744246
Validation loss: 2.835994929488661

Epoch: 6| Step: 4
Training loss: 3.114184163688958
Validation loss: 2.8356089679518015

Epoch: 6| Step: 5
Training loss: 2.589837305857839
Validation loss: 2.8347472997342638

Epoch: 6| Step: 6
Training loss: 3.32949342488758
Validation loss: 2.838959807370953

Epoch: 6| Step: 7
Training loss: 2.922035580062697
Validation loss: 2.858338059791836

Epoch: 6| Step: 8
Training loss: 3.628295058569997
Validation loss: 2.8693998955364535

Epoch: 6| Step: 9
Training loss: 3.1272268372066034
Validation loss: 2.842077304885116

Epoch: 6| Step: 10
Training loss: 3.472444783177523
Validation loss: 2.8334939716290712

Epoch: 6| Step: 11
Training loss: 2.833277271688495
Validation loss: 2.8307728142765733

Epoch: 6| Step: 12
Training loss: 2.9484226794494535
Validation loss: 2.832740687930158

Epoch: 6| Step: 13
Training loss: 3.2114686549826446
Validation loss: 2.832698078228286

Epoch: 81| Step: 0
Training loss: 3.5126419636013466
Validation loss: 2.835155941982199

Epoch: 6| Step: 1
Training loss: 2.541319234480014
Validation loss: 2.8428318696584083

Epoch: 6| Step: 2
Training loss: 3.278727697310399
Validation loss: 2.851992671456231

Epoch: 6| Step: 3
Training loss: 2.648487011832088
Validation loss: 2.8463721903214454

Epoch: 6| Step: 4
Training loss: 3.1971674899989906
Validation loss: 2.835470055916267

Epoch: 6| Step: 5
Training loss: 2.86916073453853
Validation loss: 2.8348120305872544

Epoch: 6| Step: 6
Training loss: 2.1755695342741665
Validation loss: 2.832380171268896

Epoch: 6| Step: 7
Training loss: 3.633540517400261
Validation loss: 2.8296918565289157

Epoch: 6| Step: 8
Training loss: 3.2086534381717673
Validation loss: 2.8298776721014693

Epoch: 6| Step: 9
Training loss: 3.6818620933885406
Validation loss: 2.825856957031327

Epoch: 6| Step: 10
Training loss: 3.0621097861055024
Validation loss: 2.827462451817115

Epoch: 6| Step: 11
Training loss: 3.15415099193419
Validation loss: 2.825884846288536

Epoch: 6| Step: 12
Training loss: 3.1187692706596364
Validation loss: 2.825334843131521

Epoch: 6| Step: 13
Training loss: 3.8458401339309978
Validation loss: 2.824166483982582

Epoch: 82| Step: 0
Training loss: 3.232083453300159
Validation loss: 2.8316610897928425

Epoch: 6| Step: 1
Training loss: 3.129206306081155
Validation loss: 2.8600418350592896

Epoch: 6| Step: 2
Training loss: 2.958428358960639
Validation loss: 2.8766724375398827

Epoch: 6| Step: 3
Training loss: 2.3102292433434646
Validation loss: 2.8876526791727004

Epoch: 6| Step: 4
Training loss: 2.651185896771617
Validation loss: 2.9077923188979873

Epoch: 6| Step: 5
Training loss: 2.274945365333569
Validation loss: 2.917427270278718

Epoch: 6| Step: 6
Training loss: 3.6956540488216394
Validation loss: 2.908007276287918

Epoch: 6| Step: 7
Training loss: 3.2825556019521174
Validation loss: 2.826128306309105

Epoch: 6| Step: 8
Training loss: 3.774241486190509
Validation loss: 2.8187086880802052

Epoch: 6| Step: 9
Training loss: 3.3360389854842674
Validation loss: 2.8228280016777094

Epoch: 6| Step: 10
Training loss: 3.4956597255903294
Validation loss: 2.8248968515196493

Epoch: 6| Step: 11
Training loss: 3.524932476506213
Validation loss: 2.8356463282468645

Epoch: 6| Step: 12
Training loss: 2.925801622144111
Validation loss: 2.8496995730138646

Epoch: 6| Step: 13
Training loss: 2.9318642629452425
Validation loss: 2.840104966577344

Epoch: 83| Step: 0
Training loss: 3.5301421461582136
Validation loss: 2.8377871611413923

Epoch: 6| Step: 1
Training loss: 3.078067062529773
Validation loss: 2.8254345329438615

Epoch: 6| Step: 2
Training loss: 3.685383205287072
Validation loss: 2.822228543576972

Epoch: 6| Step: 3
Training loss: 2.936870263959009
Validation loss: 2.82037688587368

Epoch: 6| Step: 4
Training loss: 3.0092941003939804
Validation loss: 2.818780493802676

Epoch: 6| Step: 5
Training loss: 2.740742794624147
Validation loss: 2.817497103718429

Epoch: 6| Step: 6
Training loss: 3.392427167679904
Validation loss: 2.816540027532849

Epoch: 6| Step: 7
Training loss: 2.2010591168365576
Validation loss: 2.8174407530474572

Epoch: 6| Step: 8
Training loss: 3.2434811872110485
Validation loss: 2.818551626069643

Epoch: 6| Step: 9
Training loss: 3.322966253375038
Validation loss: 2.8187388072159862

Epoch: 6| Step: 10
Training loss: 3.161335389178297
Validation loss: 2.8173622897079857

Epoch: 6| Step: 11
Training loss: 3.881956071254278
Validation loss: 2.818137706046521

Epoch: 6| Step: 12
Training loss: 2.7272192920883116
Validation loss: 2.8168100399811205

Epoch: 6| Step: 13
Training loss: 1.8549177455916386
Validation loss: 2.8177770605825323

Epoch: 84| Step: 0
Training loss: 3.419799314488994
Validation loss: 2.818733495735767

Epoch: 6| Step: 1
Training loss: 3.7039054981642088
Validation loss: 2.810307089696626

Epoch: 6| Step: 2
Training loss: 2.2949743386622883
Validation loss: 2.8080443296514854

Epoch: 6| Step: 3
Training loss: 2.9197128374171517
Validation loss: 2.80913421059976

Epoch: 6| Step: 4
Training loss: 3.755337286581104
Validation loss: 2.80586911599006

Epoch: 6| Step: 5
Training loss: 2.668978185971167
Validation loss: 2.806066810937121

Epoch: 6| Step: 6
Training loss: 3.59273348820036
Validation loss: 2.806402864587956

Epoch: 6| Step: 7
Training loss: 2.94149849026395
Validation loss: 2.8152667202206327

Epoch: 6| Step: 8
Training loss: 3.056073354909194
Validation loss: 2.8286054256741915

Epoch: 6| Step: 9
Training loss: 3.5350471268983235
Validation loss: 2.8336320088693743

Epoch: 6| Step: 10
Training loss: 3.1432021465683517
Validation loss: 2.8415557715071382

Epoch: 6| Step: 11
Training loss: 2.3773908125938537
Validation loss: 2.8141185519533334

Epoch: 6| Step: 12
Training loss: 2.6439395845583222
Validation loss: 2.8053543450239173

Epoch: 6| Step: 13
Training loss: 3.1176001865957597
Validation loss: 2.808686993945267

Epoch: 85| Step: 0
Training loss: 3.388885755137956
Validation loss: 2.8052026620191297

Epoch: 6| Step: 1
Training loss: 3.6482673294930414
Validation loss: 2.8047838946591037

Epoch: 6| Step: 2
Training loss: 3.4470449922755537
Validation loss: 2.803720638992304

Epoch: 6| Step: 3
Training loss: 2.579210642335484
Validation loss: 2.805520287693479

Epoch: 6| Step: 4
Training loss: 2.7798039824174765
Validation loss: 2.8041906392873903

Epoch: 6| Step: 5
Training loss: 3.432161798562421
Validation loss: 2.8040420073247248

Epoch: 6| Step: 6
Training loss: 3.275710161394381
Validation loss: 2.8015934276905727

Epoch: 6| Step: 7
Training loss: 2.888572995529192
Validation loss: 2.800074556782

Epoch: 6| Step: 8
Training loss: 3.319379177187843
Validation loss: 2.8008914115262757

Epoch: 6| Step: 9
Training loss: 2.747984928173062
Validation loss: 2.800104053273489

Epoch: 6| Step: 10
Training loss: 2.724487389462347
Validation loss: 2.7991445360367395

Epoch: 6| Step: 11
Training loss: 3.4609950902551865
Validation loss: 2.80148295884233

Epoch: 6| Step: 12
Training loss: 3.007777939635051
Validation loss: 2.8018744145649275

Epoch: 6| Step: 13
Training loss: 2.2007468083089945
Validation loss: 2.7998145142365365

Epoch: 86| Step: 0
Training loss: 2.740307546605251
Validation loss: 2.7978451979493046

Epoch: 6| Step: 1
Training loss: 2.707812792320698
Validation loss: 2.8019991629247802

Epoch: 6| Step: 2
Training loss: 3.8223685444195037
Validation loss: 2.8058155067583375

Epoch: 6| Step: 3
Training loss: 3.1146511380949446
Validation loss: 2.806553256879581

Epoch: 6| Step: 4
Training loss: 2.701436744882764
Validation loss: 2.7994094486622254

Epoch: 6| Step: 5
Training loss: 2.843693826979973
Validation loss: 2.7972751921648538

Epoch: 6| Step: 6
Training loss: 3.186533014561918
Validation loss: 2.7937958069709885

Epoch: 6| Step: 7
Training loss: 4.024740715442187
Validation loss: 2.790622542247837

Epoch: 6| Step: 8
Training loss: 2.3140902850474685
Validation loss: 2.7935208784057814

Epoch: 6| Step: 9
Training loss: 3.4854652512366444
Validation loss: 2.7917869274430887

Epoch: 6| Step: 10
Training loss: 3.017460081884127
Validation loss: 2.7909337218630488

Epoch: 6| Step: 11
Training loss: 3.633515058283366
Validation loss: 2.7881167460440963

Epoch: 6| Step: 12
Training loss: 2.800107824429298
Validation loss: 2.7967048318728107

Epoch: 6| Step: 13
Training loss: 1.8529420373150618
Validation loss: 2.806427211004754

Epoch: 87| Step: 0
Training loss: 2.1185152176937736
Validation loss: 2.809363490556562

Epoch: 6| Step: 1
Training loss: 3.19158404635936
Validation loss: 2.822583043555956

Epoch: 6| Step: 2
Training loss: 2.342424755536784
Validation loss: 2.814061457657972

Epoch: 6| Step: 3
Training loss: 3.7390824658139366
Validation loss: 2.800491921037543

Epoch: 6| Step: 4
Training loss: 2.6502917614955197
Validation loss: 2.793382956111803

Epoch: 6| Step: 5
Training loss: 3.549925714709542
Validation loss: 2.791623554316205

Epoch: 6| Step: 6
Training loss: 2.9650208190392906
Validation loss: 2.7883957406855133

Epoch: 6| Step: 7
Training loss: 3.427596373646519
Validation loss: 2.7858707986588422

Epoch: 6| Step: 8
Training loss: 2.993668391443389
Validation loss: 2.783275138414112

Epoch: 6| Step: 9
Training loss: 2.4473517449182682
Validation loss: 2.78631526904452

Epoch: 6| Step: 10
Training loss: 3.2844928520683503
Validation loss: 2.78198777161439

Epoch: 6| Step: 11
Training loss: 3.4119856953382546
Validation loss: 2.786310252748812

Epoch: 6| Step: 12
Training loss: 3.4917101096376966
Validation loss: 2.782584726989365

Epoch: 6| Step: 13
Training loss: 3.3053725233792557
Validation loss: 2.785791230794626

Epoch: 88| Step: 0
Training loss: 3.185973755694271
Validation loss: 2.7814842845337138

Epoch: 6| Step: 1
Training loss: 2.438383773608798
Validation loss: 2.7806243137388673

Epoch: 6| Step: 2
Training loss: 2.9590562465487635
Validation loss: 2.7903744739394716

Epoch: 6| Step: 3
Training loss: 3.0271750520033014
Validation loss: 2.785115499767454

Epoch: 6| Step: 4
Training loss: 2.718092477147338
Validation loss: 2.7805039614011977

Epoch: 6| Step: 5
Training loss: 3.7545997383951115
Validation loss: 2.778814994059999

Epoch: 6| Step: 6
Training loss: 2.7645679759959942
Validation loss: 2.774105572861626

Epoch: 6| Step: 7
Training loss: 3.3191964461625005
Validation loss: 2.7723929911424148

Epoch: 6| Step: 8
Training loss: 2.996391510372945
Validation loss: 2.7719420044579137

Epoch: 6| Step: 9
Training loss: 3.415421483851373
Validation loss: 2.771825986540454

Epoch: 6| Step: 10
Training loss: 3.0467609090718524
Validation loss: 2.7718561138199584

Epoch: 6| Step: 11
Training loss: 3.4523081093731274
Validation loss: 2.7729208225056907

Epoch: 6| Step: 12
Training loss: 2.9008078535130397
Validation loss: 2.771416286296475

Epoch: 6| Step: 13
Training loss: 3.1028763993209414
Validation loss: 2.775926599855755

Epoch: 89| Step: 0
Training loss: 3.404137752663856
Validation loss: 2.771218676391092

Epoch: 6| Step: 1
Training loss: 3.1707833953280207
Validation loss: 2.7711355627566916

Epoch: 6| Step: 2
Training loss: 1.9400293391260663
Validation loss: 2.7708917581260053

Epoch: 6| Step: 3
Training loss: 3.5483349723567255
Validation loss: 2.770872389834021

Epoch: 6| Step: 4
Training loss: 3.188109246166248
Validation loss: 2.772051358844241

Epoch: 6| Step: 5
Training loss: 3.0069578864012745
Validation loss: 2.773305937139297

Epoch: 6| Step: 6
Training loss: 2.7037550351840682
Validation loss: 2.770101785755829

Epoch: 6| Step: 7
Training loss: 3.4864632545590704
Validation loss: 2.77103863132214

Epoch: 6| Step: 8
Training loss: 2.780552122876359
Validation loss: 2.775338038008187

Epoch: 6| Step: 9
Training loss: 3.5567299141901563
Validation loss: 2.7774605379832416

Epoch: 6| Step: 10
Training loss: 3.1368003825091377
Validation loss: 2.7706814021954633

Epoch: 6| Step: 11
Training loss: 3.433681656164611
Validation loss: 2.765808837223736

Epoch: 6| Step: 12
Training loss: 2.531154772062162
Validation loss: 2.7657071613472994

Epoch: 6| Step: 13
Training loss: 2.917380726916892
Validation loss: 2.768997162869491

Epoch: 90| Step: 0
Training loss: 3.071236119625164
Validation loss: 2.776934974612513

Epoch: 6| Step: 1
Training loss: 3.3960386030880967
Validation loss: 2.78317878912559

Epoch: 6| Step: 2
Training loss: 3.4886683540809127
Validation loss: 2.77372742910638

Epoch: 6| Step: 3
Training loss: 3.181983812157906
Validation loss: 2.770159426081292

Epoch: 6| Step: 4
Training loss: 3.896180992457713
Validation loss: 2.763434852052349

Epoch: 6| Step: 5
Training loss: 2.6580138689171577
Validation loss: 2.7601431746929963

Epoch: 6| Step: 6
Training loss: 2.993065448773155
Validation loss: 2.7604240363207047

Epoch: 6| Step: 7
Training loss: 2.980154198362982
Validation loss: 2.7600589705414174

Epoch: 6| Step: 8
Training loss: 2.2304051485363443
Validation loss: 2.762046380867393

Epoch: 6| Step: 9
Training loss: 2.997454517009886
Validation loss: 2.767515821484587

Epoch: 6| Step: 10
Training loss: 2.825551078857177
Validation loss: 2.775001079814464

Epoch: 6| Step: 11
Training loss: 3.4147532307730812
Validation loss: 2.7885061956847594

Epoch: 6| Step: 12
Training loss: 2.1833107207003315
Validation loss: 2.8108379352377066

Epoch: 6| Step: 13
Training loss: 3.54136316831595
Validation loss: 2.824013904124275

Epoch: 91| Step: 0
Training loss: 3.1607908311985575
Validation loss: 2.792505986331415

Epoch: 6| Step: 1
Training loss: 2.7199858564121304
Validation loss: 2.76805807969911

Epoch: 6| Step: 2
Training loss: 3.306203075285064
Validation loss: 2.7572859213411482

Epoch: 6| Step: 3
Training loss: 2.7738000767069626
Validation loss: 2.7552718645201675

Epoch: 6| Step: 4
Training loss: 2.8149281510556303
Validation loss: 2.7595741278629276

Epoch: 6| Step: 5
Training loss: 3.241098391057818
Validation loss: 2.7604219717917813

Epoch: 6| Step: 6
Training loss: 3.137572821877677
Validation loss: 2.763319422328878

Epoch: 6| Step: 7
Training loss: 2.7456347758889565
Validation loss: 2.7661832905596135

Epoch: 6| Step: 8
Training loss: 2.6043768429183207
Validation loss: 2.7648956966837566

Epoch: 6| Step: 9
Training loss: 3.1942026313994942
Validation loss: 2.7675132323832448

Epoch: 6| Step: 10
Training loss: 3.126363533090808
Validation loss: 2.766380856109138

Epoch: 6| Step: 11
Training loss: 3.2579310553405727
Validation loss: 2.767176352500274

Epoch: 6| Step: 12
Training loss: 3.5923387493135075
Validation loss: 2.7649483190941577

Epoch: 6| Step: 13
Training loss: 3.297656793691468
Validation loss: 2.7657307481255216

Epoch: 92| Step: 0
Training loss: 3.498125936955498
Validation loss: 2.763766274614972

Epoch: 6| Step: 1
Training loss: 2.772332801558582
Validation loss: 2.764336877133931

Epoch: 6| Step: 2
Training loss: 2.7572571624875892
Validation loss: 2.762812472869404

Epoch: 6| Step: 3
Training loss: 2.6956508258278515
Validation loss: 2.7614593799468223

Epoch: 6| Step: 4
Training loss: 2.601751830397184
Validation loss: 2.761678939615714

Epoch: 6| Step: 5
Training loss: 3.0078476940919883
Validation loss: 2.7577509919250636

Epoch: 6| Step: 6
Training loss: 3.1667559427091305
Validation loss: 2.7599035515592427

Epoch: 6| Step: 7
Training loss: 2.809610875022192
Validation loss: 2.759218077309349

Epoch: 6| Step: 8
Training loss: 3.5962059585266495
Validation loss: 2.7554117726215006

Epoch: 6| Step: 9
Training loss: 3.3335352518595966
Validation loss: 2.7547359797110156

Epoch: 6| Step: 10
Training loss: 3.2962718249145633
Validation loss: 2.753181079394244

Epoch: 6| Step: 11
Training loss: 3.127365590232959
Validation loss: 2.7536120060084976

Epoch: 6| Step: 12
Training loss: 3.315687984691656
Validation loss: 2.7536968802377677

Epoch: 6| Step: 13
Training loss: 2.8453049652821023
Validation loss: 2.7516447203455088

Epoch: 93| Step: 0
Training loss: 3.078607356816762
Validation loss: 2.758924334788124

Epoch: 6| Step: 1
Training loss: 3.0003569708477436
Validation loss: 2.7657482309094967

Epoch: 6| Step: 2
Training loss: 3.409602623883817
Validation loss: 2.7637795103581575

Epoch: 6| Step: 3
Training loss: 3.3619250178193227
Validation loss: 2.7822928340725426

Epoch: 6| Step: 4
Training loss: 2.774695828237665
Validation loss: 2.7645169460036825

Epoch: 6| Step: 5
Training loss: 2.672862801686728
Validation loss: 2.7509751078005507

Epoch: 6| Step: 6
Training loss: 2.7127633665706656
Validation loss: 2.7448070919760577

Epoch: 6| Step: 7
Training loss: 3.333218969926376
Validation loss: 2.7453426354410686

Epoch: 6| Step: 8
Training loss: 3.5482235668065654
Validation loss: 2.746791033807928

Epoch: 6| Step: 9
Training loss: 2.588597154438347
Validation loss: 2.7462376011448746

Epoch: 6| Step: 10
Training loss: 3.1908046570953243
Validation loss: 2.744629003858985

Epoch: 6| Step: 11
Training loss: 3.372705315291988
Validation loss: 2.742415253783274

Epoch: 6| Step: 12
Training loss: 2.7446900167348347
Validation loss: 2.742181353098641

Epoch: 6| Step: 13
Training loss: 2.9691987351034688
Validation loss: 2.7469172235168853

Epoch: 94| Step: 0
Training loss: 3.2780819085473607
Validation loss: 2.7596955062989728

Epoch: 6| Step: 1
Training loss: 3.914549289059292
Validation loss: 2.7677437909304095

Epoch: 6| Step: 2
Training loss: 3.069786589719373
Validation loss: 2.7802641290646535

Epoch: 6| Step: 3
Training loss: 3.4270454257773992
Validation loss: 2.7783637875257554

Epoch: 6| Step: 4
Training loss: 3.010710036470808
Validation loss: 2.772622117575861

Epoch: 6| Step: 5
Training loss: 2.5252813918939507
Validation loss: 2.756459066686846

Epoch: 6| Step: 6
Training loss: 2.5688896531060275
Validation loss: 2.7494255390683313

Epoch: 6| Step: 7
Training loss: 3.147448211558977
Validation loss: 2.7395512166350113

Epoch: 6| Step: 8
Training loss: 2.414048870751878
Validation loss: 2.7409798699560444

Epoch: 6| Step: 9
Training loss: 2.9628268934724473
Validation loss: 2.7455232525604942

Epoch: 6| Step: 10
Training loss: 2.397996296514685
Validation loss: 2.744213803618791

Epoch: 6| Step: 11
Training loss: 3.3232274084578073
Validation loss: 2.7425382684457325

Epoch: 6| Step: 12
Training loss: 3.1506833379785757
Validation loss: 2.7417189104782946

Epoch: 6| Step: 13
Training loss: 3.367750222609992
Validation loss: 2.7414402424606514

Epoch: 95| Step: 0
Training loss: 2.873836945508161
Validation loss: 2.733922693958255

Epoch: 6| Step: 1
Training loss: 2.85929561984248
Validation loss: 2.732393541240246

Epoch: 6| Step: 2
Training loss: 2.899188579298518
Validation loss: 2.732261522067918

Epoch: 6| Step: 3
Training loss: 2.604999734508772
Validation loss: 2.731766125419534

Epoch: 6| Step: 4
Training loss: 3.8284814785393118
Validation loss: 2.735253324530927

Epoch: 6| Step: 5
Training loss: 3.2345132844268534
Validation loss: 2.735467852815284

Epoch: 6| Step: 6
Training loss: 3.250852032995302
Validation loss: 2.737999205923355

Epoch: 6| Step: 7
Training loss: 3.184067167877151
Validation loss: 2.738067850352877

Epoch: 6| Step: 8
Training loss: 2.5209627564889754
Validation loss: 2.7373351497688576

Epoch: 6| Step: 9
Training loss: 2.6120544199627003
Validation loss: 2.736719630214271

Epoch: 6| Step: 10
Training loss: 2.2417829726818885
Validation loss: 2.7336666885585785

Epoch: 6| Step: 11
Training loss: 3.5600057871910806
Validation loss: 2.7340572902727556

Epoch: 6| Step: 12
Training loss: 3.2974463957506757
Validation loss: 2.731997348225833

Epoch: 6| Step: 13
Training loss: 3.8510887984402125
Validation loss: 2.74630459368264

Epoch: 96| Step: 0
Training loss: 2.7570676148833075
Validation loss: 2.732571801944129

Epoch: 6| Step: 1
Training loss: 3.6853344264251957
Validation loss: 2.7278774954955027

Epoch: 6| Step: 2
Training loss: 3.4960610159082073
Validation loss: 2.724777262024219

Epoch: 6| Step: 3
Training loss: 2.5106950871943443
Validation loss: 2.72497664512432

Epoch: 6| Step: 4
Training loss: 2.298923850193398
Validation loss: 2.7258090083957387

Epoch: 6| Step: 5
Training loss: 2.277470632587785
Validation loss: 2.726922547355921

Epoch: 6| Step: 6
Training loss: 2.609369883275298
Validation loss: 2.7258206687683177

Epoch: 6| Step: 7
Training loss: 3.1442649586392926
Validation loss: 2.7261831499961793

Epoch: 6| Step: 8
Training loss: 3.3321388647627668
Validation loss: 2.7256453102340195

Epoch: 6| Step: 9
Training loss: 2.842934795532242
Validation loss: 2.7254527476494212

Epoch: 6| Step: 10
Training loss: 3.387436734555383
Validation loss: 2.7289373401205417

Epoch: 6| Step: 11
Training loss: 3.3884379985034623
Validation loss: 2.725419566749851

Epoch: 6| Step: 12
Training loss: 3.4144179379568493
Validation loss: 2.725323060006088

Epoch: 6| Step: 13
Training loss: 3.157257674606991
Validation loss: 2.7286974818225405

Epoch: 97| Step: 0
Training loss: 2.557035248144598
Validation loss: 2.731701821699609

Epoch: 6| Step: 1
Training loss: 2.5127414264739536
Validation loss: 2.7397290546676474

Epoch: 6| Step: 2
Training loss: 3.3382480311688254
Validation loss: 2.7436028201789457

Epoch: 6| Step: 3
Training loss: 3.850858364776462
Validation loss: 2.7398795015309045

Epoch: 6| Step: 4
Training loss: 3.015776793459481
Validation loss: 2.731279551152184

Epoch: 6| Step: 5
Training loss: 3.0144549852389946
Validation loss: 2.725367435001678

Epoch: 6| Step: 6
Training loss: 3.2634771118857637
Validation loss: 2.721769239390007

Epoch: 6| Step: 7
Training loss: 2.8289281221106273
Validation loss: 2.7211497315653523

Epoch: 6| Step: 8
Training loss: 3.38390841803389
Validation loss: 2.7261571559640867

Epoch: 6| Step: 9
Training loss: 2.929006756848649
Validation loss: 2.7238711963139393

Epoch: 6| Step: 10
Training loss: 2.6690296392871073
Validation loss: 2.721260178376554

Epoch: 6| Step: 11
Training loss: 3.0681843844316328
Validation loss: 2.7213856264229013

Epoch: 6| Step: 12
Training loss: 2.4424344514545524
Validation loss: 2.7191963833589017

Epoch: 6| Step: 13
Training loss: 3.6270677654203225
Validation loss: 2.7212593427528193

Epoch: 98| Step: 0
Training loss: 3.147269285440654
Validation loss: 2.7181841514027725

Epoch: 6| Step: 1
Training loss: 2.651242371601675
Validation loss: 2.720426117039979

Epoch: 6| Step: 2
Training loss: 2.813975138052162
Validation loss: 2.7177729498205236

Epoch: 6| Step: 3
Training loss: 3.005244598081713
Validation loss: 2.716122404299948

Epoch: 6| Step: 4
Training loss: 2.934871390285211
Validation loss: 2.722764898526849

Epoch: 6| Step: 5
Training loss: 3.0840777624001716
Validation loss: 2.7234902260945324

Epoch: 6| Step: 6
Training loss: 2.9505259869298457
Validation loss: 2.723503827006588

Epoch: 6| Step: 7
Training loss: 3.0705039860075707
Validation loss: 2.720965829821789

Epoch: 6| Step: 8
Training loss: 2.843446820205354
Validation loss: 2.722426069154483

Epoch: 6| Step: 9
Training loss: 2.7813449800539467
Validation loss: 2.720243627144226

Epoch: 6| Step: 10
Training loss: 3.5592951496870064
Validation loss: 2.7207706322518526

Epoch: 6| Step: 11
Training loss: 2.573759417153055
Validation loss: 2.722816405019731

Epoch: 6| Step: 12
Training loss: 3.550825968545759
Validation loss: 2.71589279864217

Epoch: 6| Step: 13
Training loss: 3.6283853442404417
Validation loss: 2.7191129165706247

Epoch: 99| Step: 0
Training loss: 2.9735928838144394
Validation loss: 2.717302855910042

Epoch: 6| Step: 1
Training loss: 3.131156959598105
Validation loss: 2.7154791325037735

Epoch: 6| Step: 2
Training loss: 3.1405219065888015
Validation loss: 2.7169144067592113

Epoch: 6| Step: 3
Training loss: 3.151262327092175
Validation loss: 2.7138062685598165

Epoch: 6| Step: 4
Training loss: 3.1297665674103383
Validation loss: 2.7143192880362736

Epoch: 6| Step: 5
Training loss: 3.0452416370146422
Validation loss: 2.7123344557248616

Epoch: 6| Step: 6
Training loss: 2.4494064234815296
Validation loss: 2.708663709823996

Epoch: 6| Step: 7
Training loss: 3.2607683635985127
Validation loss: 2.7100805687322236

Epoch: 6| Step: 8
Training loss: 2.9281799506666815
Validation loss: 2.708268953477932

Epoch: 6| Step: 9
Training loss: 3.520786142127032
Validation loss: 2.7112375147587313

Epoch: 6| Step: 10
Training loss: 2.6243864886547286
Validation loss: 2.7099036240367216

Epoch: 6| Step: 11
Training loss: 3.2245758073377755
Validation loss: 2.7111555787631234

Epoch: 6| Step: 12
Training loss: 2.6489027846784037
Validation loss: 2.709598677941883

Epoch: 6| Step: 13
Training loss: 3.0170586691346406
Validation loss: 2.7224681673526376

Epoch: 100| Step: 0
Training loss: 3.0513335642610007
Validation loss: 2.7334525347463328

Epoch: 6| Step: 1
Training loss: 3.7664776228555614
Validation loss: 2.7376539015426586

Epoch: 6| Step: 2
Training loss: 2.2224339808129883
Validation loss: 2.708798240975832

Epoch: 6| Step: 3
Training loss: 2.6999809193819972
Validation loss: 2.7032332063491853

Epoch: 6| Step: 4
Training loss: 2.0398773085406203
Validation loss: 2.7031057426927996

Epoch: 6| Step: 5
Training loss: 3.4321413754952927
Validation loss: 2.7116485341282903

Epoch: 6| Step: 6
Training loss: 3.327130522818295
Validation loss: 2.7132447104085333

Epoch: 6| Step: 7
Training loss: 2.3540350503054124
Validation loss: 2.7178837338229878

Epoch: 6| Step: 8
Training loss: 2.466777351404826
Validation loss: 2.7119508675406085

Epoch: 6| Step: 9
Training loss: 2.6980517634635657
Validation loss: 2.7125383835862005

Epoch: 6| Step: 10
Training loss: 3.860542892860058
Validation loss: 2.713872056195139

Epoch: 6| Step: 11
Training loss: 3.1623308882901062
Validation loss: 2.7121221300424163

Epoch: 6| Step: 12
Training loss: 3.2389573517665373
Validation loss: 2.7101580610550546

Epoch: 6| Step: 13
Training loss: 3.97994102146788
Validation loss: 2.7071048105266575

Epoch: 101| Step: 0
Training loss: 2.4427870118918533
Validation loss: 2.7069555007210777

Epoch: 6| Step: 1
Training loss: 3.3908896628596565
Validation loss: 2.7018274800271573

Epoch: 6| Step: 2
Training loss: 2.675751311420104
Validation loss: 2.700777412331212

Epoch: 6| Step: 3
Training loss: 2.6803180631099726
Validation loss: 2.705644787296773

Epoch: 6| Step: 4
Training loss: 2.9296035144211894
Validation loss: 2.7114109837336797

Epoch: 6| Step: 5
Training loss: 3.111138232052377
Validation loss: 2.7307704060773874

Epoch: 6| Step: 6
Training loss: 3.1348582601674884
Validation loss: 2.7409067943989247

Epoch: 6| Step: 7
Training loss: 3.340263188665777
Validation loss: 2.742782356700848

Epoch: 6| Step: 8
Training loss: 3.058821200784168
Validation loss: 2.716608041291417

Epoch: 6| Step: 9
Training loss: 3.1709826487316404
Validation loss: 2.6969091241544834

Epoch: 6| Step: 10
Training loss: 3.136506982022965
Validation loss: 2.6931957263064183

Epoch: 6| Step: 11
Training loss: 2.7094077595596895
Validation loss: 2.691448503823962

Epoch: 6| Step: 12
Training loss: 3.489426581814417
Validation loss: 2.690514856893229

Epoch: 6| Step: 13
Training loss: 2.7418987415573643
Validation loss: 2.691444116543888

Epoch: 102| Step: 0
Training loss: 2.260687031083371
Validation loss: 2.6921465922430654

Epoch: 6| Step: 1
Training loss: 2.754123803602087
Validation loss: 2.69212459860938

Epoch: 6| Step: 2
Training loss: 2.8038183369091407
Validation loss: 2.6927576902921513

Epoch: 6| Step: 3
Training loss: 3.179316168620043
Validation loss: 2.6932161167806905

Epoch: 6| Step: 4
Training loss: 2.8433180260851825
Validation loss: 2.691842902133227

Epoch: 6| Step: 5
Training loss: 3.4301604550925404
Validation loss: 2.6919352655685875

Epoch: 6| Step: 6
Training loss: 3.1284064990351825
Validation loss: 2.693059452368299

Epoch: 6| Step: 7
Training loss: 3.6839016960605493
Validation loss: 2.712407540679785

Epoch: 6| Step: 8
Training loss: 2.665526225684987
Validation loss: 2.7345119197100565

Epoch: 6| Step: 9
Training loss: 3.1275898691952206
Validation loss: 2.7610800051537248

Epoch: 6| Step: 10
Training loss: 2.913592180439963
Validation loss: 2.72756090967539

Epoch: 6| Step: 11
Training loss: 3.1335361624737574
Validation loss: 2.6965329002026985

Epoch: 6| Step: 12
Training loss: 2.8918132917037895
Validation loss: 2.689575473729467

Epoch: 6| Step: 13
Training loss: 3.439215769422235
Validation loss: 2.688015355394089

Epoch: 103| Step: 0
Training loss: 3.179445599626433
Validation loss: 2.6920555035679588

Epoch: 6| Step: 1
Training loss: 3.2845843131372683
Validation loss: 2.6981625600291963

Epoch: 6| Step: 2
Training loss: 1.671297419238376
Validation loss: 2.7033382713131457

Epoch: 6| Step: 3
Training loss: 3.7322532340237657
Validation loss: 2.7217452820002332

Epoch: 6| Step: 4
Training loss: 3.2426654509345503
Validation loss: 2.701257538017902

Epoch: 6| Step: 5
Training loss: 3.1157359326355794
Validation loss: 2.6977940132924934

Epoch: 6| Step: 6
Training loss: 2.522348269236586
Validation loss: 2.6915560585300993

Epoch: 6| Step: 7
Training loss: 2.636286404802823
Validation loss: 2.690518794994134

Epoch: 6| Step: 8
Training loss: 2.805686836402524
Validation loss: 2.6926261641939413

Epoch: 6| Step: 9
Training loss: 2.6857175904546424
Validation loss: 2.6904020730682827

Epoch: 6| Step: 10
Training loss: 3.512852368039903
Validation loss: 2.7089271355120914

Epoch: 6| Step: 11
Training loss: 3.1703102499106417
Validation loss: 2.712681929345725

Epoch: 6| Step: 12
Training loss: 3.559572589805513
Validation loss: 2.7128685821930194

Epoch: 6| Step: 13
Training loss: 1.9491300084892456
Validation loss: 2.699110547979576

Epoch: 104| Step: 0
Training loss: 2.347020829669465
Validation loss: 2.7040705077881437

Epoch: 6| Step: 1
Training loss: 3.8502432709166907
Validation loss: 2.695246545651369

Epoch: 6| Step: 2
Training loss: 2.7829867308968876
Validation loss: 2.699758848976835

Epoch: 6| Step: 3
Training loss: 3.136159274513523
Validation loss: 2.687795801617926

Epoch: 6| Step: 4
Training loss: 3.0586043512348207
Validation loss: 2.6809547518194625

Epoch: 6| Step: 5
Training loss: 3.1375798127862824
Validation loss: 2.6803285517264506

Epoch: 6| Step: 6
Training loss: 2.6668057902125497
Validation loss: 2.6875694096142713

Epoch: 6| Step: 7
Training loss: 3.8358496133405113
Validation loss: 2.686264652749403

Epoch: 6| Step: 8
Training loss: 2.664875879600083
Validation loss: 2.6856368852523365

Epoch: 6| Step: 9
Training loss: 2.7912650507424215
Validation loss: 2.6882966490342874

Epoch: 6| Step: 10
Training loss: 2.6856282835672434
Validation loss: 2.6817166467230695

Epoch: 6| Step: 11
Training loss: 2.6173436360259252
Validation loss: 2.68574027705053

Epoch: 6| Step: 12
Training loss: 3.09197392200759
Validation loss: 2.6847637801246376

Epoch: 6| Step: 13
Training loss: 3.10715271019587
Validation loss: 2.6881480169042935

Epoch: 105| Step: 0
Training loss: 3.2730542233943796
Validation loss: 2.689248169160911

Epoch: 6| Step: 1
Training loss: 3.6529993458226975
Validation loss: 2.6837386977750715

Epoch: 6| Step: 2
Training loss: 3.3802632864710787
Validation loss: 2.688224193149182

Epoch: 6| Step: 3
Training loss: 2.7107323120913587
Validation loss: 2.6893748025343425

Epoch: 6| Step: 4
Training loss: 3.244938062832049
Validation loss: 2.690342128384403

Epoch: 6| Step: 5
Training loss: 2.652483524914918
Validation loss: 2.6921912017433627

Epoch: 6| Step: 6
Training loss: 3.562104052575117
Validation loss: 2.7007667269042708

Epoch: 6| Step: 7
Training loss: 2.6812501138184706
Validation loss: 2.6911745889561085

Epoch: 6| Step: 8
Training loss: 2.61270769379682
Validation loss: 2.692617240176261

Epoch: 6| Step: 9
Training loss: 3.4278943494542693
Validation loss: 2.69894038900664

Epoch: 6| Step: 10
Training loss: 2.376898157617312
Validation loss: 2.6903108786342735

Epoch: 6| Step: 11
Training loss: 2.0562187262014926
Validation loss: 2.686348314668724

Epoch: 6| Step: 12
Training loss: 3.244231165955086
Validation loss: 2.6824110565870303

Epoch: 6| Step: 13
Training loss: 2.384024590058206
Validation loss: 2.691367170813748

Epoch: 106| Step: 0
Training loss: 2.9176105243632158
Validation loss: 2.687452901096971

Epoch: 6| Step: 1
Training loss: 2.648967138574036
Validation loss: 2.6889393007963736

Epoch: 6| Step: 2
Training loss: 3.1839576934419105
Validation loss: 2.7007757274594684

Epoch: 6| Step: 3
Training loss: 2.7156650974838366
Validation loss: 2.7083625533150273

Epoch: 6| Step: 4
Training loss: 2.6624027574717473
Validation loss: 2.693459725365277

Epoch: 6| Step: 5
Training loss: 3.4580757933783093
Validation loss: 2.685797894243634

Epoch: 6| Step: 6
Training loss: 2.5979687495594983
Validation loss: 2.6868291305131256

Epoch: 6| Step: 7
Training loss: 3.074050297660067
Validation loss: 2.6758908284008247

Epoch: 6| Step: 8
Training loss: 3.349655070980213
Validation loss: 2.668411645960323

Epoch: 6| Step: 9
Training loss: 2.784946514006412
Validation loss: 2.6695656397483245

Epoch: 6| Step: 10
Training loss: 3.042664420857828
Validation loss: 2.6680221406939455

Epoch: 6| Step: 11
Training loss: 2.9666228051818617
Validation loss: 2.6657779213061183

Epoch: 6| Step: 12
Training loss: 3.2860052619655127
Validation loss: 2.6673227517011338

Epoch: 6| Step: 13
Training loss: 3.1255410298260324
Validation loss: 2.6694163632382484

Epoch: 107| Step: 0
Training loss: 3.0548115970936394
Validation loss: 2.6671925578650417

Epoch: 6| Step: 1
Training loss: 2.6463613108494908
Validation loss: 2.6734136145083367

Epoch: 6| Step: 2
Training loss: 2.446124054907741
Validation loss: 2.6747397485469007

Epoch: 6| Step: 3
Training loss: 2.5913459023276406
Validation loss: 2.678439269079648

Epoch: 6| Step: 4
Training loss: 2.757478947770935
Validation loss: 2.6985615155897236

Epoch: 6| Step: 5
Training loss: 2.6111548287088886
Validation loss: 2.730322722532926

Epoch: 6| Step: 6
Training loss: 3.7085246061794805
Validation loss: 2.764520677607849

Epoch: 6| Step: 7
Training loss: 2.5622578948486736
Validation loss: 2.7510774315899673

Epoch: 6| Step: 8
Training loss: 2.682076859746136
Validation loss: 2.7281741955582866

Epoch: 6| Step: 9
Training loss: 2.98645538198651
Validation loss: 2.7261209075956856

Epoch: 6| Step: 10
Training loss: 2.9921039938168015
Validation loss: 2.720793607929616

Epoch: 6| Step: 11
Training loss: 3.921009469746384
Validation loss: 2.687751668568088

Epoch: 6| Step: 12
Training loss: 3.5522354555790017
Validation loss: 2.670332139763573

Epoch: 6| Step: 13
Training loss: 3.2126277734898787
Validation loss: 2.6661362405680564

Epoch: 108| Step: 0
Training loss: 3.1008927321150574
Validation loss: 2.667717092427528

Epoch: 6| Step: 1
Training loss: 3.008483653306415
Validation loss: 2.672960048699429

Epoch: 6| Step: 2
Training loss: 3.0465561920047497
Validation loss: 2.689770806853558

Epoch: 6| Step: 3
Training loss: 3.0096746848079814
Validation loss: 2.6982335490397173

Epoch: 6| Step: 4
Training loss: 3.01989064909157
Validation loss: 2.703427803946868

Epoch: 6| Step: 5
Training loss: 3.1614696286715605
Validation loss: 2.685972590051031

Epoch: 6| Step: 6
Training loss: 2.931674944367324
Validation loss: 2.670493902548453

Epoch: 6| Step: 7
Training loss: 2.8643898268567067
Validation loss: 2.669969452145566

Epoch: 6| Step: 8
Training loss: 2.4184068027258068
Validation loss: 2.667100900499121

Epoch: 6| Step: 9
Training loss: 2.7480155547200154
Validation loss: 2.6716120576794653

Epoch: 6| Step: 10
Training loss: 3.1516702492658433
Validation loss: 2.6809496703464393

Epoch: 6| Step: 11
Training loss: 3.264519755400239
Validation loss: 2.7083594088249643

Epoch: 6| Step: 12
Training loss: 3.1405604721196703
Validation loss: 2.7361123280550004

Epoch: 6| Step: 13
Training loss: 3.379331564182288
Validation loss: 2.7356308863586567

Epoch: 109| Step: 0
Training loss: 2.750508694849797
Validation loss: 2.7330885281798185

Epoch: 6| Step: 1
Training loss: 3.0203226293560745
Validation loss: 2.682715367178119

Epoch: 6| Step: 2
Training loss: 3.1384239265006313
Validation loss: 2.65893466117291

Epoch: 6| Step: 3
Training loss: 3.386242684560248
Validation loss: 2.6557958843268845

Epoch: 6| Step: 4
Training loss: 3.175616383232104
Validation loss: 2.654097786497684

Epoch: 6| Step: 5
Training loss: 3.4407237801850297
Validation loss: 2.6581643354967817

Epoch: 6| Step: 6
Training loss: 2.9194217929834463
Validation loss: 2.658076280644896

Epoch: 6| Step: 7
Training loss: 2.510088211880391
Validation loss: 2.6605087084603753

Epoch: 6| Step: 8
Training loss: 2.715990266279664
Validation loss: 2.662112859171551

Epoch: 6| Step: 9
Training loss: 2.669614047183448
Validation loss: 2.6650772459637357

Epoch: 6| Step: 10
Training loss: 2.888783956317408
Validation loss: 2.667440353786024

Epoch: 6| Step: 11
Training loss: 3.62526872888458
Validation loss: 2.661292705957434

Epoch: 6| Step: 12
Training loss: 2.944411243595421
Validation loss: 2.6571281791066306

Epoch: 6| Step: 13
Training loss: 1.9557150794959803
Validation loss: 2.653059606112069

Epoch: 110| Step: 0
Training loss: 3.001777757971425
Validation loss: 2.6533913292526377

Epoch: 6| Step: 1
Training loss: 2.952560774575771
Validation loss: 2.6538438973155603

Epoch: 6| Step: 2
Training loss: 3.0047685553716277
Validation loss: 2.6554989606539645

Epoch: 6| Step: 3
Training loss: 2.5952991317597647
Validation loss: 2.662922054394962

Epoch: 6| Step: 4
Training loss: 2.1713872128506013
Validation loss: 2.6990271149553355

Epoch: 6| Step: 5
Training loss: 3.5921177349973537
Validation loss: 2.749477819794524

Epoch: 6| Step: 6
Training loss: 2.478212306443765
Validation loss: 2.7513387475421642

Epoch: 6| Step: 7
Training loss: 3.081858273524404
Validation loss: 2.7622368286256314

Epoch: 6| Step: 8
Training loss: 2.800929364872816
Validation loss: 2.7329070254644883

Epoch: 6| Step: 9
Training loss: 2.820139110867543
Validation loss: 2.7396116388989804

Epoch: 6| Step: 10
Training loss: 3.1281005736472953
Validation loss: 2.6959342563986364

Epoch: 6| Step: 11
Training loss: 3.2490259324738693
Validation loss: 2.659217712155304

Epoch: 6| Step: 12
Training loss: 3.49609497752248
Validation loss: 2.646777141566629

Epoch: 6| Step: 13
Training loss: 3.285044918827348
Validation loss: 2.6436833971203733

Epoch: 111| Step: 0
Training loss: 3.5725240389720545
Validation loss: 2.650549424529262

Epoch: 6| Step: 1
Training loss: 3.5460104539849437
Validation loss: 2.6493692929922377

Epoch: 6| Step: 2
Training loss: 2.8646957837777034
Validation loss: 2.6531764924877788

Epoch: 6| Step: 3
Training loss: 2.692077287309859
Validation loss: 2.6619738836071085

Epoch: 6| Step: 4
Training loss: 2.941023316603204
Validation loss: 2.6488391947772842

Epoch: 6| Step: 5
Training loss: 2.725156405098793
Validation loss: 2.648445752036293

Epoch: 6| Step: 6
Training loss: 2.66981123253396
Validation loss: 2.6418415346576745

Epoch: 6| Step: 7
Training loss: 2.94645300520637
Validation loss: 2.6433355927794873

Epoch: 6| Step: 8
Training loss: 2.1647571316491554
Validation loss: 2.6408046310110667

Epoch: 6| Step: 9
Training loss: 2.7996382888401574
Validation loss: 2.6459029904485774

Epoch: 6| Step: 10
Training loss: 3.6349347222303026
Validation loss: 2.643950088528988

Epoch: 6| Step: 11
Training loss: 2.948325965603309
Validation loss: 2.647316982193329

Epoch: 6| Step: 12
Training loss: 3.371424299634578
Validation loss: 2.655652193555449

Epoch: 6| Step: 13
Training loss: 2.4643291050978604
Validation loss: 2.6616369077998776

Epoch: 112| Step: 0
Training loss: 2.754199895691975
Validation loss: 2.66274481323847

Epoch: 6| Step: 1
Training loss: 2.2917508427737086
Validation loss: 2.6700497139728503

Epoch: 6| Step: 2
Training loss: 3.240917425839233
Validation loss: 2.6853872925001556

Epoch: 6| Step: 3
Training loss: 3.327147434280374
Validation loss: 2.691478579265006

Epoch: 6| Step: 4
Training loss: 3.3319876020642782
Validation loss: 2.6831224298137495

Epoch: 6| Step: 5
Training loss: 3.205632563400048
Validation loss: 2.6620604815190583

Epoch: 6| Step: 6
Training loss: 3.5110551081857553
Validation loss: 2.6441076246598265

Epoch: 6| Step: 7
Training loss: 3.381879224067832
Validation loss: 2.636020527177902

Epoch: 6| Step: 8
Training loss: 2.8311943132932473
Validation loss: 2.637371473627022

Epoch: 6| Step: 9
Training loss: 2.936601541975521
Validation loss: 2.6374593857487705

Epoch: 6| Step: 10
Training loss: 2.4598408511094503
Validation loss: 2.6368773860753523

Epoch: 6| Step: 11
Training loss: 2.5867315726969067
Validation loss: 2.6373031963854845

Epoch: 6| Step: 12
Training loss: 2.5386231966718054
Validation loss: 2.6383256001966413

Epoch: 6| Step: 13
Training loss: 3.136634226951182
Validation loss: 2.6436214708530477

Epoch: 113| Step: 0
Training loss: 2.9216497813852293
Validation loss: 2.641537083510674

Epoch: 6| Step: 1
Training loss: 3.1349181901639787
Validation loss: 2.6402596462867063

Epoch: 6| Step: 2
Training loss: 3.1935543829027897
Validation loss: 2.636416204391774

Epoch: 6| Step: 3
Training loss: 3.2428876373652944
Validation loss: 2.6353565873776854

Epoch: 6| Step: 4
Training loss: 3.348069440342592
Validation loss: 2.6316049729740425

Epoch: 6| Step: 5
Training loss: 2.2510085494609062
Validation loss: 2.633777563129372

Epoch: 6| Step: 6
Training loss: 2.5370512993136582
Validation loss: 2.6331460981860846

Epoch: 6| Step: 7
Training loss: 3.049740739653383
Validation loss: 2.6409016630698874

Epoch: 6| Step: 8
Training loss: 2.873037912651725
Validation loss: 2.6503390593890686

Epoch: 6| Step: 9
Training loss: 3.1276753989479285
Validation loss: 2.6740828356622695

Epoch: 6| Step: 10
Training loss: 2.951246198807643
Validation loss: 2.6835977183187243

Epoch: 6| Step: 11
Training loss: 3.614909630961008
Validation loss: 2.7331311703249788

Epoch: 6| Step: 12
Training loss: 2.832557871295533
Validation loss: 2.7556710736935717

Epoch: 6| Step: 13
Training loss: 1.6100786763272232
Validation loss: 2.758814211959542

Epoch: 114| Step: 0
Training loss: 2.9709907507866404
Validation loss: 2.758623009353376

Epoch: 6| Step: 1
Training loss: 2.1212922454745478
Validation loss: 2.7446052441417277

Epoch: 6| Step: 2
Training loss: 3.0963563055486114
Validation loss: 2.7158462553794847

Epoch: 6| Step: 3
Training loss: 3.362682470879964
Validation loss: 2.683364172676551

Epoch: 6| Step: 4
Training loss: 2.679143110758058
Validation loss: 2.6455962527284873

Epoch: 6| Step: 5
Training loss: 2.30291110615145
Validation loss: 2.635049214480736

Epoch: 6| Step: 6
Training loss: 3.1811636982361637
Validation loss: 2.628193725555122

Epoch: 6| Step: 7
Training loss: 3.1498408443873323
Validation loss: 2.628520154220431

Epoch: 6| Step: 8
Training loss: 3.6373754578339095
Validation loss: 2.6265344720044737

Epoch: 6| Step: 9
Training loss: 3.1437153201911108
Validation loss: 2.6306866198255063

Epoch: 6| Step: 10
Training loss: 2.79535348093475
Validation loss: 2.6316517027025066

Epoch: 6| Step: 11
Training loss: 2.8191250232308684
Validation loss: 2.6315629399611007

Epoch: 6| Step: 12
Training loss: 2.5969117897631864
Validation loss: 2.629228267790165

Epoch: 6| Step: 13
Training loss: 3.6240248848437555
Validation loss: 2.6305990480630634

Epoch: 115| Step: 0
Training loss: 3.2929442779247102
Validation loss: 2.6302966976683892

Epoch: 6| Step: 1
Training loss: 2.670976097191358
Validation loss: 2.628968157207932

Epoch: 6| Step: 2
Training loss: 2.659559096028158
Validation loss: 2.628679748313899

Epoch: 6| Step: 3
Training loss: 2.550260201436657
Validation loss: 2.630746639938189

Epoch: 6| Step: 4
Training loss: 2.9844318803889025
Validation loss: 2.62567853385998

Epoch: 6| Step: 5
Training loss: 3.730550299746732
Validation loss: 2.6357969798962904

Epoch: 6| Step: 6
Training loss: 3.029113645933488
Validation loss: 2.6427238701924245

Epoch: 6| Step: 7
Training loss: 3.2347453177194354
Validation loss: 2.6519208022913845

Epoch: 6| Step: 8
Training loss: 2.9442062121608537
Validation loss: 2.6606895451054244

Epoch: 6| Step: 9
Training loss: 3.0642586154609663
Validation loss: 2.6666271142051627

Epoch: 6| Step: 10
Training loss: 2.993096355524999
Validation loss: 2.6738462038899433

Epoch: 6| Step: 11
Training loss: 2.065807464897236
Validation loss: 2.686272356263469

Epoch: 6| Step: 12
Training loss: 3.0834870858563
Validation loss: 2.671949855578865

Epoch: 6| Step: 13
Training loss: 2.9240024593671694
Validation loss: 2.6919790967116217

Epoch: 116| Step: 0
Training loss: 2.9300556409324314
Validation loss: 2.6720165797346076

Epoch: 6| Step: 1
Training loss: 3.0628590276037246
Validation loss: 2.678664453534783

Epoch: 6| Step: 2
Training loss: 2.2928956522167216
Validation loss: 2.670027967511388

Epoch: 6| Step: 3
Training loss: 2.324630367470801
Validation loss: 2.6435993101307216

Epoch: 6| Step: 4
Training loss: 3.114806678614517
Validation loss: 2.6373177997373825

Epoch: 6| Step: 5
Training loss: 3.6356512975897477
Validation loss: 2.631051254239467

Epoch: 6| Step: 6
Training loss: 3.2896991756852034
Validation loss: 2.626313963265468

Epoch: 6| Step: 7
Training loss: 2.4205475153145133
Validation loss: 2.626824627202371

Epoch: 6| Step: 8
Training loss: 3.1424212277295593
Validation loss: 2.627515793413512

Epoch: 6| Step: 9
Training loss: 3.2401986146026225
Validation loss: 2.6361544962946977

Epoch: 6| Step: 10
Training loss: 2.5755443256928037
Validation loss: 2.6307053430941307

Epoch: 6| Step: 11
Training loss: 3.387028769060914
Validation loss: 2.6246978031094126

Epoch: 6| Step: 12
Training loss: 2.9750487315570413
Validation loss: 2.6303511191036004

Epoch: 6| Step: 13
Training loss: 2.5099699538358893
Validation loss: 2.638763857263023

Epoch: 117| Step: 0
Training loss: 2.919119448427387
Validation loss: 2.64739886234579

Epoch: 6| Step: 1
Training loss: 2.6565332598277944
Validation loss: 2.6585133502561145

Epoch: 6| Step: 2
Training loss: 2.7664897881310266
Validation loss: 2.6608296360112105

Epoch: 6| Step: 3
Training loss: 2.958502661645313
Validation loss: 2.653072051974144

Epoch: 6| Step: 4
Training loss: 2.76465999340794
Validation loss: 2.667539939699387

Epoch: 6| Step: 5
Training loss: 2.386090035050017
Validation loss: 2.6697801692984062

Epoch: 6| Step: 6
Training loss: 2.76282769240323
Validation loss: 2.6634760914827926

Epoch: 6| Step: 7
Training loss: 3.66838277769296
Validation loss: 2.6390288154134196

Epoch: 6| Step: 8
Training loss: 3.2534303901088295
Validation loss: 2.627789763588105

Epoch: 6| Step: 9
Training loss: 2.9422549458297738
Validation loss: 2.6214580264110556

Epoch: 6| Step: 10
Training loss: 3.1233201661811156
Validation loss: 2.6159187867297624

Epoch: 6| Step: 11
Training loss: 2.992423981965423
Validation loss: 2.612519958108984

Epoch: 6| Step: 12
Training loss: 2.8323440694690407
Validation loss: 2.6092169811260124

Epoch: 6| Step: 13
Training loss: 3.307275502723583
Validation loss: 2.612877506034316

Epoch: 118| Step: 0
Training loss: 2.728957995719451
Validation loss: 2.613614434782512

Epoch: 6| Step: 1
Training loss: 2.8014412372341972
Validation loss: 2.6105468233058335

Epoch: 6| Step: 2
Training loss: 3.0800007173611683
Validation loss: 2.6129278408183936

Epoch: 6| Step: 3
Training loss: 2.890529486650465
Validation loss: 2.6143471093450357

Epoch: 6| Step: 4
Training loss: 3.1133870833152435
Validation loss: 2.6170193006684244

Epoch: 6| Step: 5
Training loss: 3.1714883202186326
Validation loss: 2.6365640968169997

Epoch: 6| Step: 6
Training loss: 3.250753168719586
Validation loss: 2.6478037926476095

Epoch: 6| Step: 7
Training loss: 3.220701792516022
Validation loss: 2.623885485056163

Epoch: 6| Step: 8
Training loss: 2.0910458538878394
Validation loss: 2.6177562033905772

Epoch: 6| Step: 9
Training loss: 3.511398555428232
Validation loss: 2.607331553891142

Epoch: 6| Step: 10
Training loss: 2.2538920754130762
Validation loss: 2.6114858698602537

Epoch: 6| Step: 11
Training loss: 2.4712562876627637
Validation loss: 2.609903958021844

Epoch: 6| Step: 12
Training loss: 3.2538323914936975
Validation loss: 2.6111351964947067

Epoch: 6| Step: 13
Training loss: 3.148176991781439
Validation loss: 2.610074408416666

Epoch: 119| Step: 0
Training loss: 3.4499317438864767
Validation loss: 2.6147856758856385

Epoch: 6| Step: 1
Training loss: 3.229299645095658
Validation loss: 2.6121553617128908

Epoch: 6| Step: 2
Training loss: 2.6978620329717002
Validation loss: 2.6139928267515837

Epoch: 6| Step: 3
Training loss: 3.3077489501730035
Validation loss: 2.6216955701192783

Epoch: 6| Step: 4
Training loss: 2.4306412079266537
Validation loss: 2.6226247890846768

Epoch: 6| Step: 5
Training loss: 3.419650256025484
Validation loss: 2.621445501845062

Epoch: 6| Step: 6
Training loss: 2.85005177233335
Validation loss: 2.619687419196933

Epoch: 6| Step: 7
Training loss: 2.2252482500779767
Validation loss: 2.618786696725291

Epoch: 6| Step: 8
Training loss: 2.7332580028791162
Validation loss: 2.6204395799790774

Epoch: 6| Step: 9
Training loss: 3.1384239265006313
Validation loss: 2.6212446077262888

Epoch: 6| Step: 10
Training loss: 2.444206889727975
Validation loss: 2.637981728924354

Epoch: 6| Step: 11
Training loss: 3.1811746404749117
Validation loss: 2.645189953295313

Epoch: 6| Step: 12
Training loss: 3.103721808660009
Validation loss: 2.646395736800444

Epoch: 6| Step: 13
Training loss: 2.487570189439425
Validation loss: 2.6432040399391354

Epoch: 120| Step: 0
Training loss: 2.6170663378553933
Validation loss: 2.626892481943082

Epoch: 6| Step: 1
Training loss: 3.2996687058120298
Validation loss: 2.620216754131156

Epoch: 6| Step: 2
Training loss: 3.1811677453699496
Validation loss: 2.613088938576062

Epoch: 6| Step: 3
Training loss: 3.6126390370998775
Validation loss: 2.607992980189753

Epoch: 6| Step: 4
Training loss: 3.1742317952426222
Validation loss: 2.60704378504878

Epoch: 6| Step: 5
Training loss: 2.7305195684983907
Validation loss: 2.6062130136305615

Epoch: 6| Step: 6
Training loss: 2.4827935325517427
Validation loss: 2.602066283439162

Epoch: 6| Step: 7
Training loss: 3.25668732677246
Validation loss: 2.6045443655136133

Epoch: 6| Step: 8
Training loss: 2.8262747935000982
Validation loss: 2.6021806152048383

Epoch: 6| Step: 9
Training loss: 2.7092299126625496
Validation loss: 2.6068837691682867

Epoch: 6| Step: 10
Training loss: 2.198886338041262
Validation loss: 2.6045942018736863

Epoch: 6| Step: 11
Training loss: 2.9661346158470576
Validation loss: 2.6058391567204655

Epoch: 6| Step: 12
Training loss: 2.6432780644947313
Validation loss: 2.6030935699232187

Epoch: 6| Step: 13
Training loss: 3.1267013496096614
Validation loss: 2.605497925804358

Epoch: 121| Step: 0
Training loss: 2.956164859247337
Validation loss: 2.6133751471197124

Epoch: 6| Step: 1
Training loss: 2.985720825318523
Validation loss: 2.6237295683153614

Epoch: 6| Step: 2
Training loss: 3.0361728610357224
Validation loss: 2.634639927244801

Epoch: 6| Step: 3
Training loss: 2.6651605485433176
Validation loss: 2.6344138445706804

Epoch: 6| Step: 4
Training loss: 2.4765615373001877
Validation loss: 2.658157563188827

Epoch: 6| Step: 5
Training loss: 3.0079074596921656
Validation loss: 2.7194453637195584

Epoch: 6| Step: 6
Training loss: 3.0872086236893095
Validation loss: 2.692094293266591

Epoch: 6| Step: 7
Training loss: 2.836651336532869
Validation loss: 2.671152085794306

Epoch: 6| Step: 8
Training loss: 3.0913642392643164
Validation loss: 2.644544596832336

Epoch: 6| Step: 9
Training loss: 3.0119695299286726
Validation loss: 2.6177648792385138

Epoch: 6| Step: 10
Training loss: 3.1022985243256658
Validation loss: 2.6004861673722552

Epoch: 6| Step: 11
Training loss: 2.973596892742825
Validation loss: 2.627263749889806

Epoch: 6| Step: 12
Training loss: 2.9106949480435778
Validation loss: 2.6537117515396087

Epoch: 6| Step: 13
Training loss: 3.4787015013855656
Validation loss: 2.6735304356611787

Epoch: 122| Step: 0
Training loss: 1.917171771071252
Validation loss: 2.6608780193173867

Epoch: 6| Step: 1
Training loss: 2.502721640178015
Validation loss: 2.6413021405090187

Epoch: 6| Step: 2
Training loss: 3.466349690568903
Validation loss: 2.617916354772831

Epoch: 6| Step: 3
Training loss: 2.3746540419928186
Validation loss: 2.6126988137421416

Epoch: 6| Step: 4
Training loss: 3.0911655612863433
Validation loss: 2.6057440022343665

Epoch: 6| Step: 5
Training loss: 3.188634932179112
Validation loss: 2.597419427338211

Epoch: 6| Step: 6
Training loss: 3.0621157035270743
Validation loss: 2.598358346111373

Epoch: 6| Step: 7
Training loss: 3.409253257584867
Validation loss: 2.6015480132498583

Epoch: 6| Step: 8
Training loss: 3.0446836758879012
Validation loss: 2.6030817744219688

Epoch: 6| Step: 9
Training loss: 2.8366526813214623
Validation loss: 2.6114395332223364

Epoch: 6| Step: 10
Training loss: 2.9495595570882354
Validation loss: 2.629247197428471

Epoch: 6| Step: 11
Training loss: 3.4176918135575796
Validation loss: 2.638057310088675

Epoch: 6| Step: 12
Training loss: 2.6657424954528124
Validation loss: 2.6270096733404227

Epoch: 6| Step: 13
Training loss: 2.733516885440491
Validation loss: 2.6466032217274806

Epoch: 123| Step: 0
Training loss: 3.3397066857839945
Validation loss: 2.651373537208171

Epoch: 6| Step: 1
Training loss: 2.743176751873018
Validation loss: 2.63133474861456

Epoch: 6| Step: 2
Training loss: 2.4023526819574808
Validation loss: 2.6136536863398967

Epoch: 6| Step: 3
Training loss: 2.5317832479281766
Validation loss: 2.61024203432324

Epoch: 6| Step: 4
Training loss: 2.7522410884424957
Validation loss: 2.5970475581539434

Epoch: 6| Step: 5
Training loss: 3.3284258639316953
Validation loss: 2.590415189596484

Epoch: 6| Step: 6
Training loss: 2.7271061658571263
Validation loss: 2.5908867769830413

Epoch: 6| Step: 7
Training loss: 3.197442797282624
Validation loss: 2.588550857709528

Epoch: 6| Step: 8
Training loss: 2.659669178919887
Validation loss: 2.585887941547892

Epoch: 6| Step: 9
Training loss: 3.28323638372692
Validation loss: 2.5912297509445033

Epoch: 6| Step: 10
Training loss: 2.8210138098842874
Validation loss: 2.588045422070097

Epoch: 6| Step: 11
Training loss: 3.0320222795015135
Validation loss: 2.589356714751564

Epoch: 6| Step: 12
Training loss: 2.829215329575237
Validation loss: 2.5902196453941784

Epoch: 6| Step: 13
Training loss: 3.553484836900811
Validation loss: 2.592197854716389

Epoch: 124| Step: 0
Training loss: 3.305646896881207
Validation loss: 2.592625963133348

Epoch: 6| Step: 1
Training loss: 3.270385047337564
Validation loss: 2.59255723329324

Epoch: 6| Step: 2
Training loss: 2.8159196197785388
Validation loss: 2.5931570850839023

Epoch: 6| Step: 3
Training loss: 2.550735075972299
Validation loss: 2.5946837937441796

Epoch: 6| Step: 4
Training loss: 2.403971993307013
Validation loss: 2.593942410957359

Epoch: 6| Step: 5
Training loss: 3.0333785616119324
Validation loss: 2.590941330611553

Epoch: 6| Step: 6
Training loss: 2.6256812891820744
Validation loss: 2.595046230374372

Epoch: 6| Step: 7
Training loss: 3.1180412633880312
Validation loss: 2.5968565234189667

Epoch: 6| Step: 8
Training loss: 2.6305446195749944
Validation loss: 2.5990312609505257

Epoch: 6| Step: 9
Training loss: 2.281632273795387
Validation loss: 2.595965210300974

Epoch: 6| Step: 10
Training loss: 3.5811251260712886
Validation loss: 2.605016392708661

Epoch: 6| Step: 11
Training loss: 2.80741779183255
Validation loss: 2.5948118182965065

Epoch: 6| Step: 12
Training loss: 2.4604873487724417
Validation loss: 2.597760267732576

Epoch: 6| Step: 13
Training loss: 4.02815257700025
Validation loss: 2.5988574287807356

Epoch: 125| Step: 0
Training loss: 2.5326507836781267
Validation loss: 2.5901065761664763

Epoch: 6| Step: 1
Training loss: 2.666565376583288
Validation loss: 2.590437822123429

Epoch: 6| Step: 2
Training loss: 2.9019868818705623
Validation loss: 2.5897563914086392

Epoch: 6| Step: 3
Training loss: 2.890900139988368
Validation loss: 2.590394186862118

Epoch: 6| Step: 4
Training loss: 2.313457187814608
Validation loss: 2.588929350058813

Epoch: 6| Step: 5
Training loss: 2.5476952852489037
Validation loss: 2.5888493727376445

Epoch: 6| Step: 6
Training loss: 3.3958394961310945
Validation loss: 2.594102948406816

Epoch: 6| Step: 7
Training loss: 2.8602960489342406
Validation loss: 2.6026359195467266

Epoch: 6| Step: 8
Training loss: 2.7037292863437727
Validation loss: 2.610184021218637

Epoch: 6| Step: 9
Training loss: 3.300380777296233
Validation loss: 2.605333451939931

Epoch: 6| Step: 10
Training loss: 2.9668357700914854
Validation loss: 2.6050396827149114

Epoch: 6| Step: 11
Training loss: 3.388603486791903
Validation loss: 2.6048635391250263

Epoch: 6| Step: 12
Training loss: 2.7967186569758598
Validation loss: 2.5997848381879067

Epoch: 6| Step: 13
Training loss: 3.5978264286908463
Validation loss: 2.6034485538505057

Epoch: 126| Step: 0
Training loss: 3.0413834601116037
Validation loss: 2.5868200661016725

Epoch: 6| Step: 1
Training loss: 3.364085882081711
Validation loss: 2.5795730775032264

Epoch: 6| Step: 2
Training loss: 3.114857196994112
Validation loss: 2.5816512259857958

Epoch: 6| Step: 3
Training loss: 3.0284328937977687
Validation loss: 2.583009053127306

Epoch: 6| Step: 4
Training loss: 3.0313335289212255
Validation loss: 2.589358592910913

Epoch: 6| Step: 5
Training loss: 2.991622353511598
Validation loss: 2.587150187023209

Epoch: 6| Step: 6
Training loss: 2.512811070254284
Validation loss: 2.586158621295854

Epoch: 6| Step: 7
Training loss: 3.121933615194382
Validation loss: 2.58534794775

Epoch: 6| Step: 8
Training loss: 2.6940978035905228
Validation loss: 2.581656127545711

Epoch: 6| Step: 9
Training loss: 3.2675889237904343
Validation loss: 2.581758164470212

Epoch: 6| Step: 10
Training loss: 2.8112508754974805
Validation loss: 2.5836657823915115

Epoch: 6| Step: 11
Training loss: 1.729325651037544
Validation loss: 2.5876926599475656

Epoch: 6| Step: 12
Training loss: 3.2021853673724388
Validation loss: 2.5974390289899016

Epoch: 6| Step: 13
Training loss: 2.6150067253828637
Validation loss: 2.6053322160392445

Epoch: 127| Step: 0
Training loss: 2.908065884889291
Validation loss: 2.6028144009704848

Epoch: 6| Step: 1
Training loss: 2.7944325272609576
Validation loss: 2.611679456640377

Epoch: 6| Step: 2
Training loss: 2.755399604797224
Validation loss: 2.606626514595235

Epoch: 6| Step: 3
Training loss: 2.9529748303212378
Validation loss: 2.6032109813413165

Epoch: 6| Step: 4
Training loss: 2.7561095602020096
Validation loss: 2.6026291933494243

Epoch: 6| Step: 5
Training loss: 3.6909626366215798
Validation loss: 2.5980769573329887

Epoch: 6| Step: 6
Training loss: 3.0464832543132476
Validation loss: 2.604417830793992

Epoch: 6| Step: 7
Training loss: 3.4159523907365585
Validation loss: 2.601886244665005

Epoch: 6| Step: 8
Training loss: 2.2908946962303416
Validation loss: 2.6000277292147027

Epoch: 6| Step: 9
Training loss: 3.1950229802745427
Validation loss: 2.595740467203141

Epoch: 6| Step: 10
Training loss: 2.962065227812912
Validation loss: 2.587766380740612

Epoch: 6| Step: 11
Training loss: 1.946616842381284
Validation loss: 2.5883919508408937

Epoch: 6| Step: 12
Training loss: 2.593788790125511
Validation loss: 2.5890183535499376

Epoch: 6| Step: 13
Training loss: 2.9801993192029514
Validation loss: 2.5863321868902105

Epoch: 128| Step: 0
Training loss: 2.7399428872609115
Validation loss: 2.5891395053938404

Epoch: 6| Step: 1
Training loss: 2.7473363113584655
Validation loss: 2.583281184717741

Epoch: 6| Step: 2
Training loss: 3.105254697320252
Validation loss: 2.5891406653561853

Epoch: 6| Step: 3
Training loss: 2.5442999243008604
Validation loss: 2.5809557645457817

Epoch: 6| Step: 4
Training loss: 3.208814972894735
Validation loss: 2.58533426953214

Epoch: 6| Step: 5
Training loss: 2.810672929493817
Validation loss: 2.5914622641643676

Epoch: 6| Step: 6
Training loss: 3.097171163399444
Validation loss: 2.588433652878868

Epoch: 6| Step: 7
Training loss: 2.6492358779466034
Validation loss: 2.5871434369153574

Epoch: 6| Step: 8
Training loss: 3.0561895945689725
Validation loss: 2.5902072404744247

Epoch: 6| Step: 9
Training loss: 2.923847369154271
Validation loss: 2.5848229840663994

Epoch: 6| Step: 10
Training loss: 2.273952674829558
Validation loss: 2.5886321455680363

Epoch: 6| Step: 11
Training loss: 3.2762931076293538
Validation loss: 2.604903413639541

Epoch: 6| Step: 12
Training loss: 2.931154905944345
Validation loss: 2.6091750531772804

Epoch: 6| Step: 13
Training loss: 3.2426135415203086
Validation loss: 2.6122352329727816

Epoch: 129| Step: 0
Training loss: 3.2308803974141505
Validation loss: 2.6112942518663655

Epoch: 6| Step: 1
Training loss: 3.265295276696819
Validation loss: 2.6243583912724837

Epoch: 6| Step: 2
Training loss: 3.0888590057293634
Validation loss: 2.63722887483211

Epoch: 6| Step: 3
Training loss: 2.246617211421056
Validation loss: 2.6378038635392036

Epoch: 6| Step: 4
Training loss: 2.8460910090292697
Validation loss: 2.6235624186711344

Epoch: 6| Step: 5
Training loss: 2.5654112862753653
Validation loss: 2.611661922150727

Epoch: 6| Step: 6
Training loss: 2.7930857813931276
Validation loss: 2.5957566658259297

Epoch: 6| Step: 7
Training loss: 2.972853224214847
Validation loss: 2.5868619936662633

Epoch: 6| Step: 8
Training loss: 2.5546886199108783
Validation loss: 2.5870660908376273

Epoch: 6| Step: 9
Training loss: 2.960583990327202
Validation loss: 2.581192167949665

Epoch: 6| Step: 10
Training loss: 2.8443115015387543
Validation loss: 2.584549085549892

Epoch: 6| Step: 11
Training loss: 2.820095909868481
Validation loss: 2.5802836748202194

Epoch: 6| Step: 12
Training loss: 2.9243215833800598
Validation loss: 2.583446662618742

Epoch: 6| Step: 13
Training loss: 3.5295485727124127
Validation loss: 2.5803164240048138

Epoch: 130| Step: 0
Training loss: 2.9064924897786417
Validation loss: 2.5851554137779424

Epoch: 6| Step: 1
Training loss: 2.3466691212569026
Validation loss: 2.5897570323790067

Epoch: 6| Step: 2
Training loss: 3.1430316263538063
Validation loss: 2.589191166038417

Epoch: 6| Step: 3
Training loss: 2.285337991904841
Validation loss: 2.6054057629174157

Epoch: 6| Step: 4
Training loss: 2.9334908580387253
Validation loss: 2.609801638433806

Epoch: 6| Step: 5
Training loss: 3.054723246723786
Validation loss: 2.6626101177051518

Epoch: 6| Step: 6
Training loss: 2.974318892784794
Validation loss: 2.6404151529733135

Epoch: 6| Step: 7
Training loss: 3.3096835560811617
Validation loss: 2.6148168948717894

Epoch: 6| Step: 8
Training loss: 2.8646979476656633
Validation loss: 2.5965008984191735

Epoch: 6| Step: 9
Training loss: 2.798142641381263
Validation loss: 2.5873759893861785

Epoch: 6| Step: 10
Training loss: 2.912307824601372
Validation loss: 2.5706406749210347

Epoch: 6| Step: 11
Training loss: 2.6876825669843494
Validation loss: 2.577190395082486

Epoch: 6| Step: 12
Training loss: 3.4685233102218365
Validation loss: 2.586953300982099

Epoch: 6| Step: 13
Training loss: 2.734191801201155
Validation loss: 2.6050118608464325

Epoch: 131| Step: 0
Training loss: 2.8391167760939915
Validation loss: 2.5877797949677666

Epoch: 6| Step: 1
Training loss: 3.278623856078711
Validation loss: 2.5856995395797373

Epoch: 6| Step: 2
Training loss: 3.357498567514121
Validation loss: 2.579386540004757

Epoch: 6| Step: 3
Training loss: 3.067341616893456
Validation loss: 2.578605937629048

Epoch: 6| Step: 4
Training loss: 3.253297160317526
Validation loss: 2.5709524476654333

Epoch: 6| Step: 5
Training loss: 2.32818992575419
Validation loss: 2.57123146170051

Epoch: 6| Step: 6
Training loss: 3.4868193806548895
Validation loss: 2.5671908415347207

Epoch: 6| Step: 7
Training loss: 2.8847694267810935
Validation loss: 2.5761738762171413

Epoch: 6| Step: 8
Training loss: 3.2020050323847076
Validation loss: 2.587062762250675

Epoch: 6| Step: 9
Training loss: 2.4432341789780234
Validation loss: 2.59038080052385

Epoch: 6| Step: 10
Training loss: 2.50994696648488
Validation loss: 2.6098308885876462

Epoch: 6| Step: 11
Training loss: 2.6100868578960585
Validation loss: 2.6638058399335325

Epoch: 6| Step: 12
Training loss: 2.515915089816479
Validation loss: 2.6870149096891964

Epoch: 6| Step: 13
Training loss: 1.716670633823786
Validation loss: 2.7212483872968316

Epoch: 132| Step: 0
Training loss: 2.7810390263809066
Validation loss: 2.7327348544122696

Epoch: 6| Step: 1
Training loss: 2.1505947310676974
Validation loss: 2.642941900129419

Epoch: 6| Step: 2
Training loss: 2.9999443684823985
Validation loss: 2.602145520553068

Epoch: 6| Step: 3
Training loss: 3.3235921302767433
Validation loss: 2.5804046645056187

Epoch: 6| Step: 4
Training loss: 2.983944207700266
Validation loss: 2.5649118285868453

Epoch: 6| Step: 5
Training loss: 2.017712835078091
Validation loss: 2.5599898382595354

Epoch: 6| Step: 6
Training loss: 2.9246393682410035
Validation loss: 2.575914318017243

Epoch: 6| Step: 7
Training loss: 2.4989781198570284
Validation loss: 2.574821922228877

Epoch: 6| Step: 8
Training loss: 3.0450037761094806
Validation loss: 2.5753224085105155

Epoch: 6| Step: 9
Training loss: 3.1206677734572965
Validation loss: 2.574027910340992

Epoch: 6| Step: 10
Training loss: 2.9432851760513246
Validation loss: 2.5662769811939996

Epoch: 6| Step: 11
Training loss: 3.000950344876121
Validation loss: 2.5640109570036045

Epoch: 6| Step: 12
Training loss: 3.359147600860986
Validation loss: 2.5627027742005866

Epoch: 6| Step: 13
Training loss: 3.8473890492563774
Validation loss: 2.575971330430742

Epoch: 133| Step: 0
Training loss: 2.9426294546892886
Validation loss: 2.5657617602540603

Epoch: 6| Step: 1
Training loss: 2.8071888260178426
Validation loss: 2.577345394171086

Epoch: 6| Step: 2
Training loss: 2.428363598818432
Validation loss: 2.595263065391033

Epoch: 6| Step: 3
Training loss: 2.829942993560428
Validation loss: 2.6501952807325457

Epoch: 6| Step: 4
Training loss: 3.2174972021984396
Validation loss: 2.640373920936387

Epoch: 6| Step: 5
Training loss: 3.126204144226572
Validation loss: 2.624460014396768

Epoch: 6| Step: 6
Training loss: 3.2442573282929663
Validation loss: 2.5982690458906204

Epoch: 6| Step: 7
Training loss: 2.7513343001557224
Validation loss: 2.5924577415799592

Epoch: 6| Step: 8
Training loss: 2.3739446001602746
Validation loss: 2.5775919552435878

Epoch: 6| Step: 9
Training loss: 2.801360385665503
Validation loss: 2.5713247776976402

Epoch: 6| Step: 10
Training loss: 3.086001933909989
Validation loss: 2.582345085450435

Epoch: 6| Step: 11
Training loss: 3.421975608984004
Validation loss: 2.5776580099233635

Epoch: 6| Step: 12
Training loss: 2.5671394961251948
Validation loss: 2.5783611170839076

Epoch: 6| Step: 13
Training loss: 2.606617549895289
Validation loss: 2.5789411876798436

Epoch: 134| Step: 0
Training loss: 2.992706970858947
Validation loss: 2.589218699478466

Epoch: 6| Step: 1
Training loss: 3.3037428351161133
Validation loss: 2.598112036883919

Epoch: 6| Step: 2
Training loss: 2.947895081421959
Validation loss: 2.585203498784371

Epoch: 6| Step: 3
Training loss: 2.838395831826901
Validation loss: 2.5751301165181566

Epoch: 6| Step: 4
Training loss: 2.6863435430557163
Validation loss: 2.5693955623459765

Epoch: 6| Step: 5
Training loss: 3.0147181911572973
Validation loss: 2.5642310257687586

Epoch: 6| Step: 6
Training loss: 2.9532645056334483
Validation loss: 2.5645088557316083

Epoch: 6| Step: 7
Training loss: 2.5237808230191385
Validation loss: 2.5691045451112697

Epoch: 6| Step: 8
Training loss: 2.769824960734947
Validation loss: 2.5655494111545436

Epoch: 6| Step: 9
Training loss: 2.836947678910123
Validation loss: 2.5719591388070473

Epoch: 6| Step: 10
Training loss: 3.273523880358272
Validation loss: 2.579636773853631

Epoch: 6| Step: 11
Training loss: 2.2161009111942964
Validation loss: 2.5958023886254264

Epoch: 6| Step: 12
Training loss: 2.8593933438405785
Validation loss: 2.6109089166183437

Epoch: 6| Step: 13
Training loss: 3.2823702398540435
Validation loss: 2.6657491436664507

Epoch: 135| Step: 0
Training loss: 3.1831409342943906
Validation loss: 2.6267569815187355

Epoch: 6| Step: 1
Training loss: 2.673205128240968
Validation loss: 2.5784176140545108

Epoch: 6| Step: 2
Training loss: 2.996184943252396
Validation loss: 2.5797714529697506

Epoch: 6| Step: 3
Training loss: 3.1693423829142726
Validation loss: 2.5680102638173943

Epoch: 6| Step: 4
Training loss: 2.5519219691326276
Validation loss: 2.57024459382619

Epoch: 6| Step: 5
Training loss: 2.559409161573752
Validation loss: 2.578838706270327

Epoch: 6| Step: 6
Training loss: 3.0844568490992184
Validation loss: 2.597154062083883

Epoch: 6| Step: 7
Training loss: 2.851880868357703
Validation loss: 2.5830369303620038

Epoch: 6| Step: 8
Training loss: 2.6983895691290884
Validation loss: 2.591103577677663

Epoch: 6| Step: 9
Training loss: 3.5416719025217884
Validation loss: 2.6092324333698005

Epoch: 6| Step: 10
Training loss: 2.6747844537900733
Validation loss: 2.6207462743912875

Epoch: 6| Step: 11
Training loss: 2.2448495619905664
Validation loss: 2.6466371902393218

Epoch: 6| Step: 12
Training loss: 3.0841501202294497
Validation loss: 2.654275956636197

Epoch: 6| Step: 13
Training loss: 2.94404376400678
Validation loss: 2.618997616977094

Epoch: 136| Step: 0
Training loss: 2.9636379197260725
Validation loss: 2.5970702542989366

Epoch: 6| Step: 1
Training loss: 2.996374641789227
Validation loss: 2.609787773056774

Epoch: 6| Step: 2
Training loss: 2.8677813255442155
Validation loss: 2.629681927322382

Epoch: 6| Step: 3
Training loss: 2.7144740010687203
Validation loss: 2.6231618208284653

Epoch: 6| Step: 4
Training loss: 3.213982616242242
Validation loss: 2.6130802236573296

Epoch: 6| Step: 5
Training loss: 2.8059212778839475
Validation loss: 2.5872176286707718

Epoch: 6| Step: 6
Training loss: 3.216966301463759
Validation loss: 2.5770907517965034

Epoch: 6| Step: 7
Training loss: 2.5228997475403014
Validation loss: 2.56638502281167

Epoch: 6| Step: 8
Training loss: 2.8017312624003443
Validation loss: 2.564880096125143

Epoch: 6| Step: 9
Training loss: 3.10263727048886
Validation loss: 2.563377442240117

Epoch: 6| Step: 10
Training loss: 2.756416378059937
Validation loss: 2.5640620111204018

Epoch: 6| Step: 11
Training loss: 2.755352965935295
Validation loss: 2.563611169580999

Epoch: 6| Step: 12
Training loss: 2.5714926749519513
Validation loss: 2.5601705993027712

Epoch: 6| Step: 13
Training loss: 3.0730542857933076
Validation loss: 2.5639449556879805

Epoch: 137| Step: 0
Training loss: 2.676539760477416
Validation loss: 2.5625452717429353

Epoch: 6| Step: 1
Training loss: 2.3677814607170427
Validation loss: 2.5639340629578746

Epoch: 6| Step: 2
Training loss: 3.233634827180806
Validation loss: 2.572726058592052

Epoch: 6| Step: 3
Training loss: 2.483762749618575
Validation loss: 2.5696086381729955

Epoch: 6| Step: 4
Training loss: 3.0128455126152325
Validation loss: 2.568965573535866

Epoch: 6| Step: 5
Training loss: 3.1649678006575703
Validation loss: 2.5638361052983476

Epoch: 6| Step: 6
Training loss: 2.7681218315170115
Validation loss: 2.5615309456896886

Epoch: 6| Step: 7
Training loss: 3.733540333958235
Validation loss: 2.5646026852375754

Epoch: 6| Step: 8
Training loss: 2.5336869365294694
Validation loss: 2.562099581571687

Epoch: 6| Step: 9
Training loss: 2.773550197836818
Validation loss: 2.5710649672766626

Epoch: 6| Step: 10
Training loss: 2.8501186948453623
Validation loss: 2.582219586028652

Epoch: 6| Step: 11
Training loss: 2.5754905418617793
Validation loss: 2.5822717464861595

Epoch: 6| Step: 12
Training loss: 3.078865852855621
Validation loss: 2.585567655982841

Epoch: 6| Step: 13
Training loss: 2.4007890834612278
Validation loss: 2.5745057457315452

Epoch: 138| Step: 0
Training loss: 3.15117910206265
Validation loss: 2.589957401838971

Epoch: 6| Step: 1
Training loss: 3.2074401074449823
Validation loss: 2.578576250754868

Epoch: 6| Step: 2
Training loss: 3.1846321518739056
Validation loss: 2.5737567088414277

Epoch: 6| Step: 3
Training loss: 2.7833568865146883
Validation loss: 2.575011623829038

Epoch: 6| Step: 4
Training loss: 3.1511567065884774
Validation loss: 2.5701383443239956

Epoch: 6| Step: 5
Training loss: 3.0909460442929877
Validation loss: 2.5669390538531642

Epoch: 6| Step: 6
Training loss: 2.4622998538710785
Validation loss: 2.566467944202943

Epoch: 6| Step: 7
Training loss: 2.9295060165142957
Validation loss: 2.561741504317257

Epoch: 6| Step: 8
Training loss: 2.5798495911217922
Validation loss: 2.5710314561063603

Epoch: 6| Step: 9
Training loss: 2.767169327248125
Validation loss: 2.5699005789295777

Epoch: 6| Step: 10
Training loss: 1.9629301608075327
Validation loss: 2.5719664450892057

Epoch: 6| Step: 11
Training loss: 2.906158938057999
Validation loss: 2.5659209376109824

Epoch: 6| Step: 12
Training loss: 3.1406574911837666
Validation loss: 2.5608094694459638

Epoch: 6| Step: 13
Training loss: 1.9787293871289708
Validation loss: 2.5588788133383193

Epoch: 139| Step: 0
Training loss: 2.9755742392389837
Validation loss: 2.567276357683113

Epoch: 6| Step: 1
Training loss: 2.0949117369711456
Validation loss: 2.5621630459357947

Epoch: 6| Step: 2
Training loss: 3.1184510846505833
Validation loss: 2.5659322535207547

Epoch: 6| Step: 3
Training loss: 3.097845584042762
Validation loss: 2.5662431737373246

Epoch: 6| Step: 4
Training loss: 2.770976433369131
Validation loss: 2.5651696028086963

Epoch: 6| Step: 5
Training loss: 3.1045507069724416
Validation loss: 2.5708215327080213

Epoch: 6| Step: 6
Training loss: 3.0428990171226125
Validation loss: 2.5634312191970334

Epoch: 6| Step: 7
Training loss: 2.8087504506333603
Validation loss: 2.561322061283104

Epoch: 6| Step: 8
Training loss: 3.013633109713008
Validation loss: 2.565237529397064

Epoch: 6| Step: 9
Training loss: 2.332047505537723
Validation loss: 2.5600711327394134

Epoch: 6| Step: 10
Training loss: 2.7726771212276233
Validation loss: 2.568612805998193

Epoch: 6| Step: 11
Training loss: 2.865820119490299
Validation loss: 2.565315919369396

Epoch: 6| Step: 12
Training loss: 3.198436450445602
Validation loss: 2.5685065798226483

Epoch: 6| Step: 13
Training loss: 2.208268026669839
Validation loss: 2.5642866703502714

Epoch: 140| Step: 0
Training loss: 2.9202445473885805
Validation loss: 2.5704803247435835

Epoch: 6| Step: 1
Training loss: 2.4450702973851843
Validation loss: 2.584745362249654

Epoch: 6| Step: 2
Training loss: 2.365860671041876
Validation loss: 2.5860554415091457

Epoch: 6| Step: 3
Training loss: 2.827010298600547
Validation loss: 2.5700302869249776

Epoch: 6| Step: 4
Training loss: 2.6504733832418386
Validation loss: 2.559764670717399

Epoch: 6| Step: 5
Training loss: 3.460360580133732
Validation loss: 2.5566258275529243

Epoch: 6| Step: 6
Training loss: 3.08797154088322
Validation loss: 2.552117317648143

Epoch: 6| Step: 7
Training loss: 3.146795635112811
Validation loss: 2.5499581380790395

Epoch: 6| Step: 8
Training loss: 2.9474393819928615
Validation loss: 2.5529028421590074

Epoch: 6| Step: 9
Training loss: 2.5424639175840427
Validation loss: 2.5470743580052972

Epoch: 6| Step: 10
Training loss: 2.8246955099835263
Validation loss: 2.550899410979954

Epoch: 6| Step: 11
Training loss: 3.164717542871665
Validation loss: 2.553709875887859

Epoch: 6| Step: 12
Training loss: 2.2578703665000224
Validation loss: 2.5652198183681

Epoch: 6| Step: 13
Training loss: 3.3332900680277295
Validation loss: 2.570776638067259

Epoch: 141| Step: 0
Training loss: 2.0499654255254183
Validation loss: 2.5710008322102884

Epoch: 6| Step: 1
Training loss: 3.127215096283409
Validation loss: 2.5629463017240153

Epoch: 6| Step: 2
Training loss: 2.6718374327756913
Validation loss: 2.560464459217203

Epoch: 6| Step: 3
Training loss: 3.1790671903380074
Validation loss: 2.552376259489514

Epoch: 6| Step: 4
Training loss: 2.857676684373106
Validation loss: 2.54935703845868

Epoch: 6| Step: 5
Training loss: 2.739955765582918
Validation loss: 2.544342345989123

Epoch: 6| Step: 6
Training loss: 2.776303553917048
Validation loss: 2.5442515589651027

Epoch: 6| Step: 7
Training loss: 3.2466881824018086
Validation loss: 2.549967043593509

Epoch: 6| Step: 8
Training loss: 2.8879377091154437
Validation loss: 2.556959915939444

Epoch: 6| Step: 9
Training loss: 3.1747841108318884
Validation loss: 2.5665098321646345

Epoch: 6| Step: 10
Training loss: 2.7769366474336183
Validation loss: 2.5749190487727875

Epoch: 6| Step: 11
Training loss: 2.7807647624681544
Validation loss: 2.581485596249829

Epoch: 6| Step: 12
Training loss: 2.378725342535053
Validation loss: 2.57348980215559

Epoch: 6| Step: 13
Training loss: 3.1410133539235976
Validation loss: 2.5918640582519474

Epoch: 142| Step: 0
Training loss: 2.958597592295168
Validation loss: 2.5731749753472655

Epoch: 6| Step: 1
Training loss: 2.981741657142101
Validation loss: 2.5547215165721635

Epoch: 6| Step: 2
Training loss: 3.123620300897612
Validation loss: 2.53747808023738

Epoch: 6| Step: 3
Training loss: 2.5922375601176517
Validation loss: 2.5416861746362316

Epoch: 6| Step: 4
Training loss: 2.929930653972029
Validation loss: 2.538963724112921

Epoch: 6| Step: 5
Training loss: 2.671423801449917
Validation loss: 2.5407259239196502

Epoch: 6| Step: 6
Training loss: 3.510228198205781
Validation loss: 2.544545373276042

Epoch: 6| Step: 7
Training loss: 3.0046354085976277
Validation loss: 2.5419484628983984

Epoch: 6| Step: 8
Training loss: 3.284004581081155
Validation loss: 2.5429776436988067

Epoch: 6| Step: 9
Training loss: 2.840854554086348
Validation loss: 2.5361865788482447

Epoch: 6| Step: 10
Training loss: 2.3024332692502916
Validation loss: 2.544314623150318

Epoch: 6| Step: 11
Training loss: 2.414059537126519
Validation loss: 2.54157453161876

Epoch: 6| Step: 12
Training loss: 2.5819527618436573
Validation loss: 2.546476737517466

Epoch: 6| Step: 13
Training loss: 2.6093570914196453
Validation loss: 2.5551571331081

Epoch: 143| Step: 0
Training loss: 2.7172252720406003
Validation loss: 2.5618035455263386

Epoch: 6| Step: 1
Training loss: 2.850478209145439
Validation loss: 2.5803703407241767

Epoch: 6| Step: 2
Training loss: 3.049475552855103
Validation loss: 2.5681780902702602

Epoch: 6| Step: 3
Training loss: 3.1621142005058918
Validation loss: 2.542091656528158

Epoch: 6| Step: 4
Training loss: 2.7534715241704832
Validation loss: 2.5393649689874014

Epoch: 6| Step: 5
Training loss: 2.6377796440667813
Validation loss: 2.53015946758531

Epoch: 6| Step: 6
Training loss: 2.673124946770836
Validation loss: 2.5371631358099376

Epoch: 6| Step: 7
Training loss: 2.2883043302998067
Validation loss: 2.5393494096050344

Epoch: 6| Step: 8
Training loss: 3.129843505993435
Validation loss: 2.535115266306191

Epoch: 6| Step: 9
Training loss: 2.7946250859247876
Validation loss: 2.5307168747292748

Epoch: 6| Step: 10
Training loss: 2.91318267549106
Validation loss: 2.53204312616419

Epoch: 6| Step: 11
Training loss: 2.926624375242687
Validation loss: 2.5432956712809536

Epoch: 6| Step: 12
Training loss: 3.252041395667611
Validation loss: 2.567114238472455

Epoch: 6| Step: 13
Training loss: 2.639295254477531
Validation loss: 2.578350113244582

Epoch: 144| Step: 0
Training loss: 2.9279434913226905
Validation loss: 2.584244026390463

Epoch: 6| Step: 1
Training loss: 2.564371309624066
Validation loss: 2.568829875802279

Epoch: 6| Step: 2
Training loss: 3.0559326131890634
Validation loss: 2.5641718807072333

Epoch: 6| Step: 3
Training loss: 3.0918355856211344
Validation loss: 2.555060814565037

Epoch: 6| Step: 4
Training loss: 3.0642645287329193
Validation loss: 2.538689022188922

Epoch: 6| Step: 5
Training loss: 2.441181044300534
Validation loss: 2.5348628401586275

Epoch: 6| Step: 6
Training loss: 2.5618212661635993
Validation loss: 2.533345665386259

Epoch: 6| Step: 7
Training loss: 2.4395327772662125
Validation loss: 2.536650503041125

Epoch: 6| Step: 8
Training loss: 2.778869467366648
Validation loss: 2.5371591839921797

Epoch: 6| Step: 9
Training loss: 3.080626270234335
Validation loss: 2.5453623382622963

Epoch: 6| Step: 10
Training loss: 2.7344843379367503
Validation loss: 2.5507356649371244

Epoch: 6| Step: 11
Training loss: 2.90677334575115
Validation loss: 2.5634127546222207

Epoch: 6| Step: 12
Training loss: 3.0669140826499275
Validation loss: 2.5739034496057203

Epoch: 6| Step: 13
Training loss: 3.158523194201769
Validation loss: 2.5766021337622216

Epoch: 145| Step: 0
Training loss: 2.215039656652222
Validation loss: 2.5598762469813567

Epoch: 6| Step: 1
Training loss: 2.740038080994995
Validation loss: 2.5379035817691102

Epoch: 6| Step: 2
Training loss: 2.8745757080130336
Validation loss: 2.5318082677174965

Epoch: 6| Step: 3
Training loss: 2.8335891121993857
Validation loss: 2.5270930385843684

Epoch: 6| Step: 4
Training loss: 2.609201939491722
Validation loss: 2.5281265313745838

Epoch: 6| Step: 5
Training loss: 2.892975712251952
Validation loss: 2.5344755089653574

Epoch: 6| Step: 6
Training loss: 2.6890098411462255
Validation loss: 2.5402650671987006

Epoch: 6| Step: 7
Training loss: 2.7154382288085834
Validation loss: 2.539733608207468

Epoch: 6| Step: 8
Training loss: 2.988588564161176
Validation loss: 2.541260143297092

Epoch: 6| Step: 9
Training loss: 3.577320258252333
Validation loss: 2.537539365939839

Epoch: 6| Step: 10
Training loss: 2.81213571520494
Validation loss: 2.52679638174141

Epoch: 6| Step: 11
Training loss: 2.983031125097145
Validation loss: 2.522500549480257

Epoch: 6| Step: 12
Training loss: 3.1190829907695794
Validation loss: 2.5241061902228714

Epoch: 6| Step: 13
Training loss: 2.801987392290982
Validation loss: 2.5366723863361136

Epoch: 146| Step: 0
Training loss: 2.9131759644989312
Validation loss: 2.536171139461182

Epoch: 6| Step: 1
Training loss: 2.913572704889522
Validation loss: 2.5452450644386517

Epoch: 6| Step: 2
Training loss: 3.214370562932147
Validation loss: 2.571505120802004

Epoch: 6| Step: 3
Training loss: 3.2584178188392148
Validation loss: 2.572851638467056

Epoch: 6| Step: 4
Training loss: 2.7442462724325174
Validation loss: 2.572503596335751

Epoch: 6| Step: 5
Training loss: 2.8027761423009365
Validation loss: 2.5756184603930494

Epoch: 6| Step: 6
Training loss: 2.3425036358881433
Validation loss: 2.580020933063939

Epoch: 6| Step: 7
Training loss: 1.8783535531057747
Validation loss: 2.5617067843617907

Epoch: 6| Step: 8
Training loss: 3.355932982974818
Validation loss: 2.5334852065700906

Epoch: 6| Step: 9
Training loss: 2.7165011170228923
Validation loss: 2.522014822753967

Epoch: 6| Step: 10
Training loss: 3.339820049714885
Validation loss: 2.521050746786155

Epoch: 6| Step: 11
Training loss: 3.210355311423634
Validation loss: 2.5263954020637307

Epoch: 6| Step: 12
Training loss: 1.995949697055582
Validation loss: 2.534275154817587

Epoch: 6| Step: 13
Training loss: 2.493597797538952
Validation loss: 2.5345383217826587

Epoch: 147| Step: 0
Training loss: 2.7788356631550317
Validation loss: 2.5333597943111936

Epoch: 6| Step: 1
Training loss: 2.926608733847125
Validation loss: 2.5341702783543365

Epoch: 6| Step: 2
Training loss: 2.398715820068984
Validation loss: 2.534933943331483

Epoch: 6| Step: 3
Training loss: 2.688903264812085
Validation loss: 2.5346433610308114

Epoch: 6| Step: 4
Training loss: 2.8495754059511498
Validation loss: 2.5320931927585475

Epoch: 6| Step: 5
Training loss: 2.96026748685824
Validation loss: 2.5299339514233616

Epoch: 6| Step: 6
Training loss: 2.527049311329977
Validation loss: 2.52620557264476

Epoch: 6| Step: 7
Training loss: 3.110339911183044
Validation loss: 2.5232721028993077

Epoch: 6| Step: 8
Training loss: 2.7445791742542243
Validation loss: 2.529989514361385

Epoch: 6| Step: 9
Training loss: 3.035390326901222
Validation loss: 2.548810340179038

Epoch: 6| Step: 10
Training loss: 2.9121506379118896
Validation loss: 2.593065311080254

Epoch: 6| Step: 11
Training loss: 3.312508061237243
Validation loss: 2.645785238190436

Epoch: 6| Step: 12
Training loss: 3.076043834140805
Validation loss: 2.653738303523004

Epoch: 6| Step: 13
Training loss: 3.0662398566518747
Validation loss: 2.619445047514147

Epoch: 148| Step: 0
Training loss: 2.4281009510867158
Validation loss: 2.5820456466830697

Epoch: 6| Step: 1
Training loss: 2.17048413866105
Validation loss: 2.5527109904104393

Epoch: 6| Step: 2
Training loss: 3.411357724790711
Validation loss: 2.5268317660349076

Epoch: 6| Step: 3
Training loss: 2.6597588196027453
Validation loss: 2.5193971664848

Epoch: 6| Step: 4
Training loss: 2.5210981834143307
Validation loss: 2.5255275076612405

Epoch: 6| Step: 5
Training loss: 2.4340461322735125
Validation loss: 2.5394435892541356

Epoch: 6| Step: 6
Training loss: 2.7831944729854556
Validation loss: 2.5377846727529634

Epoch: 6| Step: 7
Training loss: 2.4357937440668604
Validation loss: 2.5324683063578726

Epoch: 6| Step: 8
Training loss: 3.459255524513116
Validation loss: 2.5310257610177986

Epoch: 6| Step: 9
Training loss: 2.9722057908535864
Validation loss: 2.5316750430234305

Epoch: 6| Step: 10
Training loss: 2.5963235978929102
Validation loss: 2.525442039600138

Epoch: 6| Step: 11
Training loss: 3.0457993393726146
Validation loss: 2.5342691075413177

Epoch: 6| Step: 12
Training loss: 3.4647885633200164
Validation loss: 2.5338749311749083

Epoch: 6| Step: 13
Training loss: 3.464194253042826
Validation loss: 2.536145849352066

Epoch: 149| Step: 0
Training loss: 3.1932357344183666
Validation loss: 2.5432818293948514

Epoch: 6| Step: 1
Training loss: 2.7814213560658603
Validation loss: 2.5532518823507995

Epoch: 6| Step: 2
Training loss: 2.714983380795471
Validation loss: 2.5590072927623795

Epoch: 6| Step: 3
Training loss: 2.498680720320636
Validation loss: 2.5665055289771

Epoch: 6| Step: 4
Training loss: 2.33072880295621
Validation loss: 2.587794170567269

Epoch: 6| Step: 5
Training loss: 2.9123909991254795
Validation loss: 2.573802441971515

Epoch: 6| Step: 6
Training loss: 2.5373162940664797
Validation loss: 2.572045587839571

Epoch: 6| Step: 7
Training loss: 3.337253855797408
Validation loss: 2.5670130695549904

Epoch: 6| Step: 8
Training loss: 2.493506772983884
Validation loss: 2.5591669733848548

Epoch: 6| Step: 9
Training loss: 3.167699310848521
Validation loss: 2.547618114097719

Epoch: 6| Step: 10
Training loss: 2.9518864370589326
Validation loss: 2.5398767954903843

Epoch: 6| Step: 11
Training loss: 3.0495782842037054
Validation loss: 2.5459291659785444

Epoch: 6| Step: 12
Training loss: 2.731702795839057
Validation loss: 2.54445562823982

Epoch: 6| Step: 13
Training loss: 2.8490969515499214
Validation loss: 2.5651980766686258

Epoch: 150| Step: 0
Training loss: 3.1025181602419907
Validation loss: 2.5595391598492836

Epoch: 6| Step: 1
Training loss: 2.8628368995675233
Validation loss: 2.5674185880284086

Epoch: 6| Step: 2
Training loss: 2.7775633305317715
Validation loss: 2.5598390080301097

Epoch: 6| Step: 3
Training loss: 2.999153017643846
Validation loss: 2.546452198105556

Epoch: 6| Step: 4
Training loss: 2.952734542949625
Validation loss: 2.535701649874661

Epoch: 6| Step: 5
Training loss: 3.529740677728912
Validation loss: 2.5273081537694804

Epoch: 6| Step: 6
Training loss: 2.3131232581638392
Validation loss: 2.5216531792432697

Epoch: 6| Step: 7
Training loss: 2.7258633916914423
Validation loss: 2.5145158849407694

Epoch: 6| Step: 8
Training loss: 2.8220726712803312
Validation loss: 2.5062751217008756

Epoch: 6| Step: 9
Training loss: 3.0951162076712495
Validation loss: 2.5070561964981763

Epoch: 6| Step: 10
Training loss: 2.626732753884024
Validation loss: 2.509019197123602

Epoch: 6| Step: 11
Training loss: 2.940689141347245
Validation loss: 2.516066710960031

Epoch: 6| Step: 12
Training loss: 2.214046381835848
Validation loss: 2.5141452642788367

Epoch: 6| Step: 13
Training loss: 2.2987359222097203
Validation loss: 2.51453647235632

Epoch: 151| Step: 0
Training loss: 2.7234995779643283
Validation loss: 2.52166252834638

Epoch: 6| Step: 1
Training loss: 2.582230876182956
Validation loss: 2.525754376435158

Epoch: 6| Step: 2
Training loss: 3.217648956715879
Validation loss: 2.5204074133349628

Epoch: 6| Step: 3
Training loss: 3.1895350523387664
Validation loss: 2.5278009372443417

Epoch: 6| Step: 4
Training loss: 2.65127456531358
Validation loss: 2.521597143880417

Epoch: 6| Step: 5
Training loss: 2.6176043278143064
Validation loss: 2.5267430273855083

Epoch: 6| Step: 6
Training loss: 3.0591381070902885
Validation loss: 2.5270790384585116

Epoch: 6| Step: 7
Training loss: 2.6825114237319005
Validation loss: 2.524520492793449

Epoch: 6| Step: 8
Training loss: 2.6350073113240504
Validation loss: 2.529528904883417

Epoch: 6| Step: 9
Training loss: 2.9588573869202976
Validation loss: 2.5346376372832577

Epoch: 6| Step: 10
Training loss: 2.6594341267020654
Validation loss: 2.5332118009933757

Epoch: 6| Step: 11
Training loss: 2.178098256454586
Validation loss: 2.5347342464221567

Epoch: 6| Step: 12
Training loss: 2.716761420846124
Validation loss: 2.525799604429217

Epoch: 6| Step: 13
Training loss: 3.6628117815961962
Validation loss: 2.5277766490807396

Epoch: 152| Step: 0
Training loss: 3.23120891021044
Validation loss: 2.515124074999878

Epoch: 6| Step: 1
Training loss: 2.343678079137395
Validation loss: 2.51571470964467

Epoch: 6| Step: 2
Training loss: 3.0842441210279876
Validation loss: 2.5149948644511215

Epoch: 6| Step: 3
Training loss: 2.6419917074126773
Validation loss: 2.5131564896494516

Epoch: 6| Step: 4
Training loss: 2.6780418926150267
Validation loss: 2.5134184611017045

Epoch: 6| Step: 5
Training loss: 2.6878828618775046
Validation loss: 2.5145843336482936

Epoch: 6| Step: 6
Training loss: 2.4383074083425424
Validation loss: 2.5181297948348345

Epoch: 6| Step: 7
Training loss: 3.056311602449444
Validation loss: 2.5301328680572595

Epoch: 6| Step: 8
Training loss: 3.224981109800387
Validation loss: 2.5371861539398144

Epoch: 6| Step: 9
Training loss: 2.6464061767736675
Validation loss: 2.5409683856613543

Epoch: 6| Step: 10
Training loss: 3.4331279347530637
Validation loss: 2.539005446380679

Epoch: 6| Step: 11
Training loss: 2.5869501902677348
Validation loss: 2.538997865521546

Epoch: 6| Step: 12
Training loss: 2.586620782202689
Validation loss: 2.536402850784377

Epoch: 6| Step: 13
Training loss: 2.3788427084468533
Validation loss: 2.530153264566326

Epoch: 153| Step: 0
Training loss: 2.81380076528245
Validation loss: 2.5239857287305325

Epoch: 6| Step: 1
Training loss: 2.7544718709365617
Validation loss: 2.5272968262077464

Epoch: 6| Step: 2
Training loss: 2.944489786610677
Validation loss: 2.523625043201626

Epoch: 6| Step: 3
Training loss: 2.522146644757666
Validation loss: 2.520607097022875

Epoch: 6| Step: 4
Training loss: 2.551860399954216
Validation loss: 2.5192817164412236

Epoch: 6| Step: 5
Training loss: 3.326255882398471
Validation loss: 2.529873440107929

Epoch: 6| Step: 6
Training loss: 2.4322829535666566
Validation loss: 2.517275391730392

Epoch: 6| Step: 7
Training loss: 3.1636142742896545
Validation loss: 2.521669115193667

Epoch: 6| Step: 8
Training loss: 3.1375702382770765
Validation loss: 2.5190827733914434

Epoch: 6| Step: 9
Training loss: 3.165921642266388
Validation loss: 2.5132058971233366

Epoch: 6| Step: 10
Training loss: 2.9407238415637242
Validation loss: 2.506816879137313

Epoch: 6| Step: 11
Training loss: 2.2701875194113406
Validation loss: 2.5137699283141517

Epoch: 6| Step: 12
Training loss: 2.457854164968386
Validation loss: 2.5223793740507827

Epoch: 6| Step: 13
Training loss: 2.4452236756593715
Validation loss: 2.518231887188975

Epoch: 154| Step: 0
Training loss: 2.6214435645269023
Validation loss: 2.5207502988236667

Epoch: 6| Step: 1
Training loss: 2.5904558704050746
Validation loss: 2.523198254984731

Epoch: 6| Step: 2
Training loss: 2.4965529519410765
Validation loss: 2.5359832371959037

Epoch: 6| Step: 3
Training loss: 3.387802144332019
Validation loss: 2.5405728334730195

Epoch: 6| Step: 4
Training loss: 3.4002205216194565
Validation loss: 2.5387127591076744

Epoch: 6| Step: 5
Training loss: 2.1437158476219413
Validation loss: 2.534493378191417

Epoch: 6| Step: 6
Training loss: 2.3234461934915327
Validation loss: 2.532504116538031

Epoch: 6| Step: 7
Training loss: 3.0213439159135027
Validation loss: 2.5267857306433203

Epoch: 6| Step: 8
Training loss: 2.79078240885101
Validation loss: 2.5293250877969293

Epoch: 6| Step: 9
Training loss: 3.040731800238463
Validation loss: 2.517745222905282

Epoch: 6| Step: 10
Training loss: 2.859478891288432
Validation loss: 2.5094060983223576

Epoch: 6| Step: 11
Training loss: 2.5636889792945152
Validation loss: 2.5151694309541033

Epoch: 6| Step: 12
Training loss: 3.139130953416916
Validation loss: 2.513783498255394

Epoch: 6| Step: 13
Training loss: 2.4039778447391784
Validation loss: 2.508139807343854

Epoch: 155| Step: 0
Training loss: 3.004958029404718
Validation loss: 2.511557317392996

Epoch: 6| Step: 1
Training loss: 3.1902004097673835
Validation loss: 2.5073763621730576

Epoch: 6| Step: 2
Training loss: 2.9152639739971984
Validation loss: 2.5117749455223453

Epoch: 6| Step: 3
Training loss: 2.5411448229609004
Validation loss: 2.5157198425974086

Epoch: 6| Step: 4
Training loss: 2.830179890553006
Validation loss: 2.5480749868004606

Epoch: 6| Step: 5
Training loss: 3.5559254261860835
Validation loss: 2.5630572973831245

Epoch: 6| Step: 6
Training loss: 2.6126230092269886
Validation loss: 2.590487691365875

Epoch: 6| Step: 7
Training loss: 2.6573980206707635
Validation loss: 2.6291471030077176

Epoch: 6| Step: 8
Training loss: 2.77502868568784
Validation loss: 2.6632845090874913

Epoch: 6| Step: 9
Training loss: 3.213077027267522
Validation loss: 2.6795083435148026

Epoch: 6| Step: 10
Training loss: 2.517699908262294
Validation loss: 2.6491418080416986

Epoch: 6| Step: 11
Training loss: 3.09177096483142
Validation loss: 2.5977932273592437

Epoch: 6| Step: 12
Training loss: 2.519805088982559
Validation loss: 2.546036718774363

Epoch: 6| Step: 13
Training loss: 2.2180351932647038
Validation loss: 2.5146245814911317

Epoch: 156| Step: 0
Training loss: 2.710944535743752
Validation loss: 2.5095093393361587

Epoch: 6| Step: 1
Training loss: 2.679245003068683
Validation loss: 2.5089997466338034

Epoch: 6| Step: 2
Training loss: 2.7160773459139222
Validation loss: 2.517132334447354

Epoch: 6| Step: 3
Training loss: 2.8031615460074963
Validation loss: 2.515966586986881

Epoch: 6| Step: 4
Training loss: 3.229443757669075
Validation loss: 2.506960591531513

Epoch: 6| Step: 5
Training loss: 2.6207797321444137
Validation loss: 2.5037886583460613

Epoch: 6| Step: 6
Training loss: 2.61680267693229
Validation loss: 2.501123524538375

Epoch: 6| Step: 7
Training loss: 2.8506106943726257
Validation loss: 2.5025923926511737

Epoch: 6| Step: 8
Training loss: 2.6705031414517038
Validation loss: 2.500104145218844

Epoch: 6| Step: 9
Training loss: 2.7680779048232025
Validation loss: 2.5059553114937745

Epoch: 6| Step: 10
Training loss: 2.9205836742178626
Validation loss: 2.504141222227494

Epoch: 6| Step: 11
Training loss: 3.19814870450209
Validation loss: 2.5096311086034513

Epoch: 6| Step: 12
Training loss: 3.070401954803719
Validation loss: 2.5108558880893144

Epoch: 6| Step: 13
Training loss: 2.359072027900951
Validation loss: 2.526188246585812

Epoch: 157| Step: 0
Training loss: 3.360977287535806
Validation loss: 2.5270375453651512

Epoch: 6| Step: 1
Training loss: 2.8398202425522934
Validation loss: 2.5387681703064744

Epoch: 6| Step: 2
Training loss: 3.073235515712094
Validation loss: 2.530687297713457

Epoch: 6| Step: 3
Training loss: 2.631465941060686
Validation loss: 2.5442657099514046

Epoch: 6| Step: 4
Training loss: 2.8425520165615104
Validation loss: 2.5285232068291155

Epoch: 6| Step: 5
Training loss: 2.3711929928970794
Validation loss: 2.526307668445843

Epoch: 6| Step: 6
Training loss: 2.004919439205136
Validation loss: 2.521962775128746

Epoch: 6| Step: 7
Training loss: 2.7347591457282014
Validation loss: 2.508106399369485

Epoch: 6| Step: 8
Training loss: 2.3598840429622867
Validation loss: 2.516342475539568

Epoch: 6| Step: 9
Training loss: 3.554192208797954
Validation loss: 2.512525177896153

Epoch: 6| Step: 10
Training loss: 2.9766417965877037
Validation loss: 2.5030727187087036

Epoch: 6| Step: 11
Training loss: 2.6700034920887488
Validation loss: 2.4983543260610377

Epoch: 6| Step: 12
Training loss: 2.3937849714548274
Validation loss: 2.500971188126447

Epoch: 6| Step: 13
Training loss: 3.2675213577985125
Validation loss: 2.503737860901423

Epoch: 158| Step: 0
Training loss: 2.54985162639915
Validation loss: 2.5099628797272784

Epoch: 6| Step: 1
Training loss: 2.249429842446496
Validation loss: 2.5073774014825947

Epoch: 6| Step: 2
Training loss: 2.5674957331814174
Validation loss: 2.5057339428472853

Epoch: 6| Step: 3
Training loss: 2.903260693289227
Validation loss: 2.499765288707398

Epoch: 6| Step: 4
Training loss: 2.626611941279027
Validation loss: 2.495821444832867

Epoch: 6| Step: 5
Training loss: 2.879660933191428
Validation loss: 2.4951466261967226

Epoch: 6| Step: 6
Training loss: 3.082047959199002
Validation loss: 2.501679360945032

Epoch: 6| Step: 7
Training loss: 2.729933002613981
Validation loss: 2.514836325224479

Epoch: 6| Step: 8
Training loss: 3.3202240337479254
Validation loss: 2.520529767800224

Epoch: 6| Step: 9
Training loss: 3.0695633690198063
Validation loss: 2.523481133897545

Epoch: 6| Step: 10
Training loss: 2.7609523805175185
Validation loss: 2.5327127844068387

Epoch: 6| Step: 11
Training loss: 2.7277069750331115
Validation loss: 2.531994499365613

Epoch: 6| Step: 12
Training loss: 3.060931680001007
Validation loss: 2.535527851904048

Epoch: 6| Step: 13
Training loss: 2.6088865816693536
Validation loss: 2.5334061777568935

Epoch: 159| Step: 0
Training loss: 2.6999908093896496
Validation loss: 2.539159945376336

Epoch: 6| Step: 1
Training loss: 2.540660648635441
Validation loss: 2.5168064170988926

Epoch: 6| Step: 2
Training loss: 2.7795672523087873
Validation loss: 2.508299127040996

Epoch: 6| Step: 3
Training loss: 3.264287501314085
Validation loss: 2.4956397128070624

Epoch: 6| Step: 4
Training loss: 2.2243652209768756
Validation loss: 2.489436870531083

Epoch: 6| Step: 5
Training loss: 2.932169846781727
Validation loss: 2.489713844492498

Epoch: 6| Step: 6
Training loss: 3.2323898636538035
Validation loss: 2.4913263598926796

Epoch: 6| Step: 7
Training loss: 3.1023778348196838
Validation loss: 2.492175071567793

Epoch: 6| Step: 8
Training loss: 2.3013918314195982
Validation loss: 2.5023832354363686

Epoch: 6| Step: 9
Training loss: 2.214552010727075
Validation loss: 2.5028940287991976

Epoch: 6| Step: 10
Training loss: 2.8781081274741256
Validation loss: 2.507581505244434

Epoch: 6| Step: 11
Training loss: 2.961692210616634
Validation loss: 2.5098027264193425

Epoch: 6| Step: 12
Training loss: 3.2073714230367054
Validation loss: 2.5111118403072004

Epoch: 6| Step: 13
Training loss: 2.6754970873006108
Validation loss: 2.5015283424940686

Epoch: 160| Step: 0
Training loss: 2.5881622977978855
Validation loss: 2.516258203366059

Epoch: 6| Step: 1
Training loss: 3.0863211477799726
Validation loss: 2.5174413070568438

Epoch: 6| Step: 2
Training loss: 3.0729306150647857
Validation loss: 2.5255197513378125

Epoch: 6| Step: 3
Training loss: 2.5737452440556017
Validation loss: 2.5234633553342114

Epoch: 6| Step: 4
Training loss: 2.867617873651772
Validation loss: 2.529731122611474

Epoch: 6| Step: 5
Training loss: 2.085037780346244
Validation loss: 2.5239912597799457

Epoch: 6| Step: 6
Training loss: 2.997145884565705
Validation loss: 2.529424020144469

Epoch: 6| Step: 7
Training loss: 2.782643001477091
Validation loss: 2.527937523075867

Epoch: 6| Step: 8
Training loss: 2.88779884542377
Validation loss: 2.511437071641768

Epoch: 6| Step: 9
Training loss: 2.904025303060466
Validation loss: 2.510540960461321

Epoch: 6| Step: 10
Training loss: 2.8392523106394894
Validation loss: 2.5079986050349325

Epoch: 6| Step: 11
Training loss: 2.6652818501423527
Validation loss: 2.519885856753822

Epoch: 6| Step: 12
Training loss: 2.6929980970022545
Validation loss: 2.50700542742519

Epoch: 6| Step: 13
Training loss: 3.2722683004327577
Validation loss: 2.508148387585052

Epoch: 161| Step: 0
Training loss: 2.78086987587347
Validation loss: 2.49847181230279

Epoch: 6| Step: 1
Training loss: 3.2180035660785005
Validation loss: 2.5022659850944398

Epoch: 6| Step: 2
Training loss: 2.8824436189508833
Validation loss: 2.490305183525108

Epoch: 6| Step: 3
Training loss: 3.2563880349334315
Validation loss: 2.496115194942333

Epoch: 6| Step: 4
Training loss: 2.8058829562409646
Validation loss: 2.4871231825125464

Epoch: 6| Step: 5
Training loss: 2.275174031570307
Validation loss: 2.4906661457925416

Epoch: 6| Step: 6
Training loss: 3.1092023178533634
Validation loss: 2.491972753650482

Epoch: 6| Step: 7
Training loss: 2.454727524128167
Validation loss: 2.510457026598397

Epoch: 6| Step: 8
Training loss: 2.3780153106376236
Validation loss: 2.516668143296075

Epoch: 6| Step: 9
Training loss: 3.0013002121175476
Validation loss: 2.499919616268293

Epoch: 6| Step: 10
Training loss: 2.369718501599916
Validation loss: 2.508643958758507

Epoch: 6| Step: 11
Training loss: 2.7881088549846207
Validation loss: 2.5095886048018037

Epoch: 6| Step: 12
Training loss: 3.0493584317685496
Validation loss: 2.4971188596697416

Epoch: 6| Step: 13
Training loss: 2.243574610578762
Validation loss: 2.4998867050258857

Epoch: 162| Step: 0
Training loss: 3.2564256675620484
Validation loss: 2.502609517387108

Epoch: 6| Step: 1
Training loss: 2.899238249606009
Validation loss: 2.49534443039476

Epoch: 6| Step: 2
Training loss: 2.3443787812151884
Validation loss: 2.4913653802688005

Epoch: 6| Step: 3
Training loss: 3.2888699654157905
Validation loss: 2.4865122696955377

Epoch: 6| Step: 4
Training loss: 2.7898295226705097
Validation loss: 2.4920805107916677

Epoch: 6| Step: 5
Training loss: 2.612673929803825
Validation loss: 2.49655934934622

Epoch: 6| Step: 6
Training loss: 3.34551812599664
Validation loss: 2.4880213684922117

Epoch: 6| Step: 7
Training loss: 2.5300852603643884
Validation loss: 2.4834796666947154

Epoch: 6| Step: 8
Training loss: 2.58641559526088
Validation loss: 2.4850692269214316

Epoch: 6| Step: 9
Training loss: 2.6767025885857585
Validation loss: 2.4740964558012437

Epoch: 6| Step: 10
Training loss: 2.925760225798544
Validation loss: 2.5052027064076396

Epoch: 6| Step: 11
Training loss: 2.5930240948164807
Validation loss: 2.514057013939442

Epoch: 6| Step: 12
Training loss: 2.695691068296469
Validation loss: 2.520707949967128

Epoch: 6| Step: 13
Training loss: 2.3281827573844427
Validation loss: 2.521921190741862

Epoch: 163| Step: 0
Training loss: 2.6877301139787786
Validation loss: 2.534603298572324

Epoch: 6| Step: 1
Training loss: 2.3362634743944337
Validation loss: 2.508772132204025

Epoch: 6| Step: 2
Training loss: 2.881638533405436
Validation loss: 2.487512009929147

Epoch: 6| Step: 3
Training loss: 2.730455128386087
Validation loss: 2.480107645291349

Epoch: 6| Step: 4
Training loss: 3.4437152507711137
Validation loss: 2.479406536683246

Epoch: 6| Step: 5
Training loss: 2.6493433300662272
Validation loss: 2.483294579635121

Epoch: 6| Step: 6
Training loss: 2.857665504608695
Validation loss: 2.490631581686058

Epoch: 6| Step: 7
Training loss: 3.361833391444474
Validation loss: 2.490618770817665

Epoch: 6| Step: 8
Training loss: 2.5847391999721285
Validation loss: 2.489764992931556

Epoch: 6| Step: 9
Training loss: 2.932582716559813
Validation loss: 2.4852604195340673

Epoch: 6| Step: 10
Training loss: 2.0966718413264345
Validation loss: 2.486995398329883

Epoch: 6| Step: 11
Training loss: 2.9555705606307536
Validation loss: 2.4908682785695517

Epoch: 6| Step: 12
Training loss: 2.294601560923982
Validation loss: 2.503236025757772

Epoch: 6| Step: 13
Training loss: 3.3551737219323985
Validation loss: 2.505736991712257

Epoch: 164| Step: 0
Training loss: 2.6945595394429094
Validation loss: 2.5079093988243613

Epoch: 6| Step: 1
Training loss: 3.0045373300844664
Validation loss: 2.505301053329375

Epoch: 6| Step: 2
Training loss: 3.2031818663968905
Validation loss: 2.4996403937993157

Epoch: 6| Step: 3
Training loss: 2.715385020794883
Validation loss: 2.4920084616367744

Epoch: 6| Step: 4
Training loss: 2.4242957046101274
Validation loss: 2.494418195889117

Epoch: 6| Step: 5
Training loss: 2.7599000459345997
Validation loss: 2.4901258996657094

Epoch: 6| Step: 6
Training loss: 2.8909024492059907
Validation loss: 2.4838295810814235

Epoch: 6| Step: 7
Training loss: 2.598722907177873
Validation loss: 2.4882286131761906

Epoch: 6| Step: 8
Training loss: 3.1323383381526084
Validation loss: 2.4907439750344436

Epoch: 6| Step: 9
Training loss: 2.94329262843198
Validation loss: 2.4776070334483613

Epoch: 6| Step: 10
Training loss: 2.958856419985078
Validation loss: 2.48223852988275

Epoch: 6| Step: 11
Training loss: 2.3578837146963014
Validation loss: 2.482528143492119

Epoch: 6| Step: 12
Training loss: 2.4029129470506243
Validation loss: 2.487995689927397

Epoch: 6| Step: 13
Training loss: 2.6670954379443867
Validation loss: 2.481420619681106

Epoch: 165| Step: 0
Training loss: 2.915787500757343
Validation loss: 2.5193908484398024

Epoch: 6| Step: 1
Training loss: 2.1099990486757565
Validation loss: 2.5179565464008475

Epoch: 6| Step: 2
Training loss: 2.9655538922257527
Validation loss: 2.529238982794566

Epoch: 6| Step: 3
Training loss: 2.792863067548194
Validation loss: 2.5252045240838403

Epoch: 6| Step: 4
Training loss: 2.667106611995204
Validation loss: 2.5236782521827346

Epoch: 6| Step: 5
Training loss: 2.960799322200472
Validation loss: 2.5139726671933116

Epoch: 6| Step: 6
Training loss: 2.329293693759095
Validation loss: 2.4992191838625217

Epoch: 6| Step: 7
Training loss: 3.0317174806647733
Validation loss: 2.4968183514187126

Epoch: 6| Step: 8
Training loss: 2.8527164162492715
Validation loss: 2.4869722986129164

Epoch: 6| Step: 9
Training loss: 1.82348055882677
Validation loss: 2.489626318028933

Epoch: 6| Step: 10
Training loss: 2.6557803468073713
Validation loss: 2.4925714053671864

Epoch: 6| Step: 11
Training loss: 2.9381927322730927
Validation loss: 2.476940856563007

Epoch: 6| Step: 12
Training loss: 2.7681376794079813
Validation loss: 2.4838576353099118

Epoch: 6| Step: 13
Training loss: 4.217189924218921
Validation loss: 2.4855892644801996

Epoch: 166| Step: 0
Training loss: 2.899386762038868
Validation loss: 2.4717158494174876

Epoch: 6| Step: 1
Training loss: 2.610124491795535
Validation loss: 2.4805151432095505

Epoch: 6| Step: 2
Training loss: 2.909370961580844
Validation loss: 2.48492937899598

Epoch: 6| Step: 3
Training loss: 3.096556036389302
Validation loss: 2.48253503760978

Epoch: 6| Step: 4
Training loss: 2.6244157413410014
Validation loss: 2.489211313944676

Epoch: 6| Step: 5
Training loss: 3.0165188902458344
Validation loss: 2.4971458118887484

Epoch: 6| Step: 6
Training loss: 2.592939227132369
Validation loss: 2.498134262420524

Epoch: 6| Step: 7
Training loss: 2.3698314845055153
Validation loss: 2.5051283892790206

Epoch: 6| Step: 8
Training loss: 2.376460178637937
Validation loss: 2.510394721296306

Epoch: 6| Step: 9
Training loss: 2.9013426993770515
Validation loss: 2.5155094461328353

Epoch: 6| Step: 10
Training loss: 3.225279176442128
Validation loss: 2.522980405065478

Epoch: 6| Step: 11
Training loss: 2.6245876169984794
Validation loss: 2.5105981513966342

Epoch: 6| Step: 12
Training loss: 3.254658221746311
Validation loss: 2.521719836086377

Epoch: 6| Step: 13
Training loss: 1.3922872573955485
Validation loss: 2.510632011753842

Epoch: 167| Step: 0
Training loss: 2.5081640454657834
Validation loss: 2.4952204320402216

Epoch: 6| Step: 1
Training loss: 2.6283820934848507
Validation loss: 2.4823395908328028

Epoch: 6| Step: 2
Training loss: 2.990993331182424
Validation loss: 2.4775915197757468

Epoch: 6| Step: 3
Training loss: 2.8498794396315383
Validation loss: 2.4746739798107775

Epoch: 6| Step: 4
Training loss: 3.071316698007623
Validation loss: 2.483438306080384

Epoch: 6| Step: 5
Training loss: 2.8233791596507882
Validation loss: 2.4768191465626117

Epoch: 6| Step: 6
Training loss: 2.7057145785004852
Validation loss: 2.4865686101048547

Epoch: 6| Step: 7
Training loss: 2.215407096359515
Validation loss: 2.4931208162608343

Epoch: 6| Step: 8
Training loss: 2.2225116488276964
Validation loss: 2.488738288103784

Epoch: 6| Step: 9
Training loss: 2.76214622200002
Validation loss: 2.500618269568006

Epoch: 6| Step: 10
Training loss: 3.189373587687077
Validation loss: 2.5129593631844087

Epoch: 6| Step: 11
Training loss: 3.317630752941956
Validation loss: 2.513605292351112

Epoch: 6| Step: 12
Training loss: 2.999624228785335
Validation loss: 2.5244802595341094

Epoch: 6| Step: 13
Training loss: 1.8201489682067875
Validation loss: 2.530262476817233

Epoch: 168| Step: 0
Training loss: 2.5624717152592935
Validation loss: 2.5306348094862967

Epoch: 6| Step: 1
Training loss: 2.2971550387986075
Validation loss: 2.527869773653232

Epoch: 6| Step: 2
Training loss: 2.823079703902708
Validation loss: 2.522846568883681

Epoch: 6| Step: 3
Training loss: 2.3647901021708964
Validation loss: 2.5061839520138216

Epoch: 6| Step: 4
Training loss: 2.978201347405181
Validation loss: 2.494291154416295

Epoch: 6| Step: 5
Training loss: 2.017310214280607
Validation loss: 2.4966280993659584

Epoch: 6| Step: 6
Training loss: 2.7445796954675865
Validation loss: 2.4892538793793437

Epoch: 6| Step: 7
Training loss: 2.5675149552040653
Validation loss: 2.4840328986864044

Epoch: 6| Step: 8
Training loss: 3.0391252604380776
Validation loss: 2.491710712771866

Epoch: 6| Step: 9
Training loss: 2.986343772951973
Validation loss: 2.485091155915585

Epoch: 6| Step: 10
Training loss: 3.2320417013499587
Validation loss: 2.4888469032305087

Epoch: 6| Step: 11
Training loss: 3.491712158076728
Validation loss: 2.4840081975320536

Epoch: 6| Step: 12
Training loss: 2.8770986443806668
Validation loss: 2.483435162740501

Epoch: 6| Step: 13
Training loss: 2.2569393594798655
Validation loss: 2.4900930257658436

Epoch: 169| Step: 0
Training loss: 2.8019124277930674
Validation loss: 2.4803521019474304

Epoch: 6| Step: 1
Training loss: 2.764291042887416
Validation loss: 2.4704437188422466

Epoch: 6| Step: 2
Training loss: 2.7185356669511163
Validation loss: 2.4905556418977963

Epoch: 6| Step: 3
Training loss: 3.194309515568271
Validation loss: 2.500997686761575

Epoch: 6| Step: 4
Training loss: 3.0606917667721008
Validation loss: 2.5132686820277264

Epoch: 6| Step: 5
Training loss: 2.2168614046224646
Validation loss: 2.523025894134324

Epoch: 6| Step: 6
Training loss: 2.758616559872331
Validation loss: 2.5294693021178243

Epoch: 6| Step: 7
Training loss: 2.9370402524201022
Validation loss: 2.5454253588129028

Epoch: 6| Step: 8
Training loss: 2.5603090549717265
Validation loss: 2.551991855638495

Epoch: 6| Step: 9
Training loss: 2.5926728367371177
Validation loss: 2.543884527797262

Epoch: 6| Step: 10
Training loss: 2.721338289692147
Validation loss: 2.5388468231909473

Epoch: 6| Step: 11
Training loss: 2.4443888031763175
Validation loss: 2.5169662123602774

Epoch: 6| Step: 12
Training loss: 3.1093799073453736
Validation loss: 2.5119189835472393

Epoch: 6| Step: 13
Training loss: 2.9197098977194327
Validation loss: 2.4857106842941574

Epoch: 170| Step: 0
Training loss: 2.650059026384649
Validation loss: 2.4778958951269834

Epoch: 6| Step: 1
Training loss: 2.7468246854615845
Validation loss: 2.48346797509016

Epoch: 6| Step: 2
Training loss: 2.7582647801050517
Validation loss: 2.513931324894347

Epoch: 6| Step: 3
Training loss: 2.4331838100252807
Validation loss: 2.5660444892373087

Epoch: 6| Step: 4
Training loss: 3.0176865246508906
Validation loss: 2.5877594544130953

Epoch: 6| Step: 5
Training loss: 2.669925625511722
Validation loss: 2.6368997471775097

Epoch: 6| Step: 6
Training loss: 3.313661191851811
Validation loss: 2.6356136766057348

Epoch: 6| Step: 7
Training loss: 3.0061219059228192
Validation loss: 2.5629082261289082

Epoch: 6| Step: 8
Training loss: 3.3891266355517966
Validation loss: 2.522231241610344

Epoch: 6| Step: 9
Training loss: 2.76329364682157
Validation loss: 2.503476620368469

Epoch: 6| Step: 10
Training loss: 2.816143050044548
Validation loss: 2.491869797388276

Epoch: 6| Step: 11
Training loss: 2.618910947965823
Validation loss: 2.48835208731655

Epoch: 6| Step: 12
Training loss: 2.2889129277338336
Validation loss: 2.4789342987645577

Epoch: 6| Step: 13
Training loss: 3.419456428474466
Validation loss: 2.47403992255515

Epoch: 171| Step: 0
Training loss: 2.769927993141468
Validation loss: 2.502626046841022

Epoch: 6| Step: 1
Training loss: 2.5296916167595054
Validation loss: 2.5204268022359675

Epoch: 6| Step: 2
Training loss: 2.9574367794396426
Validation loss: 2.5316783036778947

Epoch: 6| Step: 3
Training loss: 3.1183010779676175
Validation loss: 2.542297943195123

Epoch: 6| Step: 4
Training loss: 2.868095399725021
Validation loss: 2.5323556875067053

Epoch: 6| Step: 5
Training loss: 2.7994949600602226
Validation loss: 2.52184338132839

Epoch: 6| Step: 6
Training loss: 3.1230070243998305
Validation loss: 2.503072532304765

Epoch: 6| Step: 7
Training loss: 2.5512646250700435
Validation loss: 2.483015644462583

Epoch: 6| Step: 8
Training loss: 2.680058222892645
Validation loss: 2.4673515264416

Epoch: 6| Step: 9
Training loss: 3.0859456895164277
Validation loss: 2.4713417458424987

Epoch: 6| Step: 10
Training loss: 2.347432409903932
Validation loss: 2.4675611564740065

Epoch: 6| Step: 11
Training loss: 3.083023124417551
Validation loss: 2.475551696166438

Epoch: 6| Step: 12
Training loss: 2.3294421060986434
Validation loss: 2.481433834466134

Epoch: 6| Step: 13
Training loss: 2.941346592190493
Validation loss: 2.4754885361550536

Epoch: 172| Step: 0
Training loss: 2.7418370906034317
Validation loss: 2.4891913749860164

Epoch: 6| Step: 1
Training loss: 2.5811792950494814
Validation loss: 2.485956073943044

Epoch: 6| Step: 2
Training loss: 2.972810558269135
Validation loss: 2.5079922623638375

Epoch: 6| Step: 3
Training loss: 3.095007438589102
Validation loss: 2.4964216372145898

Epoch: 6| Step: 4
Training loss: 2.8848932298707184
Validation loss: 2.487295791596734

Epoch: 6| Step: 5
Training loss: 2.8421213705413244
Validation loss: 2.4768094294601215

Epoch: 6| Step: 6
Training loss: 2.7572937388328853
Validation loss: 2.477531706172295

Epoch: 6| Step: 7
Training loss: 2.725850884118563
Validation loss: 2.4713635409398984

Epoch: 6| Step: 8
Training loss: 2.456560584080775
Validation loss: 2.483571241456441

Epoch: 6| Step: 9
Training loss: 2.351935575679835
Validation loss: 2.467162092910447

Epoch: 6| Step: 10
Training loss: 2.6649580090848612
Validation loss: 2.469851759806909

Epoch: 6| Step: 11
Training loss: 2.8509162902210328
Validation loss: 2.4725687501090357

Epoch: 6| Step: 12
Training loss: 2.7179640587626137
Validation loss: 2.479122672996601

Epoch: 6| Step: 13
Training loss: 2.9716309071127776
Validation loss: 2.475169587086976

Epoch: 173| Step: 0
Training loss: 2.1418923294973693
Validation loss: 2.481406913051131

Epoch: 6| Step: 1
Training loss: 2.940445093211469
Validation loss: 2.4840615233986685

Epoch: 6| Step: 2
Training loss: 2.7761873608993652
Validation loss: 2.478055066920939

Epoch: 6| Step: 3
Training loss: 2.8819103948785236
Validation loss: 2.4753942296426223

Epoch: 6| Step: 4
Training loss: 2.232693446237487
Validation loss: 2.4931845331737974

Epoch: 6| Step: 5
Training loss: 2.449348312431111
Validation loss: 2.4981729229872496

Epoch: 6| Step: 6
Training loss: 3.0368399448416667
Validation loss: 2.5123888715112375

Epoch: 6| Step: 7
Training loss: 2.435251519374532
Validation loss: 2.5250804067143346

Epoch: 6| Step: 8
Training loss: 3.0060030956747292
Validation loss: 2.532810096536895

Epoch: 6| Step: 9
Training loss: 2.769247322970415
Validation loss: 2.5080409344151224

Epoch: 6| Step: 10
Training loss: 2.8145559637591724
Validation loss: 2.4709998092786414

Epoch: 6| Step: 11
Training loss: 3.126653920237812
Validation loss: 2.4767311954595046

Epoch: 6| Step: 12
Training loss: 3.217263776737376
Validation loss: 2.478173777243716

Epoch: 6| Step: 13
Training loss: 2.7091156832136534
Validation loss: 2.4924198360838434

Epoch: 174| Step: 0
Training loss: 3.013588331230222
Validation loss: 2.5085647002343827

Epoch: 6| Step: 1
Training loss: 2.65433325332066
Validation loss: 2.518703958333852

Epoch: 6| Step: 2
Training loss: 2.6583704843187252
Validation loss: 2.519181686664926

Epoch: 6| Step: 3
Training loss: 2.696874193741732
Validation loss: 2.48191254325291

Epoch: 6| Step: 4
Training loss: 3.119644458760047
Validation loss: 2.4769845664141146

Epoch: 6| Step: 5
Training loss: 2.4894829787028514
Validation loss: 2.474012923790653

Epoch: 6| Step: 6
Training loss: 2.559487782137117
Validation loss: 2.4748663743052006

Epoch: 6| Step: 7
Training loss: 2.6282811321460127
Validation loss: 2.4922977679897436

Epoch: 6| Step: 8
Training loss: 2.379306903543038
Validation loss: 2.519535185713928

Epoch: 6| Step: 9
Training loss: 2.6153910834245404
Validation loss: 2.5378938101506736

Epoch: 6| Step: 10
Training loss: 3.2301265807489856
Validation loss: 2.5432007915630264

Epoch: 6| Step: 11
Training loss: 2.2917764348415233
Validation loss: 2.561535119120722

Epoch: 6| Step: 12
Training loss: 3.3539313634629306
Validation loss: 2.544987445936284

Epoch: 6| Step: 13
Training loss: 3.690042815128034
Validation loss: 2.520111389092704

Epoch: 175| Step: 0
Training loss: 2.9834192153531784
Validation loss: 2.4970847832219

Epoch: 6| Step: 1
Training loss: 2.772144886799206
Validation loss: 2.4851385434221416

Epoch: 6| Step: 2
Training loss: 2.732945531766422
Validation loss: 2.4786538810268275

Epoch: 6| Step: 3
Training loss: 2.6683552184231
Validation loss: 2.488092706752033

Epoch: 6| Step: 4
Training loss: 2.369916796612018
Validation loss: 2.4832973494410253

Epoch: 6| Step: 5
Training loss: 3.1261769939258195
Validation loss: 2.4771870207734965

Epoch: 6| Step: 6
Training loss: 2.6249992733908964
Validation loss: 2.484515145346895

Epoch: 6| Step: 7
Training loss: 2.7020032021300953
Validation loss: 2.491931172902244

Epoch: 6| Step: 8
Training loss: 2.0550351157053806
Validation loss: 2.498467830069656

Epoch: 6| Step: 9
Training loss: 2.647459946888647
Validation loss: 2.5070417690155162

Epoch: 6| Step: 10
Training loss: 2.9501120723836958
Validation loss: 2.524990798330745

Epoch: 6| Step: 11
Training loss: 2.6431935475522366
Validation loss: 2.524042412906045

Epoch: 6| Step: 12
Training loss: 3.078646543052375
Validation loss: 2.5287279127725113

Epoch: 6| Step: 13
Training loss: 3.4250417887790525
Validation loss: 2.519980279570566

Epoch: 176| Step: 0
Training loss: 2.093988319612151
Validation loss: 2.506343594984451

Epoch: 6| Step: 1
Training loss: 3.0822100956109932
Validation loss: 2.49065393003985

Epoch: 6| Step: 2
Training loss: 2.1325765066968367
Validation loss: 2.4818135318884167

Epoch: 6| Step: 3
Training loss: 3.1869527309564205
Validation loss: 2.493386673595565

Epoch: 6| Step: 4
Training loss: 2.827609189030746
Validation loss: 2.4915594666894476

Epoch: 6| Step: 5
Training loss: 3.039452535121553
Validation loss: 2.4995271676544593

Epoch: 6| Step: 6
Training loss: 3.0933931703644655
Validation loss: 2.495323723677578

Epoch: 6| Step: 7
Training loss: 3.204769996090864
Validation loss: 2.4892559700412673

Epoch: 6| Step: 8
Training loss: 2.9666340565407197
Validation loss: 2.4906618072926956

Epoch: 6| Step: 9
Training loss: 2.5540900508804683
Validation loss: 2.48848557302622

Epoch: 6| Step: 10
Training loss: 2.4111841319151193
Validation loss: 2.486702750320641

Epoch: 6| Step: 11
Training loss: 2.15974596207448
Validation loss: 2.4823965991092978

Epoch: 6| Step: 12
Training loss: 2.9279408856037112
Validation loss: 2.484463645306541

Epoch: 6| Step: 13
Training loss: 2.0285953487697572
Validation loss: 2.4747693434656077

Epoch: 177| Step: 0
Training loss: 2.7411436175270314
Validation loss: 2.4798064500311305

Epoch: 6| Step: 1
Training loss: 2.970293145916858
Validation loss: 2.48431944776936

Epoch: 6| Step: 2
Training loss: 2.934189574666744
Validation loss: 2.4859709249208644

Epoch: 6| Step: 3
Training loss: 2.3910813238911257
Validation loss: 2.4789920265219005

Epoch: 6| Step: 4
Training loss: 2.5201110645826765
Validation loss: 2.4862815242222616

Epoch: 6| Step: 5
Training loss: 2.412403808415411
Validation loss: 2.4816725253176344

Epoch: 6| Step: 6
Training loss: 3.0621993248146047
Validation loss: 2.4892894389308844

Epoch: 6| Step: 7
Training loss: 3.022852483725711
Validation loss: 2.4959580243021366

Epoch: 6| Step: 8
Training loss: 2.490965732064637
Validation loss: 2.485923080963007

Epoch: 6| Step: 9
Training loss: 2.3228215995003723
Validation loss: 2.48051773887203

Epoch: 6| Step: 10
Training loss: 2.8776826367388195
Validation loss: 2.4770465736294156

Epoch: 6| Step: 11
Training loss: 2.559446702262505
Validation loss: 2.477879691108486

Epoch: 6| Step: 12
Training loss: 3.001249688850333
Validation loss: 2.4614814142899606

Epoch: 6| Step: 13
Training loss: 3.095924923048101
Validation loss: 2.4768321095402857

Epoch: 178| Step: 0
Training loss: 2.3516309354335423
Validation loss: 2.4685596555200515

Epoch: 6| Step: 1
Training loss: 3.1538729639685177
Validation loss: 2.4704826124603967

Epoch: 6| Step: 2
Training loss: 2.5997718857684853
Validation loss: 2.4740636258907664

Epoch: 6| Step: 3
Training loss: 3.0438658893933392
Validation loss: 2.4632316806592445

Epoch: 6| Step: 4
Training loss: 2.667672225983853
Validation loss: 2.4712449998665114

Epoch: 6| Step: 5
Training loss: 2.7515579492205324
Validation loss: 2.4590364670395046

Epoch: 6| Step: 6
Training loss: 2.3981102338052445
Validation loss: 2.479100757907487

Epoch: 6| Step: 7
Training loss: 2.6937693725739007
Validation loss: 2.4542302769725155

Epoch: 6| Step: 8
Training loss: 2.6261481544323275
Validation loss: 2.464550909881877

Epoch: 6| Step: 9
Training loss: 1.9039990001403364
Validation loss: 2.4566995006893926

Epoch: 6| Step: 10
Training loss: 2.654607017873275
Validation loss: 2.449206859257977

Epoch: 6| Step: 11
Training loss: 3.1403876827023214
Validation loss: 2.4677748576043284

Epoch: 6| Step: 12
Training loss: 3.451856837710938
Validation loss: 2.471346199690765

Epoch: 6| Step: 13
Training loss: 2.421428614671452
Validation loss: 2.478878415699441

Epoch: 179| Step: 0
Training loss: 2.475921451622998
Validation loss: 2.4832299090024894

Epoch: 6| Step: 1
Training loss: 2.7273852137285157
Validation loss: 2.469393785243137

Epoch: 6| Step: 2
Training loss: 2.7886953245759507
Validation loss: 2.4699201260221924

Epoch: 6| Step: 3
Training loss: 2.549405765483415
Validation loss: 2.4596681810189063

Epoch: 6| Step: 4
Training loss: 2.8163111825418725
Validation loss: 2.467195013098041

Epoch: 6| Step: 5
Training loss: 2.9716147002937565
Validation loss: 2.4547907718494253

Epoch: 6| Step: 6
Training loss: 2.562706171441154
Validation loss: 2.455832767794736

Epoch: 6| Step: 7
Training loss: 3.049380323902259
Validation loss: 2.455184109954942

Epoch: 6| Step: 8
Training loss: 2.6785691488347116
Validation loss: 2.453735758345316

Epoch: 6| Step: 9
Training loss: 3.1883806994107524
Validation loss: 2.4595347166902655

Epoch: 6| Step: 10
Training loss: 2.9917605421662006
Validation loss: 2.4744112601227553

Epoch: 6| Step: 11
Training loss: 2.7882537951604776
Validation loss: 2.4781290590344334

Epoch: 6| Step: 12
Training loss: 1.7937409643284576
Validation loss: 2.4873813593643463

Epoch: 6| Step: 13
Training loss: 2.6700211724859857
Validation loss: 2.478093536929929

Epoch: 180| Step: 0
Training loss: 2.470531062591946
Validation loss: 2.4754742514275683

Epoch: 6| Step: 1
Training loss: 2.999790820140566
Validation loss: 2.4730315272357988

Epoch: 6| Step: 2
Training loss: 2.9500577630029063
Validation loss: 2.4682786812758364

Epoch: 6| Step: 3
Training loss: 2.6566320705514475
Validation loss: 2.46390462421322

Epoch: 6| Step: 4
Training loss: 2.443274090175746
Validation loss: 2.4668427994238162

Epoch: 6| Step: 5
Training loss: 2.6777416760590653
Validation loss: 2.456641725992462

Epoch: 6| Step: 6
Training loss: 2.4570384305961253
Validation loss: 2.470041352918484

Epoch: 6| Step: 7
Training loss: 3.0809304092902923
Validation loss: 2.4675329834579944

Epoch: 6| Step: 8
Training loss: 2.7526502842981135
Validation loss: 2.4896074615584816

Epoch: 6| Step: 9
Training loss: 2.5728685835284923
Validation loss: 2.5073644926448013

Epoch: 6| Step: 10
Training loss: 2.8206004156946958
Validation loss: 2.520244668643678

Epoch: 6| Step: 11
Training loss: 2.6845360313494178
Validation loss: 2.50783381508784

Epoch: 6| Step: 12
Training loss: 2.4987195550572374
Validation loss: 2.514036462367117

Epoch: 6| Step: 13
Training loss: 3.3408522839927346
Validation loss: 2.5173923146981685

Epoch: 181| Step: 0
Training loss: 2.6174336331906707
Validation loss: 2.5225601685251036

Epoch: 6| Step: 1
Training loss: 2.810167065605707
Validation loss: 2.5320848662817372

Epoch: 6| Step: 2
Training loss: 3.254301012874725
Validation loss: 2.529607154881491

Epoch: 6| Step: 3
Training loss: 1.970839829330008
Validation loss: 2.532990314517706

Epoch: 6| Step: 4
Training loss: 3.1165519965253106
Validation loss: 2.5287371748911576

Epoch: 6| Step: 5
Training loss: 2.6663422883949197
Validation loss: 2.5047445928231533

Epoch: 6| Step: 6
Training loss: 2.6015964998423455
Validation loss: 2.4840789389431976

Epoch: 6| Step: 7
Training loss: 2.9755207151019762
Validation loss: 2.4763854004134673

Epoch: 6| Step: 8
Training loss: 2.6064359822683323
Validation loss: 2.4599116705546713

Epoch: 6| Step: 9
Training loss: 2.634850321794716
Validation loss: 2.45694163268391

Epoch: 6| Step: 10
Training loss: 2.966799768040887
Validation loss: 2.4617677964142946

Epoch: 6| Step: 11
Training loss: 2.458045543916055
Validation loss: 2.474451366749317

Epoch: 6| Step: 12
Training loss: 2.9899709275277138
Validation loss: 2.4670818721754033

Epoch: 6| Step: 13
Training loss: 2.509605456039437
Validation loss: 2.466649502125224

Epoch: 182| Step: 0
Training loss: 2.710143662899343
Validation loss: 2.465452809417215

Epoch: 6| Step: 1
Training loss: 2.792001580792611
Validation loss: 2.4759368628988443

Epoch: 6| Step: 2
Training loss: 3.2485726963696893
Validation loss: 2.494581715980807

Epoch: 6| Step: 3
Training loss: 2.5259876887790895
Validation loss: 2.496787041112273

Epoch: 6| Step: 4
Training loss: 2.5885471418132227
Validation loss: 2.494705660788976

Epoch: 6| Step: 5
Training loss: 2.68476790904416
Validation loss: 2.5032088231647966

Epoch: 6| Step: 6
Training loss: 2.7910988263381555
Validation loss: 2.4964439224392834

Epoch: 6| Step: 7
Training loss: 2.788912558064659
Validation loss: 2.504510043655959

Epoch: 6| Step: 8
Training loss: 2.5327184679672112
Validation loss: 2.477896858342981

Epoch: 6| Step: 9
Training loss: 2.4706479273725495
Validation loss: 2.4754278797353497

Epoch: 6| Step: 10
Training loss: 2.88959744722036
Validation loss: 2.4702275627315093

Epoch: 6| Step: 11
Training loss: 2.3697974795315613
Validation loss: 2.4649564070722985

Epoch: 6| Step: 12
Training loss: 2.901950568242833
Validation loss: 2.4557171397208863

Epoch: 6| Step: 13
Training loss: 2.960674022536863
Validation loss: 2.4667138544833276

Epoch: 183| Step: 0
Training loss: 2.618838390233379
Validation loss: 2.4793234265689517

Epoch: 6| Step: 1
Training loss: 2.8259070535319126
Validation loss: 2.47702674995321

Epoch: 6| Step: 2
Training loss: 2.799908915809336
Validation loss: 2.4895236086717007

Epoch: 6| Step: 3
Training loss: 2.4893321358804354
Validation loss: 2.5013078550065773

Epoch: 6| Step: 4
Training loss: 3.5966737215281093
Validation loss: 2.5189924488975506

Epoch: 6| Step: 5
Training loss: 3.0875519597550114
Validation loss: 2.542681005628423

Epoch: 6| Step: 6
Training loss: 2.8602582057358044
Validation loss: 2.567517422474199

Epoch: 6| Step: 7
Training loss: 2.7457099744054916
Validation loss: 2.5996031493405347

Epoch: 6| Step: 8
Training loss: 2.9264562258592077
Validation loss: 2.635811492386026

Epoch: 6| Step: 9
Training loss: 2.585218254630016
Validation loss: 2.6672525537765632

Epoch: 6| Step: 10
Training loss: 2.2064400480291493
Validation loss: 2.673769645818752

Epoch: 6| Step: 11
Training loss: 2.2802382015144276
Validation loss: 2.626230739486507

Epoch: 6| Step: 12
Training loss: 2.731173488496763
Validation loss: 2.585656413298066

Epoch: 6| Step: 13
Training loss: 2.668663548804673
Validation loss: 2.5594490190515597

Epoch: 184| Step: 0
Training loss: 2.8044962273196754
Validation loss: 2.5456416333723997

Epoch: 6| Step: 1
Training loss: 3.17062247966694
Validation loss: 2.5320064149261863

Epoch: 6| Step: 2
Training loss: 2.888912869215333
Validation loss: 2.506150523593298

Epoch: 6| Step: 3
Training loss: 2.7868810505361807
Validation loss: 2.4943673494488334

Epoch: 6| Step: 4
Training loss: 2.392947595834713
Validation loss: 2.4839926660420306

Epoch: 6| Step: 5
Training loss: 2.8235149429922948
Validation loss: 2.4747774194141146

Epoch: 6| Step: 6
Training loss: 2.5132763246838397
Validation loss: 2.459022387514307

Epoch: 6| Step: 7
Training loss: 3.20651200025256
Validation loss: 2.461564872688159

Epoch: 6| Step: 8
Training loss: 3.152983381949252
Validation loss: 2.459633123986442

Epoch: 6| Step: 9
Training loss: 2.5937323512200763
Validation loss: 2.4670954796612024

Epoch: 6| Step: 10
Training loss: 2.334332887813546
Validation loss: 2.47257588039863

Epoch: 6| Step: 11
Training loss: 2.6435632554060913
Validation loss: 2.4702286597023275

Epoch: 6| Step: 12
Training loss: 2.507598677696942
Validation loss: 2.478239140495827

Epoch: 6| Step: 13
Training loss: 2.4601581611032293
Validation loss: 2.5035112129607384

Epoch: 185| Step: 0
Training loss: 2.845834156965264
Validation loss: 2.4950547940281247

Epoch: 6| Step: 1
Training loss: 2.8006869290908387
Validation loss: 2.496115076831326

Epoch: 6| Step: 2
Training loss: 3.0859418265396887
Validation loss: 2.5024614522087543

Epoch: 6| Step: 3
Training loss: 2.5234630099208837
Validation loss: 2.512706446738254

Epoch: 6| Step: 4
Training loss: 2.345989937125736
Validation loss: 2.496512411727289

Epoch: 6| Step: 5
Training loss: 3.1003555524643907
Validation loss: 2.471490502728699

Epoch: 6| Step: 6
Training loss: 3.050044050054915
Validation loss: 2.4596341016503116

Epoch: 6| Step: 7
Training loss: 2.5102846314041884
Validation loss: 2.455849999370135

Epoch: 6| Step: 8
Training loss: 3.1616331216590705
Validation loss: 2.484442910847421

Epoch: 6| Step: 9
Training loss: 1.5712913385141223
Validation loss: 2.487142519597134

Epoch: 6| Step: 10
Training loss: 2.954497487672495
Validation loss: 2.470623780357466

Epoch: 6| Step: 11
Training loss: 2.7405023423414376
Validation loss: 2.487495131149552

Epoch: 6| Step: 12
Training loss: 2.6296885263188265
Validation loss: 2.499248248048597

Epoch: 6| Step: 13
Training loss: 2.770291287361944
Validation loss: 2.5088952564223237

Epoch: 186| Step: 0
Training loss: 2.7008032557589896
Validation loss: 2.509465917107658

Epoch: 6| Step: 1
Training loss: 2.702021731985979
Validation loss: 2.510878575109243

Epoch: 6| Step: 2
Training loss: 2.8856501479082746
Validation loss: 2.478482241285202

Epoch: 6| Step: 3
Training loss: 2.5323342720777506
Validation loss: 2.4685790466292885

Epoch: 6| Step: 4
Training loss: 2.57625016909788
Validation loss: 2.4722632139008422

Epoch: 6| Step: 5
Training loss: 2.8578280240445975
Validation loss: 2.4853968820796233

Epoch: 6| Step: 6
Training loss: 3.188954339443062
Validation loss: 2.4752762818967184

Epoch: 6| Step: 7
Training loss: 2.6458420540573298
Validation loss: 2.4645862256626403

Epoch: 6| Step: 8
Training loss: 2.1554924560216646
Validation loss: 2.457666925867012

Epoch: 6| Step: 9
Training loss: 2.7809635829248904
Validation loss: 2.4492239417143273

Epoch: 6| Step: 10
Training loss: 3.2364707459521855
Validation loss: 2.4715743715229297

Epoch: 6| Step: 11
Training loss: 2.3708192267330648
Validation loss: 2.497341900467193

Epoch: 6| Step: 12
Training loss: 2.7912495049947257
Validation loss: 2.498300516160002

Epoch: 6| Step: 13
Training loss: 2.974407707687003
Validation loss: 2.492024323801676

Epoch: 187| Step: 0
Training loss: 2.963746361571371
Validation loss: 2.499359079467237

Epoch: 6| Step: 1
Training loss: 2.562928047715131
Validation loss: 2.5232862323506877

Epoch: 6| Step: 2
Training loss: 3.084448037253836
Validation loss: 2.488997961887911

Epoch: 6| Step: 3
Training loss: 2.268869116312258
Validation loss: 2.4775580604897063

Epoch: 6| Step: 4
Training loss: 3.365577968031483
Validation loss: 2.4800636400587814

Epoch: 6| Step: 5
Training loss: 2.393662262346984
Validation loss: 2.4753209170047787

Epoch: 6| Step: 6
Training loss: 2.159727747325092
Validation loss: 2.48494042202546

Epoch: 6| Step: 7
Training loss: 2.7298614743478136
Validation loss: 2.4816118588926197

Epoch: 6| Step: 8
Training loss: 2.717319682296939
Validation loss: 2.4825813410893716

Epoch: 6| Step: 9
Training loss: 2.422599438023004
Validation loss: 2.4842829471497847

Epoch: 6| Step: 10
Training loss: 3.0623779272545604
Validation loss: 2.493608542074653

Epoch: 6| Step: 11
Training loss: 2.975236732616802
Validation loss: 2.486924709983826

Epoch: 6| Step: 12
Training loss: 2.691485621108315
Validation loss: 2.4810170580567896

Epoch: 6| Step: 13
Training loss: 2.296135089056932
Validation loss: 2.468718822817698

Epoch: 188| Step: 0
Training loss: 2.730803942537235
Validation loss: 2.4762109313030614

Epoch: 6| Step: 1
Training loss: 3.1870971125878667
Validation loss: 2.481079681585716

Epoch: 6| Step: 2
Training loss: 1.672550670956705
Validation loss: 2.487575739107724

Epoch: 6| Step: 3
Training loss: 2.2893103768040657
Validation loss: 2.4877470750313213

Epoch: 6| Step: 4
Training loss: 3.017681784222796
Validation loss: 2.5001865666003824

Epoch: 6| Step: 5
Training loss: 3.1914645204862393
Validation loss: 2.491352228453452

Epoch: 6| Step: 6
Training loss: 2.8786261537441815
Validation loss: 2.486744172102637

Epoch: 6| Step: 7
Training loss: 2.8608878047508384
Validation loss: 2.486197516883271

Epoch: 6| Step: 8
Training loss: 2.055736201599419
Validation loss: 2.494991270784872

Epoch: 6| Step: 9
Training loss: 2.461467770560942
Validation loss: 2.5044016011261063

Epoch: 6| Step: 10
Training loss: 2.6366044535412576
Validation loss: 2.495278132336043

Epoch: 6| Step: 11
Training loss: 3.065085740251449
Validation loss: 2.4975979668539754

Epoch: 6| Step: 12
Training loss: 2.5826998723576593
Validation loss: 2.498568330006531

Epoch: 6| Step: 13
Training loss: 2.8379774927022363
Validation loss: 2.5018662331965564

Epoch: 189| Step: 0
Training loss: 3.7454555950432677
Validation loss: 2.488504798565338

Epoch: 6| Step: 1
Training loss: 2.7555588112917846
Validation loss: 2.507944656553156

Epoch: 6| Step: 2
Training loss: 2.73675764635014
Validation loss: 2.497249712727262

Epoch: 6| Step: 3
Training loss: 2.3553287597354147
Validation loss: 2.503883740414143

Epoch: 6| Step: 4
Training loss: 2.497212572636653
Validation loss: 2.5115952354619084

Epoch: 6| Step: 5
Training loss: 2.816622277385947
Validation loss: 2.510059867634847

Epoch: 6| Step: 6
Training loss: 2.456519432918087
Validation loss: 2.502613089422

Epoch: 6| Step: 7
Training loss: 2.5516135477541497
Validation loss: 2.5004879598322205

Epoch: 6| Step: 8
Training loss: 2.1494846081108308
Validation loss: 2.502486259084498

Epoch: 6| Step: 9
Training loss: 2.6418347719377224
Validation loss: 2.511238428973652

Epoch: 6| Step: 10
Training loss: 2.305418461115741
Validation loss: 2.4851734242832912

Epoch: 6| Step: 11
Training loss: 2.9088364443784123
Validation loss: 2.4894486175169495

Epoch: 6| Step: 12
Training loss: 2.481622670818887
Validation loss: 2.4767843307366655

Epoch: 6| Step: 13
Training loss: 3.1839057254636383
Validation loss: 2.4706181147866775

Epoch: 190| Step: 0
Training loss: 2.162161753225932
Validation loss: 2.4780985145243357

Epoch: 6| Step: 1
Training loss: 2.533312392984813
Validation loss: 2.4650355826159296

Epoch: 6| Step: 2
Training loss: 3.156517244110306
Validation loss: 2.46384445258693

Epoch: 6| Step: 3
Training loss: 2.879229544262612
Validation loss: 2.480594755897546

Epoch: 6| Step: 4
Training loss: 3.3039666870968603
Validation loss: 2.469942922297606

Epoch: 6| Step: 5
Training loss: 2.0111474272163696
Validation loss: 2.486906590707668

Epoch: 6| Step: 6
Training loss: 3.159781717897732
Validation loss: 2.49268313942309

Epoch: 6| Step: 7
Training loss: 2.1354937903890714
Validation loss: 2.501479957764554

Epoch: 6| Step: 8
Training loss: 2.954994699696081
Validation loss: 2.506948446996798

Epoch: 6| Step: 9
Training loss: 2.406221067576669
Validation loss: 2.500498866483259

Epoch: 6| Step: 10
Training loss: 2.3745845632108695
Validation loss: 2.518867880394769

Epoch: 6| Step: 11
Training loss: 2.5563362237616585
Validation loss: 2.5127758272452905

Epoch: 6| Step: 12
Training loss: 2.259677842396127
Validation loss: 2.4900542366620306

Epoch: 6| Step: 13
Training loss: 3.895983456797794
Validation loss: 2.503066561226205

Epoch: 191| Step: 0
Training loss: 2.460763882764608
Validation loss: 2.492344770581377

Epoch: 6| Step: 1
Training loss: 3.2003742595204354
Validation loss: 2.489040836872638

Epoch: 6| Step: 2
Training loss: 2.602891920263263
Validation loss: 2.4819085509772547

Epoch: 6| Step: 3
Training loss: 1.8917549476805855
Validation loss: 2.4900256746631166

Epoch: 6| Step: 4
Training loss: 2.7635888831951516
Validation loss: 2.4919045130411996

Epoch: 6| Step: 5
Training loss: 2.538348382148375
Validation loss: 2.4991593824209994

Epoch: 6| Step: 6
Training loss: 2.98334329557265
Validation loss: 2.4857013618934034

Epoch: 6| Step: 7
Training loss: 2.7082566959590952
Validation loss: 2.494272739196907

Epoch: 6| Step: 8
Training loss: 3.1838660375314616
Validation loss: 2.4851766324767928

Epoch: 6| Step: 9
Training loss: 2.5452804722653095
Validation loss: 2.496469953621909

Epoch: 6| Step: 10
Training loss: 2.743282088785684
Validation loss: 2.494014787470265

Epoch: 6| Step: 11
Training loss: 3.0274792056389375
Validation loss: 2.501493006115128

Epoch: 6| Step: 12
Training loss: 2.567924155140244
Validation loss: 2.519012198784124

Epoch: 6| Step: 13
Training loss: 1.6361987760611287
Validation loss: 2.521462741163997

Epoch: 192| Step: 0
Training loss: 2.279350639696333
Validation loss: 2.535164815152346

Epoch: 6| Step: 1
Training loss: 2.794046175488465
Validation loss: 2.5592968176804787

Epoch: 6| Step: 2
Training loss: 2.398790265213012
Validation loss: 2.5514461790958785

Epoch: 6| Step: 3
Training loss: 2.853625912268104
Validation loss: 2.570019688319173

Epoch: 6| Step: 4
Training loss: 2.796540650570009
Validation loss: 2.5957111753052198

Epoch: 6| Step: 5
Training loss: 3.022737643836189
Validation loss: 2.6203422847646842

Epoch: 6| Step: 6
Training loss: 2.5229493604999234
Validation loss: 2.5887470181651984

Epoch: 6| Step: 7
Training loss: 2.9021331176723146
Validation loss: 2.5458020526370087

Epoch: 6| Step: 8
Training loss: 2.6268334116832754
Validation loss: 2.5442919219164906

Epoch: 6| Step: 9
Training loss: 1.8315211645388005
Validation loss: 2.521145598812854

Epoch: 6| Step: 10
Training loss: 2.509708531542968
Validation loss: 2.5263661067870005

Epoch: 6| Step: 11
Training loss: 3.290323264986337
Validation loss: 2.525748194062728

Epoch: 6| Step: 12
Training loss: 2.384314292044887
Validation loss: 2.5158829085172383

Epoch: 6| Step: 13
Training loss: 3.2347553416543464
Validation loss: 2.5031875306554285

Epoch: 193| Step: 0
Training loss: 2.755437849805476
Validation loss: 2.4755907425365873

Epoch: 6| Step: 1
Training loss: 3.2126837295656445
Validation loss: 2.458724308017421

Epoch: 6| Step: 2
Training loss: 2.483852307497655
Validation loss: 2.464878669479586

Epoch: 6| Step: 3
Training loss: 2.4733529939752628
Validation loss: 2.4642598336933608

Epoch: 6| Step: 4
Training loss: 2.0870874785371134
Validation loss: 2.452637037031349

Epoch: 6| Step: 5
Training loss: 2.9179231571174533
Validation loss: 2.469753787698531

Epoch: 6| Step: 6
Training loss: 2.546613621317395
Validation loss: 2.485446030650514

Epoch: 6| Step: 7
Training loss: 2.2089831877552624
Validation loss: 2.4936690307568523

Epoch: 6| Step: 8
Training loss: 2.781928333327446
Validation loss: 2.4675427048835377

Epoch: 6| Step: 9
Training loss: 2.9488109584586097
Validation loss: 2.47008479773349

Epoch: 6| Step: 10
Training loss: 2.841456903525853
Validation loss: 2.46811461096049

Epoch: 6| Step: 11
Training loss: 2.7372278644343693
Validation loss: 2.456674979689459

Epoch: 6| Step: 12
Training loss: 2.210437300211545
Validation loss: 2.4621443542510404

Epoch: 6| Step: 13
Training loss: 3.604984139289832
Validation loss: 2.463792839913799

Epoch: 194| Step: 0
Training loss: 2.898707950446616
Validation loss: 2.461761068036092

Epoch: 6| Step: 1
Training loss: 2.747785977448489
Validation loss: 2.4585874713608846

Epoch: 6| Step: 2
Training loss: 2.791799361837776
Validation loss: 2.4724605366014134

Epoch: 6| Step: 3
Training loss: 1.6381923987980582
Validation loss: 2.4764915966751984

Epoch: 6| Step: 4
Training loss: 3.1042261480653304
Validation loss: 2.493744955922078

Epoch: 6| Step: 5
Training loss: 2.5820421458142837
Validation loss: 2.511496100980035

Epoch: 6| Step: 6
Training loss: 3.093595866978037
Validation loss: 2.5219218936810575

Epoch: 6| Step: 7
Training loss: 2.86372786261512
Validation loss: 2.515449689533361

Epoch: 6| Step: 8
Training loss: 3.1590880674021324
Validation loss: 2.5083342162748608

Epoch: 6| Step: 9
Training loss: 2.9814881747451256
Validation loss: 2.4889169313306914

Epoch: 6| Step: 10
Training loss: 2.4604352165985035
Validation loss: 2.4682155314598244

Epoch: 6| Step: 11
Training loss: 1.95862470312504
Validation loss: 2.4784957023978436

Epoch: 6| Step: 12
Training loss: 2.97220242177799
Validation loss: 2.4884287032139203

Epoch: 6| Step: 13
Training loss: 1.998138932748376
Validation loss: 2.4771012198752835

Epoch: 195| Step: 0
Training loss: 2.913790856348653
Validation loss: 2.4961752274763995

Epoch: 6| Step: 1
Training loss: 1.9225042290014773
Validation loss: 2.513724183019116

Epoch: 6| Step: 2
Training loss: 2.7793662732079327
Validation loss: 2.5195061652755264

Epoch: 6| Step: 3
Training loss: 2.8777154455058156
Validation loss: 2.504975773449779

Epoch: 6| Step: 4
Training loss: 2.838139291411042
Validation loss: 2.4891183152580862

Epoch: 6| Step: 5
Training loss: 2.5400170981965573
Validation loss: 2.5092429282203432

Epoch: 6| Step: 6
Training loss: 2.021531315502707
Validation loss: 2.510344908212121

Epoch: 6| Step: 7
Training loss: 3.398239094872939
Validation loss: 2.523840480893253

Epoch: 6| Step: 8
Training loss: 2.863823603829345
Validation loss: 2.5227623981303675

Epoch: 6| Step: 9
Training loss: 2.4661875113349456
Validation loss: 2.529139748239306

Epoch: 6| Step: 10
Training loss: 2.795720378869928
Validation loss: 2.538078820547427

Epoch: 6| Step: 11
Training loss: 2.3112903214728946
Validation loss: 2.540046491886185

Epoch: 6| Step: 12
Training loss: 2.6602562704902355
Validation loss: 2.554328059509238

Epoch: 6| Step: 13
Training loss: 3.0147039558481112
Validation loss: 2.569271863045035

Epoch: 196| Step: 0
Training loss: 2.592469048457843
Validation loss: 2.579190026460978

Epoch: 6| Step: 1
Training loss: 2.6737353000174355
Validation loss: 2.5817150200137613

Epoch: 6| Step: 2
Training loss: 2.717331263998415
Validation loss: 2.594116077369057

Epoch: 6| Step: 3
Training loss: 2.6263436103126208
Validation loss: 2.547918789660403

Epoch: 6| Step: 4
Training loss: 3.119420067123981
Validation loss: 2.561442612476066

Epoch: 6| Step: 5
Training loss: 1.6796601049273978
Validation loss: 2.5484866693570836

Epoch: 6| Step: 6
Training loss: 3.218305983055951
Validation loss: 2.5266665809785667

Epoch: 6| Step: 7
Training loss: 2.5053948368009866
Validation loss: 2.5181295688225585

Epoch: 6| Step: 8
Training loss: 2.26917299473114
Validation loss: 2.5010471837501913

Epoch: 6| Step: 9
Training loss: 2.8624491191489843
Validation loss: 2.504471304849363

Epoch: 6| Step: 10
Training loss: 2.673591196445648
Validation loss: 2.4878556953054627

Epoch: 6| Step: 11
Training loss: 2.6594005076959077
Validation loss: 2.4809158925990404

Epoch: 6| Step: 12
Training loss: 3.211211032772071
Validation loss: 2.468850373252226

Epoch: 6| Step: 13
Training loss: 1.9329056565479
Validation loss: 2.4552502585624625

Epoch: 197| Step: 0
Training loss: 1.8366255100067537
Validation loss: 2.4694037858758358

Epoch: 6| Step: 1
Training loss: 2.6672255009970463
Validation loss: 2.463366593166573

Epoch: 6| Step: 2
Training loss: 2.927076636111018
Validation loss: 2.470134665074883

Epoch: 6| Step: 3
Training loss: 3.0653495765953673
Validation loss: 2.4741192622969996

Epoch: 6| Step: 4
Training loss: 3.1386878268982468
Validation loss: 2.4810041582773255

Epoch: 6| Step: 5
Training loss: 2.1720149592030227
Validation loss: 2.4839119387096114

Epoch: 6| Step: 6
Training loss: 2.3832032930692657
Validation loss: 2.503613720187637

Epoch: 6| Step: 7
Training loss: 2.8499205996512265
Validation loss: 2.508923883582466

Epoch: 6| Step: 8
Training loss: 2.5706059714442437
Validation loss: 2.5328656510376457

Epoch: 6| Step: 9
Training loss: 2.7192560360767777
Validation loss: 2.556689853946777

Epoch: 6| Step: 10
Training loss: 2.8738591791745947
Validation loss: 2.6052025573537594

Epoch: 6| Step: 11
Training loss: 2.624538199357688
Validation loss: 2.6397616795549843

Epoch: 6| Step: 12
Training loss: 2.623658336911965
Validation loss: 2.572902122583658

Epoch: 6| Step: 13
Training loss: 2.9088939822257363
Validation loss: 2.5168385539947264

Epoch: 198| Step: 0
Training loss: 2.611403173881823
Validation loss: 2.4831463435401053

Epoch: 6| Step: 1
Training loss: 3.1313189896770823
Validation loss: 2.4883672583107557

Epoch: 6| Step: 2
Training loss: 3.103614263005355
Validation loss: 2.49121545924746

Epoch: 6| Step: 3
Training loss: 2.948733824216194
Validation loss: 2.503194488723914

Epoch: 6| Step: 4
Training loss: 3.199286715166342
Validation loss: 2.4984388830149595

Epoch: 6| Step: 5
Training loss: 2.3690655500651245
Validation loss: 2.488772304748501

Epoch: 6| Step: 6
Training loss: 2.002878382791542
Validation loss: 2.476534449568996

Epoch: 6| Step: 7
Training loss: 2.67856799170864
Validation loss: 2.4711421074786886

Epoch: 6| Step: 8
Training loss: 2.9002663325640783
Validation loss: 2.4647839819795783

Epoch: 6| Step: 9
Training loss: 2.0010801021360427
Validation loss: 2.4595587359675464

Epoch: 6| Step: 10
Training loss: 2.774171028382056
Validation loss: 2.4570912274706336

Epoch: 6| Step: 11
Training loss: 2.0593119170233143
Validation loss: 2.4527892878495883

Epoch: 6| Step: 12
Training loss: 3.0337850450928623
Validation loss: 2.441873828502536

Epoch: 6| Step: 13
Training loss: 2.6017444077321055
Validation loss: 2.4463585021861998

Epoch: 199| Step: 0
Training loss: 2.190626471460477
Validation loss: 2.4541363089067767

Epoch: 6| Step: 1
Training loss: 2.666982175123095
Validation loss: 2.4621360379911508

Epoch: 6| Step: 2
Training loss: 2.2092287179738346
Validation loss: 2.482243375746665

Epoch: 6| Step: 3
Training loss: 2.79856940575744
Validation loss: 2.4859427625405353

Epoch: 6| Step: 4
Training loss: 3.057355335272327
Validation loss: 2.462834094761891

Epoch: 6| Step: 5
Training loss: 2.8584376398597184
Validation loss: 2.461211439786289

Epoch: 6| Step: 6
Training loss: 2.6091664853416274
Validation loss: 2.4654502758811465

Epoch: 6| Step: 7
Training loss: 2.6021806595383588
Validation loss: 2.4477103787654597

Epoch: 6| Step: 8
Training loss: 3.106448842981725
Validation loss: 2.4718900342682457

Epoch: 6| Step: 9
Training loss: 2.2687798994632007
Validation loss: 2.5062791794972763

Epoch: 6| Step: 10
Training loss: 3.2910544554459955
Validation loss: 2.5109570326360844

Epoch: 6| Step: 11
Training loss: 2.7363622800777003
Validation loss: 2.509951506569778

Epoch: 6| Step: 12
Training loss: 2.404245309408443
Validation loss: 2.512823865923392

Epoch: 6| Step: 13
Training loss: 2.6296688521160894
Validation loss: 2.551062778707841

Epoch: 200| Step: 0
Training loss: 3.2917866423427347
Validation loss: 2.5626324044913145

Epoch: 6| Step: 1
Training loss: 2.867937452477519
Validation loss: 2.563733240077791

Epoch: 6| Step: 2
Training loss: 2.732872424769125
Validation loss: 2.561498040399852

Epoch: 6| Step: 3
Training loss: 2.725969222703184
Validation loss: 2.5735625556141364

Epoch: 6| Step: 4
Training loss: 2.371376887954878
Validation loss: 2.573815570897217

Epoch: 6| Step: 5
Training loss: 2.861242132880185
Validation loss: 2.569829872606483

Epoch: 6| Step: 6
Training loss: 2.296251692503927
Validation loss: 2.575377716889525

Epoch: 6| Step: 7
Training loss: 2.7289171954180365
Validation loss: 2.5700239307592887

Epoch: 6| Step: 8
Training loss: 2.215744561976453
Validation loss: 2.5528101412055952

Epoch: 6| Step: 9
Training loss: 2.186586243654693
Validation loss: 2.550376317854523

Epoch: 6| Step: 10
Training loss: 3.319771612653597
Validation loss: 2.5425160668276714

Epoch: 6| Step: 11
Training loss: 2.322235235555996
Validation loss: 2.5842084788315764

Epoch: 6| Step: 12
Training loss: 2.508207961420738
Validation loss: 2.6382524900277113

Epoch: 6| Step: 13
Training loss: 3.1114652882410883
Validation loss: 2.6656508295815193

Epoch: 201| Step: 0
Training loss: 2.8461436164418332
Validation loss: 2.6217159446468665

Epoch: 6| Step: 1
Training loss: 2.951477883187724
Validation loss: 2.5303574556660458

Epoch: 6| Step: 2
Training loss: 2.9700500853968146
Validation loss: 2.5004765507558586

Epoch: 6| Step: 3
Training loss: 2.546930792261794
Validation loss: 2.496811438214039

Epoch: 6| Step: 4
Training loss: 2.71636331966993
Validation loss: 2.5164559342983117

Epoch: 6| Step: 5
Training loss: 2.808961804378449
Validation loss: 2.54270617326868

Epoch: 6| Step: 6
Training loss: 2.6917184944792663
Validation loss: 2.548487345352881

Epoch: 6| Step: 7
Training loss: 2.496958981129322
Validation loss: 2.5359459749274955

Epoch: 6| Step: 8
Training loss: 2.9448206159430166
Validation loss: 2.509677321783597

Epoch: 6| Step: 9
Training loss: 2.998468166908134
Validation loss: 2.4831400168852675

Epoch: 6| Step: 10
Training loss: 2.7104796097112858
Validation loss: 2.465448767612285

Epoch: 6| Step: 11
Training loss: 2.0352967080174693
Validation loss: 2.4507680281386985

Epoch: 6| Step: 12
Training loss: 2.8653580236505753
Validation loss: 2.4472174496549237

Epoch: 6| Step: 13
Training loss: 2.2520372915957756
Validation loss: 2.4604172346287023

Epoch: 202| Step: 0
Training loss: 2.4214951740337316
Validation loss: 2.4782443841708304

Epoch: 6| Step: 1
Training loss: 2.582156087422767
Validation loss: 2.4872719979139157

Epoch: 6| Step: 2
Training loss: 2.327767363863613
Validation loss: 2.528226971807962

Epoch: 6| Step: 3
Training loss: 2.5576714403968084
Validation loss: 2.519587836997783

Epoch: 6| Step: 4
Training loss: 2.7957105716714348
Validation loss: 2.4862545666217333

Epoch: 6| Step: 5
Training loss: 2.1859810051123305
Validation loss: 2.472683204481024

Epoch: 6| Step: 6
Training loss: 2.9670250951144754
Validation loss: 2.469986315910154

Epoch: 6| Step: 7
Training loss: 3.435481363076348
Validation loss: 2.465849365920943

Epoch: 6| Step: 8
Training loss: 2.812454053715412
Validation loss: 2.464515217035053

Epoch: 6| Step: 9
Training loss: 2.593989717367552
Validation loss: 2.500929405386471

Epoch: 6| Step: 10
Training loss: 3.086325319281885
Validation loss: 2.5785418171318244

Epoch: 6| Step: 11
Training loss: 3.165250879984041
Validation loss: 2.5468897886719466

Epoch: 6| Step: 12
Training loss: 2.7184600675483503
Validation loss: 2.542194729850863

Epoch: 6| Step: 13
Training loss: 2.5074291471015435
Validation loss: 2.569228204572372

Epoch: 203| Step: 0
Training loss: 2.0620042609717433
Validation loss: 2.5878614270232303

Epoch: 6| Step: 1
Training loss: 1.9884488797675264
Validation loss: 2.6476924553818013

Epoch: 6| Step: 2
Training loss: 2.9178783806182857
Validation loss: 2.6428309594638737

Epoch: 6| Step: 3
Training loss: 2.084424102067589
Validation loss: 2.5951540403928215

Epoch: 6| Step: 4
Training loss: 2.9157974764558072
Validation loss: 2.5768920008372604

Epoch: 6| Step: 5
Training loss: 3.003225499911772
Validation loss: 2.5457173448150394

Epoch: 6| Step: 6
Training loss: 2.8910406690156303
Validation loss: 2.5250118841368585

Epoch: 6| Step: 7
Training loss: 2.4686980423107414
Validation loss: 2.522927493320809

Epoch: 6| Step: 8
Training loss: 2.803613228525353
Validation loss: 2.5191483574492066

Epoch: 6| Step: 9
Training loss: 3.214276807258012
Validation loss: 2.5263098258622705

Epoch: 6| Step: 10
Training loss: 2.6767528245803582
Validation loss: 2.5249568167947096

Epoch: 6| Step: 11
Training loss: 2.6181296403579224
Validation loss: 2.531109084715529

Epoch: 6| Step: 12
Training loss: 2.7071253112040314
Validation loss: 2.545151343222814

Epoch: 6| Step: 13
Training loss: 3.9532605777454943
Validation loss: 2.5536846656069865

Epoch: 204| Step: 0
Training loss: 2.9044699190840757
Validation loss: 2.60374437480899

Epoch: 6| Step: 1
Training loss: 2.605417780113094
Validation loss: 2.7232731915687727

Epoch: 6| Step: 2
Training loss: 3.1014524195279383
Validation loss: 2.850255380093303

Epoch: 6| Step: 3
Training loss: 2.917546457478093
Validation loss: 2.953859783744159

Epoch: 6| Step: 4
Training loss: 3.576152007684778
Validation loss: 2.941739380818663

Epoch: 6| Step: 5
Training loss: 2.6537108009379335
Validation loss: 2.747466550841364

Epoch: 6| Step: 6
Training loss: 2.9112238826538372
Validation loss: 2.5861670155503638

Epoch: 6| Step: 7
Training loss: 2.641223185123751
Validation loss: 2.537628989863915

Epoch: 6| Step: 8
Training loss: 2.6320692875446943
Validation loss: 2.5045801056853283

Epoch: 6| Step: 9
Training loss: 2.8520259950798708
Validation loss: 2.491410721137033

Epoch: 6| Step: 10
Training loss: 2.943104044997005
Validation loss: 2.521822347306215

Epoch: 6| Step: 11
Training loss: 2.6597151649675843
Validation loss: 2.598073368537282

Epoch: 6| Step: 12
Training loss: 2.570637134585502
Validation loss: 2.6763357238440477

Epoch: 6| Step: 13
Training loss: 2.91341902350042
Validation loss: 2.7267983609561552

Epoch: 205| Step: 0
Training loss: 3.819906076604768
Validation loss: 2.7017099533256625

Epoch: 6| Step: 1
Training loss: 2.263076085044252
Validation loss: 2.55808232818267

Epoch: 6| Step: 2
Training loss: 2.7018815195859585
Validation loss: 2.5006652910735703

Epoch: 6| Step: 3
Training loss: 2.481824225177959
Validation loss: 2.4657552282678084

Epoch: 6| Step: 4
Training loss: 2.681597504404541
Validation loss: 2.4561729226387903

Epoch: 6| Step: 5
Training loss: 2.3361422343782077
Validation loss: 2.4567232868063917

Epoch: 6| Step: 6
Training loss: 2.7210049978628805
Validation loss: 2.45293348798115

Epoch: 6| Step: 7
Training loss: 2.3534453195541527
Validation loss: 2.4582711016031213

Epoch: 6| Step: 8
Training loss: 3.1056623674410506
Validation loss: 2.446567957865409

Epoch: 6| Step: 9
Training loss: 2.9254518534848777
Validation loss: 2.4579814344783832

Epoch: 6| Step: 10
Training loss: 2.7064394173176307
Validation loss: 2.436720785324986

Epoch: 6| Step: 11
Training loss: 2.7109700401617842
Validation loss: 2.4438939935665296

Epoch: 6| Step: 12
Training loss: 2.4450473824494887
Validation loss: 2.44218533016247

Epoch: 6| Step: 13
Training loss: 2.401828518332612
Validation loss: 2.4368248565347135

Epoch: 206| Step: 0
Training loss: 3.189263547833428
Validation loss: 2.440298604161866

Epoch: 6| Step: 1
Training loss: 2.0691765889936047
Validation loss: 2.4503948391171084

Epoch: 6| Step: 2
Training loss: 2.33525396954912
Validation loss: 2.454762539472781

Epoch: 6| Step: 3
Training loss: 2.7956353535791973
Validation loss: 2.4621406537427215

Epoch: 6| Step: 4
Training loss: 2.9223483921012727
Validation loss: 2.459305185467796

Epoch: 6| Step: 5
Training loss: 2.1282787833197063
Validation loss: 2.458817058113208

Epoch: 6| Step: 6
Training loss: 2.8290761117577174
Validation loss: 2.4507177478945374

Epoch: 6| Step: 7
Training loss: 2.4092379757402087
Validation loss: 2.4654966688655753

Epoch: 6| Step: 8
Training loss: 2.482485454474456
Validation loss: 2.474087339361255

Epoch: 6| Step: 9
Training loss: 2.96463755819163
Validation loss: 2.4853769393383813

Epoch: 6| Step: 10
Training loss: 2.93095366519367
Validation loss: 2.5213185274543597

Epoch: 6| Step: 11
Training loss: 3.069723834809423
Validation loss: 2.546982470077614

Epoch: 6| Step: 12
Training loss: 2.8661994582926007
Validation loss: 2.609900185104926

Epoch: 6| Step: 13
Training loss: 2.5185903758922104
Validation loss: 2.6093423247064553

Epoch: 207| Step: 0
Training loss: 2.6334831674015047
Validation loss: 2.5783019362186663

Epoch: 6| Step: 1
Training loss: 2.7892732941284866
Validation loss: 2.528015725993445

Epoch: 6| Step: 2
Training loss: 2.980814462512606
Validation loss: 2.52205149087167

Epoch: 6| Step: 3
Training loss: 2.203441515972853
Validation loss: 2.5415569310645436

Epoch: 6| Step: 4
Training loss: 2.6831415009096724
Validation loss: 2.5401868366903675

Epoch: 6| Step: 5
Training loss: 1.7582860690208222
Validation loss: 2.529617671472387

Epoch: 6| Step: 6
Training loss: 2.6427982574147673
Validation loss: 2.542479159442706

Epoch: 6| Step: 7
Training loss: 2.8739731654943204
Validation loss: 2.5597001794018905

Epoch: 6| Step: 8
Training loss: 2.735554467996477
Validation loss: 2.564072351399957

Epoch: 6| Step: 9
Training loss: 2.9252177817625387
Validation loss: 2.551125608194978

Epoch: 6| Step: 10
Training loss: 2.6330596173958893
Validation loss: 2.5575843200650366

Epoch: 6| Step: 11
Training loss: 2.3520405939193174
Validation loss: 2.546770873924171

Epoch: 6| Step: 12
Training loss: 3.1878981996027216
Validation loss: 2.5273453750068784

Epoch: 6| Step: 13
Training loss: 2.943477959829154
Validation loss: 2.529209642912983

Epoch: 208| Step: 0
Training loss: 2.744329675427433
Validation loss: 2.4956093184113315

Epoch: 6| Step: 1
Training loss: 2.4562013616429677
Validation loss: 2.5028202167266684

Epoch: 6| Step: 2
Training loss: 2.7741549571294266
Validation loss: 2.48914179467229

Epoch: 6| Step: 3
Training loss: 3.103565712603213
Validation loss: 2.482188471926705

Epoch: 6| Step: 4
Training loss: 2.8033079191848342
Validation loss: 2.4741499507423663

Epoch: 6| Step: 5
Training loss: 2.554934801736727
Validation loss: 2.4665635742449243

Epoch: 6| Step: 6
Training loss: 2.9341372457594965
Validation loss: 2.4607014350286556

Epoch: 6| Step: 7
Training loss: 2.687448900313618
Validation loss: 2.4611697705714923

Epoch: 6| Step: 8
Training loss: 3.0741771806671725
Validation loss: 2.4804502993410917

Epoch: 6| Step: 9
Training loss: 2.556275040706738
Validation loss: 2.4734577025173157

Epoch: 6| Step: 10
Training loss: 1.9802344670812846
Validation loss: 2.4877672025539

Epoch: 6| Step: 11
Training loss: 2.669758811944
Validation loss: 2.488138172169307

Epoch: 6| Step: 12
Training loss: 2.3977223675245005
Validation loss: 2.4853282618327426

Epoch: 6| Step: 13
Training loss: 2.1590125037746026
Validation loss: 2.4866126868267378

Epoch: 209| Step: 0
Training loss: 2.710071964223373
Validation loss: 2.501758045483906

Epoch: 6| Step: 1
Training loss: 2.6893504669609474
Validation loss: 2.487953560474001

Epoch: 6| Step: 2
Training loss: 2.7911543494653
Validation loss: 2.5086701576583352

Epoch: 6| Step: 3
Training loss: 2.692607904820448
Validation loss: 2.5016285626858634

Epoch: 6| Step: 4
Training loss: 2.5371489371253895
Validation loss: 2.505526639974942

Epoch: 6| Step: 5
Training loss: 2.75649301231823
Validation loss: 2.5174294289745887

Epoch: 6| Step: 6
Training loss: 3.012040295487128
Validation loss: 2.563757666079104

Epoch: 6| Step: 7
Training loss: 2.663354863575918
Validation loss: 2.5603911843874925

Epoch: 6| Step: 8
Training loss: 2.6303071459851335
Validation loss: 2.5069775729201926

Epoch: 6| Step: 9
Training loss: 2.114539936791715
Validation loss: 2.472541274921282

Epoch: 6| Step: 10
Training loss: 2.7912163632215825
Validation loss: 2.472201549725042

Epoch: 6| Step: 11
Training loss: 2.6080256645250426
Validation loss: 2.474689520060821

Epoch: 6| Step: 12
Training loss: 2.3427804594582655
Validation loss: 2.4902922031766628

Epoch: 6| Step: 13
Training loss: 3.188870303741893
Validation loss: 2.5014397300461404

Epoch: 210| Step: 0
Training loss: 2.807048430842782
Validation loss: 2.561154017795897

Epoch: 6| Step: 1
Training loss: 2.758442144946419
Validation loss: 2.5908045070207164

Epoch: 6| Step: 2
Training loss: 3.2341090291080485
Validation loss: 2.6195985779218813

Epoch: 6| Step: 3
Training loss: 2.6384805854226214
Validation loss: 2.5891056320858716

Epoch: 6| Step: 4
Training loss: 2.9558325571583097
Validation loss: 2.5673599447782975

Epoch: 6| Step: 5
Training loss: 2.440788007658108
Validation loss: 2.5342865847170453

Epoch: 6| Step: 6
Training loss: 2.1754363795143945
Validation loss: 2.5000298775148893

Epoch: 6| Step: 7
Training loss: 1.5462287554750147
Validation loss: 2.493971997994942

Epoch: 6| Step: 8
Training loss: 2.9381969517911233
Validation loss: 2.4880212329954845

Epoch: 6| Step: 9
Training loss: 2.216962819883291
Validation loss: 2.4900684526772188

Epoch: 6| Step: 10
Training loss: 2.620363591423397
Validation loss: 2.4812966993652887

Epoch: 6| Step: 11
Training loss: 2.792641787297584
Validation loss: 2.495830711971316

Epoch: 6| Step: 12
Training loss: 3.149485222064308
Validation loss: 2.5069298517144483

Epoch: 6| Step: 13
Training loss: 2.413676406947467
Validation loss: 2.5010356132198073

Epoch: 211| Step: 0
Training loss: 2.147415639443802
Validation loss: 2.534219245792364

Epoch: 6| Step: 1
Training loss: 2.558867321967973
Validation loss: 2.5822308980245716

Epoch: 6| Step: 2
Training loss: 2.819536435193045
Validation loss: 2.6048551578803103

Epoch: 6| Step: 3
Training loss: 2.6928733514411434
Validation loss: 2.6425666347717973

Epoch: 6| Step: 4
Training loss: 2.474659281696339
Validation loss: 2.649416228045008

Epoch: 6| Step: 5
Training loss: 2.6813317417587093
Validation loss: 2.6320404627729608

Epoch: 6| Step: 6
Training loss: 2.8877298238870273
Validation loss: 2.607872716986213

Epoch: 6| Step: 7
Training loss: 2.2207172967061
Validation loss: 2.6226367567061297

Epoch: 6| Step: 8
Training loss: 3.011526217905601
Validation loss: 2.5725962244305873

Epoch: 6| Step: 9
Training loss: 2.7096750799401903
Validation loss: 2.5490349989542715

Epoch: 6| Step: 10
Training loss: 2.364681717986666
Validation loss: 2.533669710198322

Epoch: 6| Step: 11
Training loss: 2.329253467268583
Validation loss: 2.516394448900776

Epoch: 6| Step: 12
Training loss: 2.9726953892380674
Validation loss: 2.507906099600076

Epoch: 6| Step: 13
Training loss: 2.751489755945894
Validation loss: 2.499113099382036

Epoch: 212| Step: 0
Training loss: 2.401172979133368
Validation loss: 2.4800271326235452

Epoch: 6| Step: 1
Training loss: 2.049184530003726
Validation loss: 2.477736545491106

Epoch: 6| Step: 2
Training loss: 3.300957488823141
Validation loss: 2.4784761261467185

Epoch: 6| Step: 3
Training loss: 2.6779889209053764
Validation loss: 2.468158013866179

Epoch: 6| Step: 4
Training loss: 2.273029303855655
Validation loss: 2.4643433498794085

Epoch: 6| Step: 5
Training loss: 2.9184563368563046
Validation loss: 2.4509800848541454

Epoch: 6| Step: 6
Training loss: 3.001061251804928
Validation loss: 2.4458049608660906

Epoch: 6| Step: 7
Training loss: 3.2754057654688826
Validation loss: 2.438094858218029

Epoch: 6| Step: 8
Training loss: 2.4961046388773642
Validation loss: 2.438784778957712

Epoch: 6| Step: 9
Training loss: 2.8612021356648
Validation loss: 2.437339466110457

Epoch: 6| Step: 10
Training loss: 2.1944419791077663
Validation loss: 2.437186810798209

Epoch: 6| Step: 11
Training loss: 2.2897026546950863
Validation loss: 2.4297656323114065

Epoch: 6| Step: 12
Training loss: 2.697200655586336
Validation loss: 2.4516844152756736

Epoch: 6| Step: 13
Training loss: 2.4602545865449037
Validation loss: 2.4554046933945197

Epoch: 213| Step: 0
Training loss: 2.4039660426834235
Validation loss: 2.456723728737202

Epoch: 6| Step: 1
Training loss: 2.9523689069077372
Validation loss: 2.4608039482457498

Epoch: 6| Step: 2
Training loss: 2.0155355744152468
Validation loss: 2.4670036175435777

Epoch: 6| Step: 3
Training loss: 2.3234533764746317
Validation loss: 2.469787521906544

Epoch: 6| Step: 4
Training loss: 2.5596891664507266
Validation loss: 2.4829382575207366

Epoch: 6| Step: 5
Training loss: 2.80351381529045
Validation loss: 2.484115545761736

Epoch: 6| Step: 6
Training loss: 2.6782668549081987
Validation loss: 2.492724052505691

Epoch: 6| Step: 7
Training loss: 2.8107548703656424
Validation loss: 2.488798631456127

Epoch: 6| Step: 8
Training loss: 2.222258252275628
Validation loss: 2.4952835497932075

Epoch: 6| Step: 9
Training loss: 2.5860610425313326
Validation loss: 2.4967514548612737

Epoch: 6| Step: 10
Training loss: 2.3275415086169176
Validation loss: 2.5017145522510096

Epoch: 6| Step: 11
Training loss: 2.8260663374655777
Validation loss: 2.516182711986793

Epoch: 6| Step: 12
Training loss: 2.9040834288159556
Validation loss: 2.5090608032545005

Epoch: 6| Step: 13
Training loss: 3.5650566697933277
Validation loss: 2.546135352169258

Epoch: 214| Step: 0
Training loss: 2.693777869272887
Validation loss: 2.5393932859706383

Epoch: 6| Step: 1
Training loss: 2.5081522583686318
Validation loss: 2.5663780852289917

Epoch: 6| Step: 2
Training loss: 2.0826267442910593
Validation loss: 2.5837805334779755

Epoch: 6| Step: 3
Training loss: 2.4660519693162697
Validation loss: 2.5514777500749983

Epoch: 6| Step: 4
Training loss: 2.8513364101295497
Validation loss: 2.5477078574145215

Epoch: 6| Step: 5
Training loss: 1.5023605528242456
Validation loss: 2.5299087570444874

Epoch: 6| Step: 6
Training loss: 3.12072996232319
Validation loss: 2.5196688986543507

Epoch: 6| Step: 7
Training loss: 2.845042846571581
Validation loss: 2.5251933886078652

Epoch: 6| Step: 8
Training loss: 3.146091846345184
Validation loss: 2.5123150404327137

Epoch: 6| Step: 9
Training loss: 2.621754410963439
Validation loss: 2.5169529081044164

Epoch: 6| Step: 10
Training loss: 3.1732123801744474
Validation loss: 2.5137673481201315

Epoch: 6| Step: 11
Training loss: 2.426507371225879
Validation loss: 2.503403427110047

Epoch: 6| Step: 12
Training loss: 2.5284466702685444
Validation loss: 2.5102330891583744

Epoch: 6| Step: 13
Training loss: 2.5233454731792393
Validation loss: 2.5112336319146737

Epoch: 215| Step: 0
Training loss: 3.341089206056119
Validation loss: 2.510269940608575

Epoch: 6| Step: 1
Training loss: 2.2433107333960276
Validation loss: 2.504505568430595

Epoch: 6| Step: 2
Training loss: 1.8434269508930394
Validation loss: 2.515652633410254

Epoch: 6| Step: 3
Training loss: 2.751017642298447
Validation loss: 2.5040387079283537

Epoch: 6| Step: 4
Training loss: 2.7356977478631617
Validation loss: 2.525475118263334

Epoch: 6| Step: 5
Training loss: 2.7335406093005665
Validation loss: 2.5208184155278963

Epoch: 6| Step: 6
Training loss: 2.6071843071197525
Validation loss: 2.5264413060578423

Epoch: 6| Step: 7
Training loss: 1.8063827413074067
Validation loss: 2.5828610728538623

Epoch: 6| Step: 8
Training loss: 2.4899056730060134
Validation loss: 2.632613302972985

Epoch: 6| Step: 9
Training loss: 2.679009354532676
Validation loss: 2.7027359719925435

Epoch: 6| Step: 10
Training loss: 2.9605549990508173
Validation loss: 2.6740434855708304

Epoch: 6| Step: 11
Training loss: 2.0096282467169
Validation loss: 2.648786424956084

Epoch: 6| Step: 12
Training loss: 2.8226040224786053
Validation loss: 2.630962376235141

Epoch: 6| Step: 13
Training loss: 3.0773712629573446
Validation loss: 2.5737636394838863

Epoch: 216| Step: 0
Training loss: 2.450175559312813
Validation loss: 2.5609285001346294

Epoch: 6| Step: 1
Training loss: 2.94427050870503
Validation loss: 2.5518159935167253

Epoch: 6| Step: 2
Training loss: 2.603686133236438
Validation loss: 2.5510968606959783

Epoch: 6| Step: 3
Training loss: 2.9035389057993064
Validation loss: 2.5406561614088683

Epoch: 6| Step: 4
Training loss: 2.9544159827507874
Validation loss: 2.5258541997103388

Epoch: 6| Step: 5
Training loss: 2.4817332491408814
Validation loss: 2.5323811096149873

Epoch: 6| Step: 6
Training loss: 2.762592959673908
Validation loss: 2.5657229131013892

Epoch: 6| Step: 7
Training loss: 2.2015871131880216
Validation loss: 2.5955586992108404

Epoch: 6| Step: 8
Training loss: 3.1444160013818294
Validation loss: 2.575350243523258

Epoch: 6| Step: 9
Training loss: 2.5528380439331135
Validation loss: 2.6160991425423514

Epoch: 6| Step: 10
Training loss: 2.1728473929033028
Validation loss: 2.659889305012586

Epoch: 6| Step: 11
Training loss: 2.8952144995303914
Validation loss: 2.635558146973426

Epoch: 6| Step: 12
Training loss: 1.5635234532660403
Validation loss: 2.6313826610177387

Epoch: 6| Step: 13
Training loss: 3.0605060547892022
Validation loss: 2.6102256780917013

Epoch: 217| Step: 0
Training loss: 2.461532859841722
Validation loss: 2.6251823276029294

Epoch: 6| Step: 1
Training loss: 2.9439347583756446
Validation loss: 2.6196154965736778

Epoch: 6| Step: 2
Training loss: 2.4439865271014325
Validation loss: 2.583637729366222

Epoch: 6| Step: 3
Training loss: 2.30311142647003
Validation loss: 2.5718387007754275

Epoch: 6| Step: 4
Training loss: 2.684736560990017
Validation loss: 2.5642043337768006

Epoch: 6| Step: 5
Training loss: 2.255692697948217
Validation loss: 2.552086273921623

Epoch: 6| Step: 6
Training loss: 2.579668727277337
Validation loss: 2.5480819490637585

Epoch: 6| Step: 7
Training loss: 2.373585932537136
Validation loss: 2.5362213833336176

Epoch: 6| Step: 8
Training loss: 2.3375296891718853
Validation loss: 2.528976851841671

Epoch: 6| Step: 9
Training loss: 2.933411695416224
Validation loss: 2.528534054399053

Epoch: 6| Step: 10
Training loss: 3.184595018447174
Validation loss: 2.5176259661449296

Epoch: 6| Step: 11
Training loss: 3.0886258933476576
Validation loss: 2.5153506417337606

Epoch: 6| Step: 12
Training loss: 2.632243561893241
Validation loss: 2.519167025365065

Epoch: 6| Step: 13
Training loss: 2.0687799503428765
Validation loss: 2.5837859022950584

Epoch: 218| Step: 0
Training loss: 2.82950857472001
Validation loss: 2.6819993427397515

Epoch: 6| Step: 1
Training loss: 3.02206839383462
Validation loss: 2.781366793558492

Epoch: 6| Step: 2
Training loss: 3.2641285657245644
Validation loss: 2.8400069390431266

Epoch: 6| Step: 3
Training loss: 2.6675386096051414
Validation loss: 2.778398195852549

Epoch: 6| Step: 4
Training loss: 2.625282454053661
Validation loss: 2.711968883243449

Epoch: 6| Step: 5
Training loss: 2.0006796158995757
Validation loss: 2.600736572237522

Epoch: 6| Step: 6
Training loss: 3.260527067580156
Validation loss: 2.559889930036712

Epoch: 6| Step: 7
Training loss: 2.128731536695566
Validation loss: 2.544059557649627

Epoch: 6| Step: 8
Training loss: 2.7882582415836294
Validation loss: 2.555473225622631

Epoch: 6| Step: 9
Training loss: 2.113974297171459
Validation loss: 2.5837469768781824

Epoch: 6| Step: 10
Training loss: 2.6039701667400994
Validation loss: 2.6054369516220746

Epoch: 6| Step: 11
Training loss: 3.409476615587256
Validation loss: 2.5658707077972194

Epoch: 6| Step: 12
Training loss: 3.001706591617209
Validation loss: 2.512036070614237

Epoch: 6| Step: 13
Training loss: 2.700167233974715
Validation loss: 2.480063520149632

Epoch: 219| Step: 0
Training loss: 2.232955054610241
Validation loss: 2.4331102054272247

Epoch: 6| Step: 1
Training loss: 2.675944302456812
Validation loss: 2.4206356671125238

Epoch: 6| Step: 2
Training loss: 2.8549116141672464
Validation loss: 2.4366256632909016

Epoch: 6| Step: 3
Training loss: 2.664825598644573
Validation loss: 2.478228482425816

Epoch: 6| Step: 4
Training loss: 2.8552924022153032
Validation loss: 2.5294844155232

Epoch: 6| Step: 5
Training loss: 2.483244824805705
Validation loss: 2.571873734504435

Epoch: 6| Step: 6
Training loss: 3.5245800660978017
Validation loss: 2.6139655434743316

Epoch: 6| Step: 7
Training loss: 2.2487108988222415
Validation loss: 2.641302963575372

Epoch: 6| Step: 8
Training loss: 3.311638918105894
Validation loss: 2.6677292589718538

Epoch: 6| Step: 9
Training loss: 2.661108622309778
Validation loss: 2.6718479815497904

Epoch: 6| Step: 10
Training loss: 3.2749331751404855
Validation loss: 2.660157042176132

Epoch: 6| Step: 11
Training loss: 2.858041587895398
Validation loss: 2.6389930605948733

Epoch: 6| Step: 12
Training loss: 2.5047151922169344
Validation loss: 2.5900803497824136

Epoch: 6| Step: 13
Training loss: 2.8135196109167575
Validation loss: 2.5449981638983576

Epoch: 220| Step: 0
Training loss: 3.2281917125680843
Validation loss: 2.496464977229189

Epoch: 6| Step: 1
Training loss: 2.777450022964575
Validation loss: 2.466172889463773

Epoch: 6| Step: 2
Training loss: 2.7093316414607513
Validation loss: 2.441596968357161

Epoch: 6| Step: 3
Training loss: 2.723379906435496
Validation loss: 2.444260816476067

Epoch: 6| Step: 4
Training loss: 2.9413550221717673
Validation loss: 2.4486895519061456

Epoch: 6| Step: 5
Training loss: 2.9208440746884414
Validation loss: 2.460063428427064

Epoch: 6| Step: 6
Training loss: 2.398187381985864
Validation loss: 2.4740721725066326

Epoch: 6| Step: 7
Training loss: 2.784913040392394
Validation loss: 2.4819559682613312

Epoch: 6| Step: 8
Training loss: 2.460803800311583
Validation loss: 2.5326446140913816

Epoch: 6| Step: 9
Training loss: 2.6747135008929708
Validation loss: 2.525996378391261

Epoch: 6| Step: 10
Training loss: 2.9498715518207246
Validation loss: 2.525910875448263

Epoch: 6| Step: 11
Training loss: 3.1482363653185352
Validation loss: 2.5043445594064613

Epoch: 6| Step: 12
Training loss: 2.4588604593603836
Validation loss: 2.5099595224296576

Epoch: 6| Step: 13
Training loss: 1.9370444592881473
Validation loss: 2.496240082907787

Epoch: 221| Step: 0
Training loss: 3.094685422720795
Validation loss: 2.4982439888107884

Epoch: 6| Step: 1
Training loss: 2.1572403775658247
Validation loss: 2.490243824557432

Epoch: 6| Step: 2
Training loss: 2.774837516632889
Validation loss: 2.476813638001095

Epoch: 6| Step: 3
Training loss: 2.0085497738190834
Validation loss: 2.4856129515354737

Epoch: 6| Step: 4
Training loss: 3.213319808910395
Validation loss: 2.4773528351674416

Epoch: 6| Step: 5
Training loss: 2.8185778749273593
Validation loss: 2.480306652464438

Epoch: 6| Step: 6
Training loss: 2.593549973461809
Validation loss: 2.4803168938516347

Epoch: 6| Step: 7
Training loss: 2.548601747011126
Validation loss: 2.494851125122988

Epoch: 6| Step: 8
Training loss: 2.5351307636972473
Validation loss: 2.5078734229897166

Epoch: 6| Step: 9
Training loss: 2.518911927274013
Validation loss: 2.5194405223565077

Epoch: 6| Step: 10
Training loss: 2.4967152951457336
Validation loss: 2.524797608492114

Epoch: 6| Step: 11
Training loss: 2.6456289337583154
Validation loss: 2.585900843551673

Epoch: 6| Step: 12
Training loss: 2.6711212344232553
Validation loss: 2.6043407993959202

Epoch: 6| Step: 13
Training loss: 2.467554213248131
Validation loss: 2.5895420618205067

Epoch: 222| Step: 0
Training loss: 2.6497207278518826
Validation loss: 2.575096176403073

Epoch: 6| Step: 1
Training loss: 2.691441418067811
Validation loss: 2.5661515376260673

Epoch: 6| Step: 2
Training loss: 2.3191796822364874
Validation loss: 2.5271138111364357

Epoch: 6| Step: 3
Training loss: 2.918587696864206
Validation loss: 2.5036089730298956

Epoch: 6| Step: 4
Training loss: 2.956093401319833
Validation loss: 2.5027358303350313

Epoch: 6| Step: 5
Training loss: 3.303263039352652
Validation loss: 2.5012980229289696

Epoch: 6| Step: 6
Training loss: 2.3745381759559616
Validation loss: 2.518339410450956

Epoch: 6| Step: 7
Training loss: 2.897954772069763
Validation loss: 2.505268035751022

Epoch: 6| Step: 8
Training loss: 3.2066233813509593
Validation loss: 2.507235340284086

Epoch: 6| Step: 9
Training loss: 1.9319628686831585
Validation loss: 2.512605939396964

Epoch: 6| Step: 10
Training loss: 1.819324929515812
Validation loss: 2.5275673520820625

Epoch: 6| Step: 11
Training loss: 1.6868923647404794
Validation loss: 2.5363517695552877

Epoch: 6| Step: 12
Training loss: 2.578343052746093
Validation loss: 2.568439190845278

Epoch: 6| Step: 13
Training loss: 2.0911549670509655
Validation loss: 2.5747477576241087

Epoch: 223| Step: 0
Training loss: 2.1604425333719113
Validation loss: 2.5835365277686897

Epoch: 6| Step: 1
Training loss: 2.2432672645434204
Validation loss: 2.5958404004719378

Epoch: 6| Step: 2
Training loss: 2.3134944942450897
Validation loss: 2.604240924063614

Epoch: 6| Step: 3
Training loss: 2.508999932597385
Validation loss: 2.601379427999509

Epoch: 6| Step: 4
Training loss: 2.690561015113726
Validation loss: 2.6260606719656154

Epoch: 6| Step: 5
Training loss: 2.948050362259018
Validation loss: 2.6475193219097255

Epoch: 6| Step: 6
Training loss: 2.411577445618241
Validation loss: 2.605014801391161

Epoch: 6| Step: 7
Training loss: 2.34692422177728
Validation loss: 2.5687921918040706

Epoch: 6| Step: 8
Training loss: 3.015855217086803
Validation loss: 2.5598726066333723

Epoch: 6| Step: 9
Training loss: 2.493684229545138
Validation loss: 2.5603547519499834

Epoch: 6| Step: 10
Training loss: 2.6244163772653426
Validation loss: 2.560933818755806

Epoch: 6| Step: 11
Training loss: 2.674297283244232
Validation loss: 2.5552456986560257

Epoch: 6| Step: 12
Training loss: 2.580676394223592
Validation loss: 2.5524364552769607

Epoch: 6| Step: 13
Training loss: 2.6692306192981947
Validation loss: 2.5507462763312807

Epoch: 224| Step: 0
Training loss: 2.5799140040533417
Validation loss: 2.5522701460417174

Epoch: 6| Step: 1
Training loss: 2.4528511040242913
Validation loss: 2.5325108482892085

Epoch: 6| Step: 2
Training loss: 2.43343718929835
Validation loss: 2.5338387832163662

Epoch: 6| Step: 3
Training loss: 2.7985682982479623
Validation loss: 2.543533744568025

Epoch: 6| Step: 4
Training loss: 3.004445279376474
Validation loss: 2.544978740580861

Epoch: 6| Step: 5
Training loss: 2.7522771250673403
Validation loss: 2.554402195741531

Epoch: 6| Step: 6
Training loss: 2.1162766189838846
Validation loss: 2.5774405308225132

Epoch: 6| Step: 7
Training loss: 1.9589788982584835
Validation loss: 2.5646374019744633

Epoch: 6| Step: 8
Training loss: 2.6939945260426303
Validation loss: 2.5650220855444585

Epoch: 6| Step: 9
Training loss: 2.721715778375706
Validation loss: 2.5593684530581995

Epoch: 6| Step: 10
Training loss: 2.7678992624198404
Validation loss: 2.566522620819823

Epoch: 6| Step: 11
Training loss: 2.220039530221719
Validation loss: 2.5635832751086287

Epoch: 6| Step: 12
Training loss: 2.24306978418688
Validation loss: 2.580667679121876

Epoch: 6| Step: 13
Training loss: 2.9179679329295207
Validation loss: 2.605018309767661

Epoch: 225| Step: 0
Training loss: 1.7842380157106712
Validation loss: 2.615622540707265

Epoch: 6| Step: 1
Training loss: 2.5266999216164323
Validation loss: 2.6406130915741763

Epoch: 6| Step: 2
Training loss: 2.5144724604687094
Validation loss: 2.6793912089182794

Epoch: 6| Step: 3
Training loss: 2.919706468068353
Validation loss: 2.6727057950403172

Epoch: 6| Step: 4
Training loss: 1.8306175259391664
Validation loss: 2.6520288290628615

Epoch: 6| Step: 5
Training loss: 3.1940945493573567
Validation loss: 2.638343301455647

Epoch: 6| Step: 6
Training loss: 3.131166096855712
Validation loss: 2.6213857054347565

Epoch: 6| Step: 7
Training loss: 1.7382318725430763
Validation loss: 2.617904816037407

Epoch: 6| Step: 8
Training loss: 2.3237281602117394
Validation loss: 2.6055024459978866

Epoch: 6| Step: 9
Training loss: 2.7721858249212454
Validation loss: 2.6023191468737257

Epoch: 6| Step: 10
Training loss: 2.9703470853169627
Validation loss: 2.5874385077998943

Epoch: 6| Step: 11
Training loss: 2.3327277850989296
Validation loss: 2.61607861843483

Epoch: 6| Step: 12
Training loss: 2.910508020633406
Validation loss: 2.612476627892767

Epoch: 6| Step: 13
Training loss: 2.2046747911547904
Validation loss: 2.6147756464547687

Epoch: 226| Step: 0
Training loss: 2.0399283839725992
Validation loss: 2.6292742626548087

Epoch: 6| Step: 1
Training loss: 2.566352181757794
Validation loss: 2.6047961754365896

Epoch: 6| Step: 2
Training loss: 2.6642311020465743
Validation loss: 2.570854499155243

Epoch: 6| Step: 3
Training loss: 3.211882737523973
Validation loss: 2.5934886590678956

Epoch: 6| Step: 4
Training loss: 2.6516925085292296
Validation loss: 2.570078584093541

Epoch: 6| Step: 5
Training loss: 1.9019377664920172
Validation loss: 2.5363117270066406

Epoch: 6| Step: 6
Training loss: 2.3256859003472448
Validation loss: 2.5049831297771434

Epoch: 6| Step: 7
Training loss: 3.3560881392734276
Validation loss: 2.4868454705507297

Epoch: 6| Step: 8
Training loss: 2.3335283288766653
Validation loss: 2.5048698688019058

Epoch: 6| Step: 9
Training loss: 2.2797794566652088
Validation loss: 2.507910387824134

Epoch: 6| Step: 10
Training loss: 2.485608064796666
Validation loss: 2.5248938417653366

Epoch: 6| Step: 11
Training loss: 2.1358218917312
Validation loss: 2.5375442031848596

Epoch: 6| Step: 12
Training loss: 2.9728666975441715
Validation loss: 2.536629090519641

Epoch: 6| Step: 13
Training loss: 2.3826445973759465
Validation loss: 2.5705054685376574

Epoch: 227| Step: 0
Training loss: 2.1237568304301186
Validation loss: 2.577004831138601

Epoch: 6| Step: 1
Training loss: 2.7963619507508204
Validation loss: 2.5874194159553903

Epoch: 6| Step: 2
Training loss: 2.823140425218723
Validation loss: 2.5996696663826806

Epoch: 6| Step: 3
Training loss: 2.5818493385120096
Validation loss: 2.594713615459188

Epoch: 6| Step: 4
Training loss: 2.9633975315184378
Validation loss: 2.6048619752710542

Epoch: 6| Step: 5
Training loss: 2.782045400659041
Validation loss: 2.6000243610190545

Epoch: 6| Step: 6
Training loss: 2.4426565158013953
Validation loss: 2.6120401945666796

Epoch: 6| Step: 7
Training loss: 2.59123521711344
Validation loss: 2.6382599965479594

Epoch: 6| Step: 8
Training loss: 2.24019467785093
Validation loss: 2.6602666628148097

Epoch: 6| Step: 9
Training loss: 2.5074055659424426
Validation loss: 2.6359060166248596

Epoch: 6| Step: 10
Training loss: 2.5304618833000574
Validation loss: 2.617164380787667

Epoch: 6| Step: 11
Training loss: 2.256115760930984
Validation loss: 2.62200717473818

Epoch: 6| Step: 12
Training loss: 2.0082508603121116
Validation loss: 2.606159058060789

Epoch: 6| Step: 13
Training loss: 2.374706752140333
Validation loss: 2.598038307212682

Epoch: 228| Step: 0
Training loss: 2.1504337538604696
Validation loss: 2.5994379282230247

Epoch: 6| Step: 1
Training loss: 1.935449068464126
Validation loss: 2.604445635876354

Epoch: 6| Step: 2
Training loss: 2.1870391360227455
Validation loss: 2.5972542997580894

Epoch: 6| Step: 3
Training loss: 2.5483824592414175
Validation loss: 2.5902063071461887

Epoch: 6| Step: 4
Training loss: 2.379977782009506
Validation loss: 2.589311300899216

Epoch: 6| Step: 5
Training loss: 2.7468511586895974
Validation loss: 2.582943795322317

Epoch: 6| Step: 6
Training loss: 2.6350993290806124
Validation loss: 2.5852118763070715

Epoch: 6| Step: 7
Training loss: 2.0263674228162514
Validation loss: 2.5976573770455706

Epoch: 6| Step: 8
Training loss: 2.8854860556805426
Validation loss: 2.5792705338907136

Epoch: 6| Step: 9
Training loss: 2.6887600628368817
Validation loss: 2.60207610520482

Epoch: 6| Step: 10
Training loss: 2.893193109369478
Validation loss: 2.6048252357506008

Epoch: 6| Step: 11
Training loss: 2.806604521856999
Validation loss: 2.5889065993791176

Epoch: 6| Step: 12
Training loss: 2.861197469286584
Validation loss: 2.598041787513353

Epoch: 6| Step: 13
Training loss: 2.0278329130483574
Validation loss: 2.6033767522717053

Epoch: 229| Step: 0
Training loss: 2.519552919752985
Validation loss: 2.618638099861933

Epoch: 6| Step: 1
Training loss: 3.062150896377025
Validation loss: 2.675300584074143

Epoch: 6| Step: 2
Training loss: 2.402467206558472
Validation loss: 2.6908804906549357

Epoch: 6| Step: 3
Training loss: 2.875907588837599
Validation loss: 2.750302325174782

Epoch: 6| Step: 4
Training loss: 1.9547844512826886
Validation loss: 2.723266006931109

Epoch: 6| Step: 5
Training loss: 2.501773300676889
Validation loss: 2.6929075093203365

Epoch: 6| Step: 6
Training loss: 1.8593360191554689
Validation loss: 2.61607695152999

Epoch: 6| Step: 7
Training loss: 2.757556935861271
Validation loss: 2.5991345460367787

Epoch: 6| Step: 8
Training loss: 3.3034104208575674
Validation loss: 2.565126666056817

Epoch: 6| Step: 9
Training loss: 2.9624996845229097
Validation loss: 2.5612330962788836

Epoch: 6| Step: 10
Training loss: 2.356093391860134
Validation loss: 2.5579115662613963

Epoch: 6| Step: 11
Training loss: 2.480280446992566
Validation loss: 2.549436986651951

Epoch: 6| Step: 12
Training loss: 2.331464791310415
Validation loss: 2.5608101952474023

Epoch: 6| Step: 13
Training loss: 2.566051812859693
Validation loss: 2.5628462866851076

Epoch: 230| Step: 0
Training loss: 2.256354471678059
Validation loss: 2.5820299761379015

Epoch: 6| Step: 1
Training loss: 2.7885430544162317
Validation loss: 2.6215875813059784

Epoch: 6| Step: 2
Training loss: 2.6285474512534885
Validation loss: 2.656288604166264

Epoch: 6| Step: 3
Training loss: 2.8768888156848362
Validation loss: 2.645960262071344

Epoch: 6| Step: 4
Training loss: 2.398408870961056
Validation loss: 2.6101402009102013

Epoch: 6| Step: 5
Training loss: 2.431871616162152
Validation loss: 2.602712359191263

Epoch: 6| Step: 6
Training loss: 2.668810419832558
Validation loss: 2.5596756375622687

Epoch: 6| Step: 7
Training loss: 2.441539449491417
Validation loss: 2.5428090492809297

Epoch: 6| Step: 8
Training loss: 2.791352515313337
Validation loss: 2.5331112212001794

Epoch: 6| Step: 9
Training loss: 2.53412210917248
Validation loss: 2.511321496574733

Epoch: 6| Step: 10
Training loss: 2.7621545946802706
Validation loss: 2.515217206815547

Epoch: 6| Step: 11
Training loss: 1.4510921081553396
Validation loss: 2.5005291799156035

Epoch: 6| Step: 12
Training loss: 2.8609083056457765
Validation loss: 2.5025304498524914

Epoch: 6| Step: 13
Training loss: 2.313467699632137
Validation loss: 2.517359271380627

Epoch: 231| Step: 0
Training loss: 2.583781562394625
Validation loss: 2.529260650462783

Epoch: 6| Step: 1
Training loss: 2.5091113948488326
Validation loss: 2.5499695167834746

Epoch: 6| Step: 2
Training loss: 1.9651501759807326
Validation loss: 2.58422147949553

Epoch: 6| Step: 3
Training loss: 2.22262235323999
Validation loss: 2.6068995361643057

Epoch: 6| Step: 4
Training loss: 2.819372638692102
Validation loss: 2.654908256248815

Epoch: 6| Step: 5
Training loss: 1.943253005294017
Validation loss: 2.7374913527773135

Epoch: 6| Step: 6
Training loss: 2.681279635321181
Validation loss: 2.753034165155559

Epoch: 6| Step: 7
Training loss: 2.4457026648722815
Validation loss: 2.751826258828711

Epoch: 6| Step: 8
Training loss: 2.8568914915955377
Validation loss: 2.7082355771908246

Epoch: 6| Step: 9
Training loss: 2.5715301319532418
Validation loss: 2.6790299218802955

Epoch: 6| Step: 10
Training loss: 2.7350362795527907
Validation loss: 2.632765669156828

Epoch: 6| Step: 11
Training loss: 2.7889282878137744
Validation loss: 2.635343660952292

Epoch: 6| Step: 12
Training loss: 2.2857357496718382
Validation loss: 2.6073580767375786

Epoch: 6| Step: 13
Training loss: 2.540961016479408
Validation loss: 2.6026826744363754

Epoch: 232| Step: 0
Training loss: 1.9673375709502703
Validation loss: 2.614779287330377

Epoch: 6| Step: 1
Training loss: 2.4573960753593234
Validation loss: 2.614969098022985

Epoch: 6| Step: 2
Training loss: 2.3234247470241485
Validation loss: 2.604852065591807

Epoch: 6| Step: 3
Training loss: 2.5407863926974756
Validation loss: 2.612465126953749

Epoch: 6| Step: 4
Training loss: 2.8122739912988974
Validation loss: 2.6331717865929174

Epoch: 6| Step: 5
Training loss: 2.658536308535674
Validation loss: 2.6401368143960307

Epoch: 6| Step: 6
Training loss: 2.3358921824878833
Validation loss: 2.6302428189777185

Epoch: 6| Step: 7
Training loss: 2.24775117177151
Validation loss: 2.597576956873006

Epoch: 6| Step: 8
Training loss: 2.663791318274931
Validation loss: 2.5674815564605913

Epoch: 6| Step: 9
Training loss: 2.377206480116712
Validation loss: 2.5551859302407416

Epoch: 6| Step: 10
Training loss: 2.8398210821073477
Validation loss: 2.5458223779863314

Epoch: 6| Step: 11
Training loss: 2.3555460801723727
Validation loss: 2.5358204710542065

Epoch: 6| Step: 12
Training loss: 2.6876570189981495
Validation loss: 2.5429861356298664

Epoch: 6| Step: 13
Training loss: 2.976876630252037
Validation loss: 2.5566125521936107

Epoch: 233| Step: 0
Training loss: 2.940736975650991
Validation loss: 2.584132962579012

Epoch: 6| Step: 1
Training loss: 2.1781790377728965
Validation loss: 2.619534896146787

Epoch: 6| Step: 2
Training loss: 2.3843034926024886
Validation loss: 2.6415967120002724

Epoch: 6| Step: 3
Training loss: 2.2635739217239816
Validation loss: 2.6723848211631656

Epoch: 6| Step: 4
Training loss: 1.9455383659899432
Validation loss: 2.6715744426161447

Epoch: 6| Step: 5
Training loss: 2.293893968601114
Validation loss: 2.6699763884481067

Epoch: 6| Step: 6
Training loss: 2.2090645665083413
Validation loss: 2.6941634701451416

Epoch: 6| Step: 7
Training loss: 3.1283772339244535
Validation loss: 2.656754665702414

Epoch: 6| Step: 8
Training loss: 2.3373476192968425
Validation loss: 2.6399027256556615

Epoch: 6| Step: 9
Training loss: 2.393712263083744
Validation loss: 2.6242468398507564

Epoch: 6| Step: 10
Training loss: 2.3172002914188834
Validation loss: 2.589178130919818

Epoch: 6| Step: 11
Training loss: 2.8325575346124303
Validation loss: 2.579866053980341

Epoch: 6| Step: 12
Training loss: 3.0223651729073575
Validation loss: 2.569940051241505

Epoch: 6| Step: 13
Training loss: 2.4252971467115967
Validation loss: 2.569556434169285

Epoch: 234| Step: 0
Training loss: 2.4085010056607405
Validation loss: 2.5835299537796494

Epoch: 6| Step: 1
Training loss: 2.4047867921155603
Validation loss: 2.584121955539575

Epoch: 6| Step: 2
Training loss: 1.9969311654037958
Validation loss: 2.583796937555462

Epoch: 6| Step: 3
Training loss: 2.14232328667646
Validation loss: 2.578948982148342

Epoch: 6| Step: 4
Training loss: 2.5818618049367514
Validation loss: 2.5852018744462164

Epoch: 6| Step: 5
Training loss: 2.2737210545891577
Validation loss: 2.581927999601165

Epoch: 6| Step: 6
Training loss: 3.017463874505833
Validation loss: 2.589355318754539

Epoch: 6| Step: 7
Training loss: 2.020926784701097
Validation loss: 2.595112456226528

Epoch: 6| Step: 8
Training loss: 2.1996180983167015
Validation loss: 2.623216358033808

Epoch: 6| Step: 9
Training loss: 2.5159900471501073
Validation loss: 2.65165695637197

Epoch: 6| Step: 10
Training loss: 3.1117880194575513
Validation loss: 2.6403563978660634

Epoch: 6| Step: 11
Training loss: 2.605130701282406
Validation loss: 2.6354059655833435

Epoch: 6| Step: 12
Training loss: 2.5613052560292355
Validation loss: 2.638958865455685

Epoch: 6| Step: 13
Training loss: 3.1147015059048964
Validation loss: 2.6191896374657095

Epoch: 235| Step: 0
Training loss: 1.839516709857602
Validation loss: 2.616976939341852

Epoch: 6| Step: 1
Training loss: 2.5654930684857136
Validation loss: 2.5743601884937077

Epoch: 6| Step: 2
Training loss: 2.245728252361218
Validation loss: 2.58695738781491

Epoch: 6| Step: 3
Training loss: 2.190414666759131
Validation loss: 2.5663004059978465

Epoch: 6| Step: 4
Training loss: 2.332549735599001
Validation loss: 2.545515048007075

Epoch: 6| Step: 5
Training loss: 2.6614615980950704
Validation loss: 2.53397375468189

Epoch: 6| Step: 6
Training loss: 2.780042064540613
Validation loss: 2.5326487622417626

Epoch: 6| Step: 7
Training loss: 1.9307191384563325
Validation loss: 2.552873842530217

Epoch: 6| Step: 8
Training loss: 2.6203324737424483
Validation loss: 2.5633042316786914

Epoch: 6| Step: 9
Training loss: 2.8654433930236776
Validation loss: 2.5698997270096693

Epoch: 6| Step: 10
Training loss: 2.6129283353114823
Validation loss: 2.5945930539081856

Epoch: 6| Step: 11
Training loss: 2.859852902024127
Validation loss: 2.637846940023269

Epoch: 6| Step: 12
Training loss: 2.7954449114242292
Validation loss: 2.6804117294206398

Epoch: 6| Step: 13
Training loss: 2.4734365669292107
Validation loss: 2.7165798304233344

Epoch: 236| Step: 0
Training loss: 2.5778337718739386
Validation loss: 2.75972610692784

Epoch: 6| Step: 1
Training loss: 2.6645249667323148
Validation loss: 2.7481916789600533

Epoch: 6| Step: 2
Training loss: 2.218439429669603
Validation loss: 2.749860940887101

Epoch: 6| Step: 3
Training loss: 2.540916259136378
Validation loss: 2.730079478187571

Epoch: 6| Step: 4
Training loss: 2.126903466800076
Validation loss: 2.665412559546189

Epoch: 6| Step: 5
Training loss: 2.635042055869308
Validation loss: 2.6173986176836492

Epoch: 6| Step: 6
Training loss: 2.054798195761612
Validation loss: 2.5991513187615345

Epoch: 6| Step: 7
Training loss: 2.861783040308927
Validation loss: 2.5671002433968724

Epoch: 6| Step: 8
Training loss: 2.2077402242073245
Validation loss: 2.558068056199422

Epoch: 6| Step: 9
Training loss: 2.677258338601056
Validation loss: 2.550521258683422

Epoch: 6| Step: 10
Training loss: 1.981768179919705
Validation loss: 2.5699969527906936

Epoch: 6| Step: 11
Training loss: 2.9492721047533026
Validation loss: 2.567206042438989

Epoch: 6| Step: 12
Training loss: 2.6522615894744366
Validation loss: 2.569215148994343

Epoch: 6| Step: 13
Training loss: 2.4146460164326515
Validation loss: 2.602667419707374

Epoch: 237| Step: 0
Training loss: 1.9890019697521921
Validation loss: 2.591951750339589

Epoch: 6| Step: 1
Training loss: 2.8291865090155173
Validation loss: 2.5994684897955733

Epoch: 6| Step: 2
Training loss: 2.6017234225520696
Validation loss: 2.5900667193218414

Epoch: 6| Step: 3
Training loss: 2.320008537342543
Validation loss: 2.594813469222446

Epoch: 6| Step: 4
Training loss: 2.2977461427953605
Validation loss: 2.5780992533372977

Epoch: 6| Step: 5
Training loss: 2.003429571792655
Validation loss: 2.5907028155086564

Epoch: 6| Step: 6
Training loss: 2.505154160345416
Validation loss: 2.618071360409035

Epoch: 6| Step: 7
Training loss: 2.6230487837681533
Validation loss: 2.6231967124956617

Epoch: 6| Step: 8
Training loss: 2.247432091082692
Validation loss: 2.644613279411648

Epoch: 6| Step: 9
Training loss: 2.1448442963684013
Validation loss: 2.686069056065161

Epoch: 6| Step: 10
Training loss: 2.195831563274483
Validation loss: 2.707387268314986

Epoch: 6| Step: 11
Training loss: 2.959250097650061
Validation loss: 2.749031257971625

Epoch: 6| Step: 12
Training loss: 2.65941314849208
Validation loss: 2.766903637704074

Epoch: 6| Step: 13
Training loss: 2.416563053759999
Validation loss: 2.7684005261196414

Epoch: 238| Step: 0
Training loss: 2.5114098532475277
Validation loss: 2.76599406546881

Epoch: 6| Step: 1
Training loss: 2.3123927735909118
Validation loss: 2.7725130298126754

Epoch: 6| Step: 2
Training loss: 2.258594944946015
Validation loss: 2.7901609206524705

Epoch: 6| Step: 3
Training loss: 2.9749887866922835
Validation loss: 2.8194653679513357

Epoch: 6| Step: 4
Training loss: 2.715221351325585
Validation loss: 2.8233996559591987

Epoch: 6| Step: 5
Training loss: 2.966422684598601
Validation loss: 2.8151270466371097

Epoch: 6| Step: 6
Training loss: 2.186593440078055
Validation loss: 2.7993592616867047

Epoch: 6| Step: 7
Training loss: 2.2522603443275315
Validation loss: 2.7633829318634024

Epoch: 6| Step: 8
Training loss: 2.259281934243364
Validation loss: 2.701765499204177

Epoch: 6| Step: 9
Training loss: 2.2588865899827306
Validation loss: 2.65732200653058

Epoch: 6| Step: 10
Training loss: 2.830721511526323
Validation loss: 2.6020744441083274

Epoch: 6| Step: 11
Training loss: 2.053142938869381
Validation loss: 2.552531992032342

Epoch: 6| Step: 12
Training loss: 2.348973874014614
Validation loss: 2.550706268792944

Epoch: 6| Step: 13
Training loss: 2.4870891020811206
Validation loss: 2.5392418522117874

Epoch: 239| Step: 0
Training loss: 2.1480683720538476
Validation loss: 2.553900233708514

Epoch: 6| Step: 1
Training loss: 2.8045739281061732
Validation loss: 2.539701981076075

Epoch: 6| Step: 2
Training loss: 2.891401196990485
Validation loss: 2.5551280125781552

Epoch: 6| Step: 3
Training loss: 2.103633498322289
Validation loss: 2.580569193347399

Epoch: 6| Step: 4
Training loss: 2.12058596214477
Validation loss: 2.588902150223912

Epoch: 6| Step: 5
Training loss: 2.488063832699957
Validation loss: 2.5997231087543606

Epoch: 6| Step: 6
Training loss: 2.4312907629837124
Validation loss: 2.5873309420590944

Epoch: 6| Step: 7
Training loss: 2.3495450411366003
Validation loss: 2.5987170394681325

Epoch: 6| Step: 8
Training loss: 2.0104620999224556
Validation loss: 2.594894127185383

Epoch: 6| Step: 9
Training loss: 3.030206402336197
Validation loss: 2.573667892769331

Epoch: 6| Step: 10
Training loss: 2.394962738639208
Validation loss: 2.581869026598356

Epoch: 6| Step: 11
Training loss: 2.360689315020768
Validation loss: 2.6012722923808727

Epoch: 6| Step: 12
Training loss: 2.3288913975868755
Validation loss: 2.619864948863782

Epoch: 6| Step: 13
Training loss: 1.7716918958349077
Validation loss: 2.6456906861007012

Epoch: 240| Step: 0
Training loss: 2.556101929496281
Validation loss: 2.6602696251595384

Epoch: 6| Step: 1
Training loss: 1.9339500638398783
Validation loss: 2.661346158336545

Epoch: 6| Step: 2
Training loss: 1.853385832315148
Validation loss: 2.6629801402612547

Epoch: 6| Step: 3
Training loss: 2.4049683167081675
Validation loss: 2.6541641316732028

Epoch: 6| Step: 4
Training loss: 2.269498158408975
Validation loss: 2.6545309083588298

Epoch: 6| Step: 5
Training loss: 2.044731123953146
Validation loss: 2.670423151496046

Epoch: 6| Step: 6
Training loss: 2.484346017728453
Validation loss: 2.67622844449282

Epoch: 6| Step: 7
Training loss: 2.638564801531989
Validation loss: 2.663716280584469

Epoch: 6| Step: 8
Training loss: 2.2318688055468985
Validation loss: 2.6531006414829537

Epoch: 6| Step: 9
Training loss: 2.2562665563594093
Validation loss: 2.647422799179519

Epoch: 6| Step: 10
Training loss: 2.353718627785441
Validation loss: 2.6412860275746635

Epoch: 6| Step: 11
Training loss: 3.0411253843792143
Validation loss: 2.593655517928953

Epoch: 6| Step: 12
Training loss: 2.6514901991491655
Validation loss: 2.587077139852628

Epoch: 6| Step: 13
Training loss: 3.0767951067575634
Validation loss: 2.5796340597869336

Epoch: 241| Step: 0
Training loss: 2.394392647395649
Validation loss: 2.5985818949882455

Epoch: 6| Step: 1
Training loss: 2.1413120921274214
Validation loss: 2.610873885285015

Epoch: 6| Step: 2
Training loss: 2.1588754564684245
Validation loss: 2.606633674530918

Epoch: 6| Step: 3
Training loss: 2.1944016708626335
Validation loss: 2.618923040236346

Epoch: 6| Step: 4
Training loss: 2.5075473348118518
Validation loss: 2.6229178945683866

Epoch: 6| Step: 5
Training loss: 2.10242158142521
Validation loss: 2.642947721063474

Epoch: 6| Step: 6
Training loss: 2.2119037147936766
Validation loss: 2.649410781279861

Epoch: 6| Step: 7
Training loss: 2.090891808788965
Validation loss: 2.6839261035845525

Epoch: 6| Step: 8
Training loss: 2.365853112937456
Validation loss: 2.75121261992986

Epoch: 6| Step: 9
Training loss: 3.3987949928709225
Validation loss: 2.8686966173695425

Epoch: 6| Step: 10
Training loss: 2.5745556716515385
Validation loss: 2.8433448298225388

Epoch: 6| Step: 11
Training loss: 2.738041452310003
Validation loss: 2.7019984809340074

Epoch: 6| Step: 12
Training loss: 2.631575930744249
Validation loss: 2.6003969895162604

Epoch: 6| Step: 13
Training loss: 2.541880666343314
Validation loss: 2.550521626566027

Epoch: 242| Step: 0
Training loss: 3.0615073950436944
Validation loss: 2.5245613763341246

Epoch: 6| Step: 1
Training loss: 2.3204275802690844
Validation loss: 2.533556812855918

Epoch: 6| Step: 2
Training loss: 2.222174996298078
Validation loss: 2.52592063404954

Epoch: 6| Step: 3
Training loss: 2.690508378499839
Validation loss: 2.558131359520127

Epoch: 6| Step: 4
Training loss: 2.7543537182177262
Validation loss: 2.5611017275433925

Epoch: 6| Step: 5
Training loss: 1.902970854932437
Validation loss: 2.6102782139020637

Epoch: 6| Step: 6
Training loss: 2.721230526295042
Validation loss: 2.643174768228883

Epoch: 6| Step: 7
Training loss: 2.360598720477988
Validation loss: 2.690615451506101

Epoch: 6| Step: 8
Training loss: 2.3391242600762254
Validation loss: 2.6880837484031104

Epoch: 6| Step: 9
Training loss: 2.4947687730687793
Validation loss: 2.6972300509825318

Epoch: 6| Step: 10
Training loss: 3.1863938450509863
Validation loss: 2.6163404778580817

Epoch: 6| Step: 11
Training loss: 2.3375171436354325
Validation loss: 2.590216384203095

Epoch: 6| Step: 12
Training loss: 2.1229140197118466
Validation loss: 2.5840804488072466

Epoch: 6| Step: 13
Training loss: 1.7233582188760488
Validation loss: 2.600306762562946

Epoch: 243| Step: 0
Training loss: 2.2540427022847513
Validation loss: 2.595330269055022

Epoch: 6| Step: 1
Training loss: 2.1141803401293844
Validation loss: 2.5972135556583678

Epoch: 6| Step: 2
Training loss: 2.576277377127969
Validation loss: 2.6392393030287806

Epoch: 6| Step: 3
Training loss: 2.3869399047881
Validation loss: 2.645822976689364

Epoch: 6| Step: 4
Training loss: 2.8729808185174743
Validation loss: 2.7540400940105227

Epoch: 6| Step: 5
Training loss: 1.5493216383755808
Validation loss: 2.760420366974709

Epoch: 6| Step: 6
Training loss: 1.8073237596753349
Validation loss: 2.780642107622676

Epoch: 6| Step: 7
Training loss: 2.827704635486917
Validation loss: 2.793058026314904

Epoch: 6| Step: 8
Training loss: 2.561417979237589
Validation loss: 2.775535615098282

Epoch: 6| Step: 9
Training loss: 2.4867283453293316
Validation loss: 2.685644692706276

Epoch: 6| Step: 10
Training loss: 2.9179260986152444
Validation loss: 2.625298427918061

Epoch: 6| Step: 11
Training loss: 2.2013949913263895
Validation loss: 2.5837600071501297

Epoch: 6| Step: 12
Training loss: 2.549689767703032
Validation loss: 2.5290920022399876

Epoch: 6| Step: 13
Training loss: 2.5978326493795034
Validation loss: 2.53388457007128

Epoch: 244| Step: 0
Training loss: 2.8191848148848444
Validation loss: 2.5320044633437577

Epoch: 6| Step: 1
Training loss: 1.7222261821879046
Validation loss: 2.548153069707079

Epoch: 6| Step: 2
Training loss: 2.3788056250526703
Validation loss: 2.5293961986634117

Epoch: 6| Step: 3
Training loss: 2.963274111790687
Validation loss: 2.5440109882163866

Epoch: 6| Step: 4
Training loss: 3.2202266528048256
Validation loss: 2.5510517224392038

Epoch: 6| Step: 5
Training loss: 2.101789837988396
Validation loss: 2.531844013316401

Epoch: 6| Step: 6
Training loss: 2.7041605470781094
Validation loss: 2.551918452053282

Epoch: 6| Step: 7
Training loss: 2.3488634404696875
Validation loss: 2.558462736734369

Epoch: 6| Step: 8
Training loss: 1.9709806369738094
Validation loss: 2.592976927001849

Epoch: 6| Step: 9
Training loss: 2.1295287175925837
Validation loss: 2.6199053201458304

Epoch: 6| Step: 10
Training loss: 2.9443722142251105
Validation loss: 2.608002825344443

Epoch: 6| Step: 11
Training loss: 2.1626362972635835
Validation loss: 2.608801657104733

Epoch: 6| Step: 12
Training loss: 1.9007396161920789
Validation loss: 2.6238308445116303

Epoch: 6| Step: 13
Training loss: 1.098909904292743
Validation loss: 2.6302019240817933

Epoch: 245| Step: 0
Training loss: 2.25848252013652
Validation loss: 2.6305166561900806

Epoch: 6| Step: 1
Training loss: 2.5657321735629965
Validation loss: 2.6466006451087587

Epoch: 6| Step: 2
Training loss: 2.6044325018939127
Validation loss: 2.6320366339265537

Epoch: 6| Step: 3
Training loss: 1.9458815879747013
Validation loss: 2.623895166526004

Epoch: 6| Step: 4
Training loss: 2.3265885781388747
Validation loss: 2.625745097219786

Epoch: 6| Step: 5
Training loss: 1.746873515065335
Validation loss: 2.621882748536454

Epoch: 6| Step: 6
Training loss: 2.7918049128069633
Validation loss: 2.6314759706907997

Epoch: 6| Step: 7
Training loss: 2.7780585676903176
Validation loss: 2.648972306561

Epoch: 6| Step: 8
Training loss: 2.3321277592048655
Validation loss: 2.6654572557958063

Epoch: 6| Step: 9
Training loss: 2.963541380620226
Validation loss: 2.7065844781016617

Epoch: 6| Step: 10
Training loss: 2.0935802106193875
Validation loss: 2.6689138736946387

Epoch: 6| Step: 11
Training loss: 2.2671538357696783
Validation loss: 2.6450546972183173

Epoch: 6| Step: 12
Training loss: 2.1209815682379647
Validation loss: 2.5864136782902136

Epoch: 6| Step: 13
Training loss: 2.4098441294365767
Validation loss: 2.5753320027742626

Epoch: 246| Step: 0
Training loss: 2.798022157484535
Validation loss: 2.561374267967613

Epoch: 6| Step: 1
Training loss: 2.4891014005084124
Validation loss: 2.5548093044905498

Epoch: 6| Step: 2
Training loss: 2.046712621406939
Validation loss: 2.5728752206293364

Epoch: 6| Step: 3
Training loss: 2.7213426702277848
Validation loss: 2.5632703190043276

Epoch: 6| Step: 4
Training loss: 1.9118027407112035
Validation loss: 2.5365980421940284

Epoch: 6| Step: 5
Training loss: 2.1357566996963517
Validation loss: 2.5317006147452794

Epoch: 6| Step: 6
Training loss: 2.6315509252562066
Validation loss: 2.5516438517434628

Epoch: 6| Step: 7
Training loss: 1.8064125700656026
Validation loss: 2.5706366648673793

Epoch: 6| Step: 8
Training loss: 2.4788946969586303
Validation loss: 2.585236969046438

Epoch: 6| Step: 9
Training loss: 1.977432481695779
Validation loss: 2.6419476495491967

Epoch: 6| Step: 10
Training loss: 2.523730187227304
Validation loss: 2.6666482481269127

Epoch: 6| Step: 11
Training loss: 2.0141589133518893
Validation loss: 2.6630177611969925

Epoch: 6| Step: 12
Training loss: 2.8972455064523275
Validation loss: 2.638166259227176

Epoch: 6| Step: 13
Training loss: 2.274601693969944
Validation loss: 2.6296262656053977

Epoch: 247| Step: 0
Training loss: 2.185171795688468
Validation loss: 2.624550187558

Epoch: 6| Step: 1
Training loss: 2.300135989937245
Validation loss: 2.5937188585598467

Epoch: 6| Step: 2
Training loss: 1.8682782805762892
Validation loss: 2.566271132202197

Epoch: 6| Step: 3
Training loss: 2.432710000330748
Validation loss: 2.5616437020002585

Epoch: 6| Step: 4
Training loss: 2.5471762262552815
Validation loss: 2.552075463174652

Epoch: 6| Step: 5
Training loss: 2.7201019959399777
Validation loss: 2.5673125900428073

Epoch: 6| Step: 6
Training loss: 2.375964822046363
Validation loss: 2.586009274745601

Epoch: 6| Step: 7
Training loss: 2.816229657312601
Validation loss: 2.6532302822994516

Epoch: 6| Step: 8
Training loss: 2.4242239113303095
Validation loss: 2.728272422505349

Epoch: 6| Step: 9
Training loss: 2.4842196242011028
Validation loss: 2.836701264996864

Epoch: 6| Step: 10
Training loss: 2.1570204312095695
Validation loss: 2.8283233074487404

Epoch: 6| Step: 11
Training loss: 2.286821954846447
Validation loss: 2.7604146767390656

Epoch: 6| Step: 12
Training loss: 1.8586281310241175
Validation loss: 2.696262955215605

Epoch: 6| Step: 13
Training loss: 2.3237712525477803
Validation loss: 2.5988309217711305

Epoch: 248| Step: 0
Training loss: 2.0958238266513765
Validation loss: 2.581390868876951

Epoch: 6| Step: 1
Training loss: 2.066722362547166
Validation loss: 2.556146085963619

Epoch: 6| Step: 2
Training loss: 2.089860406256638
Validation loss: 2.5577565501540698

Epoch: 6| Step: 3
Training loss: 2.538843515196106
Validation loss: 2.546677094100859

Epoch: 6| Step: 4
Training loss: 2.2313985139376
Validation loss: 2.5574106178281593

Epoch: 6| Step: 5
Training loss: 2.125739473817729
Validation loss: 2.580743562997552

Epoch: 6| Step: 6
Training loss: 2.6383752211400173
Validation loss: 2.5781592263951323

Epoch: 6| Step: 7
Training loss: 1.9864356687946796
Validation loss: 2.579623436041786

Epoch: 6| Step: 8
Training loss: 2.931705197125728
Validation loss: 2.582402075018268

Epoch: 6| Step: 9
Training loss: 2.564375214508144
Validation loss: 2.5767212890564415

Epoch: 6| Step: 10
Training loss: 1.618986078670183
Validation loss: 2.5536420407176847

Epoch: 6| Step: 11
Training loss: 2.406897222495082
Validation loss: 2.5464116267659236

Epoch: 6| Step: 12
Training loss: 2.673063850265312
Validation loss: 2.537508639924023

Epoch: 6| Step: 13
Training loss: 2.9738500857096666
Validation loss: 2.5909873570540727

Epoch: 249| Step: 0
Training loss: 1.9985838286966495
Validation loss: 2.62284085670325

Epoch: 6| Step: 1
Training loss: 2.139715182344126
Validation loss: 2.6803986635249433

Epoch: 6| Step: 2
Training loss: 2.160337140475152
Validation loss: 2.7216835852170616

Epoch: 6| Step: 3
Training loss: 2.1089823039412643
Validation loss: 2.7636106828621307

Epoch: 6| Step: 4
Training loss: 2.4247240597751007
Validation loss: 2.7716390234213617

Epoch: 6| Step: 5
Training loss: 2.065717326306915
Validation loss: 2.7452667937187463

Epoch: 6| Step: 6
Training loss: 2.16827577358653
Validation loss: 2.719954828482008

Epoch: 6| Step: 7
Training loss: 2.007107028146861
Validation loss: 2.6863140428472785

Epoch: 6| Step: 8
Training loss: 2.1634412624354518
Validation loss: 2.6668013383586744

Epoch: 6| Step: 9
Training loss: 2.49743568513251
Validation loss: 2.6707034538275187

Epoch: 6| Step: 10
Training loss: 2.8607137912391276
Validation loss: 2.70734727450734

Epoch: 6| Step: 11
Training loss: 3.030373830112703
Validation loss: 2.7239997973708

Epoch: 6| Step: 12
Training loss: 2.1162215277913368
Validation loss: 2.7262157827724782

Epoch: 6| Step: 13
Training loss: 2.597146441690842
Validation loss: 2.6807786723031883

Epoch: 250| Step: 0
Training loss: 2.0509043629340935
Validation loss: 2.638069047355563

Epoch: 6| Step: 1
Training loss: 2.569214189081448
Validation loss: 2.570836997344089

Epoch: 6| Step: 2
Training loss: 2.109297461320824
Validation loss: 2.5421340212799537

Epoch: 6| Step: 3
Training loss: 2.2538696497651154
Validation loss: 2.5125349456327375

Epoch: 6| Step: 4
Training loss: 2.48936929673852
Validation loss: 2.507406649715456

Epoch: 6| Step: 5
Training loss: 2.664744449265054
Validation loss: 2.4936060068166466

Epoch: 6| Step: 6
Training loss: 2.415922861623572
Validation loss: 2.495194807013835

Epoch: 6| Step: 7
Training loss: 2.316075010241241
Validation loss: 2.474031883575592

Epoch: 6| Step: 8
Training loss: 2.7516972766038585
Validation loss: 2.469739608377588

Epoch: 6| Step: 9
Training loss: 2.2430856215197736
Validation loss: 2.488712290392169

Epoch: 6| Step: 10
Training loss: 2.5452100308132035
Validation loss: 2.52120905894578

Epoch: 6| Step: 11
Training loss: 2.22771640792416
Validation loss: 2.5577086196956973

Epoch: 6| Step: 12
Training loss: 2.1369630998166596
Validation loss: 2.6465709934711956

Epoch: 6| Step: 13
Training loss: 1.9411658401079182
Validation loss: 2.673939000094998

Epoch: 251| Step: 0
Training loss: 2.2468629796922905
Validation loss: 2.695497332122628

Epoch: 6| Step: 1
Training loss: 2.148961228778446
Validation loss: 2.746591840726957

Epoch: 6| Step: 2
Training loss: 2.5414391295929692
Validation loss: 2.7432793469147643

Epoch: 6| Step: 3
Training loss: 2.3211923080777046
Validation loss: 2.7024881311045785

Epoch: 6| Step: 4
Training loss: 1.8049496546986301
Validation loss: 2.651257843855194

Epoch: 6| Step: 5
Training loss: 2.345202390156009
Validation loss: 2.627289683160078

Epoch: 6| Step: 6
Training loss: 2.5469386555024403
Validation loss: 2.627577949979427

Epoch: 6| Step: 7
Training loss: 1.990717865650662
Validation loss: 2.6125880244277186

Epoch: 6| Step: 8
Training loss: 2.500039291073078
Validation loss: 2.59202590534928

Epoch: 6| Step: 9
Training loss: 2.476263274879825
Validation loss: 2.5729959170231766

Epoch: 6| Step: 10
Training loss: 2.0294538332586245
Validation loss: 2.56285753214487

Epoch: 6| Step: 11
Training loss: 2.1266051569128206
Validation loss: 2.5380242710593564

Epoch: 6| Step: 12
Training loss: 2.0735167843939855
Validation loss: 2.5508846746986817

Epoch: 6| Step: 13
Training loss: 3.017215763791346
Validation loss: 2.553697872863716

Epoch: 252| Step: 0
Training loss: 1.997590640306831
Validation loss: 2.566677795679549

Epoch: 6| Step: 1
Training loss: 2.428620327930059
Validation loss: 2.5948503208566067

Epoch: 6| Step: 2
Training loss: 2.3385244480736738
Validation loss: 2.624281241345264

Epoch: 6| Step: 3
Training loss: 2.425499154856072
Validation loss: 2.6556561041957782

Epoch: 6| Step: 4
Training loss: 2.2036672154898427
Validation loss: 2.646586197593032

Epoch: 6| Step: 5
Training loss: 1.5249877866662411
Validation loss: 2.652160869233431

Epoch: 6| Step: 6
Training loss: 2.587792414115214
Validation loss: 2.646818692762853

Epoch: 6| Step: 7
Training loss: 2.7286185570800296
Validation loss: 2.663429374354928

Epoch: 6| Step: 8
Training loss: 2.3412539606015037
Validation loss: 2.6629537401148293

Epoch: 6| Step: 9
Training loss: 1.8867882504506366
Validation loss: 2.6562996403050794

Epoch: 6| Step: 10
Training loss: 2.652690881589682
Validation loss: 2.7033545084683714

Epoch: 6| Step: 11
Training loss: 1.5187005368564908
Validation loss: 2.68400934649366

Epoch: 6| Step: 12
Training loss: 2.0895448274826673
Validation loss: 2.6738866134487433

Epoch: 6| Step: 13
Training loss: 2.2079814654553678
Validation loss: 2.642891731507813

Epoch: 253| Step: 0
Training loss: 2.5116965380408804
Validation loss: 2.602697365659604

Epoch: 6| Step: 1
Training loss: 1.728394378030396
Validation loss: 2.6023729475994886

Epoch: 6| Step: 2
Training loss: 2.1609701930598137
Validation loss: 2.5998320629415796

Epoch: 6| Step: 3
Training loss: 1.4133140733069327
Validation loss: 2.603804365653706

Epoch: 6| Step: 4
Training loss: 2.5326974756760623
Validation loss: 2.6265417279831644

Epoch: 6| Step: 5
Training loss: 2.408511201654685
Validation loss: 2.636059849188416

Epoch: 6| Step: 6
Training loss: 1.9913951420015878
Validation loss: 2.671756700747622

Epoch: 6| Step: 7
Training loss: 3.117777603625529
Validation loss: 2.6663986027738575

Epoch: 6| Step: 8
Training loss: 1.8921399312926845
Validation loss: 2.6607055684763106

Epoch: 6| Step: 9
Training loss: 2.225716413395122
Validation loss: 2.6303147161155622

Epoch: 6| Step: 10
Training loss: 2.1914939386839687
Validation loss: 2.606067133989331

Epoch: 6| Step: 11
Training loss: 2.1600747946752468
Validation loss: 2.590287143704602

Epoch: 6| Step: 12
Training loss: 2.141736486857845
Validation loss: 2.5618763226449937

Epoch: 6| Step: 13
Training loss: 2.449990961486337
Validation loss: 2.5714141228416083

Epoch: 254| Step: 0
Training loss: 2.203069158617443
Validation loss: 2.5923997982485396

Epoch: 6| Step: 1
Training loss: 1.7622146077784617
Validation loss: 2.608517117751448

Epoch: 6| Step: 2
Training loss: 2.395583651151236
Validation loss: 2.6309707522651533

Epoch: 6| Step: 3
Training loss: 2.017358315561283
Validation loss: 2.641832181934637

Epoch: 6| Step: 4
Training loss: 2.2570609455525292
Validation loss: 2.681794800910751

Epoch: 6| Step: 5
Training loss: 1.9696976333785996
Validation loss: 2.728300475824749

Epoch: 6| Step: 6
Training loss: 2.5261342664178037
Validation loss: 2.746348042508292

Epoch: 6| Step: 7
Training loss: 2.4130499731739223
Validation loss: 2.75513087366001

Epoch: 6| Step: 8
Training loss: 1.6778441494254919
Validation loss: 2.7479612758378247

Epoch: 6| Step: 9
Training loss: 2.034717241555267
Validation loss: 2.7289365204693325

Epoch: 6| Step: 10
Training loss: 2.596378786715772
Validation loss: 2.6964880288221993

Epoch: 6| Step: 11
Training loss: 2.7066024726934743
Validation loss: 2.649180468371533

Epoch: 6| Step: 12
Training loss: 2.0361513132402895
Validation loss: 2.5531450070274926

Epoch: 6| Step: 13
Training loss: 2.8200754504560064
Validation loss: 2.5061543146046197

Epoch: 255| Step: 0
Training loss: 2.53222599757755
Validation loss: 2.4835201750051743

Epoch: 6| Step: 1
Training loss: 2.3528144013387915
Validation loss: 2.4707166004798347

Epoch: 6| Step: 2
Training loss: 1.9179586810374065
Validation loss: 2.4785261421992515

Epoch: 6| Step: 3
Training loss: 2.570365835639397
Validation loss: 2.476143590858386

Epoch: 6| Step: 4
Training loss: 2.4385873374480687
Validation loss: 2.4747078821063684

Epoch: 6| Step: 5
Training loss: 2.1183482011362824
Validation loss: 2.49646351439787

Epoch: 6| Step: 6
Training loss: 2.2350762607271077
Validation loss: 2.5592572553410156

Epoch: 6| Step: 7
Training loss: 1.8029648126224787
Validation loss: 2.634546431867567

Epoch: 6| Step: 8
Training loss: 2.634495409547575
Validation loss: 2.753019852489377

Epoch: 6| Step: 9
Training loss: 2.4471689800350327
Validation loss: 2.8131533812912455

Epoch: 6| Step: 10
Training loss: 2.1051278767287207
Validation loss: 2.8096909782155315

Epoch: 6| Step: 11
Training loss: 2.5382166935585846
Validation loss: 2.7713656312415624

Epoch: 6| Step: 12
Training loss: 2.3938495107340194
Validation loss: 2.7046033420752456

Epoch: 6| Step: 13
Training loss: 1.470719579272787
Validation loss: 2.596340088605515

Epoch: 256| Step: 0
Training loss: 1.932155436385964
Validation loss: 2.5253060385586035

Epoch: 6| Step: 1
Training loss: 2.63844416925531
Validation loss: 2.497582590698388

Epoch: 6| Step: 2
Training loss: 2.2984906178138345
Validation loss: 2.476227035464427

Epoch: 6| Step: 3
Training loss: 1.8215872431010587
Validation loss: 2.488712521136188

Epoch: 6| Step: 4
Training loss: 2.639736409755391
Validation loss: 2.4900066008885764

Epoch: 6| Step: 5
Training loss: 2.659525030366512
Validation loss: 2.493448587022378

Epoch: 6| Step: 6
Training loss: 1.4637237743240226
Validation loss: 2.496621493687672

Epoch: 6| Step: 7
Training loss: 2.5653816395802704
Validation loss: 2.5202944559334117

Epoch: 6| Step: 8
Training loss: 2.140427294880438
Validation loss: 2.515112402064543

Epoch: 6| Step: 9
Training loss: 2.1937725055116175
Validation loss: 2.5437587705938034

Epoch: 6| Step: 10
Training loss: 2.1444951177725136
Validation loss: 2.5555034738107905

Epoch: 6| Step: 11
Training loss: 2.496571096705592
Validation loss: 2.5763437431364737

Epoch: 6| Step: 12
Training loss: 2.377509347474087
Validation loss: 2.618071332991166

Epoch: 6| Step: 13
Training loss: 1.9177672985432028
Validation loss: 2.6567929798088694

Epoch: 257| Step: 0
Training loss: 2.611269143464882
Validation loss: 2.7037835201929807

Epoch: 6| Step: 1
Training loss: 2.208817614830323
Validation loss: 2.7019153918459806

Epoch: 6| Step: 2
Training loss: 2.198618940879111
Validation loss: 2.6800791858569286

Epoch: 6| Step: 3
Training loss: 1.8714957870488975
Validation loss: 2.661103921044581

Epoch: 6| Step: 4
Training loss: 2.2996860870427485
Validation loss: 2.6300556575129814

Epoch: 6| Step: 5
Training loss: 2.199782196013938
Validation loss: 2.5911902230271115

Epoch: 6| Step: 6
Training loss: 2.9248276749409676
Validation loss: 2.5292833092305487

Epoch: 6| Step: 7
Training loss: 2.1422282431391677
Validation loss: 2.521614220884984

Epoch: 6| Step: 8
Training loss: 2.6640050439987317
Validation loss: 2.518683231948411

Epoch: 6| Step: 9
Training loss: 2.1194540468828627
Validation loss: 2.5525151409587035

Epoch: 6| Step: 10
Training loss: 2.721487837190097
Validation loss: 2.6168989291497056

Epoch: 6| Step: 11
Training loss: 1.923198585329789
Validation loss: 2.685444658558462

Epoch: 6| Step: 12
Training loss: 1.7614310086697187
Validation loss: 2.7134993348724623

Epoch: 6| Step: 13
Training loss: 1.5211468029517634
Validation loss: 2.676692302215712

Epoch: 258| Step: 0
Training loss: 2.3831948895914707
Validation loss: 2.65233869876985

Epoch: 6| Step: 1
Training loss: 1.9322379242722916
Validation loss: 2.5915697870294405

Epoch: 6| Step: 2
Training loss: 2.3176764210993563
Validation loss: 2.5342454342075795

Epoch: 6| Step: 3
Training loss: 2.500528279755389
Validation loss: 2.5055552268380663

Epoch: 6| Step: 4
Training loss: 1.6240062609490786
Validation loss: 2.4892892808460734

Epoch: 6| Step: 5
Training loss: 2.1590411048146008
Validation loss: 2.478559006090621

Epoch: 6| Step: 6
Training loss: 2.6201868890398052
Validation loss: 2.487486395672683

Epoch: 6| Step: 7
Training loss: 2.331884229361112
Validation loss: 2.5002401574978026

Epoch: 6| Step: 8
Training loss: 2.142037475585795
Validation loss: 2.502431335316904

Epoch: 6| Step: 9
Training loss: 2.2965245401212036
Validation loss: 2.5263959901069066

Epoch: 6| Step: 10
Training loss: 1.8797221167112619
Validation loss: 2.533931153338006

Epoch: 6| Step: 11
Training loss: 2.1940638564909327
Validation loss: 2.565397967439797

Epoch: 6| Step: 12
Training loss: 2.1420241189946907
Validation loss: 2.6168586261075295

Epoch: 6| Step: 13
Training loss: 2.4542803139486806
Validation loss: 2.647455262541086

Epoch: 259| Step: 0
Training loss: 2.080996945321638
Validation loss: 2.7176927060174165

Epoch: 6| Step: 1
Training loss: 2.5052861593507387
Validation loss: 2.737011014440196

Epoch: 6| Step: 2
Training loss: 1.9691640630385463
Validation loss: 2.727257234791008

Epoch: 6| Step: 3
Training loss: 2.2168327967216213
Validation loss: 2.7335041512247944

Epoch: 6| Step: 4
Training loss: 2.065926104831385
Validation loss: 2.7170418198759667

Epoch: 6| Step: 5
Training loss: 2.3270887078268974
Validation loss: 2.738846140247394

Epoch: 6| Step: 6
Training loss: 1.9272594543256805
Validation loss: 2.7230443046614266

Epoch: 6| Step: 7
Training loss: 2.150364902491479
Validation loss: 2.6724025500789463

Epoch: 6| Step: 8
Training loss: 1.8738647839059885
Validation loss: 2.650475251946498

Epoch: 6| Step: 9
Training loss: 2.0911415134890454
Validation loss: 2.614915871163044

Epoch: 6| Step: 10
Training loss: 2.313836922684711
Validation loss: 2.588054707658364

Epoch: 6| Step: 11
Training loss: 1.9574234925345042
Validation loss: 2.569087888557417

Epoch: 6| Step: 12
Training loss: 2.3069087299866826
Validation loss: 2.5629759475818568

Epoch: 6| Step: 13
Training loss: 2.7804976742368925
Validation loss: 2.5741353288557263

Epoch: 260| Step: 0
Training loss: 1.715238278131946
Validation loss: 2.577338869044925

Epoch: 6| Step: 1
Training loss: 2.121877058474816
Validation loss: 2.6008861021751843

Epoch: 6| Step: 2
Training loss: 2.486802169066967
Validation loss: 2.6455076681109104

Epoch: 6| Step: 3
Training loss: 1.9791083544790873
Validation loss: 2.609592312026456

Epoch: 6| Step: 4
Training loss: 1.9281100725433862
Validation loss: 2.5827759833848476

Epoch: 6| Step: 5
Training loss: 2.590851784639697
Validation loss: 2.583469907926099

Epoch: 6| Step: 6
Training loss: 2.84114340908228
Validation loss: 2.5523754991485403

Epoch: 6| Step: 7
Training loss: 2.1772832702624716
Validation loss: 2.550021749794182

Epoch: 6| Step: 8
Training loss: 2.047221729526377
Validation loss: 2.573223926826301

Epoch: 6| Step: 9
Training loss: 1.8721767787279344
Validation loss: 2.568472848624584

Epoch: 6| Step: 10
Training loss: 1.6649338138014975
Validation loss: 2.5947396813907524

Epoch: 6| Step: 11
Training loss: 1.9121189760117105
Validation loss: 2.601140895783008

Epoch: 6| Step: 12
Training loss: 2.030443119299743
Validation loss: 2.6578275923968304

Epoch: 6| Step: 13
Training loss: 2.04799056775186
Validation loss: 2.667791443412615

Epoch: 261| Step: 0
Training loss: 1.887993107734643
Validation loss: 2.683078760697574

Epoch: 6| Step: 1
Training loss: 1.363420452017459
Validation loss: 2.709245501333754

Epoch: 6| Step: 2
Training loss: 2.3037509890475043
Validation loss: 2.7342401136655257

Epoch: 6| Step: 3
Training loss: 1.8457712635198646
Validation loss: 2.700248162833595

Epoch: 6| Step: 4
Training loss: 2.4102635784765765
Validation loss: 2.7069215115859135

Epoch: 6| Step: 5
Training loss: 1.678479137028501
Validation loss: 2.7031730881358387

Epoch: 6| Step: 6
Training loss: 2.249143437419544
Validation loss: 2.6756309194591057

Epoch: 6| Step: 7
Training loss: 1.7073634193273992
Validation loss: 2.639140140300112

Epoch: 6| Step: 8
Training loss: 2.137504251933191
Validation loss: 2.6100136177626476

Epoch: 6| Step: 9
Training loss: 2.5619796596794693
Validation loss: 2.6091548184981606

Epoch: 6| Step: 10
Training loss: 2.2514702973292495
Validation loss: 2.587864275113431

Epoch: 6| Step: 11
Training loss: 2.3405033258203822
Validation loss: 2.5618769270608848

Epoch: 6| Step: 12
Training loss: 2.2318423128792286
Validation loss: 2.5192721325930685

Epoch: 6| Step: 13
Training loss: 1.7495185325973226
Validation loss: 2.5142627661563632

Epoch: 262| Step: 0
Training loss: 2.025499626029683
Validation loss: 2.497830409332497

Epoch: 6| Step: 1
Training loss: 2.2945841049637288
Validation loss: 2.5081344794945184

Epoch: 6| Step: 2
Training loss: 2.2560033182566164
Validation loss: 2.5145159450934202

Epoch: 6| Step: 3
Training loss: 2.350078126947866
Validation loss: 2.542621297777941

Epoch: 6| Step: 4
Training loss: 2.379426946170671
Validation loss: 2.5439337929746744

Epoch: 6| Step: 5
Training loss: 1.8985552339192204
Validation loss: 2.5354628886969524

Epoch: 6| Step: 6
Training loss: 2.464564578150771
Validation loss: 2.5554828633088706

Epoch: 6| Step: 7
Training loss: 1.7182938403904695
Validation loss: 2.5902013846507175

Epoch: 6| Step: 8
Training loss: 2.21031541463605
Validation loss: 2.656726165693259

Epoch: 6| Step: 9
Training loss: 2.4956752563582816
Validation loss: 2.6817976018197305

Epoch: 6| Step: 10
Training loss: 1.7623590291237992
Validation loss: 2.6754681047019506

Epoch: 6| Step: 11
Training loss: 2.193541875025187
Validation loss: 2.663499164836941

Epoch: 6| Step: 12
Training loss: 1.2173507678868014
Validation loss: 2.6846884071296935

Epoch: 6| Step: 13
Training loss: 1.3163501037034258
Validation loss: 2.6751289254570545

Epoch: 263| Step: 0
Training loss: 2.1852549340035625
Validation loss: 2.6286039228707248

Epoch: 6| Step: 1
Training loss: 2.320885481553872
Validation loss: 2.5953517770999

Epoch: 6| Step: 2
Training loss: 2.144570827987475
Validation loss: 2.5678071519677834

Epoch: 6| Step: 3
Training loss: 1.7813898667417871
Validation loss: 2.5552298983674686

Epoch: 6| Step: 4
Training loss: 2.15086045013719
Validation loss: 2.542886836180236

Epoch: 6| Step: 5
Training loss: 2.145559262547363
Validation loss: 2.5638037725597296

Epoch: 6| Step: 6
Training loss: 1.356603977049968
Validation loss: 2.5969088326392953

Epoch: 6| Step: 7
Training loss: 2.5020000087088534
Validation loss: 2.656572331771787

Epoch: 6| Step: 8
Training loss: 2.4785864228462113
Validation loss: 2.7149876544969107

Epoch: 6| Step: 9
Training loss: 2.2304730256635903
Validation loss: 2.6625304201930162

Epoch: 6| Step: 10
Training loss: 1.900390060440403
Validation loss: 2.664767660754712

Epoch: 6| Step: 11
Training loss: 1.7124030399021968
Validation loss: 2.6059857613592583

Epoch: 6| Step: 12
Training loss: 1.7626968679658996
Validation loss: 2.5759127465403617

Epoch: 6| Step: 13
Training loss: 2.17833555673351
Validation loss: 2.5548347108856158

Epoch: 264| Step: 0
Training loss: 2.2180236917095506
Validation loss: 2.5106059604565027

Epoch: 6| Step: 1
Training loss: 1.9282849732349054
Validation loss: 2.5158306341723318

Epoch: 6| Step: 2
Training loss: 2.168655314288645
Validation loss: 2.557783562009558

Epoch: 6| Step: 3
Training loss: 2.2232074288783914
Validation loss: 2.604466300872098

Epoch: 6| Step: 4
Training loss: 2.012585025673496
Validation loss: 2.643885253744999

Epoch: 6| Step: 5
Training loss: 2.1285057321067584
Validation loss: 2.6769320926979745

Epoch: 6| Step: 6
Training loss: 2.4710977714088562
Validation loss: 2.708455562120978

Epoch: 6| Step: 7
Training loss: 1.777703485658495
Validation loss: 2.6977761804116525

Epoch: 6| Step: 8
Training loss: 2.047908376506843
Validation loss: 2.678360216785723

Epoch: 6| Step: 9
Training loss: 2.4667265120111295
Validation loss: 2.6032714079317216

Epoch: 6| Step: 10
Training loss: 1.3671499628636015
Validation loss: 2.558086018180411

Epoch: 6| Step: 11
Training loss: 1.8629268413150095
Validation loss: 2.5260653340015664

Epoch: 6| Step: 12
Training loss: 2.0966459146310594
Validation loss: 2.509476823559012

Epoch: 6| Step: 13
Training loss: 2.229484594852654
Validation loss: 2.50522486133115

Epoch: 265| Step: 0
Training loss: 2.3251538871782356
Validation loss: 2.505661430946225

Epoch: 6| Step: 1
Training loss: 2.4964125643056567
Validation loss: 2.5037413791064127

Epoch: 6| Step: 2
Training loss: 1.5520240550487454
Validation loss: 2.5485214134981446

Epoch: 6| Step: 3
Training loss: 1.8289643667471853
Validation loss: 2.6062686658534964

Epoch: 6| Step: 4
Training loss: 2.2741481024391073
Validation loss: 2.67386680519979

Epoch: 6| Step: 5
Training loss: 2.079902863618545
Validation loss: 2.6847519419118737

Epoch: 6| Step: 6
Training loss: 1.9256076695827118
Validation loss: 2.721653369757322

Epoch: 6| Step: 7
Training loss: 1.6353414562773687
Validation loss: 2.73062907395548

Epoch: 6| Step: 8
Training loss: 2.8676920350749358
Validation loss: 2.714111003550596

Epoch: 6| Step: 9
Training loss: 1.8051597340669956
Validation loss: 2.6492038007446577

Epoch: 6| Step: 10
Training loss: 2.080534262633799
Validation loss: 2.5941259312119325

Epoch: 6| Step: 11
Training loss: 1.97154134838484
Validation loss: 2.5476466372058835

Epoch: 6| Step: 12
Training loss: 1.7739279988760912
Validation loss: 2.5189881062628494

Epoch: 6| Step: 13
Training loss: 2.0902092444702625
Validation loss: 2.493152694972182

Epoch: 266| Step: 0
Training loss: 1.8636948228493457
Validation loss: 2.4825325437093313

Epoch: 6| Step: 1
Training loss: 2.460373489901147
Validation loss: 2.474573734513475

Epoch: 6| Step: 2
Training loss: 1.9112976034359868
Validation loss: 2.489601022605405

Epoch: 6| Step: 3
Training loss: 2.1329855377093274
Validation loss: 2.456890098299227

Epoch: 6| Step: 4
Training loss: 2.1706537339593033
Validation loss: 2.4731023452436287

Epoch: 6| Step: 5
Training loss: 1.509856898619562
Validation loss: 2.495467346985293

Epoch: 6| Step: 6
Training loss: 1.6777208036821956
Validation loss: 2.527220266708144

Epoch: 6| Step: 7
Training loss: 2.5884945492258757
Validation loss: 2.573585904143259

Epoch: 6| Step: 8
Training loss: 1.7578571907296332
Validation loss: 2.630078937308657

Epoch: 6| Step: 9
Training loss: 1.6669497805778757
Validation loss: 2.6650988144634167

Epoch: 6| Step: 10
Training loss: 2.515342459597976
Validation loss: 2.6663387510995786

Epoch: 6| Step: 11
Training loss: 2.2076911952338767
Validation loss: 2.7003288424280134

Epoch: 6| Step: 12
Training loss: 2.032048229951764
Validation loss: 2.6982309875200015

Epoch: 6| Step: 13
Training loss: 1.7124911008728914
Validation loss: 2.698853637948415

Epoch: 267| Step: 0
Training loss: 2.604844780688848
Validation loss: 2.665910925858911

Epoch: 6| Step: 1
Training loss: 2.6385997703069273
Validation loss: 2.6074943443613523

Epoch: 6| Step: 2
Training loss: 1.7296367910062767
Validation loss: 2.5627906068279436

Epoch: 6| Step: 3
Training loss: 1.6759915164377732
Validation loss: 2.5482703384736087

Epoch: 6| Step: 4
Training loss: 2.1742902540428415
Validation loss: 2.5121588578070893

Epoch: 6| Step: 5
Training loss: 2.148392555460286
Validation loss: 2.519657067701756

Epoch: 6| Step: 6
Training loss: 1.0816556092585132
Validation loss: 2.5362249231914937

Epoch: 6| Step: 7
Training loss: 2.0799144411830026
Validation loss: 2.546463048833451

Epoch: 6| Step: 8
Training loss: 1.7702220385233678
Validation loss: 2.5709572589385874

Epoch: 6| Step: 9
Training loss: 2.3123935984284194
Validation loss: 2.601967930732048

Epoch: 6| Step: 10
Training loss: 2.131551963915453
Validation loss: 2.629065797253263

Epoch: 6| Step: 11
Training loss: 2.1693284728111646
Validation loss: 2.694907379497866

Epoch: 6| Step: 12
Training loss: 2.273680578915817
Validation loss: 2.761728253685944

Epoch: 6| Step: 13
Training loss: 1.579977553365102
Validation loss: 2.7835283587871147

Epoch: 268| Step: 0
Training loss: 1.9739023031235896
Validation loss: 2.7432116954749604

Epoch: 6| Step: 1
Training loss: 2.123127055825492
Validation loss: 2.6909252992989914

Epoch: 6| Step: 2
Training loss: 2.258480408818957
Validation loss: 2.635421231199533

Epoch: 6| Step: 3
Training loss: 2.090078294373521
Validation loss: 2.6243203411758844

Epoch: 6| Step: 4
Training loss: 2.0276844127998266
Validation loss: 2.592166809352722

Epoch: 6| Step: 5
Training loss: 1.904092599720706
Validation loss: 2.5778827214063207

Epoch: 6| Step: 6
Training loss: 2.6182474751259512
Validation loss: 2.5918473857473074

Epoch: 6| Step: 7
Training loss: 1.7320350464541374
Validation loss: 2.5866404181136953

Epoch: 6| Step: 8
Training loss: 2.238026443011597
Validation loss: 2.5752162580101725

Epoch: 6| Step: 9
Training loss: 1.3949589434088685
Validation loss: 2.551874923651202

Epoch: 6| Step: 10
Training loss: 1.8248996811559146
Validation loss: 2.5767371615200583

Epoch: 6| Step: 11
Training loss: 1.6499262590980925
Validation loss: 2.5547989849205153

Epoch: 6| Step: 12
Training loss: 1.9612490949756292
Validation loss: 2.5523866039210232

Epoch: 6| Step: 13
Training loss: 2.372701436084482
Validation loss: 2.576688189230456

Epoch: 269| Step: 0
Training loss: 2.3023081766052687
Validation loss: 2.6015284701502153

Epoch: 6| Step: 1
Training loss: 1.977212188455627
Validation loss: 2.60599708381475

Epoch: 6| Step: 2
Training loss: 2.162131539414679
Validation loss: 2.617220183137662

Epoch: 6| Step: 3
Training loss: 1.875222447233468
Validation loss: 2.6300947065896767

Epoch: 6| Step: 4
Training loss: 1.7786643016595478
Validation loss: 2.615902513523814

Epoch: 6| Step: 5
Training loss: 1.8646280151923824
Validation loss: 2.593864113721084

Epoch: 6| Step: 6
Training loss: 1.930714075485564
Validation loss: 2.6126629596011717

Epoch: 6| Step: 7
Training loss: 1.6806003662664633
Validation loss: 2.604388121674264

Epoch: 6| Step: 8
Training loss: 2.102436777223439
Validation loss: 2.648586323097978

Epoch: 6| Step: 9
Training loss: 1.1232665800717148
Validation loss: 2.6046195134029055

Epoch: 6| Step: 10
Training loss: 1.6030493556686254
Validation loss: 2.6112318677200075

Epoch: 6| Step: 11
Training loss: 2.4306779909328733
Validation loss: 2.6003346623777635

Epoch: 6| Step: 12
Training loss: 1.8727315531881221
Validation loss: 2.560384242078617

Epoch: 6| Step: 13
Training loss: 2.3642177775356226
Validation loss: 2.5351932933174113

Epoch: 270| Step: 0
Training loss: 2.056596224777435
Validation loss: 2.517457480466595

Epoch: 6| Step: 1
Training loss: 1.7688215908484002
Validation loss: 2.5185017143300894

Epoch: 6| Step: 2
Training loss: 1.826458097660709
Validation loss: 2.5110716673517386

Epoch: 6| Step: 3
Training loss: 1.6969123007255738
Validation loss: 2.5054698684179146

Epoch: 6| Step: 4
Training loss: 1.6742153721293356
Validation loss: 2.508170562484272

Epoch: 6| Step: 5
Training loss: 2.1365471305478487
Validation loss: 2.51609439250176

Epoch: 6| Step: 6
Training loss: 1.6924795221078797
Validation loss: 2.5485565555093697

Epoch: 6| Step: 7
Training loss: 2.436350233385339
Validation loss: 2.555479826644088

Epoch: 6| Step: 8
Training loss: 1.260950191013233
Validation loss: 2.5942892202748467

Epoch: 6| Step: 9
Training loss: 2.1289516059173668
Validation loss: 2.656982571791555

Epoch: 6| Step: 10
Training loss: 1.9247627582753988
Validation loss: 2.701809926165493

Epoch: 6| Step: 11
Training loss: 2.18905823929758
Validation loss: 2.7375569111629336

Epoch: 6| Step: 12
Training loss: 2.0599701132967394
Validation loss: 2.740147657012416

Epoch: 6| Step: 13
Training loss: 1.8293585894558557
Validation loss: 2.694256805458066

Epoch: 271| Step: 0
Training loss: 2.083666533209825
Validation loss: 2.631800264195936

Epoch: 6| Step: 1
Training loss: 1.7432927615743068
Validation loss: 2.576443918798376

Epoch: 6| Step: 2
Training loss: 2.0523550044151593
Validation loss: 2.534946250108647

Epoch: 6| Step: 3
Training loss: 1.9818963618046042
Validation loss: 2.5044413748851837

Epoch: 6| Step: 4
Training loss: 2.274628317516759
Validation loss: 2.4932339785971807

Epoch: 6| Step: 5
Training loss: 2.010116857861025
Validation loss: 2.4995140064759496

Epoch: 6| Step: 6
Training loss: 1.3074223527773534
Validation loss: 2.4834489211458965

Epoch: 6| Step: 7
Training loss: 1.7802262961737136
Validation loss: 2.5088143351073278

Epoch: 6| Step: 8
Training loss: 1.6139188157832502
Validation loss: 2.5241435592258266

Epoch: 6| Step: 9
Training loss: 2.2010931290331635
Validation loss: 2.5600222712411327

Epoch: 6| Step: 10
Training loss: 2.1874296994493236
Validation loss: 2.588313618919478

Epoch: 6| Step: 11
Training loss: 1.7924999546705425
Validation loss: 2.5863384197140427

Epoch: 6| Step: 12
Training loss: 1.2616362648093178
Validation loss: 2.576958617631942

Epoch: 6| Step: 13
Training loss: 2.353541761071164
Validation loss: 2.5823303072304697

Epoch: 272| Step: 0
Training loss: 1.5346582590221391
Validation loss: 2.645067526755956

Epoch: 6| Step: 1
Training loss: 1.7849322623001007
Validation loss: 2.686570453456421

Epoch: 6| Step: 2
Training loss: 1.5671283836282577
Validation loss: 2.751213712025108

Epoch: 6| Step: 3
Training loss: 1.944811530506407
Validation loss: 2.786727246125839

Epoch: 6| Step: 4
Training loss: 1.7623165495070696
Validation loss: 2.8075356380965815

Epoch: 6| Step: 5
Training loss: 2.249888629276287
Validation loss: 2.7593576515390166

Epoch: 6| Step: 6
Training loss: 1.8924851527570201
Validation loss: 2.6710188844033578

Epoch: 6| Step: 7
Training loss: 1.9969634608105016
Validation loss: 2.609162847933167

Epoch: 6| Step: 8
Training loss: 1.32270659132916
Validation loss: 2.5664321229581084

Epoch: 6| Step: 9
Training loss: 2.7083455207746114
Validation loss: 2.5277078430978186

Epoch: 6| Step: 10
Training loss: 1.6847559199152058
Validation loss: 2.483004725029579

Epoch: 6| Step: 11
Training loss: 1.8114880334731056
Validation loss: 2.4798167751545055

Epoch: 6| Step: 12
Training loss: 1.9282192559597457
Validation loss: 2.486166184185571

Epoch: 6| Step: 13
Training loss: 2.232213074805859
Validation loss: 2.5156216482207534

Epoch: 273| Step: 0
Training loss: 2.065995462181817
Validation loss: 2.5528552945652674

Epoch: 6| Step: 1
Training loss: 2.002554454277384
Validation loss: 2.5948561834785173

Epoch: 6| Step: 2
Training loss: 1.9864114839509934
Validation loss: 2.6546843902788506

Epoch: 6| Step: 3
Training loss: 1.8729986954301079
Validation loss: 2.701266413561051

Epoch: 6| Step: 4
Training loss: 2.1796947192000746
Validation loss: 2.7773048078887204

Epoch: 6| Step: 5
Training loss: 2.234346829750304
Validation loss: 2.7868209080088784

Epoch: 6| Step: 6
Training loss: 2.0390412194321765
Validation loss: 2.7426323850146908

Epoch: 6| Step: 7
Training loss: 1.6575323934252104
Validation loss: 2.6159560476290338

Epoch: 6| Step: 8
Training loss: 1.2347780366422825
Validation loss: 2.552171273607189

Epoch: 6| Step: 9
Training loss: 1.4823452373089852
Validation loss: 2.536425347707605

Epoch: 6| Step: 10
Training loss: 2.188166489565995
Validation loss: 2.5428569026806276

Epoch: 6| Step: 11
Training loss: 2.023567814110321
Validation loss: 2.535008619439081

Epoch: 6| Step: 12
Training loss: 1.7068264836246936
Validation loss: 2.533101501938795

Epoch: 6| Step: 13
Training loss: 1.6659587389769757
Validation loss: 2.5703283088088953

Epoch: 274| Step: 0
Training loss: 1.6609369574013915
Validation loss: 2.545424721283022

Epoch: 6| Step: 1
Training loss: 1.6482169198075811
Validation loss: 2.548075503940325

Epoch: 6| Step: 2
Training loss: 1.523363317003945
Validation loss: 2.5516678228061074

Epoch: 6| Step: 3
Training loss: 1.884449227612401
Validation loss: 2.5604689047210254

Epoch: 6| Step: 4
Training loss: 2.061809886726389
Validation loss: 2.584633407949482

Epoch: 6| Step: 5
Training loss: 2.397130852563185
Validation loss: 2.596094317654008

Epoch: 6| Step: 6
Training loss: 1.8586625729839135
Validation loss: 2.553852194737177

Epoch: 6| Step: 7
Training loss: 1.9130081075246272
Validation loss: 2.542074180572418

Epoch: 6| Step: 8
Training loss: 1.7327076913767376
Validation loss: 2.569870544093237

Epoch: 6| Step: 9
Training loss: 1.8632129840621177
Validation loss: 2.5731704093245233

Epoch: 6| Step: 10
Training loss: 1.5861249540444564
Validation loss: 2.6140315479404372

Epoch: 6| Step: 11
Training loss: 1.9585118584389516
Validation loss: 2.6418542769374667

Epoch: 6| Step: 12
Training loss: 2.3443361693756133
Validation loss: 2.6114997792318677

Epoch: 6| Step: 13
Training loss: 1.8049678171939678
Validation loss: 2.6101129785279102

Epoch: 275| Step: 0
Training loss: 1.787339359347752
Validation loss: 2.5743615338678354

Epoch: 6| Step: 1
Training loss: 1.5975328318486066
Validation loss: 2.590143055311685

Epoch: 6| Step: 2
Training loss: 1.9204539185636338
Validation loss: 2.6223713770550434

Epoch: 6| Step: 3
Training loss: 2.0705534021104626
Validation loss: 2.6275731633536243

Epoch: 6| Step: 4
Training loss: 2.4617893258513184
Validation loss: 2.6681078918070114

Epoch: 6| Step: 5
Training loss: 1.176886663070154
Validation loss: 2.6278947201465224

Epoch: 6| Step: 6
Training loss: 2.088272216868674
Validation loss: 2.6111316501918282

Epoch: 6| Step: 7
Training loss: 1.8170868285642003
Validation loss: 2.596002035216447

Epoch: 6| Step: 8
Training loss: 1.8590108049970293
Validation loss: 2.5723712016291125

Epoch: 6| Step: 9
Training loss: 1.4204204791058805
Validation loss: 2.5601007277754415

Epoch: 6| Step: 10
Training loss: 1.739117641894309
Validation loss: 2.528001284267392

Epoch: 6| Step: 11
Training loss: 2.1279850357791523
Validation loss: 2.529466238277386

Epoch: 6| Step: 12
Training loss: 1.4526889926256255
Validation loss: 2.5002412228442834

Epoch: 6| Step: 13
Training loss: 1.376007881105941
Validation loss: 2.496993798511491

Epoch: 276| Step: 0
Training loss: 1.5758600883828358
Validation loss: 2.5179666545074304

Epoch: 6| Step: 1
Training loss: 1.610702263633467
Validation loss: 2.486609349551757

Epoch: 6| Step: 2
Training loss: 1.7947928264995716
Validation loss: 2.46342314240546

Epoch: 6| Step: 3
Training loss: 2.078962343785929
Validation loss: 2.4642260487818795

Epoch: 6| Step: 4
Training loss: 1.8806442502153138
Validation loss: 2.4694144633466824

Epoch: 6| Step: 5
Training loss: 1.7769335598307712
Validation loss: 2.502946773055258

Epoch: 6| Step: 6
Training loss: 2.0052889985212436
Validation loss: 2.529446790962823

Epoch: 6| Step: 7
Training loss: 1.4847128232716522
Validation loss: 2.5902631786852566

Epoch: 6| Step: 8
Training loss: 1.6293948238968121
Validation loss: 2.6439301781701467

Epoch: 6| Step: 9
Training loss: 2.148713361195844
Validation loss: 2.6798270378231273

Epoch: 6| Step: 10
Training loss: 2.159434523914474
Validation loss: 2.6936989425869418

Epoch: 6| Step: 11
Training loss: 1.708100496877769
Validation loss: 2.6987685968255244

Epoch: 6| Step: 12
Training loss: 1.7950355734527763
Validation loss: 2.6600570748163106

Epoch: 6| Step: 13
Training loss: 1.7514766866061837
Validation loss: 2.585611163490515

Epoch: 277| Step: 0
Training loss: 1.3257180337664984
Validation loss: 2.5661764416134356

Epoch: 6| Step: 1
Training loss: 1.8382175004883297
Validation loss: 2.525295385235337

Epoch: 6| Step: 2
Training loss: 2.19203196141686
Validation loss: 2.4888519159713782

Epoch: 6| Step: 3
Training loss: 1.8858368828583185
Validation loss: 2.5140367009841333

Epoch: 6| Step: 4
Training loss: 1.835171024137994
Validation loss: 2.544924834608262

Epoch: 6| Step: 5
Training loss: 1.6193823179597155
Validation loss: 2.5786019787361063

Epoch: 6| Step: 6
Training loss: 1.9309354754374197
Validation loss: 2.601560181297642

Epoch: 6| Step: 7
Training loss: 1.704475637219839
Validation loss: 2.6309231393048944

Epoch: 6| Step: 8
Training loss: 1.685487677638599
Validation loss: 2.617707476007694

Epoch: 6| Step: 9
Training loss: 2.0304704784284677
Validation loss: 2.6060919541131153

Epoch: 6| Step: 10
Training loss: 1.7574512703924268
Validation loss: 2.6000500488236478

Epoch: 6| Step: 11
Training loss: 1.8069487437846141
Validation loss: 2.5698858089526233

Epoch: 6| Step: 12
Training loss: 1.5629364929867173
Validation loss: 2.5327761632277386

Epoch: 6| Step: 13
Training loss: 1.8774924560273405
Validation loss: 2.510346187813536

Epoch: 278| Step: 0
Training loss: 1.3856802476907621
Validation loss: 2.4687863824005936

Epoch: 6| Step: 1
Training loss: 2.1541695993822847
Validation loss: 2.4608062443495613

Epoch: 6| Step: 2
Training loss: 1.9866306370896596
Validation loss: 2.4398625243762093

Epoch: 6| Step: 3
Training loss: 1.7713017311698926
Validation loss: 2.4604518418327324

Epoch: 6| Step: 4
Training loss: 2.0047378450465936
Validation loss: 2.457473319408745

Epoch: 6| Step: 5
Training loss: 2.1666904839404824
Validation loss: 2.4766087785054047

Epoch: 6| Step: 6
Training loss: 1.606363979704017
Validation loss: 2.541497839355919

Epoch: 6| Step: 7
Training loss: 1.5348157820609225
Validation loss: 2.6066441577034682

Epoch: 6| Step: 8
Training loss: 2.021510440087091
Validation loss: 2.6834692904587296

Epoch: 6| Step: 9
Training loss: 1.3591042172188357
Validation loss: 2.717114609322882

Epoch: 6| Step: 10
Training loss: 1.9464160898790848
Validation loss: 2.668162774762637

Epoch: 6| Step: 11
Training loss: 2.0226936298568976
Validation loss: 2.6256257350031977

Epoch: 6| Step: 12
Training loss: 1.3688782618796156
Validation loss: 2.561653733794841

Epoch: 6| Step: 13
Training loss: 1.672776807906307
Validation loss: 2.5429271119136523

Epoch: 279| Step: 0
Training loss: 1.8420026872513808
Validation loss: 2.5567667161906305

Epoch: 6| Step: 1
Training loss: 1.6468480840868556
Validation loss: 2.59069084781353

Epoch: 6| Step: 2
Training loss: 2.0890412403014977
Validation loss: 2.606148496209165

Epoch: 6| Step: 3
Training loss: 1.6772857528062333
Validation loss: 2.619736355867362

Epoch: 6| Step: 4
Training loss: 1.707631719152826
Validation loss: 2.6211174321556974

Epoch: 6| Step: 5
Training loss: 1.3577698625162864
Validation loss: 2.6094902788772325

Epoch: 6| Step: 6
Training loss: 1.3735848860920599
Validation loss: 2.6029753593890383

Epoch: 6| Step: 7
Training loss: 1.8291878504239723
Validation loss: 2.5970606307707245

Epoch: 6| Step: 8
Training loss: 1.7058570017971741
Validation loss: 2.5758166567201473

Epoch: 6| Step: 9
Training loss: 1.6367277814301837
Validation loss: 2.5339115015219984

Epoch: 6| Step: 10
Training loss: 1.8751379598089977
Validation loss: 2.5383407670079463

Epoch: 6| Step: 11
Training loss: 1.7168515210790707
Validation loss: 2.477142233005022

Epoch: 6| Step: 12
Training loss: 1.9558522219152825
Validation loss: 2.4472828833760882

Epoch: 6| Step: 13
Training loss: 1.4631683126798738
Validation loss: 2.447334798142275

Epoch: 280| Step: 0
Training loss: 1.7993159424821314
Validation loss: 2.4597385093288224

Epoch: 6| Step: 1
Training loss: 1.3577312309079033
Validation loss: 2.4685840626208595

Epoch: 6| Step: 2
Training loss: 1.8435606131835784
Validation loss: 2.5258398055085305

Epoch: 6| Step: 3
Training loss: 1.6404916618295713
Validation loss: 2.5566100042071764

Epoch: 6| Step: 4
Training loss: 1.73333124594685
Validation loss: 2.6129315330802516

Epoch: 6| Step: 5
Training loss: 1.7252479485595076
Validation loss: 2.663725677735057

Epoch: 6| Step: 6
Training loss: 1.4992344810213152
Validation loss: 2.6916437467392114

Epoch: 6| Step: 7
Training loss: 1.829675978340078
Validation loss: 2.678257096222709

Epoch: 6| Step: 8
Training loss: 1.8958963097253565
Validation loss: 2.699961539001775

Epoch: 6| Step: 9
Training loss: 2.15228603721825
Validation loss: 2.65987073898361

Epoch: 6| Step: 10
Training loss: 1.7149831936738449
Validation loss: 2.573356766807907

Epoch: 6| Step: 11
Training loss: 1.7635541266151207
Validation loss: 2.546808987442766

Epoch: 6| Step: 12
Training loss: 1.4672739444247183
Validation loss: 2.524987297550051

Epoch: 6| Step: 13
Training loss: 1.4455275916808183
Validation loss: 2.5117551448533204

Epoch: 281| Step: 0
Training loss: 1.542140149101707
Validation loss: 2.489351749311225

Epoch: 6| Step: 1
Training loss: 1.8680342665557854
Validation loss: 2.501236087023463

Epoch: 6| Step: 2
Training loss: 1.5907901880492596
Validation loss: 2.5045093250818855

Epoch: 6| Step: 3
Training loss: 1.5769900026845112
Validation loss: 2.5430952448691113

Epoch: 6| Step: 4
Training loss: 1.5536435710273697
Validation loss: 2.584591828591376

Epoch: 6| Step: 5
Training loss: 1.9457507271832084
Validation loss: 2.6415595779174423

Epoch: 6| Step: 6
Training loss: 1.9066694454804203
Validation loss: 2.6317476690070674

Epoch: 6| Step: 7
Training loss: 1.3271195588889158
Validation loss: 2.5761417092745207

Epoch: 6| Step: 8
Training loss: 1.361981403453539
Validation loss: 2.5618892855333577

Epoch: 6| Step: 9
Training loss: 1.433619028642934
Validation loss: 2.523264659683423

Epoch: 6| Step: 10
Training loss: 1.7508589816253644
Validation loss: 2.511129233380912

Epoch: 6| Step: 11
Training loss: 1.8552296052713115
Validation loss: 2.5093055982451093

Epoch: 6| Step: 12
Training loss: 2.1685230543139413
Validation loss: 2.4886280776976566

Epoch: 6| Step: 13
Training loss: 1.7708988252384599
Validation loss: 2.5020579952926894

Epoch: 282| Step: 0
Training loss: 1.6097562023647045
Validation loss: 2.515042146199

Epoch: 6| Step: 1
Training loss: 1.7513276921967866
Validation loss: 2.4953311731841583

Epoch: 6| Step: 2
Training loss: 1.4662333903302822
Validation loss: 2.5043407165189904

Epoch: 6| Step: 3
Training loss: 2.084397565499339
Validation loss: 2.536651212510353

Epoch: 6| Step: 4
Training loss: 1.7541911482140868
Validation loss: 2.5616719778696533

Epoch: 6| Step: 5
Training loss: 1.5790674398176245
Validation loss: 2.5647626882006587

Epoch: 6| Step: 6
Training loss: 1.5132410236106904
Validation loss: 2.578290531416649

Epoch: 6| Step: 7
Training loss: 1.8222490087080714
Validation loss: 2.6358469664842166

Epoch: 6| Step: 8
Training loss: 2.048041324436976
Validation loss: 2.6536606480051486

Epoch: 6| Step: 9
Training loss: 1.7233178215632285
Validation loss: 2.6600370392590333

Epoch: 6| Step: 10
Training loss: 1.4648404947880498
Validation loss: 2.656633453391064

Epoch: 6| Step: 11
Training loss: 1.2540264606786957
Validation loss: 2.5923956230825462

Epoch: 6| Step: 12
Training loss: 1.61411417225701
Validation loss: 2.593623422498562

Epoch: 6| Step: 13
Training loss: 1.2609567614742212
Validation loss: 2.5596369644576726

Epoch: 283| Step: 0
Training loss: 1.9119306252834087
Validation loss: 2.513658842955013

Epoch: 6| Step: 1
Training loss: 1.6914340891320028
Validation loss: 2.5400213352367014

Epoch: 6| Step: 2
Training loss: 1.5403639814085979
Validation loss: 2.559974612531858

Epoch: 6| Step: 3
Training loss: 1.9027500854419994
Validation loss: 2.5491378216965184

Epoch: 6| Step: 4
Training loss: 1.356846046437552
Validation loss: 2.575169506182695

Epoch: 6| Step: 5
Training loss: 1.708933662752049
Validation loss: 2.5788926856949725

Epoch: 6| Step: 6
Training loss: 1.3141004250731483
Validation loss: 2.58955718597091

Epoch: 6| Step: 7
Training loss: 1.813094337622265
Validation loss: 2.6192191410126617

Epoch: 6| Step: 8
Training loss: 1.5718785917267613
Validation loss: 2.6245433905393925

Epoch: 6| Step: 9
Training loss: 1.6665852367853697
Validation loss: 2.647394165785597

Epoch: 6| Step: 10
Training loss: 1.7578236219266206
Validation loss: 2.6776912096904035

Epoch: 6| Step: 11
Training loss: 1.4592458140927682
Validation loss: 2.631943624656527

Epoch: 6| Step: 12
Training loss: 1.632828707819902
Validation loss: 2.5920819462380296

Epoch: 6| Step: 13
Training loss: 1.8562541383639357
Validation loss: 2.5262361469173014

Epoch: 284| Step: 0
Training loss: 1.8178801432591032
Validation loss: 2.5030584055087526

Epoch: 6| Step: 1
Training loss: 1.5415267966802986
Validation loss: 2.4967940354995637

Epoch: 6| Step: 2
Training loss: 1.758314950976472
Validation loss: 2.4839894783797853

Epoch: 6| Step: 3
Training loss: 2.108151003023809
Validation loss: 2.496522478297903

Epoch: 6| Step: 4
Training loss: 1.9401772367981795
Validation loss: 2.5185790579801965

Epoch: 6| Step: 5
Training loss: 1.944413003970076
Validation loss: 2.564643603555732

Epoch: 6| Step: 6
Training loss: 1.4233596931238153
Validation loss: 2.5741222145079674

Epoch: 6| Step: 7
Training loss: 1.4506038000553796
Validation loss: 2.6213408826595717

Epoch: 6| Step: 8
Training loss: 1.7180901387807295
Validation loss: 2.6450687101679042

Epoch: 6| Step: 9
Training loss: 1.3812316651659329
Validation loss: 2.6498322914225785

Epoch: 6| Step: 10
Training loss: 1.2287229717770725
Validation loss: 2.610754857523425

Epoch: 6| Step: 11
Training loss: 1.6912934792082952
Validation loss: 2.631386846418659

Epoch: 6| Step: 12
Training loss: 1.7218258471664842
Validation loss: 2.584905708710687

Epoch: 6| Step: 13
Training loss: 2.0568729280306624
Validation loss: 2.570657221686571

Epoch: 285| Step: 0
Training loss: 1.545831347495943
Validation loss: 2.545582478873541

Epoch: 6| Step: 1
Training loss: 2.0604172796924116
Validation loss: 2.5506570660777355

Epoch: 6| Step: 2
Training loss: 1.336355311327112
Validation loss: 2.522174535025907

Epoch: 6| Step: 3
Training loss: 1.8563067983035835
Validation loss: 2.489106557443908

Epoch: 6| Step: 4
Training loss: 1.734532460806001
Validation loss: 2.5157900693474247

Epoch: 6| Step: 5
Training loss: 1.4014667967375425
Validation loss: 2.5114332426693196

Epoch: 6| Step: 6
Training loss: 1.7973353584025338
Validation loss: 2.522404608062754

Epoch: 6| Step: 7
Training loss: 1.1511457002095615
Validation loss: 2.540425171044481

Epoch: 6| Step: 8
Training loss: 1.3467921043429667
Validation loss: 2.5639901669224616

Epoch: 6| Step: 9
Training loss: 1.537428865105241
Validation loss: 2.589894288940503

Epoch: 6| Step: 10
Training loss: 1.7560753949344237
Validation loss: 2.6285589218136693

Epoch: 6| Step: 11
Training loss: 1.6390458999825954
Validation loss: 2.6265382190747992

Epoch: 6| Step: 12
Training loss: 1.5679062204099983
Validation loss: 2.645975324370069

Epoch: 6| Step: 13
Training loss: 1.7117703296406293
Validation loss: 2.63536308947799

Epoch: 286| Step: 0
Training loss: 1.7021583823845312
Validation loss: 2.6351159692013466

Epoch: 6| Step: 1
Training loss: 1.6034672273308692
Validation loss: 2.5924295384476723

Epoch: 6| Step: 2
Training loss: 1.7397376656361598
Validation loss: 2.58067442729337

Epoch: 6| Step: 3
Training loss: 1.7296380315941582
Validation loss: 2.561449008952319

Epoch: 6| Step: 4
Training loss: 1.7237506599231367
Validation loss: 2.5596167998870962

Epoch: 6| Step: 5
Training loss: 1.2547455352624723
Validation loss: 2.584049214149755

Epoch: 6| Step: 6
Training loss: 1.250110430607872
Validation loss: 2.6151930111219572

Epoch: 6| Step: 7
Training loss: 1.5131954895517001
Validation loss: 2.6132931829113515

Epoch: 6| Step: 8
Training loss: 1.7263886377128623
Validation loss: 2.6555942659781295

Epoch: 6| Step: 9
Training loss: 1.775671001994519
Validation loss: 2.651486478639058

Epoch: 6| Step: 10
Training loss: 1.849939206129686
Validation loss: 2.656132310724821

Epoch: 6| Step: 11
Training loss: 1.4833403344292742
Validation loss: 2.593503058378776

Epoch: 6| Step: 12
Training loss: 1.4490506056642325
Validation loss: 2.546663469913776

Epoch: 6| Step: 13
Training loss: 2.1239666389675866
Validation loss: 2.504927848310797

Epoch: 287| Step: 0
Training loss: 1.2141004048325355
Validation loss: 2.523296815925453

Epoch: 6| Step: 1
Training loss: 1.4285637446605572
Validation loss: 2.5612742996422386

Epoch: 6| Step: 2
Training loss: 1.5747281521112646
Validation loss: 2.62929127895175

Epoch: 6| Step: 3
Training loss: 1.805221214475935
Validation loss: 2.655342600459345

Epoch: 6| Step: 4
Training loss: 1.4950870483470218
Validation loss: 2.6546906412766553

Epoch: 6| Step: 5
Training loss: 1.713054931833229
Validation loss: 2.6515507408223264

Epoch: 6| Step: 6
Training loss: 1.5420490855952849
Validation loss: 2.592132513737914

Epoch: 6| Step: 7
Training loss: 1.2536788211291805
Validation loss: 2.5878675016243515

Epoch: 6| Step: 8
Training loss: 1.9036826683756354
Validation loss: 2.5740687903786608

Epoch: 6| Step: 9
Training loss: 1.3819107305012812
Validation loss: 2.5679081478364516

Epoch: 6| Step: 10
Training loss: 1.445467718913888
Validation loss: 2.6170446360248736

Epoch: 6| Step: 11
Training loss: 1.735421354814893
Validation loss: 2.644208483927281

Epoch: 6| Step: 12
Training loss: 2.1833373654549133
Validation loss: 2.660648204748305

Epoch: 6| Step: 13
Training loss: 0.9646896980638736
Validation loss: 2.6707832198942945

Epoch: 288| Step: 0
Training loss: 1.6992701730949213
Validation loss: 2.6293819084759127

Epoch: 6| Step: 1
Training loss: 1.6896174532843204
Validation loss: 2.600318343896316

Epoch: 6| Step: 2
Training loss: 1.5842096095691982
Validation loss: 2.5696343432043443

Epoch: 6| Step: 3
Training loss: 1.6267502235751294
Validation loss: 2.538580545604046

Epoch: 6| Step: 4
Training loss: 1.0301920347914113
Validation loss: 2.543626460068451

Epoch: 6| Step: 5
Training loss: 1.9270709750492319
Validation loss: 2.6003686181356698

Epoch: 6| Step: 6
Training loss: 1.4539799789928793
Validation loss: 2.6512861589766485

Epoch: 6| Step: 7
Training loss: 1.8470503799639246
Validation loss: 2.664611132491177

Epoch: 6| Step: 8
Training loss: 2.0007552866534013
Validation loss: 2.574409559330137

Epoch: 6| Step: 9
Training loss: 1.43188074864233
Validation loss: 2.527473512943267

Epoch: 6| Step: 10
Training loss: 1.2510573683406347
Validation loss: 2.477326008072513

Epoch: 6| Step: 11
Training loss: 1.7509056200334994
Validation loss: 2.4912100926300265

Epoch: 6| Step: 12
Training loss: 1.7420491390283188
Validation loss: 2.5158058605427676

Epoch: 6| Step: 13
Training loss: 1.1942391157478787
Validation loss: 2.536198386266834

Epoch: 289| Step: 0
Training loss: 1.7451747037335585
Validation loss: 2.577800524227972

Epoch: 6| Step: 1
Training loss: 1.5485222263040548
Validation loss: 2.614389382374534

Epoch: 6| Step: 2
Training loss: 1.5681761828234593
Validation loss: 2.613748972665846

Epoch: 6| Step: 3
Training loss: 2.018674332939685
Validation loss: 2.625304039937947

Epoch: 6| Step: 4
Training loss: 1.5071474496232962
Validation loss: 2.567293382482232

Epoch: 6| Step: 5
Training loss: 1.1541972109245164
Validation loss: 2.5614498917068236

Epoch: 6| Step: 6
Training loss: 1.7589232601669267
Validation loss: 2.5578130441971103

Epoch: 6| Step: 7
Training loss: 1.2950626256521196
Validation loss: 2.5731905045461696

Epoch: 6| Step: 8
Training loss: 1.257768902704254
Validation loss: 2.6173078993859775

Epoch: 6| Step: 9
Training loss: 1.565229854096447
Validation loss: 2.64673632585759

Epoch: 6| Step: 10
Training loss: 1.7329208876728157
Validation loss: 2.695960920301054

Epoch: 6| Step: 11
Training loss: 1.2748117812859212
Validation loss: 2.7118522507636857

Epoch: 6| Step: 12
Training loss: 1.9296146641626377
Validation loss: 2.707655388452716

Epoch: 6| Step: 13
Training loss: 1.2799838718500909
Validation loss: 2.703643092886136

Epoch: 290| Step: 0
Training loss: 1.3175499359743488
Validation loss: 2.6404971267563986

Epoch: 6| Step: 1
Training loss: 1.5459183325966315
Validation loss: 2.5768516898861757

Epoch: 6| Step: 2
Training loss: 1.5715179371503458
Validation loss: 2.487331237938569

Epoch: 6| Step: 3
Training loss: 1.9353356732139586
Validation loss: 2.4628807233501586

Epoch: 6| Step: 4
Training loss: 1.38364630954195
Validation loss: 2.429626765852379

Epoch: 6| Step: 5
Training loss: 1.5305815035464179
Validation loss: 2.4316673256586436

Epoch: 6| Step: 6
Training loss: 1.7998140265501394
Validation loss: 2.4646562872578537

Epoch: 6| Step: 7
Training loss: 1.5342221123689317
Validation loss: 2.4545292322745498

Epoch: 6| Step: 8
Training loss: 1.5138936329494108
Validation loss: 2.494803711959311

Epoch: 6| Step: 9
Training loss: 1.5735707049537906
Validation loss: 2.5394304815024777

Epoch: 6| Step: 10
Training loss: 1.9592661022728335
Validation loss: 2.5895509707943107

Epoch: 6| Step: 11
Training loss: 1.1834074572508888
Validation loss: 2.6171285163160247

Epoch: 6| Step: 12
Training loss: 1.378106249900128
Validation loss: 2.633332061598525

Epoch: 6| Step: 13
Training loss: 1.7491173561903497
Validation loss: 2.629069897607266

Epoch: 291| Step: 0
Training loss: 1.779560425519446
Validation loss: 2.596685661502768

Epoch: 6| Step: 1
Training loss: 1.466590429983384
Validation loss: 2.531544815936751

Epoch: 6| Step: 2
Training loss: 1.5467604777781385
Validation loss: 2.5064377378365905

Epoch: 6| Step: 3
Training loss: 1.6265209123056872
Validation loss: 2.5203723050282645

Epoch: 6| Step: 4
Training loss: 1.7380567084170713
Validation loss: 2.5512432688838076

Epoch: 6| Step: 5
Training loss: 1.8398288475129607
Validation loss: 2.591581967799157

Epoch: 6| Step: 6
Training loss: 1.454835766571792
Validation loss: 2.643967768615786

Epoch: 6| Step: 7
Training loss: 1.7545492442175914
Validation loss: 2.6248309651850006

Epoch: 6| Step: 8
Training loss: 1.2416319174459112
Validation loss: 2.6316507392615427

Epoch: 6| Step: 9
Training loss: 1.5821509045221243
Validation loss: 2.6422810180536525

Epoch: 6| Step: 10
Training loss: 1.4907164987436292
Validation loss: 2.673390682342223

Epoch: 6| Step: 11
Training loss: 1.3453314590447347
Validation loss: 2.7016850655777365

Epoch: 6| Step: 12
Training loss: 1.5252360364508923
Validation loss: 2.692975195476599

Epoch: 6| Step: 13
Training loss: 1.614237947335989
Validation loss: 2.6330608860427978

Epoch: 292| Step: 0
Training loss: 1.653798862695574
Validation loss: 2.6776112200028046

Epoch: 6| Step: 1
Training loss: 1.62836101380908
Validation loss: 2.6659113989846515

Epoch: 6| Step: 2
Training loss: 1.58153656183578
Validation loss: 2.6836312491357814

Epoch: 6| Step: 3
Training loss: 0.9587902486377683
Validation loss: 2.6315684626348292

Epoch: 6| Step: 4
Training loss: 1.787882919911673
Validation loss: 2.612114692029585

Epoch: 6| Step: 5
Training loss: 1.716681119555523
Validation loss: 2.572768282604396

Epoch: 6| Step: 6
Training loss: 1.0430037246154817
Validation loss: 2.5396438829111827

Epoch: 6| Step: 7
Training loss: 1.6840533627099201
Validation loss: 2.5342635817263215

Epoch: 6| Step: 8
Training loss: 1.8924736883836364
Validation loss: 2.566943371294644

Epoch: 6| Step: 9
Training loss: 0.9185722801994439
Validation loss: 2.6005204642167037

Epoch: 6| Step: 10
Training loss: 1.6984533932108064
Validation loss: 2.621505939389331

Epoch: 6| Step: 11
Training loss: 1.3658294908718935
Validation loss: 2.6840883990776754

Epoch: 6| Step: 12
Training loss: 1.3169659519877757
Validation loss: 2.7335674428239445

Epoch: 6| Step: 13
Training loss: 1.4952252210060506
Validation loss: 2.782418076151164

Epoch: 293| Step: 0
Training loss: 1.891256305812653
Validation loss: 2.7895418920576174

Epoch: 6| Step: 1
Training loss: 1.3221164545975204
Validation loss: 2.7830999309563023

Epoch: 6| Step: 2
Training loss: 1.6587711075889362
Validation loss: 2.7532149434615016

Epoch: 6| Step: 3
Training loss: 1.6137486258810443
Validation loss: 2.687995981254933

Epoch: 6| Step: 4
Training loss: 1.454431336299059
Validation loss: 2.6566487253737416

Epoch: 6| Step: 5
Training loss: 1.6455202730425842
Validation loss: 2.5576038922273776

Epoch: 6| Step: 6
Training loss: 1.5748158877103495
Validation loss: 2.5323733003818987

Epoch: 6| Step: 7
Training loss: 1.4814940754478765
Validation loss: 2.5225864972890992

Epoch: 6| Step: 8
Training loss: 1.6006401569523176
Validation loss: 2.546032738439249

Epoch: 6| Step: 9
Training loss: 1.750779387078577
Validation loss: 2.5571472362432397

Epoch: 6| Step: 10
Training loss: 1.4615448693856994
Validation loss: 2.5664911330242983

Epoch: 6| Step: 11
Training loss: 1.3146136385673455
Validation loss: 2.6314293644926825

Epoch: 6| Step: 12
Training loss: 1.684085145827433
Validation loss: 2.702548824229475

Epoch: 6| Step: 13
Training loss: 1.160747749768454
Validation loss: 2.734236338860134

Epoch: 294| Step: 0
Training loss: 1.2640453889157848
Validation loss: 2.7170917195325233

Epoch: 6| Step: 1
Training loss: 1.2670704628816443
Validation loss: 2.6914952870631503

Epoch: 6| Step: 2
Training loss: 2.173263435331894
Validation loss: 2.6471964998639046

Epoch: 6| Step: 3
Training loss: 1.5200225898670239
Validation loss: 2.5927452496670575

Epoch: 6| Step: 4
Training loss: 1.4724794478998016
Validation loss: 2.5870955227325703

Epoch: 6| Step: 5
Training loss: 1.5659054076758834
Validation loss: 2.5438516209973723

Epoch: 6| Step: 6
Training loss: 1.402883866624124
Validation loss: 2.5567055444402897

Epoch: 6| Step: 7
Training loss: 1.466475734781771
Validation loss: 2.5416690827076964

Epoch: 6| Step: 8
Training loss: 1.4644327222817712
Validation loss: 2.516466174757079

Epoch: 6| Step: 9
Training loss: 1.4444425696988452
Validation loss: 2.51552471882521

Epoch: 6| Step: 10
Training loss: 1.5060073245504921
Validation loss: 2.528466221596966

Epoch: 6| Step: 11
Training loss: 1.5314260887571192
Validation loss: 2.5671487994111755

Epoch: 6| Step: 12
Training loss: 1.5497271512976851
Validation loss: 2.6551866356105664

Epoch: 6| Step: 13
Training loss: 1.3757531964172907
Validation loss: 2.7169131083854574

Epoch: 295| Step: 0
Training loss: 1.3999590986952848
Validation loss: 2.760178954897804

Epoch: 6| Step: 1
Training loss: 1.4666824397770604
Validation loss: 2.733157277183588

Epoch: 6| Step: 2
Training loss: 1.3505658570932437
Validation loss: 2.642945547308397

Epoch: 6| Step: 3
Training loss: 1.3177121078175802
Validation loss: 2.5809952048579103

Epoch: 6| Step: 4
Training loss: 0.8832653538319309
Validation loss: 2.5831513659972845

Epoch: 6| Step: 5
Training loss: 2.007652662275352
Validation loss: 2.561044495224376

Epoch: 6| Step: 6
Training loss: 1.6939145138506149
Validation loss: 2.565392539155047

Epoch: 6| Step: 7
Training loss: 1.7377368546011889
Validation loss: 2.5842125759574537

Epoch: 6| Step: 8
Training loss: 1.4531008810687385
Validation loss: 2.6047834930033296

Epoch: 6| Step: 9
Training loss: 1.374088852442941
Validation loss: 2.677237654226115

Epoch: 6| Step: 10
Training loss: 1.4137982284859663
Validation loss: 2.6799630117611204

Epoch: 6| Step: 11
Training loss: 1.2306098493783575
Validation loss: 2.7062126117109058

Epoch: 6| Step: 12
Training loss: 1.8140408773390369
Validation loss: 2.6657518614183293

Epoch: 6| Step: 13
Training loss: 1.2857695162732943
Validation loss: 2.5696057957883216

Epoch: 296| Step: 0
Training loss: 1.066954810493201
Validation loss: 2.5426222062261643

Epoch: 6| Step: 1
Training loss: 1.4912622589093483
Validation loss: 2.4799268850755314

Epoch: 6| Step: 2
Training loss: 1.426627965889447
Validation loss: 2.4846356735567188

Epoch: 6| Step: 3
Training loss: 1.6272560744307734
Validation loss: 2.517364587344121

Epoch: 6| Step: 4
Training loss: 1.1890192853616437
Validation loss: 2.5850500786156236

Epoch: 6| Step: 5
Training loss: 1.3789549216522985
Validation loss: 2.6181873354265073

Epoch: 6| Step: 6
Training loss: 1.368313353056161
Validation loss: 2.6632986638784035

Epoch: 6| Step: 7
Training loss: 1.6022465431341557
Validation loss: 2.642674838261466

Epoch: 6| Step: 8
Training loss: 2.069100078915025
Validation loss: 2.6255621066544546

Epoch: 6| Step: 9
Training loss: 1.2401321969782317
Validation loss: 2.615039028932985

Epoch: 6| Step: 10
Training loss: 1.2298738525025474
Validation loss: 2.5988176607664606

Epoch: 6| Step: 11
Training loss: 1.755434725354859
Validation loss: 2.604939837622822

Epoch: 6| Step: 12
Training loss: 1.6595355859557417
Validation loss: 2.5767050645386607

Epoch: 6| Step: 13
Training loss: 1.2326624615822577
Validation loss: 2.580091006375146

Epoch: 297| Step: 0
Training loss: 1.2337559463527734
Validation loss: 2.568176848966975

Epoch: 6| Step: 1
Training loss: 1.0717224524134124
Validation loss: 2.5979980559681355

Epoch: 6| Step: 2
Training loss: 1.6291993972859624
Validation loss: 2.611609742040627

Epoch: 6| Step: 3
Training loss: 1.3834207780998011
Validation loss: 2.6216115489442826

Epoch: 6| Step: 4
Training loss: 1.029826308577183
Validation loss: 2.639722469501845

Epoch: 6| Step: 5
Training loss: 1.532348783540593
Validation loss: 2.6383738365041873

Epoch: 6| Step: 6
Training loss: 1.7355229470756213
Validation loss: 2.665403792564605

Epoch: 6| Step: 7
Training loss: 1.374466228918099
Validation loss: 2.686549989640651

Epoch: 6| Step: 8
Training loss: 1.7447551059213644
Validation loss: 2.668610726207699

Epoch: 6| Step: 9
Training loss: 1.481440645335018
Validation loss: 2.5982629304872202

Epoch: 6| Step: 10
Training loss: 1.41231158696271
Validation loss: 2.568186538303945

Epoch: 6| Step: 11
Training loss: 1.1185409243979039
Validation loss: 2.540683111893397

Epoch: 6| Step: 12
Training loss: 1.7938756705997838
Validation loss: 2.5297643144278434

Epoch: 6| Step: 13
Training loss: 0.6192973326672571
Validation loss: 2.514915175085409

Epoch: 298| Step: 0
Training loss: 1.3562556024954264
Validation loss: 2.5188888525781175

Epoch: 6| Step: 1
Training loss: 1.7834047368570982
Validation loss: 2.4893589056776064

Epoch: 6| Step: 2
Training loss: 1.7213036726462811
Validation loss: 2.5287010153308795

Epoch: 6| Step: 3
Training loss: 1.4388955018338732
Validation loss: 2.564900010419698

Epoch: 6| Step: 4
Training loss: 0.8361580103298841
Validation loss: 2.6158413584890075

Epoch: 6| Step: 5
Training loss: 1.6791800508683554
Validation loss: 2.6567204000371607

Epoch: 6| Step: 6
Training loss: 1.1254482435937152
Validation loss: 2.64912434538734

Epoch: 6| Step: 7
Training loss: 1.1577993786025838
Validation loss: 2.6428681173938866

Epoch: 6| Step: 8
Training loss: 0.9534123722292339
Validation loss: 2.668683797221653

Epoch: 6| Step: 9
Training loss: 1.7886671270743588
Validation loss: 2.6401908387988353

Epoch: 6| Step: 10
Training loss: 1.5755387822749762
Validation loss: 2.6236560328515663

Epoch: 6| Step: 11
Training loss: 1.2739314893928748
Validation loss: 2.6153183064894083

Epoch: 6| Step: 12
Training loss: 1.3572052926924694
Validation loss: 2.6275694636156803

Epoch: 6| Step: 13
Training loss: 1.2558581884684081
Validation loss: 2.6073515274140036

Epoch: 299| Step: 0
Training loss: 0.8876724156279364
Validation loss: 2.626968125498991

Epoch: 6| Step: 1
Training loss: 1.7885328283371125
Validation loss: 2.637456520257556

Epoch: 6| Step: 2
Training loss: 1.360376011395291
Validation loss: 2.639736064017793

Epoch: 6| Step: 3
Training loss: 1.2284015062755813
Validation loss: 2.6649250013669383

Epoch: 6| Step: 4
Training loss: 1.6627085734156373
Validation loss: 2.6891769076811856

Epoch: 6| Step: 5
Training loss: 1.2459157499697338
Validation loss: 2.6671489912601007

Epoch: 6| Step: 6
Training loss: 1.2306696167738642
Validation loss: 2.6471573457031075

Epoch: 6| Step: 7
Training loss: 1.6691525834483423
Validation loss: 2.610239725786369

Epoch: 6| Step: 8
Training loss: 1.013372417457483
Validation loss: 2.5765636012887887

Epoch: 6| Step: 9
Training loss: 1.1645984312021707
Validation loss: 2.5884400153394953

Epoch: 6| Step: 10
Training loss: 1.5457479821811557
Validation loss: 2.600602183325643

Epoch: 6| Step: 11
Training loss: 1.5608745512617634
Validation loss: 2.566752814706436

Epoch: 6| Step: 12
Training loss: 1.350090151001969
Validation loss: 2.583827880086966

Epoch: 6| Step: 13
Training loss: 1.436951159316866
Validation loss: 2.604537617176668

Epoch: 300| Step: 0
Training loss: 1.463098406837216
Validation loss: 2.5435861046990857

Epoch: 6| Step: 1
Training loss: 1.4407514206367782
Validation loss: 2.516387246148743

Epoch: 6| Step: 2
Training loss: 1.113393998710859
Validation loss: 2.5190985597202427

Epoch: 6| Step: 3
Training loss: 1.5012256859836093
Validation loss: 2.528992024957191

Epoch: 6| Step: 4
Training loss: 1.8762638283155795
Validation loss: 2.551557906112603

Epoch: 6| Step: 5
Training loss: 1.8024783133420383
Validation loss: 2.565019846749884

Epoch: 6| Step: 6
Training loss: 1.3805177689610428
Validation loss: 2.591477243558376

Epoch: 6| Step: 7
Training loss: 1.4671414271586622
Validation loss: 2.61751167837672

Epoch: 6| Step: 8
Training loss: 1.0906744631505711
Validation loss: 2.6138235283335978

Epoch: 6| Step: 9
Training loss: 0.48135022197340643
Validation loss: 2.608327436107941

Epoch: 6| Step: 10
Training loss: 1.413303150283562
Validation loss: 2.595040982655597

Epoch: 6| Step: 11
Training loss: 1.4460833169405183
Validation loss: 2.5995269008139146

Epoch: 6| Step: 12
Training loss: 1.3158971328359723
Validation loss: 2.5815833022769237

Epoch: 6| Step: 13
Training loss: 1.271118298875572
Validation loss: 2.570625853348601

Epoch: 301| Step: 0
Training loss: 1.062936917397077
Validation loss: 2.534621857211467

Epoch: 6| Step: 1
Training loss: 1.1037960270133647
Validation loss: 2.523718536828833

Epoch: 6| Step: 2
Training loss: 1.3436039690023243
Validation loss: 2.5360811597464252

Epoch: 6| Step: 3
Training loss: 1.2946716803362956
Validation loss: 2.5127978633659387

Epoch: 6| Step: 4
Training loss: 1.292188610736042
Validation loss: 2.5381331476622457

Epoch: 6| Step: 5
Training loss: 2.108617123689459
Validation loss: 2.5527442640510065

Epoch: 6| Step: 6
Training loss: 1.189082446538821
Validation loss: 2.560903605677331

Epoch: 6| Step: 7
Training loss: 1.4151576738159795
Validation loss: 2.600218031097292

Epoch: 6| Step: 8
Training loss: 1.3445537735927104
Validation loss: 2.59742088611678

Epoch: 6| Step: 9
Training loss: 1.1735926945813262
Validation loss: 2.6189432738386405

Epoch: 6| Step: 10
Training loss: 1.3139762296718458
Validation loss: 2.651386859266131

Epoch: 6| Step: 11
Training loss: 1.3541309449790675
Validation loss: 2.6499493472396667

Epoch: 6| Step: 12
Training loss: 1.344534534049138
Validation loss: 2.628811987030287

Epoch: 6| Step: 13
Training loss: 1.4109300091482309
Validation loss: 2.6114501247226847

Epoch: 302| Step: 0
Training loss: 1.729219489458932
Validation loss: 2.6178136628423085

Epoch: 6| Step: 1
Training loss: 1.5291204630898962
Validation loss: 2.663566567493144

Epoch: 6| Step: 2
Training loss: 1.369654364527766
Validation loss: 2.659757875981614

Epoch: 6| Step: 3
Training loss: 0.9153643735159158
Validation loss: 2.621195924164067

Epoch: 6| Step: 4
Training loss: 1.3415990958563908
Validation loss: 2.5951057762230287

Epoch: 6| Step: 5
Training loss: 1.2422422960779096
Validation loss: 2.581661310120921

Epoch: 6| Step: 6
Training loss: 1.274214104059802
Validation loss: 2.55015200645042

Epoch: 6| Step: 7
Training loss: 1.6740214037056687
Validation loss: 2.550762432541362

Epoch: 6| Step: 8
Training loss: 1.5225180957138484
Validation loss: 2.5307937711241486

Epoch: 6| Step: 9
Training loss: 1.4446053089325788
Validation loss: 2.532043986771242

Epoch: 6| Step: 10
Training loss: 1.0855871499885843
Validation loss: 2.6028277066187138

Epoch: 6| Step: 11
Training loss: 0.9308170220924712
Validation loss: 2.618133426874455

Epoch: 6| Step: 12
Training loss: 1.0524003838448892
Validation loss: 2.6964792411811076

Epoch: 6| Step: 13
Training loss: 1.395352162035596
Validation loss: 2.7046069847773655

Epoch: 303| Step: 0
Training loss: 1.1234980199479776
Validation loss: 2.7799546683200824

Epoch: 6| Step: 1
Training loss: 1.3593229086530594
Validation loss: 2.7815839957045356

Epoch: 6| Step: 2
Training loss: 1.0523172943029584
Validation loss: 2.757345666758758

Epoch: 6| Step: 3
Training loss: 1.0797297379751432
Validation loss: 2.755476686004699

Epoch: 6| Step: 4
Training loss: 1.3599411235014032
Validation loss: 2.724560027040027

Epoch: 6| Step: 5
Training loss: 1.2437449833754386
Validation loss: 2.6263462551229866

Epoch: 6| Step: 6
Training loss: 1.5035887544071886
Validation loss: 2.5252654076754464

Epoch: 6| Step: 7
Training loss: 1.8973539423360548
Validation loss: 2.479998058191969

Epoch: 6| Step: 8
Training loss: 1.3591591674641461
Validation loss: 2.4458227232376424

Epoch: 6| Step: 9
Training loss: 1.8012061290176689
Validation loss: 2.4451328685875056

Epoch: 6| Step: 10
Training loss: 1.2186570743444824
Validation loss: 2.436197093056895

Epoch: 6| Step: 11
Training loss: 1.179493465002827
Validation loss: 2.4316449359648518

Epoch: 6| Step: 12
Training loss: 1.6146506346755343
Validation loss: 2.461234380260769

Epoch: 6| Step: 13
Training loss: 0.9229436596323694
Validation loss: 2.4900486379512703

Epoch: 304| Step: 0
Training loss: 1.2996077184090407
Validation loss: 2.5567014814459683

Epoch: 6| Step: 1
Training loss: 1.1417127152133741
Validation loss: 2.6643528038995625

Epoch: 6| Step: 2
Training loss: 1.386463668358233
Validation loss: 2.750020443792786

Epoch: 6| Step: 3
Training loss: 2.0723153269251724
Validation loss: 2.7945802814260983

Epoch: 6| Step: 4
Training loss: 1.132250152968592
Validation loss: 2.7906471990438155

Epoch: 6| Step: 5
Training loss: 1.1116603897657198
Validation loss: 2.736436060186074

Epoch: 6| Step: 6
Training loss: 1.1102127887629032
Validation loss: 2.6826460211889525

Epoch: 6| Step: 7
Training loss: 1.0202441299221001
Validation loss: 2.659942201533397

Epoch: 6| Step: 8
Training loss: 1.5078156624400125
Validation loss: 2.6080529145921645

Epoch: 6| Step: 9
Training loss: 1.1822935207985388
Validation loss: 2.539828697188725

Epoch: 6| Step: 10
Training loss: 1.1703025440561636
Validation loss: 2.5006785569120455

Epoch: 6| Step: 11
Training loss: 1.528982234854124
Validation loss: 2.5152347480844957

Epoch: 6| Step: 12
Training loss: 1.2945942413898583
Validation loss: 2.5098946829086177

Epoch: 6| Step: 13
Training loss: 1.1403204628940005
Validation loss: 2.522287952001867

Epoch: 305| Step: 0
Training loss: 1.3117144822578912
Validation loss: 2.5663200695215806

Epoch: 6| Step: 1
Training loss: 0.963553210352576
Validation loss: 2.6350915090437064

Epoch: 6| Step: 2
Training loss: 1.3663942488093694
Validation loss: 2.6832573224201446

Epoch: 6| Step: 3
Training loss: 2.0828461904011664
Validation loss: 2.755977849206714

Epoch: 6| Step: 4
Training loss: 1.1092650667980937
Validation loss: 2.828149593620034

Epoch: 6| Step: 5
Training loss: 1.3593482968568664
Validation loss: 2.831087873630867

Epoch: 6| Step: 6
Training loss: 1.243495708137594
Validation loss: 2.8169804242182575

Epoch: 6| Step: 7
Training loss: 1.3339648489688951
Validation loss: 2.798030744408375

Epoch: 6| Step: 8
Training loss: 0.9674147355904354
Validation loss: 2.712070762636363

Epoch: 6| Step: 9
Training loss: 1.157513211959676
Validation loss: 2.6331087475645973

Epoch: 6| Step: 10
Training loss: 1.106057970438549
Validation loss: 2.569895937259488

Epoch: 6| Step: 11
Training loss: 1.5094500726388902
Validation loss: 2.5369093935811415

Epoch: 6| Step: 12
Training loss: 1.2649099896942066
Validation loss: 2.503464491701881

Epoch: 6| Step: 13
Training loss: 1.1051656893965207
Validation loss: 2.49045328585952

Epoch: 306| Step: 0
Training loss: 0.9380334607929505
Validation loss: 2.495379125447264

Epoch: 6| Step: 1
Training loss: 1.4807455564010699
Validation loss: 2.491223247253885

Epoch: 6| Step: 2
Training loss: 1.0818863644325332
Validation loss: 2.533792707176796

Epoch: 6| Step: 3
Training loss: 1.334249713027806
Validation loss: 2.595878219677291

Epoch: 6| Step: 4
Training loss: 1.4192618366854572
Validation loss: 2.6289604759331584

Epoch: 6| Step: 5
Training loss: 1.6968355852189632
Validation loss: 2.7040101740126836

Epoch: 6| Step: 6
Training loss: 1.2111396866867687
Validation loss: 2.7589819661108845

Epoch: 6| Step: 7
Training loss: 1.1482111908981765
Validation loss: 2.761409933886766

Epoch: 6| Step: 8
Training loss: 1.0962312075179688
Validation loss: 2.7383468297314044

Epoch: 6| Step: 9
Training loss: 1.5287476158591369
Validation loss: 2.738956531463504

Epoch: 6| Step: 10
Training loss: 1.6795777750771053
Validation loss: 2.7103318185616105

Epoch: 6| Step: 11
Training loss: 1.2918130832666928
Validation loss: 2.6641732864264025

Epoch: 6| Step: 12
Training loss: 0.8743283895921671
Validation loss: 2.6006424238381687

Epoch: 6| Step: 13
Training loss: 0.7030604650763187
Validation loss: 2.5918411899102285

Epoch: 307| Step: 0
Training loss: 1.5237163581920907
Validation loss: 2.5830847054544117

Epoch: 6| Step: 1
Training loss: 1.4267244746329697
Validation loss: 2.5764773655411326

Epoch: 6| Step: 2
Training loss: 1.1712201132365778
Validation loss: 2.558109525004667

Epoch: 6| Step: 3
Training loss: 1.7023356997267634
Validation loss: 2.600656957035018

Epoch: 6| Step: 4
Training loss: 1.0629273845312186
Validation loss: 2.6404462864168097

Epoch: 6| Step: 5
Training loss: 1.0512207700314815
Validation loss: 2.679807177818712

Epoch: 6| Step: 6
Training loss: 1.1858787512017743
Validation loss: 2.7135940920502857

Epoch: 6| Step: 7
Training loss: 1.455946940702382
Validation loss: 2.7187820279926176

Epoch: 6| Step: 8
Training loss: 1.3938352413368933
Validation loss: 2.7110612498273103

Epoch: 6| Step: 9
Training loss: 1.072596431211687
Validation loss: 2.6763528537722396

Epoch: 6| Step: 10
Training loss: 1.3125923669193518
Validation loss: 2.6499395268390096

Epoch: 6| Step: 11
Training loss: 1.0475519752809008
Validation loss: 2.5993239576136666

Epoch: 6| Step: 12
Training loss: 1.0306720848270077
Validation loss: 2.58324424545052

Epoch: 6| Step: 13
Training loss: 1.3427047212530914
Validation loss: 2.556680615883032

Epoch: 308| Step: 0
Training loss: 1.1588082750927617
Validation loss: 2.5492189272370496

Epoch: 6| Step: 1
Training loss: 1.1839988191605169
Validation loss: 2.570724380994438

Epoch: 6| Step: 2
Training loss: 1.2255596750796742
Validation loss: 2.579850621606212

Epoch: 6| Step: 3
Training loss: 1.1847398201093962
Validation loss: 2.6066079424368795

Epoch: 6| Step: 4
Training loss: 1.3516245480445552
Validation loss: 2.6159441856649797

Epoch: 6| Step: 5
Training loss: 1.2192730881470377
Validation loss: 2.6573364323375674

Epoch: 6| Step: 6
Training loss: 1.2954490819691098
Validation loss: 2.6698307031058794

Epoch: 6| Step: 7
Training loss: 1.3840466611554079
Validation loss: 2.678570558632799

Epoch: 6| Step: 8
Training loss: 0.8962200498165482
Validation loss: 2.6865890401342805

Epoch: 6| Step: 9
Training loss: 1.257178531835677
Validation loss: 2.6697399486915105

Epoch: 6| Step: 10
Training loss: 0.8903627846182616
Validation loss: 2.6764441205415803

Epoch: 6| Step: 11
Training loss: 1.3487363163746233
Validation loss: 2.6792507470444002

Epoch: 6| Step: 12
Training loss: 1.7035743750483603
Validation loss: 2.681116337447694

Epoch: 6| Step: 13
Training loss: 1.2055320935717937
Validation loss: 2.680521488655087

Epoch: 309| Step: 0
Training loss: 1.2095986132434686
Validation loss: 2.660779049282315

Epoch: 6| Step: 1
Training loss: 1.3027547808969193
Validation loss: 2.6385902244049344

Epoch: 6| Step: 2
Training loss: 1.0911339127186082
Validation loss: 2.6290620781632694

Epoch: 6| Step: 3
Training loss: 1.281855044904753
Validation loss: 2.6456716880677766

Epoch: 6| Step: 4
Training loss: 1.0716553221043281
Validation loss: 2.626332100305067

Epoch: 6| Step: 5
Training loss: 0.9205201424773124
Validation loss: 2.6229436841248943

Epoch: 6| Step: 6
Training loss: 1.7570168962312138
Validation loss: 2.551214704592212

Epoch: 6| Step: 7
Training loss: 1.2234749779740146
Validation loss: 2.568987464971696

Epoch: 6| Step: 8
Training loss: 1.4497466655284348
Validation loss: 2.5408114396123733

Epoch: 6| Step: 9
Training loss: 0.9360067236874837
Validation loss: 2.550736292094059

Epoch: 6| Step: 10
Training loss: 1.4915402591500933
Validation loss: 2.538855381951248

Epoch: 6| Step: 11
Training loss: 0.9608961577167245
Validation loss: 2.5490488287081834

Epoch: 6| Step: 12
Training loss: 1.4344089279650112
Validation loss: 2.6049233467313

Epoch: 6| Step: 13
Training loss: 1.1642636630956473
Validation loss: 2.6596215948757003

Epoch: 310| Step: 0
Training loss: 1.218561989391991
Validation loss: 2.702283487492128

Epoch: 6| Step: 1
Training loss: 1.1781887613947124
Validation loss: 2.690672480287516

Epoch: 6| Step: 2
Training loss: 1.4803576264157936
Validation loss: 2.701930628009696

Epoch: 6| Step: 3
Training loss: 0.9567627510694351
Validation loss: 2.6443838564743434

Epoch: 6| Step: 4
Training loss: 1.1864811391315981
Validation loss: 2.650189695787575

Epoch: 6| Step: 5
Training loss: 1.118501384111826
Validation loss: 2.6313843533000574

Epoch: 6| Step: 6
Training loss: 1.3155968325537655
Validation loss: 2.5952287282091806

Epoch: 6| Step: 7
Training loss: 1.3628091076531161
Validation loss: 2.5825100237465386

Epoch: 6| Step: 8
Training loss: 1.2634690371041735
Validation loss: 2.5646338793416743

Epoch: 6| Step: 9
Training loss: 1.2008838339216923
Validation loss: 2.5828182952146648

Epoch: 6| Step: 10
Training loss: 1.470304437629413
Validation loss: 2.604066202174185

Epoch: 6| Step: 11
Training loss: 1.1833409709863032
Validation loss: 2.6209397075785037

Epoch: 6| Step: 12
Training loss: 0.8700873886811344
Validation loss: 2.6346499963636694

Epoch: 6| Step: 13
Training loss: 1.7595623207990552
Validation loss: 2.6118581374503025

Epoch: 311| Step: 0
Training loss: 1.254972533347193
Validation loss: 2.6389027339512383

Epoch: 6| Step: 1
Training loss: 1.18819788452895
Validation loss: 2.618145845866066

Epoch: 6| Step: 2
Training loss: 1.263332692869992
Validation loss: 2.601175614688897

Epoch: 6| Step: 3
Training loss: 1.252277397734897
Validation loss: 2.6005368287488175

Epoch: 6| Step: 4
Training loss: 1.1702113740671096
Validation loss: 2.585536520101414

Epoch: 6| Step: 5
Training loss: 1.4869575120336773
Validation loss: 2.563584002124792

Epoch: 6| Step: 6
Training loss: 1.4497534081816472
Validation loss: 2.5635623205541407

Epoch: 6| Step: 7
Training loss: 1.1471669441362102
Validation loss: 2.553034350608325

Epoch: 6| Step: 8
Training loss: 0.9350892542500964
Validation loss: 2.556950977631076

Epoch: 6| Step: 9
Training loss: 0.9084449364115363
Validation loss: 2.587814779317527

Epoch: 6| Step: 10
Training loss: 1.0204661675675903
Validation loss: 2.616195482377879

Epoch: 6| Step: 11
Training loss: 0.8643653931983767
Validation loss: 2.6076393222658734

Epoch: 6| Step: 12
Training loss: 1.4117008953305927
Validation loss: 2.6356326070716483

Epoch: 6| Step: 13
Training loss: 1.8908290280051692
Validation loss: 2.6337455059595856

Epoch: 312| Step: 0
Training loss: 1.1625308001960288
Validation loss: 2.634521686170643

Epoch: 6| Step: 1
Training loss: 1.1173967285569921
Validation loss: 2.6410687529971186

Epoch: 6| Step: 2
Training loss: 1.11853666136151
Validation loss: 2.6414139703585975

Epoch: 6| Step: 3
Training loss: 1.1424664825931994
Validation loss: 2.6089232197779593

Epoch: 6| Step: 4
Training loss: 1.223531001818711
Validation loss: 2.5944640363702263

Epoch: 6| Step: 5
Training loss: 1.5776834908969322
Validation loss: 2.588513227080279

Epoch: 6| Step: 6
Training loss: 0.9810946772887369
Validation loss: 2.5639148550843998

Epoch: 6| Step: 7
Training loss: 1.2280075890713515
Validation loss: 2.5981513785829846

Epoch: 6| Step: 8
Training loss: 1.4539679266686063
Validation loss: 2.601902444930559

Epoch: 6| Step: 9
Training loss: 0.9342172687299934
Validation loss: 2.6238731298698688

Epoch: 6| Step: 10
Training loss: 1.1450058926093383
Validation loss: 2.6351545259341598

Epoch: 6| Step: 11
Training loss: 1.412130141995896
Validation loss: 2.659226594972704

Epoch: 6| Step: 12
Training loss: 1.0241758289553278
Validation loss: 2.6469587134283006

Epoch: 6| Step: 13
Training loss: 1.207805644382301
Validation loss: 2.6527931376005043

Epoch: 313| Step: 0
Training loss: 1.391080117491451
Validation loss: 2.642760817184672

Epoch: 6| Step: 1
Training loss: 1.4291876247341058
Validation loss: 2.65027099821104

Epoch: 6| Step: 2
Training loss: 1.0600211454477626
Validation loss: 2.5990830869771404

Epoch: 6| Step: 3
Training loss: 1.076484648570707
Validation loss: 2.605170516600475

Epoch: 6| Step: 4
Training loss: 1.1535092941094947
Validation loss: 2.5532004032228133

Epoch: 6| Step: 5
Training loss: 1.3732706812730655
Validation loss: 2.5222925247584214

Epoch: 6| Step: 6
Training loss: 1.350808567280552
Validation loss: 2.528565478529561

Epoch: 6| Step: 7
Training loss: 1.1308417705951088
Validation loss: 2.5230196791655053

Epoch: 6| Step: 8
Training loss: 1.647213811604537
Validation loss: 2.510619240652849

Epoch: 6| Step: 9
Training loss: 1.0104969556442676
Validation loss: 2.53962982528738

Epoch: 6| Step: 10
Training loss: 1.0646237857744942
Validation loss: 2.5452077997727676

Epoch: 6| Step: 11
Training loss: 1.0019207627570905
Validation loss: 2.601461256612473

Epoch: 6| Step: 12
Training loss: 1.0021705911968597
Validation loss: 2.6539183853272217

Epoch: 6| Step: 13
Training loss: 0.7237881430686419
Validation loss: 2.6409783541655907

Epoch: 314| Step: 0
Training loss: 0.6165712394423658
Validation loss: 2.698746320880457

Epoch: 6| Step: 1
Training loss: 1.594022390986114
Validation loss: 2.664216660648114

Epoch: 6| Step: 2
Training loss: 1.321322263764309
Validation loss: 2.6561261456427965

Epoch: 6| Step: 3
Training loss: 1.2834523509104243
Validation loss: 2.6218570639240886

Epoch: 6| Step: 4
Training loss: 1.0770103110100537
Validation loss: 2.6314098991290904

Epoch: 6| Step: 5
Training loss: 0.9558623357118212
Validation loss: 2.6205875141436508

Epoch: 6| Step: 6
Training loss: 1.3863575639605956
Validation loss: 2.62825417764418

Epoch: 6| Step: 7
Training loss: 1.1097946984934917
Validation loss: 2.6264653605844765

Epoch: 6| Step: 8
Training loss: 0.7785633430461081
Validation loss: 2.6206654918174874

Epoch: 6| Step: 9
Training loss: 1.3149049161033048
Validation loss: 2.6553100901536824

Epoch: 6| Step: 10
Training loss: 1.0968274011092614
Validation loss: 2.6257892638969715

Epoch: 6| Step: 11
Training loss: 1.3296548895417515
Validation loss: 2.6391513783146885

Epoch: 6| Step: 12
Training loss: 1.3050691880048875
Validation loss: 2.612384828969918

Epoch: 6| Step: 13
Training loss: 1.1898150214511038
Validation loss: 2.628154260491193

Epoch: 315| Step: 0
Training loss: 1.1618137528568033
Validation loss: 2.6049649996493836

Epoch: 6| Step: 1
Training loss: 1.3227596740484253
Validation loss: 2.6115351320073232

Epoch: 6| Step: 2
Training loss: 1.2473018613498181
Validation loss: 2.626829029693918

Epoch: 6| Step: 3
Training loss: 1.5589010370738396
Validation loss: 2.6464482229928676

Epoch: 6| Step: 4
Training loss: 1.2511686107677475
Validation loss: 2.672439467115625

Epoch: 6| Step: 5
Training loss: 0.7573719513814928
Validation loss: 2.6948946892485246

Epoch: 6| Step: 6
Training loss: 1.0057012044745595
Validation loss: 2.6985254788979582

Epoch: 6| Step: 7
Training loss: 1.1377454492875692
Validation loss: 2.6504573937693747

Epoch: 6| Step: 8
Training loss: 1.0261850531188947
Validation loss: 2.642748281049622

Epoch: 6| Step: 9
Training loss: 1.2336010981625372
Validation loss: 2.6197898419655026

Epoch: 6| Step: 10
Training loss: 1.02150730668945
Validation loss: 2.5799606922627842

Epoch: 6| Step: 11
Training loss: 0.9815385309236123
Validation loss: 2.5731503169348544

Epoch: 6| Step: 12
Training loss: 1.332638509826624
Validation loss: 2.5538485387754513

Epoch: 6| Step: 13
Training loss: 1.2771138675559572
Validation loss: 2.562829052287067

Epoch: 316| Step: 0
Training loss: 1.0780236016841023
Validation loss: 2.571769545987366

Epoch: 6| Step: 1
Training loss: 1.4509258241366463
Validation loss: 2.5811898895473493

Epoch: 6| Step: 2
Training loss: 1.0175422764648703
Validation loss: 2.5883303092342644

Epoch: 6| Step: 3
Training loss: 0.950921936409234
Validation loss: 2.630173546703077

Epoch: 6| Step: 4
Training loss: 1.1681728631220492
Validation loss: 2.5944706804775715

Epoch: 6| Step: 5
Training loss: 1.0817215128445528
Validation loss: 2.5963217682181443

Epoch: 6| Step: 6
Training loss: 0.8790880481466848
Validation loss: 2.582380963431838

Epoch: 6| Step: 7
Training loss: 0.9065125841339304
Validation loss: 2.621841469991451

Epoch: 6| Step: 8
Training loss: 1.7244751339051763
Validation loss: 2.6031571181652065

Epoch: 6| Step: 9
Training loss: 1.1106193977691232
Validation loss: 2.6183709774884494

Epoch: 6| Step: 10
Training loss: 0.9479298258835683
Validation loss: 2.6758116921948503

Epoch: 6| Step: 11
Training loss: 1.2522641656995501
Validation loss: 2.7201149163621

Epoch: 6| Step: 12
Training loss: 1.3434340526947421
Validation loss: 2.723739127376332

Epoch: 6| Step: 13
Training loss: 0.9843995530230155
Validation loss: 2.6881255547185128

Epoch: 317| Step: 0
Training loss: 1.3822304314180125
Validation loss: 2.6716037524526177

Epoch: 6| Step: 1
Training loss: 0.8328558189476911
Validation loss: 2.620322422983233

Epoch: 6| Step: 2
Training loss: 1.121229422730244
Validation loss: 2.5892418474213246

Epoch: 6| Step: 3
Training loss: 1.0999224743833655
Validation loss: 2.5587224621567883

Epoch: 6| Step: 4
Training loss: 1.3839498034839386
Validation loss: 2.5412533580531727

Epoch: 6| Step: 5
Training loss: 0.9696922027247654
Validation loss: 2.5165433925053438

Epoch: 6| Step: 6
Training loss: 0.7884569771833334
Validation loss: 2.51070150880859

Epoch: 6| Step: 7
Training loss: 1.2158719829319138
Validation loss: 2.510629323160143

Epoch: 6| Step: 8
Training loss: 1.09447487924884
Validation loss: 2.5280452232236934

Epoch: 6| Step: 9
Training loss: 0.9609704360899983
Validation loss: 2.54508381833572

Epoch: 6| Step: 10
Training loss: 1.0103418119304053
Validation loss: 2.5708153779404723

Epoch: 6| Step: 11
Training loss: 1.0952895092693988
Validation loss: 2.5841829931738887

Epoch: 6| Step: 12
Training loss: 1.7134855622572982
Validation loss: 2.655783101789193

Epoch: 6| Step: 13
Training loss: 1.0508160780342803
Validation loss: 2.7009538766553507

Epoch: 318| Step: 0
Training loss: 1.3205080508268716
Validation loss: 2.7414074935318546

Epoch: 6| Step: 1
Training loss: 0.9679120346584706
Validation loss: 2.692951231344673

Epoch: 6| Step: 2
Training loss: 1.5002020064071626
Validation loss: 2.6234099831229094

Epoch: 6| Step: 3
Training loss: 1.2250619931007583
Validation loss: 2.5618111349536443

Epoch: 6| Step: 4
Training loss: 0.9996011952061432
Validation loss: 2.5174910062026474

Epoch: 6| Step: 5
Training loss: 1.5235566703940557
Validation loss: 2.502280167590208

Epoch: 6| Step: 6
Training loss: 1.053980272322006
Validation loss: 2.532314037398432

Epoch: 6| Step: 7
Training loss: 0.7634358931722451
Validation loss: 2.5509198454573125

Epoch: 6| Step: 8
Training loss: 1.0105584166420292
Validation loss: 2.5833304790900504

Epoch: 6| Step: 9
Training loss: 0.9480557636587746
Validation loss: 2.6590182738133037

Epoch: 6| Step: 10
Training loss: 1.1239954914294465
Validation loss: 2.688767716295581

Epoch: 6| Step: 11
Training loss: 1.2628394189961252
Validation loss: 2.6897064789552965

Epoch: 6| Step: 12
Training loss: 1.2148428668543314
Validation loss: 2.6999581198138936

Epoch: 6| Step: 13
Training loss: 0.9419275320549655
Validation loss: 2.664969331584532

Epoch: 319| Step: 0
Training loss: 1.0722071452774566
Validation loss: 2.6411431654810524

Epoch: 6| Step: 1
Training loss: 1.4345417266552887
Validation loss: 2.6052185451092926

Epoch: 6| Step: 2
Training loss: 1.082303395114435
Validation loss: 2.562149687201499

Epoch: 6| Step: 3
Training loss: 0.79314383091377
Validation loss: 2.534994049675297

Epoch: 6| Step: 4
Training loss: 0.8148432467377701
Validation loss: 2.5160120398355312

Epoch: 6| Step: 5
Training loss: 0.9282422412329223
Validation loss: 2.522996025767647

Epoch: 6| Step: 6
Training loss: 1.1072796119662969
Validation loss: 2.5454960017746453

Epoch: 6| Step: 7
Training loss: 0.9739840838994198
Validation loss: 2.5664988339501162

Epoch: 6| Step: 8
Training loss: 0.9451685709188866
Validation loss: 2.6056333570033674

Epoch: 6| Step: 9
Training loss: 1.3040877008551253
Validation loss: 2.650742374172074

Epoch: 6| Step: 10
Training loss: 0.9115938285750972
Validation loss: 2.652660639882816

Epoch: 6| Step: 11
Training loss: 1.7651951359411908
Validation loss: 2.657089875622588

Epoch: 6| Step: 12
Training loss: 1.4719936995215959
Validation loss: 2.690660205490831

Epoch: 6| Step: 13
Training loss: 0.7430985731426119
Validation loss: 2.652869146217758

Epoch: 320| Step: 0
Training loss: 1.2312984515111378
Validation loss: 2.687208886296854

Epoch: 6| Step: 1
Training loss: 1.196665428279636
Validation loss: 2.7027103253718248

Epoch: 6| Step: 2
Training loss: 1.0521250927383365
Validation loss: 2.6379490211829846

Epoch: 6| Step: 3
Training loss: 1.2804358617202616
Validation loss: 2.6503425725760263

Epoch: 6| Step: 4
Training loss: 1.3316198256175529
Validation loss: 2.607053178497863

Epoch: 6| Step: 5
Training loss: 0.8615902179718813
Validation loss: 2.6043214377075

Epoch: 6| Step: 6
Training loss: 1.1914449716748041
Validation loss: 2.5787613198733133

Epoch: 6| Step: 7
Training loss: 0.8022995488101471
Validation loss: 2.582453517035077

Epoch: 6| Step: 8
Training loss: 1.2210816795841064
Validation loss: 2.5863341871842285

Epoch: 6| Step: 9
Training loss: 0.9901874839620427
Validation loss: 2.5732954828400523

Epoch: 6| Step: 10
Training loss: 0.8086328911637307
Validation loss: 2.586900741397978

Epoch: 6| Step: 11
Training loss: 1.508630955384002
Validation loss: 2.6367684731301386

Epoch: 6| Step: 12
Training loss: 0.9294173545395914
Validation loss: 2.7050505994521212

Epoch: 6| Step: 13
Training loss: 0.9507708947801855
Validation loss: 2.7302768205636943

Epoch: 321| Step: 0
Training loss: 0.9812129870194803
Validation loss: 2.727214890911195

Epoch: 6| Step: 1
Training loss: 1.0268914565139315
Validation loss: 2.7020290907608766

Epoch: 6| Step: 2
Training loss: 1.1626654312392621
Validation loss: 2.6939205437651284

Epoch: 6| Step: 3
Training loss: 1.6145542101130574
Validation loss: 2.6348068762052383

Epoch: 6| Step: 4
Training loss: 0.8740436231956752
Validation loss: 2.6344394028675198

Epoch: 6| Step: 5
Training loss: 1.532727054621437
Validation loss: 2.647641780319444

Epoch: 6| Step: 6
Training loss: 0.4650149470921299
Validation loss: 2.647299022334036

Epoch: 6| Step: 7
Training loss: 1.0799817668294034
Validation loss: 2.6699953652501787

Epoch: 6| Step: 8
Training loss: 1.099602653523529
Validation loss: 2.6655994312641345

Epoch: 6| Step: 9
Training loss: 0.6798248590691071
Validation loss: 2.654504732261893

Epoch: 6| Step: 10
Training loss: 1.1120707037217976
Validation loss: 2.626359583579646

Epoch: 6| Step: 11
Training loss: 0.7934477914125471
Validation loss: 2.589114598010426

Epoch: 6| Step: 12
Training loss: 1.4621376371187325
Validation loss: 2.5597917184681727

Epoch: 6| Step: 13
Training loss: 0.9494341696105166
Validation loss: 2.545183806143866

Epoch: 322| Step: 0
Training loss: 1.0764279484925585
Validation loss: 2.5577456240531258

Epoch: 6| Step: 1
Training loss: 0.9321863267656515
Validation loss: 2.574101804872588

Epoch: 6| Step: 2
Training loss: 0.819316950181327
Validation loss: 2.5683605124061923

Epoch: 6| Step: 3
Training loss: 1.049817064788954
Validation loss: 2.597661186495456

Epoch: 6| Step: 4
Training loss: 1.1851999695973903
Validation loss: 2.6089030293302047

Epoch: 6| Step: 5
Training loss: 1.4718891442787578
Validation loss: 2.6699975333057044

Epoch: 6| Step: 6
Training loss: 1.5524555075838224
Validation loss: 2.6743693955825125

Epoch: 6| Step: 7
Training loss: 1.0145542075319347
Validation loss: 2.6895531988512635

Epoch: 6| Step: 8
Training loss: 0.9918390999001753
Validation loss: 2.7407777243601283

Epoch: 6| Step: 9
Training loss: 0.9298040493268748
Validation loss: 2.7269676991748524

Epoch: 6| Step: 10
Training loss: 1.2398310929285123
Validation loss: 2.7257647656782655

Epoch: 6| Step: 11
Training loss: 1.1172322617746873
Validation loss: 2.6750097532787436

Epoch: 6| Step: 12
Training loss: 0.6051979443768588
Validation loss: 2.633416487137787

Epoch: 6| Step: 13
Training loss: 1.0775795814705105
Validation loss: 2.5805788898002113

Epoch: 323| Step: 0
Training loss: 0.9912239261772144
Validation loss: 2.5049084335993697

Epoch: 6| Step: 1
Training loss: 1.201504892225779
Validation loss: 2.496592696710318

Epoch: 6| Step: 2
Training loss: 1.0843526678506588
Validation loss: 2.4765196294759493

Epoch: 6| Step: 3
Training loss: 1.5386294612573466
Validation loss: 2.5056439863607545

Epoch: 6| Step: 4
Training loss: 1.2432041446430142
Validation loss: 2.5335169993429583

Epoch: 6| Step: 5
Training loss: 0.8683247712482596
Validation loss: 2.591081424893152

Epoch: 6| Step: 6
Training loss: 0.8431995150226306
Validation loss: 2.69215482742995

Epoch: 6| Step: 7
Training loss: 1.1039093665465727
Validation loss: 2.742646435948942

Epoch: 6| Step: 8
Training loss: 1.011015540859112
Validation loss: 2.7567877829614393

Epoch: 6| Step: 9
Training loss: 1.2957284294097902
Validation loss: 2.716377788673256

Epoch: 6| Step: 10
Training loss: 0.7702215748450845
Validation loss: 2.588888837371081

Epoch: 6| Step: 11
Training loss: 1.3101161015727651
Validation loss: 2.5769398764230615

Epoch: 6| Step: 12
Training loss: 0.9910435727892135
Validation loss: 2.546795144519325

Epoch: 6| Step: 13
Training loss: 1.1796086771317642
Validation loss: 2.5183943356776486

Epoch: 324| Step: 0
Training loss: 0.9061649545687644
Validation loss: 2.526803312337516

Epoch: 6| Step: 1
Training loss: 1.4206477307818381
Validation loss: 2.5198526477460335

Epoch: 6| Step: 2
Training loss: 0.9271499238405112
Validation loss: 2.545027966445496

Epoch: 6| Step: 3
Training loss: 0.7512701723053128
Validation loss: 2.5761147356639604

Epoch: 6| Step: 4
Training loss: 0.4982570877748205
Validation loss: 2.5668326715190135

Epoch: 6| Step: 5
Training loss: 0.9343137638094466
Validation loss: 2.593474299216934

Epoch: 6| Step: 6
Training loss: 1.4227606561717843
Validation loss: 2.6301817566219237

Epoch: 6| Step: 7
Training loss: 1.11852744248975
Validation loss: 2.6409596071412462

Epoch: 6| Step: 8
Training loss: 1.1450291094348855
Validation loss: 2.673147078504749

Epoch: 6| Step: 9
Training loss: 1.4327771098218465
Validation loss: 2.7164011790117506

Epoch: 6| Step: 10
Training loss: 0.9864368643164966
Validation loss: 2.6758206358531083

Epoch: 6| Step: 11
Training loss: 1.0982242078698423
Validation loss: 2.6515878278001095

Epoch: 6| Step: 12
Training loss: 1.0595003307102582
Validation loss: 2.6473955466719947

Epoch: 6| Step: 13
Training loss: 1.2341508782609178
Validation loss: 2.5760044101094417

Epoch: 325| Step: 0
Training loss: 1.116194223460684
Validation loss: 2.548352525910636

Epoch: 6| Step: 1
Training loss: 1.224789254881047
Validation loss: 2.532096533871165

Epoch: 6| Step: 2
Training loss: 0.6539841089417866
Validation loss: 2.5270944258611934

Epoch: 6| Step: 3
Training loss: 1.0853703067321774
Validation loss: 2.5335283021295707

Epoch: 6| Step: 4
Training loss: 0.9877306946354973
Validation loss: 2.5188596516708426

Epoch: 6| Step: 5
Training loss: 0.9500631022828139
Validation loss: 2.5244774821065703

Epoch: 6| Step: 6
Training loss: 0.7471299091577998
Validation loss: 2.5512589024375694

Epoch: 6| Step: 7
Training loss: 0.4839530460541236
Validation loss: 2.6241599954406007

Epoch: 6| Step: 8
Training loss: 1.4677960970836976
Validation loss: 2.6668115359866245

Epoch: 6| Step: 9
Training loss: 1.239866956218414
Validation loss: 2.6740012448154613

Epoch: 6| Step: 10
Training loss: 0.8257620947284402
Validation loss: 2.6861045268863277

Epoch: 6| Step: 11
Training loss: 0.8482152967518682
Validation loss: 2.714657167798641

Epoch: 6| Step: 12
Training loss: 1.5034809254234596
Validation loss: 2.6940354165496547

Epoch: 6| Step: 13
Training loss: 1.213110469237794
Validation loss: 2.7177209741947603

Epoch: 326| Step: 0
Training loss: 0.7454841080320688
Validation loss: 2.76999003971587

Epoch: 6| Step: 1
Training loss: 1.3753157599890933
Validation loss: 2.763764766353999

Epoch: 6| Step: 2
Training loss: 1.1553309112724484
Validation loss: 2.6734798926751138

Epoch: 6| Step: 3
Training loss: 0.9290442284854127
Validation loss: 2.605940688458047

Epoch: 6| Step: 4
Training loss: 1.171569886223726
Validation loss: 2.5279181116650404

Epoch: 6| Step: 5
Training loss: 0.5490290589589311
Validation loss: 2.4789050398411008

Epoch: 6| Step: 6
Training loss: 1.641206765342638
Validation loss: 2.494209898048665

Epoch: 6| Step: 7
Training loss: 1.044343478116917
Validation loss: 2.499833236792861

Epoch: 6| Step: 8
Training loss: 0.9026606279966614
Validation loss: 2.515795885907403

Epoch: 6| Step: 9
Training loss: 0.7858005366420879
Validation loss: 2.5875111127910704

Epoch: 6| Step: 10
Training loss: 1.1689617311986555
Validation loss: 2.6243294437086964

Epoch: 6| Step: 11
Training loss: 1.4380270779464999
Validation loss: 2.691553765921102

Epoch: 6| Step: 12
Training loss: 1.0576717401385438
Validation loss: 2.6954854701942272

Epoch: 6| Step: 13
Training loss: 0.6595291680630971
Validation loss: 2.6565801336911794

Epoch: 327| Step: 0
Training loss: 0.5670005311526144
Validation loss: 2.669418811713088

Epoch: 6| Step: 1
Training loss: 0.8883280665424614
Validation loss: 2.6518752321166894

Epoch: 6| Step: 2
Training loss: 1.2271941678434546
Validation loss: 2.646877087464903

Epoch: 6| Step: 3
Training loss: 1.4957983457392687
Validation loss: 2.63072310244881

Epoch: 6| Step: 4
Training loss: 1.3056885311142177
Validation loss: 2.5810410024221566

Epoch: 6| Step: 5
Training loss: 1.1303395079449052
Validation loss: 2.566274420825702

Epoch: 6| Step: 6
Training loss: 1.0735648644638873
Validation loss: 2.5852936211779554

Epoch: 6| Step: 7
Training loss: 0.6178099234049222
Validation loss: 2.6021351453633863

Epoch: 6| Step: 8
Training loss: 0.7306476312791979
Validation loss: 2.6277766936007407

Epoch: 6| Step: 9
Training loss: 1.1194879282564152
Validation loss: 2.613189824668463

Epoch: 6| Step: 10
Training loss: 1.456744700217766
Validation loss: 2.6661455397647633

Epoch: 6| Step: 11
Training loss: 0.9255552056147675
Validation loss: 2.6952308997924486

Epoch: 6| Step: 12
Training loss: 0.8646429033707651
Validation loss: 2.750446794148283

Epoch: 6| Step: 13
Training loss: 1.005340086582464
Validation loss: 2.7208557102608784

Epoch: 328| Step: 0
Training loss: 1.1198857408381686
Validation loss: 2.7171813806457132

Epoch: 6| Step: 1
Training loss: 1.09639746549495
Validation loss: 2.7110212818502584

Epoch: 6| Step: 2
Training loss: 1.0357415038323632
Validation loss: 2.6884565122635276

Epoch: 6| Step: 3
Training loss: 1.3102855165934282
Validation loss: 2.625589127849533

Epoch: 6| Step: 4
Training loss: 0.9171689709119107
Validation loss: 2.605714221163998

Epoch: 6| Step: 5
Training loss: 1.0967847412012073
Validation loss: 2.5776662180302563

Epoch: 6| Step: 6
Training loss: 0.7062093689295155
Validation loss: 2.574058687454552

Epoch: 6| Step: 7
Training loss: 1.050439261335062
Validation loss: 2.5768994851402454

Epoch: 6| Step: 8
Training loss: 1.280940879190068
Validation loss: 2.5558303805910954

Epoch: 6| Step: 9
Training loss: 1.1962717234075062
Validation loss: 2.590704931174493

Epoch: 6| Step: 10
Training loss: 1.0815103426935637
Validation loss: 2.6510665950082197

Epoch: 6| Step: 11
Training loss: 1.0657979606701966
Validation loss: 2.645233555926365

Epoch: 6| Step: 12
Training loss: 0.7557351653485156
Validation loss: 2.659733217375282

Epoch: 6| Step: 13
Training loss: 0.4677156002468504
Validation loss: 2.656983764369613

Epoch: 329| Step: 0
Training loss: 0.6548891489852681
Validation loss: 2.6636356960585315

Epoch: 6| Step: 1
Training loss: 0.932375572023371
Validation loss: 2.649930371514966

Epoch: 6| Step: 2
Training loss: 0.8545389914637154
Validation loss: 2.618436198281028

Epoch: 6| Step: 3
Training loss: 0.9704076060004102
Validation loss: 2.598682460355421

Epoch: 6| Step: 4
Training loss: 1.2162040625715287
Validation loss: 2.613625242089721

Epoch: 6| Step: 5
Training loss: 1.4506526136091624
Validation loss: 2.6637035995757357

Epoch: 6| Step: 6
Training loss: 0.867665133520944
Validation loss: 2.6751611364542316

Epoch: 6| Step: 7
Training loss: 0.8936861202112756
Validation loss: 2.6897245006818764

Epoch: 6| Step: 8
Training loss: 1.0924684373324878
Validation loss: 2.675657800063685

Epoch: 6| Step: 9
Training loss: 0.7407312663011044
Validation loss: 2.6539999459014094

Epoch: 6| Step: 10
Training loss: 1.3888902452250322
Validation loss: 2.6493673480313813

Epoch: 6| Step: 11
Training loss: 0.8967785653828082
Validation loss: 2.637910776440403

Epoch: 6| Step: 12
Training loss: 0.9895715545488692
Validation loss: 2.6260094076469715

Epoch: 6| Step: 13
Training loss: 1.3932858844751443
Validation loss: 2.615472393778964

Epoch: 330| Step: 0
Training loss: 0.7463338575419529
Validation loss: 2.6199309338688637

Epoch: 6| Step: 1
Training loss: 1.0703482517480662
Validation loss: 2.596051881511109

Epoch: 6| Step: 2
Training loss: 1.1247019902870121
Validation loss: 2.589361620536558

Epoch: 6| Step: 3
Training loss: 1.3504635085790138
Validation loss: 2.6149683578425544

Epoch: 6| Step: 4
Training loss: 0.8852206779930587
Validation loss: 2.5991067812926256

Epoch: 6| Step: 5
Training loss: 0.9053040862424914
Validation loss: 2.591328953932935

Epoch: 6| Step: 6
Training loss: 1.475903237724772
Validation loss: 2.6530140999487037

Epoch: 6| Step: 7
Training loss: 0.7910106140731523
Validation loss: 2.6642517478758

Epoch: 6| Step: 8
Training loss: 0.8335924858219532
Validation loss: 2.661052050509469

Epoch: 6| Step: 9
Training loss: 0.879355523463787
Validation loss: 2.7132994296244073

Epoch: 6| Step: 10
Training loss: 1.142649278299979
Validation loss: 2.6916684368385133

Epoch: 6| Step: 11
Training loss: 1.148418296601511
Validation loss: 2.7051704080324703

Epoch: 6| Step: 12
Training loss: 0.7310841054294495
Validation loss: 2.6810581453682323

Epoch: 6| Step: 13
Training loss: 0.7811008310960424
Validation loss: 2.6403727718304486

Epoch: 331| Step: 0
Training loss: 0.889032278234433
Validation loss: 2.5762603748793658

Epoch: 6| Step: 1
Training loss: 1.0061193630171021
Validation loss: 2.5581666626436337

Epoch: 6| Step: 2
Training loss: 0.4730197360052561
Validation loss: 2.556022378331872

Epoch: 6| Step: 3
Training loss: 1.2176355989051861
Validation loss: 2.5711819632852673

Epoch: 6| Step: 4
Training loss: 1.323176240861316
Validation loss: 2.593678113284908

Epoch: 6| Step: 5
Training loss: 0.7558712034261017
Validation loss: 2.595028538545115

Epoch: 6| Step: 6
Training loss: 1.3346679187321642
Validation loss: 2.630265387557249

Epoch: 6| Step: 7
Training loss: 1.121315857687211
Validation loss: 2.672252217499239

Epoch: 6| Step: 8
Training loss: 0.9060811510310338
Validation loss: 2.6981844825927066

Epoch: 6| Step: 9
Training loss: 0.4283702078518672
Validation loss: 2.6740145313184316

Epoch: 6| Step: 10
Training loss: 1.1354788083677825
Validation loss: 2.690061487017487

Epoch: 6| Step: 11
Training loss: 0.9684907812507909
Validation loss: 2.6984850193407937

Epoch: 6| Step: 12
Training loss: 0.9254032441708314
Validation loss: 2.712812813828672

Epoch: 6| Step: 13
Training loss: 1.1162960523992607
Validation loss: 2.691961074841452

Epoch: 332| Step: 0
Training loss: 0.8668501601617342
Validation loss: 2.677268403994259

Epoch: 6| Step: 1
Training loss: 0.8350741482551752
Validation loss: 2.6608142107449746

Epoch: 6| Step: 2
Training loss: 0.8449586053449003
Validation loss: 2.624573371622844

Epoch: 6| Step: 3
Training loss: 1.2690154450951874
Validation loss: 2.601157924632918

Epoch: 6| Step: 4
Training loss: 1.1694944998981625
Validation loss: 2.611650298848317

Epoch: 6| Step: 5
Training loss: 0.6299433716043233
Validation loss: 2.5956438239698243

Epoch: 6| Step: 6
Training loss: 0.6383082670099263
Validation loss: 2.6117585346168295

Epoch: 6| Step: 7
Training loss: 0.8420833445389672
Validation loss: 2.6122927117995647

Epoch: 6| Step: 8
Training loss: 1.3185907909596521
Validation loss: 2.6462102893919255

Epoch: 6| Step: 9
Training loss: 0.9671477018435415
Validation loss: 2.67588498428163

Epoch: 6| Step: 10
Training loss: 1.03693493311736
Validation loss: 2.68394597131779

Epoch: 6| Step: 11
Training loss: 1.274592665511044
Validation loss: 2.651827216261983

Epoch: 6| Step: 12
Training loss: 1.0834948284868964
Validation loss: 2.609837649759688

Epoch: 6| Step: 13
Training loss: 0.9233412961983718
Validation loss: 2.6107438645275662

Epoch: 333| Step: 0
Training loss: 1.1368930853379833
Validation loss: 2.6167847819567247

Epoch: 6| Step: 1
Training loss: 0.8002179653545094
Validation loss: 2.609579827768676

Epoch: 6| Step: 2
Training loss: 0.8560611293793171
Validation loss: 2.6135180596399312

Epoch: 6| Step: 3
Training loss: 1.0880856570296713
Validation loss: 2.6398123495330625

Epoch: 6| Step: 4
Training loss: 1.1428882667015987
Validation loss: 2.626926817561929

Epoch: 6| Step: 5
Training loss: 1.1444945866567997
Validation loss: 2.588805452239539

Epoch: 6| Step: 6
Training loss: 0.7841258713437503
Validation loss: 2.6247841999752066

Epoch: 6| Step: 7
Training loss: 1.0544424266771315
Validation loss: 2.6512967082957384

Epoch: 6| Step: 8
Training loss: 1.09473445729549
Validation loss: 2.658669948247401

Epoch: 6| Step: 9
Training loss: 0.6469310588779522
Validation loss: 2.672688123290033

Epoch: 6| Step: 10
Training loss: 1.1845865649486629
Validation loss: 2.6588647566658947

Epoch: 6| Step: 11
Training loss: 1.0025964645816512
Validation loss: 2.589694671406112

Epoch: 6| Step: 12
Training loss: 0.8298605959228732
Validation loss: 2.5662062599454414

Epoch: 6| Step: 13
Training loss: 0.7998415760294662
Validation loss: 2.572536963761487

Epoch: 334| Step: 0
Training loss: 1.2631996840907227
Validation loss: 2.611889679751897

Epoch: 6| Step: 1
Training loss: 1.0382900952377887
Validation loss: 2.6865163377995973

Epoch: 6| Step: 2
Training loss: 1.1817475577906806
Validation loss: 2.7108612272048562

Epoch: 6| Step: 3
Training loss: 1.272223051469765
Validation loss: 2.711312506169789

Epoch: 6| Step: 4
Training loss: 0.7158979969623804
Validation loss: 2.7346446252135603

Epoch: 6| Step: 5
Training loss: 0.6244815583510702
Validation loss: 2.7308128347041842

Epoch: 6| Step: 6
Training loss: 1.072438988628607
Validation loss: 2.663738280682494

Epoch: 6| Step: 7
Training loss: 0.7580426839873631
Validation loss: 2.6095555074613848

Epoch: 6| Step: 8
Training loss: 0.40116238531758186
Validation loss: 2.5574652359763443

Epoch: 6| Step: 9
Training loss: 1.1046668065573082
Validation loss: 2.521651818964178

Epoch: 6| Step: 10
Training loss: 1.0095657947783845
Validation loss: 2.4665967846022885

Epoch: 6| Step: 11
Training loss: 1.097746604377292
Validation loss: 2.499743264869632

Epoch: 6| Step: 12
Training loss: 0.8121199085603843
Validation loss: 2.5165232147353955

Epoch: 6| Step: 13
Training loss: 1.1394819515584929
Validation loss: 2.530891787088325

Epoch: 335| Step: 0
Training loss: 0.9128647153782488
Validation loss: 2.5544159020976736

Epoch: 6| Step: 1
Training loss: 0.9806770316251973
Validation loss: 2.5777464199937627

Epoch: 6| Step: 2
Training loss: 1.1826144658631461
Validation loss: 2.565814794575551

Epoch: 6| Step: 3
Training loss: 0.6752685630729656
Validation loss: 2.6073015402242223

Epoch: 6| Step: 4
Training loss: 1.121364706969995
Validation loss: 2.5657968819542147

Epoch: 6| Step: 5
Training loss: 1.1060222951735463
Validation loss: 2.556170438038839

Epoch: 6| Step: 6
Training loss: 0.8340361889504945
Validation loss: 2.5626267852752256

Epoch: 6| Step: 7
Training loss: 1.3156215694863
Validation loss: 2.5724213503554116

Epoch: 6| Step: 8
Training loss: 0.9221437353480544
Validation loss: 2.5472911452209592

Epoch: 6| Step: 9
Training loss: 0.6425012930994343
Validation loss: 2.571477116557724

Epoch: 6| Step: 10
Training loss: 0.7691134950300279
Validation loss: 2.5802635200846273

Epoch: 6| Step: 11
Training loss: 1.2919408394434186
Validation loss: 2.6046582814169486

Epoch: 6| Step: 12
Training loss: 0.5821720695395969
Validation loss: 2.6460076170449804

Epoch: 6| Step: 13
Training loss: 0.9302667368075488
Validation loss: 2.6836554923242604

Epoch: 336| Step: 0
Training loss: 0.9957523134756833
Validation loss: 2.738577261951133

Epoch: 6| Step: 1
Training loss: 0.8319524808321095
Validation loss: 2.7411409352432967

Epoch: 6| Step: 2
Training loss: 0.7468305614450926
Validation loss: 2.7222434166811547

Epoch: 6| Step: 3
Training loss: 1.0532835481644354
Validation loss: 2.7071086611628887

Epoch: 6| Step: 4
Training loss: 0.8632781775234316
Validation loss: 2.680637233053034

Epoch: 6| Step: 5
Training loss: 1.0710099446950725
Validation loss: 2.6366552998980315

Epoch: 6| Step: 6
Training loss: 0.8328729589678588
Validation loss: 2.575231287105153

Epoch: 6| Step: 7
Training loss: 0.8455965181954808
Validation loss: 2.5571490909402974

Epoch: 6| Step: 8
Training loss: 1.2210716240672759
Validation loss: 2.5635140166234662

Epoch: 6| Step: 9
Training loss: 1.1235678351804466
Validation loss: 2.5521987704767928

Epoch: 6| Step: 10
Training loss: 1.2340397439859618
Validation loss: 2.546366466869996

Epoch: 6| Step: 11
Training loss: 1.18564219460816
Validation loss: 2.5402227106368205

Epoch: 6| Step: 12
Training loss: 0.39652394816027803
Validation loss: 2.5633211138384007

Epoch: 6| Step: 13
Training loss: 0.7540186664790227
Validation loss: 2.578958973467399

Epoch: 337| Step: 0
Training loss: 0.8601535738176643
Validation loss: 2.592165891564977

Epoch: 6| Step: 1
Training loss: 0.47182187608707366
Validation loss: 2.637094684692325

Epoch: 6| Step: 2
Training loss: 1.0268531469154683
Validation loss: 2.6356494811592044

Epoch: 6| Step: 3
Training loss: 0.8812509414992478
Validation loss: 2.657059643460175

Epoch: 6| Step: 4
Training loss: 1.054982123020086
Validation loss: 2.618137140925822

Epoch: 6| Step: 5
Training loss: 1.0535383392476563
Validation loss: 2.6140847280801895

Epoch: 6| Step: 6
Training loss: 1.1791870874764183
Validation loss: 2.6003719158883145

Epoch: 6| Step: 7
Training loss: 0.8945155912802851
Validation loss: 2.6053902205757904

Epoch: 6| Step: 8
Training loss: 0.9892060246520521
Validation loss: 2.6199936206774095

Epoch: 6| Step: 9
Training loss: 1.030257064906193
Validation loss: 2.6282240205410625

Epoch: 6| Step: 10
Training loss: 1.018235826917689
Validation loss: 2.64299960596165

Epoch: 6| Step: 11
Training loss: 0.9565829725794596
Validation loss: 2.620777092965763

Epoch: 6| Step: 12
Training loss: 0.9141591664901737
Validation loss: 2.6070468213908655

Epoch: 6| Step: 13
Training loss: 0.7558310254519837
Validation loss: 2.6428985177134856

Epoch: 338| Step: 0
Training loss: 0.8964340096082399
Validation loss: 2.6041189931792212

Epoch: 6| Step: 1
Training loss: 1.0310356610972997
Validation loss: 2.6022806691119453

Epoch: 6| Step: 2
Training loss: 0.8758477463944272
Validation loss: 2.6219779479787273

Epoch: 6| Step: 3
Training loss: 0.9974556084126937
Validation loss: 2.6173987107324703

Epoch: 6| Step: 4
Training loss: 0.5001427029577805
Validation loss: 2.596671568125997

Epoch: 6| Step: 5
Training loss: 0.9091417937776468
Validation loss: 2.6134532781899225

Epoch: 6| Step: 6
Training loss: 0.7894583360744444
Validation loss: 2.6319071073264135

Epoch: 6| Step: 7
Training loss: 1.1747620686627356
Validation loss: 2.629938255307999

Epoch: 6| Step: 8
Training loss: 0.6852177973977365
Validation loss: 2.6350007275936074

Epoch: 6| Step: 9
Training loss: 1.2341352785297364
Validation loss: 2.638687347123614

Epoch: 6| Step: 10
Training loss: 1.094375540462515
Validation loss: 2.6018074829596682

Epoch: 6| Step: 11
Training loss: 0.892282783510991
Validation loss: 2.5868939093763252

Epoch: 6| Step: 12
Training loss: 0.8004138382784429
Validation loss: 2.5728015469534062

Epoch: 6| Step: 13
Training loss: 0.9069192979905252
Validation loss: 2.5755578458791994

Epoch: 339| Step: 0
Training loss: 0.7052052137643022
Validation loss: 2.5820101582179187

Epoch: 6| Step: 1
Training loss: 0.5338133230324713
Validation loss: 2.584001183560765

Epoch: 6| Step: 2
Training loss: 1.2204769810057279
Validation loss: 2.6097433463798456

Epoch: 6| Step: 3
Training loss: 0.6605636423104514
Validation loss: 2.6560181624537402

Epoch: 6| Step: 4
Training loss: 1.003388742731309
Validation loss: 2.648332971820032

Epoch: 6| Step: 5
Training loss: 0.9150427102715445
Validation loss: 2.6517619882095644

Epoch: 6| Step: 6
Training loss: 0.3578882145628731
Validation loss: 2.6279654894359807

Epoch: 6| Step: 7
Training loss: 1.2267298007263756
Validation loss: 2.630441180952346

Epoch: 6| Step: 8
Training loss: 1.141795981292949
Validation loss: 2.5733832762009365

Epoch: 6| Step: 9
Training loss: 0.9184314292247602
Validation loss: 2.5844354515536114

Epoch: 6| Step: 10
Training loss: 0.7441009350702485
Validation loss: 2.5596190323902137

Epoch: 6| Step: 11
Training loss: 1.0375415885586907
Validation loss: 2.5897423810931595

Epoch: 6| Step: 12
Training loss: 1.1980774260196179
Validation loss: 2.6051064919725664

Epoch: 6| Step: 13
Training loss: 0.369694994885143
Validation loss: 2.6287629774541963

Epoch: 340| Step: 0
Training loss: 0.871065558417831
Validation loss: 2.61013290130084

Epoch: 6| Step: 1
Training loss: 0.6802634506522038
Validation loss: 2.617966639680562

Epoch: 6| Step: 2
Training loss: 1.212292362406762
Validation loss: 2.6497031209823

Epoch: 6| Step: 3
Training loss: 0.9551609058038885
Validation loss: 2.6209701832459396

Epoch: 6| Step: 4
Training loss: 0.8686647634063309
Validation loss: 2.653372646258935

Epoch: 6| Step: 5
Training loss: 0.6707521637289129
Validation loss: 2.616324954910754

Epoch: 6| Step: 6
Training loss: 0.773729365602126
Validation loss: 2.59689796070068

Epoch: 6| Step: 7
Training loss: 0.9452123667750244
Validation loss: 2.6265824563545808

Epoch: 6| Step: 8
Training loss: 1.1606984011642607
Validation loss: 2.6133272812682002

Epoch: 6| Step: 9
Training loss: 0.6681256026433898
Validation loss: 2.5946544311283297

Epoch: 6| Step: 10
Training loss: 0.5258850267314444
Validation loss: 2.6243832943424517

Epoch: 6| Step: 11
Training loss: 1.1163644493184506
Validation loss: 2.646572922082466

Epoch: 6| Step: 12
Training loss: 0.9308600524566913
Validation loss: 2.606379033295959

Epoch: 6| Step: 13
Training loss: 1.1000222875764736
Validation loss: 2.631104457708647

Epoch: 341| Step: 0
Training loss: 0.8596761002611562
Validation loss: 2.639801980597245

Epoch: 6| Step: 1
Training loss: 0.8810606597515316
Validation loss: 2.6231242547417795

Epoch: 6| Step: 2
Training loss: 0.8059650020928584
Validation loss: 2.6665116856002924

Epoch: 6| Step: 3
Training loss: 0.9968164253365663
Validation loss: 2.6524880157801833

Epoch: 6| Step: 4
Training loss: 0.9746057055448206
Validation loss: 2.630544925588854

Epoch: 6| Step: 5
Training loss: 0.984518071025722
Validation loss: 2.632134606227408

Epoch: 6| Step: 6
Training loss: 0.7625157026331228
Validation loss: 2.6503704680050832

Epoch: 6| Step: 7
Training loss: 0.7332594088299617
Validation loss: 2.600469524515145

Epoch: 6| Step: 8
Training loss: 1.0153157863874895
Validation loss: 2.6239938951564357

Epoch: 6| Step: 9
Training loss: 1.1804019709645295
Validation loss: 2.603504070690251

Epoch: 6| Step: 10
Training loss: 0.7686052511757968
Validation loss: 2.612980804028503

Epoch: 6| Step: 11
Training loss: 0.8008681459498268
Validation loss: 2.596402891776493

Epoch: 6| Step: 12
Training loss: 0.9121774325414753
Validation loss: 2.598530899526077

Epoch: 6| Step: 13
Training loss: 0.8666605680202214
Validation loss: 2.6299245048675584

Epoch: 342| Step: 0
Training loss: 1.0086398018887732
Validation loss: 2.6188768234398

Epoch: 6| Step: 1
Training loss: 0.884379321515743
Validation loss: 2.594056285452026

Epoch: 6| Step: 2
Training loss: 0.8838445656561618
Validation loss: 2.62168633229776

Epoch: 6| Step: 3
Training loss: 0.8155392144935395
Validation loss: 2.6167626153731

Epoch: 6| Step: 4
Training loss: 1.054322016933164
Validation loss: 2.6729668400902273

Epoch: 6| Step: 5
Training loss: 0.9820247628688878
Validation loss: 2.6605567931137046

Epoch: 6| Step: 6
Training loss: 1.0933972471055646
Validation loss: 2.611363383890274

Epoch: 6| Step: 7
Training loss: 0.936877998006247
Validation loss: 2.608122217065645

Epoch: 6| Step: 8
Training loss: 0.8860296184678287
Validation loss: 2.5830446410122607

Epoch: 6| Step: 9
Training loss: 1.0017341835595504
Validation loss: 2.618445713875901

Epoch: 6| Step: 10
Training loss: 0.6095731853110623
Validation loss: 2.6307115575175994

Epoch: 6| Step: 11
Training loss: 0.913177387737407
Validation loss: 2.6541998366626487

Epoch: 6| Step: 12
Training loss: 0.6357092782920922
Validation loss: 2.662905993336911

Epoch: 6| Step: 13
Training loss: 0.635468431354984
Validation loss: 2.6874843872639405

Epoch: 343| Step: 0
Training loss: 0.83856291576181
Validation loss: 2.6626092444182885

Epoch: 6| Step: 1
Training loss: 0.8219419009752431
Validation loss: 2.6841575191702183

Epoch: 6| Step: 2
Training loss: 0.9777777777627261
Validation loss: 2.6545435462683726

Epoch: 6| Step: 3
Training loss: 0.7577069395813086
Validation loss: 2.6053404776699556

Epoch: 6| Step: 4
Training loss: 0.8160372908780622
Validation loss: 2.5731242375422516

Epoch: 6| Step: 5
Training loss: 1.0294130321302546
Validation loss: 2.582239216688213

Epoch: 6| Step: 6
Training loss: 0.7819342858930917
Validation loss: 2.6072303211542054

Epoch: 6| Step: 7
Training loss: 0.9540609860650304
Validation loss: 2.596431569131482

Epoch: 6| Step: 8
Training loss: 0.66995107959672
Validation loss: 2.633211964569588

Epoch: 6| Step: 9
Training loss: 0.7933923125649224
Validation loss: 2.6173236652939154

Epoch: 6| Step: 10
Training loss: 1.0047591330708057
Validation loss: 2.627435688051201

Epoch: 6| Step: 11
Training loss: 0.9012895511408793
Validation loss: 2.588907290567021

Epoch: 6| Step: 12
Training loss: 1.1027468543811005
Validation loss: 2.6107826810358947

Epoch: 6| Step: 13
Training loss: 0.8097093782520424
Validation loss: 2.630008508545355

Epoch: 344| Step: 0
Training loss: 1.0665479852296207
Validation loss: 2.6462977741916336

Epoch: 6| Step: 1
Training loss: 0.9269213517085
Validation loss: 2.606531505894399

Epoch: 6| Step: 2
Training loss: 0.9006198086612132
Validation loss: 2.658904684279732

Epoch: 6| Step: 3
Training loss: 0.5431788195951336
Validation loss: 2.627118159932418

Epoch: 6| Step: 4
Training loss: 0.7113238531965832
Validation loss: 2.6124280517816696

Epoch: 6| Step: 5
Training loss: 0.8016153968772373
Validation loss: 2.5989468202494788

Epoch: 6| Step: 6
Training loss: 0.7101010862439121
Validation loss: 2.596193399441497

Epoch: 6| Step: 7
Training loss: 0.961846890500448
Validation loss: 2.607009280242549

Epoch: 6| Step: 8
Training loss: 1.0197273738078259
Validation loss: 2.6027626876553254

Epoch: 6| Step: 9
Training loss: 1.0758358522519134
Validation loss: 2.593196728839416

Epoch: 6| Step: 10
Training loss: 0.6852674213548271
Validation loss: 2.5975054129410955

Epoch: 6| Step: 11
Training loss: 0.9919937725621535
Validation loss: 2.635775459519457

Epoch: 6| Step: 12
Training loss: 0.7355359417492251
Validation loss: 2.695932240429528

Epoch: 6| Step: 13
Training loss: 0.93428288646835
Validation loss: 2.6978532944679605

Epoch: 345| Step: 0
Training loss: 0.7654510611868949
Validation loss: 2.681550102019614

Epoch: 6| Step: 1
Training loss: 0.6502867377997069
Validation loss: 2.625358218212133

Epoch: 6| Step: 2
Training loss: 0.7807320594521936
Validation loss: 2.626631286036236

Epoch: 6| Step: 3
Training loss: 0.9354002963179208
Validation loss: 2.5969126229498807

Epoch: 6| Step: 4
Training loss: 0.7474598386430998
Validation loss: 2.5605647665287785

Epoch: 6| Step: 5
Training loss: 0.6726678561495323
Validation loss: 2.561483075849364

Epoch: 6| Step: 6
Training loss: 1.2162336144906907
Validation loss: 2.531475111313377

Epoch: 6| Step: 7
Training loss: 0.8534726060025462
Validation loss: 2.546447260998991

Epoch: 6| Step: 8
Training loss: 0.8150872339474419
Validation loss: 2.597462323771523

Epoch: 6| Step: 9
Training loss: 0.7396553613395563
Validation loss: 2.6041486605770308

Epoch: 6| Step: 10
Training loss: 0.8102976956028368
Validation loss: 2.650331278998237

Epoch: 6| Step: 11
Training loss: 1.0972809608178147
Validation loss: 2.6707376053628513

Epoch: 6| Step: 12
Training loss: 1.184218339448106
Validation loss: 2.702515438958132

Epoch: 6| Step: 13
Training loss: 0.8820404457714422
Validation loss: 2.700579425586995

Epoch: 346| Step: 0
Training loss: 0.7858630363120429
Validation loss: 2.6199819805205378

Epoch: 6| Step: 1
Training loss: 0.564450036274732
Validation loss: 2.586738477991014

Epoch: 6| Step: 2
Training loss: 1.0943138304150053
Validation loss: 2.5490028757398466

Epoch: 6| Step: 3
Training loss: 1.2070508047945723
Validation loss: 2.533667170506114

Epoch: 6| Step: 4
Training loss: 0.5349815807558675
Validation loss: 2.5590427926766215

Epoch: 6| Step: 5
Training loss: 0.8437435715041928
Validation loss: 2.583269070498507

Epoch: 6| Step: 6
Training loss: 0.9342645126901916
Validation loss: 2.5790579233099016

Epoch: 6| Step: 7
Training loss: 0.9750108522642612
Validation loss: 2.623354384754052

Epoch: 6| Step: 8
Training loss: 0.9987113517378111
Validation loss: 2.646628164429414

Epoch: 6| Step: 9
Training loss: 0.7762821174894072
Validation loss: 2.653955017090193

Epoch: 6| Step: 10
Training loss: 0.8130275407539301
Validation loss: 2.6382967368910752

Epoch: 6| Step: 11
Training loss: 0.8209107896563912
Validation loss: 2.6586325695331894

Epoch: 6| Step: 12
Training loss: 0.9493685003765088
Validation loss: 2.671237957166623

Epoch: 6| Step: 13
Training loss: 0.6448000260788508
Validation loss: 2.638447183307607

Epoch: 347| Step: 0
Training loss: 0.9656803967038919
Validation loss: 2.5884872064023665

Epoch: 6| Step: 1
Training loss: 0.9308137883314651
Validation loss: 2.575569487735023

Epoch: 6| Step: 2
Training loss: 0.6944018411813555
Validation loss: 2.579979542195398

Epoch: 6| Step: 3
Training loss: 0.7944864866237017
Validation loss: 2.5617940196824764

Epoch: 6| Step: 4
Training loss: 0.8214403663996811
Validation loss: 2.549383477631011

Epoch: 6| Step: 5
Training loss: 0.9418322284000981
Validation loss: 2.6126896461578974

Epoch: 6| Step: 6
Training loss: 0.7194484965465175
Validation loss: 2.6116907814060606

Epoch: 6| Step: 7
Training loss: 0.8354292777450141
Validation loss: 2.620439508561377

Epoch: 6| Step: 8
Training loss: 0.7560286221535607
Validation loss: 2.6183632063795828

Epoch: 6| Step: 9
Training loss: 0.8240203618663344
Validation loss: 2.630836548412238

Epoch: 6| Step: 10
Training loss: 1.0777194601079794
Validation loss: 2.592514206255857

Epoch: 6| Step: 11
Training loss: 0.8720306011526308
Validation loss: 2.581810731434782

Epoch: 6| Step: 12
Training loss: 0.6618264192901923
Validation loss: 2.5631849522518317

Epoch: 6| Step: 13
Training loss: 1.212924090674711
Validation loss: 2.5818688260244995

Epoch: 348| Step: 0
Training loss: 0.8622772454358987
Validation loss: 2.6010213413067214

Epoch: 6| Step: 1
Training loss: 0.6481481389078513
Validation loss: 2.587862398841491

Epoch: 6| Step: 2
Training loss: 0.7501312776750066
Validation loss: 2.6043974149465905

Epoch: 6| Step: 3
Training loss: 0.7715621715867869
Validation loss: 2.6167455274012292

Epoch: 6| Step: 4
Training loss: 1.0841656507525912
Validation loss: 2.626950314409697

Epoch: 6| Step: 5
Training loss: 1.0865492161269834
Validation loss: 2.6652193541718514

Epoch: 6| Step: 6
Training loss: 0.6644536605375309
Validation loss: 2.686663101205323

Epoch: 6| Step: 7
Training loss: 0.852777751355856
Validation loss: 2.6873203226109914

Epoch: 6| Step: 8
Training loss: 0.5605135386054394
Validation loss: 2.6761010721594247

Epoch: 6| Step: 9
Training loss: 0.9221803838234892
Validation loss: 2.6469460320408276

Epoch: 6| Step: 10
Training loss: 0.6769526477774618
Validation loss: 2.6606576609118227

Epoch: 6| Step: 11
Training loss: 0.6308455096631417
Validation loss: 2.564072001958779

Epoch: 6| Step: 12
Training loss: 0.9178196562766314
Validation loss: 2.570056833622196

Epoch: 6| Step: 13
Training loss: 1.4223078812857224
Validation loss: 2.528591193730205

Epoch: 349| Step: 0
Training loss: 0.7787922154919685
Validation loss: 2.564273553622118

Epoch: 6| Step: 1
Training loss: 0.9937739867188501
Validation loss: 2.584830305065427

Epoch: 6| Step: 2
Training loss: 0.8956788543460656
Validation loss: 2.6328545919345854

Epoch: 6| Step: 3
Training loss: 0.9685871233454216
Validation loss: 2.6612284362597816

Epoch: 6| Step: 4
Training loss: 0.8066868064536322
Validation loss: 2.60772274712273

Epoch: 6| Step: 5
Training loss: 0.8517344939799733
Validation loss: 2.664880189407098

Epoch: 6| Step: 6
Training loss: 1.1146803246243904
Validation loss: 2.719447530059766

Epoch: 6| Step: 7
Training loss: 0.6101078126561874
Validation loss: 2.712620347749376

Epoch: 6| Step: 8
Training loss: 0.6161002227419968
Validation loss: 2.6901856606346604

Epoch: 6| Step: 9
Training loss: 0.7816173834064346
Validation loss: 2.621028241263084

Epoch: 6| Step: 10
Training loss: 0.7879957031626631
Validation loss: 2.5547832184957624

Epoch: 6| Step: 11
Training loss: 1.0761008680564343
Validation loss: 2.516827520543181

Epoch: 6| Step: 12
Training loss: 0.6036105281938006
Validation loss: 2.5087621500406203

Epoch: 6| Step: 13
Training loss: 0.712477598340077
Validation loss: 2.4917255952985

Epoch: 350| Step: 0
Training loss: 0.9215884652397731
Validation loss: 2.4746881634913183

Epoch: 6| Step: 1
Training loss: 0.8987451441266242
Validation loss: 2.5124289779979585

Epoch: 6| Step: 2
Training loss: 0.7190762484287617
Validation loss: 2.553491068457168

Epoch: 6| Step: 3
Training loss: 0.9343598227400567
Validation loss: 2.616090724777088

Epoch: 6| Step: 4
Training loss: 0.6538843477106401
Validation loss: 2.694225207179358

Epoch: 6| Step: 5
Training loss: 0.8946682021404551
Validation loss: 2.704248735709556

Epoch: 6| Step: 6
Training loss: 0.7356838574843099
Validation loss: 2.714319212477273

Epoch: 6| Step: 7
Training loss: 1.0290630154531644
Validation loss: 2.67135810949567

Epoch: 6| Step: 8
Training loss: 0.6329659640877802
Validation loss: 2.5582597171479464

Epoch: 6| Step: 9
Training loss: 0.9645775184428612
Validation loss: 2.531136108493788

Epoch: 6| Step: 10
Training loss: 0.9023054701046469
Validation loss: 2.52516508802418

Epoch: 6| Step: 11
Training loss: 0.9777684814259245
Validation loss: 2.5183753156684525

Epoch: 6| Step: 12
Training loss: 1.0974183826033852
Validation loss: 2.5405746674748286

Epoch: 6| Step: 13
Training loss: 0.5670173505402414
Validation loss: 2.5893024198133734

Epoch: 351| Step: 0
Training loss: 0.9740293684297511
Validation loss: 2.672695688963976

Epoch: 6| Step: 1
Training loss: 0.9728278809142418
Validation loss: 2.6793146533258807

Epoch: 6| Step: 2
Training loss: 0.7484231903683259
Validation loss: 2.717402090934899

Epoch: 6| Step: 3
Training loss: 0.8277013162705456
Validation loss: 2.7582510234345743

Epoch: 6| Step: 4
Training loss: 0.7780913395476046
Validation loss: 2.719441526898681

Epoch: 6| Step: 5
Training loss: 0.9287999829464795
Validation loss: 2.7060610329906964

Epoch: 6| Step: 6
Training loss: 0.8175387034455737
Validation loss: 2.660704917137319

Epoch: 6| Step: 7
Training loss: 0.4682619096837137
Validation loss: 2.6048365243752536

Epoch: 6| Step: 8
Training loss: 0.9131727207985966
Validation loss: 2.595493817189642

Epoch: 6| Step: 9
Training loss: 0.9859233970056617
Validation loss: 2.5797316759442688

Epoch: 6| Step: 10
Training loss: 0.9852290611374854
Validation loss: 2.584048481482255

Epoch: 6| Step: 11
Training loss: 0.7907025129596478
Validation loss: 2.609906532560563

Epoch: 6| Step: 12
Training loss: 0.8689541048654165
Validation loss: 2.589429550099843

Epoch: 6| Step: 13
Training loss: 0.5518628315863924
Validation loss: 2.588617889998043

Epoch: 352| Step: 0
Training loss: 0.9828980279772105
Validation loss: 2.6019956935186634

Epoch: 6| Step: 1
Training loss: 0.9678058946018875
Validation loss: 2.601263762575614

Epoch: 6| Step: 2
Training loss: 0.820835273921112
Validation loss: 2.596269380518046

Epoch: 6| Step: 3
Training loss: 0.7365474627209697
Validation loss: 2.5797855303540533

Epoch: 6| Step: 4
Training loss: 1.1037255011633713
Validation loss: 2.600489447230892

Epoch: 6| Step: 5
Training loss: 0.8399619085894101
Validation loss: 2.6038963494234877

Epoch: 6| Step: 6
Training loss: 1.2245084243366242
Validation loss: 2.555770230635713

Epoch: 6| Step: 7
Training loss: 0.4669150039406771
Validation loss: 2.548373799687196

Epoch: 6| Step: 8
Training loss: 0.761798482781119
Validation loss: 2.5755624982482104

Epoch: 6| Step: 9
Training loss: 0.6822791620132673
Validation loss: 2.569056217905955

Epoch: 6| Step: 10
Training loss: 0.5653785590212239
Validation loss: 2.5639923456244875

Epoch: 6| Step: 11
Training loss: 0.650586531177022
Validation loss: 2.592439211800617

Epoch: 6| Step: 12
Training loss: 0.777498047817024
Validation loss: 2.602359023925055

Epoch: 6| Step: 13
Training loss: 0.4914613999075285
Validation loss: 2.6006288615508244

Epoch: 353| Step: 0
Training loss: 0.9252228803435187
Validation loss: 2.615972881059226

Epoch: 6| Step: 1
Training loss: 0.7279991384936045
Validation loss: 2.587270236315111

Epoch: 6| Step: 2
Training loss: 0.855738314306704
Validation loss: 2.6189442938351593

Epoch: 6| Step: 3
Training loss: 0.8447377816045077
Validation loss: 2.6158725344951588

Epoch: 6| Step: 4
Training loss: 0.62403399200349
Validation loss: 2.6745737768024145

Epoch: 6| Step: 5
Training loss: 0.58116987352915
Validation loss: 2.630396396505342

Epoch: 6| Step: 6
Training loss: 0.9558920171516679
Validation loss: 2.658709707151664

Epoch: 6| Step: 7
Training loss: 0.9766268594514904
Validation loss: 2.6612057979133845

Epoch: 6| Step: 8
Training loss: 0.7364384899856322
Validation loss: 2.6118730899273084

Epoch: 6| Step: 9
Training loss: 0.869798869638066
Validation loss: 2.6532947152975725

Epoch: 6| Step: 10
Training loss: 0.6779867796073137
Validation loss: 2.6261388883443497

Epoch: 6| Step: 11
Training loss: 0.624260226173955
Validation loss: 2.608263251112622

Epoch: 6| Step: 12
Training loss: 0.9934228130549685
Validation loss: 2.583354938613886

Epoch: 6| Step: 13
Training loss: 0.7689814273491331
Validation loss: 2.572474998045606

Epoch: 354| Step: 0
Training loss: 0.599056000970283
Validation loss: 2.550826676459561

Epoch: 6| Step: 1
Training loss: 0.7063533631364124
Validation loss: 2.5241659450178227

Epoch: 6| Step: 2
Training loss: 1.2024726089720563
Validation loss: 2.5607403231514927

Epoch: 6| Step: 3
Training loss: 0.3740683944416194
Validation loss: 2.5850767130481325

Epoch: 6| Step: 4
Training loss: 0.9019231435254238
Validation loss: 2.598822585191179

Epoch: 6| Step: 5
Training loss: 0.9460222401514864
Validation loss: 2.6351487023782165

Epoch: 6| Step: 6
Training loss: 0.38474889418732466
Validation loss: 2.6359449060911797

Epoch: 6| Step: 7
Training loss: 0.8815301341674151
Validation loss: 2.65046057310051

Epoch: 6| Step: 8
Training loss: 0.872502782538494
Validation loss: 2.630955885670513

Epoch: 6| Step: 9
Training loss: 0.7207385212132714
Validation loss: 2.5978938790110635

Epoch: 6| Step: 10
Training loss: 0.83539103534474
Validation loss: 2.5573140232696288

Epoch: 6| Step: 11
Training loss: 1.0681529290223628
Validation loss: 2.5075980039689565

Epoch: 6| Step: 12
Training loss: 0.6701886060343265
Validation loss: 2.518878856819264

Epoch: 6| Step: 13
Training loss: 0.6743147709831502
Validation loss: 2.5159192095066243

Epoch: 355| Step: 0
Training loss: 1.0268154163684884
Validation loss: 2.488953037480269

Epoch: 6| Step: 1
Training loss: 1.0839891588260149
Validation loss: 2.5118559396055704

Epoch: 6| Step: 2
Training loss: 0.5446356017994105
Validation loss: 2.5348285277598923

Epoch: 6| Step: 3
Training loss: 0.5836058445587493
Validation loss: 2.5155247728389716

Epoch: 6| Step: 4
Training loss: 0.47923696216545214
Validation loss: 2.5419474558773203

Epoch: 6| Step: 5
Training loss: 0.75527379420913
Validation loss: 2.5498574017061877

Epoch: 6| Step: 6
Training loss: 0.8846217832206313
Validation loss: 2.5419180766055613

Epoch: 6| Step: 7
Training loss: 0.7292288799084979
Validation loss: 2.538032098258205

Epoch: 6| Step: 8
Training loss: 0.8363380542007136
Validation loss: 2.531432821866723

Epoch: 6| Step: 9
Training loss: 0.8405142658005584
Validation loss: 2.5394526729751834

Epoch: 6| Step: 10
Training loss: 0.9012668673647177
Validation loss: 2.543716434917333

Epoch: 6| Step: 11
Training loss: 0.7188702358352644
Validation loss: 2.5407343391238606

Epoch: 6| Step: 12
Training loss: 0.5276701588106459
Validation loss: 2.585089479270599

Epoch: 6| Step: 13
Training loss: 1.2221847941466937
Validation loss: 2.5908339963871274

Epoch: 356| Step: 0
Training loss: 0.6333250160256736
Validation loss: 2.575434835746716

Epoch: 6| Step: 1
Training loss: 0.8134585008757006
Validation loss: 2.5940223231638324

Epoch: 6| Step: 2
Training loss: 0.6447869920535463
Validation loss: 2.586552911686899

Epoch: 6| Step: 3
Training loss: 1.0839290570414895
Validation loss: 2.6091820312263097

Epoch: 6| Step: 4
Training loss: 0.9318738921252905
Validation loss: 2.587732748523915

Epoch: 6| Step: 5
Training loss: 0.7441963315122382
Validation loss: 2.521637043927345

Epoch: 6| Step: 6
Training loss: 1.0868849977512764
Validation loss: 2.4616686118942046

Epoch: 6| Step: 7
Training loss: 0.8857944729649571
Validation loss: 2.467598564936007

Epoch: 6| Step: 8
Training loss: 0.987626654313226
Validation loss: 2.4837970934739886

Epoch: 6| Step: 9
Training loss: 1.0238268162712805
Validation loss: 2.5207455620722783

Epoch: 6| Step: 10
Training loss: 0.9592576268866959
Validation loss: 2.5886310700524158

Epoch: 6| Step: 11
Training loss: 0.9233892257129606
Validation loss: 2.61297710227036

Epoch: 6| Step: 12
Training loss: 0.8197469669226597
Validation loss: 2.593643338742878

Epoch: 6| Step: 13
Training loss: 1.4152231248097298
Validation loss: 2.5720385688419007

Epoch: 357| Step: 0
Training loss: 1.2178062795510027
Validation loss: 2.674053610041814

Epoch: 6| Step: 1
Training loss: 1.3116950791241269
Validation loss: 2.6289703113153635

Epoch: 6| Step: 2
Training loss: 1.2115128657672924
Validation loss: 2.6015550462465167

Epoch: 6| Step: 3
Training loss: 0.7776664945676078
Validation loss: 2.539720579677843

Epoch: 6| Step: 4
Training loss: 1.0194086461504899
Validation loss: 2.5262063266549357

Epoch: 6| Step: 5
Training loss: 0.7953705142582776
Validation loss: 2.473273610994743

Epoch: 6| Step: 6
Training loss: 1.09993401676296
Validation loss: 2.4732965650092837

Epoch: 6| Step: 7
Training loss: 1.039808192171791
Validation loss: 2.474364320940693

Epoch: 6| Step: 8
Training loss: 1.1233493563436554
Validation loss: 2.4866437798694725

Epoch: 6| Step: 9
Training loss: 0.9084258431971765
Validation loss: 2.5659623474434037

Epoch: 6| Step: 10
Training loss: 1.019188483486355
Validation loss: 2.5852689603492895

Epoch: 6| Step: 11
Training loss: 0.8092814299354952
Validation loss: 2.5600879661222247

Epoch: 6| Step: 12
Training loss: 0.7151789061925005
Validation loss: 2.583927989823816

Epoch: 6| Step: 13
Training loss: 0.8271292692122985
Validation loss: 2.548211774685741

Epoch: 358| Step: 0
Training loss: 1.2575357736917718
Validation loss: 2.5016137821150504

Epoch: 6| Step: 1
Training loss: 0.7599200015879807
Validation loss: 2.521232120541362

Epoch: 6| Step: 2
Training loss: 0.8322888902244681
Validation loss: 2.547182799461805

Epoch: 6| Step: 3
Training loss: 0.6579524618473084
Validation loss: 2.598081530400786

Epoch: 6| Step: 4
Training loss: 1.1053343242963698
Validation loss: 2.645813355109227

Epoch: 6| Step: 5
Training loss: 0.9357479253731145
Validation loss: 2.6979841276999217

Epoch: 6| Step: 6
Training loss: 0.9879814567756295
Validation loss: 2.7274299508909543

Epoch: 6| Step: 7
Training loss: 0.888528632053115
Validation loss: 2.694642214115015

Epoch: 6| Step: 8
Training loss: 0.9364855045595977
Validation loss: 2.648520115033195

Epoch: 6| Step: 9
Training loss: 1.0015105521169445
Validation loss: 2.617620254513671

Epoch: 6| Step: 10
Training loss: 1.0216838576243215
Validation loss: 2.568660078377766

Epoch: 6| Step: 11
Training loss: 0.6473716800896989
Validation loss: 2.551831778776713

Epoch: 6| Step: 12
Training loss: 0.48946724861390645
Validation loss: 2.56933078294601

Epoch: 6| Step: 13
Training loss: 1.3148288501568457
Validation loss: 2.5740815833087707

Epoch: 359| Step: 0
Training loss: 0.8014578589238097
Validation loss: 2.600874552940486

Epoch: 6| Step: 1
Training loss: 0.7568592092566266
Validation loss: 2.612327987602255

Epoch: 6| Step: 2
Training loss: 0.9548018042131436
Validation loss: 2.6559993473625565

Epoch: 6| Step: 3
Training loss: 1.082102528782389
Validation loss: 2.740203378008386

Epoch: 6| Step: 4
Training loss: 0.8858768987364812
Validation loss: 2.7592974953598577

Epoch: 6| Step: 5
Training loss: 0.8655390149319231
Validation loss: 2.7440522133356553

Epoch: 6| Step: 6
Training loss: 0.8883433311059642
Validation loss: 2.6951640274412862

Epoch: 6| Step: 7
Training loss: 0.7309211105459784
Validation loss: 2.6615775568293807

Epoch: 6| Step: 8
Training loss: 0.8835557829965902
Validation loss: 2.5994405491248282

Epoch: 6| Step: 9
Training loss: 0.7987848843760884
Validation loss: 2.5784857866968793

Epoch: 6| Step: 10
Training loss: 0.43237414971097354
Validation loss: 2.607022571118749

Epoch: 6| Step: 11
Training loss: 1.073364084279118
Validation loss: 2.608258608910386

Epoch: 6| Step: 12
Training loss: 0.9466524951729259
Validation loss: 2.636877411353227

Epoch: 6| Step: 13
Training loss: 1.1386272755389792
Validation loss: 2.6406756796248017

Epoch: 360| Step: 0
Training loss: 0.7922279392732863
Validation loss: 2.661138990548775

Epoch: 6| Step: 1
Training loss: 1.0393711864885482
Validation loss: 2.6859558354913458

Epoch: 6| Step: 2
Training loss: 0.794484648561619
Validation loss: 2.7291149938282375

Epoch: 6| Step: 3
Training loss: 0.8649710777717498
Validation loss: 2.7171099860914003

Epoch: 6| Step: 4
Training loss: 1.0659559927225046
Validation loss: 2.6867865769509485

Epoch: 6| Step: 5
Training loss: 0.8047931935052874
Validation loss: 2.677678412956229

Epoch: 6| Step: 6
Training loss: 0.9918364557133649
Validation loss: 2.631647337503569

Epoch: 6| Step: 7
Training loss: 0.8804446510733472
Validation loss: 2.5881568449495163

Epoch: 6| Step: 8
Training loss: 0.6237497699714191
Validation loss: 2.578715402289948

Epoch: 6| Step: 9
Training loss: 0.8210586424199248
Validation loss: 2.5390396084317537

Epoch: 6| Step: 10
Training loss: 0.44888387720566114
Validation loss: 2.5607086601347784

Epoch: 6| Step: 11
Training loss: 0.7469338685142854
Validation loss: 2.614214275731425

Epoch: 6| Step: 12
Training loss: 0.9396396380440455
Validation loss: 2.645888503273553

Epoch: 6| Step: 13
Training loss: 0.758129722033306
Validation loss: 2.6647349566147502

Epoch: 361| Step: 0
Training loss: 0.9187885276345578
Validation loss: 2.701961475095471

Epoch: 6| Step: 1
Training loss: 0.981524746085882
Validation loss: 2.6415838840451022

Epoch: 6| Step: 2
Training loss: 0.6446995139840129
Validation loss: 2.5752713327393195

Epoch: 6| Step: 3
Training loss: 0.5732585378261427
Validation loss: 2.54853536373252

Epoch: 6| Step: 4
Training loss: 0.9551522629871647
Validation loss: 2.5349806579993017

Epoch: 6| Step: 5
Training loss: 0.9931192303556555
Validation loss: 2.5097162366256045

Epoch: 6| Step: 6
Training loss: 0.6721064811980354
Validation loss: 2.5411744194981254

Epoch: 6| Step: 7
Training loss: 0.9095655824924489
Validation loss: 2.5884191040396862

Epoch: 6| Step: 8
Training loss: 1.0144324123190827
Validation loss: 2.6188260949340245

Epoch: 6| Step: 9
Training loss: 1.0255447707797936
Validation loss: 2.6720415605673282

Epoch: 6| Step: 10
Training loss: 0.6644564862309232
Validation loss: 2.6711695887142417

Epoch: 6| Step: 11
Training loss: 0.4831410657276727
Validation loss: 2.6126240670160517

Epoch: 6| Step: 12
Training loss: 0.5573602141057207
Validation loss: 2.572272556670051

Epoch: 6| Step: 13
Training loss: 0.9170385314475531
Validation loss: 2.519285324875772

Epoch: 362| Step: 0
Training loss: 0.6309968544644334
Validation loss: 2.533570897093004

Epoch: 6| Step: 1
Training loss: 0.5465600878148098
Validation loss: 2.510628347995367

Epoch: 6| Step: 2
Training loss: 0.8621651870367761
Validation loss: 2.4927937346372144

Epoch: 6| Step: 3
Training loss: 0.7709755293825727
Validation loss: 2.521716870592739

Epoch: 6| Step: 4
Training loss: 0.850588390114683
Validation loss: 2.5324425966139237

Epoch: 6| Step: 5
Training loss: 0.7970565140382078
Validation loss: 2.568841447353396

Epoch: 6| Step: 6
Training loss: 0.7984640322343531
Validation loss: 2.659794312140785

Epoch: 6| Step: 7
Training loss: 1.0556141491293307
Validation loss: 2.710541378976881

Epoch: 6| Step: 8
Training loss: 0.7835052744548513
Validation loss: 2.7444650541667603

Epoch: 6| Step: 9
Training loss: 0.6294294278079209
Validation loss: 2.7527939939799584

Epoch: 6| Step: 10
Training loss: 0.7514496938703933
Validation loss: 2.7369919562130485

Epoch: 6| Step: 11
Training loss: 0.7771795664935706
Validation loss: 2.656835979512723

Epoch: 6| Step: 12
Training loss: 0.6734414359418021
Validation loss: 2.6984206835195828

Epoch: 6| Step: 13
Training loss: 0.8680555792914493
Validation loss: 2.654738235483736

Epoch: 363| Step: 0
Training loss: 1.0431477253828605
Validation loss: 2.6410101823039502

Epoch: 6| Step: 1
Training loss: 0.6528671586166328
Validation loss: 2.631227420418394

Epoch: 6| Step: 2
Training loss: 0.6933763528813749
Validation loss: 2.634544144141043

Epoch: 6| Step: 3
Training loss: 0.7308148466865474
Validation loss: 2.6105089372166543

Epoch: 6| Step: 4
Training loss: 1.1243128267309257
Validation loss: 2.626200076915665

Epoch: 6| Step: 5
Training loss: 0.6681040576618034
Validation loss: 2.6161087038756987

Epoch: 6| Step: 6
Training loss: 0.49154434871445774
Validation loss: 2.6325300144305634

Epoch: 6| Step: 7
Training loss: 0.7004158811169572
Validation loss: 2.6407557153747585

Epoch: 6| Step: 8
Training loss: 0.9838930191330534
Validation loss: 2.661589533273901

Epoch: 6| Step: 9
Training loss: 0.5682579028599165
Validation loss: 2.6156988963379066

Epoch: 6| Step: 10
Training loss: 0.5722635939630394
Validation loss: 2.6522037705307784

Epoch: 6| Step: 11
Training loss: 0.6475535883139802
Validation loss: 2.620556749346251

Epoch: 6| Step: 12
Training loss: 0.9468391953047198
Validation loss: 2.6173866505982084

Epoch: 6| Step: 13
Training loss: 0.5458676460876648
Validation loss: 2.5748731562603333

Epoch: 364| Step: 0
Training loss: 0.7929511608559556
Validation loss: 2.6628550166703295

Epoch: 6| Step: 1
Training loss: 0.6437651271339003
Validation loss: 2.6141159083642043

Epoch: 6| Step: 2
Training loss: 0.9322913754141298
Validation loss: 2.5964537078644843

Epoch: 6| Step: 3
Training loss: 0.5595585953316212
Validation loss: 2.619776828945415

Epoch: 6| Step: 4
Training loss: 0.7610582667086815
Validation loss: 2.6943847609960723

Epoch: 6| Step: 5
Training loss: 0.5734091780318188
Validation loss: 2.7037404597548753

Epoch: 6| Step: 6
Training loss: 1.0215305296060295
Validation loss: 2.656436365913898

Epoch: 6| Step: 7
Training loss: 0.5886412989137357
Validation loss: 2.6768607121279406

Epoch: 6| Step: 8
Training loss: 0.8640669617356621
Validation loss: 2.6731611091446528

Epoch: 6| Step: 9
Training loss: 0.7358455138820192
Validation loss: 2.6536218041780937

Epoch: 6| Step: 10
Training loss: 0.9815580236896996
Validation loss: 2.6511705836506474

Epoch: 6| Step: 11
Training loss: 0.4842013078411927
Validation loss: 2.6507976543866136

Epoch: 6| Step: 12
Training loss: 0.5510803925355814
Validation loss: 2.6463320992501282

Epoch: 6| Step: 13
Training loss: 0.8600902008836084
Validation loss: 2.660228988517687

Epoch: 365| Step: 0
Training loss: 0.8754632268619421
Validation loss: 2.6016571698770226

Epoch: 6| Step: 1
Training loss: 0.5982394894331401
Validation loss: 2.614669728433817

Epoch: 6| Step: 2
Training loss: 0.8788488411697758
Validation loss: 2.58207495510313

Epoch: 6| Step: 3
Training loss: 0.5968429666681101
Validation loss: 2.6148347091943767

Epoch: 6| Step: 4
Training loss: 0.7965691671470321
Validation loss: 2.629724827814798

Epoch: 6| Step: 5
Training loss: 0.7508712714585153
Validation loss: 2.611975369592629

Epoch: 6| Step: 6
Training loss: 0.7105646937538848
Validation loss: 2.624355743970328

Epoch: 6| Step: 7
Training loss: 0.8786768635122936
Validation loss: 2.6073829966601565

Epoch: 6| Step: 8
Training loss: 0.645316322075191
Validation loss: 2.612264166368094

Epoch: 6| Step: 9
Training loss: 0.595739895045376
Validation loss: 2.587825787491056

Epoch: 6| Step: 10
Training loss: 0.6796829179631271
Validation loss: 2.5830681916510523

Epoch: 6| Step: 11
Training loss: 0.6729625283744824
Validation loss: 2.5616964015085864

Epoch: 6| Step: 12
Training loss: 0.7755900398017177
Validation loss: 2.5640390987840247

Epoch: 6| Step: 13
Training loss: 0.7224318697264708
Validation loss: 2.6047786408687323

Epoch: 366| Step: 0
Training loss: 0.559520965583921
Validation loss: 2.59593905150006

Epoch: 6| Step: 1
Training loss: 0.9056306893306225
Validation loss: 2.59265357282086

Epoch: 6| Step: 2
Training loss: 0.7874573726318846
Validation loss: 2.601604998994449

Epoch: 6| Step: 3
Training loss: 0.6318020465139638
Validation loss: 2.5994173647773975

Epoch: 6| Step: 4
Training loss: 0.46640232602102966
Validation loss: 2.5807586488105243

Epoch: 6| Step: 5
Training loss: 0.8232644509125376
Validation loss: 2.5867011426028457

Epoch: 6| Step: 6
Training loss: 0.8446751926215623
Validation loss: 2.629006127846613

Epoch: 6| Step: 7
Training loss: 0.583371328637811
Validation loss: 2.6481642661240903

Epoch: 6| Step: 8
Training loss: 0.5961272683975342
Validation loss: 2.641880064072796

Epoch: 6| Step: 9
Training loss: 0.598731003342469
Validation loss: 2.6715391473656784

Epoch: 6| Step: 10
Training loss: 0.9604259462935723
Validation loss: 2.6575156538934097

Epoch: 6| Step: 11
Training loss: 0.5807586172074625
Validation loss: 2.5870436626784783

Epoch: 6| Step: 12
Training loss: 0.6818078172141576
Validation loss: 2.6027139450215797

Epoch: 6| Step: 13
Training loss: 0.9636582415744769
Validation loss: 2.6022534039169316

Epoch: 367| Step: 0
Training loss: 0.5734452987681083
Validation loss: 2.5444545819093913

Epoch: 6| Step: 1
Training loss: 0.6753670189142504
Validation loss: 2.5581504209122863

Epoch: 6| Step: 2
Training loss: 0.6099278314298872
Validation loss: 2.6040898019255234

Epoch: 6| Step: 3
Training loss: 0.6910774181764012
Validation loss: 2.6314348767301454

Epoch: 6| Step: 4
Training loss: 0.8761535941949491
Validation loss: 2.654634632371533

Epoch: 6| Step: 5
Training loss: 0.5615281610704858
Validation loss: 2.661206000214354

Epoch: 6| Step: 6
Training loss: 0.4524710145118144
Validation loss: 2.658028167514558

Epoch: 6| Step: 7
Training loss: 0.7511426248474397
Validation loss: 2.6437953095151148

Epoch: 6| Step: 8
Training loss: 0.8417609045570327
Validation loss: 2.6309865585874443

Epoch: 6| Step: 9
Training loss: 1.0338288631593682
Validation loss: 2.6063517485147623

Epoch: 6| Step: 10
Training loss: 0.7673670354722808
Validation loss: 2.570717927318843

Epoch: 6| Step: 11
Training loss: 0.4891002195638563
Validation loss: 2.5800271503313743

Epoch: 6| Step: 12
Training loss: 0.8408954511468839
Validation loss: 2.52264549896288

Epoch: 6| Step: 13
Training loss: 0.581172565716706
Validation loss: 2.556504261032027

Epoch: 368| Step: 0
Training loss: 0.8275112180727366
Validation loss: 2.5460970634367373

Epoch: 6| Step: 1
Training loss: 0.609607138800122
Validation loss: 2.5479169020839096

Epoch: 6| Step: 2
Training loss: 0.6306496380774611
Validation loss: 2.5843078556150414

Epoch: 6| Step: 3
Training loss: 0.7084077954890285
Validation loss: 2.6170739374698493

Epoch: 6| Step: 4
Training loss: 0.3512863346054596
Validation loss: 2.601899224985554

Epoch: 6| Step: 5
Training loss: 0.7279432569282526
Validation loss: 2.686423698349338

Epoch: 6| Step: 6
Training loss: 1.053069845051371
Validation loss: 2.6858129603029175

Epoch: 6| Step: 7
Training loss: 0.5514412030637549
Validation loss: 2.6666348196507035

Epoch: 6| Step: 8
Training loss: 0.5547182853644779
Validation loss: 2.6693761376299294

Epoch: 6| Step: 9
Training loss: 0.6144488451518244
Validation loss: 2.6627809938286133

Epoch: 6| Step: 10
Training loss: 0.5726333061919878
Validation loss: 2.6370657063237437

Epoch: 6| Step: 11
Training loss: 0.6743242068602594
Validation loss: 2.6197173325511547

Epoch: 6| Step: 12
Training loss: 0.9102269419447727
Validation loss: 2.5829603267938333

Epoch: 6| Step: 13
Training loss: 0.8423759079846336
Validation loss: 2.5461101398885013

Epoch: 369| Step: 0
Training loss: 0.853805841823045
Validation loss: 2.5810666492196725

Epoch: 6| Step: 1
Training loss: 0.4492284359095044
Validation loss: 2.5357169303583964

Epoch: 6| Step: 2
Training loss: 0.5211977510314456
Validation loss: 2.6322803940027977

Epoch: 6| Step: 3
Training loss: 0.9583049161816555
Validation loss: 2.598287951453762

Epoch: 6| Step: 4
Training loss: 0.6441157070728056
Validation loss: 2.6039651053574904

Epoch: 6| Step: 5
Training loss: 0.6659932510331865
Validation loss: 2.5991109298962867

Epoch: 6| Step: 6
Training loss: 0.4502070957056793
Validation loss: 2.6108380654889616

Epoch: 6| Step: 7
Training loss: 0.687117079821182
Validation loss: 2.606779817994705

Epoch: 6| Step: 8
Training loss: 0.6829507910314099
Validation loss: 2.627538245893682

Epoch: 6| Step: 9
Training loss: 0.7445157124518236
Validation loss: 2.6193605308495114

Epoch: 6| Step: 10
Training loss: 0.6108220842617155
Validation loss: 2.609620341462874

Epoch: 6| Step: 11
Training loss: 0.8025282992070356
Validation loss: 2.586335614548687

Epoch: 6| Step: 12
Training loss: 0.6960384565285267
Validation loss: 2.548889486809265

Epoch: 6| Step: 13
Training loss: 0.34208830262190104
Validation loss: 2.5716500650587677

Epoch: 370| Step: 0
Training loss: 0.8271757479395967
Validation loss: 2.577025876344081

Epoch: 6| Step: 1
Training loss: 0.5579647177083437
Validation loss: 2.5660101626945306

Epoch: 6| Step: 2
Training loss: 0.6525677279330618
Validation loss: 2.5924642405191194

Epoch: 6| Step: 3
Training loss: 0.5444107119280662
Validation loss: 2.6114233224203356

Epoch: 6| Step: 4
Training loss: 0.8020914292030141
Validation loss: 2.622611653279175

Epoch: 6| Step: 5
Training loss: 0.9016050808006041
Validation loss: 2.6680365422768846

Epoch: 6| Step: 6
Training loss: 0.8404609009489167
Validation loss: 2.650416203337472

Epoch: 6| Step: 7
Training loss: 0.2704533133021541
Validation loss: 2.6667818543208246

Epoch: 6| Step: 8
Training loss: 0.853313151421407
Validation loss: 2.6680274850854766

Epoch: 6| Step: 9
Training loss: 0.6097306900720522
Validation loss: 2.634644646540906

Epoch: 6| Step: 10
Training loss: 0.3081502866718284
Validation loss: 2.604250410804866

Epoch: 6| Step: 11
Training loss: 0.5480436916354028
Validation loss: 2.5618961191926615

Epoch: 6| Step: 12
Training loss: 0.8306019285971877
Validation loss: 2.5148848852063166

Epoch: 6| Step: 13
Training loss: 0.679148032414495
Validation loss: 2.5176300351765644

Epoch: 371| Step: 0
Training loss: 0.7405826282854853
Validation loss: 2.5118090084317557

Epoch: 6| Step: 1
Training loss: 0.6170991279011104
Validation loss: 2.5122882167667977

Epoch: 6| Step: 2
Training loss: 0.5015317580644609
Validation loss: 2.527324495313369

Epoch: 6| Step: 3
Training loss: 0.8055752422039162
Validation loss: 2.5789027726640037

Epoch: 6| Step: 4
Training loss: 0.44104384001765645
Validation loss: 2.6044968334624894

Epoch: 6| Step: 5
Training loss: 0.8426160963872935
Validation loss: 2.6432709912108336

Epoch: 6| Step: 6
Training loss: 0.7052278438970149
Validation loss: 2.682235982579536

Epoch: 6| Step: 7
Training loss: 0.820180101155038
Validation loss: 2.6704704787519096

Epoch: 6| Step: 8
Training loss: 0.7725475084331416
Validation loss: 2.6676487187893527

Epoch: 6| Step: 9
Training loss: 0.46341813688154165
Validation loss: 2.621567725047652

Epoch: 6| Step: 10
Training loss: 0.6148629172220361
Validation loss: 2.613564515389866

Epoch: 6| Step: 11
Training loss: 0.7266619624487237
Validation loss: 2.58748408431515

Epoch: 6| Step: 12
Training loss: 0.6932757689882884
Validation loss: 2.533063925537985

Epoch: 6| Step: 13
Training loss: 0.42212450631891946
Validation loss: 2.5407856430141185

Epoch: 372| Step: 0
Training loss: 0.7675882586327138
Validation loss: 2.5520895788146882

Epoch: 6| Step: 1
Training loss: 0.7399702179560432
Validation loss: 2.5196383444037083

Epoch: 6| Step: 2
Training loss: 0.7440736595319889
Validation loss: 2.551473497897526

Epoch: 6| Step: 3
Training loss: 0.5694566078618577
Validation loss: 2.5806772733813124

Epoch: 6| Step: 4
Training loss: 0.5563411509378096
Validation loss: 2.6056677720500394

Epoch: 6| Step: 5
Training loss: 0.45855509385493
Validation loss: 2.6026158049292714

Epoch: 6| Step: 6
Training loss: 0.6905986573731833
Validation loss: 2.5786891793524327

Epoch: 6| Step: 7
Training loss: 0.8780809045220844
Validation loss: 2.596275749449537

Epoch: 6| Step: 8
Training loss: 0.5468796866079876
Validation loss: 2.632594642938144

Epoch: 6| Step: 9
Training loss: 0.4749924326595042
Validation loss: 2.648673530999414

Epoch: 6| Step: 10
Training loss: 0.5095236485302327
Validation loss: 2.635510594515944

Epoch: 6| Step: 11
Training loss: 0.5711959110838264
Validation loss: 2.660043408749542

Epoch: 6| Step: 12
Training loss: 0.7287372732605205
Validation loss: 2.6593333445658556

Epoch: 6| Step: 13
Training loss: 0.68276037370755
Validation loss: 2.611248995700252

Epoch: 373| Step: 0
Training loss: 0.6246537680055851
Validation loss: 2.585677044044385

Epoch: 6| Step: 1
Training loss: 0.5535284478338401
Validation loss: 2.5213583190489133

Epoch: 6| Step: 2
Training loss: 0.621556020044119
Validation loss: 2.5214191638446355

Epoch: 6| Step: 3
Training loss: 0.4508456251962509
Validation loss: 2.5645787561057114

Epoch: 6| Step: 4
Training loss: 0.6645147242353521
Validation loss: 2.588732002176605

Epoch: 6| Step: 5
Training loss: 0.5759446811487059
Validation loss: 2.592862155784501

Epoch: 6| Step: 6
Training loss: 0.6158161863702384
Validation loss: 2.6000192495569014

Epoch: 6| Step: 7
Training loss: 0.7535363114890642
Validation loss: 2.6107476607741553

Epoch: 6| Step: 8
Training loss: 0.7200123026909374
Validation loss: 2.63424982337878

Epoch: 6| Step: 9
Training loss: 0.8603871021009851
Validation loss: 2.626872578194341

Epoch: 6| Step: 10
Training loss: 0.4396171772238884
Validation loss: 2.598467563722135

Epoch: 6| Step: 11
Training loss: 0.6381311022908518
Validation loss: 2.597329398980304

Epoch: 6| Step: 12
Training loss: 0.7420199958106869
Validation loss: 2.5974327852975683

Epoch: 6| Step: 13
Training loss: 0.901331081473154
Validation loss: 2.5526917955043675

Epoch: 374| Step: 0
Training loss: 0.4592645155461393
Validation loss: 2.544312172676241

Epoch: 6| Step: 1
Training loss: 0.7990135593218641
Validation loss: 2.5626984085997937

Epoch: 6| Step: 2
Training loss: 0.6457783973053051
Validation loss: 2.5859490366359505

Epoch: 6| Step: 3
Training loss: 0.7269047167042602
Validation loss: 2.5974837746834347

Epoch: 6| Step: 4
Training loss: 0.7991836987637194
Validation loss: 2.6163576495580854

Epoch: 6| Step: 5
Training loss: 0.574466158966611
Validation loss: 2.574483068739889

Epoch: 6| Step: 6
Training loss: 0.668067211010675
Validation loss: 2.5964828783339007

Epoch: 6| Step: 7
Training loss: 0.6577837142626333
Validation loss: 2.6157559726884774

Epoch: 6| Step: 8
Training loss: 0.7156623364166371
Validation loss: 2.6205085147621867

Epoch: 6| Step: 9
Training loss: 0.6507189039611121
Validation loss: 2.610027123917984

Epoch: 6| Step: 10
Training loss: 0.41408520762238854
Validation loss: 2.6139466600903445

Epoch: 6| Step: 11
Training loss: 0.5074791327541389
Validation loss: 2.5784624417729223

Epoch: 6| Step: 12
Training loss: 0.5543183723781241
Validation loss: 2.551582294943924

Epoch: 6| Step: 13
Training loss: 0.8964717756063326
Validation loss: 2.5413723715896173

Epoch: 375| Step: 0
Training loss: 0.6691201754160373
Validation loss: 2.5635732318642424

Epoch: 6| Step: 1
Training loss: 0.46959628957471816
Validation loss: 2.5384148962473962

Epoch: 6| Step: 2
Training loss: 0.6645211375041344
Validation loss: 2.5563200390966743

Epoch: 6| Step: 3
Training loss: 0.4790444079900188
Validation loss: 2.5349068366577487

Epoch: 6| Step: 4
Training loss: 0.4692941685956224
Validation loss: 2.5810575043643267

Epoch: 6| Step: 5
Training loss: 0.5998570182427883
Validation loss: 2.5600621041524994

Epoch: 6| Step: 6
Training loss: 0.5684929130434552
Validation loss: 2.5631490366162994

Epoch: 6| Step: 7
Training loss: 0.7061542530479781
Validation loss: 2.5652284480377654

Epoch: 6| Step: 8
Training loss: 0.6821917734960259
Validation loss: 2.6000207985755246

Epoch: 6| Step: 9
Training loss: 0.7537356168725291
Validation loss: 2.6218418474228193

Epoch: 6| Step: 10
Training loss: 0.661972166715199
Validation loss: 2.6532820893146694

Epoch: 6| Step: 11
Training loss: 0.4424140026558169
Validation loss: 2.643679201125556

Epoch: 6| Step: 12
Training loss: 0.8734901890020849
Validation loss: 2.6591813939068634

Epoch: 6| Step: 13
Training loss: 0.694236544377366
Validation loss: 2.59950096769878

Epoch: 376| Step: 0
Training loss: 0.6519882695511896
Validation loss: 2.61208831857089

Epoch: 6| Step: 1
Training loss: 0.3881764537226607
Validation loss: 2.5241525954273625

Epoch: 6| Step: 2
Training loss: 0.9426314426207515
Validation loss: 2.4914924114387054

Epoch: 6| Step: 3
Training loss: 0.7513491892908695
Validation loss: 2.443719922883991

Epoch: 6| Step: 4
Training loss: 0.8361608616829734
Validation loss: 2.485095911625247

Epoch: 6| Step: 5
Training loss: 0.5860717619613293
Validation loss: 2.487270669336396

Epoch: 6| Step: 6
Training loss: 0.48175280425557626
Validation loss: 2.5235061262821192

Epoch: 6| Step: 7
Training loss: 0.5132049643207306
Validation loss: 2.572876170208646

Epoch: 6| Step: 8
Training loss: 0.5535578709581411
Validation loss: 2.6296263601713594

Epoch: 6| Step: 9
Training loss: 0.4738669062733022
Validation loss: 2.6915205033451852

Epoch: 6| Step: 10
Training loss: 0.9950771155258273
Validation loss: 2.680862558019105

Epoch: 6| Step: 11
Training loss: 0.6423167708847801
Validation loss: 2.5826964592300854

Epoch: 6| Step: 12
Training loss: 0.6349627614178448
Validation loss: 2.5130777641494393

Epoch: 6| Step: 13
Training loss: 0.7041939980283352
Validation loss: 2.4373084687992512

Epoch: 377| Step: 0
Training loss: 0.7479360314060959
Validation loss: 2.3932364265735

Epoch: 6| Step: 1
Training loss: 0.6871186195606098
Validation loss: 2.4647287391638537

Epoch: 6| Step: 2
Training loss: 0.6309081256560252
Validation loss: 2.5123166027099475

Epoch: 6| Step: 3
Training loss: 0.8610002235230655
Validation loss: 2.5757669373802172

Epoch: 6| Step: 4
Training loss: 0.4676053854278547
Validation loss: 2.653038197739898

Epoch: 6| Step: 5
Training loss: 0.6707725351239777
Validation loss: 2.69012805546243

Epoch: 6| Step: 6
Training loss: 0.8847144914213124
Validation loss: 2.690533309366466

Epoch: 6| Step: 7
Training loss: 0.606554841548913
Validation loss: 2.7006109969827743

Epoch: 6| Step: 8
Training loss: 0.5594331796321822
Validation loss: 2.668649642458723

Epoch: 6| Step: 9
Training loss: 0.6360006202658741
Validation loss: 2.6496974522768393

Epoch: 6| Step: 10
Training loss: 0.6033491380300487
Validation loss: 2.6320069350969026

Epoch: 6| Step: 11
Training loss: 0.5799859227330144
Validation loss: 2.5781775883407057

Epoch: 6| Step: 12
Training loss: 0.6956339746600614
Validation loss: 2.565291512202769

Epoch: 6| Step: 13
Training loss: 0.8237299622340247
Validation loss: 2.5723591685798346

Epoch: 378| Step: 0
Training loss: 0.8730422666287245
Validation loss: 2.530273345299964

Epoch: 6| Step: 1
Training loss: 0.26510931895607254
Validation loss: 2.523210429005512

Epoch: 6| Step: 2
Training loss: 0.6876650742110051
Validation loss: 2.5356179038283426

Epoch: 6| Step: 3
Training loss: 0.8833811456108372
Validation loss: 2.5396707250241053

Epoch: 6| Step: 4
Training loss: 0.7344910955986481
Validation loss: 2.5697137283753064

Epoch: 6| Step: 5
Training loss: 0.5334951977178488
Validation loss: 2.5614424483353293

Epoch: 6| Step: 6
Training loss: 0.9368624108545787
Validation loss: 2.59767434583195

Epoch: 6| Step: 7
Training loss: 0.6571563411115591
Validation loss: 2.638941121695356

Epoch: 6| Step: 8
Training loss: 0.6843201619652259
Validation loss: 2.6662053476997225

Epoch: 6| Step: 9
Training loss: 0.5699181957269913
Validation loss: 2.641270313462325

Epoch: 6| Step: 10
Training loss: 0.6424328254212706
Validation loss: 2.6563882076396763

Epoch: 6| Step: 11
Training loss: 0.5792395699080208
Validation loss: 2.619150383715999

Epoch: 6| Step: 12
Training loss: 0.5991912775816871
Validation loss: 2.597039128981038

Epoch: 6| Step: 13
Training loss: 0.3507501541662115
Validation loss: 2.5774797116156836

Epoch: 379| Step: 0
Training loss: 0.6333100517494421
Validation loss: 2.5444521597812604

Epoch: 6| Step: 1
Training loss: 0.661588120430658
Validation loss: 2.5137409825667922

Epoch: 6| Step: 2
Training loss: 0.4629770833970338
Validation loss: 2.53586770228894

Epoch: 6| Step: 3
Training loss: 0.5573600002237296
Validation loss: 2.510658791337795

Epoch: 6| Step: 4
Training loss: 0.6327244026179152
Validation loss: 2.53688698078352

Epoch: 6| Step: 5
Training loss: 0.4013081713723568
Validation loss: 2.5910607718764678

Epoch: 6| Step: 6
Training loss: 0.5849947147456676
Validation loss: 2.600397322738642

Epoch: 6| Step: 7
Training loss: 0.6637137899920679
Validation loss: 2.6263227416453674

Epoch: 6| Step: 8
Training loss: 0.8317006488602586
Validation loss: 2.637145388901682

Epoch: 6| Step: 9
Training loss: 0.5768698909281171
Validation loss: 2.6241904581328326

Epoch: 6| Step: 10
Training loss: 0.7226620235727979
Validation loss: 2.6027363612699923

Epoch: 6| Step: 11
Training loss: 0.6913075349672726
Validation loss: 2.5445041252082174

Epoch: 6| Step: 12
Training loss: 0.7563450556513958
Validation loss: 2.5160388813704517

Epoch: 6| Step: 13
Training loss: 0.856804384233618
Validation loss: 2.571355421663634

Epoch: 380| Step: 0
Training loss: 0.4901482707849508
Validation loss: 2.5345901405023357

Epoch: 6| Step: 1
Training loss: 0.6074086767400273
Validation loss: 2.5588499450545243

Epoch: 6| Step: 2
Training loss: 0.899906715221002
Validation loss: 2.6243063356395586

Epoch: 6| Step: 3
Training loss: 0.46513267962239546
Validation loss: 2.6067769281218696

Epoch: 6| Step: 4
Training loss: 0.7057228838839172
Validation loss: 2.6365014588071527

Epoch: 6| Step: 5
Training loss: 0.34488553280178275
Validation loss: 2.627490813681817

Epoch: 6| Step: 6
Training loss: 0.43984472840439165
Validation loss: 2.635752195994829

Epoch: 6| Step: 7
Training loss: 0.721622697079511
Validation loss: 2.625015852529198

Epoch: 6| Step: 8
Training loss: 0.583195232892405
Validation loss: 2.6105315330221144

Epoch: 6| Step: 9
Training loss: 0.4852497753966262
Validation loss: 2.5937922356047087

Epoch: 6| Step: 10
Training loss: 0.6592311584722573
Validation loss: 2.5328133213163113

Epoch: 6| Step: 11
Training loss: 0.5009817082250504
Validation loss: 2.5535741861764962

Epoch: 6| Step: 12
Training loss: 0.7551963717510869
Validation loss: 2.543337913163066

Epoch: 6| Step: 13
Training loss: 0.7697930447398761
Validation loss: 2.534097426854052

Epoch: 381| Step: 0
Training loss: 0.5439056162842805
Validation loss: 2.514976532532488

Epoch: 6| Step: 1
Training loss: 0.5967380975831545
Validation loss: 2.5945082335931136

Epoch: 6| Step: 2
Training loss: 0.5796808751388338
Validation loss: 2.588133248990136

Epoch: 6| Step: 3
Training loss: 0.5047227616879628
Validation loss: 2.579411778863218

Epoch: 6| Step: 4
Training loss: 0.4108084806091547
Validation loss: 2.6032396398311635

Epoch: 6| Step: 5
Training loss: 0.5479929804387164
Validation loss: 2.6245466916157283

Epoch: 6| Step: 6
Training loss: 0.7577416298358991
Validation loss: 2.5948431521185884

Epoch: 6| Step: 7
Training loss: 0.769062964769802
Validation loss: 2.5932082475152622

Epoch: 6| Step: 8
Training loss: 0.47442284203325175
Validation loss: 2.5311712323401694

Epoch: 6| Step: 9
Training loss: 0.5407765820953997
Validation loss: 2.4948084928270684

Epoch: 6| Step: 10
Training loss: 0.7415899983615346
Validation loss: 2.495321906245277

Epoch: 6| Step: 11
Training loss: 0.5673229560203682
Validation loss: 2.473675898355437

Epoch: 6| Step: 12
Training loss: 0.5915708204551791
Validation loss: 2.475713925371113

Epoch: 6| Step: 13
Training loss: 0.8933690279500419
Validation loss: 2.5202373833110285

Epoch: 382| Step: 0
Training loss: 0.31921171986311697
Validation loss: 2.5081770989059757

Epoch: 6| Step: 1
Training loss: 0.5529369077544578
Validation loss: 2.531501579518408

Epoch: 6| Step: 2
Training loss: 0.6131245601236397
Validation loss: 2.5727451697916157

Epoch: 6| Step: 3
Training loss: 0.3599662685154763
Validation loss: 2.5947588695509545

Epoch: 6| Step: 4
Training loss: 0.7069665447154004
Validation loss: 2.588613137793815

Epoch: 6| Step: 5
Training loss: 0.46168480117358135
Validation loss: 2.580366915076843

Epoch: 6| Step: 6
Training loss: 0.6696650732987308
Validation loss: 2.6070804234879956

Epoch: 6| Step: 7
Training loss: 0.524574496770742
Validation loss: 2.6232334370817343

Epoch: 6| Step: 8
Training loss: 0.7094587100207913
Validation loss: 2.5668070747622194

Epoch: 6| Step: 9
Training loss: 0.6859762471927483
Validation loss: 2.572334129611098

Epoch: 6| Step: 10
Training loss: 0.5321045061896004
Validation loss: 2.5784757244441376

Epoch: 6| Step: 11
Training loss: 0.5785235500372417
Validation loss: 2.5579877649131206

Epoch: 6| Step: 12
Training loss: 0.6552746882192213
Validation loss: 2.548619911503745

Epoch: 6| Step: 13
Training loss: 0.6134568710105895
Validation loss: 2.5591918576882526

Epoch: 383| Step: 0
Training loss: 0.34193037423232603
Validation loss: 2.5601380119868358

Epoch: 6| Step: 1
Training loss: 0.5978362616419516
Validation loss: 2.5626207668880525

Epoch: 6| Step: 2
Training loss: 0.7655651302673963
Validation loss: 2.579762853067223

Epoch: 6| Step: 3
Training loss: 0.6723516680698691
Validation loss: 2.5603579650663026

Epoch: 6| Step: 4
Training loss: 0.6401510113387018
Validation loss: 2.5805094710178373

Epoch: 6| Step: 5
Training loss: 0.4218973401123906
Validation loss: 2.5597719787559963

Epoch: 6| Step: 6
Training loss: 0.3262135827358444
Validation loss: 2.599459041817259

Epoch: 6| Step: 7
Training loss: 0.3582310090605063
Validation loss: 2.5699844926542053

Epoch: 6| Step: 8
Training loss: 0.3895081002050547
Validation loss: 2.556567269654036

Epoch: 6| Step: 9
Training loss: 0.7783724624986946
Validation loss: 2.5347080731714584

Epoch: 6| Step: 10
Training loss: 0.41783382341386327
Validation loss: 2.526802451974694

Epoch: 6| Step: 11
Training loss: 0.8311906248412972
Validation loss: 2.501679063762331

Epoch: 6| Step: 12
Training loss: 0.6758462290311599
Validation loss: 2.4975743570258238

Epoch: 6| Step: 13
Training loss: 0.3311926180243771
Validation loss: 2.535312616606899

Epoch: 384| Step: 0
Training loss: 0.4591818364465064
Validation loss: 2.520615890617996

Epoch: 6| Step: 1
Training loss: 0.5326194223175893
Validation loss: 2.52020229196317

Epoch: 6| Step: 2
Training loss: 0.6551542671186343
Validation loss: 2.531666254424848

Epoch: 6| Step: 3
Training loss: 0.35650757546287726
Validation loss: 2.5334525684487126

Epoch: 6| Step: 4
Training loss: 0.3930479436293838
Validation loss: 2.561822597107801

Epoch: 6| Step: 5
Training loss: 0.5431985711771358
Validation loss: 2.5648240631034542

Epoch: 6| Step: 6
Training loss: 0.5664662559556649
Validation loss: 2.58455584441725

Epoch: 6| Step: 7
Training loss: 0.47949116195910885
Validation loss: 2.573367720271166

Epoch: 6| Step: 8
Training loss: 0.6904160472596206
Validation loss: 2.571587081560666

Epoch: 6| Step: 9
Training loss: 0.8166421065886825
Validation loss: 2.556505144491149

Epoch: 6| Step: 10
Training loss: 0.7264905094044032
Validation loss: 2.5593808156300164

Epoch: 6| Step: 11
Training loss: 0.45267628781754915
Validation loss: 2.5340189755869797

Epoch: 6| Step: 12
Training loss: 0.5282153238558785
Validation loss: 2.5386061775330404

Epoch: 6| Step: 13
Training loss: 0.40873522962195535
Validation loss: 2.5375276465945382

Epoch: 385| Step: 0
Training loss: 0.6624764294300013
Validation loss: 2.538832328971608

Epoch: 6| Step: 1
Training loss: 0.2783689757518752
Validation loss: 2.5169403025066504

Epoch: 6| Step: 2
Training loss: 0.23550870405804422
Validation loss: 2.5649384882289197

Epoch: 6| Step: 3
Training loss: 0.7503485664364657
Validation loss: 2.5976020698161615

Epoch: 6| Step: 4
Training loss: 0.8746726241078479
Validation loss: 2.563482346863674

Epoch: 6| Step: 5
Training loss: 0.7597704105177453
Validation loss: 2.547585963960685

Epoch: 6| Step: 6
Training loss: 0.5314765895737014
Validation loss: 2.5495346629590667

Epoch: 6| Step: 7
Training loss: 0.43330407991458353
Validation loss: 2.5497151728272347

Epoch: 6| Step: 8
Training loss: 0.40263284093380514
Validation loss: 2.56078411231732

Epoch: 6| Step: 9
Training loss: 0.5347195535100532
Validation loss: 2.575673636008149

Epoch: 6| Step: 10
Training loss: 0.4911259298920172
Validation loss: 2.596027768747271

Epoch: 6| Step: 11
Training loss: 0.3987002908580744
Validation loss: 2.611217969684424

Epoch: 6| Step: 12
Training loss: 0.439102796151205
Validation loss: 2.591501563372803

Epoch: 6| Step: 13
Training loss: 0.6524375802361718
Validation loss: 2.5962148075152705

Epoch: 386| Step: 0
Training loss: 0.6437571645541705
Validation loss: 2.6014351200639005

Epoch: 6| Step: 1
Training loss: 0.39047856447143936
Validation loss: 2.5999142345910617

Epoch: 6| Step: 2
Training loss: 0.6926914705408618
Validation loss: 2.590627794345757

Epoch: 6| Step: 3
Training loss: 0.5879581957540657
Validation loss: 2.5466653825792838

Epoch: 6| Step: 4
Training loss: 0.6858597174753441
Validation loss: 2.5588152514876974

Epoch: 6| Step: 5
Training loss: 0.4322741593029135
Validation loss: 2.533451405757213

Epoch: 6| Step: 6
Training loss: 0.40691792160625534
Validation loss: 2.54315894911273

Epoch: 6| Step: 7
Training loss: 0.7087035240261198
Validation loss: 2.54801856963174

Epoch: 6| Step: 8
Training loss: 0.49467284298339415
Validation loss: 2.5215890633476215

Epoch: 6| Step: 9
Training loss: 0.4726388786213285
Validation loss: 2.547365102311843

Epoch: 6| Step: 10
Training loss: 0.5099853977282056
Validation loss: 2.544013784626814

Epoch: 6| Step: 11
Training loss: 0.6968165428721123
Validation loss: 2.5663898436464145

Epoch: 6| Step: 12
Training loss: 0.2456225394958066
Validation loss: 2.528830186539081

Epoch: 6| Step: 13
Training loss: 0.5105463531421426
Validation loss: 2.5643009807041364

Epoch: 387| Step: 0
Training loss: 0.5504560931155857
Validation loss: 2.527001268150485

Epoch: 6| Step: 1
Training loss: 0.39900710958944335
Validation loss: 2.552669457003394

Epoch: 6| Step: 2
Training loss: 0.5595420044667331
Validation loss: 2.5240867127831574

Epoch: 6| Step: 3
Training loss: 0.6299864691083555
Validation loss: 2.528090795070623

Epoch: 6| Step: 4
Training loss: 0.6009349026279189
Validation loss: 2.57291567359305

Epoch: 6| Step: 5
Training loss: 0.642462119904304
Validation loss: 2.5437847020696625

Epoch: 6| Step: 6
Training loss: 0.40741333920542755
Validation loss: 2.5355570034126154

Epoch: 6| Step: 7
Training loss: 0.6577118078443529
Validation loss: 2.570747053247155

Epoch: 6| Step: 8
Training loss: 0.5357530148448483
Validation loss: 2.586324075176585

Epoch: 6| Step: 9
Training loss: 0.5890320504410931
Validation loss: 2.594687626332453

Epoch: 6| Step: 10
Training loss: 0.6807570537603755
Validation loss: 2.595239890646066

Epoch: 6| Step: 11
Training loss: 0.19326687536545262
Validation loss: 2.6041542079176314

Epoch: 6| Step: 12
Training loss: 0.40218372310593037
Validation loss: 2.570988510556072

Epoch: 6| Step: 13
Training loss: 0.6032902318310053
Validation loss: 2.540179513684439

Epoch: 388| Step: 0
Training loss: 0.4519370060505078
Validation loss: 2.528204733515801

Epoch: 6| Step: 1
Training loss: 0.7996665080670476
Validation loss: 2.554347444854356

Epoch: 6| Step: 2
Training loss: 0.32551253371784383
Validation loss: 2.571913949040556

Epoch: 6| Step: 3
Training loss: 0.6303074551230563
Validation loss: 2.562095716245251

Epoch: 6| Step: 4
Training loss: 0.6326711520349881
Validation loss: 2.5615441865517616

Epoch: 6| Step: 5
Training loss: 0.6055768562526244
Validation loss: 2.5627849999627386

Epoch: 6| Step: 6
Training loss: 0.41491551972745494
Validation loss: 2.5605927879959345

Epoch: 6| Step: 7
Training loss: 0.30772054237795937
Validation loss: 2.5549026493492315

Epoch: 6| Step: 8
Training loss: 0.5465486915375194
Validation loss: 2.558319533500825

Epoch: 6| Step: 9
Training loss: 0.48522391837895396
Validation loss: 2.524197190949237

Epoch: 6| Step: 10
Training loss: 0.6061060351085302
Validation loss: 2.530997043510152

Epoch: 6| Step: 11
Training loss: 0.3460656759616869
Validation loss: 2.5221717032207636

Epoch: 6| Step: 12
Training loss: 0.5744557053959246
Validation loss: 2.5532038582909884

Epoch: 6| Step: 13
Training loss: 0.7420371857062527
Validation loss: 2.553655554387469

Epoch: 389| Step: 0
Training loss: 0.5513439145177951
Validation loss: 2.5678492272403344

Epoch: 6| Step: 1
Training loss: 0.6668913556982873
Validation loss: 2.556503039631739

Epoch: 6| Step: 2
Training loss: 0.6627955973842705
Validation loss: 2.55964595798721

Epoch: 6| Step: 3
Training loss: 0.5240845737346557
Validation loss: 2.5991614306747888

Epoch: 6| Step: 4
Training loss: 0.30225560877402197
Validation loss: 2.5970419038294783

Epoch: 6| Step: 5
Training loss: 0.4105217894231889
Validation loss: 2.5643842119142617

Epoch: 6| Step: 6
Training loss: 0.6183028705587049
Validation loss: 2.5670296357089177

Epoch: 6| Step: 7
Training loss: 0.4587689807405717
Validation loss: 2.6012252879278837

Epoch: 6| Step: 8
Training loss: 0.4238090159243877
Validation loss: 2.588153243388871

Epoch: 6| Step: 9
Training loss: 0.6993505470903204
Validation loss: 2.549447497866961

Epoch: 6| Step: 10
Training loss: 0.2857261215146896
Validation loss: 2.5892684258639993

Epoch: 6| Step: 11
Training loss: 0.5208442273590085
Validation loss: 2.588446054908604

Epoch: 6| Step: 12
Training loss: 0.491672124940133
Validation loss: 2.5859916802036067

Epoch: 6| Step: 13
Training loss: 0.7606463586195391
Validation loss: 2.610733775872322

Epoch: 390| Step: 0
Training loss: 0.4760181413537359
Validation loss: 2.588516531023103

Epoch: 6| Step: 1
Training loss: 0.6252043866705927
Validation loss: 2.562857238055019

Epoch: 6| Step: 2
Training loss: 0.6432750598015702
Validation loss: 2.5700364515527667

Epoch: 6| Step: 3
Training loss: 0.49173715969711884
Validation loss: 2.579594114675681

Epoch: 6| Step: 4
Training loss: 0.5506946414462369
Validation loss: 2.5567496343319354

Epoch: 6| Step: 5
Training loss: 0.4730433148124909
Validation loss: 2.5511793580242097

Epoch: 6| Step: 6
Training loss: 0.6716890743184277
Validation loss: 2.5702673132002336

Epoch: 6| Step: 7
Training loss: 0.4577824214910157
Validation loss: 2.535295167738958

Epoch: 6| Step: 8
Training loss: 0.43705880534780045
Validation loss: 2.548652186403672

Epoch: 6| Step: 9
Training loss: 0.6502871960946429
Validation loss: 2.5867475477583466

Epoch: 6| Step: 10
Training loss: 0.6072158709468557
Validation loss: 2.60462317093594

Epoch: 6| Step: 11
Training loss: 0.5491664834473245
Validation loss: 2.57280590537532

Epoch: 6| Step: 12
Training loss: 0.3702250099647856
Validation loss: 2.6124990329896667

Epoch: 6| Step: 13
Training loss: 0.33721808385867164
Validation loss: 2.5584522485294214

Epoch: 391| Step: 0
Training loss: 0.3340494192932864
Validation loss: 2.533335922231253

Epoch: 6| Step: 1
Training loss: 0.5504061997905854
Validation loss: 2.4901429536474837

Epoch: 6| Step: 2
Training loss: 0.4128814082709456
Validation loss: 2.469342867867379

Epoch: 6| Step: 3
Training loss: 0.5302327458345524
Validation loss: 2.477698883202706

Epoch: 6| Step: 4
Training loss: 0.3919889289328974
Validation loss: 2.460260087375533

Epoch: 6| Step: 5
Training loss: 0.6215210889980858
Validation loss: 2.494194435224425

Epoch: 6| Step: 6
Training loss: 0.5538084021742692
Validation loss: 2.5193946826168494

Epoch: 6| Step: 7
Training loss: 0.7653573015837273
Validation loss: 2.551672053561251

Epoch: 6| Step: 8
Training loss: 0.5065311698944106
Validation loss: 2.524837214273577

Epoch: 6| Step: 9
Training loss: 0.3146652311914307
Validation loss: 2.5481081257962095

Epoch: 6| Step: 10
Training loss: 0.5098315375382587
Validation loss: 2.547787738623976

Epoch: 6| Step: 11
Training loss: 0.4194743233246316
Validation loss: 2.577500155175497

Epoch: 6| Step: 12
Training loss: 0.6883239793449779
Validation loss: 2.5475033864934655

Epoch: 6| Step: 13
Training loss: 0.7403915359219362
Validation loss: 2.583057272375294

Epoch: 392| Step: 0
Training loss: 0.2564930240266214
Validation loss: 2.5388909515914366

Epoch: 6| Step: 1
Training loss: 0.48047954268080284
Validation loss: 2.5510589298213597

Epoch: 6| Step: 2
Training loss: 0.38147566401629274
Validation loss: 2.556201683895789

Epoch: 6| Step: 3
Training loss: 0.529258839271693
Validation loss: 2.572046103150062

Epoch: 6| Step: 4
Training loss: 0.5140472896841756
Validation loss: 2.5424425288148553

Epoch: 6| Step: 5
Training loss: 0.5276918180913209
Validation loss: 2.5477353682440493

Epoch: 6| Step: 6
Training loss: 0.33914011976533526
Validation loss: 2.540977969399826

Epoch: 6| Step: 7
Training loss: 0.7514884008094925
Validation loss: 2.5601842657646925

Epoch: 6| Step: 8
Training loss: 0.6325009367864253
Validation loss: 2.5495187352703392

Epoch: 6| Step: 9
Training loss: 0.22511307173300532
Validation loss: 2.552607484039137

Epoch: 6| Step: 10
Training loss: 0.5894414274901709
Validation loss: 2.5753056821730596

Epoch: 6| Step: 11
Training loss: 0.6802844791135071
Validation loss: 2.552988304693813

Epoch: 6| Step: 12
Training loss: 0.6814364151990188
Validation loss: 2.5263013920380937

Epoch: 6| Step: 13
Training loss: 0.40342365631179494
Validation loss: 2.5359162718774177

Epoch: 393| Step: 0
Training loss: 0.5974091661113388
Validation loss: 2.538846158764979

Epoch: 6| Step: 1
Training loss: 0.631656414865559
Validation loss: 2.544829418247609

Epoch: 6| Step: 2
Training loss: 0.4822372206680073
Validation loss: 2.531246289111635

Epoch: 6| Step: 3
Training loss: 0.6402437657429221
Validation loss: 2.5338777640652292

Epoch: 6| Step: 4
Training loss: 0.5315192606101558
Validation loss: 2.521446392131988

Epoch: 6| Step: 5
Training loss: 0.3049892496340637
Validation loss: 2.5296712725201322

Epoch: 6| Step: 6
Training loss: 0.5872374800301134
Validation loss: 2.499600484160839

Epoch: 6| Step: 7
Training loss: 0.6645624410600007
Validation loss: 2.524663018720889

Epoch: 6| Step: 8
Training loss: 0.5132355958559006
Validation loss: 2.5409550496863633

Epoch: 6| Step: 9
Training loss: 0.49325229875190363
Validation loss: 2.5915290228043375

Epoch: 6| Step: 10
Training loss: 0.3927241950369061
Validation loss: 2.5572044044060376

Epoch: 6| Step: 11
Training loss: 0.30652657592924615
Validation loss: 2.563768050584018

Epoch: 6| Step: 12
Training loss: 0.4538819633197672
Validation loss: 2.5787713268314483

Epoch: 6| Step: 13
Training loss: 0.8033301006215161
Validation loss: 2.5891283963640817

Epoch: 394| Step: 0
Training loss: 0.653571270239883
Validation loss: 2.564104101356672

Epoch: 6| Step: 1
Training loss: 0.6484635129559665
Validation loss: 2.5195710896621053

Epoch: 6| Step: 2
Training loss: 0.5904860883167405
Validation loss: 2.4973962802140837

Epoch: 6| Step: 3
Training loss: 0.46832168401990926
Validation loss: 2.4955203160101567

Epoch: 6| Step: 4
Training loss: 0.6185147705303504
Validation loss: 2.499211000203158

Epoch: 6| Step: 5
Training loss: 0.6401600895273727
Validation loss: 2.50547998392578

Epoch: 6| Step: 6
Training loss: 0.35948279049658
Validation loss: 2.500597805412905

Epoch: 6| Step: 7
Training loss: 0.278602764627777
Validation loss: 2.51412459208419

Epoch: 6| Step: 8
Training loss: 0.3863256942317696
Validation loss: 2.5498959830960057

Epoch: 6| Step: 9
Training loss: 0.5316137583136233
Validation loss: 2.5501825248416883

Epoch: 6| Step: 10
Training loss: 0.5121117167706636
Validation loss: 2.572397474022953

Epoch: 6| Step: 11
Training loss: 0.5340548130506739
Validation loss: 2.562041809692947

Epoch: 6| Step: 12
Training loss: 0.47594660687015033
Validation loss: 2.5924166728916624

Epoch: 6| Step: 13
Training loss: 0.5338033016132744
Validation loss: 2.6302079749718836

Epoch: 395| Step: 0
Training loss: 0.4988979771636338
Validation loss: 2.5905575092654805

Epoch: 6| Step: 1
Training loss: 0.5885766421252816
Validation loss: 2.606997697902732

Epoch: 6| Step: 2
Training loss: 0.33574440307951336
Validation loss: 2.585105782814242

Epoch: 6| Step: 3
Training loss: 0.38009353324183304
Validation loss: 2.579935860222518

Epoch: 6| Step: 4
Training loss: 0.3580045900756524
Validation loss: 2.5388265874041287

Epoch: 6| Step: 5
Training loss: 0.7061977426218444
Validation loss: 2.5007269612479095

Epoch: 6| Step: 6
Training loss: 0.5407076348010712
Validation loss: 2.5235464715815685

Epoch: 6| Step: 7
Training loss: 0.4961886878296703
Validation loss: 2.5243914463477823

Epoch: 6| Step: 8
Training loss: 0.6107315711552562
Validation loss: 2.503547357464438

Epoch: 6| Step: 9
Training loss: 0.32292526243931136
Validation loss: 2.507158085866136

Epoch: 6| Step: 10
Training loss: 0.4610168905908266
Validation loss: 2.5249347400750297

Epoch: 6| Step: 11
Training loss: 0.633186112304167
Validation loss: 2.596875098680727

Epoch: 6| Step: 12
Training loss: 0.5891619145616737
Validation loss: 2.601783366387789

Epoch: 6| Step: 13
Training loss: 0.538608747051617
Validation loss: 2.6169581266687323

Epoch: 396| Step: 0
Training loss: 0.5208803886773821
Validation loss: 2.6308721363648435

Epoch: 6| Step: 1
Training loss: 0.5338883799932999
Validation loss: 2.624395567513714

Epoch: 6| Step: 2
Training loss: 0.43246030007881253
Validation loss: 2.6295067822080895

Epoch: 6| Step: 3
Training loss: 0.3590070250363092
Validation loss: 2.5548488443942605

Epoch: 6| Step: 4
Training loss: 0.5464656660300846
Validation loss: 2.5236015666511693

Epoch: 6| Step: 5
Training loss: 0.4566866235595412
Validation loss: 2.4971233080943476

Epoch: 6| Step: 6
Training loss: 0.3838099505537519
Validation loss: 2.4787342027483867

Epoch: 6| Step: 7
Training loss: 0.6195799896194475
Validation loss: 2.503462772342921

Epoch: 6| Step: 8
Training loss: 0.4839723821082399
Validation loss: 2.5216862303430636

Epoch: 6| Step: 9
Training loss: 0.4384449053170903
Validation loss: 2.5635615010289743

Epoch: 6| Step: 10
Training loss: 0.5428027441260422
Validation loss: 2.5839321221195886

Epoch: 6| Step: 11
Training loss: 0.9230467897625794
Validation loss: 2.5588218238500287

Epoch: 6| Step: 12
Training loss: 0.3367750240308645
Validation loss: 2.6063793991960207

Epoch: 6| Step: 13
Training loss: 0.5540029573155048
Validation loss: 2.580713555015486

Epoch: 397| Step: 0
Training loss: 0.6402267055273213
Validation loss: 2.587491443856287

Epoch: 6| Step: 1
Training loss: 0.6339285627936933
Validation loss: 2.565549135359874

Epoch: 6| Step: 2
Training loss: 0.6735273049079324
Validation loss: 2.5792772628569987

Epoch: 6| Step: 3
Training loss: 0.3353363913479743
Validation loss: 2.5523690337300797

Epoch: 6| Step: 4
Training loss: 0.6568146274817871
Validation loss: 2.5498867611369898

Epoch: 6| Step: 5
Training loss: 0.48323154843858945
Validation loss: 2.5781663888223627

Epoch: 6| Step: 6
Training loss: 0.5104098579056409
Validation loss: 2.5441569370839217

Epoch: 6| Step: 7
Training loss: 0.3707187966831708
Validation loss: 2.551566946706006

Epoch: 6| Step: 8
Training loss: 0.5711942153838108
Validation loss: 2.5087600035918394

Epoch: 6| Step: 9
Training loss: 0.38515597840583926
Validation loss: 2.5168126428268938

Epoch: 6| Step: 10
Training loss: 0.47051190809571053
Validation loss: 2.474811987407932

Epoch: 6| Step: 11
Training loss: 0.33716153993274356
Validation loss: 2.4660959220640204

Epoch: 6| Step: 12
Training loss: 0.5239607629536392
Validation loss: 2.476750517416268

Epoch: 6| Step: 13
Training loss: 0.20490385552956641
Validation loss: 2.46267138196508

Epoch: 398| Step: 0
Training loss: 0.4434851917430955
Validation loss: 2.531514059695651

Epoch: 6| Step: 1
Training loss: 0.6488203274455252
Validation loss: 2.556395203129228

Epoch: 6| Step: 2
Training loss: 0.26495826012350976
Validation loss: 2.5602833995027754

Epoch: 6| Step: 3
Training loss: 0.40285881184654465
Validation loss: 2.5934243806446067

Epoch: 6| Step: 4
Training loss: 0.577097004568985
Validation loss: 2.5786848457867553

Epoch: 6| Step: 5
Training loss: 0.42355360642263273
Validation loss: 2.589986624688521

Epoch: 6| Step: 6
Training loss: 0.24096948685927305
Validation loss: 2.5580466024757484

Epoch: 6| Step: 7
Training loss: 0.6093265807649231
Validation loss: 2.543720082261306

Epoch: 6| Step: 8
Training loss: 0.4990180177636906
Validation loss: 2.549593557338331

Epoch: 6| Step: 9
Training loss: 0.4105591384696655
Validation loss: 2.518577012017115

Epoch: 6| Step: 10
Training loss: 0.3944857920528557
Validation loss: 2.5160903943473674

Epoch: 6| Step: 11
Training loss: 0.7390213743223685
Validation loss: 2.537625588348627

Epoch: 6| Step: 12
Training loss: 0.5686328138417085
Validation loss: 2.543962976141131

Epoch: 6| Step: 13
Training loss: 0.6219493562727694
Validation loss: 2.5757607506367286

Epoch: 399| Step: 0
Training loss: 0.5966399284139945
Validation loss: 2.565886196277237

Epoch: 6| Step: 1
Training loss: 0.5086962419361699
Validation loss: 2.5889691263816417

Epoch: 6| Step: 2
Training loss: 0.46022547669065605
Validation loss: 2.5791630191277877

Epoch: 6| Step: 3
Training loss: 0.4695833586659237
Validation loss: 2.5901301764188327

Epoch: 6| Step: 4
Training loss: 0.3754697876978205
Validation loss: 2.5982593922688704

Epoch: 6| Step: 5
Training loss: 0.548501294112787
Validation loss: 2.5899815988332398

Epoch: 6| Step: 6
Training loss: 0.44342032194300784
Validation loss: 2.593817939169981

Epoch: 6| Step: 7
Training loss: 0.2744945530255449
Validation loss: 2.5972946385311904

Epoch: 6| Step: 8
Training loss: 0.5613084464449792
Validation loss: 2.589958215486435

Epoch: 6| Step: 9
Training loss: 0.3462972116130055
Validation loss: 2.5724143403557482

Epoch: 6| Step: 10
Training loss: 0.4943048558586456
Validation loss: 2.546394663709171

Epoch: 6| Step: 11
Training loss: 0.6097421273805989
Validation loss: 2.536432293433148

Epoch: 6| Step: 12
Training loss: 0.6643229703007199
Validation loss: 2.5290501620435544

Epoch: 6| Step: 13
Training loss: 0.4944012825173036
Validation loss: 2.5325823120637985

Epoch: 400| Step: 0
Training loss: 0.8069176002089163
Validation loss: 2.5242603062462883

Epoch: 6| Step: 1
Training loss: 0.42727190212229105
Validation loss: 2.563749416942407

Epoch: 6| Step: 2
Training loss: 0.425368502683563
Validation loss: 2.5747071303223352

Epoch: 6| Step: 3
Training loss: 0.3839362058957705
Validation loss: 2.5273983738001786

Epoch: 6| Step: 4
Training loss: 0.621368923049338
Validation loss: 2.5822822928195945

Epoch: 6| Step: 5
Training loss: 0.48067979906991554
Validation loss: 2.6053552247534157

Epoch: 6| Step: 6
Training loss: 0.44198241650767145
Validation loss: 2.5725862343097017

Epoch: 6| Step: 7
Training loss: 0.5461813751341738
Validation loss: 2.5661105489438687

Epoch: 6| Step: 8
Training loss: 0.5598496942952493
Validation loss: 2.571000989757965

Epoch: 6| Step: 9
Training loss: 0.25856817643405633
Validation loss: 2.5294134781702824

Epoch: 6| Step: 10
Training loss: 0.37599929146370176
Validation loss: 2.5360060868536975

Epoch: 6| Step: 11
Training loss: 0.45110531931180375
Validation loss: 2.5037038509903318

Epoch: 6| Step: 12
Training loss: 0.44601508814902513
Validation loss: 2.5137490368252156

Epoch: 6| Step: 13
Training loss: 0.3529137392984798
Validation loss: 2.4863170829785335

Epoch: 401| Step: 0
Training loss: 0.5073907714896166
Validation loss: 2.524791181607044

Epoch: 6| Step: 1
Training loss: 0.3296463190366188
Validation loss: 2.513337842501434

Epoch: 6| Step: 2
Training loss: 0.5886472984200776
Validation loss: 2.560785868273283

Epoch: 6| Step: 3
Training loss: 0.45910977213028725
Validation loss: 2.6240211298522262

Epoch: 6| Step: 4
Training loss: 0.5312129737068253
Validation loss: 2.597501593393115

Epoch: 6| Step: 5
Training loss: 0.4728371140148826
Validation loss: 2.642538809275604

Epoch: 6| Step: 6
Training loss: 0.40869098695211653
Validation loss: 2.5854614878488893

Epoch: 6| Step: 7
Training loss: 0.5321972200197067
Validation loss: 2.600296876931802

Epoch: 6| Step: 8
Training loss: 0.5260355794825101
Validation loss: 2.581408568268129

Epoch: 6| Step: 9
Training loss: 0.40193774283794315
Validation loss: 2.546496277264074

Epoch: 6| Step: 10
Training loss: 0.6308635557998681
Validation loss: 2.528038325947724

Epoch: 6| Step: 11
Training loss: 0.4219291440339484
Validation loss: 2.518136786952348

Epoch: 6| Step: 12
Training loss: 0.5855222629415879
Validation loss: 2.5001456679698153

Epoch: 6| Step: 13
Training loss: 0.4060937874571257
Validation loss: 2.5034101239553617

Epoch: 402| Step: 0
Training loss: 0.7061089248191521
Validation loss: 2.555112150859915

Epoch: 6| Step: 1
Training loss: 0.4046060237093867
Validation loss: 2.5306292630724845

Epoch: 6| Step: 2
Training loss: 0.4694595847127392
Validation loss: 2.5590060024299994

Epoch: 6| Step: 3
Training loss: 0.37824419523173314
Validation loss: 2.5691492489438374

Epoch: 6| Step: 4
Training loss: 0.5263921558353678
Validation loss: 2.573167257040512

Epoch: 6| Step: 5
Training loss: 0.4823475521766964
Validation loss: 2.6059444808803005

Epoch: 6| Step: 6
Training loss: 0.6376985839012087
Validation loss: 2.5582254154213273

Epoch: 6| Step: 7
Training loss: 0.32334536378066414
Validation loss: 2.4731312115314648

Epoch: 6| Step: 8
Training loss: 0.27456549542150116
Validation loss: 2.4483444988508483

Epoch: 6| Step: 9
Training loss: 0.460521024928139
Validation loss: 2.4359289806497753

Epoch: 6| Step: 10
Training loss: 0.4464525887295817
Validation loss: 2.4075164253653276

Epoch: 6| Step: 11
Training loss: 0.5555246510122055
Validation loss: 2.4428218636141397

Epoch: 6| Step: 12
Training loss: 0.5468786511980513
Validation loss: 2.4676708055288175

Epoch: 6| Step: 13
Training loss: 0.6452740867949096
Validation loss: 2.4951464104320253

Epoch: 403| Step: 0
Training loss: 0.5214045317029661
Validation loss: 2.535363838088369

Epoch: 6| Step: 1
Training loss: 0.5577592819002369
Validation loss: 2.5208872514160494

Epoch: 6| Step: 2
Training loss: 0.5860250280490659
Validation loss: 2.5282774663328293

Epoch: 6| Step: 3
Training loss: 0.37292298661458423
Validation loss: 2.5239074913451596

Epoch: 6| Step: 4
Training loss: 0.5560355662524229
Validation loss: 2.52950972510609

Epoch: 6| Step: 5
Training loss: 0.6772904274971299
Validation loss: 2.488105626965253

Epoch: 6| Step: 6
Training loss: 0.5267439928459102
Validation loss: 2.4668841473018266

Epoch: 6| Step: 7
Training loss: 0.5136252262414845
Validation loss: 2.449603345122733

Epoch: 6| Step: 8
Training loss: 0.37871430638011516
Validation loss: 2.472908201452918

Epoch: 6| Step: 9
Training loss: 0.5653169615122966
Validation loss: 2.487377034717698

Epoch: 6| Step: 10
Training loss: 0.2352231177756533
Validation loss: 2.4806452904004623

Epoch: 6| Step: 11
Training loss: 0.4760166387705273
Validation loss: 2.4955439694124197

Epoch: 6| Step: 12
Training loss: 0.40950854794869435
Validation loss: 2.5286750472832495

Epoch: 6| Step: 13
Training loss: 0.33911866632572757
Validation loss: 2.542989295586764

Epoch: 404| Step: 0
Training loss: 0.3859303462180164
Validation loss: 2.5322322096927636

Epoch: 6| Step: 1
Training loss: 0.6202429936669435
Validation loss: 2.4951081558268604

Epoch: 6| Step: 2
Training loss: 0.4276814188465654
Validation loss: 2.504711008039945

Epoch: 6| Step: 3
Training loss: 0.446397997626647
Validation loss: 2.492882893516513

Epoch: 6| Step: 4
Training loss: 0.4416205637039837
Validation loss: 2.5260215366898984

Epoch: 6| Step: 5
Training loss: 0.5305887763483772
Validation loss: 2.505533201711547

Epoch: 6| Step: 6
Training loss: 0.43025852754156085
Validation loss: 2.5117659341959873

Epoch: 6| Step: 7
Training loss: 0.2762381586065683
Validation loss: 2.5251078442611075

Epoch: 6| Step: 8
Training loss: 0.43569646071326656
Validation loss: 2.5440379767237586

Epoch: 6| Step: 9
Training loss: 0.33057640207073086
Validation loss: 2.5738065038676776

Epoch: 6| Step: 10
Training loss: 0.6215592085730554
Validation loss: 2.5588901263266144

Epoch: 6| Step: 11
Training loss: 0.7019189451596499
Validation loss: 2.581467079077081

Epoch: 6| Step: 12
Training loss: 0.368430650759022
Validation loss: 2.5812367364316753

Epoch: 6| Step: 13
Training loss: 0.469565635602645
Validation loss: 2.5872049016852467

Epoch: 405| Step: 0
Training loss: 0.44623733988736347
Validation loss: 2.618006601538988

Epoch: 6| Step: 1
Training loss: 0.5004706254031331
Validation loss: 2.5766999165180384

Epoch: 6| Step: 2
Training loss: 0.5085141249995131
Validation loss: 2.577942703230733

Epoch: 6| Step: 3
Training loss: 0.516344262354476
Validation loss: 2.523969093992098

Epoch: 6| Step: 4
Training loss: 0.6687501051715519
Validation loss: 2.5441567269871754

Epoch: 6| Step: 5
Training loss: 0.34459279520558594
Validation loss: 2.547708355006962

Epoch: 6| Step: 6
Training loss: 0.23734747732423842
Validation loss: 2.55340056053462

Epoch: 6| Step: 7
Training loss: 0.5177799335246354
Validation loss: 2.5278131235803656

Epoch: 6| Step: 8
Training loss: 0.5345107034516143
Validation loss: 2.572517983556205

Epoch: 6| Step: 9
Training loss: 0.5895345521657969
Validation loss: 2.5715705427721436

Epoch: 6| Step: 10
Training loss: 0.2404225085726074
Validation loss: 2.5739080910209187

Epoch: 6| Step: 11
Training loss: 0.5877045498518494
Validation loss: 2.566963841840731

Epoch: 6| Step: 12
Training loss: 0.26491319426722465
Validation loss: 2.5487970130488504

Epoch: 6| Step: 13
Training loss: 0.33946748709722474
Validation loss: 2.5631571881664654

Epoch: 406| Step: 0
Training loss: 0.43122761156873823
Validation loss: 2.566162933439357

Epoch: 6| Step: 1
Training loss: 0.3163077354125072
Validation loss: 2.5903896195217406

Epoch: 6| Step: 2
Training loss: 0.4579534111981293
Validation loss: 2.5310236997938875

Epoch: 6| Step: 3
Training loss: 0.5997693472822887
Validation loss: 2.531757643625378

Epoch: 6| Step: 4
Training loss: 0.19899040112695723
Validation loss: 2.5190143074921227

Epoch: 6| Step: 5
Training loss: 0.5005539864930543
Validation loss: 2.552572585609077

Epoch: 6| Step: 6
Training loss: 0.5418454083169199
Validation loss: 2.5492099145203526

Epoch: 6| Step: 7
Training loss: 0.29122315757896305
Validation loss: 2.555783459213462

Epoch: 6| Step: 8
Training loss: 0.5342124636007692
Validation loss: 2.5500366810704547

Epoch: 6| Step: 9
Training loss: 0.44856586280594435
Validation loss: 2.560010440515755

Epoch: 6| Step: 10
Training loss: 0.44070997433343223
Validation loss: 2.5198545827967282

Epoch: 6| Step: 11
Training loss: 0.4377734147350353
Validation loss: 2.5420949582792844

Epoch: 6| Step: 12
Training loss: 0.5248248375735706
Validation loss: 2.549966950094817

Epoch: 6| Step: 13
Training loss: 0.6363626197939964
Validation loss: 2.5405818026626705

Epoch: 407| Step: 0
Training loss: 0.5148113651538682
Validation loss: 2.564190558768668

Epoch: 6| Step: 1
Training loss: 0.6216742723560497
Validation loss: 2.516685306716644

Epoch: 6| Step: 2
Training loss: 0.561955188125351
Validation loss: 2.527869721931551

Epoch: 6| Step: 3
Training loss: 0.4113233220036441
Validation loss: 2.5447267226414896

Epoch: 6| Step: 4
Training loss: 0.41469773562346424
Validation loss: 2.515095259508566

Epoch: 6| Step: 5
Training loss: 0.1855706450646017
Validation loss: 2.5324880407401436

Epoch: 6| Step: 6
Training loss: 0.44039884742638835
Validation loss: 2.5700159615896068

Epoch: 6| Step: 7
Training loss: 0.6105979483165439
Validation loss: 2.569475727136607

Epoch: 6| Step: 8
Training loss: 0.4623939005837205
Validation loss: 2.5779686734661444

Epoch: 6| Step: 9
Training loss: 0.39239393249826343
Validation loss: 2.59251034227192

Epoch: 6| Step: 10
Training loss: 0.4737291061202477
Validation loss: 2.5954648395721662

Epoch: 6| Step: 11
Training loss: 0.42264389682845804
Validation loss: 2.5455772726962014

Epoch: 6| Step: 12
Training loss: 0.4083595706172202
Validation loss: 2.5372392225107947

Epoch: 6| Step: 13
Training loss: 0.12482026335779806
Validation loss: 2.496868781399648

Epoch: 408| Step: 0
Training loss: 0.25132746230664454
Validation loss: 2.533310798116796

Epoch: 6| Step: 1
Training loss: 0.5973125292147448
Validation loss: 2.5474579460586124

Epoch: 6| Step: 2
Training loss: 0.6318614311912106
Validation loss: 2.50740842771564

Epoch: 6| Step: 3
Training loss: 0.25169317749000764
Validation loss: 2.530832206289871

Epoch: 6| Step: 4
Training loss: 0.7764971546334666
Validation loss: 2.514159531695482

Epoch: 6| Step: 5
Training loss: 0.3562488798491954
Validation loss: 2.5696491236056436

Epoch: 6| Step: 6
Training loss: 0.37590977459503916
Validation loss: 2.522959034024269

Epoch: 6| Step: 7
Training loss: 0.3654911953874073
Validation loss: 2.5709036882694174

Epoch: 6| Step: 8
Training loss: 0.434053040299074
Validation loss: 2.541491273637785

Epoch: 6| Step: 9
Training loss: 0.41036242797933664
Validation loss: 2.5729610330849084

Epoch: 6| Step: 10
Training loss: 0.4855902716101307
Validation loss: 2.5729272696133894

Epoch: 6| Step: 11
Training loss: 0.44832076836224044
Validation loss: 2.5874530993077

Epoch: 6| Step: 12
Training loss: 0.3268503453674056
Validation loss: 2.5489664917379256

Epoch: 6| Step: 13
Training loss: 0.36747778922712643
Validation loss: 2.5333513950887085

Epoch: 409| Step: 0
Training loss: 0.1865279411850702
Validation loss: 2.4973217276964603

Epoch: 6| Step: 1
Training loss: 0.4085480542277695
Validation loss: 2.5447479521799248

Epoch: 6| Step: 2
Training loss: 0.36892524369819785
Validation loss: 2.5619030478981712

Epoch: 6| Step: 3
Training loss: 0.4973076214552854
Validation loss: 2.528521899926484

Epoch: 6| Step: 4
Training loss: 0.5240987330486354
Validation loss: 2.535675494950491

Epoch: 6| Step: 5
Training loss: 0.5217091222504784
Validation loss: 2.5586599512216117

Epoch: 6| Step: 6
Training loss: 0.38383231271190393
Validation loss: 2.514761919678114

Epoch: 6| Step: 7
Training loss: 0.4545588006422802
Validation loss: 2.52713096600205

Epoch: 6| Step: 8
Training loss: 0.6310206345933973
Validation loss: 2.52722522920304

Epoch: 6| Step: 9
Training loss: 0.39291560911492707
Validation loss: 2.533013132219563

Epoch: 6| Step: 10
Training loss: 0.3815887509625317
Validation loss: 2.5334931621369825

Epoch: 6| Step: 11
Training loss: 0.2679468246031565
Validation loss: 2.533348815611057

Epoch: 6| Step: 12
Training loss: 0.4807369755048372
Validation loss: 2.5548417861789856

Epoch: 6| Step: 13
Training loss: 0.6456703523879576
Validation loss: 2.5477314056564118

Epoch: 410| Step: 0
Training loss: 0.4528037938767812
Validation loss: 2.554464615921521

Epoch: 6| Step: 1
Training loss: 0.48789431690441
Validation loss: 2.5783871554388607

Epoch: 6| Step: 2
Training loss: 0.43520504320080955
Validation loss: 2.600816165288751

Epoch: 6| Step: 3
Training loss: 0.5735063350430697
Validation loss: 2.617594102042644

Epoch: 6| Step: 4
Training loss: 0.34265839039855506
Validation loss: 2.6189669920810097

Epoch: 6| Step: 5
Training loss: 0.42726409002277016
Validation loss: 2.555362999086244

Epoch: 6| Step: 6
Training loss: 0.5841516873846716
Validation loss: 2.5376956667754196

Epoch: 6| Step: 7
Training loss: 0.6329882342433797
Validation loss: 2.5028417013427733

Epoch: 6| Step: 8
Training loss: 0.3814442374296806
Validation loss: 2.520817313113284

Epoch: 6| Step: 9
Training loss: 0.1774748070058218
Validation loss: 2.5080837833558833

Epoch: 6| Step: 10
Training loss: 0.435234556566131
Validation loss: 2.4899181539502653

Epoch: 6| Step: 11
Training loss: 0.5442026512356196
Validation loss: 2.5108497343784952

Epoch: 6| Step: 12
Training loss: 0.2309065555958204
Validation loss: 2.4785577783441037

Epoch: 6| Step: 13
Training loss: 0.2875105202864727
Validation loss: 2.5002169586709635

Epoch: 411| Step: 0
Training loss: 0.4437450798191725
Validation loss: 2.5208363693600053

Epoch: 6| Step: 1
Training loss: 0.2847793125792862
Validation loss: 2.5539229679852578

Epoch: 6| Step: 2
Training loss: 0.26916728116094246
Validation loss: 2.519024576223512

Epoch: 6| Step: 3
Training loss: 0.6684052452162961
Validation loss: 2.5640549752672026

Epoch: 6| Step: 4
Training loss: 0.4893341614015019
Validation loss: 2.574412548023977

Epoch: 6| Step: 5
Training loss: 0.34946184935020874
Validation loss: 2.5513549053095033

Epoch: 6| Step: 6
Training loss: 0.41000930333631047
Validation loss: 2.530554830542496

Epoch: 6| Step: 7
Training loss: 0.727107510169304
Validation loss: 2.5134091659920075

Epoch: 6| Step: 8
Training loss: 0.2566998922813302
Validation loss: 2.481958737495273

Epoch: 6| Step: 9
Training loss: 0.5208648544945647
Validation loss: 2.516798271272817

Epoch: 6| Step: 10
Training loss: 0.35201803999563497
Validation loss: 2.4676021263555517

Epoch: 6| Step: 11
Training loss: 0.4351357200066947
Validation loss: 2.47056733886321

Epoch: 6| Step: 12
Training loss: 0.38579649723988196
Validation loss: 2.506528615492601

Epoch: 6| Step: 13
Training loss: 0.17280530041085332
Validation loss: 2.506407653892523

Epoch: 412| Step: 0
Training loss: 0.5877854262611328
Validation loss: 2.512014700864794

Epoch: 6| Step: 1
Training loss: 0.3248019660473265
Validation loss: 2.5307513502521353

Epoch: 6| Step: 2
Training loss: 0.4028086337606119
Validation loss: 2.551799475776405

Epoch: 6| Step: 3
Training loss: 0.36262512431755684
Validation loss: 2.569794827474217

Epoch: 6| Step: 4
Training loss: 0.205720685027524
Validation loss: 2.5539667756671887

Epoch: 6| Step: 5
Training loss: 0.22452112205562083
Validation loss: 2.5639201445131596

Epoch: 6| Step: 6
Training loss: 0.572886263878741
Validation loss: 2.553892675982237

Epoch: 6| Step: 7
Training loss: 0.3334219362797031
Validation loss: 2.530535572935556

Epoch: 6| Step: 8
Training loss: 0.5294722938529322
Validation loss: 2.550165178722664

Epoch: 6| Step: 9
Training loss: 0.40617753262843465
Validation loss: 2.5319008222838844

Epoch: 6| Step: 10
Training loss: 0.41923185921616823
Validation loss: 2.5758692750193384

Epoch: 6| Step: 11
Training loss: 0.5600287671448949
Validation loss: 2.5741935568284777

Epoch: 6| Step: 12
Training loss: 0.5629135307188896
Validation loss: 2.5635804890447775

Epoch: 6| Step: 13
Training loss: 0.4330894355429656
Validation loss: 2.5388060576094764

Epoch: 413| Step: 0
Training loss: 0.39401615623568104
Validation loss: 2.548332779075576

Epoch: 6| Step: 1
Training loss: 0.5858106857397063
Validation loss: 2.5147736074929146

Epoch: 6| Step: 2
Training loss: 0.47339460537414924
Validation loss: 2.572055292005881

Epoch: 6| Step: 3
Training loss: 0.25235802990926504
Validation loss: 2.5140805163949778

Epoch: 6| Step: 4
Training loss: 0.311869665054376
Validation loss: 2.5150532985886516

Epoch: 6| Step: 5
Training loss: 0.39722309916443194
Validation loss: 2.5134273971447985

Epoch: 6| Step: 6
Training loss: 0.5194346976371578
Validation loss: 2.5468125387565475

Epoch: 6| Step: 7
Training loss: 0.35666096055882424
Validation loss: 2.5410445460753053

Epoch: 6| Step: 8
Training loss: 0.4355073748411949
Validation loss: 2.581240716113183

Epoch: 6| Step: 9
Training loss: 0.44003623423067456
Validation loss: 2.5426651877570015

Epoch: 6| Step: 10
Training loss: 0.5907404317528941
Validation loss: 2.58409258997739

Epoch: 6| Step: 11
Training loss: 0.4705118922606581
Validation loss: 2.5119850026375263

Epoch: 6| Step: 12
Training loss: 0.31274696366690957
Validation loss: 2.4965427961551017

Epoch: 6| Step: 13
Training loss: 0.44581674169107927
Validation loss: 2.4992257421568094

Epoch: 414| Step: 0
Training loss: 0.28966035104585847
Validation loss: 2.5311352171927832

Epoch: 6| Step: 1
Training loss: 0.2844477958567651
Validation loss: 2.5180585928378783

Epoch: 6| Step: 2
Training loss: 0.5229040815604457
Validation loss: 2.4866098227708173

Epoch: 6| Step: 3
Training loss: 0.32714659277552427
Validation loss: 2.522545607148332

Epoch: 6| Step: 4
Training loss: 0.6933244293432824
Validation loss: 2.5469914509180835

Epoch: 6| Step: 5
Training loss: 0.525446552008517
Validation loss: 2.563827690926109

Epoch: 6| Step: 6
Training loss: 0.3399640013065677
Validation loss: 2.530885162454358

Epoch: 6| Step: 7
Training loss: 0.2618818344326002
Validation loss: 2.5401522782954835

Epoch: 6| Step: 8
Training loss: 0.4798218629019663
Validation loss: 2.5573006301828722

Epoch: 6| Step: 9
Training loss: 0.47458929639502373
Validation loss: 2.5241502919455425

Epoch: 6| Step: 10
Training loss: 0.4116997875501239
Validation loss: 2.4922224200447194

Epoch: 6| Step: 11
Training loss: 0.2356117361671282
Validation loss: 2.5005008452181965

Epoch: 6| Step: 12
Training loss: 0.548905933878455
Validation loss: 2.5272818315906123

Epoch: 6| Step: 13
Training loss: 0.43790449448875196
Validation loss: 2.514040335302048

Epoch: 415| Step: 0
Training loss: 0.4608558970486799
Validation loss: 2.497269544229454

Epoch: 6| Step: 1
Training loss: 0.5769970948775888
Validation loss: 2.480573355571878

Epoch: 6| Step: 2
Training loss: 0.5361954560361567
Validation loss: 2.512430639181463

Epoch: 6| Step: 3
Training loss: 0.5136075577883197
Validation loss: 2.5238042763167283

Epoch: 6| Step: 4
Training loss: 0.25424446175225085
Validation loss: 2.486366107158436

Epoch: 6| Step: 5
Training loss: 0.42394054697328903
Validation loss: 2.486716534977422

Epoch: 6| Step: 6
Training loss: 0.3072701570558297
Validation loss: 2.5131814571979363

Epoch: 6| Step: 7
Training loss: 0.45981075483465145
Validation loss: 2.535205155922923

Epoch: 6| Step: 8
Training loss: 0.2104335876465976
Validation loss: 2.55085961488556

Epoch: 6| Step: 9
Training loss: 0.3571897910137244
Validation loss: 2.5606306096821863

Epoch: 6| Step: 10
Training loss: 0.573049535660655
Validation loss: 2.5857567635560743

Epoch: 6| Step: 11
Training loss: 0.4665242121036132
Validation loss: 2.6282049596532064

Epoch: 6| Step: 12
Training loss: 0.3624274362086843
Validation loss: 2.583297532422673

Epoch: 6| Step: 13
Training loss: 0.2719012154622846
Validation loss: 2.5990323617538853

Epoch: 416| Step: 0
Training loss: 0.5026009976249233
Validation loss: 2.556825711697151

Epoch: 6| Step: 1
Training loss: 0.39299679726225023
Validation loss: 2.5335798440186656

Epoch: 6| Step: 2
Training loss: 0.36048394642823806
Validation loss: 2.5005804854365405

Epoch: 6| Step: 3
Training loss: 0.42815110621248725
Validation loss: 2.4933322855701694

Epoch: 6| Step: 4
Training loss: 0.4992015244641777
Validation loss: 2.4965027430370665

Epoch: 6| Step: 5
Training loss: 0.2812374430078508
Validation loss: 2.4874639570230648

Epoch: 6| Step: 6
Training loss: 0.5002753572418964
Validation loss: 2.4979253056220534

Epoch: 6| Step: 7
Training loss: 0.6020036541267081
Validation loss: 2.532050753347275

Epoch: 6| Step: 8
Training loss: 0.4323683080946644
Validation loss: 2.5313529977690465

Epoch: 6| Step: 9
Training loss: 0.1747469993321404
Validation loss: 2.593224349750426

Epoch: 6| Step: 10
Training loss: 0.46395511797661687
Validation loss: 2.6105217101705698

Epoch: 6| Step: 11
Training loss: 0.5615203061223829
Validation loss: 2.6108120198647833

Epoch: 6| Step: 12
Training loss: 0.39022020346690933
Validation loss: 2.618917893221523

Epoch: 6| Step: 13
Training loss: 0.5149758905952427
Validation loss: 2.616381230055845

Epoch: 417| Step: 0
Training loss: 0.3656257939126288
Validation loss: 2.5387189816053475

Epoch: 6| Step: 1
Training loss: 0.4066703345799102
Validation loss: 2.496044505018683

Epoch: 6| Step: 2
Training loss: 0.5456956954373842
Validation loss: 2.491538223307177

Epoch: 6| Step: 3
Training loss: 0.5481712781971761
Validation loss: 2.4952457013195812

Epoch: 6| Step: 4
Training loss: 0.40649505706775446
Validation loss: 2.5358375655030803

Epoch: 6| Step: 5
Training loss: 0.45482065014379675
Validation loss: 2.5911358359091374

Epoch: 6| Step: 6
Training loss: 0.5457023855435079
Validation loss: 2.5720697784161013

Epoch: 6| Step: 7
Training loss: 0.5043461971260227
Validation loss: 2.5671710438746675

Epoch: 6| Step: 8
Training loss: 0.40845948706639096
Validation loss: 2.6077401979934964

Epoch: 6| Step: 9
Training loss: 0.4563387653799844
Validation loss: 2.6098691744876796

Epoch: 6| Step: 10
Training loss: 0.584572945183237
Validation loss: 2.5677279474701185

Epoch: 6| Step: 11
Training loss: 0.1817020291961213
Validation loss: 2.561321192497221

Epoch: 6| Step: 12
Training loss: 0.31934382344345946
Validation loss: 2.5136570448987374

Epoch: 6| Step: 13
Training loss: 0.29659556740125714
Validation loss: 2.516391310051965

Epoch: 418| Step: 0
Training loss: 0.3760376719564653
Validation loss: 2.473168345270508

Epoch: 6| Step: 1
Training loss: 0.48561041700837515
Validation loss: 2.422111964996377

Epoch: 6| Step: 2
Training loss: 0.5761875473735809
Validation loss: 2.4958448170200125

Epoch: 6| Step: 3
Training loss: 0.5022298740154063
Validation loss: 2.5228055163036434

Epoch: 6| Step: 4
Training loss: 0.417844664791419
Validation loss: 2.5497860005787287

Epoch: 6| Step: 5
Training loss: 0.5092694436445319
Validation loss: 2.5667626257773306

Epoch: 6| Step: 6
Training loss: 0.4523198439320921
Validation loss: 2.548774727919849

Epoch: 6| Step: 7
Training loss: 0.4932067550460331
Validation loss: 2.533008931024959

Epoch: 6| Step: 8
Training loss: 0.47579885490932305
Validation loss: 2.5141398497363174

Epoch: 6| Step: 9
Training loss: 0.44173484994203555
Validation loss: 2.484658618045528

Epoch: 6| Step: 10
Training loss: 0.27336484761305213
Validation loss: 2.4559461043931297

Epoch: 6| Step: 11
Training loss: 0.5439505996310174
Validation loss: 2.4632089711037577

Epoch: 6| Step: 12
Training loss: 0.5735684299933533
Validation loss: 2.5161515560409367

Epoch: 6| Step: 13
Training loss: 0.5907941575999899
Validation loss: 2.5811943649076223

Epoch: 419| Step: 0
Training loss: 0.3506575062417098
Validation loss: 2.6379532991795784

Epoch: 6| Step: 1
Training loss: 0.6248178693520239
Validation loss: 2.6330946300736655

Epoch: 6| Step: 2
Training loss: 0.6320802667233689
Validation loss: 2.6740340767434887

Epoch: 6| Step: 3
Training loss: 0.6107404522799492
Validation loss: 2.6693251980883606

Epoch: 6| Step: 4
Training loss: 0.4607039360930658
Validation loss: 2.600156441108312

Epoch: 6| Step: 5
Training loss: 0.33392440525192457
Validation loss: 2.5217303154236865

Epoch: 6| Step: 6
Training loss: 0.5107372859916574
Validation loss: 2.522054449872919

Epoch: 6| Step: 7
Training loss: 0.34869439785895734
Validation loss: 2.4948714339850224

Epoch: 6| Step: 8
Training loss: 0.7198419568996068
Validation loss: 2.4680591965161867

Epoch: 6| Step: 9
Training loss: 0.5424328911052908
Validation loss: 2.5019384959472046

Epoch: 6| Step: 10
Training loss: 0.5116416348889913
Validation loss: 2.5441096961167644

Epoch: 6| Step: 11
Training loss: 0.5384711186767182
Validation loss: 2.6019381320591113

Epoch: 6| Step: 12
Training loss: 0.35188907713706535
Validation loss: 2.632412690440832

Epoch: 6| Step: 13
Training loss: 0.5896343339444484
Validation loss: 2.679839814730823

Epoch: 420| Step: 0
Training loss: 0.4008816569114294
Validation loss: 2.683089616892479

Epoch: 6| Step: 1
Training loss: 0.6389919260690993
Validation loss: 2.6620759660124347

Epoch: 6| Step: 2
Training loss: 0.41330284033412434
Validation loss: 2.5901155158612648

Epoch: 6| Step: 3
Training loss: 0.7860224865567548
Validation loss: 2.5274871705850646

Epoch: 6| Step: 4
Training loss: 0.5404826268942581
Validation loss: 2.463544415321491

Epoch: 6| Step: 5
Training loss: 0.5048233085704111
Validation loss: 2.443575430309923

Epoch: 6| Step: 6
Training loss: 0.62021942497367
Validation loss: 2.422303485841544

Epoch: 6| Step: 7
Training loss: 0.5768929317741617
Validation loss: 2.4234463402921604

Epoch: 6| Step: 8
Training loss: 0.4816627088992435
Validation loss: 2.40304906805594

Epoch: 6| Step: 9
Training loss: 0.3528783966776613
Validation loss: 2.4471254366463304

Epoch: 6| Step: 10
Training loss: 0.37655341742867715
Validation loss: 2.432813733877126

Epoch: 6| Step: 11
Training loss: 0.5210485458784218
Validation loss: 2.4565071141513264

Epoch: 6| Step: 12
Training loss: 0.48063207192048524
Validation loss: 2.4649378876216788

Epoch: 6| Step: 13
Training loss: 0.5732342851084357
Validation loss: 2.5291665518155635

Epoch: 421| Step: 0
Training loss: 0.45510821590890876
Validation loss: 2.452389159132024

Epoch: 6| Step: 1
Training loss: 0.3724221595937523
Validation loss: 2.40467781406576

Epoch: 6| Step: 2
Training loss: 0.5477395716692571
Validation loss: 2.3947139496917424

Epoch: 6| Step: 3
Training loss: 0.4643492111602717
Validation loss: 2.4238115478852014

Epoch: 6| Step: 4
Training loss: 0.5956464896873647
Validation loss: 2.4449912732401398

Epoch: 6| Step: 5
Training loss: 0.6239603455457471
Validation loss: 2.518372798217451

Epoch: 6| Step: 6
Training loss: 0.46517043294866006
Validation loss: 2.5480978998189676

Epoch: 6| Step: 7
Training loss: 0.40983458121511684
Validation loss: 2.5603638105446107

Epoch: 6| Step: 8
Training loss: 0.39608451335904293
Validation loss: 2.5618328003232365

Epoch: 6| Step: 9
Training loss: 0.3952510612601426
Validation loss: 2.5502746759427226

Epoch: 6| Step: 10
Training loss: 0.4047172498630282
Validation loss: 2.538956959994422

Epoch: 6| Step: 11
Training loss: 0.6367950627751984
Validation loss: 2.487034038257711

Epoch: 6| Step: 12
Training loss: 0.5126257567680333
Validation loss: 2.448740439133511

Epoch: 6| Step: 13
Training loss: 0.7564148746811203
Validation loss: 2.4596921197810686

Epoch: 422| Step: 0
Training loss: 0.3923334526433469
Validation loss: 2.443548926391943

Epoch: 6| Step: 1
Training loss: 0.6624758895949242
Validation loss: 2.4221343802317117

Epoch: 6| Step: 2
Training loss: 0.49025246028292535
Validation loss: 2.4534583371132177

Epoch: 6| Step: 3
Training loss: 0.46093546333509594
Validation loss: 2.519379283801981

Epoch: 6| Step: 4
Training loss: 0.3813317328534241
Validation loss: 2.5523954201077172

Epoch: 6| Step: 5
Training loss: 0.35471587046621533
Validation loss: 2.5942002879275856

Epoch: 6| Step: 6
Training loss: 0.5192546825390649
Validation loss: 2.571553100665102

Epoch: 6| Step: 7
Training loss: 0.44211710177402186
Validation loss: 2.5790241740499193

Epoch: 6| Step: 8
Training loss: 0.3091441087620476
Validation loss: 2.5507064074927235

Epoch: 6| Step: 9
Training loss: 0.5115365730571251
Validation loss: 2.4956370984598064

Epoch: 6| Step: 10
Training loss: 0.5069490280844114
Validation loss: 2.5036080778169247

Epoch: 6| Step: 11
Training loss: 0.4213230619828373
Validation loss: 2.5396757570685278

Epoch: 6| Step: 12
Training loss: 0.5736175296086696
Validation loss: 2.5402324919670547

Epoch: 6| Step: 13
Training loss: 0.44375287041608835
Validation loss: 2.5426684348221027

Epoch: 423| Step: 0
Training loss: 0.43383376892914055
Validation loss: 2.526684395343992

Epoch: 6| Step: 1
Training loss: 0.4595886149006403
Validation loss: 2.5675970927572984

Epoch: 6| Step: 2
Training loss: 0.574555227086945
Validation loss: 2.6168196685225302

Epoch: 6| Step: 3
Training loss: 0.5900533947787101
Validation loss: 2.582311023740093

Epoch: 6| Step: 4
Training loss: 0.4300552874884617
Validation loss: 2.6021991376839337

Epoch: 6| Step: 5
Training loss: 0.18376834156657973
Validation loss: 2.584960788737169

Epoch: 6| Step: 6
Training loss: 0.415141229957221
Validation loss: 2.5548152770581303

Epoch: 6| Step: 7
Training loss: 0.34528185074058526
Validation loss: 2.5033683286707302

Epoch: 6| Step: 8
Training loss: 0.2908203442677928
Validation loss: 2.532995304674056

Epoch: 6| Step: 9
Training loss: 0.37335348261517626
Validation loss: 2.502241443439278

Epoch: 6| Step: 10
Training loss: 0.399199038502294
Validation loss: 2.494723734724059

Epoch: 6| Step: 11
Training loss: 0.47747111080816157
Validation loss: 2.462644177885222

Epoch: 6| Step: 12
Training loss: 0.39843237630504236
Validation loss: 2.4682487933340362

Epoch: 6| Step: 13
Training loss: 0.546118021631655
Validation loss: 2.4876347276579835

Epoch: 424| Step: 0
Training loss: 0.5050705462932289
Validation loss: 2.5047339380219196

Epoch: 6| Step: 1
Training loss: 0.4907881508007767
Validation loss: 2.502220995632775

Epoch: 6| Step: 2
Training loss: 0.4885191986133852
Validation loss: 2.515106459569667

Epoch: 6| Step: 3
Training loss: 0.16804703839700683
Validation loss: 2.473064861171008

Epoch: 6| Step: 4
Training loss: 0.5211063400646392
Validation loss: 2.5030731099520898

Epoch: 6| Step: 5
Training loss: 0.3166338490538335
Validation loss: 2.532801676260173

Epoch: 6| Step: 6
Training loss: 0.4995288417114968
Validation loss: 2.5959677695307377

Epoch: 6| Step: 7
Training loss: 0.5277338351254698
Validation loss: 2.6083712912934263

Epoch: 6| Step: 8
Training loss: 0.25786353097504566
Validation loss: 2.615336527134298

Epoch: 6| Step: 9
Training loss: 0.2435205443310356
Validation loss: 2.5409223168252026

Epoch: 6| Step: 10
Training loss: 0.41698207440943963
Validation loss: 2.546279580948168

Epoch: 6| Step: 11
Training loss: 0.331054822533504
Validation loss: 2.5254392870858204

Epoch: 6| Step: 12
Training loss: 0.34828143751739205
Validation loss: 2.5171227098241307

Epoch: 6| Step: 13
Training loss: 0.59024862578966
Validation loss: 2.490009084214575

Epoch: 425| Step: 0
Training loss: 0.45507196905204644
Validation loss: 2.472189326211671

Epoch: 6| Step: 1
Training loss: 0.24966202928254913
Validation loss: 2.4862349813456817

Epoch: 6| Step: 2
Training loss: 0.542713846433708
Validation loss: 2.4952677586895273

Epoch: 6| Step: 3
Training loss: 0.4101925061867969
Validation loss: 2.5372319425282397

Epoch: 6| Step: 4
Training loss: 0.4783217056646654
Validation loss: 2.5593845207839307

Epoch: 6| Step: 5
Training loss: 0.4205977921663311
Validation loss: 2.6219431848017662

Epoch: 6| Step: 6
Training loss: 0.5311600104015552
Validation loss: 2.6696213579666135

Epoch: 6| Step: 7
Training loss: 0.6024238562845076
Validation loss: 2.6727424791240746

Epoch: 6| Step: 8
Training loss: 0.4891267399141565
Validation loss: 2.6469551487766627

Epoch: 6| Step: 9
Training loss: 0.3977214325129268
Validation loss: 2.6441463576254103

Epoch: 6| Step: 10
Training loss: 0.5079421831480465
Validation loss: 2.6062575113062314

Epoch: 6| Step: 11
Training loss: 0.645010013206885
Validation loss: 2.5963054452503656

Epoch: 6| Step: 12
Training loss: 0.2263585191832818
Validation loss: 2.5685192587259733

Epoch: 6| Step: 13
Training loss: 0.413192446710083
Validation loss: 2.5449119646188887

Epoch: 426| Step: 0
Training loss: 0.5286483451395229
Validation loss: 2.5289809984052964

Epoch: 6| Step: 1
Training loss: 0.5448425672784675
Validation loss: 2.5423289138433347

Epoch: 6| Step: 2
Training loss: 0.41678583904553546
Validation loss: 2.5287243155312624

Epoch: 6| Step: 3
Training loss: 0.3922155423416542
Validation loss: 2.5651793477282596

Epoch: 6| Step: 4
Training loss: 0.4036293785268846
Validation loss: 2.6167061213799028

Epoch: 6| Step: 5
Training loss: 0.47396664210431977
Validation loss: 2.6401475005119712

Epoch: 6| Step: 6
Training loss: 0.4964552635944253
Validation loss: 2.6442255524557248

Epoch: 6| Step: 7
Training loss: 0.4826638082281103
Validation loss: 2.6417756582937417

Epoch: 6| Step: 8
Training loss: 0.4181254262594151
Validation loss: 2.6220791295299137

Epoch: 6| Step: 9
Training loss: 0.41584176025694336
Validation loss: 2.582875554241348

Epoch: 6| Step: 10
Training loss: 0.2914050907592624
Validation loss: 2.5441861595081328

Epoch: 6| Step: 11
Training loss: 0.5796405927491127
Validation loss: 2.518551755941927

Epoch: 6| Step: 12
Training loss: 0.4967481247243056
Validation loss: 2.5324335393765307

Epoch: 6| Step: 13
Training loss: 0.25332454657269815
Validation loss: 2.470273378750766

Epoch: 427| Step: 0
Training loss: 0.45808564523170525
Validation loss: 2.488723221866563

Epoch: 6| Step: 1
Training loss: 0.20568849467382153
Validation loss: 2.5211835973977066

Epoch: 6| Step: 2
Training loss: 0.3575945577748183
Validation loss: 2.550626095037686

Epoch: 6| Step: 3
Training loss: 0.34093226476857913
Validation loss: 2.5758429934982354

Epoch: 6| Step: 4
Training loss: 0.5414667004942599
Validation loss: 2.6062361990043215

Epoch: 6| Step: 5
Training loss: 0.48659745384209463
Validation loss: 2.634608389480155

Epoch: 6| Step: 6
Training loss: 0.3639244620129806
Validation loss: 2.615205102938507

Epoch: 6| Step: 7
Training loss: 0.46550767431683643
Validation loss: 2.604417056608055

Epoch: 6| Step: 8
Training loss: 0.43968797977857843
Validation loss: 2.5915257761211006

Epoch: 6| Step: 9
Training loss: 0.34887917413131386
Validation loss: 2.535653262079705

Epoch: 6| Step: 10
Training loss: 0.6436885526644608
Validation loss: 2.4953334025867138

Epoch: 6| Step: 11
Training loss: 0.29318328631741164
Validation loss: 2.540993810890168

Epoch: 6| Step: 12
Training loss: 0.49743754193722417
Validation loss: 2.5157659765399543

Epoch: 6| Step: 13
Training loss: 0.2567699623222099
Validation loss: 2.5384474061828843

Epoch: 428| Step: 0
Training loss: 0.4515788567032464
Validation loss: 2.5614209127792678

Epoch: 6| Step: 1
Training loss: 0.3944118432368569
Validation loss: 2.5619811306320734

Epoch: 6| Step: 2
Training loss: 0.37617711254684505
Validation loss: 2.5950503548446884

Epoch: 6| Step: 3
Training loss: 0.2166121701256464
Validation loss: 2.5830634992066277

Epoch: 6| Step: 4
Training loss: 0.4127364788474756
Validation loss: 2.577211440762141

Epoch: 6| Step: 5
Training loss: 0.2840859432219934
Validation loss: 2.54400074173923

Epoch: 6| Step: 6
Training loss: 0.32663914908016595
Validation loss: 2.5414172671679247

Epoch: 6| Step: 7
Training loss: 0.3911258157347929
Validation loss: 2.5453123987158914

Epoch: 6| Step: 8
Training loss: 0.4146316143976907
Validation loss: 2.522148382889739

Epoch: 6| Step: 9
Training loss: 0.695299019843598
Validation loss: 2.4897072132614775

Epoch: 6| Step: 10
Training loss: 0.5072926721686934
Validation loss: 2.4678702510076613

Epoch: 6| Step: 11
Training loss: 0.4049349370840872
Validation loss: 2.50617132498391

Epoch: 6| Step: 12
Training loss: 0.37906826134412913
Validation loss: 2.475493950318113

Epoch: 6| Step: 13
Training loss: 0.15230004588487753
Validation loss: 2.4841635855229605

Epoch: 429| Step: 0
Training loss: 0.3455680971401257
Validation loss: 2.5281487064701946

Epoch: 6| Step: 1
Training loss: 0.31589911285211214
Validation loss: 2.5385641901743417

Epoch: 6| Step: 2
Training loss: 0.26846218943714023
Validation loss: 2.5510790223517255

Epoch: 6| Step: 3
Training loss: 0.468816720664581
Validation loss: 2.5456585178606908

Epoch: 6| Step: 4
Training loss: 0.2870054770638213
Validation loss: 2.521877193372461

Epoch: 6| Step: 5
Training loss: 0.37449061049517973
Validation loss: 2.53250005672666

Epoch: 6| Step: 6
Training loss: 0.540555324364356
Validation loss: 2.5117058007027966

Epoch: 6| Step: 7
Training loss: 0.5393682801235811
Validation loss: 2.4480321713341024

Epoch: 6| Step: 8
Training loss: 0.3119305787225308
Validation loss: 2.448169584349732

Epoch: 6| Step: 9
Training loss: 0.5387248211705596
Validation loss: 2.3999027870641907

Epoch: 6| Step: 10
Training loss: 0.3992570414534307
Validation loss: 2.421396420047155

Epoch: 6| Step: 11
Training loss: 0.47686175034241174
Validation loss: 2.4534946129499127

Epoch: 6| Step: 12
Training loss: 0.3984122174787263
Validation loss: 2.449565649550145

Epoch: 6| Step: 13
Training loss: 0.3950039515116572
Validation loss: 2.516259955753931

Epoch: 430| Step: 0
Training loss: 0.3171603552943224
Validation loss: 2.5219325637962076

Epoch: 6| Step: 1
Training loss: 0.5691028464613965
Validation loss: 2.605707654918544

Epoch: 6| Step: 2
Training loss: 0.5114688408646964
Validation loss: 2.606997514012728

Epoch: 6| Step: 3
Training loss: 0.37103770987349854
Validation loss: 2.598084977587687

Epoch: 6| Step: 4
Training loss: 0.5271613476682184
Validation loss: 2.5925126042977644

Epoch: 6| Step: 5
Training loss: 0.5180705481102105
Validation loss: 2.571228669965194

Epoch: 6| Step: 6
Training loss: 0.23530419850492557
Validation loss: 2.5590189718437224

Epoch: 6| Step: 7
Training loss: 0.19402800657338795
Validation loss: 2.547633659206106

Epoch: 6| Step: 8
Training loss: 0.35878269478552116
Validation loss: 2.5030928318169465

Epoch: 6| Step: 9
Training loss: 0.3259971516154187
Validation loss: 2.4525193485107537

Epoch: 6| Step: 10
Training loss: 0.47618535236315446
Validation loss: 2.4709413532187345

Epoch: 6| Step: 11
Training loss: 0.3669982584826235
Validation loss: 2.482630016692454

Epoch: 6| Step: 12
Training loss: 0.3750380258354145
Validation loss: 2.5156596161077145

Epoch: 6| Step: 13
Training loss: 0.4330503478126904
Validation loss: 2.52285248400148

Epoch: 431| Step: 0
Training loss: 0.3461933647068083
Validation loss: 2.499158293532813

Epoch: 6| Step: 1
Training loss: 0.5441970653523505
Validation loss: 2.5344823052742087

Epoch: 6| Step: 2
Training loss: 0.268842508230032
Validation loss: 2.570035166757774

Epoch: 6| Step: 3
Training loss: 0.5145078753025278
Validation loss: 2.5677448669389187

Epoch: 6| Step: 4
Training loss: 0.42282657681621494
Validation loss: 2.5796096588972084

Epoch: 6| Step: 5
Training loss: 0.37029165619724624
Validation loss: 2.550625719129328

Epoch: 6| Step: 6
Training loss: 0.32874660423106006
Validation loss: 2.4943511619891012

Epoch: 6| Step: 7
Training loss: 0.5246988727184507
Validation loss: 2.5000300108226057

Epoch: 6| Step: 8
Training loss: 0.36356783401985837
Validation loss: 2.4514312613434317

Epoch: 6| Step: 9
Training loss: 0.4582857862287697
Validation loss: 2.4636578310811417

Epoch: 6| Step: 10
Training loss: 0.3046678023206725
Validation loss: 2.4703516252788784

Epoch: 6| Step: 11
Training loss: 0.3008474673418645
Validation loss: 2.4927343133245534

Epoch: 6| Step: 12
Training loss: 0.3979777694476866
Validation loss: 2.4966961579875835

Epoch: 6| Step: 13
Training loss: 0.1752249870132521
Validation loss: 2.4929622649792194

Epoch: 432| Step: 0
Training loss: 0.16740731179094864
Validation loss: 2.487920295672196

Epoch: 6| Step: 1
Training loss: 0.3143935887621853
Validation loss: 2.5013474309572836

Epoch: 6| Step: 2
Training loss: 0.2620948821607693
Validation loss: 2.51045154385105

Epoch: 6| Step: 3
Training loss: 0.42055486831282735
Validation loss: 2.514297574355167

Epoch: 6| Step: 4
Training loss: 0.2901075776731168
Validation loss: 2.5146952088933845

Epoch: 6| Step: 5
Training loss: 0.51308456902817
Validation loss: 2.5106410779503565

Epoch: 6| Step: 6
Training loss: 0.2994340724442353
Validation loss: 2.47270339060084

Epoch: 6| Step: 7
Training loss: 0.3411936969037088
Validation loss: 2.477486827107498

Epoch: 6| Step: 8
Training loss: 0.3659248557052229
Validation loss: 2.431958960079735

Epoch: 6| Step: 9
Training loss: 0.49487672041295017
Validation loss: 2.4087617781375976

Epoch: 6| Step: 10
Training loss: 0.47325810032948556
Validation loss: 2.440097513908916

Epoch: 6| Step: 11
Training loss: 0.6029353144920347
Validation loss: 2.4483780144487035

Epoch: 6| Step: 12
Training loss: 0.45953310367193495
Validation loss: 2.4960292692481767

Epoch: 6| Step: 13
Training loss: 0.3081742465337964
Validation loss: 2.5225976905129373

Epoch: 433| Step: 0
Training loss: 0.2820457090227227
Validation loss: 2.5519481978928282

Epoch: 6| Step: 1
Training loss: 0.33661719248840255
Validation loss: 2.555718985801341

Epoch: 6| Step: 2
Training loss: 0.48348568215714494
Validation loss: 2.5478980111493876

Epoch: 6| Step: 3
Training loss: 0.40817943303470844
Validation loss: 2.579650958308808

Epoch: 6| Step: 4
Training loss: 0.5076081671799488
Validation loss: 2.53410781201081

Epoch: 6| Step: 5
Training loss: 0.32993209588173417
Validation loss: 2.531630624795414

Epoch: 6| Step: 6
Training loss: 0.2791288177017321
Validation loss: 2.545279788870916

Epoch: 6| Step: 7
Training loss: 0.3765502516151391
Validation loss: 2.5502624833456307

Epoch: 6| Step: 8
Training loss: 0.2948924422577235
Validation loss: 2.5476728043233137

Epoch: 6| Step: 9
Training loss: 0.4156957300851483
Validation loss: 2.5419123097345055

Epoch: 6| Step: 10
Training loss: 0.4081890706102337
Validation loss: 2.525077090837426

Epoch: 6| Step: 11
Training loss: 0.407184918879235
Validation loss: 2.5251542757286387

Epoch: 6| Step: 12
Training loss: 0.39700208416446964
Validation loss: 2.515816867395158

Epoch: 6| Step: 13
Training loss: 0.3394586310252881
Validation loss: 2.533255327253763

Epoch: 434| Step: 0
Training loss: 0.5269835195407478
Validation loss: 2.5343923090962273

Epoch: 6| Step: 1
Training loss: 0.23730478953920534
Validation loss: 2.4832333189562656

Epoch: 6| Step: 2
Training loss: 0.23094516747874252
Validation loss: 2.463320723618236

Epoch: 6| Step: 3
Training loss: 0.34798364546591737
Validation loss: 2.4956737422159936

Epoch: 6| Step: 4
Training loss: 0.4607627019968328
Validation loss: 2.5191014346695515

Epoch: 6| Step: 5
Training loss: 0.33671121433968654
Validation loss: 2.538683817527278

Epoch: 6| Step: 6
Training loss: 0.3037848796558969
Validation loss: 2.5170665074004854

Epoch: 6| Step: 7
Training loss: 0.38256064713329624
Validation loss: 2.5503058573223143

Epoch: 6| Step: 8
Training loss: 0.46594505319287344
Validation loss: 2.5710789567248957

Epoch: 6| Step: 9
Training loss: 0.4067391605070028
Validation loss: 2.5553436575622115

Epoch: 6| Step: 10
Training loss: 0.5292292759369164
Validation loss: 2.556553530208581

Epoch: 6| Step: 11
Training loss: 0.3067467256906009
Validation loss: 2.5621540147146185

Epoch: 6| Step: 12
Training loss: 0.23307671179780612
Validation loss: 2.4952963860272774

Epoch: 6| Step: 13
Training loss: 0.478203948365643
Validation loss: 2.517480499035308

Epoch: 435| Step: 0
Training loss: 0.46011008337061365
Validation loss: 2.52863474731374

Epoch: 6| Step: 1
Training loss: 0.26892371052827113
Validation loss: 2.5404751768928673

Epoch: 6| Step: 2
Training loss: 0.4445344251039947
Validation loss: 2.545095468639538

Epoch: 6| Step: 3
Training loss: 0.43459167427965667
Validation loss: 2.5484410050234136

Epoch: 6| Step: 4
Training loss: 0.4643673739827531
Validation loss: 2.57161019032691

Epoch: 6| Step: 5
Training loss: 0.33029647241502275
Validation loss: 2.511353617910236

Epoch: 6| Step: 6
Training loss: 0.24001176335891405
Validation loss: 2.5170206009994893

Epoch: 6| Step: 7
Training loss: 0.21003579867726818
Validation loss: 2.534573263197646

Epoch: 6| Step: 8
Training loss: 0.4023295650018626
Validation loss: 2.4976094126877735

Epoch: 6| Step: 9
Training loss: 0.410205910718954
Validation loss: 2.5233658366705995

Epoch: 6| Step: 10
Training loss: 0.39446142730770123
Validation loss: 2.51001731798275

Epoch: 6| Step: 11
Training loss: 0.3033952697769279
Validation loss: 2.5201781619912085

Epoch: 6| Step: 12
Training loss: 0.41694088693992054
Validation loss: 2.518450617134598

Epoch: 6| Step: 13
Training loss: 0.3869311972554431
Validation loss: 2.5119166295541624

Epoch: 436| Step: 0
Training loss: 0.48529159820212037
Validation loss: 2.5230110671941173

Epoch: 6| Step: 1
Training loss: 0.28202678116826946
Validation loss: 2.5211927774136105

Epoch: 6| Step: 2
Training loss: 0.1675125847544049
Validation loss: 2.5262727395566227

Epoch: 6| Step: 3
Training loss: 0.3330730475017101
Validation loss: 2.5349526477078834

Epoch: 6| Step: 4
Training loss: 0.3062536385378436
Validation loss: 2.545886776773041

Epoch: 6| Step: 5
Training loss: 0.44231619764924784
Validation loss: 2.5187015460490754

Epoch: 6| Step: 6
Training loss: 0.561412979540052
Validation loss: 2.554807993975701

Epoch: 6| Step: 7
Training loss: 0.2765197737066178
Validation loss: 2.534518773800465

Epoch: 6| Step: 8
Training loss: 0.4181303620956846
Validation loss: 2.5053604416131505

Epoch: 6| Step: 9
Training loss: 0.308307853281703
Validation loss: 2.4756941831855994

Epoch: 6| Step: 10
Training loss: 0.46335829275928125
Validation loss: 2.4815910747793626

Epoch: 6| Step: 11
Training loss: 0.4849109453358832
Validation loss: 2.4861868155936135

Epoch: 6| Step: 12
Training loss: 0.34198684862502093
Validation loss: 2.4945390626373998

Epoch: 6| Step: 13
Training loss: 0.1503135062320838
Validation loss: 2.501293249852862

Epoch: 437| Step: 0
Training loss: 0.31035404096301544
Validation loss: 2.4835250591425617

Epoch: 6| Step: 1
Training loss: 0.31869264722468976
Validation loss: 2.5210320734978855

Epoch: 6| Step: 2
Training loss: 0.4433642483750092
Validation loss: 2.5157844392551

Epoch: 6| Step: 3
Training loss: 0.3177432786244147
Validation loss: 2.508313998018812

Epoch: 6| Step: 4
Training loss: 0.46123449811239503
Validation loss: 2.525641243018923

Epoch: 6| Step: 5
Training loss: 0.3228328221692391
Validation loss: 2.5160450020113845

Epoch: 6| Step: 6
Training loss: 0.3373830323275448
Validation loss: 2.492369865611307

Epoch: 6| Step: 7
Training loss: 0.510006873093835
Validation loss: 2.5196371224294687

Epoch: 6| Step: 8
Training loss: 0.353335550716628
Validation loss: 2.505641155313054

Epoch: 6| Step: 9
Training loss: 0.2888039128228669
Validation loss: 2.515794079188303

Epoch: 6| Step: 10
Training loss: 0.2703953450652605
Validation loss: 2.5150827760908254

Epoch: 6| Step: 11
Training loss: 0.39313943314855854
Validation loss: 2.5130589551083498

Epoch: 6| Step: 12
Training loss: 0.38317178876104535
Validation loss: 2.5071631458433887

Epoch: 6| Step: 13
Training loss: 0.6005692394385405
Validation loss: 2.4946206248048917

Epoch: 438| Step: 0
Training loss: 0.43527940483285515
Validation loss: 2.5028353389451676

Epoch: 6| Step: 1
Training loss: 0.26873207476075217
Validation loss: 2.5266904876607317

Epoch: 6| Step: 2
Training loss: 0.5290365106606244
Validation loss: 2.4811453743515566

Epoch: 6| Step: 3
Training loss: 0.44283127106243914
Validation loss: 2.5045448174813947

Epoch: 6| Step: 4
Training loss: 0.20395137426416476
Validation loss: 2.486010521251038

Epoch: 6| Step: 5
Training loss: 0.27368149089553917
Validation loss: 2.5080579708409503

Epoch: 6| Step: 6
Training loss: 0.2487474071065631
Validation loss: 2.521903873877115

Epoch: 6| Step: 7
Training loss: 0.27073339152712017
Validation loss: 2.492198152892561

Epoch: 6| Step: 8
Training loss: 0.39253479448006906
Validation loss: 2.5122272737905043

Epoch: 6| Step: 9
Training loss: 0.4994695949598611
Validation loss: 2.5097193552211983

Epoch: 6| Step: 10
Training loss: 0.2863383027228544
Validation loss: 2.4913043303977656

Epoch: 6| Step: 11
Training loss: 0.2722822033775588
Validation loss: 2.459436281482112

Epoch: 6| Step: 12
Training loss: 0.35657030814177876
Validation loss: 2.4878938561102513

Epoch: 6| Step: 13
Training loss: 0.5626630281920932
Validation loss: 2.45858327124459

Epoch: 439| Step: 0
Training loss: 0.17934270617906967
Validation loss: 2.486350489866709

Epoch: 6| Step: 1
Training loss: 0.29764234355170244
Validation loss: 2.4961140338595356

Epoch: 6| Step: 2
Training loss: 0.4557887410779845
Validation loss: 2.5109325187510105

Epoch: 6| Step: 3
Training loss: 0.32456310782549186
Validation loss: 2.553503363102734

Epoch: 6| Step: 4
Training loss: 0.5015647068153389
Validation loss: 2.559175858875015

Epoch: 6| Step: 5
Training loss: 0.45995287068090396
Validation loss: 2.584702898473641

Epoch: 6| Step: 6
Training loss: 0.4535226392573186
Validation loss: 2.5268434375890467

Epoch: 6| Step: 7
Training loss: 0.2994638674048493
Validation loss: 2.5007096278137677

Epoch: 6| Step: 8
Training loss: 0.37325309126660383
Validation loss: 2.521937146345975

Epoch: 6| Step: 9
Training loss: 0.17013787101151348
Validation loss: 2.5275169199496514

Epoch: 6| Step: 10
Training loss: 0.32663001361901317
Validation loss: 2.5172021429278466

Epoch: 6| Step: 11
Training loss: 0.4723113827431571
Validation loss: 2.504158062005798

Epoch: 6| Step: 12
Training loss: 0.4413722539992949
Validation loss: 2.5308122052466397

Epoch: 6| Step: 13
Training loss: 0.2341138417858449
Validation loss: 2.5259019470308957

Epoch: 440| Step: 0
Training loss: 0.23201681952766615
Validation loss: 2.499004358539064

Epoch: 6| Step: 1
Training loss: 0.4366161751432759
Validation loss: 2.515948861294566

Epoch: 6| Step: 2
Training loss: 0.29037211141820435
Validation loss: 2.5080215540240047

Epoch: 6| Step: 3
Training loss: 0.34452402146210626
Validation loss: 2.5266728514060093

Epoch: 6| Step: 4
Training loss: 0.4808821411693331
Validation loss: 2.5050900571031636

Epoch: 6| Step: 5
Training loss: 0.4735700900046162
Validation loss: 2.5173495091241778

Epoch: 6| Step: 6
Training loss: 0.36971353547229546
Validation loss: 2.532998019120659

Epoch: 6| Step: 7
Training loss: 0.3045732455120327
Validation loss: 2.5346730587691675

Epoch: 6| Step: 8
Training loss: 0.2071235558926249
Validation loss: 2.5412254411133843

Epoch: 6| Step: 9
Training loss: 0.2237632404437674
Validation loss: 2.5057572765451828

Epoch: 6| Step: 10
Training loss: 0.3182157180658177
Validation loss: 2.5196165726206883

Epoch: 6| Step: 11
Training loss: 0.4761277075820976
Validation loss: 2.4807245408302676

Epoch: 6| Step: 12
Training loss: 0.40154490747767235
Validation loss: 2.430304443779106

Epoch: 6| Step: 13
Training loss: 0.33058204782914113
Validation loss: 2.480533476083466

Epoch: 441| Step: 0
Training loss: 0.37054814836515315
Validation loss: 2.458696974504798

Epoch: 6| Step: 1
Training loss: 0.22490467065360253
Validation loss: 2.4607068640158642

Epoch: 6| Step: 2
Training loss: 0.23590880623707305
Validation loss: 2.48267964031027

Epoch: 6| Step: 3
Training loss: 0.3442890968422283
Validation loss: 2.4830284976557313

Epoch: 6| Step: 4
Training loss: 0.45166842066446544
Validation loss: 2.505116954261972

Epoch: 6| Step: 5
Training loss: 0.41432000196555796
Validation loss: 2.5193401020277597

Epoch: 6| Step: 6
Training loss: 0.37482213729623154
Validation loss: 2.555183109938032

Epoch: 6| Step: 7
Training loss: 0.3546450787017657
Validation loss: 2.5417668333611445

Epoch: 6| Step: 8
Training loss: 0.45346462741734167
Validation loss: 2.5505110137346425

Epoch: 6| Step: 9
Training loss: 0.31049056112375406
Validation loss: 2.5239704965711893

Epoch: 6| Step: 10
Training loss: 0.2997815499090983
Validation loss: 2.5010469172431837

Epoch: 6| Step: 11
Training loss: 0.28401078123713663
Validation loss: 2.511187962413022

Epoch: 6| Step: 12
Training loss: 0.475264313215891
Validation loss: 2.491600025756587

Epoch: 6| Step: 13
Training loss: 0.34072423198201107
Validation loss: 2.5115983068126764

Epoch: 442| Step: 0
Training loss: 0.28767395302805854
Validation loss: 2.530617260490074

Epoch: 6| Step: 1
Training loss: 0.4295900928022248
Validation loss: 2.542168541641993

Epoch: 6| Step: 2
Training loss: 0.3285869003975091
Validation loss: 2.556982908754463

Epoch: 6| Step: 3
Training loss: 0.25339775519340185
Validation loss: 2.5671754627855443

Epoch: 6| Step: 4
Training loss: 0.3612547103944328
Validation loss: 2.580699215471559

Epoch: 6| Step: 5
Training loss: 0.35433862055386245
Validation loss: 2.551468382615094

Epoch: 6| Step: 6
Training loss: 0.504993773318135
Validation loss: 2.492631088199581

Epoch: 6| Step: 7
Training loss: 0.31114448769713376
Validation loss: 2.5179040738018634

Epoch: 6| Step: 8
Training loss: 0.31352189588893736
Validation loss: 2.5192604870185935

Epoch: 6| Step: 9
Training loss: 0.29662121415646014
Validation loss: 2.4528382327508536

Epoch: 6| Step: 10
Training loss: 0.32753215320740325
Validation loss: 2.517841996562971

Epoch: 6| Step: 11
Training loss: 0.25287269627723385
Validation loss: 2.5106715081194326

Epoch: 6| Step: 12
Training loss: 0.5392672661239698
Validation loss: 2.4890203125498505

Epoch: 6| Step: 13
Training loss: 0.33558058075375513
Validation loss: 2.5195300513764916

Epoch: 443| Step: 0
Training loss: 0.22694758869713044
Validation loss: 2.561653791839827

Epoch: 6| Step: 1
Training loss: 0.6007010248836857
Validation loss: 2.607179263776441

Epoch: 6| Step: 2
Training loss: 0.33197822147342954
Validation loss: 2.564751699986425

Epoch: 6| Step: 3
Training loss: 0.27575158075777023
Validation loss: 2.5830687633188263

Epoch: 6| Step: 4
Training loss: 0.5121920195235244
Validation loss: 2.5654358961597317

Epoch: 6| Step: 5
Training loss: 0.3790599668501505
Validation loss: 2.51060618561439

Epoch: 6| Step: 6
Training loss: 0.18335558275836758
Validation loss: 2.495117209590455

Epoch: 6| Step: 7
Training loss: 0.2482594757903095
Validation loss: 2.5348972560080014

Epoch: 6| Step: 8
Training loss: 0.42623507960206847
Validation loss: 2.5035676221507783

Epoch: 6| Step: 9
Training loss: 0.40571382793116695
Validation loss: 2.4804167907662666

Epoch: 6| Step: 10
Training loss: 0.2877324926484118
Validation loss: 2.533508816174933

Epoch: 6| Step: 11
Training loss: 0.2617418506732756
Validation loss: 2.532451555624297

Epoch: 6| Step: 12
Training loss: 0.26658593994870405
Validation loss: 2.563516696754438

Epoch: 6| Step: 13
Training loss: 0.31454767262942873
Validation loss: 2.5728337845529006

Epoch: 444| Step: 0
Training loss: 0.18230395048624742
Validation loss: 2.5810731976988737

Epoch: 6| Step: 1
Training loss: 0.4413498698999186
Validation loss: 2.5966266583672497

Epoch: 6| Step: 2
Training loss: 0.4368381603136316
Validation loss: 2.5766522956581848

Epoch: 6| Step: 3
Training loss: 0.17480548666659476
Validation loss: 2.549515790547544

Epoch: 6| Step: 4
Training loss: 0.3619246018630658
Validation loss: 2.5727908606176775

Epoch: 6| Step: 5
Training loss: 0.23523447281890225
Validation loss: 2.531112357240443

Epoch: 6| Step: 6
Training loss: 0.2957607238386014
Validation loss: 2.455473382502578

Epoch: 6| Step: 7
Training loss: 0.39460073935530815
Validation loss: 2.498255086890885

Epoch: 6| Step: 8
Training loss: 0.3967713693802266
Validation loss: 2.426413598454377

Epoch: 6| Step: 9
Training loss: 0.4835238823776539
Validation loss: 2.47503067135153

Epoch: 6| Step: 10
Training loss: 0.46904352852452186
Validation loss: 2.473488507997596

Epoch: 6| Step: 11
Training loss: 0.322923093649782
Validation loss: 2.5011087143329416

Epoch: 6| Step: 12
Training loss: 0.3091952823024243
Validation loss: 2.5285516715889114

Epoch: 6| Step: 13
Training loss: 0.33253735509931726
Validation loss: 2.5420605175971462

Epoch: 445| Step: 0
Training loss: 0.35802902183828267
Validation loss: 2.5431132249006603

Epoch: 6| Step: 1
Training loss: 0.2930972008445557
Validation loss: 2.558038683183098

Epoch: 6| Step: 2
Training loss: 0.494085949673639
Validation loss: 2.545004451362293

Epoch: 6| Step: 3
Training loss: 0.1962139688204881
Validation loss: 2.5403265248398403

Epoch: 6| Step: 4
Training loss: 0.19685284701854527
Validation loss: 2.5361654808224317

Epoch: 6| Step: 5
Training loss: 0.4079932079193951
Validation loss: 2.5456264547603173

Epoch: 6| Step: 6
Training loss: 0.3255565572845474
Validation loss: 2.5415584430889737

Epoch: 6| Step: 7
Training loss: 0.22157380856707237
Validation loss: 2.517220563028447

Epoch: 6| Step: 8
Training loss: 0.3615956527492422
Validation loss: 2.534108858566792

Epoch: 6| Step: 9
Training loss: 0.4660001363682445
Validation loss: 2.548854905093363

Epoch: 6| Step: 10
Training loss: 0.44054220246828696
Validation loss: 2.543348026233463

Epoch: 6| Step: 11
Training loss: 0.49418926376581873
Validation loss: 2.5626698119300313

Epoch: 6| Step: 12
Training loss: 0.35381902668264525
Validation loss: 2.614436604157168

Epoch: 6| Step: 13
Training loss: 0.32052040331074744
Validation loss: 2.5761983594057276

Epoch: 446| Step: 0
Training loss: 0.37952088126305994
Validation loss: 2.6000403599095234

Epoch: 6| Step: 1
Training loss: 0.3249501171711142
Validation loss: 2.548254684572919

Epoch: 6| Step: 2
Training loss: 0.276026377464432
Validation loss: 2.5359997088445505

Epoch: 6| Step: 3
Training loss: 0.34552750733494425
Validation loss: 2.4570117907085547

Epoch: 6| Step: 4
Training loss: 0.3459217436319949
Validation loss: 2.516534091619722

Epoch: 6| Step: 5
Training loss: 0.4283664857648838
Validation loss: 2.47969416961537

Epoch: 6| Step: 6
Training loss: 0.49116424884703713
Validation loss: 2.532611432692749

Epoch: 6| Step: 7
Training loss: 0.3078006015937161
Validation loss: 2.5637640837781026

Epoch: 6| Step: 8
Training loss: 0.3253777023991645
Validation loss: 2.5913190147606047

Epoch: 6| Step: 9
Training loss: 0.30378420519443555
Validation loss: 2.63495256963963

Epoch: 6| Step: 10
Training loss: 0.3182683943416785
Validation loss: 2.631648099295113

Epoch: 6| Step: 11
Training loss: 0.36457992506704784
Validation loss: 2.6437988915178736

Epoch: 6| Step: 12
Training loss: 0.5569386002584623
Validation loss: 2.61427240141129

Epoch: 6| Step: 13
Training loss: 0.14507849936162237
Validation loss: 2.5400693027213492

Epoch: 447| Step: 0
Training loss: 0.2941572369549116
Validation loss: 2.517008832969806

Epoch: 6| Step: 1
Training loss: 0.32591562998722295
Validation loss: 2.4994509858092195

Epoch: 6| Step: 2
Training loss: 0.3884537242775685
Validation loss: 2.485621862744024

Epoch: 6| Step: 3
Training loss: 0.24694472728571687
Validation loss: 2.4948192470486137

Epoch: 6| Step: 4
Training loss: 0.4979101853633832
Validation loss: 2.4960397301131514

Epoch: 6| Step: 5
Training loss: 0.3185633608481047
Validation loss: 2.5245495926810753

Epoch: 6| Step: 6
Training loss: 0.2547204388340298
Validation loss: 2.534306197207841

Epoch: 6| Step: 7
Training loss: 0.24029536364736342
Validation loss: 2.544934920218192

Epoch: 6| Step: 8
Training loss: 0.4954252469715666
Validation loss: 2.534534399251288

Epoch: 6| Step: 9
Training loss: 0.5271459420404098
Validation loss: 2.5027645494588127

Epoch: 6| Step: 10
Training loss: 0.45167628903831336
Validation loss: 2.5346540650817144

Epoch: 6| Step: 11
Training loss: 0.38566633033916364
Validation loss: 2.5332893816541406

Epoch: 6| Step: 12
Training loss: 0.3619271956900298
Validation loss: 2.5134467088239645

Epoch: 6| Step: 13
Training loss: 0.2642796470040463
Validation loss: 2.4841714647807214

Epoch: 448| Step: 0
Training loss: 0.40278381059045637
Validation loss: 2.4782783555507235

Epoch: 6| Step: 1
Training loss: 0.4837082457696644
Validation loss: 2.4669178467075663

Epoch: 6| Step: 2
Training loss: 0.43105666761198463
Validation loss: 2.45766044391303

Epoch: 6| Step: 3
Training loss: 0.3158496623653548
Validation loss: 2.473174645086753

Epoch: 6| Step: 4
Training loss: 0.33121539465965305
Validation loss: 2.5057922530257657

Epoch: 6| Step: 5
Training loss: 0.28920776995523534
Validation loss: 2.5388097306888118

Epoch: 6| Step: 6
Training loss: 0.23860686364200273
Validation loss: 2.5270879454712203

Epoch: 6| Step: 7
Training loss: 0.4370809489561828
Validation loss: 2.543192434922113

Epoch: 6| Step: 8
Training loss: 0.49717597363032767
Validation loss: 2.592459231828099

Epoch: 6| Step: 9
Training loss: 0.2142588630170636
Validation loss: 2.577048318073445

Epoch: 6| Step: 10
Training loss: 0.3088003022611206
Validation loss: 2.5973783107646784

Epoch: 6| Step: 11
Training loss: 0.3518561514350987
Validation loss: 2.652962059645984

Epoch: 6| Step: 12
Training loss: 0.22092544700842384
Validation loss: 2.629263128679622

Epoch: 6| Step: 13
Training loss: 0.5254612985037821
Validation loss: 2.6020305749149353

Epoch: 449| Step: 0
Training loss: 0.40938375478221006
Validation loss: 2.5734008792434038

Epoch: 6| Step: 1
Training loss: 0.3676690738061099
Validation loss: 2.5727376041491365

Epoch: 6| Step: 2
Training loss: 0.3231868408394109
Validation loss: 2.572484940763499

Epoch: 6| Step: 3
Training loss: 0.4660308170320429
Validation loss: 2.5649542771870797

Epoch: 6| Step: 4
Training loss: 0.3905515220199267
Validation loss: 2.595760755588136

Epoch: 6| Step: 5
Training loss: 0.4028851468296513
Validation loss: 2.535993985125574

Epoch: 6| Step: 6
Training loss: 0.41942448100980895
Validation loss: 2.550443756898189

Epoch: 6| Step: 7
Training loss: 0.2588046519064435
Validation loss: 2.527026431662084

Epoch: 6| Step: 8
Training loss: 0.3262337951362675
Validation loss: 2.503340195083483

Epoch: 6| Step: 9
Training loss: 0.3074193409060354
Validation loss: 2.500796392708084

Epoch: 6| Step: 10
Training loss: 0.2575901112704968
Validation loss: 2.4744650103759036

Epoch: 6| Step: 11
Training loss: 0.5134432613910938
Validation loss: 2.5265588519960374

Epoch: 6| Step: 12
Training loss: 0.4638027748761027
Validation loss: 2.531939038140299

Epoch: 6| Step: 13
Training loss: 0.24651013827608756
Validation loss: 2.5131513463607766

Epoch: 450| Step: 0
Training loss: 0.19153688799414212
Validation loss: 2.5058736742473102

Epoch: 6| Step: 1
Training loss: 0.19422852121019699
Validation loss: 2.5692633277791734

Epoch: 6| Step: 2
Training loss: 0.4904254981514897
Validation loss: 2.57128907346728

Epoch: 6| Step: 3
Training loss: 0.3040914329257854
Validation loss: 2.556635287420203

Epoch: 6| Step: 4
Training loss: 0.4481169249260616
Validation loss: 2.5538544623944976

Epoch: 6| Step: 5
Training loss: 0.46730444857355197
Validation loss: 2.5281590881771208

Epoch: 6| Step: 6
Training loss: 0.33121376379215156
Validation loss: 2.5128024482912417

Epoch: 6| Step: 7
Training loss: 0.3445238592691555
Validation loss: 2.547651428090699

Epoch: 6| Step: 8
Training loss: 0.33474164852425065
Validation loss: 2.504755068464905

Epoch: 6| Step: 9
Training loss: 0.234151415673293
Validation loss: 2.549432849225527

Epoch: 6| Step: 10
Training loss: 0.3138074228088372
Validation loss: 2.5387124622208415

Epoch: 6| Step: 11
Training loss: 0.37361261898494386
Validation loss: 2.5561111641352596

Epoch: 6| Step: 12
Training loss: 0.4295886186051985
Validation loss: 2.53101898885274

Epoch: 6| Step: 13
Training loss: 0.21213310980032268
Validation loss: 2.5479526038068694

Testing loss: 2.7321168605835253
