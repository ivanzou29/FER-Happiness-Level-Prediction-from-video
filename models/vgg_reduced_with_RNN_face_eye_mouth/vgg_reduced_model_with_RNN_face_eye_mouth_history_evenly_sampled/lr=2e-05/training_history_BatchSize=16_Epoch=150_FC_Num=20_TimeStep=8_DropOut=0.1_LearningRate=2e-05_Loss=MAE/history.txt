Epoch: 1| Step: 0
Training loss: 4.2563886642456055
Validation loss: 5.255766458408807

Epoch: 6| Step: 1
Training loss: 5.745322227478027
Validation loss: 5.23238943981868

Epoch: 6| Step: 2
Training loss: 5.082008361816406
Validation loss: 5.211004821203089

Epoch: 6| Step: 3
Training loss: 5.428018093109131
Validation loss: 5.18772832808956

Epoch: 6| Step: 4
Training loss: 4.616172790527344
Validation loss: 5.162667582111974

Epoch: 6| Step: 5
Training loss: 5.924341201782227
Validation loss: 5.133367461542929

Epoch: 6| Step: 6
Training loss: 5.224629878997803
Validation loss: 5.100163511050645

Epoch: 6| Step: 7
Training loss: 4.892070293426514
Validation loss: 5.063152456796297

Epoch: 6| Step: 8
Training loss: 5.446786403656006
Validation loss: 5.021457297827608

Epoch: 6| Step: 9
Training loss: 4.49168586730957
Validation loss: 4.97397401255946

Epoch: 6| Step: 10
Training loss: 5.386039733886719
Validation loss: 4.921959338649627

Epoch: 6| Step: 11
Training loss: 4.265357494354248
Validation loss: 4.863627854213919

Epoch: 6| Step: 12
Training loss: 2.964569091796875
Validation loss: 4.801817770927183

Epoch: 6| Step: 13
Training loss: 3.742873191833496
Validation loss: 4.73532606965752

Epoch: 2| Step: 0
Training loss: 4.417319297790527
Validation loss: 4.667416782789333

Epoch: 6| Step: 1
Training loss: 4.469438076019287
Validation loss: 4.599649083229803

Epoch: 6| Step: 2
Training loss: 3.748605728149414
Validation loss: 4.526219778163458

Epoch: 6| Step: 3
Training loss: 3.9609789848327637
Validation loss: 4.455899541096021

Epoch: 6| Step: 4
Training loss: 4.70207405090332
Validation loss: 4.386090563189599

Epoch: 6| Step: 5
Training loss: 4.146666526794434
Validation loss: 4.318870472651656

Epoch: 6| Step: 6
Training loss: 4.633397102355957
Validation loss: 4.261294472602106

Epoch: 6| Step: 7
Training loss: 4.851463794708252
Validation loss: 4.203411076658515

Epoch: 6| Step: 8
Training loss: 4.3641839027404785
Validation loss: 4.150922477886241

Epoch: 6| Step: 9
Training loss: 2.5890064239501953
Validation loss: 4.100872931941863

Epoch: 6| Step: 10
Training loss: 4.458272457122803
Validation loss: 4.06068294279037

Epoch: 6| Step: 11
Training loss: 3.3195698261260986
Validation loss: 4.024244344362649

Epoch: 6| Step: 12
Training loss: 3.7957522869110107
Validation loss: 3.9894205165165726

Epoch: 6| Step: 13
Training loss: 3.9844534397125244
Validation loss: 3.9547833473451677

Epoch: 3| Step: 0
Training loss: 3.3575382232666016
Validation loss: 3.9146090553652857

Epoch: 6| Step: 1
Training loss: 3.7530977725982666
Validation loss: 3.8759247231227096

Epoch: 6| Step: 2
Training loss: 3.743900775909424
Validation loss: 3.8377501221113306

Epoch: 6| Step: 3
Training loss: 3.6298160552978516
Validation loss: 3.8024109050791752

Epoch: 6| Step: 4
Training loss: 4.341403007507324
Validation loss: 3.7677866540929323

Epoch: 6| Step: 5
Training loss: 4.743106365203857
Validation loss: 3.7373451417492283

Epoch: 6| Step: 6
Training loss: 3.843801975250244
Validation loss: 3.707688062421737

Epoch: 6| Step: 7
Training loss: 2.8988537788391113
Validation loss: 3.6765462839475243

Epoch: 6| Step: 8
Training loss: 3.6918225288391113
Validation loss: 3.6478729965866252

Epoch: 6| Step: 9
Training loss: 4.076998233795166
Validation loss: 3.6133374296208864

Epoch: 6| Step: 10
Training loss: 3.3351902961730957
Validation loss: 3.580357587465676

Epoch: 6| Step: 11
Training loss: 2.2391700744628906
Validation loss: 3.564807843136531

Epoch: 6| Step: 12
Training loss: 2.9605348110198975
Validation loss: 3.5540647686168714

Epoch: 6| Step: 13
Training loss: 3.983941078186035
Validation loss: 3.537297915386897

Epoch: 4| Step: 0
Training loss: 3.5339412689208984
Validation loss: 3.522841335624777

Epoch: 6| Step: 1
Training loss: 4.405797958374023
Validation loss: 3.5073835619034304

Epoch: 6| Step: 2
Training loss: 3.804091453552246
Validation loss: 3.490832144214261

Epoch: 6| Step: 3
Training loss: 3.860492706298828
Validation loss: 3.4785139381244616

Epoch: 6| Step: 4
Training loss: 3.33134126663208
Validation loss: 3.463019981179186

Epoch: 6| Step: 5
Training loss: 3.4349000453948975
Validation loss: 3.4467931665400022

Epoch: 6| Step: 6
Training loss: 2.5721726417541504
Validation loss: 3.4279956868899766

Epoch: 6| Step: 7
Training loss: 3.1701884269714355
Validation loss: 3.407427195579775

Epoch: 6| Step: 8
Training loss: 3.0045835971832275
Validation loss: 3.393128959081506

Epoch: 6| Step: 9
Training loss: 3.2287955284118652
Validation loss: 3.3857641450820433

Epoch: 6| Step: 10
Training loss: 3.8681278228759766
Validation loss: 3.362896873104957

Epoch: 6| Step: 11
Training loss: 2.665515661239624
Validation loss: 3.3485325228783394

Epoch: 6| Step: 12
Training loss: 2.966470241546631
Validation loss: 3.345788494233162

Epoch: 6| Step: 13
Training loss: 3.6179699897766113
Validation loss: 3.3488417210117465

Epoch: 5| Step: 0
Training loss: 4.213391304016113
Validation loss: 3.3353893269774733

Epoch: 6| Step: 1
Training loss: 3.324589252471924
Validation loss: 3.314039058582757

Epoch: 6| Step: 2
Training loss: 3.6419966220855713
Validation loss: 3.302085194536435

Epoch: 6| Step: 3
Training loss: 3.2296438217163086
Validation loss: 3.2884919105037564

Epoch: 6| Step: 4
Training loss: 3.296830177307129
Validation loss: 3.280759290982318

Epoch: 6| Step: 5
Training loss: 2.745389938354492
Validation loss: 3.2725478244084183

Epoch: 6| Step: 6
Training loss: 3.573208808898926
Validation loss: 3.2625094331720823

Epoch: 6| Step: 7
Training loss: 3.3629910945892334
Validation loss: 3.2539555103548112

Epoch: 6| Step: 8
Training loss: 2.390267848968506
Validation loss: 3.241136522703273

Epoch: 6| Step: 9
Training loss: 2.1142916679382324
Validation loss: 3.2324857557973554

Epoch: 6| Step: 10
Training loss: 3.8513994216918945
Validation loss: 3.220710451884936

Epoch: 6| Step: 11
Training loss: 3.7081236839294434
Validation loss: 3.2124140390785794

Epoch: 6| Step: 12
Training loss: 3.4367594718933105
Validation loss: 3.2073060671488443

Epoch: 6| Step: 13
Training loss: 1.9532792568206787
Validation loss: 3.200038035710653

Epoch: 6| Step: 0
Training loss: 3.3968234062194824
Validation loss: 3.1823571625576226

Epoch: 6| Step: 1
Training loss: 4.1120076179504395
Validation loss: 3.1828537910215315

Epoch: 6| Step: 2
Training loss: 4.315299034118652
Validation loss: 3.1763210450449297

Epoch: 6| Step: 3
Training loss: 3.0552356243133545
Validation loss: 3.166626468781502

Epoch: 6| Step: 4
Training loss: 2.325822353363037
Validation loss: 3.1533067072591474

Epoch: 6| Step: 5
Training loss: 3.2767934799194336
Validation loss: 3.1373267917222876

Epoch: 6| Step: 6
Training loss: 3.601653575897217
Validation loss: 3.133783681418306

Epoch: 6| Step: 7
Training loss: 2.1563234329223633
Validation loss: 3.1314831933667584

Epoch: 6| Step: 8
Training loss: 3.2072324752807617
Validation loss: 3.1235111708282144

Epoch: 6| Step: 9
Training loss: 2.760532855987549
Validation loss: 3.1058705673422864

Epoch: 6| Step: 10
Training loss: 3.1554501056671143
Validation loss: 3.0952097318505727

Epoch: 6| Step: 11
Training loss: 2.0541133880615234
Validation loss: 3.0908162029840613

Epoch: 6| Step: 12
Training loss: 3.1475167274475098
Validation loss: 3.087933450616816

Epoch: 6| Step: 13
Training loss: 3.9566714763641357
Validation loss: 3.086361349269908

Epoch: 7| Step: 0
Training loss: 3.3532981872558594
Validation loss: 3.077923164572767

Epoch: 6| Step: 1
Training loss: 3.9913575649261475
Validation loss: 3.0662945726866364

Epoch: 6| Step: 2
Training loss: 2.8315179347991943
Validation loss: 3.0564714964999946

Epoch: 6| Step: 3
Training loss: 3.1350574493408203
Validation loss: 3.0504128676588818

Epoch: 6| Step: 4
Training loss: 3.1818313598632812
Validation loss: 3.0465886900501866

Epoch: 6| Step: 5
Training loss: 3.2665395736694336
Validation loss: 3.0425605645743747

Epoch: 6| Step: 6
Training loss: 3.123522996902466
Validation loss: 3.0260697385316253

Epoch: 6| Step: 7
Training loss: 3.119020938873291
Validation loss: 3.021265883599558

Epoch: 6| Step: 8
Training loss: 3.219207763671875
Validation loss: 3.015148260260141

Epoch: 6| Step: 9
Training loss: 2.7655248641967773
Validation loss: 3.00763431672127

Epoch: 6| Step: 10
Training loss: 2.451840877532959
Validation loss: 2.9975267789697133

Epoch: 6| Step: 11
Training loss: 2.438209056854248
Validation loss: 2.9889647294116277

Epoch: 6| Step: 12
Training loss: 3.6239330768585205
Validation loss: 2.985678308753557

Epoch: 6| Step: 13
Training loss: 2.354090690612793
Validation loss: 2.974548045025077

Epoch: 8| Step: 0
Training loss: 3.1651225090026855
Validation loss: 2.9709876429650093

Epoch: 6| Step: 1
Training loss: 2.9156198501586914
Validation loss: 2.9657779662839827

Epoch: 6| Step: 2
Training loss: 2.836001396179199
Validation loss: 2.961931715729416

Epoch: 6| Step: 3
Training loss: 2.369291305541992
Validation loss: 2.96335934054467

Epoch: 6| Step: 4
Training loss: 3.242486000061035
Validation loss: 2.9624527295430503

Epoch: 6| Step: 5
Training loss: 3.8207621574401855
Validation loss: 2.9352727423432055

Epoch: 6| Step: 6
Training loss: 3.3011116981506348
Validation loss: 2.9296838852667038

Epoch: 6| Step: 7
Training loss: 2.5765249729156494
Validation loss: 2.9242870218010357

Epoch: 6| Step: 8
Training loss: 2.624863862991333
Validation loss: 2.917404379895938

Epoch: 6| Step: 9
Training loss: 3.0227415561676025
Validation loss: 2.9087497777836298

Epoch: 6| Step: 10
Training loss: 2.6461002826690674
Validation loss: 2.903418722973075

Epoch: 6| Step: 11
Training loss: 3.986219882965088
Validation loss: 2.8979851750917334

Epoch: 6| Step: 12
Training loss: 2.775352954864502
Validation loss: 2.8897152203385548

Epoch: 6| Step: 13
Training loss: 2.912357807159424
Validation loss: 2.8881806660723943

Epoch: 9| Step: 0
Training loss: 3.2533624172210693
Validation loss: 2.8795740681309856

Epoch: 6| Step: 1
Training loss: 2.9135947227478027
Validation loss: 2.8665244938224874

Epoch: 6| Step: 2
Training loss: 2.9005703926086426
Validation loss: 2.855349358691964

Epoch: 6| Step: 3
Training loss: 3.4538519382476807
Validation loss: 2.8522304360584547

Epoch: 6| Step: 4
Training loss: 3.0799176692962646
Validation loss: 2.85209257371964

Epoch: 6| Step: 5
Training loss: 3.144982099533081
Validation loss: 2.842508703149775

Epoch: 6| Step: 6
Training loss: 3.1089701652526855
Validation loss: 2.8362285398667857

Epoch: 6| Step: 7
Training loss: 3.0144553184509277
Validation loss: 2.819828120611047

Epoch: 6| Step: 8
Training loss: 2.9717280864715576
Validation loss: 2.8204418741246706

Epoch: 6| Step: 9
Training loss: 2.9517173767089844
Validation loss: 2.8224067585442656

Epoch: 6| Step: 10
Training loss: 3.318826913833618
Validation loss: 2.8025030166872087

Epoch: 6| Step: 11
Training loss: 2.6274704933166504
Validation loss: 2.7962187464519213

Epoch: 6| Step: 12
Training loss: 1.7369959354400635
Validation loss: 2.8025386205283542

Epoch: 6| Step: 13
Training loss: 2.913735866546631
Validation loss: 2.8310542029719197

Epoch: 10| Step: 0
Training loss: 2.5070104598999023
Validation loss: 2.8462793032328286

Epoch: 6| Step: 1
Training loss: 3.0530004501342773
Validation loss: 2.8430477316661547

Epoch: 6| Step: 2
Training loss: 2.6185312271118164
Validation loss: 2.825943649456065

Epoch: 6| Step: 3
Training loss: 3.0808286666870117
Validation loss: 2.814495043088031

Epoch: 6| Step: 4
Training loss: 2.6454591751098633
Validation loss: 2.7958475620515886

Epoch: 6| Step: 5
Training loss: 3.9172310829162598
Validation loss: 2.789132910390054

Epoch: 6| Step: 6
Training loss: 3.7798690795898438
Validation loss: 2.7867329761546147

Epoch: 6| Step: 7
Training loss: 2.667470932006836
Validation loss: 2.7871172658858763

Epoch: 6| Step: 8
Training loss: 2.000434637069702
Validation loss: 2.7743273037736134

Epoch: 6| Step: 9
Training loss: 2.6650431156158447
Validation loss: 2.7641885793337257

Epoch: 6| Step: 10
Training loss: 3.1444151401519775
Validation loss: 2.7597569214400424

Epoch: 6| Step: 11
Training loss: 3.0368499755859375
Validation loss: 2.743564392930718

Epoch: 6| Step: 12
Training loss: 3.009918212890625
Validation loss: 2.734611239484561

Epoch: 6| Step: 13
Training loss: 2.6759896278381348
Validation loss: 2.741076341239355

Epoch: 11| Step: 0
Training loss: 3.262441396713257
Validation loss: 2.719649399480512

Epoch: 6| Step: 1
Training loss: 3.0458974838256836
Validation loss: 2.712073036419448

Epoch: 6| Step: 2
Training loss: 3.123401165008545
Validation loss: 2.7101128844804663

Epoch: 6| Step: 3
Training loss: 2.4977216720581055
Validation loss: 2.710693402956891

Epoch: 6| Step: 4
Training loss: 2.526022434234619
Validation loss: 2.809171279271444

Epoch: 6| Step: 5
Training loss: 3.4323058128356934
Validation loss: 2.7232035283119447

Epoch: 6| Step: 6
Training loss: 2.6955766677856445
Validation loss: 2.700977699730986

Epoch: 6| Step: 7
Training loss: 2.9422779083251953
Validation loss: 2.724055051803589

Epoch: 6| Step: 8
Training loss: 2.749958038330078
Validation loss: 2.8042655324423187

Epoch: 6| Step: 9
Training loss: 3.481586217880249
Validation loss: 2.7535434384499826

Epoch: 6| Step: 10
Training loss: 3.011861801147461
Validation loss: 2.7172815850985947

Epoch: 6| Step: 11
Training loss: 2.5018835067749023
Validation loss: 2.6956716506711897

Epoch: 6| Step: 12
Training loss: 2.6474318504333496
Validation loss: 2.7000989734485583

Epoch: 6| Step: 13
Training loss: 2.3424229621887207
Validation loss: 2.741753060330627

Epoch: 12| Step: 0
Training loss: 3.1695613861083984
Validation loss: 2.7899393112428728

Epoch: 6| Step: 1
Training loss: 3.315507173538208
Validation loss: 2.790206506688108

Epoch: 6| Step: 2
Training loss: 2.5860729217529297
Validation loss: 2.755741996149863

Epoch: 6| Step: 3
Training loss: 3.029294013977051
Validation loss: 2.6924063467210337

Epoch: 6| Step: 4
Training loss: 2.563845634460449
Validation loss: 2.6711245993132233

Epoch: 6| Step: 5
Training loss: 3.462048053741455
Validation loss: 2.674134805638303

Epoch: 6| Step: 6
Training loss: 2.5530576705932617
Validation loss: 2.6841169711082213

Epoch: 6| Step: 7
Training loss: 2.5798797607421875
Validation loss: 2.707729467781641

Epoch: 6| Step: 8
Training loss: 2.6409668922424316
Validation loss: 2.6983098573582147

Epoch: 6| Step: 9
Training loss: 2.627887725830078
Validation loss: 2.6924433605645293

Epoch: 6| Step: 10
Training loss: 2.9580702781677246
Validation loss: 2.6714674990664244

Epoch: 6| Step: 11
Training loss: 3.2187161445617676
Validation loss: 2.6463638915810535

Epoch: 6| Step: 12
Training loss: 3.1151955127716064
Validation loss: 2.6364618680810414

Epoch: 6| Step: 13
Training loss: 2.1075680255889893
Validation loss: 2.6300664922242523

Epoch: 13| Step: 0
Training loss: 3.4134697914123535
Validation loss: 2.6455915281849522

Epoch: 6| Step: 1
Training loss: 3.1405491828918457
Validation loss: 2.6586456529555784

Epoch: 6| Step: 2
Training loss: 2.4529824256896973
Validation loss: 2.6312088351095877

Epoch: 6| Step: 3
Training loss: 2.762073040008545
Validation loss: 2.6229070360942552

Epoch: 6| Step: 4
Training loss: 3.1170873641967773
Validation loss: 2.613762935002645

Epoch: 6| Step: 5
Training loss: 2.6081511974334717
Validation loss: 2.612682129747124

Epoch: 6| Step: 6
Training loss: 2.8771469593048096
Validation loss: 2.61664225721872

Epoch: 6| Step: 7
Training loss: 2.772580146789551
Validation loss: 2.6190396278135237

Epoch: 6| Step: 8
Training loss: 2.204943895339966
Validation loss: 2.6130507351249777

Epoch: 6| Step: 9
Training loss: 2.218686819076538
Validation loss: 2.60951643349022

Epoch: 6| Step: 10
Training loss: 3.252593755722046
Validation loss: 2.615538525324996

Epoch: 6| Step: 11
Training loss: 3.0525972843170166
Validation loss: 2.6165997366751395

Epoch: 6| Step: 12
Training loss: 2.463630199432373
Validation loss: 2.613395280735467

Epoch: 6| Step: 13
Training loss: 3.309370279312134
Validation loss: 2.607234178050872

Epoch: 14| Step: 0
Training loss: 2.679919958114624
Validation loss: 2.6043892252829766

Epoch: 6| Step: 1
Training loss: 2.534891128540039
Validation loss: 2.5950572003600416

Epoch: 6| Step: 2
Training loss: 2.8883461952209473
Validation loss: 2.5894244691377044

Epoch: 6| Step: 3
Training loss: 2.4701714515686035
Validation loss: 2.5793830271690124

Epoch: 6| Step: 4
Training loss: 2.7853517532348633
Validation loss: 2.5748043906304146

Epoch: 6| Step: 5
Training loss: 2.8971822261810303
Validation loss: 2.5729221964395173

Epoch: 6| Step: 6
Training loss: 3.057126998901367
Validation loss: 2.571491000472858

Epoch: 6| Step: 7
Training loss: 2.2745420932769775
Validation loss: 2.5665586584357807

Epoch: 6| Step: 8
Training loss: 2.3157835006713867
Validation loss: 2.56067891018365

Epoch: 6| Step: 9
Training loss: 3.8858633041381836
Validation loss: 2.5587354962543776

Epoch: 6| Step: 10
Training loss: 2.8241794109344482
Validation loss: 2.550021266424528

Epoch: 6| Step: 11
Training loss: 2.8128437995910645
Validation loss: 2.5514849590998825

Epoch: 6| Step: 12
Training loss: 3.0527329444885254
Validation loss: 2.544998222781766

Epoch: 6| Step: 13
Training loss: 2.2341115474700928
Validation loss: 2.540232148221744

Epoch: 15| Step: 0
Training loss: 3.0542404651641846
Validation loss: 2.534088050165484

Epoch: 6| Step: 1
Training loss: 3.131625175476074
Validation loss: 2.530663659495692

Epoch: 6| Step: 2
Training loss: 3.507187843322754
Validation loss: 2.526966776899112

Epoch: 6| Step: 3
Training loss: 2.2278428077697754
Validation loss: 2.521444361696961

Epoch: 6| Step: 4
Training loss: 2.9575986862182617
Validation loss: 2.518319001761816

Epoch: 6| Step: 5
Training loss: 3.576489210128784
Validation loss: 2.5161586833256546

Epoch: 6| Step: 6
Training loss: 2.743865489959717
Validation loss: 2.5138040281111196

Epoch: 6| Step: 7
Training loss: 1.6274981498718262
Validation loss: 2.5085165628822903

Epoch: 6| Step: 8
Training loss: 2.1723575592041016
Validation loss: 2.503527092677291

Epoch: 6| Step: 9
Training loss: 2.7178940773010254
Validation loss: 2.503441790098785

Epoch: 6| Step: 10
Training loss: 2.5622570514678955
Validation loss: 2.5059081841540594

Epoch: 6| Step: 11
Training loss: 2.4681053161621094
Validation loss: 2.5136251295766523

Epoch: 6| Step: 12
Training loss: 2.962712526321411
Validation loss: 2.5215065184459893

Epoch: 6| Step: 13
Training loss: 2.8711671829223633
Validation loss: 2.5458447035922798

Epoch: 16| Step: 0
Training loss: 3.3714051246643066
Validation loss: 2.5998413665320284

Epoch: 6| Step: 1
Training loss: 3.299224376678467
Validation loss: 2.640704708714639

Epoch: 6| Step: 2
Training loss: 2.64760160446167
Validation loss: 2.6390958242518927

Epoch: 6| Step: 3
Training loss: 1.9341340065002441
Validation loss: 2.6236653122850644

Epoch: 6| Step: 4
Training loss: 3.035003662109375
Validation loss: 2.562144746062576

Epoch: 6| Step: 5
Training loss: 2.6011850833892822
Validation loss: 2.5198161653293076

Epoch: 6| Step: 6
Training loss: 2.65805721282959
Validation loss: 2.4863393024731706

Epoch: 6| Step: 7
Training loss: 3.0953664779663086
Validation loss: 2.4842180462293726

Epoch: 6| Step: 8
Training loss: 2.8228931427001953
Validation loss: 2.492518389096824

Epoch: 6| Step: 9
Training loss: 2.701333999633789
Validation loss: 2.5325101370452554

Epoch: 6| Step: 10
Training loss: 2.5136866569519043
Validation loss: 2.5346327776549966

Epoch: 6| Step: 11
Training loss: 3.016636371612549
Validation loss: 2.4981538480327976

Epoch: 6| Step: 12
Training loss: 2.40529465675354
Validation loss: 2.4817483553322415

Epoch: 6| Step: 13
Training loss: 2.2620139122009277
Validation loss: 2.482815040055142

Epoch: 17| Step: 0
Training loss: 2.844447135925293
Validation loss: 2.482076311624178

Epoch: 6| Step: 1
Training loss: 2.6702218055725098
Validation loss: 2.4817419257215274

Epoch: 6| Step: 2
Training loss: 3.562246084213257
Validation loss: 2.4925577358532975

Epoch: 6| Step: 3
Training loss: 2.271754026412964
Validation loss: 2.4914675015275196

Epoch: 6| Step: 4
Training loss: 3.541365623474121
Validation loss: 2.507094326839652

Epoch: 6| Step: 5
Training loss: 3.1062731742858887
Validation loss: 2.4855550284026773

Epoch: 6| Step: 6
Training loss: 2.3977713584899902
Validation loss: 2.477921196209487

Epoch: 6| Step: 7
Training loss: 3.016103744506836
Validation loss: 2.475245891078826

Epoch: 6| Step: 8
Training loss: 2.363955020904541
Validation loss: 2.459962532084475

Epoch: 6| Step: 9
Training loss: 2.051407814025879
Validation loss: 2.4530095002984487

Epoch: 6| Step: 10
Training loss: 2.332745313644409
Validation loss: 2.4613766080589703

Epoch: 6| Step: 11
Training loss: 2.6910524368286133
Validation loss: 2.507734403815321

Epoch: 6| Step: 12
Training loss: 2.1153225898742676
Validation loss: 2.576909718974944

Epoch: 6| Step: 13
Training loss: 3.3272528648376465
Validation loss: 2.687516607264037

Epoch: 18| Step: 0
Training loss: 2.5871338844299316
Validation loss: 2.6831621777626777

Epoch: 6| Step: 1
Training loss: 2.249849796295166
Validation loss: 2.6049448623452136

Epoch: 6| Step: 2
Training loss: 3.1452670097351074
Validation loss: 2.577044322926511

Epoch: 6| Step: 3
Training loss: 2.589615821838379
Validation loss: 2.546081450677687

Epoch: 6| Step: 4
Training loss: 2.378793716430664
Validation loss: 2.516058493685979

Epoch: 6| Step: 5
Training loss: 2.6997690200805664
Validation loss: 2.5062560573700936

Epoch: 6| Step: 6
Training loss: 2.4090628623962402
Validation loss: 2.5090446061985467

Epoch: 6| Step: 7
Training loss: 2.627591371536255
Validation loss: 2.4953916995756087

Epoch: 6| Step: 8
Training loss: 2.71177339553833
Validation loss: 2.4873585316442672

Epoch: 6| Step: 9
Training loss: 3.33866024017334
Validation loss: 2.4843456155510357

Epoch: 6| Step: 10
Training loss: 3.5490612983703613
Validation loss: 2.4542418808065434

Epoch: 6| Step: 11
Training loss: 2.3676679134368896
Validation loss: 2.4323996728466404

Epoch: 6| Step: 12
Training loss: 3.1617040634155273
Validation loss: 2.428318391564072

Epoch: 6| Step: 13
Training loss: 1.8480112552642822
Validation loss: 2.4421535743180143

Epoch: 19| Step: 0
Training loss: 3.1860437393188477
Validation loss: 2.4736650630991948

Epoch: 6| Step: 1
Training loss: 2.807894229888916
Validation loss: 2.496370884679979

Epoch: 6| Step: 2
Training loss: 3.0070481300354004
Validation loss: 2.4990208495047783

Epoch: 6| Step: 3
Training loss: 3.567629337310791
Validation loss: 2.472863689545662

Epoch: 6| Step: 4
Training loss: 2.45731258392334
Validation loss: 2.462686482296195

Epoch: 6| Step: 5
Training loss: 2.263227939605713
Validation loss: 2.442042737878779

Epoch: 6| Step: 6
Training loss: 2.3999481201171875
Validation loss: 2.430039362240863

Epoch: 6| Step: 7
Training loss: 2.576111078262329
Validation loss: 2.424623066379178

Epoch: 6| Step: 8
Training loss: 2.1037354469299316
Validation loss: 2.42403733089406

Epoch: 6| Step: 9
Training loss: 2.2344870567321777
Validation loss: 2.4277837020094677

Epoch: 6| Step: 10
Training loss: 2.3024659156799316
Validation loss: 2.432252755729101

Epoch: 6| Step: 11
Training loss: 2.453895092010498
Validation loss: 2.4384593707258984

Epoch: 6| Step: 12
Training loss: 3.745258331298828
Validation loss: 2.447152163392754

Epoch: 6| Step: 13
Training loss: 2.679335594177246
Validation loss: 2.454131764750327

Epoch: 20| Step: 0
Training loss: 2.913794755935669
Validation loss: 2.4565823911338724

Epoch: 6| Step: 1
Training loss: 2.9041786193847656
Validation loss: 2.4492247130281184

Epoch: 6| Step: 2
Training loss: 2.727388381958008
Validation loss: 2.429549681243076

Epoch: 6| Step: 3
Training loss: 2.449369430541992
Validation loss: 2.422107460678265

Epoch: 6| Step: 4
Training loss: 2.865511417388916
Validation loss: 2.40879907402941

Epoch: 6| Step: 5
Training loss: 2.4896504878997803
Validation loss: 2.3987496591383413

Epoch: 6| Step: 6
Training loss: 3.3431921005249023
Validation loss: 2.3867070815896474

Epoch: 6| Step: 7
Training loss: 2.2794032096862793
Validation loss: 2.380519687488515

Epoch: 6| Step: 8
Training loss: 2.194955348968506
Validation loss: 2.378973117438696

Epoch: 6| Step: 9
Training loss: 2.476517915725708
Validation loss: 2.391464597435408

Epoch: 6| Step: 10
Training loss: 2.026716947555542
Validation loss: 2.4133377972469536

Epoch: 6| Step: 11
Training loss: 3.0787034034729004
Validation loss: 2.4504651766951366

Epoch: 6| Step: 12
Training loss: 3.0998430252075195
Validation loss: 2.4503131117872012

Epoch: 6| Step: 13
Training loss: 2.480156660079956
Validation loss: 2.4279902109535794

Epoch: 21| Step: 0
Training loss: 1.9603335857391357
Validation loss: 2.4442857926891697

Epoch: 6| Step: 1
Training loss: 3.0946993827819824
Validation loss: 2.4473283521590696

Epoch: 6| Step: 2
Training loss: 2.2638230323791504
Validation loss: 2.4144940914646273

Epoch: 6| Step: 3
Training loss: 2.3760299682617188
Validation loss: 2.4060751007449244

Epoch: 6| Step: 4
Training loss: 2.676114797592163
Validation loss: 2.3951340465135473

Epoch: 6| Step: 5
Training loss: 3.669631004333496
Validation loss: 2.3855371013764413

Epoch: 6| Step: 6
Training loss: 2.380248546600342
Validation loss: 2.3804318007602485

Epoch: 6| Step: 7
Training loss: 2.7226529121398926
Validation loss: 2.3725278685169835

Epoch: 6| Step: 8
Training loss: 2.6595797538757324
Validation loss: 2.3795916341966197

Epoch: 6| Step: 9
Training loss: 2.766162633895874
Validation loss: 2.374357815711729

Epoch: 6| Step: 10
Training loss: 2.447920799255371
Validation loss: 2.373133743962934

Epoch: 6| Step: 11
Training loss: 2.802647829055786
Validation loss: 2.368023569865893

Epoch: 6| Step: 12
Training loss: 2.664640188217163
Validation loss: 2.3619321443701304

Epoch: 6| Step: 13
Training loss: 2.6604058742523193
Validation loss: 2.364255861569476

Epoch: 22| Step: 0
Training loss: 2.4948768615722656
Validation loss: 2.370850691231348

Epoch: 6| Step: 1
Training loss: 2.914222478866577
Validation loss: 2.3858099163219495

Epoch: 6| Step: 2
Training loss: 2.6567680835723877
Validation loss: 2.4087759012817056

Epoch: 6| Step: 3
Training loss: 2.4504480361938477
Validation loss: 2.4030003342577206

Epoch: 6| Step: 4
Training loss: 3.3231780529022217
Validation loss: 2.3853700955708823

Epoch: 6| Step: 5
Training loss: 2.7180733680725098
Validation loss: 2.3613712377445673

Epoch: 6| Step: 6
Training loss: 2.2396116256713867
Validation loss: 2.3574018401484333

Epoch: 6| Step: 7
Training loss: 2.673567056655884
Validation loss: 2.3554601643675115

Epoch: 6| Step: 8
Training loss: 2.179286003112793
Validation loss: 2.357292152220203

Epoch: 6| Step: 9
Training loss: 3.0015130043029785
Validation loss: 2.3483811911716255

Epoch: 6| Step: 10
Training loss: 2.6679372787475586
Validation loss: 2.352387010410268

Epoch: 6| Step: 11
Training loss: 1.99705171585083
Validation loss: 2.3423338526038715

Epoch: 6| Step: 12
Training loss: 2.568755865097046
Validation loss: 2.3383223395193777

Epoch: 6| Step: 13
Training loss: 3.3999924659729004
Validation loss: 2.344370618943245

Epoch: 23| Step: 0
Training loss: 2.812993049621582
Validation loss: 2.3653613213569886

Epoch: 6| Step: 1
Training loss: 3.2977442741394043
Validation loss: 2.3844900541408087

Epoch: 6| Step: 2
Training loss: 1.9238141775131226
Validation loss: 2.385711782722063

Epoch: 6| Step: 3
Training loss: 2.9865074157714844
Validation loss: 2.3908526948703233

Epoch: 6| Step: 4
Training loss: 3.1845433712005615
Validation loss: 2.371859268475604

Epoch: 6| Step: 5
Training loss: 2.989036798477173
Validation loss: 2.3476093558854956

Epoch: 6| Step: 6
Training loss: 2.195488452911377
Validation loss: 2.3264645030421596

Epoch: 6| Step: 7
Training loss: 2.7378528118133545
Validation loss: 2.3158635606047926

Epoch: 6| Step: 8
Training loss: 2.4330315589904785
Validation loss: 2.3195629747965003

Epoch: 6| Step: 9
Training loss: 2.5606188774108887
Validation loss: 2.328191352146928

Epoch: 6| Step: 10
Training loss: 2.607776641845703
Validation loss: 2.3258722392461633

Epoch: 6| Step: 11
Training loss: 2.783022880554199
Validation loss: 2.3229243704067764

Epoch: 6| Step: 12
Training loss: 2.1186132431030273
Validation loss: 2.3257205024842293

Epoch: 6| Step: 13
Training loss: 1.9713948965072632
Validation loss: 2.318667325922238

Epoch: 24| Step: 0
Training loss: 2.824155330657959
Validation loss: 2.3268835852223058

Epoch: 6| Step: 1
Training loss: 2.6018810272216797
Validation loss: 2.3108962120548373

Epoch: 6| Step: 2
Training loss: 1.8138166666030884
Validation loss: 2.321010543454078

Epoch: 6| Step: 3
Training loss: 2.8014302253723145
Validation loss: 2.3335720723675144

Epoch: 6| Step: 4
Training loss: 2.498002767562866
Validation loss: 2.3584046568921817

Epoch: 6| Step: 5
Training loss: 2.9154391288757324
Validation loss: 2.3787185556145123

Epoch: 6| Step: 6
Training loss: 2.976339817047119
Validation loss: 2.3667061841616066

Epoch: 6| Step: 7
Training loss: 2.7772483825683594
Validation loss: 2.3532035735345658

Epoch: 6| Step: 8
Training loss: 2.7533645629882812
Validation loss: 2.3415813933136644

Epoch: 6| Step: 9
Training loss: 2.408940315246582
Validation loss: 2.326944907506307

Epoch: 6| Step: 10
Training loss: 2.9093754291534424
Validation loss: 2.3134179012749785

Epoch: 6| Step: 11
Training loss: 2.9464001655578613
Validation loss: 2.3044341841051654

Epoch: 6| Step: 12
Training loss: 2.038747549057007
Validation loss: 2.297627769490724

Epoch: 6| Step: 13
Training loss: 2.076141834259033
Validation loss: 2.2990050290220525

Epoch: 25| Step: 0
Training loss: 3.0952413082122803
Validation loss: 2.2997940919732534

Epoch: 6| Step: 1
Training loss: 2.8977513313293457
Validation loss: 2.293943341060351

Epoch: 6| Step: 2
Training loss: 3.021573543548584
Validation loss: 2.298705372759091

Epoch: 6| Step: 3
Training loss: 2.877326011657715
Validation loss: 2.292252822588849

Epoch: 6| Step: 4
Training loss: 1.6011381149291992
Validation loss: 2.2928396553121586

Epoch: 6| Step: 5
Training loss: 2.4088287353515625
Validation loss: 2.301638936483732

Epoch: 6| Step: 6
Training loss: 2.7286229133605957
Validation loss: 2.3168319861094155

Epoch: 6| Step: 7
Training loss: 2.816143035888672
Validation loss: 2.345055913412443

Epoch: 6| Step: 8
Training loss: 2.5786356925964355
Validation loss: 2.378284687637001

Epoch: 6| Step: 9
Training loss: 3.0587990283966064
Validation loss: 2.403551656712768

Epoch: 6| Step: 10
Training loss: 2.6022017002105713
Validation loss: 2.4065815889707176

Epoch: 6| Step: 11
Training loss: 2.520071506500244
Validation loss: 2.3263392653516544

Epoch: 6| Step: 12
Training loss: 1.8647878170013428
Validation loss: 2.3048636785117527

Epoch: 6| Step: 13
Training loss: 2.354642391204834
Validation loss: 2.3427647903401363

Epoch: 26| Step: 0
Training loss: 2.571594476699829
Validation loss: 2.4178011494298137

Epoch: 6| Step: 1
Training loss: 2.5461978912353516
Validation loss: 2.4597739019701557

Epoch: 6| Step: 2
Training loss: 2.423102855682373
Validation loss: 2.4182134161713305

Epoch: 6| Step: 3
Training loss: 2.4360532760620117
Validation loss: 2.411872597150905

Epoch: 6| Step: 4
Training loss: 2.762946128845215
Validation loss: 2.3626178900400796

Epoch: 6| Step: 5
Training loss: 2.413923978805542
Validation loss: 2.3042128957727903

Epoch: 6| Step: 6
Training loss: 2.280041456222534
Validation loss: 2.309826107435329

Epoch: 6| Step: 7
Training loss: 2.769559860229492
Validation loss: 2.320740335731096

Epoch: 6| Step: 8
Training loss: 2.23435378074646
Validation loss: 2.345628964003696

Epoch: 6| Step: 9
Training loss: 3.0012617111206055
Validation loss: 2.370640144553236

Epoch: 6| Step: 10
Training loss: 2.467437982559204
Validation loss: 2.419435660044352

Epoch: 6| Step: 11
Training loss: 3.453819990158081
Validation loss: 2.506883716070524

Epoch: 6| Step: 12
Training loss: 3.1682279109954834
Validation loss: 2.6168125778116207

Epoch: 6| Step: 13
Training loss: 2.4103407859802246
Validation loss: 2.625819734347764

Epoch: 27| Step: 0
Training loss: 2.5228769779205322
Validation loss: 2.578331438443994

Epoch: 6| Step: 1
Training loss: 2.652033567428589
Validation loss: 2.553351894501717

Epoch: 6| Step: 2
Training loss: 2.3521430492401123
Validation loss: 2.480259938906598

Epoch: 6| Step: 3
Training loss: 2.3406615257263184
Validation loss: 2.463753761783723

Epoch: 6| Step: 4
Training loss: 3.0945017337799072
Validation loss: 2.4071996058187177

Epoch: 6| Step: 5
Training loss: 2.7789957523345947
Validation loss: 2.3737848804843042

Epoch: 6| Step: 6
Training loss: 2.6573996543884277
Validation loss: 2.3344122197038386

Epoch: 6| Step: 7
Training loss: 2.920233726501465
Validation loss: 2.3092504624397523

Epoch: 6| Step: 8
Training loss: 2.634589195251465
Validation loss: 2.293764329725696

Epoch: 6| Step: 9
Training loss: 2.313774585723877
Validation loss: 2.2909980307343187

Epoch: 6| Step: 10
Training loss: 3.05234956741333
Validation loss: 2.2882487773895264

Epoch: 6| Step: 11
Training loss: 2.586721420288086
Validation loss: 2.2748926480611167

Epoch: 6| Step: 12
Training loss: 2.3212249279022217
Validation loss: 2.275039472887593

Epoch: 6| Step: 13
Training loss: 2.4090139865875244
Validation loss: 2.268390770881407

Epoch: 28| Step: 0
Training loss: 2.299913167953491
Validation loss: 2.2742194206483903

Epoch: 6| Step: 1
Training loss: 2.1081318855285645
Validation loss: 2.2905192003455213

Epoch: 6| Step: 2
Training loss: 1.798187255859375
Validation loss: 2.318006512939289

Epoch: 6| Step: 3
Training loss: 3.147772789001465
Validation loss: 2.3392890294392905

Epoch: 6| Step: 4
Training loss: 3.5376901626586914
Validation loss: 2.342256807511853

Epoch: 6| Step: 5
Training loss: 2.711857795715332
Validation loss: 2.363926884948566

Epoch: 6| Step: 6
Training loss: 2.700763702392578
Validation loss: 2.351361054246144

Epoch: 6| Step: 7
Training loss: 2.7150204181671143
Validation loss: 2.3426103233009257

Epoch: 6| Step: 8
Training loss: 2.522921562194824
Validation loss: 2.2984670105800835

Epoch: 6| Step: 9
Training loss: 3.02199125289917
Validation loss: 2.2694013298198743

Epoch: 6| Step: 10
Training loss: 2.671133041381836
Validation loss: 2.2479894007405927

Epoch: 6| Step: 11
Training loss: 2.4723126888275146
Validation loss: 2.2471664541511127

Epoch: 6| Step: 12
Training loss: 2.4181971549987793
Validation loss: 2.2551373461241364

Epoch: 6| Step: 13
Training loss: 1.688395619392395
Validation loss: 2.2666982322610836

Epoch: 29| Step: 0
Training loss: 2.2653415203094482
Validation loss: 2.26762133003563

Epoch: 6| Step: 1
Training loss: 1.7581770420074463
Validation loss: 2.2631565281139907

Epoch: 6| Step: 2
Training loss: 2.891758918762207
Validation loss: 2.260016236253964

Epoch: 6| Step: 3
Training loss: 2.9862284660339355
Validation loss: 2.2450321438491985

Epoch: 6| Step: 4
Training loss: 2.8063764572143555
Validation loss: 2.2440571861882366

Epoch: 6| Step: 5
Training loss: 2.0500078201293945
Validation loss: 2.243316182526209

Epoch: 6| Step: 6
Training loss: 3.384197235107422
Validation loss: 2.248948940666773

Epoch: 6| Step: 7
Training loss: 2.2575879096984863
Validation loss: 2.290210546985749

Epoch: 6| Step: 8
Training loss: 2.666954755783081
Validation loss: 2.3362480632720457

Epoch: 6| Step: 9
Training loss: 2.0989420413970947
Validation loss: 2.38854048585379

Epoch: 6| Step: 10
Training loss: 2.9438211917877197
Validation loss: 2.3990845385418145

Epoch: 6| Step: 11
Training loss: 2.237891674041748
Validation loss: 2.345362660705402

Epoch: 6| Step: 12
Training loss: 3.219555616378784
Validation loss: 2.3658209769956526

Epoch: 6| Step: 13
Training loss: 3.0814177989959717
Validation loss: 2.3226543600841234

Epoch: 30| Step: 0
Training loss: 2.19118070602417
Validation loss: 2.2719809803911435

Epoch: 6| Step: 1
Training loss: 2.4736127853393555
Validation loss: 2.245196445013887

Epoch: 6| Step: 2
Training loss: 2.2768049240112305
Validation loss: 2.2407235663424254

Epoch: 6| Step: 3
Training loss: 2.305800437927246
Validation loss: 2.2425701746376614

Epoch: 6| Step: 4
Training loss: 2.513335704803467
Validation loss: 2.2483720292327223

Epoch: 6| Step: 5
Training loss: 2.6208882331848145
Validation loss: 2.264755282350766

Epoch: 6| Step: 6
Training loss: 2.939948081970215
Validation loss: 2.285135164055773

Epoch: 6| Step: 7
Training loss: 2.480243444442749
Validation loss: 2.2856025657346173

Epoch: 6| Step: 8
Training loss: 2.636580228805542
Validation loss: 2.2673113320463445

Epoch: 6| Step: 9
Training loss: 3.234015464782715
Validation loss: 2.2503114490098852

Epoch: 6| Step: 10
Training loss: 2.571662664413452
Validation loss: 2.250445028787018

Epoch: 6| Step: 11
Training loss: 2.3540308475494385
Validation loss: 2.2613065729859056

Epoch: 6| Step: 12
Training loss: 2.5467963218688965
Validation loss: 2.273025910059611

Epoch: 6| Step: 13
Training loss: 2.7771778106689453
Validation loss: 2.2846383048642065

Epoch: 31| Step: 0
Training loss: 2.62667179107666
Validation loss: 2.3100673934464813

Epoch: 6| Step: 1
Training loss: 3.100451946258545
Validation loss: 2.3571937186743623

Epoch: 6| Step: 2
Training loss: 3.203504800796509
Validation loss: 2.38733587982834

Epoch: 6| Step: 3
Training loss: 2.4161367416381836
Validation loss: 2.4286677516916746

Epoch: 6| Step: 4
Training loss: 2.697530508041382
Validation loss: 2.3864116040609216

Epoch: 6| Step: 5
Training loss: 2.267530918121338
Validation loss: 2.3203406731287637

Epoch: 6| Step: 6
Training loss: 2.7851386070251465
Validation loss: 2.285178442155161

Epoch: 6| Step: 7
Training loss: 2.534165382385254
Validation loss: 2.260713484979445

Epoch: 6| Step: 8
Training loss: 2.2831597328186035
Validation loss: 2.2465367112108456

Epoch: 6| Step: 9
Training loss: 2.3762733936309814
Validation loss: 2.2370967224080074

Epoch: 6| Step: 10
Training loss: 2.488955020904541
Validation loss: 2.236504711130614

Epoch: 6| Step: 11
Training loss: 2.6726152896881104
Validation loss: 2.2433395949743127

Epoch: 6| Step: 12
Training loss: 2.3397397994995117
Validation loss: 2.24579640101361

Epoch: 6| Step: 13
Training loss: 2.3613767623901367
Validation loss: 2.2444005371421896

Epoch: 32| Step: 0
Training loss: 3.2218902111053467
Validation loss: 2.245137655606834

Epoch: 6| Step: 1
Training loss: 2.703366279602051
Validation loss: 2.2406856834247546

Epoch: 6| Step: 2
Training loss: 2.2817158699035645
Validation loss: 2.2374723521612023

Epoch: 6| Step: 3
Training loss: 3.1157822608947754
Validation loss: 2.2363213954433316

Epoch: 6| Step: 4
Training loss: 2.4244437217712402
Validation loss: 2.2384944961917017

Epoch: 6| Step: 5
Training loss: 2.8077352046966553
Validation loss: 2.239817152741135

Epoch: 6| Step: 6
Training loss: 2.3687496185302734
Validation loss: 2.2349224552031486

Epoch: 6| Step: 7
Training loss: 2.496904134750366
Validation loss: 2.2463958647943314

Epoch: 6| Step: 8
Training loss: 2.054882764816284
Validation loss: 2.2522439085027224

Epoch: 6| Step: 9
Training loss: 2.3422224521636963
Validation loss: 2.2674315565375873

Epoch: 6| Step: 10
Training loss: 2.2517523765563965
Validation loss: 2.276470971363847

Epoch: 6| Step: 11
Training loss: 2.359203815460205
Validation loss: 2.2733905981945735

Epoch: 6| Step: 12
Training loss: 2.433692693710327
Validation loss: 2.284544590980776

Epoch: 6| Step: 13
Training loss: 3.209181070327759
Validation loss: 2.274158872583861

Epoch: 33| Step: 0
Training loss: 3.366283416748047
Validation loss: 2.2582824640376593

Epoch: 6| Step: 1
Training loss: 2.135402202606201
Validation loss: 2.2454043652421687

Epoch: 6| Step: 2
Training loss: 2.8703951835632324
Validation loss: 2.240517068934697

Epoch: 6| Step: 3
Training loss: 2.6653194427490234
Validation loss: 2.2376786534504225

Epoch: 6| Step: 4
Training loss: 2.2954494953155518
Validation loss: 2.2303230275389967

Epoch: 6| Step: 5
Training loss: 2.3110876083374023
Validation loss: 2.225951288336067

Epoch: 6| Step: 6
Training loss: 3.0110249519348145
Validation loss: 2.2293796500852032

Epoch: 6| Step: 7
Training loss: 2.121746063232422
Validation loss: 2.2325345957151024

Epoch: 6| Step: 8
Training loss: 2.014486789703369
Validation loss: 2.246104855691233

Epoch: 6| Step: 9
Training loss: 1.8756517171859741
Validation loss: 2.26117286374492

Epoch: 6| Step: 10
Training loss: 3.1317646503448486
Validation loss: 2.286486025779478

Epoch: 6| Step: 11
Training loss: 2.6393866539001465
Validation loss: 2.2870564665845645

Epoch: 6| Step: 12
Training loss: 2.4261667728424072
Validation loss: 2.294746733480884

Epoch: 6| Step: 13
Training loss: 2.8948609828948975
Validation loss: 2.2961306559142245

Epoch: 34| Step: 0
Training loss: 2.4242429733276367
Validation loss: 2.3037216189087077

Epoch: 6| Step: 1
Training loss: 2.5830044746398926
Validation loss: 2.2999768667323615

Epoch: 6| Step: 2
Training loss: 2.926229476928711
Validation loss: 2.29782344448951

Epoch: 6| Step: 3
Training loss: 2.1365585327148438
Validation loss: 2.280039555283003

Epoch: 6| Step: 4
Training loss: 2.462040901184082
Validation loss: 2.2736742599036104

Epoch: 6| Step: 5
Training loss: 3.3237037658691406
Validation loss: 2.2673497225648616

Epoch: 6| Step: 6
Training loss: 2.3819620609283447
Validation loss: 2.2709354636489705

Epoch: 6| Step: 7
Training loss: 2.694878578186035
Validation loss: 2.2648745967495825

Epoch: 6| Step: 8
Training loss: 2.471236228942871
Validation loss: 2.2622829303946546

Epoch: 6| Step: 9
Training loss: 2.5932230949401855
Validation loss: 2.2614503432345647

Epoch: 6| Step: 10
Training loss: 2.55851149559021
Validation loss: 2.251976982239754

Epoch: 6| Step: 11
Training loss: 2.7569961547851562
Validation loss: 2.2482518842143397

Epoch: 6| Step: 12
Training loss: 2.443488597869873
Validation loss: 2.230856926210465

Epoch: 6| Step: 13
Training loss: 1.7950420379638672
Validation loss: 2.2268224839241273

Epoch: 35| Step: 0
Training loss: 2.1500701904296875
Validation loss: 2.2186663073878132

Epoch: 6| Step: 1
Training loss: 3.01546049118042
Validation loss: 2.207554606981175

Epoch: 6| Step: 2
Training loss: 2.254960775375366
Validation loss: 2.20200240483848

Epoch: 6| Step: 3
Training loss: 2.342578887939453
Validation loss: 2.200764012593095

Epoch: 6| Step: 4
Training loss: 2.339919090270996
Validation loss: 2.2055167805763984

Epoch: 6| Step: 5
Training loss: 3.4136157035827637
Validation loss: 2.2081338449191024

Epoch: 6| Step: 6
Training loss: 2.3774027824401855
Validation loss: 2.210442376393144

Epoch: 6| Step: 7
Training loss: 2.1024532318115234
Validation loss: 2.2085540602284093

Epoch: 6| Step: 8
Training loss: 1.8785761594772339
Validation loss: 2.2222027035169702

Epoch: 6| Step: 9
Training loss: 2.531764507293701
Validation loss: 2.2792023740788943

Epoch: 6| Step: 10
Training loss: 2.6932504177093506
Validation loss: 2.3261492457441104

Epoch: 6| Step: 11
Training loss: 3.1160242557525635
Validation loss: 2.3063655053415606

Epoch: 6| Step: 12
Training loss: 2.3153226375579834
Validation loss: 2.247197607512115

Epoch: 6| Step: 13
Training loss: 3.337676763534546
Validation loss: 2.199223497862457

Epoch: 36| Step: 0
Training loss: 2.1018059253692627
Validation loss: 2.1951221035372828

Epoch: 6| Step: 1
Training loss: 2.3949406147003174
Validation loss: 2.221176057733515

Epoch: 6| Step: 2
Training loss: 2.6936020851135254
Validation loss: 2.271469182865594

Epoch: 6| Step: 3
Training loss: 2.745089530944824
Validation loss: 2.2704128924236504

Epoch: 6| Step: 4
Training loss: 2.216867446899414
Validation loss: 2.2811775515156407

Epoch: 6| Step: 5
Training loss: 2.620678663253784
Validation loss: 2.2439749163966023

Epoch: 6| Step: 6
Training loss: 2.046787738800049
Validation loss: 2.2031180986794094

Epoch: 6| Step: 7
Training loss: 2.511592149734497
Validation loss: 2.206779949126705

Epoch: 6| Step: 8
Training loss: 2.827505111694336
Validation loss: 2.2059803085942424

Epoch: 6| Step: 9
Training loss: 3.5400402545928955
Validation loss: 2.236529714317732

Epoch: 6| Step: 10
Training loss: 2.24522066116333
Validation loss: 2.252238007001979

Epoch: 6| Step: 11
Training loss: 2.5112662315368652
Validation loss: 2.28206955745656

Epoch: 6| Step: 12
Training loss: 2.6882529258728027
Validation loss: 2.3177681046147502

Epoch: 6| Step: 13
Training loss: 2.5216312408447266
Validation loss: 2.352681882919804

Epoch: 37| Step: 0
Training loss: 2.411755084991455
Validation loss: 2.3009372167689826

Epoch: 6| Step: 1
Training loss: 2.3535585403442383
Validation loss: 2.2615597581350677

Epoch: 6| Step: 2
Training loss: 2.6770057678222656
Validation loss: 2.220515767733256

Epoch: 6| Step: 3
Training loss: 2.580620527267456
Validation loss: 2.209694634201706

Epoch: 6| Step: 4
Training loss: 3.0052239894866943
Validation loss: 2.201228751931139

Epoch: 6| Step: 5
Training loss: 2.580470561981201
Validation loss: 2.202585684355869

Epoch: 6| Step: 6
Training loss: 3.0087788105010986
Validation loss: 2.2024090777161303

Epoch: 6| Step: 7
Training loss: 2.572460174560547
Validation loss: 2.203320069979596

Epoch: 6| Step: 8
Training loss: 2.6582469940185547
Validation loss: 2.2118789124232467

Epoch: 6| Step: 9
Training loss: 2.381793975830078
Validation loss: 2.2054698569800264

Epoch: 6| Step: 10
Training loss: 2.3417680263519287
Validation loss: 2.2113108417039276

Epoch: 6| Step: 11
Training loss: 2.281585693359375
Validation loss: 2.209405968266149

Epoch: 6| Step: 12
Training loss: 1.846097707748413
Validation loss: 2.216951352293773

Epoch: 6| Step: 13
Training loss: 3.127556324005127
Validation loss: 2.2246036760268675

Epoch: 38| Step: 0
Training loss: 2.144972801208496
Validation loss: 2.232186096970753

Epoch: 6| Step: 1
Training loss: 2.9614996910095215
Validation loss: 2.2388525444974183

Epoch: 6| Step: 2
Training loss: 2.7519991397857666
Validation loss: 2.234263695696349

Epoch: 6| Step: 3
Training loss: 2.7391014099121094
Validation loss: 2.228385570228741

Epoch: 6| Step: 4
Training loss: 1.5760207176208496
Validation loss: 2.2260172802914857

Epoch: 6| Step: 5
Training loss: 2.469646692276001
Validation loss: 2.221088558114985

Epoch: 6| Step: 6
Training loss: 2.8593287467956543
Validation loss: 2.212126624199652

Epoch: 6| Step: 7
Training loss: 2.7010116577148438
Validation loss: 2.21732561690833

Epoch: 6| Step: 8
Training loss: 2.395409107208252
Validation loss: 2.2240654858209754

Epoch: 6| Step: 9
Training loss: 2.6257944107055664
Validation loss: 2.2273996465949604

Epoch: 6| Step: 10
Training loss: 2.2844913005828857
Validation loss: 2.226652591459213

Epoch: 6| Step: 11
Training loss: 2.458097457885742
Validation loss: 2.242385487402639

Epoch: 6| Step: 12
Training loss: 3.3164615631103516
Validation loss: 2.2793586228483464

Epoch: 6| Step: 13
Training loss: 2.257005214691162
Validation loss: 2.3281106769397693

Epoch: 39| Step: 0
Training loss: 2.6817047595977783
Validation loss: 2.2837952618957846

Epoch: 6| Step: 1
Training loss: 1.8088092803955078
Validation loss: 2.235550057503485

Epoch: 6| Step: 2
Training loss: 2.665187358856201
Validation loss: 2.196850666435816

Epoch: 6| Step: 3
Training loss: 2.7947182655334473
Validation loss: 2.182348128288023

Epoch: 6| Step: 4
Training loss: 2.1628804206848145
Validation loss: 2.18228595231169

Epoch: 6| Step: 5
Training loss: 2.5357255935668945
Validation loss: 2.1843896091625257

Epoch: 6| Step: 6
Training loss: 3.07932448387146
Validation loss: 2.18671086013958

Epoch: 6| Step: 7
Training loss: 2.7404274940490723
Validation loss: 2.183007155695269

Epoch: 6| Step: 8
Training loss: 1.8348240852355957
Validation loss: 2.1809085440892044

Epoch: 6| Step: 9
Training loss: 2.9549200534820557
Validation loss: 2.1819754621034027

Epoch: 6| Step: 10
Training loss: 2.7584428787231445
Validation loss: 2.1840648446031796

Epoch: 6| Step: 11
Training loss: 2.364607572555542
Validation loss: 2.17739281090357

Epoch: 6| Step: 12
Training loss: 2.185035228729248
Validation loss: 2.1792903254109044

Epoch: 6| Step: 13
Training loss: 3.1626884937286377
Validation loss: 2.1766978925274265

Epoch: 40| Step: 0
Training loss: 2.4318768978118896
Validation loss: 2.1777116124347975

Epoch: 6| Step: 1
Training loss: 2.2164063453674316
Validation loss: 2.183094861686871

Epoch: 6| Step: 2
Training loss: 2.327019214630127
Validation loss: 2.1850734090292327

Epoch: 6| Step: 3
Training loss: 2.6416616439819336
Validation loss: 2.1796772685102237

Epoch: 6| Step: 4
Training loss: 2.696420192718506
Validation loss: 2.1761375883574128

Epoch: 6| Step: 5
Training loss: 2.845331907272339
Validation loss: 2.1764843028078795

Epoch: 6| Step: 6
Training loss: 2.3359127044677734
Validation loss: 2.1814896932212253

Epoch: 6| Step: 7
Training loss: 2.4201531410217285
Validation loss: 2.1962986684614614

Epoch: 6| Step: 8
Training loss: 1.8753576278686523
Validation loss: 2.2134232341602282

Epoch: 6| Step: 9
Training loss: 2.89764404296875
Validation loss: 2.227507340010776

Epoch: 6| Step: 10
Training loss: 2.411329746246338
Validation loss: 2.2406546556821434

Epoch: 6| Step: 11
Training loss: 2.6513004302978516
Validation loss: 2.3035532248917447

Epoch: 6| Step: 12
Training loss: 3.182912826538086
Validation loss: 2.366044880241476

Epoch: 6| Step: 13
Training loss: 2.375253200531006
Validation loss: 2.403075510455716

Epoch: 41| Step: 0
Training loss: 2.791255474090576
Validation loss: 2.438571547949186

Epoch: 6| Step: 1
Training loss: 2.6186249256134033
Validation loss: 2.4496014784741145

Epoch: 6| Step: 2
Training loss: 2.695479393005371
Validation loss: 2.4412811597188315

Epoch: 6| Step: 3
Training loss: 2.2293217182159424
Validation loss: 2.3850243194128877

Epoch: 6| Step: 4
Training loss: 2.9892070293426514
Validation loss: 2.358468276198192

Epoch: 6| Step: 5
Training loss: 2.4935591220855713
Validation loss: 2.3289668303664013

Epoch: 6| Step: 6
Training loss: 2.0966265201568604
Validation loss: 2.3032575986718618

Epoch: 6| Step: 7
Training loss: 2.48463773727417
Validation loss: 2.2821384886259675

Epoch: 6| Step: 8
Training loss: 2.6308064460754395
Validation loss: 2.275087402712914

Epoch: 6| Step: 9
Training loss: 2.740488290786743
Validation loss: 2.2548159912068355

Epoch: 6| Step: 10
Training loss: 2.4900176525115967
Validation loss: 2.2500012638748332

Epoch: 6| Step: 11
Training loss: 2.695800304412842
Validation loss: 2.2424204195699384

Epoch: 6| Step: 12
Training loss: 2.5352747440338135
Validation loss: 2.2455860196903186

Epoch: 6| Step: 13
Training loss: 2.3192243576049805
Validation loss: 2.2370259377264206

Epoch: 42| Step: 0
Training loss: 2.401500701904297
Validation loss: 2.2237307204995105

Epoch: 6| Step: 1
Training loss: 2.931119918823242
Validation loss: 2.2159147672755743

Epoch: 6| Step: 2
Training loss: 2.176973581314087
Validation loss: 2.208924073044972

Epoch: 6| Step: 3
Training loss: 2.532696008682251
Validation loss: 2.2173613258587417

Epoch: 6| Step: 4
Training loss: 2.458735466003418
Validation loss: 2.220288881691553

Epoch: 6| Step: 5
Training loss: 2.2348721027374268
Validation loss: 2.2314892584277737

Epoch: 6| Step: 6
Training loss: 2.0234830379486084
Validation loss: 2.255724363429572

Epoch: 6| Step: 7
Training loss: 3.299428939819336
Validation loss: 2.282628884879492

Epoch: 6| Step: 8
Training loss: 2.811001777648926
Validation loss: 2.2736123941277944

Epoch: 6| Step: 9
Training loss: 3.1127309799194336
Validation loss: 2.259421243462511

Epoch: 6| Step: 10
Training loss: 2.7779741287231445
Validation loss: 2.2363787748480357

Epoch: 6| Step: 11
Training loss: 2.6069555282592773
Validation loss: 2.2302261526866625

Epoch: 6| Step: 12
Training loss: 1.6625765562057495
Validation loss: 2.1853533355138635

Epoch: 6| Step: 13
Training loss: 2.292658805847168
Validation loss: 2.163874292886385

Epoch: 43| Step: 0
Training loss: 2.773887872695923
Validation loss: 2.155203898747762

Epoch: 6| Step: 1
Training loss: 2.4872236251831055
Validation loss: 2.1507159817603325

Epoch: 6| Step: 2
Training loss: 2.4182238578796387
Validation loss: 2.153979547562138

Epoch: 6| Step: 3
Training loss: 2.4248809814453125
Validation loss: 2.1469296716874644

Epoch: 6| Step: 4
Training loss: 2.649930000305176
Validation loss: 2.1497330819406817

Epoch: 6| Step: 5
Training loss: 2.5689709186553955
Validation loss: 2.151473718304788

Epoch: 6| Step: 6
Training loss: 2.811692237854004
Validation loss: 2.1529883107831402

Epoch: 6| Step: 7
Training loss: 2.758913040161133
Validation loss: 2.1560377664463495

Epoch: 6| Step: 8
Training loss: 2.1714696884155273
Validation loss: 2.1690729125853507

Epoch: 6| Step: 9
Training loss: 2.2102670669555664
Validation loss: 2.168685428557857

Epoch: 6| Step: 10
Training loss: 2.309621810913086
Validation loss: 2.177949223467099

Epoch: 6| Step: 11
Training loss: 2.241962432861328
Validation loss: 2.1846845995995308

Epoch: 6| Step: 12
Training loss: 2.4631564617156982
Validation loss: 2.2122448234147924

Epoch: 6| Step: 13
Training loss: 3.023205041885376
Validation loss: 2.2564378220547914

Epoch: 44| Step: 0
Training loss: 2.4752254486083984
Validation loss: 2.2676385961553103

Epoch: 6| Step: 1
Training loss: 1.8962483406066895
Validation loss: 2.248355233541099

Epoch: 6| Step: 2
Training loss: 3.066884756088257
Validation loss: 2.2399094617494972

Epoch: 6| Step: 3
Training loss: 3.185476064682007
Validation loss: 2.202913834202674

Epoch: 6| Step: 4
Training loss: 2.310617685317993
Validation loss: 2.186060623456073

Epoch: 6| Step: 5
Training loss: 3.3909199237823486
Validation loss: 2.1798161473325504

Epoch: 6| Step: 6
Training loss: 2.3344435691833496
Validation loss: 2.163233644218855

Epoch: 6| Step: 7
Training loss: 2.4483463764190674
Validation loss: 2.156593180471851

Epoch: 6| Step: 8
Training loss: 2.4274957180023193
Validation loss: 2.1491653816674345

Epoch: 6| Step: 9
Training loss: 2.389753818511963
Validation loss: 2.1409962433640675

Epoch: 6| Step: 10
Training loss: 2.0987377166748047
Validation loss: 2.1421143559999365

Epoch: 6| Step: 11
Training loss: 2.367847442626953
Validation loss: 2.1346633152295182

Epoch: 6| Step: 12
Training loss: 2.1955454349517822
Validation loss: 2.1349757204773607

Epoch: 6| Step: 13
Training loss: 2.1704163551330566
Validation loss: 2.136024546879594

Epoch: 45| Step: 0
Training loss: 2.7499327659606934
Validation loss: 2.1370070339531027

Epoch: 6| Step: 1
Training loss: 2.7956671714782715
Validation loss: 2.138869620138599

Epoch: 6| Step: 2
Training loss: 2.037766933441162
Validation loss: 2.13879334029331

Epoch: 6| Step: 3
Training loss: 1.9816266298294067
Validation loss: 2.1476865314668223

Epoch: 6| Step: 4
Training loss: 2.0127832889556885
Validation loss: 2.1560612519582114

Epoch: 6| Step: 5
Training loss: 2.2242608070373535
Validation loss: 2.1781035443787933

Epoch: 6| Step: 6
Training loss: 3.4275288581848145
Validation loss: 2.2060720356561805

Epoch: 6| Step: 7
Training loss: 2.5918803215026855
Validation loss: 2.2470874632558515

Epoch: 6| Step: 8
Training loss: 2.860724925994873
Validation loss: 2.2716961445346957

Epoch: 6| Step: 9
Training loss: 2.056877613067627
Validation loss: 2.342699016294172

Epoch: 6| Step: 10
Training loss: 2.573925018310547
Validation loss: 2.2554234740554646

Epoch: 6| Step: 11
Training loss: 2.63572359085083
Validation loss: 2.178882106657951

Epoch: 6| Step: 12
Training loss: 2.2766833305358887
Validation loss: 2.132642993363001

Epoch: 6| Step: 13
Training loss: 3.2406349182128906
Validation loss: 2.137333825070371

Epoch: 46| Step: 0
Training loss: 2.938556671142578
Validation loss: 2.185458872907905

Epoch: 6| Step: 1
Training loss: 2.3587851524353027
Validation loss: 2.2260618235475276

Epoch: 6| Step: 2
Training loss: 3.3157222270965576
Validation loss: 2.2444028239096365

Epoch: 6| Step: 3
Training loss: 2.4886393547058105
Validation loss: 2.1930744647979736

Epoch: 6| Step: 4
Training loss: 2.954371213912964
Validation loss: 2.1649970828845935

Epoch: 6| Step: 5
Training loss: 2.868372917175293
Validation loss: 2.1450681340309883

Epoch: 6| Step: 6
Training loss: 2.09294056892395
Validation loss: 2.140565037727356

Epoch: 6| Step: 7
Training loss: 2.029360771179199
Validation loss: 2.143552072586552

Epoch: 6| Step: 8
Training loss: 3.2231335639953613
Validation loss: 2.1464164923596125

Epoch: 6| Step: 9
Training loss: 2.6009697914123535
Validation loss: 2.1430770325404342

Epoch: 6| Step: 10
Training loss: 2.627150297164917
Validation loss: 2.1506389751229236

Epoch: 6| Step: 11
Training loss: 2.088083505630493
Validation loss: 2.158199617939611

Epoch: 6| Step: 12
Training loss: 1.838305950164795
Validation loss: 2.1753380580614974

Epoch: 6| Step: 13
Training loss: 1.4530062675476074
Validation loss: 2.190235273812407

Epoch: 47| Step: 0
Training loss: 2.316877841949463
Validation loss: 2.211354955550163

Epoch: 6| Step: 1
Training loss: 2.7745909690856934
Validation loss: 2.2224912822887464

Epoch: 6| Step: 2
Training loss: 1.7404428720474243
Validation loss: 2.2152921486926336

Epoch: 6| Step: 3
Training loss: 2.736635208129883
Validation loss: 2.2241251058475946

Epoch: 6| Step: 4
Training loss: 3.357903242111206
Validation loss: 2.224608252125402

Epoch: 6| Step: 5
Training loss: 2.3631935119628906
Validation loss: 2.2490233682817027

Epoch: 6| Step: 6
Training loss: 1.7356631755828857
Validation loss: 2.2474742153639435

Epoch: 6| Step: 7
Training loss: 2.5123960971832275
Validation loss: 2.236991418305264

Epoch: 6| Step: 8
Training loss: 2.573192596435547
Validation loss: 2.229659516324279

Epoch: 6| Step: 9
Training loss: 3.034536838531494
Validation loss: 2.21110975357794

Epoch: 6| Step: 10
Training loss: 3.288123369216919
Validation loss: 2.1945880459200953

Epoch: 6| Step: 11
Training loss: 2.34993052482605
Validation loss: 2.1821343783409364

Epoch: 6| Step: 12
Training loss: 2.241488456726074
Validation loss: 2.1804480655218965

Epoch: 6| Step: 13
Training loss: 1.460184097290039
Validation loss: 2.1742601574108167

Epoch: 48| Step: 0
Training loss: 3.1016740798950195
Validation loss: 2.1762328506797872

Epoch: 6| Step: 1
Training loss: 2.1216509342193604
Validation loss: 2.1673769412502164

Epoch: 6| Step: 2
Training loss: 2.76192569732666
Validation loss: 2.1664272175040296

Epoch: 6| Step: 3
Training loss: 2.2217211723327637
Validation loss: 2.161216464093936

Epoch: 6| Step: 4
Training loss: 2.1414284706115723
Validation loss: 2.1502566440131075

Epoch: 6| Step: 5
Training loss: 2.8879313468933105
Validation loss: 2.1474798956224994

Epoch: 6| Step: 6
Training loss: 2.37196683883667
Validation loss: 2.14419940851068

Epoch: 6| Step: 7
Training loss: 2.433162212371826
Validation loss: 2.1432694747883785

Epoch: 6| Step: 8
Training loss: 2.675992488861084
Validation loss: 2.1346328822515344

Epoch: 6| Step: 9
Training loss: 2.293980598449707
Validation loss: 2.139285820786671

Epoch: 6| Step: 10
Training loss: 2.3845295906066895
Validation loss: 2.1420621948857463

Epoch: 6| Step: 11
Training loss: 2.893311023712158
Validation loss: 2.1469918874002274

Epoch: 6| Step: 12
Training loss: 2.0969810485839844
Validation loss: 2.1389815550978466

Epoch: 6| Step: 13
Training loss: 2.1664047241210938
Validation loss: 2.1343846756924867

Epoch: 49| Step: 0
Training loss: 1.869178295135498
Validation loss: 2.152269048075522

Epoch: 6| Step: 1
Training loss: 2.157700777053833
Validation loss: 2.1578660216382755

Epoch: 6| Step: 2
Training loss: 2.622032642364502
Validation loss: 2.165123096076391

Epoch: 6| Step: 3
Training loss: 2.69765043258667
Validation loss: 2.168352057856898

Epoch: 6| Step: 4
Training loss: 2.5070276260375977
Validation loss: 2.1815405737969185

Epoch: 6| Step: 5
Training loss: 2.66113018989563
Validation loss: 2.197917822868593

Epoch: 6| Step: 6
Training loss: 3.168052911758423
Validation loss: 2.2273401829504196

Epoch: 6| Step: 7
Training loss: 2.2283377647399902
Validation loss: 2.244749802415089

Epoch: 6| Step: 8
Training loss: 2.1932129859924316
Validation loss: 2.227508698740313

Epoch: 6| Step: 9
Training loss: 2.2107181549072266
Validation loss: 2.2227309185971498

Epoch: 6| Step: 10
Training loss: 2.0551135540008545
Validation loss: 2.188695284628099

Epoch: 6| Step: 11
Training loss: 2.660628080368042
Validation loss: 2.1738876501719155

Epoch: 6| Step: 12
Training loss: 3.2164106369018555
Validation loss: 2.163995217251521

Epoch: 6| Step: 13
Training loss: 2.283494710922241
Validation loss: 2.1434884789169475

Epoch: 50| Step: 0
Training loss: 3.0703883171081543
Validation loss: 2.127149439627124

Epoch: 6| Step: 1
Training loss: 2.5521814823150635
Validation loss: 2.1077594744261874

Epoch: 6| Step: 2
Training loss: 2.1331348419189453
Validation loss: 2.101032066088851

Epoch: 6| Step: 3
Training loss: 3.078845500946045
Validation loss: 2.100541002006941

Epoch: 6| Step: 4
Training loss: 1.6421610116958618
Validation loss: 2.10237515998143

Epoch: 6| Step: 5
Training loss: 2.7790780067443848
Validation loss: 2.1069347884065364

Epoch: 6| Step: 6
Training loss: 2.6167092323303223
Validation loss: 2.1088893708362373

Epoch: 6| Step: 7
Training loss: 2.0635874271392822
Validation loss: 2.1077148786155124

Epoch: 6| Step: 8
Training loss: 2.2758359909057617
Validation loss: 2.1191147527387066

Epoch: 6| Step: 9
Training loss: 2.5018553733825684
Validation loss: 2.1230532097560104

Epoch: 6| Step: 10
Training loss: 2.6595280170440674
Validation loss: 2.124847960728471

Epoch: 6| Step: 11
Training loss: 2.603590488433838
Validation loss: 2.1471251569768435

Epoch: 6| Step: 12
Training loss: 2.0906014442443848
Validation loss: 2.1590126483671126

Epoch: 6| Step: 13
Training loss: 2.3430910110473633
Validation loss: 2.172977808983095

Epoch: 51| Step: 0
Training loss: 2.266026496887207
Validation loss: 2.1372252638621996

Epoch: 6| Step: 1
Training loss: 2.7972278594970703
Validation loss: 2.120542158362686

Epoch: 6| Step: 2
Training loss: 2.6621294021606445
Validation loss: 2.1103230240524455

Epoch: 6| Step: 3
Training loss: 2.442317485809326
Validation loss: 2.102378983651438

Epoch: 6| Step: 4
Training loss: 2.022432327270508
Validation loss: 2.1044595792729366

Epoch: 6| Step: 5
Training loss: 2.582162380218506
Validation loss: 2.106261653284873

Epoch: 6| Step: 6
Training loss: 3.0236077308654785
Validation loss: 2.1106495959784395

Epoch: 6| Step: 7
Training loss: 2.317155361175537
Validation loss: 2.1087612105954077

Epoch: 6| Step: 8
Training loss: 2.4932923316955566
Validation loss: 2.128685833305441

Epoch: 6| Step: 9
Training loss: 2.446432590484619
Validation loss: 2.1175395570775515

Epoch: 6| Step: 10
Training loss: 2.5691795349121094
Validation loss: 2.105688600129979

Epoch: 6| Step: 11
Training loss: 2.2755517959594727
Validation loss: 2.0948138313908733

Epoch: 6| Step: 12
Training loss: 2.320619583129883
Validation loss: 2.0903832707353818

Epoch: 6| Step: 13
Training loss: 2.210554361343384
Validation loss: 2.094751993815104

Epoch: 52| Step: 0
Training loss: 1.924943447113037
Validation loss: 2.1166377375202794

Epoch: 6| Step: 1
Training loss: 2.4076924324035645
Validation loss: 2.170696959700636

Epoch: 6| Step: 2
Training loss: 2.3372859954833984
Validation loss: 2.21803976387106

Epoch: 6| Step: 3
Training loss: 2.6126315593719482
Validation loss: 2.2617026567459106

Epoch: 6| Step: 4
Training loss: 2.5229978561401367
Validation loss: 2.3159574641976306

Epoch: 6| Step: 5
Training loss: 3.323535442352295
Validation loss: 2.330179763096635

Epoch: 6| Step: 6
Training loss: 2.4242124557495117
Validation loss: 2.3293568447072017

Epoch: 6| Step: 7
Training loss: 2.4671459197998047
Validation loss: 2.2930077865559566

Epoch: 6| Step: 8
Training loss: 1.5325120687484741
Validation loss: 2.229969991150723

Epoch: 6| Step: 9
Training loss: 3.0439212322235107
Validation loss: 2.1875369202706123

Epoch: 6| Step: 10
Training loss: 2.60491943359375
Validation loss: 2.1516753422316683

Epoch: 6| Step: 11
Training loss: 2.937615394592285
Validation loss: 2.1464709287048667

Epoch: 6| Step: 12
Training loss: 2.270442247390747
Validation loss: 2.1257440659307663

Epoch: 6| Step: 13
Training loss: 2.2377545833587646
Validation loss: 2.1152607446075766

Epoch: 53| Step: 0
Training loss: 2.558493137359619
Validation loss: 2.1098096716788506

Epoch: 6| Step: 1
Training loss: 2.943704128265381
Validation loss: 2.1181591685100267

Epoch: 6| Step: 2
Training loss: 2.4409725666046143
Validation loss: 2.1223009940116637

Epoch: 6| Step: 3
Training loss: 1.6661112308502197
Validation loss: 2.117513959125806

Epoch: 6| Step: 4
Training loss: 2.7354183197021484
Validation loss: 2.117828353758781

Epoch: 6| Step: 5
Training loss: 2.3894224166870117
Validation loss: 2.124621005468471

Epoch: 6| Step: 6
Training loss: 2.3456315994262695
Validation loss: 2.11041352569416

Epoch: 6| Step: 7
Training loss: 2.943112850189209
Validation loss: 2.1077227900105138

Epoch: 6| Step: 8
Training loss: 2.404757499694824
Validation loss: 2.106923939079367

Epoch: 6| Step: 9
Training loss: 2.5631439685821533
Validation loss: 2.1102338375583773

Epoch: 6| Step: 10
Training loss: 2.587801456451416
Validation loss: 2.1189100075793523

Epoch: 6| Step: 11
Training loss: 2.058218240737915
Validation loss: 2.1267704335592126

Epoch: 6| Step: 12
Training loss: 2.317383050918579
Validation loss: 2.1287130822417555

Epoch: 6| Step: 13
Training loss: 2.3379430770874023
Validation loss: 2.1393203812260784

Epoch: 54| Step: 0
Training loss: 2.6093053817749023
Validation loss: 2.1554025706424507

Epoch: 6| Step: 1
Training loss: 1.7913181781768799
Validation loss: 2.1555559865890013

Epoch: 6| Step: 2
Training loss: 2.234119176864624
Validation loss: 2.179959989363147

Epoch: 6| Step: 3
Training loss: 2.4541335105895996
Validation loss: 2.194189061400711

Epoch: 6| Step: 4
Training loss: 2.598254442214966
Validation loss: 2.1822354703821163

Epoch: 6| Step: 5
Training loss: 2.3676273822784424
Validation loss: 2.1732071779107534

Epoch: 6| Step: 6
Training loss: 2.710674285888672
Validation loss: 2.1595522383207917

Epoch: 6| Step: 7
Training loss: 3.022796869277954
Validation loss: 2.150241853088461

Epoch: 6| Step: 8
Training loss: 2.6565287113189697
Validation loss: 2.135321737617575

Epoch: 6| Step: 9
Training loss: 3.1351747512817383
Validation loss: 2.1477206612146027

Epoch: 6| Step: 10
Training loss: 2.6714978218078613
Validation loss: 2.1583430715786514

Epoch: 6| Step: 11
Training loss: 2.191716194152832
Validation loss: 2.189380166351154

Epoch: 6| Step: 12
Training loss: 2.377345085144043
Validation loss: 2.1978677652215444

Epoch: 6| Step: 13
Training loss: 2.5196614265441895
Validation loss: 2.2079626642247683

Epoch: 55| Step: 0
Training loss: 2.6858739852905273
Validation loss: 2.1857575267873783

Epoch: 6| Step: 1
Training loss: 2.8250133991241455
Validation loss: 2.168554231684695

Epoch: 6| Step: 2
Training loss: 2.25968337059021
Validation loss: 2.134027647715743

Epoch: 6| Step: 3
Training loss: 1.8658225536346436
Validation loss: 2.128044718055315

Epoch: 6| Step: 4
Training loss: 2.5416860580444336
Validation loss: 2.122795112671391

Epoch: 6| Step: 5
Training loss: 2.4072458744049072
Validation loss: 2.1160108171483523

Epoch: 6| Step: 6
Training loss: 3.025233030319214
Validation loss: 2.126882844073798

Epoch: 6| Step: 7
Training loss: 1.525255799293518
Validation loss: 2.1354773121495403

Epoch: 6| Step: 8
Training loss: 2.1709206104278564
Validation loss: 2.151545504088043

Epoch: 6| Step: 9
Training loss: 2.566310405731201
Validation loss: 2.1758001876133743

Epoch: 6| Step: 10
Training loss: 2.999453544616699
Validation loss: 2.171772027528414

Epoch: 6| Step: 11
Training loss: 2.759007453918457
Validation loss: 2.1560435577105452

Epoch: 6| Step: 12
Training loss: 2.3121626377105713
Validation loss: 2.131947507140457

Epoch: 6| Step: 13
Training loss: 2.429274082183838
Validation loss: 2.1118154115574335

Epoch: 56| Step: 0
Training loss: 2.7512989044189453
Validation loss: 2.0900558707534627

Epoch: 6| Step: 1
Training loss: 2.171052932739258
Validation loss: 2.079267788958806

Epoch: 6| Step: 2
Training loss: 2.747774839401245
Validation loss: 2.075821421479666

Epoch: 6| Step: 3
Training loss: 2.3732123374938965
Validation loss: 2.0726670501052693

Epoch: 6| Step: 4
Training loss: 2.1544575691223145
Validation loss: 2.0697356577842467

Epoch: 6| Step: 5
Training loss: 2.452554941177368
Validation loss: 2.0679359307853122

Epoch: 6| Step: 6
Training loss: 2.7180800437927246
Validation loss: 2.066353795348957

Epoch: 6| Step: 7
Training loss: 1.9538094997406006
Validation loss: 2.074184170333288

Epoch: 6| Step: 8
Training loss: 1.9329761266708374
Validation loss: 2.073229926888661

Epoch: 6| Step: 9
Training loss: 3.0520498752593994
Validation loss: 2.079541954942929

Epoch: 6| Step: 10
Training loss: 2.6333279609680176
Validation loss: 2.0847014406675934

Epoch: 6| Step: 11
Training loss: 2.198723077774048
Validation loss: 2.0909420008300454

Epoch: 6| Step: 12
Training loss: 2.6250197887420654
Validation loss: 2.0953110571830504

Epoch: 6| Step: 13
Training loss: 2.501664161682129
Validation loss: 2.0995343551840833

Epoch: 57| Step: 0
Training loss: 2.476752281188965
Validation loss: 2.1198242761755504

Epoch: 6| Step: 1
Training loss: 2.53969669342041
Validation loss: 2.156583370700959

Epoch: 6| Step: 2
Training loss: 2.0494794845581055
Validation loss: 2.1726339299191713

Epoch: 6| Step: 3
Training loss: 1.796022653579712
Validation loss: 2.1835752020600023

Epoch: 6| Step: 4
Training loss: 3.641693592071533
Validation loss: 2.1684760175725466

Epoch: 6| Step: 5
Training loss: 2.5710740089416504
Validation loss: 2.1535467486227713

Epoch: 6| Step: 6
Training loss: 2.4364981651306152
Validation loss: 2.143068850681346

Epoch: 6| Step: 7
Training loss: 2.358686685562134
Validation loss: 2.1196068012586204

Epoch: 6| Step: 8
Training loss: 2.593029737472534
Validation loss: 2.110126519715914

Epoch: 6| Step: 9
Training loss: 2.2808175086975098
Validation loss: 2.108021984818161

Epoch: 6| Step: 10
Training loss: 2.5353615283966064
Validation loss: 2.1019198740682294

Epoch: 6| Step: 11
Training loss: 2.519592761993408
Validation loss: 2.0956535493173907

Epoch: 6| Step: 12
Training loss: 2.5606095790863037
Validation loss: 2.0947815872007802

Epoch: 6| Step: 13
Training loss: 1.4099974632263184
Validation loss: 2.0926914702179613

Epoch: 58| Step: 0
Training loss: 2.5124711990356445
Validation loss: 2.0862638360710553

Epoch: 6| Step: 1
Training loss: 3.1680994033813477
Validation loss: 2.0915023870365594

Epoch: 6| Step: 2
Training loss: 3.1260197162628174
Validation loss: 2.0934703567976594

Epoch: 6| Step: 3
Training loss: 2.332733631134033
Validation loss: 2.0896389792042394

Epoch: 6| Step: 4
Training loss: 1.7681307792663574
Validation loss: 2.0939940098793275

Epoch: 6| Step: 5
Training loss: 2.6986374855041504
Validation loss: 2.095877283362932

Epoch: 6| Step: 6
Training loss: 1.9917778968811035
Validation loss: 2.0903465965742707

Epoch: 6| Step: 7
Training loss: 2.78700852394104
Validation loss: 2.0851315067660425

Epoch: 6| Step: 8
Training loss: 1.9063160419464111
Validation loss: 2.0894084066473027

Epoch: 6| Step: 9
Training loss: 2.1145341396331787
Validation loss: 2.081069802725187

Epoch: 6| Step: 10
Training loss: 1.9360758066177368
Validation loss: 2.0884062013318463

Epoch: 6| Step: 11
Training loss: 2.9571499824523926
Validation loss: 2.099362425906684

Epoch: 6| Step: 12
Training loss: 2.01301908493042
Validation loss: 2.111544152741791

Epoch: 6| Step: 13
Training loss: 2.663586378097534
Validation loss: 2.123640088624852

Epoch: 59| Step: 0
Training loss: 2.760298490524292
Validation loss: 2.1298461934571624

Epoch: 6| Step: 1
Training loss: 2.197279930114746
Validation loss: 2.174976912877893

Epoch: 6| Step: 2
Training loss: 2.313920497894287
Validation loss: 2.2016623045808528

Epoch: 6| Step: 3
Training loss: 2.364124298095703
Validation loss: 2.2137851561269453

Epoch: 6| Step: 4
Training loss: 2.4130167961120605
Validation loss: 2.190576393117187

Epoch: 6| Step: 5
Training loss: 2.7589638233184814
Validation loss: 2.15552278231549

Epoch: 6| Step: 6
Training loss: 2.2909317016601562
Validation loss: 2.111042550815049

Epoch: 6| Step: 7
Training loss: 2.5287671089172363
Validation loss: 2.0743362724140124

Epoch: 6| Step: 8
Training loss: 1.6833703517913818
Validation loss: 2.0719773730924054

Epoch: 6| Step: 9
Training loss: 2.2257814407348633
Validation loss: 2.0785774364266345

Epoch: 6| Step: 10
Training loss: 2.571967124938965
Validation loss: 2.0821216055141982

Epoch: 6| Step: 11
Training loss: 2.5246951580047607
Validation loss: 2.0935872318924114

Epoch: 6| Step: 12
Training loss: 3.261323928833008
Validation loss: 2.0940561345828477

Epoch: 6| Step: 13
Training loss: 2.4192817211151123
Validation loss: 2.100106439282817

Epoch: 60| Step: 0
Training loss: 2.7251458168029785
Validation loss: 2.106112005890057

Epoch: 6| Step: 1
Training loss: 2.0913033485412598
Validation loss: 2.0976092277034635

Epoch: 6| Step: 2
Training loss: 2.3365397453308105
Validation loss: 2.1021609203789824

Epoch: 6| Step: 3
Training loss: 2.7288126945495605
Validation loss: 2.097580575173901

Epoch: 6| Step: 4
Training loss: 2.581245183944702
Validation loss: 2.0945680115812566

Epoch: 6| Step: 5
Training loss: 2.8807520866394043
Validation loss: 2.0884517162076888

Epoch: 6| Step: 6
Training loss: 1.8020703792572021
Validation loss: 2.087348699569702

Epoch: 6| Step: 7
Training loss: 2.3577280044555664
Validation loss: 2.0818926595872447

Epoch: 6| Step: 8
Training loss: 2.3461873531341553
Validation loss: 2.090791279269803

Epoch: 6| Step: 9
Training loss: 2.9833903312683105
Validation loss: 2.0973042775225896

Epoch: 6| Step: 10
Training loss: 2.2787437438964844
Validation loss: 2.106390454435861

Epoch: 6| Step: 11
Training loss: 2.2238197326660156
Validation loss: 2.1094586849212646

Epoch: 6| Step: 12
Training loss: 2.168030261993408
Validation loss: 2.1125916101599254

Epoch: 6| Step: 13
Training loss: 2.589911937713623
Validation loss: 2.1191847914008686

Epoch: 61| Step: 0
Training loss: 2.962528944015503
Validation loss: 2.116652073398713

Epoch: 6| Step: 1
Training loss: 3.5656256675720215
Validation loss: 2.125957053194764

Epoch: 6| Step: 2
Training loss: 2.0028398036956787
Validation loss: 2.119948064127276

Epoch: 6| Step: 3
Training loss: 2.727907657623291
Validation loss: 2.1138807804353776

Epoch: 6| Step: 4
Training loss: 2.401360034942627
Validation loss: 2.121304635078676

Epoch: 6| Step: 5
Training loss: 2.4377145767211914
Validation loss: 2.1176233727444886

Epoch: 6| Step: 6
Training loss: 1.9662063121795654
Validation loss: 2.111237128575643

Epoch: 6| Step: 7
Training loss: 2.9701504707336426
Validation loss: 2.1069202705096175

Epoch: 6| Step: 8
Training loss: 1.9116616249084473
Validation loss: 2.10426486948485

Epoch: 6| Step: 9
Training loss: 2.1093533039093018
Validation loss: 2.09638931674342

Epoch: 6| Step: 10
Training loss: 1.9945154190063477
Validation loss: 2.095464910230329

Epoch: 6| Step: 11
Training loss: 1.83793044090271
Validation loss: 2.0886855151063655

Epoch: 6| Step: 12
Training loss: 2.4608263969421387
Validation loss: 2.0912725515263055

Epoch: 6| Step: 13
Training loss: 2.7825207710266113
Validation loss: 2.0955395660092755

Epoch: 62| Step: 0
Training loss: 2.7203917503356934
Validation loss: 2.094903856195429

Epoch: 6| Step: 1
Training loss: 2.649545669555664
Validation loss: 2.085923680695154

Epoch: 6| Step: 2
Training loss: 2.2563087940216064
Validation loss: 2.0808040224095827

Epoch: 6| Step: 3
Training loss: 2.018594980239868
Validation loss: 2.0850896220053396

Epoch: 6| Step: 4
Training loss: 2.645702362060547
Validation loss: 2.0817577018532702

Epoch: 6| Step: 5
Training loss: 2.2848405838012695
Validation loss: 2.091683454411004

Epoch: 6| Step: 6
Training loss: 2.902327537536621
Validation loss: 2.1063471366000432

Epoch: 6| Step: 7
Training loss: 2.0745701789855957
Validation loss: 2.1049389454626266

Epoch: 6| Step: 8
Training loss: 2.1128764152526855
Validation loss: 2.1159133231768044

Epoch: 6| Step: 9
Training loss: 2.490656852722168
Validation loss: 2.122015251908251

Epoch: 6| Step: 10
Training loss: 2.441801071166992
Validation loss: 2.1216884300272953

Epoch: 6| Step: 11
Training loss: 2.3213934898376465
Validation loss: 2.1232177749756844

Epoch: 6| Step: 12
Training loss: 2.3102002143859863
Validation loss: 2.128149942685199

Epoch: 6| Step: 13
Training loss: 2.2454519271850586
Validation loss: 2.141481602063743

Epoch: 63| Step: 0
Training loss: 2.079798936843872
Validation loss: 2.147375088866039

Epoch: 6| Step: 1
Training loss: 1.8110616207122803
Validation loss: 2.1355424440035256

Epoch: 6| Step: 2
Training loss: 2.6859445571899414
Validation loss: 2.1168063661103607

Epoch: 6| Step: 3
Training loss: 2.374161720275879
Validation loss: 2.100685409320298

Epoch: 6| Step: 4
Training loss: 2.4903197288513184
Validation loss: 2.0938451136312177

Epoch: 6| Step: 5
Training loss: 2.0584936141967773
Validation loss: 2.0795680066590667

Epoch: 6| Step: 6
Training loss: 2.425662040710449
Validation loss: 2.0763994903974634

Epoch: 6| Step: 7
Training loss: 2.5371785163879395
Validation loss: 2.062078406733851

Epoch: 6| Step: 8
Training loss: 2.1446661949157715
Validation loss: 2.0506469024124967

Epoch: 6| Step: 9
Training loss: 2.7236995697021484
Validation loss: 2.051366062574489

Epoch: 6| Step: 10
Training loss: 3.4269704818725586
Validation loss: 2.049413337502428

Epoch: 6| Step: 11
Training loss: 2.119952917098999
Validation loss: 2.0536497023797806

Epoch: 6| Step: 12
Training loss: 2.53692626953125
Validation loss: 2.0555172415189844

Epoch: 6| Step: 13
Training loss: 2.014803886413574
Validation loss: 2.05277419090271

Epoch: 64| Step: 0
Training loss: 2.5310425758361816
Validation loss: 2.0596858455288793

Epoch: 6| Step: 1
Training loss: 2.8289546966552734
Validation loss: 2.055252491786916

Epoch: 6| Step: 2
Training loss: 2.960033893585205
Validation loss: 2.0511064798601213

Epoch: 6| Step: 3
Training loss: 2.6020636558532715
Validation loss: 2.05358350148765

Epoch: 6| Step: 4
Training loss: 2.12681245803833
Validation loss: 2.0537563664938814

Epoch: 6| Step: 5
Training loss: 2.470677375793457
Validation loss: 2.053459954518144

Epoch: 6| Step: 6
Training loss: 1.598999261856079
Validation loss: 2.060863091099647

Epoch: 6| Step: 7
Training loss: 1.9378337860107422
Validation loss: 2.057608990259068

Epoch: 6| Step: 8
Training loss: 2.110414505004883
Validation loss: 2.060558549819454

Epoch: 6| Step: 9
Training loss: 1.853069543838501
Validation loss: 2.078916113863709

Epoch: 6| Step: 10
Training loss: 2.360987663269043
Validation loss: 2.139017460166767

Epoch: 6| Step: 11
Training loss: 2.8036766052246094
Validation loss: 2.1943329149676907

Epoch: 6| Step: 12
Training loss: 2.639007329940796
Validation loss: 2.2639414853947137

Epoch: 6| Step: 13
Training loss: 2.888463020324707
Validation loss: 2.234333766404019

Epoch: 65| Step: 0
Training loss: 2.679716110229492
Validation loss: 2.174682422350812

Epoch: 6| Step: 1
Training loss: 2.6110379695892334
Validation loss: 2.118769348308604

Epoch: 6| Step: 2
Training loss: 2.4335670471191406
Validation loss: 2.095715650948145

Epoch: 6| Step: 3
Training loss: 2.2835586071014404
Validation loss: 2.0720823170036398

Epoch: 6| Step: 4
Training loss: 2.0903749465942383
Validation loss: 2.0653568108876548

Epoch: 6| Step: 5
Training loss: 2.3093857765197754
Validation loss: 2.059157884249123

Epoch: 6| Step: 6
Training loss: 2.9898228645324707
Validation loss: 2.060883269515089

Epoch: 6| Step: 7
Training loss: 2.2792906761169434
Validation loss: 2.050525274328006

Epoch: 6| Step: 8
Training loss: 2.1738436222076416
Validation loss: 2.0567966763691237

Epoch: 6| Step: 9
Training loss: 2.2155885696411133
Validation loss: 2.053682096542851

Epoch: 6| Step: 10
Training loss: 2.338078022003174
Validation loss: 2.057602297875189

Epoch: 6| Step: 11
Training loss: 2.4112062454223633
Validation loss: 2.057143762547483

Epoch: 6| Step: 12
Training loss: 2.0569045543670654
Validation loss: 2.056321067194785

Epoch: 6| Step: 13
Training loss: 2.0399866104125977
Validation loss: 2.047971115317396

Epoch: 66| Step: 0
Training loss: 2.6758673191070557
Validation loss: 2.050708318269381

Epoch: 6| Step: 1
Training loss: 2.771249294281006
Validation loss: 2.0552777039107455

Epoch: 6| Step: 2
Training loss: 2.3769614696502686
Validation loss: 2.0512415901307137

Epoch: 6| Step: 3
Training loss: 1.7448586225509644
Validation loss: 2.0660027329639723

Epoch: 6| Step: 4
Training loss: 2.6884546279907227
Validation loss: 2.0761546319530857

Epoch: 6| Step: 5
Training loss: 3.366037368774414
Validation loss: 2.1045151513109923

Epoch: 6| Step: 6
Training loss: 2.0271716117858887
Validation loss: 2.1248334146315053

Epoch: 6| Step: 7
Training loss: 2.379065990447998
Validation loss: 2.1618359729807866

Epoch: 6| Step: 8
Training loss: 1.9243577718734741
Validation loss: 2.181001983663087

Epoch: 6| Step: 9
Training loss: 2.3582894802093506
Validation loss: 2.1865987021435975

Epoch: 6| Step: 10
Training loss: 2.131354331970215
Validation loss: 2.1671523458214215

Epoch: 6| Step: 11
Training loss: 2.3365609645843506
Validation loss: 2.147708886413164

Epoch: 6| Step: 12
Training loss: 2.484644889831543
Validation loss: 2.122319811133928

Epoch: 6| Step: 13
Training loss: 2.2874090671539307
Validation loss: 2.1084413810442855

Epoch: 67| Step: 0
Training loss: 2.4203779697418213
Validation loss: 2.0982073160909835

Epoch: 6| Step: 1
Training loss: 2.558727264404297
Validation loss: 2.1015786458087224

Epoch: 6| Step: 2
Training loss: 2.0203704833984375
Validation loss: 2.102935929452219

Epoch: 6| Step: 3
Training loss: 2.1959030628204346
Validation loss: 2.0829910821812128

Epoch: 6| Step: 4
Training loss: 2.6217093467712402
Validation loss: 2.0821767250696817

Epoch: 6| Step: 5
Training loss: 2.5600123405456543
Validation loss: 2.0739199705021356

Epoch: 6| Step: 6
Training loss: 2.388059377670288
Validation loss: 2.0806347400911394

Epoch: 6| Step: 7
Training loss: 1.9576472043991089
Validation loss: 2.1100455945537937

Epoch: 6| Step: 8
Training loss: 2.5275192260742188
Validation loss: 2.1281927170292025

Epoch: 6| Step: 9
Training loss: 2.316514015197754
Validation loss: 2.119431354666269

Epoch: 6| Step: 10
Training loss: 1.9168528318405151
Validation loss: 2.0782849634847333

Epoch: 6| Step: 11
Training loss: 2.5288197994232178
Validation loss: 2.053498097645339

Epoch: 6| Step: 12
Training loss: 2.8430073261260986
Validation loss: 2.0599926594764955

Epoch: 6| Step: 13
Training loss: 3.0651352405548096
Validation loss: 2.0641197466081187

Epoch: 68| Step: 0
Training loss: 2.6901817321777344
Validation loss: 2.0945415163552887

Epoch: 6| Step: 1
Training loss: 2.0474395751953125
Validation loss: 2.0839311871477353

Epoch: 6| Step: 2
Training loss: 2.2234044075012207
Validation loss: 2.0678296089172363

Epoch: 6| Step: 3
Training loss: 2.2504427433013916
Validation loss: 2.053108202513828

Epoch: 6| Step: 4
Training loss: 1.5916637182235718
Validation loss: 2.042978529007204

Epoch: 6| Step: 5
Training loss: 2.5846445560455322
Validation loss: 2.03742399010607

Epoch: 6| Step: 6
Training loss: 2.8055965900421143
Validation loss: 2.0473818881537325

Epoch: 6| Step: 7
Training loss: 2.3412389755249023
Validation loss: 2.0638104895109772

Epoch: 6| Step: 8
Training loss: 2.6700916290283203
Validation loss: 2.0776051423882924

Epoch: 6| Step: 9
Training loss: 2.0344409942626953
Validation loss: 2.084044664136825

Epoch: 6| Step: 10
Training loss: 2.728957176208496
Validation loss: 2.084619629767633

Epoch: 6| Step: 11
Training loss: 2.3642578125
Validation loss: 2.0849124257282545

Epoch: 6| Step: 12
Training loss: 2.239799976348877
Validation loss: 2.0767548366259505

Epoch: 6| Step: 13
Training loss: 3.2252321243286133
Validation loss: 2.0603101663692023

Epoch: 69| Step: 0
Training loss: 2.386409282684326
Validation loss: 2.039010924677695

Epoch: 6| Step: 1
Training loss: 2.3959336280822754
Validation loss: 2.0259143511454263

Epoch: 6| Step: 2
Training loss: 2.4031777381896973
Validation loss: 2.0238164676133024

Epoch: 6| Step: 3
Training loss: 2.7215957641601562
Validation loss: 2.0214841493996243

Epoch: 6| Step: 4
Training loss: 3.434494733810425
Validation loss: 2.023062167629119

Epoch: 6| Step: 5
Training loss: 1.4285529851913452
Validation loss: 2.0278545912875923

Epoch: 6| Step: 6
Training loss: 2.154447078704834
Validation loss: 2.020868642355806

Epoch: 6| Step: 7
Training loss: 2.213667392730713
Validation loss: 2.0236632593216433

Epoch: 6| Step: 8
Training loss: 2.986400604248047
Validation loss: 2.025657983236415

Epoch: 6| Step: 9
Training loss: 1.7448612451553345
Validation loss: 2.02018036893619

Epoch: 6| Step: 10
Training loss: 2.3415911197662354
Validation loss: 2.0214652271680933

Epoch: 6| Step: 11
Training loss: 2.154806613922119
Validation loss: 2.0228141687249623

Epoch: 6| Step: 12
Training loss: 2.2726612091064453
Validation loss: 2.0221773744911276

Epoch: 6| Step: 13
Training loss: 2.1302003860473633
Validation loss: 2.0245486241514965

Epoch: 70| Step: 0
Training loss: 2.9468936920166016
Validation loss: 2.0286191765980055

Epoch: 6| Step: 1
Training loss: 2.4844846725463867
Validation loss: 2.0412076147653724

Epoch: 6| Step: 2
Training loss: 2.1760549545288086
Validation loss: 2.048055192475678

Epoch: 6| Step: 3
Training loss: 2.5359320640563965
Validation loss: 2.0428133933774886

Epoch: 6| Step: 4
Training loss: 2.484057903289795
Validation loss: 2.0493831711430706

Epoch: 6| Step: 5
Training loss: 2.4631595611572266
Validation loss: 2.0326651065580306

Epoch: 6| Step: 6
Training loss: 1.9440499544143677
Validation loss: 2.037796502472252

Epoch: 6| Step: 7
Training loss: 1.323982834815979
Validation loss: 2.0351173903352473

Epoch: 6| Step: 8
Training loss: 2.8583858013153076
Validation loss: 2.035005032375295

Epoch: 6| Step: 9
Training loss: 2.8840413093566895
Validation loss: 2.0372840512183403

Epoch: 6| Step: 10
Training loss: 1.5447287559509277
Validation loss: 2.034548733824043

Epoch: 6| Step: 11
Training loss: 2.8337886333465576
Validation loss: 2.051531642995855

Epoch: 6| Step: 12
Training loss: 1.342293381690979
Validation loss: 2.0581689906376663

Epoch: 6| Step: 13
Training loss: 3.153163433074951
Validation loss: 2.052580682180261

Epoch: 71| Step: 0
Training loss: 2.4703526496887207
Validation loss: 2.050564113483634

Epoch: 6| Step: 1
Training loss: 2.5378339290618896
Validation loss: 2.061884823665824

Epoch: 6| Step: 2
Training loss: 2.1411452293395996
Validation loss: 2.0512389598354215

Epoch: 6| Step: 3
Training loss: 2.0899806022644043
Validation loss: 2.0476385213995494

Epoch: 6| Step: 4
Training loss: 1.9647104740142822
Validation loss: 2.050448630445747

Epoch: 6| Step: 5
Training loss: 3.38196063041687
Validation loss: 2.050521425021592

Epoch: 6| Step: 6
Training loss: 3.3326969146728516
Validation loss: 2.0444173684684177

Epoch: 6| Step: 7
Training loss: 2.3468644618988037
Validation loss: 2.05065905919639

Epoch: 6| Step: 8
Training loss: 2.0106165409088135
Validation loss: 2.05257148127402

Epoch: 6| Step: 9
Training loss: 1.859092354774475
Validation loss: 2.0580409829334547

Epoch: 6| Step: 10
Training loss: 2.237363576889038
Validation loss: 2.0578885027157363

Epoch: 6| Step: 11
Training loss: 2.110729694366455
Validation loss: 2.043943839688455

Epoch: 6| Step: 12
Training loss: 2.020024061203003
Validation loss: 2.034144760459982

Epoch: 6| Step: 13
Training loss: 2.1021664142608643
Validation loss: 2.022335780564175

Epoch: 72| Step: 0
Training loss: 2.3515186309814453
Validation loss: 2.0262242632527507

Epoch: 6| Step: 1
Training loss: 2.24721622467041
Validation loss: 2.021480198829405

Epoch: 6| Step: 2
Training loss: 2.7324492931365967
Validation loss: 2.0243907154247327

Epoch: 6| Step: 3
Training loss: 1.732515573501587
Validation loss: 2.020948645889118

Epoch: 6| Step: 4
Training loss: 3.162202835083008
Validation loss: 2.017031564507433

Epoch: 6| Step: 5
Training loss: 2.09084415435791
Validation loss: 2.0176752100708666

Epoch: 6| Step: 6
Training loss: 1.882222056388855
Validation loss: 2.0163794589299027

Epoch: 6| Step: 7
Training loss: 2.489323616027832
Validation loss: 2.018216609954834

Epoch: 6| Step: 8
Training loss: 2.21408748626709
Validation loss: 2.013416308228688

Epoch: 6| Step: 9
Training loss: 2.7471253871917725
Validation loss: 2.02275711746626

Epoch: 6| Step: 10
Training loss: 2.484470844268799
Validation loss: 2.032190945840651

Epoch: 6| Step: 11
Training loss: 1.5457441806793213
Validation loss: 2.0460306623930573

Epoch: 6| Step: 12
Training loss: 2.7391703128814697
Validation loss: 2.0688910894496466

Epoch: 6| Step: 13
Training loss: 1.5121467113494873
Validation loss: 2.059950817015863

Epoch: 73| Step: 0
Training loss: 2.5114598274230957
Validation loss: 2.04513931146232

Epoch: 6| Step: 1
Training loss: 2.205850124359131
Validation loss: 2.0364926117722706

Epoch: 6| Step: 2
Training loss: 2.1440253257751465
Validation loss: 2.0189656134574645

Epoch: 6| Step: 3
Training loss: 1.5012986660003662
Validation loss: 2.021661800722922

Epoch: 6| Step: 4
Training loss: 2.6335620880126953
Validation loss: 2.0232195110731226

Epoch: 6| Step: 5
Training loss: 2.523113489151001
Validation loss: 2.0204785998149584

Epoch: 6| Step: 6
Training loss: 2.6610116958618164
Validation loss: 2.0261960606421194

Epoch: 6| Step: 7
Training loss: 2.168839454650879
Validation loss: 2.014502392020277

Epoch: 6| Step: 8
Training loss: 2.4734771251678467
Validation loss: 2.018346002024989

Epoch: 6| Step: 9
Training loss: 2.769707202911377
Validation loss: 2.0098045513194096

Epoch: 6| Step: 10
Training loss: 2.416316032409668
Validation loss: 2.010804427567349

Epoch: 6| Step: 11
Training loss: 2.1118791103363037
Validation loss: 2.003369482614661

Epoch: 6| Step: 12
Training loss: 2.102712631225586
Validation loss: 2.002115450879579

Epoch: 6| Step: 13
Training loss: 2.4410579204559326
Validation loss: 1.9986857060463197

Epoch: 74| Step: 0
Training loss: 2.5547432899475098
Validation loss: 2.0105601485057543

Epoch: 6| Step: 1
Training loss: 2.823171854019165
Validation loss: 2.0212585618419032

Epoch: 6| Step: 2
Training loss: 2.302442789077759
Validation loss: 2.034453889375092

Epoch: 6| Step: 3
Training loss: 2.1869454383850098
Validation loss: 2.024472343024387

Epoch: 6| Step: 4
Training loss: 1.9446322917938232
Validation loss: 2.019921971905616

Epoch: 6| Step: 5
Training loss: 2.8256850242614746
Validation loss: 2.016405044063445

Epoch: 6| Step: 6
Training loss: 2.6526215076446533
Validation loss: 2.0162869243211645

Epoch: 6| Step: 7
Training loss: 2.144949436187744
Validation loss: 2.0250666038964384

Epoch: 6| Step: 8
Training loss: 2.068376302719116
Validation loss: 2.024379389260405

Epoch: 6| Step: 9
Training loss: 2.5488100051879883
Validation loss: 2.026267191415192

Epoch: 6| Step: 10
Training loss: 1.4381920099258423
Validation loss: 2.031516718608077

Epoch: 6| Step: 11
Training loss: 1.937528133392334
Validation loss: 2.028812463565539

Epoch: 6| Step: 12
Training loss: 2.8531525135040283
Validation loss: 2.030350714601496

Epoch: 6| Step: 13
Training loss: 1.8749991655349731
Validation loss: 2.0263943313270487

Epoch: 75| Step: 0
Training loss: 2.24735689163208
Validation loss: 2.021444643697431

Epoch: 6| Step: 1
Training loss: 3.071493148803711
Validation loss: 2.017234120317685

Epoch: 6| Step: 2
Training loss: 2.240901470184326
Validation loss: 2.0110617876052856

Epoch: 6| Step: 3
Training loss: 2.079237461090088
Validation loss: 2.012329452781267

Epoch: 6| Step: 4
Training loss: 2.701143741607666
Validation loss: 2.0059019519436743

Epoch: 6| Step: 5
Training loss: 2.110238790512085
Validation loss: 2.0141354171178674

Epoch: 6| Step: 6
Training loss: 2.621337652206421
Validation loss: 2.0057227637178157

Epoch: 6| Step: 7
Training loss: 3.001922130584717
Validation loss: 2.006584063653023

Epoch: 6| Step: 8
Training loss: 1.8071460723876953
Validation loss: 2.0054411183121386

Epoch: 6| Step: 9
Training loss: 2.575780153274536
Validation loss: 2.006826203356507

Epoch: 6| Step: 10
Training loss: 2.2547760009765625
Validation loss: 2.0133894464021087

Epoch: 6| Step: 11
Training loss: 2.015705108642578
Validation loss: 2.0311100072758173

Epoch: 6| Step: 12
Training loss: 1.796391487121582
Validation loss: 2.0417278069321827

Epoch: 6| Step: 13
Training loss: 1.2168042659759521
Validation loss: 2.0582268340613252

Epoch: 76| Step: 0
Training loss: 2.4201035499572754
Validation loss: 2.075746879782728

Epoch: 6| Step: 1
Training loss: 2.388148307800293
Validation loss: 2.075573995549192

Epoch: 6| Step: 2
Training loss: 2.2627835273742676
Validation loss: 2.070716875855641

Epoch: 6| Step: 3
Training loss: 2.421696662902832
Validation loss: 2.0470495198362615

Epoch: 6| Step: 4
Training loss: 1.9506491422653198
Validation loss: 2.034527373570268

Epoch: 6| Step: 5
Training loss: 2.9618234634399414
Validation loss: 2.0137375503458004

Epoch: 6| Step: 6
Training loss: 1.8923146724700928
Validation loss: 1.995023763307961

Epoch: 6| Step: 7
Training loss: 2.226759195327759
Validation loss: 1.9822439019398024

Epoch: 6| Step: 8
Training loss: 1.981506586074829
Validation loss: 2.001587624190956

Epoch: 6| Step: 9
Training loss: 2.2957892417907715
Validation loss: 2.0056207000568347

Epoch: 6| Step: 10
Training loss: 3.059753894805908
Validation loss: 2.0051168780173025

Epoch: 6| Step: 11
Training loss: 1.8506691455841064
Validation loss: 1.996500051149758

Epoch: 6| Step: 12
Training loss: 1.9677774906158447
Validation loss: 1.9877781009161344

Epoch: 6| Step: 13
Training loss: 3.168468713760376
Validation loss: 1.982735772286692

Epoch: 77| Step: 0
Training loss: 2.3986763954162598
Validation loss: 1.979782308301618

Epoch: 6| Step: 1
Training loss: 2.2255778312683105
Validation loss: 2.001925021089533

Epoch: 6| Step: 2
Training loss: 2.2094779014587402
Validation loss: 2.009049894989178

Epoch: 6| Step: 3
Training loss: 2.2482094764709473
Validation loss: 2.030733786603456

Epoch: 6| Step: 4
Training loss: 2.0749480724334717
Validation loss: 2.0777987357108825

Epoch: 6| Step: 5
Training loss: 3.038719654083252
Validation loss: 2.0685426637690556

Epoch: 6| Step: 6
Training loss: 1.9359583854675293
Validation loss: 2.0627968721492316

Epoch: 6| Step: 7
Training loss: 2.235619068145752
Validation loss: 2.04486850512925

Epoch: 6| Step: 8
Training loss: 2.6664111614227295
Validation loss: 2.0385500538733696

Epoch: 6| Step: 9
Training loss: 2.5156283378601074
Validation loss: 2.0166818223973757

Epoch: 6| Step: 10
Training loss: 2.3048665523529053
Validation loss: 2.020261264616443

Epoch: 6| Step: 11
Training loss: 2.3087286949157715
Validation loss: 2.0012253253690657

Epoch: 6| Step: 12
Training loss: 2.057847023010254
Validation loss: 1.9985568138860887

Epoch: 6| Step: 13
Training loss: 2.02427339553833
Validation loss: 1.9926538749407696

Epoch: 78| Step: 0
Training loss: 3.0360422134399414
Validation loss: 2.0077819080762964

Epoch: 6| Step: 1
Training loss: 2.460768938064575
Validation loss: 2.0040422844630417

Epoch: 6| Step: 2
Training loss: 2.1899185180664062
Validation loss: 2.0158036037157943

Epoch: 6| Step: 3
Training loss: 2.7277774810791016
Validation loss: 2.0111041402304046

Epoch: 6| Step: 4
Training loss: 1.5577960014343262
Validation loss: 2.015555512520575

Epoch: 6| Step: 5
Training loss: 1.7037811279296875
Validation loss: 2.0168623501254666

Epoch: 6| Step: 6
Training loss: 2.2222588062286377
Validation loss: 2.013122543211906

Epoch: 6| Step: 7
Training loss: 1.8010610342025757
Validation loss: 2.0176339777567054

Epoch: 6| Step: 8
Training loss: 2.8824117183685303
Validation loss: 2.02141139840567

Epoch: 6| Step: 9
Training loss: 1.9770933389663696
Validation loss: 2.0163987657075286

Epoch: 6| Step: 10
Training loss: 2.263300895690918
Validation loss: 2.010049994273852

Epoch: 6| Step: 11
Training loss: 2.265061616897583
Validation loss: 2.003493898658342

Epoch: 6| Step: 12
Training loss: 2.6668639183044434
Validation loss: 2.001684060660742

Epoch: 6| Step: 13
Training loss: 2.34653377532959
Validation loss: 1.9980067488967732

Epoch: 79| Step: 0
Training loss: 2.1065425872802734
Validation loss: 1.999251579725614

Epoch: 6| Step: 1
Training loss: 2.16471004486084
Validation loss: 1.980170460157497

Epoch: 6| Step: 2
Training loss: 2.116177797317505
Validation loss: 1.9848894560208885

Epoch: 6| Step: 3
Training loss: 3.1441633701324463
Validation loss: 1.9843003070482643

Epoch: 6| Step: 4
Training loss: 1.799310326576233
Validation loss: 1.9861354007515857

Epoch: 6| Step: 5
Training loss: 2.8079686164855957
Validation loss: 1.9903393073748517

Epoch: 6| Step: 6
Training loss: 2.9273266792297363
Validation loss: 1.9960030740307224

Epoch: 6| Step: 7
Training loss: 1.629897952079773
Validation loss: 2.0002883147167903

Epoch: 6| Step: 8
Training loss: 2.1263742446899414
Validation loss: 1.9994636274153186

Epoch: 6| Step: 9
Training loss: 2.0593860149383545
Validation loss: 2.004488757861558

Epoch: 6| Step: 10
Training loss: 2.2299489974975586
Validation loss: 1.9908624182465255

Epoch: 6| Step: 11
Training loss: 1.951849341392517
Validation loss: 1.9922772710041334

Epoch: 6| Step: 12
Training loss: 2.7066798210144043
Validation loss: 1.9857498433000298

Epoch: 6| Step: 13
Training loss: 1.7637782096862793
Validation loss: 1.9869058721808976

Epoch: 80| Step: 0
Training loss: 1.8460195064544678
Validation loss: 1.9772662629363358

Epoch: 6| Step: 1
Training loss: 1.9370896816253662
Validation loss: 1.9842401563480336

Epoch: 6| Step: 2
Training loss: 2.757175922393799
Validation loss: 1.9797920334723689

Epoch: 6| Step: 3
Training loss: 2.315065860748291
Validation loss: 1.9784782881377845

Epoch: 6| Step: 4
Training loss: 2.8747215270996094
Validation loss: 1.9874692681015178

Epoch: 6| Step: 5
Training loss: 2.0732219219207764
Validation loss: 1.9844420712481263

Epoch: 6| Step: 6
Training loss: 1.655739188194275
Validation loss: 1.9771649632402646

Epoch: 6| Step: 7
Training loss: 2.5145676136016846
Validation loss: 1.9838183669633762

Epoch: 6| Step: 8
Training loss: 2.425030469894409
Validation loss: 1.987471015222611

Epoch: 6| Step: 9
Training loss: 2.8954572677612305
Validation loss: 1.9842496084910568

Epoch: 6| Step: 10
Training loss: 1.6658973693847656
Validation loss: 1.9847929605873682

Epoch: 6| Step: 11
Training loss: 2.0345818996429443
Validation loss: 1.9729236287455405

Epoch: 6| Step: 12
Training loss: 2.5289154052734375
Validation loss: 1.9821617398210751

Epoch: 6| Step: 13
Training loss: 2.038736581802368
Validation loss: 1.990781267484029

Epoch: 81| Step: 0
Training loss: 2.008913278579712
Validation loss: 2.00195207647098

Epoch: 6| Step: 1
Training loss: 2.1557278633117676
Validation loss: 1.9993071735546153

Epoch: 6| Step: 2
Training loss: 2.3645691871643066
Validation loss: 2.006305925307735

Epoch: 6| Step: 3
Training loss: 2.4847970008850098
Validation loss: 2.00246415856064

Epoch: 6| Step: 4
Training loss: 2.37269926071167
Validation loss: 1.9953348303353915

Epoch: 6| Step: 5
Training loss: 2.0740256309509277
Validation loss: 1.9880446208420621

Epoch: 6| Step: 6
Training loss: 1.6790924072265625
Validation loss: 2.013513359972226

Epoch: 6| Step: 7
Training loss: 2.278776168823242
Validation loss: 2.006390525448707

Epoch: 6| Step: 8
Training loss: 2.1167750358581543
Validation loss: 2.0191103771168697

Epoch: 6| Step: 9
Training loss: 2.271845817565918
Validation loss: 2.007292220669408

Epoch: 6| Step: 10
Training loss: 2.433830738067627
Validation loss: 2.002326447476623

Epoch: 6| Step: 11
Training loss: 2.172257900238037
Validation loss: 1.9947705525223927

Epoch: 6| Step: 12
Training loss: 2.5835399627685547
Validation loss: 2.0010556033862534

Epoch: 6| Step: 13
Training loss: 3.374131679534912
Validation loss: 1.9978671637914514

Epoch: 82| Step: 0
Training loss: 2.398341178894043
Validation loss: 2.000433765431886

Epoch: 6| Step: 1
Training loss: 2.0351295471191406
Validation loss: 1.9814549825524772

Epoch: 6| Step: 2
Training loss: 1.9456626176834106
Validation loss: 1.976293703561188

Epoch: 6| Step: 3
Training loss: 2.2340893745422363
Validation loss: 1.965224116079269

Epoch: 6| Step: 4
Training loss: 2.4667439460754395
Validation loss: 1.9650416784389044

Epoch: 6| Step: 5
Training loss: 1.9312489032745361
Validation loss: 1.9786419240377282

Epoch: 6| Step: 6
Training loss: 2.5061511993408203
Validation loss: 1.9824628573591991

Epoch: 6| Step: 7
Training loss: 2.3941304683685303
Validation loss: 1.9794178496124923

Epoch: 6| Step: 8
Training loss: 2.640470504760742
Validation loss: 1.9803323514999882

Epoch: 6| Step: 9
Training loss: 2.073680877685547
Validation loss: 1.97440408250337

Epoch: 6| Step: 10
Training loss: 2.085433006286621
Validation loss: 1.9721511730583765

Epoch: 6| Step: 11
Training loss: 2.525576114654541
Validation loss: 1.9688162521649433

Epoch: 6| Step: 12
Training loss: 2.965466022491455
Validation loss: 1.9755422171726023

Epoch: 6| Step: 13
Training loss: 0.9392478466033936
Validation loss: 1.9787105206520326

Epoch: 83| Step: 0
Training loss: 1.7701560258865356
Validation loss: 1.9750438556876233

Epoch: 6| Step: 1
Training loss: 2.622191905975342
Validation loss: 1.9828654925028484

Epoch: 6| Step: 2
Training loss: 2.542261838912964
Validation loss: 1.9810882088958577

Epoch: 6| Step: 3
Training loss: 2.3734734058380127
Validation loss: 1.9899437453157158

Epoch: 6| Step: 4
Training loss: 2.6691057682037354
Validation loss: 1.995349931460555

Epoch: 6| Step: 5
Training loss: 1.3647074699401855
Validation loss: 1.9914147879487725

Epoch: 6| Step: 6
Training loss: 2.302767276763916
Validation loss: 1.9895379389486005

Epoch: 6| Step: 7
Training loss: 2.210575580596924
Validation loss: 1.9869619005469865

Epoch: 6| Step: 8
Training loss: 2.295473098754883
Validation loss: 1.9944896544179609

Epoch: 6| Step: 9
Training loss: 2.8031744956970215
Validation loss: 1.9822992099228727

Epoch: 6| Step: 10
Training loss: 1.661160945892334
Validation loss: 1.987507168964673

Epoch: 6| Step: 11
Training loss: 2.5029778480529785
Validation loss: 1.9778861896966093

Epoch: 6| Step: 12
Training loss: 2.308650493621826
Validation loss: 1.9822423124826083

Epoch: 6| Step: 13
Training loss: 1.9804341793060303
Validation loss: 1.9797106340367308

Epoch: 84| Step: 0
Training loss: 2.2952213287353516
Validation loss: 1.9713009249779485

Epoch: 6| Step: 1
Training loss: 2.314079999923706
Validation loss: 1.9741332300247685

Epoch: 6| Step: 2
Training loss: 1.6543773412704468
Validation loss: 1.9741640936943792

Epoch: 6| Step: 3
Training loss: 2.588021755218506
Validation loss: 1.9746188373975857

Epoch: 6| Step: 4
Training loss: 1.7864711284637451
Validation loss: 1.9808412649298226

Epoch: 6| Step: 5
Training loss: 3.0892302989959717
Validation loss: 1.9755580591899093

Epoch: 6| Step: 6
Training loss: 2.3921689987182617
Validation loss: 1.97478061978535

Epoch: 6| Step: 7
Training loss: 2.612311840057373
Validation loss: 1.9730201921155375

Epoch: 6| Step: 8
Training loss: 2.2653462886810303
Validation loss: 1.9741194094381025

Epoch: 6| Step: 9
Training loss: 2.826493740081787
Validation loss: 1.98306857385943

Epoch: 6| Step: 10
Training loss: 1.5837244987487793
Validation loss: 1.986412457240525

Epoch: 6| Step: 11
Training loss: 2.1633379459381104
Validation loss: 1.9928366291907527

Epoch: 6| Step: 12
Training loss: 1.6203231811523438
Validation loss: 1.9695595592580817

Epoch: 6| Step: 13
Training loss: 2.653834104537964
Validation loss: 1.9687679647117533

Epoch: 85| Step: 0
Training loss: 1.9594659805297852
Validation loss: 1.962048158850721

Epoch: 6| Step: 1
Training loss: 1.6449439525604248
Validation loss: 1.9682971559545046

Epoch: 6| Step: 2
Training loss: 2.1065595149993896
Validation loss: 1.963553326104277

Epoch: 6| Step: 3
Training loss: 1.9093213081359863
Validation loss: 1.9703110161648

Epoch: 6| Step: 4
Training loss: 2.0968103408813477
Validation loss: 1.9799807892050794

Epoch: 6| Step: 5
Training loss: 2.403470039367676
Validation loss: 1.974627169229651

Epoch: 6| Step: 6
Training loss: 3.013339042663574
Validation loss: 1.9781344975194624

Epoch: 6| Step: 7
Training loss: 2.5513336658477783
Validation loss: 1.9781888518282162

Epoch: 6| Step: 8
Training loss: 2.7943286895751953
Validation loss: 1.9807030206085534

Epoch: 6| Step: 9
Training loss: 2.406053304672241
Validation loss: 1.9754433042259627

Epoch: 6| Step: 10
Training loss: 2.666591167449951
Validation loss: 1.9724648614083566

Epoch: 6| Step: 11
Training loss: 1.9009021520614624
Validation loss: 1.9756265019857755

Epoch: 6| Step: 12
Training loss: 1.7778918743133545
Validation loss: 1.9784827309270059

Epoch: 6| Step: 13
Training loss: 2.190978765487671
Validation loss: 1.9799957147208593

Epoch: 86| Step: 0
Training loss: 2.603339672088623
Validation loss: 1.9820926394513858

Epoch: 6| Step: 1
Training loss: 2.102620840072632
Validation loss: 1.9785907037796513

Epoch: 6| Step: 2
Training loss: 2.156722068786621
Validation loss: 1.968899337194299

Epoch: 6| Step: 3
Training loss: 2.284280776977539
Validation loss: 1.968507803896422

Epoch: 6| Step: 4
Training loss: 1.6720399856567383
Validation loss: 1.9752480881188506

Epoch: 6| Step: 5
Training loss: 2.3230226039886475
Validation loss: 1.975872011594875

Epoch: 6| Step: 6
Training loss: 1.7281948328018188
Validation loss: 1.9769097861423288

Epoch: 6| Step: 7
Training loss: 2.2727935314178467
Validation loss: 1.9674456170810166

Epoch: 6| Step: 8
Training loss: 2.644698143005371
Validation loss: 1.9677309400291854

Epoch: 6| Step: 9
Training loss: 2.179107666015625
Validation loss: 1.967957647897864

Epoch: 6| Step: 10
Training loss: 2.695375442504883
Validation loss: 1.9608986839171378

Epoch: 6| Step: 11
Training loss: 1.696699619293213
Validation loss: 1.9576918155916276

Epoch: 6| Step: 12
Training loss: 2.674272298812866
Validation loss: 1.9603607039297781

Epoch: 6| Step: 13
Training loss: 2.4285571575164795
Validation loss: 1.959291341484234

Epoch: 87| Step: 0
Training loss: 2.2030935287475586
Validation loss: 1.9538473467673025

Epoch: 6| Step: 1
Training loss: 2.4037275314331055
Validation loss: 1.9503791319426669

Epoch: 6| Step: 2
Training loss: 2.3794803619384766
Validation loss: 1.9566343099840227

Epoch: 6| Step: 3
Training loss: 2.020341396331787
Validation loss: 1.9545926073546052

Epoch: 6| Step: 4
Training loss: 2.205648183822632
Validation loss: 1.9445584025434268

Epoch: 6| Step: 5
Training loss: 2.34985613822937
Validation loss: 1.9450862766594015

Epoch: 6| Step: 6
Training loss: 2.6664021015167236
Validation loss: 1.9486887954896497

Epoch: 6| Step: 7
Training loss: 1.9527225494384766
Validation loss: 1.951763876022831

Epoch: 6| Step: 8
Training loss: 2.28995418548584
Validation loss: 1.9430113159200197

Epoch: 6| Step: 9
Training loss: 1.8875770568847656
Validation loss: 1.9537095357013006

Epoch: 6| Step: 10
Training loss: 1.8733670711517334
Validation loss: 1.9482649987743748

Epoch: 6| Step: 11
Training loss: 2.540569305419922
Validation loss: 1.9480056339694607

Epoch: 6| Step: 12
Training loss: 2.4979333877563477
Validation loss: 1.9577695438938756

Epoch: 6| Step: 13
Training loss: 1.7379071712493896
Validation loss: 1.9571982224782307

Epoch: 88| Step: 0
Training loss: 2.057453155517578
Validation loss: 1.9575357770407071

Epoch: 6| Step: 1
Training loss: 2.493950843811035
Validation loss: 1.950657724052347

Epoch: 6| Step: 2
Training loss: 2.9106016159057617
Validation loss: 1.9462552916619085

Epoch: 6| Step: 3
Training loss: 1.8563743829727173
Validation loss: 1.9483416336838917

Epoch: 6| Step: 4
Training loss: 1.8089452981948853
Validation loss: 1.9466083639411516

Epoch: 6| Step: 5
Training loss: 2.710294723510742
Validation loss: 1.9477476432759275

Epoch: 6| Step: 6
Training loss: 1.9697504043579102
Validation loss: 1.9563966310152443

Epoch: 6| Step: 7
Training loss: 2.17755126953125
Validation loss: 1.9508312543233235

Epoch: 6| Step: 8
Training loss: 2.635450839996338
Validation loss: 1.9580989371063888

Epoch: 6| Step: 9
Training loss: 2.312460422515869
Validation loss: 1.9678662425728255

Epoch: 6| Step: 10
Training loss: 1.7599492073059082
Validation loss: 1.9745447430559384

Epoch: 6| Step: 11
Training loss: 2.322291135787964
Validation loss: 1.9740217321662492

Epoch: 6| Step: 12
Training loss: 2.089877128601074
Validation loss: 1.987883799819536

Epoch: 6| Step: 13
Training loss: 2.052380323410034
Validation loss: 1.9796378561245498

Epoch: 89| Step: 0
Training loss: 2.4705262184143066
Validation loss: 1.9913443621768747

Epoch: 6| Step: 1
Training loss: 1.6442952156066895
Validation loss: 2.0082108974456787

Epoch: 6| Step: 2
Training loss: 2.429222583770752
Validation loss: 2.0250564775159283

Epoch: 6| Step: 3
Training loss: 2.5432686805725098
Validation loss: 2.0329975287119546

Epoch: 6| Step: 4
Training loss: 2.2546896934509277
Validation loss: 2.0604488465093795

Epoch: 6| Step: 5
Training loss: 2.534992218017578
Validation loss: 2.0546885921109106

Epoch: 6| Step: 6
Training loss: 1.1887991428375244
Validation loss: 2.04847655757781

Epoch: 6| Step: 7
Training loss: 1.6689618825912476
Validation loss: 2.0201507358140844

Epoch: 6| Step: 8
Training loss: 2.5509634017944336
Validation loss: 2.0132278344964467

Epoch: 6| Step: 9
Training loss: 2.5018434524536133
Validation loss: 1.9765532426936652

Epoch: 6| Step: 10
Training loss: 2.3095669746398926
Validation loss: 1.9532770085078415

Epoch: 6| Step: 11
Training loss: 2.376649856567383
Validation loss: 1.9454021658948673

Epoch: 6| Step: 12
Training loss: 2.4581403732299805
Validation loss: 1.9496893523841776

Epoch: 6| Step: 13
Training loss: 2.21984601020813
Validation loss: 1.951137722179454

Epoch: 90| Step: 0
Training loss: 2.0312962532043457
Validation loss: 1.9535932489620742

Epoch: 6| Step: 1
Training loss: 2.9883525371551514
Validation loss: 1.9582286957771546

Epoch: 6| Step: 2
Training loss: 2.0788156986236572
Validation loss: 1.9505878238267795

Epoch: 6| Step: 3
Training loss: 1.956437587738037
Validation loss: 1.9418169375388854

Epoch: 6| Step: 4
Training loss: 2.287018299102783
Validation loss: 1.9369401085761286

Epoch: 6| Step: 5
Training loss: 2.231029748916626
Validation loss: 1.9405062019184072

Epoch: 6| Step: 6
Training loss: 2.7011466026306152
Validation loss: 1.9373712565309258

Epoch: 6| Step: 7
Training loss: 1.6069836616516113
Validation loss: 1.9583964668294436

Epoch: 6| Step: 8
Training loss: 2.35487699508667
Validation loss: 1.9651162855086788

Epoch: 6| Step: 9
Training loss: 1.6620348691940308
Validation loss: 1.9633962197970318

Epoch: 6| Step: 10
Training loss: 2.286661148071289
Validation loss: 1.9664825649671658

Epoch: 6| Step: 11
Training loss: 1.9692457914352417
Validation loss: 1.9482792756890739

Epoch: 6| Step: 12
Training loss: 2.665005683898926
Validation loss: 1.9423723374643633

Epoch: 6| Step: 13
Training loss: 2.606229543685913
Validation loss: 1.9498754855125182

Epoch: 91| Step: 0
Training loss: 2.5231449604034424
Validation loss: 1.9528961822550783

Epoch: 6| Step: 1
Training loss: 1.824053406715393
Validation loss: 1.9635139037204046

Epoch: 6| Step: 2
Training loss: 2.08579421043396
Validation loss: 1.9632756607506865

Epoch: 6| Step: 3
Training loss: 2.2115771770477295
Validation loss: 1.9656196127655685

Epoch: 6| Step: 4
Training loss: 2.0859787464141846
Validation loss: 1.9493345368293025

Epoch: 6| Step: 5
Training loss: 2.8226280212402344
Validation loss: 1.9542183773491972

Epoch: 6| Step: 6
Training loss: 2.453372001647949
Validation loss: 1.9478100935618083

Epoch: 6| Step: 7
Training loss: 2.578564405441284
Validation loss: 1.9354235843945575

Epoch: 6| Step: 8
Training loss: 1.786961317062378
Validation loss: 1.9375100545985724

Epoch: 6| Step: 9
Training loss: 1.9169230461120605
Validation loss: 1.941189000683446

Epoch: 6| Step: 10
Training loss: 3.2025389671325684
Validation loss: 1.9467282602863927

Epoch: 6| Step: 11
Training loss: 1.6595497131347656
Validation loss: 1.9695544037767636

Epoch: 6| Step: 12
Training loss: 2.028764009475708
Validation loss: 1.9972183537739578

Epoch: 6| Step: 13
Training loss: 1.8397761583328247
Validation loss: 2.009202846916773

Epoch: 92| Step: 0
Training loss: 2.412655830383301
Validation loss: 1.9764173082126084

Epoch: 6| Step: 1
Training loss: 2.3902125358581543
Validation loss: 1.9663473303600023

Epoch: 6| Step: 2
Training loss: 2.7313051223754883
Validation loss: 1.9579475400268391

Epoch: 6| Step: 3
Training loss: 1.503922462463379
Validation loss: 1.9862258447113859

Epoch: 6| Step: 4
Training loss: 1.9993922710418701
Validation loss: 2.0085258701796174

Epoch: 6| Step: 5
Training loss: 1.9553766250610352
Validation loss: 2.018015894838559

Epoch: 6| Step: 6
Training loss: 2.4949145317077637
Validation loss: 2.0005892066545385

Epoch: 6| Step: 7
Training loss: 1.890681505203247
Validation loss: 1.989958191430697

Epoch: 6| Step: 8
Training loss: 2.6014583110809326
Validation loss: 1.9766705766800912

Epoch: 6| Step: 9
Training loss: 2.691819190979004
Validation loss: 1.9993133980740783

Epoch: 6| Step: 10
Training loss: 2.1477668285369873
Validation loss: 2.0006264563529723

Epoch: 6| Step: 11
Training loss: 2.250619649887085
Validation loss: 1.99008725279121

Epoch: 6| Step: 12
Training loss: 2.4204535484313965
Validation loss: 1.9741651832416494

Epoch: 6| Step: 13
Training loss: 1.701670527458191
Validation loss: 1.9760623696029826

Epoch: 93| Step: 0
Training loss: 2.570852756500244
Validation loss: 1.9595202989475702

Epoch: 6| Step: 1
Training loss: 2.349581718444824
Validation loss: 1.9441644812142977

Epoch: 6| Step: 2
Training loss: 1.6031290292739868
Validation loss: 1.9366980701364496

Epoch: 6| Step: 3
Training loss: 2.2814342975616455
Validation loss: 1.9388207248462144

Epoch: 6| Step: 4
Training loss: 2.790910243988037
Validation loss: 1.952059902170653

Epoch: 6| Step: 5
Training loss: 2.638658285140991
Validation loss: 1.9568276597607521

Epoch: 6| Step: 6
Training loss: 2.3751659393310547
Validation loss: 1.955075810032506

Epoch: 6| Step: 7
Training loss: 2.4306368827819824
Validation loss: 1.9652518213436168

Epoch: 6| Step: 8
Training loss: 2.0955045223236084
Validation loss: 1.9574775952164845

Epoch: 6| Step: 9
Training loss: 1.8776843547821045
Validation loss: 1.9586182819899691

Epoch: 6| Step: 10
Training loss: 2.354891300201416
Validation loss: 1.9656655352602723

Epoch: 6| Step: 11
Training loss: 2.3101696968078613
Validation loss: 1.9678994122371878

Epoch: 6| Step: 12
Training loss: 1.33919095993042
Validation loss: 1.9490089160139843

Epoch: 6| Step: 13
Training loss: 1.9315507411956787
Validation loss: 1.9519891367163709

Epoch: 94| Step: 0
Training loss: 2.3669800758361816
Validation loss: 1.959803896565591

Epoch: 6| Step: 1
Training loss: 2.878645420074463
Validation loss: 1.9740939473593107

Epoch: 6| Step: 2
Training loss: 1.7531664371490479
Validation loss: 1.9688080203148626

Epoch: 6| Step: 3
Training loss: 2.2506346702575684
Validation loss: 1.953741224863196

Epoch: 6| Step: 4
Training loss: 2.3489837646484375
Validation loss: 1.9399942210925523

Epoch: 6| Step: 5
Training loss: 2.404597520828247
Validation loss: 1.9267187964531682

Epoch: 6| Step: 6
Training loss: 2.33752703666687
Validation loss: 1.9286346512456094

Epoch: 6| Step: 7
Training loss: 1.4791041612625122
Validation loss: 1.9441083259479974

Epoch: 6| Step: 8
Training loss: 2.1943211555480957
Validation loss: 1.9344919894331245

Epoch: 6| Step: 9
Training loss: 1.5707356929779053
Validation loss: 1.9335498912360078

Epoch: 6| Step: 10
Training loss: 2.76809024810791
Validation loss: 1.9316048545222129

Epoch: 6| Step: 11
Training loss: 2.030372142791748
Validation loss: 1.9291435236571937

Epoch: 6| Step: 12
Training loss: 1.9390990734100342
Validation loss: 1.9392225614158056

Epoch: 6| Step: 13
Training loss: 2.3922641277313232
Validation loss: 1.9397621667513283

Epoch: 95| Step: 0
Training loss: 2.5518622398376465
Validation loss: 1.947007094660113

Epoch: 6| Step: 1
Training loss: 1.7296855449676514
Validation loss: 1.950792356203961

Epoch: 6| Step: 2
Training loss: 2.723773956298828
Validation loss: 1.9476079658795429

Epoch: 6| Step: 3
Training loss: 2.133977174758911
Validation loss: 1.9451128680218932

Epoch: 6| Step: 4
Training loss: 2.826779842376709
Validation loss: 1.9592372063667542

Epoch: 6| Step: 5
Training loss: 2.4841647148132324
Validation loss: 1.9518204119897657

Epoch: 6| Step: 6
Training loss: 1.9202576875686646
Validation loss: 1.9514515246114423

Epoch: 6| Step: 7
Training loss: 2.243403911590576
Validation loss: 1.957171238878722

Epoch: 6| Step: 8
Training loss: 2.484506607055664
Validation loss: 1.9500992887763566

Epoch: 6| Step: 9
Training loss: 1.857356071472168
Validation loss: 1.9545103542266353

Epoch: 6| Step: 10
Training loss: 1.6472917795181274
Validation loss: 1.9553720848534697

Epoch: 6| Step: 11
Training loss: 2.0784847736358643
Validation loss: 1.9458347494884203

Epoch: 6| Step: 12
Training loss: 2.1440985202789307
Validation loss: 1.9463556787019134

Epoch: 6| Step: 13
Training loss: 1.002968668937683
Validation loss: 1.9411000026169645

Epoch: 96| Step: 0
Training loss: 1.6090291738510132
Validation loss: 1.95163086921938

Epoch: 6| Step: 1
Training loss: 1.9480164051055908
Validation loss: 1.9660042947338474

Epoch: 6| Step: 2
Training loss: 2.5424861907958984
Validation loss: 1.9969487587610881

Epoch: 6| Step: 3
Training loss: 2.385859489440918
Validation loss: 1.993335908459079

Epoch: 6| Step: 4
Training loss: 2.5142412185668945
Validation loss: 1.9815928602731356

Epoch: 6| Step: 5
Training loss: 2.7219440937042236
Validation loss: 1.9653738032105148

Epoch: 6| Step: 6
Training loss: 1.869781732559204
Validation loss: 1.9535533202591764

Epoch: 6| Step: 7
Training loss: 2.085679531097412
Validation loss: 1.9220427428522417

Epoch: 6| Step: 8
Training loss: 2.25820255279541
Validation loss: 1.9308110693449616

Epoch: 6| Step: 9
Training loss: 1.9506151676177979
Validation loss: 1.9456883784263366

Epoch: 6| Step: 10
Training loss: 2.591907024383545
Validation loss: 1.9427798255797355

Epoch: 6| Step: 11
Training loss: 2.23359751701355
Validation loss: 1.9464030919536468

Epoch: 6| Step: 12
Training loss: 2.5813822746276855
Validation loss: 1.935260723995906

Epoch: 6| Step: 13
Training loss: 1.1701818704605103
Validation loss: 1.925451683741744

Epoch: 97| Step: 0
Training loss: 1.898118019104004
Validation loss: 1.9236420918536443

Epoch: 6| Step: 1
Training loss: 2.3357975482940674
Validation loss: 1.9101064147487763

Epoch: 6| Step: 2
Training loss: 1.8868927955627441
Validation loss: 1.930877439437374

Epoch: 6| Step: 3
Training loss: 2.080073833465576
Validation loss: 1.940316819375561

Epoch: 6| Step: 4
Training loss: 1.4411389827728271
Validation loss: 1.9416638317928518

Epoch: 6| Step: 5
Training loss: 2.3884005546569824
Validation loss: 1.937846310677067

Epoch: 6| Step: 6
Training loss: 1.9194470643997192
Validation loss: 1.925104412981259

Epoch: 6| Step: 7
Training loss: 2.834290027618408
Validation loss: 1.9217682218038907

Epoch: 6| Step: 8
Training loss: 2.283313274383545
Validation loss: 1.9118511138423797

Epoch: 6| Step: 9
Training loss: 2.752121925354004
Validation loss: 1.919788783596408

Epoch: 6| Step: 10
Training loss: 1.263067603111267
Validation loss: 1.9225321392859183

Epoch: 6| Step: 11
Training loss: 2.032299518585205
Validation loss: 1.9225048813768613

Epoch: 6| Step: 12
Training loss: 2.795337677001953
Validation loss: 1.9306442263305827

Epoch: 6| Step: 13
Training loss: 2.8996729850769043
Validation loss: 1.9274792607112596

Epoch: 98| Step: 0
Training loss: 1.7270405292510986
Validation loss: 1.9213216279142646

Epoch: 6| Step: 1
Training loss: 2.0682005882263184
Validation loss: 1.9436676322772939

Epoch: 6| Step: 2
Training loss: 1.9326850175857544
Validation loss: 1.952982420562416

Epoch: 6| Step: 3
Training loss: 2.514930248260498
Validation loss: 1.9610850157276276

Epoch: 6| Step: 4
Training loss: 2.348958730697632
Validation loss: 1.9839322695168116

Epoch: 6| Step: 5
Training loss: 2.702249526977539
Validation loss: 1.9717854428034958

Epoch: 6| Step: 6
Training loss: 2.0372776985168457
Validation loss: 1.9593816854620492

Epoch: 6| Step: 7
Training loss: 2.1777284145355225
Validation loss: 1.9412433396103561

Epoch: 6| Step: 8
Training loss: 2.079921245574951
Validation loss: 1.9464838415063836

Epoch: 6| Step: 9
Training loss: 2.256094455718994
Validation loss: 1.934817780730545

Epoch: 6| Step: 10
Training loss: 1.954246997833252
Validation loss: 1.9343863712844027

Epoch: 6| Step: 11
Training loss: 1.7826042175292969
Validation loss: 1.919697646171816

Epoch: 6| Step: 12
Training loss: 2.2999281883239746
Validation loss: 1.9194586584644933

Epoch: 6| Step: 13
Training loss: 2.5618109703063965
Validation loss: 1.9077152077869703

Epoch: 99| Step: 0
Training loss: 2.37337327003479
Validation loss: 1.9073969830748856

Epoch: 6| Step: 1
Training loss: 1.9875538349151611
Validation loss: 1.911648214504283

Epoch: 6| Step: 2
Training loss: 2.2724552154541016
Validation loss: 1.9060037597533195

Epoch: 6| Step: 3
Training loss: 2.3727664947509766
Validation loss: 1.9180800504581903

Epoch: 6| Step: 4
Training loss: 2.103700876235962
Validation loss: 1.9189545287880847

Epoch: 6| Step: 5
Training loss: 2.871541976928711
Validation loss: 1.912472096822595

Epoch: 6| Step: 6
Training loss: 1.4490840435028076
Validation loss: 1.9245303612883373

Epoch: 6| Step: 7
Training loss: 2.444638967514038
Validation loss: 1.9197111950125745

Epoch: 6| Step: 8
Training loss: 1.767983317375183
Validation loss: 1.920110705078289

Epoch: 6| Step: 9
Training loss: 1.3667216300964355
Validation loss: 1.9223746650962419

Epoch: 6| Step: 10
Training loss: 2.078540086746216
Validation loss: 1.9273967319919216

Epoch: 6| Step: 11
Training loss: 2.2959094047546387
Validation loss: 1.9111701416712936

Epoch: 6| Step: 12
Training loss: 2.490004539489746
Validation loss: 1.9086030478118567

Epoch: 6| Step: 13
Training loss: 2.3542251586914062
Validation loss: 1.9045577561983498

Epoch: 100| Step: 0
Training loss: 2.602105140686035
Validation loss: 1.9082436253947597

Epoch: 6| Step: 1
Training loss: 2.7998287677764893
Validation loss: 1.9177604772711312

Epoch: 6| Step: 2
Training loss: 1.699253797531128
Validation loss: 1.9228053618502874

Epoch: 6| Step: 3
Training loss: 2.443204164505005
Validation loss: 1.9195055000243648

Epoch: 6| Step: 4
Training loss: 2.0198771953582764
Validation loss: 1.918399069898872

Epoch: 6| Step: 5
Training loss: 2.2950448989868164
Validation loss: 1.9135075512752737

Epoch: 6| Step: 6
Training loss: 2.7120227813720703
Validation loss: 1.9037765354238532

Epoch: 6| Step: 7
Training loss: 2.2887351512908936
Validation loss: 1.9078591305722472

Epoch: 6| Step: 8
Training loss: 1.6746771335601807
Validation loss: 1.911385484921035

Epoch: 6| Step: 9
Training loss: 2.438535213470459
Validation loss: 1.919164273046678

Epoch: 6| Step: 10
Training loss: 1.4795476198196411
Validation loss: 1.922171861894669

Epoch: 6| Step: 11
Training loss: 1.712527871131897
Validation loss: 1.925957815621489

Epoch: 6| Step: 12
Training loss: 1.8931807279586792
Validation loss: 1.935746136532035

Epoch: 6| Step: 13
Training loss: 2.067891836166382
Validation loss: 1.9350369617503176

Epoch: 101| Step: 0
Training loss: 1.9102271795272827
Validation loss: 1.9357917283170967

Epoch: 6| Step: 1
Training loss: 2.6092166900634766
Validation loss: 1.9367625380075106

Epoch: 6| Step: 2
Training loss: 2.2783660888671875
Validation loss: 1.9497836917959235

Epoch: 6| Step: 3
Training loss: 2.450483798980713
Validation loss: 1.9466519227591894

Epoch: 6| Step: 4
Training loss: 1.6095750331878662
Validation loss: 1.9434437572315175

Epoch: 6| Step: 5
Training loss: 1.8440515995025635
Validation loss: 1.9466939049382364

Epoch: 6| Step: 6
Training loss: 1.3201303482055664
Validation loss: 1.9656617910631242

Epoch: 6| Step: 7
Training loss: 2.0842628479003906
Validation loss: 1.9725912488916868

Epoch: 6| Step: 8
Training loss: 2.132153034210205
Validation loss: 1.983189332869745

Epoch: 6| Step: 9
Training loss: 2.0861129760742188
Validation loss: 1.963188245732297

Epoch: 6| Step: 10
Training loss: 2.395815849304199
Validation loss: 1.929958676779142

Epoch: 6| Step: 11
Training loss: 2.0967841148376465
Validation loss: 1.9262287014274186

Epoch: 6| Step: 12
Training loss: 2.76442289352417
Validation loss: 1.9330318871364798

Epoch: 6| Step: 13
Training loss: 2.268972396850586
Validation loss: 1.9349550175410446

Epoch: 102| Step: 0
Training loss: 2.0464138984680176
Validation loss: 1.9370401649064914

Epoch: 6| Step: 1
Training loss: 1.1689884662628174
Validation loss: 1.9408974121975642

Epoch: 6| Step: 2
Training loss: 2.375980854034424
Validation loss: 1.9411120619825137

Epoch: 6| Step: 3
Training loss: 2.136714220046997
Validation loss: 1.941347704138807

Epoch: 6| Step: 4
Training loss: 2.493964672088623
Validation loss: 1.927268748642296

Epoch: 6| Step: 5
Training loss: 2.8610458374023438
Validation loss: 1.9426632286399923

Epoch: 6| Step: 6
Training loss: 1.7428594827651978
Validation loss: 1.9366553419379777

Epoch: 6| Step: 7
Training loss: 1.9604191780090332
Validation loss: 1.916561495873236

Epoch: 6| Step: 8
Training loss: 2.0536887645721436
Validation loss: 1.9188121159871419

Epoch: 6| Step: 9
Training loss: 1.9361692667007446
Validation loss: 1.9165918980875323

Epoch: 6| Step: 10
Training loss: 2.093334674835205
Validation loss: 1.921838907785313

Epoch: 6| Step: 11
Training loss: 2.7744240760803223
Validation loss: 1.9280811407232796

Epoch: 6| Step: 12
Training loss: 2.576674222946167
Validation loss: 1.9422128802986556

Epoch: 6| Step: 13
Training loss: 1.8612596988677979
Validation loss: 1.935072099008868

Epoch: 103| Step: 0
Training loss: 1.8520817756652832
Validation loss: 1.9435754552964242

Epoch: 6| Step: 1
Training loss: 2.012382984161377
Validation loss: 1.9440340367696618

Epoch: 6| Step: 2
Training loss: 2.439392566680908
Validation loss: 1.9497350723512712

Epoch: 6| Step: 3
Training loss: 2.8522605895996094
Validation loss: 1.944454090569609

Epoch: 6| Step: 4
Training loss: 2.323606252670288
Validation loss: 1.9421500621303436

Epoch: 6| Step: 5
Training loss: 2.305675745010376
Validation loss: 1.931839696822628

Epoch: 6| Step: 6
Training loss: 1.6520968675613403
Validation loss: 1.9379055961485832

Epoch: 6| Step: 7
Training loss: 1.883290410041809
Validation loss: 1.937613021942877

Epoch: 6| Step: 8
Training loss: 2.270780563354492
Validation loss: 1.94235614679193

Epoch: 6| Step: 9
Training loss: 2.0708889961242676
Validation loss: 1.9455623703618203

Epoch: 6| Step: 10
Training loss: 2.459954023361206
Validation loss: 1.9416733428996096

Epoch: 6| Step: 11
Training loss: 2.446094512939453
Validation loss: 1.9397173132947696

Epoch: 6| Step: 12
Training loss: 1.4985930919647217
Validation loss: 1.9533430901906823

Epoch: 6| Step: 13
Training loss: 1.9599285125732422
Validation loss: 1.9788078992597518

Epoch: 104| Step: 0
Training loss: 2.2874698638916016
Validation loss: 1.960382641002696

Epoch: 6| Step: 1
Training loss: 1.3284149169921875
Validation loss: 1.9331868002491612

Epoch: 6| Step: 2
Training loss: 1.6305427551269531
Validation loss: 1.9147621239385297

Epoch: 6| Step: 3
Training loss: 2.367666721343994
Validation loss: 1.9039019999965545

Epoch: 6| Step: 4
Training loss: 2.5116987228393555
Validation loss: 1.8973325144860052

Epoch: 6| Step: 5
Training loss: 1.676509976387024
Validation loss: 1.8975475834261986

Epoch: 6| Step: 6
Training loss: 2.3211612701416016
Validation loss: 1.8852098808493665

Epoch: 6| Step: 7
Training loss: 2.0460424423217773
Validation loss: 1.8843505241537606

Epoch: 6| Step: 8
Training loss: 1.7897331714630127
Validation loss: 1.890357332844888

Epoch: 6| Step: 9
Training loss: 1.8550729751586914
Validation loss: 1.8978214571552892

Epoch: 6| Step: 10
Training loss: 2.5893468856811523
Validation loss: 1.8982854171465802

Epoch: 6| Step: 11
Training loss: 3.0590524673461914
Validation loss: 1.910708963230092

Epoch: 6| Step: 12
Training loss: 2.4481120109558105
Validation loss: 1.9116663420072166

Epoch: 6| Step: 13
Training loss: 2.2529215812683105
Validation loss: 1.910317567086989

Epoch: 105| Step: 0
Training loss: 1.8727807998657227
Validation loss: 1.9498735320183538

Epoch: 6| Step: 1
Training loss: 2.2416491508483887
Validation loss: 1.932433787212577

Epoch: 6| Step: 2
Training loss: 2.6475627422332764
Validation loss: 1.9537603880769463

Epoch: 6| Step: 3
Training loss: 1.8605093955993652
Validation loss: 1.975907100144253

Epoch: 6| Step: 4
Training loss: 1.9095759391784668
Validation loss: 1.9458853737000497

Epoch: 6| Step: 5
Training loss: 2.154587507247925
Validation loss: 1.9195580021027596

Epoch: 6| Step: 6
Training loss: 2.445420503616333
Validation loss: 1.906126541476096

Epoch: 6| Step: 7
Training loss: 2.402001142501831
Validation loss: 1.8990609389479443

Epoch: 6| Step: 8
Training loss: 1.3679016828536987
Validation loss: 1.9108729054850917

Epoch: 6| Step: 9
Training loss: 2.2760865688323975
Validation loss: 1.926655041274204

Epoch: 6| Step: 10
Training loss: 1.9631178379058838
Validation loss: 1.933298118652836

Epoch: 6| Step: 11
Training loss: 1.8889133930206299
Validation loss: 1.9300999461963613

Epoch: 6| Step: 12
Training loss: 3.216346025466919
Validation loss: 1.916946716206048

Epoch: 6| Step: 13
Training loss: 1.3668971061706543
Validation loss: 1.930797726877274

Epoch: 106| Step: 0
Training loss: 2.3199472427368164
Validation loss: 1.9332041125143729

Epoch: 6| Step: 1
Training loss: 1.4151498079299927
Validation loss: 1.9404799784383466

Epoch: 6| Step: 2
Training loss: 1.5173163414001465
Validation loss: 1.929634145511094

Epoch: 6| Step: 3
Training loss: 2.3456759452819824
Validation loss: 1.9260941654123285

Epoch: 6| Step: 4
Training loss: 1.8430421352386475
Validation loss: 1.900806680802376

Epoch: 6| Step: 5
Training loss: 2.1587891578674316
Validation loss: 1.9065786254021428

Epoch: 6| Step: 6
Training loss: 2.3651697635650635
Validation loss: 1.9052312117750927

Epoch: 6| Step: 7
Training loss: 2.1392741203308105
Validation loss: 1.9069190461148497

Epoch: 6| Step: 8
Training loss: 2.5240612030029297
Validation loss: 1.8936779434962938

Epoch: 6| Step: 9
Training loss: 2.2753329277038574
Validation loss: 1.8996840228316605

Epoch: 6| Step: 10
Training loss: 2.699430465698242
Validation loss: 1.9054638506263815

Epoch: 6| Step: 11
Training loss: 1.7895891666412354
Validation loss: 1.8914484464994041

Epoch: 6| Step: 12
Training loss: 2.2904820442199707
Validation loss: 1.9088331883953464

Epoch: 6| Step: 13
Training loss: 2.2510647773742676
Validation loss: 1.8959686525406376

Epoch: 107| Step: 0
Training loss: 2.19374942779541
Validation loss: 1.8910648745875205

Epoch: 6| Step: 1
Training loss: 1.837159276008606
Validation loss: 1.906103608428791

Epoch: 6| Step: 2
Training loss: 2.695568084716797
Validation loss: 1.905678056901501

Epoch: 6| Step: 3
Training loss: 2.1269757747650146
Validation loss: 1.901410441244802

Epoch: 6| Step: 4
Training loss: 1.6333825588226318
Validation loss: 1.9003701991932367

Epoch: 6| Step: 5
Training loss: 2.4800920486450195
Validation loss: 1.9117730048394972

Epoch: 6| Step: 6
Training loss: 2.6986312866210938
Validation loss: 1.9193796201418805

Epoch: 6| Step: 7
Training loss: 1.352315902709961
Validation loss: 1.9357645255263134

Epoch: 6| Step: 8
Training loss: 2.0238471031188965
Validation loss: 1.9658740887077906

Epoch: 6| Step: 9
Training loss: 1.723389983177185
Validation loss: 1.9522022662624237

Epoch: 6| Step: 10
Training loss: 2.4032957553863525
Validation loss: 1.9508460542207122

Epoch: 6| Step: 11
Training loss: 2.0450363159179688
Validation loss: 1.9508517378120012

Epoch: 6| Step: 12
Training loss: 1.8846721649169922
Validation loss: 1.9306264423554944

Epoch: 6| Step: 13
Training loss: 2.224982738494873
Validation loss: 1.9061374036214684

Epoch: 108| Step: 0
Training loss: 2.5946130752563477
Validation loss: 1.8910460805380216

Epoch: 6| Step: 1
Training loss: 1.9627611637115479
Validation loss: 1.8910641131862518

Epoch: 6| Step: 2
Training loss: 1.7229881286621094
Validation loss: 1.8913534290047103

Epoch: 6| Step: 3
Training loss: 1.4571444988250732
Validation loss: 1.8807783319104103

Epoch: 6| Step: 4
Training loss: 2.364682674407959
Validation loss: 1.8892022448201333

Epoch: 6| Step: 5
Training loss: 2.134345054626465
Validation loss: 1.9100356371172014

Epoch: 6| Step: 6
Training loss: 1.4335005283355713
Validation loss: 1.9162553459085443

Epoch: 6| Step: 7
Training loss: 2.1145973205566406
Validation loss: 1.9117304907050183

Epoch: 6| Step: 8
Training loss: 1.7086083889007568
Validation loss: 1.905896891829788

Epoch: 6| Step: 9
Training loss: 2.788567543029785
Validation loss: 1.9016283788988668

Epoch: 6| Step: 10
Training loss: 2.0892887115478516
Validation loss: 1.897310955550081

Epoch: 6| Step: 11
Training loss: 2.5765624046325684
Validation loss: 1.896771495060254

Epoch: 6| Step: 12
Training loss: 2.081976890563965
Validation loss: 1.9113716130615563

Epoch: 6| Step: 13
Training loss: 2.259233236312866
Validation loss: 1.9063624335873512

Epoch: 109| Step: 0
Training loss: 2.060150384902954
Validation loss: 1.9188403314159763

Epoch: 6| Step: 1
Training loss: 1.644136667251587
Validation loss: 1.9155811148305093

Epoch: 6| Step: 2
Training loss: 2.642108917236328
Validation loss: 1.9066869674190399

Epoch: 6| Step: 3
Training loss: 2.038450241088867
Validation loss: 1.9082396748245403

Epoch: 6| Step: 4
Training loss: 2.336085796356201
Validation loss: 1.9141773549459313

Epoch: 6| Step: 5
Training loss: 2.31632661819458
Validation loss: 1.9598739403550343

Epoch: 6| Step: 6
Training loss: 2.212482452392578
Validation loss: 1.9969987330898162

Epoch: 6| Step: 7
Training loss: 2.9009976387023926
Validation loss: 2.0066316076504287

Epoch: 6| Step: 8
Training loss: 1.8611550331115723
Validation loss: 2.0092462596072944

Epoch: 6| Step: 9
Training loss: 1.6864736080169678
Validation loss: 1.9878834934644802

Epoch: 6| Step: 10
Training loss: 1.6123263835906982
Validation loss: 1.9318962250986407

Epoch: 6| Step: 11
Training loss: 2.040428400039673
Validation loss: 1.936626995763471

Epoch: 6| Step: 12
Training loss: 2.1217193603515625
Validation loss: 1.9468300496378252

Epoch: 6| Step: 13
Training loss: 1.9004590511322021
Validation loss: 1.945138685164913

Epoch: 110| Step: 0
Training loss: 1.8664374351501465
Validation loss: 1.9206976044562556

Epoch: 6| Step: 1
Training loss: 1.6090314388275146
Validation loss: 1.9076145092646282

Epoch: 6| Step: 2
Training loss: 1.7938264608383179
Validation loss: 1.8976120666791034

Epoch: 6| Step: 3
Training loss: 1.770185112953186
Validation loss: 1.8922712572159306

Epoch: 6| Step: 4
Training loss: 2.2460076808929443
Validation loss: 1.9159773934272029

Epoch: 6| Step: 5
Training loss: 2.440218687057495
Validation loss: 1.9451839513676141

Epoch: 6| Step: 6
Training loss: 1.8535327911376953
Validation loss: 1.9618113425470167

Epoch: 6| Step: 7
Training loss: 2.6523337364196777
Validation loss: 1.9642409919410624

Epoch: 6| Step: 8
Training loss: 2.5346364974975586
Validation loss: 1.9527466758604972

Epoch: 6| Step: 9
Training loss: 2.3777034282684326
Validation loss: 1.941657385518474

Epoch: 6| Step: 10
Training loss: 2.371461868286133
Validation loss: 1.913387026838077

Epoch: 6| Step: 11
Training loss: 1.9799602031707764
Validation loss: 1.898996599258915

Epoch: 6| Step: 12
Training loss: 2.1291775703430176
Validation loss: 1.890019839809787

Epoch: 6| Step: 13
Training loss: 1.6719956398010254
Validation loss: 1.9043516958913496

Epoch: 111| Step: 0
Training loss: 2.974057912826538
Validation loss: 1.8974153880150086

Epoch: 6| Step: 1
Training loss: 2.1648101806640625
Validation loss: 1.9171323084062146

Epoch: 6| Step: 2
Training loss: 1.8415799140930176
Validation loss: 1.9292828575257333

Epoch: 6| Step: 3
Training loss: 1.659524917602539
Validation loss: 1.9264615222971926

Epoch: 6| Step: 4
Training loss: 1.6332428455352783
Validation loss: 1.9484608314370597

Epoch: 6| Step: 5
Training loss: 1.685512661933899
Validation loss: 1.9396618476478003

Epoch: 6| Step: 6
Training loss: 2.1344432830810547
Validation loss: 1.957135497882802

Epoch: 6| Step: 7
Training loss: 1.6915762424468994
Validation loss: 1.963099689893825

Epoch: 6| Step: 8
Training loss: 2.582307815551758
Validation loss: 1.9404606114151657

Epoch: 6| Step: 9
Training loss: 2.478140354156494
Validation loss: 1.9200984393396685

Epoch: 6| Step: 10
Training loss: 1.8326510190963745
Validation loss: 1.8951745930538382

Epoch: 6| Step: 11
Training loss: 2.434131622314453
Validation loss: 1.8964901431914298

Epoch: 6| Step: 12
Training loss: 2.1889617443084717
Validation loss: 1.9013430418506745

Epoch: 6| Step: 13
Training loss: 2.2249999046325684
Validation loss: 1.8904054241795694

Epoch: 112| Step: 0
Training loss: 1.254538893699646
Validation loss: 1.8865018698476976

Epoch: 6| Step: 1
Training loss: 2.167898416519165
Validation loss: 1.8843364959122033

Epoch: 6| Step: 2
Training loss: 2.347792625427246
Validation loss: 1.8968546621261104

Epoch: 6| Step: 3
Training loss: 2.086672782897949
Validation loss: 1.898202383390037

Epoch: 6| Step: 4
Training loss: 1.817240834236145
Validation loss: 1.9235229876733595

Epoch: 6| Step: 5
Training loss: 1.6850497722625732
Validation loss: 1.9420515093752133

Epoch: 6| Step: 6
Training loss: 2.403259754180908
Validation loss: 1.930838183690143

Epoch: 6| Step: 7
Training loss: 2.0983119010925293
Validation loss: 1.9383396499900407

Epoch: 6| Step: 8
Training loss: 1.9581642150878906
Validation loss: 1.9542430959722048

Epoch: 6| Step: 9
Training loss: 2.2168521881103516
Validation loss: 1.9419332063326271

Epoch: 6| Step: 10
Training loss: 2.2701735496520996
Validation loss: 1.9619694320104455

Epoch: 6| Step: 11
Training loss: 2.2594637870788574
Validation loss: 1.949578792818131

Epoch: 6| Step: 12
Training loss: 2.582872152328491
Validation loss: 1.898382713717799

Epoch: 6| Step: 13
Training loss: 1.6386637687683105
Validation loss: 1.8930642297191005

Epoch: 113| Step: 0
Training loss: 1.485785961151123
Validation loss: 1.872340500995677

Epoch: 6| Step: 1
Training loss: 1.937772512435913
Validation loss: 1.8870476189480032

Epoch: 6| Step: 2
Training loss: 1.3238530158996582
Validation loss: 1.90285962371416

Epoch: 6| Step: 3
Training loss: 2.143364906311035
Validation loss: 1.9150967328779158

Epoch: 6| Step: 4
Training loss: 2.821692943572998
Validation loss: 1.9212382737026419

Epoch: 6| Step: 5
Training loss: 1.6126821041107178
Validation loss: 1.9204928964696906

Epoch: 6| Step: 6
Training loss: 2.252556324005127
Validation loss: 1.955401110392745

Epoch: 6| Step: 7
Training loss: 2.103455066680908
Validation loss: 1.940012590859526

Epoch: 6| Step: 8
Training loss: 1.489600658416748
Validation loss: 1.922148919874622

Epoch: 6| Step: 9
Training loss: 2.47544002532959
Validation loss: 1.8793326872651295

Epoch: 6| Step: 10
Training loss: 3.1338484287261963
Validation loss: 1.8769615157958

Epoch: 6| Step: 11
Training loss: 2.0585570335388184
Validation loss: 1.881099998310048

Epoch: 6| Step: 12
Training loss: 2.163003921508789
Validation loss: 1.9308194204043316

Epoch: 6| Step: 13
Training loss: 2.6575114727020264
Validation loss: 2.0072332479620494

Epoch: 114| Step: 0
Training loss: 2.0696582794189453
Validation loss: 2.061971059409521

Epoch: 6| Step: 1
Training loss: 1.5134892463684082
Validation loss: 2.105023084148284

Epoch: 6| Step: 2
Training loss: 2.0305392742156982
Validation loss: 2.0657956933462494

Epoch: 6| Step: 3
Training loss: 2.055072546005249
Validation loss: 1.9261220296223958

Epoch: 6| Step: 4
Training loss: 1.6417899131774902
Validation loss: 1.8387974821111208

Epoch: 6| Step: 5
Training loss: 2.5358963012695312
Validation loss: 1.885136660709176

Epoch: 6| Step: 6
Training loss: 2.0107624530792236
Validation loss: 1.9250200692043509

Epoch: 6| Step: 7
Training loss: 3.605504035949707
Validation loss: 1.9215361533626434

Epoch: 6| Step: 8
Training loss: 1.966031789779663
Validation loss: 1.9312869592379498

Epoch: 6| Step: 9
Training loss: 2.5918116569519043
Validation loss: 1.9311850775954544

Epoch: 6| Step: 10
Training loss: 2.2513813972473145
Validation loss: 1.9227468852073915

Epoch: 6| Step: 11
Training loss: 1.7970085144042969
Validation loss: 1.875153136509721

Epoch: 6| Step: 12
Training loss: 1.7570667266845703
Validation loss: 1.8519807041332286

Epoch: 6| Step: 13
Training loss: 3.023617744445801
Validation loss: 1.871334578401299

Epoch: 115| Step: 0
Training loss: 1.7029447555541992
Validation loss: 1.8905797004699707

Epoch: 6| Step: 1
Training loss: 2.102665424346924
Validation loss: 1.923817466664058

Epoch: 6| Step: 2
Training loss: 3.055128574371338
Validation loss: 1.9090148377162155

Epoch: 6| Step: 3
Training loss: 2.3498120307922363
Validation loss: 1.9229521905222247

Epoch: 6| Step: 4
Training loss: 2.328840732574463
Validation loss: 1.9309180103322512

Epoch: 6| Step: 5
Training loss: 1.6373544931411743
Validation loss: 1.9094497285863405

Epoch: 6| Step: 6
Training loss: 2.2488088607788086
Validation loss: 1.8998771175261466

Epoch: 6| Step: 7
Training loss: 1.8134937286376953
Validation loss: 1.89132797333502

Epoch: 6| Step: 8
Training loss: 2.4563965797424316
Validation loss: 1.902288625317235

Epoch: 6| Step: 9
Training loss: 1.9880138635635376
Validation loss: 1.8989808277417255

Epoch: 6| Step: 10
Training loss: 1.9630801677703857
Validation loss: 1.9149598152406755

Epoch: 6| Step: 11
Training loss: 2.3381500244140625
Validation loss: 1.9268980667155275

Epoch: 6| Step: 12
Training loss: 1.9874606132507324
Validation loss: 1.901831699955848

Epoch: 6| Step: 13
Training loss: 1.5834527015686035
Validation loss: 1.9026604365277033

Epoch: 116| Step: 0
Training loss: 1.8105639219284058
Validation loss: 1.8897362793645551

Epoch: 6| Step: 1
Training loss: 1.7085106372833252
Validation loss: 1.9003791155353669

Epoch: 6| Step: 2
Training loss: 2.0650320053100586
Validation loss: 1.9260951985595047

Epoch: 6| Step: 3
Training loss: 2.153942108154297
Validation loss: 1.9450954942293064

Epoch: 6| Step: 4
Training loss: 2.3840084075927734
Validation loss: 1.9766044309062343

Epoch: 6| Step: 5
Training loss: 1.6650950908660889
Validation loss: 1.9630013255662815

Epoch: 6| Step: 6
Training loss: 1.5832734107971191
Validation loss: 1.937580785443706

Epoch: 6| Step: 7
Training loss: 2.44447660446167
Validation loss: 1.9448776001571326

Epoch: 6| Step: 8
Training loss: 2.1647238731384277
Validation loss: 1.9386733783188688

Epoch: 6| Step: 9
Training loss: 2.3822431564331055
Validation loss: 1.9191606006314677

Epoch: 6| Step: 10
Training loss: 1.5781692266464233
Validation loss: 1.8946917621038293

Epoch: 6| Step: 11
Training loss: 2.9813623428344727
Validation loss: 1.8491668752444688

Epoch: 6| Step: 12
Training loss: 2.4540863037109375
Validation loss: 1.84714420892859

Epoch: 6| Step: 13
Training loss: 1.5542877912521362
Validation loss: 1.8635899289961784

Epoch: 117| Step: 0
Training loss: 1.9543671607971191
Validation loss: 1.888150143366988

Epoch: 6| Step: 1
Training loss: 2.746854066848755
Validation loss: 1.9290044602527414

Epoch: 6| Step: 2
Training loss: 2.2309370040893555
Validation loss: 1.9332090885408464

Epoch: 6| Step: 3
Training loss: 1.9565180540084839
Validation loss: 1.930626493628307

Epoch: 6| Step: 4
Training loss: 2.249777317047119
Validation loss: 1.9453282958717757

Epoch: 6| Step: 5
Training loss: 1.8344415426254272
Validation loss: 1.9002435745731476

Epoch: 6| Step: 6
Training loss: 1.9750704765319824
Validation loss: 1.8776503929527857

Epoch: 6| Step: 7
Training loss: 1.570615291595459
Validation loss: 1.8710682289574736

Epoch: 6| Step: 8
Training loss: 2.289121389389038
Validation loss: 1.871847971793144

Epoch: 6| Step: 9
Training loss: 2.6194920539855957
Validation loss: 1.8877208655880344

Epoch: 6| Step: 10
Training loss: 1.6992592811584473
Validation loss: 1.9138966170690392

Epoch: 6| Step: 11
Training loss: 1.9556047916412354
Validation loss: 1.925956791447055

Epoch: 6| Step: 12
Training loss: 1.8701088428497314
Validation loss: 1.9302478887701546

Epoch: 6| Step: 13
Training loss: 1.5842102766036987
Validation loss: 1.9386539446410311

Epoch: 118| Step: 0
Training loss: 1.6793116331100464
Validation loss: 1.9211773744193457

Epoch: 6| Step: 1
Training loss: 2.229027032852173
Validation loss: 1.906374845453488

Epoch: 6| Step: 2
Training loss: 1.9620771408081055
Validation loss: 1.8846583417666856

Epoch: 6| Step: 3
Training loss: 2.808755397796631
Validation loss: 1.8670916454766386

Epoch: 6| Step: 4
Training loss: 1.8814750909805298
Validation loss: 1.8768081972675938

Epoch: 6| Step: 5
Training loss: 2.031033992767334
Validation loss: 1.886321501065326

Epoch: 6| Step: 6
Training loss: 2.1965954303741455
Validation loss: 1.9196586865250782

Epoch: 6| Step: 7
Training loss: 1.9613311290740967
Validation loss: 1.9383824307431456

Epoch: 6| Step: 8
Training loss: 2.433213710784912
Validation loss: 1.9415836539319766

Epoch: 6| Step: 9
Training loss: 1.6759581565856934
Validation loss: 1.91889968738761

Epoch: 6| Step: 10
Training loss: 1.798672080039978
Validation loss: 1.8940017095176123

Epoch: 6| Step: 11
Training loss: 2.476433515548706
Validation loss: 1.8852117446161085

Epoch: 6| Step: 12
Training loss: 1.7661702632904053
Validation loss: 1.8797959332825036

Epoch: 6| Step: 13
Training loss: 2.2029221057891846
Validation loss: 1.873858380061324

Epoch: 119| Step: 0
Training loss: 2.4622018337249756
Validation loss: 1.9066148560534242

Epoch: 6| Step: 1
Training loss: 1.9283645153045654
Validation loss: 1.911211532931174

Epoch: 6| Step: 2
Training loss: 1.7440651655197144
Validation loss: 1.934237644236575

Epoch: 6| Step: 3
Training loss: 2.109553098678589
Validation loss: 1.965708339086143

Epoch: 6| Step: 4
Training loss: 2.897226333618164
Validation loss: 1.9688754902091077

Epoch: 6| Step: 5
Training loss: 1.9417870044708252
Validation loss: 1.9619422830561155

Epoch: 6| Step: 6
Training loss: 2.318854808807373
Validation loss: 1.9454383183551092

Epoch: 6| Step: 7
Training loss: 1.9276758432388306
Validation loss: 1.9377921089049308

Epoch: 6| Step: 8
Training loss: 2.597217559814453
Validation loss: 1.9184526243517477

Epoch: 6| Step: 9
Training loss: 1.4009679555892944
Validation loss: 1.9612370511536956

Epoch: 6| Step: 10
Training loss: 1.7678332328796387
Validation loss: 1.9955256344169698

Epoch: 6| Step: 11
Training loss: 1.6155223846435547
Validation loss: 2.0298969694363174

Epoch: 6| Step: 12
Training loss: 2.4456963539123535
Validation loss: 2.024587833753196

Epoch: 6| Step: 13
Training loss: 1.5445351600646973
Validation loss: 1.9827903060502903

Epoch: 120| Step: 0
Training loss: 1.1468586921691895
Validation loss: 1.943452060863536

Epoch: 6| Step: 1
Training loss: 2.1906216144561768
Validation loss: 1.9147595282523864

Epoch: 6| Step: 2
Training loss: 2.050379753112793
Validation loss: 1.9272075032675138

Epoch: 6| Step: 3
Training loss: 1.9923440217971802
Validation loss: 1.9229664623096425

Epoch: 6| Step: 4
Training loss: 1.910278558731079
Validation loss: 1.9130901469979236

Epoch: 6| Step: 5
Training loss: 2.1800103187561035
Validation loss: 1.9202272866361885

Epoch: 6| Step: 6
Training loss: 1.5188757181167603
Validation loss: 1.9238657079717165

Epoch: 6| Step: 7
Training loss: 2.1898353099823
Validation loss: 1.8991300867449852

Epoch: 6| Step: 8
Training loss: 1.839341163635254
Validation loss: 1.8812400307706607

Epoch: 6| Step: 9
Training loss: 2.844269275665283
Validation loss: 1.860055726061585

Epoch: 6| Step: 10
Training loss: 2.390061855316162
Validation loss: 1.8579532830945906

Epoch: 6| Step: 11
Training loss: 2.3247017860412598
Validation loss: 1.8616002849353257

Epoch: 6| Step: 12
Training loss: 1.939109206199646
Validation loss: 1.8676003884243708

Epoch: 6| Step: 13
Training loss: 1.90427565574646
Validation loss: 1.8952002820148264

Epoch: 121| Step: 0
Training loss: 1.8230206966400146
Validation loss: 1.8841826351740028

Epoch: 6| Step: 1
Training loss: 2.267970085144043
Validation loss: 1.8901123154547907

Epoch: 6| Step: 2
Training loss: 1.6910135746002197
Validation loss: 1.880371262950282

Epoch: 6| Step: 3
Training loss: 1.6235229969024658
Validation loss: 1.8830572379532682

Epoch: 6| Step: 4
Training loss: 2.699214458465576
Validation loss: 1.8754191424257012

Epoch: 6| Step: 5
Training loss: 1.9442218542099
Validation loss: 1.8701255488139328

Epoch: 6| Step: 6
Training loss: 2.320584774017334
Validation loss: 1.8676298485007337

Epoch: 6| Step: 7
Training loss: 2.3382697105407715
Validation loss: 1.868328453392111

Epoch: 6| Step: 8
Training loss: 2.036097288131714
Validation loss: 1.885555172479281

Epoch: 6| Step: 9
Training loss: 2.4003190994262695
Validation loss: 1.893189500736934

Epoch: 6| Step: 10
Training loss: 2.0907487869262695
Validation loss: 1.9131846248462636

Epoch: 6| Step: 11
Training loss: 1.2069509029388428
Validation loss: 1.9100455366155153

Epoch: 6| Step: 12
Training loss: 1.921247959136963
Validation loss: 1.9031935276523713

Epoch: 6| Step: 13
Training loss: 2.5294642448425293
Validation loss: 1.8996524528790546

Epoch: 122| Step: 0
Training loss: 1.2850925922393799
Validation loss: 1.9016909009666854

Epoch: 6| Step: 1
Training loss: 1.4336540699005127
Validation loss: 1.9199427545711558

Epoch: 6| Step: 2
Training loss: 2.282132625579834
Validation loss: 1.9171622286560714

Epoch: 6| Step: 3
Training loss: 2.0937013626098633
Validation loss: 1.9232569010026994

Epoch: 6| Step: 4
Training loss: 2.2622642517089844
Validation loss: 1.9379794020806589

Epoch: 6| Step: 5
Training loss: 1.5844343900680542
Validation loss: 1.9320286858466365

Epoch: 6| Step: 6
Training loss: 1.8697829246520996
Validation loss: 1.9205065363196916

Epoch: 6| Step: 7
Training loss: 2.4352331161499023
Validation loss: 1.922992919081001

Epoch: 6| Step: 8
Training loss: 2.67851185798645
Validation loss: 1.8890951295052805

Epoch: 6| Step: 9
Training loss: 2.7842628955841064
Validation loss: 1.8703273957775486

Epoch: 6| Step: 10
Training loss: 2.2265517711639404
Validation loss: 1.880339914752591

Epoch: 6| Step: 11
Training loss: 1.6985936164855957
Validation loss: 1.872557270911432

Epoch: 6| Step: 12
Training loss: 2.050185203552246
Validation loss: 1.8754334270313222

Epoch: 6| Step: 13
Training loss: 1.0904301404953003
Validation loss: 1.863584856833181

Epoch: 123| Step: 0
Training loss: 1.6311278343200684
Validation loss: 1.8385244249015726

Epoch: 6| Step: 1
Training loss: 2.371277093887329
Validation loss: 1.8473358692661408

Epoch: 6| Step: 2
Training loss: 1.9495253562927246
Validation loss: 1.8874998169560586

Epoch: 6| Step: 3
Training loss: 2.2412009239196777
Validation loss: 1.913858490605508

Epoch: 6| Step: 4
Training loss: 1.8271092176437378
Validation loss: 2.00381560479441

Epoch: 6| Step: 5
Training loss: 1.7501918077468872
Validation loss: 2.042069015964385

Epoch: 6| Step: 6
Training loss: 2.2707371711730957
Validation loss: 2.0003609657287598

Epoch: 6| Step: 7
Training loss: 2.041550874710083
Validation loss: 1.9835119747346448

Epoch: 6| Step: 8
Training loss: 2.8357961177825928
Validation loss: 1.9501304357282576

Epoch: 6| Step: 9
Training loss: 2.2208011150360107
Validation loss: 1.9522485092122068

Epoch: 6| Step: 10
Training loss: 2.1455445289611816
Validation loss: 1.9537071233154626

Epoch: 6| Step: 11
Training loss: 2.703120231628418
Validation loss: 1.9453933597892843

Epoch: 6| Step: 12
Training loss: 1.5210864543914795
Validation loss: 1.912558667121395

Epoch: 6| Step: 13
Training loss: 1.2424994707107544
Validation loss: 1.8743087027662544

Epoch: 124| Step: 0
Training loss: 2.500190019607544
Validation loss: 1.8655454061364616

Epoch: 6| Step: 1
Training loss: 2.4638113975524902
Validation loss: 1.9099372368986889

Epoch: 6| Step: 2
Training loss: 1.710366129875183
Validation loss: 1.9422691522106048

Epoch: 6| Step: 3
Training loss: 2.1911368370056152
Validation loss: 1.9592300935458111

Epoch: 6| Step: 4
Training loss: 2.840442657470703
Validation loss: 1.9897106898728238

Epoch: 6| Step: 5
Training loss: 2.0715348720550537
Validation loss: 1.9906557093384445

Epoch: 6| Step: 6
Training loss: 1.8568685054779053
Validation loss: 1.9834779385597474

Epoch: 6| Step: 7
Training loss: 2.3231587409973145
Validation loss: 1.9682365578989829

Epoch: 6| Step: 8
Training loss: 1.608295202255249
Validation loss: 1.9359956595205492

Epoch: 6| Step: 9
Training loss: 2.122621536254883
Validation loss: 1.9013298660196283

Epoch: 6| Step: 10
Training loss: 2.207108497619629
Validation loss: 1.924795396866337

Epoch: 6| Step: 11
Training loss: 1.7252697944641113
Validation loss: 1.9021952382979854

Epoch: 6| Step: 12
Training loss: 1.58384370803833
Validation loss: 1.8909211953481038

Epoch: 6| Step: 13
Training loss: 1.8521902561187744
Validation loss: 1.8819490171247912

Epoch: 125| Step: 0
Training loss: 2.1810407638549805
Validation loss: 1.8988023906625726

Epoch: 6| Step: 1
Training loss: 2.337675094604492
Validation loss: 1.9155540543217813

Epoch: 6| Step: 2
Training loss: 1.951692819595337
Validation loss: 1.9682721527673865

Epoch: 6| Step: 3
Training loss: 1.880840539932251
Validation loss: 1.9786620255439513

Epoch: 6| Step: 4
Training loss: 2.1453638076782227
Validation loss: 2.007724674799109

Epoch: 6| Step: 5
Training loss: 1.9911272525787354
Validation loss: 2.0075536415141118

Epoch: 6| Step: 6
Training loss: 2.4380974769592285
Validation loss: 2.013433176984069

Epoch: 6| Step: 7
Training loss: 2.07102108001709
Validation loss: 2.0010662540312736

Epoch: 6| Step: 8
Training loss: 2.177347183227539
Validation loss: 1.9834427859193535

Epoch: 6| Step: 9
Training loss: 2.3314268589019775
Validation loss: 1.966550419407506

Epoch: 6| Step: 10
Training loss: 1.3628439903259277
Validation loss: 1.9515992544030631

Epoch: 6| Step: 11
Training loss: 1.7900135517120361
Validation loss: 1.9836577548775622

Epoch: 6| Step: 12
Training loss: 2.203951358795166
Validation loss: 2.008749443997619

Epoch: 6| Step: 13
Training loss: 1.942176342010498
Validation loss: 1.988041780328238

Epoch: 126| Step: 0
Training loss: 2.3331217765808105
Validation loss: 1.9126025963855047

Epoch: 6| Step: 1
Training loss: 2.586660146713257
Validation loss: 1.8829438224915536

Epoch: 6| Step: 2
Training loss: 1.7142733335494995
Validation loss: 1.8975587480811662

Epoch: 6| Step: 3
Training loss: 2.3398776054382324
Validation loss: 1.9236197586982482

Epoch: 6| Step: 4
Training loss: 2.3809049129486084
Validation loss: 1.947824232039913

Epoch: 6| Step: 5
Training loss: 1.9645836353302002
Validation loss: 1.9542334374561106

Epoch: 6| Step: 6
Training loss: 1.7012931108474731
Validation loss: 1.94860581685138

Epoch: 6| Step: 7
Training loss: 2.232602834701538
Validation loss: 1.9254736310692244

Epoch: 6| Step: 8
Training loss: 2.016178846359253
Validation loss: 1.9035704828077746

Epoch: 6| Step: 9
Training loss: 2.124070644378662
Validation loss: 1.8963392934491556

Epoch: 6| Step: 10
Training loss: 2.5986874103546143
Validation loss: 1.8940906165748514

Epoch: 6| Step: 11
Training loss: 0.9652162194252014
Validation loss: 1.900330812700333

Epoch: 6| Step: 12
Training loss: 1.9714850187301636
Validation loss: 1.9150884382186397

Epoch: 6| Step: 13
Training loss: 1.3706191778182983
Validation loss: 1.981330563945155

Epoch: 127| Step: 0
Training loss: 2.596417188644409
Validation loss: 2.0133635754226358

Epoch: 6| Step: 1
Training loss: 1.9549634456634521
Validation loss: 2.0568535840639504

Epoch: 6| Step: 2
Training loss: 1.9537980556488037
Validation loss: 2.061235112528647

Epoch: 6| Step: 3
Training loss: 2.2628259658813477
Validation loss: 1.9929706076140046

Epoch: 6| Step: 4
Training loss: 1.689409852027893
Validation loss: 1.9144737002670125

Epoch: 6| Step: 5
Training loss: 2.7149574756622314
Validation loss: 1.8905793928330945

Epoch: 6| Step: 6
Training loss: 1.5289273262023926
Validation loss: 1.8766904710441508

Epoch: 6| Step: 7
Training loss: 2.7693984508514404
Validation loss: 1.8826701307809481

Epoch: 6| Step: 8
Training loss: 1.4710397720336914
Validation loss: 1.882264414141255

Epoch: 6| Step: 9
Training loss: 1.9356998205184937
Validation loss: 1.8818958856726204

Epoch: 6| Step: 10
Training loss: 2.1642608642578125
Validation loss: 1.8725796848215082

Epoch: 6| Step: 11
Training loss: 1.7603940963745117
Validation loss: 1.8672705799020746

Epoch: 6| Step: 12
Training loss: 1.7084460258483887
Validation loss: 1.8611309887260519

Epoch: 6| Step: 13
Training loss: 1.9963003396987915
Validation loss: 1.8633914916746077

Epoch: 128| Step: 0
Training loss: 1.8035759925842285
Validation loss: 1.8733641998742216

Epoch: 6| Step: 1
Training loss: 2.418135643005371
Validation loss: 1.8487249023170882

Epoch: 6| Step: 2
Training loss: 1.9409949779510498
Validation loss: 1.8530293920988679

Epoch: 6| Step: 3
Training loss: 2.0103578567504883
Validation loss: 1.8412086156106764

Epoch: 6| Step: 4
Training loss: 1.7179116010665894
Validation loss: 1.847341678475821

Epoch: 6| Step: 5
Training loss: 1.8902714252471924
Validation loss: 1.8491379061052877

Epoch: 6| Step: 6
Training loss: 2.549640655517578
Validation loss: 1.8431148721325783

Epoch: 6| Step: 7
Training loss: 2.195869207382202
Validation loss: 1.8585040902578702

Epoch: 6| Step: 8
Training loss: 1.4913535118103027
Validation loss: 1.8488925862055954

Epoch: 6| Step: 9
Training loss: 1.8109493255615234
Validation loss: 1.8703619587805964

Epoch: 6| Step: 10
Training loss: 2.0703632831573486
Validation loss: 1.850550187531338

Epoch: 6| Step: 11
Training loss: 2.157820701599121
Validation loss: 1.8688127879173524

Epoch: 6| Step: 12
Training loss: 1.7052764892578125
Validation loss: 1.8662745721878544

Epoch: 6| Step: 13
Training loss: 2.1520206928253174
Validation loss: 1.8682135984461794

Epoch: 129| Step: 0
Training loss: 2.2049031257629395
Validation loss: 1.8789365368504678

Epoch: 6| Step: 1
Training loss: 2.22088360786438
Validation loss: 1.8981982738740983

Epoch: 6| Step: 2
Training loss: 2.0229625701904297
Validation loss: 1.890673473317136

Epoch: 6| Step: 3
Training loss: 1.5224552154541016
Validation loss: 1.9081065936755108

Epoch: 6| Step: 4
Training loss: 1.8724805116653442
Validation loss: 1.904889182377887

Epoch: 6| Step: 5
Training loss: 2.548799514770508
Validation loss: 1.9089199202035063

Epoch: 6| Step: 6
Training loss: 1.7671170234680176
Validation loss: 1.8747137823412496

Epoch: 6| Step: 7
Training loss: 1.495469331741333
Validation loss: 1.876838562309101

Epoch: 6| Step: 8
Training loss: 1.211714506149292
Validation loss: 1.860891697227314

Epoch: 6| Step: 9
Training loss: 2.2514100074768066
Validation loss: 1.8552729134918542

Epoch: 6| Step: 10
Training loss: 1.6676417589187622
Validation loss: 1.851370919135309

Epoch: 6| Step: 11
Training loss: 2.145418167114258
Validation loss: 1.8710185891838484

Epoch: 6| Step: 12
Training loss: 2.324522018432617
Validation loss: 1.8635759315183085

Epoch: 6| Step: 13
Training loss: 2.1868371963500977
Validation loss: 1.8722760638883036

Epoch: 130| Step: 0
Training loss: 1.9809046983718872
Validation loss: 1.8880074665110598

Epoch: 6| Step: 1
Training loss: 1.1830006837844849
Validation loss: 1.8660905002265848

Epoch: 6| Step: 2
Training loss: 2.2549853324890137
Validation loss: 1.8681215445200603

Epoch: 6| Step: 3
Training loss: 2.0223517417907715
Validation loss: 1.8828883632536857

Epoch: 6| Step: 4
Training loss: 1.7731927633285522
Validation loss: 1.8836489544119885

Epoch: 6| Step: 5
Training loss: 1.986128807067871
Validation loss: 1.8946630800923994

Epoch: 6| Step: 6
Training loss: 2.0453596115112305
Validation loss: 1.9091399895247592

Epoch: 6| Step: 7
Training loss: 2.1658754348754883
Validation loss: 1.9373698644740607

Epoch: 6| Step: 8
Training loss: 1.5458509922027588
Validation loss: 1.9186017423547723

Epoch: 6| Step: 9
Training loss: 2.4656364917755127
Validation loss: 1.9208046749073973

Epoch: 6| Step: 10
Training loss: 2.3031749725341797
Validation loss: 1.9032946991664108

Epoch: 6| Step: 11
Training loss: 2.5126564502716064
Validation loss: 1.919752432454017

Epoch: 6| Step: 12
Training loss: 1.9640696048736572
Validation loss: 1.9343119334149104

Epoch: 6| Step: 13
Training loss: 0.9670470356941223
Validation loss: 1.9116259480035434

Epoch: 131| Step: 0
Training loss: 2.0242929458618164
Validation loss: 1.9104087275843467

Epoch: 6| Step: 1
Training loss: 1.6830271482467651
Validation loss: 1.8764524382929648

Epoch: 6| Step: 2
Training loss: 1.2329425811767578
Validation loss: 1.8705958422794138

Epoch: 6| Step: 3
Training loss: 2.04168701171875
Validation loss: 1.8899229367574055

Epoch: 6| Step: 4
Training loss: 2.0318846702575684
Validation loss: 1.9431852589371383

Epoch: 6| Step: 5
Training loss: 2.368844747543335
Validation loss: 1.9655655814755348

Epoch: 6| Step: 6
Training loss: 1.9433735609054565
Validation loss: 1.9949535092999857

Epoch: 6| Step: 7
Training loss: 1.6616352796554565
Validation loss: 2.0257845437654884

Epoch: 6| Step: 8
Training loss: 1.715788722038269
Validation loss: 1.9966201218225623

Epoch: 6| Step: 9
Training loss: 2.0093507766723633
Validation loss: 1.9630005372467862

Epoch: 6| Step: 10
Training loss: 1.9581116437911987
Validation loss: 1.8905208905537922

Epoch: 6| Step: 11
Training loss: 2.2677431106567383
Validation loss: 1.921995247564008

Epoch: 6| Step: 12
Training loss: 2.5521068572998047
Validation loss: 1.926881310760334

Epoch: 6| Step: 13
Training loss: 2.3584091663360596
Validation loss: 1.922040295857255

Epoch: 132| Step: 0
Training loss: 2.071939706802368
Validation loss: 1.9715034064426218

Epoch: 6| Step: 1
Training loss: 2.119758367538452
Validation loss: 2.0017920924771215

Epoch: 6| Step: 2
Training loss: 2.4584405422210693
Validation loss: 1.9927421180150842

Epoch: 6| Step: 3
Training loss: 2.60200834274292
Validation loss: 1.975110016843324

Epoch: 6| Step: 4
Training loss: 2.1834704875946045
Validation loss: 1.9446624825077672

Epoch: 6| Step: 5
Training loss: 1.908775806427002
Validation loss: 1.8776601899054743

Epoch: 6| Step: 6
Training loss: 1.5400629043579102
Validation loss: 1.8719998085370628

Epoch: 6| Step: 7
Training loss: 1.4195303916931152
Validation loss: 1.9239709864380539

Epoch: 6| Step: 8
Training loss: 2.265613079071045
Validation loss: 1.938853697110248

Epoch: 6| Step: 9
Training loss: 1.8045328855514526
Validation loss: 1.9577088676473147

Epoch: 6| Step: 10
Training loss: 2.6342053413391113
Validation loss: 1.968958334256244

Epoch: 6| Step: 11
Training loss: 1.3859686851501465
Validation loss: 1.940256235420063

Epoch: 6| Step: 12
Training loss: 1.9567742347717285
Validation loss: 1.9276932067768549

Epoch: 6| Step: 13
Training loss: 2.47430157661438
Validation loss: 1.936960752292346

Epoch: 133| Step: 0
Training loss: 1.8209317922592163
Validation loss: 1.9413264746307044

Epoch: 6| Step: 1
Training loss: 2.033815383911133
Validation loss: 1.943957257014449

Epoch: 6| Step: 2
Training loss: 1.386728048324585
Validation loss: 1.9392383983058314

Epoch: 6| Step: 3
Training loss: 1.9758954048156738
Validation loss: 1.9305332386365501

Epoch: 6| Step: 4
Training loss: 2.389963150024414
Validation loss: 1.9197265358381375

Epoch: 6| Step: 5
Training loss: 2.1186060905456543
Validation loss: 1.9013819181790916

Epoch: 6| Step: 6
Training loss: 1.4634144306182861
Validation loss: 1.8784161383105862

Epoch: 6| Step: 7
Training loss: 1.5737595558166504
Validation loss: 1.8508470404532649

Epoch: 6| Step: 8
Training loss: 2.459867477416992
Validation loss: 1.8314197012173232

Epoch: 6| Step: 9
Training loss: 2.5516085624694824
Validation loss: 1.826506140411541

Epoch: 6| Step: 10
Training loss: 2.4520938396453857
Validation loss: 1.844076600126041

Epoch: 6| Step: 11
Training loss: 1.37514328956604
Validation loss: 1.8438547913746168

Epoch: 6| Step: 12
Training loss: 2.0392098426818848
Validation loss: 1.832540012175037

Epoch: 6| Step: 13
Training loss: 2.190971612930298
Validation loss: 1.825502461002719

Epoch: 134| Step: 0
Training loss: 2.21169376373291
Validation loss: 1.8304697518707604

Epoch: 6| Step: 1
Training loss: 2.854165554046631
Validation loss: 1.8261862954785746

Epoch: 6| Step: 2
Training loss: 1.4991226196289062
Validation loss: 1.84538189313745

Epoch: 6| Step: 3
Training loss: 1.9237279891967773
Validation loss: 1.8674970801158617

Epoch: 6| Step: 4
Training loss: 2.529954195022583
Validation loss: 1.8858649012862996

Epoch: 6| Step: 5
Training loss: 1.1854885816574097
Validation loss: 1.915608803431193

Epoch: 6| Step: 6
Training loss: 1.851050615310669
Validation loss: 1.9115147693182832

Epoch: 6| Step: 7
Training loss: 1.6608927249908447
Validation loss: 1.88732272835188

Epoch: 6| Step: 8
Training loss: 1.8590565919876099
Validation loss: 1.8684163580658615

Epoch: 6| Step: 9
Training loss: 1.257156491279602
Validation loss: 1.8764199672206756

Epoch: 6| Step: 10
Training loss: 1.674207091331482
Validation loss: 1.8856422811426141

Epoch: 6| Step: 11
Training loss: 2.7162363529205322
Validation loss: 1.8702225864574473

Epoch: 6| Step: 12
Training loss: 2.148343324661255
Validation loss: 1.8836209863744757

Epoch: 6| Step: 13
Training loss: 1.82120943069458
Validation loss: 1.9009469132269583

Epoch: 135| Step: 0
Training loss: 2.135301351547241
Validation loss: 1.888219794919414

Epoch: 6| Step: 1
Training loss: 1.6677385568618774
Validation loss: 1.9314304679952643

Epoch: 6| Step: 2
Training loss: 1.9667693376541138
Validation loss: 1.960006154993529

Epoch: 6| Step: 3
Training loss: 1.9313597679138184
Validation loss: 1.9665492542328373

Epoch: 6| Step: 4
Training loss: 1.2220996618270874
Validation loss: 1.9607231578519266

Epoch: 6| Step: 5
Training loss: 1.9265905618667603
Validation loss: 1.9461274839216662

Epoch: 6| Step: 6
Training loss: 2.111750602722168
Validation loss: 1.9014974473625101

Epoch: 6| Step: 7
Training loss: 1.6008028984069824
Validation loss: 1.8688417288564867

Epoch: 6| Step: 8
Training loss: 2.1432862281799316
Validation loss: 1.861477905704129

Epoch: 6| Step: 9
Training loss: 1.8612759113311768
Validation loss: 1.869931746554631

Epoch: 6| Step: 10
Training loss: 2.0907704830169678
Validation loss: 1.8759537948075162

Epoch: 6| Step: 11
Training loss: 1.8803837299346924
Validation loss: 1.8821708771490282

Epoch: 6| Step: 12
Training loss: 2.7818448543548584
Validation loss: 1.8810791892390097

Epoch: 6| Step: 13
Training loss: 2.2892613410949707
Validation loss: 1.8650830317569036

Epoch: 136| Step: 0
Training loss: 1.9494609832763672
Validation loss: 1.8721474498830817

Epoch: 6| Step: 1
Training loss: 2.312833786010742
Validation loss: 1.8737612026993946

Epoch: 6| Step: 2
Training loss: 2.632875442504883
Validation loss: 1.869305654238629

Epoch: 6| Step: 3
Training loss: 1.1833134889602661
Validation loss: 1.8786520291400213

Epoch: 6| Step: 4
Training loss: 1.9565694332122803
Validation loss: 1.9040103830317014

Epoch: 6| Step: 5
Training loss: 2.480656385421753
Validation loss: 1.9083887274547289

Epoch: 6| Step: 6
Training loss: 1.4703540802001953
Validation loss: 1.8882498100239744

Epoch: 6| Step: 7
Training loss: 1.7059288024902344
Validation loss: 1.8987699631721742

Epoch: 6| Step: 8
Training loss: 1.6597188711166382
Validation loss: 1.9197077751159668

Epoch: 6| Step: 9
Training loss: 2.4109866619110107
Validation loss: 1.9328724158707487

Epoch: 6| Step: 10
Training loss: 1.5366567373275757
Validation loss: 1.925736524725473

Epoch: 6| Step: 11
Training loss: 1.3967580795288086
Validation loss: 1.8972439971021426

Epoch: 6| Step: 12
Training loss: 2.0060462951660156
Validation loss: 1.8980632866582563

Epoch: 6| Step: 13
Training loss: 2.086491584777832
Validation loss: 1.9058992093609226

Epoch: 137| Step: 0
Training loss: 1.313317060470581
Validation loss: 1.927920610673966

Epoch: 6| Step: 1
Training loss: 2.1261701583862305
Validation loss: 1.9604321961761804

Epoch: 6| Step: 2
Training loss: 1.5024855136871338
Validation loss: 1.9567746667451755

Epoch: 6| Step: 3
Training loss: 2.185356616973877
Validation loss: 1.971983758352136

Epoch: 6| Step: 4
Training loss: 2.8019633293151855
Validation loss: 1.9416135049635364

Epoch: 6| Step: 5
Training loss: 1.8339107036590576
Validation loss: 1.952612574382495

Epoch: 6| Step: 6
Training loss: 1.674116611480713
Validation loss: 1.9435975038877098

Epoch: 6| Step: 7
Training loss: 2.6328752040863037
Validation loss: 1.9323770320543678

Epoch: 6| Step: 8
Training loss: 1.7090073823928833
Validation loss: 1.9503264811731154

Epoch: 6| Step: 9
Training loss: 2.155302047729492
Validation loss: 1.9132250380772415

Epoch: 6| Step: 10
Training loss: 1.6455061435699463
Validation loss: 1.927968627663069

Epoch: 6| Step: 11
Training loss: 1.5037562847137451
Validation loss: 1.93616271275346

Epoch: 6| Step: 12
Training loss: 1.9722703695297241
Validation loss: 1.9844588182305778

Epoch: 6| Step: 13
Training loss: 2.104022979736328
Validation loss: 1.9894164146915558

Epoch: 138| Step: 0
Training loss: 2.0608768463134766
Validation loss: 1.985669869248585

Epoch: 6| Step: 1
Training loss: 1.694309949874878
Validation loss: 1.9595111711050874

Epoch: 6| Step: 2
Training loss: 1.6279624700546265
Validation loss: 1.9484238496390722

Epoch: 6| Step: 3
Training loss: 1.4901167154312134
Validation loss: 1.9246480464935303

Epoch: 6| Step: 4
Training loss: 2.118196964263916
Validation loss: 1.929505302060035

Epoch: 6| Step: 5
Training loss: 1.6895941495895386
Validation loss: 1.938993146342616

Epoch: 6| Step: 6
Training loss: 1.93253755569458
Validation loss: 1.9172958609878377

Epoch: 6| Step: 7
Training loss: 1.6596561670303345
Validation loss: 1.9094701800295102

Epoch: 6| Step: 8
Training loss: 1.5976353883743286
Validation loss: 1.9201516656465427

Epoch: 6| Step: 9
Training loss: 2.105405330657959
Validation loss: 1.911831425082299

Epoch: 6| Step: 10
Training loss: 1.8736896514892578
Validation loss: 1.920116457887875

Epoch: 6| Step: 11
Training loss: 1.5241446495056152
Validation loss: 1.896108204318631

Epoch: 6| Step: 12
Training loss: 2.6222171783447266
Validation loss: 1.8907280609171877

Epoch: 6| Step: 13
Training loss: 2.4001564979553223
Validation loss: 1.889620816835793

Epoch: 139| Step: 0
Training loss: 2.34067964553833
Validation loss: 1.8805230253486223

Epoch: 6| Step: 1
Training loss: 1.683706521987915
Validation loss: 1.8652525922303558

Epoch: 6| Step: 2
Training loss: 2.432788133621216
Validation loss: 1.8827877480496642

Epoch: 6| Step: 3
Training loss: 0.8093826770782471
Validation loss: 1.8835705839177614

Epoch: 6| Step: 4
Training loss: 1.60038423538208
Validation loss: 1.8713213141246507

Epoch: 6| Step: 5
Training loss: 2.1217284202575684
Validation loss: 1.8963905739527878

Epoch: 6| Step: 6
Training loss: 1.874128818511963
Validation loss: 1.935128265811551

Epoch: 6| Step: 7
Training loss: 2.1429262161254883
Validation loss: 2.00384880394064

Epoch: 6| Step: 8
Training loss: 1.6784756183624268
Validation loss: 2.0416953858508857

Epoch: 6| Step: 9
Training loss: 1.7329976558685303
Validation loss: 2.0372690641751854

Epoch: 6| Step: 10
Training loss: 2.0336945056915283
Validation loss: 2.0223247992095126

Epoch: 6| Step: 11
Training loss: 2.1039135456085205
Validation loss: 1.9934177347408828

Epoch: 6| Step: 12
Training loss: 2.058314561843872
Validation loss: 1.9558830030502812

Epoch: 6| Step: 13
Training loss: 1.7493668794631958
Validation loss: 1.9277250689844931

Epoch: 140| Step: 0
Training loss: 2.0714545249938965
Validation loss: 1.922918652975431

Epoch: 6| Step: 1
Training loss: 2.0649213790893555
Validation loss: 1.9238518796941286

Epoch: 6| Step: 2
Training loss: 2.789149284362793
Validation loss: 1.9167545533949328

Epoch: 6| Step: 3
Training loss: 2.090418577194214
Validation loss: 1.8978082954242665

Epoch: 6| Step: 4
Training loss: 1.8315956592559814
Validation loss: 1.89380007918163

Epoch: 6| Step: 5
Training loss: 1.3628485202789307
Validation loss: 1.906921491828016

Epoch: 6| Step: 6
Training loss: 1.5254673957824707
Validation loss: 1.9547926764334402

Epoch: 6| Step: 7
Training loss: 1.9081034660339355
Validation loss: 1.956157212616295

Epoch: 6| Step: 8
Training loss: 2.0953590869903564
Validation loss: 1.9072212608911658

Epoch: 6| Step: 9
Training loss: 1.7749207019805908
Validation loss: 1.8826382916460755

Epoch: 6| Step: 10
Training loss: 1.3622006177902222
Validation loss: 1.8756135881588023

Epoch: 6| Step: 11
Training loss: 2.623338222503662
Validation loss: 1.8820964661977624

Epoch: 6| Step: 12
Training loss: 2.242671251296997
Validation loss: 1.913816580208399

Epoch: 6| Step: 13
Training loss: 1.1034185886383057
Validation loss: 1.9161527964376635

Epoch: 141| Step: 0
Training loss: 2.333458662033081
Validation loss: 1.9055000274412093

Epoch: 6| Step: 1
Training loss: 1.1980328559875488
Validation loss: 1.9135933524818831

Epoch: 6| Step: 2
Training loss: 2.0163512229919434
Validation loss: 1.9391709937844226

Epoch: 6| Step: 3
Training loss: 2.7088656425476074
Validation loss: 1.9669075358298518

Epoch: 6| Step: 4
Training loss: 1.7025762796401978
Validation loss: 2.011344266194169

Epoch: 6| Step: 5
Training loss: 2.0551042556762695
Validation loss: 2.024844851545108

Epoch: 6| Step: 6
Training loss: 1.5004640817642212
Validation loss: 2.0312944740377445

Epoch: 6| Step: 7
Training loss: 2.0118072032928467
Validation loss: 2.0890651890026626

Epoch: 6| Step: 8
Training loss: 2.053560256958008
Validation loss: 2.0559506929048927

Epoch: 6| Step: 9
Training loss: 1.6140546798706055
Validation loss: 2.0268946078515824

Epoch: 6| Step: 10
Training loss: 1.5605297088623047
Validation loss: 1.9564516236705165

Epoch: 6| Step: 11
Training loss: 1.5562517642974854
Validation loss: 1.9248315236901725

Epoch: 6| Step: 12
Training loss: 1.4544336795806885
Validation loss: 1.9286510662365985

Epoch: 6| Step: 13
Training loss: 2.840442657470703
Validation loss: 1.9067354971362698

Epoch: 142| Step: 0
Training loss: 1.876169204711914
Validation loss: 1.8920583225065661

Epoch: 6| Step: 1
Training loss: 1.4171468019485474
Validation loss: 1.8826392440385715

Epoch: 6| Step: 2
Training loss: 2.1019093990325928
Validation loss: 1.8659716921467935

Epoch: 6| Step: 3
Training loss: 1.5365960597991943
Validation loss: 1.860055527379436

Epoch: 6| Step: 4
Training loss: 2.0612077713012695
Validation loss: 1.8530753299754152

Epoch: 6| Step: 5
Training loss: 2.3972628116607666
Validation loss: 1.8563179956969393

Epoch: 6| Step: 6
Training loss: 2.2244672775268555
Validation loss: 1.8583129580302904

Epoch: 6| Step: 7
Training loss: 2.1718430519104004
Validation loss: 1.8558116292440763

Epoch: 6| Step: 8
Training loss: 1.6210691928863525
Validation loss: 1.8565044428712578

Epoch: 6| Step: 9
Training loss: 2.237175941467285
Validation loss: 1.8633583976376442

Epoch: 6| Step: 10
Training loss: 1.7348544597625732
Validation loss: 1.8657212923931819

Epoch: 6| Step: 11
Training loss: 1.915666103363037
Validation loss: 1.8835545457819456

Epoch: 6| Step: 12
Training loss: 2.2461659908294678
Validation loss: 1.8882295277810865

Epoch: 6| Step: 13
Training loss: 1.924612283706665
Validation loss: 1.9007520509022537

Epoch: 143| Step: 0
Training loss: 1.8128007650375366
Validation loss: 1.9577462673187256

Epoch: 6| Step: 1
Training loss: 1.4156229496002197
Validation loss: 2.0459403094424995

Epoch: 6| Step: 2
Training loss: 2.235504150390625
Validation loss: 2.0769940294245237

Epoch: 6| Step: 3
Training loss: 1.0926114320755005
Validation loss: 2.0348646884323447

Epoch: 6| Step: 4
Training loss: 1.4491913318634033
Validation loss: 2.0170887131844797

Epoch: 6| Step: 5
Training loss: 1.9600858688354492
Validation loss: 1.9847465356190999

Epoch: 6| Step: 6
Training loss: 2.288963794708252
Validation loss: 1.9503456238777406

Epoch: 6| Step: 7
Training loss: 2.6782567501068115
Validation loss: 1.899209305804263

Epoch: 6| Step: 8
Training loss: 1.701667070388794
Validation loss: 1.8925427749592771

Epoch: 6| Step: 9
Training loss: 1.9632855653762817
Validation loss: 1.870900087459113

Epoch: 6| Step: 10
Training loss: 1.5903761386871338
Validation loss: 1.8649156221779444

Epoch: 6| Step: 11
Training loss: 2.35343599319458
Validation loss: 1.8765661972825245

Epoch: 6| Step: 12
Training loss: 2.0026588439941406
Validation loss: 1.9053033167316067

Epoch: 6| Step: 13
Training loss: 1.943025827407837
Validation loss: 1.913320484981742

Epoch: 144| Step: 0
Training loss: 1.866084098815918
Validation loss: 1.9367369426194059

Epoch: 6| Step: 1
Training loss: 1.6553843021392822
Validation loss: 1.918436276015415

Epoch: 6| Step: 2
Training loss: 1.847265601158142
Validation loss: 1.9353258699499152

Epoch: 6| Step: 3
Training loss: 1.8353283405303955
Validation loss: 1.9283200079394924

Epoch: 6| Step: 4
Training loss: 1.8361653089523315
Validation loss: 1.9441230899544173

Epoch: 6| Step: 5
Training loss: 1.8842049837112427
Validation loss: 1.9499643643697102

Epoch: 6| Step: 6
Training loss: 2.741215229034424
Validation loss: 1.9510556241517425

Epoch: 6| Step: 7
Training loss: 2.047071933746338
Validation loss: 1.9561647189560758

Epoch: 6| Step: 8
Training loss: 1.563938856124878
Validation loss: 1.9716776929875857

Epoch: 6| Step: 9
Training loss: 2.033968210220337
Validation loss: 1.9650128015907862

Epoch: 6| Step: 10
Training loss: 1.5201098918914795
Validation loss: 1.9776311061715568

Epoch: 6| Step: 11
Training loss: 1.4389986991882324
Validation loss: 1.9591738921339794

Epoch: 6| Step: 12
Training loss: 1.768345832824707
Validation loss: 1.98258650431069

Epoch: 6| Step: 13
Training loss: 1.8439733982086182
Validation loss: 1.963727157603028

Epoch: 145| Step: 0
Training loss: 1.2575138807296753
Validation loss: 2.007655141174152

Epoch: 6| Step: 1
Training loss: 1.9774706363677979
Validation loss: 1.9767240734510525

Epoch: 6| Step: 2
Training loss: 1.7227866649627686
Validation loss: 2.0193663156160744

Epoch: 6| Step: 3
Training loss: 1.523719310760498
Validation loss: 2.006826636611774

Epoch: 6| Step: 4
Training loss: 2.1909327507019043
Validation loss: 1.9958854747074906

Epoch: 6| Step: 5
Training loss: 2.214728832244873
Validation loss: 1.9811281645169823

Epoch: 6| Step: 6
Training loss: 1.9869105815887451
Validation loss: 1.9507976501218733

Epoch: 6| Step: 7
Training loss: 1.6795134544372559
Validation loss: 1.9319054183139597

Epoch: 6| Step: 8
Training loss: 1.61194908618927
Validation loss: 1.920147652267128

Epoch: 6| Step: 9
Training loss: 1.7799451351165771
Validation loss: 1.8756579481145388

Epoch: 6| Step: 10
Training loss: 1.7719805240631104
Validation loss: 1.8997429916935582

Epoch: 6| Step: 11
Training loss: 2.3417580127716064
Validation loss: 1.8907049958423903

Epoch: 6| Step: 12
Training loss: 2.400331974029541
Validation loss: 1.9277093615583194

Epoch: 6| Step: 13
Training loss: 0.8270465135574341
Validation loss: 1.912411702576504

Epoch: 146| Step: 0
Training loss: 1.8983149528503418
Validation loss: 1.9435909102039952

Epoch: 6| Step: 1
Training loss: 1.0690498352050781
Validation loss: 1.9582967245450584

Epoch: 6| Step: 2
Training loss: 2.043825149536133
Validation loss: 1.9685593830641879

Epoch: 6| Step: 3
Training loss: 1.8555266857147217
Validation loss: 1.973400737649651

Epoch: 6| Step: 4
Training loss: 2.0965042114257812
Validation loss: 1.9839536259251256

Epoch: 6| Step: 5
Training loss: 2.141725778579712
Validation loss: 1.9675383362718808

Epoch: 6| Step: 6
Training loss: 1.8515459299087524
Validation loss: 1.9670688413804578

Epoch: 6| Step: 7
Training loss: 1.750516414642334
Validation loss: 1.9831218847664454

Epoch: 6| Step: 8
Training loss: 2.134777069091797
Validation loss: 1.983073652431529

Epoch: 6| Step: 9
Training loss: 2.720165729522705
Validation loss: 1.9789360646278626

Epoch: 6| Step: 10
Training loss: 2.0684051513671875
Validation loss: 1.9493555894462011

Epoch: 6| Step: 11
Training loss: 1.079575538635254
Validation loss: 1.9414109606896677

Epoch: 6| Step: 12
Training loss: 0.6659657955169678
Validation loss: 1.9604911291471092

Epoch: 6| Step: 13
Training loss: 2.067638874053955
Validation loss: 1.9701888894522062

Epoch: 147| Step: 0
Training loss: 2.034834146499634
Validation loss: 1.9627554211565243

Epoch: 6| Step: 1
Training loss: 1.5139901638031006
Validation loss: 1.957837712380194

Epoch: 6| Step: 2
Training loss: 1.7070502042770386
Validation loss: 1.9367601153671101

Epoch: 6| Step: 3
Training loss: 1.3134020566940308
Validation loss: 1.9342393413666756

Epoch: 6| Step: 4
Training loss: 1.4814882278442383
Validation loss: 1.9498808640305714

Epoch: 6| Step: 5
Training loss: 2.0473556518554688
Validation loss: 1.9571414057926466

Epoch: 6| Step: 6
Training loss: 1.7176313400268555
Validation loss: 1.965465526426992

Epoch: 6| Step: 7
Training loss: 1.1475672721862793
Validation loss: 1.9890591534235145

Epoch: 6| Step: 8
Training loss: 2.045823574066162
Validation loss: 2.0084911905309206

Epoch: 6| Step: 9
Training loss: 1.4281036853790283
Validation loss: 2.0389799046260055

Epoch: 6| Step: 10
Training loss: 2.4531633853912354
Validation loss: 2.0774622476229103

Epoch: 6| Step: 11
Training loss: 1.4124722480773926
Validation loss: 2.136810779571533

Epoch: 6| Step: 12
Training loss: 2.099508047103882
Validation loss: 2.135997365879756

Epoch: 6| Step: 13
Training loss: 2.8065547943115234
Validation loss: 2.0613975896630237

Epoch: 148| Step: 0
Training loss: 2.5274715423583984
Validation loss: 2.0051582705590034

Epoch: 6| Step: 1
Training loss: 1.678833246231079
Validation loss: 1.9875146124952583

Epoch: 6| Step: 2
Training loss: 1.1897270679473877
Validation loss: 1.9818462902499783

Epoch: 6| Step: 3
Training loss: 1.9179984331130981
Validation loss: 1.9732786340098227

Epoch: 6| Step: 4
Training loss: 1.7666597366333008
Validation loss: 1.9400814630651986

Epoch: 6| Step: 5
Training loss: 1.7829868793487549
Validation loss: 1.9195456786822247

Epoch: 6| Step: 6
Training loss: 2.057196855545044
Validation loss: 1.9116565335181452

Epoch: 6| Step: 7
Training loss: 1.6636706590652466
Validation loss: 1.8934375188683952

Epoch: 6| Step: 8
Training loss: 2.2438998222351074
Validation loss: 1.935672028090364

Epoch: 6| Step: 9
Training loss: 2.1540560722351074
Validation loss: 2.0189139330258934

Epoch: 6| Step: 10
Training loss: 2.2429113388061523
Validation loss: 2.061500060942865

Epoch: 6| Step: 11
Training loss: 2.6297428607940674
Validation loss: 2.1320785527588217

Epoch: 6| Step: 12
Training loss: 1.7373225688934326
Validation loss: 2.207236074632214

Epoch: 6| Step: 13
Training loss: 2.8036770820617676
Validation loss: 2.2660053519792456

Epoch: 149| Step: 0
Training loss: 1.804654598236084
Validation loss: 2.3035870059843986

Epoch: 6| Step: 1
Training loss: 1.7840983867645264
Validation loss: 2.2497034252330823

Epoch: 6| Step: 2
Training loss: 2.265076160430908
Validation loss: 2.2047338254990114

Epoch: 6| Step: 3
Training loss: 1.405665397644043
Validation loss: 2.1234043131592455

Epoch: 6| Step: 4
Training loss: 1.9688808917999268
Validation loss: 2.0343750394800657

Epoch: 6| Step: 5
Training loss: 2.0710418224334717
Validation loss: 1.9893081342020342

Epoch: 6| Step: 6
Training loss: 2.6148948669433594
Validation loss: 1.9766417703320902

Epoch: 6| Step: 7
Training loss: 1.9715042114257812
Validation loss: 1.965738127308507

Epoch: 6| Step: 8
Training loss: 1.6973146200180054
Validation loss: 1.963531409540484

Epoch: 6| Step: 9
Training loss: 1.7409131526947021
Validation loss: 1.9796765683799662

Epoch: 6| Step: 10
Training loss: 1.729736089706421
Validation loss: 1.985469336150795

Epoch: 6| Step: 11
Training loss: 2.0897610187530518
Validation loss: 1.988604030301494

Epoch: 6| Step: 12
Training loss: 2.5778849124908447
Validation loss: 2.005801663603834

Epoch: 6| Step: 13
Training loss: 2.7684597969055176
Validation loss: 2.016838317276329

Epoch: 150| Step: 0
Training loss: 1.8419201374053955
Validation loss: 1.9794143540884859

Epoch: 6| Step: 1
Training loss: 1.4553388357162476
Validation loss: 1.98256718215122

Epoch: 6| Step: 2
Training loss: 1.4791855812072754
Validation loss: 1.953098076646046

Epoch: 6| Step: 3
Training loss: 1.043915033340454
Validation loss: 2.000000843437769

Epoch: 6| Step: 4
Training loss: 1.3303563594818115
Validation loss: 2.0689791710146013

Epoch: 6| Step: 5
Training loss: 2.076122760772705
Validation loss: 2.143791167966781

Epoch: 6| Step: 6
Training loss: 2.369901657104492
Validation loss: 2.1823032517586984

Epoch: 6| Step: 7
Training loss: 2.326422929763794
Validation loss: 2.103691929130144

Epoch: 6| Step: 8
Training loss: 1.9239637851715088
Validation loss: 2.0242612490089993

Epoch: 6| Step: 9
Training loss: 1.666605830192566
Validation loss: 1.9658503135045369

Epoch: 6| Step: 10
Training loss: 1.988903522491455
Validation loss: 1.9191869766481462

Epoch: 6| Step: 11
Training loss: 1.9762601852416992
Validation loss: 1.9166268135911675

Epoch: 6| Step: 12
Training loss: 2.467972755432129
Validation loss: 1.9243812176489061

Epoch: 6| Step: 13
Training loss: 2.3523988723754883
Validation loss: 1.939144488303892

Testing loss: 2.3103575706481934
