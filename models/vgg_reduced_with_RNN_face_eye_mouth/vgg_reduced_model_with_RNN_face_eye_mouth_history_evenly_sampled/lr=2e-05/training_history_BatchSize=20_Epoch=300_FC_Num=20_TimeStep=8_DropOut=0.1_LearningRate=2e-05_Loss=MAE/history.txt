Epoch: 1| Step: 0
Training loss: 4.299500942230225
Validation loss: 5.175443910783337

Epoch: 5| Step: 1
Training loss: 4.9763007164001465
Validation loss: 5.159317544711533

Epoch: 5| Step: 2
Training loss: 5.137031555175781
Validation loss: 5.144058673612533

Epoch: 5| Step: 3
Training loss: 5.604166507720947
Validation loss: 5.129801437418948

Epoch: 5| Step: 4
Training loss: 5.022258281707764
Validation loss: 5.113888473920925

Epoch: 5| Step: 5
Training loss: 3.991223096847534
Validation loss: 5.095503232812368

Epoch: 5| Step: 6
Training loss: 5.213510036468506
Validation loss: 5.073941210264801

Epoch: 5| Step: 7
Training loss: 5.750463962554932
Validation loss: 5.049550681985835

Epoch: 5| Step: 8
Training loss: 4.557276725769043
Validation loss: 5.02098947955716

Epoch: 5| Step: 9
Training loss: 5.039865016937256
Validation loss: 4.9884017564917125

Epoch: 5| Step: 10
Training loss: 3.8942153453826904
Validation loss: 4.950404403030231

Epoch: 2| Step: 0
Training loss: 5.319897651672363
Validation loss: 4.9086844177656275

Epoch: 5| Step: 1
Training loss: 5.204782009124756
Validation loss: 4.863272359294276

Epoch: 5| Step: 2
Training loss: 4.7338547706604
Validation loss: 4.812711849007555

Epoch: 5| Step: 3
Training loss: 4.251532554626465
Validation loss: 4.7563496148714455

Epoch: 5| Step: 4
Training loss: 4.202739238739014
Validation loss: 4.699728427394744

Epoch: 5| Step: 5
Training loss: 4.3047614097595215
Validation loss: 4.642180678664997

Epoch: 5| Step: 6
Training loss: 5.138175010681152
Validation loss: 4.582619062034032

Epoch: 5| Step: 7
Training loss: 4.294571399688721
Validation loss: 4.523459147381526

Epoch: 5| Step: 8
Training loss: 3.23633074760437
Validation loss: 4.462098060115691

Epoch: 5| Step: 9
Training loss: 3.635491132736206
Validation loss: 4.402367812331005

Epoch: 5| Step: 10
Training loss: 4.4781999588012695
Validation loss: 4.342761839589765

Epoch: 3| Step: 0
Training loss: 3.90269136428833
Validation loss: 4.278337099218882

Epoch: 5| Step: 1
Training loss: 4.44441032409668
Validation loss: 4.213135519335347

Epoch: 5| Step: 2
Training loss: 3.5889523029327393
Validation loss: 4.155396640941661

Epoch: 5| Step: 3
Training loss: 3.623178005218506
Validation loss: 4.0978038182822605

Epoch: 5| Step: 4
Training loss: 4.037937164306641
Validation loss: 4.03749906375844

Epoch: 5| Step: 5
Training loss: 2.6109142303466797
Validation loss: 3.9794891444585656

Epoch: 5| Step: 6
Training loss: 4.4615278244018555
Validation loss: 3.9212228739133446

Epoch: 5| Step: 7
Training loss: 4.717797756195068
Validation loss: 3.8682895834727953

Epoch: 5| Step: 8
Training loss: 2.6184709072113037
Validation loss: 3.8298518837139173

Epoch: 5| Step: 9
Training loss: 3.786160945892334
Validation loss: 3.8043623944764495

Epoch: 5| Step: 10
Training loss: 4.594944000244141
Validation loss: 3.771267029546922

Epoch: 4| Step: 0
Training loss: 3.424525737762451
Validation loss: 3.7275197454678115

Epoch: 5| Step: 1
Training loss: 3.4624247550964355
Validation loss: 3.7014620534835325

Epoch: 5| Step: 2
Training loss: 2.937807559967041
Validation loss: 3.686030546824137

Epoch: 5| Step: 3
Training loss: 4.068229675292969
Validation loss: 3.67430857945514

Epoch: 5| Step: 4
Training loss: 3.2735183238983154
Validation loss: 3.66040882243905

Epoch: 5| Step: 5
Training loss: 3.70686674118042
Validation loss: 3.642594619463849

Epoch: 5| Step: 6
Training loss: 2.6138346195220947
Validation loss: 3.6183353393308577

Epoch: 5| Step: 7
Training loss: 3.351706027984619
Validation loss: 3.5944594747276715

Epoch: 5| Step: 8
Training loss: 3.714825391769409
Validation loss: 3.5716001295274302

Epoch: 5| Step: 9
Training loss: 4.618407249450684
Validation loss: 3.553727149963379

Epoch: 5| Step: 10
Training loss: 3.7662582397460938
Validation loss: 3.536836926655103

Epoch: 5| Step: 0
Training loss: 3.4884467124938965
Validation loss: 3.5170432777814966

Epoch: 5| Step: 1
Training loss: 3.204615831375122
Validation loss: 3.492386643604566

Epoch: 5| Step: 2
Training loss: 3.068572998046875
Validation loss: 3.4685455599138812

Epoch: 5| Step: 3
Training loss: 2.6888604164123535
Validation loss: 3.4537677354710077

Epoch: 5| Step: 4
Training loss: 2.8156139850616455
Validation loss: 3.449205747214697

Epoch: 5| Step: 5
Training loss: 4.011838436126709
Validation loss: 3.433260251117009

Epoch: 5| Step: 6
Training loss: 3.217761516571045
Validation loss: 3.4150968572144866

Epoch: 5| Step: 7
Training loss: 4.200089931488037
Validation loss: 3.4009122745965117

Epoch: 5| Step: 8
Training loss: 3.6825485229492188
Validation loss: 3.389080980772613

Epoch: 5| Step: 9
Training loss: 3.0721564292907715
Validation loss: 3.3788437228049

Epoch: 5| Step: 10
Training loss: 3.7673003673553467
Validation loss: 3.370438875690583

Epoch: 6| Step: 0
Training loss: 2.9912049770355225
Validation loss: 3.348278348163892

Epoch: 5| Step: 1
Training loss: 4.299824237823486
Validation loss: 3.3371169387653308

Epoch: 5| Step: 2
Training loss: 3.6713154315948486
Validation loss: 3.324235826410273

Epoch: 5| Step: 3
Training loss: 2.6543097496032715
Validation loss: 3.31237797070575

Epoch: 5| Step: 4
Training loss: 3.1921708583831787
Validation loss: 3.2987734579270884

Epoch: 5| Step: 5
Training loss: 2.6035525798797607
Validation loss: 3.279057220746112

Epoch: 5| Step: 6
Training loss: 3.4145050048828125
Validation loss: 3.264643748601278

Epoch: 5| Step: 7
Training loss: 3.5083656311035156
Validation loss: 3.2552231716853317

Epoch: 5| Step: 8
Training loss: 3.2486815452575684
Validation loss: 3.2475475547134236

Epoch: 5| Step: 9
Training loss: 3.5499770641326904
Validation loss: 3.2414886746355283

Epoch: 5| Step: 10
Training loss: 2.6904406547546387
Validation loss: 3.2286120281424573

Epoch: 7| Step: 0
Training loss: 3.738966703414917
Validation loss: 3.2147817355330273

Epoch: 5| Step: 1
Training loss: 3.1968441009521484
Validation loss: 3.1953308966852005

Epoch: 5| Step: 2
Training loss: 2.858027219772339
Validation loss: 3.187450485844766

Epoch: 5| Step: 3
Training loss: 3.34698224067688
Validation loss: 3.1802329247997654

Epoch: 5| Step: 4
Training loss: 3.069147825241089
Validation loss: 3.1717477921516664

Epoch: 5| Step: 5
Training loss: 2.4304139614105225
Validation loss: 3.1550521594221874

Epoch: 5| Step: 6
Training loss: 3.7208263874053955
Validation loss: 3.1423617896213325

Epoch: 5| Step: 7
Training loss: 3.5438621044158936
Validation loss: 3.131267924462595

Epoch: 5| Step: 8
Training loss: 3.208819627761841
Validation loss: 3.1330419150731896

Epoch: 5| Step: 9
Training loss: 2.6801886558532715
Validation loss: 3.129768451054891

Epoch: 5| Step: 10
Training loss: 3.0409176349639893
Validation loss: 3.0982288827178297

Epoch: 8| Step: 0
Training loss: 3.5413601398468018
Validation loss: 3.0976635486848894

Epoch: 5| Step: 1
Training loss: 3.717975616455078
Validation loss: 3.0998126768296763

Epoch: 5| Step: 2
Training loss: 2.468161106109619
Validation loss: 3.0904730084121868

Epoch: 5| Step: 3
Training loss: 2.337268114089966
Validation loss: 3.0758244504210768

Epoch: 5| Step: 4
Training loss: 2.883748769760132
Validation loss: 3.062174456093901

Epoch: 5| Step: 5
Training loss: 2.6992366313934326
Validation loss: 3.047117494767712

Epoch: 5| Step: 6
Training loss: 2.798748016357422
Validation loss: 3.035696955137355

Epoch: 5| Step: 7
Training loss: 3.319988965988159
Validation loss: 3.03898621630925

Epoch: 5| Step: 8
Training loss: 3.30450177192688
Validation loss: 3.0404340682491178

Epoch: 5| Step: 9
Training loss: 3.543433427810669
Validation loss: 3.0140428594363633

Epoch: 5| Step: 10
Training loss: 3.4975013732910156
Validation loss: 3.0041753681757117

Epoch: 9| Step: 0
Training loss: 3.1013028621673584
Validation loss: 3.0028166642753025

Epoch: 5| Step: 1
Training loss: 3.0264852046966553
Validation loss: 2.9941044776670394

Epoch: 5| Step: 2
Training loss: 3.2427783012390137
Validation loss: 2.9776799422438427

Epoch: 5| Step: 3
Training loss: 2.038923978805542
Validation loss: 2.9736795553597073

Epoch: 5| Step: 4
Training loss: 3.095057964324951
Validation loss: 2.971975649556806

Epoch: 5| Step: 5
Training loss: 3.0600414276123047
Validation loss: 2.958390235900879

Epoch: 5| Step: 6
Training loss: 2.8330271244049072
Validation loss: 2.951097173075522

Epoch: 5| Step: 7
Training loss: 2.634061574935913
Validation loss: 2.9386442399794057

Epoch: 5| Step: 8
Training loss: 3.5799717903137207
Validation loss: 2.92500336452197

Epoch: 5| Step: 9
Training loss: 3.1347649097442627
Validation loss: 2.9208347053938013

Epoch: 5| Step: 10
Training loss: 3.6905336380004883
Validation loss: 2.912734998169766

Epoch: 10| Step: 0
Training loss: 2.711371421813965
Validation loss: 2.904186956344112

Epoch: 5| Step: 1
Training loss: 3.160421848297119
Validation loss: 2.8955662288973407

Epoch: 5| Step: 2
Training loss: 3.9056320190429688
Validation loss: 2.8863494139845653

Epoch: 5| Step: 3
Training loss: 2.773427963256836
Validation loss: 2.8785773656701528

Epoch: 5| Step: 4
Training loss: 3.412438154220581
Validation loss: 2.871628369054487

Epoch: 5| Step: 5
Training loss: 2.6729893684387207
Validation loss: 2.8668688753599763

Epoch: 5| Step: 6
Training loss: 3.511753797531128
Validation loss: 2.854691295213597

Epoch: 5| Step: 7
Training loss: 2.7764930725097656
Validation loss: 2.847935612483691

Epoch: 5| Step: 8
Training loss: 2.32835054397583
Validation loss: 2.840670385668355

Epoch: 5| Step: 9
Training loss: 2.6440269947052
Validation loss: 2.834777770503875

Epoch: 5| Step: 10
Training loss: 2.7397942543029785
Validation loss: 2.8311546002664874

Epoch: 11| Step: 0
Training loss: 2.805650234222412
Validation loss: 2.8275004381774576

Epoch: 5| Step: 1
Training loss: 2.962317943572998
Validation loss: 2.852385356862058

Epoch: 5| Step: 2
Training loss: 4.220304012298584
Validation loss: 2.860598066801666

Epoch: 5| Step: 3
Training loss: 2.6442067623138428
Validation loss: 2.7951301297833844

Epoch: 5| Step: 4
Training loss: 3.306504487991333
Validation loss: 2.804961727511498

Epoch: 5| Step: 5
Training loss: 2.4786083698272705
Validation loss: 2.818084288668889

Epoch: 5| Step: 6
Training loss: 3.0786585807800293
Validation loss: 2.8048462047371814

Epoch: 5| Step: 7
Training loss: 2.8799240589141846
Validation loss: 2.795386124682683

Epoch: 5| Step: 8
Training loss: 2.4290313720703125
Validation loss: 2.7792581127535914

Epoch: 5| Step: 9
Training loss: 2.858246326446533
Validation loss: 2.768423411153978

Epoch: 5| Step: 10
Training loss: 2.499270439147949
Validation loss: 2.765974085818055

Epoch: 12| Step: 0
Training loss: 2.5836641788482666
Validation loss: 2.7538000229866273

Epoch: 5| Step: 1
Training loss: 2.539804697036743
Validation loss: 2.750273932692825

Epoch: 5| Step: 2
Training loss: 2.4881529808044434
Validation loss: 2.7476465317510788

Epoch: 5| Step: 3
Training loss: 2.596652030944824
Validation loss: 2.7471856558194725

Epoch: 5| Step: 4
Training loss: 3.4858157634735107
Validation loss: 2.7575637704582623

Epoch: 5| Step: 5
Training loss: 3.6234004497528076
Validation loss: 2.7319195783266457

Epoch: 5| Step: 6
Training loss: 2.697727680206299
Validation loss: 2.7255263533643497

Epoch: 5| Step: 7
Training loss: 2.9313995838165283
Validation loss: 2.725493138836276

Epoch: 5| Step: 8
Training loss: 2.9880173206329346
Validation loss: 2.7271564186260266

Epoch: 5| Step: 9
Training loss: 2.4949378967285156
Validation loss: 2.722609007230369

Epoch: 5| Step: 10
Training loss: 3.2426366806030273
Validation loss: 2.716021189125635

Epoch: 13| Step: 0
Training loss: 2.976712703704834
Validation loss: 2.701912103160735

Epoch: 5| Step: 1
Training loss: 2.825455904006958
Validation loss: 2.7000385510024203

Epoch: 5| Step: 2
Training loss: 2.9943175315856934
Validation loss: 2.7130920143537622

Epoch: 5| Step: 3
Training loss: 2.4619224071502686
Validation loss: 2.715463953633462

Epoch: 5| Step: 4
Training loss: 2.7439892292022705
Validation loss: 2.701909508756412

Epoch: 5| Step: 5
Training loss: 2.510380268096924
Validation loss: 2.674451171710927

Epoch: 5| Step: 6
Training loss: 2.7115817070007324
Validation loss: 2.6713161365960234

Epoch: 5| Step: 7
Training loss: 3.145847797393799
Validation loss: 2.6690066937477357

Epoch: 5| Step: 8
Training loss: 2.5115723609924316
Validation loss: 2.673063426889399

Epoch: 5| Step: 9
Training loss: 3.383464813232422
Validation loss: 2.6691449226871615

Epoch: 5| Step: 10
Training loss: 3.0185697078704834
Validation loss: 2.6603153315923547

Epoch: 14| Step: 0
Training loss: 3.1243834495544434
Validation loss: 2.6486793487302718

Epoch: 5| Step: 1
Training loss: 2.9835336208343506
Validation loss: 2.6396523496156097

Epoch: 5| Step: 2
Training loss: 3.648113250732422
Validation loss: 2.641084653075023

Epoch: 5| Step: 3
Training loss: 2.2154765129089355
Validation loss: 2.639385813026018

Epoch: 5| Step: 4
Training loss: 2.678358316421509
Validation loss: 2.6295721530914307

Epoch: 5| Step: 5
Training loss: 3.0230114459991455
Validation loss: 2.6230292166433027

Epoch: 5| Step: 6
Training loss: 2.248589038848877
Validation loss: 2.6151066236598517

Epoch: 5| Step: 7
Training loss: 2.6954290866851807
Validation loss: 2.6159671942392984

Epoch: 5| Step: 8
Training loss: 2.6253206729888916
Validation loss: 2.6141073165401334

Epoch: 5| Step: 9
Training loss: 2.2345712184906006
Validation loss: 2.6065621247855564

Epoch: 5| Step: 10
Training loss: 3.446367025375366
Validation loss: 2.6197534325302287

Epoch: 15| Step: 0
Training loss: 2.6760871410369873
Validation loss: 2.608898042350687

Epoch: 5| Step: 1
Training loss: 2.911935329437256
Validation loss: 2.5975557604143695

Epoch: 5| Step: 2
Training loss: 2.2657923698425293
Validation loss: 2.6374984812992874

Epoch: 5| Step: 3
Training loss: 2.9158599376678467
Validation loss: 2.7221447908750145

Epoch: 5| Step: 4
Training loss: 2.932842493057251
Validation loss: 2.6503067657511723

Epoch: 5| Step: 5
Training loss: 2.815051555633545
Validation loss: 2.6054007417412213

Epoch: 5| Step: 6
Training loss: 3.0415096282958984
Validation loss: 2.582113765901135

Epoch: 5| Step: 7
Training loss: 3.2314019203186035
Validation loss: 2.588771197103685

Epoch: 5| Step: 8
Training loss: 2.3526270389556885
Validation loss: 2.596765059296803

Epoch: 5| Step: 9
Training loss: 2.6078336238861084
Validation loss: 2.624458405279344

Epoch: 5| Step: 10
Training loss: 3.0443224906921387
Validation loss: 2.6506753403653383

Epoch: 16| Step: 0
Training loss: 2.273646831512451
Validation loss: 2.7060104159898657

Epoch: 5| Step: 1
Training loss: 3.39727783203125
Validation loss: 2.6674844449566257

Epoch: 5| Step: 2
Training loss: 2.521775484085083
Validation loss: 2.5778777137879403

Epoch: 5| Step: 3
Training loss: 3.220576524734497
Validation loss: 2.559924089780418

Epoch: 5| Step: 4
Training loss: 2.9132890701293945
Validation loss: 2.568554378324939

Epoch: 5| Step: 5
Training loss: 3.106135129928589
Validation loss: 2.5823435911568264

Epoch: 5| Step: 6
Training loss: 2.74710750579834
Validation loss: 2.5677267710367837

Epoch: 5| Step: 7
Training loss: 2.541693925857544
Validation loss: 2.561530866930562

Epoch: 5| Step: 8
Training loss: 2.2233519554138184
Validation loss: 2.556372916826638

Epoch: 5| Step: 9
Training loss: 3.2195067405700684
Validation loss: 2.5452873270998717

Epoch: 5| Step: 10
Training loss: 2.2265098094940186
Validation loss: 2.5455562145479265

Epoch: 17| Step: 0
Training loss: 2.85223126411438
Validation loss: 2.5505167438137915

Epoch: 5| Step: 1
Training loss: 2.7289323806762695
Validation loss: 2.552819957015335

Epoch: 5| Step: 2
Training loss: 2.859149217605591
Validation loss: 2.5413728042315413

Epoch: 5| Step: 3
Training loss: 2.8613600730895996
Validation loss: 2.539301126233993

Epoch: 5| Step: 4
Training loss: 2.478260040283203
Validation loss: 2.5334188425412743

Epoch: 5| Step: 5
Training loss: 2.8893494606018066
Validation loss: 2.545184676365186

Epoch: 5| Step: 6
Training loss: 3.455631732940674
Validation loss: 2.539663337892102

Epoch: 5| Step: 7
Training loss: 2.393969774246216
Validation loss: 2.531717913125151

Epoch: 5| Step: 8
Training loss: 2.8856358528137207
Validation loss: 2.527897257958689

Epoch: 5| Step: 9
Training loss: 2.4201769828796387
Validation loss: 2.518073835680562

Epoch: 5| Step: 10
Training loss: 2.1643271446228027
Validation loss: 2.521877581073392

Epoch: 18| Step: 0
Training loss: 2.7795355319976807
Validation loss: 2.5265718967683855

Epoch: 5| Step: 1
Training loss: 3.157975196838379
Validation loss: 2.5241565191617577

Epoch: 5| Step: 2
Training loss: 2.8165125846862793
Validation loss: 2.5211536422852547

Epoch: 5| Step: 3
Training loss: 2.5973994731903076
Validation loss: 2.5142301897848807

Epoch: 5| Step: 4
Training loss: 2.4789257049560547
Validation loss: 2.5073592701265888

Epoch: 5| Step: 5
Training loss: 2.1750500202178955
Validation loss: 2.50801432260903

Epoch: 5| Step: 6
Training loss: 3.2162082195281982
Validation loss: 2.504006355039535

Epoch: 5| Step: 7
Training loss: 2.7160754203796387
Validation loss: 2.5025087684713383

Epoch: 5| Step: 8
Training loss: 2.703084707260132
Validation loss: 2.5000137334228842

Epoch: 5| Step: 9
Training loss: 3.006577730178833
Validation loss: 2.4936038806874263

Epoch: 5| Step: 10
Training loss: 2.1787843704223633
Validation loss: 2.494040491760418

Epoch: 19| Step: 0
Training loss: 2.514582395553589
Validation loss: 2.494120802930606

Epoch: 5| Step: 1
Training loss: 1.9252135753631592
Validation loss: 2.4958488505373717

Epoch: 5| Step: 2
Training loss: 2.7177672386169434
Validation loss: 2.49505937996731

Epoch: 5| Step: 3
Training loss: 2.974973678588867
Validation loss: 2.4971843483627483

Epoch: 5| Step: 4
Training loss: 2.728986978530884
Validation loss: 2.495828410630585

Epoch: 5| Step: 5
Training loss: 3.297765016555786
Validation loss: 2.491421571341894

Epoch: 5| Step: 6
Training loss: 2.924830198287964
Validation loss: 2.49286977962781

Epoch: 5| Step: 7
Training loss: 2.271719455718994
Validation loss: 2.5040917268363376

Epoch: 5| Step: 8
Training loss: 2.5885720252990723
Validation loss: 2.4838230071529264

Epoch: 5| Step: 9
Training loss: 3.0445187091827393
Validation loss: 2.4870896313780095

Epoch: 5| Step: 10
Training loss: 2.6919078826904297
Validation loss: 2.4875700217421337

Epoch: 20| Step: 0
Training loss: 3.013577938079834
Validation loss: 2.500939715293146

Epoch: 5| Step: 1
Training loss: 2.5092387199401855
Validation loss: 2.474007923115966

Epoch: 5| Step: 2
Training loss: 2.6194489002227783
Validation loss: 2.470388909821869

Epoch: 5| Step: 3
Training loss: 2.0474886894226074
Validation loss: 2.471534926404235

Epoch: 5| Step: 4
Training loss: 2.890612840652466
Validation loss: 2.484425876730232

Epoch: 5| Step: 5
Training loss: 2.243379592895508
Validation loss: 2.4935982124779814

Epoch: 5| Step: 6
Training loss: 2.285511016845703
Validation loss: 2.522509087798416

Epoch: 5| Step: 7
Training loss: 2.9476842880249023
Validation loss: 2.5327532419594387

Epoch: 5| Step: 8
Training loss: 2.7786920070648193
Validation loss: 2.4853854025563886

Epoch: 5| Step: 9
Training loss: 3.020354747772217
Validation loss: 2.463118617252637

Epoch: 5| Step: 10
Training loss: 3.450223445892334
Validation loss: 2.45738628602797

Epoch: 21| Step: 0
Training loss: 2.4803948402404785
Validation loss: 2.4776766505292667

Epoch: 5| Step: 1
Training loss: 2.7561745643615723
Validation loss: 2.5138585593110774

Epoch: 5| Step: 2
Training loss: 2.7096333503723145
Validation loss: 2.5260639985402427

Epoch: 5| Step: 3
Training loss: 2.734562635421753
Validation loss: 2.4921592717529624

Epoch: 5| Step: 4
Training loss: 3.3710410594940186
Validation loss: 2.453825348167009

Epoch: 5| Step: 5
Training loss: 2.5489935874938965
Validation loss: 2.4578344693747898

Epoch: 5| Step: 6
Training loss: 3.14184308052063
Validation loss: 2.5159643260381555

Epoch: 5| Step: 7
Training loss: 2.9425597190856934
Validation loss: 2.5668855892714633

Epoch: 5| Step: 8
Training loss: 2.3886189460754395
Validation loss: 2.546111686255342

Epoch: 5| Step: 9
Training loss: 2.345770835876465
Validation loss: 2.501646667398432

Epoch: 5| Step: 10
Training loss: 2.4595437049865723
Validation loss: 2.4707333708322174

Epoch: 22| Step: 0
Training loss: 2.5122179985046387
Validation loss: 2.4554579591238372

Epoch: 5| Step: 1
Training loss: 2.8496944904327393
Validation loss: 2.4515299361239196

Epoch: 5| Step: 2
Training loss: 1.979186773300171
Validation loss: 2.449045793984526

Epoch: 5| Step: 3
Training loss: 2.582580327987671
Validation loss: 2.4499891137564056

Epoch: 5| Step: 4
Training loss: 3.104029655456543
Validation loss: 2.4453113514889955

Epoch: 5| Step: 5
Training loss: 2.606740951538086
Validation loss: 2.4416177247160222

Epoch: 5| Step: 6
Training loss: 2.049376964569092
Validation loss: 2.4386248075833885

Epoch: 5| Step: 7
Training loss: 2.626209259033203
Validation loss: 2.4429771233630437

Epoch: 5| Step: 8
Training loss: 2.6855437755584717
Validation loss: 2.4491928777387066

Epoch: 5| Step: 9
Training loss: 3.2705798149108887
Validation loss: 2.441326302866782

Epoch: 5| Step: 10
Training loss: 3.254103660583496
Validation loss: 2.4416079341724353

Epoch: 23| Step: 0
Training loss: 2.549781560897827
Validation loss: 2.445605144705824

Epoch: 5| Step: 1
Training loss: 2.7280619144439697
Validation loss: 2.432932415316182

Epoch: 5| Step: 2
Training loss: 1.9117648601531982
Validation loss: 2.428212417069302

Epoch: 5| Step: 3
Training loss: 2.467434883117676
Validation loss: 2.4304186503092446

Epoch: 5| Step: 4
Training loss: 2.669837474822998
Validation loss: 2.4513206481933594

Epoch: 5| Step: 5
Training loss: 3.090397357940674
Validation loss: 2.4283216281603743

Epoch: 5| Step: 6
Training loss: 2.657890796661377
Validation loss: 2.418293260758923

Epoch: 5| Step: 7
Training loss: 2.703972101211548
Validation loss: 2.414941228846068

Epoch: 5| Step: 8
Training loss: 2.4076056480407715
Validation loss: 2.4146012439522693

Epoch: 5| Step: 9
Training loss: 3.162553310394287
Validation loss: 2.419716255639189

Epoch: 5| Step: 10
Training loss: 2.971508264541626
Validation loss: 2.4204581783663843

Epoch: 24| Step: 0
Training loss: 2.350799322128296
Validation loss: 2.4109313513643

Epoch: 5| Step: 1
Training loss: 3.2113499641418457
Validation loss: 2.4076249138001473

Epoch: 5| Step: 2
Training loss: 3.232074737548828
Validation loss: 2.399275352877955

Epoch: 5| Step: 3
Training loss: 2.4768874645233154
Validation loss: 2.403628913305139

Epoch: 5| Step: 4
Training loss: 2.41717529296875
Validation loss: 2.4286174466533046

Epoch: 5| Step: 5
Training loss: 2.489391565322876
Validation loss: 2.4741882585710093

Epoch: 5| Step: 6
Training loss: 2.516367197036743
Validation loss: 2.4598150125113865

Epoch: 5| Step: 7
Training loss: 2.595759630203247
Validation loss: 2.458616864296698

Epoch: 5| Step: 8
Training loss: 2.8905014991760254
Validation loss: 2.448643030658845

Epoch: 5| Step: 9
Training loss: 2.7103257179260254
Validation loss: 2.4274478112497637

Epoch: 5| Step: 10
Training loss: 2.24040150642395
Validation loss: 2.394997701849989

Epoch: 25| Step: 0
Training loss: 2.9576666355133057
Validation loss: 2.3854470919537287

Epoch: 5| Step: 1
Training loss: 2.7236156463623047
Validation loss: 2.3858304741562053

Epoch: 5| Step: 2
Training loss: 2.063729763031006
Validation loss: 2.384577335849885

Epoch: 5| Step: 3
Training loss: 2.395890951156616
Validation loss: 2.383114017466063

Epoch: 5| Step: 4
Training loss: 3.1375136375427246
Validation loss: 2.3949511512633292

Epoch: 5| Step: 5
Training loss: 2.2987608909606934
Validation loss: 2.4151754994546213

Epoch: 5| Step: 6
Training loss: 2.6160008907318115
Validation loss: 2.4327349944781234

Epoch: 5| Step: 7
Training loss: 3.1967926025390625
Validation loss: 2.468697383839597

Epoch: 5| Step: 8
Training loss: 3.5183990001678467
Validation loss: 2.4598469144554547

Epoch: 5| Step: 9
Training loss: 2.261282444000244
Validation loss: 2.4320258940419843

Epoch: 5| Step: 10
Training loss: 1.922062635421753
Validation loss: 2.3896904376245316

Epoch: 26| Step: 0
Training loss: 3.2460460662841797
Validation loss: 2.384303446738951

Epoch: 5| Step: 1
Training loss: 2.6594512462615967
Validation loss: 2.3904300005205217

Epoch: 5| Step: 2
Training loss: 2.551823854446411
Validation loss: 2.3996424803169827

Epoch: 5| Step: 3
Training loss: 3.2523086071014404
Validation loss: 2.4300944036053074

Epoch: 5| Step: 4
Training loss: 2.6158840656280518
Validation loss: 2.4231046322853333

Epoch: 5| Step: 5
Training loss: 2.5635266304016113
Validation loss: 2.381949609325778

Epoch: 5| Step: 6
Training loss: 2.339176893234253
Validation loss: 2.3774841818758237

Epoch: 5| Step: 7
Training loss: 2.4655330181121826
Validation loss: 2.3830461014983473

Epoch: 5| Step: 8
Training loss: 2.134549617767334
Validation loss: 2.4185809217473513

Epoch: 5| Step: 9
Training loss: 2.7313287258148193
Validation loss: 2.4635789599469913

Epoch: 5| Step: 10
Training loss: 2.726500988006592
Validation loss: 2.4868617506437403

Epoch: 27| Step: 0
Training loss: 3.0494048595428467
Validation loss: 2.425080990278593

Epoch: 5| Step: 1
Training loss: 2.8895411491394043
Validation loss: 2.3926764931730045

Epoch: 5| Step: 2
Training loss: 2.003270149230957
Validation loss: 2.3790130128142652

Epoch: 5| Step: 3
Training loss: 2.1290743350982666
Validation loss: 2.386732457786478

Epoch: 5| Step: 4
Training loss: 2.4826443195343018
Validation loss: 2.386711282114829

Epoch: 5| Step: 5
Training loss: 2.526737689971924
Validation loss: 2.3886000392257527

Epoch: 5| Step: 6
Training loss: 2.3861262798309326
Validation loss: 2.3864732403909006

Epoch: 5| Step: 7
Training loss: 2.9137070178985596
Validation loss: 2.380558026734219

Epoch: 5| Step: 8
Training loss: 3.050780773162842
Validation loss: 2.3674871357538367

Epoch: 5| Step: 9
Training loss: 2.922727584838867
Validation loss: 2.3663007854133524

Epoch: 5| Step: 10
Training loss: 2.8664417266845703
Validation loss: 2.3642461146077802

Epoch: 28| Step: 0
Training loss: 2.800853729248047
Validation loss: 2.373837847863474

Epoch: 5| Step: 1
Training loss: 3.153658866882324
Validation loss: 2.369094430759389

Epoch: 5| Step: 2
Training loss: 2.293851613998413
Validation loss: 2.3698873801897933

Epoch: 5| Step: 3
Training loss: 2.4544920921325684
Validation loss: 2.3671555724195255

Epoch: 5| Step: 4
Training loss: 2.6096320152282715
Validation loss: 2.3777931403088313

Epoch: 5| Step: 5
Training loss: 3.3879356384277344
Validation loss: 2.3964536651488273

Epoch: 5| Step: 6
Training loss: 2.865652084350586
Validation loss: 2.4066633460342244

Epoch: 5| Step: 7
Training loss: 2.1596992015838623
Validation loss: 2.4061699785212034

Epoch: 5| Step: 8
Training loss: 2.06687593460083
Validation loss: 2.3822198888306976

Epoch: 5| Step: 9
Training loss: 2.4867029190063477
Validation loss: 2.3598831187012377

Epoch: 5| Step: 10
Training loss: 2.598363161087036
Validation loss: 2.344861361288255

Epoch: 29| Step: 0
Training loss: 2.824336290359497
Validation loss: 2.3516639342872043

Epoch: 5| Step: 1
Training loss: 2.9864752292633057
Validation loss: 2.360063035001037

Epoch: 5| Step: 2
Training loss: 2.1912178993225098
Validation loss: 2.369184091526975

Epoch: 5| Step: 3
Training loss: 2.4808619022369385
Validation loss: 2.3653737293776644

Epoch: 5| Step: 4
Training loss: 2.6428589820861816
Validation loss: 2.374622634662095

Epoch: 5| Step: 5
Training loss: 2.9586076736450195
Validation loss: 2.3898734226021716

Epoch: 5| Step: 6
Training loss: 3.0870039463043213
Validation loss: 2.369650827941074

Epoch: 5| Step: 7
Training loss: 2.275042772293091
Validation loss: 2.3540117304812194

Epoch: 5| Step: 8
Training loss: 1.9510084390640259
Validation loss: 2.343227353147281

Epoch: 5| Step: 9
Training loss: 2.6487979888916016
Validation loss: 2.335912755740586

Epoch: 5| Step: 10
Training loss: 2.6351537704467773
Validation loss: 2.3305759686295704

Epoch: 30| Step: 0
Training loss: 2.767037868499756
Validation loss: 2.330805024793071

Epoch: 5| Step: 1
Training loss: 2.778977632522583
Validation loss: 2.328591805632396

Epoch: 5| Step: 2
Training loss: 2.7722082138061523
Validation loss: 2.3259864276455295

Epoch: 5| Step: 3
Training loss: 2.3085408210754395
Validation loss: 2.3258957709035566

Epoch: 5| Step: 4
Training loss: 2.546841859817505
Validation loss: 2.3223137419710875

Epoch: 5| Step: 5
Training loss: 2.0714409351348877
Validation loss: 2.3207631649509555

Epoch: 5| Step: 6
Training loss: 2.8557209968566895
Validation loss: 2.320381651642502

Epoch: 5| Step: 7
Training loss: 2.550354480743408
Validation loss: 2.320947201021256

Epoch: 5| Step: 8
Training loss: 2.53779935836792
Validation loss: 2.315907765460271

Epoch: 5| Step: 9
Training loss: 2.5317599773406982
Validation loss: 2.3181184158530286

Epoch: 5| Step: 10
Training loss: 2.831418514251709
Validation loss: 2.3373772021262877

Epoch: 31| Step: 0
Training loss: 2.6212451457977295
Validation loss: 2.3655842170920423

Epoch: 5| Step: 1
Training loss: 2.139505386352539
Validation loss: 2.3627315490476546

Epoch: 5| Step: 2
Training loss: 3.1838512420654297
Validation loss: 2.3869874682477725

Epoch: 5| Step: 3
Training loss: 2.4841692447662354
Validation loss: 2.3923257858522478

Epoch: 5| Step: 4
Training loss: 2.9621613025665283
Validation loss: 2.354187229628204

Epoch: 5| Step: 5
Training loss: 2.662728786468506
Validation loss: 2.326374189828032

Epoch: 5| Step: 6
Training loss: 2.6190648078918457
Validation loss: 2.3105386918590916

Epoch: 5| Step: 7
Training loss: 2.3464531898498535
Validation loss: 2.309020501311107

Epoch: 5| Step: 8
Training loss: 2.5476882457733154
Validation loss: 2.302473093873711

Epoch: 5| Step: 9
Training loss: 1.8761154413223267
Validation loss: 2.306895404733637

Epoch: 5| Step: 10
Training loss: 3.193903684616089
Validation loss: 2.3122493861823954

Epoch: 32| Step: 0
Training loss: 2.328683376312256
Validation loss: 2.315469334202428

Epoch: 5| Step: 1
Training loss: 2.1820931434631348
Validation loss: 2.3393877065309914

Epoch: 5| Step: 2
Training loss: 2.640991449356079
Validation loss: 2.355301785212691

Epoch: 5| Step: 3
Training loss: 2.5448625087738037
Validation loss: 2.339272311938706

Epoch: 5| Step: 4
Training loss: 2.6114299297332764
Validation loss: 2.334076258444017

Epoch: 5| Step: 5
Training loss: 2.669433116912842
Validation loss: 2.340883085804601

Epoch: 5| Step: 6
Training loss: 2.9184210300445557
Validation loss: 2.370303351392028

Epoch: 5| Step: 7
Training loss: 3.372758150100708
Validation loss: 2.3687604576028805

Epoch: 5| Step: 8
Training loss: 1.9635063409805298
Validation loss: 2.3487342916509157

Epoch: 5| Step: 9
Training loss: 2.571298599243164
Validation loss: 2.3250538969552643

Epoch: 5| Step: 10
Training loss: 2.689615249633789
Validation loss: 2.31443017016175

Epoch: 33| Step: 0
Training loss: 1.8969013690948486
Validation loss: 2.3164775576642764

Epoch: 5| Step: 1
Training loss: 2.937779664993286
Validation loss: 2.323844558449202

Epoch: 5| Step: 2
Training loss: 2.7724978923797607
Validation loss: 2.3154521142282793

Epoch: 5| Step: 3
Training loss: 2.6048216819763184
Validation loss: 2.3110750823892574

Epoch: 5| Step: 4
Training loss: 2.941999912261963
Validation loss: 2.309169371922811

Epoch: 5| Step: 5
Training loss: 2.270655393600464
Validation loss: 2.3103144297035794

Epoch: 5| Step: 6
Training loss: 2.410799026489258
Validation loss: 2.3272084548909175

Epoch: 5| Step: 7
Training loss: 2.3843095302581787
Validation loss: 2.3350813465733684

Epoch: 5| Step: 8
Training loss: 3.0458593368530273
Validation loss: 2.335940973733061

Epoch: 5| Step: 9
Training loss: 2.7114529609680176
Validation loss: 2.3174150092627412

Epoch: 5| Step: 10
Training loss: 2.521426200866699
Validation loss: 2.299649897442069

Epoch: 34| Step: 0
Training loss: 2.767058849334717
Validation loss: 2.292664658638739

Epoch: 5| Step: 1
Training loss: 2.47519588470459
Validation loss: 2.292008264090425

Epoch: 5| Step: 2
Training loss: 2.5141265392303467
Validation loss: 2.2987957205823673

Epoch: 5| Step: 3
Training loss: 3.169910430908203
Validation loss: 2.294011982538367

Epoch: 5| Step: 4
Training loss: 2.1888091564178467
Validation loss: 2.2940346323033816

Epoch: 5| Step: 5
Training loss: 1.9460843801498413
Validation loss: 2.2884992809705835

Epoch: 5| Step: 6
Training loss: 2.6036605834960938
Validation loss: 2.290425049361362

Epoch: 5| Step: 7
Training loss: 2.300312042236328
Validation loss: 2.2940273105457263

Epoch: 5| Step: 8
Training loss: 3.232667922973633
Validation loss: 2.2977707386016846

Epoch: 5| Step: 9
Training loss: 2.678680896759033
Validation loss: 2.3167110027805453

Epoch: 5| Step: 10
Training loss: 2.422306537628174
Validation loss: 2.314851701900523

Epoch: 35| Step: 0
Training loss: 2.82322359085083
Validation loss: 2.314486394646347

Epoch: 5| Step: 1
Training loss: 2.061513662338257
Validation loss: 2.3112502482629593

Epoch: 5| Step: 2
Training loss: 2.329251766204834
Validation loss: 2.3170096002599245

Epoch: 5| Step: 3
Training loss: 2.544999122619629
Validation loss: 2.288349691257682

Epoch: 5| Step: 4
Training loss: 2.6129262447357178
Validation loss: 2.2804496570300032

Epoch: 5| Step: 5
Training loss: 2.6944942474365234
Validation loss: 2.281155704170145

Epoch: 5| Step: 6
Training loss: 2.214212417602539
Validation loss: 2.277260411170221

Epoch: 5| Step: 7
Training loss: 2.8933842182159424
Validation loss: 2.2832349936167398

Epoch: 5| Step: 8
Training loss: 2.940718173980713
Validation loss: 2.2815603671535367

Epoch: 5| Step: 9
Training loss: 2.473496437072754
Validation loss: 2.2870503830653366

Epoch: 5| Step: 10
Training loss: 2.667022228240967
Validation loss: 2.3291375919054915

Epoch: 36| Step: 0
Training loss: 2.433615207672119
Validation loss: 2.344910257606096

Epoch: 5| Step: 1
Training loss: 3.3040192127227783
Validation loss: 2.3493814622202227

Epoch: 5| Step: 2
Training loss: 3.108762502670288
Validation loss: 2.346147483394992

Epoch: 5| Step: 3
Training loss: 2.538665294647217
Validation loss: 2.3498604477092786

Epoch: 5| Step: 4
Training loss: 2.6254584789276123
Validation loss: 2.354324563857048

Epoch: 5| Step: 5
Training loss: 2.9674911499023438
Validation loss: 2.370890350751979

Epoch: 5| Step: 6
Training loss: 2.7907636165618896
Validation loss: 2.3686500108370216

Epoch: 5| Step: 7
Training loss: 2.009922981262207
Validation loss: 2.355335135613718

Epoch: 5| Step: 8
Training loss: 2.3372128009796143
Validation loss: 2.338927835546514

Epoch: 5| Step: 9
Training loss: 1.7486603260040283
Validation loss: 2.310336248849028

Epoch: 5| Step: 10
Training loss: 2.5960636138916016
Validation loss: 2.2935882204322406

Epoch: 37| Step: 0
Training loss: 2.8285446166992188
Validation loss: 2.307670793225688

Epoch: 5| Step: 1
Training loss: 2.630251407623291
Validation loss: 2.335155035859795

Epoch: 5| Step: 2
Training loss: 2.8056652545928955
Validation loss: 2.361070981589697

Epoch: 5| Step: 3
Training loss: 2.5758092403411865
Validation loss: 2.3243292608568744

Epoch: 5| Step: 4
Training loss: 1.9838199615478516
Validation loss: 2.287480474800192

Epoch: 5| Step: 5
Training loss: 2.922466278076172
Validation loss: 2.2689276485032934

Epoch: 5| Step: 6
Training loss: 2.6373982429504395
Validation loss: 2.2726470783192623

Epoch: 5| Step: 7
Training loss: 2.338972806930542
Validation loss: 2.2639124957464074

Epoch: 5| Step: 8
Training loss: 2.2999165058135986
Validation loss: 2.2654891321735997

Epoch: 5| Step: 9
Training loss: 1.7673753499984741
Validation loss: 2.2582743770332745

Epoch: 5| Step: 10
Training loss: 3.449779748916626
Validation loss: 2.257805653797683

Epoch: 38| Step: 0
Training loss: 2.5161426067352295
Validation loss: 2.2589073296516173

Epoch: 5| Step: 1
Training loss: 2.437040328979492
Validation loss: 2.261707725063447

Epoch: 5| Step: 2
Training loss: 2.2764477729797363
Validation loss: 2.2554924872613724

Epoch: 5| Step: 3
Training loss: 2.7179951667785645
Validation loss: 2.2608248238922446

Epoch: 5| Step: 4
Training loss: 2.547302722930908
Validation loss: 2.272854596055964

Epoch: 5| Step: 5
Training loss: 2.4128589630126953
Validation loss: 2.2983303608432895

Epoch: 5| Step: 6
Training loss: 2.083630084991455
Validation loss: 2.3121400110183226

Epoch: 5| Step: 7
Training loss: 2.7086968421936035
Validation loss: 2.3240810004613732

Epoch: 5| Step: 8
Training loss: 2.7192845344543457
Validation loss: 2.3272157356303227

Epoch: 5| Step: 9
Training loss: 3.0152974128723145
Validation loss: 2.310478966723206

Epoch: 5| Step: 10
Training loss: 2.611081600189209
Validation loss: 2.281910155409126

Epoch: 39| Step: 0
Training loss: 2.4461846351623535
Validation loss: 2.264539708373367

Epoch: 5| Step: 1
Training loss: 2.9488637447357178
Validation loss: 2.2685673877757084

Epoch: 5| Step: 2
Training loss: 2.309521198272705
Validation loss: 2.274665568464546

Epoch: 5| Step: 3
Training loss: 2.749990463256836
Validation loss: 2.2712058610813592

Epoch: 5| Step: 4
Training loss: 2.4267947673797607
Validation loss: 2.2784684755468882

Epoch: 5| Step: 5
Training loss: 2.418980121612549
Validation loss: 2.28705947373503

Epoch: 5| Step: 6
Training loss: 2.2472732067108154
Validation loss: 2.311405017811765

Epoch: 5| Step: 7
Training loss: 2.4464809894561768
Validation loss: 2.3043514092763266

Epoch: 5| Step: 8
Training loss: 2.708885669708252
Validation loss: 2.300130162187802

Epoch: 5| Step: 9
Training loss: 2.948268413543701
Validation loss: 2.2893378580770185

Epoch: 5| Step: 10
Training loss: 2.29526948928833
Validation loss: 2.272791558696378

Epoch: 40| Step: 0
Training loss: 2.5004804134368896
Validation loss: 2.2771294706611225

Epoch: 5| Step: 1
Training loss: 2.6679234504699707
Validation loss: 2.262398878733317

Epoch: 5| Step: 2
Training loss: 2.297415018081665
Validation loss: 2.2602270854416715

Epoch: 5| Step: 3
Training loss: 3.2706997394561768
Validation loss: 2.2601444208493797

Epoch: 5| Step: 4
Training loss: 2.374904155731201
Validation loss: 2.254440984418315

Epoch: 5| Step: 5
Training loss: 2.17649507522583
Validation loss: 2.249506522250432

Epoch: 5| Step: 6
Training loss: 2.5637881755828857
Validation loss: 2.2584271738606114

Epoch: 5| Step: 7
Training loss: 2.0134389400482178
Validation loss: 2.262827797602582

Epoch: 5| Step: 8
Training loss: 3.0146172046661377
Validation loss: 2.2469299454842844

Epoch: 5| Step: 9
Training loss: 2.6953511238098145
Validation loss: 2.240299791418096

Epoch: 5| Step: 10
Training loss: 2.2962002754211426
Validation loss: 2.244371942294541

Epoch: 41| Step: 0
Training loss: 2.4630324840545654
Validation loss: 2.2588934513830368

Epoch: 5| Step: 1
Training loss: 2.8997976779937744
Validation loss: 2.301389096885599

Epoch: 5| Step: 2
Training loss: 2.8885886669158936
Validation loss: 2.290359386833765

Epoch: 5| Step: 3
Training loss: 2.4751734733581543
Validation loss: 2.317033088335427

Epoch: 5| Step: 4
Training loss: 1.7902978658676147
Validation loss: 2.299896127434187

Epoch: 5| Step: 5
Training loss: 3.2043075561523438
Validation loss: 2.309003224936865

Epoch: 5| Step: 6
Training loss: 2.957442283630371
Validation loss: 2.2869183248089207

Epoch: 5| Step: 7
Training loss: 2.1365973949432373
Validation loss: 2.2586479981740317

Epoch: 5| Step: 8
Training loss: 2.2779457569122314
Validation loss: 2.2726437635319208

Epoch: 5| Step: 9
Training loss: 2.3825714588165283
Validation loss: 2.2912585248229322

Epoch: 5| Step: 10
Training loss: 2.542447328567505
Validation loss: 2.2866932448520454

Epoch: 42| Step: 0
Training loss: 2.3608896732330322
Validation loss: 2.276991726249777

Epoch: 5| Step: 1
Training loss: 2.5274600982666016
Validation loss: 2.268504120970285

Epoch: 5| Step: 2
Training loss: 3.06973934173584
Validation loss: 2.255242560499458

Epoch: 5| Step: 3
Training loss: 2.6587576866149902
Validation loss: 2.242992457523141

Epoch: 5| Step: 4
Training loss: 2.7330596446990967
Validation loss: 2.2367306114524923

Epoch: 5| Step: 5
Training loss: 2.02252197265625
Validation loss: 2.2350683032825427

Epoch: 5| Step: 6
Training loss: 2.0182156562805176
Validation loss: 2.235263280971076

Epoch: 5| Step: 7
Training loss: 2.821239471435547
Validation loss: 2.254375348808945

Epoch: 5| Step: 8
Training loss: 2.35500431060791
Validation loss: 2.2848724601089314

Epoch: 5| Step: 9
Training loss: 2.4525701999664307
Validation loss: 2.296275261909731

Epoch: 5| Step: 10
Training loss: 2.886828899383545
Validation loss: 2.281570916534752

Epoch: 43| Step: 0
Training loss: 2.38203501701355
Validation loss: 2.249447637988675

Epoch: 5| Step: 1
Training loss: 2.3238277435302734
Validation loss: 2.258812186538532

Epoch: 5| Step: 2
Training loss: 3.5286240577697754
Validation loss: 2.269139030928253

Epoch: 5| Step: 3
Training loss: 2.310741424560547
Validation loss: 2.262830113851896

Epoch: 5| Step: 4
Training loss: 2.3061306476593018
Validation loss: 2.2634811401367188

Epoch: 5| Step: 5
Training loss: 2.302611827850342
Validation loss: 2.2556510638165217

Epoch: 5| Step: 6
Training loss: 2.056828022003174
Validation loss: 2.2450382350593485

Epoch: 5| Step: 7
Training loss: 2.3978848457336426
Validation loss: 2.255631926239178

Epoch: 5| Step: 8
Training loss: 2.8474793434143066
Validation loss: 2.26372698045546

Epoch: 5| Step: 9
Training loss: 2.8918471336364746
Validation loss: 2.241080322573262

Epoch: 5| Step: 10
Training loss: 2.6298396587371826
Validation loss: 2.2248309671237902

Epoch: 44| Step: 0
Training loss: 1.784637212753296
Validation loss: 2.2203685237515356

Epoch: 5| Step: 1
Training loss: 2.6699438095092773
Validation loss: 2.2203628760512157

Epoch: 5| Step: 2
Training loss: 2.660090446472168
Validation loss: 2.2345304386590117

Epoch: 5| Step: 3
Training loss: 2.5365188121795654
Validation loss: 2.2334423270276798

Epoch: 5| Step: 4
Training loss: 3.0859246253967285
Validation loss: 2.243356748293805

Epoch: 5| Step: 5
Training loss: 2.5557756423950195
Validation loss: 2.2391466068965133

Epoch: 5| Step: 6
Training loss: 2.690464735031128
Validation loss: 2.2262784204175396

Epoch: 5| Step: 7
Training loss: 2.125272512435913
Validation loss: 2.210663362215924

Epoch: 5| Step: 8
Training loss: 2.892122268676758
Validation loss: 2.210890103411931

Epoch: 5| Step: 9
Training loss: 2.422332286834717
Validation loss: 2.2098883595517886

Epoch: 5| Step: 10
Training loss: 2.568016529083252
Validation loss: 2.217889326874928

Epoch: 45| Step: 0
Training loss: 2.6462647914886475
Validation loss: 2.2671305338541665

Epoch: 5| Step: 1
Training loss: 2.68678617477417
Validation loss: 2.2843844582957606

Epoch: 5| Step: 2
Training loss: 1.863385558128357
Validation loss: 2.3057095055939048

Epoch: 5| Step: 3
Training loss: 2.6833865642547607
Validation loss: 2.264002482096354

Epoch: 5| Step: 4
Training loss: 2.257567882537842
Validation loss: 2.2628364639897502

Epoch: 5| Step: 5
Training loss: 3.360353946685791
Validation loss: 2.2505419203030166

Epoch: 5| Step: 6
Training loss: 2.4966399669647217
Validation loss: 2.2526116140427126

Epoch: 5| Step: 7
Training loss: 2.0192511081695557
Validation loss: 2.2473626572598695

Epoch: 5| Step: 8
Training loss: 2.3700900077819824
Validation loss: 2.246957773803383

Epoch: 5| Step: 9
Training loss: 2.627824306488037
Validation loss: 2.234195263155045

Epoch: 5| Step: 10
Training loss: 2.6976983547210693
Validation loss: 2.224028907796388

Epoch: 46| Step: 0
Training loss: 2.5109219551086426
Validation loss: 2.225908492201118

Epoch: 5| Step: 1
Training loss: 2.3391895294189453
Validation loss: 2.223914743751608

Epoch: 5| Step: 2
Training loss: 2.5825741291046143
Validation loss: 2.224286203743309

Epoch: 5| Step: 3
Training loss: 1.8606822490692139
Validation loss: 2.2356719996339534

Epoch: 5| Step: 4
Training loss: 2.882805347442627
Validation loss: 2.244222617918445

Epoch: 5| Step: 5
Training loss: 2.8447670936584473
Validation loss: 2.2370493027471725

Epoch: 5| Step: 6
Training loss: 2.6561503410339355
Validation loss: 2.227384715951899

Epoch: 5| Step: 7
Training loss: 2.1996114253997803
Validation loss: 2.2173309377444688

Epoch: 5| Step: 8
Training loss: 2.7336771488189697
Validation loss: 2.2308767226434525

Epoch: 5| Step: 9
Training loss: 2.2620153427124023
Validation loss: 2.2287651749067408

Epoch: 5| Step: 10
Training loss: 2.7786216735839844
Validation loss: 2.2481826351534937

Epoch: 47| Step: 0
Training loss: 2.680103063583374
Validation loss: 2.267827582615678

Epoch: 5| Step: 1
Training loss: 2.3705010414123535
Validation loss: 2.2748549740801574

Epoch: 5| Step: 2
Training loss: 3.3448798656463623
Validation loss: 2.305584579385737

Epoch: 5| Step: 3
Training loss: 2.1952269077301025
Validation loss: 2.2484392927538965

Epoch: 5| Step: 4
Training loss: 2.787313938140869
Validation loss: 2.210323727259072

Epoch: 5| Step: 5
Training loss: 2.6923670768737793
Validation loss: 2.185757214023221

Epoch: 5| Step: 6
Training loss: 2.125643491744995
Validation loss: 2.1829155747608473

Epoch: 5| Step: 7
Training loss: 2.506309986114502
Validation loss: 2.1816880600426787

Epoch: 5| Step: 8
Training loss: 2.4070546627044678
Validation loss: 2.1784020649489535

Epoch: 5| Step: 9
Training loss: 2.5077102184295654
Validation loss: 2.180938506639132

Epoch: 5| Step: 10
Training loss: 2.000342845916748
Validation loss: 2.179625913661013

Epoch: 48| Step: 0
Training loss: 3.2358925342559814
Validation loss: 2.1863357482417936

Epoch: 5| Step: 1
Training loss: 1.9342024326324463
Validation loss: 2.1992957745828936

Epoch: 5| Step: 2
Training loss: 2.0537593364715576
Validation loss: 2.2268184154264388

Epoch: 5| Step: 3
Training loss: 2.5092005729675293
Validation loss: 2.2521197078048543

Epoch: 5| Step: 4
Training loss: 2.8369204998016357
Validation loss: 2.2474699353659027

Epoch: 5| Step: 5
Training loss: 2.316148519515991
Validation loss: 2.210483535643547

Epoch: 5| Step: 6
Training loss: 3.1802918910980225
Validation loss: 2.1850375462603826

Epoch: 5| Step: 7
Training loss: 2.1665449142456055
Validation loss: 2.1799390008372646

Epoch: 5| Step: 8
Training loss: 2.4604554176330566
Validation loss: 2.2053397073540637

Epoch: 5| Step: 9
Training loss: 2.2497267723083496
Validation loss: 2.2408813520144393

Epoch: 5| Step: 10
Training loss: 2.548978090286255
Validation loss: 2.319778847438033

Epoch: 49| Step: 0
Training loss: 2.4728171825408936
Validation loss: 2.3366633487004105

Epoch: 5| Step: 1
Training loss: 2.904768705368042
Validation loss: 2.3126835720513457

Epoch: 5| Step: 2
Training loss: 2.7882003784179688
Validation loss: 2.2841669128787134

Epoch: 5| Step: 3
Training loss: 2.6717748641967773
Validation loss: 2.258466884654055

Epoch: 5| Step: 4
Training loss: 2.4856364727020264
Validation loss: 2.2288122818034184

Epoch: 5| Step: 5
Training loss: 2.256171226501465
Validation loss: 2.203869988841395

Epoch: 5| Step: 6
Training loss: 2.565807580947876
Validation loss: 2.186346855214847

Epoch: 5| Step: 7
Training loss: 2.794672727584839
Validation loss: 2.172409560090752

Epoch: 5| Step: 8
Training loss: 2.017578363418579
Validation loss: 2.170805094062641

Epoch: 5| Step: 9
Training loss: 2.410339832305908
Validation loss: 2.1845314707807315

Epoch: 5| Step: 10
Training loss: 1.9979196786880493
Validation loss: 2.1833883382940806

Epoch: 50| Step: 0
Training loss: 2.6183383464813232
Validation loss: 2.178055017225204

Epoch: 5| Step: 1
Training loss: 2.6279397010803223
Validation loss: 2.1815699992641324

Epoch: 5| Step: 2
Training loss: 2.85062575340271
Validation loss: 2.194968201780832

Epoch: 5| Step: 3
Training loss: 2.534363269805908
Validation loss: 2.198747214450631

Epoch: 5| Step: 4
Training loss: 2.7784342765808105
Validation loss: 2.2051299207954

Epoch: 5| Step: 5
Training loss: 2.1110899448394775
Validation loss: 2.199091770315683

Epoch: 5| Step: 6
Training loss: 2.5179078578948975
Validation loss: 2.176336714016494

Epoch: 5| Step: 7
Training loss: 2.1821255683898926
Validation loss: 2.170533111018519

Epoch: 5| Step: 8
Training loss: 2.2963366508483887
Validation loss: 2.182626885752524

Epoch: 5| Step: 9
Training loss: 2.204232931137085
Validation loss: 2.1900024593517347

Epoch: 5| Step: 10
Training loss: 2.5498597621917725
Validation loss: 2.2068478189488894

Epoch: 51| Step: 0
Training loss: 1.52561354637146
Validation loss: 2.2244673416178715

Epoch: 5| Step: 1
Training loss: 2.340597152709961
Validation loss: 2.256554880449849

Epoch: 5| Step: 2
Training loss: 3.156033992767334
Validation loss: 2.2461976492276756

Epoch: 5| Step: 3
Training loss: 2.778883457183838
Validation loss: 2.215772336529147

Epoch: 5| Step: 4
Training loss: 3.2646737098693848
Validation loss: 2.185110217781477

Epoch: 5| Step: 5
Training loss: 2.742762327194214
Validation loss: 2.1680990803626274

Epoch: 5| Step: 6
Training loss: 1.774190902709961
Validation loss: 2.159335031304308

Epoch: 5| Step: 7
Training loss: 2.6546592712402344
Validation loss: 2.150677952715146

Epoch: 5| Step: 8
Training loss: 1.511689305305481
Validation loss: 2.1527386762762584

Epoch: 5| Step: 9
Training loss: 2.8476061820983887
Validation loss: 2.15204527044809

Epoch: 5| Step: 10
Training loss: 2.6217541694641113
Validation loss: 2.1503195275542555

Epoch: 52| Step: 0
Training loss: 2.425541877746582
Validation loss: 2.149868756212214

Epoch: 5| Step: 1
Training loss: 2.843830108642578
Validation loss: 2.1424623612434632

Epoch: 5| Step: 2
Training loss: 2.774506092071533
Validation loss: 2.1402805518078547

Epoch: 5| Step: 3
Training loss: 1.870435357093811
Validation loss: 2.1411815676637875

Epoch: 5| Step: 4
Training loss: 2.4234843254089355
Validation loss: 2.141195515150665

Epoch: 5| Step: 5
Training loss: 2.026217222213745
Validation loss: 2.1456248888405423

Epoch: 5| Step: 6
Training loss: 2.6945345401763916
Validation loss: 2.1970957376623668

Epoch: 5| Step: 7
Training loss: 2.678213596343994
Validation loss: 2.23915667944057

Epoch: 5| Step: 8
Training loss: 2.188429594039917
Validation loss: 2.218777843700942

Epoch: 5| Step: 9
Training loss: 2.1086652278900146
Validation loss: 2.1747333157447075

Epoch: 5| Step: 10
Training loss: 3.194028854370117
Validation loss: 2.1576140619093374

Epoch: 53| Step: 0
Training loss: 2.3374545574188232
Validation loss: 2.1283226474638908

Epoch: 5| Step: 1
Training loss: 2.1769909858703613
Validation loss: 2.13023720249053

Epoch: 5| Step: 2
Training loss: 2.4375014305114746
Validation loss: 2.131248858667189

Epoch: 5| Step: 3
Training loss: 2.2326104640960693
Validation loss: 2.13452406596112

Epoch: 5| Step: 4
Training loss: 2.246030330657959
Validation loss: 2.1380150395054973

Epoch: 5| Step: 5
Training loss: 2.6841378211975098
Validation loss: 2.146336401662519

Epoch: 5| Step: 6
Training loss: 2.2573742866516113
Validation loss: 2.1396355129057363

Epoch: 5| Step: 7
Training loss: 3.002237558364868
Validation loss: 2.138150907331897

Epoch: 5| Step: 8
Training loss: 2.784019947052002
Validation loss: 2.134383696381764

Epoch: 5| Step: 9
Training loss: 2.353975772857666
Validation loss: 2.1383675811111287

Epoch: 5| Step: 10
Training loss: 2.577007293701172
Validation loss: 2.15021365175965

Epoch: 54| Step: 0
Training loss: 2.399259567260742
Validation loss: 2.1770425278653383

Epoch: 5| Step: 1
Training loss: 2.2950222492218018
Validation loss: 2.1792461038917623

Epoch: 5| Step: 2
Training loss: 2.2318637371063232
Validation loss: 2.172102105232977

Epoch: 5| Step: 3
Training loss: 2.8466951847076416
Validation loss: 2.1657798444071124

Epoch: 5| Step: 4
Training loss: 2.7038161754608154
Validation loss: 2.1514299120954288

Epoch: 5| Step: 5
Training loss: 2.69266676902771
Validation loss: 2.1449294718362952

Epoch: 5| Step: 6
Training loss: 2.6100234985351562
Validation loss: 2.1377726844561997

Epoch: 5| Step: 7
Training loss: 2.942415714263916
Validation loss: 2.1317116829656784

Epoch: 5| Step: 8
Training loss: 1.950282096862793
Validation loss: 2.1320419555069297

Epoch: 5| Step: 9
Training loss: 1.4677627086639404
Validation loss: 2.1303125709615727

Epoch: 5| Step: 10
Training loss: 2.7389538288116455
Validation loss: 2.131808320681254

Epoch: 55| Step: 0
Training loss: 2.346822738647461
Validation loss: 2.1509652060847126

Epoch: 5| Step: 1
Training loss: 2.3106367588043213
Validation loss: 2.17519651433473

Epoch: 5| Step: 2
Training loss: 2.1803932189941406
Validation loss: 2.202990552430512

Epoch: 5| Step: 3
Training loss: 2.595438003540039
Validation loss: 2.2006795175613894

Epoch: 5| Step: 4
Training loss: 2.4249675273895264
Validation loss: 2.1815569375150945

Epoch: 5| Step: 5
Training loss: 2.739558458328247
Validation loss: 2.1460303055342806

Epoch: 5| Step: 6
Training loss: 2.2592837810516357
Validation loss: 2.136431133875283

Epoch: 5| Step: 7
Training loss: 2.225689172744751
Validation loss: 2.1554332317844516

Epoch: 5| Step: 8
Training loss: 2.6152291297912598
Validation loss: 2.143254259581207

Epoch: 5| Step: 9
Training loss: 2.305095911026001
Validation loss: 2.137278719614911

Epoch: 5| Step: 10
Training loss: 3.1418323516845703
Validation loss: 2.1324349270072034

Epoch: 56| Step: 0
Training loss: 2.3989288806915283
Validation loss: 2.129917980522238

Epoch: 5| Step: 1
Training loss: 2.3613409996032715
Validation loss: 2.1446436400054605

Epoch: 5| Step: 2
Training loss: 2.300774335861206
Validation loss: 2.1474155738789547

Epoch: 5| Step: 3
Training loss: 2.421891689300537
Validation loss: 2.1638955736673005

Epoch: 5| Step: 4
Training loss: 2.175736427307129
Validation loss: 2.1799151077065417

Epoch: 5| Step: 5
Training loss: 2.3732311725616455
Validation loss: 2.1786671146269767

Epoch: 5| Step: 6
Training loss: 2.6502950191497803
Validation loss: 2.1651774888397544

Epoch: 5| Step: 7
Training loss: 1.7478630542755127
Validation loss: 2.1470486938312487

Epoch: 5| Step: 8
Training loss: 1.9094346761703491
Validation loss: 2.1410439040071223

Epoch: 5| Step: 9
Training loss: 3.673656940460205
Validation loss: 2.123227169436793

Epoch: 5| Step: 10
Training loss: 2.7325451374053955
Validation loss: 2.115873136828023

Epoch: 57| Step: 0
Training loss: 2.5192437171936035
Validation loss: 2.111150139121599

Epoch: 5| Step: 1
Training loss: 2.267137050628662
Validation loss: 2.112932494891587

Epoch: 5| Step: 2
Training loss: 2.1612913608551025
Validation loss: 2.1209198941466627

Epoch: 5| Step: 3
Training loss: 2.767439365386963
Validation loss: 2.123760179806781

Epoch: 5| Step: 4
Training loss: 2.327564239501953
Validation loss: 2.1534730439545005

Epoch: 5| Step: 5
Training loss: 1.9963229894638062
Validation loss: 2.166208092884351

Epoch: 5| Step: 6
Training loss: 2.3862338066101074
Validation loss: 2.1669459150683497

Epoch: 5| Step: 7
Training loss: 2.594730854034424
Validation loss: 2.167007392452609

Epoch: 5| Step: 8
Training loss: 2.66410493850708
Validation loss: 2.154895841434438

Epoch: 5| Step: 9
Training loss: 2.776007890701294
Validation loss: 2.146345453877603

Epoch: 5| Step: 10
Training loss: 2.3654685020446777
Validation loss: 2.139603719916395

Epoch: 58| Step: 0
Training loss: 2.4501194953918457
Validation loss: 2.1332684383597424

Epoch: 5| Step: 1
Training loss: 1.8604122400283813
Validation loss: 2.122231060458768

Epoch: 5| Step: 2
Training loss: 2.2749276161193848
Validation loss: 2.1168216697631346

Epoch: 5| Step: 3
Training loss: 2.439300775527954
Validation loss: 2.1175952957522486

Epoch: 5| Step: 4
Training loss: 2.7999744415283203
Validation loss: 2.1093450284773305

Epoch: 5| Step: 5
Training loss: 2.016364574432373
Validation loss: 2.1010390814914497

Epoch: 5| Step: 6
Training loss: 2.6648831367492676
Validation loss: 2.099774013283432

Epoch: 5| Step: 7
Training loss: 2.2250285148620605
Validation loss: 2.108252480465879

Epoch: 5| Step: 8
Training loss: 2.523391008377075
Validation loss: 2.1116321727793705

Epoch: 5| Step: 9
Training loss: 2.8659515380859375
Validation loss: 2.1381525711346696

Epoch: 5| Step: 10
Training loss: 2.4253101348876953
Validation loss: 2.1587123563212733

Epoch: 59| Step: 0
Training loss: 2.4719886779785156
Validation loss: 2.1887630954865487

Epoch: 5| Step: 1
Training loss: 1.6388862133026123
Validation loss: 2.1869552725104877

Epoch: 5| Step: 2
Training loss: 2.375213146209717
Validation loss: 2.2106308962709162

Epoch: 5| Step: 3
Training loss: 1.7793833017349243
Validation loss: 2.1619499421888784

Epoch: 5| Step: 4
Training loss: 2.4075093269348145
Validation loss: 2.1287831849949335

Epoch: 5| Step: 5
Training loss: 1.9110246896743774
Validation loss: 2.111724579206077

Epoch: 5| Step: 6
Training loss: 2.8842296600341797
Validation loss: 2.1052080239019086

Epoch: 5| Step: 7
Training loss: 2.716050624847412
Validation loss: 2.10765439720564

Epoch: 5| Step: 8
Training loss: 2.9098408222198486
Validation loss: 2.11780450933723

Epoch: 5| Step: 9
Training loss: 2.3033859729766846
Validation loss: 2.107811315085298

Epoch: 5| Step: 10
Training loss: 3.353844404220581
Validation loss: 2.0984495352673274

Epoch: 60| Step: 0
Training loss: 2.660283327102661
Validation loss: 2.0968684227235856

Epoch: 5| Step: 1
Training loss: 2.277064800262451
Validation loss: 2.0901267054260417

Epoch: 5| Step: 2
Training loss: 2.2804713249206543
Validation loss: 2.089712304453696

Epoch: 5| Step: 3
Training loss: 2.122180223464966
Validation loss: 2.0972047864749865

Epoch: 5| Step: 4
Training loss: 2.644667148590088
Validation loss: 2.1033297020901918

Epoch: 5| Step: 5
Training loss: 2.3503477573394775
Validation loss: 2.1203848367096274

Epoch: 5| Step: 6
Training loss: 1.823555588722229
Validation loss: 2.1439996739869476

Epoch: 5| Step: 7
Training loss: 2.8814613819122314
Validation loss: 2.1774658926071657

Epoch: 5| Step: 8
Training loss: 1.7736530303955078
Validation loss: 2.207242965698242

Epoch: 5| Step: 9
Training loss: 2.794994831085205
Validation loss: 2.191297951564994

Epoch: 5| Step: 10
Training loss: 2.8658382892608643
Validation loss: 2.182011942709646

Epoch: 61| Step: 0
Training loss: 2.137979745864868
Validation loss: 2.1737232695343676

Epoch: 5| Step: 1
Training loss: 2.5848770141601562
Validation loss: 2.150349070948939

Epoch: 5| Step: 2
Training loss: 2.0614285469055176
Validation loss: 2.1317866399723995

Epoch: 5| Step: 3
Training loss: 2.7390458583831787
Validation loss: 2.136339931077855

Epoch: 5| Step: 4
Training loss: 2.3162670135498047
Validation loss: 2.1487143296067432

Epoch: 5| Step: 5
Training loss: 2.423464298248291
Validation loss: 2.15777555460571

Epoch: 5| Step: 6
Training loss: 2.3648555278778076
Validation loss: 2.16789871902876

Epoch: 5| Step: 7
Training loss: 2.7634501457214355
Validation loss: 2.142239761608903

Epoch: 5| Step: 8
Training loss: 2.8912715911865234
Validation loss: 2.1318071452520226

Epoch: 5| Step: 9
Training loss: 1.9185025691986084
Validation loss: 2.112915668436276

Epoch: 5| Step: 10
Training loss: 2.36389422416687
Validation loss: 2.114474232478808

Epoch: 62| Step: 0
Training loss: 1.9913034439086914
Validation loss: 2.1314956552238873

Epoch: 5| Step: 1
Training loss: 2.2109603881835938
Validation loss: 2.173913291705552

Epoch: 5| Step: 2
Training loss: 3.330361843109131
Validation loss: 2.225331926858553

Epoch: 5| Step: 3
Training loss: 2.2810797691345215
Validation loss: 2.268331238018569

Epoch: 5| Step: 4
Training loss: 2.9511666297912598
Validation loss: 2.2392775897056825

Epoch: 5| Step: 5
Training loss: 2.2508256435394287
Validation loss: 2.160533989629438

Epoch: 5| Step: 6
Training loss: 2.298983097076416
Validation loss: 2.1178168776214763

Epoch: 5| Step: 7
Training loss: 2.1198418140411377
Validation loss: 2.1066681108167096

Epoch: 5| Step: 8
Training loss: 2.1434521675109863
Validation loss: 2.0963345599430863

Epoch: 5| Step: 9
Training loss: 2.5015335083007812
Validation loss: 2.097750497120683

Epoch: 5| Step: 10
Training loss: 2.5492429733276367
Validation loss: 2.0841637683171097

Epoch: 63| Step: 0
Training loss: 2.229757785797119
Validation loss: 2.079152394366521

Epoch: 5| Step: 1
Training loss: 2.2559456825256348
Validation loss: 2.0792897619226927

Epoch: 5| Step: 2
Training loss: 3.010139226913452
Validation loss: 2.0714839466156496

Epoch: 5| Step: 3
Training loss: 2.3196494579315186
Validation loss: 2.0792051643453617

Epoch: 5| Step: 4
Training loss: 1.576324224472046
Validation loss: 2.082355805622634

Epoch: 5| Step: 5
Training loss: 2.8787660598754883
Validation loss: 2.0907685141409598

Epoch: 5| Step: 6
Training loss: 2.196321487426758
Validation loss: 2.0965650978908745

Epoch: 5| Step: 7
Training loss: 2.249094009399414
Validation loss: 2.1058123201452275

Epoch: 5| Step: 8
Training loss: 1.9638671875
Validation loss: 2.1018298454182123

Epoch: 5| Step: 9
Training loss: 2.825890302658081
Validation loss: 2.0986045714347594

Epoch: 5| Step: 10
Training loss: 2.9711527824401855
Validation loss: 2.087232735849196

Epoch: 64| Step: 0
Training loss: 1.980531096458435
Validation loss: 2.0735921705922773

Epoch: 5| Step: 1
Training loss: 1.985943078994751
Validation loss: 2.0608371714110016

Epoch: 5| Step: 2
Training loss: 2.389113664627075
Validation loss: 2.062731639031441

Epoch: 5| Step: 3
Training loss: 2.50627064704895
Validation loss: 2.0620061710316646

Epoch: 5| Step: 4
Training loss: 2.0454797744750977
Validation loss: 2.0666768832873275

Epoch: 5| Step: 5
Training loss: 2.217327117919922
Validation loss: 2.0702993433962584

Epoch: 5| Step: 6
Training loss: 2.962064027786255
Validation loss: 2.0682971246780886

Epoch: 5| Step: 7
Training loss: 2.1864538192749023
Validation loss: 2.0756553449938373

Epoch: 5| Step: 8
Training loss: 2.5591793060302734
Validation loss: 2.094491248489708

Epoch: 5| Step: 9
Training loss: 2.7976479530334473
Validation loss: 2.1184518542341007

Epoch: 5| Step: 10
Training loss: 2.7394752502441406
Validation loss: 2.11345322157747

Epoch: 65| Step: 0
Training loss: 2.8335702419281006
Validation loss: 2.116439511699061

Epoch: 5| Step: 1
Training loss: 2.4647326469421387
Validation loss: 2.1311802197528142

Epoch: 5| Step: 2
Training loss: 2.71787691116333
Validation loss: 2.1156682827139415

Epoch: 5| Step: 3
Training loss: 2.2076926231384277
Validation loss: 2.0996364419178297

Epoch: 5| Step: 4
Training loss: 1.9287189245224
Validation loss: 2.0903444456797775

Epoch: 5| Step: 5
Training loss: 1.9969943761825562
Validation loss: 2.0872546677948325

Epoch: 5| Step: 6
Training loss: 2.9586150646209717
Validation loss: 2.091010121889012

Epoch: 5| Step: 7
Training loss: 2.019542694091797
Validation loss: 2.0923428714916272

Epoch: 5| Step: 8
Training loss: 2.1532645225524902
Validation loss: 2.094248503767034

Epoch: 5| Step: 9
Training loss: 2.1667745113372803
Validation loss: 2.1034695897051083

Epoch: 5| Step: 10
Training loss: 2.761807680130005
Validation loss: 2.1076887243537494

Epoch: 66| Step: 0
Training loss: 2.4499075412750244
Validation loss: 2.10007671899693

Epoch: 5| Step: 1
Training loss: 2.6385622024536133
Validation loss: 2.104394999883508

Epoch: 5| Step: 2
Training loss: 2.7165932655334473
Validation loss: 2.090324109600436

Epoch: 5| Step: 3
Training loss: 2.7721261978149414
Validation loss: 2.0924619013263333

Epoch: 5| Step: 4
Training loss: 2.6875386238098145
Validation loss: 2.085359263163741

Epoch: 5| Step: 5
Training loss: 2.6887784004211426
Validation loss: 2.0904849626684703

Epoch: 5| Step: 6
Training loss: 2.0833892822265625
Validation loss: 2.0865767617379465

Epoch: 5| Step: 7
Training loss: 1.1350599527359009
Validation loss: 2.108949843273368

Epoch: 5| Step: 8
Training loss: 2.1092400550842285
Validation loss: 2.1272395195499545

Epoch: 5| Step: 9
Training loss: 2.095266342163086
Validation loss: 2.108373406112835

Epoch: 5| Step: 10
Training loss: 2.6096346378326416
Validation loss: 2.093087593714396

Epoch: 67| Step: 0
Training loss: 2.6442041397094727
Validation loss: 2.0774371290719635

Epoch: 5| Step: 1
Training loss: 2.0963997840881348
Validation loss: 2.089461220208035

Epoch: 5| Step: 2
Training loss: 2.7587881088256836
Validation loss: 2.072135115182528

Epoch: 5| Step: 3
Training loss: 2.6838161945343018
Validation loss: 2.074416527184107

Epoch: 5| Step: 4
Training loss: 2.288036823272705
Validation loss: 2.0638316780008297

Epoch: 5| Step: 5
Training loss: 1.943498969078064
Validation loss: 2.0606685633300454

Epoch: 5| Step: 6
Training loss: 2.7091174125671387
Validation loss: 2.054951596003707

Epoch: 5| Step: 7
Training loss: 2.1786048412323
Validation loss: 2.0584579129372873

Epoch: 5| Step: 8
Training loss: 2.0874404907226562
Validation loss: 2.0587438793592554

Epoch: 5| Step: 9
Training loss: 2.128941297531128
Validation loss: 2.0669179911254556

Epoch: 5| Step: 10
Training loss: 2.439012050628662
Validation loss: 2.0724042205400366

Epoch: 68| Step: 0
Training loss: 1.8544881343841553
Validation loss: 2.0799826127226635

Epoch: 5| Step: 1
Training loss: 2.409389019012451
Validation loss: 2.0670548331352974

Epoch: 5| Step: 2
Training loss: 1.767599105834961
Validation loss: 2.061695905141933

Epoch: 5| Step: 3
Training loss: 2.3456499576568604
Validation loss: 2.069493793672131

Epoch: 5| Step: 4
Training loss: 2.594712018966675
Validation loss: 2.0682437214800107

Epoch: 5| Step: 5
Training loss: 2.7907276153564453
Validation loss: 2.0624185095551195

Epoch: 5| Step: 6
Training loss: 2.552640438079834
Validation loss: 2.0487038781566005

Epoch: 5| Step: 7
Training loss: 2.7949931621551514
Validation loss: 2.048245060828424

Epoch: 5| Step: 8
Training loss: 2.3639943599700928
Validation loss: 2.0420262044475925

Epoch: 5| Step: 9
Training loss: 2.360957384109497
Validation loss: 2.0417868155305103

Epoch: 5| Step: 10
Training loss: 1.9038465023040771
Validation loss: 2.0396813782312537

Epoch: 69| Step: 0
Training loss: 1.4896451234817505
Validation loss: 2.0506662578992945

Epoch: 5| Step: 1
Training loss: 2.9406051635742188
Validation loss: 2.059995230808053

Epoch: 5| Step: 2
Training loss: 2.6727325916290283
Validation loss: 2.080927465551643

Epoch: 5| Step: 3
Training loss: 1.855187177658081
Validation loss: 2.094490130742391

Epoch: 5| Step: 4
Training loss: 2.3510704040527344
Validation loss: 2.0878227590232767

Epoch: 5| Step: 5
Training loss: 2.2855563163757324
Validation loss: 2.078194729743465

Epoch: 5| Step: 6
Training loss: 2.599367618560791
Validation loss: 2.0858383652984456

Epoch: 5| Step: 7
Training loss: 2.0806376934051514
Validation loss: 2.0578741540190992

Epoch: 5| Step: 8
Training loss: 2.337681293487549
Validation loss: 2.065824585576211

Epoch: 5| Step: 9
Training loss: 2.519073247909546
Validation loss: 2.0830104530498548

Epoch: 5| Step: 10
Training loss: 2.861135482788086
Validation loss: 2.0837613792829615

Epoch: 70| Step: 0
Training loss: 2.5120747089385986
Validation loss: 2.0885716638257428

Epoch: 5| Step: 1
Training loss: 2.659815549850464
Validation loss: 2.0727382436875375

Epoch: 5| Step: 2
Training loss: 2.4413352012634277
Validation loss: 2.0749719681278354

Epoch: 5| Step: 3
Training loss: 1.951428771018982
Validation loss: 2.059882302438059

Epoch: 5| Step: 4
Training loss: 1.5105488300323486
Validation loss: 2.0497486565702703

Epoch: 5| Step: 5
Training loss: 2.998812437057495
Validation loss: 2.0446803185247604

Epoch: 5| Step: 6
Training loss: 3.0384292602539062
Validation loss: 2.052519339387135

Epoch: 5| Step: 7
Training loss: 2.141920804977417
Validation loss: 2.0484287661890828

Epoch: 5| Step: 8
Training loss: 2.3929712772369385
Validation loss: 2.041374878216815

Epoch: 5| Step: 9
Training loss: 2.1880598068237305
Validation loss: 2.0491917594786613

Epoch: 5| Step: 10
Training loss: 1.707719087600708
Validation loss: 2.038314127152966

Epoch: 71| Step: 0
Training loss: 2.2681386470794678
Validation loss: 2.048414438001571

Epoch: 5| Step: 1
Training loss: 2.821812391281128
Validation loss: 2.0509352709657405

Epoch: 5| Step: 2
Training loss: 2.6589465141296387
Validation loss: 2.0603551505714335

Epoch: 5| Step: 3
Training loss: 2.5596110820770264
Validation loss: 2.0803737153289137

Epoch: 5| Step: 4
Training loss: 1.8014390468597412
Validation loss: 2.0909144365659325

Epoch: 5| Step: 5
Training loss: 1.821671724319458
Validation loss: 2.107273896535238

Epoch: 5| Step: 6
Training loss: 2.408958911895752
Validation loss: 2.075884331939041

Epoch: 5| Step: 7
Training loss: 2.007136344909668
Validation loss: 2.0588352398205827

Epoch: 5| Step: 8
Training loss: 2.039034366607666
Validation loss: 2.035289681085976

Epoch: 5| Step: 9
Training loss: 2.5417001247406006
Validation loss: 2.02606193224589

Epoch: 5| Step: 10
Training loss: 2.946465492248535
Validation loss: 2.0338346573614303

Epoch: 72| Step: 0
Training loss: 2.1302809715270996
Validation loss: 2.035316091711803

Epoch: 5| Step: 1
Training loss: 2.0199084281921387
Validation loss: 2.0221642230146673

Epoch: 5| Step: 2
Training loss: 2.34745454788208
Validation loss: 2.0204436009930027

Epoch: 5| Step: 3
Training loss: 2.4437553882598877
Validation loss: 2.03935557411563

Epoch: 5| Step: 4
Training loss: 2.3972229957580566
Validation loss: 2.0482539925523984

Epoch: 5| Step: 5
Training loss: 2.1581854820251465
Validation loss: 2.039688533352267

Epoch: 5| Step: 6
Training loss: 2.2846567630767822
Validation loss: 2.049120642805612

Epoch: 5| Step: 7
Training loss: 2.1882643699645996
Validation loss: 2.0489213902463197

Epoch: 5| Step: 8
Training loss: 2.7365431785583496
Validation loss: 2.0761854956226964

Epoch: 5| Step: 9
Training loss: 2.5424015522003174
Validation loss: 2.0736186965819328

Epoch: 5| Step: 10
Training loss: 2.5354537963867188
Validation loss: 2.078068102559736

Epoch: 73| Step: 0
Training loss: 2.1304221153259277
Validation loss: 2.065172541526056

Epoch: 5| Step: 1
Training loss: 1.906162977218628
Validation loss: 2.0457724037990777

Epoch: 5| Step: 2
Training loss: 2.130955457687378
Validation loss: 2.038058239926574

Epoch: 5| Step: 3
Training loss: 2.5132503509521484
Validation loss: 2.0323651708582395

Epoch: 5| Step: 4
Training loss: 2.1288466453552246
Validation loss: 2.0399911493383427

Epoch: 5| Step: 5
Training loss: 3.032186985015869
Validation loss: 2.027074868961047

Epoch: 5| Step: 6
Training loss: 2.1209957599639893
Validation loss: 2.0352797867149435

Epoch: 5| Step: 7
Training loss: 2.0993144512176514
Validation loss: 2.0422703373816704

Epoch: 5| Step: 8
Training loss: 2.946075916290283
Validation loss: 2.052563093041861

Epoch: 5| Step: 9
Training loss: 2.047022581100464
Validation loss: 2.0446629793413225

Epoch: 5| Step: 10
Training loss: 2.4150986671447754
Validation loss: 2.0410063074481104

Epoch: 74| Step: 0
Training loss: 1.6326593160629272
Validation loss: 2.0526665077414563

Epoch: 5| Step: 1
Training loss: 2.15258526802063
Validation loss: 2.0575291187532487

Epoch: 5| Step: 2
Training loss: 2.5110559463500977
Validation loss: 2.0557060997973204

Epoch: 5| Step: 3
Training loss: 2.2310080528259277
Validation loss: 2.0469764586417907

Epoch: 5| Step: 4
Training loss: 2.5939133167266846
Validation loss: 2.0590362497555312

Epoch: 5| Step: 5
Training loss: 2.876530885696411
Validation loss: 2.052954225129979

Epoch: 5| Step: 6
Training loss: 1.899510383605957
Validation loss: 2.0272201979032127

Epoch: 5| Step: 7
Training loss: 1.9616382122039795
Validation loss: 2.007539327426623

Epoch: 5| Step: 8
Training loss: 2.6591858863830566
Validation loss: 2.028503248768468

Epoch: 5| Step: 9
Training loss: 2.0988259315490723
Validation loss: 2.041098011437283

Epoch: 5| Step: 10
Training loss: 2.8646907806396484
Validation loss: 2.056536014362048

Epoch: 75| Step: 0
Training loss: 2.087872266769409
Validation loss: 2.059569498544098

Epoch: 5| Step: 1
Training loss: 2.4555864334106445
Validation loss: 2.0552846911132976

Epoch: 5| Step: 2
Training loss: 2.168224573135376
Validation loss: 2.029218363505538

Epoch: 5| Step: 3
Training loss: 2.1159894466400146
Validation loss: 2.022025437765224

Epoch: 5| Step: 4
Training loss: 2.2368457317352295
Validation loss: 2.028186326385826

Epoch: 5| Step: 5
Training loss: 2.406374216079712
Validation loss: 2.0515045017324467

Epoch: 5| Step: 6
Training loss: 2.4057259559631348
Validation loss: 2.0851119538789153

Epoch: 5| Step: 7
Training loss: 2.4677116870880127
Validation loss: 2.113538749756352

Epoch: 5| Step: 8
Training loss: 3.082479238510132
Validation loss: 2.11684662295926

Epoch: 5| Step: 9
Training loss: 2.3725426197052
Validation loss: 2.1017130292871946

Epoch: 5| Step: 10
Training loss: 2.233829975128174
Validation loss: 2.0643423885427494

Epoch: 76| Step: 0
Training loss: 2.4123802185058594
Validation loss: 2.0256154716655774

Epoch: 5| Step: 1
Training loss: 1.9349088668823242
Validation loss: 2.0275429448773785

Epoch: 5| Step: 2
Training loss: 3.0060057640075684
Validation loss: 2.038671334584554

Epoch: 5| Step: 3
Training loss: 1.9530904293060303
Validation loss: 2.0790311892827353

Epoch: 5| Step: 4
Training loss: 1.7217833995819092
Validation loss: 2.0666643291391353

Epoch: 5| Step: 5
Training loss: 2.612539768218994
Validation loss: 2.0471964600265666

Epoch: 5| Step: 6
Training loss: 2.4037113189697266
Validation loss: 2.039285990499681

Epoch: 5| Step: 7
Training loss: 2.6177706718444824
Validation loss: 2.020379002376269

Epoch: 5| Step: 8
Training loss: 2.063396692276001
Validation loss: 2.0388840603572067

Epoch: 5| Step: 9
Training loss: 2.830317974090576
Validation loss: 2.061139657933225

Epoch: 5| Step: 10
Training loss: 1.9388140439987183
Validation loss: 2.122766713942251

Epoch: 77| Step: 0
Training loss: 2.142068386077881
Validation loss: 2.229800142267699

Epoch: 5| Step: 1
Training loss: 3.1383056640625
Validation loss: 2.2687313684853176

Epoch: 5| Step: 2
Training loss: 2.523385524749756
Validation loss: 2.21511403206856

Epoch: 5| Step: 3
Training loss: 1.967678427696228
Validation loss: 2.155327812317879

Epoch: 5| Step: 4
Training loss: 2.081496477127075
Validation loss: 2.0670930518898913

Epoch: 5| Step: 5
Training loss: 2.1222968101501465
Validation loss: 2.036051739928543

Epoch: 5| Step: 6
Training loss: 2.596428632736206
Validation loss: 2.0200114839820453

Epoch: 5| Step: 7
Training loss: 2.083547353744507
Validation loss: 2.0182237253394177

Epoch: 5| Step: 8
Training loss: 2.270092487335205
Validation loss: 2.042396953029017

Epoch: 5| Step: 9
Training loss: 2.3152236938476562
Validation loss: 2.0527461036559074

Epoch: 5| Step: 10
Training loss: 2.4428458213806152
Validation loss: 2.060926902678705

Epoch: 78| Step: 0
Training loss: 2.3292150497436523
Validation loss: 2.0994302457378757

Epoch: 5| Step: 1
Training loss: 1.9635740518569946
Validation loss: 2.0608892902251212

Epoch: 5| Step: 2
Training loss: 2.6914143562316895
Validation loss: 2.036812843814973

Epoch: 5| Step: 3
Training loss: 1.8874537944793701
Validation loss: 2.0598305989337224

Epoch: 5| Step: 4
Training loss: 2.577345132827759
Validation loss: 2.065336517108384

Epoch: 5| Step: 5
Training loss: 2.207670211791992
Validation loss: 2.0674025397146902

Epoch: 5| Step: 6
Training loss: 2.2190096378326416
Validation loss: 2.0651722646528676

Epoch: 5| Step: 7
Training loss: 2.15472674369812
Validation loss: 2.0889205432707265

Epoch: 5| Step: 8
Training loss: 2.700873851776123
Validation loss: 2.0942142522463234

Epoch: 5| Step: 9
Training loss: 1.8210407495498657
Validation loss: 2.087454729182746

Epoch: 5| Step: 10
Training loss: 2.9993395805358887
Validation loss: 2.0870033951215845

Epoch: 79| Step: 0
Training loss: 2.7231626510620117
Validation loss: 2.0861593497696744

Epoch: 5| Step: 1
Training loss: 2.0581016540527344
Validation loss: 2.0689068596850158

Epoch: 5| Step: 2
Training loss: 1.9177539348602295
Validation loss: 2.0438670624968824

Epoch: 5| Step: 3
Training loss: 1.8826711177825928
Validation loss: 2.0255501449749036

Epoch: 5| Step: 4
Training loss: 2.0307579040527344
Validation loss: 2.011484715246385

Epoch: 5| Step: 5
Training loss: 2.7036139965057373
Validation loss: 2.0013898239340833

Epoch: 5| Step: 6
Training loss: 2.2547526359558105
Validation loss: 1.9905854271304222

Epoch: 5| Step: 7
Training loss: 2.4361860752105713
Validation loss: 2.0006164363635484

Epoch: 5| Step: 8
Training loss: 2.4374356269836426
Validation loss: 1.9874476591746013

Epoch: 5| Step: 9
Training loss: 2.0600998401641846
Validation loss: 1.9970846201783867

Epoch: 5| Step: 10
Training loss: 2.8022143840789795
Validation loss: 2.0018563270568848

Epoch: 80| Step: 0
Training loss: 2.146202802658081
Validation loss: 1.9987613924088017

Epoch: 5| Step: 1
Training loss: 1.7167809009552002
Validation loss: 2.000978228866413

Epoch: 5| Step: 2
Training loss: 1.8575286865234375
Validation loss: 2.0045940927279893

Epoch: 5| Step: 3
Training loss: 2.499746799468994
Validation loss: 2.0048725399919736

Epoch: 5| Step: 4
Training loss: 1.9768822193145752
Validation loss: 2.0275976093866492

Epoch: 5| Step: 5
Training loss: 1.8418169021606445
Validation loss: 2.028964396445982

Epoch: 5| Step: 6
Training loss: 3.352257251739502
Validation loss: 2.072204943626158

Epoch: 5| Step: 7
Training loss: 2.506354808807373
Validation loss: 2.0837737360308246

Epoch: 5| Step: 8
Training loss: 2.7674973011016846
Validation loss: 2.0660752352847847

Epoch: 5| Step: 9
Training loss: 2.329148769378662
Validation loss: 2.040072568001286

Epoch: 5| Step: 10
Training loss: 2.4901986122131348
Validation loss: 2.0221281256726993

Epoch: 81| Step: 0
Training loss: 2.6332430839538574
Validation loss: 2.014109757638747

Epoch: 5| Step: 1
Training loss: 2.612257480621338
Validation loss: 2.037578682745657

Epoch: 5| Step: 2
Training loss: 2.1111350059509277
Validation loss: 2.0829351691789526

Epoch: 5| Step: 3
Training loss: 2.4754490852355957
Validation loss: 2.0976024699467484

Epoch: 5| Step: 4
Training loss: 2.3623623847961426
Validation loss: 2.054685356796429

Epoch: 5| Step: 5
Training loss: 2.1106362342834473
Validation loss: 2.0324995927913214

Epoch: 5| Step: 6
Training loss: 2.6050610542297363
Validation loss: 2.0302380797683552

Epoch: 5| Step: 7
Training loss: 1.7561614513397217
Validation loss: 2.0512295717834146

Epoch: 5| Step: 8
Training loss: 2.535714864730835
Validation loss: 2.0803234807906614

Epoch: 5| Step: 9
Training loss: 2.1175131797790527
Validation loss: 2.140952112854168

Epoch: 5| Step: 10
Training loss: 2.2457761764526367
Validation loss: 2.1611105831720496

Epoch: 82| Step: 0
Training loss: 2.2947208881378174
Validation loss: 2.121965439088883

Epoch: 5| Step: 1
Training loss: 2.5569891929626465
Validation loss: 2.0352249196780625

Epoch: 5| Step: 2
Training loss: 2.01951003074646
Validation loss: 1.997172200551597

Epoch: 5| Step: 3
Training loss: 1.5059897899627686
Validation loss: 1.992628312879993

Epoch: 5| Step: 4
Training loss: 2.7441582679748535
Validation loss: 2.0062909228827364

Epoch: 5| Step: 5
Training loss: 2.6506550312042236
Validation loss: 2.033447404061594

Epoch: 5| Step: 6
Training loss: 2.4735641479492188
Validation loss: 2.011125600466164

Epoch: 5| Step: 7
Training loss: 1.6050010919570923
Validation loss: 1.9926409375283025

Epoch: 5| Step: 8
Training loss: 2.2675952911376953
Validation loss: 1.9804760897031395

Epoch: 5| Step: 9
Training loss: 2.6003940105438232
Validation loss: 1.9909498268558132

Epoch: 5| Step: 10
Training loss: 2.5969431400299072
Validation loss: 1.9876452107583322

Epoch: 83| Step: 0
Training loss: 2.491818904876709
Validation loss: 1.9850604713604014

Epoch: 5| Step: 1
Training loss: 2.2576980590820312
Validation loss: 1.989551700571532

Epoch: 5| Step: 2
Training loss: 2.090514659881592
Validation loss: 1.9902003580524075

Epoch: 5| Step: 3
Training loss: 2.7924022674560547
Validation loss: 1.9967274691468926

Epoch: 5| Step: 4
Training loss: 2.157041072845459
Validation loss: 2.024891743095972

Epoch: 5| Step: 5
Training loss: 2.532623767852783
Validation loss: 2.061709139936714

Epoch: 5| Step: 6
Training loss: 2.009359359741211
Validation loss: 2.076426613715387

Epoch: 5| Step: 7
Training loss: 2.0900683403015137
Validation loss: 2.0670601065440843

Epoch: 5| Step: 8
Training loss: 2.5073115825653076
Validation loss: 2.0200906850958384

Epoch: 5| Step: 9
Training loss: 2.043152332305908
Validation loss: 1.9892733814895793

Epoch: 5| Step: 10
Training loss: 2.5071544647216797
Validation loss: 1.9922031382078766

Epoch: 84| Step: 0
Training loss: 2.465900421142578
Validation loss: 2.0257170328529934

Epoch: 5| Step: 1
Training loss: 2.7955636978149414
Validation loss: 2.0919911861419678

Epoch: 5| Step: 2
Training loss: 2.157827615737915
Validation loss: 2.155072719820084

Epoch: 5| Step: 3
Training loss: 2.3872060775756836
Validation loss: 2.1809778982593166

Epoch: 5| Step: 4
Training loss: 2.5508151054382324
Validation loss: 2.178301303617416

Epoch: 5| Step: 5
Training loss: 2.6212573051452637
Validation loss: 2.1430342812691965

Epoch: 5| Step: 6
Training loss: 2.000638484954834
Validation loss: 2.1017780457773516

Epoch: 5| Step: 7
Training loss: 3.182791233062744
Validation loss: 2.0655435669806694

Epoch: 5| Step: 8
Training loss: 2.1360530853271484
Validation loss: 2.029459479034588

Epoch: 5| Step: 9
Training loss: 1.8065223693847656
Validation loss: 2.0331107839461295

Epoch: 5| Step: 10
Training loss: 2.8949670791625977
Validation loss: 2.109927490193357

Epoch: 85| Step: 0
Training loss: 2.1421780586242676
Validation loss: 2.200410355803787

Epoch: 5| Step: 1
Training loss: 2.928152561187744
Validation loss: 2.200799206251739

Epoch: 5| Step: 2
Training loss: 2.1496729850769043
Validation loss: 2.1917703766976633

Epoch: 5| Step: 3
Training loss: 2.399752378463745
Validation loss: 2.1509443636863463

Epoch: 5| Step: 4
Training loss: 2.5181632041931152
Validation loss: 2.1061774171808714

Epoch: 5| Step: 5
Training loss: 2.1795284748077393
Validation loss: 2.038131918958438

Epoch: 5| Step: 6
Training loss: 2.3171353340148926
Validation loss: 1.9870964378438971

Epoch: 5| Step: 7
Training loss: 1.6992648839950562
Validation loss: 1.965929574863885

Epoch: 5| Step: 8
Training loss: 2.4083428382873535
Validation loss: 1.957169594303254

Epoch: 5| Step: 9
Training loss: 2.2172200679779053
Validation loss: 1.9599713221673043

Epoch: 5| Step: 10
Training loss: 2.9317448139190674
Validation loss: 1.9583994342434792

Epoch: 86| Step: 0
Training loss: 2.5822088718414307
Validation loss: 1.9562846050467542

Epoch: 5| Step: 1
Training loss: 2.1618614196777344
Validation loss: 1.9715146326249646

Epoch: 5| Step: 2
Training loss: 2.2453675270080566
Validation loss: 2.0072958277117823

Epoch: 5| Step: 3
Training loss: 1.6820738315582275
Validation loss: 2.028592135316582

Epoch: 5| Step: 4
Training loss: 2.6511054039001465
Validation loss: 2.060865168930382

Epoch: 5| Step: 5
Training loss: 2.7147998809814453
Validation loss: 2.0452329433092507

Epoch: 5| Step: 6
Training loss: 2.5435287952423096
Validation loss: 2.016282573823006

Epoch: 5| Step: 7
Training loss: 1.506571888923645
Validation loss: 2.012580402435795

Epoch: 5| Step: 8
Training loss: 2.8061938285827637
Validation loss: 2.0252736191595755

Epoch: 5| Step: 9
Training loss: 2.034355878829956
Validation loss: 2.019472345229118

Epoch: 5| Step: 10
Training loss: 2.2334368228912354
Validation loss: 2.0219504038492837

Epoch: 87| Step: 0
Training loss: 1.779581069946289
Validation loss: 2.009173738059177

Epoch: 5| Step: 1
Training loss: 2.766298532485962
Validation loss: 1.9876860034081243

Epoch: 5| Step: 2
Training loss: 2.2175517082214355
Validation loss: 1.9858815003466863

Epoch: 5| Step: 3
Training loss: 1.3628952503204346
Validation loss: 1.9785351061051892

Epoch: 5| Step: 4
Training loss: 2.2527003288269043
Validation loss: 1.9837035671357186

Epoch: 5| Step: 5
Training loss: 1.8369852304458618
Validation loss: 1.9854557462917861

Epoch: 5| Step: 6
Training loss: 1.7854629755020142
Validation loss: 1.9895066625328475

Epoch: 5| Step: 7
Training loss: 2.9780473709106445
Validation loss: 1.9900343853940246

Epoch: 5| Step: 8
Training loss: 2.6834306716918945
Validation loss: 1.9800012086027412

Epoch: 5| Step: 9
Training loss: 2.7497565746307373
Validation loss: 1.9784495304989558

Epoch: 5| Step: 10
Training loss: 2.7148306369781494
Validation loss: 1.9773634582437494

Epoch: 88| Step: 0
Training loss: 2.279784679412842
Validation loss: 1.9913581314907278

Epoch: 5| Step: 1
Training loss: 3.1429977416992188
Validation loss: 1.9901586168555803

Epoch: 5| Step: 2
Training loss: 2.304413318634033
Validation loss: 2.012597417318693

Epoch: 5| Step: 3
Training loss: 2.3584561347961426
Validation loss: 2.0288967445332515

Epoch: 5| Step: 4
Training loss: 2.1645514965057373
Validation loss: 2.04706117158295

Epoch: 5| Step: 5
Training loss: 2.410867214202881
Validation loss: 2.0569028777460896

Epoch: 5| Step: 6
Training loss: 2.3260936737060547
Validation loss: 2.066108638240445

Epoch: 5| Step: 7
Training loss: 1.5685584545135498
Validation loss: 2.0522617601579234

Epoch: 5| Step: 8
Training loss: 2.010065793991089
Validation loss: 2.043087811880214

Epoch: 5| Step: 9
Training loss: 1.9812214374542236
Validation loss: 2.0434512322948826

Epoch: 5| Step: 10
Training loss: 2.156026840209961
Validation loss: 2.051812578273076

Epoch: 89| Step: 0
Training loss: 2.043414831161499
Validation loss: 2.0414970882477297

Epoch: 5| Step: 1
Training loss: 2.660658836364746
Validation loss: 2.0683947506771294

Epoch: 5| Step: 2
Training loss: 2.2426187992095947
Validation loss: 2.0727543318143455

Epoch: 5| Step: 3
Training loss: 2.2510828971862793
Validation loss: 2.056088862880584

Epoch: 5| Step: 4
Training loss: 1.834747076034546
Validation loss: 2.033840640898674

Epoch: 5| Step: 5
Training loss: 1.5535814762115479
Validation loss: 2.0231112690382105

Epoch: 5| Step: 6
Training loss: 2.0130057334899902
Validation loss: 2.013406812503774

Epoch: 5| Step: 7
Training loss: 2.7589423656463623
Validation loss: 2.0038439586598384

Epoch: 5| Step: 8
Training loss: 2.5643880367279053
Validation loss: 2.0056913578382103

Epoch: 5| Step: 9
Training loss: 2.2519211769104004
Validation loss: 2.022215406099955

Epoch: 5| Step: 10
Training loss: 2.1729347705841064
Validation loss: 2.052503219214819

Epoch: 90| Step: 0
Training loss: 2.072113513946533
Validation loss: 2.071998175754342

Epoch: 5| Step: 1
Training loss: 2.0133965015411377
Validation loss: 2.0589091213800574

Epoch: 5| Step: 2
Training loss: 2.264256000518799
Validation loss: 2.0671559585038053

Epoch: 5| Step: 3
Training loss: 2.287928819656372
Validation loss: 2.082800519081854

Epoch: 5| Step: 4
Training loss: 2.1063504219055176
Validation loss: 2.103185712650258

Epoch: 5| Step: 5
Training loss: 2.4417924880981445
Validation loss: 2.089463608239287

Epoch: 5| Step: 6
Training loss: 1.9213314056396484
Validation loss: 2.0794127910367903

Epoch: 5| Step: 7
Training loss: 2.3504209518432617
Validation loss: 2.060188397284477

Epoch: 5| Step: 8
Training loss: 2.646634817123413
Validation loss: 2.0380444462581346

Epoch: 5| Step: 9
Training loss: 1.900207757949829
Validation loss: 2.0180998694512153

Epoch: 5| Step: 10
Training loss: 2.2503395080566406
Validation loss: 2.0063798376308974

Epoch: 91| Step: 0
Training loss: 2.446991443634033
Validation loss: 2.002682001360001

Epoch: 5| Step: 1
Training loss: 2.6322364807128906
Validation loss: 2.003793098593271

Epoch: 5| Step: 2
Training loss: 2.0956149101257324
Validation loss: 2.0033799050956644

Epoch: 5| Step: 3
Training loss: 1.997401475906372
Validation loss: 1.996585528055827

Epoch: 5| Step: 4
Training loss: 2.1518542766571045
Validation loss: 1.9926246314920404

Epoch: 5| Step: 5
Training loss: 2.3215599060058594
Validation loss: 2.003435993707308

Epoch: 5| Step: 6
Training loss: 2.4150118827819824
Validation loss: 1.992843185701678

Epoch: 5| Step: 7
Training loss: 2.086894989013672
Validation loss: 2.002028811362482

Epoch: 5| Step: 8
Training loss: 1.772178053855896
Validation loss: 2.0084631930115404

Epoch: 5| Step: 9
Training loss: 2.4100306034088135
Validation loss: 2.019100336618321

Epoch: 5| Step: 10
Training loss: 2.0066587924957275
Validation loss: 2.0224944622285905

Epoch: 92| Step: 0
Training loss: 1.5799752473831177
Validation loss: 2.075317064921061

Epoch: 5| Step: 1
Training loss: 1.808036208152771
Validation loss: 2.12670632331602

Epoch: 5| Step: 2
Training loss: 2.610724925994873
Validation loss: 2.0856153439450007

Epoch: 5| Step: 3
Training loss: 2.536238431930542
Validation loss: 2.0825607802278254

Epoch: 5| Step: 4
Training loss: 2.006483793258667
Validation loss: 2.0112073729115147

Epoch: 5| Step: 5
Training loss: 2.2930054664611816
Validation loss: 1.9924198324962328

Epoch: 5| Step: 6
Training loss: 2.356873035430908
Validation loss: 1.9733808450801398

Epoch: 5| Step: 7
Training loss: 1.9692102670669556
Validation loss: 1.9779905067977084

Epoch: 5| Step: 8
Training loss: 2.259209156036377
Validation loss: 1.9840135881977696

Epoch: 5| Step: 9
Training loss: 2.252657175064087
Validation loss: 1.9997310676882345

Epoch: 5| Step: 10
Training loss: 2.5538249015808105
Validation loss: 2.0123118149336947

Epoch: 93| Step: 0
Training loss: 2.1582512855529785
Validation loss: 2.0199688455109954

Epoch: 5| Step: 1
Training loss: 2.5413081645965576
Validation loss: 2.0244884849876486

Epoch: 5| Step: 2
Training loss: 1.416153907775879
Validation loss: 2.015650451824229

Epoch: 5| Step: 3
Training loss: 1.665229082107544
Validation loss: 1.9833314418792725

Epoch: 5| Step: 4
Training loss: 2.6611855030059814
Validation loss: 1.993292180440759

Epoch: 5| Step: 5
Training loss: 2.6297478675842285
Validation loss: 2.0188752925524147

Epoch: 5| Step: 6
Training loss: 2.786327600479126
Validation loss: 2.0202414374197684

Epoch: 5| Step: 7
Training loss: 2.171949625015259
Validation loss: 1.996541311663966

Epoch: 5| Step: 8
Training loss: 1.7393373250961304
Validation loss: 1.973401496487279

Epoch: 5| Step: 9
Training loss: 2.8220648765563965
Validation loss: 1.95330124773005

Epoch: 5| Step: 10
Training loss: 2.304288625717163
Validation loss: 1.9607847736727806

Epoch: 94| Step: 0
Training loss: 2.110461711883545
Validation loss: 1.9680250267828665

Epoch: 5| Step: 1
Training loss: 1.862169623374939
Validation loss: 2.004967986896474

Epoch: 5| Step: 2
Training loss: 2.3533172607421875
Validation loss: 2.030709863990866

Epoch: 5| Step: 3
Training loss: 2.500298023223877
Validation loss: 2.0584275132866314

Epoch: 5| Step: 4
Training loss: 2.384946346282959
Validation loss: 2.060498229918941

Epoch: 5| Step: 5
Training loss: 2.3100972175598145
Validation loss: 2.0320806605841524

Epoch: 5| Step: 6
Training loss: 2.301719903945923
Validation loss: 2.0198531971182874

Epoch: 5| Step: 7
Training loss: 2.488799571990967
Validation loss: 2.0081994892448507

Epoch: 5| Step: 8
Training loss: 2.1439616680145264
Validation loss: 1.9961987592840706

Epoch: 5| Step: 9
Training loss: 2.357267379760742
Validation loss: 1.985707623984224

Epoch: 5| Step: 10
Training loss: 2.0466554164886475
Validation loss: 1.9834828351133613

Epoch: 95| Step: 0
Training loss: 1.693250298500061
Validation loss: 2.00948465383181

Epoch: 5| Step: 1
Training loss: 2.198692560195923
Validation loss: 2.051521816561299

Epoch: 5| Step: 2
Training loss: 2.8969502449035645
Validation loss: 2.1471006793360554

Epoch: 5| Step: 3
Training loss: 2.532386064529419
Validation loss: 2.204061628669821

Epoch: 5| Step: 4
Training loss: 2.0878777503967285
Validation loss: 2.2364495236386537

Epoch: 5| Step: 5
Training loss: 2.059074640274048
Validation loss: 2.1826685218400854

Epoch: 5| Step: 6
Training loss: 2.6129894256591797
Validation loss: 2.0870067842545046

Epoch: 5| Step: 7
Training loss: 2.9568428993225098
Validation loss: 2.020256050171391

Epoch: 5| Step: 8
Training loss: 2.38450288772583
Validation loss: 1.967267700420913

Epoch: 5| Step: 9
Training loss: 2.1241469383239746
Validation loss: 1.9703980568916566

Epoch: 5| Step: 10
Training loss: 1.4722450971603394
Validation loss: 1.9748933494731944

Epoch: 96| Step: 0
Training loss: 2.4015228748321533
Validation loss: 2.0047397395615936

Epoch: 5| Step: 1
Training loss: 1.8823438882827759
Validation loss: 2.0409463015935754

Epoch: 5| Step: 2
Training loss: 2.049752950668335
Validation loss: 2.050987130852156

Epoch: 5| Step: 3
Training loss: 2.1608927249908447
Validation loss: 2.0532518227895102

Epoch: 5| Step: 4
Training loss: 2.46852970123291
Validation loss: 2.0493778951706423

Epoch: 5| Step: 5
Training loss: 1.9787838459014893
Validation loss: 2.077145884113927

Epoch: 5| Step: 6
Training loss: 1.9008270502090454
Validation loss: 2.0623921655839488

Epoch: 5| Step: 7
Training loss: 2.2917771339416504
Validation loss: 2.0598170295838387

Epoch: 5| Step: 8
Training loss: 2.014300584793091
Validation loss: 2.036937439313499

Epoch: 5| Step: 9
Training loss: 2.5093777179718018
Validation loss: 2.0392988125483194

Epoch: 5| Step: 10
Training loss: 2.848381280899048
Validation loss: 2.050592280203296

Epoch: 97| Step: 0
Training loss: 2.1178958415985107
Validation loss: 2.0742556382251043

Epoch: 5| Step: 1
Training loss: 2.3680784702301025
Validation loss: 2.079167676228349

Epoch: 5| Step: 2
Training loss: 2.556352138519287
Validation loss: 2.0685252297309136

Epoch: 5| Step: 3
Training loss: 2.5589311122894287
Validation loss: 2.061721194174982

Epoch: 5| Step: 4
Training loss: 1.656925916671753
Validation loss: 2.034806510453583

Epoch: 5| Step: 5
Training loss: 2.0661990642547607
Validation loss: 2.0015094331515733

Epoch: 5| Step: 6
Training loss: 1.7343326807022095
Validation loss: 1.9783491703771776

Epoch: 5| Step: 7
Training loss: 2.2178444862365723
Validation loss: 1.9771731220265871

Epoch: 5| Step: 8
Training loss: 2.0697314739227295
Validation loss: 1.9943322033010504

Epoch: 5| Step: 9
Training loss: 2.568429946899414
Validation loss: 1.9912658801642797

Epoch: 5| Step: 10
Training loss: 2.404834032058716
Validation loss: 1.976574041510141

Epoch: 98| Step: 0
Training loss: 2.0290746688842773
Validation loss: 1.9810239909797587

Epoch: 5| Step: 1
Training loss: 2.477102279663086
Validation loss: 1.9766975884796472

Epoch: 5| Step: 2
Training loss: 1.858731985092163
Validation loss: 1.9728446468230216

Epoch: 5| Step: 3
Training loss: 2.0730109214782715
Validation loss: 1.9558835952512679

Epoch: 5| Step: 4
Training loss: 2.9245238304138184
Validation loss: 1.9626377333876908

Epoch: 5| Step: 5
Training loss: 1.898056983947754
Validation loss: 1.9577248096466064

Epoch: 5| Step: 6
Training loss: 2.008756637573242
Validation loss: 1.9701692045375865

Epoch: 5| Step: 7
Training loss: 1.7728830575942993
Validation loss: 1.9943114890847156

Epoch: 5| Step: 8
Training loss: 2.055232524871826
Validation loss: 1.9950937853064588

Epoch: 5| Step: 9
Training loss: 2.4457249641418457
Validation loss: 1.993639084600633

Epoch: 5| Step: 10
Training loss: 2.128878116607666
Validation loss: 1.9736278005825576

Epoch: 99| Step: 0
Training loss: 2.231858730316162
Validation loss: 1.9685971506180302

Epoch: 5| Step: 1
Training loss: 1.8494161367416382
Validation loss: 1.9711138663753387

Epoch: 5| Step: 2
Training loss: 2.0563082695007324
Validation loss: 1.9670940483770063

Epoch: 5| Step: 3
Training loss: 2.4451584815979004
Validation loss: 1.9525454069978447

Epoch: 5| Step: 4
Training loss: 2.276961088180542
Validation loss: 1.9553432131326327

Epoch: 5| Step: 5
Training loss: 2.0603368282318115
Validation loss: 1.9439650171546525

Epoch: 5| Step: 6
Training loss: 2.1639058589935303
Validation loss: 1.955634182499301

Epoch: 5| Step: 7
Training loss: 2.237300395965576
Validation loss: 1.9464443550314954

Epoch: 5| Step: 8
Training loss: 1.8003265857696533
Validation loss: 1.9714950758923766

Epoch: 5| Step: 9
Training loss: 2.4861552715301514
Validation loss: 1.9801141779909852

Epoch: 5| Step: 10
Training loss: 1.8951215744018555
Validation loss: 1.984628221040131

Epoch: 100| Step: 0
Training loss: 2.1311516761779785
Validation loss: 2.0017137463374803

Epoch: 5| Step: 1
Training loss: 1.759810447692871
Validation loss: 2.0103087835414435

Epoch: 5| Step: 2
Training loss: 1.5769875049591064
Validation loss: 2.0101025130159114

Epoch: 5| Step: 3
Training loss: 2.5655436515808105
Validation loss: 2.006861376506026

Epoch: 5| Step: 4
Training loss: 2.662264585494995
Validation loss: 2.015203660534274

Epoch: 5| Step: 5
Training loss: 2.4011268615722656
Validation loss: 2.0009984047182146

Epoch: 5| Step: 6
Training loss: 1.5117294788360596
Validation loss: 2.009737317280103

Epoch: 5| Step: 7
Training loss: 1.848089575767517
Validation loss: 2.00311714987601

Epoch: 5| Step: 8
Training loss: 2.5677566528320312
Validation loss: 1.9907937498502835

Epoch: 5| Step: 9
Training loss: 2.898860216140747
Validation loss: 1.9891280512655936

Epoch: 5| Step: 10
Training loss: 1.3554449081420898
Validation loss: 1.985687740387455

Epoch: 101| Step: 0
Training loss: 2.4296023845672607
Validation loss: 1.9903156193353797

Epoch: 5| Step: 1
Training loss: 1.4143619537353516
Validation loss: 1.996463203942904

Epoch: 5| Step: 2
Training loss: 2.09832763671875
Validation loss: 1.9888120530754008

Epoch: 5| Step: 3
Training loss: 1.9455581903457642
Validation loss: 1.9790915135414369

Epoch: 5| Step: 4
Training loss: 2.42031192779541
Validation loss: 1.9812737998142038

Epoch: 5| Step: 5
Training loss: 2.510871648788452
Validation loss: 1.9623785518830823

Epoch: 5| Step: 6
Training loss: 2.031477212905884
Validation loss: 1.9776904736795733

Epoch: 5| Step: 7
Training loss: 2.60276198387146
Validation loss: 1.9700357375606414

Epoch: 5| Step: 8
Training loss: 2.382575511932373
Validation loss: 1.965458828915832

Epoch: 5| Step: 9
Training loss: 1.5707718133926392
Validation loss: 1.9866535984059817

Epoch: 5| Step: 10
Training loss: 1.6425610780715942
Validation loss: 2.0092615876146542

Epoch: 102| Step: 0
Training loss: 1.9988205432891846
Validation loss: 2.017768283044138

Epoch: 5| Step: 1
Training loss: 2.17863392829895
Validation loss: 1.9926241149184525

Epoch: 5| Step: 2
Training loss: 1.7563610076904297
Validation loss: 1.9775590640242382

Epoch: 5| Step: 3
Training loss: 2.9384851455688477
Validation loss: 1.9452292855067919

Epoch: 5| Step: 4
Training loss: 2.0862040519714355
Validation loss: 1.9432827695723502

Epoch: 5| Step: 5
Training loss: 1.7344757318496704
Validation loss: 1.9572102100618425

Epoch: 5| Step: 6
Training loss: 1.6910959482192993
Validation loss: 1.9466432807266072

Epoch: 5| Step: 7
Training loss: 1.8652795553207397
Validation loss: 1.9654075150848718

Epoch: 5| Step: 8
Training loss: 2.7005181312561035
Validation loss: 1.9482199299720027

Epoch: 5| Step: 9
Training loss: 2.47015643119812
Validation loss: 1.9640262024376982

Epoch: 5| Step: 10
Training loss: 1.7469879388809204
Validation loss: 1.9739567643852645

Epoch: 103| Step: 0
Training loss: 2.5346927642822266
Validation loss: 2.014302744660326

Epoch: 5| Step: 1
Training loss: 2.045140504837036
Validation loss: 2.0882765657158306

Epoch: 5| Step: 2
Training loss: 2.28096342086792
Validation loss: 2.0960053756672847

Epoch: 5| Step: 3
Training loss: 2.574031352996826
Validation loss: 2.1005690431082122

Epoch: 5| Step: 4
Training loss: 2.680327892303467
Validation loss: 2.0358689215875443

Epoch: 5| Step: 5
Training loss: 1.6155598163604736
Validation loss: 1.9899246923385128

Epoch: 5| Step: 6
Training loss: 2.002617359161377
Validation loss: 1.9605056214076217

Epoch: 5| Step: 7
Training loss: 1.5833443403244019
Validation loss: 1.9548669886845413

Epoch: 5| Step: 8
Training loss: 1.8116645812988281
Validation loss: 1.9746867059379496

Epoch: 5| Step: 9
Training loss: 2.4493002891540527
Validation loss: 1.9705936062720515

Epoch: 5| Step: 10
Training loss: 1.9011980295181274
Validation loss: 1.9724068269934705

Epoch: 104| Step: 0
Training loss: 1.9139913320541382
Validation loss: 1.9563390144737818

Epoch: 5| Step: 1
Training loss: 1.8872525691986084
Validation loss: 1.966412607059684

Epoch: 5| Step: 2
Training loss: 2.0903778076171875
Validation loss: 1.9780185607171827

Epoch: 5| Step: 3
Training loss: 2.518970012664795
Validation loss: 1.9822875248488558

Epoch: 5| Step: 4
Training loss: 2.0144381523132324
Validation loss: 1.9808727874550769

Epoch: 5| Step: 5
Training loss: 2.3141865730285645
Validation loss: 1.9605164963711974

Epoch: 5| Step: 6
Training loss: 2.0128273963928223
Validation loss: 1.9420544344891784

Epoch: 5| Step: 7
Training loss: 2.3272430896759033
Validation loss: 1.9357561155032086

Epoch: 5| Step: 8
Training loss: 2.2519044876098633
Validation loss: 1.918518727825534

Epoch: 5| Step: 9
Training loss: 1.5237891674041748
Validation loss: 1.9161555997786983

Epoch: 5| Step: 10
Training loss: 2.666577100753784
Validation loss: 1.9303399285962504

Epoch: 105| Step: 0
Training loss: 1.9560880661010742
Validation loss: 1.9404631276284494

Epoch: 5| Step: 1
Training loss: 2.457542896270752
Validation loss: 1.9721745252609253

Epoch: 5| Step: 2
Training loss: 2.623084306716919
Validation loss: 2.007732096538749

Epoch: 5| Step: 3
Training loss: 1.575305700302124
Validation loss: 2.0345153500956874

Epoch: 5| Step: 4
Training loss: 1.602434754371643
Validation loss: 2.0648755924676054

Epoch: 5| Step: 5
Training loss: 2.183931350708008
Validation loss: 2.085499850652551

Epoch: 5| Step: 6
Training loss: 1.8769077062606812
Validation loss: 2.077319173402684

Epoch: 5| Step: 7
Training loss: 2.5805249214172363
Validation loss: 2.0450361338994836

Epoch: 5| Step: 8
Training loss: 2.0888113975524902
Validation loss: 2.019260742331064

Epoch: 5| Step: 9
Training loss: 1.8387501239776611
Validation loss: 1.9899269624422955

Epoch: 5| Step: 10
Training loss: 2.480569362640381
Validation loss: 1.9693264063968454

Epoch: 106| Step: 0
Training loss: 2.960714340209961
Validation loss: 1.9522839951258835

Epoch: 5| Step: 1
Training loss: 1.280578374862671
Validation loss: 1.9523987449625486

Epoch: 5| Step: 2
Training loss: 2.2486584186553955
Validation loss: 1.9540554118412796

Epoch: 5| Step: 3
Training loss: 2.4807000160217285
Validation loss: 1.9947588161755634

Epoch: 5| Step: 4
Training loss: 1.9993646144866943
Validation loss: 2.035492882933668

Epoch: 5| Step: 5
Training loss: 2.168794870376587
Validation loss: 2.058109817966338

Epoch: 5| Step: 6
Training loss: 1.9251708984375
Validation loss: 2.0503342305460284

Epoch: 5| Step: 7
Training loss: 2.58701753616333
Validation loss: 2.024629690313852

Epoch: 5| Step: 8
Training loss: 1.8089988231658936
Validation loss: 1.9850947113447293

Epoch: 5| Step: 9
Training loss: 2.5251951217651367
Validation loss: 1.971305142166794

Epoch: 5| Step: 10
Training loss: 1.5348892211914062
Validation loss: 1.9791588334627048

Epoch: 107| Step: 0
Training loss: 1.9232685565948486
Validation loss: 2.0019576293165966

Epoch: 5| Step: 1
Training loss: 1.96249258518219
Validation loss: 2.017585398048483

Epoch: 5| Step: 2
Training loss: 2.419212818145752
Validation loss: 2.043983950409838

Epoch: 5| Step: 3
Training loss: 2.574709177017212
Validation loss: 2.0211221505236883

Epoch: 5| Step: 4
Training loss: 2.423067569732666
Validation loss: 1.9594754685637772

Epoch: 5| Step: 5
Training loss: 2.0468523502349854
Validation loss: 1.9532107332701325

Epoch: 5| Step: 6
Training loss: 1.8481886386871338
Validation loss: 2.022438513335361

Epoch: 5| Step: 7
Training loss: 2.8779051303863525
Validation loss: 2.066339635079907

Epoch: 5| Step: 8
Training loss: 2.3661177158355713
Validation loss: 2.097734489748555

Epoch: 5| Step: 9
Training loss: 1.6819216012954712
Validation loss: 2.092069774545649

Epoch: 5| Step: 10
Training loss: 2.2444984912872314
Validation loss: 2.083342695748934

Epoch: 108| Step: 0
Training loss: 2.0419247150421143
Validation loss: 2.0717554861499416

Epoch: 5| Step: 1
Training loss: 2.224367141723633
Validation loss: 2.0395075249415573

Epoch: 5| Step: 2
Training loss: 2.3372483253479004
Validation loss: 1.9974096103381085

Epoch: 5| Step: 3
Training loss: 2.1016693115234375
Validation loss: 1.9544541835784912

Epoch: 5| Step: 4
Training loss: 2.1630208492279053
Validation loss: 1.9226072590838197

Epoch: 5| Step: 5
Training loss: 1.9592078924179077
Validation loss: 1.9069673553589852

Epoch: 5| Step: 6
Training loss: 2.6667613983154297
Validation loss: 1.8945994812955138

Epoch: 5| Step: 7
Training loss: 2.2880568504333496
Validation loss: 1.9160938903849611

Epoch: 5| Step: 8
Training loss: 1.9867851734161377
Validation loss: 1.9434059640412689

Epoch: 5| Step: 9
Training loss: 2.2063746452331543
Validation loss: 1.9397620001146871

Epoch: 5| Step: 10
Training loss: 1.81804358959198
Validation loss: 1.9327212725916216

Epoch: 109| Step: 0
Training loss: 1.9768190383911133
Validation loss: 1.9342164967649726

Epoch: 5| Step: 1
Training loss: 2.3574907779693604
Validation loss: 1.9493284661282775

Epoch: 5| Step: 2
Training loss: 2.0172924995422363
Validation loss: 1.9711192025933215

Epoch: 5| Step: 3
Training loss: 2.3054966926574707
Validation loss: 1.983192434874914

Epoch: 5| Step: 4
Training loss: 1.858648657798767
Validation loss: 2.000620772761683

Epoch: 5| Step: 5
Training loss: 2.2177202701568604
Validation loss: 2.0324876385350383

Epoch: 5| Step: 6
Training loss: 1.9988454580307007
Validation loss: 2.035943288956919

Epoch: 5| Step: 7
Training loss: 1.955936074256897
Validation loss: 2.033909302885814

Epoch: 5| Step: 8
Training loss: 2.049114942550659
Validation loss: 2.0158059443196943

Epoch: 5| Step: 9
Training loss: 1.5289084911346436
Validation loss: 2.005942065228698

Epoch: 5| Step: 10
Training loss: 2.6980793476104736
Validation loss: 1.9872141089490665

Epoch: 110| Step: 0
Training loss: 2.6037096977233887
Validation loss: 1.9878959245579217

Epoch: 5| Step: 1
Training loss: 1.7868257761001587
Validation loss: 1.9734410675623084

Epoch: 5| Step: 2
Training loss: 2.1969149112701416
Validation loss: 1.975375606167701

Epoch: 5| Step: 3
Training loss: 1.942552924156189
Validation loss: 1.9817090931759085

Epoch: 5| Step: 4
Training loss: 2.0902044773101807
Validation loss: 1.9927454328024259

Epoch: 5| Step: 5
Training loss: 1.729087471961975
Validation loss: 2.003198763375641

Epoch: 5| Step: 6
Training loss: 1.6174261569976807
Validation loss: 2.021579157921576

Epoch: 5| Step: 7
Training loss: 1.2268222570419312
Validation loss: 2.0518577137301044

Epoch: 5| Step: 8
Training loss: 2.333822727203369
Validation loss: 2.090483988485029

Epoch: 5| Step: 9
Training loss: 2.843413829803467
Validation loss: 2.1295257652959516

Epoch: 5| Step: 10
Training loss: 2.5444326400756836
Validation loss: 2.1456288317198395

Epoch: 111| Step: 0
Training loss: 2.1010611057281494
Validation loss: 2.1694658956220074

Epoch: 5| Step: 1
Training loss: 2.469852924346924
Validation loss: 2.114319847476098

Epoch: 5| Step: 2
Training loss: 1.9805418252944946
Validation loss: 2.0324458640108825

Epoch: 5| Step: 3
Training loss: 2.3407809734344482
Validation loss: 1.9861534077634093

Epoch: 5| Step: 4
Training loss: 2.1454203128814697
Validation loss: 1.9500432475920646

Epoch: 5| Step: 5
Training loss: 2.1252663135528564
Validation loss: 1.9539401492764872

Epoch: 5| Step: 6
Training loss: 2.5288310050964355
Validation loss: 1.9684030368763914

Epoch: 5| Step: 7
Training loss: 2.3482613563537598
Validation loss: 1.9957504862098283

Epoch: 5| Step: 8
Training loss: 2.0393881797790527
Validation loss: 2.0340708660823044

Epoch: 5| Step: 9
Training loss: 1.7625741958618164
Validation loss: 2.027229127063546

Epoch: 5| Step: 10
Training loss: 1.8055033683776855
Validation loss: 1.9863096001327678

Epoch: 112| Step: 0
Training loss: 2.1934967041015625
Validation loss: 1.9680728720080467

Epoch: 5| Step: 1
Training loss: 1.9035810232162476
Validation loss: 1.957306952886684

Epoch: 5| Step: 2
Training loss: 2.1402034759521484
Validation loss: 1.945508501862967

Epoch: 5| Step: 3
Training loss: 2.0780534744262695
Validation loss: 1.9466602892004035

Epoch: 5| Step: 4
Training loss: 2.866123914718628
Validation loss: 1.924509512480869

Epoch: 5| Step: 5
Training loss: 2.4883947372436523
Validation loss: 1.913096417662918

Epoch: 5| Step: 6
Training loss: 1.4780504703521729
Validation loss: 1.9157358369519633

Epoch: 5| Step: 7
Training loss: 2.2676970958709717
Validation loss: 1.9205469982598418

Epoch: 5| Step: 8
Training loss: 2.1369636058807373
Validation loss: 1.924011666287658

Epoch: 5| Step: 9
Training loss: 1.896449327468872
Validation loss: 1.9466254967515186

Epoch: 5| Step: 10
Training loss: 1.3764435052871704
Validation loss: 1.96597626901442

Epoch: 113| Step: 0
Training loss: 1.8155332803726196
Validation loss: 1.987749094604164

Epoch: 5| Step: 1
Training loss: 1.8736196756362915
Validation loss: 2.0044656492048696

Epoch: 5| Step: 2
Training loss: 1.6281471252441406
Validation loss: 2.02375167159624

Epoch: 5| Step: 3
Training loss: 2.0440409183502197
Validation loss: 2.0541778738780687

Epoch: 5| Step: 4
Training loss: 2.169904947280884
Validation loss: 2.0900069975083873

Epoch: 5| Step: 5
Training loss: 1.7137813568115234
Validation loss: 2.03789472387683

Epoch: 5| Step: 6
Training loss: 2.230262279510498
Validation loss: 2.0010843866614887

Epoch: 5| Step: 7
Training loss: 1.9480171203613281
Validation loss: 1.9976041188804052

Epoch: 5| Step: 8
Training loss: 1.9776710271835327
Validation loss: 1.9918728182392735

Epoch: 5| Step: 9
Training loss: 2.8675899505615234
Validation loss: 1.9701748073741954

Epoch: 5| Step: 10
Training loss: 2.3957276344299316
Validation loss: 1.9740567053517988

Epoch: 114| Step: 0
Training loss: 1.4753915071487427
Validation loss: 1.9696828703726492

Epoch: 5| Step: 1
Training loss: 2.5294604301452637
Validation loss: 1.9763622078844296

Epoch: 5| Step: 2
Training loss: 2.1185786724090576
Validation loss: 1.973319915033156

Epoch: 5| Step: 3
Training loss: 2.25384259223938
Validation loss: 1.9942830506191458

Epoch: 5| Step: 4
Training loss: 2.2715556621551514
Validation loss: 2.0060531605956373

Epoch: 5| Step: 5
Training loss: 1.4662272930145264
Validation loss: 2.018640882225447

Epoch: 5| Step: 6
Training loss: 2.2486603260040283
Validation loss: 2.01693542029268

Epoch: 5| Step: 7
Training loss: 1.3676464557647705
Validation loss: 2.0389852062348397

Epoch: 5| Step: 8
Training loss: 2.5154521465301514
Validation loss: 2.013218802790488

Epoch: 5| Step: 9
Training loss: 2.3642733097076416
Validation loss: 1.9625899971172374

Epoch: 5| Step: 10
Training loss: 1.4371296167373657
Validation loss: 1.964192633987755

Epoch: 115| Step: 0
Training loss: 2.2323825359344482
Validation loss: 1.9498505207800096

Epoch: 5| Step: 1
Training loss: 1.5374828577041626
Validation loss: 1.9228689465471493

Epoch: 5| Step: 2
Training loss: 2.1899380683898926
Validation loss: 1.9035660451458347

Epoch: 5| Step: 3
Training loss: 2.8999674320220947
Validation loss: 1.9170982530040126

Epoch: 5| Step: 4
Training loss: 2.0084726810455322
Validation loss: 1.9215900257069578

Epoch: 5| Step: 5
Training loss: 2.0233449935913086
Validation loss: 1.9145395281494304

Epoch: 5| Step: 6
Training loss: 1.95578134059906
Validation loss: 1.92359681283274

Epoch: 5| Step: 7
Training loss: 1.8126024007797241
Validation loss: 1.938035024109707

Epoch: 5| Step: 8
Training loss: 1.8786046504974365
Validation loss: 1.938041712648125

Epoch: 5| Step: 9
Training loss: 2.2708730697631836
Validation loss: 1.9541993525720411

Epoch: 5| Step: 10
Training loss: 1.8072084188461304
Validation loss: 1.9478559288927304

Epoch: 116| Step: 0
Training loss: 2.1162030696868896
Validation loss: 1.9430742738067464

Epoch: 5| Step: 1
Training loss: 2.1781840324401855
Validation loss: 1.9325493535687845

Epoch: 5| Step: 2
Training loss: 2.285081148147583
Validation loss: 1.9282626528893747

Epoch: 5| Step: 3
Training loss: 1.9863523244857788
Validation loss: 1.9059201825049616

Epoch: 5| Step: 4
Training loss: 1.843446969985962
Validation loss: 1.9220869438622588

Epoch: 5| Step: 5
Training loss: 1.8293555974960327
Validation loss: 1.935196344570447

Epoch: 5| Step: 6
Training loss: 1.687278389930725
Validation loss: 1.936079280350798

Epoch: 5| Step: 7
Training loss: 2.537071704864502
Validation loss: 1.978796979432465

Epoch: 5| Step: 8
Training loss: 2.5269322395324707
Validation loss: 2.001339039494914

Epoch: 5| Step: 9
Training loss: 1.5136158466339111
Validation loss: 2.051211177661855

Epoch: 5| Step: 10
Training loss: 1.5672324895858765
Validation loss: 2.0568581588806643

Epoch: 117| Step: 0
Training loss: 1.9850209951400757
Validation loss: 2.044552565902792

Epoch: 5| Step: 1
Training loss: 2.101335048675537
Validation loss: 2.016236453927973

Epoch: 5| Step: 2
Training loss: 1.8878952264785767
Validation loss: 1.9745208345433718

Epoch: 5| Step: 3
Training loss: 2.2776429653167725
Validation loss: 1.928267607124903

Epoch: 5| Step: 4
Training loss: 1.779789924621582
Validation loss: 1.919872905618401

Epoch: 5| Step: 5
Training loss: 1.7088428735733032
Validation loss: 1.9091169705954931

Epoch: 5| Step: 6
Training loss: 1.6627448797225952
Validation loss: 1.9082265464208459

Epoch: 5| Step: 7
Training loss: 2.3389363288879395
Validation loss: 1.901848667411394

Epoch: 5| Step: 8
Training loss: 2.4698832035064697
Validation loss: 1.9078937371571858

Epoch: 5| Step: 9
Training loss: 1.8442134857177734
Validation loss: 1.9153554413908271

Epoch: 5| Step: 10
Training loss: 2.1964893341064453
Validation loss: 1.9291702137198499

Epoch: 118| Step: 0
Training loss: 1.6839691400527954
Validation loss: 1.9416856176109725

Epoch: 5| Step: 1
Training loss: 1.8162956237792969
Validation loss: 1.9564848894714026

Epoch: 5| Step: 2
Training loss: 2.0699429512023926
Validation loss: 1.9683661486512871

Epoch: 5| Step: 3
Training loss: 1.7979333400726318
Validation loss: 1.989642050958449

Epoch: 5| Step: 4
Training loss: 2.3372561931610107
Validation loss: 2.0066435683158135

Epoch: 5| Step: 5
Training loss: 2.517472267150879
Validation loss: 2.004662290696175

Epoch: 5| Step: 6
Training loss: 2.043651819229126
Validation loss: 2.0265681218075495

Epoch: 5| Step: 7
Training loss: 2.1593375205993652
Validation loss: 2.0434587181255384

Epoch: 5| Step: 8
Training loss: 1.617735505104065
Validation loss: 2.0682754490965154

Epoch: 5| Step: 9
Training loss: 2.2146592140197754
Validation loss: 2.048063772980885

Epoch: 5| Step: 10
Training loss: 1.8711367845535278
Validation loss: 2.0297042067332933

Epoch: 119| Step: 0
Training loss: 1.7032018899917603
Validation loss: 1.998641239699497

Epoch: 5| Step: 1
Training loss: 1.5362027883529663
Validation loss: 1.9728734236891552

Epoch: 5| Step: 2
Training loss: 2.232961416244507
Validation loss: 1.9592237831443868

Epoch: 5| Step: 3
Training loss: 1.712481141090393
Validation loss: 1.9198466872656217

Epoch: 5| Step: 4
Training loss: 2.1675238609313965
Validation loss: 1.9124046294919905

Epoch: 5| Step: 5
Training loss: 2.644624710083008
Validation loss: 1.8910312575678672

Epoch: 5| Step: 6
Training loss: 2.2399463653564453
Validation loss: 1.8989979426066081

Epoch: 5| Step: 7
Training loss: 1.8291009664535522
Validation loss: 1.907504758527202

Epoch: 5| Step: 8
Training loss: 1.9481284618377686
Validation loss: 1.895486807310453

Epoch: 5| Step: 9
Training loss: 2.5046839714050293
Validation loss: 1.9240675344262073

Epoch: 5| Step: 10
Training loss: 1.8140621185302734
Validation loss: 1.9288948607701126

Epoch: 120| Step: 0
Training loss: 2.649010181427002
Validation loss: 1.9254864608087847

Epoch: 5| Step: 1
Training loss: 1.5712827444076538
Validation loss: 1.9198095862583449

Epoch: 5| Step: 2
Training loss: 1.9298295974731445
Validation loss: 1.9342583456347067

Epoch: 5| Step: 3
Training loss: 2.2360422611236572
Validation loss: 1.953777502941829

Epoch: 5| Step: 4
Training loss: 1.9360153675079346
Validation loss: 1.9788453732767413

Epoch: 5| Step: 5
Training loss: 1.5055506229400635
Validation loss: 1.9811835853002404

Epoch: 5| Step: 6
Training loss: 2.0164542198181152
Validation loss: 2.0080809759837326

Epoch: 5| Step: 7
Training loss: 2.072962999343872
Validation loss: 1.9855426972912205

Epoch: 5| Step: 8
Training loss: 1.9759159088134766
Validation loss: 2.025604805638713

Epoch: 5| Step: 9
Training loss: 2.191715955734253
Validation loss: 2.0282286251744917

Epoch: 5| Step: 10
Training loss: 1.6095882654190063
Validation loss: 2.0313306828980804

Epoch: 121| Step: 0
Training loss: 2.1001346111297607
Validation loss: 2.0423255146190686

Epoch: 5| Step: 1
Training loss: 1.764330506324768
Validation loss: 2.0163194915299774

Epoch: 5| Step: 2
Training loss: 2.2251503467559814
Validation loss: 2.0023714162970103

Epoch: 5| Step: 3
Training loss: 1.879461646080017
Validation loss: 1.9820688078480382

Epoch: 5| Step: 4
Training loss: 1.9551284313201904
Validation loss: 1.9755658847029491

Epoch: 5| Step: 5
Training loss: 2.086984157562256
Validation loss: 1.9605914559415591

Epoch: 5| Step: 6
Training loss: 2.2183620929718018
Validation loss: 1.988595054995629

Epoch: 5| Step: 7
Training loss: 2.0923593044281006
Validation loss: 1.9876992625574912

Epoch: 5| Step: 8
Training loss: 1.908328652381897
Validation loss: 1.9938682574097828

Epoch: 5| Step: 9
Training loss: 1.761160135269165
Validation loss: 1.989945766746357

Epoch: 5| Step: 10
Training loss: 1.8741331100463867
Validation loss: 2.0174298645347677

Epoch: 122| Step: 0
Training loss: 1.9371792078018188
Validation loss: 2.035508535241568

Epoch: 5| Step: 1
Training loss: 2.5373988151550293
Validation loss: 2.0454726296086467

Epoch: 5| Step: 2
Training loss: 2.024559497833252
Validation loss: 1.968670565594909

Epoch: 5| Step: 3
Training loss: 2.482219696044922
Validation loss: 1.9333479301903838

Epoch: 5| Step: 4
Training loss: 2.2689080238342285
Validation loss: 1.9212558602774015

Epoch: 5| Step: 5
Training loss: 2.1125311851501465
Validation loss: 1.9252536104571434

Epoch: 5| Step: 6
Training loss: 2.192486524581909
Validation loss: 1.9236677462054836

Epoch: 5| Step: 7
Training loss: 1.607174277305603
Validation loss: 1.9217825640914261

Epoch: 5| Step: 8
Training loss: 1.5827792882919312
Validation loss: 1.936427834213421

Epoch: 5| Step: 9
Training loss: 1.4094822406768799
Validation loss: 1.947680716873497

Epoch: 5| Step: 10
Training loss: 1.9073470830917358
Validation loss: 1.9657489997084423

Epoch: 123| Step: 0
Training loss: 2.62827730178833
Validation loss: 1.9760596470166278

Epoch: 5| Step: 1
Training loss: 1.7682340145111084
Validation loss: 1.9993932170252646

Epoch: 5| Step: 2
Training loss: 2.4341611862182617
Validation loss: 2.030595512800319

Epoch: 5| Step: 3
Training loss: 1.666477918624878
Validation loss: 2.057222072796155

Epoch: 5| Step: 4
Training loss: 2.2936911582946777
Validation loss: 2.0782740731393137

Epoch: 5| Step: 5
Training loss: 1.8765392303466797
Validation loss: 2.035300165094355

Epoch: 5| Step: 6
Training loss: 1.874471664428711
Validation loss: 2.0009742167688187

Epoch: 5| Step: 7
Training loss: 1.5663423538208008
Validation loss: 1.9684218834805232

Epoch: 5| Step: 8
Training loss: 1.415362000465393
Validation loss: 1.9645405725766254

Epoch: 5| Step: 9
Training loss: 2.209286689758301
Validation loss: 1.9636278306284258

Epoch: 5| Step: 10
Training loss: 1.7388602495193481
Validation loss: 1.961447205594791

Epoch: 124| Step: 0
Training loss: 2.1049001216888428
Validation loss: 1.9455477883738856

Epoch: 5| Step: 1
Training loss: 1.4739654064178467
Validation loss: 1.9380192436197752

Epoch: 5| Step: 2
Training loss: 1.9745228290557861
Validation loss: 1.9454361187514437

Epoch: 5| Step: 3
Training loss: 2.278938055038452
Validation loss: 1.9564253694267684

Epoch: 5| Step: 4
Training loss: 1.9471629858016968
Validation loss: 1.9558032917720016

Epoch: 5| Step: 5
Training loss: 1.70809805393219
Validation loss: 1.968221587519492

Epoch: 5| Step: 6
Training loss: 1.2582502365112305
Validation loss: 1.9569629353861655

Epoch: 5| Step: 7
Training loss: 1.961695909500122
Validation loss: 1.9609545366738432

Epoch: 5| Step: 8
Training loss: 2.3926033973693848
Validation loss: 1.9817069602268997

Epoch: 5| Step: 9
Training loss: 2.216468334197998
Validation loss: 1.9875446775908112

Epoch: 5| Step: 10
Training loss: 2.126058578491211
Validation loss: 2.015313481771818

Epoch: 125| Step: 0
Training loss: 1.777421236038208
Validation loss: 1.9900225811107184

Epoch: 5| Step: 1
Training loss: 2.361452579498291
Validation loss: 1.960334582995343

Epoch: 5| Step: 2
Training loss: 1.8907884359359741
Validation loss: 1.9488581534354918

Epoch: 5| Step: 3
Training loss: 1.9808868169784546
Validation loss: 1.9399586736515004

Epoch: 5| Step: 4
Training loss: 1.486611008644104
Validation loss: 1.939508072791561

Epoch: 5| Step: 5
Training loss: 1.8944628238677979
Validation loss: 1.9246809367210633

Epoch: 5| Step: 6
Training loss: 1.6849315166473389
Validation loss: 1.9199874580547374

Epoch: 5| Step: 7
Training loss: 2.386887311935425
Validation loss: 1.9301350988367552

Epoch: 5| Step: 8
Training loss: 2.033776044845581
Validation loss: 1.9480944641174809

Epoch: 5| Step: 9
Training loss: 2.0325567722320557
Validation loss: 1.97186904568826

Epoch: 5| Step: 10
Training loss: 1.9941327571868896
Validation loss: 1.963019165941464

Epoch: 126| Step: 0
Training loss: 2.0208239555358887
Validation loss: 1.9608304590307257

Epoch: 5| Step: 1
Training loss: 1.6970561742782593
Validation loss: 1.9540370356652044

Epoch: 5| Step: 2
Training loss: 2.097517728805542
Validation loss: 1.9650125682994883

Epoch: 5| Step: 3
Training loss: 2.2349636554718018
Validation loss: 1.9586758344404158

Epoch: 5| Step: 4
Training loss: 2.616818904876709
Validation loss: 1.9535796821758311

Epoch: 5| Step: 5
Training loss: 1.4216339588165283
Validation loss: 1.9670126515050088

Epoch: 5| Step: 6
Training loss: 1.4973748922348022
Validation loss: 1.9886166331588582

Epoch: 5| Step: 7
Training loss: 1.5661348104476929
Validation loss: 2.0020769206426476

Epoch: 5| Step: 8
Training loss: 2.1144676208496094
Validation loss: 2.029475983752999

Epoch: 5| Step: 9
Training loss: 1.9592649936676025
Validation loss: 2.055401558517128

Epoch: 5| Step: 10
Training loss: 2.1592743396759033
Validation loss: 2.0396094501659436

Epoch: 127| Step: 0
Training loss: 1.675990343093872
Validation loss: 2.0067720925936134

Epoch: 5| Step: 1
Training loss: 1.7221218347549438
Validation loss: 2.0156475523466706

Epoch: 5| Step: 2
Training loss: 2.237607479095459
Validation loss: 2.034800988371654

Epoch: 5| Step: 3
Training loss: 1.795528769493103
Validation loss: 2.027413709189302

Epoch: 5| Step: 4
Training loss: 2.053162097930908
Validation loss: 2.031299344954952

Epoch: 5| Step: 5
Training loss: 2.256826877593994
Validation loss: 2.0263546461700113

Epoch: 5| Step: 6
Training loss: 1.9001424312591553
Validation loss: 1.978528638039866

Epoch: 5| Step: 7
Training loss: 1.8916412591934204
Validation loss: 1.97452421598537

Epoch: 5| Step: 8
Training loss: 2.0687570571899414
Validation loss: 1.9964169045930267

Epoch: 5| Step: 9
Training loss: 2.2070059776306152
Validation loss: 2.0604569014682563

Epoch: 5| Step: 10
Training loss: 1.8535630702972412
Validation loss: 2.0940524275584886

Epoch: 128| Step: 0
Training loss: 2.2686238288879395
Validation loss: 2.07941456507611

Epoch: 5| Step: 1
Training loss: 2.0924017429351807
Validation loss: 2.05209267780345

Epoch: 5| Step: 2
Training loss: 2.076960802078247
Validation loss: 2.0443448712748866

Epoch: 5| Step: 3
Training loss: 1.8145039081573486
Validation loss: 2.027704829810768

Epoch: 5| Step: 4
Training loss: 2.3933653831481934
Validation loss: 2.013564935294531

Epoch: 5| Step: 5
Training loss: 2.0042593479156494
Validation loss: 1.9560829054924749

Epoch: 5| Step: 6
Training loss: 1.72124445438385
Validation loss: 1.9575812611528622

Epoch: 5| Step: 7
Training loss: 1.7077007293701172
Validation loss: 1.953197568975469

Epoch: 5| Step: 8
Training loss: 1.8775415420532227
Validation loss: 1.94546599541941

Epoch: 5| Step: 9
Training loss: 2.0168731212615967
Validation loss: 1.9668547158600183

Epoch: 5| Step: 10
Training loss: 1.248023271560669
Validation loss: 1.995477545645929

Epoch: 129| Step: 0
Training loss: 1.927152395248413
Validation loss: 2.0445577841933056

Epoch: 5| Step: 1
Training loss: 1.7724395990371704
Validation loss: 2.095622134465043

Epoch: 5| Step: 2
Training loss: 2.0995640754699707
Validation loss: 2.1530313709730744

Epoch: 5| Step: 3
Training loss: 2.0967578887939453
Validation loss: 2.1606470641269477

Epoch: 5| Step: 4
Training loss: 1.9639828205108643
Validation loss: 2.1251267310111754

Epoch: 5| Step: 5
Training loss: 2.0624442100524902
Validation loss: 2.0996319760558424

Epoch: 5| Step: 6
Training loss: 2.7050023078918457
Validation loss: 2.0728227284646805

Epoch: 5| Step: 7
Training loss: 1.5227251052856445
Validation loss: 2.0216379216922227

Epoch: 5| Step: 8
Training loss: 2.3223586082458496
Validation loss: 1.9773325945741387

Epoch: 5| Step: 9
Training loss: 1.503212571144104
Validation loss: 1.9402855737234956

Epoch: 5| Step: 10
Training loss: 1.9021328687667847
Validation loss: 1.9371398918090328

Epoch: 130| Step: 0
Training loss: 2.102801561355591
Validation loss: 1.9272403870859454

Epoch: 5| Step: 1
Training loss: 1.6643463373184204
Validation loss: 1.9513730541352303

Epoch: 5| Step: 2
Training loss: 1.865220308303833
Validation loss: 1.9541796061300463

Epoch: 5| Step: 3
Training loss: 2.475207567214966
Validation loss: 1.9661406022246166

Epoch: 5| Step: 4
Training loss: 1.7176513671875
Validation loss: 1.976948857307434

Epoch: 5| Step: 5
Training loss: 1.4246588945388794
Validation loss: 2.017059371035586

Epoch: 5| Step: 6
Training loss: 2.0031626224517822
Validation loss: 2.047706118194006

Epoch: 5| Step: 7
Training loss: 2.133312702178955
Validation loss: 2.052904663547393

Epoch: 5| Step: 8
Training loss: 1.3756909370422363
Validation loss: 2.034787380567161

Epoch: 5| Step: 9
Training loss: 2.2717528343200684
Validation loss: 1.9908375611869238

Epoch: 5| Step: 10
Training loss: 2.2315754890441895
Validation loss: 1.9472419036331998

Epoch: 131| Step: 0
Training loss: 1.8881042003631592
Validation loss: 1.933603044479124

Epoch: 5| Step: 1
Training loss: 2.1960175037384033
Validation loss: 1.9038281735553537

Epoch: 5| Step: 2
Training loss: 2.018009662628174
Validation loss: 1.9410693722386514

Epoch: 5| Step: 3
Training loss: 1.978742003440857
Validation loss: 1.933311991794135

Epoch: 5| Step: 4
Training loss: 2.0036861896514893
Validation loss: 1.9254265267361876

Epoch: 5| Step: 5
Training loss: 1.304753065109253
Validation loss: 1.9177056948343914

Epoch: 5| Step: 6
Training loss: 2.428478240966797
Validation loss: 1.9390247637225735

Epoch: 5| Step: 7
Training loss: 1.92108154296875
Validation loss: 1.9380809004588793

Epoch: 5| Step: 8
Training loss: 1.9643833637237549
Validation loss: 1.9340803815472511

Epoch: 5| Step: 9
Training loss: 1.669116735458374
Validation loss: 1.9546851675997499

Epoch: 5| Step: 10
Training loss: 1.2106026411056519
Validation loss: 1.954012579815362

Epoch: 132| Step: 0
Training loss: 1.9468978643417358
Validation loss: 1.9825914418825539

Epoch: 5| Step: 1
Training loss: 2.161452531814575
Validation loss: 2.0054722742367814

Epoch: 5| Step: 2
Training loss: 1.8753433227539062
Validation loss: 2.0175010414533716

Epoch: 5| Step: 3
Training loss: 1.8211473226547241
Validation loss: 1.9950796634920183

Epoch: 5| Step: 4
Training loss: 1.893799066543579
Validation loss: 1.9874831989247312

Epoch: 5| Step: 5
Training loss: 1.9053866863250732
Validation loss: 1.9349692983012046

Epoch: 5| Step: 6
Training loss: 1.8508713245391846
Validation loss: 1.9235269805436492

Epoch: 5| Step: 7
Training loss: 2.0123372077941895
Validation loss: 1.9470476809368338

Epoch: 5| Step: 8
Training loss: 1.4707943201065063
Validation loss: 1.9775167408809866

Epoch: 5| Step: 9
Training loss: 1.5136592388153076
Validation loss: 2.015888039783765

Epoch: 5| Step: 10
Training loss: 2.3335342407226562
Validation loss: 2.058122093959521

Epoch: 133| Step: 0
Training loss: 2.0416946411132812
Validation loss: 2.0609640703406384

Epoch: 5| Step: 1
Training loss: 1.6810821294784546
Validation loss: 2.015537526017876

Epoch: 5| Step: 2
Training loss: 1.9261375665664673
Validation loss: 1.9899971382592314

Epoch: 5| Step: 3
Training loss: 2.2068705558776855
Validation loss: 1.9565605963430097

Epoch: 5| Step: 4
Training loss: 1.7823060750961304
Validation loss: 1.9740150538823937

Epoch: 5| Step: 5
Training loss: 2.194567918777466
Validation loss: 1.9825752191646124

Epoch: 5| Step: 6
Training loss: 2.0010266304016113
Validation loss: 1.9763380430077995

Epoch: 5| Step: 7
Training loss: 1.5999412536621094
Validation loss: 1.9806802785524757

Epoch: 5| Step: 8
Training loss: 1.764566421508789
Validation loss: 1.9803212663178802

Epoch: 5| Step: 9
Training loss: 1.7544902563095093
Validation loss: 1.9899342367725987

Epoch: 5| Step: 10
Training loss: 1.6325963735580444
Validation loss: 2.005906858751851

Epoch: 134| Step: 0
Training loss: 1.7169681787490845
Validation loss: 2.031570524297735

Epoch: 5| Step: 1
Training loss: 1.384971022605896
Validation loss: 2.070563421454481

Epoch: 5| Step: 2
Training loss: 1.8066486120224
Validation loss: 2.1243698340590282

Epoch: 5| Step: 3
Training loss: 2.1627488136291504
Validation loss: 2.1732981820260324

Epoch: 5| Step: 4
Training loss: 1.9679992198944092
Validation loss: 2.1179152316944574

Epoch: 5| Step: 5
Training loss: 1.8754154443740845
Validation loss: 2.032022378777945

Epoch: 5| Step: 6
Training loss: 1.9205471277236938
Validation loss: 1.968675204502639

Epoch: 5| Step: 7
Training loss: 1.815725326538086
Validation loss: 1.951407859402318

Epoch: 5| Step: 8
Training loss: 2.2016284465789795
Validation loss: 1.942921066796908

Epoch: 5| Step: 9
Training loss: 1.6641805171966553
Validation loss: 1.909922953574888

Epoch: 5| Step: 10
Training loss: 2.1852381229400635
Validation loss: 1.8994570509079964

Epoch: 135| Step: 0
Training loss: 2.061652421951294
Validation loss: 1.9016393179534583

Epoch: 5| Step: 1
Training loss: 1.9655367136001587
Validation loss: 1.9072336612209198

Epoch: 5| Step: 2
Training loss: 1.6379354000091553
Validation loss: 1.921751065920758

Epoch: 5| Step: 3
Training loss: 1.8108751773834229
Validation loss: 1.9128215723140265

Epoch: 5| Step: 4
Training loss: 2.7899744510650635
Validation loss: 1.9352541431303947

Epoch: 5| Step: 5
Training loss: 1.4011614322662354
Validation loss: 1.9998248725809076

Epoch: 5| Step: 6
Training loss: 1.5637569427490234
Validation loss: 2.075689437568829

Epoch: 5| Step: 7
Training loss: 1.72406005859375
Validation loss: 2.133843593699958

Epoch: 5| Step: 8
Training loss: 2.334749698638916
Validation loss: 2.1726724691288446

Epoch: 5| Step: 9
Training loss: 2.464113235473633
Validation loss: 2.1731347960810505

Epoch: 5| Step: 10
Training loss: 1.6196576356887817
Validation loss: 2.051437524057204

Epoch: 136| Step: 0
Training loss: 2.098762035369873
Validation loss: 1.9793369065048874

Epoch: 5| Step: 1
Training loss: 1.9635957479476929
Validation loss: 1.9414966798597766

Epoch: 5| Step: 2
Training loss: 1.9144935607910156
Validation loss: 1.941056292544129

Epoch: 5| Step: 3
Training loss: 1.5857290029525757
Validation loss: 1.9500405429511942

Epoch: 5| Step: 4
Training loss: 1.4876203536987305
Validation loss: 1.9340911949834516

Epoch: 5| Step: 5
Training loss: 2.2400944232940674
Validation loss: 1.9116241239732312

Epoch: 5| Step: 6
Training loss: 1.9790308475494385
Validation loss: 1.9214075150028351

Epoch: 5| Step: 7
Training loss: 2.0583090782165527
Validation loss: 1.927936432182148

Epoch: 5| Step: 8
Training loss: 1.8713128566741943
Validation loss: 1.9462719655806018

Epoch: 5| Step: 9
Training loss: 2.1745340824127197
Validation loss: 1.9790071210553568

Epoch: 5| Step: 10
Training loss: 2.085362672805786
Validation loss: 1.9910683221714471

Epoch: 137| Step: 0
Training loss: 2.170729875564575
Validation loss: 1.9656820553605274

Epoch: 5| Step: 1
Training loss: 1.4164011478424072
Validation loss: 1.9537225615593694

Epoch: 5| Step: 2
Training loss: 1.9323803186416626
Validation loss: 1.9531156427116805

Epoch: 5| Step: 3
Training loss: 1.7884708642959595
Validation loss: 1.961760841390138

Epoch: 5| Step: 4
Training loss: 1.611559271812439
Validation loss: 1.9954408240574661

Epoch: 5| Step: 5
Training loss: 2.4485490322113037
Validation loss: 2.039015011120868

Epoch: 5| Step: 6
Training loss: 1.864466667175293
Validation loss: 2.0339521438844743

Epoch: 5| Step: 7
Training loss: 1.4399385452270508
Validation loss: 2.0385186236391784

Epoch: 5| Step: 8
Training loss: 1.864330530166626
Validation loss: 2.0359076094883743

Epoch: 5| Step: 9
Training loss: 1.980566382408142
Validation loss: 1.9984043105956046

Epoch: 5| Step: 10
Training loss: 1.733364224433899
Validation loss: 1.984028580368206

Epoch: 138| Step: 0
Training loss: 1.169614315032959
Validation loss: 1.9783770115144792

Epoch: 5| Step: 1
Training loss: 1.9728164672851562
Validation loss: 1.9909924717359646

Epoch: 5| Step: 2
Training loss: 2.113848924636841
Validation loss: 1.9998866576020435

Epoch: 5| Step: 3
Training loss: 1.9078929424285889
Validation loss: 1.9852476837814494

Epoch: 5| Step: 4
Training loss: 2.0588879585266113
Validation loss: 1.965136230632823

Epoch: 5| Step: 5
Training loss: 2.1554811000823975
Validation loss: 1.9439636571432954

Epoch: 5| Step: 6
Training loss: 1.7035773992538452
Validation loss: 1.9509592620275353

Epoch: 5| Step: 7
Training loss: 1.967984914779663
Validation loss: 1.935936047184852

Epoch: 5| Step: 8
Training loss: 1.7826080322265625
Validation loss: 1.921206707595497

Epoch: 5| Step: 9
Training loss: 1.3946367502212524
Validation loss: 1.9546009520048737

Epoch: 5| Step: 10
Training loss: 1.6675920486450195
Validation loss: 1.9698991775512695

Epoch: 139| Step: 0
Training loss: 1.6112239360809326
Validation loss: 1.9704267286485242

Epoch: 5| Step: 1
Training loss: 1.2471376657485962
Validation loss: 1.9683859784116027

Epoch: 5| Step: 2
Training loss: 1.9354040622711182
Validation loss: 1.9840097068458475

Epoch: 5| Step: 3
Training loss: 1.4984155893325806
Validation loss: 1.9623993404449955

Epoch: 5| Step: 4
Training loss: 1.5973625183105469
Validation loss: 1.9468721740989274

Epoch: 5| Step: 5
Training loss: 1.8274176120758057
Validation loss: 1.9669673801750265

Epoch: 5| Step: 6
Training loss: 2.2849936485290527
Validation loss: 2.0072442703349616

Epoch: 5| Step: 7
Training loss: 1.924976110458374
Validation loss: 2.041021764919322

Epoch: 5| Step: 8
Training loss: 2.210732936859131
Validation loss: 2.063487155463106

Epoch: 5| Step: 9
Training loss: 2.5283451080322266
Validation loss: 2.0749943538378646

Epoch: 5| Step: 10
Training loss: 1.4405105113983154
Validation loss: 2.015032222194056

Epoch: 140| Step: 0
Training loss: 2.3004708290100098
Validation loss: 1.9937750113907682

Epoch: 5| Step: 1
Training loss: 1.6359421014785767
Validation loss: 1.9754893472117763

Epoch: 5| Step: 2
Training loss: 1.697792410850525
Validation loss: 1.9680713351054857

Epoch: 5| Step: 3
Training loss: 1.0580494403839111
Validation loss: 1.9434748952106764

Epoch: 5| Step: 4
Training loss: 1.2136932611465454
Validation loss: 1.9459040421311573

Epoch: 5| Step: 5
Training loss: 2.365600109100342
Validation loss: 1.9329524552950295

Epoch: 5| Step: 6
Training loss: 2.085418701171875
Validation loss: 1.9460429863263202

Epoch: 5| Step: 7
Training loss: 1.6461385488510132
Validation loss: 1.9502873189987675

Epoch: 5| Step: 8
Training loss: 1.824509620666504
Validation loss: 1.972787028999739

Epoch: 5| Step: 9
Training loss: 1.6475868225097656
Validation loss: 1.9664307871172506

Epoch: 5| Step: 10
Training loss: 1.9670870304107666
Validation loss: 1.9706518265508837

Epoch: 141| Step: 0
Training loss: 1.8834460973739624
Validation loss: 1.988317886988322

Epoch: 5| Step: 1
Training loss: 1.8167965412139893
Validation loss: 1.9889410054811867

Epoch: 5| Step: 2
Training loss: 1.7164214849472046
Validation loss: 2.0076928010550876

Epoch: 5| Step: 3
Training loss: 1.710540533065796
Validation loss: 2.00208544218412

Epoch: 5| Step: 4
Training loss: 2.0212795734405518
Validation loss: 1.9785131382685837

Epoch: 5| Step: 5
Training loss: 1.6674801111221313
Validation loss: 2.0356416356179023

Epoch: 5| Step: 6
Training loss: 1.9195168018341064
Validation loss: 2.02504325169389

Epoch: 5| Step: 7
Training loss: 1.5434765815734863
Validation loss: 2.05567237382294

Epoch: 5| Step: 8
Training loss: 1.549656629562378
Validation loss: 2.092246775986046

Epoch: 5| Step: 9
Training loss: 2.379132032394409
Validation loss: 2.1098668139467955

Epoch: 5| Step: 10
Training loss: 1.583622932434082
Validation loss: 2.1009407915094847

Epoch: 142| Step: 0
Training loss: 2.378406286239624
Validation loss: 2.055344248330721

Epoch: 5| Step: 1
Training loss: 1.9092750549316406
Validation loss: 1.9929467811379382

Epoch: 5| Step: 2
Training loss: 1.9012107849121094
Validation loss: 1.9301530750848914

Epoch: 5| Step: 3
Training loss: 1.8699287176132202
Validation loss: 1.9056915185784782

Epoch: 5| Step: 4
Training loss: 1.6491501331329346
Validation loss: 1.8965207581878991

Epoch: 5| Step: 5
Training loss: 1.8334248065948486
Validation loss: 1.8800066158335695

Epoch: 5| Step: 6
Training loss: 1.672403335571289
Validation loss: 1.8934373701772382

Epoch: 5| Step: 7
Training loss: 1.7139335870742798
Validation loss: 1.8871518117125317

Epoch: 5| Step: 8
Training loss: 1.2508809566497803
Validation loss: 1.8873781619533416

Epoch: 5| Step: 9
Training loss: 1.9621556997299194
Validation loss: 1.8816085938484437

Epoch: 5| Step: 10
Training loss: 2.2628042697906494
Validation loss: 1.9038658193362656

Epoch: 143| Step: 0
Training loss: 2.3670494556427
Validation loss: 1.9146693098929621

Epoch: 5| Step: 1
Training loss: 1.7802845239639282
Validation loss: 1.9414886236190796

Epoch: 5| Step: 2
Training loss: 2.258922576904297
Validation loss: 1.9893638087857155

Epoch: 5| Step: 3
Training loss: 1.6475845575332642
Validation loss: 2.0249673999765867

Epoch: 5| Step: 4
Training loss: 1.4159798622131348
Validation loss: 2.0602464099084177

Epoch: 5| Step: 5
Training loss: 1.0828979015350342
Validation loss: 2.084468424961131

Epoch: 5| Step: 6
Training loss: 1.7632757425308228
Validation loss: 2.066848793337422

Epoch: 5| Step: 7
Training loss: 2.651364803314209
Validation loss: 2.0747600806656705

Epoch: 5| Step: 8
Training loss: 1.7332642078399658
Validation loss: 2.056950625552926

Epoch: 5| Step: 9
Training loss: 1.5553115606307983
Validation loss: 2.0388717433457733

Epoch: 5| Step: 10
Training loss: 1.6358009576797485
Validation loss: 2.0020448776983444

Epoch: 144| Step: 0
Training loss: 1.4883893728256226
Validation loss: 2.0068240422074513

Epoch: 5| Step: 1
Training loss: 1.8718265295028687
Validation loss: 1.9868655871319514

Epoch: 5| Step: 2
Training loss: 1.7158832550048828
Validation loss: 1.9727274397368073

Epoch: 5| Step: 3
Training loss: 1.9281034469604492
Validation loss: 1.9929167070696432

Epoch: 5| Step: 4
Training loss: 2.005711555480957
Validation loss: 1.9906294679128995

Epoch: 5| Step: 5
Training loss: 1.8720905780792236
Validation loss: 1.9903811306081793

Epoch: 5| Step: 6
Training loss: 1.453038215637207
Validation loss: 2.0219116723665627

Epoch: 5| Step: 7
Training loss: 1.2065632343292236
Validation loss: 1.9883213504668205

Epoch: 5| Step: 8
Training loss: 2.237922430038452
Validation loss: 1.9731791262985559

Epoch: 5| Step: 9
Training loss: 1.6389033794403076
Validation loss: 1.9677736502821728

Epoch: 5| Step: 10
Training loss: 2.2635581493377686
Validation loss: 1.9599078521933606

Epoch: 145| Step: 0
Training loss: 1.6262617111206055
Validation loss: 1.9614184287286573

Epoch: 5| Step: 1
Training loss: 1.9812984466552734
Validation loss: 1.9416723379524805

Epoch: 5| Step: 2
Training loss: 1.3522565364837646
Validation loss: 1.9633442278831237

Epoch: 5| Step: 3
Training loss: 2.097195863723755
Validation loss: 1.9769941760647682

Epoch: 5| Step: 4
Training loss: 1.5277175903320312
Validation loss: 1.9962843618085306

Epoch: 5| Step: 5
Training loss: 1.1685140132904053
Validation loss: 2.015154242515564

Epoch: 5| Step: 6
Training loss: 1.0108861923217773
Validation loss: 2.0438050416208084

Epoch: 5| Step: 7
Training loss: 1.788863182067871
Validation loss: 2.0690645697296306

Epoch: 5| Step: 8
Training loss: 2.1610991954803467
Validation loss: 2.04364562290971

Epoch: 5| Step: 9
Training loss: 2.5600380897521973
Validation loss: 2.0179470533965738

Epoch: 5| Step: 10
Training loss: 1.9571449756622314
Validation loss: 1.9875917332146757

Epoch: 146| Step: 0
Training loss: 1.45406973361969
Validation loss: 1.9731783841245918

Epoch: 5| Step: 1
Training loss: 2.021975040435791
Validation loss: 1.9762114786332654

Epoch: 5| Step: 2
Training loss: 1.5980594158172607
Validation loss: 1.9778282924364972

Epoch: 5| Step: 3
Training loss: 1.7273553609848022
Validation loss: 2.011157476773826

Epoch: 5| Step: 4
Training loss: 1.8022644519805908
Validation loss: 1.999762615849895

Epoch: 5| Step: 5
Training loss: 2.1935012340545654
Validation loss: 2.0006136663498415

Epoch: 5| Step: 6
Training loss: 1.585850715637207
Validation loss: 1.9904958971085087

Epoch: 5| Step: 7
Training loss: 1.5653358697891235
Validation loss: 1.9674960669650827

Epoch: 5| Step: 8
Training loss: 1.5230072736740112
Validation loss: 1.9721026702593731

Epoch: 5| Step: 9
Training loss: 1.6153074502944946
Validation loss: 1.9628329200129355

Epoch: 5| Step: 10
Training loss: 1.525207757949829
Validation loss: 1.9575609314826228

Epoch: 147| Step: 0
Training loss: 1.9243892431259155
Validation loss: 1.9662960165290422

Epoch: 5| Step: 1
Training loss: 1.848351240158081
Validation loss: 1.9572406020215762

Epoch: 5| Step: 2
Training loss: 1.3583672046661377
Validation loss: 1.9744023302549958

Epoch: 5| Step: 3
Training loss: 2.3554272651672363
Validation loss: 2.0189015493598035

Epoch: 5| Step: 4
Training loss: 1.4247034788131714
Validation loss: 2.0551846950284895

Epoch: 5| Step: 5
Training loss: 1.6609073877334595
Validation loss: 2.0761020952655422

Epoch: 5| Step: 6
Training loss: 1.6459636688232422
Validation loss: 2.088951544095111

Epoch: 5| Step: 7
Training loss: 1.7500784397125244
Validation loss: 2.054686320725308

Epoch: 5| Step: 8
Training loss: 1.5894898176193237
Validation loss: 2.019874172825967

Epoch: 5| Step: 9
Training loss: 1.7945085763931274
Validation loss: 2.0070144617429344

Epoch: 5| Step: 10
Training loss: 1.7890695333480835
Validation loss: 1.9883094897834204

Epoch: 148| Step: 0
Training loss: 2.124943733215332
Validation loss: 1.9881494891258977

Epoch: 5| Step: 1
Training loss: 1.4297350645065308
Validation loss: 1.9601821925050469

Epoch: 5| Step: 2
Training loss: 1.2238280773162842
Validation loss: 1.9433962760433074

Epoch: 5| Step: 3
Training loss: 1.8812379837036133
Validation loss: 1.978269443717054

Epoch: 5| Step: 4
Training loss: 1.7455625534057617
Validation loss: 2.015545501503893

Epoch: 5| Step: 5
Training loss: 1.8316075801849365
Validation loss: 2.0510930143376833

Epoch: 5| Step: 6
Training loss: 1.5480581521987915
Validation loss: 2.1032605735204553

Epoch: 5| Step: 7
Training loss: 1.6153686046600342
Validation loss: 2.079922406904159

Epoch: 5| Step: 8
Training loss: 1.5927915573120117
Validation loss: 2.014071954193936

Epoch: 5| Step: 9
Training loss: 2.061469793319702
Validation loss: 1.9726249889660907

Epoch: 5| Step: 10
Training loss: 1.9754407405853271
Validation loss: 1.9618656071283485

Epoch: 149| Step: 0
Training loss: 2.178128480911255
Validation loss: 1.9519881292056012

Epoch: 5| Step: 1
Training loss: 2.495018482208252
Validation loss: 1.989657684039044

Epoch: 5| Step: 2
Training loss: 1.9839155673980713
Validation loss: 1.979435714342261

Epoch: 5| Step: 3
Training loss: 2.1315221786499023
Validation loss: 1.9747920549044045

Epoch: 5| Step: 4
Training loss: 1.737783432006836
Validation loss: 1.975023567035634

Epoch: 5| Step: 5
Training loss: 1.4605541229248047
Validation loss: 2.0172106040421354

Epoch: 5| Step: 6
Training loss: 1.5984359979629517
Validation loss: 2.0906559587806783

Epoch: 5| Step: 7
Training loss: 1.7570133209228516
Validation loss: 2.1990509853568128

Epoch: 5| Step: 8
Training loss: 1.41574227809906
Validation loss: 2.236806918216008

Epoch: 5| Step: 9
Training loss: 1.838834524154663
Validation loss: 2.225752486977526

Epoch: 5| Step: 10
Training loss: 1.5521796941757202
Validation loss: 2.176100733459637

Epoch: 150| Step: 0
Training loss: 1.4361947774887085
Validation loss: 2.0709512541371007

Epoch: 5| Step: 1
Training loss: 1.333516001701355
Validation loss: 1.9922384395394275

Epoch: 5| Step: 2
Training loss: 1.9340299367904663
Validation loss: 1.9551120445292482

Epoch: 5| Step: 3
Training loss: 2.2167131900787354
Validation loss: 1.9387648900349934

Epoch: 5| Step: 4
Training loss: 2.676872968673706
Validation loss: 1.9372348388036091

Epoch: 5| Step: 5
Training loss: 1.5252586603164673
Validation loss: 1.9333131890143118

Epoch: 5| Step: 6
Training loss: 1.3041470050811768
Validation loss: 1.921153501797748

Epoch: 5| Step: 7
Training loss: 1.6097627878189087
Validation loss: 1.9451963939974386

Epoch: 5| Step: 8
Training loss: 1.8899112939834595
Validation loss: 1.9604587811295704

Epoch: 5| Step: 9
Training loss: 1.9149097204208374
Validation loss: 1.9569828997376144

Epoch: 5| Step: 10
Training loss: 1.1382054090499878
Validation loss: 1.9730292404851606

Epoch: 151| Step: 0
Training loss: 1.532306432723999
Validation loss: 1.9690751837145897

Epoch: 5| Step: 1
Training loss: 1.3624392747879028
Validation loss: 1.9469492012454617

Epoch: 5| Step: 2
Training loss: 2.007589101791382
Validation loss: 1.967876095925608

Epoch: 5| Step: 3
Training loss: 1.9217555522918701
Validation loss: 1.9804320104660527

Epoch: 5| Step: 4
Training loss: 1.8338148593902588
Validation loss: 1.991082424758583

Epoch: 5| Step: 5
Training loss: 1.6424182653427124
Validation loss: 2.0236545788344515

Epoch: 5| Step: 6
Training loss: 1.0965940952301025
Validation loss: 2.0674721092306156

Epoch: 5| Step: 7
Training loss: 2.1605589389801025
Validation loss: 2.100149868637003

Epoch: 5| Step: 8
Training loss: 1.649698257446289
Validation loss: 2.1022479918695267

Epoch: 5| Step: 9
Training loss: 2.051433801651001
Validation loss: 2.0614952323257283

Epoch: 5| Step: 10
Training loss: 1.7267675399780273
Validation loss: 2.0330040659955753

Epoch: 152| Step: 0
Training loss: 1.7307459115982056
Validation loss: 1.9659851853565504

Epoch: 5| Step: 1
Training loss: 1.8780018091201782
Validation loss: 1.9432328131891066

Epoch: 5| Step: 2
Training loss: 1.2148268222808838
Validation loss: 1.9205834750206239

Epoch: 5| Step: 3
Training loss: 1.3668007850646973
Validation loss: 1.9143045948397728

Epoch: 5| Step: 4
Training loss: 1.5368168354034424
Validation loss: 1.9318184070689703

Epoch: 5| Step: 5
Training loss: 1.3332650661468506
Validation loss: 1.9490492125993133

Epoch: 5| Step: 6
Training loss: 1.7568657398223877
Validation loss: 1.9894402655222083

Epoch: 5| Step: 7
Training loss: 2.1014819145202637
Validation loss: 2.019975621213195

Epoch: 5| Step: 8
Training loss: 1.4990720748901367
Validation loss: 2.0394249693039925

Epoch: 5| Step: 9
Training loss: 2.0686025619506836
Validation loss: 2.0376780584294307

Epoch: 5| Step: 10
Training loss: 1.9082250595092773
Validation loss: 2.0187135716920257

Epoch: 153| Step: 0
Training loss: 1.8070003986358643
Validation loss: 1.9834778347323019

Epoch: 5| Step: 1
Training loss: 1.3079944849014282
Validation loss: 1.9529399923098985

Epoch: 5| Step: 2
Training loss: 1.2864099740982056
Validation loss: 1.9608826714177285

Epoch: 5| Step: 3
Training loss: 1.8341999053955078
Validation loss: 1.959120761963629

Epoch: 5| Step: 4
Training loss: 2.2333226203918457
Validation loss: 1.9665698389853201

Epoch: 5| Step: 5
Training loss: 1.669995665550232
Validation loss: 1.9661595539380146

Epoch: 5| Step: 6
Training loss: 1.679027795791626
Validation loss: 1.9987933328074794

Epoch: 5| Step: 7
Training loss: 1.6016318798065186
Validation loss: 2.0397489314438193

Epoch: 5| Step: 8
Training loss: 1.807905912399292
Validation loss: 2.073191950398107

Epoch: 5| Step: 9
Training loss: 1.7205314636230469
Validation loss: 2.0838680305788593

Epoch: 5| Step: 10
Training loss: 1.2708289623260498
Validation loss: 2.0500647355151433

Epoch: 154| Step: 0
Training loss: 1.6276273727416992
Validation loss: 2.0029050739862586

Epoch: 5| Step: 1
Training loss: 1.7671016454696655
Validation loss: 1.9629656319977136

Epoch: 5| Step: 2
Training loss: 1.5849788188934326
Validation loss: 1.9559884096986504

Epoch: 5| Step: 3
Training loss: 1.9065258502960205
Validation loss: 1.9356398531185683

Epoch: 5| Step: 4
Training loss: 1.6000953912734985
Validation loss: 1.9560820492365028

Epoch: 5| Step: 5
Training loss: 1.550245761871338
Validation loss: 1.987744867160756

Epoch: 5| Step: 6
Training loss: 1.8032146692276
Validation loss: 2.033507340697832

Epoch: 5| Step: 7
Training loss: 1.2643691301345825
Validation loss: 2.0691877808622134

Epoch: 5| Step: 8
Training loss: 1.6170876026153564
Validation loss: 2.0781860018289215

Epoch: 5| Step: 9
Training loss: 1.8306703567504883
Validation loss: 2.0106009693555933

Epoch: 5| Step: 10
Training loss: 1.3069826364517212
Validation loss: 1.9912134934497137

Epoch: 155| Step: 0
Training loss: 1.6621173620224
Validation loss: 1.9548563598304667

Epoch: 5| Step: 1
Training loss: 1.8319282531738281
Validation loss: 1.9299721000015095

Epoch: 5| Step: 2
Training loss: 1.7292636632919312
Validation loss: 1.9292380053509948

Epoch: 5| Step: 3
Training loss: 1.7658195495605469
Validation loss: 1.950584715412509

Epoch: 5| Step: 4
Training loss: 1.885335922241211
Validation loss: 1.9848189943580217

Epoch: 5| Step: 5
Training loss: 1.6569786071777344
Validation loss: 2.0150633217186056

Epoch: 5| Step: 6
Training loss: 1.4714081287384033
Validation loss: 2.0642596085866294

Epoch: 5| Step: 7
Training loss: 1.8029348850250244
Validation loss: 2.081198042438876

Epoch: 5| Step: 8
Training loss: 1.5203683376312256
Validation loss: 2.027970214043894

Epoch: 5| Step: 9
Training loss: 1.2245686054229736
Validation loss: 2.0064727016674575

Epoch: 5| Step: 10
Training loss: 1.2717370986938477
Validation loss: 1.9479469137807046

Epoch: 156| Step: 0
Training loss: 1.6387662887573242
Validation loss: 1.941924096435629

Epoch: 5| Step: 1
Training loss: 2.080540418624878
Validation loss: 1.9511178488372474

Epoch: 5| Step: 2
Training loss: 1.909379243850708
Validation loss: 1.9469006420463644

Epoch: 5| Step: 3
Training loss: 1.3700878620147705
Validation loss: 1.9366753665349816

Epoch: 5| Step: 4
Training loss: 1.146277666091919
Validation loss: 1.9374164778699157

Epoch: 5| Step: 5
Training loss: 1.2312276363372803
Validation loss: 1.9736868694264402

Epoch: 5| Step: 6
Training loss: 1.2267937660217285
Validation loss: 1.9886604496227798

Epoch: 5| Step: 7
Training loss: 1.9054229259490967
Validation loss: 2.0017431397591867

Epoch: 5| Step: 8
Training loss: 1.4930009841918945
Validation loss: 2.0421284526906986

Epoch: 5| Step: 9
Training loss: 1.5069546699523926
Validation loss: 2.043599699133186

Epoch: 5| Step: 10
Training loss: 2.1486079692840576
Validation loss: 2.047712961832682

Epoch: 157| Step: 0
Training loss: 1.3619107007980347
Validation loss: 1.9803046103446715

Epoch: 5| Step: 1
Training loss: 1.5865956544876099
Validation loss: 1.9614137577754196

Epoch: 5| Step: 2
Training loss: 1.432105302810669
Validation loss: 1.9458576017810452

Epoch: 5| Step: 3
Training loss: 2.1349899768829346
Validation loss: 1.9232223136450655

Epoch: 5| Step: 4
Training loss: 1.4862877130508423
Validation loss: 1.9154962519163727

Epoch: 5| Step: 5
Training loss: 1.996009111404419
Validation loss: 1.9323869418072444

Epoch: 5| Step: 6
Training loss: 1.099959135055542
Validation loss: 1.9418095132356048

Epoch: 5| Step: 7
Training loss: 1.7190039157867432
Validation loss: 1.9342126102857693

Epoch: 5| Step: 8
Training loss: 1.3369419574737549
Validation loss: 1.9504342591890724

Epoch: 5| Step: 9
Training loss: 1.570225715637207
Validation loss: 1.9916447900956677

Epoch: 5| Step: 10
Training loss: 1.5100167989730835
Validation loss: 2.0074150562286377

Epoch: 158| Step: 0
Training loss: 1.9516699314117432
Validation loss: 2.0102267752411547

Epoch: 5| Step: 1
Training loss: 1.6382732391357422
Validation loss: 2.0059894028530327

Epoch: 5| Step: 2
Training loss: 1.6574652194976807
Validation loss: 2.0047991237332745

Epoch: 5| Step: 3
Training loss: 1.2212493419647217
Validation loss: 1.9627303128601403

Epoch: 5| Step: 4
Training loss: 0.9932782053947449
Validation loss: 1.9400276573755408

Epoch: 5| Step: 5
Training loss: 1.7925968170166016
Validation loss: 1.921714598132718

Epoch: 5| Step: 6
Training loss: 1.4686105251312256
Validation loss: 1.9144791018578313

Epoch: 5| Step: 7
Training loss: 1.5202314853668213
Validation loss: 1.9112221733216317

Epoch: 5| Step: 8
Training loss: 1.9059371948242188
Validation loss: 1.9081385366378292

Epoch: 5| Step: 9
Training loss: 1.4160785675048828
Validation loss: 1.939750729068633

Epoch: 5| Step: 10
Training loss: 1.6966094970703125
Validation loss: 1.967363949744932

Epoch: 159| Step: 0
Training loss: 2.0175185203552246
Validation loss: 1.9882642979262977

Epoch: 5| Step: 1
Training loss: 2.164219379425049
Validation loss: 1.9856678016724125

Epoch: 5| Step: 2
Training loss: 1.5771598815917969
Validation loss: 1.9589628506732244

Epoch: 5| Step: 3
Training loss: 1.0155656337738037
Validation loss: 1.9475986573003954

Epoch: 5| Step: 4
Training loss: 1.3515336513519287
Validation loss: 1.9333422850537043

Epoch: 5| Step: 5
Training loss: 1.2775065898895264
Validation loss: 1.9399213457620272

Epoch: 5| Step: 6
Training loss: 1.7234933376312256
Validation loss: 1.9271527285216956

Epoch: 5| Step: 7
Training loss: 1.0430071353912354
Validation loss: 1.9645709972227774

Epoch: 5| Step: 8
Training loss: 1.3499832153320312
Validation loss: 1.9741063502527052

Epoch: 5| Step: 9
Training loss: 1.7522556781768799
Validation loss: 1.9651976323896838

Epoch: 5| Step: 10
Training loss: 1.7020319700241089
Validation loss: 1.950804087423509

Epoch: 160| Step: 0
Training loss: 1.2285759449005127
Validation loss: 1.931588286994606

Epoch: 5| Step: 1
Training loss: 1.6051689386367798
Validation loss: 1.9509537630183722

Epoch: 5| Step: 2
Training loss: 1.540202021598816
Validation loss: 1.958988630643455

Epoch: 5| Step: 3
Training loss: 2.0720551013946533
Validation loss: 1.9645792925229637

Epoch: 5| Step: 4
Training loss: 1.5955297946929932
Validation loss: 1.933441064691031

Epoch: 5| Step: 5
Training loss: 1.2387912273406982
Validation loss: 1.9268743914942588

Epoch: 5| Step: 6
Training loss: 1.2527717351913452
Validation loss: 1.9198749988309798

Epoch: 5| Step: 7
Training loss: 1.7978112697601318
Validation loss: 1.9094515333893478

Epoch: 5| Step: 8
Training loss: 1.6093887090682983
Validation loss: 1.9088232119878132

Epoch: 5| Step: 9
Training loss: 1.5701631307601929
Validation loss: 1.9092218850248603

Epoch: 5| Step: 10
Training loss: 1.4278804063796997
Validation loss: 1.9033051370292582

Epoch: 161| Step: 0
Training loss: 1.599031925201416
Validation loss: 1.918044077452793

Epoch: 5| Step: 1
Training loss: 1.0941269397735596
Validation loss: 1.9613803509742982

Epoch: 5| Step: 2
Training loss: 0.8889096975326538
Validation loss: 2.0396418725290606

Epoch: 5| Step: 3
Training loss: 1.9366499185562134
Validation loss: 2.0723359841172413

Epoch: 5| Step: 4
Training loss: 1.7587295770645142
Validation loss: 2.0693345005794237

Epoch: 5| Step: 5
Training loss: 1.7264769077301025
Validation loss: 2.046188960793198

Epoch: 5| Step: 6
Training loss: 1.4991166591644287
Validation loss: 2.017196839855563

Epoch: 5| Step: 7
Training loss: 1.0143654346466064
Validation loss: 1.9586411996554303

Epoch: 5| Step: 8
Training loss: 1.7777626514434814
Validation loss: 1.9349631929910311

Epoch: 5| Step: 9
Training loss: 1.659318208694458
Validation loss: 1.9149460664359472

Epoch: 5| Step: 10
Training loss: 1.8279660940170288
Validation loss: 1.9082399222158617

Epoch: 162| Step: 0
Training loss: 1.2723355293273926
Validation loss: 1.9175848678875995

Epoch: 5| Step: 1
Training loss: 1.5022773742675781
Validation loss: 1.9252686218548847

Epoch: 5| Step: 2
Training loss: 1.4255659580230713
Validation loss: 1.9183912661767775

Epoch: 5| Step: 3
Training loss: 1.4670617580413818
Validation loss: 1.9234876401962773

Epoch: 5| Step: 4
Training loss: 1.6439268589019775
Validation loss: 1.9189608814895793

Epoch: 5| Step: 5
Training loss: 0.8355366587638855
Validation loss: 1.9236465795065767

Epoch: 5| Step: 6
Training loss: 1.8096725940704346
Validation loss: 1.928172734475905

Epoch: 5| Step: 7
Training loss: 1.7510063648223877
Validation loss: 1.9399382683538622

Epoch: 5| Step: 8
Training loss: 1.4313329458236694
Validation loss: 1.948884674297866

Epoch: 5| Step: 9
Training loss: 1.9249063730239868
Validation loss: 1.9658262575826337

Epoch: 5| Step: 10
Training loss: 1.392578125
Validation loss: 1.9618506482852403

Epoch: 163| Step: 0
Training loss: 1.0310685634613037
Validation loss: 1.9507791470455866

Epoch: 5| Step: 1
Training loss: 1.711146593093872
Validation loss: 1.9483597688777472

Epoch: 5| Step: 2
Training loss: 1.2437598705291748
Validation loss: 1.9284728919306109

Epoch: 5| Step: 3
Training loss: 1.1702033281326294
Validation loss: 1.9160809619452364

Epoch: 5| Step: 4
Training loss: 1.3504531383514404
Validation loss: 1.9084281626568045

Epoch: 5| Step: 5
Training loss: 1.3829245567321777
Validation loss: 1.9044597635986984

Epoch: 5| Step: 6
Training loss: 1.6814056634902954
Validation loss: 1.9286441033886326

Epoch: 5| Step: 7
Training loss: 2.0512802600860596
Validation loss: 1.9328178628798454

Epoch: 5| Step: 8
Training loss: 1.6925170421600342
Validation loss: 1.9681185445477885

Epoch: 5| Step: 9
Training loss: 1.643514633178711
Validation loss: 1.963677728047935

Epoch: 5| Step: 10
Training loss: 1.263445496559143
Validation loss: 1.9684911927869242

Epoch: 164| Step: 0
Training loss: 1.431175947189331
Validation loss: 1.9503594444644066

Epoch: 5| Step: 1
Training loss: 1.2140271663665771
Validation loss: 1.9612665112300585

Epoch: 5| Step: 2
Training loss: 1.9538593292236328
Validation loss: 1.954703991131116

Epoch: 5| Step: 3
Training loss: 1.5228530168533325
Validation loss: 1.950047759599583

Epoch: 5| Step: 4
Training loss: 1.5354845523834229
Validation loss: 1.9577099853946316

Epoch: 5| Step: 5
Training loss: 1.4318757057189941
Validation loss: 1.959188292103429

Epoch: 5| Step: 6
Training loss: 1.156633973121643
Validation loss: 1.9678979996711976

Epoch: 5| Step: 7
Training loss: 1.7862942218780518
Validation loss: 1.966698085108111

Epoch: 5| Step: 8
Training loss: 1.031821370124817
Validation loss: 1.9448752787805372

Epoch: 5| Step: 9
Training loss: 1.1361887454986572
Validation loss: 1.945424263195325

Epoch: 5| Step: 10
Training loss: 1.8986107110977173
Validation loss: 1.9421943644041657

Epoch: 165| Step: 0
Training loss: 1.7566564083099365
Validation loss: 1.943545441473684

Epoch: 5| Step: 1
Training loss: 1.3678836822509766
Validation loss: 1.9222293182085919

Epoch: 5| Step: 2
Training loss: 1.128530740737915
Validation loss: 1.9024250045899422

Epoch: 5| Step: 3
Training loss: 1.4835646152496338
Validation loss: 1.91085894133455

Epoch: 5| Step: 4
Training loss: 1.3194458484649658
Validation loss: 1.918757184859245

Epoch: 5| Step: 5
Training loss: 1.0596728324890137
Validation loss: 1.928968596202071

Epoch: 5| Step: 6
Training loss: 1.5181246995925903
Validation loss: 1.9353198902581328

Epoch: 5| Step: 7
Training loss: 1.804608702659607
Validation loss: 1.9588826138486144

Epoch: 5| Step: 8
Training loss: 1.773924469947815
Validation loss: 1.9584136368125997

Epoch: 5| Step: 9
Training loss: 1.2675195932388306
Validation loss: 2.0006682090861823

Epoch: 5| Step: 10
Training loss: 1.343979001045227
Validation loss: 2.0288921376710296

Epoch: 166| Step: 0
Training loss: 1.4877090454101562
Validation loss: 2.024786276202048

Epoch: 5| Step: 1
Training loss: 1.8651835918426514
Validation loss: 2.0128526995258946

Epoch: 5| Step: 2
Training loss: 1.4659302234649658
Validation loss: 1.9974598474400018

Epoch: 5| Step: 3
Training loss: 1.186199426651001
Validation loss: 1.9540699271745579

Epoch: 5| Step: 4
Training loss: 1.288872480392456
Validation loss: 1.9215965706815001

Epoch: 5| Step: 5
Training loss: 1.614431619644165
Validation loss: 1.9117428346346783

Epoch: 5| Step: 6
Training loss: 0.8918854594230652
Validation loss: 1.9023386099005257

Epoch: 5| Step: 7
Training loss: 1.9887683391571045
Validation loss: 1.9074404073017899

Epoch: 5| Step: 8
Training loss: 1.2414487600326538
Validation loss: 1.8950639514512913

Epoch: 5| Step: 9
Training loss: 1.0533256530761719
Validation loss: 1.9051670464136268

Epoch: 5| Step: 10
Training loss: 1.9187873601913452
Validation loss: 1.9217696984608967

Epoch: 167| Step: 0
Training loss: 1.5288550853729248
Validation loss: 1.964537223180135

Epoch: 5| Step: 1
Training loss: 1.7338062524795532
Validation loss: 1.9869491220802389

Epoch: 5| Step: 2
Training loss: 1.5822057723999023
Validation loss: 1.966818101944462

Epoch: 5| Step: 3
Training loss: 0.9877068400382996
Validation loss: 1.9473568495883737

Epoch: 5| Step: 4
Training loss: 1.1326265335083008
Validation loss: 1.9528463989175775

Epoch: 5| Step: 5
Training loss: 2.070544958114624
Validation loss: 1.969449399619974

Epoch: 5| Step: 6
Training loss: 1.5923175811767578
Validation loss: 1.959600269153554

Epoch: 5| Step: 7
Training loss: 1.1519557237625122
Validation loss: 1.9668097931851622

Epoch: 5| Step: 8
Training loss: 1.262909173965454
Validation loss: 1.9737153463466193

Epoch: 5| Step: 9
Training loss: 1.244763731956482
Validation loss: 1.9844491533053819

Epoch: 5| Step: 10
Training loss: 1.4685392379760742
Validation loss: 1.9969181142827517

Epoch: 168| Step: 0
Training loss: 1.7202192544937134
Validation loss: 2.0074974465113815

Epoch: 5| Step: 1
Training loss: 1.5290883779525757
Validation loss: 2.013375666833693

Epoch: 5| Step: 2
Training loss: 1.303279161453247
Validation loss: 2.0288876820636053

Epoch: 5| Step: 3
Training loss: 1.2601748704910278
Validation loss: 1.9745304981867473

Epoch: 5| Step: 4
Training loss: 1.2696774005889893
Validation loss: 1.9456427020411338

Epoch: 5| Step: 5
Training loss: 1.5335737466812134
Validation loss: 1.9445507180306218

Epoch: 5| Step: 6
Training loss: 1.7838199138641357
Validation loss: 1.9277203634221067

Epoch: 5| Step: 7
Training loss: 1.0962879657745361
Validation loss: 1.911808890681113

Epoch: 5| Step: 8
Training loss: 1.36704683303833
Validation loss: 1.8949839286906744

Epoch: 5| Step: 9
Training loss: 1.3723894357681274
Validation loss: 1.9105617295029342

Epoch: 5| Step: 10
Training loss: 1.5556304454803467
Validation loss: 1.9222705735955188

Epoch: 169| Step: 0
Training loss: 1.762096643447876
Validation loss: 1.9271421868314025

Epoch: 5| Step: 1
Training loss: 1.3058598041534424
Validation loss: 1.908485080606194

Epoch: 5| Step: 2
Training loss: 0.7484103441238403
Validation loss: 1.911176284154256

Epoch: 5| Step: 3
Training loss: 1.0446739196777344
Validation loss: 1.9061602007958196

Epoch: 5| Step: 4
Training loss: 1.6342694759368896
Validation loss: 1.8994759795486287

Epoch: 5| Step: 5
Training loss: 1.6281646490097046
Validation loss: 1.9047581905959754

Epoch: 5| Step: 6
Training loss: 1.2466245889663696
Validation loss: 1.9177268423059934

Epoch: 5| Step: 7
Training loss: 0.9557579755783081
Validation loss: 1.9622186524893648

Epoch: 5| Step: 8
Training loss: 1.5328289270401
Validation loss: 1.9875584033227736

Epoch: 5| Step: 9
Training loss: 1.40970778465271
Validation loss: 1.985721811171501

Epoch: 5| Step: 10
Training loss: 2.345529556274414
Validation loss: 1.9693383503985662

Epoch: 170| Step: 0
Training loss: 1.544891119003296
Validation loss: 1.9794481569720852

Epoch: 5| Step: 1
Training loss: 1.5259469747543335
Validation loss: 1.9487644972339753

Epoch: 5| Step: 2
Training loss: 1.5609147548675537
Validation loss: 1.932586476367007

Epoch: 5| Step: 3
Training loss: 1.422134518623352
Validation loss: 1.9472312286335935

Epoch: 5| Step: 4
Training loss: 1.2453689575195312
Validation loss: 1.9589472586108791

Epoch: 5| Step: 5
Training loss: 1.4422369003295898
Validation loss: 1.9471418844756259

Epoch: 5| Step: 6
Training loss: 1.1140825748443604
Validation loss: 1.9428517920996553

Epoch: 5| Step: 7
Training loss: 1.245422601699829
Validation loss: 1.947143550842039

Epoch: 5| Step: 8
Training loss: 1.163214921951294
Validation loss: 1.950140280108298

Epoch: 5| Step: 9
Training loss: 1.2486566305160522
Validation loss: 1.976823781126289

Epoch: 5| Step: 10
Training loss: 1.7146960496902466
Validation loss: 2.009731169669859

Epoch: 171| Step: 0
Training loss: 1.7458248138427734
Validation loss: 2.0194696854519587

Epoch: 5| Step: 1
Training loss: 1.7456998825073242
Validation loss: 2.0138177653794647

Epoch: 5| Step: 2
Training loss: 0.9042118191719055
Validation loss: 1.995441157330749

Epoch: 5| Step: 3
Training loss: 1.7488800287246704
Validation loss: 1.9688602198836624

Epoch: 5| Step: 4
Training loss: 1.2854130268096924
Validation loss: 1.9434388004323488

Epoch: 5| Step: 5
Training loss: 1.722149133682251
Validation loss: 1.9611982837800057

Epoch: 5| Step: 6
Training loss: 1.5970923900604248
Validation loss: 1.9783325451676563

Epoch: 5| Step: 7
Training loss: 1.5304038524627686
Validation loss: 1.9801352588079308

Epoch: 5| Step: 8
Training loss: 1.2210056781768799
Validation loss: 1.956717437313449

Epoch: 5| Step: 9
Training loss: 1.2765729427337646
Validation loss: 1.960067996414759

Epoch: 5| Step: 10
Training loss: 1.2139770984649658
Validation loss: 1.9697806604446904

Epoch: 172| Step: 0
Training loss: 1.4964685440063477
Validation loss: 2.0035409248003395

Epoch: 5| Step: 1
Training loss: 1.6239697933197021
Validation loss: 2.024607568658808

Epoch: 5| Step: 2
Training loss: 1.2094978094100952
Validation loss: 2.029003971366472

Epoch: 5| Step: 3
Training loss: 1.5901861190795898
Validation loss: 2.0406946341196694

Epoch: 5| Step: 4
Training loss: 1.475936770439148
Validation loss: 2.009573869807746

Epoch: 5| Step: 5
Training loss: 0.9939220547676086
Validation loss: 1.9458158054659445

Epoch: 5| Step: 6
Training loss: 1.4196075201034546
Validation loss: 1.9094657385221092

Epoch: 5| Step: 7
Training loss: 1.4082204103469849
Validation loss: 1.903689863861248

Epoch: 5| Step: 8
Training loss: 1.3149135112762451
Validation loss: 1.9195110259517547

Epoch: 5| Step: 9
Training loss: 1.3792765140533447
Validation loss: 1.930188617398662

Epoch: 5| Step: 10
Training loss: 1.461622953414917
Validation loss: 1.9704415567459599

Epoch: 173| Step: 0
Training loss: 1.3944486379623413
Validation loss: 1.984364116063682

Epoch: 5| Step: 1
Training loss: 1.0214389562606812
Validation loss: 2.010491640337052

Epoch: 5| Step: 2
Training loss: 1.3090741634368896
Validation loss: 2.0429425034471738

Epoch: 5| Step: 3
Training loss: 1.0841106176376343
Validation loss: 2.038311243057251

Epoch: 5| Step: 4
Training loss: 1.0744285583496094
Validation loss: 2.023255626360575

Epoch: 5| Step: 5
Training loss: 1.2854112386703491
Validation loss: 1.9568814769867928

Epoch: 5| Step: 6
Training loss: 1.7967555522918701
Validation loss: 1.9236839138051516

Epoch: 5| Step: 7
Training loss: 1.7118622064590454
Validation loss: 1.9194443251497002

Epoch: 5| Step: 8
Training loss: 1.425840139389038
Validation loss: 1.910623614506055

Epoch: 5| Step: 9
Training loss: 1.937156081199646
Validation loss: 1.91682340252784

Epoch: 5| Step: 10
Training loss: 1.2526657581329346
Validation loss: 1.9009404105524863

Epoch: 174| Step: 0
Training loss: 1.4872795343399048
Validation loss: 1.929905713245433

Epoch: 5| Step: 1
Training loss: 1.3141169548034668
Validation loss: 1.939449566666798

Epoch: 5| Step: 2
Training loss: 1.3871417045593262
Validation loss: 1.968702107347468

Epoch: 5| Step: 3
Training loss: 1.0475037097930908
Validation loss: 2.0036200797686012

Epoch: 5| Step: 4
Training loss: 1.903753638267517
Validation loss: 2.052623785952086

Epoch: 5| Step: 5
Training loss: 1.5442124605178833
Validation loss: 2.0488566083292805

Epoch: 5| Step: 6
Training loss: 1.5799312591552734
Validation loss: 2.029953228530063

Epoch: 5| Step: 7
Training loss: 1.2533886432647705
Validation loss: 2.0348084639477473

Epoch: 5| Step: 8
Training loss: 1.262001395225525
Validation loss: 2.0258367728161555

Epoch: 5| Step: 9
Training loss: 1.4119879007339478
Validation loss: 1.9293041049793203

Epoch: 5| Step: 10
Training loss: 0.8960537314414978
Validation loss: 1.91329667645116

Epoch: 175| Step: 0
Training loss: 1.5675239562988281
Validation loss: 1.910923614296862

Epoch: 5| Step: 1
Training loss: 1.236753225326538
Validation loss: 1.8992817401885986

Epoch: 5| Step: 2
Training loss: 1.4216359853744507
Validation loss: 1.9008402362946542

Epoch: 5| Step: 3
Training loss: 1.4374879598617554
Validation loss: 1.9101000947336997

Epoch: 5| Step: 4
Training loss: 1.7361841201782227
Validation loss: 1.972263531018329

Epoch: 5| Step: 5
Training loss: 0.8770267367362976
Validation loss: 1.9959671676799815

Epoch: 5| Step: 6
Training loss: 1.2136406898498535
Validation loss: 1.9790478098777033

Epoch: 5| Step: 7
Training loss: 1.5723375082015991
Validation loss: 1.9895751245560185

Epoch: 5| Step: 8
Training loss: 1.4378914833068848
Validation loss: 1.9798646050114785

Epoch: 5| Step: 9
Training loss: 1.0878270864486694
Validation loss: 1.9557397032296786

Epoch: 5| Step: 10
Training loss: 1.4718437194824219
Validation loss: 1.972506352650222

Epoch: 176| Step: 0
Training loss: 1.2248656749725342
Validation loss: 1.9694620511865104

Epoch: 5| Step: 1
Training loss: 1.400705337524414
Validation loss: 1.960056548477501

Epoch: 5| Step: 2
Training loss: 1.4346396923065186
Validation loss: 1.951069090956001

Epoch: 5| Step: 3
Training loss: 1.0799787044525146
Validation loss: 1.964921876948367

Epoch: 5| Step: 4
Training loss: 1.4320106506347656
Validation loss: 1.972354499242639

Epoch: 5| Step: 5
Training loss: 1.5753898620605469
Validation loss: 1.9899462076925463

Epoch: 5| Step: 6
Training loss: 1.8073389530181885
Validation loss: 1.9845685394861365

Epoch: 5| Step: 7
Training loss: 1.2532331943511963
Validation loss: 2.0073982669461157

Epoch: 5| Step: 8
Training loss: 1.1083052158355713
Validation loss: 1.9937151106454993

Epoch: 5| Step: 9
Training loss: 1.158534288406372
Validation loss: 1.9714642801592428

Epoch: 5| Step: 10
Training loss: 1.334288239479065
Validation loss: 1.9428376382397068

Epoch: 177| Step: 0
Training loss: 1.6080633401870728
Validation loss: 1.9322065396975445

Epoch: 5| Step: 1
Training loss: 1.2001434564590454
Validation loss: 1.9245160959100212

Epoch: 5| Step: 2
Training loss: 1.2272436618804932
Validation loss: 1.9498010540521273

Epoch: 5| Step: 3
Training loss: 1.1878769397735596
Validation loss: 1.960531896160495

Epoch: 5| Step: 4
Training loss: 1.503171443939209
Validation loss: 1.9622916483109998

Epoch: 5| Step: 5
Training loss: 1.5369709730148315
Validation loss: 1.9661311026542418

Epoch: 5| Step: 6
Training loss: 1.4929338693618774
Validation loss: 1.9573700389554423

Epoch: 5| Step: 7
Training loss: 1.1085236072540283
Validation loss: 1.9603991303392636

Epoch: 5| Step: 8
Training loss: 0.927966296672821
Validation loss: 1.9609410852514289

Epoch: 5| Step: 9
Training loss: 1.4295928478240967
Validation loss: 1.9526503752636653

Epoch: 5| Step: 10
Training loss: 1.070719838142395
Validation loss: 1.961578083294694

Epoch: 178| Step: 0
Training loss: 1.1833115816116333
Validation loss: 1.9611329622166132

Epoch: 5| Step: 1
Training loss: 1.2854211330413818
Validation loss: 1.9723473415579846

Epoch: 5| Step: 2
Training loss: 1.2214457988739014
Validation loss: 1.927485199384792

Epoch: 5| Step: 3
Training loss: 1.3592665195465088
Validation loss: 1.9005955342323548

Epoch: 5| Step: 4
Training loss: 1.4677960872650146
Validation loss: 1.880419392739573

Epoch: 5| Step: 5
Training loss: 1.5967081785202026
Validation loss: 1.8765831557653283

Epoch: 5| Step: 6
Training loss: 1.4167813062667847
Validation loss: 1.8615825189057218

Epoch: 5| Step: 7
Training loss: 1.1309902667999268
Validation loss: 1.892022063655238

Epoch: 5| Step: 8
Training loss: 1.1837952136993408
Validation loss: 1.8831633393482496

Epoch: 5| Step: 9
Training loss: 1.812750220298767
Validation loss: 1.91692292305731

Epoch: 5| Step: 10
Training loss: 0.8593948483467102
Validation loss: 1.9952498610301683

Epoch: 179| Step: 0
Training loss: 1.0968601703643799
Validation loss: 2.0488001377351823

Epoch: 5| Step: 1
Training loss: 2.055790424346924
Validation loss: 2.102588135709045

Epoch: 5| Step: 2
Training loss: 1.0294420719146729
Validation loss: 2.0488906906497095

Epoch: 5| Step: 3
Training loss: 1.0663135051727295
Validation loss: 1.9626454666096678

Epoch: 5| Step: 4
Training loss: 1.555646538734436
Validation loss: 1.9250773024815384

Epoch: 5| Step: 5
Training loss: 1.4781620502471924
Validation loss: 1.9093779492121872

Epoch: 5| Step: 6
Training loss: 1.3958818912506104
Validation loss: 1.8776903895921604

Epoch: 5| Step: 7
Training loss: 1.257636308670044
Validation loss: 1.8946736781827864

Epoch: 5| Step: 8
Training loss: 1.5733904838562012
Validation loss: 1.885891552894346

Epoch: 5| Step: 9
Training loss: 1.0876176357269287
Validation loss: 1.886247056786732

Epoch: 5| Step: 10
Training loss: 1.4705318212509155
Validation loss: 1.8817818139189033

Epoch: 180| Step: 0
Training loss: 1.417331576347351
Validation loss: 1.9257488225096016

Epoch: 5| Step: 1
Training loss: 1.2300506830215454
Validation loss: 1.950956675314134

Epoch: 5| Step: 2
Training loss: 1.5905808210372925
Validation loss: 1.9875433598795245

Epoch: 5| Step: 3
Training loss: 1.2807700634002686
Validation loss: 2.0127733651027886

Epoch: 5| Step: 4
Training loss: 1.277031660079956
Validation loss: 2.001433403261246

Epoch: 5| Step: 5
Training loss: 1.1796941757202148
Validation loss: 1.9841390476431897

Epoch: 5| Step: 6
Training loss: 1.4468215703964233
Validation loss: 2.001833482455182

Epoch: 5| Step: 7
Training loss: 0.8441282510757446
Validation loss: 1.9593203657416887

Epoch: 5| Step: 8
Training loss: 0.9982544183731079
Validation loss: 1.947478009808448

Epoch: 5| Step: 9
Training loss: 1.7841367721557617
Validation loss: 1.9561549540488952

Epoch: 5| Step: 10
Training loss: 1.4379262924194336
Validation loss: 1.9275686189692507

Epoch: 181| Step: 0
Training loss: 1.5296425819396973
Validation loss: 1.9193371380529096

Epoch: 5| Step: 1
Training loss: 0.7363361120223999
Validation loss: 1.9134645359490507

Epoch: 5| Step: 2
Training loss: 1.6759001016616821
Validation loss: 1.9134591087218253

Epoch: 5| Step: 3
Training loss: 1.4285017251968384
Validation loss: 1.9123172965101016

Epoch: 5| Step: 4
Training loss: 1.7796707153320312
Validation loss: 1.9120126462751819

Epoch: 5| Step: 5
Training loss: 0.9639713168144226
Validation loss: 1.9374628682290354

Epoch: 5| Step: 6
Training loss: 0.953650176525116
Validation loss: 1.9340286306155625

Epoch: 5| Step: 7
Training loss: 1.2211993932724
Validation loss: 1.9734178076508224

Epoch: 5| Step: 8
Training loss: 1.246781349182129
Validation loss: 1.9738168921521915

Epoch: 5| Step: 9
Training loss: 1.0998400449752808
Validation loss: 1.9732330050519717

Epoch: 5| Step: 10
Training loss: 1.2201486825942993
Validation loss: 1.9944400428443827

Epoch: 182| Step: 0
Training loss: 1.4050061702728271
Validation loss: 1.9788846713240429

Epoch: 5| Step: 1
Training loss: 1.0552494525909424
Validation loss: 1.9387200596512004

Epoch: 5| Step: 2
Training loss: 0.8819354176521301
Validation loss: 1.9344267345243884

Epoch: 5| Step: 3
Training loss: 1.3844845294952393
Validation loss: 1.9272243656137937

Epoch: 5| Step: 4
Training loss: 1.2828369140625
Validation loss: 1.9018937336501254

Epoch: 5| Step: 5
Training loss: 1.191546082496643
Validation loss: 1.9025361448205926

Epoch: 5| Step: 6
Training loss: 1.511289358139038
Validation loss: 1.9097624414710588

Epoch: 5| Step: 7
Training loss: 1.238762617111206
Validation loss: 1.9249097877933132

Epoch: 5| Step: 8
Training loss: 1.2172343730926514
Validation loss: 1.9172440972379459

Epoch: 5| Step: 9
Training loss: 1.2567839622497559
Validation loss: 1.9283187568828624

Epoch: 5| Step: 10
Training loss: 1.2014615535736084
Validation loss: 1.9480110573512253

Epoch: 183| Step: 0
Training loss: 1.0075054168701172
Validation loss: 1.9803882132294357

Epoch: 5| Step: 1
Training loss: 0.8565144538879395
Validation loss: 2.02324782007484

Epoch: 5| Step: 2
Training loss: 1.0184221267700195
Validation loss: 2.0545932182701687

Epoch: 5| Step: 3
Training loss: 0.9498860239982605
Validation loss: 2.05011776954897

Epoch: 5| Step: 4
Training loss: 1.3628116846084595
Validation loss: 2.064377610401441

Epoch: 5| Step: 5
Training loss: 1.474331259727478
Validation loss: 2.0340429890540337

Epoch: 5| Step: 6
Training loss: 1.1834638118743896
Validation loss: 1.9964663444026824

Epoch: 5| Step: 7
Training loss: 1.3611576557159424
Validation loss: 1.955010410278074

Epoch: 5| Step: 8
Training loss: 1.3511464595794678
Validation loss: 1.9278503566659906

Epoch: 5| Step: 9
Training loss: 1.7991092205047607
Validation loss: 1.9250057717805267

Epoch: 5| Step: 10
Training loss: 1.1583960056304932
Validation loss: 1.9165652259703605

Epoch: 184| Step: 0
Training loss: 1.5607961416244507
Validation loss: 1.901043217669251

Epoch: 5| Step: 1
Training loss: 1.0641400814056396
Validation loss: 1.8983780684009675

Epoch: 5| Step: 2
Training loss: 1.642563819885254
Validation loss: 1.8921909768094298

Epoch: 5| Step: 3
Training loss: 1.0796383619308472
Validation loss: 1.8937904680928876

Epoch: 5| Step: 4
Training loss: 1.387321949005127
Validation loss: 1.90861980248523

Epoch: 5| Step: 5
Training loss: 1.264635443687439
Validation loss: 1.925922591199157

Epoch: 5| Step: 6
Training loss: 1.4497661590576172
Validation loss: 1.9127232938684442

Epoch: 5| Step: 7
Training loss: 1.0266447067260742
Validation loss: 1.9443266981391496

Epoch: 5| Step: 8
Training loss: 1.1699485778808594
Validation loss: 2.0117203420208347

Epoch: 5| Step: 9
Training loss: 1.1217294931411743
Validation loss: 1.989071770380902

Epoch: 5| Step: 10
Training loss: 0.7265893220901489
Validation loss: 1.9741284180712957

Epoch: 185| Step: 0
Training loss: 1.3950726985931396
Validation loss: 1.9426019755742883

Epoch: 5| Step: 1
Training loss: 1.235138177871704
Validation loss: 1.9067516108994842

Epoch: 5| Step: 2
Training loss: 0.9662456512451172
Validation loss: 1.8892939270183604

Epoch: 5| Step: 3
Training loss: 1.371781349182129
Validation loss: 1.9052383553597234

Epoch: 5| Step: 4
Training loss: 1.072736144065857
Validation loss: 1.9278236589124125

Epoch: 5| Step: 5
Training loss: 1.3038395643234253
Validation loss: 1.9547085364659627

Epoch: 5| Step: 6
Training loss: 1.3218294382095337
Validation loss: 1.9591765429383965

Epoch: 5| Step: 7
Training loss: 1.2537422180175781
Validation loss: 1.94948915255967

Epoch: 5| Step: 8
Training loss: 0.9611074328422546
Validation loss: 1.9230511444871143

Epoch: 5| Step: 9
Training loss: 1.265183687210083
Validation loss: 1.936258569840462

Epoch: 5| Step: 10
Training loss: 1.4330073595046997
Validation loss: 1.9532388999897947

Epoch: 186| Step: 0
Training loss: 0.9521503448486328
Validation loss: 1.9630283642840642

Epoch: 5| Step: 1
Training loss: 0.307794988155365
Validation loss: 2.011147565739129

Epoch: 5| Step: 2
Training loss: 1.134918451309204
Validation loss: 2.053064256586054

Epoch: 5| Step: 3
Training loss: 1.3332445621490479
Validation loss: 2.015343681458504

Epoch: 5| Step: 4
Training loss: 1.2888946533203125
Validation loss: 1.9747516570552703

Epoch: 5| Step: 5
Training loss: 1.3619656562805176
Validation loss: 1.951594204031011

Epoch: 5| Step: 6
Training loss: 1.258527159690857
Validation loss: 1.9279980633848457

Epoch: 5| Step: 7
Training loss: 1.300657033920288
Validation loss: 1.9273639314918107

Epoch: 5| Step: 8
Training loss: 1.4074636697769165
Validation loss: 1.9405749843966575

Epoch: 5| Step: 9
Training loss: 1.8408561944961548
Validation loss: 1.9579665635221748

Epoch: 5| Step: 10
Training loss: 1.478028416633606
Validation loss: 1.9573424016275713

Epoch: 187| Step: 0
Training loss: 1.0387156009674072
Validation loss: 1.9813273337579542

Epoch: 5| Step: 1
Training loss: 1.4933379888534546
Validation loss: 2.000517640062558

Epoch: 5| Step: 2
Training loss: 1.3118400573730469
Validation loss: 2.0040784446142053

Epoch: 5| Step: 3
Training loss: 1.4354296922683716
Validation loss: 1.9922925246659147

Epoch: 5| Step: 4
Training loss: 1.2315165996551514
Validation loss: 1.9768531989025813

Epoch: 5| Step: 5
Training loss: 1.3264153003692627
Validation loss: 1.9837646894557501

Epoch: 5| Step: 6
Training loss: 0.4747684597969055
Validation loss: 2.001393538649364

Epoch: 5| Step: 7
Training loss: 1.2612886428833008
Validation loss: 1.9712832461121261

Epoch: 5| Step: 8
Training loss: 1.0791767835617065
Validation loss: 1.9557107520359818

Epoch: 5| Step: 9
Training loss: 1.4060076475143433
Validation loss: 1.9378660827554681

Epoch: 5| Step: 10
Training loss: 1.3240405321121216
Validation loss: 1.9298856104573896

Epoch: 188| Step: 0
Training loss: 1.1088058948516846
Validation loss: 1.9065688399858371

Epoch: 5| Step: 1
Training loss: 1.3528361320495605
Validation loss: 1.9027814134474723

Epoch: 5| Step: 2
Training loss: 0.9096509218215942
Validation loss: 1.9043876150602936

Epoch: 5| Step: 3
Training loss: 1.3928136825561523
Validation loss: 1.9095381588064215

Epoch: 5| Step: 4
Training loss: 1.3562089204788208
Validation loss: 1.9011656468914402

Epoch: 5| Step: 5
Training loss: 1.584655523300171
Validation loss: 1.9148365400170768

Epoch: 5| Step: 6
Training loss: 1.0464742183685303
Validation loss: 1.9216604822425432

Epoch: 5| Step: 7
Training loss: 1.3639066219329834
Validation loss: 1.9460465972141554

Epoch: 5| Step: 8
Training loss: 1.1232455968856812
Validation loss: 1.9625374745297175

Epoch: 5| Step: 9
Training loss: 0.9786758422851562
Validation loss: 1.9852221396661573

Epoch: 5| Step: 10
Training loss: 1.1366026401519775
Validation loss: 2.018466188061622

Epoch: 189| Step: 0
Training loss: 0.9610090255737305
Validation loss: 2.0395710622110674

Epoch: 5| Step: 1
Training loss: 1.026301383972168
Validation loss: 2.051087494819395

Epoch: 5| Step: 2
Training loss: 1.1593481302261353
Validation loss: 2.0321703264790196

Epoch: 5| Step: 3
Training loss: 1.2134126424789429
Validation loss: 2.031184337472403

Epoch: 5| Step: 4
Training loss: 0.8702775835990906
Validation loss: 1.995734796729139

Epoch: 5| Step: 5
Training loss: 1.093252182006836
Validation loss: 1.9785130908412318

Epoch: 5| Step: 6
Training loss: 1.2930243015289307
Validation loss: 1.958615896522358

Epoch: 5| Step: 7
Training loss: 1.309654712677002
Validation loss: 1.9330572928151777

Epoch: 5| Step: 8
Training loss: 1.0745676755905151
Validation loss: 1.9362506328090545

Epoch: 5| Step: 9
Training loss: 1.2020223140716553
Validation loss: 1.920274455060241

Epoch: 5| Step: 10
Training loss: 1.6438461542129517
Validation loss: 1.8936172249496623

Epoch: 190| Step: 0
Training loss: 1.0851207971572876
Validation loss: 1.9212664506768669

Epoch: 5| Step: 1
Training loss: 0.9952720403671265
Validation loss: 1.9557140411869172

Epoch: 5| Step: 2
Training loss: 1.4245736598968506
Validation loss: 1.9702528394678587

Epoch: 5| Step: 3
Training loss: 1.3251327276229858
Validation loss: 1.982922618107129

Epoch: 5| Step: 4
Training loss: 1.108426809310913
Validation loss: 2.0009467768412765

Epoch: 5| Step: 5
Training loss: 1.208552598953247
Validation loss: 1.9997486555448143

Epoch: 5| Step: 6
Training loss: 0.7930444478988647
Validation loss: 1.9814646526049542

Epoch: 5| Step: 7
Training loss: 1.0003024339675903
Validation loss: 1.9353243099745883

Epoch: 5| Step: 8
Training loss: 1.274744987487793
Validation loss: 1.9407174228340067

Epoch: 5| Step: 9
Training loss: 1.072204828262329
Validation loss: 1.9363733606953775

Epoch: 5| Step: 10
Training loss: 1.4353080987930298
Validation loss: 1.9415794418704124

Epoch: 191| Step: 0
Training loss: 1.052379846572876
Validation loss: 1.9461394433052308

Epoch: 5| Step: 1
Training loss: 1.2398661375045776
Validation loss: 1.9761736392974854

Epoch: 5| Step: 2
Training loss: 1.2424451112747192
Validation loss: 2.006182078392275

Epoch: 5| Step: 3
Training loss: 1.1718076467514038
Validation loss: 1.995803427952592

Epoch: 5| Step: 4
Training loss: 1.0915690660476685
Validation loss: 1.9619193102723809

Epoch: 5| Step: 5
Training loss: 1.8282606601715088
Validation loss: 1.9218787685517342

Epoch: 5| Step: 6
Training loss: 1.229913592338562
Validation loss: 1.9060880984029462

Epoch: 5| Step: 7
Training loss: 0.981608510017395
Validation loss: 1.9181031873149257

Epoch: 5| Step: 8
Training loss: 0.9968101382255554
Validation loss: 1.9027988538947156

Epoch: 5| Step: 9
Training loss: 0.8531279563903809
Validation loss: 1.9007039403402677

Epoch: 5| Step: 10
Training loss: 1.4637038707733154
Validation loss: 1.9211213447714364

Epoch: 192| Step: 0
Training loss: 1.364015817642212
Validation loss: 1.9550518464016657

Epoch: 5| Step: 1
Training loss: 1.173969030380249
Validation loss: 1.9896632330391997

Epoch: 5| Step: 2
Training loss: 1.613684058189392
Validation loss: 2.0161099177534862

Epoch: 5| Step: 3
Training loss: 1.1396033763885498
Validation loss: 1.9958370295904015

Epoch: 5| Step: 4
Training loss: 0.9037752151489258
Validation loss: 1.935377993891316

Epoch: 5| Step: 5
Training loss: 1.2153675556182861
Validation loss: 1.9236016965681506

Epoch: 5| Step: 6
Training loss: 0.9669748544692993
Validation loss: 1.9046809750218545

Epoch: 5| Step: 7
Training loss: 1.6592676639556885
Validation loss: 1.8875151795725669

Epoch: 5| Step: 8
Training loss: 1.0434318780899048
Validation loss: 1.8895857180318525

Epoch: 5| Step: 9
Training loss: 1.1642544269561768
Validation loss: 1.8915565526613625

Epoch: 5| Step: 10
Training loss: 1.122802972793579
Validation loss: 1.895464240863759

Epoch: 193| Step: 0
Training loss: 1.1853224039077759
Validation loss: 1.93608687257254

Epoch: 5| Step: 1
Training loss: 1.3513069152832031
Validation loss: 1.950817633700627

Epoch: 5| Step: 2
Training loss: 1.5294581651687622
Validation loss: 1.985362147772184

Epoch: 5| Step: 3
Training loss: 1.0024337768554688
Validation loss: 2.000353536298198

Epoch: 5| Step: 4
Training loss: 1.411781668663025
Validation loss: 2.034125684410013

Epoch: 5| Step: 5
Training loss: 1.0196889638900757
Validation loss: 2.0328045737358833

Epoch: 5| Step: 6
Training loss: 1.0475444793701172
Validation loss: 2.036186631007861

Epoch: 5| Step: 7
Training loss: 1.401100516319275
Validation loss: 1.9816189812075706

Epoch: 5| Step: 8
Training loss: 0.8117160797119141
Validation loss: 1.92096802496141

Epoch: 5| Step: 9
Training loss: 0.8221327066421509
Validation loss: 1.8877053363348848

Epoch: 5| Step: 10
Training loss: 1.0426242351531982
Validation loss: 1.8902311690392033

Epoch: 194| Step: 0
Training loss: 1.2894127368927002
Validation loss: 1.8712548645593787

Epoch: 5| Step: 1
Training loss: 1.0936696529388428
Validation loss: 1.867005358460129

Epoch: 5| Step: 2
Training loss: 0.8858460187911987
Validation loss: 1.8687989878398117

Epoch: 5| Step: 3
Training loss: 1.5711300373077393
Validation loss: 1.8667067609807497

Epoch: 5| Step: 4
Training loss: 0.8524129986763
Validation loss: 1.8805203142986502

Epoch: 5| Step: 5
Training loss: 0.8998109698295593
Validation loss: 1.9440265752935921

Epoch: 5| Step: 6
Training loss: 1.2117353677749634
Validation loss: 1.9642232669297086

Epoch: 5| Step: 7
Training loss: 1.5199735164642334
Validation loss: 1.9905438884612052

Epoch: 5| Step: 8
Training loss: 1.1510961055755615
Validation loss: 1.964624007542928

Epoch: 5| Step: 9
Training loss: 0.9457869529724121
Validation loss: 1.960943986651718

Epoch: 5| Step: 10
Training loss: 1.0845184326171875
Validation loss: 1.9143968397571194

Epoch: 195| Step: 0
Training loss: 1.0347368717193604
Validation loss: 1.9274418738580519

Epoch: 5| Step: 1
Training loss: 1.4092031717300415
Validation loss: 1.9174233290456957

Epoch: 5| Step: 2
Training loss: 0.8913253545761108
Validation loss: 1.9493942260742188

Epoch: 5| Step: 3
Training loss: 0.9714179039001465
Validation loss: 1.9274556752174132

Epoch: 5| Step: 4
Training loss: 1.021279215812683
Validation loss: 1.9385354506072177

Epoch: 5| Step: 5
Training loss: 1.9375178813934326
Validation loss: 1.947890604695966

Epoch: 5| Step: 6
Training loss: 0.8638588190078735
Validation loss: 1.955205822503695

Epoch: 5| Step: 7
Training loss: 1.2317088842391968
Validation loss: 1.976571847033757

Epoch: 5| Step: 8
Training loss: 1.0004656314849854
Validation loss: 2.0030255856052523

Epoch: 5| Step: 9
Training loss: 1.0870803594589233
Validation loss: 2.0060253374038206

Epoch: 5| Step: 10
Training loss: 1.088175892829895
Validation loss: 1.9777283668518066

Epoch: 196| Step: 0
Training loss: 1.3281750679016113
Validation loss: 1.9148893766505743

Epoch: 5| Step: 1
Training loss: 0.7147011756896973
Validation loss: 1.913232022716153

Epoch: 5| Step: 2
Training loss: 1.1818034648895264
Validation loss: 1.9243858578384563

Epoch: 5| Step: 3
Training loss: 1.293206810951233
Validation loss: 1.9029305609323646

Epoch: 5| Step: 4
Training loss: 1.435349702835083
Validation loss: 1.9145398139953613

Epoch: 5| Step: 5
Training loss: 1.2248883247375488
Validation loss: 1.9096157473902549

Epoch: 5| Step: 6
Training loss: 1.2271803617477417
Validation loss: 1.9171867050150389

Epoch: 5| Step: 7
Training loss: 1.1101570129394531
Validation loss: 1.935895767263187

Epoch: 5| Step: 8
Training loss: 0.8630577921867371
Validation loss: 1.9339987026747836

Epoch: 5| Step: 9
Training loss: 0.9528903961181641
Validation loss: 1.9247810673970047

Epoch: 5| Step: 10
Training loss: 0.5211619138717651
Validation loss: 1.9095108803882395

Epoch: 197| Step: 0
Training loss: 0.9249780774116516
Validation loss: 1.9314388177728141

Epoch: 5| Step: 1
Training loss: 0.7766703367233276
Validation loss: 1.9549470409270255

Epoch: 5| Step: 2
Training loss: 0.9031413793563843
Validation loss: 1.9221675242147138

Epoch: 5| Step: 3
Training loss: 0.8940388560295105
Validation loss: 1.9096488811636483

Epoch: 5| Step: 4
Training loss: 1.1506850719451904
Validation loss: 1.9149420620292745

Epoch: 5| Step: 5
Training loss: 1.185288667678833
Validation loss: 1.9361084148448

Epoch: 5| Step: 6
Training loss: 1.029296636581421
Validation loss: 1.9407436052958171

Epoch: 5| Step: 7
Training loss: 1.162070870399475
Validation loss: 1.9352752957292783

Epoch: 5| Step: 8
Training loss: 1.447156310081482
Validation loss: 1.9610209208662792

Epoch: 5| Step: 9
Training loss: 1.1960656642913818
Validation loss: 1.972778921486229

Epoch: 5| Step: 10
Training loss: 1.245449185371399
Validation loss: 1.982150032956113

Epoch: 198| Step: 0
Training loss: 1.5747426748275757
Validation loss: 1.961798385907245

Epoch: 5| Step: 1
Training loss: 1.0574510097503662
Validation loss: 1.9454746489883752

Epoch: 5| Step: 2
Training loss: 1.3718147277832031
Validation loss: 1.9296333148915281

Epoch: 5| Step: 3
Training loss: 0.9860247373580933
Validation loss: 1.9216273805146575

Epoch: 5| Step: 4
Training loss: 1.1084856986999512
Validation loss: 1.9087166465738767

Epoch: 5| Step: 5
Training loss: 1.3181157112121582
Validation loss: 1.9282900235986198

Epoch: 5| Step: 6
Training loss: 0.6201751828193665
Validation loss: 1.9755840711696173

Epoch: 5| Step: 7
Training loss: 0.8538878560066223
Validation loss: 1.978808477360715

Epoch: 5| Step: 8
Training loss: 1.1035940647125244
Validation loss: 2.021751046180725

Epoch: 5| Step: 9
Training loss: 1.0856343507766724
Validation loss: 1.9956381423498994

Epoch: 5| Step: 10
Training loss: 0.7582488059997559
Validation loss: 2.005782490135521

Epoch: 199| Step: 0
Training loss: 1.1882933378219604
Validation loss: 1.968843078100553

Epoch: 5| Step: 1
Training loss: 0.7278383374214172
Validation loss: 1.9416969617207844

Epoch: 5| Step: 2
Training loss: 1.3603298664093018
Validation loss: 1.901849747985922

Epoch: 5| Step: 3
Training loss: 1.2270344495773315
Validation loss: 1.8756932315006052

Epoch: 5| Step: 4
Training loss: 1.0290863513946533
Validation loss: 1.8727559940789336

Epoch: 5| Step: 5
Training loss: 1.2107919454574585
Validation loss: 1.8913060336984613

Epoch: 5| Step: 6
Training loss: 1.0749298334121704
Validation loss: 1.8861695476757583

Epoch: 5| Step: 7
Training loss: 1.0545003414154053
Validation loss: 1.8973747389290923

Epoch: 5| Step: 8
Training loss: 0.8898709416389465
Validation loss: 1.9105728698033158

Epoch: 5| Step: 9
Training loss: 1.0691472291946411
Validation loss: 1.9220423826607325

Epoch: 5| Step: 10
Training loss: 1.1417328119277954
Validation loss: 1.9336522945793726

Epoch: 200| Step: 0
Training loss: 0.7874270677566528
Validation loss: 1.960303924416983

Epoch: 5| Step: 1
Training loss: 1.2315517663955688
Validation loss: 1.9681837315200477

Epoch: 5| Step: 2
Training loss: 0.9875567555427551
Validation loss: 1.9607336444239463

Epoch: 5| Step: 3
Training loss: 1.1827785968780518
Validation loss: 1.982264054718838

Epoch: 5| Step: 4
Training loss: 1.1386982202529907
Validation loss: 1.9309473704266291

Epoch: 5| Step: 5
Training loss: 1.2609270811080933
Validation loss: 1.9197338896413003

Epoch: 5| Step: 6
Training loss: 1.041212797164917
Validation loss: 1.889521965416529

Epoch: 5| Step: 7
Training loss: 0.8714173436164856
Validation loss: 1.8822063169171732

Epoch: 5| Step: 8
Training loss: 0.7373783588409424
Validation loss: 1.8852324562688028

Epoch: 5| Step: 9
Training loss: 1.3337194919586182
Validation loss: 1.8853399304933445

Epoch: 5| Step: 10
Training loss: 1.0589103698730469
Validation loss: 1.8895421745956584

Epoch: 201| Step: 0
Training loss: 1.1225030422210693
Validation loss: 1.8872675370144587

Epoch: 5| Step: 1
Training loss: 0.8547652959823608
Validation loss: 1.9216790506916661

Epoch: 5| Step: 2
Training loss: 1.4930040836334229
Validation loss: 1.9024589010464248

Epoch: 5| Step: 3
Training loss: 0.8402616381645203
Validation loss: 1.9249566011531378

Epoch: 5| Step: 4
Training loss: 0.9259578585624695
Validation loss: 1.9039174574677662

Epoch: 5| Step: 5
Training loss: 1.5810552835464478
Validation loss: 1.9160902756516651

Epoch: 5| Step: 6
Training loss: 1.0608081817626953
Validation loss: 1.9279381088031236

Epoch: 5| Step: 7
Training loss: 1.0312142372131348
Validation loss: 1.9466215987359323

Epoch: 5| Step: 8
Training loss: 1.0424917936325073
Validation loss: 1.9355415759548065

Epoch: 5| Step: 9
Training loss: 0.5104748010635376
Validation loss: 1.95010708737117

Epoch: 5| Step: 10
Training loss: 0.8650585412979126
Validation loss: 1.9751194753954489

Epoch: 202| Step: 0
Training loss: 1.6503379344940186
Validation loss: 2.000094090738604

Epoch: 5| Step: 1
Training loss: 0.8800674676895142
Validation loss: 1.980050830430882

Epoch: 5| Step: 2
Training loss: 0.8787981271743774
Validation loss: 1.966405281456568

Epoch: 5| Step: 3
Training loss: 1.0558286905288696
Validation loss: 1.9307937763070548

Epoch: 5| Step: 4
Training loss: 1.1187909841537476
Validation loss: 1.90058385556744

Epoch: 5| Step: 5
Training loss: 0.9588929414749146
Validation loss: 1.890609937329446

Epoch: 5| Step: 6
Training loss: 0.9332319498062134
Validation loss: 1.8780432285801056

Epoch: 5| Step: 7
Training loss: 1.321706771850586
Validation loss: 1.8693960097528273

Epoch: 5| Step: 8
Training loss: 0.5592054128646851
Validation loss: 1.8869799849807576

Epoch: 5| Step: 9
Training loss: 1.4216500520706177
Validation loss: 1.8732677018770607

Epoch: 5| Step: 10
Training loss: 0.7539728283882141
Validation loss: 1.8951622606605611

Epoch: 203| Step: 0
Training loss: 1.006343960762024
Validation loss: 1.9167627583267868

Epoch: 5| Step: 1
Training loss: 1.383111834526062
Validation loss: 1.9411915476604173

Epoch: 5| Step: 2
Training loss: 1.016251564025879
Validation loss: 1.9533758060906523

Epoch: 5| Step: 3
Training loss: 0.6640183925628662
Validation loss: 1.9816397543876403

Epoch: 5| Step: 4
Training loss: 1.2361143827438354
Validation loss: 1.9803958016057168

Epoch: 5| Step: 5
Training loss: 1.2433252334594727
Validation loss: 1.9511023042022542

Epoch: 5| Step: 6
Training loss: 0.7649641036987305
Validation loss: 1.9561155188468196

Epoch: 5| Step: 7
Training loss: 1.329162359237671
Validation loss: 1.9556080397739206

Epoch: 5| Step: 8
Training loss: 1.0313150882720947
Validation loss: 1.95631504443384

Epoch: 5| Step: 9
Training loss: 0.5221976041793823
Validation loss: 1.9666518818947576

Epoch: 5| Step: 10
Training loss: 1.269430160522461
Validation loss: 1.9518398623312674

Epoch: 204| Step: 0
Training loss: 0.7162362337112427
Validation loss: 1.9760256980055122

Epoch: 5| Step: 1
Training loss: 1.096864938735962
Validation loss: 1.9506477937903455

Epoch: 5| Step: 2
Training loss: 1.0305767059326172
Validation loss: 1.9512623612598707

Epoch: 5| Step: 3
Training loss: 0.6306021809577942
Validation loss: 1.9612731420865623

Epoch: 5| Step: 4
Training loss: 0.9715533256530762
Validation loss: 1.9351555455115534

Epoch: 5| Step: 5
Training loss: 1.0626226663589478
Validation loss: 1.9257243974234468

Epoch: 5| Step: 6
Training loss: 0.9015275835990906
Validation loss: 1.8979689549374323

Epoch: 5| Step: 7
Training loss: 0.714911162853241
Validation loss: 1.910920549464482

Epoch: 5| Step: 8
Training loss: 1.0861536264419556
Validation loss: 1.9038331418909051

Epoch: 5| Step: 9
Training loss: 1.0473607778549194
Validation loss: 1.8775281085762927

Epoch: 5| Step: 10
Training loss: 1.6909703016281128
Validation loss: 1.8681132165334557

Epoch: 205| Step: 0
Training loss: 1.1595017910003662
Validation loss: 1.8854938566043813

Epoch: 5| Step: 1
Training loss: 1.0107073783874512
Validation loss: 1.8862829131464804

Epoch: 5| Step: 2
Training loss: 0.7905040979385376
Validation loss: 1.9275678447497788

Epoch: 5| Step: 3
Training loss: 0.738665759563446
Validation loss: 1.9465923822054298

Epoch: 5| Step: 4
Training loss: 1.387192964553833
Validation loss: 1.9449520751994143

Epoch: 5| Step: 5
Training loss: 1.0666494369506836
Validation loss: 1.9675708047805294

Epoch: 5| Step: 6
Training loss: 1.1171292066574097
Validation loss: 1.9447179750729633

Epoch: 5| Step: 7
Training loss: 1.0192527770996094
Validation loss: 1.9216744707476707

Epoch: 5| Step: 8
Training loss: 0.8313511610031128
Validation loss: 1.9237619958898073

Epoch: 5| Step: 9
Training loss: 1.1607258319854736
Validation loss: 1.9415670940952916

Epoch: 5| Step: 10
Training loss: 0.7980573177337646
Validation loss: 1.9151414043159896

Epoch: 206| Step: 0
Training loss: 0.7272188067436218
Validation loss: 1.9223622596392067

Epoch: 5| Step: 1
Training loss: 0.8188454508781433
Validation loss: 1.9246352359812746

Epoch: 5| Step: 2
Training loss: 1.1846296787261963
Validation loss: 1.9542566294311194

Epoch: 5| Step: 3
Training loss: 1.2456161975860596
Validation loss: 1.9356167976574232

Epoch: 5| Step: 4
Training loss: 1.005391240119934
Validation loss: 1.9278315908165389

Epoch: 5| Step: 5
Training loss: 1.3235350847244263
Validation loss: 1.9089352084744362

Epoch: 5| Step: 6
Training loss: 0.8844302892684937
Validation loss: 1.9056958216492847

Epoch: 5| Step: 7
Training loss: 0.7885602712631226
Validation loss: 1.9319304497011247

Epoch: 5| Step: 8
Training loss: 1.167293906211853
Validation loss: 1.920864184697469

Epoch: 5| Step: 9
Training loss: 0.7529712915420532
Validation loss: 1.9206894008062219

Epoch: 5| Step: 10
Training loss: 0.8145892024040222
Validation loss: 1.907292486518942

Epoch: 207| Step: 0
Training loss: 0.9381593465805054
Validation loss: 1.9505183683928622

Epoch: 5| Step: 1
Training loss: 0.8172445297241211
Validation loss: 1.922710067482405

Epoch: 5| Step: 2
Training loss: 1.3670837879180908
Validation loss: 1.9235155402973134

Epoch: 5| Step: 3
Training loss: 1.0899145603179932
Validation loss: 1.9024347771880448

Epoch: 5| Step: 4
Training loss: 1.2491854429244995
Validation loss: 1.9127506991868377

Epoch: 5| Step: 5
Training loss: 0.6557672023773193
Validation loss: 1.9172429974361131

Epoch: 5| Step: 6
Training loss: 0.7418530583381653
Validation loss: 1.9110828484258344

Epoch: 5| Step: 7
Training loss: 1.034891128540039
Validation loss: 1.9105772972106934

Epoch: 5| Step: 8
Training loss: 0.7109200358390808
Validation loss: 1.905737075113481

Epoch: 5| Step: 9
Training loss: 1.011523962020874
Validation loss: 1.908502508235234

Epoch: 5| Step: 10
Training loss: 1.0095679759979248
Validation loss: 1.911427092808549

Epoch: 208| Step: 0
Training loss: 0.7679259181022644
Validation loss: 1.910767944910193

Epoch: 5| Step: 1
Training loss: 0.8065029978752136
Validation loss: 1.8994467373817199

Epoch: 5| Step: 2
Training loss: 0.7328603267669678
Validation loss: 1.9125704150046072

Epoch: 5| Step: 3
Training loss: 0.7412127256393433
Validation loss: 1.9091629238538845

Epoch: 5| Step: 4
Training loss: 1.2721471786499023
Validation loss: 1.892054291181667

Epoch: 5| Step: 5
Training loss: 1.0432095527648926
Validation loss: 1.894870126119224

Epoch: 5| Step: 6
Training loss: 0.9668466448783875
Validation loss: 1.8942082812709193

Epoch: 5| Step: 7
Training loss: 1.1793104410171509
Validation loss: 1.9127067436454117

Epoch: 5| Step: 8
Training loss: 1.0863536596298218
Validation loss: 1.9202185061670118

Epoch: 5| Step: 9
Training loss: 0.813830554485321
Validation loss: 1.9221984442844187

Epoch: 5| Step: 10
Training loss: 1.0247552394866943
Validation loss: 1.9016027130106443

Epoch: 209| Step: 0
Training loss: 1.0352483987808228
Validation loss: 1.8952297472184705

Epoch: 5| Step: 1
Training loss: 0.804179310798645
Validation loss: 1.8815549547954271

Epoch: 5| Step: 2
Training loss: 0.9502288699150085
Validation loss: 1.874031553986252

Epoch: 5| Step: 3
Training loss: 0.6472945213317871
Validation loss: 1.8817575170147804

Epoch: 5| Step: 4
Training loss: 1.027454137802124
Validation loss: 1.8616579963314919

Epoch: 5| Step: 5
Training loss: 1.4689280986785889
Validation loss: 1.914434168928413

Epoch: 5| Step: 6
Training loss: 0.636603832244873
Validation loss: 1.915620626941804

Epoch: 5| Step: 7
Training loss: 0.9206477999687195
Validation loss: 1.9177640920044274

Epoch: 5| Step: 8
Training loss: 0.9539490938186646
Validation loss: 1.928028073362125

Epoch: 5| Step: 9
Training loss: 1.2164912223815918
Validation loss: 1.934744640063214

Epoch: 5| Step: 10
Training loss: 0.5931693911552429
Validation loss: 1.9050614577467724

Epoch: 210| Step: 0
Training loss: 0.9627929925918579
Validation loss: 1.9100186670980146

Epoch: 5| Step: 1
Training loss: 1.010318636894226
Validation loss: 1.8969797549709198

Epoch: 5| Step: 2
Training loss: 0.9613171815872192
Validation loss: 1.8937850024110527

Epoch: 5| Step: 3
Training loss: 0.7078291177749634
Validation loss: 1.8851749948275986

Epoch: 5| Step: 4
Training loss: 0.7389296293258667
Validation loss: 1.9006035725275676

Epoch: 5| Step: 5
Training loss: 1.1449356079101562
Validation loss: 1.8846050539324362

Epoch: 5| Step: 6
Training loss: 1.1613709926605225
Validation loss: 1.9113732063642113

Epoch: 5| Step: 7
Training loss: 1.0830882787704468
Validation loss: 1.9103048386112336

Epoch: 5| Step: 8
Training loss: 0.7627722024917603
Validation loss: 1.8952507485625565

Epoch: 5| Step: 9
Training loss: 0.7795841097831726
Validation loss: 1.9515179229039017

Epoch: 5| Step: 10
Training loss: 0.9414560794830322
Validation loss: 1.9767289828228694

Epoch: 211| Step: 0
Training loss: 0.9123699069023132
Validation loss: 1.9738522780838834

Epoch: 5| Step: 1
Training loss: 1.2098524570465088
Validation loss: 1.928329977937924

Epoch: 5| Step: 2
Training loss: 0.9225581288337708
Validation loss: 1.9369937899292156

Epoch: 5| Step: 3
Training loss: 0.9823297262191772
Validation loss: 1.912773513024853

Epoch: 5| Step: 4
Training loss: 1.1274058818817139
Validation loss: 1.9034138674377112

Epoch: 5| Step: 5
Training loss: 0.7749246954917908
Validation loss: 1.8798746460227556

Epoch: 5| Step: 6
Training loss: 1.0109672546386719
Validation loss: 1.8845916076373028

Epoch: 5| Step: 7
Training loss: 0.8846441507339478
Validation loss: 1.865437476865707

Epoch: 5| Step: 8
Training loss: 0.6857664585113525
Validation loss: 1.8911393380934192

Epoch: 5| Step: 9
Training loss: 0.7729769945144653
Validation loss: 1.8995375915240216

Epoch: 5| Step: 10
Training loss: 0.9137289524078369
Validation loss: 1.9049962509062983

Epoch: 212| Step: 0
Training loss: 1.3185056447982788
Validation loss: 1.9449776718693395

Epoch: 5| Step: 1
Training loss: 0.6940619945526123
Validation loss: 1.9590159513617074

Epoch: 5| Step: 2
Training loss: 0.5361387133598328
Validation loss: 1.963888019643804

Epoch: 5| Step: 3
Training loss: 0.914566695690155
Validation loss: 1.9472810658075477

Epoch: 5| Step: 4
Training loss: 0.9366607666015625
Validation loss: 1.955566575450282

Epoch: 5| Step: 5
Training loss: 1.248505711555481
Validation loss: 1.9350300809388519

Epoch: 5| Step: 6
Training loss: 1.0432045459747314
Validation loss: 1.903147194975166

Epoch: 5| Step: 7
Training loss: 0.912609875202179
Validation loss: 1.9163733451597151

Epoch: 5| Step: 8
Training loss: 0.8715972900390625
Validation loss: 1.8978078506326164

Epoch: 5| Step: 9
Training loss: 0.9110797047615051
Validation loss: 1.926919719224335

Epoch: 5| Step: 10
Training loss: 1.050145149230957
Validation loss: 1.9735560878630607

Epoch: 213| Step: 0
Training loss: 1.0059150457382202
Validation loss: 2.0039827503183836

Epoch: 5| Step: 1
Training loss: 1.1954625844955444
Validation loss: 1.986501827034899

Epoch: 5| Step: 2
Training loss: 1.0508842468261719
Validation loss: 1.9486597661049134

Epoch: 5| Step: 3
Training loss: 0.828631579875946
Validation loss: 1.9419061701784852

Epoch: 5| Step: 4
Training loss: 0.8395174145698547
Validation loss: 1.931711830118651

Epoch: 5| Step: 5
Training loss: 0.9444977641105652
Validation loss: 1.9263356347237863

Epoch: 5| Step: 6
Training loss: 0.6752906441688538
Validation loss: 1.9164633545824277

Epoch: 5| Step: 7
Training loss: 0.9356353878974915
Validation loss: 1.9284404195765013

Epoch: 5| Step: 8
Training loss: 1.324877381324768
Validation loss: 1.9306787124244116

Epoch: 5| Step: 9
Training loss: 0.8312905430793762
Validation loss: 1.9385107383933118

Epoch: 5| Step: 10
Training loss: 1.31985604763031
Validation loss: 1.96907010129703

Epoch: 214| Step: 0
Training loss: 0.9619096517562866
Validation loss: 1.9809262342350458

Epoch: 5| Step: 1
Training loss: 0.9121417999267578
Validation loss: 1.9716927466853973

Epoch: 5| Step: 2
Training loss: 0.8144318461418152
Validation loss: 1.9524231854305472

Epoch: 5| Step: 3
Training loss: 0.9294372797012329
Validation loss: 1.9148398958226687

Epoch: 5| Step: 4
Training loss: 0.8579568862915039
Validation loss: 1.908946862784765

Epoch: 5| Step: 5
Training loss: 0.7616597414016724
Validation loss: 1.9062949495930825

Epoch: 5| Step: 6
Training loss: 0.9227373003959656
Validation loss: 1.9049234544077227

Epoch: 5| Step: 7
Training loss: 0.9958588480949402
Validation loss: 1.9035419379511187

Epoch: 5| Step: 8
Training loss: 1.0983459949493408
Validation loss: 1.914215765973573

Epoch: 5| Step: 9
Training loss: 1.1214964389801025
Validation loss: 1.9049645034215783

Epoch: 5| Step: 10
Training loss: 0.8740513920783997
Validation loss: 1.9146757946219495

Epoch: 215| Step: 0
Training loss: 0.8382536172866821
Validation loss: 1.8896595585730769

Epoch: 5| Step: 1
Training loss: 1.0504252910614014
Validation loss: 1.8899315864809099

Epoch: 5| Step: 2
Training loss: 1.0212005376815796
Validation loss: 1.8980190856482393

Epoch: 5| Step: 3
Training loss: 0.8516479730606079
Validation loss: 1.8918035248274445

Epoch: 5| Step: 4
Training loss: 0.8086203336715698
Validation loss: 1.9092080336745068

Epoch: 5| Step: 5
Training loss: 0.825849711894989
Validation loss: 1.8970677621902958

Epoch: 5| Step: 6
Training loss: 0.9208167791366577
Validation loss: 1.8890256625349804

Epoch: 5| Step: 7
Training loss: 1.0957139730453491
Validation loss: 1.8981842610143846

Epoch: 5| Step: 8
Training loss: 0.8137609362602234
Validation loss: 1.8960037359627344

Epoch: 5| Step: 9
Training loss: 0.8350178003311157
Validation loss: 1.892010990009513

Epoch: 5| Step: 10
Training loss: 0.9699498414993286
Validation loss: 1.8983227898997646

Epoch: 216| Step: 0
Training loss: 0.9741507768630981
Validation loss: 1.9249365983470794

Epoch: 5| Step: 1
Training loss: 0.6914139986038208
Validation loss: 1.9318653024652952

Epoch: 5| Step: 2
Training loss: 0.8858660459518433
Validation loss: 1.947475129558194

Epoch: 5| Step: 3
Training loss: 1.0401867628097534
Validation loss: 1.9149216105861049

Epoch: 5| Step: 4
Training loss: 0.4328088164329529
Validation loss: 1.899767191179337

Epoch: 5| Step: 5
Training loss: 0.728026270866394
Validation loss: 1.8935871893359768

Epoch: 5| Step: 6
Training loss: 0.9141983985900879
Validation loss: 1.8966069259951193

Epoch: 5| Step: 7
Training loss: 1.0373332500457764
Validation loss: 1.8628330320440314

Epoch: 5| Step: 8
Training loss: 0.7576667666435242
Validation loss: 1.8739942350695211

Epoch: 5| Step: 9
Training loss: 0.8507679104804993
Validation loss: 1.8708512988141788

Epoch: 5| Step: 10
Training loss: 1.674294352531433
Validation loss: 1.8789224765634025

Epoch: 217| Step: 0
Training loss: 1.3305917978286743
Validation loss: 1.912691807234159

Epoch: 5| Step: 1
Training loss: 0.8253154754638672
Validation loss: 1.9349090860735985

Epoch: 5| Step: 2
Training loss: 0.7973845601081848
Validation loss: 1.9725776359599123

Epoch: 5| Step: 3
Training loss: 0.7559732794761658
Validation loss: 1.981128333717264

Epoch: 5| Step: 4
Training loss: 0.863792896270752
Validation loss: 1.9601554780878045

Epoch: 5| Step: 5
Training loss: 0.4557962417602539
Validation loss: 1.946707522997292

Epoch: 5| Step: 6
Training loss: 1.194109320640564
Validation loss: 1.9049711817054338

Epoch: 5| Step: 7
Training loss: 0.923690140247345
Validation loss: 1.8868476524147937

Epoch: 5| Step: 8
Training loss: 0.5952184796333313
Validation loss: 1.8797788299540037

Epoch: 5| Step: 9
Training loss: 1.0475070476531982
Validation loss: 1.8835943604028353

Epoch: 5| Step: 10
Training loss: 1.3780895471572876
Validation loss: 1.8783865705613167

Epoch: 218| Step: 0
Training loss: 0.6991873979568481
Validation loss: 1.8735886427663988

Epoch: 5| Step: 1
Training loss: 1.0440094470977783
Validation loss: 1.8802166792654222

Epoch: 5| Step: 2
Training loss: 0.9248396754264832
Validation loss: 1.8983218426345496

Epoch: 5| Step: 3
Training loss: 1.1966643333435059
Validation loss: 1.8797884487336682

Epoch: 5| Step: 4
Training loss: 0.7381746768951416
Validation loss: 1.9292497993797384

Epoch: 5| Step: 5
Training loss: 0.6673868894577026
Validation loss: 1.9321223702481998

Epoch: 5| Step: 6
Training loss: 0.6717243194580078
Validation loss: 1.9484041634426321

Epoch: 5| Step: 7
Training loss: 0.6031413078308105
Validation loss: 1.912350905838833

Epoch: 5| Step: 8
Training loss: 1.1318540573120117
Validation loss: 1.910247387424592

Epoch: 5| Step: 9
Training loss: 0.7174409031867981
Validation loss: 1.885803872539151

Epoch: 5| Step: 10
Training loss: 1.6214609146118164
Validation loss: 1.8831532142495597

Epoch: 219| Step: 0
Training loss: 1.1187851428985596
Validation loss: 1.8781441321936987

Epoch: 5| Step: 1
Training loss: 1.150675892829895
Validation loss: 1.8599952343971498

Epoch: 5| Step: 2
Training loss: 0.7921223640441895
Validation loss: 1.866628400741085

Epoch: 5| Step: 3
Training loss: 0.9341835975646973
Validation loss: 1.88908028218054

Epoch: 5| Step: 4
Training loss: 0.7642122507095337
Validation loss: 1.9333287003219768

Epoch: 5| Step: 5
Training loss: 0.9602724313735962
Validation loss: 1.9463043417981876

Epoch: 5| Step: 6
Training loss: 0.6905737519264221
Validation loss: 1.9497177600860596

Epoch: 5| Step: 7
Training loss: 0.6761471629142761
Validation loss: 1.9167890817888322

Epoch: 5| Step: 8
Training loss: 1.3028770685195923
Validation loss: 1.899494630034252

Epoch: 5| Step: 9
Training loss: 0.5480451583862305
Validation loss: 1.8969570795694988

Epoch: 5| Step: 10
Training loss: 0.6298520565032959
Validation loss: 1.8674911632332751

Epoch: 220| Step: 0
Training loss: 1.0094997882843018
Validation loss: 1.8656012499204246

Epoch: 5| Step: 1
Training loss: 0.9241039156913757
Validation loss: 1.864253992675453

Epoch: 5| Step: 2
Training loss: 0.9495042562484741
Validation loss: 1.8713612377002675

Epoch: 5| Step: 3
Training loss: 0.8337448239326477
Validation loss: 1.8855732102547922

Epoch: 5| Step: 4
Training loss: 0.779535174369812
Validation loss: 1.893658031699478

Epoch: 5| Step: 5
Training loss: 0.986679196357727
Validation loss: 1.9248053104646745

Epoch: 5| Step: 6
Training loss: 0.8021697998046875
Validation loss: 1.9406337635491484

Epoch: 5| Step: 7
Training loss: 1.0910835266113281
Validation loss: 1.9257407547325216

Epoch: 5| Step: 8
Training loss: 0.8755720853805542
Validation loss: 1.9353891970008932

Epoch: 5| Step: 9
Training loss: 0.8284689784049988
Validation loss: 1.9182287569968932

Epoch: 5| Step: 10
Training loss: 0.36249881982803345
Validation loss: 1.925330272284887

Epoch: 221| Step: 0
Training loss: 0.7104844450950623
Validation loss: 1.9137425461123068

Epoch: 5| Step: 1
Training loss: 1.0631916522979736
Validation loss: 1.95197259354335

Epoch: 5| Step: 2
Training loss: 0.7513645887374878
Validation loss: 1.9478734923947243

Epoch: 5| Step: 3
Training loss: 0.6888242959976196
Validation loss: 1.9594752352724794

Epoch: 5| Step: 4
Training loss: 0.761903703212738
Validation loss: 1.9371776170628046

Epoch: 5| Step: 5
Training loss: 0.8439752459526062
Validation loss: 1.9109024104251657

Epoch: 5| Step: 6
Training loss: 0.8927608728408813
Validation loss: 1.9228515471181562

Epoch: 5| Step: 7
Training loss: 0.8894699215888977
Validation loss: 1.880938535095543

Epoch: 5| Step: 8
Training loss: 0.7154273986816406
Validation loss: 1.8877189338848155

Epoch: 5| Step: 9
Training loss: 1.2481372356414795
Validation loss: 1.8975757924459313

Epoch: 5| Step: 10
Training loss: 0.7163440585136414
Validation loss: 1.904385248819987

Epoch: 222| Step: 0
Training loss: 0.8662967681884766
Validation loss: 1.9399722776105326

Epoch: 5| Step: 1
Training loss: 0.6277907490730286
Validation loss: 1.9474870530507897

Epoch: 5| Step: 2
Training loss: 0.7981373071670532
Validation loss: 1.9429732573929654

Epoch: 5| Step: 3
Training loss: 1.087017297744751
Validation loss: 1.9535426119322419

Epoch: 5| Step: 4
Training loss: 1.0238678455352783
Validation loss: 1.9301272182054416

Epoch: 5| Step: 5
Training loss: 0.7567200660705566
Validation loss: 1.9270144367730746

Epoch: 5| Step: 6
Training loss: 0.7997546195983887
Validation loss: 1.9055721195795203

Epoch: 5| Step: 7
Training loss: 1.3394427299499512
Validation loss: 1.8855435207325926

Epoch: 5| Step: 8
Training loss: 0.5769199132919312
Validation loss: 1.8863219471387966

Epoch: 5| Step: 9
Training loss: 0.8303106427192688
Validation loss: 1.8978028528151973

Epoch: 5| Step: 10
Training loss: 0.7364517450332642
Validation loss: 1.8830864506383096

Epoch: 223| Step: 0
Training loss: 0.6026420593261719
Validation loss: 1.8807193258757233

Epoch: 5| Step: 1
Training loss: 1.233902931213379
Validation loss: 1.9113905019657587

Epoch: 5| Step: 2
Training loss: 0.8046060800552368
Validation loss: 1.9033454079781809

Epoch: 5| Step: 3
Training loss: 0.9142023324966431
Validation loss: 1.88762947692666

Epoch: 5| Step: 4
Training loss: 0.8159500360488892
Validation loss: 1.8950187288304812

Epoch: 5| Step: 5
Training loss: 0.9589792490005493
Validation loss: 1.8858847778330567

Epoch: 5| Step: 6
Training loss: 0.6146734952926636
Validation loss: 1.904420461705936

Epoch: 5| Step: 7
Training loss: 1.1025139093399048
Validation loss: 1.8838702453080045

Epoch: 5| Step: 8
Training loss: 0.6454612016677856
Validation loss: 1.896556015937559

Epoch: 5| Step: 9
Training loss: 0.6771430969238281
Validation loss: 1.9123473872420609

Epoch: 5| Step: 10
Training loss: 0.7387371063232422
Validation loss: 1.924409858642086

Epoch: 224| Step: 0
Training loss: 1.0225744247436523
Validation loss: 1.8910313831862582

Epoch: 5| Step: 1
Training loss: 0.8406411409378052
Validation loss: 1.903663137907623

Epoch: 5| Step: 2
Training loss: 0.7793427109718323
Validation loss: 1.911386384758898

Epoch: 5| Step: 3
Training loss: 1.1011136770248413
Validation loss: 1.908956330309632

Epoch: 5| Step: 4
Training loss: 0.7137593030929565
Validation loss: 1.896233626591262

Epoch: 5| Step: 5
Training loss: 0.6688448190689087
Validation loss: 1.883400151806493

Epoch: 5| Step: 6
Training loss: 0.6369186639785767
Validation loss: 1.8962793555310977

Epoch: 5| Step: 7
Training loss: 1.100785255432129
Validation loss: 1.8786821621720509

Epoch: 5| Step: 8
Training loss: 0.8032761812210083
Validation loss: 1.8548829529875068

Epoch: 5| Step: 9
Training loss: 0.698175311088562
Validation loss: 1.8542664127965127

Epoch: 5| Step: 10
Training loss: 0.5347502827644348
Validation loss: 1.8667915815948157

Epoch: 225| Step: 0
Training loss: 0.6283056139945984
Validation loss: 1.8964787016632736

Epoch: 5| Step: 1
Training loss: 0.6369922161102295
Validation loss: 1.91240571647562

Epoch: 5| Step: 2
Training loss: 1.0692169666290283
Validation loss: 1.9203026499799503

Epoch: 5| Step: 3
Training loss: 0.9284403920173645
Validation loss: 1.9239020065594745

Epoch: 5| Step: 4
Training loss: 0.6943427920341492
Validation loss: 1.917927388221987

Epoch: 5| Step: 5
Training loss: 0.7268646955490112
Validation loss: 1.939402267497073

Epoch: 5| Step: 6
Training loss: 0.85541832447052
Validation loss: 1.9087694716709915

Epoch: 5| Step: 7
Training loss: 0.7108230590820312
Validation loss: 1.8735381890368719

Epoch: 5| Step: 8
Training loss: 0.839826226234436
Validation loss: 1.8746418799123457

Epoch: 5| Step: 9
Training loss: 1.0964912176132202
Validation loss: 1.8666267702656407

Epoch: 5| Step: 10
Training loss: 0.9628269076347351
Validation loss: 1.8832949874221638

Epoch: 226| Step: 0
Training loss: 1.3253283500671387
Validation loss: 1.9005012255842968

Epoch: 5| Step: 1
Training loss: 0.810699462890625
Validation loss: 1.9313513425088698

Epoch: 5| Step: 2
Training loss: 1.11008620262146
Validation loss: 1.9627100754809637

Epoch: 5| Step: 3
Training loss: 0.5749838948249817
Validation loss: 1.9563099466344362

Epoch: 5| Step: 4
Training loss: 0.5846637487411499
Validation loss: 1.9336761351554625

Epoch: 5| Step: 5
Training loss: 0.4668373167514801
Validation loss: 1.91326944674215

Epoch: 5| Step: 6
Training loss: 0.9680644273757935
Validation loss: 1.9013046397957751

Epoch: 5| Step: 7
Training loss: 1.063982367515564
Validation loss: 1.8974043092420023

Epoch: 5| Step: 8
Training loss: 0.8366664052009583
Validation loss: 1.8961892051081504

Epoch: 5| Step: 9
Training loss: 1.1369235515594482
Validation loss: 1.9022205683492845

Epoch: 5| Step: 10
Training loss: 0.6649142503738403
Validation loss: 1.9017481009165447

Epoch: 227| Step: 0
Training loss: 0.7214668989181519
Validation loss: 1.9218262651915192

Epoch: 5| Step: 1
Training loss: 1.2668393850326538
Validation loss: 1.9076776812153478

Epoch: 5| Step: 2
Training loss: 0.782781720161438
Validation loss: 1.9048073061050907

Epoch: 5| Step: 3
Training loss: 1.1069395542144775
Validation loss: 1.9026276757640224

Epoch: 5| Step: 4
Training loss: 0.688884437084198
Validation loss: 1.8951564604236233

Epoch: 5| Step: 5
Training loss: 0.9504855871200562
Validation loss: 1.8647438685099285

Epoch: 5| Step: 6
Training loss: 0.509114146232605
Validation loss: 1.8909114663318922

Epoch: 5| Step: 7
Training loss: 0.812954306602478
Validation loss: 1.9022699838043542

Epoch: 5| Step: 8
Training loss: 0.6230986714363098
Validation loss: 1.9003877178315194

Epoch: 5| Step: 9
Training loss: 0.7398398518562317
Validation loss: 1.9296064710104337

Epoch: 5| Step: 10
Training loss: 0.908037543296814
Validation loss: 1.928260257167201

Epoch: 228| Step: 0
Training loss: 1.0024983882904053
Validation loss: 1.95144013948338

Epoch: 5| Step: 1
Training loss: 1.0775158405303955
Validation loss: 1.9496116048546248

Epoch: 5| Step: 2
Training loss: 0.6756789684295654
Validation loss: 1.9405031870770197

Epoch: 5| Step: 3
Training loss: 0.5345737338066101
Validation loss: 1.9436283931937268

Epoch: 5| Step: 4
Training loss: 0.6339663863182068
Validation loss: 1.925173290314213

Epoch: 5| Step: 5
Training loss: 0.7524367570877075
Validation loss: 1.8882103889219222

Epoch: 5| Step: 6
Training loss: 0.4933754503726959
Validation loss: 1.9034736335918467

Epoch: 5| Step: 7
Training loss: 0.7505252957344055
Validation loss: 1.9044395057103967

Epoch: 5| Step: 8
Training loss: 0.6776713132858276
Validation loss: 1.8707318485424083

Epoch: 5| Step: 9
Training loss: 1.0744123458862305
Validation loss: 1.9111803731610697

Epoch: 5| Step: 10
Training loss: 1.182576298713684
Validation loss: 1.8975683540426276

Epoch: 229| Step: 0
Training loss: 1.0226136445999146
Validation loss: 1.9036401946057555

Epoch: 5| Step: 1
Training loss: 0.45824021100997925
Validation loss: 1.8985265967666463

Epoch: 5| Step: 2
Training loss: 0.6937287449836731
Validation loss: 1.9094047930932814

Epoch: 5| Step: 3
Training loss: 0.8147926330566406
Validation loss: 1.926902853032594

Epoch: 5| Step: 4
Training loss: 0.7973003387451172
Validation loss: 1.9395531185211674

Epoch: 5| Step: 5
Training loss: 1.1675137281417847
Validation loss: 1.9867558299854238

Epoch: 5| Step: 6
Training loss: 0.9941832423210144
Validation loss: 1.9864264970184655

Epoch: 5| Step: 7
Training loss: 0.7936832308769226
Validation loss: 2.00628468554507

Epoch: 5| Step: 8
Training loss: 0.6479136347770691
Validation loss: 1.9754162347444923

Epoch: 5| Step: 9
Training loss: 1.0674450397491455
Validation loss: 1.9361043463471115

Epoch: 5| Step: 10
Training loss: 0.6810669302940369
Validation loss: 1.8923715545285134

Epoch: 230| Step: 0
Training loss: 0.6518024206161499
Validation loss: 1.8817530062890822

Epoch: 5| Step: 1
Training loss: 1.1806786060333252
Validation loss: 1.871390602921927

Epoch: 5| Step: 2
Training loss: 0.9208564758300781
Validation loss: 1.8706077080900951

Epoch: 5| Step: 3
Training loss: 0.7937410473823547
Validation loss: 1.8816839879558933

Epoch: 5| Step: 4
Training loss: 0.8478606343269348
Validation loss: 1.879857999022289

Epoch: 5| Step: 5
Training loss: 1.1100807189941406
Validation loss: 1.9067662672329975

Epoch: 5| Step: 6
Training loss: 0.5079162120819092
Validation loss: 1.9275642043800765

Epoch: 5| Step: 7
Training loss: 0.7791743278503418
Validation loss: 1.934147483559065

Epoch: 5| Step: 8
Training loss: 0.7914799451828003
Validation loss: 1.9249194719458138

Epoch: 5| Step: 9
Training loss: 0.4669402241706848
Validation loss: 1.898651228156141

Epoch: 5| Step: 10
Training loss: 0.7021470069885254
Validation loss: 1.8803690069465226

Epoch: 231| Step: 0
Training loss: 0.7815972566604614
Validation loss: 1.875612312747586

Epoch: 5| Step: 1
Training loss: 0.6127002239227295
Validation loss: 1.887078054489628

Epoch: 5| Step: 2
Training loss: 0.8572795987129211
Validation loss: 1.8719046167148057

Epoch: 5| Step: 3
Training loss: 1.0547010898590088
Validation loss: 1.886114699866182

Epoch: 5| Step: 4
Training loss: 1.182387113571167
Validation loss: 1.9085441481682561

Epoch: 5| Step: 5
Training loss: 0.6134870648384094
Validation loss: 1.894772416801863

Epoch: 5| Step: 6
Training loss: 0.7019091844558716
Validation loss: 1.9310786595908545

Epoch: 5| Step: 7
Training loss: 0.6910427212715149
Validation loss: 1.9497460652423162

Epoch: 5| Step: 8
Training loss: 0.6178767085075378
Validation loss: 1.9225570681274577

Epoch: 5| Step: 9
Training loss: 0.6170438528060913
Validation loss: 1.94327586953358

Epoch: 5| Step: 10
Training loss: 0.6566600799560547
Validation loss: 1.9174812365603704

Epoch: 232| Step: 0
Training loss: 0.7032505869865417
Validation loss: 1.907747204585742

Epoch: 5| Step: 1
Training loss: 0.8522569537162781
Validation loss: 1.8965125032650527

Epoch: 5| Step: 2
Training loss: 0.7962006330490112
Validation loss: 1.906718316898551

Epoch: 5| Step: 3
Training loss: 0.8005260229110718
Validation loss: 1.8954234328321231

Epoch: 5| Step: 4
Training loss: 0.5654538869857788
Validation loss: 1.8871538408340947

Epoch: 5| Step: 5
Training loss: 0.66473388671875
Validation loss: 1.8920426317440566

Epoch: 5| Step: 6
Training loss: 0.9759331941604614
Validation loss: 1.9005832531118905

Epoch: 5| Step: 7
Training loss: 0.7500180006027222
Validation loss: 1.86655092752108

Epoch: 5| Step: 8
Training loss: 0.6850460171699524
Validation loss: 1.896605351919769

Epoch: 5| Step: 9
Training loss: 0.7138824462890625
Validation loss: 1.8770566909543929

Epoch: 5| Step: 10
Training loss: 0.6680467128753662
Validation loss: 1.8860726792325255

Epoch: 233| Step: 0
Training loss: 0.5827800035476685
Validation loss: 1.909510624024176

Epoch: 5| Step: 1
Training loss: 0.9235028028488159
Validation loss: 1.9231627705276653

Epoch: 5| Step: 2
Training loss: 0.7940812110900879
Validation loss: 1.9017941259568738

Epoch: 5| Step: 3
Training loss: 0.43778809905052185
Validation loss: 1.9135954392853605

Epoch: 5| Step: 4
Training loss: 0.835922360420227
Validation loss: 1.9064693822655627

Epoch: 5| Step: 5
Training loss: 0.792512059211731
Validation loss: 1.8933493732124247

Epoch: 5| Step: 6
Training loss: 0.3727540373802185
Validation loss: 1.9206831378321494

Epoch: 5| Step: 7
Training loss: 0.915644645690918
Validation loss: 1.9095768133799236

Epoch: 5| Step: 8
Training loss: 1.0915638208389282
Validation loss: 1.88350171683937

Epoch: 5| Step: 9
Training loss: 0.7134289741516113
Validation loss: 1.9000616586336525

Epoch: 5| Step: 10
Training loss: 0.5449373126029968
Validation loss: 1.8828190295926985

Epoch: 234| Step: 0
Training loss: 0.9180750846862793
Validation loss: 1.886354083655983

Epoch: 5| Step: 1
Training loss: 0.9679939150810242
Validation loss: 1.9152010717699606

Epoch: 5| Step: 2
Training loss: 0.7777529954910278
Validation loss: 1.937232425135951

Epoch: 5| Step: 3
Training loss: 0.6775308847427368
Validation loss: 1.9440928800131685

Epoch: 5| Step: 4
Training loss: 0.9513670206069946
Validation loss: 1.925705094491282

Epoch: 5| Step: 5
Training loss: 0.5024983286857605
Validation loss: 1.9355529687737907

Epoch: 5| Step: 6
Training loss: 0.53199702501297
Validation loss: 1.9031621538182741

Epoch: 5| Step: 7
Training loss: 0.6956483125686646
Validation loss: 1.9027763361571937

Epoch: 5| Step: 8
Training loss: 0.7530184984207153
Validation loss: 1.8892276645988546

Epoch: 5| Step: 9
Training loss: 0.6390973329544067
Validation loss: 1.8887129368320588

Epoch: 5| Step: 10
Training loss: 0.8423941135406494
Validation loss: 1.8870453885806504

Epoch: 235| Step: 0
Training loss: 0.5389760732650757
Validation loss: 1.8915829273962206

Epoch: 5| Step: 1
Training loss: 0.7812035083770752
Validation loss: 1.9155459198900449

Epoch: 5| Step: 2
Training loss: 0.7254256010055542
Validation loss: 1.8996796531061972

Epoch: 5| Step: 3
Training loss: 0.6907749176025391
Validation loss: 1.933332904692619

Epoch: 5| Step: 4
Training loss: 0.9944771528244019
Validation loss: 1.8981509080497168

Epoch: 5| Step: 5
Training loss: 0.28982654213905334
Validation loss: 1.913600775503343

Epoch: 5| Step: 6
Training loss: 0.40967997908592224
Validation loss: 1.9066835987952448

Epoch: 5| Step: 7
Training loss: 1.0167040824890137
Validation loss: 1.8944896113487981

Epoch: 5| Step: 8
Training loss: 0.6320887804031372
Validation loss: 1.868213580500695

Epoch: 5| Step: 9
Training loss: 0.892055332660675
Validation loss: 1.8711653319738244

Epoch: 5| Step: 10
Training loss: 1.3331294059753418
Validation loss: 1.8727462714718235

Epoch: 236| Step: 0
Training loss: 0.8781884908676147
Validation loss: 1.8853219709088724

Epoch: 5| Step: 1
Training loss: 0.9688905477523804
Validation loss: 1.881052952940746

Epoch: 5| Step: 2
Training loss: 0.44733086228370667
Validation loss: 1.886992226364792

Epoch: 5| Step: 3
Training loss: 0.5689505338668823
Validation loss: 1.894262534315868

Epoch: 5| Step: 4
Training loss: 0.916782557964325
Validation loss: 1.9381527029057986

Epoch: 5| Step: 5
Training loss: 0.9413727521896362
Validation loss: 1.9453979102514123

Epoch: 5| Step: 6
Training loss: 0.643520176410675
Validation loss: 1.9272844227411414

Epoch: 5| Step: 7
Training loss: 0.6677216291427612
Validation loss: 1.9031342690990818

Epoch: 5| Step: 8
Training loss: 0.7921420931816101
Validation loss: 1.8943240027273855

Epoch: 5| Step: 9
Training loss: 0.7121720910072327
Validation loss: 1.9007513561556417

Epoch: 5| Step: 10
Training loss: 0.6071257591247559
Validation loss: 1.8781075554509317

Epoch: 237| Step: 0
Training loss: 0.33636119961738586
Validation loss: 1.8702750487994122

Epoch: 5| Step: 1
Training loss: 0.9057197570800781
Validation loss: 1.9000120803874025

Epoch: 5| Step: 2
Training loss: 0.6289350390434265
Validation loss: 1.879672126103473

Epoch: 5| Step: 3
Training loss: 0.47122296690940857
Validation loss: 1.880548502809258

Epoch: 5| Step: 4
Training loss: 0.9464371800422668
Validation loss: 1.9204352568554621

Epoch: 5| Step: 5
Training loss: 0.9643300771713257
Validation loss: 1.9338965518500215

Epoch: 5| Step: 6
Training loss: 0.7173305749893188
Validation loss: 1.9564224122672953

Epoch: 5| Step: 7
Training loss: 1.004173755645752
Validation loss: 1.9234460169269192

Epoch: 5| Step: 8
Training loss: 0.7682641744613647
Validation loss: 1.9092625418016989

Epoch: 5| Step: 9
Training loss: 0.8181865811347961
Validation loss: 1.9168760520155712

Epoch: 5| Step: 10
Training loss: 0.5937052965164185
Validation loss: 1.909083907322217

Epoch: 238| Step: 0
Training loss: 0.9397382736206055
Validation loss: 1.8844694142700524

Epoch: 5| Step: 1
Training loss: 0.8218637704849243
Validation loss: 1.8987986990200576

Epoch: 5| Step: 2
Training loss: 0.7945951223373413
Validation loss: 1.9014776534931634

Epoch: 5| Step: 3
Training loss: 0.6127315759658813
Validation loss: 1.906027022228446

Epoch: 5| Step: 4
Training loss: 0.45264214277267456
Validation loss: 1.9236193613339496

Epoch: 5| Step: 5
Training loss: 0.6140427589416504
Validation loss: 1.936517894908946

Epoch: 5| Step: 6
Training loss: 0.8611999750137329
Validation loss: 1.9377118272166098

Epoch: 5| Step: 7
Training loss: 0.8162229657173157
Validation loss: 1.9284637358880812

Epoch: 5| Step: 8
Training loss: 0.9989643096923828
Validation loss: 1.921251570024798

Epoch: 5| Step: 9
Training loss: 0.6545761823654175
Validation loss: 1.8945827381585234

Epoch: 5| Step: 10
Training loss: 0.4094211459159851
Validation loss: 1.9184665923477502

Epoch: 239| Step: 0
Training loss: 0.6476749181747437
Validation loss: 1.9119985321516633

Epoch: 5| Step: 1
Training loss: 0.5824248194694519
Validation loss: 1.917703777231196

Epoch: 5| Step: 2
Training loss: 1.0022153854370117
Validation loss: 1.9324240889600528

Epoch: 5| Step: 3
Training loss: 0.8166409730911255
Validation loss: 1.9475363531420309

Epoch: 5| Step: 4
Training loss: 0.7800062298774719
Validation loss: 1.9447300485385361

Epoch: 5| Step: 5
Training loss: 0.6976801156997681
Validation loss: 1.9662199148567774

Epoch: 5| Step: 6
Training loss: 0.49093684554100037
Validation loss: 1.9474486920141405

Epoch: 5| Step: 7
Training loss: 0.6710924506187439
Validation loss: 1.9530256204707648

Epoch: 5| Step: 8
Training loss: 0.5948494076728821
Validation loss: 1.946678541039908

Epoch: 5| Step: 9
Training loss: 0.6484237313270569
Validation loss: 1.9329442388267928

Epoch: 5| Step: 10
Training loss: 0.8835670948028564
Validation loss: 1.9278268826905118

Epoch: 240| Step: 0
Training loss: 0.47088247537612915
Validation loss: 1.91055646763053

Epoch: 5| Step: 1
Training loss: 0.7003147006034851
Validation loss: 1.8997627599264986

Epoch: 5| Step: 2
Training loss: 0.773829996585846
Validation loss: 1.876010214128802

Epoch: 5| Step: 3
Training loss: 0.6357000470161438
Validation loss: 1.8725486814334829

Epoch: 5| Step: 4
Training loss: 0.5980263948440552
Validation loss: 1.8973614592706003

Epoch: 5| Step: 5
Training loss: 0.6516031622886658
Validation loss: 1.8964164436504405

Epoch: 5| Step: 6
Training loss: 0.8288372159004211
Validation loss: 1.8865341012195875

Epoch: 5| Step: 7
Training loss: 1.0496464967727661
Validation loss: 1.8736060152771652

Epoch: 5| Step: 8
Training loss: 0.3717442452907562
Validation loss: 1.88412566338816

Epoch: 5| Step: 9
Training loss: 0.9208011627197266
Validation loss: 1.8848776355866463

Epoch: 5| Step: 10
Training loss: 0.6053962111473083
Validation loss: 1.8811358508243357

Epoch: 241| Step: 0
Training loss: 0.4350352883338928
Validation loss: 1.8952604070786507

Epoch: 5| Step: 1
Training loss: 0.5502996444702148
Validation loss: 1.8840557631625925

Epoch: 5| Step: 2
Training loss: 0.6160248517990112
Validation loss: 1.9155037492834113

Epoch: 5| Step: 3
Training loss: 0.8812740445137024
Validation loss: 1.9209422821639686

Epoch: 5| Step: 4
Training loss: 0.44414591789245605
Validation loss: 1.9146974420034757

Epoch: 5| Step: 5
Training loss: 0.4958101212978363
Validation loss: 1.9234711124051003

Epoch: 5| Step: 6
Training loss: 0.7969290018081665
Validation loss: 1.8976471603557628

Epoch: 5| Step: 7
Training loss: 1.1630330085754395
Validation loss: 1.893925259190221

Epoch: 5| Step: 8
Training loss: 0.6498931646347046
Validation loss: 1.8764216092325026

Epoch: 5| Step: 9
Training loss: 0.6248909831047058
Validation loss: 1.9043287025984896

Epoch: 5| Step: 10
Training loss: 0.9577775597572327
Validation loss: 1.8932995309111893

Epoch: 242| Step: 0
Training loss: 0.5462681651115417
Validation loss: 1.9196071317118983

Epoch: 5| Step: 1
Training loss: 0.6512492299079895
Validation loss: 1.8981848429608088

Epoch: 5| Step: 2
Training loss: 0.4619300961494446
Validation loss: 1.914430610595211

Epoch: 5| Step: 3
Training loss: 0.7146070599555969
Validation loss: 1.893894204529383

Epoch: 5| Step: 4
Training loss: 0.7090698480606079
Validation loss: 1.8950187006304342

Epoch: 5| Step: 5
Training loss: 0.9701984524726868
Validation loss: 1.8983637927680888

Epoch: 5| Step: 6
Training loss: 0.7966674566268921
Validation loss: 1.879199299761044

Epoch: 5| Step: 7
Training loss: 0.76988285779953
Validation loss: 1.8825067576541696

Epoch: 5| Step: 8
Training loss: 0.316009521484375
Validation loss: 1.8876863295032131

Epoch: 5| Step: 9
Training loss: 0.8446186780929565
Validation loss: 1.9007347155642766

Epoch: 5| Step: 10
Training loss: 0.673367440700531
Validation loss: 1.919018364721729

Epoch: 243| Step: 0
Training loss: 1.054985523223877
Validation loss: 1.937855302646596

Epoch: 5| Step: 1
Training loss: 0.5979716777801514
Validation loss: 1.9194446481684202

Epoch: 5| Step: 2
Training loss: 0.8942111730575562
Validation loss: 1.9181196253786805

Epoch: 5| Step: 3
Training loss: 0.4774593412876129
Validation loss: 1.9212849729804582

Epoch: 5| Step: 4
Training loss: 0.8496118783950806
Validation loss: 1.9036337675586823

Epoch: 5| Step: 5
Training loss: 0.5989788770675659
Validation loss: 1.9069478011900378

Epoch: 5| Step: 6
Training loss: 0.7940230965614319
Validation loss: 1.8717393798212851

Epoch: 5| Step: 7
Training loss: 0.6224405169487
Validation loss: 1.892541734121179

Epoch: 5| Step: 8
Training loss: 0.710720419883728
Validation loss: 1.8884347305502942

Epoch: 5| Step: 9
Training loss: 0.44934433698654175
Validation loss: 1.8748632246448147

Epoch: 5| Step: 10
Training loss: 0.6966664791107178
Validation loss: 1.9002551071105465

Epoch: 244| Step: 0
Training loss: 0.5849236249923706
Validation loss: 1.9096250328966367

Epoch: 5| Step: 1
Training loss: 0.7367923855781555
Validation loss: 1.8875061850393973

Epoch: 5| Step: 2
Training loss: 1.0304994583129883
Validation loss: 1.8600910607204642

Epoch: 5| Step: 3
Training loss: 0.6582706570625305
Validation loss: 1.8566600250941452

Epoch: 5| Step: 4
Training loss: 0.9975017309188843
Validation loss: 1.8647574199143278

Epoch: 5| Step: 5
Training loss: 0.6506282687187195
Validation loss: 1.8564798537121023

Epoch: 5| Step: 6
Training loss: 0.4797557294368744
Validation loss: 1.8827478321649695

Epoch: 5| Step: 7
Training loss: 0.8267477750778198
Validation loss: 1.8598258873467803

Epoch: 5| Step: 8
Training loss: 0.4201079308986664
Validation loss: 1.8649655208792737

Epoch: 5| Step: 9
Training loss: 0.480290025472641
Validation loss: 1.8878434729832474

Epoch: 5| Step: 10
Training loss: 0.6097385883331299
Validation loss: 1.9101217408334055

Epoch: 245| Step: 0
Training loss: 0.5013770461082458
Validation loss: 1.9242174138305008

Epoch: 5| Step: 1
Training loss: 0.28465449810028076
Validation loss: 1.8797096398568922

Epoch: 5| Step: 2
Training loss: 1.1065051555633545
Validation loss: 1.8951988399669688

Epoch: 5| Step: 3
Training loss: 0.6602979898452759
Validation loss: 1.8801220578532065

Epoch: 5| Step: 4
Training loss: 0.8041362762451172
Validation loss: 1.8882821195869035

Epoch: 5| Step: 5
Training loss: 0.5320295691490173
Validation loss: 1.8789087905678699

Epoch: 5| Step: 6
Training loss: 0.8851277232170105
Validation loss: 1.8875136542063888

Epoch: 5| Step: 7
Training loss: 0.8560754060745239
Validation loss: 1.904265949803014

Epoch: 5| Step: 8
Training loss: 0.33243516087532043
Validation loss: 1.9052252077287244

Epoch: 5| Step: 9
Training loss: 0.50730299949646
Validation loss: 1.9077366616136284

Epoch: 5| Step: 10
Training loss: 0.7157098650932312
Validation loss: 1.903420102211737

Epoch: 246| Step: 0
Training loss: 0.42915600538253784
Validation loss: 1.8824694695011261

Epoch: 5| Step: 1
Training loss: 0.7224050760269165
Validation loss: 1.8998601346887567

Epoch: 5| Step: 2
Training loss: 0.560813307762146
Validation loss: 1.883827510700431

Epoch: 5| Step: 3
Training loss: 0.6153361201286316
Validation loss: 1.9129172166188557

Epoch: 5| Step: 4
Training loss: 0.41057735681533813
Validation loss: 1.918715012970791

Epoch: 5| Step: 5
Training loss: 0.9168697595596313
Validation loss: 1.9193237520033313

Epoch: 5| Step: 6
Training loss: 0.6185470223426819
Validation loss: 1.9030673914058234

Epoch: 5| Step: 7
Training loss: 0.4826788902282715
Validation loss: 1.9190244546500586

Epoch: 5| Step: 8
Training loss: 0.7452482581138611
Validation loss: 1.879599932701357

Epoch: 5| Step: 9
Training loss: 0.7428773045539856
Validation loss: 1.880206674657842

Epoch: 5| Step: 10
Training loss: 0.7676364779472351
Validation loss: 1.8856996329881812

Epoch: 247| Step: 0
Training loss: 0.7136175632476807
Validation loss: 1.8418660984244397

Epoch: 5| Step: 1
Training loss: 0.6100595593452454
Validation loss: 1.8698950506025744

Epoch: 5| Step: 2
Training loss: 0.8888190984725952
Validation loss: 1.8811749514713083

Epoch: 5| Step: 3
Training loss: 0.5921911001205444
Validation loss: 1.8879482746124268

Epoch: 5| Step: 4
Training loss: 0.6349185109138489
Validation loss: 1.881712673812784

Epoch: 5| Step: 5
Training loss: 0.39055299758911133
Validation loss: 1.898529685953612

Epoch: 5| Step: 6
Training loss: 0.71365886926651
Validation loss: 1.8971138333761564

Epoch: 5| Step: 7
Training loss: 0.4008956849575043
Validation loss: 1.876186619522751

Epoch: 5| Step: 8
Training loss: 0.7704364061355591
Validation loss: 1.8731846206931657

Epoch: 5| Step: 9
Training loss: 0.41599541902542114
Validation loss: 1.8658578229206864

Epoch: 5| Step: 10
Training loss: 0.9777712821960449
Validation loss: 1.87636060355812

Epoch: 248| Step: 0
Training loss: 1.0973377227783203
Validation loss: 1.9038257778331797

Epoch: 5| Step: 1
Training loss: 0.9851584434509277
Validation loss: 1.922513524691264

Epoch: 5| Step: 2
Training loss: 0.4350254535675049
Validation loss: 1.8894951099990516

Epoch: 5| Step: 3
Training loss: 0.5247408151626587
Validation loss: 1.8833692740368586

Epoch: 5| Step: 4
Training loss: 0.5283805727958679
Validation loss: 1.8853180485387002

Epoch: 5| Step: 5
Training loss: 0.474526584148407
Validation loss: 1.8986114981353923

Epoch: 5| Step: 6
Training loss: 0.6724089980125427
Validation loss: 1.8766168650760446

Epoch: 5| Step: 7
Training loss: 0.43865078687667847
Validation loss: 1.8867807676715236

Epoch: 5| Step: 8
Training loss: 0.7343674302101135
Validation loss: 1.948501891987298

Epoch: 5| Step: 9
Training loss: 0.5342625379562378
Validation loss: 1.9414528903140817

Epoch: 5| Step: 10
Training loss: 0.632601797580719
Validation loss: 1.9243576885551534

Epoch: 249| Step: 0
Training loss: 0.7486447095870972
Validation loss: 1.898263112191231

Epoch: 5| Step: 1
Training loss: 0.5660974383354187
Validation loss: 1.9072621631365951

Epoch: 5| Step: 2
Training loss: 0.6029102802276611
Validation loss: 1.876846134021718

Epoch: 5| Step: 3
Training loss: 0.9247747659683228
Validation loss: 1.8897239213348718

Epoch: 5| Step: 4
Training loss: 0.43690410256385803
Validation loss: 1.876039630623274

Epoch: 5| Step: 5
Training loss: 0.4133450388908386
Validation loss: 1.8961163541322112

Epoch: 5| Step: 6
Training loss: 0.5218410491943359
Validation loss: 1.8587479540096816

Epoch: 5| Step: 7
Training loss: 0.6905199885368347
Validation loss: 1.8716419499407533

Epoch: 5| Step: 8
Training loss: 0.3880715072154999
Validation loss: 1.872316688619634

Epoch: 5| Step: 9
Training loss: 0.5446404218673706
Validation loss: 1.875385187005484

Epoch: 5| Step: 10
Training loss: 1.210145115852356
Validation loss: 1.8915303958359586

Epoch: 250| Step: 0
Training loss: 0.46925491094589233
Validation loss: 1.8991481078568326

Epoch: 5| Step: 1
Training loss: 0.8364356756210327
Validation loss: 1.902144980686967

Epoch: 5| Step: 2
Training loss: 0.41929012537002563
Validation loss: 1.9049189244547198

Epoch: 5| Step: 3
Training loss: 0.3898143768310547
Validation loss: 1.8844002164820188

Epoch: 5| Step: 4
Training loss: 0.9548091888427734
Validation loss: 1.886451522509257

Epoch: 5| Step: 5
Training loss: 0.45283517241477966
Validation loss: 1.8472280502319336

Epoch: 5| Step: 6
Training loss: 0.6455776691436768
Validation loss: 1.8659591341531405

Epoch: 5| Step: 7
Training loss: 0.6504514217376709
Validation loss: 1.8745093038005214

Epoch: 5| Step: 8
Training loss: 0.8903456926345825
Validation loss: 1.870894862759498

Epoch: 5| Step: 9
Training loss: 0.7900584936141968
Validation loss: 1.8790127064592095

Epoch: 5| Step: 10
Training loss: 0.25634434819221497
Validation loss: 1.8712052440130582

Epoch: 251| Step: 0
Training loss: 0.7645301818847656
Validation loss: 1.9019223284977738

Epoch: 5| Step: 1
Training loss: 0.46737509965896606
Validation loss: 1.88613385282537

Epoch: 5| Step: 2
Training loss: 0.6282273530960083
Validation loss: 1.9124074802603772

Epoch: 5| Step: 3
Training loss: 0.5406981706619263
Validation loss: 1.8850971806433894

Epoch: 5| Step: 4
Training loss: 0.634270191192627
Validation loss: 1.8663608335679578

Epoch: 5| Step: 5
Training loss: 0.6900525093078613
Validation loss: 1.8661691937395322

Epoch: 5| Step: 6
Training loss: 0.8801968693733215
Validation loss: 1.8629477011260165

Epoch: 5| Step: 7
Training loss: 0.3863404393196106
Validation loss: 1.8601369216877928

Epoch: 5| Step: 8
Training loss: 0.7288581728935242
Validation loss: 1.8673715437612226

Epoch: 5| Step: 9
Training loss: 0.5320943593978882
Validation loss: 1.8730242739441574

Epoch: 5| Step: 10
Training loss: 0.6133496761322021
Validation loss: 1.8764577373381583

Epoch: 252| Step: 0
Training loss: 0.35897931456565857
Validation loss: 1.860496219768319

Epoch: 5| Step: 1
Training loss: 0.8108166456222534
Validation loss: 1.8661917742862497

Epoch: 5| Step: 2
Training loss: 0.7902020812034607
Validation loss: 1.8463650980303365

Epoch: 5| Step: 3
Training loss: 0.8117517232894897
Validation loss: 1.856752928867135

Epoch: 5| Step: 4
Training loss: 0.5261939764022827
Validation loss: 1.8586720766559723

Epoch: 5| Step: 5
Training loss: 0.5319806337356567
Validation loss: 1.882735336980512

Epoch: 5| Step: 6
Training loss: 0.5130540132522583
Validation loss: 1.842173748118903

Epoch: 5| Step: 7
Training loss: 0.6304236054420471
Validation loss: 1.8482184435731621

Epoch: 5| Step: 8
Training loss: 0.6059911847114563
Validation loss: 1.8494850743201472

Epoch: 5| Step: 9
Training loss: 0.6860239505767822
Validation loss: 1.8416902890769384

Epoch: 5| Step: 10
Training loss: 0.46659260988235474
Validation loss: 1.8630273213950537

Epoch: 253| Step: 0
Training loss: 0.8106098175048828
Validation loss: 1.863141930231484

Epoch: 5| Step: 1
Training loss: 0.5859530568122864
Validation loss: 1.862447948865993

Epoch: 5| Step: 2
Training loss: 0.5901845693588257
Validation loss: 1.8600705772317865

Epoch: 5| Step: 3
Training loss: 0.3244175612926483
Validation loss: 1.839226407389487

Epoch: 5| Step: 4
Training loss: 0.31589189171791077
Validation loss: 1.8644213548270605

Epoch: 5| Step: 5
Training loss: 0.6409891843795776
Validation loss: 1.8770412655286892

Epoch: 5| Step: 6
Training loss: 0.39791446924209595
Validation loss: 1.867863557671988

Epoch: 5| Step: 7
Training loss: 0.9630090594291687
Validation loss: 1.87281052015161

Epoch: 5| Step: 8
Training loss: 0.7422246932983398
Validation loss: 1.8864081675006497

Epoch: 5| Step: 9
Training loss: 0.5260413289070129
Validation loss: 1.9088281803233649

Epoch: 5| Step: 10
Training loss: 0.9877063632011414
Validation loss: 1.9152170470965806

Epoch: 254| Step: 0
Training loss: 0.34365567564964294
Validation loss: 1.9000319909023982

Epoch: 5| Step: 1
Training loss: 0.3832247257232666
Validation loss: 1.891702623777492

Epoch: 5| Step: 2
Training loss: 0.49869832396507263
Validation loss: 1.8791633690557172

Epoch: 5| Step: 3
Training loss: 0.4885135591030121
Validation loss: 1.8737700049595167

Epoch: 5| Step: 4
Training loss: 0.7463748455047607
Validation loss: 1.8702398935953777

Epoch: 5| Step: 5
Training loss: 0.6241984367370605
Validation loss: 1.8687157477101972

Epoch: 5| Step: 6
Training loss: 0.539539635181427
Validation loss: 1.8470038085855462

Epoch: 5| Step: 7
Training loss: 0.715288519859314
Validation loss: 1.87849675455401

Epoch: 5| Step: 8
Training loss: 0.4416235089302063
Validation loss: 1.8792604541265836

Epoch: 5| Step: 9
Training loss: 0.8004469871520996
Validation loss: 1.8900920152664185

Epoch: 5| Step: 10
Training loss: 1.0349955558776855
Validation loss: 1.861684812012539

Epoch: 255| Step: 0
Training loss: 0.6308754682540894
Validation loss: 1.8720399692494383

Epoch: 5| Step: 1
Training loss: 0.7556158304214478
Validation loss: 1.8483415149873303

Epoch: 5| Step: 2
Training loss: 0.4337630867958069
Validation loss: 1.8380013255662815

Epoch: 5| Step: 3
Training loss: 0.40010833740234375
Validation loss: 1.8175992324788084

Epoch: 5| Step: 4
Training loss: 0.4775734841823578
Validation loss: 1.8348353024451964

Epoch: 5| Step: 5
Training loss: 0.6739413142204285
Validation loss: 1.8678289600597915

Epoch: 5| Step: 6
Training loss: 0.4785063862800598
Validation loss: 1.875491516564482

Epoch: 5| Step: 7
Training loss: 0.9823238253593445
Validation loss: 1.8888336625150455

Epoch: 5| Step: 8
Training loss: 0.6418201923370361
Validation loss: 1.8911028831235823

Epoch: 5| Step: 9
Training loss: 0.5503794550895691
Validation loss: 1.8980873912893317

Epoch: 5| Step: 10
Training loss: 0.6541876792907715
Validation loss: 1.8880236430834698

Epoch: 256| Step: 0
Training loss: 0.7624780535697937
Validation loss: 1.9000032127544444

Epoch: 5| Step: 1
Training loss: 0.6731613874435425
Validation loss: 1.8895609199359853

Epoch: 5| Step: 2
Training loss: 0.557327151298523
Validation loss: 1.9127090464356125

Epoch: 5| Step: 3
Training loss: 0.4272555410861969
Validation loss: 1.9376958877809587

Epoch: 5| Step: 4
Training loss: 0.61575847864151
Validation loss: 1.9342569099959506

Epoch: 5| Step: 5
Training loss: 0.5966085195541382
Validation loss: 1.9118409105526504

Epoch: 5| Step: 6
Training loss: 0.4736299514770508
Validation loss: 1.8978623241506598

Epoch: 5| Step: 7
Training loss: 0.36393338441848755
Validation loss: 1.9005989887381112

Epoch: 5| Step: 8
Training loss: 0.7222380042076111
Validation loss: 1.8848255142088859

Epoch: 5| Step: 9
Training loss: 0.8853757977485657
Validation loss: 1.8925193279020247

Epoch: 5| Step: 10
Training loss: 0.5095734596252441
Validation loss: 1.8873673292898363

Epoch: 257| Step: 0
Training loss: 0.5262885093688965
Validation loss: 1.8699861585452993

Epoch: 5| Step: 1
Training loss: 0.6695396304130554
Validation loss: 1.888042498660344

Epoch: 5| Step: 2
Training loss: 0.7008119821548462
Validation loss: 1.8432797603709723

Epoch: 5| Step: 3
Training loss: 0.5369474291801453
Validation loss: 1.8566423308464788

Epoch: 5| Step: 4
Training loss: 0.5642607808113098
Validation loss: 1.8671683534499137

Epoch: 5| Step: 5
Training loss: 0.5638101696968079
Validation loss: 1.8920770101649786

Epoch: 5| Step: 6
Training loss: 0.7609877586364746
Validation loss: 1.912490992135899

Epoch: 5| Step: 7
Training loss: 0.3985441029071808
Validation loss: 1.8949161165504045

Epoch: 5| Step: 8
Training loss: 0.6740039587020874
Validation loss: 1.8871459127754293

Epoch: 5| Step: 9
Training loss: 0.6574234962463379
Validation loss: 1.8705489430376279

Epoch: 5| Step: 10
Training loss: 0.6467785239219666
Validation loss: 1.8616125070920555

Epoch: 258| Step: 0
Training loss: 0.5386118292808533
Validation loss: 1.874762140294557

Epoch: 5| Step: 1
Training loss: 0.5437008142471313
Validation loss: 1.8731407221927439

Epoch: 5| Step: 2
Training loss: 0.5133976340293884
Validation loss: 1.8933359140990882

Epoch: 5| Step: 3
Training loss: 0.47961264848709106
Validation loss: 1.9005635899882163

Epoch: 5| Step: 4
Training loss: 0.5940486192703247
Validation loss: 1.9243124518343198

Epoch: 5| Step: 5
Training loss: 0.4332748055458069
Validation loss: 1.895024763640537

Epoch: 5| Step: 6
Training loss: 0.44135165214538574
Validation loss: 1.8736662915957871

Epoch: 5| Step: 7
Training loss: 0.6385699510574341
Validation loss: 1.8844533889524397

Epoch: 5| Step: 8
Training loss: 1.2819894552230835
Validation loss: 1.8714838566318635

Epoch: 5| Step: 9
Training loss: 0.4320123791694641
Validation loss: 1.8641823863470426

Epoch: 5| Step: 10
Training loss: 0.6049020290374756
Validation loss: 1.8562794411054222

Epoch: 259| Step: 0
Training loss: 0.6181293725967407
Validation loss: 1.886066880277408

Epoch: 5| Step: 1
Training loss: 0.32332050800323486
Validation loss: 1.8608655788565194

Epoch: 5| Step: 2
Training loss: 0.5825597047805786
Validation loss: 1.8763963637813446

Epoch: 5| Step: 3
Training loss: 0.5405570268630981
Validation loss: 1.8821186173346736

Epoch: 5| Step: 4
Training loss: 0.8493968844413757
Validation loss: 1.8858382471146122

Epoch: 5| Step: 5
Training loss: 0.46966925263404846
Validation loss: 1.8908792080417756

Epoch: 5| Step: 6
Training loss: 0.7010337114334106
Validation loss: 1.8976702613215293

Epoch: 5| Step: 7
Training loss: 0.44318443536758423
Validation loss: 1.8821217142125612

Epoch: 5| Step: 8
Training loss: 0.6215665340423584
Validation loss: 1.8836544200938234

Epoch: 5| Step: 9
Training loss: 0.5810964107513428
Validation loss: 1.877594050540719

Epoch: 5| Step: 10
Training loss: 0.41772255301475525
Validation loss: 1.867713556494764

Epoch: 260| Step: 0
Training loss: 0.6088981628417969
Validation loss: 1.886673645306659

Epoch: 5| Step: 1
Training loss: 0.5867741107940674
Validation loss: 1.8972291433683006

Epoch: 5| Step: 2
Training loss: 0.44893789291381836
Validation loss: 1.8807917012963244

Epoch: 5| Step: 3
Training loss: 1.1953659057617188
Validation loss: 1.8602187569423387

Epoch: 5| Step: 4
Training loss: 0.2208390235900879
Validation loss: 1.8680285510196482

Epoch: 5| Step: 5
Training loss: 0.5637539625167847
Validation loss: 1.8535236620133924

Epoch: 5| Step: 6
Training loss: 0.4853057861328125
Validation loss: 1.8766058401394916

Epoch: 5| Step: 7
Training loss: 0.5842228531837463
Validation loss: 1.8557180204699117

Epoch: 5| Step: 8
Training loss: 0.3899576663970947
Validation loss: 1.8663540629930393

Epoch: 5| Step: 9
Training loss: 0.39795178174972534
Validation loss: 1.8857108969842233

Epoch: 5| Step: 10
Training loss: 0.6857649087905884
Validation loss: 1.8706745140014156

Epoch: 261| Step: 0
Training loss: 0.6498006582260132
Validation loss: 1.8625889491009455

Epoch: 5| Step: 1
Training loss: 0.7792640924453735
Validation loss: 1.8729263467173423

Epoch: 5| Step: 2
Training loss: 0.786636471748352
Validation loss: 1.87740368740533

Epoch: 5| Step: 3
Training loss: 0.43196263909339905
Validation loss: 1.8567657957794845

Epoch: 5| Step: 4
Training loss: 0.44116243720054626
Validation loss: 1.8327248878376459

Epoch: 5| Step: 5
Training loss: 0.3077106475830078
Validation loss: 1.8344514190509755

Epoch: 5| Step: 6
Training loss: 0.5809210538864136
Validation loss: 1.8363900928087131

Epoch: 5| Step: 7
Training loss: 0.9033180475234985
Validation loss: 1.831283953882033

Epoch: 5| Step: 8
Training loss: 0.4035719931125641
Validation loss: 1.8242083685372465

Epoch: 5| Step: 9
Training loss: 0.2593640685081482
Validation loss: 1.855290719257888

Epoch: 5| Step: 10
Training loss: 0.6072978377342224
Validation loss: 1.850708665386323

Epoch: 262| Step: 0
Training loss: 0.33448415994644165
Validation loss: 1.8763333225762973

Epoch: 5| Step: 1
Training loss: 0.6064705848693848
Validation loss: 1.877940688081967

Epoch: 5| Step: 2
Training loss: 0.6736093759536743
Validation loss: 1.8674053556175643

Epoch: 5| Step: 3
Training loss: 0.467583030462265
Validation loss: 1.8652708786790089

Epoch: 5| Step: 4
Training loss: 0.48685240745544434
Validation loss: 1.8480864981169343

Epoch: 5| Step: 5
Training loss: 0.6181721687316895
Validation loss: 1.8507702017343173

Epoch: 5| Step: 6
Training loss: 0.5267749428749084
Validation loss: 1.8209269367238528

Epoch: 5| Step: 7
Training loss: 0.7305728793144226
Validation loss: 1.8085146636091254

Epoch: 5| Step: 8
Training loss: 0.47166213393211365
Validation loss: 1.8598832263741443

Epoch: 5| Step: 9
Training loss: 0.5442753434181213
Validation loss: 1.8518991483155118

Epoch: 5| Step: 10
Training loss: 0.7275399565696716
Validation loss: 1.8555635072851693

Epoch: 263| Step: 0
Training loss: 0.5087547898292542
Validation loss: 1.8825916256955875

Epoch: 5| Step: 1
Training loss: 0.760375440120697
Validation loss: 1.870804484172534

Epoch: 5| Step: 2
Training loss: 0.47317904233932495
Validation loss: 1.87039767542193

Epoch: 5| Step: 3
Training loss: 0.4824684262275696
Validation loss: 1.866634984170237

Epoch: 5| Step: 4
Training loss: 0.6672621965408325
Validation loss: 1.848114743027636

Epoch: 5| Step: 5
Training loss: 0.724644660949707
Validation loss: 1.8367548693892777

Epoch: 5| Step: 6
Training loss: 0.2879926562309265
Validation loss: 1.8133357929927048

Epoch: 5| Step: 7
Training loss: 0.5006557703018188
Validation loss: 1.834975060596261

Epoch: 5| Step: 8
Training loss: 0.4303654134273529
Validation loss: 1.8170950592205088

Epoch: 5| Step: 9
Training loss: 0.6405960917472839
Validation loss: 1.8265673998863465

Epoch: 5| Step: 10
Training loss: 0.5696816444396973
Validation loss: 1.8335612896950013

Epoch: 264| Step: 0
Training loss: 0.5206674337387085
Validation loss: 1.8648540627571843

Epoch: 5| Step: 1
Training loss: 0.649309515953064
Validation loss: 1.8886537423697851

Epoch: 5| Step: 2
Training loss: 0.6460343599319458
Validation loss: 1.8744076631402458

Epoch: 5| Step: 3
Training loss: 0.5385788083076477
Validation loss: 1.8736536361837899

Epoch: 5| Step: 4
Training loss: 0.4825593829154968
Validation loss: 1.8721963449191021

Epoch: 5| Step: 5
Training loss: 0.38781705498695374
Validation loss: 1.8369981229946177

Epoch: 5| Step: 6
Training loss: 0.4711110591888428
Validation loss: 1.8047843235795216

Epoch: 5| Step: 7
Training loss: 0.7995790243148804
Validation loss: 1.8102258789923884

Epoch: 5| Step: 8
Training loss: 0.4861157536506653
Validation loss: 1.8115468089298536

Epoch: 5| Step: 9
Training loss: 0.8269052505493164
Validation loss: 1.8380628901143228

Epoch: 5| Step: 10
Training loss: 0.4541849195957184
Validation loss: 1.8457858088195964

Epoch: 265| Step: 0
Training loss: 0.5760923624038696
Validation loss: 1.8705300028606127

Epoch: 5| Step: 1
Training loss: 1.0246468782424927
Validation loss: 1.9068835204647434

Epoch: 5| Step: 2
Training loss: 0.5653886795043945
Validation loss: 1.9066719406394548

Epoch: 5| Step: 3
Training loss: 0.32916581630706787
Validation loss: 1.8939066240864415

Epoch: 5| Step: 4
Training loss: 0.6267538070678711
Validation loss: 1.8944867528894895

Epoch: 5| Step: 5
Training loss: 0.6262207627296448
Validation loss: 1.8702023644601145

Epoch: 5| Step: 6
Training loss: 0.5249354243278503
Validation loss: 1.8392312462611864

Epoch: 5| Step: 7
Training loss: 0.3554479479789734
Validation loss: 1.8306724307357625

Epoch: 5| Step: 8
Training loss: 0.4346660077571869
Validation loss: 1.8355460730932092

Epoch: 5| Step: 9
Training loss: 0.4374002516269684
Validation loss: 1.8350056409835815

Epoch: 5| Step: 10
Training loss: 0.8924139738082886
Validation loss: 1.8348202154200564

Epoch: 266| Step: 0
Training loss: 0.7199736833572388
Validation loss: 1.841581162586007

Epoch: 5| Step: 1
Training loss: 0.5726788640022278
Validation loss: 1.8766069463504258

Epoch: 5| Step: 2
Training loss: 0.39321112632751465
Validation loss: 1.8434325110527776

Epoch: 5| Step: 3
Training loss: 0.5184814929962158
Validation loss: 1.8609798685196908

Epoch: 5| Step: 4
Training loss: 0.47142738103866577
Validation loss: 1.8570429586595105

Epoch: 5| Step: 5
Training loss: 0.5621939301490784
Validation loss: 1.8525044315604753

Epoch: 5| Step: 6
Training loss: 0.6209021806716919
Validation loss: 1.8317788467612317

Epoch: 5| Step: 7
Training loss: 0.5861995816230774
Validation loss: 1.815707988636468

Epoch: 5| Step: 8
Training loss: 0.6867018342018127
Validation loss: 1.8122530175793556

Epoch: 5| Step: 9
Training loss: 0.3814219832420349
Validation loss: 1.8110792226688837

Epoch: 5| Step: 10
Training loss: 0.5272794961929321
Validation loss: 1.8295064754383539

Epoch: 267| Step: 0
Training loss: 1.1005401611328125
Validation loss: 1.839971996122791

Epoch: 5| Step: 1
Training loss: 0.440744549036026
Validation loss: 1.827964537887163

Epoch: 5| Step: 2
Training loss: 0.5625420808792114
Validation loss: 1.822730197701403

Epoch: 5| Step: 3
Training loss: 0.5447610020637512
Validation loss: 1.806450592574253

Epoch: 5| Step: 4
Training loss: 0.3895006775856018
Validation loss: 1.8184552269597207

Epoch: 5| Step: 5
Training loss: 0.6688839197158813
Validation loss: 1.8125600891728555

Epoch: 5| Step: 6
Training loss: 0.47408121824264526
Validation loss: 1.8133343291539017

Epoch: 5| Step: 7
Training loss: 0.5452982783317566
Validation loss: 1.828775285392679

Epoch: 5| Step: 8
Training loss: 0.6323074102401733
Validation loss: 1.8230213542138376

Epoch: 5| Step: 9
Training loss: 0.37746214866638184
Validation loss: 1.8107118401476132

Epoch: 5| Step: 10
Training loss: 0.43915075063705444
Validation loss: 1.8413580386869368

Epoch: 268| Step: 0
Training loss: 0.8071533441543579
Validation loss: 1.8513478540605115

Epoch: 5| Step: 1
Training loss: 0.3499864935874939
Validation loss: 1.8352515236023934

Epoch: 5| Step: 2
Training loss: 0.2354169338941574
Validation loss: 1.8613029115943498

Epoch: 5| Step: 3
Training loss: 0.6344678997993469
Validation loss: 1.8410084427043956

Epoch: 5| Step: 4
Training loss: 0.8334498405456543
Validation loss: 1.8456340361666936

Epoch: 5| Step: 5
Training loss: 0.4162207543849945
Validation loss: 1.8405065510862617

Epoch: 5| Step: 6
Training loss: 0.3910081386566162
Validation loss: 1.8646824911076536

Epoch: 5| Step: 7
Training loss: 0.5321091413497925
Validation loss: 1.8587795649805376

Epoch: 5| Step: 8
Training loss: 0.6729390621185303
Validation loss: 1.8746526754030617

Epoch: 5| Step: 9
Training loss: 0.540749192237854
Validation loss: 1.879352952844353

Epoch: 5| Step: 10
Training loss: 0.4512181580066681
Validation loss: 1.8726775261663622

Epoch: 269| Step: 0
Training loss: 0.4523516595363617
Validation loss: 1.8727431335756857

Epoch: 5| Step: 1
Training loss: 0.7510703802108765
Validation loss: 1.8678350563972228

Epoch: 5| Step: 2
Training loss: 0.5058520436286926
Validation loss: 1.8281844354444934

Epoch: 5| Step: 3
Training loss: 0.40778422355651855
Validation loss: 1.8023829139688963

Epoch: 5| Step: 4
Training loss: 0.41157254576683044
Validation loss: 1.8015124028728855

Epoch: 5| Step: 5
Training loss: 0.7893915176391602
Validation loss: 1.8009715464807325

Epoch: 5| Step: 6
Training loss: 0.4035183787345886
Validation loss: 1.7647181351979573

Epoch: 5| Step: 7
Training loss: 0.707008957862854
Validation loss: 1.7968953219793176

Epoch: 5| Step: 8
Training loss: 0.31437039375305176
Validation loss: 1.8069248981373285

Epoch: 5| Step: 9
Training loss: 0.460559219121933
Validation loss: 1.8186002008376583

Epoch: 5| Step: 10
Training loss: 0.5062437057495117
Validation loss: 1.8323179502641

Epoch: 270| Step: 0
Training loss: 0.546089231967926
Validation loss: 1.8339204480571132

Epoch: 5| Step: 1
Training loss: 0.5574887990951538
Validation loss: 1.845940456595472

Epoch: 5| Step: 2
Training loss: 0.45357567071914673
Validation loss: 1.8711824981115197

Epoch: 5| Step: 3
Training loss: 0.31630510091781616
Validation loss: 1.8870940234071465

Epoch: 5| Step: 4
Training loss: 0.17101922631263733
Validation loss: 1.8362404505411785

Epoch: 5| Step: 5
Training loss: 0.37524932622909546
Validation loss: 1.8267311370500954

Epoch: 5| Step: 6
Training loss: 0.7245604395866394
Validation loss: 1.7950264484651628

Epoch: 5| Step: 7
Training loss: 1.1071007251739502
Validation loss: 1.7978930191327167

Epoch: 5| Step: 8
Training loss: 0.5990148782730103
Validation loss: 1.7754180380093154

Epoch: 5| Step: 9
Training loss: 0.4883878827095032
Validation loss: 1.817429099031674

Epoch: 5| Step: 10
Training loss: 0.442446231842041
Validation loss: 1.8322378063714633

Epoch: 271| Step: 0
Training loss: 0.5329561233520508
Validation loss: 1.8234432499895814

Epoch: 5| Step: 1
Training loss: 0.6233699917793274
Validation loss: 1.8521659502419092

Epoch: 5| Step: 2
Training loss: 0.43300944566726685
Validation loss: 1.9161707534584949

Epoch: 5| Step: 3
Training loss: 1.0110161304473877
Validation loss: 1.9008894376857306

Epoch: 5| Step: 4
Training loss: 0.48684564232826233
Validation loss: 1.8898689836584113

Epoch: 5| Step: 5
Training loss: 0.3904951214790344
Validation loss: 1.8795324051251976

Epoch: 5| Step: 6
Training loss: 0.44995108246803284
Validation loss: 1.8696365369263517

Epoch: 5| Step: 7
Training loss: 0.3454032838344574
Validation loss: 1.8537850097943378

Epoch: 5| Step: 8
Training loss: 0.33344218134880066
Validation loss: 1.8578101678561139

Epoch: 5| Step: 9
Training loss: 0.5647845268249512
Validation loss: 1.8221169992159771

Epoch: 5| Step: 10
Training loss: 0.6567132472991943
Validation loss: 1.8160520497188772

Epoch: 272| Step: 0
Training loss: 0.4660140573978424
Validation loss: 1.8268718168299685

Epoch: 5| Step: 1
Training loss: 0.48574599623680115
Validation loss: 1.8348030274914158

Epoch: 5| Step: 2
Training loss: 0.42703181505203247
Validation loss: 1.8657615492420812

Epoch: 5| Step: 3
Training loss: 0.6146910786628723
Validation loss: 1.85889829615111

Epoch: 5| Step: 4
Training loss: 0.7253992557525635
Validation loss: 1.887195675603805

Epoch: 5| Step: 5
Training loss: 0.6623928546905518
Validation loss: 1.8998350956106698

Epoch: 5| Step: 6
Training loss: 0.6203359365463257
Validation loss: 1.8880499716727965

Epoch: 5| Step: 7
Training loss: 0.6455215215682983
Validation loss: 1.8854438604847077

Epoch: 5| Step: 8
Training loss: 0.2849927544593811
Validation loss: 1.8583014299792628

Epoch: 5| Step: 9
Training loss: 0.5444909334182739
Validation loss: 1.8303606676798996

Epoch: 5| Step: 10
Training loss: 0.39965423941612244
Validation loss: 1.8247075247508224

Epoch: 273| Step: 0
Training loss: 0.49188584089279175
Validation loss: 1.8241625908882386

Epoch: 5| Step: 1
Training loss: 0.38035327196121216
Validation loss: 1.8364806393141389

Epoch: 5| Step: 2
Training loss: 0.5293173789978027
Validation loss: 1.8576923275506625

Epoch: 5| Step: 3
Training loss: 0.2762863039970398
Validation loss: 1.8441318055634857

Epoch: 5| Step: 4
Training loss: 0.57806396484375
Validation loss: 1.8798121233140268

Epoch: 5| Step: 5
Training loss: 0.5881726741790771
Validation loss: 1.8520719159033991

Epoch: 5| Step: 6
Training loss: 0.7012650370597839
Validation loss: 1.8255250684676632

Epoch: 5| Step: 7
Training loss: 0.6912833452224731
Validation loss: 1.816496100476993

Epoch: 5| Step: 8
Training loss: 0.587184727191925
Validation loss: 1.8088071128373504

Epoch: 5| Step: 9
Training loss: 0.33966031670570374
Validation loss: 1.7888699052154378

Epoch: 5| Step: 10
Training loss: 0.4576880633831024
Validation loss: 1.789592558337796

Epoch: 274| Step: 0
Training loss: 0.4926382005214691
Validation loss: 1.821412258250739

Epoch: 5| Step: 1
Training loss: 0.6029394865036011
Validation loss: 1.8242247412281651

Epoch: 5| Step: 2
Training loss: 0.25909653306007385
Validation loss: 1.862060458429398

Epoch: 5| Step: 3
Training loss: 0.3396371006965637
Validation loss: 1.8386517878501647

Epoch: 5| Step: 4
Training loss: 0.68694007396698
Validation loss: 1.8477437496185303

Epoch: 5| Step: 5
Training loss: 0.9182519912719727
Validation loss: 1.8670809474042667

Epoch: 5| Step: 6
Training loss: 0.48702993988990784
Validation loss: 1.8491527418936453

Epoch: 5| Step: 7
Training loss: 0.571894109249115
Validation loss: 1.8507434373260827

Epoch: 5| Step: 8
Training loss: 0.47139301896095276
Validation loss: 1.8388136574017104

Epoch: 5| Step: 9
Training loss: 0.19929666817188263
Validation loss: 1.822998405784689

Epoch: 5| Step: 10
Training loss: 0.3393190801143646
Validation loss: 1.8060883424615348

Epoch: 275| Step: 0
Training loss: 0.3830289840698242
Validation loss: 1.837091447204672

Epoch: 5| Step: 1
Training loss: 0.27824628353118896
Validation loss: 1.8510189415306173

Epoch: 5| Step: 2
Training loss: 0.5181297659873962
Validation loss: 1.859771538806218

Epoch: 5| Step: 3
Training loss: 0.5269017815589905
Validation loss: 1.860974722011115

Epoch: 5| Step: 4
Training loss: 0.5692915916442871
Validation loss: 1.8468602139462706

Epoch: 5| Step: 5
Training loss: 0.4220966696739197
Validation loss: 1.863226649581745

Epoch: 5| Step: 6
Training loss: 0.43504923582077026
Validation loss: 1.8192114804380684

Epoch: 5| Step: 7
Training loss: 0.4835039973258972
Validation loss: 1.843792733325753

Epoch: 5| Step: 8
Training loss: 0.6573343276977539
Validation loss: 1.8057741618925525

Epoch: 5| Step: 9
Training loss: 0.5655115246772766
Validation loss: 1.8324704554773146

Epoch: 5| Step: 10
Training loss: 0.39646434783935547
Validation loss: 1.81779444602228

Epoch: 276| Step: 0
Training loss: 0.428658664226532
Validation loss: 1.8021105348422963

Epoch: 5| Step: 1
Training loss: 0.553138256072998
Validation loss: 1.845187012867261

Epoch: 5| Step: 2
Training loss: 0.563632607460022
Validation loss: 1.845533868317963

Epoch: 5| Step: 3
Training loss: 0.37692463397979736
Validation loss: 1.8507101715251963

Epoch: 5| Step: 4
Training loss: 0.653885006904602
Validation loss: 1.8009634722945511

Epoch: 5| Step: 5
Training loss: 0.33362752199172974
Validation loss: 1.8065806076090822

Epoch: 5| Step: 6
Training loss: 0.3583377003669739
Validation loss: 1.8061124970836024

Epoch: 5| Step: 7
Training loss: 0.49742841720581055
Validation loss: 1.7825618559314358

Epoch: 5| Step: 8
Training loss: 0.19824370741844177
Validation loss: 1.783419930806724

Epoch: 5| Step: 9
Training loss: 0.7097290754318237
Validation loss: 1.8126228958047845

Epoch: 5| Step: 10
Training loss: 0.4558737576007843
Validation loss: 1.8197775707449964

Epoch: 277| Step: 0
Training loss: 0.37393826246261597
Validation loss: 1.8297900563927108

Epoch: 5| Step: 1
Training loss: 0.4759172797203064
Validation loss: 1.8537184192288307

Epoch: 5| Step: 2
Training loss: 0.7381640672683716
Validation loss: 1.8347680825059132

Epoch: 5| Step: 3
Training loss: 0.5564137101173401
Validation loss: 1.8232717872947775

Epoch: 5| Step: 4
Training loss: 0.41796964406967163
Validation loss: 1.8135309937179729

Epoch: 5| Step: 5
Training loss: 0.3642979860305786
Validation loss: 1.8111103683389642

Epoch: 5| Step: 6
Training loss: 0.37828904390335083
Validation loss: 1.8258964297592

Epoch: 5| Step: 7
Training loss: 0.3508961796760559
Validation loss: 1.8213815637814101

Epoch: 5| Step: 8
Training loss: 0.26820358633995056
Validation loss: 1.8294105529785156

Epoch: 5| Step: 9
Training loss: 0.4140357971191406
Validation loss: 1.840718311648215

Epoch: 5| Step: 10
Training loss: 0.6457997560501099
Validation loss: 1.8257701089305263

Epoch: 278| Step: 0
Training loss: 0.24795985221862793
Validation loss: 1.814653549143063

Epoch: 5| Step: 1
Training loss: 0.41961947083473206
Validation loss: 1.8100839866104947

Epoch: 5| Step: 2
Training loss: 0.3332700729370117
Validation loss: 1.8010256559618059

Epoch: 5| Step: 3
Training loss: 0.5871326327323914
Validation loss: 1.8216359038506784

Epoch: 5| Step: 4
Training loss: 0.4146099090576172
Validation loss: 1.8287421939193562

Epoch: 5| Step: 5
Training loss: 0.24708032608032227
Validation loss: 1.8425641290603145

Epoch: 5| Step: 6
Training loss: 0.7099283933639526
Validation loss: 1.8424127383898663

Epoch: 5| Step: 7
Training loss: 0.8960610628128052
Validation loss: 1.836015893566993

Epoch: 5| Step: 8
Training loss: 0.3951965868473053
Validation loss: 1.844531943721156

Epoch: 5| Step: 9
Training loss: 0.6396207809448242
Validation loss: 1.8259074957140031

Epoch: 5| Step: 10
Training loss: 0.20015424489974976
Validation loss: 1.8257856830473869

Epoch: 279| Step: 0
Training loss: 0.5141350626945496
Validation loss: 1.8058179360564037

Epoch: 5| Step: 1
Training loss: 0.48230409622192383
Validation loss: 1.7940466942325715

Epoch: 5| Step: 2
Training loss: 0.4833223819732666
Validation loss: 1.78415887201986

Epoch: 5| Step: 3
Training loss: 0.6863827705383301
Validation loss: 1.7889160699741815

Epoch: 5| Step: 4
Training loss: 0.4859983026981354
Validation loss: 1.7886921590374363

Epoch: 5| Step: 5
Training loss: 0.29835042357444763
Validation loss: 1.8152956142220447

Epoch: 5| Step: 6
Training loss: 0.6912519335746765
Validation loss: 1.8214021523793538

Epoch: 5| Step: 7
Training loss: 0.3109254837036133
Validation loss: 1.8370875491890857

Epoch: 5| Step: 8
Training loss: 0.24268296360969543
Validation loss: 1.8227935901252172

Epoch: 5| Step: 9
Training loss: 0.49969482421875
Validation loss: 1.821001539948166

Epoch: 5| Step: 10
Training loss: 0.4684186279773712
Validation loss: 1.8228049739714591

Epoch: 280| Step: 0
Training loss: 0.5406365394592285
Validation loss: 1.820825425527429

Epoch: 5| Step: 1
Training loss: 0.2597772181034088
Validation loss: 1.8431315460512716

Epoch: 5| Step: 2
Training loss: 0.6435137391090393
Validation loss: 1.8646750398861465

Epoch: 5| Step: 3
Training loss: 0.5605983138084412
Validation loss: 1.8826863688807334

Epoch: 5| Step: 4
Training loss: 0.7303739786148071
Validation loss: 1.901297462883816

Epoch: 5| Step: 5
Training loss: 0.60347980260849
Validation loss: 1.8924040191917009

Epoch: 5| Step: 6
Training loss: 0.3542340397834778
Validation loss: 1.8792802390231882

Epoch: 5| Step: 7
Training loss: 0.5015190243721008
Validation loss: 1.86289620014929

Epoch: 5| Step: 8
Training loss: 0.3979857563972473
Validation loss: 1.8542594499485467

Epoch: 5| Step: 9
Training loss: 0.3781205713748932
Validation loss: 1.8138628646891604

Epoch: 5| Step: 10
Training loss: 0.43611907958984375
Validation loss: 1.839129065954557

Epoch: 281| Step: 0
Training loss: 0.6505399942398071
Validation loss: 1.787542522594493

Epoch: 5| Step: 1
Training loss: 0.4088137745857239
Validation loss: 1.8012926552885322

Epoch: 5| Step: 2
Training loss: 0.31909283995628357
Validation loss: 1.8261257320322015

Epoch: 5| Step: 3
Training loss: 0.2579287886619568
Validation loss: 1.8195603457830285

Epoch: 5| Step: 4
Training loss: 0.5854263305664062
Validation loss: 1.7839036628764162

Epoch: 5| Step: 5
Training loss: 0.43363386392593384
Validation loss: 1.7815601646259267

Epoch: 5| Step: 6
Training loss: 0.6215649843215942
Validation loss: 1.779100461672711

Epoch: 5| Step: 7
Training loss: 0.7138034105300903
Validation loss: 1.777788628814041

Epoch: 5| Step: 8
Training loss: 0.473133385181427
Validation loss: 1.8165711959203084

Epoch: 5| Step: 9
Training loss: 0.24794094264507294
Validation loss: 1.8149799762233612

Epoch: 5| Step: 10
Training loss: 0.5089802742004395
Validation loss: 1.8280595874273649

Epoch: 282| Step: 0
Training loss: 0.4934461712837219
Validation loss: 1.8266035433738463

Epoch: 5| Step: 1
Training loss: 0.6205039620399475
Validation loss: 1.8286118238202986

Epoch: 5| Step: 2
Training loss: 0.33786213397979736
Validation loss: 1.821406965614647

Epoch: 5| Step: 3
Training loss: 0.20908646285533905
Validation loss: 1.8172159066764257

Epoch: 5| Step: 4
Training loss: 0.5146344304084778
Validation loss: 1.784586121959071

Epoch: 5| Step: 5
Training loss: 0.41254058480262756
Validation loss: 1.7721149549689343

Epoch: 5| Step: 6
Training loss: 0.7829693555831909
Validation loss: 1.767297875496649

Epoch: 5| Step: 7
Training loss: 0.21351346373558044
Validation loss: 1.7850130591341244

Epoch: 5| Step: 8
Training loss: 0.618912398815155
Validation loss: 1.7932642416287494

Epoch: 5| Step: 9
Training loss: 0.5199066400527954
Validation loss: 1.8137895073941959

Epoch: 5| Step: 10
Training loss: 0.4857330918312073
Validation loss: 1.8187512800257692

Epoch: 283| Step: 0
Training loss: 0.6250346899032593
Validation loss: 1.8565322404266686

Epoch: 5| Step: 1
Training loss: 0.6933421492576599
Validation loss: 1.8471493746644707

Epoch: 5| Step: 2
Training loss: 0.35795480012893677
Validation loss: 1.8634482122236682

Epoch: 5| Step: 3
Training loss: 0.6263037323951721
Validation loss: 1.8649134738470918

Epoch: 5| Step: 4
Training loss: 0.33231431245803833
Validation loss: 1.8322920824891777

Epoch: 5| Step: 5
Training loss: 0.5853168368339539
Validation loss: 1.8451470867280038

Epoch: 5| Step: 6
Training loss: 0.35278788208961487
Validation loss: 1.8241807671003445

Epoch: 5| Step: 7
Training loss: 0.3037705421447754
Validation loss: 1.846434571409738

Epoch: 5| Step: 8
Training loss: 0.2527235150337219
Validation loss: 1.8407326962358208

Epoch: 5| Step: 9
Training loss: 0.5056924819946289
Validation loss: 1.8383419821339269

Epoch: 5| Step: 10
Training loss: 0.4475201964378357
Validation loss: 1.8292386685648272

Epoch: 284| Step: 0
Training loss: 0.5518084764480591
Validation loss: 1.8626728698771486

Epoch: 5| Step: 1
Training loss: 0.29519522190093994
Validation loss: 1.8310725272342723

Epoch: 5| Step: 2
Training loss: 0.2930680215358734
Validation loss: 1.832833561846005

Epoch: 5| Step: 3
Training loss: 0.5909551382064819
Validation loss: 1.807229629126928

Epoch: 5| Step: 4
Training loss: 0.3493097424507141
Validation loss: 1.7886686132800194

Epoch: 5| Step: 5
Training loss: 0.4177459180355072
Validation loss: 1.7943920884081113

Epoch: 5| Step: 6
Training loss: 0.5759075880050659
Validation loss: 1.7829955726541498

Epoch: 5| Step: 7
Training loss: 0.45779579877853394
Validation loss: 1.8178517241631784

Epoch: 5| Step: 8
Training loss: 0.6557821035385132
Validation loss: 1.8292134167045675

Epoch: 5| Step: 9
Training loss: 0.26862889528274536
Validation loss: 1.8285060057076075

Epoch: 5| Step: 10
Training loss: 0.5383197665214539
Validation loss: 1.83952296164728

Epoch: 285| Step: 0
Training loss: 0.684333860874176
Validation loss: 1.8348696898388606

Epoch: 5| Step: 1
Training loss: 0.49420905113220215
Validation loss: 1.8320160437655706

Epoch: 5| Step: 2
Training loss: 0.5632404088973999
Validation loss: 1.8388716354165027

Epoch: 5| Step: 3
Training loss: 0.4501393735408783
Validation loss: 1.8296475051551737

Epoch: 5| Step: 4
Training loss: 0.3620831370353699
Validation loss: 1.8360978390580864

Epoch: 5| Step: 5
Training loss: 0.4039316773414612
Validation loss: 1.8291879456530336

Epoch: 5| Step: 6
Training loss: 0.43492770195007324
Validation loss: 1.8063237282537645

Epoch: 5| Step: 7
Training loss: 0.31856396794319153
Validation loss: 1.7861439374185377

Epoch: 5| Step: 8
Training loss: 0.39179572463035583
Validation loss: 1.769929180863083

Epoch: 5| Step: 9
Training loss: 0.24218420684337616
Validation loss: 1.7912014966369958

Epoch: 5| Step: 10
Training loss: 0.40584680438041687
Validation loss: 1.7692073622057516

Epoch: 286| Step: 0
Training loss: 0.2434871643781662
Validation loss: 1.7832546067494217

Epoch: 5| Step: 1
Training loss: 0.704251766204834
Validation loss: 1.7704158380467405

Epoch: 5| Step: 2
Training loss: 0.45620131492614746
Validation loss: 1.799072600180103

Epoch: 5| Step: 3
Training loss: 0.38379907608032227
Validation loss: 1.8178410248089862

Epoch: 5| Step: 4
Training loss: 0.428087055683136
Validation loss: 1.7998614939310218

Epoch: 5| Step: 5
Training loss: 0.7266215085983276
Validation loss: 1.800751043263302

Epoch: 5| Step: 6
Training loss: 0.39207199215888977
Validation loss: 1.844445760532092

Epoch: 5| Step: 7
Training loss: 0.48998910188674927
Validation loss: 1.8288997732182986

Epoch: 5| Step: 8
Training loss: 0.24882599711418152
Validation loss: 1.803687846788796

Epoch: 5| Step: 9
Training loss: 0.2507546842098236
Validation loss: 1.8175837583439325

Epoch: 5| Step: 10
Training loss: 0.2709983289241791
Validation loss: 1.7881267686044016

Epoch: 287| Step: 0
Training loss: 0.34866541624069214
Validation loss: 1.781215726688344

Epoch: 5| Step: 1
Training loss: 0.36302313208580017
Validation loss: 1.7726588646570842

Epoch: 5| Step: 2
Training loss: 0.5338229537010193
Validation loss: 1.7893383990051925

Epoch: 5| Step: 3
Training loss: 0.32024967670440674
Validation loss: 1.7994072591104815

Epoch: 5| Step: 4
Training loss: 0.7484917640686035
Validation loss: 1.8394721349080403

Epoch: 5| Step: 5
Training loss: 0.32446250319480896
Validation loss: 1.8355262023146435

Epoch: 5| Step: 6
Training loss: 0.5440026521682739
Validation loss: 1.8233423258668633

Epoch: 5| Step: 7
Training loss: 0.4559890627861023
Validation loss: 1.8350822502566921

Epoch: 5| Step: 8
Training loss: 0.18941499292850494
Validation loss: 1.817834113233833

Epoch: 5| Step: 9
Training loss: 0.41524046659469604
Validation loss: 1.7523171247974518

Epoch: 5| Step: 10
Training loss: 0.486079603433609
Validation loss: 1.7512694635698873

Epoch: 288| Step: 0
Training loss: 0.3924000859260559
Validation loss: 1.755441423385374

Epoch: 5| Step: 1
Training loss: 0.36094751954078674
Validation loss: 1.7677050431569417

Epoch: 5| Step: 2
Training loss: 0.19765910506248474
Validation loss: 1.761576223117049

Epoch: 5| Step: 3
Training loss: 0.596695065498352
Validation loss: 1.7937764570277224

Epoch: 5| Step: 4
Training loss: 0.5156973004341125
Validation loss: 1.7858745141695904

Epoch: 5| Step: 5
Training loss: 0.44034236669540405
Validation loss: 1.7705786638362433

Epoch: 5| Step: 6
Training loss: 0.3711184561252594
Validation loss: 1.7857095810674852

Epoch: 5| Step: 7
Training loss: 0.45368409156799316
Validation loss: 1.7864022831762991

Epoch: 5| Step: 8
Training loss: 0.4095188081264496
Validation loss: 1.7766389475073865

Epoch: 5| Step: 9
Training loss: 0.34570521116256714
Validation loss: 1.7789695314181748

Epoch: 5| Step: 10
Training loss: 0.37199515104293823
Validation loss: 1.778441971348178

Epoch: 289| Step: 0
Training loss: 0.6739119291305542
Validation loss: 1.7604049559562438

Epoch: 5| Step: 1
Training loss: 0.2764667868614197
Validation loss: 1.7641818420861357

Epoch: 5| Step: 2
Training loss: 0.33206525444984436
Validation loss: 1.7572393994177542

Epoch: 5| Step: 3
Training loss: 0.4851159155368805
Validation loss: 1.7608941331986459

Epoch: 5| Step: 4
Training loss: 0.4884676933288574
Validation loss: 1.756435150741249

Epoch: 5| Step: 5
Training loss: 0.44130244851112366
Validation loss: 1.7810596086645638

Epoch: 5| Step: 6
Training loss: 0.3979577422142029
Validation loss: 1.7699603931878203

Epoch: 5| Step: 7
Training loss: 0.386610746383667
Validation loss: 1.752516500411495

Epoch: 5| Step: 8
Training loss: 0.37047725915908813
Validation loss: 1.7666818941793134

Epoch: 5| Step: 9
Training loss: 0.34468311071395874
Validation loss: 1.743283175653027

Epoch: 5| Step: 10
Training loss: 0.25950735807418823
Validation loss: 1.740101525860448

Epoch: 290| Step: 0
Training loss: 0.3180398941040039
Validation loss: 1.7662040802740282

Epoch: 5| Step: 1
Training loss: 0.3303880989551544
Validation loss: 1.7815085329035276

Epoch: 5| Step: 2
Training loss: 0.30208495259284973
Validation loss: 1.7805373745579873

Epoch: 5| Step: 3
Training loss: 0.4435303807258606
Validation loss: 1.7929072098065448

Epoch: 5| Step: 4
Training loss: 0.28955310583114624
Validation loss: 1.7935773736687117

Epoch: 5| Step: 5
Training loss: 0.2269393503665924
Validation loss: 1.7937574258414648

Epoch: 5| Step: 6
Training loss: 0.5976377129554749
Validation loss: 1.8108038748464277

Epoch: 5| Step: 7
Training loss: 0.6449106931686401
Validation loss: 1.8089844385782878

Epoch: 5| Step: 8
Training loss: 0.43005093932151794
Validation loss: 1.7992310805987286

Epoch: 5| Step: 9
Training loss: 0.40496987104415894
Validation loss: 1.7752281837565924

Epoch: 5| Step: 10
Training loss: 0.36272290349006653
Validation loss: 1.7789623724517

Epoch: 291| Step: 0
Training loss: 0.29163557291030884
Validation loss: 1.7820476050017982

Epoch: 5| Step: 1
Training loss: 0.45283108949661255
Validation loss: 1.769823210213774

Epoch: 5| Step: 2
Training loss: 0.3727501928806305
Validation loss: 1.782422573335709

Epoch: 5| Step: 3
Training loss: 0.48987478017807007
Validation loss: 1.7855493394277429

Epoch: 5| Step: 4
Training loss: 0.31758707761764526
Validation loss: 1.7761861624256257

Epoch: 5| Step: 5
Training loss: 0.34406688809394836
Validation loss: 1.8163434792590398

Epoch: 5| Step: 6
Training loss: 0.204971045255661
Validation loss: 1.7997165610713344

Epoch: 5| Step: 7
Training loss: 0.4970909655094147
Validation loss: 1.8165697410542478

Epoch: 5| Step: 8
Training loss: 0.35675114393234253
Validation loss: 1.8062378539833972

Epoch: 5| Step: 9
Training loss: 0.3420199155807495
Validation loss: 1.7678787631373252

Epoch: 5| Step: 10
Training loss: 0.6013126373291016
Validation loss: 1.7468343319431427

Epoch: 292| Step: 0
Training loss: 0.31562793254852295
Validation loss: 1.7641754893846409

Epoch: 5| Step: 1
Training loss: 0.3894803524017334
Validation loss: 1.7670876556827175

Epoch: 5| Step: 2
Training loss: 0.3025497794151306
Validation loss: 1.7823202302378993

Epoch: 5| Step: 3
Training loss: 0.3424674868583679
Validation loss: 1.784334787758448

Epoch: 5| Step: 4
Training loss: 0.3642204999923706
Validation loss: 1.7719203900265437

Epoch: 5| Step: 5
Training loss: 0.37027862668037415
Validation loss: 1.7622348852055048

Epoch: 5| Step: 6
Training loss: 0.2580599784851074
Validation loss: 1.7592232945144817

Epoch: 5| Step: 7
Training loss: 0.267957478761673
Validation loss: 1.7717188891544138

Epoch: 5| Step: 8
Training loss: 0.40158429741859436
Validation loss: 1.7696611086527507

Epoch: 5| Step: 9
Training loss: 0.7414520978927612
Validation loss: 1.7938547595854728

Epoch: 5| Step: 10
Training loss: 0.5710127949714661
Validation loss: 1.7924865996965798

Epoch: 293| Step: 0
Training loss: 0.24829892814159393
Validation loss: 1.797585762957091

Epoch: 5| Step: 1
Training loss: 0.4519893229007721
Validation loss: 1.7793066040162118

Epoch: 5| Step: 2
Training loss: 0.45448288321495056
Validation loss: 1.7939163446426392

Epoch: 5| Step: 3
Training loss: 0.47472184896469116
Validation loss: 1.8109003651526667

Epoch: 5| Step: 4
Training loss: 0.4027027487754822
Validation loss: 1.8056364687540198

Epoch: 5| Step: 5
Training loss: 0.48386096954345703
Validation loss: 1.8135421711911437

Epoch: 5| Step: 6
Training loss: 0.2430388480424881
Validation loss: 1.8042611140076832

Epoch: 5| Step: 7
Training loss: 0.35027700662612915
Validation loss: 1.7932921942844187

Epoch: 5| Step: 8
Training loss: 0.36546793580055237
Validation loss: 1.78650463011957

Epoch: 5| Step: 9
Training loss: 0.37259557843208313
Validation loss: 1.7701077653515724

Epoch: 5| Step: 10
Training loss: 0.4793383777141571
Validation loss: 1.7654592683238368

Epoch: 294| Step: 0
Training loss: 0.25749820470809937
Validation loss: 1.7715618943655362

Epoch: 5| Step: 1
Training loss: 0.2631177604198456
Validation loss: 1.759498542354953

Epoch: 5| Step: 2
Training loss: 0.3712267279624939
Validation loss: 1.7756339632054812

Epoch: 5| Step: 3
Training loss: 0.2491556704044342
Validation loss: 1.7585480789984427

Epoch: 5| Step: 4
Training loss: 0.5161557793617249
Validation loss: 1.7880965343085669

Epoch: 5| Step: 5
Training loss: 0.17466795444488525
Validation loss: 1.782178872375078

Epoch: 5| Step: 6
Training loss: 0.5412480235099792
Validation loss: 1.788119754483623

Epoch: 5| Step: 7
Training loss: 0.40932855010032654
Validation loss: 1.7936270429242043

Epoch: 5| Step: 8
Training loss: 0.5063589811325073
Validation loss: 1.7776891339209773

Epoch: 5| Step: 9
Training loss: 0.6053324341773987
Validation loss: 1.7818421048502768

Epoch: 5| Step: 10
Training loss: 0.44412845373153687
Validation loss: 1.8195225051654282

Epoch: 295| Step: 0
Training loss: 0.39456409215927124
Validation loss: 1.8167167043173185

Epoch: 5| Step: 1
Training loss: 0.33230382204055786
Validation loss: 1.8413837878934798

Epoch: 5| Step: 2
Training loss: 0.33964574337005615
Validation loss: 1.8713410073711025

Epoch: 5| Step: 3
Training loss: 0.44211506843566895
Validation loss: 1.8473596726694415

Epoch: 5| Step: 4
Training loss: 0.4917396008968353
Validation loss: 1.8321796130108576

Epoch: 5| Step: 5
Training loss: 0.5496442317962646
Validation loss: 1.7943624142677552

Epoch: 5| Step: 6
Training loss: 0.25300654768943787
Validation loss: 1.7702763413870206

Epoch: 5| Step: 7
Training loss: 0.4441039562225342
Validation loss: 1.7456032960645613

Epoch: 5| Step: 8
Training loss: 0.5736939907073975
Validation loss: 1.7290125252098165

Epoch: 5| Step: 9
Training loss: 0.40097516775131226
Validation loss: 1.7488281598655127

Epoch: 5| Step: 10
Training loss: 0.43454986810684204
Validation loss: 1.748147549167756

Epoch: 296| Step: 0
Training loss: 0.3412661552429199
Validation loss: 1.74995687571905

Epoch: 5| Step: 1
Training loss: 0.40925368666648865
Validation loss: 1.756884987636279

Epoch: 5| Step: 2
Training loss: 0.23060055077075958
Validation loss: 1.767047418061123

Epoch: 5| Step: 3
Training loss: 0.4008716642856598
Validation loss: 1.7810615121677358

Epoch: 5| Step: 4
Training loss: 0.42367735505104065
Validation loss: 1.8059669976593347

Epoch: 5| Step: 5
Training loss: 0.4660695195198059
Validation loss: 1.8173443014903734

Epoch: 5| Step: 6
Training loss: 0.6428840756416321
Validation loss: 1.7801827288443042

Epoch: 5| Step: 7
Training loss: 0.31579262018203735
Validation loss: 1.7631425255088395

Epoch: 5| Step: 8
Training loss: 0.43184977769851685
Validation loss: 1.7798294226328533

Epoch: 5| Step: 9
Training loss: 0.3334847390651703
Validation loss: 1.7379505570216844

Epoch: 5| Step: 10
Training loss: 0.35517776012420654
Validation loss: 1.736615273260301

Epoch: 297| Step: 0
Training loss: 0.513633668422699
Validation loss: 1.7450948287081975

Epoch: 5| Step: 1
Training loss: 0.25517138838768005
Validation loss: 1.72666496487074

Epoch: 5| Step: 2
Training loss: 0.2670609652996063
Validation loss: 1.7432358380286925

Epoch: 5| Step: 3
Training loss: 0.2665199339389801
Validation loss: 1.769169440833471

Epoch: 5| Step: 4
Training loss: 0.35813969373703003
Validation loss: 1.7423655781694638

Epoch: 5| Step: 5
Training loss: 0.30581897497177124
Validation loss: 1.7609804240606164

Epoch: 5| Step: 6
Training loss: 0.4528657793998718
Validation loss: 1.7659027909719816

Epoch: 5| Step: 7
Training loss: 0.20251870155334473
Validation loss: 1.777318423794162

Epoch: 5| Step: 8
Training loss: 0.6057401895523071
Validation loss: 1.7669245658382293

Epoch: 5| Step: 9
Training loss: 0.46166592836380005
Validation loss: 1.774558126285512

Epoch: 5| Step: 10
Training loss: 0.7492754459381104
Validation loss: 1.7650157661848171

Epoch: 298| Step: 0
Training loss: 0.4417511820793152
Validation loss: 1.7577766987585253

Epoch: 5| Step: 1
Training loss: 0.1968086063861847
Validation loss: 1.7071017949811873

Epoch: 5| Step: 2
Training loss: 0.517910897731781
Validation loss: 1.739434496048958

Epoch: 5| Step: 3
Training loss: 0.20735231041908264
Validation loss: 1.7444458398767697

Epoch: 5| Step: 4
Training loss: 0.44776004552841187
Validation loss: 1.7395626678261706

Epoch: 5| Step: 5
Training loss: 0.2622709274291992
Validation loss: 1.795714347593246

Epoch: 5| Step: 6
Training loss: 0.3824346363544464
Validation loss: 1.8032614813056043

Epoch: 5| Step: 7
Training loss: 0.8594135046005249
Validation loss: 1.7633953120118828

Epoch: 5| Step: 8
Training loss: 0.23604726791381836
Validation loss: 1.754843165797572

Epoch: 5| Step: 9
Training loss: 0.2831018567085266
Validation loss: 1.7390826837990874

Epoch: 5| Step: 10
Training loss: 0.3567560315132141
Validation loss: 1.7107753804934922

Epoch: 299| Step: 0
Training loss: 0.3725574016571045
Validation loss: 1.730959721790847

Epoch: 5| Step: 1
Training loss: 0.25843262672424316
Validation loss: 1.7263474131143222

Epoch: 5| Step: 2
Training loss: 0.37197840213775635
Validation loss: 1.7211676771922777

Epoch: 5| Step: 3
Training loss: 0.35067421197891235
Validation loss: 1.731060435695033

Epoch: 5| Step: 4
Training loss: 0.4276658892631531
Validation loss: 1.7270251820164342

Epoch: 5| Step: 5
Training loss: 0.4377902150154114
Validation loss: 1.7242261850705711

Epoch: 5| Step: 6
Training loss: 0.5811408162117004
Validation loss: 1.729245719089303

Epoch: 5| Step: 7
Training loss: 0.3484504520893097
Validation loss: 1.7407449112143567

Epoch: 5| Step: 8
Training loss: 0.18675453960895538
Validation loss: 1.7327370951252599

Epoch: 5| Step: 9
Training loss: 0.2769545614719391
Validation loss: 1.7530209351611394

Epoch: 5| Step: 10
Training loss: 0.32750001549720764
Validation loss: 1.7416906831085042

Epoch: 300| Step: 0
Training loss: 0.772545337677002
Validation loss: 1.7567243806777462

Epoch: 5| Step: 1
Training loss: 0.1814723014831543
Validation loss: 1.7660482493779992

Epoch: 5| Step: 2
Training loss: 0.3903624415397644
Validation loss: 1.7467637561982678

Epoch: 5| Step: 3
Training loss: 0.35429543256759644
Validation loss: 1.7610196221259333

Epoch: 5| Step: 4
Training loss: 0.3145371973514557
Validation loss: 1.7554055875347507

Epoch: 5| Step: 5
Training loss: 0.23483538627624512
Validation loss: 1.764353052262337

Epoch: 5| Step: 6
Training loss: 0.36202865839004517
Validation loss: 1.7654538898057834

Epoch: 5| Step: 7
Training loss: 0.1517372578382492
Validation loss: 1.771155672688638

Epoch: 5| Step: 8
Training loss: 0.40685319900512695
Validation loss: 1.7847839350341468

Epoch: 5| Step: 9
Training loss: 0.49786585569381714
Validation loss: 1.7777487334384714

Epoch: 5| Step: 10
Training loss: 0.25228995084762573
Validation loss: 1.7835683540631366

Testing loss: 2.045474304093255
