Epoch: 1| Step: 0
Training loss: 6.462498984714923
Validation loss: 5.838164059398776

Epoch: 6| Step: 1
Training loss: 6.285906986899283
Validation loss: 5.819152497084214

Epoch: 6| Step: 2
Training loss: 5.936214588964944
Validation loss: 5.803608902687735

Epoch: 6| Step: 3
Training loss: 5.104744495719364
Validation loss: 5.788342553389602

Epoch: 6| Step: 4
Training loss: 5.216919172389497
Validation loss: 5.770293326645196

Epoch: 6| Step: 5
Training loss: 5.7898933751331
Validation loss: 5.750019854582205

Epoch: 6| Step: 6
Training loss: 6.678636327651138
Validation loss: 5.726135346312628

Epoch: 6| Step: 7
Training loss: 5.0696180247138845
Validation loss: 5.700272278830197

Epoch: 6| Step: 8
Training loss: 5.488576296006103
Validation loss: 5.671148855910944

Epoch: 6| Step: 9
Training loss: 5.610614267810451
Validation loss: 5.639609164849818

Epoch: 6| Step: 10
Training loss: 5.276375049879622
Validation loss: 5.605694202578318

Epoch: 6| Step: 11
Training loss: 5.047317154828472
Validation loss: 5.56949051507961

Epoch: 6| Step: 12
Training loss: 6.096178715226327
Validation loss: 5.531443098500652

Epoch: 6| Step: 13
Training loss: 6.045383476418442
Validation loss: 5.493004809332811

Epoch: 2| Step: 0
Training loss: 5.708608504668218
Validation loss: 5.453127959894934

Epoch: 6| Step: 1
Training loss: 4.933612113670792
Validation loss: 5.412556201645203

Epoch: 6| Step: 2
Training loss: 5.0995267162249664
Validation loss: 5.37096232198072

Epoch: 6| Step: 3
Training loss: 5.016111736507172
Validation loss: 5.328635282051379

Epoch: 6| Step: 4
Training loss: 5.498174711269154
Validation loss: 5.28658204971743

Epoch: 6| Step: 5
Training loss: 6.24911218059448
Validation loss: 5.246487322786669

Epoch: 6| Step: 6
Training loss: 4.901150330958069
Validation loss: 5.208336484190285

Epoch: 6| Step: 7
Training loss: 5.6757328585342455
Validation loss: 5.172979566229607

Epoch: 6| Step: 8
Training loss: 5.868577734030736
Validation loss: 5.137577361713612

Epoch: 6| Step: 9
Training loss: 5.018531218780259
Validation loss: 5.10259365665892

Epoch: 6| Step: 10
Training loss: 6.175965009026898
Validation loss: 5.06976231745147

Epoch: 6| Step: 11
Training loss: 4.590447101301108
Validation loss: 5.034433914470985

Epoch: 6| Step: 12
Training loss: 3.8939041964398977
Validation loss: 4.997840529867632

Epoch: 6| Step: 13
Training loss: 3.9583350064458154
Validation loss: 4.961394020516606

Epoch: 3| Step: 0
Training loss: 5.163238967581545
Validation loss: 4.9241112934496805

Epoch: 6| Step: 1
Training loss: 6.898293170736772
Validation loss: 4.8813743198697495

Epoch: 6| Step: 2
Training loss: 5.09670579022464
Validation loss: 4.838384271296716

Epoch: 6| Step: 3
Training loss: 3.3378269106887153
Validation loss: 4.809738259555077

Epoch: 6| Step: 4
Training loss: 4.819751774897838
Validation loss: 4.788614487485516

Epoch: 6| Step: 5
Training loss: 4.119443213977888
Validation loss: 4.7710616214806025

Epoch: 6| Step: 6
Training loss: 5.023050581060535
Validation loss: 4.754267310136955

Epoch: 6| Step: 7
Training loss: 4.027554733122307
Validation loss: 4.736600160371658

Epoch: 6| Step: 8
Training loss: 4.188839143164794
Validation loss: 4.718473486515706

Epoch: 6| Step: 9
Training loss: 4.957664166770327
Validation loss: 4.696956897279465

Epoch: 6| Step: 10
Training loss: 4.870050313952086
Validation loss: 4.6759081971909

Epoch: 6| Step: 11
Training loss: 4.787184280064726
Validation loss: 4.653801574291684

Epoch: 6| Step: 12
Training loss: 5.2879931497226496
Validation loss: 4.627883391469464

Epoch: 6| Step: 13
Training loss: 3.9948425422356584
Validation loss: 4.603604942217309

Epoch: 4| Step: 0
Training loss: 4.345639483382308
Validation loss: 4.580172996134017

Epoch: 6| Step: 1
Training loss: 4.709322372577853
Validation loss: 4.543824067952031

Epoch: 6| Step: 2
Training loss: 4.634627760144029
Validation loss: 4.520474528490979

Epoch: 6| Step: 3
Training loss: 4.406525731759455
Validation loss: 4.506926329973487

Epoch: 6| Step: 4
Training loss: 5.166234746947848
Validation loss: 4.493311912770622

Epoch: 6| Step: 5
Training loss: 4.314195824717936
Validation loss: 4.483753960697616

Epoch: 6| Step: 6
Training loss: 4.926133992499651
Validation loss: 4.4772325732353995

Epoch: 6| Step: 7
Training loss: 3.8018660531165276
Validation loss: 4.46161089671861

Epoch: 6| Step: 8
Training loss: 4.901605047370226
Validation loss: 4.440105416893132

Epoch: 6| Step: 9
Training loss: 3.7610919941263403
Validation loss: 4.4257949365343885

Epoch: 6| Step: 10
Training loss: 4.573534020857547
Validation loss: 4.413592235340902

Epoch: 6| Step: 11
Training loss: 4.743260069062592
Validation loss: 4.402764679177476

Epoch: 6| Step: 12
Training loss: 4.711690307996874
Validation loss: 4.389248934743565

Epoch: 6| Step: 13
Training loss: 5.025428199553466
Validation loss: 4.3791456067926395

Epoch: 5| Step: 0
Training loss: 4.790510198383407
Validation loss: 4.371347356394396

Epoch: 6| Step: 1
Training loss: 3.93529291209118
Validation loss: 4.354503588921202

Epoch: 6| Step: 2
Training loss: 4.639370424375522
Validation loss: 4.34807310457326

Epoch: 6| Step: 3
Training loss: 4.583881599694688
Validation loss: 4.339474904127494

Epoch: 6| Step: 4
Training loss: 4.489100501818787
Validation loss: 4.3324002964486565

Epoch: 6| Step: 5
Training loss: 3.4423775487548407
Validation loss: 4.3147529826849285

Epoch: 6| Step: 6
Training loss: 4.658322276384928
Validation loss: 4.301925123927215

Epoch: 6| Step: 7
Training loss: 4.466152903678198
Validation loss: 4.304532964876915

Epoch: 6| Step: 8
Training loss: 4.903501092844714
Validation loss: 4.292210803773924

Epoch: 6| Step: 9
Training loss: 4.084243335659364
Validation loss: 4.279489505996249

Epoch: 6| Step: 10
Training loss: 3.9264050343973205
Validation loss: 4.2733482169593024

Epoch: 6| Step: 11
Training loss: 4.50223104483805
Validation loss: 4.260414900775472

Epoch: 6| Step: 12
Training loss: 4.572611017229935
Validation loss: 4.2605577093460765

Epoch: 6| Step: 13
Training loss: 5.027831438502988
Validation loss: 4.241616840498213

Epoch: 6| Step: 0
Training loss: 4.049312137540331
Validation loss: 4.225370542040824

Epoch: 6| Step: 1
Training loss: 3.970353891276275
Validation loss: 4.222756165480848

Epoch: 6| Step: 2
Training loss: 4.612532229427225
Validation loss: 4.204153017917301

Epoch: 6| Step: 3
Training loss: 4.226576038275453
Validation loss: 4.207287516604822

Epoch: 6| Step: 4
Training loss: 4.4155867113962755
Validation loss: 4.207239283936972

Epoch: 6| Step: 5
Training loss: 4.354875984396977
Validation loss: 4.1953725264569846

Epoch: 6| Step: 6
Training loss: 3.9956937498362497
Validation loss: 4.186299295916555

Epoch: 6| Step: 7
Training loss: 3.3568055728429713
Validation loss: 4.179488151763808

Epoch: 6| Step: 8
Training loss: 4.643524805207478
Validation loss: 4.173000858349957

Epoch: 6| Step: 9
Training loss: 4.799328900153197
Validation loss: 4.163213889535568

Epoch: 6| Step: 10
Training loss: 4.110880180837926
Validation loss: 4.153908568955364

Epoch: 6| Step: 11
Training loss: 5.1086531662916705
Validation loss: 4.146205806010726

Epoch: 6| Step: 12
Training loss: 4.519228226930992
Validation loss: 4.134620825290118

Epoch: 6| Step: 13
Training loss: 3.662832610875158
Validation loss: 4.130199850357374

Epoch: 7| Step: 0
Training loss: 4.172602329359294
Validation loss: 4.12963517271002

Epoch: 6| Step: 1
Training loss: 4.824109429113069
Validation loss: 4.111568770413626

Epoch: 6| Step: 2
Training loss: 4.097452367723354
Validation loss: 4.104316891488744

Epoch: 6| Step: 3
Training loss: 4.176324307677792
Validation loss: 4.098623497740305

Epoch: 6| Step: 4
Training loss: 4.294563920394878
Validation loss: 4.091635846907726

Epoch: 6| Step: 5
Training loss: 3.4261200236036236
Validation loss: 4.083636836177635

Epoch: 6| Step: 6
Training loss: 4.168990491710278
Validation loss: 4.0771753367376125

Epoch: 6| Step: 7
Training loss: 4.368515877187386
Validation loss: 4.074448784235343

Epoch: 6| Step: 8
Training loss: 4.434909978079812
Validation loss: 4.057593533751155

Epoch: 6| Step: 9
Training loss: 3.7366576301222696
Validation loss: 4.050200722238859

Epoch: 6| Step: 10
Training loss: 4.605451769874338
Validation loss: 4.0459318669090605

Epoch: 6| Step: 11
Training loss: 4.201626308377972
Validation loss: 4.033206142988632

Epoch: 6| Step: 12
Training loss: 4.166605961675302
Validation loss: 4.02798423242685

Epoch: 6| Step: 13
Training loss: 4.232023930732549
Validation loss: 4.02586262953864

Epoch: 8| Step: 0
Training loss: 4.454462860983669
Validation loss: 4.016598880525854

Epoch: 6| Step: 1
Training loss: 4.420264068586305
Validation loss: 4.006596962666756

Epoch: 6| Step: 2
Training loss: 3.8765971676169277
Validation loss: 3.996635603882837

Epoch: 6| Step: 3
Training loss: 4.349693568168094
Validation loss: 3.993457704576361

Epoch: 6| Step: 4
Training loss: 4.7195734985461035
Validation loss: 3.9877085224336124

Epoch: 6| Step: 5
Training loss: 4.142087512570442
Validation loss: 3.980222128563888

Epoch: 6| Step: 6
Training loss: 4.148474281852004
Validation loss: 3.9734932238844234

Epoch: 6| Step: 7
Training loss: 3.8378087469398965
Validation loss: 3.9674538351367024

Epoch: 6| Step: 8
Training loss: 4.350184881731927
Validation loss: 3.9625176886862485

Epoch: 6| Step: 9
Training loss: 4.211624117838739
Validation loss: 3.9547588527919495

Epoch: 6| Step: 10
Training loss: 3.4253143723159685
Validation loss: 3.952824808940994

Epoch: 6| Step: 11
Training loss: 3.708800397169867
Validation loss: 3.947543051735058

Epoch: 6| Step: 12
Training loss: 4.09860523969907
Validation loss: 3.937845990016096

Epoch: 6| Step: 13
Training loss: 3.740399469063617
Validation loss: 3.934155738252497

Epoch: 9| Step: 0
Training loss: 4.261452447139181
Validation loss: 3.9265792695959423

Epoch: 6| Step: 1
Training loss: 4.209718432219007
Validation loss: 3.9246169629223053

Epoch: 6| Step: 2
Training loss: 3.0468271105010505
Validation loss: 3.9171332764495963

Epoch: 6| Step: 3
Training loss: 3.8225156208165743
Validation loss: 3.9109455158788533

Epoch: 6| Step: 4
Training loss: 4.118043987793281
Validation loss: 3.907485564368854

Epoch: 6| Step: 5
Training loss: 5.308678363184675
Validation loss: 3.9039029880027973

Epoch: 6| Step: 6
Training loss: 3.9623349224566726
Validation loss: 3.8992537944416137

Epoch: 6| Step: 7
Training loss: 3.4493016959873786
Validation loss: 3.8989268579468126

Epoch: 6| Step: 8
Training loss: 3.1068733925317393
Validation loss: 3.8966448661769606

Epoch: 6| Step: 9
Training loss: 4.499123593923968
Validation loss: 3.889432544229468

Epoch: 6| Step: 10
Training loss: 4.547787289680305
Validation loss: 3.8819040274870407

Epoch: 6| Step: 11
Training loss: 3.1550109244035065
Validation loss: 3.881604868287556

Epoch: 6| Step: 12
Training loss: 5.083421779342566
Validation loss: 3.8784181521779506

Epoch: 6| Step: 13
Training loss: 2.9948528958018414
Validation loss: 3.871601052331713

Epoch: 10| Step: 0
Training loss: 4.462105459515265
Validation loss: 3.8779867096171383

Epoch: 6| Step: 1
Training loss: 3.4745558530342397
Validation loss: 3.87764701449625

Epoch: 6| Step: 2
Training loss: 5.233690268296634
Validation loss: 3.8746805578715273

Epoch: 6| Step: 3
Training loss: 4.176866381458077
Validation loss: 3.8641516154648583

Epoch: 6| Step: 4
Training loss: 3.7253377569286577
Validation loss: 3.8566489720307993

Epoch: 6| Step: 5
Training loss: 4.114641766998378
Validation loss: 3.8540007569118457

Epoch: 6| Step: 6
Training loss: 3.6000086148476838
Validation loss: 3.8523341928007397

Epoch: 6| Step: 7
Training loss: 4.61624471524161
Validation loss: 3.8530686525815407

Epoch: 6| Step: 8
Training loss: 3.747868377108693
Validation loss: 3.848776576564794

Epoch: 6| Step: 9
Training loss: 2.9071693196938395
Validation loss: 3.842737580272925

Epoch: 6| Step: 10
Training loss: 3.4507312331440705
Validation loss: 3.83848621538011

Epoch: 6| Step: 11
Training loss: 5.014022618720913
Validation loss: 3.8369085729617445

Epoch: 6| Step: 12
Training loss: 3.788883794915985
Validation loss: 3.8330687493550952

Epoch: 6| Step: 13
Training loss: 2.634237475442631
Validation loss: 3.831750704000988

Epoch: 11| Step: 0
Training loss: 4.196471439594813
Validation loss: 3.8296016641841737

Epoch: 6| Step: 1
Training loss: 4.804017753752492
Validation loss: 3.826472436221725

Epoch: 6| Step: 2
Training loss: 3.697372668732388
Validation loss: 3.8229247174118575

Epoch: 6| Step: 3
Training loss: 4.499693966101941
Validation loss: 3.818195424031016

Epoch: 6| Step: 4
Training loss: 3.6636278102025392
Validation loss: 3.817477387220158

Epoch: 6| Step: 5
Training loss: 4.42737251085263
Validation loss: 3.8126755191040855

Epoch: 6| Step: 6
Training loss: 4.265907585648906
Validation loss: 3.808829838177377

Epoch: 6| Step: 7
Training loss: 4.548006421664224
Validation loss: 3.8077498076818346

Epoch: 6| Step: 8
Training loss: 3.898386494335356
Validation loss: 3.8054569980030797

Epoch: 6| Step: 9
Training loss: 3.735879379579797
Validation loss: 3.801945820590435

Epoch: 6| Step: 10
Training loss: 3.555631474505635
Validation loss: 3.801181154287204

Epoch: 6| Step: 11
Training loss: 3.63549941587227
Validation loss: 3.80160348077736

Epoch: 6| Step: 12
Training loss: 3.0953540689449066
Validation loss: 3.7962738564570033

Epoch: 6| Step: 13
Training loss: 2.788293556192635
Validation loss: 3.793052859883059

Epoch: 12| Step: 0
Training loss: 3.7881338967623366
Validation loss: 3.7906197219586133

Epoch: 6| Step: 1
Training loss: 3.2349471171329793
Validation loss: 3.792030080863847

Epoch: 6| Step: 2
Training loss: 3.624472086382824
Validation loss: 3.791538937290242

Epoch: 6| Step: 3
Training loss: 4.011103002434939
Validation loss: 3.786898919763008

Epoch: 6| Step: 4
Training loss: 4.513902593086502
Validation loss: 3.785610257635388

Epoch: 6| Step: 5
Training loss: 4.129874383895691
Validation loss: 3.782644452876265

Epoch: 6| Step: 6
Training loss: 3.838031391542203
Validation loss: 3.782200595412025

Epoch: 6| Step: 7
Training loss: 4.4660657810640245
Validation loss: 3.779326485693821

Epoch: 6| Step: 8
Training loss: 4.132964796638595
Validation loss: 3.777469709813546

Epoch: 6| Step: 9
Training loss: 3.5568815397967604
Validation loss: 3.775081317832283

Epoch: 6| Step: 10
Training loss: 4.620979830062424
Validation loss: 3.773761500033548

Epoch: 6| Step: 11
Training loss: 4.269000495944572
Validation loss: 3.7741055895969287

Epoch: 6| Step: 12
Training loss: 3.0299283321956954
Validation loss: 3.7717386039610594

Epoch: 6| Step: 13
Training loss: 3.7724801501743483
Validation loss: 3.7697514230759945

Epoch: 13| Step: 0
Training loss: 3.5811557511049243
Validation loss: 3.7679350710612414

Epoch: 6| Step: 1
Training loss: 3.192934676460596
Validation loss: 3.7669102014144245

Epoch: 6| Step: 2
Training loss: 4.944396791454713
Validation loss: 3.7658959517065766

Epoch: 6| Step: 3
Training loss: 4.418140141597029
Validation loss: 3.7639981691033606

Epoch: 6| Step: 4
Training loss: 3.4012848950621484
Validation loss: 3.7618674343423617

Epoch: 6| Step: 5
Training loss: 4.001507951691608
Validation loss: 3.7608941496866013

Epoch: 6| Step: 6
Training loss: 4.437507736844047
Validation loss: 3.7589173313812405

Epoch: 6| Step: 7
Training loss: 3.7465007986457084
Validation loss: 3.7561328603158035

Epoch: 6| Step: 8
Training loss: 4.614372621752909
Validation loss: 3.7521840083237756

Epoch: 6| Step: 9
Training loss: 4.100950010071742
Validation loss: 3.747474552885142

Epoch: 6| Step: 10
Training loss: 4.1505459529757855
Validation loss: 3.7465658809407287

Epoch: 6| Step: 11
Training loss: 2.571154239189882
Validation loss: 3.7450274077314964

Epoch: 6| Step: 12
Training loss: 3.102389823438884
Validation loss: 3.741037283162735

Epoch: 6| Step: 13
Training loss: 4.324749122355362
Validation loss: 3.7427871740503273

Epoch: 14| Step: 0
Training loss: 3.314748181060699
Validation loss: 3.7400696054079035

Epoch: 6| Step: 1
Training loss: 3.8531781690259668
Validation loss: 3.7387962275054134

Epoch: 6| Step: 2
Training loss: 3.7116742175784396
Validation loss: 3.7377687420230057

Epoch: 6| Step: 3
Training loss: 3.5349388097838434
Validation loss: 3.7346980958756406

Epoch: 6| Step: 4
Training loss: 3.0965605020819793
Validation loss: 3.733988040896067

Epoch: 6| Step: 5
Training loss: 3.803388620610527
Validation loss: 3.7329312972913664

Epoch: 6| Step: 6
Training loss: 3.7971039377272526
Validation loss: 3.731486895863957

Epoch: 6| Step: 7
Training loss: 3.307810504896511
Validation loss: 3.7297068869308494

Epoch: 6| Step: 8
Training loss: 3.316137080507793
Validation loss: 3.7266825664812937

Epoch: 6| Step: 9
Training loss: 3.900497595514545
Validation loss: 3.7277596759989846

Epoch: 6| Step: 10
Training loss: 4.219739331696428
Validation loss: 3.727676103792281

Epoch: 6| Step: 11
Training loss: 4.946031370539352
Validation loss: 3.727708600343999

Epoch: 6| Step: 12
Training loss: 4.720401298144824
Validation loss: 3.7411249089808565

Epoch: 6| Step: 13
Training loss: 5.310713882878721
Validation loss: 3.726378494294327

Epoch: 15| Step: 0
Training loss: 3.6778776411371097
Validation loss: 3.7262340808626373

Epoch: 6| Step: 1
Training loss: 4.10609682398378
Validation loss: 3.725251369414651

Epoch: 6| Step: 2
Training loss: 3.673102770133302
Validation loss: 3.7255465645886097

Epoch: 6| Step: 3
Training loss: 4.022464138176986
Validation loss: 3.7251577221837113

Epoch: 6| Step: 4
Training loss: 3.588445978683691
Validation loss: 3.7237914538136225

Epoch: 6| Step: 5
Training loss: 4.000842959273161
Validation loss: 3.726126703507848

Epoch: 6| Step: 6
Training loss: 4.049612172713537
Validation loss: 3.7238691871598077

Epoch: 6| Step: 7
Training loss: 3.8931349658945678
Validation loss: 3.7211779152525564

Epoch: 6| Step: 8
Training loss: 2.7674798295165597
Validation loss: 3.7185147573757216

Epoch: 6| Step: 9
Training loss: 4.429608056703295
Validation loss: 3.7150343403137005

Epoch: 6| Step: 10
Training loss: 3.7269663082121935
Validation loss: 3.7153327471421145

Epoch: 6| Step: 11
Training loss: 3.248697460024183
Validation loss: 3.71302396208377

Epoch: 6| Step: 12
Training loss: 4.891190078801159
Validation loss: 3.7086290354746616

Epoch: 6| Step: 13
Training loss: 4.366515297243839
Validation loss: 3.7057454083592307

Epoch: 16| Step: 0
Training loss: 3.7887094864146986
Validation loss: 3.705252624678925

Epoch: 6| Step: 1
Training loss: 4.4911384219996515
Validation loss: 3.7058821265891755

Epoch: 6| Step: 2
Training loss: 3.3908944440390996
Validation loss: 3.705701564481102

Epoch: 6| Step: 3
Training loss: 3.645598064279283
Validation loss: 3.7042615067339986

Epoch: 6| Step: 4
Training loss: 2.853114210194035
Validation loss: 3.7011513529172944

Epoch: 6| Step: 5
Training loss: 3.473820734611362
Validation loss: 3.6973307363592878

Epoch: 6| Step: 6
Training loss: 3.8515776040049943
Validation loss: 3.694936454686449

Epoch: 6| Step: 7
Training loss: 3.4607266949590443
Validation loss: 3.693571006622171

Epoch: 6| Step: 8
Training loss: 5.208498634258368
Validation loss: 3.6921854801309673

Epoch: 6| Step: 9
Training loss: 4.188501949860401
Validation loss: 3.6913570854149733

Epoch: 6| Step: 10
Training loss: 3.8280345672513576
Validation loss: 3.6900521399903345

Epoch: 6| Step: 11
Training loss: 3.7624090240733676
Validation loss: 3.689649283345684

Epoch: 6| Step: 12
Training loss: 4.042081254492532
Validation loss: 3.687650314223507

Epoch: 6| Step: 13
Training loss: 3.893654620378573
Validation loss: 3.6860057166241185

Epoch: 17| Step: 0
Training loss: 3.290286454829425
Validation loss: 3.6853963094267885

Epoch: 6| Step: 1
Training loss: 4.567494624092434
Validation loss: 3.68393520784428

Epoch: 6| Step: 2
Training loss: 3.5035284512740463
Validation loss: 3.6827375367124797

Epoch: 6| Step: 3
Training loss: 3.9215811205178768
Validation loss: 3.6809729877210717

Epoch: 6| Step: 4
Training loss: 4.863628525188809
Validation loss: 3.680585071189718

Epoch: 6| Step: 5
Training loss: 3.374721374313448
Validation loss: 3.679343196730243

Epoch: 6| Step: 6
Training loss: 3.6102588446641986
Validation loss: 3.6780365343427794

Epoch: 6| Step: 7
Training loss: 4.449836453636395
Validation loss: 3.6769809931179878

Epoch: 6| Step: 8
Training loss: 3.8008294254398027
Validation loss: 3.6747934012833388

Epoch: 6| Step: 9
Training loss: 4.001228620668096
Validation loss: 3.6733780995383234

Epoch: 6| Step: 10
Training loss: 2.381942740372721
Validation loss: 3.6719976323965255

Epoch: 6| Step: 11
Training loss: 3.0590003122190508
Validation loss: 3.672321744302098

Epoch: 6| Step: 12
Training loss: 4.00373237046223
Validation loss: 3.6703346472318334

Epoch: 6| Step: 13
Training loss: 5.06942294506699
Validation loss: 3.6707464399886787

Epoch: 18| Step: 0
Training loss: 3.5055552401158803
Validation loss: 3.6673071256240846

Epoch: 6| Step: 1
Training loss: 3.2945025979438665
Validation loss: 3.6675011509333335

Epoch: 6| Step: 2
Training loss: 4.5252801966457605
Validation loss: 3.6703793773618307

Epoch: 6| Step: 3
Training loss: 4.203398174498688
Validation loss: 3.6672694241246684

Epoch: 6| Step: 4
Training loss: 4.00629573325776
Validation loss: 3.665113709402964

Epoch: 6| Step: 5
Training loss: 4.182739968538468
Validation loss: 3.6625615452253606

Epoch: 6| Step: 6
Training loss: 4.169423729759456
Validation loss: 3.662120116471702

Epoch: 6| Step: 7
Training loss: 2.944830979061321
Validation loss: 3.661481535002557

Epoch: 6| Step: 8
Training loss: 4.297247853141371
Validation loss: 3.6610585395885584

Epoch: 6| Step: 9
Training loss: 3.8592403249370357
Validation loss: 3.6583936738772014

Epoch: 6| Step: 10
Training loss: 4.035752258893751
Validation loss: 3.6582431876756725

Epoch: 6| Step: 11
Training loss: 3.138775636848566
Validation loss: 3.656287599168161

Epoch: 6| Step: 12
Training loss: 4.181682132121183
Validation loss: 3.654593185665986

Epoch: 6| Step: 13
Training loss: 2.6140430292383705
Validation loss: 3.6539683718810423

Epoch: 19| Step: 0
Training loss: 4.2043058303671
Validation loss: 3.6527898974288866

Epoch: 6| Step: 1
Training loss: 3.427677756165224
Validation loss: 3.6518137757614304

Epoch: 6| Step: 2
Training loss: 3.6550901480645477
Validation loss: 3.6506280159015176

Epoch: 6| Step: 3
Training loss: 3.3776689502127715
Validation loss: 3.650262045686341

Epoch: 6| Step: 4
Training loss: 4.067102964374906
Validation loss: 3.6485658007226136

Epoch: 6| Step: 5
Training loss: 4.931146324237897
Validation loss: 3.647549680453471

Epoch: 6| Step: 6
Training loss: 3.7500611618140565
Validation loss: 3.646591548334584

Epoch: 6| Step: 7
Training loss: 4.566790509923073
Validation loss: 3.6453804393451406

Epoch: 6| Step: 8
Training loss: 3.506977619144325
Validation loss: 3.643938338667037

Epoch: 6| Step: 9
Training loss: 2.80497327958434
Validation loss: 3.642796310043721

Epoch: 6| Step: 10
Training loss: 3.1205378909934707
Validation loss: 3.642172318985518

Epoch: 6| Step: 11
Training loss: 3.3886676535456415
Validation loss: 3.6407281391931425

Epoch: 6| Step: 12
Training loss: 4.437919489415198
Validation loss: 3.6398891068057013

Epoch: 6| Step: 13
Training loss: 4.043798742929157
Validation loss: 3.6393878610531534

Epoch: 20| Step: 0
Training loss: 3.474405987143842
Validation loss: 3.6380220745095504

Epoch: 6| Step: 1
Training loss: 3.7916349193096273
Validation loss: 3.6367499431219907

Epoch: 6| Step: 2
Training loss: 3.928662873727247
Validation loss: 3.6358463620946395

Epoch: 6| Step: 3
Training loss: 3.1770497471435974
Validation loss: 3.6351835147471525

Epoch: 6| Step: 4
Training loss: 3.186573267835557
Validation loss: 3.633804057180404

Epoch: 6| Step: 5
Training loss: 5.1927529820621015
Validation loss: 3.6331236086064953

Epoch: 6| Step: 6
Training loss: 3.1186591859488315
Validation loss: 3.6320119077286632

Epoch: 6| Step: 7
Training loss: 4.086669389517429
Validation loss: 3.631198495143039

Epoch: 6| Step: 8
Training loss: 4.052138039710776
Validation loss: 3.6301101885751668

Epoch: 6| Step: 9
Training loss: 3.8331281081839674
Validation loss: 3.628897259706812

Epoch: 6| Step: 10
Training loss: 3.6267991698359525
Validation loss: 3.628186680579293

Epoch: 6| Step: 11
Training loss: 4.088182230252696
Validation loss: 3.627059301384243

Epoch: 6| Step: 12
Training loss: 4.073263376345931
Validation loss: 3.6260428380185554

Epoch: 6| Step: 13
Training loss: 3.214113024962166
Validation loss: 3.6248818259094655

Epoch: 21| Step: 0
Training loss: 3.5812502876002013
Validation loss: 3.6239622934186193

Epoch: 6| Step: 1
Training loss: 4.023993059338145
Validation loss: 3.6229608194138962

Epoch: 6| Step: 2
Training loss: 2.5603098930607286
Validation loss: 3.6216767579795026

Epoch: 6| Step: 3
Training loss: 4.755169715459917
Validation loss: 3.6211281248119205

Epoch: 6| Step: 4
Training loss: 3.1380560697526776
Validation loss: 3.619680465485717

Epoch: 6| Step: 5
Training loss: 3.3268142053100638
Validation loss: 3.618460809809424

Epoch: 6| Step: 6
Training loss: 4.403359838305358
Validation loss: 3.6168804982371587

Epoch: 6| Step: 7
Training loss: 4.057637752843492
Validation loss: 3.615733077141624

Epoch: 6| Step: 8
Training loss: 3.3571909347384516
Validation loss: 3.6144007206718523

Epoch: 6| Step: 9
Training loss: 3.2023391876225427
Validation loss: 3.6112779312684404

Epoch: 6| Step: 10
Training loss: 4.65118193833158
Validation loss: 3.6046353050349125

Epoch: 6| Step: 11
Training loss: 4.52478702950244
Validation loss: 3.593005491575714

Epoch: 6| Step: 12
Training loss: 3.4524938774745166
Validation loss: 3.5839330715537674

Epoch: 6| Step: 13
Training loss: 3.389476669562111
Validation loss: 3.586235214008077

Epoch: 22| Step: 0
Training loss: 4.718346180594599
Validation loss: 3.599048518216782

Epoch: 6| Step: 1
Training loss: 3.482675180513375
Validation loss: 3.583657531686471

Epoch: 6| Step: 2
Training loss: 3.2139753464309306
Validation loss: 3.5785869581934473

Epoch: 6| Step: 3
Training loss: 3.775198641975936
Validation loss: 3.5773948364710666

Epoch: 6| Step: 4
Training loss: 3.999208848914536
Validation loss: 3.574757913105547

Epoch: 6| Step: 5
Training loss: 3.628193599502539
Validation loss: 3.5749623440154004

Epoch: 6| Step: 6
Training loss: 3.358289250415027
Validation loss: 3.574976522682824

Epoch: 6| Step: 7
Training loss: 3.691062757869573
Validation loss: 3.5765451469551084

Epoch: 6| Step: 8
Training loss: 3.995522735160577
Validation loss: 3.576152731724689

Epoch: 6| Step: 9
Training loss: 3.4427020851497923
Validation loss: 3.5694093121668815

Epoch: 6| Step: 10
Training loss: 3.1078479793588967
Validation loss: 3.5672561453557194

Epoch: 6| Step: 11
Training loss: 4.502963044260802
Validation loss: 3.5661889625662404

Epoch: 6| Step: 12
Training loss: 3.182517851654352
Validation loss: 3.5661009425436143

Epoch: 6| Step: 13
Training loss: 4.785756499342199
Validation loss: 3.5659757108353403

Epoch: 23| Step: 0
Training loss: 3.6929826226568028
Validation loss: 3.563841500439848

Epoch: 6| Step: 1
Training loss: 3.417540012172827
Validation loss: 3.563296617761406

Epoch: 6| Step: 2
Training loss: 3.4601611780100097
Validation loss: 3.56086874377855

Epoch: 6| Step: 3
Training loss: 4.258272534637496
Validation loss: 3.5594334655147257

Epoch: 6| Step: 4
Training loss: 3.8577290473029318
Validation loss: 3.558283718849022

Epoch: 6| Step: 5
Training loss: 3.6915221180972058
Validation loss: 3.557006910060049

Epoch: 6| Step: 6
Training loss: 4.052445396323749
Validation loss: 3.555828375042258

Epoch: 6| Step: 7
Training loss: 3.001506268333487
Validation loss: 3.554782861554859

Epoch: 6| Step: 8
Training loss: 2.8706604092085777
Validation loss: 3.554253011025256

Epoch: 6| Step: 9
Training loss: 3.7518298453035355
Validation loss: 3.553116452782078

Epoch: 6| Step: 10
Training loss: 4.588966214316433
Validation loss: 3.5528867815676946

Epoch: 6| Step: 11
Training loss: 4.022322594694033
Validation loss: 3.5508105729189645

Epoch: 6| Step: 12
Training loss: 3.0476921355191493
Validation loss: 3.549523908357666

Epoch: 6| Step: 13
Training loss: 4.969605762035225
Validation loss: 3.549088210816699

Epoch: 24| Step: 0
Training loss: 4.625900799431043
Validation loss: 3.5473031194049995

Epoch: 6| Step: 1
Training loss: 4.122921506709567
Validation loss: 3.5465924564847335

Epoch: 6| Step: 2
Training loss: 4.892038549338393
Validation loss: 3.5453544517067708

Epoch: 6| Step: 3
Training loss: 3.0568646333651657
Validation loss: 3.544169637544851

Epoch: 6| Step: 4
Training loss: 3.6711979667968837
Validation loss: 3.542980139216669

Epoch: 6| Step: 5
Training loss: 2.9418500790858433
Validation loss: 3.5418975947818887

Epoch: 6| Step: 6
Training loss: 3.6767637782156117
Validation loss: 3.5407848647783955

Epoch: 6| Step: 7
Training loss: 4.107446486344477
Validation loss: 3.5397765982490097

Epoch: 6| Step: 8
Training loss: 2.7339845215053002
Validation loss: 3.5389414316130505

Epoch: 6| Step: 9
Training loss: 3.9144596347615765
Validation loss: 3.5379100389003892

Epoch: 6| Step: 10
Training loss: 2.6269543048614916
Validation loss: 3.5369129733501112

Epoch: 6| Step: 11
Training loss: 3.9110100392325178
Validation loss: 3.536188443004729

Epoch: 6| Step: 12
Training loss: 3.920411585395259
Validation loss: 3.5353949552848727

Epoch: 6| Step: 13
Training loss: 3.3437187692485004
Validation loss: 3.5343148386333683

Epoch: 25| Step: 0
Training loss: 3.8190783670100643
Validation loss: 3.5334729715183832

Epoch: 6| Step: 1
Training loss: 3.6699934663636467
Validation loss: 3.5326078089307797

Epoch: 6| Step: 2
Training loss: 3.756949026152394
Validation loss: 3.5317875362882445

Epoch: 6| Step: 3
Training loss: 3.315231204938761
Validation loss: 3.5309590648053164

Epoch: 6| Step: 4
Training loss: 3.8440351923146356
Validation loss: 3.529888968515796

Epoch: 6| Step: 5
Training loss: 3.762724586450165
Validation loss: 3.5291633506470985

Epoch: 6| Step: 6
Training loss: 3.704435607507035
Validation loss: 3.527956840611472

Epoch: 6| Step: 7
Training loss: 1.937725054067876
Validation loss: 3.527297940084669

Epoch: 6| Step: 8
Training loss: 3.6849001755256365
Validation loss: 3.5262858070796224

Epoch: 6| Step: 9
Training loss: 4.510695568503682
Validation loss: 3.5256249378192117

Epoch: 6| Step: 10
Training loss: 3.5964443555494467
Validation loss: 3.524493632779119

Epoch: 6| Step: 11
Training loss: 4.325928939990537
Validation loss: 3.523663960029528

Epoch: 6| Step: 12
Training loss: 4.346311184636495
Validation loss: 3.5226478180131364

Epoch: 6| Step: 13
Training loss: 3.156185489410737
Validation loss: 3.521771387496947

Epoch: 26| Step: 0
Training loss: 2.8645353186080174
Validation loss: 3.5208429529493466

Epoch: 6| Step: 1
Training loss: 3.8400153648545907
Validation loss: 3.520006843825462

Epoch: 6| Step: 2
Training loss: 4.112854387498852
Validation loss: 3.519248668892709

Epoch: 6| Step: 3
Training loss: 2.7724802003777804
Validation loss: 3.5183353410632137

Epoch: 6| Step: 4
Training loss: 4.776185189201509
Validation loss: 3.517548388032224

Epoch: 6| Step: 5
Training loss: 3.7618700989315608
Validation loss: 3.5168335115174627

Epoch: 6| Step: 6
Training loss: 3.4881183035150065
Validation loss: 3.5158593496880672

Epoch: 6| Step: 7
Training loss: 3.1475901634870245
Validation loss: 3.51476949512186

Epoch: 6| Step: 8
Training loss: 3.5653426223192586
Validation loss: 3.514172909283572

Epoch: 6| Step: 9
Training loss: 3.5811377755734504
Validation loss: 3.513408449433994

Epoch: 6| Step: 10
Training loss: 4.359199547740558
Validation loss: 3.5124204757774056

Epoch: 6| Step: 11
Training loss: 4.011225684006961
Validation loss: 3.511595125479464

Epoch: 6| Step: 12
Training loss: 3.7816086275890397
Validation loss: 3.5106608961685026

Epoch: 6| Step: 13
Training loss: 3.531144942349696
Validation loss: 3.5097720776190564

Epoch: 27| Step: 0
Training loss: 3.6820428846059285
Validation loss: 3.508802538287869

Epoch: 6| Step: 1
Training loss: 3.9215138789637445
Validation loss: 3.507901416938533

Epoch: 6| Step: 2
Training loss: 2.9196308514042797
Validation loss: 3.506970643826565

Epoch: 6| Step: 3
Training loss: 3.8076247014384696
Validation loss: 3.506031515983352

Epoch: 6| Step: 4
Training loss: 3.999856350226684
Validation loss: 3.505313101520794

Epoch: 6| Step: 5
Training loss: 4.298247960694708
Validation loss: 3.504309648082685

Epoch: 6| Step: 6
Training loss: 3.478241178726354
Validation loss: 3.5032976659364508

Epoch: 6| Step: 7
Training loss: 4.129069777095211
Validation loss: 3.502367409986078

Epoch: 6| Step: 8
Training loss: 3.9834404541253656
Validation loss: 3.5014846102465347

Epoch: 6| Step: 9
Training loss: 3.1280152079610084
Validation loss: 3.500745960440202

Epoch: 6| Step: 10
Training loss: 3.852547726542856
Validation loss: 3.4995514857719603

Epoch: 6| Step: 11
Training loss: 3.531434721039714
Validation loss: 3.498524057249205

Epoch: 6| Step: 12
Training loss: 2.943908680650153
Validation loss: 3.497777483692982

Epoch: 6| Step: 13
Training loss: 4.278389079245051
Validation loss: 3.4969695400776333

Epoch: 28| Step: 0
Training loss: 4.388395021446658
Validation loss: 3.496160127989603

Epoch: 6| Step: 1
Training loss: 4.28327259263092
Validation loss: 3.495233559942712

Epoch: 6| Step: 2
Training loss: 3.3389290254126642
Validation loss: 3.4943840792076

Epoch: 6| Step: 3
Training loss: 4.0184076664706625
Validation loss: 3.4934200748854827

Epoch: 6| Step: 4
Training loss: 3.8759360874760587
Validation loss: 3.4924327977724414

Epoch: 6| Step: 5
Training loss: 2.299056075080542
Validation loss: 3.4915004062640866

Epoch: 6| Step: 6
Training loss: 3.4449183093657134
Validation loss: 3.49056846195438

Epoch: 6| Step: 7
Training loss: 3.387986804850891
Validation loss: 3.489565961142826

Epoch: 6| Step: 8
Training loss: 3.637445067944594
Validation loss: 3.4888072052387

Epoch: 6| Step: 9
Training loss: 5.008688815804437
Validation loss: 3.4879056911209654

Epoch: 6| Step: 10
Training loss: 3.1328729257440147
Validation loss: 3.487225618395674

Epoch: 6| Step: 11
Training loss: 3.719807706805602
Validation loss: 3.486234403036242

Epoch: 6| Step: 12
Training loss: 2.3634002907777263
Validation loss: 3.485361424703107

Epoch: 6| Step: 13
Training loss: 4.286940753375211
Validation loss: 3.4845567881425845

Epoch: 29| Step: 0
Training loss: 4.44191189507056
Validation loss: 3.483752867931291

Epoch: 6| Step: 1
Training loss: 4.409802026435372
Validation loss: 3.4827537581610595

Epoch: 6| Step: 2
Training loss: 3.4453345058023843
Validation loss: 3.481961671632774

Epoch: 6| Step: 3
Training loss: 3.6665473109383995
Validation loss: 3.4812422577488045

Epoch: 6| Step: 4
Training loss: 3.426354111346037
Validation loss: 3.480187518619585

Epoch: 6| Step: 5
Training loss: 2.9403403327817355
Validation loss: 3.4791732396508332

Epoch: 6| Step: 6
Training loss: 3.300903751425036
Validation loss: 3.47833779885509

Epoch: 6| Step: 7
Training loss: 3.2479761130859255
Validation loss: 3.4776894922102435

Epoch: 6| Step: 8
Training loss: 3.8301164701994335
Validation loss: 3.4767609142700753

Epoch: 6| Step: 9
Training loss: 3.25300986959307
Validation loss: 3.4760536329320275

Epoch: 6| Step: 10
Training loss: 4.118645599848139
Validation loss: 3.4754874181730764

Epoch: 6| Step: 11
Training loss: 3.5372072455917256
Validation loss: 3.473987510162467

Epoch: 6| Step: 12
Training loss: 4.214126653186479
Validation loss: 3.4736248063556654

Epoch: 6| Step: 13
Training loss: 3.4150149066649975
Validation loss: 3.4726888341175632

Epoch: 30| Step: 0
Training loss: 2.6548300145218073
Validation loss: 3.4719604162690483

Epoch: 6| Step: 1
Training loss: 3.814461625534563
Validation loss: 3.4713828971702916

Epoch: 6| Step: 2
Training loss: 3.6702212241537313
Validation loss: 3.4701909800153046

Epoch: 6| Step: 3
Training loss: 3.636456243462874
Validation loss: 3.4694460992868743

Epoch: 6| Step: 4
Training loss: 4.207919084663023
Validation loss: 3.4688319379756574

Epoch: 6| Step: 5
Training loss: 3.7474848895948467
Validation loss: 3.4680843466578146

Epoch: 6| Step: 6
Training loss: 3.5700381651475874
Validation loss: 3.46730079816426

Epoch: 6| Step: 7
Training loss: 3.8863776742619796
Validation loss: 3.466241803492509

Epoch: 6| Step: 8
Training loss: 3.7517146958663696
Validation loss: 3.4653515141069255

Epoch: 6| Step: 9
Training loss: 3.58977268551294
Validation loss: 3.464551233411981

Epoch: 6| Step: 10
Training loss: 4.119735826707867
Validation loss: 3.463717812441412

Epoch: 6| Step: 11
Training loss: 3.0082544571811725
Validation loss: 3.4629315880392695

Epoch: 6| Step: 12
Training loss: 3.8023870198797747
Validation loss: 3.462219023240762

Epoch: 6| Step: 13
Training loss: 4.002611738142779
Validation loss: 3.4612330869250654

Epoch: 31| Step: 0
Training loss: 3.361302448287679
Validation loss: 3.4603095878877856

Epoch: 6| Step: 1
Training loss: 2.857213939055015
Validation loss: 3.4595168014012687

Epoch: 6| Step: 2
Training loss: 4.128067263387878
Validation loss: 3.4586080646373625

Epoch: 6| Step: 3
Training loss: 4.123277709223914
Validation loss: 3.4579309455994482

Epoch: 6| Step: 4
Training loss: 3.6089730967900677
Validation loss: 3.456838557297727

Epoch: 6| Step: 5
Training loss: 3.641877446014227
Validation loss: 3.456204786881853

Epoch: 6| Step: 6
Training loss: 3.0909898563787506
Validation loss: 3.455380271743031

Epoch: 6| Step: 7
Training loss: 3.7296564785674455
Validation loss: 3.454607730837868

Epoch: 6| Step: 8
Training loss: 4.069313556416435
Validation loss: 3.4536817431567686

Epoch: 6| Step: 9
Training loss: 3.312781411939003
Validation loss: 3.4528832652367916

Epoch: 6| Step: 10
Training loss: 3.0651842148450164
Validation loss: 3.4522304152881333

Epoch: 6| Step: 11
Training loss: 4.582835407375411
Validation loss: 3.451363707497924

Epoch: 6| Step: 12
Training loss: 4.488661999733502
Validation loss: 3.4505426835776647

Epoch: 6| Step: 13
Training loss: 1.8936812234104283
Validation loss: 3.4497478457756903

Epoch: 32| Step: 0
Training loss: 3.384326763284839
Validation loss: 3.448811821981277

Epoch: 6| Step: 1
Training loss: 4.517698663207613
Validation loss: 3.44800415959086

Epoch: 6| Step: 2
Training loss: 3.871876103460295
Validation loss: 3.447233434191764

Epoch: 6| Step: 3
Training loss: 3.07352549238355
Validation loss: 3.446248572634822

Epoch: 6| Step: 4
Training loss: 2.8370559210444375
Validation loss: 3.445385432467216

Epoch: 6| Step: 5
Training loss: 3.172143633511638
Validation loss: 3.4445322932793587

Epoch: 6| Step: 6
Training loss: 4.26126624903514
Validation loss: 3.4437582478892454

Epoch: 6| Step: 7
Training loss: 3.784892070042759
Validation loss: 3.4430808219416167

Epoch: 6| Step: 8
Training loss: 2.8446206237783445
Validation loss: 3.4424677998688757

Epoch: 6| Step: 9
Training loss: 3.3394673810229105
Validation loss: 3.4415336308660187

Epoch: 6| Step: 10
Training loss: 4.60709979268475
Validation loss: 3.4406762447577415

Epoch: 6| Step: 11
Training loss: 3.6162177942650358
Validation loss: 3.4396661043538646

Epoch: 6| Step: 12
Training loss: 3.5702805799397095
Validation loss: 3.4389985697066066

Epoch: 6| Step: 13
Training loss: 4.043350865094658
Validation loss: 3.4381014613750316

Epoch: 33| Step: 0
Training loss: 3.6482770014550296
Validation loss: 3.43750796200603

Epoch: 6| Step: 1
Training loss: 3.6998001817926425
Validation loss: 3.436574399249864

Epoch: 6| Step: 2
Training loss: 4.111917731623606
Validation loss: 3.435811005028334

Epoch: 6| Step: 3
Training loss: 3.6659321193705985
Validation loss: 3.4349081894136893

Epoch: 6| Step: 4
Training loss: 3.674098733429836
Validation loss: 3.4341284915197434

Epoch: 6| Step: 5
Training loss: 3.109894828857982
Validation loss: 3.4333021259492456

Epoch: 6| Step: 6
Training loss: 2.8605474350931446
Validation loss: 3.4325075201946955

Epoch: 6| Step: 7
Training loss: 3.1736400184641096
Validation loss: 3.4321281768498477

Epoch: 6| Step: 8
Training loss: 4.347139202675309
Validation loss: 3.430974842011923

Epoch: 6| Step: 9
Training loss: 3.117181687122556
Validation loss: 3.4301480933697954

Epoch: 6| Step: 10
Training loss: 4.384172252445304
Validation loss: 3.429482019133826

Epoch: 6| Step: 11
Training loss: 4.1542291532591324
Validation loss: 3.428652057264866

Epoch: 6| Step: 12
Training loss: 4.045419320721741
Validation loss: 3.4278238898165996

Epoch: 6| Step: 13
Training loss: 1.4527809802316478
Validation loss: 3.4269978158225585

Epoch: 34| Step: 0
Training loss: 3.668069368877511
Validation loss: 3.426200683965279

Epoch: 6| Step: 1
Training loss: 4.1256537641849675
Validation loss: 3.4253120753543196

Epoch: 6| Step: 2
Training loss: 4.205022334017959
Validation loss: 3.424607580890182

Epoch: 6| Step: 3
Training loss: 3.128202094805779
Validation loss: 3.423666811888633

Epoch: 6| Step: 4
Training loss: 3.4572367634005063
Validation loss: 3.422778795514558

Epoch: 6| Step: 5
Training loss: 3.131981489738244
Validation loss: 3.4221246171027744

Epoch: 6| Step: 6
Training loss: 4.157162673670749
Validation loss: 3.421398819528027

Epoch: 6| Step: 7
Training loss: 3.8087472424999507
Validation loss: 3.420558397268279

Epoch: 6| Step: 8
Training loss: 3.2279841729287817
Validation loss: 3.419624668629307

Epoch: 6| Step: 9
Training loss: 3.341098482783061
Validation loss: 3.418912555105222

Epoch: 6| Step: 10
Training loss: 4.386364155651175
Validation loss: 3.4181522765688204

Epoch: 6| Step: 11
Training loss: 2.695622965305338
Validation loss: 3.4172170892484672

Epoch: 6| Step: 12
Training loss: 3.385192597627891
Validation loss: 3.416353880438336

Epoch: 6| Step: 13
Training loss: 4.098836519724797
Validation loss: 3.415557114414078

Epoch: 35| Step: 0
Training loss: 3.2680221593378675
Validation loss: 3.4147726362148165

Epoch: 6| Step: 1
Training loss: 4.1219528965967935
Validation loss: 3.4142516119859874

Epoch: 6| Step: 2
Training loss: 3.5612233869442607
Validation loss: 3.413224785407701

Epoch: 6| Step: 3
Training loss: 3.8706618606041707
Validation loss: 3.412630986217933

Epoch: 6| Step: 4
Training loss: 3.8393272448349762
Validation loss: 3.4116845747340245

Epoch: 6| Step: 5
Training loss: 2.585776517069491
Validation loss: 3.4109523768415735

Epoch: 6| Step: 6
Training loss: 3.16466616299694
Validation loss: 3.410248437858498

Epoch: 6| Step: 7
Training loss: 3.5567443933070715
Validation loss: 3.409472317631657

Epoch: 6| Step: 8
Training loss: 3.904202099900213
Validation loss: 3.408662534544235

Epoch: 6| Step: 9
Training loss: 3.990072925828571
Validation loss: 3.408044546118982

Epoch: 6| Step: 10
Training loss: 3.6113022452087833
Validation loss: 3.4070053790847274

Epoch: 6| Step: 11
Training loss: 3.726303635409246
Validation loss: 3.4062073046260792

Epoch: 6| Step: 12
Training loss: 4.254336668996009
Validation loss: 3.4055613385796857

Epoch: 6| Step: 13
Training loss: 2.6377456586793184
Validation loss: 3.404625865099397

Epoch: 36| Step: 0
Training loss: 2.670068855397912
Validation loss: 3.4039185104825824

Epoch: 6| Step: 1
Training loss: 3.357461357661243
Validation loss: 3.403271917164798

Epoch: 6| Step: 2
Training loss: 4.249227116936513
Validation loss: 3.4023770210539372

Epoch: 6| Step: 3
Training loss: 3.762173285509347
Validation loss: 3.4017112457371637

Epoch: 6| Step: 4
Training loss: 2.715772906139644
Validation loss: 3.4008956842924607

Epoch: 6| Step: 5
Training loss: 3.6277439650056293
Validation loss: 3.4001281538595194

Epoch: 6| Step: 6
Training loss: 3.883171817111117
Validation loss: 3.39933565195237

Epoch: 6| Step: 7
Training loss: 3.4603527255335433
Validation loss: 3.398524385915606

Epoch: 6| Step: 8
Training loss: 3.829253112237817
Validation loss: 3.39779583930973

Epoch: 6| Step: 9
Training loss: 4.041821244157956
Validation loss: 3.396908261856963

Epoch: 6| Step: 10
Training loss: 3.7360118646372045
Validation loss: 3.3961824400857874

Epoch: 6| Step: 11
Training loss: 4.023137172119349
Validation loss: 3.395300180050885

Epoch: 6| Step: 12
Training loss: 3.4823851784031183
Validation loss: 3.3943967067178904

Epoch: 6| Step: 13
Training loss: 3.5615522228151932
Validation loss: 3.3936971884484715

Epoch: 37| Step: 0
Training loss: 2.6142423997666224
Validation loss: 3.3930164528903624

Epoch: 6| Step: 1
Training loss: 3.347366231420736
Validation loss: 3.3923029578456627

Epoch: 6| Step: 2
Training loss: 3.567314909615869
Validation loss: 3.39155254338806

Epoch: 6| Step: 3
Training loss: 3.476954063052831
Validation loss: 3.3906214040018203

Epoch: 6| Step: 4
Training loss: 3.7415330031775995
Validation loss: 3.389957421801594

Epoch: 6| Step: 5
Training loss: 3.673934553714923
Validation loss: 3.3892009979601134

Epoch: 6| Step: 6
Training loss: 3.2125727070102474
Validation loss: 3.388377275977677

Epoch: 6| Step: 7
Training loss: 2.9956004944055072
Validation loss: 3.3874116084227257

Epoch: 6| Step: 8
Training loss: 3.927850919765208
Validation loss: 3.3868597219188676

Epoch: 6| Step: 9
Training loss: 4.42275226639061
Validation loss: 3.3861219591837384

Epoch: 6| Step: 10
Training loss: 3.2375351951777525
Validation loss: 3.3853234673758537

Epoch: 6| Step: 11
Training loss: 4.568472102072214
Validation loss: 3.3846546359847873

Epoch: 6| Step: 12
Training loss: 3.08943430120348
Validation loss: 3.3837993964789295

Epoch: 6| Step: 13
Training loss: 4.645056666756384
Validation loss: 3.383058836978861

Epoch: 38| Step: 0
Training loss: 3.5996194426405603
Validation loss: 3.382206879246176

Epoch: 6| Step: 1
Training loss: 3.6332364398973875
Validation loss: 3.381336777612081

Epoch: 6| Step: 2
Training loss: 2.7532814561638026
Validation loss: 3.3803915637797046

Epoch: 6| Step: 3
Training loss: 3.252156935711601
Validation loss: 3.3797518261382424

Epoch: 6| Step: 4
Training loss: 4.218200873911874
Validation loss: 3.3787899864405277

Epoch: 6| Step: 5
Training loss: 3.693827744132137
Validation loss: 3.3783873343156383

Epoch: 6| Step: 6
Training loss: 3.4717092177453637
Validation loss: 3.3778761378981805

Epoch: 6| Step: 7
Training loss: 4.198326576735292
Validation loss: 3.377570856014716

Epoch: 6| Step: 8
Training loss: 4.081026061195665
Validation loss: 3.3758491168064264

Epoch: 6| Step: 9
Training loss: 3.1839927376515744
Validation loss: 3.3750656467921574

Epoch: 6| Step: 10
Training loss: 2.6919137063840677
Validation loss: 3.37448881768051

Epoch: 6| Step: 11
Training loss: 3.9944283304845927
Validation loss: 3.37354755329723

Epoch: 6| Step: 12
Training loss: 3.4696461662600364
Validation loss: 3.3741623641535976

Epoch: 6| Step: 13
Training loss: 4.072054148061051
Validation loss: 3.371819515620078

Epoch: 39| Step: 0
Training loss: 3.467534032543257
Validation loss: 3.371203421225845

Epoch: 6| Step: 1
Training loss: 3.8818510465507847
Validation loss: 3.37059586213496

Epoch: 6| Step: 2
Training loss: 2.8081207089250197
Validation loss: 3.3697187074063075

Epoch: 6| Step: 3
Training loss: 4.140012990958798
Validation loss: 3.3686332125792706

Epoch: 6| Step: 4
Training loss: 3.4661631518054774
Validation loss: 3.3685625575457165

Epoch: 6| Step: 5
Training loss: 3.777888798173168
Validation loss: 3.367641687388246

Epoch: 6| Step: 6
Training loss: 3.4136845359824997
Validation loss: 3.366075697886221

Epoch: 6| Step: 7
Training loss: 2.985839005327458
Validation loss: 3.3654860038679524

Epoch: 6| Step: 8
Training loss: 4.15599208404404
Validation loss: 3.364598175557583

Epoch: 6| Step: 9
Training loss: 2.8463032756605773
Validation loss: 3.363970313456517

Epoch: 6| Step: 10
Training loss: 4.228604935546443
Validation loss: 3.363386178859235

Epoch: 6| Step: 11
Training loss: 4.480677765258732
Validation loss: 3.362745840802898

Epoch: 6| Step: 12
Training loss: 2.7680837617559857
Validation loss: 3.3615625270936276

Epoch: 6| Step: 13
Training loss: 3.2396952782492745
Validation loss: 3.360778405561092

Epoch: 40| Step: 0
Training loss: 3.2145160864971762
Validation loss: 3.359962130094861

Epoch: 6| Step: 1
Training loss: 3.4169197609054005
Validation loss: 3.3590238471105653

Epoch: 6| Step: 2
Training loss: 3.2061993987197033
Validation loss: 3.358587349627893

Epoch: 6| Step: 3
Training loss: 4.241930987223414
Validation loss: 3.357666982525796

Epoch: 6| Step: 4
Training loss: 3.4714155523200687
Validation loss: 3.357076674385407

Epoch: 6| Step: 5
Training loss: 3.5820466917946874
Validation loss: 3.3562978278249687

Epoch: 6| Step: 6
Training loss: 3.4695233007149704
Validation loss: 3.355476246542418

Epoch: 6| Step: 7
Training loss: 3.6133401072064446
Validation loss: 3.3547671486327153

Epoch: 6| Step: 8
Training loss: 3.443269638649195
Validation loss: 3.354161996187874

Epoch: 6| Step: 9
Training loss: 3.6678634482189048
Validation loss: 3.353441561419409

Epoch: 6| Step: 10
Training loss: 3.392914873363407
Validation loss: 3.352658206152726

Epoch: 6| Step: 11
Training loss: 3.57124433314722
Validation loss: 3.3519467224107133

Epoch: 6| Step: 12
Training loss: 4.484513656120761
Validation loss: 3.351294540102743

Epoch: 6| Step: 13
Training loss: 2.9943379376338632
Validation loss: 3.3504691824383417

Epoch: 41| Step: 0
Training loss: 4.137453181529152
Validation loss: 3.3497347117992073

Epoch: 6| Step: 1
Training loss: 3.7380730741408987
Validation loss: 3.3489111774513063

Epoch: 6| Step: 2
Training loss: 3.4381882412046623
Validation loss: 3.3480850469489005

Epoch: 6| Step: 3
Training loss: 2.7502519318749217
Validation loss: 3.3472446829010014

Epoch: 6| Step: 4
Training loss: 3.852458238418655
Validation loss: 3.3465183648543864

Epoch: 6| Step: 5
Training loss: 3.348983804102612
Validation loss: 3.3458210501275967

Epoch: 6| Step: 6
Training loss: 4.289127203448086
Validation loss: 3.3450865552188715

Epoch: 6| Step: 7
Training loss: 3.6978315030172793
Validation loss: 3.3442791119647794

Epoch: 6| Step: 8
Training loss: 3.3078494264958826
Validation loss: 3.3435438872907897

Epoch: 6| Step: 9
Training loss: 3.1469936799263807
Validation loss: 3.3428129167874223

Epoch: 6| Step: 10
Training loss: 3.222841791533807
Validation loss: 3.342120107919493

Epoch: 6| Step: 11
Training loss: 3.499267774009819
Validation loss: 3.3412169816879906

Epoch: 6| Step: 12
Training loss: 3.742349067656497
Validation loss: 3.3406036143895803

Epoch: 6| Step: 13
Training loss: 3.7802770955081115
Validation loss: 3.3397825216166694

Epoch: 42| Step: 0
Training loss: 3.920731944044477
Validation loss: 3.3392085862370986

Epoch: 6| Step: 1
Training loss: 3.1386934480240254
Validation loss: 3.338160120105218

Epoch: 6| Step: 2
Training loss: 3.988232708522548
Validation loss: 3.3377223504074194

Epoch: 6| Step: 3
Training loss: 4.407897208453592
Validation loss: 3.336834381514988

Epoch: 6| Step: 4
Training loss: 3.9935290924728166
Validation loss: 3.3359186888045245

Epoch: 6| Step: 5
Training loss: 2.656931531650636
Validation loss: 3.3351108354525922

Epoch: 6| Step: 6
Training loss: 3.1720152574920264
Validation loss: 3.334293274682758

Epoch: 6| Step: 7
Training loss: 3.6522278140021736
Validation loss: 3.3335130171389036

Epoch: 6| Step: 8
Training loss: 3.329925909506873
Validation loss: 3.3327533222431813

Epoch: 6| Step: 9
Training loss: 3.201349128996639
Validation loss: 3.332034453749807

Epoch: 6| Step: 10
Training loss: 3.935560687398218
Validation loss: 3.3312132204789684

Epoch: 6| Step: 11
Training loss: 4.2688664567066645
Validation loss: 3.3304180923086317

Epoch: 6| Step: 12
Training loss: 2.5541998254844196
Validation loss: 3.329778750008546

Epoch: 6| Step: 13
Training loss: 2.899764011909946
Validation loss: 3.328598289993491

Epoch: 43| Step: 0
Training loss: 2.6539955894473812
Validation loss: 3.3282489860394975

Epoch: 6| Step: 1
Training loss: 3.1676634842519005
Validation loss: 3.3273997398815007

Epoch: 6| Step: 2
Training loss: 3.567542405922346
Validation loss: 3.3268537522301247

Epoch: 6| Step: 3
Training loss: 3.9147106859822793
Validation loss: 3.3262232056562864

Epoch: 6| Step: 4
Training loss: 3.395295613471152
Validation loss: 3.3256116773986015

Epoch: 6| Step: 5
Training loss: 3.9995155041052315
Validation loss: 3.325020696079222

Epoch: 6| Step: 6
Training loss: 4.165118858225947
Validation loss: 3.3240790486408422

Epoch: 6| Step: 7
Training loss: 3.8356100591375077
Validation loss: 3.323340893277055

Epoch: 6| Step: 8
Training loss: 3.8517815022755344
Validation loss: 3.3227304555664823

Epoch: 6| Step: 9
Training loss: 3.2885451827434746
Validation loss: 3.3219634576615196

Epoch: 6| Step: 10
Training loss: 3.4714608811585452
Validation loss: 3.321111068097435

Epoch: 6| Step: 11
Training loss: 3.387845495418892
Validation loss: 3.3210046753912934

Epoch: 6| Step: 12
Training loss: 3.0635517416361098
Validation loss: 3.319749617810883

Epoch: 6| Step: 13
Training loss: 4.0261055701523425
Validation loss: 3.3191148784806876

Epoch: 44| Step: 0
Training loss: 3.6652317418293587
Validation loss: 3.3181112541265225

Epoch: 6| Step: 1
Training loss: 4.079084144721312
Validation loss: 3.3173917165757216

Epoch: 6| Step: 2
Training loss: 2.5582228530074183
Validation loss: 3.3163786485161793

Epoch: 6| Step: 3
Training loss: 4.0390596666455245
Validation loss: 3.315782039781968

Epoch: 6| Step: 4
Training loss: 2.7520962441714527
Validation loss: 3.314984169261182

Epoch: 6| Step: 5
Training loss: 3.488815420501646
Validation loss: 3.314435472747825

Epoch: 6| Step: 6
Training loss: 3.9318317607538917
Validation loss: 3.313926100344832

Epoch: 6| Step: 7
Training loss: 4.235784204650792
Validation loss: 3.312763388608938

Epoch: 6| Step: 8
Training loss: 3.3512181814320217
Validation loss: 3.312392802873131

Epoch: 6| Step: 9
Training loss: 2.7472605498695657
Validation loss: 3.3113398223836294

Epoch: 6| Step: 10
Training loss: 3.327301353297338
Validation loss: 3.3107522094288138

Epoch: 6| Step: 11
Training loss: 3.2529963838948257
Validation loss: 3.309944101683287

Epoch: 6| Step: 12
Training loss: 3.4613899296902866
Validation loss: 3.3094787146355262

Epoch: 6| Step: 13
Training loss: 4.82483054540469
Validation loss: 3.308544192221638

Epoch: 45| Step: 0
Training loss: 3.5429721146707425
Validation loss: 3.3080143801718855

Epoch: 6| Step: 1
Training loss: 4.051727802333728
Validation loss: 3.307168283535733

Epoch: 6| Step: 2
Training loss: 3.199939762979037
Validation loss: 3.3063020524785838

Epoch: 6| Step: 3
Training loss: 3.4806310956192275
Validation loss: 3.306445894754119

Epoch: 6| Step: 4
Training loss: 3.6152453224020498
Validation loss: 3.3047399595013403

Epoch: 6| Step: 5
Training loss: 3.7698428010419573
Validation loss: 3.3039155933874382

Epoch: 6| Step: 6
Training loss: 3.3417694786282035
Validation loss: 3.3035699110541956

Epoch: 6| Step: 7
Training loss: 3.475712841661467
Validation loss: 3.3037505312836046

Epoch: 6| Step: 8
Training loss: 3.1680533401352924
Validation loss: 3.3026981557107598

Epoch: 6| Step: 9
Training loss: 3.181790043347274
Validation loss: 3.3019006213465842

Epoch: 6| Step: 10
Training loss: 3.1072770138296053
Validation loss: 3.301948586279217

Epoch: 6| Step: 11
Training loss: 3.4013984496930405
Validation loss: 3.3010292305207276

Epoch: 6| Step: 12
Training loss: 4.40531251281578
Validation loss: 3.3006530802852065

Epoch: 6| Step: 13
Training loss: 3.795574075252646
Validation loss: 3.3016053691004394

Epoch: 46| Step: 0
Training loss: 4.026389807305186
Validation loss: 3.2973040097649036

Epoch: 6| Step: 1
Training loss: 3.3569702057662565
Validation loss: 3.2967691416663882

Epoch: 6| Step: 2
Training loss: 3.077993012517641
Validation loss: 3.2961739667289263

Epoch: 6| Step: 3
Training loss: 3.708182185375212
Validation loss: 3.297021536483358

Epoch: 6| Step: 4
Training loss: 3.9661626116205078
Validation loss: 3.2981321333727136

Epoch: 6| Step: 5
Training loss: 3.2338131034129316
Validation loss: 3.3000326396139643

Epoch: 6| Step: 6
Training loss: 3.0187393472613864
Validation loss: 3.297018569303144

Epoch: 6| Step: 7
Training loss: 3.893134475968385
Validation loss: 3.297102471980903

Epoch: 6| Step: 8
Training loss: 3.7482852830149165
Validation loss: 3.293719291244199

Epoch: 6| Step: 9
Training loss: 2.5690336901459148
Validation loss: 3.2919868530546

Epoch: 6| Step: 10
Training loss: 4.187275894772795
Validation loss: 3.291436824559849

Epoch: 6| Step: 11
Training loss: 3.9659269610213763
Validation loss: 3.290060885062031

Epoch: 6| Step: 12
Training loss: 3.065078739567474
Validation loss: 3.2889410572363715

Epoch: 6| Step: 13
Training loss: 3.139541059351588
Validation loss: 3.2881066159933323

Epoch: 47| Step: 0
Training loss: 3.8176512390835766
Validation loss: 3.2876906727504864

Epoch: 6| Step: 1
Training loss: 3.2229388488782096
Validation loss: 3.286663211221727

Epoch: 6| Step: 2
Training loss: 3.7698325555584353
Validation loss: 3.286365385574148

Epoch: 6| Step: 3
Training loss: 3.3562336273078155
Validation loss: 3.2856219439599497

Epoch: 6| Step: 4
Training loss: 3.2686444063071183
Validation loss: 3.2848399956766903

Epoch: 6| Step: 5
Training loss: 3.626414450565868
Validation loss: 3.2841821932347903

Epoch: 6| Step: 6
Training loss: 3.603499878226096
Validation loss: 3.283370867545306

Epoch: 6| Step: 7
Training loss: 4.183544511264865
Validation loss: 3.282420383374386

Epoch: 6| Step: 8
Training loss: 2.514908208669785
Validation loss: 3.281610559517071

Epoch: 6| Step: 9
Training loss: 3.523993133243794
Validation loss: 3.2805697062563732

Epoch: 6| Step: 10
Training loss: 3.5540169890453326
Validation loss: 3.280445675729849

Epoch: 6| Step: 11
Training loss: 3.367968546124733
Validation loss: 3.2794356322851104

Epoch: 6| Step: 12
Training loss: 3.6402461955892425
Validation loss: 3.2787330548920295

Epoch: 6| Step: 13
Training loss: 3.859005311873814
Validation loss: 3.2777073625324435

Epoch: 48| Step: 0
Training loss: 3.0192270853635974
Validation loss: 3.2780920032988936

Epoch: 6| Step: 1
Training loss: 3.793540463639155
Validation loss: 3.27799962437061

Epoch: 6| Step: 2
Training loss: 4.1283634229561175
Validation loss: 3.276887236219219

Epoch: 6| Step: 3
Training loss: 3.338223748188361
Validation loss: 3.2796018962687126

Epoch: 6| Step: 4
Training loss: 3.291451427005705
Validation loss: 3.2770321114700547

Epoch: 6| Step: 5
Training loss: 2.914368968730775
Validation loss: 3.275614133915198

Epoch: 6| Step: 6
Training loss: 3.0945399653334418
Validation loss: 3.273993026753535

Epoch: 6| Step: 7
Training loss: 3.6640324377847913
Validation loss: 3.2748445821076366

Epoch: 6| Step: 8
Training loss: 3.419145026389904
Validation loss: 3.2719923298682647

Epoch: 6| Step: 9
Training loss: 4.431998267438529
Validation loss: 3.2707962374715827

Epoch: 6| Step: 10
Training loss: 2.895055561224289
Validation loss: 3.271544590314576

Epoch: 6| Step: 11
Training loss: 4.039092722324068
Validation loss: 3.270026973986792

Epoch: 6| Step: 12
Training loss: 3.812584672831832
Validation loss: 3.2704596122102134

Epoch: 6| Step: 13
Training loss: 2.5869715717701602
Validation loss: 3.2685115362610877

Epoch: 49| Step: 0
Training loss: 2.9240047424424063
Validation loss: 3.269527458088452

Epoch: 6| Step: 1
Training loss: 3.450397501726703
Validation loss: 3.2814781832326263

Epoch: 6| Step: 2
Training loss: 3.7988738147959307
Validation loss: 3.267745029955077

Epoch: 6| Step: 3
Training loss: 3.2973545683863303
Validation loss: 3.265766073042141

Epoch: 6| Step: 4
Training loss: 3.615274207556765
Validation loss: 3.2649021996372043

Epoch: 6| Step: 5
Training loss: 3.268838569797834
Validation loss: 3.2642244457262226

Epoch: 6| Step: 6
Training loss: 3.3977473818867354
Validation loss: 3.2639668136739726

Epoch: 6| Step: 7
Training loss: 3.6186889432457097
Validation loss: 3.2629576490339804

Epoch: 6| Step: 8
Training loss: 3.2043410063209627
Validation loss: 3.2632084960230863

Epoch: 6| Step: 9
Training loss: 3.6786711437239115
Validation loss: 3.263094132941493

Epoch: 6| Step: 10
Training loss: 4.420561147083314
Validation loss: 3.2628960747097278

Epoch: 6| Step: 11
Training loss: 3.438460891978279
Validation loss: 3.2623984750765773

Epoch: 6| Step: 12
Training loss: 3.7432227882736777
Validation loss: 3.262710159869609

Epoch: 6| Step: 13
Training loss: 2.727104242495779
Validation loss: 3.262238909930623

Epoch: 50| Step: 0
Training loss: 3.172341899614819
Validation loss: 3.2601872053837972

Epoch: 6| Step: 1
Training loss: 3.872552406345533
Validation loss: 3.2574488065814173

Epoch: 6| Step: 2
Training loss: 3.2044975503455917
Validation loss: 3.259263238603268

Epoch: 6| Step: 3
Training loss: 4.368546658260103
Validation loss: 3.2566134494698065

Epoch: 6| Step: 4
Training loss: 4.362228498782009
Validation loss: 3.2553419781558373

Epoch: 6| Step: 5
Training loss: 3.7698016924521425
Validation loss: 3.256031470923276

Epoch: 6| Step: 6
Training loss: 4.040482232801424
Validation loss: 3.254465098073274

Epoch: 6| Step: 7
Training loss: 3.5148123246903826
Validation loss: 3.252570491724069

Epoch: 6| Step: 8
Training loss: 3.6120975679419334
Validation loss: 3.253336808164803

Epoch: 6| Step: 9
Training loss: 2.9913698677885163
Validation loss: 3.253537025801012

Epoch: 6| Step: 10
Training loss: 2.782142495960329
Validation loss: 3.251923997329714

Epoch: 6| Step: 11
Training loss: 3.0326901190552475
Validation loss: 3.2507376594900665

Epoch: 6| Step: 12
Training loss: 2.7150260589641664
Validation loss: 3.252669865088801

Epoch: 6| Step: 13
Training loss: 2.697614576789506
Validation loss: 3.2505597641398962

Epoch: 51| Step: 0
Training loss: 3.98914652824432
Validation loss: 3.2485825371684927

Epoch: 6| Step: 1
Training loss: 4.026668577088499
Validation loss: 3.247796686695052

Epoch: 6| Step: 2
Training loss: 3.5639597261253333
Validation loss: 3.246794324161161

Epoch: 6| Step: 3
Training loss: 2.693251731442127
Validation loss: 3.2456596173746437

Epoch: 6| Step: 4
Training loss: 3.6330723823373976
Validation loss: 3.2454451881550863

Epoch: 6| Step: 5
Training loss: 3.484131671979466
Validation loss: 3.2445149861805755

Epoch: 6| Step: 6
Training loss: 2.58253222523882
Validation loss: 3.244638579258718

Epoch: 6| Step: 7
Training loss: 4.050661179060627
Validation loss: 3.2444769104002655

Epoch: 6| Step: 8
Training loss: 3.1749508230651124
Validation loss: 3.2435183356984014

Epoch: 6| Step: 9
Training loss: 3.897695222263318
Validation loss: 3.2428730122952927

Epoch: 6| Step: 10
Training loss: 2.789976253476828
Validation loss: 3.2470973835933945

Epoch: 6| Step: 11
Training loss: 4.2063574857993045
Validation loss: 3.257124795501753

Epoch: 6| Step: 12
Training loss: 3.422975406773466
Validation loss: 3.2692745803538936

Epoch: 6| Step: 13
Training loss: 2.4148563203265416
Validation loss: 3.253542697495867

Epoch: 52| Step: 0
Training loss: 3.0243579340731337
Validation loss: 3.3796536057918902

Epoch: 6| Step: 1
Training loss: 4.002309847525624
Validation loss: 3.4519399015188883

Epoch: 6| Step: 2
Training loss: 4.179945779111087
Validation loss: 3.360218243127765

Epoch: 6| Step: 3
Training loss: 3.268778906962436
Validation loss: 3.3625969719664535

Epoch: 6| Step: 4
Training loss: 4.771274107626539
Validation loss: 3.3804501531179056

Epoch: 6| Step: 5
Training loss: 2.474392009001198
Validation loss: 3.3084331753930396

Epoch: 6| Step: 6
Training loss: 3.4426765998305022
Validation loss: 3.312603558627889

Epoch: 6| Step: 7
Training loss: 2.9969180488875646
Validation loss: 3.3410167500191985

Epoch: 6| Step: 8
Training loss: 4.105438551714578
Validation loss: 3.3520123327385054

Epoch: 6| Step: 9
Training loss: 3.043450254998573
Validation loss: 3.2876472315093266

Epoch: 6| Step: 10
Training loss: 3.4559764567562263
Validation loss: 3.263644608329549

Epoch: 6| Step: 11
Training loss: 3.507621641000639
Validation loss: 3.24476176942591

Epoch: 6| Step: 12
Training loss: 3.20067163809981
Validation loss: 3.2436269459502993

Epoch: 6| Step: 13
Training loss: 3.977873520495109
Validation loss: 3.250031282575699

Epoch: 53| Step: 0
Training loss: 2.792955860028166
Validation loss: 3.2481694568251

Epoch: 6| Step: 1
Training loss: 3.110949860284335
Validation loss: 3.2576215386119465

Epoch: 6| Step: 2
Training loss: 3.0808016375382556
Validation loss: 3.244810035416682

Epoch: 6| Step: 3
Training loss: 2.70481396428486
Validation loss: 3.2482263617597686

Epoch: 6| Step: 4
Training loss: 3.1093553705410546
Validation loss: 3.2633160942842623

Epoch: 6| Step: 5
Training loss: 4.137060394443788
Validation loss: 3.245159583330934

Epoch: 6| Step: 6
Training loss: 3.5456140099968216
Validation loss: 3.2361747526183713

Epoch: 6| Step: 7
Training loss: 3.2689297395088968
Validation loss: 3.2376449341568376

Epoch: 6| Step: 8
Training loss: 4.390414304191709
Validation loss: 3.241240325960501

Epoch: 6| Step: 9
Training loss: 3.6516031585375495
Validation loss: 3.2236812357897997

Epoch: 6| Step: 10
Training loss: 3.1000631633599482
Validation loss: 3.222802306265326

Epoch: 6| Step: 11
Training loss: 4.054874482005496
Validation loss: 3.227792144191426

Epoch: 6| Step: 12
Training loss: 4.024756354308649
Validation loss: 3.225911573830128

Epoch: 6| Step: 13
Training loss: 3.4071582668169613
Validation loss: 3.2258365371285573

Epoch: 54| Step: 0
Training loss: 3.544493829614986
Validation loss: 3.2195099585493563

Epoch: 6| Step: 1
Training loss: 3.965047956948733
Validation loss: 3.220698626869379

Epoch: 6| Step: 2
Training loss: 2.9810436889149625
Validation loss: 3.2215102176652337

Epoch: 6| Step: 3
Training loss: 3.899061990077334
Validation loss: 3.2236319782674645

Epoch: 6| Step: 4
Training loss: 4.1890057945184065
Validation loss: 3.2202988635543655

Epoch: 6| Step: 5
Training loss: 3.6386464517865202
Validation loss: 3.2188193049637124

Epoch: 6| Step: 6
Training loss: 3.406729428210243
Validation loss: 3.218718596593068

Epoch: 6| Step: 7
Training loss: 3.4962732364890265
Validation loss: 3.214893179252973

Epoch: 6| Step: 8
Training loss: 2.8367871569614396
Validation loss: 3.214754722717266

Epoch: 6| Step: 9
Training loss: 3.6610409899878333
Validation loss: 3.212618102650362

Epoch: 6| Step: 10
Training loss: 3.3617060181245657
Validation loss: 3.213370126824126

Epoch: 6| Step: 11
Training loss: 3.1977881655311893
Validation loss: 3.211846763629549

Epoch: 6| Step: 12
Training loss: 3.2364082763913053
Validation loss: 3.2119949109104016

Epoch: 6| Step: 13
Training loss: 2.443248718829704
Validation loss: 3.2113456653278134

Epoch: 55| Step: 0
Training loss: 3.258940064770164
Validation loss: 3.21345663317999

Epoch: 6| Step: 1
Training loss: 3.2088565812578835
Validation loss: 3.2105068844892877

Epoch: 6| Step: 2
Training loss: 3.6800485097756197
Validation loss: 3.2117394764998313

Epoch: 6| Step: 3
Training loss: 4.239897670230771
Validation loss: 3.207792051595871

Epoch: 6| Step: 4
Training loss: 3.74962003690275
Validation loss: 3.209067101078492

Epoch: 6| Step: 5
Training loss: 3.452792466666813
Validation loss: 3.2064787196476896

Epoch: 6| Step: 6
Training loss: 3.4951135039010346
Validation loss: 3.207655592312802

Epoch: 6| Step: 7
Training loss: 3.1897966675246505
Validation loss: 3.203614566025612

Epoch: 6| Step: 8
Training loss: 3.788023879075641
Validation loss: 3.2051369595782777

Epoch: 6| Step: 9
Training loss: 2.840084858016116
Validation loss: 3.2030481144691323

Epoch: 6| Step: 10
Training loss: 2.7349415219486874
Validation loss: 3.2019490914557944

Epoch: 6| Step: 11
Training loss: 4.017853233698805
Validation loss: 3.2025509651820827

Epoch: 6| Step: 12
Training loss: 2.818134174615406
Validation loss: 3.2021954892278623

Epoch: 6| Step: 13
Training loss: 3.801574561511127
Validation loss: 3.2004326294631844

Epoch: 56| Step: 0
Training loss: 3.3433649429647527
Validation loss: 3.2002633883024973

Epoch: 6| Step: 1
Training loss: 2.9247472996248063
Validation loss: 3.1999234771038916

Epoch: 6| Step: 2
Training loss: 3.4854972640023925
Validation loss: 3.198976021732308

Epoch: 6| Step: 3
Training loss: 3.277478475609116
Validation loss: 3.19923798354493

Epoch: 6| Step: 4
Training loss: 3.597468964613174
Validation loss: 3.1974161861461114

Epoch: 6| Step: 5
Training loss: 3.4289381733657924
Validation loss: 3.197719349167714

Epoch: 6| Step: 6
Training loss: 2.8802404327167457
Validation loss: 3.195080883108918

Epoch: 6| Step: 7
Training loss: 2.7567013671548355
Validation loss: 3.194012154649418

Epoch: 6| Step: 8
Training loss: 3.432252242113218
Validation loss: 3.197276621179655

Epoch: 6| Step: 9
Training loss: 3.649444375793959
Validation loss: 3.1943732570428254

Epoch: 6| Step: 10
Training loss: 4.313403048848601
Validation loss: 3.194569284021789

Epoch: 6| Step: 11
Training loss: 4.294242135486596
Validation loss: 3.195186784713604

Epoch: 6| Step: 12
Training loss: 3.127767329389588
Validation loss: 3.1946640578210395

Epoch: 6| Step: 13
Training loss: 3.5299731621519017
Validation loss: 3.191328451539034

Epoch: 57| Step: 0
Training loss: 4.440314246733131
Validation loss: 3.1888219403253317

Epoch: 6| Step: 1
Training loss: 3.1083025592443034
Validation loss: 3.189273957475513

Epoch: 6| Step: 2
Training loss: 3.7376230072907175
Validation loss: 3.191591674014478

Epoch: 6| Step: 3
Training loss: 3.48197190420526
Validation loss: 3.1878934911314762

Epoch: 6| Step: 4
Training loss: 3.9618251189717384
Validation loss: 3.1874367862282735

Epoch: 6| Step: 5
Training loss: 3.686585781757604
Validation loss: 3.18857524316917

Epoch: 6| Step: 6
Training loss: 2.881155969901732
Validation loss: 3.1902351033418044

Epoch: 6| Step: 7
Training loss: 2.900346564269707
Validation loss: 3.1864823694062796

Epoch: 6| Step: 8
Training loss: 3.4841274293266915
Validation loss: 3.1916305397508204

Epoch: 6| Step: 9
Training loss: 2.992628418629641
Validation loss: 3.21476847888536

Epoch: 6| Step: 10
Training loss: 3.145880103026755
Validation loss: 3.232345909200285

Epoch: 6| Step: 11
Training loss: 3.146605457933668
Validation loss: 3.214510537348733

Epoch: 6| Step: 12
Training loss: 3.553118483135652
Validation loss: 3.1983639753421653

Epoch: 6| Step: 13
Training loss: 3.446931143032824
Validation loss: 3.1869632591556276

Epoch: 58| Step: 0
Training loss: 3.791925414482598
Validation loss: 3.1821586321006246

Epoch: 6| Step: 1
Training loss: 3.5975385516170766
Validation loss: 3.180465338247025

Epoch: 6| Step: 2
Training loss: 2.90864628271246
Validation loss: 3.180755246488443

Epoch: 6| Step: 3
Training loss: 3.9840845338746367
Validation loss: 3.180898113771709

Epoch: 6| Step: 4
Training loss: 3.792348667613257
Validation loss: 3.18017701584052

Epoch: 6| Step: 5
Training loss: 3.733913504842541
Validation loss: 3.1804031389524767

Epoch: 6| Step: 6
Training loss: 3.91376571900663
Validation loss: 3.179718079512757

Epoch: 6| Step: 7
Training loss: 2.9855667051709616
Validation loss: 3.179708149749622

Epoch: 6| Step: 8
Training loss: 2.7275299716774746
Validation loss: 3.178527909226876

Epoch: 6| Step: 9
Training loss: 3.4366800890961673
Validation loss: 3.177131148687415

Epoch: 6| Step: 10
Training loss: 3.326828968418338
Validation loss: 3.176386910209973

Epoch: 6| Step: 11
Training loss: 3.160135276168424
Validation loss: 3.1758403060441793

Epoch: 6| Step: 12
Training loss: 3.1086875884107217
Validation loss: 3.1750359328819395

Epoch: 6| Step: 13
Training loss: 3.473563076946196
Validation loss: 3.1744836522228255

Epoch: 59| Step: 0
Training loss: 3.731625873796475
Validation loss: 3.173790089722464

Epoch: 6| Step: 1
Training loss: 3.7155667312455014
Validation loss: 3.1734309453455207

Epoch: 6| Step: 2
Training loss: 3.9092067667061103
Validation loss: 3.172729196122551

Epoch: 6| Step: 3
Training loss: 3.7573513453881886
Validation loss: 3.1719100758655814

Epoch: 6| Step: 4
Training loss: 3.1655492986305784
Validation loss: 3.171170671987153

Epoch: 6| Step: 5
Training loss: 3.347205257416748
Validation loss: 3.1704750820991925

Epoch: 6| Step: 6
Training loss: 3.1911842147555323
Validation loss: 3.16968775895031

Epoch: 6| Step: 7
Training loss: 3.864447715552668
Validation loss: 3.169160526901485

Epoch: 6| Step: 8
Training loss: 2.868219756279581
Validation loss: 3.168295221859843

Epoch: 6| Step: 9
Training loss: 3.190194580457694
Validation loss: 3.1674843128159478

Epoch: 6| Step: 10
Training loss: 3.9451326536979003
Validation loss: 3.166986014342195

Epoch: 6| Step: 11
Training loss: 3.181059520242538
Validation loss: 3.166347024995136

Epoch: 6| Step: 12
Training loss: 3.077493050859478
Validation loss: 3.1657073122649195

Epoch: 6| Step: 13
Training loss: 2.403957910140697
Validation loss: 3.1651101315853385

Epoch: 60| Step: 0
Training loss: 3.221506364455235
Validation loss: 3.1649330706805543

Epoch: 6| Step: 1
Training loss: 3.691996790561128
Validation loss: 3.1642536356266273

Epoch: 6| Step: 2
Training loss: 3.3826653358217276
Validation loss: 3.1637607225459132

Epoch: 6| Step: 3
Training loss: 2.7931822368419192
Validation loss: 3.162882411134637

Epoch: 6| Step: 4
Training loss: 3.135516210519905
Validation loss: 3.162314506011976

Epoch: 6| Step: 5
Training loss: 3.7833947018478926
Validation loss: 3.161825164684409

Epoch: 6| Step: 6
Training loss: 3.163418928086382
Validation loss: 3.1611491733286683

Epoch: 6| Step: 7
Training loss: 2.7211845284235934
Validation loss: 3.1606296679704315

Epoch: 6| Step: 8
Training loss: 4.35254815545522
Validation loss: 3.1602022777187564

Epoch: 6| Step: 9
Training loss: 3.551222770610696
Validation loss: 3.159608210825434

Epoch: 6| Step: 10
Training loss: 3.72794442774729
Validation loss: 3.1588461429051162

Epoch: 6| Step: 11
Training loss: 3.0547141930079738
Validation loss: 3.1580415731913503

Epoch: 6| Step: 12
Training loss: 3.777106671156886
Validation loss: 3.1574381100131403

Epoch: 6| Step: 13
Training loss: 3.184502931669865
Validation loss: 3.156894162841943

Epoch: 61| Step: 0
Training loss: 2.6881759148436526
Validation loss: 3.157552110396921

Epoch: 6| Step: 1
Training loss: 2.996397398441129
Validation loss: 3.1561448550714575

Epoch: 6| Step: 2
Training loss: 3.310497182287444
Validation loss: 3.1553152741620405

Epoch: 6| Step: 3
Training loss: 2.912238237790635
Validation loss: 3.154735530392213

Epoch: 6| Step: 4
Training loss: 3.0218864622164983
Validation loss: 3.154293970246195

Epoch: 6| Step: 5
Training loss: 3.989727777932273
Validation loss: 3.1539000237872274

Epoch: 6| Step: 6
Training loss: 3.675802913849218
Validation loss: 3.1532440768294983

Epoch: 6| Step: 7
Training loss: 3.686599362835694
Validation loss: 3.1526495249543314

Epoch: 6| Step: 8
Training loss: 3.4524931869052895
Validation loss: 3.152136581816222

Epoch: 6| Step: 9
Training loss: 3.52362114201479
Validation loss: 3.1514251879668223

Epoch: 6| Step: 10
Training loss: 4.068808484572708
Validation loss: 3.150910632260686

Epoch: 6| Step: 11
Training loss: 3.9087687192248435
Validation loss: 3.15008369649733

Epoch: 6| Step: 12
Training loss: 3.113690166350269
Validation loss: 3.149546876106793

Epoch: 6| Step: 13
Training loss: 3.056112205971947
Validation loss: 3.1488632060505255

Epoch: 62| Step: 0
Training loss: 2.996782166571644
Validation loss: 3.1484986078464567

Epoch: 6| Step: 1
Training loss: 2.8189404814446237
Validation loss: 3.1475069814535166

Epoch: 6| Step: 2
Training loss: 3.9651357458672583
Validation loss: 3.146617573792171

Epoch: 6| Step: 3
Training loss: 4.004772200564967
Validation loss: 3.1462869988685855

Epoch: 6| Step: 4
Training loss: 3.3817345573437616
Validation loss: 3.1459951399211556

Epoch: 6| Step: 5
Training loss: 2.7116909244376903
Validation loss: 3.145161755406398

Epoch: 6| Step: 6
Training loss: 2.914621089957057
Validation loss: 3.1445183931726204

Epoch: 6| Step: 7
Training loss: 2.6892809622296876
Validation loss: 3.143834180847933

Epoch: 6| Step: 8
Training loss: 3.7656324711009264
Validation loss: 3.144440546691261

Epoch: 6| Step: 9
Training loss: 3.435525222892259
Validation loss: 3.1424964011030068

Epoch: 6| Step: 10
Training loss: 3.581792026797477
Validation loss: 3.1421158052693254

Epoch: 6| Step: 11
Training loss: 3.986208983551524
Validation loss: 3.142690505959976

Epoch: 6| Step: 12
Training loss: 4.03861952811491
Validation loss: 3.1408871728145527

Epoch: 6| Step: 13
Training loss: 2.690820638564254
Validation loss: 3.139974939165184

Epoch: 63| Step: 0
Training loss: 3.920815617314906
Validation loss: 3.139565265523316

Epoch: 6| Step: 1
Training loss: 3.2072304815931996
Validation loss: 3.139320995426363

Epoch: 6| Step: 2
Training loss: 3.5444397485503285
Validation loss: 3.137976041765277

Epoch: 6| Step: 3
Training loss: 2.8847965349880065
Validation loss: 3.1383388040425966

Epoch: 6| Step: 4
Training loss: 3.549643624913859
Validation loss: 3.1369246407601947

Epoch: 6| Step: 5
Training loss: 3.596569116546381
Validation loss: 3.137650278248896

Epoch: 6| Step: 6
Training loss: 3.05099334174936
Validation loss: 3.1360264236568782

Epoch: 6| Step: 7
Training loss: 3.85518279556327
Validation loss: 3.1351225588326974

Epoch: 6| Step: 8
Training loss: 3.12350275411373
Validation loss: 3.134899963663279

Epoch: 6| Step: 9
Training loss: 3.6336363155715423
Validation loss: 3.134649948640126

Epoch: 6| Step: 10
Training loss: 3.5206272734586097
Validation loss: 3.1328318466429153

Epoch: 6| Step: 11
Training loss: 3.447588041535442
Validation loss: 3.1331548038625

Epoch: 6| Step: 12
Training loss: 2.9472950705744116
Validation loss: 3.133443614216376

Epoch: 6| Step: 13
Training loss: 3.1135639746743036
Validation loss: 3.132141977681784

Epoch: 64| Step: 0
Training loss: 3.573338935003113
Validation loss: 3.131641914629483

Epoch: 6| Step: 1
Training loss: 3.3733831700751096
Validation loss: 3.130263475571862

Epoch: 6| Step: 2
Training loss: 3.687233349485705
Validation loss: 3.1300781631342263

Epoch: 6| Step: 3
Training loss: 4.210471840556256
Validation loss: 3.129102031920183

Epoch: 6| Step: 4
Training loss: 3.606741600973972
Validation loss: 3.128981893908165

Epoch: 6| Step: 5
Training loss: 3.5293247071917238
Validation loss: 3.1272752940764814

Epoch: 6| Step: 6
Training loss: 3.3121484533938594
Validation loss: 3.125684795206829

Epoch: 6| Step: 7
Training loss: 3.4021252497379906
Validation loss: 3.124582941261193

Epoch: 6| Step: 8
Training loss: 3.4365110882219856
Validation loss: 3.1239935913553807

Epoch: 6| Step: 9
Training loss: 2.014970540098743
Validation loss: 3.1244062323116175

Epoch: 6| Step: 10
Training loss: 3.1685639938145402
Validation loss: 3.1229258711265486

Epoch: 6| Step: 11
Training loss: 3.4057157604986052
Validation loss: 3.123254335186479

Epoch: 6| Step: 12
Training loss: 3.0835767770149802
Validation loss: 3.1222510956974623

Epoch: 6| Step: 13
Training loss: 3.383361067133643
Validation loss: 3.120947083772649

Epoch: 65| Step: 0
Training loss: 3.1632232683312917
Validation loss: 3.121585972900528

Epoch: 6| Step: 1
Training loss: 3.568223070569952
Validation loss: 3.1216524747219276

Epoch: 6| Step: 2
Training loss: 2.914425579289057
Validation loss: 3.1218083299405603

Epoch: 6| Step: 3
Training loss: 4.257298653770085
Validation loss: 3.120510016904245

Epoch: 6| Step: 4
Training loss: 3.1651311129490676
Validation loss: 3.1190817578874395

Epoch: 6| Step: 5
Training loss: 3.117347043957131
Validation loss: 3.1150969793995698

Epoch: 6| Step: 6
Training loss: 3.5694724666090885
Validation loss: 3.11761520691403

Epoch: 6| Step: 7
Training loss: 3.791093482545108
Validation loss: 3.116320378182685

Epoch: 6| Step: 8
Training loss: 3.565202725118364
Validation loss: 3.122403073610565

Epoch: 6| Step: 9
Training loss: 3.457933762842071
Validation loss: 3.1182435597627265

Epoch: 6| Step: 10
Training loss: 3.177936343554811
Validation loss: 3.1185569324148963

Epoch: 6| Step: 11
Training loss: 3.8508510590237295
Validation loss: 3.1137527382803536

Epoch: 6| Step: 12
Training loss: 2.6769601716878837
Validation loss: 3.1130480393893083

Epoch: 6| Step: 13
Training loss: 2.3525977406481924
Validation loss: 3.1138778042718944

Epoch: 66| Step: 0
Training loss: 3.75091770387139
Validation loss: 3.112077380999937

Epoch: 6| Step: 1
Training loss: 3.1408003573071066
Validation loss: 3.113264889593764

Epoch: 6| Step: 2
Training loss: 3.0438646361521684
Validation loss: 3.1111239006606795

Epoch: 6| Step: 3
Training loss: 3.6580444888104764
Validation loss: 3.1097366008144522

Epoch: 6| Step: 4
Training loss: 3.214259005238811
Validation loss: 3.111130417035328

Epoch: 6| Step: 5
Training loss: 3.6510611990253357
Validation loss: 3.1107015481766807

Epoch: 6| Step: 6
Training loss: 2.816184618479209
Validation loss: 3.1085962680886374

Epoch: 6| Step: 7
Training loss: 3.5632109350933394
Validation loss: 3.1072988460704614

Epoch: 6| Step: 8
Training loss: 3.575191444659544
Validation loss: 3.1085752300739613

Epoch: 6| Step: 9
Training loss: 3.496424892662403
Validation loss: 3.108328320063359

Epoch: 6| Step: 10
Training loss: 3.797270075333649
Validation loss: 3.1067112386423035

Epoch: 6| Step: 11
Training loss: 3.0041987917836264
Validation loss: 3.1047395000207665

Epoch: 6| Step: 12
Training loss: 3.2771508179393436
Validation loss: 3.1062440882163727

Epoch: 6| Step: 13
Training loss: 3.13629094267021
Validation loss: 3.103698340566668

Epoch: 67| Step: 0
Training loss: 3.5577140918469223
Validation loss: 3.102024237311861

Epoch: 6| Step: 1
Training loss: 3.648516701077575
Validation loss: 3.1045920892665917

Epoch: 6| Step: 2
Training loss: 3.671902530648121
Validation loss: 3.1028479658541492

Epoch: 6| Step: 3
Training loss: 3.832758501048032
Validation loss: 3.1027336642248557

Epoch: 6| Step: 4
Training loss: 3.0024721767842046
Validation loss: 3.0994488385932226

Epoch: 6| Step: 5
Training loss: 3.4323217055878392
Validation loss: 3.0996214603434757

Epoch: 6| Step: 6
Training loss: 3.2158962302191276
Validation loss: 3.102199350300988

Epoch: 6| Step: 7
Training loss: 3.639944381288944
Validation loss: 3.100555745026988

Epoch: 6| Step: 8
Training loss: 2.780144632542783
Validation loss: 3.10170874138898

Epoch: 6| Step: 9
Training loss: 3.9029205781839598
Validation loss: 3.1056520192934585

Epoch: 6| Step: 10
Training loss: 3.421206474320017
Validation loss: 3.1064029018414057

Epoch: 6| Step: 11
Training loss: 2.8214465790875822
Validation loss: 3.1019887232772874

Epoch: 6| Step: 12
Training loss: 2.8711894116716357
Validation loss: 3.1063876193376334

Epoch: 6| Step: 13
Training loss: 2.9828699920692827
Validation loss: 3.1074339976095247

Epoch: 68| Step: 0
Training loss: 3.5299561417316263
Validation loss: 3.102216942538282

Epoch: 6| Step: 1
Training loss: 3.991332319003906
Validation loss: 3.0970685455894156

Epoch: 6| Step: 2
Training loss: 2.9899160662961917
Validation loss: 3.0983990272156947

Epoch: 6| Step: 3
Training loss: 2.9710485293939026
Validation loss: 3.0993892360101807

Epoch: 6| Step: 4
Training loss: 3.158957047554762
Validation loss: 3.0986330789053143

Epoch: 6| Step: 5
Training loss: 2.9075695036750493
Validation loss: 3.093217398883337

Epoch: 6| Step: 6
Training loss: 3.962729144766303
Validation loss: 3.09045749298592

Epoch: 6| Step: 7
Training loss: 2.953239801991021
Validation loss: 3.0930783647030515

Epoch: 6| Step: 8
Training loss: 2.701784451988371
Validation loss: 3.0990053505078436

Epoch: 6| Step: 9
Training loss: 3.2036659342214224
Validation loss: 3.0985909551419653

Epoch: 6| Step: 10
Training loss: 3.9961198822688435
Validation loss: 3.09192136233895

Epoch: 6| Step: 11
Training loss: 4.04175045804868
Validation loss: 3.096298934427491

Epoch: 6| Step: 12
Training loss: 3.2682963127543787
Validation loss: 3.093222244839221

Epoch: 6| Step: 13
Training loss: 2.786290519628513
Validation loss: 3.0880797815736694

Epoch: 69| Step: 0
Training loss: 2.9505306736422034
Validation loss: 3.08904820259418

Epoch: 6| Step: 1
Training loss: 2.9109059437030833
Validation loss: 3.088061196433495

Epoch: 6| Step: 2
Training loss: 3.7984952256128883
Validation loss: 3.0861931026882496

Epoch: 6| Step: 3
Training loss: 3.468567302119637
Validation loss: 3.0876431552234354

Epoch: 6| Step: 4
Training loss: 2.7276408077156216
Validation loss: 3.085516035386398

Epoch: 6| Step: 5
Training loss: 3.302404891441478
Validation loss: 3.084370882247013

Epoch: 6| Step: 6
Training loss: 3.240625359030311
Validation loss: 3.083472133750555

Epoch: 6| Step: 7
Training loss: 3.982247296857039
Validation loss: 3.085570139038878

Epoch: 6| Step: 8
Training loss: 3.157876077396076
Validation loss: 3.0816502610053664

Epoch: 6| Step: 9
Training loss: 3.193014125067545
Validation loss: 3.0838070239240363

Epoch: 6| Step: 10
Training loss: 3.7667776535922
Validation loss: 3.082630593441928

Epoch: 6| Step: 11
Training loss: 3.739950574660489
Validation loss: 3.0813651938665716

Epoch: 6| Step: 12
Training loss: 3.511483970660908
Validation loss: 3.0841138451031056

Epoch: 6| Step: 13
Training loss: 2.7707175228229377
Validation loss: 3.081297810900828

Epoch: 70| Step: 0
Training loss: 2.8399374420368164
Validation loss: 3.0816378581069475

Epoch: 6| Step: 1
Training loss: 3.440851277213512
Validation loss: 3.079555698894874

Epoch: 6| Step: 2
Training loss: 2.9461299662360623
Validation loss: 3.077761645973432

Epoch: 6| Step: 3
Training loss: 3.0970946448660257
Validation loss: 3.077786719518737

Epoch: 6| Step: 4
Training loss: 3.6240843570145844
Validation loss: 3.0746011334756

Epoch: 6| Step: 5
Training loss: 2.1547547836808274
Validation loss: 3.0749655112616705

Epoch: 6| Step: 6
Training loss: 4.196185768779013
Validation loss: 3.0744136200188192

Epoch: 6| Step: 7
Training loss: 3.2174368837178466
Validation loss: 3.071896630720727

Epoch: 6| Step: 8
Training loss: 3.2469551788798663
Validation loss: 3.076257180110141

Epoch: 6| Step: 9
Training loss: 4.032795454578226
Validation loss: 3.0796836137233314

Epoch: 6| Step: 10
Training loss: 3.8505056916093143
Validation loss: 3.0849602760140993

Epoch: 6| Step: 11
Training loss: 2.940670493865508
Validation loss: 3.0698751212000466

Epoch: 6| Step: 12
Training loss: 3.0693531818736868
Validation loss: 3.070664180564265

Epoch: 6| Step: 13
Training loss: 3.8736443147770787
Validation loss: 3.071536963512596

Epoch: 71| Step: 0
Training loss: 3.7976779167280763
Validation loss: 3.0710614398952463

Epoch: 6| Step: 1
Training loss: 3.1647842902608443
Validation loss: 3.0698684805089504

Epoch: 6| Step: 2
Training loss: 3.978201118214474
Validation loss: 3.070183256183904

Epoch: 6| Step: 3
Training loss: 3.1150364540869386
Validation loss: 3.070337552550779

Epoch: 6| Step: 4
Training loss: 3.0606470535913997
Validation loss: 3.0695261247376973

Epoch: 6| Step: 5
Training loss: 3.316328319626929
Validation loss: 3.066796201437521

Epoch: 6| Step: 6
Training loss: 3.408579038858854
Validation loss: 3.0667386041762272

Epoch: 6| Step: 7
Training loss: 3.003583992487435
Validation loss: 3.069052316879944

Epoch: 6| Step: 8
Training loss: 4.063480904340086
Validation loss: 3.068780479198757

Epoch: 6| Step: 9
Training loss: 3.8409406117935743
Validation loss: 3.068215615694155

Epoch: 6| Step: 10
Training loss: 2.6001661981135937
Validation loss: 3.068670330530109

Epoch: 6| Step: 11
Training loss: 3.2443508054844887
Validation loss: 3.0653059332940247

Epoch: 6| Step: 12
Training loss: 3.0396611817927432
Validation loss: 3.0680514019371574

Epoch: 6| Step: 13
Training loss: 2.251779911893355
Validation loss: 3.066744016948755

Epoch: 72| Step: 0
Training loss: 2.922737850955873
Validation loss: 3.066994976867215

Epoch: 6| Step: 1
Training loss: 4.195939853582605
Validation loss: 3.065524864461751

Epoch: 6| Step: 2
Training loss: 3.463531417640303
Validation loss: 3.0661148157484037

Epoch: 6| Step: 3
Training loss: 3.00853136067769
Validation loss: 3.0657449206009586

Epoch: 6| Step: 4
Training loss: 2.5213887782335744
Validation loss: 3.0669350135729108

Epoch: 6| Step: 5
Training loss: 2.612235231991384
Validation loss: 3.0701296880105735

Epoch: 6| Step: 6
Training loss: 3.187685792781493
Validation loss: 3.0739810305113173

Epoch: 6| Step: 7
Training loss: 3.6457195736530252
Validation loss: 3.069487968799089

Epoch: 6| Step: 8
Training loss: 3.84756007969915
Validation loss: 3.067247735814275

Epoch: 6| Step: 9
Training loss: 3.7391702039472494
Validation loss: 3.059054913332812

Epoch: 6| Step: 10
Training loss: 2.737265840731754
Validation loss: 3.0572527411476234

Epoch: 6| Step: 11
Training loss: 3.6731445714933164
Validation loss: 3.0556830191913433

Epoch: 6| Step: 12
Training loss: 3.1900443599570294
Validation loss: 3.05436207597026

Epoch: 6| Step: 13
Training loss: 3.535784080774296
Validation loss: 3.0533557300142062

Epoch: 73| Step: 0
Training loss: 3.623502092990663
Validation loss: 3.055180432874673

Epoch: 6| Step: 1
Training loss: 2.86190983714627
Validation loss: 3.054889815871587

Epoch: 6| Step: 2
Training loss: 3.562033639465192
Validation loss: 3.054846133071834

Epoch: 6| Step: 3
Training loss: 3.4231484190547383
Validation loss: 3.0553476215012787

Epoch: 6| Step: 4
Training loss: 3.0979519446766566
Validation loss: 3.052802917484845

Epoch: 6| Step: 5
Training loss: 3.2750487811699798
Validation loss: 3.052633345929186

Epoch: 6| Step: 6
Training loss: 3.245176109860417
Validation loss: 3.0538784718487504

Epoch: 6| Step: 7
Training loss: 4.099668926735169
Validation loss: 3.0520891419600105

Epoch: 6| Step: 8
Training loss: 2.8116753110845067
Validation loss: 3.053176336985899

Epoch: 6| Step: 9
Training loss: 3.4733669038737878
Validation loss: 3.054972518012638

Epoch: 6| Step: 10
Training loss: 2.9984519461183887
Validation loss: 3.060754837530479

Epoch: 6| Step: 11
Training loss: 2.4251255986044
Validation loss: 3.064295229374008

Epoch: 6| Step: 12
Training loss: 3.569068074123077
Validation loss: 3.0660067469759675

Epoch: 6| Step: 13
Training loss: 4.168192978094551
Validation loss: 3.067540936978166

Epoch: 74| Step: 0
Training loss: 3.467179363803334
Validation loss: 3.0519321304381024

Epoch: 6| Step: 1
Training loss: 3.9022556482093704
Validation loss: 3.0472920483910544

Epoch: 6| Step: 2
Training loss: 3.104912550918711
Validation loss: 3.045351164950384

Epoch: 6| Step: 3
Training loss: 3.001403003686701
Validation loss: 3.044757082733207

Epoch: 6| Step: 4
Training loss: 2.8611491384931678
Validation loss: 3.044880064828971

Epoch: 6| Step: 5
Training loss: 4.111340187036937
Validation loss: 3.048406412456584

Epoch: 6| Step: 6
Training loss: 3.0977119739037393
Validation loss: 3.0501017398363466

Epoch: 6| Step: 7
Training loss: 2.502746218097662
Validation loss: 3.0714799467660527

Epoch: 6| Step: 8
Training loss: 3.278234349437072
Validation loss: 3.079016738348237

Epoch: 6| Step: 9
Training loss: 3.0442894553514237
Validation loss: 3.0737356661195405

Epoch: 6| Step: 10
Training loss: 4.140730946462966
Validation loss: 3.044576202083205

Epoch: 6| Step: 11
Training loss: 2.641462565659186
Validation loss: 3.0482903604241365

Epoch: 6| Step: 12
Training loss: 3.39413340951155
Validation loss: 3.0632833015269383

Epoch: 6| Step: 13
Training loss: 3.7562918966943166
Validation loss: 3.0576835328500533

Epoch: 75| Step: 0
Training loss: 2.8286823545451405
Validation loss: 3.045210253478258

Epoch: 6| Step: 1
Training loss: 3.8429684968759448
Validation loss: 3.0473044632063044

Epoch: 6| Step: 2
Training loss: 2.9768180036644694
Validation loss: 3.051511082095986

Epoch: 6| Step: 3
Training loss: 3.0960619986188895
Validation loss: 3.051777415931661

Epoch: 6| Step: 4
Training loss: 3.3996000559575106
Validation loss: 3.0426396611604654

Epoch: 6| Step: 5
Training loss: 3.5520330222287373
Validation loss: 3.056083205714449

Epoch: 6| Step: 6
Training loss: 3.2359986583579623
Validation loss: 3.0457446336165037

Epoch: 6| Step: 7
Training loss: 3.638707650664504
Validation loss: 3.04630497390186

Epoch: 6| Step: 8
Training loss: 2.9761297757452776
Validation loss: 3.040797062214128

Epoch: 6| Step: 9
Training loss: 3.7037244866812364
Validation loss: 3.0385463221515296

Epoch: 6| Step: 10
Training loss: 3.605582354275708
Validation loss: 3.0426012025962814

Epoch: 6| Step: 11
Training loss: 3.258773113208273
Validation loss: 3.036968121638231

Epoch: 6| Step: 12
Training loss: 3.0271210225527265
Validation loss: 3.033687936868564

Epoch: 6| Step: 13
Training loss: 2.899172954356967
Validation loss: 3.0308844131596797

Epoch: 76| Step: 0
Training loss: 3.09852139681116
Validation loss: 3.0326368565333186

Epoch: 6| Step: 1
Training loss: 3.2378627382417458
Validation loss: 3.0341879558808014

Epoch: 6| Step: 2
Training loss: 3.7401030594604934
Validation loss: 3.0366179248890033

Epoch: 6| Step: 3
Training loss: 2.8403361862962777
Validation loss: 3.0385022331159295

Epoch: 6| Step: 4
Training loss: 3.3237176645233206
Validation loss: 3.0355489558106212

Epoch: 6| Step: 5
Training loss: 3.295749562609902
Validation loss: 3.028641865388157

Epoch: 6| Step: 6
Training loss: 3.97445221011442
Validation loss: 3.0279668677313287

Epoch: 6| Step: 7
Training loss: 3.470223053900605
Validation loss: 3.0263669257455788

Epoch: 6| Step: 8
Training loss: 3.0419122431309007
Validation loss: 3.0264438322866756

Epoch: 6| Step: 9
Training loss: 3.662693052444245
Validation loss: 3.0266166198551487

Epoch: 6| Step: 10
Training loss: 3.184513562962235
Validation loss: 3.0249333248114323

Epoch: 6| Step: 11
Training loss: 3.571918552029705
Validation loss: 3.0266042057310862

Epoch: 6| Step: 12
Training loss: 2.835502990559639
Validation loss: 3.0310986075840436

Epoch: 6| Step: 13
Training loss: 2.333937385117983
Validation loss: 3.02914465882291

Epoch: 77| Step: 0
Training loss: 2.955299827997873
Validation loss: 3.033833430303549

Epoch: 6| Step: 1
Training loss: 4.145354711358655
Validation loss: 3.04726419584622

Epoch: 6| Step: 2
Training loss: 2.7057721180791194
Validation loss: 3.0337840572521464

Epoch: 6| Step: 3
Training loss: 3.5874813969890735
Validation loss: 3.0307118283049364

Epoch: 6| Step: 4
Training loss: 2.9819218804138905
Validation loss: 3.030100694321585

Epoch: 6| Step: 5
Training loss: 3.702973825451314
Validation loss: 3.031265123433397

Epoch: 6| Step: 6
Training loss: 2.986779168286444
Validation loss: 3.0413748235488054

Epoch: 6| Step: 7
Training loss: 2.8461390929127224
Validation loss: 3.0523912010715666

Epoch: 6| Step: 8
Training loss: 2.9468038410806408
Validation loss: 3.0433201113174198

Epoch: 6| Step: 9
Training loss: 3.2440766862772765
Validation loss: 3.037742697012222

Epoch: 6| Step: 10
Training loss: 3.3124494728697282
Validation loss: 3.029487692977504

Epoch: 6| Step: 11
Training loss: 3.537837003689239
Validation loss: 3.037079666562693

Epoch: 6| Step: 12
Training loss: 3.39275043864715
Validation loss: 3.0270430805045923

Epoch: 6| Step: 13
Training loss: 3.8748056916772478
Validation loss: 3.0214038133402528

Epoch: 78| Step: 0
Training loss: 3.2716317305899554
Validation loss: 3.022865968272313

Epoch: 6| Step: 1
Training loss: 2.8074634808469123
Validation loss: 3.0215312399096828

Epoch: 6| Step: 2
Training loss: 2.542671713642832
Validation loss: 3.024851900694299

Epoch: 6| Step: 3
Training loss: 4.251809352113948
Validation loss: 3.0213145505354637

Epoch: 6| Step: 4
Training loss: 3.781302964020853
Validation loss: 3.0228269935278824

Epoch: 6| Step: 5
Training loss: 2.7653867112430635
Validation loss: 3.0193703242711085

Epoch: 6| Step: 6
Training loss: 3.7147449115235935
Validation loss: 3.0217492796633247

Epoch: 6| Step: 7
Training loss: 3.479686096766668
Validation loss: 3.014957077509096

Epoch: 6| Step: 8
Training loss: 3.1026154467599802
Validation loss: 3.014382973448776

Epoch: 6| Step: 9
Training loss: 3.5986740213464823
Validation loss: 3.0138376822091923

Epoch: 6| Step: 10
Training loss: 2.692884241454191
Validation loss: 3.015273130447389

Epoch: 6| Step: 11
Training loss: 2.979829692198337
Validation loss: 3.015843632524824

Epoch: 6| Step: 12
Training loss: 3.612829099666016
Validation loss: 3.015373007347188

Epoch: 6| Step: 13
Training loss: 2.8505636895864424
Validation loss: 3.0275422061967583

Epoch: 79| Step: 0
Training loss: 3.230739153208476
Validation loss: 3.0542682198087374

Epoch: 6| Step: 1
Training loss: 2.596131483889178
Validation loss: 3.0446703873268848

Epoch: 6| Step: 2
Training loss: 3.041598401980153
Validation loss: 3.011889941159242

Epoch: 6| Step: 3
Training loss: 3.132586007242808
Validation loss: 3.0087426543521336

Epoch: 6| Step: 4
Training loss: 3.741934813567283
Validation loss: 3.010845399196755

Epoch: 6| Step: 5
Training loss: 3.392788807460436
Validation loss: 3.0110308672095956

Epoch: 6| Step: 6
Training loss: 4.081458121772203
Validation loss: 3.0084918815313206

Epoch: 6| Step: 7
Training loss: 3.54031720351288
Validation loss: 3.006414218466524

Epoch: 6| Step: 8
Training loss: 3.691910901971127
Validation loss: 3.0109370686250596

Epoch: 6| Step: 9
Training loss: 3.2907607526028966
Validation loss: 3.013714188736383

Epoch: 6| Step: 10
Training loss: 2.7816264722817885
Validation loss: 3.0087598140156415

Epoch: 6| Step: 11
Training loss: 3.173018225991711
Validation loss: 3.0073580013482646

Epoch: 6| Step: 12
Training loss: 3.1760328880548228
Validation loss: 3.004450733553383

Epoch: 6| Step: 13
Training loss: 2.891855833551932
Validation loss: 3.0027752451078253

Epoch: 80| Step: 0
Training loss: 2.785726823184686
Validation loss: 3.004234605069082

Epoch: 6| Step: 1
Training loss: 3.167882652382752
Validation loss: 3.005652379601122

Epoch: 6| Step: 2
Training loss: 3.3136442115615594
Validation loss: 3.0038199647112678

Epoch: 6| Step: 3
Training loss: 3.0338202522357807
Validation loss: 3.003226446586278

Epoch: 6| Step: 4
Training loss: 2.7385635121662704
Validation loss: 3.0045061519346987

Epoch: 6| Step: 5
Training loss: 3.291211076586698
Validation loss: 3.005287282973053

Epoch: 6| Step: 6
Training loss: 2.5573352776335376
Validation loss: 3.0022498499674586

Epoch: 6| Step: 7
Training loss: 3.30189313049942
Validation loss: 3.0044195016009967

Epoch: 6| Step: 8
Training loss: 4.0546458688704545
Validation loss: 3.0074688254172988

Epoch: 6| Step: 9
Training loss: 3.8974331649521017
Validation loss: 3.014344640845907

Epoch: 6| Step: 10
Training loss: 2.8478839715189195
Validation loss: 3.0116602960321877

Epoch: 6| Step: 11
Training loss: 3.5365193979256353
Validation loss: 3.0149037474512244

Epoch: 6| Step: 12
Training loss: 3.045589860681721
Validation loss: 3.017884712057598

Epoch: 6| Step: 13
Training loss: 4.4832636821871805
Validation loss: 3.011969322247841

Epoch: 81| Step: 0
Training loss: 2.231775118372278
Validation loss: 3.0049590258684744

Epoch: 6| Step: 1
Training loss: 3.7794568562715423
Validation loss: 3.0021602943345727

Epoch: 6| Step: 2
Training loss: 2.612882894537918
Validation loss: 2.997888947744778

Epoch: 6| Step: 3
Training loss: 3.2111795524451745
Validation loss: 3.0020662373789717

Epoch: 6| Step: 4
Training loss: 4.824682100724034
Validation loss: 3.0004037154720398

Epoch: 6| Step: 5
Training loss: 2.7765901082243585
Validation loss: 2.99963321118469

Epoch: 6| Step: 6
Training loss: 3.543875345909643
Validation loss: 2.9957703816724464

Epoch: 6| Step: 7
Training loss: 3.0086944476055946
Validation loss: 2.993266551073084

Epoch: 6| Step: 8
Training loss: 3.401325270476356
Validation loss: 2.992182235950899

Epoch: 6| Step: 9
Training loss: 3.9104315997112784
Validation loss: 3.0060230034603466

Epoch: 6| Step: 10
Training loss: 2.724807042980892
Validation loss: 2.992370392538954

Epoch: 6| Step: 11
Training loss: 3.3072574803945907
Validation loss: 2.990425388880737

Epoch: 6| Step: 12
Training loss: 2.4917694984913954
Validation loss: 2.9893783782635763

Epoch: 6| Step: 13
Training loss: 3.198189109769487
Validation loss: 2.9891570492892736

Epoch: 82| Step: 0
Training loss: 3.2676439386957714
Validation loss: 2.988990266661937

Epoch: 6| Step: 1
Training loss: 3.389316007314237
Validation loss: 2.9896703942306315

Epoch: 6| Step: 2
Training loss: 3.7346176004814966
Validation loss: 2.989492113927651

Epoch: 6| Step: 3
Training loss: 3.0048098153913774
Validation loss: 2.989505509694931

Epoch: 6| Step: 4
Training loss: 3.614674826278492
Validation loss: 2.9903555212204256

Epoch: 6| Step: 5
Training loss: 2.6460928201462606
Validation loss: 2.988784553554987

Epoch: 6| Step: 6
Training loss: 3.4358438837292034
Validation loss: 2.9925105478686462

Epoch: 6| Step: 7
Training loss: 3.2553780880216787
Validation loss: 2.988196553673363

Epoch: 6| Step: 8
Training loss: 2.798362975456763
Validation loss: 2.985156472737356

Epoch: 6| Step: 9
Training loss: 2.4763787138221085
Validation loss: 2.9834088058214983

Epoch: 6| Step: 10
Training loss: 3.023610033735898
Validation loss: 2.987084560038866

Epoch: 6| Step: 11
Training loss: 3.301372046332504
Validation loss: 2.9822472059561687

Epoch: 6| Step: 12
Training loss: 4.1056346043151954
Validation loss: 2.980216327514334

Epoch: 6| Step: 13
Training loss: 3.409994324710184
Validation loss: 2.978482447855832

Epoch: 83| Step: 0
Training loss: 3.2482201030549986
Validation loss: 2.975272644639667

Epoch: 6| Step: 1
Training loss: 2.8222308199627224
Validation loss: 2.97869242438792

Epoch: 6| Step: 2
Training loss: 3.591373354329849
Validation loss: 2.9756385799669918

Epoch: 6| Step: 3
Training loss: 3.7740465387447633
Validation loss: 2.975165887862518

Epoch: 6| Step: 4
Training loss: 3.2028903782212628
Validation loss: 2.975587944930063

Epoch: 6| Step: 5
Training loss: 2.8844416287249572
Validation loss: 2.9722246355255186

Epoch: 6| Step: 6
Training loss: 2.6913945567371167
Validation loss: 2.9716195711483677

Epoch: 6| Step: 7
Training loss: 2.9392631596112238
Validation loss: 2.974569118129502

Epoch: 6| Step: 8
Training loss: 3.886073748106206
Validation loss: 2.9749715416776725

Epoch: 6| Step: 9
Training loss: 3.1400334194858948
Validation loss: 2.9777091098116637

Epoch: 6| Step: 10
Training loss: 3.109004779800957
Validation loss: 2.9723198506989235

Epoch: 6| Step: 11
Training loss: 3.175443849552783
Validation loss: 2.9728650746079675

Epoch: 6| Step: 12
Training loss: 3.4904285071657397
Validation loss: 2.9722851553716145

Epoch: 6| Step: 13
Training loss: 3.598185580036665
Validation loss: 2.9700291570460933

Epoch: 84| Step: 0
Training loss: 3.1240283218350378
Validation loss: 2.967835361103402

Epoch: 6| Step: 1
Training loss: 3.310470679202413
Validation loss: 2.95998704702353

Epoch: 6| Step: 2
Training loss: 3.867129670298354
Validation loss: 2.960228205818955

Epoch: 6| Step: 3
Training loss: 3.5843383946831944
Validation loss: 2.958081149892982

Epoch: 6| Step: 4
Training loss: 3.3722042230596716
Validation loss: 2.9564252977503735

Epoch: 6| Step: 5
Training loss: 2.6961980719378422
Validation loss: 2.966498534455017

Epoch: 6| Step: 6
Training loss: 2.8902978660434924
Validation loss: 2.964094899751683

Epoch: 6| Step: 7
Training loss: 3.608267081506292
Validation loss: 2.951913331012887

Epoch: 6| Step: 8
Training loss: 2.805546026140234
Validation loss: 2.9442075252377706

Epoch: 6| Step: 9
Training loss: 3.610596685366207
Validation loss: 2.9400584630432043

Epoch: 6| Step: 10
Training loss: 3.027000201020803
Validation loss: 2.947818822456985

Epoch: 6| Step: 11
Training loss: 2.8155867697843755
Validation loss: 2.946750728732585

Epoch: 6| Step: 12
Training loss: 3.5944578054246272
Validation loss: 2.950520125487858

Epoch: 6| Step: 13
Training loss: 2.290818201845146
Validation loss: 2.9466495455380577

Epoch: 85| Step: 0
Training loss: 2.7201495898008172
Validation loss: 2.9449210558666814

Epoch: 6| Step: 1
Training loss: 2.8231706587110152
Validation loss: 2.9364235606865114

Epoch: 6| Step: 2
Training loss: 3.6560078076085167
Validation loss: 2.9368380112866728

Epoch: 6| Step: 3
Training loss: 2.3194899208752755
Validation loss: 2.949218212796696

Epoch: 6| Step: 4
Training loss: 3.6196139870632944
Validation loss: 2.965780904464194

Epoch: 6| Step: 5
Training loss: 3.140730367382814
Validation loss: 2.9663467550209406

Epoch: 6| Step: 6
Training loss: 2.955988550218183
Validation loss: 2.95832895304315

Epoch: 6| Step: 7
Training loss: 3.6035013338131248
Validation loss: 2.944786564694184

Epoch: 6| Step: 8
Training loss: 3.548552935464119
Validation loss: 2.9357436110389687

Epoch: 6| Step: 9
Training loss: 3.3125987488044872
Validation loss: 2.9306052270043605

Epoch: 6| Step: 10
Training loss: 3.3052060417089604
Validation loss: 2.930189658605041

Epoch: 6| Step: 11
Training loss: 2.796647302320305
Validation loss: 2.9305206851050696

Epoch: 6| Step: 12
Training loss: 3.5696198106593044
Validation loss: 2.932782020340317

Epoch: 6| Step: 13
Training loss: 3.711976751065618
Validation loss: 2.937196014600979

Epoch: 86| Step: 0
Training loss: 3.7821752503861834
Validation loss: 2.935073414054697

Epoch: 6| Step: 1
Training loss: 3.8315541381595355
Validation loss: 2.932339312146413

Epoch: 6| Step: 2
Training loss: 2.904425263533251
Validation loss: 2.9308777946435707

Epoch: 6| Step: 3
Training loss: 3.522793662376936
Validation loss: 2.9285201439832074

Epoch: 6| Step: 4
Training loss: 3.5577615378260217
Validation loss: 2.9269165077938086

Epoch: 6| Step: 5
Training loss: 3.0700686603037872
Validation loss: 2.933176872712969

Epoch: 6| Step: 6
Training loss: 2.672734083409971
Validation loss: 2.9302027961647115

Epoch: 6| Step: 7
Training loss: 2.993178400251141
Validation loss: 2.9295788737842434

Epoch: 6| Step: 8
Training loss: 3.4107898940591483
Validation loss: 2.925464721382961

Epoch: 6| Step: 9
Training loss: 3.2643871242729685
Validation loss: 2.924636219612759

Epoch: 6| Step: 10
Training loss: 2.7251195723871224
Validation loss: 2.928154527598019

Epoch: 6| Step: 11
Training loss: 3.1560868324934095
Validation loss: 2.925500699319033

Epoch: 6| Step: 12
Training loss: 2.457976288379247
Validation loss: 2.922967453520068

Epoch: 6| Step: 13
Training loss: 3.324762069105413
Validation loss: 2.924863036645679

Epoch: 87| Step: 0
Training loss: 3.3174959331335168
Validation loss: 2.9232610951031424

Epoch: 6| Step: 1
Training loss: 3.0913188899809776
Validation loss: 2.9312529682155155

Epoch: 6| Step: 2
Training loss: 3.2566628748996282
Validation loss: 2.9506206198891873

Epoch: 6| Step: 3
Training loss: 3.970799915430616
Validation loss: 2.961040357698835

Epoch: 6| Step: 4
Training loss: 3.3413840506536214
Validation loss: 2.9284265415782733

Epoch: 6| Step: 5
Training loss: 3.029412725460438
Validation loss: 2.917732642255045

Epoch: 6| Step: 6
Training loss: 2.8651301931255357
Validation loss: 2.920456522730863

Epoch: 6| Step: 7
Training loss: 3.141875819791767
Validation loss: 2.9234591998585007

Epoch: 6| Step: 8
Training loss: 3.294719841353406
Validation loss: 2.929781574010447

Epoch: 6| Step: 9
Training loss: 3.093462073288915
Validation loss: 2.937644966264509

Epoch: 6| Step: 10
Training loss: 3.3980116303297074
Validation loss: 2.9330042959929528

Epoch: 6| Step: 11
Training loss: 3.000327728172446
Validation loss: 2.9320219902350804

Epoch: 6| Step: 12
Training loss: 3.1184331943242554
Validation loss: 2.9295460350310214

Epoch: 6| Step: 13
Training loss: 2.602041572701969
Validation loss: 2.916014666716811

Epoch: 88| Step: 0
Training loss: 3.1778463145811
Validation loss: 2.9154828061221547

Epoch: 6| Step: 1
Training loss: 2.8353523091998913
Validation loss: 2.9147869879815698

Epoch: 6| Step: 2
Training loss: 3.303743989775174
Validation loss: 2.9139991627346817

Epoch: 6| Step: 3
Training loss: 2.9636982550703324
Validation loss: 2.9153749925338657

Epoch: 6| Step: 4
Training loss: 2.959863150758126
Validation loss: 2.9134312238748596

Epoch: 6| Step: 5
Training loss: 3.537223826704711
Validation loss: 2.9103077640583157

Epoch: 6| Step: 6
Training loss: 3.6870879896780235
Validation loss: 2.912881309775146

Epoch: 6| Step: 7
Training loss: 3.5966196295980155
Validation loss: 2.9179545171266756

Epoch: 6| Step: 8
Training loss: 3.3783267544075573
Validation loss: 2.915712930758719

Epoch: 6| Step: 9
Training loss: 2.8953472433872314
Validation loss: 2.911863878870602

Epoch: 6| Step: 10
Training loss: 3.1006283830756116
Validation loss: 2.909184202009998

Epoch: 6| Step: 11
Training loss: 3.2482496096248856
Validation loss: 2.9070240462647847

Epoch: 6| Step: 12
Training loss: 3.1115771599271285
Validation loss: 2.906710789838464

Epoch: 6| Step: 13
Training loss: 2.810557393895361
Validation loss: 2.9052791696259073

Epoch: 89| Step: 0
Training loss: 3.1106616861189327
Validation loss: 2.905978506486494

Epoch: 6| Step: 1
Training loss: 2.7122312421421686
Validation loss: 2.9050224632450994

Epoch: 6| Step: 2
Training loss: 3.4107924105042966
Validation loss: 2.9070362531948297

Epoch: 6| Step: 3
Training loss: 2.6276897092618072
Validation loss: 2.9064398509599263

Epoch: 6| Step: 4
Training loss: 2.8853467434743654
Validation loss: 2.9046106733150703

Epoch: 6| Step: 5
Training loss: 3.2684877250292668
Validation loss: 2.9427378849103314

Epoch: 6| Step: 6
Training loss: 2.962909454507159
Validation loss: 2.935811168441249

Epoch: 6| Step: 7
Training loss: 3.172577878749159
Validation loss: 2.940714879734151

Epoch: 6| Step: 8
Training loss: 3.0104518655129353
Validation loss: 2.904026282955724

Epoch: 6| Step: 9
Training loss: 3.391758601811731
Validation loss: 2.9004954565825054

Epoch: 6| Step: 10
Training loss: 3.5380131595295676
Validation loss: 2.899303363002352

Epoch: 6| Step: 11
Training loss: 3.1485157997106876
Validation loss: 2.899006960460495

Epoch: 6| Step: 12
Training loss: 4.035016333489053
Validation loss: 2.8996041868669424

Epoch: 6| Step: 13
Training loss: 3.307250848152801
Validation loss: 2.8961901996302246

Epoch: 90| Step: 0
Training loss: 3.5020977273373295
Validation loss: 2.906611818427566

Epoch: 6| Step: 1
Training loss: 2.8282843276187783
Validation loss: 2.902165210117957

Epoch: 6| Step: 2
Training loss: 2.7627365632414347
Validation loss: 2.897675835852984

Epoch: 6| Step: 3
Training loss: 3.6312491385742844
Validation loss: 2.8966593593779626

Epoch: 6| Step: 4
Training loss: 2.7105930780171943
Validation loss: 2.897429449469392

Epoch: 6| Step: 5
Training loss: 2.788060881974764
Validation loss: 2.898023574850634

Epoch: 6| Step: 6
Training loss: 3.0948413503778816
Validation loss: 2.904488184658853

Epoch: 6| Step: 7
Training loss: 2.8848667837290654
Validation loss: 2.9081209449729832

Epoch: 6| Step: 8
Training loss: 3.8040031428599885
Validation loss: 2.903407824728484

Epoch: 6| Step: 9
Training loss: 3.206832749499755
Validation loss: 2.8995282360503545

Epoch: 6| Step: 10
Training loss: 2.848212126386399
Validation loss: 2.89551508416199

Epoch: 6| Step: 11
Training loss: 3.146152320166952
Validation loss: 2.891096494934412

Epoch: 6| Step: 12
Training loss: 3.9779749312342116
Validation loss: 2.8907573710660928

Epoch: 6| Step: 13
Training loss: 3.3538736408886742
Validation loss: 2.8919967106146722

Epoch: 91| Step: 0
Training loss: 3.2040075063343676
Validation loss: 2.8891169238416223

Epoch: 6| Step: 1
Training loss: 3.0661818501192144
Validation loss: 2.8895648718442013

Epoch: 6| Step: 2
Training loss: 3.041032559562675
Validation loss: 2.8903560620854862

Epoch: 6| Step: 3
Training loss: 3.490108681984065
Validation loss: 2.91549805523957

Epoch: 6| Step: 4
Training loss: 2.7416741306315413
Validation loss: 2.930854985861351

Epoch: 6| Step: 5
Training loss: 4.00964670427648
Validation loss: 2.9901380755651936

Epoch: 6| Step: 6
Training loss: 2.7264119191383798
Validation loss: 2.89619816355576

Epoch: 6| Step: 7
Training loss: 2.815154793584328
Validation loss: 2.9163081046879187

Epoch: 6| Step: 8
Training loss: 2.1364174583340247
Validation loss: 3.0049984038381847

Epoch: 6| Step: 9
Training loss: 4.136741342744018
Validation loss: 3.0929492781412367

Epoch: 6| Step: 10
Training loss: 3.4676997338865676
Validation loss: 3.1366256139985222

Epoch: 6| Step: 11
Training loss: 3.169606116099188
Validation loss: 3.094774741289225

Epoch: 6| Step: 12
Training loss: 3.3835501978732814
Validation loss: 3.0518708480410197

Epoch: 6| Step: 13
Training loss: 4.2094671906229015
Validation loss: 2.9989436060271255

Epoch: 92| Step: 0
Training loss: 2.4262343028139055
Validation loss: 2.933500429211023

Epoch: 6| Step: 1
Training loss: 3.3418194197624977
Validation loss: 2.9077065591399736

Epoch: 6| Step: 2
Training loss: 3.6751147972394254
Validation loss: 2.8947924508457623

Epoch: 6| Step: 3
Training loss: 3.269559543355029
Validation loss: 2.884622157866943

Epoch: 6| Step: 4
Training loss: 2.615402660695994
Validation loss: 2.8822728387332206

Epoch: 6| Step: 5
Training loss: 2.8307482950686698
Validation loss: 2.900371034286096

Epoch: 6| Step: 6
Training loss: 2.8391305481770797
Validation loss: 2.944881638027406

Epoch: 6| Step: 7
Training loss: 4.289035150826397
Validation loss: 2.9455782914907664

Epoch: 6| Step: 8
Training loss: 3.084482820707587
Validation loss: 2.87569888387103

Epoch: 6| Step: 9
Training loss: 2.9684369373893267
Validation loss: 2.8895176215031717

Epoch: 6| Step: 10
Training loss: 2.882120354325337
Validation loss: 2.9108000655466015

Epoch: 6| Step: 11
Training loss: 3.758019836162292
Validation loss: 2.917399267548696

Epoch: 6| Step: 12
Training loss: 2.5240528785377667
Validation loss: 2.9383667902139616

Epoch: 6| Step: 13
Training loss: 4.443193892866312
Validation loss: 2.986588657697328

Epoch: 93| Step: 0
Training loss: 2.9475163883339257
Validation loss: 2.9828995880929767

Epoch: 6| Step: 1
Training loss: 3.5880433259302267
Validation loss: 2.9512982486814714

Epoch: 6| Step: 2
Training loss: 3.6172689671745157
Validation loss: 2.941229120780978

Epoch: 6| Step: 3
Training loss: 3.3969394933900325
Validation loss: 2.915615876647612

Epoch: 6| Step: 4
Training loss: 2.0180989541327934
Validation loss: 2.8871017522351345

Epoch: 6| Step: 5
Training loss: 3.126495308752184
Validation loss: 2.883728296287747

Epoch: 6| Step: 6
Training loss: 2.947734454199629
Validation loss: 2.8913393210599185

Epoch: 6| Step: 7
Training loss: 3.9255767009832754
Validation loss: 2.9070305756823767

Epoch: 6| Step: 8
Training loss: 3.603986540833807
Validation loss: 2.876675374876477

Epoch: 6| Step: 9
Training loss: 2.8431021822325913
Validation loss: 2.872478247670404

Epoch: 6| Step: 10
Training loss: 3.1675186684170478
Validation loss: 2.8728295185714163

Epoch: 6| Step: 11
Training loss: 3.6008256336339657
Validation loss: 2.8737845685045933

Epoch: 6| Step: 12
Training loss: 2.68825715510671
Validation loss: 2.8777145876078243

Epoch: 6| Step: 13
Training loss: 2.701013170104982
Validation loss: 2.8845050959700256

Epoch: 94| Step: 0
Training loss: 3.5057247210387397
Validation loss: 2.893322171377366

Epoch: 6| Step: 1
Training loss: 3.4273200760130913
Validation loss: 2.8937229795312227

Epoch: 6| Step: 2
Training loss: 3.0182368377421303
Validation loss: 2.8909177251129736

Epoch: 6| Step: 3
Training loss: 3.526897212054382
Validation loss: 2.895156239103477

Epoch: 6| Step: 4
Training loss: 3.4352742705590256
Validation loss: 2.8913883530514397

Epoch: 6| Step: 5
Training loss: 2.6883898304321665
Validation loss: 2.887315773668176

Epoch: 6| Step: 6
Training loss: 3.337023377407222
Validation loss: 2.8827651576586164

Epoch: 6| Step: 7
Training loss: 2.881932400802102
Validation loss: 2.8805172766086873

Epoch: 6| Step: 8
Training loss: 3.227225838148393
Validation loss: 2.8782360310638193

Epoch: 6| Step: 9
Training loss: 2.9565332514936307
Validation loss: 2.8765492271142126

Epoch: 6| Step: 10
Training loss: 3.5148931801248224
Validation loss: 2.872974027894938

Epoch: 6| Step: 11
Training loss: 2.6110131152907323
Validation loss: 2.873174058095073

Epoch: 6| Step: 12
Training loss: 3.1479708418022874
Validation loss: 2.8671881929512812

Epoch: 6| Step: 13
Training loss: 3.2604507265759572
Validation loss: 2.86780358202265

Epoch: 95| Step: 0
Training loss: 2.9421298288293634
Validation loss: 2.8693535782674537

Epoch: 6| Step: 1
Training loss: 2.729826975918241
Validation loss: 2.8739082061027506

Epoch: 6| Step: 2
Training loss: 2.6737092620756524
Validation loss: 2.9168722112512455

Epoch: 6| Step: 3
Training loss: 2.4972278484110904
Validation loss: 2.9891277210593414

Epoch: 6| Step: 4
Training loss: 3.8783490874709963
Validation loss: 2.9933438926693423

Epoch: 6| Step: 5
Training loss: 2.78979123636825
Validation loss: 2.886774284735224

Epoch: 6| Step: 6
Training loss: 2.8582027512983217
Validation loss: 2.8737390114927246

Epoch: 6| Step: 7
Training loss: 3.4514573156753237
Validation loss: 2.890219606609336

Epoch: 6| Step: 8
Training loss: 3.3153006751868723
Validation loss: 2.9056092339980144

Epoch: 6| Step: 9
Training loss: 3.5999834484143705
Validation loss: 2.902052011334017

Epoch: 6| Step: 10
Training loss: 4.101427174106832
Validation loss: 2.9174443475326406

Epoch: 6| Step: 11
Training loss: 3.1094989080996083
Validation loss: 2.9059562468489513

Epoch: 6| Step: 12
Training loss: 3.1881620430154447
Validation loss: 2.9082830372603192

Epoch: 6| Step: 13
Training loss: 3.2404323009264067
Validation loss: 2.9105447013699406

Epoch: 96| Step: 0
Training loss: 3.496939001784582
Validation loss: 2.902644650026802

Epoch: 6| Step: 1
Training loss: 2.6894171330766143
Validation loss: 2.8943201554124385

Epoch: 6| Step: 2
Training loss: 3.0973920865846334
Validation loss: 2.8897416219208547

Epoch: 6| Step: 3
Training loss: 3.3944171846845284
Validation loss: 2.8863791570831117

Epoch: 6| Step: 4
Training loss: 3.697044821391398
Validation loss: 2.886073843983423

Epoch: 6| Step: 5
Training loss: 2.974415563029039
Validation loss: 2.884954174152171

Epoch: 6| Step: 6
Training loss: 3.093037378716147
Validation loss: 2.8830559616025058

Epoch: 6| Step: 7
Training loss: 2.577985817591304
Validation loss: 2.8808343459165373

Epoch: 6| Step: 8
Training loss: 2.8616684018016687
Validation loss: 2.8765747355241635

Epoch: 6| Step: 9
Training loss: 3.2409136004491343
Validation loss: 2.872197554904285

Epoch: 6| Step: 10
Training loss: 3.2829871529296715
Validation loss: 2.864706789341419

Epoch: 6| Step: 11
Training loss: 3.2487106700129598
Validation loss: 2.8538363383612317

Epoch: 6| Step: 12
Training loss: 3.466411180129467
Validation loss: 2.851199602271668

Epoch: 6| Step: 13
Training loss: 3.159287001896403
Validation loss: 2.8443271854002736

Epoch: 97| Step: 0
Training loss: 2.6013596830840493
Validation loss: 2.8406048835319977

Epoch: 6| Step: 1
Training loss: 3.2414897121846953
Validation loss: 2.841032701318276

Epoch: 6| Step: 2
Training loss: 2.605219015480623
Validation loss: 2.8428665857005337

Epoch: 6| Step: 3
Training loss: 3.8215393717533304
Validation loss: 2.8506251303864114

Epoch: 6| Step: 4
Training loss: 3.2867562732771587
Validation loss: 2.867968086163512

Epoch: 6| Step: 5
Training loss: 3.746989758589762
Validation loss: 2.844531612087144

Epoch: 6| Step: 6
Training loss: 2.5032306777420192
Validation loss: 2.840492590688371

Epoch: 6| Step: 7
Training loss: 3.450393079395991
Validation loss: 2.8391231953088782

Epoch: 6| Step: 8
Training loss: 2.827973082450736
Validation loss: 2.8422628356950232

Epoch: 6| Step: 9
Training loss: 3.2679117035908147
Validation loss: 2.8417454663479726

Epoch: 6| Step: 10
Training loss: 2.9831252751888755
Validation loss: 2.8397045233112905

Epoch: 6| Step: 11
Training loss: 3.3421247578956215
Validation loss: 2.840087540730454

Epoch: 6| Step: 12
Training loss: 3.178284431592079
Validation loss: 2.8429933271726067

Epoch: 6| Step: 13
Training loss: 2.6043429709200483
Validation loss: 2.84756029111026

Epoch: 98| Step: 0
Training loss: 3.576609727940147
Validation loss: 2.849089110610979

Epoch: 6| Step: 1
Training loss: 3.103864224099222
Validation loss: 2.8453040138182004

Epoch: 6| Step: 2
Training loss: 4.082262300952061
Validation loss: 2.8410586161412867

Epoch: 6| Step: 3
Training loss: 2.910784885175494
Validation loss: 2.8382471105432954

Epoch: 6| Step: 4
Training loss: 3.1262738492560103
Validation loss: 2.8372061821205623

Epoch: 6| Step: 5
Training loss: 3.4108091867578403
Validation loss: 2.8369848553041352

Epoch: 6| Step: 6
Training loss: 3.564804402639386
Validation loss: 2.8349000045524635

Epoch: 6| Step: 7
Training loss: 2.6967372501065174
Validation loss: 2.8382869985918577

Epoch: 6| Step: 8
Training loss: 2.960395219811522
Validation loss: 2.8351955344375637

Epoch: 6| Step: 9
Training loss: 3.0819535819784383
Validation loss: 2.8351401685035746

Epoch: 6| Step: 10
Training loss: 2.7535297975190307
Validation loss: 2.8327478582649275

Epoch: 6| Step: 11
Training loss: 2.6663252989504107
Validation loss: 2.8352619576640303

Epoch: 6| Step: 12
Training loss: 3.099975795036079
Validation loss: 2.83310172879479

Epoch: 6| Step: 13
Training loss: 2.122935694895313
Validation loss: 2.831125020120454

Epoch: 99| Step: 0
Training loss: 3.253120391578598
Validation loss: 2.8323081808224986

Epoch: 6| Step: 1
Training loss: 2.913831440864671
Validation loss: 2.8314188271344767

Epoch: 6| Step: 2
Training loss: 3.4982922338573714
Validation loss: 2.834983856760862

Epoch: 6| Step: 3
Training loss: 3.4480979541397563
Validation loss: 2.8321445318810867

Epoch: 6| Step: 4
Training loss: 3.712548478449
Validation loss: 2.8346444980211087

Epoch: 6| Step: 5
Training loss: 2.8042472982693725
Validation loss: 2.8323746446079094

Epoch: 6| Step: 6
Training loss: 3.21216494820549
Validation loss: 2.828324270969963

Epoch: 6| Step: 7
Training loss: 2.9997517165121805
Validation loss: 2.8299389315093952

Epoch: 6| Step: 8
Training loss: 3.118846786312091
Validation loss: 2.831082296453848

Epoch: 6| Step: 9
Training loss: 3.291489672831653
Validation loss: 2.82894520799351

Epoch: 6| Step: 10
Training loss: 3.1427207520850367
Validation loss: 2.829091372625149

Epoch: 6| Step: 11
Training loss: 2.526237328151687
Validation loss: 2.829445379716663

Epoch: 6| Step: 12
Training loss: 2.575084858949747
Validation loss: 2.83180101883847

Epoch: 6| Step: 13
Training loss: 3.2479549722979835
Validation loss: 2.826418633648947

Epoch: 100| Step: 0
Training loss: 3.035149180282548
Validation loss: 2.8248125292687325

Epoch: 6| Step: 1
Training loss: 3.8494153953695878
Validation loss: 2.8238432733662715

Epoch: 6| Step: 2
Training loss: 2.774045206033014
Validation loss: 2.822693062637007

Epoch: 6| Step: 3
Training loss: 3.2713566906052858
Validation loss: 2.8247691283835343

Epoch: 6| Step: 4
Training loss: 3.0248569044836713
Validation loss: 2.8224480837209582

Epoch: 6| Step: 5
Training loss: 2.8868878925413024
Validation loss: 2.820263220402788

Epoch: 6| Step: 6
Training loss: 3.2273799424184024
Validation loss: 2.8204163794756374

Epoch: 6| Step: 7
Training loss: 3.02055975014957
Validation loss: 2.8221881624050114

Epoch: 6| Step: 8
Training loss: 3.2078509938364075
Validation loss: 2.820734273331701

Epoch: 6| Step: 9
Training loss: 2.607256000400332
Validation loss: 2.8217948676800733

Epoch: 6| Step: 10
Training loss: 3.1566376400841287
Validation loss: 2.817261845618914

Epoch: 6| Step: 11
Training loss: 3.597627621018012
Validation loss: 2.8175039943827587

Epoch: 6| Step: 12
Training loss: 2.920692571784465
Validation loss: 2.8220356163918736

Epoch: 6| Step: 13
Training loss: 3.070549176827242
Validation loss: 2.8202901868926347

Epoch: 101| Step: 0
Training loss: 3.612018624410846
Validation loss: 2.8196017143680483

Epoch: 6| Step: 1
Training loss: 3.549376290561759
Validation loss: 2.821626955637031

Epoch: 6| Step: 2
Training loss: 3.0176824162803055
Validation loss: 2.8211763806602734

Epoch: 6| Step: 3
Training loss: 3.276534988949985
Validation loss: 2.818674937821924

Epoch: 6| Step: 4
Training loss: 3.22673274369272
Validation loss: 2.815316953262256

Epoch: 6| Step: 5
Training loss: 2.262320588306375
Validation loss: 2.8156281051481136

Epoch: 6| Step: 6
Training loss: 3.412150460810882
Validation loss: 2.8152375601680544

Epoch: 6| Step: 7
Training loss: 2.2326435769999082
Validation loss: 2.813465425788119

Epoch: 6| Step: 8
Training loss: 3.964409564819437
Validation loss: 2.8135005160310294

Epoch: 6| Step: 9
Training loss: 2.106450292645944
Validation loss: 2.811185830106956

Epoch: 6| Step: 10
Training loss: 3.145539343698684
Validation loss: 2.8137945497834895

Epoch: 6| Step: 11
Training loss: 3.393107968574146
Validation loss: 2.8152025462151227

Epoch: 6| Step: 12
Training loss: 3.0029612866731754
Validation loss: 2.8121319218901935

Epoch: 6| Step: 13
Training loss: 2.763820253304857
Validation loss: 2.81003074219873

Epoch: 102| Step: 0
Training loss: 2.662098986016962
Validation loss: 2.81124497353414

Epoch: 6| Step: 1
Training loss: 3.6974699081836797
Validation loss: 2.8110956849412045

Epoch: 6| Step: 2
Training loss: 3.6269123689316207
Validation loss: 2.8133165475354

Epoch: 6| Step: 3
Training loss: 3.1623557679830867
Validation loss: 2.8131396023264736

Epoch: 6| Step: 4
Training loss: 3.1149545573782054
Validation loss: 2.8132951658346768

Epoch: 6| Step: 5
Training loss: 2.473305856426988
Validation loss: 2.821116437656135

Epoch: 6| Step: 6
Training loss: 3.187584969379125
Validation loss: 2.8237588688123094

Epoch: 6| Step: 7
Training loss: 3.05907887476144
Validation loss: 2.8170411850894572

Epoch: 6| Step: 8
Training loss: 2.3186747618444894
Validation loss: 2.8120493337509087

Epoch: 6| Step: 9
Training loss: 3.6250536684470056
Validation loss: 2.824987493725637

Epoch: 6| Step: 10
Training loss: 3.084255252511777
Validation loss: 2.8199083715165245

Epoch: 6| Step: 11
Training loss: 3.0359919316884465
Validation loss: 2.8119552494926094

Epoch: 6| Step: 12
Training loss: 3.220437949826713
Validation loss: 2.8158758159838366

Epoch: 6| Step: 13
Training loss: 2.9930888678360623
Validation loss: 2.815730796289423

Epoch: 103| Step: 0
Training loss: 3.4211868221204447
Validation loss: 2.8104271518362056

Epoch: 6| Step: 1
Training loss: 3.1971700254396582
Validation loss: 2.8190834690531545

Epoch: 6| Step: 2
Training loss: 3.4853869965714197
Validation loss: 2.8065197395296733

Epoch: 6| Step: 3
Training loss: 3.3140373261398026
Validation loss: 2.802596754277157

Epoch: 6| Step: 4
Training loss: 3.8528108566197754
Validation loss: 2.8024435754500865

Epoch: 6| Step: 5
Training loss: 2.6760831119648647
Validation loss: 2.799794417552874

Epoch: 6| Step: 6
Training loss: 3.0554610343724495
Validation loss: 2.8013757526763663

Epoch: 6| Step: 7
Training loss: 3.6483823457588334
Validation loss: 2.7976748579148416

Epoch: 6| Step: 8
Training loss: 2.0437547036213077
Validation loss: 2.7972890419431966

Epoch: 6| Step: 9
Training loss: 3.130897602649887
Validation loss: 2.7980089701098314

Epoch: 6| Step: 10
Training loss: 3.0076389014939586
Validation loss: 2.7976813209019418

Epoch: 6| Step: 11
Training loss: 2.5794835066012025
Validation loss: 2.8006776912486178

Epoch: 6| Step: 12
Training loss: 2.73303276906082
Validation loss: 2.8002722726454006

Epoch: 6| Step: 13
Training loss: 3.0986223482135
Validation loss: 2.799917947428294

Epoch: 104| Step: 0
Training loss: 2.837826774703251
Validation loss: 2.800420890471318

Epoch: 6| Step: 1
Training loss: 2.9091483809472773
Validation loss: 2.797632943894444

Epoch: 6| Step: 2
Training loss: 2.7935990909380486
Validation loss: 2.7993254338278613

Epoch: 6| Step: 3
Training loss: 2.622871262387389
Validation loss: 2.7952108129131847

Epoch: 6| Step: 4
Training loss: 3.7529345156747502
Validation loss: 2.7979202979919777

Epoch: 6| Step: 5
Training loss: 3.4413882373074283
Validation loss: 2.795430428893158

Epoch: 6| Step: 6
Training loss: 3.1504705410663583
Validation loss: 2.795146601260428

Epoch: 6| Step: 7
Training loss: 2.4245975081711273
Validation loss: 2.7944363932244616

Epoch: 6| Step: 8
Training loss: 2.9599422503327957
Validation loss: 2.7944488387650006

Epoch: 6| Step: 9
Training loss: 3.817054529485647
Validation loss: 2.791212322881512

Epoch: 6| Step: 10
Training loss: 3.485302720351596
Validation loss: 2.791448482373971

Epoch: 6| Step: 11
Training loss: 3.0883464440611132
Validation loss: 2.793842036243121

Epoch: 6| Step: 12
Training loss: 3.016663209551381
Validation loss: 2.7994791001217094

Epoch: 6| Step: 13
Training loss: 2.8486339842408457
Validation loss: 2.8040495308106186

Epoch: 105| Step: 0
Training loss: 3.1741928876930667
Validation loss: 2.8043951606064668

Epoch: 6| Step: 1
Training loss: 2.4749446361784413
Validation loss: 2.817903325679632

Epoch: 6| Step: 2
Training loss: 3.9844715779885216
Validation loss: 2.8218779700649748

Epoch: 6| Step: 3
Training loss: 2.800889442727013
Validation loss: 2.82084424455454

Epoch: 6| Step: 4
Training loss: 3.323299294249273
Validation loss: 2.8044683593782023

Epoch: 6| Step: 5
Training loss: 2.734839699631081
Validation loss: 2.8031973541985984

Epoch: 6| Step: 6
Training loss: 3.38423954770997
Validation loss: 2.7943798389845624

Epoch: 6| Step: 7
Training loss: 3.362458131664218
Validation loss: 2.7923855888199007

Epoch: 6| Step: 8
Training loss: 3.12050549593666
Validation loss: 2.790659036800725

Epoch: 6| Step: 9
Training loss: 2.8264566632600454
Validation loss: 2.788172113399841

Epoch: 6| Step: 10
Training loss: 2.8316554168723185
Validation loss: 2.788405179191618

Epoch: 6| Step: 11
Training loss: 2.882151789017456
Validation loss: 2.7889717905137195

Epoch: 6| Step: 12
Training loss: 3.3995592392603244
Validation loss: 2.788895997241809

Epoch: 6| Step: 13
Training loss: 2.761317200989187
Validation loss: 2.7906308993092406

Epoch: 106| Step: 0
Training loss: 2.927720693972371
Validation loss: 2.790430713386144

Epoch: 6| Step: 1
Training loss: 3.1204327586404244
Validation loss: 2.792027441107654

Epoch: 6| Step: 2
Training loss: 2.8044424986022283
Validation loss: 2.7904057367952912

Epoch: 6| Step: 3
Training loss: 3.0868836316615376
Validation loss: 2.7910821866363458

Epoch: 6| Step: 4
Training loss: 3.0986483549779598
Validation loss: 2.791064264585566

Epoch: 6| Step: 5
Training loss: 2.8944780393746923
Validation loss: 2.7909425859548946

Epoch: 6| Step: 6
Training loss: 3.2825733241123234
Validation loss: 2.7894809108368057

Epoch: 6| Step: 7
Training loss: 3.2486267122812174
Validation loss: 2.791611832686432

Epoch: 6| Step: 8
Training loss: 2.5605176375499914
Validation loss: 2.7874180680969016

Epoch: 6| Step: 9
Training loss: 3.4231349071382304
Validation loss: 2.7909672050185796

Epoch: 6| Step: 10
Training loss: 3.0172620688043827
Validation loss: 2.7895678882131016

Epoch: 6| Step: 11
Training loss: 4.013337073551433
Validation loss: 2.789985051695218

Epoch: 6| Step: 12
Training loss: 3.0605308274248237
Validation loss: 2.787174146174837

Epoch: 6| Step: 13
Training loss: 2.368791093696308
Validation loss: 2.7878183984352387

Epoch: 107| Step: 0
Training loss: 3.118757497896955
Validation loss: 2.7852252325227913

Epoch: 6| Step: 1
Training loss: 3.3939701577955628
Validation loss: 2.788082128934912

Epoch: 6| Step: 2
Training loss: 3.3896148161235917
Validation loss: 2.7837391198007606

Epoch: 6| Step: 3
Training loss: 2.8867425362687134
Validation loss: 2.7841160529212

Epoch: 6| Step: 4
Training loss: 2.5142109373664816
Validation loss: 2.7852183135453354

Epoch: 6| Step: 5
Training loss: 2.8941249793957247
Validation loss: 2.7835210699522484

Epoch: 6| Step: 6
Training loss: 2.820261946882886
Validation loss: 2.7803883597613765

Epoch: 6| Step: 7
Training loss: 3.487529199402782
Validation loss: 2.7770893038117084

Epoch: 6| Step: 8
Training loss: 3.0619936154608562
Validation loss: 2.7819723933465172

Epoch: 6| Step: 9
Training loss: 3.073254444933055
Validation loss: 2.7784390875101845

Epoch: 6| Step: 10
Training loss: 2.9360052323255768
Validation loss: 2.77873212977852

Epoch: 6| Step: 11
Training loss: 3.3638820488171834
Validation loss: 2.7764255795608275

Epoch: 6| Step: 12
Training loss: 3.5200303345153436
Validation loss: 2.7776536908343594

Epoch: 6| Step: 13
Training loss: 2.4127983066955108
Validation loss: 2.7798272992609516

Epoch: 108| Step: 0
Training loss: 3.173055044067642
Validation loss: 2.7765722422074237

Epoch: 6| Step: 1
Training loss: 3.4576622338617926
Validation loss: 2.7916695789609096

Epoch: 6| Step: 2
Training loss: 2.4872425732085235
Validation loss: 2.7803238113160815

Epoch: 6| Step: 3
Training loss: 3.7232472129795466
Validation loss: 2.7796333982138033

Epoch: 6| Step: 4
Training loss: 2.5904054334704862
Validation loss: 2.7820730748560965

Epoch: 6| Step: 5
Training loss: 3.499525582994111
Validation loss: 2.778544224310762

Epoch: 6| Step: 6
Training loss: 3.1839015320451223
Validation loss: 2.7782636064468162

Epoch: 6| Step: 7
Training loss: 3.097231360756051
Validation loss: 2.7750685623037215

Epoch: 6| Step: 8
Training loss: 3.0329636910991664
Validation loss: 2.7734440019049797

Epoch: 6| Step: 9
Training loss: 3.120110004637663
Validation loss: 2.771225086367169

Epoch: 6| Step: 10
Training loss: 3.1782127165715863
Validation loss: 2.7732265671239604

Epoch: 6| Step: 11
Training loss: 3.2007613230097305
Validation loss: 2.772460613861797

Epoch: 6| Step: 12
Training loss: 2.3835756174283675
Validation loss: 2.77031393007212

Epoch: 6| Step: 13
Training loss: 2.6865308034193367
Validation loss: 2.7698966555761904

Epoch: 109| Step: 0
Training loss: 3.1762343642965765
Validation loss: 2.769778021460921

Epoch: 6| Step: 1
Training loss: 2.996168232654692
Validation loss: 2.768361633228832

Epoch: 6| Step: 2
Training loss: 3.451202686044906
Validation loss: 2.7696951691187177

Epoch: 6| Step: 3
Training loss: 2.9209248839073556
Validation loss: 2.7663730133273297

Epoch: 6| Step: 4
Training loss: 3.157938288505459
Validation loss: 2.7664629672076626

Epoch: 6| Step: 5
Training loss: 2.4925266142775846
Validation loss: 2.7657591658197873

Epoch: 6| Step: 6
Training loss: 1.9738786290432357
Validation loss: 2.767460115901994

Epoch: 6| Step: 7
Training loss: 3.054920704713129
Validation loss: 2.765083405027948

Epoch: 6| Step: 8
Training loss: 3.2189413958189417
Validation loss: 2.7722081636306948

Epoch: 6| Step: 9
Training loss: 3.7502216273619746
Validation loss: 2.772148581316604

Epoch: 6| Step: 10
Training loss: 3.4499266298757543
Validation loss: 2.7773016639180184

Epoch: 6| Step: 11
Training loss: 3.476700752166799
Validation loss: 2.7768444690572927

Epoch: 6| Step: 12
Training loss: 3.0087039567746974
Validation loss: 2.788176523174512

Epoch: 6| Step: 13
Training loss: 2.2798995109632205
Validation loss: 2.8024061100734508

Epoch: 110| Step: 0
Training loss: 3.1721538552664708
Validation loss: 2.8039659347794363

Epoch: 6| Step: 1
Training loss: 2.7888501511205783
Validation loss: 2.786005274999162

Epoch: 6| Step: 2
Training loss: 2.7110210482780364
Validation loss: 2.7769025935087495

Epoch: 6| Step: 3
Training loss: 3.0594591887037406
Validation loss: 2.7663401100992995

Epoch: 6| Step: 4
Training loss: 2.8890373199999577
Validation loss: 2.7666202592299594

Epoch: 6| Step: 5
Training loss: 3.7250799592928203
Validation loss: 2.7622487064639003

Epoch: 6| Step: 6
Training loss: 2.944885708674991
Validation loss: 2.7619847879387027

Epoch: 6| Step: 7
Training loss: 3.1471547431441818
Validation loss: 2.7688011423041923

Epoch: 6| Step: 8
Training loss: 2.792705475462936
Validation loss: 2.771290359227976

Epoch: 6| Step: 9
Training loss: 3.2849897598734072
Validation loss: 2.769703668000639

Epoch: 6| Step: 10
Training loss: 3.4734492732031694
Validation loss: 2.7824079290686523

Epoch: 6| Step: 11
Training loss: 3.0546537821828363
Validation loss: 2.7726449224767533

Epoch: 6| Step: 12
Training loss: 3.2387740585040157
Validation loss: 2.7613463204849595

Epoch: 6| Step: 13
Training loss: 2.4836424701300293
Validation loss: 2.760718684392402

Epoch: 111| Step: 0
Training loss: 3.0250295148938635
Validation loss: 2.7578461342952396

Epoch: 6| Step: 1
Training loss: 2.9701923279831495
Validation loss: 2.757492742692064

Epoch: 6| Step: 2
Training loss: 3.0450505981250298
Validation loss: 2.757185126895298

Epoch: 6| Step: 3
Training loss: 2.418084112567563
Validation loss: 2.757732759368845

Epoch: 6| Step: 4
Training loss: 3.37383871939187
Validation loss: 2.7559203150620037

Epoch: 6| Step: 5
Training loss: 2.8876074634718174
Validation loss: 2.7585441220571236

Epoch: 6| Step: 6
Training loss: 2.9626730309025175
Validation loss: 2.759198850992686

Epoch: 6| Step: 7
Training loss: 3.9595321178499305
Validation loss: 2.7591159021113794

Epoch: 6| Step: 8
Training loss: 3.279404330012478
Validation loss: 2.7588734122726906

Epoch: 6| Step: 9
Training loss: 3.1527066122379863
Validation loss: 2.7568003194218225

Epoch: 6| Step: 10
Training loss: 3.5537816496897885
Validation loss: 2.7573446059144233

Epoch: 6| Step: 11
Training loss: 2.5261714521802645
Validation loss: 2.7563185234742478

Epoch: 6| Step: 12
Training loss: 2.975842165955662
Validation loss: 2.759353099084764

Epoch: 6| Step: 13
Training loss: 2.324858351463615
Validation loss: 2.7567152691928594

Epoch: 112| Step: 0
Training loss: 3.3959539349130985
Validation loss: 2.7593825384658657

Epoch: 6| Step: 1
Training loss: 3.5133317715993035
Validation loss: 2.7571755684978014

Epoch: 6| Step: 2
Training loss: 3.607267086258516
Validation loss: 2.756970242771125

Epoch: 6| Step: 3
Training loss: 2.6494884825004594
Validation loss: 2.7613107810112156

Epoch: 6| Step: 4
Training loss: 2.959607955641867
Validation loss: 2.754181208659098

Epoch: 6| Step: 5
Training loss: 2.5390251274292828
Validation loss: 2.753640857860867

Epoch: 6| Step: 6
Training loss: 3.418876135136338
Validation loss: 2.7544455277263458

Epoch: 6| Step: 7
Training loss: 3.196473151015596
Validation loss: 2.750467851187394

Epoch: 6| Step: 8
Training loss: 3.2295088719991605
Validation loss: 2.750091865362474

Epoch: 6| Step: 9
Training loss: 2.9483877463860737
Validation loss: 2.7490091925460893

Epoch: 6| Step: 10
Training loss: 2.857330758864251
Validation loss: 2.7540140734070553

Epoch: 6| Step: 11
Training loss: 2.662230994734253
Validation loss: 2.7656171671253165

Epoch: 6| Step: 12
Training loss: 3.1393589485512994
Validation loss: 2.7901828935580903

Epoch: 6| Step: 13
Training loss: 2.4175876199964517
Validation loss: 2.819046031119996

Epoch: 113| Step: 0
Training loss: 2.9790904606673756
Validation loss: 2.8519265749749225

Epoch: 6| Step: 1
Training loss: 3.6318888484734795
Validation loss: 2.8247354287544377

Epoch: 6| Step: 2
Training loss: 2.7323833950951593
Validation loss: 2.767114816318148

Epoch: 6| Step: 3
Training loss: 3.031533139563137
Validation loss: 2.7498823310385436

Epoch: 6| Step: 4
Training loss: 3.2151747912031596
Validation loss: 2.7445922671412553

Epoch: 6| Step: 5
Training loss: 3.5012625733067737
Validation loss: 2.7451255177963807

Epoch: 6| Step: 6
Training loss: 3.101767583643935
Validation loss: 2.7520232732903143

Epoch: 6| Step: 7
Training loss: 3.256899625735976
Validation loss: 2.7554216274219057

Epoch: 6| Step: 8
Training loss: 2.707512002286083
Validation loss: 2.751255674431668

Epoch: 6| Step: 9
Training loss: 2.708990975765886
Validation loss: 2.7481321347311063

Epoch: 6| Step: 10
Training loss: 2.6935232221906356
Validation loss: 2.753093458097893

Epoch: 6| Step: 11
Training loss: 3.1032166189938164
Validation loss: 2.753036718519935

Epoch: 6| Step: 12
Training loss: 3.596664971418102
Validation loss: 2.7534746069005274

Epoch: 6| Step: 13
Training loss: 2.707376829605615
Validation loss: 2.755185335103133

Epoch: 114| Step: 0
Training loss: 3.270894011564376
Validation loss: 2.751263076700385

Epoch: 6| Step: 1
Training loss: 3.5781564502916403
Validation loss: 2.7531123182638733

Epoch: 6| Step: 2
Training loss: 2.751748309557993
Validation loss: 2.761807811194658

Epoch: 6| Step: 3
Training loss: 3.2069856034072597
Validation loss: 2.753204456893466

Epoch: 6| Step: 4
Training loss: 2.8450815625558463
Validation loss: 2.74763993356575

Epoch: 6| Step: 5
Training loss: 3.375946759839165
Validation loss: 2.748597950167114

Epoch: 6| Step: 6
Training loss: 2.8385552548891124
Validation loss: 2.7428066182415067

Epoch: 6| Step: 7
Training loss: 3.03917735061741
Validation loss: 2.744654412900899

Epoch: 6| Step: 8
Training loss: 3.048996406910882
Validation loss: 2.7428088091255485

Epoch: 6| Step: 9
Training loss: 3.0755793700218033
Validation loss: 2.7409671199060317

Epoch: 6| Step: 10
Training loss: 3.233960111241113
Validation loss: 2.739674934444451

Epoch: 6| Step: 11
Training loss: 2.3007864312468187
Validation loss: 2.7440868944783166

Epoch: 6| Step: 12
Training loss: 2.8580978125991905
Validation loss: 2.752658859089725

Epoch: 6| Step: 13
Training loss: 3.849319764521536
Validation loss: 2.756242624741331

Epoch: 115| Step: 0
Training loss: 2.842175561377568
Validation loss: 2.7601043790757127

Epoch: 6| Step: 1
Training loss: 3.0782356048696005
Validation loss: 2.7713880209640127

Epoch: 6| Step: 2
Training loss: 3.4560134337658637
Validation loss: 2.7636674910587073

Epoch: 6| Step: 3
Training loss: 3.645915235780193
Validation loss: 2.7685466619747348

Epoch: 6| Step: 4
Training loss: 2.52476697922956
Validation loss: 2.7537263661234808

Epoch: 6| Step: 5
Training loss: 3.0965390974964646
Validation loss: 2.7435005493371634

Epoch: 6| Step: 6
Training loss: 2.599659358231211
Validation loss: 2.7345313130364315

Epoch: 6| Step: 7
Training loss: 3.4226268482316806
Validation loss: 2.734654306423958

Epoch: 6| Step: 8
Training loss: 2.758446293695093
Validation loss: 2.7311605706407533

Epoch: 6| Step: 9
Training loss: 3.0912496307780057
Validation loss: 2.7324581199983533

Epoch: 6| Step: 10
Training loss: 3.3198949932819346
Validation loss: 2.7295130375472603

Epoch: 6| Step: 11
Training loss: 2.9285508862881486
Validation loss: 2.7302672750055064

Epoch: 6| Step: 12
Training loss: 2.7808263220244736
Validation loss: 2.7286579234353945

Epoch: 6| Step: 13
Training loss: 3.121875574304721
Validation loss: 2.729936958978537

Epoch: 116| Step: 0
Training loss: 2.6684093642100084
Validation loss: 2.7263703670375485

Epoch: 6| Step: 1
Training loss: 3.1181129859972723
Validation loss: 2.727938032540543

Epoch: 6| Step: 2
Training loss: 3.509209369613086
Validation loss: 2.728518687067912

Epoch: 6| Step: 3
Training loss: 2.504924120943501
Validation loss: 2.731251472582943

Epoch: 6| Step: 4
Training loss: 3.2350725536671097
Validation loss: 2.7310108300017952

Epoch: 6| Step: 5
Training loss: 2.9034305144847887
Validation loss: 2.7274820375776385

Epoch: 6| Step: 6
Training loss: 2.432760472559044
Validation loss: 2.731194082598061

Epoch: 6| Step: 7
Training loss: 3.2866774947921114
Validation loss: 2.727103078701695

Epoch: 6| Step: 8
Training loss: 2.592244090266761
Validation loss: 2.7285200043479882

Epoch: 6| Step: 9
Training loss: 2.6128185643806794
Validation loss: 2.7269394243788185

Epoch: 6| Step: 10
Training loss: 3.0999751797574615
Validation loss: 2.7247357621468358

Epoch: 6| Step: 11
Training loss: 3.8157457387255955
Validation loss: 2.72247011093914

Epoch: 6| Step: 12
Training loss: 3.443208705226005
Validation loss: 2.723080411343069

Epoch: 6| Step: 13
Training loss: 3.4244549227050953
Validation loss: 2.719779563041713

Epoch: 117| Step: 0
Training loss: 3.0042802158717676
Validation loss: 2.720680146673565

Epoch: 6| Step: 1
Training loss: 3.025535781953884
Validation loss: 2.7232883185957215

Epoch: 6| Step: 2
Training loss: 3.249041489326542
Validation loss: 2.7246344673505885

Epoch: 6| Step: 3
Training loss: 3.206338006014568
Validation loss: 2.7262795877397745

Epoch: 6| Step: 4
Training loss: 3.679968950721118
Validation loss: 2.7286440578994107

Epoch: 6| Step: 5
Training loss: 3.1325959014216953
Validation loss: 2.7355900571922387

Epoch: 6| Step: 6
Training loss: 3.0328283231893383
Validation loss: 2.7396310644359874

Epoch: 6| Step: 7
Training loss: 3.2607731893367506
Validation loss: 2.7362450655596433

Epoch: 6| Step: 8
Training loss: 3.5514910400827544
Validation loss: 2.7484722825471493

Epoch: 6| Step: 9
Training loss: 2.3875355423283957
Validation loss: 2.742776642958564

Epoch: 6| Step: 10
Training loss: 2.285215197723936
Validation loss: 2.753087383037161

Epoch: 6| Step: 11
Training loss: 3.537503267428234
Validation loss: 2.771133784670138

Epoch: 6| Step: 12
Training loss: 2.3750896436939546
Validation loss: 2.747844440409397

Epoch: 6| Step: 13
Training loss: 2.27034000555968
Validation loss: 2.727330607923078

Epoch: 118| Step: 0
Training loss: 3.275419304482744
Validation loss: 2.7268260618397617

Epoch: 6| Step: 1
Training loss: 3.242747945489454
Validation loss: 2.7356787732612906

Epoch: 6| Step: 2
Training loss: 3.2645393282600894
Validation loss: 2.748556401420819

Epoch: 6| Step: 3
Training loss: 2.9012624952186092
Validation loss: 2.75459503773778

Epoch: 6| Step: 4
Training loss: 3.0740372678126997
Validation loss: 2.7767599819880737

Epoch: 6| Step: 5
Training loss: 3.2881635221114736
Validation loss: 2.7666611039686066

Epoch: 6| Step: 6
Training loss: 3.3352753386298795
Validation loss: 2.7635035595002155

Epoch: 6| Step: 7
Training loss: 2.6685029105302287
Validation loss: 2.7397551426344497

Epoch: 6| Step: 8
Training loss: 2.427353108574955
Validation loss: 2.7212535197577554

Epoch: 6| Step: 9
Training loss: 2.9039011661956105
Validation loss: 2.7207389122309107

Epoch: 6| Step: 10
Training loss: 2.864602235673904
Validation loss: 2.719765146069111

Epoch: 6| Step: 11
Training loss: 3.254198736666925
Validation loss: 2.71622660261214

Epoch: 6| Step: 12
Training loss: 3.3926953442076697
Validation loss: 2.7174681462341734

Epoch: 6| Step: 13
Training loss: 2.262935647067175
Validation loss: 2.7192169022388986

Epoch: 119| Step: 0
Training loss: 3.2498634016234322
Validation loss: 2.7143921986584805

Epoch: 6| Step: 1
Training loss: 2.609647542460077
Validation loss: 2.7173447551654903

Epoch: 6| Step: 2
Training loss: 2.9009722296704834
Validation loss: 2.720825892650268

Epoch: 6| Step: 3
Training loss: 3.1928226684874352
Validation loss: 2.7265178501525593

Epoch: 6| Step: 4
Training loss: 2.9976819937770967
Validation loss: 2.7169487020959435

Epoch: 6| Step: 5
Training loss: 2.8256373133873076
Validation loss: 2.712055850007085

Epoch: 6| Step: 6
Training loss: 2.501412755426472
Validation loss: 2.7125592911759027

Epoch: 6| Step: 7
Training loss: 3.24841416622587
Validation loss: 2.710411295660414

Epoch: 6| Step: 8
Training loss: 3.2273269006478134
Validation loss: 2.712952606795544

Epoch: 6| Step: 9
Training loss: 3.621506816591628
Validation loss: 2.713349274333031

Epoch: 6| Step: 10
Training loss: 3.3970155744759873
Validation loss: 2.7115616110278684

Epoch: 6| Step: 11
Training loss: 2.845592530666669
Validation loss: 2.711391840116022

Epoch: 6| Step: 12
Training loss: 2.863859901400743
Validation loss: 2.71051463907683

Epoch: 6| Step: 13
Training loss: 3.079100478462781
Validation loss: 2.716007960691681

Epoch: 120| Step: 0
Training loss: 2.78663628030786
Validation loss: 2.7120025501100082

Epoch: 6| Step: 1
Training loss: 3.440730432320723
Validation loss: 2.7121946488563324

Epoch: 6| Step: 2
Training loss: 3.1204964802714055
Validation loss: 2.7100392070547024

Epoch: 6| Step: 3
Training loss: 2.770233366600371
Validation loss: 2.709079338362464

Epoch: 6| Step: 4
Training loss: 2.1858471757007165
Validation loss: 2.7089230623432545

Epoch: 6| Step: 5
Training loss: 3.023340031435219
Validation loss: 2.708212853269028

Epoch: 6| Step: 6
Training loss: 2.7863902050970957
Validation loss: 2.708885431613891

Epoch: 6| Step: 7
Training loss: 3.567753983180044
Validation loss: 2.710703638130754

Epoch: 6| Step: 8
Training loss: 3.127115067929431
Validation loss: 2.712201484732113

Epoch: 6| Step: 9
Training loss: 3.2280908248584264
Validation loss: 2.7143129401283708

Epoch: 6| Step: 10
Training loss: 3.3662391265228906
Validation loss: 2.7228082691601903

Epoch: 6| Step: 11
Training loss: 2.3264163102642077
Validation loss: 2.7260550751282024

Epoch: 6| Step: 12
Training loss: 3.3343899641621806
Validation loss: 2.731542166999489

Epoch: 6| Step: 13
Training loss: 3.1853337125952286
Validation loss: 2.7385927266321226

Epoch: 121| Step: 0
Training loss: 2.5194731476464334
Validation loss: 2.740611230031252

Epoch: 6| Step: 1
Training loss: 2.8200229485572286
Validation loss: 2.7528877440917205

Epoch: 6| Step: 2
Training loss: 2.9607183128696355
Validation loss: 2.752290564163443

Epoch: 6| Step: 3
Training loss: 3.0204775019696446
Validation loss: 2.7596175684268194

Epoch: 6| Step: 4
Training loss: 3.0239621675637633
Validation loss: 2.736401069408228

Epoch: 6| Step: 5
Training loss: 2.3680507986767356
Validation loss: 2.71912088246563

Epoch: 6| Step: 6
Training loss: 2.5745488188192116
Validation loss: 2.712007627281106

Epoch: 6| Step: 7
Training loss: 2.7467988195694253
Validation loss: 2.7079126619782867

Epoch: 6| Step: 8
Training loss: 3.394362819694028
Validation loss: 2.7066653931517397

Epoch: 6| Step: 9
Training loss: 3.173012665673725
Validation loss: 2.705222410621172

Epoch: 6| Step: 10
Training loss: 3.4266784954485345
Validation loss: 2.7066262534456618

Epoch: 6| Step: 11
Training loss: 3.4510826181334195
Validation loss: 2.7043648078676137

Epoch: 6| Step: 12
Training loss: 3.4830052715637287
Validation loss: 2.7032475853586786

Epoch: 6| Step: 13
Training loss: 3.4679180900378004
Validation loss: 2.7048728167501004

Epoch: 122| Step: 0
Training loss: 3.1589709347084862
Validation loss: 2.704734105657503

Epoch: 6| Step: 1
Training loss: 2.6749054972275004
Validation loss: 2.705191755427417

Epoch: 6| Step: 2
Training loss: 2.503559630113332
Validation loss: 2.7054270536644194

Epoch: 6| Step: 3
Training loss: 3.035040461664864
Validation loss: 2.703156972232876

Epoch: 6| Step: 4
Training loss: 3.707300335169311
Validation loss: 2.705751534193181

Epoch: 6| Step: 5
Training loss: 2.724844929893768
Validation loss: 2.702958543289869

Epoch: 6| Step: 6
Training loss: 3.029376050454271
Validation loss: 2.7021406075242203

Epoch: 6| Step: 7
Training loss: 2.8489359425298897
Validation loss: 2.7023450855036155

Epoch: 6| Step: 8
Training loss: 2.8386778819213654
Validation loss: 2.702302466052689

Epoch: 6| Step: 9
Training loss: 3.5059281961385764
Validation loss: 2.702316645099223

Epoch: 6| Step: 10
Training loss: 3.1771268914577253
Validation loss: 2.701682062293888

Epoch: 6| Step: 11
Training loss: 3.2406206504329087
Validation loss: 2.7042351327552443

Epoch: 6| Step: 12
Training loss: 2.749018320515886
Validation loss: 2.707968448894076

Epoch: 6| Step: 13
Training loss: 3.167420665587463
Validation loss: 2.7109521048218834

Epoch: 123| Step: 0
Training loss: 2.603377983192291
Validation loss: 2.71152130438706

Epoch: 6| Step: 1
Training loss: 2.787375402017981
Validation loss: 2.7127244840099776

Epoch: 6| Step: 2
Training loss: 3.0648055448346025
Validation loss: 2.7056445750532707

Epoch: 6| Step: 3
Training loss: 2.552409144773184
Validation loss: 2.70007846768387

Epoch: 6| Step: 4
Training loss: 3.290841461916058
Validation loss: 2.698552896201765

Epoch: 6| Step: 5
Training loss: 3.3445268245561706
Validation loss: 2.701733656633293

Epoch: 6| Step: 6
Training loss: 2.7897269688939312
Validation loss: 2.7018729620265907

Epoch: 6| Step: 7
Training loss: 3.0156613678789888
Validation loss: 2.6998340215373506

Epoch: 6| Step: 8
Training loss: 3.065510107409194
Validation loss: 2.7009645622910563

Epoch: 6| Step: 9
Training loss: 3.5970465094725412
Validation loss: 2.701154839826751

Epoch: 6| Step: 10
Training loss: 3.0509772439243688
Validation loss: 2.7040134866314673

Epoch: 6| Step: 11
Training loss: 3.6570678839491753
Validation loss: 2.7095378200937676

Epoch: 6| Step: 12
Training loss: 2.760596752890192
Validation loss: 2.7050101142869956

Epoch: 6| Step: 13
Training loss: 2.2709770390480712
Validation loss: 2.700236853446694

Epoch: 124| Step: 0
Training loss: 2.919464422517127
Validation loss: 2.6998364457499324

Epoch: 6| Step: 1
Training loss: 2.958203666603344
Validation loss: 2.697731622401489

Epoch: 6| Step: 2
Training loss: 2.9254588623075373
Validation loss: 2.69863146812941

Epoch: 6| Step: 3
Training loss: 3.429159832032547
Validation loss: 2.6981136329149553

Epoch: 6| Step: 4
Training loss: 2.6316253974228245
Validation loss: 2.6964807699646083

Epoch: 6| Step: 5
Training loss: 2.6078002198000445
Validation loss: 2.7007661393327083

Epoch: 6| Step: 6
Training loss: 3.366363920316154
Validation loss: 2.6978486268258313

Epoch: 6| Step: 7
Training loss: 2.9597054285959032
Validation loss: 2.6979531261017042

Epoch: 6| Step: 8
Training loss: 3.604861653671921
Validation loss: 2.700235097031618

Epoch: 6| Step: 9
Training loss: 3.3503952305644136
Validation loss: 2.6959761168957894

Epoch: 6| Step: 10
Training loss: 2.821186807217966
Validation loss: 2.696805713762472

Epoch: 6| Step: 11
Training loss: 2.7996238115187815
Validation loss: 2.6951362807878305

Epoch: 6| Step: 12
Training loss: 2.501055399327282
Validation loss: 2.6948030703439634

Epoch: 6| Step: 13
Training loss: 3.3944219608953152
Validation loss: 2.695225310672795

Epoch: 125| Step: 0
Training loss: 2.4206868856740065
Validation loss: 2.693865193000429

Epoch: 6| Step: 1
Training loss: 3.4262139668008578
Validation loss: 2.701029334866227

Epoch: 6| Step: 2
Training loss: 2.5990544507148674
Validation loss: 2.702400553819041

Epoch: 6| Step: 3
Training loss: 2.611288134568976
Validation loss: 2.7024374618641205

Epoch: 6| Step: 4
Training loss: 3.2431746485260833
Validation loss: 2.7022734834934115

Epoch: 6| Step: 5
Training loss: 3.140563356923808
Validation loss: 2.716777122945164

Epoch: 6| Step: 6
Training loss: 2.7462713800013914
Validation loss: 2.7086602173860057

Epoch: 6| Step: 7
Training loss: 2.8727766645112105
Validation loss: 2.7245967666370117

Epoch: 6| Step: 8
Training loss: 3.327499115884321
Validation loss: 2.717093567894969

Epoch: 6| Step: 9
Training loss: 3.680976658049395
Validation loss: 2.7109099289760246

Epoch: 6| Step: 10
Training loss: 2.9480718744799304
Validation loss: 2.6994469172245696

Epoch: 6| Step: 11
Training loss: 3.0848162581814695
Validation loss: 2.70287535282399

Epoch: 6| Step: 12
Training loss: 3.130193133748368
Validation loss: 2.6986312116353273

Epoch: 6| Step: 13
Training loss: 2.682577015534671
Validation loss: 2.703201962419276

Epoch: 126| Step: 0
Training loss: 2.820793892731657
Validation loss: 2.6918078002634642

Epoch: 6| Step: 1
Training loss: 3.324286167702816
Validation loss: 2.6934882012301182

Epoch: 6| Step: 2
Training loss: 3.3912662304083137
Validation loss: 2.6946146970827702

Epoch: 6| Step: 3
Training loss: 2.960219484903731
Validation loss: 2.689611299589764

Epoch: 6| Step: 4
Training loss: 2.219579192479289
Validation loss: 2.6871723395982343

Epoch: 6| Step: 5
Training loss: 3.5257127947493925
Validation loss: 2.685979104200202

Epoch: 6| Step: 6
Training loss: 3.4524071408986976
Validation loss: 2.6891090477461694

Epoch: 6| Step: 7
Training loss: 2.9774271192367094
Validation loss: 2.6897905685111456

Epoch: 6| Step: 8
Training loss: 3.2305212973734134
Validation loss: 2.6890229433769726

Epoch: 6| Step: 9
Training loss: 2.9874317432730293
Validation loss: 2.6924382242084914

Epoch: 6| Step: 10
Training loss: 2.4014933748044647
Validation loss: 2.6998426036009344

Epoch: 6| Step: 11
Training loss: 2.729727059019261
Validation loss: 2.705655116144579

Epoch: 6| Step: 12
Training loss: 2.7866337135714985
Validation loss: 2.7134326926080705

Epoch: 6| Step: 13
Training loss: 3.2299184272787755
Validation loss: 2.7118124910797894

Epoch: 127| Step: 0
Training loss: 3.009830105317976
Validation loss: 2.724659290371792

Epoch: 6| Step: 1
Training loss: 3.329617304534159
Validation loss: 2.7168574956998497

Epoch: 6| Step: 2
Training loss: 3.5858566507770324
Validation loss: 2.7251620513637653

Epoch: 6| Step: 3
Training loss: 2.1986757627861553
Validation loss: 2.7157331840321803

Epoch: 6| Step: 4
Training loss: 2.954335282593209
Validation loss: 2.7057131913730763

Epoch: 6| Step: 5
Training loss: 3.168551202139718
Validation loss: 2.7020517874645953

Epoch: 6| Step: 6
Training loss: 3.1310503562891103
Validation loss: 2.7063760122923495

Epoch: 6| Step: 7
Training loss: 2.8631933180563447
Validation loss: 2.697076124363634

Epoch: 6| Step: 8
Training loss: 3.2607010949885264
Validation loss: 2.7071882952685167

Epoch: 6| Step: 9
Training loss: 2.9942148377340656
Validation loss: 2.6971175237250002

Epoch: 6| Step: 10
Training loss: 3.023548212907538
Validation loss: 2.6992933630059945

Epoch: 6| Step: 11
Training loss: 2.1425010090027685
Validation loss: 2.698021524697253

Epoch: 6| Step: 12
Training loss: 3.2878180752472987
Validation loss: 2.685216558910647

Epoch: 6| Step: 13
Training loss: 3.073653793287593
Validation loss: 2.6793328731639052

Epoch: 128| Step: 0
Training loss: 3.5316487315071905
Validation loss: 2.6871074753302135

Epoch: 6| Step: 1
Training loss: 2.8479331971595467
Validation loss: 2.6838742013030594

Epoch: 6| Step: 2
Training loss: 2.8802694046324415
Validation loss: 2.678206134152565

Epoch: 6| Step: 3
Training loss: 2.8382337117328786
Validation loss: 2.6800985445281484

Epoch: 6| Step: 4
Training loss: 2.74329555979881
Validation loss: 2.676289606693254

Epoch: 6| Step: 5
Training loss: 3.0671634589568195
Validation loss: 2.6780453503144837

Epoch: 6| Step: 6
Training loss: 3.016479213082123
Validation loss: 2.670650114817576

Epoch: 6| Step: 7
Training loss: 3.18806497391334
Validation loss: 2.6761509918238646

Epoch: 6| Step: 8
Training loss: 3.3725431471454757
Validation loss: 2.672815461160559

Epoch: 6| Step: 9
Training loss: 2.973566264392867
Validation loss: 2.6710587647042603

Epoch: 6| Step: 10
Training loss: 3.2530435835940925
Validation loss: 2.6756960834997203

Epoch: 6| Step: 11
Training loss: 2.139370738768283
Validation loss: 2.682246960702367

Epoch: 6| Step: 12
Training loss: 2.638123811831339
Validation loss: 2.705295951154975

Epoch: 6| Step: 13
Training loss: 3.6813422044174855
Validation loss: 2.7387148177839573

Epoch: 129| Step: 0
Training loss: 3.7064747528323716
Validation loss: 2.7528349032413484

Epoch: 6| Step: 1
Training loss: 3.1200751598793093
Validation loss: 2.714988017090802

Epoch: 6| Step: 2
Training loss: 2.937348219825862
Validation loss: 2.681648892450095

Epoch: 6| Step: 3
Training loss: 3.08644335499911
Validation loss: 2.6676586354468053

Epoch: 6| Step: 4
Training loss: 2.7192376236615967
Validation loss: 2.6676664772585577

Epoch: 6| Step: 5
Training loss: 2.7957109980720847
Validation loss: 2.669727206030025

Epoch: 6| Step: 6
Training loss: 2.8482934895498926
Validation loss: 2.674022832892542

Epoch: 6| Step: 7
Training loss: 3.4457708559903093
Validation loss: 2.6718415288982134

Epoch: 6| Step: 8
Training loss: 2.922297809221163
Validation loss: 2.6771321940824095

Epoch: 6| Step: 9
Training loss: 3.196277873634174
Validation loss: 2.672422609964059

Epoch: 6| Step: 10
Training loss: 2.8309704707851546
Validation loss: 2.6760344843342807

Epoch: 6| Step: 11
Training loss: 2.763326519527095
Validation loss: 2.6767254258141544

Epoch: 6| Step: 12
Training loss: 2.971568004905134
Validation loss: 2.682956049772191

Epoch: 6| Step: 13
Training loss: 2.8588214609465994
Validation loss: 2.681347633169709

Epoch: 130| Step: 0
Training loss: 2.5182737065781144
Validation loss: 2.678238829820597

Epoch: 6| Step: 1
Training loss: 3.2813835480170215
Validation loss: 2.675823788880724

Epoch: 6| Step: 2
Training loss: 3.012518671381534
Validation loss: 2.6761030829503207

Epoch: 6| Step: 3
Training loss: 3.11198507438748
Validation loss: 2.6689832729471257

Epoch: 6| Step: 4
Training loss: 3.1401512585794036
Validation loss: 2.670191637233069

Epoch: 6| Step: 5
Training loss: 3.1500745734212763
Validation loss: 2.669218795273122

Epoch: 6| Step: 6
Training loss: 2.6785912231440516
Validation loss: 2.669337449982044

Epoch: 6| Step: 7
Training loss: 3.4457953497481815
Validation loss: 2.670844046536495

Epoch: 6| Step: 8
Training loss: 2.5828784931888285
Validation loss: 2.678401285677327

Epoch: 6| Step: 9
Training loss: 2.83503073916178
Validation loss: 2.684160558298818

Epoch: 6| Step: 10
Training loss: 3.055969749660465
Validation loss: 2.6902167936736006

Epoch: 6| Step: 11
Training loss: 2.688034448045295
Validation loss: 2.695251713359029

Epoch: 6| Step: 12
Training loss: 3.794700596474289
Validation loss: 2.70580430110918

Epoch: 6| Step: 13
Training loss: 2.1455537064461643
Validation loss: 2.6992591149805496

Epoch: 131| Step: 0
Training loss: 2.6122846085676934
Validation loss: 2.681357019202224

Epoch: 6| Step: 1
Training loss: 3.1875415874086976
Validation loss: 2.6762674808306315

Epoch: 6| Step: 2
Training loss: 2.943413807973779
Validation loss: 2.669005816990031

Epoch: 6| Step: 3
Training loss: 2.934422930731248
Validation loss: 2.660993770336083

Epoch: 6| Step: 4
Training loss: 2.87795785424798
Validation loss: 2.66303252678047

Epoch: 6| Step: 5
Training loss: 2.979676387548104
Validation loss: 2.6612361390336496

Epoch: 6| Step: 6
Training loss: 2.4149298729991946
Validation loss: 2.6620674509486117

Epoch: 6| Step: 7
Training loss: 3.376145768828765
Validation loss: 2.660686438699324

Epoch: 6| Step: 8
Training loss: 2.87718747719551
Validation loss: 2.6645379170778845

Epoch: 6| Step: 9
Training loss: 3.2157974775229348
Validation loss: 2.661871490058988

Epoch: 6| Step: 10
Training loss: 3.599786349420561
Validation loss: 2.663662418603699

Epoch: 6| Step: 11
Training loss: 2.594556384379818
Validation loss: 2.660588776799359

Epoch: 6| Step: 12
Training loss: 3.2237438978985726
Validation loss: 2.6568187194066506

Epoch: 6| Step: 13
Training loss: 3.1117486376216563
Validation loss: 2.659079587950085

Epoch: 132| Step: 0
Training loss: 3.090447406661347
Validation loss: 2.657150953498299

Epoch: 6| Step: 1
Training loss: 3.1392287761423123
Validation loss: 2.6613518503944036

Epoch: 6| Step: 2
Training loss: 2.641804809648645
Validation loss: 2.6663391010795388

Epoch: 6| Step: 3
Training loss: 3.6145756233125774
Validation loss: 2.680512511905079

Epoch: 6| Step: 4
Training loss: 2.8934474053580517
Validation loss: 2.6970008863398465

Epoch: 6| Step: 5
Training loss: 2.6052611123867413
Validation loss: 2.691202953730953

Epoch: 6| Step: 6
Training loss: 3.00477918781552
Validation loss: 2.716188650228607

Epoch: 6| Step: 7
Training loss: 2.483273819929267
Validation loss: 2.6998082229568996

Epoch: 6| Step: 8
Training loss: 2.669736128780231
Validation loss: 2.698538070372071

Epoch: 6| Step: 9
Training loss: 3.149486887481665
Validation loss: 2.6925091527686025

Epoch: 6| Step: 10
Training loss: 3.6829202952609656
Validation loss: 2.6766810810243116

Epoch: 6| Step: 11
Training loss: 2.8766454880495815
Validation loss: 2.6711007271100615

Epoch: 6| Step: 12
Training loss: 3.1581495253355945
Validation loss: 2.6633875182463806

Epoch: 6| Step: 13
Training loss: 2.4599685941412703
Validation loss: 2.6591453007581634

Epoch: 133| Step: 0
Training loss: 2.3325720180829266
Validation loss: 2.655206740595328

Epoch: 6| Step: 1
Training loss: 3.1155463083444093
Validation loss: 2.6518993479905175

Epoch: 6| Step: 2
Training loss: 3.4429732705041802
Validation loss: 2.6545336829867967

Epoch: 6| Step: 3
Training loss: 3.046411723593585
Validation loss: 2.6529764956320228

Epoch: 6| Step: 4
Training loss: 2.67630316106459
Validation loss: 2.6492223205667176

Epoch: 6| Step: 5
Training loss: 2.8937694046325633
Validation loss: 2.650856888885581

Epoch: 6| Step: 6
Training loss: 2.7470925306824574
Validation loss: 2.650797881659911

Epoch: 6| Step: 7
Training loss: 3.269471453959621
Validation loss: 2.6526194169779007

Epoch: 6| Step: 8
Training loss: 2.7114755058160007
Validation loss: 2.655964077756453

Epoch: 6| Step: 9
Training loss: 2.903476499173017
Validation loss: 2.666709451242465

Epoch: 6| Step: 10
Training loss: 2.8489382857617507
Validation loss: 2.6807485820140715

Epoch: 6| Step: 11
Training loss: 3.40566451614201
Validation loss: 2.6827297605991056

Epoch: 6| Step: 12
Training loss: 3.076260539396818
Validation loss: 2.7024483304122784

Epoch: 6| Step: 13
Training loss: 3.4195579452814795
Validation loss: 2.706267241023971

Epoch: 134| Step: 0
Training loss: 3.072238929278486
Validation loss: 2.7142956681901325

Epoch: 6| Step: 1
Training loss: 2.1059165577456427
Validation loss: 2.7250319975658077

Epoch: 6| Step: 2
Training loss: 2.6277509534280807
Validation loss: 2.7170938490648484

Epoch: 6| Step: 3
Training loss: 3.7711394521197414
Validation loss: 2.6761722718214553

Epoch: 6| Step: 4
Training loss: 3.1862163576944287
Validation loss: 2.6480376698956865

Epoch: 6| Step: 5
Training loss: 2.4866435891410945
Validation loss: 2.6461407976382154

Epoch: 6| Step: 6
Training loss: 3.3144980108922955
Validation loss: 2.649935359131622

Epoch: 6| Step: 7
Training loss: 3.478020728674128
Validation loss: 2.6607760239141713

Epoch: 6| Step: 8
Training loss: 2.783214346879789
Validation loss: 2.6728460738118867

Epoch: 6| Step: 9
Training loss: 3.3256999032070538
Validation loss: 2.6596454409827874

Epoch: 6| Step: 10
Training loss: 2.4578075062094156
Validation loss: 2.6600859901702956

Epoch: 6| Step: 11
Training loss: 3.298862527111174
Validation loss: 2.6659476236268747

Epoch: 6| Step: 12
Training loss: 3.4236080710445074
Validation loss: 2.6613279993479657

Epoch: 6| Step: 13
Training loss: 1.7266080686329648
Validation loss: 2.661609160309537

Epoch: 135| Step: 0
Training loss: 2.5622509160750613
Validation loss: 2.661059940691727

Epoch: 6| Step: 1
Training loss: 2.787845463578709
Validation loss: 2.657853697186181

Epoch: 6| Step: 2
Training loss: 3.050001838558456
Validation loss: 2.6555173255518225

Epoch: 6| Step: 3
Training loss: 2.9045651381863986
Validation loss: 2.655603220768681

Epoch: 6| Step: 4
Training loss: 2.308366741760358
Validation loss: 2.653190446115504

Epoch: 6| Step: 5
Training loss: 3.171146553466429
Validation loss: 2.651934486048283

Epoch: 6| Step: 6
Training loss: 3.0569710159899355
Validation loss: 2.649819849693312

Epoch: 6| Step: 7
Training loss: 3.54812976303977
Validation loss: 2.652440634908044

Epoch: 6| Step: 8
Training loss: 3.1045413377872397
Validation loss: 2.666429155934695

Epoch: 6| Step: 9
Training loss: 2.872663460671362
Validation loss: 2.699482412644694

Epoch: 6| Step: 10
Training loss: 2.9483209519227844
Validation loss: 2.7098885197355598

Epoch: 6| Step: 11
Training loss: 3.6790286241658463
Validation loss: 2.7050367664412343

Epoch: 6| Step: 12
Training loss: 2.682653270655125
Validation loss: 2.71076173571029

Epoch: 6| Step: 13
Training loss: 3.2712004307747304
Validation loss: 2.7276518089270128

Epoch: 136| Step: 0
Training loss: 2.733545493599141
Validation loss: 2.7143783461970843

Epoch: 6| Step: 1
Training loss: 2.937476787069602
Validation loss: 2.7200364937617283

Epoch: 6| Step: 2
Training loss: 3.387939092464693
Validation loss: 2.7009968799597144

Epoch: 6| Step: 3
Training loss: 2.7424552765001504
Validation loss: 2.6803673370608796

Epoch: 6| Step: 4
Training loss: 3.3747589590393283
Validation loss: 2.6756659892286

Epoch: 6| Step: 5
Training loss: 2.653373866546399
Validation loss: 2.6624894280931235

Epoch: 6| Step: 6
Training loss: 3.183394237421688
Validation loss: 2.6668206645993817

Epoch: 6| Step: 7
Training loss: 2.3734652931338984
Validation loss: 2.664204998160987

Epoch: 6| Step: 8
Training loss: 2.8712199695895
Validation loss: 2.6650569874601335

Epoch: 6| Step: 9
Training loss: 3.048831722201193
Validation loss: 2.6688743157935373

Epoch: 6| Step: 10
Training loss: 2.5823103714901916
Validation loss: 2.6675736742812903

Epoch: 6| Step: 11
Training loss: 3.4749498377410997
Validation loss: 2.67368759907424

Epoch: 6| Step: 12
Training loss: 2.9847814472898913
Validation loss: 2.691170136451878

Epoch: 6| Step: 13
Training loss: 3.601491004747255
Validation loss: 2.689927903922486

Epoch: 137| Step: 0
Training loss: 3.0660215099996075
Validation loss: 2.6771899888738426

Epoch: 6| Step: 1
Training loss: 3.029836895521664
Validation loss: 2.6650464195015515

Epoch: 6| Step: 2
Training loss: 2.5695789531061966
Validation loss: 2.653599626496157

Epoch: 6| Step: 3
Training loss: 2.9758306289385668
Validation loss: 2.653447995783393

Epoch: 6| Step: 4
Training loss: 3.0146342018614325
Validation loss: 2.644705537769398

Epoch: 6| Step: 5
Training loss: 2.4293568867645328
Validation loss: 2.6445437708972523

Epoch: 6| Step: 6
Training loss: 2.9348096499218506
Validation loss: 2.641821780169431

Epoch: 6| Step: 7
Training loss: 3.1151746786012247
Validation loss: 2.6367442820659988

Epoch: 6| Step: 8
Training loss: 3.301024948243097
Validation loss: 2.639761765017386

Epoch: 6| Step: 9
Training loss: 3.129256439614396
Validation loss: 2.6369466416817997

Epoch: 6| Step: 10
Training loss: 3.065452242619713
Validation loss: 2.6354647152987343

Epoch: 6| Step: 11
Training loss: 2.8843698817710886
Validation loss: 2.637147257329406

Epoch: 6| Step: 12
Training loss: 2.9946960610871707
Validation loss: 2.638143462822554

Epoch: 6| Step: 13
Training loss: 3.3007828390806084
Validation loss: 2.639384693516095

Epoch: 138| Step: 0
Training loss: 2.4599987358772317
Validation loss: 2.6452904679570066

Epoch: 6| Step: 1
Training loss: 2.5520433280041024
Validation loss: 2.6449937684225544

Epoch: 6| Step: 2
Training loss: 3.449946809441571
Validation loss: 2.652135183026652

Epoch: 6| Step: 3
Training loss: 3.219226690752019
Validation loss: 2.6632534058239687

Epoch: 6| Step: 4
Training loss: 3.5478195747594587
Validation loss: 2.6701859169742477

Epoch: 6| Step: 5
Training loss: 2.7659745507327997
Validation loss: 2.6452695239216464

Epoch: 6| Step: 6
Training loss: 2.672410877765088
Validation loss: 2.643222340897729

Epoch: 6| Step: 7
Training loss: 2.9887693318212847
Validation loss: 2.637161642817568

Epoch: 6| Step: 8
Training loss: 3.0118235608181005
Validation loss: 2.6354061085803497

Epoch: 6| Step: 9
Training loss: 2.7685965398622296
Validation loss: 2.6374566330110003

Epoch: 6| Step: 10
Training loss: 3.006895088885132
Validation loss: 2.6389440598915597

Epoch: 6| Step: 11
Training loss: 3.127781507475914
Validation loss: 2.6351921423321127

Epoch: 6| Step: 12
Training loss: 2.5486662948505683
Validation loss: 2.6382132351945917

Epoch: 6| Step: 13
Training loss: 3.477709360299442
Validation loss: 2.6401448923462736

Epoch: 139| Step: 0
Training loss: 3.350936439924527
Validation loss: 2.639835036354552

Epoch: 6| Step: 1
Training loss: 3.218836218410646
Validation loss: 2.6403441959730403

Epoch: 6| Step: 2
Training loss: 2.5523173218460244
Validation loss: 2.6458237634675816

Epoch: 6| Step: 3
Training loss: 2.890174294466093
Validation loss: 2.6500735981403496

Epoch: 6| Step: 4
Training loss: 2.7368647983706733
Validation loss: 2.6681874409782087

Epoch: 6| Step: 5
Training loss: 3.3553607465883744
Validation loss: 2.660435754994987

Epoch: 6| Step: 6
Training loss: 2.368212487423711
Validation loss: 2.6767003742420257

Epoch: 6| Step: 7
Training loss: 2.958679465519626
Validation loss: 2.717800509705053

Epoch: 6| Step: 8
Training loss: 3.024751599414269
Validation loss: 2.715913246199755

Epoch: 6| Step: 9
Training loss: 2.890928840133534
Validation loss: 2.693857352271803

Epoch: 6| Step: 10
Training loss: 2.9100966069810967
Validation loss: 2.6751809696183697

Epoch: 6| Step: 11
Training loss: 2.8599012547232427
Validation loss: 2.649827261526778

Epoch: 6| Step: 12
Training loss: 3.4401174117167113
Validation loss: 2.6417071523139293

Epoch: 6| Step: 13
Training loss: 2.93876701788151
Validation loss: 2.6364079078958405

Epoch: 140| Step: 0
Training loss: 3.3512349713396525
Validation loss: 2.637689553841191

Epoch: 6| Step: 1
Training loss: 2.6849647806653043
Validation loss: 2.6387961293792457

Epoch: 6| Step: 2
Training loss: 2.861189136449412
Validation loss: 2.6396714044637615

Epoch: 6| Step: 3
Training loss: 3.125866273974073
Validation loss: 2.647708685217159

Epoch: 6| Step: 4
Training loss: 3.667373690208072
Validation loss: 2.650426990195081

Epoch: 6| Step: 5
Training loss: 2.602469529588253
Validation loss: 2.652529279870011

Epoch: 6| Step: 6
Training loss: 2.778514588440426
Validation loss: 2.6530244684613575

Epoch: 6| Step: 7
Training loss: 2.812425315713045
Validation loss: 2.651534300525772

Epoch: 6| Step: 8
Training loss: 2.703976888320838
Validation loss: 2.658051781009572

Epoch: 6| Step: 9
Training loss: 3.3036198616159633
Validation loss: 2.6551712692863205

Epoch: 6| Step: 10
Training loss: 3.2815229029927875
Validation loss: 2.6562792627410503

Epoch: 6| Step: 11
Training loss: 2.691609810936313
Validation loss: 2.668410237520149

Epoch: 6| Step: 12
Training loss: 3.0243204094314824
Validation loss: 2.6568055519569684

Epoch: 6| Step: 13
Training loss: 2.8794372151772056
Validation loss: 2.6496653293834855

Epoch: 141| Step: 0
Training loss: 2.433557696863759
Validation loss: 2.6494340293771765

Epoch: 6| Step: 1
Training loss: 2.771019969954955
Validation loss: 2.651923538081703

Epoch: 6| Step: 2
Training loss: 1.913759417769209
Validation loss: 2.6408056673186406

Epoch: 6| Step: 3
Training loss: 2.99597024476538
Validation loss: 2.638089439250625

Epoch: 6| Step: 4
Training loss: 3.4236011070808576
Validation loss: 2.633521093871355

Epoch: 6| Step: 5
Training loss: 2.8793598785566386
Validation loss: 2.6316623706688134

Epoch: 6| Step: 6
Training loss: 3.285231871760791
Validation loss: 2.6416639534180106

Epoch: 6| Step: 7
Training loss: 2.572012759258605
Validation loss: 2.675147350133583

Epoch: 6| Step: 8
Training loss: 3.0678769612017143
Validation loss: 2.7031027865109145

Epoch: 6| Step: 9
Training loss: 3.52382940240111
Validation loss: 2.753055850053305

Epoch: 6| Step: 10
Training loss: 3.540384950774479
Validation loss: 2.7868310371835436

Epoch: 6| Step: 11
Training loss: 3.244864881902888
Validation loss: 2.7631634092469946

Epoch: 6| Step: 12
Training loss: 2.7854311942437584
Validation loss: 2.713106167489729

Epoch: 6| Step: 13
Training loss: 3.1900229847238415
Validation loss: 2.644113980166695

Epoch: 142| Step: 0
Training loss: 3.0656451210038274
Validation loss: 2.6380493219536754

Epoch: 6| Step: 1
Training loss: 3.033990623887121
Validation loss: 2.6416628189449667

Epoch: 6| Step: 2
Training loss: 2.9397830613213345
Validation loss: 2.664782854372426

Epoch: 6| Step: 3
Training loss: 3.6088521999875502
Validation loss: 2.694771086519024

Epoch: 6| Step: 4
Training loss: 3.172517157133226
Validation loss: 2.6407034325254326

Epoch: 6| Step: 5
Training loss: 2.924265490521956
Validation loss: 2.6277339593516174

Epoch: 6| Step: 6
Training loss: 3.0315529583422087
Validation loss: 2.624441295414414

Epoch: 6| Step: 7
Training loss: 2.9529583596336857
Validation loss: 2.6264604235665683

Epoch: 6| Step: 8
Training loss: 3.1462146115349374
Validation loss: 2.626496384131922

Epoch: 6| Step: 9
Training loss: 2.959854612388428
Validation loss: 2.62462754251412

Epoch: 6| Step: 10
Training loss: 2.8161944390381213
Validation loss: 2.6195689514239597

Epoch: 6| Step: 11
Training loss: 2.6484265172499972
Validation loss: 2.624123265259631

Epoch: 6| Step: 12
Training loss: 2.7362223461107757
Validation loss: 2.6265608233900797

Epoch: 6| Step: 13
Training loss: 2.0389843922121056
Validation loss: 2.6351370883052336

Epoch: 143| Step: 0
Training loss: 2.5231118951721268
Validation loss: 2.631661299100779

Epoch: 6| Step: 1
Training loss: 2.9979412644265016
Validation loss: 2.63438988976763

Epoch: 6| Step: 2
Training loss: 3.0773528239108416
Validation loss: 2.636433967090112

Epoch: 6| Step: 3
Training loss: 3.498237165922712
Validation loss: 2.642051845734426

Epoch: 6| Step: 4
Training loss: 2.7197300690058186
Validation loss: 2.6420949276733263

Epoch: 6| Step: 5
Training loss: 3.2750317462809346
Validation loss: 2.6498840952141225

Epoch: 6| Step: 6
Training loss: 3.37231550476946
Validation loss: 2.6584265133606415

Epoch: 6| Step: 7
Training loss: 2.6923109065026183
Validation loss: 2.6631518142512025

Epoch: 6| Step: 8
Training loss: 2.7227862859291756
Validation loss: 2.6671141324655006

Epoch: 6| Step: 9
Training loss: 2.469002915959666
Validation loss: 2.6686141019819947

Epoch: 6| Step: 10
Training loss: 2.6865308921652296
Validation loss: 2.6723589331470623

Epoch: 6| Step: 11
Training loss: 3.1892605575670254
Validation loss: 2.6609730009599497

Epoch: 6| Step: 12
Training loss: 3.2977403707287776
Validation loss: 2.6619961244224197

Epoch: 6| Step: 13
Training loss: 2.5865448299042666
Validation loss: 2.6532979680424935

Epoch: 144| Step: 0
Training loss: 3.4152818680216
Validation loss: 2.652230216786102

Epoch: 6| Step: 1
Training loss: 2.996028496579987
Validation loss: 2.6417283749660347

Epoch: 6| Step: 2
Training loss: 2.34389912448764
Validation loss: 2.6336984556572074

Epoch: 6| Step: 3
Training loss: 3.164260820366526
Validation loss: 2.6315489866098005

Epoch: 6| Step: 4
Training loss: 2.8281506279052913
Validation loss: 2.627233643868773

Epoch: 6| Step: 5
Training loss: 3.3310805973688167
Validation loss: 2.622577696164393

Epoch: 6| Step: 6
Training loss: 2.6673699484729525
Validation loss: 2.623363179389409

Epoch: 6| Step: 7
Training loss: 2.702207023556252
Validation loss: 2.626508116450231

Epoch: 6| Step: 8
Training loss: 3.0043956025641068
Validation loss: 2.6255949228119735

Epoch: 6| Step: 9
Training loss: 2.906380106977219
Validation loss: 2.619002957649783

Epoch: 6| Step: 10
Training loss: 3.219741816624845
Validation loss: 2.616499056117047

Epoch: 6| Step: 11
Training loss: 2.838747592187597
Validation loss: 2.6226221170611086

Epoch: 6| Step: 12
Training loss: 2.861863351178793
Validation loss: 2.61721971100509

Epoch: 6| Step: 13
Training loss: 2.974683914703379
Validation loss: 2.6228905956370268

Epoch: 145| Step: 0
Training loss: 2.7620864903901015
Validation loss: 2.6257564677424723

Epoch: 6| Step: 1
Training loss: 3.084339046558594
Validation loss: 2.632184123766233

Epoch: 6| Step: 2
Training loss: 2.367346226371964
Validation loss: 2.631437332779916

Epoch: 6| Step: 3
Training loss: 2.6421708316829906
Validation loss: 2.6343559365557194

Epoch: 6| Step: 4
Training loss: 2.817509915081406
Validation loss: 2.6330647572133157

Epoch: 6| Step: 5
Training loss: 3.387143787081203
Validation loss: 2.6424684487148657

Epoch: 6| Step: 6
Training loss: 3.279888052076667
Validation loss: 2.654298771919842

Epoch: 6| Step: 7
Training loss: 2.500031375688123
Validation loss: 2.653179243892725

Epoch: 6| Step: 8
Training loss: 2.2916202771664547
Validation loss: 2.6450910281907367

Epoch: 6| Step: 9
Training loss: 2.8608174672303974
Validation loss: 2.6331115846843303

Epoch: 6| Step: 10
Training loss: 3.036710716651083
Validation loss: 2.628857208049525

Epoch: 6| Step: 11
Training loss: 3.370298431041712
Validation loss: 2.619874294875318

Epoch: 6| Step: 12
Training loss: 3.6210135540522863
Validation loss: 2.6171210745700515

Epoch: 6| Step: 13
Training loss: 2.986922370262019
Validation loss: 2.6134172627327974

Epoch: 146| Step: 0
Training loss: 3.1755740390195473
Validation loss: 2.6121891432042266

Epoch: 6| Step: 1
Training loss: 2.808208752216724
Validation loss: 2.608470520020385

Epoch: 6| Step: 2
Training loss: 3.490491211870685
Validation loss: 2.6083689953522082

Epoch: 6| Step: 3
Training loss: 2.9509506698099606
Validation loss: 2.6128911833141895

Epoch: 6| Step: 4
Training loss: 2.3749014181457393
Validation loss: 2.6092364361806673

Epoch: 6| Step: 5
Training loss: 3.0397135765264687
Validation loss: 2.6066789095270892

Epoch: 6| Step: 6
Training loss: 2.8728365843863064
Validation loss: 2.6073491273349942

Epoch: 6| Step: 7
Training loss: 2.632218472170499
Validation loss: 2.608902175406524

Epoch: 6| Step: 8
Training loss: 2.8112188176197797
Validation loss: 2.6122628100916794

Epoch: 6| Step: 9
Training loss: 2.7172572104498496
Validation loss: 2.6115123259732127

Epoch: 6| Step: 10
Training loss: 3.340926645075932
Validation loss: 2.609093019908763

Epoch: 6| Step: 11
Training loss: 2.9139342088046853
Validation loss: 2.6103774192456335

Epoch: 6| Step: 12
Training loss: 2.998873658137045
Validation loss: 2.6109263530666627

Epoch: 6| Step: 13
Training loss: 3.0440230104175723
Validation loss: 2.6104332773094097

Epoch: 147| Step: 0
Training loss: 3.2959055266127466
Validation loss: 2.6103472824807072

Epoch: 6| Step: 1
Training loss: 3.393173455429712
Validation loss: 2.6058875782263713

Epoch: 6| Step: 2
Training loss: 2.903753048866041
Validation loss: 2.6030006984783993

Epoch: 6| Step: 3
Training loss: 3.241127079737738
Validation loss: 2.603262661131711

Epoch: 6| Step: 4
Training loss: 3.2308765601401106
Validation loss: 2.60574431312845

Epoch: 6| Step: 5
Training loss: 2.281248536827977
Validation loss: 2.607588365312222

Epoch: 6| Step: 6
Training loss: 3.156169021625174
Validation loss: 2.6053188818537083

Epoch: 6| Step: 7
Training loss: 2.501977043424654
Validation loss: 2.605462273659175

Epoch: 6| Step: 8
Training loss: 3.1673633076860597
Validation loss: 2.609401570848568

Epoch: 6| Step: 9
Training loss: 2.4164162429321743
Validation loss: 2.6182339433244413

Epoch: 6| Step: 10
Training loss: 2.6301947464292996
Validation loss: 2.616475439938415

Epoch: 6| Step: 11
Training loss: 2.5270808229069663
Validation loss: 2.632484634465667

Epoch: 6| Step: 12
Training loss: 3.0191031050056547
Validation loss: 2.635013984546086

Epoch: 6| Step: 13
Training loss: 3.323091093804774
Validation loss: 2.6527029947984175

Epoch: 148| Step: 0
Training loss: 2.2935072934167997
Validation loss: 2.6518209227447285

Epoch: 6| Step: 1
Training loss: 3.1863416175046866
Validation loss: 2.671717363413808

Epoch: 6| Step: 2
Training loss: 2.163945274070008
Validation loss: 2.6668884341511796

Epoch: 6| Step: 3
Training loss: 3.257069308542859
Validation loss: 2.6436820715086786

Epoch: 6| Step: 4
Training loss: 2.6533483476389708
Validation loss: 2.6359463454942174

Epoch: 6| Step: 5
Training loss: 3.4925198322189073
Validation loss: 2.614995264001881

Epoch: 6| Step: 6
Training loss: 2.4236769340877213
Validation loss: 2.6071296292453794

Epoch: 6| Step: 7
Training loss: 3.1640447168674646
Validation loss: 2.6028210808891425

Epoch: 6| Step: 8
Training loss: 2.733285392557903
Validation loss: 2.5997373926727

Epoch: 6| Step: 9
Training loss: 2.829009534229813
Validation loss: 2.600574915319853

Epoch: 6| Step: 10
Training loss: 3.12630252395917
Validation loss: 2.598851286154778

Epoch: 6| Step: 11
Training loss: 2.9990965754473233
Validation loss: 2.5940284752481415

Epoch: 6| Step: 12
Training loss: 3.153884605652833
Validation loss: 2.5945311337606247

Epoch: 6| Step: 13
Training loss: 3.7131883079475405
Validation loss: 2.5960140238532157

Epoch: 149| Step: 0
Training loss: 3.325714097746337
Validation loss: 2.5966788779332064

Epoch: 6| Step: 1
Training loss: 2.6428732245556157
Validation loss: 2.596148708531126

Epoch: 6| Step: 2
Training loss: 2.77794158982347
Validation loss: 2.595314224336531

Epoch: 6| Step: 3
Training loss: 2.5782657469275323
Validation loss: 2.593349046748386

Epoch: 6| Step: 4
Training loss: 3.2454824595055967
Validation loss: 2.5976228854793635

Epoch: 6| Step: 5
Training loss: 2.8103727985311187
Validation loss: 2.599453432187165

Epoch: 6| Step: 6
Training loss: 2.425715397971404
Validation loss: 2.602422155675689

Epoch: 6| Step: 7
Training loss: 2.829650130464868
Validation loss: 2.5988550040876564

Epoch: 6| Step: 8
Training loss: 3.082126707815528
Validation loss: 2.602639689696578

Epoch: 6| Step: 9
Training loss: 2.5715494165332236
Validation loss: 2.6034174176409244

Epoch: 6| Step: 10
Training loss: 2.9207728954235086
Validation loss: 2.60089016415806

Epoch: 6| Step: 11
Training loss: 3.2769820294462213
Validation loss: 2.604575388346402

Epoch: 6| Step: 12
Training loss: 2.9977314637118235
Validation loss: 2.604918078068006

Epoch: 6| Step: 13
Training loss: 3.792036450697753
Validation loss: 2.601591249569642

Epoch: 150| Step: 0
Training loss: 3.133473314716129
Validation loss: 2.601547625976266

Epoch: 6| Step: 1
Training loss: 3.567767214695263
Validation loss: 2.602093614634307

Epoch: 6| Step: 2
Training loss: 3.6351145679831443
Validation loss: 2.601278789994233

Epoch: 6| Step: 3
Training loss: 2.696056141752694
Validation loss: 2.5953446038202745

Epoch: 6| Step: 4
Training loss: 2.802095027932269
Validation loss: 2.599549021075407

Epoch: 6| Step: 5
Training loss: 2.8047540598332543
Validation loss: 2.5955984657969733

Epoch: 6| Step: 6
Training loss: 3.159113274514445
Validation loss: 2.595940131888396

Epoch: 6| Step: 7
Training loss: 2.348272817069744
Validation loss: 2.595705315602028

Epoch: 6| Step: 8
Training loss: 2.576002229624429
Validation loss: 2.6003400226492586

Epoch: 6| Step: 9
Training loss: 2.3777111039167407
Validation loss: 2.597333466525526

Epoch: 6| Step: 10
Training loss: 2.7131910823708654
Validation loss: 2.5968323811059038

Epoch: 6| Step: 11
Training loss: 2.9488200139186698
Validation loss: 2.5970366739632436

Epoch: 6| Step: 12
Training loss: 2.9371519491278666
Validation loss: 2.598112650631234

Epoch: 6| Step: 13
Training loss: 3.1486995010597045
Validation loss: 2.595439371102981

Testing loss: 2.8425187087377624
