Epoch: 1| Step: 0
Training loss: 5.252205848693848
Validation loss: 5.132883979428199

Epoch: 6| Step: 1
Training loss: 4.988722801208496
Validation loss: 5.11488865780574

Epoch: 6| Step: 2
Training loss: 5.1929731369018555
Validation loss: 5.099278496157739

Epoch: 6| Step: 3
Training loss: 4.343296527862549
Validation loss: 5.084210780359084

Epoch: 6| Step: 4
Training loss: 3.6194238662719727
Validation loss: 5.067589682917441

Epoch: 6| Step: 5
Training loss: 5.83656120300293
Validation loss: 5.048722897806475

Epoch: 6| Step: 6
Training loss: 5.278372764587402
Validation loss: 5.026705085590321

Epoch: 6| Step: 7
Training loss: 4.544795036315918
Validation loss: 5.001329796288603

Epoch: 6| Step: 8
Training loss: 5.781479835510254
Validation loss: 4.972518074897028

Epoch: 6| Step: 9
Training loss: 4.706482410430908
Validation loss: 4.9402322000072845

Epoch: 6| Step: 10
Training loss: 4.83944845199585
Validation loss: 4.903547204950804

Epoch: 6| Step: 11
Training loss: 4.726425647735596
Validation loss: 4.862637360890706

Epoch: 6| Step: 12
Training loss: 4.16164493560791
Validation loss: 4.817523166697512

Epoch: 6| Step: 13
Training loss: 3.1453866958618164
Validation loss: 4.769011728225216

Epoch: 2| Step: 0
Training loss: 4.0499348640441895
Validation loss: 4.718812573340632

Epoch: 6| Step: 1
Training loss: 4.703096389770508
Validation loss: 4.666287642653271

Epoch: 6| Step: 2
Training loss: 4.721072196960449
Validation loss: 4.611239566597887

Epoch: 6| Step: 3
Training loss: 4.524962902069092
Validation loss: 4.553830515953802

Epoch: 6| Step: 4
Training loss: 2.413693904876709
Validation loss: 4.492485251477969

Epoch: 6| Step: 5
Training loss: 4.233572006225586
Validation loss: 4.424162249411306

Epoch: 6| Step: 6
Training loss: 4.086668014526367
Validation loss: 4.353778946784235

Epoch: 6| Step: 7
Training loss: 4.1621413230896
Validation loss: 4.2875650723775225

Epoch: 6| Step: 8
Training loss: 3.7711198329925537
Validation loss: 4.2347957805920675

Epoch: 6| Step: 9
Training loss: 4.283870697021484
Validation loss: 4.193062120868314

Epoch: 6| Step: 10
Training loss: 4.593128204345703
Validation loss: 4.153560202608826

Epoch: 6| Step: 11
Training loss: 4.812774658203125
Validation loss: 4.114644217234786

Epoch: 6| Step: 12
Training loss: 3.6522645950317383
Validation loss: 4.071855898826353

Epoch: 6| Step: 13
Training loss: 4.345262050628662
Validation loss: 4.036140923858971

Epoch: 3| Step: 0
Training loss: 3.904275894165039
Validation loss: 3.9946435600198726

Epoch: 6| Step: 1
Training loss: 4.624327659606934
Validation loss: 3.9526534054868963

Epoch: 6| Step: 2
Training loss: 3.571805000305176
Validation loss: 3.9262621069467194

Epoch: 6| Step: 3
Training loss: 4.067500591278076
Validation loss: 3.9021064132772465

Epoch: 6| Step: 4
Training loss: 2.5830626487731934
Validation loss: 3.8792860943783998

Epoch: 6| Step: 5
Training loss: 3.945326328277588
Validation loss: 3.854423389639906

Epoch: 6| Step: 6
Training loss: 4.789113998413086
Validation loss: 3.823240239133117

Epoch: 6| Step: 7
Training loss: 3.130023956298828
Validation loss: 3.791777303141932

Epoch: 6| Step: 8
Training loss: 3.8194079399108887
Validation loss: 3.7663079436107347

Epoch: 6| Step: 9
Training loss: 3.3984413146972656
Validation loss: 3.744573821303665

Epoch: 6| Step: 10
Training loss: 3.861210823059082
Validation loss: 3.7173025223516647

Epoch: 6| Step: 11
Training loss: 2.9178647994995117
Validation loss: 3.6892989937977125

Epoch: 6| Step: 12
Training loss: 3.962986469268799
Validation loss: 3.6783211128686064

Epoch: 6| Step: 13
Training loss: 2.7910656929016113
Validation loss: 3.6674850704849407

Epoch: 4| Step: 0
Training loss: 4.725810527801514
Validation loss: 3.6516114357979066

Epoch: 6| Step: 1
Training loss: 4.086536407470703
Validation loss: 3.6315593847664456

Epoch: 6| Step: 2
Training loss: 2.342090606689453
Validation loss: 3.6144716021835164

Epoch: 6| Step: 3
Training loss: 2.5690419673919678
Validation loss: 3.607875193319013

Epoch: 6| Step: 4
Training loss: 3.6220860481262207
Validation loss: 3.6095948219299316

Epoch: 6| Step: 5
Training loss: 4.354696750640869
Validation loss: 3.6049660277623

Epoch: 6| Step: 6
Training loss: 3.204071521759033
Validation loss: 3.5750397200225503

Epoch: 6| Step: 7
Training loss: 3.633124351501465
Validation loss: 3.5520073393339753

Epoch: 6| Step: 8
Training loss: 3.553246021270752
Validation loss: 3.54343681950723

Epoch: 6| Step: 9
Training loss: 3.5145888328552246
Validation loss: 3.533610882297639

Epoch: 6| Step: 10
Training loss: 3.1388628482818604
Validation loss: 3.5187256643849034

Epoch: 6| Step: 11
Training loss: 3.214965343475342
Validation loss: 3.504846167820756

Epoch: 6| Step: 12
Training loss: 3.0399575233459473
Validation loss: 3.4935831408346854

Epoch: 6| Step: 13
Training loss: 4.1106767654418945
Validation loss: 3.4798414579001804

Epoch: 5| Step: 0
Training loss: 3.7903342247009277
Validation loss: 3.4672086213224675

Epoch: 6| Step: 1
Training loss: 3.3497350215911865
Validation loss: 3.4545485050447526

Epoch: 6| Step: 2
Training loss: 4.6361918449401855
Validation loss: 3.4444803166133102

Epoch: 6| Step: 3
Training loss: 2.88192081451416
Validation loss: 3.432943113388554

Epoch: 6| Step: 4
Training loss: 3.4639134407043457
Validation loss: 3.4257913533077446

Epoch: 6| Step: 5
Training loss: 4.442028045654297
Validation loss: 3.420006316195252

Epoch: 6| Step: 6
Training loss: 3.0867786407470703
Validation loss: 3.408956135472944

Epoch: 6| Step: 7
Training loss: 3.197695016860962
Validation loss: 3.400597805617958

Epoch: 6| Step: 8
Training loss: 2.7309608459472656
Validation loss: 3.3911756007902083

Epoch: 6| Step: 9
Training loss: 2.1321940422058105
Validation loss: 3.3819182585644465

Epoch: 6| Step: 10
Training loss: 4.035188674926758
Validation loss: 3.3744480943167083

Epoch: 6| Step: 11
Training loss: 3.196639060974121
Validation loss: 3.367673848264961

Epoch: 6| Step: 12
Training loss: 3.4580917358398438
Validation loss: 3.3576834560722433

Epoch: 6| Step: 13
Training loss: 1.964621663093567
Validation loss: 3.3479460106101087

Epoch: 6| Step: 0
Training loss: 2.909025192260742
Validation loss: 3.3383974413717947

Epoch: 6| Step: 1
Training loss: 2.964956045150757
Validation loss: 3.332380574236634

Epoch: 6| Step: 2
Training loss: 4.824942588806152
Validation loss: 3.321935910050587

Epoch: 6| Step: 3
Training loss: 3.6343350410461426
Validation loss: 3.3166512648264566

Epoch: 6| Step: 4
Training loss: 2.034545421600342
Validation loss: 3.315800464281472

Epoch: 6| Step: 5
Training loss: 2.6735010147094727
Validation loss: 3.300832656122023

Epoch: 6| Step: 6
Training loss: 2.934445858001709
Validation loss: 3.294244545762257

Epoch: 6| Step: 7
Training loss: 3.837048292160034
Validation loss: 3.2919406147413355

Epoch: 6| Step: 8
Training loss: 3.1886210441589355
Validation loss: 3.284874277730142

Epoch: 6| Step: 9
Training loss: 3.8707237243652344
Validation loss: 3.279311369824153

Epoch: 6| Step: 10
Training loss: 2.6604788303375244
Validation loss: 3.2767171603377148

Epoch: 6| Step: 11
Training loss: 3.2958133220672607
Validation loss: 3.265852415433494

Epoch: 6| Step: 12
Training loss: 3.557990312576294
Validation loss: 3.25819758958714

Epoch: 6| Step: 13
Training loss: 3.4700071811676025
Validation loss: 3.249898838740523

Epoch: 7| Step: 0
Training loss: 2.9554824829101562
Validation loss: 3.2445480746607624

Epoch: 6| Step: 1
Training loss: 3.3167688846588135
Validation loss: 3.237137330475674

Epoch: 6| Step: 2
Training loss: 2.405097484588623
Validation loss: 3.2316545517213884

Epoch: 6| Step: 3
Training loss: 3.2479021549224854
Validation loss: 3.2261364306173017

Epoch: 6| Step: 4
Training loss: 2.923891544342041
Validation loss: 3.220674071260678

Epoch: 6| Step: 5
Training loss: 2.892192840576172
Validation loss: 3.2167541365469656

Epoch: 6| Step: 6
Training loss: 3.322322368621826
Validation loss: 3.2048281495289137

Epoch: 6| Step: 7
Training loss: 3.548330783843994
Validation loss: 3.2111324725612516

Epoch: 6| Step: 8
Training loss: 2.8846871852874756
Validation loss: 3.191353141620595

Epoch: 6| Step: 9
Training loss: 3.2517383098602295
Validation loss: 3.187280701052758

Epoch: 6| Step: 10
Training loss: 3.0097007751464844
Validation loss: 3.1862933328074794

Epoch: 6| Step: 11
Training loss: 3.973054885864258
Validation loss: 3.1845750219078472

Epoch: 6| Step: 12
Training loss: 3.7124595642089844
Validation loss: 3.180300943313106

Epoch: 6| Step: 13
Training loss: 3.6230921745300293
Validation loss: 3.1686315151952926

Epoch: 8| Step: 0
Training loss: 3.00038480758667
Validation loss: 3.1601229585627073

Epoch: 6| Step: 1
Training loss: 2.716193675994873
Validation loss: 3.1543538621676865

Epoch: 6| Step: 2
Training loss: 2.6156373023986816
Validation loss: 3.147395231390512

Epoch: 6| Step: 3
Training loss: 3.3848347663879395
Validation loss: 3.145472288131714

Epoch: 6| Step: 4
Training loss: 2.4135000705718994
Validation loss: 3.1394393700425343

Epoch: 6| Step: 5
Training loss: 3.201180934906006
Validation loss: 3.130241019751436

Epoch: 6| Step: 6
Training loss: 3.3195223808288574
Validation loss: 3.1264686123017342

Epoch: 6| Step: 7
Training loss: 3.861898422241211
Validation loss: 3.1269521661984023

Epoch: 6| Step: 8
Training loss: 2.6628284454345703
Validation loss: 3.1240957860023744

Epoch: 6| Step: 9
Training loss: 2.878716230392456
Validation loss: 3.116985441536032

Epoch: 6| Step: 10
Training loss: 2.7102766036987305
Validation loss: 3.112267699292911

Epoch: 6| Step: 11
Training loss: 4.959443092346191
Validation loss: 3.1054716366593555

Epoch: 6| Step: 12
Training loss: 2.6801047325134277
Validation loss: 3.0985696854129916

Epoch: 6| Step: 13
Training loss: 4.0240349769592285
Validation loss: 3.095397905636859

Epoch: 9| Step: 0
Training loss: 3.0621330738067627
Validation loss: 3.1292712252627135

Epoch: 6| Step: 1
Training loss: 2.338397979736328
Validation loss: 3.1099098523457847

Epoch: 6| Step: 2
Training loss: 3.452852725982666
Validation loss: 3.0812118181618313

Epoch: 6| Step: 3
Training loss: 1.9766749143600464
Validation loss: 3.1241647863900788

Epoch: 6| Step: 4
Training loss: 2.7432565689086914
Validation loss: 3.177279677442325

Epoch: 6| Step: 5
Training loss: 2.906825542449951
Validation loss: 3.1680796633484545

Epoch: 6| Step: 6
Training loss: 2.622561454772949
Validation loss: 3.1422326744243665

Epoch: 6| Step: 7
Training loss: 3.022935628890991
Validation loss: 3.1153656487823813

Epoch: 6| Step: 8
Training loss: 3.4736289978027344
Validation loss: 3.0795084225234164

Epoch: 6| Step: 9
Training loss: 3.753983736038208
Validation loss: 3.097857675244731

Epoch: 6| Step: 10
Training loss: 4.30003547668457
Validation loss: 3.1532941377291115

Epoch: 6| Step: 11
Training loss: 2.6926679611206055
Validation loss: 3.0941457979140745

Epoch: 6| Step: 12
Training loss: 4.044314384460449
Validation loss: 3.0784992761509393

Epoch: 6| Step: 13
Training loss: 3.955674171447754
Validation loss: 3.050891601911155

Epoch: 10| Step: 0
Training loss: 4.160748481750488
Validation loss: 3.0451683280288533

Epoch: 6| Step: 1
Training loss: 2.4627697467803955
Validation loss: 3.054416764167047

Epoch: 6| Step: 2
Training loss: 3.0290982723236084
Validation loss: 3.0781029603814565

Epoch: 6| Step: 3
Training loss: 3.691756248474121
Validation loss: 3.053479056204519

Epoch: 6| Step: 4
Training loss: 3.630265712738037
Validation loss: 3.031266063772222

Epoch: 6| Step: 5
Training loss: 2.4341773986816406
Validation loss: 3.024686364717381

Epoch: 6| Step: 6
Training loss: 2.8566102981567383
Validation loss: 3.027818069663099

Epoch: 6| Step: 7
Training loss: 3.144728660583496
Validation loss: 3.0335525569095405

Epoch: 6| Step: 8
Training loss: 3.2794604301452637
Validation loss: 3.0422273297463693

Epoch: 6| Step: 9
Training loss: 3.7926669120788574
Validation loss: 3.0305219363140803

Epoch: 6| Step: 10
Training loss: 3.082718849182129
Validation loss: 3.0158264944630284

Epoch: 6| Step: 11
Training loss: 2.5732951164245605
Validation loss: 3.007968492405389

Epoch: 6| Step: 12
Training loss: 2.4473533630371094
Validation loss: 3.002202695415866

Epoch: 6| Step: 13
Training loss: 2.338932991027832
Validation loss: 3.029056105562436

Epoch: 11| Step: 0
Training loss: 3.192640542984009
Validation loss: 2.984509124550768

Epoch: 6| Step: 1
Training loss: 3.171175479888916
Validation loss: 2.9904756610111525

Epoch: 6| Step: 2
Training loss: 3.688662052154541
Validation loss: 2.9972611242725002

Epoch: 6| Step: 3
Training loss: 3.003307819366455
Validation loss: 2.9722576243903047

Epoch: 6| Step: 4
Training loss: 3.1339058876037598
Validation loss: 2.955705827282321

Epoch: 6| Step: 5
Training loss: 2.4132251739501953
Validation loss: 2.9461789028618925

Epoch: 6| Step: 6
Training loss: 2.3644607067108154
Validation loss: 2.944644230668263

Epoch: 6| Step: 7
Training loss: 3.044034957885742
Validation loss: 2.9547012108628468

Epoch: 6| Step: 8
Training loss: 2.589071750640869
Validation loss: 2.9413867304402013

Epoch: 6| Step: 9
Training loss: 3.2490322589874268
Validation loss: 2.9353332775895313

Epoch: 6| Step: 10
Training loss: 2.607999801635742
Validation loss: 2.933417607379216

Epoch: 6| Step: 11
Training loss: 3.244568347930908
Validation loss: 2.9309982689478065

Epoch: 6| Step: 12
Training loss: 2.768935203552246
Validation loss: 2.927338497613066

Epoch: 6| Step: 13
Training loss: 4.7851433753967285
Validation loss: 2.924207261813584

Epoch: 12| Step: 0
Training loss: 2.871572494506836
Validation loss: 2.923128627961682

Epoch: 6| Step: 1
Training loss: 2.7738471031188965
Validation loss: 2.933674156024892

Epoch: 6| Step: 2
Training loss: 4.127922058105469
Validation loss: 2.937730607166085

Epoch: 6| Step: 3
Training loss: 2.777228593826294
Validation loss: 2.9126025117853636

Epoch: 6| Step: 4
Training loss: 3.3002309799194336
Validation loss: 2.9107606026434127

Epoch: 6| Step: 5
Training loss: 3.038365602493286
Validation loss: 2.916027722820159

Epoch: 6| Step: 6
Training loss: 2.6404545307159424
Validation loss: 2.952004696733208

Epoch: 6| Step: 7
Training loss: 2.887688159942627
Validation loss: 2.901607298081921

Epoch: 6| Step: 8
Training loss: 2.183342933654785
Validation loss: 2.9187021691312074

Epoch: 6| Step: 9
Training loss: 3.033646583557129
Validation loss: 2.9433948686045985

Epoch: 6| Step: 10
Training loss: 3.207846164703369
Validation loss: 2.9479688828991306

Epoch: 6| Step: 11
Training loss: 2.9726076126098633
Validation loss: 2.958955792970555

Epoch: 6| Step: 12
Training loss: 3.0406136512756348
Validation loss: 2.9350430888514363

Epoch: 6| Step: 13
Training loss: 3.757674217224121
Validation loss: 2.924018636826546

Epoch: 13| Step: 0
Training loss: 2.7492175102233887
Validation loss: 2.9031827731799056

Epoch: 6| Step: 1
Training loss: 2.7601356506347656
Validation loss: 2.899421117639029

Epoch: 6| Step: 2
Training loss: 2.9209651947021484
Validation loss: 2.909388521666168

Epoch: 6| Step: 3
Training loss: 3.928910732269287
Validation loss: 2.9128492621965307

Epoch: 6| Step: 4
Training loss: 2.555276393890381
Validation loss: 2.9113647322500906

Epoch: 6| Step: 5
Training loss: 3.151848554611206
Validation loss: 2.9235506621740197

Epoch: 6| Step: 6
Training loss: 4.2607011795043945
Validation loss: 2.937864201043242

Epoch: 6| Step: 7
Training loss: 2.519188642501831
Validation loss: 2.8821356296539307

Epoch: 6| Step: 8
Training loss: 2.8434619903564453
Validation loss: 2.870758879569269

Epoch: 6| Step: 9
Training loss: 2.7190637588500977
Validation loss: 2.864930211856801

Epoch: 6| Step: 10
Training loss: 3.4290671348571777
Validation loss: 2.8587783459694154

Epoch: 6| Step: 11
Training loss: 3.30169939994812
Validation loss: 2.856027833877071

Epoch: 6| Step: 12
Training loss: 2.680241107940674
Validation loss: 2.852575553360806

Epoch: 6| Step: 13
Training loss: 1.3867745399475098
Validation loss: 2.847364133404147

Epoch: 14| Step: 0
Training loss: 2.4907455444335938
Validation loss: 2.854420328652987

Epoch: 6| Step: 1
Training loss: 3.9213531017303467
Validation loss: 2.8555616486457085

Epoch: 6| Step: 2
Training loss: 3.2354037761688232
Validation loss: 2.853102953203263

Epoch: 6| Step: 3
Training loss: 2.5219147205352783
Validation loss: 2.8412935682522353

Epoch: 6| Step: 4
Training loss: 3.5566787719726562
Validation loss: 2.834030300058344

Epoch: 6| Step: 5
Training loss: 2.302013874053955
Validation loss: 2.8277031785698346

Epoch: 6| Step: 6
Training loss: 3.764815330505371
Validation loss: 2.8243543255713677

Epoch: 6| Step: 7
Training loss: 3.207892417907715
Validation loss: 2.819093260713803

Epoch: 6| Step: 8
Training loss: 2.951101779937744
Validation loss: 2.8155950295027865

Epoch: 6| Step: 9
Training loss: 2.511636734008789
Validation loss: 2.814289269908782

Epoch: 6| Step: 10
Training loss: 2.3575098514556885
Validation loss: 2.812900341967101

Epoch: 6| Step: 11
Training loss: 2.551692485809326
Validation loss: 2.8104757570451304

Epoch: 6| Step: 12
Training loss: 2.4186081886291504
Validation loss: 2.807666817019063

Epoch: 6| Step: 13
Training loss: 3.9664714336395264
Validation loss: 2.809078388316657

Epoch: 15| Step: 0
Training loss: 3.241048812866211
Validation loss: 2.8088396672279603

Epoch: 6| Step: 1
Training loss: 3.170267343521118
Validation loss: 2.804243831224339

Epoch: 6| Step: 2
Training loss: 3.603339433670044
Validation loss: 2.80617715210043

Epoch: 6| Step: 3
Training loss: 2.4830281734466553
Validation loss: 2.8033675327095935

Epoch: 6| Step: 4
Training loss: 2.800532341003418
Validation loss: 2.803559867284631

Epoch: 6| Step: 5
Training loss: 3.1356983184814453
Validation loss: 2.802683684133714

Epoch: 6| Step: 6
Training loss: 2.9892094135284424
Validation loss: 2.801392250163581

Epoch: 6| Step: 7
Training loss: 3.764679431915283
Validation loss: 2.7985029707672777

Epoch: 6| Step: 8
Training loss: 1.7763144969940186
Validation loss: 2.793191340661818

Epoch: 6| Step: 9
Training loss: 2.846836566925049
Validation loss: 2.7919801588981383

Epoch: 6| Step: 10
Training loss: 2.8066346645355225
Validation loss: 2.7938825135589926

Epoch: 6| Step: 11
Training loss: 2.504638671875
Validation loss: 2.788364912873955

Epoch: 6| Step: 12
Training loss: 2.5985300540924072
Validation loss: 2.788394574196108

Epoch: 6| Step: 13
Training loss: 3.658712148666382
Validation loss: 2.788236351423366

Epoch: 16| Step: 0
Training loss: 2.868072748184204
Validation loss: 2.7842075850373957

Epoch: 6| Step: 1
Training loss: 2.4924328327178955
Validation loss: 2.7829881765509166

Epoch: 6| Step: 2
Training loss: 2.8302481174468994
Validation loss: 2.779048317222185

Epoch: 6| Step: 3
Training loss: 2.683314323425293
Validation loss: 2.778336755691036

Epoch: 6| Step: 4
Training loss: 3.8943707942962646
Validation loss: 2.7762095825646513

Epoch: 6| Step: 5
Training loss: 3.7242884635925293
Validation loss: 2.7765402306792555

Epoch: 6| Step: 6
Training loss: 3.363961696624756
Validation loss: 2.7752262623079362

Epoch: 6| Step: 7
Training loss: 1.2315974235534668
Validation loss: 2.773794968922933

Epoch: 6| Step: 8
Training loss: 3.5479884147644043
Validation loss: 2.7724238493109263

Epoch: 6| Step: 9
Training loss: 3.2272329330444336
Validation loss: 2.7735506360248854

Epoch: 6| Step: 10
Training loss: 3.310546398162842
Validation loss: 2.770624094111945

Epoch: 6| Step: 11
Training loss: 2.8589720726013184
Validation loss: 2.768981069646856

Epoch: 6| Step: 12
Training loss: 2.0664401054382324
Validation loss: 2.7659099794203237

Epoch: 6| Step: 13
Training loss: 2.629321575164795
Validation loss: 2.765236895571473

Epoch: 17| Step: 0
Training loss: 3.072100877761841
Validation loss: 2.7626842042451263

Epoch: 6| Step: 1
Training loss: 3.2695913314819336
Validation loss: 2.7641022897535756

Epoch: 6| Step: 2
Training loss: 3.3476479053497314
Validation loss: 2.7643608226571033

Epoch: 6| Step: 3
Training loss: 3.0636227130889893
Validation loss: 2.7629857934931272

Epoch: 6| Step: 4
Training loss: 2.8836584091186523
Validation loss: 2.7607179534050728

Epoch: 6| Step: 5
Training loss: 3.422882556915283
Validation loss: 2.758267858976959

Epoch: 6| Step: 6
Training loss: 3.173375368118286
Validation loss: 2.7596262860041794

Epoch: 6| Step: 7
Training loss: 2.589965343475342
Validation loss: 2.7558225944478023

Epoch: 6| Step: 8
Training loss: 2.8467748165130615
Validation loss: 2.7584787338010726

Epoch: 6| Step: 9
Training loss: 1.855330228805542
Validation loss: 2.7568615277608237

Epoch: 6| Step: 10
Training loss: 2.9445669651031494
Validation loss: 2.759577243558822

Epoch: 6| Step: 11
Training loss: 2.8005173206329346
Validation loss: 2.7551932104172243

Epoch: 6| Step: 12
Training loss: 2.5944366455078125
Validation loss: 2.753645617474792

Epoch: 6| Step: 13
Training loss: 2.7936999797821045
Validation loss: 2.7542849843220045

Epoch: 18| Step: 0
Training loss: 2.2234864234924316
Validation loss: 2.756704540662868

Epoch: 6| Step: 1
Training loss: 3.822021961212158
Validation loss: 2.756305028033513

Epoch: 6| Step: 2
Training loss: 1.6019883155822754
Validation loss: 2.7523013391802387

Epoch: 6| Step: 3
Training loss: 2.404843807220459
Validation loss: 2.751330442326043

Epoch: 6| Step: 4
Training loss: 2.8480920791625977
Validation loss: 2.749754213517712

Epoch: 6| Step: 5
Training loss: 2.485252857208252
Validation loss: 2.7474644055930515

Epoch: 6| Step: 6
Training loss: 3.309673547744751
Validation loss: 2.749341070011098

Epoch: 6| Step: 7
Training loss: 3.7070846557617188
Validation loss: 2.7506984126183296

Epoch: 6| Step: 8
Training loss: 3.7655258178710938
Validation loss: 2.749789212339668

Epoch: 6| Step: 9
Training loss: 1.9446618556976318
Validation loss: 2.7464066423395628

Epoch: 6| Step: 10
Training loss: 3.230588436126709
Validation loss: 2.746810310630388

Epoch: 6| Step: 11
Training loss: 3.231376886367798
Validation loss: 2.740725701855075

Epoch: 6| Step: 12
Training loss: 3.0600883960723877
Validation loss: 2.7397471474063013

Epoch: 6| Step: 13
Training loss: 3.0660548210144043
Validation loss: 2.742613874455934

Epoch: 19| Step: 0
Training loss: 2.7503085136413574
Validation loss: 2.7384440924531672

Epoch: 6| Step: 1
Training loss: 2.9280076026916504
Validation loss: 2.7339794610136297

Epoch: 6| Step: 2
Training loss: 3.593161106109619
Validation loss: 2.732295936153781

Epoch: 6| Step: 3
Training loss: 3.258361339569092
Validation loss: 2.7344259600485525

Epoch: 6| Step: 4
Training loss: 2.953888177871704
Validation loss: 2.733671344736571

Epoch: 6| Step: 5
Training loss: 3.0754857063293457
Validation loss: 2.7270477535904094

Epoch: 6| Step: 6
Training loss: 2.3473992347717285
Validation loss: 2.7265165544325307

Epoch: 6| Step: 7
Training loss: 3.1118006706237793
Validation loss: 2.721283453767018

Epoch: 6| Step: 8
Training loss: 2.69283390045166
Validation loss: 2.72039811072811

Epoch: 6| Step: 9
Training loss: 2.0513038635253906
Validation loss: 2.7206369651261197

Epoch: 6| Step: 10
Training loss: 2.747135639190674
Validation loss: 2.7227955325957267

Epoch: 6| Step: 11
Training loss: 2.704350233078003
Validation loss: 2.721936143854613

Epoch: 6| Step: 12
Training loss: 3.5912206172943115
Validation loss: 2.731533037718906

Epoch: 6| Step: 13
Training loss: 2.2735750675201416
Validation loss: 2.7295488029397945

Epoch: 20| Step: 0
Training loss: 2.146120309829712
Validation loss: 2.7231399269514185

Epoch: 6| Step: 1
Training loss: 3.9313693046569824
Validation loss: 2.7186225255330405

Epoch: 6| Step: 2
Training loss: 2.5315322875976562
Validation loss: 2.7125044715019966

Epoch: 6| Step: 3
Training loss: 2.583991050720215
Validation loss: 2.7153070024264756

Epoch: 6| Step: 4
Training loss: 2.838994026184082
Validation loss: 2.7101958054368214

Epoch: 6| Step: 5
Training loss: 2.542241096496582
Validation loss: 2.709451331887194

Epoch: 6| Step: 6
Training loss: 2.3799571990966797
Validation loss: 2.71107667492282

Epoch: 6| Step: 7
Training loss: 3.2449326515197754
Validation loss: 2.7124571236230994

Epoch: 6| Step: 8
Training loss: 3.1249234676361084
Validation loss: 2.717034419377645

Epoch: 6| Step: 9
Training loss: 2.946784019470215
Validation loss: 2.708668619073847

Epoch: 6| Step: 10
Training loss: 3.2629261016845703
Validation loss: 2.705092037877729

Epoch: 6| Step: 11
Training loss: 2.639197826385498
Validation loss: 2.701248468891267

Epoch: 6| Step: 12
Training loss: 3.0843148231506348
Validation loss: 2.700296909578385

Epoch: 6| Step: 13
Training loss: 2.9925742149353027
Validation loss: 2.7041665687355945

Epoch: 21| Step: 0
Training loss: 2.5084893703460693
Validation loss: 2.7053480532861527

Epoch: 6| Step: 1
Training loss: 3.4053492546081543
Validation loss: 2.7008489921528804

Epoch: 6| Step: 2
Training loss: 2.458728075027466
Validation loss: 2.6974928814877748

Epoch: 6| Step: 3
Training loss: 3.3659892082214355
Validation loss: 2.6976797811446653

Epoch: 6| Step: 4
Training loss: 2.712367057800293
Validation loss: 2.695683740800427

Epoch: 6| Step: 5
Training loss: 1.9645334482192993
Validation loss: 2.6896368457425024

Epoch: 6| Step: 6
Training loss: 2.950091600418091
Validation loss: 2.691007214207803

Epoch: 6| Step: 7
Training loss: 3.2125723361968994
Validation loss: 2.712761637985065

Epoch: 6| Step: 8
Training loss: 2.2374868392944336
Validation loss: 2.7521198052231983

Epoch: 6| Step: 9
Training loss: 2.9388785362243652
Validation loss: 2.717216876245314

Epoch: 6| Step: 10
Training loss: 2.917609453201294
Validation loss: 2.6886205468126523

Epoch: 6| Step: 11
Training loss: 3.2923083305358887
Validation loss: 2.696269184030512

Epoch: 6| Step: 12
Training loss: 3.2780869007110596
Validation loss: 2.707679453716483

Epoch: 6| Step: 13
Training loss: 2.8264694213867188
Validation loss: 2.713763642054732

Epoch: 22| Step: 0
Training loss: 2.5080389976501465
Validation loss: 2.7174850894558813

Epoch: 6| Step: 1
Training loss: 2.3879377841949463
Validation loss: 2.6951581637064614

Epoch: 6| Step: 2
Training loss: 3.6505589485168457
Validation loss: 2.6892373177313034

Epoch: 6| Step: 3
Training loss: 2.9264726638793945
Validation loss: 2.682730072288103

Epoch: 6| Step: 4
Training loss: 3.453035831451416
Validation loss: 2.6822238327354513

Epoch: 6| Step: 5
Training loss: 2.1370620727539062
Validation loss: 2.6886828048254854

Epoch: 6| Step: 6
Training loss: 3.6537747383117676
Validation loss: 2.7126828573083364

Epoch: 6| Step: 7
Training loss: 2.8943898677825928
Validation loss: 2.721328530260312

Epoch: 6| Step: 8
Training loss: 3.177334785461426
Validation loss: 2.692938607226136

Epoch: 6| Step: 9
Training loss: 1.8331047296524048
Validation loss: 2.66830099526272

Epoch: 6| Step: 10
Training loss: 2.7357685565948486
Validation loss: 2.6745555323939167

Epoch: 6| Step: 11
Training loss: 2.6264889240264893
Validation loss: 2.6829729721110356

Epoch: 6| Step: 12
Training loss: 2.748004913330078
Validation loss: 2.6964743855178996

Epoch: 6| Step: 13
Training loss: 3.6345033645629883
Validation loss: 2.7309340071934525

Epoch: 23| Step: 0
Training loss: 3.1259818077087402
Validation loss: 2.686547299867035

Epoch: 6| Step: 1
Training loss: 3.131490707397461
Validation loss: 2.6771914523134948

Epoch: 6| Step: 2
Training loss: 3.028470993041992
Validation loss: 2.680159491877402

Epoch: 6| Step: 3
Training loss: 3.216815710067749
Validation loss: 2.687621575529857

Epoch: 6| Step: 4
Training loss: 2.2002224922180176
Validation loss: 2.686237565932735

Epoch: 6| Step: 5
Training loss: 2.1875109672546387
Validation loss: 2.6710888442172798

Epoch: 6| Step: 6
Training loss: 2.7407383918762207
Validation loss: 2.666596035803518

Epoch: 6| Step: 7
Training loss: 2.903191089630127
Validation loss: 2.6740844480453

Epoch: 6| Step: 8
Training loss: 3.3135082721710205
Validation loss: 2.684554325636997

Epoch: 6| Step: 9
Training loss: 2.9213240146636963
Validation loss: 2.683483446798017

Epoch: 6| Step: 10
Training loss: 2.4706871509552
Validation loss: 2.66950657034433

Epoch: 6| Step: 11
Training loss: 3.9092025756835938
Validation loss: 2.652615808671521

Epoch: 6| Step: 12
Training loss: 1.9736002683639526
Validation loss: 2.6470950957267516

Epoch: 6| Step: 13
Training loss: 2.592479705810547
Validation loss: 2.6441028553952455

Epoch: 24| Step: 0
Training loss: 2.6487393379211426
Validation loss: 2.6421023671345045

Epoch: 6| Step: 1
Training loss: 2.1574630737304688
Validation loss: 2.6461555829612156

Epoch: 6| Step: 2
Training loss: 2.748904228210449
Validation loss: 2.6420128806944816

Epoch: 6| Step: 3
Training loss: 2.8760221004486084
Validation loss: 2.6425649325052896

Epoch: 6| Step: 4
Training loss: 3.0845513343811035
Validation loss: 2.640905180285054

Epoch: 6| Step: 5
Training loss: 2.7688868045806885
Validation loss: 2.6464390754699707

Epoch: 6| Step: 6
Training loss: 2.902663469314575
Validation loss: 2.648510024111758

Epoch: 6| Step: 7
Training loss: 3.0860421657562256
Validation loss: 2.652096538133519

Epoch: 6| Step: 8
Training loss: 2.9212303161621094
Validation loss: 2.6477633804403324

Epoch: 6| Step: 9
Training loss: 2.7009525299072266
Validation loss: 2.6434845770559003

Epoch: 6| Step: 10
Training loss: 3.09321928024292
Validation loss: 2.641803244108795

Epoch: 6| Step: 11
Training loss: 3.111508369445801
Validation loss: 2.6388397985889065

Epoch: 6| Step: 12
Training loss: 2.763091564178467
Validation loss: 2.631706973557831

Epoch: 6| Step: 13
Training loss: 2.4667396545410156
Validation loss: 2.6369873862112723

Epoch: 25| Step: 0
Training loss: 2.4744176864624023
Validation loss: 2.6743186648173998

Epoch: 6| Step: 1
Training loss: 3.0310611724853516
Validation loss: 2.7211300096204205

Epoch: 6| Step: 2
Training loss: 3.4269356727600098
Validation loss: 2.712449486537646

Epoch: 6| Step: 3
Training loss: 2.6281838417053223
Validation loss: 2.673986468263852

Epoch: 6| Step: 4
Training loss: 2.6232080459594727
Validation loss: 2.6293863275999665

Epoch: 6| Step: 5
Training loss: 3.2977166175842285
Validation loss: 2.6386377837068293

Epoch: 6| Step: 6
Training loss: 3.407869338989258
Validation loss: 2.659301088702294

Epoch: 6| Step: 7
Training loss: 2.7486956119537354
Validation loss: 2.7297750878077682

Epoch: 6| Step: 8
Training loss: 3.1381330490112305
Validation loss: 2.7286825795327463

Epoch: 6| Step: 9
Training loss: 2.2454121112823486
Validation loss: 2.712702158958681

Epoch: 6| Step: 10
Training loss: 2.439405918121338
Validation loss: 2.7139528489881948

Epoch: 6| Step: 11
Training loss: 2.975078582763672
Validation loss: 2.6955700074472735

Epoch: 6| Step: 12
Training loss: 2.925567626953125
Validation loss: 2.667303798019245

Epoch: 6| Step: 13
Training loss: 2.2608401775360107
Validation loss: 2.653704689395043

Epoch: 26| Step: 0
Training loss: 3.2766199111938477
Validation loss: 2.642566993672361

Epoch: 6| Step: 1
Training loss: 2.935225009918213
Validation loss: 2.6298733475387737

Epoch: 6| Step: 2
Training loss: 3.0289483070373535
Validation loss: 2.6271344256657425

Epoch: 6| Step: 3
Training loss: 2.449021816253662
Validation loss: 2.633296997316422

Epoch: 6| Step: 4
Training loss: 3.0914058685302734
Validation loss: 2.6379912232839935

Epoch: 6| Step: 5
Training loss: 2.4892358779907227
Validation loss: 2.6390856619804137

Epoch: 6| Step: 6
Training loss: 2.557466506958008
Validation loss: 2.663253415015436

Epoch: 6| Step: 7
Training loss: 2.270368814468384
Validation loss: 2.6962006527890443

Epoch: 6| Step: 8
Training loss: 3.6995983123779297
Validation loss: 2.6624583172541794

Epoch: 6| Step: 9
Training loss: 2.720088481903076
Validation loss: 2.621677742209486

Epoch: 6| Step: 10
Training loss: 3.3151004314422607
Validation loss: 2.614926894505819

Epoch: 6| Step: 11
Training loss: 2.168652057647705
Validation loss: 2.617137626935077

Epoch: 6| Step: 12
Training loss: 2.636141538619995
Validation loss: 2.62017628710757

Epoch: 6| Step: 13
Training loss: 2.917267084121704
Validation loss: 2.622489321616388

Epoch: 27| Step: 0
Training loss: 2.0900068283081055
Validation loss: 2.624628882254324

Epoch: 6| Step: 1
Training loss: 3.2063446044921875
Validation loss: 2.629269907551427

Epoch: 6| Step: 2
Training loss: 2.6546692848205566
Validation loss: 2.622606885048651

Epoch: 6| Step: 3
Training loss: 2.786653518676758
Validation loss: 2.613968995309645

Epoch: 6| Step: 4
Training loss: 3.246100664138794
Validation loss: 2.6033773268422773

Epoch: 6| Step: 5
Training loss: 2.0246822834014893
Validation loss: 2.5983757767626035

Epoch: 6| Step: 6
Training loss: 2.183136224746704
Validation loss: 2.593529744814801

Epoch: 6| Step: 7
Training loss: 3.052928924560547
Validation loss: 2.5887407256710913

Epoch: 6| Step: 8
Training loss: 2.686453342437744
Validation loss: 2.5899001680394655

Epoch: 6| Step: 9
Training loss: 3.509049654006958
Validation loss: 2.596781092305337

Epoch: 6| Step: 10
Training loss: 3.6797122955322266
Validation loss: 2.5958863586507817

Epoch: 6| Step: 11
Training loss: 2.6683788299560547
Validation loss: 2.5885818235335813

Epoch: 6| Step: 12
Training loss: 2.9015159606933594
Validation loss: 2.573180483233544

Epoch: 6| Step: 13
Training loss: 2.202582359313965
Validation loss: 2.5784481430566437

Epoch: 28| Step: 0
Training loss: 3.0120537281036377
Validation loss: 2.5785122020270235

Epoch: 6| Step: 1
Training loss: 2.851351261138916
Validation loss: 2.5798237349397395

Epoch: 6| Step: 2
Training loss: 2.627204418182373
Validation loss: 2.5774480655629146

Epoch: 6| Step: 3
Training loss: 3.0171778202056885
Validation loss: 2.5782271431338404

Epoch: 6| Step: 4
Training loss: 3.2719709873199463
Validation loss: 2.5761375709246566

Epoch: 6| Step: 5
Training loss: 2.87953519821167
Validation loss: 2.575864209923693

Epoch: 6| Step: 6
Training loss: 1.8391704559326172
Validation loss: 2.5728450359836703

Epoch: 6| Step: 7
Training loss: 2.9329867362976074
Validation loss: 2.57169258722695

Epoch: 6| Step: 8
Training loss: 2.5628511905670166
Validation loss: 2.5706131945374193

Epoch: 6| Step: 9
Training loss: 2.1381163597106934
Validation loss: 2.5738326529020905

Epoch: 6| Step: 10
Training loss: 3.2705235481262207
Validation loss: 2.620474294949603

Epoch: 6| Step: 11
Training loss: 2.462338447570801
Validation loss: 2.6294310785109

Epoch: 6| Step: 12
Training loss: 3.557003974914551
Validation loss: 2.577264985730571

Epoch: 6| Step: 13
Training loss: 2.253572702407837
Validation loss: 2.5673098820512013

Epoch: 29| Step: 0
Training loss: 3.008230686187744
Validation loss: 2.5637251638597056

Epoch: 6| Step: 1
Training loss: 3.370673656463623
Validation loss: 2.5733204580122426

Epoch: 6| Step: 2
Training loss: 2.552485227584839
Validation loss: 2.6009369255394064

Epoch: 6| Step: 3
Training loss: 2.4296865463256836
Validation loss: 2.6008018216779156

Epoch: 6| Step: 4
Training loss: 2.583193302154541
Validation loss: 2.5755044311605473

Epoch: 6| Step: 5
Training loss: 3.681044101715088
Validation loss: 2.565587059144051

Epoch: 6| Step: 6
Training loss: 2.611806631088257
Validation loss: 2.5584772248421945

Epoch: 6| Step: 7
Training loss: 2.7963123321533203
Validation loss: 2.5570242122937272

Epoch: 6| Step: 8
Training loss: 2.2317705154418945
Validation loss: 2.5536588186858804

Epoch: 6| Step: 9
Training loss: 3.058201789855957
Validation loss: 2.5585346939743205

Epoch: 6| Step: 10
Training loss: 3.117497444152832
Validation loss: 2.5561466165768203

Epoch: 6| Step: 11
Training loss: 1.8612897396087646
Validation loss: 2.5555649726621565

Epoch: 6| Step: 12
Training loss: 2.614779472351074
Validation loss: 2.560174313924646

Epoch: 6| Step: 13
Training loss: 2.9690654277801514
Validation loss: 2.5507344738129647

Epoch: 30| Step: 0
Training loss: 3.272305488586426
Validation loss: 2.549046047272221

Epoch: 6| Step: 1
Training loss: 2.117335319519043
Validation loss: 2.5510277261016188

Epoch: 6| Step: 2
Training loss: 2.8816604614257812
Validation loss: 2.550271572605256

Epoch: 6| Step: 3
Training loss: 1.8910490274429321
Validation loss: 2.5489225028663554

Epoch: 6| Step: 4
Training loss: 2.8823161125183105
Validation loss: 2.5483842408785256

Epoch: 6| Step: 5
Training loss: 2.7620646953582764
Validation loss: 2.547422383421211

Epoch: 6| Step: 6
Training loss: 2.6355063915252686
Validation loss: 2.544086604989985

Epoch: 6| Step: 7
Training loss: 1.9839518070220947
Validation loss: 2.5409409666574128

Epoch: 6| Step: 8
Training loss: 2.882371187210083
Validation loss: 2.5429258090193554

Epoch: 6| Step: 9
Training loss: 3.6273577213287354
Validation loss: 2.5417356849998556

Epoch: 6| Step: 10
Training loss: 3.2136356830596924
Validation loss: 2.5439043327044417

Epoch: 6| Step: 11
Training loss: 2.5455448627471924
Validation loss: 2.538725581220401

Epoch: 6| Step: 12
Training loss: 2.984172821044922
Validation loss: 2.537931811424994

Epoch: 6| Step: 13
Training loss: 2.9018595218658447
Validation loss: 2.536868031306933

Epoch: 31| Step: 0
Training loss: 2.388312816619873
Validation loss: 2.531575713106381

Epoch: 6| Step: 1
Training loss: 2.263071060180664
Validation loss: 2.529646199236634

Epoch: 6| Step: 2
Training loss: 3.8942131996154785
Validation loss: 2.52827218527435

Epoch: 6| Step: 3
Training loss: 3.1812996864318848
Validation loss: 2.5328929783195577

Epoch: 6| Step: 4
Training loss: 2.605807304382324
Validation loss: 2.528412857363301

Epoch: 6| Step: 5
Training loss: 3.0381240844726562
Validation loss: 2.525849688437677

Epoch: 6| Step: 6
Training loss: 2.375483989715576
Validation loss: 2.524421630367156

Epoch: 6| Step: 7
Training loss: 3.123788833618164
Validation loss: 2.5291572437491467

Epoch: 6| Step: 8
Training loss: 2.3021018505096436
Validation loss: 2.5294768964090655

Epoch: 6| Step: 9
Training loss: 2.034651756286621
Validation loss: 2.5324454845920688

Epoch: 6| Step: 10
Training loss: 2.5886902809143066
Validation loss: 2.5270679561040734

Epoch: 6| Step: 11
Training loss: 2.8791089057922363
Validation loss: 2.5291302716860207

Epoch: 6| Step: 12
Training loss: 2.4688820838928223
Validation loss: 2.5259349217978855

Epoch: 6| Step: 13
Training loss: 3.7360353469848633
Validation loss: 2.5211362505471833

Epoch: 32| Step: 0
Training loss: 2.55590558052063
Validation loss: 2.5194371336249897

Epoch: 6| Step: 1
Training loss: 2.9146718978881836
Validation loss: 2.5181010448804466

Epoch: 6| Step: 2
Training loss: 2.5681235790252686
Validation loss: 2.515013135889525

Epoch: 6| Step: 3
Training loss: 3.3629398345947266
Validation loss: 2.515432062969413

Epoch: 6| Step: 4
Training loss: 1.6024866104125977
Validation loss: 2.5145290179919173

Epoch: 6| Step: 5
Training loss: 2.7218880653381348
Validation loss: 2.5315317799968104

Epoch: 6| Step: 6
Training loss: 2.116288900375366
Validation loss: 2.5305305783466627

Epoch: 6| Step: 7
Training loss: 3.51029109954834
Validation loss: 2.5232258355745705

Epoch: 6| Step: 8
Training loss: 2.869394302368164
Validation loss: 2.508583127811391

Epoch: 6| Step: 9
Training loss: 2.222881317138672
Validation loss: 2.509014309093516

Epoch: 6| Step: 10
Training loss: 2.755323886871338
Validation loss: 2.5084064698988393

Epoch: 6| Step: 11
Training loss: 3.676270008087158
Validation loss: 2.5125264813823085

Epoch: 6| Step: 12
Training loss: 2.6769485473632812
Validation loss: 2.5122468343345066

Epoch: 6| Step: 13
Training loss: 2.8634114265441895
Validation loss: 2.50941631614521

Epoch: 33| Step: 0
Training loss: 2.674238681793213
Validation loss: 2.5110221780756468

Epoch: 6| Step: 1
Training loss: 2.7902684211730957
Validation loss: 2.5039850255494476

Epoch: 6| Step: 2
Training loss: 2.8532896041870117
Validation loss: 2.4989159645572787

Epoch: 6| Step: 3
Training loss: 2.4216158390045166
Validation loss: 2.5035385111326813

Epoch: 6| Step: 4
Training loss: 3.413458824157715
Validation loss: 2.506773096258922

Epoch: 6| Step: 5
Training loss: 3.530252456665039
Validation loss: 2.4994033818603842

Epoch: 6| Step: 6
Training loss: 2.3764541149139404
Validation loss: 2.497478956817299

Epoch: 6| Step: 7
Training loss: 3.00783109664917
Validation loss: 2.4991997339392222

Epoch: 6| Step: 8
Training loss: 2.0064423084259033
Validation loss: 2.5019858780727593

Epoch: 6| Step: 9
Training loss: 2.6215968132019043
Validation loss: 2.5039293996749388

Epoch: 6| Step: 10
Training loss: 3.410618543624878
Validation loss: 2.505686198511431

Epoch: 6| Step: 11
Training loss: 2.5454185009002686
Validation loss: 2.5081813437964326

Epoch: 6| Step: 12
Training loss: 2.1159796714782715
Validation loss: 2.5092326851301294

Epoch: 6| Step: 13
Training loss: 2.3020334243774414
Validation loss: 2.508856952831309

Epoch: 34| Step: 0
Training loss: 2.0992722511291504
Validation loss: 2.5067995209847727

Epoch: 6| Step: 1
Training loss: 2.2890682220458984
Validation loss: 2.5043472961712907

Epoch: 6| Step: 2
Training loss: 2.906893253326416
Validation loss: 2.4992180383333595

Epoch: 6| Step: 3
Training loss: 2.765838146209717
Validation loss: 2.501813437349053

Epoch: 6| Step: 4
Training loss: 2.6422994136810303
Validation loss: 2.5058718753117386

Epoch: 6| Step: 5
Training loss: 3.0554518699645996
Validation loss: 2.505672183088077

Epoch: 6| Step: 6
Training loss: 2.2881174087524414
Validation loss: 2.5010436145208215

Epoch: 6| Step: 7
Training loss: 3.566070079803467
Validation loss: 2.5012880525281354

Epoch: 6| Step: 8
Training loss: 2.422266960144043
Validation loss: 2.5031087770256946

Epoch: 6| Step: 9
Training loss: 3.81424880027771
Validation loss: 2.5148667545728784

Epoch: 6| Step: 10
Training loss: 2.6718478202819824
Validation loss: 2.522684702309229

Epoch: 6| Step: 11
Training loss: 2.123722553253174
Validation loss: 2.5264688884058306

Epoch: 6| Step: 12
Training loss: 2.2584478855133057
Validation loss: 2.531455014341621

Epoch: 6| Step: 13
Training loss: 3.63869047164917
Validation loss: 2.5214614868164062

Epoch: 35| Step: 0
Training loss: 3.1773247718811035
Validation loss: 2.5046623291507846

Epoch: 6| Step: 1
Training loss: 2.705164909362793
Validation loss: 2.4970014941307808

Epoch: 6| Step: 2
Training loss: 3.578214168548584
Validation loss: 2.4930106055351997

Epoch: 6| Step: 3
Training loss: 1.7426447868347168
Validation loss: 2.497675444490166

Epoch: 6| Step: 4
Training loss: 2.2759957313537598
Validation loss: 2.4997204093522924

Epoch: 6| Step: 5
Training loss: 3.052793502807617
Validation loss: 2.5124980454803794

Epoch: 6| Step: 6
Training loss: 2.79223370552063
Validation loss: 2.5166967914950464

Epoch: 6| Step: 7
Training loss: 2.8109962940216064
Validation loss: 2.5209201946053454

Epoch: 6| Step: 8
Training loss: 2.1779134273529053
Validation loss: 2.5158145581522295

Epoch: 6| Step: 9
Training loss: 2.625913143157959
Validation loss: 2.5187619104180285

Epoch: 6| Step: 10
Training loss: 2.4178314208984375
Validation loss: 2.5106242446489233

Epoch: 6| Step: 11
Training loss: 3.250037908554077
Validation loss: 2.503793288302678

Epoch: 6| Step: 12
Training loss: 2.8031134605407715
Validation loss: 2.4960303614216466

Epoch: 6| Step: 13
Training loss: 2.8344039916992188
Validation loss: 2.487802013274162

Epoch: 36| Step: 0
Training loss: 2.578044891357422
Validation loss: 2.4871517150632796

Epoch: 6| Step: 1
Training loss: 1.974823236465454
Validation loss: 2.48570349139552

Epoch: 6| Step: 2
Training loss: 2.6527700424194336
Validation loss: 2.4923272158509944

Epoch: 6| Step: 3
Training loss: 2.260619640350342
Validation loss: 2.519633782807217

Epoch: 6| Step: 4
Training loss: 2.236084222793579
Validation loss: 2.5015383381997385

Epoch: 6| Step: 5
Training loss: 3.5340416431427
Validation loss: 2.531661546358498

Epoch: 6| Step: 6
Training loss: 2.5069098472595215
Validation loss: 2.5316394272670952

Epoch: 6| Step: 7
Training loss: 3.3450798988342285
Validation loss: 2.524755549687211

Epoch: 6| Step: 8
Training loss: 2.451648235321045
Validation loss: 2.512814491025863

Epoch: 6| Step: 9
Training loss: 2.1364223957061768
Validation loss: 2.5095241531249015

Epoch: 6| Step: 10
Training loss: 3.3546934127807617
Validation loss: 2.5104161462476178

Epoch: 6| Step: 11
Training loss: 2.80558180809021
Validation loss: 2.5077657635493944

Epoch: 6| Step: 12
Training loss: 3.2688379287719727
Validation loss: 2.4980442190683014

Epoch: 6| Step: 13
Training loss: 3.0941171646118164
Validation loss: 2.49137944047169

Epoch: 37| Step: 0
Training loss: 3.018764019012451
Validation loss: 2.4845386064180763

Epoch: 6| Step: 1
Training loss: 1.5023484230041504
Validation loss: 2.490210871542654

Epoch: 6| Step: 2
Training loss: 2.8519127368927
Validation loss: 2.5063501686178227

Epoch: 6| Step: 3
Training loss: 3.0953550338745117
Validation loss: 2.489650959609657

Epoch: 6| Step: 4
Training loss: 2.3745014667510986
Validation loss: 2.487777053668935

Epoch: 6| Step: 5
Training loss: 3.0701308250427246
Validation loss: 2.490975190234441

Epoch: 6| Step: 6
Training loss: 2.942291259765625
Validation loss: 2.4944922872768935

Epoch: 6| Step: 7
Training loss: 2.7635910511016846
Validation loss: 2.493326356334071

Epoch: 6| Step: 8
Training loss: 3.490224599838257
Validation loss: 2.4859251335103023

Epoch: 6| Step: 9
Training loss: 3.204193353652954
Validation loss: 2.478509441498787

Epoch: 6| Step: 10
Training loss: 3.0676589012145996
Validation loss: 2.480969273915855

Epoch: 6| Step: 11
Training loss: 1.74062979221344
Validation loss: 2.484973333215201

Epoch: 6| Step: 12
Training loss: 3.0910706520080566
Validation loss: 2.4931142330169678

Epoch: 6| Step: 13
Training loss: 1.2588871717453003
Validation loss: 2.4950604900237052

Epoch: 38| Step: 0
Training loss: 3.106757402420044
Validation loss: 2.4923568259003344

Epoch: 6| Step: 1
Training loss: 2.467757225036621
Validation loss: 2.481297495544598

Epoch: 6| Step: 2
Training loss: 3.0425422191619873
Validation loss: 2.481014185054328

Epoch: 6| Step: 3
Training loss: 2.520496368408203
Validation loss: 2.4878135163296937

Epoch: 6| Step: 4
Training loss: 2.1077609062194824
Validation loss: 2.484160900115967

Epoch: 6| Step: 5
Training loss: 2.502542495727539
Validation loss: 2.4895280240684428

Epoch: 6| Step: 6
Training loss: 2.825133800506592
Validation loss: 2.48238068754955

Epoch: 6| Step: 7
Training loss: 2.5295777320861816
Validation loss: 2.4688295625871226

Epoch: 6| Step: 8
Training loss: 2.841435432434082
Validation loss: 2.469940395765407

Epoch: 6| Step: 9
Training loss: 2.528657913208008
Validation loss: 2.4672881467368013

Epoch: 6| Step: 10
Training loss: 2.6334023475646973
Validation loss: 2.4650835529450448

Epoch: 6| Step: 11
Training loss: 2.1915879249572754
Validation loss: 2.4692218688226517

Epoch: 6| Step: 12
Training loss: 3.5880212783813477
Validation loss: 2.469529204471137

Epoch: 6| Step: 13
Training loss: 3.171093702316284
Validation loss: 2.4657300121040753

Epoch: 39| Step: 0
Training loss: 2.74373459815979
Validation loss: 2.4642279096828994

Epoch: 6| Step: 1
Training loss: 3.7376198768615723
Validation loss: 2.4611837171739146

Epoch: 6| Step: 2
Training loss: 2.8372392654418945
Validation loss: 2.462011642353509

Epoch: 6| Step: 3
Training loss: 1.93674635887146
Validation loss: 2.46137172432356

Epoch: 6| Step: 4
Training loss: 2.9524049758911133
Validation loss: 2.460668553588211

Epoch: 6| Step: 5
Training loss: 2.2283759117126465
Validation loss: 2.4766290264744915

Epoch: 6| Step: 6
Training loss: 2.4734721183776855
Validation loss: 2.5004342191962787

Epoch: 6| Step: 7
Training loss: 2.593308448791504
Validation loss: 2.519384163682179

Epoch: 6| Step: 8
Training loss: 3.293609857559204
Validation loss: 2.5121882474550636

Epoch: 6| Step: 9
Training loss: 3.2960152626037598
Validation loss: 2.4780457942716536

Epoch: 6| Step: 10
Training loss: 2.517082691192627
Validation loss: 2.4546692345732

Epoch: 6| Step: 11
Training loss: 2.433185338973999
Validation loss: 2.462407919668382

Epoch: 6| Step: 12
Training loss: 2.4187583923339844
Validation loss: 2.479805302876298

Epoch: 6| Step: 13
Training loss: 2.3187196254730225
Validation loss: 2.4963677878020913

Epoch: 40| Step: 0
Training loss: 3.2413816452026367
Validation loss: 2.5103761572991647

Epoch: 6| Step: 1
Training loss: 2.616541624069214
Validation loss: 2.5033995387374715

Epoch: 6| Step: 2
Training loss: 2.5491392612457275
Validation loss: 2.505240865932998

Epoch: 6| Step: 3
Training loss: 3.3809218406677246
Validation loss: 2.4882644299537904

Epoch: 6| Step: 4
Training loss: 1.9432013034820557
Validation loss: 2.4790959050578456

Epoch: 6| Step: 5
Training loss: 2.575592517852783
Validation loss: 2.4730396757843676

Epoch: 6| Step: 6
Training loss: 2.208982467651367
Validation loss: 2.4623240322195072

Epoch: 6| Step: 7
Training loss: 3.040043830871582
Validation loss: 2.4553803577218005

Epoch: 6| Step: 8
Training loss: 3.2045578956604004
Validation loss: 2.4549456001609884

Epoch: 6| Step: 9
Training loss: 3.1638777256011963
Validation loss: 2.4535557608450613

Epoch: 6| Step: 10
Training loss: 3.049685478210449
Validation loss: 2.4484680955128004

Epoch: 6| Step: 11
Training loss: 2.278294801712036
Validation loss: 2.4530076057680192

Epoch: 6| Step: 12
Training loss: 2.7372655868530273
Validation loss: 2.4552299002165436

Epoch: 6| Step: 13
Training loss: 1.6400684118270874
Validation loss: 2.4673195833800943

Epoch: 41| Step: 0
Training loss: 2.713569164276123
Validation loss: 2.47912871965798

Epoch: 6| Step: 1
Training loss: 2.7166643142700195
Validation loss: 2.48716615861462

Epoch: 6| Step: 2
Training loss: 2.5577757358551025
Validation loss: 2.4935745680204002

Epoch: 6| Step: 3
Training loss: 2.798275947570801
Validation loss: 2.5149512803682716

Epoch: 6| Step: 4
Training loss: 2.617276906967163
Validation loss: 2.5284583748027845

Epoch: 6| Step: 5
Training loss: 2.99169659614563
Validation loss: 2.5445835282725673

Epoch: 6| Step: 6
Training loss: 3.000368595123291
Validation loss: 2.5478800727475073

Epoch: 6| Step: 7
Training loss: 2.79384183883667
Validation loss: 2.531803410540345

Epoch: 6| Step: 8
Training loss: 2.6846537590026855
Validation loss: 2.518267321330245

Epoch: 6| Step: 9
Training loss: 2.459785223007202
Validation loss: 2.5120304143556984

Epoch: 6| Step: 10
Training loss: 2.445173740386963
Validation loss: 2.512457634813042

Epoch: 6| Step: 11
Training loss: 3.1318864822387695
Validation loss: 2.51062233601847

Epoch: 6| Step: 12
Training loss: 2.536496162414551
Validation loss: 2.5143119622302312

Epoch: 6| Step: 13
Training loss: 2.6260976791381836
Validation loss: 2.5139888768555014

Epoch: 42| Step: 0
Training loss: 2.8668131828308105
Validation loss: 2.502442847016037

Epoch: 6| Step: 1
Training loss: 2.6627345085144043
Validation loss: 2.5023902000919467

Epoch: 6| Step: 2
Training loss: 3.1026697158813477
Validation loss: 2.5016200439904326

Epoch: 6| Step: 3
Training loss: 2.32814884185791
Validation loss: 2.50390294290358

Epoch: 6| Step: 4
Training loss: 2.0274605751037598
Validation loss: 2.4941578283104846

Epoch: 6| Step: 5
Training loss: 3.012409210205078
Validation loss: 2.486018071892441

Epoch: 6| Step: 6
Training loss: 2.2731173038482666
Validation loss: 2.4825767573489936

Epoch: 6| Step: 7
Training loss: 2.3866140842437744
Validation loss: 2.492707739594162

Epoch: 6| Step: 8
Training loss: 3.3965208530426025
Validation loss: 2.5253674471250145

Epoch: 6| Step: 9
Training loss: 2.334880828857422
Validation loss: 2.4815574563959593

Epoch: 6| Step: 10
Training loss: 3.0702872276306152
Validation loss: 2.4644765443699335

Epoch: 6| Step: 11
Training loss: 2.836176872253418
Validation loss: 2.470821511360907

Epoch: 6| Step: 12
Training loss: 2.6263980865478516
Validation loss: 2.517791143027685

Epoch: 6| Step: 13
Training loss: 3.2711474895477295
Validation loss: 2.532512508412843

Epoch: 43| Step: 0
Training loss: 3.2476422786712646
Validation loss: 2.4636664749473653

Epoch: 6| Step: 1
Training loss: 3.0346994400024414
Validation loss: 2.469850012051162

Epoch: 6| Step: 2
Training loss: 2.7922205924987793
Validation loss: 2.4914667657626572

Epoch: 6| Step: 3
Training loss: 2.3596670627593994
Validation loss: 2.5348806099225114

Epoch: 6| Step: 4
Training loss: 2.438319683074951
Validation loss: 2.566833596075735

Epoch: 6| Step: 5
Training loss: 2.8598573207855225
Validation loss: 2.586282232756256

Epoch: 6| Step: 6
Training loss: 2.19360613822937
Validation loss: 2.5384960687288673

Epoch: 6| Step: 7
Training loss: 2.392726421356201
Validation loss: 2.4756757264496176

Epoch: 6| Step: 8
Training loss: 2.078143835067749
Validation loss: 2.4521605583929245

Epoch: 6| Step: 9
Training loss: 2.3726768493652344
Validation loss: 2.4694280291116364

Epoch: 6| Step: 10
Training loss: 2.900014877319336
Validation loss: 2.483047459715156

Epoch: 6| Step: 11
Training loss: 3.1675336360931396
Validation loss: 2.488469003349222

Epoch: 6| Step: 12
Training loss: 3.4394495487213135
Validation loss: 2.485726628252255

Epoch: 6| Step: 13
Training loss: 2.8557751178741455
Validation loss: 2.4796695222136793

Epoch: 44| Step: 0
Training loss: 1.8170650005340576
Validation loss: 2.4789360543733

Epoch: 6| Step: 1
Training loss: 2.24713397026062
Validation loss: 2.4776527240712154

Epoch: 6| Step: 2
Training loss: 2.966459274291992
Validation loss: 2.4925458021061395

Epoch: 6| Step: 3
Training loss: 2.1970107555389404
Validation loss: 2.533122803575249

Epoch: 6| Step: 4
Training loss: 2.638411045074463
Validation loss: 2.5356956040987404

Epoch: 6| Step: 5
Training loss: 3.6797759532928467
Validation loss: 2.4977627697811333

Epoch: 6| Step: 6
Training loss: 3.1586289405822754
Validation loss: 2.4554798885058333

Epoch: 6| Step: 7
Training loss: 2.903883457183838
Validation loss: 2.4444149489043863

Epoch: 6| Step: 8
Training loss: 2.502234935760498
Validation loss: 2.443968011486915

Epoch: 6| Step: 9
Training loss: 2.5265069007873535
Validation loss: 2.446343175826534

Epoch: 6| Step: 10
Training loss: 3.2094764709472656
Validation loss: 2.447939157485962

Epoch: 6| Step: 11
Training loss: 2.392709255218506
Validation loss: 2.4527549718015935

Epoch: 6| Step: 12
Training loss: 2.806081771850586
Validation loss: 2.478619337081909

Epoch: 6| Step: 13
Training loss: 2.7497220039367676
Validation loss: 2.506318256419192

Epoch: 45| Step: 0
Training loss: 2.963810443878174
Validation loss: 2.5088724038934194

Epoch: 6| Step: 1
Training loss: 3.010741710662842
Validation loss: 2.5237294294500865

Epoch: 6| Step: 2
Training loss: 2.5782315731048584
Validation loss: 2.5286603332847677

Epoch: 6| Step: 3
Training loss: 2.032132863998413
Validation loss: 2.503469608163321

Epoch: 6| Step: 4
Training loss: 3.0107340812683105
Validation loss: 2.50354516249831

Epoch: 6| Step: 5
Training loss: 2.779546022415161
Validation loss: 2.495797518760927

Epoch: 6| Step: 6
Training loss: 1.9560737609863281
Validation loss: 2.470214092603294

Epoch: 6| Step: 7
Training loss: 2.003994941711426
Validation loss: 2.4531284147693264

Epoch: 6| Step: 8
Training loss: 2.9275827407836914
Validation loss: 2.457743596005183

Epoch: 6| Step: 9
Training loss: 3.1440963745117188
Validation loss: 2.474813586922102

Epoch: 6| Step: 10
Training loss: 2.8539023399353027
Validation loss: 2.44924509140753

Epoch: 6| Step: 11
Training loss: 2.6495513916015625
Validation loss: 2.4390876959728938

Epoch: 6| Step: 12
Training loss: 2.975975513458252
Validation loss: 2.4358913001193794

Epoch: 6| Step: 13
Training loss: 2.8555915355682373
Validation loss: 2.4253317668873775

Epoch: 46| Step: 0
Training loss: 2.6040730476379395
Validation loss: 2.4287664275015555

Epoch: 6| Step: 1
Training loss: 2.1324925422668457
Validation loss: 2.43238833642775

Epoch: 6| Step: 2
Training loss: 2.2134292125701904
Validation loss: 2.427870947827575

Epoch: 6| Step: 3
Training loss: 2.986283779144287
Validation loss: 2.423411871797295

Epoch: 6| Step: 4
Training loss: 2.6263632774353027
Validation loss: 2.4231235134986138

Epoch: 6| Step: 5
Training loss: 2.250826835632324
Validation loss: 2.424202593423987

Epoch: 6| Step: 6
Training loss: 2.9810924530029297
Validation loss: 2.4228913912209133

Epoch: 6| Step: 7
Training loss: 4.002749919891357
Validation loss: 2.422224483182353

Epoch: 6| Step: 8
Training loss: 2.974331855773926
Validation loss: 2.4222949986816733

Epoch: 6| Step: 9
Training loss: 2.451270341873169
Validation loss: 2.4250854266587125

Epoch: 6| Step: 10
Training loss: 2.0716938972473145
Validation loss: 2.418707514321932

Epoch: 6| Step: 11
Training loss: 2.5640623569488525
Validation loss: 2.411479603859686

Epoch: 6| Step: 12
Training loss: 2.7698051929473877
Validation loss: 2.4158774729697936

Epoch: 6| Step: 13
Training loss: 2.976365089416504
Validation loss: 2.415243451313306

Epoch: 47| Step: 0
Training loss: 2.2595765590667725
Validation loss: 2.418583567424487

Epoch: 6| Step: 1
Training loss: 2.288501262664795
Validation loss: 2.4212322286380235

Epoch: 6| Step: 2
Training loss: 3.1909561157226562
Validation loss: 2.435014291476178

Epoch: 6| Step: 3
Training loss: 2.1314845085144043
Validation loss: 2.4477448719804005

Epoch: 6| Step: 4
Training loss: 2.983464002609253
Validation loss: 2.457901890559863

Epoch: 6| Step: 5
Training loss: 2.216221570968628
Validation loss: 2.4630892302400325

Epoch: 6| Step: 6
Training loss: 2.562479257583618
Validation loss: 2.4539344695306595

Epoch: 6| Step: 7
Training loss: 3.2937252521514893
Validation loss: 2.415274455983152

Epoch: 6| Step: 8
Training loss: 2.595430374145508
Validation loss: 2.4093059032194075

Epoch: 6| Step: 9
Training loss: 2.8509230613708496
Validation loss: 2.422087610408824

Epoch: 6| Step: 10
Training loss: 2.856506824493408
Validation loss: 2.440299367391935

Epoch: 6| Step: 11
Training loss: 3.1379666328430176
Validation loss: 2.4488322375923075

Epoch: 6| Step: 12
Training loss: 2.419613838195801
Validation loss: 2.443754055166757

Epoch: 6| Step: 13
Training loss: 2.7440412044525146
Validation loss: 2.4505882237547185

Epoch: 48| Step: 0
Training loss: 2.8035943508148193
Validation loss: 2.420470488968716

Epoch: 6| Step: 1
Training loss: 2.6546146869659424
Validation loss: 2.407037760621758

Epoch: 6| Step: 2
Training loss: 2.162405014038086
Validation loss: 2.3980857992684967

Epoch: 6| Step: 3
Training loss: 2.2991340160369873
Validation loss: 2.3966579616710706

Epoch: 6| Step: 4
Training loss: 3.154726266860962
Validation loss: 2.397065531822943

Epoch: 6| Step: 5
Training loss: 2.7509946823120117
Validation loss: 2.4023776490201234

Epoch: 6| Step: 6
Training loss: 3.4688234329223633
Validation loss: 2.4145629687975814

Epoch: 6| Step: 7
Training loss: 2.549571990966797
Validation loss: 2.438628319771059

Epoch: 6| Step: 8
Training loss: 2.300360679626465
Validation loss: 2.4651161496357252

Epoch: 6| Step: 9
Training loss: 2.957895278930664
Validation loss: 2.4668636552749144

Epoch: 6| Step: 10
Training loss: 2.368948221206665
Validation loss: 2.4649184057789464

Epoch: 6| Step: 11
Training loss: 3.006289005279541
Validation loss: 2.4706500832752516

Epoch: 6| Step: 12
Training loss: 2.294145345687866
Validation loss: 2.4612665432755665

Epoch: 6| Step: 13
Training loss: 2.3668463230133057
Validation loss: 2.4412213346009612

Epoch: 49| Step: 0
Training loss: 2.227245330810547
Validation loss: 2.4239559737584924

Epoch: 6| Step: 1
Training loss: 3.386624813079834
Validation loss: 2.4160577148519535

Epoch: 6| Step: 2
Training loss: 3.0454883575439453
Validation loss: 2.4032032130866923

Epoch: 6| Step: 3
Training loss: 1.7262024879455566
Validation loss: 2.4130276121119016

Epoch: 6| Step: 4
Training loss: 2.750545024871826
Validation loss: 2.405069761378791

Epoch: 6| Step: 5
Training loss: 2.4017043113708496
Validation loss: 2.405315496588266

Epoch: 6| Step: 6
Training loss: 2.891681432723999
Validation loss: 2.409529388591807

Epoch: 6| Step: 7
Training loss: 2.8585901260375977
Validation loss: 2.4222135954005743

Epoch: 6| Step: 8
Training loss: 3.104611873626709
Validation loss: 2.425924598529775

Epoch: 6| Step: 9
Training loss: 2.5012800693511963
Validation loss: 2.433857412748439

Epoch: 6| Step: 10
Training loss: 2.166109323501587
Validation loss: 2.437567295566682

Epoch: 6| Step: 11
Training loss: 2.8400001525878906
Validation loss: 2.4318204156814085

Epoch: 6| Step: 12
Training loss: 3.0542140007019043
Validation loss: 2.425798195664601

Epoch: 6| Step: 13
Training loss: 1.7450127601623535
Validation loss: 2.4043885789891726

Epoch: 50| Step: 0
Training loss: 3.4592556953430176
Validation loss: 2.3978446709212435

Epoch: 6| Step: 1
Training loss: 2.5674147605895996
Validation loss: 2.3911485287450973

Epoch: 6| Step: 2
Training loss: 2.6651763916015625
Validation loss: 2.3863997638866468

Epoch: 6| Step: 3
Training loss: 2.2608683109283447
Validation loss: 2.384101143447302

Epoch: 6| Step: 4
Training loss: 2.6501476764678955
Validation loss: 2.386851477366622

Epoch: 6| Step: 5
Training loss: 2.421466112136841
Validation loss: 2.3866883195856565

Epoch: 6| Step: 6
Training loss: 3.670074462890625
Validation loss: 2.3909263200657342

Epoch: 6| Step: 7
Training loss: 3.1723685264587402
Validation loss: 2.389196688129056

Epoch: 6| Step: 8
Training loss: 2.8586807250976562
Validation loss: 2.3871942899560414

Epoch: 6| Step: 9
Training loss: 2.0169525146484375
Validation loss: 2.378293224560317

Epoch: 6| Step: 10
Training loss: 2.670114755630493
Validation loss: 2.377201990414691

Epoch: 6| Step: 11
Training loss: 1.9903178215026855
Validation loss: 2.3823492732099307

Epoch: 6| Step: 12
Training loss: 2.4280428886413574
Validation loss: 2.385997550461882

Epoch: 6| Step: 13
Training loss: 2.238959312438965
Validation loss: 2.3904516235474618

Epoch: 51| Step: 0
Training loss: 3.3531012535095215
Validation loss: 2.3937201987030687

Epoch: 6| Step: 1
Training loss: 2.8614213466644287
Validation loss: 2.3960889718865834

Epoch: 6| Step: 2
Training loss: 2.418271541595459
Validation loss: 2.3959522093496015

Epoch: 6| Step: 3
Training loss: 2.633248805999756
Validation loss: 2.3998321358875563

Epoch: 6| Step: 4
Training loss: 2.406140089035034
Validation loss: 2.394957234782557

Epoch: 6| Step: 5
Training loss: 2.9800639152526855
Validation loss: 2.3959542833348757

Epoch: 6| Step: 6
Training loss: 1.8509900569915771
Validation loss: 2.3936636729906966

Epoch: 6| Step: 7
Training loss: 2.1471238136291504
Validation loss: 2.386994843841881

Epoch: 6| Step: 8
Training loss: 3.2132012844085693
Validation loss: 2.398855601587603

Epoch: 6| Step: 9
Training loss: 2.5990748405456543
Validation loss: 2.4138710985901537

Epoch: 6| Step: 10
Training loss: 2.6588711738586426
Validation loss: 2.440602525588005

Epoch: 6| Step: 11
Training loss: 3.0668492317199707
Validation loss: 2.4685828403760026

Epoch: 6| Step: 12
Training loss: 2.303966999053955
Validation loss: 2.4436699190447406

Epoch: 6| Step: 13
Training loss: 2.6212949752807617
Validation loss: 2.421933592006724

Epoch: 52| Step: 0
Training loss: 2.7363815307617188
Validation loss: 2.3944167552455777

Epoch: 6| Step: 1
Training loss: 2.765042304992676
Validation loss: 2.3851390936041392

Epoch: 6| Step: 2
Training loss: 2.7568106651306152
Validation loss: 2.385690055867677

Epoch: 6| Step: 3
Training loss: 2.725774049758911
Validation loss: 2.382118255861344

Epoch: 6| Step: 4
Training loss: 2.3322107791900635
Validation loss: 2.384720781798004

Epoch: 6| Step: 5
Training loss: 2.4099957942962646
Validation loss: 2.381107399540563

Epoch: 6| Step: 6
Training loss: 2.9312832355499268
Validation loss: 2.380786813715453

Epoch: 6| Step: 7
Training loss: 2.8243801593780518
Validation loss: 2.376919666926066

Epoch: 6| Step: 8
Training loss: 2.7459630966186523
Validation loss: 2.375259014867967

Epoch: 6| Step: 9
Training loss: 2.1807985305786133
Validation loss: 2.3737988843712756

Epoch: 6| Step: 10
Training loss: 2.013540267944336
Validation loss: 2.3744410891686716

Epoch: 6| Step: 11
Training loss: 3.179563045501709
Validation loss: 2.3753404078945035

Epoch: 6| Step: 12
Training loss: 3.3911988735198975
Validation loss: 2.3721077339623564

Epoch: 6| Step: 13
Training loss: 1.2749841213226318
Validation loss: 2.379988039693525

Epoch: 53| Step: 0
Training loss: 2.98331618309021
Validation loss: 2.3882828040789534

Epoch: 6| Step: 1
Training loss: 2.4846267700195312
Validation loss: 2.3826783626310286

Epoch: 6| Step: 2
Training loss: 2.9709177017211914
Validation loss: 2.3782142029013684

Epoch: 6| Step: 3
Training loss: 2.666532516479492
Validation loss: 2.3782726051986858

Epoch: 6| Step: 4
Training loss: 2.272998094558716
Validation loss: 2.378421127155263

Epoch: 6| Step: 5
Training loss: 2.4815287590026855
Validation loss: 2.3728711271798737

Epoch: 6| Step: 6
Training loss: 2.4619760513305664
Validation loss: 2.369308223006546

Epoch: 6| Step: 7
Training loss: 2.9034571647644043
Validation loss: 2.3629910087072723

Epoch: 6| Step: 8
Training loss: 2.4281671047210693
Validation loss: 2.3666276342125347

Epoch: 6| Step: 9
Training loss: 2.4352810382843018
Validation loss: 2.361311461335869

Epoch: 6| Step: 10
Training loss: 3.0908684730529785
Validation loss: 2.360786025242139

Epoch: 6| Step: 11
Training loss: 2.484503984451294
Validation loss: 2.36016853650411

Epoch: 6| Step: 12
Training loss: 2.733928918838501
Validation loss: 2.364649344516057

Epoch: 6| Step: 13
Training loss: 2.358511447906494
Validation loss: 2.3798255510227655

Epoch: 54| Step: 0
Training loss: 3.116912603378296
Validation loss: 2.4262911196677917

Epoch: 6| Step: 1
Training loss: 2.585346221923828
Validation loss: 2.4963058425534155

Epoch: 6| Step: 2
Training loss: 1.9516031742095947
Validation loss: 2.5379232591198337

Epoch: 6| Step: 3
Training loss: 2.6697139739990234
Validation loss: 2.5736336605523222

Epoch: 6| Step: 4
Training loss: 2.6191117763519287
Validation loss: 2.5580495634386615

Epoch: 6| Step: 5
Training loss: 2.9346187114715576
Validation loss: 2.505441291357881

Epoch: 6| Step: 6
Training loss: 2.5072717666625977
Validation loss: 2.452958535122615

Epoch: 6| Step: 7
Training loss: 2.031627655029297
Validation loss: 2.4188010256777526

Epoch: 6| Step: 8
Training loss: 2.3866963386535645
Validation loss: 2.4085298763808383

Epoch: 6| Step: 9
Training loss: 3.3613882064819336
Validation loss: 2.3987508845585648

Epoch: 6| Step: 10
Training loss: 2.6947784423828125
Validation loss: 2.3948620109147924

Epoch: 6| Step: 11
Training loss: 2.5075297355651855
Validation loss: 2.3843855704030683

Epoch: 6| Step: 12
Training loss: 3.2226147651672363
Validation loss: 2.3808193334969143

Epoch: 6| Step: 13
Training loss: 2.5274059772491455
Validation loss: 2.382665398300335

Epoch: 55| Step: 0
Training loss: 2.353163957595825
Validation loss: 2.384811334712531

Epoch: 6| Step: 1
Training loss: 2.6553726196289062
Validation loss: 2.3765840068940194

Epoch: 6| Step: 2
Training loss: 2.2482852935791016
Validation loss: 2.3795564636107414

Epoch: 6| Step: 3
Training loss: 2.3696107864379883
Validation loss: 2.3862786049483926

Epoch: 6| Step: 4
Training loss: 3.0137617588043213
Validation loss: 2.3983883473180954

Epoch: 6| Step: 5
Training loss: 2.656947135925293
Validation loss: 2.4042489887565694

Epoch: 6| Step: 6
Training loss: 2.741048812866211
Validation loss: 2.405629061883496

Epoch: 6| Step: 7
Training loss: 2.557405948638916
Validation loss: 2.4232897143210135

Epoch: 6| Step: 8
Training loss: 2.798482894897461
Validation loss: 2.4116261877039427

Epoch: 6| Step: 9
Training loss: 3.340674877166748
Validation loss: 2.3973921319489837

Epoch: 6| Step: 10
Training loss: 2.864187717437744
Validation loss: 2.4009088777726695

Epoch: 6| Step: 11
Training loss: 2.1205978393554688
Validation loss: 2.3933008101678666

Epoch: 6| Step: 12
Training loss: 2.2749249935150146
Validation loss: 2.3809339461788053

Epoch: 6| Step: 13
Training loss: 3.1836769580841064
Validation loss: 2.3743534934136177

Epoch: 56| Step: 0
Training loss: 3.1563470363616943
Validation loss: 2.362745959271667

Epoch: 6| Step: 1
Training loss: 2.0075864791870117
Validation loss: 2.3592735541764127

Epoch: 6| Step: 2
Training loss: 2.270573616027832
Validation loss: 2.3554733466076594

Epoch: 6| Step: 3
Training loss: 3.25423002243042
Validation loss: 2.3537453323282223

Epoch: 6| Step: 4
Training loss: 3.387789011001587
Validation loss: 2.3481463078529603

Epoch: 6| Step: 5
Training loss: 2.5291385650634766
Validation loss: 2.3487349197428715

Epoch: 6| Step: 6
Training loss: 3.0170514583587646
Validation loss: 2.3440085123944026

Epoch: 6| Step: 7
Training loss: 2.508157253265381
Validation loss: 2.34146112267689

Epoch: 6| Step: 8
Training loss: 2.45353364944458
Validation loss: 2.343104365051434

Epoch: 6| Step: 9
Training loss: 2.608671188354492
Validation loss: 2.351306544837131

Epoch: 6| Step: 10
Training loss: 2.2664480209350586
Validation loss: 2.356452441984607

Epoch: 6| Step: 11
Training loss: 2.2117552757263184
Validation loss: 2.3616106433253132

Epoch: 6| Step: 12
Training loss: 2.3720993995666504
Validation loss: 2.374111562646845

Epoch: 6| Step: 13
Training loss: 2.757697582244873
Validation loss: 2.385667008738364

Epoch: 57| Step: 0
Training loss: 1.6035881042480469
Validation loss: 2.383907720606814

Epoch: 6| Step: 1
Training loss: 2.7108192443847656
Validation loss: 2.3665433699084866

Epoch: 6| Step: 2
Training loss: 2.7687220573425293
Validation loss: 2.3565922501266643

Epoch: 6| Step: 3
Training loss: 3.143984794616699
Validation loss: 2.3534132639567056

Epoch: 6| Step: 4
Training loss: 2.482895851135254
Validation loss: 2.345541810476652

Epoch: 6| Step: 5
Training loss: 3.246116876602173
Validation loss: 2.345797984830795

Epoch: 6| Step: 6
Training loss: 3.079955816268921
Validation loss: 2.346664128764983

Epoch: 6| Step: 7
Training loss: 2.8482260704040527
Validation loss: 2.3409459590911865

Epoch: 6| Step: 8
Training loss: 2.7830874919891357
Validation loss: 2.342875090978479

Epoch: 6| Step: 9
Training loss: 2.6387860774993896
Validation loss: 2.3416659114181355

Epoch: 6| Step: 10
Training loss: 2.088613748550415
Validation loss: 2.3428381296896164

Epoch: 6| Step: 11
Training loss: 1.684326410293579
Validation loss: 2.34824179321207

Epoch: 6| Step: 12
Training loss: 2.700345039367676
Validation loss: 2.354304495678153

Epoch: 6| Step: 13
Training loss: 3.200469970703125
Validation loss: 2.3516348946479058

Epoch: 58| Step: 0
Training loss: 2.7585601806640625
Validation loss: 2.35653495019482

Epoch: 6| Step: 1
Training loss: 2.334035873413086
Validation loss: 2.3538683076058664

Epoch: 6| Step: 2
Training loss: 3.4153597354888916
Validation loss: 2.3506509821902037

Epoch: 6| Step: 3
Training loss: 2.702021598815918
Validation loss: 2.3472111917311147

Epoch: 6| Step: 4
Training loss: 2.575505018234253
Validation loss: 2.3347619630957164

Epoch: 6| Step: 5
Training loss: 1.830730676651001
Validation loss: 2.333390728119881

Epoch: 6| Step: 6
Training loss: 3.1088297367095947
Validation loss: 2.3257656815231487

Epoch: 6| Step: 7
Training loss: 2.0559582710266113
Validation loss: 2.3221252015841904

Epoch: 6| Step: 8
Training loss: 2.0459096431732178
Validation loss: 2.326412295782438

Epoch: 6| Step: 9
Training loss: 2.2541239261627197
Validation loss: 2.329383629624562

Epoch: 6| Step: 10
Training loss: 2.79233717918396
Validation loss: 2.3307672880029164

Epoch: 6| Step: 11
Training loss: 2.6255805492401123
Validation loss: 2.330347443139681

Epoch: 6| Step: 12
Training loss: 3.3647336959838867
Validation loss: 2.3327468954106814

Epoch: 6| Step: 13
Training loss: 2.747955799102783
Validation loss: 2.334808257318312

Epoch: 59| Step: 0
Training loss: 2.419680595397949
Validation loss: 2.3359621891411404

Epoch: 6| Step: 1
Training loss: 2.4964616298675537
Validation loss: 2.3371197946609987

Epoch: 6| Step: 2
Training loss: 2.8101367950439453
Validation loss: 2.3407425213885564

Epoch: 6| Step: 3
Training loss: 2.3858141899108887
Validation loss: 2.343855272057236

Epoch: 6| Step: 4
Training loss: 3.0918564796447754
Validation loss: 2.3370950478379444

Epoch: 6| Step: 5
Training loss: 2.6397109031677246
Validation loss: 2.3426765729022283

Epoch: 6| Step: 6
Training loss: 1.731183648109436
Validation loss: 2.3324602855149137

Epoch: 6| Step: 7
Training loss: 2.7675538063049316
Validation loss: 2.3326497077941895

Epoch: 6| Step: 8
Training loss: 1.888243556022644
Validation loss: 2.323950295807213

Epoch: 6| Step: 9
Training loss: 2.8786330223083496
Validation loss: 2.3183943174218618

Epoch: 6| Step: 10
Training loss: 3.0725979804992676
Validation loss: 2.3215353309467273

Epoch: 6| Step: 11
Training loss: 2.313272476196289
Validation loss: 2.325439445434078

Epoch: 6| Step: 12
Training loss: 3.0894012451171875
Validation loss: 2.325198704196561

Epoch: 6| Step: 13
Training loss: 2.898996114730835
Validation loss: 2.322157011237196

Epoch: 60| Step: 0
Training loss: 2.340132236480713
Validation loss: 2.325601395740304

Epoch: 6| Step: 1
Training loss: 2.449864387512207
Validation loss: 2.326049094559044

Epoch: 6| Step: 2
Training loss: 2.0599887371063232
Validation loss: 2.322637217019194

Epoch: 6| Step: 3
Training loss: 2.154658317565918
Validation loss: 2.322104623240809

Epoch: 6| Step: 4
Training loss: 2.8207545280456543
Validation loss: 2.3253273605018534

Epoch: 6| Step: 5
Training loss: 2.3176937103271484
Validation loss: 2.322597619025938

Epoch: 6| Step: 6
Training loss: 2.8259520530700684
Validation loss: 2.31406819692222

Epoch: 6| Step: 7
Training loss: 2.48140811920166
Validation loss: 2.3145859279940204

Epoch: 6| Step: 8
Training loss: 2.626227378845215
Validation loss: 2.316972860725977

Epoch: 6| Step: 9
Training loss: 3.033730983734131
Validation loss: 2.319855938675583

Epoch: 6| Step: 10
Training loss: 2.3296210765838623
Validation loss: 2.325600926594068

Epoch: 6| Step: 11
Training loss: 2.9705114364624023
Validation loss: 2.329417032580222

Epoch: 6| Step: 12
Training loss: 2.9757018089294434
Validation loss: 2.3289992578567995

Epoch: 6| Step: 13
Training loss: 3.1043920516967773
Validation loss: 2.3266557288426224

Epoch: 61| Step: 0
Training loss: 2.579226493835449
Validation loss: 2.324521408286146

Epoch: 6| Step: 1
Training loss: 2.435275077819824
Validation loss: 2.3333262294851322

Epoch: 6| Step: 2
Training loss: 3.3023149967193604
Validation loss: 2.330530938281808

Epoch: 6| Step: 3
Training loss: 2.3109655380249023
Validation loss: 2.3298762024089856

Epoch: 6| Step: 4
Training loss: 2.749337673187256
Validation loss: 2.327561988625475

Epoch: 6| Step: 5
Training loss: 2.3574166297912598
Validation loss: 2.3240752322699434

Epoch: 6| Step: 6
Training loss: 3.0336599349975586
Validation loss: 2.3212658615522486

Epoch: 6| Step: 7
Training loss: 3.033808946609497
Validation loss: 2.3132459860976025

Epoch: 6| Step: 8
Training loss: 2.811821937561035
Validation loss: 2.3089307687615834

Epoch: 6| Step: 9
Training loss: 2.31974720954895
Validation loss: 2.3085171253450456

Epoch: 6| Step: 10
Training loss: 2.154571056365967
Validation loss: 2.3025842251316195

Epoch: 6| Step: 11
Training loss: 2.490861177444458
Validation loss: 2.303807891825194

Epoch: 6| Step: 12
Training loss: 2.3278157711029053
Validation loss: 2.300813578790234

Epoch: 6| Step: 13
Training loss: 2.2063260078430176
Validation loss: 2.305136952348935

Epoch: 62| Step: 0
Training loss: 2.674290895462036
Validation loss: 2.3049415772961033

Epoch: 6| Step: 1
Training loss: 2.92582631111145
Validation loss: 2.305062473461192

Epoch: 6| Step: 2
Training loss: 3.006629467010498
Validation loss: 2.3074460580784786

Epoch: 6| Step: 3
Training loss: 2.6951072216033936
Validation loss: 2.3102508014248264

Epoch: 6| Step: 4
Training loss: 3.3161606788635254
Validation loss: 2.307117223739624

Epoch: 6| Step: 5
Training loss: 1.9838178157806396
Validation loss: 2.3088341823188205

Epoch: 6| Step: 6
Training loss: 3.030343532562256
Validation loss: 2.315379668307561

Epoch: 6| Step: 7
Training loss: 2.3927550315856934
Validation loss: 2.309694879798479

Epoch: 6| Step: 8
Training loss: 2.0902624130249023
Validation loss: 2.3198573717506985

Epoch: 6| Step: 9
Training loss: 2.0478572845458984
Validation loss: 2.328467643389138

Epoch: 6| Step: 10
Training loss: 2.6944222450256348
Validation loss: 2.3560909327640327

Epoch: 6| Step: 11
Training loss: 2.587264060974121
Validation loss: 2.3723044985084125

Epoch: 6| Step: 12
Training loss: 2.6502490043640137
Validation loss: 2.377229267551053

Epoch: 6| Step: 13
Training loss: 1.8507660627365112
Validation loss: 2.370320027874362

Epoch: 63| Step: 0
Training loss: 2.2481586933135986
Validation loss: 2.38817681548416

Epoch: 6| Step: 1
Training loss: 2.14909029006958
Validation loss: 2.390748877679148

Epoch: 6| Step: 2
Training loss: 2.1212856769561768
Validation loss: 2.3740527988761984

Epoch: 6| Step: 3
Training loss: 2.7611887454986572
Validation loss: 2.3454222756047405

Epoch: 6| Step: 4
Training loss: 2.511044979095459
Validation loss: 2.3105435730308614

Epoch: 6| Step: 5
Training loss: 3.414130687713623
Validation loss: 2.3018448686087005

Epoch: 6| Step: 6
Training loss: 2.7757906913757324
Validation loss: 2.296737127406623

Epoch: 6| Step: 7
Training loss: 2.3192224502563477
Validation loss: 2.2944619835063977

Epoch: 6| Step: 8
Training loss: 2.842133045196533
Validation loss: 2.292470080878145

Epoch: 6| Step: 9
Training loss: 2.6925735473632812
Validation loss: 2.2935322369298627

Epoch: 6| Step: 10
Training loss: 2.936959743499756
Validation loss: 2.2955638067696684

Epoch: 6| Step: 11
Training loss: 1.8698837757110596
Validation loss: 2.2973160692440566

Epoch: 6| Step: 12
Training loss: 2.954806089401245
Validation loss: 2.2953488608842254

Epoch: 6| Step: 13
Training loss: 3.073050022125244
Validation loss: 2.2948268869871735

Epoch: 64| Step: 0
Training loss: 2.8109500408172607
Validation loss: 2.296709114505399

Epoch: 6| Step: 1
Training loss: 2.462090015411377
Validation loss: 2.2958728754392235

Epoch: 6| Step: 2
Training loss: 2.291924476623535
Validation loss: 2.300482219265353

Epoch: 6| Step: 3
Training loss: 3.1585848331451416
Validation loss: 2.309331768302507

Epoch: 6| Step: 4
Training loss: 2.7485287189483643
Validation loss: 2.3199982745673067

Epoch: 6| Step: 5
Training loss: 2.9482831954956055
Validation loss: 2.336756762637887

Epoch: 6| Step: 6
Training loss: 2.656157970428467
Validation loss: 2.359581767871816

Epoch: 6| Step: 7
Training loss: 2.904134750366211
Validation loss: 2.367808629107732

Epoch: 6| Step: 8
Training loss: 2.4516048431396484
Validation loss: 2.3748883226866364

Epoch: 6| Step: 9
Training loss: 2.430114507675171
Validation loss: 2.4032616435840564

Epoch: 6| Step: 10
Training loss: 2.5805821418762207
Validation loss: 2.4188454586972474

Epoch: 6| Step: 11
Training loss: 2.3562886714935303
Validation loss: 2.394438928173434

Epoch: 6| Step: 12
Training loss: 2.5975422859191895
Validation loss: 2.340868167979743

Epoch: 6| Step: 13
Training loss: 1.4978430271148682
Validation loss: 2.3085073142923336

Epoch: 65| Step: 0
Training loss: 2.4858477115631104
Validation loss: 2.3002560753976145

Epoch: 6| Step: 1
Training loss: 2.8713083267211914
Validation loss: 2.2981842563998316

Epoch: 6| Step: 2
Training loss: 2.3678557872772217
Validation loss: 2.2943900477501655

Epoch: 6| Step: 3
Training loss: 2.75097393989563
Validation loss: 2.294789086106003

Epoch: 6| Step: 4
Training loss: 2.2495102882385254
Validation loss: 2.285563617624262

Epoch: 6| Step: 5
Training loss: 2.732041358947754
Validation loss: 2.2885759684347335

Epoch: 6| Step: 6
Training loss: 2.0459022521972656
Validation loss: 2.2923934613504717

Epoch: 6| Step: 7
Training loss: 2.6414377689361572
Validation loss: 2.290994403182819

Epoch: 6| Step: 8
Training loss: 2.4732604026794434
Validation loss: 2.292627437140352

Epoch: 6| Step: 9
Training loss: 2.872714042663574
Validation loss: 2.2977388776758665

Epoch: 6| Step: 10
Training loss: 3.0266151428222656
Validation loss: 2.303016380597186

Epoch: 6| Step: 11
Training loss: 2.90425443649292
Validation loss: 2.3226890384509997

Epoch: 6| Step: 12
Training loss: 2.306089401245117
Validation loss: 2.329506920230004

Epoch: 6| Step: 13
Training loss: 2.446674108505249
Validation loss: 2.3322064107464207

Epoch: 66| Step: 0
Training loss: 2.5048632621765137
Validation loss: 2.3231932527275494

Epoch: 6| Step: 1
Training loss: 2.5387470722198486
Validation loss: 2.3126997050418647

Epoch: 6| Step: 2
Training loss: 3.128671884536743
Validation loss: 2.296563543299193

Epoch: 6| Step: 3
Training loss: 2.4141201972961426
Validation loss: 2.2966445171704857

Epoch: 6| Step: 4
Training loss: 2.445528745651245
Validation loss: 2.299652212409563

Epoch: 6| Step: 5
Training loss: 2.511866807937622
Validation loss: 2.2959260068913943

Epoch: 6| Step: 6
Training loss: 2.834716320037842
Validation loss: 2.2883020908601823

Epoch: 6| Step: 7
Training loss: 2.7741286754608154
Validation loss: 2.2804535768365346

Epoch: 6| Step: 8
Training loss: 2.5837106704711914
Validation loss: 2.2785369555155435

Epoch: 6| Step: 9
Training loss: 2.513981819152832
Validation loss: 2.27832361959642

Epoch: 6| Step: 10
Training loss: 1.9807342290878296
Validation loss: 2.2805393613794798

Epoch: 6| Step: 11
Training loss: 2.116806745529175
Validation loss: 2.2842113138527

Epoch: 6| Step: 12
Training loss: 3.402550220489502
Validation loss: 2.2925597160093245

Epoch: 6| Step: 13
Training loss: 2.081176996231079
Validation loss: 2.290672153554937

Epoch: 67| Step: 0
Training loss: 3.0147862434387207
Validation loss: 2.296522681431104

Epoch: 6| Step: 1
Training loss: 1.9874259233474731
Validation loss: 2.3043125547388548

Epoch: 6| Step: 2
Training loss: 2.9314441680908203
Validation loss: 2.3072709960322224

Epoch: 6| Step: 3
Training loss: 2.2730443477630615
Validation loss: 2.3120549699311614

Epoch: 6| Step: 4
Training loss: 1.759647011756897
Validation loss: 2.296712701038648

Epoch: 6| Step: 5
Training loss: 2.8240954875946045
Validation loss: 2.292101962592012

Epoch: 6| Step: 6
Training loss: 3.472519636154175
Validation loss: 2.2766048882597234

Epoch: 6| Step: 7
Training loss: 2.634150505065918
Validation loss: 2.2734973712634017

Epoch: 6| Step: 8
Training loss: 1.8745267391204834
Validation loss: 2.2687552231614307

Epoch: 6| Step: 9
Training loss: 2.295379638671875
Validation loss: 2.274720835429366

Epoch: 6| Step: 10
Training loss: 2.082124710083008
Validation loss: 2.267570557132844

Epoch: 6| Step: 11
Training loss: 2.7460570335388184
Validation loss: 2.273629931993382

Epoch: 6| Step: 12
Training loss: 3.0226659774780273
Validation loss: 2.2713891049867034

Epoch: 6| Step: 13
Training loss: 3.470212697982788
Validation loss: 2.2648239699743127

Epoch: 68| Step: 0
Training loss: 2.595648765563965
Validation loss: 2.266387942016766

Epoch: 6| Step: 1
Training loss: 2.692605495452881
Validation loss: 2.2674808579106487

Epoch: 6| Step: 2
Training loss: 2.2072670459747314
Validation loss: 2.2755778604938137

Epoch: 6| Step: 3
Training loss: 2.8061952590942383
Validation loss: 2.283296077482162

Epoch: 6| Step: 4
Training loss: 3.085195302963257
Validation loss: 2.2888715062090146

Epoch: 6| Step: 5
Training loss: 2.538522243499756
Validation loss: 2.2857944593634656

Epoch: 6| Step: 6
Training loss: 2.4030933380126953
Validation loss: 2.276332022041403

Epoch: 6| Step: 7
Training loss: 2.7649011611938477
Validation loss: 2.2843055802006877

Epoch: 6| Step: 8
Training loss: 2.189713954925537
Validation loss: 2.2875261742581605

Epoch: 6| Step: 9
Training loss: 3.038046360015869
Validation loss: 2.2873321297348186

Epoch: 6| Step: 10
Training loss: 1.9696062803268433
Validation loss: 2.285451968510946

Epoch: 6| Step: 11
Training loss: 2.907390594482422
Validation loss: 2.2851039389128327

Epoch: 6| Step: 12
Training loss: 1.9531162977218628
Validation loss: 2.290510833904307

Epoch: 6| Step: 13
Training loss: 2.8688547611236572
Validation loss: 2.2873195550775014

Epoch: 69| Step: 0
Training loss: 2.3511977195739746
Validation loss: 2.308028708222092

Epoch: 6| Step: 1
Training loss: 2.310896635055542
Validation loss: 2.3326123696501537

Epoch: 6| Step: 2
Training loss: 2.203723907470703
Validation loss: 2.354109982008575

Epoch: 6| Step: 3
Training loss: 3.44685959815979
Validation loss: 2.3298534193346576

Epoch: 6| Step: 4
Training loss: 2.65661358833313
Validation loss: 2.3068123684134534

Epoch: 6| Step: 5
Training loss: 2.7980470657348633
Validation loss: 2.3059613909772647

Epoch: 6| Step: 6
Training loss: 2.403243064880371
Validation loss: 2.2929063612414944

Epoch: 6| Step: 7
Training loss: 2.4760007858276367
Validation loss: 2.278977806850146

Epoch: 6| Step: 8
Training loss: 2.664377212524414
Validation loss: 2.272064052602296

Epoch: 6| Step: 9
Training loss: 2.6115803718566895
Validation loss: 2.2709282521278626

Epoch: 6| Step: 10
Training loss: 1.9022670984268188
Validation loss: 2.2704300572795253

Epoch: 6| Step: 11
Training loss: 2.0508921146392822
Validation loss: 2.2796411309190976

Epoch: 6| Step: 12
Training loss: 3.228736400604248
Validation loss: 2.3111204985649354

Epoch: 6| Step: 13
Training loss: 3.100827217102051
Validation loss: 2.3484504274142686

Epoch: 70| Step: 0
Training loss: 2.939101219177246
Validation loss: 2.3183177389124388

Epoch: 6| Step: 1
Training loss: 2.061589241027832
Validation loss: 2.2729584991291003

Epoch: 6| Step: 2
Training loss: 2.9429779052734375
Validation loss: 2.256595685917844

Epoch: 6| Step: 3
Training loss: 2.3375821113586426
Validation loss: 2.2549180317950506

Epoch: 6| Step: 4
Training loss: 2.6821980476379395
Validation loss: 2.2562511761983237

Epoch: 6| Step: 5
Training loss: 2.4188120365142822
Validation loss: 2.2553964968650573

Epoch: 6| Step: 6
Training loss: 3.070963144302368
Validation loss: 2.2608257878211235

Epoch: 6| Step: 7
Training loss: 2.1107401847839355
Validation loss: 2.269184938041113

Epoch: 6| Step: 8
Training loss: 2.436472177505493
Validation loss: 2.27350180379806

Epoch: 6| Step: 9
Training loss: 3.199944257736206
Validation loss: 2.292158175540227

Epoch: 6| Step: 10
Training loss: 2.349043846130371
Validation loss: 2.3083582693530666

Epoch: 6| Step: 11
Training loss: 2.5402016639709473
Validation loss: 2.335523011863873

Epoch: 6| Step: 12
Training loss: 2.0469155311584473
Validation loss: 2.393363901363906

Epoch: 6| Step: 13
Training loss: 2.914720296859741
Validation loss: 2.5217168074782177

Epoch: 71| Step: 0
Training loss: 1.8817050457000732
Validation loss: 2.404140813376314

Epoch: 6| Step: 1
Training loss: 2.7188563346862793
Validation loss: 2.3569980667483423

Epoch: 6| Step: 2
Training loss: 2.836742401123047
Validation loss: 2.3466133456076346

Epoch: 6| Step: 3
Training loss: 2.8874459266662598
Validation loss: 2.3427328037959274

Epoch: 6| Step: 4
Training loss: 2.4486351013183594
Validation loss: 2.4081862613719

Epoch: 6| Step: 5
Training loss: 2.9642577171325684
Validation loss: 2.422627402890113

Epoch: 6| Step: 6
Training loss: 2.572052478790283
Validation loss: 2.3840442088342484

Epoch: 6| Step: 7
Training loss: 2.74272084236145
Validation loss: 2.361507911835947

Epoch: 6| Step: 8
Training loss: 2.326958179473877
Validation loss: 2.344050781701201

Epoch: 6| Step: 9
Training loss: 2.019022226333618
Validation loss: 2.3289999705488964

Epoch: 6| Step: 10
Training loss: 3.013005495071411
Validation loss: 2.31303043775661

Epoch: 6| Step: 11
Training loss: 3.3107051849365234
Validation loss: 2.3030970506770636

Epoch: 6| Step: 12
Training loss: 2.0254569053649902
Validation loss: 2.299792158988214

Epoch: 6| Step: 13
Training loss: 2.5402700901031494
Validation loss: 2.3002551832506732

Epoch: 72| Step: 0
Training loss: 2.711012840270996
Validation loss: 2.303969557567309

Epoch: 6| Step: 1
Training loss: 2.1958184242248535
Validation loss: 2.293935296356037

Epoch: 6| Step: 2
Training loss: 2.40402889251709
Validation loss: 2.291057784070251

Epoch: 6| Step: 3
Training loss: 2.480381965637207
Validation loss: 2.2840846507780013

Epoch: 6| Step: 4
Training loss: 2.755129337310791
Validation loss: 2.292754086115027

Epoch: 6| Step: 5
Training loss: 2.527859687805176
Validation loss: 2.296506381803943

Epoch: 6| Step: 6
Training loss: 2.4800586700439453
Validation loss: 2.2865736023072274

Epoch: 6| Step: 7
Training loss: 3.393183469772339
Validation loss: 2.288974312043959

Epoch: 6| Step: 8
Training loss: 2.130876064300537
Validation loss: 2.293419199605142

Epoch: 6| Step: 9
Training loss: 3.422330856323242
Validation loss: 2.2873021684667116

Epoch: 6| Step: 10
Training loss: 2.9433131217956543
Validation loss: 2.2788743870232695

Epoch: 6| Step: 11
Training loss: 2.116367816925049
Validation loss: 2.2713723028859785

Epoch: 6| Step: 12
Training loss: 1.8689796924591064
Validation loss: 2.2719348810052358

Epoch: 6| Step: 13
Training loss: 2.21102237701416
Validation loss: 2.267225334721227

Epoch: 73| Step: 0
Training loss: 2.150019645690918
Validation loss: 2.266797750226913

Epoch: 6| Step: 1
Training loss: 2.5401268005371094
Validation loss: 2.269030337692589

Epoch: 6| Step: 2
Training loss: 3.0126571655273438
Validation loss: 2.2895069468405937

Epoch: 6| Step: 3
Training loss: 2.945598840713501
Validation loss: 2.3204342370392173

Epoch: 6| Step: 4
Training loss: 2.3045895099639893
Validation loss: 2.3935442329734884

Epoch: 6| Step: 5
Training loss: 2.1702239513397217
Validation loss: 2.35702617578609

Epoch: 6| Step: 6
Training loss: 2.1989545822143555
Validation loss: 2.3232347234602897

Epoch: 6| Step: 7
Training loss: 3.0860543251037598
Validation loss: 2.290212510734476

Epoch: 6| Step: 8
Training loss: 2.9783787727355957
Validation loss: 2.253433181393531

Epoch: 6| Step: 9
Training loss: 2.3877224922180176
Validation loss: 2.252982724097467

Epoch: 6| Step: 10
Training loss: 2.584690809249878
Validation loss: 2.2612291702660183

Epoch: 6| Step: 11
Training loss: 2.661052942276001
Validation loss: 2.2600523887142057

Epoch: 6| Step: 12
Training loss: 3.0534868240356445
Validation loss: 2.2606147540512906

Epoch: 6| Step: 13
Training loss: 1.5676497220993042
Validation loss: 2.262395115308864

Epoch: 74| Step: 0
Training loss: 2.515821933746338
Validation loss: 2.2736728857922297

Epoch: 6| Step: 1
Training loss: 2.4464409351348877
Validation loss: 2.264866293117564

Epoch: 6| Step: 2
Training loss: 2.6335361003875732
Validation loss: 2.2697673049024356

Epoch: 6| Step: 3
Training loss: 2.7876667976379395
Validation loss: 2.2662057850950506

Epoch: 6| Step: 4
Training loss: 2.9574151039123535
Validation loss: 2.2624225154999764

Epoch: 6| Step: 5
Training loss: 2.228092670440674
Validation loss: 2.25475404595816

Epoch: 6| Step: 6
Training loss: 2.9278011322021484
Validation loss: 2.2517609288615565

Epoch: 6| Step: 7
Training loss: 2.037320137023926
Validation loss: 2.243489424387614

Epoch: 6| Step: 8
Training loss: 3.162292003631592
Validation loss: 2.243377440719194

Epoch: 6| Step: 9
Training loss: 2.2830958366394043
Validation loss: 2.24867743830527

Epoch: 6| Step: 10
Training loss: 2.532066583633423
Validation loss: 2.2484260925682644

Epoch: 6| Step: 11
Training loss: 2.709214210510254
Validation loss: 2.259037676677909

Epoch: 6| Step: 12
Training loss: 2.4893786907196045
Validation loss: 2.264813170638136

Epoch: 6| Step: 13
Training loss: 1.8828167915344238
Validation loss: 2.2924869650153705

Epoch: 75| Step: 0
Training loss: 3.0495452880859375
Validation loss: 2.3362989682023243

Epoch: 6| Step: 1
Training loss: 2.4550740718841553
Validation loss: 2.372888042080787

Epoch: 6| Step: 2
Training loss: 2.1299681663513184
Validation loss: 2.396782713551675

Epoch: 6| Step: 3
Training loss: 2.576404094696045
Validation loss: 2.38912215540486

Epoch: 6| Step: 4
Training loss: 3.541301965713501
Validation loss: 2.3386917575713126

Epoch: 6| Step: 5
Training loss: 2.111619710922241
Validation loss: 2.275547609534315

Epoch: 6| Step: 6
Training loss: 2.6664071083068848
Validation loss: 2.239061688864103

Epoch: 6| Step: 7
Training loss: 2.193192481994629
Validation loss: 2.2326807014403807

Epoch: 6| Step: 8
Training loss: 2.4436447620391846
Validation loss: 2.2323916778769544

Epoch: 6| Step: 9
Training loss: 2.6540398597717285
Validation loss: 2.2393776447542253

Epoch: 6| Step: 10
Training loss: 2.6036019325256348
Validation loss: 2.2474798925461306

Epoch: 6| Step: 11
Training loss: 2.4681448936462402
Validation loss: 2.2638092528107348

Epoch: 6| Step: 12
Training loss: 2.7931413650512695
Validation loss: 2.266805043784521

Epoch: 6| Step: 13
Training loss: 2.55475115776062
Validation loss: 2.272739830837455

Epoch: 76| Step: 0
Training loss: 2.7104687690734863
Validation loss: 2.284627322227724

Epoch: 6| Step: 1
Training loss: 2.353977680206299
Validation loss: 2.323147141805259

Epoch: 6| Step: 2
Training loss: 2.6255288124084473
Validation loss: 2.446152607599894

Epoch: 6| Step: 3
Training loss: 2.693453788757324
Validation loss: 2.4810830649509223

Epoch: 6| Step: 4
Training loss: 3.249674081802368
Validation loss: 2.4033026669615056

Epoch: 6| Step: 5
Training loss: 1.7807507514953613
Validation loss: 2.2737528483072915

Epoch: 6| Step: 6
Training loss: 2.8986971378326416
Validation loss: 2.2619342521954606

Epoch: 6| Step: 7
Training loss: 2.6271862983703613
Validation loss: 2.2447401503080964

Epoch: 6| Step: 8
Training loss: 2.4960479736328125
Validation loss: 2.2434082787523986

Epoch: 6| Step: 9
Training loss: 1.9526288509368896
Validation loss: 2.2547540639036443

Epoch: 6| Step: 10
Training loss: 3.014583110809326
Validation loss: 2.2945647983140844

Epoch: 6| Step: 11
Training loss: 2.856844902038574
Validation loss: 2.3597908686566096

Epoch: 6| Step: 12
Training loss: 2.301112174987793
Validation loss: 2.36295271688892

Epoch: 6| Step: 13
Training loss: 2.846129894256592
Validation loss: 2.338885807221936

Epoch: 77| Step: 0
Training loss: 2.7789125442504883
Validation loss: 2.2855620743125997

Epoch: 6| Step: 1
Training loss: 3.1365811824798584
Validation loss: 2.2533367885056363

Epoch: 6| Step: 2
Training loss: 2.60516095161438
Validation loss: 2.2535445433790966

Epoch: 6| Step: 3
Training loss: 2.8540472984313965
Validation loss: 2.245124596421437

Epoch: 6| Step: 4
Training loss: 3.0921711921691895
Validation loss: 2.2272838597656577

Epoch: 6| Step: 5
Training loss: 1.5771667957305908
Validation loss: 2.2169316994246615

Epoch: 6| Step: 6
Training loss: 2.1367850303649902
Validation loss: 2.2255099332460793

Epoch: 6| Step: 7
Training loss: 2.0943074226379395
Validation loss: 2.23056548641574

Epoch: 6| Step: 8
Training loss: 2.484931707382202
Validation loss: 2.225868458388954

Epoch: 6| Step: 9
Training loss: 2.827817916870117
Validation loss: 2.242800768985543

Epoch: 6| Step: 10
Training loss: 1.644059181213379
Validation loss: 2.252663061182986

Epoch: 6| Step: 11
Training loss: 2.9720423221588135
Validation loss: 2.2558277717200657

Epoch: 6| Step: 12
Training loss: 2.78570818901062
Validation loss: 2.27287309656861

Epoch: 6| Step: 13
Training loss: 2.468592882156372
Validation loss: 2.26695926215059

Epoch: 78| Step: 0
Training loss: 2.8944075107574463
Validation loss: 2.2776555143376833

Epoch: 6| Step: 1
Training loss: 2.2078723907470703
Validation loss: 2.2862033151811167

Epoch: 6| Step: 2
Training loss: 2.9699161052703857
Validation loss: 2.3367316210141746

Epoch: 6| Step: 3
Training loss: 2.616090774536133
Validation loss: 2.3750467556779102

Epoch: 6| Step: 4
Training loss: 2.906989097595215
Validation loss: 2.3677197335868754

Epoch: 6| Step: 5
Training loss: 2.3284311294555664
Validation loss: 2.363937529184485

Epoch: 6| Step: 6
Training loss: 2.6822292804718018
Validation loss: 2.3457420590103313

Epoch: 6| Step: 7
Training loss: 2.8085272312164307
Validation loss: 2.315874089476883

Epoch: 6| Step: 8
Training loss: 1.9963070154190063
Validation loss: 2.290974106839908

Epoch: 6| Step: 9
Training loss: 2.3962252140045166
Validation loss: 2.2700920245980702

Epoch: 6| Step: 10
Training loss: 2.8334097862243652
Validation loss: 2.261677776613543

Epoch: 6| Step: 11
Training loss: 2.3888192176818848
Validation loss: 2.2396859943225818

Epoch: 6| Step: 12
Training loss: 2.595287799835205
Validation loss: 2.2240683340257212

Epoch: 6| Step: 13
Training loss: 1.8996222019195557
Validation loss: 2.210144776169972

Epoch: 79| Step: 0
Training loss: 2.5989108085632324
Validation loss: 2.207024585816168

Epoch: 6| Step: 1
Training loss: 2.234243154525757
Validation loss: 2.2223531123130553

Epoch: 6| Step: 2
Training loss: 3.3402256965637207
Validation loss: 2.2278167073444655

Epoch: 6| Step: 3
Training loss: 2.9756436347961426
Validation loss: 2.220077171120592

Epoch: 6| Step: 4
Training loss: 2.31064510345459
Validation loss: 2.2217543150788996

Epoch: 6| Step: 5
Training loss: 2.5176451206207275
Validation loss: 2.216002320730558

Epoch: 6| Step: 6
Training loss: 2.1038131713867188
Validation loss: 2.2112863243267102

Epoch: 6| Step: 7
Training loss: 2.241485357284546
Validation loss: 2.2091832468586583

Epoch: 6| Step: 8
Training loss: 2.5490753650665283
Validation loss: 2.2177401383717856

Epoch: 6| Step: 9
Training loss: 3.210787296295166
Validation loss: 2.2216984636040142

Epoch: 6| Step: 10
Training loss: 2.755197525024414
Validation loss: 2.221303898801086

Epoch: 6| Step: 11
Training loss: 2.5857443809509277
Validation loss: 2.22586747395095

Epoch: 6| Step: 12
Training loss: 2.29311466217041
Validation loss: 2.232467605221656

Epoch: 6| Step: 13
Training loss: 1.4240994453430176
Validation loss: 2.2355701705460906

Epoch: 80| Step: 0
Training loss: 2.58937668800354
Validation loss: 2.2258096023272445

Epoch: 6| Step: 1
Training loss: 1.9816482067108154
Validation loss: 2.227346585642907

Epoch: 6| Step: 2
Training loss: 3.158447265625
Validation loss: 2.2128628684628393

Epoch: 6| Step: 3
Training loss: 2.639357328414917
Validation loss: 2.2046892886520713

Epoch: 6| Step: 4
Training loss: 2.5878546237945557
Validation loss: 2.1946535392474105

Epoch: 6| Step: 5
Training loss: 2.5318875312805176
Validation loss: 2.1902245129308393

Epoch: 6| Step: 6
Training loss: 2.9397518634796143
Validation loss: 2.1927980069191224

Epoch: 6| Step: 7
Training loss: 2.5480823516845703
Validation loss: 2.190746799592049

Epoch: 6| Step: 8
Training loss: 2.3027915954589844
Validation loss: 2.193043362709784

Epoch: 6| Step: 9
Training loss: 2.4366796016693115
Validation loss: 2.1949900760445544

Epoch: 6| Step: 10
Training loss: 2.498690605163574
Validation loss: 2.194080175891999

Epoch: 6| Step: 11
Training loss: 2.447141170501709
Validation loss: 2.197561543474915

Epoch: 6| Step: 12
Training loss: 1.9582202434539795
Validation loss: 2.206057325486214

Epoch: 6| Step: 13
Training loss: 2.8803844451904297
Validation loss: 2.2007929484049478

Epoch: 81| Step: 0
Training loss: 2.063776731491089
Validation loss: 2.207716215041376

Epoch: 6| Step: 1
Training loss: 2.501394271850586
Validation loss: 2.2136263052622476

Epoch: 6| Step: 2
Training loss: 1.8720440864562988
Validation loss: 2.2190656072349957

Epoch: 6| Step: 3
Training loss: 2.8277015686035156
Validation loss: 2.22747286417151

Epoch: 6| Step: 4
Training loss: 2.8208398818969727
Validation loss: 2.226015898489183

Epoch: 6| Step: 5
Training loss: 2.2173140048980713
Validation loss: 2.226154342774422

Epoch: 6| Step: 6
Training loss: 3.019562005996704
Validation loss: 2.212912223672354

Epoch: 6| Step: 7
Training loss: 2.006087064743042
Validation loss: 2.2095463506637083

Epoch: 6| Step: 8
Training loss: 2.638899803161621
Validation loss: 2.1946180687155774

Epoch: 6| Step: 9
Training loss: 2.6054484844207764
Validation loss: 2.189255540088941

Epoch: 6| Step: 10
Training loss: 2.9121649265289307
Validation loss: 2.195658483812886

Epoch: 6| Step: 11
Training loss: 2.629720687866211
Validation loss: 2.1865175616356636

Epoch: 6| Step: 12
Training loss: 2.629406690597534
Validation loss: 2.1972879312371694

Epoch: 6| Step: 13
Training loss: 2.165268659591675
Validation loss: 2.200314229534518

Epoch: 82| Step: 0
Training loss: 2.364687919616699
Validation loss: 2.2112361820795203

Epoch: 6| Step: 1
Training loss: 2.518864631652832
Validation loss: 2.2240420592728483

Epoch: 6| Step: 2
Training loss: 2.9725699424743652
Validation loss: 2.231395072834466

Epoch: 6| Step: 3
Training loss: 2.5620665550231934
Validation loss: 2.2398197727818645

Epoch: 6| Step: 4
Training loss: 2.532681941986084
Validation loss: 2.233500534488309

Epoch: 6| Step: 5
Training loss: 2.7690248489379883
Validation loss: 2.2158091068267822

Epoch: 6| Step: 6
Training loss: 2.984804153442383
Validation loss: 2.219031891515178

Epoch: 6| Step: 7
Training loss: 2.9278132915496826
Validation loss: 2.218543691019858

Epoch: 6| Step: 8
Training loss: 2.5617830753326416
Validation loss: 2.211241323460815

Epoch: 6| Step: 9
Training loss: 2.4149837493896484
Validation loss: 2.206059963472428

Epoch: 6| Step: 10
Training loss: 2.726905345916748
Validation loss: 2.2000625415514876

Epoch: 6| Step: 11
Training loss: 1.5979520082473755
Validation loss: 2.2088079760151524

Epoch: 6| Step: 12
Training loss: 2.182311773300171
Validation loss: 2.2119859110924507

Epoch: 6| Step: 13
Training loss: 1.3924202919006348
Validation loss: 2.20098546243483

Epoch: 83| Step: 0
Training loss: 2.4281930923461914
Validation loss: 2.2001744739470945

Epoch: 6| Step: 1
Training loss: 1.9040064811706543
Validation loss: 2.201156662356469

Epoch: 6| Step: 2
Training loss: 2.834115982055664
Validation loss: 2.204018062160861

Epoch: 6| Step: 3
Training loss: 3.1479082107543945
Validation loss: 2.205003014174841

Epoch: 6| Step: 4
Training loss: 2.6482982635498047
Validation loss: 2.197628331440751

Epoch: 6| Step: 5
Training loss: 1.9662878513336182
Validation loss: 2.199538238586918

Epoch: 6| Step: 6
Training loss: 2.510507106781006
Validation loss: 2.20322338996395

Epoch: 6| Step: 7
Training loss: 2.9746055603027344
Validation loss: 2.2075095202333186

Epoch: 6| Step: 8
Training loss: 2.8613369464874268
Validation loss: 2.21989462068004

Epoch: 6| Step: 9
Training loss: 1.9879390001296997
Validation loss: 2.227506158172443

Epoch: 6| Step: 10
Training loss: 3.137505054473877
Validation loss: 2.212607886201592

Epoch: 6| Step: 11
Training loss: 2.0571484565734863
Validation loss: 2.2150883930985645

Epoch: 6| Step: 12
Training loss: 1.823012351989746
Validation loss: 2.1957771444833405

Epoch: 6| Step: 13
Training loss: 2.615912437438965
Validation loss: 2.1878325964814875

Epoch: 84| Step: 0
Training loss: 2.466115951538086
Validation loss: 2.2047203151128625

Epoch: 6| Step: 1
Training loss: 2.215273857116699
Validation loss: 2.2529035178563928

Epoch: 6| Step: 2
Training loss: 2.6320252418518066
Validation loss: 2.2987199778197915

Epoch: 6| Step: 3
Training loss: 2.402097702026367
Validation loss: 2.336405433634276

Epoch: 6| Step: 4
Training loss: 2.781798839569092
Validation loss: 2.361128053357524

Epoch: 6| Step: 5
Training loss: 2.574640989303589
Validation loss: 2.371790473179151

Epoch: 6| Step: 6
Training loss: 3.0717108249664307
Validation loss: 2.363105317597748

Epoch: 6| Step: 7
Training loss: 2.284942150115967
Validation loss: 2.317273275826567

Epoch: 6| Step: 8
Training loss: 2.7294604778289795
Validation loss: 2.274635740505752

Epoch: 6| Step: 9
Training loss: 2.469316005706787
Validation loss: 2.2418682241952546

Epoch: 6| Step: 10
Training loss: 2.448981285095215
Validation loss: 2.223043005953553

Epoch: 6| Step: 11
Training loss: 2.267887830734253
Validation loss: 2.2186397762708765

Epoch: 6| Step: 12
Training loss: 2.105121612548828
Validation loss: 2.2084225018819175

Epoch: 6| Step: 13
Training loss: 3.2469329833984375
Validation loss: 2.1990853407049693

Epoch: 85| Step: 0
Training loss: 1.6783480644226074
Validation loss: 2.1988818325022215

Epoch: 6| Step: 1
Training loss: 2.3308496475219727
Validation loss: 2.1979337661497054

Epoch: 6| Step: 2
Training loss: 3.021876096725464
Validation loss: 2.200870466488664

Epoch: 6| Step: 3
Training loss: 2.235266923904419
Validation loss: 2.1968450084809334

Epoch: 6| Step: 4
Training loss: 3.055699348449707
Validation loss: 2.2133161303817586

Epoch: 6| Step: 5
Training loss: 2.8561060428619385
Validation loss: 2.207561577520063

Epoch: 6| Step: 6
Training loss: 2.552212715148926
Validation loss: 2.208891540445307

Epoch: 6| Step: 7
Training loss: 2.4270577430725098
Validation loss: 2.213085907761769

Epoch: 6| Step: 8
Training loss: 2.7858951091766357
Validation loss: 2.2184699530242593

Epoch: 6| Step: 9
Training loss: 2.214555025100708
Validation loss: 2.2214143942761164

Epoch: 6| Step: 10
Training loss: 2.6017723083496094
Validation loss: 2.2311024281286422

Epoch: 6| Step: 11
Training loss: 2.621474027633667
Validation loss: 2.244091728682159

Epoch: 6| Step: 12
Training loss: 2.416918992996216
Validation loss: 2.2507145814998175

Epoch: 6| Step: 13
Training loss: 2.2577552795410156
Validation loss: 2.2574167661769415

Epoch: 86| Step: 0
Training loss: 2.366438865661621
Validation loss: 2.2174543052591305

Epoch: 6| Step: 1
Training loss: 2.3475656509399414
Validation loss: 2.186864819577945

Epoch: 6| Step: 2
Training loss: 2.07356333732605
Validation loss: 2.1720084451859996

Epoch: 6| Step: 3
Training loss: 2.0315582752227783
Validation loss: 2.166421377530662

Epoch: 6| Step: 4
Training loss: 2.8788630962371826
Validation loss: 2.1718461308428036

Epoch: 6| Step: 5
Training loss: 2.721719264984131
Validation loss: 2.173158332865725

Epoch: 6| Step: 6
Training loss: 2.7453575134277344
Validation loss: 2.1759956908482376

Epoch: 6| Step: 7
Training loss: 2.195115089416504
Validation loss: 2.179741795345019

Epoch: 6| Step: 8
Training loss: 2.398223876953125
Validation loss: 2.1756083439755183

Epoch: 6| Step: 9
Training loss: 2.3510870933532715
Validation loss: 2.1715452747960247

Epoch: 6| Step: 10
Training loss: 2.6910786628723145
Validation loss: 2.171296996455039

Epoch: 6| Step: 11
Training loss: 2.4814724922180176
Validation loss: 2.172759307328091

Epoch: 6| Step: 12
Training loss: 2.8139524459838867
Validation loss: 2.184992198021181

Epoch: 6| Step: 13
Training loss: 3.213301658630371
Validation loss: 2.180520083314629

Epoch: 87| Step: 0
Training loss: 3.1545538902282715
Validation loss: 2.19287775152473

Epoch: 6| Step: 1
Training loss: 2.822603702545166
Validation loss: 2.2162427850948867

Epoch: 6| Step: 2
Training loss: 2.7033488750457764
Validation loss: 2.231050729751587

Epoch: 6| Step: 3
Training loss: 2.744584083557129
Validation loss: 2.253556413035239

Epoch: 6| Step: 4
Training loss: 1.8473217487335205
Validation loss: 2.260482730404023

Epoch: 6| Step: 5
Training loss: 2.327695846557617
Validation loss: 2.2536568564753376

Epoch: 6| Step: 6
Training loss: 2.4136404991149902
Validation loss: 2.248088490578436

Epoch: 6| Step: 7
Training loss: 1.8789762258529663
Validation loss: 2.2376928021830897

Epoch: 6| Step: 8
Training loss: 2.4582479000091553
Validation loss: 2.215538150520735

Epoch: 6| Step: 9
Training loss: 2.1091456413269043
Validation loss: 2.197095614607616

Epoch: 6| Step: 10
Training loss: 2.5198867321014404
Validation loss: 2.189596519675306

Epoch: 6| Step: 11
Training loss: 2.4891600608825684
Validation loss: 2.166319724052183

Epoch: 6| Step: 12
Training loss: 2.819286823272705
Validation loss: 2.1649010027608564

Epoch: 6| Step: 13
Training loss: 2.309995174407959
Validation loss: 2.166012015393985

Epoch: 88| Step: 0
Training loss: 1.7855310440063477
Validation loss: 2.158958086403467

Epoch: 6| Step: 1
Training loss: 3.0294077396392822
Validation loss: 2.16065062246015

Epoch: 6| Step: 2
Training loss: 2.440232515335083
Validation loss: 2.161923240589839

Epoch: 6| Step: 3
Training loss: 2.951889991760254
Validation loss: 2.1620458120940835

Epoch: 6| Step: 4
Training loss: 2.3022730350494385
Validation loss: 2.1605441903555267

Epoch: 6| Step: 5
Training loss: 2.192117214202881
Validation loss: 2.168821474557282

Epoch: 6| Step: 6
Training loss: 2.312324047088623
Validation loss: 2.1712267988471576

Epoch: 6| Step: 7
Training loss: 1.6314327716827393
Validation loss: 2.1722237986903035

Epoch: 6| Step: 8
Training loss: 2.8756556510925293
Validation loss: 2.191172161409932

Epoch: 6| Step: 9
Training loss: 2.6816928386688232
Validation loss: 2.191889593678136

Epoch: 6| Step: 10
Training loss: 2.1811110973358154
Validation loss: 2.1904237039627565

Epoch: 6| Step: 11
Training loss: 2.4314098358154297
Validation loss: 2.20745498646972

Epoch: 6| Step: 12
Training loss: 3.1654882431030273
Validation loss: 2.240487019220988

Epoch: 6| Step: 13
Training loss: 2.846985340118408
Validation loss: 2.277899370398573

Epoch: 89| Step: 0
Training loss: 2.343970775604248
Validation loss: 2.290273363872241

Epoch: 6| Step: 1
Training loss: 2.355639934539795
Validation loss: 2.234840052102202

Epoch: 6| Step: 2
Training loss: 2.7537779808044434
Validation loss: 2.1811822998908257

Epoch: 6| Step: 3
Training loss: 2.1299610137939453
Validation loss: 2.1532624139580676

Epoch: 6| Step: 4
Training loss: 2.931570053100586
Validation loss: 2.147682656524002

Epoch: 6| Step: 5
Training loss: 2.9541187286376953
Validation loss: 2.1512742734724477

Epoch: 6| Step: 6
Training loss: 2.9198033809661865
Validation loss: 2.1558666998340237

Epoch: 6| Step: 7
Training loss: 1.9898693561553955
Validation loss: 2.1555220004050963

Epoch: 6| Step: 8
Training loss: 2.5845377445220947
Validation loss: 2.157716069170224

Epoch: 6| Step: 9
Training loss: 2.179354667663574
Validation loss: 2.156725755301855

Epoch: 6| Step: 10
Training loss: 2.8055660724639893
Validation loss: 2.156136938320693

Epoch: 6| Step: 11
Training loss: 2.53074049949646
Validation loss: 2.1525899415375083

Epoch: 6| Step: 12
Training loss: 1.7050213813781738
Validation loss: 2.147189670993436

Epoch: 6| Step: 13
Training loss: 3.008471727371216
Validation loss: 2.1461238591901717

Epoch: 90| Step: 0
Training loss: 2.9202637672424316
Validation loss: 2.144616937124601

Epoch: 6| Step: 1
Training loss: 1.9427372217178345
Validation loss: 2.141007233691472

Epoch: 6| Step: 2
Training loss: 3.0552098751068115
Validation loss: 2.1417419166975122

Epoch: 6| Step: 3
Training loss: 2.8297626972198486
Validation loss: 2.142538846180003

Epoch: 6| Step: 4
Training loss: 2.678109645843506
Validation loss: 2.1494659839137906

Epoch: 6| Step: 5
Training loss: 2.277730941772461
Validation loss: 2.1667086680730185

Epoch: 6| Step: 6
Training loss: 2.3719091415405273
Validation loss: 2.192474752344111

Epoch: 6| Step: 7
Training loss: 2.3987765312194824
Validation loss: 2.202425895198699

Epoch: 6| Step: 8
Training loss: 2.559279203414917
Validation loss: 2.2207945828796714

Epoch: 6| Step: 9
Training loss: 1.7067534923553467
Validation loss: 2.211700129252608

Epoch: 6| Step: 10
Training loss: 2.4077301025390625
Validation loss: 2.1941951346653763

Epoch: 6| Step: 11
Training loss: 3.5249862670898438
Validation loss: 2.189118513496973

Epoch: 6| Step: 12
Training loss: 1.8513000011444092
Validation loss: 2.1732082520761797

Epoch: 6| Step: 13
Training loss: 2.001363754272461
Validation loss: 2.161864803683373

Epoch: 91| Step: 0
Training loss: 3.00453519821167
Validation loss: 2.155264110975368

Epoch: 6| Step: 1
Training loss: 2.377434253692627
Validation loss: 2.1637204744482554

Epoch: 6| Step: 2
Training loss: 1.8436062335968018
Validation loss: 2.160280325079477

Epoch: 6| Step: 3
Training loss: 3.1025748252868652
Validation loss: 2.1655996230340775

Epoch: 6| Step: 4
Training loss: 1.8040051460266113
Validation loss: 2.1646777506797545

Epoch: 6| Step: 5
Training loss: 1.9694010019302368
Validation loss: 2.156555562890986

Epoch: 6| Step: 6
Training loss: 1.921981692314148
Validation loss: 2.148032639616279

Epoch: 6| Step: 7
Training loss: 2.8281660079956055
Validation loss: 2.13997588106381

Epoch: 6| Step: 8
Training loss: 2.644138813018799
Validation loss: 2.13755375851867

Epoch: 6| Step: 9
Training loss: 2.132364273071289
Validation loss: 2.135345556402719

Epoch: 6| Step: 10
Training loss: 2.8513870239257812
Validation loss: 2.133795146019228

Epoch: 6| Step: 11
Training loss: 2.596302032470703
Validation loss: 2.133154115369243

Epoch: 6| Step: 12
Training loss: 3.0589895248413086
Validation loss: 2.138268514346051

Epoch: 6| Step: 13
Training loss: 2.401987314224243
Validation loss: 2.135286492686118

Epoch: 92| Step: 0
Training loss: 2.882411003112793
Validation loss: 2.133173478546963

Epoch: 6| Step: 1
Training loss: 2.479926109313965
Validation loss: 2.1285924732044177

Epoch: 6| Step: 2
Training loss: 2.064699649810791
Validation loss: 2.126452704911591

Epoch: 6| Step: 3
Training loss: 2.2817578315734863
Validation loss: 2.122039379612092

Epoch: 6| Step: 4
Training loss: 2.8480589389801025
Validation loss: 2.1263591858648483

Epoch: 6| Step: 5
Training loss: 2.4427602291107178
Validation loss: 2.1335846916321786

Epoch: 6| Step: 6
Training loss: 2.5728659629821777
Validation loss: 2.1477718763453986

Epoch: 6| Step: 7
Training loss: 2.677173376083374
Validation loss: 2.158584416553538

Epoch: 6| Step: 8
Training loss: 2.707674503326416
Validation loss: 2.1747763900346655

Epoch: 6| Step: 9
Training loss: 2.3868279457092285
Validation loss: 2.184843264600282

Epoch: 6| Step: 10
Training loss: 2.234684944152832
Validation loss: 2.197814122323067

Epoch: 6| Step: 11
Training loss: 2.1341171264648438
Validation loss: 2.2193106938433904

Epoch: 6| Step: 12
Training loss: 1.7503836154937744
Validation loss: 2.213168877427296

Epoch: 6| Step: 13
Training loss: 3.098621368408203
Validation loss: 2.2210541258576098

Epoch: 93| Step: 0
Training loss: 2.2643306255340576
Validation loss: 2.2252094181635047

Epoch: 6| Step: 1
Training loss: 2.319389820098877
Validation loss: 2.2086393692160167

Epoch: 6| Step: 2
Training loss: 2.2650012969970703
Validation loss: 2.204984447007538

Epoch: 6| Step: 3
Training loss: 2.073802947998047
Validation loss: 2.1867828984414377

Epoch: 6| Step: 4
Training loss: 2.437723159790039
Validation loss: 2.1812369951637844

Epoch: 6| Step: 5
Training loss: 2.889909029006958
Validation loss: 2.17797940264466

Epoch: 6| Step: 6
Training loss: 2.4446496963500977
Validation loss: 2.1703805744007068

Epoch: 6| Step: 7
Training loss: 2.6343724727630615
Validation loss: 2.174635684618386

Epoch: 6| Step: 8
Training loss: 2.4153213500976562
Validation loss: 2.170619713362827

Epoch: 6| Step: 9
Training loss: 3.335819721221924
Validation loss: 2.1643610692793325

Epoch: 6| Step: 10
Training loss: 1.5362049341201782
Validation loss: 2.1638775512736332

Epoch: 6| Step: 11
Training loss: 3.050158739089966
Validation loss: 2.1618190093707015

Epoch: 6| Step: 12
Training loss: 2.348358154296875
Validation loss: 2.1521450499052643

Epoch: 6| Step: 13
Training loss: 2.168362617492676
Validation loss: 2.145711306602724

Epoch: 94| Step: 0
Training loss: 2.6857500076293945
Validation loss: 2.145063578441579

Epoch: 6| Step: 1
Training loss: 2.484992265701294
Validation loss: 2.151721521090436

Epoch: 6| Step: 2
Training loss: 2.354836940765381
Validation loss: 2.1683408932019304

Epoch: 6| Step: 3
Training loss: 2.1634373664855957
Validation loss: 2.2135149945494947

Epoch: 6| Step: 4
Training loss: 2.068376064300537
Validation loss: 2.238643987204439

Epoch: 6| Step: 5
Training loss: 2.672196388244629
Validation loss: 2.240361463639044

Epoch: 6| Step: 6
Training loss: 2.716864824295044
Validation loss: 2.2316311508096676

Epoch: 6| Step: 7
Training loss: 2.996845245361328
Validation loss: 2.228353956694244

Epoch: 6| Step: 8
Training loss: 2.082914352416992
Validation loss: 2.1835912914686304

Epoch: 6| Step: 9
Training loss: 1.97688627243042
Validation loss: 2.1612313742278726

Epoch: 6| Step: 10
Training loss: 2.9780731201171875
Validation loss: 2.141312758127848

Epoch: 6| Step: 11
Training loss: 2.349663257598877
Validation loss: 2.1325124181726927

Epoch: 6| Step: 12
Training loss: 2.093639850616455
Validation loss: 2.1368874452447377

Epoch: 6| Step: 13
Training loss: 2.573932409286499
Validation loss: 2.137770429734261

Epoch: 95| Step: 0
Training loss: 2.6274309158325195
Validation loss: 2.1339987554857807

Epoch: 6| Step: 1
Training loss: 2.3032641410827637
Validation loss: 2.1318368963015977

Epoch: 6| Step: 2
Training loss: 2.7353665828704834
Validation loss: 2.1271819350539998

Epoch: 6| Step: 3
Training loss: 2.4460527896881104
Validation loss: 2.1326100749354207

Epoch: 6| Step: 4
Training loss: 2.38055157661438
Validation loss: 2.1389033153492916

Epoch: 6| Step: 5
Training loss: 1.8973259925842285
Validation loss: 2.149378776550293

Epoch: 6| Step: 6
Training loss: 2.1476564407348633
Validation loss: 2.15178277415614

Epoch: 6| Step: 7
Training loss: 1.9605906009674072
Validation loss: 2.150821280735795

Epoch: 6| Step: 8
Training loss: 2.284297466278076
Validation loss: 2.153000609849089

Epoch: 6| Step: 9
Training loss: 2.731534481048584
Validation loss: 2.1576140670366186

Epoch: 6| Step: 10
Training loss: 3.053980827331543
Validation loss: 2.154758431578195

Epoch: 6| Step: 11
Training loss: 2.4974968433380127
Validation loss: 2.1371603063357774

Epoch: 6| Step: 12
Training loss: 2.6847879886627197
Validation loss: 2.1353679549309517

Epoch: 6| Step: 13
Training loss: 2.279627799987793
Validation loss: 2.1280626199578725

Epoch: 96| Step: 0
Training loss: 1.9922759532928467
Validation loss: 2.126293424637087

Epoch: 6| Step: 1
Training loss: 2.3050103187561035
Validation loss: 2.1206537818395965

Epoch: 6| Step: 2
Training loss: 2.2963500022888184
Validation loss: 2.128814415265155

Epoch: 6| Step: 3
Training loss: 2.607679605484009
Validation loss: 2.1213369754052933

Epoch: 6| Step: 4
Training loss: 2.753196954727173
Validation loss: 2.1272880954127156

Epoch: 6| Step: 5
Training loss: 2.129777669906616
Validation loss: 2.1289824926725

Epoch: 6| Step: 6
Training loss: 2.6538023948669434
Validation loss: 2.1400476437742992

Epoch: 6| Step: 7
Training loss: 2.4010772705078125
Validation loss: 2.140943358021398

Epoch: 6| Step: 8
Training loss: 2.720642566680908
Validation loss: 2.1353157592076126

Epoch: 6| Step: 9
Training loss: 2.7939772605895996
Validation loss: 2.1294817975772324

Epoch: 6| Step: 10
Training loss: 3.138180732727051
Validation loss: 2.1253535747528076

Epoch: 6| Step: 11
Training loss: 1.7462159395217896
Validation loss: 2.125176188766315

Epoch: 6| Step: 12
Training loss: 2.426042079925537
Validation loss: 2.1202032002069617

Epoch: 6| Step: 13
Training loss: 1.7279906272888184
Validation loss: 2.1165297621039936

Epoch: 97| Step: 0
Training loss: 2.397634744644165
Validation loss: 2.1146096106498473

Epoch: 6| Step: 1
Training loss: 2.583277702331543
Validation loss: 2.1084901004709224

Epoch: 6| Step: 2
Training loss: 2.1847972869873047
Validation loss: 2.1130806669112174

Epoch: 6| Step: 3
Training loss: 1.8241825103759766
Validation loss: 2.1184949208331365

Epoch: 6| Step: 4
Training loss: 2.237786293029785
Validation loss: 2.114321570242605

Epoch: 6| Step: 5
Training loss: 2.7447571754455566
Validation loss: 2.1217939751122588

Epoch: 6| Step: 6
Training loss: 2.5560483932495117
Validation loss: 2.114177442366077

Epoch: 6| Step: 7
Training loss: 1.9273678064346313
Validation loss: 2.107293878832171

Epoch: 6| Step: 8
Training loss: 2.6050562858581543
Validation loss: 2.1123161469736407

Epoch: 6| Step: 9
Training loss: 2.259732961654663
Validation loss: 2.123866073546871

Epoch: 6| Step: 10
Training loss: 2.97346830368042
Validation loss: 2.1336265533201155

Epoch: 6| Step: 11
Training loss: 2.432675838470459
Validation loss: 2.1188014937985327

Epoch: 6| Step: 12
Training loss: 2.8923254013061523
Validation loss: 2.11479841509173

Epoch: 6| Step: 13
Training loss: 2.0639355182647705
Validation loss: 2.1047265888542257

Epoch: 98| Step: 0
Training loss: 1.5611648559570312
Validation loss: 2.0969372180200394

Epoch: 6| Step: 1
Training loss: 2.5205912590026855
Validation loss: 2.094424145196074

Epoch: 6| Step: 2
Training loss: 2.4377315044403076
Validation loss: 2.0972694761009625

Epoch: 6| Step: 3
Training loss: 1.6925675868988037
Validation loss: 2.0934790718939995

Epoch: 6| Step: 4
Training loss: 2.669240951538086
Validation loss: 2.0963177270786737

Epoch: 6| Step: 5
Training loss: 2.4865710735321045
Validation loss: 2.0985809487681233

Epoch: 6| Step: 6
Training loss: 2.4310214519500732
Validation loss: 2.1059930093826784

Epoch: 6| Step: 7
Training loss: 2.3995144367218018
Validation loss: 2.1144748938980924

Epoch: 6| Step: 8
Training loss: 2.4234609603881836
Validation loss: 2.1237949466192596

Epoch: 6| Step: 9
Training loss: 2.7071940898895264
Validation loss: 2.140835487714378

Epoch: 6| Step: 10
Training loss: 2.8361082077026367
Validation loss: 2.1152219644156833

Epoch: 6| Step: 11
Training loss: 2.4327216148376465
Validation loss: 2.113978329525199

Epoch: 6| Step: 12
Training loss: 2.3709099292755127
Validation loss: 2.1082302114014984

Epoch: 6| Step: 13
Training loss: 3.0392847061157227
Validation loss: 2.0948476817018244

Epoch: 99| Step: 0
Training loss: 1.6546854972839355
Validation loss: 2.0897649065140755

Epoch: 6| Step: 1
Training loss: 2.4388856887817383
Validation loss: 2.0880068168845227

Epoch: 6| Step: 2
Training loss: 2.0329456329345703
Validation loss: 2.083957361918624

Epoch: 6| Step: 3
Training loss: 2.3148369789123535
Validation loss: 2.0831656712357716

Epoch: 6| Step: 4
Training loss: 1.9390318393707275
Validation loss: 2.0871717993931105

Epoch: 6| Step: 5
Training loss: 3.01495099067688
Validation loss: 2.079873082458332

Epoch: 6| Step: 6
Training loss: 2.354447841644287
Validation loss: 2.081609945143423

Epoch: 6| Step: 7
Training loss: 2.363332986831665
Validation loss: 2.086277174693282

Epoch: 6| Step: 8
Training loss: 2.633153200149536
Validation loss: 2.0898615519205728

Epoch: 6| Step: 9
Training loss: 2.677135467529297
Validation loss: 2.102933261984138

Epoch: 6| Step: 10
Training loss: 2.736557960510254
Validation loss: 2.10357073045546

Epoch: 6| Step: 11
Training loss: 2.9425530433654785
Validation loss: 2.1190298552154214

Epoch: 6| Step: 12
Training loss: 2.102708339691162
Validation loss: 2.134761587265999

Epoch: 6| Step: 13
Training loss: 2.4396703243255615
Validation loss: 2.143738523606331

Epoch: 100| Step: 0
Training loss: 1.9187800884246826
Validation loss: 2.1426930940279396

Epoch: 6| Step: 1
Training loss: 2.0770673751831055
Validation loss: 2.1522279964980258

Epoch: 6| Step: 2
Training loss: 2.805859088897705
Validation loss: 2.1405235669946157

Epoch: 6| Step: 3
Training loss: 2.4201242923736572
Validation loss: 2.1153576015144266

Epoch: 6| Step: 4
Training loss: 1.9207539558410645
Validation loss: 2.0994181876541465

Epoch: 6| Step: 5
Training loss: 2.6521122455596924
Validation loss: 2.094380783778365

Epoch: 6| Step: 6
Training loss: 3.2990059852600098
Validation loss: 2.091175745892268

Epoch: 6| Step: 7
Training loss: 2.9791808128356934
Validation loss: 2.087574694746284

Epoch: 6| Step: 8
Training loss: 2.0221660137176514
Validation loss: 2.0950004362290904

Epoch: 6| Step: 9
Training loss: 2.3046364784240723
Validation loss: 2.0949067415729647

Epoch: 6| Step: 10
Training loss: 1.99184250831604
Validation loss: 2.0943364071589645

Epoch: 6| Step: 11
Training loss: 2.3573455810546875
Validation loss: 2.096869566107309

Epoch: 6| Step: 12
Training loss: 2.6900455951690674
Validation loss: 2.0986180728481663

Epoch: 6| Step: 13
Training loss: 2.3097147941589355
Validation loss: 2.092932842111075

Epoch: 101| Step: 0
Training loss: 3.110841751098633
Validation loss: 2.1048719306145944

Epoch: 6| Step: 1
Training loss: 2.372162103652954
Validation loss: 2.1171301129043743

Epoch: 6| Step: 2
Training loss: 2.2744593620300293
Validation loss: 2.130034474916356

Epoch: 6| Step: 3
Training loss: 3.1548995971679688
Validation loss: 2.14519142335461

Epoch: 6| Step: 4
Training loss: 2.3519883155822754
Validation loss: 2.159849819316659

Epoch: 6| Step: 5
Training loss: 2.062288761138916
Validation loss: 2.188765387381277

Epoch: 6| Step: 6
Training loss: 2.1692638397216797
Validation loss: 2.1858106351667836

Epoch: 6| Step: 7
Training loss: 2.0070223808288574
Validation loss: 2.178995204228227

Epoch: 6| Step: 8
Training loss: 1.8744456768035889
Validation loss: 2.167978104724679

Epoch: 6| Step: 9
Training loss: 3.01938533782959
Validation loss: 2.1367925546502553

Epoch: 6| Step: 10
Training loss: 2.347968339920044
Validation loss: 2.1120276117837555

Epoch: 6| Step: 11
Training loss: 2.4990620613098145
Validation loss: 2.0996879916037283

Epoch: 6| Step: 12
Training loss: 2.0567808151245117
Validation loss: 2.0839851953650035

Epoch: 6| Step: 13
Training loss: 2.383376121520996
Validation loss: 2.0892089515604

Epoch: 102| Step: 0
Training loss: 2.419959783554077
Validation loss: 2.098184859880837

Epoch: 6| Step: 1
Training loss: 2.4959802627563477
Validation loss: 2.0994970926674466

Epoch: 6| Step: 2
Training loss: 2.477019786834717
Validation loss: 2.1013244326396654

Epoch: 6| Step: 3
Training loss: 2.095306396484375
Validation loss: 2.094568761446143

Epoch: 6| Step: 4
Training loss: 2.326042890548706
Validation loss: 2.0819102743620514

Epoch: 6| Step: 5
Training loss: 2.5856399536132812
Validation loss: 2.0916138387495473

Epoch: 6| Step: 6
Training loss: 2.4090614318847656
Validation loss: 2.100440299639138

Epoch: 6| Step: 7
Training loss: 2.469182014465332
Validation loss: 2.1129826653388237

Epoch: 6| Step: 8
Training loss: 2.460339069366455
Validation loss: 2.1046436691796906

Epoch: 6| Step: 9
Training loss: 2.841817855834961
Validation loss: 2.1055869902333906

Epoch: 6| Step: 10
Training loss: 2.1639745235443115
Validation loss: 2.113467234437184

Epoch: 6| Step: 11
Training loss: 2.361285924911499
Validation loss: 2.1028560566645798

Epoch: 6| Step: 12
Training loss: 2.435570001602173
Validation loss: 2.09378711382548

Epoch: 6| Step: 13
Training loss: 1.538475751876831
Validation loss: 2.0921570485638035

Epoch: 103| Step: 0
Training loss: 2.734471082687378
Validation loss: 2.100603602265799

Epoch: 6| Step: 1
Training loss: 2.3157970905303955
Validation loss: 2.104373114083403

Epoch: 6| Step: 2
Training loss: 1.7917535305023193
Validation loss: 2.116558890188894

Epoch: 6| Step: 3
Training loss: 3.634979248046875
Validation loss: 2.1084649844836165

Epoch: 6| Step: 4
Training loss: 1.3940865993499756
Validation loss: 2.0976384096248175

Epoch: 6| Step: 5
Training loss: 2.7254135608673096
Validation loss: 2.0968710812189246

Epoch: 6| Step: 6
Training loss: 2.257570266723633
Validation loss: 2.087479245278143

Epoch: 6| Step: 7
Training loss: 1.963263750076294
Validation loss: 2.0877418056611092

Epoch: 6| Step: 8
Training loss: 2.008977174758911
Validation loss: 2.0859894893502675

Epoch: 6| Step: 9
Training loss: 1.9795854091644287
Validation loss: 2.081513653519333

Epoch: 6| Step: 10
Training loss: 2.9675378799438477
Validation loss: 2.0855825818994993

Epoch: 6| Step: 11
Training loss: 3.1431632041931152
Validation loss: 2.0836926916594147

Epoch: 6| Step: 12
Training loss: 1.703307867050171
Validation loss: 2.09299902249408

Epoch: 6| Step: 13
Training loss: 2.99536395072937
Validation loss: 2.08197513703377

Epoch: 104| Step: 0
Training loss: 1.9146769046783447
Validation loss: 2.082100922061551

Epoch: 6| Step: 1
Training loss: 2.6001882553100586
Validation loss: 2.0676652744252193

Epoch: 6| Step: 2
Training loss: 2.2439701557159424
Validation loss: 2.06513056191065

Epoch: 6| Step: 3
Training loss: 2.512944221496582
Validation loss: 2.0695681200232556

Epoch: 6| Step: 4
Training loss: 1.9808223247528076
Validation loss: 2.072214739297026

Epoch: 6| Step: 5
Training loss: 3.094226837158203
Validation loss: 2.0749789361030824

Epoch: 6| Step: 6
Training loss: 1.602881908416748
Validation loss: 2.066750172645815

Epoch: 6| Step: 7
Training loss: 2.7097930908203125
Validation loss: 2.070820845583434

Epoch: 6| Step: 8
Training loss: 2.406402111053467
Validation loss: 2.0905796712444675

Epoch: 6| Step: 9
Training loss: 2.541008949279785
Validation loss: 2.1016678681937595

Epoch: 6| Step: 10
Training loss: 2.4940285682678223
Validation loss: 2.142335832759898

Epoch: 6| Step: 11
Training loss: 2.847102642059326
Validation loss: 2.170723230608048

Epoch: 6| Step: 12
Training loss: 1.8654450178146362
Validation loss: 2.1485923900399158

Epoch: 6| Step: 13
Training loss: 2.71136474609375
Validation loss: 2.132330304832869

Epoch: 105| Step: 0
Training loss: 1.7835917472839355
Validation loss: 2.1072931571673323

Epoch: 6| Step: 1
Training loss: 3.4051647186279297
Validation loss: 2.069534186393984

Epoch: 6| Step: 2
Training loss: 2.1799004077911377
Validation loss: 2.064823358289657

Epoch: 6| Step: 3
Training loss: 2.6838390827178955
Validation loss: 2.061185917546672

Epoch: 6| Step: 4
Training loss: 2.338754177093506
Validation loss: 2.076666506387854

Epoch: 6| Step: 5
Training loss: 2.33225679397583
Validation loss: 2.084173761388307

Epoch: 6| Step: 6
Training loss: 2.4581637382507324
Validation loss: 2.0762373529454714

Epoch: 6| Step: 7
Training loss: 2.0422372817993164
Validation loss: 2.0651089901565225

Epoch: 6| Step: 8
Training loss: 3.1135220527648926
Validation loss: 2.0648877518151396

Epoch: 6| Step: 9
Training loss: 1.7481876611709595
Validation loss: 2.0652739591495965

Epoch: 6| Step: 10
Training loss: 2.8566043376922607
Validation loss: 2.058800058980142

Epoch: 6| Step: 11
Training loss: 2.1271800994873047
Validation loss: 2.0736056540601995

Epoch: 6| Step: 12
Training loss: 2.5808675289154053
Validation loss: 2.0915831494074997

Epoch: 6| Step: 13
Training loss: 1.4603146314620972
Validation loss: 2.106355441513882

Epoch: 106| Step: 0
Training loss: 2.4731369018554688
Validation loss: 2.0872182961433166

Epoch: 6| Step: 1
Training loss: 1.9974443912506104
Validation loss: 2.0808999820422103

Epoch: 6| Step: 2
Training loss: 2.5005955696105957
Validation loss: 2.0773422436047624

Epoch: 6| Step: 3
Training loss: 1.97446608543396
Validation loss: 2.0644584804452877

Epoch: 6| Step: 4
Training loss: 2.677273750305176
Validation loss: 2.0653560879409953

Epoch: 6| Step: 5
Training loss: 2.3917858600616455
Validation loss: 2.060256281206685

Epoch: 6| Step: 6
Training loss: 1.5449308156967163
Validation loss: 2.0638711747302803

Epoch: 6| Step: 7
Training loss: 2.280087947845459
Validation loss: 2.050681109069496

Epoch: 6| Step: 8
Training loss: 2.4565138816833496
Validation loss: 2.0487117369969687

Epoch: 6| Step: 9
Training loss: 2.6648409366607666
Validation loss: 2.05785640593498

Epoch: 6| Step: 10
Training loss: 2.5309877395629883
Validation loss: 2.0477399210776053

Epoch: 6| Step: 11
Training loss: 2.5010769367218018
Validation loss: 2.0476329275356826

Epoch: 6| Step: 12
Training loss: 2.582639455795288
Validation loss: 2.0560568468545073

Epoch: 6| Step: 13
Training loss: 3.149219512939453
Validation loss: 2.0555379826535463

Epoch: 107| Step: 0
Training loss: 2.028580904006958
Validation loss: 2.06082433654416

Epoch: 6| Step: 1
Training loss: 2.2145838737487793
Validation loss: 2.0472918684764574

Epoch: 6| Step: 2
Training loss: 2.00777530670166
Validation loss: 2.0480792471157607

Epoch: 6| Step: 3
Training loss: 2.4276161193847656
Validation loss: 2.0553448097680205

Epoch: 6| Step: 4
Training loss: 2.0160739421844482
Validation loss: 2.0555034811778734

Epoch: 6| Step: 5
Training loss: 2.757227659225464
Validation loss: 2.0623714206039265

Epoch: 6| Step: 6
Training loss: 2.3597049713134766
Validation loss: 2.0613797544151224

Epoch: 6| Step: 7
Training loss: 2.457253932952881
Validation loss: 2.0773620118377027

Epoch: 6| Step: 8
Training loss: 2.193488359451294
Validation loss: 2.101363174376949

Epoch: 6| Step: 9
Training loss: 3.076852560043335
Validation loss: 2.125690251268366

Epoch: 6| Step: 10
Training loss: 2.277278423309326
Validation loss: 2.1533221352484917

Epoch: 6| Step: 11
Training loss: 2.633671522140503
Validation loss: 2.129502929666991

Epoch: 6| Step: 12
Training loss: 2.604696273803711
Validation loss: 2.067735433578491

Epoch: 6| Step: 13
Training loss: 2.046509265899658
Validation loss: 2.039762512330086

Epoch: 108| Step: 0
Training loss: 2.7301669120788574
Validation loss: 2.0654297426182735

Epoch: 6| Step: 1
Training loss: 2.2655489444732666
Validation loss: 2.074160414357339

Epoch: 6| Step: 2
Training loss: 2.5987725257873535
Validation loss: 2.0827772078975553

Epoch: 6| Step: 3
Training loss: 2.0588812828063965
Validation loss: 2.098123094087006

Epoch: 6| Step: 4
Training loss: 2.91960072517395
Validation loss: 2.105953508807767

Epoch: 6| Step: 5
Training loss: 2.4043350219726562
Validation loss: 2.1049031185847458

Epoch: 6| Step: 6
Training loss: 2.876234531402588
Validation loss: 2.088463029553813

Epoch: 6| Step: 7
Training loss: 2.5833358764648438
Validation loss: 2.1004686893955355

Epoch: 6| Step: 8
Training loss: 2.475955009460449
Validation loss: 2.092262501357704

Epoch: 6| Step: 9
Training loss: 1.5361015796661377
Validation loss: 2.095656474431356

Epoch: 6| Step: 10
Training loss: 2.1253275871276855
Validation loss: 2.0954088344368884

Epoch: 6| Step: 11
Training loss: 2.3465898036956787
Validation loss: 2.085619754688714

Epoch: 6| Step: 12
Training loss: 2.9991133213043213
Validation loss: 2.0789812123903664

Epoch: 6| Step: 13
Training loss: 1.903597354888916
Validation loss: 2.080045520618398

Epoch: 109| Step: 0
Training loss: 2.489854335784912
Validation loss: 2.0668444787302325

Epoch: 6| Step: 1
Training loss: 2.697497606277466
Validation loss: 2.0706685794297086

Epoch: 6| Step: 2
Training loss: 2.8437886238098145
Validation loss: 2.0782077799561205

Epoch: 6| Step: 3
Training loss: 2.2481350898742676
Validation loss: 2.0743811258705716

Epoch: 6| Step: 4
Training loss: 2.06429386138916
Validation loss: 2.063620654485559

Epoch: 6| Step: 5
Training loss: 1.9021260738372803
Validation loss: 2.067793070629079

Epoch: 6| Step: 6
Training loss: 2.24515962600708
Validation loss: 2.0692424825442735

Epoch: 6| Step: 7
Training loss: 2.770291328430176
Validation loss: 2.074025100277316

Epoch: 6| Step: 8
Training loss: 2.4825072288513184
Validation loss: 2.094815941267116

Epoch: 6| Step: 9
Training loss: 2.3746204376220703
Validation loss: 2.0831577880408174

Epoch: 6| Step: 10
Training loss: 1.904973030090332
Validation loss: 2.08175487672129

Epoch: 6| Step: 11
Training loss: 2.7471699714660645
Validation loss: 2.0664667109007477

Epoch: 6| Step: 12
Training loss: 2.0078604221343994
Validation loss: 2.062458453639861

Epoch: 6| Step: 13
Training loss: 2.692655324935913
Validation loss: 2.058149007058913

Epoch: 110| Step: 0
Training loss: 2.1600711345672607
Validation loss: 2.0535640075642574

Epoch: 6| Step: 1
Training loss: 2.03312087059021
Validation loss: 2.0537166364731325

Epoch: 6| Step: 2
Training loss: 2.8298239707946777
Validation loss: 2.0725946246936755

Epoch: 6| Step: 3
Training loss: 2.314980983734131
Validation loss: 2.0814040707003687

Epoch: 6| Step: 4
Training loss: 2.005937337875366
Validation loss: 2.0923025608062744

Epoch: 6| Step: 5
Training loss: 2.474945545196533
Validation loss: 2.1021731604811964

Epoch: 6| Step: 6
Training loss: 3.2960257530212402
Validation loss: 2.081565095532325

Epoch: 6| Step: 7
Training loss: 1.7467964887619019
Validation loss: 2.081774991045716

Epoch: 6| Step: 8
Training loss: 2.730177879333496
Validation loss: 2.073166840819902

Epoch: 6| Step: 9
Training loss: 2.2283170223236084
Validation loss: 2.0670235990196146

Epoch: 6| Step: 10
Training loss: 2.62803316116333
Validation loss: 2.0476699913701704

Epoch: 6| Step: 11
Training loss: 2.6580944061279297
Validation loss: 2.041475513929962

Epoch: 6| Step: 12
Training loss: 2.1026763916015625
Validation loss: 2.0361180100389706

Epoch: 6| Step: 13
Training loss: 1.5570712089538574
Validation loss: 2.043153942272227

Epoch: 111| Step: 0
Training loss: 2.606189250946045
Validation loss: 2.0365281592133226

Epoch: 6| Step: 1
Training loss: 2.7203357219696045
Validation loss: 2.0422508921674503

Epoch: 6| Step: 2
Training loss: 1.8759565353393555
Validation loss: 2.0366160138960807

Epoch: 6| Step: 3
Training loss: 1.9247007369995117
Validation loss: 2.039614613338183

Epoch: 6| Step: 4
Training loss: 2.38313627243042
Validation loss: 2.0384618223354383

Epoch: 6| Step: 5
Training loss: 2.2240793704986572
Validation loss: 2.032323678334554

Epoch: 6| Step: 6
Training loss: 2.4087700843811035
Validation loss: 2.0636962024114465

Epoch: 6| Step: 7
Training loss: 2.1807899475097656
Validation loss: 2.08483822115006

Epoch: 6| Step: 8
Training loss: 2.477522373199463
Validation loss: 2.1173493913424912

Epoch: 6| Step: 9
Training loss: 2.6052653789520264
Validation loss: 2.146473712818597

Epoch: 6| Step: 10
Training loss: 1.91273832321167
Validation loss: 2.1456447878191547

Epoch: 6| Step: 11
Training loss: 2.634917736053467
Validation loss: 2.138870187985

Epoch: 6| Step: 12
Training loss: 2.6805930137634277
Validation loss: 2.116538106754262

Epoch: 6| Step: 13
Training loss: 2.489136219024658
Validation loss: 2.114555231986507

Epoch: 112| Step: 0
Training loss: 2.13021183013916
Validation loss: 2.0829230713587936

Epoch: 6| Step: 1
Training loss: 1.7885472774505615
Validation loss: 2.05782990301809

Epoch: 6| Step: 2
Training loss: 1.9258383512496948
Validation loss: 2.0406690130951586

Epoch: 6| Step: 3
Training loss: 2.8114852905273438
Validation loss: 2.033120201480004

Epoch: 6| Step: 4
Training loss: 2.497800827026367
Validation loss: 2.042316923859299

Epoch: 6| Step: 5
Training loss: 2.1266403198242188
Validation loss: 2.0470554649188952

Epoch: 6| Step: 6
Training loss: 2.150886058807373
Validation loss: 2.0394305644496793

Epoch: 6| Step: 7
Training loss: 2.729201316833496
Validation loss: 2.0459420911727415

Epoch: 6| Step: 8
Training loss: 1.7040672302246094
Validation loss: 2.038055899322674

Epoch: 6| Step: 9
Training loss: 3.192162036895752
Validation loss: 2.0418470649309057

Epoch: 6| Step: 10
Training loss: 2.37934947013855
Validation loss: 2.0525450796209355

Epoch: 6| Step: 11
Training loss: 2.8836569786071777
Validation loss: 2.070635332856127

Epoch: 6| Step: 12
Training loss: 2.364713668823242
Validation loss: 2.0638577489442724

Epoch: 6| Step: 13
Training loss: 2.3864166736602783
Validation loss: 2.086578047403725

Epoch: 113| Step: 0
Training loss: 1.6779067516326904
Validation loss: 2.116372245614247

Epoch: 6| Step: 1
Training loss: 2.4413223266601562
Validation loss: 2.1243071248454433

Epoch: 6| Step: 2
Training loss: 2.551093101501465
Validation loss: 2.1359831594651744

Epoch: 6| Step: 3
Training loss: 2.1636757850646973
Validation loss: 2.113781767506753

Epoch: 6| Step: 4
Training loss: 2.8561291694641113
Validation loss: 2.1084743212628108

Epoch: 6| Step: 5
Training loss: 2.3561811447143555
Validation loss: 2.0696317688111336

Epoch: 6| Step: 6
Training loss: 2.2063000202178955
Validation loss: 2.0409040489504413

Epoch: 6| Step: 7
Training loss: 2.267322063446045
Validation loss: 2.037400181575488

Epoch: 6| Step: 8
Training loss: 3.152130365371704
Validation loss: 2.0433363068488335

Epoch: 6| Step: 9
Training loss: 2.2307236194610596
Validation loss: 2.033375924633395

Epoch: 6| Step: 10
Training loss: 1.7421274185180664
Validation loss: 2.037470409947057

Epoch: 6| Step: 11
Training loss: 2.579643726348877
Validation loss: 2.032565047664027

Epoch: 6| Step: 12
Training loss: 2.6747329235076904
Validation loss: 2.0310493464111

Epoch: 6| Step: 13
Training loss: 2.224256753921509
Validation loss: 2.0276202168515933

Epoch: 114| Step: 0
Training loss: 2.334855556488037
Validation loss: 2.0347571270440215

Epoch: 6| Step: 1
Training loss: 1.9582579135894775
Validation loss: 2.0466827218250563

Epoch: 6| Step: 2
Training loss: 2.6362624168395996
Validation loss: 2.092370815174554

Epoch: 6| Step: 3
Training loss: 1.8130805492401123
Validation loss: 2.10353389991227

Epoch: 6| Step: 4
Training loss: 2.930812358856201
Validation loss: 2.1139854231188373

Epoch: 6| Step: 5
Training loss: 2.329097032546997
Validation loss: 2.132006755439184

Epoch: 6| Step: 6
Training loss: 1.8313477039337158
Validation loss: 2.108782087602923

Epoch: 6| Step: 7
Training loss: 1.9680073261260986
Validation loss: 2.100998665696831

Epoch: 6| Step: 8
Training loss: 2.3963074684143066
Validation loss: 2.085585114776447

Epoch: 6| Step: 9
Training loss: 2.571805238723755
Validation loss: 2.0646720394011466

Epoch: 6| Step: 10
Training loss: 2.250383138656616
Validation loss: 2.0355442595738236

Epoch: 6| Step: 11
Training loss: 3.042818069458008
Validation loss: 2.0442091418850805

Epoch: 6| Step: 12
Training loss: 2.287925958633423
Validation loss: 2.0416536241449337

Epoch: 6| Step: 13
Training loss: 2.635007858276367
Validation loss: 2.036676565806071

Epoch: 115| Step: 0
Training loss: 2.3828206062316895
Validation loss: 2.0436470136847547

Epoch: 6| Step: 1
Training loss: 2.5670835971832275
Validation loss: 2.039492291788901

Epoch: 6| Step: 2
Training loss: 2.127873659133911
Validation loss: 2.034754086566228

Epoch: 6| Step: 3
Training loss: 2.2398452758789062
Validation loss: 2.031093165438662

Epoch: 6| Step: 4
Training loss: 2.40653395652771
Validation loss: 2.0255225191834154

Epoch: 6| Step: 5
Training loss: 2.3802170753479004
Validation loss: 2.030205043413306

Epoch: 6| Step: 6
Training loss: 2.6476480960845947
Validation loss: 2.0221248185762795

Epoch: 6| Step: 7
Training loss: 2.0260214805603027
Validation loss: 2.024503118248396

Epoch: 6| Step: 8
Training loss: 2.0833377838134766
Validation loss: 2.015937146320138

Epoch: 6| Step: 9
Training loss: 2.9230270385742188
Validation loss: 2.047279629656064

Epoch: 6| Step: 10
Training loss: 2.1026439666748047
Validation loss: 2.098993270627914

Epoch: 6| Step: 11
Training loss: 1.8207128047943115
Validation loss: 2.114435757360151

Epoch: 6| Step: 12
Training loss: 2.7032265663146973
Validation loss: 2.113249453165198

Epoch: 6| Step: 13
Training loss: 2.2712764739990234
Validation loss: 2.1224352108534945

Epoch: 116| Step: 0
Training loss: 2.438786506652832
Validation loss: 2.1286074679384948

Epoch: 6| Step: 1
Training loss: 2.6748404502868652
Validation loss: 2.127677232988419

Epoch: 6| Step: 2
Training loss: 2.7775473594665527
Validation loss: 2.1170047354954544

Epoch: 6| Step: 3
Training loss: 2.5609312057495117
Validation loss: 2.1055052485517276

Epoch: 6| Step: 4
Training loss: 2.497718334197998
Validation loss: 2.0834002340993574

Epoch: 6| Step: 5
Training loss: 2.4603307247161865
Validation loss: 2.0566773158247753

Epoch: 6| Step: 6
Training loss: 2.5560226440429688
Validation loss: 2.042758672468124

Epoch: 6| Step: 7
Training loss: 1.9534428119659424
Validation loss: 2.0403191274212253

Epoch: 6| Step: 8
Training loss: 1.9768335819244385
Validation loss: 2.032518939305377

Epoch: 6| Step: 9
Training loss: 1.8037183284759521
Validation loss: 2.0318764409711285

Epoch: 6| Step: 10
Training loss: 2.4822492599487305
Validation loss: 2.0426526505460023

Epoch: 6| Step: 11
Training loss: 1.8635762929916382
Validation loss: 2.0372141458654918

Epoch: 6| Step: 12
Training loss: 2.37161922454834
Validation loss: 2.030423670686701

Epoch: 6| Step: 13
Training loss: 2.743650197982788
Validation loss: 2.017789661243398

Epoch: 117| Step: 0
Training loss: 2.2856829166412354
Validation loss: 2.016395479120234

Epoch: 6| Step: 1
Training loss: 2.6359453201293945
Validation loss: 2.016209222937143

Epoch: 6| Step: 2
Training loss: 2.336209297180176
Validation loss: 2.0102375591954877

Epoch: 6| Step: 3
Training loss: 1.5772576332092285
Validation loss: 2.0247935428414294

Epoch: 6| Step: 4
Training loss: 2.7975010871887207
Validation loss: 2.0248953578292683

Epoch: 6| Step: 5
Training loss: 2.0691566467285156
Validation loss: 2.0309167420992287

Epoch: 6| Step: 6
Training loss: 2.275360107421875
Validation loss: 2.06319288797276

Epoch: 6| Step: 7
Training loss: 2.2131612300872803
Validation loss: 2.06618659727035

Epoch: 6| Step: 8
Training loss: 1.8503096103668213
Validation loss: 2.0800960448480423

Epoch: 6| Step: 9
Training loss: 2.4372732639312744
Validation loss: 2.1189453832564817

Epoch: 6| Step: 10
Training loss: 2.7206859588623047
Validation loss: 2.1136863000931276

Epoch: 6| Step: 11
Training loss: 2.9576547145843506
Validation loss: 2.1013236738020376

Epoch: 6| Step: 12
Training loss: 2.2987852096557617
Validation loss: 2.047693811437135

Epoch: 6| Step: 13
Training loss: 2.26466703414917
Validation loss: 2.019967932854929

Epoch: 118| Step: 0
Training loss: 1.8892054557800293
Validation loss: 2.0122339123038837

Epoch: 6| Step: 1
Training loss: 1.3944792747497559
Validation loss: 2.0245318182053103

Epoch: 6| Step: 2
Training loss: 2.602257013320923
Validation loss: 2.0169731417009906

Epoch: 6| Step: 3
Training loss: 2.2858328819274902
Validation loss: 2.011817988529

Epoch: 6| Step: 4
Training loss: 2.4064383506774902
Validation loss: 2.0251081169292493

Epoch: 6| Step: 5
Training loss: 2.3093113899230957
Validation loss: 2.0424045080779702

Epoch: 6| Step: 6
Training loss: 2.036588430404663
Validation loss: 2.0720524044447046

Epoch: 6| Step: 7
Training loss: 3.2082180976867676
Validation loss: 2.08479227301895

Epoch: 6| Step: 8
Training loss: 2.315187931060791
Validation loss: 2.0800931453704834

Epoch: 6| Step: 9
Training loss: 1.6141058206558228
Validation loss: 2.0471838648601244

Epoch: 6| Step: 10
Training loss: 2.454677104949951
Validation loss: 2.030759919074274

Epoch: 6| Step: 11
Training loss: 3.445521831512451
Validation loss: 2.0081041115586475

Epoch: 6| Step: 12
Training loss: 2.3512697219848633
Validation loss: 2.0190096644945044

Epoch: 6| Step: 13
Training loss: 2.324484348297119
Validation loss: 2.0106144720508206

Epoch: 119| Step: 0
Training loss: 2.6007769107818604
Validation loss: 2.0150264258025796

Epoch: 6| Step: 1
Training loss: 1.8719514608383179
Validation loss: 2.005962085980241

Epoch: 6| Step: 2
Training loss: 2.186052083969116
Validation loss: 2.013595397754382

Epoch: 6| Step: 3
Training loss: 2.1034884452819824
Validation loss: 2.0153042475382485

Epoch: 6| Step: 4
Training loss: 2.7834420204162598
Validation loss: 2.0062322719122774

Epoch: 6| Step: 5
Training loss: 2.076157331466675
Validation loss: 2.0107683353526618

Epoch: 6| Step: 6
Training loss: 1.6245239973068237
Validation loss: 2.0103935195553686

Epoch: 6| Step: 7
Training loss: 2.9484705924987793
Validation loss: 2.0137048511094946

Epoch: 6| Step: 8
Training loss: 2.1888906955718994
Validation loss: 2.044764123937135

Epoch: 6| Step: 9
Training loss: 2.6200876235961914
Validation loss: 2.0889125716301704

Epoch: 6| Step: 10
Training loss: 2.137570381164551
Validation loss: 2.111291931521508

Epoch: 6| Step: 11
Training loss: 3.122368097305298
Validation loss: 2.126645153568637

Epoch: 6| Step: 12
Training loss: 2.2179088592529297
Validation loss: 2.104457239950857

Epoch: 6| Step: 13
Training loss: 1.3338295221328735
Validation loss: 2.0648949838453725

Epoch: 120| Step: 0
Training loss: 2.1715826988220215
Validation loss: 2.0511112443862425

Epoch: 6| Step: 1
Training loss: 1.9656620025634766
Validation loss: 2.0399809140031055

Epoch: 6| Step: 2
Training loss: 2.3709418773651123
Validation loss: 2.0267701148986816

Epoch: 6| Step: 3
Training loss: 2.087799310684204
Validation loss: 2.0365915939372075

Epoch: 6| Step: 4
Training loss: 2.576362371444702
Validation loss: 2.044185766609766

Epoch: 6| Step: 5
Training loss: 2.1384196281433105
Validation loss: 2.0703081328381776

Epoch: 6| Step: 6
Training loss: 1.5039119720458984
Validation loss: 2.077861947398032

Epoch: 6| Step: 7
Training loss: 2.6824421882629395
Validation loss: 2.0968720297659598

Epoch: 6| Step: 8
Training loss: 2.098905563354492
Validation loss: 2.083199701001567

Epoch: 6| Step: 9
Training loss: 2.1429896354675293
Validation loss: 2.0620137055714927

Epoch: 6| Step: 10
Training loss: 2.8266518115997314
Validation loss: 2.0391375505796043

Epoch: 6| Step: 11
Training loss: 2.4269204139709473
Validation loss: 2.024806950681953

Epoch: 6| Step: 12
Training loss: 2.4139606952667236
Validation loss: 2.016827271830651

Epoch: 6| Step: 13
Training loss: 3.1832728385925293
Validation loss: 2.0125136208790604

Epoch: 121| Step: 0
Training loss: 1.9459662437438965
Validation loss: 2.005504395372124

Epoch: 6| Step: 1
Training loss: 2.1341817378997803
Validation loss: 2.0082711007005427

Epoch: 6| Step: 2
Training loss: 2.4624860286712646
Validation loss: 2.0264167567735076

Epoch: 6| Step: 3
Training loss: 2.2533679008483887
Validation loss: 2.028254747390747

Epoch: 6| Step: 4
Training loss: 2.5457329750061035
Validation loss: 2.0363073323362615

Epoch: 6| Step: 5
Training loss: 2.262338161468506
Validation loss: 2.0363669267264743

Epoch: 6| Step: 6
Training loss: 2.944246768951416
Validation loss: 2.0248729939101846

Epoch: 6| Step: 7
Training loss: 2.297450065612793
Validation loss: 2.0217456138262184

Epoch: 6| Step: 8
Training loss: 2.138857364654541
Validation loss: 2.0216331251205935

Epoch: 6| Step: 9
Training loss: 2.548682928085327
Validation loss: 2.011989524287562

Epoch: 6| Step: 10
Training loss: 2.4430813789367676
Validation loss: 2.0262201921914214

Epoch: 6| Step: 11
Training loss: 1.9513695240020752
Validation loss: 2.0559917906279206

Epoch: 6| Step: 12
Training loss: 2.169656991958618
Validation loss: 2.099271103899966

Epoch: 6| Step: 13
Training loss: 3.039604902267456
Validation loss: 2.150997882248253

Epoch: 122| Step: 0
Training loss: 2.6799731254577637
Validation loss: 2.21281272621565

Epoch: 6| Step: 1
Training loss: 2.563389301300049
Validation loss: 2.198557210224931

Epoch: 6| Step: 2
Training loss: 2.1326942443847656
Validation loss: 2.176328238620553

Epoch: 6| Step: 3
Training loss: 2.5364878177642822
Validation loss: 2.1491319235935005

Epoch: 6| Step: 4
Training loss: 2.373271942138672
Validation loss: 2.124281060311102

Epoch: 6| Step: 5
Training loss: 2.585707426071167
Validation loss: 2.1031484116790113

Epoch: 6| Step: 6
Training loss: 2.1475303173065186
Validation loss: 2.0858788977387133

Epoch: 6| Step: 7
Training loss: 2.0416340827941895
Validation loss: 2.0898730037032918

Epoch: 6| Step: 8
Training loss: 2.5233066082000732
Validation loss: 2.1007374217433314

Epoch: 6| Step: 9
Training loss: 2.4688446521759033
Validation loss: 2.086167271419238

Epoch: 6| Step: 10
Training loss: 2.2264087200164795
Validation loss: 2.09081389827113

Epoch: 6| Step: 11
Training loss: 1.6653201580047607
Validation loss: 2.0815190563919725

Epoch: 6| Step: 12
Training loss: 2.557767868041992
Validation loss: 2.0834472666504564

Epoch: 6| Step: 13
Training loss: 3.6198344230651855
Validation loss: 2.0813910538150417

Epoch: 123| Step: 0
Training loss: 1.9498854875564575
Validation loss: 2.089562000766877

Epoch: 6| Step: 1
Training loss: 3.4341278076171875
Validation loss: 2.0947940452124483

Epoch: 6| Step: 2
Training loss: 2.3872878551483154
Validation loss: 2.099692731775263

Epoch: 6| Step: 3
Training loss: 2.1325676441192627
Validation loss: 2.119356921924058

Epoch: 6| Step: 4
Training loss: 2.7976503372192383
Validation loss: 2.123268460714689

Epoch: 6| Step: 5
Training loss: 2.053131103515625
Validation loss: 2.113558761535152

Epoch: 6| Step: 6
Training loss: 2.5288138389587402
Validation loss: 2.1069613631053636

Epoch: 6| Step: 7
Training loss: 2.76786470413208
Validation loss: 2.104053851096861

Epoch: 6| Step: 8
Training loss: 2.0574417114257812
Validation loss: 2.090401885330036

Epoch: 6| Step: 9
Training loss: 2.1499340534210205
Validation loss: 2.0666006290784447

Epoch: 6| Step: 10
Training loss: 1.6097824573516846
Validation loss: 2.051732086366223

Epoch: 6| Step: 11
Training loss: 2.3059751987457275
Validation loss: 2.0538389272587274

Epoch: 6| Step: 12
Training loss: 2.0361125469207764
Validation loss: 2.0526400689155824

Epoch: 6| Step: 13
Training loss: 2.727327346801758
Validation loss: 2.045015381228539

Epoch: 124| Step: 0
Training loss: 2.986569881439209
Validation loss: 2.0435221631039857

Epoch: 6| Step: 1
Training loss: 2.644497871398926
Validation loss: 2.0491910903684554

Epoch: 6| Step: 2
Training loss: 1.7410199642181396
Validation loss: 2.0657074297628095

Epoch: 6| Step: 3
Training loss: 1.961000680923462
Validation loss: 2.0852212777701755

Epoch: 6| Step: 4
Training loss: 2.146700859069824
Validation loss: 2.0673163860074935

Epoch: 6| Step: 5
Training loss: 3.0246853828430176
Validation loss: 2.046155761646968

Epoch: 6| Step: 6
Training loss: 2.411487579345703
Validation loss: 2.0112728329115015

Epoch: 6| Step: 7
Training loss: 2.419229030609131
Validation loss: 2.0073372112807406

Epoch: 6| Step: 8
Training loss: 2.250319242477417
Validation loss: 1.9907925526301067

Epoch: 6| Step: 9
Training loss: 1.757490634918213
Validation loss: 1.9935218467507312

Epoch: 6| Step: 10
Training loss: 1.8919031620025635
Validation loss: 2.0079092864067323

Epoch: 6| Step: 11
Training loss: 2.1473264694213867
Validation loss: 2.016072633445904

Epoch: 6| Step: 12
Training loss: 2.604341983795166
Validation loss: 2.015757486384402

Epoch: 6| Step: 13
Training loss: 2.1017351150512695
Validation loss: 2.0274713654671945

Epoch: 125| Step: 0
Training loss: 1.8261117935180664
Validation loss: 2.017940754531532

Epoch: 6| Step: 1
Training loss: 2.5006868839263916
Validation loss: 2.0022589724550963

Epoch: 6| Step: 2
Training loss: 2.1117470264434814
Validation loss: 1.99733151671707

Epoch: 6| Step: 3
Training loss: 1.9888906478881836
Validation loss: 1.9974102640664706

Epoch: 6| Step: 4
Training loss: 3.1119885444641113
Validation loss: 2.0131629256791967

Epoch: 6| Step: 5
Training loss: 2.873420238494873
Validation loss: 2.0244948505073466

Epoch: 6| Step: 6
Training loss: 2.5594522953033447
Validation loss: 2.0149707140461093

Epoch: 6| Step: 7
Training loss: 2.204319953918457
Validation loss: 1.9992529781915809

Epoch: 6| Step: 8
Training loss: 2.4265964031219482
Validation loss: 1.9922122211866482

Epoch: 6| Step: 9
Training loss: 1.6485847234725952
Validation loss: 1.9857887016829623

Epoch: 6| Step: 10
Training loss: 2.040848731994629
Validation loss: 1.9886244035536242

Epoch: 6| Step: 11
Training loss: 2.2177658081054688
Validation loss: 1.986064733997468

Epoch: 6| Step: 12
Training loss: 2.430180549621582
Validation loss: 1.996147083979781

Epoch: 6| Step: 13
Training loss: 1.945995807647705
Validation loss: 2.019026674250121

Epoch: 126| Step: 0
Training loss: 2.863813877105713
Validation loss: 2.0474944794049827

Epoch: 6| Step: 1
Training loss: 1.762665867805481
Validation loss: 2.0549819084905807

Epoch: 6| Step: 2
Training loss: 2.7573299407958984
Validation loss: 2.0693763609855407

Epoch: 6| Step: 3
Training loss: 2.7656476497650146
Validation loss: 2.0593379364218762

Epoch: 6| Step: 4
Training loss: 2.0539650917053223
Validation loss: 2.019953789249543

Epoch: 6| Step: 5
Training loss: 2.139369010925293
Validation loss: 2.005224561178556

Epoch: 6| Step: 6
Training loss: 1.8809847831726074
Validation loss: 1.98961309079201

Epoch: 6| Step: 7
Training loss: 2.5427093505859375
Validation loss: 1.9796523496668825

Epoch: 6| Step: 8
Training loss: 2.3033502101898193
Validation loss: 1.9786186077261483

Epoch: 6| Step: 9
Training loss: 2.237852096557617
Validation loss: 1.9912091096242268

Epoch: 6| Step: 10
Training loss: 2.946019172668457
Validation loss: 1.9922307819448493

Epoch: 6| Step: 11
Training loss: 1.5386439561843872
Validation loss: 1.9959754572119763

Epoch: 6| Step: 12
Training loss: 2.1627745628356934
Validation loss: 2.005145985593078

Epoch: 6| Step: 13
Training loss: 2.173588275909424
Validation loss: 2.0121185548843874

Epoch: 127| Step: 0
Training loss: 1.9456292390823364
Validation loss: 2.0326045379843762

Epoch: 6| Step: 1
Training loss: 1.749299168586731
Validation loss: 2.057847429347295

Epoch: 6| Step: 2
Training loss: 2.5653305053710938
Validation loss: 2.0440786448858117

Epoch: 6| Step: 3
Training loss: 3.38643741607666
Validation loss: 2.035106446153374

Epoch: 6| Step: 4
Training loss: 2.1012377738952637
Validation loss: 2.0109156818800074

Epoch: 6| Step: 5
Training loss: 2.193648338317871
Validation loss: 1.9939678868939799

Epoch: 6| Step: 6
Training loss: 2.7686960697174072
Validation loss: 1.9943441216663649

Epoch: 6| Step: 7
Training loss: 2.2818498611450195
Validation loss: 1.9910125809331094

Epoch: 6| Step: 8
Training loss: 2.455216407775879
Validation loss: 1.9939925465532529

Epoch: 6| Step: 9
Training loss: 2.1503005027770996
Validation loss: 2.0031925798744283

Epoch: 6| Step: 10
Training loss: 2.2726001739501953
Validation loss: 1.9997121749385711

Epoch: 6| Step: 11
Training loss: 1.5254544019699097
Validation loss: 1.9940831430496708

Epoch: 6| Step: 12
Training loss: 2.6134285926818848
Validation loss: 1.9975528153040076

Epoch: 6| Step: 13
Training loss: 1.9492535591125488
Validation loss: 2.025829001139569

Epoch: 128| Step: 0
Training loss: 2.5753726959228516
Validation loss: 2.0584276824869137

Epoch: 6| Step: 1
Training loss: 2.4048585891723633
Validation loss: 2.08574426815074

Epoch: 6| Step: 2
Training loss: 2.4771323204040527
Validation loss: 2.0921221830511607

Epoch: 6| Step: 3
Training loss: 2.746229648590088
Validation loss: 2.071954145226427

Epoch: 6| Step: 4
Training loss: 2.5208194255828857
Validation loss: 2.036233030339723

Epoch: 6| Step: 5
Training loss: 2.133604049682617
Validation loss: 2.014360420165523

Epoch: 6| Step: 6
Training loss: 1.7935540676116943
Validation loss: 2.002070503850137

Epoch: 6| Step: 7
Training loss: 1.8800500631332397
Validation loss: 1.998230985415879

Epoch: 6| Step: 8
Training loss: 2.2527084350585938
Validation loss: 2.010836639711934

Epoch: 6| Step: 9
Training loss: 2.068265914916992
Validation loss: 2.028220756079561

Epoch: 6| Step: 10
Training loss: 2.1101040840148926
Validation loss: 2.050100993084651

Epoch: 6| Step: 11
Training loss: 2.2271618843078613
Validation loss: 2.071603141805177

Epoch: 6| Step: 12
Training loss: 2.5893964767456055
Validation loss: 2.084613960276368

Epoch: 6| Step: 13
Training loss: 2.1442642211914062
Validation loss: 2.111302768030474

Epoch: 129| Step: 0
Training loss: 2.08048677444458
Validation loss: 2.0977242915861067

Epoch: 6| Step: 1
Training loss: 2.475904703140259
Validation loss: 2.077222055004489

Epoch: 6| Step: 2
Training loss: 3.055575370788574
Validation loss: 2.0765966664078417

Epoch: 6| Step: 3
Training loss: 2.4003560543060303
Validation loss: 2.056384448082216

Epoch: 6| Step: 4
Training loss: 3.1361453533172607
Validation loss: 2.051224482956753

Epoch: 6| Step: 5
Training loss: 2.0527987480163574
Validation loss: 2.0371611951499857

Epoch: 6| Step: 6
Training loss: 2.422589063644409
Validation loss: 2.029597072191136

Epoch: 6| Step: 7
Training loss: 1.7461662292480469
Validation loss: 2.0247953502080773

Epoch: 6| Step: 8
Training loss: 1.759488582611084
Validation loss: 2.041651830878309

Epoch: 6| Step: 9
Training loss: 1.7802542448043823
Validation loss: 2.0144336787603234

Epoch: 6| Step: 10
Training loss: 1.6699652671813965
Validation loss: 2.0093036774666078

Epoch: 6| Step: 11
Training loss: 2.1490187644958496
Validation loss: 2.000765064711212

Epoch: 6| Step: 12
Training loss: 2.413522720336914
Validation loss: 2.0064260318715084

Epoch: 6| Step: 13
Training loss: 2.6287546157836914
Validation loss: 2.0053399532072005

Epoch: 130| Step: 0
Training loss: 1.815352439880371
Validation loss: 1.9965821184137815

Epoch: 6| Step: 1
Training loss: 2.2535104751586914
Validation loss: 2.0005256950214343

Epoch: 6| Step: 2
Training loss: 2.2458786964416504
Validation loss: 1.9957293682200934

Epoch: 6| Step: 3
Training loss: 2.673407554626465
Validation loss: 2.0028251986349783

Epoch: 6| Step: 4
Training loss: 2.631476879119873
Validation loss: 2.007720092291473

Epoch: 6| Step: 5
Training loss: 1.8148428201675415
Validation loss: 2.004014879144648

Epoch: 6| Step: 6
Training loss: 2.3684935569763184
Validation loss: 2.018721003686228

Epoch: 6| Step: 7
Training loss: 1.735720157623291
Validation loss: 2.04642576812416

Epoch: 6| Step: 8
Training loss: 1.932629942893982
Validation loss: 2.044577016625353

Epoch: 6| Step: 9
Training loss: 2.7441062927246094
Validation loss: 2.0251573490840133

Epoch: 6| Step: 10
Training loss: 2.00480318069458
Validation loss: 2.0359901702532204

Epoch: 6| Step: 11
Training loss: 2.5030643939971924
Validation loss: 2.0689488444277035

Epoch: 6| Step: 12
Training loss: 2.5415735244750977
Validation loss: 2.061167792607379

Epoch: 6| Step: 13
Training loss: 2.103600025177002
Validation loss: 2.0506395383547713

Epoch: 131| Step: 0
Training loss: 1.8151270151138306
Validation loss: 2.0445822067158197

Epoch: 6| Step: 1
Training loss: 2.273803949356079
Validation loss: 2.025143395188034

Epoch: 6| Step: 2
Training loss: 2.405642509460449
Validation loss: 1.9983994691602645

Epoch: 6| Step: 3
Training loss: 2.3624019622802734
Validation loss: 2.005648615539715

Epoch: 6| Step: 4
Training loss: 2.568913221359253
Validation loss: 2.0052159986188336

Epoch: 6| Step: 5
Training loss: 1.7495895624160767
Validation loss: 2.0093790561922136

Epoch: 6| Step: 6
Training loss: 2.428269863128662
Validation loss: 2.0036243161847516

Epoch: 6| Step: 7
Training loss: 1.4626303911209106
Validation loss: 1.9938611958616523

Epoch: 6| Step: 8
Training loss: 2.8981189727783203
Validation loss: 2.009562334706706

Epoch: 6| Step: 9
Training loss: 1.8004217147827148
Validation loss: 2.0672940336247927

Epoch: 6| Step: 10
Training loss: 2.682321548461914
Validation loss: 2.114499722757647

Epoch: 6| Step: 11
Training loss: 2.0645065307617188
Validation loss: 2.184549529065368

Epoch: 6| Step: 12
Training loss: 2.908146858215332
Validation loss: 2.223818830264512

Epoch: 6| Step: 13
Training loss: 1.945931077003479
Validation loss: 2.2598836063056864

Epoch: 132| Step: 0
Training loss: 2.661632537841797
Validation loss: 2.2416076173064527

Epoch: 6| Step: 1
Training loss: 2.790536403656006
Validation loss: 2.1605246579775246

Epoch: 6| Step: 2
Training loss: 2.224095582962036
Validation loss: 2.112213744912096

Epoch: 6| Step: 3
Training loss: 2.7520642280578613
Validation loss: 2.064622422700287

Epoch: 6| Step: 4
Training loss: 1.4017612934112549
Validation loss: 2.017081622154482

Epoch: 6| Step: 5
Training loss: 2.5653724670410156
Validation loss: 2.000213711492477

Epoch: 6| Step: 6
Training loss: 1.6746399402618408
Validation loss: 2.002543592965731

Epoch: 6| Step: 7
Training loss: 2.1030197143554688
Validation loss: 2.0264694242067236

Epoch: 6| Step: 8
Training loss: 1.6444377899169922
Validation loss: 2.043252282245185

Epoch: 6| Step: 9
Training loss: 2.0514512062072754
Validation loss: 2.0386624977152836

Epoch: 6| Step: 10
Training loss: 2.6260833740234375
Validation loss: 2.025062343125702

Epoch: 6| Step: 11
Training loss: 2.2476046085357666
Validation loss: 2.0177882127864386

Epoch: 6| Step: 12
Training loss: 2.4446535110473633
Validation loss: 1.9974152324020222

Epoch: 6| Step: 13
Training loss: 2.5092146396636963
Validation loss: 1.9961327365649644

Epoch: 133| Step: 0
Training loss: 1.977413535118103
Validation loss: 1.9927378623716292

Epoch: 6| Step: 1
Training loss: 2.347047805786133
Validation loss: 1.9842622151938818

Epoch: 6| Step: 2
Training loss: 2.743704319000244
Validation loss: 1.9892592353205527

Epoch: 6| Step: 3
Training loss: 2.6719393730163574
Validation loss: 1.9903725116483626

Epoch: 6| Step: 4
Training loss: 2.5492658615112305
Validation loss: 1.982999493998866

Epoch: 6| Step: 5
Training loss: 2.2623395919799805
Validation loss: 1.9753329241147606

Epoch: 6| Step: 6
Training loss: 2.029202461242676
Validation loss: 2.0149465299421743

Epoch: 6| Step: 7
Training loss: 2.0142245292663574
Validation loss: 2.0262541694025837

Epoch: 6| Step: 8
Training loss: 1.679431676864624
Validation loss: 2.047672697292861

Epoch: 6| Step: 9
Training loss: 2.0204341411590576
Validation loss: 2.06260488622932

Epoch: 6| Step: 10
Training loss: 2.7350552082061768
Validation loss: 2.0636282531164025

Epoch: 6| Step: 11
Training loss: 2.3278961181640625
Validation loss: 2.043786374471521

Epoch: 6| Step: 12
Training loss: 2.2362489700317383
Validation loss: 1.9973621381226407

Epoch: 6| Step: 13
Training loss: 2.3126699924468994
Validation loss: 1.976687700517716

Epoch: 134| Step: 0
Training loss: 2.0834991931915283
Validation loss: 1.971788373044742

Epoch: 6| Step: 1
Training loss: 2.4004693031311035
Validation loss: 1.9778420207321004

Epoch: 6| Step: 2
Training loss: 2.7024035453796387
Validation loss: 1.9798872727219776

Epoch: 6| Step: 3
Training loss: 2.533447265625
Validation loss: 1.9723004807708084

Epoch: 6| Step: 4
Training loss: 1.546843409538269
Validation loss: 1.9676667221130864

Epoch: 6| Step: 5
Training loss: 2.0953493118286133
Validation loss: 1.9682426068090624

Epoch: 6| Step: 6
Training loss: 2.5530779361724854
Validation loss: 1.9770296414693196

Epoch: 6| Step: 7
Training loss: 2.821162223815918
Validation loss: 2.0016129196331067

Epoch: 6| Step: 8
Training loss: 2.4136040210723877
Validation loss: 2.009501814842224

Epoch: 6| Step: 9
Training loss: 1.9913018941879272
Validation loss: 2.020315324106524

Epoch: 6| Step: 10
Training loss: 1.9087274074554443
Validation loss: 2.036969884749382

Epoch: 6| Step: 11
Training loss: 2.267641305923462
Validation loss: 2.0477690350624824

Epoch: 6| Step: 12
Training loss: 1.9987566471099854
Validation loss: 2.049976142503882

Epoch: 6| Step: 13
Training loss: 2.502028465270996
Validation loss: 2.0649269550077376

Epoch: 135| Step: 0
Training loss: 2.6788673400878906
Validation loss: 2.043229018488238

Epoch: 6| Step: 1
Training loss: 2.0217831134796143
Validation loss: 2.0357846777926207

Epoch: 6| Step: 2
Training loss: 1.923951268196106
Validation loss: 2.0468236066961802

Epoch: 6| Step: 3
Training loss: 2.5773918628692627
Validation loss: 2.0465964322449057

Epoch: 6| Step: 4
Training loss: 2.291337013244629
Validation loss: 2.0549575590318248

Epoch: 6| Step: 5
Training loss: 2.1198267936706543
Validation loss: 2.0707986098463818

Epoch: 6| Step: 6
Training loss: 2.823354959487915
Validation loss: 2.046521061210222

Epoch: 6| Step: 7
Training loss: 2.177969455718994
Validation loss: 2.0388556244552776

Epoch: 6| Step: 8
Training loss: 2.2754387855529785
Validation loss: 2.0448773650712866

Epoch: 6| Step: 9
Training loss: 1.282088279724121
Validation loss: 2.06169839443699

Epoch: 6| Step: 10
Training loss: 2.0250630378723145
Validation loss: 2.0388798611138457

Epoch: 6| Step: 11
Training loss: 1.6819038391113281
Validation loss: 2.022153317287404

Epoch: 6| Step: 12
Training loss: 2.3435275554656982
Validation loss: 2.012072137607041

Epoch: 6| Step: 13
Training loss: 3.1401591300964355
Validation loss: 1.9997377113629413

Epoch: 136| Step: 0
Training loss: 3.1168994903564453
Validation loss: 1.9921788528401365

Epoch: 6| Step: 1
Training loss: 2.3006319999694824
Validation loss: 1.984492604450513

Epoch: 6| Step: 2
Training loss: 1.9782648086547852
Validation loss: 1.98029161525029

Epoch: 6| Step: 3
Training loss: 2.217294692993164
Validation loss: 1.9845082554765927

Epoch: 6| Step: 4
Training loss: 2.5629501342773438
Validation loss: 2.0174462103074595

Epoch: 6| Step: 5
Training loss: 1.989500880241394
Validation loss: 2.0542802221031597

Epoch: 6| Step: 6
Training loss: 2.5574424266815186
Validation loss: 2.087569881510991

Epoch: 6| Step: 7
Training loss: 2.206864833831787
Validation loss: 2.0851235287163847

Epoch: 6| Step: 8
Training loss: 2.241260528564453
Validation loss: 2.109678855506323

Epoch: 6| Step: 9
Training loss: 2.6900622844696045
Validation loss: 2.1084065168134627

Epoch: 6| Step: 10
Training loss: 2.0167720317840576
Validation loss: 2.0903721342804613

Epoch: 6| Step: 11
Training loss: 2.0431768894195557
Validation loss: 2.057589702708747

Epoch: 6| Step: 12
Training loss: 1.6981070041656494
Validation loss: 2.0265591298380206

Epoch: 6| Step: 13
Training loss: 1.3949713706970215
Validation loss: 2.0013112906486756

Epoch: 137| Step: 0
Training loss: 2.8123421669006348
Validation loss: 1.9698112869775424

Epoch: 6| Step: 1
Training loss: 2.3356423377990723
Validation loss: 1.9690246453849218

Epoch: 6| Step: 2
Training loss: 2.7747244834899902
Validation loss: 1.9701634837735085

Epoch: 6| Step: 3
Training loss: 2.0863142013549805
Validation loss: 1.970220015894982

Epoch: 6| Step: 4
Training loss: 1.8802270889282227
Validation loss: 1.9885341313577467

Epoch: 6| Step: 5
Training loss: 1.8594083786010742
Validation loss: 2.0064296299411404

Epoch: 6| Step: 6
Training loss: 1.887085199356079
Validation loss: 2.0072958687300324

Epoch: 6| Step: 7
Training loss: 3.0207552909851074
Validation loss: 2.0273740445413897

Epoch: 6| Step: 8
Training loss: 1.843077540397644
Validation loss: 2.0632636444542998

Epoch: 6| Step: 9
Training loss: 1.669055461883545
Validation loss: 2.0549395161290325

Epoch: 6| Step: 10
Training loss: 1.967270851135254
Validation loss: 2.0703188398832917

Epoch: 6| Step: 11
Training loss: 2.127027988433838
Validation loss: 2.059767020645962

Epoch: 6| Step: 12
Training loss: 2.857081890106201
Validation loss: 2.0561577555953816

Epoch: 6| Step: 13
Training loss: 2.205486297607422
Validation loss: 2.0237932179563787

Epoch: 138| Step: 0
Training loss: 1.6519005298614502
Validation loss: 2.0144742868279897

Epoch: 6| Step: 1
Training loss: 1.5901269912719727
Validation loss: 2.0148715960082186

Epoch: 6| Step: 2
Training loss: 2.589938163757324
Validation loss: 2.006407751831957

Epoch: 6| Step: 3
Training loss: 2.456376791000366
Validation loss: 2.0100944939480034

Epoch: 6| Step: 4
Training loss: 2.2016472816467285
Validation loss: 2.0197997323928343

Epoch: 6| Step: 5
Training loss: 1.9310777187347412
Validation loss: 2.010804501912927

Epoch: 6| Step: 6
Training loss: 2.136261463165283
Validation loss: 2.0155734144231325

Epoch: 6| Step: 7
Training loss: 2.369445562362671
Validation loss: 2.017204625632173

Epoch: 6| Step: 8
Training loss: 2.0127758979797363
Validation loss: 2.0489701750457927

Epoch: 6| Step: 9
Training loss: 2.014066696166992
Validation loss: 2.070152896706776

Epoch: 6| Step: 10
Training loss: 2.8147788047790527
Validation loss: 2.1072037066182783

Epoch: 6| Step: 11
Training loss: 2.9153685569763184
Validation loss: 2.13798269917888

Epoch: 6| Step: 12
Training loss: 2.6231865882873535
Validation loss: 2.104087607834929

Epoch: 6| Step: 13
Training loss: 1.3440704345703125
Validation loss: 2.037173976180374

Epoch: 139| Step: 0
Training loss: 2.823690176010132
Validation loss: 2.015184606275251

Epoch: 6| Step: 1
Training loss: 2.253056049346924
Validation loss: 2.019054551278391

Epoch: 6| Step: 2
Training loss: 1.7628587484359741
Validation loss: 2.0149954160054526

Epoch: 6| Step: 3
Training loss: 2.139040470123291
Validation loss: 1.9988185872313797

Epoch: 6| Step: 4
Training loss: 2.7399933338165283
Validation loss: 1.9895586480376541

Epoch: 6| Step: 5
Training loss: 1.4627476930618286
Validation loss: 1.9924675367211784

Epoch: 6| Step: 6
Training loss: 1.9106061458587646
Validation loss: 1.9924253289417555

Epoch: 6| Step: 7
Training loss: 2.785907506942749
Validation loss: 1.9907108596576157

Epoch: 6| Step: 8
Training loss: 1.4881625175476074
Validation loss: 1.9844743885019773

Epoch: 6| Step: 9
Training loss: 2.870875835418701
Validation loss: 2.0137090811165432

Epoch: 6| Step: 10
Training loss: 2.10426664352417
Validation loss: 2.0136311259320987

Epoch: 6| Step: 11
Training loss: 1.8807497024536133
Validation loss: 2.0444973130379953

Epoch: 6| Step: 12
Training loss: 2.510608673095703
Validation loss: 2.050003126103391

Epoch: 6| Step: 13
Training loss: 2.5534350872039795
Validation loss: 2.0641543429384948

Epoch: 140| Step: 0
Training loss: 2.095494270324707
Validation loss: 2.059091161656123

Epoch: 6| Step: 1
Training loss: 3.118450164794922
Validation loss: 2.0369434484871487

Epoch: 6| Step: 2
Training loss: 1.7162737846374512
Validation loss: 2.0149973618086947

Epoch: 6| Step: 3
Training loss: 1.9782335758209229
Validation loss: 1.9998768580857145

Epoch: 6| Step: 4
Training loss: 1.8347647190093994
Validation loss: 1.9904850247085735

Epoch: 6| Step: 5
Training loss: 2.76715087890625
Validation loss: 1.9855442559847267

Epoch: 6| Step: 6
Training loss: 1.9930328130722046
Validation loss: 1.9794494900652158

Epoch: 6| Step: 7
Training loss: 2.219377279281616
Validation loss: 1.97894133803665

Epoch: 6| Step: 8
Training loss: 2.257761001586914
Validation loss: 1.982910486959642

Epoch: 6| Step: 9
Training loss: 2.522341728210449
Validation loss: 1.9834388276582122

Epoch: 6| Step: 10
Training loss: 1.651151418685913
Validation loss: 1.9887589728960426

Epoch: 6| Step: 11
Training loss: 1.8650448322296143
Validation loss: 1.9747813273501653

Epoch: 6| Step: 12
Training loss: 2.2694034576416016
Validation loss: 1.9869229639730146

Epoch: 6| Step: 13
Training loss: 2.075174570083618
Validation loss: 1.9900716068924114

Epoch: 141| Step: 0
Training loss: 2.070517063140869
Validation loss: 2.0161990478474605

Epoch: 6| Step: 1
Training loss: 1.6924424171447754
Validation loss: 2.0514636437098184

Epoch: 6| Step: 2
Training loss: 1.7358630895614624
Validation loss: 2.0926811490007626

Epoch: 6| Step: 3
Training loss: 1.8490146398544312
Validation loss: 2.1369033257166543

Epoch: 6| Step: 4
Training loss: 2.8295540809631348
Validation loss: 2.146533296954247

Epoch: 6| Step: 5
Training loss: 2.43326735496521
Validation loss: 2.147403633722695

Epoch: 6| Step: 6
Training loss: 2.4753029346466064
Validation loss: 2.106559540635796

Epoch: 6| Step: 7
Training loss: 2.658437728881836
Validation loss: 2.0591024237294353

Epoch: 6| Step: 8
Training loss: 2.131844997406006
Validation loss: 2.0169639792493594

Epoch: 6| Step: 9
Training loss: 1.8412306308746338
Validation loss: 2.005749676817207

Epoch: 6| Step: 10
Training loss: 2.2487988471984863
Validation loss: 2.000277428216832

Epoch: 6| Step: 11
Training loss: 2.6471922397613525
Validation loss: 2.035008454835543

Epoch: 6| Step: 12
Training loss: 2.6331372261047363
Validation loss: 2.0815139855107954

Epoch: 6| Step: 13
Training loss: 1.882143497467041
Validation loss: 2.0952556543452765

Epoch: 142| Step: 0
Training loss: 2.4721734523773193
Validation loss: 2.0623615172601517

Epoch: 6| Step: 1
Training loss: 1.7093902826309204
Validation loss: 1.9963250160217285

Epoch: 6| Step: 2
Training loss: 1.33391535282135
Validation loss: 2.00675610316697

Epoch: 6| Step: 3
Training loss: 2.5244200229644775
Validation loss: 2.035025251808987

Epoch: 6| Step: 4
Training loss: 2.357879400253296
Validation loss: 2.141019800657867

Epoch: 6| Step: 5
Training loss: 2.8855338096618652
Validation loss: 2.1956363801033265

Epoch: 6| Step: 6
Training loss: 2.611168146133423
Validation loss: 2.33484834753057

Epoch: 6| Step: 7
Training loss: 1.8619037866592407
Validation loss: 2.344134920386858

Epoch: 6| Step: 8
Training loss: 2.191657543182373
Validation loss: 2.343076136804396

Epoch: 6| Step: 9
Training loss: 2.166750431060791
Validation loss: 2.2635983984957457

Epoch: 6| Step: 10
Training loss: 3.011584758758545
Validation loss: 2.1697710637123353

Epoch: 6| Step: 11
Training loss: 1.9902467727661133
Validation loss: 2.0780240066589846

Epoch: 6| Step: 12
Training loss: 1.954681396484375
Validation loss: 2.0369039376576743

Epoch: 6| Step: 13
Training loss: 1.9783293008804321
Validation loss: 2.0112941444561048

Epoch: 143| Step: 0
Training loss: 1.8900697231292725
Validation loss: 2.0151600978707753

Epoch: 6| Step: 1
Training loss: 2.4394211769104004
Validation loss: 2.0245602464163177

Epoch: 6| Step: 2
Training loss: 2.1537814140319824
Validation loss: 2.0790703219752156

Epoch: 6| Step: 3
Training loss: 3.1077170372009277
Validation loss: 2.0974616260938745

Epoch: 6| Step: 4
Training loss: 3.059659004211426
Validation loss: 2.1393057582198933

Epoch: 6| Step: 5
Training loss: 2.5550873279571533
Validation loss: 2.131108635215349

Epoch: 6| Step: 6
Training loss: 2.185943841934204
Validation loss: 2.100661234189105

Epoch: 6| Step: 7
Training loss: 2.1753454208374023
Validation loss: 2.0586598227100987

Epoch: 6| Step: 8
Training loss: 2.528221368789673
Validation loss: 2.025965754703809

Epoch: 6| Step: 9
Training loss: 1.5372259616851807
Validation loss: 2.034050827385277

Epoch: 6| Step: 10
Training loss: 2.3601465225219727
Validation loss: 2.0650127613416283

Epoch: 6| Step: 11
Training loss: 1.8315372467041016
Validation loss: 2.084678061546818

Epoch: 6| Step: 12
Training loss: 2.26824951171875
Validation loss: 2.121103132924726

Epoch: 6| Step: 13
Training loss: 2.7098283767700195
Validation loss: 2.137392818286855

Epoch: 144| Step: 0
Training loss: 1.776742696762085
Validation loss: 2.1428970111313688

Epoch: 6| Step: 1
Training loss: 2.686866283416748
Validation loss: 2.113320122482956

Epoch: 6| Step: 2
Training loss: 1.8534841537475586
Validation loss: 2.078069794562555

Epoch: 6| Step: 3
Training loss: 1.9803977012634277
Validation loss: 2.0280095684912895

Epoch: 6| Step: 4
Training loss: 1.5157861709594727
Validation loss: 2.009350356235299

Epoch: 6| Step: 5
Training loss: 2.1749343872070312
Validation loss: 1.9999655831244685

Epoch: 6| Step: 6
Training loss: 1.6796232461929321
Validation loss: 1.9876004649746803

Epoch: 6| Step: 7
Training loss: 1.7951714992523193
Validation loss: 1.979218070225049

Epoch: 6| Step: 8
Training loss: 2.4291200637817383
Validation loss: 1.9740512396699639

Epoch: 6| Step: 9
Training loss: 2.5954599380493164
Validation loss: 1.967585632877965

Epoch: 6| Step: 10
Training loss: 2.357501268386841
Validation loss: 1.9760943253835042

Epoch: 6| Step: 11
Training loss: 2.127305507659912
Validation loss: 1.9775633119767713

Epoch: 6| Step: 12
Training loss: 3.0785865783691406
Validation loss: 1.9715516849230694

Epoch: 6| Step: 13
Training loss: 2.4858860969543457
Validation loss: 1.9632690055395967

Epoch: 145| Step: 0
Training loss: 1.8945674896240234
Validation loss: 1.9613136322267595

Epoch: 6| Step: 1
Training loss: 1.9207415580749512
Validation loss: 1.9757682802856609

Epoch: 6| Step: 2
Training loss: 2.035088300704956
Validation loss: 1.9839357637589978

Epoch: 6| Step: 3
Training loss: 2.3026437759399414
Validation loss: 1.9789436914587533

Epoch: 6| Step: 4
Training loss: 2.0203332901000977
Validation loss: 2.002639655143984

Epoch: 6| Step: 5
Training loss: 2.74685001373291
Validation loss: 2.0257162611971617

Epoch: 6| Step: 6
Training loss: 0.9335458278656006
Validation loss: 2.0325040663442304

Epoch: 6| Step: 7
Training loss: 2.666438102722168
Validation loss: 2.0454725578267086

Epoch: 6| Step: 8
Training loss: 2.261570930480957
Validation loss: 2.023595720209101

Epoch: 6| Step: 9
Training loss: 2.4334588050842285
Validation loss: 2.0155247847239175

Epoch: 6| Step: 10
Training loss: 2.277766704559326
Validation loss: 1.9970297915961153

Epoch: 6| Step: 11
Training loss: 2.454066514968872
Validation loss: 1.9992158707752024

Epoch: 6| Step: 12
Training loss: 2.3882713317871094
Validation loss: 1.999014308375697

Epoch: 6| Step: 13
Training loss: 1.3109345436096191
Validation loss: 2.0207354894248386

Epoch: 146| Step: 0
Training loss: 2.206575632095337
Validation loss: 2.0180965956821235

Epoch: 6| Step: 1
Training loss: 2.5870110988616943
Validation loss: 2.0098079148159234

Epoch: 6| Step: 2
Training loss: 2.1805953979492188
Validation loss: 2.0058893260135444

Epoch: 6| Step: 3
Training loss: 2.788151741027832
Validation loss: 2.000484792135095

Epoch: 6| Step: 4
Training loss: 1.6847853660583496
Validation loss: 1.998938798904419

Epoch: 6| Step: 5
Training loss: 2.6130571365356445
Validation loss: 2.0090691517758112

Epoch: 6| Step: 6
Training loss: 2.7720606327056885
Validation loss: 2.028339701314126

Epoch: 6| Step: 7
Training loss: 2.2311010360717773
Validation loss: 2.0711356068170197

Epoch: 6| Step: 8
Training loss: 1.5822908878326416
Validation loss: 2.1029820314017673

Epoch: 6| Step: 9
Training loss: 2.4415600299835205
Validation loss: 2.121217471297069

Epoch: 6| Step: 10
Training loss: 1.824072241783142
Validation loss: 2.1279249242556992

Epoch: 6| Step: 11
Training loss: 1.5844881534576416
Validation loss: 2.110001999844787

Epoch: 6| Step: 12
Training loss: 1.6772983074188232
Validation loss: 2.0893485443566435

Epoch: 6| Step: 13
Training loss: 1.8734130859375
Validation loss: 2.0586647243909937

Epoch: 147| Step: 0
Training loss: 2.000354290008545
Validation loss: 2.04278390894654

Epoch: 6| Step: 1
Training loss: 2.311781883239746
Validation loss: 2.0206426369246615

Epoch: 6| Step: 2
Training loss: 1.4229021072387695
Validation loss: 2.0261276665554253

Epoch: 6| Step: 3
Training loss: 2.3719217777252197
Validation loss: 2.019903116328742

Epoch: 6| Step: 4
Training loss: 2.8806753158569336
Validation loss: 1.9954191010485414

Epoch: 6| Step: 5
Training loss: 1.4996914863586426
Validation loss: 1.9742707180720505

Epoch: 6| Step: 6
Training loss: 2.6210412979125977
Validation loss: 1.9707130667983845

Epoch: 6| Step: 7
Training loss: 2.5031092166900635
Validation loss: 1.9700479866355978

Epoch: 6| Step: 8
Training loss: 1.973353624343872
Validation loss: 1.9902066312810427

Epoch: 6| Step: 9
Training loss: 1.8679571151733398
Validation loss: 1.9879544447827082

Epoch: 6| Step: 10
Training loss: 1.6970291137695312
Validation loss: 1.9886625582172024

Epoch: 6| Step: 11
Training loss: 2.2177743911743164
Validation loss: 1.978226084862986

Epoch: 6| Step: 12
Training loss: 2.434699535369873
Validation loss: 1.9885629620603336

Epoch: 6| Step: 13
Training loss: 1.9476640224456787
Validation loss: 1.9968098389205111

Epoch: 148| Step: 0
Training loss: 2.41770601272583
Validation loss: 2.003469664563415

Epoch: 6| Step: 1
Training loss: 2.1123361587524414
Validation loss: 2.0204242211516186

Epoch: 6| Step: 2
Training loss: 1.6656849384307861
Validation loss: 2.019115686416626

Epoch: 6| Step: 3
Training loss: 2.350931406021118
Validation loss: 2.0308994477795017

Epoch: 6| Step: 4
Training loss: 2.490208864212036
Validation loss: 2.0176732565767024

Epoch: 6| Step: 5
Training loss: 2.380859851837158
Validation loss: 2.0311966429474535

Epoch: 6| Step: 6
Training loss: 2.0808534622192383
Validation loss: 2.038578306474993

Epoch: 6| Step: 7
Training loss: 2.171844720840454
Validation loss: 2.048927487865571

Epoch: 6| Step: 8
Training loss: 1.4608402252197266
Validation loss: 2.047980782806232

Epoch: 6| Step: 9
Training loss: 2.027101755142212
Validation loss: 2.0466444402612667

Epoch: 6| Step: 10
Training loss: 1.8172144889831543
Validation loss: 2.0687117884235997

Epoch: 6| Step: 11
Training loss: 2.2257497310638428
Validation loss: 2.0804671369573122

Epoch: 6| Step: 12
Training loss: 2.3505024909973145
Validation loss: 2.0899764081483245

Epoch: 6| Step: 13
Training loss: 1.895862102508545
Validation loss: 2.0619694084249516

Epoch: 149| Step: 0
Training loss: 2.721869468688965
Validation loss: 2.028392537947624

Epoch: 6| Step: 1
Training loss: 2.108273983001709
Validation loss: 2.001632833993563

Epoch: 6| Step: 2
Training loss: 2.205066442489624
Validation loss: 1.9930486973895822

Epoch: 6| Step: 3
Training loss: 2.218106746673584
Validation loss: 1.9981508331914102

Epoch: 6| Step: 4
Training loss: 1.449787974357605
Validation loss: 1.9955686125704037

Epoch: 6| Step: 5
Training loss: 1.397357702255249
Validation loss: 2.0021967900696622

Epoch: 6| Step: 6
Training loss: 2.0667481422424316
Validation loss: 2.0027595168800763

Epoch: 6| Step: 7
Training loss: 1.7870912551879883
Validation loss: 2.017239985927459

Epoch: 6| Step: 8
Training loss: 2.324907064437866
Validation loss: 2.029132309780326

Epoch: 6| Step: 9
Training loss: 1.8869341611862183
Validation loss: 2.0223909244742444

Epoch: 6| Step: 10
Training loss: 2.6563031673431396
Validation loss: 2.0250623982439757

Epoch: 6| Step: 11
Training loss: 1.9971977472305298
Validation loss: 2.025506216992614

Epoch: 6| Step: 12
Training loss: 2.5442662239074707
Validation loss: 2.0069214144060687

Epoch: 6| Step: 13
Training loss: 1.5528507232666016
Validation loss: 2.0116518159066477

Epoch: 150| Step: 0
Training loss: 1.6880111694335938
Validation loss: 2.0193260690217376

Epoch: 6| Step: 1
Training loss: 1.6692605018615723
Validation loss: 2.0240779551126624

Epoch: 6| Step: 2
Training loss: 2.076814651489258
Validation loss: 2.030098194717079

Epoch: 6| Step: 3
Training loss: 2.005143642425537
Validation loss: 2.0118849662042435

Epoch: 6| Step: 4
Training loss: 2.7619266510009766
Validation loss: 2.0160966662950415

Epoch: 6| Step: 5
Training loss: 1.5767180919647217
Validation loss: 2.017291353594872

Epoch: 6| Step: 6
Training loss: 2.0500168800354004
Validation loss: 2.012389907272913

Epoch: 6| Step: 7
Training loss: 2.550055503845215
Validation loss: 2.008647018863309

Epoch: 6| Step: 8
Training loss: 2.048081398010254
Validation loss: 2.013746682033744

Epoch: 6| Step: 9
Training loss: 2.632611036300659
Validation loss: 2.0207481230458906

Epoch: 6| Step: 10
Training loss: 1.2922335863113403
Validation loss: 2.0050587320840485

Epoch: 6| Step: 11
Training loss: 2.7777328491210938
Validation loss: 2.0109043300792737

Epoch: 6| Step: 12
Training loss: 2.2577767372131348
Validation loss: 2.015563336751794

Epoch: 6| Step: 13
Training loss: 1.3536372184753418
Validation loss: 2.0172633048026793

Epoch: 151| Step: 0
Training loss: 1.6409547328948975
Validation loss: 2.023050409491344

Epoch: 6| Step: 1
Training loss: 1.724909782409668
Validation loss: 2.0140106729281846

Epoch: 6| Step: 2
Training loss: 2.141374111175537
Validation loss: 2.0166409323292394

Epoch: 6| Step: 3
Training loss: 2.640624523162842
Validation loss: 2.016973682629165

Epoch: 6| Step: 4
Training loss: 2.3615963459014893
Validation loss: 2.023766594548379

Epoch: 6| Step: 5
Training loss: 2.2233614921569824
Validation loss: 2.0419955048509824

Epoch: 6| Step: 6
Training loss: 2.041057586669922
Validation loss: 2.072185834248861

Epoch: 6| Step: 7
Training loss: 1.4063036441802979
Validation loss: 2.063943568096366

Epoch: 6| Step: 8
Training loss: 2.49198579788208
Validation loss: 2.0378242602912326

Epoch: 6| Step: 9
Training loss: 1.505499005317688
Validation loss: 2.0237324160914265

Epoch: 6| Step: 10
Training loss: 1.9660229682922363
Validation loss: 1.9948590827244583

Epoch: 6| Step: 11
Training loss: 2.217773914337158
Validation loss: 1.9869678392205188

Epoch: 6| Step: 12
Training loss: 2.284607172012329
Validation loss: 1.9679263227729387

Epoch: 6| Step: 13
Training loss: 2.526569128036499
Validation loss: 1.9646448525049354

Epoch: 152| Step: 0
Training loss: 1.5492286682128906
Validation loss: 1.957888146882416

Epoch: 6| Step: 1
Training loss: 2.3846964836120605
Validation loss: 1.9537291296066777

Epoch: 6| Step: 2
Training loss: 1.791190266609192
Validation loss: 1.9568386513699767

Epoch: 6| Step: 3
Training loss: 2.9167685508728027
Validation loss: 1.9451879532106462

Epoch: 6| Step: 4
Training loss: 1.707633137702942
Validation loss: 1.9452340372147099

Epoch: 6| Step: 5
Training loss: 1.755815029144287
Validation loss: 1.948379301255749

Epoch: 6| Step: 6
Training loss: 2.035214424133301
Validation loss: 1.9530311707527406

Epoch: 6| Step: 7
Training loss: 1.2162199020385742
Validation loss: 1.9705513292743313

Epoch: 6| Step: 8
Training loss: 2.683990240097046
Validation loss: 1.99830872525451

Epoch: 6| Step: 9
Training loss: 2.216409206390381
Validation loss: 2.004267354165354

Epoch: 6| Step: 10
Training loss: 2.1236472129821777
Validation loss: 1.9869691479590632

Epoch: 6| Step: 11
Training loss: 1.9193732738494873
Validation loss: 1.9786291122436523

Epoch: 6| Step: 12
Training loss: 2.5870962142944336
Validation loss: 1.971849936310963

Epoch: 6| Step: 13
Training loss: 2.023636817932129
Validation loss: 1.9690042362418225

Epoch: 153| Step: 0
Training loss: 2.5442538261413574
Validation loss: 1.9737083450440438

Epoch: 6| Step: 1
Training loss: 1.5981519222259521
Validation loss: 1.985305445168608

Epoch: 6| Step: 2
Training loss: 2.323359489440918
Validation loss: 2.0011040984943347

Epoch: 6| Step: 3
Training loss: 2.130978584289551
Validation loss: 2.011392694647594

Epoch: 6| Step: 4
Training loss: 2.16082763671875
Validation loss: 2.0261016609848186

Epoch: 6| Step: 5
Training loss: 1.749830961227417
Validation loss: 2.0309600996714767

Epoch: 6| Step: 6
Training loss: 2.0416526794433594
Validation loss: 2.0275906042386125

Epoch: 6| Step: 7
Training loss: 1.8126400709152222
Validation loss: 2.0194722170470865

Epoch: 6| Step: 8
Training loss: 2.3182997703552246
Validation loss: 2.003340869821528

Epoch: 6| Step: 9
Training loss: 2.102428436279297
Validation loss: 2.002112534738356

Epoch: 6| Step: 10
Training loss: 2.384335994720459
Validation loss: 1.9974571966355847

Epoch: 6| Step: 11
Training loss: 1.7357585430145264
Validation loss: 2.007283409436544

Epoch: 6| Step: 12
Training loss: 1.6724815368652344
Validation loss: 1.996791990854407

Epoch: 6| Step: 13
Training loss: 2.0502591133117676
Validation loss: 1.9939803333692654

Epoch: 154| Step: 0
Training loss: 2.4234399795532227
Validation loss: 2.002926872622582

Epoch: 6| Step: 1
Training loss: 1.6475419998168945
Validation loss: 2.016440209522042

Epoch: 6| Step: 2
Training loss: 1.3468940258026123
Validation loss: 2.0080930545765865

Epoch: 6| Step: 3
Training loss: 2.166494369506836
Validation loss: 2.017075889854021

Epoch: 6| Step: 4
Training loss: 2.0108091831207275
Validation loss: 2.018994087814003

Epoch: 6| Step: 5
Training loss: 1.978731632232666
Validation loss: 2.013218375944322

Epoch: 6| Step: 6
Training loss: 1.9734396934509277
Validation loss: 2.025392711803477

Epoch: 6| Step: 7
Training loss: 2.1476778984069824
Validation loss: 2.0501438956106863

Epoch: 6| Step: 8
Training loss: 2.162189483642578
Validation loss: 2.0819018271661576

Epoch: 6| Step: 9
Training loss: 1.8050947189331055
Validation loss: 2.0836014081073064

Epoch: 6| Step: 10
Training loss: 2.5268073081970215
Validation loss: 2.078847631331413

Epoch: 6| Step: 11
Training loss: 2.4636359214782715
Validation loss: 2.0518290483823387

Epoch: 6| Step: 12
Training loss: 1.9966102838516235
Validation loss: 2.032527990238641

Epoch: 6| Step: 13
Training loss: 2.3451452255249023
Validation loss: 2.024866447653822

Epoch: 155| Step: 0
Training loss: 1.6532132625579834
Validation loss: 2.016767140357725

Epoch: 6| Step: 1
Training loss: 1.6797614097595215
Validation loss: 2.0273731677762923

Epoch: 6| Step: 2
Training loss: 2.1355013847351074
Validation loss: 2.0217569387087257

Epoch: 6| Step: 3
Training loss: 1.714058518409729
Validation loss: 2.0312166803626606

Epoch: 6| Step: 4
Training loss: 1.6353538036346436
Validation loss: 2.056119757313882

Epoch: 6| Step: 5
Training loss: 1.280545711517334
Validation loss: 2.083875540764101

Epoch: 6| Step: 6
Training loss: 1.5406190156936646
Validation loss: 2.105148776885002

Epoch: 6| Step: 7
Training loss: 2.4671692848205566
Validation loss: 2.0735447534950833

Epoch: 6| Step: 8
Training loss: 2.4821770191192627
Validation loss: 2.056475031760431

Epoch: 6| Step: 9
Training loss: 2.77778959274292
Validation loss: 2.0481215189861994

Epoch: 6| Step: 10
Training loss: 2.717665910720825
Validation loss: 2.030271981352119

Epoch: 6| Step: 11
Training loss: 2.578019142150879
Validation loss: 2.0228891859772387

Epoch: 6| Step: 12
Training loss: 2.3388099670410156
Validation loss: 2.0235864385481803

Epoch: 6| Step: 13
Training loss: 1.875322937965393
Validation loss: 1.995315738903579

Epoch: 156| Step: 0
Training loss: 1.6533410549163818
Validation loss: 2.0185371239980063

Epoch: 6| Step: 1
Training loss: 2.186609983444214
Validation loss: 2.0529788155709543

Epoch: 6| Step: 2
Training loss: 1.8886594772338867
Validation loss: 2.0339387309166694

Epoch: 6| Step: 3
Training loss: 2.0470292568206787
Validation loss: 2.015008500827256

Epoch: 6| Step: 4
Training loss: 2.4402060508728027
Validation loss: 2.006617684518137

Epoch: 6| Step: 5
Training loss: 2.4503374099731445
Validation loss: 2.017540157482188

Epoch: 6| Step: 6
Training loss: 2.3748555183410645
Validation loss: 2.0183027764802337

Epoch: 6| Step: 7
Training loss: 2.1169490814208984
Validation loss: 2.0101496519580966

Epoch: 6| Step: 8
Training loss: 1.8863441944122314
Validation loss: 2.0139148837776593

Epoch: 6| Step: 9
Training loss: 1.9880746603012085
Validation loss: 2.0193041473306637

Epoch: 6| Step: 10
Training loss: 2.2404801845550537
Validation loss: 2.0148302098756194

Epoch: 6| Step: 11
Training loss: 2.201556444168091
Validation loss: 2.012467363829254

Epoch: 6| Step: 12
Training loss: 1.8324565887451172
Validation loss: 2.01399996460125

Epoch: 6| Step: 13
Training loss: 1.105101227760315
Validation loss: 2.0040540746463242

Epoch: 157| Step: 0
Training loss: 2.1870367527008057
Validation loss: 2.0038358062826176

Epoch: 6| Step: 1
Training loss: 1.9551739692687988
Validation loss: 2.036606252834361

Epoch: 6| Step: 2
Training loss: 2.708057165145874
Validation loss: 2.0469543075048797

Epoch: 6| Step: 3
Training loss: 2.3396997451782227
Validation loss: 2.032729419328833

Epoch: 6| Step: 4
Training loss: 2.238823413848877
Validation loss: 2.0081906831392677

Epoch: 6| Step: 5
Training loss: 1.758344292640686
Validation loss: 1.9998474787640315

Epoch: 6| Step: 6
Training loss: 1.6237379312515259
Validation loss: 1.9817581433121876

Epoch: 6| Step: 7
Training loss: 1.6375632286071777
Validation loss: 1.9729454735273957

Epoch: 6| Step: 8
Training loss: 2.7158830165863037
Validation loss: 1.9748783342299923

Epoch: 6| Step: 9
Training loss: 1.7212095260620117
Validation loss: 1.9680621521447295

Epoch: 6| Step: 10
Training loss: 2.0862762928009033
Validation loss: 1.9702890611463977

Epoch: 6| Step: 11
Training loss: 2.079470157623291
Validation loss: 1.9855719894491217

Epoch: 6| Step: 12
Training loss: 1.527742862701416
Validation loss: 1.9984686438755324

Epoch: 6| Step: 13
Training loss: 1.621695876121521
Validation loss: 2.005096176619171

Epoch: 158| Step: 0
Training loss: 2.6089937686920166
Validation loss: 2.002525855136174

Epoch: 6| Step: 1
Training loss: 1.789475679397583
Validation loss: 2.0240523507518153

Epoch: 6| Step: 2
Training loss: 1.9405450820922852
Validation loss: 2.033682953926825

Epoch: 6| Step: 3
Training loss: 1.9800492525100708
Validation loss: 2.0525851929059593

Epoch: 6| Step: 4
Training loss: 2.7711973190307617
Validation loss: 2.0554536363129974

Epoch: 6| Step: 5
Training loss: 1.7378876209259033
Validation loss: 2.0469255421751287

Epoch: 6| Step: 6
Training loss: 1.5621238946914673
Validation loss: 2.0256251545362574

Epoch: 6| Step: 7
Training loss: 2.2719459533691406
Validation loss: 2.002808842607724

Epoch: 6| Step: 8
Training loss: 2.7241268157958984
Validation loss: 1.992512841378489

Epoch: 6| Step: 9
Training loss: 2.320281505584717
Validation loss: 1.9800525121791388

Epoch: 6| Step: 10
Training loss: 1.4494774341583252
Validation loss: 1.9595440767144645

Epoch: 6| Step: 11
Training loss: 1.9770102500915527
Validation loss: 1.9653194386471984

Epoch: 6| Step: 12
Training loss: 1.5552144050598145
Validation loss: 1.9648165831001856

Epoch: 6| Step: 13
Training loss: 1.5198540687561035
Validation loss: 1.9688700886182888

Epoch: 159| Step: 0
Training loss: 1.6379820108413696
Validation loss: 1.9499387702634257

Epoch: 6| Step: 1
Training loss: 2.1183347702026367
Validation loss: 1.9545469181511992

Epoch: 6| Step: 2
Training loss: 1.8366055488586426
Validation loss: 1.957566330509801

Epoch: 6| Step: 3
Training loss: 1.6622226238250732
Validation loss: 1.9535206197410502

Epoch: 6| Step: 4
Training loss: 2.1471803188323975
Validation loss: 1.956925953588178

Epoch: 6| Step: 5
Training loss: 2.187351703643799
Validation loss: 1.9711207728232107

Epoch: 6| Step: 6
Training loss: 2.4504642486572266
Validation loss: 1.9741034969206779

Epoch: 6| Step: 7
Training loss: 2.399911403656006
Validation loss: 1.9860582582412227

Epoch: 6| Step: 8
Training loss: 1.748297929763794
Validation loss: 1.9958958138701737

Epoch: 6| Step: 9
Training loss: 1.5140469074249268
Validation loss: 2.016855380868399

Epoch: 6| Step: 10
Training loss: 1.6491985321044922
Validation loss: 2.0113897015971522

Epoch: 6| Step: 11
Training loss: 2.037118434906006
Validation loss: 2.0334306096517913

Epoch: 6| Step: 12
Training loss: 2.291191577911377
Validation loss: 2.0267176602476384

Epoch: 6| Step: 13
Training loss: 2.6358721256256104
Validation loss: 2.040079665440385

Epoch: 160| Step: 0
Training loss: 2.095510959625244
Validation loss: 2.0382604393907773

Epoch: 6| Step: 1
Training loss: 2.0059685707092285
Validation loss: 2.0205086174831597

Epoch: 6| Step: 2
Training loss: 2.4118130207061768
Validation loss: 2.0445273845426497

Epoch: 6| Step: 3
Training loss: 1.9056296348571777
Validation loss: 2.037004524661649

Epoch: 6| Step: 4
Training loss: 1.9440358877182007
Validation loss: 2.005316784304957

Epoch: 6| Step: 5
Training loss: 1.628025770187378
Validation loss: 1.9858178797588553

Epoch: 6| Step: 6
Training loss: 2.049630880355835
Validation loss: 2.0077017032971947

Epoch: 6| Step: 7
Training loss: 2.542781352996826
Validation loss: 2.030083626829168

Epoch: 6| Step: 8
Training loss: 2.3401694297790527
Validation loss: 2.0297922703527633

Epoch: 6| Step: 9
Training loss: 2.6986818313598633
Validation loss: 2.028669047099288

Epoch: 6| Step: 10
Training loss: 2.2926788330078125
Validation loss: 2.0080291840337936

Epoch: 6| Step: 11
Training loss: 1.7051429748535156
Validation loss: 1.9790227259359052

Epoch: 6| Step: 12
Training loss: 1.6335612535476685
Validation loss: 1.9643470394995906

Epoch: 6| Step: 13
Training loss: 1.1871705055236816
Validation loss: 2.00405058937688

Epoch: 161| Step: 0
Training loss: 1.6335585117340088
Validation loss: 2.066919649800947

Epoch: 6| Step: 1
Training loss: 1.742281436920166
Validation loss: 2.1050037043069

Epoch: 6| Step: 2
Training loss: 1.920240879058838
Validation loss: 2.1318959574545584

Epoch: 6| Step: 3
Training loss: 2.0016489028930664
Validation loss: 2.132540190091697

Epoch: 6| Step: 4
Training loss: 2.125640392303467
Validation loss: 2.1291121795613277

Epoch: 6| Step: 5
Training loss: 1.973562240600586
Validation loss: 2.073076213559797

Epoch: 6| Step: 6
Training loss: 2.6064324378967285
Validation loss: 2.0354622666553785

Epoch: 6| Step: 7
Training loss: 2.1784656047821045
Validation loss: 2.0291696902244323

Epoch: 6| Step: 8
Training loss: 1.4662508964538574
Validation loss: 2.0151038554406937

Epoch: 6| Step: 9
Training loss: 2.8136281967163086
Validation loss: 2.0214142901923067

Epoch: 6| Step: 10
Training loss: 2.269235134124756
Validation loss: 2.000959647599087

Epoch: 6| Step: 11
Training loss: 1.9783216714859009
Validation loss: 2.0221988308814263

Epoch: 6| Step: 12
Training loss: 2.1361703872680664
Validation loss: 2.0320421393199632

Epoch: 6| Step: 13
Training loss: 2.2721383571624756
Validation loss: 2.0517211524389123

Epoch: 162| Step: 0
Training loss: 2.5684032440185547
Validation loss: 2.092197446412938

Epoch: 6| Step: 1
Training loss: 2.1654462814331055
Validation loss: 2.080007697946282

Epoch: 6| Step: 2
Training loss: 2.8099260330200195
Validation loss: 2.0355483370442546

Epoch: 6| Step: 3
Training loss: 2.274441719055176
Validation loss: 2.0103343391931183

Epoch: 6| Step: 4
Training loss: 2.0423598289489746
Validation loss: 2.0174056919672156

Epoch: 6| Step: 5
Training loss: 1.6838536262512207
Validation loss: 2.0247188652715375

Epoch: 6| Step: 6
Training loss: 2.0733108520507812
Validation loss: 2.0369510214815856

Epoch: 6| Step: 7
Training loss: 1.0172381401062012
Validation loss: 2.059556366294943

Epoch: 6| Step: 8
Training loss: 2.211977958679199
Validation loss: 2.059074601819438

Epoch: 6| Step: 9
Training loss: 0.9897239208221436
Validation loss: 2.044255100270753

Epoch: 6| Step: 10
Training loss: 2.3267672061920166
Validation loss: 2.0613091914884505

Epoch: 6| Step: 11
Training loss: 1.9780001640319824
Validation loss: 2.070354423215312

Epoch: 6| Step: 12
Training loss: 1.6957682371139526
Validation loss: 2.076847650671518

Epoch: 6| Step: 13
Training loss: 3.242467164993286
Validation loss: 2.0460657304333103

Epoch: 163| Step: 0
Training loss: 1.6162538528442383
Validation loss: 2.061934760821763

Epoch: 6| Step: 1
Training loss: 2.56844162940979
Validation loss: 2.057337409706526

Epoch: 6| Step: 2
Training loss: 2.1368603706359863
Validation loss: 2.0525107896456154

Epoch: 6| Step: 3
Training loss: 1.6564773321151733
Validation loss: 2.0544784812517065

Epoch: 6| Step: 4
Training loss: 2.804841995239258
Validation loss: 2.0671560764312744

Epoch: 6| Step: 5
Training loss: 2.1331186294555664
Validation loss: 2.0521742913030807

Epoch: 6| Step: 6
Training loss: 2.049971580505371
Validation loss: 2.0394476177871868

Epoch: 6| Step: 7
Training loss: 2.0944089889526367
Validation loss: 2.041035748297168

Epoch: 6| Step: 8
Training loss: 1.5302777290344238
Validation loss: 2.042819312823716

Epoch: 6| Step: 9
Training loss: 1.7417099475860596
Validation loss: 2.0534836733213035

Epoch: 6| Step: 10
Training loss: 2.0403292179107666
Validation loss: 2.0860613674245854

Epoch: 6| Step: 11
Training loss: 1.5774950981140137
Validation loss: 2.0926953848972114

Epoch: 6| Step: 12
Training loss: 1.8973169326782227
Validation loss: 2.095163429937055

Epoch: 6| Step: 13
Training loss: 2.113778829574585
Validation loss: 2.076222981176069

Epoch: 164| Step: 0
Training loss: 1.990159034729004
Validation loss: 2.0414375194939236

Epoch: 6| Step: 1
Training loss: 1.9233967065811157
Validation loss: 2.0407814031006186

Epoch: 6| Step: 2
Training loss: 2.9901914596557617
Validation loss: 2.0566616199349843

Epoch: 6| Step: 3
Training loss: 2.3523335456848145
Validation loss: 2.0713669689752723

Epoch: 6| Step: 4
Training loss: 1.8116337060928345
Validation loss: 2.0839011182067213

Epoch: 6| Step: 5
Training loss: 1.81014883518219
Validation loss: 2.118016904400241

Epoch: 6| Step: 6
Training loss: 2.152726411819458
Validation loss: 2.1225378820973058

Epoch: 6| Step: 7
Training loss: 1.7068169116973877
Validation loss: 2.100420040469016

Epoch: 6| Step: 8
Training loss: 1.6826691627502441
Validation loss: 2.096472230008853

Epoch: 6| Step: 9
Training loss: 1.9208346605300903
Validation loss: 2.0976028288564375

Epoch: 6| Step: 10
Training loss: 1.9639153480529785
Validation loss: 2.1017062241031277

Epoch: 6| Step: 11
Training loss: 2.13944935798645
Validation loss: 2.081146950362831

Epoch: 6| Step: 12
Training loss: 1.8243952989578247
Validation loss: 2.053671177997384

Epoch: 6| Step: 13
Training loss: 1.3463553190231323
Validation loss: 2.0126477262025237

Epoch: 165| Step: 0
Training loss: 2.2546310424804688
Validation loss: 2.0015694325970066

Epoch: 6| Step: 1
Training loss: 1.893524169921875
Validation loss: 1.9922644040917838

Epoch: 6| Step: 2
Training loss: 2.467751979827881
Validation loss: 1.9963893634016796

Epoch: 6| Step: 3
Training loss: 1.9086108207702637
Validation loss: 1.9840207189641974

Epoch: 6| Step: 4
Training loss: 2.057708501815796
Validation loss: 2.0039763988987094

Epoch: 6| Step: 5
Training loss: 2.023617744445801
Validation loss: 2.008718080418084

Epoch: 6| Step: 6
Training loss: 1.600020170211792
Validation loss: 2.037155084712531

Epoch: 6| Step: 7
Training loss: 2.3755953311920166
Validation loss: 2.0303124330377065

Epoch: 6| Step: 8
Training loss: 1.9060919284820557
Validation loss: 2.0279724982477005

Epoch: 6| Step: 9
Training loss: 2.4217209815979004
Validation loss: 2.0042019787655083

Epoch: 6| Step: 10
Training loss: 2.3508777618408203
Validation loss: 2.007473562353401

Epoch: 6| Step: 11
Training loss: 1.6419392824172974
Validation loss: 2.024735298208011

Epoch: 6| Step: 12
Training loss: 1.6406209468841553
Validation loss: 2.0421285244726364

Epoch: 6| Step: 13
Training loss: 1.589136004447937
Validation loss: 2.050415272353798

Epoch: 166| Step: 0
Training loss: 2.0458827018737793
Validation loss: 2.069970553921115

Epoch: 6| Step: 1
Training loss: 2.2051689624786377
Validation loss: 2.105607230176208

Epoch: 6| Step: 2
Training loss: 1.8849058151245117
Validation loss: 2.1288881122425036

Epoch: 6| Step: 3
Training loss: 2.0055787563323975
Validation loss: 2.1429748471065233

Epoch: 6| Step: 4
Training loss: 2.132101058959961
Validation loss: 2.152950415047266

Epoch: 6| Step: 5
Training loss: 2.0763542652130127
Validation loss: 2.1733343165407897

Epoch: 6| Step: 6
Training loss: 1.6958953142166138
Validation loss: 2.201255726557906

Epoch: 6| Step: 7
Training loss: 1.654099702835083
Validation loss: 2.1709233304505706

Epoch: 6| Step: 8
Training loss: 2.1272237300872803
Validation loss: 2.1611719516015824

Epoch: 6| Step: 9
Training loss: 2.20418643951416
Validation loss: 2.13620561938132

Epoch: 6| Step: 10
Training loss: 1.648660659790039
Validation loss: 2.1033406693448304

Epoch: 6| Step: 11
Training loss: 1.4895775318145752
Validation loss: 2.0710220824005785

Epoch: 6| Step: 12
Training loss: 2.735231876373291
Validation loss: 2.042493874026883

Epoch: 6| Step: 13
Training loss: 1.9429007768630981
Validation loss: 2.0123834251075663

Epoch: 167| Step: 0
Training loss: 1.7020800113677979
Validation loss: 2.0289491145841536

Epoch: 6| Step: 1
Training loss: 1.6957728862762451
Validation loss: 2.040087387125979

Epoch: 6| Step: 2
Training loss: 2.033893346786499
Validation loss: 2.029560463402861

Epoch: 6| Step: 3
Training loss: 2.044649124145508
Validation loss: 2.0377354724432832

Epoch: 6| Step: 4
Training loss: 2.0112862586975098
Validation loss: 2.0259112440129763

Epoch: 6| Step: 5
Training loss: 2.4973983764648438
Validation loss: 2.0141732461990847

Epoch: 6| Step: 6
Training loss: 2.102429151535034
Validation loss: 2.0388085906223585

Epoch: 6| Step: 7
Training loss: 1.8657355308532715
Validation loss: 2.061043563709464

Epoch: 6| Step: 8
Training loss: 1.8127590417861938
Validation loss: 2.0606173712720155

Epoch: 6| Step: 9
Training loss: 1.9083514213562012
Validation loss: 2.0509743254671813

Epoch: 6| Step: 10
Training loss: 2.341360569000244
Validation loss: 2.0496105404310327

Epoch: 6| Step: 11
Training loss: 1.5133056640625
Validation loss: 2.0663812532219836

Epoch: 6| Step: 12
Training loss: 2.4695911407470703
Validation loss: 2.108697473361928

Epoch: 6| Step: 13
Training loss: 1.7550442218780518
Validation loss: 2.116886326061782

Epoch: 168| Step: 0
Training loss: 1.8298654556274414
Validation loss: 2.12940485759448

Epoch: 6| Step: 1
Training loss: 1.4180457592010498
Validation loss: 2.135475645783127

Epoch: 6| Step: 2
Training loss: 2.071521759033203
Validation loss: 2.1531989189886276

Epoch: 6| Step: 3
Training loss: 1.8898168802261353
Validation loss: 2.122900391137728

Epoch: 6| Step: 4
Training loss: 2.2172412872314453
Validation loss: 2.0800863850501274

Epoch: 6| Step: 5
Training loss: 2.4513139724731445
Validation loss: 2.0683962760433072

Epoch: 6| Step: 6
Training loss: 1.9521170854568481
Validation loss: 2.044877349689443

Epoch: 6| Step: 7
Training loss: 1.7752656936645508
Validation loss: 2.021327443020318

Epoch: 6| Step: 8
Training loss: 1.948626160621643
Validation loss: 2.015573631050766

Epoch: 6| Step: 9
Training loss: 2.20478892326355
Validation loss: 2.008288583447856

Epoch: 6| Step: 10
Training loss: 2.224735975265503
Validation loss: 2.002287087901946

Epoch: 6| Step: 11
Training loss: 2.178131341934204
Validation loss: 1.9997668394478418

Epoch: 6| Step: 12
Training loss: 1.055168628692627
Validation loss: 2.0287051623867405

Epoch: 6| Step: 13
Training loss: 2.444295644760132
Validation loss: 2.0201235471233243

Epoch: 169| Step: 0
Training loss: 1.745740532875061
Validation loss: 2.030471449257225

Epoch: 6| Step: 1
Training loss: 2.48353910446167
Validation loss: 2.0269542201872794

Epoch: 6| Step: 2
Training loss: 1.676630973815918
Validation loss: 2.018106483644055

Epoch: 6| Step: 3
Training loss: 2.7269487380981445
Validation loss: 2.0216614789860223

Epoch: 6| Step: 4
Training loss: 1.6956864595413208
Validation loss: 2.0281039271303403

Epoch: 6| Step: 5
Training loss: 1.3768696784973145
Validation loss: 2.0152400975586264

Epoch: 6| Step: 6
Training loss: 2.0689938068389893
Validation loss: 2.008399513459975

Epoch: 6| Step: 7
Training loss: 2.4019036293029785
Validation loss: 2.040065691035281

Epoch: 6| Step: 8
Training loss: 1.9330809116363525
Validation loss: 2.070641506102777

Epoch: 6| Step: 9
Training loss: 1.7414060831069946
Validation loss: 2.0892404074309976

Epoch: 6| Step: 10
Training loss: 1.8495776653289795
Validation loss: 2.05637050572262

Epoch: 6| Step: 11
Training loss: 2.2010035514831543
Validation loss: 2.029237320346217

Epoch: 6| Step: 12
Training loss: 1.9432146549224854
Validation loss: 1.9908851244116341

Epoch: 6| Step: 13
Training loss: 1.8168752193450928
Validation loss: 2.009618487409366

Epoch: 170| Step: 0
Training loss: 1.4584696292877197
Validation loss: 2.030832452158774

Epoch: 6| Step: 1
Training loss: 1.5692857503890991
Validation loss: 2.0307841390691777

Epoch: 6| Step: 2
Training loss: 1.4893336296081543
Validation loss: 2.0249742820698726

Epoch: 6| Step: 3
Training loss: 2.973724365234375
Validation loss: 2.0183151665554253

Epoch: 6| Step: 4
Training loss: 2.3096916675567627
Validation loss: 2.024302306995597

Epoch: 6| Step: 5
Training loss: 1.9078917503356934
Validation loss: 2.0195511092421827

Epoch: 6| Step: 6
Training loss: 2.1929931640625
Validation loss: 2.0093152574313584

Epoch: 6| Step: 7
Training loss: 2.3433499336242676
Validation loss: 2.022009321438369

Epoch: 6| Step: 8
Training loss: 1.1632025241851807
Validation loss: 2.0115838973752913

Epoch: 6| Step: 9
Training loss: 2.062285900115967
Validation loss: 2.0216861642817014

Epoch: 6| Step: 10
Training loss: 2.591338634490967
Validation loss: 2.04387830662471

Epoch: 6| Step: 11
Training loss: 2.0091538429260254
Validation loss: 2.0490039907475954

Epoch: 6| Step: 12
Training loss: 1.8595649003982544
Validation loss: 2.053324104637228

Epoch: 6| Step: 13
Training loss: 2.064222812652588
Validation loss: 2.070081559560632

Epoch: 171| Step: 0
Training loss: 2.60903263092041
Validation loss: 2.079237017580258

Epoch: 6| Step: 1
Training loss: 1.2383360862731934
Validation loss: 2.0939016906164025

Epoch: 6| Step: 2
Training loss: 2.1778578758239746
Validation loss: 2.1130213019668416

Epoch: 6| Step: 3
Training loss: 1.7658052444458008
Validation loss: 2.1092810246252243

Epoch: 6| Step: 4
Training loss: 1.5465757846832275
Validation loss: 2.0964264074961343

Epoch: 6| Step: 5
Training loss: 2.523247718811035
Validation loss: 2.0881335453320573

Epoch: 6| Step: 6
Training loss: 1.7274678945541382
Validation loss: 2.067153822991156

Epoch: 6| Step: 7
Training loss: 2.1257681846618652
Validation loss: 2.05018997833293

Epoch: 6| Step: 8
Training loss: 1.5623832941055298
Validation loss: 2.0397698315241004

Epoch: 6| Step: 9
Training loss: 2.4285054206848145
Validation loss: 2.034968635087372

Epoch: 6| Step: 10
Training loss: 2.2898902893066406
Validation loss: 2.0568300780429634

Epoch: 6| Step: 11
Training loss: 1.5173407793045044
Validation loss: 2.0826389533217236

Epoch: 6| Step: 12
Training loss: 2.003706693649292
Validation loss: 2.0770569309111564

Epoch: 6| Step: 13
Training loss: 1.8208460807800293
Validation loss: 2.0828827940007693

Epoch: 172| Step: 0
Training loss: 1.518613338470459
Validation loss: 2.0620653219120477

Epoch: 6| Step: 1
Training loss: 1.364263892173767
Validation loss: 2.0599417583916777

Epoch: 6| Step: 2
Training loss: 2.2887117862701416
Validation loss: 2.055093308930756

Epoch: 6| Step: 3
Training loss: 1.9587814807891846
Validation loss: 2.0534912206793345

Epoch: 6| Step: 4
Training loss: 1.7661052942276
Validation loss: 2.048813731439652

Epoch: 6| Step: 5
Training loss: 1.7657619714736938
Validation loss: 2.0285707968537525

Epoch: 6| Step: 6
Training loss: 2.229937791824341
Validation loss: 2.0343771801199964

Epoch: 6| Step: 7
Training loss: 2.267949104309082
Validation loss: 2.0239255133495537

Epoch: 6| Step: 8
Training loss: 1.2690832614898682
Validation loss: 2.039739083218318

Epoch: 6| Step: 9
Training loss: 1.8507537841796875
Validation loss: 2.052471814617034

Epoch: 6| Step: 10
Training loss: 2.4541242122650146
Validation loss: 2.0984537191288446

Epoch: 6| Step: 11
Training loss: 2.2283873558044434
Validation loss: 2.100540799479331

Epoch: 6| Step: 12
Training loss: 1.946370244026184
Validation loss: 2.1116690968954437

Epoch: 6| Step: 13
Training loss: 1.7553199529647827
Validation loss: 2.113490855821999

Epoch: 173| Step: 0
Training loss: 1.7501665353775024
Validation loss: 2.064889379726943

Epoch: 6| Step: 1
Training loss: 1.4584897756576538
Validation loss: 2.0424969324501614

Epoch: 6| Step: 2
Training loss: 2.3106820583343506
Validation loss: 2.0310815636829664

Epoch: 6| Step: 3
Training loss: 1.7337565422058105
Validation loss: 2.0263084621839624

Epoch: 6| Step: 4
Training loss: 1.9952846765518188
Validation loss: 2.0170658878100816

Epoch: 6| Step: 5
Training loss: 2.2751169204711914
Validation loss: 2.0162152744108632

Epoch: 6| Step: 6
Training loss: 1.1266230344772339
Validation loss: 2.0173034270604453

Epoch: 6| Step: 7
Training loss: 2.227062702178955
Validation loss: 2.0309157884249123

Epoch: 6| Step: 8
Training loss: 2.2079362869262695
Validation loss: 2.0336768934803624

Epoch: 6| Step: 9
Training loss: 1.641439437866211
Validation loss: 2.047467508623677

Epoch: 6| Step: 10
Training loss: 2.815865993499756
Validation loss: 2.0586597611827235

Epoch: 6| Step: 11
Training loss: 1.8644204139709473
Validation loss: 2.0681126066433486

Epoch: 6| Step: 12
Training loss: 1.761425256729126
Validation loss: 2.0867077714653424

Epoch: 6| Step: 13
Training loss: 1.1786869764328003
Validation loss: 2.080481142126104

Epoch: 174| Step: 0
Training loss: 1.296750783920288
Validation loss: 2.092887081125731

Epoch: 6| Step: 1
Training loss: 1.947815179824829
Validation loss: 2.1091130677089898

Epoch: 6| Step: 2
Training loss: 1.2228829860687256
Validation loss: 2.109818285511386

Epoch: 6| Step: 3
Training loss: 2.0948665142059326
Validation loss: 2.1055332435074674

Epoch: 6| Step: 4
Training loss: 2.145176887512207
Validation loss: 2.104356655510523

Epoch: 6| Step: 5
Training loss: 1.9290225505828857
Validation loss: 2.0930301130458875

Epoch: 6| Step: 6
Training loss: 1.940169095993042
Validation loss: 2.074721920874811

Epoch: 6| Step: 7
Training loss: 2.3328468799591064
Validation loss: 2.065101497916765

Epoch: 6| Step: 8
Training loss: 2.0352184772491455
Validation loss: 2.0405152408025597

Epoch: 6| Step: 9
Training loss: 1.8540148735046387
Validation loss: 2.0332875149224394

Epoch: 6| Step: 10
Training loss: 1.8921197652816772
Validation loss: 2.026216189066569

Epoch: 6| Step: 11
Training loss: 2.359220027923584
Validation loss: 2.022104727324619

Epoch: 6| Step: 12
Training loss: 1.0466848611831665
Validation loss: 1.9940763750383932

Epoch: 6| Step: 13
Training loss: 2.6670806407928467
Validation loss: 1.9952515286784018

Epoch: 175| Step: 0
Training loss: 1.7563753128051758
Validation loss: 2.013688870655593

Epoch: 6| Step: 1
Training loss: 2.309520721435547
Validation loss: 1.998533123282976

Epoch: 6| Step: 2
Training loss: 1.623572826385498
Validation loss: 2.009858049372191

Epoch: 6| Step: 3
Training loss: 1.5282589197158813
Validation loss: 2.0566695877300796

Epoch: 6| Step: 4
Training loss: 2.347742795944214
Validation loss: 2.0901242981674852

Epoch: 6| Step: 5
Training loss: 2.2431442737579346
Validation loss: 2.094322399426532

Epoch: 6| Step: 6
Training loss: 2.33219051361084
Validation loss: 2.1202953374514015

Epoch: 6| Step: 7
Training loss: 1.6160284280776978
Validation loss: 2.132051726823212

Epoch: 6| Step: 8
Training loss: 1.660530686378479
Validation loss: 2.1468234062194824

Epoch: 6| Step: 9
Training loss: 2.014162063598633
Validation loss: 2.1353471022780224

Epoch: 6| Step: 10
Training loss: 1.9565808773040771
Validation loss: 2.1205865631821337

Epoch: 6| Step: 11
Training loss: 1.747171401977539
Validation loss: 2.106252388287616

Epoch: 6| Step: 12
Training loss: 1.588477611541748
Validation loss: 2.109216337562889

Epoch: 6| Step: 13
Training loss: 1.5628596544265747
Validation loss: 2.0912859926941576

Epoch: 176| Step: 0
Training loss: 1.954709768295288
Validation loss: 2.077264198692896

Epoch: 6| Step: 1
Training loss: 1.8312504291534424
Validation loss: 2.04961141719613

Epoch: 6| Step: 2
Training loss: 1.6680196523666382
Validation loss: 2.0515513279104747

Epoch: 6| Step: 3
Training loss: 1.835207462310791
Validation loss: 2.0432775302599837

Epoch: 6| Step: 4
Training loss: 1.755353569984436
Validation loss: 2.04391893007422

Epoch: 6| Step: 5
Training loss: 1.4246046543121338
Validation loss: 2.052684809571953

Epoch: 6| Step: 6
Training loss: 2.019674062728882
Validation loss: 2.0479298304486018

Epoch: 6| Step: 7
Training loss: 2.20674467086792
Validation loss: 2.0516246416235484

Epoch: 6| Step: 8
Training loss: 2.8269944190979004
Validation loss: 2.0425260477168585

Epoch: 6| Step: 9
Training loss: 2.4710001945495605
Validation loss: 2.0685465207663913

Epoch: 6| Step: 10
Training loss: 1.1128054857254028
Validation loss: 2.0505027732541485

Epoch: 6| Step: 11
Training loss: 2.4440224170684814
Validation loss: 2.037777086739899

Epoch: 6| Step: 12
Training loss: 1.2422970533370972
Validation loss: 2.025647537682646

Epoch: 6| Step: 13
Training loss: 1.7061316967010498
Validation loss: 2.039673591172823

Epoch: 177| Step: 0
Training loss: 2.1375861167907715
Validation loss: 2.041555440554055

Epoch: 6| Step: 1
Training loss: 1.7692981958389282
Validation loss: 2.0563876269966044

Epoch: 6| Step: 2
Training loss: 1.282550573348999
Validation loss: 2.060803160872511

Epoch: 6| Step: 3
Training loss: 1.8016319274902344
Validation loss: 2.0810831669838197

Epoch: 6| Step: 4
Training loss: 1.634568214416504
Validation loss: 2.08757358981717

Epoch: 6| Step: 5
Training loss: 2.1309072971343994
Validation loss: 2.086701241872644

Epoch: 6| Step: 6
Training loss: 1.2495806217193604
Validation loss: 2.089434108426494

Epoch: 6| Step: 7
Training loss: 1.5138555765151978
Validation loss: 2.0950186175684773

Epoch: 6| Step: 8
Training loss: 2.713071823120117
Validation loss: 2.088390632342267

Epoch: 6| Step: 9
Training loss: 1.7075716257095337
Validation loss: 2.0911951154790898

Epoch: 6| Step: 10
Training loss: 1.9669203758239746
Validation loss: 2.06609635455634

Epoch: 6| Step: 11
Training loss: 2.3123621940612793
Validation loss: 2.057437781364687

Epoch: 6| Step: 12
Training loss: 1.6494983434677124
Validation loss: 2.049534425940565

Epoch: 6| Step: 13
Training loss: 2.074122428894043
Validation loss: 2.0560812873225056

Epoch: 178| Step: 0
Training loss: 2.255960702896118
Validation loss: 2.0701521186418432

Epoch: 6| Step: 1
Training loss: 1.9884161949157715
Validation loss: 2.0762147134350193

Epoch: 6| Step: 2
Training loss: 1.5811158418655396
Validation loss: 2.1001006582731843

Epoch: 6| Step: 3
Training loss: 1.5446590185165405
Validation loss: 2.116289605376541

Epoch: 6| Step: 4
Training loss: 1.6259958744049072
Validation loss: 2.126318670088245

Epoch: 6| Step: 5
Training loss: 2.240147590637207
Validation loss: 2.1530425933099564

Epoch: 6| Step: 6
Training loss: 1.81908118724823
Validation loss: 2.196110940748645

Epoch: 6| Step: 7
Training loss: 2.2342119216918945
Validation loss: 2.1857552707836194

Epoch: 6| Step: 8
Training loss: 1.9907317161560059
Validation loss: 2.1369941247406827

Epoch: 6| Step: 9
Training loss: 1.7789273262023926
Validation loss: 2.0872378451849825

Epoch: 6| Step: 10
Training loss: 1.9191023111343384
Validation loss: 2.0407147279349704

Epoch: 6| Step: 11
Training loss: 1.789151668548584
Validation loss: 2.033551614771607

Epoch: 6| Step: 12
Training loss: 1.7841198444366455
Validation loss: 2.025267953513771

Epoch: 6| Step: 13
Training loss: 1.5139145851135254
Validation loss: 2.026041241102321

Epoch: 179| Step: 0
Training loss: 2.0520410537719727
Validation loss: 2.0243210472086424

Epoch: 6| Step: 1
Training loss: 1.3878848552703857
Validation loss: 2.0244464207721014

Epoch: 6| Step: 2
Training loss: 2.2325429916381836
Validation loss: 1.9894432406271658

Epoch: 6| Step: 3
Training loss: 1.6416538953781128
Validation loss: 1.9665345940538632

Epoch: 6| Step: 4
Training loss: 1.4979523420333862
Validation loss: 1.9756061851337392

Epoch: 6| Step: 5
Training loss: 1.981586217880249
Validation loss: 1.9768005827421784

Epoch: 6| Step: 6
Training loss: 2.2414493560791016
Validation loss: 1.9900707583273611

Epoch: 6| Step: 7
Training loss: 2.5237035751342773
Validation loss: 1.9889972312476045

Epoch: 6| Step: 8
Training loss: 1.7720141410827637
Validation loss: 2.026949600506854

Epoch: 6| Step: 9
Training loss: 1.3547250032424927
Validation loss: 2.041128022696382

Epoch: 6| Step: 10
Training loss: 2.1896698474884033
Validation loss: 2.078721143866098

Epoch: 6| Step: 11
Training loss: 1.4674732685089111
Validation loss: 2.112327109100998

Epoch: 6| Step: 12
Training loss: 2.3233022689819336
Validation loss: 2.1221649646759033

Epoch: 6| Step: 13
Training loss: 2.1889657974243164
Validation loss: 2.1376503436796126

Epoch: 180| Step: 0
Training loss: 2.7548418045043945
Validation loss: 2.1415156882296325

Epoch: 6| Step: 1
Training loss: 2.115907669067383
Validation loss: 2.1321323943394486

Epoch: 6| Step: 2
Training loss: 1.545518398284912
Validation loss: 2.112374464670817

Epoch: 6| Step: 3
Training loss: 1.479528546333313
Validation loss: 2.0805633952540736

Epoch: 6| Step: 4
Training loss: 1.578076958656311
Validation loss: 2.060666602144959

Epoch: 6| Step: 5
Training loss: 2.7111358642578125
Validation loss: 2.0476560515742146

Epoch: 6| Step: 6
Training loss: 2.3662052154541016
Validation loss: 2.0462925011111843

Epoch: 6| Step: 7
Training loss: 1.4316154718399048
Validation loss: 2.046214613863217

Epoch: 6| Step: 8
Training loss: 1.716907024383545
Validation loss: 2.055010932748036

Epoch: 6| Step: 9
Training loss: 1.5978455543518066
Validation loss: 2.042622443168394

Epoch: 6| Step: 10
Training loss: 2.3404245376586914
Validation loss: 2.031129669117671

Epoch: 6| Step: 11
Training loss: 2.1696271896362305
Validation loss: 2.0195401163511377

Epoch: 6| Step: 12
Training loss: 1.3860106468200684
Validation loss: 1.993224682346467

Epoch: 6| Step: 13
Training loss: 0.713166356086731
Validation loss: 1.9761087561166415

Epoch: 181| Step: 0
Training loss: 1.873894453048706
Validation loss: 1.9919406149976997

Epoch: 6| Step: 1
Training loss: 2.1715192794799805
Validation loss: 1.9932257565118934

Epoch: 6| Step: 2
Training loss: 1.3255245685577393
Validation loss: 2.023150131266604

Epoch: 6| Step: 3
Training loss: 1.5929877758026123
Validation loss: 2.037548121585641

Epoch: 6| Step: 4
Training loss: 2.1389527320861816
Validation loss: 2.036732530081144

Epoch: 6| Step: 5
Training loss: 1.1341402530670166
Validation loss: 2.0337226275474793

Epoch: 6| Step: 6
Training loss: 1.772463321685791
Validation loss: 2.0631967026700258

Epoch: 6| Step: 7
Training loss: 1.7517037391662598
Validation loss: 2.0726874515574467

Epoch: 6| Step: 8
Training loss: 2.0516443252563477
Validation loss: 2.0648099145581646

Epoch: 6| Step: 9
Training loss: 2.037594795227051
Validation loss: 2.082697747856058

Epoch: 6| Step: 10
Training loss: 1.8207416534423828
Validation loss: 2.085303477061692

Epoch: 6| Step: 11
Training loss: 1.9148246049880981
Validation loss: 2.096545462967247

Epoch: 6| Step: 12
Training loss: 2.429927110671997
Validation loss: 2.076225911417315

Epoch: 6| Step: 13
Training loss: 1.7266510725021362
Validation loss: 2.0717355871713288

Epoch: 182| Step: 0
Training loss: 2.3208351135253906
Validation loss: 2.0807461046403453

Epoch: 6| Step: 1
Training loss: 1.8070464134216309
Validation loss: 2.0788763940975232

Epoch: 6| Step: 2
Training loss: 1.6360623836517334
Validation loss: 2.0671540844825005

Epoch: 6| Step: 3
Training loss: 1.3517744541168213
Validation loss: 2.077639930991716

Epoch: 6| Step: 4
Training loss: 1.9796066284179688
Validation loss: 2.080062468846639

Epoch: 6| Step: 5
Training loss: 1.9335455894470215
Validation loss: 2.0849463683302685

Epoch: 6| Step: 6
Training loss: 1.926662564277649
Validation loss: 2.1011948559873845

Epoch: 6| Step: 7
Training loss: 1.5077322721481323
Validation loss: 2.103064440911816

Epoch: 6| Step: 8
Training loss: 2.2528433799743652
Validation loss: 2.1183662235095935

Epoch: 6| Step: 9
Training loss: 2.2327146530151367
Validation loss: 2.130887177682692

Epoch: 6| Step: 10
Training loss: 1.2879605293273926
Validation loss: 2.078150180078322

Epoch: 6| Step: 11
Training loss: 2.2823739051818848
Validation loss: 2.080249822267922

Epoch: 6| Step: 12
Training loss: 0.9345903992652893
Validation loss: 2.045537192334411

Epoch: 6| Step: 13
Training loss: 1.8729498386383057
Validation loss: 2.040502073944256

Epoch: 183| Step: 0
Training loss: 1.9249250888824463
Validation loss: 2.031372703531737

Epoch: 6| Step: 1
Training loss: 1.377460241317749
Validation loss: 2.0309743945316603

Epoch: 6| Step: 2
Training loss: 1.9983279705047607
Validation loss: 2.0361822933279057

Epoch: 6| Step: 3
Training loss: 2.2467713356018066
Validation loss: 2.05066236629281

Epoch: 6| Step: 4
Training loss: 2.201467514038086
Validation loss: 2.055272776593444

Epoch: 6| Step: 5
Training loss: 1.253191590309143
Validation loss: 2.034820815568329

Epoch: 6| Step: 6
Training loss: 1.7457560300827026
Validation loss: 2.0455963688512004

Epoch: 6| Step: 7
Training loss: 1.7576074600219727
Validation loss: 2.05164013883119

Epoch: 6| Step: 8
Training loss: 1.3606648445129395
Validation loss: 2.0337800928341445

Epoch: 6| Step: 9
Training loss: 1.61454176902771
Validation loss: 2.065972133349347

Epoch: 6| Step: 10
Training loss: 1.8049726486206055
Validation loss: 2.0730832802352084

Epoch: 6| Step: 11
Training loss: 2.597405433654785
Validation loss: 2.109582362636443

Epoch: 6| Step: 12
Training loss: 1.6614561080932617
Validation loss: 2.1199223687571864

Epoch: 6| Step: 13
Training loss: 1.502606749534607
Validation loss: 2.120584487915039

Epoch: 184| Step: 0
Training loss: 2.067729949951172
Validation loss: 2.115234153245085

Epoch: 6| Step: 1
Training loss: 1.8007335662841797
Validation loss: 2.098610375517158

Epoch: 6| Step: 2
Training loss: 1.3567852973937988
Validation loss: 2.0866390966599986

Epoch: 6| Step: 3
Training loss: 2.346430540084839
Validation loss: 2.059152503167429

Epoch: 6| Step: 4
Training loss: 1.9902925491333008
Validation loss: 2.0731618506934053

Epoch: 6| Step: 5
Training loss: 1.3908149003982544
Validation loss: 2.0653005389757055

Epoch: 6| Step: 6
Training loss: 2.0472230911254883
Validation loss: 2.067342588978429

Epoch: 6| Step: 7
Training loss: 1.6525030136108398
Validation loss: 2.07736684045484

Epoch: 6| Step: 8
Training loss: 2.274317741394043
Validation loss: 2.074039823265486

Epoch: 6| Step: 9
Training loss: 1.6583034992218018
Validation loss: 2.065880255032611

Epoch: 6| Step: 10
Training loss: 1.5547384023666382
Validation loss: 2.0581423595387447

Epoch: 6| Step: 11
Training loss: 1.3660099506378174
Validation loss: 2.052124436183642

Epoch: 6| Step: 12
Training loss: 1.624476671218872
Validation loss: 2.0439544108606156

Epoch: 6| Step: 13
Training loss: 1.9725499153137207
Validation loss: 2.0577058099931285

Epoch: 185| Step: 0
Training loss: 1.8246986865997314
Validation loss: 2.079908296626101

Epoch: 6| Step: 1
Training loss: 2.046353340148926
Validation loss: 2.0814774908045286

Epoch: 6| Step: 2
Training loss: 1.346387505531311
Validation loss: 2.07095996538798

Epoch: 6| Step: 3
Training loss: 1.9771748781204224
Validation loss: 2.057019434949403

Epoch: 6| Step: 4
Training loss: 1.6226438283920288
Validation loss: 2.0626442278585126

Epoch: 6| Step: 5
Training loss: 2.5166361331939697
Validation loss: 2.0392610142307896

Epoch: 6| Step: 6
Training loss: 1.186333417892456
Validation loss: 2.0260243082559235

Epoch: 6| Step: 7
Training loss: 1.7454743385314941
Validation loss: 2.055330148307226

Epoch: 6| Step: 8
Training loss: 1.573033094406128
Validation loss: 2.044551691701335

Epoch: 6| Step: 9
Training loss: 2.2694919109344482
Validation loss: 2.0661213269797702

Epoch: 6| Step: 10
Training loss: 1.8296968936920166
Validation loss: 2.0808451124416885

Epoch: 6| Step: 11
Training loss: 1.7607667446136475
Validation loss: 2.086102795857255

Epoch: 6| Step: 12
Training loss: 1.5668803453445435
Validation loss: 2.0961435687157417

Epoch: 6| Step: 13
Training loss: 1.5360854864120483
Validation loss: 2.109443772223688

Epoch: 186| Step: 0
Training loss: 1.1903854608535767
Validation loss: 2.1285901710551274

Epoch: 6| Step: 1
Training loss: 1.7592058181762695
Validation loss: 2.1237480948048253

Epoch: 6| Step: 2
Training loss: 2.439039468765259
Validation loss: 2.113480547423004

Epoch: 6| Step: 3
Training loss: 1.7042841911315918
Validation loss: 2.11754394731214

Epoch: 6| Step: 4
Training loss: 1.3390698432922363
Validation loss: 2.1100312843117663

Epoch: 6| Step: 5
Training loss: 1.5907806158065796
Validation loss: 2.0899955662347938

Epoch: 6| Step: 6
Training loss: 2.689055919647217
Validation loss: 2.100916620223753

Epoch: 6| Step: 7
Training loss: 1.469963788986206
Validation loss: 2.0687735516537904

Epoch: 6| Step: 8
Training loss: 1.5388028621673584
Validation loss: 2.0684218560495684

Epoch: 6| Step: 9
Training loss: 2.5281224250793457
Validation loss: 2.0608064038779146

Epoch: 6| Step: 10
Training loss: 1.9106318950653076
Validation loss: 2.061313936787267

Epoch: 6| Step: 11
Training loss: 1.2352445125579834
Validation loss: 2.052772384817882

Epoch: 6| Step: 12
Training loss: 1.9997059106826782
Validation loss: 2.052210743709277

Epoch: 6| Step: 13
Training loss: 1.404478907585144
Validation loss: 2.067774631643808

Epoch: 187| Step: 0
Training loss: 0.9799471497535706
Validation loss: 2.101156242432133

Epoch: 6| Step: 1
Training loss: 1.8778398036956787
Validation loss: 2.089746211164741

Epoch: 6| Step: 2
Training loss: 1.5462279319763184
Validation loss: 2.1132987635110014

Epoch: 6| Step: 3
Training loss: 1.5037953853607178
Validation loss: 2.130240078895323

Epoch: 6| Step: 4
Training loss: 2.701359987258911
Validation loss: 2.1387099181452105

Epoch: 6| Step: 5
Training loss: 1.547192096710205
Validation loss: 2.1074694984702655

Epoch: 6| Step: 6
Training loss: 1.9523649215698242
Validation loss: 2.1160145241727113

Epoch: 6| Step: 7
Training loss: 1.759669303894043
Validation loss: 2.0792275269826255

Epoch: 6| Step: 8
Training loss: 2.181918144226074
Validation loss: 2.0803652988967074

Epoch: 6| Step: 9
Training loss: 1.9222643375396729
Validation loss: 2.058500777008713

Epoch: 6| Step: 10
Training loss: 2.0622634887695312
Validation loss: 2.0631029323865007

Epoch: 6| Step: 11
Training loss: 1.523537516593933
Validation loss: 2.0639254662298385

Epoch: 6| Step: 12
Training loss: 1.8301767110824585
Validation loss: 2.058138046213376

Epoch: 6| Step: 13
Training loss: 1.169991135597229
Validation loss: 2.0340370593532437

Epoch: 188| Step: 0
Training loss: 2.407421827316284
Validation loss: 2.0417656488316034

Epoch: 6| Step: 1
Training loss: 1.548738718032837
Validation loss: 2.045455922362625

Epoch: 6| Step: 2
Training loss: 1.9541051387786865
Validation loss: 2.0405019175621772

Epoch: 6| Step: 3
Training loss: 1.9747505187988281
Validation loss: 2.0607205719076176

Epoch: 6| Step: 4
Training loss: 1.687542200088501
Validation loss: 2.072987990994607

Epoch: 6| Step: 5
Training loss: 1.1301525831222534
Validation loss: 2.094889756171934

Epoch: 6| Step: 6
Training loss: 1.696886420249939
Validation loss: 2.0853408100784465

Epoch: 6| Step: 7
Training loss: 1.5967848300933838
Validation loss: 2.090823786233061

Epoch: 6| Step: 8
Training loss: 1.4431166648864746
Validation loss: 2.073172246256182

Epoch: 6| Step: 9
Training loss: 1.455403447151184
Validation loss: 2.0731670395020516

Epoch: 6| Step: 10
Training loss: 2.228625774383545
Validation loss: 2.046090490074568

Epoch: 6| Step: 11
Training loss: 2.224090099334717
Validation loss: 2.028238829746041

Epoch: 6| Step: 12
Training loss: 1.671750783920288
Validation loss: 2.037154459184216

Epoch: 6| Step: 13
Training loss: 0.8277544379234314
Validation loss: 2.043434607085361

Epoch: 189| Step: 0
Training loss: 2.3001370429992676
Validation loss: 2.0707873734094764

Epoch: 6| Step: 1
Training loss: 1.6150236129760742
Validation loss: 2.1201764588714926

Epoch: 6| Step: 2
Training loss: 2.256479024887085
Validation loss: 2.1288515342179166

Epoch: 6| Step: 3
Training loss: 1.3020564317703247
Validation loss: 2.1480538204152095

Epoch: 6| Step: 4
Training loss: 1.5094680786132812
Validation loss: 2.1457413563164334

Epoch: 6| Step: 5
Training loss: 2.1253740787506104
Validation loss: 2.153996573981418

Epoch: 6| Step: 6
Training loss: 2.5501790046691895
Validation loss: 2.1333129816157843

Epoch: 6| Step: 7
Training loss: 1.4973502159118652
Validation loss: 2.12326874784244

Epoch: 6| Step: 8
Training loss: 1.4043607711791992
Validation loss: 2.1328127256003757

Epoch: 6| Step: 9
Training loss: 1.290801763534546
Validation loss: 2.1211901992879887

Epoch: 6| Step: 10
Training loss: 1.5704689025878906
Validation loss: 2.1059554238473215

Epoch: 6| Step: 11
Training loss: 1.302682638168335
Validation loss: 2.102672683295383

Epoch: 6| Step: 12
Training loss: 1.648853063583374
Validation loss: 2.097132564872824

Epoch: 6| Step: 13
Training loss: 2.054551124572754
Validation loss: 2.103332354176429

Epoch: 190| Step: 0
Training loss: 1.9810476303100586
Validation loss: 2.1088683002738544

Epoch: 6| Step: 1
Training loss: 1.8273380994796753
Validation loss: 2.1041555789209183

Epoch: 6| Step: 2
Training loss: 1.485007643699646
Validation loss: 2.118715129872804

Epoch: 6| Step: 3
Training loss: 1.623699426651001
Validation loss: 2.0890518978077877

Epoch: 6| Step: 4
Training loss: 2.0216779708862305
Validation loss: 2.0506361761400775

Epoch: 6| Step: 5
Training loss: 1.423683762550354
Validation loss: 2.0400594677976382

Epoch: 6| Step: 6
Training loss: 1.741497278213501
Validation loss: 2.0507801835254957

Epoch: 6| Step: 7
Training loss: 2.108443260192871
Validation loss: 2.0590077010534142

Epoch: 6| Step: 8
Training loss: 1.713838815689087
Validation loss: 2.08196109853765

Epoch: 6| Step: 9
Training loss: 1.9149965047836304
Validation loss: 2.096624687153806

Epoch: 6| Step: 10
Training loss: 2.313504695892334
Validation loss: 2.120658620711296

Epoch: 6| Step: 11
Training loss: 1.3643484115600586
Validation loss: 2.1390701788727955

Epoch: 6| Step: 12
Training loss: 0.9934958815574646
Validation loss: 2.1051264347568637

Epoch: 6| Step: 13
Training loss: 1.7008895874023438
Validation loss: 2.1256064189377653

Epoch: 191| Step: 0
Training loss: 2.384073495864868
Validation loss: 2.105190287354172

Epoch: 6| Step: 1
Training loss: 1.3779114484786987
Validation loss: 2.0969482442384124

Epoch: 6| Step: 2
Training loss: 2.329719066619873
Validation loss: 2.092666720831266

Epoch: 6| Step: 3
Training loss: 1.9330635070800781
Validation loss: 2.080113322504105

Epoch: 6| Step: 4
Training loss: 1.3768668174743652
Validation loss: 2.066324428845477

Epoch: 6| Step: 5
Training loss: 0.9933124780654907
Validation loss: 2.058371090119885

Epoch: 6| Step: 6
Training loss: 1.716404676437378
Validation loss: 2.075529767620948

Epoch: 6| Step: 7
Training loss: 1.9014019966125488
Validation loss: 2.0533771527710782

Epoch: 6| Step: 8
Training loss: 1.3972089290618896
Validation loss: 2.0630684232199066

Epoch: 6| Step: 9
Training loss: 1.9175972938537598
Validation loss: 2.0611440981588056

Epoch: 6| Step: 10
Training loss: 1.509782314300537
Validation loss: 2.070972265735749

Epoch: 6| Step: 11
Training loss: 1.7414164543151855
Validation loss: 2.063949905416017

Epoch: 6| Step: 12
Training loss: 1.7579900026321411
Validation loss: 2.0653299875156854

Epoch: 6| Step: 13
Training loss: 1.616288661956787
Validation loss: 2.0475169048514417

Epoch: 192| Step: 0
Training loss: 1.9035258293151855
Validation loss: 2.07125223195681

Epoch: 6| Step: 1
Training loss: 1.7962230443954468
Validation loss: 2.0856873540468115

Epoch: 6| Step: 2
Training loss: 2.0104620456695557
Validation loss: 2.0790356653992847

Epoch: 6| Step: 3
Training loss: 1.2896569967269897
Validation loss: 2.081533590952555

Epoch: 6| Step: 4
Training loss: 1.2911136150360107
Validation loss: 2.0806411389381654

Epoch: 6| Step: 5
Training loss: 1.5447845458984375
Validation loss: 2.1070460991192888

Epoch: 6| Step: 6
Training loss: 1.4892678260803223
Validation loss: 2.0975430575750207

Epoch: 6| Step: 7
Training loss: 2.171896457672119
Validation loss: 2.080897154346589

Epoch: 6| Step: 8
Training loss: 1.7329909801483154
Validation loss: 2.060764783172197

Epoch: 6| Step: 9
Training loss: 1.6393376588821411
Validation loss: 2.0403462533027894

Epoch: 6| Step: 10
Training loss: 1.4805084466934204
Validation loss: 2.0594721660819104

Epoch: 6| Step: 11
Training loss: 2.0506467819213867
Validation loss: 2.064258457511984

Epoch: 6| Step: 12
Training loss: 1.2153013944625854
Validation loss: 2.0896586820643437

Epoch: 6| Step: 13
Training loss: 2.8497111797332764
Validation loss: 2.12413965758457

Epoch: 193| Step: 0
Training loss: 1.5962738990783691
Validation loss: 2.1313478036593367

Epoch: 6| Step: 1
Training loss: 1.9725356101989746
Validation loss: 2.15870693806679

Epoch: 6| Step: 2
Training loss: 1.6880478858947754
Validation loss: 2.1152877551253124

Epoch: 6| Step: 3
Training loss: 1.5613861083984375
Validation loss: 2.1148207303016417

Epoch: 6| Step: 4
Training loss: 1.4835731983184814
Validation loss: 2.104757232050742

Epoch: 6| Step: 5
Training loss: 1.6591123342514038
Validation loss: 2.132627128272928

Epoch: 6| Step: 6
Training loss: 1.825185775756836
Validation loss: 2.1245606253224034

Epoch: 6| Step: 7
Training loss: 2.108649730682373
Validation loss: 2.14426859219869

Epoch: 6| Step: 8
Training loss: 1.3253802061080933
Validation loss: 2.1469994039945703

Epoch: 6| Step: 9
Training loss: 1.7054462432861328
Validation loss: 2.139014854226061

Epoch: 6| Step: 10
Training loss: 2.0508224964141846
Validation loss: 2.113421763143232

Epoch: 6| Step: 11
Training loss: 2.015164852142334
Validation loss: 2.1101401928932435

Epoch: 6| Step: 12
Training loss: 1.5115149021148682
Validation loss: 2.052790959676107

Epoch: 6| Step: 13
Training loss: 1.2786647081375122
Validation loss: 2.021543199016202

Epoch: 194| Step: 0
Training loss: 1.7465085983276367
Validation loss: 2.0059623346533826

Epoch: 6| Step: 1
Training loss: 1.4982833862304688
Validation loss: 2.008717203652987

Epoch: 6| Step: 2
Training loss: 2.815890073776245
Validation loss: 2.011101350989393

Epoch: 6| Step: 3
Training loss: 1.8792622089385986
Validation loss: 2.0091662176193728

Epoch: 6| Step: 4
Training loss: 2.3253040313720703
Validation loss: 2.006781138399596

Epoch: 6| Step: 5
Training loss: 1.314375877380371
Validation loss: 2.0252902943600892

Epoch: 6| Step: 6
Training loss: 1.3112869262695312
Validation loss: 2.0331269848731255

Epoch: 6| Step: 7
Training loss: 1.3456015586853027
Validation loss: 2.077704188644245

Epoch: 6| Step: 8
Training loss: 1.3377275466918945
Validation loss: 2.113552870288972

Epoch: 6| Step: 9
Training loss: 1.4231503009796143
Validation loss: 2.1461556675613567

Epoch: 6| Step: 10
Training loss: 1.2475354671478271
Validation loss: 2.1633069284500612

Epoch: 6| Step: 11
Training loss: 2.007517099380493
Validation loss: 2.167013397780798

Epoch: 6| Step: 12
Training loss: 1.6582114696502686
Validation loss: 2.183826251696515

Epoch: 6| Step: 13
Training loss: 1.5914357900619507
Validation loss: 2.1673735931355465

Epoch: 195| Step: 0
Training loss: 1.8599770069122314
Validation loss: 2.138828028914749

Epoch: 6| Step: 1
Training loss: 1.2395800352096558
Validation loss: 2.1283350016481135

Epoch: 6| Step: 2
Training loss: 2.083559513092041
Validation loss: 2.128475369945649

Epoch: 6| Step: 3
Training loss: 1.4523534774780273
Validation loss: 2.112337109863117

Epoch: 6| Step: 4
Training loss: 1.440126657485962
Validation loss: 2.090348897441741

Epoch: 6| Step: 5
Training loss: 1.6141996383666992
Validation loss: 2.093672328097846

Epoch: 6| Step: 6
Training loss: 1.2715805768966675
Validation loss: 2.0824601842511083

Epoch: 6| Step: 7
Training loss: 1.8872783184051514
Validation loss: 2.0663863151304183

Epoch: 6| Step: 8
Training loss: 2.0048751831054688
Validation loss: 2.0801982956547893

Epoch: 6| Step: 9
Training loss: 2.1712589263916016
Validation loss: 2.104352363976099

Epoch: 6| Step: 10
Training loss: 1.809738039970398
Validation loss: 2.1371244397214664

Epoch: 6| Step: 11
Training loss: 1.3870078325271606
Validation loss: 2.1397589957842262

Epoch: 6| Step: 12
Training loss: 1.8309283256530762
Validation loss: 2.175293417387111

Epoch: 6| Step: 13
Training loss: 1.5686583518981934
Validation loss: 2.1355232577170096

Epoch: 196| Step: 0
Training loss: 1.5617423057556152
Validation loss: 2.1153342313663934

Epoch: 6| Step: 1
Training loss: 1.440538763999939
Validation loss: 2.0724540820685764

Epoch: 6| Step: 2
Training loss: 1.5154845714569092
Validation loss: 2.037023495602351

Epoch: 6| Step: 3
Training loss: 1.6594988107681274
Validation loss: 2.032985189909576

Epoch: 6| Step: 4
Training loss: 1.7671990394592285
Validation loss: 2.0654165449962822

Epoch: 6| Step: 5
Training loss: 1.8382335901260376
Validation loss: 2.056806150303092

Epoch: 6| Step: 6
Training loss: 1.537240982055664
Validation loss: 2.0364669189658215

Epoch: 6| Step: 7
Training loss: 2.838918685913086
Validation loss: 2.0171331564585366

Epoch: 6| Step: 8
Training loss: 1.8379511833190918
Validation loss: 2.010718975015866

Epoch: 6| Step: 9
Training loss: 1.6181848049163818
Validation loss: 2.00597970972779

Epoch: 6| Step: 10
Training loss: 1.383298635482788
Validation loss: 2.047072865629709

Epoch: 6| Step: 11
Training loss: 1.5061283111572266
Validation loss: 2.1019140571676274

Epoch: 6| Step: 12
Training loss: 1.9235022068023682
Validation loss: 2.1021625021452546

Epoch: 6| Step: 13
Training loss: 1.022495985031128
Validation loss: 2.090386193285706

Epoch: 197| Step: 0
Training loss: 1.61307954788208
Validation loss: 2.107249900858889

Epoch: 6| Step: 1
Training loss: 2.0925142765045166
Validation loss: 2.1126421625896166

Epoch: 6| Step: 2
Training loss: 1.0792068243026733
Validation loss: 2.0878849311541487

Epoch: 6| Step: 3
Training loss: 1.5284309387207031
Validation loss: 2.1099355900159447

Epoch: 6| Step: 4
Training loss: 2.187223196029663
Validation loss: 2.1144505290574926

Epoch: 6| Step: 5
Training loss: 1.7606477737426758
Validation loss: 2.1616343682812107

Epoch: 6| Step: 6
Training loss: 1.912488579750061
Validation loss: 2.1796499170282835

Epoch: 6| Step: 7
Training loss: 1.6352065801620483
Validation loss: 2.1782200695365987

Epoch: 6| Step: 8
Training loss: 1.36258864402771
Validation loss: 2.158980959205217

Epoch: 6| Step: 9
Training loss: 1.8891749382019043
Validation loss: 2.136725600047778

Epoch: 6| Step: 10
Training loss: 1.1782047748565674
Validation loss: 2.1295986649810628

Epoch: 6| Step: 11
Training loss: 1.4636422395706177
Validation loss: 2.0891003583067205

Epoch: 6| Step: 12
Training loss: 1.4979643821716309
Validation loss: 2.0446248413414083

Epoch: 6| Step: 13
Training loss: 1.7674756050109863
Validation loss: 2.0242221688711517

Epoch: 198| Step: 0
Training loss: 1.5049958229064941
Validation loss: 1.9890179031638688

Epoch: 6| Step: 1
Training loss: 2.3235254287719727
Validation loss: 1.997692863146464

Epoch: 6| Step: 2
Training loss: 1.9365673065185547
Validation loss: 1.9923894584819835

Epoch: 6| Step: 3
Training loss: 1.545452356338501
Validation loss: 1.9832942613991358

Epoch: 6| Step: 4
Training loss: 1.3499033451080322
Validation loss: 1.979715475472071

Epoch: 6| Step: 5
Training loss: 1.8455215692520142
Validation loss: 1.9911926074694561

Epoch: 6| Step: 6
Training loss: 1.547516107559204
Validation loss: 2.0328377216093

Epoch: 6| Step: 7
Training loss: 1.8197729587554932
Validation loss: 2.0526461396166074

Epoch: 6| Step: 8
Training loss: 1.8378448486328125
Validation loss: 2.074465667047808

Epoch: 6| Step: 9
Training loss: 1.275757074356079
Validation loss: 2.1108555127215642

Epoch: 6| Step: 10
Training loss: 1.8674848079681396
Validation loss: 2.124013928956883

Epoch: 6| Step: 11
Training loss: 1.710824728012085
Validation loss: 2.112770290784938

Epoch: 6| Step: 12
Training loss: 0.7798517346382141
Validation loss: 2.0761870748253277

Epoch: 6| Step: 13
Training loss: 1.8866312503814697
Validation loss: 2.0729100550374677

Epoch: 199| Step: 0
Training loss: 1.7106010913848877
Validation loss: 2.0622832518751903

Epoch: 6| Step: 1
Training loss: 1.7563003301620483
Validation loss: 2.067736179597916

Epoch: 6| Step: 2
Training loss: 1.5269970893859863
Validation loss: 2.063056033144715

Epoch: 6| Step: 3
Training loss: 1.3945982456207275
Validation loss: 2.066639572061518

Epoch: 6| Step: 4
Training loss: 1.4828689098358154
Validation loss: 2.070426772999507

Epoch: 6| Step: 5
Training loss: 1.683631420135498
Validation loss: 2.0716371305527224

Epoch: 6| Step: 6
Training loss: 1.515397310256958
Validation loss: 2.1135432758638935

Epoch: 6| Step: 7
Training loss: 1.7451653480529785
Validation loss: 2.097278238624655

Epoch: 6| Step: 8
Training loss: 1.4774444103240967
Validation loss: 2.1349342433355187

Epoch: 6| Step: 9
Training loss: 1.3740519285202026
Validation loss: 2.1515697151102047

Epoch: 6| Step: 10
Training loss: 2.484168529510498
Validation loss: 2.1743303101549865

Epoch: 6| Step: 11
Training loss: 1.7434277534484863
Validation loss: 2.1623730236484158

Epoch: 6| Step: 12
Training loss: 1.8024725914001465
Validation loss: 2.138754961311176

Epoch: 6| Step: 13
Training loss: 1.3458024263381958
Validation loss: 2.076543482401038

Epoch: 200| Step: 0
Training loss: 1.37982976436615
Validation loss: 2.0653570416153118

Epoch: 6| Step: 1
Training loss: 1.1490998268127441
Validation loss: 2.0329140668274253

Epoch: 6| Step: 2
Training loss: 2.0328173637390137
Validation loss: 2.0271589961103214

Epoch: 6| Step: 3
Training loss: 1.3774054050445557
Validation loss: 2.017974494605936

Epoch: 6| Step: 4
Training loss: 2.1154372692108154
Validation loss: 2.0084255844034176

Epoch: 6| Step: 5
Training loss: 1.3515028953552246
Validation loss: 2.011224603140226

Epoch: 6| Step: 6
Training loss: 2.5504884719848633
Validation loss: 2.037696728142359

Epoch: 6| Step: 7
Training loss: 1.697585105895996
Validation loss: 2.044047300533582

Epoch: 6| Step: 8
Training loss: 2.026068925857544
Validation loss: 2.0513948240587787

Epoch: 6| Step: 9
Training loss: 1.3604357242584229
Validation loss: 2.0883392069929387

Epoch: 6| Step: 10
Training loss: 1.2364095449447632
Validation loss: 2.1352925095506894

Epoch: 6| Step: 11
Training loss: 2.424032688140869
Validation loss: 2.125758494100263

Epoch: 6| Step: 12
Training loss: 1.2496815919876099
Validation loss: 2.1241441567738852

Epoch: 6| Step: 13
Training loss: 0.3985578715801239
Validation loss: 2.135554999433538

Epoch: 201| Step: 0
Training loss: 1.5370151996612549
Validation loss: 2.142152053053661

Epoch: 6| Step: 1
Training loss: 1.3102426528930664
Validation loss: 2.170720613130959

Epoch: 6| Step: 2
Training loss: 1.7687678337097168
Validation loss: 2.1975037051785375

Epoch: 6| Step: 3
Training loss: 1.4990638494491577
Validation loss: 2.183638552183746

Epoch: 6| Step: 4
Training loss: 1.1642532348632812
Validation loss: 2.194835570550734

Epoch: 6| Step: 5
Training loss: 1.7225737571716309
Validation loss: 2.1763958431059316

Epoch: 6| Step: 6
Training loss: 1.4632858037948608
Validation loss: 2.159700337276664

Epoch: 6| Step: 7
Training loss: 2.3567097187042236
Validation loss: 2.111513081417289

Epoch: 6| Step: 8
Training loss: 2.4310896396636963
Validation loss: 2.1103365421295166

Epoch: 6| Step: 9
Training loss: 1.8124761581420898
Validation loss: 2.0644679915520454

Epoch: 6| Step: 10
Training loss: 1.9900147914886475
Validation loss: 2.050896881729044

Epoch: 6| Step: 11
Training loss: 1.6845192909240723
Validation loss: 2.0294929191630375

Epoch: 6| Step: 12
Training loss: 0.9221071004867554
Validation loss: 2.009981829632995

Epoch: 6| Step: 13
Training loss: 0.8460394740104675
Validation loss: 2.012566081939205

Epoch: 202| Step: 0
Training loss: 1.8180339336395264
Validation loss: 1.9949291880412767

Epoch: 6| Step: 1
Training loss: 1.5833667516708374
Validation loss: 1.9945279526454147

Epoch: 6| Step: 2
Training loss: 1.2462924718856812
Validation loss: 2.0046185267868863

Epoch: 6| Step: 3
Training loss: 1.912959098815918
Validation loss: 2.0024731928302395

Epoch: 6| Step: 4
Training loss: 1.8096822500228882
Validation loss: 2.011587671054307

Epoch: 6| Step: 5
Training loss: 1.4055249691009521
Validation loss: 2.006422186410555

Epoch: 6| Step: 6
Training loss: 1.6706708669662476
Validation loss: 2.0015414171321417

Epoch: 6| Step: 7
Training loss: 1.7000536918640137
Validation loss: 2.009395530146937

Epoch: 6| Step: 8
Training loss: 1.7022826671600342
Validation loss: 2.032511297092643

Epoch: 6| Step: 9
Training loss: 1.354940414428711
Validation loss: 2.0664187733845045

Epoch: 6| Step: 10
Training loss: 1.5022077560424805
Validation loss: 2.090707858403524

Epoch: 6| Step: 11
Training loss: 1.957352638244629
Validation loss: 2.0906676425728747

Epoch: 6| Step: 12
Training loss: 1.7415874004364014
Validation loss: 2.0907998751568537

Epoch: 6| Step: 13
Training loss: 0.31927692890167236
Validation loss: 2.1376300063184512

Epoch: 203| Step: 0
Training loss: 1.4542789459228516
Validation loss: 2.1732499830184446

Epoch: 6| Step: 1
Training loss: 2.343660831451416
Validation loss: 2.192753038098735

Epoch: 6| Step: 2
Training loss: 1.6555335521697998
Validation loss: 2.176043792437482

Epoch: 6| Step: 3
Training loss: 1.383455514907837
Validation loss: 2.1529291881028043

Epoch: 6| Step: 4
Training loss: 2.2261080741882324
Validation loss: 2.1143224239349365

Epoch: 6| Step: 5
Training loss: 1.9986646175384521
Validation loss: 2.099905921566871

Epoch: 6| Step: 6
Training loss: 1.46293044090271
Validation loss: 2.0739970643033265

Epoch: 6| Step: 7
Training loss: 0.9150490760803223
Validation loss: 2.073828189603744

Epoch: 6| Step: 8
Training loss: 1.7357549667358398
Validation loss: 2.0433271008153118

Epoch: 6| Step: 9
Training loss: 1.2136437892913818
Validation loss: 2.034033757384105

Epoch: 6| Step: 10
Training loss: 0.9260812997817993
Validation loss: 2.0001680158799693

Epoch: 6| Step: 11
Training loss: 1.71790611743927
Validation loss: 2.014945997986742

Epoch: 6| Step: 12
Training loss: 1.3209308385849
Validation loss: 2.0438179559605096

Epoch: 6| Step: 13
Training loss: 2.4243416786193848
Validation loss: 2.0624831671355874

Epoch: 204| Step: 0
Training loss: 2.1668150424957275
Validation loss: 2.112287470089492

Epoch: 6| Step: 1
Training loss: 1.3304251432418823
Validation loss: 2.104806291159763

Epoch: 6| Step: 2
Training loss: 1.2971986532211304
Validation loss: 2.1413918374687113

Epoch: 6| Step: 3
Training loss: 1.161760926246643
Validation loss: 2.1698329320517917

Epoch: 6| Step: 4
Training loss: 1.7498092651367188
Validation loss: 2.1206555174243067

Epoch: 6| Step: 5
Training loss: 1.7181825637817383
Validation loss: 2.0853569174325592

Epoch: 6| Step: 6
Training loss: 1.941628098487854
Validation loss: 2.0680429756000476

Epoch: 6| Step: 7
Training loss: 1.1932315826416016
Validation loss: 2.0677144014707176

Epoch: 6| Step: 8
Training loss: 2.0735549926757812
Validation loss: 2.0706730094007266

Epoch: 6| Step: 9
Training loss: 2.156172275543213
Validation loss: 2.080288589641612

Epoch: 6| Step: 10
Training loss: 0.9996107220649719
Validation loss: 2.069452255002914

Epoch: 6| Step: 11
Training loss: 1.873492956161499
Validation loss: 2.081754861339446

Epoch: 6| Step: 12
Training loss: 1.2155565023422241
Validation loss: 2.0793800072003434

Epoch: 6| Step: 13
Training loss: 1.8135122060775757
Validation loss: 2.1113971048785793

Epoch: 205| Step: 0
Training loss: 1.4848390817642212
Validation loss: 2.1324729483614684

Epoch: 6| Step: 1
Training loss: 2.081825017929077
Validation loss: 2.1356200774510703

Epoch: 6| Step: 2
Training loss: 1.705082654953003
Validation loss: 2.142857704111325

Epoch: 6| Step: 3
Training loss: 2.569164752960205
Validation loss: 2.1201999956561672

Epoch: 6| Step: 4
Training loss: 1.2830896377563477
Validation loss: 2.0762000096741544

Epoch: 6| Step: 5
Training loss: 1.2682218551635742
Validation loss: 2.06508925525091

Epoch: 6| Step: 6
Training loss: 1.4600200653076172
Validation loss: 2.070606934126987

Epoch: 6| Step: 7
Training loss: 1.403051495552063
Validation loss: 2.065077498394956

Epoch: 6| Step: 8
Training loss: 1.6455520391464233
Validation loss: 2.047783372222736

Epoch: 6| Step: 9
Training loss: 1.2709283828735352
Validation loss: 2.048844245172316

Epoch: 6| Step: 10
Training loss: 1.2682907581329346
Validation loss: 2.035211842547181

Epoch: 6| Step: 11
Training loss: 1.5592331886291504
Validation loss: 2.055059704729306

Epoch: 6| Step: 12
Training loss: 2.105742931365967
Validation loss: 2.04131942923351

Epoch: 6| Step: 13
Training loss: 1.097565770149231
Validation loss: 2.0505741001457296

Epoch: 206| Step: 0
Training loss: 1.5822734832763672
Validation loss: 2.0807001603546964

Epoch: 6| Step: 1
Training loss: 1.6677844524383545
Validation loss: 2.090481945263442

Epoch: 6| Step: 2
Training loss: 1.6435332298278809
Validation loss: 2.1086454276115663

Epoch: 6| Step: 3
Training loss: 1.9608722925186157
Validation loss: 2.1000483702587824

Epoch: 6| Step: 4
Training loss: 1.580996036529541
Validation loss: 2.0927045499124834

Epoch: 6| Step: 5
Training loss: 1.5633554458618164
Validation loss: 2.0609412411207795

Epoch: 6| Step: 6
Training loss: 1.3870141506195068
Validation loss: 2.0661543492347962

Epoch: 6| Step: 7
Training loss: 1.0195257663726807
Validation loss: 2.089665856412662

Epoch: 6| Step: 8
Training loss: 1.486825942993164
Validation loss: 2.0742872376595773

Epoch: 6| Step: 9
Training loss: 1.2424668073654175
Validation loss: 2.089195671901908

Epoch: 6| Step: 10
Training loss: 2.0073797702789307
Validation loss: 2.1094371682854107

Epoch: 6| Step: 11
Training loss: 1.8150205612182617
Validation loss: 2.145795096633255

Epoch: 6| Step: 12
Training loss: 1.609265923500061
Validation loss: 2.1380552476452244

Epoch: 6| Step: 13
Training loss: 1.5252994298934937
Validation loss: 2.131712746876542

Epoch: 207| Step: 0
Training loss: 1.5225286483764648
Validation loss: 2.148231739638954

Epoch: 6| Step: 1
Training loss: 1.344053864479065
Validation loss: 2.173457602018951

Epoch: 6| Step: 2
Training loss: 1.7504596710205078
Validation loss: 2.158917304008238

Epoch: 6| Step: 3
Training loss: 1.9686182737350464
Validation loss: 2.1405222492833293

Epoch: 6| Step: 4
Training loss: 1.153012752532959
Validation loss: 2.1495110809162097

Epoch: 6| Step: 5
Training loss: 1.6160247325897217
Validation loss: 2.136078001350485

Epoch: 6| Step: 6
Training loss: 1.3608298301696777
Validation loss: 2.123419956494403

Epoch: 6| Step: 7
Training loss: 2.061365842819214
Validation loss: 2.103513025468396

Epoch: 6| Step: 8
Training loss: 1.3919599056243896
Validation loss: 2.090391630767494

Epoch: 6| Step: 9
Training loss: 1.6583435535430908
Validation loss: 2.0403651934798046

Epoch: 6| Step: 10
Training loss: 1.1872118711471558
Validation loss: 2.038084395470158

Epoch: 6| Step: 11
Training loss: 1.4199031591415405
Validation loss: 2.0123525127287833

Epoch: 6| Step: 12
Training loss: 1.6131645441055298
Validation loss: 2.0102861645401164

Epoch: 6| Step: 13
Training loss: 1.5306432247161865
Validation loss: 2.01379838297444

Epoch: 208| Step: 0
Training loss: 1.5691266059875488
Validation loss: 2.016771375492055

Epoch: 6| Step: 1
Training loss: 2.180209159851074
Validation loss: 2.003570395131265

Epoch: 6| Step: 2
Training loss: 1.2307907342910767
Validation loss: 2.014074913917049

Epoch: 6| Step: 3
Training loss: 1.452510118484497
Validation loss: 2.0207162531473304

Epoch: 6| Step: 4
Training loss: 1.415467619895935
Validation loss: 2.068391737117562

Epoch: 6| Step: 5
Training loss: 1.0358034372329712
Validation loss: 2.0983836676484797

Epoch: 6| Step: 6
Training loss: 1.4013067483901978
Validation loss: 2.155982466154201

Epoch: 6| Step: 7
Training loss: 1.4750308990478516
Validation loss: 2.167221051390453

Epoch: 6| Step: 8
Training loss: 1.669872522354126
Validation loss: 2.1678530195707917

Epoch: 6| Step: 9
Training loss: 2.07350492477417
Validation loss: 2.123762769083823

Epoch: 6| Step: 10
Training loss: 1.6193326711654663
Validation loss: 2.0527561800454253

Epoch: 6| Step: 11
Training loss: 1.9018527269363403
Validation loss: 2.001345883133591

Epoch: 6| Step: 12
Training loss: 1.798280954360962
Validation loss: 1.9800911641890002

Epoch: 6| Step: 13
Training loss: 0.8020697832107544
Validation loss: 1.967844755418839

Epoch: 209| Step: 0
Training loss: 0.8997591733932495
Validation loss: 1.9478258304698493

Epoch: 6| Step: 1
Training loss: 1.5128097534179688
Validation loss: 1.8996234068306543

Epoch: 6| Step: 2
Training loss: 1.76765775680542
Validation loss: 1.9088969499834123

Epoch: 6| Step: 3
Training loss: 1.4094085693359375
Validation loss: 1.9026766592456448

Epoch: 6| Step: 4
Training loss: 1.2401847839355469
Validation loss: 1.8995080776112054

Epoch: 6| Step: 5
Training loss: 1.6509795188903809
Validation loss: 1.906934884286696

Epoch: 6| Step: 6
Training loss: 2.1100411415100098
Validation loss: 1.9246146896834015

Epoch: 6| Step: 7
Training loss: 2.733964443206787
Validation loss: 1.9356635385943997

Epoch: 6| Step: 8
Training loss: 1.8411177396774292
Validation loss: 2.0111020995724584

Epoch: 6| Step: 9
Training loss: 1.3660156726837158
Validation loss: 2.068056696204729

Epoch: 6| Step: 10
Training loss: 1.8220481872558594
Validation loss: 2.1245412800901677

Epoch: 6| Step: 11
Training loss: 2.149244546890259
Validation loss: 2.166845316527992

Epoch: 6| Step: 12
Training loss: 1.6408073902130127
Validation loss: 2.201840813441943

Epoch: 6| Step: 13
Training loss: 1.199882984161377
Validation loss: 2.2130540891360213

Epoch: 210| Step: 0
Training loss: 2.0451180934906006
Validation loss: 2.195773891223374

Epoch: 6| Step: 1
Training loss: 2.356365203857422
Validation loss: 2.1611972675528577

Epoch: 6| Step: 2
Training loss: 1.9649903774261475
Validation loss: 2.095096923971689

Epoch: 6| Step: 3
Training loss: 1.3750057220458984
Validation loss: 2.0883622156676425

Epoch: 6| Step: 4
Training loss: 1.580978512763977
Validation loss: 2.1010175879283617

Epoch: 6| Step: 5
Training loss: 1.540062427520752
Validation loss: 2.122353517881004

Epoch: 6| Step: 6
Training loss: 2.233821392059326
Validation loss: 2.1228665023721676

Epoch: 6| Step: 7
Training loss: 1.4699326753616333
Validation loss: 2.1296728593046947

Epoch: 6| Step: 8
Training loss: 1.4718326330184937
Validation loss: 2.128962984649084

Epoch: 6| Step: 9
Training loss: 1.4616565704345703
Validation loss: 2.153173759419431

Epoch: 6| Step: 10
Training loss: 1.0962810516357422
Validation loss: 2.144860585530599

Epoch: 6| Step: 11
Training loss: 0.799182653427124
Validation loss: 2.1703122200504428

Epoch: 6| Step: 12
Training loss: 1.4790408611297607
Validation loss: 2.219147200225502

Epoch: 6| Step: 13
Training loss: 1.884093165397644
Validation loss: 2.2182206133360505

Epoch: 211| Step: 0
Training loss: 1.5601284503936768
Validation loss: 2.2147652897783505

Epoch: 6| Step: 1
Training loss: 1.1740660667419434
Validation loss: 2.2235297695282967

Epoch: 6| Step: 2
Training loss: 1.7215487957000732
Validation loss: 2.2003490630016533

Epoch: 6| Step: 3
Training loss: 0.8217490911483765
Validation loss: 2.1742608521574285

Epoch: 6| Step: 4
Training loss: 1.910517930984497
Validation loss: 2.1297043843935897

Epoch: 6| Step: 5
Training loss: 1.7558362483978271
Validation loss: 2.1056321795268724

Epoch: 6| Step: 6
Training loss: 2.0245800018310547
Validation loss: 2.0989397289932414

Epoch: 6| Step: 7
Training loss: 1.7130775451660156
Validation loss: 2.0989464008679954

Epoch: 6| Step: 8
Training loss: 1.2016029357910156
Validation loss: 2.063217370740829

Epoch: 6| Step: 9
Training loss: 2.213575839996338
Validation loss: 2.0318763563709874

Epoch: 6| Step: 10
Training loss: 1.6758397817611694
Validation loss: 1.992486164134036

Epoch: 6| Step: 11
Training loss: 1.2333623170852661
Validation loss: 1.9702138772574804

Epoch: 6| Step: 12
Training loss: 1.3764970302581787
Validation loss: 1.9795611776331419

Epoch: 6| Step: 13
Training loss: 1.9613265991210938
Validation loss: 2.0232644337479786

Epoch: 212| Step: 0
Training loss: 1.418660283088684
Validation loss: 2.0625683030774518

Epoch: 6| Step: 1
Training loss: 1.4212719202041626
Validation loss: 2.1373471726653395

Epoch: 6| Step: 2
Training loss: 1.8425748348236084
Validation loss: 2.129169928130283

Epoch: 6| Step: 3
Training loss: 1.7750229835510254
Validation loss: 2.160361087450417

Epoch: 6| Step: 4
Training loss: 1.2163326740264893
Validation loss: 2.156669778208579

Epoch: 6| Step: 5
Training loss: 1.5060153007507324
Validation loss: 2.157857958988477

Epoch: 6| Step: 6
Training loss: 2.0741631984710693
Validation loss: 2.133140561401203

Epoch: 6| Step: 7
Training loss: 1.7369608879089355
Validation loss: 2.072255575528709

Epoch: 6| Step: 8
Training loss: 1.5910322666168213
Validation loss: 2.0616266624901884

Epoch: 6| Step: 9
Training loss: 1.282772421836853
Validation loss: 2.0176631865962857

Epoch: 6| Step: 10
Training loss: 1.3845083713531494
Validation loss: 2.0137304836703884

Epoch: 6| Step: 11
Training loss: 1.3688896894454956
Validation loss: 2.0082154299623225

Epoch: 6| Step: 12
Training loss: 1.0565046072006226
Validation loss: 2.0298125423410887

Epoch: 6| Step: 13
Training loss: 2.0002942085266113
Validation loss: 2.0495874087015786

Epoch: 213| Step: 0
Training loss: 2.0437240600585938
Validation loss: 2.0493267479763237

Epoch: 6| Step: 1
Training loss: 1.49422025680542
Validation loss: 2.0773115440081527

Epoch: 6| Step: 2
Training loss: 0.9629414081573486
Validation loss: 2.113124716666437

Epoch: 6| Step: 3
Training loss: 1.9006184339523315
Validation loss: 2.1391226373692995

Epoch: 6| Step: 4
Training loss: 2.237595319747925
Validation loss: 2.1412343453335505

Epoch: 6| Step: 5
Training loss: 1.4776829481124878
Validation loss: 2.130896919517107

Epoch: 6| Step: 6
Training loss: 0.9888628125190735
Validation loss: 2.103901529824862

Epoch: 6| Step: 7
Training loss: 1.3102898597717285
Validation loss: 2.100130013240281

Epoch: 6| Step: 8
Training loss: 1.5422786474227905
Validation loss: 2.0785673510643745

Epoch: 6| Step: 9
Training loss: 1.4887481927871704
Validation loss: 2.0735909118447253

Epoch: 6| Step: 10
Training loss: 1.1588172912597656
Validation loss: 2.0664886915555565

Epoch: 6| Step: 11
Training loss: 1.3944754600524902
Validation loss: 2.0767272826164

Epoch: 6| Step: 12
Training loss: 1.1253670454025269
Validation loss: 2.105147971901842

Epoch: 6| Step: 13
Training loss: 2.014012098312378
Validation loss: 2.1316593770057923

Epoch: 214| Step: 0
Training loss: 1.378528356552124
Validation loss: 2.1329277664102535

Epoch: 6| Step: 1
Training loss: 1.6417044401168823
Validation loss: 2.1326201577340402

Epoch: 6| Step: 2
Training loss: 1.647711157798767
Validation loss: 2.0977580111513854

Epoch: 6| Step: 3
Training loss: 1.077998399734497
Validation loss: 2.1102595752285374

Epoch: 6| Step: 4
Training loss: 1.4937052726745605
Validation loss: 2.1164250745568225

Epoch: 6| Step: 5
Training loss: 1.0986452102661133
Validation loss: 2.132810179905225

Epoch: 6| Step: 6
Training loss: 1.7941842079162598
Validation loss: 2.1148833946515153

Epoch: 6| Step: 7
Training loss: 2.1466965675354004
Validation loss: 2.0947655631649877

Epoch: 6| Step: 8
Training loss: 0.9906231164932251
Validation loss: 2.0581231835067912

Epoch: 6| Step: 9
Training loss: 1.4132776260375977
Validation loss: 2.0683371854084793

Epoch: 6| Step: 10
Training loss: 0.9339409470558167
Validation loss: 2.073114538705477

Epoch: 6| Step: 11
Training loss: 1.9559890031814575
Validation loss: 2.0615248654478338

Epoch: 6| Step: 12
Training loss: 1.5757014751434326
Validation loss: 2.059010044220955

Epoch: 6| Step: 13
Training loss: 1.3695253133773804
Validation loss: 2.05029135493822

Epoch: 215| Step: 0
Training loss: 1.363982081413269
Validation loss: 2.04077346094193

Epoch: 6| Step: 1
Training loss: 1.1136806011199951
Validation loss: 2.023275476630016

Epoch: 6| Step: 2
Training loss: 1.265296459197998
Validation loss: 2.026309859368109

Epoch: 6| Step: 3
Training loss: 1.8919110298156738
Validation loss: 2.052338465567558

Epoch: 6| Step: 4
Training loss: 1.8651697635650635
Validation loss: 2.077160532756518

Epoch: 6| Step: 5
Training loss: 1.8899781703948975
Validation loss: 2.0756239750052012

Epoch: 6| Step: 6
Training loss: 1.5245705842971802
Validation loss: 2.113182226816813

Epoch: 6| Step: 7
Training loss: 1.4261059761047363
Validation loss: 2.1178642011457876

Epoch: 6| Step: 8
Training loss: 1.075439691543579
Validation loss: 2.1352585720759567

Epoch: 6| Step: 9
Training loss: 1.7878167629241943
Validation loss: 2.1555195803283365

Epoch: 6| Step: 10
Training loss: 1.049159288406372
Validation loss: 2.1238057549281786

Epoch: 6| Step: 11
Training loss: 1.4115855693817139
Validation loss: 2.090052908466708

Epoch: 6| Step: 12
Training loss: 1.0089924335479736
Validation loss: 2.054754662257369

Epoch: 6| Step: 13
Training loss: 1.6880853176116943
Validation loss: 2.0169705190966205

Epoch: 216| Step: 0
Training loss: 2.061769485473633
Validation loss: 2.0203557117010957

Epoch: 6| Step: 1
Training loss: 1.3118953704833984
Validation loss: 2.0206208305974163

Epoch: 6| Step: 2
Training loss: 1.6183596849441528
Validation loss: 2.0192629650074947

Epoch: 6| Step: 3
Training loss: 1.2999019622802734
Validation loss: 2.0452702160804503

Epoch: 6| Step: 4
Training loss: 1.6486737728118896
Validation loss: 2.0406691438408306

Epoch: 6| Step: 5
Training loss: 1.916540265083313
Validation loss: 2.071474431663431

Epoch: 6| Step: 6
Training loss: 1.1203274726867676
Validation loss: 2.0789850732331634

Epoch: 6| Step: 7
Training loss: 1.4185261726379395
Validation loss: 2.1208574694971882

Epoch: 6| Step: 8
Training loss: 1.784733533859253
Validation loss: 2.082223758902601

Epoch: 6| Step: 9
Training loss: 1.14048433303833
Validation loss: 2.0646871789809196

Epoch: 6| Step: 10
Training loss: 1.175044059753418
Validation loss: 2.056618975054833

Epoch: 6| Step: 11
Training loss: 0.7899112105369568
Validation loss: 2.0423489129671486

Epoch: 6| Step: 12
Training loss: 1.3558008670806885
Validation loss: 2.0224574740215013

Epoch: 6| Step: 13
Training loss: 0.855130672454834
Validation loss: 2.0554963542569067

Epoch: 217| Step: 0
Training loss: 1.2718403339385986
Validation loss: 2.0687543012762584

Epoch: 6| Step: 1
Training loss: 1.1716272830963135
Validation loss: 2.078716262694328

Epoch: 6| Step: 2
Training loss: 1.3576010465621948
Validation loss: 2.0811995049958587

Epoch: 6| Step: 3
Training loss: 1.015393614768982
Validation loss: 2.105442031737297

Epoch: 6| Step: 4
Training loss: 1.9684158563613892
Validation loss: 2.1141116644746516

Epoch: 6| Step: 5
Training loss: 1.1534191370010376
Validation loss: 2.133524819086957

Epoch: 6| Step: 6
Training loss: 1.905395269393921
Validation loss: 2.1193553017031763

Epoch: 6| Step: 7
Training loss: 2.0307540893554688
Validation loss: 2.1381640818811234

Epoch: 6| Step: 8
Training loss: 1.0341060161590576
Validation loss: 2.1237066176629837

Epoch: 6| Step: 9
Training loss: 1.55845046043396
Validation loss: 2.1566835782861196

Epoch: 6| Step: 10
Training loss: 1.2109639644622803
Validation loss: 2.130860108201222

Epoch: 6| Step: 11
Training loss: 0.9793142080307007
Validation loss: 2.0979985857522614

Epoch: 6| Step: 12
Training loss: 1.7319841384887695
Validation loss: 2.053504570837944

Epoch: 6| Step: 13
Training loss: 1.4102346897125244
Validation loss: 2.041875509805577

Epoch: 218| Step: 0
Training loss: 1.7819206714630127
Validation loss: 2.023899837206769

Epoch: 6| Step: 1
Training loss: 1.524794340133667
Validation loss: 2.002199313973868

Epoch: 6| Step: 2
Training loss: 1.054107904434204
Validation loss: 1.9954634558769964

Epoch: 6| Step: 3
Training loss: 1.2799668312072754
Validation loss: 1.9954666591459704

Epoch: 6| Step: 4
Training loss: 0.9937446117401123
Validation loss: 2.005203363715961

Epoch: 6| Step: 5
Training loss: 1.5909351110458374
Validation loss: 2.011016804684875

Epoch: 6| Step: 6
Training loss: 1.3213005065917969
Validation loss: 2.016962118046258

Epoch: 6| Step: 7
Training loss: 1.4008032083511353
Validation loss: 2.026620170121552

Epoch: 6| Step: 8
Training loss: 1.1261603832244873
Validation loss: 2.0356730145792805

Epoch: 6| Step: 9
Training loss: 1.6904606819152832
Validation loss: 2.077036606368198

Epoch: 6| Step: 10
Training loss: 1.77852463722229
Validation loss: 2.0963184961708645

Epoch: 6| Step: 11
Training loss: 1.143141508102417
Validation loss: 2.1027815072767195

Epoch: 6| Step: 12
Training loss: 1.1908563375473022
Validation loss: 2.103505262764551

Epoch: 6| Step: 13
Training loss: 1.3611140251159668
Validation loss: 2.1347051307719243

Epoch: 219| Step: 0
Training loss: 1.19711172580719
Validation loss: 2.1589846277749665

Epoch: 6| Step: 1
Training loss: 1.4516522884368896
Validation loss: 2.1324105493484007

Epoch: 6| Step: 2
Training loss: 2.0244314670562744
Validation loss: 2.1225392882541945

Epoch: 6| Step: 3
Training loss: 1.3574919700622559
Validation loss: 2.0867447545451503

Epoch: 6| Step: 4
Training loss: 1.2357816696166992
Validation loss: 2.0492812369459417

Epoch: 6| Step: 5
Training loss: 1.872302770614624
Validation loss: 2.044578993192283

Epoch: 6| Step: 6
Training loss: 1.1766630411148071
Validation loss: 2.0542145339391564

Epoch: 6| Step: 7
Training loss: 1.7263290882110596
Validation loss: 2.0772729086619552

Epoch: 6| Step: 8
Training loss: 1.0857735872268677
Validation loss: 2.080882642858772

Epoch: 6| Step: 9
Training loss: 1.1659159660339355
Validation loss: 2.0832333859576972

Epoch: 6| Step: 10
Training loss: 1.3481976985931396
Validation loss: 2.099498556506249

Epoch: 6| Step: 11
Training loss: 1.9436464309692383
Validation loss: 2.077039823737196

Epoch: 6| Step: 12
Training loss: 0.8000947833061218
Validation loss: 2.080076830361479

Epoch: 6| Step: 13
Training loss: 0.5894431471824646
Validation loss: 2.079598372982394

Epoch: 220| Step: 0
Training loss: 1.4194834232330322
Validation loss: 2.080466566547271

Epoch: 6| Step: 1
Training loss: 1.5336519479751587
Validation loss: 2.095748446320975

Epoch: 6| Step: 2
Training loss: 1.3638542890548706
Validation loss: 2.102693852557931

Epoch: 6| Step: 3
Training loss: 1.1935608386993408
Validation loss: 2.0866210358117216

Epoch: 6| Step: 4
Training loss: 1.447126030921936
Validation loss: 2.1000901473465787

Epoch: 6| Step: 5
Training loss: 0.9576476812362671
Validation loss: 2.0639446986618863

Epoch: 6| Step: 6
Training loss: 1.166409969329834
Validation loss: 2.0636807718584613

Epoch: 6| Step: 7
Training loss: 1.3702222108840942
Validation loss: 2.0473375897253714

Epoch: 6| Step: 8
Training loss: 1.0015546083450317
Validation loss: 2.0477010870492585

Epoch: 6| Step: 9
Training loss: 1.5929710865020752
Validation loss: 2.04429171674995

Epoch: 6| Step: 10
Training loss: 1.3407381772994995
Validation loss: 2.042117308544856

Epoch: 6| Step: 11
Training loss: 0.6378519535064697
Validation loss: 2.067623670383166

Epoch: 6| Step: 12
Training loss: 1.8159630298614502
Validation loss: 2.0588971645601335

Epoch: 6| Step: 13
Training loss: 2.267364740371704
Validation loss: 2.0616588951438986

Epoch: 221| Step: 0
Training loss: 1.0747337341308594
Validation loss: 2.066632729704662

Epoch: 6| Step: 1
Training loss: 1.8543754816055298
Validation loss: 2.020802226117862

Epoch: 6| Step: 2
Training loss: 0.7138936519622803
Validation loss: 2.022991523947767

Epoch: 6| Step: 3
Training loss: 1.4237442016601562
Validation loss: 2.036897938738587

Epoch: 6| Step: 4
Training loss: 0.9406669735908508
Validation loss: 2.0632431430201374

Epoch: 6| Step: 5
Training loss: 1.3089827299118042
Validation loss: 2.0310709066288446

Epoch: 6| Step: 6
Training loss: 1.5814270973205566
Validation loss: 2.016497991418326

Epoch: 6| Step: 7
Training loss: 1.8153603076934814
Validation loss: 2.0088190135135444

Epoch: 6| Step: 8
Training loss: 1.808295488357544
Validation loss: 2.007371246173818

Epoch: 6| Step: 9
Training loss: 1.0015161037445068
Validation loss: 1.9968351792263728

Epoch: 6| Step: 10
Training loss: 1.6140060424804688
Validation loss: 1.9750407588097356

Epoch: 6| Step: 11
Training loss: 1.3157583475112915
Validation loss: 1.9934795941075971

Epoch: 6| Step: 12
Training loss: 1.2330008745193481
Validation loss: 2.01945823495106

Epoch: 6| Step: 13
Training loss: 0.9551482796669006
Validation loss: 2.0096026441102386

Epoch: 222| Step: 0
Training loss: 1.0075914859771729
Validation loss: 2.022853838500156

Epoch: 6| Step: 1
Training loss: 1.849116325378418
Validation loss: 2.043821397648063

Epoch: 6| Step: 2
Training loss: 1.7899168729782104
Validation loss: 2.0163842016650784

Epoch: 6| Step: 3
Training loss: 1.3028349876403809
Validation loss: 2.030859217848829

Epoch: 6| Step: 4
Training loss: 1.9786877632141113
Validation loss: 2.0302990610881517

Epoch: 6| Step: 5
Training loss: 1.701829433441162
Validation loss: 2.04277906879302

Epoch: 6| Step: 6
Training loss: 0.8877370357513428
Validation loss: 2.036271123475926

Epoch: 6| Step: 7
Training loss: 1.2891803979873657
Validation loss: 2.0560453502080773

Epoch: 6| Step: 8
Training loss: 1.0977561473846436
Validation loss: 2.0210468769073486

Epoch: 6| Step: 9
Training loss: 1.026504635810852
Validation loss: 2.035982415240298

Epoch: 6| Step: 10
Training loss: 1.1028951406478882
Validation loss: 2.0492559017673617

Epoch: 6| Step: 11
Training loss: 1.0434467792510986
Validation loss: 2.0600144478582565

Epoch: 6| Step: 12
Training loss: 1.2618640661239624
Validation loss: 2.0832216611472507

Epoch: 6| Step: 13
Training loss: 1.4685750007629395
Validation loss: 2.1044472955888316

Epoch: 223| Step: 0
Training loss: 1.229337215423584
Validation loss: 2.124157376186822

Epoch: 6| Step: 1
Training loss: 1.4828197956085205
Validation loss: 2.114573429989558

Epoch: 6| Step: 2
Training loss: 1.3730311393737793
Validation loss: 2.0855548125441357

Epoch: 6| Step: 3
Training loss: 1.530799388885498
Validation loss: 2.077813474080896

Epoch: 6| Step: 4
Training loss: 0.9925185441970825
Validation loss: 2.0898704772354453

Epoch: 6| Step: 5
Training loss: 1.6967262029647827
Validation loss: 2.0939665712336057

Epoch: 6| Step: 6
Training loss: 1.3742682933807373
Validation loss: 2.1129354610238025

Epoch: 6| Step: 7
Training loss: 1.825945258140564
Validation loss: 2.0970317215047856

Epoch: 6| Step: 8
Training loss: 0.94903165102005
Validation loss: 2.088264867823611

Epoch: 6| Step: 9
Training loss: 1.3915584087371826
Validation loss: 2.0539986395066783

Epoch: 6| Step: 10
Training loss: 1.1305865049362183
Validation loss: 2.0639722167804675

Epoch: 6| Step: 11
Training loss: 0.9193970561027527
Validation loss: 2.0545257291486188

Epoch: 6| Step: 12
Training loss: 1.6128268241882324
Validation loss: 2.0906687398110666

Epoch: 6| Step: 13
Training loss: 1.2388969659805298
Validation loss: 2.091496127907948

Epoch: 224| Step: 0
Training loss: 1.4869242906570435
Validation loss: 2.0665157700097687

Epoch: 6| Step: 1
Training loss: 1.8666092157363892
Validation loss: 2.034336397724767

Epoch: 6| Step: 2
Training loss: 2.2282142639160156
Validation loss: 2.018885430469308

Epoch: 6| Step: 3
Training loss: 0.9364889860153198
Validation loss: 1.9728609951593543

Epoch: 6| Step: 4
Training loss: 1.5448882579803467
Validation loss: 1.944847841416636

Epoch: 6| Step: 5
Training loss: 0.5581605434417725
Validation loss: 1.9668217012959142

Epoch: 6| Step: 6
Training loss: 0.9160847067832947
Validation loss: 1.949137835092442

Epoch: 6| Step: 7
Training loss: 1.0661648511886597
Validation loss: 1.9709402233041742

Epoch: 6| Step: 8
Training loss: 1.0940591096878052
Validation loss: 1.9891011894390147

Epoch: 6| Step: 9
Training loss: 1.3889081478118896
Validation loss: 2.018431886549919

Epoch: 6| Step: 10
Training loss: 1.259875774383545
Validation loss: 2.0654841212816137

Epoch: 6| Step: 11
Training loss: 1.3571650981903076
Validation loss: 2.0807492220273582

Epoch: 6| Step: 12
Training loss: 1.3116800785064697
Validation loss: 2.0832843806153987

Epoch: 6| Step: 13
Training loss: 2.0640242099761963
Validation loss: 2.1149487751786427

Epoch: 225| Step: 0
Training loss: 1.5194060802459717
Validation loss: 2.0814120666955107

Epoch: 6| Step: 1
Training loss: 0.9163771271705627
Validation loss: 2.0644781307507585

Epoch: 6| Step: 2
Training loss: 0.7438508868217468
Validation loss: 2.0159282889417423

Epoch: 6| Step: 3
Training loss: 1.522306203842163
Validation loss: 2.0297637908689437

Epoch: 6| Step: 4
Training loss: 1.3199681043624878
Validation loss: 2.0003446302106305

Epoch: 6| Step: 5
Training loss: 1.631390929222107
Validation loss: 1.9951925046982304

Epoch: 6| Step: 6
Training loss: 1.386203408241272
Validation loss: 1.9755783593782814

Epoch: 6| Step: 7
Training loss: 1.3491076231002808
Validation loss: 2.0120562725169684

Epoch: 6| Step: 8
Training loss: 1.3735123872756958
Validation loss: 2.0534436164363736

Epoch: 6| Step: 9
Training loss: 1.4363532066345215
Validation loss: 2.079431718395602

Epoch: 6| Step: 10
Training loss: 1.3203504085540771
Validation loss: 2.080377019861693

Epoch: 6| Step: 11
Training loss: 1.621861219406128
Validation loss: 2.114097128632248

Epoch: 6| Step: 12
Training loss: 0.8571082353591919
Validation loss: 2.110338462296353

Epoch: 6| Step: 13
Training loss: 1.4661246538162231
Validation loss: 2.1167249628292617

Epoch: 226| Step: 0
Training loss: 1.3912315368652344
Validation loss: 2.1023632518706785

Epoch: 6| Step: 1
Training loss: 1.1190351247787476
Validation loss: 2.096077472932877

Epoch: 6| Step: 2
Training loss: 1.0990722179412842
Validation loss: 2.0543897408311085

Epoch: 6| Step: 3
Training loss: 1.3106492757797241
Validation loss: 2.0589508471950406

Epoch: 6| Step: 4
Training loss: 1.0281734466552734
Validation loss: 2.0582879538177163

Epoch: 6| Step: 5
Training loss: 1.3871574401855469
Validation loss: 2.051696754270984

Epoch: 6| Step: 6
Training loss: 1.5237960815429688
Validation loss: 2.0452786389217583

Epoch: 6| Step: 7
Training loss: 1.6943812370300293
Validation loss: 2.0475049916134087

Epoch: 6| Step: 8
Training loss: 0.8045127391815186
Validation loss: 2.0336081289475962

Epoch: 6| Step: 9
Training loss: 1.0303444862365723
Validation loss: 2.027556760336763

Epoch: 6| Step: 10
Training loss: 1.6177737712860107
Validation loss: 2.018205947773431

Epoch: 6| Step: 11
Training loss: 1.082857370376587
Validation loss: 2.041212007563601

Epoch: 6| Step: 12
Training loss: 1.1927623748779297
Validation loss: 2.0688775995726227

Epoch: 6| Step: 13
Training loss: 1.3962891101837158
Validation loss: 2.0554765014238257

Epoch: 227| Step: 0
Training loss: 1.5035243034362793
Validation loss: 2.0568210796643327

Epoch: 6| Step: 1
Training loss: 1.4626779556274414
Validation loss: 2.0358469486236572

Epoch: 6| Step: 2
Training loss: 1.9162179231643677
Validation loss: 2.0275650306414534

Epoch: 6| Step: 3
Training loss: 1.0219043493270874
Validation loss: 2.0243637356706845

Epoch: 6| Step: 4
Training loss: 1.2681018114089966
Validation loss: 2.0391181399745326

Epoch: 6| Step: 5
Training loss: 1.2821693420410156
Validation loss: 2.0665793085610993

Epoch: 6| Step: 6
Training loss: 1.0782361030578613
Validation loss: 2.0864378572792135

Epoch: 6| Step: 7
Training loss: 0.9043924808502197
Validation loss: 2.085710540894539

Epoch: 6| Step: 8
Training loss: 1.6190129518508911
Validation loss: 2.0916251059501403

Epoch: 6| Step: 9
Training loss: 1.1811041831970215
Validation loss: 2.0942584583836217

Epoch: 6| Step: 10
Training loss: 0.7608680725097656
Validation loss: 2.0375546152873705

Epoch: 6| Step: 11
Training loss: 1.4211398363113403
Validation loss: 2.0054903261123167

Epoch: 6| Step: 12
Training loss: 0.8628754615783691
Validation loss: 1.9823454644090386

Epoch: 6| Step: 13
Training loss: 1.0438307523727417
Validation loss: 1.9686075948899793

Epoch: 228| Step: 0
Training loss: 1.1406999826431274
Validation loss: 1.9909657496278004

Epoch: 6| Step: 1
Training loss: 1.1645910739898682
Validation loss: 1.9878620742469706

Epoch: 6| Step: 2
Training loss: 1.3681628704071045
Validation loss: 2.0369072062994844

Epoch: 6| Step: 3
Training loss: 1.5436677932739258
Validation loss: 2.0969627980263

Epoch: 6| Step: 4
Training loss: 1.455566644668579
Validation loss: 2.0709028692655664

Epoch: 6| Step: 5
Training loss: 0.862677812576294
Validation loss: 2.09578231329559

Epoch: 6| Step: 6
Training loss: 1.1349101066589355
Validation loss: 2.080283784097241

Epoch: 6| Step: 7
Training loss: 1.6906428337097168
Validation loss: 2.055674681099512

Epoch: 6| Step: 8
Training loss: 1.3904056549072266
Validation loss: 2.087686050322748

Epoch: 6| Step: 9
Training loss: 1.2114737033843994
Validation loss: 2.0794434867879397

Epoch: 6| Step: 10
Training loss: 1.6564706563949585
Validation loss: 2.0333720330269105

Epoch: 6| Step: 11
Training loss: 0.7434663772583008
Validation loss: 2.0108283655617827

Epoch: 6| Step: 12
Training loss: 1.4759819507598877
Validation loss: 2.0095364662908737

Epoch: 6| Step: 13
Training loss: 0.5032240748405457
Validation loss: 2.004505967581144

Epoch: 229| Step: 0
Training loss: 2.0658369064331055
Validation loss: 2.0174638250822663

Epoch: 6| Step: 1
Training loss: 0.8075288534164429
Validation loss: 2.076899060639002

Epoch: 6| Step: 2
Training loss: 0.6129207015037537
Validation loss: 2.105207822656119

Epoch: 6| Step: 3
Training loss: 1.1607075929641724
Validation loss: 2.130983870516541

Epoch: 6| Step: 4
Training loss: 1.860245704650879
Validation loss: 2.104466851039599

Epoch: 6| Step: 5
Training loss: 1.1038925647735596
Validation loss: 2.0589599737557034

Epoch: 6| Step: 6
Training loss: 1.5837332010269165
Validation loss: 2.032829030867546

Epoch: 6| Step: 7
Training loss: 1.2214653491973877
Validation loss: 1.98743684317476

Epoch: 6| Step: 8
Training loss: 0.9169026613235474
Validation loss: 1.9961545236649052

Epoch: 6| Step: 9
Training loss: 1.1963422298431396
Validation loss: 1.9860302453399987

Epoch: 6| Step: 10
Training loss: 1.5916154384613037
Validation loss: 2.00741324886199

Epoch: 6| Step: 11
Training loss: 0.8694055080413818
Validation loss: 1.9872700014422018

Epoch: 6| Step: 12
Training loss: 1.6176543235778809
Validation loss: 2.01106119924976

Epoch: 6| Step: 13
Training loss: 1.1784285306930542
Validation loss: 2.0430269715606526

Epoch: 230| Step: 0
Training loss: 1.1080989837646484
Validation loss: 2.0477010242400633

Epoch: 6| Step: 1
Training loss: 1.4742714166641235
Validation loss: 2.0495708629649174

Epoch: 6| Step: 2
Training loss: 1.0993854999542236
Validation loss: 2.038395284324564

Epoch: 6| Step: 3
Training loss: 1.2280828952789307
Validation loss: 2.0459591932194208

Epoch: 6| Step: 4
Training loss: 2.1391711235046387
Validation loss: 2.046267908106568

Epoch: 6| Step: 5
Training loss: 1.4269675016403198
Validation loss: 2.0545305167475054

Epoch: 6| Step: 6
Training loss: 0.77419513463974
Validation loss: 1.9977958702271985

Epoch: 6| Step: 7
Training loss: 0.885273814201355
Validation loss: 2.0134274985200618

Epoch: 6| Step: 8
Training loss: 0.9784089922904968
Validation loss: 1.998124477683857

Epoch: 6| Step: 9
Training loss: 1.619131326675415
Validation loss: 1.9983470337365263

Epoch: 6| Step: 10
Training loss: 1.5808765888214111
Validation loss: 1.9920620379909393

Epoch: 6| Step: 11
Training loss: 1.1366502046585083
Validation loss: 1.9792617623524

Epoch: 6| Step: 12
Training loss: 1.2314947843551636
Validation loss: 1.9664840095786638

Epoch: 6| Step: 13
Training loss: 0.8933089375495911
Validation loss: 1.9576591637826735

Epoch: 231| Step: 0
Training loss: 0.9248834848403931
Validation loss: 1.9611167394986717

Epoch: 6| Step: 1
Training loss: 1.5556180477142334
Validation loss: 1.9265989334352556

Epoch: 6| Step: 2
Training loss: 1.1762120723724365
Validation loss: 1.9436330256923553

Epoch: 6| Step: 3
Training loss: 1.0382447242736816
Validation loss: 1.9374533481495355

Epoch: 6| Step: 4
Training loss: 1.4923492670059204
Validation loss: 1.9447686877301944

Epoch: 6| Step: 5
Training loss: 1.4820315837860107
Validation loss: 1.9701594139939995

Epoch: 6| Step: 6
Training loss: 1.6230227947235107
Validation loss: 1.9925535853191088

Epoch: 6| Step: 7
Training loss: 1.876603364944458
Validation loss: 2.0385685582314768

Epoch: 6| Step: 8
Training loss: 0.7073902487754822
Validation loss: 2.042277564284622

Epoch: 6| Step: 9
Training loss: 0.8741214871406555
Validation loss: 2.048688937258977

Epoch: 6| Step: 10
Training loss: 1.084590196609497
Validation loss: 2.0116162761565177

Epoch: 6| Step: 11
Training loss: 1.246497631072998
Validation loss: 1.988532462427693

Epoch: 6| Step: 12
Training loss: 0.7188043594360352
Validation loss: 1.9762885903799405

Epoch: 6| Step: 13
Training loss: 0.8822374939918518
Validation loss: 1.9538273734431113

Epoch: 232| Step: 0
Training loss: 1.0216933488845825
Validation loss: 1.9562784997365807

Epoch: 6| Step: 1
Training loss: 1.0096015930175781
Validation loss: 1.963262314437538

Epoch: 6| Step: 2
Training loss: 0.7695627808570862
Validation loss: 1.9716666001145557

Epoch: 6| Step: 3
Training loss: 0.9093393087387085
Validation loss: 2.001639671223138

Epoch: 6| Step: 4
Training loss: 1.1148948669433594
Validation loss: 2.0459495468806197

Epoch: 6| Step: 5
Training loss: 1.4358344078063965
Validation loss: 2.0843858590690036

Epoch: 6| Step: 6
Training loss: 1.273633360862732
Validation loss: 2.0755964248411116

Epoch: 6| Step: 7
Training loss: 1.798636555671692
Validation loss: 2.053646288892274

Epoch: 6| Step: 8
Training loss: 1.4685639142990112
Validation loss: 2.000577019106957

Epoch: 6| Step: 9
Training loss: 0.943510890007019
Validation loss: 2.018520894870963

Epoch: 6| Step: 10
Training loss: 1.539387583732605
Validation loss: 2.0161342108121483

Epoch: 6| Step: 11
Training loss: 1.2746171951293945
Validation loss: 2.003118243268741

Epoch: 6| Step: 12
Training loss: 1.2435767650604248
Validation loss: 1.9692722110338108

Epoch: 6| Step: 13
Training loss: 1.2943013906478882
Validation loss: 1.9678352725121282

Epoch: 233| Step: 0
Training loss: 1.2866082191467285
Validation loss: 1.9697571518600627

Epoch: 6| Step: 1
Training loss: 1.03449285030365
Validation loss: 1.9686595624493015

Epoch: 6| Step: 2
Training loss: 1.4381170272827148
Validation loss: 1.9984127988097489

Epoch: 6| Step: 3
Training loss: 0.9837174415588379
Validation loss: 2.0030346275657736

Epoch: 6| Step: 4
Training loss: 1.1661431789398193
Validation loss: 2.0244899770264984

Epoch: 6| Step: 5
Training loss: 1.3354318141937256
Validation loss: 2.0354148418672624

Epoch: 6| Step: 6
Training loss: 1.1333181858062744
Validation loss: 2.0713973352985997

Epoch: 6| Step: 7
Training loss: 1.45743727684021
Validation loss: 2.0570147857871106

Epoch: 6| Step: 8
Training loss: 0.9937542676925659
Validation loss: 2.0573962888410016

Epoch: 6| Step: 9
Training loss: 1.4150545597076416
Validation loss: 2.019548490483274

Epoch: 6| Step: 10
Training loss: 1.2440913915634155
Validation loss: 2.0056053297494048

Epoch: 6| Step: 11
Training loss: 0.8346139788627625
Validation loss: 1.9645300283226916

Epoch: 6| Step: 12
Training loss: 0.9319949150085449
Validation loss: 1.9356173648629138

Epoch: 6| Step: 13
Training loss: 1.5296318531036377
Validation loss: 1.9349107562854726

Epoch: 234| Step: 0
Training loss: 1.5679547786712646
Validation loss: 1.9295229296530447

Epoch: 6| Step: 1
Training loss: 1.1438953876495361
Validation loss: 1.9432856293134793

Epoch: 6| Step: 2
Training loss: 0.9103906750679016
Validation loss: 1.985725655350634

Epoch: 6| Step: 3
Training loss: 1.4874238967895508
Validation loss: 2.0195416404354956

Epoch: 6| Step: 4
Training loss: 0.9468353390693665
Validation loss: 2.017472897806475

Epoch: 6| Step: 5
Training loss: 1.0288417339324951
Validation loss: 2.0440214705723587

Epoch: 6| Step: 6
Training loss: 1.118522047996521
Validation loss: 1.981668391535359

Epoch: 6| Step: 7
Training loss: 0.4382469952106476
Validation loss: 1.9595445304788568

Epoch: 6| Step: 8
Training loss: 2.100512981414795
Validation loss: 1.9172343861672185

Epoch: 6| Step: 9
Training loss: 1.208459734916687
Validation loss: 1.9104780484271306

Epoch: 6| Step: 10
Training loss: 1.7385156154632568
Validation loss: 1.9182584567736554

Epoch: 6| Step: 11
Training loss: 1.2809072732925415
Validation loss: 1.9083609709175684

Epoch: 6| Step: 12
Training loss: 0.8393495082855225
Validation loss: 1.9113496888068415

Epoch: 6| Step: 13
Training loss: 1.1889090538024902
Validation loss: 1.934121706152475

Epoch: 235| Step: 0
Training loss: 1.4095696210861206
Validation loss: 1.9346856481285506

Epoch: 6| Step: 1
Training loss: 0.8019010424613953
Validation loss: 1.966654808290543

Epoch: 6| Step: 2
Training loss: 1.2584311962127686
Validation loss: 2.0061312106347855

Epoch: 6| Step: 3
Training loss: 1.5101652145385742
Validation loss: 2.017763845382198

Epoch: 6| Step: 4
Training loss: 1.3392360210418701
Validation loss: 2.046830992544851

Epoch: 6| Step: 5
Training loss: 1.0015954971313477
Validation loss: 2.06476471501012

Epoch: 6| Step: 6
Training loss: 1.5534961223602295
Validation loss: 2.035865883673391

Epoch: 6| Step: 7
Training loss: 1.0785942077636719
Validation loss: 2.026260109357936

Epoch: 6| Step: 8
Training loss: 1.1029999256134033
Validation loss: 2.008196593612753

Epoch: 6| Step: 9
Training loss: 1.4030689001083374
Validation loss: 2.016878894580308

Epoch: 6| Step: 10
Training loss: 1.1878727674484253
Validation loss: 1.9737922030110513

Epoch: 6| Step: 11
Training loss: 0.8594538569450378
Validation loss: 1.9595167944508214

Epoch: 6| Step: 12
Training loss: 1.3058468103408813
Validation loss: 1.9113450947628225

Epoch: 6| Step: 13
Training loss: 0.4961603879928589
Validation loss: 1.9109646581834363

Epoch: 236| Step: 0
Training loss: 1.4493372440338135
Validation loss: 1.9046634794563375

Epoch: 6| Step: 1
Training loss: 1.213681697845459
Validation loss: 1.9295917493040844

Epoch: 6| Step: 2
Training loss: 1.2994027137756348
Validation loss: 1.9067936943423363

Epoch: 6| Step: 3
Training loss: 1.0729650259017944
Validation loss: 1.9225006270152267

Epoch: 6| Step: 4
Training loss: 0.5279107093811035
Validation loss: 1.9352272479764876

Epoch: 6| Step: 5
Training loss: 1.2217156887054443
Validation loss: 1.9297893713879328

Epoch: 6| Step: 6
Training loss: 1.0107040405273438
Validation loss: 1.9402059534544587

Epoch: 6| Step: 7
Training loss: 0.8011521697044373
Validation loss: 1.93028925952091

Epoch: 6| Step: 8
Training loss: 0.8154746294021606
Validation loss: 1.9486377405863937

Epoch: 6| Step: 9
Training loss: 1.5922176837921143
Validation loss: 1.9722001629491006

Epoch: 6| Step: 10
Training loss: 0.9517369270324707
Validation loss: 1.9676409331701135

Epoch: 6| Step: 11
Training loss: 1.6250860691070557
Validation loss: 2.005441733585891

Epoch: 6| Step: 12
Training loss: 1.051534652709961
Validation loss: 2.0252271634276195

Epoch: 6| Step: 13
Training loss: 1.6459397077560425
Validation loss: 2.0533383225881927

Epoch: 237| Step: 0
Training loss: 0.6616746187210083
Validation loss: 2.0065548112315517

Epoch: 6| Step: 1
Training loss: 1.1645245552062988
Validation loss: 2.002655167733469

Epoch: 6| Step: 2
Training loss: 1.4609451293945312
Validation loss: 1.9769918816063994

Epoch: 6| Step: 3
Training loss: 1.5511146783828735
Validation loss: 1.9551131174128542

Epoch: 6| Step: 4
Training loss: 1.1307549476623535
Validation loss: 1.957446793074249

Epoch: 6| Step: 5
Training loss: 1.4269474744796753
Validation loss: 1.9198756115410918

Epoch: 6| Step: 6
Training loss: 0.7427840828895569
Validation loss: 1.9208389341190297

Epoch: 6| Step: 7
Training loss: 1.29367995262146
Validation loss: 1.9385249255805888

Epoch: 6| Step: 8
Training loss: 1.209069848060608
Validation loss: 1.9878173258996779

Epoch: 6| Step: 9
Training loss: 1.2305289506912231
Validation loss: 2.0311322135310017

Epoch: 6| Step: 10
Training loss: 0.5722553730010986
Validation loss: 2.0504606334112023

Epoch: 6| Step: 11
Training loss: 1.3070026636123657
Validation loss: 2.0316047540274997

Epoch: 6| Step: 12
Training loss: 0.851656436920166
Validation loss: 2.031618223395399

Epoch: 6| Step: 13
Training loss: 1.4596143960952759
Validation loss: 2.0326604586775585

Epoch: 238| Step: 0
Training loss: 1.0895040035247803
Validation loss: 2.040428243657594

Epoch: 6| Step: 1
Training loss: 1.0656126737594604
Validation loss: 2.0526772147865704

Epoch: 6| Step: 2
Training loss: 0.8866949081420898
Validation loss: 2.020729628942346

Epoch: 6| Step: 3
Training loss: 1.0468544960021973
Validation loss: 1.9967706895643664

Epoch: 6| Step: 4
Training loss: 1.4296268224716187
Validation loss: 1.9907056554671256

Epoch: 6| Step: 5
Training loss: 0.8797911405563354
Validation loss: 1.9888079217685166

Epoch: 6| Step: 6
Training loss: 1.3198764324188232
Validation loss: 1.950886558460933

Epoch: 6| Step: 7
Training loss: 1.2736856937408447
Validation loss: 1.969421987892479

Epoch: 6| Step: 8
Training loss: 1.2024554014205933
Validation loss: 1.994413552745696

Epoch: 6| Step: 9
Training loss: 1.057511329650879
Validation loss: 2.009978962200944

Epoch: 6| Step: 10
Training loss: 1.0029264688491821
Validation loss: 2.0362454204149145

Epoch: 6| Step: 11
Training loss: 1.5281647443771362
Validation loss: 2.029054603269023

Epoch: 6| Step: 12
Training loss: 1.3388288021087646
Validation loss: 2.0096777741627028

Epoch: 6| Step: 13
Training loss: 0.4831048548221588
Validation loss: 1.9615503690576042

Epoch: 239| Step: 0
Training loss: 0.8099421262741089
Validation loss: 1.9681074914111887

Epoch: 6| Step: 1
Training loss: 0.7898786067962646
Validation loss: 1.9874374225575437

Epoch: 6| Step: 2
Training loss: 1.7004258632659912
Validation loss: 2.0307674895050707

Epoch: 6| Step: 3
Training loss: 1.2774460315704346
Validation loss: 2.0045946669834915

Epoch: 6| Step: 4
Training loss: 0.8298405408859253
Validation loss: 1.9854414360497588

Epoch: 6| Step: 5
Training loss: 1.1776018142700195
Validation loss: 1.9702417722312353

Epoch: 6| Step: 6
Training loss: 1.1716060638427734
Validation loss: 1.9259580386582242

Epoch: 6| Step: 7
Training loss: 0.9128220081329346
Validation loss: 1.9189343977999944

Epoch: 6| Step: 8
Training loss: 1.6159425973892212
Validation loss: 1.9200801900638047

Epoch: 6| Step: 9
Training loss: 1.2770817279815674
Validation loss: 1.9221710620387908

Epoch: 6| Step: 10
Training loss: 0.7679448127746582
Validation loss: 1.908344808445182

Epoch: 6| Step: 11
Training loss: 1.493758201599121
Validation loss: 1.9059850015947897

Epoch: 6| Step: 12
Training loss: 0.7976124286651611
Validation loss: 1.906426546394184

Epoch: 6| Step: 13
Training loss: 1.0038427114486694
Validation loss: 1.8891730923806467

Epoch: 240| Step: 0
Training loss: 1.043271780014038
Validation loss: 1.8864746145022813

Epoch: 6| Step: 1
Training loss: 1.4274706840515137
Validation loss: 1.8921860943558395

Epoch: 6| Step: 2
Training loss: 1.2565832138061523
Validation loss: 1.9033147147906724

Epoch: 6| Step: 3
Training loss: 0.8624356389045715
Validation loss: 1.938666505198325

Epoch: 6| Step: 4
Training loss: 1.4380574226379395
Validation loss: 2.010629227084498

Epoch: 6| Step: 5
Training loss: 1.393846035003662
Validation loss: 2.011031263618059

Epoch: 6| Step: 6
Training loss: 1.0023326873779297
Validation loss: 2.022607934090399

Epoch: 6| Step: 7
Training loss: 1.088215947151184
Validation loss: 1.9664248497255388

Epoch: 6| Step: 8
Training loss: 0.8010239601135254
Validation loss: 1.9637015609331028

Epoch: 6| Step: 9
Training loss: 0.8929620385169983
Validation loss: 1.9617007393990793

Epoch: 6| Step: 10
Training loss: 1.2334010601043701
Validation loss: 1.937122324461578

Epoch: 6| Step: 11
Training loss: 0.8082271218299866
Validation loss: 1.9379493574942313

Epoch: 6| Step: 12
Training loss: 1.1564512252807617
Validation loss: 1.935893254895364

Epoch: 6| Step: 13
Training loss: 1.28622305393219
Validation loss: 1.9462540675235052

Epoch: 241| Step: 0
Training loss: 0.6993035078048706
Validation loss: 1.9311910483144945

Epoch: 6| Step: 1
Training loss: 1.3993229866027832
Validation loss: 1.9619962246187272

Epoch: 6| Step: 2
Training loss: 1.1676537990570068
Validation loss: 1.9566923354261665

Epoch: 6| Step: 3
Training loss: 1.1934926509857178
Validation loss: 1.9681564710473503

Epoch: 6| Step: 4
Training loss: 1.6315686702728271
Validation loss: 2.010488945950744

Epoch: 6| Step: 5
Training loss: 1.0366936922073364
Validation loss: 2.0220480631756526

Epoch: 6| Step: 6
Training loss: 1.2401344776153564
Validation loss: 2.0151435098340436

Epoch: 6| Step: 7
Training loss: 1.190787434577942
Validation loss: 2.0466267960045927

Epoch: 6| Step: 8
Training loss: 1.3840340375900269
Validation loss: 2.0644424602549565

Epoch: 6| Step: 9
Training loss: 0.9437116384506226
Validation loss: 2.0610266552176526

Epoch: 6| Step: 10
Training loss: 0.8679441213607788
Validation loss: 2.0283904819078344

Epoch: 6| Step: 11
Training loss: 1.0958757400512695
Validation loss: 2.0236632516307216

Epoch: 6| Step: 12
Training loss: 0.7832544445991516
Validation loss: 2.009627913915983

Epoch: 6| Step: 13
Training loss: 0.9897229671478271
Validation loss: 1.9805422777770667

Epoch: 242| Step: 0
Training loss: 1.0657894611358643
Validation loss: 2.0122471368441017

Epoch: 6| Step: 1
Training loss: 0.9113044738769531
Validation loss: 2.010148448328818

Epoch: 6| Step: 2
Training loss: 1.0338305234909058
Validation loss: 1.98652938360809

Epoch: 6| Step: 3
Training loss: 1.304598331451416
Validation loss: 1.986199935277303

Epoch: 6| Step: 4
Training loss: 0.7310957312583923
Validation loss: 1.9512981599377048

Epoch: 6| Step: 5
Training loss: 1.276448130607605
Validation loss: 1.9800169711471887

Epoch: 6| Step: 6
Training loss: 0.6370335817337036
Validation loss: 1.9794933924110987

Epoch: 6| Step: 7
Training loss: 0.6102923154830933
Validation loss: 1.9969069803914716

Epoch: 6| Step: 8
Training loss: 1.458924651145935
Validation loss: 2.0142787682112826

Epoch: 6| Step: 9
Training loss: 1.2279911041259766
Validation loss: 2.0106091383964784

Epoch: 6| Step: 10
Training loss: 1.2890435457229614
Validation loss: 1.9856690309380973

Epoch: 6| Step: 11
Training loss: 1.1205558776855469
Validation loss: 1.9907886905054892

Epoch: 6| Step: 12
Training loss: 1.40745210647583
Validation loss: 1.984423634826496

Epoch: 6| Step: 13
Training loss: 0.9406753182411194
Validation loss: 1.9554770377374464

Epoch: 243| Step: 0
Training loss: 0.3223598599433899
Validation loss: 1.9766563215563375

Epoch: 6| Step: 1
Training loss: 0.8578811883926392
Validation loss: 1.9563754925163843

Epoch: 6| Step: 2
Training loss: 1.273829460144043
Validation loss: 1.9819945545606716

Epoch: 6| Step: 3
Training loss: 1.0243167877197266
Validation loss: 1.9622463039172593

Epoch: 6| Step: 4
Training loss: 0.6039570569992065
Validation loss: 1.973252486157161

Epoch: 6| Step: 5
Training loss: 1.6265325546264648
Validation loss: 1.9547994905902493

Epoch: 6| Step: 6
Training loss: 1.4346498250961304
Validation loss: 1.9243707785042383

Epoch: 6| Step: 7
Training loss: 0.9561557769775391
Validation loss: 1.921630021064512

Epoch: 6| Step: 8
Training loss: 0.8447920083999634
Validation loss: 1.919071792274393

Epoch: 6| Step: 9
Training loss: 0.9934902787208557
Validation loss: 1.9345925597734348

Epoch: 6| Step: 10
Training loss: 1.251678466796875
Validation loss: 1.919155025994906

Epoch: 6| Step: 11
Training loss: 1.3888213634490967
Validation loss: 1.9366036281790784

Epoch: 6| Step: 12
Training loss: 0.9258062839508057
Validation loss: 1.9333317279815674

Epoch: 6| Step: 13
Training loss: 0.9662516117095947
Validation loss: 1.9622387322046424

Epoch: 244| Step: 0
Training loss: 1.1568622589111328
Validation loss: 1.9780776269974247

Epoch: 6| Step: 1
Training loss: 1.068232774734497
Validation loss: 1.9669291985932218

Epoch: 6| Step: 2
Training loss: 0.6689505577087402
Validation loss: 2.032521988755913

Epoch: 6| Step: 3
Training loss: 1.5098929405212402
Validation loss: 2.030363949396277

Epoch: 6| Step: 4
Training loss: 0.8208931088447571
Validation loss: 2.0628519237682386

Epoch: 6| Step: 5
Training loss: 1.15249502658844
Validation loss: 2.0726736463526243

Epoch: 6| Step: 6
Training loss: 0.6982234716415405
Validation loss: 2.030433565057734

Epoch: 6| Step: 7
Training loss: 1.168292760848999
Validation loss: 2.015477790627428

Epoch: 6| Step: 8
Training loss: 1.0790246725082397
Validation loss: 2.000807839055215

Epoch: 6| Step: 9
Training loss: 0.8671500086784363
Validation loss: 1.972691664131739

Epoch: 6| Step: 10
Training loss: 1.1055279970169067
Validation loss: 1.926428807679043

Epoch: 6| Step: 11
Training loss: 1.3241478204727173
Validation loss: 1.906600062565137

Epoch: 6| Step: 12
Training loss: 0.857041597366333
Validation loss: 1.882791893456572

Epoch: 6| Step: 13
Training loss: 1.4587428569793701
Validation loss: 1.880429558856513

Epoch: 245| Step: 0
Training loss: 1.8077833652496338
Validation loss: 1.87136661365468

Epoch: 6| Step: 1
Training loss: 1.5510058403015137
Validation loss: 1.9069803055896555

Epoch: 6| Step: 2
Training loss: 1.2415344715118408
Validation loss: 1.9266766707102458

Epoch: 6| Step: 3
Training loss: 0.648260235786438
Validation loss: 1.937406527098789

Epoch: 6| Step: 4
Training loss: 0.8597415685653687
Validation loss: 1.969952170566846

Epoch: 6| Step: 5
Training loss: 0.8919508457183838
Validation loss: 1.973436899082635

Epoch: 6| Step: 6
Training loss: 0.6965962052345276
Validation loss: 1.9788608153661091

Epoch: 6| Step: 7
Training loss: 0.8220788240432739
Validation loss: 1.96760525754703

Epoch: 6| Step: 8
Training loss: 1.2776775360107422
Validation loss: 1.971801156638771

Epoch: 6| Step: 9
Training loss: 0.9161010384559631
Validation loss: 1.9737244434254144

Epoch: 6| Step: 10
Training loss: 0.9787356853485107
Validation loss: 1.9858051423103578

Epoch: 6| Step: 11
Training loss: 1.0173901319503784
Validation loss: 1.9977554659689627

Epoch: 6| Step: 12
Training loss: 0.9715456366539001
Validation loss: 2.0265971024831138

Epoch: 6| Step: 13
Training loss: 1.6483098268508911
Validation loss: 2.033658987732344

Epoch: 246| Step: 0
Training loss: 0.7928515672683716
Validation loss: 1.9970409152328328

Epoch: 6| Step: 1
Training loss: 1.207842469215393
Validation loss: 1.9898008044048021

Epoch: 6| Step: 2
Training loss: 1.248483419418335
Validation loss: 1.9981583613221363

Epoch: 6| Step: 3
Training loss: 1.534439206123352
Validation loss: 1.990346029881508

Epoch: 6| Step: 4
Training loss: 1.1102168560028076
Validation loss: 2.0039174031185847

Epoch: 6| Step: 5
Training loss: 1.4554095268249512
Validation loss: 2.007022758965851

Epoch: 6| Step: 6
Training loss: 0.582323431968689
Validation loss: 1.9966607529629943

Epoch: 6| Step: 7
Training loss: 0.6897926926612854
Validation loss: 2.0113289817687003

Epoch: 6| Step: 8
Training loss: 1.0116517543792725
Validation loss: 2.0131320773914294

Epoch: 6| Step: 9
Training loss: 1.0500558614730835
Validation loss: 1.9999427872319375

Epoch: 6| Step: 10
Training loss: 1.0732927322387695
Validation loss: 1.9981545966158631

Epoch: 6| Step: 11
Training loss: 0.5086383819580078
Validation loss: 1.9731585107823855

Epoch: 6| Step: 12
Training loss: 1.4976061582565308
Validation loss: 1.9611031880942724

Epoch: 6| Step: 13
Training loss: 0.6663762331008911
Validation loss: 1.938469595806573

Epoch: 247| Step: 0
Training loss: 1.2866591215133667
Validation loss: 1.929527118641843

Epoch: 6| Step: 1
Training loss: 1.1360139846801758
Validation loss: 1.9144342637831164

Epoch: 6| Step: 2
Training loss: 1.2338495254516602
Validation loss: 1.9011890221667547

Epoch: 6| Step: 3
Training loss: 1.188610553741455
Validation loss: 1.9030922612836283

Epoch: 6| Step: 4
Training loss: 1.331558346748352
Validation loss: 1.9118233726870628

Epoch: 6| Step: 5
Training loss: 1.0786755084991455
Validation loss: 1.9460505747026013

Epoch: 6| Step: 6
Training loss: 0.6606010794639587
Validation loss: 1.9121760065837572

Epoch: 6| Step: 7
Training loss: 0.7829875349998474
Validation loss: 1.9126189543354897

Epoch: 6| Step: 8
Training loss: 0.950039803981781
Validation loss: 1.9111162577905962

Epoch: 6| Step: 9
Training loss: 1.3861850500106812
Validation loss: 1.9093318985354515

Epoch: 6| Step: 10
Training loss: 0.9460190534591675
Validation loss: 1.8995385298164942

Epoch: 6| Step: 11
Training loss: 1.3072307109832764
Validation loss: 1.8780048995889642

Epoch: 6| Step: 12
Training loss: 0.8132390975952148
Validation loss: 1.8885668093158352

Epoch: 6| Step: 13
Training loss: 0.8310204744338989
Validation loss: 1.8927296541070426

Epoch: 248| Step: 0
Training loss: 0.9658264517784119
Validation loss: 1.9055065903612363

Epoch: 6| Step: 1
Training loss: 0.6770657300949097
Validation loss: 1.931609611357412

Epoch: 6| Step: 2
Training loss: 0.9707705974578857
Validation loss: 1.953963848852342

Epoch: 6| Step: 3
Training loss: 1.4381791353225708
Validation loss: 1.9947125475893739

Epoch: 6| Step: 4
Training loss: 1.1514321565628052
Validation loss: 2.0234061466750277

Epoch: 6| Step: 5
Training loss: 1.1862475872039795
Validation loss: 2.0143345376496673

Epoch: 6| Step: 6
Training loss: 0.9074558019638062
Validation loss: 2.023018995920817

Epoch: 6| Step: 7
Training loss: 0.9043704271316528
Validation loss: 2.0259941906057377

Epoch: 6| Step: 8
Training loss: 0.7539002895355225
Validation loss: 2.0190716199977423

Epoch: 6| Step: 9
Training loss: 1.4302469491958618
Validation loss: 1.9801472066551127

Epoch: 6| Step: 10
Training loss: 1.176444411277771
Validation loss: 1.94380186962825

Epoch: 6| Step: 11
Training loss: 1.0494914054870605
Validation loss: 1.922610354679887

Epoch: 6| Step: 12
Training loss: 0.8277280330657959
Validation loss: 1.9480670780263922

Epoch: 6| Step: 13
Training loss: 1.6863194704055786
Validation loss: 1.9204742139385593

Epoch: 249| Step: 0
Training loss: 0.8013656735420227
Validation loss: 1.93470924515878

Epoch: 6| Step: 1
Training loss: 1.1370093822479248
Validation loss: 1.9524296688777145

Epoch: 6| Step: 2
Training loss: 0.8350121974945068
Validation loss: 1.9807991725142284

Epoch: 6| Step: 3
Training loss: 1.349875569343567
Validation loss: 1.9886519703813779

Epoch: 6| Step: 4
Training loss: 1.3117995262145996
Validation loss: 2.008082784632201

Epoch: 6| Step: 5
Training loss: 1.0888283252716064
Validation loss: 1.9805354379838513

Epoch: 6| Step: 6
Training loss: 0.9722225069999695
Validation loss: 1.9458877989040908

Epoch: 6| Step: 7
Training loss: 1.6614634990692139
Validation loss: 1.944527022300228

Epoch: 6| Step: 8
Training loss: 0.7055320739746094
Validation loss: 1.970179982082818

Epoch: 6| Step: 9
Training loss: 1.0859546661376953
Validation loss: 1.9476217864662089

Epoch: 6| Step: 10
Training loss: 1.486579418182373
Validation loss: 1.9554418056241927

Epoch: 6| Step: 11
Training loss: 0.6170050501823425
Validation loss: 1.9289621435185915

Epoch: 6| Step: 12
Training loss: 0.8084388971328735
Validation loss: 1.9133382663931897

Epoch: 6| Step: 13
Training loss: 1.0131564140319824
Validation loss: 1.9086998406276907

Epoch: 250| Step: 0
Training loss: 0.24397389590740204
Validation loss: 1.9202472766240437

Epoch: 6| Step: 1
Training loss: 0.9813489317893982
Validation loss: 1.9412454007774271

Epoch: 6| Step: 2
Training loss: 1.0228233337402344
Validation loss: 1.979660621253393

Epoch: 6| Step: 3
Training loss: 0.6002775430679321
Validation loss: 1.99431775974971

Epoch: 6| Step: 4
Training loss: 1.459539771080017
Validation loss: 2.0183816366298224

Epoch: 6| Step: 5
Training loss: 1.0688985586166382
Validation loss: 1.9800925947004748

Epoch: 6| Step: 6
Training loss: 1.0149810314178467
Validation loss: 1.9490485524618497

Epoch: 6| Step: 7
Training loss: 1.3250168561935425
Validation loss: 1.9275594603630803

Epoch: 6| Step: 8
Training loss: 0.8499515056610107
Validation loss: 1.8863302174434866

Epoch: 6| Step: 9
Training loss: 1.5214412212371826
Validation loss: 1.9188786065706642

Epoch: 6| Step: 10
Training loss: 1.4595754146575928
Validation loss: 1.9165158502517208

Epoch: 6| Step: 11
Training loss: 0.9482276439666748
Validation loss: 1.926701158605596

Epoch: 6| Step: 12
Training loss: 0.9169037938117981
Validation loss: 1.941893990321826

Epoch: 6| Step: 13
Training loss: 0.7298445105552673
Validation loss: 1.9661837688056372

Testing loss: 2.4434704144795734
