Epoch: 1| Step: 0
Training loss: 6.525464575587404
Validation loss: 5.837560478610894

Epoch: 5| Step: 1
Training loss: 5.883330262843439
Validation loss: 5.814003038970274

Epoch: 5| Step: 2
Training loss: 5.608274899197676
Validation loss: 5.794177128825793

Epoch: 5| Step: 3
Training loss: 6.10276214099089
Validation loss: 5.772765648798912

Epoch: 5| Step: 4
Training loss: 4.4530924477976885
Validation loss: 5.748035261095131

Epoch: 5| Step: 5
Training loss: 5.979160038571112
Validation loss: 5.721149337761157

Epoch: 5| Step: 6
Training loss: 6.367124292726914
Validation loss: 5.688853394351059

Epoch: 5| Step: 7
Training loss: 5.792959860179456
Validation loss: 5.652156002920898

Epoch: 5| Step: 8
Training loss: 5.281771120623677
Validation loss: 5.610975780389546

Epoch: 5| Step: 9
Training loss: 3.7548373493671647
Validation loss: 5.564457109283052

Epoch: 5| Step: 10
Training loss: 6.851727299899457
Validation loss: 5.512962024048049

Epoch: 2| Step: 0
Training loss: 5.696928823178101
Validation loss: 5.455596297088115

Epoch: 5| Step: 1
Training loss: 5.022630594092781
Validation loss: 5.393511987830149

Epoch: 5| Step: 2
Training loss: 4.51120993647407
Validation loss: 5.328765125318477

Epoch: 5| Step: 3
Training loss: 5.252097119690675
Validation loss: 5.260167255497533

Epoch: 5| Step: 4
Training loss: 5.825343554929527
Validation loss: 5.190568338971591

Epoch: 5| Step: 5
Training loss: 6.38292814451158
Validation loss: 5.120854633862756

Epoch: 5| Step: 6
Training loss: 4.706105247996969
Validation loss: 5.054557948124311

Epoch: 5| Step: 7
Training loss: 5.120215625096794
Validation loss: 4.991465306768053

Epoch: 5| Step: 8
Training loss: 4.859514534961587
Validation loss: 4.933661775262347

Epoch: 5| Step: 9
Training loss: 5.2492969587165685
Validation loss: 4.88202201472666

Epoch: 5| Step: 10
Training loss: 3.9610723288196374
Validation loss: 4.836820182019158

Epoch: 3| Step: 0
Training loss: 4.581008784044426
Validation loss: 4.7960234486057995

Epoch: 5| Step: 1
Training loss: 4.577877936352878
Validation loss: 4.7609892484401

Epoch: 5| Step: 2
Training loss: 5.240947730284311
Validation loss: 4.727628842285017

Epoch: 5| Step: 3
Training loss: 5.572384057188677
Validation loss: 4.696576668170559

Epoch: 5| Step: 4
Training loss: 5.130825174752785
Validation loss: 4.663264824837104

Epoch: 5| Step: 5
Training loss: 5.235358757835244
Validation loss: 4.624715743659831

Epoch: 5| Step: 6
Training loss: 4.669497085709259
Validation loss: 4.588304745841671

Epoch: 5| Step: 7
Training loss: 4.567172649410298
Validation loss: 4.5641048933456405

Epoch: 5| Step: 8
Training loss: 4.129546001318057
Validation loss: 4.542793713607319

Epoch: 5| Step: 9
Training loss: 3.3360801505470494
Validation loss: 4.5262992384665175

Epoch: 5| Step: 10
Training loss: 4.736751551627003
Validation loss: 4.512348457723092

Epoch: 4| Step: 0
Training loss: 4.306482954880215
Validation loss: 4.499864364275328

Epoch: 5| Step: 1
Training loss: 4.315660949159536
Validation loss: 4.486509755063694

Epoch: 5| Step: 2
Training loss: 4.539244866441943
Validation loss: 4.474382864591617

Epoch: 5| Step: 3
Training loss: 5.6709609122667235
Validation loss: 4.4581099622813625

Epoch: 5| Step: 4
Training loss: 5.190914455107984
Validation loss: 4.439008334811753

Epoch: 5| Step: 5
Training loss: 4.816489807542637
Validation loss: 4.422125791514242

Epoch: 5| Step: 6
Training loss: 3.914325027646287
Validation loss: 4.405509766115612

Epoch: 5| Step: 7
Training loss: 4.525449420677072
Validation loss: 4.391262337061739

Epoch: 5| Step: 8
Training loss: 4.2340173323920265
Validation loss: 4.3764134340298755

Epoch: 5| Step: 9
Training loss: 3.9745893398220464
Validation loss: 4.361754046823334

Epoch: 5| Step: 10
Training loss: 4.109052638184868
Validation loss: 4.347266684030719

Epoch: 5| Step: 0
Training loss: 5.274314705686799
Validation loss: 4.332264173546433

Epoch: 5| Step: 1
Training loss: 4.388263759812483
Validation loss: 4.317582730358785

Epoch: 5| Step: 2
Training loss: 4.547266363231191
Validation loss: 4.303296910659529

Epoch: 5| Step: 3
Training loss: 4.627020317288607
Validation loss: 4.291369371225163

Epoch: 5| Step: 4
Training loss: 4.6084705564591575
Validation loss: 4.27360894594772

Epoch: 5| Step: 5
Training loss: 3.800676115018802
Validation loss: 4.25147998238286

Epoch: 5| Step: 6
Training loss: 4.322570100550125
Validation loss: 4.23330912271026

Epoch: 5| Step: 7
Training loss: 3.5316669589287524
Validation loss: 4.2149458505249315

Epoch: 5| Step: 8
Training loss: 4.647512340642131
Validation loss: 4.198599787446363

Epoch: 5| Step: 9
Training loss: 4.224580254103863
Validation loss: 4.178616360442288

Epoch: 5| Step: 10
Training loss: 3.905149014764308
Validation loss: 4.15878395433638

Epoch: 6| Step: 0
Training loss: 4.751182609708439
Validation loss: 4.143043972682217

Epoch: 5| Step: 1
Training loss: 4.283586964105285
Validation loss: 4.127524448985041

Epoch: 5| Step: 2
Training loss: 4.186138330236239
Validation loss: 4.111967761966708

Epoch: 5| Step: 3
Training loss: 4.178461597382556
Validation loss: 4.092047437422132

Epoch: 5| Step: 4
Training loss: 4.502982528730567
Validation loss: 4.0761522723566594

Epoch: 5| Step: 5
Training loss: 3.4301961812671853
Validation loss: 4.057978875936917

Epoch: 5| Step: 6
Training loss: 4.839639605510979
Validation loss: 4.04509368739314

Epoch: 5| Step: 7
Training loss: 4.284692869630278
Validation loss: 4.033454034948962

Epoch: 5| Step: 8
Training loss: 3.5523883468617203
Validation loss: 4.0192576568529175

Epoch: 5| Step: 9
Training loss: 3.705971569390721
Validation loss: 4.009822472974724

Epoch: 5| Step: 10
Training loss: 4.4340523234761475
Validation loss: 4.00250064839472

Epoch: 7| Step: 0
Training loss: 3.8953075496123404
Validation loss: 3.992059835678766

Epoch: 5| Step: 1
Training loss: 3.6950035691921563
Validation loss: 3.9862098865024382

Epoch: 5| Step: 2
Training loss: 3.540645287532207
Validation loss: 3.9801709497450504

Epoch: 5| Step: 3
Training loss: 4.5478443279212915
Validation loss: 3.959948055705169

Epoch: 5| Step: 4
Training loss: 4.662819548182839
Validation loss: 3.9529891024178982

Epoch: 5| Step: 5
Training loss: 4.373749036415433
Validation loss: 3.9453632862774284

Epoch: 5| Step: 6
Training loss: 3.962859099569652
Validation loss: 3.9307762876456485

Epoch: 5| Step: 7
Training loss: 3.7193303016075427
Validation loss: 3.9221904650478168

Epoch: 5| Step: 8
Training loss: 4.710051141611076
Validation loss: 3.908181025509661

Epoch: 5| Step: 9
Training loss: 3.6971801167558587
Validation loss: 3.895840280546494

Epoch: 5| Step: 10
Training loss: 4.047202314300087
Validation loss: 3.8805302413383442

Epoch: 8| Step: 0
Training loss: 3.713351779414806
Validation loss: 3.86875405930704

Epoch: 5| Step: 1
Training loss: 4.752716091005144
Validation loss: 3.8558390883631133

Epoch: 5| Step: 2
Training loss: 4.242576173852672
Validation loss: 3.8392531579488933

Epoch: 5| Step: 3
Training loss: 4.090297262119819
Validation loss: 3.833962434791332

Epoch: 5| Step: 4
Training loss: 3.705171558768531
Validation loss: 3.857053398123187

Epoch: 5| Step: 5
Training loss: 3.6508715594938286
Validation loss: 3.8244334647496783

Epoch: 5| Step: 6
Training loss: 3.8992028717775535
Validation loss: 3.810744657640887

Epoch: 5| Step: 7
Training loss: 3.884537066318777
Validation loss: 3.8012746807571984

Epoch: 5| Step: 8
Training loss: 3.2073574481068925
Validation loss: 3.79215635599077

Epoch: 5| Step: 9
Training loss: 4.742214246796998
Validation loss: 3.785593445264485

Epoch: 5| Step: 10
Training loss: 3.7331684030704526
Validation loss: 3.7784301527097117

Epoch: 9| Step: 0
Training loss: 4.441498365428331
Validation loss: 3.777247554149163

Epoch: 5| Step: 1
Training loss: 3.3906888472351233
Validation loss: 3.7701169230112197

Epoch: 5| Step: 2
Training loss: 3.6709697500305896
Validation loss: 3.7600332857852234

Epoch: 5| Step: 3
Training loss: 4.065797377266639
Validation loss: 3.75064967827418

Epoch: 5| Step: 4
Training loss: 3.2336363017970657
Validation loss: 3.734771485042551

Epoch: 5| Step: 5
Training loss: 4.384728215319257
Validation loss: 3.725267390192779

Epoch: 5| Step: 6
Training loss: 4.659542276717277
Validation loss: 3.7171919217888765

Epoch: 5| Step: 7
Training loss: 3.593294330401764
Validation loss: 3.7069305987515304

Epoch: 5| Step: 8
Training loss: 4.147731455115541
Validation loss: 3.6956437350147593

Epoch: 5| Step: 9
Training loss: 3.9474632519490642
Validation loss: 3.687519354306266

Epoch: 5| Step: 10
Training loss: 2.987331982600457
Validation loss: 3.6939688176518586

Epoch: 10| Step: 0
Training loss: 3.733860124024633
Validation loss: 3.6749182118800636

Epoch: 5| Step: 1
Training loss: 3.496525811290893
Validation loss: 3.666846001528675

Epoch: 5| Step: 2
Training loss: 4.022979058378304
Validation loss: 3.662056993072951

Epoch: 5| Step: 3
Training loss: 3.5460074956118675
Validation loss: 3.653884224678587

Epoch: 5| Step: 4
Training loss: 3.8355144570458237
Validation loss: 3.6477806302963938

Epoch: 5| Step: 5
Training loss: 3.9150747486447286
Validation loss: 3.6444293678594453

Epoch: 5| Step: 6
Training loss: 4.3424632410086925
Validation loss: 3.639157667746265

Epoch: 5| Step: 7
Training loss: 3.8894769284542026
Validation loss: 3.6321000992770682

Epoch: 5| Step: 8
Training loss: 3.4556171520776715
Validation loss: 3.6208478707384293

Epoch: 5| Step: 9
Training loss: 3.480302971553441
Validation loss: 3.6145655661223084

Epoch: 5| Step: 10
Training loss: 4.4260719250998655
Validation loss: 3.6116715101816843

Epoch: 11| Step: 0
Training loss: 3.9365161696007083
Validation loss: 3.6044999726687927

Epoch: 5| Step: 1
Training loss: 3.976906152651464
Validation loss: 3.5981117647718435

Epoch: 5| Step: 2
Training loss: 3.5544477780174
Validation loss: 3.5940324156061814

Epoch: 5| Step: 3
Training loss: 3.8506029028522404
Validation loss: 3.5899947982468414

Epoch: 5| Step: 4
Training loss: 2.7741479957558064
Validation loss: 3.5819986170376628

Epoch: 5| Step: 5
Training loss: 4.174297872197201
Validation loss: 3.585820936928288

Epoch: 5| Step: 6
Training loss: 4.4933350266661884
Validation loss: 3.5706697792658084

Epoch: 5| Step: 7
Training loss: 4.33347119821194
Validation loss: 3.5640046778174335

Epoch: 5| Step: 8
Training loss: 2.129264031539894
Validation loss: 3.5601063422510437

Epoch: 5| Step: 9
Training loss: 3.7171989219461183
Validation loss: 3.5627531297408384

Epoch: 5| Step: 10
Training loss: 4.061953463837666
Validation loss: 3.587931224129681

Epoch: 12| Step: 0
Training loss: 4.143721664124695
Validation loss: 3.5445689307103008

Epoch: 5| Step: 1
Training loss: 4.022086914929253
Validation loss: 3.540649287238961

Epoch: 5| Step: 2
Training loss: 3.928595267879932
Validation loss: 3.539289979723498

Epoch: 5| Step: 3
Training loss: 4.029017813667083
Validation loss: 3.536745417535613

Epoch: 5| Step: 4
Training loss: 3.6184338261867093
Validation loss: 3.5276536370353724

Epoch: 5| Step: 5
Training loss: 3.357007279020843
Validation loss: 3.522727174933027

Epoch: 5| Step: 6
Training loss: 3.5414418018238796
Validation loss: 3.512922046132642

Epoch: 5| Step: 7
Training loss: 4.241535059318009
Validation loss: 3.513736696644081

Epoch: 5| Step: 8
Training loss: 3.3065324687900897
Validation loss: 3.5073583523464964

Epoch: 5| Step: 9
Training loss: 3.4020324634705243
Validation loss: 3.5024595203382054

Epoch: 5| Step: 10
Training loss: 3.2202059221469477
Validation loss: 3.5027337890139703

Epoch: 13| Step: 0
Training loss: 3.786504200373775
Validation loss: 3.49758370518951

Epoch: 5| Step: 1
Training loss: 3.7399711018226145
Validation loss: 3.4910826536463886

Epoch: 5| Step: 2
Training loss: 3.6718500664047067
Validation loss: 3.48398351895789

Epoch: 5| Step: 3
Training loss: 4.394536675343873
Validation loss: 3.4797529807637435

Epoch: 5| Step: 4
Training loss: 3.2990322196707598
Validation loss: 3.478631860073244

Epoch: 5| Step: 5
Training loss: 4.1540608771707035
Validation loss: 3.477272037054688

Epoch: 5| Step: 6
Training loss: 3.7282340021817855
Validation loss: 3.4691133317175424

Epoch: 5| Step: 7
Training loss: 3.011612035540485
Validation loss: 3.4696295237618124

Epoch: 5| Step: 8
Training loss: 3.2564231782576347
Validation loss: 3.4653163101680344

Epoch: 5| Step: 9
Training loss: 3.563287614458318
Validation loss: 3.466218254473214

Epoch: 5| Step: 10
Training loss: 3.8207387237871653
Validation loss: 3.4633769620780797

Epoch: 14| Step: 0
Training loss: 3.546041651223504
Validation loss: 3.46269626827484

Epoch: 5| Step: 1
Training loss: 4.114213886655793
Validation loss: 3.459253553197038

Epoch: 5| Step: 2
Training loss: 3.4892032852844843
Validation loss: 3.452419381337208

Epoch: 5| Step: 3
Training loss: 3.1855702261943035
Validation loss: 3.448910811181506

Epoch: 5| Step: 4
Training loss: 3.1302437084735875
Validation loss: 3.4435496162511683

Epoch: 5| Step: 5
Training loss: 3.29566477759707
Validation loss: 3.4364963845112375

Epoch: 5| Step: 6
Training loss: 4.189703745781674
Validation loss: 3.429942414373086

Epoch: 5| Step: 7
Training loss: 3.249937350329525
Validation loss: 3.427762077515725

Epoch: 5| Step: 8
Training loss: 3.656723904667376
Validation loss: 3.4230693164431463

Epoch: 5| Step: 9
Training loss: 3.924886208603796
Validation loss: 3.424544719379149

Epoch: 5| Step: 10
Training loss: 4.341888248307528
Validation loss: 3.4224057252605227

Epoch: 15| Step: 0
Training loss: 3.5031462560684288
Validation loss: 3.4196408460393384

Epoch: 5| Step: 1
Training loss: 3.706552971072741
Validation loss: 3.408938174016092

Epoch: 5| Step: 2
Training loss: 3.169547895087394
Validation loss: 3.4082210302536335

Epoch: 5| Step: 3
Training loss: 3.6286820752037885
Validation loss: 3.40755349723228

Epoch: 5| Step: 4
Training loss: 3.1208881028737925
Validation loss: 3.405976384487272

Epoch: 5| Step: 5
Training loss: 3.348681939299524
Validation loss: 3.399832386431117

Epoch: 5| Step: 6
Training loss: 3.929897416501305
Validation loss: 3.3952100780628443

Epoch: 5| Step: 7
Training loss: 3.346342988743896
Validation loss: 3.3947477545070206

Epoch: 5| Step: 8
Training loss: 4.087303852192955
Validation loss: 3.3923552595049116

Epoch: 5| Step: 9
Training loss: 3.638017498316109
Validation loss: 3.3919938667485314

Epoch: 5| Step: 10
Training loss: 4.336644790285385
Validation loss: 3.390467245810698

Epoch: 16| Step: 0
Training loss: 3.8541290831236936
Validation loss: 3.4336484540038787

Epoch: 5| Step: 1
Training loss: 3.513251694581876
Validation loss: 3.39517865317682

Epoch: 5| Step: 2
Training loss: 3.6988828158084446
Validation loss: 3.4555995220831472

Epoch: 5| Step: 3
Training loss: 3.9714516883091053
Validation loss: 3.521383516435246

Epoch: 5| Step: 4
Training loss: 3.677617424205955
Validation loss: 3.475122760319735

Epoch: 5| Step: 5
Training loss: 3.5096039477404166
Validation loss: 3.4600982215052016

Epoch: 5| Step: 6
Training loss: 3.092775287633643
Validation loss: 3.4638984791837215

Epoch: 5| Step: 7
Training loss: 3.5128548113722617
Validation loss: 3.475859028332182

Epoch: 5| Step: 8
Training loss: 3.488850682718266
Validation loss: 3.4834135768927106

Epoch: 5| Step: 9
Training loss: 3.8768546065489513
Validation loss: 3.4762535629911735

Epoch: 5| Step: 10
Training loss: 4.306255961775286
Validation loss: 3.4626466549378048

Epoch: 17| Step: 0
Training loss: 4.053653886651359
Validation loss: 3.4403442160945175

Epoch: 5| Step: 1
Training loss: 3.652857975790516
Validation loss: 3.4075995958346605

Epoch: 5| Step: 2
Training loss: 4.029017340264176
Validation loss: 3.3962712783403854

Epoch: 5| Step: 3
Training loss: 3.9784620503342376
Validation loss: 3.385163683403764

Epoch: 5| Step: 4
Training loss: 4.717563707399617
Validation loss: 3.3771767844890404

Epoch: 5| Step: 5
Training loss: 3.7767549389194346
Validation loss: 3.375903263550648

Epoch: 5| Step: 6
Training loss: 3.0137530431490784
Validation loss: 3.3700757368234995

Epoch: 5| Step: 7
Training loss: 2.9653953471365897
Validation loss: 3.3684558309316124

Epoch: 5| Step: 8
Training loss: 2.7187090465048147
Validation loss: 3.3613770403255288

Epoch: 5| Step: 9
Training loss: 2.4739756265671633
Validation loss: 3.3597896097813

Epoch: 5| Step: 10
Training loss: 3.801589111536019
Validation loss: 3.3598817474116105

Epoch: 18| Step: 0
Training loss: 3.6770302802014774
Validation loss: 3.3547424518238596

Epoch: 5| Step: 1
Training loss: 4.074159060339961
Validation loss: 3.3513101860028254

Epoch: 5| Step: 2
Training loss: 2.941715381280189
Validation loss: 3.3484979439785234

Epoch: 5| Step: 3
Training loss: 3.6386608670324634
Validation loss: 3.350080926071034

Epoch: 5| Step: 4
Training loss: 3.303123735411374
Validation loss: 3.346015454842476

Epoch: 5| Step: 5
Training loss: 4.090729042869113
Validation loss: 3.332314107541138

Epoch: 5| Step: 6
Training loss: 3.2503292210430033
Validation loss: 3.326812232575319

Epoch: 5| Step: 7
Training loss: 3.320882304048692
Validation loss: 3.3250420708577253

Epoch: 5| Step: 8
Training loss: 3.5073269038539943
Validation loss: 3.319424591151536

Epoch: 5| Step: 9
Training loss: 4.100512793502507
Validation loss: 3.321657698685313

Epoch: 5| Step: 10
Training loss: 3.0729253391639184
Validation loss: 3.3148712119401873

Epoch: 19| Step: 0
Training loss: 2.8189787947339924
Validation loss: 3.3149248373731095

Epoch: 5| Step: 1
Training loss: 3.953049730632232
Validation loss: 3.312703978251694

Epoch: 5| Step: 2
Training loss: 2.8941276155607527
Validation loss: 3.3132391855783667

Epoch: 5| Step: 3
Training loss: 3.4745660085475287
Validation loss: 3.309553126861551

Epoch: 5| Step: 4
Training loss: 3.5898412262385717
Validation loss: 3.3055832016831106

Epoch: 5| Step: 5
Training loss: 3.990643047629511
Validation loss: 3.3036025674213705

Epoch: 5| Step: 6
Training loss: 3.516481422378498
Validation loss: 3.302866743844037

Epoch: 5| Step: 7
Training loss: 4.325712006455466
Validation loss: 3.2999242559486524

Epoch: 5| Step: 8
Training loss: 3.7911905821216982
Validation loss: 3.298912350007979

Epoch: 5| Step: 9
Training loss: 3.13697276149862
Validation loss: 3.2960381588141203

Epoch: 5| Step: 10
Training loss: 3.1419615677122716
Validation loss: 3.2934948392903727

Epoch: 20| Step: 0
Training loss: 3.7246276823012976
Validation loss: 3.2899917545907855

Epoch: 5| Step: 1
Training loss: 4.208772290190315
Validation loss: 3.2914743695698148

Epoch: 5| Step: 2
Training loss: 3.766968799952999
Validation loss: 3.2895313474677623

Epoch: 5| Step: 3
Training loss: 2.9499121248767106
Validation loss: 3.2876081050493053

Epoch: 5| Step: 4
Training loss: 3.466015399376965
Validation loss: 3.2860189273836786

Epoch: 5| Step: 5
Training loss: 3.493821412586699
Validation loss: 3.285823315191246

Epoch: 5| Step: 6
Training loss: 3.1264298791701175
Validation loss: 3.2833102874192748

Epoch: 5| Step: 7
Training loss: 3.139732727532998
Validation loss: 3.2829504869760786

Epoch: 5| Step: 8
Training loss: 3.525634621923362
Validation loss: 3.281742239896294

Epoch: 5| Step: 9
Training loss: 3.8680098458828516
Validation loss: 3.2811001979308574

Epoch: 5| Step: 10
Training loss: 3.3614170698847237
Validation loss: 3.279892984123124

Epoch: 21| Step: 0
Training loss: 3.7819452828776705
Validation loss: 3.2786058029257577

Epoch: 5| Step: 1
Training loss: 2.7585679011185835
Validation loss: 3.2780826671407084

Epoch: 5| Step: 2
Training loss: 4.337237408959164
Validation loss: 3.2749962359001836

Epoch: 5| Step: 3
Training loss: 2.5709627482661843
Validation loss: 3.273380729466323

Epoch: 5| Step: 4
Training loss: 3.1863715474353684
Validation loss: 3.275037211670393

Epoch: 5| Step: 5
Training loss: 3.4093592740403382
Validation loss: 3.2775875264256933

Epoch: 5| Step: 6
Training loss: 3.434068388785019
Validation loss: 3.274057991907899

Epoch: 5| Step: 7
Training loss: 3.1282481288399775
Validation loss: 3.272347366264395

Epoch: 5| Step: 8
Training loss: 4.370366503886819
Validation loss: 3.2688409900434054

Epoch: 5| Step: 9
Training loss: 3.0444702048344965
Validation loss: 3.2682848228922476

Epoch: 5| Step: 10
Training loss: 4.234188286863067
Validation loss: 3.2669255667203743

Epoch: 22| Step: 0
Training loss: 3.7392448052463765
Validation loss: 3.2674102770495366

Epoch: 5| Step: 1
Training loss: 3.8448194551182837
Validation loss: 3.2666478012307

Epoch: 5| Step: 2
Training loss: 3.012288990782468
Validation loss: 3.264274822438594

Epoch: 5| Step: 3
Training loss: 3.1858375552348437
Validation loss: 3.2650696889291306

Epoch: 5| Step: 4
Training loss: 3.0066062985750808
Validation loss: 3.264075242250364

Epoch: 5| Step: 5
Training loss: 4.026456363272414
Validation loss: 3.262466903101862

Epoch: 5| Step: 6
Training loss: 3.3963427171346954
Validation loss: 3.2611755260637403

Epoch: 5| Step: 7
Training loss: 3.6911059060603257
Validation loss: 3.2601617103197262

Epoch: 5| Step: 8
Training loss: 3.303548269301137
Validation loss: 3.25842930572929

Epoch: 5| Step: 9
Training loss: 3.5797613808156408
Validation loss: 3.2568919416522513

Epoch: 5| Step: 10
Training loss: 3.663918433376757
Validation loss: 3.257036994761735

Epoch: 23| Step: 0
Training loss: 3.7977496109194417
Validation loss: 3.258438115989183

Epoch: 5| Step: 1
Training loss: 3.241372909245709
Validation loss: 3.2553142022749713

Epoch: 5| Step: 2
Training loss: 3.6868575231484186
Validation loss: 3.2538650506738658

Epoch: 5| Step: 3
Training loss: 4.053569426395025
Validation loss: 3.2544167814914315

Epoch: 5| Step: 4
Training loss: 3.8705185848805534
Validation loss: 3.2520497060984326

Epoch: 5| Step: 5
Training loss: 2.2613200361667603
Validation loss: 3.251852159313262

Epoch: 5| Step: 6
Training loss: 3.3649183801328757
Validation loss: 3.2504810674522373

Epoch: 5| Step: 7
Training loss: 3.5936540673761628
Validation loss: 3.2501861323339747

Epoch: 5| Step: 8
Training loss: 3.5515905282642795
Validation loss: 3.248047244386217

Epoch: 5| Step: 9
Training loss: 3.760165233430924
Validation loss: 3.2483445124780865

Epoch: 5| Step: 10
Training loss: 2.8406497698250535
Validation loss: 3.246463192152983

Epoch: 24| Step: 0
Training loss: 3.7779839652646587
Validation loss: 3.257660836358815

Epoch: 5| Step: 1
Training loss: 3.578628571236012
Validation loss: 3.267518258695491

Epoch: 5| Step: 2
Training loss: 3.942094332591596
Validation loss: 3.2487762251685424

Epoch: 5| Step: 3
Training loss: 3.4914660636676214
Validation loss: 3.2443782864573443

Epoch: 5| Step: 4
Training loss: 3.2813214975469367
Validation loss: 3.2442504574203217

Epoch: 5| Step: 5
Training loss: 3.198670951698341
Validation loss: 3.2450287632422934

Epoch: 5| Step: 6
Training loss: 2.8996901774155113
Validation loss: 3.2493566581508

Epoch: 5| Step: 7
Training loss: 3.4493019724706677
Validation loss: 3.2448689949569514

Epoch: 5| Step: 8
Training loss: 3.6048267326037635
Validation loss: 3.2419854838650495

Epoch: 5| Step: 9
Training loss: 3.306227449221225
Validation loss: 3.2422219954730087

Epoch: 5| Step: 10
Training loss: 3.844760048749271
Validation loss: 3.240031824060724

Epoch: 25| Step: 0
Training loss: 4.039466468782355
Validation loss: 3.23538887089057

Epoch: 5| Step: 1
Training loss: 3.5357188077515147
Validation loss: 3.2340849312916267

Epoch: 5| Step: 2
Training loss: 2.6549408323085246
Validation loss: 3.2353535434592566

Epoch: 5| Step: 3
Training loss: 3.616389077311247
Validation loss: 3.2427738067279703

Epoch: 5| Step: 4
Training loss: 3.9102057607223846
Validation loss: 3.2375026705878907

Epoch: 5| Step: 5
Training loss: 3.5759195919000155
Validation loss: 3.2363061682547505

Epoch: 5| Step: 6
Training loss: 3.543445962986107
Validation loss: 3.235512994023306

Epoch: 5| Step: 7
Training loss: 3.5280889355528453
Validation loss: 3.231006771790454

Epoch: 5| Step: 8
Training loss: 2.6881078875382154
Validation loss: 3.2294965511343534

Epoch: 5| Step: 9
Training loss: 3.723542147057106
Validation loss: 3.2283677037961427

Epoch: 5| Step: 10
Training loss: 3.152333615273749
Validation loss: 3.228724761375522

Epoch: 26| Step: 0
Training loss: 3.719676182917233
Validation loss: 3.2275857067518343

Epoch: 5| Step: 1
Training loss: 3.342882275515993
Validation loss: 3.226048960696639

Epoch: 5| Step: 2
Training loss: 3.327189855874794
Validation loss: 3.224573341147874

Epoch: 5| Step: 3
Training loss: 3.8830152493201258
Validation loss: 3.224387019896294

Epoch: 5| Step: 4
Training loss: 3.851104523394537
Validation loss: 3.224299623688592

Epoch: 5| Step: 5
Training loss: 3.0763223859508364
Validation loss: 3.223267518879883

Epoch: 5| Step: 6
Training loss: 2.9484052129695
Validation loss: 3.2237360465134692

Epoch: 5| Step: 7
Training loss: 4.773964710746011
Validation loss: 3.2211878817501076

Epoch: 5| Step: 8
Training loss: 2.908853984526535
Validation loss: 3.218823159797448

Epoch: 5| Step: 9
Training loss: 2.4971648352392495
Validation loss: 3.219755182038857

Epoch: 5| Step: 10
Training loss: 3.294656305289356
Validation loss: 3.2376230908631554

Epoch: 27| Step: 0
Training loss: 4.13367820859662
Validation loss: 3.2270268321136406

Epoch: 5| Step: 1
Training loss: 2.7813823539873597
Validation loss: 3.2174902797576723

Epoch: 5| Step: 2
Training loss: 3.3910139713342646
Validation loss: 3.2152872388344043

Epoch: 5| Step: 3
Training loss: 3.8127784001995604
Validation loss: 3.214373433335029

Epoch: 5| Step: 4
Training loss: 2.993531883751714
Validation loss: 3.214964870673755

Epoch: 5| Step: 5
Training loss: 3.6673803212948215
Validation loss: 3.214953845683552

Epoch: 5| Step: 6
Training loss: 3.162745976588502
Validation loss: 3.2155917337958404

Epoch: 5| Step: 7
Training loss: 4.037282525692342
Validation loss: 3.214675170240766

Epoch: 5| Step: 8
Training loss: 2.8837020866074567
Validation loss: 3.2123997377340046

Epoch: 5| Step: 9
Training loss: 3.4128218781973145
Validation loss: 3.20927980704382

Epoch: 5| Step: 10
Training loss: 3.5662577035140823
Validation loss: 3.208277283269343

Epoch: 28| Step: 0
Training loss: 3.2786642876495296
Validation loss: 3.2102053826875987

Epoch: 5| Step: 1
Training loss: 3.8992170575000085
Validation loss: 3.2200734211122857

Epoch: 5| Step: 2
Training loss: 2.910022870789937
Validation loss: 3.204248829360829

Epoch: 5| Step: 3
Training loss: 3.7032782285512282
Validation loss: 3.2073701409649216

Epoch: 5| Step: 4
Training loss: 2.809336854465682
Validation loss: 3.2083935483585693

Epoch: 5| Step: 5
Training loss: 3.5173613604869463
Validation loss: 3.2111336614441903

Epoch: 5| Step: 6
Training loss: 3.5916876141025074
Validation loss: 3.2109888875719728

Epoch: 5| Step: 7
Training loss: 3.741507514225236
Validation loss: 3.2097166558024175

Epoch: 5| Step: 8
Training loss: 3.7016409302466187
Validation loss: 3.20488785146196

Epoch: 5| Step: 9
Training loss: 3.5067402107687924
Validation loss: 3.20317511390523

Epoch: 5| Step: 10
Training loss: 3.232214754504762
Validation loss: 3.200462107209427

Epoch: 29| Step: 0
Training loss: 3.502124141808607
Validation loss: 3.2040145619227793

Epoch: 5| Step: 1
Training loss: 3.9333913044509905
Validation loss: 3.207798722441671

Epoch: 5| Step: 2
Training loss: 3.26865593098353
Validation loss: 3.2009971628185836

Epoch: 5| Step: 3
Training loss: 3.1367372961196742
Validation loss: 3.197810992822784

Epoch: 5| Step: 4
Training loss: 3.7746602796066866
Validation loss: 3.1953886434067074

Epoch: 5| Step: 5
Training loss: 2.7527711084436675
Validation loss: 3.1969639361447864

Epoch: 5| Step: 6
Training loss: 2.367508668168664
Validation loss: 3.2052181852913413

Epoch: 5| Step: 7
Training loss: 4.102758847101631
Validation loss: 3.2263399219343722

Epoch: 5| Step: 8
Training loss: 3.6188217656689985
Validation loss: 3.2220345088730853

Epoch: 5| Step: 9
Training loss: 3.3740914146100884
Validation loss: 3.200236923986303

Epoch: 5| Step: 10
Training loss: 3.9252444683162553
Validation loss: 3.1951596067817905

Epoch: 30| Step: 0
Training loss: 3.028721807067617
Validation loss: 3.192320350717978

Epoch: 5| Step: 1
Training loss: 3.200335073809579
Validation loss: 3.1949036031172096

Epoch: 5| Step: 2
Training loss: 3.735379008273353
Validation loss: 3.1957824635813257

Epoch: 5| Step: 3
Training loss: 3.7020614963990153
Validation loss: 3.199167400147688

Epoch: 5| Step: 4
Training loss: 3.9169275453949903
Validation loss: 3.1983319084722917

Epoch: 5| Step: 5
Training loss: 3.8947686493200178
Validation loss: 3.1887847769010973

Epoch: 5| Step: 6
Training loss: 2.6378274578731955
Validation loss: 3.1858303982329477

Epoch: 5| Step: 7
Training loss: 3.0848349617658655
Validation loss: 3.185225957396118

Epoch: 5| Step: 8
Training loss: 3.4529939514425347
Validation loss: 3.1846786421077065

Epoch: 5| Step: 9
Training loss: 3.6281566687490607
Validation loss: 3.184410103989819

Epoch: 5| Step: 10
Training loss: 3.398271648700889
Validation loss: 3.184355580846519

Epoch: 31| Step: 0
Training loss: 3.068003944096026
Validation loss: 3.1859884230887694

Epoch: 5| Step: 1
Training loss: 3.341735660922035
Validation loss: 3.1845937159357485

Epoch: 5| Step: 2
Training loss: 3.786090117561374
Validation loss: 3.183289985853396

Epoch: 5| Step: 3
Training loss: 3.2451362896293037
Validation loss: 3.1807325982326837

Epoch: 5| Step: 4
Training loss: 4.347643527469031
Validation loss: 3.1817268257119946

Epoch: 5| Step: 5
Training loss: 3.2794630725361764
Validation loss: 3.1807337346792535

Epoch: 5| Step: 6
Training loss: 3.1194234300605523
Validation loss: 3.1772576445489387

Epoch: 5| Step: 7
Training loss: 3.223846104917373
Validation loss: 3.17587782920524

Epoch: 5| Step: 8
Training loss: 3.425632730220208
Validation loss: 3.1767109884542344

Epoch: 5| Step: 9
Training loss: 3.974963753013171
Validation loss: 3.175111853635213

Epoch: 5| Step: 10
Training loss: 2.539543411487696
Validation loss: 3.172237102183741

Epoch: 32| Step: 0
Training loss: 2.7953624364786105
Validation loss: 3.171624705248547

Epoch: 5| Step: 1
Training loss: 3.998852922952013
Validation loss: 3.174472970381162

Epoch: 5| Step: 2
Training loss: 3.458796060391235
Validation loss: 3.18408144309315

Epoch: 5| Step: 3
Training loss: 3.7626096437009755
Validation loss: 3.173924033458358

Epoch: 5| Step: 4
Training loss: 3.479149154040334
Validation loss: 3.167873446227901

Epoch: 5| Step: 5
Training loss: 2.6398833548179126
Validation loss: 3.1677851755190862

Epoch: 5| Step: 6
Training loss: 3.9056200663950076
Validation loss: 3.1671857802360392

Epoch: 5| Step: 7
Training loss: 3.2286560803442725
Validation loss: 3.1661399236984917

Epoch: 5| Step: 8
Training loss: 3.3808685426020273
Validation loss: 3.1653799012757977

Epoch: 5| Step: 9
Training loss: 3.2617675777595254
Validation loss: 3.165371164064402

Epoch: 5| Step: 10
Training loss: 3.600612159180353
Validation loss: 3.1641039433531986

Epoch: 33| Step: 0
Training loss: 3.084403359264414
Validation loss: 3.165095966818272

Epoch: 5| Step: 1
Training loss: 3.403393869138747
Validation loss: 3.1632534526616984

Epoch: 5| Step: 2
Training loss: 2.849937163881641
Validation loss: 3.161935707016434

Epoch: 5| Step: 3
Training loss: 3.37927201777501
Validation loss: 3.1604765934970223

Epoch: 5| Step: 4
Training loss: 3.0175120719914705
Validation loss: 3.1599227312173146

Epoch: 5| Step: 5
Training loss: 2.627135361941013
Validation loss: 3.1587385286585272

Epoch: 5| Step: 6
Training loss: 3.7344270965900637
Validation loss: 3.1579465218548965

Epoch: 5| Step: 7
Training loss: 3.8494951685082244
Validation loss: 3.1582965987549754

Epoch: 5| Step: 8
Training loss: 3.1532793322960386
Validation loss: 3.159240863465946

Epoch: 5| Step: 9
Training loss: 4.579557331464784
Validation loss: 3.165506351649724

Epoch: 5| Step: 10
Training loss: 3.522044513349613
Validation loss: 3.162083067674941

Epoch: 34| Step: 0
Training loss: 3.495584973017945
Validation loss: 3.1594493842076963

Epoch: 5| Step: 1
Training loss: 3.1663168329112223
Validation loss: 3.1555084645643556

Epoch: 5| Step: 2
Training loss: 3.325406105653427
Validation loss: 3.152320832557791

Epoch: 5| Step: 3
Training loss: 3.4415188964697405
Validation loss: 3.1526165279613942

Epoch: 5| Step: 4
Training loss: 4.493676298807781
Validation loss: 3.1529496355264337

Epoch: 5| Step: 5
Training loss: 3.6773251606179813
Validation loss: 3.1518189882606897

Epoch: 5| Step: 6
Training loss: 2.6234402336756157
Validation loss: 3.152472120379061

Epoch: 5| Step: 7
Training loss: 2.8074149893223352
Validation loss: 3.1524359117305876

Epoch: 5| Step: 8
Training loss: 3.175972833051205
Validation loss: 3.1513319383007223

Epoch: 5| Step: 9
Training loss: 3.373385997129935
Validation loss: 3.151061105867347

Epoch: 5| Step: 10
Training loss: 3.7148089642906696
Validation loss: 3.1489269629620957

Epoch: 35| Step: 0
Training loss: 3.0605961078123736
Validation loss: 3.1470580661236105

Epoch: 5| Step: 1
Training loss: 2.952398624601665
Validation loss: 3.1448892764461576

Epoch: 5| Step: 2
Training loss: 3.4278787696616506
Validation loss: 3.1453608681204805

Epoch: 5| Step: 3
Training loss: 3.821834206538859
Validation loss: 3.1433138543810566

Epoch: 5| Step: 4
Training loss: 2.946532302946073
Validation loss: 3.141897676799102

Epoch: 5| Step: 5
Training loss: 3.8105796605297684
Validation loss: 3.1429109351184277

Epoch: 5| Step: 6
Training loss: 3.5308381237087265
Validation loss: 3.1586546735688277

Epoch: 5| Step: 7
Training loss: 3.2471569537312988
Validation loss: 3.157486138965562

Epoch: 5| Step: 8
Training loss: 3.216988683470179
Validation loss: 3.1375921718509736

Epoch: 5| Step: 9
Training loss: 3.351681153657987
Validation loss: 3.138460307425424

Epoch: 5| Step: 10
Training loss: 4.017666902428222
Validation loss: 3.1392314090099793

Epoch: 36| Step: 0
Training loss: 3.4336595756808856
Validation loss: 3.1397045249587894

Epoch: 5| Step: 1
Training loss: 3.5958259225874323
Validation loss: 3.1404353479246456

Epoch: 5| Step: 2
Training loss: 2.72696584434368
Validation loss: 3.1434725910061307

Epoch: 5| Step: 3
Training loss: 4.033815971901299
Validation loss: 3.1470704286962263

Epoch: 5| Step: 4
Training loss: 3.6457423316860793
Validation loss: 3.1470741482114035

Epoch: 5| Step: 5
Training loss: 2.8962384130437933
Validation loss: 3.1398265625488464

Epoch: 5| Step: 6
Training loss: 2.688350365528216
Validation loss: 3.136101990649354

Epoch: 5| Step: 7
Training loss: 3.7605811564784037
Validation loss: 3.135392968385278

Epoch: 5| Step: 8
Training loss: 2.833626975008548
Validation loss: 3.130928096984647

Epoch: 5| Step: 9
Training loss: 3.805230636524356
Validation loss: 3.1322777613207697

Epoch: 5| Step: 10
Training loss: 3.717488820329183
Validation loss: 3.1310056555082197

Epoch: 37| Step: 0
Training loss: 3.654219887033084
Validation loss: 3.1287560661380707

Epoch: 5| Step: 1
Training loss: 3.028156078009865
Validation loss: 3.1291804058168275

Epoch: 5| Step: 2
Training loss: 3.8477635712348635
Validation loss: 3.134866362772609

Epoch: 5| Step: 3
Training loss: 3.2724685145204733
Validation loss: 3.1330105400812704

Epoch: 5| Step: 4
Training loss: 3.382129485707675
Validation loss: 3.1326346349082206

Epoch: 5| Step: 5
Training loss: 3.798827371866892
Validation loss: 3.1293775534244355

Epoch: 5| Step: 6
Training loss: 2.659082495699053
Validation loss: 3.1251327355200087

Epoch: 5| Step: 7
Training loss: 2.9565642175769242
Validation loss: 3.124340877137839

Epoch: 5| Step: 8
Training loss: 3.7874828073847877
Validation loss: 3.12442845850289

Epoch: 5| Step: 9
Training loss: 3.492406100060074
Validation loss: 3.1207396550390767

Epoch: 5| Step: 10
Training loss: 3.19723997298048
Validation loss: 3.123217750046834

Epoch: 38| Step: 0
Training loss: 3.2061959780776514
Validation loss: 3.125720422211655

Epoch: 5| Step: 1
Training loss: 3.64074680632137
Validation loss: 3.127936799951482

Epoch: 5| Step: 2
Training loss: 3.3028261971638586
Validation loss: 3.1304715515974397

Epoch: 5| Step: 3
Training loss: 2.5309847469043545
Validation loss: 3.128296245367974

Epoch: 5| Step: 4
Training loss: 3.2436387823953488
Validation loss: 3.1289823314255587

Epoch: 5| Step: 5
Training loss: 4.140110430143054
Validation loss: 3.125288530381207

Epoch: 5| Step: 6
Training loss: 3.3972269642684942
Validation loss: 3.120607778453374

Epoch: 5| Step: 7
Training loss: 3.2608508388700295
Validation loss: 3.1191165405932346

Epoch: 5| Step: 8
Training loss: 3.3448940708511
Validation loss: 3.115916305021458

Epoch: 5| Step: 9
Training loss: 2.98413851934469
Validation loss: 3.11429773060327

Epoch: 5| Step: 10
Training loss: 4.032956494048224
Validation loss: 3.1130879911221907

Epoch: 39| Step: 0
Training loss: 3.4545787668219057
Validation loss: 3.1132181399261043

Epoch: 5| Step: 1
Training loss: 3.894501497543386
Validation loss: 3.1249624040864736

Epoch: 5| Step: 2
Training loss: 2.776868304670197
Validation loss: 3.115209932038823

Epoch: 5| Step: 3
Training loss: 3.596037029156329
Validation loss: 3.1220127602724697

Epoch: 5| Step: 4
Training loss: 3.2278948012160007
Validation loss: 3.1160472283478815

Epoch: 5| Step: 5
Training loss: 3.390412776651472
Validation loss: 3.113441751665244

Epoch: 5| Step: 6
Training loss: 3.033404498959722
Validation loss: 3.1138784283295897

Epoch: 5| Step: 7
Training loss: 3.7379152762586516
Validation loss: 3.112624526412528

Epoch: 5| Step: 8
Training loss: 3.125696638659726
Validation loss: 3.108031858965752

Epoch: 5| Step: 9
Training loss: 3.1396926330967916
Validation loss: 3.1057432809078565

Epoch: 5| Step: 10
Training loss: 3.6802261509028966
Validation loss: 3.1064929703637416

Epoch: 40| Step: 0
Training loss: 3.8928683144545335
Validation loss: 3.1045970850962914

Epoch: 5| Step: 1
Training loss: 2.6146883291209226
Validation loss: 3.1044755743287666

Epoch: 5| Step: 2
Training loss: 3.6814052840481284
Validation loss: 3.104670062929805

Epoch: 5| Step: 3
Training loss: 3.3510807286860307
Validation loss: 3.103714496995164

Epoch: 5| Step: 4
Training loss: 3.3999087601929436
Validation loss: 3.1017346867350195

Epoch: 5| Step: 5
Training loss: 4.2320133394056345
Validation loss: 3.100354118643716

Epoch: 5| Step: 6
Training loss: 3.364931417279283
Validation loss: 3.102050651913056

Epoch: 5| Step: 7
Training loss: 3.1141085225564615
Validation loss: 3.099206052154773

Epoch: 5| Step: 8
Training loss: 3.0744943652756653
Validation loss: 3.09926946988899

Epoch: 5| Step: 9
Training loss: 2.74811888426221
Validation loss: 3.095658188753797

Epoch: 5| Step: 10
Training loss: 3.228864905911587
Validation loss: 3.0949677189803397

Epoch: 41| Step: 0
Training loss: 3.814641382403171
Validation loss: 3.094478356952412

Epoch: 5| Step: 1
Training loss: 3.488700064093649
Validation loss: 3.0949039803346285

Epoch: 5| Step: 2
Training loss: 3.8886923528387864
Validation loss: 3.093691030938641

Epoch: 5| Step: 3
Training loss: 3.0900997629696327
Validation loss: 3.091399981501104

Epoch: 5| Step: 4
Training loss: 3.3166663401490117
Validation loss: 3.0907549571523996

Epoch: 5| Step: 5
Training loss: 3.0628442376186182
Validation loss: 3.089153460300815

Epoch: 5| Step: 6
Training loss: 3.5051042939041084
Validation loss: 3.089614581094033

Epoch: 5| Step: 7
Training loss: 3.32822342847958
Validation loss: 3.088402447172834

Epoch: 5| Step: 8
Training loss: 3.1003141797736666
Validation loss: 3.0872614388038206

Epoch: 5| Step: 9
Training loss: 3.613055577834433
Validation loss: 3.089247819219244

Epoch: 5| Step: 10
Training loss: 2.390089685680628
Validation loss: 3.0888211906949423

Epoch: 42| Step: 0
Training loss: 3.4514516513029325
Validation loss: 3.087942938626026

Epoch: 5| Step: 1
Training loss: 3.2075502670285836
Validation loss: 3.087280243828976

Epoch: 5| Step: 2
Training loss: 3.114093669729621
Validation loss: 3.085901078071163

Epoch: 5| Step: 3
Training loss: 3.6102904112602485
Validation loss: 3.085878900044517

Epoch: 5| Step: 4
Training loss: 3.816456227282795
Validation loss: 3.0851074730753942

Epoch: 5| Step: 5
Training loss: 2.6239350293012946
Validation loss: 3.087286400319874

Epoch: 5| Step: 6
Training loss: 3.6148881298182762
Validation loss: 3.086905980194234

Epoch: 5| Step: 7
Training loss: 3.856250687511018
Validation loss: 3.0858764958092473

Epoch: 5| Step: 8
Training loss: 3.2516657155275217
Validation loss: 3.081707978042213

Epoch: 5| Step: 9
Training loss: 3.303496306165429
Validation loss: 3.0819594978996925

Epoch: 5| Step: 10
Training loss: 2.7340563779207123
Validation loss: 3.0804713590550454

Epoch: 43| Step: 0
Training loss: 3.3042017802953905
Validation loss: 3.080151083664223

Epoch: 5| Step: 1
Training loss: 3.249968161793795
Validation loss: 3.080947968203785

Epoch: 5| Step: 2
Training loss: 3.6197623199078297
Validation loss: 3.081401814172374

Epoch: 5| Step: 3
Training loss: 3.028203947850982
Validation loss: 3.0802395894087464

Epoch: 5| Step: 4
Training loss: 3.6458638362516766
Validation loss: 3.0797803279914606

Epoch: 5| Step: 5
Training loss: 2.7793769958914405
Validation loss: 3.0777995569082885

Epoch: 5| Step: 6
Training loss: 3.8337264204963706
Validation loss: 3.0768782557771837

Epoch: 5| Step: 7
Training loss: 3.27019884957277
Validation loss: 3.0764716645794103

Epoch: 5| Step: 8
Training loss: 3.2579593030754093
Validation loss: 3.075096126400844

Epoch: 5| Step: 9
Training loss: 3.578203092164336
Validation loss: 3.0746667287995675

Epoch: 5| Step: 10
Training loss: 3.087539913521821
Validation loss: 3.0734040160465272

Epoch: 44| Step: 0
Training loss: 3.5758681196946065
Validation loss: 3.071870833945006

Epoch: 5| Step: 1
Training loss: 3.2557526074931937
Validation loss: 3.0723792444429163

Epoch: 5| Step: 2
Training loss: 3.814919251353578
Validation loss: 3.0793472311251717

Epoch: 5| Step: 3
Training loss: 2.836768330755603
Validation loss: 3.071582923688476

Epoch: 5| Step: 4
Training loss: 3.3525258349305758
Validation loss: 3.071922202788681

Epoch: 5| Step: 5
Training loss: 3.754233831269847
Validation loss: 3.068151083992172

Epoch: 5| Step: 6
Training loss: 3.1361507599851555
Validation loss: 3.0686183667215308

Epoch: 5| Step: 7
Training loss: 3.175677646199822
Validation loss: 3.0676386608505615

Epoch: 5| Step: 8
Training loss: 3.1631456341811943
Validation loss: 3.0646349271319746

Epoch: 5| Step: 9
Training loss: 3.197191352890388
Validation loss: 3.0652718455232497

Epoch: 5| Step: 10
Training loss: 3.3602418712571285
Validation loss: 3.064844965252465

Epoch: 45| Step: 0
Training loss: 2.397472174903654
Validation loss: 3.065110997783375

Epoch: 5| Step: 1
Training loss: 3.222207443890353
Validation loss: 3.063051419802761

Epoch: 5| Step: 2
Training loss: 3.708301258305624
Validation loss: 3.064066017937305

Epoch: 5| Step: 3
Training loss: 3.7378023771619833
Validation loss: 3.06194521223653

Epoch: 5| Step: 4
Training loss: 3.6945929119008456
Validation loss: 3.061407324158858

Epoch: 5| Step: 5
Training loss: 3.6099686567895475
Validation loss: 3.060526251362679

Epoch: 5| Step: 6
Training loss: 3.1103713389775516
Validation loss: 3.0587777962323837

Epoch: 5| Step: 7
Training loss: 3.1123707204420303
Validation loss: 3.0607629754901082

Epoch: 5| Step: 8
Training loss: 3.568720556561922
Validation loss: 3.0581578094492987

Epoch: 5| Step: 9
Training loss: 3.0345967487745944
Validation loss: 3.057741757610922

Epoch: 5| Step: 10
Training loss: 3.198132750990262
Validation loss: 3.057937038814707

Epoch: 46| Step: 0
Training loss: 3.827954845150187
Validation loss: 3.0602574042883544

Epoch: 5| Step: 1
Training loss: 3.034936452637091
Validation loss: 3.0617433257342364

Epoch: 5| Step: 2
Training loss: 2.9245436614011093
Validation loss: 3.0601258877070663

Epoch: 5| Step: 3
Training loss: 3.6727675631430827
Validation loss: 3.0616332638509722

Epoch: 5| Step: 4
Training loss: 4.063101151811093
Validation loss: 3.056610867359615

Epoch: 5| Step: 5
Training loss: 3.795701336092251
Validation loss: 3.0535943533009733

Epoch: 5| Step: 6
Training loss: 2.525515996501306
Validation loss: 3.0537205415533473

Epoch: 5| Step: 7
Training loss: 3.1159465107372877
Validation loss: 3.053575077205996

Epoch: 5| Step: 8
Training loss: 3.49393769171216
Validation loss: 3.0523517642773483

Epoch: 5| Step: 9
Training loss: 2.3222782529290282
Validation loss: 3.050844508414351

Epoch: 5| Step: 10
Training loss: 3.442854162100704
Validation loss: 3.0486143252334723

Epoch: 47| Step: 0
Training loss: 3.53745649331234
Validation loss: 3.0486513877144885

Epoch: 5| Step: 1
Training loss: 3.269526291345553
Validation loss: 3.0486209012204646

Epoch: 5| Step: 2
Training loss: 2.5559914903573713
Validation loss: 3.0472250275377064

Epoch: 5| Step: 3
Training loss: 3.355452833926164
Validation loss: 3.0464386439540014

Epoch: 5| Step: 4
Training loss: 3.0038284668692423
Validation loss: 3.0453336095641537

Epoch: 5| Step: 5
Training loss: 2.944810738561938
Validation loss: 3.045905588317967

Epoch: 5| Step: 6
Training loss: 3.864354184221265
Validation loss: 3.044316788584815

Epoch: 5| Step: 7
Training loss: 3.1501393605240158
Validation loss: 3.042820549928074

Epoch: 5| Step: 8
Training loss: 3.8742406777932334
Validation loss: 3.043575991195351

Epoch: 5| Step: 9
Training loss: 4.027894745513172
Validation loss: 3.04289102179268

Epoch: 5| Step: 10
Training loss: 2.4386699509693277
Validation loss: 3.041323044117907

Epoch: 48| Step: 0
Training loss: 3.8540411164050803
Validation loss: 3.0412704141113753

Epoch: 5| Step: 1
Training loss: 3.795104693349564
Validation loss: 3.0403070674380888

Epoch: 5| Step: 2
Training loss: 3.7415159255987125
Validation loss: 3.0411688587885637

Epoch: 5| Step: 3
Training loss: 2.4463810642629804
Validation loss: 3.039571771978763

Epoch: 5| Step: 4
Training loss: 3.0935023044881564
Validation loss: 3.0428892424287244

Epoch: 5| Step: 5
Training loss: 2.9971070646268108
Validation loss: 3.043266781277377

Epoch: 5| Step: 6
Training loss: 3.954797684887756
Validation loss: 3.0415145649444653

Epoch: 5| Step: 7
Training loss: 3.517029341908552
Validation loss: 3.0439907224303906

Epoch: 5| Step: 8
Training loss: 2.7288914218939846
Validation loss: 3.0470623975770383

Epoch: 5| Step: 9
Training loss: 2.706224109270322
Validation loss: 3.0420968637467323

Epoch: 5| Step: 10
Training loss: 3.1629302082786155
Validation loss: 3.032902661076275

Epoch: 49| Step: 0
Training loss: 2.9294384659781043
Validation loss: 3.0358768896294377

Epoch: 5| Step: 1
Training loss: 3.7199356368864938
Validation loss: 3.0405203518660238

Epoch: 5| Step: 2
Training loss: 3.244763924779624
Validation loss: 3.0505774380550226

Epoch: 5| Step: 3
Training loss: 3.5201834054329812
Validation loss: 3.0582414299817926

Epoch: 5| Step: 4
Training loss: 2.481176848978767
Validation loss: 3.0541401017445344

Epoch: 5| Step: 5
Training loss: 3.603361330114732
Validation loss: 3.043013861947852

Epoch: 5| Step: 6
Training loss: 2.5066782445166758
Validation loss: 3.0348548424343553

Epoch: 5| Step: 7
Training loss: 3.8357333810731307
Validation loss: 3.032248311156918

Epoch: 5| Step: 8
Training loss: 3.4038517059585933
Validation loss: 3.029483239270491

Epoch: 5| Step: 9
Training loss: 3.5808702623716346
Validation loss: 3.028721773209894

Epoch: 5| Step: 10
Training loss: 3.3737843054730035
Validation loss: 3.0434609713159144

Epoch: 50| Step: 0
Training loss: 3.5146202177423636
Validation loss: 3.0355451942298886

Epoch: 5| Step: 1
Training loss: 3.060474270736616
Validation loss: 3.030537240597107

Epoch: 5| Step: 2
Training loss: 3.695303467301989
Validation loss: 3.028137171229055

Epoch: 5| Step: 3
Training loss: 3.9053852802658144
Validation loss: 3.03166293008533

Epoch: 5| Step: 4
Training loss: 2.525806932587201
Validation loss: 3.024302494616143

Epoch: 5| Step: 5
Training loss: 3.2531167271167174
Validation loss: 3.0247672282715934

Epoch: 5| Step: 6
Training loss: 2.743233592590698
Validation loss: 3.026717272668758

Epoch: 5| Step: 7
Training loss: 3.3806715042038524
Validation loss: 3.0366201427121395

Epoch: 5| Step: 8
Training loss: 2.932090973747663
Validation loss: 3.0318496883907486

Epoch: 5| Step: 9
Training loss: 3.660343193890172
Validation loss: 3.023718553738115

Epoch: 5| Step: 10
Training loss: 3.427227415323888
Validation loss: 3.021186654061688

Epoch: 51| Step: 0
Training loss: 3.042753434796487
Validation loss: 3.0210669054163724

Epoch: 5| Step: 1
Training loss: 3.688001049074698
Validation loss: 3.0193078868067555

Epoch: 5| Step: 2
Training loss: 3.912613712888634
Validation loss: 3.019536348357243

Epoch: 5| Step: 3
Training loss: 3.5188182654797098
Validation loss: 3.0172074472004597

Epoch: 5| Step: 4
Training loss: 2.728057888468365
Validation loss: 3.014833079717371

Epoch: 5| Step: 5
Training loss: 3.4140929476080797
Validation loss: 3.016992390620392

Epoch: 5| Step: 6
Training loss: 3.0936615285842732
Validation loss: 3.0133690161130033

Epoch: 5| Step: 7
Training loss: 3.1537855743687904
Validation loss: 3.0137352016215613

Epoch: 5| Step: 8
Training loss: 2.7916338524858904
Validation loss: 3.019211585762224

Epoch: 5| Step: 9
Training loss: 3.485219810263693
Validation loss: 3.0207526883968527

Epoch: 5| Step: 10
Training loss: 3.297470979020575
Validation loss: 3.034060504052389

Epoch: 52| Step: 0
Training loss: 3.543809280034245
Validation loss: 3.022564042501777

Epoch: 5| Step: 1
Training loss: 3.535407395688821
Validation loss: 3.014809060848024

Epoch: 5| Step: 2
Training loss: 3.0457193383742656
Validation loss: 3.011732745756207

Epoch: 5| Step: 3
Training loss: 3.122763176510089
Validation loss: 3.0131992855860505

Epoch: 5| Step: 4
Training loss: 3.979948569497441
Validation loss: 3.014773250727567

Epoch: 5| Step: 5
Training loss: 3.4507078799047193
Validation loss: 3.0112050312881204

Epoch: 5| Step: 6
Training loss: 3.5990157318322566
Validation loss: 3.0110918433217932

Epoch: 5| Step: 7
Training loss: 2.6827215251483225
Validation loss: 3.0114589416462656

Epoch: 5| Step: 8
Training loss: 2.3349587932275284
Validation loss: 3.0101055727251116

Epoch: 5| Step: 9
Training loss: 3.1651430145301807
Validation loss: 3.009641391172421

Epoch: 5| Step: 10
Training loss: 3.4923422008956595
Validation loss: 3.0076673264102216

Epoch: 53| Step: 0
Training loss: 3.302173713546281
Validation loss: 3.0070602970129574

Epoch: 5| Step: 1
Training loss: 3.690955014376612
Validation loss: 3.0060073556090985

Epoch: 5| Step: 2
Training loss: 3.3242391188969083
Validation loss: 3.005852934035069

Epoch: 5| Step: 3
Training loss: 3.8380245583341406
Validation loss: 3.0045977690387518

Epoch: 5| Step: 4
Training loss: 3.2180911380529515
Validation loss: 3.0024711231414356

Epoch: 5| Step: 5
Training loss: 3.2542673119005894
Validation loss: 3.0016592967608

Epoch: 5| Step: 6
Training loss: 2.9474342050238094
Validation loss: 3.001260197090285

Epoch: 5| Step: 7
Training loss: 3.2119871034375165
Validation loss: 2.9985462190406897

Epoch: 5| Step: 8
Training loss: 3.18810042167841
Validation loss: 2.998252359611189

Epoch: 5| Step: 9
Training loss: 3.153311390655929
Validation loss: 2.998113497090404

Epoch: 5| Step: 10
Training loss: 2.8249296399021957
Validation loss: 2.9981666170394954

Epoch: 54| Step: 0
Training loss: 3.0132069751386834
Validation loss: 3.0060417956135557

Epoch: 5| Step: 1
Training loss: 3.0728694761284245
Validation loss: 3.0473051858669615

Epoch: 5| Step: 2
Training loss: 3.6932735180974587
Validation loss: 3.0094057161149648

Epoch: 5| Step: 3
Training loss: 3.372091665015295
Validation loss: 2.9955361254288024

Epoch: 5| Step: 4
Training loss: 2.4311395458245446
Validation loss: 2.9923440224055473

Epoch: 5| Step: 5
Training loss: 3.3885490285279616
Validation loss: 2.992265649991221

Epoch: 5| Step: 6
Training loss: 3.0991425958984067
Validation loss: 2.9940196404977644

Epoch: 5| Step: 7
Training loss: 3.3655418392805996
Validation loss: 2.992781112924282

Epoch: 5| Step: 8
Training loss: 3.4982537954398865
Validation loss: 2.9923382008974144

Epoch: 5| Step: 9
Training loss: 3.410123390135569
Validation loss: 2.992633662190948

Epoch: 5| Step: 10
Training loss: 3.6605707705341346
Validation loss: 2.9902849574959625

Epoch: 55| Step: 0
Training loss: 3.4095998268578502
Validation loss: 2.9913171096488655

Epoch: 5| Step: 1
Training loss: 3.381117327726161
Validation loss: 2.991145125879497

Epoch: 5| Step: 2
Training loss: 3.315982355675961
Validation loss: 2.9909670586203747

Epoch: 5| Step: 3
Training loss: 3.418308855846698
Validation loss: 2.989364359318354

Epoch: 5| Step: 4
Training loss: 3.4545370813660696
Validation loss: 2.9887743359769376

Epoch: 5| Step: 5
Training loss: 3.362366519817021
Validation loss: 2.989387251663638

Epoch: 5| Step: 6
Training loss: 3.267737476501445
Validation loss: 2.990817210092562

Epoch: 5| Step: 7
Training loss: 3.0281900908695327
Validation loss: 2.984889119267353

Epoch: 5| Step: 8
Training loss: 3.1056087822201826
Validation loss: 2.9837339279979402

Epoch: 5| Step: 9
Training loss: 3.2187597774616363
Validation loss: 2.9836570581866653

Epoch: 5| Step: 10
Training loss: 3.005936312418952
Validation loss: 2.9834744229012045

Epoch: 56| Step: 0
Training loss: 3.583299784540254
Validation loss: 2.981616534231436

Epoch: 5| Step: 1
Training loss: 2.381760562018436
Validation loss: 2.982326765726648

Epoch: 5| Step: 2
Training loss: 2.953459705579697
Validation loss: 2.9838095929719017

Epoch: 5| Step: 3
Training loss: 2.9956057473130473
Validation loss: 2.9868438521545992

Epoch: 5| Step: 4
Training loss: 3.1140204764141894
Validation loss: 2.9882183654118046

Epoch: 5| Step: 5
Training loss: 3.4710136107252367
Validation loss: 2.984710997437026

Epoch: 5| Step: 6
Training loss: 3.434893087752804
Validation loss: 2.981849693369281

Epoch: 5| Step: 7
Training loss: 3.750392638949829
Validation loss: 2.980346727078153

Epoch: 5| Step: 8
Training loss: 3.2512298604480043
Validation loss: 2.979474168347354

Epoch: 5| Step: 9
Training loss: 3.2233190606270368
Validation loss: 2.977156803512748

Epoch: 5| Step: 10
Training loss: 3.6735410116743115
Validation loss: 2.97815145320197

Epoch: 57| Step: 0
Training loss: 2.945702483972961
Validation loss: 2.978006438317529

Epoch: 5| Step: 1
Training loss: 3.2186034826615524
Validation loss: 2.978954312493569

Epoch: 5| Step: 2
Training loss: 2.3795730332855403
Validation loss: 2.9820694043067904

Epoch: 5| Step: 3
Training loss: 3.9350640164006716
Validation loss: 2.980970335081588

Epoch: 5| Step: 4
Training loss: 2.9545780220104145
Validation loss: 2.9833356553664054

Epoch: 5| Step: 5
Training loss: 3.011329239768246
Validation loss: 2.9807905823510223

Epoch: 5| Step: 6
Training loss: 3.5438396893274313
Validation loss: 2.9842567035990273

Epoch: 5| Step: 7
Training loss: 3.900917991779482
Validation loss: 2.9773327760404324

Epoch: 5| Step: 8
Training loss: 3.2931801579899203
Validation loss: 2.971303627151127

Epoch: 5| Step: 9
Training loss: 3.160456809331895
Validation loss: 2.970222746000123

Epoch: 5| Step: 10
Training loss: 3.223061202066766
Validation loss: 2.9702270166847926

Epoch: 58| Step: 0
Training loss: 2.962237794756786
Validation loss: 2.97191758566171

Epoch: 5| Step: 1
Training loss: 3.1399426074766192
Validation loss: 2.972226619349831

Epoch: 5| Step: 2
Training loss: 3.4327424852665263
Validation loss: 2.9742107588454436

Epoch: 5| Step: 3
Training loss: 3.3638607859432934
Validation loss: 2.9775502674433287

Epoch: 5| Step: 4
Training loss: 3.3638229376952276
Validation loss: 2.9725316157248693

Epoch: 5| Step: 5
Training loss: 2.90218898108962
Validation loss: 2.9725727212237953

Epoch: 5| Step: 6
Training loss: 3.6272849412366095
Validation loss: 2.9702264383992327

Epoch: 5| Step: 7
Training loss: 3.383968164677496
Validation loss: 2.9675349444904318

Epoch: 5| Step: 8
Training loss: 2.793891380880212
Validation loss: 2.9657854892733417

Epoch: 5| Step: 9
Training loss: 3.6362487948229782
Validation loss: 2.963188503432166

Epoch: 5| Step: 10
Training loss: 3.1450986362145392
Validation loss: 2.961983851505389

Epoch: 59| Step: 0
Training loss: 3.5128100166756577
Validation loss: 2.9625253234171414

Epoch: 5| Step: 1
Training loss: 3.1133918311799444
Validation loss: 2.9607938690029285

Epoch: 5| Step: 2
Training loss: 2.886594034063792
Validation loss: 2.959907106775536

Epoch: 5| Step: 3
Training loss: 2.8336409420504136
Validation loss: 2.9605973947998763

Epoch: 5| Step: 4
Training loss: 3.022329201238538
Validation loss: 2.963656542934212

Epoch: 5| Step: 5
Training loss: 3.7481226990441288
Validation loss: 2.969170518678256

Epoch: 5| Step: 6
Training loss: 3.902095446930165
Validation loss: 2.9671031293704253

Epoch: 5| Step: 7
Training loss: 3.6313624615743803
Validation loss: 2.9597525848467496

Epoch: 5| Step: 8
Training loss: 2.772866805555236
Validation loss: 2.960380749263998

Epoch: 5| Step: 9
Training loss: 2.84994887590565
Validation loss: 2.961969518546882

Epoch: 5| Step: 10
Training loss: 3.2760926906249033
Validation loss: 2.964487350780607

Epoch: 60| Step: 0
Training loss: 3.2605291150154265
Validation loss: 2.9672733107874847

Epoch: 5| Step: 1
Training loss: 3.2861976741834313
Validation loss: 2.9626438169132174

Epoch: 5| Step: 2
Training loss: 3.3221476431321584
Validation loss: 2.9588981616670598

Epoch: 5| Step: 3
Training loss: 3.101579718938349
Validation loss: 2.957824806021496

Epoch: 5| Step: 4
Training loss: 3.2067493310161703
Validation loss: 2.9542281440877676

Epoch: 5| Step: 5
Training loss: 3.241046603669593
Validation loss: 2.9536154472623553

Epoch: 5| Step: 6
Training loss: 3.299929537165354
Validation loss: 2.9524352737546016

Epoch: 5| Step: 7
Training loss: 2.922729040981574
Validation loss: 2.951628572856225

Epoch: 5| Step: 8
Training loss: 3.817880055033686
Validation loss: 2.9568342743440117

Epoch: 5| Step: 9
Training loss: 3.5053494308361306
Validation loss: 2.9569080500673994

Epoch: 5| Step: 10
Training loss: 2.5457819365845413
Validation loss: 2.9617668018875984

Epoch: 61| Step: 0
Training loss: 3.224911172515869
Validation loss: 2.961169421740242

Epoch: 5| Step: 1
Training loss: 3.4954178652274566
Validation loss: 2.951757828689086

Epoch: 5| Step: 2
Training loss: 3.510686907379453
Validation loss: 2.949874644834125

Epoch: 5| Step: 3
Training loss: 3.499958855523368
Validation loss: 2.9496687277098004

Epoch: 5| Step: 4
Training loss: 3.095614709403796
Validation loss: 2.946438379177729

Epoch: 5| Step: 5
Training loss: 3.1984433083232253
Validation loss: 2.9465282145620115

Epoch: 5| Step: 6
Training loss: 3.382698885307001
Validation loss: 2.9442481032053855

Epoch: 5| Step: 7
Training loss: 3.1026992060101595
Validation loss: 2.9444885363469635

Epoch: 5| Step: 8
Training loss: 2.3977894855072415
Validation loss: 2.9432359424818313

Epoch: 5| Step: 9
Training loss: 3.4871861361027388
Validation loss: 2.9429836680525994

Epoch: 5| Step: 10
Training loss: 3.0772838701948233
Validation loss: 2.9440812738705495

Epoch: 62| Step: 0
Training loss: 3.459388127771571
Validation loss: 2.943939325829004

Epoch: 5| Step: 1
Training loss: 3.230806160111415
Validation loss: 2.941454680987747

Epoch: 5| Step: 2
Training loss: 2.101128856064663
Validation loss: 2.93807391405583

Epoch: 5| Step: 3
Training loss: 3.5061725954701766
Validation loss: 2.9387941435560445

Epoch: 5| Step: 4
Training loss: 3.225866358108466
Validation loss: 2.9375542186445247

Epoch: 5| Step: 5
Training loss: 2.779168539508911
Validation loss: 2.938308821777822

Epoch: 5| Step: 6
Training loss: 3.0521291961522343
Validation loss: 2.9417913278763765

Epoch: 5| Step: 7
Training loss: 3.24556179714535
Validation loss: 2.951523557064155

Epoch: 5| Step: 8
Training loss: 3.2039784852828324
Validation loss: 2.95895991665042

Epoch: 5| Step: 9
Training loss: 3.6958330041884513
Validation loss: 2.9567970580535623

Epoch: 5| Step: 10
Training loss: 3.8549398660484457
Validation loss: 2.9345034883276875

Epoch: 63| Step: 0
Training loss: 3.110703074475883
Validation loss: 2.933568277719913

Epoch: 5| Step: 1
Training loss: 2.993204845256419
Validation loss: 2.9327182910041616

Epoch: 5| Step: 2
Training loss: 3.194585069150309
Validation loss: 2.9308710681880545

Epoch: 5| Step: 3
Training loss: 3.2777477647373545
Validation loss: 2.931630116438866

Epoch: 5| Step: 4
Training loss: 3.1519160967372817
Validation loss: 2.9308727143779443

Epoch: 5| Step: 5
Training loss: 3.6848594133534047
Validation loss: 2.930086624358456

Epoch: 5| Step: 6
Training loss: 3.3698794762767625
Validation loss: 2.9321889286486496

Epoch: 5| Step: 7
Training loss: 3.5009212643819705
Validation loss: 2.9313719299762346

Epoch: 5| Step: 8
Training loss: 2.786258088994767
Validation loss: 2.9307395764400503

Epoch: 5| Step: 9
Training loss: 3.292303015769363
Validation loss: 2.9301144559661076

Epoch: 5| Step: 10
Training loss: 3.0335442424293677
Validation loss: 2.926091387174012

Epoch: 64| Step: 0
Training loss: 3.036678055435861
Validation loss: 2.9278142305060944

Epoch: 5| Step: 1
Training loss: 3.59781980194541
Validation loss: 2.92682415132924

Epoch: 5| Step: 2
Training loss: 3.609515563077358
Validation loss: 2.928301624283743

Epoch: 5| Step: 3
Training loss: 3.356683122758073
Validation loss: 2.932392461710555

Epoch: 5| Step: 4
Training loss: 3.161649108526944
Validation loss: 2.930959919134565

Epoch: 5| Step: 5
Training loss: 3.119724398202467
Validation loss: 2.9312445371686096

Epoch: 5| Step: 6
Training loss: 3.5932539887830464
Validation loss: 2.927234343745895

Epoch: 5| Step: 7
Training loss: 2.928992104969995
Validation loss: 2.9239494255878866

Epoch: 5| Step: 8
Training loss: 3.425062114959816
Validation loss: 2.920801759326576

Epoch: 5| Step: 9
Training loss: 2.7948272710393156
Validation loss: 2.921620781954707

Epoch: 5| Step: 10
Training loss: 2.6136657705650483
Validation loss: 2.9198958058239026

Epoch: 65| Step: 0
Training loss: 3.2481722460583087
Validation loss: 2.9182203599245233

Epoch: 5| Step: 1
Training loss: 2.6489732588631156
Validation loss: 2.9189770110779145

Epoch: 5| Step: 2
Training loss: 2.8229681388038044
Validation loss: 2.921522040986522

Epoch: 5| Step: 3
Training loss: 2.7259470947404636
Validation loss: 2.927522978297135

Epoch: 5| Step: 4
Training loss: 3.869361959690209
Validation loss: 2.9604452158315326

Epoch: 5| Step: 5
Training loss: 3.151132192441041
Validation loss: 2.9796801112510485

Epoch: 5| Step: 6
Training loss: 3.222100745209602
Validation loss: 3.0089327437763513

Epoch: 5| Step: 7
Training loss: 3.4382603584665516
Validation loss: 3.0196918903872314

Epoch: 5| Step: 8
Training loss: 3.930113266921517
Validation loss: 3.01632575002876

Epoch: 5| Step: 9
Training loss: 3.1955821476134822
Validation loss: 2.935035002518007

Epoch: 5| Step: 10
Training loss: 3.280761973100991
Validation loss: 2.918528667107989

Epoch: 66| Step: 0
Training loss: 3.566618295739661
Validation loss: 2.9581834673382925

Epoch: 5| Step: 1
Training loss: 3.1912037891429517
Validation loss: 2.978547737086999

Epoch: 5| Step: 2
Training loss: 3.2835945109426166
Validation loss: 2.945999883050144

Epoch: 5| Step: 3
Training loss: 2.7288233611467656
Validation loss: 2.929514102521509

Epoch: 5| Step: 4
Training loss: 3.138048624044904
Validation loss: 2.9195852502322026

Epoch: 5| Step: 5
Training loss: 3.2140516044495073
Validation loss: 2.916486888097127

Epoch: 5| Step: 6
Training loss: 3.447452494713757
Validation loss: 2.9155162587580588

Epoch: 5| Step: 7
Training loss: 3.4907041808789474
Validation loss: 2.9143451299697563

Epoch: 5| Step: 8
Training loss: 3.0834411567874302
Validation loss: 2.914462641737483

Epoch: 5| Step: 9
Training loss: 3.12354504093373
Validation loss: 2.9142340765986763

Epoch: 5| Step: 10
Training loss: 3.205331925984781
Validation loss: 2.9307059502946835

Epoch: 67| Step: 0
Training loss: 3.1669402422601656
Validation loss: 2.920046796961727

Epoch: 5| Step: 1
Training loss: 2.863784475198115
Validation loss: 2.9147108672425457

Epoch: 5| Step: 2
Training loss: 2.8226345995831044
Validation loss: 2.9103715754041897

Epoch: 5| Step: 3
Training loss: 2.8229956715544198
Validation loss: 2.9083698069322788

Epoch: 5| Step: 4
Training loss: 3.266798036879128
Validation loss: 2.9092789240318035

Epoch: 5| Step: 5
Training loss: 2.821531756068056
Validation loss: 2.9080096688946626

Epoch: 5| Step: 6
Training loss: 3.4597022476412596
Validation loss: 2.9241836970288984

Epoch: 5| Step: 7
Training loss: 3.679998494023554
Validation loss: 2.9074813540044215

Epoch: 5| Step: 8
Training loss: 3.4560200564720835
Validation loss: 2.9067851568563023

Epoch: 5| Step: 9
Training loss: 3.493880917411363
Validation loss: 2.9039179398489163

Epoch: 5| Step: 10
Training loss: 3.3203252814551787
Validation loss: 2.9045320572281064

Epoch: 68| Step: 0
Training loss: 2.997536919679033
Validation loss: 2.903605481983941

Epoch: 5| Step: 1
Training loss: 3.2545842337925555
Validation loss: 2.9026773497567713

Epoch: 5| Step: 2
Training loss: 2.6436586729467613
Validation loss: 2.901429913404611

Epoch: 5| Step: 3
Training loss: 4.02946160442474
Validation loss: 2.9023465818588616

Epoch: 5| Step: 4
Training loss: 3.877644528635148
Validation loss: 2.9031072007270335

Epoch: 5| Step: 5
Training loss: 2.9429151254198285
Validation loss: 2.9002003479953533

Epoch: 5| Step: 6
Training loss: 3.0285711347574673
Validation loss: 2.901254699830185

Epoch: 5| Step: 7
Training loss: 2.481874274986467
Validation loss: 2.9064901100356044

Epoch: 5| Step: 8
Training loss: 3.645200678111373
Validation loss: 2.92432738424456

Epoch: 5| Step: 9
Training loss: 2.2635131464315825
Validation loss: 2.8968560027267425

Epoch: 5| Step: 10
Training loss: 3.6427662327853527
Validation loss: 2.8967238643280075

Epoch: 69| Step: 0
Training loss: 3.8049614590310785
Validation loss: 2.8963228368093734

Epoch: 5| Step: 1
Training loss: 2.84973386893922
Validation loss: 2.8996798793018095

Epoch: 5| Step: 2
Training loss: 3.488495857497658
Validation loss: 2.8977067841851136

Epoch: 5| Step: 3
Training loss: 3.382665194856802
Validation loss: 2.897210096129775

Epoch: 5| Step: 4
Training loss: 3.8886765346374643
Validation loss: 2.8984891299081808

Epoch: 5| Step: 5
Training loss: 3.5484858816553193
Validation loss: 2.900522764285415

Epoch: 5| Step: 6
Training loss: 2.16918845018354
Validation loss: 2.901962492619003

Epoch: 5| Step: 7
Training loss: 2.7005798176448974
Validation loss: 2.905788148967786

Epoch: 5| Step: 8
Training loss: 2.5644343448831575
Validation loss: 2.915146688004366

Epoch: 5| Step: 9
Training loss: 2.982592624655341
Validation loss: 2.923163669804896

Epoch: 5| Step: 10
Training loss: 3.4128633745836088
Validation loss: 2.9213737446959676

Epoch: 70| Step: 0
Training loss: 2.9398515095482898
Validation loss: 2.8977593631227645

Epoch: 5| Step: 1
Training loss: 3.411792690208758
Validation loss: 2.8918524861123642

Epoch: 5| Step: 2
Training loss: 3.5396322503319935
Validation loss: 2.890572313462131

Epoch: 5| Step: 3
Training loss: 3.1841188337108877
Validation loss: 2.8928812743645738

Epoch: 5| Step: 4
Training loss: 3.643576935572654
Validation loss: 2.893695877870668

Epoch: 5| Step: 5
Training loss: 3.3414324278003384
Validation loss: 2.8932037752615503

Epoch: 5| Step: 6
Training loss: 3.5433793508197677
Validation loss: 2.891030311715375

Epoch: 5| Step: 7
Training loss: 2.410381386997944
Validation loss: 2.890053254587885

Epoch: 5| Step: 8
Training loss: 3.1582549119807117
Validation loss: 2.8890588084349886

Epoch: 5| Step: 9
Training loss: 3.03571250659025
Validation loss: 2.8891129742706743

Epoch: 5| Step: 10
Training loss: 2.642421495034786
Validation loss: 2.8870757481103886

Epoch: 71| Step: 0
Training loss: 2.4930957825183024
Validation loss: 2.8869140910587587

Epoch: 5| Step: 1
Training loss: 2.976178642612728
Validation loss: 2.886023406136444

Epoch: 5| Step: 2
Training loss: 3.3599347734932157
Validation loss: 2.8861258469581643

Epoch: 5| Step: 3
Training loss: 2.9668548960031713
Validation loss: 2.884121311577764

Epoch: 5| Step: 4
Training loss: 2.888716939145197
Validation loss: 2.8840071449980353

Epoch: 5| Step: 5
Training loss: 3.72493825259651
Validation loss: 2.8822079347585094

Epoch: 5| Step: 6
Training loss: 3.5058540705478674
Validation loss: 2.882025781333622

Epoch: 5| Step: 7
Training loss: 2.5245697032533037
Validation loss: 2.8818932885327393

Epoch: 5| Step: 8
Training loss: 3.000347117369427
Validation loss: 2.8814536286102808

Epoch: 5| Step: 9
Training loss: 3.9603314359277384
Validation loss: 2.8785913844851128

Epoch: 5| Step: 10
Training loss: 3.377787251487073
Validation loss: 2.8750607919708293

Epoch: 72| Step: 0
Training loss: 2.7416442159025296
Validation loss: 2.8748553142905564

Epoch: 5| Step: 1
Training loss: 3.159806466755303
Validation loss: 2.8754578502697785

Epoch: 5| Step: 2
Training loss: 2.6375138051905624
Validation loss: 2.8748134607806266

Epoch: 5| Step: 3
Training loss: 3.839463239348515
Validation loss: 2.8876112188966716

Epoch: 5| Step: 4
Training loss: 2.955438585603898
Validation loss: 2.898791513420824

Epoch: 5| Step: 5
Training loss: 3.453258943333372
Validation loss: 2.898885408564419

Epoch: 5| Step: 6
Training loss: 3.1290086593727553
Validation loss: 2.880385889263933

Epoch: 5| Step: 7
Training loss: 3.1101812342981985
Validation loss: 2.8743774735219674

Epoch: 5| Step: 8
Training loss: 3.5387609492287173
Validation loss: 2.8685051585332113

Epoch: 5| Step: 9
Training loss: 3.2866542816186683
Validation loss: 2.868592596984911

Epoch: 5| Step: 10
Training loss: 2.9020611508615466
Validation loss: 2.871404986979209

Epoch: 73| Step: 0
Training loss: 2.834362254592519
Validation loss: 2.873283674669763

Epoch: 5| Step: 1
Training loss: 3.4746534270763547
Validation loss: 2.8722625369182055

Epoch: 5| Step: 2
Training loss: 2.779892064887689
Validation loss: 2.8731532547964918

Epoch: 5| Step: 3
Training loss: 2.512785167547813
Validation loss: 2.8726438316862066

Epoch: 5| Step: 4
Training loss: 2.7995192319383477
Validation loss: 2.872773808857928

Epoch: 5| Step: 5
Training loss: 3.3194624945993527
Validation loss: 2.8710707823667825

Epoch: 5| Step: 6
Training loss: 3.902824059178412
Validation loss: 2.867942931166893

Epoch: 5| Step: 7
Training loss: 3.1062213489585035
Validation loss: 2.8678189335910327

Epoch: 5| Step: 8
Training loss: 3.423625759448494
Validation loss: 2.8647706007317812

Epoch: 5| Step: 9
Training loss: 3.8297875355884985
Validation loss: 2.865816909816499

Epoch: 5| Step: 10
Training loss: 2.5305557240740706
Validation loss: 2.8649227754873934

Epoch: 74| Step: 0
Training loss: 3.371915608781112
Validation loss: 2.861309813274578

Epoch: 5| Step: 1
Training loss: 2.9540817083527027
Validation loss: 2.862111223723904

Epoch: 5| Step: 2
Training loss: 2.749933241987555
Validation loss: 2.859537126425597

Epoch: 5| Step: 3
Training loss: 3.938904163729725
Validation loss: 2.8611396227680146

Epoch: 5| Step: 4
Training loss: 3.089001643305447
Validation loss: 2.859579201730732

Epoch: 5| Step: 5
Training loss: 3.4382815772959825
Validation loss: 2.8599688897598234

Epoch: 5| Step: 6
Training loss: 2.7968815638289337
Validation loss: 2.861937702924431

Epoch: 5| Step: 7
Training loss: 3.5719030664497717
Validation loss: 2.8582474598941796

Epoch: 5| Step: 8
Training loss: 3.082764822295882
Validation loss: 2.8612539554267324

Epoch: 5| Step: 9
Training loss: 2.2647062346077127
Validation loss: 2.8599209613062806

Epoch: 5| Step: 10
Training loss: 3.3681997384128275
Validation loss: 2.859422379945126

Epoch: 75| Step: 0
Training loss: 3.890008471560631
Validation loss: 2.8568614947162994

Epoch: 5| Step: 1
Training loss: 3.182552312404528
Validation loss: 2.8568525336394033

Epoch: 5| Step: 2
Training loss: 3.4696798367069097
Validation loss: 2.85829875650919

Epoch: 5| Step: 3
Training loss: 3.2540328606820244
Validation loss: 2.8587268722623618

Epoch: 5| Step: 4
Training loss: 2.6467536367000633
Validation loss: 2.85551258745544

Epoch: 5| Step: 5
Training loss: 3.1457079089763234
Validation loss: 2.8569167573596617

Epoch: 5| Step: 6
Training loss: 3.363415510486208
Validation loss: 2.856009452892077

Epoch: 5| Step: 7
Training loss: 2.13836048942482
Validation loss: 2.8546311464837335

Epoch: 5| Step: 8
Training loss: 3.0822283508941486
Validation loss: 2.8531045508598996

Epoch: 5| Step: 9
Training loss: 3.270150439333644
Validation loss: 2.8536720670691205

Epoch: 5| Step: 10
Training loss: 3.0862686172733422
Validation loss: 2.8528139315788974

Epoch: 76| Step: 0
Training loss: 3.2813895059629465
Validation loss: 2.854643158958632

Epoch: 5| Step: 1
Training loss: 3.1008118458548166
Validation loss: 2.852926876176772

Epoch: 5| Step: 2
Training loss: 3.1319003406322405
Validation loss: 2.85202155638705

Epoch: 5| Step: 3
Training loss: 3.4742525463206086
Validation loss: 2.8513217358573977

Epoch: 5| Step: 4
Training loss: 3.2158287643659813
Validation loss: 2.850196339181023

Epoch: 5| Step: 5
Training loss: 3.3322977046707143
Validation loss: 2.8493432813763624

Epoch: 5| Step: 6
Training loss: 3.0239148613282767
Validation loss: 2.850091931426089

Epoch: 5| Step: 7
Training loss: 3.0918763006518737
Validation loss: 2.8508679236150547

Epoch: 5| Step: 8
Training loss: 3.574960033486785
Validation loss: 2.857961919537467

Epoch: 5| Step: 9
Training loss: 2.3806349513215705
Validation loss: 2.852162544880346

Epoch: 5| Step: 10
Training loss: 2.9464636862507794
Validation loss: 2.8522673388274313

Epoch: 77| Step: 0
Training loss: 2.439713573372677
Validation loss: 2.845336275114622

Epoch: 5| Step: 1
Training loss: 3.180842909031893
Validation loss: 2.8422771562635925

Epoch: 5| Step: 2
Training loss: 3.390422199706217
Validation loss: 2.84403751168003

Epoch: 5| Step: 3
Training loss: 2.71833394692806
Validation loss: 2.8455039620107274

Epoch: 5| Step: 4
Training loss: 3.2263832319581085
Validation loss: 2.844309329351817

Epoch: 5| Step: 5
Training loss: 3.3987909242860583
Validation loss: 2.847518652221468

Epoch: 5| Step: 6
Training loss: 2.9183682700578033
Validation loss: 2.8431808910088483

Epoch: 5| Step: 7
Training loss: 3.29602748589953
Validation loss: 2.844125233635444

Epoch: 5| Step: 8
Training loss: 3.601346818336832
Validation loss: 2.8419277478882954

Epoch: 5| Step: 9
Training loss: 3.362494293548393
Validation loss: 2.8433822435511873

Epoch: 5| Step: 10
Training loss: 2.9668140724793695
Validation loss: 2.8381849375054684

Epoch: 78| Step: 0
Training loss: 2.7556371998057227
Validation loss: 2.837872272251975

Epoch: 5| Step: 1
Training loss: 3.2703114151895893
Validation loss: 2.8377383178069335

Epoch: 5| Step: 2
Training loss: 2.9312590186136913
Validation loss: 2.837364642906519

Epoch: 5| Step: 3
Training loss: 3.421977281130493
Validation loss: 2.8368980999877107

Epoch: 5| Step: 4
Training loss: 3.3030060803562136
Validation loss: 2.835559763428164

Epoch: 5| Step: 5
Training loss: 2.8265826830293617
Validation loss: 2.83625493772674

Epoch: 5| Step: 6
Training loss: 3.316956167829071
Validation loss: 2.8325969832820213

Epoch: 5| Step: 7
Training loss: 3.509156239485862
Validation loss: 2.835399190933499

Epoch: 5| Step: 8
Training loss: 3.023628012004861
Validation loss: 2.8362682419391048

Epoch: 5| Step: 9
Training loss: 3.0687848432936304
Validation loss: 2.831996096971704

Epoch: 5| Step: 10
Training loss: 3.1299213567731954
Validation loss: 2.831031800723701

Epoch: 79| Step: 0
Training loss: 3.17060759079581
Validation loss: 2.8325476721329226

Epoch: 5| Step: 1
Training loss: 2.8944750740479126
Validation loss: 2.8321245043899146

Epoch: 5| Step: 2
Training loss: 3.721807296995539
Validation loss: 2.832675043635488

Epoch: 5| Step: 3
Training loss: 3.393760672705292
Validation loss: 2.830132730323052

Epoch: 5| Step: 4
Training loss: 3.429701125133101
Validation loss: 2.8320593898508117

Epoch: 5| Step: 5
Training loss: 2.62359308959451
Validation loss: 2.8314817834307515

Epoch: 5| Step: 6
Training loss: 2.913475979848856
Validation loss: 2.828209816311188

Epoch: 5| Step: 7
Training loss: 3.131130156821968
Validation loss: 2.827972461478055

Epoch: 5| Step: 8
Training loss: 3.519447520421213
Validation loss: 2.8285730505926825

Epoch: 5| Step: 9
Training loss: 2.7218479615017084
Validation loss: 2.827626849533543

Epoch: 5| Step: 10
Training loss: 2.8073598727195725
Validation loss: 2.826495284632704

Epoch: 80| Step: 0
Training loss: 3.2198528881705077
Validation loss: 2.82867611736751

Epoch: 5| Step: 1
Training loss: 2.7553037303617565
Validation loss: 2.8291541197420935

Epoch: 5| Step: 2
Training loss: 3.1600708448943005
Validation loss: 2.8324687457180677

Epoch: 5| Step: 3
Training loss: 3.311643381739251
Validation loss: 2.8269845043800794

Epoch: 5| Step: 4
Training loss: 3.231165080919167
Validation loss: 2.8259991764838155

Epoch: 5| Step: 5
Training loss: 2.830453999096862
Validation loss: 2.8280725868021688

Epoch: 5| Step: 6
Training loss: 2.8701176859156594
Validation loss: 2.8283713806843953

Epoch: 5| Step: 7
Training loss: 3.5256669461913597
Validation loss: 2.8226768834690454

Epoch: 5| Step: 8
Training loss: 3.5747263396832896
Validation loss: 2.8224856363880715

Epoch: 5| Step: 9
Training loss: 2.740502777332053
Validation loss: 2.819193220043295

Epoch: 5| Step: 10
Training loss: 3.1937216083735276
Validation loss: 2.8189884700554124

Epoch: 81| Step: 0
Training loss: 3.0108248599985767
Validation loss: 2.8188335954458235

Epoch: 5| Step: 1
Training loss: 3.100684361134692
Validation loss: 2.819386880029935

Epoch: 5| Step: 2
Training loss: 2.791357042213604
Validation loss: 2.819605302151195

Epoch: 5| Step: 3
Training loss: 3.149860070163258
Validation loss: 2.8191497126426177

Epoch: 5| Step: 4
Training loss: 3.7738867071761804
Validation loss: 2.817973007652487

Epoch: 5| Step: 5
Training loss: 3.626425627196819
Validation loss: 2.8138460026223484

Epoch: 5| Step: 6
Training loss: 2.516568593352144
Validation loss: 2.8157437650054544

Epoch: 5| Step: 7
Training loss: 3.0700921132437164
Validation loss: 2.8129059164800734

Epoch: 5| Step: 8
Training loss: 3.236050968584527
Validation loss: 2.809612660694071

Epoch: 5| Step: 9
Training loss: 3.1874615536035384
Validation loss: 2.809136645439016

Epoch: 5| Step: 10
Training loss: 2.7559825672323606
Validation loss: 2.8107927343080394

Epoch: 82| Step: 0
Training loss: 3.2284586140421574
Validation loss: 2.8108673643834825

Epoch: 5| Step: 1
Training loss: 2.933353663142876
Validation loss: 2.806982932793374

Epoch: 5| Step: 2
Training loss: 2.873098324976949
Validation loss: 2.8059689437114366

Epoch: 5| Step: 3
Training loss: 3.024635255119809
Validation loss: 2.8017886729231045

Epoch: 5| Step: 4
Training loss: 3.593768310500228
Validation loss: 2.802452776368674

Epoch: 5| Step: 5
Training loss: 3.4257333680376703
Validation loss: 2.803402622864855

Epoch: 5| Step: 6
Training loss: 3.566122789597728
Validation loss: 2.800743076794699

Epoch: 5| Step: 7
Training loss: 2.7633592192845082
Validation loss: 2.7959147697934106

Epoch: 5| Step: 8
Training loss: 2.5718797352261715
Validation loss: 2.797956630471558

Epoch: 5| Step: 9
Training loss: 3.0163525904358566
Validation loss: 2.7985515664654246

Epoch: 5| Step: 10
Training loss: 3.167713009146029
Validation loss: 2.7973760514787136

Epoch: 83| Step: 0
Training loss: 2.9951423417593865
Validation loss: 2.796999892512766

Epoch: 5| Step: 1
Training loss: 3.424955192328508
Validation loss: 2.7946011274733236

Epoch: 5| Step: 2
Training loss: 3.165089231079946
Validation loss: 2.791305460464235

Epoch: 5| Step: 3
Training loss: 2.90769643577559
Validation loss: 2.794027115428173

Epoch: 5| Step: 4
Training loss: 2.7415296846932815
Validation loss: 2.794117041474456

Epoch: 5| Step: 5
Training loss: 3.697192627135291
Validation loss: 2.796411963245421

Epoch: 5| Step: 6
Training loss: 3.4392515401779225
Validation loss: 2.7941961704046303

Epoch: 5| Step: 7
Training loss: 3.1130487410237024
Validation loss: 2.797733318402481

Epoch: 5| Step: 8
Training loss: 3.0489218072470377
Validation loss: 2.7909589270410997

Epoch: 5| Step: 9
Training loss: 2.5648401321353083
Validation loss: 2.7890971564144715

Epoch: 5| Step: 10
Training loss: 2.9349087588215452
Validation loss: 2.79114111953868

Epoch: 84| Step: 0
Training loss: 2.97269186031151
Validation loss: 2.7871899133286524

Epoch: 5| Step: 1
Training loss: 2.085060306655747
Validation loss: 2.790121576273797

Epoch: 5| Step: 2
Training loss: 3.341762344119521
Validation loss: 2.7876245593790343

Epoch: 5| Step: 3
Training loss: 3.132308653081453
Validation loss: 2.787358017174026

Epoch: 5| Step: 4
Training loss: 3.3241158995087248
Validation loss: 2.78669534955005

Epoch: 5| Step: 5
Training loss: 3.2677094592180747
Validation loss: 2.787801395225872

Epoch: 5| Step: 6
Training loss: 2.3350561003715358
Validation loss: 2.78611776812115

Epoch: 5| Step: 7
Training loss: 3.3401398466151515
Validation loss: 2.783903242018779

Epoch: 5| Step: 8
Training loss: 3.4453475154559228
Validation loss: 2.7852282801073818

Epoch: 5| Step: 9
Training loss: 3.4557573460587285
Validation loss: 2.786180757059216

Epoch: 5| Step: 10
Training loss: 3.1553710620149675
Validation loss: 2.7842964539241684

Epoch: 85| Step: 0
Training loss: 3.1294910965387697
Validation loss: 2.786293816312365

Epoch: 5| Step: 1
Training loss: 2.742610800912069
Validation loss: 2.7846969126534704

Epoch: 5| Step: 2
Training loss: 3.2361990535139897
Validation loss: 2.7859038181399267

Epoch: 5| Step: 3
Training loss: 3.3614417527369795
Validation loss: 2.7853132438770274

Epoch: 5| Step: 4
Training loss: 2.5749336604489232
Validation loss: 2.784788389226827

Epoch: 5| Step: 5
Training loss: 3.7879716384373783
Validation loss: 2.783967507645879

Epoch: 5| Step: 6
Training loss: 2.94665092190755
Validation loss: 2.783601412783408

Epoch: 5| Step: 7
Training loss: 3.1843250394276765
Validation loss: 2.7839356503576798

Epoch: 5| Step: 8
Training loss: 3.09273211756026
Validation loss: 2.7825077407352303

Epoch: 5| Step: 9
Training loss: 3.320370662404183
Validation loss: 2.7830260817228214

Epoch: 5| Step: 10
Training loss: 2.5174242302592615
Validation loss: 2.7816893684610378

Epoch: 86| Step: 0
Training loss: 3.1113215348819883
Validation loss: 2.780045371400595

Epoch: 5| Step: 1
Training loss: 2.5982245031651243
Validation loss: 2.778655069074841

Epoch: 5| Step: 2
Training loss: 2.7203117357457822
Validation loss: 2.777441732390716

Epoch: 5| Step: 3
Training loss: 3.592213974133767
Validation loss: 2.7800446419736478

Epoch: 5| Step: 4
Training loss: 3.0411365168949733
Validation loss: 2.776664136017733

Epoch: 5| Step: 5
Training loss: 2.567599270395632
Validation loss: 2.7784193400080315

Epoch: 5| Step: 6
Training loss: 3.575670491545792
Validation loss: 2.777372069178607

Epoch: 5| Step: 7
Training loss: 3.6601802210394343
Validation loss: 2.7834986433568023

Epoch: 5| Step: 8
Training loss: 2.782142495960329
Validation loss: 2.78383974293958

Epoch: 5| Step: 9
Training loss: 3.083307541060611
Validation loss: 2.7790803206418886

Epoch: 5| Step: 10
Training loss: 3.1093271529767144
Validation loss: 2.779354334777101

Epoch: 87| Step: 0
Training loss: 3.6568762088109277
Validation loss: 2.7825811025287224

Epoch: 5| Step: 1
Training loss: 2.850503636080663
Validation loss: 2.776266504987098

Epoch: 5| Step: 2
Training loss: 3.2482321405934904
Validation loss: 2.774587842071005

Epoch: 5| Step: 3
Training loss: 3.0223954645069315
Validation loss: 2.7736612061319423

Epoch: 5| Step: 4
Training loss: 3.4561097377026337
Validation loss: 2.7723043194733994

Epoch: 5| Step: 5
Training loss: 2.9060470346108658
Validation loss: 2.7715643295452557

Epoch: 5| Step: 6
Training loss: 2.803092311638766
Validation loss: 2.7728517733344336

Epoch: 5| Step: 7
Training loss: 3.2912167269788406
Validation loss: 2.769607629672593

Epoch: 5| Step: 8
Training loss: 2.7950383981104125
Validation loss: 2.7720064604576695

Epoch: 5| Step: 9
Training loss: 2.8466919154432913
Validation loss: 2.7702949575146354

Epoch: 5| Step: 10
Training loss: 3.039813343642101
Validation loss: 2.7703043799569964

Epoch: 88| Step: 0
Training loss: 2.9359735621683423
Validation loss: 2.7674101628766596

Epoch: 5| Step: 1
Training loss: 3.1016378321495384
Validation loss: 2.768460661367245

Epoch: 5| Step: 2
Training loss: 3.1260215615415476
Validation loss: 2.768187757295081

Epoch: 5| Step: 3
Training loss: 3.3660521396490486
Validation loss: 2.768110164106848

Epoch: 5| Step: 4
Training loss: 2.5627341744955126
Validation loss: 2.7668908570130095

Epoch: 5| Step: 5
Training loss: 3.2476206652958624
Validation loss: 2.768488097252264

Epoch: 5| Step: 6
Training loss: 3.3919672264998986
Validation loss: 2.769046938208571

Epoch: 5| Step: 7
Training loss: 2.8200248930894287
Validation loss: 2.7677019145579194

Epoch: 5| Step: 8
Training loss: 3.2383425054520076
Validation loss: 2.7674984239738887

Epoch: 5| Step: 9
Training loss: 2.6011269694558297
Validation loss: 2.7665955393405772

Epoch: 5| Step: 10
Training loss: 3.5656252086214746
Validation loss: 2.76347919393792

Epoch: 89| Step: 0
Training loss: 2.7167215782497895
Validation loss: 2.7640829123495934

Epoch: 5| Step: 1
Training loss: 3.1801271626700642
Validation loss: 2.7778036719998704

Epoch: 5| Step: 2
Training loss: 2.8502408243792328
Validation loss: 2.7901705622169874

Epoch: 5| Step: 3
Training loss: 3.377507443931616
Validation loss: 2.8082269455325477

Epoch: 5| Step: 4
Training loss: 3.71873256134304
Validation loss: 2.7721022788088074

Epoch: 5| Step: 5
Training loss: 2.593432487448934
Validation loss: 2.7639878362602253

Epoch: 5| Step: 6
Training loss: 3.3300371721272155
Validation loss: 2.7612353676666124

Epoch: 5| Step: 7
Training loss: 3.0592297590651802
Validation loss: 2.7648910142661927

Epoch: 5| Step: 8
Training loss: 3.3630417795027694
Validation loss: 2.7610008069018668

Epoch: 5| Step: 9
Training loss: 2.756007914389221
Validation loss: 2.7624400014899204

Epoch: 5| Step: 10
Training loss: 2.874334341194194
Validation loss: 2.767476399259524

Epoch: 90| Step: 0
Training loss: 3.551885754114048
Validation loss: 2.7683525968204927

Epoch: 5| Step: 1
Training loss: 3.1812618772513575
Validation loss: 2.7589610692970243

Epoch: 5| Step: 2
Training loss: 3.2526700715880317
Validation loss: 2.764327421367218

Epoch: 5| Step: 3
Training loss: 2.9544125933885157
Validation loss: 2.76195996158754

Epoch: 5| Step: 4
Training loss: 2.90774727265974
Validation loss: 2.771760366501647

Epoch: 5| Step: 5
Training loss: 2.7469197275037662
Validation loss: 2.7757340148976266

Epoch: 5| Step: 6
Training loss: 2.4727405214337255
Validation loss: 2.7772545630078023

Epoch: 5| Step: 7
Training loss: 2.9048192594048894
Validation loss: 2.76757930048959

Epoch: 5| Step: 8
Training loss: 3.5363806527341928
Validation loss: 2.7665261441850424

Epoch: 5| Step: 9
Training loss: 2.8773225442238024
Validation loss: 2.759310342811152

Epoch: 5| Step: 10
Training loss: 3.433124462428347
Validation loss: 2.753530835626108

Epoch: 91| Step: 0
Training loss: 2.964172850280552
Validation loss: 2.7562282692080937

Epoch: 5| Step: 1
Training loss: 2.311183864210507
Validation loss: 2.7567770230973525

Epoch: 5| Step: 2
Training loss: 2.9026010227283314
Validation loss: 2.7592655938799115

Epoch: 5| Step: 3
Training loss: 3.4757590747828107
Validation loss: 2.7595256485716146

Epoch: 5| Step: 4
Training loss: 3.315495126609344
Validation loss: 2.7602584846172307

Epoch: 5| Step: 5
Training loss: 2.216435044121431
Validation loss: 2.7555900421130826

Epoch: 5| Step: 6
Training loss: 3.5466809996934354
Validation loss: 2.7573751275724043

Epoch: 5| Step: 7
Training loss: 3.381484125461344
Validation loss: 2.7546302059685384

Epoch: 5| Step: 8
Training loss: 2.646266261047654
Validation loss: 2.7499103885790728

Epoch: 5| Step: 9
Training loss: 3.3017149197247195
Validation loss: 2.750800034090337

Epoch: 5| Step: 10
Training loss: 3.5880612668661547
Validation loss: 2.7519127131389416

Epoch: 92| Step: 0
Training loss: 3.3403599747246084
Validation loss: 2.752156876328191

Epoch: 5| Step: 1
Training loss: 3.041415443671084
Validation loss: 2.7502213507398054

Epoch: 5| Step: 2
Training loss: 2.6836116962304772
Validation loss: 2.751245999457521

Epoch: 5| Step: 3
Training loss: 3.0859977619709396
Validation loss: 2.751310317875471

Epoch: 5| Step: 4
Training loss: 3.134588256761757
Validation loss: 2.7488475549424365

Epoch: 5| Step: 5
Training loss: 2.614914912340227
Validation loss: 2.752787775771152

Epoch: 5| Step: 6
Training loss: 3.6115348925900617
Validation loss: 2.7517777622884765

Epoch: 5| Step: 7
Training loss: 2.698362443738257
Validation loss: 2.756244997480359

Epoch: 5| Step: 8
Training loss: 3.1516657103630026
Validation loss: 2.766838732047772

Epoch: 5| Step: 9
Training loss: 3.171738645131408
Validation loss: 2.7683233445105317

Epoch: 5| Step: 10
Training loss: 3.1433905576133663
Validation loss: 2.789439662241313

Epoch: 93| Step: 0
Training loss: 3.5061925873161313
Validation loss: 2.79404041426795

Epoch: 5| Step: 1
Training loss: 3.451339881663318
Validation loss: 2.781080122107237

Epoch: 5| Step: 2
Training loss: 2.731301722265956
Validation loss: 2.75903683006366

Epoch: 5| Step: 3
Training loss: 3.157876077396076
Validation loss: 2.7539133323590583

Epoch: 5| Step: 4
Training loss: 3.376356911744284
Validation loss: 2.7493400872652454

Epoch: 5| Step: 5
Training loss: 2.7996479971196164
Validation loss: 2.7436868874545097

Epoch: 5| Step: 6
Training loss: 2.9074225572684944
Validation loss: 2.7454693408666744

Epoch: 5| Step: 7
Training loss: 2.552495453444718
Validation loss: 2.741709392601307

Epoch: 5| Step: 8
Training loss: 3.126198500644143
Validation loss: 2.7464192776786214

Epoch: 5| Step: 9
Training loss: 3.1647802221758297
Validation loss: 2.7448134898456704

Epoch: 5| Step: 10
Training loss: 2.7998714485631306
Validation loss: 2.7443523828737404

Epoch: 94| Step: 0
Training loss: 3.153379135551921
Validation loss: 2.7443710041846807

Epoch: 5| Step: 1
Training loss: 2.9897923058678444
Validation loss: 2.7457273857925055

Epoch: 5| Step: 2
Training loss: 2.65972601146334
Validation loss: 2.743112439005856

Epoch: 5| Step: 3
Training loss: 2.8116190908311656
Validation loss: 2.7454258314454734

Epoch: 5| Step: 4
Training loss: 2.656810925666102
Validation loss: 2.7538385216943047

Epoch: 5| Step: 5
Training loss: 3.4127189035036354
Validation loss: 2.780504666735506

Epoch: 5| Step: 6
Training loss: 2.7393807069134564
Validation loss: 2.784841202355248

Epoch: 5| Step: 7
Training loss: 3.254238299478088
Validation loss: 2.7736434682104383

Epoch: 5| Step: 8
Training loss: 3.6628067044414947
Validation loss: 2.756710310630648

Epoch: 5| Step: 9
Training loss: 3.26727939295874
Validation loss: 2.741628609470543

Epoch: 5| Step: 10
Training loss: 2.943614844845936
Validation loss: 2.736289965171792

Epoch: 95| Step: 0
Training loss: 2.774725816257836
Validation loss: 2.738028116492

Epoch: 5| Step: 1
Training loss: 2.6888509504235727
Validation loss: 2.742743451049302

Epoch: 5| Step: 2
Training loss: 3.5851323838311364
Validation loss: 2.7450630502303426

Epoch: 5| Step: 3
Training loss: 3.1663660776793354
Validation loss: 2.7435110103892684

Epoch: 5| Step: 4
Training loss: 3.8878711928000134
Validation loss: 2.7469545366980888

Epoch: 5| Step: 5
Training loss: 3.358738896671366
Validation loss: 2.7476593368659277

Epoch: 5| Step: 6
Training loss: 2.5810835075717877
Validation loss: 2.7453878550336124

Epoch: 5| Step: 7
Training loss: 2.9838083737899495
Validation loss: 2.7450644632351486

Epoch: 5| Step: 8
Training loss: 2.9189511934325165
Validation loss: 2.7421925474604865

Epoch: 5| Step: 9
Training loss: 2.8692547987728036
Validation loss: 2.742743635185076

Epoch: 5| Step: 10
Training loss: 2.8124406596387517
Validation loss: 2.737943808986555

Epoch: 96| Step: 0
Training loss: 2.6874707242568787
Validation loss: 2.7341844352263345

Epoch: 5| Step: 1
Training loss: 3.2002111067278847
Validation loss: 2.730777533419277

Epoch: 5| Step: 2
Training loss: 3.1777529818524086
Validation loss: 2.7326864853152464

Epoch: 5| Step: 3
Training loss: 2.7103677200327283
Validation loss: 2.7350977426199514

Epoch: 5| Step: 4
Training loss: 2.9337447492034823
Validation loss: 2.73820425959305

Epoch: 5| Step: 5
Training loss: 2.8508985608699087
Validation loss: 2.7387583130683426

Epoch: 5| Step: 6
Training loss: 3.326672304132102
Validation loss: 2.7359935033608704

Epoch: 5| Step: 7
Training loss: 2.3689369309074455
Validation loss: 2.7348321976030285

Epoch: 5| Step: 8
Training loss: 4.126148410807325
Validation loss: 2.7393713746333908

Epoch: 5| Step: 9
Training loss: 3.052161848253957
Validation loss: 2.736221976961507

Epoch: 5| Step: 10
Training loss: 2.867787477671566
Validation loss: 2.732857183814161

Epoch: 97| Step: 0
Training loss: 3.043341049513239
Validation loss: 2.7303170681610944

Epoch: 5| Step: 1
Training loss: 3.5551399362226923
Validation loss: 2.725397875488428

Epoch: 5| Step: 2
Training loss: 2.9847204198211044
Validation loss: 2.7258576377824206

Epoch: 5| Step: 3
Training loss: 2.3745407865181805
Validation loss: 2.7275291154166785

Epoch: 5| Step: 4
Training loss: 3.6741123606653545
Validation loss: 2.726620723197797

Epoch: 5| Step: 5
Training loss: 2.8300818317565444
Validation loss: 2.724249722063545

Epoch: 5| Step: 6
Training loss: 2.9718348487363935
Validation loss: 2.720120087718174

Epoch: 5| Step: 7
Training loss: 3.0058412904548573
Validation loss: 2.7246449509693456

Epoch: 5| Step: 8
Training loss: 3.223902457908035
Validation loss: 2.7226668617596217

Epoch: 5| Step: 9
Training loss: 2.9636823266587817
Validation loss: 2.722078161094964

Epoch: 5| Step: 10
Training loss: 2.7126679188308334
Validation loss: 2.7218515170776314

Epoch: 98| Step: 0
Training loss: 2.8265731516100177
Validation loss: 2.7226245142832504

Epoch: 5| Step: 1
Training loss: 3.123552215896922
Validation loss: 2.722930488093462

Epoch: 5| Step: 2
Training loss: 3.4960518775861904
Validation loss: 2.7261928132957562

Epoch: 5| Step: 3
Training loss: 2.8174484800622666
Validation loss: 2.7249716523280183

Epoch: 5| Step: 4
Training loss: 2.848562004980025
Validation loss: 2.7242214077648716

Epoch: 5| Step: 5
Training loss: 3.4307213270021455
Validation loss: 2.722842727527072

Epoch: 5| Step: 6
Training loss: 3.2600947374491365
Validation loss: 2.7195597720256077

Epoch: 5| Step: 7
Training loss: 2.777346239477831
Validation loss: 2.7214329321856807

Epoch: 5| Step: 8
Training loss: 2.4358274149901664
Validation loss: 2.716856679481301

Epoch: 5| Step: 9
Training loss: 3.070782574493351
Validation loss: 2.7200465389326305

Epoch: 5| Step: 10
Training loss: 3.4395364451240265
Validation loss: 2.7217995326823567

Epoch: 99| Step: 0
Training loss: 3.148036429556749
Validation loss: 2.72495977382015

Epoch: 5| Step: 1
Training loss: 2.9758988889724893
Validation loss: 2.736295893893007

Epoch: 5| Step: 2
Training loss: 2.987585926815324
Validation loss: 2.722799831981712

Epoch: 5| Step: 3
Training loss: 2.9954772872050994
Validation loss: 2.715666505016452

Epoch: 5| Step: 4
Training loss: 3.502257028085101
Validation loss: 2.7172223982069195

Epoch: 5| Step: 5
Training loss: 2.6761779936538304
Validation loss: 2.7176394355468894

Epoch: 5| Step: 6
Training loss: 2.707481445925216
Validation loss: 2.715393744420166

Epoch: 5| Step: 7
Training loss: 2.796012447056604
Validation loss: 2.712863904475798

Epoch: 5| Step: 8
Training loss: 3.1996350139847647
Validation loss: 2.7115136149328714

Epoch: 5| Step: 9
Training loss: 2.780931604569669
Validation loss: 2.712648015742263

Epoch: 5| Step: 10
Training loss: 3.6861932023032966
Validation loss: 2.7120925992435483

Epoch: 100| Step: 0
Training loss: 2.7693094829229596
Validation loss: 2.7105477636186586

Epoch: 5| Step: 1
Training loss: 2.897911990664942
Validation loss: 2.7162025708518436

Epoch: 5| Step: 2
Training loss: 3.4428624721230334
Validation loss: 2.711448423406835

Epoch: 5| Step: 3
Training loss: 3.3482608494018513
Validation loss: 2.7100032321741288

Epoch: 5| Step: 4
Training loss: 2.7689247059006536
Validation loss: 2.713282710584734

Epoch: 5| Step: 5
Training loss: 2.6914827864661794
Validation loss: 2.7142486488970543

Epoch: 5| Step: 6
Training loss: 3.1491030611948627
Validation loss: 2.7230671688928236

Epoch: 5| Step: 7
Training loss: 2.8822639584401437
Validation loss: 2.7319519313902187

Epoch: 5| Step: 8
Training loss: 3.408381783685891
Validation loss: 2.7458589498642145

Epoch: 5| Step: 9
Training loss: 2.8312160397276007
Validation loss: 2.7264956128698383

Epoch: 5| Step: 10
Training loss: 3.2616517933808704
Validation loss: 2.7283436757751

Testing loss: 2.945692294789876
