Epoch: 1| Step: 0
Training loss: 4.9083404541015625
Validation loss: 5.1670876882409535

Epoch: 6| Step: 1
Training loss: 4.851173400878906
Validation loss: 5.149525457812894

Epoch: 6| Step: 2
Training loss: 4.856985092163086
Validation loss: 5.131348743233629

Epoch: 6| Step: 3
Training loss: 3.715770959854126
Validation loss: 5.111917229108913

Epoch: 6| Step: 4
Training loss: 5.247923851013184
Validation loss: 5.0906782304087

Epoch: 6| Step: 5
Training loss: 3.730921983718872
Validation loss: 5.067042422550981

Epoch: 6| Step: 6
Training loss: 4.5139594078063965
Validation loss: 5.040615061277984

Epoch: 6| Step: 7
Training loss: 4.436600685119629
Validation loss: 5.011022654912805

Epoch: 6| Step: 8
Training loss: 5.41249942779541
Validation loss: 4.9779933806388605

Epoch: 6| Step: 9
Training loss: 6.093162536621094
Validation loss: 4.940737819158903

Epoch: 6| Step: 10
Training loss: 4.933499336242676
Validation loss: 4.9016707994604625

Epoch: 6| Step: 11
Training loss: 4.4162678718566895
Validation loss: 4.857107839276714

Epoch: 6| Step: 12
Training loss: 3.8123464584350586
Validation loss: 4.807338073689451

Epoch: 6| Step: 13
Training loss: 7.33329439163208
Validation loss: 4.756430902788716

Epoch: 2| Step: 0
Training loss: 5.31394624710083
Validation loss: 4.701515269535844

Epoch: 6| Step: 1
Training loss: 4.35308837890625
Validation loss: 4.644149370090936

Epoch: 6| Step: 2
Training loss: 3.5118353366851807
Validation loss: 4.585172458361554

Epoch: 6| Step: 3
Training loss: 3.5464303493499756
Validation loss: 4.524444995387908

Epoch: 6| Step: 4
Training loss: 4.633444786071777
Validation loss: 4.465335399873795

Epoch: 6| Step: 5
Training loss: 4.874553680419922
Validation loss: 4.408826556257022

Epoch: 6| Step: 6
Training loss: 3.2795979976654053
Validation loss: 4.355882352398288

Epoch: 6| Step: 7
Training loss: 4.7420525550842285
Validation loss: 4.306907623044906

Epoch: 6| Step: 8
Training loss: 4.578760147094727
Validation loss: 4.26384989933301

Epoch: 6| Step: 9
Training loss: 5.933372497558594
Validation loss: 4.2239791039497625

Epoch: 6| Step: 10
Training loss: 3.7818684577941895
Validation loss: 4.185066335944719

Epoch: 6| Step: 11
Training loss: 2.28847599029541
Validation loss: 4.150540562086208

Epoch: 6| Step: 12
Training loss: 3.6864094734191895
Validation loss: 4.115944872620285

Epoch: 6| Step: 13
Training loss: 3.719653606414795
Validation loss: 4.085026669245894

Epoch: 3| Step: 0
Training loss: 4.097095489501953
Validation loss: 4.0589636243799685

Epoch: 6| Step: 1
Training loss: 3.0179073810577393
Validation loss: 4.033336485585859

Epoch: 6| Step: 2
Training loss: 5.0208892822265625
Validation loss: 4.006122491692984

Epoch: 6| Step: 3
Training loss: 3.389982223510742
Validation loss: 3.977947496598767

Epoch: 6| Step: 4
Training loss: 3.6449875831604004
Validation loss: 3.949349731527349

Epoch: 6| Step: 5
Training loss: 4.331366539001465
Validation loss: 3.9199713789006716

Epoch: 6| Step: 6
Training loss: 3.55765700340271
Validation loss: 3.8842307931633404

Epoch: 6| Step: 7
Training loss: 4.278927803039551
Validation loss: 3.8485831470899683

Epoch: 6| Step: 8
Training loss: 2.8688924312591553
Validation loss: 3.8214197030631443

Epoch: 6| Step: 9
Training loss: 4.59749698638916
Validation loss: 3.79297778683324

Epoch: 6| Step: 10
Training loss: 3.4743711948394775
Validation loss: 3.7599596849051853

Epoch: 6| Step: 11
Training loss: 2.34033203125
Validation loss: 3.733140237869755

Epoch: 6| Step: 12
Training loss: 4.680844306945801
Validation loss: 3.709031807479038

Epoch: 6| Step: 13
Training loss: 2.830228805541992
Validation loss: 3.6858215844759377

Epoch: 4| Step: 0
Training loss: 3.8024635314941406
Validation loss: 3.6608280597194547

Epoch: 6| Step: 1
Training loss: 3.7198867797851562
Validation loss: 3.63828303224297

Epoch: 6| Step: 2
Training loss: 2.9648618698120117
Validation loss: 3.6225449654363815

Epoch: 6| Step: 3
Training loss: 3.3715081214904785
Validation loss: 3.6082122351533625

Epoch: 6| Step: 4
Training loss: 3.804802656173706
Validation loss: 3.597233098040345

Epoch: 6| Step: 5
Training loss: 4.069005012512207
Validation loss: 3.587728992585213

Epoch: 6| Step: 6
Training loss: 3.3612618446350098
Validation loss: 3.572168832184166

Epoch: 6| Step: 7
Training loss: 2.699122190475464
Validation loss: 3.559105726980394

Epoch: 6| Step: 8
Training loss: 3.964198589324951
Validation loss: 3.5447567278339016

Epoch: 6| Step: 9
Training loss: 3.2619144916534424
Validation loss: 3.532786492378481

Epoch: 6| Step: 10
Training loss: 2.821720838546753
Validation loss: 3.519347411330028

Epoch: 6| Step: 11
Training loss: 4.637883186340332
Validation loss: 3.506820899184032

Epoch: 6| Step: 12
Training loss: 2.6678712368011475
Validation loss: 3.4959477916840584

Epoch: 6| Step: 13
Training loss: 4.0690717697143555
Validation loss: 3.483327788691367

Epoch: 5| Step: 0
Training loss: 3.3601958751678467
Validation loss: 3.4699990800631944

Epoch: 6| Step: 1
Training loss: 3.4124183654785156
Validation loss: 3.4569435427265782

Epoch: 6| Step: 2
Training loss: 3.6069836616516113
Validation loss: 3.4415572894516813

Epoch: 6| Step: 3
Training loss: 4.525298595428467
Validation loss: 3.4244478261598976

Epoch: 6| Step: 4
Training loss: 3.215782642364502
Validation loss: 3.408866774651312

Epoch: 6| Step: 5
Training loss: 3.199718952178955
Validation loss: 3.391285711719144

Epoch: 6| Step: 6
Training loss: 3.4110684394836426
Validation loss: 3.373695583753688

Epoch: 6| Step: 7
Training loss: 3.040992259979248
Validation loss: 3.3544441064198813

Epoch: 6| Step: 8
Training loss: 3.1684396266937256
Validation loss: 3.3416256725147204

Epoch: 6| Step: 9
Training loss: 3.056259870529175
Validation loss: 3.33125259799342

Epoch: 6| Step: 10
Training loss: 2.4623360633850098
Validation loss: 3.315363804499308

Epoch: 6| Step: 11
Training loss: 3.6918458938598633
Validation loss: 3.295620072272516

Epoch: 6| Step: 12
Training loss: 3.5323984622955322
Validation loss: 3.2826013103608163

Epoch: 6| Step: 13
Training loss: 2.6503677368164062
Validation loss: 3.263356611292849

Epoch: 6| Step: 0
Training loss: 2.724195957183838
Validation loss: 3.24703388573021

Epoch: 6| Step: 1
Training loss: 3.522674560546875
Validation loss: 3.234222037817842

Epoch: 6| Step: 2
Training loss: 3.725755214691162
Validation loss: 3.2275225987998386

Epoch: 6| Step: 3
Training loss: 3.0129153728485107
Validation loss: 3.221895166622695

Epoch: 6| Step: 4
Training loss: 2.910094738006592
Validation loss: 3.218096210110572

Epoch: 6| Step: 5
Training loss: 3.5569276809692383
Validation loss: 3.21141815698275

Epoch: 6| Step: 6
Training loss: 3.625302791595459
Validation loss: 3.209195952261648

Epoch: 6| Step: 7
Training loss: 3.483348846435547
Validation loss: 3.188083899918423

Epoch: 6| Step: 8
Training loss: 2.912142753601074
Validation loss: 3.175122176447222

Epoch: 6| Step: 9
Training loss: 2.244749069213867
Validation loss: 3.1678595568544123

Epoch: 6| Step: 10
Training loss: 3.672544479370117
Validation loss: 3.15732939012589

Epoch: 6| Step: 11
Training loss: 2.8772130012512207
Validation loss: 3.136988519340433

Epoch: 6| Step: 12
Training loss: 3.0341196060180664
Validation loss: 3.1315676755802606

Epoch: 6| Step: 13
Training loss: 3.5061283111572266
Validation loss: 3.1437126436541156

Epoch: 7| Step: 0
Training loss: 3.4803409576416016
Validation loss: 3.1476500059968684

Epoch: 6| Step: 1
Training loss: 3.737247943878174
Validation loss: 3.138624711703229

Epoch: 6| Step: 2
Training loss: 3.0008649826049805
Validation loss: 3.126645093323082

Epoch: 6| Step: 3
Training loss: 2.7918732166290283
Validation loss: 3.116569326769921

Epoch: 6| Step: 4
Training loss: 3.2531473636627197
Validation loss: 3.110264350009221

Epoch: 6| Step: 5
Training loss: 3.2666802406311035
Validation loss: 3.108009551161079

Epoch: 6| Step: 6
Training loss: 3.1672420501708984
Validation loss: 3.1000024144367506

Epoch: 6| Step: 7
Training loss: 3.128052234649658
Validation loss: 3.088767456751998

Epoch: 6| Step: 8
Training loss: 3.0049593448638916
Validation loss: 3.0832667325132634

Epoch: 6| Step: 9
Training loss: 4.031364440917969
Validation loss: 3.07914739014

Epoch: 6| Step: 10
Training loss: 3.0659656524658203
Validation loss: 3.0692463459507113

Epoch: 6| Step: 11
Training loss: 2.2181668281555176
Validation loss: 3.062159481868949

Epoch: 6| Step: 12
Training loss: 2.9076051712036133
Validation loss: 3.0606494129344983

Epoch: 6| Step: 13
Training loss: 2.399259328842163
Validation loss: 3.05064127009402

Epoch: 8| Step: 0
Training loss: 4.36200475692749
Validation loss: 3.047623836865989

Epoch: 6| Step: 1
Training loss: 2.7209272384643555
Validation loss: 3.0385589317608903

Epoch: 6| Step: 2
Training loss: 3.3393282890319824
Validation loss: 3.0292457765148533

Epoch: 6| Step: 3
Training loss: 3.2406435012817383
Validation loss: 3.0243776895666636

Epoch: 6| Step: 4
Training loss: 1.9830397367477417
Validation loss: 3.0186644472101682

Epoch: 6| Step: 5
Training loss: 3.490072250366211
Validation loss: 3.0164651332363004

Epoch: 6| Step: 6
Training loss: 3.543975830078125
Validation loss: 3.0127479953150593

Epoch: 6| Step: 7
Training loss: 2.7395076751708984
Validation loss: 3.009675315631333

Epoch: 6| Step: 8
Training loss: 2.262338876724243
Validation loss: 3.0052991733756116

Epoch: 6| Step: 9
Training loss: 3.2838945388793945
Validation loss: 3.0016955355162263

Epoch: 6| Step: 10
Training loss: 3.6479012966156006
Validation loss: 2.9970932519564064

Epoch: 6| Step: 11
Training loss: 2.699634075164795
Validation loss: 2.9895164171854653

Epoch: 6| Step: 12
Training loss: 2.8739073276519775
Validation loss: 2.9868575321730746

Epoch: 6| Step: 13
Training loss: 2.711230754852295
Validation loss: 2.9816227036137737

Epoch: 9| Step: 0
Training loss: 2.728083610534668
Validation loss: 3.0569885469252065

Epoch: 6| Step: 1
Training loss: 2.988407850265503
Validation loss: 3.0706754704957366

Epoch: 6| Step: 2
Training loss: 2.9634013175964355
Validation loss: 3.0568213360283965

Epoch: 6| Step: 3
Training loss: 2.3138930797576904
Validation loss: 3.059601419715471

Epoch: 6| Step: 4
Training loss: 2.5435492992401123
Validation loss: 3.0746054649353027

Epoch: 6| Step: 5
Training loss: 3.4249792098999023
Validation loss: 3.0763656093228247

Epoch: 6| Step: 6
Training loss: 3.385672092437744
Validation loss: 3.0687235632250385

Epoch: 6| Step: 7
Training loss: 4.387201309204102
Validation loss: 3.0503914228049656

Epoch: 6| Step: 8
Training loss: 3.338639736175537
Validation loss: 3.0377478266275055

Epoch: 6| Step: 9
Training loss: 2.7980103492736816
Validation loss: 3.0317392964516916

Epoch: 6| Step: 10
Training loss: 2.887479782104492
Validation loss: 3.0281148238848616

Epoch: 6| Step: 11
Training loss: 3.1943886280059814
Validation loss: 3.025214772070608

Epoch: 6| Step: 12
Training loss: 2.8937432765960693
Validation loss: 3.0219962904530187

Epoch: 6| Step: 13
Training loss: 3.797966957092285
Validation loss: 3.016242878411406

Epoch: 10| Step: 0
Training loss: 3.46885347366333
Validation loss: 3.0142224270810365

Epoch: 6| Step: 1
Training loss: 3.4524686336517334
Validation loss: 3.0107759480835288

Epoch: 6| Step: 2
Training loss: 2.8782081604003906
Validation loss: 3.005964466320571

Epoch: 6| Step: 3
Training loss: 2.6072990894317627
Validation loss: 3.0045640109687723

Epoch: 6| Step: 4
Training loss: 3.644319772720337
Validation loss: 3.0026837036173832

Epoch: 6| Step: 5
Training loss: 2.7842164039611816
Validation loss: 2.9972600116524646

Epoch: 6| Step: 6
Training loss: 2.6632790565490723
Validation loss: 2.99162035347313

Epoch: 6| Step: 7
Training loss: 3.4492368698120117
Validation loss: 2.986620041631883

Epoch: 6| Step: 8
Training loss: 2.924060344696045
Validation loss: 2.984284467594598

Epoch: 6| Step: 9
Training loss: 2.8848466873168945
Validation loss: 2.984222868437408

Epoch: 6| Step: 10
Training loss: 4.001857757568359
Validation loss: 2.9785264589453257

Epoch: 6| Step: 11
Training loss: 2.931421995162964
Validation loss: 2.975521908011488

Epoch: 6| Step: 12
Training loss: 2.5343613624572754
Validation loss: 2.972060829080561

Epoch: 6| Step: 13
Training loss: 2.329920768737793
Validation loss: 2.969755344493415

Epoch: 11| Step: 0
Training loss: 3.679324150085449
Validation loss: 2.9671084470646356

Epoch: 6| Step: 1
Training loss: 2.847820281982422
Validation loss: 2.968093882324875

Epoch: 6| Step: 2
Training loss: 2.1964523792266846
Validation loss: 2.966795754689042

Epoch: 6| Step: 3
Training loss: 3.839141607284546
Validation loss: 2.964351169524654

Epoch: 6| Step: 4
Training loss: 3.308236598968506
Validation loss: 2.961382560832526

Epoch: 6| Step: 5
Training loss: 3.0260660648345947
Validation loss: 2.9576086946713027

Epoch: 6| Step: 6
Training loss: 2.605849266052246
Validation loss: 2.956954138253325

Epoch: 6| Step: 7
Training loss: 4.552924156188965
Validation loss: 2.952873060780187

Epoch: 6| Step: 8
Training loss: 2.7292215824127197
Validation loss: 2.952399028244839

Epoch: 6| Step: 9
Training loss: 2.9952802658081055
Validation loss: 2.949103832244873

Epoch: 6| Step: 10
Training loss: 2.915985584259033
Validation loss: 2.9440744359006166

Epoch: 6| Step: 11
Training loss: 3.3722872734069824
Validation loss: 2.9422327805590887

Epoch: 6| Step: 12
Training loss: 2.2176706790924072
Validation loss: 2.939590697647423

Epoch: 6| Step: 13
Training loss: 1.6742899417877197
Validation loss: 2.935078808056411

Epoch: 12| Step: 0
Training loss: 3.5819222927093506
Validation loss: 2.9393030674226823

Epoch: 6| Step: 1
Training loss: 3.6765341758728027
Validation loss: 2.9332846749213433

Epoch: 6| Step: 2
Training loss: 3.7295420169830322
Validation loss: 2.934655850933444

Epoch: 6| Step: 3
Training loss: 2.932157516479492
Validation loss: 2.9287006778101765

Epoch: 6| Step: 4
Training loss: 2.1127614974975586
Validation loss: 2.9260136696600143

Epoch: 6| Step: 5
Training loss: 3.5178256034851074
Validation loss: 2.9261783810072046

Epoch: 6| Step: 6
Training loss: 3.1727294921875
Validation loss: 2.924608463882118

Epoch: 6| Step: 7
Training loss: 2.007905960083008
Validation loss: 2.920613734952865

Epoch: 6| Step: 8
Training loss: 2.577077865600586
Validation loss: 2.915813474244969

Epoch: 6| Step: 9
Training loss: 2.9290690422058105
Validation loss: 2.902287344778738

Epoch: 6| Step: 10
Training loss: 3.7023534774780273
Validation loss: 2.8876161190771286

Epoch: 6| Step: 11
Training loss: 2.248947858810425
Validation loss: 2.863288043647684

Epoch: 6| Step: 12
Training loss: 2.4488062858581543
Validation loss: 2.8596427902098625

Epoch: 6| Step: 13
Training loss: 3.875051736831665
Validation loss: 2.858733853986186

Epoch: 13| Step: 0
Training loss: 2.6815435886383057
Validation loss: 2.8549095148681314

Epoch: 6| Step: 1
Training loss: 1.9964483976364136
Validation loss: 2.8511057874207855

Epoch: 6| Step: 2
Training loss: 2.7879772186279297
Validation loss: 2.8521875822415916

Epoch: 6| Step: 3
Training loss: 2.17101788520813
Validation loss: 2.854954283724549

Epoch: 6| Step: 4
Training loss: 3.7053334712982178
Validation loss: 2.8559690777973463

Epoch: 6| Step: 5
Training loss: 3.9475932121276855
Validation loss: 2.847096025302846

Epoch: 6| Step: 6
Training loss: 2.349395751953125
Validation loss: 2.840922829925373

Epoch: 6| Step: 7
Training loss: 2.3499553203582764
Validation loss: 2.842538061962333

Epoch: 6| Step: 8
Training loss: 3.294481039047241
Validation loss: 2.8464914880773073

Epoch: 6| Step: 9
Training loss: 3.7944698333740234
Validation loss: 2.8410544395446777

Epoch: 6| Step: 10
Training loss: 3.1702184677124023
Validation loss: 2.8323559530319704

Epoch: 6| Step: 11
Training loss: 2.8152999877929688
Validation loss: 2.8304302512958484

Epoch: 6| Step: 12
Training loss: 3.348453998565674
Validation loss: 2.8266191456907537

Epoch: 6| Step: 13
Training loss: 3.1488430500030518
Validation loss: 2.825481096903483

Epoch: 14| Step: 0
Training loss: 3.17201828956604
Validation loss: 2.8248702710674656

Epoch: 6| Step: 1
Training loss: 3.008298397064209
Validation loss: 2.824069079532418

Epoch: 6| Step: 2
Training loss: 2.3518104553222656
Validation loss: 2.8212816894695325

Epoch: 6| Step: 3
Training loss: 2.67503023147583
Validation loss: 2.8174878089658675

Epoch: 6| Step: 4
Training loss: 3.2859842777252197
Validation loss: 2.814090444195655

Epoch: 6| Step: 5
Training loss: 2.5835371017456055
Validation loss: 2.8100770647807787

Epoch: 6| Step: 6
Training loss: 3.080313205718994
Validation loss: 2.806338930642733

Epoch: 6| Step: 7
Training loss: 3.1554012298583984
Validation loss: 2.802121041923441

Epoch: 6| Step: 8
Training loss: 3.0691561698913574
Validation loss: 2.796435515085856

Epoch: 6| Step: 9
Training loss: 3.113132953643799
Validation loss: 2.793889066224457

Epoch: 6| Step: 10
Training loss: 2.7758662700653076
Validation loss: 2.7901180354497765

Epoch: 6| Step: 11
Training loss: 3.0993192195892334
Validation loss: 2.786998179651076

Epoch: 6| Step: 12
Training loss: 2.769912004470825
Validation loss: 2.7813322364643054

Epoch: 6| Step: 13
Training loss: 2.96683931350708
Validation loss: 2.7809899750576226

Epoch: 15| Step: 0
Training loss: 3.034332752227783
Validation loss: 2.7839507902822187

Epoch: 6| Step: 1
Training loss: 2.5217905044555664
Validation loss: 2.777983439865933

Epoch: 6| Step: 2
Training loss: 2.326113224029541
Validation loss: 2.772640448744579

Epoch: 6| Step: 3
Training loss: 2.290241241455078
Validation loss: 2.7731077235232116

Epoch: 6| Step: 4
Training loss: 2.967371940612793
Validation loss: 2.7725341089310183

Epoch: 6| Step: 5
Training loss: 3.056797981262207
Validation loss: 2.771402100081085

Epoch: 6| Step: 6
Training loss: 2.402420997619629
Validation loss: 2.768550859984531

Epoch: 6| Step: 7
Training loss: 3.436873435974121
Validation loss: 2.7628968633631223

Epoch: 6| Step: 8
Training loss: 3.6271324157714844
Validation loss: 2.7610940805045505

Epoch: 6| Step: 9
Training loss: 3.591491460800171
Validation loss: 2.7577239954343407

Epoch: 6| Step: 10
Training loss: 2.9355554580688477
Validation loss: 2.7569706260517077

Epoch: 6| Step: 11
Training loss: 3.129537582397461
Validation loss: 2.7572568719105055

Epoch: 6| Step: 12
Training loss: 2.9601526260375977
Validation loss: 2.7589149013642342

Epoch: 6| Step: 13
Training loss: 2.158108711242676
Validation loss: 2.7526994982073383

Epoch: 16| Step: 0
Training loss: 2.6457889080047607
Validation loss: 2.7538738327641643

Epoch: 6| Step: 1
Training loss: 3.439568281173706
Validation loss: 2.7575172865262596

Epoch: 6| Step: 2
Training loss: 3.733332633972168
Validation loss: 2.7632977270310923

Epoch: 6| Step: 3
Training loss: 2.7770016193389893
Validation loss: 2.764410908504199

Epoch: 6| Step: 4
Training loss: 2.932781457901001
Validation loss: 2.758540532922232

Epoch: 6| Step: 5
Training loss: 3.737509250640869
Validation loss: 2.7494794117507113

Epoch: 6| Step: 6
Training loss: 2.811476230621338
Validation loss: 2.7442213924982215

Epoch: 6| Step: 7
Training loss: 2.099864959716797
Validation loss: 2.7480404428256455

Epoch: 6| Step: 8
Training loss: 2.9144363403320312
Validation loss: 2.750757166134414

Epoch: 6| Step: 9
Training loss: 2.6513850688934326
Validation loss: 2.748954680658156

Epoch: 6| Step: 10
Training loss: 2.765821695327759
Validation loss: 2.746769315452986

Epoch: 6| Step: 11
Training loss: 2.7453432083129883
Validation loss: 2.742653141739548

Epoch: 6| Step: 12
Training loss: 2.5578694343566895
Validation loss: 2.740237861551264

Epoch: 6| Step: 13
Training loss: 2.795952320098877
Validation loss: 2.7382247576149563

Epoch: 17| Step: 0
Training loss: 2.7134456634521484
Validation loss: 2.74153918861061

Epoch: 6| Step: 1
Training loss: 3.335233688354492
Validation loss: 2.790436326816518

Epoch: 6| Step: 2
Training loss: 2.7392942905426025
Validation loss: 2.8075889182347122

Epoch: 6| Step: 3
Training loss: 2.092958927154541
Validation loss: 2.757025470015823

Epoch: 6| Step: 4
Training loss: 3.464723825454712
Validation loss: 2.7452783892231603

Epoch: 6| Step: 5
Training loss: 3.663651943206787
Validation loss: 2.749579393735496

Epoch: 6| Step: 6
Training loss: 2.083109140396118
Validation loss: 2.7499108006877284

Epoch: 6| Step: 7
Training loss: 3.168729782104492
Validation loss: 2.7599499994708645

Epoch: 6| Step: 8
Training loss: 2.629328727722168
Validation loss: 2.7620472626019548

Epoch: 6| Step: 9
Training loss: 3.0694284439086914
Validation loss: 2.755961605297622

Epoch: 6| Step: 10
Training loss: 3.256772994995117
Validation loss: 2.7549438656017347

Epoch: 6| Step: 11
Training loss: 2.264976739883423
Validation loss: 2.749449017227337

Epoch: 6| Step: 12
Training loss: 2.9833993911743164
Validation loss: 2.742924021136376

Epoch: 6| Step: 13
Training loss: 3.507329225540161
Validation loss: 2.7381326485705633

Epoch: 18| Step: 0
Training loss: 3.344731330871582
Validation loss: 2.7357460016845376

Epoch: 6| Step: 1
Training loss: 2.851773738861084
Validation loss: 2.7362145967380975

Epoch: 6| Step: 2
Training loss: 2.9100570678710938
Validation loss: 2.733994294238347

Epoch: 6| Step: 3
Training loss: 2.4213669300079346
Validation loss: 2.729975369668776

Epoch: 6| Step: 4
Training loss: 2.3054518699645996
Validation loss: 2.7312711361915833

Epoch: 6| Step: 5
Training loss: 2.8779423236846924
Validation loss: 2.7391311968526533

Epoch: 6| Step: 6
Training loss: 2.3363146781921387
Validation loss: 2.7775403017638833

Epoch: 6| Step: 7
Training loss: 3.9007551670074463
Validation loss: 2.843094825744629

Epoch: 6| Step: 8
Training loss: 2.670865297317505
Validation loss: 2.7749270367366012

Epoch: 6| Step: 9
Training loss: 2.7467775344848633
Validation loss: 2.72737866832364

Epoch: 6| Step: 10
Training loss: 3.6999897956848145
Validation loss: 2.7355554667852258

Epoch: 6| Step: 11
Training loss: 2.7323856353759766
Validation loss: 2.7359470500740954

Epoch: 6| Step: 12
Training loss: 2.5436863899230957
Validation loss: 2.7485106632273686

Epoch: 6| Step: 13
Training loss: 3.5420150756835938
Validation loss: 2.7696007502976285

Epoch: 19| Step: 0
Training loss: 2.6830921173095703
Validation loss: 2.781493863751811

Epoch: 6| Step: 1
Training loss: 2.997009038925171
Validation loss: 2.78981731143049

Epoch: 6| Step: 2
Training loss: 3.4847230911254883
Validation loss: 2.770326557979789

Epoch: 6| Step: 3
Training loss: 3.6954991817474365
Validation loss: 2.7332189724009526

Epoch: 6| Step: 4
Training loss: 3.0885539054870605
Validation loss: 2.7182207133180354

Epoch: 6| Step: 5
Training loss: 2.0174591541290283
Validation loss: 2.726617387546006

Epoch: 6| Step: 6
Training loss: 3.633981466293335
Validation loss: 2.7459176894157165

Epoch: 6| Step: 7
Training loss: 2.900432586669922
Validation loss: 2.754683397149527

Epoch: 6| Step: 8
Training loss: 2.2275547981262207
Validation loss: 2.7594143575237644

Epoch: 6| Step: 9
Training loss: 2.517306327819824
Validation loss: 2.8046651527445805

Epoch: 6| Step: 10
Training loss: 3.032827854156494
Validation loss: 2.8067247406128915

Epoch: 6| Step: 11
Training loss: 3.4832534790039062
Validation loss: 2.8025014349209365

Epoch: 6| Step: 12
Training loss: 2.638026237487793
Validation loss: 2.7810932179932952

Epoch: 6| Step: 13
Training loss: 2.0402097702026367
Validation loss: 2.7707854547808246

Epoch: 20| Step: 0
Training loss: 2.9916820526123047
Validation loss: 2.7659133480441187

Epoch: 6| Step: 1
Training loss: 2.8615617752075195
Validation loss: 2.756141616452125

Epoch: 6| Step: 2
Training loss: 2.3133902549743652
Validation loss: 2.7698433219745593

Epoch: 6| Step: 3
Training loss: 2.6013240814208984
Validation loss: 2.757543692024805

Epoch: 6| Step: 4
Training loss: 2.5272772312164307
Validation loss: 2.7234083119259087

Epoch: 6| Step: 5
Training loss: 3.51853084564209
Validation loss: 2.7098767167778424

Epoch: 6| Step: 6
Training loss: 3.087843179702759
Validation loss: 2.7194216225736882

Epoch: 6| Step: 7
Training loss: 2.5241546630859375
Validation loss: 2.7356189450910016

Epoch: 6| Step: 8
Training loss: 2.2868733406066895
Validation loss: 2.7491323435178368

Epoch: 6| Step: 9
Training loss: 3.9241583347320557
Validation loss: 2.759871793049638

Epoch: 6| Step: 10
Training loss: 2.805464267730713
Validation loss: 2.749146294850175

Epoch: 6| Step: 11
Training loss: 3.8438234329223633
Validation loss: 2.7297744443339687

Epoch: 6| Step: 12
Training loss: 2.598367214202881
Validation loss: 2.718638571359778

Epoch: 6| Step: 13
Training loss: 2.367816209793091
Validation loss: 2.7248236133206274

Epoch: 21| Step: 0
Training loss: 3.0823137760162354
Validation loss: 2.7163356350314234

Epoch: 6| Step: 1
Training loss: 2.5207056999206543
Validation loss: 2.706815424785819

Epoch: 6| Step: 2
Training loss: 3.0200085639953613
Validation loss: 2.707045817887911

Epoch: 6| Step: 3
Training loss: 2.511725664138794
Validation loss: 2.7141080082103772

Epoch: 6| Step: 4
Training loss: 2.6894726753234863
Validation loss: 2.721990595581711

Epoch: 6| Step: 5
Training loss: 2.333975315093994
Validation loss: 2.728707769865631

Epoch: 6| Step: 6
Training loss: 2.8774259090423584
Validation loss: 2.735281229019165

Epoch: 6| Step: 7
Training loss: 2.676799774169922
Validation loss: 2.714499355644308

Epoch: 6| Step: 8
Training loss: 2.5949385166168213
Validation loss: 2.712697216259536

Epoch: 6| Step: 9
Training loss: 3.3508505821228027
Validation loss: 2.7093180328287105

Epoch: 6| Step: 10
Training loss: 2.919628858566284
Validation loss: 2.7241722358170377

Epoch: 6| Step: 11
Training loss: 3.4330806732177734
Validation loss: 2.72952079003857

Epoch: 6| Step: 12
Training loss: 3.127612590789795
Validation loss: 2.7125247832267516

Epoch: 6| Step: 13
Training loss: 3.36661696434021
Validation loss: 2.6998498901244132

Epoch: 22| Step: 0
Training loss: 3.0188889503479004
Validation loss: 2.6963387996919694

Epoch: 6| Step: 1
Training loss: 3.212430953979492
Validation loss: 2.6963121609021257

Epoch: 6| Step: 2
Training loss: 3.3581912517547607
Validation loss: 2.696477472141225

Epoch: 6| Step: 3
Training loss: 3.374654769897461
Validation loss: 2.6989820336782806

Epoch: 6| Step: 4
Training loss: 2.573737621307373
Validation loss: 2.697022235521706

Epoch: 6| Step: 5
Training loss: 3.551978826522827
Validation loss: 2.6978715850460913

Epoch: 6| Step: 6
Training loss: 2.469179630279541
Validation loss: 2.6960436887638544

Epoch: 6| Step: 7
Training loss: 1.9645851850509644
Validation loss: 2.6988858945908083

Epoch: 6| Step: 8
Training loss: 2.4780843257904053
Validation loss: 2.6950479399773384

Epoch: 6| Step: 9
Training loss: 2.992504596710205
Validation loss: 2.6947941882635957

Epoch: 6| Step: 10
Training loss: 2.517393112182617
Validation loss: 2.6935354996752996

Epoch: 6| Step: 11
Training loss: 2.9943268299102783
Validation loss: 2.693236166431058

Epoch: 6| Step: 12
Training loss: 3.215728759765625
Validation loss: 2.696522743471207

Epoch: 6| Step: 13
Training loss: 1.9877700805664062
Validation loss: 2.6940363273825696

Epoch: 23| Step: 0
Training loss: 2.644322395324707
Validation loss: 2.6966684095321165

Epoch: 6| Step: 1
Training loss: 2.620539426803589
Validation loss: 2.6978036972784225

Epoch: 6| Step: 2
Training loss: 2.7068490982055664
Validation loss: 2.698636447229693

Epoch: 6| Step: 3
Training loss: 2.462317705154419
Validation loss: 2.69191324839028

Epoch: 6| Step: 4
Training loss: 3.452253580093384
Validation loss: 2.6952530286645375

Epoch: 6| Step: 5
Training loss: 2.618175506591797
Validation loss: 2.693425117000457

Epoch: 6| Step: 6
Training loss: 2.33902907371521
Validation loss: 2.688696092174899

Epoch: 6| Step: 7
Training loss: 2.8336398601531982
Validation loss: 2.688815410419177

Epoch: 6| Step: 8
Training loss: 3.2978131771087646
Validation loss: 2.690226306197464

Epoch: 6| Step: 9
Training loss: 2.814363479614258
Validation loss: 2.6864763972579793

Epoch: 6| Step: 10
Training loss: 2.421661615371704
Validation loss: 2.6876328709304973

Epoch: 6| Step: 11
Training loss: 3.1175975799560547
Validation loss: 2.6907012052433465

Epoch: 6| Step: 12
Training loss: 3.658719301223755
Validation loss: 2.6868108908335366

Epoch: 6| Step: 13
Training loss: 3.0335867404937744
Validation loss: 2.6852326444400254

Epoch: 24| Step: 0
Training loss: 3.662508487701416
Validation loss: 2.690347327980944

Epoch: 6| Step: 1
Training loss: 2.954082489013672
Validation loss: 2.6830225016481135

Epoch: 6| Step: 2
Training loss: 2.7689287662506104
Validation loss: 2.6784728701396654

Epoch: 6| Step: 3
Training loss: 2.6175436973571777
Validation loss: 2.6767219279402044

Epoch: 6| Step: 4
Training loss: 3.2862372398376465
Validation loss: 2.6785394760870163

Epoch: 6| Step: 5
Training loss: 2.785795211791992
Validation loss: 2.677735620929349

Epoch: 6| Step: 6
Training loss: 2.993464946746826
Validation loss: 2.678728078001289

Epoch: 6| Step: 7
Training loss: 2.57789945602417
Validation loss: 2.6837117082329205

Epoch: 6| Step: 8
Training loss: 2.9350602626800537
Validation loss: 2.679674135741367

Epoch: 6| Step: 9
Training loss: 2.3064496517181396
Validation loss: 2.6806433867382746

Epoch: 6| Step: 10
Training loss: 3.08683443069458
Validation loss: 2.684010123693815

Epoch: 6| Step: 11
Training loss: 2.807861328125
Validation loss: 2.690366955213649

Epoch: 6| Step: 12
Training loss: 2.8424792289733887
Validation loss: 2.68637482325236

Epoch: 6| Step: 13
Training loss: 1.8347039222717285
Validation loss: 2.675942200486378

Epoch: 25| Step: 0
Training loss: 3.6900856494903564
Validation loss: 2.6717286827743694

Epoch: 6| Step: 1
Training loss: 3.259181499481201
Validation loss: 2.672960191644648

Epoch: 6| Step: 2
Training loss: 2.420958995819092
Validation loss: 2.675112367958151

Epoch: 6| Step: 3
Training loss: 2.5773544311523438
Validation loss: 2.6810745859658844

Epoch: 6| Step: 4
Training loss: 3.433070659637451
Validation loss: 2.6811451809380644

Epoch: 6| Step: 5
Training loss: 2.649372100830078
Validation loss: 2.6860829373841644

Epoch: 6| Step: 6
Training loss: 2.205028533935547
Validation loss: 2.6865815065240346

Epoch: 6| Step: 7
Training loss: 3.0386128425598145
Validation loss: 2.6869947295035086

Epoch: 6| Step: 8
Training loss: 1.9551417827606201
Validation loss: 2.6833430772186606

Epoch: 6| Step: 9
Training loss: 3.8343892097473145
Validation loss: 2.6775942489665043

Epoch: 6| Step: 10
Training loss: 2.8158247470855713
Validation loss: 2.668902991920389

Epoch: 6| Step: 11
Training loss: 2.6940982341766357
Validation loss: 2.663300327075425

Epoch: 6| Step: 12
Training loss: 2.689126968383789
Validation loss: 2.6632050493712067

Epoch: 6| Step: 13
Training loss: 2.124070167541504
Validation loss: 2.6625293634271108

Epoch: 26| Step: 0
Training loss: 2.859757900238037
Validation loss: 2.661291758219401

Epoch: 6| Step: 1
Training loss: 3.5258655548095703
Validation loss: 2.6638496152816282

Epoch: 6| Step: 2
Training loss: 3.300114154815674
Validation loss: 2.665815176502351

Epoch: 6| Step: 3
Training loss: 3.413151264190674
Validation loss: 2.663686801028508

Epoch: 6| Step: 4
Training loss: 3.226590156555176
Validation loss: 2.6622649700410905

Epoch: 6| Step: 5
Training loss: 2.5784411430358887
Validation loss: 2.661673956019904

Epoch: 6| Step: 6
Training loss: 2.5331952571868896
Validation loss: 2.6587211752450592

Epoch: 6| Step: 7
Training loss: 3.086864948272705
Validation loss: 2.6592817742337465

Epoch: 6| Step: 8
Training loss: 3.3699252605438232
Validation loss: 2.6580949957652757

Epoch: 6| Step: 9
Training loss: 1.8703806400299072
Validation loss: 2.662823664244785

Epoch: 6| Step: 10
Training loss: 2.9213075637817383
Validation loss: 2.6680009749627884

Epoch: 6| Step: 11
Training loss: 2.509296178817749
Validation loss: 2.6634774310614473

Epoch: 6| Step: 12
Training loss: 2.1425957679748535
Validation loss: 2.6577863411236833

Epoch: 6| Step: 13
Training loss: 1.8759695291519165
Validation loss: 2.6557994709219983

Epoch: 27| Step: 0
Training loss: 1.8404372930526733
Validation loss: 2.6573023488444667

Epoch: 6| Step: 1
Training loss: 2.312574863433838
Validation loss: 2.653125916757891

Epoch: 6| Step: 2
Training loss: 2.760317325592041
Validation loss: 2.6515516209345993

Epoch: 6| Step: 3
Training loss: 3.2284440994262695
Validation loss: 2.6498885616179435

Epoch: 6| Step: 4
Training loss: 2.8924126625061035
Validation loss: 2.646927938666395

Epoch: 6| Step: 5
Training loss: 3.1254734992980957
Validation loss: 2.6452802945208806

Epoch: 6| Step: 6
Training loss: 4.195317268371582
Validation loss: 2.6515658106855167

Epoch: 6| Step: 7
Training loss: 1.9988703727722168
Validation loss: 2.655941814504644

Epoch: 6| Step: 8
Training loss: 2.1927154064178467
Validation loss: 2.6528330695244575

Epoch: 6| Step: 9
Training loss: 3.1128575801849365
Validation loss: 2.6485447678514706

Epoch: 6| Step: 10
Training loss: 3.112098217010498
Validation loss: 2.6463356018066406

Epoch: 6| Step: 11
Training loss: 2.414564371109009
Validation loss: 2.6452848783103367

Epoch: 6| Step: 12
Training loss: 3.0243937969207764
Validation loss: 2.6469146487533406

Epoch: 6| Step: 13
Training loss: 3.596564292907715
Validation loss: 2.6523169291916715

Epoch: 28| Step: 0
Training loss: 3.112338066101074
Validation loss: 2.6574339866638184

Epoch: 6| Step: 1
Training loss: 2.43076753616333
Validation loss: 2.6594561787061792

Epoch: 6| Step: 2
Training loss: 1.8539142608642578
Validation loss: 2.669993918429139

Epoch: 6| Step: 3
Training loss: 2.1003289222717285
Validation loss: 2.6821000165836786

Epoch: 6| Step: 4
Training loss: 3.3665006160736084
Validation loss: 2.7010321591490056

Epoch: 6| Step: 5
Training loss: 3.6290876865386963
Validation loss: 2.6922682792909685

Epoch: 6| Step: 6
Training loss: 2.930436611175537
Validation loss: 2.6638606697000484

Epoch: 6| Step: 7
Training loss: 2.868281602859497
Validation loss: 2.638998826344808

Epoch: 6| Step: 8
Training loss: 3.2066903114318848
Validation loss: 2.6381526659893733

Epoch: 6| Step: 9
Training loss: 2.1227948665618896
Validation loss: 2.6502581706611057

Epoch: 6| Step: 10
Training loss: 3.699038505554199
Validation loss: 2.676818347746326

Epoch: 6| Step: 11
Training loss: 3.1660332679748535
Validation loss: 2.666562767438991

Epoch: 6| Step: 12
Training loss: 2.6315927505493164
Validation loss: 2.646491914667109

Epoch: 6| Step: 13
Training loss: 2.233215093612671
Validation loss: 2.6429833545479724

Epoch: 29| Step: 0
Training loss: 2.9460601806640625
Validation loss: 2.6412316214653755

Epoch: 6| Step: 1
Training loss: 2.700033187866211
Validation loss: 2.6405481369264665

Epoch: 6| Step: 2
Training loss: 2.9739863872528076
Validation loss: 2.6473299175180416

Epoch: 6| Step: 3
Training loss: 3.08547043800354
Validation loss: 2.6514424893163864

Epoch: 6| Step: 4
Training loss: 2.2768211364746094
Validation loss: 2.6583822619530464

Epoch: 6| Step: 5
Training loss: 2.5568933486938477
Validation loss: 2.674157629730881

Epoch: 6| Step: 6
Training loss: 3.224846363067627
Validation loss: 2.671799498219644

Epoch: 6| Step: 7
Training loss: 2.463179588317871
Validation loss: 2.658660481053014

Epoch: 6| Step: 8
Training loss: 2.046250343322754
Validation loss: 2.6502785375041347

Epoch: 6| Step: 9
Training loss: 3.1817197799682617
Validation loss: 2.6421839062885573

Epoch: 6| Step: 10
Training loss: 3.2097370624542236
Validation loss: 2.635490407225906

Epoch: 6| Step: 11
Training loss: 3.244159698486328
Validation loss: 2.6354665525497927

Epoch: 6| Step: 12
Training loss: 2.8893542289733887
Validation loss: 2.630538414883357

Epoch: 6| Step: 13
Training loss: 2.2487940788269043
Validation loss: 2.627229041950677

Epoch: 30| Step: 0
Training loss: 3.071629047393799
Validation loss: 2.628423603632117

Epoch: 6| Step: 1
Training loss: 2.039417028427124
Validation loss: 2.624863129790111

Epoch: 6| Step: 2
Training loss: 2.698525905609131
Validation loss: 2.6207624763570805

Epoch: 6| Step: 3
Training loss: 2.8241167068481445
Validation loss: 2.6219533566505677

Epoch: 6| Step: 4
Training loss: 2.9643707275390625
Validation loss: 2.626220182705951

Epoch: 6| Step: 5
Training loss: 2.1779730319976807
Validation loss: 2.6260931030396493

Epoch: 6| Step: 6
Training loss: 3.202768325805664
Validation loss: 2.627503384826004

Epoch: 6| Step: 7
Training loss: 3.2167766094207764
Validation loss: 2.6230955918629966

Epoch: 6| Step: 8
Training loss: 2.390566110610962
Validation loss: 2.62236887152477

Epoch: 6| Step: 9
Training loss: 2.59624981880188
Validation loss: 2.6222022835926344

Epoch: 6| Step: 10
Training loss: 3.1670405864715576
Validation loss: 2.6221156248482327

Epoch: 6| Step: 11
Training loss: 2.956918239593506
Validation loss: 2.618384192066808

Epoch: 6| Step: 12
Training loss: 2.9107871055603027
Validation loss: 2.615076054808914

Epoch: 6| Step: 13
Training loss: 3.038633108139038
Validation loss: 2.6138598842005574

Epoch: 31| Step: 0
Training loss: 2.927182674407959
Validation loss: 2.616154714297223

Epoch: 6| Step: 1
Training loss: 3.0965449810028076
Validation loss: 2.611227907160277

Epoch: 6| Step: 2
Training loss: 2.489131450653076
Validation loss: 2.609841413395379

Epoch: 6| Step: 3
Training loss: 3.0810747146606445
Validation loss: 2.611454999575051

Epoch: 6| Step: 4
Training loss: 2.298140525817871
Validation loss: 2.611693977027811

Epoch: 6| Step: 5
Training loss: 2.664555549621582
Validation loss: 2.6116958843764437

Epoch: 6| Step: 6
Training loss: 3.1104540824890137
Validation loss: 2.612257993349465

Epoch: 6| Step: 7
Training loss: 2.8130109310150146
Validation loss: 2.611028617428195

Epoch: 6| Step: 8
Training loss: 1.7305924892425537
Validation loss: 2.6139695746924287

Epoch: 6| Step: 9
Training loss: 3.33663272857666
Validation loss: 2.61722154771128

Epoch: 6| Step: 10
Training loss: 3.207277297973633
Validation loss: 2.620468862595097

Epoch: 6| Step: 11
Training loss: 3.6611757278442383
Validation loss: 2.618711894558322

Epoch: 6| Step: 12
Training loss: 1.8962148427963257
Validation loss: 2.619063864472092

Epoch: 6| Step: 13
Training loss: 2.6096861362457275
Validation loss: 2.631999123481012

Epoch: 32| Step: 0
Training loss: 2.9446792602539062
Validation loss: 2.6457181207595335

Epoch: 6| Step: 1
Training loss: 3.2410330772399902
Validation loss: 2.669811917889503

Epoch: 6| Step: 2
Training loss: 2.8915114402770996
Validation loss: 2.651988124334684

Epoch: 6| Step: 3
Training loss: 2.273054599761963
Validation loss: 2.6269398427778676

Epoch: 6| Step: 4
Training loss: 3.147921323776245
Validation loss: 2.6192481415246123

Epoch: 6| Step: 5
Training loss: 3.0757431983947754
Validation loss: 2.617068967511577

Epoch: 6| Step: 6
Training loss: 2.096036911010742
Validation loss: 2.6078006823857627

Epoch: 6| Step: 7
Training loss: 2.7942028045654297
Validation loss: 2.6066108570303967

Epoch: 6| Step: 8
Training loss: 2.202125072479248
Validation loss: 2.602452911356444

Epoch: 6| Step: 9
Training loss: 2.3430840969085693
Validation loss: 2.6013603338631253

Epoch: 6| Step: 10
Training loss: 3.4803824424743652
Validation loss: 2.6027940088702786

Epoch: 6| Step: 11
Training loss: 3.688197612762451
Validation loss: 2.6018494918782222

Epoch: 6| Step: 12
Training loss: 2.3232321739196777
Validation loss: 2.600581802347655

Epoch: 6| Step: 13
Training loss: 2.181063413619995
Validation loss: 2.6025518653213338

Epoch: 33| Step: 0
Training loss: 3.258349657058716
Validation loss: 2.6033646368211314

Epoch: 6| Step: 1
Training loss: 2.9080634117126465
Validation loss: 2.606806657647574

Epoch: 6| Step: 2
Training loss: 2.424793243408203
Validation loss: 2.6061322048146236

Epoch: 6| Step: 3
Training loss: 2.513235330581665
Validation loss: 2.611244358042235

Epoch: 6| Step: 4
Training loss: 1.9404757022857666
Validation loss: 2.6125793585213284

Epoch: 6| Step: 5
Training loss: 3.504145860671997
Validation loss: 2.611100624966365

Epoch: 6| Step: 6
Training loss: 3.493823528289795
Validation loss: 2.6091784354179137

Epoch: 6| Step: 7
Training loss: 2.327024459838867
Validation loss: 2.62382778557398

Epoch: 6| Step: 8
Training loss: 3.2222213745117188
Validation loss: 2.6508827183836248

Epoch: 6| Step: 9
Training loss: 2.675095558166504
Validation loss: 2.678642447276782

Epoch: 6| Step: 10
Training loss: 2.2344419956207275
Validation loss: 2.6587389951111167

Epoch: 6| Step: 11
Training loss: 3.244760274887085
Validation loss: 2.6269957788528933

Epoch: 6| Step: 12
Training loss: 2.5885682106018066
Validation loss: 2.6005268250742266

Epoch: 6| Step: 13
Training loss: 2.536372184753418
Validation loss: 2.6001577120955273

Epoch: 34| Step: 0
Training loss: 2.7587592601776123
Validation loss: 2.6116908801499235

Epoch: 6| Step: 1
Training loss: 3.5115513801574707
Validation loss: 2.662236234193207

Epoch: 6| Step: 2
Training loss: 1.8744279146194458
Validation loss: 2.5995348320212415

Epoch: 6| Step: 3
Training loss: 3.773503065109253
Validation loss: 2.5963579211183774

Epoch: 6| Step: 4
Training loss: 2.477651357650757
Validation loss: 2.638687167116391

Epoch: 6| Step: 5
Training loss: 2.903118133544922
Validation loss: 2.6212688107644357

Epoch: 6| Step: 6
Training loss: 2.0238213539123535
Validation loss: 2.620780070622762

Epoch: 6| Step: 7
Training loss: 2.9424190521240234
Validation loss: 2.6062297872317735

Epoch: 6| Step: 8
Training loss: 2.8703067302703857
Validation loss: 2.615667635394681

Epoch: 6| Step: 9
Training loss: 2.405257225036621
Validation loss: 2.623665404576127

Epoch: 6| Step: 10
Training loss: 3.3314099311828613
Validation loss: 2.6263331213305072

Epoch: 6| Step: 11
Training loss: 2.309213399887085
Validation loss: 2.6235956684235604

Epoch: 6| Step: 12
Training loss: 2.755934953689575
Validation loss: 2.6219477371502946

Epoch: 6| Step: 13
Training loss: 3.38505482673645
Validation loss: 2.6169428210104666

Epoch: 35| Step: 0
Training loss: 2.6095361709594727
Validation loss: 2.6120396814038678

Epoch: 6| Step: 1
Training loss: 2.315758228302002
Validation loss: 2.5936684813550723

Epoch: 6| Step: 2
Training loss: 2.417895555496216
Validation loss: 2.588209411149384

Epoch: 6| Step: 3
Training loss: 2.997828245162964
Validation loss: 2.5800104846236525

Epoch: 6| Step: 4
Training loss: 3.07507586479187
Validation loss: 2.582045985806373

Epoch: 6| Step: 5
Training loss: 2.4370522499084473
Validation loss: 2.5829847961343746

Epoch: 6| Step: 6
Training loss: 2.923539161682129
Validation loss: 2.5834331179177887

Epoch: 6| Step: 7
Training loss: 3.237304210662842
Validation loss: 2.5828633923684396

Epoch: 6| Step: 8
Training loss: 2.7969188690185547
Validation loss: 2.5814385003941034

Epoch: 6| Step: 9
Training loss: 2.3918166160583496
Validation loss: 2.5815682526557677

Epoch: 6| Step: 10
Training loss: 2.7564353942871094
Validation loss: 2.5783628494508806

Epoch: 6| Step: 11
Training loss: 2.814396381378174
Validation loss: 2.5757393349883375

Epoch: 6| Step: 12
Training loss: 2.809386968612671
Validation loss: 2.576496342177032

Epoch: 6| Step: 13
Training loss: 3.534580707550049
Validation loss: 2.5765136698240876

Epoch: 36| Step: 0
Training loss: 3.2701971530914307
Validation loss: 2.574742178763113

Epoch: 6| Step: 1
Training loss: 3.6314399242401123
Validation loss: 2.574039702774376

Epoch: 6| Step: 2
Training loss: 2.5534229278564453
Validation loss: 2.5707891320669525

Epoch: 6| Step: 3
Training loss: 1.6394635438919067
Validation loss: 2.5716597367358465

Epoch: 6| Step: 4
Training loss: 2.275495767593384
Validation loss: 2.571006482647311

Epoch: 6| Step: 5
Training loss: 2.7614195346832275
Validation loss: 2.5716201105425434

Epoch: 6| Step: 6
Training loss: 2.680788993835449
Validation loss: 2.5726732746247323

Epoch: 6| Step: 7
Training loss: 2.325972080230713
Validation loss: 2.569761860755182

Epoch: 6| Step: 8
Training loss: 2.610144853591919
Validation loss: 2.5706647544778805

Epoch: 6| Step: 9
Training loss: 3.1027960777282715
Validation loss: 2.5674835558860534

Epoch: 6| Step: 10
Training loss: 3.4161672592163086
Validation loss: 2.570939533172115

Epoch: 6| Step: 11
Training loss: 2.404953956604004
Validation loss: 2.566532337537376

Epoch: 6| Step: 12
Training loss: 2.922363519668579
Validation loss: 2.5673982071620163

Epoch: 6| Step: 13
Training loss: 3.0034873485565186
Validation loss: 2.5702611810417584

Epoch: 37| Step: 0
Training loss: 2.231339454650879
Validation loss: 2.569048807185183

Epoch: 6| Step: 1
Training loss: 3.1384034156799316
Validation loss: 2.572953877910491

Epoch: 6| Step: 2
Training loss: 2.5530693531036377
Validation loss: 2.5710005247464744

Epoch: 6| Step: 3
Training loss: 2.4536399841308594
Validation loss: 2.5680493488106677

Epoch: 6| Step: 4
Training loss: 2.8920300006866455
Validation loss: 2.568461231006089

Epoch: 6| Step: 5
Training loss: 2.5726828575134277
Validation loss: 2.570155128355949

Epoch: 6| Step: 6
Training loss: 2.4919896125793457
Validation loss: 2.5686494124832975

Epoch: 6| Step: 7
Training loss: 3.1749582290649414
Validation loss: 2.5706297043831117

Epoch: 6| Step: 8
Training loss: 3.523341178894043
Validation loss: 2.567645408773935

Epoch: 6| Step: 9
Training loss: 2.8039543628692627
Validation loss: 2.567176721429312

Epoch: 6| Step: 10
Training loss: 2.973060131072998
Validation loss: 2.5592272512374388

Epoch: 6| Step: 11
Training loss: 3.3431432247161865
Validation loss: 2.5579684498489543

Epoch: 6| Step: 12
Training loss: 2.1548752784729004
Validation loss: 2.5542128034817275

Epoch: 6| Step: 13
Training loss: 1.7556428909301758
Validation loss: 2.557207122925789

Epoch: 38| Step: 0
Training loss: 2.8791286945343018
Validation loss: 2.5541057279033046

Epoch: 6| Step: 1
Training loss: 2.6809611320495605
Validation loss: 2.5528950332313456

Epoch: 6| Step: 2
Training loss: 3.101876974105835
Validation loss: 2.5566527946020967

Epoch: 6| Step: 3
Training loss: 3.096367120742798
Validation loss: 2.5548642130308252

Epoch: 6| Step: 4
Training loss: 2.674450635910034
Validation loss: 2.5556399053142917

Epoch: 6| Step: 5
Training loss: 2.6534082889556885
Validation loss: 2.557985641623056

Epoch: 6| Step: 6
Training loss: 3.0921053886413574
Validation loss: 2.5628895131490563

Epoch: 6| Step: 7
Training loss: 2.6655054092407227
Validation loss: 2.557059872534967

Epoch: 6| Step: 8
Training loss: 2.038666248321533
Validation loss: 2.55735969415275

Epoch: 6| Step: 9
Training loss: 2.8227686882019043
Validation loss: 2.5539326719058457

Epoch: 6| Step: 10
Training loss: 3.3585364818573
Validation loss: 2.553918295009162

Epoch: 6| Step: 11
Training loss: 3.2616214752197266
Validation loss: 2.552522033773443

Epoch: 6| Step: 12
Training loss: 1.5449540615081787
Validation loss: 2.5519971796261367

Epoch: 6| Step: 13
Training loss: 2.2218775749206543
Validation loss: 2.550784710914858

Epoch: 39| Step: 0
Training loss: 3.19342041015625
Validation loss: 2.5514770528321624

Epoch: 6| Step: 1
Training loss: 2.1541123390197754
Validation loss: 2.552915327010616

Epoch: 6| Step: 2
Training loss: 3.055974006652832
Validation loss: 2.5489857299353487

Epoch: 6| Step: 3
Training loss: 3.3964016437530518
Validation loss: 2.544946978169103

Epoch: 6| Step: 4
Training loss: 3.9959213733673096
Validation loss: 2.5457031239745436

Epoch: 6| Step: 5
Training loss: 2.4388208389282227
Validation loss: 2.5478769912514636

Epoch: 6| Step: 6
Training loss: 2.3903262615203857
Validation loss: 2.5557860789760465

Epoch: 6| Step: 7
Training loss: 2.185136556625366
Validation loss: 2.5591289817645984

Epoch: 6| Step: 8
Training loss: 3.3321597576141357
Validation loss: 2.566616994078441

Epoch: 6| Step: 9
Training loss: 1.792328119277954
Validation loss: 2.569998884713778

Epoch: 6| Step: 10
Training loss: 2.220950126647949
Validation loss: 2.5614521657266924

Epoch: 6| Step: 11
Training loss: 2.2997288703918457
Validation loss: 2.5461871316356044

Epoch: 6| Step: 12
Training loss: 3.012462615966797
Validation loss: 2.5354244196286766

Epoch: 6| Step: 13
Training loss: 2.9684553146362305
Validation loss: 2.5401904608613703

Epoch: 40| Step: 0
Training loss: 3.5519237518310547
Validation loss: 2.543172841430992

Epoch: 6| Step: 1
Training loss: 3.76399564743042
Validation loss: 2.544741363935573

Epoch: 6| Step: 2
Training loss: 2.8433837890625
Validation loss: 2.5499902925183697

Epoch: 6| Step: 3
Training loss: 2.2933273315429688
Validation loss: 2.5554968259667836

Epoch: 6| Step: 4
Training loss: 2.9485669136047363
Validation loss: 2.5570413297222507

Epoch: 6| Step: 5
Training loss: 2.3329386711120605
Validation loss: 2.5589393415758686

Epoch: 6| Step: 6
Training loss: 2.599400758743286
Validation loss: 2.552802206367575

Epoch: 6| Step: 7
Training loss: 3.1499383449554443
Validation loss: 2.5463367508303736

Epoch: 6| Step: 8
Training loss: 2.9046597480773926
Validation loss: 2.543208650363389

Epoch: 6| Step: 9
Training loss: 2.114556312561035
Validation loss: 2.5345167626616774

Epoch: 6| Step: 10
Training loss: 1.5488264560699463
Validation loss: 2.53133193139107

Epoch: 6| Step: 11
Training loss: 3.123347282409668
Validation loss: 2.5305956871278825

Epoch: 6| Step: 12
Training loss: 2.6455459594726562
Validation loss: 2.536115046470396

Epoch: 6| Step: 13
Training loss: 2.329432964324951
Validation loss: 2.554154911348897

Epoch: 41| Step: 0
Training loss: 3.3595376014709473
Validation loss: 2.553367043054232

Epoch: 6| Step: 1
Training loss: 2.107264280319214
Validation loss: 2.5557914267304125

Epoch: 6| Step: 2
Training loss: 3.1490063667297363
Validation loss: 2.5572900977185977

Epoch: 6| Step: 3
Training loss: 2.620164155960083
Validation loss: 2.5538736979166665

Epoch: 6| Step: 4
Training loss: 2.526885986328125
Validation loss: 2.550093448290261

Epoch: 6| Step: 5
Training loss: 2.179947853088379
Validation loss: 2.5493233075705906

Epoch: 6| Step: 6
Training loss: 2.869292736053467
Validation loss: 2.5479294946116786

Epoch: 6| Step: 7
Training loss: 2.334787368774414
Validation loss: 2.5459188517703804

Epoch: 6| Step: 8
Training loss: 3.242765426635742
Validation loss: 2.5385268606165403

Epoch: 6| Step: 9
Training loss: 2.7608189582824707
Validation loss: 2.5332088265367734

Epoch: 6| Step: 10
Training loss: 2.499943256378174
Validation loss: 2.528817166564285

Epoch: 6| Step: 11
Training loss: 2.9184322357177734
Validation loss: 2.527336420551423

Epoch: 6| Step: 12
Training loss: 2.7778844833374023
Validation loss: 2.5268665513684674

Epoch: 6| Step: 13
Training loss: 2.979194402694702
Validation loss: 2.526093885462771

Epoch: 42| Step: 0
Training loss: 2.1077466011047363
Validation loss: 2.526363036965811

Epoch: 6| Step: 1
Training loss: 2.6515040397644043
Validation loss: 2.5232695559019684

Epoch: 6| Step: 2
Training loss: 2.5029067993164062
Validation loss: 2.5246297236411803

Epoch: 6| Step: 3
Training loss: 2.1951634883880615
Validation loss: 2.520844135233151

Epoch: 6| Step: 4
Training loss: 3.088090658187866
Validation loss: 2.519781538235244

Epoch: 6| Step: 5
Training loss: 2.8759942054748535
Validation loss: 2.520188493113364

Epoch: 6| Step: 6
Training loss: 3.2203164100646973
Validation loss: 2.5197593717164892

Epoch: 6| Step: 7
Training loss: 2.2994191646575928
Validation loss: 2.5213919685732935

Epoch: 6| Step: 8
Training loss: 1.6369198560714722
Validation loss: 2.5235997707613054

Epoch: 6| Step: 9
Training loss: 3.2054576873779297
Validation loss: 2.5261426817986274

Epoch: 6| Step: 10
Training loss: 2.6970813274383545
Validation loss: 2.5233975738607426

Epoch: 6| Step: 11
Training loss: 3.1316676139831543
Validation loss: 2.5251699596322994

Epoch: 6| Step: 12
Training loss: 3.2986507415771484
Validation loss: 2.523626963297526

Epoch: 6| Step: 13
Training loss: 3.3902883529663086
Validation loss: 2.5223214267402567

Epoch: 43| Step: 0
Training loss: 2.504214286804199
Validation loss: 2.5240367715076735

Epoch: 6| Step: 1
Training loss: 2.341477870941162
Validation loss: 2.5145467660760366

Epoch: 6| Step: 2
Training loss: 2.286372661590576
Validation loss: 2.513596245037612

Epoch: 6| Step: 3
Training loss: 3.5358452796936035
Validation loss: 2.5181182507545716

Epoch: 6| Step: 4
Training loss: 2.739201307296753
Validation loss: 2.5169127782185874

Epoch: 6| Step: 5
Training loss: 1.868011236190796
Validation loss: 2.5160511744919645

Epoch: 6| Step: 6
Training loss: 2.5905585289001465
Validation loss: 2.5166693682311685

Epoch: 6| Step: 7
Training loss: 2.258924961090088
Validation loss: 2.5152768473471365

Epoch: 6| Step: 8
Training loss: 3.1992063522338867
Validation loss: 2.513988276963593

Epoch: 6| Step: 9
Training loss: 2.823274612426758
Validation loss: 2.583769752133277

Epoch: 6| Step: 10
Training loss: 2.23746395111084
Validation loss: 2.5967769186983825

Epoch: 6| Step: 11
Training loss: 3.8143086433410645
Validation loss: 2.610076945315125

Epoch: 6| Step: 12
Training loss: 3.234391689300537
Validation loss: 2.6230760415395102

Epoch: 6| Step: 13
Training loss: 2.755800485610962
Validation loss: 2.640969640465193

Epoch: 44| Step: 0
Training loss: 2.8190109729766846
Validation loss: 2.6380616541831725

Epoch: 6| Step: 1
Training loss: 2.4127085208892822
Validation loss: 2.6178239417332474

Epoch: 6| Step: 2
Training loss: 2.2213921546936035
Validation loss: 2.607449157263643

Epoch: 6| Step: 3
Training loss: 2.901637554168701
Validation loss: 2.601323655856553

Epoch: 6| Step: 4
Training loss: 2.6022329330444336
Validation loss: 2.596644006749635

Epoch: 6| Step: 5
Training loss: 2.110163450241089
Validation loss: 2.5891665233078824

Epoch: 6| Step: 6
Training loss: 3.228239059448242
Validation loss: 2.590379117637552

Epoch: 6| Step: 7
Training loss: 3.244494915008545
Validation loss: 2.5885788266376784

Epoch: 6| Step: 8
Training loss: 2.8663382530212402
Validation loss: 2.587221427630353

Epoch: 6| Step: 9
Training loss: 2.9110074043273926
Validation loss: 2.58819309870402

Epoch: 6| Step: 10
Training loss: 3.1484556198120117
Validation loss: 2.5870077481833835

Epoch: 6| Step: 11
Training loss: 2.4388649463653564
Validation loss: 2.5863257300469185

Epoch: 6| Step: 12
Training loss: 3.0214343070983887
Validation loss: 2.5845885738249748

Epoch: 6| Step: 13
Training loss: 2.7046003341674805
Validation loss: 2.585091637026879

Epoch: 45| Step: 0
Training loss: 2.5398902893066406
Validation loss: 2.581408011016025

Epoch: 6| Step: 1
Training loss: 1.6225080490112305
Validation loss: 2.5832853983807307

Epoch: 6| Step: 2
Training loss: 3.0917680263519287
Validation loss: 2.5817420021180184

Epoch: 6| Step: 3
Training loss: 2.8846731185913086
Validation loss: 2.5783992044387327

Epoch: 6| Step: 4
Training loss: 2.644092082977295
Validation loss: 2.578800537252939

Epoch: 6| Step: 5
Training loss: 2.788731098175049
Validation loss: 2.578405476385547

Epoch: 6| Step: 6
Training loss: 3.603381395339966
Validation loss: 2.5772541107669955

Epoch: 6| Step: 7
Training loss: 2.323896884918213
Validation loss: 2.5756605722570933

Epoch: 6| Step: 8
Training loss: 2.1931183338165283
Validation loss: 2.5761644263421335

Epoch: 6| Step: 9
Training loss: 3.368439197540283
Validation loss: 2.5757475360747306

Epoch: 6| Step: 10
Training loss: 2.9024810791015625
Validation loss: 2.578585478567308

Epoch: 6| Step: 11
Training loss: 2.445983648300171
Validation loss: 2.5789848194327405

Epoch: 6| Step: 12
Training loss: 2.9773778915405273
Validation loss: 2.5854032449824835

Epoch: 6| Step: 13
Training loss: 3.4164559841156006
Validation loss: 2.592330394252654

Epoch: 46| Step: 0
Training loss: 2.021702527999878
Validation loss: 2.588040146776425

Epoch: 6| Step: 1
Training loss: 3.4123058319091797
Validation loss: 2.5925741682770433

Epoch: 6| Step: 2
Training loss: 3.0336031913757324
Validation loss: 2.6076736809105

Epoch: 6| Step: 3
Training loss: 2.7745988368988037
Validation loss: 2.6015136882823002

Epoch: 6| Step: 4
Training loss: 3.01865291595459
Validation loss: 2.592597253860966

Epoch: 6| Step: 5
Training loss: 3.191340923309326
Validation loss: 2.586039671333887

Epoch: 6| Step: 6
Training loss: 3.0229456424713135
Validation loss: 2.581237623768468

Epoch: 6| Step: 7
Training loss: 2.465423822402954
Validation loss: 2.57502737609289

Epoch: 6| Step: 8
Training loss: 1.8898046016693115
Validation loss: 2.5653698008547545

Epoch: 6| Step: 9
Training loss: 2.4980220794677734
Validation loss: 2.536901166362147

Epoch: 6| Step: 10
Training loss: 2.8571043014526367
Validation loss: 2.497962410731982

Epoch: 6| Step: 11
Training loss: 3.0783214569091797
Validation loss: 2.510645233174806

Epoch: 6| Step: 12
Training loss: 2.7928342819213867
Validation loss: 2.5008114589157926

Epoch: 6| Step: 13
Training loss: 1.831957459449768
Validation loss: 2.5073410387962096

Epoch: 47| Step: 0
Training loss: 3.242727041244507
Validation loss: 2.527659108561854

Epoch: 6| Step: 1
Training loss: 3.0124359130859375
Validation loss: 2.533826038401614

Epoch: 6| Step: 2
Training loss: 2.5789806842803955
Validation loss: 2.5281235864085536

Epoch: 6| Step: 3
Training loss: 2.3587112426757812
Validation loss: 2.5026857263298443

Epoch: 6| Step: 4
Training loss: 2.417978048324585
Validation loss: 2.490335210677116

Epoch: 6| Step: 5
Training loss: 3.175553321838379
Validation loss: 2.4869470160494567

Epoch: 6| Step: 6
Training loss: 2.663454532623291
Validation loss: 2.4830699633526545

Epoch: 6| Step: 7
Training loss: 2.541496753692627
Validation loss: 2.484945345950383

Epoch: 6| Step: 8
Training loss: 3.0122337341308594
Validation loss: 2.4845635967869915

Epoch: 6| Step: 9
Training loss: 2.229846954345703
Validation loss: 2.4909036133878972

Epoch: 6| Step: 10
Training loss: 2.838582992553711
Validation loss: 2.4971841201987317

Epoch: 6| Step: 11
Training loss: 2.5068278312683105
Validation loss: 2.493296956503263

Epoch: 6| Step: 12
Training loss: 2.150986909866333
Validation loss: 2.501122228560909

Epoch: 6| Step: 13
Training loss: 3.5528602600097656
Validation loss: 2.4965159021398073

Epoch: 48| Step: 0
Training loss: 2.709770917892456
Validation loss: 2.491238042872439

Epoch: 6| Step: 1
Training loss: 2.179835081100464
Validation loss: 2.4885941961760163

Epoch: 6| Step: 2
Training loss: 2.835085868835449
Validation loss: 2.486851769108926

Epoch: 6| Step: 3
Training loss: 3.775707244873047
Validation loss: 2.483733900131718

Epoch: 6| Step: 4
Training loss: 1.9853060245513916
Validation loss: 2.4829798103660665

Epoch: 6| Step: 5
Training loss: 2.6929845809936523
Validation loss: 2.477955554121284

Epoch: 6| Step: 6
Training loss: 2.6018800735473633
Validation loss: 2.4840688141443397

Epoch: 6| Step: 7
Training loss: 3.367819309234619
Validation loss: 2.4885965124253304

Epoch: 6| Step: 8
Training loss: 2.9124767780303955
Validation loss: 2.486823535734607

Epoch: 6| Step: 9
Training loss: 2.7925803661346436
Validation loss: 2.4829203646670104

Epoch: 6| Step: 10
Training loss: 2.9566586017608643
Validation loss: 2.4819727302879415

Epoch: 6| Step: 11
Training loss: 1.9228914976119995
Validation loss: 2.4774334097421296

Epoch: 6| Step: 12
Training loss: 2.516806125640869
Validation loss: 2.485838192765431

Epoch: 6| Step: 13
Training loss: 2.3287453651428223
Validation loss: 2.485178839775824

Epoch: 49| Step: 0
Training loss: 2.2578258514404297
Validation loss: 2.489252985164683

Epoch: 6| Step: 1
Training loss: 2.8092799186706543
Validation loss: 2.49073822780322

Epoch: 6| Step: 2
Training loss: 2.9691238403320312
Validation loss: 2.4983606107773317

Epoch: 6| Step: 3
Training loss: 2.925723075866699
Validation loss: 2.495902033262355

Epoch: 6| Step: 4
Training loss: 3.443359136581421
Validation loss: 2.492516145911268

Epoch: 6| Step: 5
Training loss: 3.2497479915618896
Validation loss: 2.4896569764742287

Epoch: 6| Step: 6
Training loss: 2.965592384338379
Validation loss: 2.490145235933283

Epoch: 6| Step: 7
Training loss: 2.494138240814209
Validation loss: 2.488820798935429

Epoch: 6| Step: 8
Training loss: 2.6503329277038574
Validation loss: 2.4862769406328917

Epoch: 6| Step: 9
Training loss: 2.2036807537078857
Validation loss: 2.480337372390173

Epoch: 6| Step: 10
Training loss: 1.6778920888900757
Validation loss: 2.4769997673649944

Epoch: 6| Step: 11
Training loss: 2.9108166694641113
Validation loss: 2.4800189592505015

Epoch: 6| Step: 12
Training loss: 2.3221688270568848
Validation loss: 2.4795326904584

Epoch: 6| Step: 13
Training loss: 2.8540267944335938
Validation loss: 2.485599361440187

Epoch: 50| Step: 0
Training loss: 2.526782274246216
Validation loss: 2.4976815613367225

Epoch: 6| Step: 1
Training loss: 2.0626797676086426
Validation loss: 2.50883589765077

Epoch: 6| Step: 2
Training loss: 2.786278486251831
Validation loss: 2.5154302620118663

Epoch: 6| Step: 3
Training loss: 3.4653842449188232
Validation loss: 2.5019257504452943

Epoch: 6| Step: 4
Training loss: 3.388308048248291
Validation loss: 2.482238624685554

Epoch: 6| Step: 5
Training loss: 3.1670048236846924
Validation loss: 2.470561558200467

Epoch: 6| Step: 6
Training loss: 2.2193450927734375
Validation loss: 2.468997552830686

Epoch: 6| Step: 7
Training loss: 2.6144962310791016
Validation loss: 2.475569607109152

Epoch: 6| Step: 8
Training loss: 2.1889092922210693
Validation loss: 2.479180253962035

Epoch: 6| Step: 9
Training loss: 2.6213653087615967
Validation loss: 2.487068945361722

Epoch: 6| Step: 10
Training loss: 2.7397403717041016
Validation loss: 2.523736984499039

Epoch: 6| Step: 11
Training loss: 3.216250419616699
Validation loss: 2.5983518221045054

Epoch: 6| Step: 12
Training loss: 2.0715198516845703
Validation loss: 2.468006172487813

Epoch: 6| Step: 13
Training loss: 2.6979570388793945
Validation loss: 2.467301468695364

Epoch: 51| Step: 0
Training loss: 1.9879101514816284
Validation loss: 2.4702504937366774

Epoch: 6| Step: 1
Training loss: 2.8486976623535156
Validation loss: 2.475533127784729

Epoch: 6| Step: 2
Training loss: 2.2077622413635254
Validation loss: 2.479130027114704

Epoch: 6| Step: 3
Training loss: 3.2746949195861816
Validation loss: 2.5034786962693736

Epoch: 6| Step: 4
Training loss: 3.508709669113159
Validation loss: 2.4977079360715804

Epoch: 6| Step: 5
Training loss: 2.592803955078125
Validation loss: 2.5054682916210544

Epoch: 6| Step: 6
Training loss: 2.74725079536438
Validation loss: 2.4883801808921238

Epoch: 6| Step: 7
Training loss: 2.526106357574463
Validation loss: 2.4800793765693583

Epoch: 6| Step: 8
Training loss: 2.530919075012207
Validation loss: 2.473802743419524

Epoch: 6| Step: 9
Training loss: 2.495795249938965
Validation loss: 2.4715106384728545

Epoch: 6| Step: 10
Training loss: 2.9302027225494385
Validation loss: 2.4706472632705525

Epoch: 6| Step: 11
Training loss: 3.12117338180542
Validation loss: 2.4649134425706762

Epoch: 6| Step: 12
Training loss: 2.264153480529785
Validation loss: 2.4681695584327943

Epoch: 6| Step: 13
Training loss: 2.5217785835266113
Validation loss: 2.465934025344028

Epoch: 52| Step: 0
Training loss: 3.207355499267578
Validation loss: 2.4585610589673443

Epoch: 6| Step: 1
Training loss: 2.845724582672119
Validation loss: 2.4570726912508727

Epoch: 6| Step: 2
Training loss: 2.3231141567230225
Validation loss: 2.455335629883633

Epoch: 6| Step: 3
Training loss: 1.6666181087493896
Validation loss: 2.4582267089556624

Epoch: 6| Step: 4
Training loss: 2.692750930786133
Validation loss: 2.4602270690343713

Epoch: 6| Step: 5
Training loss: 3.1918554306030273
Validation loss: 2.4609864834816224

Epoch: 6| Step: 6
Training loss: 2.437662124633789
Validation loss: 2.4566312810426116

Epoch: 6| Step: 7
Training loss: 2.372886896133423
Validation loss: 2.459209785666517

Epoch: 6| Step: 8
Training loss: 2.6710853576660156
Validation loss: 2.4583137932644097

Epoch: 6| Step: 9
Training loss: 2.9651601314544678
Validation loss: 2.4593459983025827

Epoch: 6| Step: 10
Training loss: 2.7031002044677734
Validation loss: 2.457482435370004

Epoch: 6| Step: 11
Training loss: 2.505079746246338
Validation loss: 2.459144543575984

Epoch: 6| Step: 12
Training loss: 2.677739143371582
Validation loss: 2.454402890256656

Epoch: 6| Step: 13
Training loss: 3.57300066947937
Validation loss: 2.455180973135015

Epoch: 53| Step: 0
Training loss: 2.0867624282836914
Validation loss: 2.4537769004862797

Epoch: 6| Step: 1
Training loss: 2.7685937881469727
Validation loss: 2.448832227337745

Epoch: 6| Step: 2
Training loss: 2.600600004196167
Validation loss: 2.443519884540189

Epoch: 6| Step: 3
Training loss: 2.8103134632110596
Validation loss: 2.4458346136154665

Epoch: 6| Step: 4
Training loss: 3.4109530448913574
Validation loss: 2.443368909179523

Epoch: 6| Step: 5
Training loss: 2.2303078174591064
Validation loss: 2.4392103661773024

Epoch: 6| Step: 6
Training loss: 2.075700521469116
Validation loss: 2.4391107431022068

Epoch: 6| Step: 7
Training loss: 3.444549560546875
Validation loss: 2.441081808459374

Epoch: 6| Step: 8
Training loss: 2.8869965076446533
Validation loss: 2.4470939354229997

Epoch: 6| Step: 9
Training loss: 2.522766351699829
Validation loss: 2.4449728560704056

Epoch: 6| Step: 10
Training loss: 2.476512908935547
Validation loss: 2.4508375121701147

Epoch: 6| Step: 11
Training loss: 2.395265817642212
Validation loss: 2.4491804645907496

Epoch: 6| Step: 12
Training loss: 2.683701753616333
Validation loss: 2.4393745289053967

Epoch: 6| Step: 13
Training loss: 3.0001132488250732
Validation loss: 2.44625872694036

Epoch: 54| Step: 0
Training loss: 2.509626626968384
Validation loss: 2.4451590584170435

Epoch: 6| Step: 1
Training loss: 2.7221899032592773
Validation loss: 2.4623027463113107

Epoch: 6| Step: 2
Training loss: 2.5781021118164062
Validation loss: 2.475799111909764

Epoch: 6| Step: 3
Training loss: 2.757878303527832
Validation loss: 2.5375126536174486

Epoch: 6| Step: 4
Training loss: 3.3139238357543945
Validation loss: 2.5814048141561527

Epoch: 6| Step: 5
Training loss: 2.679966688156128
Validation loss: 2.541816396097983

Epoch: 6| Step: 6
Training loss: 2.8684298992156982
Validation loss: 2.471188827227521

Epoch: 6| Step: 7
Training loss: 3.1080846786499023
Validation loss: 2.4360373327808995

Epoch: 6| Step: 8
Training loss: 2.2214717864990234
Validation loss: 2.4268928368886313

Epoch: 6| Step: 9
Training loss: 2.1044344902038574
Validation loss: 2.433199195451634

Epoch: 6| Step: 10
Training loss: 2.3546042442321777
Validation loss: 2.4410371806031916

Epoch: 6| Step: 11
Training loss: 2.402456521987915
Validation loss: 2.4440312026649393

Epoch: 6| Step: 12
Training loss: 2.8786745071411133
Validation loss: 2.4436522888880905

Epoch: 6| Step: 13
Training loss: 3.290125846862793
Validation loss: 2.4307403410634687

Epoch: 55| Step: 0
Training loss: 2.9326181411743164
Validation loss: 2.420809022841915

Epoch: 6| Step: 1
Training loss: 2.384373188018799
Validation loss: 2.4252891989164453

Epoch: 6| Step: 2
Training loss: 2.868915557861328
Validation loss: 2.4472201024332354

Epoch: 6| Step: 3
Training loss: 2.643829822540283
Validation loss: 2.4510384913413756

Epoch: 6| Step: 4
Training loss: 2.0946154594421387
Validation loss: 2.4702243112748667

Epoch: 6| Step: 5
Training loss: 2.8243296146392822
Validation loss: 2.498721033014277

Epoch: 6| Step: 6
Training loss: 2.904865264892578
Validation loss: 2.4738626377556914

Epoch: 6| Step: 7
Training loss: 2.3632442951202393
Validation loss: 2.449671806827668

Epoch: 6| Step: 8
Training loss: 3.225342273712158
Validation loss: 2.4367084541628437

Epoch: 6| Step: 9
Training loss: 1.9950518608093262
Validation loss: 2.4323957812401558

Epoch: 6| Step: 10
Training loss: 2.6568660736083984
Validation loss: 2.425584759763492

Epoch: 6| Step: 11
Training loss: 2.8844809532165527
Validation loss: 2.424205736447406

Epoch: 6| Step: 12
Training loss: 2.804377317428589
Validation loss: 2.425133782048379

Epoch: 6| Step: 13
Training loss: 2.511223554611206
Validation loss: 2.4410080191909627

Epoch: 56| Step: 0
Training loss: 3.02337646484375
Validation loss: 2.4454248182235228

Epoch: 6| Step: 1
Training loss: 2.3688273429870605
Validation loss: 2.4624872963915587

Epoch: 6| Step: 2
Training loss: 2.636840343475342
Validation loss: 2.466033899655906

Epoch: 6| Step: 3
Training loss: 2.5392417907714844
Validation loss: 2.4633422461889123

Epoch: 6| Step: 4
Training loss: 2.2186203002929688
Validation loss: 2.4663733872034217

Epoch: 6| Step: 5
Training loss: 2.9987967014312744
Validation loss: 2.460257463557746

Epoch: 6| Step: 6
Training loss: 2.4200363159179688
Validation loss: 2.4457391282563568

Epoch: 6| Step: 7
Training loss: 3.0693507194519043
Validation loss: 2.4317506487651537

Epoch: 6| Step: 8
Training loss: 2.686960220336914
Validation loss: 2.422702755979312

Epoch: 6| Step: 9
Training loss: 2.855816602706909
Validation loss: 2.4233377031100694

Epoch: 6| Step: 10
Training loss: 2.9612505435943604
Validation loss: 2.4243728845350203

Epoch: 6| Step: 11
Training loss: 1.8406250476837158
Validation loss: 2.43290517919807

Epoch: 6| Step: 12
Training loss: 2.9665274620056152
Validation loss: 2.467743314722533

Epoch: 6| Step: 13
Training loss: 2.5755741596221924
Validation loss: 2.4884092730860554

Epoch: 57| Step: 0
Training loss: 2.429255962371826
Validation loss: 2.492009465412427

Epoch: 6| Step: 1
Training loss: 2.646625518798828
Validation loss: 2.496710656791605

Epoch: 6| Step: 2
Training loss: 3.0434398651123047
Validation loss: 2.5039610555095058

Epoch: 6| Step: 3
Training loss: 2.421070098876953
Validation loss: 2.5090420605033956

Epoch: 6| Step: 4
Training loss: 2.636167526245117
Validation loss: 2.520854906369281

Epoch: 6| Step: 5
Training loss: 2.323824882507324
Validation loss: 2.533625977013701

Epoch: 6| Step: 6
Training loss: 2.488222122192383
Validation loss: 2.540713543532997

Epoch: 6| Step: 7
Training loss: 2.992187738418579
Validation loss: 2.540113587533274

Epoch: 6| Step: 8
Training loss: 2.6542110443115234
Validation loss: 2.528099198495188

Epoch: 6| Step: 9
Training loss: 3.100186586380005
Validation loss: 2.5159535715656896

Epoch: 6| Step: 10
Training loss: 2.7147138118743896
Validation loss: 2.5069584949042207

Epoch: 6| Step: 11
Training loss: 3.051793336868286
Validation loss: 2.5016568014698644

Epoch: 6| Step: 12
Training loss: 2.798916816711426
Validation loss: 2.4964444252752487

Epoch: 6| Step: 13
Training loss: 2.3115904331207275
Validation loss: 2.498981750139626

Epoch: 58| Step: 0
Training loss: 2.8164520263671875
Validation loss: 2.505655660424181

Epoch: 6| Step: 1
Training loss: 2.5803942680358887
Validation loss: 2.501717500789191

Epoch: 6| Step: 2
Training loss: 2.641622304916382
Validation loss: 2.490818877373972

Epoch: 6| Step: 3
Training loss: 2.615260601043701
Validation loss: 2.485614566392796

Epoch: 6| Step: 4
Training loss: 3.170921802520752
Validation loss: 2.485590519443635

Epoch: 6| Step: 5
Training loss: 2.448791027069092
Validation loss: 2.4850704644315984

Epoch: 6| Step: 6
Training loss: 2.6950526237487793
Validation loss: 2.4800576343331286

Epoch: 6| Step: 7
Training loss: 2.3017337322235107
Validation loss: 2.4846187765880297

Epoch: 6| Step: 8
Training loss: 3.091242790222168
Validation loss: 2.4859087236465944

Epoch: 6| Step: 9
Training loss: 2.130767822265625
Validation loss: 2.4835894184727825

Epoch: 6| Step: 10
Training loss: 2.3732070922851562
Validation loss: 2.485607349744407

Epoch: 6| Step: 11
Training loss: 2.698190212249756
Validation loss: 2.4890469017849175

Epoch: 6| Step: 12
Training loss: 3.3559515476226807
Validation loss: 2.4932751783760647

Epoch: 6| Step: 13
Training loss: 2.492727041244507
Validation loss: 2.489803949991862

Epoch: 59| Step: 0
Training loss: 2.5594065189361572
Validation loss: 2.4912013905022734

Epoch: 6| Step: 1
Training loss: 3.2177529335021973
Validation loss: 2.4897216340546966

Epoch: 6| Step: 2
Training loss: 2.663262367248535
Validation loss: 2.4818292792125414

Epoch: 6| Step: 3
Training loss: 2.394305467605591
Validation loss: 2.4814934756166194

Epoch: 6| Step: 4
Training loss: 2.951478958129883
Validation loss: 2.473127865022229

Epoch: 6| Step: 5
Training loss: 2.1727681159973145
Validation loss: 2.4699234629190094

Epoch: 6| Step: 6
Training loss: 2.571431875228882
Validation loss: 2.466600082253897

Epoch: 6| Step: 7
Training loss: 2.538240671157837
Validation loss: 2.4730120115382697

Epoch: 6| Step: 8
Training loss: 2.7174177169799805
Validation loss: 2.4649274708122335

Epoch: 6| Step: 9
Training loss: 2.997035503387451
Validation loss: 2.4640736477349394

Epoch: 6| Step: 10
Training loss: 2.1430001258850098
Validation loss: 2.465947128111316

Epoch: 6| Step: 11
Training loss: 2.858588695526123
Validation loss: 2.4648083563773864

Epoch: 6| Step: 12
Training loss: 2.72342848777771
Validation loss: 2.467271953500727

Epoch: 6| Step: 13
Training loss: 3.308732271194458
Validation loss: 2.4700057198924403

Epoch: 60| Step: 0
Training loss: 1.4755843877792358
Validation loss: 2.464590541778072

Epoch: 6| Step: 1
Training loss: 2.4750800132751465
Validation loss: 2.476193258839269

Epoch: 6| Step: 2
Training loss: 2.7037689685821533
Validation loss: 2.47723957543732

Epoch: 6| Step: 3
Training loss: 2.733386754989624
Validation loss: 2.490085042932982

Epoch: 6| Step: 4
Training loss: 2.7896902561187744
Validation loss: 2.4908761593603317

Epoch: 6| Step: 5
Training loss: 2.43792724609375
Validation loss: 2.494213265757407

Epoch: 6| Step: 6
Training loss: 2.73012638092041
Validation loss: 2.508060989841338

Epoch: 6| Step: 7
Training loss: 3.1015355587005615
Validation loss: 2.5223715023327897

Epoch: 6| Step: 8
Training loss: 2.6138930320739746
Validation loss: 2.5146493117014566

Epoch: 6| Step: 9
Training loss: 2.5898356437683105
Validation loss: 2.4949986729570615

Epoch: 6| Step: 10
Training loss: 3.15695858001709
Validation loss: 2.477970643710065

Epoch: 6| Step: 11
Training loss: 3.6844024658203125
Validation loss: 2.4648088255236225

Epoch: 6| Step: 12
Training loss: 2.028623104095459
Validation loss: 2.460694843722928

Epoch: 6| Step: 13
Training loss: 3.312817096710205
Validation loss: 2.4575565015116045

Epoch: 61| Step: 0
Training loss: 3.105508804321289
Validation loss: 2.4577375586314867

Epoch: 6| Step: 1
Training loss: 2.677852153778076
Validation loss: 2.4589604229055424

Epoch: 6| Step: 2
Training loss: 2.3517496585845947
Validation loss: 2.4615055168828657

Epoch: 6| Step: 3
Training loss: 2.9373300075531006
Validation loss: 2.467223093073855

Epoch: 6| Step: 4
Training loss: 2.525581121444702
Validation loss: 2.4706032199244343

Epoch: 6| Step: 5
Training loss: 3.24155330657959
Validation loss: 2.4709455172220864

Epoch: 6| Step: 6
Training loss: 1.768740177154541
Validation loss: 2.481016948658933

Epoch: 6| Step: 7
Training loss: 2.2744998931884766
Validation loss: 2.475321453104737

Epoch: 6| Step: 8
Training loss: 2.675326347351074
Validation loss: 2.4742914169065413

Epoch: 6| Step: 9
Training loss: 2.6340532302856445
Validation loss: 2.464913527170817

Epoch: 6| Step: 10
Training loss: 3.002579927444458
Validation loss: 2.460400765941989

Epoch: 6| Step: 11
Training loss: 2.7382850646972656
Validation loss: 2.455024811529344

Epoch: 6| Step: 12
Training loss: 2.8736274242401123
Validation loss: 2.453071119964764

Epoch: 6| Step: 13
Training loss: 2.56081223487854
Validation loss: 2.4446679751078286

Epoch: 62| Step: 0
Training loss: 2.23043155670166
Validation loss: 2.448742066660235

Epoch: 6| Step: 1
Training loss: 3.2150917053222656
Validation loss: 2.4465909927122054

Epoch: 6| Step: 2
Training loss: 2.665459156036377
Validation loss: 2.4493388591274137

Epoch: 6| Step: 3
Training loss: 2.389824867248535
Validation loss: 2.454715762087094

Epoch: 6| Step: 4
Training loss: 2.8794662952423096
Validation loss: 2.4621264447448072

Epoch: 6| Step: 5
Training loss: 2.1543703079223633
Validation loss: 2.4609376358729538

Epoch: 6| Step: 6
Training loss: 2.7773566246032715
Validation loss: 2.44939281863551

Epoch: 6| Step: 7
Training loss: 2.7663822174072266
Validation loss: 2.4610414479368474

Epoch: 6| Step: 8
Training loss: 2.9355266094207764
Validation loss: 2.431106267436858

Epoch: 6| Step: 9
Training loss: 2.2580575942993164
Validation loss: 2.414361071842973

Epoch: 6| Step: 10
Training loss: 2.0482177734375
Validation loss: 2.4026093380425566

Epoch: 6| Step: 11
Training loss: 2.6772446632385254
Validation loss: 2.3895738586302726

Epoch: 6| Step: 12
Training loss: 3.3870890140533447
Validation loss: 2.3808372251449095

Epoch: 6| Step: 13
Training loss: 2.9610798358917236
Validation loss: 2.3766109558843795

Epoch: 63| Step: 0
Training loss: 3.8179917335510254
Validation loss: 2.3676583126027095

Epoch: 6| Step: 1
Training loss: 2.6284823417663574
Validation loss: 2.377794640038603

Epoch: 6| Step: 2
Training loss: 2.6753697395324707
Validation loss: 2.3853708826085573

Epoch: 6| Step: 3
Training loss: 2.538719654083252
Validation loss: 2.3812725082520516

Epoch: 6| Step: 4
Training loss: 2.2422618865966797
Validation loss: 2.368102083923996

Epoch: 6| Step: 5
Training loss: 2.830198287963867
Validation loss: 2.386645301695793

Epoch: 6| Step: 6
Training loss: 2.255443572998047
Validation loss: 2.3982869143127115

Epoch: 6| Step: 7
Training loss: 1.9783282279968262
Validation loss: 2.4272584966433945

Epoch: 6| Step: 8
Training loss: 3.6275064945220947
Validation loss: 2.4391065220679007

Epoch: 6| Step: 9
Training loss: 1.9690369367599487
Validation loss: 2.415734265440254

Epoch: 6| Step: 10
Training loss: 2.393059730529785
Validation loss: 2.3938598171357186

Epoch: 6| Step: 11
Training loss: 3.0308971405029297
Validation loss: 2.3827785676525486

Epoch: 6| Step: 12
Training loss: 2.713005781173706
Validation loss: 2.3780094064692014

Epoch: 6| Step: 13
Training loss: 2.254385471343994
Validation loss: 2.400876993774086

Epoch: 64| Step: 0
Training loss: 2.0804860591888428
Validation loss: 2.404170177316153

Epoch: 6| Step: 1
Training loss: 3.457392930984497
Validation loss: 2.403822413054846

Epoch: 6| Step: 2
Training loss: 2.6867566108703613
Validation loss: 2.401323213372179

Epoch: 6| Step: 3
Training loss: 2.0755245685577393
Validation loss: 2.4024629490349882

Epoch: 6| Step: 4
Training loss: 2.6584129333496094
Validation loss: 2.4039679701610277

Epoch: 6| Step: 5
Training loss: 2.4882047176361084
Validation loss: 2.404425205722932

Epoch: 6| Step: 6
Training loss: 2.4092931747436523
Validation loss: 2.4039611098586873

Epoch: 6| Step: 7
Training loss: 2.705288887023926
Validation loss: 2.404453768525072

Epoch: 6| Step: 8
Training loss: 2.978196620941162
Validation loss: 2.400020726265446

Epoch: 6| Step: 9
Training loss: 3.5910961627960205
Validation loss: 2.384651066154562

Epoch: 6| Step: 10
Training loss: 2.1342947483062744
Validation loss: 2.3728118481174594

Epoch: 6| Step: 11
Training loss: 2.5945611000061035
Validation loss: 2.3692446395915043

Epoch: 6| Step: 12
Training loss: 2.57315731048584
Validation loss: 2.3633612343060073

Epoch: 6| Step: 13
Training loss: 2.3854610919952393
Validation loss: 2.3580016192569526

Epoch: 65| Step: 0
Training loss: 2.6883363723754883
Validation loss: 2.359524234648674

Epoch: 6| Step: 1
Training loss: 2.7289211750030518
Validation loss: 2.360239285294728

Epoch: 6| Step: 2
Training loss: 2.7213597297668457
Validation loss: 2.3586038543332006

Epoch: 6| Step: 3
Training loss: 3.3488309383392334
Validation loss: 2.3574635277512255

Epoch: 6| Step: 4
Training loss: 2.8031492233276367
Validation loss: 2.3603318660489974

Epoch: 6| Step: 5
Training loss: 3.019947052001953
Validation loss: 2.363578739986625

Epoch: 6| Step: 6
Training loss: 3.0804762840270996
Validation loss: 2.3584347335241174

Epoch: 6| Step: 7
Training loss: 2.7429120540618896
Validation loss: 2.3587008086583947

Epoch: 6| Step: 8
Training loss: 2.1936168670654297
Validation loss: 2.3567794933114

Epoch: 6| Step: 9
Training loss: 2.3902149200439453
Validation loss: 2.3588375660680954

Epoch: 6| Step: 10
Training loss: 2.4516024589538574
Validation loss: 2.358686234361382

Epoch: 6| Step: 11
Training loss: 2.074049472808838
Validation loss: 2.3588829501982658

Epoch: 6| Step: 12
Training loss: 2.0562429428100586
Validation loss: 2.3673095651852187

Epoch: 6| Step: 13
Training loss: 2.290766716003418
Validation loss: 2.37464568948233

Epoch: 66| Step: 0
Training loss: 2.799286365509033
Validation loss: 2.3848183308878252

Epoch: 6| Step: 1
Training loss: 2.6982667446136475
Validation loss: 2.3847464335862028

Epoch: 6| Step: 2
Training loss: 1.9059979915618896
Validation loss: 2.386091245118008

Epoch: 6| Step: 3
Training loss: 1.893430233001709
Validation loss: 2.372564584978165

Epoch: 6| Step: 4
Training loss: 3.274357795715332
Validation loss: 2.373687549303937

Epoch: 6| Step: 5
Training loss: 2.2046265602111816
Validation loss: 2.3695222921268915

Epoch: 6| Step: 6
Training loss: 3.058436393737793
Validation loss: 2.3626625742963565

Epoch: 6| Step: 7
Training loss: 2.918266534805298
Validation loss: 2.363432550943026

Epoch: 6| Step: 8
Training loss: 2.6954617500305176
Validation loss: 2.37391903579876

Epoch: 6| Step: 9
Training loss: 2.3067421913146973
Validation loss: 2.388982998427524

Epoch: 6| Step: 10
Training loss: 2.6450953483581543
Validation loss: 2.407019594664215

Epoch: 6| Step: 11
Training loss: 2.8355090618133545
Validation loss: 2.4340442534415954

Epoch: 6| Step: 12
Training loss: 2.2540125846862793
Validation loss: 2.4670101699008735

Epoch: 6| Step: 13
Training loss: 3.775974750518799
Validation loss: 2.4403333151212303

Epoch: 67| Step: 0
Training loss: 2.8660290241241455
Validation loss: 2.4190138052868586

Epoch: 6| Step: 1
Training loss: 2.27664852142334
Validation loss: 2.3716022917019424

Epoch: 6| Step: 2
Training loss: 2.718038320541382
Validation loss: 2.360974242610316

Epoch: 6| Step: 3
Training loss: 2.454596519470215
Validation loss: 2.3612616062164307

Epoch: 6| Step: 4
Training loss: 2.4555752277374268
Validation loss: 2.3587928638663342

Epoch: 6| Step: 5
Training loss: 2.765956163406372
Validation loss: 2.3845335155405025

Epoch: 6| Step: 6
Training loss: 2.7420010566711426
Validation loss: 2.393121214323146

Epoch: 6| Step: 7
Training loss: 2.582909345626831
Validation loss: 2.4345602143195366

Epoch: 6| Step: 8
Training loss: 2.2145915031433105
Validation loss: 2.452164611508769

Epoch: 6| Step: 9
Training loss: 3.318483352661133
Validation loss: 2.473748163510394

Epoch: 6| Step: 10
Training loss: 2.294860363006592
Validation loss: 2.4821742196236887

Epoch: 6| Step: 11
Training loss: 3.0252933502197266
Validation loss: 2.44286895567371

Epoch: 6| Step: 12
Training loss: 2.947768211364746
Validation loss: 2.4025978119142595

Epoch: 6| Step: 13
Training loss: 2.248992681503296
Validation loss: 2.3707971342148317

Epoch: 68| Step: 0
Training loss: 2.3684957027435303
Validation loss: 2.3542299091175036

Epoch: 6| Step: 1
Training loss: 1.9601027965545654
Validation loss: 2.347234820806852

Epoch: 6| Step: 2
Training loss: 2.6566896438598633
Validation loss: 2.343413673421388

Epoch: 6| Step: 3
Training loss: 2.868837594985962
Validation loss: 2.3466814923030075

Epoch: 6| Step: 4
Training loss: 2.720370292663574
Validation loss: 2.347123053766066

Epoch: 6| Step: 5
Training loss: 2.7376484870910645
Validation loss: 2.3526754122908398

Epoch: 6| Step: 6
Training loss: 3.2981925010681152
Validation loss: 2.361658493677775

Epoch: 6| Step: 7
Training loss: 2.2224128246307373
Validation loss: 2.3853571799493607

Epoch: 6| Step: 8
Training loss: 2.198307991027832
Validation loss: 2.3961290056987474

Epoch: 6| Step: 9
Training loss: 2.860546350479126
Validation loss: 2.4112996298779725

Epoch: 6| Step: 10
Training loss: 2.9481444358825684
Validation loss: 2.3780246626946235

Epoch: 6| Step: 11
Training loss: 3.0595641136169434
Validation loss: 2.356708521484047

Epoch: 6| Step: 12
Training loss: 2.5306029319763184
Validation loss: 2.3417442883214643

Epoch: 6| Step: 13
Training loss: 2.4011058807373047
Validation loss: 2.3421888171985583

Epoch: 69| Step: 0
Training loss: 2.784623146057129
Validation loss: 2.3423153405548423

Epoch: 6| Step: 1
Training loss: 2.211559295654297
Validation loss: 2.33622827324816

Epoch: 6| Step: 2
Training loss: 1.8976854085922241
Validation loss: 2.3406759128775647

Epoch: 6| Step: 3
Training loss: 3.0580410957336426
Validation loss: 2.3418190197278093

Epoch: 6| Step: 4
Training loss: 2.4419522285461426
Validation loss: 2.358853586258427

Epoch: 6| Step: 5
Training loss: 3.0171260833740234
Validation loss: 2.3799519385060957

Epoch: 6| Step: 6
Training loss: 2.280333995819092
Validation loss: 2.4139414320709887

Epoch: 6| Step: 7
Training loss: 2.008284091949463
Validation loss: 2.4109041280643915

Epoch: 6| Step: 8
Training loss: 3.367530107498169
Validation loss: 2.3953298932762555

Epoch: 6| Step: 9
Training loss: 3.083223819732666
Validation loss: 2.3841916694436023

Epoch: 6| Step: 10
Training loss: 2.77256441116333
Validation loss: 2.371088074099633

Epoch: 6| Step: 11
Training loss: 2.488345146179199
Validation loss: 2.3566764529033373

Epoch: 6| Step: 12
Training loss: 2.158367395401001
Validation loss: 2.3532440277837936

Epoch: 6| Step: 13
Training loss: 3.743535041809082
Validation loss: 2.349688991423576

Epoch: 70| Step: 0
Training loss: 2.4909043312072754
Validation loss: 2.344820558383901

Epoch: 6| Step: 1
Training loss: 3.3210036754608154
Validation loss: 2.3514631473889915

Epoch: 6| Step: 2
Training loss: 2.2325851917266846
Validation loss: 2.3641300560325704

Epoch: 6| Step: 3
Training loss: 2.7326934337615967
Validation loss: 2.3771601569268013

Epoch: 6| Step: 4
Training loss: 2.3923416137695312
Validation loss: 2.392358018505958

Epoch: 6| Step: 5
Training loss: 2.9018969535827637
Validation loss: 2.354856188579272

Epoch: 6| Step: 6
Training loss: 2.535348415374756
Validation loss: 2.351538642760246

Epoch: 6| Step: 7
Training loss: 2.202566623687744
Validation loss: 2.362462415490099

Epoch: 6| Step: 8
Training loss: 2.118166446685791
Validation loss: 2.376294864121304

Epoch: 6| Step: 9
Training loss: 2.2075564861297607
Validation loss: 2.3936045067284697

Epoch: 6| Step: 10
Training loss: 2.128514051437378
Validation loss: 2.4151772581120974

Epoch: 6| Step: 11
Training loss: 3.074040651321411
Validation loss: 2.447119951248169

Epoch: 6| Step: 12
Training loss: 3.0483953952789307
Validation loss: 2.4844371862308954

Epoch: 6| Step: 13
Training loss: 4.196916580200195
Validation loss: 2.437294008911297

Epoch: 71| Step: 0
Training loss: 2.971867561340332
Validation loss: 2.402448632383859

Epoch: 6| Step: 1
Training loss: 2.0390498638153076
Validation loss: 2.377842285299814

Epoch: 6| Step: 2
Training loss: 2.507978916168213
Validation loss: 2.355705004866405

Epoch: 6| Step: 3
Training loss: 2.211674213409424
Validation loss: 2.3464844021745908

Epoch: 6| Step: 4
Training loss: 2.451773166656494
Validation loss: 2.3353822462020384

Epoch: 6| Step: 5
Training loss: 3.211636543273926
Validation loss: 2.340856808488087

Epoch: 6| Step: 6
Training loss: 3.000661611557007
Validation loss: 2.339195730865643

Epoch: 6| Step: 7
Training loss: 2.464048385620117
Validation loss: 2.344935845303279

Epoch: 6| Step: 8
Training loss: 2.4272825717926025
Validation loss: 2.3472895955526702

Epoch: 6| Step: 9
Training loss: 2.664403200149536
Validation loss: 2.3457700796024774

Epoch: 6| Step: 10
Training loss: 2.9813766479492188
Validation loss: 2.357924827965357

Epoch: 6| Step: 11
Training loss: 3.1973578929901123
Validation loss: 2.378953536351522

Epoch: 6| Step: 12
Training loss: 2.062811851501465
Validation loss: 2.387015709313013

Epoch: 6| Step: 13
Training loss: 2.5820038318634033
Validation loss: 2.390094849371141

Epoch: 72| Step: 0
Training loss: 3.035275459289551
Validation loss: 2.418261751051872

Epoch: 6| Step: 1
Training loss: 2.9883840084075928
Validation loss: 2.4247319211242018

Epoch: 6| Step: 2
Training loss: 3.2874927520751953
Validation loss: 2.4300186300790436

Epoch: 6| Step: 3
Training loss: 1.858499526977539
Validation loss: 2.4066471386981267

Epoch: 6| Step: 4
Training loss: 2.3018388748168945
Validation loss: 2.3600307331290296

Epoch: 6| Step: 5
Training loss: 3.0309834480285645
Validation loss: 2.3374188202683643

Epoch: 6| Step: 6
Training loss: 2.2734375
Validation loss: 2.3411117266583186

Epoch: 6| Step: 7
Training loss: 2.1073174476623535
Validation loss: 2.3435677072053314

Epoch: 6| Step: 8
Training loss: 3.201833724975586
Validation loss: 2.350027238169024

Epoch: 6| Step: 9
Training loss: 3.0890467166900635
Validation loss: 2.3676399569357596

Epoch: 6| Step: 10
Training loss: 2.216695785522461
Validation loss: 2.383801209029331

Epoch: 6| Step: 11
Training loss: 2.617405652999878
Validation loss: 2.3773671016898206

Epoch: 6| Step: 12
Training loss: 2.1545937061309814
Validation loss: 2.381031108158891

Epoch: 6| Step: 13
Training loss: 2.3849737644195557
Validation loss: 2.3798712556080153

Epoch: 73| Step: 0
Training loss: 2.4274284839630127
Validation loss: 2.3604568896755094

Epoch: 6| Step: 1
Training loss: 1.8700547218322754
Validation loss: 2.3591599695144163

Epoch: 6| Step: 2
Training loss: 2.7641048431396484
Validation loss: 2.3569440431492303

Epoch: 6| Step: 3
Training loss: 2.8876819610595703
Validation loss: 2.3613818922350482

Epoch: 6| Step: 4
Training loss: 2.8559153079986572
Validation loss: 2.3711847002788256

Epoch: 6| Step: 5
Training loss: 1.9253432750701904
Validation loss: 2.365066418083765

Epoch: 6| Step: 6
Training loss: 3.040020704269409
Validation loss: 2.3695469979316957

Epoch: 6| Step: 7
Training loss: 3.1313657760620117
Validation loss: 2.374446709950765

Epoch: 6| Step: 8
Training loss: 2.350865364074707
Validation loss: 2.37713623046875

Epoch: 6| Step: 9
Training loss: 2.5088510513305664
Validation loss: 2.3669699494556715

Epoch: 6| Step: 10
Training loss: 3.699462413787842
Validation loss: 2.367860991467712

Epoch: 6| Step: 11
Training loss: 1.6131784915924072
Validation loss: 2.3652472649851153

Epoch: 6| Step: 12
Training loss: 2.6509134769439697
Validation loss: 2.3681337884677354

Epoch: 6| Step: 13
Training loss: 3.1632776260375977
Validation loss: 2.388311457890336

Epoch: 74| Step: 0
Training loss: 2.413867473602295
Validation loss: 2.4169863090720227

Epoch: 6| Step: 1
Training loss: 3.045492649078369
Validation loss: 2.4122665825710503

Epoch: 6| Step: 2
Training loss: 1.9690182209014893
Validation loss: 2.4104272114333285

Epoch: 6| Step: 3
Training loss: 2.325430393218994
Validation loss: 2.407690335345525

Epoch: 6| Step: 4
Training loss: 2.3281030654907227
Validation loss: 2.4104089044755503

Epoch: 6| Step: 5
Training loss: 2.196455478668213
Validation loss: 2.421057144800822

Epoch: 6| Step: 6
Training loss: 2.9652881622314453
Validation loss: 2.396044049211728

Epoch: 6| Step: 7
Training loss: 2.946007251739502
Validation loss: 2.359519879023234

Epoch: 6| Step: 8
Training loss: 3.0641164779663086
Validation loss: 2.3252049799888366

Epoch: 6| Step: 9
Training loss: 2.5080156326293945
Validation loss: 2.305947883154756

Epoch: 6| Step: 10
Training loss: 3.568845748901367
Validation loss: 2.302198927889588

Epoch: 6| Step: 11
Training loss: 2.1649725437164307
Validation loss: 2.2994714449810725

Epoch: 6| Step: 12
Training loss: 2.6848995685577393
Validation loss: 2.3040234696480537

Epoch: 6| Step: 13
Training loss: 2.176947832107544
Validation loss: 2.3041936095042894

Epoch: 75| Step: 0
Training loss: 3.0251903533935547
Validation loss: 2.3074914614359536

Epoch: 6| Step: 1
Training loss: 2.878253698348999
Validation loss: 2.3113674912401425

Epoch: 6| Step: 2
Training loss: 3.0503602027893066
Validation loss: 2.31069081060348

Epoch: 6| Step: 3
Training loss: 2.1510682106018066
Validation loss: 2.3045932759520826

Epoch: 6| Step: 4
Training loss: 2.497966766357422
Validation loss: 2.2975654678960002

Epoch: 6| Step: 5
Training loss: 2.7540524005889893
Validation loss: 2.296739770520118

Epoch: 6| Step: 6
Training loss: 2.556154727935791
Validation loss: 2.2942182812639462

Epoch: 6| Step: 7
Training loss: 2.3362791538238525
Validation loss: 2.2946217931726927

Epoch: 6| Step: 8
Training loss: 3.0895774364471436
Validation loss: 2.298472450625512

Epoch: 6| Step: 9
Training loss: 3.0902318954467773
Validation loss: 2.2988007683907785

Epoch: 6| Step: 10
Training loss: 2.1586427688598633
Validation loss: 2.3029974250383276

Epoch: 6| Step: 11
Training loss: 2.4508306980133057
Validation loss: 2.3132939953957834

Epoch: 6| Step: 12
Training loss: 1.975395679473877
Validation loss: 2.316800166201848

Epoch: 6| Step: 13
Training loss: 2.0801377296447754
Validation loss: 2.339758132093696

Epoch: 76| Step: 0
Training loss: 2.643322229385376
Validation loss: 2.358171352776148

Epoch: 6| Step: 1
Training loss: 3.2868094444274902
Validation loss: 2.350122085181616

Epoch: 6| Step: 2
Training loss: 3.1881203651428223
Validation loss: 2.3408463936980053

Epoch: 6| Step: 3
Training loss: 2.2849745750427246
Validation loss: 2.333975826540301

Epoch: 6| Step: 4
Training loss: 2.2968103885650635
Validation loss: 2.336730226393669

Epoch: 6| Step: 5
Training loss: 3.1659793853759766
Validation loss: 2.3421689464199926

Epoch: 6| Step: 6
Training loss: 2.295687198638916
Validation loss: 2.3349528902320453

Epoch: 6| Step: 7
Training loss: 1.8497192859649658
Validation loss: 2.3389409280592397

Epoch: 6| Step: 8
Training loss: 2.519570827484131
Validation loss: 2.333936891248149

Epoch: 6| Step: 9
Training loss: 2.9191699028015137
Validation loss: 2.313966363988897

Epoch: 6| Step: 10
Training loss: 2.2903692722320557
Validation loss: 2.3074395297676005

Epoch: 6| Step: 11
Training loss: 2.686666965484619
Validation loss: 2.297604573670254

Epoch: 6| Step: 12
Training loss: 2.510087728500366
Validation loss: 2.2897307744590183

Epoch: 6| Step: 13
Training loss: 2.1276843547821045
Validation loss: 2.290520577020543

Epoch: 77| Step: 0
Training loss: 3.2138290405273438
Validation loss: 2.303108323004938

Epoch: 6| Step: 1
Training loss: 2.684232711791992
Validation loss: 2.3065594473192768

Epoch: 6| Step: 2
Training loss: 1.7102627754211426
Validation loss: 2.317937507424303

Epoch: 6| Step: 3
Training loss: 1.733729362487793
Validation loss: 2.328020085570633

Epoch: 6| Step: 4
Training loss: 2.7342889308929443
Validation loss: 2.3416840722483974

Epoch: 6| Step: 5
Training loss: 2.1352968215942383
Validation loss: 2.3463289327518915

Epoch: 6| Step: 6
Training loss: 1.9375131130218506
Validation loss: 2.330138511555169

Epoch: 6| Step: 7
Training loss: 3.0000038146972656
Validation loss: 2.320956971055718

Epoch: 6| Step: 8
Training loss: 2.5860466957092285
Validation loss: 2.315464573521768

Epoch: 6| Step: 9
Training loss: 3.401839017868042
Validation loss: 2.3292420128340363

Epoch: 6| Step: 10
Training loss: 2.941235065460205
Validation loss: 2.3296170824317524

Epoch: 6| Step: 11
Training loss: 2.2827465534210205
Validation loss: 2.3534923266339045

Epoch: 6| Step: 12
Training loss: 2.8279080390930176
Validation loss: 2.392030546742101

Epoch: 6| Step: 13
Training loss: 3.578685760498047
Validation loss: 2.4465451291812363

Epoch: 78| Step: 0
Training loss: 3.0405073165893555
Validation loss: 2.394857111797538

Epoch: 6| Step: 1
Training loss: 2.3246207237243652
Validation loss: 2.339552720387777

Epoch: 6| Step: 2
Training loss: 2.7180235385894775
Validation loss: 2.312545271329982

Epoch: 6| Step: 3
Training loss: 1.7258830070495605
Validation loss: 2.2983460836513068

Epoch: 6| Step: 4
Training loss: 3.3541431427001953
Validation loss: 2.3073760014708324

Epoch: 6| Step: 5
Training loss: 1.9858578443527222
Validation loss: 2.3059403409240065

Epoch: 6| Step: 6
Training loss: 2.941101551055908
Validation loss: 2.3238859843182307

Epoch: 6| Step: 7
Training loss: 2.9547247886657715
Validation loss: 2.322680724564419

Epoch: 6| Step: 8
Training loss: 2.319070816040039
Validation loss: 2.334666023972214

Epoch: 6| Step: 9
Training loss: 2.555243968963623
Validation loss: 2.349017425249982

Epoch: 6| Step: 10
Training loss: 2.0203542709350586
Validation loss: 2.360533227202713

Epoch: 6| Step: 11
Training loss: 2.6751413345336914
Validation loss: 2.386837941344066

Epoch: 6| Step: 12
Training loss: 3.111571788787842
Validation loss: 2.41645719159034

Epoch: 6| Step: 13
Training loss: 2.579949140548706
Validation loss: 2.444450537363688

Epoch: 79| Step: 0
Training loss: 1.8640786409378052
Validation loss: 2.411032735660512

Epoch: 6| Step: 1
Training loss: 2.2711422443389893
Validation loss: 2.3954111478661977

Epoch: 6| Step: 2
Training loss: 2.640526056289673
Validation loss: 2.3689590346428657

Epoch: 6| Step: 3
Training loss: 3.0466158390045166
Validation loss: 2.328692379818168

Epoch: 6| Step: 4
Training loss: 2.594999313354492
Validation loss: 2.3151845932006836

Epoch: 6| Step: 5
Training loss: 2.4953715801239014
Validation loss: 2.3050109699208248

Epoch: 6| Step: 6
Training loss: 2.6671810150146484
Validation loss: 2.3061595091255764

Epoch: 6| Step: 7
Training loss: 2.476381301879883
Validation loss: 2.314382066008865

Epoch: 6| Step: 8
Training loss: 3.279470920562744
Validation loss: 2.313661753490407

Epoch: 6| Step: 9
Training loss: 2.9737515449523926
Validation loss: 2.2979115311817457

Epoch: 6| Step: 10
Training loss: 2.155587673187256
Validation loss: 2.28649648286963

Epoch: 6| Step: 11
Training loss: 2.5363364219665527
Validation loss: 2.2847736625261206

Epoch: 6| Step: 12
Training loss: 2.481250762939453
Validation loss: 2.2775640026215584

Epoch: 6| Step: 13
Training loss: 2.7777414321899414
Validation loss: 2.277907858612717

Epoch: 80| Step: 0
Training loss: 2.275683641433716
Validation loss: 2.2906474528774137

Epoch: 6| Step: 1
Training loss: 2.410698890686035
Validation loss: 2.314071568109656

Epoch: 6| Step: 2
Training loss: 2.674550771713257
Validation loss: 2.3389620191307476

Epoch: 6| Step: 3
Training loss: 3.0294859409332275
Validation loss: 2.351364634370291

Epoch: 6| Step: 4
Training loss: 2.778125762939453
Validation loss: 2.402532398059804

Epoch: 6| Step: 5
Training loss: 2.4502925872802734
Validation loss: 2.3797002979504165

Epoch: 6| Step: 6
Training loss: 2.8149490356445312
Validation loss: 2.3515160622135287

Epoch: 6| Step: 7
Training loss: 2.8130693435668945
Validation loss: 2.3058391540281233

Epoch: 6| Step: 8
Training loss: 2.6099443435668945
Validation loss: 2.2843735064229658

Epoch: 6| Step: 9
Training loss: 3.1134605407714844
Validation loss: 2.2698349798879316

Epoch: 6| Step: 10
Training loss: 2.8250436782836914
Validation loss: 2.2734858194986978

Epoch: 6| Step: 11
Training loss: 2.4366912841796875
Validation loss: 2.271341395634477

Epoch: 6| Step: 12
Training loss: 1.9670941829681396
Validation loss: 2.2734555352118706

Epoch: 6| Step: 13
Training loss: 1.7868238687515259
Validation loss: 2.2746361660700973

Epoch: 81| Step: 0
Training loss: 2.092205047607422
Validation loss: 2.272072207543158

Epoch: 6| Step: 1
Training loss: 2.6759421825408936
Validation loss: 2.270296742839198

Epoch: 6| Step: 2
Training loss: 1.4156646728515625
Validation loss: 2.2693327088509836

Epoch: 6| Step: 3
Training loss: 2.905032157897949
Validation loss: 2.2833477361227876

Epoch: 6| Step: 4
Training loss: 3.2117791175842285
Validation loss: 2.291669835326492

Epoch: 6| Step: 5
Training loss: 2.2366974353790283
Validation loss: 2.317734210721908

Epoch: 6| Step: 6
Training loss: 2.7106714248657227
Validation loss: 2.3428755447428715

Epoch: 6| Step: 7
Training loss: 3.3039214611053467
Validation loss: 2.366579226268235

Epoch: 6| Step: 8
Training loss: 2.5294430255889893
Validation loss: 2.3296458849342923

Epoch: 6| Step: 9
Training loss: 2.616865634918213
Validation loss: 2.3101746792434366

Epoch: 6| Step: 10
Training loss: 3.127429723739624
Validation loss: 2.2945758886234735

Epoch: 6| Step: 11
Training loss: 2.9571049213409424
Validation loss: 2.285061018441313

Epoch: 6| Step: 12
Training loss: 2.109374761581421
Validation loss: 2.2774673226059123

Epoch: 6| Step: 13
Training loss: 1.8661022186279297
Validation loss: 2.2744444570233746

Epoch: 82| Step: 0
Training loss: 2.5958445072174072
Validation loss: 2.27519820069754

Epoch: 6| Step: 1
Training loss: 2.562389850616455
Validation loss: 2.2681144847664783

Epoch: 6| Step: 2
Training loss: 2.1924386024475098
Validation loss: 2.2646119030573035

Epoch: 6| Step: 3
Training loss: 2.78830885887146
Validation loss: 2.266779148450462

Epoch: 6| Step: 4
Training loss: 3.028289556503296
Validation loss: 2.268784772965216

Epoch: 6| Step: 5
Training loss: 3.3579115867614746
Validation loss: 2.268972626296423

Epoch: 6| Step: 6
Training loss: 2.2842040061950684
Validation loss: 2.267097257798718

Epoch: 6| Step: 7
Training loss: 2.814289093017578
Validation loss: 2.264293768072641

Epoch: 6| Step: 8
Training loss: 2.554104804992676
Validation loss: 2.2767024347859044

Epoch: 6| Step: 9
Training loss: 3.169287919998169
Validation loss: 2.29537041982015

Epoch: 6| Step: 10
Training loss: 2.2228891849517822
Validation loss: 2.3042102834229827

Epoch: 6| Step: 11
Training loss: 1.8758037090301514
Validation loss: 2.304418602297383

Epoch: 6| Step: 12
Training loss: 2.120940685272217
Validation loss: 2.309195077547463

Epoch: 6| Step: 13
Training loss: 2.4010331630706787
Validation loss: 2.3012492631071355

Epoch: 83| Step: 0
Training loss: 2.702174663543701
Validation loss: 2.298003994008546

Epoch: 6| Step: 1
Training loss: 2.5500073432922363
Validation loss: 2.2907224368023615

Epoch: 6| Step: 2
Training loss: 2.8292369842529297
Validation loss: 2.2802046524581088

Epoch: 6| Step: 3
Training loss: 2.731093168258667
Validation loss: 2.2845763288518435

Epoch: 6| Step: 4
Training loss: 2.2736449241638184
Validation loss: 2.289290266652261

Epoch: 6| Step: 5
Training loss: 2.587223529815674
Validation loss: 2.296768673004643

Epoch: 6| Step: 6
Training loss: 2.1240689754486084
Validation loss: 2.3056428893919914

Epoch: 6| Step: 7
Training loss: 2.1552205085754395
Validation loss: 2.308055067575106

Epoch: 6| Step: 8
Training loss: 2.2661118507385254
Validation loss: 2.3250734934242825

Epoch: 6| Step: 9
Training loss: 3.3602170944213867
Validation loss: 2.324570261022096

Epoch: 6| Step: 10
Training loss: 2.5673437118530273
Validation loss: 2.32032258536226

Epoch: 6| Step: 11
Training loss: 3.1168346405029297
Validation loss: 2.3171387667297036

Epoch: 6| Step: 12
Training loss: 2.3844332695007324
Validation loss: 2.3165711561838784

Epoch: 6| Step: 13
Training loss: 1.9247750043869019
Validation loss: 2.3267408237662366

Epoch: 84| Step: 0
Training loss: 1.690342664718628
Validation loss: 2.3317129176150084

Epoch: 6| Step: 1
Training loss: 2.213552713394165
Validation loss: 2.3307762389541953

Epoch: 6| Step: 2
Training loss: 3.105923652648926
Validation loss: 2.325879494990072

Epoch: 6| Step: 3
Training loss: 2.7094180583953857
Validation loss: 2.3271496026746687

Epoch: 6| Step: 4
Training loss: 2.3291773796081543
Validation loss: 2.2979705077345653

Epoch: 6| Step: 5
Training loss: 2.138526439666748
Validation loss: 2.289599262258058

Epoch: 6| Step: 6
Training loss: 2.1394705772399902
Validation loss: 2.2942267258961997

Epoch: 6| Step: 7
Training loss: 2.8531277179718018
Validation loss: 2.2909299519754227

Epoch: 6| Step: 8
Training loss: 3.6449053287506104
Validation loss: 2.2890459004268853

Epoch: 6| Step: 9
Training loss: 2.9606590270996094
Validation loss: 2.2842335072896813

Epoch: 6| Step: 10
Training loss: 2.2895381450653076
Validation loss: 2.2873847125678934

Epoch: 6| Step: 11
Training loss: 2.1748228073120117
Validation loss: 2.279645566017397

Epoch: 6| Step: 12
Training loss: 2.8595919609069824
Validation loss: 2.276543660830426

Epoch: 6| Step: 13
Training loss: 2.7409074306488037
Validation loss: 2.2665371330835486

Epoch: 85| Step: 0
Training loss: 2.9900293350219727
Validation loss: 2.259433687374156

Epoch: 6| Step: 1
Training loss: 2.7961320877075195
Validation loss: 2.2568251881548154

Epoch: 6| Step: 2
Training loss: 2.5598344802856445
Validation loss: 2.249768885233069

Epoch: 6| Step: 3
Training loss: 1.8893271684646606
Validation loss: 2.2534886483223207

Epoch: 6| Step: 4
Training loss: 2.4410014152526855
Validation loss: 2.2575849204935055

Epoch: 6| Step: 5
Training loss: 2.015556812286377
Validation loss: 2.2587516359103623

Epoch: 6| Step: 6
Training loss: 2.6418910026550293
Validation loss: 2.2617739541556245

Epoch: 6| Step: 7
Training loss: 3.0861716270446777
Validation loss: 2.2631530223354215

Epoch: 6| Step: 8
Training loss: 2.913679361343384
Validation loss: 2.2625470699802523

Epoch: 6| Step: 9
Training loss: 1.7370562553405762
Validation loss: 2.2588216643179617

Epoch: 6| Step: 10
Training loss: 2.3371760845184326
Validation loss: 2.254822149071642

Epoch: 6| Step: 11
Training loss: 2.577871084213257
Validation loss: 2.250450704687385

Epoch: 6| Step: 12
Training loss: 2.699934959411621
Validation loss: 2.251162467464324

Epoch: 6| Step: 13
Training loss: 3.4659628868103027
Validation loss: 2.2494320715627363

Epoch: 86| Step: 0
Training loss: 3.2373056411743164
Validation loss: 2.24653063666436

Epoch: 6| Step: 1
Training loss: 2.6465487480163574
Validation loss: 2.245338936005869

Epoch: 6| Step: 2
Training loss: 2.49798583984375
Validation loss: 2.2448803019779984

Epoch: 6| Step: 3
Training loss: 2.024258852005005
Validation loss: 2.2429386082515923

Epoch: 6| Step: 4
Training loss: 2.6190240383148193
Validation loss: 2.240627642600767

Epoch: 6| Step: 5
Training loss: 3.346835136413574
Validation loss: 2.240254904634209

Epoch: 6| Step: 6
Training loss: 2.4615628719329834
Validation loss: 2.241815987453666

Epoch: 6| Step: 7
Training loss: 1.7948310375213623
Validation loss: 2.2457904123490855

Epoch: 6| Step: 8
Training loss: 2.041140556335449
Validation loss: 2.2445297548847813

Epoch: 6| Step: 9
Training loss: 2.195159673690796
Validation loss: 2.266190508360504

Epoch: 6| Step: 10
Training loss: 2.638874053955078
Validation loss: 2.281033641548567

Epoch: 6| Step: 11
Training loss: 3.1257739067077637
Validation loss: 2.306236154289656

Epoch: 6| Step: 12
Training loss: 3.083970308303833
Validation loss: 2.313830621780888

Epoch: 6| Step: 13
Training loss: 1.7079683542251587
Validation loss: 2.3002965245195615

Epoch: 87| Step: 0
Training loss: 2.374420166015625
Validation loss: 2.2981063627427623

Epoch: 6| Step: 1
Training loss: 2.4345130920410156
Validation loss: 2.293420043042911

Epoch: 6| Step: 2
Training loss: 2.4787344932556152
Validation loss: 2.2717975160127044

Epoch: 6| Step: 3
Training loss: 3.5903077125549316
Validation loss: 2.269049293251448

Epoch: 6| Step: 4
Training loss: 3.194188117980957
Validation loss: 2.2524383452630814

Epoch: 6| Step: 5
Training loss: 3.213918685913086
Validation loss: 2.2357249362494356

Epoch: 6| Step: 6
Training loss: 2.6099705696105957
Validation loss: 2.239318819456203

Epoch: 6| Step: 7
Training loss: 2.345600128173828
Validation loss: 2.2404717527410036

Epoch: 6| Step: 8
Training loss: 2.816739082336426
Validation loss: 2.2405839761098227

Epoch: 6| Step: 9
Training loss: 2.127664566040039
Validation loss: 2.24341143074856

Epoch: 6| Step: 10
Training loss: 2.0716214179992676
Validation loss: 2.2449162660106534

Epoch: 6| Step: 11
Training loss: 2.455080270767212
Validation loss: 2.2451058049355783

Epoch: 6| Step: 12
Training loss: 2.105271816253662
Validation loss: 2.246664135686813

Epoch: 6| Step: 13
Training loss: 1.5346529483795166
Validation loss: 2.2419813166382494

Epoch: 88| Step: 0
Training loss: 2.576519012451172
Validation loss: 2.237825278312929

Epoch: 6| Step: 1
Training loss: 2.4272427558898926
Validation loss: 2.2375207639509633

Epoch: 6| Step: 2
Training loss: 2.803926944732666
Validation loss: 2.239998561079784

Epoch: 6| Step: 3
Training loss: 2.3994555473327637
Validation loss: 2.2530987749817553

Epoch: 6| Step: 4
Training loss: 2.6122913360595703
Validation loss: 2.263772045412371

Epoch: 6| Step: 5
Training loss: 2.570422649383545
Validation loss: 2.2882232742924846

Epoch: 6| Step: 6
Training loss: 2.6968417167663574
Validation loss: 2.313802647334273

Epoch: 6| Step: 7
Training loss: 1.7424893379211426
Validation loss: 2.3226403741426367

Epoch: 6| Step: 8
Training loss: 2.9033637046813965
Validation loss: 2.3246802873508905

Epoch: 6| Step: 9
Training loss: 2.5350308418273926
Validation loss: 2.3310888172477804

Epoch: 6| Step: 10
Training loss: 2.761749267578125
Validation loss: 2.3222095786884265

Epoch: 6| Step: 11
Training loss: 2.63942289352417
Validation loss: 2.314828690662179

Epoch: 6| Step: 12
Training loss: 2.213118076324463
Validation loss: 2.291652951189267

Epoch: 6| Step: 13
Training loss: 3.42679500579834
Validation loss: 2.271529528402513

Epoch: 89| Step: 0
Training loss: 2.7558798789978027
Validation loss: 2.253606709100867

Epoch: 6| Step: 1
Training loss: 2.0533969402313232
Validation loss: 2.243548108685401

Epoch: 6| Step: 2
Training loss: 3.0140380859375
Validation loss: 2.2419982956301783

Epoch: 6| Step: 3
Training loss: 2.752964496612549
Validation loss: 2.2384297617020144

Epoch: 6| Step: 4
Training loss: 2.6816811561584473
Validation loss: 2.2363495698539158

Epoch: 6| Step: 5
Training loss: 2.8919317722320557
Validation loss: 2.238670192739015

Epoch: 6| Step: 6
Training loss: 2.7967262268066406
Validation loss: 2.2483037287189114

Epoch: 6| Step: 7
Training loss: 2.668668746948242
Validation loss: 2.250404547619563

Epoch: 6| Step: 8
Training loss: 2.507462978363037
Validation loss: 2.243330673504901

Epoch: 6| Step: 9
Training loss: 2.0111708641052246
Validation loss: 2.2421162436085362

Epoch: 6| Step: 10
Training loss: 2.3298187255859375
Validation loss: 2.2543273407925843

Epoch: 6| Step: 11
Training loss: 1.6368026733398438
Validation loss: 2.2546467742612286

Epoch: 6| Step: 12
Training loss: 2.9654183387756348
Validation loss: 2.270078730839555

Epoch: 6| Step: 13
Training loss: 2.385721445083618
Validation loss: 2.287473855480071

Epoch: 90| Step: 0
Training loss: 2.768259048461914
Validation loss: 2.321485415581734

Epoch: 6| Step: 1
Training loss: 2.390740156173706
Validation loss: 2.3516719084914013

Epoch: 6| Step: 2
Training loss: 2.6042730808258057
Validation loss: 2.3809643227566957

Epoch: 6| Step: 3
Training loss: 2.715200901031494
Validation loss: 2.4067605797962477

Epoch: 6| Step: 4
Training loss: 2.6657657623291016
Validation loss: 2.3999199431429625

Epoch: 6| Step: 5
Training loss: 2.4879961013793945
Validation loss: 2.3920190026683192

Epoch: 6| Step: 6
Training loss: 2.638172149658203
Validation loss: 2.364875965220954

Epoch: 6| Step: 7
Training loss: 2.078099250793457
Validation loss: 2.3369151623018327

Epoch: 6| Step: 8
Training loss: 2.4774885177612305
Validation loss: 2.324005265389719

Epoch: 6| Step: 9
Training loss: 2.8774635791778564
Validation loss: 2.317742742517943

Epoch: 6| Step: 10
Training loss: 2.56142520904541
Validation loss: 2.3088420385955484

Epoch: 6| Step: 11
Training loss: 2.378253698348999
Validation loss: 2.3057316118671047

Epoch: 6| Step: 12
Training loss: 3.26332950592041
Validation loss: 2.3110085187419767

Epoch: 6| Step: 13
Training loss: 2.1592907905578613
Validation loss: 2.311153050391905

Epoch: 91| Step: 0
Training loss: 2.588533401489258
Validation loss: 2.305725848802956

Epoch: 6| Step: 1
Training loss: 2.3270254135131836
Validation loss: 2.307259177648893

Epoch: 6| Step: 2
Training loss: 1.6783688068389893
Validation loss: 2.307570477967621

Epoch: 6| Step: 3
Training loss: 2.8447937965393066
Validation loss: 2.3083874999835925

Epoch: 6| Step: 4
Training loss: 3.003380060195923
Validation loss: 2.3037758052990003

Epoch: 6| Step: 5
Training loss: 2.779717445373535
Validation loss: 2.3053205244002806

Epoch: 6| Step: 6
Training loss: 3.109731674194336
Validation loss: 2.306642045256912

Epoch: 6| Step: 7
Training loss: 2.137897491455078
Validation loss: 2.3053092213087183

Epoch: 6| Step: 8
Training loss: 2.6362857818603516
Validation loss: 2.307541931829145

Epoch: 6| Step: 9
Training loss: 2.5933241844177246
Validation loss: 2.3152870414077595

Epoch: 6| Step: 10
Training loss: 1.9226908683776855
Validation loss: 2.3258839268838205

Epoch: 6| Step: 11
Training loss: 1.909847378730774
Validation loss: 2.315615951374013

Epoch: 6| Step: 12
Training loss: 3.5208935737609863
Validation loss: 2.316207162795528

Epoch: 6| Step: 13
Training loss: 2.837770938873291
Validation loss: 2.3177680174509683

Epoch: 92| Step: 0
Training loss: 1.9292070865631104
Validation loss: 2.3022093337069274

Epoch: 6| Step: 1
Training loss: 2.465139150619507
Validation loss: 2.3024912649585354

Epoch: 6| Step: 2
Training loss: 3.266209125518799
Validation loss: 2.3017637934736026

Epoch: 6| Step: 3
Training loss: 2.4938974380493164
Validation loss: 2.2949852610147126

Epoch: 6| Step: 4
Training loss: 2.4310736656188965
Validation loss: 2.2885905106862388

Epoch: 6| Step: 5
Training loss: 1.6489872932434082
Validation loss: 2.27992711400473

Epoch: 6| Step: 6
Training loss: 3.004713535308838
Validation loss: 2.2738260376837944

Epoch: 6| Step: 7
Training loss: 2.748709201812744
Validation loss: 2.279765095762027

Epoch: 6| Step: 8
Training loss: 2.8953213691711426
Validation loss: 2.2679414492781445

Epoch: 6| Step: 9
Training loss: 2.113370656967163
Validation loss: 2.258034339515112

Epoch: 6| Step: 10
Training loss: 2.455286741256714
Validation loss: 2.2554647614878993

Epoch: 6| Step: 11
Training loss: 3.073856830596924
Validation loss: 2.2525574263706

Epoch: 6| Step: 12
Training loss: 2.296323299407959
Validation loss: 2.256061633427938

Epoch: 6| Step: 13
Training loss: 2.5716280937194824
Validation loss: 2.2615447992919595

Epoch: 93| Step: 0
Training loss: 3.1100120544433594
Validation loss: 2.268291211897327

Epoch: 6| Step: 1
Training loss: 2.9363045692443848
Validation loss: 2.2724302943034838

Epoch: 6| Step: 2
Training loss: 2.5721817016601562
Validation loss: 2.2616905986621814

Epoch: 6| Step: 3
Training loss: 2.304381847381592
Validation loss: 2.2517817610053608

Epoch: 6| Step: 4
Training loss: 2.7544569969177246
Validation loss: 2.265022188104609

Epoch: 6| Step: 5
Training loss: 2.3733773231506348
Validation loss: 2.2990649105400167

Epoch: 6| Step: 6
Training loss: 1.9408869743347168
Validation loss: 2.311009342952441

Epoch: 6| Step: 7
Training loss: 2.9902870655059814
Validation loss: 2.326168635840057

Epoch: 6| Step: 8
Training loss: 2.4363863468170166
Validation loss: 2.314582606797577

Epoch: 6| Step: 9
Training loss: 2.4335217475891113
Validation loss: 2.3135391896770847

Epoch: 6| Step: 10
Training loss: 2.083326816558838
Validation loss: 2.3054410219192505

Epoch: 6| Step: 11
Training loss: 2.633114814758301
Validation loss: 2.3245038986206055

Epoch: 6| Step: 12
Training loss: 2.5052270889282227
Validation loss: 2.314020659333916

Epoch: 6| Step: 13
Training loss: 2.081796884536743
Validation loss: 2.2863172279891146

Epoch: 94| Step: 0
Training loss: 2.2822375297546387
Validation loss: 2.2623459498087564

Epoch: 6| Step: 1
Training loss: 2.8017563819885254
Validation loss: 2.256449048237134

Epoch: 6| Step: 2
Training loss: 1.884779930114746
Validation loss: 2.237077510485085

Epoch: 6| Step: 3
Training loss: 2.871164083480835
Validation loss: 2.2297328813101656

Epoch: 6| Step: 4
Training loss: 2.9193718433380127
Validation loss: 2.214227686646164

Epoch: 6| Step: 5
Training loss: 2.796022891998291
Validation loss: 2.2131174661779918

Epoch: 6| Step: 6
Training loss: 2.5425705909729004
Validation loss: 2.203957675605692

Epoch: 6| Step: 7
Training loss: 2.9859414100646973
Validation loss: 2.1988155662372546

Epoch: 6| Step: 8
Training loss: 2.7207024097442627
Validation loss: 2.1946628144992295

Epoch: 6| Step: 9
Training loss: 2.247709274291992
Validation loss: 2.189791435836464

Epoch: 6| Step: 10
Training loss: 2.918877124786377
Validation loss: 2.1965899518741074

Epoch: 6| Step: 11
Training loss: 2.301086902618408
Validation loss: 2.1979529755089873

Epoch: 6| Step: 12
Training loss: 1.7604809999465942
Validation loss: 2.1975899204131095

Epoch: 6| Step: 13
Training loss: 1.7759974002838135
Validation loss: 2.196606638611004

Epoch: 95| Step: 0
Training loss: 2.8229923248291016
Validation loss: 2.196126740465882

Epoch: 6| Step: 1
Training loss: 2.6518406867980957
Validation loss: 2.197984036578927

Epoch: 6| Step: 2
Training loss: 2.254568576812744
Validation loss: 2.2082046360097904

Epoch: 6| Step: 3
Training loss: 2.3091139793395996
Validation loss: 2.2183990632334063

Epoch: 6| Step: 4
Training loss: 2.8219785690307617
Validation loss: 2.213265231860581

Epoch: 6| Step: 5
Training loss: 2.891366958618164
Validation loss: 2.224528069137245

Epoch: 6| Step: 6
Training loss: 2.929387331008911
Validation loss: 2.235881669546968

Epoch: 6| Step: 7
Training loss: 1.9518438577651978
Validation loss: 2.2325137148621264

Epoch: 6| Step: 8
Training loss: 2.1184465885162354
Validation loss: 2.2416492918486237

Epoch: 6| Step: 9
Training loss: 2.122941493988037
Validation loss: 2.237178856326688

Epoch: 6| Step: 10
Training loss: 3.0721263885498047
Validation loss: 2.2320271461240706

Epoch: 6| Step: 11
Training loss: 2.7969017028808594
Validation loss: 2.2211243465382564

Epoch: 6| Step: 12
Training loss: 2.0951294898986816
Validation loss: 2.200159345903704

Epoch: 6| Step: 13
Training loss: 2.0539348125457764
Validation loss: 2.1884108986905826

Epoch: 96| Step: 0
Training loss: 3.054232358932495
Validation loss: 2.1857317288716636

Epoch: 6| Step: 1
Training loss: 2.5060510635375977
Validation loss: 2.1869214503995833

Epoch: 6| Step: 2
Training loss: 2.2665836811065674
Validation loss: 2.195425591161174

Epoch: 6| Step: 3
Training loss: 2.737133502960205
Validation loss: 2.2042162931093605

Epoch: 6| Step: 4
Training loss: 2.286285638809204
Validation loss: 2.215818774315619

Epoch: 6| Step: 5
Training loss: 2.5296266078948975
Validation loss: 2.2254348954846783

Epoch: 6| Step: 6
Training loss: 2.212434768676758
Validation loss: 2.2377918945845736

Epoch: 6| Step: 7
Training loss: 1.9178720712661743
Validation loss: 2.2616720173948552

Epoch: 6| Step: 8
Training loss: 2.4939842224121094
Validation loss: 2.2861950756401144

Epoch: 6| Step: 9
Training loss: 3.0945985317230225
Validation loss: 2.2416339176957325

Epoch: 6| Step: 10
Training loss: 2.966904640197754
Validation loss: 2.2167366525178314

Epoch: 6| Step: 11
Training loss: 2.7630908489227295
Validation loss: 2.217250716301703

Epoch: 6| Step: 12
Training loss: 2.2122397422790527
Validation loss: 2.2077501102160384

Epoch: 6| Step: 13
Training loss: 1.6515393257141113
Validation loss: 2.198216002474549

Epoch: 97| Step: 0
Training loss: 2.423088550567627
Validation loss: 2.201018116807425

Epoch: 6| Step: 1
Training loss: 2.731898546218872
Validation loss: 2.2042317185350644

Epoch: 6| Step: 2
Training loss: 2.2769668102264404
Validation loss: 2.1990683232584307

Epoch: 6| Step: 3
Training loss: 2.6114912033081055
Validation loss: 2.217762780445878

Epoch: 6| Step: 4
Training loss: 3.0274524688720703
Validation loss: 2.211377587369693

Epoch: 6| Step: 5
Training loss: 1.6003592014312744
Validation loss: 2.200358590772075

Epoch: 6| Step: 6
Training loss: 3.0061397552490234
Validation loss: 2.211567242940267

Epoch: 6| Step: 7
Training loss: 2.690565586090088
Validation loss: 2.206868540856146

Epoch: 6| Step: 8
Training loss: 3.0481414794921875
Validation loss: 2.2048477639434156

Epoch: 6| Step: 9
Training loss: 2.3552114963531494
Validation loss: 2.210856681228966

Epoch: 6| Step: 10
Training loss: 2.071934223175049
Validation loss: 2.2065591991588636

Epoch: 6| Step: 11
Training loss: 2.0852952003479004
Validation loss: 2.2091084923795474

Epoch: 6| Step: 12
Training loss: 2.2577972412109375
Validation loss: 2.2081481769520748

Epoch: 6| Step: 13
Training loss: 2.740706443786621
Validation loss: 2.199402288724017

Epoch: 98| Step: 0
Training loss: 2.5750133991241455
Validation loss: 2.2037569938167447

Epoch: 6| Step: 1
Training loss: 1.960428237915039
Validation loss: 2.2030336395386727

Epoch: 6| Step: 2
Training loss: 2.808593273162842
Validation loss: 2.202065572943739

Epoch: 6| Step: 3
Training loss: 2.39504337310791
Validation loss: 2.199904949434342

Epoch: 6| Step: 4
Training loss: 2.4124650955200195
Validation loss: 2.1992185500360306

Epoch: 6| Step: 5
Training loss: 2.14481782913208
Validation loss: 2.2081449236921085

Epoch: 6| Step: 6
Training loss: 2.2322640419006348
Validation loss: 2.210755936561092

Epoch: 6| Step: 7
Training loss: 2.763866901397705
Validation loss: 2.2319054116484938

Epoch: 6| Step: 8
Training loss: 1.9682302474975586
Validation loss: 2.244457896037768

Epoch: 6| Step: 9
Training loss: 3.0463802814483643
Validation loss: 2.273494969132126

Epoch: 6| Step: 10
Training loss: 1.7182021141052246
Validation loss: 2.294235429456157

Epoch: 6| Step: 11
Training loss: 2.5103816986083984
Validation loss: 2.3203533541771675

Epoch: 6| Step: 12
Training loss: 3.4668354988098145
Validation loss: 2.3029695864646667

Epoch: 6| Step: 13
Training loss: 3.094241142272949
Validation loss: 2.221503729461342

Epoch: 99| Step: 0
Training loss: 3.161592960357666
Validation loss: 2.2105656029075704

Epoch: 6| Step: 1
Training loss: 2.1969046592712402
Validation loss: 2.199370018897518

Epoch: 6| Step: 2
Training loss: 2.1791131496429443
Validation loss: 2.185221122157189

Epoch: 6| Step: 3
Training loss: 2.0121049880981445
Validation loss: 2.179614313187138

Epoch: 6| Step: 4
Training loss: 3.082247734069824
Validation loss: 2.1835001002075853

Epoch: 6| Step: 5
Training loss: 2.544093608856201
Validation loss: 2.1867974881202943

Epoch: 6| Step: 6
Training loss: 2.7741098403930664
Validation loss: 2.1858314109104935

Epoch: 6| Step: 7
Training loss: 2.327476978302002
Validation loss: 2.190964029681298

Epoch: 6| Step: 8
Training loss: 2.55257511138916
Validation loss: 2.1884187818855367

Epoch: 6| Step: 9
Training loss: 2.223252296447754
Validation loss: 2.1959082029199086

Epoch: 6| Step: 10
Training loss: 3.1209282875061035
Validation loss: 2.2140562508695867

Epoch: 6| Step: 11
Training loss: 2.075066566467285
Validation loss: 2.206703991018316

Epoch: 6| Step: 12
Training loss: 2.3225889205932617
Validation loss: 2.2083997623894804

Epoch: 6| Step: 13
Training loss: 2.1467268466949463
Validation loss: 2.204932757603225

Epoch: 100| Step: 0
Training loss: 2.2529537677764893
Validation loss: 2.204305256566694

Epoch: 6| Step: 1
Training loss: 3.120741367340088
Validation loss: 2.2146311088274886

Epoch: 6| Step: 2
Training loss: 2.548630952835083
Validation loss: 2.2153330426062308

Epoch: 6| Step: 3
Training loss: 2.3111133575439453
Validation loss: 2.2214199855763423

Epoch: 6| Step: 4
Training loss: 1.9251976013183594
Validation loss: 2.2397506493394093

Epoch: 6| Step: 5
Training loss: 1.705744743347168
Validation loss: 2.231172412954351

Epoch: 6| Step: 6
Training loss: 2.4073452949523926
Validation loss: 2.20919450893197

Epoch: 6| Step: 7
Training loss: 2.612251043319702
Validation loss: 2.229641914367676

Epoch: 6| Step: 8
Training loss: 2.605297565460205
Validation loss: 2.2152069691688783

Epoch: 6| Step: 9
Training loss: 2.9118781089782715
Validation loss: 2.2367354234059653

Epoch: 6| Step: 10
Training loss: 2.5496959686279297
Validation loss: 2.223266032434279

Epoch: 6| Step: 11
Training loss: 2.6527974605560303
Validation loss: 2.2136697512800976

Epoch: 6| Step: 12
Training loss: 2.275791645050049
Validation loss: 2.197400959589148

Epoch: 6| Step: 13
Training loss: 2.675664186477661
Validation loss: 2.197184834429013

Epoch: 101| Step: 0
Training loss: 2.9643406867980957
Validation loss: 2.199890669956002

Epoch: 6| Step: 1
Training loss: 3.156513214111328
Validation loss: 2.185935079410512

Epoch: 6| Step: 2
Training loss: 2.39115047454834
Validation loss: 2.189998483145109

Epoch: 6| Step: 3
Training loss: 2.5473179817199707
Validation loss: 2.186983959649199

Epoch: 6| Step: 4
Training loss: 2.821551561355591
Validation loss: 2.1874682518743698

Epoch: 6| Step: 5
Training loss: 2.453829288482666
Validation loss: 2.1907923247224543

Epoch: 6| Step: 6
Training loss: 1.827669382095337
Validation loss: 2.1908073643202424

Epoch: 6| Step: 7
Training loss: 2.4960696697235107
Validation loss: 2.203137413147957

Epoch: 6| Step: 8
Training loss: 2.8009531497955322
Validation loss: 2.2387674021464523

Epoch: 6| Step: 9
Training loss: 2.2170088291168213
Validation loss: 2.2462748917200233

Epoch: 6| Step: 10
Training loss: 2.469080924987793
Validation loss: 2.2453775149519726

Epoch: 6| Step: 11
Training loss: 2.0477170944213867
Validation loss: 2.2272275673445834

Epoch: 6| Step: 12
Training loss: 2.3791635036468506
Validation loss: 2.2093830672643517

Epoch: 6| Step: 13
Training loss: 1.4703527688980103
Validation loss: 2.208709222014232

Epoch: 102| Step: 0
Training loss: 1.9490313529968262
Validation loss: 2.2138261589952695

Epoch: 6| Step: 1
Training loss: 2.0448760986328125
Validation loss: 2.2154638228877896

Epoch: 6| Step: 2
Training loss: 2.084829807281494
Validation loss: 2.2156579673931165

Epoch: 6| Step: 3
Training loss: 3.1043574810028076
Validation loss: 2.21274233377108

Epoch: 6| Step: 4
Training loss: 2.5605196952819824
Validation loss: 2.201885886089776

Epoch: 6| Step: 5
Training loss: 2.9671316146850586
Validation loss: 2.1949378316120436

Epoch: 6| Step: 6
Training loss: 2.3348803520202637
Validation loss: 2.1827401679049254

Epoch: 6| Step: 7
Training loss: 2.2668163776397705
Validation loss: 2.1726807240516908

Epoch: 6| Step: 8
Training loss: 2.2697277069091797
Validation loss: 2.1721113574120308

Epoch: 6| Step: 9
Training loss: 2.0238454341888428
Validation loss: 2.165861862961964

Epoch: 6| Step: 10
Training loss: 3.09112286567688
Validation loss: 2.163088106339978

Epoch: 6| Step: 11
Training loss: 2.7328624725341797
Validation loss: 2.171206025667088

Epoch: 6| Step: 12
Training loss: 2.400202989578247
Validation loss: 2.1642767742115963

Epoch: 6| Step: 13
Training loss: 2.8085200786590576
Validation loss: 2.168222350458945

Epoch: 103| Step: 0
Training loss: 1.7064900398254395
Validation loss: 2.1657939751942954

Epoch: 6| Step: 1
Training loss: 2.096132755279541
Validation loss: 2.169244240689021

Epoch: 6| Step: 2
Training loss: 2.515838623046875
Validation loss: 2.183854256906817

Epoch: 6| Step: 3
Training loss: 2.220345973968506
Validation loss: 2.199368930632068

Epoch: 6| Step: 4
Training loss: 1.992154836654663
Validation loss: 2.2312623916133756

Epoch: 6| Step: 5
Training loss: 2.8197145462036133
Validation loss: 2.2439083860766504

Epoch: 6| Step: 6
Training loss: 2.6967549324035645
Validation loss: 2.2286292455529653

Epoch: 6| Step: 7
Training loss: 2.2105259895324707
Validation loss: 2.2860100987137004

Epoch: 6| Step: 8
Training loss: 2.342306613922119
Validation loss: 2.318182437650619

Epoch: 6| Step: 9
Training loss: 3.233348846435547
Validation loss: 2.331103999127624

Epoch: 6| Step: 10
Training loss: 2.901468515396118
Validation loss: 2.3736596799665883

Epoch: 6| Step: 11
Training loss: 2.940206289291382
Validation loss: 2.397372345770559

Epoch: 6| Step: 12
Training loss: 2.4528756141662598
Validation loss: 2.3574852481965096

Epoch: 6| Step: 13
Training loss: 2.904918670654297
Validation loss: 2.28875070746227

Epoch: 104| Step: 0
Training loss: 2.5224785804748535
Validation loss: 2.2033230617482173

Epoch: 6| Step: 1
Training loss: 2.281492233276367
Validation loss: 2.1749180978344334

Epoch: 6| Step: 2
Training loss: 2.406837224960327
Validation loss: 2.152308820396341

Epoch: 6| Step: 3
Training loss: 2.53554368019104
Validation loss: 2.149890422821045

Epoch: 6| Step: 4
Training loss: 3.0235095024108887
Validation loss: 2.1478302606972317

Epoch: 6| Step: 5
Training loss: 2.593046188354492
Validation loss: 2.1620702974257933

Epoch: 6| Step: 6
Training loss: 2.6011927127838135
Validation loss: 2.164356429089782

Epoch: 6| Step: 7
Training loss: 2.2426750659942627
Validation loss: 2.169225090293474

Epoch: 6| Step: 8
Training loss: 1.9077898263931274
Validation loss: 2.1679762319851945

Epoch: 6| Step: 9
Training loss: 2.5680227279663086
Validation loss: 2.1516213750326507

Epoch: 6| Step: 10
Training loss: 2.808525323867798
Validation loss: 2.1432928833910214

Epoch: 6| Step: 11
Training loss: 2.125070333480835
Validation loss: 2.1530807966827066

Epoch: 6| Step: 12
Training loss: 2.380692720413208
Validation loss: 2.157335904336745

Epoch: 6| Step: 13
Training loss: 3.2926957607269287
Validation loss: 2.1612837570969776

Epoch: 105| Step: 0
Training loss: 2.451606035232544
Validation loss: 2.1835243317388717

Epoch: 6| Step: 1
Training loss: 2.64011287689209
Validation loss: 2.194970687230428

Epoch: 6| Step: 2
Training loss: 1.9101530313491821
Validation loss: 2.232253679665186

Epoch: 6| Step: 3
Training loss: 2.4225120544433594
Validation loss: 2.2119571214081137

Epoch: 6| Step: 4
Training loss: 1.9586095809936523
Validation loss: 2.2094011306762695

Epoch: 6| Step: 5
Training loss: 2.5276718139648438
Validation loss: 2.2079676530694448

Epoch: 6| Step: 6
Training loss: 2.7939858436584473
Validation loss: 2.223176466521396

Epoch: 6| Step: 7
Training loss: 2.0887699127197266
Validation loss: 2.2322103015838133

Epoch: 6| Step: 8
Training loss: 3.0122649669647217
Validation loss: 2.2453166746324107

Epoch: 6| Step: 9
Training loss: 3.709611415863037
Validation loss: 2.248440334873815

Epoch: 6| Step: 10
Training loss: 2.5888659954071045
Validation loss: 2.2299011291996127

Epoch: 6| Step: 11
Training loss: 2.144376754760742
Validation loss: 2.2141295838099655

Epoch: 6| Step: 12
Training loss: 2.1273419857025146
Validation loss: 2.1970419037726616

Epoch: 6| Step: 13
Training loss: 2.2004382610321045
Validation loss: 2.1907382370323263

Epoch: 106| Step: 0
Training loss: 1.8187166452407837
Validation loss: 2.1741780363103396

Epoch: 6| Step: 1
Training loss: 2.4310359954833984
Validation loss: 2.170342501773629

Epoch: 6| Step: 2
Training loss: 3.0344152450561523
Validation loss: 2.1719069403986775

Epoch: 6| Step: 3
Training loss: 3.0691757202148438
Validation loss: 2.1856103443330333

Epoch: 6| Step: 4
Training loss: 2.5012552738189697
Validation loss: 2.2021021689138105

Epoch: 6| Step: 5
Training loss: 2.453016996383667
Validation loss: 2.213617455574774

Epoch: 6| Step: 6
Training loss: 3.1772427558898926
Validation loss: 2.2549889984951226

Epoch: 6| Step: 7
Training loss: 2.9809083938598633
Validation loss: 2.270832760359651

Epoch: 6| Step: 8
Training loss: 2.802300453186035
Validation loss: 2.2810821533203125

Epoch: 6| Step: 9
Training loss: 2.0588581562042236
Validation loss: 2.2103201830258934

Epoch: 6| Step: 10
Training loss: 1.4256374835968018
Validation loss: 2.1630388613670104

Epoch: 6| Step: 11
Training loss: 2.022911310195923
Validation loss: 2.1543540800771406

Epoch: 6| Step: 12
Training loss: 2.237797498703003
Validation loss: 2.16278931402391

Epoch: 6| Step: 13
Training loss: 3.004906177520752
Validation loss: 2.1447831174378753

Epoch: 107| Step: 0
Training loss: 2.2420926094055176
Validation loss: 2.1435094507791663

Epoch: 6| Step: 1
Training loss: 2.6821751594543457
Validation loss: 2.1557416749256912

Epoch: 6| Step: 2
Training loss: 1.9141639471054077
Validation loss: 2.161281097319818

Epoch: 6| Step: 3
Training loss: 3.037808418273926
Validation loss: 2.1601974143776843

Epoch: 6| Step: 4
Training loss: 2.2540440559387207
Validation loss: 2.1463898997153006

Epoch: 6| Step: 5
Training loss: 2.4306044578552246
Validation loss: 2.140313265144184

Epoch: 6| Step: 6
Training loss: 2.572658061981201
Validation loss: 2.1362492166539675

Epoch: 6| Step: 7
Training loss: 2.2555508613586426
Validation loss: 2.147320137229017

Epoch: 6| Step: 8
Training loss: 2.6352930068969727
Validation loss: 2.154619916792839

Epoch: 6| Step: 9
Training loss: 2.1032028198242188
Validation loss: 2.1694904117174048

Epoch: 6| Step: 10
Training loss: 1.9026721715927124
Validation loss: 2.2074902852376304

Epoch: 6| Step: 11
Training loss: 3.0208306312561035
Validation loss: 2.262140125356695

Epoch: 6| Step: 12
Training loss: 2.8790926933288574
Validation loss: 2.2931361044606855

Epoch: 6| Step: 13
Training loss: 2.493717908859253
Validation loss: 2.3331925176805064

Epoch: 108| Step: 0
Training loss: 2.928618907928467
Validation loss: 2.3626389529115412

Epoch: 6| Step: 1
Training loss: 2.9365580081939697
Validation loss: 2.3780670319834063

Epoch: 6| Step: 2
Training loss: 2.2203636169433594
Validation loss: 2.327986455732776

Epoch: 6| Step: 3
Training loss: 2.2105863094329834
Validation loss: 2.3071376303190827

Epoch: 6| Step: 4
Training loss: 2.5439915657043457
Validation loss: 2.290057836040374

Epoch: 6| Step: 5
Training loss: 1.928975224494934
Validation loss: 2.243848887822961

Epoch: 6| Step: 6
Training loss: 2.253371238708496
Validation loss: 2.219747681771555

Epoch: 6| Step: 7
Training loss: 3.1045358180999756
Validation loss: 2.2169798535685383

Epoch: 6| Step: 8
Training loss: 2.527958869934082
Validation loss: 2.2089955550368114

Epoch: 6| Step: 9
Training loss: 2.3593075275421143
Validation loss: 2.205554054629418

Epoch: 6| Step: 10
Training loss: 2.097592830657959
Validation loss: 2.188468205031528

Epoch: 6| Step: 11
Training loss: 3.004890203475952
Validation loss: 2.1883728516999112

Epoch: 6| Step: 12
Training loss: 2.2201480865478516
Validation loss: 2.18976249746097

Epoch: 6| Step: 13
Training loss: 2.454148292541504
Validation loss: 2.187902982516955

Epoch: 109| Step: 0
Training loss: 2.220104455947876
Validation loss: 2.179248639332351

Epoch: 6| Step: 1
Training loss: 2.7026638984680176
Validation loss: 2.1792076967095815

Epoch: 6| Step: 2
Training loss: 2.1401147842407227
Validation loss: 2.1828932762145996

Epoch: 6| Step: 3
Training loss: 2.3989479541778564
Validation loss: 2.178862405079667

Epoch: 6| Step: 4
Training loss: 2.5155134201049805
Validation loss: 2.1812876680845856

Epoch: 6| Step: 5
Training loss: 2.346966028213501
Validation loss: 2.181844006302536

Epoch: 6| Step: 6
Training loss: 2.818202495574951
Validation loss: 2.180143181995679

Epoch: 6| Step: 7
Training loss: 2.7148547172546387
Validation loss: 2.188202214497392

Epoch: 6| Step: 8
Training loss: 1.8817882537841797
Validation loss: 2.1853328289524203

Epoch: 6| Step: 9
Training loss: 2.5093655586242676
Validation loss: 2.1813971893761748

Epoch: 6| Step: 10
Training loss: 3.1289563179016113
Validation loss: 2.185054895698383

Epoch: 6| Step: 11
Training loss: 2.4681739807128906
Validation loss: 2.188135911059636

Epoch: 6| Step: 12
Training loss: 2.7354912757873535
Validation loss: 2.188829634779243

Epoch: 6| Step: 13
Training loss: 2.256985664367676
Validation loss: 2.1880812568049275

Epoch: 110| Step: 0
Training loss: 2.256350517272949
Validation loss: 2.2021033558794247

Epoch: 6| Step: 1
Training loss: 2.2546885013580322
Validation loss: 2.206717501404465

Epoch: 6| Step: 2
Training loss: 2.451918601989746
Validation loss: 2.2114054208160727

Epoch: 6| Step: 3
Training loss: 2.7621936798095703
Validation loss: 2.205720724598054

Epoch: 6| Step: 4
Training loss: 2.980891227722168
Validation loss: 2.2143158784476658

Epoch: 6| Step: 5
Training loss: 2.1669979095458984
Validation loss: 2.2024197296429704

Epoch: 6| Step: 6
Training loss: 2.218696117401123
Validation loss: 2.1973468231898483

Epoch: 6| Step: 7
Training loss: 2.6917457580566406
Validation loss: 2.201092758486348

Epoch: 6| Step: 8
Training loss: 3.4280214309692383
Validation loss: 2.2004666533521426

Epoch: 6| Step: 9
Training loss: 2.5464487075805664
Validation loss: 2.1923123892917427

Epoch: 6| Step: 10
Training loss: 1.9055734872817993
Validation loss: 2.189032559753746

Epoch: 6| Step: 11
Training loss: 2.1702332496643066
Validation loss: 2.1901798607200704

Epoch: 6| Step: 12
Training loss: 2.710742950439453
Validation loss: 2.186335012476931

Epoch: 6| Step: 13
Training loss: 1.844867467880249
Validation loss: 2.1844271946978826

Epoch: 111| Step: 0
Training loss: 2.1429619789123535
Validation loss: 2.182732128327893

Epoch: 6| Step: 1
Training loss: 2.3636415004730225
Validation loss: 2.1806949569332983

Epoch: 6| Step: 2
Training loss: 2.1221959590911865
Validation loss: 2.1820623413208993

Epoch: 6| Step: 3
Training loss: 2.3634557723999023
Validation loss: 2.189120295227215

Epoch: 6| Step: 4
Training loss: 3.131406784057617
Validation loss: 2.192855747797156

Epoch: 6| Step: 5
Training loss: 2.511958599090576
Validation loss: 2.1964359206538044

Epoch: 6| Step: 6
Training loss: 2.4481801986694336
Validation loss: 2.1861781881701563

Epoch: 6| Step: 7
Training loss: 2.829127788543701
Validation loss: 2.184800996575304

Epoch: 6| Step: 8
Training loss: 2.2774276733398438
Validation loss: 2.181896996754472

Epoch: 6| Step: 9
Training loss: 2.5479824542999268
Validation loss: 2.180256529520917

Epoch: 6| Step: 10
Training loss: 2.116596221923828
Validation loss: 2.179731397218602

Epoch: 6| Step: 11
Training loss: 2.658193588256836
Validation loss: 2.184907341516146

Epoch: 6| Step: 12
Training loss: 2.499549388885498
Validation loss: 2.209815002256824

Epoch: 6| Step: 13
Training loss: 2.175328254699707
Validation loss: 2.21206324074858

Epoch: 112| Step: 0
Training loss: 2.23811674118042
Validation loss: 2.2038696991500033

Epoch: 6| Step: 1
Training loss: 2.3503482341766357
Validation loss: 2.205779943414914

Epoch: 6| Step: 2
Training loss: 2.5532774925231934
Validation loss: 2.1892600867056076

Epoch: 6| Step: 3
Training loss: 2.2073700428009033
Validation loss: 2.193287052134032

Epoch: 6| Step: 4
Training loss: 2.6380438804626465
Validation loss: 2.1663552740568757

Epoch: 6| Step: 5
Training loss: 2.049349308013916
Validation loss: 2.154981743904852

Epoch: 6| Step: 6
Training loss: 3.2239747047424316
Validation loss: 2.1435639114790064

Epoch: 6| Step: 7
Training loss: 2.555833101272583
Validation loss: 2.146088969322943

Epoch: 6| Step: 8
Training loss: 2.4978725910186768
Validation loss: 2.144722436064033

Epoch: 6| Step: 9
Training loss: 2.4636640548706055
Validation loss: 2.140022397041321

Epoch: 6| Step: 10
Training loss: 2.416682004928589
Validation loss: 2.139142974730461

Epoch: 6| Step: 11
Training loss: 2.0911262035369873
Validation loss: 2.139621227018295

Epoch: 6| Step: 12
Training loss: 2.2941689491271973
Validation loss: 2.13792694768598

Epoch: 6| Step: 13
Training loss: 2.615246295928955
Validation loss: 2.136016509866202

Epoch: 113| Step: 0
Training loss: 2.181389331817627
Validation loss: 2.1690831697115334

Epoch: 6| Step: 1
Training loss: 2.5760810375213623
Validation loss: 2.2293679380929596

Epoch: 6| Step: 2
Training loss: 2.1160354614257812
Validation loss: 2.370245305440759

Epoch: 6| Step: 3
Training loss: 1.658582329750061
Validation loss: 2.4329553804089947

Epoch: 6| Step: 4
Training loss: 3.298030138015747
Validation loss: 2.5246941069121003

Epoch: 6| Step: 5
Training loss: 3.404334545135498
Validation loss: 2.46742844581604

Epoch: 6| Step: 6
Training loss: 1.8294262886047363
Validation loss: 2.3534049769883514

Epoch: 6| Step: 7
Training loss: 3.4538300037384033
Validation loss: 2.292052989364952

Epoch: 6| Step: 8
Training loss: 3.115300178527832
Validation loss: 2.22913360082975

Epoch: 6| Step: 9
Training loss: 2.3097267150878906
Validation loss: 2.1698672233089322

Epoch: 6| Step: 10
Training loss: 2.410391092300415
Validation loss: 2.16267861986673

Epoch: 6| Step: 11
Training loss: 1.7491562366485596
Validation loss: 2.15737662776824

Epoch: 6| Step: 12
Training loss: 2.5516762733459473
Validation loss: 2.1581694079983618

Epoch: 6| Step: 13
Training loss: 1.9345817565917969
Validation loss: 2.1668430425787486

Epoch: 114| Step: 0
Training loss: 2.542595386505127
Validation loss: 2.1910579358377764

Epoch: 6| Step: 1
Training loss: 2.369701862335205
Validation loss: 2.214905261993408

Epoch: 6| Step: 2
Training loss: 2.4202077388763428
Validation loss: 2.2131139219448133

Epoch: 6| Step: 3
Training loss: 2.4034223556518555
Validation loss: 2.2084781264746063

Epoch: 6| Step: 4
Training loss: 3.2906503677368164
Validation loss: 2.2031962487005416

Epoch: 6| Step: 5
Training loss: 2.0313477516174316
Validation loss: 2.1903002159569853

Epoch: 6| Step: 6
Training loss: 2.152923583984375
Validation loss: 2.1941903944938415

Epoch: 6| Step: 7
Training loss: 2.945772647857666
Validation loss: 2.2010964885834725

Epoch: 6| Step: 8
Training loss: 2.047438383102417
Validation loss: 2.2019831518973074

Epoch: 6| Step: 9
Training loss: 2.626201629638672
Validation loss: 2.2037162473124843

Epoch: 6| Step: 10
Training loss: 2.0829062461853027
Validation loss: 2.2096891659562305

Epoch: 6| Step: 11
Training loss: 1.7911348342895508
Validation loss: 2.1862692140763804

Epoch: 6| Step: 12
Training loss: 2.9193525314331055
Validation loss: 2.1814734153850104

Epoch: 6| Step: 13
Training loss: 2.2923967838287354
Validation loss: 2.1652119185334895

Epoch: 115| Step: 0
Training loss: 2.0984904766082764
Validation loss: 2.1702829894199165

Epoch: 6| Step: 1
Training loss: 2.006950855255127
Validation loss: 2.156972869749992

Epoch: 6| Step: 2
Training loss: 2.791545867919922
Validation loss: 2.155697562361276

Epoch: 6| Step: 3
Training loss: 2.2606077194213867
Validation loss: 2.151199745875533

Epoch: 6| Step: 4
Training loss: 2.1015708446502686
Validation loss: 2.1526585317427114

Epoch: 6| Step: 5
Training loss: 2.5383763313293457
Validation loss: 2.152927585827407

Epoch: 6| Step: 6
Training loss: 2.6986474990844727
Validation loss: 2.153691050826862

Epoch: 6| Step: 7
Training loss: 2.645559787750244
Validation loss: 2.157354183094476

Epoch: 6| Step: 8
Training loss: 2.6147260665893555
Validation loss: 2.1461784865266536

Epoch: 6| Step: 9
Training loss: 2.2017292976379395
Validation loss: 2.1490995627577587

Epoch: 6| Step: 10
Training loss: 2.5751333236694336
Validation loss: 2.146852393304148

Epoch: 6| Step: 11
Training loss: 2.3729028701782227
Validation loss: 2.145915710797874

Epoch: 6| Step: 12
Training loss: 2.705641984939575
Validation loss: 2.155602821739771

Epoch: 6| Step: 13
Training loss: 2.107703685760498
Validation loss: 2.164396406501852

Epoch: 116| Step: 0
Training loss: 2.753620147705078
Validation loss: 2.183782828751431

Epoch: 6| Step: 1
Training loss: 2.3214809894561768
Validation loss: 2.1971283010257188

Epoch: 6| Step: 2
Training loss: 1.8175594806671143
Validation loss: 2.216350301619499

Epoch: 6| Step: 3
Training loss: 2.4244751930236816
Validation loss: 2.2457575157124507

Epoch: 6| Step: 4
Training loss: 3.039907932281494
Validation loss: 2.270147342835703

Epoch: 6| Step: 5
Training loss: 2.860095262527466
Validation loss: 2.2712053252804663

Epoch: 6| Step: 6
Training loss: 2.1633968353271484
Validation loss: 2.251444588425339

Epoch: 6| Step: 7
Training loss: 2.2735753059387207
Validation loss: 2.2189485180762505

Epoch: 6| Step: 8
Training loss: 2.4190289974212646
Validation loss: 2.1785854434454315

Epoch: 6| Step: 9
Training loss: 1.7586755752563477
Validation loss: 2.1635534404426493

Epoch: 6| Step: 10
Training loss: 2.7255115509033203
Validation loss: 2.145603185058922

Epoch: 6| Step: 11
Training loss: 2.4552602767944336
Validation loss: 2.1461322128131823

Epoch: 6| Step: 12
Training loss: 2.3307271003723145
Validation loss: 2.147102527720954

Epoch: 6| Step: 13
Training loss: 2.6578352451324463
Validation loss: 2.1478004378657185

Epoch: 117| Step: 0
Training loss: 2.2119977474212646
Validation loss: 2.1489679121202037

Epoch: 6| Step: 1
Training loss: 2.619117259979248
Validation loss: 2.148062321447557

Epoch: 6| Step: 2
Training loss: 2.2231531143188477
Validation loss: 2.1488562630068873

Epoch: 6| Step: 3
Training loss: 2.0456655025482178
Validation loss: 2.1605534015163297

Epoch: 6| Step: 4
Training loss: 2.5188674926757812
Validation loss: 2.1618875649667557

Epoch: 6| Step: 5
Training loss: 2.755246162414551
Validation loss: 2.171585076598711

Epoch: 6| Step: 6
Training loss: 2.349701404571533
Validation loss: 2.189002449794482

Epoch: 6| Step: 7
Training loss: 2.4518489837646484
Validation loss: 2.198141746623542

Epoch: 6| Step: 8
Training loss: 2.4447293281555176
Validation loss: 2.218266378166855

Epoch: 6| Step: 9
Training loss: 2.022840976715088
Validation loss: 2.228825443534441

Epoch: 6| Step: 10
Training loss: 2.764735698699951
Validation loss: 2.2366649668703795

Epoch: 6| Step: 11
Training loss: 2.8974218368530273
Validation loss: 2.224366611050021

Epoch: 6| Step: 12
Training loss: 1.97540283203125
Validation loss: 2.195782866529239

Epoch: 6| Step: 13
Training loss: 2.251368284225464
Validation loss: 2.1630352748337613

Epoch: 118| Step: 0
Training loss: 1.957313895225525
Validation loss: 2.141656401336834

Epoch: 6| Step: 1
Training loss: 3.1891791820526123
Validation loss: 2.143237039607058

Epoch: 6| Step: 2
Training loss: 2.289478302001953
Validation loss: 2.1352105627777758

Epoch: 6| Step: 3
Training loss: 1.9548392295837402
Validation loss: 2.1338725013117634

Epoch: 6| Step: 4
Training loss: 2.0768985748291016
Validation loss: 2.1322297152652534

Epoch: 6| Step: 5
Training loss: 2.76762056350708
Validation loss: 2.1266423451003207

Epoch: 6| Step: 6
Training loss: 2.7075209617614746
Validation loss: 2.1307929715802594

Epoch: 6| Step: 7
Training loss: 2.157261610031128
Validation loss: 2.1294336998334495

Epoch: 6| Step: 8
Training loss: 2.576836347579956
Validation loss: 2.1274130562300324

Epoch: 6| Step: 9
Training loss: 2.150373935699463
Validation loss: 2.1336202749641995

Epoch: 6| Step: 10
Training loss: 2.5618457794189453
Validation loss: 2.1401937341177337

Epoch: 6| Step: 11
Training loss: 2.1139369010925293
Validation loss: 2.1458587492665937

Epoch: 6| Step: 12
Training loss: 2.7389214038848877
Validation loss: 2.1613454793089177

Epoch: 6| Step: 13
Training loss: 2.244112968444824
Validation loss: 2.171530592826105

Epoch: 119| Step: 0
Training loss: 1.8891154527664185
Validation loss: 2.183459835667764

Epoch: 6| Step: 1
Training loss: 3.3867411613464355
Validation loss: 2.191806213830107

Epoch: 6| Step: 2
Training loss: 2.9541311264038086
Validation loss: 2.210594715610627

Epoch: 6| Step: 3
Training loss: 1.662931203842163
Validation loss: 2.220059415345551

Epoch: 6| Step: 4
Training loss: 2.4539713859558105
Validation loss: 2.2431043040367866

Epoch: 6| Step: 5
Training loss: 1.9928488731384277
Validation loss: 2.2404487543208624

Epoch: 6| Step: 6
Training loss: 1.863898754119873
Validation loss: 2.205637747241605

Epoch: 6| Step: 7
Training loss: 2.6720621585845947
Validation loss: 2.187559937918058

Epoch: 6| Step: 8
Training loss: 2.5761725902557373
Validation loss: 2.158418286231256

Epoch: 6| Step: 9
Training loss: 2.435028076171875
Validation loss: 2.1425258216037544

Epoch: 6| Step: 10
Training loss: 2.1224231719970703
Validation loss: 2.1370760087044007

Epoch: 6| Step: 11
Training loss: 2.599228858947754
Validation loss: 2.126049277602985

Epoch: 6| Step: 12
Training loss: 2.6339690685272217
Validation loss: 2.119882465690695

Epoch: 6| Step: 13
Training loss: 2.2246086597442627
Validation loss: 2.124352296193441

Epoch: 120| Step: 0
Training loss: 2.268988609313965
Validation loss: 2.1249711052063973

Epoch: 6| Step: 1
Training loss: 1.5702464580535889
Validation loss: 2.124847076272452

Epoch: 6| Step: 2
Training loss: 2.6694438457489014
Validation loss: 2.132733820587076

Epoch: 6| Step: 3
Training loss: 2.8328709602355957
Validation loss: 2.132428391005403

Epoch: 6| Step: 4
Training loss: 2.242938995361328
Validation loss: 2.128345363883562

Epoch: 6| Step: 5
Training loss: 2.717404842376709
Validation loss: 2.124793965329406

Epoch: 6| Step: 6
Training loss: 2.333759069442749
Validation loss: 2.1360232573683544

Epoch: 6| Step: 7
Training loss: 2.515017509460449
Validation loss: 2.14550002672339

Epoch: 6| Step: 8
Training loss: 2.245278835296631
Validation loss: 2.1682393550872803

Epoch: 6| Step: 9
Training loss: 3.0947177410125732
Validation loss: 2.188865407820671

Epoch: 6| Step: 10
Training loss: 2.1846415996551514
Validation loss: 2.208604604967179

Epoch: 6| Step: 11
Training loss: 2.7458066940307617
Validation loss: 2.196590615857032

Epoch: 6| Step: 12
Training loss: 2.559006929397583
Validation loss: 2.198810751720141

Epoch: 6| Step: 13
Training loss: 1.5939021110534668
Validation loss: 2.1913389416151148

Epoch: 121| Step: 0
Training loss: 2.6242899894714355
Validation loss: 2.1897591185826126

Epoch: 6| Step: 1
Training loss: 3.1182055473327637
Validation loss: 2.1796669601112284

Epoch: 6| Step: 2
Training loss: 1.598780632019043
Validation loss: 2.175709932081161

Epoch: 6| Step: 3
Training loss: 2.177793502807617
Validation loss: 2.151334180626818

Epoch: 6| Step: 4
Training loss: 2.3947629928588867
Validation loss: 2.148902734120687

Epoch: 6| Step: 5
Training loss: 2.416808605194092
Validation loss: 2.158818215452215

Epoch: 6| Step: 6
Training loss: 2.5050201416015625
Validation loss: 2.138994191282539

Epoch: 6| Step: 7
Training loss: 2.914417266845703
Validation loss: 2.158139767185334

Epoch: 6| Step: 8
Training loss: 1.7990403175354004
Validation loss: 2.1551124972681843

Epoch: 6| Step: 9
Training loss: 2.697737693786621
Validation loss: 2.145124258533601

Epoch: 6| Step: 10
Training loss: 2.3254969120025635
Validation loss: 2.1241355660141155

Epoch: 6| Step: 11
Training loss: 1.967413306236267
Validation loss: 2.1203159260493454

Epoch: 6| Step: 12
Training loss: 2.4305667877197266
Validation loss: 2.124255326486403

Epoch: 6| Step: 13
Training loss: 2.663865566253662
Validation loss: 2.141381017623409

Epoch: 122| Step: 0
Training loss: 2.7406697273254395
Validation loss: 2.151998495542875

Epoch: 6| Step: 1
Training loss: 2.714773178100586
Validation loss: 2.1370430838677192

Epoch: 6| Step: 2
Training loss: 2.3125200271606445
Validation loss: 2.1332428711716847

Epoch: 6| Step: 3
Training loss: 1.956683874130249
Validation loss: 2.1226543893096266

Epoch: 6| Step: 4
Training loss: 2.1502623558044434
Validation loss: 2.12193041206688

Epoch: 6| Step: 5
Training loss: 2.6026532649993896
Validation loss: 2.1354500888496317

Epoch: 6| Step: 6
Training loss: 2.605085849761963
Validation loss: 2.134337317559027

Epoch: 6| Step: 7
Training loss: 2.4052867889404297
Validation loss: 2.140368060399127

Epoch: 6| Step: 8
Training loss: 2.013974189758301
Validation loss: 2.147498814008569

Epoch: 6| Step: 9
Training loss: 1.7444276809692383
Validation loss: 2.1950391812991072

Epoch: 6| Step: 10
Training loss: 2.7417001724243164
Validation loss: 2.2178751294330885

Epoch: 6| Step: 11
Training loss: 2.5186407566070557
Validation loss: 2.2158418432358773

Epoch: 6| Step: 12
Training loss: 2.128056526184082
Validation loss: 2.1805633421867125

Epoch: 6| Step: 13
Training loss: 2.7569820880889893
Validation loss: 2.1544798971504293

Epoch: 123| Step: 0
Training loss: 2.1232409477233887
Validation loss: 2.120784697994109

Epoch: 6| Step: 1
Training loss: 2.380382776260376
Validation loss: 2.118484893152791

Epoch: 6| Step: 2
Training loss: 1.919661045074463
Validation loss: 2.122515009295556

Epoch: 6| Step: 3
Training loss: 2.921123504638672
Validation loss: 2.1235473130338933

Epoch: 6| Step: 4
Training loss: 2.492628335952759
Validation loss: 2.123903856482557

Epoch: 6| Step: 5
Training loss: 2.2440133094787598
Validation loss: 2.1226890881856284

Epoch: 6| Step: 6
Training loss: 2.3659863471984863
Validation loss: 2.128352226749543

Epoch: 6| Step: 7
Training loss: 2.529919385910034
Validation loss: 2.1239550267496417

Epoch: 6| Step: 8
Training loss: 2.1956100463867188
Validation loss: 2.1238434366000596

Epoch: 6| Step: 9
Training loss: 1.886155128479004
Validation loss: 2.1265008065008346

Epoch: 6| Step: 10
Training loss: 2.9559125900268555
Validation loss: 2.125725555163558

Epoch: 6| Step: 11
Training loss: 2.8808987140655518
Validation loss: 2.1197375533401326

Epoch: 6| Step: 12
Training loss: 2.1812431812286377
Validation loss: 2.1202399935773624

Epoch: 6| Step: 13
Training loss: 2.1301980018615723
Validation loss: 2.1200184540082048

Epoch: 124| Step: 0
Training loss: 2.6801605224609375
Validation loss: 2.125125523536436

Epoch: 6| Step: 1
Training loss: 1.9755924940109253
Validation loss: 2.118157281670519

Epoch: 6| Step: 2
Training loss: 1.3472952842712402
Validation loss: 2.120194991429647

Epoch: 6| Step: 3
Training loss: 2.2592668533325195
Validation loss: 2.119185962984639

Epoch: 6| Step: 4
Training loss: 2.7291805744171143
Validation loss: 2.1189296348120576

Epoch: 6| Step: 5
Training loss: 2.4525842666625977
Validation loss: 2.131679268293483

Epoch: 6| Step: 6
Training loss: 2.6598873138427734
Validation loss: 2.147310741486088

Epoch: 6| Step: 7
Training loss: 2.705827236175537
Validation loss: 2.1846452348975727

Epoch: 6| Step: 8
Training loss: 2.2571659088134766
Validation loss: 2.228116258498161

Epoch: 6| Step: 9
Training loss: 2.1653075218200684
Validation loss: 2.2481891852553173

Epoch: 6| Step: 10
Training loss: 2.05519437789917
Validation loss: 2.1957136636139243

Epoch: 6| Step: 11
Training loss: 2.887381076812744
Validation loss: 2.154342201448256

Epoch: 6| Step: 12
Training loss: 2.5752203464508057
Validation loss: 2.1282583205930647

Epoch: 6| Step: 13
Training loss: 2.2448067665100098
Validation loss: 2.1164500380075104

Epoch: 125| Step: 0
Training loss: 1.9399603605270386
Validation loss: 2.1227083565086446

Epoch: 6| Step: 1
Training loss: 1.6785929203033447
Validation loss: 2.113804317289783

Epoch: 6| Step: 2
Training loss: 2.4283018112182617
Validation loss: 2.123908737654327

Epoch: 6| Step: 3
Training loss: 3.2739951610565186
Validation loss: 2.118601026073579

Epoch: 6| Step: 4
Training loss: 2.706617593765259
Validation loss: 2.1236050667301303

Epoch: 6| Step: 5
Training loss: 2.5134811401367188
Validation loss: 2.1262822240911503

Epoch: 6| Step: 6
Training loss: 1.8369648456573486
Validation loss: 2.133931916247132

Epoch: 6| Step: 7
Training loss: 2.428666591644287
Validation loss: 2.1296975792095227

Epoch: 6| Step: 8
Training loss: 2.576967239379883
Validation loss: 2.129500953100061

Epoch: 6| Step: 9
Training loss: 1.9379222393035889
Validation loss: 2.1450510524934336

Epoch: 6| Step: 10
Training loss: 2.471930980682373
Validation loss: 2.1532704189259517

Epoch: 6| Step: 11
Training loss: 2.5356178283691406
Validation loss: 2.1637054028049594

Epoch: 6| Step: 12
Training loss: 2.337651252746582
Validation loss: 2.186166419777819

Epoch: 6| Step: 13
Training loss: 2.613107442855835
Validation loss: 2.19842121934378

Epoch: 126| Step: 0
Training loss: 1.8965520858764648
Validation loss: 2.2111301678483204

Epoch: 6| Step: 1
Training loss: 2.4125564098358154
Validation loss: 2.2177975511038177

Epoch: 6| Step: 2
Training loss: 3.0594310760498047
Validation loss: 2.2290136634662585

Epoch: 6| Step: 3
Training loss: 3.2654824256896973
Validation loss: 2.2189898695997012

Epoch: 6| Step: 4
Training loss: 2.5537161827087402
Validation loss: 2.1894563500599196

Epoch: 6| Step: 5
Training loss: 2.4018354415893555
Validation loss: 2.18126444919135

Epoch: 6| Step: 6
Training loss: 2.2120914459228516
Validation loss: 2.152467990434298

Epoch: 6| Step: 7
Training loss: 1.8374981880187988
Validation loss: 2.152515047339983

Epoch: 6| Step: 8
Training loss: 2.8502306938171387
Validation loss: 2.149949522428615

Epoch: 6| Step: 9
Training loss: 1.9128655195236206
Validation loss: 2.1471687491222093

Epoch: 6| Step: 10
Training loss: 2.516730785369873
Validation loss: 2.1352535242675454

Epoch: 6| Step: 11
Training loss: 1.784329891204834
Validation loss: 2.1504599253336587

Epoch: 6| Step: 12
Training loss: 2.2025086879730225
Validation loss: 2.1498953014291744

Epoch: 6| Step: 13
Training loss: 1.7791646718978882
Validation loss: 2.1465118879913003

Epoch: 127| Step: 0
Training loss: 2.5909762382507324
Validation loss: 2.128804411939395

Epoch: 6| Step: 1
Training loss: 2.0717215538024902
Validation loss: 2.1244641632162113

Epoch: 6| Step: 2
Training loss: 2.5068552494049072
Validation loss: 2.1317218196007515

Epoch: 6| Step: 3
Training loss: 1.8455469608306885
Validation loss: 2.1211167830292896

Epoch: 6| Step: 4
Training loss: 2.2712268829345703
Validation loss: 2.1064404249191284

Epoch: 6| Step: 5
Training loss: 2.340665817260742
Validation loss: 2.119359823965257

Epoch: 6| Step: 6
Training loss: 1.9000139236450195
Validation loss: 2.1239200856096003

Epoch: 6| Step: 7
Training loss: 2.9181761741638184
Validation loss: 2.115796322463661

Epoch: 6| Step: 8
Training loss: 2.366588830947876
Validation loss: 2.1223190099962297

Epoch: 6| Step: 9
Training loss: 1.9191436767578125
Validation loss: 2.1021865132034465

Epoch: 6| Step: 10
Training loss: 2.644460678100586
Validation loss: 2.0890683461261053

Epoch: 6| Step: 11
Training loss: 2.2727608680725098
Validation loss: 2.0844405107600714

Epoch: 6| Step: 12
Training loss: 2.587890386581421
Validation loss: 2.0903864957953013

Epoch: 6| Step: 13
Training loss: 3.163829803466797
Validation loss: 2.080393914253481

Epoch: 128| Step: 0
Training loss: 2.075192451477051
Validation loss: 2.091334914648405

Epoch: 6| Step: 1
Training loss: 2.880690097808838
Validation loss: 2.0824295269545687

Epoch: 6| Step: 2
Training loss: 2.274725914001465
Validation loss: 2.089165441451534

Epoch: 6| Step: 3
Training loss: 2.1253411769866943
Validation loss: 2.0934810074426795

Epoch: 6| Step: 4
Training loss: 2.205275535583496
Validation loss: 2.1064058375614945

Epoch: 6| Step: 5
Training loss: 2.806868553161621
Validation loss: 2.112353845309186

Epoch: 6| Step: 6
Training loss: 2.3127071857452393
Validation loss: 2.1096335572581135

Epoch: 6| Step: 7
Training loss: 1.5650687217712402
Validation loss: 2.1171369552612305

Epoch: 6| Step: 8
Training loss: 2.2967681884765625
Validation loss: 2.1228369077046714

Epoch: 6| Step: 9
Training loss: 2.5555760860443115
Validation loss: 2.1220958771244174

Epoch: 6| Step: 10
Training loss: 2.2555465698242188
Validation loss: 2.1301224077901533

Epoch: 6| Step: 11
Training loss: 2.0468244552612305
Validation loss: 2.13278018787343

Epoch: 6| Step: 12
Training loss: 2.75966215133667
Validation loss: 2.139449309277278

Epoch: 6| Step: 13
Training loss: 2.9059224128723145
Validation loss: 2.1502509911855063

Epoch: 129| Step: 0
Training loss: 2.20458722114563
Validation loss: 2.135264491522184

Epoch: 6| Step: 1
Training loss: 2.3370468616485596
Validation loss: 2.1172284849228395

Epoch: 6| Step: 2
Training loss: 2.081028938293457
Validation loss: 2.1031730790292062

Epoch: 6| Step: 3
Training loss: 2.268920421600342
Validation loss: 2.088265352351691

Epoch: 6| Step: 4
Training loss: 1.7608548402786255
Validation loss: 2.081977739129015

Epoch: 6| Step: 5
Training loss: 2.964784622192383
Validation loss: 2.0869114527138333

Epoch: 6| Step: 6
Training loss: 2.076780319213867
Validation loss: 2.0907878004094607

Epoch: 6| Step: 7
Training loss: 2.805098056793213
Validation loss: 2.0912235988083707

Epoch: 6| Step: 8
Training loss: 2.5020813941955566
Validation loss: 2.0935590010817333

Epoch: 6| Step: 9
Training loss: 2.195341110229492
Validation loss: 2.0985804603945826

Epoch: 6| Step: 10
Training loss: 2.008795976638794
Validation loss: 2.1079131313549575

Epoch: 6| Step: 11
Training loss: 2.3475232124328613
Validation loss: 2.1174496514822847

Epoch: 6| Step: 12
Training loss: 2.5661826133728027
Validation loss: 2.134924332300822

Epoch: 6| Step: 13
Training loss: 2.8151350021362305
Validation loss: 2.139269951851137

Epoch: 130| Step: 0
Training loss: 2.049192428588867
Validation loss: 2.1529075176485124

Epoch: 6| Step: 1
Training loss: 2.338510274887085
Validation loss: 2.1418133807438675

Epoch: 6| Step: 2
Training loss: 2.2897040843963623
Validation loss: 2.12540667287765

Epoch: 6| Step: 3
Training loss: 2.561147689819336
Validation loss: 2.1125380633979716

Epoch: 6| Step: 4
Training loss: 3.127537727355957
Validation loss: 2.0982544973332393

Epoch: 6| Step: 5
Training loss: 1.890927791595459
Validation loss: 2.083353506621494

Epoch: 6| Step: 6
Training loss: 1.9744396209716797
Validation loss: 2.0789625952320714

Epoch: 6| Step: 7
Training loss: 1.6646595001220703
Validation loss: 2.080222201603715

Epoch: 6| Step: 8
Training loss: 2.613459348678589
Validation loss: 2.080270012219747

Epoch: 6| Step: 9
Training loss: 2.2589733600616455
Validation loss: 2.0823859783910934

Epoch: 6| Step: 10
Training loss: 3.0407094955444336
Validation loss: 2.0944105745643697

Epoch: 6| Step: 11
Training loss: 2.352816104888916
Validation loss: 2.108816913379136

Epoch: 6| Step: 12
Training loss: 2.544849395751953
Validation loss: 2.1325370496319187

Epoch: 6| Step: 13
Training loss: 1.6015604734420776
Validation loss: 2.1457459490786315

Epoch: 131| Step: 0
Training loss: 2.762592315673828
Validation loss: 2.161981794141954

Epoch: 6| Step: 1
Training loss: 2.766890048980713
Validation loss: 2.170584485095034

Epoch: 6| Step: 2
Training loss: 2.364248275756836
Validation loss: 2.1707259224307154

Epoch: 6| Step: 3
Training loss: 1.6038482189178467
Validation loss: 2.1468177149372716

Epoch: 6| Step: 4
Training loss: 2.7018842697143555
Validation loss: 2.1402290764675347

Epoch: 6| Step: 5
Training loss: 1.6482365131378174
Validation loss: 2.1352889140446982

Epoch: 6| Step: 6
Training loss: 2.7757444381713867
Validation loss: 2.1011927563657045

Epoch: 6| Step: 7
Training loss: 2.3834588527679443
Validation loss: 2.107232388629708

Epoch: 6| Step: 8
Training loss: 2.456101417541504
Validation loss: 2.1062069990301646

Epoch: 6| Step: 9
Training loss: 1.7649158239364624
Validation loss: 2.106066947342247

Epoch: 6| Step: 10
Training loss: 1.911756992340088
Validation loss: 2.109062535788423

Epoch: 6| Step: 11
Training loss: 2.496023654937744
Validation loss: 2.1120907311798423

Epoch: 6| Step: 12
Training loss: 2.7273917198181152
Validation loss: 2.1031012535095215

Epoch: 6| Step: 13
Training loss: 1.545082926750183
Validation loss: 2.09639193806597

Epoch: 132| Step: 0
Training loss: 1.9980340003967285
Validation loss: 2.098767195978472

Epoch: 6| Step: 1
Training loss: 2.2452285289764404
Validation loss: 2.0919890442202167

Epoch: 6| Step: 2
Training loss: 2.3416924476623535
Validation loss: 2.077768805206463

Epoch: 6| Step: 3
Training loss: 2.4470372200012207
Validation loss: 2.0821825278702604

Epoch: 6| Step: 4
Training loss: 3.084031343460083
Validation loss: 2.08556003339829

Epoch: 6| Step: 5
Training loss: 2.5527219772338867
Validation loss: 2.0957993294603083

Epoch: 6| Step: 6
Training loss: 1.4666106700897217
Validation loss: 2.099759796614288

Epoch: 6| Step: 7
Training loss: 1.918039083480835
Validation loss: 2.106211922502005

Epoch: 6| Step: 8
Training loss: 2.0272324085235596
Validation loss: 2.119600938212487

Epoch: 6| Step: 9
Training loss: 1.6982500553131104
Validation loss: 2.124032332051185

Epoch: 6| Step: 10
Training loss: 2.8061203956604004
Validation loss: 2.1415652972395702

Epoch: 6| Step: 11
Training loss: 3.088271141052246
Validation loss: 2.1511813645721762

Epoch: 6| Step: 12
Training loss: 2.1354706287384033
Validation loss: 2.1504721756904357

Epoch: 6| Step: 13
Training loss: 2.5713446140289307
Validation loss: 2.1600110018125145

Epoch: 133| Step: 0
Training loss: 2.994973659515381
Validation loss: 2.1521394355322725

Epoch: 6| Step: 1
Training loss: 2.319737434387207
Validation loss: 2.120256829005416

Epoch: 6| Step: 2
Training loss: 2.4330906867980957
Validation loss: 2.1020051023011566

Epoch: 6| Step: 3
Training loss: 1.8637685775756836
Validation loss: 2.0923561690956034

Epoch: 6| Step: 4
Training loss: 2.80804443359375
Validation loss: 2.085558188858853

Epoch: 6| Step: 5
Training loss: 1.9745585918426514
Validation loss: 2.0691826112808718

Epoch: 6| Step: 6
Training loss: 1.939225435256958
Validation loss: 2.0709134776105165

Epoch: 6| Step: 7
Training loss: 2.6930384635925293
Validation loss: 2.0781012324876684

Epoch: 6| Step: 8
Training loss: 2.327460765838623
Validation loss: 2.0660544749229186

Epoch: 6| Step: 9
Training loss: 2.0899157524108887
Validation loss: 2.070140702750093

Epoch: 6| Step: 10
Training loss: 2.6088738441467285
Validation loss: 2.092270157670462

Epoch: 6| Step: 11
Training loss: 1.4864039421081543
Validation loss: 2.0942027107361825

Epoch: 6| Step: 12
Training loss: 1.6084589958190918
Validation loss: 2.1191617417079147

Epoch: 6| Step: 13
Training loss: 3.3354501724243164
Validation loss: 2.14820219368063

Epoch: 134| Step: 0
Training loss: 2.5395991802215576
Validation loss: 2.1431229729806223

Epoch: 6| Step: 1
Training loss: 2.280010223388672
Validation loss: 2.151432955136863

Epoch: 6| Step: 2
Training loss: 2.0151052474975586
Validation loss: 2.188307349399854

Epoch: 6| Step: 3
Training loss: 2.507559299468994
Validation loss: 2.2058542954024447

Epoch: 6| Step: 4
Training loss: 2.338153600692749
Validation loss: 2.184034205252124

Epoch: 6| Step: 5
Training loss: 1.2059721946716309
Validation loss: 2.14468321236231

Epoch: 6| Step: 6
Training loss: 3.076557159423828
Validation loss: 2.1163039720186623

Epoch: 6| Step: 7
Training loss: 2.02494740486145
Validation loss: 2.101059188124954

Epoch: 6| Step: 8
Training loss: 2.677989959716797
Validation loss: 2.0793326695760093

Epoch: 6| Step: 9
Training loss: 2.2029471397399902
Validation loss: 2.070078903628934

Epoch: 6| Step: 10
Training loss: 2.805081844329834
Validation loss: 2.072746310182797

Epoch: 6| Step: 11
Training loss: 2.422825336456299
Validation loss: 2.0701736916777906

Epoch: 6| Step: 12
Training loss: 2.085662364959717
Validation loss: 2.0618870181422078

Epoch: 6| Step: 13
Training loss: 1.8864301443099976
Validation loss: 2.06191494131601

Epoch: 135| Step: 0
Training loss: 2.4587230682373047
Validation loss: 2.065994237058906

Epoch: 6| Step: 1
Training loss: 2.5267605781555176
Validation loss: 2.0800990007256948

Epoch: 6| Step: 2
Training loss: 2.211822986602783
Validation loss: 2.095391527298958

Epoch: 6| Step: 3
Training loss: 2.11580228805542
Validation loss: 2.097815400810652

Epoch: 6| Step: 4
Training loss: 1.9435479640960693
Validation loss: 2.0990695556004844

Epoch: 6| Step: 5
Training loss: 2.6152536869049072
Validation loss: 2.096851248894968

Epoch: 6| Step: 6
Training loss: 2.542707920074463
Validation loss: 2.1002541716380785

Epoch: 6| Step: 7
Training loss: 2.024855136871338
Validation loss: 2.111041327958466

Epoch: 6| Step: 8
Training loss: 2.309687376022339
Validation loss: 2.120776355907481

Epoch: 6| Step: 9
Training loss: 2.9533324241638184
Validation loss: 2.146662324987432

Epoch: 6| Step: 10
Training loss: 1.7117961645126343
Validation loss: 2.123789188682392

Epoch: 6| Step: 11
Training loss: 1.8174028396606445
Validation loss: 2.110938964351531

Epoch: 6| Step: 12
Training loss: 2.3447718620300293
Validation loss: 2.091894813763198

Epoch: 6| Step: 13
Training loss: 2.459325075149536
Validation loss: 2.0919686876317507

Epoch: 136| Step: 0
Training loss: 2.2307705879211426
Validation loss: 2.077119242760443

Epoch: 6| Step: 1
Training loss: 2.146730899810791
Validation loss: 2.0841593768007014

Epoch: 6| Step: 2
Training loss: 2.314297914505005
Validation loss: 2.083833320166475

Epoch: 6| Step: 3
Training loss: 2.5461432933807373
Validation loss: 2.0839855670928955

Epoch: 6| Step: 4
Training loss: 2.438697338104248
Validation loss: 2.089347331754623

Epoch: 6| Step: 5
Training loss: 1.9899518489837646
Validation loss: 2.0992385507911764

Epoch: 6| Step: 6
Training loss: 2.0030465126037598
Validation loss: 2.1117742843525384

Epoch: 6| Step: 7
Training loss: 2.3762192726135254
Validation loss: 2.136174968493882

Epoch: 6| Step: 8
Training loss: 1.6504628658294678
Validation loss: 2.1774571839199273

Epoch: 6| Step: 9
Training loss: 2.9248337745666504
Validation loss: 2.1943195686545423

Epoch: 6| Step: 10
Training loss: 2.4847939014434814
Validation loss: 2.1641416293318554

Epoch: 6| Step: 11
Training loss: 2.116258144378662
Validation loss: 2.1186058598179973

Epoch: 6| Step: 12
Training loss: 2.2152183055877686
Validation loss: 2.0977762617090696

Epoch: 6| Step: 13
Training loss: 3.1322314739227295
Validation loss: 2.092374191489271

Epoch: 137| Step: 0
Training loss: 2.02278995513916
Validation loss: 2.079900836431852

Epoch: 6| Step: 1
Training loss: 1.8507990837097168
Validation loss: 2.0829555347401607

Epoch: 6| Step: 2
Training loss: 1.528852939605713
Validation loss: 2.0739176580982823

Epoch: 6| Step: 3
Training loss: 2.613823890686035
Validation loss: 2.072567311666345

Epoch: 6| Step: 4
Training loss: 2.667520523071289
Validation loss: 2.0717674198971

Epoch: 6| Step: 5
Training loss: 1.992870569229126
Validation loss: 2.075303352007302

Epoch: 6| Step: 6
Training loss: 2.643246650695801
Validation loss: 2.07980090571988

Epoch: 6| Step: 7
Training loss: 2.3299450874328613
Validation loss: 2.083244627521884

Epoch: 6| Step: 8
Training loss: 2.8805925846099854
Validation loss: 2.092450767435053

Epoch: 6| Step: 9
Training loss: 2.3246848583221436
Validation loss: 2.097513007861312

Epoch: 6| Step: 10
Training loss: 2.369349479675293
Validation loss: 2.1065369844436646

Epoch: 6| Step: 11
Training loss: 2.625509023666382
Validation loss: 2.1082968981035295

Epoch: 6| Step: 12
Training loss: 1.4622198343276978
Validation loss: 2.1242251293633574

Epoch: 6| Step: 13
Training loss: 2.5092718601226807
Validation loss: 2.1419303224932764

Epoch: 138| Step: 0
Training loss: 1.9270602464675903
Validation loss: 2.177149021497337

Epoch: 6| Step: 1
Training loss: 2.0730690956115723
Validation loss: 2.204798044696931

Epoch: 6| Step: 2
Training loss: 3.2230913639068604
Validation loss: 2.200938024828511

Epoch: 6| Step: 3
Training loss: 3.039015293121338
Validation loss: 2.1672419348070697

Epoch: 6| Step: 4
Training loss: 2.478562355041504
Validation loss: 2.1328946057186333

Epoch: 6| Step: 5
Training loss: 2.430969715118408
Validation loss: 2.1306407836175736

Epoch: 6| Step: 6
Training loss: 2.085813522338867
Validation loss: 2.100758115450541

Epoch: 6| Step: 7
Training loss: 2.34867525100708
Validation loss: 2.086535030795682

Epoch: 6| Step: 8
Training loss: 2.0557589530944824
Validation loss: 2.0924994150797525

Epoch: 6| Step: 9
Training loss: 2.201429843902588
Validation loss: 2.082484713164709

Epoch: 6| Step: 10
Training loss: 1.6940369606018066
Validation loss: 2.0767522755489556

Epoch: 6| Step: 11
Training loss: 1.915814757347107
Validation loss: 2.066215120336061

Epoch: 6| Step: 12
Training loss: 1.9339768886566162
Validation loss: 2.0738700230916343

Epoch: 6| Step: 13
Training loss: 2.584944486618042
Validation loss: 2.080150031274365

Epoch: 139| Step: 0
Training loss: 2.0576748847961426
Validation loss: 2.076074689947149

Epoch: 6| Step: 1
Training loss: 2.676910400390625
Validation loss: 2.084706311584801

Epoch: 6| Step: 2
Training loss: 2.1575615406036377
Validation loss: 2.079457143301605

Epoch: 6| Step: 3
Training loss: 2.326385974884033
Validation loss: 2.080656756636917

Epoch: 6| Step: 4
Training loss: 2.337930202484131
Validation loss: 2.0891891871729205

Epoch: 6| Step: 5
Training loss: 2.096165657043457
Validation loss: 2.0875590719202513

Epoch: 6| Step: 6
Training loss: 1.7735917568206787
Validation loss: 2.0928960141315254

Epoch: 6| Step: 7
Training loss: 2.4973790645599365
Validation loss: 2.09827838149122

Epoch: 6| Step: 8
Training loss: 3.103640079498291
Validation loss: 2.0900153165222495

Epoch: 6| Step: 9
Training loss: 2.7966790199279785
Validation loss: 2.0850061421753256

Epoch: 6| Step: 10
Training loss: 2.19661545753479
Validation loss: 2.0865053233279975

Epoch: 6| Step: 11
Training loss: 1.772538661956787
Validation loss: 2.06757608280387

Epoch: 6| Step: 12
Training loss: 1.4411879777908325
Validation loss: 2.0641780463598107

Epoch: 6| Step: 13
Training loss: 2.1327250003814697
Validation loss: 2.0657930604873167

Epoch: 140| Step: 0
Training loss: 2.3513665199279785
Validation loss: 2.0748709235140073

Epoch: 6| Step: 1
Training loss: 2.06823992729187
Validation loss: 2.0750285951040124

Epoch: 6| Step: 2
Training loss: 2.4795267581939697
Validation loss: 2.093581409864528

Epoch: 6| Step: 3
Training loss: 2.1282315254211426
Validation loss: 2.102440021371329

Epoch: 6| Step: 4
Training loss: 2.2053070068359375
Validation loss: 2.115173811553627

Epoch: 6| Step: 5
Training loss: 2.0365123748779297
Validation loss: 2.111648339097218

Epoch: 6| Step: 6
Training loss: 2.4575889110565186
Validation loss: 2.118380332505831

Epoch: 6| Step: 7
Training loss: 2.633108139038086
Validation loss: 2.1132431543001564

Epoch: 6| Step: 8
Training loss: 2.0904781818389893
Validation loss: 2.1197815402861564

Epoch: 6| Step: 9
Training loss: 2.4882850646972656
Validation loss: 2.1163044847467893

Epoch: 6| Step: 10
Training loss: 2.4666264057159424
Validation loss: 2.126531813734321

Epoch: 6| Step: 11
Training loss: 2.563976764678955
Validation loss: 2.124213353280098

Epoch: 6| Step: 12
Training loss: 1.6451574563980103
Validation loss: 2.1361080228641467

Epoch: 6| Step: 13
Training loss: 1.777724027633667
Validation loss: 2.154122873019147

Epoch: 141| Step: 0
Training loss: 2.1184170246124268
Validation loss: 2.1711831169743694

Epoch: 6| Step: 1
Training loss: 2.1126863956451416
Validation loss: 2.192045011828023

Epoch: 6| Step: 2
Training loss: 2.4178414344787598
Validation loss: 2.198866267358103

Epoch: 6| Step: 3
Training loss: 2.6579580307006836
Validation loss: 2.193248556506249

Epoch: 6| Step: 4
Training loss: 2.7716526985168457
Validation loss: 2.1717376144983436

Epoch: 6| Step: 5
Training loss: 2.9962382316589355
Validation loss: 2.137906115542176

Epoch: 6| Step: 6
Training loss: 1.8567441701889038
Validation loss: 2.1093625689065583

Epoch: 6| Step: 7
Training loss: 2.604318857192993
Validation loss: 2.0814126383873726

Epoch: 6| Step: 8
Training loss: 2.5914406776428223
Validation loss: 2.0670544024436706

Epoch: 6| Step: 9
Training loss: 1.7965953350067139
Validation loss: 2.0673285722732544

Epoch: 6| Step: 10
Training loss: 1.9082109928131104
Validation loss: 2.0669843150723364

Epoch: 6| Step: 11
Training loss: 1.704290509223938
Validation loss: 2.075982928276062

Epoch: 6| Step: 12
Training loss: 2.081721782684326
Validation loss: 2.0748491287231445

Epoch: 6| Step: 13
Training loss: 1.867606282234192
Validation loss: 2.0865700014175905

Epoch: 142| Step: 0
Training loss: 2.7556674480438232
Validation loss: 2.0833043898305585

Epoch: 6| Step: 1
Training loss: 2.570875883102417
Validation loss: 2.0894437669425883

Epoch: 6| Step: 2
Training loss: 2.5820693969726562
Validation loss: 2.097009294776506

Epoch: 6| Step: 3
Training loss: 2.4341037273406982
Validation loss: 2.102505765935426

Epoch: 6| Step: 4
Training loss: 1.6886320114135742
Validation loss: 2.1099566028964136

Epoch: 6| Step: 5
Training loss: 1.8535237312316895
Validation loss: 2.094184280723654

Epoch: 6| Step: 6
Training loss: 2.2877116203308105
Validation loss: 2.1014999945958457

Epoch: 6| Step: 7
Training loss: 2.071685552597046
Validation loss: 2.1059810756355204

Epoch: 6| Step: 8
Training loss: 2.090325355529785
Validation loss: 2.107034401227069

Epoch: 6| Step: 9
Training loss: 1.5668292045593262
Validation loss: 2.115838894280054

Epoch: 6| Step: 10
Training loss: 2.5795257091522217
Validation loss: 2.1457334667123775

Epoch: 6| Step: 11
Training loss: 1.9288545846939087
Validation loss: 2.146946040532922

Epoch: 6| Step: 12
Training loss: 2.4688634872436523
Validation loss: 2.172451111578172

Epoch: 6| Step: 13
Training loss: 2.596693992614746
Validation loss: 2.1434220088425504

Epoch: 143| Step: 0
Training loss: 2.0614683628082275
Validation loss: 2.104990449002994

Epoch: 6| Step: 1
Training loss: 1.6549811363220215
Validation loss: 2.0931255330321608

Epoch: 6| Step: 2
Training loss: 2.1312429904937744
Validation loss: 2.077787886383713

Epoch: 6| Step: 3
Training loss: 1.8925869464874268
Validation loss: 2.072469631830851

Epoch: 6| Step: 4
Training loss: 2.5515027046203613
Validation loss: 2.0628667992930256

Epoch: 6| Step: 5
Training loss: 2.509647846221924
Validation loss: 2.0681771911600584

Epoch: 6| Step: 6
Training loss: 2.1486656665802
Validation loss: 2.06057269214302

Epoch: 6| Step: 7
Training loss: 2.637101411819458
Validation loss: 2.0806284566079416

Epoch: 6| Step: 8
Training loss: 2.2635483741760254
Validation loss: 2.086257921752109

Epoch: 6| Step: 9
Training loss: 1.8031322956085205
Validation loss: 2.083728003245528

Epoch: 6| Step: 10
Training loss: 2.1760730743408203
Validation loss: 2.0921326516776957

Epoch: 6| Step: 11
Training loss: 2.5159714221954346
Validation loss: 2.1106590827306113

Epoch: 6| Step: 12
Training loss: 2.4406869411468506
Validation loss: 2.121367995456983

Epoch: 6| Step: 13
Training loss: 2.8477158546447754
Validation loss: 2.1655444868149294

Epoch: 144| Step: 0
Training loss: 2.5875422954559326
Validation loss: 2.16831136006181

Epoch: 6| Step: 1
Training loss: 1.647378921508789
Validation loss: 2.1472092546442503

Epoch: 6| Step: 2
Training loss: 2.362367630004883
Validation loss: 2.1366224750395744

Epoch: 6| Step: 3
Training loss: 1.9586431980133057
Validation loss: 2.125653633507349

Epoch: 6| Step: 4
Training loss: 2.426241636276245
Validation loss: 2.118394051828692

Epoch: 6| Step: 5
Training loss: 1.7065379619598389
Validation loss: 2.124646750829553

Epoch: 6| Step: 6
Training loss: 2.247145175933838
Validation loss: 2.122978530904298

Epoch: 6| Step: 7
Training loss: 2.6759631633758545
Validation loss: 2.1232313494528494

Epoch: 6| Step: 8
Training loss: 2.1256911754608154
Validation loss: 2.1276609974522747

Epoch: 6| Step: 9
Training loss: 2.3025784492492676
Validation loss: 2.1250260952980287

Epoch: 6| Step: 10
Training loss: 2.108811855316162
Validation loss: 2.10150747658104

Epoch: 6| Step: 11
Training loss: 3.0329184532165527
Validation loss: 2.103376055276522

Epoch: 6| Step: 12
Training loss: 2.0997679233551025
Validation loss: 2.092987398947439

Epoch: 6| Step: 13
Training loss: 1.650941014289856
Validation loss: 2.0796573033896824

Epoch: 145| Step: 0
Training loss: 1.7463629245758057
Validation loss: 2.0641801241905458

Epoch: 6| Step: 1
Training loss: 2.6259593963623047
Validation loss: 2.0570823031087078

Epoch: 6| Step: 2
Training loss: 2.0158469676971436
Validation loss: 2.052108395484186

Epoch: 6| Step: 3
Training loss: 1.9021848440170288
Validation loss: 2.0501258821897608

Epoch: 6| Step: 4
Training loss: 1.731543779373169
Validation loss: 2.053306171970983

Epoch: 6| Step: 5
Training loss: 2.1985883712768555
Validation loss: 2.0709068390630905

Epoch: 6| Step: 6
Training loss: 2.3980231285095215
Validation loss: 2.0883504357389224

Epoch: 6| Step: 7
Training loss: 2.5593042373657227
Validation loss: 2.1104020777569024

Epoch: 6| Step: 8
Training loss: 2.1946825981140137
Validation loss: 2.1275107373473463

Epoch: 6| Step: 9
Training loss: 2.9076220989227295
Validation loss: 2.1640440135873775

Epoch: 6| Step: 10
Training loss: 2.1601622104644775
Validation loss: 2.1398897529930196

Epoch: 6| Step: 11
Training loss: 2.1303224563598633
Validation loss: 2.129798598186944

Epoch: 6| Step: 12
Training loss: 2.517548084259033
Validation loss: 2.1114700045636905

Epoch: 6| Step: 13
Training loss: 2.384690761566162
Validation loss: 2.085730121981713

Epoch: 146| Step: 0
Training loss: 2.2909812927246094
Validation loss: 2.0776661698536207

Epoch: 6| Step: 1
Training loss: 2.431657075881958
Validation loss: 2.0635006197037233

Epoch: 6| Step: 2
Training loss: 1.6636543273925781
Validation loss: 2.0710983635276876

Epoch: 6| Step: 3
Training loss: 2.714262008666992
Validation loss: 2.0680611595030753

Epoch: 6| Step: 4
Training loss: 2.0511748790740967
Validation loss: 2.066697061702769

Epoch: 6| Step: 5
Training loss: 2.005305528640747
Validation loss: 2.0714700363015615

Epoch: 6| Step: 6
Training loss: 2.015928030014038
Validation loss: 2.099179502456419

Epoch: 6| Step: 7
Training loss: 2.248546600341797
Validation loss: 2.1230371998202417

Epoch: 6| Step: 8
Training loss: 2.093018054962158
Validation loss: 2.138632578234519

Epoch: 6| Step: 9
Training loss: 2.2037134170532227
Validation loss: 2.149617793739483

Epoch: 6| Step: 10
Training loss: 2.228602170944214
Validation loss: 2.1244585078249694

Epoch: 6| Step: 11
Training loss: 2.7158772945404053
Validation loss: 2.123785836722261

Epoch: 6| Step: 12
Training loss: 2.487895965576172
Validation loss: 2.0981822962402017

Epoch: 6| Step: 13
Training loss: 1.4624394178390503
Validation loss: 2.0904165237180647

Epoch: 147| Step: 0
Training loss: 2.4800944328308105
Validation loss: 2.1036333883962324

Epoch: 6| Step: 1
Training loss: 2.042266845703125
Validation loss: 2.122380038743378

Epoch: 6| Step: 2
Training loss: 1.936635971069336
Validation loss: 2.133938136921134

Epoch: 6| Step: 3
Training loss: 3.3633487224578857
Validation loss: 2.1479128022347727

Epoch: 6| Step: 4
Training loss: 1.8512731790542603
Validation loss: 2.1544835541837957

Epoch: 6| Step: 5
Training loss: 2.352081060409546
Validation loss: 2.155779374543057

Epoch: 6| Step: 6
Training loss: 2.5076584815979004
Validation loss: 2.1299772813755977

Epoch: 6| Step: 7
Training loss: 1.7922723293304443
Validation loss: 2.122852599749001

Epoch: 6| Step: 8
Training loss: 2.150653600692749
Validation loss: 2.1044730191589682

Epoch: 6| Step: 9
Training loss: 2.2894837856292725
Validation loss: 2.072343417393264

Epoch: 6| Step: 10
Training loss: 2.2029805183410645
Validation loss: 2.067830508755099

Epoch: 6| Step: 11
Training loss: 1.7011299133300781
Validation loss: 2.0633821231062695

Epoch: 6| Step: 12
Training loss: 1.7638633251190186
Validation loss: 2.0588429076697237

Epoch: 6| Step: 13
Training loss: 2.2412490844726562
Validation loss: 2.0618283248716787

Epoch: 148| Step: 0
Training loss: 1.9729549884796143
Validation loss: 2.062556484694122

Epoch: 6| Step: 1
Training loss: 2.7251176834106445
Validation loss: 2.082446567473873

Epoch: 6| Step: 2
Training loss: 1.942699670791626
Validation loss: 2.1077732475855018

Epoch: 6| Step: 3
Training loss: 2.3093810081481934
Validation loss: 2.108075661043967

Epoch: 6| Step: 4
Training loss: 1.693507194519043
Validation loss: 2.1076953641829954

Epoch: 6| Step: 5
Training loss: 2.613015651702881
Validation loss: 2.1174087255231795

Epoch: 6| Step: 6
Training loss: 1.2069377899169922
Validation loss: 2.116650022486205

Epoch: 6| Step: 7
Training loss: 2.204939603805542
Validation loss: 2.127742516097202

Epoch: 6| Step: 8
Training loss: 2.138530731201172
Validation loss: 2.113924954527168

Epoch: 6| Step: 9
Training loss: 1.8793456554412842
Validation loss: 2.0934233357829433

Epoch: 6| Step: 10
Training loss: 2.21985125541687
Validation loss: 2.080270449320475

Epoch: 6| Step: 11
Training loss: 2.541030168533325
Validation loss: 2.072818386939264

Epoch: 6| Step: 12
Training loss: 2.8555119037628174
Validation loss: 2.073844249530505

Epoch: 6| Step: 13
Training loss: 2.410667896270752
Validation loss: 2.0954211347846576

Epoch: 149| Step: 0
Training loss: 2.0859484672546387
Validation loss: 2.0908273778935915

Epoch: 6| Step: 1
Training loss: 1.8497190475463867
Validation loss: 2.0908769228125132

Epoch: 6| Step: 2
Training loss: 1.7968683242797852
Validation loss: 2.086302093280259

Epoch: 6| Step: 3
Training loss: 1.9013086557388306
Validation loss: 2.0942616975435646

Epoch: 6| Step: 4
Training loss: 2.3250246047973633
Validation loss: 2.09100087740088

Epoch: 6| Step: 5
Training loss: 2.6144638061523438
Validation loss: 2.0859145682345153

Epoch: 6| Step: 6
Training loss: 1.6520390510559082
Validation loss: 2.091015851625832

Epoch: 6| Step: 7
Training loss: 2.8976633548736572
Validation loss: 2.0777263718266643

Epoch: 6| Step: 8
Training loss: 2.949934482574463
Validation loss: 2.0741120307676253

Epoch: 6| Step: 9
Training loss: 2.439999580383301
Validation loss: 2.0584732845265377

Epoch: 6| Step: 10
Training loss: 2.163123846054077
Validation loss: 2.0558194319407144

Epoch: 6| Step: 11
Training loss: 1.6804128885269165
Validation loss: 2.04549757383203

Epoch: 6| Step: 12
Training loss: 1.9361259937286377
Validation loss: 2.064744621194819

Epoch: 6| Step: 13
Training loss: 1.6893551349639893
Validation loss: 2.0806748764489287

Epoch: 150| Step: 0
Training loss: 2.937303066253662
Validation loss: 2.1002831561591035

Epoch: 6| Step: 1
Training loss: 1.8218005895614624
Validation loss: 2.117443279553485

Epoch: 6| Step: 2
Training loss: 2.420888900756836
Validation loss: 2.145655716619184

Epoch: 6| Step: 3
Training loss: 2.2108020782470703
Validation loss: 2.1662558740185154

Epoch: 6| Step: 4
Training loss: 1.3467987775802612
Validation loss: 2.1795066146440405

Epoch: 6| Step: 5
Training loss: 2.463005781173706
Validation loss: 2.223850741181322

Epoch: 6| Step: 6
Training loss: 1.9868793487548828
Validation loss: 2.2130564540945072

Epoch: 6| Step: 7
Training loss: 2.403986930847168
Validation loss: 2.219046118438885

Epoch: 6| Step: 8
Training loss: 1.962264060974121
Validation loss: 2.1699396179568384

Epoch: 6| Step: 9
Training loss: 2.5207889080047607
Validation loss: 2.1158391814078055

Epoch: 6| Step: 10
Training loss: 2.270780086517334
Validation loss: 2.0875207890746412

Epoch: 6| Step: 11
Training loss: 2.485469341278076
Validation loss: 2.0704882273110012

Epoch: 6| Step: 12
Training loss: 2.1676831245422363
Validation loss: 2.04798791357266

Epoch: 6| Step: 13
Training loss: 1.067764401435852
Validation loss: 2.0516026404596146

Epoch: 151| Step: 0
Training loss: 1.925182580947876
Validation loss: 2.0515998153276342

Epoch: 6| Step: 1
Training loss: 2.4520297050476074
Validation loss: 2.0522012966935352

Epoch: 6| Step: 2
Training loss: 2.47365140914917
Validation loss: 2.06296988584662

Epoch: 6| Step: 3
Training loss: 1.7953630685806274
Validation loss: 2.068834850865026

Epoch: 6| Step: 4
Training loss: 1.4365942478179932
Validation loss: 2.107143825100314

Epoch: 6| Step: 5
Training loss: 2.8556318283081055
Validation loss: 2.145548569258823

Epoch: 6| Step: 6
Training loss: 2.6728978157043457
Validation loss: 2.178848117910406

Epoch: 6| Step: 7
Training loss: 2.216489553451538
Validation loss: 2.179195442507344

Epoch: 6| Step: 8
Training loss: 1.9046306610107422
Validation loss: 2.155390129294447

Epoch: 6| Step: 9
Training loss: 2.476668119430542
Validation loss: 2.1285679647999425

Epoch: 6| Step: 10
Training loss: 2.4634146690368652
Validation loss: 2.118477375276627

Epoch: 6| Step: 11
Training loss: 1.5205321311950684
Validation loss: 2.09606098615995

Epoch: 6| Step: 12
Training loss: 2.0205516815185547
Validation loss: 2.077017388036174

Epoch: 6| Step: 13
Training loss: 1.805437684059143
Validation loss: 2.0701495985830984

Epoch: 152| Step: 0
Training loss: 2.6447365283966064
Validation loss: 2.061602997523482

Epoch: 6| Step: 1
Training loss: 2.421809196472168
Validation loss: 2.0567234972471833

Epoch: 6| Step: 2
Training loss: 2.603848934173584
Validation loss: 2.060644970145277

Epoch: 6| Step: 3
Training loss: 1.856440782546997
Validation loss: 2.0556964861449374

Epoch: 6| Step: 4
Training loss: 2.839897394180298
Validation loss: 2.0524603192524244

Epoch: 6| Step: 5
Training loss: 1.8014057874679565
Validation loss: 2.0592121437031734

Epoch: 6| Step: 6
Training loss: 1.9898786544799805
Validation loss: 2.077511659232519

Epoch: 6| Step: 7
Training loss: 1.797027587890625
Validation loss: 2.0794678080466484

Epoch: 6| Step: 8
Training loss: 1.9625663757324219
Validation loss: 2.093776910535751

Epoch: 6| Step: 9
Training loss: 1.8918111324310303
Validation loss: 2.1082101739862913

Epoch: 6| Step: 10
Training loss: 2.321265935897827
Validation loss: 2.139964565154045

Epoch: 6| Step: 11
Training loss: 2.0289621353149414
Validation loss: 2.1493476078074467

Epoch: 6| Step: 12
Training loss: 1.6890819072723389
Validation loss: 2.131950775782267

Epoch: 6| Step: 13
Training loss: 2.5626540184020996
Validation loss: 2.107503935854922

Epoch: 153| Step: 0
Training loss: 1.4707417488098145
Validation loss: 2.0794178260269987

Epoch: 6| Step: 1
Training loss: 1.7920465469360352
Validation loss: 2.071249072269727

Epoch: 6| Step: 2
Training loss: 1.6140590906143188
Validation loss: 2.0481407078363563

Epoch: 6| Step: 3
Training loss: 2.39970064163208
Validation loss: 2.0489603704021824

Epoch: 6| Step: 4
Training loss: 1.9520750045776367
Validation loss: 2.0606388007440875

Epoch: 6| Step: 5
Training loss: 2.427704095840454
Validation loss: 2.0570040133691605

Epoch: 6| Step: 6
Training loss: 2.6864094734191895
Validation loss: 2.074817225497256

Epoch: 6| Step: 7
Training loss: 2.6255273818969727
Validation loss: 2.080525767418646

Epoch: 6| Step: 8
Training loss: 2.101168632507324
Validation loss: 2.105476020484842

Epoch: 6| Step: 9
Training loss: 1.7847644090652466
Validation loss: 2.1116375589883454

Epoch: 6| Step: 10
Training loss: 2.0277881622314453
Validation loss: 2.098568824029738

Epoch: 6| Step: 11
Training loss: 2.68235182762146
Validation loss: 2.087260018112839

Epoch: 6| Step: 12
Training loss: 2.3742599487304688
Validation loss: 2.091192103201343

Epoch: 6| Step: 13
Training loss: 1.9779616594314575
Validation loss: 2.1012665481977564

Epoch: 154| Step: 0
Training loss: 2.329080581665039
Validation loss: 2.102387107828612

Epoch: 6| Step: 1
Training loss: 2.652674913406372
Validation loss: 2.0893816524936306

Epoch: 6| Step: 2
Training loss: 2.3099355697631836
Validation loss: 2.0953461816233974

Epoch: 6| Step: 3
Training loss: 2.538818836212158
Validation loss: 2.088346637705321

Epoch: 6| Step: 4
Training loss: 2.503938913345337
Validation loss: 2.081485579090734

Epoch: 6| Step: 5
Training loss: 2.515376567840576
Validation loss: 2.059619229326966

Epoch: 6| Step: 6
Training loss: 2.2485952377319336
Validation loss: 2.055900717294344

Epoch: 6| Step: 7
Training loss: 1.7676830291748047
Validation loss: 2.055261086392146

Epoch: 6| Step: 8
Training loss: 2.0864086151123047
Validation loss: 2.0679135014933925

Epoch: 6| Step: 9
Training loss: 1.8570098876953125
Validation loss: 2.0766416326645882

Epoch: 6| Step: 10
Training loss: 1.593269944190979
Validation loss: 2.088172915161297

Epoch: 6| Step: 11
Training loss: 1.5889296531677246
Validation loss: 2.071873270055299

Epoch: 6| Step: 12
Training loss: 1.5890027284622192
Validation loss: 2.0820044702099216

Epoch: 6| Step: 13
Training loss: 1.7156673669815063
Validation loss: 2.088070488745166

Epoch: 155| Step: 0
Training loss: 2.499399185180664
Validation loss: 2.114162033604037

Epoch: 6| Step: 1
Training loss: 2.3484060764312744
Validation loss: 2.148767073949178

Epoch: 6| Step: 2
Training loss: 2.125941753387451
Validation loss: 2.1438375762713853

Epoch: 6| Step: 3
Training loss: 1.9418349266052246
Validation loss: 2.113992101402693

Epoch: 6| Step: 4
Training loss: 1.6772212982177734
Validation loss: 2.1048133321987685

Epoch: 6| Step: 5
Training loss: 1.6079769134521484
Validation loss: 2.0736914052758166

Epoch: 6| Step: 6
Training loss: 2.121932029724121
Validation loss: 2.0802060224676646

Epoch: 6| Step: 7
Training loss: 2.7945685386657715
Validation loss: 2.0740871813989457

Epoch: 6| Step: 8
Training loss: 2.142848014831543
Validation loss: 2.08222258475519

Epoch: 6| Step: 9
Training loss: 2.4208426475524902
Validation loss: 2.0632259038186844

Epoch: 6| Step: 10
Training loss: 1.8539083003997803
Validation loss: 2.074271453324185

Epoch: 6| Step: 11
Training loss: 1.6752312183380127
Validation loss: 2.071312508275432

Epoch: 6| Step: 12
Training loss: 2.604318618774414
Validation loss: 2.0609931202344995

Epoch: 6| Step: 13
Training loss: 1.2740024328231812
Validation loss: 2.0726452386507423

Epoch: 156| Step: 0
Training loss: 2.1130623817443848
Validation loss: 2.085398838084231

Epoch: 6| Step: 1
Training loss: 2.118774890899658
Validation loss: 2.091528877135246

Epoch: 6| Step: 2
Training loss: 2.3501062393188477
Validation loss: 2.1047720037480837

Epoch: 6| Step: 3
Training loss: 2.6794991493225098
Validation loss: 2.1077647952623266

Epoch: 6| Step: 4
Training loss: 2.1340432167053223
Validation loss: 2.1132503350575766

Epoch: 6| Step: 5
Training loss: 1.5815712213516235
Validation loss: 2.1205520834974063

Epoch: 6| Step: 6
Training loss: 1.9634580612182617
Validation loss: 2.131853965020949

Epoch: 6| Step: 7
Training loss: 2.1608405113220215
Validation loss: 2.1582482912207164

Epoch: 6| Step: 8
Training loss: 2.3743762969970703
Validation loss: 2.1574460985840007

Epoch: 6| Step: 9
Training loss: 2.194868326187134
Validation loss: 2.1589369696955525

Epoch: 6| Step: 10
Training loss: 2.4310531616210938
Validation loss: 2.136991726454868

Epoch: 6| Step: 11
Training loss: 1.5452879667282104
Validation loss: 2.092849662227015

Epoch: 6| Step: 12
Training loss: 2.2778573036193848
Validation loss: 2.0846027648577126

Epoch: 6| Step: 13
Training loss: 0.76854008436203
Validation loss: 2.0675650822219027

Epoch: 157| Step: 0
Training loss: 2.231180191040039
Validation loss: 2.0721321926322034

Epoch: 6| Step: 1
Training loss: 2.030585765838623
Validation loss: 2.0628753426254436

Epoch: 6| Step: 2
Training loss: 2.2468528747558594
Validation loss: 2.0550956110800467

Epoch: 6| Step: 3
Training loss: 1.975795030593872
Validation loss: 2.0528246946232294

Epoch: 6| Step: 4
Training loss: 2.4419050216674805
Validation loss: 2.0597286301274456

Epoch: 6| Step: 5
Training loss: 2.060115337371826
Validation loss: 2.071507703873419

Epoch: 6| Step: 6
Training loss: 1.9823213815689087
Validation loss: 2.1223452911582044

Epoch: 6| Step: 7
Training loss: 2.4292964935302734
Validation loss: 2.165156149095105

Epoch: 6| Step: 8
Training loss: 2.7993006706237793
Validation loss: 2.2024960056427987

Epoch: 6| Step: 9
Training loss: 1.520240068435669
Validation loss: 2.2084257089963524

Epoch: 6| Step: 10
Training loss: 2.3391897678375244
Validation loss: 2.181103710205324

Epoch: 6| Step: 11
Training loss: 2.108747959136963
Validation loss: 2.1327175683872674

Epoch: 6| Step: 12
Training loss: 1.5740548372268677
Validation loss: 2.099607267687398

Epoch: 6| Step: 13
Training loss: 2.1228044033050537
Validation loss: 2.073800761212585

Epoch: 158| Step: 0
Training loss: 2.2454466819763184
Validation loss: 2.045688568904836

Epoch: 6| Step: 1
Training loss: 1.7039545774459839
Validation loss: 2.042161528782178

Epoch: 6| Step: 2
Training loss: 1.954509973526001
Validation loss: 2.0561881603733188

Epoch: 6| Step: 3
Training loss: 1.9930815696716309
Validation loss: 2.060951227782875

Epoch: 6| Step: 4
Training loss: 2.2680039405822754
Validation loss: 2.0682821119985273

Epoch: 6| Step: 5
Training loss: 2.1743428707122803
Validation loss: 2.0639591191404607

Epoch: 6| Step: 6
Training loss: 1.9334708452224731
Validation loss: 2.0549047198346866

Epoch: 6| Step: 7
Training loss: 2.6176939010620117
Validation loss: 2.0612819246066514

Epoch: 6| Step: 8
Training loss: 2.2116830348968506
Validation loss: 2.0790636847096104

Epoch: 6| Step: 9
Training loss: 1.532301664352417
Validation loss: 2.126186404176938

Epoch: 6| Step: 10
Training loss: 2.489403009414673
Validation loss: 2.147558630153697

Epoch: 6| Step: 11
Training loss: 2.808572769165039
Validation loss: 2.1944842030925136

Epoch: 6| Step: 12
Training loss: 2.162810802459717
Validation loss: 2.178717951620779

Epoch: 6| Step: 13
Training loss: 1.9400967359542847
Validation loss: 2.135680458878958

Epoch: 159| Step: 0
Training loss: 2.198288679122925
Validation loss: 2.097712396293558

Epoch: 6| Step: 1
Training loss: 2.1018502712249756
Validation loss: 2.06624258974547

Epoch: 6| Step: 2
Training loss: 2.009446620941162
Validation loss: 2.0297063012276926

Epoch: 6| Step: 3
Training loss: 2.5403497219085693
Validation loss: 2.007306659093467

Epoch: 6| Step: 4
Training loss: 1.325736403465271
Validation loss: 2.0004051090568624

Epoch: 6| Step: 5
Training loss: 2.6093945503234863
Validation loss: 2.007875181013538

Epoch: 6| Step: 6
Training loss: 1.9222056865692139
Validation loss: 1.9957364964228805

Epoch: 6| Step: 7
Training loss: 2.3898098468780518
Validation loss: 2.004045973541916

Epoch: 6| Step: 8
Training loss: 2.0957190990448
Validation loss: 2.0146989258386756

Epoch: 6| Step: 9
Training loss: 2.221859931945801
Validation loss: 2.041233426781111

Epoch: 6| Step: 10
Training loss: 1.9401389360427856
Validation loss: 2.056572057867563

Epoch: 6| Step: 11
Training loss: 2.3391785621643066
Validation loss: 2.096378737880338

Epoch: 6| Step: 12
Training loss: 2.4393436908721924
Validation loss: 2.114732203945037

Epoch: 6| Step: 13
Training loss: 1.4618659019470215
Validation loss: 2.136078872988301

Epoch: 160| Step: 0
Training loss: 2.493443489074707
Validation loss: 2.148041025284798

Epoch: 6| Step: 1
Training loss: 1.879591464996338
Validation loss: 2.1550990304639264

Epoch: 6| Step: 2
Training loss: 2.5319619178771973
Validation loss: 2.1371762265441236

Epoch: 6| Step: 3
Training loss: 2.3501172065734863
Validation loss: 2.1392581616678545

Epoch: 6| Step: 4
Training loss: 1.8449294567108154
Validation loss: 2.1186472626142603

Epoch: 6| Step: 5
Training loss: 1.8879492282867432
Validation loss: 2.10004489139844

Epoch: 6| Step: 6
Training loss: 2.240018606185913
Validation loss: 2.0904351767673286

Epoch: 6| Step: 7
Training loss: 1.0618293285369873
Validation loss: 2.0803460280100503

Epoch: 6| Step: 8
Training loss: 2.151524782180786
Validation loss: 2.071643812682039

Epoch: 6| Step: 9
Training loss: 2.471770763397217
Validation loss: 2.0702633139907674

Epoch: 6| Step: 10
Training loss: 1.81551194190979
Validation loss: 2.0726791684345534

Epoch: 6| Step: 11
Training loss: 2.657505750656128
Validation loss: 2.069315456574963

Epoch: 6| Step: 12
Training loss: 2.011870861053467
Validation loss: 2.053925206584315

Epoch: 6| Step: 13
Training loss: 1.881032943725586
Validation loss: 2.057346572158157

Epoch: 161| Step: 0
Training loss: 1.8735798597335815
Validation loss: 2.066774350340648

Epoch: 6| Step: 1
Training loss: 1.7454216480255127
Validation loss: 2.042872239184636

Epoch: 6| Step: 2
Training loss: 2.1749789714813232
Validation loss: 2.0526424120831233

Epoch: 6| Step: 3
Training loss: 2.2321102619171143
Validation loss: 2.0471913917090303

Epoch: 6| Step: 4
Training loss: 2.538918972015381
Validation loss: 2.041718175334315

Epoch: 6| Step: 5
Training loss: 2.3048481941223145
Validation loss: 2.0397898984211746

Epoch: 6| Step: 6
Training loss: 2.1123440265655518
Validation loss: 2.035746496210816

Epoch: 6| Step: 7
Training loss: 1.9947007894515991
Validation loss: 2.034023969404159

Epoch: 6| Step: 8
Training loss: 2.059389114379883
Validation loss: 2.0449302837412846

Epoch: 6| Step: 9
Training loss: 2.716010093688965
Validation loss: 2.067122999057975

Epoch: 6| Step: 10
Training loss: 1.1669055223464966
Validation loss: 2.0731464855132566

Epoch: 6| Step: 11
Training loss: 2.6364593505859375
Validation loss: 2.098775784174601

Epoch: 6| Step: 12
Training loss: 2.192502975463867
Validation loss: 2.1233495409770677

Epoch: 6| Step: 13
Training loss: 0.7753781676292419
Validation loss: 2.1344846910045994

Epoch: 162| Step: 0
Training loss: 2.6798787117004395
Validation loss: 2.1765225292533956

Epoch: 6| Step: 1
Training loss: 2.0177955627441406
Validation loss: 2.199882963652252

Epoch: 6| Step: 2
Training loss: 2.0756547451019287
Validation loss: 2.200593932982414

Epoch: 6| Step: 3
Training loss: 1.9517009258270264
Validation loss: 2.159099881367017

Epoch: 6| Step: 4
Training loss: 2.000150680541992
Validation loss: 2.117019453356343

Epoch: 6| Step: 5
Training loss: 2.197063446044922
Validation loss: 2.1073160440691057

Epoch: 6| Step: 6
Training loss: 2.4975385665893555
Validation loss: 2.0839468843193463

Epoch: 6| Step: 7
Training loss: 2.019422769546509
Validation loss: 2.0835727555777437

Epoch: 6| Step: 8
Training loss: 1.6380321979522705
Validation loss: 2.079648522920506

Epoch: 6| Step: 9
Training loss: 2.185168981552124
Validation loss: 2.084672410001037

Epoch: 6| Step: 10
Training loss: 1.699681043624878
Validation loss: 2.0834252372864754

Epoch: 6| Step: 11
Training loss: 2.0994958877563477
Validation loss: 2.094451085213692

Epoch: 6| Step: 12
Training loss: 2.3148272037506104
Validation loss: 2.1021385115961873

Epoch: 6| Step: 13
Training loss: 2.301511526107788
Validation loss: 2.1064319584959295

Epoch: 163| Step: 0
Training loss: 3.034152030944824
Validation loss: 2.107480227306325

Epoch: 6| Step: 1
Training loss: 2.7711308002471924
Validation loss: 2.12123639481042

Epoch: 6| Step: 2
Training loss: 1.948246717453003
Validation loss: 2.1081348029516076

Epoch: 6| Step: 3
Training loss: 1.9174869060516357
Validation loss: 2.1193395583860335

Epoch: 6| Step: 4
Training loss: 1.9586536884307861
Validation loss: 2.1239283289960635

Epoch: 6| Step: 5
Training loss: 2.098179340362549
Validation loss: 2.151138504346212

Epoch: 6| Step: 6
Training loss: 2.108887195587158
Validation loss: 2.169656745849117

Epoch: 6| Step: 7
Training loss: 2.272447347640991
Validation loss: 2.1748812993367515

Epoch: 6| Step: 8
Training loss: 1.5382893085479736
Validation loss: 2.1836888341493506

Epoch: 6| Step: 9
Training loss: 2.130908966064453
Validation loss: 2.1703240948338665

Epoch: 6| Step: 10
Training loss: 1.6660194396972656
Validation loss: 2.1458861481758857

Epoch: 6| Step: 11
Training loss: 1.9066989421844482
Validation loss: 2.121837439075593

Epoch: 6| Step: 12
Training loss: 1.876592993736267
Validation loss: 2.0899543634024997

Epoch: 6| Step: 13
Training loss: 1.1288437843322754
Validation loss: 2.0916293436481106

Epoch: 164| Step: 0
Training loss: 2.1763477325439453
Validation loss: 2.087370013677946

Epoch: 6| Step: 1
Training loss: 2.429649829864502
Validation loss: 2.0955602020345707

Epoch: 6| Step: 2
Training loss: 2.3979334831237793
Validation loss: 2.11684400035489

Epoch: 6| Step: 3
Training loss: 1.6672241687774658
Validation loss: 2.125706854686942

Epoch: 6| Step: 4
Training loss: 1.8257722854614258
Validation loss: 2.1531707522689656

Epoch: 6| Step: 5
Training loss: 1.5808866024017334
Validation loss: 2.1744552145722094

Epoch: 6| Step: 6
Training loss: 2.121624708175659
Validation loss: 2.2028165478860178

Epoch: 6| Step: 7
Training loss: 1.7079687118530273
Validation loss: 2.217633403757567

Epoch: 6| Step: 8
Training loss: 2.246384620666504
Validation loss: 2.264063940253309

Epoch: 6| Step: 9
Training loss: 2.1917762756347656
Validation loss: 2.2729625855722735

Epoch: 6| Step: 10
Training loss: 2.064896583557129
Validation loss: 2.267512183035574

Epoch: 6| Step: 11
Training loss: 1.811522364616394
Validation loss: 2.205831194436678

Epoch: 6| Step: 12
Training loss: 2.518836259841919
Validation loss: 2.132855387144191

Epoch: 6| Step: 13
Training loss: 2.779956340789795
Validation loss: 2.1287331068387596

Epoch: 165| Step: 0
Training loss: 2.447571277618408
Validation loss: 2.122674770252679

Epoch: 6| Step: 1
Training loss: 2.3069961071014404
Validation loss: 2.1143123154999106

Epoch: 6| Step: 2
Training loss: 1.8916836977005005
Validation loss: 2.106969018136301

Epoch: 6| Step: 3
Training loss: 1.8247531652450562
Validation loss: 2.0908184128422893

Epoch: 6| Step: 4
Training loss: 1.9939171075820923
Validation loss: 2.075702175017326

Epoch: 6| Step: 5
Training loss: 2.59555983543396
Validation loss: 2.0881987156406527

Epoch: 6| Step: 6
Training loss: 2.0946109294891357
Validation loss: 2.0678783975621706

Epoch: 6| Step: 7
Training loss: 2.2286250591278076
Validation loss: 2.070193341983262

Epoch: 6| Step: 8
Training loss: 1.5347135066986084
Validation loss: 2.115767817343435

Epoch: 6| Step: 9
Training loss: 2.0623528957366943
Validation loss: 2.1544845616945656

Epoch: 6| Step: 10
Training loss: 2.2785840034484863
Validation loss: 2.242233009748561

Epoch: 6| Step: 11
Training loss: 1.7001112699508667
Validation loss: 2.28434113020538

Epoch: 6| Step: 12
Training loss: 2.2083818912506104
Validation loss: 2.257466394414184

Epoch: 6| Step: 13
Training loss: 2.607977867126465
Validation loss: 2.221079321317775

Epoch: 166| Step: 0
Training loss: 1.6722958087921143
Validation loss: 2.159742057964366

Epoch: 6| Step: 1
Training loss: 2.561086893081665
Validation loss: 2.115882496679983

Epoch: 6| Step: 2
Training loss: 1.7239320278167725
Validation loss: 2.1042614047245314

Epoch: 6| Step: 3
Training loss: 2.3138926029205322
Validation loss: 2.096367512979815

Epoch: 6| Step: 4
Training loss: 1.5418763160705566
Validation loss: 2.089162452246553

Epoch: 6| Step: 5
Training loss: 1.6065871715545654
Validation loss: 2.0880660459559452

Epoch: 6| Step: 6
Training loss: 1.529404878616333
Validation loss: 2.0996329963848157

Epoch: 6| Step: 7
Training loss: 2.292238235473633
Validation loss: 2.0999021453242146

Epoch: 6| Step: 8
Training loss: 2.066988468170166
Validation loss: 2.108795782571198

Epoch: 6| Step: 9
Training loss: 2.254704713821411
Validation loss: 2.1119154525059525

Epoch: 6| Step: 10
Training loss: 2.061232566833496
Validation loss: 2.117407521893901

Epoch: 6| Step: 11
Training loss: 2.0721664428710938
Validation loss: 2.169267221163678

Epoch: 6| Step: 12
Training loss: 2.5487232208251953
Validation loss: 2.196365543591079

Epoch: 6| Step: 13
Training loss: 2.8312416076660156
Validation loss: 2.230996234442598

Epoch: 167| Step: 0
Training loss: 1.4786341190338135
Validation loss: 2.218751950930524

Epoch: 6| Step: 1
Training loss: 1.9243323802947998
Validation loss: 2.186007397149199

Epoch: 6| Step: 2
Training loss: 2.094306468963623
Validation loss: 2.1560767953113844

Epoch: 6| Step: 3
Training loss: 1.7875661849975586
Validation loss: 2.1361320121313936

Epoch: 6| Step: 4
Training loss: 1.769209384918213
Validation loss: 2.139677248975282

Epoch: 6| Step: 5
Training loss: 1.8060065507888794
Validation loss: 2.118849282623619

Epoch: 6| Step: 6
Training loss: 1.5529608726501465
Validation loss: 2.116934673760527

Epoch: 6| Step: 7
Training loss: 2.1487152576446533
Validation loss: 2.107032657951437

Epoch: 6| Step: 8
Training loss: 2.143664598464966
Validation loss: 2.112442672893565

Epoch: 6| Step: 9
Training loss: 1.7710552215576172
Validation loss: 2.1300678176264607

Epoch: 6| Step: 10
Training loss: 2.4732251167297363
Validation loss: 2.1489775129543838

Epoch: 6| Step: 11
Training loss: 2.260209083557129
Validation loss: 2.187176619806597

Epoch: 6| Step: 12
Training loss: 3.081923723220825
Validation loss: 2.2116902823089273

Epoch: 6| Step: 13
Training loss: 2.561051607131958
Validation loss: 2.2034716324139665

Epoch: 168| Step: 0
Training loss: 1.731499195098877
Validation loss: 2.21477016838648

Epoch: 6| Step: 1
Training loss: 2.0736899375915527
Validation loss: 2.2103171617754045

Epoch: 6| Step: 2
Training loss: 1.5947554111480713
Validation loss: 2.223549396761002

Epoch: 6| Step: 3
Training loss: 2.1568899154663086
Validation loss: 2.214821546308456

Epoch: 6| Step: 4
Training loss: 2.0972418785095215
Validation loss: 2.191068603146461

Epoch: 6| Step: 5
Training loss: 1.9245305061340332
Validation loss: 2.1919713891962522

Epoch: 6| Step: 6
Training loss: 2.1181159019470215
Validation loss: 2.1609798413451

Epoch: 6| Step: 7
Training loss: 2.21665096282959
Validation loss: 2.152409509945941

Epoch: 6| Step: 8
Training loss: 2.2007484436035156
Validation loss: 2.1623213701350714

Epoch: 6| Step: 9
Training loss: 2.7802040576934814
Validation loss: 2.1508064000837264

Epoch: 6| Step: 10
Training loss: 1.7402119636535645
Validation loss: 2.145941580495527

Epoch: 6| Step: 11
Training loss: 1.6403404474258423
Validation loss: 2.110236998527281

Epoch: 6| Step: 12
Training loss: 1.695214033126831
Validation loss: 2.1019182435927855

Epoch: 6| Step: 13
Training loss: 1.8846874237060547
Validation loss: 2.0834551703545356

Epoch: 169| Step: 0
Training loss: 2.1048743724823
Validation loss: 2.0963143328184723

Epoch: 6| Step: 1
Training loss: 2.761064052581787
Validation loss: 2.097318523673601

Epoch: 6| Step: 2
Training loss: 1.8626890182495117
Validation loss: 2.098789632961314

Epoch: 6| Step: 3
Training loss: 1.907036304473877
Validation loss: 2.084755095102454

Epoch: 6| Step: 4
Training loss: 1.5969517230987549
Validation loss: 2.1007805947334535

Epoch: 6| Step: 5
Training loss: 1.7729982137680054
Validation loss: 2.0961413614211546

Epoch: 6| Step: 6
Training loss: 1.0694246292114258
Validation loss: 2.1092375298982025

Epoch: 6| Step: 7
Training loss: 1.8225691318511963
Validation loss: 2.0828515111759143

Epoch: 6| Step: 8
Training loss: 1.851206660270691
Validation loss: 2.098498193166589

Epoch: 6| Step: 9
Training loss: 2.4549503326416016
Validation loss: 2.094213725418173

Epoch: 6| Step: 10
Training loss: 1.8519771099090576
Validation loss: 2.092702178544896

Epoch: 6| Step: 11
Training loss: 2.2149460315704346
Validation loss: 2.099609233999765

Epoch: 6| Step: 12
Training loss: 1.8659663200378418
Validation loss: 2.096082111840607

Epoch: 6| Step: 13
Training loss: 2.7637851238250732
Validation loss: 2.1161487461418234

Epoch: 170| Step: 0
Training loss: 2.082479953765869
Validation loss: 2.139908035596212

Epoch: 6| Step: 1
Training loss: 1.5103261470794678
Validation loss: 2.154063845193514

Epoch: 6| Step: 2
Training loss: 2.168175220489502
Validation loss: 2.159235700484245

Epoch: 6| Step: 3
Training loss: 1.8057518005371094
Validation loss: 2.141150025911229

Epoch: 6| Step: 4
Training loss: 1.8066295385360718
Validation loss: 2.148155871257987

Epoch: 6| Step: 5
Training loss: 1.8592220544815063
Validation loss: 2.122843534715714

Epoch: 6| Step: 6
Training loss: 2.4380388259887695
Validation loss: 2.1011294626420542

Epoch: 6| Step: 7
Training loss: 2.206545114517212
Validation loss: 2.1048255710191626

Epoch: 6| Step: 8
Training loss: 2.2930359840393066
Validation loss: 2.1083256775333035

Epoch: 6| Step: 9
Training loss: 2.0615553855895996
Validation loss: 2.094858120846492

Epoch: 6| Step: 10
Training loss: 1.9554195404052734
Validation loss: 2.1073567482732956

Epoch: 6| Step: 11
Training loss: 1.7781486511230469
Validation loss: 2.1105637832354476

Epoch: 6| Step: 12
Training loss: 1.7401936054229736
Validation loss: 2.1073518901742916

Epoch: 6| Step: 13
Training loss: 1.7722594738006592
Validation loss: 2.1101690159049085

Epoch: 171| Step: 0
Training loss: 2.1456685066223145
Validation loss: 2.0896642413190616

Epoch: 6| Step: 1
Training loss: 1.9485809803009033
Validation loss: 2.0817947003149215

Epoch: 6| Step: 2
Training loss: 2.4642529487609863
Validation loss: 2.1040246179026942

Epoch: 6| Step: 3
Training loss: 1.889043927192688
Validation loss: 2.100976321005052

Epoch: 6| Step: 4
Training loss: 1.8924397230148315
Validation loss: 2.1176910682391097

Epoch: 6| Step: 5
Training loss: 1.681466817855835
Validation loss: 2.1338621621490805

Epoch: 6| Step: 6
Training loss: 2.3227972984313965
Validation loss: 2.174671293586813

Epoch: 6| Step: 7
Training loss: 1.7356815338134766
Validation loss: 2.1571911329864175

Epoch: 6| Step: 8
Training loss: 0.9278033971786499
Validation loss: 2.1267234035717544

Epoch: 6| Step: 9
Training loss: 2.101719856262207
Validation loss: 2.0900720627077165

Epoch: 6| Step: 10
Training loss: 2.0878591537475586
Validation loss: 2.0965472241883636

Epoch: 6| Step: 11
Training loss: 1.8328042030334473
Validation loss: 2.067049131598524

Epoch: 6| Step: 12
Training loss: 2.047929286956787
Validation loss: 2.0693452819701164

Epoch: 6| Step: 13
Training loss: 2.356562376022339
Validation loss: 2.06913742198739

Epoch: 172| Step: 0
Training loss: 2.221768856048584
Validation loss: 2.0687442005321546

Epoch: 6| Step: 1
Training loss: 1.7710473537445068
Validation loss: 2.062248641444791

Epoch: 6| Step: 2
Training loss: 2.3287501335144043
Validation loss: 2.0737432664440525

Epoch: 6| Step: 3
Training loss: 1.4949123859405518
Validation loss: 2.092440282144854

Epoch: 6| Step: 4
Training loss: 1.4801881313323975
Validation loss: 2.129630809189171

Epoch: 6| Step: 5
Training loss: 1.5787118673324585
Validation loss: 2.164390437064632

Epoch: 6| Step: 6
Training loss: 1.7076411247253418
Validation loss: 2.214039776914863

Epoch: 6| Step: 7
Training loss: 2.193120002746582
Validation loss: 2.2292451602156445

Epoch: 6| Step: 8
Training loss: 2.674773693084717
Validation loss: 2.2300573933509087

Epoch: 6| Step: 9
Training loss: 1.9144768714904785
Validation loss: 2.1857694643799976

Epoch: 6| Step: 10
Training loss: 1.2905991077423096
Validation loss: 2.151340271836968

Epoch: 6| Step: 11
Training loss: 2.083096504211426
Validation loss: 2.14297995516049

Epoch: 6| Step: 12
Training loss: 2.1591827869415283
Validation loss: 2.1150511541674213

Epoch: 6| Step: 13
Training loss: 2.7166588306427
Validation loss: 2.129209667123774

Epoch: 173| Step: 0
Training loss: 1.280538558959961
Validation loss: 2.128481395782963

Epoch: 6| Step: 1
Training loss: 1.8729387521743774
Validation loss: 2.1388507632799048

Epoch: 6| Step: 2
Training loss: 2.3388009071350098
Validation loss: 2.1558119648246357

Epoch: 6| Step: 3
Training loss: 1.9400123357772827
Validation loss: 2.169208844502767

Epoch: 6| Step: 4
Training loss: 1.8341355323791504
Validation loss: 2.184146224811513

Epoch: 6| Step: 5
Training loss: 1.4869834184646606
Validation loss: 2.185431049716088

Epoch: 6| Step: 6
Training loss: 2.3832125663757324
Validation loss: 2.18708562338224

Epoch: 6| Step: 7
Training loss: 2.0915958881378174
Validation loss: 2.1956513415100756

Epoch: 6| Step: 8
Training loss: 2.983344316482544
Validation loss: 2.178792833000101

Epoch: 6| Step: 9
Training loss: 1.5471088886260986
Validation loss: 2.17232257832763

Epoch: 6| Step: 10
Training loss: 2.0487406253814697
Validation loss: 2.1683268931604203

Epoch: 6| Step: 11
Training loss: 0.9932762384414673
Validation loss: 2.148916505998181

Epoch: 6| Step: 12
Training loss: 2.4420089721679688
Validation loss: 2.142826545623041

Epoch: 6| Step: 13
Training loss: 1.1637524366378784
Validation loss: 2.1297171756785405

Epoch: 174| Step: 0
Training loss: 1.1817140579223633
Validation loss: 2.1194433384044196

Epoch: 6| Step: 1
Training loss: 1.787772297859192
Validation loss: 2.0919895838665705

Epoch: 6| Step: 2
Training loss: 1.5555980205535889
Validation loss: 2.096555632929648

Epoch: 6| Step: 3
Training loss: 1.7078015804290771
Validation loss: 2.0955119427814277

Epoch: 6| Step: 4
Training loss: 1.8052014112472534
Validation loss: 2.1278786505422285

Epoch: 6| Step: 5
Training loss: 2.063873767852783
Validation loss: 2.1624583762179137

Epoch: 6| Step: 6
Training loss: 1.899782657623291
Validation loss: 2.198173466549125

Epoch: 6| Step: 7
Training loss: 2.737231731414795
Validation loss: 2.2398412304539836

Epoch: 6| Step: 8
Training loss: 1.4777872562408447
Validation loss: 2.2626989272332962

Epoch: 6| Step: 9
Training loss: 1.6550389528274536
Validation loss: 2.262315188684771

Epoch: 6| Step: 10
Training loss: 2.5119683742523193
Validation loss: 2.2705138883283063

Epoch: 6| Step: 11
Training loss: 2.129021644592285
Validation loss: 2.276889829225438

Epoch: 6| Step: 12
Training loss: 2.420565605163574
Validation loss: 2.2645461277295182

Epoch: 6| Step: 13
Training loss: 2.464686393737793
Validation loss: 2.245366540006412

Epoch: 175| Step: 0
Training loss: 1.9044065475463867
Validation loss: 2.2165848875558503

Epoch: 6| Step: 1
Training loss: 1.3447058200836182
Validation loss: 2.187941946009154

Epoch: 6| Step: 2
Training loss: 1.9899965524673462
Validation loss: 2.139661168539396

Epoch: 6| Step: 3
Training loss: 2.751783847808838
Validation loss: 2.1325605428347023

Epoch: 6| Step: 4
Training loss: 1.9687923192977905
Validation loss: 2.1244686444600425

Epoch: 6| Step: 5
Training loss: 1.889336347579956
Validation loss: 2.134578738161313

Epoch: 6| Step: 6
Training loss: 1.622267723083496
Validation loss: 2.1392320561152633

Epoch: 6| Step: 7
Training loss: 1.5914757251739502
Validation loss: 2.131393653090282

Epoch: 6| Step: 8
Training loss: 1.6549255847930908
Validation loss: 2.152905200117378

Epoch: 6| Step: 9
Training loss: 2.2595274448394775
Validation loss: 2.1592700558324016

Epoch: 6| Step: 10
Training loss: 1.6590653657913208
Validation loss: 2.1446302783104683

Epoch: 6| Step: 11
Training loss: 2.445326089859009
Validation loss: 2.1572277981747865

Epoch: 6| Step: 12
Training loss: 1.8792810440063477
Validation loss: 2.1347585826791744

Epoch: 6| Step: 13
Training loss: 2.235043525695801
Validation loss: 2.1074567405126428

Epoch: 176| Step: 0
Training loss: 1.8632190227508545
Validation loss: 2.1078817177844305

Epoch: 6| Step: 1
Training loss: 2.0033211708068848
Validation loss: 2.1237753206683743

Epoch: 6| Step: 2
Training loss: 1.4552286863327026
Validation loss: 2.125626997281146

Epoch: 6| Step: 3
Training loss: 1.77786386013031
Validation loss: 2.137280456481441

Epoch: 6| Step: 4
Training loss: 1.6122641563415527
Validation loss: 2.169244509871288

Epoch: 6| Step: 5
Training loss: 2.350510835647583
Validation loss: 2.1894617644689416

Epoch: 6| Step: 6
Training loss: 2.0306179523468018
Validation loss: 2.1948031212693904

Epoch: 6| Step: 7
Training loss: 2.232452392578125
Validation loss: 2.2095971620211037

Epoch: 6| Step: 8
Training loss: 2.4469261169433594
Validation loss: 2.212035902084843

Epoch: 6| Step: 9
Training loss: 1.9068766832351685
Validation loss: 2.1898250310651717

Epoch: 6| Step: 10
Training loss: 1.2571076154708862
Validation loss: 2.1636841220240437

Epoch: 6| Step: 11
Training loss: 2.083298683166504
Validation loss: 2.143070541402345

Epoch: 6| Step: 12
Training loss: 2.1401219367980957
Validation loss: 2.125247807912929

Epoch: 6| Step: 13
Training loss: 1.6886670589447021
Validation loss: 2.1346572881103842

Epoch: 177| Step: 0
Training loss: 1.5218713283538818
Validation loss: 2.1549123025709584

Epoch: 6| Step: 1
Training loss: 2.5254030227661133
Validation loss: 2.142777540350473

Epoch: 6| Step: 2
Training loss: 1.985571265220642
Validation loss: 2.1387117806301323

Epoch: 6| Step: 3
Training loss: 2.0445950031280518
Validation loss: 2.1182740042286534

Epoch: 6| Step: 4
Training loss: 2.1476340293884277
Validation loss: 2.13570769756071

Epoch: 6| Step: 5
Training loss: 1.7335622310638428
Validation loss: 2.1316432619607575

Epoch: 6| Step: 6
Training loss: 2.04447340965271
Validation loss: 2.1186559636105775

Epoch: 6| Step: 7
Training loss: 1.6101014614105225
Validation loss: 2.1127202997925463

Epoch: 6| Step: 8
Training loss: 1.3100786209106445
Validation loss: 2.1048161240034204

Epoch: 6| Step: 9
Training loss: 2.213552474975586
Validation loss: 2.1187652105926187

Epoch: 6| Step: 10
Training loss: 1.7360213994979858
Validation loss: 2.1204192176941903

Epoch: 6| Step: 11
Training loss: 1.42828369140625
Validation loss: 2.1424110358761204

Epoch: 6| Step: 12
Training loss: 2.313721179962158
Validation loss: 2.1502762533003286

Epoch: 6| Step: 13
Training loss: 1.9879239797592163
Validation loss: 2.14888148794892

Epoch: 178| Step: 0
Training loss: 2.039701461791992
Validation loss: 2.156321397391699

Epoch: 6| Step: 1
Training loss: 1.838931679725647
Validation loss: 2.1871626505287747

Epoch: 6| Step: 2
Training loss: 1.8656556606292725
Validation loss: 2.202678629147109

Epoch: 6| Step: 3
Training loss: 1.7223434448242188
Validation loss: 2.220504722287578

Epoch: 6| Step: 4
Training loss: 1.6688742637634277
Validation loss: 2.2330338416561

Epoch: 6| Step: 5
Training loss: 2.2660388946533203
Validation loss: 2.2410995550053094

Epoch: 6| Step: 6
Training loss: 1.8047761917114258
Validation loss: 2.2343300132341284

Epoch: 6| Step: 7
Training loss: 2.5259289741516113
Validation loss: 2.23985795820913

Epoch: 6| Step: 8
Training loss: 1.8547453880310059
Validation loss: 2.1849882551418838

Epoch: 6| Step: 9
Training loss: 1.4235303401947021
Validation loss: 2.159078141694428

Epoch: 6| Step: 10
Training loss: 2.3772644996643066
Validation loss: 2.1307288921007546

Epoch: 6| Step: 11
Training loss: 0.9744638800621033
Validation loss: 2.0994749992124495

Epoch: 6| Step: 12
Training loss: 1.97410249710083
Validation loss: 2.089350244050385

Epoch: 6| Step: 13
Training loss: 1.8440355062484741
Validation loss: 2.0715012575990412

Epoch: 179| Step: 0
Training loss: 1.4033026695251465
Validation loss: 2.0631299031678068

Epoch: 6| Step: 1
Training loss: 1.3107811212539673
Validation loss: 2.089479784811697

Epoch: 6| Step: 2
Training loss: 2.1538233757019043
Validation loss: 2.1007579270229546

Epoch: 6| Step: 3
Training loss: 2.370255470275879
Validation loss: 2.178540911725772

Epoch: 6| Step: 4
Training loss: 2.591545343399048
Validation loss: 2.1900092888903875

Epoch: 6| Step: 5
Training loss: 2.1994547843933105
Validation loss: 2.1744456906472482

Epoch: 6| Step: 6
Training loss: 2.3490676879882812
Validation loss: 2.143180534403811

Epoch: 6| Step: 7
Training loss: 2.532311201095581
Validation loss: 2.130536469080115

Epoch: 6| Step: 8
Training loss: 1.720729112625122
Validation loss: 2.068186160056822

Epoch: 6| Step: 9
Training loss: 1.6526260375976562
Validation loss: 2.040826189902521

Epoch: 6| Step: 10
Training loss: 2.178375244140625
Validation loss: 2.0300490830534246

Epoch: 6| Step: 11
Training loss: 1.3166470527648926
Validation loss: 2.0336377671969834

Epoch: 6| Step: 12
Training loss: 2.210364580154419
Validation loss: 2.046363346038326

Epoch: 6| Step: 13
Training loss: 1.4055322408676147
Validation loss: 2.0969419543461134

Epoch: 180| Step: 0
Training loss: 2.4854111671447754
Validation loss: 2.1499263727536766

Epoch: 6| Step: 1
Training loss: 1.4831668138504028
Validation loss: 2.2152624053339802

Epoch: 6| Step: 2
Training loss: 2.1652159690856934
Validation loss: 2.294294790555072

Epoch: 6| Step: 3
Training loss: 1.9604424238204956
Validation loss: 2.344616490025674

Epoch: 6| Step: 4
Training loss: 1.740479588508606
Validation loss: 2.3583876240637993

Epoch: 6| Step: 5
Training loss: 2.488556385040283
Validation loss: 2.348292491769278

Epoch: 6| Step: 6
Training loss: 2.146371841430664
Validation loss: 2.3027424197043143

Epoch: 6| Step: 7
Training loss: 1.9000056982040405
Validation loss: 2.217259773644068

Epoch: 6| Step: 8
Training loss: 0.9709433317184448
Validation loss: 2.156762014153183

Epoch: 6| Step: 9
Training loss: 1.415376901626587
Validation loss: 2.1251610709774877

Epoch: 6| Step: 10
Training loss: 2.9160656929016113
Validation loss: 2.108582588934129

Epoch: 6| Step: 11
Training loss: 1.8725993633270264
Validation loss: 2.0873066814996863

Epoch: 6| Step: 12
Training loss: 1.8783202171325684
Validation loss: 2.065021276473999

Epoch: 6| Step: 13
Training loss: 1.3935552835464478
Validation loss: 2.0478619324263705

Epoch: 181| Step: 0
Training loss: 1.7462739944458008
Validation loss: 2.0563866669131863

Epoch: 6| Step: 1
Training loss: 2.412141799926758
Validation loss: 2.080262807107741

Epoch: 6| Step: 2
Training loss: 1.7923195362091064
Validation loss: 2.0531787923587266

Epoch: 6| Step: 3
Training loss: 1.7334742546081543
Validation loss: 2.0408520749820176

Epoch: 6| Step: 4
Training loss: 2.125927448272705
Validation loss: 2.0556640112271873

Epoch: 6| Step: 5
Training loss: 2.339215040206909
Validation loss: 2.059095850554846

Epoch: 6| Step: 6
Training loss: 2.282341718673706
Validation loss: 2.0682811942151798

Epoch: 6| Step: 7
Training loss: 2.152608633041382
Validation loss: 2.0938626848241335

Epoch: 6| Step: 8
Training loss: 1.2129809856414795
Validation loss: 2.0953403775409987

Epoch: 6| Step: 9
Training loss: 1.6049830913543701
Validation loss: 2.0994088880477415

Epoch: 6| Step: 10
Training loss: 1.6369612216949463
Validation loss: 2.1035659467020342

Epoch: 6| Step: 11
Training loss: 1.7417051792144775
Validation loss: 2.098723059059471

Epoch: 6| Step: 12
Training loss: 2.1896724700927734
Validation loss: 2.1120109429923435

Epoch: 6| Step: 13
Training loss: 1.3090355396270752
Validation loss: 2.0801703288990963

Epoch: 182| Step: 0
Training loss: 2.0635108947753906
Validation loss: 2.1073320270866476

Epoch: 6| Step: 1
Training loss: 1.2064744234085083
Validation loss: 2.1189254560778217

Epoch: 6| Step: 2
Training loss: 1.8474515676498413
Validation loss: 2.1459841625664824

Epoch: 6| Step: 3
Training loss: 2.585249423980713
Validation loss: 2.1617532468611196

Epoch: 6| Step: 4
Training loss: 1.9274048805236816
Validation loss: 2.1301775696457073

Epoch: 6| Step: 5
Training loss: 0.9976000785827637
Validation loss: 2.152169168636363

Epoch: 6| Step: 6
Training loss: 2.008883476257324
Validation loss: 2.1624935955129643

Epoch: 6| Step: 7
Training loss: 1.9190702438354492
Validation loss: 2.1647094065143215

Epoch: 6| Step: 8
Training loss: 1.7313205003738403
Validation loss: 2.1504558055631575

Epoch: 6| Step: 9
Training loss: 2.07431697845459
Validation loss: 2.131159702936808

Epoch: 6| Step: 10
Training loss: 1.5237171649932861
Validation loss: 2.110048714504447

Epoch: 6| Step: 11
Training loss: 1.9353132247924805
Validation loss: 2.0875143107547554

Epoch: 6| Step: 12
Training loss: 1.9511489868164062
Validation loss: 2.070520236927976

Epoch: 6| Step: 13
Training loss: 1.7392677068710327
Validation loss: 2.0480448122947448

Epoch: 183| Step: 0
Training loss: 1.7968008518218994
Validation loss: 2.0376535795068227

Epoch: 6| Step: 1
Training loss: 2.114518642425537
Validation loss: 2.032288584657895

Epoch: 6| Step: 2
Training loss: 2.077279567718506
Validation loss: 2.0424479156412105

Epoch: 6| Step: 3
Training loss: 2.1611135005950928
Validation loss: 2.0569406273544475

Epoch: 6| Step: 4
Training loss: 1.439676284790039
Validation loss: 2.0762912560534734

Epoch: 6| Step: 5
Training loss: 2.0167527198791504
Validation loss: 2.1176837387905327

Epoch: 6| Step: 6
Training loss: 2.0961992740631104
Validation loss: 2.180924795007193

Epoch: 6| Step: 7
Training loss: 1.99030339717865
Validation loss: 2.2456531806658675

Epoch: 6| Step: 8
Training loss: 1.3819421529769897
Validation loss: 2.246808123844926

Epoch: 6| Step: 9
Training loss: 1.4750462770462036
Validation loss: 2.2297154088174143

Epoch: 6| Step: 10
Training loss: 1.4110163450241089
Validation loss: 2.208973951237176

Epoch: 6| Step: 11
Training loss: 1.7447803020477295
Validation loss: 2.188504083182222

Epoch: 6| Step: 12
Training loss: 2.0784077644348145
Validation loss: 2.148539984098045

Epoch: 6| Step: 13
Training loss: 1.997347354888916
Validation loss: 2.124818540388538

Epoch: 184| Step: 0
Training loss: 1.9271240234375
Validation loss: 2.1402953593961653

Epoch: 6| Step: 1
Training loss: 1.192901849746704
Validation loss: 2.135284286673351

Epoch: 6| Step: 2
Training loss: 1.7858715057373047
Validation loss: 2.148709063888878

Epoch: 6| Step: 3
Training loss: 1.8896616697311401
Validation loss: 2.1637693323114866

Epoch: 6| Step: 4
Training loss: 2.396219253540039
Validation loss: 2.144766157673251

Epoch: 6| Step: 5
Training loss: 1.6407489776611328
Validation loss: 2.1511347832218295

Epoch: 6| Step: 6
Training loss: 2.100984573364258
Validation loss: 2.1239142648635374

Epoch: 6| Step: 7
Training loss: 1.2723325490951538
Validation loss: 2.1198473027957383

Epoch: 6| Step: 8
Training loss: 1.4758927822113037
Validation loss: 2.113966267596009

Epoch: 6| Step: 9
Training loss: 1.7059797048568726
Validation loss: 2.0954541993397537

Epoch: 6| Step: 10
Training loss: 1.5909932851791382
Validation loss: 2.102427831260107

Epoch: 6| Step: 11
Training loss: 1.755966067314148
Validation loss: 2.1249648447959655

Epoch: 6| Step: 12
Training loss: 2.593602180480957
Validation loss: 2.1239417778548373

Epoch: 6| Step: 13
Training loss: 1.4620006084442139
Validation loss: 2.134749940646592

Epoch: 185| Step: 0
Training loss: 1.5847052335739136
Validation loss: 2.121819992219248

Epoch: 6| Step: 1
Training loss: 1.4172041416168213
Validation loss: 2.124605627470119

Epoch: 6| Step: 2
Training loss: 1.7643462419509888
Validation loss: 2.1457831757042998

Epoch: 6| Step: 3
Training loss: 1.7399184703826904
Validation loss: 2.156424938991506

Epoch: 6| Step: 4
Training loss: 2.2662620544433594
Validation loss: 2.1857345283672376

Epoch: 6| Step: 5
Training loss: 1.9281761646270752
Validation loss: 2.2248487626352618

Epoch: 6| Step: 6
Training loss: 1.8782169818878174
Validation loss: 2.209200547587487

Epoch: 6| Step: 7
Training loss: 2.204838991165161
Validation loss: 2.1864251936635664

Epoch: 6| Step: 8
Training loss: 1.6419976949691772
Validation loss: 2.149717310423492

Epoch: 6| Step: 9
Training loss: 1.9880976676940918
Validation loss: 2.1175238124785887

Epoch: 6| Step: 10
Training loss: 1.6563522815704346
Validation loss: 2.0823729627875873

Epoch: 6| Step: 11
Training loss: 1.80592942237854
Validation loss: 2.0743601322174072

Epoch: 6| Step: 12
Training loss: 1.9180351495742798
Validation loss: 2.080592457966138

Epoch: 6| Step: 13
Training loss: 1.1668899059295654
Validation loss: 2.0760447440608853

Epoch: 186| Step: 0
Training loss: 1.2912745475769043
Validation loss: 2.0926923521103395

Epoch: 6| Step: 1
Training loss: 1.7864453792572021
Validation loss: 2.082389203451013

Epoch: 6| Step: 2
Training loss: 1.7785826921463013
Validation loss: 2.0876758983058314

Epoch: 6| Step: 3
Training loss: 1.3747974634170532
Validation loss: 2.122341937916253

Epoch: 6| Step: 4
Training loss: 2.1344685554504395
Validation loss: 2.1459028656764696

Epoch: 6| Step: 5
Training loss: 2.363569736480713
Validation loss: 2.1596025638682868

Epoch: 6| Step: 6
Training loss: 1.1314613819122314
Validation loss: 2.1854417606066634

Epoch: 6| Step: 7
Training loss: 1.7399654388427734
Validation loss: 2.2054366924429454

Epoch: 6| Step: 8
Training loss: 1.337664008140564
Validation loss: 2.1751483871090795

Epoch: 6| Step: 9
Training loss: 2.231091022491455
Validation loss: 2.162912896884385

Epoch: 6| Step: 10
Training loss: 1.8278683423995972
Validation loss: 2.1656064987182617

Epoch: 6| Step: 11
Training loss: 2.1288866996765137
Validation loss: 2.160596837279617

Epoch: 6| Step: 12
Training loss: 2.1115822792053223
Validation loss: 2.1471759016795824

Epoch: 6| Step: 13
Training loss: 1.8174176216125488
Validation loss: 2.126478672027588

Epoch: 187| Step: 0
Training loss: 1.9714034795761108
Validation loss: 2.0962863609354985

Epoch: 6| Step: 1
Training loss: 2.0037450790405273
Validation loss: 2.0787450280240787

Epoch: 6| Step: 2
Training loss: 1.647195816040039
Validation loss: 2.070079490702639

Epoch: 6| Step: 3
Training loss: 2.1825873851776123
Validation loss: 2.053266038176834

Epoch: 6| Step: 4
Training loss: 1.5769548416137695
Validation loss: 2.063651834764788

Epoch: 6| Step: 5
Training loss: 1.6909267902374268
Validation loss: 2.074839799634872

Epoch: 6| Step: 6
Training loss: 1.6469428539276123
Validation loss: 2.113724426556659

Epoch: 6| Step: 7
Training loss: 2.3169095516204834
Validation loss: 2.139964172917028

Epoch: 6| Step: 8
Training loss: 1.5247279405593872
Validation loss: 2.1731641395117647

Epoch: 6| Step: 9
Training loss: 1.8516364097595215
Validation loss: 2.183320738935983

Epoch: 6| Step: 10
Training loss: 2.0727899074554443
Validation loss: 2.20433936965081

Epoch: 6| Step: 11
Training loss: 1.9247848987579346
Validation loss: 2.1966918206984

Epoch: 6| Step: 12
Training loss: 1.1677675247192383
Validation loss: 2.1932473618497133

Epoch: 6| Step: 13
Training loss: 1.055611491203308
Validation loss: 2.197735157064212

Epoch: 188| Step: 0
Training loss: 1.7365334033966064
Validation loss: 2.186218438609954

Epoch: 6| Step: 1
Training loss: 1.9678597450256348
Validation loss: 2.2091146874171432

Epoch: 6| Step: 2
Training loss: 2.316777467727661
Validation loss: 2.2006347922868628

Epoch: 6| Step: 3
Training loss: 1.7498681545257568
Validation loss: 2.1775133558498916

Epoch: 6| Step: 4
Training loss: 1.9047455787658691
Validation loss: 2.1453713909272225

Epoch: 6| Step: 5
Training loss: 2.0754218101501465
Validation loss: 2.130098153186101

Epoch: 6| Step: 6
Training loss: 1.5829105377197266
Validation loss: 2.1111584389081566

Epoch: 6| Step: 7
Training loss: 2.00793719291687
Validation loss: 2.1223229182663785

Epoch: 6| Step: 8
Training loss: 1.3562343120574951
Validation loss: 2.114629799319852

Epoch: 6| Step: 9
Training loss: 1.2053256034851074
Validation loss: 2.1327960824453704

Epoch: 6| Step: 10
Training loss: 1.5737667083740234
Validation loss: 2.1675593724814792

Epoch: 6| Step: 11
Training loss: 1.8399832248687744
Validation loss: 2.172835365418465

Epoch: 6| Step: 12
Training loss: 1.6562037467956543
Validation loss: 2.1774045575049614

Epoch: 6| Step: 13
Training loss: 2.1565399169921875
Validation loss: 2.2026231776001635

Epoch: 189| Step: 0
Training loss: 1.7680917978286743
Validation loss: 2.201837915246205

Epoch: 6| Step: 1
Training loss: 1.5576701164245605
Validation loss: 2.2108194007668445

Epoch: 6| Step: 2
Training loss: 2.363828182220459
Validation loss: 2.2336160649535475

Epoch: 6| Step: 3
Training loss: 2.1243324279785156
Validation loss: 2.2004105429495535

Epoch: 6| Step: 4
Training loss: 1.9408979415893555
Validation loss: 2.1613539316320933

Epoch: 6| Step: 5
Training loss: 1.2048732042312622
Validation loss: 2.132770876730642

Epoch: 6| Step: 6
Training loss: 2.0814080238342285
Validation loss: 2.107511007657615

Epoch: 6| Step: 7
Training loss: 1.691089153289795
Validation loss: 2.104635594993509

Epoch: 6| Step: 8
Training loss: 1.743253231048584
Validation loss: 2.076534796786565

Epoch: 6| Step: 9
Training loss: 1.2509773969650269
Validation loss: 2.0805488606934905

Epoch: 6| Step: 10
Training loss: 1.3846499919891357
Validation loss: 2.0608042978471324

Epoch: 6| Step: 11
Training loss: 2.0526273250579834
Validation loss: 2.0804047751170334

Epoch: 6| Step: 12
Training loss: 1.942488193511963
Validation loss: 2.0926510544233423

Epoch: 6| Step: 13
Training loss: 1.4976391792297363
Validation loss: 2.1248040199279785

Epoch: 190| Step: 0
Training loss: 2.4327392578125
Validation loss: 2.163106072333551

Epoch: 6| Step: 1
Training loss: 1.6864192485809326
Validation loss: 2.195745196393741

Epoch: 6| Step: 2
Training loss: 1.9805076122283936
Validation loss: 2.190810990589921

Epoch: 6| Step: 3
Training loss: 1.7767914533615112
Validation loss: 2.1658193424183834

Epoch: 6| Step: 4
Training loss: 1.7460432052612305
Validation loss: 2.1536156233920845

Epoch: 6| Step: 5
Training loss: 2.2071800231933594
Validation loss: 2.125670039525596

Epoch: 6| Step: 6
Training loss: 1.1795704364776611
Validation loss: 2.0947733502234183

Epoch: 6| Step: 7
Training loss: 1.1125513315200806
Validation loss: 2.0929574171702066

Epoch: 6| Step: 8
Training loss: 2.0194573402404785
Validation loss: 2.101605494817098

Epoch: 6| Step: 9
Training loss: 1.7692633867263794
Validation loss: 2.1020541473101546

Epoch: 6| Step: 10
Training loss: 1.2359488010406494
Validation loss: 2.098282221824892

Epoch: 6| Step: 11
Training loss: 1.578484296798706
Validation loss: 2.1150900625413462

Epoch: 6| Step: 12
Training loss: 1.2780449390411377
Validation loss: 2.1277844598216396

Epoch: 6| Step: 13
Training loss: 3.1838748455047607
Validation loss: 2.160715828659714

Epoch: 191| Step: 0
Training loss: 2.1425161361694336
Validation loss: 2.152006521019884

Epoch: 6| Step: 1
Training loss: 1.6242833137512207
Validation loss: 2.1563987167932654

Epoch: 6| Step: 2
Training loss: 1.9444806575775146
Validation loss: 2.1199434393195697

Epoch: 6| Step: 3
Training loss: 1.0247015953063965
Validation loss: 2.095000254210605

Epoch: 6| Step: 4
Training loss: 2.160203456878662
Validation loss: 2.0868135639416274

Epoch: 6| Step: 5
Training loss: 1.9086503982543945
Validation loss: 2.091264524767476

Epoch: 6| Step: 6
Training loss: 1.9630346298217773
Validation loss: 2.082956629414712

Epoch: 6| Step: 7
Training loss: 1.885056495666504
Validation loss: 2.073716104671519

Epoch: 6| Step: 8
Training loss: 2.3068723678588867
Validation loss: 2.0667519851397445

Epoch: 6| Step: 9
Training loss: 2.09513521194458
Validation loss: 2.08880352973938

Epoch: 6| Step: 10
Training loss: 1.4007163047790527
Validation loss: 2.0854866927669895

Epoch: 6| Step: 11
Training loss: 0.9998596906661987
Validation loss: 2.1179262925219793

Epoch: 6| Step: 12
Training loss: 1.2960212230682373
Validation loss: 2.1631274056690994

Epoch: 6| Step: 13
Training loss: 1.2113715410232544
Validation loss: 2.205270175010927

Epoch: 192| Step: 0
Training loss: 1.716742753982544
Validation loss: 2.2794113082270466

Epoch: 6| Step: 1
Training loss: 1.8343769311904907
Validation loss: 2.3368246709146807

Epoch: 6| Step: 2
Training loss: 1.565467357635498
Validation loss: 2.3097360569943666

Epoch: 6| Step: 3
Training loss: 1.8092340230941772
Validation loss: 2.2289008786601405

Epoch: 6| Step: 4
Training loss: 1.9940816164016724
Validation loss: 2.1876420692730973

Epoch: 6| Step: 5
Training loss: 1.7472542524337769
Validation loss: 2.1189060723909767

Epoch: 6| Step: 6
Training loss: 1.942173957824707
Validation loss: 2.0728778377656014

Epoch: 6| Step: 7
Training loss: 2.168912410736084
Validation loss: 2.051293833281404

Epoch: 6| Step: 8
Training loss: 1.8531291484832764
Validation loss: 2.037309815806727

Epoch: 6| Step: 9
Training loss: 1.3139097690582275
Validation loss: 2.0369052617780623

Epoch: 6| Step: 10
Training loss: 1.8602409362792969
Validation loss: 2.057035694840134

Epoch: 6| Step: 11
Training loss: 2.1164979934692383
Validation loss: 2.0851597978222753

Epoch: 6| Step: 12
Training loss: 1.316158413887024
Validation loss: 2.150873643095775

Epoch: 6| Step: 13
Training loss: 1.9437533617019653
Validation loss: 2.173978319732092

Epoch: 193| Step: 0
Training loss: 2.111046075820923
Validation loss: 2.2202490222069526

Epoch: 6| Step: 1
Training loss: 1.5913240909576416
Validation loss: 2.2498044326741207

Epoch: 6| Step: 2
Training loss: 1.9650473594665527
Validation loss: 2.245211362838745

Epoch: 6| Step: 3
Training loss: 1.6867473125457764
Validation loss: 2.209148976110643

Epoch: 6| Step: 4
Training loss: 1.6434526443481445
Validation loss: 2.1762099471143497

Epoch: 6| Step: 5
Training loss: 1.6076505184173584
Validation loss: 2.1739839148777786

Epoch: 6| Step: 6
Training loss: 1.616930603981018
Validation loss: 2.1578700709086593

Epoch: 6| Step: 7
Training loss: 1.690679907798767
Validation loss: 2.13543616571734

Epoch: 6| Step: 8
Training loss: 1.6472104787826538
Validation loss: 2.1314334818111953

Epoch: 6| Step: 9
Training loss: 1.5143953561782837
Validation loss: 2.1422525657120572

Epoch: 6| Step: 10
Training loss: 1.755109190940857
Validation loss: 2.1476755116575506

Epoch: 6| Step: 11
Training loss: 1.9662644863128662
Validation loss: 2.1761534419111026

Epoch: 6| Step: 12
Training loss: 1.9014276266098022
Validation loss: 2.2157487369352773

Epoch: 6| Step: 13
Training loss: 1.8348244428634644
Validation loss: 2.2361986380751415

Epoch: 194| Step: 0
Training loss: 1.838600516319275
Validation loss: 2.2320335270256124

Epoch: 6| Step: 1
Training loss: 1.4588006734848022
Validation loss: 2.2002475069415186

Epoch: 6| Step: 2
Training loss: 2.652383327484131
Validation loss: 2.1622627678737847

Epoch: 6| Step: 3
Training loss: 1.494994878768921
Validation loss: 2.1369560636499876

Epoch: 6| Step: 4
Training loss: 1.1949539184570312
Validation loss: 2.1256209804165747

Epoch: 6| Step: 5
Training loss: 1.7131427526474
Validation loss: 2.138604228214551

Epoch: 6| Step: 6
Training loss: 1.6898958683013916
Validation loss: 2.127407463647986

Epoch: 6| Step: 7
Training loss: 1.83686363697052
Validation loss: 2.1297600294954036

Epoch: 6| Step: 8
Training loss: 1.4060745239257812
Validation loss: 2.1177001358360372

Epoch: 6| Step: 9
Training loss: 1.8563810586929321
Validation loss: 2.1425682319107877

Epoch: 6| Step: 10
Training loss: 1.7741374969482422
Validation loss: 2.135346681840958

Epoch: 6| Step: 11
Training loss: 1.9521052837371826
Validation loss: 2.1384510173592517

Epoch: 6| Step: 12
Training loss: 1.5520340204238892
Validation loss: 2.1426345199666996

Epoch: 6| Step: 13
Training loss: 1.635335087776184
Validation loss: 2.1740191918547436

Epoch: 195| Step: 0
Training loss: 1.2989568710327148
Validation loss: 2.1649607996786795

Epoch: 6| Step: 1
Training loss: 1.844238042831421
Validation loss: 2.196058455333915

Epoch: 6| Step: 2
Training loss: 1.1410884857177734
Validation loss: 2.2138447761535645

Epoch: 6| Step: 3
Training loss: 1.216996669769287
Validation loss: 2.2167908145535375

Epoch: 6| Step: 4
Training loss: 1.816272258758545
Validation loss: 2.218749451380904

Epoch: 6| Step: 5
Training loss: 1.8140175342559814
Validation loss: 2.1912125618227067

Epoch: 6| Step: 6
Training loss: 2.0258798599243164
Validation loss: 2.1393345812315583

Epoch: 6| Step: 7
Training loss: 1.952821969985962
Validation loss: 2.109100813506752

Epoch: 6| Step: 8
Training loss: 2.24969482421875
Validation loss: 2.062550765211864

Epoch: 6| Step: 9
Training loss: 2.160022258758545
Validation loss: 2.0452151721523655

Epoch: 6| Step: 10
Training loss: 2.214646577835083
Validation loss: 2.041740958408643

Epoch: 6| Step: 11
Training loss: 1.5748378038406372
Validation loss: 2.030189391105406

Epoch: 6| Step: 12
Training loss: 1.4989432096481323
Validation loss: 2.0422343054125385

Epoch: 6| Step: 13
Training loss: 0.4278102219104767
Validation loss: 2.030299572534459

Epoch: 196| Step: 0
Training loss: 1.7103877067565918
Validation loss: 2.0606683249114663

Epoch: 6| Step: 1
Training loss: 1.8945039510726929
Validation loss: 2.084427297756236

Epoch: 6| Step: 2
Training loss: 1.727599024772644
Validation loss: 2.1236789354714016

Epoch: 6| Step: 3
Training loss: 1.3295007944107056
Validation loss: 2.16212978670674

Epoch: 6| Step: 4
Training loss: 1.4018893241882324
Validation loss: 2.178083728718501

Epoch: 6| Step: 5
Training loss: 1.448012113571167
Validation loss: 2.2036634722063617

Epoch: 6| Step: 6
Training loss: 1.8529068231582642
Validation loss: 2.2374366970472437

Epoch: 6| Step: 7
Training loss: 2.0815107822418213
Validation loss: 2.2539989589363016

Epoch: 6| Step: 8
Training loss: 1.580960750579834
Validation loss: 2.2572984515979724

Epoch: 6| Step: 9
Training loss: 1.9165773391723633
Validation loss: 2.2027854842524373

Epoch: 6| Step: 10
Training loss: 1.4661140441894531
Validation loss: 2.1657645369088776

Epoch: 6| Step: 11
Training loss: 1.4566400051116943
Validation loss: 2.119731528784639

Epoch: 6| Step: 12
Training loss: 2.1037044525146484
Validation loss: 2.1007746317053355

Epoch: 6| Step: 13
Training loss: 1.7572141885757446
Validation loss: 2.0995080650493665

Epoch: 197| Step: 0
Training loss: 1.2986669540405273
Validation loss: 2.081126912947624

Epoch: 6| Step: 1
Training loss: 2.0371413230895996
Validation loss: 2.044586863569034

Epoch: 6| Step: 2
Training loss: 1.3473453521728516
Validation loss: 2.048021016582366

Epoch: 6| Step: 3
Training loss: 2.440336227416992
Validation loss: 2.0799777200145106

Epoch: 6| Step: 4
Training loss: 1.8909796476364136
Validation loss: 2.10915014307986

Epoch: 6| Step: 5
Training loss: 0.9489374160766602
Validation loss: 2.120548446973165

Epoch: 6| Step: 6
Training loss: 1.645758867263794
Validation loss: 2.157768928876487

Epoch: 6| Step: 7
Training loss: 1.9957504272460938
Validation loss: 2.167940931935464

Epoch: 6| Step: 8
Training loss: 1.0503597259521484
Validation loss: 2.1942542137638217

Epoch: 6| Step: 9
Training loss: 2.092555284500122
Validation loss: 2.218083845671787

Epoch: 6| Step: 10
Training loss: 1.9308555126190186
Validation loss: 2.237607635477538

Epoch: 6| Step: 11
Training loss: 1.9846627712249756
Validation loss: 2.210754612440704

Epoch: 6| Step: 12
Training loss: 1.6657496690750122
Validation loss: 2.187123267881332

Epoch: 6| Step: 13
Training loss: 1.7108105421066284
Validation loss: 2.154498120789887

Epoch: 198| Step: 0
Training loss: 2.250629186630249
Validation loss: 2.152891312876055

Epoch: 6| Step: 1
Training loss: 1.947068214416504
Validation loss: 2.124032296160216

Epoch: 6| Step: 2
Training loss: 1.3919553756713867
Validation loss: 2.1054453542155604

Epoch: 6| Step: 3
Training loss: 2.1538286209106445
Validation loss: 2.089292364735757

Epoch: 6| Step: 4
Training loss: 0.90314781665802
Validation loss: 2.0984585208277546

Epoch: 6| Step: 5
Training loss: 1.6503363847732544
Validation loss: 2.1132671525401454

Epoch: 6| Step: 6
Training loss: 1.7908499240875244
Validation loss: 2.1366216880018993

Epoch: 6| Step: 7
Training loss: 1.317516803741455
Validation loss: 2.1649086398463093

Epoch: 6| Step: 8
Training loss: 1.3157672882080078
Validation loss: 2.196486662792903

Epoch: 6| Step: 9
Training loss: 1.326512098312378
Validation loss: 2.1801527802662184

Epoch: 6| Step: 10
Training loss: 2.2746753692626953
Validation loss: 2.1579414003638813

Epoch: 6| Step: 11
Training loss: 1.3532323837280273
Validation loss: 2.115518141818303

Epoch: 6| Step: 12
Training loss: 1.9754822254180908
Validation loss: 2.1024075336353754

Epoch: 6| Step: 13
Training loss: 1.8040415048599243
Validation loss: 2.084276665923416

Epoch: 199| Step: 0
Training loss: 1.5979026556015015
Validation loss: 2.0529175548143286

Epoch: 6| Step: 1
Training loss: 1.512298345565796
Validation loss: 2.0419910838527064

Epoch: 6| Step: 2
Training loss: 1.6792426109313965
Validation loss: 2.047803819820445

Epoch: 6| Step: 3
Training loss: 2.0966172218322754
Validation loss: 2.0631922932081324

Epoch: 6| Step: 4
Training loss: 1.6767722368240356
Validation loss: 2.0868384504830964

Epoch: 6| Step: 5
Training loss: 1.5707813501358032
Validation loss: 2.117388535571355

Epoch: 6| Step: 6
Training loss: 1.550680160522461
Validation loss: 2.140548557363531

Epoch: 6| Step: 7
Training loss: 1.7739152908325195
Validation loss: 2.1508490526547996

Epoch: 6| Step: 8
Training loss: 1.3830924034118652
Validation loss: 2.1555486827768306

Epoch: 6| Step: 9
Training loss: 1.387520432472229
Validation loss: 2.13358808589238

Epoch: 6| Step: 10
Training loss: 2.088115930557251
Validation loss: 2.122016688828827

Epoch: 6| Step: 11
Training loss: 1.1193428039550781
Validation loss: 2.1051245235627696

Epoch: 6| Step: 12
Training loss: 1.5108041763305664
Validation loss: 2.0812702653228596

Epoch: 6| Step: 13
Training loss: 2.4150946140289307
Validation loss: 2.0913012040558683

Epoch: 200| Step: 0
Training loss: 1.6313848495483398
Validation loss: 2.079144747026505

Epoch: 6| Step: 1
Training loss: 1.6255500316619873
Validation loss: 2.0719258605792956

Epoch: 6| Step: 2
Training loss: 1.3272631168365479
Validation loss: 2.062085618254959

Epoch: 6| Step: 3
Training loss: 1.2849998474121094
Validation loss: 2.075762374426729

Epoch: 6| Step: 4
Training loss: 1.0763185024261475
Validation loss: 2.0724058099972305

Epoch: 6| Step: 5
Training loss: 1.2078022956848145
Validation loss: 2.071463228553854

Epoch: 6| Step: 6
Training loss: 1.8613502979278564
Validation loss: 2.0967650695513655

Epoch: 6| Step: 7
Training loss: 1.838657021522522
Validation loss: 2.103834870041058

Epoch: 6| Step: 8
Training loss: 1.8485256433486938
Validation loss: 2.1129775560030373

Epoch: 6| Step: 9
Training loss: 1.7626408338546753
Validation loss: 2.107473352903961

Epoch: 6| Step: 10
Training loss: 2.0032529830932617
Validation loss: 2.101224401945709

Epoch: 6| Step: 11
Training loss: 1.7438679933547974
Validation loss: 2.1026956829973447

Epoch: 6| Step: 12
Training loss: 1.8102021217346191
Validation loss: 2.077770653591361

Epoch: 6| Step: 13
Training loss: 1.8747766017913818
Validation loss: 2.075714026727984

Epoch: 201| Step: 0
Training loss: 2.058539628982544
Validation loss: 2.083023414816908

Epoch: 6| Step: 1
Training loss: 2.0395588874816895
Validation loss: 2.102307378604848

Epoch: 6| Step: 2
Training loss: 1.3346953392028809
Validation loss: 2.1081942973598355

Epoch: 6| Step: 3
Training loss: 2.231637477874756
Validation loss: 2.119350706377337

Epoch: 6| Step: 4
Training loss: 1.651125192642212
Validation loss: 2.1022750126418246

Epoch: 6| Step: 5
Training loss: 1.6266131401062012
Validation loss: 2.0596708584857244

Epoch: 6| Step: 6
Training loss: 1.7243655920028687
Validation loss: 2.0501738530333324

Epoch: 6| Step: 7
Training loss: 1.150436520576477
Validation loss: 2.0373029670407696

Epoch: 6| Step: 8
Training loss: 1.3581929206848145
Validation loss: 2.0454215875235935

Epoch: 6| Step: 9
Training loss: 1.8757320642471313
Validation loss: 2.033078296210176

Epoch: 6| Step: 10
Training loss: 1.3674806356430054
Validation loss: 2.0492956292244697

Epoch: 6| Step: 11
Training loss: 1.7095563411712646
Validation loss: 2.042558664916664

Epoch: 6| Step: 12
Training loss: 1.3476704359054565
Validation loss: 2.0705265550203222

Epoch: 6| Step: 13
Training loss: 0.8472357392311096
Validation loss: 2.1330239106250066

Epoch: 202| Step: 0
Training loss: 2.3268063068389893
Validation loss: 2.154005301895962

Epoch: 6| Step: 1
Training loss: 1.3337476253509521
Validation loss: 2.2084858571329424

Epoch: 6| Step: 2
Training loss: 1.2376601696014404
Validation loss: 2.2467024326324463

Epoch: 6| Step: 3
Training loss: 0.7118443846702576
Validation loss: 2.2585738730686966

Epoch: 6| Step: 4
Training loss: 1.1991829872131348
Validation loss: 2.2432081494280087

Epoch: 6| Step: 5
Training loss: 1.2914021015167236
Validation loss: 2.2092722436433196

Epoch: 6| Step: 6
Training loss: 1.7016946077346802
Validation loss: 2.1570226671875163

Epoch: 6| Step: 7
Training loss: 2.2074804306030273
Validation loss: 2.1246879280254407

Epoch: 6| Step: 8
Training loss: 1.8668774366378784
Validation loss: 2.1062862873077393

Epoch: 6| Step: 9
Training loss: 1.2330422401428223
Validation loss: 2.0639034394294984

Epoch: 6| Step: 10
Training loss: 1.931246280670166
Validation loss: 2.026448501053677

Epoch: 6| Step: 11
Training loss: 1.2998780012130737
Validation loss: 2.0177439207671792

Epoch: 6| Step: 12
Training loss: 2.3845248222351074
Validation loss: 2.013486877564461

Epoch: 6| Step: 13
Training loss: 2.4180774688720703
Validation loss: 2.017753157564389

Epoch: 203| Step: 0
Training loss: 1.458544373512268
Validation loss: 2.0254098599956882

Epoch: 6| Step: 1
Training loss: 1.506474494934082
Validation loss: 2.018292680863411

Epoch: 6| Step: 2
Training loss: 1.6292262077331543
Validation loss: 2.0242823400805072

Epoch: 6| Step: 3
Training loss: 0.9508914947509766
Validation loss: 2.013701705522435

Epoch: 6| Step: 4
Training loss: 1.5949146747589111
Validation loss: 2.016635602520358

Epoch: 6| Step: 5
Training loss: 1.9332807064056396
Validation loss: 2.0481188399817354

Epoch: 6| Step: 6
Training loss: 1.9192147254943848
Validation loss: 2.052966553677795

Epoch: 6| Step: 7
Training loss: 1.7296338081359863
Validation loss: 2.053670883178711

Epoch: 6| Step: 8
Training loss: 1.8596043586730957
Validation loss: 2.0672818691499772

Epoch: 6| Step: 9
Training loss: 1.7723536491394043
Validation loss: 2.066631692712025

Epoch: 6| Step: 10
Training loss: 1.4361307621002197
Validation loss: 2.095658517652942

Epoch: 6| Step: 11
Training loss: 1.4266510009765625
Validation loss: 2.103946493517968

Epoch: 6| Step: 12
Training loss: 1.5667047500610352
Validation loss: 2.096287005691118

Epoch: 6| Step: 13
Training loss: 1.5183777809143066
Validation loss: 2.1252045926227363

Epoch: 204| Step: 0
Training loss: 1.6572868824005127
Validation loss: 2.0954962135643087

Epoch: 6| Step: 1
Training loss: 1.562122106552124
Validation loss: 2.097884865217311

Epoch: 6| Step: 2
Training loss: 1.7264528274536133
Validation loss: 2.0911517425249984

Epoch: 6| Step: 3
Training loss: 1.5924131870269775
Validation loss: 2.0960770499321724

Epoch: 6| Step: 4
Training loss: 1.360568881034851
Validation loss: 2.1047123042486047

Epoch: 6| Step: 5
Training loss: 1.4856053590774536
Validation loss: 2.079527049936274

Epoch: 6| Step: 6
Training loss: 1.811724066734314
Validation loss: 2.091994047164917

Epoch: 6| Step: 7
Training loss: 1.3491511344909668
Validation loss: 2.106846963205645

Epoch: 6| Step: 8
Training loss: 2.582974910736084
Validation loss: 2.1585008021323913

Epoch: 6| Step: 9
Training loss: 0.8730623722076416
Validation loss: 2.230043513800508

Epoch: 6| Step: 10
Training loss: 1.465576410293579
Validation loss: 2.248092471912343

Epoch: 6| Step: 11
Training loss: 1.3132061958312988
Validation loss: 2.2629077511449016

Epoch: 6| Step: 12
Training loss: 1.398259162902832
Validation loss: 2.31507993513538

Epoch: 6| Step: 13
Training loss: 2.163283348083496
Validation loss: 2.2613428023553666

Epoch: 205| Step: 0
Training loss: 1.376915454864502
Validation loss: 2.266058062994352

Epoch: 6| Step: 1
Training loss: 1.7972415685653687
Validation loss: 2.1977338842166367

Epoch: 6| Step: 2
Training loss: 1.894805669784546
Validation loss: 2.14501957226825

Epoch: 6| Step: 3
Training loss: 1.1731030941009521
Validation loss: 2.0829224676214237

Epoch: 6| Step: 4
Training loss: 1.3384342193603516
Validation loss: 2.057960865318134

Epoch: 6| Step: 5
Training loss: 1.6063454151153564
Validation loss: 2.0331901170874156

Epoch: 6| Step: 6
Training loss: 2.0238804817199707
Validation loss: 2.0161408557686755

Epoch: 6| Step: 7
Training loss: 2.024268388748169
Validation loss: 2.0260567883009553

Epoch: 6| Step: 8
Training loss: 1.5924967527389526
Validation loss: 2.0379716068185787

Epoch: 6| Step: 9
Training loss: 2.028395891189575
Validation loss: 2.0504138905514955

Epoch: 6| Step: 10
Training loss: 1.2191399335861206
Validation loss: 2.067427167328455

Epoch: 6| Step: 11
Training loss: 1.4365768432617188
Validation loss: 2.1038044524449173

Epoch: 6| Step: 12
Training loss: 1.6682730913162231
Validation loss: 2.147612997280654

Epoch: 6| Step: 13
Training loss: 0.9985407590866089
Validation loss: 2.1731078393997683

Epoch: 206| Step: 0
Training loss: 1.743194341659546
Validation loss: 2.1591831778967254

Epoch: 6| Step: 1
Training loss: 1.1099777221679688
Validation loss: 2.163098007120112

Epoch: 6| Step: 2
Training loss: 1.8889243602752686
Validation loss: 2.142378176412275

Epoch: 6| Step: 3
Training loss: 1.872677206993103
Validation loss: 2.1346671940178

Epoch: 6| Step: 4
Training loss: 1.5888028144836426
Validation loss: 2.099447152947867

Epoch: 6| Step: 5
Training loss: 1.4328343868255615
Validation loss: 2.059751493956453

Epoch: 6| Step: 6
Training loss: 1.4246355295181274
Validation loss: 2.0221937010365147

Epoch: 6| Step: 7
Training loss: 1.6244633197784424
Validation loss: 2.0013718194859003

Epoch: 6| Step: 8
Training loss: 1.4399802684783936
Validation loss: 2.0022670812504266

Epoch: 6| Step: 9
Training loss: 1.913568139076233
Validation loss: 2.00118923699984

Epoch: 6| Step: 10
Training loss: 1.8314214944839478
Validation loss: 2.0210881438306583

Epoch: 6| Step: 11
Training loss: 1.6129190921783447
Validation loss: 2.0283581825994674

Epoch: 6| Step: 12
Training loss: 1.609302282333374
Validation loss: 2.065637637210149

Epoch: 6| Step: 13
Training loss: 1.0452567338943481
Validation loss: 2.1213465044575353

Epoch: 207| Step: 0
Training loss: 1.897932767868042
Validation loss: 2.15889472346152

Epoch: 6| Step: 1
Training loss: 1.6373679637908936
Validation loss: 2.176503845440444

Epoch: 6| Step: 2
Training loss: 2.256225109100342
Validation loss: 2.1301682226119505

Epoch: 6| Step: 3
Training loss: 0.9393294453620911
Validation loss: 2.1107846639489614

Epoch: 6| Step: 4
Training loss: 1.1375705003738403
Validation loss: 2.091823242043936

Epoch: 6| Step: 5
Training loss: 1.4163110256195068
Validation loss: 2.079998118903047

Epoch: 6| Step: 6
Training loss: 1.0261409282684326
Validation loss: 2.061970818427301

Epoch: 6| Step: 7
Training loss: 1.6697969436645508
Validation loss: 2.0709829779081446

Epoch: 6| Step: 8
Training loss: 1.7544081211090088
Validation loss: 2.084072861620175

Epoch: 6| Step: 9
Training loss: 1.8715448379516602
Validation loss: 2.091002715531216

Epoch: 6| Step: 10
Training loss: 1.1715260744094849
Validation loss: 2.1026638374533704

Epoch: 6| Step: 11
Training loss: 1.9373916387557983
Validation loss: 2.130931305628951

Epoch: 6| Step: 12
Training loss: 1.972196340560913
Validation loss: 2.145726832010413

Epoch: 6| Step: 13
Training loss: 0.8236877918243408
Validation loss: 2.1496358968878306

Epoch: 208| Step: 0
Training loss: 1.131483793258667
Validation loss: 2.1480731066837104

Epoch: 6| Step: 1
Training loss: 1.4933762550354004
Validation loss: 2.137684355499924

Epoch: 6| Step: 2
Training loss: 1.6120028495788574
Validation loss: 2.129224882330946

Epoch: 6| Step: 3
Training loss: 1.2896045446395874
Validation loss: 2.132673740386963

Epoch: 6| Step: 4
Training loss: 1.9234375953674316
Validation loss: 2.113551808941749

Epoch: 6| Step: 5
Training loss: 2.1214170455932617
Validation loss: 2.1018052101135254

Epoch: 6| Step: 6
Training loss: 1.5315980911254883
Validation loss: 2.097310232859786

Epoch: 6| Step: 7
Training loss: 1.0036265850067139
Validation loss: 2.084886904685728

Epoch: 6| Step: 8
Training loss: 2.1746346950531006
Validation loss: 2.0421377869062525

Epoch: 6| Step: 9
Training loss: 1.9268852472305298
Validation loss: 2.017657938823905

Epoch: 6| Step: 10
Training loss: 0.7230866551399231
Validation loss: 2.0161183495675363

Epoch: 6| Step: 11
Training loss: 1.5700674057006836
Validation loss: 2.0261763142001246

Epoch: 6| Step: 12
Training loss: 1.5669679641723633
Validation loss: 2.0124384023809947

Epoch: 6| Step: 13
Training loss: 1.1256823539733887
Validation loss: 2.0515998294276576

Epoch: 209| Step: 0
Training loss: 1.1474875211715698
Validation loss: 2.058758977920778

Epoch: 6| Step: 1
Training loss: 1.0612889528274536
Validation loss: 2.085966847276175

Epoch: 6| Step: 2
Training loss: 2.1931257247924805
Validation loss: 2.1415150909013647

Epoch: 6| Step: 3
Training loss: 1.830216407775879
Validation loss: 2.1867604076221423

Epoch: 6| Step: 4
Training loss: 1.897944688796997
Validation loss: 2.233632092834801

Epoch: 6| Step: 5
Training loss: 0.7874632477760315
Validation loss: 2.2396575250933246

Epoch: 6| Step: 6
Training loss: 1.7039211988449097
Validation loss: 2.232481118171446

Epoch: 6| Step: 7
Training loss: 1.6948124170303345
Validation loss: 2.1992844868731756

Epoch: 6| Step: 8
Training loss: 1.5107557773590088
Validation loss: 2.1455263348035913

Epoch: 6| Step: 9
Training loss: 1.6671074628829956
Validation loss: 2.1229829506207536

Epoch: 6| Step: 10
Training loss: 1.3336617946624756
Validation loss: 2.074569755984891

Epoch: 6| Step: 11
Training loss: 1.8720111846923828
Validation loss: 2.08076560625466

Epoch: 6| Step: 12
Training loss: 1.6335092782974243
Validation loss: 2.022530814652802

Epoch: 6| Step: 13
Training loss: 1.5248630046844482
Validation loss: 2.0222637640532626

Epoch: 210| Step: 0
Training loss: 1.333107590675354
Validation loss: 2.0450006300403225

Epoch: 6| Step: 1
Training loss: 1.539334774017334
Validation loss: 2.0933956510277203

Epoch: 6| Step: 2
Training loss: 1.4444186687469482
Validation loss: 2.1419560396543114

Epoch: 6| Step: 3
Training loss: 2.023792028427124
Validation loss: 2.21090381632569

Epoch: 6| Step: 4
Training loss: 1.721738338470459
Validation loss: 2.2494084142869517

Epoch: 6| Step: 5
Training loss: 1.8610278367996216
Validation loss: 2.260277391761862

Epoch: 6| Step: 6
Training loss: 0.6865981817245483
Validation loss: 2.17605253957933

Epoch: 6| Step: 7
Training loss: 1.300414800643921
Validation loss: 2.067185007115846

Epoch: 6| Step: 8
Training loss: 1.8799848556518555
Validation loss: 1.9918933709462483

Epoch: 6| Step: 9
Training loss: 1.6676292419433594
Validation loss: 1.9584402333023727

Epoch: 6| Step: 10
Training loss: 1.9388995170593262
Validation loss: 1.9665079386003557

Epoch: 6| Step: 11
Training loss: 1.4483892917633057
Validation loss: 1.996331209777504

Epoch: 6| Step: 12
Training loss: 2.2165043354034424
Validation loss: 2.011246609431441

Epoch: 6| Step: 13
Training loss: 1.685203194618225
Validation loss: 2.050801423288161

Epoch: 211| Step: 0
Training loss: 1.6640948057174683
Validation loss: 2.045105755970042

Epoch: 6| Step: 1
Training loss: 1.8213908672332764
Validation loss: 2.0631708406632945

Epoch: 6| Step: 2
Training loss: 1.4915510416030884
Validation loss: 2.086369796465802

Epoch: 6| Step: 3
Training loss: 1.2418155670166016
Validation loss: 2.0705272561760357

Epoch: 6| Step: 4
Training loss: 1.3437072038650513
Validation loss: 2.047741308007189

Epoch: 6| Step: 5
Training loss: 0.9737982749938965
Validation loss: 2.0665305019706808

Epoch: 6| Step: 6
Training loss: 1.6420153379440308
Validation loss: 2.1179267309045278

Epoch: 6| Step: 7
Training loss: 2.1699461936950684
Validation loss: 2.1532516351310154

Epoch: 6| Step: 8
Training loss: 1.4963552951812744
Validation loss: 2.220650875440208

Epoch: 6| Step: 9
Training loss: 1.5233930349349976
Validation loss: 2.2606794244499615

Epoch: 6| Step: 10
Training loss: 2.6176538467407227
Validation loss: 2.219870185339323

Epoch: 6| Step: 11
Training loss: 0.9097785949707031
Validation loss: 2.156963344543211

Epoch: 6| Step: 12
Training loss: 1.38833749294281
Validation loss: 2.1536021924787954

Epoch: 6| Step: 13
Training loss: 2.284288167953491
Validation loss: 2.1136142182093796

Epoch: 212| Step: 0
Training loss: 1.752406120300293
Validation loss: 2.068597924324774

Epoch: 6| Step: 1
Training loss: 1.5323842763900757
Validation loss: 2.0309079308663645

Epoch: 6| Step: 2
Training loss: 1.0041570663452148
Validation loss: 2.0127618723018195

Epoch: 6| Step: 3
Training loss: 1.0170058012008667
Validation loss: 2.002251046960072

Epoch: 6| Step: 4
Training loss: 1.0212950706481934
Validation loss: 2.0262887118965067

Epoch: 6| Step: 5
Training loss: 1.7490090131759644
Validation loss: 2.0403944933286278

Epoch: 6| Step: 6
Training loss: 2.4451069831848145
Validation loss: 2.075840268083798

Epoch: 6| Step: 7
Training loss: 1.838639259338379
Validation loss: 2.1074092016425183

Epoch: 6| Step: 8
Training loss: 1.6828149557113647
Validation loss: 2.1647969804784304

Epoch: 6| Step: 9
Training loss: 1.397120475769043
Validation loss: 2.1908047071067234

Epoch: 6| Step: 10
Training loss: 1.9611436128616333
Validation loss: 2.2193584929230394

Epoch: 6| Step: 11
Training loss: 1.6380380392074585
Validation loss: 2.236364377442227

Epoch: 6| Step: 12
Training loss: 1.5573134422302246
Validation loss: 2.231014126090593

Epoch: 6| Step: 13
Training loss: 2.0790622234344482
Validation loss: 2.213152336817916

Epoch: 213| Step: 0
Training loss: 0.99470055103302
Validation loss: 2.169599022916568

Epoch: 6| Step: 1
Training loss: 1.5133800506591797
Validation loss: 2.1690462802046087

Epoch: 6| Step: 2
Training loss: 1.44528329372406
Validation loss: 2.1540185687362507

Epoch: 6| Step: 3
Training loss: 1.074485421180725
Validation loss: 2.1078317370466007

Epoch: 6| Step: 4
Training loss: 1.959757924079895
Validation loss: 2.1061948012280207

Epoch: 6| Step: 5
Training loss: 2.240478992462158
Validation loss: 2.0821963587114887

Epoch: 6| Step: 6
Training loss: 1.5780413150787354
Validation loss: 2.069113036637665

Epoch: 6| Step: 7
Training loss: 1.0729881525039673
Validation loss: 2.0703244696381273

Epoch: 6| Step: 8
Training loss: 1.1273101568222046
Validation loss: 2.0737555539736183

Epoch: 6| Step: 9
Training loss: 1.9749919176101685
Validation loss: 2.1032192950607627

Epoch: 6| Step: 10
Training loss: 1.3141365051269531
Validation loss: 2.1115753266119186

Epoch: 6| Step: 11
Training loss: 1.70169997215271
Validation loss: 2.1115082105000815

Epoch: 6| Step: 12
Training loss: 1.5577456951141357
Validation loss: 2.106916707049134

Epoch: 6| Step: 13
Training loss: 1.6024316549301147
Validation loss: 2.0964990533808225

Epoch: 214| Step: 0
Training loss: 1.5340250730514526
Validation loss: 2.1178794176347795

Epoch: 6| Step: 1
Training loss: 1.355463981628418
Validation loss: 2.1095850506136493

Epoch: 6| Step: 2
Training loss: 1.1599102020263672
Validation loss: 2.099575633643776

Epoch: 6| Step: 3
Training loss: 2.178405523300171
Validation loss: 2.0915098100580196

Epoch: 6| Step: 4
Training loss: 2.0413975715637207
Validation loss: 2.0526149965101674

Epoch: 6| Step: 5
Training loss: 1.5436772108078003
Validation loss: 2.0625294818673083

Epoch: 6| Step: 6
Training loss: 1.5874419212341309
Validation loss: 2.0393053754683463

Epoch: 6| Step: 7
Training loss: 1.6609243154525757
Validation loss: 2.0455541251808085

Epoch: 6| Step: 8
Training loss: 1.4586503505706787
Validation loss: 2.0096118065618698

Epoch: 6| Step: 9
Training loss: 1.412898063659668
Validation loss: 2.0058682733966458

Epoch: 6| Step: 10
Training loss: 0.8172553181648254
Validation loss: 2.029503640308175

Epoch: 6| Step: 11
Training loss: 1.1517398357391357
Validation loss: 2.071325780243002

Epoch: 6| Step: 12
Training loss: 1.4411815404891968
Validation loss: 2.0836218121231243

Epoch: 6| Step: 13
Training loss: 1.6859116554260254
Validation loss: 2.154586139545646

Epoch: 215| Step: 0
Training loss: 0.9391547441482544
Validation loss: 2.180172369044314

Epoch: 6| Step: 1
Training loss: 1.7268112897872925
Validation loss: 2.2468857406288065

Epoch: 6| Step: 2
Training loss: 1.8116111755371094
Validation loss: 2.2732191239633868

Epoch: 6| Step: 3
Training loss: 1.529831886291504
Validation loss: 2.265147155331027

Epoch: 6| Step: 4
Training loss: 2.0204317569732666
Validation loss: 2.256023455691594

Epoch: 6| Step: 5
Training loss: 2.4065113067626953
Validation loss: 2.2171088777562624

Epoch: 6| Step: 6
Training loss: 1.7796545028686523
Validation loss: 2.150673358671127

Epoch: 6| Step: 7
Training loss: 2.1010589599609375
Validation loss: 2.1087042516277683

Epoch: 6| Step: 8
Training loss: 1.1900160312652588
Validation loss: 2.0525634904061594

Epoch: 6| Step: 9
Training loss: 1.717416763305664
Validation loss: 2.0405718767514793

Epoch: 6| Step: 10
Training loss: 1.039953589439392
Validation loss: 2.0256549414768013

Epoch: 6| Step: 11
Training loss: 1.13778555393219
Validation loss: 2.0109624247397146

Epoch: 6| Step: 12
Training loss: 0.9095522165298462
Validation loss: 2.0379545022082586

Epoch: 6| Step: 13
Training loss: 0.6535618901252747
Validation loss: 2.0595186897503432

Epoch: 216| Step: 0
Training loss: 1.4925134181976318
Validation loss: 2.0571682991520053

Epoch: 6| Step: 1
Training loss: 1.9410079717636108
Validation loss: 2.0429407063350884

Epoch: 6| Step: 2
Training loss: 1.8051270246505737
Validation loss: 2.042448733442573

Epoch: 6| Step: 3
Training loss: 1.4341880083084106
Validation loss: 1.9983809891567434

Epoch: 6| Step: 4
Training loss: 0.7430665493011475
Validation loss: 1.9587831292101132

Epoch: 6| Step: 5
Training loss: 1.6393547058105469
Validation loss: 1.9830461702039164

Epoch: 6| Step: 6
Training loss: 1.8679925203323364
Validation loss: 2.012698083795527

Epoch: 6| Step: 7
Training loss: 1.843967080116272
Validation loss: 2.0268165655033563

Epoch: 6| Step: 8
Training loss: 1.4173214435577393
Validation loss: 2.0878930784040883

Epoch: 6| Step: 9
Training loss: 1.7031522989273071
Validation loss: 2.107996384302775

Epoch: 6| Step: 10
Training loss: 1.0809710025787354
Validation loss: 2.118768979144353

Epoch: 6| Step: 11
Training loss: 1.378898024559021
Validation loss: 2.1590109422642696

Epoch: 6| Step: 12
Training loss: 1.5488851070404053
Validation loss: 2.153366888723066

Epoch: 6| Step: 13
Training loss: 1.4589506387710571
Validation loss: 2.1234651509151665

Epoch: 217| Step: 0
Training loss: 1.0940124988555908
Validation loss: 2.0891919866684945

Epoch: 6| Step: 1
Training loss: 1.2563650608062744
Validation loss: 2.0489630622248494

Epoch: 6| Step: 2
Training loss: 1.1498968601226807
Validation loss: 2.036077904444869

Epoch: 6| Step: 3
Training loss: 1.4023656845092773
Validation loss: 2.004135936819097

Epoch: 6| Step: 4
Training loss: 1.8167598247528076
Validation loss: 1.9878433032702374

Epoch: 6| Step: 5
Training loss: 1.3189878463745117
Validation loss: 2.007965665991588

Epoch: 6| Step: 6
Training loss: 2.1150565147399902
Validation loss: 1.999094537509385

Epoch: 6| Step: 7
Training loss: 1.2755318880081177
Validation loss: 2.0127371921334216

Epoch: 6| Step: 8
Training loss: 1.112419843673706
Validation loss: 2.0286381372841458

Epoch: 6| Step: 9
Training loss: 1.6889747381210327
Validation loss: 2.041459100220793

Epoch: 6| Step: 10
Training loss: 1.4086949825286865
Validation loss: 2.0480844256698445

Epoch: 6| Step: 11
Training loss: 1.5207972526550293
Validation loss: 2.048173896728023

Epoch: 6| Step: 12
Training loss: 1.7346391677856445
Validation loss: 2.0766262982481267

Epoch: 6| Step: 13
Training loss: 1.6303128004074097
Validation loss: 2.066267849296652

Epoch: 218| Step: 0
Training loss: 1.7589595317840576
Validation loss: 2.0865748249074465

Epoch: 6| Step: 1
Training loss: 0.9071588516235352
Validation loss: 2.0842980005407847

Epoch: 6| Step: 2
Training loss: 1.106075644493103
Validation loss: 2.0721933482795634

Epoch: 6| Step: 3
Training loss: 1.0939961671829224
Validation loss: 2.068448781967163

Epoch: 6| Step: 4
Training loss: 0.8951059579849243
Validation loss: 2.063636267057029

Epoch: 6| Step: 5
Training loss: 1.7996559143066406
Validation loss: 2.0761560445190756

Epoch: 6| Step: 6
Training loss: 0.9268017411231995
Validation loss: 2.074213474027572

Epoch: 6| Step: 7
Training loss: 1.8074971437454224
Validation loss: 2.084448306791244

Epoch: 6| Step: 8
Training loss: 2.1959919929504395
Validation loss: 2.0768509193133284

Epoch: 6| Step: 9
Training loss: 1.2007992267608643
Validation loss: 2.0909732644275953

Epoch: 6| Step: 10
Training loss: 1.9940142631530762
Validation loss: 2.084726769437072

Epoch: 6| Step: 11
Training loss: 1.2515596151351929
Validation loss: 2.057708219815326

Epoch: 6| Step: 12
Training loss: 1.7566739320755005
Validation loss: 2.0506085964941208

Epoch: 6| Step: 13
Training loss: 1.0169258117675781
Validation loss: 2.0932982403744935

Epoch: 219| Step: 0
Training loss: 2.3321008682250977
Validation loss: 2.1193875830660582

Epoch: 6| Step: 1
Training loss: 0.967505156993866
Validation loss: 2.14867647745276

Epoch: 6| Step: 2
Training loss: 1.0754785537719727
Validation loss: 2.169119611863167

Epoch: 6| Step: 3
Training loss: 1.2943756580352783
Validation loss: 2.155783817332278

Epoch: 6| Step: 4
Training loss: 1.6986453533172607
Validation loss: 2.131377132990027

Epoch: 6| Step: 5
Training loss: 2.038348913192749
Validation loss: 2.095235634875554

Epoch: 6| Step: 6
Training loss: 0.8836256265640259
Validation loss: 2.069809450898119

Epoch: 6| Step: 7
Training loss: 1.491028904914856
Validation loss: 2.065351514406102

Epoch: 6| Step: 8
Training loss: 1.1150683164596558
Validation loss: 2.036656710409349

Epoch: 6| Step: 9
Training loss: 1.2300643920898438
Validation loss: 2.0114660827062463

Epoch: 6| Step: 10
Training loss: 1.364034652709961
Validation loss: 2.017236637812789

Epoch: 6| Step: 11
Training loss: 1.3385365009307861
Validation loss: 2.0221966492232455

Epoch: 6| Step: 12
Training loss: 1.700207233428955
Validation loss: 2.0346843824591687

Epoch: 6| Step: 13
Training loss: 1.0727214813232422
Validation loss: 2.0640525433324997

Epoch: 220| Step: 0
Training loss: 1.4036898612976074
Validation loss: 2.0848746299743652

Epoch: 6| Step: 1
Training loss: 1.5647188425064087
Validation loss: 2.1105942572316816

Epoch: 6| Step: 2
Training loss: 1.8472933769226074
Validation loss: 2.115388847166492

Epoch: 6| Step: 3
Training loss: 1.5973838567733765
Validation loss: 2.1255219623606694

Epoch: 6| Step: 4
Training loss: 1.0584759712219238
Validation loss: 2.098482080685195

Epoch: 6| Step: 5
Training loss: 1.146416425704956
Validation loss: 2.0255937345566286

Epoch: 6| Step: 6
Training loss: 1.9463508129119873
Validation loss: 1.9814350835738643

Epoch: 6| Step: 7
Training loss: 1.2889182567596436
Validation loss: 2.0013795539896977

Epoch: 6| Step: 8
Training loss: 1.178574800491333
Validation loss: 1.9795007808234102

Epoch: 6| Step: 9
Training loss: 1.2010891437530518
Validation loss: 1.9858050243828886

Epoch: 6| Step: 10
Training loss: 1.411663293838501
Validation loss: 2.0080869556755148

Epoch: 6| Step: 11
Training loss: 1.3891284465789795
Validation loss: 2.0321218018890708

Epoch: 6| Step: 12
Training loss: 0.8997049331665039
Validation loss: 2.0768147591621644

Epoch: 6| Step: 13
Training loss: 2.029308557510376
Validation loss: 2.1275329807753205

Epoch: 221| Step: 0
Training loss: 1.7133361101150513
Validation loss: 2.1579870229126303

Epoch: 6| Step: 1
Training loss: 1.0742850303649902
Validation loss: 2.1320899763414936

Epoch: 6| Step: 2
Training loss: 1.4257441759109497
Validation loss: 2.1084390712040726

Epoch: 6| Step: 3
Training loss: 1.0870187282562256
Validation loss: 2.0874168642105593

Epoch: 6| Step: 4
Training loss: 1.5720694065093994
Validation loss: 2.050937444932999

Epoch: 6| Step: 5
Training loss: 1.7815907001495361
Validation loss: 2.030327905890762

Epoch: 6| Step: 6
Training loss: 1.2420504093170166
Validation loss: 2.024000152464836

Epoch: 6| Step: 7
Training loss: 1.783548355102539
Validation loss: 2.0372176990714124

Epoch: 6| Step: 8
Training loss: 1.132331371307373
Validation loss: 2.073219904335596

Epoch: 6| Step: 9
Training loss: 0.9233195781707764
Validation loss: 2.0642722345167592

Epoch: 6| Step: 10
Training loss: 1.2028977870941162
Validation loss: 2.06647765251898

Epoch: 6| Step: 11
Training loss: 1.9274173974990845
Validation loss: 2.0550019459057878

Epoch: 6| Step: 12
Training loss: 1.1389563083648682
Validation loss: 2.037623149092479

Epoch: 6| Step: 13
Training loss: 1.2773061990737915
Validation loss: 2.026298535767422

Epoch: 222| Step: 0
Training loss: 1.1586735248565674
Validation loss: 2.0051143092493855

Epoch: 6| Step: 1
Training loss: 1.462998867034912
Validation loss: 2.012131626887988

Epoch: 6| Step: 2
Training loss: 1.3552004098892212
Validation loss: 2.004674878171695

Epoch: 6| Step: 3
Training loss: 1.1094927787780762
Validation loss: 2.0080501879415205

Epoch: 6| Step: 4
Training loss: 1.1443674564361572
Validation loss: 2.0224868546250048

Epoch: 6| Step: 5
Training loss: 1.5526378154754639
Validation loss: 2.018152403575118

Epoch: 6| Step: 6
Training loss: 0.6746441125869751
Validation loss: 2.0476109981536865

Epoch: 6| Step: 7
Training loss: 1.8395652770996094
Validation loss: 2.0936467698825303

Epoch: 6| Step: 8
Training loss: 1.3530683517456055
Validation loss: 2.082195202509562

Epoch: 6| Step: 9
Training loss: 1.2854788303375244
Validation loss: 2.074801198897823

Epoch: 6| Step: 10
Training loss: 1.645254135131836
Validation loss: 2.0491252189041465

Epoch: 6| Step: 11
Training loss: 1.5268489122390747
Validation loss: 2.039002844082412

Epoch: 6| Step: 12
Training loss: 1.460891842842102
Validation loss: 2.005934576834402

Epoch: 6| Step: 13
Training loss: 1.5655815601348877
Validation loss: 2.000328363910798

Epoch: 223| Step: 0
Training loss: 0.7959825992584229
Validation loss: 2.0159530819103284

Epoch: 6| Step: 1
Training loss: 1.4661459922790527
Validation loss: 2.035471332970486

Epoch: 6| Step: 2
Training loss: 0.9514904618263245
Validation loss: 2.0358359877781202

Epoch: 6| Step: 3
Training loss: 1.0849940776824951
Validation loss: 2.071949851128363

Epoch: 6| Step: 4
Training loss: 1.5216712951660156
Validation loss: 2.0508658488591514

Epoch: 6| Step: 5
Training loss: 1.4586905241012573
Validation loss: 2.0418039496226976

Epoch: 6| Step: 6
Training loss: 1.731001615524292
Validation loss: 2.039825721453595

Epoch: 6| Step: 7
Training loss: 1.5032892227172852
Validation loss: 2.006223861889173

Epoch: 6| Step: 8
Training loss: 1.4700901508331299
Validation loss: 2.0059522774911698

Epoch: 6| Step: 9
Training loss: 1.4242736101150513
Validation loss: 2.020038139435553

Epoch: 6| Step: 10
Training loss: 1.0723057985305786
Validation loss: 2.0593376492941253

Epoch: 6| Step: 11
Training loss: 1.627837896347046
Validation loss: 2.1105131231328493

Epoch: 6| Step: 12
Training loss: 0.9992881417274475
Validation loss: 2.1209589614663074

Epoch: 6| Step: 13
Training loss: 2.0145609378814697
Validation loss: 2.1747678018385366

Epoch: 224| Step: 0
Training loss: 1.0560286045074463
Validation loss: 2.151078160091113

Epoch: 6| Step: 1
Training loss: 1.21480131149292
Validation loss: 2.1091702574042865

Epoch: 6| Step: 2
Training loss: 1.243762493133545
Validation loss: 2.0693735050898727

Epoch: 6| Step: 3
Training loss: 1.2120388746261597
Validation loss: 2.0249115472198813

Epoch: 6| Step: 4
Training loss: 1.653709888458252
Validation loss: 2.0069117187171854

Epoch: 6| Step: 5
Training loss: 0.9286441802978516
Validation loss: 1.970656136030792

Epoch: 6| Step: 6
Training loss: 1.1741557121276855
Validation loss: 1.9693678091931086

Epoch: 6| Step: 7
Training loss: 1.3397775888442993
Validation loss: 1.9663168050909554

Epoch: 6| Step: 8
Training loss: 1.3227795362472534
Validation loss: 1.9544573599292385

Epoch: 6| Step: 9
Training loss: 1.4273353815078735
Validation loss: 1.9857956670945691

Epoch: 6| Step: 10
Training loss: 1.4975690841674805
Validation loss: 2.0249581131883847

Epoch: 6| Step: 11
Training loss: 2.082913875579834
Validation loss: 2.0556335269763903

Epoch: 6| Step: 12
Training loss: 1.1000871658325195
Validation loss: 2.051125903283396

Epoch: 6| Step: 13
Training loss: 1.4076900482177734
Validation loss: 2.087906914372598

Epoch: 225| Step: 0
Training loss: 1.1822748184204102
Validation loss: 2.080260830540811

Epoch: 6| Step: 1
Training loss: 1.541212797164917
Validation loss: 2.072588279683103

Epoch: 6| Step: 2
Training loss: 1.521970510482788
Validation loss: 2.0507806360080676

Epoch: 6| Step: 3
Training loss: 1.812615156173706
Validation loss: 2.033775943581776

Epoch: 6| Step: 4
Training loss: 1.4625294208526611
Validation loss: 2.050686558087667

Epoch: 6| Step: 5
Training loss: 1.1944913864135742
Validation loss: 2.0642577217471216

Epoch: 6| Step: 6
Training loss: 1.089561104774475
Validation loss: 2.044325849061371

Epoch: 6| Step: 7
Training loss: 1.3683764934539795
Validation loss: 2.0522857109705606

Epoch: 6| Step: 8
Training loss: 1.153738260269165
Validation loss: 2.0481944789168653

Epoch: 6| Step: 9
Training loss: 1.4380995035171509
Validation loss: 2.026241663963564

Epoch: 6| Step: 10
Training loss: 1.1339620351791382
Validation loss: 2.0110473966085785

Epoch: 6| Step: 11
Training loss: 1.028524398803711
Validation loss: 1.9594851386162542

Epoch: 6| Step: 12
Training loss: 1.4434938430786133
Validation loss: 1.963130299763013

Epoch: 6| Step: 13
Training loss: 0.9573951363563538
Validation loss: 1.9757130658754738

Epoch: 226| Step: 0
Training loss: 1.1390836238861084
Validation loss: 2.0029152362577376

Epoch: 6| Step: 1
Training loss: 1.2916688919067383
Validation loss: 2.023037874570457

Epoch: 6| Step: 2
Training loss: 1.0115776062011719
Validation loss: 2.0191463680677515

Epoch: 6| Step: 3
Training loss: 0.8513729572296143
Validation loss: 2.035700818543793

Epoch: 6| Step: 4
Training loss: 1.2409701347351074
Validation loss: 2.0106756366709226

Epoch: 6| Step: 5
Training loss: 1.3542791604995728
Validation loss: 2.0159779851154616

Epoch: 6| Step: 6
Training loss: 1.2957375049591064
Validation loss: 1.974890132104197

Epoch: 6| Step: 7
Training loss: 1.533215880393982
Validation loss: 2.0011011720985494

Epoch: 6| Step: 8
Training loss: 1.3028753995895386
Validation loss: 1.9791800578435261

Epoch: 6| Step: 9
Training loss: 1.157731294631958
Validation loss: 1.9646698787648191

Epoch: 6| Step: 10
Training loss: 1.4795026779174805
Validation loss: 1.9971785724803965

Epoch: 6| Step: 11
Training loss: 1.4466171264648438
Validation loss: 1.9695100681756132

Epoch: 6| Step: 12
Training loss: 1.2769782543182373
Validation loss: 2.0192717941858436

Epoch: 6| Step: 13
Training loss: 2.426015615463257
Validation loss: 2.0231043741267216

Epoch: 227| Step: 0
Training loss: 1.0843565464019775
Validation loss: 2.0441646293927263

Epoch: 6| Step: 1
Training loss: 1.215475082397461
Validation loss: 2.0892914341342066

Epoch: 6| Step: 2
Training loss: 1.014373540878296
Validation loss: 2.125967305193665

Epoch: 6| Step: 3
Training loss: 1.761566162109375
Validation loss: 2.110691992185449

Epoch: 6| Step: 4
Training loss: 0.9291163682937622
Validation loss: 2.0739912268935994

Epoch: 6| Step: 5
Training loss: 1.2254619598388672
Validation loss: 2.009166616265492

Epoch: 6| Step: 6
Training loss: 1.1469042301177979
Validation loss: 1.9759158344678982

Epoch: 6| Step: 7
Training loss: 1.483457326889038
Validation loss: 1.9616049874213435

Epoch: 6| Step: 8
Training loss: 1.3787363767623901
Validation loss: 1.9485827479311215

Epoch: 6| Step: 9
Training loss: 1.8098942041397095
Validation loss: 1.9506873623017342

Epoch: 6| Step: 10
Training loss: 1.263167142868042
Validation loss: 1.9523757734606344

Epoch: 6| Step: 11
Training loss: 1.4886000156402588
Validation loss: 1.9552957075898365

Epoch: 6| Step: 12
Training loss: 1.9570128917694092
Validation loss: 1.9898961897819274

Epoch: 6| Step: 13
Training loss: 0.9320454001426697
Validation loss: 2.065098603566488

Epoch: 228| Step: 0
Training loss: 1.517683982849121
Validation loss: 2.153179345592376

Epoch: 6| Step: 1
Training loss: 1.2249317169189453
Validation loss: 2.206650726256832

Epoch: 6| Step: 2
Training loss: 1.217694878578186
Validation loss: 2.228532927010649

Epoch: 6| Step: 3
Training loss: 1.21934974193573
Validation loss: 2.23604481450973

Epoch: 6| Step: 4
Training loss: 1.8646751642227173
Validation loss: 2.172051436157637

Epoch: 6| Step: 5
Training loss: 0.9122298955917358
Validation loss: 2.0972078923256166

Epoch: 6| Step: 6
Training loss: 1.1151319742202759
Validation loss: 2.0133519608487367

Epoch: 6| Step: 7
Training loss: 1.0932059288024902
Validation loss: 1.9690665711638748

Epoch: 6| Step: 8
Training loss: 1.5380208492279053
Validation loss: 1.9376692836002638

Epoch: 6| Step: 9
Training loss: 1.5078210830688477
Validation loss: 1.9536441628650953

Epoch: 6| Step: 10
Training loss: 1.5567951202392578
Validation loss: 1.9287634024056055

Epoch: 6| Step: 11
Training loss: 1.626719355583191
Validation loss: 1.9828252279630272

Epoch: 6| Step: 12
Training loss: 1.1612412929534912
Validation loss: 1.9798312417922481

Epoch: 6| Step: 13
Training loss: 2.574831247329712
Validation loss: 2.005595681487873

Epoch: 229| Step: 0
Training loss: 1.3455369472503662
Validation loss: 2.065410248694881

Epoch: 6| Step: 1
Training loss: 1.2569856643676758
Validation loss: 2.0725698265978085

Epoch: 6| Step: 2
Training loss: 1.7010496854782104
Validation loss: 2.1356350850033503

Epoch: 6| Step: 3
Training loss: 1.6632250547409058
Validation loss: 2.1646514323449906

Epoch: 6| Step: 4
Training loss: 0.9902057647705078
Validation loss: 2.2036467572694183

Epoch: 6| Step: 5
Training loss: 1.6723971366882324
Validation loss: 2.175705043218469

Epoch: 6| Step: 6
Training loss: 0.9587889909744263
Validation loss: 2.162069495006274

Epoch: 6| Step: 7
Training loss: 1.1449577808380127
Validation loss: 2.12810182058683

Epoch: 6| Step: 8
Training loss: 1.7793145179748535
Validation loss: 2.0509680522385465

Epoch: 6| Step: 9
Training loss: 0.8892202973365784
Validation loss: 2.0288715285639607

Epoch: 6| Step: 10
Training loss: 1.4752273559570312
Validation loss: 1.9963844899208314

Epoch: 6| Step: 11
Training loss: 1.1496813297271729
Validation loss: 1.9982248147328694

Epoch: 6| Step: 12
Training loss: 1.341052532196045
Validation loss: 1.9995380857939362

Epoch: 6| Step: 13
Training loss: 0.9223909378051758
Validation loss: 1.9897230004751554

Epoch: 230| Step: 0
Training loss: 1.0370938777923584
Validation loss: 1.9700290913222938

Epoch: 6| Step: 1
Training loss: 1.5586724281311035
Validation loss: 2.006450124966201

Epoch: 6| Step: 2
Training loss: 1.5524028539657593
Validation loss: 1.9931783381328787

Epoch: 6| Step: 3
Training loss: 1.3233294486999512
Validation loss: 2.0235605214231756

Epoch: 6| Step: 4
Training loss: 1.3779618740081787
Validation loss: 1.9971399179068945

Epoch: 6| Step: 5
Training loss: 1.3781083822250366
Validation loss: 2.0013855605997066

Epoch: 6| Step: 6
Training loss: 1.2199432849884033
Validation loss: 2.02318654265455

Epoch: 6| Step: 7
Training loss: 0.9833558797836304
Validation loss: 2.024622606974776

Epoch: 6| Step: 8
Training loss: 1.410099983215332
Validation loss: 2.030740476423694

Epoch: 6| Step: 9
Training loss: 1.2919535636901855
Validation loss: 2.0045683922306186

Epoch: 6| Step: 10
Training loss: 1.5276787281036377
Validation loss: 1.9980438447767688

Epoch: 6| Step: 11
Training loss: 1.20013427734375
Validation loss: 2.0338799389459754

Epoch: 6| Step: 12
Training loss: 0.9524455666542053
Validation loss: 2.0354899732015466

Epoch: 6| Step: 13
Training loss: 1.112714409828186
Validation loss: 2.0711568324796614

Epoch: 231| Step: 0
Training loss: 1.7367295026779175
Validation loss: 2.0777767217287453

Epoch: 6| Step: 1
Training loss: 1.405721664428711
Validation loss: 2.0884745569639307

Epoch: 6| Step: 2
Training loss: 1.811004877090454
Validation loss: 2.069992441003041

Epoch: 6| Step: 3
Training loss: 1.170029640197754
Validation loss: 2.020622343145391

Epoch: 6| Step: 4
Training loss: 1.1975406408309937
Validation loss: 2.0293622734726116

Epoch: 6| Step: 5
Training loss: 0.9361408948898315
Validation loss: 1.9568215659869614

Epoch: 6| Step: 6
Training loss: 1.9580492973327637
Validation loss: 1.915364001386909

Epoch: 6| Step: 7
Training loss: 1.331918716430664
Validation loss: 1.8954693835268739

Epoch: 6| Step: 8
Training loss: 0.7727838158607483
Validation loss: 1.9193390261742376

Epoch: 6| Step: 9
Training loss: 1.1280179023742676
Validation loss: 1.9261485043392386

Epoch: 6| Step: 10
Training loss: 1.3324323892593384
Validation loss: 1.9512054817650908

Epoch: 6| Step: 11
Training loss: 1.1659369468688965
Validation loss: 2.006007848247405

Epoch: 6| Step: 12
Training loss: 0.9336453676223755
Validation loss: 2.0777385798833703

Epoch: 6| Step: 13
Training loss: 1.3483383655548096
Validation loss: 2.1516222723068728

Epoch: 232| Step: 0
Training loss: 0.9100995063781738
Validation loss: 2.148842865420926

Epoch: 6| Step: 1
Training loss: 1.3366221189498901
Validation loss: 2.1005465586980185

Epoch: 6| Step: 2
Training loss: 1.3369898796081543
Validation loss: 2.099283633693572

Epoch: 6| Step: 3
Training loss: 1.0687024593353271
Validation loss: 2.0598135443143946

Epoch: 6| Step: 4
Training loss: 1.9298627376556396
Validation loss: 2.0601971687809115

Epoch: 6| Step: 5
Training loss: 1.3456225395202637
Validation loss: 2.0362276915580995

Epoch: 6| Step: 6
Training loss: 1.4056005477905273
Validation loss: 2.008731354949295

Epoch: 6| Step: 7
Training loss: 1.0790605545043945
Validation loss: 1.975732881535766

Epoch: 6| Step: 8
Training loss: 1.4371421337127686
Validation loss: 1.9481341403017762

Epoch: 6| Step: 9
Training loss: 0.9413406848907471
Validation loss: 1.933779465254917

Epoch: 6| Step: 10
Training loss: 1.5439894199371338
Validation loss: 1.9585979959016204

Epoch: 6| Step: 11
Training loss: 1.1291447877883911
Validation loss: 1.9621328538463962

Epoch: 6| Step: 12
Training loss: 0.759990930557251
Validation loss: 1.9990475844311457

Epoch: 6| Step: 13
Training loss: 1.6214523315429688
Validation loss: 2.0199737907737814

Epoch: 233| Step: 0
Training loss: 1.3483457565307617
Validation loss: 2.080512785142468

Epoch: 6| Step: 1
Training loss: 1.0157591104507446
Validation loss: 2.094592294385356

Epoch: 6| Step: 2
Training loss: 0.7719229459762573
Validation loss: 2.0980526170422955

Epoch: 6| Step: 3
Training loss: 1.1705845594406128
Validation loss: 2.0815538385862946

Epoch: 6| Step: 4
Training loss: 0.7121021747589111
Validation loss: 2.0561369926698747

Epoch: 6| Step: 5
Training loss: 1.3880224227905273
Validation loss: 2.020397468279767

Epoch: 6| Step: 6
Training loss: 0.8874687552452087
Validation loss: 1.9962616120615313

Epoch: 6| Step: 7
Training loss: 1.7035815715789795
Validation loss: 1.9715085055238457

Epoch: 6| Step: 8
Training loss: 1.4775848388671875
Validation loss: 1.9834520816802979

Epoch: 6| Step: 9
Training loss: 1.430772304534912
Validation loss: 1.980880952650501

Epoch: 6| Step: 10
Training loss: 1.4883308410644531
Validation loss: 1.9836076292940366

Epoch: 6| Step: 11
Training loss: 1.3194341659545898
Validation loss: 1.9997808753803212

Epoch: 6| Step: 12
Training loss: 0.9679667353630066
Validation loss: 2.021249848027383

Epoch: 6| Step: 13
Training loss: 1.4959218502044678
Validation loss: 2.010508063018963

Epoch: 234| Step: 0
Training loss: 1.2977440357208252
Validation loss: 2.006302302883517

Epoch: 6| Step: 1
Training loss: 0.9967634677886963
Validation loss: 2.0042610578639533

Epoch: 6| Step: 2
Training loss: 1.1638307571411133
Validation loss: 1.9771384551960935

Epoch: 6| Step: 3
Training loss: 1.4971439838409424
Validation loss: 1.9729081097469534

Epoch: 6| Step: 4
Training loss: 1.238789677619934
Validation loss: 1.9915782764393797

Epoch: 6| Step: 5
Training loss: 1.122497320175171
Validation loss: 2.0007443402403142

Epoch: 6| Step: 6
Training loss: 1.0923160314559937
Validation loss: 2.0295569153242212

Epoch: 6| Step: 7
Training loss: 1.493267297744751
Validation loss: 2.0544634506266606

Epoch: 6| Step: 8
Training loss: 1.031290888786316
Validation loss: 2.0281821245788247

Epoch: 6| Step: 9
Training loss: 1.2614941596984863
Validation loss: 2.0081347816733905

Epoch: 6| Step: 10
Training loss: 0.997141420841217
Validation loss: 2.0336543001154417

Epoch: 6| Step: 11
Training loss: 1.503605842590332
Validation loss: 2.0362830059502715

Epoch: 6| Step: 12
Training loss: 1.1566067934036255
Validation loss: 2.034962352885995

Epoch: 6| Step: 13
Training loss: 1.436255931854248
Validation loss: 2.010693370655019

Epoch: 235| Step: 0
Training loss: 1.4474639892578125
Validation loss: 2.0074247493538806

Epoch: 6| Step: 1
Training loss: 1.2168822288513184
Validation loss: 2.0006438609092467

Epoch: 6| Step: 2
Training loss: 1.7440204620361328
Validation loss: 2.000543996851931

Epoch: 6| Step: 3
Training loss: 1.1612000465393066
Validation loss: 2.0027779276653

Epoch: 6| Step: 4
Training loss: 1.3241238594055176
Validation loss: 1.9984489499881704

Epoch: 6| Step: 5
Training loss: 1.2361375093460083
Validation loss: 2.023705220991565

Epoch: 6| Step: 6
Training loss: 1.1935186386108398
Validation loss: 1.9980600956947572

Epoch: 6| Step: 7
Training loss: 0.8868481516838074
Validation loss: 1.9942626594215311

Epoch: 6| Step: 8
Training loss: 1.1157515048980713
Validation loss: 2.0025492880934026

Epoch: 6| Step: 9
Training loss: 1.5528677701950073
Validation loss: 1.9920486429686188

Epoch: 6| Step: 10
Training loss: 0.5961994528770447
Validation loss: 2.009919426774466

Epoch: 6| Step: 11
Training loss: 1.2389161586761475
Validation loss: 2.0050321548215804

Epoch: 6| Step: 12
Training loss: 1.0436830520629883
Validation loss: 2.0313989705936883

Epoch: 6| Step: 13
Training loss: 0.8792892098426819
Validation loss: 2.0474956522705736

Epoch: 236| Step: 0
Training loss: 0.7098053693771362
Validation loss: 2.0256988002407934

Epoch: 6| Step: 1
Training loss: 1.129536509513855
Validation loss: 2.0319565444864254

Epoch: 6| Step: 2
Training loss: 1.0743886232376099
Validation loss: 2.0355643854346326

Epoch: 6| Step: 3
Training loss: 0.8940513134002686
Validation loss: 2.0087969918404855

Epoch: 6| Step: 4
Training loss: 1.4636142253875732
Validation loss: 2.031470343630801

Epoch: 6| Step: 5
Training loss: 0.843725323677063
Validation loss: 2.0116683436978247

Epoch: 6| Step: 6
Training loss: 0.7427775263786316
Validation loss: 1.9720208439775693

Epoch: 6| Step: 7
Training loss: 1.2973549365997314
Validation loss: 1.931462316102879

Epoch: 6| Step: 8
Training loss: 1.8199902772903442
Validation loss: 1.9191026072348318

Epoch: 6| Step: 9
Training loss: 1.2122560739517212
Validation loss: 1.912323026246922

Epoch: 6| Step: 10
Training loss: 0.9146566390991211
Validation loss: 1.9016973305773992

Epoch: 6| Step: 11
Training loss: 0.9002619981765747
Validation loss: 1.8882466721278366

Epoch: 6| Step: 12
Training loss: 1.4765312671661377
Validation loss: 1.9093803718525877

Epoch: 6| Step: 13
Training loss: 2.9911305904388428
Validation loss: 1.9326786764206425

Epoch: 237| Step: 0
Training loss: 0.9629017114639282
Validation loss: 1.978447824396113

Epoch: 6| Step: 1
Training loss: 1.2209978103637695
Validation loss: 2.0268784646065003

Epoch: 6| Step: 2
Training loss: 1.0145800113677979
Validation loss: 2.0816556817741803

Epoch: 6| Step: 3
Training loss: 2.1524672508239746
Validation loss: 2.1320470533063336

Epoch: 6| Step: 4
Training loss: 0.9756382703781128
Validation loss: 2.138456147204163

Epoch: 6| Step: 5
Training loss: 1.0129632949829102
Validation loss: 2.1229455342856784

Epoch: 6| Step: 6
Training loss: 1.1702889204025269
Validation loss: 2.101881629677229

Epoch: 6| Step: 7
Training loss: 0.9681777358055115
Validation loss: 2.0609272679974957

Epoch: 6| Step: 8
Training loss: 1.1144044399261475
Validation loss: 2.0030070479198168

Epoch: 6| Step: 9
Training loss: 1.1578402519226074
Validation loss: 1.9785180809677287

Epoch: 6| Step: 10
Training loss: 1.1950891017913818
Validation loss: 1.9504406221451298

Epoch: 6| Step: 11
Training loss: 1.3412753343582153
Validation loss: 1.9361052987396077

Epoch: 6| Step: 12
Training loss: 1.2970480918884277
Validation loss: 1.9288855175818167

Epoch: 6| Step: 13
Training loss: 1.2378556728363037
Validation loss: 1.9095924541514406

Epoch: 238| Step: 0
Training loss: 0.6076102256774902
Validation loss: 1.934615929921468

Epoch: 6| Step: 1
Training loss: 1.1732447147369385
Validation loss: 1.9584646776158323

Epoch: 6| Step: 2
Training loss: 1.1800551414489746
Validation loss: 2.0049704544005857

Epoch: 6| Step: 3
Training loss: 1.3065998554229736
Validation loss: 2.0156155145296486

Epoch: 6| Step: 4
Training loss: 1.7135226726531982
Validation loss: 2.021123916872086

Epoch: 6| Step: 5
Training loss: 0.5557275414466858
Validation loss: 2.0407040247353176

Epoch: 6| Step: 6
Training loss: 1.4746060371398926
Validation loss: 2.031861525709911

Epoch: 6| Step: 7
Training loss: 1.5735077857971191
Validation loss: 2.0385451752652406

Epoch: 6| Step: 8
Training loss: 0.9786490797996521
Validation loss: 1.9898208213108841

Epoch: 6| Step: 9
Training loss: 0.7574968934059143
Validation loss: 1.9439632790063017

Epoch: 6| Step: 10
Training loss: 1.3839713335037231
Validation loss: 1.9153758389975435

Epoch: 6| Step: 11
Training loss: 1.273432970046997
Validation loss: 1.90971206080529

Epoch: 6| Step: 12
Training loss: 1.5524200201034546
Validation loss: 1.8930566772337882

Epoch: 6| Step: 13
Training loss: 0.876032829284668
Validation loss: 1.931236841345346

Epoch: 239| Step: 0
Training loss: 0.7051317095756531
Validation loss: 1.962283416460919

Epoch: 6| Step: 1
Training loss: 0.7535868883132935
Validation loss: 2.0168235455789874

Epoch: 6| Step: 2
Training loss: 1.087475061416626
Validation loss: 2.014488758579377

Epoch: 6| Step: 3
Training loss: 0.747816801071167
Validation loss: 2.042462706565857

Epoch: 6| Step: 4
Training loss: 1.1398570537567139
Validation loss: 2.0324216106886506

Epoch: 6| Step: 5
Training loss: 1.3609592914581299
Validation loss: 2.0637370309522076

Epoch: 6| Step: 6
Training loss: 1.7646543979644775
Validation loss: 2.055906411140196

Epoch: 6| Step: 7
Training loss: 1.757532000541687
Validation loss: 2.0084847455383628

Epoch: 6| Step: 8
Training loss: 0.822267472743988
Validation loss: 1.9952286315220658

Epoch: 6| Step: 9
Training loss: 1.6907137632369995
Validation loss: 1.9636697307709725

Epoch: 6| Step: 10
Training loss: 1.263271450996399
Validation loss: 1.9796606007442679

Epoch: 6| Step: 11
Training loss: 0.933473527431488
Validation loss: 1.9809344263486965

Epoch: 6| Step: 12
Training loss: 1.1914732456207275
Validation loss: 1.99186776145812

Epoch: 6| Step: 13
Training loss: 0.8942997455596924
Validation loss: 1.9959338185607747

Epoch: 240| Step: 0
Training loss: 0.8257972002029419
Validation loss: 2.0424882481175084

Epoch: 6| Step: 1
Training loss: 1.222948670387268
Validation loss: 2.0528170190831667

Epoch: 6| Step: 2
Training loss: 1.436221718788147
Validation loss: 2.0614216276394424

Epoch: 6| Step: 3
Training loss: 1.0651743412017822
Validation loss: 2.089691631255611

Epoch: 6| Step: 4
Training loss: 1.081944465637207
Validation loss: 2.0945570327902354

Epoch: 6| Step: 5
Training loss: 0.9005995988845825
Validation loss: 2.0928302708492486

Epoch: 6| Step: 6
Training loss: 1.5305243730545044
Validation loss: 2.069158031094459

Epoch: 6| Step: 7
Training loss: 1.1040763854980469
Validation loss: 2.0439115519164712

Epoch: 6| Step: 8
Training loss: 1.389101266860962
Validation loss: 2.0375122024166967

Epoch: 6| Step: 9
Training loss: 0.5300455689430237
Validation loss: 1.9889248314724173

Epoch: 6| Step: 10
Training loss: 1.3428980112075806
Validation loss: 1.9910449533052341

Epoch: 6| Step: 11
Training loss: 0.9617476463317871
Validation loss: 1.9806171489018265

Epoch: 6| Step: 12
Training loss: 0.9237157702445984
Validation loss: 1.9769952053664832

Epoch: 6| Step: 13
Training loss: 1.9419097900390625
Validation loss: 1.9623473408401653

Epoch: 241| Step: 0
Training loss: 0.7443028688430786
Validation loss: 2.0053547543864094

Epoch: 6| Step: 1
Training loss: 1.1860954761505127
Validation loss: 2.049984291035642

Epoch: 6| Step: 2
Training loss: 0.8752807378768921
Validation loss: 2.0630824027522916

Epoch: 6| Step: 3
Training loss: 1.155883550643921
Validation loss: 2.0105068029895907

Epoch: 6| Step: 4
Training loss: 0.5222705006599426
Validation loss: 2.0207122859134468

Epoch: 6| Step: 5
Training loss: 1.1612882614135742
Validation loss: 1.9937921826557448

Epoch: 6| Step: 6
Training loss: 0.8230891823768616
Validation loss: 1.9747860329125517

Epoch: 6| Step: 7
Training loss: 1.1677792072296143
Validation loss: 1.9773844929151638

Epoch: 6| Step: 8
Training loss: 1.667124629020691
Validation loss: 1.9677083671733897

Epoch: 6| Step: 9
Training loss: 1.4199554920196533
Validation loss: 1.9408217540351294

Epoch: 6| Step: 10
Training loss: 1.5608973503112793
Validation loss: 1.944208304087321

Epoch: 6| Step: 11
Training loss: 1.2777600288391113
Validation loss: 1.946947269542243

Epoch: 6| Step: 12
Training loss: 0.5933660864830017
Validation loss: 1.9490471463049612

Epoch: 6| Step: 13
Training loss: 2.084214448928833
Validation loss: 1.9452647380931403

Epoch: 242| Step: 0
Training loss: 0.9790330529212952
Validation loss: 1.9833952649947135

Epoch: 6| Step: 1
Training loss: 0.8706506490707397
Validation loss: 1.995811734148251

Epoch: 6| Step: 2
Training loss: 2.0069243907928467
Validation loss: 1.9985941571574057

Epoch: 6| Step: 3
Training loss: 1.6714190244674683
Validation loss: 2.0090857551943873

Epoch: 6| Step: 4
Training loss: 0.7716884613037109
Validation loss: 2.0267526911151026

Epoch: 6| Step: 5
Training loss: 1.1181066036224365
Validation loss: 2.0384944318443217

Epoch: 6| Step: 6
Training loss: 1.159903883934021
Validation loss: 2.038534290047102

Epoch: 6| Step: 7
Training loss: 0.7375547885894775
Validation loss: 2.022936581283487

Epoch: 6| Step: 8
Training loss: 0.943159282207489
Validation loss: 1.987119669555336

Epoch: 6| Step: 9
Training loss: 0.8893030881881714
Validation loss: 1.9705316353869695

Epoch: 6| Step: 10
Training loss: 1.2646106481552124
Validation loss: 1.9526617603917276

Epoch: 6| Step: 11
Training loss: 1.4782136678695679
Validation loss: 1.9075803513168006

Epoch: 6| Step: 12
Training loss: 1.260941743850708
Validation loss: 1.9234520043096235

Epoch: 6| Step: 13
Training loss: 0.8684895038604736
Validation loss: 1.9273624291983984

Epoch: 243| Step: 0
Training loss: 0.9017375111579895
Validation loss: 1.9513135879270491

Epoch: 6| Step: 1
Training loss: 1.0875567197799683
Validation loss: 1.9829173985347952

Epoch: 6| Step: 2
Training loss: 1.5205485820770264
Validation loss: 1.979274171654896

Epoch: 6| Step: 3
Training loss: 0.6081191301345825
Validation loss: 2.000757881390151

Epoch: 6| Step: 4
Training loss: 0.5921663045883179
Validation loss: 2.023840494053338

Epoch: 6| Step: 5
Training loss: 1.596994400024414
Validation loss: 2.0040804827085106

Epoch: 6| Step: 6
Training loss: 0.9373304843902588
Validation loss: 2.0253955164263324

Epoch: 6| Step: 7
Training loss: 1.2494571208953857
Validation loss: 2.043684123664774

Epoch: 6| Step: 8
Training loss: 1.3653655052185059
Validation loss: 2.0619047303353586

Epoch: 6| Step: 9
Training loss: 1.08391273021698
Validation loss: 2.0529837813428653

Epoch: 6| Step: 10
Training loss: 0.9710695743560791
Validation loss: 2.0711896509252568

Epoch: 6| Step: 11
Training loss: 1.2755873203277588
Validation loss: 2.037111573321845

Epoch: 6| Step: 12
Training loss: 1.1837127208709717
Validation loss: 2.0246613000028875

Epoch: 6| Step: 13
Training loss: 1.3281018733978271
Validation loss: 1.987965097991369

Epoch: 244| Step: 0
Training loss: 1.114723801612854
Validation loss: 1.9914654916332615

Epoch: 6| Step: 1
Training loss: 1.0592714548110962
Validation loss: 2.016215767911685

Epoch: 6| Step: 2
Training loss: 0.780613899230957
Validation loss: 1.9819882992775208

Epoch: 6| Step: 3
Training loss: 0.9547041058540344
Validation loss: 2.0188310300150225

Epoch: 6| Step: 4
Training loss: 1.0161073207855225
Validation loss: 2.0196842403822046

Epoch: 6| Step: 5
Training loss: 1.160473108291626
Validation loss: 1.991798666215712

Epoch: 6| Step: 6
Training loss: 1.069027066230774
Validation loss: 1.992965325232475

Epoch: 6| Step: 7
Training loss: 1.2713537216186523
Validation loss: 1.997199261060325

Epoch: 6| Step: 8
Training loss: 1.2552428245544434
Validation loss: 1.978943483803862

Epoch: 6| Step: 9
Training loss: 0.9439514875411987
Validation loss: 1.9524917846084924

Epoch: 6| Step: 10
Training loss: 1.5230791568756104
Validation loss: 1.9704562117976527

Epoch: 6| Step: 11
Training loss: 0.9813146591186523
Validation loss: 1.9766863392245384

Epoch: 6| Step: 12
Training loss: 1.0753600597381592
Validation loss: 1.996276383758873

Epoch: 6| Step: 13
Training loss: 0.9628584384918213
Validation loss: 1.9813412338174798

Epoch: 245| Step: 0
Training loss: 1.1586134433746338
Validation loss: 2.0099749026759977

Epoch: 6| Step: 1
Training loss: 1.1371488571166992
Validation loss: 2.0018332876184934

Epoch: 6| Step: 2
Training loss: 0.9515677094459534
Validation loss: 2.0240045183448383

Epoch: 6| Step: 3
Training loss: 0.9702639579772949
Validation loss: 2.08345063014697

Epoch: 6| Step: 4
Training loss: 0.44928354024887085
Validation loss: 2.0413009428208873

Epoch: 6| Step: 5
Training loss: 1.2165307998657227
Validation loss: 2.040953888688036

Epoch: 6| Step: 6
Training loss: 1.2981353998184204
Validation loss: 1.973095965641801

Epoch: 6| Step: 7
Training loss: 1.2181236743927002
Validation loss: 1.9654307596145137

Epoch: 6| Step: 8
Training loss: 1.099536657333374
Validation loss: 1.9648021216033607

Epoch: 6| Step: 9
Training loss: 1.0238709449768066
Validation loss: 1.9528831153787591

Epoch: 6| Step: 10
Training loss: 1.2488336563110352
Validation loss: 1.9487791369038243

Epoch: 6| Step: 11
Training loss: 1.2393609285354614
Validation loss: 1.951301916953056

Epoch: 6| Step: 12
Training loss: 0.8050764799118042
Validation loss: 1.9717631211844824

Epoch: 6| Step: 13
Training loss: 1.0078481435775757
Validation loss: 1.9522931716775382

Epoch: 246| Step: 0
Training loss: 1.2337067127227783
Validation loss: 1.948118984058339

Epoch: 6| Step: 1
Training loss: 0.6656869649887085
Validation loss: 1.9528340639606598

Epoch: 6| Step: 2
Training loss: 1.1444050073623657
Validation loss: 1.9655472129903815

Epoch: 6| Step: 3
Training loss: 1.0455621480941772
Validation loss: 1.9890874995980212

Epoch: 6| Step: 4
Training loss: 1.159143328666687
Validation loss: 1.99070232401612

Epoch: 6| Step: 5
Training loss: 0.9044256210327148
Validation loss: 1.979898706559212

Epoch: 6| Step: 6
Training loss: 1.1588778495788574
Validation loss: 1.9565752731856478

Epoch: 6| Step: 7
Training loss: 0.9511686563491821
Validation loss: 1.9602139431943175

Epoch: 6| Step: 8
Training loss: 0.9194837212562561
Validation loss: 1.9621232145576066

Epoch: 6| Step: 9
Training loss: 1.1294938325881958
Validation loss: 1.9506108632651709

Epoch: 6| Step: 10
Training loss: 1.0558162927627563
Validation loss: 1.9552724156328427

Epoch: 6| Step: 11
Training loss: 0.8679383993148804
Validation loss: 1.9635096288496448

Epoch: 6| Step: 12
Training loss: 0.8142827749252319
Validation loss: 1.925730243805916

Epoch: 6| Step: 13
Training loss: 1.6032230854034424
Validation loss: 1.921825401244625

Epoch: 247| Step: 0
Training loss: 1.3511735200881958
Validation loss: 1.9367691265639437

Epoch: 6| Step: 1
Training loss: 0.9792503118515015
Validation loss: 1.9577613005074121

Epoch: 6| Step: 2
Training loss: 1.2672439813613892
Validation loss: 1.9618602837285688

Epoch: 6| Step: 3
Training loss: 1.2835748195648193
Validation loss: 2.008531011560912

Epoch: 6| Step: 4
Training loss: 0.6888468265533447
Validation loss: 1.9935360159925235

Epoch: 6| Step: 5
Training loss: 1.2416975498199463
Validation loss: 2.041673755133024

Epoch: 6| Step: 6
Training loss: 0.3682326674461365
Validation loss: 2.0238842220716577

Epoch: 6| Step: 7
Training loss: 0.7837721109390259
Validation loss: 2.027035395304362

Epoch: 6| Step: 8
Training loss: 0.5602076053619385
Validation loss: 2.0090622094369706

Epoch: 6| Step: 9
Training loss: 1.004197597503662
Validation loss: 1.9915861903980214

Epoch: 6| Step: 10
Training loss: 1.6501619815826416
Validation loss: 2.00155476344529

Epoch: 6| Step: 11
Training loss: 1.1332011222839355
Validation loss: 1.96984451816928

Epoch: 6| Step: 12
Training loss: 0.9833089113235474
Validation loss: 1.9481574489224343

Epoch: 6| Step: 13
Training loss: 1.1065150499343872
Validation loss: 1.9364100117837229

Epoch: 248| Step: 0
Training loss: 0.9060063362121582
Validation loss: 1.9145245064971268

Epoch: 6| Step: 1
Training loss: 1.6950411796569824
Validation loss: 1.9051797941166868

Epoch: 6| Step: 2
Training loss: 1.4063891172409058
Validation loss: 1.882500784371489

Epoch: 6| Step: 3
Training loss: 1.0963629484176636
Validation loss: 1.9058864616578626

Epoch: 6| Step: 4
Training loss: 1.1585919857025146
Validation loss: 1.929278055826823

Epoch: 6| Step: 5
Training loss: 0.7421672344207764
Validation loss: 1.9803393156297746

Epoch: 6| Step: 6
Training loss: 1.2565381526947021
Validation loss: 1.9841468629016672

Epoch: 6| Step: 7
Training loss: 0.7415659427642822
Validation loss: 1.9965078869173605

Epoch: 6| Step: 8
Training loss: 1.0015084743499756
Validation loss: 2.0315749811869797

Epoch: 6| Step: 9
Training loss: 0.5521853566169739
Validation loss: 2.050973889648273

Epoch: 6| Step: 10
Training loss: 0.9140843152999878
Validation loss: 2.042407753647015

Epoch: 6| Step: 11
Training loss: 0.5813078284263611
Validation loss: 2.0294070756563576

Epoch: 6| Step: 12
Training loss: 0.9785466194152832
Validation loss: 1.9983245095899027

Epoch: 6| Step: 13
Training loss: 1.551247477531433
Validation loss: 1.9674078418362526

Epoch: 249| Step: 0
Training loss: 1.102141261100769
Validation loss: 1.9649789064161238

Epoch: 6| Step: 1
Training loss: 0.4899536073207855
Validation loss: 1.9458412701083767

Epoch: 6| Step: 2
Training loss: 1.1006784439086914
Validation loss: 1.9106113205673874

Epoch: 6| Step: 3
Training loss: 0.6496917605400085
Validation loss: 1.9161066624426073

Epoch: 6| Step: 4
Training loss: 1.0834879875183105
Validation loss: 1.8866928674841439

Epoch: 6| Step: 5
Training loss: 0.8432309627532959
Validation loss: 1.9246317609663932

Epoch: 6| Step: 6
Training loss: 1.214802861213684
Validation loss: 1.9779218601924118

Epoch: 6| Step: 7
Training loss: 1.120039939880371
Validation loss: 1.9717458486557007

Epoch: 6| Step: 8
Training loss: 1.4132938385009766
Validation loss: 2.0346514307042605

Epoch: 6| Step: 9
Training loss: 1.2655749320983887
Validation loss: 2.0386742314984723

Epoch: 6| Step: 10
Training loss: 1.377450942993164
Validation loss: 2.095879554748535

Epoch: 6| Step: 11
Training loss: 1.311948299407959
Validation loss: 2.1128261909689954

Epoch: 6| Step: 12
Training loss: 0.9013610482215881
Validation loss: 2.097266633023498

Epoch: 6| Step: 13
Training loss: 0.7260901927947998
Validation loss: 2.088743370066407

Epoch: 250| Step: 0
Training loss: 1.2560100555419922
Validation loss: 2.0677653384465042

Epoch: 6| Step: 1
Training loss: 1.2626093626022339
Validation loss: 2.0416577387881536

Epoch: 6| Step: 2
Training loss: 0.5294793844223022
Validation loss: 2.028937506419356

Epoch: 6| Step: 3
Training loss: 1.3433663845062256
Validation loss: 1.9919500812407462

Epoch: 6| Step: 4
Training loss: 0.9275161623954773
Validation loss: 1.938323461881248

Epoch: 6| Step: 5
Training loss: 1.3306249380111694
Validation loss: 1.9244948458927933

Epoch: 6| Step: 6
Training loss: 0.5055515170097351
Validation loss: 1.905092885417323

Epoch: 6| Step: 7
Training loss: 0.5986120700836182
Validation loss: 1.9343107079946866

Epoch: 6| Step: 8
Training loss: 1.1404993534088135
Validation loss: 1.9545069894483011

Epoch: 6| Step: 9
Training loss: 1.0268654823303223
Validation loss: 1.9491803389723583

Epoch: 6| Step: 10
Training loss: 0.8429766297340393
Validation loss: 2.0205705396590696

Epoch: 6| Step: 11
Training loss: 1.529996633529663
Validation loss: 2.03434786617115

Epoch: 6| Step: 12
Training loss: 1.1873904466629028
Validation loss: 2.03684506365048

Epoch: 6| Step: 13
Training loss: 0.7626819610595703
Validation loss: 2.0398817805833716

Epoch: 251| Step: 0
Training loss: 0.5555083751678467
Validation loss: 2.047846658255464

Epoch: 6| Step: 1
Training loss: 0.9299266934394836
Validation loss: 1.9958776415035289

Epoch: 6| Step: 2
Training loss: 1.2166807651519775
Validation loss: 1.9728108964940554

Epoch: 6| Step: 3
Training loss: 1.254387617111206
Validation loss: 2.0043679552693523

Epoch: 6| Step: 4
Training loss: 0.7663297057151794
Validation loss: 1.9586115460241995

Epoch: 6| Step: 5
Training loss: 0.8291997909545898
Validation loss: 1.9763848884131319

Epoch: 6| Step: 6
Training loss: 1.0457252264022827
Validation loss: 1.9238770315724034

Epoch: 6| Step: 7
Training loss: 1.041252613067627
Validation loss: 1.935216385831115

Epoch: 6| Step: 8
Training loss: 1.0348811149597168
Validation loss: 1.9584886540648758

Epoch: 6| Step: 9
Training loss: 0.7037681937217712
Validation loss: 1.9762942867894326

Epoch: 6| Step: 10
Training loss: 1.0022706985473633
Validation loss: 1.995335699409567

Epoch: 6| Step: 11
Training loss: 1.6241440773010254
Validation loss: 2.0349613543479674

Epoch: 6| Step: 12
Training loss: 1.0120490789413452
Validation loss: 2.048674293743667

Epoch: 6| Step: 13
Training loss: 0.9943286180496216
Validation loss: 2.013471249611147

Epoch: 252| Step: 0
Training loss: 1.2429653406143188
Validation loss: 2.0018419924602715

Epoch: 6| Step: 1
Training loss: 1.0385091304779053
Validation loss: 1.9582145624263312

Epoch: 6| Step: 2
Training loss: 0.8372126221656799
Validation loss: 1.9600192180243872

Epoch: 6| Step: 3
Training loss: 0.8088277578353882
Validation loss: 1.9079392725421536

Epoch: 6| Step: 4
Training loss: 0.8360308408737183
Validation loss: 1.9300454611419349

Epoch: 6| Step: 5
Training loss: 1.0068717002868652
Validation loss: 1.8920270435271724

Epoch: 6| Step: 6
Training loss: 0.7678667306900024
Validation loss: 1.9085692346736949

Epoch: 6| Step: 7
Training loss: 1.098885178565979
Validation loss: 1.9513358352004841

Epoch: 6| Step: 8
Training loss: 0.8985156416893005
Validation loss: 1.973192386729743

Epoch: 6| Step: 9
Training loss: 1.2794404029846191
Validation loss: 2.017859790914802

Epoch: 6| Step: 10
Training loss: 1.001560926437378
Validation loss: 2.049401326846051

Epoch: 6| Step: 11
Training loss: 1.1216683387756348
Validation loss: 2.0699047119386735

Epoch: 6| Step: 12
Training loss: 1.1529629230499268
Validation loss: 2.089598014790525

Epoch: 6| Step: 13
Training loss: 1.1437221765518188
Validation loss: 2.0658419568051576

Epoch: 253| Step: 0
Training loss: 1.097057819366455
Validation loss: 2.034760252121956

Epoch: 6| Step: 1
Training loss: 1.1551920175552368
Validation loss: 1.974061785205718

Epoch: 6| Step: 2
Training loss: 0.7550803422927856
Validation loss: 1.9804838421524211

Epoch: 6| Step: 3
Training loss: 1.3208976984024048
Validation loss: 1.938952669020622

Epoch: 6| Step: 4
Training loss: 0.5636463761329651
Validation loss: 1.9135178699288318

Epoch: 6| Step: 5
Training loss: 0.665480375289917
Validation loss: 1.8905509838493921

Epoch: 6| Step: 6
Training loss: 1.358622431755066
Validation loss: 1.8817503016482118

Epoch: 6| Step: 7
Training loss: 1.3685734272003174
Validation loss: 1.8917787510861632

Epoch: 6| Step: 8
Training loss: 0.7042664885520935
Validation loss: 1.9345000866920716

Epoch: 6| Step: 9
Training loss: 1.2536176443099976
Validation loss: 1.9269826771110616

Epoch: 6| Step: 10
Training loss: 1.5969152450561523
Validation loss: 1.9775292014562955

Epoch: 6| Step: 11
Training loss: 0.7663458585739136
Validation loss: 1.9807237758431384

Epoch: 6| Step: 12
Training loss: 0.8934661746025085
Validation loss: 1.9809441528012675

Epoch: 6| Step: 13
Training loss: 0.5259531736373901
Validation loss: 1.9694924636553692

Epoch: 254| Step: 0
Training loss: 0.9078190326690674
Validation loss: 1.9551030038505472

Epoch: 6| Step: 1
Training loss: 0.9030008316040039
Validation loss: 1.970239963582767

Epoch: 6| Step: 2
Training loss: 0.9286028742790222
Validation loss: 1.9492179296349967

Epoch: 6| Step: 3
Training loss: 1.2666420936584473
Validation loss: 1.9349546676040978

Epoch: 6| Step: 4
Training loss: 0.7495383024215698
Validation loss: 1.9181877272103423

Epoch: 6| Step: 5
Training loss: 1.0098824501037598
Validation loss: 1.858962066711918

Epoch: 6| Step: 6
Training loss: 1.5518593788146973
Validation loss: 1.8519992636096092

Epoch: 6| Step: 7
Training loss: 0.7684866189956665
Validation loss: 1.8600489811230732

Epoch: 6| Step: 8
Training loss: 0.7920193672180176
Validation loss: 1.8962316718152774

Epoch: 6| Step: 9
Training loss: 1.1864761114120483
Validation loss: 1.8846128281726633

Epoch: 6| Step: 10
Training loss: 0.7080172896385193
Validation loss: 1.9234268588404502

Epoch: 6| Step: 11
Training loss: 0.38083475828170776
Validation loss: 1.9186127121730516

Epoch: 6| Step: 12
Training loss: 1.3206385374069214
Validation loss: 1.9683623852268342

Epoch: 6| Step: 13
Training loss: 1.3797119855880737
Validation loss: 1.9829782657725836

Epoch: 255| Step: 0
Training loss: 1.1536201238632202
Validation loss: 1.980814855585816

Epoch: 6| Step: 1
Training loss: 0.6710769534111023
Validation loss: 1.987077836067446

Epoch: 6| Step: 2
Training loss: 0.9106051325798035
Validation loss: 2.001623417741509

Epoch: 6| Step: 3
Training loss: 0.6409890651702881
Validation loss: 1.9613296818989578

Epoch: 6| Step: 4
Training loss: 1.529239535331726
Validation loss: 1.976731615681802

Epoch: 6| Step: 5
Training loss: 0.6027425527572632
Validation loss: 1.9689561128616333

Epoch: 6| Step: 6
Training loss: 0.47571730613708496
Validation loss: 1.9481288617657078

Epoch: 6| Step: 7
Training loss: 1.2102856636047363
Validation loss: 1.9369520525778494

Epoch: 6| Step: 8
Training loss: 0.9803295135498047
Validation loss: 1.939428553786329

Epoch: 6| Step: 9
Training loss: 0.7475389242172241
Validation loss: 1.9498487928862214

Epoch: 6| Step: 10
Training loss: 0.7971927523612976
Validation loss: 1.9221350082787134

Epoch: 6| Step: 11
Training loss: 1.1415050029754639
Validation loss: 1.940315515764298

Epoch: 6| Step: 12
Training loss: 1.1472320556640625
Validation loss: 1.9462178727631927

Epoch: 6| Step: 13
Training loss: 1.5854264497756958
Validation loss: 1.9626765456250919

Epoch: 256| Step: 0
Training loss: 0.9722368717193604
Validation loss: 1.951007781490203

Epoch: 6| Step: 1
Training loss: 0.8260241150856018
Validation loss: 1.9353560209274292

Epoch: 6| Step: 2
Training loss: 0.8246880769729614
Validation loss: 1.9585400704414613

Epoch: 6| Step: 3
Training loss: 1.1635942459106445
Validation loss: 1.9410876048508512

Epoch: 6| Step: 4
Training loss: 0.5844991207122803
Validation loss: 1.94171307932946

Epoch: 6| Step: 5
Training loss: 0.9939929246902466
Validation loss: 1.9392404505001601

Epoch: 6| Step: 6
Training loss: 0.9139246940612793
Validation loss: 1.954354234921035

Epoch: 6| Step: 7
Training loss: 0.9937922358512878
Validation loss: 1.9703978941004763

Epoch: 6| Step: 8
Training loss: 1.2881625890731812
Validation loss: 2.0594331577260006

Epoch: 6| Step: 9
Training loss: 0.9180122017860413
Validation loss: 2.09000515296895

Epoch: 6| Step: 10
Training loss: 0.8970859050750732
Validation loss: 2.1286684928401822

Epoch: 6| Step: 11
Training loss: 1.1491568088531494
Validation loss: 2.101916261898574

Epoch: 6| Step: 12
Training loss: 0.8993085622787476
Validation loss: 2.0982553087255007

Epoch: 6| Step: 13
Training loss: 1.20053231716156
Validation loss: 2.0209717096820956

Epoch: 257| Step: 0
Training loss: 1.1266741752624512
Validation loss: 1.9525345730525192

Epoch: 6| Step: 1
Training loss: 1.014337182044983
Validation loss: 1.9191396941420853

Epoch: 6| Step: 2
Training loss: 0.8487128019332886
Validation loss: 1.8837742472207675

Epoch: 6| Step: 3
Training loss: 0.7236055135726929
Validation loss: 1.837289692253195

Epoch: 6| Step: 4
Training loss: 1.045459270477295
Validation loss: 1.822963168544154

Epoch: 6| Step: 5
Training loss: 0.758165717124939
Validation loss: 1.8299699009105723

Epoch: 6| Step: 6
Training loss: 0.674674928188324
Validation loss: 1.8343406992573892

Epoch: 6| Step: 7
Training loss: 0.6248959302902222
Validation loss: 1.8631397806188112

Epoch: 6| Step: 8
Training loss: 1.3729779720306396
Validation loss: 1.8657127144516155

Epoch: 6| Step: 9
Training loss: 0.9664194583892822
Validation loss: 1.868114798299728

Epoch: 6| Step: 10
Training loss: 0.9171194434165955
Validation loss: 1.883324787180911

Epoch: 6| Step: 11
Training loss: 0.8307551145553589
Validation loss: 1.900520093979374

Epoch: 6| Step: 12
Training loss: 1.445972204208374
Validation loss: 1.9074535600600704

Epoch: 6| Step: 13
Training loss: 0.8619682788848877
Validation loss: 1.900051748880776

Epoch: 258| Step: 0
Training loss: 1.0462329387664795
Validation loss: 1.9207917862041022

Epoch: 6| Step: 1
Training loss: 0.9687875509262085
Validation loss: 1.9326810195881834

Epoch: 6| Step: 2
Training loss: 1.0548157691955566
Validation loss: 1.9896494675708074

Epoch: 6| Step: 3
Training loss: 0.9512208104133606
Validation loss: 1.982034296117803

Epoch: 6| Step: 4
Training loss: 0.407088041305542
Validation loss: 1.9843772201127903

Epoch: 6| Step: 5
Training loss: 1.123898983001709
Validation loss: 2.0003961901510916

Epoch: 6| Step: 6
Training loss: 0.6273940801620483
Validation loss: 1.984274600141792

Epoch: 6| Step: 7
Training loss: 0.7350012063980103
Validation loss: 1.9457670629665416

Epoch: 6| Step: 8
Training loss: 1.0565497875213623
Validation loss: 1.9375782602576799

Epoch: 6| Step: 9
Training loss: 0.9872488975524902
Validation loss: 1.855334593403724

Epoch: 6| Step: 10
Training loss: 1.2785522937774658
Validation loss: 1.8349005329993464

Epoch: 6| Step: 11
Training loss: 1.3628547191619873
Validation loss: 1.8376886472907117

Epoch: 6| Step: 12
Training loss: 0.6989070177078247
Validation loss: 1.821712036286631

Epoch: 6| Step: 13
Training loss: 0.856571614742279
Validation loss: 1.844687734880755

Epoch: 259| Step: 0
Training loss: 0.8803883790969849
Validation loss: 1.8709767672323412

Epoch: 6| Step: 1
Training loss: 0.8141467571258545
Validation loss: 1.8803498309145692

Epoch: 6| Step: 2
Training loss: 0.8607968688011169
Validation loss: 1.9583186052178825

Epoch: 6| Step: 3
Training loss: 1.1308231353759766
Validation loss: 1.9665528164115003

Epoch: 6| Step: 4
Training loss: 1.0447496175765991
Validation loss: 2.057195237887803

Epoch: 6| Step: 5
Training loss: 0.5031430125236511
Validation loss: 2.019193175018475

Epoch: 6| Step: 6
Training loss: 1.0704996585845947
Validation loss: 1.9815184647037136

Epoch: 6| Step: 7
Training loss: 0.814734935760498
Validation loss: 1.9843378848926996

Epoch: 6| Step: 8
Training loss: 0.8453606367111206
Validation loss: 1.9876225251023487

Epoch: 6| Step: 9
Training loss: 1.3566094636917114
Validation loss: 1.9768810759308517

Epoch: 6| Step: 10
Training loss: 0.6087223887443542
Validation loss: 1.9747340127985964

Epoch: 6| Step: 11
Training loss: 0.9755378365516663
Validation loss: 1.9266587623985865

Epoch: 6| Step: 12
Training loss: 0.8855292797088623
Validation loss: 1.9407967521298317

Epoch: 6| Step: 13
Training loss: 1.3282169103622437
Validation loss: 1.936137927475796

Epoch: 260| Step: 0
Training loss: 1.2052079439163208
Validation loss: 1.9035815000534058

Epoch: 6| Step: 1
Training loss: 1.2648974657058716
Validation loss: 1.9082962800097722

Epoch: 6| Step: 2
Training loss: 0.6799368858337402
Validation loss: 1.9101052976423694

Epoch: 6| Step: 3
Training loss: 1.0670833587646484
Validation loss: 1.89553330790612

Epoch: 6| Step: 4
Training loss: 0.6887084245681763
Validation loss: 1.9104230890991867

Epoch: 6| Step: 5
Training loss: 1.0969593524932861
Validation loss: 1.8919465605930617

Epoch: 6| Step: 6
Training loss: 1.1942594051361084
Validation loss: 1.9063370432904971

Epoch: 6| Step: 7
Training loss: 1.1814923286437988
Validation loss: 1.9021937859955655

Epoch: 6| Step: 8
Training loss: 0.8887482285499573
Validation loss: 1.9167696634928386

Epoch: 6| Step: 9
Training loss: 0.8295264840126038
Validation loss: 1.9738585179851902

Epoch: 6| Step: 10
Training loss: 0.5177658200263977
Validation loss: 2.029249055411226

Epoch: 6| Step: 11
Training loss: 0.8040009140968323
Validation loss: 2.0503426662055393

Epoch: 6| Step: 12
Training loss: 1.0058118104934692
Validation loss: 2.098431820510536

Epoch: 6| Step: 13
Training loss: 0.5789870023727417
Validation loss: 2.1251391621046167

Epoch: 261| Step: 0
Training loss: 1.2863736152648926
Validation loss: 2.120259079881894

Epoch: 6| Step: 1
Training loss: 1.0592154264450073
Validation loss: 2.1030701052758003

Epoch: 6| Step: 2
Training loss: 1.3910969495773315
Validation loss: 2.068019720815843

Epoch: 6| Step: 3
Training loss: 0.8218591213226318
Validation loss: 2.0177894241066388

Epoch: 6| Step: 4
Training loss: 0.9413007497787476
Validation loss: 1.9707199091552405

Epoch: 6| Step: 5
Training loss: 1.2914557456970215
Validation loss: 1.9530454143401115

Epoch: 6| Step: 6
Training loss: 0.6821577548980713
Validation loss: 1.8664743438843758

Epoch: 6| Step: 7
Training loss: 0.701481282711029
Validation loss: 1.8645049346390592

Epoch: 6| Step: 8
Training loss: 1.2466728687286377
Validation loss: 1.8877366127506379

Epoch: 6| Step: 9
Training loss: 0.6855369210243225
Validation loss: 1.9047388594637635

Epoch: 6| Step: 10
Training loss: 0.49619799852371216
Validation loss: 1.9244750917598765

Epoch: 6| Step: 11
Training loss: 1.0213452577590942
Validation loss: 1.924334946499076

Epoch: 6| Step: 12
Training loss: 0.8312439918518066
Validation loss: 1.9780116337601856

Epoch: 6| Step: 13
Training loss: 1.0883249044418335
Validation loss: 1.9700354119782806

Epoch: 262| Step: 0
Training loss: 1.1788074970245361
Validation loss: 1.9765618193534114

Epoch: 6| Step: 1
Training loss: 0.9263713955879211
Validation loss: 2.008597622635544

Epoch: 6| Step: 2
Training loss: 0.8245770931243896
Validation loss: 2.0048545534892748

Epoch: 6| Step: 3
Training loss: 0.7411271333694458
Validation loss: 2.018210757163263

Epoch: 6| Step: 4
Training loss: 1.2166569232940674
Validation loss: 2.018538175090667

Epoch: 6| Step: 5
Training loss: 0.7744265198707581
Validation loss: 2.0152854406705467

Epoch: 6| Step: 6
Training loss: 0.6118830442428589
Validation loss: 1.9301345707267843

Epoch: 6| Step: 7
Training loss: 0.9050182104110718
Validation loss: 1.91356651372807

Epoch: 6| Step: 8
Training loss: 1.001025676727295
Validation loss: 1.8568106825633715

Epoch: 6| Step: 9
Training loss: 1.1228177547454834
Validation loss: 1.848676678954914

Epoch: 6| Step: 10
Training loss: 1.0304226875305176
Validation loss: 1.8782855080020042

Epoch: 6| Step: 11
Training loss: 0.9993799328804016
Validation loss: 1.89201565711729

Epoch: 6| Step: 12
Training loss: 0.7849122285842896
Validation loss: 1.9234136766003025

Epoch: 6| Step: 13
Training loss: 0.7511915564537048
Validation loss: 1.931585483653571

Epoch: 263| Step: 0
Training loss: 0.8013198375701904
Validation loss: 1.982421790399859

Epoch: 6| Step: 1
Training loss: 0.9898321032524109
Validation loss: 2.011673414579002

Epoch: 6| Step: 2
Training loss: 1.164560317993164
Validation loss: 1.9846190688430623

Epoch: 6| Step: 3
Training loss: 0.8758978247642517
Validation loss: 1.9797372459083475

Epoch: 6| Step: 4
Training loss: 0.9938149452209473
Validation loss: 1.9853857973570466

Epoch: 6| Step: 5
Training loss: 0.8180014491081238
Validation loss: 2.00142986800081

Epoch: 6| Step: 6
Training loss: 0.83071368932724
Validation loss: 2.003379693595312

Epoch: 6| Step: 7
Training loss: 0.5600630044937134
Validation loss: 2.0290258546029367

Epoch: 6| Step: 8
Training loss: 0.7048690915107727
Validation loss: 1.9613567129258187

Epoch: 6| Step: 9
Training loss: 1.349543809890747
Validation loss: 1.9630871421547347

Epoch: 6| Step: 10
Training loss: 0.8929868340492249
Validation loss: 1.9406093410266343

Epoch: 6| Step: 11
Training loss: 0.5100818872451782
Validation loss: 1.9249882787786505

Epoch: 6| Step: 12
Training loss: 0.5316430926322937
Validation loss: 1.9190688761331702

Epoch: 6| Step: 13
Training loss: 1.2272003889083862
Validation loss: 1.9035261856612338

Epoch: 264| Step: 0
Training loss: 0.970149576663971
Validation loss: 1.9092032755574873

Epoch: 6| Step: 1
Training loss: 0.8350052237510681
Validation loss: 1.8911281580566077

Epoch: 6| Step: 2
Training loss: 0.3930550813674927
Validation loss: 1.9468951827736312

Epoch: 6| Step: 3
Training loss: 0.5236316323280334
Validation loss: 1.9370615764330792

Epoch: 6| Step: 4
Training loss: 0.8753147125244141
Validation loss: 1.946739496723298

Epoch: 6| Step: 5
Training loss: 1.281082034111023
Validation loss: 1.9618043655990272

Epoch: 6| Step: 6
Training loss: 0.7919187545776367
Validation loss: 1.9697565532499743

Epoch: 6| Step: 7
Training loss: 0.7859285473823547
Validation loss: 1.9671559231255644

Epoch: 6| Step: 8
Training loss: 1.140479326248169
Validation loss: 1.9622383720131331

Epoch: 6| Step: 9
Training loss: 0.9267736673355103
Validation loss: 1.9384766496637815

Epoch: 6| Step: 10
Training loss: 0.9551198482513428
Validation loss: 1.9171918707509195

Epoch: 6| Step: 11
Training loss: 0.9140442609786987
Validation loss: 1.9345266126817273

Epoch: 6| Step: 12
Training loss: 0.9442707300186157
Validation loss: 1.9353782335917156

Epoch: 6| Step: 13
Training loss: 0.974288284778595
Validation loss: 1.9005636861247401

Epoch: 265| Step: 0
Training loss: 1.0444294214248657
Validation loss: 1.8901791495661582

Epoch: 6| Step: 1
Training loss: 0.4104368984699249
Validation loss: 1.8668979085901731

Epoch: 6| Step: 2
Training loss: 1.379425287246704
Validation loss: 1.8875693505810154

Epoch: 6| Step: 3
Training loss: 0.730079174041748
Validation loss: 1.9389599971873785

Epoch: 6| Step: 4
Training loss: 1.090285062789917
Validation loss: 1.9066799866255892

Epoch: 6| Step: 5
Training loss: 0.8011422157287598
Validation loss: 1.9326244105574906

Epoch: 6| Step: 6
Training loss: 0.7734688520431519
Validation loss: 1.936097316844489

Epoch: 6| Step: 7
Training loss: 0.976753294467926
Validation loss: 1.9718540022450108

Epoch: 6| Step: 8
Training loss: 0.6630496978759766
Validation loss: 1.9740716706040085

Epoch: 6| Step: 9
Training loss: 0.9052587747573853
Validation loss: 1.9590013642464914

Epoch: 6| Step: 10
Training loss: 0.5543609857559204
Validation loss: 1.9663960984958115

Epoch: 6| Step: 11
Training loss: 0.7720131874084473
Validation loss: 1.9532849301574051

Epoch: 6| Step: 12
Training loss: 0.7933802604675293
Validation loss: 1.9344762153522943

Epoch: 6| Step: 13
Training loss: 1.087113857269287
Validation loss: 1.962591750647432

Epoch: 266| Step: 0
Training loss: 0.7093843221664429
Validation loss: 1.912241784475183

Epoch: 6| Step: 1
Training loss: 0.4621727168560028
Validation loss: 1.9213726494901924

Epoch: 6| Step: 2
Training loss: 0.5220910310745239
Validation loss: 1.9053321269250685

Epoch: 6| Step: 3
Training loss: 1.0061006546020508
Validation loss: 1.897374055718863

Epoch: 6| Step: 4
Training loss: 0.6915187835693359
Validation loss: 1.9229393569372033

Epoch: 6| Step: 5
Training loss: 0.7912412285804749
Validation loss: 1.9052275688417497

Epoch: 6| Step: 6
Training loss: 0.9187983870506287
Validation loss: 1.9461221182218162

Epoch: 6| Step: 7
Training loss: 1.3377866744995117
Validation loss: 1.9678277610450663

Epoch: 6| Step: 8
Training loss: 1.0974292755126953
Validation loss: 1.9687939305459299

Epoch: 6| Step: 9
Training loss: 0.9038993120193481
Validation loss: 1.976980714387791

Epoch: 6| Step: 10
Training loss: 0.8295425176620483
Validation loss: 1.9475877772095382

Epoch: 6| Step: 11
Training loss: 0.7742525935173035
Validation loss: 1.9289517838467833

Epoch: 6| Step: 12
Training loss: 0.9613577127456665
Validation loss: 1.8954540529558737

Epoch: 6| Step: 13
Training loss: 0.8525054454803467
Validation loss: 1.9032196255140408

Epoch: 267| Step: 0
Training loss: 0.815991997718811
Validation loss: 1.8766676379788307

Epoch: 6| Step: 1
Training loss: 0.8930120468139648
Validation loss: 1.8973696783024778

Epoch: 6| Step: 2
Training loss: 0.785609245300293
Validation loss: 1.8944039088423534

Epoch: 6| Step: 3
Training loss: 0.883990466594696
Validation loss: 1.9251186847686768

Epoch: 6| Step: 4
Training loss: 0.8258602023124695
Validation loss: 1.9103204947645946

Epoch: 6| Step: 5
Training loss: 0.783686637878418
Validation loss: 1.8976402949261408

Epoch: 6| Step: 6
Training loss: 0.8076617121696472
Validation loss: 1.932172530440874

Epoch: 6| Step: 7
Training loss: 1.4299860000610352
Validation loss: 1.9140366341478081

Epoch: 6| Step: 8
Training loss: 0.5189534425735474
Validation loss: 1.9552362503543976

Epoch: 6| Step: 9
Training loss: 0.7553091645240784
Validation loss: 1.9268501061265186

Epoch: 6| Step: 10
Training loss: 0.7158657312393188
Validation loss: 1.9448994103298392

Epoch: 6| Step: 11
Training loss: 0.38428065180778503
Validation loss: 1.9508955273576962

Epoch: 6| Step: 12
Training loss: 1.0955127477645874
Validation loss: 1.9228136308731572

Epoch: 6| Step: 13
Training loss: 0.8022698163986206
Validation loss: 1.9038282402100102

Epoch: 268| Step: 0
Training loss: 0.41856318712234497
Validation loss: 1.908229035715903

Epoch: 6| Step: 1
Training loss: 0.8508889675140381
Validation loss: 1.9282361320270005

Epoch: 6| Step: 2
Training loss: 0.6767570972442627
Validation loss: 1.9209506511688232

Epoch: 6| Step: 3
Training loss: 0.9951549768447876
Validation loss: 1.96082091587846

Epoch: 6| Step: 4
Training loss: 0.9764374494552612
Validation loss: 1.9730287726207445

Epoch: 6| Step: 5
Training loss: 0.45514121651649475
Validation loss: 1.9577963493203605

Epoch: 6| Step: 6
Training loss: 0.7222048044204712
Validation loss: 1.9546850522359211

Epoch: 6| Step: 7
Training loss: 1.0013694763183594
Validation loss: 1.9939538355796569

Epoch: 6| Step: 8
Training loss: 0.8144105672836304
Validation loss: 2.0008099630314815

Epoch: 6| Step: 9
Training loss: 0.9687339067459106
Validation loss: 2.016454532582273

Epoch: 6| Step: 10
Training loss: 0.6966358423233032
Validation loss: 2.008073963144774

Epoch: 6| Step: 11
Training loss: 0.8896287679672241
Validation loss: 1.9754249280498875

Epoch: 6| Step: 12
Training loss: 0.9300292730331421
Validation loss: 1.9547422726949055

Epoch: 6| Step: 13
Training loss: 1.0319119691848755
Validation loss: 1.9746375109559746

Epoch: 269| Step: 0
Training loss: 0.7422674298286438
Validation loss: 1.913852345558905

Epoch: 6| Step: 1
Training loss: 1.1887825727462769
Validation loss: 1.86770970718835

Epoch: 6| Step: 2
Training loss: 1.161230206489563
Validation loss: 1.8793897167328866

Epoch: 6| Step: 3
Training loss: 0.7349625825881958
Validation loss: 1.8450995209396526

Epoch: 6| Step: 4
Training loss: 0.7940934300422668
Validation loss: 1.856699433377994

Epoch: 6| Step: 5
Training loss: 0.4755951464176178
Validation loss: 1.8654558376599384

Epoch: 6| Step: 6
Training loss: 0.6876823902130127
Validation loss: 1.866649522576281

Epoch: 6| Step: 7
Training loss: 1.145416021347046
Validation loss: 1.8829591338352492

Epoch: 6| Step: 8
Training loss: 0.854137659072876
Validation loss: 1.9433675222499396

Epoch: 6| Step: 9
Training loss: 0.654624879360199
Validation loss: 1.9521467736972276

Epoch: 6| Step: 10
Training loss: 1.1395379304885864
Validation loss: 1.9788748141257995

Epoch: 6| Step: 11
Training loss: 0.7524295449256897
Validation loss: 1.940795592082444

Epoch: 6| Step: 12
Training loss: 0.36950355768203735
Validation loss: 1.9689512932172386

Epoch: 6| Step: 13
Training loss: 0.7993087768554688
Validation loss: 1.9390812817440237

Epoch: 270| Step: 0
Training loss: 0.8570595979690552
Validation loss: 1.9161120653152466

Epoch: 6| Step: 1
Training loss: 0.8476112484931946
Validation loss: 1.910385432422802

Epoch: 6| Step: 2
Training loss: 1.0056841373443604
Validation loss: 1.9148168807388635

Epoch: 6| Step: 3
Training loss: 0.7406928539276123
Validation loss: 1.896717079224125

Epoch: 6| Step: 4
Training loss: 0.48329609632492065
Validation loss: 1.9000943399244739

Epoch: 6| Step: 5
Training loss: 0.6821341514587402
Validation loss: 1.934670868740287

Epoch: 6| Step: 6
Training loss: 0.7940012216567993
Validation loss: 1.9679125085953744

Epoch: 6| Step: 7
Training loss: 0.5923801064491272
Validation loss: 1.9898093464553996

Epoch: 6| Step: 8
Training loss: 0.7366738319396973
Validation loss: 1.99887119313722

Epoch: 6| Step: 9
Training loss: 1.3456567525863647
Validation loss: 2.0246204176256732

Epoch: 6| Step: 10
Training loss: 0.6707337498664856
Validation loss: 2.052529957986647

Epoch: 6| Step: 11
Training loss: 1.0682992935180664
Validation loss: 2.0528228718747377

Epoch: 6| Step: 12
Training loss: 0.662295937538147
Validation loss: 1.994961811650184

Epoch: 6| Step: 13
Training loss: 1.0734525918960571
Validation loss: 1.9578861626245643

Epoch: 271| Step: 0
Training loss: 1.0197094678878784
Validation loss: 1.9680288222528273

Epoch: 6| Step: 1
Training loss: 0.7075492143630981
Validation loss: 1.9404502402069748

Epoch: 6| Step: 2
Training loss: 0.6647754907608032
Validation loss: 1.9130134851701799

Epoch: 6| Step: 3
Training loss: 0.8426960706710815
Validation loss: 1.9148463972153202

Epoch: 6| Step: 4
Training loss: 1.2602553367614746
Validation loss: 1.8826440483011224

Epoch: 6| Step: 5
Training loss: 0.9712966084480286
Validation loss: 1.8719863968510781

Epoch: 6| Step: 6
Training loss: 1.0906591415405273
Validation loss: 1.875750894187599

Epoch: 6| Step: 7
Training loss: 0.9893896579742432
Validation loss: 1.8880752645513064

Epoch: 6| Step: 8
Training loss: 0.5075260996818542
Validation loss: 1.889038647374799

Epoch: 6| Step: 9
Training loss: 0.4206467866897583
Validation loss: 1.9306575405982234

Epoch: 6| Step: 10
Training loss: 0.5372677445411682
Validation loss: 1.967464505985219

Epoch: 6| Step: 11
Training loss: 0.9100192785263062
Validation loss: 1.9942295089844735

Epoch: 6| Step: 12
Training loss: 0.6406000852584839
Validation loss: 2.009079264056298

Epoch: 6| Step: 13
Training loss: 0.9723544716835022
Validation loss: 1.999634083881173

Epoch: 272| Step: 0
Training loss: 1.0907373428344727
Validation loss: 1.9797559425395022

Epoch: 6| Step: 1
Training loss: 0.924135684967041
Validation loss: 1.96252792368653

Epoch: 6| Step: 2
Training loss: 0.8114986419677734
Validation loss: 1.9313842058181763

Epoch: 6| Step: 3
Training loss: 0.6611768007278442
Validation loss: 1.8842389980951946

Epoch: 6| Step: 4
Training loss: 0.9394189119338989
Validation loss: 1.8977968051869383

Epoch: 6| Step: 5
Training loss: 0.7174426317214966
Validation loss: 1.916572634891797

Epoch: 6| Step: 6
Training loss: 0.578288197517395
Validation loss: 1.940298673927143

Epoch: 6| Step: 7
Training loss: 0.6586340069770813
Validation loss: 1.9454985369918167

Epoch: 6| Step: 8
Training loss: 1.264794111251831
Validation loss: 2.0520547564311693

Epoch: 6| Step: 9
Training loss: 0.8740790486335754
Validation loss: 2.047552481774361

Epoch: 6| Step: 10
Training loss: 1.2141720056533813
Validation loss: 2.0325538317362466

Epoch: 6| Step: 11
Training loss: 0.5814375877380371
Validation loss: 1.9845533268426054

Epoch: 6| Step: 12
Training loss: 0.5997812151908875
Validation loss: 1.9386030704744401

Epoch: 6| Step: 13
Training loss: 0.7690512537956238
Validation loss: 1.9597133064782748

Epoch: 273| Step: 0
Training loss: 0.5237894058227539
Validation loss: 1.9593382766169887

Epoch: 6| Step: 1
Training loss: 0.5669702291488647
Validation loss: 1.9906565886671825

Epoch: 6| Step: 2
Training loss: 1.1928222179412842
Validation loss: 1.9730542475177395

Epoch: 6| Step: 3
Training loss: 0.8758918046951294
Validation loss: 1.9639483267261135

Epoch: 6| Step: 4
Training loss: 0.8090106248855591
Validation loss: 1.905120051035317

Epoch: 6| Step: 5
Training loss: 0.5708529949188232
Validation loss: 1.8619028547758698

Epoch: 6| Step: 6
Training loss: 0.571935772895813
Validation loss: 1.8832949643493981

Epoch: 6| Step: 7
Training loss: 0.5102808475494385
Validation loss: 1.876397914783929

Epoch: 6| Step: 8
Training loss: 1.1635146141052246
Validation loss: 1.9022752892586492

Epoch: 6| Step: 9
Training loss: 0.7261941432952881
Validation loss: 1.9106538603382726

Epoch: 6| Step: 10
Training loss: 0.9275400638580322
Validation loss: 1.9286048425141202

Epoch: 6| Step: 11
Training loss: 0.8233168125152588
Validation loss: 1.9844862376489947

Epoch: 6| Step: 12
Training loss: 1.2578370571136475
Validation loss: 1.9979542916820896

Epoch: 6| Step: 13
Training loss: 0.8507068157196045
Validation loss: 1.9707244685901109

Epoch: 274| Step: 0
Training loss: 0.42692965269088745
Validation loss: 1.959850590716126

Epoch: 6| Step: 1
Training loss: 0.5586260557174683
Validation loss: 1.9445029061327699

Epoch: 6| Step: 2
Training loss: 1.135784387588501
Validation loss: 1.9383265203045261

Epoch: 6| Step: 3
Training loss: 0.993014931678772
Validation loss: 1.9348579350338186

Epoch: 6| Step: 4
Training loss: 0.7038218975067139
Validation loss: 1.9366123458390594

Epoch: 6| Step: 5
Training loss: 0.4572300314903259
Validation loss: 1.92752545110641

Epoch: 6| Step: 6
Training loss: 1.0986934900283813
Validation loss: 1.9172092817162956

Epoch: 6| Step: 7
Training loss: 0.7813929319381714
Validation loss: 1.9186065619991672

Epoch: 6| Step: 8
Training loss: 1.0776393413543701
Validation loss: 1.9132190135217482

Epoch: 6| Step: 9
Training loss: 1.0654605627059937
Validation loss: 1.9440050791668635

Epoch: 6| Step: 10
Training loss: 0.6834483742713928
Validation loss: 1.9128614856350807

Epoch: 6| Step: 11
Training loss: 0.8124544620513916
Validation loss: 1.9215766127391527

Epoch: 6| Step: 12
Training loss: 0.7225335836410522
Validation loss: 1.9445715271016604

Epoch: 6| Step: 13
Training loss: 0.4597441256046295
Validation loss: 1.9509839511686755

Epoch: 275| Step: 0
Training loss: 1.0577547550201416
Validation loss: 1.9714485035147717

Epoch: 6| Step: 1
Training loss: 1.1251156330108643
Validation loss: 1.9904006437588764

Epoch: 6| Step: 2
Training loss: 0.6340667605400085
Validation loss: 1.97459061684147

Epoch: 6| Step: 3
Training loss: 0.9253326654434204
Validation loss: 1.9645133223584903

Epoch: 6| Step: 4
Training loss: 0.5340373516082764
Validation loss: 1.929557243982951

Epoch: 6| Step: 5
Training loss: 0.5244581699371338
Validation loss: 1.9163137071876115

Epoch: 6| Step: 6
Training loss: 0.6889380216598511
Validation loss: 1.9260573976783342

Epoch: 6| Step: 7
Training loss: 0.5566537380218506
Validation loss: 1.917153989115069

Epoch: 6| Step: 8
Training loss: 0.7635973691940308
Validation loss: 1.942835061780868

Epoch: 6| Step: 9
Training loss: 1.4251059293746948
Validation loss: 1.9626751253681798

Epoch: 6| Step: 10
Training loss: 0.6657240390777588
Validation loss: 1.9496012733828636

Epoch: 6| Step: 11
Training loss: 0.64532870054245
Validation loss: 1.973328859575333

Epoch: 6| Step: 12
Training loss: 0.7986299991607666
Validation loss: 1.9498315293301818

Epoch: 6| Step: 13
Training loss: 0.4819256365299225
Validation loss: 1.9420510812472271

Epoch: 276| Step: 0
Training loss: 0.524592399597168
Validation loss: 1.9054475740719867

Epoch: 6| Step: 1
Training loss: 0.5712697505950928
Validation loss: 1.8885469141826834

Epoch: 6| Step: 2
Training loss: 1.008181095123291
Validation loss: 1.899989176821965

Epoch: 6| Step: 3
Training loss: 0.3969714641571045
Validation loss: 1.9016908907121228

Epoch: 6| Step: 4
Training loss: 0.6632592678070068
Validation loss: 1.9014934903831893

Epoch: 6| Step: 5
Training loss: 0.8017873167991638
Validation loss: 1.9223136440400155

Epoch: 6| Step: 6
Training loss: 0.9619685411453247
Validation loss: 1.952748998518913

Epoch: 6| Step: 7
Training loss: 0.7230669260025024
Validation loss: 1.8905679025957662

Epoch: 6| Step: 8
Training loss: 1.0906425714492798
Validation loss: 1.9282572307894308

Epoch: 6| Step: 9
Training loss: 0.7107312679290771
Validation loss: 1.9241199339589765

Epoch: 6| Step: 10
Training loss: 0.6909067630767822
Validation loss: 1.9239627392061296

Epoch: 6| Step: 11
Training loss: 1.0572377443313599
Validation loss: 1.9458029295808525

Epoch: 6| Step: 12
Training loss: 0.6151974201202393
Validation loss: 1.9044053836535382

Epoch: 6| Step: 13
Training loss: 0.7512289881706238
Validation loss: 1.9412390583304948

Epoch: 277| Step: 0
Training loss: 1.0068882703781128
Validation loss: 1.92914455680437

Epoch: 6| Step: 1
Training loss: 0.9723145365715027
Validation loss: 1.9487419589873283

Epoch: 6| Step: 2
Training loss: 0.5188073515892029
Validation loss: 1.9143934557514806

Epoch: 6| Step: 3
Training loss: 1.1545246839523315
Validation loss: 1.8915182787884948

Epoch: 6| Step: 4
Training loss: 0.8779247403144836
Validation loss: 1.8625051295885475

Epoch: 6| Step: 5
Training loss: 0.561587929725647
Validation loss: 1.8490808202374367

Epoch: 6| Step: 6
Training loss: 0.685407280921936
Validation loss: 1.8410528180419758

Epoch: 6| Step: 7
Training loss: 0.7798423171043396
Validation loss: 1.8456887224669098

Epoch: 6| Step: 8
Training loss: 0.6643955111503601
Validation loss: 1.807937737434141

Epoch: 6| Step: 9
Training loss: 0.3264569342136383
Validation loss: 1.8501290762296287

Epoch: 6| Step: 10
Training loss: 0.7052338719367981
Validation loss: 1.8798515027569187

Epoch: 6| Step: 11
Training loss: 0.8804188370704651
Validation loss: 1.9183924672424153

Epoch: 6| Step: 12
Training loss: 0.5180598497390747
Validation loss: 1.933941097669704

Epoch: 6| Step: 13
Training loss: 0.979839026927948
Validation loss: 1.944046353781095

Epoch: 278| Step: 0
Training loss: 0.5872333645820618
Validation loss: 1.9701821752773818

Epoch: 6| Step: 1
Training loss: 1.0157363414764404
Validation loss: 1.9767049922738025

Epoch: 6| Step: 2
Training loss: 0.5353978872299194
Validation loss: 1.982549262303178

Epoch: 6| Step: 3
Training loss: 0.3820831775665283
Validation loss: 1.9754053982355262

Epoch: 6| Step: 4
Training loss: 0.6215035915374756
Validation loss: 1.9611748803046443

Epoch: 6| Step: 5
Training loss: 1.0499768257141113
Validation loss: 1.9708475143678728

Epoch: 6| Step: 6
Training loss: 0.8121374249458313
Validation loss: 1.948325317393067

Epoch: 6| Step: 7
Training loss: 0.6312792301177979
Validation loss: 1.8813558470818303

Epoch: 6| Step: 8
Training loss: 0.869442343711853
Validation loss: 1.886084601443301

Epoch: 6| Step: 9
Training loss: 0.7440950274467468
Validation loss: 1.8952831516983688

Epoch: 6| Step: 10
Training loss: 0.824677586555481
Validation loss: 1.8995313413681523

Epoch: 6| Step: 11
Training loss: 0.49005091190338135
Validation loss: 1.902692360262717

Epoch: 6| Step: 12
Training loss: 1.0932307243347168
Validation loss: 1.9329869772798272

Epoch: 6| Step: 13
Training loss: 0.3925805389881134
Validation loss: 1.8938349139305852

Epoch: 279| Step: 0
Training loss: 0.8174952864646912
Validation loss: 1.9324859931904783

Epoch: 6| Step: 1
Training loss: 0.46462956070899963
Validation loss: 1.9221555340674616

Epoch: 6| Step: 2
Training loss: 0.8147488236427307
Validation loss: 1.9341537132058093

Epoch: 6| Step: 3
Training loss: 0.8794127702713013
Validation loss: 1.9612552004475747

Epoch: 6| Step: 4
Training loss: 0.91124427318573
Validation loss: 1.9824511658760808

Epoch: 6| Step: 5
Training loss: 1.2508947849273682
Validation loss: 1.9580061089607976

Epoch: 6| Step: 6
Training loss: 0.5978639125823975
Validation loss: 1.963248933515241

Epoch: 6| Step: 7
Training loss: 0.9371919631958008
Validation loss: 1.9455329397673249

Epoch: 6| Step: 8
Training loss: 0.6003702282905579
Validation loss: 1.9405669114922965

Epoch: 6| Step: 9
Training loss: 0.7147520780563354
Validation loss: 1.897744963246007

Epoch: 6| Step: 10
Training loss: 0.7302032709121704
Validation loss: 1.874121537772558

Epoch: 6| Step: 11
Training loss: 0.6456847190856934
Validation loss: 1.8796708083921863

Epoch: 6| Step: 12
Training loss: 0.4984040856361389
Validation loss: 1.8186235761129728

Epoch: 6| Step: 13
Training loss: 0.6128098964691162
Validation loss: 1.8181919000482047

Epoch: 280| Step: 0
Training loss: 1.06699800491333
Validation loss: 1.8215614390629593

Epoch: 6| Step: 1
Training loss: 0.3655714988708496
Validation loss: 1.849460373642624

Epoch: 6| Step: 2
Training loss: 0.8666086196899414
Validation loss: 1.914547574135565

Epoch: 6| Step: 3
Training loss: 0.6097095012664795
Validation loss: 1.8965454678381644

Epoch: 6| Step: 4
Training loss: 0.7026787996292114
Validation loss: 1.956074801824426

Epoch: 6| Step: 5
Training loss: 0.9684978723526001
Validation loss: 1.9577471492111043

Epoch: 6| Step: 6
Training loss: 0.8151103258132935
Validation loss: 1.9617756592330111

Epoch: 6| Step: 7
Training loss: 0.660216748714447
Validation loss: 1.9635498241711689

Epoch: 6| Step: 8
Training loss: 0.6823426485061646
Validation loss: 1.966599182416034

Epoch: 6| Step: 9
Training loss: 0.8783180713653564
Validation loss: 2.007882131043301

Epoch: 6| Step: 10
Training loss: 0.8198347091674805
Validation loss: 2.0032376691859257

Epoch: 6| Step: 11
Training loss: 0.9422191381454468
Validation loss: 1.9821168594462897

Epoch: 6| Step: 12
Training loss: 0.47667455673217773
Validation loss: 1.907365014476161

Epoch: 6| Step: 13
Training loss: 1.292423129081726
Validation loss: 1.9328087978465582

Epoch: 281| Step: 0
Training loss: 0.9156165719032288
Validation loss: 1.9018665257320608

Epoch: 6| Step: 1
Training loss: 0.5356406569480896
Validation loss: 1.8655859372949088

Epoch: 6| Step: 2
Training loss: 0.5482781529426575
Validation loss: 1.8759743526417723

Epoch: 6| Step: 3
Training loss: 0.737587034702301
Validation loss: 1.9591334904393842

Epoch: 6| Step: 4
Training loss: 0.4934324324131012
Validation loss: 1.974737544213572

Epoch: 6| Step: 5
Training loss: 0.9638618230819702
Validation loss: 2.0009724786204677

Epoch: 6| Step: 6
Training loss: 0.802459180355072
Validation loss: 2.0245845292204168

Epoch: 6| Step: 7
Training loss: 0.9097145795822144
Validation loss: 2.0521784892646213

Epoch: 6| Step: 8
Training loss: 0.7682316899299622
Validation loss: 2.0587465096545476

Epoch: 6| Step: 9
Training loss: 0.9402217864990234
Validation loss: 2.054377730174731

Epoch: 6| Step: 10
Training loss: 1.0267693996429443
Validation loss: 2.0255080781957155

Epoch: 6| Step: 11
Training loss: 1.0897878408432007
Validation loss: 1.9922984671849076

Epoch: 6| Step: 12
Training loss: 1.006212830543518
Validation loss: 1.9756024922094038

Epoch: 6| Step: 13
Training loss: 0.8062934279441833
Validation loss: 1.9333264276545534

Epoch: 282| Step: 0
Training loss: 0.5005680918693542
Validation loss: 1.8913970506319435

Epoch: 6| Step: 1
Training loss: 1.0967059135437012
Validation loss: 1.8545594356393302

Epoch: 6| Step: 2
Training loss: 0.6397038102149963
Validation loss: 1.8430359927556847

Epoch: 6| Step: 3
Training loss: 0.897903561592102
Validation loss: 1.8373039589133313

Epoch: 6| Step: 4
Training loss: 1.001643419265747
Validation loss: 1.8729560964850969

Epoch: 6| Step: 5
Training loss: 0.868199348449707
Validation loss: 1.8819298359655565

Epoch: 6| Step: 6
Training loss: 0.7928918600082397
Validation loss: 1.8811031092879593

Epoch: 6| Step: 7
Training loss: 0.5585472583770752
Validation loss: 1.8801567631383096

Epoch: 6| Step: 8
Training loss: 0.537544310092926
Validation loss: 1.8982593718395437

Epoch: 6| Step: 9
Training loss: 0.4650886058807373
Validation loss: 1.8970710282684655

Epoch: 6| Step: 10
Training loss: 0.7350656390190125
Validation loss: 1.9251521736062982

Epoch: 6| Step: 11
Training loss: 0.6858690977096558
Validation loss: 1.9496009337004794

Epoch: 6| Step: 12
Training loss: 0.915732204914093
Validation loss: 1.9497863938731532

Epoch: 6| Step: 13
Training loss: 0.7347864508628845
Validation loss: 1.9445050429272395

Epoch: 283| Step: 0
Training loss: 0.6294363737106323
Validation loss: 1.943476979450513

Epoch: 6| Step: 1
Training loss: 0.6504017114639282
Validation loss: 1.912390580741308

Epoch: 6| Step: 2
Training loss: 0.4818280041217804
Validation loss: 1.9169545506918302

Epoch: 6| Step: 3
Training loss: 0.6437000632286072
Validation loss: 1.9069644892087547

Epoch: 6| Step: 4
Training loss: 0.7161321640014648
Validation loss: 1.9224951562061106

Epoch: 6| Step: 5
Training loss: 1.0024651288986206
Validation loss: 1.9235857199597102

Epoch: 6| Step: 6
Training loss: 0.6811206340789795
Validation loss: 1.8930068900508266

Epoch: 6| Step: 7
Training loss: 0.41087865829467773
Validation loss: 1.9012932251858454

Epoch: 6| Step: 8
Training loss: 0.9900500178337097
Validation loss: 1.917477071926158

Epoch: 6| Step: 9
Training loss: 0.7711797952651978
Validation loss: 1.9064541221946798

Epoch: 6| Step: 10
Training loss: 0.5579899549484253
Validation loss: 1.9725681440804594

Epoch: 6| Step: 11
Training loss: 0.9319581389427185
Validation loss: 1.9689155368394748

Epoch: 6| Step: 12
Training loss: 0.9928280711174011
Validation loss: 1.9596409874577676

Epoch: 6| Step: 13
Training loss: 0.6243683695793152
Validation loss: 1.9348521488969044

Epoch: 284| Step: 0
Training loss: 0.7272064685821533
Validation loss: 1.9177452851367254

Epoch: 6| Step: 1
Training loss: 0.7249975800514221
Validation loss: 1.9037143517565984

Epoch: 6| Step: 2
Training loss: 0.6598413586616516
Validation loss: 1.9030917588100638

Epoch: 6| Step: 3
Training loss: 0.5691426396369934
Validation loss: 1.9094506091968988

Epoch: 6| Step: 4
Training loss: 0.6709418892860413
Validation loss: 1.8948162960749801

Epoch: 6| Step: 5
Training loss: 0.4376799464225769
Validation loss: 1.893433650334676

Epoch: 6| Step: 6
Training loss: 0.7199125289916992
Validation loss: 1.9013248643567484

Epoch: 6| Step: 7
Training loss: 0.7025424838066101
Validation loss: 1.9004853310123566

Epoch: 6| Step: 8
Training loss: 0.7069072127342224
Validation loss: 1.9223232333378126

Epoch: 6| Step: 9
Training loss: 1.0686672925949097
Validation loss: 1.9095102587053854

Epoch: 6| Step: 10
Training loss: 0.917986273765564
Validation loss: 1.9204294771276496

Epoch: 6| Step: 11
Training loss: 0.47452035546302795
Validation loss: 1.8807006625718967

Epoch: 6| Step: 12
Training loss: 0.8168361186981201
Validation loss: 1.8960338946311706

Epoch: 6| Step: 13
Training loss: 0.557860791683197
Validation loss: 1.8696776551585044

Epoch: 285| Step: 0
Training loss: 0.7565252780914307
Validation loss: 1.859833199490783

Epoch: 6| Step: 1
Training loss: 0.8544730544090271
Validation loss: 1.858709926246315

Epoch: 6| Step: 2
Training loss: 0.6618918180465698
Validation loss: 1.8411892780693628

Epoch: 6| Step: 3
Training loss: 1.0404187440872192
Validation loss: 1.8713121926912697

Epoch: 6| Step: 4
Training loss: 0.6619787812232971
Validation loss: 1.8779299643731886

Epoch: 6| Step: 5
Training loss: 0.8262853026390076
Validation loss: 1.8622283679182812

Epoch: 6| Step: 6
Training loss: 0.9829505681991577
Validation loss: 1.8289672713125906

Epoch: 6| Step: 7
Training loss: 0.641732931137085
Validation loss: 1.8442173260514454

Epoch: 6| Step: 8
Training loss: 0.772845447063446
Validation loss: 1.8441181567407423

Epoch: 6| Step: 9
Training loss: 0.3774210214614868
Validation loss: 1.8671921376259095

Epoch: 6| Step: 10
Training loss: 0.398210346698761
Validation loss: 1.8896861512173888

Epoch: 6| Step: 11
Training loss: 0.5983917117118835
Validation loss: 1.9073146645740797

Epoch: 6| Step: 12
Training loss: 0.5650128126144409
Validation loss: 1.9170717462416618

Epoch: 6| Step: 13
Training loss: 0.5908650159835815
Validation loss: 1.9069867326367287

Epoch: 286| Step: 0
Training loss: 0.36901429295539856
Validation loss: 1.9412613222675938

Epoch: 6| Step: 1
Training loss: 0.763095498085022
Validation loss: 1.913657429397747

Epoch: 6| Step: 2
Training loss: 0.5620425939559937
Validation loss: 1.9584356456674554

Epoch: 6| Step: 3
Training loss: 0.9890629649162292
Validation loss: 1.9559122041989399

Epoch: 6| Step: 4
Training loss: 0.6203681230545044
Validation loss: 1.9539399236761115

Epoch: 6| Step: 5
Training loss: 1.0197843313217163
Validation loss: 1.9034138033466954

Epoch: 6| Step: 6
Training loss: 0.4726184010505676
Validation loss: 1.9038318639160485

Epoch: 6| Step: 7
Training loss: 0.8951821327209473
Validation loss: 1.8513959582133959

Epoch: 6| Step: 8
Training loss: 0.7491700053215027
Validation loss: 1.852076070283049

Epoch: 6| Step: 9
Training loss: 0.39485567808151245
Validation loss: 1.843030575783022

Epoch: 6| Step: 10
Training loss: 0.5373004674911499
Validation loss: 1.844673450275134

Epoch: 6| Step: 11
Training loss: 0.7715257406234741
Validation loss: 1.84840738901528

Epoch: 6| Step: 12
Training loss: 0.39310845732688904
Validation loss: 1.9006172354503343

Epoch: 6| Step: 13
Training loss: 1.181520700454712
Validation loss: 1.882632932355327

Epoch: 287| Step: 0
Training loss: 0.7686400413513184
Validation loss: 1.926111505877587

Epoch: 6| Step: 1
Training loss: 1.3530802726745605
Validation loss: 1.92037848887905

Epoch: 6| Step: 2
Training loss: 0.7625210285186768
Validation loss: 1.9129634852050452

Epoch: 6| Step: 3
Training loss: 0.6826454997062683
Validation loss: 1.9136505755045081

Epoch: 6| Step: 4
Training loss: 0.8131977915763855
Validation loss: 1.8849997110264276

Epoch: 6| Step: 5
Training loss: 0.7073925733566284
Validation loss: 1.888598035740596

Epoch: 6| Step: 6
Training loss: 0.6741647720336914
Validation loss: 1.8433306512012277

Epoch: 6| Step: 7
Training loss: 0.7702363729476929
Validation loss: 1.8045487621779084

Epoch: 6| Step: 8
Training loss: 0.5828046798706055
Validation loss: 1.8382049247782717

Epoch: 6| Step: 9
Training loss: 1.0263563394546509
Validation loss: 1.8103318906599475

Epoch: 6| Step: 10
Training loss: 0.5758755207061768
Validation loss: 1.8368364136706117

Epoch: 6| Step: 11
Training loss: 0.343829870223999
Validation loss: 1.8473018997459

Epoch: 6| Step: 12
Training loss: 0.44902288913726807
Validation loss: 1.849013238824824

Epoch: 6| Step: 13
Training loss: 0.41795724630355835
Validation loss: 1.8564439550522835

Epoch: 288| Step: 0
Training loss: 0.44049903750419617
Validation loss: 1.8834509413729432

Epoch: 6| Step: 1
Training loss: 0.5500855445861816
Validation loss: 1.8702091965624081

Epoch: 6| Step: 2
Training loss: 0.39976736903190613
Validation loss: 1.868633403572985

Epoch: 6| Step: 3
Training loss: 0.4144536852836609
Validation loss: 1.8600957560282882

Epoch: 6| Step: 4
Training loss: 0.6487953662872314
Validation loss: 1.8595823075181694

Epoch: 6| Step: 5
Training loss: 0.967552900314331
Validation loss: 1.8879868753494755

Epoch: 6| Step: 6
Training loss: 0.8528242111206055
Validation loss: 1.9111459588491788

Epoch: 6| Step: 7
Training loss: 0.7089522480964661
Validation loss: 1.9587973676702028

Epoch: 6| Step: 8
Training loss: 0.4550427794456482
Validation loss: 1.919850085371284

Epoch: 6| Step: 9
Training loss: 0.8117719888687134
Validation loss: 1.9267663635233396

Epoch: 6| Step: 10
Training loss: 1.021661400794983
Validation loss: 1.9148564351502286

Epoch: 6| Step: 11
Training loss: 0.9492541551589966
Validation loss: 1.883874882933914

Epoch: 6| Step: 12
Training loss: 0.5156594514846802
Validation loss: 1.908257886927615

Epoch: 6| Step: 13
Training loss: 0.6493386030197144
Validation loss: 1.9008240084494314

Epoch: 289| Step: 0
Training loss: 0.5643554925918579
Validation loss: 1.8887979112645632

Epoch: 6| Step: 1
Training loss: 0.7430744171142578
Validation loss: 1.8755479794676586

Epoch: 6| Step: 2
Training loss: 0.6428025364875793
Validation loss: 1.8645901397992206

Epoch: 6| Step: 3
Training loss: 0.6102359294891357
Validation loss: 1.8662694705429899

Epoch: 6| Step: 4
Training loss: 0.8997323513031006
Validation loss: 1.8726206402624808

Epoch: 6| Step: 5
Training loss: 0.4681079387664795
Validation loss: 1.866127174387696

Epoch: 6| Step: 6
Training loss: 0.8947498798370361
Validation loss: 1.8502568506425427

Epoch: 6| Step: 7
Training loss: 0.4772561490535736
Validation loss: 1.8641237289674821

Epoch: 6| Step: 8
Training loss: 0.6219473481178284
Validation loss: 1.8325347297935075

Epoch: 6| Step: 9
Training loss: 0.2998747229576111
Validation loss: 1.817199509630921

Epoch: 6| Step: 10
Training loss: 1.0868947505950928
Validation loss: 1.8581973596285748

Epoch: 6| Step: 11
Training loss: 0.6509805917739868
Validation loss: 1.8717291637133526

Epoch: 6| Step: 12
Training loss: 0.4590328335762024
Validation loss: 1.870434194482783

Epoch: 6| Step: 13
Training loss: 0.4645673930644989
Validation loss: 1.8934330555700487

Epoch: 290| Step: 0
Training loss: 0.49384135007858276
Validation loss: 1.9112480378920031

Epoch: 6| Step: 1
Training loss: 0.7813940048217773
Validation loss: 1.943512632000831

Epoch: 6| Step: 2
Training loss: 0.5196800827980042
Validation loss: 1.9704893917165778

Epoch: 6| Step: 3
Training loss: 0.34756213426589966
Validation loss: 1.9638202908218547

Epoch: 6| Step: 4
Training loss: 0.7239896059036255
Validation loss: 1.9144500224821028

Epoch: 6| Step: 5
Training loss: 0.5324611067771912
Validation loss: 1.9093373270444973

Epoch: 6| Step: 6
Training loss: 0.7655501961708069
Validation loss: 1.9152246111182756

Epoch: 6| Step: 7
Training loss: 0.5778165459632874
Validation loss: 1.9034031975653865

Epoch: 6| Step: 8
Training loss: 1.3612966537475586
Validation loss: 1.913182238096832

Epoch: 6| Step: 9
Training loss: 0.6418677568435669
Validation loss: 1.9238731297113563

Epoch: 6| Step: 10
Training loss: 0.5470296144485474
Validation loss: 1.9038607894733388

Epoch: 6| Step: 11
Training loss: 0.6879695057868958
Validation loss: 1.9005169419832126

Epoch: 6| Step: 12
Training loss: 0.4848572015762329
Validation loss: 1.906736969947815

Epoch: 6| Step: 13
Training loss: 0.6466953754425049
Validation loss: 1.871480994327094

Epoch: 291| Step: 0
Training loss: 0.4197100102901459
Validation loss: 1.8912486440391951

Epoch: 6| Step: 1
Training loss: 0.7825758457183838
Validation loss: 1.9093668486482354

Epoch: 6| Step: 2
Training loss: 0.7061010599136353
Validation loss: 1.9070964795286938

Epoch: 6| Step: 3
Training loss: 1.050007700920105
Validation loss: 1.8765042225519817

Epoch: 6| Step: 4
Training loss: 0.7608870267868042
Validation loss: 1.8987010730210172

Epoch: 6| Step: 5
Training loss: 0.6732170581817627
Validation loss: 1.8694591342761953

Epoch: 6| Step: 6
Training loss: 0.4640464782714844
Validation loss: 1.8580488158810524

Epoch: 6| Step: 7
Training loss: 0.4629926085472107
Validation loss: 1.8466004940771288

Epoch: 6| Step: 8
Training loss: 0.47547879815101624
Validation loss: 1.8391539409596434

Epoch: 6| Step: 9
Training loss: 0.740632176399231
Validation loss: 1.8394103178413965

Epoch: 6| Step: 10
Training loss: 0.4660733640193939
Validation loss: 1.8578004631944882

Epoch: 6| Step: 11
Training loss: 0.6690168976783752
Validation loss: 1.8375363888279084

Epoch: 6| Step: 12
Training loss: 0.401335746049881
Validation loss: 1.8524023717449558

Epoch: 6| Step: 13
Training loss: 0.7359189987182617
Validation loss: 1.8354111807320708

Epoch: 292| Step: 0
Training loss: 0.4046320915222168
Validation loss: 1.8201193828736582

Epoch: 6| Step: 1
Training loss: 0.7516307830810547
Validation loss: 1.8032562066149969

Epoch: 6| Step: 2
Training loss: 0.5746259093284607
Validation loss: 1.8053877712577902

Epoch: 6| Step: 3
Training loss: 0.5911645889282227
Validation loss: 1.8225133957401398

Epoch: 6| Step: 4
Training loss: 0.5064603090286255
Validation loss: 1.7994183878744803

Epoch: 6| Step: 5
Training loss: 0.45339226722717285
Validation loss: 1.83038071919513

Epoch: 6| Step: 6
Training loss: 0.6513949036598206
Validation loss: 1.8318463743373912

Epoch: 6| Step: 7
Training loss: 0.28296077251434326
Validation loss: 1.8297569328738796

Epoch: 6| Step: 8
Training loss: 1.1421828269958496
Validation loss: 1.8190562737885343

Epoch: 6| Step: 9
Training loss: 0.6301060914993286
Validation loss: 1.8137774698195919

Epoch: 6| Step: 10
Training loss: 0.7207168340682983
Validation loss: 1.8259445941576393

Epoch: 6| Step: 11
Training loss: 0.7751864790916443
Validation loss: 1.8227077863549674

Epoch: 6| Step: 12
Training loss: 0.6534472107887268
Validation loss: 1.8189068814759612

Epoch: 6| Step: 13
Training loss: 0.4506188631057739
Validation loss: 1.8164247107762161

Epoch: 293| Step: 0
Training loss: 0.3546913266181946
Validation loss: 1.8094542334156651

Epoch: 6| Step: 1
Training loss: 0.40887194871902466
Validation loss: 1.8464474460130096

Epoch: 6| Step: 2
Training loss: 0.47900983691215515
Validation loss: 1.8805126233767437

Epoch: 6| Step: 3
Training loss: 0.6286587715148926
Validation loss: 1.911038105205823

Epoch: 6| Step: 4
Training loss: 0.5375001430511475
Validation loss: 1.9126202291057957

Epoch: 6| Step: 5
Training loss: 0.4915085732936859
Validation loss: 1.906786628948745

Epoch: 6| Step: 6
Training loss: 1.3345147371292114
Validation loss: 1.9097696055648148

Epoch: 6| Step: 7
Training loss: 0.7580360770225525
Validation loss: 1.8795148852050945

Epoch: 6| Step: 8
Training loss: 0.6545315980911255
Validation loss: 1.8589804595516575

Epoch: 6| Step: 9
Training loss: 0.3790038824081421
Validation loss: 1.81694955595078

Epoch: 6| Step: 10
Training loss: 0.5541843175888062
Validation loss: 1.8459338988027265

Epoch: 6| Step: 11
Training loss: 0.698442816734314
Validation loss: 1.8357861811114895

Epoch: 6| Step: 12
Training loss: 0.569949746131897
Validation loss: 1.843439858446839

Epoch: 6| Step: 13
Training loss: 0.7962542176246643
Validation loss: 1.8552398348367343

Epoch: 294| Step: 0
Training loss: 0.37046194076538086
Validation loss: 1.8721262575477682

Epoch: 6| Step: 1
Training loss: 0.6820074319839478
Validation loss: 1.9123833692202004

Epoch: 6| Step: 2
Training loss: 0.6421629786491394
Validation loss: 1.8562719104110554

Epoch: 6| Step: 3
Training loss: 0.8066166639328003
Validation loss: 1.8516244785760039

Epoch: 6| Step: 4
Training loss: 0.699741780757904
Validation loss: 1.8209814230600994

Epoch: 6| Step: 5
Training loss: 0.59098881483078
Validation loss: 1.8444919765636485

Epoch: 6| Step: 6
Training loss: 0.6578953266143799
Validation loss: 1.8302453025694816

Epoch: 6| Step: 7
Training loss: 0.434065580368042
Validation loss: 1.8241981742202595

Epoch: 6| Step: 8
Training loss: 0.3306134343147278
Validation loss: 1.804953408497636

Epoch: 6| Step: 9
Training loss: 0.9136501550674438
Validation loss: 1.8753589660890642

Epoch: 6| Step: 10
Training loss: 0.2908426523208618
Validation loss: 1.8807093110135806

Epoch: 6| Step: 11
Training loss: 0.6398801803588867
Validation loss: 1.9104342665723575

Epoch: 6| Step: 12
Training loss: 0.5578968524932861
Validation loss: 1.9041173535008584

Epoch: 6| Step: 13
Training loss: 0.957560658454895
Validation loss: 1.9182495993952597

Epoch: 295| Step: 0
Training loss: 0.4087800681591034
Validation loss: 1.9229002268083635

Epoch: 6| Step: 1
Training loss: 0.6451501846313477
Validation loss: 1.8692766748448855

Epoch: 6| Step: 2
Training loss: 0.46531912684440613
Validation loss: 1.8689057186085691

Epoch: 6| Step: 3
Training loss: 0.910537600517273
Validation loss: 1.8186196140063706

Epoch: 6| Step: 4
Training loss: 0.5747541189193726
Validation loss: 1.83126800803728

Epoch: 6| Step: 5
Training loss: 0.6185692548751831
Validation loss: 1.848435963353803

Epoch: 6| Step: 6
Training loss: 0.6353803277015686
Validation loss: 1.8272223523868028

Epoch: 6| Step: 7
Training loss: 0.7528423070907593
Validation loss: 1.8372069122970744

Epoch: 6| Step: 8
Training loss: 0.499847948551178
Validation loss: 1.832601349840882

Epoch: 6| Step: 9
Training loss: 0.770094096660614
Validation loss: 1.8766506692414642

Epoch: 6| Step: 10
Training loss: 0.7160241007804871
Validation loss: 1.8835301835049865

Epoch: 6| Step: 11
Training loss: 0.7962678074836731
Validation loss: 1.9342634972705637

Epoch: 6| Step: 12
Training loss: 0.6059408783912659
Validation loss: 1.8838411992596042

Epoch: 6| Step: 13
Training loss: 0.14489002525806427
Validation loss: 1.8841241841675134

Epoch: 296| Step: 0
Training loss: 0.502852201461792
Validation loss: 1.873044103704473

Epoch: 6| Step: 1
Training loss: 0.28473392128944397
Validation loss: 1.8745527241819648

Epoch: 6| Step: 2
Training loss: 0.45252540707588196
Validation loss: 1.8456458558318436

Epoch: 6| Step: 3
Training loss: 0.7898105382919312
Validation loss: 1.844735284005442

Epoch: 6| Step: 4
Training loss: 0.7550342679023743
Validation loss: 1.8278272241674445

Epoch: 6| Step: 5
Training loss: 0.49989086389541626
Validation loss: 1.8406489356871574

Epoch: 6| Step: 6
Training loss: 0.6363283395767212
Validation loss: 1.8242205471120856

Epoch: 6| Step: 7
Training loss: 0.58182692527771
Validation loss: 1.8251766504779938

Epoch: 6| Step: 8
Training loss: 0.698216438293457
Validation loss: 1.8211565658610354

Epoch: 6| Step: 9
Training loss: 0.8466790318489075
Validation loss: 1.8123287821328768

Epoch: 6| Step: 10
Training loss: 0.7035582065582275
Validation loss: 1.8678695591547156

Epoch: 6| Step: 11
Training loss: 0.5633962750434875
Validation loss: 1.8811926931463263

Epoch: 6| Step: 12
Training loss: 0.4968922436237335
Validation loss: 1.8749300279924948

Epoch: 6| Step: 13
Training loss: 0.6613712906837463
Validation loss: 1.8729340081573815

Epoch: 297| Step: 0
Training loss: 0.3765525817871094
Validation loss: 1.8553756129357122

Epoch: 6| Step: 1
Training loss: 0.44916024804115295
Validation loss: 1.8114319680839457

Epoch: 6| Step: 2
Training loss: 0.5515289902687073
Validation loss: 1.8173243820026357

Epoch: 6| Step: 3
Training loss: 0.5409361720085144
Validation loss: 1.7896017855213535

Epoch: 6| Step: 4
Training loss: 0.5476441383361816
Validation loss: 1.777953851607538

Epoch: 6| Step: 5
Training loss: 0.8412914276123047
Validation loss: 1.7856025259981874

Epoch: 6| Step: 6
Training loss: 0.852405846118927
Validation loss: 1.7761273102093769

Epoch: 6| Step: 7
Training loss: 0.842599093914032
Validation loss: 1.7708087095650293

Epoch: 6| Step: 8
Training loss: 0.5812727212905884
Validation loss: 1.7777251838355936

Epoch: 6| Step: 9
Training loss: 0.6453906297683716
Validation loss: 1.7962720163406865

Epoch: 6| Step: 10
Training loss: 0.6695938110351562
Validation loss: 1.8250531393994567

Epoch: 6| Step: 11
Training loss: 0.5292277336120605
Validation loss: 1.8410121740833405

Epoch: 6| Step: 12
Training loss: 0.6571075916290283
Validation loss: 1.8607779074740667

Epoch: 6| Step: 13
Training loss: 0.3670695722103119
Validation loss: 1.8905892167040097

Epoch: 298| Step: 0
Training loss: 0.6385622620582581
Validation loss: 1.884960638579502

Epoch: 6| Step: 1
Training loss: 0.5255643129348755
Validation loss: 1.8880695963418612

Epoch: 6| Step: 2
Training loss: 0.49414581060409546
Validation loss: 1.872702698553762

Epoch: 6| Step: 3
Training loss: 0.49713319540023804
Validation loss: 1.8472610391596311

Epoch: 6| Step: 4
Training loss: 0.4980449378490448
Validation loss: 1.8732893966859387

Epoch: 6| Step: 5
Training loss: 0.47846919298171997
Validation loss: 1.8300987905071628

Epoch: 6| Step: 6
Training loss: 0.4011799693107605
Validation loss: 1.7976367883784796

Epoch: 6| Step: 7
Training loss: 0.8379219770431519
Validation loss: 1.808714767938019

Epoch: 6| Step: 8
Training loss: 0.6724066734313965
Validation loss: 1.811676900873902

Epoch: 6| Step: 9
Training loss: 0.39920473098754883
Validation loss: 1.7981216035863405

Epoch: 6| Step: 10
Training loss: 0.7749332785606384
Validation loss: 1.8129265551925988

Epoch: 6| Step: 11
Training loss: 0.75037682056427
Validation loss: 1.8035099788378643

Epoch: 6| Step: 12
Training loss: 0.5345414876937866
Validation loss: 1.7813030417247484

Epoch: 6| Step: 13
Training loss: 0.6158771514892578
Validation loss: 1.8401039851609098

Epoch: 299| Step: 0
Training loss: 0.9469255805015564
Validation loss: 1.8353578223977038

Epoch: 6| Step: 1
Training loss: 0.45702260732650757
Validation loss: 1.851497801401282

Epoch: 6| Step: 2
Training loss: 0.5510828495025635
Validation loss: 1.8179642295324674

Epoch: 6| Step: 3
Training loss: 0.2920331358909607
Validation loss: 1.8687238577873475

Epoch: 6| Step: 4
Training loss: 0.6227384805679321
Validation loss: 1.8496314620458951

Epoch: 6| Step: 5
Training loss: 0.5118197202682495
Validation loss: 1.836598712910888

Epoch: 6| Step: 6
Training loss: 0.41518235206604004
Validation loss: 1.8559768687012375

Epoch: 6| Step: 7
Training loss: 0.45499876141548157
Validation loss: 1.8474125118665798

Epoch: 6| Step: 8
Training loss: 0.37443938851356506
Validation loss: 1.8564829185444822

Epoch: 6| Step: 9
Training loss: 0.667346715927124
Validation loss: 1.8491528444392706

Epoch: 6| Step: 10
Training loss: 0.5471365451812744
Validation loss: 1.8402975067015617

Epoch: 6| Step: 11
Training loss: 0.7554662823677063
Validation loss: 1.861465718156548

Epoch: 6| Step: 12
Training loss: 0.9379329085350037
Validation loss: 1.8444397552039034

Epoch: 6| Step: 13
Training loss: 0.3864850699901581
Validation loss: 1.850202392506343

Epoch: 300| Step: 0
Training loss: 0.12508314847946167
Validation loss: 1.8552148495951006

Epoch: 6| Step: 1
Training loss: 0.5155461430549622
Validation loss: 1.8547935755022111

Epoch: 6| Step: 2
Training loss: 0.5573980808258057
Validation loss: 1.8648240271434988

Epoch: 6| Step: 3
Training loss: 0.6150847673416138
Validation loss: 1.864673492729023

Epoch: 6| Step: 4
Training loss: 0.5827422142028809
Validation loss: 1.905990695440641

Epoch: 6| Step: 5
Training loss: 0.5354422330856323
Validation loss: 1.8631026027023152

Epoch: 6| Step: 6
Training loss: 0.7872030735015869
Validation loss: 1.8746572643197992

Epoch: 6| Step: 7
Training loss: 0.7352381944656372
Validation loss: 1.8831240848828388

Epoch: 6| Step: 8
Training loss: 0.5374749898910522
Validation loss: 1.8890052149372716

Epoch: 6| Step: 9
Training loss: 0.7715819478034973
Validation loss: 1.8564651704603625

Epoch: 6| Step: 10
Training loss: 0.6289023756980896
Validation loss: 1.8656157601264216

Epoch: 6| Step: 11
Training loss: 0.27471163868904114
Validation loss: 1.8629522861972931

Epoch: 6| Step: 12
Training loss: 0.4160088002681732
Validation loss: 1.8528855475046302

Epoch: 6| Step: 13
Training loss: 1.1069676876068115
Validation loss: 1.8612375413217852

Epoch: 301| Step: 0
Training loss: 0.5360656976699829
Validation loss: 1.8589365084966023

Epoch: 6| Step: 1
Training loss: 0.38759928941726685
Validation loss: 1.8323051724382626

Epoch: 6| Step: 2
Training loss: 0.45599478483200073
Validation loss: 1.8158044481790194

Epoch: 6| Step: 3
Training loss: 0.4957248270511627
Validation loss: 1.8511117081488333

Epoch: 6| Step: 4
Training loss: 0.8683252930641174
Validation loss: 1.8315071598176034

Epoch: 6| Step: 5
Training loss: 0.47181665897369385
Validation loss: 1.8238959517530215

Epoch: 6| Step: 6
Training loss: 0.6779347658157349
Validation loss: 1.8301120535019906

Epoch: 6| Step: 7
Training loss: 0.45087799429893494
Validation loss: 1.8091863150237708

Epoch: 6| Step: 8
Training loss: 0.8453245162963867
Validation loss: 1.8008912096741378

Epoch: 6| Step: 9
Training loss: 0.45930367708206177
Validation loss: 1.8222667696655437

Epoch: 6| Step: 10
Training loss: 0.40071284770965576
Validation loss: 1.8569926728484452

Epoch: 6| Step: 11
Training loss: 0.660306453704834
Validation loss: 1.862883283245948

Epoch: 6| Step: 12
Training loss: 0.5535316467285156
Validation loss: 1.8758269151051838

Epoch: 6| Step: 13
Training loss: 0.5430769920349121
Validation loss: 1.8446119575090305

Epoch: 302| Step: 0
Training loss: 0.5722908973693848
Validation loss: 1.8497061037248181

Epoch: 6| Step: 1
Training loss: 0.34809356927871704
Validation loss: 1.855450694279004

Epoch: 6| Step: 2
Training loss: 0.4358633756637573
Validation loss: 1.8560809320019138

Epoch: 6| Step: 3
Training loss: 0.5540832877159119
Validation loss: 1.8645419241279684

Epoch: 6| Step: 4
Training loss: 0.6816028952598572
Validation loss: 1.832156176208168

Epoch: 6| Step: 5
Training loss: 0.7504501342773438
Validation loss: 1.8334001648810603

Epoch: 6| Step: 6
Training loss: 0.5324355959892273
Validation loss: 1.8159628939884964

Epoch: 6| Step: 7
Training loss: 0.5185942053794861
Validation loss: 1.8259089351982198

Epoch: 6| Step: 8
Training loss: 0.523530125617981
Validation loss: 1.8293295239889493

Epoch: 6| Step: 9
Training loss: 0.9467165470123291
Validation loss: 1.8217152857011365

Epoch: 6| Step: 10
Training loss: 0.5191693305969238
Validation loss: 1.886626458937122

Epoch: 6| Step: 11
Training loss: 0.4145185947418213
Validation loss: 1.8611924814921554

Epoch: 6| Step: 12
Training loss: 0.2899166941642761
Validation loss: 1.8493741327716458

Epoch: 6| Step: 13
Training loss: 0.6052829027175903
Validation loss: 1.8429890422410862

Epoch: 303| Step: 0
Training loss: 0.6563441753387451
Validation loss: 1.8606801943112445

Epoch: 6| Step: 1
Training loss: 0.759339451789856
Validation loss: 1.828744396086662

Epoch: 6| Step: 2
Training loss: 0.7270763516426086
Validation loss: 1.838229698519553

Epoch: 6| Step: 3
Training loss: 0.5675996541976929
Validation loss: 1.8236883353161555

Epoch: 6| Step: 4
Training loss: 0.5514066219329834
Validation loss: 1.8324248380558465

Epoch: 6| Step: 5
Training loss: 0.5220871567726135
Validation loss: 1.832596331514338

Epoch: 6| Step: 6
Training loss: 0.6768098473548889
Validation loss: 1.8441015520403463

Epoch: 6| Step: 7
Training loss: 0.570420503616333
Validation loss: 1.8391246616199453

Epoch: 6| Step: 8
Training loss: 0.3651477098464966
Validation loss: 1.8567372355409848

Epoch: 6| Step: 9
Training loss: 0.5925552845001221
Validation loss: 1.865716253557513

Epoch: 6| Step: 10
Training loss: 0.6412456631660461
Validation loss: 1.8657890378787954

Epoch: 6| Step: 11
Training loss: 0.43312856554985046
Validation loss: 1.873269465661818

Epoch: 6| Step: 12
Training loss: 0.358090341091156
Validation loss: 1.8473200195579118

Epoch: 6| Step: 13
Training loss: 0.26283979415893555
Validation loss: 1.8346532262781614

Epoch: 304| Step: 0
Training loss: 0.4851212203502655
Validation loss: 1.806689090626214

Epoch: 6| Step: 1
Training loss: 0.6206396818161011
Validation loss: 1.8179120966183242

Epoch: 6| Step: 2
Training loss: 0.506618857383728
Validation loss: 1.8017222778771513

Epoch: 6| Step: 3
Training loss: 0.6006388664245605
Validation loss: 1.816901781225717

Epoch: 6| Step: 4
Training loss: 0.8998023271560669
Validation loss: 1.7814954250089583

Epoch: 6| Step: 5
Training loss: 0.48115015029907227
Validation loss: 1.8042593245865197

Epoch: 6| Step: 6
Training loss: 0.4953514635562897
Validation loss: 1.8470335916806293

Epoch: 6| Step: 7
Training loss: 0.48187944293022156
Validation loss: 1.8736217944852767

Epoch: 6| Step: 8
Training loss: 0.43533772230148315
Validation loss: 1.841755877258957

Epoch: 6| Step: 9
Training loss: 0.35820114612579346
Validation loss: 1.872700947587208

Epoch: 6| Step: 10
Training loss: 0.49884265661239624
Validation loss: 1.8478779664603613

Epoch: 6| Step: 11
Training loss: 0.8170932531356812
Validation loss: 1.8301557635748258

Epoch: 6| Step: 12
Training loss: 0.234308660030365
Validation loss: 1.8246450975377073

Epoch: 6| Step: 13
Training loss: 0.614248514175415
Validation loss: 1.8095529438346944

Epoch: 305| Step: 0
Training loss: 0.2260407954454422
Validation loss: 1.832709789276123

Epoch: 6| Step: 1
Training loss: 0.4056546688079834
Validation loss: 1.8517646366550076

Epoch: 6| Step: 2
Training loss: 0.5413698554039001
Validation loss: 1.828438057694384

Epoch: 6| Step: 3
Training loss: 0.48455068469047546
Validation loss: 1.8212839339369087

Epoch: 6| Step: 4
Training loss: 0.526128888130188
Validation loss: 1.8294402924917077

Epoch: 6| Step: 5
Training loss: 0.4253397583961487
Validation loss: 1.8339169281785206

Epoch: 6| Step: 6
Training loss: 0.5675541162490845
Validation loss: 1.8530008498058523

Epoch: 6| Step: 7
Training loss: 0.8972427845001221
Validation loss: 1.8184029697090067

Epoch: 6| Step: 8
Training loss: 0.43613681197166443
Validation loss: 1.8583431987352268

Epoch: 6| Step: 9
Training loss: 0.5546578764915466
Validation loss: 1.8186982421464817

Epoch: 6| Step: 10
Training loss: 0.7576358318328857
Validation loss: 1.8496882069495417

Epoch: 6| Step: 11
Training loss: 0.3778403699398041
Validation loss: 1.8266981173587102

Epoch: 6| Step: 12
Training loss: 0.4089469313621521
Validation loss: 1.8386775332112466

Epoch: 6| Step: 13
Training loss: 0.8127912878990173
Validation loss: 1.8495759707625195

Epoch: 306| Step: 0
Training loss: 0.4462210536003113
Validation loss: 1.8521907816651046

Epoch: 6| Step: 1
Training loss: 0.7141387462615967
Validation loss: 1.852042907027788

Epoch: 6| Step: 2
Training loss: 0.6221867203712463
Validation loss: 1.8423220701115106

Epoch: 6| Step: 3
Training loss: 0.5855327844619751
Validation loss: 1.8459238993224276

Epoch: 6| Step: 4
Training loss: 0.5400140285491943
Validation loss: 1.8665222634551346

Epoch: 6| Step: 5
Training loss: 0.44266974925994873
Validation loss: 1.8281566058435748

Epoch: 6| Step: 6
Training loss: 0.3442598879337311
Validation loss: 1.8282906957851943

Epoch: 6| Step: 7
Training loss: 0.5351245999336243
Validation loss: 1.816150511464765

Epoch: 6| Step: 8
Training loss: 0.2753518223762512
Validation loss: 1.8108177864423363

Epoch: 6| Step: 9
Training loss: 0.5563650131225586
Validation loss: 1.7946861354253625

Epoch: 6| Step: 10
Training loss: 0.5570526719093323
Validation loss: 1.7944678221979449

Epoch: 6| Step: 11
Training loss: 0.45711278915405273
Validation loss: 1.8001215201552196

Epoch: 6| Step: 12
Training loss: 0.5641550421714783
Validation loss: 1.7872920215770762

Epoch: 6| Step: 13
Training loss: 0.6259642243385315
Validation loss: 1.820228866351548

Epoch: 307| Step: 0
Training loss: 0.6058078408241272
Validation loss: 1.8067199696776688

Epoch: 6| Step: 1
Training loss: 0.646669864654541
Validation loss: 1.833047680957343

Epoch: 6| Step: 2
Training loss: 0.6398849487304688
Validation loss: 1.8277525799248808

Epoch: 6| Step: 3
Training loss: 0.41418540477752686
Validation loss: 1.8305671420148624

Epoch: 6| Step: 4
Training loss: 0.7842298150062561
Validation loss: 1.8233129824361494

Epoch: 6| Step: 5
Training loss: 0.5378667116165161
Validation loss: 1.8756635663329915

Epoch: 6| Step: 6
Training loss: 0.34182387590408325
Validation loss: 1.8772183208055393

Epoch: 6| Step: 7
Training loss: 0.3109215497970581
Validation loss: 1.9029409513678601

Epoch: 6| Step: 8
Training loss: 0.5149282813072205
Validation loss: 1.894680658976237

Epoch: 6| Step: 9
Training loss: 0.5975281596183777
Validation loss: 1.9110272289604269

Epoch: 6| Step: 10
Training loss: 0.5110788941383362
Validation loss: 1.9082264977116739

Epoch: 6| Step: 11
Training loss: 0.2903827428817749
Validation loss: 1.908322112534636

Epoch: 6| Step: 12
Training loss: 0.6569454073905945
Validation loss: 1.925740083058675

Epoch: 6| Step: 13
Training loss: 0.32053226232528687
Validation loss: 1.8780948500479422

Epoch: 308| Step: 0
Training loss: 0.8107995986938477
Validation loss: 1.8718853868463987

Epoch: 6| Step: 1
Training loss: 0.27958884835243225
Validation loss: 1.8738387400104153

Epoch: 6| Step: 2
Training loss: 0.29143428802490234
Validation loss: 1.9068550525173065

Epoch: 6| Step: 3
Training loss: 0.17890706658363342
Validation loss: 1.8603865997765654

Epoch: 6| Step: 4
Training loss: 0.5917896032333374
Validation loss: 1.8875209439185359

Epoch: 6| Step: 5
Training loss: 0.48107999563217163
Validation loss: 1.8962439080720306

Epoch: 6| Step: 6
Training loss: 0.5905770063400269
Validation loss: 1.8875798730440037

Epoch: 6| Step: 7
Training loss: 0.5833014845848083
Validation loss: 1.8899410988694878

Epoch: 6| Step: 8
Training loss: 0.5875605344772339
Validation loss: 1.9242784925686416

Epoch: 6| Step: 9
Training loss: 0.39734411239624023
Validation loss: 1.8650311077794721

Epoch: 6| Step: 10
Training loss: 0.36871087551116943
Validation loss: 1.8830076084342053

Epoch: 6| Step: 11
Training loss: 0.5206027030944824
Validation loss: 1.8653000926458707

Epoch: 6| Step: 12
Training loss: 0.6568426489830017
Validation loss: 1.8568347243852512

Epoch: 6| Step: 13
Training loss: 0.8490912914276123
Validation loss: 1.8408754218009211

Epoch: 309| Step: 0
Training loss: 0.4644100069999695
Validation loss: 1.8807116426447386

Epoch: 6| Step: 1
Training loss: 0.3751497268676758
Validation loss: 1.8773240991818008

Epoch: 6| Step: 2
Training loss: 0.791498064994812
Validation loss: 1.8997997391608454

Epoch: 6| Step: 3
Training loss: 0.472595751285553
Validation loss: 1.9161331602322158

Epoch: 6| Step: 4
Training loss: 0.5158975124359131
Validation loss: 1.9280890816001481

Epoch: 6| Step: 5
Training loss: 0.5814735889434814
Validation loss: 1.915234293988956

Epoch: 6| Step: 6
Training loss: 0.5956345796585083
Validation loss: 1.8541664487572127

Epoch: 6| Step: 7
Training loss: 0.40069061517715454
Validation loss: 1.8955229789979997

Epoch: 6| Step: 8
Training loss: 0.8052701950073242
Validation loss: 1.8848560753689017

Epoch: 6| Step: 9
Training loss: 0.4322561025619507
Validation loss: 1.8526481966818533

Epoch: 6| Step: 10
Training loss: 0.34324926137924194
Validation loss: 1.8553140778695383

Epoch: 6| Step: 11
Training loss: 0.8085892796516418
Validation loss: 1.864949139215613

Epoch: 6| Step: 12
Training loss: 0.6283771991729736
Validation loss: 1.851885898138887

Epoch: 6| Step: 13
Training loss: 0.5202526450157166
Validation loss: 1.8668330100274855

Epoch: 310| Step: 0
Training loss: 0.11742249876260757
Validation loss: 1.8777197971138904

Epoch: 6| Step: 1
Training loss: 0.5031983256340027
Validation loss: 1.8476809801593903

Epoch: 6| Step: 2
Training loss: 0.3840808868408203
Validation loss: 1.880336457683194

Epoch: 6| Step: 3
Training loss: 0.4362102448940277
Validation loss: 1.850548162255236

Epoch: 6| Step: 4
Training loss: 0.452817440032959
Validation loss: 1.921116505899737

Epoch: 6| Step: 5
Training loss: 0.5133260488510132
Validation loss: 1.8994026235354844

Epoch: 6| Step: 6
Training loss: 0.5711123943328857
Validation loss: 1.9003041585286458

Epoch: 6| Step: 7
Training loss: 0.3226921856403351
Validation loss: 1.9207308779480636

Epoch: 6| Step: 8
Training loss: 0.6556198596954346
Validation loss: 1.8880446649366809

Epoch: 6| Step: 9
Training loss: 0.6069662570953369
Validation loss: 1.9048625743517311

Epoch: 6| Step: 10
Training loss: 0.5201266407966614
Validation loss: 1.8694029777280745

Epoch: 6| Step: 11
Training loss: 0.5508686304092407
Validation loss: 1.8364951559292373

Epoch: 6| Step: 12
Training loss: 0.49362415075302124
Validation loss: 1.8279896961745394

Epoch: 6| Step: 13
Training loss: 1.092405915260315
Validation loss: 1.8055634062777284

Epoch: 311| Step: 0
Training loss: 0.5747287273406982
Validation loss: 1.7925432087272726

Epoch: 6| Step: 1
Training loss: 0.3692718744277954
Validation loss: 1.768518159466405

Epoch: 6| Step: 2
Training loss: 0.5262441635131836
Validation loss: 1.7872658929517191

Epoch: 6| Step: 3
Training loss: 0.45280876755714417
Validation loss: 1.7890476090933687

Epoch: 6| Step: 4
Training loss: 0.5863294005393982
Validation loss: 1.8014730920073807

Epoch: 6| Step: 5
Training loss: 0.38201290369033813
Validation loss: 1.7989009375213294

Epoch: 6| Step: 6
Training loss: 0.3781386613845825
Validation loss: 1.7883820636298067

Epoch: 6| Step: 7
Training loss: 0.4589058756828308
Validation loss: 1.827540163070925

Epoch: 6| Step: 8
Training loss: 0.4337376356124878
Validation loss: 1.8420426076458347

Epoch: 6| Step: 9
Training loss: 0.8224189281463623
Validation loss: 1.89422809180393

Epoch: 6| Step: 10
Training loss: 0.3972305655479431
Validation loss: 1.8754324425933182

Epoch: 6| Step: 11
Training loss: 0.5412646532058716
Validation loss: 1.8939467745442544

Epoch: 6| Step: 12
Training loss: 0.753679633140564
Validation loss: 1.8984032125883206

Epoch: 6| Step: 13
Training loss: 0.32624995708465576
Validation loss: 1.9373204349189677

Epoch: 312| Step: 0
Training loss: 0.4090784192085266
Validation loss: 1.9016155568502282

Epoch: 6| Step: 1
Training loss: 0.7025362849235535
Validation loss: 1.8787150024085917

Epoch: 6| Step: 2
Training loss: 0.48693013191223145
Validation loss: 1.8627708676040813

Epoch: 6| Step: 3
Training loss: 0.25586366653442383
Validation loss: 1.8523656847656413

Epoch: 6| Step: 4
Training loss: 0.33596372604370117
Validation loss: 1.8429959179252706

Epoch: 6| Step: 5
Training loss: 0.356188029050827
Validation loss: 1.8256217920652

Epoch: 6| Step: 6
Training loss: 0.27452683448791504
Validation loss: 1.8584266631833968

Epoch: 6| Step: 7
Training loss: 0.5319080948829651
Validation loss: 1.865455969687431

Epoch: 6| Step: 8
Training loss: 0.8298075199127197
Validation loss: 1.8659060385919386

Epoch: 6| Step: 9
Training loss: 0.5510364770889282
Validation loss: 1.816702095411157

Epoch: 6| Step: 10
Training loss: 0.6740736961364746
Validation loss: 1.8405649456926572

Epoch: 6| Step: 11
Training loss: 0.6228642463684082
Validation loss: 1.8214851745995142

Epoch: 6| Step: 12
Training loss: 0.22083885967731476
Validation loss: 1.7946730531671995

Epoch: 6| Step: 13
Training loss: 0.5166902542114258
Validation loss: 1.8089348757138817

Epoch: 313| Step: 0
Training loss: 0.6750665903091431
Validation loss: 1.80661557310371

Epoch: 6| Step: 1
Training loss: 0.5324325561523438
Validation loss: 1.8074009931215675

Epoch: 6| Step: 2
Training loss: 0.46418190002441406
Validation loss: 1.8252220756264144

Epoch: 6| Step: 3
Training loss: 0.4773339033126831
Validation loss: 1.8511721626404793

Epoch: 6| Step: 4
Training loss: 0.26251667737960815
Validation loss: 1.8604492320809314

Epoch: 6| Step: 5
Training loss: 0.3356233537197113
Validation loss: 1.85491007502361

Epoch: 6| Step: 6
Training loss: 0.37730926275253296
Validation loss: 1.8723394255484305

Epoch: 6| Step: 7
Training loss: 0.528536319732666
Validation loss: 1.8720486792184974

Epoch: 6| Step: 8
Training loss: 0.7586405277252197
Validation loss: 1.8625235557556152

Epoch: 6| Step: 9
Training loss: 0.6025294661521912
Validation loss: 1.888438118401394

Epoch: 6| Step: 10
Training loss: 0.4911900758743286
Validation loss: 1.8665633534872403

Epoch: 6| Step: 11
Training loss: 0.4936319589614868
Validation loss: 1.8683516748489872

Epoch: 6| Step: 12
Training loss: 0.327785849571228
Validation loss: 1.833743433798513

Epoch: 6| Step: 13
Training loss: 0.47822093963623047
Validation loss: 1.81604141061024

Epoch: 314| Step: 0
Training loss: 0.41881000995635986
Validation loss: 1.8330137447644306

Epoch: 6| Step: 1
Training loss: 0.5366041660308838
Validation loss: 1.7823125982797274

Epoch: 6| Step: 2
Training loss: 0.6681445837020874
Validation loss: 1.765054013139458

Epoch: 6| Step: 3
Training loss: 0.738524317741394
Validation loss: 1.750223187990086

Epoch: 6| Step: 4
Training loss: 0.37929636240005493
Validation loss: 1.7949569174038467

Epoch: 6| Step: 5
Training loss: 0.3527306318283081
Validation loss: 1.7758829055293914

Epoch: 6| Step: 6
Training loss: 0.43108612298965454
Validation loss: 1.7859245846348424

Epoch: 6| Step: 7
Training loss: 0.47696807980537415
Validation loss: 1.781239232709331

Epoch: 6| Step: 8
Training loss: 0.5977349281311035
Validation loss: 1.7815753708603561

Epoch: 6| Step: 9
Training loss: 0.15610067546367645
Validation loss: 1.7859288851420085

Epoch: 6| Step: 10
Training loss: 0.2524275481700897
Validation loss: 1.8337759330708494

Epoch: 6| Step: 11
Training loss: 0.8061230778694153
Validation loss: 1.86122336054361

Epoch: 6| Step: 12
Training loss: 0.7492688894271851
Validation loss: 1.8871098397880472

Epoch: 6| Step: 13
Training loss: 0.6284688711166382
Validation loss: 1.865467010005828

Epoch: 315| Step: 0
Training loss: 0.803022563457489
Validation loss: 1.884569291145571

Epoch: 6| Step: 1
Training loss: 0.4055612087249756
Validation loss: 1.8641802598071355

Epoch: 6| Step: 2
Training loss: 0.4306609332561493
Validation loss: 1.8276896758746075

Epoch: 6| Step: 3
Training loss: 0.32245540618896484
Validation loss: 1.8493994615411247

Epoch: 6| Step: 4
Training loss: 0.6826785802841187
Validation loss: 1.818439459287992

Epoch: 6| Step: 5
Training loss: 0.9257159233093262
Validation loss: 1.8951448163678568

Epoch: 6| Step: 6
Training loss: 0.5535335540771484
Validation loss: 1.8772715778761013

Epoch: 6| Step: 7
Training loss: 0.2801242172718048
Validation loss: 1.864547356482475

Epoch: 6| Step: 8
Training loss: 0.4912911653518677
Validation loss: 1.8542206082292783

Epoch: 6| Step: 9
Training loss: 0.41422319412231445
Validation loss: 1.833690804819907

Epoch: 6| Step: 10
Training loss: 0.5115127563476562
Validation loss: 1.8076750488691433

Epoch: 6| Step: 11
Training loss: 0.38975316286087036
Validation loss: 1.7981272717957855

Epoch: 6| Step: 12
Training loss: 0.39542651176452637
Validation loss: 1.7901011436216292

Epoch: 6| Step: 13
Training loss: 0.49111706018447876
Validation loss: 1.7789023576244232

Epoch: 316| Step: 0
Training loss: 0.8648563027381897
Validation loss: 1.7794089432685607

Epoch: 6| Step: 1
Training loss: 0.29487380385398865
Validation loss: 1.8017190188489935

Epoch: 6| Step: 2
Training loss: 0.4939366281032562
Validation loss: 1.7817676426261984

Epoch: 6| Step: 3
Training loss: 0.5450068712234497
Validation loss: 1.8105183275797034

Epoch: 6| Step: 4
Training loss: 0.25886470079421997
Validation loss: 1.830350605390405

Epoch: 6| Step: 5
Training loss: 0.6215968132019043
Validation loss: 1.7963717945160405

Epoch: 6| Step: 6
Training loss: 0.3413103222846985
Validation loss: 1.8387440084129252

Epoch: 6| Step: 7
Training loss: 0.45370495319366455
Validation loss: 1.8096253948826944

Epoch: 6| Step: 8
Training loss: 0.3192979097366333
Validation loss: 1.8258849741310201

Epoch: 6| Step: 9
Training loss: 0.5334622859954834
Validation loss: 1.8121203991674608

Epoch: 6| Step: 10
Training loss: 0.73048996925354
Validation loss: 1.8066009475338844

Epoch: 6| Step: 11
Training loss: 0.571640133857727
Validation loss: 1.7962773794768958

Epoch: 6| Step: 12
Training loss: 0.1708955615758896
Validation loss: 1.7897975957521828

Epoch: 6| Step: 13
Training loss: 0.3163487911224365
Validation loss: 1.8227664091253792

Epoch: 317| Step: 0
Training loss: 0.31797489523887634
Validation loss: 1.8416525907413934

Epoch: 6| Step: 1
Training loss: 0.5427209138870239
Validation loss: 1.8163481297031525

Epoch: 6| Step: 2
Training loss: 0.36377766728401184
Validation loss: 1.83276092877952

Epoch: 6| Step: 3
Training loss: 0.6434942483901978
Validation loss: 1.8317655581299976

Epoch: 6| Step: 4
Training loss: 0.35251784324645996
Validation loss: 1.8313429394075948

Epoch: 6| Step: 5
Training loss: 0.5749982595443726
Validation loss: 1.8753129198986997

Epoch: 6| Step: 6
Training loss: 0.6420308947563171
Validation loss: 1.87171471118927

Epoch: 6| Step: 7
Training loss: 0.35340219736099243
Validation loss: 1.8378434527304865

Epoch: 6| Step: 8
Training loss: 0.4549543857574463
Validation loss: 1.842876479189883

Epoch: 6| Step: 9
Training loss: 0.4958462715148926
Validation loss: 1.8177773234664754

Epoch: 6| Step: 10
Training loss: 0.4344691038131714
Validation loss: 1.788288252328032

Epoch: 6| Step: 11
Training loss: 0.4284510612487793
Validation loss: 1.7925911526526175

Epoch: 6| Step: 12
Training loss: 0.5986140370368958
Validation loss: 1.7536656446354364

Epoch: 6| Step: 13
Training loss: 0.3641585409641266
Validation loss: 1.7708245195368284

Epoch: 318| Step: 0
Training loss: 0.34702104330062866
Validation loss: 1.776152660769801

Epoch: 6| Step: 1
Training loss: 0.30799630284309387
Validation loss: 1.8196583460736018

Epoch: 6| Step: 2
Training loss: 0.32016175985336304
Validation loss: 1.812893493201143

Epoch: 6| Step: 3
Training loss: 0.7075709104537964
Validation loss: 1.8232530778454197

Epoch: 6| Step: 4
Training loss: 0.6724245548248291
Validation loss: 1.8260881464968446

Epoch: 6| Step: 5
Training loss: 0.23274056613445282
Validation loss: 1.8709674266076857

Epoch: 6| Step: 6
Training loss: 0.48088783025741577
Validation loss: 1.8992821119164909

Epoch: 6| Step: 7
Training loss: 0.5215955972671509
Validation loss: 1.8637990631083006

Epoch: 6| Step: 8
Training loss: 0.671274721622467
Validation loss: 1.8870778211983301

Epoch: 6| Step: 9
Training loss: 0.4113895297050476
Validation loss: 1.8448251370460755

Epoch: 6| Step: 10
Training loss: 0.40131106972694397
Validation loss: 1.881892752903764

Epoch: 6| Step: 11
Training loss: 0.5330619812011719
Validation loss: 1.8596577080347205

Epoch: 6| Step: 12
Training loss: 0.5281429886817932
Validation loss: 1.8736217842307141

Epoch: 6| Step: 13
Training loss: 0.24947302043437958
Validation loss: 1.897132178788544

Epoch: 319| Step: 0
Training loss: 0.4531797766685486
Validation loss: 1.892680013051597

Epoch: 6| Step: 1
Training loss: 0.8553469181060791
Validation loss: 1.8560959780088035

Epoch: 6| Step: 2
Training loss: 0.2925519347190857
Validation loss: 1.8647338972296765

Epoch: 6| Step: 3
Training loss: 0.3610553443431854
Validation loss: 1.810673306065221

Epoch: 6| Step: 4
Training loss: 0.5943278074264526
Validation loss: 1.8546932422986595

Epoch: 6| Step: 5
Training loss: 0.16201359033584595
Validation loss: 1.8526156461367043

Epoch: 6| Step: 6
Training loss: 0.3635377883911133
Validation loss: 1.8602035558351906

Epoch: 6| Step: 7
Training loss: 0.6152340173721313
Validation loss: 1.8425048499978998

Epoch: 6| Step: 8
Training loss: 0.47718706727027893
Validation loss: 1.7751932080074022

Epoch: 6| Step: 9
Training loss: 0.41991591453552246
Validation loss: 1.800412171630449

Epoch: 6| Step: 10
Training loss: 0.40258145332336426
Validation loss: 1.7745944966552079

Epoch: 6| Step: 11
Training loss: 0.8410547971725464
Validation loss: 1.7578546218974616

Epoch: 6| Step: 12
Training loss: 0.2524062693119049
Validation loss: 1.7439358798406457

Epoch: 6| Step: 13
Training loss: 0.2350335419178009
Validation loss: 1.737316003409765

Epoch: 320| Step: 0
Training loss: 0.48045235872268677
Validation loss: 1.7551075784108972

Epoch: 6| Step: 1
Training loss: 0.8496299982070923
Validation loss: 1.755479786985664

Epoch: 6| Step: 2
Training loss: 0.24075666069984436
Validation loss: 1.8043010209196357

Epoch: 6| Step: 3
Training loss: 0.3325357437133789
Validation loss: 1.795555240364485

Epoch: 6| Step: 4
Training loss: 0.40215951204299927
Validation loss: 1.7908800750650384

Epoch: 6| Step: 5
Training loss: 0.5127028822898865
Validation loss: 1.7888915500333231

Epoch: 6| Step: 6
Training loss: 0.6434015035629272
Validation loss: 1.7770933252508923

Epoch: 6| Step: 7
Training loss: 0.22506827116012573
Validation loss: 1.775364637374878

Epoch: 6| Step: 8
Training loss: 0.4059610068798065
Validation loss: 1.7834434560550156

Epoch: 6| Step: 9
Training loss: 0.583808183670044
Validation loss: 1.7666341771361649

Epoch: 6| Step: 10
Training loss: 0.40836334228515625
Validation loss: 1.8101143529338222

Epoch: 6| Step: 11
Training loss: 0.3082156479358673
Validation loss: 1.8667176231261222

Epoch: 6| Step: 12
Training loss: 0.4438425302505493
Validation loss: 1.8560181112699612

Epoch: 6| Step: 13
Training loss: 0.632580041885376
Validation loss: 1.8693713167662263

Epoch: 321| Step: 0
Training loss: 0.7402312159538269
Validation loss: 1.8837459048917216

Epoch: 6| Step: 1
Training loss: 0.28512245416641235
Validation loss: 1.9070559073519964

Epoch: 6| Step: 2
Training loss: 0.5019776821136475
Validation loss: 1.893474668584844

Epoch: 6| Step: 3
Training loss: 0.498879611492157
Validation loss: 1.9094215708394204

Epoch: 6| Step: 4
Training loss: 0.3952868580818176
Validation loss: 1.8938429586348995

Epoch: 6| Step: 5
Training loss: 0.38067203760147095
Validation loss: 1.851292448659097

Epoch: 6| Step: 6
Training loss: 0.5415915250778198
Validation loss: 1.8489721359745148

Epoch: 6| Step: 7
Training loss: 0.32975977659225464
Validation loss: 1.8040605578371274

Epoch: 6| Step: 8
Training loss: 0.3394184708595276
Validation loss: 1.775136939940914

Epoch: 6| Step: 9
Training loss: 0.4492773413658142
Validation loss: 1.7496435642242432

Epoch: 6| Step: 10
Training loss: 0.24228811264038086
Validation loss: 1.7365471381013111

Epoch: 6| Step: 11
Training loss: 0.4154702425003052
Validation loss: 1.7469868736882364

Epoch: 6| Step: 12
Training loss: 0.6333785653114319
Validation loss: 1.7425691927632978

Epoch: 6| Step: 13
Training loss: 0.7311327457427979
Validation loss: 1.7456334431966145

Epoch: 322| Step: 0
Training loss: 0.569840669631958
Validation loss: 1.7578108323517667

Epoch: 6| Step: 1
Training loss: 0.24362263083457947
Validation loss: 1.7826346082072104

Epoch: 6| Step: 2
Training loss: 0.32390734553337097
Validation loss: 1.793651359055632

Epoch: 6| Step: 3
Training loss: 0.29996711015701294
Validation loss: 1.8143657151088919

Epoch: 6| Step: 4
Training loss: 0.6384842991828918
Validation loss: 1.8324188442640408

Epoch: 6| Step: 5
Training loss: 0.3001272678375244
Validation loss: 1.870682054950345

Epoch: 6| Step: 6
Training loss: 0.34633713960647583
Validation loss: 1.8554376530390915

Epoch: 6| Step: 7
Training loss: 0.46446382999420166
Validation loss: 1.8543839211105018

Epoch: 6| Step: 8
Training loss: 0.3773483335971832
Validation loss: 1.8211014937329035

Epoch: 6| Step: 9
Training loss: 0.5646470189094543
Validation loss: 1.8250810984642274

Epoch: 6| Step: 10
Training loss: 0.5105868577957153
Validation loss: 1.785436418748671

Epoch: 6| Step: 11
Training loss: 0.5702537298202515
Validation loss: 1.7715224783907655

Epoch: 6| Step: 12
Training loss: 0.8770118951797485
Validation loss: 1.7590066399625552

Epoch: 6| Step: 13
Training loss: 0.090287946164608
Validation loss: 1.762339682989223

Epoch: 323| Step: 0
Training loss: 0.5324529409408569
Validation loss: 1.7463390173450593

Epoch: 6| Step: 1
Training loss: 0.2398841381072998
Validation loss: 1.7471977369759673

Epoch: 6| Step: 2
Training loss: 0.4264456629753113
Validation loss: 1.7619522797164096

Epoch: 6| Step: 3
Training loss: 0.5331457257270813
Validation loss: 1.7673184076944988

Epoch: 6| Step: 4
Training loss: 0.41522130370140076
Validation loss: 1.7811939126701766

Epoch: 6| Step: 5
Training loss: 0.2586615979671478
Validation loss: 1.8034893774217176

Epoch: 6| Step: 6
Training loss: 0.8999373912811279
Validation loss: 1.8123504551508094

Epoch: 6| Step: 7
Training loss: 0.4457911252975464
Validation loss: 1.7835081161991242

Epoch: 6| Step: 8
Training loss: 0.37820130586624146
Validation loss: 1.8143183826118388

Epoch: 6| Step: 9
Training loss: 0.1822614073753357
Validation loss: 1.7951933683887604

Epoch: 6| Step: 10
Training loss: 0.3708990216255188
Validation loss: 1.8414775479224421

Epoch: 6| Step: 11
Training loss: 0.44412457942962646
Validation loss: 1.8081700237848426

Epoch: 6| Step: 12
Training loss: 0.3722509741783142
Validation loss: 1.8152083658402967

Epoch: 6| Step: 13
Training loss: 0.7657168507575989
Validation loss: 1.7944052732118996

Epoch: 324| Step: 0
Training loss: 0.30515435338020325
Validation loss: 1.8008291772616807

Epoch: 6| Step: 1
Training loss: 0.40821728110313416
Validation loss: 1.8185600067979546

Epoch: 6| Step: 2
Training loss: 0.4557899832725525
Validation loss: 1.8037422562158236

Epoch: 6| Step: 3
Training loss: 0.7084159851074219
Validation loss: 1.818307904786961

Epoch: 6| Step: 4
Training loss: 0.642304539680481
Validation loss: 1.8023814270573277

Epoch: 6| Step: 5
Training loss: 0.4418576657772064
Validation loss: 1.7824357824940835

Epoch: 6| Step: 6
Training loss: 0.2513428330421448
Validation loss: 1.7859808629558933

Epoch: 6| Step: 7
Training loss: 0.2543332874774933
Validation loss: 1.8021764806521836

Epoch: 6| Step: 8
Training loss: 0.7384125590324402
Validation loss: 1.7936862630228843

Epoch: 6| Step: 9
Training loss: 0.27617931365966797
Validation loss: 1.788132825205403

Epoch: 6| Step: 10
Training loss: 0.3872445225715637
Validation loss: 1.783861187196547

Epoch: 6| Step: 11
Training loss: 0.4061795473098755
Validation loss: 1.7726704010399439

Epoch: 6| Step: 12
Training loss: 0.3883393406867981
Validation loss: 1.7672291045547814

Epoch: 6| Step: 13
Training loss: 0.17524157464504242
Validation loss: 1.7819880964935466

Epoch: 325| Step: 0
Training loss: 0.2974419891834259
Validation loss: 1.8017695616650324

Epoch: 6| Step: 1
Training loss: 0.4468576908111572
Validation loss: 1.7690753923949374

Epoch: 6| Step: 2
Training loss: 0.4608873128890991
Validation loss: 1.8220335065677602

Epoch: 6| Step: 3
Training loss: 0.500978410243988
Validation loss: 1.827071512899091

Epoch: 6| Step: 4
Training loss: 0.23908595740795135
Validation loss: 1.8358603446714339

Epoch: 6| Step: 5
Training loss: 0.32330381870269775
Validation loss: 1.8153814692651071

Epoch: 6| Step: 6
Training loss: 0.6077420115470886
Validation loss: 1.7975674060083204

Epoch: 6| Step: 7
Training loss: 0.3955109119415283
Validation loss: 1.8238980565019833

Epoch: 6| Step: 8
Training loss: 0.5073332786560059
Validation loss: 1.8407649019713044

Epoch: 6| Step: 9
Training loss: 0.32770970463752747
Validation loss: 1.8532337001574937

Epoch: 6| Step: 10
Training loss: 0.6689209938049316
Validation loss: 1.8299926942394626

Epoch: 6| Step: 11
Training loss: 0.664521336555481
Validation loss: 1.8531793855851697

Epoch: 6| Step: 12
Training loss: 0.4216471314430237
Validation loss: 1.8322122084197177

Epoch: 6| Step: 13
Training loss: 0.14070826768875122
Validation loss: 1.8612057816597722

Epoch: 326| Step: 0
Training loss: 0.227865070104599
Validation loss: 1.8854990659221527

Epoch: 6| Step: 1
Training loss: 0.3287128806114197
Validation loss: 1.8537034514129802

Epoch: 6| Step: 2
Training loss: 0.5908547639846802
Validation loss: 1.8692736420580136

Epoch: 6| Step: 3
Training loss: 0.48258155584335327
Validation loss: 1.8698171210545365

Epoch: 6| Step: 4
Training loss: 0.43841999769210815
Validation loss: 1.8816812743422806

Epoch: 6| Step: 5
Training loss: 0.7001597881317139
Validation loss: 1.871071852663512

Epoch: 6| Step: 6
Training loss: 0.5432754755020142
Validation loss: 1.8463887463333786

Epoch: 6| Step: 7
Training loss: 0.68247389793396
Validation loss: 1.799026548221547

Epoch: 6| Step: 8
Training loss: 0.39063340425491333
Validation loss: 1.7721234752285866

Epoch: 6| Step: 9
Training loss: 0.1912781000137329
Validation loss: 1.721434864946591

Epoch: 6| Step: 10
Training loss: 0.348704993724823
Validation loss: 1.735767360656492

Epoch: 6| Step: 11
Training loss: 0.2912811040878296
Validation loss: 1.699281096458435

Epoch: 6| Step: 12
Training loss: 0.44868120551109314
Validation loss: 1.6996480495698991

Epoch: 6| Step: 13
Training loss: 0.9187920689582825
Validation loss: 1.766033660980963

Epoch: 327| Step: 0
Training loss: 0.39817529916763306
Validation loss: 1.7717681315637404

Epoch: 6| Step: 1
Training loss: 0.434232622385025
Validation loss: 1.7982289688561552

Epoch: 6| Step: 2
Training loss: 0.36712729930877686
Validation loss: 1.7961014522019254

Epoch: 6| Step: 3
Training loss: 0.1885048747062683
Validation loss: 1.8015583458767142

Epoch: 6| Step: 4
Training loss: 0.5154585838317871
Validation loss: 1.8012303101119174

Epoch: 6| Step: 5
Training loss: 0.4744238257408142
Validation loss: 1.8455261235596032

Epoch: 6| Step: 6
Training loss: 0.5400897264480591
Validation loss: 1.8534605015990555

Epoch: 6| Step: 7
Training loss: 0.48790496587753296
Validation loss: 1.8169229286973194

Epoch: 6| Step: 8
Training loss: 0.2829051613807678
Validation loss: 1.8200578728029806

Epoch: 6| Step: 9
Training loss: 0.40958625078201294
Validation loss: 1.8100479905323317

Epoch: 6| Step: 10
Training loss: 0.6214330792427063
Validation loss: 1.8108464992174538

Epoch: 6| Step: 11
Training loss: 0.5414748191833496
Validation loss: 1.7856891309061358

Epoch: 6| Step: 12
Training loss: 0.253317266702652
Validation loss: 1.7721702142428326

Epoch: 6| Step: 13
Training loss: 0.5310851335525513
Validation loss: 1.771889381511237

Epoch: 328| Step: 0
Training loss: 0.2692718803882599
Validation loss: 1.7845978108785485

Epoch: 6| Step: 1
Training loss: 0.21477320790290833
Validation loss: 1.7715799321410477

Epoch: 6| Step: 2
Training loss: 0.45742467045783997
Validation loss: 1.729946441547845

Epoch: 6| Step: 3
Training loss: 0.3160662353038788
Validation loss: 1.7675972202772736

Epoch: 6| Step: 4
Training loss: 0.464881956577301
Validation loss: 1.7854300186198244

Epoch: 6| Step: 5
Training loss: 0.435851514339447
Validation loss: 1.7961886980200326

Epoch: 6| Step: 6
Training loss: 0.37203022837638855
Validation loss: 1.8372226684324202

Epoch: 6| Step: 7
Training loss: 0.976858377456665
Validation loss: 1.8502068955411193

Epoch: 6| Step: 8
Training loss: 0.5626819133758545
Validation loss: 1.8467104242693992

Epoch: 6| Step: 9
Training loss: 0.4516778290271759
Validation loss: 1.8354420136379939

Epoch: 6| Step: 10
Training loss: 0.5151578783988953
Validation loss: 1.7969168078514837

Epoch: 6| Step: 11
Training loss: 0.2907174229621887
Validation loss: 1.8117066455143753

Epoch: 6| Step: 12
Training loss: 0.39604952931404114
Validation loss: 1.8008056891861783

Epoch: 6| Step: 13
Training loss: 0.2820579707622528
Validation loss: 1.7893759268586353

Epoch: 329| Step: 0
Training loss: 0.5077248215675354
Validation loss: 1.7778174479802449

Epoch: 6| Step: 1
Training loss: 0.6322553157806396
Validation loss: 1.7441223654695737

Epoch: 6| Step: 2
Training loss: 0.3446676731109619
Validation loss: 1.7295006718686832

Epoch: 6| Step: 3
Training loss: 0.36193692684173584
Validation loss: 1.7489229632962136

Epoch: 6| Step: 4
Training loss: 0.39953169226646423
Validation loss: 1.7388396416940997

Epoch: 6| Step: 5
Training loss: 0.5402294397354126
Validation loss: 1.769319765029415

Epoch: 6| Step: 6
Training loss: 0.39851677417755127
Validation loss: 1.7653657210770475

Epoch: 6| Step: 7
Training loss: 0.3725843131542206
Validation loss: 1.7874658774304133

Epoch: 6| Step: 8
Training loss: 0.4421911835670471
Validation loss: 1.7491682421776555

Epoch: 6| Step: 9
Training loss: 0.3751545548439026
Validation loss: 1.736480930800079

Epoch: 6| Step: 10
Training loss: 0.3625478744506836
Validation loss: 1.7474972535205144

Epoch: 6| Step: 11
Training loss: 0.3292056918144226
Validation loss: 1.7434001443206624

Epoch: 6| Step: 12
Training loss: 0.2965819835662842
Validation loss: 1.7439241486210977

Epoch: 6| Step: 13
Training loss: 0.26980137825012207
Validation loss: 1.739979527329886

Epoch: 330| Step: 0
Training loss: 0.36986827850341797
Validation loss: 1.7490154453503188

Epoch: 6| Step: 1
Training loss: 0.3649473190307617
Validation loss: 1.7554921052789176

Epoch: 6| Step: 2
Training loss: 0.3990654945373535
Validation loss: 1.7615375108616327

Epoch: 6| Step: 3
Training loss: 0.6421823501586914
Validation loss: 1.766243928222246

Epoch: 6| Step: 4
Training loss: 0.16135619580745697
Validation loss: 1.7490732849285167

Epoch: 6| Step: 5
Training loss: 0.5613012313842773
Validation loss: 1.7829099816660727

Epoch: 6| Step: 6
Training loss: 0.6296550035476685
Validation loss: 1.7908981628315424

Epoch: 6| Step: 7
Training loss: 0.39744067192077637
Validation loss: 1.8393559276416738

Epoch: 6| Step: 8
Training loss: 0.4438348412513733
Validation loss: 1.877038150705317

Epoch: 6| Step: 9
Training loss: 0.3744705021381378
Validation loss: 1.8195617224580498

Epoch: 6| Step: 10
Training loss: 0.7492164969444275
Validation loss: 1.7868079780250468

Epoch: 6| Step: 11
Training loss: 0.4555528461933136
Validation loss: 1.7888326055260115

Epoch: 6| Step: 12
Training loss: 0.44040924310684204
Validation loss: 1.777054230372111

Epoch: 6| Step: 13
Training loss: 0.31050506234169006
Validation loss: 1.7995636834893176

Epoch: 331| Step: 0
Training loss: 0.9010586738586426
Validation loss: 1.8361319829058904

Epoch: 6| Step: 1
Training loss: 0.17342369258403778
Validation loss: 1.8457153087021203

Epoch: 6| Step: 2
Training loss: 0.42307764291763306
Validation loss: 1.8167294609931208

Epoch: 6| Step: 3
Training loss: 0.49251848459243774
Validation loss: 1.8396196801175353

Epoch: 6| Step: 4
Training loss: 0.4481106102466583
Validation loss: 1.8690526075260614

Epoch: 6| Step: 5
Training loss: 0.3364775776863098
Validation loss: 1.8160617659168858

Epoch: 6| Step: 6
Training loss: 0.27950578927993774
Validation loss: 1.7928374518630326

Epoch: 6| Step: 7
Training loss: 0.35153836011886597
Validation loss: 1.7903681570483791

Epoch: 6| Step: 8
Training loss: 0.2964548170566559
Validation loss: 1.7453139097459855

Epoch: 6| Step: 9
Training loss: 0.6827194690704346
Validation loss: 1.7164764686297345

Epoch: 6| Step: 10
Training loss: 0.39132463932037354
Validation loss: 1.7062473745756253

Epoch: 6| Step: 11
Training loss: 0.3575516939163208
Validation loss: 1.7042607351015973

Epoch: 6| Step: 12
Training loss: 0.387630820274353
Validation loss: 1.7377746233376123

Epoch: 6| Step: 13
Training loss: 0.4500938057899475
Validation loss: 1.7170474490811747

Epoch: 332| Step: 0
Training loss: 0.45051464438438416
Validation loss: 1.7760656354247883

Epoch: 6| Step: 1
Training loss: 0.4715965986251831
Validation loss: 1.791762254571402

Epoch: 6| Step: 2
Training loss: 0.24339903891086578
Validation loss: 1.8044385499851678

Epoch: 6| Step: 3
Training loss: 0.266910195350647
Validation loss: 1.839141079174575

Epoch: 6| Step: 4
Training loss: 0.3169347643852234
Validation loss: 1.848457626117173

Epoch: 6| Step: 5
Training loss: 0.3672155737876892
Validation loss: 1.8611761357194634

Epoch: 6| Step: 6
Training loss: 0.3970804810523987
Validation loss: 1.8806129501711937

Epoch: 6| Step: 7
Training loss: 0.6201804876327515
Validation loss: 1.8682902654012044

Epoch: 6| Step: 8
Training loss: 0.533525288105011
Validation loss: 1.8588516609643095

Epoch: 6| Step: 9
Training loss: 0.4872294068336487
Validation loss: 1.8280564328675628

Epoch: 6| Step: 10
Training loss: 0.41421598196029663
Validation loss: 1.8404941020473358

Epoch: 6| Step: 11
Training loss: 0.24109989404678345
Validation loss: 1.77569491376159

Epoch: 6| Step: 12
Training loss: 0.2993401885032654
Validation loss: 1.7797655764446463

Epoch: 6| Step: 13
Training loss: 1.143358588218689
Validation loss: 1.754663554571008

Epoch: 333| Step: 0
Training loss: 0.42597663402557373
Validation loss: 1.7522535759915587

Epoch: 6| Step: 1
Training loss: 0.5209163427352905
Validation loss: 1.742817081430907

Epoch: 6| Step: 2
Training loss: 0.23868560791015625
Validation loss: 1.772962635563266

Epoch: 6| Step: 3
Training loss: 0.3260799050331116
Validation loss: 1.725187247799289

Epoch: 6| Step: 4
Training loss: 0.3953818380832672
Validation loss: 1.7461333992660686

Epoch: 6| Step: 5
Training loss: 0.4794752895832062
Validation loss: 1.797045930739372

Epoch: 6| Step: 6
Training loss: 0.4443953335285187
Validation loss: 1.7845961496394167

Epoch: 6| Step: 7
Training loss: 0.39639127254486084
Validation loss: 1.8076833089192708

Epoch: 6| Step: 8
Training loss: 0.564971923828125
Validation loss: 1.7736409671844975

Epoch: 6| Step: 9
Training loss: 0.7705864906311035
Validation loss: 1.7150383175060313

Epoch: 6| Step: 10
Training loss: 0.3256053924560547
Validation loss: 1.7251074801209152

Epoch: 6| Step: 11
Training loss: 0.4956519603729248
Validation loss: 1.744325900590548

Epoch: 6| Step: 12
Training loss: 0.4748367667198181
Validation loss: 1.72115154932904

Epoch: 6| Step: 13
Training loss: 0.21687419712543488
Validation loss: 1.722330326675087

Epoch: 334| Step: 0
Training loss: 0.3421782851219177
Validation loss: 1.7095954661728234

Epoch: 6| Step: 1
Training loss: 0.39077532291412354
Validation loss: 1.6990304493135022

Epoch: 6| Step: 2
Training loss: 0.318903386592865
Validation loss: 1.7497763851637482

Epoch: 6| Step: 3
Training loss: 0.5305458903312683
Validation loss: 1.7367496041841404

Epoch: 6| Step: 4
Training loss: 0.2767183184623718
Validation loss: 1.748266799475557

Epoch: 6| Step: 5
Training loss: 0.725886344909668
Validation loss: 1.7615090570142191

Epoch: 6| Step: 6
Training loss: 0.48901796340942383
Validation loss: 1.7628395685585596

Epoch: 6| Step: 7
Training loss: 0.44155651330947876
Validation loss: 1.7933078747923656

Epoch: 6| Step: 8
Training loss: 0.23984383046627045
Validation loss: 1.8093258386017175

Epoch: 6| Step: 9
Training loss: 0.2913471460342407
Validation loss: 1.8181483976302608

Epoch: 6| Step: 10
Training loss: 0.2915976941585541
Validation loss: 1.7739493872529717

Epoch: 6| Step: 11
Training loss: 0.36655542254447937
Validation loss: 1.749864298810241

Epoch: 6| Step: 12
Training loss: 0.41490960121154785
Validation loss: 1.7671576315356838

Epoch: 6| Step: 13
Training loss: 0.32071733474731445
Validation loss: 1.761981725692749

Epoch: 335| Step: 0
Training loss: 0.6368423700332642
Validation loss: 1.7708449068889822

Epoch: 6| Step: 1
Training loss: 0.284699022769928
Validation loss: 1.7856820244942941

Epoch: 6| Step: 2
Training loss: 0.29423952102661133
Validation loss: 1.7979089649774695

Epoch: 6| Step: 3
Training loss: 0.14920136332511902
Validation loss: 1.790826330902756

Epoch: 6| Step: 4
Training loss: 0.2424897402524948
Validation loss: 1.816467679956908

Epoch: 6| Step: 5
Training loss: 0.7413663864135742
Validation loss: 1.8212754264954598

Epoch: 6| Step: 6
Training loss: 0.5139017701148987
Validation loss: 1.8295837692035142

Epoch: 6| Step: 7
Training loss: 0.33089479804039
Validation loss: 1.8196377779847832

Epoch: 6| Step: 8
Training loss: 0.3000611960887909
Validation loss: 1.815753149729903

Epoch: 6| Step: 9
Training loss: 0.21781206130981445
Validation loss: 1.8114923533572946

Epoch: 6| Step: 10
Training loss: 0.5604262351989746
Validation loss: 1.7736774029270295

Epoch: 6| Step: 11
Training loss: 0.3922368288040161
Validation loss: 1.7584085458068437

Epoch: 6| Step: 12
Training loss: 0.3705611228942871
Validation loss: 1.7349777772862425

Epoch: 6| Step: 13
Training loss: 0.4573758840560913
Validation loss: 1.7430795623410134

Epoch: 336| Step: 0
Training loss: 0.2677493095397949
Validation loss: 1.722441937333794

Epoch: 6| Step: 1
Training loss: 0.23038098216056824
Validation loss: 1.744098565911734

Epoch: 6| Step: 2
Training loss: 0.6066745519638062
Validation loss: 1.7658448808936662

Epoch: 6| Step: 3
Training loss: 0.31689080595970154
Validation loss: 1.7958500910830755

Epoch: 6| Step: 4
Training loss: 0.2312217354774475
Validation loss: 1.7877779301776682

Epoch: 6| Step: 5
Training loss: 0.2839457392692566
Validation loss: 1.7984952644635273

Epoch: 6| Step: 6
Training loss: 0.4359119236469269
Validation loss: 1.7990850466553883

Epoch: 6| Step: 7
Training loss: 0.43477171659469604
Validation loss: 1.7828241202139086

Epoch: 6| Step: 8
Training loss: 0.2472546249628067
Validation loss: 1.7577681720897715

Epoch: 6| Step: 9
Training loss: 0.4085175096988678
Validation loss: 1.7412057615095569

Epoch: 6| Step: 10
Training loss: 0.5275426506996155
Validation loss: 1.7754518473020164

Epoch: 6| Step: 11
Training loss: 0.4943789839744568
Validation loss: 1.7485160481545232

Epoch: 6| Step: 12
Training loss: 0.44605907797813416
Validation loss: 1.7533327366716118

Epoch: 6| Step: 13
Training loss: 0.42405951023101807
Validation loss: 1.7596564485180763

Epoch: 337| Step: 0
Training loss: 0.24361024796962738
Validation loss: 1.7573855012975714

Epoch: 6| Step: 1
Training loss: 0.4570542275905609
Validation loss: 1.7798887311771352

Epoch: 6| Step: 2
Training loss: 0.8019973039627075
Validation loss: 1.7876436594993836

Epoch: 6| Step: 3
Training loss: 0.3989256024360657
Validation loss: 1.8027702723779986

Epoch: 6| Step: 4
Training loss: 0.3160892128944397
Validation loss: 1.7958969134156422

Epoch: 6| Step: 5
Training loss: 0.41896119713783264
Validation loss: 1.7978871586502239

Epoch: 6| Step: 6
Training loss: 0.3874298632144928
Validation loss: 1.7963965169845089

Epoch: 6| Step: 7
Training loss: 0.3271741569042206
Validation loss: 1.7628250519434612

Epoch: 6| Step: 8
Training loss: 0.1596337854862213
Validation loss: 1.7535784449628604

Epoch: 6| Step: 9
Training loss: 0.16702760756015778
Validation loss: 1.728440882057272

Epoch: 6| Step: 10
Training loss: 0.2967648208141327
Validation loss: 1.7420506003082439

Epoch: 6| Step: 11
Training loss: 0.34054484963417053
Validation loss: 1.7555035378343316

Epoch: 6| Step: 12
Training loss: 0.3576607406139374
Validation loss: 1.7355885864585958

Epoch: 6| Step: 13
Training loss: 0.40379998087882996
Validation loss: 1.7848212026780652

Epoch: 338| Step: 0
Training loss: 0.44209742546081543
Validation loss: 1.7631637768078876

Epoch: 6| Step: 1
Training loss: 0.36167484521865845
Validation loss: 1.74904937641595

Epoch: 6| Step: 2
Training loss: 0.5163806676864624
Validation loss: 1.7574478426287252

Epoch: 6| Step: 3
Training loss: 0.3610762357711792
Validation loss: 1.7389409516447334

Epoch: 6| Step: 4
Training loss: 0.32653290033340454
Validation loss: 1.7619376951648342

Epoch: 6| Step: 5
Training loss: 0.34930089116096497
Validation loss: 1.753001989856843

Epoch: 6| Step: 6
Training loss: 0.24996569752693176
Validation loss: 1.7642779875827093

Epoch: 6| Step: 7
Training loss: 0.31509214639663696
Validation loss: 1.7531574964523315

Epoch: 6| Step: 8
Training loss: 0.14873358607292175
Validation loss: 1.7789041996002197

Epoch: 6| Step: 9
Training loss: 0.4321918189525604
Validation loss: 1.6966693657700733

Epoch: 6| Step: 10
Training loss: 0.6981993317604065
Validation loss: 1.7398722197419854

Epoch: 6| Step: 11
Training loss: 0.2795270085334778
Validation loss: 1.7274610868064306

Epoch: 6| Step: 12
Training loss: 0.3346226215362549
Validation loss: 1.6930403940139278

Epoch: 6| Step: 13
Training loss: 0.43055814504623413
Validation loss: 1.7464585842624787

Epoch: 339| Step: 0
Training loss: 0.49637994170188904
Validation loss: 1.7188397633132113

Epoch: 6| Step: 1
Training loss: 0.6113306283950806
Validation loss: 1.7506954772498018

Epoch: 6| Step: 2
Training loss: 0.3944975733757019
Validation loss: 1.768298497764013

Epoch: 6| Step: 3
Training loss: 0.3103788495063782
Validation loss: 1.7742069152093702

Epoch: 6| Step: 4
Training loss: 0.3585657477378845
Validation loss: 1.7841690407004407

Epoch: 6| Step: 5
Training loss: 0.2913772761821747
Validation loss: 1.781914040606509

Epoch: 6| Step: 6
Training loss: 0.3208405673503876
Validation loss: 1.7815598518617692

Epoch: 6| Step: 7
Training loss: 0.5519858598709106
Validation loss: 1.7701987822850545

Epoch: 6| Step: 8
Training loss: 0.409089058637619
Validation loss: 1.7743470796974756

Epoch: 6| Step: 9
Training loss: 0.24591824412345886
Validation loss: 1.724077631068486

Epoch: 6| Step: 10
Training loss: 0.16748282313346863
Validation loss: 1.7076662996763825

Epoch: 6| Step: 11
Training loss: 0.33229199051856995
Validation loss: 1.704409800549989

Epoch: 6| Step: 12
Training loss: 0.4261346161365509
Validation loss: 1.6853897058835594

Epoch: 6| Step: 13
Training loss: 0.28476157784461975
Validation loss: 1.7000009596988719

Epoch: 340| Step: 0
Training loss: 0.5184835195541382
Validation loss: 1.6627364056084746

Epoch: 6| Step: 1
Training loss: 0.354084312915802
Validation loss: 1.697089595179404

Epoch: 6| Step: 2
Training loss: 0.6847557425498962
Validation loss: 1.680665926266742

Epoch: 6| Step: 3
Training loss: 0.258567214012146
Validation loss: 1.6913043786120672

Epoch: 6| Step: 4
Training loss: 0.42461007833480835
Validation loss: 1.7350159063134143

Epoch: 6| Step: 5
Training loss: 0.3798137307167053
Validation loss: 1.7919568630956835

Epoch: 6| Step: 6
Training loss: 0.20488658547401428
Validation loss: 1.8255224843179025

Epoch: 6| Step: 7
Training loss: 0.43476253747940063
Validation loss: 1.7766460705828924

Epoch: 6| Step: 8
Training loss: 0.28457167744636536
Validation loss: 1.7853801917004328

Epoch: 6| Step: 9
Training loss: 0.4437418580055237
Validation loss: 1.7768610805593512

Epoch: 6| Step: 10
Training loss: 0.3228207230567932
Validation loss: 1.750978187848163

Epoch: 6| Step: 11
Training loss: 0.48691678047180176
Validation loss: 1.7189328234682801

Epoch: 6| Step: 12
Training loss: 0.32995831966400146
Validation loss: 1.7115546657193093

Epoch: 6| Step: 13
Training loss: 0.19545263051986694
Validation loss: 1.6950561769547001

Epoch: 341| Step: 0
Training loss: 0.41977283358573914
Validation loss: 1.6619193451378935

Epoch: 6| Step: 1
Training loss: 0.5798672437667847
Validation loss: 1.6679677181346442

Epoch: 6| Step: 2
Training loss: 0.3674011826515198
Validation loss: 1.6666600793920539

Epoch: 6| Step: 3
Training loss: 0.35949942469596863
Validation loss: 1.6702983456273233

Epoch: 6| Step: 4
Training loss: 0.4587888717651367
Validation loss: 1.671275725928686

Epoch: 6| Step: 5
Training loss: 0.4028276205062866
Validation loss: 1.703538848507789

Epoch: 6| Step: 6
Training loss: 0.26261213421821594
Validation loss: 1.7163459434304187

Epoch: 6| Step: 7
Training loss: 0.3960576355457306
Validation loss: 1.7836942288183397

Epoch: 6| Step: 8
Training loss: 0.4983772933483124
Validation loss: 1.768170834869467

Epoch: 6| Step: 9
Training loss: 0.7443927526473999
Validation loss: 1.7715335635728733

Epoch: 6| Step: 10
Training loss: 0.235190749168396
Validation loss: 1.7668404694526427

Epoch: 6| Step: 11
Training loss: 0.2880082428455353
Validation loss: 1.732421144362419

Epoch: 6| Step: 12
Training loss: 0.29259663820266724
Validation loss: 1.7585730603946153

Epoch: 6| Step: 13
Training loss: 0.4357561469078064
Validation loss: 1.7265867879313808

Epoch: 342| Step: 0
Training loss: 0.25824227929115295
Validation loss: 1.7480683454903223

Epoch: 6| Step: 1
Training loss: 0.34065526723861694
Validation loss: 1.7678963010029127

Epoch: 6| Step: 2
Training loss: 0.37726742029190063
Validation loss: 1.7904848437155447

Epoch: 6| Step: 3
Training loss: 0.28131914138793945
Validation loss: 1.7827119365815194

Epoch: 6| Step: 4
Training loss: 0.4636036455631256
Validation loss: 1.8019921856541787

Epoch: 6| Step: 5
Training loss: 0.6016174554824829
Validation loss: 1.815660866357947

Epoch: 6| Step: 6
Training loss: 0.6937958598136902
Validation loss: 1.81424500865321

Epoch: 6| Step: 7
Training loss: 0.23752206563949585
Validation loss: 1.7996508344527213

Epoch: 6| Step: 8
Training loss: 0.33885592222213745
Validation loss: 1.7568669613971506

Epoch: 6| Step: 9
Training loss: 0.39052054286003113
Validation loss: 1.7394823938287713

Epoch: 6| Step: 10
Training loss: 0.4495910704135895
Validation loss: 1.733615368284205

Epoch: 6| Step: 11
Training loss: 0.2911830544471741
Validation loss: 1.710230577376581

Epoch: 6| Step: 12
Training loss: 0.36369597911834717
Validation loss: 1.724471394733716

Epoch: 6| Step: 13
Training loss: 0.33145949244499207
Validation loss: 1.7110600612496818

Epoch: 343| Step: 0
Training loss: 0.46169513463974
Validation loss: 1.6926295975203156

Epoch: 6| Step: 1
Training loss: 0.375501811504364
Validation loss: 1.7068065994529313

Epoch: 6| Step: 2
Training loss: 0.3214561939239502
Validation loss: 1.6854476633892264

Epoch: 6| Step: 3
Training loss: 0.23537757992744446
Validation loss: 1.730607489103912

Epoch: 6| Step: 4
Training loss: 0.3781886696815491
Validation loss: 1.7321845664772937

Epoch: 6| Step: 5
Training loss: 0.6065353155136108
Validation loss: 1.7367895085324523

Epoch: 6| Step: 6
Training loss: 0.5484934449195862
Validation loss: 1.7032772674355456

Epoch: 6| Step: 7
Training loss: 0.3630598783493042
Validation loss: 1.7116936970782537

Epoch: 6| Step: 8
Training loss: 0.2964656352996826
Validation loss: 1.744125626420462

Epoch: 6| Step: 9
Training loss: 0.3341478705406189
Validation loss: 1.7393695359588952

Epoch: 6| Step: 10
Training loss: 0.2512752115726471
Validation loss: 1.728101267609545

Epoch: 6| Step: 11
Training loss: 0.21137972176074982
Validation loss: 1.7283310377469627

Epoch: 6| Step: 12
Training loss: 0.33110520243644714
Validation loss: 1.7303320489903933

Epoch: 6| Step: 13
Training loss: 0.31147632002830505
Validation loss: 1.7075775977103942

Epoch: 344| Step: 0
Training loss: 0.4953012466430664
Validation loss: 1.7481931922256306

Epoch: 6| Step: 1
Training loss: 0.47333723306655884
Validation loss: 1.7582485714266378

Epoch: 6| Step: 2
Training loss: 0.3967217206954956
Validation loss: 1.769149395727342

Epoch: 6| Step: 3
Training loss: 0.3865995705127716
Validation loss: 1.7598002059485323

Epoch: 6| Step: 4
Training loss: 0.35037949681282043
Validation loss: 1.737694674922574

Epoch: 6| Step: 5
Training loss: 0.7573873996734619
Validation loss: 1.725392242913605

Epoch: 6| Step: 6
Training loss: 0.26703423261642456
Validation loss: 1.733296303338902

Epoch: 6| Step: 7
Training loss: 0.32965123653411865
Validation loss: 1.7070825663946008

Epoch: 6| Step: 8
Training loss: 0.35380998253822327
Validation loss: 1.7102739323851883

Epoch: 6| Step: 9
Training loss: 0.22478248178958893
Validation loss: 1.7115124733217302

Epoch: 6| Step: 10
Training loss: 0.16598477959632874
Validation loss: 1.6967869804751488

Epoch: 6| Step: 11
Training loss: 0.22291423380374908
Validation loss: 1.7277821135777298

Epoch: 6| Step: 12
Training loss: 0.259547621011734
Validation loss: 1.7328434913389144

Epoch: 6| Step: 13
Training loss: 0.33544760942459106
Validation loss: 1.7018070361947502

Epoch: 345| Step: 0
Training loss: 0.4311026632785797
Validation loss: 1.7583558226144442

Epoch: 6| Step: 1
Training loss: 0.9362460374832153
Validation loss: 1.7448836347108245

Epoch: 6| Step: 2
Training loss: 0.22911995649337769
Validation loss: 1.7486187463165612

Epoch: 6| Step: 3
Training loss: 0.25082287192344666
Validation loss: 1.7302156648328226

Epoch: 6| Step: 4
Training loss: 0.38177740573883057
Validation loss: 1.741975866338258

Epoch: 6| Step: 5
Training loss: 0.335561066865921
Validation loss: 1.7373887556855396

Epoch: 6| Step: 6
Training loss: 0.28404000401496887
Validation loss: 1.7174090505928121

Epoch: 6| Step: 7
Training loss: 0.18816909193992615
Validation loss: 1.7112229921484505

Epoch: 6| Step: 8
Training loss: 0.26345008611679077
Validation loss: 1.696296617548953

Epoch: 6| Step: 9
Training loss: 0.45340240001678467
Validation loss: 1.7266694345781881

Epoch: 6| Step: 10
Training loss: 0.3235676884651184
Validation loss: 1.698607652418075

Epoch: 6| Step: 11
Training loss: 0.42802146077156067
Validation loss: 1.655415714427989

Epoch: 6| Step: 12
Training loss: 0.3641788363456726
Validation loss: 1.7011415932768135

Epoch: 6| Step: 13
Training loss: 0.1541738510131836
Validation loss: 1.7113823044684626

Epoch: 346| Step: 0
Training loss: 0.3934217691421509
Validation loss: 1.7516020831241403

Epoch: 6| Step: 1
Training loss: 0.526678204536438
Validation loss: 1.808324856142844

Epoch: 6| Step: 2
Training loss: 0.29046502709388733
Validation loss: 1.8245968511027675

Epoch: 6| Step: 3
Training loss: 0.23051854968070984
Validation loss: 1.7785699149613738

Epoch: 6| Step: 4
Training loss: 0.27888548374176025
Validation loss: 1.777788483968345

Epoch: 6| Step: 5
Training loss: 0.37540966272354126
Validation loss: 1.7857449746900989

Epoch: 6| Step: 6
Training loss: 0.339374840259552
Validation loss: 1.739208065053468

Epoch: 6| Step: 7
Training loss: 0.27536219358444214
Validation loss: 1.7658937509341905

Epoch: 6| Step: 8
Training loss: 0.3101678490638733
Validation loss: 1.7639453475193312

Epoch: 6| Step: 9
Training loss: 0.27512580156326294
Validation loss: 1.7355100634277507

Epoch: 6| Step: 10
Training loss: 0.9100446701049805
Validation loss: 1.7247914319397302

Epoch: 6| Step: 11
Training loss: 0.5079301595687866
Validation loss: 1.7450662864151822

Epoch: 6| Step: 12
Training loss: 0.3513326048851013
Validation loss: 1.7283017545618036

Epoch: 6| Step: 13
Training loss: 0.31788814067840576
Validation loss: 1.7407218756214264

Epoch: 347| Step: 0
Training loss: 0.4621620178222656
Validation loss: 1.769514767072534

Epoch: 6| Step: 1
Training loss: 0.4728703498840332
Validation loss: 1.760156266150936

Epoch: 6| Step: 2
Training loss: 0.34559914469718933
Validation loss: 1.8067911248053274

Epoch: 6| Step: 3
Training loss: 0.44438835978507996
Validation loss: 1.7674355814533849

Epoch: 6| Step: 4
Training loss: 0.2959206700325012
Validation loss: 1.7679665857745754

Epoch: 6| Step: 5
Training loss: 0.3186924457550049
Validation loss: 1.7491233477028467

Epoch: 6| Step: 6
Training loss: 0.5557320713996887
Validation loss: 1.7280005190962104

Epoch: 6| Step: 7
Training loss: 0.1990332007408142
Validation loss: 1.6781995142659833

Epoch: 6| Step: 8
Training loss: 0.20948070287704468
Validation loss: 1.705365643706373

Epoch: 6| Step: 9
Training loss: 0.4138951003551483
Validation loss: 1.6242779583059332

Epoch: 6| Step: 10
Training loss: 0.3597812056541443
Validation loss: 1.6527456006696146

Epoch: 6| Step: 11
Training loss: 0.269270658493042
Validation loss: 1.656698089773937

Epoch: 6| Step: 12
Training loss: 0.27761024236679077
Validation loss: 1.6311629279967277

Epoch: 6| Step: 13
Training loss: 0.4329596161842346
Validation loss: 1.6476400988076323

Epoch: 348| Step: 0
Training loss: 0.368863582611084
Validation loss: 1.659042723717228

Epoch: 6| Step: 1
Training loss: 0.2279893457889557
Validation loss: 1.6771368262588338

Epoch: 6| Step: 2
Training loss: 0.4606865644454956
Validation loss: 1.705836264036035

Epoch: 6| Step: 3
Training loss: 0.24930916726589203
Validation loss: 1.719694637483166

Epoch: 6| Step: 4
Training loss: 0.2672748565673828
Validation loss: 1.7573215653819423

Epoch: 6| Step: 5
Training loss: 0.38212302327156067
Validation loss: 1.7707784855237572

Epoch: 6| Step: 6
Training loss: 0.28564000129699707
Validation loss: 1.7756013178056287

Epoch: 6| Step: 7
Training loss: 0.3244311213493347
Validation loss: 1.7785134020672049

Epoch: 6| Step: 8
Training loss: 0.32982927560806274
Validation loss: 1.7842174191628732

Epoch: 6| Step: 9
Training loss: 0.6483084559440613
Validation loss: 1.717819195921703

Epoch: 6| Step: 10
Training loss: 0.19040563702583313
Validation loss: 1.6875080382952126

Epoch: 6| Step: 11
Training loss: 0.3326571583747864
Validation loss: 1.6744274593168689

Epoch: 6| Step: 12
Training loss: 0.32568055391311646
Validation loss: 1.657434509646508

Epoch: 6| Step: 13
Training loss: 0.39492154121398926
Validation loss: 1.6571083504666564

Epoch: 349| Step: 0
Training loss: 0.1999487280845642
Validation loss: 1.6504079808471024

Epoch: 6| Step: 1
Training loss: 0.26521268486976624
Validation loss: 1.678315604886701

Epoch: 6| Step: 2
Training loss: 0.25636985898017883
Validation loss: 1.6679010724508634

Epoch: 6| Step: 3
Training loss: 0.2799091339111328
Validation loss: 1.693957612078677

Epoch: 6| Step: 4
Training loss: 0.30278581380844116
Validation loss: 1.696276771124973

Epoch: 6| Step: 5
Training loss: 0.7071214914321899
Validation loss: 1.6989367828574231

Epoch: 6| Step: 6
Training loss: 0.514293372631073
Validation loss: 1.7136249157690233

Epoch: 6| Step: 7
Training loss: 0.3023204803466797
Validation loss: 1.711224223977776

Epoch: 6| Step: 8
Training loss: 0.48888668417930603
Validation loss: 1.725146657677107

Epoch: 6| Step: 9
Training loss: 0.30399495363235474
Validation loss: 1.689986571188896

Epoch: 6| Step: 10
Training loss: 0.44277873635292053
Validation loss: 1.681242457000158

Epoch: 6| Step: 11
Training loss: 0.2382977306842804
Validation loss: 1.7094453227135442

Epoch: 6| Step: 12
Training loss: 0.17819854617118835
Validation loss: 1.6987103492982927

Epoch: 6| Step: 13
Training loss: 0.31842589378356934
Validation loss: 1.7153426280585669

Epoch: 350| Step: 0
Training loss: 0.3078818619251251
Validation loss: 1.7260631284406107

Epoch: 6| Step: 1
Training loss: 0.25725263357162476
Validation loss: 1.741335707326089

Epoch: 6| Step: 2
Training loss: 0.20539002120494843
Validation loss: 1.7345400074476838

Epoch: 6| Step: 3
Training loss: 0.2001059353351593
Validation loss: 1.7692930095939225

Epoch: 6| Step: 4
Training loss: 0.40375804901123047
Validation loss: 1.7725711791746077

Epoch: 6| Step: 5
Training loss: 0.14847354590892792
Validation loss: 1.763312275691699

Epoch: 6| Step: 6
Training loss: 0.32890158891677856
Validation loss: 1.7873259680245512

Epoch: 6| Step: 7
Training loss: 0.2796628475189209
Validation loss: 1.8101284696209816

Epoch: 6| Step: 8
Training loss: 0.6001826524734497
Validation loss: 1.790291388829549

Epoch: 6| Step: 9
Training loss: 0.2748388648033142
Validation loss: 1.75866650765942

Epoch: 6| Step: 10
Training loss: 0.2860599756240845
Validation loss: 1.7212700561810566

Epoch: 6| Step: 11
Training loss: 0.25601619482040405
Validation loss: 1.6934124141611078

Epoch: 6| Step: 12
Training loss: 0.4183349311351776
Validation loss: 1.6612971277647122

Epoch: 6| Step: 13
Training loss: 0.7743462324142456
Validation loss: 1.656930487643006

Epoch: 351| Step: 0
Training loss: 0.3457646369934082
Validation loss: 1.6349727428087624

Epoch: 6| Step: 1
Training loss: 0.36291080713272095
Validation loss: 1.6236919472294469

Epoch: 6| Step: 2
Training loss: 0.2956690192222595
Validation loss: 1.6651105124463317

Epoch: 6| Step: 3
Training loss: 0.2261941283941269
Validation loss: 1.6590027950143302

Epoch: 6| Step: 4
Training loss: 0.2683056592941284
Validation loss: 1.6975845072859077

Epoch: 6| Step: 5
Training loss: 0.3024631142616272
Validation loss: 1.7175562907290716

Epoch: 6| Step: 6
Training loss: 0.30271095037460327
Validation loss: 1.7241851873295282

Epoch: 6| Step: 7
Training loss: 0.27649548649787903
Validation loss: 1.746810898985914

Epoch: 6| Step: 8
Training loss: 0.6693562269210815
Validation loss: 1.7207217267764512

Epoch: 6| Step: 9
Training loss: 0.34232205152511597
Validation loss: 1.7353705808680544

Epoch: 6| Step: 10
Training loss: 0.3880244791507721
Validation loss: 1.7206367023529545

Epoch: 6| Step: 11
Training loss: 0.30959445238113403
Validation loss: 1.6913750569025676

Epoch: 6| Step: 12
Training loss: 0.35732126235961914
Validation loss: 1.7131127131882535

Epoch: 6| Step: 13
Training loss: 0.11623106896877289
Validation loss: 1.6728849231555898

Epoch: 352| Step: 0
Training loss: 0.46379199624061584
Validation loss: 1.6570620793168263

Epoch: 6| Step: 1
Training loss: 0.27112945914268494
Validation loss: 1.6475379095282605

Epoch: 6| Step: 2
Training loss: 0.2782614231109619
Validation loss: 1.638815733694261

Epoch: 6| Step: 3
Training loss: 0.2723359167575836
Validation loss: 1.6189172806278351

Epoch: 6| Step: 4
Training loss: 0.2900303900241852
Validation loss: 1.62684493167426

Epoch: 6| Step: 5
Training loss: 0.16944050788879395
Validation loss: 1.621815727603051

Epoch: 6| Step: 6
Training loss: 0.287115216255188
Validation loss: 1.6540135978370585

Epoch: 6| Step: 7
Training loss: 0.24689170718193054
Validation loss: 1.6345013610778316

Epoch: 6| Step: 8
Training loss: 0.22249361872673035
Validation loss: 1.628062613548771

Epoch: 6| Step: 9
Training loss: 0.5832531452178955
Validation loss: 1.668450221579562

Epoch: 6| Step: 10
Training loss: 0.5182816386222839
Validation loss: 1.6759903943666847

Epoch: 6| Step: 11
Training loss: 0.4215448796749115
Validation loss: 1.6847491866798812

Epoch: 6| Step: 12
Training loss: 0.237357497215271
Validation loss: 1.723399721166139

Epoch: 6| Step: 13
Training loss: 0.29776838421821594
Validation loss: 1.7353639705206758

Epoch: 353| Step: 0
Training loss: 0.34680962562561035
Validation loss: 1.7303785457405993

Epoch: 6| Step: 1
Training loss: 0.6862950325012207
Validation loss: 1.7770460754312494

Epoch: 6| Step: 2
Training loss: 0.24301230907440186
Validation loss: 1.78541148349803

Epoch: 6| Step: 3
Training loss: 0.2718358635902405
Validation loss: 1.8009824868171447

Epoch: 6| Step: 4
Training loss: 0.21350954473018646
Validation loss: 1.8033710474609046

Epoch: 6| Step: 5
Training loss: 0.2528632879257202
Validation loss: 1.7847455739974976

Epoch: 6| Step: 6
Training loss: 0.4409230351448059
Validation loss: 1.7920302755089217

Epoch: 6| Step: 7
Training loss: 0.2652858793735504
Validation loss: 1.7787513950819611

Epoch: 6| Step: 8
Training loss: 0.3102586269378662
Validation loss: 1.750955799574493

Epoch: 6| Step: 9
Training loss: 0.35203784704208374
Validation loss: 1.700194780544568

Epoch: 6| Step: 10
Training loss: 0.34206849336624146
Validation loss: 1.6833516128601567

Epoch: 6| Step: 11
Training loss: 0.3155127167701721
Validation loss: 1.6754476152440554

Epoch: 6| Step: 12
Training loss: 0.3853582739830017
Validation loss: 1.6694835616696266

Epoch: 6| Step: 13
Training loss: 0.1701236516237259
Validation loss: 1.6368153120881768

Epoch: 354| Step: 0
Training loss: 0.44085007905960083
Validation loss: 1.664396814120713

Epoch: 6| Step: 1
Training loss: 0.2651962637901306
Validation loss: 1.6472988949027112

Epoch: 6| Step: 2
Training loss: 0.2691410183906555
Validation loss: 1.6475932598114014

Epoch: 6| Step: 3
Training loss: 0.4268655776977539
Validation loss: 1.6817952125303206

Epoch: 6| Step: 4
Training loss: 0.1844596564769745
Validation loss: 1.6558449217068252

Epoch: 6| Step: 5
Training loss: 0.2551943063735962
Validation loss: 1.662393295636741

Epoch: 6| Step: 6
Training loss: 0.2631880044937134
Validation loss: 1.6783371458771408

Epoch: 6| Step: 7
Training loss: 0.12694376707077026
Validation loss: 1.7200678849733004

Epoch: 6| Step: 8
Training loss: 0.7410256862640381
Validation loss: 1.670452235847391

Epoch: 6| Step: 9
Training loss: 0.5377810001373291
Validation loss: 1.7013373054483885

Epoch: 6| Step: 10
Training loss: 0.27624911069869995
Validation loss: 1.6916901616639988

Epoch: 6| Step: 11
Training loss: 0.3194946050643921
Validation loss: 1.7204405780761474

Epoch: 6| Step: 12
Training loss: 0.19686362147331238
Validation loss: 1.7271661053421676

Epoch: 6| Step: 13
Training loss: 0.21586009860038757
Validation loss: 1.707965059946942

Epoch: 355| Step: 0
Training loss: 0.20417580008506775
Validation loss: 1.733878859909632

Epoch: 6| Step: 1
Training loss: 0.24894246459007263
Validation loss: 1.7102532540598223

Epoch: 6| Step: 2
Training loss: 0.202082097530365
Validation loss: 1.6988053911475725

Epoch: 6| Step: 3
Training loss: 0.374588280916214
Validation loss: 1.7239524202962075

Epoch: 6| Step: 4
Training loss: 0.2919803857803345
Validation loss: 1.744719604010223

Epoch: 6| Step: 5
Training loss: 0.14741770923137665
Validation loss: 1.7068364466390302

Epoch: 6| Step: 6
Training loss: 0.25101298093795776
Validation loss: 1.7435449643801617

Epoch: 6| Step: 7
Training loss: 0.5744671821594238
Validation loss: 1.7049834958968624

Epoch: 6| Step: 8
Training loss: 0.3553932011127472
Validation loss: 1.7212859789530437

Epoch: 6| Step: 9
Training loss: 0.20958563685417175
Validation loss: 1.725974844348046

Epoch: 6| Step: 10
Training loss: 0.21272483468055725
Validation loss: 1.7123999159823182

Epoch: 6| Step: 11
Training loss: 0.811538577079773
Validation loss: 1.693630991443511

Epoch: 6| Step: 12
Training loss: 0.2383526861667633
Validation loss: 1.694916502121956

Epoch: 6| Step: 13
Training loss: 0.12317562103271484
Validation loss: 1.7454997365192702

Epoch: 356| Step: 0
Training loss: 0.16239777207374573
Validation loss: 1.7133397568938553

Epoch: 6| Step: 1
Training loss: 0.40594398975372314
Validation loss: 1.7268885386887418

Epoch: 6| Step: 2
Training loss: 0.2974557876586914
Validation loss: 1.7442087998954199

Epoch: 6| Step: 3
Training loss: 0.33387768268585205
Validation loss: 1.7726719135879188

Epoch: 6| Step: 4
Training loss: 0.24776199460029602
Validation loss: 1.764763552655456

Epoch: 6| Step: 5
Training loss: 0.6855300664901733
Validation loss: 1.7446440073751635

Epoch: 6| Step: 6
Training loss: 0.20491553843021393
Validation loss: 1.7421474687514766

Epoch: 6| Step: 7
Training loss: 0.3020601272583008
Validation loss: 1.7240265031014719

Epoch: 6| Step: 8
Training loss: 0.3816972076892853
Validation loss: 1.7292700147116056

Epoch: 6| Step: 9
Training loss: 0.2375500202178955
Validation loss: 1.6772725159122097

Epoch: 6| Step: 10
Training loss: 0.35054901242256165
Validation loss: 1.6779136824351486

Epoch: 6| Step: 11
Training loss: 0.25740328431129456
Validation loss: 1.6609505094507688

Epoch: 6| Step: 12
Training loss: 0.48466384410858154
Validation loss: 1.6808568508394304

Epoch: 6| Step: 13
Training loss: 0.24288643896579742
Validation loss: 1.644098299805836

Epoch: 357| Step: 0
Training loss: 0.2265232354402542
Validation loss: 1.6270662956340338

Epoch: 6| Step: 1
Training loss: 0.29404300451278687
Validation loss: 1.6777780017545145

Epoch: 6| Step: 2
Training loss: 0.18589729070663452
Validation loss: 1.665471678139061

Epoch: 6| Step: 3
Training loss: 0.22559809684753418
Validation loss: 1.6933815927915676

Epoch: 6| Step: 4
Training loss: 0.38313767313957214
Validation loss: 1.6573771046053978

Epoch: 6| Step: 5
Training loss: 0.4193188548088074
Validation loss: 1.7173191924248972

Epoch: 6| Step: 6
Training loss: 0.200829416513443
Validation loss: 1.7181879986998856

Epoch: 6| Step: 7
Training loss: 0.2603837847709656
Validation loss: 1.702549567786596

Epoch: 6| Step: 8
Training loss: 0.28513166308403015
Validation loss: 1.6866036474063832

Epoch: 6| Step: 9
Training loss: 0.5122041702270508
Validation loss: 1.7047120140444847

Epoch: 6| Step: 10
Training loss: 0.291402131319046
Validation loss: 1.710545870565599

Epoch: 6| Step: 11
Training loss: 0.565237283706665
Validation loss: 1.7096428230244627

Epoch: 6| Step: 12
Training loss: 0.38625597953796387
Validation loss: 1.678061221235542

Epoch: 6| Step: 13
Training loss: 0.1853354275226593
Validation loss: 1.6746238316259077

Epoch: 358| Step: 0
Training loss: 0.3338071405887604
Validation loss: 1.6422922624054777

Epoch: 6| Step: 1
Training loss: 0.4720163345336914
Validation loss: 1.6477890783740627

Epoch: 6| Step: 2
Training loss: 0.27871793508529663
Validation loss: 1.6407231335998864

Epoch: 6| Step: 3
Training loss: 0.2476121485233307
Validation loss: 1.6419600158609369

Epoch: 6| Step: 4
Training loss: 0.2736018896102905
Validation loss: 1.6559720449550177

Epoch: 6| Step: 5
Training loss: 0.25552433729171753
Validation loss: 1.657348059838818

Epoch: 6| Step: 6
Training loss: 0.5431463122367859
Validation loss: 1.698267170177993

Epoch: 6| Step: 7
Training loss: 0.3072529733181
Validation loss: 1.7644318137117612

Epoch: 6| Step: 8
Training loss: 0.28817927837371826
Validation loss: 1.7776434908631027

Epoch: 6| Step: 9
Training loss: 0.2678043246269226
Validation loss: 1.7771584064729753

Epoch: 6| Step: 10
Training loss: 0.2534773349761963
Validation loss: 1.7835680419398892

Epoch: 6| Step: 11
Training loss: 0.3817739486694336
Validation loss: 1.763398995963476

Epoch: 6| Step: 12
Training loss: 0.2048896849155426
Validation loss: 1.7385201748981272

Epoch: 6| Step: 13
Training loss: 0.18362829089164734
Validation loss: 1.7456830650247552

Epoch: 359| Step: 0
Training loss: 0.19304899871349335
Validation loss: 1.7399480009591708

Epoch: 6| Step: 1
Training loss: 0.11364206671714783
Validation loss: 1.7230346055441006

Epoch: 6| Step: 2
Training loss: 0.28639674186706543
Validation loss: 1.7044854330760177

Epoch: 6| Step: 3
Training loss: 0.333918035030365
Validation loss: 1.6768521570390271

Epoch: 6| Step: 4
Training loss: 0.24365559220314026
Validation loss: 1.6967582702636719

Epoch: 6| Step: 5
Training loss: 0.21298861503601074
Validation loss: 1.6707976402774933

Epoch: 6| Step: 6
Training loss: 0.3770991563796997
Validation loss: 1.669417582532411

Epoch: 6| Step: 7
Training loss: 0.2201189398765564
Validation loss: 1.6817153551245247

Epoch: 6| Step: 8
Training loss: 0.4530491232872009
Validation loss: 1.6695192885655228

Epoch: 6| Step: 9
Training loss: 0.20482563972473145
Validation loss: 1.7053236243545369

Epoch: 6| Step: 10
Training loss: 0.3976048231124878
Validation loss: 1.6777532433950773

Epoch: 6| Step: 11
Training loss: 0.6556929349899292
Validation loss: 1.6992756602584675

Epoch: 6| Step: 12
Training loss: 0.4376642107963562
Validation loss: 1.6974645045495802

Epoch: 6| Step: 13
Training loss: 0.44877174496650696
Validation loss: 1.7357202960598854

Epoch: 360| Step: 0
Training loss: 0.2250170260667801
Validation loss: 1.7422600869209535

Epoch: 6| Step: 1
Training loss: 0.28997260332107544
Validation loss: 1.7244639627395137

Epoch: 6| Step: 2
Training loss: 0.3915727734565735
Validation loss: 1.7653210099025438

Epoch: 6| Step: 3
Training loss: 0.5684628486633301
Validation loss: 1.7669249452570432

Epoch: 6| Step: 4
Training loss: 0.2880786061286926
Validation loss: 1.7626216129590107

Epoch: 6| Step: 5
Training loss: 0.5091292858123779
Validation loss: 1.6914874379352858

Epoch: 6| Step: 6
Training loss: 0.18300816416740417
Validation loss: 1.696037866735971

Epoch: 6| Step: 7
Training loss: 0.23284387588500977
Validation loss: 1.651792755690954

Epoch: 6| Step: 8
Training loss: 0.29727303981781006
Validation loss: 1.654799371637324

Epoch: 6| Step: 9
Training loss: 0.18834711611270905
Validation loss: 1.6547460440666444

Epoch: 6| Step: 10
Training loss: 0.34627431631088257
Validation loss: 1.6351230003500496

Epoch: 6| Step: 11
Training loss: 0.3256806433200836
Validation loss: 1.6449693890028103

Epoch: 6| Step: 12
Training loss: 0.3191174268722534
Validation loss: 1.6460898383971183

Epoch: 6| Step: 13
Training loss: 0.3531210720539093
Validation loss: 1.6654724010857203

Epoch: 361| Step: 0
Training loss: 0.1793035864830017
Validation loss: 1.6751766691925705

Epoch: 6| Step: 1
Training loss: 0.19222885370254517
Validation loss: 1.726475114463478

Epoch: 6| Step: 2
Training loss: 0.6161423325538635
Validation loss: 1.740566768953877

Epoch: 6| Step: 3
Training loss: 0.2084815949201584
Validation loss: 1.7438905982561008

Epoch: 6| Step: 4
Training loss: 0.24079358577728271
Validation loss: 1.7580254834185365

Epoch: 6| Step: 5
Training loss: 0.28879761695861816
Validation loss: 1.7529863503671461

Epoch: 6| Step: 6
Training loss: 0.23230068385601044
Validation loss: 1.7224427730806413

Epoch: 6| Step: 7
Training loss: 0.28920912742614746
Validation loss: 1.6885931440578994

Epoch: 6| Step: 8
Training loss: 0.4264380633831024
Validation loss: 1.664338017022738

Epoch: 6| Step: 9
Training loss: 0.22775748372077942
Validation loss: 1.6296120523124613

Epoch: 6| Step: 10
Training loss: 0.40570998191833496
Validation loss: 1.6131824524171892

Epoch: 6| Step: 11
Training loss: 0.35670042037963867
Validation loss: 1.6079089269843152

Epoch: 6| Step: 12
Training loss: 0.27718454599380493
Validation loss: 1.6437488294416858

Epoch: 6| Step: 13
Training loss: 0.3761565685272217
Validation loss: 1.6223123560669601

Epoch: 362| Step: 0
Training loss: 0.26298239827156067
Validation loss: 1.623048077347458

Epoch: 6| Step: 1
Training loss: 0.18516802787780762
Validation loss: 1.6741106522980558

Epoch: 6| Step: 2
Training loss: 0.3402780294418335
Validation loss: 1.6354653091840847

Epoch: 6| Step: 3
Training loss: 0.37202703952789307
Validation loss: 1.7104326332769086

Epoch: 6| Step: 4
Training loss: 0.32532358169555664
Validation loss: 1.724961175713488

Epoch: 6| Step: 5
Training loss: 0.1741492748260498
Validation loss: 1.7598485741564023

Epoch: 6| Step: 6
Training loss: 0.36823391914367676
Validation loss: 1.7611114933926573

Epoch: 6| Step: 7
Training loss: 0.24927598237991333
Validation loss: 1.73252244405849

Epoch: 6| Step: 8
Training loss: 0.22509270906448364
Validation loss: 1.7172516930487849

Epoch: 6| Step: 9
Training loss: 0.3744552433490753
Validation loss: 1.7100058665839575

Epoch: 6| Step: 10
Training loss: 0.4405044913291931
Validation loss: 1.7204349989532142

Epoch: 6| Step: 11
Training loss: 0.5086180567741394
Validation loss: 1.6886798527932936

Epoch: 6| Step: 12
Training loss: 0.4102029800415039
Validation loss: 1.7039412567692418

Epoch: 6| Step: 13
Training loss: 0.19402268528938293
Validation loss: 1.6599407811318674

Epoch: 363| Step: 0
Training loss: 0.7769460678100586
Validation loss: 1.6595867961965582

Epoch: 6| Step: 1
Training loss: 0.15849587321281433
Validation loss: 1.6535906817323418

Epoch: 6| Step: 2
Training loss: 0.26086512207984924
Validation loss: 1.660024663453461

Epoch: 6| Step: 3
Training loss: 0.2803773880004883
Validation loss: 1.6653268978159914

Epoch: 6| Step: 4
Training loss: 0.2328127920627594
Validation loss: 1.6799336646192817

Epoch: 6| Step: 5
Training loss: 0.2505617141723633
Validation loss: 1.6650546443077825

Epoch: 6| Step: 6
Training loss: 0.16171012818813324
Validation loss: 1.7389586125650713

Epoch: 6| Step: 7
Training loss: 0.24502159655094147
Validation loss: 1.7530098730517971

Epoch: 6| Step: 8
Training loss: 0.2432309240102768
Validation loss: 1.7619050369467786

Epoch: 6| Step: 9
Training loss: 0.19393835961818695
Validation loss: 1.7583378027844172

Epoch: 6| Step: 10
Training loss: 0.3067985773086548
Validation loss: 1.7519688067897674

Epoch: 6| Step: 11
Training loss: 0.41763630509376526
Validation loss: 1.7342471499596872

Epoch: 6| Step: 12
Training loss: 0.24311476945877075
Validation loss: 1.6776950564435733

Epoch: 6| Step: 13
Training loss: 0.5419229865074158
Validation loss: 1.6705637503695745

Epoch: 364| Step: 0
Training loss: 0.5878549218177795
Validation loss: 1.694179129856889

Epoch: 6| Step: 1
Training loss: 0.3106249272823334
Validation loss: 1.69899703866692

Epoch: 6| Step: 2
Training loss: 0.12158798426389694
Validation loss: 1.669513394755702

Epoch: 6| Step: 3
Training loss: 0.1728869080543518
Validation loss: 1.652372565320743

Epoch: 6| Step: 4
Training loss: 0.2189047783613205
Validation loss: 1.645067604639197

Epoch: 6| Step: 5
Training loss: 0.24201509356498718
Validation loss: 1.6500003094314246

Epoch: 6| Step: 6
Training loss: 0.36569464206695557
Validation loss: 1.6497738322904032

Epoch: 6| Step: 7
Training loss: 0.30366384983062744
Validation loss: 1.6444067775562246

Epoch: 6| Step: 8
Training loss: 0.322322815656662
Validation loss: 1.6496326301687507

Epoch: 6| Step: 9
Training loss: 0.39557865262031555
Validation loss: 1.6727451444954

Epoch: 6| Step: 10
Training loss: 0.3621882200241089
Validation loss: 1.666225410917754

Epoch: 6| Step: 11
Training loss: 0.4923747777938843
Validation loss: 1.666426315102526

Epoch: 6| Step: 12
Training loss: 0.27796730399131775
Validation loss: 1.6717679372397802

Epoch: 6| Step: 13
Training loss: 0.1865171641111374
Validation loss: 1.652780532836914

Epoch: 365| Step: 0
Training loss: 0.337065190076828
Validation loss: 1.6561844938544816

Epoch: 6| Step: 1
Training loss: 0.29960447549819946
Validation loss: 1.650882964493126

Epoch: 6| Step: 2
Training loss: 0.20412248373031616
Validation loss: 1.6454263989643385

Epoch: 6| Step: 3
Training loss: 0.19735127687454224
Validation loss: 1.6183026964946459

Epoch: 6| Step: 4
Training loss: 0.16253647208213806
Validation loss: 1.6399325542552496

Epoch: 6| Step: 5
Training loss: 0.36417442560195923
Validation loss: 1.605967535767504

Epoch: 6| Step: 6
Training loss: 0.2028966099023819
Validation loss: 1.6339072540242185

Epoch: 6| Step: 7
Training loss: 0.47371166944503784
Validation loss: 1.6087165622300998

Epoch: 6| Step: 8
Training loss: 0.19610285758972168
Validation loss: 1.6185018298446492

Epoch: 6| Step: 9
Training loss: 0.20933537185192108
Validation loss: 1.6163028260712982

Epoch: 6| Step: 10
Training loss: 0.3389371633529663
Validation loss: 1.5978536464834725

Epoch: 6| Step: 11
Training loss: 0.3157787322998047
Validation loss: 1.5990031842262513

Epoch: 6| Step: 12
Training loss: 0.6034448146820068
Validation loss: 1.5971776029115081

Epoch: 6| Step: 13
Training loss: 0.2564444839954376
Validation loss: 1.6092763652083695

Epoch: 366| Step: 0
Training loss: 0.2053970843553543
Validation loss: 1.6294940902340798

Epoch: 6| Step: 1
Training loss: 0.29695287346839905
Validation loss: 1.6477833819645706

Epoch: 6| Step: 2
Training loss: 0.3023069202899933
Validation loss: 1.6710065398164975

Epoch: 6| Step: 3
Training loss: 0.2285412847995758
Validation loss: 1.6665910866952711

Epoch: 6| Step: 4
Training loss: 0.12976667284965515
Validation loss: 1.722227519558322

Epoch: 6| Step: 5
Training loss: 0.48514658212661743
Validation loss: 1.6834199774649836

Epoch: 6| Step: 6
Training loss: 0.21864759922027588
Validation loss: 1.700175351994012

Epoch: 6| Step: 7
Training loss: 0.3013566732406616
Validation loss: 1.6848006069019277

Epoch: 6| Step: 8
Training loss: 0.6705405712127686
Validation loss: 1.6494223610047372

Epoch: 6| Step: 9
Training loss: 0.22173812985420227
Validation loss: 1.645159944411247

Epoch: 6| Step: 10
Training loss: 0.16097071766853333
Validation loss: 1.6359492540359497

Epoch: 6| Step: 11
Training loss: 0.26328739523887634
Validation loss: 1.6528269270414948

Epoch: 6| Step: 12
Training loss: 0.45257341861724854
Validation loss: 1.631469734253422

Epoch: 6| Step: 13
Training loss: 0.36556345224380493
Validation loss: 1.6371986276359969

Epoch: 367| Step: 0
Training loss: 0.28716516494750977
Validation loss: 1.631510321811963

Epoch: 6| Step: 1
Training loss: 0.28921476006507874
Validation loss: 1.6354525601992043

Epoch: 6| Step: 2
Training loss: 0.24862778186798096
Validation loss: 1.617601470280719

Epoch: 6| Step: 3
Training loss: 0.6147611141204834
Validation loss: 1.6711589110794889

Epoch: 6| Step: 4
Training loss: 0.23679743707180023
Validation loss: 1.6657905309431014

Epoch: 6| Step: 5
Training loss: 0.26876649260520935
Validation loss: 1.685167138294507

Epoch: 6| Step: 6
Training loss: 0.24966378509998322
Validation loss: 1.7093266953704178

Epoch: 6| Step: 7
Training loss: 0.3401087522506714
Validation loss: 1.7090159436707855

Epoch: 6| Step: 8
Training loss: 0.2730340361595154
Validation loss: 1.7341678552730109

Epoch: 6| Step: 9
Training loss: 0.1832253783941269
Validation loss: 1.7201267211667952

Epoch: 6| Step: 10
Training loss: 0.3510718047618866
Validation loss: 1.708316364595967

Epoch: 6| Step: 11
Training loss: 0.2960371971130371
Validation loss: 1.67469754270328

Epoch: 6| Step: 12
Training loss: 0.21566569805145264
Validation loss: 1.6623604682184034

Epoch: 6| Step: 13
Training loss: 0.43620848655700684
Validation loss: 1.6138065322752921

Epoch: 368| Step: 0
Training loss: 0.672806978225708
Validation loss: 1.6292582673411216

Epoch: 6| Step: 1
Training loss: 0.13192598521709442
Validation loss: 1.6157719063502487

Epoch: 6| Step: 2
Training loss: 0.3044254779815674
Validation loss: 1.6603677477887882

Epoch: 6| Step: 3
Training loss: 0.3671170473098755
Validation loss: 1.6081939692138343

Epoch: 6| Step: 4
Training loss: 0.22415383160114288
Validation loss: 1.6282012642070811

Epoch: 6| Step: 5
Training loss: 0.2477424144744873
Validation loss: 1.624758735779793

Epoch: 6| Step: 6
Training loss: 0.21327918767929077
Validation loss: 1.6274878196818854

Epoch: 6| Step: 7
Training loss: 0.3071241080760956
Validation loss: 1.616955808413926

Epoch: 6| Step: 8
Training loss: 0.23871973156929016
Validation loss: 1.596680429673964

Epoch: 6| Step: 9
Training loss: 0.29521700739860535
Validation loss: 1.6309874532043294

Epoch: 6| Step: 10
Training loss: 0.3170439600944519
Validation loss: 1.6430278683221469

Epoch: 6| Step: 11
Training loss: 0.36155590415000916
Validation loss: 1.695535312416733

Epoch: 6| Step: 12
Training loss: 0.1901031881570816
Validation loss: 1.7051421320566567

Epoch: 6| Step: 13
Training loss: 0.3015827536582947
Validation loss: 1.701013877827634

Epoch: 369| Step: 0
Training loss: 0.22921745479106903
Validation loss: 1.6888831866684781

Epoch: 6| Step: 1
Training loss: 0.35241127014160156
Validation loss: 1.7001273196230653

Epoch: 6| Step: 2
Training loss: 0.226984903216362
Validation loss: 1.6700440965672976

Epoch: 6| Step: 3
Training loss: 0.31930920481681824
Validation loss: 1.6697935942680604

Epoch: 6| Step: 4
Training loss: 0.19101493060588837
Validation loss: 1.665445226494984

Epoch: 6| Step: 5
Training loss: 0.20076587796211243
Validation loss: 1.6454446264492568

Epoch: 6| Step: 6
Training loss: 0.5704575777053833
Validation loss: 1.6395700247057023

Epoch: 6| Step: 7
Training loss: 0.40346407890319824
Validation loss: 1.6051714522864229

Epoch: 6| Step: 8
Training loss: 0.3244120478630066
Validation loss: 1.5998810850163943

Epoch: 6| Step: 9
Training loss: 0.2575540244579315
Validation loss: 1.5792807250894525

Epoch: 6| Step: 10
Training loss: 0.27916333079338074
Validation loss: 1.6123349858868508

Epoch: 6| Step: 11
Training loss: 0.14960718154907227
Validation loss: 1.6221132060532928

Epoch: 6| Step: 12
Training loss: 0.253501296043396
Validation loss: 1.6393825161841609

Epoch: 6| Step: 13
Training loss: 0.4317571222782135
Validation loss: 1.6693610260563512

Epoch: 370| Step: 0
Training loss: 0.2975252866744995
Validation loss: 1.6712526698266306

Epoch: 6| Step: 1
Training loss: 0.6518232822418213
Validation loss: 1.6911004986814273

Epoch: 6| Step: 2
Training loss: 0.2787574529647827
Validation loss: 1.68494168660974

Epoch: 6| Step: 3
Training loss: 0.38842761516571045
Validation loss: 1.737595590212012

Epoch: 6| Step: 4
Training loss: 0.38613563776016235
Validation loss: 1.699433631794427

Epoch: 6| Step: 5
Training loss: 0.33382898569107056
Validation loss: 1.6886342712627944

Epoch: 6| Step: 6
Training loss: 0.3298880159854889
Validation loss: 1.6659707612888788

Epoch: 6| Step: 7
Training loss: 0.23330968618392944
Validation loss: 1.6610360068659629

Epoch: 6| Step: 8
Training loss: 0.2183760404586792
Validation loss: 1.6461305131194413

Epoch: 6| Step: 9
Training loss: 0.3822583556175232
Validation loss: 1.6361685722104964

Epoch: 6| Step: 10
Training loss: 0.3159264028072357
Validation loss: 1.6333499544410295

Epoch: 6| Step: 11
Training loss: 0.23284684121608734
Validation loss: 1.6201168952449676

Epoch: 6| Step: 12
Training loss: 0.22540174424648285
Validation loss: 1.5869779843156055

Epoch: 6| Step: 13
Training loss: 0.08753731846809387
Validation loss: 1.6291989305967927

Epoch: 371| Step: 0
Training loss: 0.19893737137317657
Validation loss: 1.6417704512996059

Epoch: 6| Step: 1
Training loss: 0.27140241861343384
Validation loss: 1.6538464138584752

Epoch: 6| Step: 2
Training loss: 0.16568921506404877
Validation loss: 1.656611337456652

Epoch: 6| Step: 3
Training loss: 0.20302391052246094
Validation loss: 1.6569089607525898

Epoch: 6| Step: 4
Training loss: 0.24711866676807404
Validation loss: 1.670542904125747

Epoch: 6| Step: 5
Training loss: 0.607577919960022
Validation loss: 1.651313017773372

Epoch: 6| Step: 6
Training loss: 0.31729573011398315
Validation loss: 1.6087135768705798

Epoch: 6| Step: 7
Training loss: 0.8553755283355713
Validation loss: 1.6392285952004053

Epoch: 6| Step: 8
Training loss: 0.28809070587158203
Validation loss: 1.6198875955356065

Epoch: 6| Step: 9
Training loss: 0.16445398330688477
Validation loss: 1.58288562169639

Epoch: 6| Step: 10
Training loss: 0.26280367374420166
Validation loss: 1.628909485314482

Epoch: 6| Step: 11
Training loss: 0.25198957324028015
Validation loss: 1.6556029217217558

Epoch: 6| Step: 12
Training loss: 0.10217426717281342
Validation loss: 1.6252565947912072

Epoch: 6| Step: 13
Training loss: 0.1151697114109993
Validation loss: 1.6344834604570944

Epoch: 372| Step: 0
Training loss: 0.2754426598548889
Validation loss: 1.6490568704502557

Epoch: 6| Step: 1
Training loss: 0.33733507990837097
Validation loss: 1.683443651404432

Epoch: 6| Step: 2
Training loss: 0.25355327129364014
Validation loss: 1.6872376011263939

Epoch: 6| Step: 3
Training loss: 0.3333864212036133
Validation loss: 1.7095683467003606

Epoch: 6| Step: 4
Training loss: 0.2021896094083786
Validation loss: 1.6728694464570733

Epoch: 6| Step: 5
Training loss: 0.2763881981372833
Validation loss: 1.7117359574123094

Epoch: 6| Step: 6
Training loss: 0.3793073892593384
Validation loss: 1.6849245717448573

Epoch: 6| Step: 7
Training loss: 0.255596399307251
Validation loss: 1.682035138530116

Epoch: 6| Step: 8
Training loss: 0.27157050371170044
Validation loss: 1.657162211274588

Epoch: 6| Step: 9
Training loss: 0.5789741277694702
Validation loss: 1.633778787428333

Epoch: 6| Step: 10
Training loss: 0.2890937328338623
Validation loss: 1.636695759270781

Epoch: 6| Step: 11
Training loss: 0.16034144163131714
Validation loss: 1.6140779256820679

Epoch: 6| Step: 12
Training loss: 0.24174487590789795
Validation loss: 1.5995337706740185

Epoch: 6| Step: 13
Training loss: 0.5151025056838989
Validation loss: 1.6064035687395322

Epoch: 373| Step: 0
Training loss: 0.23483581840991974
Validation loss: 1.59899184268008

Epoch: 6| Step: 1
Training loss: 0.34035736322402954
Validation loss: 1.6310406948930474

Epoch: 6| Step: 2
Training loss: 0.2680608630180359
Validation loss: 1.6164445530983709

Epoch: 6| Step: 3
Training loss: 0.15474125742912292
Validation loss: 1.611979562749145

Epoch: 6| Step: 4
Training loss: 0.35724925994873047
Validation loss: 1.6109735260727585

Epoch: 6| Step: 5
Training loss: 0.25547951459884644
Validation loss: 1.6528523199019893

Epoch: 6| Step: 6
Training loss: 0.29483065009117126
Validation loss: 1.6600419770004928

Epoch: 6| Step: 7
Training loss: 0.27270472049713135
Validation loss: 1.6575198711887482

Epoch: 6| Step: 8
Training loss: 0.3363126516342163
Validation loss: 1.6670696145744734

Epoch: 6| Step: 9
Training loss: 0.2465333342552185
Validation loss: 1.6709674507059076

Epoch: 6| Step: 10
Training loss: 0.2513183653354645
Validation loss: 1.678578269097113

Epoch: 6| Step: 11
Training loss: 0.16830287873744965
Validation loss: 1.682177105257588

Epoch: 6| Step: 12
Training loss: 0.6071453094482422
Validation loss: 1.6825931456781202

Epoch: 6| Step: 13
Training loss: 0.15557879209518433
Validation loss: 1.7019008257055794

Epoch: 374| Step: 0
Training loss: 0.25962206721305847
Validation loss: 1.6825895238948125

Epoch: 6| Step: 1
Training loss: 0.29711437225341797
Validation loss: 1.6711363561691777

Epoch: 6| Step: 2
Training loss: 0.3093012571334839
Validation loss: 1.671118720885246

Epoch: 6| Step: 3
Training loss: 0.24621745944023132
Validation loss: 1.6435608017829157

Epoch: 6| Step: 4
Training loss: 0.2885509431362152
Validation loss: 1.6206641786841935

Epoch: 6| Step: 5
Training loss: 0.2692531943321228
Validation loss: 1.6335660334556334

Epoch: 6| Step: 6
Training loss: 0.24621838331222534
Validation loss: 1.6038290172494867

Epoch: 6| Step: 7
Training loss: 0.32506904006004333
Validation loss: 1.622161421724545

Epoch: 6| Step: 8
Training loss: 0.23608222603797913
Validation loss: 1.6084515574157878

Epoch: 6| Step: 9
Training loss: 0.26916295289993286
Validation loss: 1.607707263321005

Epoch: 6| Step: 10
Training loss: 0.1672372817993164
Validation loss: 1.6168725759752336

Epoch: 6| Step: 11
Training loss: 0.7140610218048096
Validation loss: 1.6569735683420652

Epoch: 6| Step: 12
Training loss: 0.18729162216186523
Validation loss: 1.6793028513590496

Epoch: 6| Step: 13
Training loss: 0.2294502854347229
Validation loss: 1.6819504563526442

Epoch: 375| Step: 0
Training loss: 0.14153523743152618
Validation loss: 1.7009519171971146

Epoch: 6| Step: 1
Training loss: 0.35438549518585205
Validation loss: 1.7219759994937527

Epoch: 6| Step: 2
Training loss: 0.26775914430618286
Validation loss: 1.7345234053109282

Epoch: 6| Step: 3
Training loss: 0.26589635014533997
Validation loss: 1.72615602964996

Epoch: 6| Step: 4
Training loss: 0.2678883671760559
Validation loss: 1.7175511647296209

Epoch: 6| Step: 5
Training loss: 0.2526654601097107
Validation loss: 1.699308438967633

Epoch: 6| Step: 6
Training loss: 0.1957220584154129
Validation loss: 1.6823621206386115

Epoch: 6| Step: 7
Training loss: 0.6067799925804138
Validation loss: 1.6710932613700948

Epoch: 6| Step: 8
Training loss: 0.28523582220077515
Validation loss: 1.635352046258988

Epoch: 6| Step: 9
Training loss: 0.2777464985847473
Validation loss: 1.5900840759277344

Epoch: 6| Step: 10
Training loss: 0.3018384575843811
Validation loss: 1.5879551633711784

Epoch: 6| Step: 11
Training loss: 0.11660439521074295
Validation loss: 1.5790823287861322

Epoch: 6| Step: 12
Training loss: 0.20710885524749756
Validation loss: 1.5973230279901975

Epoch: 6| Step: 13
Training loss: 0.24701336026191711
Validation loss: 1.6113001056896743

Epoch: 376| Step: 0
Training loss: 0.25605759024620056
Validation loss: 1.6232958096329884

Epoch: 6| Step: 1
Training loss: 0.17282772064208984
Validation loss: 1.6602626526227562

Epoch: 6| Step: 2
Training loss: 0.22299563884735107
Validation loss: 1.6567779984525455

Epoch: 6| Step: 3
Training loss: 0.2019311785697937
Validation loss: 1.7045367943343295

Epoch: 6| Step: 4
Training loss: 0.12275764346122742
Validation loss: 1.701211110238106

Epoch: 6| Step: 5
Training loss: 0.5443458557128906
Validation loss: 1.7139240990402878

Epoch: 6| Step: 6
Training loss: 0.322405070066452
Validation loss: 1.6925178599613968

Epoch: 6| Step: 7
Training loss: 0.19115516543388367
Validation loss: 1.7130779617576188

Epoch: 6| Step: 8
Training loss: 0.1961643397808075
Validation loss: 1.7146822534581667

Epoch: 6| Step: 9
Training loss: 0.2406320869922638
Validation loss: 1.6975618626481743

Epoch: 6| Step: 10
Training loss: 0.22353489696979523
Validation loss: 1.7183505309525358

Epoch: 6| Step: 11
Training loss: 0.26038676500320435
Validation loss: 1.663771616515293

Epoch: 6| Step: 12
Training loss: 0.3550751805305481
Validation loss: 1.6497015376244821

Epoch: 6| Step: 13
Training loss: 0.3948248624801636
Validation loss: 1.6904241282452819

Epoch: 377| Step: 0
Training loss: 0.29659414291381836
Validation loss: 1.6697383106395762

Epoch: 6| Step: 1
Training loss: 0.27361804246902466
Validation loss: 1.6876852807178293

Epoch: 6| Step: 2
Training loss: 0.19099518656730652
Validation loss: 1.6424842656299632

Epoch: 6| Step: 3
Training loss: 0.20813170075416565
Validation loss: 1.662180241718087

Epoch: 6| Step: 4
Training loss: 0.24143636226654053
Validation loss: 1.6772212738631873

Epoch: 6| Step: 5
Training loss: 0.29575595259666443
Validation loss: 1.6465016565015238

Epoch: 6| Step: 6
Training loss: 0.2680795192718506
Validation loss: 1.6479458443580135

Epoch: 6| Step: 7
Training loss: 0.2659449279308319
Validation loss: 1.6489744263310586

Epoch: 6| Step: 8
Training loss: 0.20674319565296173
Validation loss: 1.666820324877257

Epoch: 6| Step: 9
Training loss: 0.24435469508171082
Validation loss: 1.6639009060398224

Epoch: 6| Step: 10
Training loss: 0.1732250452041626
Validation loss: 1.6875895825765466

Epoch: 6| Step: 11
Training loss: 0.22644230723381042
Validation loss: 1.6776058994313723

Epoch: 6| Step: 12
Training loss: 0.549580454826355
Validation loss: 1.67525040975181

Epoch: 6| Step: 13
Training loss: 0.26092529296875
Validation loss: 1.744569045241161

Epoch: 378| Step: 0
Training loss: 0.2569146156311035
Validation loss: 1.7128277594043362

Epoch: 6| Step: 1
Training loss: 0.34824278950691223
Validation loss: 1.7175842638938659

Epoch: 6| Step: 2
Training loss: 0.13293582201004028
Validation loss: 1.7274988274420462

Epoch: 6| Step: 3
Training loss: 0.28914669156074524
Validation loss: 1.6923748511140064

Epoch: 6| Step: 4
Training loss: 0.632849931716919
Validation loss: 1.7302969668501167

Epoch: 6| Step: 5
Training loss: 0.23087123036384583
Validation loss: 1.7061899515890306

Epoch: 6| Step: 6
Training loss: 0.14367106556892395
Validation loss: 1.6939423327804894

Epoch: 6| Step: 7
Training loss: 0.21201783418655396
Validation loss: 1.6478799773800759

Epoch: 6| Step: 8
Training loss: 0.18592405319213867
Validation loss: 1.650271737447349

Epoch: 6| Step: 9
Training loss: 0.20062243938446045
Validation loss: 1.6476693960928148

Epoch: 6| Step: 10
Training loss: 0.2642642557621002
Validation loss: 1.6532063048372987

Epoch: 6| Step: 11
Training loss: 0.26311880350112915
Validation loss: 1.6489240636107743

Epoch: 6| Step: 12
Training loss: 0.25481361150741577
Validation loss: 1.6271314031334334

Epoch: 6| Step: 13
Training loss: 0.3482228219509125
Validation loss: 1.637222961712909

Epoch: 379| Step: 0
Training loss: 0.21426576375961304
Validation loss: 1.6233704167027627

Epoch: 6| Step: 1
Training loss: 0.09503773599863052
Validation loss: 1.646373741088375

Epoch: 6| Step: 2
Training loss: 0.1614968627691269
Validation loss: 1.6905694289874005

Epoch: 6| Step: 3
Training loss: 0.2898871898651123
Validation loss: 1.689177591313598

Epoch: 6| Step: 4
Training loss: 0.4846590757369995
Validation loss: 1.71342501589047

Epoch: 6| Step: 5
Training loss: 0.12046532332897186
Validation loss: 1.6973402538607198

Epoch: 6| Step: 6
Training loss: 0.1976851224899292
Validation loss: 1.709342016968676

Epoch: 6| Step: 7
Training loss: 0.13373854756355286
Validation loss: 1.712034535664384

Epoch: 6| Step: 8
Training loss: 0.1786733716726303
Validation loss: 1.7252590605007705

Epoch: 6| Step: 9
Training loss: 0.1852477341890335
Validation loss: 1.7018563080859441

Epoch: 6| Step: 10
Training loss: 0.21484839916229248
Validation loss: 1.6817814714165145

Epoch: 6| Step: 11
Training loss: 0.34293338656425476
Validation loss: 1.6847671283188688

Epoch: 6| Step: 12
Training loss: 0.23462608456611633
Validation loss: 1.685701165148007

Epoch: 6| Step: 13
Training loss: 0.8448829650878906
Validation loss: 1.6755491713041901

Epoch: 380| Step: 0
Training loss: 0.12911128997802734
Validation loss: 1.6765454738370833

Epoch: 6| Step: 1
Training loss: 0.20344418287277222
Validation loss: 1.6426965857064852

Epoch: 6| Step: 2
Training loss: 0.3734690845012665
Validation loss: 1.642779274653363

Epoch: 6| Step: 3
Training loss: 0.23039597272872925
Validation loss: 1.6668278581352645

Epoch: 6| Step: 4
Training loss: 0.26563286781311035
Validation loss: 1.6527028211983301

Epoch: 6| Step: 5
Training loss: 0.24229907989501953
Validation loss: 1.640348055029428

Epoch: 6| Step: 6
Training loss: 0.12680335342884064
Validation loss: 1.6525532686582176

Epoch: 6| Step: 7
Training loss: 0.2438131868839264
Validation loss: 1.649674347651902

Epoch: 6| Step: 8
Training loss: 0.5424959659576416
Validation loss: 1.6215649099760159

Epoch: 6| Step: 9
Training loss: 0.1821499466896057
Validation loss: 1.6392200441770657

Epoch: 6| Step: 10
Training loss: 0.28484266996383667
Validation loss: 1.6844464976300475

Epoch: 6| Step: 11
Training loss: 0.1922616809606552
Validation loss: 1.6583829656724007

Epoch: 6| Step: 12
Training loss: 0.42825043201446533
Validation loss: 1.6836158178185905

Epoch: 6| Step: 13
Training loss: 0.14296290278434753
Validation loss: 1.6590567596497074

Epoch: 381| Step: 0
Training loss: 0.08531416952610016
Validation loss: 1.6756729054194626

Epoch: 6| Step: 1
Training loss: 0.20183536410331726
Validation loss: 1.6613317317860101

Epoch: 6| Step: 2
Training loss: 0.7105993032455444
Validation loss: 1.6406332241591586

Epoch: 6| Step: 3
Training loss: 0.16382673382759094
Validation loss: 1.6560781155863116

Epoch: 6| Step: 4
Training loss: 0.2795563042163849
Validation loss: 1.665087652462785

Epoch: 6| Step: 5
Training loss: 0.2333524525165558
Validation loss: 1.6745946753409602

Epoch: 6| Step: 6
Training loss: 0.26638543605804443
Validation loss: 1.6943671562338387

Epoch: 6| Step: 7
Training loss: 0.20586109161376953
Validation loss: 1.732694710454633

Epoch: 6| Step: 8
Training loss: 0.16475644707679749
Validation loss: 1.7367002246200398

Epoch: 6| Step: 9
Training loss: 0.2716699242591858
Validation loss: 1.7233743321511052

Epoch: 6| Step: 10
Training loss: 0.15867257118225098
Validation loss: 1.6811663848097607

Epoch: 6| Step: 11
Training loss: 0.28449341654777527
Validation loss: 1.6570199164011146

Epoch: 6| Step: 12
Training loss: 0.2971254587173462
Validation loss: 1.6382210876352044

Epoch: 6| Step: 13
Training loss: 0.33826231956481934
Validation loss: 1.6242688471271145

Epoch: 382| Step: 0
Training loss: 0.22277629375457764
Validation loss: 1.6266718141494259

Epoch: 6| Step: 1
Training loss: 0.18424932658672333
Validation loss: 1.6222965025132703

Epoch: 6| Step: 2
Training loss: 0.3157397210597992
Validation loss: 1.5826079101972683

Epoch: 6| Step: 3
Training loss: 0.19398507475852966
Validation loss: 1.631947402031191

Epoch: 6| Step: 4
Training loss: 0.1509326547384262
Validation loss: 1.6471456750746696

Epoch: 6| Step: 5
Training loss: 0.2181532084941864
Validation loss: 1.6930200963891961

Epoch: 6| Step: 6
Training loss: 0.2026287019252777
Validation loss: 1.735226413896007

Epoch: 6| Step: 7
Training loss: 0.3429417610168457
Validation loss: 1.7452386233114427

Epoch: 6| Step: 8
Training loss: 0.37955716252326965
Validation loss: 1.774234808901305

Epoch: 6| Step: 9
Training loss: 0.5399030447006226
Validation loss: 1.7639975060698807

Epoch: 6| Step: 10
Training loss: 0.32801634073257446
Validation loss: 1.787516151705096

Epoch: 6| Step: 11
Training loss: 0.29587456583976746
Validation loss: 1.7096286319917249

Epoch: 6| Step: 12
Training loss: 0.23873834311962128
Validation loss: 1.6652752096934984

Epoch: 6| Step: 13
Training loss: 0.34605276584625244
Validation loss: 1.6571941145004765

Epoch: 383| Step: 0
Training loss: 0.18136711418628693
Validation loss: 1.6077515675175575

Epoch: 6| Step: 1
Training loss: 0.3271270990371704
Validation loss: 1.601486344491282

Epoch: 6| Step: 2
Training loss: 0.27012842893600464
Validation loss: 1.5881636629822433

Epoch: 6| Step: 3
Training loss: 0.12131904065608978
Validation loss: 1.5866841795623943

Epoch: 6| Step: 4
Training loss: 0.2782402038574219
Validation loss: 1.5595254763480155

Epoch: 6| Step: 5
Training loss: 0.5129425525665283
Validation loss: 1.5786750675529562

Epoch: 6| Step: 6
Training loss: 0.38763946294784546
Validation loss: 1.6047507204035276

Epoch: 6| Step: 7
Training loss: 0.18630802631378174
Validation loss: 1.6152193796250127

Epoch: 6| Step: 8
Training loss: 0.290630966424942
Validation loss: 1.6394100996755785

Epoch: 6| Step: 9
Training loss: 0.22710652649402618
Validation loss: 1.6413029086205266

Epoch: 6| Step: 10
Training loss: 0.13249413669109344
Validation loss: 1.6537583079389346

Epoch: 6| Step: 11
Training loss: 0.18966218829154968
Validation loss: 1.6285310054338107

Epoch: 6| Step: 12
Training loss: 0.29895439743995667
Validation loss: 1.65746683074582

Epoch: 6| Step: 13
Training loss: 0.17732089757919312
Validation loss: 1.637230424470799

Epoch: 384| Step: 0
Training loss: 0.14244727790355682
Validation loss: 1.6492406527201335

Epoch: 6| Step: 1
Training loss: 0.18931572139263153
Validation loss: 1.6690386905465076

Epoch: 6| Step: 2
Training loss: 0.10215263813734055
Validation loss: 1.6466094524629655

Epoch: 6| Step: 3
Training loss: 0.21495088934898376
Validation loss: 1.6396634937614523

Epoch: 6| Step: 4
Training loss: 0.19978150725364685
Validation loss: 1.6412168292589084

Epoch: 6| Step: 5
Training loss: 0.25846803188323975
Validation loss: 1.6102483618643977

Epoch: 6| Step: 6
Training loss: 0.28916290402412415
Validation loss: 1.6457453312412385

Epoch: 6| Step: 7
Training loss: 0.27464598417282104
Validation loss: 1.62953850658991

Epoch: 6| Step: 8
Training loss: 0.21420201659202576
Validation loss: 1.6176413656562887

Epoch: 6| Step: 9
Training loss: 0.17601433396339417
Validation loss: 1.6633018729507283

Epoch: 6| Step: 10
Training loss: 0.12684008479118347
Validation loss: 1.6602796687874743

Epoch: 6| Step: 11
Training loss: 0.3319052755832672
Validation loss: 1.6526910707514773

Epoch: 6| Step: 12
Training loss: 0.5972726941108704
Validation loss: 1.6569547089197303

Epoch: 6| Step: 13
Training loss: 0.20622165501117706
Validation loss: 1.653266736256179

Epoch: 385| Step: 0
Training loss: 0.30122315883636475
Validation loss: 1.617848100200776

Epoch: 6| Step: 1
Training loss: 0.1264226883649826
Validation loss: 1.6582253017733175

Epoch: 6| Step: 2
Training loss: 0.25992971658706665
Validation loss: 1.6353131199395785

Epoch: 6| Step: 3
Training loss: 0.18638668954372406
Validation loss: 1.629605443246903

Epoch: 6| Step: 4
Training loss: 0.13976414501667023
Validation loss: 1.6431031214293612

Epoch: 6| Step: 5
Training loss: 0.2003767192363739
Validation loss: 1.6612496837492912

Epoch: 6| Step: 6
Training loss: 0.24216970801353455
Validation loss: 1.6535756536709365

Epoch: 6| Step: 7
Training loss: 0.3103201687335968
Validation loss: 1.678072529454385

Epoch: 6| Step: 8
Training loss: 0.19346334040164948
Validation loss: 1.6080448845381379

Epoch: 6| Step: 9
Training loss: 0.24621382355690002
Validation loss: 1.6389647491516606

Epoch: 6| Step: 10
Training loss: 0.14486703276634216
Validation loss: 1.6474267833976335

Epoch: 6| Step: 11
Training loss: 0.6100113391876221
Validation loss: 1.6579961751096992

Epoch: 6| Step: 12
Training loss: 0.20217552781105042
Validation loss: 1.6526292562484741

Epoch: 6| Step: 13
Training loss: 0.1637033075094223
Validation loss: 1.6684756304628106

Epoch: 386| Step: 0
Training loss: 0.23649027943611145
Validation loss: 1.65781081363719

Epoch: 6| Step: 1
Training loss: 0.36667829751968384
Validation loss: 1.6206436003408125

Epoch: 6| Step: 2
Training loss: 0.16360929608345032
Validation loss: 1.6087225316673197

Epoch: 6| Step: 3
Training loss: 0.2891402542591095
Validation loss: 1.6233440381224438

Epoch: 6| Step: 4
Training loss: 0.21766352653503418
Validation loss: 1.6047228773434956

Epoch: 6| Step: 5
Training loss: 0.25080057978630066
Validation loss: 1.6161683631199661

Epoch: 6| Step: 6
Training loss: 0.2182445079088211
Validation loss: 1.644364022439526

Epoch: 6| Step: 7
Training loss: 0.3462473750114441
Validation loss: 1.620483939365674

Epoch: 6| Step: 8
Training loss: 0.5656781792640686
Validation loss: 1.624862112024779

Epoch: 6| Step: 9
Training loss: 0.3010507822036743
Validation loss: 1.6496002610011766

Epoch: 6| Step: 10
Training loss: 0.21900887787342072
Validation loss: 1.6680668438634565

Epoch: 6| Step: 11
Training loss: 0.12496425956487656
Validation loss: 1.6871168267342351

Epoch: 6| Step: 12
Training loss: 0.17229950428009033
Validation loss: 1.6776091603822605

Epoch: 6| Step: 13
Training loss: 0.10255566984415054
Validation loss: 1.698350614117038

Epoch: 387| Step: 0
Training loss: 0.3094639182090759
Validation loss: 1.7106154349542433

Epoch: 6| Step: 1
Training loss: 0.17434649169445038
Validation loss: 1.727230324540087

Epoch: 6| Step: 2
Training loss: 0.15979105234146118
Validation loss: 1.705411405973537

Epoch: 6| Step: 3
Training loss: 0.2120324820280075
Validation loss: 1.6744533072235763

Epoch: 6| Step: 4
Training loss: 0.16103708744049072
Validation loss: 1.7395759167209748

Epoch: 6| Step: 5
Training loss: 0.24400600790977478
Validation loss: 1.7546040857991865

Epoch: 6| Step: 6
Training loss: 0.4189860224723816
Validation loss: 1.75862765953105

Epoch: 6| Step: 7
Training loss: 0.2359490692615509
Validation loss: 1.7369774951729724

Epoch: 6| Step: 8
Training loss: 0.720699667930603
Validation loss: 1.7357112117992934

Epoch: 6| Step: 9
Training loss: 0.2851320803165436
Validation loss: 1.6431377677507297

Epoch: 6| Step: 10
Training loss: 0.11813656985759735
Validation loss: 1.6464786901268909

Epoch: 6| Step: 11
Training loss: 0.21737483143806458
Validation loss: 1.6070371827771586

Epoch: 6| Step: 12
Training loss: 0.12211087346076965
Validation loss: 1.6112425737483527

Epoch: 6| Step: 13
Training loss: 0.20652952790260315
Validation loss: 1.6372722669314312

Epoch: 388| Step: 0
Training loss: 0.23698192834854126
Validation loss: 1.6120233061493083

Epoch: 6| Step: 1
Training loss: 0.2817486822605133
Validation loss: 1.6410752291320472

Epoch: 6| Step: 2
Training loss: 0.17758208513259888
Validation loss: 1.6226706145912089

Epoch: 6| Step: 3
Training loss: 0.533332347869873
Validation loss: 1.660418782182919

Epoch: 6| Step: 4
Training loss: 0.16526514291763306
Validation loss: 1.6449302293921029

Epoch: 6| Step: 5
Training loss: 0.14403057098388672
Validation loss: 1.648224046153407

Epoch: 6| Step: 6
Training loss: 0.20044371485710144
Validation loss: 1.6784376252082087

Epoch: 6| Step: 7
Training loss: 0.17505820095539093
Validation loss: 1.7140067674780404

Epoch: 6| Step: 8
Training loss: 0.23981769382953644
Validation loss: 1.7430015789565219

Epoch: 6| Step: 9
Training loss: 0.14770328998565674
Validation loss: 1.7439203569965978

Epoch: 6| Step: 10
Training loss: 0.16221436858177185
Validation loss: 1.752051668782388

Epoch: 6| Step: 11
Training loss: 0.30148595571517944
Validation loss: 1.7187728740835702

Epoch: 6| Step: 12
Training loss: 0.20852455496788025
Validation loss: 1.73567045375865

Epoch: 6| Step: 13
Training loss: 0.573493242263794
Validation loss: 1.7030719890389392

Epoch: 389| Step: 0
Training loss: 0.17650142312049866
Validation loss: 1.677396406409561

Epoch: 6| Step: 1
Training loss: 0.2135390043258667
Validation loss: 1.5946227645361295

Epoch: 6| Step: 2
Training loss: 0.23206865787506104
Validation loss: 1.5943346959288403

Epoch: 6| Step: 3
Training loss: 0.22597187757492065
Validation loss: 1.586586239517376

Epoch: 6| Step: 4
Training loss: 0.34815216064453125
Validation loss: 1.6002844302884993

Epoch: 6| Step: 5
Training loss: 0.2895382046699524
Validation loss: 1.6190361169076735

Epoch: 6| Step: 6
Training loss: 0.23655855655670166
Validation loss: 1.6066753813015517

Epoch: 6| Step: 7
Training loss: 0.2570774555206299
Validation loss: 1.6355690469024002

Epoch: 6| Step: 8
Training loss: 0.29524675011634827
Validation loss: 1.650780080467142

Epoch: 6| Step: 9
Training loss: 0.22346141934394836
Validation loss: 1.6701637506484985

Epoch: 6| Step: 10
Training loss: 0.11852891743183136
Validation loss: 1.6793355826408631

Epoch: 6| Step: 11
Training loss: 0.19601953029632568
Validation loss: 1.6999123224648096

Epoch: 6| Step: 12
Training loss: 0.5906323194503784
Validation loss: 1.7032363094309324

Epoch: 6| Step: 13
Training loss: 0.3277103006839752
Validation loss: 1.7080487564045896

Epoch: 390| Step: 0
Training loss: 0.2089128941297531
Validation loss: 1.7031901228812434

Epoch: 6| Step: 1
Training loss: 0.22320455312728882
Validation loss: 1.7110583743741434

Epoch: 6| Step: 2
Training loss: 0.516379714012146
Validation loss: 1.6748415359886744

Epoch: 6| Step: 3
Training loss: 0.20317143201828003
Validation loss: 1.6355013232077322

Epoch: 6| Step: 4
Training loss: 0.30756404995918274
Validation loss: 1.6011595969559045

Epoch: 6| Step: 5
Training loss: 0.2860787808895111
Validation loss: 1.6061092345945296

Epoch: 6| Step: 6
Training loss: 0.22578024864196777
Validation loss: 1.5728169077186174

Epoch: 6| Step: 7
Training loss: 0.1643686145544052
Validation loss: 1.6116619597199142

Epoch: 6| Step: 8
Training loss: 0.19671255350112915
Validation loss: 1.6021014669890046

Epoch: 6| Step: 9
Training loss: 0.30236995220184326
Validation loss: 1.5646208011975853

Epoch: 6| Step: 10
Training loss: 0.30589866638183594
Validation loss: 1.5788358565299743

Epoch: 6| Step: 11
Training loss: 0.23203599452972412
Validation loss: 1.5786781695581251

Epoch: 6| Step: 12
Training loss: 0.1138426885008812
Validation loss: 1.5928528321686612

Epoch: 6| Step: 13
Training loss: 0.1553499549627304
Validation loss: 1.634746801468634

Epoch: 391| Step: 0
Training loss: 0.15883508324623108
Validation loss: 1.6163547820942377

Epoch: 6| Step: 1
Training loss: 0.2021876573562622
Validation loss: 1.6275930693072658

Epoch: 6| Step: 2
Training loss: 0.34125277400016785
Validation loss: 1.664241470316405

Epoch: 6| Step: 3
Training loss: 0.2275676131248474
Validation loss: 1.6771955246566443

Epoch: 6| Step: 4
Training loss: 0.19615742564201355
Validation loss: 1.6802118580828431

Epoch: 6| Step: 5
Training loss: 0.17294782400131226
Validation loss: 1.6582764912677068

Epoch: 6| Step: 6
Training loss: 0.3395628333091736
Validation loss: 1.6535125983658658

Epoch: 6| Step: 7
Training loss: 0.26647934317588806
Validation loss: 1.643054211011497

Epoch: 6| Step: 8
Training loss: 0.5281308889389038
Validation loss: 1.6553399562835693

Epoch: 6| Step: 9
Training loss: 0.25243136286735535
Validation loss: 1.653318691638208

Epoch: 6| Step: 10
Training loss: 0.18177220225334167
Validation loss: 1.6474116361269386

Epoch: 6| Step: 11
Training loss: 0.14435717463493347
Validation loss: 1.639098657074795

Epoch: 6| Step: 12
Training loss: 0.1986212134361267
Validation loss: 1.6379515201814714

Epoch: 6| Step: 13
Training loss: 0.12779389321804047
Validation loss: 1.6693089777423489

Epoch: 392| Step: 0
Training loss: 0.3053959906101227
Validation loss: 1.6801599225690287

Epoch: 6| Step: 1
Training loss: 0.1551009714603424
Validation loss: 1.6479983406682168

Epoch: 6| Step: 2
Training loss: 0.20839492976665497
Validation loss: 1.649832196133111

Epoch: 6| Step: 3
Training loss: 0.24154877662658691
Validation loss: 1.6501780453548636

Epoch: 6| Step: 4
Training loss: 0.18092603981494904
Validation loss: 1.6217281792753486

Epoch: 6| Step: 5
Training loss: 0.2846980690956116
Validation loss: 1.6253524288054435

Epoch: 6| Step: 6
Training loss: 0.21165448427200317
Validation loss: 1.6060677318162815

Epoch: 6| Step: 7
Training loss: 0.13441330194473267
Validation loss: 1.6077591808893348

Epoch: 6| Step: 8
Training loss: 0.5203695297241211
Validation loss: 1.6339710579123548

Epoch: 6| Step: 9
Training loss: 0.2974277138710022
Validation loss: 1.6320578513606903

Epoch: 6| Step: 10
Training loss: 0.1470954716205597
Validation loss: 1.6266275400756507

Epoch: 6| Step: 11
Training loss: 0.20766864717006683
Validation loss: 1.6519345660363474

Epoch: 6| Step: 12
Training loss: 0.23759612441062927
Validation loss: 1.6402064420843636

Epoch: 6| Step: 13
Training loss: 0.197230264544487
Validation loss: 1.6761540776939803

Epoch: 393| Step: 0
Training loss: 0.2817716896533966
Validation loss: 1.6558304525190783

Epoch: 6| Step: 1
Training loss: 0.11935392767190933
Validation loss: 1.6767812313572052

Epoch: 6| Step: 2
Training loss: 0.18177498877048492
Validation loss: 1.6836152691994943

Epoch: 6| Step: 3
Training loss: 0.27306193113327026
Validation loss: 1.7001886008888163

Epoch: 6| Step: 4
Training loss: 0.5020499229431152
Validation loss: 1.6910538468309628

Epoch: 6| Step: 5
Training loss: 0.19379353523254395
Validation loss: 1.6828641788933867

Epoch: 6| Step: 6
Training loss: 0.24380266666412354
Validation loss: 1.7134314352466213

Epoch: 6| Step: 7
Training loss: 0.21031835675239563
Validation loss: 1.7067977561745593

Epoch: 6| Step: 8
Training loss: 0.27458012104034424
Validation loss: 1.6938811053511917

Epoch: 6| Step: 9
Training loss: 0.28809794783592224
Validation loss: 1.6726000103899228

Epoch: 6| Step: 10
Training loss: 0.18402203917503357
Validation loss: 1.6705667998201104

Epoch: 6| Step: 11
Training loss: 0.21205762028694153
Validation loss: 1.6548864059550787

Epoch: 6| Step: 12
Training loss: 0.281652569770813
Validation loss: 1.6920422597598004

Epoch: 6| Step: 13
Training loss: 0.2730240225791931
Validation loss: 1.7057729158350217

Epoch: 394| Step: 0
Training loss: 0.1733655333518982
Validation loss: 1.7460095138959988

Epoch: 6| Step: 1
Training loss: 0.2096523940563202
Validation loss: 1.7411470945163439

Epoch: 6| Step: 2
Training loss: 0.26393619179725647
Validation loss: 1.7469200447041502

Epoch: 6| Step: 3
Training loss: 0.22252854704856873
Validation loss: 1.6787865546441847

Epoch: 6| Step: 4
Training loss: 0.23138579726219177
Validation loss: 1.7035659493938569

Epoch: 6| Step: 5
Training loss: 0.13196641206741333
Validation loss: 1.67027199011977

Epoch: 6| Step: 6
Training loss: 0.141733318567276
Validation loss: 1.6425947040639899

Epoch: 6| Step: 7
Training loss: 0.2087855041027069
Validation loss: 1.6548374186279953

Epoch: 6| Step: 8
Training loss: 0.11948700249195099
Validation loss: 1.6486322129926374

Epoch: 6| Step: 9
Training loss: 0.29360997676849365
Validation loss: 1.6471795253856207

Epoch: 6| Step: 10
Training loss: 0.21233631670475006
Validation loss: 1.6035790795920997

Epoch: 6| Step: 11
Training loss: 0.19034527242183685
Validation loss: 1.5923868456194479

Epoch: 6| Step: 12
Training loss: 0.2086493968963623
Validation loss: 1.5874406817138835

Epoch: 6| Step: 13
Training loss: 0.8712977766990662
Validation loss: 1.586717059535365

Epoch: 395| Step: 0
Training loss: 0.22050897777080536
Validation loss: 1.6042481148114769

Epoch: 6| Step: 1
Training loss: 0.16012704372406006
Validation loss: 1.6258183243454143

Epoch: 6| Step: 2
Training loss: 0.5634788870811462
Validation loss: 1.6300913633838776

Epoch: 6| Step: 3
Training loss: 0.3688032925128937
Validation loss: 1.6949351167166105

Epoch: 6| Step: 4
Training loss: 0.2209981083869934
Validation loss: 1.7087284864917878

Epoch: 6| Step: 5
Training loss: 0.19284871220588684
Validation loss: 1.7015107408646615

Epoch: 6| Step: 6
Training loss: 0.11910606920719147
Validation loss: 1.7209149842621179

Epoch: 6| Step: 7
Training loss: 0.24064873158931732
Validation loss: 1.6876384212124733

Epoch: 6| Step: 8
Training loss: 0.250954806804657
Validation loss: 1.67216085298087

Epoch: 6| Step: 9
Training loss: 0.22844690084457397
Validation loss: 1.6494339576331518

Epoch: 6| Step: 10
Training loss: 0.09185399860143661
Validation loss: 1.6725835069533317

Epoch: 6| Step: 11
Training loss: 0.22886179387569427
Validation loss: 1.6407377040514382

Epoch: 6| Step: 12
Training loss: 0.2947067320346832
Validation loss: 1.6151157835478425

Epoch: 6| Step: 13
Training loss: 0.23362356424331665
Validation loss: 1.6123388339114446

Epoch: 396| Step: 0
Training loss: 0.19032171368598938
Validation loss: 1.6354283299497379

Epoch: 6| Step: 1
Training loss: 0.2492629736661911
Validation loss: 1.6122800688589773

Epoch: 6| Step: 2
Training loss: 0.10327263176441193
Validation loss: 1.6062040469979728

Epoch: 6| Step: 3
Training loss: 0.17732471227645874
Validation loss: 1.621539859361546

Epoch: 6| Step: 4
Training loss: 0.10051700472831726
Validation loss: 1.5900367677852671

Epoch: 6| Step: 5
Training loss: 0.13991856575012207
Validation loss: 1.6298050444613221

Epoch: 6| Step: 6
Training loss: 0.5758708119392395
Validation loss: 1.6550591799520677

Epoch: 6| Step: 7
Training loss: 0.20922969281673431
Validation loss: 1.6830287947449634

Epoch: 6| Step: 8
Training loss: 0.22393295168876648
Validation loss: 1.6795513886277393

Epoch: 6| Step: 9
Training loss: 0.3855625092983246
Validation loss: 1.7091977788556008

Epoch: 6| Step: 10
Training loss: 0.16889509558677673
Validation loss: 1.6831122034339494

Epoch: 6| Step: 11
Training loss: 0.1843004822731018
Validation loss: 1.6800964583632767

Epoch: 6| Step: 12
Training loss: 0.3553636968135834
Validation loss: 1.6371429966342064

Epoch: 6| Step: 13
Training loss: 0.26773038506507874
Validation loss: 1.6385962296557683

Epoch: 397| Step: 0
Training loss: 0.21597521007061005
Validation loss: 1.6342077409067461

Epoch: 6| Step: 1
Training loss: 0.21451380848884583
Validation loss: 1.5760204138294343

Epoch: 6| Step: 2
Training loss: 0.6601008176803589
Validation loss: 1.6088777998442292

Epoch: 6| Step: 3
Training loss: 0.19238731265068054
Validation loss: 1.5813112822912072

Epoch: 6| Step: 4
Training loss: 0.1103188619017601
Validation loss: 1.5640917888251684

Epoch: 6| Step: 5
Training loss: 0.33119115233421326
Validation loss: 1.6065062643379293

Epoch: 6| Step: 6
Training loss: 0.16893482208251953
Validation loss: 1.5750795179797756

Epoch: 6| Step: 7
Training loss: 0.12143930792808533
Validation loss: 1.568529700720182

Epoch: 6| Step: 8
Training loss: 0.1086471900343895
Validation loss: 1.5754048619219052

Epoch: 6| Step: 9
Training loss: 0.1221386045217514
Validation loss: 1.5902674198150635

Epoch: 6| Step: 10
Training loss: 0.17574357986450195
Validation loss: 1.6246869628147413

Epoch: 6| Step: 11
Training loss: 0.21590015292167664
Validation loss: 1.6202808759545768

Epoch: 6| Step: 12
Training loss: 0.10848207026720047
Validation loss: 1.6599876649918095

Epoch: 6| Step: 13
Training loss: 0.19631624221801758
Validation loss: 1.653936606581493

Epoch: 398| Step: 0
Training loss: 0.4559241235256195
Validation loss: 1.6971593544047365

Epoch: 6| Step: 1
Training loss: 0.10775312781333923
Validation loss: 1.6935572021750993

Epoch: 6| Step: 2
Training loss: 0.14597919583320618
Validation loss: 1.6772798415153258

Epoch: 6| Step: 3
Training loss: 0.25774261355400085
Validation loss: 1.6454518424567355

Epoch: 6| Step: 4
Training loss: 0.3152658939361572
Validation loss: 1.6592562474230284

Epoch: 6| Step: 5
Training loss: 0.1660085767507553
Validation loss: 1.6604132825328457

Epoch: 6| Step: 6
Training loss: 0.2604351043701172
Validation loss: 1.658507667562013

Epoch: 6| Step: 7
Training loss: 0.20125161111354828
Validation loss: 1.6556349480023949

Epoch: 6| Step: 8
Training loss: 0.13204503059387207
Validation loss: 1.687745621127467

Epoch: 6| Step: 9
Training loss: 0.1921500712633133
Validation loss: 1.680714520074988

Epoch: 6| Step: 10
Training loss: 0.1224401518702507
Validation loss: 1.6566133999055432

Epoch: 6| Step: 11
Training loss: 0.2955172657966614
Validation loss: 1.693865711970996

Epoch: 6| Step: 12
Training loss: 0.15164603292942047
Validation loss: 1.6708207489341818

Epoch: 6| Step: 13
Training loss: 0.15698835253715515
Validation loss: 1.6546300483006302

Epoch: 399| Step: 0
Training loss: 0.24781012535095215
Validation loss: 1.6380977758797266

Epoch: 6| Step: 1
Training loss: 0.12489480525255203
Validation loss: 1.64375691388243

Epoch: 6| Step: 2
Training loss: 0.13414418697357178
Validation loss: 1.5901073332755797

Epoch: 6| Step: 3
Training loss: 0.23828516900539398
Validation loss: 1.6203180769438386

Epoch: 6| Step: 4
Training loss: 0.25560444593429565
Validation loss: 1.5998356380770284

Epoch: 6| Step: 5
Training loss: 0.2088380753993988
Validation loss: 1.6196075921417565

Epoch: 6| Step: 6
Training loss: 0.510442852973938
Validation loss: 1.6128960309490081

Epoch: 6| Step: 7
Training loss: 0.11546778678894043
Validation loss: 1.6153258098069059

Epoch: 6| Step: 8
Training loss: 0.12249794602394104
Validation loss: 1.6450343375564904

Epoch: 6| Step: 9
Training loss: 0.17768090963363647
Validation loss: 1.644374498756983

Epoch: 6| Step: 10
Training loss: 0.2360752522945404
Validation loss: 1.6851041509259133

Epoch: 6| Step: 11
Training loss: 0.2926347851753235
Validation loss: 1.7143200841001285

Epoch: 6| Step: 12
Training loss: 0.1616811603307724
Validation loss: 1.7159103270499938

Epoch: 6| Step: 13
Training loss: 0.21203777194023132
Validation loss: 1.716378337593489

Epoch: 400| Step: 0
Training loss: 0.13000160455703735
Validation loss: 1.6976759856747043

Epoch: 6| Step: 1
Training loss: 0.2506018877029419
Validation loss: 1.696541565720753

Epoch: 6| Step: 2
Training loss: 0.18358245491981506
Validation loss: 1.6410592243235598

Epoch: 6| Step: 3
Training loss: 0.29246288537979126
Validation loss: 1.6013981373079362

Epoch: 6| Step: 4
Training loss: 0.12845632433891296
Validation loss: 1.5789660189741401

Epoch: 6| Step: 5
Training loss: 0.1987665295600891
Validation loss: 1.5472035831020725

Epoch: 6| Step: 6
Training loss: 0.23507213592529297
Validation loss: 1.5482783509838967

Epoch: 6| Step: 7
Training loss: 0.11473429203033447
Validation loss: 1.5741778394227386

Epoch: 6| Step: 8
Training loss: 0.27040624618530273
Validation loss: 1.5943441596082462

Epoch: 6| Step: 9
Training loss: 0.5906269550323486
Validation loss: 1.5971595356541295

Epoch: 6| Step: 10
Training loss: 0.21507786214351654
Validation loss: 1.6406045280477053

Epoch: 6| Step: 11
Training loss: 0.08773880451917648
Validation loss: 1.6567943365343156

Epoch: 6| Step: 12
Training loss: 0.14395491778850555
Validation loss: 1.6855565950434694

Epoch: 6| Step: 13
Training loss: 0.1774955838918686
Validation loss: 1.6873618774516608

Epoch: 401| Step: 0
Training loss: 0.34131956100463867
Validation loss: 1.6817161011439499

Epoch: 6| Step: 1
Training loss: 0.21630671620368958
Validation loss: 1.6837902017818984

Epoch: 6| Step: 2
Training loss: 0.1538180410861969
Validation loss: 1.6505895558223929

Epoch: 6| Step: 3
Training loss: 0.16403086483478546
Validation loss: 1.6421948235522035

Epoch: 6| Step: 4
Training loss: 0.5187935829162598
Validation loss: 1.6684004799012215

Epoch: 6| Step: 5
Training loss: 0.2488471120595932
Validation loss: 1.6277867222345004

Epoch: 6| Step: 6
Training loss: 0.16659234464168549
Validation loss: 1.6205395498583395

Epoch: 6| Step: 7
Training loss: 0.14278289675712585
Validation loss: 1.6316935580263856

Epoch: 6| Step: 8
Training loss: 0.20690542459487915
Validation loss: 1.5918269990592875

Epoch: 6| Step: 9
Training loss: 0.22131437063217163
Validation loss: 1.6025019595699925

Epoch: 6| Step: 10
Training loss: 0.15045443177223206
Validation loss: 1.5964749064496768

Epoch: 6| Step: 11
Training loss: 0.21109820902347565
Validation loss: 1.58976778932797

Epoch: 6| Step: 12
Training loss: 0.2183440923690796
Validation loss: 1.5777919433450187

Epoch: 6| Step: 13
Training loss: 0.21226488053798676
Validation loss: 1.5692364759342645

Epoch: 402| Step: 0
Training loss: 0.22171762585639954
Validation loss: 1.5484717263970325

Epoch: 6| Step: 1
Training loss: 0.19070275127887726
Validation loss: 1.577906726509012

Epoch: 6| Step: 2
Training loss: 0.1804230809211731
Validation loss: 1.565316295111051

Epoch: 6| Step: 3
Training loss: 0.14586132764816284
Validation loss: 1.5323111344409246

Epoch: 6| Step: 4
Training loss: 0.17922881245613098
Validation loss: 1.5703624140831731

Epoch: 6| Step: 5
Training loss: 0.23618361353874207
Validation loss: 1.5669067726340344

Epoch: 6| Step: 6
Training loss: 0.15640056133270264
Validation loss: 1.577987160733951

Epoch: 6| Step: 7
Training loss: 0.1603500097990036
Validation loss: 1.6093634982262888

Epoch: 6| Step: 8
Training loss: 0.4771502614021301
Validation loss: 1.607541609835881

Epoch: 6| Step: 9
Training loss: 0.22754091024398804
Validation loss: 1.6311491227919055

Epoch: 6| Step: 10
Training loss: 0.25567787885665894
Validation loss: 1.6222009005085114

Epoch: 6| Step: 11
Training loss: 0.1482888162136078
Validation loss: 1.6294614948252195

Epoch: 6| Step: 12
Training loss: 0.20031094551086426
Validation loss: 1.5779559240546277

Epoch: 6| Step: 13
Training loss: 0.2767995595932007
Validation loss: 1.5974802342794274

Epoch: 403| Step: 0
Training loss: 0.08574187010526657
Validation loss: 1.5857773314240158

Epoch: 6| Step: 1
Training loss: 0.28674060106277466
Validation loss: 1.5924210535582675

Epoch: 6| Step: 2
Training loss: 0.11270773410797119
Validation loss: 1.599088732273348

Epoch: 6| Step: 3
Training loss: 0.17487317323684692
Validation loss: 1.574507354408182

Epoch: 6| Step: 4
Training loss: 0.6922261714935303
Validation loss: 1.5816685615047332

Epoch: 6| Step: 5
Training loss: 0.20548538863658905
Validation loss: 1.5842219552686136

Epoch: 6| Step: 6
Training loss: 0.1715930998325348
Validation loss: 1.5733936461069251

Epoch: 6| Step: 7
Training loss: 0.11538226902484894
Validation loss: 1.5706403934827415

Epoch: 6| Step: 8
Training loss: 0.31096965074539185
Validation loss: 1.5581861439571585

Epoch: 6| Step: 9
Training loss: 0.16244766116142273
Validation loss: 1.5861523382125362

Epoch: 6| Step: 10
Training loss: 0.13073378801345825
Validation loss: 1.5720634075903124

Epoch: 6| Step: 11
Training loss: 0.2167230248451233
Validation loss: 1.579717916827048

Epoch: 6| Step: 12
Training loss: 0.16582491993904114
Validation loss: 1.6077648465351393

Epoch: 6| Step: 13
Training loss: 0.1659514605998993
Validation loss: 1.5819085618501068

Epoch: 404| Step: 0
Training loss: 0.48732075095176697
Validation loss: 1.6177356986589329

Epoch: 6| Step: 1
Training loss: 0.19405631721019745
Validation loss: 1.6114715812026814

Epoch: 6| Step: 2
Training loss: 0.24960580468177795
Validation loss: 1.656996960281044

Epoch: 6| Step: 3
Training loss: 0.18318533897399902
Validation loss: 1.668211861964195

Epoch: 6| Step: 4
Training loss: 0.32277196645736694
Validation loss: 1.6668344261825725

Epoch: 6| Step: 5
Training loss: 0.20508725941181183
Validation loss: 1.6488529328377015

Epoch: 6| Step: 6
Training loss: 0.19895845651626587
Validation loss: 1.6297185933718117

Epoch: 6| Step: 7
Training loss: 0.18884649872779846
Validation loss: 1.5528935655470817

Epoch: 6| Step: 8
Training loss: 0.30857616662979126
Validation loss: 1.5821772313887073

Epoch: 6| Step: 9
Training loss: 0.1565120667219162
Validation loss: 1.5454713195882819

Epoch: 6| Step: 10
Training loss: 0.24636487662792206
Validation loss: 1.5280257245545745

Epoch: 6| Step: 11
Training loss: 0.1977071762084961
Validation loss: 1.553234104187258

Epoch: 6| Step: 12
Training loss: 0.2381243109703064
Validation loss: 1.5595153621447984

Epoch: 6| Step: 13
Training loss: 0.27038970589637756
Validation loss: 1.528673873152784

Epoch: 405| Step: 0
Training loss: 0.30081707239151
Validation loss: 1.5693771916051065

Epoch: 6| Step: 1
Training loss: 0.21919067203998566
Validation loss: 1.5929250435162616

Epoch: 6| Step: 2
Training loss: 0.30289995670318604
Validation loss: 1.62301879800776

Epoch: 6| Step: 3
Training loss: 0.2138398289680481
Validation loss: 1.6180590621886715

Epoch: 6| Step: 4
Training loss: 0.22776544094085693
Validation loss: 1.6418826336501746

Epoch: 6| Step: 5
Training loss: 0.12494491040706635
Validation loss: 1.6521072438968125

Epoch: 6| Step: 6
Training loss: 0.20203101634979248
Validation loss: 1.691177515573399

Epoch: 6| Step: 7
Training loss: 0.6425058841705322
Validation loss: 1.6655342168705438

Epoch: 6| Step: 8
Training loss: 0.3102559745311737
Validation loss: 1.6616439204062186

Epoch: 6| Step: 9
Training loss: 0.24292610585689545
Validation loss: 1.6322560618000646

Epoch: 6| Step: 10
Training loss: 0.19293862581253052
Validation loss: 1.6035329218833678

Epoch: 6| Step: 11
Training loss: 0.18916723132133484
Validation loss: 1.5655796707317393

Epoch: 6| Step: 12
Training loss: 0.1670321524143219
Validation loss: 1.5462692399178781

Epoch: 6| Step: 13
Training loss: 0.2020387053489685
Validation loss: 1.5260167967888616

Epoch: 406| Step: 0
Training loss: 0.20362597703933716
Validation loss: 1.51949740481633

Epoch: 6| Step: 1
Training loss: 0.1495402753353119
Validation loss: 1.5187870385826274

Epoch: 6| Step: 2
Training loss: 0.28350770473480225
Validation loss: 1.5274773105498283

Epoch: 6| Step: 3
Training loss: 0.13834209740161896
Validation loss: 1.5478928435233332

Epoch: 6| Step: 4
Training loss: 0.1670946329832077
Validation loss: 1.5416802078165033

Epoch: 6| Step: 5
Training loss: 0.28690868616104126
Validation loss: 1.5700441534801195

Epoch: 6| Step: 6
Training loss: 0.1901981681585312
Validation loss: 1.5581489968043503

Epoch: 6| Step: 7
Training loss: 0.2041274905204773
Validation loss: 1.601918335883848

Epoch: 6| Step: 8
Training loss: 0.17640608549118042
Validation loss: 1.6280463228943527

Epoch: 6| Step: 9
Training loss: 0.19581034779548645
Validation loss: 1.634675145149231

Epoch: 6| Step: 10
Training loss: 0.4110938608646393
Validation loss: 1.624009669467967

Epoch: 6| Step: 11
Training loss: 0.5040096044540405
Validation loss: 1.6691554797592985

Epoch: 6| Step: 12
Training loss: 0.1544029712677002
Validation loss: 1.6259603397820586

Epoch: 6| Step: 13
Training loss: 0.2265375703573227
Validation loss: 1.5879811151053316

Epoch: 407| Step: 0
Training loss: 0.1406296193599701
Validation loss: 1.5953484017361876

Epoch: 6| Step: 1
Training loss: 0.1600264012813568
Validation loss: 1.5374949196333527

Epoch: 6| Step: 2
Training loss: 0.18006086349487305
Validation loss: 1.542310469893999

Epoch: 6| Step: 3
Training loss: 0.17288106679916382
Validation loss: 1.5411349701625046

Epoch: 6| Step: 4
Training loss: 0.1182912290096283
Validation loss: 1.5437401776672692

Epoch: 6| Step: 5
Training loss: 0.4361801743507385
Validation loss: 1.593937329066697

Epoch: 6| Step: 6
Training loss: 0.21231094002723694
Validation loss: 1.558153723516772

Epoch: 6| Step: 7
Training loss: 0.14268678426742554
Validation loss: 1.5342674665553595

Epoch: 6| Step: 8
Training loss: 0.25155210494995117
Validation loss: 1.6041120841938963

Epoch: 6| Step: 9
Training loss: 0.13278828561306
Validation loss: 1.5828837143477572

Epoch: 6| Step: 10
Training loss: 0.22820435464382172
Validation loss: 1.6086141999049852

Epoch: 6| Step: 11
Training loss: 0.4151393473148346
Validation loss: 1.5934154974517

Epoch: 6| Step: 12
Training loss: 0.16559076309204102
Validation loss: 1.5848343718436457

Epoch: 6| Step: 13
Training loss: 0.16456586122512817
Validation loss: 1.5755146664957846

Epoch: 408| Step: 0
Training loss: 0.18908461928367615
Validation loss: 1.6257834934419202

Epoch: 6| Step: 1
Training loss: 0.17931827902793884
Validation loss: 1.6234868905877555

Epoch: 6| Step: 2
Training loss: 0.17284619808197021
Validation loss: 1.5729734538703837

Epoch: 6| Step: 3
Training loss: 0.17399141192436218
Validation loss: 1.6004804641969743

Epoch: 6| Step: 4
Training loss: 0.16842308640480042
Validation loss: 1.530719639152609

Epoch: 6| Step: 5
Training loss: 0.5028063058853149
Validation loss: 1.572229016211725

Epoch: 6| Step: 6
Training loss: 0.18529723584651947
Validation loss: 1.5455957048682756

Epoch: 6| Step: 7
Training loss: 0.29617005586624146
Validation loss: 1.5854127099437099

Epoch: 6| Step: 8
Training loss: 0.15414901077747345
Validation loss: 1.591298516078662

Epoch: 6| Step: 9
Training loss: 0.2455856204032898
Validation loss: 1.6441938364377586

Epoch: 6| Step: 10
Training loss: 0.15669256448745728
Validation loss: 1.6063033611543718

Epoch: 6| Step: 11
Training loss: 0.1714169830083847
Validation loss: 1.6282004066692886

Epoch: 6| Step: 12
Training loss: 0.31407034397125244
Validation loss: 1.6307491961345877

Epoch: 6| Step: 13
Training loss: 0.22520335018634796
Validation loss: 1.6608133008403163

Epoch: 409| Step: 0
Training loss: 0.16399666666984558
Validation loss: 1.6279394549708213

Epoch: 6| Step: 1
Training loss: 0.615173876285553
Validation loss: 1.6347163479815248

Epoch: 6| Step: 2
Training loss: 0.14692214131355286
Validation loss: 1.6254542425114622

Epoch: 6| Step: 3
Training loss: 0.2937971353530884
Validation loss: 1.6682341573058919

Epoch: 6| Step: 4
Training loss: 0.22833788394927979
Validation loss: 1.6418465568173317

Epoch: 6| Step: 5
Training loss: 0.18516208231449127
Validation loss: 1.6452111339056363

Epoch: 6| Step: 6
Training loss: 0.4550263285636902
Validation loss: 1.6107324541255992

Epoch: 6| Step: 7
Training loss: 0.16874057054519653
Validation loss: 1.5578957847369614

Epoch: 6| Step: 8
Training loss: 0.19795358180999756
Validation loss: 1.5667421561415478

Epoch: 6| Step: 9
Training loss: 0.21363474428653717
Validation loss: 1.5627110773517239

Epoch: 6| Step: 10
Training loss: 0.19760462641716003
Validation loss: 1.5143520447515673

Epoch: 6| Step: 11
Training loss: 0.1441667675971985
Validation loss: 1.5602891214432255

Epoch: 6| Step: 12
Training loss: 0.22961357235908508
Validation loss: 1.5548919426497592

Epoch: 6| Step: 13
Training loss: 0.1648603081703186
Validation loss: 1.5899170752494567

Epoch: 410| Step: 0
Training loss: 0.30955439805984497
Validation loss: 1.6141866009722474

Epoch: 6| Step: 1
Training loss: 0.11135096102952957
Validation loss: 1.5955005320169593

Epoch: 6| Step: 2
Training loss: 0.2442421168088913
Validation loss: 1.6360006819489181

Epoch: 6| Step: 3
Training loss: 0.5249084830284119
Validation loss: 1.6357750636275097

Epoch: 6| Step: 4
Training loss: 0.16167742013931274
Validation loss: 1.591714919254344

Epoch: 6| Step: 5
Training loss: 0.25573986768722534
Validation loss: 1.6342303393989481

Epoch: 6| Step: 6
Training loss: 0.14440064132213593
Validation loss: 1.5823700581827471

Epoch: 6| Step: 7
Training loss: 0.12136725336313248
Validation loss: 1.5877572105776878

Epoch: 6| Step: 8
Training loss: 0.1345287412405014
Validation loss: 1.5806407608011717

Epoch: 6| Step: 9
Training loss: 0.2599867582321167
Validation loss: 1.5453010130954046

Epoch: 6| Step: 10
Training loss: 0.21416454017162323
Validation loss: 1.5271594806384015

Epoch: 6| Step: 11
Training loss: 0.29178720712661743
Validation loss: 1.5321067533185404

Epoch: 6| Step: 12
Training loss: 0.24195560812950134
Validation loss: 1.5066640761590773

Epoch: 6| Step: 13
Training loss: 0.16624265909194946
Validation loss: 1.5718362472390617

Epoch: 411| Step: 0
Training loss: 0.20277070999145508
Validation loss: 1.5725518016405002

Epoch: 6| Step: 1
Training loss: 0.29409095644950867
Validation loss: 1.6008018184733648

Epoch: 6| Step: 2
Training loss: 0.19573432207107544
Validation loss: 1.6445451154503772

Epoch: 6| Step: 3
Training loss: 0.2751368582248688
Validation loss: 1.6641047346976496

Epoch: 6| Step: 4
Training loss: 0.133078932762146
Validation loss: 1.6198908757137995

Epoch: 6| Step: 5
Training loss: 0.12159664928913116
Validation loss: 1.6328465041293894

Epoch: 6| Step: 6
Training loss: 0.182851642370224
Validation loss: 1.6294400127985145

Epoch: 6| Step: 7
Training loss: 0.18148452043533325
Validation loss: 1.6360615684140114

Epoch: 6| Step: 8
Training loss: 0.49918651580810547
Validation loss: 1.6406392487146522

Epoch: 6| Step: 9
Training loss: 0.2044605165719986
Validation loss: 1.6304023060747372

Epoch: 6| Step: 10
Training loss: 0.20897415280342102
Validation loss: 1.640533636975032

Epoch: 6| Step: 11
Training loss: 0.25468751788139343
Validation loss: 1.6318946820433422

Epoch: 6| Step: 12
Training loss: 0.19814923405647278
Validation loss: 1.6318763532946188

Epoch: 6| Step: 13
Training loss: 0.07002507150173187
Validation loss: 1.5995061807734992

Epoch: 412| Step: 0
Training loss: 0.13913851976394653
Validation loss: 1.5775533094201037

Epoch: 6| Step: 1
Training loss: 0.18768519163131714
Validation loss: 1.5850631101157076

Epoch: 6| Step: 2
Training loss: 0.10667883604764938
Validation loss: 1.5701235340487572

Epoch: 6| Step: 3
Training loss: 0.1879967302083969
Validation loss: 1.5410467334972915

Epoch: 6| Step: 4
Training loss: 0.4921809434890747
Validation loss: 1.5148402362741449

Epoch: 6| Step: 5
Training loss: 0.21434424817562103
Validation loss: 1.5451680229556175

Epoch: 6| Step: 6
Training loss: 0.35016193985939026
Validation loss: 1.531187811205464

Epoch: 6| Step: 7
Training loss: 0.18765854835510254
Validation loss: 1.5852638316410843

Epoch: 6| Step: 8
Training loss: 0.14158180356025696
Validation loss: 1.5744389410941833

Epoch: 6| Step: 9
Training loss: 0.15879389643669128
Validation loss: 1.6034356855577039

Epoch: 6| Step: 10
Training loss: 0.15528635680675507
Validation loss: 1.5778343895430207

Epoch: 6| Step: 11
Training loss: 0.27576586604118347
Validation loss: 1.6213492155075073

Epoch: 6| Step: 12
Training loss: 0.16544151306152344
Validation loss: 1.6067116465619815

Epoch: 6| Step: 13
Training loss: 0.32540351152420044
Validation loss: 1.6422283546898955

Epoch: 413| Step: 0
Training loss: 0.25401872396469116
Validation loss: 1.6393053506010322

Epoch: 6| Step: 1
Training loss: 0.1670772284269333
Validation loss: 1.659769638892143

Epoch: 6| Step: 2
Training loss: 0.12350806593894958
Validation loss: 1.6398328709345993

Epoch: 6| Step: 3
Training loss: 0.2027013599872589
Validation loss: 1.6718767048210226

Epoch: 6| Step: 4
Training loss: 0.24775074422359467
Validation loss: 1.679161480678025

Epoch: 6| Step: 5
Training loss: 0.1839902251958847
Validation loss: 1.6581463685599707

Epoch: 6| Step: 6
Training loss: 0.12008136510848999
Validation loss: 1.6779708721304452

Epoch: 6| Step: 7
Training loss: 0.2038603127002716
Validation loss: 1.6322830825723627

Epoch: 6| Step: 8
Training loss: 0.15027324855327606
Validation loss: 1.5865432767457859

Epoch: 6| Step: 9
Training loss: 0.19404949247837067
Validation loss: 1.6011478131817234

Epoch: 6| Step: 10
Training loss: 0.1754074990749359
Validation loss: 1.5972418862004434

Epoch: 6| Step: 11
Training loss: 0.20229199528694153
Validation loss: 1.5835188434969993

Epoch: 6| Step: 12
Training loss: 0.5187769532203674
Validation loss: 1.6306843308992283

Epoch: 6| Step: 13
Training loss: 0.26554781198501587
Validation loss: 1.5827641910122288

Epoch: 414| Step: 0
Training loss: 0.542407751083374
Validation loss: 1.5971750431163336

Epoch: 6| Step: 1
Training loss: 0.1683558225631714
Validation loss: 1.5812285395078762

Epoch: 6| Step: 2
Training loss: 0.17795848846435547
Validation loss: 1.567339962528598

Epoch: 6| Step: 3
Training loss: 0.2394031584262848
Validation loss: 1.568636977544395

Epoch: 6| Step: 4
Training loss: 0.11839912086725235
Validation loss: 1.5705457541250414

Epoch: 6| Step: 5
Training loss: 0.15045702457427979
Validation loss: 1.6092903870408253

Epoch: 6| Step: 6
Training loss: 0.28610873222351074
Validation loss: 1.6393824738840903

Epoch: 6| Step: 7
Training loss: 0.18937483429908752
Validation loss: 1.6165033027689943

Epoch: 6| Step: 8
Training loss: 0.22811168432235718
Validation loss: 1.6450202157420497

Epoch: 6| Step: 9
Training loss: 0.23289909958839417
Validation loss: 1.6573172128328713

Epoch: 6| Step: 10
Training loss: 0.15565019845962524
Validation loss: 1.6559201927595242

Epoch: 6| Step: 11
Training loss: 0.14234137535095215
Validation loss: 1.6639522890890799

Epoch: 6| Step: 12
Training loss: 0.19743755459785461
Validation loss: 1.6639966451993553

Epoch: 6| Step: 13
Training loss: 0.1783740073442459
Validation loss: 1.6454921332738732

Epoch: 415| Step: 0
Training loss: 0.19411523640155792
Validation loss: 1.6682986802952264

Epoch: 6| Step: 1
Training loss: 0.11044509708881378
Validation loss: 1.6459705803983955

Epoch: 6| Step: 2
Training loss: 0.11231990158557892
Validation loss: 1.6023444847394062

Epoch: 6| Step: 3
Training loss: 0.14716681838035583
Validation loss: 1.5850042155993882

Epoch: 6| Step: 4
Training loss: 0.11383473128080368
Validation loss: 1.5827280705974949

Epoch: 6| Step: 5
Training loss: 0.5023059844970703
Validation loss: 1.5443346256850867

Epoch: 6| Step: 6
Training loss: 0.30014896392822266
Validation loss: 1.5484596529314596

Epoch: 6| Step: 7
Training loss: 0.17510780692100525
Validation loss: 1.5361965894699097

Epoch: 6| Step: 8
Training loss: 0.12219738215208054
Validation loss: 1.526511311531067

Epoch: 6| Step: 9
Training loss: 0.16082848608493805
Validation loss: 1.572834458402408

Epoch: 6| Step: 10
Training loss: 0.21616150438785553
Validation loss: 1.6153619853399133

Epoch: 6| Step: 11
Training loss: 0.11928030848503113
Validation loss: 1.618075288752074

Epoch: 6| Step: 12
Training loss: 0.1967569887638092
Validation loss: 1.6557669049950057

Epoch: 6| Step: 13
Training loss: 0.3373887240886688
Validation loss: 1.6708139475955759

Epoch: 416| Step: 0
Training loss: 0.20532697439193726
Validation loss: 1.697676581721152

Epoch: 6| Step: 1
Training loss: 0.256916344165802
Validation loss: 1.6212505550794705

Epoch: 6| Step: 2
Training loss: 0.15093198418617249
Validation loss: 1.6117766326473606

Epoch: 6| Step: 3
Training loss: 0.15895399451255798
Validation loss: 1.5671895921871226

Epoch: 6| Step: 4
Training loss: 0.23905852437019348
Validation loss: 1.5792710781097412

Epoch: 6| Step: 5
Training loss: 0.13459807634353638
Validation loss: 1.5295825927488265

Epoch: 6| Step: 6
Training loss: 0.21992024779319763
Validation loss: 1.537246052936841

Epoch: 6| Step: 7
Training loss: 0.4684850871562958
Validation loss: 1.4961507448586084

Epoch: 6| Step: 8
Training loss: 0.18708550930023193
Validation loss: 1.4813071553425123

Epoch: 6| Step: 9
Training loss: 0.22306445240974426
Validation loss: 1.4830177753202376

Epoch: 6| Step: 10
Training loss: 0.18039801716804504
Validation loss: 1.4751564777025612

Epoch: 6| Step: 11
Training loss: 0.1906348168849945
Validation loss: 1.493246445091822

Epoch: 6| Step: 12
Training loss: 0.2166500687599182
Validation loss: 1.4904266762477096

Epoch: 6| Step: 13
Training loss: 0.14727701246738434
Validation loss: 1.538296607232863

Epoch: 417| Step: 0
Training loss: 0.10783448815345764
Validation loss: 1.556746026521088

Epoch: 6| Step: 1
Training loss: 0.47753506898880005
Validation loss: 1.5518851004621035

Epoch: 6| Step: 2
Training loss: 0.1719675362110138
Validation loss: 1.6011963467444144

Epoch: 6| Step: 3
Training loss: 0.1604924201965332
Validation loss: 1.5854175526608703

Epoch: 6| Step: 4
Training loss: 0.19942142069339752
Validation loss: 1.6162178824024815

Epoch: 6| Step: 5
Training loss: 0.13674065470695496
Validation loss: 1.5731194852500834

Epoch: 6| Step: 6
Training loss: 0.2049868404865265
Validation loss: 1.5912996312623382

Epoch: 6| Step: 7
Training loss: 0.14182300865650177
Validation loss: 1.5659517652244979

Epoch: 6| Step: 8
Training loss: 0.3237786889076233
Validation loss: 1.5569546709778488

Epoch: 6| Step: 9
Training loss: 0.2667151093482971
Validation loss: 1.5462840910880797

Epoch: 6| Step: 10
Training loss: 0.1502790004014969
Validation loss: 1.524850873536961

Epoch: 6| Step: 11
Training loss: 0.1710822880268097
Validation loss: 1.5253754021019064

Epoch: 6| Step: 12
Training loss: 0.13579067587852478
Validation loss: 1.5187367572579333

Epoch: 6| Step: 13
Training loss: 0.33077067136764526
Validation loss: 1.5052428514726701

Epoch: 418| Step: 0
Training loss: 0.15862739086151123
Validation loss: 1.5414776981517833

Epoch: 6| Step: 1
Training loss: 0.0603252574801445
Validation loss: 1.5386458289238714

Epoch: 6| Step: 2
Training loss: 0.1543884575366974
Validation loss: 1.5557847099919473

Epoch: 6| Step: 3
Training loss: 0.2235862910747528
Validation loss: 1.557872458170819

Epoch: 6| Step: 4
Training loss: 0.19250617921352386
Validation loss: 1.6091547102056525

Epoch: 6| Step: 5
Training loss: 0.43579864501953125
Validation loss: 1.605813673747483

Epoch: 6| Step: 6
Training loss: 0.25438255071640015
Validation loss: 1.6297259458931543

Epoch: 6| Step: 7
Training loss: 0.2625822424888611
Validation loss: 1.5725096694884761

Epoch: 6| Step: 8
Training loss: 0.17566262185573578
Validation loss: 1.5888950312009422

Epoch: 6| Step: 9
Training loss: 0.1639930158853531
Validation loss: 1.5590481553026425

Epoch: 6| Step: 10
Training loss: 0.18377317488193512
Validation loss: 1.5166291421459568

Epoch: 6| Step: 11
Training loss: 0.10665865242481232
Validation loss: 1.5287831085984425

Epoch: 6| Step: 12
Training loss: 0.27124667167663574
Validation loss: 1.5405939163700226

Epoch: 6| Step: 13
Training loss: 0.28004103899002075
Validation loss: 1.5942004816506499

Epoch: 419| Step: 0
Training loss: 0.19362688064575195
Validation loss: 1.5946895435292234

Epoch: 6| Step: 1
Training loss: 0.15703320503234863
Validation loss: 1.6042140619729155

Epoch: 6| Step: 2
Training loss: 0.19756004214286804
Validation loss: 1.5670655735077397

Epoch: 6| Step: 3
Training loss: 0.1398116648197174
Validation loss: 1.5505738207089004

Epoch: 6| Step: 4
Training loss: 0.1701885461807251
Validation loss: 1.569745885428562

Epoch: 6| Step: 5
Training loss: 0.13648149371147156
Validation loss: 1.5531429436899

Epoch: 6| Step: 6
Training loss: 0.16467207670211792
Validation loss: 1.5784648836299937

Epoch: 6| Step: 7
Training loss: 0.1740390509366989
Validation loss: 1.5806548236518778

Epoch: 6| Step: 8
Training loss: 0.5597674250602722
Validation loss: 1.595129991090426

Epoch: 6| Step: 9
Training loss: 0.1197105199098587
Validation loss: 1.6150685856419225

Epoch: 6| Step: 10
Training loss: 0.3344520926475525
Validation loss: 1.6244707453635432

Epoch: 6| Step: 11
Training loss: 0.256571501493454
Validation loss: 1.6216763578435427

Epoch: 6| Step: 12
Training loss: 0.1937991827726364
Validation loss: 1.6085971581038607

Epoch: 6| Step: 13
Training loss: 0.06922367215156555
Validation loss: 1.6173338659348027

Epoch: 420| Step: 0
Training loss: 0.12283133715391159
Validation loss: 1.6123244313783542

Epoch: 6| Step: 1
Training loss: 0.13292378187179565
Validation loss: 1.5819985584546161

Epoch: 6| Step: 2
Training loss: 0.5550516247749329
Validation loss: 1.5851886298066826

Epoch: 6| Step: 3
Training loss: 0.15113843977451324
Validation loss: 1.6125157751062864

Epoch: 6| Step: 4
Training loss: 0.15644119679927826
Validation loss: 1.5838553508122761

Epoch: 6| Step: 5
Training loss: 0.1282074898481369
Validation loss: 1.601697015505965

Epoch: 6| Step: 6
Training loss: 0.14620080590248108
Validation loss: 1.6106726251622683

Epoch: 6| Step: 7
Training loss: 0.11419037729501724
Validation loss: 1.624917204662036

Epoch: 6| Step: 8
Training loss: 0.18486535549163818
Validation loss: 1.5784712517133324

Epoch: 6| Step: 9
Training loss: 0.21437077224254608
Validation loss: 1.614595003025506

Epoch: 6| Step: 10
Training loss: 0.2784295082092285
Validation loss: 1.6248248930900329

Epoch: 6| Step: 11
Training loss: 0.07081932574510574
Validation loss: 1.6297725157071186

Epoch: 6| Step: 12
Training loss: 0.18070027232170105
Validation loss: 1.5912777646895377

Epoch: 6| Step: 13
Training loss: 0.1336512565612793
Validation loss: 1.5692661654564641

Epoch: 421| Step: 0
Training loss: 0.1677468717098236
Validation loss: 1.5592234801220637

Epoch: 6| Step: 1
Training loss: 0.13644692301750183
Validation loss: 1.5741228941948182

Epoch: 6| Step: 2
Training loss: 0.28899461030960083
Validation loss: 1.5856246204786404

Epoch: 6| Step: 3
Training loss: 0.17022758722305298
Validation loss: 1.5930587976209578

Epoch: 6| Step: 4
Training loss: 0.2410428822040558
Validation loss: 1.6011739071979318

Epoch: 6| Step: 5
Training loss: 0.10434825718402863
Validation loss: 1.6311371505901378

Epoch: 6| Step: 6
Training loss: 0.1571052074432373
Validation loss: 1.620622618224031

Epoch: 6| Step: 7
Training loss: 0.18611270189285278
Validation loss: 1.6304574679302912

Epoch: 6| Step: 8
Training loss: 0.1317182183265686
Validation loss: 1.6154469956633866

Epoch: 6| Step: 9
Training loss: 0.1887209713459015
Validation loss: 1.5741034617988012

Epoch: 6| Step: 10
Training loss: 0.12094172090291977
Validation loss: 1.5571839181325768

Epoch: 6| Step: 11
Training loss: 0.4124021828174591
Validation loss: 1.5663988846604542

Epoch: 6| Step: 12
Training loss: 0.06281085312366486
Validation loss: 1.5630032875204598

Epoch: 6| Step: 13
Training loss: 0.09147278219461441
Validation loss: 1.5448518517196819

Epoch: 422| Step: 0
Training loss: 0.2104758471250534
Validation loss: 1.5720684284804969

Epoch: 6| Step: 1
Training loss: 0.10363437235355377
Validation loss: 1.5751816547045143

Epoch: 6| Step: 2
Training loss: 0.12149535119533539
Validation loss: 1.578944888166202

Epoch: 6| Step: 3
Training loss: 0.17597785592079163
Validation loss: 1.5715884982898671

Epoch: 6| Step: 4
Training loss: 0.2390533983707428
Validation loss: 1.5631856546607068

Epoch: 6| Step: 5
Training loss: 0.19543883204460144
Validation loss: 1.5701888581757903

Epoch: 6| Step: 6
Training loss: 0.13716456294059753
Validation loss: 1.5422837067675847

Epoch: 6| Step: 7
Training loss: 0.1574419140815735
Validation loss: 1.5329205143836238

Epoch: 6| Step: 8
Training loss: 0.19519203901290894
Validation loss: 1.5412515991477556

Epoch: 6| Step: 9
Training loss: 0.5456779599189758
Validation loss: 1.5914907557989961

Epoch: 6| Step: 10
Training loss: 0.3318448066711426
Validation loss: 1.6438535515980055

Epoch: 6| Step: 11
Training loss: 0.28078722953796387
Validation loss: 1.6176460084094797

Epoch: 6| Step: 12
Training loss: 0.25205498933792114
Validation loss: 1.6087499100674865

Epoch: 6| Step: 13
Training loss: 0.11209934204816818
Validation loss: 1.5843856591050343

Epoch: 423| Step: 0
Training loss: 0.15331760048866272
Validation loss: 1.5581419173107351

Epoch: 6| Step: 1
Training loss: 0.2418437898159027
Validation loss: 1.5407183106227587

Epoch: 6| Step: 2
Training loss: 0.132869154214859
Validation loss: 1.527030478241623

Epoch: 6| Step: 3
Training loss: 0.21500948071479797
Validation loss: 1.5449434993087605

Epoch: 6| Step: 4
Training loss: 0.20910212397575378
Validation loss: 1.5717013612870248

Epoch: 6| Step: 5
Training loss: 0.14328479766845703
Validation loss: 1.5878826918140534

Epoch: 6| Step: 6
Training loss: 0.16244831681251526
Validation loss: 1.621457665197311

Epoch: 6| Step: 7
Training loss: 0.2077907770872116
Validation loss: 1.6126488742008005

Epoch: 6| Step: 8
Training loss: 0.14255689084529877
Validation loss: 1.6362903861589329

Epoch: 6| Step: 9
Training loss: 0.6331843137741089
Validation loss: 1.6468430244794456

Epoch: 6| Step: 10
Training loss: 0.270580917596817
Validation loss: 1.6851505553850563

Epoch: 6| Step: 11
Training loss: 0.16281627118587494
Validation loss: 1.6553249192494217

Epoch: 6| Step: 12
Training loss: 0.1820606291294098
Validation loss: 1.6504031201844573

Epoch: 6| Step: 13
Training loss: 0.17877013981342316
Validation loss: 1.655869407038535

Epoch: 424| Step: 0
Training loss: 0.16535285115242004
Validation loss: 1.6544268182528916

Epoch: 6| Step: 1
Training loss: 0.09507694095373154
Validation loss: 1.629765893823357

Epoch: 6| Step: 2
Training loss: 0.19012576341629028
Validation loss: 1.6493107593187721

Epoch: 6| Step: 3
Training loss: 0.11104198545217514
Validation loss: 1.6221213135668027

Epoch: 6| Step: 4
Training loss: 0.13960078358650208
Validation loss: 1.5937807444603211

Epoch: 6| Step: 5
Training loss: 0.13559302687644958
Validation loss: 1.5825540250347507

Epoch: 6| Step: 6
Training loss: 0.12131020426750183
Validation loss: 1.6034300814392746

Epoch: 6| Step: 7
Training loss: 0.18887493014335632
Validation loss: 1.6327091686187252

Epoch: 6| Step: 8
Training loss: 0.12178035825490952
Validation loss: 1.6027681410953563

Epoch: 6| Step: 9
Training loss: 0.13972002267837524
Validation loss: 1.596692386493888

Epoch: 6| Step: 10
Training loss: 0.1031838059425354
Validation loss: 1.59699083400029

Epoch: 6| Step: 11
Training loss: 0.66768878698349
Validation loss: 1.5618834303271385

Epoch: 6| Step: 12
Training loss: 0.2830665707588196
Validation loss: 1.5897883721577224

Epoch: 6| Step: 13
Training loss: 0.12537379562854767
Validation loss: 1.5788037097582253

Epoch: 425| Step: 0
Training loss: 0.17678333818912506
Validation loss: 1.5910074710845947

Epoch: 6| Step: 1
Training loss: 0.12884804606437683
Validation loss: 1.5836345316261373

Epoch: 6| Step: 2
Training loss: 0.14286503195762634
Validation loss: 1.5924065741159583

Epoch: 6| Step: 3
Training loss: 0.16544827818870544
Validation loss: 1.5983238707306564

Epoch: 6| Step: 4
Training loss: 0.17857903242111206
Validation loss: 1.5856911507985925

Epoch: 6| Step: 5
Training loss: 0.18623539805412292
Validation loss: 1.6046701028782835

Epoch: 6| Step: 6
Training loss: 0.10042781382799149
Validation loss: 1.5841075963871454

Epoch: 6| Step: 7
Training loss: 0.27518463134765625
Validation loss: 1.595805170715496

Epoch: 6| Step: 8
Training loss: 0.12912550568580627
Validation loss: 1.5825198414505168

Epoch: 6| Step: 9
Training loss: 0.5138170719146729
Validation loss: 1.584454539001629

Epoch: 6| Step: 10
Training loss: 0.16552768647670746
Validation loss: 1.6045216411672614

Epoch: 6| Step: 11
Training loss: 0.2047005444765091
Validation loss: 1.6326543022227544

Epoch: 6| Step: 12
Training loss: 0.1274005025625229
Validation loss: 1.6201191352259727

Epoch: 6| Step: 13
Training loss: 0.18493857979774475
Validation loss: 1.6334289837909002

Epoch: 426| Step: 0
Training loss: 0.24017901718616486
Validation loss: 1.6098898879943355

Epoch: 6| Step: 1
Training loss: 0.1916102170944214
Validation loss: 1.5863191402086647

Epoch: 6| Step: 2
Training loss: 0.14184123277664185
Validation loss: 1.5859825636750908

Epoch: 6| Step: 3
Training loss: 0.23895354568958282
Validation loss: 1.571542614890683

Epoch: 6| Step: 4
Training loss: 0.48656848073005676
Validation loss: 1.5842775926795056

Epoch: 6| Step: 5
Training loss: 0.12215107679367065
Validation loss: 1.5621207375680246

Epoch: 6| Step: 6
Training loss: 0.211848646402359
Validation loss: 1.5870605643077562

Epoch: 6| Step: 7
Training loss: 0.1442236602306366
Validation loss: 1.5933860091752903

Epoch: 6| Step: 8
Training loss: 0.12661564350128174
Validation loss: 1.6097231077891525

Epoch: 6| Step: 9
Training loss: 0.16378134489059448
Validation loss: 1.6267551126018647

Epoch: 6| Step: 10
Training loss: 0.10330455750226974
Validation loss: 1.6534087965565343

Epoch: 6| Step: 11
Training loss: 0.3094428777694702
Validation loss: 1.6580778988458778

Epoch: 6| Step: 12
Training loss: 0.1724422127008438
Validation loss: 1.6331739400022773

Epoch: 6| Step: 13
Training loss: 0.18267172574996948
Validation loss: 1.662265714778695

Epoch: 427| Step: 0
Training loss: 0.14464730024337769
Validation loss: 1.6584717496748893

Epoch: 6| Step: 1
Training loss: 0.0989491268992424
Validation loss: 1.6287177737041185

Epoch: 6| Step: 2
Training loss: 0.22453701496124268
Validation loss: 1.613728097690049

Epoch: 6| Step: 3
Training loss: 0.18828347325325012
Validation loss: 1.6282770441424461

Epoch: 6| Step: 4
Training loss: 0.14121615886688232
Validation loss: 1.595286815397201

Epoch: 6| Step: 5
Training loss: 0.5096232891082764
Validation loss: 1.5860839300258185

Epoch: 6| Step: 6
Training loss: 0.12616965174674988
Validation loss: 1.5394885757918

Epoch: 6| Step: 7
Training loss: 0.1624230593442917
Validation loss: 1.5411867095578102

Epoch: 6| Step: 8
Training loss: 0.22086527943611145
Validation loss: 1.586368360827046

Epoch: 6| Step: 9
Training loss: 0.14496996998786926
Validation loss: 1.5710320344535254

Epoch: 6| Step: 10
Training loss: 0.1862155795097351
Validation loss: 1.5747394279767108

Epoch: 6| Step: 11
Training loss: 0.1020294725894928
Validation loss: 1.5467314386880526

Epoch: 6| Step: 12
Training loss: 0.19764474034309387
Validation loss: 1.5524234092363747

Epoch: 6| Step: 13
Training loss: 0.08730415254831314
Validation loss: 1.590591549873352

Epoch: 428| Step: 0
Training loss: 0.4720999598503113
Validation loss: 1.605440003897554

Epoch: 6| Step: 1
Training loss: 0.12234912812709808
Validation loss: 1.6249562412179925

Epoch: 6| Step: 2
Training loss: 0.1922958493232727
Validation loss: 1.6688869050754014

Epoch: 6| Step: 3
Training loss: 0.09749264270067215
Validation loss: 1.6348424316734396

Epoch: 6| Step: 4
Training loss: 0.2237033098936081
Validation loss: 1.6515541871388753

Epoch: 6| Step: 5
Training loss: 0.18370601534843445
Validation loss: 1.6212905132642357

Epoch: 6| Step: 6
Training loss: 0.20950201153755188
Validation loss: 1.6141214345091133

Epoch: 6| Step: 7
Training loss: 0.11478708684444427
Validation loss: 1.6117220488927697

Epoch: 6| Step: 8
Training loss: 0.1179223358631134
Validation loss: 1.5848759835766209

Epoch: 6| Step: 9
Training loss: 0.30367594957351685
Validation loss: 1.5796893706885717

Epoch: 6| Step: 10
Training loss: 0.12860029935836792
Validation loss: 1.5445220649883311

Epoch: 6| Step: 11
Training loss: 0.11916308850049973
Validation loss: 1.5606738636570592

Epoch: 6| Step: 12
Training loss: 0.16483721137046814
Validation loss: 1.54483175405892

Epoch: 6| Step: 13
Training loss: 0.2877994775772095
Validation loss: 1.533086610096757

Epoch: 429| Step: 0
Training loss: 0.19774360954761505
Validation loss: 1.5099773612073673

Epoch: 6| Step: 1
Training loss: 0.6238088607788086
Validation loss: 1.5400025921483194

Epoch: 6| Step: 2
Training loss: 0.14764541387557983
Validation loss: 1.5619124674027967

Epoch: 6| Step: 3
Training loss: 0.13697566092014313
Validation loss: 1.5595543922916535

Epoch: 6| Step: 4
Training loss: 0.2727999687194824
Validation loss: 1.5754060719602851

Epoch: 6| Step: 5
Training loss: 0.14473706483840942
Validation loss: 1.6168676704488776

Epoch: 6| Step: 6
Training loss: 0.0953167974948883
Validation loss: 1.6462076017933507

Epoch: 6| Step: 7
Training loss: 0.18198689818382263
Validation loss: 1.7046469847361247

Epoch: 6| Step: 8
Training loss: 0.2578267455101013
Validation loss: 1.7079889312867196

Epoch: 6| Step: 9
Training loss: 0.20193341374397278
Validation loss: 1.7109997528855518

Epoch: 6| Step: 10
Training loss: 0.21584635972976685
Validation loss: 1.712908020583532

Epoch: 6| Step: 11
Training loss: 0.19772249460220337
Validation loss: 1.6875136936864545

Epoch: 6| Step: 12
Training loss: 0.16427616775035858
Validation loss: 1.6900555344038113

Epoch: 6| Step: 13
Training loss: 0.12316396832466125
Validation loss: 1.6182585224028556

Epoch: 430| Step: 0
Training loss: 0.0863979309797287
Validation loss: 1.662432559074894

Epoch: 6| Step: 1
Training loss: 0.2316637635231018
Validation loss: 1.6517719966109081

Epoch: 6| Step: 2
Training loss: 0.5140504240989685
Validation loss: 1.6365805851515902

Epoch: 6| Step: 3
Training loss: 0.24211058020591736
Validation loss: 1.637403706709544

Epoch: 6| Step: 4
Training loss: 0.27162110805511475
Validation loss: 1.6185056137782272

Epoch: 6| Step: 5
Training loss: 0.16360431909561157
Validation loss: 1.6074087312144618

Epoch: 6| Step: 6
Training loss: 0.1648254245519638
Validation loss: 1.5642132272002518

Epoch: 6| Step: 7
Training loss: 0.13490915298461914
Validation loss: 1.5600085989121468

Epoch: 6| Step: 8
Training loss: 0.263298362493515
Validation loss: 1.533057584557482

Epoch: 6| Step: 9
Training loss: 0.17529025673866272
Validation loss: 1.5544469074536396

Epoch: 6| Step: 10
Training loss: 0.16824518144130707
Validation loss: 1.532185583986262

Epoch: 6| Step: 11
Training loss: 0.12461895495653152
Validation loss: 1.5607429204448577

Epoch: 6| Step: 12
Training loss: 0.1419963538646698
Validation loss: 1.5600477610864947

Epoch: 6| Step: 13
Training loss: 0.181979238986969
Validation loss: 1.601742631645613

Epoch: 431| Step: 0
Training loss: 0.2021816372871399
Validation loss: 1.5740251874410978

Epoch: 6| Step: 1
Training loss: 0.1716836392879486
Validation loss: 1.6184564892963698

Epoch: 6| Step: 2
Training loss: 0.24741797149181366
Validation loss: 1.661184428840555

Epoch: 6| Step: 3
Training loss: 0.14619088172912598
Validation loss: 1.6522281669801282

Epoch: 6| Step: 4
Training loss: 0.12867701053619385
Validation loss: 1.657280565589987

Epoch: 6| Step: 5
Training loss: 0.22292383015155792
Validation loss: 1.6588892372705604

Epoch: 6| Step: 6
Training loss: 0.26677143573760986
Validation loss: 1.653260269472676

Epoch: 6| Step: 7
Training loss: 0.4664750099182129
Validation loss: 1.632845764519066

Epoch: 6| Step: 8
Training loss: 0.22088199853897095
Validation loss: 1.5831643637790476

Epoch: 6| Step: 9
Training loss: 0.18359152972698212
Validation loss: 1.5520599721580424

Epoch: 6| Step: 10
Training loss: 0.23734413087368011
Validation loss: 1.5243703972908758

Epoch: 6| Step: 11
Training loss: 0.11857031285762787
Validation loss: 1.5188327681633733

Epoch: 6| Step: 12
Training loss: 0.134157195687294
Validation loss: 1.4879448836849583

Epoch: 6| Step: 13
Training loss: 0.1438601166009903
Validation loss: 1.5467554446189635

Epoch: 432| Step: 0
Training loss: 0.2477973997592926
Validation loss: 1.4819678401434293

Epoch: 6| Step: 1
Training loss: 0.12656964361667633
Validation loss: 1.5596003929773967

Epoch: 6| Step: 2
Training loss: 0.12330616265535355
Validation loss: 1.5644655766025666

Epoch: 6| Step: 3
Training loss: 0.22634099423885345
Validation loss: 1.6588089619913409

Epoch: 6| Step: 4
Training loss: 0.2109960913658142
Validation loss: 1.6779556697414768

Epoch: 6| Step: 5
Training loss: 0.3129064440727234
Validation loss: 1.7200166615106727

Epoch: 6| Step: 6
Training loss: 0.28384602069854736
Validation loss: 1.7198983302680395

Epoch: 6| Step: 7
Training loss: 0.2510954737663269
Validation loss: 1.6776525666636806

Epoch: 6| Step: 8
Training loss: 0.388641893863678
Validation loss: 1.6452655125689764

Epoch: 6| Step: 9
Training loss: 0.1866317242383957
Validation loss: 1.6181759718925721

Epoch: 6| Step: 10
Training loss: 0.12060393393039703
Validation loss: 1.6012305111013434

Epoch: 6| Step: 11
Training loss: 0.25606751441955566
Validation loss: 1.5938438664200485

Epoch: 6| Step: 12
Training loss: 0.32874274253845215
Validation loss: 1.58407760179171

Epoch: 6| Step: 13
Training loss: 0.7240479588508606
Validation loss: 1.5955715538353048

Epoch: 433| Step: 0
Training loss: 0.2072555422782898
Validation loss: 1.5764544766436341

Epoch: 6| Step: 1
Training loss: 0.1953423023223877
Validation loss: 1.5174107154210408

Epoch: 6| Step: 2
Training loss: 0.1486874222755432
Validation loss: 1.5341604922407417

Epoch: 6| Step: 3
Training loss: 0.18474437296390533
Validation loss: 1.5142523486127135

Epoch: 6| Step: 4
Training loss: 0.19868630170822144
Validation loss: 1.5334916166079942

Epoch: 6| Step: 5
Training loss: 0.13537219166755676
Validation loss: 1.564986526966095

Epoch: 6| Step: 6
Training loss: 0.17374959588050842
Validation loss: 1.6250291120621465

Epoch: 6| Step: 7
Training loss: 0.5148935317993164
Validation loss: 1.593183409783148

Epoch: 6| Step: 8
Training loss: 0.23247571289539337
Validation loss: 1.632580554613503

Epoch: 6| Step: 9
Training loss: 0.12486262619495392
Validation loss: 1.668137954127404

Epoch: 6| Step: 10
Training loss: 0.25438541173934937
Validation loss: 1.6562356538670038

Epoch: 6| Step: 11
Training loss: 0.2492639422416687
Validation loss: 1.6446787708549089

Epoch: 6| Step: 12
Training loss: 0.13616298139095306
Validation loss: 1.5837509221928094

Epoch: 6| Step: 13
Training loss: 0.1694563329219818
Validation loss: 1.6511814222540906

Epoch: 434| Step: 0
Training loss: 0.1502283811569214
Validation loss: 1.6058788120105703

Epoch: 6| Step: 1
Training loss: 0.13432706892490387
Validation loss: 1.5915015641079153

Epoch: 6| Step: 2
Training loss: 0.18200565874576569
Validation loss: 1.5966720939964376

Epoch: 6| Step: 3
Training loss: 0.17877227067947388
Validation loss: 1.6013175902828094

Epoch: 6| Step: 4
Training loss: 0.16772818565368652
Validation loss: 1.5398907456346738

Epoch: 6| Step: 5
Training loss: 0.1695503294467926
Validation loss: 1.5479827350185764

Epoch: 6| Step: 6
Training loss: 0.5399031043052673
Validation loss: 1.5434809980853912

Epoch: 6| Step: 7
Training loss: 0.18206533789634705
Validation loss: 1.5674778581947408

Epoch: 6| Step: 8
Training loss: 0.21106895804405212
Validation loss: 1.5409360752310803

Epoch: 6| Step: 9
Training loss: 0.12546415627002716
Validation loss: 1.5741418202718098

Epoch: 6| Step: 10
Training loss: 0.17726777493953705
Validation loss: 1.592101147097926

Epoch: 6| Step: 11
Training loss: 0.1704232096672058
Validation loss: 1.5637743050052273

Epoch: 6| Step: 12
Training loss: 0.09642273187637329
Validation loss: 1.6136834121519519

Epoch: 6| Step: 13
Training loss: 0.44334468245506287
Validation loss: 1.6317020808496783

Epoch: 435| Step: 0
Training loss: 0.17471249401569366
Validation loss: 1.6232933664834628

Epoch: 6| Step: 1
Training loss: 0.18904252350330353
Validation loss: 1.6155558747629966

Epoch: 6| Step: 2
Training loss: 0.11352197080850601
Validation loss: 1.599738605560795

Epoch: 6| Step: 3
Training loss: 0.2024400681257248
Validation loss: 1.572106376771004

Epoch: 6| Step: 4
Training loss: 0.1918567717075348
Validation loss: 1.5472092038841658

Epoch: 6| Step: 5
Training loss: 0.13712218403816223
Validation loss: 1.5574513494327504

Epoch: 6| Step: 6
Training loss: 0.16474393010139465
Validation loss: 1.5564088667592695

Epoch: 6| Step: 7
Training loss: 0.09609009325504303
Validation loss: 1.5559614627592024

Epoch: 6| Step: 8
Training loss: 0.1559646725654602
Validation loss: 1.554703135644236

Epoch: 6| Step: 9
Training loss: 0.09160086512565613
Validation loss: 1.584637676515887

Epoch: 6| Step: 10
Training loss: 0.5293372869491577
Validation loss: 1.5975990846592893

Epoch: 6| Step: 11
Training loss: 0.20613446831703186
Validation loss: 1.6368554446005052

Epoch: 6| Step: 12
Training loss: 0.1447901427745819
Validation loss: 1.6515063803683045

Epoch: 6| Step: 13
Training loss: 0.1279725283384323
Validation loss: 1.6498480125140118

Epoch: 436| Step: 0
Training loss: 0.19425423443317413
Validation loss: 1.6204662707544142

Epoch: 6| Step: 1
Training loss: 0.06018165498971939
Validation loss: 1.6256818822635117

Epoch: 6| Step: 2
Training loss: 0.121914803981781
Validation loss: 1.5970895533920617

Epoch: 6| Step: 3
Training loss: 0.11456785351037979
Validation loss: 1.598907587348774

Epoch: 6| Step: 4
Training loss: 0.21239526569843292
Validation loss: 1.5722008392375002

Epoch: 6| Step: 5
Training loss: 0.11095083504915237
Validation loss: 1.5746995095283753

Epoch: 6| Step: 6
Training loss: 0.19966042041778564
Validation loss: 1.5826660676669049

Epoch: 6| Step: 7
Training loss: 0.13998207449913025
Validation loss: 1.5972179981970018

Epoch: 6| Step: 8
Training loss: 0.09729647636413574
Validation loss: 1.6100803370116858

Epoch: 6| Step: 9
Training loss: 0.17204633355140686
Validation loss: 1.664522014638429

Epoch: 6| Step: 10
Training loss: 0.25424015522003174
Validation loss: 1.648150231248589

Epoch: 6| Step: 11
Training loss: 0.12408843636512756
Validation loss: 1.6585664979873165

Epoch: 6| Step: 12
Training loss: 0.5711923241615295
Validation loss: 1.6449225820520872

Epoch: 6| Step: 13
Training loss: 0.1711740642786026
Validation loss: 1.6158239585097118

Epoch: 437| Step: 0
Training loss: 0.1396893411874771
Validation loss: 1.5954321853576168

Epoch: 6| Step: 1
Training loss: 0.16314324736595154
Validation loss: 1.5506417097583893

Epoch: 6| Step: 2
Training loss: 0.19949805736541748
Validation loss: 1.549831413453625

Epoch: 6| Step: 3
Training loss: 0.17437699437141418
Validation loss: 1.5570192824127853

Epoch: 6| Step: 4
Training loss: 0.15086159110069275
Validation loss: 1.5104008682312504

Epoch: 6| Step: 5
Training loss: 0.07868817448616028
Validation loss: 1.5144355707271124

Epoch: 6| Step: 6
Training loss: 0.15111754834651947
Validation loss: 1.5595290532676123

Epoch: 6| Step: 7
Training loss: 0.11449721455574036
Validation loss: 1.534123561715567

Epoch: 6| Step: 8
Training loss: 0.6061787009239197
Validation loss: 1.5251137146385767

Epoch: 6| Step: 9
Training loss: 0.12142135947942734
Validation loss: 1.5359292658426429

Epoch: 6| Step: 10
Training loss: 0.13004469871520996
Validation loss: 1.5712359900115638

Epoch: 6| Step: 11
Training loss: 0.12024211138486862
Validation loss: 1.5813547757364088

Epoch: 6| Step: 12
Training loss: 0.15069381892681122
Validation loss: 1.590584974135122

Epoch: 6| Step: 13
Training loss: 0.08665116876363754
Validation loss: 1.6084726190054288

Epoch: 438| Step: 0
Training loss: 0.09281358867883682
Validation loss: 1.6408352851867676

Epoch: 6| Step: 1
Training loss: 0.17477551102638245
Validation loss: 1.6266240342970817

Epoch: 6| Step: 2
Training loss: 0.09780247509479523
Validation loss: 1.6273189180640764

Epoch: 6| Step: 3
Training loss: 0.0677136480808258
Validation loss: 1.6134497734808153

Epoch: 6| Step: 4
Training loss: 0.15369701385498047
Validation loss: 1.5921263374308103

Epoch: 6| Step: 5
Training loss: 0.24994832277297974
Validation loss: 1.5851206753843574

Epoch: 6| Step: 6
Training loss: 0.15385910868644714
Validation loss: 1.5778704535576604

Epoch: 6| Step: 7
Training loss: 0.476421058177948
Validation loss: 1.5697042198591336

Epoch: 6| Step: 8
Training loss: 0.16157445311546326
Validation loss: 1.6216524775310228

Epoch: 6| Step: 9
Training loss: 0.14445480704307556
Validation loss: 1.5555164672995125

Epoch: 6| Step: 10
Training loss: 0.1410907506942749
Validation loss: 1.6085444547796761

Epoch: 6| Step: 11
Training loss: 0.14054352045059204
Validation loss: 1.616648094628447

Epoch: 6| Step: 12
Training loss: 0.14495804905891418
Validation loss: 1.5802063339500017

Epoch: 6| Step: 13
Training loss: 0.1841997355222702
Validation loss: 1.5777855521889144

Epoch: 439| Step: 0
Training loss: 0.20220664143562317
Validation loss: 1.5883452841030654

Epoch: 6| Step: 1
Training loss: 0.10999135673046112
Validation loss: 1.5784443937322146

Epoch: 6| Step: 2
Training loss: 0.12627986073493958
Validation loss: 1.5635212454744565

Epoch: 6| Step: 3
Training loss: 0.13855275511741638
Validation loss: 1.5553871790568035

Epoch: 6| Step: 4
Training loss: 0.20747579634189606
Validation loss: 1.572219471777639

Epoch: 6| Step: 5
Training loss: 0.28106245398521423
Validation loss: 1.5773258234864922

Epoch: 6| Step: 6
Training loss: 0.15947505831718445
Validation loss: 1.566510332527981

Epoch: 6| Step: 7
Training loss: 0.43238145112991333
Validation loss: 1.564841389656067

Epoch: 6| Step: 8
Training loss: 0.1547749787569046
Validation loss: 1.5722307517964353

Epoch: 6| Step: 9
Training loss: 0.10122548043727875
Validation loss: 1.5814412088804348

Epoch: 6| Step: 10
Training loss: 0.14888039231300354
Validation loss: 1.5818548337105782

Epoch: 6| Step: 11
Training loss: 0.15567129850387573
Validation loss: 1.604382990508951

Epoch: 6| Step: 12
Training loss: 0.11713628470897675
Validation loss: 1.6178223689397175

Epoch: 6| Step: 13
Training loss: 0.06897732615470886
Validation loss: 1.634140133857727

Epoch: 440| Step: 0
Training loss: 0.18161773681640625
Validation loss: 1.6108287675406343

Epoch: 6| Step: 1
Training loss: 0.523289144039154
Validation loss: 1.60150138408907

Epoch: 6| Step: 2
Training loss: 0.17992231249809265
Validation loss: 1.5983171911649807

Epoch: 6| Step: 3
Training loss: 0.14554144442081451
Validation loss: 1.58813141751033

Epoch: 6| Step: 4
Training loss: 0.2640094459056854
Validation loss: 1.5554450314532045

Epoch: 6| Step: 5
Training loss: 0.08479447662830353
Validation loss: 1.5579828639184274

Epoch: 6| Step: 6
Training loss: 0.12041168659925461
Validation loss: 1.5528630313052927

Epoch: 6| Step: 7
Training loss: 0.19109494984149933
Validation loss: 1.5521209086141279

Epoch: 6| Step: 8
Training loss: 0.2797272801399231
Validation loss: 1.5433535473321074

Epoch: 6| Step: 9
Training loss: 0.10418733954429626
Validation loss: 1.5644743134898524

Epoch: 6| Step: 10
Training loss: 0.10327758640050888
Validation loss: 1.5494933525721233

Epoch: 6| Step: 11
Training loss: 0.15005409717559814
Validation loss: 1.5381774774161718

Epoch: 6| Step: 12
Training loss: 0.09210153669118881
Validation loss: 1.5426388927685317

Epoch: 6| Step: 13
Training loss: 0.16014574468135834
Validation loss: 1.5405202219563146

Epoch: 441| Step: 0
Training loss: 0.43113136291503906
Validation loss: 1.567394374519266

Epoch: 6| Step: 1
Training loss: 0.1303272843360901
Validation loss: 1.5651808054216447

Epoch: 6| Step: 2
Training loss: 0.1329880952835083
Validation loss: 1.6092034462959535

Epoch: 6| Step: 3
Training loss: 0.1215830072760582
Validation loss: 1.586209939372155

Epoch: 6| Step: 4
Training loss: 0.10842007398605347
Validation loss: 1.5697134585790737

Epoch: 6| Step: 5
Training loss: 0.12017887830734253
Validation loss: 1.6091744951022569

Epoch: 6| Step: 6
Training loss: 0.14654219150543213
Validation loss: 1.571266116634492

Epoch: 6| Step: 7
Training loss: 0.26466578245162964
Validation loss: 1.5510072567129647

Epoch: 6| Step: 8
Training loss: 0.2522618770599365
Validation loss: 1.5630923881325671

Epoch: 6| Step: 9
Training loss: 0.09114246815443039
Validation loss: 1.572408042928224

Epoch: 6| Step: 10
Training loss: 0.15417812764644623
Validation loss: 1.560879909864036

Epoch: 6| Step: 11
Training loss: 0.1142541766166687
Validation loss: 1.5581268764311267

Epoch: 6| Step: 12
Training loss: 0.1158781573176384
Validation loss: 1.5738009868129608

Epoch: 6| Step: 13
Training loss: 0.15272003412246704
Validation loss: 1.5753659779025662

Epoch: 442| Step: 0
Training loss: 0.1126965880393982
Validation loss: 1.6271589667566362

Epoch: 6| Step: 1
Training loss: 0.14501410722732544
Validation loss: 1.5465023825245519

Epoch: 6| Step: 2
Training loss: 0.18205684423446655
Validation loss: 1.5395244603515954

Epoch: 6| Step: 3
Training loss: 0.2460063397884369
Validation loss: 1.5152656519284813

Epoch: 6| Step: 4
Training loss: 0.16223938763141632
Validation loss: 1.5396064250699935

Epoch: 6| Step: 5
Training loss: 0.15158942341804504
Validation loss: 1.5614753820562874

Epoch: 6| Step: 6
Training loss: 0.14829808473587036
Validation loss: 1.5418419453405565

Epoch: 6| Step: 7
Training loss: 0.1494135558605194
Validation loss: 1.5573683861763246

Epoch: 6| Step: 8
Training loss: 0.4099244475364685
Validation loss: 1.617098735224816

Epoch: 6| Step: 9
Training loss: 0.13075508177280426
Validation loss: 1.6314453860764861

Epoch: 6| Step: 10
Training loss: 0.16599956154823303
Validation loss: 1.6549051961591166

Epoch: 6| Step: 11
Training loss: 0.16411134600639343
Validation loss: 1.647055923297841

Epoch: 6| Step: 12
Training loss: 0.20447036623954773
Validation loss: 1.6906749785587352

Epoch: 6| Step: 13
Training loss: 0.1866745948791504
Validation loss: 1.6804652137141074

Epoch: 443| Step: 0
Training loss: 0.12946678698062897
Validation loss: 1.6718238015328684

Epoch: 6| Step: 1
Training loss: 0.18459957838058472
Validation loss: 1.6695628576381232

Epoch: 6| Step: 2
Training loss: 0.21963618695735931
Validation loss: 1.6274616949019893

Epoch: 6| Step: 3
Training loss: 0.13033396005630493
Validation loss: 1.64018097231465

Epoch: 6| Step: 4
Training loss: 0.16626448929309845
Validation loss: 1.6256945633119153

Epoch: 6| Step: 5
Training loss: 0.1371031105518341
Validation loss: 1.553646702920237

Epoch: 6| Step: 6
Training loss: 0.09089398384094238
Validation loss: 1.5228255679530482

Epoch: 6| Step: 7
Training loss: 0.18621177971363068
Validation loss: 1.5012623289579987

Epoch: 6| Step: 8
Training loss: 0.1827296018600464
Validation loss: 1.5089086845356932

Epoch: 6| Step: 9
Training loss: 0.5007420778274536
Validation loss: 1.502349558696952

Epoch: 6| Step: 10
Training loss: 0.1547776311635971
Validation loss: 1.5343723220209922

Epoch: 6| Step: 11
Training loss: 0.2949172258377075
Validation loss: 1.52323470833481

Epoch: 6| Step: 12
Training loss: 0.14619266986846924
Validation loss: 1.5538367609823904

Epoch: 6| Step: 13
Training loss: 0.13890130817890167
Validation loss: 1.557442081871853

Epoch: 444| Step: 0
Training loss: 0.18728531897068024
Validation loss: 1.5680702847819175

Epoch: 6| Step: 1
Training loss: 0.0927731841802597
Validation loss: 1.6348303928170154

Epoch: 6| Step: 2
Training loss: 0.12973611056804657
Validation loss: 1.6723285862194595

Epoch: 6| Step: 3
Training loss: 0.22694244980812073
Validation loss: 1.6733686116433912

Epoch: 6| Step: 4
Training loss: 0.29070210456848145
Validation loss: 1.6503792526901409

Epoch: 6| Step: 5
Training loss: 0.16972188651561737
Validation loss: 1.6189739191403953

Epoch: 6| Step: 6
Training loss: 0.11356569826602936
Validation loss: 1.6016315683241813

Epoch: 6| Step: 7
Training loss: 0.10984964668750763
Validation loss: 1.540946513093928

Epoch: 6| Step: 8
Training loss: 0.42077749967575073
Validation loss: 1.5145228396179855

Epoch: 6| Step: 9
Training loss: 0.09904374182224274
Validation loss: 1.5194037851466928

Epoch: 6| Step: 10
Training loss: 0.23514914512634277
Validation loss: 1.54282420937733

Epoch: 6| Step: 11
Training loss: 0.10973178595304489
Validation loss: 1.54643678152433

Epoch: 6| Step: 12
Training loss: 0.2169068455696106
Validation loss: 1.5322339445032098

Epoch: 6| Step: 13
Training loss: 0.19870108366012573
Validation loss: 1.523609629241369

Epoch: 445| Step: 0
Training loss: 0.12820419669151306
Validation loss: 1.532579723224845

Epoch: 6| Step: 1
Training loss: 0.20966938138008118
Validation loss: 1.5157820550344323

Epoch: 6| Step: 2
Training loss: 0.20621414482593536
Validation loss: 1.5256089459183395

Epoch: 6| Step: 3
Training loss: 0.10603548586368561
Validation loss: 1.517313285540509

Epoch: 6| Step: 4
Training loss: 0.11560586094856262
Validation loss: 1.5351668685995123

Epoch: 6| Step: 5
Training loss: 0.1636120229959488
Validation loss: 1.5640409954132573

Epoch: 6| Step: 6
Training loss: 0.23054802417755127
Validation loss: 1.6014153931730537

Epoch: 6| Step: 7
Training loss: 0.4683825373649597
Validation loss: 1.6016267409888647

Epoch: 6| Step: 8
Training loss: 0.18468664586544037
Validation loss: 1.5827413118013771

Epoch: 6| Step: 9
Training loss: 0.12722699344158173
Validation loss: 1.563563237908066

Epoch: 6| Step: 10
Training loss: 0.16949941217899323
Validation loss: 1.5486240175462538

Epoch: 6| Step: 11
Training loss: 0.15200558304786682
Validation loss: 1.5133428086516678

Epoch: 6| Step: 12
Training loss: 0.22419200837612152
Validation loss: 1.5163401531916794

Epoch: 6| Step: 13
Training loss: 0.13740022480487823
Validation loss: 1.496277445106096

Epoch: 446| Step: 0
Training loss: 0.15129874646663666
Validation loss: 1.5114201179114721

Epoch: 6| Step: 1
Training loss: 0.08391816914081573
Validation loss: 1.4851602174902474

Epoch: 6| Step: 2
Training loss: 0.15290789306163788
Validation loss: 1.5051164934712071

Epoch: 6| Step: 3
Training loss: 0.12639263272285461
Validation loss: 1.4730714969737555

Epoch: 6| Step: 4
Training loss: 0.1413159966468811
Validation loss: 1.500475900147551

Epoch: 6| Step: 5
Training loss: 0.17073169350624084
Validation loss: 1.5225688577980123

Epoch: 6| Step: 6
Training loss: 0.11164948344230652
Validation loss: 1.5192960718626618

Epoch: 6| Step: 7
Training loss: 0.1986445039510727
Validation loss: 1.5085125982120473

Epoch: 6| Step: 8
Training loss: 0.14981427788734436
Validation loss: 1.5371773204495829

Epoch: 6| Step: 9
Training loss: 0.4620741307735443
Validation loss: 1.5677028753424203

Epoch: 6| Step: 10
Training loss: 0.15426522493362427
Validation loss: 1.5525550983285392

Epoch: 6| Step: 11
Training loss: 0.18321964144706726
Validation loss: 1.5612148636130876

Epoch: 6| Step: 12
Training loss: 0.10823723673820496
Validation loss: 1.5693885100785123

Epoch: 6| Step: 13
Training loss: 0.13143841922283173
Validation loss: 1.5728933708642119

Epoch: 447| Step: 0
Training loss: 0.14984150230884552
Validation loss: 1.5630419574758059

Epoch: 6| Step: 1
Training loss: 0.23377113044261932
Validation loss: 1.5927508697714856

Epoch: 6| Step: 2
Training loss: 0.1354386806488037
Validation loss: 1.5735036326992897

Epoch: 6| Step: 3
Training loss: 0.44290903210639954
Validation loss: 1.564273779110242

Epoch: 6| Step: 4
Training loss: 0.14786745607852936
Validation loss: 1.5828667456103909

Epoch: 6| Step: 5
Training loss: 0.14541088044643402
Validation loss: 1.5706917105182525

Epoch: 6| Step: 6
Training loss: 0.08685600012540817
Validation loss: 1.5448285354081022

Epoch: 6| Step: 7
Training loss: 0.07214732468128204
Validation loss: 1.5198926233476209

Epoch: 6| Step: 8
Training loss: 0.1718446910381317
Validation loss: 1.5365032662627518

Epoch: 6| Step: 9
Training loss: 0.11370309442281723
Validation loss: 1.5336922471241285

Epoch: 6| Step: 10
Training loss: 0.24431654810905457
Validation loss: 1.5446973231530958

Epoch: 6| Step: 11
Training loss: 0.18463140726089478
Validation loss: 1.543007053354735

Epoch: 6| Step: 12
Training loss: 0.10617616772651672
Validation loss: 1.5493403916717858

Epoch: 6| Step: 13
Training loss: 0.20691701769828796
Validation loss: 1.5682995088638798

Epoch: 448| Step: 0
Training loss: 0.13588355481624603
Validation loss: 1.5876608958808325

Epoch: 6| Step: 1
Training loss: 0.10190856456756592
Validation loss: 1.5847155438956393

Epoch: 6| Step: 2
Training loss: 0.22426041960716248
Validation loss: 1.6513563894456433

Epoch: 6| Step: 3
Training loss: 0.09558816999197006
Validation loss: 1.6266168407214585

Epoch: 6| Step: 4
Training loss: 0.11529254913330078
Validation loss: 1.6322090113034813

Epoch: 6| Step: 5
Training loss: 0.18356330692768097
Validation loss: 1.6352771956433532

Epoch: 6| Step: 6
Training loss: 0.12847112119197845
Validation loss: 1.6316915558230491

Epoch: 6| Step: 7
Training loss: 0.10994051396846771
Validation loss: 1.6299794937974663

Epoch: 6| Step: 8
Training loss: 0.16932661831378937
Validation loss: 1.655221616068194

Epoch: 6| Step: 9
Training loss: 0.19590899348258972
Validation loss: 1.6095918839977634

Epoch: 6| Step: 10
Training loss: 0.0809950977563858
Validation loss: 1.6084365703726327

Epoch: 6| Step: 11
Training loss: 0.15420770645141602
Validation loss: 1.554840903128347

Epoch: 6| Step: 12
Training loss: 0.4411690831184387
Validation loss: 1.5340642416349022

Epoch: 6| Step: 13
Training loss: 0.18919378519058228
Validation loss: 1.5492182777773948

Epoch: 449| Step: 0
Training loss: 0.17346632480621338
Validation loss: 1.50870128216282

Epoch: 6| Step: 1
Training loss: 0.15808895230293274
Validation loss: 1.5310569411964827

Epoch: 6| Step: 2
Training loss: 0.18493613600730896
Validation loss: 1.5547110611392605

Epoch: 6| Step: 3
Training loss: 0.1740216165781021
Validation loss: 1.5359897587888984

Epoch: 6| Step: 4
Training loss: 0.1063719242811203
Validation loss: 1.6195766015719342

Epoch: 6| Step: 5
Training loss: 0.11227621138095856
Validation loss: 1.57388638424617

Epoch: 6| Step: 6
Training loss: 0.12081080675125122
Validation loss: 1.577110061081507

Epoch: 6| Step: 7
Training loss: 0.0916028693318367
Validation loss: 1.5745973510126914

Epoch: 6| Step: 8
Training loss: 0.07848052680492401
Validation loss: 1.5778409896358367

Epoch: 6| Step: 9
Training loss: 0.12024398148059845
Validation loss: 1.5947038435166883

Epoch: 6| Step: 10
Training loss: 0.19202038645744324
Validation loss: 1.6267167355424614

Epoch: 6| Step: 11
Training loss: 0.21392902731895447
Validation loss: 1.5919647011705624

Epoch: 6| Step: 12
Training loss: 0.19364312291145325
Validation loss: 1.636869861233619

Epoch: 6| Step: 13
Training loss: 0.7538778781890869
Validation loss: 1.587695719093405

Epoch: 450| Step: 0
Training loss: 0.07505397498607635
Validation loss: 1.5613921316721107

Epoch: 6| Step: 1
Training loss: 0.08008167892694473
Validation loss: 1.580254393239175

Epoch: 6| Step: 2
Training loss: 0.41078662872314453
Validation loss: 1.5619273698458107

Epoch: 6| Step: 3
Training loss: 0.07187674939632416
Validation loss: 1.53309000948424

Epoch: 6| Step: 4
Training loss: 0.13804630935192108
Validation loss: 1.5318608783906507

Epoch: 6| Step: 5
Training loss: 0.1732301414012909
Validation loss: 1.5261475475885535

Epoch: 6| Step: 6
Training loss: 0.11478810012340546
Validation loss: 1.5189635253721667

Epoch: 6| Step: 7
Training loss: 0.1314830631017685
Validation loss: 1.5323356075953412

Epoch: 6| Step: 8
Training loss: 0.10486921668052673
Validation loss: 1.5008972178223312

Epoch: 6| Step: 9
Training loss: 0.14192292094230652
Validation loss: 1.501254363726544

Epoch: 6| Step: 10
Training loss: 0.18967509269714355
Validation loss: 1.5346556427658244

Epoch: 6| Step: 11
Training loss: 0.22186589241027832
Validation loss: 1.5337141201060305

Epoch: 6| Step: 12
Training loss: 0.10813100636005402
Validation loss: 1.531976314001186

Epoch: 6| Step: 13
Training loss: 0.15094693005084991
Validation loss: 1.5423965249010312

Epoch: 451| Step: 0
Training loss: 0.09367377310991287
Validation loss: 1.5575810683670865

Epoch: 6| Step: 1
Training loss: 0.13489699363708496
Validation loss: 1.5763234957571952

Epoch: 6| Step: 2
Training loss: 0.1372242122888565
Validation loss: 1.60194073248935

Epoch: 6| Step: 3
Training loss: 0.26759180426597595
Validation loss: 1.5739819516417801

Epoch: 6| Step: 4
Training loss: 0.0642794594168663
Validation loss: 1.5947608678571639

Epoch: 6| Step: 5
Training loss: 0.4424203038215637
Validation loss: 1.5904512379759101

Epoch: 6| Step: 6
Training loss: 0.10938437283039093
Validation loss: 1.5607203373344996

Epoch: 6| Step: 7
Training loss: 0.16178011894226074
Validation loss: 1.5414813244214622

Epoch: 6| Step: 8
Training loss: 0.10279366374015808
Validation loss: 1.536370550432513

Epoch: 6| Step: 9
Training loss: 0.07955653220415115
Validation loss: 1.5618636390214324

Epoch: 6| Step: 10
Training loss: 0.08361513912677765
Validation loss: 1.5510149335348478

Epoch: 6| Step: 11
Training loss: 0.0838894322514534
Validation loss: 1.5406608132905857

Epoch: 6| Step: 12
Training loss: 0.16441099345684052
Validation loss: 1.5153817419082887

Epoch: 6| Step: 13
Training loss: 0.0820198580622673
Validation loss: 1.537354370599152

Epoch: 452| Step: 0
Training loss: 0.15461158752441406
Validation loss: 1.5176246025229012

Epoch: 6| Step: 1
Training loss: 0.1027696281671524
Validation loss: 1.5435349249070691

Epoch: 6| Step: 2
Training loss: 0.2122574746608734
Validation loss: 1.5413547856833345

Epoch: 6| Step: 3
Training loss: 0.15214678645133972
Validation loss: 1.5745313334208664

Epoch: 6| Step: 4
Training loss: 0.154575914144516
Validation loss: 1.5411609424057828

Epoch: 6| Step: 5
Training loss: 0.12069189548492432
Validation loss: 1.5746794234039962

Epoch: 6| Step: 6
Training loss: 0.42451122403144836
Validation loss: 1.5441268515843216

Epoch: 6| Step: 7
Training loss: 0.08971287310123444
Validation loss: 1.57255349492514

Epoch: 6| Step: 8
Training loss: 0.06408805400133133
Validation loss: 1.5634002839365313

Epoch: 6| Step: 9
Training loss: 0.06744880974292755
Validation loss: 1.5546291464118547

Epoch: 6| Step: 10
Training loss: 0.1642453968524933
Validation loss: 1.5047834150252803

Epoch: 6| Step: 11
Training loss: 0.1092815101146698
Validation loss: 1.5271682297029803

Epoch: 6| Step: 12
Training loss: 0.1772281378507614
Validation loss: 1.531541052684989

Epoch: 6| Step: 13
Training loss: 0.04659794270992279
Validation loss: 1.5391115129634898

Epoch: 453| Step: 0
Training loss: 0.09805658459663391
Validation loss: 1.5336221430891304

Epoch: 6| Step: 1
Training loss: 0.09566677361726761
Validation loss: 1.5228651185189523

Epoch: 6| Step: 2
Training loss: 0.096096470952034
Validation loss: 1.5045888334192254

Epoch: 6| Step: 3
Training loss: 0.11860449612140656
Validation loss: 1.5286833304230885

Epoch: 6| Step: 4
Training loss: 0.17316347360610962
Validation loss: 1.5284999698720954

Epoch: 6| Step: 5
Training loss: 0.510211169719696
Validation loss: 1.5540573904591222

Epoch: 6| Step: 6
Training loss: 0.1555754691362381
Validation loss: 1.5353312723098262

Epoch: 6| Step: 7
Training loss: 0.13125649094581604
Validation loss: 1.5500554743633475

Epoch: 6| Step: 8
Training loss: 0.12559309601783752
Validation loss: 1.581575188585507

Epoch: 6| Step: 9
Training loss: 0.14005246758460999
Validation loss: 1.5714213719931982

Epoch: 6| Step: 10
Training loss: 0.11125995218753815
Validation loss: 1.6282288720530849

Epoch: 6| Step: 11
Training loss: 0.11556465923786163
Validation loss: 1.623022803696253

Epoch: 6| Step: 12
Training loss: 0.13995352387428284
Validation loss: 1.6142618412612586

Epoch: 6| Step: 13
Training loss: 0.05010880529880524
Validation loss: 1.597043147651098

Epoch: 454| Step: 0
Training loss: 0.1493077278137207
Validation loss: 1.6038923789096136

Epoch: 6| Step: 1
Training loss: 0.08002358675003052
Validation loss: 1.593021132612741

Epoch: 6| Step: 2
Training loss: 0.1271786093711853
Validation loss: 1.5784863759112615

Epoch: 6| Step: 3
Training loss: 0.10838345438241959
Validation loss: 1.564778366396504

Epoch: 6| Step: 4
Training loss: 0.12416211515665054
Validation loss: 1.527543246105153

Epoch: 6| Step: 5
Training loss: 0.4280775785446167
Validation loss: 1.5428292520584599

Epoch: 6| Step: 6
Training loss: 0.10887554287910461
Validation loss: 1.535425687348971

Epoch: 6| Step: 7
Training loss: 0.12874050438404083
Validation loss: 1.524955012465036

Epoch: 6| Step: 8
Training loss: 0.18931248784065247
Validation loss: 1.5308833006889588

Epoch: 6| Step: 9
Training loss: 0.10358447581529617
Validation loss: 1.520073757376722

Epoch: 6| Step: 10
Training loss: 0.0790167897939682
Validation loss: 1.5378738782739128

Epoch: 6| Step: 11
Training loss: 0.09837792813777924
Validation loss: 1.545989869743265

Epoch: 6| Step: 12
Training loss: 0.19210389256477356
Validation loss: 1.5740933610546974

Epoch: 6| Step: 13
Training loss: 0.048234641551971436
Validation loss: 1.555485648493613

Epoch: 455| Step: 0
Training loss: 0.11614672839641571
Validation loss: 1.5653605730302873

Epoch: 6| Step: 1
Training loss: 0.19051718711853027
Validation loss: 1.5845908695651638

Epoch: 6| Step: 2
Training loss: 0.16029393672943115
Validation loss: 1.585324636069677

Epoch: 6| Step: 3
Training loss: 0.12821805477142334
Validation loss: 1.5765453307859358

Epoch: 6| Step: 4
Training loss: 0.1257961541414261
Validation loss: 1.5346245470867361

Epoch: 6| Step: 5
Training loss: 0.13880741596221924
Validation loss: 1.5022632562985985

Epoch: 6| Step: 6
Training loss: 0.12661653757095337
Validation loss: 1.5139837194514532

Epoch: 6| Step: 7
Training loss: 0.1044791042804718
Validation loss: 1.5451405702098724

Epoch: 6| Step: 8
Training loss: 0.11449980735778809
Validation loss: 1.5102698956766436

Epoch: 6| Step: 9
Training loss: 0.20119917392730713
Validation loss: 1.5116243670063634

Epoch: 6| Step: 10
Training loss: 0.1694153994321823
Validation loss: 1.51759668191274

Epoch: 6| Step: 11
Training loss: 0.12355831265449524
Validation loss: 1.5037512035780056

Epoch: 6| Step: 12
Training loss: 0.4404726028442383
Validation loss: 1.540444318966199

Epoch: 6| Step: 13
Training loss: 0.23078295588493347
Validation loss: 1.512451224429633

Epoch: 456| Step: 0
Training loss: 0.08120343089103699
Validation loss: 1.491744218334075

Epoch: 6| Step: 1
Training loss: 0.39994871616363525
Validation loss: 1.531873022356341

Epoch: 6| Step: 2
Training loss: 0.1013408899307251
Validation loss: 1.5431149698072864

Epoch: 6| Step: 3
Training loss: 0.20385140180587769
Validation loss: 1.5594467847577986

Epoch: 6| Step: 4
Training loss: 0.16593347489833832
Validation loss: 1.5583442488024313

Epoch: 6| Step: 5
Training loss: 0.12111247330904007
Validation loss: 1.5642470890475857

Epoch: 6| Step: 6
Training loss: 0.06665406376123428
Validation loss: 1.588108189644352

Epoch: 6| Step: 7
Training loss: 0.12405966222286224
Validation loss: 1.5583741382886005

Epoch: 6| Step: 8
Training loss: 0.11164688318967819
Validation loss: 1.6047325800823908

Epoch: 6| Step: 9
Training loss: 0.17143391072750092
Validation loss: 1.583332182258688

Epoch: 6| Step: 10
Training loss: 0.12720952928066254
Validation loss: 1.566641423010057

Epoch: 6| Step: 11
Training loss: 0.08835990726947784
Validation loss: 1.5851366314836728

Epoch: 6| Step: 12
Training loss: 0.1887093186378479
Validation loss: 1.5783597346275084

Epoch: 6| Step: 13
Training loss: 0.13050805032253265
Validation loss: 1.569294988468129

Epoch: 457| Step: 0
Training loss: 0.11199291795492172
Validation loss: 1.5419832429578226

Epoch: 6| Step: 1
Training loss: 0.1873917132616043
Validation loss: 1.5459096790641866

Epoch: 6| Step: 2
Training loss: 0.1975286453962326
Validation loss: 1.5369858626396424

Epoch: 6| Step: 3
Training loss: 0.1114645004272461
Validation loss: 1.5618085015204646

Epoch: 6| Step: 4
Training loss: 0.10661861300468445
Validation loss: 1.5606731676286267

Epoch: 6| Step: 5
Training loss: 0.11850129067897797
Validation loss: 1.5659837017777145

Epoch: 6| Step: 6
Training loss: 0.09048407524824142
Validation loss: 1.5544336765043196

Epoch: 6| Step: 7
Training loss: 0.13354383409023285
Validation loss: 1.5383004808938632

Epoch: 6| Step: 8
Training loss: 0.1760648488998413
Validation loss: 1.5519993766661613

Epoch: 6| Step: 9
Training loss: 0.11171765625476837
Validation loss: 1.563046883511287

Epoch: 6| Step: 10
Training loss: 0.08016092330217361
Validation loss: 1.527386934526505

Epoch: 6| Step: 11
Training loss: 0.11721305549144745
Validation loss: 1.5028823998666578

Epoch: 6| Step: 12
Training loss: 0.41903284192085266
Validation loss: 1.5204138525070683

Epoch: 6| Step: 13
Training loss: 0.15279684960842133
Validation loss: 1.5072534545775382

Epoch: 458| Step: 0
Training loss: 0.1678120493888855
Validation loss: 1.5225238389866327

Epoch: 6| Step: 1
Training loss: 0.17046265304088593
Validation loss: 1.5170226635471467

Epoch: 6| Step: 2
Training loss: 0.08275087177753448
Validation loss: 1.5517210652751308

Epoch: 6| Step: 3
Training loss: 0.13546516001224518
Validation loss: 1.5262078604390543

Epoch: 6| Step: 4
Training loss: 0.12416952848434448
Validation loss: 1.5052843081053866

Epoch: 6| Step: 5
Training loss: 0.10899219661951065
Validation loss: 1.5171125140241397

Epoch: 6| Step: 6
Training loss: 0.4238046407699585
Validation loss: 1.5257834708818825

Epoch: 6| Step: 7
Training loss: 0.12659986317157745
Validation loss: 1.5049192636243758

Epoch: 6| Step: 8
Training loss: 0.1174178272485733
Validation loss: 1.5210666284766248

Epoch: 6| Step: 9
Training loss: 0.1951552927494049
Validation loss: 1.5553324100791768

Epoch: 6| Step: 10
Training loss: 0.14140284061431885
Validation loss: 1.5740089621595157

Epoch: 6| Step: 11
Training loss: 0.11733666062355042
Validation loss: 1.56404459604653

Epoch: 6| Step: 12
Training loss: 0.1350538730621338
Validation loss: 1.566362525186231

Epoch: 6| Step: 13
Training loss: 0.10976922512054443
Validation loss: 1.58308099034012

Epoch: 459| Step: 0
Training loss: 0.07234334200620651
Validation loss: 1.5840996632011988

Epoch: 6| Step: 1
Training loss: 0.14907245337963104
Validation loss: 1.5633675661138309

Epoch: 6| Step: 2
Training loss: 0.12461433559656143
Validation loss: 1.5740402526752924

Epoch: 6| Step: 3
Training loss: 0.1241128146648407
Validation loss: 1.5659549018388152

Epoch: 6| Step: 4
Training loss: 0.14436465501785278
Validation loss: 1.5787520177902714

Epoch: 6| Step: 5
Training loss: 0.11561945825815201
Validation loss: 1.6077244820133332

Epoch: 6| Step: 6
Training loss: 0.10915709286928177
Validation loss: 1.5525467780328566

Epoch: 6| Step: 7
Training loss: 0.10729832202196121
Validation loss: 1.532522548911392

Epoch: 6| Step: 8
Training loss: 0.15049129724502563
Validation loss: 1.526596748700706

Epoch: 6| Step: 9
Training loss: 0.24200797080993652
Validation loss: 1.5118923328256095

Epoch: 6| Step: 10
Training loss: 0.4284704923629761
Validation loss: 1.5231839027456058

Epoch: 6| Step: 11
Training loss: 0.15595200657844543
Validation loss: 1.520064821807287

Epoch: 6| Step: 12
Training loss: 0.14756402373313904
Validation loss: 1.5380542714108703

Epoch: 6| Step: 13
Training loss: 0.13473716378211975
Validation loss: 1.5571237853778306

Epoch: 460| Step: 0
Training loss: 0.4451524317264557
Validation loss: 1.566884530487881

Epoch: 6| Step: 1
Training loss: 0.11569469422101974
Validation loss: 1.5886082059593611

Epoch: 6| Step: 2
Training loss: 0.09344132244586945
Validation loss: 1.5971412940691876

Epoch: 6| Step: 3
Training loss: 0.13508158922195435
Validation loss: 1.5785090346490183

Epoch: 6| Step: 4
Training loss: 0.11417749524116516
Validation loss: 1.5849100107787757

Epoch: 6| Step: 5
Training loss: 0.09826265275478363
Validation loss: 1.5462913910547893

Epoch: 6| Step: 6
Training loss: 0.12204946577548981
Validation loss: 1.5703169953438543

Epoch: 6| Step: 7
Training loss: 0.0841921716928482
Validation loss: 1.5543230669472807

Epoch: 6| Step: 8
Training loss: 0.12108991295099258
Validation loss: 1.5322050715005526

Epoch: 6| Step: 9
Training loss: 0.09857527911663055
Validation loss: 1.4938252972018333

Epoch: 6| Step: 10
Training loss: 0.2116757333278656
Validation loss: 1.50674396176492

Epoch: 6| Step: 11
Training loss: 0.16455399990081787
Validation loss: 1.532414049230596

Epoch: 6| Step: 12
Training loss: 0.1645217388868332
Validation loss: 1.515133971809059

Epoch: 6| Step: 13
Training loss: 0.09375551342964172
Validation loss: 1.5396213095675233

Epoch: 461| Step: 0
Training loss: 0.18587051331996918
Validation loss: 1.583307118826015

Epoch: 6| Step: 1
Training loss: 0.19596260786056519
Validation loss: 1.5386738777160645

Epoch: 6| Step: 2
Training loss: 0.15982748568058014
Validation loss: 1.6251608787044403

Epoch: 6| Step: 3
Training loss: 0.07837791740894318
Validation loss: 1.5969522935087963

Epoch: 6| Step: 4
Training loss: 0.0953146293759346
Validation loss: 1.5876499491353189

Epoch: 6| Step: 5
Training loss: 0.4660973846912384
Validation loss: 1.5797946132639402

Epoch: 6| Step: 6
Training loss: 0.09224104136228561
Validation loss: 1.5719335899558118

Epoch: 6| Step: 7
Training loss: 0.09849990904331207
Validation loss: 1.5569369369937527

Epoch: 6| Step: 8
Training loss: 0.07366784662008286
Validation loss: 1.5483221802660214

Epoch: 6| Step: 9
Training loss: 0.11812900006771088
Validation loss: 1.5344325214303949

Epoch: 6| Step: 10
Training loss: 0.13786908984184265
Validation loss: 1.5138831151429044

Epoch: 6| Step: 11
Training loss: 0.11916743218898773
Validation loss: 1.5087175010353007

Epoch: 6| Step: 12
Training loss: 0.1541280746459961
Validation loss: 1.5243137331419094

Epoch: 6| Step: 13
Training loss: 0.20208436250686646
Validation loss: 1.5031619994871077

Epoch: 462| Step: 0
Training loss: 0.09935006499290466
Validation loss: 1.5224793444397628

Epoch: 6| Step: 1
Training loss: 0.08257637917995453
Validation loss: 1.5153509801433933

Epoch: 6| Step: 2
Training loss: 0.14540553092956543
Validation loss: 1.5325366579076296

Epoch: 6| Step: 3
Training loss: 0.09002333879470825
Validation loss: 1.5281264166678152

Epoch: 6| Step: 4
Training loss: 0.07349416613578796
Validation loss: 1.5702449596056374

Epoch: 6| Step: 5
Training loss: 0.42869433760643005
Validation loss: 1.5605779437608616

Epoch: 6| Step: 6
Training loss: 0.09581845998764038
Validation loss: 1.5682741583034556

Epoch: 6| Step: 7
Training loss: 0.14028872549533844
Validation loss: 1.5544857927547988

Epoch: 6| Step: 8
Training loss: 0.10162670165300369
Validation loss: 1.5389017802412792

Epoch: 6| Step: 9
Training loss: 0.2507511377334595
Validation loss: 1.5554261399853615

Epoch: 6| Step: 10
Training loss: 0.07505880296230316
Validation loss: 1.5416892484952045

Epoch: 6| Step: 11
Training loss: 0.13173402845859528
Validation loss: 1.5567940960648239

Epoch: 6| Step: 12
Training loss: 0.08867757022380829
Validation loss: 1.587536293973205

Epoch: 6| Step: 13
Training loss: 0.15850350260734558
Validation loss: 1.5791578472301524

Epoch: 463| Step: 0
Training loss: 0.11969034373760223
Validation loss: 1.606686189610471

Epoch: 6| Step: 1
Training loss: 0.10218435525894165
Validation loss: 1.5766358452458535

Epoch: 6| Step: 2
Training loss: 0.18183633685112
Validation loss: 1.5521070290637273

Epoch: 6| Step: 3
Training loss: 0.0851544439792633
Validation loss: 1.5513252904338222

Epoch: 6| Step: 4
Training loss: 0.11079169809818268
Validation loss: 1.5980191384592364

Epoch: 6| Step: 5
Training loss: 0.08229309320449829
Validation loss: 1.5677799652981501

Epoch: 6| Step: 6
Training loss: 0.07615676522254944
Validation loss: 1.5432015336969847

Epoch: 6| Step: 7
Training loss: 0.44165462255477905
Validation loss: 1.5539548089427333

Epoch: 6| Step: 8
Training loss: 0.2350509911775589
Validation loss: 1.531555809000487

Epoch: 6| Step: 9
Training loss: 0.09433447569608688
Validation loss: 1.5229939363336051

Epoch: 6| Step: 10
Training loss: 0.11013884097337723
Validation loss: 1.5203882584007837

Epoch: 6| Step: 11
Training loss: 0.17288482189178467
Validation loss: 1.529097258403737

Epoch: 6| Step: 12
Training loss: 0.1166105568408966
Validation loss: 1.5396875245596773

Epoch: 6| Step: 13
Training loss: 0.13657119870185852
Validation loss: 1.571511241697496

Epoch: 464| Step: 0
Training loss: 0.40595436096191406
Validation loss: 1.5389148894176687

Epoch: 6| Step: 1
Training loss: 0.0999637022614479
Validation loss: 1.5439846938656223

Epoch: 6| Step: 2
Training loss: 0.12889309227466583
Validation loss: 1.5598008555750693

Epoch: 6| Step: 3
Training loss: 0.13420534133911133
Validation loss: 1.593509740726922

Epoch: 6| Step: 4
Training loss: 0.16325309872627258
Validation loss: 1.572084080147487

Epoch: 6| Step: 5
Training loss: 0.12549248337745667
Validation loss: 1.5898634874692528

Epoch: 6| Step: 6
Training loss: 0.15846265852451324
Validation loss: 1.5724455438634402

Epoch: 6| Step: 7
Training loss: 0.21237409114837646
Validation loss: 1.5516840668134793

Epoch: 6| Step: 8
Training loss: 0.11500239372253418
Validation loss: 1.5232775204925126

Epoch: 6| Step: 9
Training loss: 0.14279600977897644
Validation loss: 1.525611440340678

Epoch: 6| Step: 10
Training loss: 0.11460283398628235
Validation loss: 1.5095439187942012

Epoch: 6| Step: 11
Training loss: 0.08214938640594482
Validation loss: 1.5069521204117806

Epoch: 6| Step: 12
Training loss: 0.12296480685472488
Validation loss: 1.5109550247910202

Epoch: 6| Step: 13
Training loss: 0.11993855983018875
Validation loss: 1.5203761644260858

Epoch: 465| Step: 0
Training loss: 0.18614298105239868
Validation loss: 1.5000624131130915

Epoch: 6| Step: 1
Training loss: 0.1190342903137207
Validation loss: 1.4938303552648073

Epoch: 6| Step: 2
Training loss: 0.09949392080307007
Validation loss: 1.5326676599441036

Epoch: 6| Step: 3
Training loss: 0.16877809166908264
Validation loss: 1.5182891879030453

Epoch: 6| Step: 4
Training loss: 0.21539035439491272
Validation loss: 1.5189151007642028

Epoch: 6| Step: 5
Training loss: 0.11716316640377045
Validation loss: 1.5189435674298195

Epoch: 6| Step: 6
Training loss: 0.11358009278774261
Validation loss: 1.5545998516903128

Epoch: 6| Step: 7
Training loss: 0.13974207639694214
Validation loss: 1.5375294390545096

Epoch: 6| Step: 8
Training loss: 0.06344732642173767
Validation loss: 1.5508835341340752

Epoch: 6| Step: 9
Training loss: 0.12530820071697235
Validation loss: 1.5470424518790296

Epoch: 6| Step: 10
Training loss: 0.07699327170848846
Validation loss: 1.5758017673287341

Epoch: 6| Step: 11
Training loss: 0.4244503974914551
Validation loss: 1.5759302544337448

Epoch: 6| Step: 12
Training loss: 0.1496591866016388
Validation loss: 1.5603336082991732

Epoch: 6| Step: 13
Training loss: 0.11320194602012634
Validation loss: 1.5647836051961428

Epoch: 466| Step: 0
Training loss: 0.061448801308870316
Validation loss: 1.5864709090161067

Epoch: 6| Step: 1
Training loss: 0.13205642998218536
Validation loss: 1.5632896192612187

Epoch: 6| Step: 2
Training loss: 0.11293739825487137
Validation loss: 1.5673727655923495

Epoch: 6| Step: 3
Training loss: 0.17638356983661652
Validation loss: 1.5825582294053928

Epoch: 6| Step: 4
Training loss: 0.5218497514724731
Validation loss: 1.5583630479792112

Epoch: 6| Step: 5
Training loss: 0.23914159834384918
Validation loss: 1.5609612554632208

Epoch: 6| Step: 6
Training loss: 0.15807566046714783
Validation loss: 1.5356750469053946

Epoch: 6| Step: 7
Training loss: 0.1389084756374359
Validation loss: 1.5597564969011533

Epoch: 6| Step: 8
Training loss: 0.10550279915332794
Validation loss: 1.5399720732883742

Epoch: 6| Step: 9
Training loss: 0.11452556401491165
Validation loss: 1.5396944066529632

Epoch: 6| Step: 10
Training loss: 0.2067236602306366
Validation loss: 1.5507333022291943

Epoch: 6| Step: 11
Training loss: 0.12262840569019318
Validation loss: 1.5551798343658447

Epoch: 6| Step: 12
Training loss: 0.1141979843378067
Validation loss: 1.536063091729277

Epoch: 6| Step: 13
Training loss: 0.0522548109292984
Validation loss: 1.5663797291376258

Epoch: 467| Step: 0
Training loss: 0.300926148891449
Validation loss: 1.5579638391412713

Epoch: 6| Step: 1
Training loss: 0.4707072377204895
Validation loss: 1.58478029248535

Epoch: 6| Step: 2
Training loss: 0.15532413125038147
Validation loss: 1.5581401881351267

Epoch: 6| Step: 3
Training loss: 0.10805128514766693
Validation loss: 1.5530271812151837

Epoch: 6| Step: 4
Training loss: 0.08793230354785919
Validation loss: 1.5644132796154226

Epoch: 6| Step: 5
Training loss: 0.05819658190011978
Validation loss: 1.5517425223063397

Epoch: 6| Step: 6
Training loss: 0.12257637083530426
Validation loss: 1.573998357660027

Epoch: 6| Step: 7
Training loss: 0.13599258661270142
Validation loss: 1.5660850283920125

Epoch: 6| Step: 8
Training loss: 0.12755368649959564
Validation loss: 1.5636079862553587

Epoch: 6| Step: 9
Training loss: 0.09559741616249084
Validation loss: 1.554919522295716

Epoch: 6| Step: 10
Training loss: 0.10859014093875885
Validation loss: 1.5571350769330097

Epoch: 6| Step: 11
Training loss: 0.1249050498008728
Validation loss: 1.5686189756598523

Epoch: 6| Step: 12
Training loss: 0.0717504546046257
Validation loss: 1.5566155410582019

Epoch: 6| Step: 13
Training loss: 0.13826076686382294
Validation loss: 1.6003540613318001

Epoch: 468| Step: 0
Training loss: 0.13097231090068817
Validation loss: 1.6030489526769167

Epoch: 6| Step: 1
Training loss: 0.08993202447891235
Validation loss: 1.581113193624763

Epoch: 6| Step: 2
Training loss: 0.5090394020080566
Validation loss: 1.5680635488161476

Epoch: 6| Step: 3
Training loss: 0.09213551878929138
Validation loss: 1.5484660543421263

Epoch: 6| Step: 4
Training loss: 0.09879270941019058
Validation loss: 1.532326126611361

Epoch: 6| Step: 5
Training loss: 0.07723762094974518
Validation loss: 1.5146113191881487

Epoch: 6| Step: 6
Training loss: 0.13987764716148376
Validation loss: 1.511938775739362

Epoch: 6| Step: 7
Training loss: 0.13452009856700897
Validation loss: 1.4927382302540604

Epoch: 6| Step: 8
Training loss: 0.20640814304351807
Validation loss: 1.5261238544218

Epoch: 6| Step: 9
Training loss: 0.09486541152000427
Validation loss: 1.5333556308541247

Epoch: 6| Step: 10
Training loss: 0.09422782063484192
Validation loss: 1.540540070943935

Epoch: 6| Step: 11
Training loss: 0.09946325421333313
Validation loss: 1.5491270852345291

Epoch: 6| Step: 12
Training loss: 0.1461314558982849
Validation loss: 1.5368272848026727

Epoch: 6| Step: 13
Training loss: 0.2901216745376587
Validation loss: 1.543629664246754

Epoch: 469| Step: 0
Training loss: 0.4324244558811188
Validation loss: 1.548618689660103

Epoch: 6| Step: 1
Training loss: 0.1840720772743225
Validation loss: 1.5266303631567186

Epoch: 6| Step: 2
Training loss: 0.10572746396064758
Validation loss: 1.5406361497858518

Epoch: 6| Step: 3
Training loss: 0.08655760437250137
Validation loss: 1.54417843972483

Epoch: 6| Step: 4
Training loss: 0.11108535528182983
Validation loss: 1.5363408788557975

Epoch: 6| Step: 5
Training loss: 0.1363743543624878
Validation loss: 1.5234646720270957

Epoch: 6| Step: 6
Training loss: 0.09916067123413086
Validation loss: 1.5467995238560501

Epoch: 6| Step: 7
Training loss: 0.08323754370212555
Validation loss: 1.5842037598292034

Epoch: 6| Step: 8
Training loss: 0.16978126764297485
Validation loss: 1.5758282676819833

Epoch: 6| Step: 9
Training loss: 0.10031956434249878
Validation loss: 1.6080241363535646

Epoch: 6| Step: 10
Training loss: 0.20667384564876556
Validation loss: 1.6108796006889754

Epoch: 6| Step: 11
Training loss: 0.11777400225400925
Validation loss: 1.6159425204800022

Epoch: 6| Step: 12
Training loss: 0.10685308277606964
Validation loss: 1.5652483701705933

Epoch: 6| Step: 13
Training loss: 0.15507067739963531
Validation loss: 1.5581624879631946

Epoch: 470| Step: 0
Training loss: 0.07598108053207397
Validation loss: 1.5326381793586157

Epoch: 6| Step: 1
Training loss: 0.14469189941883087
Validation loss: 1.5485964782776371

Epoch: 6| Step: 2
Training loss: 0.0777847170829773
Validation loss: 1.5300173016004666

Epoch: 6| Step: 3
Training loss: 0.43962013721466064
Validation loss: 1.4910990115134948

Epoch: 6| Step: 4
Training loss: 0.14693167805671692
Validation loss: 1.4917672353406106

Epoch: 6| Step: 5
Training loss: 0.09747163206338882
Validation loss: 1.4988110437188098

Epoch: 6| Step: 6
Training loss: 0.15053558349609375
Validation loss: 1.5201119761313162

Epoch: 6| Step: 7
Training loss: 0.21419188380241394
Validation loss: 1.4829449961262364

Epoch: 6| Step: 8
Training loss: 0.08711253106594086
Validation loss: 1.513356908675163

Epoch: 6| Step: 9
Training loss: 0.09091643989086151
Validation loss: 1.5131173685032835

Epoch: 6| Step: 10
Training loss: 0.17445552349090576
Validation loss: 1.562515547198634

Epoch: 6| Step: 11
Training loss: 0.10700959712266922
Validation loss: 1.556989577508742

Epoch: 6| Step: 12
Training loss: 0.1031857281923294
Validation loss: 1.5540088184418217

Epoch: 6| Step: 13
Training loss: 0.09099464863538742
Validation loss: 1.5369859792852913

Epoch: 471| Step: 0
Training loss: 0.16165438294410706
Validation loss: 1.578786002692356

Epoch: 6| Step: 1
Training loss: 0.06062786281108856
Validation loss: 1.5385489963716077

Epoch: 6| Step: 2
Training loss: 0.09366744011640549
Validation loss: 1.5031896944968932

Epoch: 6| Step: 3
Training loss: 0.13186389207839966
Validation loss: 1.5245841933834938

Epoch: 6| Step: 4
Training loss: 0.15825805068016052
Validation loss: 1.5415302117665608

Epoch: 6| Step: 5
Training loss: 0.09865114092826843
Validation loss: 1.535646915435791

Epoch: 6| Step: 6
Training loss: 0.09882491827011108
Validation loss: 1.54738623480643

Epoch: 6| Step: 7
Training loss: 0.12307217717170715
Validation loss: 1.5256294499161422

Epoch: 6| Step: 8
Training loss: 0.10908301919698715
Validation loss: 1.5244541514304377

Epoch: 6| Step: 9
Training loss: 0.06197177991271019
Validation loss: 1.562640954089421

Epoch: 6| Step: 10
Training loss: 0.21585118770599365
Validation loss: 1.5965126586216751

Epoch: 6| Step: 11
Training loss: 0.1014101505279541
Validation loss: 1.5679993501273535

Epoch: 6| Step: 12
Training loss: 0.08061769604682922
Validation loss: 1.5699324248939432

Epoch: 6| Step: 13
Training loss: 0.6147152781486511
Validation loss: 1.6044161447914698

Epoch: 472| Step: 0
Training loss: 0.12636449933052063
Validation loss: 1.6239212603979214

Epoch: 6| Step: 1
Training loss: 0.06661258637905121
Validation loss: 1.5767278696901055

Epoch: 6| Step: 2
Training loss: 0.088355652987957
Validation loss: 1.5877122545755038

Epoch: 6| Step: 3
Training loss: 0.16671770811080933
Validation loss: 1.6035479986539452

Epoch: 6| Step: 4
Training loss: 0.07757233083248138
Validation loss: 1.5907999097660024

Epoch: 6| Step: 5
Training loss: 0.1233370378613472
Validation loss: 1.650827653946415

Epoch: 6| Step: 6
Training loss: 0.15110009908676147
Validation loss: 1.591174348708122

Epoch: 6| Step: 7
Training loss: 0.4598892629146576
Validation loss: 1.5826157049466205

Epoch: 6| Step: 8
Training loss: 0.061718203127384186
Validation loss: 1.5725030360683319

Epoch: 6| Step: 9
Training loss: 0.13345342874526978
Validation loss: 1.55170851625422

Epoch: 6| Step: 10
Training loss: 0.1306493729352951
Validation loss: 1.514448244084594

Epoch: 6| Step: 11
Training loss: 0.08627969026565552
Validation loss: 1.5314756913851666

Epoch: 6| Step: 12
Training loss: 0.17048639059066772
Validation loss: 1.5238989219870618

Epoch: 6| Step: 13
Training loss: 0.19078081846237183
Validation loss: 1.5178083386472476

Epoch: 473| Step: 0
Training loss: 0.13996779918670654
Validation loss: 1.534933486292439

Epoch: 6| Step: 1
Training loss: 0.1171233206987381
Validation loss: 1.5591550334807365

Epoch: 6| Step: 2
Training loss: 0.08509266376495361
Validation loss: 1.5400859117507935

Epoch: 6| Step: 3
Training loss: 0.10279718041419983
Validation loss: 1.5858213850246963

Epoch: 6| Step: 4
Training loss: 0.17369338870048523
Validation loss: 1.5930212082401398

Epoch: 6| Step: 5
Training loss: 0.18989048898220062
Validation loss: 1.5852764985894645

Epoch: 6| Step: 6
Training loss: 0.40172886848449707
Validation loss: 1.5809302522290138

Epoch: 6| Step: 7
Training loss: 0.22461320459842682
Validation loss: 1.606802886532199

Epoch: 6| Step: 8
Training loss: 0.13919231295585632
Validation loss: 1.5579121215369112

Epoch: 6| Step: 9
Training loss: 0.12411685287952423
Validation loss: 1.5692300822145195

Epoch: 6| Step: 10
Training loss: 0.09941940009593964
Validation loss: 1.5337621460678756

Epoch: 6| Step: 11
Training loss: 0.09927782416343689
Validation loss: 1.519640916137285

Epoch: 6| Step: 12
Training loss: 0.08366059511899948
Validation loss: 1.490629216035207

Epoch: 6| Step: 13
Training loss: 0.06141144782304764
Validation loss: 1.5079781650215067

Epoch: 474| Step: 0
Training loss: 0.12740880250930786
Validation loss: 1.510762212097004

Epoch: 6| Step: 1
Training loss: 0.10267762839794159
Validation loss: 1.4864703968007078

Epoch: 6| Step: 2
Training loss: 0.18965287506580353
Validation loss: 1.5067227002113097

Epoch: 6| Step: 3
Training loss: 0.23874232172966003
Validation loss: 1.5055620913864465

Epoch: 6| Step: 4
Training loss: 0.15095394849777222
Validation loss: 1.4737764103438264

Epoch: 6| Step: 5
Training loss: 0.18525537848472595
Validation loss: 1.518851202021363

Epoch: 6| Step: 6
Training loss: 0.10150207579135895
Validation loss: 1.5298301917250439

Epoch: 6| Step: 7
Training loss: 0.3865430951118469
Validation loss: 1.5557178733169392

Epoch: 6| Step: 8
Training loss: 0.12462348490953445
Validation loss: 1.558826631115329

Epoch: 6| Step: 9
Training loss: 0.0738457664847374
Validation loss: 1.5960527184189006

Epoch: 6| Step: 10
Training loss: 0.14985856413841248
Validation loss: 1.6164160556690668

Epoch: 6| Step: 11
Training loss: 0.10517334192991257
Validation loss: 1.601426088681785

Epoch: 6| Step: 12
Training loss: 0.07581788301467896
Validation loss: 1.6730478489270775

Epoch: 6| Step: 13
Training loss: 0.20933455228805542
Validation loss: 1.6432160959448865

Epoch: 475| Step: 0
Training loss: 0.1603080928325653
Validation loss: 1.64703417593433

Epoch: 6| Step: 1
Training loss: 0.1177256628870964
Validation loss: 1.6501123648817821

Epoch: 6| Step: 2
Training loss: 0.3982681930065155
Validation loss: 1.6340669790903728

Epoch: 6| Step: 3
Training loss: 0.09289324283599854
Validation loss: 1.6121332831280206

Epoch: 6| Step: 4
Training loss: 0.08071783930063248
Validation loss: 1.5812043002856675

Epoch: 6| Step: 5
Training loss: 0.13773715496063232
Validation loss: 1.5753905542435185

Epoch: 6| Step: 6
Training loss: 0.1395174115896225
Validation loss: 1.5579801246684084

Epoch: 6| Step: 7
Training loss: 0.14212654531002045
Validation loss: 1.5586286148717325

Epoch: 6| Step: 8
Training loss: 0.0986420288681984
Validation loss: 1.5142408583753852

Epoch: 6| Step: 9
Training loss: 0.09880594164133072
Validation loss: 1.5414714556868359

Epoch: 6| Step: 10
Training loss: 0.1093033105134964
Validation loss: 1.528131099157436

Epoch: 6| Step: 11
Training loss: 0.16272318363189697
Validation loss: 1.5252212452632126

Epoch: 6| Step: 12
Training loss: 0.08274796605110168
Validation loss: 1.5159875051949614

Epoch: 6| Step: 13
Training loss: 0.09545185416936874
Validation loss: 1.5542881552891066

Epoch: 476| Step: 0
Training loss: 0.16193726658821106
Validation loss: 1.5460196195110198

Epoch: 6| Step: 1
Training loss: 0.05461112782359123
Validation loss: 1.5535177992236229

Epoch: 6| Step: 2
Training loss: 0.07705899327993393
Validation loss: 1.5541016811965613

Epoch: 6| Step: 3
Training loss: 0.18000566959381104
Validation loss: 1.6110573032850861

Epoch: 6| Step: 4
Training loss: 0.08369261026382446
Validation loss: 1.5839013925162695

Epoch: 6| Step: 5
Training loss: 0.12287157028913498
Validation loss: 1.578209803950402

Epoch: 6| Step: 6
Training loss: 0.133485347032547
Validation loss: 1.5858440219715078

Epoch: 6| Step: 7
Training loss: 0.11908096075057983
Validation loss: 1.5563234654805993

Epoch: 6| Step: 8
Training loss: 0.09061795473098755
Validation loss: 1.5882741123117425

Epoch: 6| Step: 9
Training loss: 0.09007035195827484
Validation loss: 1.5249737193507533

Epoch: 6| Step: 10
Training loss: 0.48142755031585693
Validation loss: 1.5322453014312252

Epoch: 6| Step: 11
Training loss: 0.06186949089169502
Validation loss: 1.5223201423562982

Epoch: 6| Step: 12
Training loss: 0.18090492486953735
Validation loss: 1.526374222129904

Epoch: 6| Step: 13
Training loss: 0.04850003495812416
Validation loss: 1.5178246280198455

Epoch: 477| Step: 0
Training loss: 0.10147675126791
Validation loss: 1.5385017612928986

Epoch: 6| Step: 1
Training loss: 0.11483830213546753
Validation loss: 1.5397734308755526

Epoch: 6| Step: 2
Training loss: 0.0699283629655838
Validation loss: 1.5460317032311552

Epoch: 6| Step: 3
Training loss: 0.14556151628494263
Validation loss: 1.5051340864550682

Epoch: 6| Step: 4
Training loss: 0.4060409367084503
Validation loss: 1.542128683418356

Epoch: 6| Step: 5
Training loss: 0.10306022316217422
Validation loss: 1.5274867575655702

Epoch: 6| Step: 6
Training loss: 0.08507344871759415
Validation loss: 1.5607530404162664

Epoch: 6| Step: 7
Training loss: 0.19903837144374847
Validation loss: 1.5959372302537322

Epoch: 6| Step: 8
Training loss: 0.09402889013290405
Validation loss: 1.5903004215609642

Epoch: 6| Step: 9
Training loss: 0.15257230401039124
Validation loss: 1.6004321902028975

Epoch: 6| Step: 10
Training loss: 0.10342201590538025
Validation loss: 1.5916549877453876

Epoch: 6| Step: 11
Training loss: 0.10816940665245056
Validation loss: 1.6164659389885523

Epoch: 6| Step: 12
Training loss: 0.1116696149110794
Validation loss: 1.5604500450113767

Epoch: 6| Step: 13
Training loss: 0.11164689064025879
Validation loss: 1.547377376146214

Epoch: 478| Step: 0
Training loss: 0.08135649561882019
Validation loss: 1.5499210780666721

Epoch: 6| Step: 1
Training loss: 0.21567560732364655
Validation loss: 1.5251645311232536

Epoch: 6| Step: 2
Training loss: 0.09028671681880951
Validation loss: 1.5077322234389603

Epoch: 6| Step: 3
Training loss: 0.09745655208826065
Validation loss: 1.4908493962339175

Epoch: 6| Step: 4
Training loss: 0.23041170835494995
Validation loss: 1.5121670730652348

Epoch: 6| Step: 5
Training loss: 0.1744842380285263
Validation loss: 1.4950871006135018

Epoch: 6| Step: 6
Training loss: 0.23632079362869263
Validation loss: 1.4805534808866438

Epoch: 6| Step: 7
Training loss: 0.39799800515174866
Validation loss: 1.5008902562561857

Epoch: 6| Step: 8
Training loss: 0.0999961569905281
Validation loss: 1.5057026660570534

Epoch: 6| Step: 9
Training loss: 0.10734643787145615
Validation loss: 1.5139886820188133

Epoch: 6| Step: 10
Training loss: 0.10832884162664413
Validation loss: 1.5017002936332458

Epoch: 6| Step: 11
Training loss: 0.07299468666315079
Validation loss: 1.5261745811790548

Epoch: 6| Step: 12
Training loss: 0.1100333034992218
Validation loss: 1.5786515435864847

Epoch: 6| Step: 13
Training loss: 0.11024565994739532
Validation loss: 1.5700509868642336

Epoch: 479| Step: 0
Training loss: 0.106635183095932
Validation loss: 1.6053263295081355

Epoch: 6| Step: 1
Training loss: 0.0848034918308258
Validation loss: 1.5464031081045828

Epoch: 6| Step: 2
Training loss: 0.1307954490184784
Validation loss: 1.569286577163204

Epoch: 6| Step: 3
Training loss: 0.40022891759872437
Validation loss: 1.5681649113214144

Epoch: 6| Step: 4
Training loss: 0.12176106125116348
Validation loss: 1.585935220923475

Epoch: 6| Step: 5
Training loss: 0.22791141271591187
Validation loss: 1.5639768056972052

Epoch: 6| Step: 6
Training loss: 0.12181660532951355
Validation loss: 1.5344497343545318

Epoch: 6| Step: 7
Training loss: 0.14591380953788757
Validation loss: 1.5230298811389553

Epoch: 6| Step: 8
Training loss: 0.15430845320224762
Validation loss: 1.509669037275417

Epoch: 6| Step: 9
Training loss: 0.07255351543426514
Validation loss: 1.495714573449986

Epoch: 6| Step: 10
Training loss: 0.08538701385259628
Validation loss: 1.4872100378877373

Epoch: 6| Step: 11
Training loss: 0.13008753955364227
Validation loss: 1.470489340443765

Epoch: 6| Step: 12
Training loss: 0.13766692578792572
Validation loss: 1.4720636913853307

Epoch: 6| Step: 13
Training loss: 0.10341308265924454
Validation loss: 1.4968314093928183

Epoch: 480| Step: 0
Training loss: 0.13374130427837372
Validation loss: 1.4895217572489092

Epoch: 6| Step: 1
Training loss: 0.5071063041687012
Validation loss: 1.4901453820607995

Epoch: 6| Step: 2
Training loss: 0.11981140822172165
Validation loss: 1.53555138521297

Epoch: 6| Step: 3
Training loss: 0.12543514370918274
Validation loss: 1.5306477892783381

Epoch: 6| Step: 4
Training loss: 0.0914875715970993
Validation loss: 1.5534293395216747

Epoch: 6| Step: 5
Training loss: 0.22993463277816772
Validation loss: 1.5968344519215245

Epoch: 6| Step: 6
Training loss: 0.0946895182132721
Validation loss: 1.621146701356416

Epoch: 6| Step: 7
Training loss: 0.15210367739200592
Validation loss: 1.5973680557743195

Epoch: 6| Step: 8
Training loss: 0.1822589933872223
Validation loss: 1.6105993998947965

Epoch: 6| Step: 9
Training loss: 0.1286202073097229
Validation loss: 1.5972724050603888

Epoch: 6| Step: 10
Training loss: 0.17370900511741638
Validation loss: 1.5574125628317557

Epoch: 6| Step: 11
Training loss: 0.08808562904596329
Validation loss: 1.543543045238782

Epoch: 6| Step: 12
Training loss: 0.07657084614038467
Validation loss: 1.5448278842433807

Epoch: 6| Step: 13
Training loss: 0.08364458382129669
Validation loss: 1.533886678757206

Epoch: 481| Step: 0
Training loss: 0.11661357432603836
Validation loss: 1.5270375461988552

Epoch: 6| Step: 1
Training loss: 0.12409435212612152
Validation loss: 1.4905453561454691

Epoch: 6| Step: 2
Training loss: 0.44262516498565674
Validation loss: 1.5111631654923963

Epoch: 6| Step: 3
Training loss: 0.17830026149749756
Validation loss: 1.4895495676225232

Epoch: 6| Step: 4
Training loss: 0.18896779417991638
Validation loss: 1.499872975451972

Epoch: 6| Step: 5
Training loss: 0.10259437561035156
Validation loss: 1.4789152030021913

Epoch: 6| Step: 6
Training loss: 0.09548895806074142
Validation loss: 1.4870336260846866

Epoch: 6| Step: 7
Training loss: 0.06994657218456268
Validation loss: 1.5179460638312883

Epoch: 6| Step: 8
Training loss: 0.07292333245277405
Validation loss: 1.497124965472888

Epoch: 6| Step: 9
Training loss: 0.1521608978509903
Validation loss: 1.4929120412436865

Epoch: 6| Step: 10
Training loss: 0.15012973546981812
Validation loss: 1.5336567381376862

Epoch: 6| Step: 11
Training loss: 0.20508648455142975
Validation loss: 1.5405302752730667

Epoch: 6| Step: 12
Training loss: 0.06769156455993652
Validation loss: 1.5626706692480272

Epoch: 6| Step: 13
Training loss: 0.11062705516815186
Validation loss: 1.5511834698338662

Epoch: 482| Step: 0
Training loss: 0.5157598257064819
Validation loss: 1.585231852787797

Epoch: 6| Step: 1
Training loss: 0.13017253577709198
Validation loss: 1.5827464672826952

Epoch: 6| Step: 2
Training loss: 0.09229331463575363
Validation loss: 1.5871097221169421

Epoch: 6| Step: 3
Training loss: 0.09955216199159622
Validation loss: 1.61061720437901

Epoch: 6| Step: 4
Training loss: 0.09863173961639404
Validation loss: 1.5851891027983798

Epoch: 6| Step: 5
Training loss: 0.10271503776311874
Validation loss: 1.571120104482097

Epoch: 6| Step: 6
Training loss: 0.1283702850341797
Validation loss: 1.5637077400761266

Epoch: 6| Step: 7
Training loss: 0.11726254224777222
Validation loss: 1.5784146375553583

Epoch: 6| Step: 8
Training loss: 0.13979092240333557
Validation loss: 1.523310956134591

Epoch: 6| Step: 9
Training loss: 0.09422287344932556
Validation loss: 1.5132545899319392

Epoch: 6| Step: 10
Training loss: 0.12514573335647583
Validation loss: 1.5059689411553003

Epoch: 6| Step: 11
Training loss: 0.08416919410228729
Validation loss: 1.5027951950668006

Epoch: 6| Step: 12
Training loss: 0.10423541069030762
Validation loss: 1.535261486166267

Epoch: 6| Step: 13
Training loss: 0.11946097761392593
Validation loss: 1.5154709303250877

Epoch: 483| Step: 0
Training loss: 0.09738657623529434
Validation loss: 1.5751768132691741

Epoch: 6| Step: 1
Training loss: 0.11657006293535233
Validation loss: 1.51977228477437

Epoch: 6| Step: 2
Training loss: 0.12906956672668457
Validation loss: 1.5937580126588062

Epoch: 6| Step: 3
Training loss: 0.15314072370529175
Validation loss: 1.582283204601657

Epoch: 6| Step: 4
Training loss: 0.14392051100730896
Validation loss: 1.6029466364973335

Epoch: 6| Step: 5
Training loss: 0.08166094124317169
Validation loss: 1.5890235862424296

Epoch: 6| Step: 6
Training loss: 0.09710501879453659
Validation loss: 1.5720396593052854

Epoch: 6| Step: 7
Training loss: 0.12965604662895203
Validation loss: 1.5728092347421954

Epoch: 6| Step: 8
Training loss: 0.13630132377147675
Validation loss: 1.548469977994119

Epoch: 6| Step: 9
Training loss: 0.40318652987480164
Validation loss: 1.5228283969304894

Epoch: 6| Step: 10
Training loss: 0.06661190837621689
Validation loss: 1.5331617042582522

Epoch: 6| Step: 11
Training loss: 0.08938081562519073
Validation loss: 1.522915462011932

Epoch: 6| Step: 12
Training loss: 0.07346825301647186
Validation loss: 1.5203753568792855

Epoch: 6| Step: 13
Training loss: 0.10814184695482254
Validation loss: 1.5134419228440972

Epoch: 484| Step: 0
Training loss: 0.19853489100933075
Validation loss: 1.537951188702737

Epoch: 6| Step: 1
Training loss: 0.10920795053243637
Validation loss: 1.5432851314544678

Epoch: 6| Step: 2
Training loss: 0.11220341920852661
Validation loss: 1.5597963307493476

Epoch: 6| Step: 3
Training loss: 0.1649707704782486
Validation loss: 1.577329763802149

Epoch: 6| Step: 4
Training loss: 0.06775122135877609
Validation loss: 1.5739539618133216

Epoch: 6| Step: 5
Training loss: 0.05404093861579895
Validation loss: 1.5914844479612125

Epoch: 6| Step: 6
Training loss: 0.4354901909828186
Validation loss: 1.5893224029130832

Epoch: 6| Step: 7
Training loss: 0.10694040358066559
Validation loss: 1.569638018967003

Epoch: 6| Step: 8
Training loss: 0.10835538059473038
Validation loss: 1.574908749390674

Epoch: 6| Step: 9
Training loss: 0.1439642459154129
Validation loss: 1.5281019127497109

Epoch: 6| Step: 10
Training loss: 0.0954226478934288
Validation loss: 1.5588497679720643

Epoch: 6| Step: 11
Training loss: 0.09253603219985962
Validation loss: 1.5140470074069114

Epoch: 6| Step: 12
Training loss: 0.11891178041696548
Validation loss: 1.5410435917556926

Epoch: 6| Step: 13
Training loss: 0.05537226423621178
Validation loss: 1.5326031113183627

Epoch: 485| Step: 0
Training loss: 0.08019708096981049
Validation loss: 1.5568800677535355

Epoch: 6| Step: 1
Training loss: 0.07425461709499359
Validation loss: 1.54506629384974

Epoch: 6| Step: 2
Training loss: 0.07749733328819275
Validation loss: 1.5435070594151814

Epoch: 6| Step: 3
Training loss: 0.20579282939434052
Validation loss: 1.5157509209007345

Epoch: 6| Step: 4
Training loss: 0.10572810471057892
Validation loss: 1.5359135289346018

Epoch: 6| Step: 5
Training loss: 0.06820033490657806
Validation loss: 1.5218577218312088

Epoch: 6| Step: 6
Training loss: 0.11704069375991821
Validation loss: 1.5392120281855266

Epoch: 6| Step: 7
Training loss: 0.19729061424732208
Validation loss: 1.5472042727214035

Epoch: 6| Step: 8
Training loss: 0.47705280780792236
Validation loss: 1.5396152016937092

Epoch: 6| Step: 9
Training loss: 0.16062167286872864
Validation loss: 1.5585080654390397

Epoch: 6| Step: 10
Training loss: 0.1739957481622696
Validation loss: 1.5401168613023655

Epoch: 6| Step: 11
Training loss: 0.07678419351577759
Validation loss: 1.562124618919947

Epoch: 6| Step: 12
Training loss: 0.0924498438835144
Validation loss: 1.586015376993405

Epoch: 6| Step: 13
Training loss: 0.1157323494553566
Validation loss: 1.581851552891475

Epoch: 486| Step: 0
Training loss: 0.0886063277721405
Validation loss: 1.6009365153569046

Epoch: 6| Step: 1
Training loss: 0.15224705636501312
Validation loss: 1.5924983114324591

Epoch: 6| Step: 2
Training loss: 0.13060422241687775
Validation loss: 1.5784097897109164

Epoch: 6| Step: 3
Training loss: 0.08272488415241241
Validation loss: 1.5886861265346568

Epoch: 6| Step: 4
Training loss: 0.07779883593320847
Validation loss: 1.5938890467407882

Epoch: 6| Step: 5
Training loss: 0.4430006146430969
Validation loss: 1.5441260312193184

Epoch: 6| Step: 6
Training loss: 0.09871400892734528
Validation loss: 1.574081870817369

Epoch: 6| Step: 7
Training loss: 0.1701328158378601
Validation loss: 1.5677168587202668

Epoch: 6| Step: 8
Training loss: 0.20461112260818481
Validation loss: 1.5266427442591677

Epoch: 6| Step: 9
Training loss: 0.07621272653341293
Validation loss: 1.5530831454902567

Epoch: 6| Step: 10
Training loss: 0.1086326315999031
Validation loss: 1.5352310544701033

Epoch: 6| Step: 11
Training loss: 0.08319360017776489
Validation loss: 1.4971068174608293

Epoch: 6| Step: 12
Training loss: 0.12076660990715027
Validation loss: 1.523459437072918

Epoch: 6| Step: 13
Training loss: 0.07116863131523132
Validation loss: 1.5238829530695432

Epoch: 487| Step: 0
Training loss: 0.07162576168775558
Validation loss: 1.526994538563554

Epoch: 6| Step: 1
Training loss: 0.07767727971076965
Validation loss: 1.5479724240559403

Epoch: 6| Step: 2
Training loss: 0.10614040493965149
Validation loss: 1.5350324710210164

Epoch: 6| Step: 3
Training loss: 0.15694355964660645
Validation loss: 1.5403692260865243

Epoch: 6| Step: 4
Training loss: 0.20126110315322876
Validation loss: 1.5462795188350063

Epoch: 6| Step: 5
Training loss: 0.1488875448703766
Validation loss: 1.539836347744029

Epoch: 6| Step: 6
Training loss: 0.15894336998462677
Validation loss: 1.5413366492076586

Epoch: 6| Step: 7
Training loss: 0.09546776115894318
Validation loss: 1.5516559590575516

Epoch: 6| Step: 8
Training loss: 0.08356988430023193
Validation loss: 1.5275861511948288

Epoch: 6| Step: 9
Training loss: 0.13968585431575775
Validation loss: 1.553011909607918

Epoch: 6| Step: 10
Training loss: 0.09259328991174698
Validation loss: 1.5388240045116794

Epoch: 6| Step: 11
Training loss: 0.10866203904151917
Validation loss: 1.5092369741009128

Epoch: 6| Step: 12
Training loss: 0.4187895357608795
Validation loss: 1.5367616504751227

Epoch: 6| Step: 13
Training loss: 0.08183249831199646
Validation loss: 1.5285431710622643

Epoch: 488| Step: 0
Training loss: 0.07551947236061096
Validation loss: 1.4854168917543145

Epoch: 6| Step: 1
Training loss: 0.15222521126270294
Validation loss: 1.5234396201308056

Epoch: 6| Step: 2
Training loss: 0.15754471719264984
Validation loss: 1.5080534347923853

Epoch: 6| Step: 3
Training loss: 0.11646163463592529
Validation loss: 1.503861032506471

Epoch: 6| Step: 4
Training loss: 0.37511199712753296
Validation loss: 1.5254839056281633

Epoch: 6| Step: 5
Training loss: 0.0834861695766449
Validation loss: 1.5149956146876018

Epoch: 6| Step: 6
Training loss: 0.1421675831079483
Validation loss: 1.5246254936341317

Epoch: 6| Step: 7
Training loss: 0.12140913307666779
Validation loss: 1.5163991528172647

Epoch: 6| Step: 8
Training loss: 0.11752419173717499
Validation loss: 1.5430976524147937

Epoch: 6| Step: 9
Training loss: 0.11396114528179169
Validation loss: 1.556716630535741

Epoch: 6| Step: 10
Training loss: 0.07477081567049026
Validation loss: 1.5495492002015472

Epoch: 6| Step: 11
Training loss: 0.09315872192382812
Validation loss: 1.5804613200567101

Epoch: 6| Step: 12
Training loss: 0.09902352839708328
Validation loss: 1.617322394924779

Epoch: 6| Step: 13
Training loss: 0.1371154487133026
Validation loss: 1.648506881088339

Epoch: 489| Step: 0
Training loss: 0.15845021605491638
Validation loss: 1.6308753310993154

Epoch: 6| Step: 1
Training loss: 0.14508157968521118
Validation loss: 1.5948173102512155

Epoch: 6| Step: 2
Training loss: 0.12155857682228088
Validation loss: 1.596441174066195

Epoch: 6| Step: 3
Training loss: 0.2743178904056549
Validation loss: 1.5386573473612468

Epoch: 6| Step: 4
Training loss: 0.08482000231742859
Validation loss: 1.5180603919490692

Epoch: 6| Step: 5
Training loss: 0.15976111590862274
Validation loss: 1.4949961182891682

Epoch: 6| Step: 6
Training loss: 0.1319100558757782
Validation loss: 1.495796593286658

Epoch: 6| Step: 7
Training loss: 0.1627945452928543
Validation loss: 1.501953439045978

Epoch: 6| Step: 8
Training loss: 0.22949223220348358
Validation loss: 1.5058611496802299

Epoch: 6| Step: 9
Training loss: 0.11420269310474396
Validation loss: 1.5277410694347915

Epoch: 6| Step: 10
Training loss: 0.1083042174577713
Validation loss: 1.5063370491868706

Epoch: 6| Step: 11
Training loss: 0.08991104364395142
Validation loss: 1.5477434589016823

Epoch: 6| Step: 12
Training loss: 0.10074691474437714
Validation loss: 1.5596841432714974

Epoch: 6| Step: 13
Training loss: 0.6319763660430908
Validation loss: 1.5770910580952961

Epoch: 490| Step: 0
Training loss: 0.25539109110832214
Validation loss: 1.6159974169987503

Epoch: 6| Step: 1
Training loss: 0.13419917225837708
Validation loss: 1.6608961820602417

Epoch: 6| Step: 2
Training loss: 0.1342563033103943
Validation loss: 1.6855217692672566

Epoch: 6| Step: 3
Training loss: 0.16541579365730286
Validation loss: 1.698870378155862

Epoch: 6| Step: 4
Training loss: 0.1735316663980484
Validation loss: 1.6467397571891866

Epoch: 6| Step: 5
Training loss: 0.1981494426727295
Validation loss: 1.609833966019333

Epoch: 6| Step: 6
Training loss: 0.06682408601045609
Validation loss: 1.565290101112858

Epoch: 6| Step: 7
Training loss: 0.10349087417125702
Validation loss: 1.5374780816416587

Epoch: 6| Step: 8
Training loss: 0.07558814436197281
Validation loss: 1.4955163732651742

Epoch: 6| Step: 9
Training loss: 0.10248088836669922
Validation loss: 1.5213100628186298

Epoch: 6| Step: 10
Training loss: 0.42739948630332947
Validation loss: 1.4990420046673025

Epoch: 6| Step: 11
Training loss: 0.20024371147155762
Validation loss: 1.4500528663717291

Epoch: 6| Step: 12
Training loss: 0.15042155981063843
Validation loss: 1.4719942513332571

Epoch: 6| Step: 13
Training loss: 0.11235279589891434
Validation loss: 1.4917197086477791

Epoch: 491| Step: 0
Training loss: 0.040908314287662506
Validation loss: 1.489041982158538

Epoch: 6| Step: 1
Training loss: 0.16640153527259827
Validation loss: 1.4957726591376848

Epoch: 6| Step: 2
Training loss: 0.177467480301857
Validation loss: 1.5374830993272925

Epoch: 6| Step: 3
Training loss: 0.12017291784286499
Validation loss: 1.5122334188030613

Epoch: 6| Step: 4
Training loss: 0.09336088597774506
Validation loss: 1.5286953564613097

Epoch: 6| Step: 5
Training loss: 0.05567736178636551
Validation loss: 1.5600021314877335

Epoch: 6| Step: 6
Training loss: 0.11797737330198288
Validation loss: 1.5504528194345453

Epoch: 6| Step: 7
Training loss: 0.08076892048120499
Validation loss: 1.585693242729351

Epoch: 6| Step: 8
Training loss: 0.08753518760204315
Validation loss: 1.59810959651906

Epoch: 6| Step: 9
Training loss: 0.0762115865945816
Validation loss: 1.5779770074352142

Epoch: 6| Step: 10
Training loss: 0.12804259359836578
Validation loss: 1.5882597149059337

Epoch: 6| Step: 11
Training loss: 0.08749948441982269
Validation loss: 1.5942192551910237

Epoch: 6| Step: 12
Training loss: 0.23038461804389954
Validation loss: 1.6001681730311403

Epoch: 6| Step: 13
Training loss: 0.5883293151855469
Validation loss: 1.5673707249344035

Epoch: 492| Step: 0
Training loss: 0.08720395714044571
Validation loss: 1.583897921346849

Epoch: 6| Step: 1
Training loss: 0.11187123507261276
Validation loss: 1.5563295374634445

Epoch: 6| Step: 2
Training loss: 0.08951590955257416
Validation loss: 1.5031417505715483

Epoch: 6| Step: 3
Training loss: 0.061255186796188354
Validation loss: 1.5334828310115363

Epoch: 6| Step: 4
Training loss: 0.3502156734466553
Validation loss: 1.5358233631298106

Epoch: 6| Step: 5
Training loss: 0.07500457763671875
Validation loss: 1.5355970333981257

Epoch: 6| Step: 6
Training loss: 0.1976357400417328
Validation loss: 1.5452233899024226

Epoch: 6| Step: 7
Training loss: 0.08229326456785202
Validation loss: 1.549912005342463

Epoch: 6| Step: 8
Training loss: 0.17560380697250366
Validation loss: 1.5630378120688981

Epoch: 6| Step: 9
Training loss: 0.1350700408220291
Validation loss: 1.5466354341917141

Epoch: 6| Step: 10
Training loss: 0.12041155993938446
Validation loss: 1.5566894585086453

Epoch: 6| Step: 11
Training loss: 0.12918099761009216
Validation loss: 1.5871544691824144

Epoch: 6| Step: 12
Training loss: 0.07505790889263153
Validation loss: 1.5993050170201126

Epoch: 6| Step: 13
Training loss: 0.09756595641374588
Validation loss: 1.5997050808322044

Epoch: 493| Step: 0
Training loss: 0.11909474432468414
Validation loss: 1.6090993035224177

Epoch: 6| Step: 1
Training loss: 0.11987349390983582
Validation loss: 1.626327803058009

Epoch: 6| Step: 2
Training loss: 0.152639240026474
Validation loss: 1.5806826340254916

Epoch: 6| Step: 3
Training loss: 0.14662569761276245
Validation loss: 1.5931366682052612

Epoch: 6| Step: 4
Training loss: 0.4809592366218567
Validation loss: 1.5775578201458018

Epoch: 6| Step: 5
Training loss: 0.12298101931810379
Validation loss: 1.5260187413102837

Epoch: 6| Step: 6
Training loss: 0.11274435371160507
Validation loss: 1.5265573506714196

Epoch: 6| Step: 7
Training loss: 0.0908513069152832
Validation loss: 1.5123709529958747

Epoch: 6| Step: 8
Training loss: 0.07789422571659088
Validation loss: 1.5067205364986131

Epoch: 6| Step: 9
Training loss: 0.10881619155406952
Validation loss: 1.5291768568818287

Epoch: 6| Step: 10
Training loss: 0.1318347156047821
Validation loss: 1.5191828550830964

Epoch: 6| Step: 11
Training loss: 0.15161491930484772
Validation loss: 1.5114184348813948

Epoch: 6| Step: 12
Training loss: 0.07859110832214355
Validation loss: 1.5366463199738534

Epoch: 6| Step: 13
Training loss: 0.11302018165588379
Validation loss: 1.5627394978718092

Epoch: 494| Step: 0
Training loss: 0.3739287257194519
Validation loss: 1.5617450808966031

Epoch: 6| Step: 1
Training loss: 0.08674658834934235
Validation loss: 1.5638854965086906

Epoch: 6| Step: 2
Training loss: 0.13006316125392914
Validation loss: 1.5566801191658102

Epoch: 6| Step: 3
Training loss: 0.09034692496061325
Validation loss: 1.5991262223130913

Epoch: 6| Step: 4
Training loss: 0.12177823483943939
Validation loss: 1.5814921266289168

Epoch: 6| Step: 5
Training loss: 0.09097933769226074
Validation loss: 1.5685726493917487

Epoch: 6| Step: 6
Training loss: 0.07550957798957825
Validation loss: 1.5583286657128284

Epoch: 6| Step: 7
Training loss: 0.1652277112007141
Validation loss: 1.5762687190886466

Epoch: 6| Step: 8
Training loss: 0.12420734018087387
Validation loss: 1.5464052577172556

Epoch: 6| Step: 9
Training loss: 0.0910465195775032
Validation loss: 1.5295965453629852

Epoch: 6| Step: 10
Training loss: 0.09493335336446762
Validation loss: 1.5667365238230715

Epoch: 6| Step: 11
Training loss: 0.10904955118894577
Validation loss: 1.52320606734163

Epoch: 6| Step: 12
Training loss: 0.16228485107421875
Validation loss: 1.536957792056504

Epoch: 6| Step: 13
Training loss: 0.07634762674570084
Validation loss: 1.5220921783037082

Epoch: 495| Step: 0
Training loss: 0.09073381125926971
Validation loss: 1.5233886562367922

Epoch: 6| Step: 1
Training loss: 0.09211554378271103
Validation loss: 1.5169201666308987

Epoch: 6| Step: 2
Training loss: 0.0755603238940239
Validation loss: 1.485626397594329

Epoch: 6| Step: 3
Training loss: 0.039765968918800354
Validation loss: 1.5138032590189288

Epoch: 6| Step: 4
Training loss: 0.12351784855127335
Validation loss: 1.5357183935821697

Epoch: 6| Step: 5
Training loss: 0.14351511001586914
Validation loss: 1.508808066768031

Epoch: 6| Step: 6
Training loss: 0.0836687684059143
Validation loss: 1.533646369493136

Epoch: 6| Step: 7
Training loss: 0.13631311058998108
Validation loss: 1.488770963043295

Epoch: 6| Step: 8
Training loss: 0.10344444960355759
Validation loss: 1.5367164240088513

Epoch: 6| Step: 9
Training loss: 0.21062695980072021
Validation loss: 1.5170152751348351

Epoch: 6| Step: 10
Training loss: 0.12066320329904556
Validation loss: 1.5717521393170921

Epoch: 6| Step: 11
Training loss: 0.411964476108551
Validation loss: 1.5371831437592864

Epoch: 6| Step: 12
Training loss: 0.17453709244728088
Validation loss: 1.5775139036998953

Epoch: 6| Step: 13
Training loss: 0.06592109799385071
Validation loss: 1.6007342377016622

Epoch: 496| Step: 0
Training loss: 0.09684626013040543
Validation loss: 1.5850930175473612

Epoch: 6| Step: 1
Training loss: 0.09822304546833038
Validation loss: 1.6201309773229784

Epoch: 6| Step: 2
Training loss: 0.09951216727495193
Validation loss: 1.6063676239341818

Epoch: 6| Step: 3
Training loss: 0.07737723737955093
Validation loss: 1.5945611512789162

Epoch: 6| Step: 4
Training loss: 0.10101552307605743
Validation loss: 1.5830036760658346

Epoch: 6| Step: 5
Training loss: 0.11321636289358139
Validation loss: 1.584767694114357

Epoch: 6| Step: 6
Training loss: 0.13889256119728088
Validation loss: 1.6141678223045923

Epoch: 6| Step: 7
Training loss: 0.09215107560157776
Validation loss: 1.5941470387161418

Epoch: 6| Step: 8
Training loss: 0.08991007506847382
Validation loss: 1.6071584532337804

Epoch: 6| Step: 9
Training loss: 0.16598287224769592
Validation loss: 1.6007976301254765

Epoch: 6| Step: 10
Training loss: 0.364978551864624
Validation loss: 1.6041402880863478

Epoch: 6| Step: 11
Training loss: 0.1343381553888321
Validation loss: 1.5742870646138345

Epoch: 6| Step: 12
Training loss: 0.0932486280798912
Validation loss: 1.592943460710587

Epoch: 6| Step: 13
Training loss: 0.20746444165706635
Validation loss: 1.5526597551120225

Epoch: 497| Step: 0
Training loss: 0.12238889932632446
Validation loss: 1.54547026336834

Epoch: 6| Step: 1
Training loss: 0.1276971995830536
Validation loss: 1.529859758192493

Epoch: 6| Step: 2
Training loss: 0.1196211576461792
Validation loss: 1.5256564412065732

Epoch: 6| Step: 3
Training loss: 0.13662172853946686
Validation loss: 1.5356777932054253

Epoch: 6| Step: 4
Training loss: 0.1464053988456726
Validation loss: 1.546760839800681

Epoch: 6| Step: 5
Training loss: 0.18426457047462463
Validation loss: 1.5054206309779998

Epoch: 6| Step: 6
Training loss: 0.0692245215177536
Validation loss: 1.5203422461786578

Epoch: 6| Step: 7
Training loss: 0.08880952000617981
Validation loss: 1.5591686630761752

Epoch: 6| Step: 8
Training loss: 0.12295983731746674
Validation loss: 1.5745710371642985

Epoch: 6| Step: 9
Training loss: 0.41048139333724976
Validation loss: 1.5851371897164213

Epoch: 6| Step: 10
Training loss: 0.11081333458423615
Validation loss: 1.601691298587348

Epoch: 6| Step: 11
Training loss: 0.1193951666355133
Validation loss: 1.5883091342064641

Epoch: 6| Step: 12
Training loss: 0.18198364973068237
Validation loss: 1.5785874128341675

Epoch: 6| Step: 13
Training loss: 0.08887561410665512
Validation loss: 1.5311379112223142

Epoch: 498| Step: 0
Training loss: 0.182715505361557
Validation loss: 1.53593357147709

Epoch: 6| Step: 1
Training loss: 0.07034897059202194
Validation loss: 1.522058880457314

Epoch: 6| Step: 2
Training loss: 0.14237698912620544
Validation loss: 1.5177251523540867

Epoch: 6| Step: 3
Training loss: 0.37443649768829346
Validation loss: 1.4806212795678007

Epoch: 6| Step: 4
Training loss: 0.18394017219543457
Validation loss: 1.5206079201031757

Epoch: 6| Step: 5
Training loss: 0.14042788743972778
Validation loss: 1.5181382048514582

Epoch: 6| Step: 6
Training loss: 0.03151800110936165
Validation loss: 1.5466325231777724

Epoch: 6| Step: 7
Training loss: 0.0999111533164978
Validation loss: 1.5321785352563346

Epoch: 6| Step: 8
Training loss: 0.11972035467624664
Validation loss: 1.560116853765262

Epoch: 6| Step: 9
Training loss: 0.08368919789791107
Validation loss: 1.548457286691153

Epoch: 6| Step: 10
Training loss: 0.10231992602348328
Validation loss: 1.5643226741462626

Epoch: 6| Step: 11
Training loss: 0.07570523023605347
Validation loss: 1.5736664238796438

Epoch: 6| Step: 12
Training loss: 0.11881974339485168
Validation loss: 1.5620267083567958

Epoch: 6| Step: 13
Training loss: 0.10729441046714783
Validation loss: 1.5759636048347718

Epoch: 499| Step: 0
Training loss: 0.07286960631608963
Validation loss: 1.572617575686465

Epoch: 6| Step: 1
Training loss: 0.10361093282699585
Validation loss: 1.5603048288693993

Epoch: 6| Step: 2
Training loss: 0.09190168231725693
Validation loss: 1.5392708381017048

Epoch: 6| Step: 3
Training loss: 0.13271848857402802
Validation loss: 1.545977319440534

Epoch: 6| Step: 4
Training loss: 0.055032409727573395
Validation loss: 1.5509609881267752

Epoch: 6| Step: 5
Training loss: 0.045597512274980545
Validation loss: 1.538081156951125

Epoch: 6| Step: 6
Training loss: 0.09820541739463806
Validation loss: 1.5473537586068595

Epoch: 6| Step: 7
Training loss: 0.08717904984951019
Validation loss: 1.5746154157064294

Epoch: 6| Step: 8
Training loss: 0.3548389673233032
Validation loss: 1.5534891825850292

Epoch: 6| Step: 9
Training loss: 0.07938756048679352
Validation loss: 1.5431079390228435

Epoch: 6| Step: 10
Training loss: 0.06759627163410187
Validation loss: 1.566267087895383

Epoch: 6| Step: 11
Training loss: 0.14520104229450226
Validation loss: 1.550518738326206

Epoch: 6| Step: 12
Training loss: 0.06596648693084717
Validation loss: 1.538952527507659

Epoch: 6| Step: 13
Training loss: 0.14306290447711945
Validation loss: 1.5391529465234408

Epoch: 500| Step: 0
Training loss: 0.38570067286491394
Validation loss: 1.5394454451017483

Epoch: 6| Step: 1
Training loss: 0.11371447890996933
Validation loss: 1.4949467964069818

Epoch: 6| Step: 2
Training loss: 0.10615810751914978
Validation loss: 1.4908635795757335

Epoch: 6| Step: 3
Training loss: 0.11442737281322479
Validation loss: 1.4946871752380042

Epoch: 6| Step: 4
Training loss: 0.1776839792728424
Validation loss: 1.5055595456912954

Epoch: 6| Step: 5
Training loss: 0.0846778005361557
Validation loss: 1.4951252052860875

Epoch: 6| Step: 6
Training loss: 0.14581160247325897
Validation loss: 1.5171729672339656

Epoch: 6| Step: 7
Training loss: 0.07620416581630707
Validation loss: 1.5167860971984042

Epoch: 6| Step: 8
Training loss: 0.0682130828499794
Validation loss: 1.5337956349054973

Epoch: 6| Step: 9
Training loss: 0.1690307855606079
Validation loss: 1.5846708102892804

Epoch: 6| Step: 10
Training loss: 0.10432132333517075
Validation loss: 1.5598766201285905

Epoch: 6| Step: 11
Training loss: 0.09712137281894684
Validation loss: 1.5778737452722364

Epoch: 6| Step: 12
Training loss: 0.07685297727584839
Validation loss: 1.5744115306485085

Epoch: 6| Step: 13
Training loss: 0.058246176689863205
Validation loss: 1.573022488624819

Epoch: 501| Step: 0
Training loss: 0.1177535355091095
Validation loss: 1.5470399997567619

Epoch: 6| Step: 1
Training loss: 0.07898720353841782
Validation loss: 1.5410288174947102

Epoch: 6| Step: 2
Training loss: 0.08763062208890915
Validation loss: 1.540767720950547

Epoch: 6| Step: 3
Training loss: 0.37342166900634766
Validation loss: 1.5352607234831779

Epoch: 6| Step: 4
Training loss: 0.204950213432312
Validation loss: 1.5526988249953075

Epoch: 6| Step: 5
Training loss: 0.10303294658660889
Validation loss: 1.5522168221012238

Epoch: 6| Step: 6
Training loss: 0.15635399520397186
Validation loss: 1.5537125333662956

Epoch: 6| Step: 7
Training loss: 0.11592704802751541
Validation loss: 1.5524720376537693

Epoch: 6| Step: 8
Training loss: 0.09267318248748779
Validation loss: 1.5718230662807342

Epoch: 6| Step: 9
Training loss: 0.07252329587936401
Validation loss: 1.5616991955746886

Epoch: 6| Step: 10
Training loss: 0.12043935805559158
Validation loss: 1.5622564105577366

Epoch: 6| Step: 11
Training loss: 0.09992533177137375
Validation loss: 1.5673296041386102

Epoch: 6| Step: 12
Training loss: 0.19196981191635132
Validation loss: 1.5521001841432305

Epoch: 6| Step: 13
Training loss: 0.06765188276767731
Validation loss: 1.5243510635950233

Epoch: 502| Step: 0
Training loss: 0.049420662224292755
Validation loss: 1.5402840875810193

Epoch: 6| Step: 1
Training loss: 0.08629928529262543
Validation loss: 1.531216771371903

Epoch: 6| Step: 2
Training loss: 0.0909036174416542
Validation loss: 1.5598480957810597

Epoch: 6| Step: 3
Training loss: 0.11885921657085419
Validation loss: 1.5340511773222236

Epoch: 6| Step: 4
Training loss: 0.11912986636161804
Validation loss: 1.5657330456600393

Epoch: 6| Step: 5
Training loss: 0.09855382889509201
Validation loss: 1.590965001813827

Epoch: 6| Step: 6
Training loss: 0.06988438963890076
Validation loss: 1.5687597900308587

Epoch: 6| Step: 7
Training loss: 0.19288209080696106
Validation loss: 1.6074446644834293

Epoch: 6| Step: 8
Training loss: 0.1291341483592987
Validation loss: 1.6045530688378118

Epoch: 6| Step: 9
Training loss: 0.0952446311712265
Validation loss: 1.584201338470623

Epoch: 6| Step: 10
Training loss: 0.17198002338409424
Validation loss: 1.5619427260532175

Epoch: 6| Step: 11
Training loss: 0.35878896713256836
Validation loss: 1.5379232732198571

Epoch: 6| Step: 12
Training loss: 0.10194564610719681
Validation loss: 1.5375587671033797

Epoch: 6| Step: 13
Training loss: 0.09572631120681763
Validation loss: 1.5446901654684415

Epoch: 503| Step: 0
Training loss: 0.08315570652484894
Validation loss: 1.4989044922654347

Epoch: 6| Step: 1
Training loss: 0.09819820523262024
Validation loss: 1.5312688780087296

Epoch: 6| Step: 2
Training loss: 0.11348527669906616
Validation loss: 1.5501226737935057

Epoch: 6| Step: 3
Training loss: 0.1456843912601471
Validation loss: 1.5716551542282104

Epoch: 6| Step: 4
Training loss: 0.0765773355960846
Validation loss: 1.590464699652887

Epoch: 6| Step: 5
Training loss: 0.0779479444026947
Validation loss: 1.580605374549025

Epoch: 6| Step: 6
Training loss: 0.10198799520730972
Validation loss: 1.5856600192285353

Epoch: 6| Step: 7
Training loss: 0.16457980871200562
Validation loss: 1.5711671434422976

Epoch: 6| Step: 8
Training loss: 0.3770177364349365
Validation loss: 1.5402176405793877

Epoch: 6| Step: 9
Training loss: 0.15141306817531586
Validation loss: 1.5553590225917038

Epoch: 6| Step: 10
Training loss: 0.08743403106927872
Validation loss: 1.5319380285919353

Epoch: 6| Step: 11
Training loss: 0.099141925573349
Validation loss: 1.5387064846613074

Epoch: 6| Step: 12
Training loss: 0.14509254693984985
Validation loss: 1.5283672501963954

Epoch: 6| Step: 13
Training loss: 0.11487507820129395
Validation loss: 1.51831558955613

Epoch: 504| Step: 0
Training loss: 0.21560928225517273
Validation loss: 1.520080263896655

Epoch: 6| Step: 1
Training loss: 0.09987898170948029
Validation loss: 1.5232967099835795

Epoch: 6| Step: 2
Training loss: 0.3974247872829437
Validation loss: 1.5367120683834117

Epoch: 6| Step: 3
Training loss: 0.09027404338121414
Validation loss: 1.5692150515894736

Epoch: 6| Step: 4
Training loss: 0.09133819490671158
Validation loss: 1.5923600696748303

Epoch: 6| Step: 5
Training loss: 0.09082869440317154
Validation loss: 1.6079185329457766

Epoch: 6| Step: 6
Training loss: 0.14000673592090607
Validation loss: 1.5811587123460666

Epoch: 6| Step: 7
Training loss: 0.12546688318252563
Validation loss: 1.5936988271692747

Epoch: 6| Step: 8
Training loss: 0.09731941670179367
Validation loss: 1.5745655029050765

Epoch: 6| Step: 9
Training loss: 0.10332108289003372
Validation loss: 1.6085119119254492

Epoch: 6| Step: 10
Training loss: 0.06889699399471283
Validation loss: 1.5811808570738761

Epoch: 6| Step: 11
Training loss: 0.08113975822925568
Validation loss: 1.6011285916451485

Epoch: 6| Step: 12
Training loss: 0.05933818221092224
Validation loss: 1.5928680666031376

Epoch: 6| Step: 13
Training loss: 0.0947156473994255
Validation loss: 1.5727336022161669

Epoch: 505| Step: 0
Training loss: 0.1040816605091095
Validation loss: 1.5634771931555964

Epoch: 6| Step: 1
Training loss: 0.09698070585727692
Validation loss: 1.533825602582706

Epoch: 6| Step: 2
Training loss: 0.11641106009483337
Validation loss: 1.5192612755683161

Epoch: 6| Step: 3
Training loss: 0.06675764918327332
Validation loss: 1.537032522181029

Epoch: 6| Step: 4
Training loss: 0.08438535034656525
Validation loss: 1.5389929304840744

Epoch: 6| Step: 5
Training loss: 0.23498478531837463
Validation loss: 1.5378741320743357

Epoch: 6| Step: 6
Training loss: 0.3689279854297638
Validation loss: 1.5286496211123723

Epoch: 6| Step: 7
Training loss: 0.11543191969394684
Validation loss: 1.530893410405805

Epoch: 6| Step: 8
Training loss: 0.1048387736082077
Validation loss: 1.5419662101294405

Epoch: 6| Step: 9
Training loss: 0.11875712126493454
Validation loss: 1.5619284068384478

Epoch: 6| Step: 10
Training loss: 0.0737713947892189
Validation loss: 1.5538720802594257

Epoch: 6| Step: 11
Training loss: 0.06666254252195358
Validation loss: 1.5335115540412165

Epoch: 6| Step: 12
Training loss: 0.08698756247758865
Validation loss: 1.5312783487381474

Epoch: 6| Step: 13
Training loss: 0.08576684445142746
Validation loss: 1.5380698788550593

Epoch: 506| Step: 0
Training loss: 0.07532256096601486
Validation loss: 1.5388903053857947

Epoch: 6| Step: 1
Training loss: 0.1115557849407196
Validation loss: 1.5557103105770644

Epoch: 6| Step: 2
Training loss: 0.10802044719457626
Validation loss: 1.5407121912125619

Epoch: 6| Step: 3
Training loss: 0.09286210685968399
Validation loss: 1.5663310584201608

Epoch: 6| Step: 4
Training loss: 0.3599809408187866
Validation loss: 1.5798118883563625

Epoch: 6| Step: 5
Training loss: 0.18577897548675537
Validation loss: 1.5831161686169204

Epoch: 6| Step: 6
Training loss: 0.13081200420856476
Validation loss: 1.5632105117203088

Epoch: 6| Step: 7
Training loss: 0.07580021023750305
Validation loss: 1.5562939528496034

Epoch: 6| Step: 8
Training loss: 0.08124081790447235
Validation loss: 1.5395700957185479

Epoch: 6| Step: 9
Training loss: 0.11664282530546188
Validation loss: 1.5640591793162848

Epoch: 6| Step: 10
Training loss: 0.08995090425014496
Validation loss: 1.5396728977080314

Epoch: 6| Step: 11
Training loss: 0.08359067142009735
Validation loss: 1.5359418584454445

Epoch: 6| Step: 12
Training loss: 0.06231401860713959
Validation loss: 1.533487061018585

Epoch: 6| Step: 13
Training loss: 0.0783778578042984
Validation loss: 1.5458218166905064

Epoch: 507| Step: 0
Training loss: 0.1770961582660675
Validation loss: 1.5510822239742483

Epoch: 6| Step: 1
Training loss: 0.09673997759819031
Validation loss: 1.5335455786797307

Epoch: 6| Step: 2
Training loss: 0.09536014497280121
Validation loss: 1.5635898805433703

Epoch: 6| Step: 3
Training loss: 0.17123454809188843
Validation loss: 1.5519083725508822

Epoch: 6| Step: 4
Training loss: 0.09978228062391281
Validation loss: 1.5445783612548665

Epoch: 6| Step: 5
Training loss: 0.3882407546043396
Validation loss: 1.5717415835267754

Epoch: 6| Step: 6
Training loss: 0.1273171752691269
Validation loss: 1.5479925576076712

Epoch: 6| Step: 7
Training loss: 0.058138810098171234
Validation loss: 1.577638642762297

Epoch: 6| Step: 8
Training loss: 0.08367649465799332
Validation loss: 1.5671140686158211

Epoch: 6| Step: 9
Training loss: 0.16182230412960052
Validation loss: 1.6012815429318337

Epoch: 6| Step: 10
Training loss: 0.07822020351886749
Validation loss: 1.5615269907059208

Epoch: 6| Step: 11
Training loss: 0.0983867347240448
Validation loss: 1.5817760511111187

Epoch: 6| Step: 12
Training loss: 0.08327232301235199
Validation loss: 1.592695991198222

Epoch: 6| Step: 13
Training loss: 0.13133028149604797
Validation loss: 1.6002074967148483

Epoch: 508| Step: 0
Training loss: 0.1601123809814453
Validation loss: 1.606374188136029

Epoch: 6| Step: 1
Training loss: 0.07909122109413147
Validation loss: 1.6282099446942728

Epoch: 6| Step: 2
Training loss: 0.2412625551223755
Validation loss: 1.5999802158724876

Epoch: 6| Step: 3
Training loss: 0.35031163692474365
Validation loss: 1.6250559386386667

Epoch: 6| Step: 4
Training loss: 0.07759413123130798
Validation loss: 1.6423919200897217

Epoch: 6| Step: 5
Training loss: 0.10774160176515579
Validation loss: 1.6178314942185597

Epoch: 6| Step: 6
Training loss: 0.05741053819656372
Validation loss: 1.5999130202877907

Epoch: 6| Step: 7
Training loss: 0.08975215256214142
Validation loss: 1.5734175610285934

Epoch: 6| Step: 8
Training loss: 0.06086386740207672
Validation loss: 1.5482183092383928

Epoch: 6| Step: 9
Training loss: 0.12832634150981903
Validation loss: 1.5600637094948882

Epoch: 6| Step: 10
Training loss: 0.09781845659017563
Validation loss: 1.539042817649021

Epoch: 6| Step: 11
Training loss: 0.16331808269023895
Validation loss: 1.549339977643823

Epoch: 6| Step: 12
Training loss: 0.07967725396156311
Validation loss: 1.5223090623014717

Epoch: 6| Step: 13
Training loss: 0.058132462203502655
Validation loss: 1.5407647996820428

Epoch: 509| Step: 0
Training loss: 0.0747784674167633
Validation loss: 1.5119410202067385

Epoch: 6| Step: 1
Training loss: 0.16198118031024933
Validation loss: 1.5433094821950442

Epoch: 6| Step: 2
Training loss: 0.08221311867237091
Validation loss: 1.56164296596281

Epoch: 6| Step: 3
Training loss: 0.0992061048746109
Validation loss: 1.5738166916754939

Epoch: 6| Step: 4
Training loss: 0.15304437279701233
Validation loss: 1.5808806124553885

Epoch: 6| Step: 5
Training loss: 0.12650510668754578
Validation loss: 1.557853465439171

Epoch: 6| Step: 6
Training loss: 0.08068118989467621
Validation loss: 1.598048069143808

Epoch: 6| Step: 7
Training loss: 0.15096858143806458
Validation loss: 1.6225403175559094

Epoch: 6| Step: 8
Training loss: 0.22722092270851135
Validation loss: 1.588358727834558

Epoch: 6| Step: 9
Training loss: 0.15533244609832764
Validation loss: 1.5458217308085451

Epoch: 6| Step: 10
Training loss: 0.059115007519721985
Validation loss: 1.5256162189668225

Epoch: 6| Step: 11
Training loss: 0.1147788017988205
Validation loss: 1.513534458734656

Epoch: 6| Step: 12
Training loss: 0.15464478731155396
Validation loss: 1.526272500714948

Epoch: 6| Step: 13
Training loss: 0.6097139716148376
Validation loss: 1.5184524783524134

Epoch: 510| Step: 0
Training loss: 0.0921417698264122
Validation loss: 1.570399453563075

Epoch: 6| Step: 1
Training loss: 0.10562211275100708
Validation loss: 1.5524202726220573

Epoch: 6| Step: 2
Training loss: 0.11121572554111481
Validation loss: 1.577573053298458

Epoch: 6| Step: 3
Training loss: 0.12499736249446869
Validation loss: 1.590949187996567

Epoch: 6| Step: 4
Training loss: 0.12006749212741852
Validation loss: 1.5954123953337311

Epoch: 6| Step: 5
Training loss: 0.23420941829681396
Validation loss: 1.6129873555193666

Epoch: 6| Step: 6
Training loss: 0.20055754482746124
Validation loss: 1.6034994715003557

Epoch: 6| Step: 7
Training loss: 0.09765858948230743
Validation loss: 1.6198832014555573

Epoch: 6| Step: 8
Training loss: 0.39952003955841064
Validation loss: 1.5985925018146474

Epoch: 6| Step: 9
Training loss: 0.09921246021986008
Validation loss: 1.5501469476248628

Epoch: 6| Step: 10
Training loss: 0.12334607541561127
Validation loss: 1.5160780388821837

Epoch: 6| Step: 11
Training loss: 0.0935768336057663
Validation loss: 1.5044670963800082

Epoch: 6| Step: 12
Training loss: 0.11434288322925568
Validation loss: 1.5254906505666754

Epoch: 6| Step: 13
Training loss: 0.09181948751211166
Validation loss: 1.4938616932079356

Epoch: 511| Step: 0
Training loss: 0.35048559308052063
Validation loss: 1.5195574850164435

Epoch: 6| Step: 1
Training loss: 0.09450925886631012
Validation loss: 1.5424853063398791

Epoch: 6| Step: 2
Training loss: 0.10393992066383362
Validation loss: 1.5354809286773845

Epoch: 6| Step: 3
Training loss: 0.14627277851104736
Validation loss: 1.5818046991543104

Epoch: 6| Step: 4
Training loss: 0.09944115579128265
Validation loss: 1.5973345477093932

Epoch: 6| Step: 5
Training loss: 0.09141485393047333
Validation loss: 1.6050775711254408

Epoch: 6| Step: 6
Training loss: 0.1559770405292511
Validation loss: 1.5882874009429768

Epoch: 6| Step: 7
Training loss: 0.11996602267026901
Validation loss: 1.5872188486078733

Epoch: 6| Step: 8
Training loss: 0.08816331624984741
Validation loss: 1.6479959193096365

Epoch: 6| Step: 9
Training loss: 0.09139516204595566
Validation loss: 1.6126171196660688

Epoch: 6| Step: 10
Training loss: 0.15157592296600342
Validation loss: 1.6306927511768956

Epoch: 6| Step: 11
Training loss: 0.08843329548835754
Validation loss: 1.6377272939169278

Epoch: 6| Step: 12
Training loss: 0.10528960824012756
Validation loss: 1.600698273669007

Epoch: 6| Step: 13
Training loss: 0.1879396289587021
Validation loss: 1.6020647941097137

Epoch: 512| Step: 0
Training loss: 0.09829577058553696
Validation loss: 1.579896596170241

Epoch: 6| Step: 1
Training loss: 0.14241813123226166
Validation loss: 1.581625606424065

Epoch: 6| Step: 2
Training loss: 0.08876681327819824
Validation loss: 1.5471266700375466

Epoch: 6| Step: 3
Training loss: 0.08834532648324966
Validation loss: 1.5810189452222598

Epoch: 6| Step: 4
Training loss: 0.07493782043457031
Validation loss: 1.551230671585247

Epoch: 6| Step: 5
Training loss: 0.09279170632362366
Validation loss: 1.5444475643096431

Epoch: 6| Step: 6
Training loss: 0.37250393629074097
Validation loss: 1.5544386140761837

Epoch: 6| Step: 7
Training loss: 0.15824124217033386
Validation loss: 1.5462760797110937

Epoch: 6| Step: 8
Training loss: 0.06601094454526901
Validation loss: 1.5420976082483928

Epoch: 6| Step: 9
Training loss: 0.10661128163337708
Validation loss: 1.5446449774567799

Epoch: 6| Step: 10
Training loss: 0.14085277915000916
Validation loss: 1.5431619536492132

Epoch: 6| Step: 11
Training loss: 0.12405002117156982
Validation loss: 1.5433437785794657

Epoch: 6| Step: 12
Training loss: 0.10008163750171661
Validation loss: 1.562545371311967

Epoch: 6| Step: 13
Training loss: 0.10623499006032944
Validation loss: 1.5622091985517932

Epoch: 513| Step: 0
Training loss: 0.16697350144386292
Validation loss: 1.5648457920679482

Epoch: 6| Step: 1
Training loss: 0.09989411383867264
Validation loss: 1.5573308179455418

Epoch: 6| Step: 2
Training loss: 0.08365160971879959
Validation loss: 1.5797443466801797

Epoch: 6| Step: 3
Training loss: 0.09848836809396744
Validation loss: 1.579312091232628

Epoch: 6| Step: 4
Training loss: 0.06991494446992874
Validation loss: 1.5801820485822615

Epoch: 6| Step: 5
Training loss: 0.08533579856157303
Validation loss: 1.5342296849014938

Epoch: 6| Step: 6
Training loss: 0.09916691482067108
Validation loss: 1.5417930823500439

Epoch: 6| Step: 7
Training loss: 0.3663589358329773
Validation loss: 1.5211631687738563

Epoch: 6| Step: 8
Training loss: 0.07965247333049774
Validation loss: 1.4982964364431237

Epoch: 6| Step: 9
Training loss: 0.21294108033180237
Validation loss: 1.530490868835039

Epoch: 6| Step: 10
Training loss: 0.1299256831407547
Validation loss: 1.5082643288438038

Epoch: 6| Step: 11
Training loss: 0.10085158050060272
Validation loss: 1.5410470334432458

Epoch: 6| Step: 12
Training loss: 0.12633633613586426
Validation loss: 1.5230675435835315

Epoch: 6| Step: 13
Training loss: 0.07926896959543228
Validation loss: 1.5145585562593193

Epoch: 514| Step: 0
Training loss: 0.05935470014810562
Validation loss: 1.523454503346515

Epoch: 6| Step: 1
Training loss: 0.14572256803512573
Validation loss: 1.5421708142885597

Epoch: 6| Step: 2
Training loss: 0.08864906430244446
Validation loss: 1.54614221536985

Epoch: 6| Step: 3
Training loss: 0.09190239012241364
Validation loss: 1.5209882669551398

Epoch: 6| Step: 4
Training loss: 0.10763803124427795
Validation loss: 1.5220138975369033

Epoch: 6| Step: 5
Training loss: 0.07794462889432907
Validation loss: 1.5496561142706102

Epoch: 6| Step: 6
Training loss: 0.2185075581073761
Validation loss: 1.5389970925546461

Epoch: 6| Step: 7
Training loss: 0.36530622839927673
Validation loss: 1.552653439583317

Epoch: 6| Step: 8
Training loss: 0.08007117360830307
Validation loss: 1.5631490715088383

Epoch: 6| Step: 9
Training loss: 0.08843765407800674
Validation loss: 1.5749444192455662

Epoch: 6| Step: 10
Training loss: 0.10845987498760223
Validation loss: 1.5899689517995363

Epoch: 6| Step: 11
Training loss: 0.09033600986003876
Validation loss: 1.5540097708343177

Epoch: 6| Step: 12
Training loss: 0.09252917021512985
Validation loss: 1.549967659417019

Epoch: 6| Step: 13
Training loss: 0.0802287757396698
Validation loss: 1.5404283974760322

Epoch: 515| Step: 0
Training loss: 0.08402005583047867
Validation loss: 1.5586856590804232

Epoch: 6| Step: 1
Training loss: 0.07946005463600159
Validation loss: 1.554285099429469

Epoch: 6| Step: 2
Training loss: 0.08515539765357971
Validation loss: 1.5334025531686761

Epoch: 6| Step: 3
Training loss: 0.1095842570066452
Validation loss: 1.5332086816910775

Epoch: 6| Step: 4
Training loss: 0.1262323260307312
Validation loss: 1.5448323462599067

Epoch: 6| Step: 5
Training loss: 0.07114189118146896
Validation loss: 1.5339435710701892

Epoch: 6| Step: 6
Training loss: 0.44111964106559753
Validation loss: 1.5311185762446413

Epoch: 6| Step: 7
Training loss: 0.08404254913330078
Validation loss: 1.5687413356637443

Epoch: 6| Step: 8
Training loss: 0.10042141377925873
Validation loss: 1.5904696718338998

Epoch: 6| Step: 9
Training loss: 0.14337821304798126
Validation loss: 1.601307197283673

Epoch: 6| Step: 10
Training loss: 0.0941142588853836
Validation loss: 1.5948040216199812

Epoch: 6| Step: 11
Training loss: 0.10421545058488846
Validation loss: 1.618976354598999

Epoch: 6| Step: 12
Training loss: 0.10583924502134323
Validation loss: 1.6153994952478716

Epoch: 6| Step: 13
Training loss: 0.19264449179172516
Validation loss: 1.615142773556453

Epoch: 516| Step: 0
Training loss: 0.39556556940078735
Validation loss: 1.5738466247435539

Epoch: 6| Step: 1
Training loss: 0.11362367123365402
Validation loss: 1.5666479436300134

Epoch: 6| Step: 2
Training loss: 0.10183130204677582
Validation loss: 1.5557605951063094

Epoch: 6| Step: 3
Training loss: 0.11507920920848846
Validation loss: 1.5444244024574116

Epoch: 6| Step: 4
Training loss: 0.12627607583999634
Validation loss: 1.5791075165553758

Epoch: 6| Step: 5
Training loss: 0.08864462375640869
Validation loss: 1.5282982895451207

Epoch: 6| Step: 6
Training loss: 0.0889417976140976
Validation loss: 1.5474756827918432

Epoch: 6| Step: 7
Training loss: 0.13945817947387695
Validation loss: 1.5930587873663953

Epoch: 6| Step: 8
Training loss: 0.12376319617033005
Validation loss: 1.5873111191616263

Epoch: 6| Step: 9
Training loss: 0.08574867993593216
Validation loss: 1.5635901433165356

Epoch: 6| Step: 10
Training loss: 0.08067911863327026
Validation loss: 1.5467774829556864

Epoch: 6| Step: 11
Training loss: 0.20339125394821167
Validation loss: 1.575785962484216

Epoch: 6| Step: 12
Training loss: 0.08769246190786362
Validation loss: 1.5885425524045063

Epoch: 6| Step: 13
Training loss: 0.1431976556777954
Validation loss: 1.5856315076992076

Epoch: 517| Step: 0
Training loss: 0.07354992628097534
Validation loss: 1.5610950403316046

Epoch: 6| Step: 1
Training loss: 0.07555711269378662
Validation loss: 1.573234704232985

Epoch: 6| Step: 2
Training loss: 0.07332620769739151
Validation loss: 1.5684318978299376

Epoch: 6| Step: 3
Training loss: 0.1832873821258545
Validation loss: 1.5825900377765778

Epoch: 6| Step: 4
Training loss: 0.11728020012378693
Validation loss: 1.5841790694062428

Epoch: 6| Step: 5
Training loss: 0.09909670054912567
Validation loss: 1.6024784131716656

Epoch: 6| Step: 6
Training loss: 0.09147828817367554
Validation loss: 1.5835130624873663

Epoch: 6| Step: 7
Training loss: 0.09329497814178467
Validation loss: 1.6128847945121028

Epoch: 6| Step: 8
Training loss: 0.3370213508605957
Validation loss: 1.6064107744924483

Epoch: 6| Step: 9
Training loss: 0.15435662865638733
Validation loss: 1.6118032829735869

Epoch: 6| Step: 10
Training loss: 0.17301391065120697
Validation loss: 1.6188417032200804

Epoch: 6| Step: 11
Training loss: 0.06813884526491165
Validation loss: 1.5684235211341613

Epoch: 6| Step: 12
Training loss: 0.08751805126667023
Validation loss: 1.5673888691010014

Epoch: 6| Step: 13
Training loss: 0.18598538637161255
Validation loss: 1.561577312407955

Epoch: 518| Step: 0
Training loss: 0.12696748971939087
Validation loss: 1.5414318423117361

Epoch: 6| Step: 1
Training loss: 0.06613323092460632
Validation loss: 1.5136272484256375

Epoch: 6| Step: 2
Training loss: 0.10869259387254715
Validation loss: 1.5274527367725168

Epoch: 6| Step: 3
Training loss: 0.10869556665420532
Validation loss: 1.5195599268841486

Epoch: 6| Step: 4
Training loss: 0.06415686011314392
Validation loss: 1.503350132255144

Epoch: 6| Step: 5
Training loss: 0.3994022607803345
Validation loss: 1.539168934668264

Epoch: 6| Step: 6
Training loss: 0.2003825306892395
Validation loss: 1.506442552612674

Epoch: 6| Step: 7
Training loss: 0.08558093011379242
Validation loss: 1.5147951623444915

Epoch: 6| Step: 8
Training loss: 0.06660572439432144
Validation loss: 1.536381104300099

Epoch: 6| Step: 9
Training loss: 0.09839874505996704
Validation loss: 1.5726906612355223

Epoch: 6| Step: 10
Training loss: 0.08608043193817139
Validation loss: 1.5551040018758466

Epoch: 6| Step: 11
Training loss: 0.1111125648021698
Validation loss: 1.5942947774805047

Epoch: 6| Step: 12
Training loss: 0.11718020588159561
Validation loss: 1.581891405966974

Epoch: 6| Step: 13
Training loss: 0.12455349415540695
Validation loss: 1.581856402017737

Epoch: 519| Step: 0
Training loss: 0.09333708137273788
Validation loss: 1.6059612138296968

Epoch: 6| Step: 1
Training loss: 0.17769208550453186
Validation loss: 1.6110565059928483

Epoch: 6| Step: 2
Training loss: 0.06688682734966278
Validation loss: 1.5832199922171972

Epoch: 6| Step: 3
Training loss: 0.34349876642227173
Validation loss: 1.581710510356452

Epoch: 6| Step: 4
Training loss: 0.07226108759641647
Validation loss: 1.5807690517876738

Epoch: 6| Step: 5
Training loss: 0.07093223184347153
Validation loss: 1.5659862231182795

Epoch: 6| Step: 6
Training loss: 0.08657577633857727
Validation loss: 1.5406234533556047

Epoch: 6| Step: 7
Training loss: 0.07715268433094025
Validation loss: 1.5358154350711453

Epoch: 6| Step: 8
Training loss: 0.10625600814819336
Validation loss: 1.5303092105414278

Epoch: 6| Step: 9
Training loss: 0.10058723390102386
Validation loss: 1.5319404288004803

Epoch: 6| Step: 10
Training loss: 0.12650035321712494
Validation loss: 1.5333428254691504

Epoch: 6| Step: 11
Training loss: 0.11422956734895706
Validation loss: 1.4795195466728621

Epoch: 6| Step: 12
Training loss: 0.19364899396896362
Validation loss: 1.5079088557151057

Epoch: 6| Step: 13
Training loss: 0.08813455700874329
Validation loss: 1.5193676358910018

Epoch: 520| Step: 0
Training loss: 0.10569459199905396
Validation loss: 1.5205174184614612

Epoch: 6| Step: 1
Training loss: 0.3399009108543396
Validation loss: 1.5717943586328977

Epoch: 6| Step: 2
Training loss: 0.11139041930437088
Validation loss: 1.5680852077340568

Epoch: 6| Step: 3
Training loss: 0.17412981390953064
Validation loss: 1.588601848130585

Epoch: 6| Step: 4
Training loss: 0.14541517198085785
Validation loss: 1.5964153799959409

Epoch: 6| Step: 5
Training loss: 0.07886267453432083
Validation loss: 1.6020342342315181

Epoch: 6| Step: 6
Training loss: 0.18533560633659363
Validation loss: 1.608203491856975

Epoch: 6| Step: 7
Training loss: 0.10520701855421066
Validation loss: 1.598059565790238

Epoch: 6| Step: 8
Training loss: 0.10309459269046783
Validation loss: 1.5676173856181483

Epoch: 6| Step: 9
Training loss: 0.14902395009994507
Validation loss: 1.5567991201595595

Epoch: 6| Step: 10
Training loss: 0.07230275869369507
Validation loss: 1.5199381689871512

Epoch: 6| Step: 11
Training loss: 0.09202438592910767
Validation loss: 1.5065938644511725

Epoch: 6| Step: 12
Training loss: 0.1198672279715538
Validation loss: 1.5007736272709344

Epoch: 6| Step: 13
Training loss: 0.07852938771247864
Validation loss: 1.4893397592729138

Epoch: 521| Step: 0
Training loss: 0.13795426487922668
Validation loss: 1.4852820724569342

Epoch: 6| Step: 1
Training loss: 0.13812240958213806
Validation loss: 1.4787832306277366

Epoch: 6| Step: 2
Training loss: 0.5123576521873474
Validation loss: 1.5145771503448486

Epoch: 6| Step: 3
Training loss: 0.15869244933128357
Validation loss: 1.5260187131102367

Epoch: 6| Step: 4
Training loss: 0.10771840810775757
Validation loss: 1.5441531455644997

Epoch: 6| Step: 5
Training loss: 0.1110004410147667
Validation loss: 1.5815005417793029

Epoch: 6| Step: 6
Training loss: 0.12083283066749573
Validation loss: 1.602991888600011

Epoch: 6| Step: 7
Training loss: 0.15614649653434753
Validation loss: 1.6597924405528652

Epoch: 6| Step: 8
Training loss: 0.1634371429681778
Validation loss: 1.675726463717799

Epoch: 6| Step: 9
Training loss: 0.12944260239601135
Validation loss: 1.6898657378330026

Epoch: 6| Step: 10
Training loss: 0.15976181626319885
Validation loss: 1.6695704030734237

Epoch: 6| Step: 11
Training loss: 0.11249637603759766
Validation loss: 1.616611470458328

Epoch: 6| Step: 12
Training loss: 0.20162808895111084
Validation loss: 1.6014357715524652

Epoch: 6| Step: 13
Training loss: 0.09191017597913742
Validation loss: 1.5643739418316913

Epoch: 522| Step: 0
Training loss: 0.09535735845565796
Validation loss: 1.554579327183385

Epoch: 6| Step: 1
Training loss: 0.14275622367858887
Validation loss: 1.5296046900492843

Epoch: 6| Step: 2
Training loss: 0.07904082536697388
Validation loss: 1.5450274200849636

Epoch: 6| Step: 3
Training loss: 0.12687118351459503
Validation loss: 1.5186333374310566

Epoch: 6| Step: 4
Training loss: 0.10678127408027649
Validation loss: 1.5079330885282127

Epoch: 6| Step: 5
Training loss: 0.13510480523109436
Validation loss: 1.5337103630906792

Epoch: 6| Step: 6
Training loss: 0.10812589526176453
Validation loss: 1.5122122021131619

Epoch: 6| Step: 7
Training loss: 0.10387987643480301
Validation loss: 1.5349829414839387

Epoch: 6| Step: 8
Training loss: 0.14419487118721008
Validation loss: 1.5528743741332844

Epoch: 6| Step: 9
Training loss: 0.3225076198577881
Validation loss: 1.5366499962345246

Epoch: 6| Step: 10
Training loss: 0.13547024130821228
Validation loss: 1.540957812340029

Epoch: 6| Step: 11
Training loss: 0.0897817462682724
Validation loss: 1.546018636354836

Epoch: 6| Step: 12
Training loss: 0.20754073560237885
Validation loss: 1.5886478821436565

Epoch: 6| Step: 13
Training loss: 0.08121006935834885
Validation loss: 1.5486398461044475

Epoch: 523| Step: 0
Training loss: 0.07768692821264267
Validation loss: 1.5682514713656517

Epoch: 6| Step: 1
Training loss: 0.11585678160190582
Validation loss: 1.5738632602076377

Epoch: 6| Step: 2
Training loss: 0.07169321179389954
Validation loss: 1.5916854489234187

Epoch: 6| Step: 3
Training loss: 0.0935634896159172
Validation loss: 1.5780894705044326

Epoch: 6| Step: 4
Training loss: 0.10520528256893158
Validation loss: 1.5429493797722684

Epoch: 6| Step: 5
Training loss: 0.11646227538585663
Validation loss: 1.5508237872072446

Epoch: 6| Step: 6
Training loss: 0.11884941905736923
Validation loss: 1.5475713591421805

Epoch: 6| Step: 7
Training loss: 0.09169450402259827
Validation loss: 1.5286235040233982

Epoch: 6| Step: 8
Training loss: 0.11070121824741364
Validation loss: 1.5128991821760773

Epoch: 6| Step: 9
Training loss: 0.07322840392589569
Validation loss: 1.5406476887323524

Epoch: 6| Step: 10
Training loss: 0.09152279794216156
Validation loss: 1.5258171981380833

Epoch: 6| Step: 11
Training loss: 0.40584108233451843
Validation loss: 1.5266131380552888

Epoch: 6| Step: 12
Training loss: 0.09005129337310791
Validation loss: 1.5232239961624146

Epoch: 6| Step: 13
Training loss: 0.22248207032680511
Validation loss: 1.5489055296426177

Epoch: 524| Step: 0
Training loss: 0.07177887856960297
Validation loss: 1.5723262153645998

Epoch: 6| Step: 1
Training loss: 0.09759502112865448
Validation loss: 1.5611048090842463

Epoch: 6| Step: 2
Training loss: 0.13424131274223328
Validation loss: 1.579977685405362

Epoch: 6| Step: 3
Training loss: 0.34974104166030884
Validation loss: 1.5717938516729622

Epoch: 6| Step: 4
Training loss: 0.08811891078948975
Validation loss: 1.568850209636073

Epoch: 6| Step: 5
Training loss: 0.0725003331899643
Validation loss: 1.548548859934653

Epoch: 6| Step: 6
Training loss: 0.09324204921722412
Validation loss: 1.5569359358920847

Epoch: 6| Step: 7
Training loss: 0.05486653745174408
Validation loss: 1.564924902813409

Epoch: 6| Step: 8
Training loss: 0.07494887709617615
Validation loss: 1.5583613431581886

Epoch: 6| Step: 9
Training loss: 0.1861918717622757
Validation loss: 1.587592036493363

Epoch: 6| Step: 10
Training loss: 0.1077137216925621
Validation loss: 1.5610733878227971

Epoch: 6| Step: 11
Training loss: 0.052018970251083374
Validation loss: 1.5424525865944483

Epoch: 6| Step: 12
Training loss: 0.05569438636302948
Validation loss: 1.5276379354538456

Epoch: 6| Step: 13
Training loss: 0.08227875828742981
Validation loss: 1.522857919816048

Epoch: 525| Step: 0
Training loss: 0.0722515806555748
Validation loss: 1.507492571748713

Epoch: 6| Step: 1
Training loss: 0.11188463121652603
Validation loss: 1.5016330224211498

Epoch: 6| Step: 2
Training loss: 0.0884934589266777
Validation loss: 1.5162951202802761

Epoch: 6| Step: 3
Training loss: 0.10903435945510864
Validation loss: 1.5173385117643623

Epoch: 6| Step: 4
Training loss: 0.121745266020298
Validation loss: 1.5307824611663818

Epoch: 6| Step: 5
Training loss: 0.11297788470983505
Validation loss: 1.545139871617799

Epoch: 6| Step: 6
Training loss: 0.07572528719902039
Validation loss: 1.5476630016039776

Epoch: 6| Step: 7
Training loss: 0.08386307954788208
Validation loss: 1.577651544283795

Epoch: 6| Step: 8
Training loss: 0.3443087041378021
Validation loss: 1.5755716741725962

Epoch: 6| Step: 9
Training loss: 0.12646424770355225
Validation loss: 1.5913996568290136

Epoch: 6| Step: 10
Training loss: 0.1940404176712036
Validation loss: 1.6405396141031736

Epoch: 6| Step: 11
Training loss: 0.15403476357460022
Validation loss: 1.6023980789287116

Epoch: 6| Step: 12
Training loss: 0.08746284246444702
Validation loss: 1.6150285108115083

Epoch: 6| Step: 13
Training loss: 0.09256801754236221
Validation loss: 1.6052318305097601

Epoch: 526| Step: 0
Training loss: 0.15569248795509338
Validation loss: 1.5901125682297574

Epoch: 6| Step: 1
Training loss: 0.12638449668884277
Validation loss: 1.580159846172538

Epoch: 6| Step: 2
Training loss: 0.14036621153354645
Validation loss: 1.5650532027726531

Epoch: 6| Step: 3
Training loss: 0.13939321041107178
Validation loss: 1.5771252750068583

Epoch: 6| Step: 4
Training loss: 0.13352423906326294
Validation loss: 1.5749369603331371

Epoch: 6| Step: 5
Training loss: 0.16721828281879425
Validation loss: 1.5550109160843717

Epoch: 6| Step: 6
Training loss: 0.0894976556301117
Validation loss: 1.52119319797844

Epoch: 6| Step: 7
Training loss: 0.15770509839057922
Validation loss: 1.4887534687595982

Epoch: 6| Step: 8
Training loss: 0.3196914792060852
Validation loss: 1.5212365260688208

Epoch: 6| Step: 9
Training loss: 0.08344309777021408
Validation loss: 1.5045595310067619

Epoch: 6| Step: 10
Training loss: 0.07474228739738464
Validation loss: 1.502762666312597

Epoch: 6| Step: 11
Training loss: 0.07543438673019409
Validation loss: 1.4802151469774143

Epoch: 6| Step: 12
Training loss: 0.09682697802782059
Validation loss: 1.5017159062047158

Epoch: 6| Step: 13
Training loss: 0.04490585997700691
Validation loss: 1.517333157600895

Epoch: 527| Step: 0
Training loss: 0.3046211898326874
Validation loss: 1.4922622288427045

Epoch: 6| Step: 1
Training loss: 0.12326348572969437
Validation loss: 1.4984914666862899

Epoch: 6| Step: 2
Training loss: 0.1326657235622406
Validation loss: 1.5456780848964569

Epoch: 6| Step: 3
Training loss: 0.15047681331634521
Validation loss: 1.5458251225051058

Epoch: 6| Step: 4
Training loss: 0.10190130025148392
Validation loss: 1.5457717372525124

Epoch: 6| Step: 5
Training loss: 0.1755363941192627
Validation loss: 1.5426070946519093

Epoch: 6| Step: 6
Training loss: 0.09601256996393204
Validation loss: 1.529708928959344

Epoch: 6| Step: 7
Training loss: 0.10957979410886765
Validation loss: 1.5494342157917638

Epoch: 6| Step: 8
Training loss: 0.1274821162223816
Validation loss: 1.5428887874849382

Epoch: 6| Step: 9
Training loss: 0.08653590828180313
Validation loss: 1.5570477554875035

Epoch: 6| Step: 10
Training loss: 0.06876738369464874
Validation loss: 1.540202663790795

Epoch: 6| Step: 11
Training loss: 0.11865874379873276
Validation loss: 1.5493385971233409

Epoch: 6| Step: 12
Training loss: 0.07154205441474915
Validation loss: 1.5608845359535628

Epoch: 6| Step: 13
Training loss: 0.07140551507472992
Validation loss: 1.5371441168169822

Epoch: 528| Step: 0
Training loss: 0.40729498863220215
Validation loss: 1.5284497917339366

Epoch: 6| Step: 1
Training loss: 0.08132220804691315
Validation loss: 1.5507467203242804

Epoch: 6| Step: 2
Training loss: 0.12879791855812073
Validation loss: 1.528538413586155

Epoch: 6| Step: 3
Training loss: 0.08072036504745483
Validation loss: 1.5291155756160777

Epoch: 6| Step: 4
Training loss: 0.06789739429950714
Validation loss: 1.5209162145532586

Epoch: 6| Step: 5
Training loss: 0.07694151997566223
Validation loss: 1.523382984181886

Epoch: 6| Step: 6
Training loss: 0.0836436003446579
Validation loss: 1.5074277359952208

Epoch: 6| Step: 7
Training loss: 0.06845948100090027
Validation loss: 1.5150345051160423

Epoch: 6| Step: 8
Training loss: 0.060500141233205795
Validation loss: 1.5134048487550469

Epoch: 6| Step: 9
Training loss: 0.14849695563316345
Validation loss: 1.523401439830821

Epoch: 6| Step: 10
Training loss: 0.13888105750083923
Validation loss: 1.5116128331871443

Epoch: 6| Step: 11
Training loss: 0.08287393301725388
Validation loss: 1.5403167714354813

Epoch: 6| Step: 12
Training loss: 0.14380528032779694
Validation loss: 1.5044461783542429

Epoch: 6| Step: 13
Training loss: 0.08406787365674973
Validation loss: 1.5439211476233698

Epoch: 529| Step: 0
Training loss: 0.10140233486890793
Validation loss: 1.521308345820314

Epoch: 6| Step: 1
Training loss: 0.3315798044204712
Validation loss: 1.5539088056933494

Epoch: 6| Step: 2
Training loss: 0.1272629201412201
Validation loss: 1.5658353605578024

Epoch: 6| Step: 3
Training loss: 0.0737716481089592
Validation loss: 1.5788263941323886

Epoch: 6| Step: 4
Training loss: 0.12881387770175934
Validation loss: 1.567918485210788

Epoch: 6| Step: 5
Training loss: 0.10256488621234894
Validation loss: 1.5532854308364212

Epoch: 6| Step: 6
Training loss: 0.13232487440109253
Validation loss: 1.5380950602152015

Epoch: 6| Step: 7
Training loss: 0.07348418235778809
Validation loss: 1.5549823225185435

Epoch: 6| Step: 8
Training loss: 0.09380091726779938
Validation loss: 1.5373806491974862

Epoch: 6| Step: 9
Training loss: 0.11646006256341934
Validation loss: 1.5228771842936033

Epoch: 6| Step: 10
Training loss: 0.13488882780075073
Validation loss: 1.5114187649501267

Epoch: 6| Step: 11
Training loss: 0.07534738630056381
Validation loss: 1.4998321879294612

Epoch: 6| Step: 12
Training loss: 0.09355845302343369
Validation loss: 1.5188883940378826

Epoch: 6| Step: 13
Training loss: 0.0894588902592659
Validation loss: 1.507609853180506

Epoch: 530| Step: 0
Training loss: 0.08405414968729019
Validation loss: 1.4915181488119147

Epoch: 6| Step: 1
Training loss: 0.14883604645729065
Validation loss: 1.4841506070988153

Epoch: 6| Step: 2
Training loss: 0.11662625521421432
Validation loss: 1.5039067781099709

Epoch: 6| Step: 3
Training loss: 0.0841226652264595
Validation loss: 1.523659699706621

Epoch: 6| Step: 4
Training loss: 0.06947581470012665
Validation loss: 1.5011444437888362

Epoch: 6| Step: 5
Training loss: 0.0829894170165062
Validation loss: 1.504114911120425

Epoch: 6| Step: 6
Training loss: 0.36870554089546204
Validation loss: 1.530830958838104

Epoch: 6| Step: 7
Training loss: 0.08855441957712173
Validation loss: 1.5331823954018213

Epoch: 6| Step: 8
Training loss: 0.0677017867565155
Validation loss: 1.5400307018269774

Epoch: 6| Step: 9
Training loss: 0.09415037930011749
Validation loss: 1.5269349454551615

Epoch: 6| Step: 10
Training loss: 0.06698784232139587
Validation loss: 1.5042757590611775

Epoch: 6| Step: 11
Training loss: 0.12492216378450394
Validation loss: 1.5333657995347054

Epoch: 6| Step: 12
Training loss: 0.0695037916302681
Validation loss: 1.554380343806359

Epoch: 6| Step: 13
Training loss: 0.12207390367984772
Validation loss: 1.5511207196020311

Epoch: 531| Step: 0
Training loss: 0.054593585431575775
Validation loss: 1.510674435605285

Epoch: 6| Step: 1
Training loss: 0.09447666257619858
Validation loss: 1.5258684709507933

Epoch: 6| Step: 2
Training loss: 0.08299124985933304
Validation loss: 1.5176338611110565

Epoch: 6| Step: 3
Training loss: 0.0832076370716095
Validation loss: 1.536973059818309

Epoch: 6| Step: 4
Training loss: 0.09724749624729156
Validation loss: 1.5225092390532136

Epoch: 6| Step: 5
Training loss: 0.04873519763350487
Validation loss: 1.5508696289472683

Epoch: 6| Step: 6
Training loss: 0.06592071801424026
Validation loss: 1.5670381322983773

Epoch: 6| Step: 7
Training loss: 0.3581000566482544
Validation loss: 1.5509880358173

Epoch: 6| Step: 8
Training loss: 0.07170219719409943
Validation loss: 1.5421398673006284

Epoch: 6| Step: 9
Training loss: 0.11662844568490982
Validation loss: 1.5278158918503792

Epoch: 6| Step: 10
Training loss: 0.05460752174258232
Validation loss: 1.5343384012099235

Epoch: 6| Step: 11
Training loss: 0.1235918253660202
Validation loss: 1.5166438241158762

Epoch: 6| Step: 12
Training loss: 0.1326572746038437
Validation loss: 1.5375521285559541

Epoch: 6| Step: 13
Training loss: 0.08022937178611755
Validation loss: 1.53633407110809

Epoch: 532| Step: 0
Training loss: 0.09519868344068527
Validation loss: 1.5353283401458495

Epoch: 6| Step: 1
Training loss: 0.07452322542667389
Validation loss: 1.5622880048649286

Epoch: 6| Step: 2
Training loss: 0.1224840059876442
Validation loss: 1.5719195976052234

Epoch: 6| Step: 3
Training loss: 0.07545485347509384
Validation loss: 1.5609595429512761

Epoch: 6| Step: 4
Training loss: 0.16109435260295868
Validation loss: 1.5961304864575785

Epoch: 6| Step: 5
Training loss: 0.07422638684511185
Validation loss: 1.568406903615562

Epoch: 6| Step: 6
Training loss: 0.15443065762519836
Validation loss: 1.5964865107690134

Epoch: 6| Step: 7
Training loss: 0.05406105890870094
Validation loss: 1.5983268714720202

Epoch: 6| Step: 8
Training loss: 0.20062009990215302
Validation loss: 1.5572749273751372

Epoch: 6| Step: 9
Training loss: 0.09135333448648453
Validation loss: 1.5825717526097451

Epoch: 6| Step: 10
Training loss: 0.1092134639620781
Validation loss: 1.509783802493926

Epoch: 6| Step: 11
Training loss: 0.30303046107292175
Validation loss: 1.4804798941458426

Epoch: 6| Step: 12
Training loss: 0.09421874582767487
Validation loss: 1.5111464646554762

Epoch: 6| Step: 13
Training loss: 0.14360743761062622
Validation loss: 1.5327703581061414

Epoch: 533| Step: 0
Training loss: 0.07963845878839493
Validation loss: 1.50453814383476

Epoch: 6| Step: 1
Training loss: 0.08039303869009018
Validation loss: 1.5234684521152126

Epoch: 6| Step: 2
Training loss: 0.07457360625267029
Validation loss: 1.5446349702855593

Epoch: 6| Step: 3
Training loss: 0.060718461871147156
Validation loss: 1.559108175257201

Epoch: 6| Step: 4
Training loss: 0.06661540269851685
Validation loss: 1.5568395430041897

Epoch: 6| Step: 5
Training loss: 0.097220279276371
Validation loss: 1.5972273477943995

Epoch: 6| Step: 6
Training loss: 0.07793166488409042
Validation loss: 1.590438283899779

Epoch: 6| Step: 7
Training loss: 0.11728163808584213
Validation loss: 1.6544722767286404

Epoch: 6| Step: 8
Training loss: 0.12252344191074371
Validation loss: 1.6819085203191286

Epoch: 6| Step: 9
Training loss: 0.12173399329185486
Validation loss: 1.6633563669778968

Epoch: 6| Step: 10
Training loss: 0.10003692656755447
Validation loss: 1.6249967595582366

Epoch: 6| Step: 11
Training loss: 0.21479207277297974
Validation loss: 1.6193842195695447

Epoch: 6| Step: 12
Training loss: 0.3635255992412567
Validation loss: 1.5752725883196759

Epoch: 6| Step: 13
Training loss: 0.19017700850963593
Validation loss: 1.5824604585606565

Epoch: 534| Step: 0
Training loss: 0.13133065402507782
Validation loss: 1.5644618388145202

Epoch: 6| Step: 1
Training loss: 0.15952324867248535
Validation loss: 1.5467961975323257

Epoch: 6| Step: 2
Training loss: 0.12349245697259903
Validation loss: 1.5236769312171525

Epoch: 6| Step: 3
Training loss: 0.10135744512081146
Validation loss: 1.5613044602896577

Epoch: 6| Step: 4
Training loss: 0.08104616403579712
Validation loss: 1.5733525458202566

Epoch: 6| Step: 5
Training loss: 0.13139696419239044
Validation loss: 1.5475987618969334

Epoch: 6| Step: 6
Training loss: 0.10539258271455765
Validation loss: 1.5582769493902884

Epoch: 6| Step: 7
Training loss: 0.4335632920265198
Validation loss: 1.5537997676480202

Epoch: 6| Step: 8
Training loss: 0.12311764061450958
Validation loss: 1.5638585500819708

Epoch: 6| Step: 9
Training loss: 0.1368960291147232
Validation loss: 1.588530530211746

Epoch: 6| Step: 10
Training loss: 0.08944298326969147
Validation loss: 1.5490461959633777

Epoch: 6| Step: 11
Training loss: 0.08710973709821701
Validation loss: 1.5739708562051096

Epoch: 6| Step: 12
Training loss: 0.11209986358880997
Validation loss: 1.542866676084457

Epoch: 6| Step: 13
Training loss: 0.09258687496185303
Validation loss: 1.5999718173857658

Epoch: 535| Step: 0
Training loss: 0.11607266217470169
Validation loss: 1.586347726083571

Epoch: 6| Step: 1
Training loss: 0.1535806655883789
Validation loss: 1.5817141840534825

Epoch: 6| Step: 2
Training loss: 0.15004962682724
Validation loss: 1.6046390494992655

Epoch: 6| Step: 3
Training loss: 0.18436911702156067
Validation loss: 1.584958714823569

Epoch: 6| Step: 4
Training loss: 0.10348719358444214
Validation loss: 1.5528101728808494

Epoch: 6| Step: 5
Training loss: 0.0987640917301178
Validation loss: 1.5780740373878068

Epoch: 6| Step: 6
Training loss: 0.10142659395933151
Validation loss: 1.571918297839421

Epoch: 6| Step: 7
Training loss: 0.05735670030117035
Validation loss: 1.5683087020791986

Epoch: 6| Step: 8
Training loss: 0.06988682597875595
Validation loss: 1.5594813285335418

Epoch: 6| Step: 9
Training loss: 0.14306104183197021
Validation loss: 1.5451892896365094

Epoch: 6| Step: 10
Training loss: 0.11609698832035065
Validation loss: 1.554406592922826

Epoch: 6| Step: 11
Training loss: 0.08474162966012955
Validation loss: 1.539959737049636

Epoch: 6| Step: 12
Training loss: 0.04506899416446686
Validation loss: 1.5414424647567093

Epoch: 6| Step: 13
Training loss: 0.4725642800331116
Validation loss: 1.51796010873651

Epoch: 536| Step: 0
Training loss: 0.08962325751781464
Validation loss: 1.5194975035164946

Epoch: 6| Step: 1
Training loss: 0.07939577847719193
Validation loss: 1.541386854264044

Epoch: 6| Step: 2
Training loss: 0.10127508640289307
Validation loss: 1.5357861403496034

Epoch: 6| Step: 3
Training loss: 0.11776875704526901
Validation loss: 1.5600807897506221

Epoch: 6| Step: 4
Training loss: 0.09487907588481903
Validation loss: 1.5564391920643468

Epoch: 6| Step: 5
Training loss: 0.3243130147457123
Validation loss: 1.5661857794689875

Epoch: 6| Step: 6
Training loss: 0.11228818446397781
Validation loss: 1.579363933173559

Epoch: 6| Step: 7
Training loss: 0.06771913915872574
Validation loss: 1.5639671535902127

Epoch: 6| Step: 8
Training loss: 0.06713953614234924
Validation loss: 1.5491575220579743

Epoch: 6| Step: 9
Training loss: 0.16623103618621826
Validation loss: 1.5512205682775027

Epoch: 6| Step: 10
Training loss: 0.08619804680347443
Validation loss: 1.6126755796453005

Epoch: 6| Step: 11
Training loss: 0.09324638545513153
Validation loss: 1.603478625256528

Epoch: 6| Step: 12
Training loss: 0.1084352508187294
Validation loss: 1.6123808571087417

Epoch: 6| Step: 13
Training loss: 0.3075801432132721
Validation loss: 1.6352378758051063

Epoch: 537| Step: 0
Training loss: 0.14941591024398804
Validation loss: 1.5970668895270235

Epoch: 6| Step: 1
Training loss: 0.19222216308116913
Validation loss: 1.612638274828593

Epoch: 6| Step: 2
Training loss: 0.08555527776479721
Validation loss: 1.575476897660122

Epoch: 6| Step: 3
Training loss: 0.09008721262216568
Validation loss: 1.5776095159592167

Epoch: 6| Step: 4
Training loss: 0.1266147494316101
Validation loss: 1.5781428653706786

Epoch: 6| Step: 5
Training loss: 0.37692511081695557
Validation loss: 1.574486396645987

Epoch: 6| Step: 6
Training loss: 0.1387987732887268
Validation loss: 1.5518036850037114

Epoch: 6| Step: 7
Training loss: 0.10796839743852615
Validation loss: 1.580067269263729

Epoch: 6| Step: 8
Training loss: 0.12435920536518097
Validation loss: 1.5579119484911683

Epoch: 6| Step: 9
Training loss: 0.09418503940105438
Validation loss: 1.5535504484689364

Epoch: 6| Step: 10
Training loss: 0.07890896499156952
Validation loss: 1.5559528784085346

Epoch: 6| Step: 11
Training loss: 0.14797578752040863
Validation loss: 1.5472438963510657

Epoch: 6| Step: 12
Training loss: 0.10328079760074615
Validation loss: 1.5624385751703733

Epoch: 6| Step: 13
Training loss: 0.09069318324327469
Validation loss: 1.5321058483533962

Epoch: 538| Step: 0
Training loss: 0.16365846991539001
Validation loss: 1.5549383445452618

Epoch: 6| Step: 1
Training loss: 0.0873534306883812
Validation loss: 1.5457134528826642

Epoch: 6| Step: 2
Training loss: 0.06710975617170334
Validation loss: 1.540911356608073

Epoch: 6| Step: 3
Training loss: 0.12396296858787537
Validation loss: 1.560801677806403

Epoch: 6| Step: 4
Training loss: 0.10015051066875458
Validation loss: 1.562840413021785

Epoch: 6| Step: 5
Training loss: 0.0694936066865921
Validation loss: 1.5234355157421482

Epoch: 6| Step: 6
Training loss: 0.175565704703331
Validation loss: 1.5461514944671302

Epoch: 6| Step: 7
Training loss: 0.43614718317985535
Validation loss: 1.4982364536613546

Epoch: 6| Step: 8
Training loss: 0.12193622440099716
Validation loss: 1.476204611921823

Epoch: 6| Step: 9
Training loss: 0.1322752833366394
Validation loss: 1.4959750624113186

Epoch: 6| Step: 10
Training loss: 0.11121419817209244
Validation loss: 1.4654640561790877

Epoch: 6| Step: 11
Training loss: 0.08947254717350006
Validation loss: 1.490389782895324

Epoch: 6| Step: 12
Training loss: 0.1585647612810135
Validation loss: 1.5022420293541365

Epoch: 6| Step: 13
Training loss: 0.07240740209817886
Validation loss: 1.5425445879659345

Epoch: 539| Step: 0
Training loss: 0.2961949110031128
Validation loss: 1.562524349458756

Epoch: 6| Step: 1
Training loss: 0.09458249807357788
Validation loss: 1.5442426736636827

Epoch: 6| Step: 2
Training loss: 0.0991264134645462
Validation loss: 1.5684228866331038

Epoch: 6| Step: 3
Training loss: 0.09737010300159454
Validation loss: 1.6083386995459115

Epoch: 6| Step: 4
Training loss: 0.16813911497592926
Validation loss: 1.6032911308350102

Epoch: 6| Step: 5
Training loss: 0.13534623384475708
Validation loss: 1.6232462019048712

Epoch: 6| Step: 6
Training loss: 0.11386583745479584
Validation loss: 1.5996566895515687

Epoch: 6| Step: 7
Training loss: 0.13306036591529846
Validation loss: 1.5658963367503176

Epoch: 6| Step: 8
Training loss: 0.10629189014434814
Validation loss: 1.5696660510955318

Epoch: 6| Step: 9
Training loss: 0.05683146417140961
Validation loss: 1.5410150468990367

Epoch: 6| Step: 10
Training loss: 0.08721531182527542
Validation loss: 1.5298425234774107

Epoch: 6| Step: 11
Training loss: 0.0991334319114685
Validation loss: 1.489567728452785

Epoch: 6| Step: 12
Training loss: 0.10026542842388153
Validation loss: 1.4987821925070979

Epoch: 6| Step: 13
Training loss: 0.1350221186876297
Validation loss: 1.478529978183008

Epoch: 540| Step: 0
Training loss: 0.1392422467470169
Validation loss: 1.498902432380184

Epoch: 6| Step: 1
Training loss: 0.08558489382266998
Validation loss: 1.492082376633921

Epoch: 6| Step: 2
Training loss: 0.13749822974205017
Validation loss: 1.4894861008531304

Epoch: 6| Step: 3
Training loss: 0.13180463016033173
Validation loss: 1.4820793251837454

Epoch: 6| Step: 4
Training loss: 0.06651626527309418
Validation loss: 1.556091239375453

Epoch: 6| Step: 5
Training loss: 0.06544432044029236
Validation loss: 1.5323292234892487

Epoch: 6| Step: 6
Training loss: 0.3225421607494354
Validation loss: 1.5680677275503836

Epoch: 6| Step: 7
Training loss: 0.08232907950878143
Validation loss: 1.5735965249358967

Epoch: 6| Step: 8
Training loss: 0.11945083737373352
Validation loss: 1.5845732906813264

Epoch: 6| Step: 9
Training loss: 0.08639536798000336
Validation loss: 1.5888465040473527

Epoch: 6| Step: 10
Training loss: 0.08836308121681213
Validation loss: 1.5848794829460882

Epoch: 6| Step: 11
Training loss: 0.1685115545988083
Validation loss: 1.5550314893004715

Epoch: 6| Step: 12
Training loss: 0.1268560290336609
Validation loss: 1.5716972492074455

Epoch: 6| Step: 13
Training loss: 0.09162300080060959
Validation loss: 1.582234186510886

Epoch: 541| Step: 0
Training loss: 0.10257692635059357
Validation loss: 1.5472373577856249

Epoch: 6| Step: 1
Training loss: 0.2525971531867981
Validation loss: 1.5640725910022695

Epoch: 6| Step: 2
Training loss: 0.09436818212270737
Validation loss: 1.5479678953847578

Epoch: 6| Step: 3
Training loss: 0.059810392558574677
Validation loss: 1.5604675444223548

Epoch: 6| Step: 4
Training loss: 0.13911724090576172
Validation loss: 1.5248085696210143

Epoch: 6| Step: 5
Training loss: 0.055277347564697266
Validation loss: 1.5182952316858436

Epoch: 6| Step: 6
Training loss: 0.08757495880126953
Validation loss: 1.5265331678493048

Epoch: 6| Step: 7
Training loss: 0.16886983811855316
Validation loss: 1.5108450305077337

Epoch: 6| Step: 8
Training loss: 0.08073621243238449
Validation loss: 1.52635496406145

Epoch: 6| Step: 9
Training loss: 0.07701331377029419
Validation loss: 1.5514576883726223

Epoch: 6| Step: 10
Training loss: 0.10986869782209396
Validation loss: 1.5444533260919715

Epoch: 6| Step: 11
Training loss: 0.11400021612644196
Validation loss: 1.5829066640587264

Epoch: 6| Step: 12
Training loss: 0.12052156031131744
Validation loss: 1.5687545922494703

Epoch: 6| Step: 13
Training loss: 0.1282237470149994
Validation loss: 1.564204430067411

Epoch: 542| Step: 0
Training loss: 0.10912331938743591
Validation loss: 1.5845931845326577

Epoch: 6| Step: 1
Training loss: 0.17407634854316711
Validation loss: 1.5395820820203392

Epoch: 6| Step: 2
Training loss: 0.19823916256427765
Validation loss: 1.5749118187094246

Epoch: 6| Step: 3
Training loss: 0.1298806518316269
Validation loss: 1.5627983077879875

Epoch: 6| Step: 4
Training loss: 0.05094743147492409
Validation loss: 1.520152109925465

Epoch: 6| Step: 5
Training loss: 0.09327604621648788
Validation loss: 1.5417537855845627

Epoch: 6| Step: 6
Training loss: 0.08195251226425171
Validation loss: 1.512293295193744

Epoch: 6| Step: 7
Training loss: 0.07380592823028564
Validation loss: 1.5224352023934806

Epoch: 6| Step: 8
Training loss: 0.10652437806129456
Validation loss: 1.4819284715960104

Epoch: 6| Step: 9
Training loss: 0.12670540809631348
Validation loss: 1.5017423360578475

Epoch: 6| Step: 10
Training loss: 0.32895156741142273
Validation loss: 1.4684157256157166

Epoch: 6| Step: 11
Training loss: 0.1027991771697998
Validation loss: 1.4912160058175363

Epoch: 6| Step: 12
Training loss: 0.10596354305744171
Validation loss: 1.4952885963583504

Epoch: 6| Step: 13
Training loss: 0.06786065548658371
Validation loss: 1.4558359743446432

Epoch: 543| Step: 0
Training loss: 0.06620843708515167
Validation loss: 1.4657864339890019

Epoch: 6| Step: 1
Training loss: 0.3022690415382385
Validation loss: 1.450109540775258

Epoch: 6| Step: 2
Training loss: 0.09944713115692139
Validation loss: 1.477004207590575

Epoch: 6| Step: 3
Training loss: 0.09617742896080017
Validation loss: 1.4897465193143455

Epoch: 6| Step: 4
Training loss: 0.10385549813508987
Validation loss: 1.4813995733056018

Epoch: 6| Step: 5
Training loss: 0.09379848092794418
Validation loss: 1.5112306046229538

Epoch: 6| Step: 6
Training loss: 0.08385857194662094
Validation loss: 1.4980451330061881

Epoch: 6| Step: 7
Training loss: 0.09229452908039093
Validation loss: 1.5340254556748174

Epoch: 6| Step: 8
Training loss: 0.09528648853302002
Validation loss: 1.5479528557869695

Epoch: 6| Step: 9
Training loss: 0.09694099426269531
Validation loss: 1.5308679829361618

Epoch: 6| Step: 10
Training loss: 0.08263707906007767
Validation loss: 1.5281505020715858

Epoch: 6| Step: 11
Training loss: 0.1474197506904602
Validation loss: 1.5194682331495388

Epoch: 6| Step: 12
Training loss: 0.11874736845493317
Validation loss: 1.5404571012784076

Epoch: 6| Step: 13
Training loss: 0.13420511782169342
Validation loss: 1.5434829932387157

Epoch: 544| Step: 0
Training loss: 0.07061337679624557
Validation loss: 1.5332906412821945

Epoch: 6| Step: 1
Training loss: 0.2661713659763336
Validation loss: 1.495344138914539

Epoch: 6| Step: 2
Training loss: 0.12383714318275452
Validation loss: 1.5168530069371706

Epoch: 6| Step: 3
Training loss: 0.07972829043865204
Validation loss: 1.4953668168796006

Epoch: 6| Step: 4
Training loss: 0.11863996088504791
Validation loss: 1.4613015920885148

Epoch: 6| Step: 5
Training loss: 0.05108707398176193
Validation loss: 1.479926622042092

Epoch: 6| Step: 6
Training loss: 0.09684804081916809
Validation loss: 1.4781236379377303

Epoch: 6| Step: 7
Training loss: 0.12108126282691956
Validation loss: 1.4693382350347375

Epoch: 6| Step: 8
Training loss: 0.09354737401008606
Validation loss: 1.4655357253166936

Epoch: 6| Step: 9
Training loss: 0.16276347637176514
Validation loss: 1.4869905223128617

Epoch: 6| Step: 10
Training loss: 0.11840569227933884
Validation loss: 1.4746989819311327

Epoch: 6| Step: 11
Training loss: 0.10749413818120956
Validation loss: 1.4919946091149443

Epoch: 6| Step: 12
Training loss: 0.10117582976818085
Validation loss: 1.4842576019225582

Epoch: 6| Step: 13
Training loss: 0.06197416037321091
Validation loss: 1.499543643766834

Epoch: 545| Step: 0
Training loss: 0.0716419592499733
Validation loss: 1.4832936153616956

Epoch: 6| Step: 1
Training loss: 0.0963473990559578
Validation loss: 1.5006047794895787

Epoch: 6| Step: 2
Training loss: 0.06914810091257095
Validation loss: 1.5144856988742788

Epoch: 6| Step: 3
Training loss: 0.2771858870983124
Validation loss: 1.4911420960580148

Epoch: 6| Step: 4
Training loss: 0.11214479804039001
Validation loss: 1.482915061776356

Epoch: 6| Step: 5
Training loss: 0.06838174164295197
Validation loss: 1.4861158478644587

Epoch: 6| Step: 6
Training loss: 0.17198561131954193
Validation loss: 1.493569568921161

Epoch: 6| Step: 7
Training loss: 0.07791075855493546
Validation loss: 1.4803834237078184

Epoch: 6| Step: 8
Training loss: 0.12134890258312225
Validation loss: 1.456177879405278

Epoch: 6| Step: 9
Training loss: 0.11924407631158829
Validation loss: 1.4987645661959084

Epoch: 6| Step: 10
Training loss: 0.08421090245246887
Validation loss: 1.4621647788632302

Epoch: 6| Step: 11
Training loss: 0.07934660464525223
Validation loss: 1.4623269175970426

Epoch: 6| Step: 12
Training loss: 0.06303023546934128
Validation loss: 1.4836861433521393

Epoch: 6| Step: 13
Training loss: 0.06865808367729187
Validation loss: 1.4778925167616976

Epoch: 546| Step: 0
Training loss: 0.10023344308137894
Validation loss: 1.4940941756771458

Epoch: 6| Step: 1
Training loss: 0.055583175271749496
Validation loss: 1.489865965740655

Epoch: 6| Step: 2
Training loss: 0.2958308756351471
Validation loss: 1.5140830880852156

Epoch: 6| Step: 3
Training loss: 0.11936702579259872
Validation loss: 1.4733411086502897

Epoch: 6| Step: 4
Training loss: 0.061588745564222336
Validation loss: 1.525086038856096

Epoch: 6| Step: 5
Training loss: 0.09176342189311981
Validation loss: 1.4651591944438156

Epoch: 6| Step: 6
Training loss: 0.16613644361495972
Validation loss: 1.4835490436964138

Epoch: 6| Step: 7
Training loss: 0.09043247997760773
Validation loss: 1.4705552388263006

Epoch: 6| Step: 8
Training loss: 0.09950874000787735
Validation loss: 1.4602856405319706

Epoch: 6| Step: 9
Training loss: 0.16588720679283142
Validation loss: 1.4654349242487261

Epoch: 6| Step: 10
Training loss: 0.11194561421871185
Validation loss: 1.4409277900572746

Epoch: 6| Step: 11
Training loss: 0.08020970970392227
Validation loss: 1.4493058240541847

Epoch: 6| Step: 12
Training loss: 0.10371554642915726
Validation loss: 1.4589408418183685

Epoch: 6| Step: 13
Training loss: 0.16359108686447144
Validation loss: 1.4406773653081668

Epoch: 547| Step: 0
Training loss: 0.15057405829429626
Validation loss: 1.4397286330499957

Epoch: 6| Step: 1
Training loss: 0.06324263662099838
Validation loss: 1.4446905736000306

Epoch: 6| Step: 2
Training loss: 0.08028373122215271
Validation loss: 1.5013852260446037

Epoch: 6| Step: 3
Training loss: 0.07367052137851715
Validation loss: 1.4818476579522575

Epoch: 6| Step: 4
Training loss: 0.0715884417295456
Validation loss: 1.4829556416439753

Epoch: 6| Step: 5
Training loss: 0.0836828202009201
Validation loss: 1.4725114568587272

Epoch: 6| Step: 6
Training loss: 0.061927430331707
Validation loss: 1.5181238510275399

Epoch: 6| Step: 7
Training loss: 0.0975806713104248
Validation loss: 1.5192389936857327

Epoch: 6| Step: 8
Training loss: 0.11309370398521423
Validation loss: 1.5512327237795758

Epoch: 6| Step: 9
Training loss: 0.12355008721351624
Validation loss: 1.525375812284408

Epoch: 6| Step: 10
Training loss: 0.15462154150009155
Validation loss: 1.5479088496136408

Epoch: 6| Step: 11
Training loss: 0.2710646390914917
Validation loss: 1.5270384434730775

Epoch: 6| Step: 12
Training loss: 0.060103341937065125
Validation loss: 1.5255353399502334

Epoch: 6| Step: 13
Training loss: 0.12110849469900131
Validation loss: 1.5212198085682367

Epoch: 548| Step: 0
Training loss: 0.1429552137851715
Validation loss: 1.5238308637372908

Epoch: 6| Step: 1
Training loss: 0.08916820585727692
Validation loss: 1.5094504587111934

Epoch: 6| Step: 2
Training loss: 0.13354071974754333
Validation loss: 1.510093089072935

Epoch: 6| Step: 3
Training loss: 0.06889507174491882
Validation loss: 1.4955174243578346

Epoch: 6| Step: 4
Training loss: 0.3038933277130127
Validation loss: 1.4619764999676776

Epoch: 6| Step: 5
Training loss: 0.11535120010375977
Validation loss: 1.463080717671302

Epoch: 6| Step: 6
Training loss: 0.08950067311525345
Validation loss: 1.4696312168593049

Epoch: 6| Step: 7
Training loss: 0.07755464315414429
Validation loss: 1.4793278055806314

Epoch: 6| Step: 8
Training loss: 0.0623716339468956
Validation loss: 1.4843708622840144

Epoch: 6| Step: 9
Training loss: 0.09937585890293121
Validation loss: 1.4885690936478235

Epoch: 6| Step: 10
Training loss: 0.05431515350937843
Validation loss: 1.4606967613261232

Epoch: 6| Step: 11
Training loss: 0.08723315596580505
Validation loss: 1.474251752258629

Epoch: 6| Step: 12
Training loss: 0.09980884939432144
Validation loss: 1.4814916246680803

Epoch: 6| Step: 13
Training loss: 0.08275679498910904
Validation loss: 1.4933985035906556

Epoch: 549| Step: 0
Training loss: 0.09347951412200928
Validation loss: 1.458238685002891

Epoch: 6| Step: 1
Training loss: 0.09522678703069687
Validation loss: 1.510957226958326

Epoch: 6| Step: 2
Training loss: 0.04950515925884247
Validation loss: 1.5170866276628228

Epoch: 6| Step: 3
Training loss: 0.13849346339702606
Validation loss: 1.5041085385507154

Epoch: 6| Step: 4
Training loss: 0.08759629726409912
Validation loss: 1.5048599217527656

Epoch: 6| Step: 5
Training loss: 0.09165804088115692
Validation loss: 1.4870528546712731

Epoch: 6| Step: 6
Training loss: 0.07792749255895615
Validation loss: 1.4720840229783008

Epoch: 6| Step: 7
Training loss: 0.29189518094062805
Validation loss: 1.478060769778426

Epoch: 6| Step: 8
Training loss: 0.05911347270011902
Validation loss: 1.4710278075228456

Epoch: 6| Step: 9
Training loss: 0.1021459549665451
Validation loss: 1.4863974330245808

Epoch: 6| Step: 10
Training loss: 0.15097977221012115
Validation loss: 1.5080521286174815

Epoch: 6| Step: 11
Training loss: 0.07649793475866318
Validation loss: 1.466903398113866

Epoch: 6| Step: 12
Training loss: 0.1109113022685051
Validation loss: 1.4733060918828493

Epoch: 6| Step: 13
Training loss: 0.24657294154167175
Validation loss: 1.4566170977007957

Epoch: 550| Step: 0
Training loss: 0.07308878004550934
Validation loss: 1.466225435656886

Epoch: 6| Step: 1
Training loss: 0.05195879936218262
Validation loss: 1.4909596135539394

Epoch: 6| Step: 2
Training loss: 0.1335560381412506
Validation loss: 1.4810114188860821

Epoch: 6| Step: 3
Training loss: 0.06782186031341553
Validation loss: 1.4960412325397614

Epoch: 6| Step: 4
Training loss: 0.08497591316699982
Validation loss: 1.4958803986990323

Epoch: 6| Step: 5
Training loss: 0.07089109718799591
Validation loss: 1.5108643859945319

Epoch: 6| Step: 6
Training loss: 0.08829950541257858
Validation loss: 1.5340822114739368

Epoch: 6| Step: 7
Training loss: 0.0875905305147171
Validation loss: 1.5131682183152886

Epoch: 6| Step: 8
Training loss: 0.10194692015647888
Validation loss: 1.5330969620776433

Epoch: 6| Step: 9
Training loss: 0.06683081388473511
Validation loss: 1.5245349253377607

Epoch: 6| Step: 10
Training loss: 0.1296273171901703
Validation loss: 1.5375012428529802

Epoch: 6| Step: 11
Training loss: 0.08508116006851196
Validation loss: 1.541699081338862

Epoch: 6| Step: 12
Training loss: 0.31854724884033203
Validation loss: 1.5487985892962384

Epoch: 6| Step: 13
Training loss: 0.07395109534263611
Validation loss: 1.5512923015061246

Epoch: 551| Step: 0
Training loss: 0.11719229817390442
Validation loss: 1.556582518803176

Epoch: 6| Step: 1
Training loss: 0.0880330353975296
Validation loss: 1.5196860092942432

Epoch: 6| Step: 2
Training loss: 0.10538730025291443
Validation loss: 1.5250660764273776

Epoch: 6| Step: 3
Training loss: 0.09363272786140442
Validation loss: 1.518627493612228

Epoch: 6| Step: 4
Training loss: 0.1352207362651825
Validation loss: 1.5089430732111777

Epoch: 6| Step: 5
Training loss: 0.09599125385284424
Validation loss: 1.492024762656099

Epoch: 6| Step: 6
Training loss: 0.11733244359493256
Validation loss: 1.4905196133480276

Epoch: 6| Step: 7
Training loss: 0.10491801053285599
Validation loss: 1.508493423461914

Epoch: 6| Step: 8
Training loss: 0.08393745869398117
Validation loss: 1.5002650355779996

Epoch: 6| Step: 9
Training loss: 0.0946177989244461
Validation loss: 1.4845977701166624

Epoch: 6| Step: 10
Training loss: 0.04484519734978676
Validation loss: 1.5036157587523102

Epoch: 6| Step: 11
Training loss: 0.07514755427837372
Validation loss: 1.5292742790714386

Epoch: 6| Step: 12
Training loss: 0.2591480612754822
Validation loss: 1.5081218019608529

Epoch: 6| Step: 13
Training loss: 0.24655896425247192
Validation loss: 1.5328702247270973

Epoch: 552| Step: 0
Training loss: 0.06862787902355194
Validation loss: 1.539029804609155

Epoch: 6| Step: 1
Training loss: 0.07665237784385681
Validation loss: 1.559084326990189

Epoch: 6| Step: 2
Training loss: 0.09523656964302063
Validation loss: 1.569629035970216

Epoch: 6| Step: 3
Training loss: 0.10753785073757172
Validation loss: 1.5903979680871452

Epoch: 6| Step: 4
Training loss: 0.08640554547309875
Validation loss: 1.55513600572463

Epoch: 6| Step: 5
Training loss: 0.08891455829143524
Validation loss: 1.5444184605793287

Epoch: 6| Step: 6
Training loss: 0.08223363757133484
Validation loss: 1.5212550547815138

Epoch: 6| Step: 7
Training loss: 0.31297487020492554
Validation loss: 1.5169258092039375

Epoch: 6| Step: 8
Training loss: 0.08207445591688156
Validation loss: 1.497381934555628

Epoch: 6| Step: 9
Training loss: 0.09693406522274017
Validation loss: 1.5139497954358336

Epoch: 6| Step: 10
Training loss: 0.1181630864739418
Validation loss: 1.4955118920213433

Epoch: 6| Step: 11
Training loss: 0.12586630880832672
Validation loss: 1.4733328396274197

Epoch: 6| Step: 12
Training loss: 0.11486901342868805
Validation loss: 1.515834177694013

Epoch: 6| Step: 13
Training loss: 0.04581742733716965
Validation loss: 1.5310394116627273

Epoch: 553| Step: 0
Training loss: 0.11370684951543808
Validation loss: 1.5357137341653146

Epoch: 6| Step: 1
Training loss: 0.06334657222032547
Validation loss: 1.5553400606237433

Epoch: 6| Step: 2
Training loss: 0.29624009132385254
Validation loss: 1.551978127930754

Epoch: 6| Step: 3
Training loss: 0.08320069313049316
Validation loss: 1.5739905321469871

Epoch: 6| Step: 4
Training loss: 0.12388771027326584
Validation loss: 1.5856308872981737

Epoch: 6| Step: 5
Training loss: 0.08904433250427246
Validation loss: 1.5783412725694719

Epoch: 6| Step: 6
Training loss: 0.08814245462417603
Validation loss: 1.5603513358741679

Epoch: 6| Step: 7
Training loss: 0.10964131355285645
Validation loss: 1.5427409333567466

Epoch: 6| Step: 8
Training loss: 0.06499460339546204
Validation loss: 1.5457639796759493

Epoch: 6| Step: 9
Training loss: 0.09394717216491699
Validation loss: 1.5318963643043273

Epoch: 6| Step: 10
Training loss: 0.04684726893901825
Validation loss: 1.5144853335554882

Epoch: 6| Step: 11
Training loss: 0.059031374752521515
Validation loss: 1.5294100828068231

Epoch: 6| Step: 12
Training loss: 0.05988861992955208
Validation loss: 1.5196610125162269

Epoch: 6| Step: 13
Training loss: 0.19940587878227234
Validation loss: 1.502392929087403

Epoch: 554| Step: 0
Training loss: 0.0758962482213974
Validation loss: 1.5474015589683288

Epoch: 6| Step: 1
Training loss: 0.07007671892642975
Validation loss: 1.516524976299655

Epoch: 6| Step: 2
Training loss: 0.05815703421831131
Validation loss: 1.5516333605653496

Epoch: 6| Step: 3
Training loss: 0.16643965244293213
Validation loss: 1.5341754421111076

Epoch: 6| Step: 4
Training loss: 0.05013378709554672
Validation loss: 1.518381246956446

Epoch: 6| Step: 5
Training loss: 0.2650187313556671
Validation loss: 1.4998420169276576

Epoch: 6| Step: 6
Training loss: 0.10005354881286621
Validation loss: 1.5161057274828675

Epoch: 6| Step: 7
Training loss: 0.045376256108284
Validation loss: 1.5124757751341789

Epoch: 6| Step: 8
Training loss: 0.06345878541469574
Validation loss: 1.5027946400386032

Epoch: 6| Step: 9
Training loss: 0.07368723303079605
Validation loss: 1.4700147515983992

Epoch: 6| Step: 10
Training loss: 0.0747634544968605
Validation loss: 1.4937812013010825

Epoch: 6| Step: 11
Training loss: 0.13770902156829834
Validation loss: 1.491187225105942

Epoch: 6| Step: 12
Training loss: 0.08004483580589294
Validation loss: 1.4764987358482935

Epoch: 6| Step: 13
Training loss: 0.07289311289787292
Validation loss: 1.4881807027324554

Epoch: 555| Step: 0
Training loss: 0.06775173544883728
Validation loss: 1.4854331529268654

Epoch: 6| Step: 1
Training loss: 0.3114036023616791
Validation loss: 1.4929324606413483

Epoch: 6| Step: 2
Training loss: 0.0655893012881279
Validation loss: 1.5222134987513225

Epoch: 6| Step: 3
Training loss: 0.09794634580612183
Validation loss: 1.5350731136978313

Epoch: 6| Step: 4
Training loss: 0.14277882874011993
Validation loss: 1.5349211705628263

Epoch: 6| Step: 5
Training loss: 0.08624060451984406
Validation loss: 1.4790375283969346

Epoch: 6| Step: 6
Training loss: 0.18167614936828613
Validation loss: 1.515278018930907

Epoch: 6| Step: 7
Training loss: 0.05825322866439819
Validation loss: 1.5011624495188396

Epoch: 6| Step: 8
Training loss: 0.1086435467004776
Validation loss: 1.5125230435402162

Epoch: 6| Step: 9
Training loss: 0.10449542850255966
Validation loss: 1.493924589567287

Epoch: 6| Step: 10
Training loss: 0.0967675969004631
Validation loss: 1.5133242299479823

Epoch: 6| Step: 11
Training loss: 0.08279895782470703
Validation loss: 1.5322172372571883

Epoch: 6| Step: 12
Training loss: 0.094121053814888
Validation loss: 1.4978469994760328

Epoch: 6| Step: 13
Training loss: 0.07614850997924805
Validation loss: 1.5339680192291096

Epoch: 556| Step: 0
Training loss: 0.09322415292263031
Validation loss: 1.5150613233607302

Epoch: 6| Step: 1
Training loss: 0.0746312364935875
Validation loss: 1.5174637725276332

Epoch: 6| Step: 2
Training loss: 0.07338876277208328
Validation loss: 1.5251425197047572

Epoch: 6| Step: 3
Training loss: 0.09028750658035278
Validation loss: 1.5081337773671715

Epoch: 6| Step: 4
Training loss: 0.09587669372558594
Validation loss: 1.4777451727979927

Epoch: 6| Step: 5
Training loss: 0.28599560260772705
Validation loss: 1.4467243814981112

Epoch: 6| Step: 6
Training loss: 0.12114808708429337
Validation loss: 1.499524615144217

Epoch: 6| Step: 7
Training loss: 0.07246141135692596
Validation loss: 1.4973857274619482

Epoch: 6| Step: 8
Training loss: 0.06860003620386124
Validation loss: 1.5128256915717997

Epoch: 6| Step: 9
Training loss: 0.06359057128429413
Validation loss: 1.5061252424793858

Epoch: 6| Step: 10
Training loss: 0.11060186475515366
Validation loss: 1.5186690835542576

Epoch: 6| Step: 11
Training loss: 0.07160604000091553
Validation loss: 1.4797670104170357

Epoch: 6| Step: 12
Training loss: 0.07720877230167389
Validation loss: 1.4871906183099235

Epoch: 6| Step: 13
Training loss: 0.09141416102647781
Validation loss: 1.509942622594936

Epoch: 557| Step: 0
Training loss: 0.06779751926660538
Validation loss: 1.4818654368000646

Epoch: 6| Step: 1
Training loss: 0.07318269461393356
Validation loss: 1.5110958814620972

Epoch: 6| Step: 2
Training loss: 0.1519603133201599
Validation loss: 1.5018725920748968

Epoch: 6| Step: 3
Training loss: 0.09141980111598969
Validation loss: 1.4894764474643174

Epoch: 6| Step: 4
Training loss: 0.3088798522949219
Validation loss: 1.4513398062798284

Epoch: 6| Step: 5
Training loss: 0.09075462818145752
Validation loss: 1.4652710999211958

Epoch: 6| Step: 6
Training loss: 0.07135411351919174
Validation loss: 1.4812159153722948

Epoch: 6| Step: 7
Training loss: 0.07498453557491302
Validation loss: 1.4847999939354517

Epoch: 6| Step: 8
Training loss: 0.06085088476538658
Validation loss: 1.4666864346432429

Epoch: 6| Step: 9
Training loss: 0.09864340722560883
Validation loss: 1.4867439487928986

Epoch: 6| Step: 10
Training loss: 0.13715341687202454
Validation loss: 1.4598618925258677

Epoch: 6| Step: 11
Training loss: 0.07414992153644562
Validation loss: 1.477348509655204

Epoch: 6| Step: 12
Training loss: 0.057227157056331635
Validation loss: 1.495461836937935

Epoch: 6| Step: 13
Training loss: 0.038959961384534836
Validation loss: 1.4826630456473238

Epoch: 558| Step: 0
Training loss: 0.11772697418928146
Validation loss: 1.4866885651824295

Epoch: 6| Step: 1
Training loss: 0.06909569352865219
Validation loss: 1.4885395675577142

Epoch: 6| Step: 2
Training loss: 0.09460484981536865
Validation loss: 1.4628128261976345

Epoch: 6| Step: 3
Training loss: 0.21604543924331665
Validation loss: 1.4988191832778275

Epoch: 6| Step: 4
Training loss: 0.07214757055044174
Validation loss: 1.488471290116669

Epoch: 6| Step: 5
Training loss: 0.09150271117687225
Validation loss: 1.4824213763718963

Epoch: 6| Step: 6
Training loss: 0.0577029213309288
Validation loss: 1.469440092322647

Epoch: 6| Step: 7
Training loss: 0.12121635675430298
Validation loss: 1.4814751994225286

Epoch: 6| Step: 8
Training loss: 0.0949755311012268
Validation loss: 1.4575234702838364

Epoch: 6| Step: 9
Training loss: 0.05558287724852562
Validation loss: 1.4569683254406016

Epoch: 6| Step: 10
Training loss: 0.08325006067752838
Validation loss: 1.5006345497664584

Epoch: 6| Step: 11
Training loss: 0.3243368864059448
Validation loss: 1.4569831304652716

Epoch: 6| Step: 12
Training loss: 0.061336271464824677
Validation loss: 1.4775154359879032

Epoch: 6| Step: 13
Training loss: 0.11733788996934891
Validation loss: 1.4724897620498494

Epoch: 559| Step: 0
Training loss: 0.0842694565653801
Validation loss: 1.4925466609257523

Epoch: 6| Step: 1
Training loss: 0.08456844091415405
Validation loss: 1.501972089531601

Epoch: 6| Step: 2
Training loss: 0.26959097385406494
Validation loss: 1.4841195934562272

Epoch: 6| Step: 3
Training loss: 0.09829771518707275
Validation loss: 1.4997451164389168

Epoch: 6| Step: 4
Training loss: 0.0948171317577362
Validation loss: 1.5295221869663527

Epoch: 6| Step: 5
Training loss: 0.060387298464775085
Validation loss: 1.5226999572528306

Epoch: 6| Step: 6
Training loss: 0.05415079742670059
Validation loss: 1.5337551960381128

Epoch: 6| Step: 7
Training loss: 0.0869445651769638
Validation loss: 1.5315942392554334

Epoch: 6| Step: 8
Training loss: 0.1214178279042244
Validation loss: 1.5395438248111355

Epoch: 6| Step: 9
Training loss: 0.08280262351036072
Validation loss: 1.554342536516087

Epoch: 6| Step: 10
Training loss: 0.06272518634796143
Validation loss: 1.5021279499094973

Epoch: 6| Step: 11
Training loss: 0.10221706330776215
Validation loss: 1.5286853723628546

Epoch: 6| Step: 12
Training loss: 0.035014621913433075
Validation loss: 1.5420675252073555

Epoch: 6| Step: 13
Training loss: 0.244211807847023
Validation loss: 1.5336172760173838

Epoch: 560| Step: 0
Training loss: 0.13077983260154724
Validation loss: 1.5237524188974851

Epoch: 6| Step: 1
Training loss: 0.08565357327461243
Validation loss: 1.5442311866309053

Epoch: 6| Step: 2
Training loss: 0.044845469295978546
Validation loss: 1.529801603286497

Epoch: 6| Step: 3
Training loss: 0.0416165292263031
Validation loss: 1.5595608116478048

Epoch: 6| Step: 4
Training loss: 0.08013966679573059
Validation loss: 1.5439058080796273

Epoch: 6| Step: 5
Training loss: 0.10640346258878708
Validation loss: 1.5393994649251301

Epoch: 6| Step: 6
Training loss: 0.07922070473432541
Validation loss: 1.539963783756379

Epoch: 6| Step: 7
Training loss: 0.07117237895727158
Validation loss: 1.5199735369733585

Epoch: 6| Step: 8
Training loss: 0.0958743542432785
Validation loss: 1.4748641149972075

Epoch: 6| Step: 9
Training loss: 0.1325405389070511
Validation loss: 1.505851298250178

Epoch: 6| Step: 10
Training loss: 0.057185541838407516
Validation loss: 1.509523235341554

Epoch: 6| Step: 11
Training loss: 0.2561723589897156
Validation loss: 1.4709856843435636

Epoch: 6| Step: 12
Training loss: 0.14211800694465637
Validation loss: 1.5238805650382914

Epoch: 6| Step: 13
Training loss: 0.15416273474693298
Validation loss: 1.4909523661418627

Epoch: 561| Step: 0
Training loss: 0.06696034967899323
Validation loss: 1.5050654488225137

Epoch: 6| Step: 1
Training loss: 0.20659324526786804
Validation loss: 1.5307074080231369

Epoch: 6| Step: 2
Training loss: 0.08207505941390991
Validation loss: 1.5469032154288342

Epoch: 6| Step: 3
Training loss: 0.10942993313074112
Validation loss: 1.564329647248791

Epoch: 6| Step: 4
Training loss: 0.12565812468528748
Validation loss: 1.595404166047291

Epoch: 6| Step: 5
Training loss: 0.1142851859331131
Validation loss: 1.5754358653099305

Epoch: 6| Step: 6
Training loss: 0.09477060288190842
Validation loss: 1.588079898588119

Epoch: 6| Step: 7
Training loss: 0.15141117572784424
Validation loss: 1.5459038031998502

Epoch: 6| Step: 8
Training loss: 0.13345488905906677
Validation loss: 1.5763721683973908

Epoch: 6| Step: 9
Training loss: 0.12308496236801147
Validation loss: 1.5638122789321407

Epoch: 6| Step: 10
Training loss: 0.10022549331188202
Validation loss: 1.515388378532984

Epoch: 6| Step: 11
Training loss: 0.071277916431427
Validation loss: 1.5084292850186747

Epoch: 6| Step: 12
Training loss: 0.13485650718212128
Validation loss: 1.4645352632768693

Epoch: 6| Step: 13
Training loss: 0.12103213369846344
Validation loss: 1.4737124545599825

Epoch: 562| Step: 0
Training loss: 0.09053992480039597
Validation loss: 1.447823670602614

Epoch: 6| Step: 1
Training loss: 0.15921753644943237
Validation loss: 1.450917342657684

Epoch: 6| Step: 2
Training loss: 0.07390551269054413
Validation loss: 1.46535736514676

Epoch: 6| Step: 3
Training loss: 0.06379044055938721
Validation loss: 1.4594895762781943

Epoch: 6| Step: 4
Training loss: 0.25453734397888184
Validation loss: 1.4770764035563315

Epoch: 6| Step: 5
Training loss: 0.058626119047403336
Validation loss: 1.486162415114782

Epoch: 6| Step: 6
Training loss: 0.08460244536399841
Validation loss: 1.4967691090799147

Epoch: 6| Step: 7
Training loss: 0.09142955392599106
Validation loss: 1.50646726546749

Epoch: 6| Step: 8
Training loss: 0.10680484771728516
Validation loss: 1.5243321285452893

Epoch: 6| Step: 9
Training loss: 0.1204184889793396
Validation loss: 1.4895699742019817

Epoch: 6| Step: 10
Training loss: 0.07819677889347076
Validation loss: 1.4915882425923501

Epoch: 6| Step: 11
Training loss: 0.038847096264362335
Validation loss: 1.486571438850895

Epoch: 6| Step: 12
Training loss: 0.05705936253070831
Validation loss: 1.4862323755859046

Epoch: 6| Step: 13
Training loss: 0.061602115631103516
Validation loss: 1.4957149022368974

Epoch: 563| Step: 0
Training loss: 0.06508581340312958
Validation loss: 1.4937990878217964

Epoch: 6| Step: 1
Training loss: 0.16655176877975464
Validation loss: 1.470123597370681

Epoch: 6| Step: 2
Training loss: 0.04498272389173508
Validation loss: 1.5043558151491228

Epoch: 6| Step: 3
Training loss: 0.10646728426218033
Validation loss: 1.4901166885129866

Epoch: 6| Step: 4
Training loss: 0.08917728811502457
Validation loss: 1.5112667840014222

Epoch: 6| Step: 5
Training loss: 0.11622798442840576
Validation loss: 1.4836594750804286

Epoch: 6| Step: 6
Training loss: 0.09097369015216827
Validation loss: 1.5068514987986574

Epoch: 6| Step: 7
Training loss: 0.25303909182548523
Validation loss: 1.5010441118671047

Epoch: 6| Step: 8
Training loss: 0.05842706561088562
Validation loss: 1.5066780198004939

Epoch: 6| Step: 9
Training loss: 0.060516275465488434
Validation loss: 1.5020208454901172

Epoch: 6| Step: 10
Training loss: 0.046950776129961014
Validation loss: 1.4984657200433875

Epoch: 6| Step: 11
Training loss: 0.1198769062757492
Validation loss: 1.4711638868495982

Epoch: 6| Step: 12
Training loss: 0.11966025829315186
Validation loss: 1.496605941044387

Epoch: 6| Step: 13
Training loss: 0.060194797813892365
Validation loss: 1.4817090701031428

Epoch: 564| Step: 0
Training loss: 0.11060456186532974
Validation loss: 1.4639776227294758

Epoch: 6| Step: 1
Training loss: 0.07000651210546494
Validation loss: 1.4888046608176282

Epoch: 6| Step: 2
Training loss: 0.06118858605623245
Validation loss: 1.4789757113302908

Epoch: 6| Step: 3
Training loss: 0.04877963662147522
Validation loss: 1.4500618237321095

Epoch: 6| Step: 4
Training loss: 0.055023301392793655
Validation loss: 1.4639314502798102

Epoch: 6| Step: 5
Training loss: 0.10382815450429916
Validation loss: 1.4634126078697942

Epoch: 6| Step: 6
Training loss: 0.10391758382320404
Validation loss: 1.4891634827019067

Epoch: 6| Step: 7
Training loss: 0.08351017534732819
Validation loss: 1.4678045485609321

Epoch: 6| Step: 8
Training loss: 0.07368271052837372
Validation loss: 1.4734843059252667

Epoch: 6| Step: 9
Training loss: 0.07923582196235657
Validation loss: 1.488140973993527

Epoch: 6| Step: 10
Training loss: 0.08065350353717804
Validation loss: 1.5027725158199188

Epoch: 6| Step: 11
Training loss: 0.06718775629997253
Validation loss: 1.5024346433660036

Epoch: 6| Step: 12
Training loss: 0.29126378893852234
Validation loss: 1.5152855483434533

Epoch: 6| Step: 13
Training loss: 0.11353867501020432
Validation loss: 1.5128388225391347

Epoch: 565| Step: 0
Training loss: 0.07007654011249542
Validation loss: 1.5055616158311085

Epoch: 6| Step: 1
Training loss: 0.07731446623802185
Validation loss: 1.4913638163638372

Epoch: 6| Step: 2
Training loss: 0.060255128890275955
Validation loss: 1.4812760955543929

Epoch: 6| Step: 3
Training loss: 0.06640399247407913
Validation loss: 1.4775332584176013

Epoch: 6| Step: 4
Training loss: 0.1153712347149849
Validation loss: 1.4795957124361427

Epoch: 6| Step: 5
Training loss: 0.1765282154083252
Validation loss: 1.5019358345257339

Epoch: 6| Step: 6
Training loss: 0.04731745272874832
Validation loss: 1.4840155352828324

Epoch: 6| Step: 7
Training loss: 0.29377612471580505
Validation loss: 1.4882670358944965

Epoch: 6| Step: 8
Training loss: 0.05347789451479912
Validation loss: 1.4918177871293918

Epoch: 6| Step: 9
Training loss: 0.05016537010669708
Validation loss: 1.5041086289190477

Epoch: 6| Step: 10
Training loss: 0.062481991946697235
Validation loss: 1.5069741587485037

Epoch: 6| Step: 11
Training loss: 0.06082278490066528
Validation loss: 1.5034257186356412

Epoch: 6| Step: 12
Training loss: 0.09795019775629044
Validation loss: 1.5303285455191007

Epoch: 6| Step: 13
Training loss: 0.07077356427907944
Validation loss: 1.5401295679871754

Epoch: 566| Step: 0
Training loss: 0.07168581336736679
Validation loss: 1.5421682019387521

Epoch: 6| Step: 1
Training loss: 0.08784051239490509
Validation loss: 1.5683131897321312

Epoch: 6| Step: 2
Training loss: 0.30728060007095337
Validation loss: 1.562216781800793

Epoch: 6| Step: 3
Training loss: 0.0865691602230072
Validation loss: 1.5715520471654914

Epoch: 6| Step: 4
Training loss: 0.1428852528333664
Validation loss: 1.5795059742466095

Epoch: 6| Step: 5
Training loss: 0.11129019409418106
Validation loss: 1.5691913135590092

Epoch: 6| Step: 6
Training loss: 0.15882472693920135
Validation loss: 1.5759636253438971

Epoch: 6| Step: 7
Training loss: 0.11067939549684525
Validation loss: 1.544067326412406

Epoch: 6| Step: 8
Training loss: 0.08554621040821075
Validation loss: 1.5243594031180105

Epoch: 6| Step: 9
Training loss: 0.12442027032375336
Validation loss: 1.4928124463686379

Epoch: 6| Step: 10
Training loss: 0.06353352963924408
Validation loss: 1.5142868590611283

Epoch: 6| Step: 11
Training loss: 0.08282122761011124
Validation loss: 1.461628274251056

Epoch: 6| Step: 12
Training loss: 0.07419008016586304
Validation loss: 1.4751719659374607

Epoch: 6| Step: 13
Training loss: 0.05318747088313103
Validation loss: 1.480386842963516

Epoch: 567| Step: 0
Training loss: 0.10556681454181671
Validation loss: 1.453547481567629

Epoch: 6| Step: 1
Training loss: 0.08276631683111191
Validation loss: 1.4233461797878306

Epoch: 6| Step: 2
Training loss: 0.3465367555618286
Validation loss: 1.4637696704556864

Epoch: 6| Step: 3
Training loss: 0.08471881598234177
Validation loss: 1.4457341612026255

Epoch: 6| Step: 4
Training loss: 0.06825673580169678
Validation loss: 1.4831645040101902

Epoch: 6| Step: 5
Training loss: 0.08466783910989761
Validation loss: 1.4937004530301659

Epoch: 6| Step: 6
Training loss: 0.06537647545337677
Validation loss: 1.5046820768745996

Epoch: 6| Step: 7
Training loss: 0.10686849057674408
Validation loss: 1.5164604212648125

Epoch: 6| Step: 8
Training loss: 0.10340681672096252
Validation loss: 1.508794451272616

Epoch: 6| Step: 9
Training loss: 0.06362947076559067
Validation loss: 1.4992716735409153

Epoch: 6| Step: 10
Training loss: 0.08875042200088501
Validation loss: 1.4810790400351248

Epoch: 6| Step: 11
Training loss: 0.09364484250545502
Validation loss: 1.4824017632392146

Epoch: 6| Step: 12
Training loss: 0.11978871375322342
Validation loss: 1.4938371937762025

Epoch: 6| Step: 13
Training loss: 0.12475155293941498
Validation loss: 1.468802712296927

Epoch: 568| Step: 0
Training loss: 0.14384831488132477
Validation loss: 1.488025261509803

Epoch: 6| Step: 1
Training loss: 0.07381545752286911
Validation loss: 1.4823990227073751

Epoch: 6| Step: 2
Training loss: 0.10079292953014374
Validation loss: 1.4867175471398137

Epoch: 6| Step: 3
Training loss: 0.0502607598900795
Validation loss: 1.4790968151502712

Epoch: 6| Step: 4
Training loss: 0.07018519937992096
Validation loss: 1.5208980069365552

Epoch: 6| Step: 5
Training loss: 0.11244192719459534
Validation loss: 1.5066630430119012

Epoch: 6| Step: 6
Training loss: 0.1039324402809143
Validation loss: 1.5092788178433654

Epoch: 6| Step: 7
Training loss: 0.3455691635608673
Validation loss: 1.5275984323152931

Epoch: 6| Step: 8
Training loss: 0.09973528981208801
Validation loss: 1.5190169195975027

Epoch: 6| Step: 9
Training loss: 0.07352247834205627
Validation loss: 1.492280952392086

Epoch: 6| Step: 10
Training loss: 0.11138410121202469
Validation loss: 1.5222489346740067

Epoch: 6| Step: 11
Training loss: 0.07553958892822266
Validation loss: 1.5231894344411872

Epoch: 6| Step: 12
Training loss: 0.14263871312141418
Validation loss: 1.5348291730368009

Epoch: 6| Step: 13
Training loss: 0.17454682290554047
Validation loss: 1.5416823766564811

Epoch: 569| Step: 0
Training loss: 0.08122210204601288
Validation loss: 1.5190443774705291

Epoch: 6| Step: 1
Training loss: 0.11596430838108063
Validation loss: 1.4970025170233943

Epoch: 6| Step: 2
Training loss: 0.12474407255649567
Validation loss: 1.4764814069194179

Epoch: 6| Step: 3
Training loss: 0.07232943177223206
Validation loss: 1.4617630256119596

Epoch: 6| Step: 4
Training loss: 0.09105146676301956
Validation loss: 1.452691884451015

Epoch: 6| Step: 5
Training loss: 0.11489175260066986
Validation loss: 1.4899271444607807

Epoch: 6| Step: 6
Training loss: 0.08242344856262207
Validation loss: 1.4746344615054388

Epoch: 6| Step: 7
Training loss: 0.15868476033210754
Validation loss: 1.4992874963309175

Epoch: 6| Step: 8
Training loss: 0.07097847759723663
Validation loss: 1.5357000020242506

Epoch: 6| Step: 9
Training loss: 0.2817787528038025
Validation loss: 1.523371414471698

Epoch: 6| Step: 10
Training loss: 0.07832273095846176
Validation loss: 1.5073788794138099

Epoch: 6| Step: 11
Training loss: 0.1266781985759735
Validation loss: 1.4840332333759596

Epoch: 6| Step: 12
Training loss: 0.14902493357658386
Validation loss: 1.464218403703423

Epoch: 6| Step: 13
Training loss: 0.06856584548950195
Validation loss: 1.4541623989741008

Epoch: 570| Step: 0
Training loss: 0.06766735017299652
Validation loss: 1.4669711230903544

Epoch: 6| Step: 1
Training loss: 0.11074248701334
Validation loss: 1.4530350021136704

Epoch: 6| Step: 2
Training loss: 0.0960192158818245
Validation loss: 1.4475058304366244

Epoch: 6| Step: 3
Training loss: 0.07020290195941925
Validation loss: 1.4756370500851703

Epoch: 6| Step: 4
Training loss: 0.261846661567688
Validation loss: 1.461833010437668

Epoch: 6| Step: 5
Training loss: 0.11944673210382462
Validation loss: 1.4569657297544583

Epoch: 6| Step: 6
Training loss: 0.04553265497088432
Validation loss: 1.4435138522937734

Epoch: 6| Step: 7
Training loss: 0.05524792522192001
Validation loss: 1.4667922014831214

Epoch: 6| Step: 8
Training loss: 0.08391374349594116
Validation loss: 1.473734022468649

Epoch: 6| Step: 9
Training loss: 0.09100937843322754
Validation loss: 1.4799264791191264

Epoch: 6| Step: 10
Training loss: 0.08219761401414871
Validation loss: 1.4575182423796704

Epoch: 6| Step: 11
Training loss: 0.06214210391044617
Validation loss: 1.474594235420227

Epoch: 6| Step: 12
Training loss: 0.07279390096664429
Validation loss: 1.4693173016271284

Epoch: 6| Step: 13
Training loss: 0.15646512806415558
Validation loss: 1.4816195362357683

Epoch: 571| Step: 0
Training loss: 0.08225663006305695
Validation loss: 1.5011501991620628

Epoch: 6| Step: 1
Training loss: 0.18298058211803436
Validation loss: 1.5034953073788715

Epoch: 6| Step: 2
Training loss: 0.04871276766061783
Validation loss: 1.4995140939630487

Epoch: 6| Step: 3
Training loss: 0.10112985968589783
Validation loss: 1.4990309258942962

Epoch: 6| Step: 4
Training loss: 0.08432168513536453
Validation loss: 1.4752506171503375

Epoch: 6| Step: 5
Training loss: 0.084877148270607
Validation loss: 1.5071701670205722

Epoch: 6| Step: 6
Training loss: 0.052385006099939346
Validation loss: 1.519961009743393

Epoch: 6| Step: 7
Training loss: 0.07712069153785706
Validation loss: 1.5305630545462332

Epoch: 6| Step: 8
Training loss: 0.07560686767101288
Validation loss: 1.5153430072210168

Epoch: 6| Step: 9
Training loss: 0.08949239552021027
Validation loss: 1.5351446700352493

Epoch: 6| Step: 10
Training loss: 0.0823691189289093
Validation loss: 1.5138080619996594

Epoch: 6| Step: 11
Training loss: 0.20558536052703857
Validation loss: 1.5232726322707308

Epoch: 6| Step: 12
Training loss: 0.06585793197154999
Validation loss: 1.4945967812691965

Epoch: 6| Step: 13
Training loss: 0.13069407641887665
Validation loss: 1.517621365926599

Epoch: 572| Step: 0
Training loss: 0.06383432447910309
Validation loss: 1.5127186365025018

Epoch: 6| Step: 1
Training loss: 0.04239644110202789
Validation loss: 1.5121464421672206

Epoch: 6| Step: 2
Training loss: 0.07766510546207428
Validation loss: 1.4783412794913016

Epoch: 6| Step: 3
Training loss: 0.08885800093412399
Validation loss: 1.5059593980030348

Epoch: 6| Step: 4
Training loss: 0.07761572301387787
Validation loss: 1.5158297425957137

Epoch: 6| Step: 5
Training loss: 0.26437854766845703
Validation loss: 1.510137184973686

Epoch: 6| Step: 6
Training loss: 0.05725772678852081
Validation loss: 1.5295008805490309

Epoch: 6| Step: 7
Training loss: 0.07242816686630249
Validation loss: 1.5080926520850069

Epoch: 6| Step: 8
Training loss: 0.050355732440948486
Validation loss: 1.5477168201118388

Epoch: 6| Step: 9
Training loss: 0.1031716912984848
Validation loss: 1.530979448749173

Epoch: 6| Step: 10
Training loss: 0.07283852994441986
Validation loss: 1.5347748289826095

Epoch: 6| Step: 11
Training loss: 0.13051873445510864
Validation loss: 1.5243056794648528

Epoch: 6| Step: 12
Training loss: 0.06258988380432129
Validation loss: 1.5330879431898876

Epoch: 6| Step: 13
Training loss: 0.11697426438331604
Validation loss: 1.4909556194018292

Epoch: 573| Step: 0
Training loss: 0.07501223683357239
Validation loss: 1.508400563270815

Epoch: 6| Step: 1
Training loss: 0.04750595614314079
Validation loss: 1.488637101265692

Epoch: 6| Step: 2
Training loss: 0.07075010240077972
Validation loss: 1.474112956754623

Epoch: 6| Step: 3
Training loss: 0.09599484503269196
Validation loss: 1.467791256084237

Epoch: 6| Step: 4
Training loss: 0.060307882726192474
Validation loss: 1.4950914286798047

Epoch: 6| Step: 5
Training loss: 0.1505061388015747
Validation loss: 1.4740383477621182

Epoch: 6| Step: 6
Training loss: 0.09200897067785263
Validation loss: 1.4639042833799958

Epoch: 6| Step: 7
Training loss: 0.07613104581832886
Validation loss: 1.4967752092628068

Epoch: 6| Step: 8
Training loss: 0.11198338866233826
Validation loss: 1.4789471728827364

Epoch: 6| Step: 9
Training loss: 0.03725346922874451
Validation loss: 1.503040834139752

Epoch: 6| Step: 10
Training loss: 0.07958758622407913
Validation loss: 1.5076265091537147

Epoch: 6| Step: 11
Training loss: 0.06738179177045822
Validation loss: 1.5065147594739032

Epoch: 6| Step: 12
Training loss: 0.05521586537361145
Validation loss: 1.5192744552448232

Epoch: 6| Step: 13
Training loss: 0.3158550560474396
Validation loss: 1.5217303947735858

Epoch: 574| Step: 0
Training loss: 0.08051109313964844
Validation loss: 1.5089406890253867

Epoch: 6| Step: 1
Training loss: 0.11098682880401611
Validation loss: 1.5029952154364636

Epoch: 6| Step: 2
Training loss: 0.09240944683551788
Validation loss: 1.5073964249703191

Epoch: 6| Step: 3
Training loss: 0.06572439521551132
Validation loss: 1.4828935797496507

Epoch: 6| Step: 4
Training loss: 0.063807412981987
Validation loss: 1.4573052493474816

Epoch: 6| Step: 5
Training loss: 0.09802291542291641
Validation loss: 1.454937110665024

Epoch: 6| Step: 6
Training loss: 0.1689087301492691
Validation loss: 1.474789160554127

Epoch: 6| Step: 7
Training loss: 0.24323852360248566
Validation loss: 1.5077450031875281

Epoch: 6| Step: 8
Training loss: 0.10405907779932022
Validation loss: 1.5093691772030247

Epoch: 6| Step: 9
Training loss: 0.05348515883088112
Validation loss: 1.502812752159693

Epoch: 6| Step: 10
Training loss: 0.05640855431556702
Validation loss: 1.539414655777716

Epoch: 6| Step: 11
Training loss: 0.10240039974451065
Validation loss: 1.5638912723910423

Epoch: 6| Step: 12
Training loss: 0.12585408985614777
Validation loss: 1.5488303566491732

Epoch: 6| Step: 13
Training loss: 0.04650076478719711
Validation loss: 1.5661808085697952

Epoch: 575| Step: 0
Training loss: 0.07618561387062073
Validation loss: 1.5560073839720858

Epoch: 6| Step: 1
Training loss: 0.10527004301548004
Validation loss: 1.5388469939590783

Epoch: 6| Step: 2
Training loss: 0.07877181470394135
Validation loss: 1.551889641310579

Epoch: 6| Step: 3
Training loss: 0.25822195410728455
Validation loss: 1.5361653425360238

Epoch: 6| Step: 4
Training loss: 0.0714711844921112
Validation loss: 1.5170577597874466

Epoch: 6| Step: 5
Training loss: 0.08923507481813431
Validation loss: 1.502888092430689

Epoch: 6| Step: 6
Training loss: 0.0658750981092453
Validation loss: 1.4998139219899331

Epoch: 6| Step: 7
Training loss: 0.10220526158809662
Validation loss: 1.482137414075995

Epoch: 6| Step: 8
Training loss: 0.13133825361728668
Validation loss: 1.519319644538305

Epoch: 6| Step: 9
Training loss: 0.09852287173271179
Validation loss: 1.5106360931550302

Epoch: 6| Step: 10
Training loss: 0.08744701743125916
Validation loss: 1.510243119732026

Epoch: 6| Step: 11
Training loss: 0.07309973984956741
Validation loss: 1.4898334459591938

Epoch: 6| Step: 12
Training loss: 0.13704948127269745
Validation loss: 1.5077742235634917

Epoch: 6| Step: 13
Training loss: 0.08549518138170242
Validation loss: 1.4881409893753708

Epoch: 576| Step: 0
Training loss: 0.12999260425567627
Validation loss: 1.4973427377721316

Epoch: 6| Step: 1
Training loss: 0.21090340614318848
Validation loss: 1.4952897487148162

Epoch: 6| Step: 2
Training loss: 0.07868386805057526
Validation loss: 1.4917124509811401

Epoch: 6| Step: 3
Training loss: 0.09862138330936432
Validation loss: 1.4883396381972938

Epoch: 6| Step: 4
Training loss: 0.12380359321832657
Validation loss: 1.4912094762248378

Epoch: 6| Step: 5
Training loss: 0.10606277734041214
Validation loss: 1.4924187429489628

Epoch: 6| Step: 6
Training loss: 0.10529588907957077
Validation loss: 1.46281167896845

Epoch: 6| Step: 7
Training loss: 0.08381091058254242
Validation loss: 1.456190792463159

Epoch: 6| Step: 8
Training loss: 0.07488802075386047
Validation loss: 1.4499586923148042

Epoch: 6| Step: 9
Training loss: 0.05554556846618652
Validation loss: 1.4488250658076296

Epoch: 6| Step: 10
Training loss: 0.10759270936250687
Validation loss: 1.4548417816879928

Epoch: 6| Step: 11
Training loss: 0.0835857167840004
Validation loss: 1.4541871739972023

Epoch: 6| Step: 12
Training loss: 0.08566052466630936
Validation loss: 1.48146023801578

Epoch: 6| Step: 13
Training loss: 0.09771344810724258
Validation loss: 1.4910624706616966

Epoch: 577| Step: 0
Training loss: 0.09202346205711365
Validation loss: 1.4938524999926168

Epoch: 6| Step: 1
Training loss: 0.09856657683849335
Validation loss: 1.4863495006356189

Epoch: 6| Step: 2
Training loss: 0.08672654628753662
Validation loss: 1.4864889601225495

Epoch: 6| Step: 3
Training loss: 0.12449438869953156
Validation loss: 1.4673903667798607

Epoch: 6| Step: 4
Training loss: 0.09719611704349518
Validation loss: 1.5038642857664375

Epoch: 6| Step: 5
Training loss: 0.06057559698820114
Validation loss: 1.4684937513002785

Epoch: 6| Step: 6
Training loss: 0.09730881452560425
Validation loss: 1.5090295691643991

Epoch: 6| Step: 7
Training loss: 0.08023776113986969
Validation loss: 1.491278770149395

Epoch: 6| Step: 8
Training loss: 0.07355142384767532
Validation loss: 1.4896843946108254

Epoch: 6| Step: 9
Training loss: 0.2581644058227539
Validation loss: 1.5366558733806814

Epoch: 6| Step: 10
Training loss: 0.07728658616542816
Validation loss: 1.5373630498045234

Epoch: 6| Step: 11
Training loss: 0.1280720829963684
Validation loss: 1.5362009168953024

Epoch: 6| Step: 12
Training loss: 0.17512178421020508
Validation loss: 1.5403790871302288

Epoch: 6| Step: 13
Training loss: 0.11217468231916428
Validation loss: 1.5528153482303824

Epoch: 578| Step: 0
Training loss: 0.06436843425035477
Validation loss: 1.5561934812094576

Epoch: 6| Step: 1
Training loss: 0.2193436324596405
Validation loss: 1.552633729032291

Epoch: 6| Step: 2
Training loss: 0.06424902379512787
Validation loss: 1.5439967186220231

Epoch: 6| Step: 3
Training loss: 0.08392594754695892
Validation loss: 1.5396565724444646

Epoch: 6| Step: 4
Training loss: 0.09056400507688522
Validation loss: 1.531855958764271

Epoch: 6| Step: 5
Training loss: 0.09024516493082047
Validation loss: 1.5193664245708014

Epoch: 6| Step: 6
Training loss: 0.06968282908201218
Validation loss: 1.5363245946104809

Epoch: 6| Step: 7
Training loss: 0.0639735758304596
Validation loss: 1.5280587269413857

Epoch: 6| Step: 8
Training loss: 0.10405157506465912
Validation loss: 1.5271154090922365

Epoch: 6| Step: 9
Training loss: 0.15474796295166016
Validation loss: 1.534604690408194

Epoch: 6| Step: 10
Training loss: 0.056515492498874664
Validation loss: 1.5241565717163907

Epoch: 6| Step: 11
Training loss: 0.073130302131176
Validation loss: 1.5327376140061246

Epoch: 6| Step: 12
Training loss: 0.12267185747623444
Validation loss: 1.5518938533721431

Epoch: 6| Step: 13
Training loss: 0.06796017289161682
Validation loss: 1.5374834665688135

Epoch: 579| Step: 0
Training loss: 0.10434276610612869
Validation loss: 1.5365591318376604

Epoch: 6| Step: 1
Training loss: 0.11278188973665237
Validation loss: 1.538041546780576

Epoch: 6| Step: 2
Training loss: 0.1881103217601776
Validation loss: 1.5269451372085079

Epoch: 6| Step: 3
Training loss: 0.247111976146698
Validation loss: 1.5109697439337288

Epoch: 6| Step: 4
Training loss: 0.09222809225320816
Validation loss: 1.5026034488472888

Epoch: 6| Step: 5
Training loss: 0.07851635664701462
Validation loss: 1.5199152602944324

Epoch: 6| Step: 6
Training loss: 0.09063075482845306
Validation loss: 1.5083791286714616

Epoch: 6| Step: 7
Training loss: 0.05075982213020325
Validation loss: 1.4999091804668467

Epoch: 6| Step: 8
Training loss: 0.0693778395652771
Validation loss: 1.4865863249507

Epoch: 6| Step: 9
Training loss: 0.07303730398416519
Validation loss: 1.487335455033087

Epoch: 6| Step: 10
Training loss: 0.08908215165138245
Validation loss: 1.4962772169420797

Epoch: 6| Step: 11
Training loss: 0.06902985274791718
Validation loss: 1.5024739516678678

Epoch: 6| Step: 12
Training loss: 0.051042526960372925
Validation loss: 1.5045163900621477

Epoch: 6| Step: 13
Training loss: 0.09105786681175232
Validation loss: 1.5136856545684159

Epoch: 580| Step: 0
Training loss: 0.0756477415561676
Validation loss: 1.538084340351884

Epoch: 6| Step: 1
Training loss: 0.08108820021152496
Validation loss: 1.5426123193515244

Epoch: 6| Step: 2
Training loss: 0.07139885425567627
Validation loss: 1.506627764753116

Epoch: 6| Step: 3
Training loss: 0.098798468708992
Validation loss: 1.5387465915372294

Epoch: 6| Step: 4
Training loss: 0.06532846391201019
Validation loss: 1.5215515346937283

Epoch: 6| Step: 5
Training loss: 0.07018496096134186
Validation loss: 1.5093326530148905

Epoch: 6| Step: 6
Training loss: 0.16762575507164001
Validation loss: 1.4723363768669866

Epoch: 6| Step: 7
Training loss: 0.11265597492456436
Validation loss: 1.5152876146378056

Epoch: 6| Step: 8
Training loss: 0.08080069720745087
Validation loss: 1.5171257565098424

Epoch: 6| Step: 9
Training loss: 0.08653824776411057
Validation loss: 1.518074704113827

Epoch: 6| Step: 10
Training loss: 0.0718003585934639
Validation loss: 1.5018682133766912

Epoch: 6| Step: 11
Training loss: 0.2064901739358902
Validation loss: 1.5266430288232782

Epoch: 6| Step: 12
Training loss: 0.07248414307832718
Validation loss: 1.5148452437052162

Epoch: 6| Step: 13
Training loss: 0.1720440685749054
Validation loss: 1.5203339412648191

Epoch: 581| Step: 0
Training loss: 0.14241939783096313
Validation loss: 1.504919150824188

Epoch: 6| Step: 1
Training loss: 0.06187834590673447
Validation loss: 1.4663237717843824

Epoch: 6| Step: 2
Training loss: 0.057888202369213104
Validation loss: 1.481350015568477

Epoch: 6| Step: 3
Training loss: 0.24564705789089203
Validation loss: 1.445269654514969

Epoch: 6| Step: 4
Training loss: 0.07454812526702881
Validation loss: 1.4755909071173718

Epoch: 6| Step: 5
Training loss: 0.1086406409740448
Validation loss: 1.4962003513049054

Epoch: 6| Step: 6
Training loss: 0.11340558528900146
Validation loss: 1.491873521958628

Epoch: 6| Step: 7
Training loss: 0.0736626461148262
Validation loss: 1.4669409939037856

Epoch: 6| Step: 8
Training loss: 0.10075069218873978
Validation loss: 1.4576588087184454

Epoch: 6| Step: 9
Training loss: 0.07975772023200989
Validation loss: 1.4766433892711517

Epoch: 6| Step: 10
Training loss: 0.13657911121845245
Validation loss: 1.4623280468807425

Epoch: 6| Step: 11
Training loss: 0.07179582118988037
Validation loss: 1.4815735201681814

Epoch: 6| Step: 12
Training loss: 0.10786930471658707
Validation loss: 1.4868149193384315

Epoch: 6| Step: 13
Training loss: 0.047025859355926514
Validation loss: 1.5002426588407127

Epoch: 582| Step: 0
Training loss: 0.07342629879713058
Validation loss: 1.5233858785321635

Epoch: 6| Step: 1
Training loss: 0.08723294734954834
Validation loss: 1.5395527514078284

Epoch: 6| Step: 2
Training loss: 0.0855635330080986
Validation loss: 1.560786303653512

Epoch: 6| Step: 3
Training loss: 0.14983931183815002
Validation loss: 1.5688466090028004

Epoch: 6| Step: 4
Training loss: 0.10575598478317261
Validation loss: 1.5822449486742738

Epoch: 6| Step: 5
Training loss: 0.08617612719535828
Validation loss: 1.5738954300521522

Epoch: 6| Step: 6
Training loss: 0.09976063668727875
Validation loss: 1.5564339737738333

Epoch: 6| Step: 7
Training loss: 0.06073900684714317
Validation loss: 1.5581716709239508

Epoch: 6| Step: 8
Training loss: 0.09164103120565414
Validation loss: 1.5201801074448453

Epoch: 6| Step: 9
Training loss: 0.09184472262859344
Validation loss: 1.5009087644597536

Epoch: 6| Step: 10
Training loss: 0.12407121062278748
Validation loss: 1.51266009576859

Epoch: 6| Step: 11
Training loss: 0.0903162881731987
Validation loss: 1.513093940673336

Epoch: 6| Step: 12
Training loss: 0.25860583782196045
Validation loss: 1.499314764494537

Epoch: 6| Step: 13
Training loss: 0.11268223822116852
Validation loss: 1.4995942859239475

Epoch: 583| Step: 0
Training loss: 0.06798215210437775
Validation loss: 1.514534673383159

Epoch: 6| Step: 1
Training loss: 0.08063898235559464
Validation loss: 1.5303952796484834

Epoch: 6| Step: 2
Training loss: 0.11433103680610657
Validation loss: 1.525546000849816

Epoch: 6| Step: 3
Training loss: 0.06033313646912575
Validation loss: 1.550577635406166

Epoch: 6| Step: 4
Training loss: 0.07663692533969879
Validation loss: 1.5433954968247363

Epoch: 6| Step: 5
Training loss: 0.0615740641951561
Validation loss: 1.5586599585830525

Epoch: 6| Step: 6
Training loss: 0.07444483041763306
Validation loss: 1.5401636067257132

Epoch: 6| Step: 7
Training loss: 0.05802378058433533
Validation loss: 1.5689734028231712

Epoch: 6| Step: 8
Training loss: 0.06948266178369522
Validation loss: 1.5568384944751699

Epoch: 6| Step: 9
Training loss: 0.20474812388420105
Validation loss: 1.5477792575795164

Epoch: 6| Step: 10
Training loss: 0.11819569766521454
Validation loss: 1.560567254661232

Epoch: 6| Step: 11
Training loss: 0.15501777827739716
Validation loss: 1.5436862950683923

Epoch: 6| Step: 12
Training loss: 0.06524921953678131
Validation loss: 1.5480894760418964

Epoch: 6| Step: 13
Training loss: 0.09702245146036148
Validation loss: 1.5195194739167408

Epoch: 584| Step: 0
Training loss: 0.12924730777740479
Validation loss: 1.514425120046062

Epoch: 6| Step: 1
Training loss: 0.09934339672327042
Validation loss: 1.5070331353013233

Epoch: 6| Step: 2
Training loss: 0.1675923466682434
Validation loss: 1.4801995254332019

Epoch: 6| Step: 3
Training loss: 0.12100271880626678
Validation loss: 1.5006271280268186

Epoch: 6| Step: 4
Training loss: 0.0764278843998909
Validation loss: 1.4740794897079468

Epoch: 6| Step: 5
Training loss: 0.07265818119049072
Validation loss: 1.503212139170657

Epoch: 6| Step: 6
Training loss: 0.0661628469824791
Validation loss: 1.5149163033372612

Epoch: 6| Step: 7
Training loss: 0.18384909629821777
Validation loss: 1.504816678262526

Epoch: 6| Step: 8
Training loss: 0.08657702803611755
Validation loss: 1.5373704548804992

Epoch: 6| Step: 9
Training loss: 0.10196815431118011
Validation loss: 1.5536855728395524

Epoch: 6| Step: 10
Training loss: 0.09387741982936859
Validation loss: 1.5620735101802374

Epoch: 6| Step: 11
Training loss: 0.10512851178646088
Validation loss: 1.5695089704246932

Epoch: 6| Step: 12
Training loss: 0.08650338649749756
Validation loss: 1.548291458878466

Epoch: 6| Step: 13
Training loss: 0.11275865137577057
Validation loss: 1.5623887815783102

Epoch: 585| Step: 0
Training loss: 0.10725526511669159
Validation loss: 1.5246169772199405

Epoch: 6| Step: 1
Training loss: 0.0776064321398735
Validation loss: 1.527205572333387

Epoch: 6| Step: 2
Training loss: 0.09810306131839752
Validation loss: 1.5233529485682005

Epoch: 6| Step: 3
Training loss: 0.05356135591864586
Validation loss: 1.5372787342276624

Epoch: 6| Step: 4
Training loss: 0.10079768300056458
Validation loss: 1.5301041372360722

Epoch: 6| Step: 5
Training loss: 0.18810349702835083
Validation loss: 1.521529681580041

Epoch: 6| Step: 6
Training loss: 0.13025794923305511
Validation loss: 1.5214291708443755

Epoch: 6| Step: 7
Training loss: 0.1021592915058136
Validation loss: 1.5348683711021178

Epoch: 6| Step: 8
Training loss: 0.09017082303762436
Validation loss: 1.5273023343855334

Epoch: 6| Step: 9
Training loss: 0.10993656516075134
Validation loss: 1.537323223647251

Epoch: 6| Step: 10
Training loss: 0.05212513357400894
Validation loss: 1.5429995470149542

Epoch: 6| Step: 11
Training loss: 0.19275060296058655
Validation loss: 1.5387118170338292

Epoch: 6| Step: 12
Training loss: 0.08104999363422394
Validation loss: 1.5974003115007955

Epoch: 6| Step: 13
Training loss: 0.07382548600435257
Validation loss: 1.5291862910793674

Epoch: 586| Step: 0
Training loss: 0.09277720749378204
Validation loss: 1.5643124144564393

Epoch: 6| Step: 1
Training loss: 0.10675352066755295
Validation loss: 1.5476664304733276

Epoch: 6| Step: 2
Training loss: 0.10737120360136032
Validation loss: 1.5533279308708765

Epoch: 6| Step: 3
Training loss: 0.12151788920164108
Validation loss: 1.5411480806207145

Epoch: 6| Step: 4
Training loss: 0.09112950414419174
Validation loss: 1.5593730608622234

Epoch: 6| Step: 5
Training loss: 0.07851243019104004
Validation loss: 1.5514833696426884

Epoch: 6| Step: 6
Training loss: 0.151005357503891
Validation loss: 1.5271642618281867

Epoch: 6| Step: 7
Training loss: 0.07664951682090759
Validation loss: 1.5448132074007423

Epoch: 6| Step: 8
Training loss: 0.09447629749774933
Validation loss: 1.5127354334759455

Epoch: 6| Step: 9
Training loss: 0.07366324961185455
Validation loss: 1.5507118419934345

Epoch: 6| Step: 10
Training loss: 0.23497407138347626
Validation loss: 1.5161365398796656

Epoch: 6| Step: 11
Training loss: 0.08642871677875519
Validation loss: 1.5532331056492303

Epoch: 6| Step: 12
Training loss: 0.09345844388008118
Validation loss: 1.5431667181753344

Epoch: 6| Step: 13
Training loss: 0.07282572239637375
Validation loss: 1.5398094025991296

Epoch: 587| Step: 0
Training loss: 0.0874001532793045
Validation loss: 1.5638101280376475

Epoch: 6| Step: 1
Training loss: 0.17643585801124573
Validation loss: 1.5663941483343802

Epoch: 6| Step: 2
Training loss: 0.08835069835186005
Validation loss: 1.5311696183296941

Epoch: 6| Step: 3
Training loss: 0.04099471867084503
Validation loss: 1.5510980339460476

Epoch: 6| Step: 4
Training loss: 0.1771933138370514
Validation loss: 1.5428267448179183

Epoch: 6| Step: 5
Training loss: 0.10472407191991806
Validation loss: 1.5375772727433072

Epoch: 6| Step: 6
Training loss: 0.06924659758806229
Validation loss: 1.5332664187236498

Epoch: 6| Step: 7
Training loss: 0.06565017253160477
Validation loss: 1.4855483424278997

Epoch: 6| Step: 8
Training loss: 0.1001049280166626
Validation loss: 1.4985340936209566

Epoch: 6| Step: 9
Training loss: 0.0911632552742958
Validation loss: 1.506481998710222

Epoch: 6| Step: 10
Training loss: 0.05825219303369522
Validation loss: 1.482880615418957

Epoch: 6| Step: 11
Training loss: 0.056088000535964966
Validation loss: 1.499968428765574

Epoch: 6| Step: 12
Training loss: 0.07970505207777023
Validation loss: 1.4727282408745057

Epoch: 6| Step: 13
Training loss: 0.06386719644069672
Validation loss: 1.4942270209712367

Epoch: 588| Step: 0
Training loss: 0.07727932184934616
Validation loss: 1.5118549510996828

Epoch: 6| Step: 1
Training loss: 0.1902260184288025
Validation loss: 1.4887536905145133

Epoch: 6| Step: 2
Training loss: 0.10895238071680069
Validation loss: 1.4813896315072173

Epoch: 6| Step: 3
Training loss: 0.06724372506141663
Validation loss: 1.5103211889984787

Epoch: 6| Step: 4
Training loss: 0.09150004386901855
Validation loss: 1.5148430870425316

Epoch: 6| Step: 5
Training loss: 0.07227982580661774
Validation loss: 1.530197242254852

Epoch: 6| Step: 6
Training loss: 0.040517546236515045
Validation loss: 1.4938064249612952

Epoch: 6| Step: 7
Training loss: 0.07176916301250458
Validation loss: 1.5114150925349163

Epoch: 6| Step: 8
Training loss: 0.055094968527555466
Validation loss: 1.533029858784009

Epoch: 6| Step: 9
Training loss: 0.14053988456726074
Validation loss: 1.5127471967410016

Epoch: 6| Step: 10
Training loss: 0.10049280524253845
Validation loss: 1.4946943649681665

Epoch: 6| Step: 11
Training loss: 0.11673659086227417
Validation loss: 1.5062868825850948

Epoch: 6| Step: 12
Training loss: 0.04792892932891846
Validation loss: 1.4683731627720658

Epoch: 6| Step: 13
Training loss: 0.11302651464939117
Validation loss: 1.4784477205686672

Epoch: 589| Step: 0
Training loss: 0.22728845477104187
Validation loss: 1.4871842322811004

Epoch: 6| Step: 1
Training loss: 0.07655362784862518
Validation loss: 1.4891574152054325

Epoch: 6| Step: 2
Training loss: 0.08341272175312042
Validation loss: 1.5064261292898526

Epoch: 6| Step: 3
Training loss: 0.07311969995498657
Validation loss: 1.5182652076085408

Epoch: 6| Step: 4
Training loss: 0.09386153519153595
Validation loss: 1.5453841558066748

Epoch: 6| Step: 5
Training loss: 0.10554514825344086
Validation loss: 1.5314707127950524

Epoch: 6| Step: 6
Training loss: 0.10487264394760132
Validation loss: 1.5275672353723997

Epoch: 6| Step: 7
Training loss: 0.05324613302946091
Validation loss: 1.4993324523331018

Epoch: 6| Step: 8
Training loss: 0.05377846956253052
Validation loss: 1.5071653114852084

Epoch: 6| Step: 9
Training loss: 0.12150963395833969
Validation loss: 1.4985784792130994

Epoch: 6| Step: 10
Training loss: 0.14650358259677887
Validation loss: 1.513426294890783

Epoch: 6| Step: 11
Training loss: 0.06445204466581345
Validation loss: 1.4865949320536789

Epoch: 6| Step: 12
Training loss: 0.07637885957956314
Validation loss: 1.495076176940754

Epoch: 6| Step: 13
Training loss: 0.0904269590973854
Validation loss: 1.4820434701058172

Epoch: 590| Step: 0
Training loss: 0.09984451532363892
Validation loss: 1.5077707767486572

Epoch: 6| Step: 1
Training loss: 0.05909116938710213
Validation loss: 1.5200195543227657

Epoch: 6| Step: 2
Training loss: 0.07612432539463043
Validation loss: 1.5190088018294303

Epoch: 6| Step: 3
Training loss: 0.1359299123287201
Validation loss: 1.5365737715075094

Epoch: 6| Step: 4
Training loss: 0.11621823906898499
Validation loss: 1.5153748386649675

Epoch: 6| Step: 5
Training loss: 0.09201325476169586
Validation loss: 1.5369567243001794

Epoch: 6| Step: 6
Training loss: 0.10548508167266846
Validation loss: 1.524393363665509

Epoch: 6| Step: 7
Training loss: 0.05100945010781288
Validation loss: 1.5074965787190262

Epoch: 6| Step: 8
Training loss: 0.06037692725658417
Validation loss: 1.5004009867227206

Epoch: 6| Step: 9
Training loss: 0.11093755066394806
Validation loss: 1.4817551733345113

Epoch: 6| Step: 10
Training loss: 0.1940624713897705
Validation loss: 1.5070838114266754

Epoch: 6| Step: 11
Training loss: 0.0663089007139206
Validation loss: 1.4859101131398191

Epoch: 6| Step: 12
Training loss: 0.06672322005033493
Validation loss: 1.454041104803803

Epoch: 6| Step: 13
Training loss: 0.13079151511192322
Validation loss: 1.5025155646826631

Epoch: 591| Step: 0
Training loss: 0.06464137136936188
Validation loss: 1.4858935033121417

Epoch: 6| Step: 1
Training loss: 0.06904047727584839
Validation loss: 1.4826755344226796

Epoch: 6| Step: 2
Training loss: 0.048077695071697235
Validation loss: 1.5038803046749485

Epoch: 6| Step: 3
Training loss: 0.1465791016817093
Validation loss: 1.5122089642350391

Epoch: 6| Step: 4
Training loss: 0.06303009390830994
Validation loss: 1.4669901773493776

Epoch: 6| Step: 5
Training loss: 0.10823000967502594
Validation loss: 1.4966314851596791

Epoch: 6| Step: 6
Training loss: 0.048728279769420624
Validation loss: 1.4857357676311205

Epoch: 6| Step: 7
Training loss: 0.04842079058289528
Validation loss: 1.4847362951565815

Epoch: 6| Step: 8
Training loss: 0.0791735053062439
Validation loss: 1.5037848539249872

Epoch: 6| Step: 9
Training loss: 0.04607543349266052
Validation loss: 1.5006542564720236

Epoch: 6| Step: 10
Training loss: 0.050704583525657654
Validation loss: 1.4889786384438957

Epoch: 6| Step: 11
Training loss: 0.05182517319917679
Validation loss: 1.490284901793285

Epoch: 6| Step: 12
Training loss: 0.20961350202560425
Validation loss: 1.4942821225812357

Epoch: 6| Step: 13
Training loss: 0.16915734112262726
Validation loss: 1.5067969060713244

Epoch: 592| Step: 0
Training loss: 0.067936971783638
Validation loss: 1.5384382663234588

Epoch: 6| Step: 1
Training loss: 0.05175265669822693
Validation loss: 1.522023070243097

Epoch: 6| Step: 2
Training loss: 0.04841981083154678
Validation loss: 1.513514522583254

Epoch: 6| Step: 3
Training loss: 0.21296431124210358
Validation loss: 1.5220977542220906

Epoch: 6| Step: 4
Training loss: 0.06868114322423935
Validation loss: 1.4938330637511386

Epoch: 6| Step: 5
Training loss: 0.06473458558320999
Validation loss: 1.498587631410168

Epoch: 6| Step: 6
Training loss: 0.12402256578207016
Validation loss: 1.496433311893094

Epoch: 6| Step: 7
Training loss: 0.06952480971813202
Validation loss: 1.4718635287336124

Epoch: 6| Step: 8
Training loss: 0.05825119838118553
Validation loss: 1.4809773314383723

Epoch: 6| Step: 9
Training loss: 0.06238409876823425
Validation loss: 1.4669026456853396

Epoch: 6| Step: 10
Training loss: 0.12499121576547623
Validation loss: 1.474577311546572

Epoch: 6| Step: 11
Training loss: 0.07814699411392212
Validation loss: 1.4845720286010413

Epoch: 6| Step: 12
Training loss: 0.06987382471561432
Validation loss: 1.4727876013325107

Epoch: 6| Step: 13
Training loss: 0.10597644001245499
Validation loss: 1.4888643692898493

Epoch: 593| Step: 0
Training loss: 0.06198921799659729
Validation loss: 1.4745320286802066

Epoch: 6| Step: 1
Training loss: 0.0633254274725914
Validation loss: 1.47701362768809

Epoch: 6| Step: 2
Training loss: 0.07510469853878021
Validation loss: 1.5038180646075998

Epoch: 6| Step: 3
Training loss: 0.04960417374968529
Validation loss: 1.5154856545950777

Epoch: 6| Step: 4
Training loss: 0.22198952734470367
Validation loss: 1.5129523674647014

Epoch: 6| Step: 5
Training loss: 0.045051850378513336
Validation loss: 1.5183186928431194

Epoch: 6| Step: 6
Training loss: 0.11697456240653992
Validation loss: 1.509426788617206

Epoch: 6| Step: 7
Training loss: 0.05408553034067154
Validation loss: 1.4971822320774038

Epoch: 6| Step: 8
Training loss: 0.06486604362726212
Validation loss: 1.5235320714212233

Epoch: 6| Step: 9
Training loss: 0.11198213696479797
Validation loss: 1.5096393413441156

Epoch: 6| Step: 10
Training loss: 0.09142805635929108
Validation loss: 1.5153517197537165

Epoch: 6| Step: 11
Training loss: 0.0970160961151123
Validation loss: 1.5249930383056722

Epoch: 6| Step: 12
Training loss: 0.10588082671165466
Validation loss: 1.5515722818272089

Epoch: 6| Step: 13
Training loss: 0.05593501031398773
Validation loss: 1.5053074654712473

Epoch: 594| Step: 0
Training loss: 0.06608446687459946
Validation loss: 1.5121688765864219

Epoch: 6| Step: 1
Training loss: 0.06961207091808319
Validation loss: 1.5085824535739036

Epoch: 6| Step: 2
Training loss: 0.09801097214221954
Validation loss: 1.4945001948264338

Epoch: 6| Step: 3
Training loss: 0.07452534884214401
Validation loss: 1.473201963850247

Epoch: 6| Step: 4
Training loss: 0.07696786522865295
Validation loss: 1.4755519461888138

Epoch: 6| Step: 5
Training loss: 0.23054814338684082
Validation loss: 1.483586439522364

Epoch: 6| Step: 6
Training loss: 0.08310873806476593
Validation loss: 1.464625843109623

Epoch: 6| Step: 7
Training loss: 0.16106897592544556
Validation loss: 1.4752443452035227

Epoch: 6| Step: 8
Training loss: 0.09088486433029175
Validation loss: 1.4567819910664712

Epoch: 6| Step: 9
Training loss: 0.04999430477619171
Validation loss: 1.473337290107563

Epoch: 6| Step: 10
Training loss: 0.098051056265831
Validation loss: 1.5134790648696244

Epoch: 6| Step: 11
Training loss: 0.0698825865983963
Validation loss: 1.492354853178865

Epoch: 6| Step: 12
Training loss: 0.08428795635700226
Validation loss: 1.4824197664055774

Epoch: 6| Step: 13
Training loss: 0.08105286955833435
Validation loss: 1.4995404340887581

Epoch: 595| Step: 0
Training loss: 0.07931871712207794
Validation loss: 1.503280717839477

Epoch: 6| Step: 1
Training loss: 0.0903070867061615
Validation loss: 1.506549153276669

Epoch: 6| Step: 2
Training loss: 0.08709384500980377
Validation loss: 1.4942860936605802

Epoch: 6| Step: 3
Training loss: 0.042664606124162674
Validation loss: 1.4887899121930521

Epoch: 6| Step: 4
Training loss: 0.03448134660720825
Validation loss: 1.520428172362748

Epoch: 6| Step: 5
Training loss: 0.0578104667365551
Validation loss: 1.5296742993016397

Epoch: 6| Step: 6
Training loss: 0.10683310031890869
Validation loss: 1.4912558050565823

Epoch: 6| Step: 7
Training loss: 0.05663047730922699
Validation loss: 1.5061203651530768

Epoch: 6| Step: 8
Training loss: 0.09234223514795303
Validation loss: 1.5067718939114643

Epoch: 6| Step: 9
Training loss: 0.08604195713996887
Validation loss: 1.5055836169950423

Epoch: 6| Step: 10
Training loss: 0.07797734439373016
Validation loss: 1.488977946260924

Epoch: 6| Step: 11
Training loss: 0.21213340759277344
Validation loss: 1.5149110145466302

Epoch: 6| Step: 12
Training loss: 0.141302227973938
Validation loss: 1.5258128309762606

Epoch: 6| Step: 13
Training loss: 0.07242261618375778
Validation loss: 1.5054014882733744

Epoch: 596| Step: 0
Training loss: 0.06741911917924881
Validation loss: 1.5110222665212487

Epoch: 6| Step: 1
Training loss: 0.27112168073654175
Validation loss: 1.5408725200160858

Epoch: 6| Step: 2
Training loss: 0.07647264003753662
Validation loss: 1.5297349934936852

Epoch: 6| Step: 3
Training loss: 0.06888943165540695
Validation loss: 1.5173077839677052

Epoch: 6| Step: 4
Training loss: 0.07111582159996033
Validation loss: 1.5036111441991662

Epoch: 6| Step: 5
Training loss: 0.0501120463013649
Validation loss: 1.5231253767526278

Epoch: 6| Step: 6
Training loss: 0.09629042446613312
Validation loss: 1.4878337921634797

Epoch: 6| Step: 7
Training loss: 0.06704282760620117
Validation loss: 1.4719601260718478

Epoch: 6| Step: 8
Training loss: 0.0629483088850975
Validation loss: 1.4941402827539751

Epoch: 6| Step: 9
Training loss: 0.05914333462715149
Validation loss: 1.4728320849839078

Epoch: 6| Step: 10
Training loss: 0.07120075821876526
Validation loss: 1.4700656206377092

Epoch: 6| Step: 11
Training loss: 0.06862808763980865
Validation loss: 1.4831933616310038

Epoch: 6| Step: 12
Training loss: 0.11065633594989777
Validation loss: 1.4903652815408603

Epoch: 6| Step: 13
Training loss: 0.06527205556631088
Validation loss: 1.4672668608286048

Epoch: 597| Step: 0
Training loss: 0.06055092811584473
Validation loss: 1.4867329059108612

Epoch: 6| Step: 1
Training loss: 0.08380021154880524
Validation loss: 1.5016185622061453

Epoch: 6| Step: 2
Training loss: 0.12893855571746826
Validation loss: 1.5035442049785326

Epoch: 6| Step: 3
Training loss: 0.09347324073314667
Validation loss: 1.5009298901404104

Epoch: 6| Step: 4
Training loss: 0.05487952008843422
Validation loss: 1.55037711897204

Epoch: 6| Step: 5
Training loss: 0.09072024375200272
Validation loss: 1.5498909347800798

Epoch: 6| Step: 6
Training loss: 0.10901708900928497
Validation loss: 1.5901117837557228

Epoch: 6| Step: 7
Training loss: 0.22896626591682434
Validation loss: 1.5721497740796817

Epoch: 6| Step: 8
Training loss: 0.06452450901269913
Validation loss: 1.5369577882110432

Epoch: 6| Step: 9
Training loss: 0.06951915472745895
Validation loss: 1.5102197572749148

Epoch: 6| Step: 10
Training loss: 0.06597240269184113
Validation loss: 1.5106288502293248

Epoch: 6| Step: 11
Training loss: 0.06914552301168442
Validation loss: 1.4690841141567434

Epoch: 6| Step: 12
Training loss: 0.10602761805057526
Validation loss: 1.4936804899605371

Epoch: 6| Step: 13
Training loss: 0.09477856755256653
Validation loss: 1.4803455888584096

Epoch: 598| Step: 0
Training loss: 0.0885385274887085
Validation loss: 1.4816224549406318

Epoch: 6| Step: 1
Training loss: 0.05607246607542038
Validation loss: 1.486750497612902

Epoch: 6| Step: 2
Training loss: 0.06062692031264305
Validation loss: 1.4901020808886456

Epoch: 6| Step: 3
Training loss: 0.23064953088760376
Validation loss: 1.4751595309985581

Epoch: 6| Step: 4
Training loss: 0.07070358097553253
Validation loss: 1.4821266538353377

Epoch: 6| Step: 5
Training loss: 0.08224879950284958
Validation loss: 1.5127842865323509

Epoch: 6| Step: 6
Training loss: 0.07233534008264542
Validation loss: 1.4967112118198025

Epoch: 6| Step: 7
Training loss: 0.06516537070274353
Validation loss: 1.525874569851865

Epoch: 6| Step: 8
Training loss: 0.07738497853279114
Validation loss: 1.5401305075614684

Epoch: 6| Step: 9
Training loss: 0.06064554303884506
Validation loss: 1.5254834621183333

Epoch: 6| Step: 10
Training loss: 0.07816028594970703
Validation loss: 1.5279840807760916

Epoch: 6| Step: 11
Training loss: 0.07570217549800873
Validation loss: 1.5526803578099897

Epoch: 6| Step: 12
Training loss: 0.0689595565199852
Validation loss: 1.531996577016769

Epoch: 6| Step: 13
Training loss: 0.2227175235748291
Validation loss: 1.5356599502666022

Epoch: 599| Step: 0
Training loss: 0.06922335922718048
Validation loss: 1.478711683263061

Epoch: 6| Step: 1
Training loss: 0.06302438676357269
Validation loss: 1.4961186493596723

Epoch: 6| Step: 2
Training loss: 0.04502645507454872
Validation loss: 1.4878314900141891

Epoch: 6| Step: 3
Training loss: 0.06986947357654572
Validation loss: 1.4857614527466476

Epoch: 6| Step: 4
Training loss: 0.08034771680831909
Validation loss: 1.4845859773697392

Epoch: 6| Step: 5
Training loss: 0.05543076992034912
Validation loss: 1.4629706375060543

Epoch: 6| Step: 6
Training loss: 0.2070876806974411
Validation loss: 1.4748605573049156

Epoch: 6| Step: 7
Training loss: 0.11478951573371887
Validation loss: 1.5138299670270694

Epoch: 6| Step: 8
Training loss: 0.06599089503288269
Validation loss: 1.5054551119445472

Epoch: 6| Step: 9
Training loss: 0.061256058514118195
Validation loss: 1.4862885077794392

Epoch: 6| Step: 10
Training loss: 0.08061274141073227
Validation loss: 1.4944240034267466

Epoch: 6| Step: 11
Training loss: 0.13720686733722687
Validation loss: 1.4556730344731321

Epoch: 6| Step: 12
Training loss: 0.0631750077009201
Validation loss: 1.4859163729093408

Epoch: 6| Step: 13
Training loss: 0.13380810618400574
Validation loss: 1.503780488044985

Epoch: 600| Step: 0
Training loss: 0.09074799716472626
Validation loss: 1.4863625662301176

Epoch: 6| Step: 1
Training loss: 0.05291347950696945
Validation loss: 1.4998078294979629

Epoch: 6| Step: 2
Training loss: 0.04290188103914261
Validation loss: 1.4929439547241374

Epoch: 6| Step: 3
Training loss: 0.12930195033550262
Validation loss: 1.4821910012152888

Epoch: 6| Step: 4
Training loss: 0.06965272128582001
Validation loss: 1.4905553819030843

Epoch: 6| Step: 5
Training loss: 0.07891447842121124
Validation loss: 1.521601302649385

Epoch: 6| Step: 6
Training loss: 0.09673377871513367
Validation loss: 1.5182743508328673

Epoch: 6| Step: 7
Training loss: 0.09613882750272751
Validation loss: 1.5287324613140476

Epoch: 6| Step: 8
Training loss: 0.057405292987823486
Validation loss: 1.487377840985534

Epoch: 6| Step: 9
Training loss: 0.06521419435739517
Validation loss: 1.485689196535336

Epoch: 6| Step: 10
Training loss: 0.04487314075231552
Validation loss: 1.5018384097724833

Epoch: 6| Step: 11
Training loss: 0.06303705275058746
Validation loss: 1.4791233975400206

Epoch: 6| Step: 12
Training loss: 0.08591217547655106
Validation loss: 1.4853690555018764

Epoch: 6| Step: 13
Training loss: 0.28630635142326355
Validation loss: 1.4811693852947605

Testing loss: 2.204161198933919
